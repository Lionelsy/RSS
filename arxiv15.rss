<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 16 Jun 2025 14:17:31 +0800</lastBuildDate>
    <item>
      <title>Cross-Modal Clustering-Guided Negative Sampling for Self-Supervised Joint Learning from Medical Images and Reports</title>
      <link>http://arxiv.org/abs/2506.11674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE TMI for possible  publication. Our code is available at https://github.com/violet-42/CM-CGNS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CM-CGNS的多模态自监督学习方法，用于从配对图像和报告中直接学习医学视觉表示，以解决现有模型存在的问题。&lt;h4&gt;背景&lt;/h4&gt;近年来，直接从配对图像和报告中通过多模态自监督学习来学习医学视觉表示已成为数字诊断的一种新颖且高效的方法。&lt;h4&gt;目的&lt;/h4&gt;针对现有模型的局限性，提出一种新的方法来提高医学视觉表示的学习效果。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法包括：1) 通过跨模态注意力将k-means聚类从单模态域扩展到多模态域，以增加负样本的数量并提高模型的表达能力；2) 引入一个名为CM-MIR的模块，该模块利用通过跨模态注意力获得的局部文本到图像特征来重建掩码的局部图像区域，增强模型的跨模态信息交互能力并保留对下游任务至关重要的低级图像特征。&lt;h4&gt;主要发现&lt;/h4&gt;通过解决现有模型的局限性，CM-CGNS能够学习有效的和鲁棒的医学视觉表示，适用于各种识别任务。&lt;h4&gt;结论&lt;/h4&gt;在五个下游数据集上的广泛实验结果表明，该方法在分类、检测和分割任务上优于现有方法，验证了其优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，通过多模态自监督学习直接从配对图像和报告中学习医学视觉表示已成为数字诊断的一种新颖且高效的方法。然而，现有的模型存在几个严重的局限性。1）忽略了负样本的选择，导致硬负样本稀缺和错误负样本的包含；2）专注于全局特征提取，但忽略了对于医学图像识别任务至关重要的细粒度局部细节；3）对比学习主要针对高级特征，但忽略了对于准确医学分析至关重要的低级细节。受这些关键问题的启发，本文提出了一种名为Cross-Modal Cluster-Guided Negative Sampling (CM-CGNS)的方法，包含两个方面的想法。首先，它通过跨模态注意力将用于单模态域中的局部文本特征的k-means聚类扩展到多模态域，这种改进增加了负样本的数量并提高了模型的表达能力。其次，它引入了一个名为Cross-Modal Masked Image Reconstruction (CM-MIR)的模块，该模块利用通过跨模态注意力获得的局部文本到图像特征来重建掩码的局部图像区域。该模块显著增强了模型的跨模态信息交互能力并保留了对于下游任务至关重要的低级图像特征。通过妥善处理上述局限性，所提出的CM-CGNS可以学习适用于各种识别任务的有效和鲁棒的医学视觉表示。在五个下游数据集上的分类、检测和分割任务的广泛实验结果表明，我们的方法在多个指标上优于现有方法，验证了其优越的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning medical visual representations directly from paired images andreports through multimodal self-supervised learning has emerged as a novel andefficient approach to digital diagnosis in recent years. However, existingmodels suffer from several severe limitations. 1) neglecting the selection ofnegative samples, resulting in the scarcity of hard negatives and the inclusionof false negatives; 2) focusing on global feature extraction, but overlookingthe fine-grained local details that are crucial for medical image recognitiontasks; and 3) contrastive learning primarily targets high-level features butignoring low-level details which are essential for accurate medical analysis.Motivated by these critical issues, this paper presents a Cross-ModalCluster-Guided Negative Sampling (CM-CGNS) method with two-fold ideas. First,it extends the k-means clustering used for local text features in thesingle-modal domain to the multimodal domain through cross-modal attention.This improvement increases the number of negative samples and boosts the modelrepresentation capability. Second, it introduces a Cross-Modal Masked ImageReconstruction (CM-MIR) module that leverages local text-to-image featuresobtained via cross-modal attention to reconstruct masked local image regions.This module significantly strengthens the model's cross-modal informationinteraction capabilities and retains low-level image features essential fordownstream tasks. By well handling the aforementioned limitations, the proposedCM-CGNS can learn effective and robust medical visual representations suitablefor various recognition tasks. Extensive experimental results onclassification, detection, and segmentation tasks across five downstreamdatasets show that our method outperforms state-of-the-art approaches onmultiple metrics, verifying its superior performance.</description>
      <author>example@mail.com (Libin Lan, Hongxing Li, Zunhui Xia, Juan Zhou, Xiaofei Zhu, Yongmei Li, Yudong Zhang, Xin Luo)</author>
      <guid isPermaLink="false">2506.11674v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
  <item>
      <title>Generative Representational Learning of Foundation Models for Recommendation</title>
      <link>http://arxiv.org/abs/2506.11999v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page is available at https://junkfood436.github.io/RecFound/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为RecFound的推荐基础模型生成表示学习框架，旨在解决推荐系统中的多任务学习问题。&lt;h4&gt;背景&lt;/h4&gt;在人工智能领域，开发能够跨不同任务表现优异的单个基础模型是一个长期目标。通用基础模型的影响已扩展到推荐系统领域。&lt;h4&gt;目的&lt;/h4&gt;针对现有推荐基础模型在嵌入任务和复杂的多任务学习问题上的不足，提出一种新的框架来解决知识共享、冲突解决和收敛速度不一致等问题。&lt;h4&gt;方法&lt;/h4&gt;构建了第一个涵盖生成和嵌入任务的推荐基础模型综合数据集，并提出了一种新颖的多任务训练方案，包括任务特定低秩专家混合（TMoLE）处理知识共享和冲突，逐步收敛导向的样本调度器（S2Sched）解决收敛不一致问题，以及模型合并模块以平衡不同任务的性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，RecFound在多种推荐任务上实现了最先进的性能，优于现有基线。&lt;h4&gt;结论&lt;/h4&gt;RecFound框架能够有效提升推荐系统的多任务学习能力，为推荐系统领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing a single foundation model with the capability to excel acrossdiverse tasks has been a long-standing objective in the field of artificialintelligence. As the wave of general-purpose foundation models sweeps acrossvarious domains, their influence has significantly extended to the field ofrecommendation systems. While recent efforts have explored recommendationfoundation models for various generative tasks, they often overlook crucialembedding tasks and struggle with the complexities of multi-task learning,including knowledge sharing &amp; conflict resolution, and convergence speedinconsistencies. To address these limitations, we introduce RecFound, agenerative representational learning framework for recommendation foundationmodels. We construct the first comprehensive dataset for recommendationfoundation models covering both generative and embedding tasks across diversescenarios. Based on this dataset, we propose a novel multi-task training schemefeaturing a Task-wise Mixture of Low-rank Experts (TMoLE) to handle knowledgesharing &amp; conflict, a Step-wise Convergence-oriented Sample Scheduler (S2Sched)to address inconsistent convergence, and a Model Merge module to balance theperformance across tasks. Experiments demonstrate that RecFound achievesstate-of-the-art performance across various recommendation tasks, outperformingexisting baselines.</description>
      <author>example@mail.com (Zheli Zhou, Chenxu Zhu, Jianghao Lin, Bo Chen, Ruiming Tang, Weinan Zhang, Yong Yu)</author>
      <guid isPermaLink="false">2506.11999v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Robust Filtering -- Novel Statistical Learning and Inference Algorithms with Applications</title>
      <link>http://arxiv.org/abs/2506.11530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD Thesis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了新颖的非线性滤波方法，用于解决实际场景中存在的异常问题，如异常值、偏差、漂移和缺失观测，以提高智能决策在自动驾驶、机器人、医疗监测、智能电网、智能交通和预测维护等领域的应用。&lt;h4&gt;背景&lt;/h4&gt;传统的滤波方法依赖于对噪声统计特性的先验知识，但在实际应用中，这些先验知识往往是未知的或部分已知的，限制了传统方法的应用。&lt;h4&gt;目的&lt;/h4&gt;提出新的鲁棒非线性滤波方法，以解决实际应用中存在的挑战，并扩展到离线估计/学习设置和提出平滑扩展。&lt;h4&gt;方法&lt;/h4&gt;方法基于贝叶斯推理框架，采用确定性近似和随机近似技术，包括变分推理（VI）和粒子滤波/顺序蒙特卡洛（SMC）。同时，使用贝叶斯克拉美罗界（BCRBs）研究测量异常情况下的理论估计极限。&lt;h4&gt;主要发现&lt;/h4&gt;通过仿真和实验验证了所提方法在目标跟踪、室内定位、3D点云配准、网格配准和姿态图优化等场景中的性能提升。&lt;h4&gt;结论&lt;/h4&gt;该研究的基础性质使其在多种应用中具有实用性，并可能在未来扩展到开发异常值鲁棒的机器学习管道、从异常数据中学习系统动力学，以及解决标准扩散模型在存在异常值、不平衡数据集和模式坍塌等挑战中的问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要：状态估计或滤波是使自动驾驶、机器人、医疗监测、智能电网、智能交通和预测维护等应用中的智能决策成为可能的基本任务。标准滤波假设对噪声统计特性的先验知识以从噪声传感器数据中提取潜在的系统状态。然而，现实场景涉及异常值、偏差、漂移和缺失观测等异常情况，具有未知或部分已知的统计特性，限制了传统方法。本文提出了新颖的鲁棒非线性滤波方法来缓解这些挑战。基于我们的滤波方案，我们扩展了离线估计/学习设置，并提出了平滑扩展。我们的方法利用贝叶斯推理框架，采用包括变分推理（VI）和粒子滤波/顺序蒙特卡洛（SMC）在内的确定性近似和随机近似技术。我们还研究了测量异常情况下的贝叶斯克拉美罗界（BCRBs）的理论估计极限。为了验证所提方法性能的提升，我们在包括目标跟踪、室内定位、3D点云配准、网格配准和姿态图优化等场景中进行了仿真和实验。该研究的基础性质使其在多种应用中具有实用性，并可能在未来扩展到开发异常值鲁棒的机器学习管道、从异常数据中学习系统动力学，以及解决标准扩散模型在存在异常值、不平衡数据集和模式坍塌等挑战中的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State estimation or filtering serves as a fundamental task to enableintelligent decision-making in applications such as autonomous vehicles,robotics, healthcare monitoring, smart grids, intelligent transportation, andpredictive maintenance. Standard filtering assumes prior knowledge of noisestatistics to extract latent system states from noisy sensor data. However,real-world scenarios involve abnormalities like outliers, biases, drifts, andmissing observations with unknown or partially known statistics, limitingconventional approaches. This thesis presents novel robust nonlinear filteringmethods to mitigate these challenges. Based on insights from our filteringproposals, we extend the formulations to offline estimation/learning setups andpropose smoothing extensions. Our methods leverage Bayesian inferenceframeworks, employing both deterministic and stochastic approximationtechniques including Variational Inference (VI) and Particle Filters/SequentialMonte Carlo (SMC). We also study theoretical estimation limits using BayesianCram\'er-Rao bounds (BCRBs) in the context of measurement abnormalities. Tovalidate the performance gains of the proposed methods, we perform simulationsand experiments in scenarios including target tracking, indoor localization, 3Dpoint cloud registration, mesh registration, and pose graph optimization. Thefundamental nature of the work makes it useful in diverse applications, withpossible future extensions toward developing outlier-robust machine learningpipelines, learning system dynamics from anomalous data, and addressingchallenges in generative AI where standard diffusion models struggle withoutliers, imbalanced datasets, and mode collapse.</description>
      <author>example@mail.com (Aamir Hussain Chughtai)</author>
      <guid isPermaLink="false">2506.11530v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>GynSurg: A Comprehensive Gynecology Laparoscopic Surgery Dataset</title>
      <link>http://arxiv.org/abs/2506.11356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;深度学习在计算机辅助干预和手术视频分析方面的进步，不仅提升了手术训练、术中决策支持和患者预后，还改善了术后文档记录和手术发现。&lt;h4&gt;背景&lt;/h4&gt;近年来，深度学习在计算机辅助干预和手术视频分析领域取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有数据集规模小、任务范围窄、标注不够详细等问题，我们引入了GynSurg数据集。&lt;h4&gt;方法&lt;/h4&gt;我们创建了GynSurg数据集，这是迄今为止最大、最多样化的多任务妇科腹腔镜手术数据集，涵盖了动作识别、语义分割、手术文档记录和新手术方法发现等多个任务。&lt;h4&gt;主要发现&lt;/h4&gt;GynSurg数据集提供了丰富的标注，支持各种应用，并通过在标准训练协议下测试最先进的模型来证明数据集的质量和多功能性。&lt;h4&gt;结论&lt;/h4&gt;为了加速该领域的发展，我们公开发布了GynSurg数据集及其标注。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in deep learning have transformed computer-assistedintervention and surgical video analysis, driving improvements not only insurgical training, intraoperative decision support, and patient outcomes, butalso in postoperative documentation and surgical discovery. Central to thesedevelopments is the availability of large, high-quality annotated datasets. Ingynecologic laparoscopy, surgical scene understanding and action recognitionare fundamental for building intelligent systems that assist surgeons duringoperations and provide deeper analysis after surgery. However, existingdatasets are often limited by small scale, narrow task focus, or insufficientlydetailed annotations, limiting their utility for comprehensive, end-to-endworkflow analysis. To address these limitations, we introduce GynSurg, thelargest and most diverse multi-task dataset for gynecologic laparoscopicsurgery to date. GynSurg provides rich annotations across multiple tasks,supporting applications in action recognition, semantic segmentation, surgicaldocumentation, and discovery of novel procedural insights. We demonstrate thedataset quality and versatility by benchmarking state-of-the-art models under astandardized training protocol. To accelerate progress in the field, wepublicly release the GynSurg dataset and its annotations</description>
      <author>example@mail.com (Sahar Nasirihaghighi, Negin Ghamsarian, Leonie Peschek, Matteo Munari, Heinrich Husslein, Raphael Sznitman, Klaus Schoeffmann)</author>
      <guid isPermaLink="false">2506.11356v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable representation learning of quantum data enabled by probabilistic variational autoencoders</title>
      <link>http://arxiv.org/abs/2506.11982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Main text 10 pages, total document 16 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;可解释机器学习正在迅速成为科学发现的关键工具。变分自编码器（VAEs）在提取某些输入数据的隐藏物理特征方面显示出潜力，无需对研究系统的监督或先验知识。然而，VAEs创建有意义的可解释表示的能力依赖于其对输入潜在概率分布的准确近似。在处理量子数据时，VAEs必须考虑其固有的随机性和复杂相关性。尽管VAEs先前已被应用于量子数据，但它们通常忽略了其概率性质，阻碍了有意义的物理描述符的提取。本研究通过两个关键修改使VAEs能够学习物理意义上的潜在表示：一个能够忠实重现量子状态的解码器和一个针对此任务的概率损失函数。使用基准量子自旋模型，我们确定了标准方法失败而本方法学习到的表示仍然有意义的范围。应用于Rydberg原子阵列的实验数据，该模型自主发现相结构，无需访问先验标签、哈密顿细节或有关相关序参数的知识，突显了其在量子系统研究中的无监督和可解释工具的潜力。&lt;h4&gt;背景&lt;/h4&gt;可解释机器学习正成为科学发现的关键工具，VAEs在提取输入数据的隐藏物理特征方面显示出潜力。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过修改VAEs来使其能够学习到物理意义上的潜在表示，并应用于量子系统的研究。&lt;h4&gt;方法&lt;/h4&gt;通过两个关键修改，包括一个能够忠实重现量子状态的解码器和针对此任务的概率损失函数，来增强VAEs的学习能力。使用基准量子自旋模型和Rydberg原子阵列的实验数据进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;通过修改VAEs，能够学习到物理意义上的潜在表示，并在量子系统研究中展现出无监督和可解释的潜力。&lt;h4&gt;结论&lt;/h4&gt;VAEs经过适当修改后，可以成为量子系统研究中无监督和可解释的工具。&lt;h4&gt;翻译&lt;/h4&gt;Interpretable machine learning is rapidly becoming a crucial tool for scientific discovery. Among existing approaches, variational autoencoders (VAEs) have shown promise in extracting the hidden physical features of some input data, with no supervision nor prior knowledge of the system at study. Yet, the ability of VAEs to create meaningful, interpretable representations relies on their accurate approximation of the underlying probability distribution of their input. When dealing with quantum data, VAEs must hence account for its intrinsic randomness and complex correlations. While VAEs have been previously applied to quantum data, they have often neglected its probabilistic nature, hindering the extraction of meaningful physical descriptors. Here, we demonstrate that two key modifications enable VAEs to learn physically meaningful latent representations: a decoder capable of faithfully reproduce quantum states and a probabilistic loss tailored to this task. Using benchmark quantum spin models, we identify regimes where standard methods fail while the representations learned by our approach remain meaningful and interpretable. Applied to experimental data from Rydberg atom arrays, the model autonomously uncovers the phase structure without access to prior labels, Hamiltonian details, or knowledge of relevant order parameters, highlighting its potential as an unsupervised and interpretable tool for the study of quantum systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpretable machine learning is rapidly becoming a crucial tool forscientific discovery. Among existing approaches, variational autoencoders(VAEs) have shown promise in extracting the hidden physical features of someinput data, with no supervision nor prior knowledge of the system at study.Yet, the ability of VAEs to create meaningful, interpretable representationsrelies on their accurate approximation of the underlying probabilitydistribution of their input. When dealing with quantum data, VAEs must henceaccount for its intrinsic randomness and complex correlations. While VAEs havebeen previously applied to quantum data, they have often neglected itsprobabilistic nature, hindering the extraction of meaningful physicaldescriptors. Here, we demonstrate that two key modifications enable VAEs tolearn physically meaningful latent representations: a decoder capable offaithfully reproduce quantum states and a probabilistic loss tailored to thistask. Using benchmark quantum spin models, we identify regimes where standardmethods fail while the representations learned by our approach remainmeaningful and interpretable. Applied to experimental data from Rydberg atomarrays, the model autonomously uncovers the phase structure without access toprior labels, Hamiltonian details, or knowledge of relevant order parameters,highlighting its potential as an unsupervised and interpretable tool for thestudy of quantum systems.</description>
      <author>example@mail.com (Paulin de Schoulepnikoff, Gorka Muñoz-Gil, Hendrik Poulsen Nautrup, Hans J. Briegel)</author>
      <guid isPermaLink="false">2506.11982v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>SemanticST: Spatially Informed Semantic Graph Learning for1 Clustering, Integration, and Scalable Analysis of Spatial2 Transcriptomics</title>
      <link>http://arxiv.org/abs/2506.11491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 Figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SemanticST是一种基于生物信息学和图神经网络的深度学习框架，用于空间转录组学分析，它能够提高数据处理的鲁棒性，并支持大规模数据集的分析。&lt;h4&gt;背景&lt;/h4&gt;空间转录组学技术提供了对组织结构和疾病异质性的空间分辨率基因表达分析，但现有方法在处理噪声数据、可扩展性和细胞关系建模方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出SemanticST，旨在通过多语义图构建来建模多样化的细胞环境，并提高空间转录组学分析的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;SemanticST通过构建多个特定于上下文的图来捕捉空间邻近性、基因表达相似性和组织域结构，并学习每个图的解耦嵌入。使用受注意力启发的策略融合这些嵌入，以获得统一的、具有生物学意义的表示。通过社区感知的min-cut损失提高鲁棒性，并支持mini-batch训练。&lt;h4&gt;主要发现&lt;/h4&gt;在四个平台（Visium、Slide-seq、Stereo-seq、Xenium）和多种人类和小鼠组织中，SemanticST在ARI、NMI和轨迹保真度方面比DeepST、GraphST和IRIS提高了20个百分点的增益。在乳腺癌Xenium数据的重新分析中，SemanticST揭示了罕见的、具有临床意义的亚群，包括三阴性受体簇、空间上不同的DCIS到IDC过渡区域和FOXC2肿瘤相关肌上皮细胞，表明存在非典型EMT程序和干细胞样特征。&lt;h4&gt;结论&lt;/h4&gt;SemanticST提供了一个可扩展的、可解释的且基于生物学的空间转录组学分析框架，能够跨组织类型和疾病进行稳健的发现，为空间解析的组织图谱和下一代精准医学铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;Spatial transcriptomics (ST) technologies enable gene expression profiling with spatial resolution, offering unprecedented insights into tissue organization and disease heterogeneity. However, current analysis methods often struggle with noisy data, limited scalability, and inadequate modelling of complex cellular relationships. We present SemanticST, a biologically informed, graph-based deep learning framework that models diverse cellular contexts through multi-semantic graph construction. SemanticST builds multiple context-specific graphs capturing spatial proximity, gene expression similarity, and tissue domain structure, and learns disentangled embeddings for each. These are fused using an attention-inspired strategy to yield a unified, biologically meaningful representation. A community-aware min-cut loss improves robustness over contrastive learning, particularly in sparse ST data. SemanticST supports mini-batch training, making it the first graph neural network scalable to large-scale datasets such as Xenium (500,000 cells). Benchmarking across four platforms (Visium, Slide-seq, Stereo-seq, Xenium) and multiple human and mouse tissues shows consistent 20 percentage gains in ARI, NMI, and trajectory fidelity over DeepST, GraphST, and IRIS. In re-analysis of breast cancer Xenium data, SemanticST revealed rare and clinically significant niches, including triple receptor-positive clusters, spatially distinct DCIS-to-IDC transition zones, and FOXC2 tumour-associated myoepithelial cells, suggesting non-canonical EMT programs with stem-like features. SemanticST thus provides a scalable, interpretable, and biologically grounded framework for spatial transcriptomics analysis, enabling robust discovery across tissue types and diseases, and paving the way for spatially resolved tissue atlases and next-generation precision medicine.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial transcriptomics (ST) technologies enable gene expression profilingwith spatial resolution, offering unprecedented insights into tissueorganization and disease heterogeneity. However, current analysis methods oftenstruggle with noisy data, limited scalability, and inadequate modelling ofcomplex cellular relationships. We present SemanticST, a biologically informed,graph-based deep learning framework that models diverse cellular contextsthrough multi-semantic graph construction. SemanticST builds multiplecontext-specific graphs capturing spatial proximity, gene expressionsimilarity, and tissue domain structure, and learns disentangled embeddings foreach. These are fused using an attention-inspired strategy to yield a unified,biologically meaningful representation. A community-aware min-cut loss improvesrobustness over contrastive learning, particularly in sparse ST data.SemanticST supports mini-batch training, making it the first graph neuralnetwork scalable to large-scale datasets such as Xenium (500,000 cells).Benchmarking across four platforms (Visium, Slide-seq, Stereo-seq, Xenium) andmultiple human and mouse tissues shows consistent 20 percentage gains in ARI,NMI, and trajectory fidelity over DeepST, GraphST, and IRIS. In re-analysis ofbreast cancer Xenium data, SemanticST revealed rare and clinically significantniches, including triple receptor-positive clusters, spatially distinctDCIS-to-IDC transition zones, and FOXC2 tumour-associated myoepithelial cells,suggesting non-canonical EMT programs with stem-like features. SemanticST thusprovides a scalable, interpretable, and biologically grounded framework forspatial transcriptomics analysis, enabling robust discovery across tissue typesand diseases, and paving the way for spatially resolved tissue atlases andnext-generation precision medicine.</description>
      <author>example@mail.com (Roxana Zahedi, Ahmadreza Argha, Nona Farbehi, Ivan Bakhshayeshi, Youqiong Ye, Nigel H. Lovell, Hamid Alinejad-Rokny)</author>
      <guid isPermaLink="false">2506.11491v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction</title>
      <link>http://arxiv.org/abs/2506.12015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review. Project page: https://hsi-che-lin.github.io/EMLoC/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;EMLoC是一种基于仿真的内存高效微调框架，通过LoRA校正，允许在推理所需内存预算内进行模型微调。&lt;h4&gt;背景&lt;/h4&gt;开源基础模型在多个领域得到广泛应用，但针对特定领域或个性化任务的微调因内存开销过大而成本高昂。&lt;h4&gt;目的&lt;/h4&gt;提出EMLoC框架，以降低微调大型基础模型的成本。&lt;h4&gt;方法&lt;/h4&gt;EMLoC使用激活感知奇异值分解（SVD）在小型下游校准集上构建特定任务的轻量级仿真器。通过LoRA在轻量级仿真器上执行微调。为了解决原始模型与压缩仿真器之间的不匹配，提出了一种新的补偿算法来校正微调的LoRA模块。&lt;h4&gt;主要发现&lt;/h4&gt;EMLoC支持灵活的压缩比和标准训练流程，适用于广泛的应用。实验表明，EMLoC在多个数据集和模态上优于其他基线。此外，EMLoC在单个24GB消费级GPU上实现了对38B模型的微调，无需量化，为个人用户提供了高效实用的模型适应性。&lt;h4&gt;结论&lt;/h4&gt;EMLoC是一种高效且实用的模型微调框架，能够降低成本并提高模型适应性，特别适用于个人用户和资源受限的环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-source foundation models have seen rapid adoption and development,enabling powerful general-purpose capabilities across diverse domains. However,fine-tuning large foundation models for domain-specific or personalized tasksremains prohibitively expensive for most users due to the significant memoryoverhead beyond that of inference. We introduce EMLoC, an Emulator-basedMemory-efficient fine-tuning framework with LoRA Correction, which enablesmodel fine-tuning within the same memory budget required for inference. EMLoCconstructs a task-specific light-weight emulator using activation-awaresingular value decomposition (SVD) on a small downstream calibration set.Fine-tuning then is performed on this lightweight emulator via LoRA. To tacklethe misalignment between the original model and the compressed emulator, wepropose a novel compensation algorithm to correct the fine-tuned LoRA module,which thus can be merged into the original model for inference. EMLoC supportsflexible compression ratios and standard training pipelines, making itadaptable to a wide range of applications. Extensive experiments demonstratethat EMLoC outperforms other baselines across multiple datasets and modalities.Moreover, without quantization, EMLoC enables fine-tuning of a 38B model on asingle 24GB consumer GPU-bringing efficient and practical model adaptation toindividual users.</description>
      <author>example@mail.com (Hsi-Che Lin, Yu-Chu Yu, Kai-Po Chang, Yu-Chiang Frank Wang)</author>
      <guid isPermaLink="false">2506.12015v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised Learning of Echocardiographic Video Representations via Online Cluster Distillation</title>
      <link>http://arxiv.org/abs/2506.11777v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DISCOVR的自监督学习框架，用于心脏超声视频表示学习，并在多个超声心动图数据集上取得了优于现有方法的性能。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在自然图像和视频理解方面取得了重大进展，但在超声心动图等领域仍面临挑战，如细微的解剖结构、复杂的时间动态以及缺乏特定领域预训练模型等问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效处理超声心动图视频表示学习的自监督学习框架。&lt;h4&gt;方法&lt;/h4&gt;DISCOVR结合了基于聚类的视频编码器和在线图像编码器，通过语义簇蒸馏损失将解剖知识从图像编码器传递到视频编码器，从而实现具有精细语义理解的时序一致表示。&lt;h4&gt;主要发现&lt;/h4&gt;DISCOVR在零样本和线性探测设置中优于专门的视频异常检测方法和最先进的视频自监督学习基线，并在分割迁移方面取得了优异的性能。&lt;h4&gt;结论&lt;/h4&gt;DISCOVR是一种有效的自监督学习框架，能够提高超声心动图视频表示学习的性能，为该领域的研究提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised learning (SSL) has achieved major advances in natural images and video understanding, but challenges remain in domains like echocardiography (heart ultrasound) due to subtle anatomical structures, complex temporal dynamics, and the current lack of domain-specific pre-trained models. Existing SSL approaches such as contrastive, masked modeling, and clustering-based methods struggle with high intersample similarity, sensitivity to low PSNR inputs common in ultrasound, or aggressive augmentations that distort clinically relevant features. We present DISCOVR (Distilled Image Supervision for Cross Modal Video Representation), a self-supervised dual branch framework for cardiac ultrasound video representation learning. DISCOVR combines a clustering-based video encoder that models temporal dynamics with an online image encoder that extracts fine-grained spatial semantics. These branches are connected through a semantic cluster distillation loss that transfers anatomical knowledge from the evolving image encoder to the video encoder, enabling temporally coherent representations enriched with fine-grained semantic understanding. Evaluated on six echocardiography datasets spanning fetal, pediatric, and adult populations, DISCOVR outperforms both specialized video anomaly detection methods and state-of-the-art video-SSL baselines in zero-shot and linear probing setups, and achieves superior segmentation transfer.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) has achieved major advances in natural imagesand video understanding, but challenges remain in domains like echocardiography(heart ultrasound) due to subtle anatomical structures, complex temporaldynamics, and the current lack of domain-specific pre-trained models. ExistingSSL approaches such as contrastive, masked modeling, and clustering-basedmethods struggle with high intersample similarity, sensitivity to low PSNRinputs common in ultrasound, or aggressive augmentations that distortclinically relevant features. We present DISCOVR (Distilled Image Supervisionfor Cross Modal Video Representation), a self-supervised dual branch frameworkfor cardiac ultrasound video representation learning. DISCOVR combines aclustering-based video encoder that models temporal dynamics with an onlineimage encoder that extracts fine-grained spatial semantics. These branches areconnected through a semantic cluster distillation loss that transfersanatomical knowledge from the evolving image encoder to the video encoder,enabling temporally coherent representations enriched with fine-grainedsemantic understanding. Evaluated on six echocardiography datasets spanningfetal, pediatric, and adult populations, DISCOVR outperforms both specializedvideo anomaly detection methods and state-of-the-art video-SSL baselines inzero-shot and linear probing setups, and achieves superior segmentationtransfer.</description>
      <author>example@mail.com (Divyanshu Mishra, Mohammadreza Salehi, Pramit Saha, Olga Patey, Aris T. Papageorghiou, Yuki M. Asano, J. Alison Noble)</author>
      <guid isPermaLink="false">2506.11777v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Aligned Novel View Image and Geometry Synthesis via Cross-modal Attention Instillation</title>
      <link>http://arxiv.org/abs/2506.11924v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散的框架，通过变形和修复方法进行对齐的新视角图像和几何生成。&lt;h4&gt;背景&lt;/h4&gt;现有的方法需要密集的姿势图像或限于领域视角的姿势嵌入生成模型。&lt;h4&gt;目的&lt;/h4&gt;开发一种不需要密集姿势图像或限制于领域视角的生成模型的新方法。&lt;h4&gt;方法&lt;/h4&gt;该方法利用现成的几何预测器来预测从参考图像中看到的局部几何，并将新视角合成作为图像和几何的修复任务。同时，提出跨模态注意力蒸馏，在训练和推理过程中将图像扩散分支的注意力图注入到平行的几何扩散分支中。此外，引入基于邻近度的网格条件来整合深度和法线线索，在点云之间进行插值，并过滤掉错误预测的几何形状。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在未见过的场景中实现了高保真的预测性视图合成，在插值设置下提供了具有竞争力的重建质量，并产生了几何对齐的彩色点云，用于全面的3D补全。&lt;h4&gt;结论&lt;/h4&gt;该方法在图像和几何上实现了高质量的合成，为3D补全提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;We introduce a diffusion-based framework that performs aligned novel viewimage and geometry generation via a warping-and-inpainting methodology. Unlike prior methods that require dense posed images or pose-embedded generativemodels limited to in-domain views, our method leverages off-the-shelf geometrypredictors to predict partial geometries viewed from reference images, andformulates novel-view synthesis as an inpainting task for both image andgeometry. To ensure accurate alignment between generated images and geometry,we propose cross-modal attention distillation, where attention maps from theimage diffusion branch are injected into a parallel geometry diffusion branchduring both training and inference. This multi-task approach achievessynergistic effects, facilitating geometrically robust image synthesis as wellas well-defined geometry prediction. We further introduce proximity-based meshconditioning to integrate depth and normal cues, interpolating between pointcloud and filtering erroneously predicted geometry from influencing thegeneration process. Empirically, our method achieves high-fidelity extrapolative view synthesis on both image and geometry across a range ofunseen scenes, delivers competitive reconstruction quality under interpolationsettings, and produces geometrically aligned colored point clouds forcomprehensive 3D completion.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a diffusion-based framework that performs aligned novel viewimage and geometry generation via a warping-and-inpainting methodology. Unlikeprior methods that require dense posed images or pose-embedded generativemodels limited to in-domain views, our method leverages off-the-shelf geometrypredictors to predict partial geometries viewed from reference images, andformulates novel-view synthesis as an inpainting task for both image andgeometry. To ensure accurate alignment between generated images and geometry,we propose cross-modal attention distillation, where attention maps from theimage diffusion branch are injected into a parallel geometry diffusion branchduring both training and inference. This multi-task approach achievessynergistic effects, facilitating geometrically robust image synthesis as wellas well-defined geometry prediction. We further introduce proximity-based meshconditioning to integrate depth and normal cues, interpolating between pointcloud and filtering erroneously predicted geometry from influencing thegeneration process. Empirically, our method achieves high-fidelityextrapolative view synthesis on both image and geometry across a range ofunseen scenes, delivers competitive reconstruction quality under interpolationsettings, and produces geometrically aligned colored point clouds forcomprehensive 3D completion. Project page is available athttps://cvlab-kaist.github.io/MoAI.</description>
      <author>example@mail.com (Min-Seop Kwak, Junho Kim, Sangdoo Yun, Dongyoon Han, Taekyoung Kim, Seungryong Kim, Jin-Hwa Kim)</author>
      <guid isPermaLink="false">2506.11924v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>FocalAD: Local Motion Planning for End-to-End Autonomous Driving</title>
      <link>http://arxiv.org/abs/2506.11419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FocalAD的新型端到端自动驾驶框架，该框架专注于关键局部邻居，通过增强局部运动表示来优化规划。&lt;h4&gt;背景&lt;/h4&gt;在端到端自动驾驶中，运动预测对自主车辆规划至关重要。然而，现有方法通常依赖于全局聚合的运动特征，忽略了规划决策主要受少数局部交互代理的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过关注关键局部邻居来改进规划，提高规划可靠性。&lt;h4&gt;方法&lt;/h4&gt;FocalAD包括两个核心模块：Ego-Local-Agents Interactor (ELAI) 和 Focal-Local-Agents Loss (FLA Loss)。ELAI通过图表示进行自我中心交互，以捕获与局部邻居的运动动力学，增强自我规划和代理运动查询。FLA Loss通过增加决策关键邻近代理的权重，引导模型优先考虑与规划更相关的代理。&lt;h4&gt;主要发现&lt;/h4&gt;FocalAD在open-loop nuScenes数据集和closed-loop Bench2Drive基准上优于现有最先进的方法。特别是在注重鲁棒性的Adv-nuScenes数据集上，FocalAD实现了更大的改进，将平均碰撞率降低了41.9%，与DiffusionDrive相比降低了15.6%，与SparseDrive相比降低了15.6%。&lt;h4&gt;结论&lt;/h4&gt;FocalAD框架通过关注局部邻居和优化局部运动表示，提高了自动驾驶的规划可靠性和安全性。&lt;h4&gt;翻译&lt;/h4&gt;In end-to-end autonomous driving, motion prediction plays a pivotal role in ego-vehicle planning. However, existing methods often rely on globally aggregated motion features, ignoring the fact that planning decisions are primarily influenced by a small number of locally interacting agents. Failing to attend to these critical local interactions can obscure potential risks and undermine planning reliability. In this work, we propose FocalAD, a novel end-to-end autonomous driving framework that focuses on critical local neighbors and refines planning by enhancing local motion representations. Specifically, FocalAD comprises two core modules: the Ego-Local-Agents Interactor (ELAI) and the Focal-Local-Agents Loss (FLA Loss). ELAI conducts a graph-based ego-centric interaction representation that captures motion dynamics with local neighbors to enhance both ego planning and agent motion queries. FLA Loss increases the weights of decision-critical neighboring agents, guiding the model to prioritize those more relevant to planning. Extensive experiments show that FocalAD outperforms existing state-of-the-art methods on the open-loop nuScenes datasets and closed-loop Bench2Drive benchmark. Notably, on the robustness-focused Adv-nuScenes dataset, FocalAD achieves even greater improvements, reducing the average collision rate by 41.9% compared to DiffusionDrive and by 15.6% compared to SparseDrive.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In end-to-end autonomous driving,the motion prediction plays a pivotal rolein ego-vehicle planning. However, existing methods often rely on globallyaggregated motion features, ignoring the fact that planning decisions areprimarily influenced by a small number of locally interacting agents. Failingto attend to these critical local interactions can obscure potential risks andundermine planning reliability. In this work, we propose FocalAD, a novelend-to-end autonomous driving framework that focuses on critical localneighbors and refines planning by enhancing local motion representations.Specifically, FocalAD comprises two core modules: the Ego-Local-AgentsInteractor (ELAI) and the Focal-Local-Agents Loss (FLA Loss). ELAI conducts agraph-based ego-centric interaction representation that captures motiondynamics with local neighbors to enhance both ego planning and agent motionqueries. FLA Loss increases the weights of decision-critical neighboringagents, guiding the model to prioritize those more relevant to planning.Extensive experiments show that FocalAD outperforms existing state-of-the-artmethods on the open-loop nuScenes datasets and closed-loop Bench2Drivebenchmark. Notably, on the robustness-focused Adv-nuScenes dataset, FocalADachieves even greater improvements, reducing the average colilision rate by41.9% compared to DiffusionDrive and by 15.6% compared to SparseDrive.</description>
      <author>example@mail.com (Bin Sun, Boao Zhang, Jiayi Lu, Xinjie Feng, Jiachen Shang, Rui Cao, Mengchao Zheng, Chuanye Wang, Shichun Yang, Yaoguang Cao, Ziying Song)</author>
      <guid isPermaLink="false">2506.11419v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Vision-based Lifting of 2D Object Detections for Automated Driving</title>
      <link>http://arxiv.org/abs/2506.11839v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  https://ieeexplore.ieee.org/document/9190325&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图像的3D物体检测方法，旨在为自动驾驶提供一种成本效益高的替代方案，以相机代替LiDAR。&lt;h4&gt;背景&lt;/h4&gt;基于图像的3D物体检测是自动驾驶不可或缺的一部分，因为大多数现代汽车已经配备了廉价的车载摄像头。由于LiDAR能够提供准确的深度信息，目前大多数最先进的3D物体检测器都依赖于LiDAR数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，将现有基于视觉的2D算法的结果提升到3D检测，仅使用相机作为LiDAR的替代品。&lt;h4&gt;方法&lt;/h4&gt;与现有方法不同，本文不仅关注汽车，还关注所有类型的道路使用者。为了尽可能降低计算工作量，本文首次使用2D卷积神经网络（CNN）处理每个2D检测的点云。&lt;h4&gt;主要发现&lt;/h4&gt;在具有挑战性的KITTI 3D物体检测基准上的评估表明，该方法的结果与最先进的基于图像的方法相当，而运行时间仅为后者的三分之一。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在保持计算效率的同时，实现了与最先进方法相当的性能，为自动驾驶中的3D物体检测提供了一种有前景的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于图像的3D物体检测方法，旨在为自动驾驶提供一种成本效益高的替代方案，以相机代替LiDAR。由于LiDAR能够提供准确的深度信息，目前大多数最先进的3D物体检测器都依赖于LiDAR数据。本文提出的方法不仅关注汽车，还关注所有类型的道路使用者。为了尽可能降低计算工作量，本文首次使用2D卷积神经网络（CNN）处理每个2D检测的点云。在具有挑战性的KITTI 3D物体检测基准上的评估表明，该方法的结果与最先进的基于图像的方法相当，而运行时间仅为后者的三分之一。本文提出的方法在保持计算效率的同时，实现了与最先进方法相当的性能，为自动驾驶中的3D物体检测提供了一种有前景的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.23919/FUSION45008.2020.9190325&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-based 3D object detection is an inevitable part of autonomous drivingbecause cheap onboard cameras are already available in most modern cars.Because of the accurate depth information, currently, most state-of-the-art 3Dobject detectors heavily rely on LiDAR data. In this paper, we propose apipeline which lifts the results of existing vision-based 2D algorithms to 3Ddetections using only cameras as a cost-effective alternative to LiDAR. Incontrast to existing approaches, we focus not only on cars but on all types ofroad users. To the best of our knowledge, we are the first using a 2D CNN toprocess the point cloud for each 2D detection to keep the computational effortas low as possible. Our evaluation on the challenging KITTI 3D object detectionbenchmark shows results comparable to state-of-the-art image-based approacheswhile having a runtime of only a third.</description>
      <author>example@mail.com (Hendrik Königshof, Kun Li, Christoph Stiller)</author>
      <guid isPermaLink="false">2506.11839v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>How Visual Representations Map to Language Feature Space in Multimodal LLMs</title>
      <link>http://arxiv.org/abs/2506.11976v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种方法框架，通过冻结大语言模型（LLM）和视觉Transformer（ViT），并仅在视觉指令调整期间训练线性适配器，来实现视觉和语言表示的对齐。实验结果表明，视觉表示与语言特征表示在中间到后层逐渐对齐，但ViT的输出与LLM早期层之间存在基本不匹配，引发关于当前适配器架构是否优化跨模态表示学习的疑问。&lt;h4&gt;背景&lt;/h4&gt;有效的多模态推理依赖于视觉和语言表示的对齐，但视觉语言模型（VLMs）如何实现这种对齐的机制尚不清楚。&lt;h4&gt;目的&lt;/h4&gt;引入一种方法框架，以实现视觉和语言表示的对齐，并探索VLMs中这种对齐的机制。&lt;h4&gt;方法&lt;/h4&gt;冻结LLM和ViT，仅通过训练线性适配器连接它们。使用预训练的稀疏自编码器（SAEs）作为分析工具，通过分析SAE重建误差、稀疏模式和特征SAE描述来揭示视觉表示与语言特征表示的对齐过程。&lt;h4&gt;主要发现&lt;/h4&gt;视觉表示与语言特征表示在中间到后层逐渐对齐，但ViT的输出与LLM早期层之间存在基本不匹配。&lt;h4&gt;结论&lt;/h4&gt;当前基于适配器的架构可能不是优化跨模态表示学习的最佳选择。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种方法框架，通过故意保持冻结的大语言模型（LLM）和冻结的视觉Transformer（ViT），并通过在视觉指令调整期间仅训练线性适配器来连接它们。这种设计是我们方法的基本原则：通过保持语言模型冻结，我们确保它保持其原始的语言表示，而不会对视觉数据进行适应。因此，线性适配器必须直接将视觉特征映射到LLM的现有表示空间，而不是允许语言模型通过微调发展专门的视觉理解。我们的实验设计独特地使得可以使用预训练的LLM稀疏自编码器（SAEs）作为分析工具。这些SAEs与未更改的语言模型保持完美对齐，并作为学习到的语言特征表示的快照。通过系统地分析SAE重建误差、稀疏模式和特征SAE描述，我们揭示了视觉表示逐渐与语言特征表示对齐的层间进展，并在中间到后层收敛。这表明ViT输出与早期LLM层之间存在基本不匹配，引发了关于当前基于适配器的架构是否优化跨模态表示学习的关键问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective multimodal reasoning depends on the alignment of visual andlinguistic representations, yet the mechanisms by which vision-language models(VLMs) achieve this alignment remain poorly understood. We introduce amethodological framework that deliberately maintains a frozen large languagemodel (LLM) and a frozen vision transformer (ViT), connected solely by traininga linear adapter during visual instruction tuning. This design is fundamentalto our approach: by keeping the language model frozen, we ensure it maintainsits original language representations without adaptation to visual data.Consequently, the linear adapter must map visual features directly into theLLM's existing representational space rather than allowing the language modelto develop specialized visual understanding through fine-tuning. Ourexperimental design uniquely enables the use of pre-trained sparse autoencoders(SAEs) of the LLM as analytical probes. These SAEs remain perfectly alignedwith the unchanged language model and serve as a snapshot of the learnedlanguage feature-representations. Through systematic analysis of SAEreconstruction error, sparsity patterns, and feature SAE descriptions, wereveal the layer-wise progression through which visual representationsgradually align with language feature representations, converging inmiddle-to-later layers. This suggests a fundamental misalignment between ViToutputs and early LLM layers, raising important questions about whether currentadapter-based architectures optimally facilitate cross-modal representationlearning.</description>
      <author>example@mail.com (Constantin Venhoff, Ashkan Khakzar, Sonia Joseph, Philip Torr, Neel Nanda)</author>
      <guid isPermaLink="false">2506.11976v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Coefficient Shape Transfer Learning for Functional Linear Regression</title>
      <link>http://arxiv.org/abs/2506.11367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的迁移学习方法，用于解决功能线性模型中数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;在功能线性模型中，数据稀缺是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种迁移学习方法来解决数据稀缺问题。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了目标模型（目标域）和辅助模型（源域）的样本，将源域中的系数形状知识迁移到目标域。&lt;h4&gt;主要发现&lt;/h4&gt;该方法具有两个关键优势：一是对协变量缩放具有鲁棒性；二是系数形状同质性的概念比传统的系数同质性有更深远的意义，使得方法能够利用更广泛的源域，并显著提高模型估计的准确性。&lt;h4&gt;结论&lt;/h4&gt;该方法的有效性通过全面的模拟研究和应用美国国家健康与营养检查调查的体力活动数据进行的职业时间分析得到了证明。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we develop a novel transfer learning methodology to tackle the challenge of data scarcity in functional linear models. The methodology incorporates samples from the target model (target domain) alongside those from auxiliary models (source domains), transferring knowledge of coefficient shape from the source domains to the target domain. This shape-based knowledge transfer offers two key advantages. First, it is robust to covariate scaling, ensuring effectiveness despite variations in data distributions across different source domains. Second, the notion of coefficient shape homogeneity represents a meaningful advance beyond traditional coefficient homogeneity, allowing the method to exploit a wider range of source domains and achieve significantly improved model estimation. We rigorously analyze the convergence rates of the proposed estimator and examine the minimax optimality. Our findings show that the degree of improvement depends not only on the similarity of coefficient shapes between the target and source domains, but also on coefficient magnitudes and the spectral decay rates of the functional covariates covariance operators. To address situations where only a subset of auxiliary models is informative for the target model, we further develop a data-driven procedure for identifying such informative sources. The effectiveness of the proposed methodology is demonstrated through comprehensive simulation studies and an application to occupation time analysis using physical activity data from the U.S. National Health and Nutrition Examination Survey.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we develop a novel transfer learning methodology to tackle thechallenge of data scarcity in functional linear models. The methodologyincorporates samples from the target model (target domain) alongside those fromauxiliary models (source domains), transferring knowledge of coefficient shapefrom the source domains to the target domain. This shape-based knowledgetransfer offers two key advantages. First, it is robust to covariate scaling,ensuring effectiveness despite variations in data distributions acrossdifferent source domains. Second, the notion of coefficient shape homogeneityrepresents a meaningful advance beyond traditional coefficient homogeneity,allowing the method to exploit a wider range of source domains and achievesignificantly improved model estimation. We rigorously analyze the convergencerates of the proposed estimator and examine the minimax optimality. Ourfindings show that the degree of improvement depends not only on the similarityof coefficient shapes between the target and source domains, but also oncoefficient magnitudes and the spectral decay rates of the functionalcovariates covariance operators. To address situations where only a subset ofauxiliary models is informative for the target model, we further develop adata-driven procedure for identifying such informative sources. Theeffectiveness of the proposed methodology is demonstrated through comprehensivesimulation studies and an application to occupation time analysis usingphysical activity data from the U.S. National Health and Nutrition ExaminationSurvey.</description>
      <author>example@mail.com (Shuhao Jiao, Ian W. Mckeague, N. -H. Chan)</author>
      <guid isPermaLink="false">2506.11367v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>AgriPotential: A Novel Multi-Spectral and Multi-Temporal Remote Sensing Dataset for Agricultural Potentials</title>
      <link>http://arxiv.org/abs/2506.11740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了AgriPotential，一个由多个月Sentinel-2卫星影像组成的创新基准数据集，用于农业潜力预测。&lt;h4&gt;背景&lt;/h4&gt;遥感技术已成为大规模地球监测和土地管理的关键工具。&lt;h4&gt;目的&lt;/h4&gt;AgriPotential旨在提高数据驱动的可持续土地利用规划方法。&lt;h4&gt;方法&lt;/h4&gt;数据集包含对三种主要作物类型（葡萄种植、园艺和农田作物）在不同等级上的像素级标注，支持包括序数回归、多标签分类和时空建模在内的多种机器学习任务。&lt;h4&gt;主要发现&lt;/h4&gt;数据集覆盖了法国南部的多个地区，提供了丰富的光谱信息。&lt;h4&gt;结论&lt;/h4&gt;AgriPotential是第一个专门为农业潜力预测设计的公开数据集。&lt;h4&gt;翻译&lt;/h4&gt;摘要：遥感已成为大规模地球监测和土地管理的关键工具。在本文中，我们介绍了AgriPotential，一个由多个月Sentinel-2卫星影像组成的创新基准数据集。该数据集提供了三种主要作物类型（葡萄种植、园艺和农田作物）在不同等级上的像素级农业潜力标注。AgriPotential支持包括序数回归、多标签分类和时空建模在内的多种机器学习任务。数据覆盖了法国南部的多个地区，提供了丰富的光谱信息。AgriPotential是第一个专门为农业潜力预测设计的公开数据集，旨在提高数据驱动的可持续土地利用规划方法。数据集和代码可在https://zenodo.org/records/15556484免费获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Remote sensing has emerged as a critical tool for large-scale Earthmonitoring and land management. In this paper, we introduce AgriPotential, anovel benchmark dataset composed of Sentinel-2 satellite imagery spanningmultiple months. The dataset provides pixel-level annotations of agriculturalpotentials for three major crop types - viticulture, market gardening, andfield crops - across five ordinal classes. AgriPotential supports a broad rangeof machine learning tasks, including ordinal regression, multi-labelclassification, and spatio-temporal modeling. The data covers diverse areas inSouthern France, offering rich spectral information. AgriPotential is the firstpublic dataset designed specifically for agricultural potential prediction,aiming to improve data-driven approaches to sustainable land use planning. Thedataset and the code are freely accessible at:https://zenodo.org/records/15556484</description>
      <author>example@mail.com (Mohammad El Sakka, Caroline De Pourtales, Lotfi Chaari, Josiane Mothe)</author>
      <guid isPermaLink="false">2506.11740v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty Awareness Enables Efficient Labeling for Cancer Subtyping in Digital Pathology</title>
      <link>http://arxiv.org/abs/2506.11439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种将不确定性感知引入自监督对比学习模型的方法，用于辅助癌症亚型分类，在有限的标注数据下实现了癌症亚型分类的最佳性能。&lt;h4&gt;背景&lt;/h4&gt;机器学习辅助的癌症亚型分类在数字病理学中具有前景，但需要使用专家标注进行仔细训练以确保预测的确定性。&lt;h4&gt;目的&lt;/h4&gt;提出不确定性感知的概念，以改善癌症亚型分类模型的性能，特别是在标注数据有限的情况下。&lt;h4&gt;方法&lt;/h4&gt;通过在每个时代计算证据向量来评估模型预测的置信度，并将不确定性分数作为衡量标准，选择性地标记最关键需要进一步标注的图像，从而迭代地优化训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;使用1-10%的策略性选择的标注，在基准数据集上实现了癌症亚型分类的领先性能。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅策略性地指导标注过程以减少对大量标注数据集的需求，而且提高了分类的精确性和效率，对于标注数据有限的环境特别有益，为数字病理学的未来研究和应用提供了有希望的方向。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces the concept of uncertainty awareness into a self-supervised contrastive learning model for the purpose of assisting in cancer subtyping in digital pathology. The background of this study is that cancer subtyping models require careful training with expert annotations to ensure the certainty of their predictions. The aim of this study is to improve the performance of cancer subtyping models, especially in the context of limited labeled data. The method involves calculating an evidence vector at each epoch to assess the model's confidence in its predictions, and using the derived uncertainty score as a metric to selectively label the most crucial images that require further annotation, thus iteratively refining the training process. With just 1-10% of strategically selected annotations, the method achieves state-of-the-art performance in cancer subtyping on benchmark datasets. The conclusion is that this method not only strategically guides the annotation process to minimize the need for extensive labeled datasets but also improves the precision and efficiency of classifications, which is particularly beneficial in settings where the availability of labeled data is limited, offering a promising direction for future research and application in digital pathology.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learning-assisted cancer subtyping is a promising avenue in digitalpathology. Cancer subtyping models, however, require careful training usingexpert annotations so that they can be inferred with a degree of knowncertainty (or uncertainty). To this end, we introduce the concept ofuncertainty awareness into a self-supervised contrastive learning model. Thisis achieved by computing an evidence vector at every epoch, which assesses themodel's confidence in its predictions. The derived uncertainty score is thenutilized as a metric to selectively label the most crucial images that requirefurther annotation, thus iteratively refining the training process. With just1-10% of strategically selected annotations, we attain state-of-the-artperformance in cancer subtyping on benchmark datasets. Our method not onlystrategically guides the annotation process to minimize the need for extensivelabeled datasets, but also improves the precision and efficiency ofclassifications. This development is particularly beneficial in settings wherethe availability of labeled data is limited, offering a promising direction forfuture research and application in digital pathology.</description>
      <author>example@mail.com (Nirhoshan Sivaroopan, Chamuditha Jayanga Galappaththige, Chalani Ekanayake, Hasindri Watawana, Ranga Rodrigo, Chamira U. S. Edussooriya, Dushan N. Wadduwage)</author>
      <guid isPermaLink="false">2506.11439v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>How do Probabilistic Graphical Models and Graph Neural Networks Look at Network Data?</title>
      <link>http://arxiv.org/abs/2506.11869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了概率图模型（PGMs）和图神经网络（GNNs）在处理网络数据方面的比较，通过解决链接预测任务，对合成和真实网络进行了实验。&lt;h4&gt;背景&lt;/h4&gt;图是表示关系数据的强大数据结构，在描述复杂现实世界系统中被广泛使用。PGMs和GNNs都能利用图结构数据，但它们的内在工作方式不同。&lt;h4&gt;目的&lt;/h4&gt;比较PGMs和GNNs在网络数据中捕获信息的能力。&lt;h4&gt;方法&lt;/h4&gt;通过解决链接预测任务，对合成和真实网络进行实验，包括PGMs和GNNs如何处理输入特征，以及它们对噪声特征和图异质性的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;当输入特征低维或噪声时，GNNs的表现不如PGMs，这在许多现实场景中很常见，例如节点属性可能是标量或噪声。当图异质性增加时，PGMs比GNNs更鲁棒。此外，还比较了两个框架的计算复杂性和可解释性。&lt;h4&gt;结论&lt;/h4&gt;PGMs和GNNs在处理网络数据方面有各自的优势和局限性，具体取决于数据的特征和任务的需求。&lt;h4&gt;翻译&lt;/h4&gt;Graphs are a powerful data structure for representing relational data and are widely used to describe complex real-world systems. Probabilistic Graphical Models (PGMs) and Graph Neural Networks (GNNs) can both leverage graph-structured data, but their inherent functioning is different. The question is how do they compare in capturing the information contained in networked datasets? We address this objective by solving a link prediction task and we conduct three main experiments, on both synthetic and real networks: one focuses on how PGMs and GNNs handle input features, while the other two investigate their robustness to noisy features and increasing heterophily of the graph. PGMs do not necessarily require features on nodes, while GNNs cannot exploit the network edges alone, and the choice of input features matters. We find that GNNs are outperformed by PGMs when input features are low-dimensional or noisy, mimicking many real scenarios where node attributes might be scalar or noisy. Then, we find that PGMs are more robust than GNNs when the heterophily of the graph is increased. Finally, to assess performance beyond prediction tasks, we also compare the two frameworks in terms of their computational complexity and interpretability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs are a powerful data structure for representing relational data and arewidely used to describe complex real-world systems. Probabilistic GraphicalModels (PGMs) and Graph Neural Networks (GNNs) can both leveragegraph-structured data, but their inherent functioning is different. Thequestion is how do they compare in capturing the information contained innetworked datasets? We address this objective by solving a link prediction taskand we conduct three main experiments, on both synthetic and real networks: onefocuses on how PGMs and GNNs handle input features, while the other twoinvestigate their robustness to noisy features and increasing heterophily ofthe graph. PGMs do not necessarily require features on nodes, while GNNs cannotexploit the network edges alone, and the choice of input features matters. Wefind that GNNs are outperformed by PGMs when input features are low-dimensionalor noisy, mimicking many real scenarios where node attributes might be scalaror noisy. Then, we find that PGMs are more robust than GNNs when theheterophily of the graph is increased. Finally, to assess performance beyondprediction tasks, we also compare the two frameworks in terms of theircomputational complexity and interpretability.</description>
      <author>example@mail.com (Michela Lapenna, Caterina De Bacco)</author>
      <guid isPermaLink="false">2506.11869v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Methods for evaluating the resolution of 3D data derived from satellite images</title>
      <link>http://arxiv.org/abs/2506.11876v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文讨论了如何评估3D数据的分辨率，并介绍了基于高分辨率参考机载激光雷达的自动化评估工具和工作流程。&lt;h4&gt;背景&lt;/h4&gt;从卫星图像中获得的3D数据对于需要大范围覆盖或涉及无法通过机载激光雷达或相机访问地点的场景建模应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;测量这种数据的分辨率对于确定任务效用和跟踪改进非常重要。&lt;h4&gt;方法&lt;/h4&gt;论文考虑了评估点云、数字表面模型和3D网格模型的分辨率的方法。&lt;h4&gt;主要发现&lt;/h4&gt;论文描述了3D度量评估工具和工作流程，并展示了使用不同质量数据的结果分析。&lt;h4&gt;结论&lt;/h4&gt;论文提出了用于评估3D数据分辨率的工具和方法，并通过实验验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;The paper discusses methods for evaluating the resolution of 3D data and introduces automated evaluation tools and workflows based on high-resolution reference airborne lidar. The background is that 3D data derived from satellite images is essential for scene modeling applications requiring large-scale coverage or involving locations not accessible by airborne lidar or cameras. The purpose is to measure the resolution of this data, which is important for determining mission utility and tracking improvements. The methods considered in the paper are to evaluate the resolution of point clouds, digital surface models, and 3D mesh models. The main findings are that 3D metric evaluation tools and workflows are described, and the results of analyses with data of varying quality are presented. The conclusion is that tools and methods for evaluating the resolution of 3D data have been proposed and verified by experiments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D data derived from satellite images is essential for scene modelingapplications requiring large-scale coverage or involving locations notaccessible by airborne lidar or cameras. Measuring the resolution of this datais important for determining mission utility and tracking improvements. In thiswork, we consider methods to evaluate the resolution of point clouds, digitalsurface models, and 3D mesh models. We describe 3D metric evaluation tools andworkflows that enable automated evaluation based on high-resolution referenceairborne lidar, and we present results of analyses with data of varyingquality.</description>
      <author>example@mail.com (Christina Selby, Holden Bindl, Tyler Feldman, Andrew Skow, Nicolas Norena Acosta, Shea Hagstrom, Myron Brown)</author>
      <guid isPermaLink="false">2506.11876v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs</title>
      <link>http://arxiv.org/abs/2506.11558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为DaMO的数据高效视频语言模型，用于提高视频语言理解中的时间推理能力。&lt;h4&gt;背景&lt;/h4&gt;尽管大语言模型（LLMs）已扩展到视频领域，但现有的视频语言模型（VideoLLMs）在细粒度时间推理方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;设计DaMO模型以实现准确的时间推理和多模态理解。&lt;h4&gt;方法&lt;/h4&gt;DaMO的核心是时间感知的Fuseformer，采用分层双流架构，逐步捕捉每个模态中的时间动态，并有效地融合互补的视觉和音频信息。为了提高计算效率，DaMO集成了全局残差，减少空间冗余的同时保留关键语义细节。通过结构化的四阶段渐进式训练方法训练DaMO，逐步赋予模型多模态对齐、语义接地和时间推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;在时间接地和视频问答基准测试中，DaMO在需要精确时间对齐和推理的任务上优于先前的方法。&lt;h4&gt;结论&lt;/h4&gt;DaMO为数据高效的视频语言建模指出了一个有前景的方向。&lt;h4&gt;翻译&lt;/h4&gt;Large Language Models (LLMs) have recently been extended to the video domain,enabling sophisticated video-language understanding. However, existing VideoLLMs often exhibit limitations in fine-grained temporal reasoning, restrictingtheir ability to precisely attribute responses to specific video moments,especially under constrained supervision. We introduce DaMO, a data-efficientVideo LLM explicitly designed for accurate temporal reasoning and multimodalunderstanding. At its core, the proposed Temporal-aware Fuseformer employs ahierarchical dual-stream architecture that progressively captures temporaldynamics within each modality and effectively fuses complementary visual andaudio information. To further enhance computational efficiency, DaMO integratesa global residual that reduces spatial redundancy while preserving essentialsemantic details. We train DaMO via a structured four-stage progressivetraining paradigm, incrementally equipping the model with multimodal alignment,semantic grounding, and temporal reasoning capabilities. This work alsocontributes multiple datasets augmented from existing ones with GPT-generatedtemporally grounded QA pairs for tasks requiring temporal supervision.Comprehensive experiments on temporal grounding and video QA benchmarksdemonstrate that DaMO consistently surpasses prior methods, particularly intasks demanding precise temporal alignment and reasoning. Our work establishesa promising direction for data-efficient video-language modeling.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have recently been extended to the video domain,enabling sophisticated video-language understanding. However, existing VideoLLMs often exhibit limitations in fine-grained temporal reasoning, restrictingtheir ability to precisely attribute responses to specific video moments,especially under constrained supervision. We introduce DaMO, a data-efficientVideo LLM explicitly designed for accurate temporal reasoning and multimodalunderstanding. At its core, the proposed Temporal-aware Fuseformer employs ahierarchical dual-stream architecture that progressively captures temporaldynamics within each modality and effectively fuses complementary visual andaudio information. To further enhance computational efficiency, DaMO integratesa global residual that reduces spatial redundancy while preserving essentialsemantic details. We train DaMO via a structured four-stage progressivetraining paradigm, incrementally equipping the model with multimodal alignment,semantic grounding, and temporal reasoning capabilities. This work alsocontributes multiple datasets augmented from existing ones with GPT-generatedtemporally grounded QA pairs for tasks requiring temporal supervision.Comprehensive experiments on temporal grounding and video QA benchmarksdemonstrate that DaMO consistently surpasses prior methods, particularly intasks demanding precise temporal alignment and reasoning. Our work establishesa promising direction for data-efficient video-language modeling.</description>
      <author>example@mail.com (Bo-Cheng Chiu, Jen-Jee Chen, Yu-Chee Tseng, Feng-Chi Chen)</author>
      <guid isPermaLink="false">2506.11558v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Improving Large Language Model Safety with Contrastive Representation Learning</title>
      <link>http://arxiv.org/abs/2506.11938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对大型语言模型（LLMs）的防御框架，通过对比表征学习（CRL）方法增强模型对对抗攻击的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型具有深远的社会影响，但它们对多样化且未受控制的输入的响应能力使其容易受到对抗攻击的攻击。&lt;h4&gt;目的&lt;/h4&gt;提出一种防御框架，以增强LLMs对对抗攻击的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;将模型防御问题表述为对比表征学习问题，通过使用基于三元组的损失函数和对抗硬负样本挖掘来微调模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法优于先前的基于表征工程的防御方法，在不影响标准性能的情况下，提高了模型对输入级别和嵌入空间攻击的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的防御框架为提高LLMs对对抗攻击的鲁棒性提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大型语言模型（LLMs）是具有深远社会影响的强大工具，然而它们对多样化且未受控制的输入生成响应的能力使它们容易受到对抗攻击。尽管现有的防御方法在应对不同攻击类型时往往难以泛化，但最近在表征工程方面的进步提供了有希望的替代方案。在这项工作中，我们提出了一种将模型防御问题表述为对比表征学习（CRL）问题的防御框架。我们的方法通过结合基于三元组的损失函数和对抗硬负样本挖掘来微调模型。我们在多个模型上的实验结果表明，我们的方法优于先前的基于表征工程的防御方法，在不损害标准性能的情况下，提高了对输入级别和嵌入空间攻击的鲁棒性。我们的代码可在https://github.com/samuelsimko/crl-llm-defense上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) are powerful tools with profound societalimpacts, yet their ability to generate responses to diverse and uncontrolledinputs leaves them vulnerable to adversarial attacks. While existing defensesoften struggle to generalize across varying attack types, recent advancementsin representation engineering offer promising alternatives. In this work, wepropose a defense framework that formulates model defense as a contrastiverepresentation learning (CRL) problem. Our method finetunes a model using atriplet-based loss combined with adversarial hard negative mining to encourageseparation between benign and harmful representations. Our experimental resultsacross multiple models demonstrate that our approach outperforms priorrepresentation engineering-based defenses, improving robustness against bothinput-level and embedding-space attacks without compromising standardperformance. Our code is available athttps://github.com/samuelsimko/crl-llm-defense</description>
      <author>example@mail.com (Samuel Simko, Mrinmaya Sachan, Bernhard Schölkopf, Zhijing Jin)</author>
      <guid isPermaLink="false">2506.11938v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Many-Body Neural Network Wavefunction for a Non-Hermitian Ising Chain</title>
      <link>http://arxiv.org/abs/2506.11222v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用神经网络方法来研究非厄米量子系统的基态性质，特别是对于具有复杂谱的量子光学材料。&lt;h4&gt;背景&lt;/h4&gt;非厄米量子系统在描述开放量子系统、非平衡动力学和工程量子光学材料方面具有重要意义。然而，由于希尔伯特空间的指数级扩展和异常点的出现，求解非厄米系统的基态性质具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;研究使用不同的神经网络架构来探究具有复杂谱的对称性时间、一维非厄米横向场伊辛模型的基态性质。&lt;h4&gt;方法&lt;/h4&gt;采用循环神经网络（RNN）、受限玻尔兹曼机（RBM）和多层感知器（MLP）等不同的神经网络架构，构建基于神经网络的多体波函数，并通过恢复小系统尺寸下模型的基态性质来验证方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;对于小系统尺寸，神经网络方法与精确对角化（ED）方法的结果吻合良好。对于较大系统尺寸，RNN的表现优于RBM和MLP。通过迁移学习，RBM和MLP的准确性可以显著提高，使得它们在较大系统尺寸下的表现与RNN相当。&lt;h4&gt;结论&lt;/h4&gt;神经网络方法在准确捕捉非厄米量子系统的低能物理方面具有潜力，特别是在研究具有复杂谱的量子光学材料时。&lt;h4&gt;翻译&lt;/h4&gt;摘要：非厄米（NH）量子系统已成为描述开放量子系统、非平衡动力学和工程量子光学材料的有力框架。然而，由于希尔伯特空间的指数级扩展和异常点的出现，求解非厄米系统的基态性质具有挑战性。另一个挑战来自传统方法（如精确对角化）的限制。在过去十年中，神经网络（NN）在近似多体波函数方面显示出希望，但它们在非厄米系统中的应用仍然在很大程度上未被探索。在本文中，我们通过采用循环神经网络（RNN）、受限玻尔兹曼机（RBM）和多层感知器（MLP）等不同的神经网络架构，研究了具有复杂谱的对称性时间、一维非厄米横向场伊辛模型的基态性质。我们构建了基于神经网络的多体波函数，并通过恢复小系统尺寸下模型的基态性质来验证我们的方法，发现与精确对角化方法结果吻合良好。此外，对于较大系统尺寸，我们证明了RNN的表现优于RBM和MLP。然而，我们表明通过迁移学习，RBM和MLP的准确性可以显著提高，使得它们在较大系统尺寸下的表现与RNN相当。这些结果突出了基于神经网络方法——尤其是对于准确捕捉非厄米量子系统的低能物理——的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Non-Hermitian (NH) quantum systems have emerged as a powerful framework fordescribing open quantum systems, non-equilibrium dynamics, and engineeredquantum optical materials. However, solving the ground-state properties of NHsystems is challenging due to the exponential scaling of the Hilbert space, andexotic phenomena such as the emergence of exceptional points. Another challengearises from the limitations of traditional methods like exact diagonalization(ED). For the past decade, neural networks (NN) have shown promise inapproximating many-body wavefunctions, yet their application to NH systemsremains largely unexplored. In this paper, we explore different NNarchitectures to investigate the ground-state properties of aparity-time-symmetric, one-dimensional NH, transverse field Ising model with acomplex spectrum by employing a recurrent neural network (RNN), a restrictedBoltzmann machine (RBM), and a multilayer perceptron (MLP). We construct theNN-based many-body wavefunctions and validate our approach by recovering theground-state properties of the model for small system sizes, finding excellentagreement with ED. Furthermore, for larger system sizes, we demonstrate thatthe RNN outperforms both the RBM and MLP. However, we show that the accuracy ofthe RBM and MLP can be significantly improved through transfer learning,allowing them to perform comparably to the RNN for larger system sizes. Theseresults highlight the potential of neural network-basedapproaches--particularly for accurately capturing the low-energy physics of NHquantum systems.</description>
      <author>example@mail.com (Lavoisier Wah, Remmy Zen, Flore K. Kunst)</author>
      <guid isPermaLink="false">2506.11222v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Teleoperated Driving: a New Challenge for 3D Object Detection in Compressed Point Clouds</title>
      <link>http://arxiv.org/abs/2506.11804v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Transactions on Intelligent Transportation Systems&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，互联设备在多个领域得到发展，从娱乐到教育和工业应用。这种趋势由于传感器数量的增加和访问强大硬件和软件的便利性而加速。其中，远程操控驾驶（TD）领域显著受益。本研究从点云数据中检测车辆和行人的存在，以实现安全的TD操作。&lt;h4&gt;背景&lt;/h4&gt;互联设备的发展在多个领域得到扩展，传感器数量的增加和访问强大硬件和软件的便利性推动了这一趋势。&lt;h4&gt;目的&lt;/h4&gt;检测点云数据中的车辆和行人存在，以支持安全的TD操作。&lt;h4&gt;方法&lt;/h4&gt;本研究使用SELMA数据集，这是一个多模式、开源的自动驾驶合成数据集，我们通过包含3D对象的边界框来扩展该数据集以支持对象检测。分析了最先进压缩算法和对象检测器在不同指标下的性能，包括压缩效率、压缩/解压缩和推理时间，以及检测精度。此外，还测量了压缩和检测对V2X网络的影响，包括数据率和延迟，与3GPP对TD应用的要求相比较。&lt;h4&gt;主要发现&lt;/h4&gt;分析了压缩算法和对象检测器的性能，并测量了压缩和检测对V2X网络的影响。&lt;h4&gt;结论&lt;/h4&gt;通过使用SELMA数据集和先进的算法，实现了对车辆和行人的有效检测，支持了安全的TD操作。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, the development of interconnected devices has expanded in many fields, from infotainment to education and industrial applications. This trend has been accelerated by the increased number of sensors and accessibility to powerful hardware and software. One area that significantly benefits from these advancements is Teleoperated Driving (TD). In this scenario, a controller drives safely a vehicle from remote leveraging sensors data generated onboard the vehicle, and exchanged via Vehicle-to-Everything (V2X) communications. In this work, we tackle the problem of detecting the presence of cars and pedestrians from point cloud data to enable safe TD operations. More specifically, we exploit the SELMA dataset, a multimodal, open-source, synthetic dataset for autonomous driving, that we expanded by including the ground-truth bounding boxes of 3D objects to support object detection. We analyze the performance of state-of-the-art compression algorithms and object detectors under several metrics, including compression efficiency, (de)compression and inference time, and detection accuracy. Moreover, we measure the impact of compression and detection on the V2X network in terms of data rate and latency with respect to 3GPP requirements for TD applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, the development of interconnected devices has expanded inmany fields, from infotainment to education and industrial applications. Thistrend has been accelerated by the increased number of sensors and accessibilityto powerful hardware and software. One area that significantly benefits fromthese advancements is Teleoperated Driving (TD). In this scenario, a controllerdrives safely a vehicle from remote leveraging sensors data generated onboardthe vehicle, and exchanged via Vehicle-to-Everything (V2X) communications. Inthis work, we tackle the problem of detecting the presence of cars andpedestrians from point cloud data to enable safe TD operations. Morespecifically, we exploit the SELMA dataset, a multimodal, open-source,synthetic dataset for autonomous driving, that we expanded by including theground-truth bounding boxes of 3D objects to support object detection. Weanalyze the performance of state-of-the-art compression algorithms and objectdetectors under several metrics, including compression efficiency,(de)compression and inference time, and detection accuracy. Moreover, wemeasure the impact of compression and detection on the V2X network in terms ofdata rate and latency with respect to 3GPP requirements for TD applications.</description>
      <author>example@mail.com (Filippo Bragato, Michael Neri, Paolo Testolina, Marco Giordani, Federica Battisti)</author>
      <guid isPermaLink="false">2506.11804v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Taxonomy of reduction matrices for Graph Coarsening</title>
      <link>http://arxiv.org/abs/2506.11743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了图粗化在图信号处理和机器学习中的应用，提出了一种更通用的降维矩阵概念，并通过修改降维矩阵来减少限制谱近似（RSA）损失。&lt;h4&gt;背景&lt;/h4&gt;图粗化通过降维矩阵和提升矩阵将图信号从原始图投影到粗化图，再返回，但这个过程会损失信息。&lt;h4&gt;目的&lt;/h4&gt;减少图粗化过程中的信息损失，引入更通用的降维矩阵概念，并研究其性质。&lt;h4&gt;方法&lt;/h4&gt;提出了新的降维矩阵概念，并建立了“可接受”的降维矩阵家族分类，讨论了这些矩阵必须满足的性质以及是否具有封闭形式的描述。&lt;h4&gt;主要发现&lt;/h4&gt;发现仅对提升矩阵施加约束可以确保重要的对象如粗化图的邻接矩阵或拉普拉斯矩阵的存在，并通过修改降维矩阵可以进一步减少RSA。&lt;h4&gt;结论&lt;/h4&gt;通过修改降维矩阵，可以在固定提升矩阵的粗化过程中减少RSA损失，并展示了这种选择对粗化图上的节点分类任务的影响。&lt;h4&gt;翻译&lt;/h4&gt;Graph coarsening aims to diminish the size of a graph to lighten its memory footprint, and has numerous applications in graph signal processing and machine learning. It is usually defined using a reduction matrix and a lifting matrix, which, respectively, allows to project a graph signal from the original graph to the coarsened one and back. This results in a loss of information measured by the so-called Restricted Spectral Approximation (RSA). Most coarsening frameworks impose a fixed relationship between the reduction and lifting matrices, generally as pseudo-inverses of each other, and seek to define a coarsening that minimizes the RSA. In this paper, we remark that the roles of these two matrices are not entirely symmetric: indeed, putting constraints on the lifting matrix alone ensures the existence of important objects such as the coarsened graph's adjacency matrix or Laplacian. In light of this, in this paper, we introduce a more general notion of reduction matrix, that is not necessarily the pseudo-inverse of the lifting matrix. We establish a taxonomy of 'admissible' families of reduction matrices, discuss the different properties that they must satisfy and whether they admit a closed-form description or not. We show that, for a fixed coarsening represented by a fixed lifting matrix, the RSA can be further reduced simply by modifying the reduction matrix. We explore different examples, including some based on a constrained optimization process of the RSA. Since this criterion has also been linked to the performance of Graph Neural Networks, we also illustrate the impact of this choice on different node classification tasks on coarsened graphs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph coarsening aims to diminish the size of a graph to lighten its memoryfootprint, and has numerous applications in graph signal processing and machinelearning. It is usually defined using a reduction matrix and a lifting matrix,which, respectively, allows to project a graph signal from the original graphto the coarsened one and back. This results in a loss of information measuredby the so-called Restricted Spectral Approximation (RSA). Most coarseningframeworks impose a fixed relationship between the reduction and liftingmatrices, generally as pseudo-inverses of each other, and seek to define acoarsening that minimizes the RSA. In this paper, we remark that the roles ofthese two matrices are not entirely symmetric: indeed, putting constraints onthe lifting matrix alone ensures the existence of important objects such as thecoarsened graph's adjacency matrix or Laplacian. In light of this, in thispaper, we introduce a more general notion of reduction matrix, that is notnecessarily the pseudo-inverse of the lifting matrix. We establish a taxonomyof ``admissible'' families of reduction matrices, discuss the differentproperties that they must satisfy and whether they admit a closed-formdescription or not. We show that, for a fixed coarsening represented by a fixedlifting matrix, the RSA can be further reduced simply by modifying thereduction matrix. We explore different examples, including some based on aconstrained optimization process of the RSA. Since this criterion has also beenlinked to the performance of Graph Neural Networks, we also illustrate theimpact of this choices on different node classification tasks on coarsenedgraphs.</description>
      <author>example@mail.com (Antonin Joly, Nicolas Keriven, Aline Roumy)</author>
      <guid isPermaLink="false">2506.11743v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Your Ride, Your Rules: Psychology and Cognition Enabled Automated Driving Systems</title>
      <link>http://arxiv.org/abs/2506.11842v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 figures,29 pages, one colummn&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PACE-ADS的自动驾驶系统，旨在提升自动驾驶车辆与乘客的交互，提高舒适度和信任度，以促进自动驾驶技术的普及。&lt;h4&gt;背景&lt;/h4&gt;尽管自动驾驶技术发展迅速，但现有自动驾驶车辆与乘客之间的双向通信效果不佳，这限制了个性化服务和从故障中恢复的能力，从而降低了舒适度和信任度。&lt;h4&gt;目的&lt;/h4&gt;提出PACE-ADS框架，通过感知、解释和响应外部交通和内部乘客状态，实现以人为中心的自动驾驶。&lt;h4&gt;方法&lt;/h4&gt;PACE-ADS包含三个基于基础模型的智能体：驾驶员智能体分析驾驶环境，心理学家智能体解释乘客的心理信号和认知命令，协调者智能体整合这些输入以产生高级行为决策和操作参数。&lt;h4&gt;主要发现&lt;/h4&gt;PACE-ADS在模拟测试中表现良好，能够根据乘客状态调整驾驶风格，提高乘坐舒适度，并通过自主推理或人工引导安全地从故障中恢复。&lt;h4&gt;结论&lt;/h4&gt;PACE-ADS展示了基于语言模型（LLM）的框架在连接机器自主性和以人为本的驾驶之间的潜力。&lt;h4&gt;翻译&lt;/h4&gt;尽管自动驾驶技术取得了快速发展，但当前自动驾驶汽车（AV）与乘客之间的双向通信效果不佳，这限制了个性化服务和从停驶状态中恢复的能力，从而降低了舒适度和信任度。我们提出了PACE-ADS（心理学和认知赋能的自动驾驶系统），这是一个以人为本的自动驾驶框架，它使自动驾驶汽车能够感知、解释和响应外部交通和内部乘客状态。PACE-ADS由三个基于基础模型的智能体组成：驾驶员智能体分析驾驶环境，心理学家智能体解释乘客的心理信号（例如，脑电图、心率、面部表情）和认知命令（例如，语音），协调者智能体整合这些输入以产生高级行为决策和操作参数。PACE-ADS不是取代现有的AV模块，而是在行为级别上与之互补，将低级控制委托给本机AV系统。这种分离实现了闭环适应，并支持跨不同平台的集成。我们在涉及交通信号灯、行人、工作区和跟车等多种场景的模拟中评估了PACE-ADS。结果表明，PACE-ADS能够根据乘客状态调整驾驶风格，提高乘坐舒适度，并通过自主推理或人工引导安全地从停驶状态中恢复。我们的发现突显了基于语言模型（LLM）的框架在连接机器自主性和以人为本的驾驶之间的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite rapid advances in autonomous driving, current autonomous vehicles(AVs) lack effective bidirectional communication with occupants, limitingpersonalization and recovery from immobilization. This reduces comfort andtrust, potentially slowing broader AV adoption. We propose PACE-ADS (Psychologyand Cognition Enabled Automated Driving Systems), a human-centered autonomyframework that enables AVs to sense, interpret, and respond to both externaltraffic and internal occupant states. PACE-ADS comprises three foundationmodel-based agents: a Driver Agent that analyzes the driving context, aPsychologist Agent that interprets occupant psychological signals (e.g., EEG,heart rate, facial expressions) and cognitive commands (e.g., speech), and aCoordinator Agent that integrates these inputs to produce high-level behaviordecisions and operational parameters. Rather than replacing existing AVmodules, PACE-ADS complements them by operating at the behavioral level,delegating low-level control to native AV systems. This separation enablesclosed-loop adaptation and supports integration across diverse platforms. Weevaluate PACE-ADS in simulation across varied scenarios involving trafficlights, pedestrians, work zones, and car following. Results show that PACE-ADSadapts driving styles to occupant states, improves ride comfort, and enablessafe recovery from immobilization via autonomous reasoning or human guidance.Our findings highlight the promise of LLM-based frameworks for bridging the gapbetween machine autonomy and human-centered driving.</description>
      <author>example@mail.com (Zhipeng Bao, Qianwen Li)</author>
      <guid isPermaLink="false">2506.11842v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>PiPViT: Patch-based Visual Interpretable Prototypes for Retinal Image Analysis</title>
      <link>http://arxiv.org/abs/2506.10669v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉可解释原型模型PiPViT，用于图像识别，旨在提高原型方法的可解释性，并在医疗成像中实现生物标志物和病变的精确定位。&lt;h4&gt;背景&lt;/h4&gt;原型方法通过学习细粒度部分原型来提高可解释性，但其输入像素空间的可视化并不总是与人类可理解的生物标志物一致。&lt;h4&gt;目的&lt;/h4&gt;提出PiPViT模型，以解决原型方法在医疗成像中可解释性差的问题，并实现生物标志物和病变的精确定位。&lt;h4&gt;方法&lt;/h4&gt;PiPViT利用视觉Transformer（ViT）捕获图像块之间的长距离依赖关系，学习鲁棒且可解释的原型，仅使用图像级标签来近似病变范围。此外，PiPViT还受益于对比学习和多分辨率输入处理，从而在各个尺度上实现生物标志物的有效定位。&lt;h4&gt;主要发现&lt;/h4&gt;在四个数据集上对PiPViT进行评估，其与现有最先进方法相比，在定量性能上具有竞争力，同时提供了更有意义的解释。在保留测试集上的定量评估确认了学习到的原型在语义和临床上的相关性。&lt;h4&gt;结论&lt;/h4&gt;PiPViT可以透明地解释其决策，并帮助临床医生理解诊断结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：背景和目标：基于原型的学习方法通过学习细粒度部分原型来提高可解释性；然而，它们在输入像素空间中的可视化并不总是与人类可理解的生物标志物一致。此外，众所周知的基于原型的方法通常学习非常细粒度的原型，这在医学成像中可解释性较差，因为生物标志物和病变的存在和范围都至关重要。方法：为了解决这些挑战，我们提出了PiPViT（基于补丁的可视化可解释原型），这是一种本质上可解释的原型模型，用于图像识别。利用视觉Transformer（ViT），PiPViT捕获图像块之间的长距离依赖关系，以学习鲁棒、可解释的原型，仅使用图像级标签来近似病变范围。此外，PiPViT受益于对比学习和多分辨率输入处理，这有助于在各个尺度上实现生物标志物的有效定位。结果：我们在四个数据集上对PiPViT进行了视网膜OCT图像分类的评估，与最先进的方法相比，它在定量性能上具有竞争力，同时提供了更有意义的解释。此外，在保留测试集上的定量评估确认了学习到的原型在语义和临床上的相关性。我们相信PiPViT可以透明地解释其决策，并帮助临床医生理解诊断结果。GitHub页面：https://github.com/marziehoghbaie/PiPViT&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Background and Objective: Prototype-based methods improve interpretability bylearning fine-grained part-prototypes; however, their visualization in theinput pixel space is not always consistent with human-understandablebiomarkers. In addition, well-known prototype-based approaches typically learnextremely granular prototypes that are less interpretable in medical imaging,where both the presence and extent of biomarkers and lesions are critical.  Methods: To address these challenges, we propose PiPViT (Patch-based VisualInterpretable Prototypes), an inherently interpretable prototypical model forimage recognition. Leveraging a vision transformer (ViT), PiPViT captureslong-range dependencies among patches to learn robust, human-interpretableprototypes that approximate lesion extent only using image-level labels.Additionally, PiPViT benefits from contrastive learning and multi-resolutioninput processing, which enables effective localization of biomarkers acrossscales.  Results: We evaluated PiPViT on retinal OCT image classification across fourdatasets, where it achieved competitive quantitative performance compared tostate-of-the-art methods while delivering more meaningful explanations.Moreover, quantitative evaluation on a hold-out test set confirms that thelearned prototypes are semantically and clinically relevant. We believe PiPViTcan transparently explain its decisions and assist clinicians in understandingdiagnostic outcomes. Github page: https://github.com/marziehoghbaie/PiPViT</description>
      <author>example@mail.com (Marzieh Oghbaie, Teresa Araújo, Hrvoje Bogunović)</author>
      <guid isPermaLink="false">2506.10669v2</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>SemanticSplat: Feed-Forward 3D Scene Understanding with Language-Aware Gaussian Fields</title>
      <link>http://arxiv.org/abs/2506.09565v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SemanticSplat的前馈语义感知3D重建方法，用于解决现有3D场景理解方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有的3D场景理解方法如LSM，只能从场景中提取基于语言的语义，无法实现整体场景理解，同时几何重建质量低，存在噪声。&lt;h4&gt;目的&lt;/h4&gt;提出SemanticSplat方法，旨在通过统一3D高斯和潜在语义属性，实现几何、外观和语义的联合建模。&lt;h4&gt;方法&lt;/h4&gt;SemanticSplat融合了多种特征场（如LSeg、SAM）和成本体积表示，用于预测语义各向异性高斯，并通过两阶段蒸馏框架从稀疏视角图像中重建整体多模态语义特征场。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在可提示和开放词汇分割等3D场景理解任务中表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;SemanticSplat方法为3D场景理解提供了新的解决方案，并可通过访问https://semanticsplat.github.io查看视频结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Holistic 3D scene understanding, which jointly models geometry, appearance,and semantics, is crucial for applications like augmented reality and roboticinteraction. Existing feed-forward 3D scene understanding methods (e.g., LSM)are limited to extracting language-based semantics from scenes, failing toachieve holistic scene comprehension. Additionally, they suffer fromlow-quality geometry reconstruction and noisy artifacts. In contrast, per-sceneoptimization methods rely on dense input views, which reduces practicality andincreases complexity during deployment. In this paper, we proposeSemanticSplat, a feed-forward semantic-aware 3D reconstruction method, whichunifies 3D Gaussians with latent semantic attributes for jointgeometry-appearance-semantics modeling. To predict the semantic anisotropicGaussians, SemanticSplat fuses diverse feature fields (e.g., LSeg, SAM) with acost volume representation that stores cross-view feature similarities,enhancing coherent and accurate scene comprehension. Leveraging a two-stagedistillation framework, SemanticSplat reconstructs a holistic multi-modalsemantic feature field from sparse-view images. Experiments demonstrate theeffectiveness of our method for 3D scene understanding tasks like promptableand open-vocabulary segmentation. Video results are available athttps://semanticsplat.github.io.</description>
      <author>example@mail.com (Qijing Li, Jingxiang Sun, Liang An, Zhaoqi Su, Hongwen Zhang, Yebin Liu)</author>
      <guid isPermaLink="false">2506.09565v2</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>PromptTSS: A Prompting-Based Approach for Interactive Multi-Granularity Time Series Segmentation</title>
      <link>http://arxiv.org/abs/2506.11170v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is currently under review. The code will be made available  upon acceptance&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PromptTSS的新框架，用于多粒度时间序列数据的分割，以解决现有方法在处理多粒度状态和适应动态环境时的挑战。&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列数据在制造和可穿戴技术等领域广泛存在，这些数据在不同粒度级别上表现出不同的状态，从粗粒度的系统行为到细粒度的详细事件。有效分割和整合这些不同粒度的状态对于预测维护和性能优化等任务至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有时间序列分割方法面临的挑战，即无法在统一模型中处理多粒度状态以及对新动态环境的适应性有限，提出了PromptTSS框架。&lt;h4&gt;方法&lt;/h4&gt;PromptTSS使用一个具有提示机制的统一模型，该机制利用标签和边界信息来引导分割，同时捕捉粗粒度和细粒度模式，并动态适应未见的模式。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，PromptTSS在多粒度分割中的准确率提高了24.49%，在单粒度分割中提高了17.88%，在迁移学习中提高了高达599.24%，证明了其对分层状态和动态时间序列动态的适应性。&lt;h4&gt;结论&lt;/h4&gt;PromptTSS框架能够有效提高时间序列分割的准确率，并适应不同粒度和动态环境的变化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate time series data, collected across various fields such asmanufacturing and wearable technology, exhibit states at multiple levels ofgranularity, from coarse-grained system behaviors to fine-grained, detailedevents. Effectively segmenting and integrating states across these differentgranularities is crucial for tasks like predictive maintenance and performanceoptimization. However, existing time series segmentation methods face two keychallenges: (1) the inability to handle multiple levels of granularity within aunified model, and (2) limited adaptability to new, evolving patterns indynamic environments. To address these challenges, we propose PromptTSS, anovel framework for time series segmentation with multi-granularity states.PromptTSS uses a unified model with a prompting mechanism that leverages labeland boundary information to guide segmentation, capturing both coarse- andfine-grained patterns while adapting dynamically to unseen patterns.Experiments show PromptTSS improves accuracy by 24.49% in multi-granularitysegmentation, 17.88% in single-granularity segmentation, and up to 599.24% intransfer learning, demonstrating its adaptability to hierarchical states andevolving time series dynamics.</description>
      <author>example@mail.com (Ching Chang, Ming-Chih Lo, Wen-Chih Peng, Tien-Fu Chen)</author>
      <guid isPermaLink="false">2506.11170v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Relational GNNs Cannot Learn $C_2$ Features for Planning</title>
      <link>http://arxiv.org/abs/2506.11721v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;R-GNNs是一种基于GNN的学习值函数的方法，能够在给定的规划领域推广到未见问题。R-GNNs的理论动机源于GNN表达能力与一阶逻辑$C_2$（具有两个变量的计数一阶逻辑）之间的联系。在规划背景下，$C_2$特征指的是由规划域的单元和二元谓词定义的关系的$C_2$公式集。一些规划域具有可分解为$C_2$特征算术表达式的最优值函数。研究显示，与实证结果相反，R-GNNs无法学习由$C_2$特征定义的值函数。此外，还确定了可能更好地学习由$C_2$特征定义的值函数的先前GNN架构。&lt;h4&gt;背景&lt;/h4&gt;R-GNNs是基于GNN的，用于学习能够推广到未见问题的值函数的方法。&lt;h4&gt;目的&lt;/h4&gt;探究R-GNNs是否能够学习由$C_2$特征定义的值函数，并比较其他GNN架构在同样任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;理论分析，实证比较。&lt;h4&gt;主要发现&lt;/h4&gt;R-GNNs不能学习由$C_2$特征定义的值函数，并且存在其他GNN架构可能更适合这项任务。&lt;h4&gt;结论&lt;/h4&gt;R-GNNs在处理某些规划域的值函数学习上存在限制，需要考虑其他可能的GNN架构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Relational Graph Neural Networks (R-GNNs) are a GNN-based approach forlearning value functions that can generalise to unseen problems from a givenplanning domain. R-GNNs were theoretically motivated by the well knownconnection between the expressive power of GNNs and $C_2$, first-order logicwith two variables and counting. In the context of planning, $C_2$ featuresrefer to the set of formulae in $C_2$ with relations defined by the unary andbinary predicates of a planning domain. Some planning domains exhibit optimalvalue functions that can be decomposed as arithmetic expressions of $C_2$features. We show that, contrary to empirical results, R-GNNs cannot learnvalue functions defined by $C_2$ features. We also identify prior GNNarchitectures for planning that may better learn value functions defined by$C_2$ features.</description>
      <author>example@mail.com (Dillon Z. Chen)</author>
      <guid isPermaLink="false">2506.11721v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>CLEAN-MI: A Scalable and Efficient Pipeline for Constructing High-Quality Neurodata in Motor Imagery Paradigm</title>
      <link>http://arxiv.org/abs/2506.11830v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CLEAN-MI的数据构建流程，用于构建大规模、高效、准确的神经数据，以促进基于运动想象（MI）的脑机接口（BCI）中稳健和泛化能力强的基础模型的发展。&lt;h4&gt;背景&lt;/h4&gt;构建大规模、高质量的数据集是开发稳健和泛化能力强的基于运动想象的脑机接口基础模型的基本前提。然而，从不同主体和设备收集的脑电图（EEG）信号通常存在信号噪声比低、电极配置异质性和显著的个体间变异等问题，这给有效的模型训练带来了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出CLEAN-MI数据构建流程，以解决上述问题，提高数据质量和分类性能。&lt;h4&gt;方法&lt;/h4&gt;CLEAN-MI通过频率带滤波、通道模板选择、受试者筛选和边缘分布对齐等步骤，系统地过滤掉无关或低质量数据，并标准化多源EEG数据集。&lt;h4&gt;主要发现&lt;/h4&gt;CLEAN-MI在多个公开的MI数据集上证明了其有效性，实现了数据质量和分类性能的一致性提升。&lt;h4&gt;结论&lt;/h4&gt;CLEAN-MI是一种有效的数据构建流程，有助于提高基于运动想象的脑机接口中数据集的质量和模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The construction of large-scale, high-quality datasets is a fundamentalprerequisite for developing robust and generalizable foundation models in motorimagery (MI)-based brain-computer interfaces (BCIs). However, EEG signalscollected from different subjects and devices are often plagued by lowsignal-to-noise ratio, heterogeneity in electrode configurations, andsubstantial inter-subject variability, posing significant challenges foreffective model training. In this paper, we propose CLEAN-MI, a scalable andsystematic data construction pipeline for constructing large-scale, efficient,and accurate neurodata in the MI paradigm. CLEAN-MI integrates frequency bandfiltering, channel template selection, subject screening, and marginaldistribution alignment to systematically filter out irrelevant or low-qualitydata and standardize multi-source EEG datasets. We demonstrate theeffectiveness of CLEAN-MI on multiple public MI datasets, achieving consistentimprovements in data quality and classification performance.</description>
      <author>example@mail.com (Dingkun Liu, Zhu Chen, Dongrui Wu)</author>
      <guid isPermaLink="false">2506.11830v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Task-Driven Discrete Representation Learning</title>
      <link>http://arxiv.org/abs/2506.11511v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了深度离散表示学习（DRL）在各个领域的成功应用，并从任务驱动的角度提出了一个统一的框架，以探讨离散特征在下游任务中的有用性。&lt;h4&gt;背景&lt;/h4&gt;近年来，深度离散表示学习（DRL）在各种领域取得了显著成功。大多数DRL框架主要关注生成设置，通过生成质量来间接评估表示的质量。&lt;h4&gt;目的&lt;/h4&gt;本文旨在从任务驱动的角度考察DRL，并分析离散表示的特性和对特定任务的益处。&lt;h4&gt;方法&lt;/h4&gt;提出了一个统一的框架，用于探索离散特征在下游任务中的有用性，并提供了关于表示能力与样本复杂度之间权衡的理论分析。&lt;h4&gt;主要发现&lt;/h4&gt;发现了离散表示的特性和它们对特定任务的影响，并揭示了离散表示利用如何影响任务性能。&lt;h4&gt;结论&lt;/h4&gt;展示了框架在多样应用中的灵活性和有效性。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, deep discrete representation learning (DRL) has achieved significant success across various domains. Most DRL frameworks (e.g., the widely used VQ-VAE and its variants) have primarily focused on generative settings, where the quality of a representation is implicitly gauged by the fidelity of its generation. In fact, the goodness of a discrete representation remains ambiguously defined across the literature. In this work, we adopt a practical approach that examines DRL from a task-driven perspective. We propose a unified framework that explores the usefulness of discrete features in relation to downstream tasks, with generation naturally viewed as one possible application. In this context, the properties of discrete representations as well as the way they benefit certain tasks are also relatively understudied. Therefore, we provide an additional theoretical analysis of the trade-off between representational capacity and sample complexity, shedding light on how discrete representation utilization impacts task performance. Finally, we demonstrate the flexibility and effectiveness of our framework across diverse applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, deep discrete representation learning (DRL) has achievedsignificant success across various domains. Most DRL frameworks (e.g., thewidely used VQ-VAE and its variants) have primarily focused on generativesettings, where the quality of a representation is implicitly gauged by thefidelity of its generation. In fact, the goodness of a discrete representationremain ambiguously defined across the literature. In this work, we adopt apractical approach that examines DRL from a task-driven perspective. We proposea unified framework that explores the usefulness of discrete features inrelation to downstream tasks, with generation naturally viewed as one possibleapplication. In this context, the properties of discrete representations aswell as the way they benefit certain tasks are also relatively understudied. Wetherefore provide an additional theoretical analysis of the trade-off betweenrepresentational capacity and sample complexity, shedding light on how discreterepresentation utilization impacts task performance. Finally, we demonstratethe flexibility and effectiveness of our framework across diverse applications.</description>
      <author>example@mail.com (Tung-Long Vuong)</author>
      <guid isPermaLink="false">2506.11511v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>CLIP Meets Diffusion: A Synergistic Approach to Anomaly Detection</title>
      <link>http://arxiv.org/abs/2506.11772v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为CLIPFUSION的异常检测方法，该方法结合了判别性和生成性基础模型，在异常检测中取得了优异的性能。&lt;h4&gt;背景&lt;/h4&gt;异常检测是一个复杂的问题，由于异常定义的模糊性、异常类型的多样性（如局部和全局缺陷）以及训练数据的稀缺性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够捕捉低级和高级特征的综合模型，即使在有限的数据下也能有效工作。&lt;h4&gt;方法&lt;/h4&gt;CLIPFUSION方法利用了基于CLIP的判别模型和基于扩散的生成模型，分别擅长捕捉全局特征和局部细节，形成协同互补的方法。同时，引入了一种利用交叉注意力图和从扩散模型中提取的特征图的方法。&lt;h4&gt;主要发现&lt;/h4&gt;在MVTec-AD和VisA等基准数据集上的实验结果表明，CLIPFUSION在异常分割和分类方面均优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;该方法强调了多模态和多模型融合在解决异常检测多方面挑战中的有效性，为现实世界的应用提供了一种可扩展的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于异常定义的模糊性、异常类型的多样性（例如，局部和全局缺陷）以及训练数据的稀缺性，异常检测是一个复杂的问题。因此，它需要一个能够捕捉低级和高级特征的综合模型，即使在有限的数据下也能有效工作。为了解决这个问题，我们提出了CLIPFUSION方法，该方法利用了判别性和生成性基础模型。具体来说，基于CLIP的判别模型擅长捕捉全局特征，而基于扩散的生成模型有效地捕捉局部细节，形成了一种协同互补的方法。值得注意的是，我们引入了一种利用交叉注意力图和从扩散模型中提取的特征图的方法，专门用于异常检测。在MVTec-AD、VisA等基准数据集上的实验结果表明，CLIPFUSION在异常分割和分类方面均优于基线方法。我们认为，我们的方法强调了多模态和多模型融合在解决异常检测多方面挑战中的有效性，为现实世界的应用提供了一种可扩展的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection is a complex problem due to the ambiguity in defininganomalies, the diversity of anomaly types (e.g., local and global defect), andthe scarcity of training data. As such, it necessitates a comprehensive modelcapable of capturing both low-level and high-level features, even with limiteddata. To address this, we propose CLIPFUSION, a method that leverages bothdiscriminative and generative foundation models. Specifically, the CLIP-baseddiscriminative model excels at capturing global features, while thediffusion-based generative model effectively captures local details, creating asynergistic and complementary approach. Notably, we introduce a methodology forutilizing cross-attention maps and feature maps extracted from diffusion modelsspecifically for anomaly detection. Experimental results on benchmark datasets(MVTec-AD, VisA) demonstrate that CLIPFUSION consistently outperforms baselinemethods, achieving outstanding performance in both anomaly segmentation andclassification. We believe that our method underscores the effectiveness ofmulti-modal and multi-model fusion in tackling the multifaceted challenges ofanomaly detection, providing a scalable solution for real-world applications.</description>
      <author>example@mail.com (Byeongchan Lee, John Won, Seunghyun Lee, Jinwoo Shin)</author>
      <guid isPermaLink="false">2506.11772v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Preserving Clusters in Prompt Learning for Unsupervised Domain Adaptation</title>
      <link>http://arxiv.org/abs/2506.11493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉和文本嵌入几何结构的方法，用于强化无监督领域自适应（UDA）中的伪标签，并促进目标提示学习，以提高领域自适应的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的基于多模态预训练模型（如CLIP）的领域自适应方法在多个基准上取得了最先进的性能，但大部分改进来源于基于伪标签（CLIP零样本预测）和自训练机制，存在视觉嵌入分布偏差的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来强化伪标签并促进目标提示学习，通过利用视觉和文本嵌入的几何结构。&lt;h4&gt;方法&lt;/h4&gt;1. 直接利用基于源和目标视觉嵌入关系的参考预测（来自源提示）。2. 利用预训练的多模态模型中视觉和文本嵌入之间的强聚类行为，基于最优传输理论，将这种洞察转化为一种新的策略，以加强文本嵌入中的聚类属性，进一步增强了目标域中的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过强化伪标签和促进目标提示学习，在领域自适应任务中取得了优越的性能和目标提示的高质量。&lt;h4&gt;结论&lt;/h4&gt;实验和消融研究表明，所提出的方法有效地提高了领域自适应的性能，并改善了目标提示的质量。&lt;h4&gt;翻译&lt;/h4&gt;Recent approaches leveraging multi-modal pre-trained models like CLIP for Unsupervised Domain Adaptation (UDA) have shown significant promise in bridging domain gaps and improving generalization by utilizing rich semantic knowledge and robust visual representations learned through extensive pre-training on diverse image-text datasets. While these methods achieve state-of-the-art performance across benchmarks, much of the improvement stems from base pseudo-labels (CLIP zero-shot predictions) and self-training mechanisms. Thus, the training mechanism exhibits a key limitation wherein the visual embedding distribution in target domains can deviate from the visual embedding distribution in the pre-trained model, leading to misguided signals from class descriptions. This work introduces a fresh solution to reinforce these pseudo-labels and facilitate target-prompt learning, by exploiting the geometry of visual and text embeddings - an aspect that is overlooked by existing methods. We first propose to directly leverage the reference predictions (from source prompts) based on the relationship between source and target visualembeddings. We later show that there is a strong clustering behavior observed between visual and text embeddings in pre-trained multi-modal models. Building on optimal transport theory, we transform this insight into a novel strategy to enforce the clustering property in text embeddings, further enhancing the alignment in the target domain. Our experiments and ablation studies validate the effectiveness of the proposed approach, demonstrating superior performance and improved quality of target prompts in terms of representation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent approaches leveraging multi-modal pre-trained models like CLIP forUnsupervised Domain Adaptation (UDA) have shown significant promise in bridgingdomain gaps and improving generalization by utilizing rich semantic knowledgeand robust visual representations learned through extensive pre-training ondiverse image-text datasets. While these methods achieve state-of-the-artperformance across benchmarks, much of the improvement stems from basepseudo-labels (CLIP zero-shot predictions) and self-training mechanisms. Thus,the training mechanism exhibits a key limitation wherein the visual embeddingdistribution in target domains can deviate from the visual embeddingdistribution in the pre-trained model, leading to misguided signals from classdescriptions. This work introduces a fresh solution to reinforce thesepseudo-labels and facilitate target-prompt learning, by exploiting the geometryof visual and text embeddings - an aspect that is overlooked by existingmethods. We first propose to directly leverage the reference predictions (fromsource prompts) based on the relationship between source and target visualembeddings. We later show that there is a strong clustering behavior observedbetween visual and text embeddings in pre-trained multi-modal models. Buildingon optimal transport theory, we transform this insight into a novel strategy toenforce the clustering property in text embeddings, further enhancing thealignment in the target domain. Our experiments and ablation studies validatethe effectiveness of the proposed approach, demonstrating superior performanceand improved quality of target prompts in terms of representation.</description>
      <author>example@mail.com (Tung-Long Vuong, Hoang Phan, Vy Vo, Anh Bui, Thanh-Toan Do, Trung Le, Dinh Phung)</author>
      <guid isPermaLink="false">2506.11493v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Effectiveness of Deep Features from Domain-Specific Foundation Models in Retinal Image Synthesis</title>
      <link>http://arxiv.org/abs/2506.11753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published and presented at the MIUA 2025 conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;医学影像中神经网络模型的采用受到隐私法规、数据可用性限制、高获取成本和人口结构偏差的制约。&lt;h4&gt;背景&lt;/h4&gt;深度生成模型通过生成合成数据，绕过隐私问题，并通过为代表性不足的群体生成样本来解决公平性问题。&lt;h4&gt;目的&lt;/h4&gt;研究基于大型领域数据集训练的大型基础模型的深度激活层的距离损失函数，是否在感知损失和边缘检测损失函数之上提供优势。&lt;h4&gt;方法&lt;/h4&gt;使用广泛的验证流程，基于无领域和领域特定任务，以评估特定领域深度特征在自动编码器图像生成中的改进。&lt;h4&gt;主要发现&lt;/h4&gt;领域特定深度特征并未提高自动编码器图像生成的质量。相反，研究发现传统的边缘检测滤波器在提高合成样本中血管结构的清晰度方面是有效的。&lt;h4&gt;结论&lt;/h4&gt;在医学影像中，验证不仅需要保证图像的真实性，还需要保证形态和临床准确性，尤其是在彩色眼底视网膜成像方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The adoption of neural network models in medical imaging has been constrainedby strict privacy regulations, limited data availability, high acquisitioncosts, and demographic biases. Deep generative models offer a promisingsolution by generating synthetic data that bypasses privacy concerns andaddresses fairness by producing samples for under-represented groups. However,unlike natural images, medical imaging requires validation not only forfidelity (e.g., Fr\'echet Inception Score) but also for morphological andclinical accuracy. This is particularly true for colour fundus retinal imaging,which requires precise replication of the retinal vascular network, includingvessel topology, continuity, and thickness. In this study, we in-vestigatedwhether a distance-based loss function based on deep activation layers of alarge foundational model trained on large corpus of domain data, colour fundusimaging, offers advantages over a perceptual loss and edge-detection based lossfunctions. Our extensive validation pipeline, based on both domain-free anddomain specific tasks, suggests that domain-specific deep features do notimprove autoen-coder image generation. Conversely, our findings highlight theeffectiveness of con-ventional edge detection filters in improving thesharpness of vascular structures in synthetic samples.</description>
      <author>example@mail.com (Zuzanna Skorniewska, Bartlomiej W. Papiez)</author>
      <guid isPermaLink="false">2506.11753v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Can Time-Series Foundation Models Perform Building Energy Management Tasks?</title>
      <link>http://arxiv.org/abs/2506.11250v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages, 5 tables, 8 figures. Under review for Data-Centric  Engineering journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文评估了时间序列基础模型（TSFMs）在建筑能源管理（BEM）任务中的应用，发现其在泛化能力、性能表现和适应性方面存在局限性。&lt;h4&gt;背景&lt;/h4&gt;BEM任务需要处理和学习多种时间序列数据，现有解决方案依赖于特定任务和数据的定制模型，限制了其更广泛的应用。&lt;h4&gt;目的&lt;/h4&gt;研究TSFMs在BEM任务中的表现，特别是其在零样本单变量预测、热行为建模、分类任务中的零样本表示学习和对性能指标及不同运行条件的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;通过四个维度评估TSFMs：1）零样本单变量预测的泛化能力；2）包含协变量的预测；3）分类任务的零样本表示学习；4）对性能指标和不同运行条件的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;TSFMs在泛化能力上有限，仅在未见数据集和模态上的单变量预测中略优于统计模型。包含协变量并未提升性能，且其表现不如使用协变量的传统模型。TSFMs在生成有效的零样本表示方面表现良好，但在统计模型进行测试时拟合时可能不如统计模型。此外，TSFMs的预测性能对评估指标敏感，在更复杂的建筑环境中表现不如统计模型。&lt;h4&gt;结论&lt;/h4&gt;需要针对TSFM设计进行改进，特别是其处理协变量的能力以及将上下文和时序动态纳入预测机制，以开发更适应性和可扩展的BEM解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Building energy management (BEM) tasks require processing and learning from avariety of time-series data. Existing solutions rely on bespoke task- anddata-specific models to perform these tasks, limiting their broaderapplicability. Inspired by the transformative success of Large Language Models(LLMs), Time-Series Foundation Models (TSFMs), trained on diverse datasets,have the potential to change this. Were TSFMs to achieve a level ofgeneralizability across tasks and contexts akin to LLMs, they couldfundamentally address the scalability challenges pervasive in BEM. Tounderstand where they stand today, we evaluate TSFMs across four dimensions:(1) generalizability in zero-shot univariate forecasting, (2) forecasting withcovariates for thermal behavior modeling, (3) zero-shot representation learningfor classification tasks, and (4) robustness to performance metrics and varyingoperational conditions. Our results reveal that TSFMs exhibit \emph{limited}generalizability, performing only marginally better than statistical models onunseen datasets and modalities for univariate forecasting. Similarly, inclusionof covariates in TSFMs does not yield performance improvements, and theirperformance remains inferior to conventional models that utilize covariates.While TSFMs generate effective zero-shot representations for downstreamclassification tasks, they may remain inferior to statistical models inforecasting when statistical models perform test-time fitting. Moreover, TSFMsforecasting performance is sensitive to evaluation metrics, and they strugglein more complex building environments compared to statistical models. Thesefindings underscore the need for targeted advancements in TSFM design,particularly their handling of covariates and incorporating context andtemporal dynamics into prediction mechanisms, to develop more adaptable andscalable solutions for BEM.</description>
      <author>example@mail.com (Ozan Baris Mulayim, Pengrui Quan, Liying Han, Xiaomin Ouyang, Dezhi Hong, Mario Bergés, Mani Srivastava)</author>
      <guid isPermaLink="false">2506.11250v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Quizzard@INOVA Challenge 2025 -- Track A: Plug-and-Play Technique in Interleaved Multi-Image Model</title>
      <link>http://arxiv.org/abs/2506.11737v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了LLaVA-NeXT-interleave在多图像推理、文档和基于知识的理解以及交互式多模态通信三个任务上的表现，并添加了密集通道集成（DCI）连接器，比较了其与标准模型的性能。&lt;h4&gt;背景&lt;/h4&gt;无具体背景信息。&lt;h4&gt;目的&lt;/h4&gt;1. 展示LLaVA-NeXT-interleave在多个数据集上的出色表现；2. 添加DCI连接器到LLaVA-NeXT-Interleave中，并与标准模型进行性能比较。&lt;h4&gt;方法&lt;/h4&gt;在22个数据集上测试LLaVA-NeXT-interleave在不同任务上的表现，并添加DCI连接器进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;1. 标准模型在整体准确率上表现最佳，尤其在视觉密集型任务上；2. DCI增强版本在需要更深层次语义连贯性或结构变化理解的集上表现突出。&lt;h4&gt;结论&lt;/h4&gt;结合强大的基础模型和即插即用技术对于Interleave任务具有潜力。&lt;h4&gt;翻译&lt;/h4&gt;本文针对两个主要目标进行研究。首先，我们在三个不同任务（多图像推理、文档和基于知识的理解以及交互式多模态通信）的22个数据集上展示了LLaVA-NeXT-interleave的出色性能。其次，我们将密集通道集成（DCI）连接器添加到LLaVA-NeXT-Interleave中，并将其性能与标准模型进行了比较。我们发现，标准模型在整体准确率上达到了最高，在像VISION、NLVR2和Fashion200K这样的视觉密集型任务上表现出色。同时，DCI增强版本在需要更深层次语义连贯性或结构变化理解的集，如MIT-States_PropertyCoherence和SlideVQA上表现出特别的优势。我们的结果突出了结合强大基础模型与即插即用技术进行Interleave任务的潜力。代码可在https://github.com/dinhvietcuong1996/icme25-inova上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses two main objectives. Firstly, we demonstrate theimpressive performance of the LLaVA-NeXT-interleave on 22 datasets across threedifferent tasks: Multi-Image Reasoning, Documents and Knowledge-BasedUnderstanding and Interactive Multi-Modal Communication. Secondly, we add theDense Channel Integration (DCI) connector to the LLaVA-NeXT-Interleave andcompare its performance against the standard model. We find that the standardmodel achieves the highest overall accuracy, excelling in vision-heavy taskslike VISION, NLVR2, and Fashion200K. Meanwhile, the DCI-enhanced version showsparticular strength on datasets requiring deeper semantic coherence orstructured change understanding such as MIT-States_PropertyCoherence andSlideVQA. Our results highlight the potential of combining powerful foundationmodels with plug-and-play techniques for Interleave tasks. The code isavailable at https://github.com/dinhvietcuong1996/icme25-inova.</description>
      <author>example@mail.com (Dinh Viet Cuong, Hoang-Bao Le, An Pham Ngoc Nguyen, Liting Zhou, Cathal Gurrin)</author>
      <guid isPermaLink="false">2506.11737v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Generalised Rate Control Approach For Stream Processing Applications</title>
      <link>http://arxiv.org/abs/2506.11710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络深度强化学习的分布式流处理系统过载控制方法。&lt;h4&gt;背景&lt;/h4&gt;分布式流处理系统广泛应用于处理来自传感器和软件系统的实时数据，其中过载问题是系统稳定性和资源消耗的关键挑战。&lt;h4&gt;目的&lt;/h4&gt;通过控制数据生成速率来避免过载情况，从而提高系统性能。&lt;h4&gt;方法&lt;/h4&gt;使用图神经网络处理流处理引擎收集的系统指标，以避免存储过去状态、减少等待时间，并适应多种场景和流应用。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法能将吞吐量和端到端延迟分别提高13.5%和30%。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提高了分布式流处理系统的性能和稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Distributed stream processing systems are widely deployed to processreal-time data generated by various devices, such as sensors and softwaresystems. A key challenge in the system is overloading, which leads to anunstable system status and consumes additional system resources. In this paper,we use a graph neural network-based deep reinforcement learning tocollaboratively control the data emission rate at which the data is generatedin the stream source to proactively avoid overloading scenarios. Instead ofusing a traditional multi-layer perceptron-styled network to control the rate,the graph neural network is used to process system metrics collected from thestream processing engine. Consequently, the learning agent (i) avoids storingpast states where previous actions may affect the current state, (ii) iswithout waiting a long interval until the current action has been fullyeffective and reflected in the system's specific metrics, and more importantly,(iii) is able to adapt multiple stream applications in multiple scenarios. Wedeploy the rate control approach on three applications, and the experimentalresults demonstrate that the throughput and end-to-end latency are improved byup to 13.5% and 30%, respectively.</description>
      <author>example@mail.com (Ziren Xiao)</author>
      <guid isPermaLink="false">2506.11710v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Brain Network Analysis Based on Fine-tuned Self-supervised Model for Brain Disease Diagnosis</title>
      <link>http://arxiv.org/abs/2506.11671v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 3 figures, International Conference on Neural Computing for  Advanced Applications&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对脑疾病诊断的精细调优脑网络模型，通过多维度扩展脑区表示，提高了模型的可推广性。&lt;h4&gt;背景&lt;/h4&gt;功能脑网络分析对脑疾病分析至关重要，受深度学习方法影响，但现有研究在脑网络基础模型方面有限，限制了其在神经科学中的应用。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效进行脑疾病诊断的精细调优脑网络模型。&lt;h4&gt;方法&lt;/h4&gt;提出模型包含两个关键模块：(1)一个适配器模块，用于在不同维度上扩展脑区特征；(2)一个基于自监督学习和预训练于数千名参与者fMRI数据的精细调优基础脑网络模型。模型中的transformer块能够有效提取脑区特征并计算区域间关联。此外，推导出脑网络的紧凑性潜在表示。&lt;h4&gt;主要发现&lt;/h4&gt;模型在脑疾病诊断中表现出优异的性能，为脑网络分析研究提供了有前景的方法。&lt;h4&gt;结论&lt;/h4&gt;该模型在脑疾病诊断方面具有潜在的应用价值，并可能推动脑网络分析研究的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Functional brain network analysis has become an indispensable tool for braindisease analysis. It is profoundly impacted by deep learning methods, which cancharacterize complex connections between ROIs. However, the research onfoundation models of brain network is limited and constrained to a singledimension, which restricts their extensive application in neuroscience. In thisstudy, we propose a fine-tuned brain network model for brain disease diagnosis.It expands brain region representations across multiple dimensions based on theoriginal brain network model, thereby enhancing its generalizability. Our modelconsists of two key modules: (1)an adapter module that expands brain regionfeatures across different dimensions. (2)a fine-tuned foundation brain networkmodel, based on self-supervised learning and pre-trained on fMRI data fromthousands of participants. Specifically, its transformer block is able toeffectively extract brain region features and compute the inter-regionassociations. Moreover, we derive a compact latent representation of the brainnetwork for brain disease diagnosis. Our downstream experiments in this studydemonstrate that the proposed model achieves superior performance in braindisease diagnosis, which potentially offers a promising approach in brainnetwork analysis research.</description>
      <author>example@mail.com (Yifei Tang, Hongjie Jiang, Changhong Jing, Hieu Pham, Shuqiang Wang)</author>
      <guid isPermaLink="false">2506.11671v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>OV-MAP : Open-Vocabulary Zero-Shot 3D Instance Segmentation Map for Robots</title>
      <link>http://arxiv.org/abs/2506.11585v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IROS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了OV-MAP，这是一种将开放特征集成到3D地图中以增强物体识别能力的移动机器人开放世界3D制图的新方法。&lt;h4&gt;背景&lt;/h4&gt;在相邻体素重叠的特征导致实例级精度降低的情况下，特征溢出体素边界，混合了邻近区域。&lt;h4&gt;目的&lt;/h4&gt;克服上述挑战，实现准确的无监督3D实例分割。&lt;h4&gt;方法&lt;/h4&gt;采用一个类无关的分割模型将2D掩码投影到3D空间，并结合由点云合并原始和合成深度图像生成的补充深度图像。此外，还引入了3D掩码投票机制。&lt;h4&gt;主要发现&lt;/h4&gt;通过在ScanNet200和Replica等公共数据集上的全面实验，证明了该方法在无监督情况下具有优越的性能、鲁棒性和适应性。&lt;h4&gt;结论&lt;/h4&gt;通过真实世界实验，展示了该方法在多样化真实世界环境中的应用适应性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/IROS58592.2024.10801841&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce OV-MAP, a novel approach to open-world 3D mapping for mobilerobots by integrating open-features into 3D maps to enhance object recognitioncapabilities. A significant challenge arises when overlapping features fromadjacent voxels reduce instance-level precision, as features spill over voxelboundaries, blending neighboring regions together. Our method overcomes this byemploying a class-agnostic segmentation model to project 2D masks into 3Dspace, combined with a supplemented depth image created by merging raw andsynthetic depth from point clouds. This approach, along with a 3D mask votingmechanism, enables accurate zero-shot 3D instance segmentation without relyingon 3D supervised segmentation models. We assess the effectiveness of our methodthrough comprehensive experiments on public datasets such as ScanNet200 andReplica, demonstrating superior zero-shot performance, robustness, andadaptability across diverse environments. Additionally, we conducted real-worldexperiments to demonstrate our method's adaptability and robustness whenapplied to diverse real-world environments.</description>
      <author>example@mail.com (Juno Kim, Yesol Park, Hye-Jung Yoon, Byoung-Tak Zhang)</author>
      <guid isPermaLink="false">2506.11585v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Multimodal Large Language Models on Video Captioning via Monte Carlo Tree Search</title>
      <link>http://arxiv.org/abs/2506.11155v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages; ACL 2025(main)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AutoCaption的自动框架，用于评估多模态大型语言模型（MLLMs）的视频理解能力，并通过实验证明了其在视频描述任务中的有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的视频描述基准和评估协议存在关键问题，如关键点的创建不足或不一致、数据创建成本高昂以及评估范围有限。&lt;h4&gt;目的&lt;/h4&gt;提出AutoCaption框架，以解决现有基准和评估协议的问题，并评估MLLMs在视频描述任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;AutoCaption利用蒙特卡洛树搜索（MCTS）构建多个描述性句子（即关键点），以迭代方式全面地表示视频内容。该框架应用于创建MCTS-VCB基准，这是一个细粒度的视频描述基准，涵盖了视频细节，从而能够全面评估MLLMs的视频描述能力。&lt;h4&gt;主要发现&lt;/h4&gt;AutoCaption能够有效地评估视频描述能力，Gemini-1.5-Pro在MCTS-VCB上取得了最高的F1分数（71.2）。使用AutoCaption生成的数据微调InternVL2.5-8B模型，在MCTS-VCB和DREAM-1K上分别提升了25.0%和16.3%，进一步证明了AutoCaption的有效性。&lt;h4&gt;结论&lt;/h4&gt;AutoCaption框架为评估MLLMs的视频描述能力提供了一种有效的方法，并为视频描述任务的研究提供了新的基准。&lt;h4&gt;翻译&lt;/h4&gt;视频描述可以用来评估多模态大型语言模型（MLLMs）的视频理解能力。然而，现有的基准和评估协议存在关键问题，如关键点的创建不足或不一致、数据创建成本高昂以及评估范围有限。为了解决这些问题，我们提出了一种自动框架，名为AutoCaption，它利用蒙特卡洛树搜索（MCTS）以迭代方式构建多个描述性句子（即关键点），以全面地表示视频内容。这种迭代描述策略使得视频细节如动作、物体的属性、环境细节等得以持续提升。我们将AutoCaption应用于创建MCTS-VCB基准，这是一个细粒度的视频描述基准，涵盖了视频细节，从而能够全面评估MLLMs在视频描述任务上的表现。我们在MCTS-VCB上评估了超过20个大小不同的开源和闭源MLLMs。结果表明，MCTS-VCB能够有效地全面评估视频描述能力，其中Gemini-1.5-Pro在MCTS-VCB上取得了最高的F1分数（71.2）。有趣的是，我们使用AutoCaption生成的数据对InternVL2.5-8B模型进行了微调，这有助于模型在MCTS-VCB和DREAM-1K上分别提升了25.0%和16.3%，进一步证明了AutoCaption的有效性。代码和数据可在https://github.com/tjunlp-lab/MCTS-VCB上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video captioning can be used to assess the video understanding capabilitiesof Multimodal Large Language Models (MLLMs). However, existing benchmarks andevaluation protocols suffer from crucial issues, such as inadequate orhomogeneous creation of key points, exorbitant cost of data creation, andlimited evaluation scopes. To address these issues, we propose an automaticframework, named AutoCaption, which leverages Monte Carlo Tree Search (MCTS) toconstruct numerous and diverse descriptive sentences (\textit{i.e.}, keypoints) that thoroughly represent video content in an iterative way. Thisiterative captioning strategy enables the continuous enhancement of videodetails such as actions, objects' attributes, environment details, etc. Weapply AutoCaption to curate MCTS-VCB, a fine-grained video caption benchmarkcovering video details, thereby enabling a comprehensive evaluation of MLLMs onthe video captioning task. We evaluate more than 20 open- and closed-sourceMLLMs of varying sizes on MCTS-VCB. Results show that MCTS-VCB can effectivelyand comprehensively evaluate the video captioning capability, withGemini-1.5-Pro achieving the highest F1 score of 71.2. Interestingly, wefine-tune InternVL2.5-8B with the AutoCaption-generated data, which helps themodel achieve an overall improvement of 25.0% on MCTS-VCB and 16.3% onDREAM-1K, further demonstrating the effectiveness of AutoCaption. The code anddata are available at https://github.com/tjunlp-lab/MCTS-VCB.</description>
      <author>example@mail.com (Linhao Yu, Xinguang Ji, Yahui Liu, Fanheng Kong, Chenxi Sun, Jingyuan Zhang, Hongzhi Zhang, V. W., Fuzheng Zhang, Deyi Xiong)</author>
      <guid isPermaLink="false">2506.11155v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Geometry-Aware Edge Pooling for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.11700v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图池化层，旨在解决现有池化操作在优化学习任务时牺牲基本图结构和可解释性的问题。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在图相关任务中取得了显著成功，但池化层在大型数据集的实时应用中至关重要。&lt;h4&gt;目的&lt;/h4&gt;通过减少输入图的大小，实现更快的训练和可能的更好泛化，同时保持图的度量结构和结构多样性。&lt;h4&gt;方法&lt;/h4&gt;提出的方法通过边缘折叠进行结构感知池化，利用扩散几何，迭代地减小图的大小，同时保留其度量结构和结构多样性。使用等距不变多样性度量（幅度）来引导池化过程，并使用度量空间的传播作为更快速、更稳定的替代方案。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法（1）在各种不同的图分类任务中比其他池化层实现更优的性能；（2）保留了输入图的关键谱属性；（3）在变化不同的池化比率下保持了高精度。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法有效地解决了现有池化操作的局限性，并展示了在图分类任务中的优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have shown significant success for graph-basedtasks. Motivated by the prevalence of large datasets in real-worldapplications, pooling layers are crucial components of GNNs. By reducing thesize of input graphs, pooling enables faster training and potentially bettergeneralisation. However, existing pooling operations often optimise for thelearning task at the expense of fundamental graph structures andinterpretability. This leads to unreliable performance across varying datasettypes, downstream tasks and pooling ratios. Addressing these concerns, wepropose novel graph pooling layers for structure aware pooling via edgecollapses. Our methods leverage diffusion geometry and iteratively reduce agraph's size while preserving both its metric structure and structuraldiversity. We guide pooling using magnitude, an isometry-invariant diversitymeasure, which permits us to control the fidelity of the pooling process.Further, we use the spread of a metric space as a faster and more stablealternative ensuring computational efficiency. Empirical results demonstratethat our methods (i) achieve superior performance compared to alternativepooling layers across a range of diverse graph classification tasks, (ii)preserve key spectral properties of the input graphs, and (iii) retain highaccuracy across varying pooling ratios.</description>
      <author>example@mail.com (Katharina Limbeck, Lydia Mezrag, Guy Wolf, Bastian Rieck)</author>
      <guid isPermaLink="false">2506.11700v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>A$^2$LC: Active and Automated Label Correction for Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2506.11599v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Under review. 22 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为A$^2$LC的语义分割主动和自动标签校正框架，通过集成自动化校正阶段提高了校正效率，并通过自适应平衡获取函数强调了代表性不足的尾部类别，实验结果表明A$^2$LC在Cityscapes和PASCAL VOC 2012数据集上显著优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;手动像素级标注在语义分割中成本高且易出错，而使用基础模型生成伪标签虽然提高了校正效率，但仍有大量低效之处。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且有效的主动标签校正框架，以降低成本并提高语义分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;A$^2$LC框架将自动化校正阶段集成到传统流程中，利用标注者反馈对查询样本以外的数据进行标签校正，并引入自适应平衡获取函数来强调尾部类别。&lt;h4&gt;主要发现&lt;/h4&gt;A$^2$LC在Cityscapes和PASCAL VOC 2012数据集上显著优于现有方法，且使用20%的预算就能超过其他方法的表现，在相同预算下性能提升了27.23%。&lt;h4&gt;结论&lt;/h4&gt;A$^2$LC是一种高效且有效的语义分割标签校正方法，值得进一步研究和应用。&lt;h4&gt;翻译&lt;/h4&gt;Active Label Correction (ALC)已经成为解决语义分割中手动像素级标注高成本和易出错问题的一种有希望的解决方案，通过选择性地识别和纠正误标注的数据。尽管最近的工作通过使用基础模型生成伪标签来提高了校正效率，但仍然存在大量的低效。在本文中，我们提出了针对语义分割的主动和自动标签校正（A$^2$LC），这是一种新颖且高效的ALC框架，它将自动化校正阶段集成到传统流程中。具体来说，自动化校正阶段利用标注者反馈对查询样本以外的数据进行标签校正，从而最大化成本效率。此外，我们还引入了一个自适应平衡获取函数，强调代表性不足的尾部类别，并补充了自动化校正机制。在Cityscapes和PASCAL VOC 2012数据集上的大量实验表明，A$^2$LC显著优于先前最先进的方法。值得注意的是，A$^2$LC通过仅使用20%的预算就优于先前的方法，并在Cityscapes数据集上在等效预算约束下实现了27.23%的性能提升。代码将在接受后发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Active Label Correction (ALC) has emerged as a promising solution to the highcost and error-prone nature of manual pixel-wise annotation in semanticsegmentation, by selectively identifying and correcting mislabeled data.Although recent work has improved correction efficiency by generatingpseudo-labels using foundation models, substantial inefficiencies still remain.In this paper, we propose Active and Automated Label Correction for semanticsegmentation (A$^2$LC), a novel and efficient ALC framework that integrates anautomated correction stage into the conventional pipeline. Specifically, theautomated correction stage leverages annotator feedback to perform labelcorrection beyond the queried samples, thereby maximizing cost efficiency. Inaddition, we further introduce an adaptively balanced acquisition function thatemphasizes underrepresented tail classes and complements the automatedcorrection mechanism. Extensive experiments on Cityscapes and PASCAL VOC 2012demonstrate that A$^2$LC significantly outperforms previous state-of-the-artmethods. Notably, A$^2$LC achieves high efficiency by outperforming previousmethods using only 20% of their budget, and demonstrates strong effectivenessby yielding a 27.23% performance improvement under an equivalent budgetconstraint on the Cityscapes dataset. The code will be released uponacceptance.</description>
      <author>example@mail.com (Youjin Jeon, Kyusik Cho, Suhan Woo, Euntai Kim)</author>
      <guid isPermaLink="false">2506.11599v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>KCES: Training-Free Defense for Robust Graph Neural Networks via Kernel Complexity</title>
      <link>http://arxiv.org/abs/2506.11611v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为KCES的Graph Neural Networks (GNNs)防御框架，用于提高GNNs的鲁棒性，该框架基于图核复杂度（GKC）进行边缘净化，能够有效抵御对抗攻击。&lt;h4&gt;背景&lt;/h4&gt;尽管GNNs在图相关任务中取得了显著成功，但它们对微小的扰动和对抗攻击非常脆弱。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种训练免费、模型无关的防御框架，以提高GNNs的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;KCES利用图核复杂度（GKC）来衡量边缘的潜在风险，通过修剪具有高KC分数的边缘来减轻有害影响。&lt;h4&gt;主要发现&lt;/h4&gt;KCES能够提高GNNs的鲁棒性，优于现有基准，并增强现有防御策略的有效性。&lt;h4&gt;结论&lt;/h4&gt;KCES提供了一个原则性和高效的解决方案，以保护GNNs免受攻击。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have achieved impressive success across a widerange of graph-based tasks, yet they remain highly vulnerable to small,imperceptible perturbations and adversarial attacks. Although numerous defensemethods have been proposed to address these vulnerabilities, many rely onheuristic metrics, overfit to specific attack patterns, and suffer from highcomputational complexity. In this paper, we propose Kernel Complexity-BasedEdge Sanitization (KCES), a training-free, model-agnostic defense framework.KCES leverages Graph Kernel Complexity (GKC), a novel metric derived from thegraph's Gram matrix that characterizes GNN generalization via its test errorbound. Building on GKC, we define a KC score for each edge, measuring thechange in GKC when the edge is removed. Edges with high KC scores, typicallyintroduced by adversarial perturbations, are pruned to mitigate their harmful effects,thereby enhancing GNNs' robustness. KCES can also be seamlessly integrated withexisting defense strategies as a plug-and-play module without requiring training. Theoretical analysis and extensive experiments demonstratethat KCES consistently enhances GNN robustness, outperforms state-of-the-artbaselines, and amplifies the effectiveness of existing defenses, offering aprincipled and efficient solution for securing GNNs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have achieved impressive success across a widerange of graph-based tasks, yet they remain highly vulnerable to small,imperceptible perturbations and adversarial attacks. Although numerous defensemethods have been proposed to address these vulnerabilities, many rely onheuristic metrics, overfit to specific attack patterns, and suffer from highcomputational complexity. In this paper, we propose Kernel Complexity-BasedEdge Sanitization (KCES), a training-free, model-agnostic defense framework.KCES leverages Graph Kernel Complexity (GKC), a novel metric derived from thegraph's Gram matrix that characterizes GNN generalization via its test errorbound. Building on GKC, we define a KC score for each edge, measuring thechange in GKC when the edge is removed. Edges with high KC scores, typicallyintroduced by adversarial perturbations, are pruned to mitigate their harmfuleffects, thereby enhancing GNNs' robustness. KCES can also be seamlesslyintegrated with existing defense strategies as a plug-and-play module withoutrequiring training. Theoretical analysis and extensive experiments demonstratethat KCES consistently enhances GNN robustness, outperforms state-of-the-artbaselines, and amplifies the effectiveness of existing defenses, offering aprincipled and efficient solution for securing GNNs.</description>
      <author>example@mail.com (Yaning Jia, Shenyang Deng, Chiyu Ma, Yaoqing Yang, Soroush Vosoughi)</author>
      <guid isPermaLink="false">2506.11611v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Learn to Preserve Personality: Federated Foundation Models in Recommendations</title>
      <link>http://arxiv.org/abs/2506.11563v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 3 figures, conference, position paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了联邦基础模型（FFM）在推荐系统中的应用，旨在在泛化与个性化之间取得平衡，同时保护用户个性的完整性。&lt;h4&gt;背景&lt;/h4&gt;现有基础模型（FM）面临泛化与个性化之间的平衡挑战，参数高效的适应技术凸显了这一困境。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的学习范式，FFM不仅利用其泛化能力，而且专门设计来保护用户个性的完整性。&lt;h4&gt;方法&lt;/h4&gt;利用联邦学习过程将共享知识与个人特定适应解耦，并在推荐系统中进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;FFM在推荐系统中能够实现用户个性化，同时保持用户个性的完整性。&lt;h4&gt;结论&lt;/h4&gt;预测未来个性化自适应FM将支持个人代理，引导用户在内容上的决策，构建以用户为中心、去中心化的系统。&lt;h4&gt;翻译&lt;/h4&gt;A core learning challenge for existed Foundation Models (FM) is striking the tradeoff between generalization with personalization, which is a dilemma that has been highlighted by various parameter-efficient adaptation techniques. Federated foundation models (FFM) provide a structural means to decouple shared knowledge from individual specific adaptations via decentralized processes. Recommendation systems offer a perfect testbed for FFMs, given their reliance on rich implicit feedback reflecting unique user characteristics. This position paper discusses a novel learning paradigm where FFMs not only harness their generalization capabilities but are specifically designed to preserve the integrity of user personality, illustrated thoroughly within the recommendation contexts. We envision future personal agents, powered by personalized adaptive FMs, guiding user decisions on content. Such an architecture promises a user-centric, decentralized system where individuals maintain control over their personalized agents.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A core learning challenge for existed Foundation Models (FM) is striking thetradeoff between generalization with personalization, which is a dilemma thathas been highlighted by various parameter-efficient adaptation techniques.Federated foundation models (FFM) provide a structural means to decouple sharedknowledge from individual specific adaptations via decentralized processes.Recommendation systems offer a perfect testbed for FFMs, given their relianceon rich implicit feedback reflecting unique user characteristics. This positionpaper discusses a novel learning paradigm where FFMs not only harness theirgeneralization capabilities but are specifically designed to preserve theintegrity of user personality, illustrated thoroughly within the recommendationcontexts. We envision future personal agents, powered by personalized adaptiveFMs, guiding user decisions on content. Such an architecture promises a usercentric, decentralized system where individuals maintain control over theirpersonalized agents.</description>
      <author>example@mail.com (Zhiwei Li, Guodong Long, Chunxu Zhang, Honglei Zhang, Jing Jiang, Chengqi Zhang)</author>
      <guid isPermaLink="false">2506.11563v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models in Autonomous Driving: A Survey on Scenario Generation and Scenario Analysis</title>
      <link>http://arxiv.org/abs/2506.11526v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对自动驾驶场景生成和分析中基础模型的应用进行了综述。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶在复杂环境中的安全导航依赖于处理多样化的驾驶场景。&lt;h4&gt;目的&lt;/h4&gt;本文旨在调查和总结基础模型在自动驾驶场景生成和分析中的应用。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个统一的分类法，包括大语言模型、视觉-语言模型、多模态大语言模型、扩散模型和世界模型。&lt;h4&gt;主要发现&lt;/h4&gt;本文回顾了场景生成和分析的方法、开源数据集、模拟平台和基准挑战，并考察了专门针对场景生成和分析的评价指标。&lt;h4&gt;结论&lt;/h4&gt;本文指出了开放挑战和研究问题，并概述了有希望的未来研究方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：对于自动驾驶汽车，在复杂环境中的安全导航取决于处理广泛的多样化和罕见的驾驶场景。基于模拟和场景的测试已成为自动驾驶系统开发和验证的关键方法。传统的场景生成依赖于基于规则的系统、知识驱动模型和数据驱动合成，通常产生有限的多样性和不切实际的安全关键案例。随着基础模型的兴起，这些代表新一代预训练的通用人工智能模型，开发者可以处理异构输入（例如，自然语言、传感器数据、高清地图和控制动作），从而实现复杂驾驶场景的合成和解释。在本文中，我们对基础模型在自动驾驶场景生成和分析中的应用进行了调查（截至2025年5月）。我们的调查提出了一个统一的分类法，包括大型语言模型、视觉-语言模型、多模态大型语言模型、扩散模型和用于自动驾驶场景生成和分析的世界模型。此外，我们回顾了方法、开源数据集、模拟平台和基准挑战，并检查了专门针对场景生成和分析的评价指标。最后，调查通过突出开放挑战和研究问题，概述了有希望的未来研究方向。所有回顾的论文都列在一个持续维护的存储库中，该存储库包含补充材料，可在https://github.com/TUM-AVS/FM-for-Scenario-Generation-Analysis上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For autonomous vehicles, safe navigation in complex environments depends onhandling a broad range of diverse and rare driving scenarios. Simulation- andscenario-based testing have emerged as key approaches to development andvalidation of autonomous driving systems. Traditional scenario generationrelies on rule-based systems, knowledge-driven models, and data-drivensynthesis, often producing limited diversity and unrealistic safety-criticalcases. With the emergence of foundation models, which represent a newgeneration of pre-trained, general-purpose AI models, developers can processheterogeneous inputs (e.g., natural language, sensor data, HD maps, and controlactions), enabling the synthesis and interpretation of complex drivingscenarios. In this paper, we conduct a survey about the application offoundation models for scenario generation and scenario analysis in autonomousdriving (as of May 2025). Our survey presents a unified taxonomy that includeslarge language models, vision-language models, multimodal large languagemodels, diffusion models, and world models for the generation and analysis ofautonomous driving scenarios. In addition, we review the methodologies,open-source datasets, simulation platforms, and benchmark challenges, and weexamine the evaluation metrics tailored explicitly to scenario generation andanalysis. Finally, the survey concludes by highlighting the open challenges andresearch questions, and outlining promising future research directions. Allreviewed papers are listed in a continuously maintained repository, whichcontains supplementary materials and is available athttps://github.com/TUM-AVS/FM-for-Scenario-Generation-Analysis.</description>
      <author>example@mail.com (Yuan Gao, Mattia Piccinini, Yuchen Zhang, Dingrui Wang, Korbinian Moller, Roberto Brusnicki, Baha Zarrouki, Alessio Gambi, Jan Frederik Totz, Kai Storms, Steven Peters, Andrea Stocco, Bassam Alrifaee, Marco Pavone, Johannes Betz)</author>
      <guid isPermaLink="false">2506.11526v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>FIGNN: Feature-Specific Interpretability for Graph Neural Network Surrogate Models</title>
      <link>http://arxiv.org/abs/2506.11398v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的图神经网络（GNN）架构，即特征特定可解释图神经网络（FIGNN），旨在提高科学应用中在无结构网格上定义的深度学习代理模型的可解释性。&lt;h4&gt;背景&lt;/h4&gt;传统的GNN在多元预测任务中往往掩盖了不同特征在空间上的独特影响。&lt;h4&gt;目的&lt;/h4&gt;增强深度学习代理模型的可解释性。&lt;h4&gt;方法&lt;/h4&gt;引入了特征特定的池化策略，允许对每个预测变量独立分配空间重要性，并在训练目标中加入了基于掩码的正则化项，以显式鼓励可解释性与预测误差之间的对齐，促进模型性能的局部归因。&lt;h4&gt;主要发现&lt;/h4&gt;FIGNN在两个物理上不同的系统（SPEEDY大气环流模型和向后-facing step（BFS）流体动力学基准）的代理建模中表现出竞争力，同时揭示了每个特征独特的物理意义上的空间模式。&lt;h4&gt;结论&lt;/h4&gt;FIGNN被证实是一个适用于复杂物理域中可解释代理建模的通用框架。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的图神经网络（GNN）架构，称为特征特定可解释图神经网络（FIGNN），旨在增强科学应用中在无结构网格上定义的深度学习代理模型的可解释性。传统的GNN在多元预测任务中往往掩盖了不同特征在空间上的独特影响。FIGNN通过引入特征特定的池化策略来解决这一限制，该策略允许对每个预测变量独立分配空间重要性。此外，在训练目标中加入了基于掩码的正则化项，以显式鼓励可解释性与预测误差之间的对齐，促进模型性能的局部归因。该方法在两个物理上不同的系统（SPEEDY大气环流模型和向后-facing step（BFS）流体动力学基准）的代理建模中进行了评估。结果表明，FIGNN在预测性能上具有竞争力，同时揭示了每个特征独特的物理意义上的空间模式。关于 rollout 稳定性、特征误差预算和空间掩码叠加的分析证实了FIGNN作为复杂物理域中可解释代理建模通用框架的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents a novel graph neural network (GNN) architecture, theFeature-specific Interpretable Graph Neural Network (FIGNN), designed toenhance the interpretability of deep learning surrogate models defined onunstructured grids in scientific applications. Traditional GNNs often obscurethe distinct spatial influences of different features in multivariateprediction tasks. FIGNN addresses this limitation by introducing afeature-specific pooling strategy, which enables independent attribution ofspatial importance for each predicted variable. Additionally, a mask-basedregularization term is incorporated into the training objective to explicitlyencourage alignment between interpretability and predictive error, promotinglocalized attribution of model performance. The method is evaluated forsurrogate modeling of two physically distinct systems: the SPEEDY atmosphericcirculation model and the backward-facing step (BFS) fluid dynamics benchmark.Results demonstrate that FIGNN achieves competitive predictive performancewhile revealing physically meaningful spatial patterns unique to each feature.Analysis of rollout stability, feature-wise error budgets, and spatial maskoverlays confirm the utility of FIGNN as a general-purpose framework forinterpretable surrogate modeling in complex physical domains.</description>
      <author>example@mail.com (Riddhiman Raut, Romit Maulik, Shivam Barwey)</author>
      <guid isPermaLink="false">2506.11398v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>TAViS: Text-bridged Audio-Visual Segmentation with Foundation Models</title>
      <link>http://arxiv.org/abs/2506.11436v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TAViS的新框架，用于解决音频-视觉分割（AVS）中的跨模态对齐问题。&lt;h4&gt;背景&lt;/h4&gt;当前音频-视觉分割方法在处理数据稀缺问题时，往往依赖于单一模态的知识或以现成方式结合基础模型，未能有效解决跨模态对齐的挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效结合多模态基础模型知识（ImageBind）和分割基础模型（SAM2）的框架，以实现精确的音频-视觉分割。&lt;h4&gt;方法&lt;/h4&gt;TAViS通过以下方式解决知识转移和监督不足的问题：(1) 引入文本桥接设计，包括一个文本桥接混合提示机制，其中伪文本提供类别原型信息，同时保留音频和视觉输入的模态特定细节；(2) 采用文本作为桥梁的归一化监督策略，以对齐音频-视觉模态中的共享语义概念。&lt;h4&gt;主要发现&lt;/h4&gt;TAViS在单源、多源和语义数据集上实现了优越的性能，并且在零样本设置中表现出色。&lt;h4&gt;结论&lt;/h4&gt;TAViS框架为音频-视觉分割提供了有效的解决方案，尤其是在跨模态对齐和数据稀缺的情况下。&lt;h4&gt;翻译&lt;/h4&gt;摘要：音频-视觉分割（AVS）面临着有效对齐音频和视觉模态的根本挑战。虽然最近的方法利用基础模型来应对数据稀缺问题，但它们通常依赖于单一模态的知识或以现成方式结合基础模型，未能解决跨模态对齐的挑战。在本文中，我们提出了一种名为TAViS的新框架，该框架将多模态基础模型（ImageBind）的知识与用于精确分割的分割基础模型（SAM2）相结合。然而，有效地结合这些模型提出了两个关键挑战：由于它们具有不同的特征空间，因此SAM2和ImageBind之间知识转移的困难，以及仅使用分割损失进行监督的不充分性。为了解决这些挑战，我们引入了一种文本桥接设计，包括两个关键组件：(1) 一个文本桥接混合提示机制，其中伪文本提供类别原型信息，同时保留音频和视觉输入的模态特定细节；(2) 一种利用文本作为桥梁的归一化监督策略，以对齐音频-视觉模态中的共享语义概念。我们的方法在单源、多源和语义数据集上实现了优越的性能，并且在零样本设置中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio-Visual Segmentation (AVS) faces a fundamental challenge of effectivelyaligning audio and visual modalities. While recent approaches leveragefoundation models to address data scarcity, they often rely on single-modalityknowledge or combine foundation models in an off-the-shelf manner, failing toaddress the cross-modal alignment challenge. In this paper, we present TAViS, anovel framework that \textbf{couples} the knowledge of multimodal foundationmodels (ImageBind) for cross-modal alignment and a segmentation foundationmodel (SAM2) for precise segmentation. However, effectively combining thesemodels poses two key challenges: the difficulty in transferring the knowledgebetween SAM2 and ImageBind due to their different feature spaces, and theinsufficiency of using only segmentation loss for supervision. To address thesechallenges, we introduce a text-bridged design with two key components: (1) atext-bridged hybrid prompting mechanism where pseudo text provides classprototype information while retaining modality-specific details from both audioand visual inputs, and (2) an alignment supervision strategy that leveragestext as a bridge to align shared semantic concepts within audio-visualmodalities. Our approach achieves superior performance on single-source,multi-source, semantic datasets, and excels in zero-shot settings.</description>
      <author>example@mail.com (Ziyang Luo, Nian Liu, Xuguang Yang, Salman Khan, Rao Muhammad Anwer, Hisham Cholakkal, Fahad Shahbaz Khan, Junwei Han)</author>
      <guid isPermaLink="false">2506.11436v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>EDN: A Novel Edge-Dependent Noise Model for Graph Data</title>
      <link>http://arxiv.org/abs/2506.11368v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了Edge-Dependent Noise (EDN)模型，该模型关注图数据中节点之间关系的边缘依赖性，并探讨了三种EDN变体，通过实验证明了其在图神经网络和噪声鲁棒算法中的有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的节点标签噪声模型如对称标签噪声（SLN）和类条件噪声（CCN）忽略了图数据中节点之间的重要关系。&lt;h4&gt;目的&lt;/h4&gt;研究边缘依赖噪声（EDN）模型，并探讨其在不同变体下的性能表现。&lt;h4&gt;方法&lt;/h4&gt;在流行的图数据集上使用5种不同的图神经网络（GNN）架构和8种噪声鲁棒算法进行实验，比较了不同EDN变体与传统的节点标签噪声模型在GNN和噪声鲁棒算法中的性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，两种EDN变体相较于传统的节点标签噪声模型，在GNN和噪声鲁棒算法中导致更大的性能下降。&lt;h4&gt;结论&lt;/h4&gt;EDN模型在评估图数据的噪声鲁棒算法时非常重要，可以提高在噪声环境中的图学习可靠性。&lt;h4&gt;翻译&lt;/h4&gt;An important structural feature of a graph is its set of edges, as it captures the relationships among the nodes (the graph's topology). Existing node label noise models like Symmetric Label Noise (SLN) and Class Conditional Noise (CCN) disregard this important node relationship in graph data; and the Edge-Dependent Noise (EDN) model addresses this limitation. EDN posits that in real-world scenarios, label noise may be influenced by the connections between nodes. We explore three variants of EDN. A crucial notion that relates nodes and edges in a graph is the degree of a node; we show that in all three variants, the probability of a node's label corruption is dependent on its degree. Additionally, we compare the dependence of these probabilities on node degree across different variants. We performed experiments on popular graph datasets using 5 different GNN architectures and 8 noise robust algorithms for graph data. The results demonstrate that 2 variants of EDN lead to greater performance degradation in both Graph Neural Networks (GNNs) and existing noise-robust algorithms, as compared to traditional node label noise models. We statistically verify this by posing a suitable hypothesis-testing problem. This emphasizes the importance of incorporating EDN when evaluating noise robust algorithms for graphs, to enhance the reliability of graph-based learning in noisy environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; An important structural feature of a graph is its set of edges, as itcaptures the relationships among the nodes (the graph's topology). Existingnode label noise models like Symmetric Label Noise (SLN) and Class ConditionalNoise (CCN) disregard this important node relationship in graph data; and theEdge-Dependent Noise (EDN) model addresses this limitation. EDN posits that inreal-world scenarios, label noise may be influenced by the connections betweennodes. We explore three variants of EDN. A crucial notion that relates nodesand edges in a graph is the degree of a node; we show that in all threevariants, the probability of a node's label corruption is dependent on itsdegree. Additionally, we compare the dependence of these probabilities on nodedegree across different variants. We performed experiments on popular graphdatasets using 5 different GNN architectures and 8 noise robust algorithms forgraph data. The results demonstrate that 2 variants of EDN lead to greaterperformance degradation in both Graph Neural Networks (GNNs) and existingnoise-robust algorithms, as compared to traditional node label noise models. Westatistically verify this by posing a suitable hypothesis-testing problem. Thisemphasizes the importance of incorporating EDN when evaluating noise robustalgorithms for graphs, to enhance the reliability of graph-based learning innoisy environments.</description>
      <author>example@mail.com (Pintu Kumar, Nandyala Hemachandra)</author>
      <guid isPermaLink="false">2506.11368v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>HyBiomass: Global Hyperspectral Imagery Benchmark Dataset for Evaluating Geospatial Foundation Models in Forest Aboveground Biomass Estimation</title>
      <link>http://arxiv.org/abs/2506.11314v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出一个全球分布的森林地上生物量（AGB）估计数据集，用于评估地理空间基础模型（Geo-FMs）的性能，并探讨了Geo-FMs在HSI应用中的地理偏差和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基准数据集主要限于分割或分类任务，且集中于特定地理区域。&lt;h4&gt;目的&lt;/h4&gt;通过引入全球分布的数据集，旨在促进Geo-FMs在HSI应用中的发展和评估。&lt;h4&gt;方法&lt;/h4&gt;数据集结合了来自EnMAP卫星的共定位高光谱图像（HSI）和来自全球生态系统动态调查激光雷达的AGB密度估计预测，覆盖七个大陆地区。&lt;h4&gt;主要发现&lt;/h4&gt;Geo-FMs的性能可以与基线U-Net相匹配，甚至在某些情况下超越U-Net，尤其是在微调编码器时。U-Net与Geo-FMs之间的性能差异取决于每个地区的数据集大小，并强调了Vision Transformer骨干网络中token patch大小对像素级回归任务准确预测的重要性。&lt;h4&gt;结论&lt;/h4&gt;通过发布这个全球分布的高光谱基准数据集，可以促进Geo-FMs的发展与评估，并有助于研究Geo-FMs的地理偏差和泛化能力。数据集和源代码将公开提供。&lt;h4&gt;翻译&lt;/h4&gt;Comprehensive evaluation of geospatial foundation models (Geo-FMs) requires benchmarking across diverse tasks, sensors, and geographic regions. However, most existing benchmark datasets are limited to segmentation or classification tasks, and focus on specific geographic areas. To address this gap, we introduce a globally distributed dataset for forest aboveground biomass (AGB) estimation, a pixel-wise regression task. This benchmark dataset combines co-located hyperspectral imagery (HSI) from the Environmental Mapping and Analysis Program (EnMAP) satellite and predictions of AGB density estimates derived from the Global Ecosystem Dynamics Investigation lidars, covering seven continental regions. Our experimental results on this dataset demonstrate that the evaluated Geo-FMs can match or, in some cases, surpass the performance of a baseline U-Net, especially when fine-tuning the encoder. We also find that the performance difference between the U-Net and Geo-FMs depends on the dataset size for each region and highlight the importance of the token patch size in the Vision Transformer backbone for accurate predictions in pixel-wise regression tasks. By releasing this globally distributed hyperspectral benchmark dataset, we aim to facilitate the development and evaluation of Geo-FMs for HSI applications. Leveraging this dataset additionally enables research into geographic bias and generalization capacity of Geo-FMs. The dataset and source code will be made publicly available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Comprehensive evaluation of geospatial foundation models (Geo-FMs) requiresbenchmarking across diverse tasks, sensors, and geographic regions. However,most existing benchmark datasets are limited to segmentation or classificationtasks, and focus on specific geographic areas. To address this gap, weintroduce a globally distributed dataset for forest aboveground biomass (AGB)estimation, a pixel-wise regression task. This benchmark dataset combinesco-located hyperspectral imagery (HSI) from the Environmental Mapping andAnalysis Program (EnMAP) satellite and predictions of AGB density estimatesderived from the Global Ecosystem Dynamics Investigation lidars, covering sevencontinental regions. Our experimental results on this dataset demonstrate thatthe evaluated Geo-FMs can match or, in some cases, surpass the performance of abaseline U-Net, especially when fine-tuning the encoder. We also find that theperformance difference between the U-Net and Geo-FMs depends on the datasetsize for each region and highlight the importance of the token patch size inthe Vision Transformer backbone for accurate predictions in pixel-wiseregression tasks. By releasing this globally distributed hyperspectralbenchmark dataset, we aim to facilitate the development and evaluation ofGeo-FMs for HSI applications. Leveraging this dataset additionally enablesresearch into geographic bias and generalization capacity of Geo-FMs. Thedataset and source code will be made publicly available.</description>
      <author>example@mail.com (Aaron Banze, Timothée Stassin, Nassim Ait Ali Braham, Rıdvan Salih Kuzu, Simon Besnard, Michael Schmitt)</author>
      <guid isPermaLink="false">2506.11314v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Lifting Data-Tracing Machine Unlearning to Knowledge-Tracing for Foundation Models</title>
      <link>http://arxiv.org/abs/2506.11253v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将数据追踪机器反学习提升到知识追踪的方法，用于基础模型（FMs）。&lt;h4&gt;背景&lt;/h4&gt;数据所有者可能会撤销允许模型从数据中学习的决定，导致机器反学习需求。目前，数据追踪无法满足对FMs多样化的反学习请求。&lt;h4&gt;目的&lt;/h4&gt;提出基于实际需求和认知研究洞察的方法，使FMs的反学习请求更方便地被提出。&lt;h4&gt;方法&lt;/h4&gt;提出知识追踪的机器反学习范式，并提供了关于视觉语言FMs的具体案例研究。&lt;h4&gt;主要发现&lt;/h4&gt;知识追踪的反学习与人类大脑遗忘过程更为吻合，且对于无权访问FMs大量训练数据的各方（如监管机构、企业用户、产品团队等）更为便利。&lt;h4&gt;结论&lt;/h4&gt;知识追踪机器反学习可以更好地满足FMs的反学习需求，并更贴近人类大脑的遗忘机制。&lt;h4&gt;翻译&lt;/h4&gt;Machine unlearning removes certain training data points and their influence on AI models (e.g., when a data owner revokes their decision to allow models to learn from the data). In this position paper, we propose to lift data-tracing machine unlearning to knowledge-tracing for foundation models (FMs). We support this position based on practical needs and insights from cognitive studies. Practically, tracing data cannot meet the diverse unlearning requests for FMs, which may be from regulators, enterprise users, product teams, etc., having no access to FMs' massive training data. Instead, it is convenient for these parties to issue an unlearning request about the knowledge or capability FMs (should not) possess. Cognitively, knowledge-tracing unlearning aligns with how the human brain forgets more closely than tracing individual training data points. Finally, we provide a concrete case study about a vision-language FM to illustrate how an unlearner might instantiate the knowledge-tracing machine unlearning paradigm.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine unlearning removes certain training data points and their influenceon AI models (e.g., when a data owner revokes their decision to allow models tolearn from the data). In this position paper, we propose to lift data-tracingmachine unlearning to knowledge-tracing for foundation models (FMs). We supportthis position based on practical needs and insights from cognitive studies.Practically, tracing data cannot meet the diverse unlearning requests for FMs,which may be from regulators, enterprise users, product teams, etc., having noaccess to FMs' massive training data. Instead, it is convenient for theseparties to issue an unlearning request about the knowledge or capability FMs(should not) possess. Cognitively, knowledge-tracing unlearning aligns with howthe human brain forgets more closely than tracing individual training datapoints. Finally, we provide a concrete case study about a vision-language FM toillustrate how an unlearner might instantiate the knowledge-tracing machineunlearning paradigm.</description>
      <author>example@mail.com (Yuwen Tan, Boqing Gong)</author>
      <guid isPermaLink="false">2506.11253v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>HEIST: A Graph Foundation Model for Spatial Transcriptomics and Proteomics Data</title>
      <link>http://arxiv.org/abs/2506.11152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;HEIST是一种基于层次图变换器的基础模型，用于处理空间转录组和蛋白质组数据，旨在通过上下文化的细胞和基因表示来理解细胞异质性和转录调控。&lt;h4&gt;背景&lt;/h4&gt;单细胞转录组学已成为生物学数据驱动洞察的重要来源，而空间转录组数据提供了细胞的空间坐标和转录组读数，有助于在组织背景下了解细胞。&lt;h4&gt;目的&lt;/h4&gt;开发一个模型来创建从空间转录组数据中获取的细胞和基因的上下文化表示，以更好地理解细胞异质性和转录调控。&lt;h4&gt;方法&lt;/h4&gt;HEIST模型将组织建模为空间细胞邻域图，每个细胞被建模为基因调控网络图，并使用层次图变换器进行跨层消息传递和层内消息传递。该模型通过空间感知对比学习和掩码自动编码目标进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;HEIST能够有效编码细胞嵌入中的微环境影响，发现先前模型未能区分的空间信息子群。在临床结果预测、细胞类型注释、基因插补和基于空间信息的细胞聚类等下游任务中，HEIST取得了最先进的成果。&lt;h4&gt;结论&lt;/h4&gt;层次建模和基于基因调控网络（GRN）的表示对于理解空间转录组数据中的细胞异质性和转录调控至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single-cell transcriptomics has become a great source for data-driveninsights into biology, enabling the use of advanced deep learning methods tounderstand cellular heterogeneity and transcriptional regulation at thesingle-cell level. With the advent of spatial transcriptomics data we have thepromise of learning about cells within a tissue context as it provides bothspatial coordinates and transcriptomic readouts. However, existing modelseither ignore spatial resolution or the gene regulatory information. Generegulation in cells can change depending on microenvironmental cues fromneighboring cells, but existing models neglect gene regulatory patterns withhierarchical dependencies across levels of abstraction. In order to createcontextualized representations of cells and genes from spatial transcriptomicsdata, we introduce HEIST, a hierarchical graph transformer-based foundationmodel for spatial transcriptomics and proteomics data. HEIST models tissue asspatial cellular neighborhood graphs, and each cell is, in turn, modeled as agene regulatory network graph. The framework includes a hierarchical graphtransformer that performs cross-level message passing and message passingwithin levels. HEIST is pre-trained on 22.3M cells from 124 tissues across 15organs using spatially-aware contrastive learning and masked auto-encodingobjectives. Unsupervised analysis of HEIST representations of cells, shows thatit effectively encodes the microenvironmental influences in cell embeddings,enabling the discovery of spatially-informed subpopulations that prior modelsfail to differentiate. Further, HEIST achieves state-of-the-art results on fourdownstream task such as clinical outcome prediction, cell type annotation, geneimputation, and spatially-informed cell clustering across multipletechnologies, highlighting the importance of hierarchical modeling andGRN-based representations.</description>
      <author>example@mail.com (Hiren Madhu, João Felipe Rocha, Tinglin Huang, Siddharth Viswanath, Smita Krishnaswamy, Rex Ying)</author>
      <guid isPermaLink="false">2506.11152v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Modeling of CRISPR-Cas12 Activity Using Foundation Models and Chromatin Accessibility Data</title>
      <link>http://arxiv.org/abs/2506.11182v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This manuscript has been accepted by ICML workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用预训练的生物基础模型来提高gRNA活性预测的准确性，并探讨了整合染色质可及性数据对预测性能的提升。&lt;h4&gt;背景&lt;/h4&gt;预测gRNA活性对于有效的CRISPR-Cas12基因组编辑至关重要，但由于数据有限、PAMs（Cas结合的短序列要求）的变异以及依赖大规模训练，这一任务仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;研究是否可以通过在转录组数据上预训练的生物基础模型来改善gRNA活性的估计，即使没有特定领域的预训练。&lt;h4&gt;方法&lt;/h4&gt;使用现有RNA基础模型的嵌入作为轻量级回归器的输入，并整合染色质可及性数据以捕获调控环境。&lt;h4&gt;主要发现&lt;/h4&gt;使用预训练的基础模型和染色质可及性数据，在gRNA活性预测方面取得了显著的提升，超过了传统的基线方法。&lt;h4&gt;结论&lt;/h4&gt;预训练的基础模型和染色质可及性数据对于gRNA活性预测是有效的。&lt;h4&gt;翻译&lt;/h4&gt;Predicting guide RNA (gRNA) activity is critical for effective CRISPR-Cas12 genome editing but remains challenging due to limited data, variation across protospacer adjacent motifs (PAMs - short sequence requirements for Cas binding), and reliance on large-scale training. We investigate whether pre-trained biological foundation model originally trained on transcriptomic data can improve gRNA activity estimation even without domain-specific pre-training. Using embeddings from existing RNA foundation model as input to lightweight regressor, we show substantial gains over traditional baselines. We also integrate chromatin accessibility data to capture regulatory context, improving performance further. Our results highlight the effectiveness of pre-trained foundation models and chromatin accessibility data for gRNA activity prediction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting guide RNA (gRNA) activity is critical for effective CRISPR-Cas12genome editing but remains challenging due to limited data, variation acrossprotospacer adjacent motifs (PAMs-short sequence requirements for Cas binding),and reliance on large-scale training. We investigate whether pre-trainedbiological foundation model originally trained on transcriptomic data canimprove gRNA activity estimation even without domain-specific pre-training.Using embeddings from existing RNA foundation model as input to lightweightregressor, we show substantial gains over traditional baselines. We alsointegrate chromatin accessibility data to capture regulatory context, improvingperformance further. Our results highlight the effectiveness of pre-trainedfoundation models and chromatin accessibility data for gRNA activityprediction.</description>
      <author>example@mail.com (Azim Dehghani Amirabad, Yanfei Zhang, Artem Moskalev, Sowmya Rajesh, Tommaso Mansi, Shuwei Li, Mangal Prakash, Rui Liao)</author>
      <guid isPermaLink="false">2506.11182v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Towards a general-purpose foundation model for fMRI analysis</title>
      <link>http://arxiv.org/abs/2506.11167v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了NeuroSTORM，一个从4D fMRI体积直接学习的通用框架，提高了fMRI分析的可重复性和可迁移性。&lt;h4&gt;背景&lt;/h4&gt;fMRI对于研究脑功能和诊断神经系统疾病至关重要，但现有的分析方法由于复杂的预处理和特定任务的模型而面临可重复性和可迁移性问题。&lt;h4&gt;目的&lt;/h4&gt;提出NeuroSTORM框架，以提高fMRI分析的可重复性和可迁移性。&lt;h4&gt;方法&lt;/h4&gt;NeuroSTORM在来自超过50,000名受试者（年龄5至100岁）的28.65百万个fMRI帧（&gt;9,000小时）上预训练，使用Mamba骨干网络和移位扫描策略高效处理4D体积，并提出空间-时间优化预训练方法和特定任务提示调优。&lt;h4&gt;主要发现&lt;/h4&gt;NeuroSTORM在五个任务上优于现有方法，包括年龄/性别预测、表型预测、疾病诊断、fMRI到图像检索和基于任务的fMRI分类。在来自美国、韩国和澳大利亚的医院数据集上表现出强大的临床实用性，在疾病诊断和认知表型预测中取得了最佳性能。&lt;h4&gt;结论&lt;/h4&gt;NeuroSTORM提供了一个标准化、开源的基础模型，以改善基于fMRI的临床研究中的可重复性和可迁移性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Functional Magnetic Resonance Imaging (fMRI) is essential for studying brainfunction and diagnosing neurological disorders, but current analysis methodsface reproducibility and transferability issues due to complex pre-processingand task-specific models. We introduce NeuroSTORM (Neuroimaging FoundationModel with Spatial-Temporal Optimized Representation Modeling), a generalizableframework that directly learns from 4D fMRI volumes and enables efficientknowledge transfer across diverse applications. NeuroSTORM is pre-trained on28.65 million fMRI frames (&gt;9,000 hours) from over 50,000 subjects acrossmultiple centers and ages 5 to 100. Using a Mamba backbone and a shiftedscanning strategy, it efficiently processes full 4D volumes. We also propose aspatial-temporal optimized pre-training approach and task-specific prompttuning to improve transferability. NeuroSTORM outperforms existing methodsacross five tasks: age/gender prediction, phenotype prediction, diseasediagnosis, fMRI-to-image retrieval, and task-based fMRI classification. Itdemonstrates strong clinical utility on datasets from hospitals in the U.S.,South Korea, and Australia, achieving top performance in disease diagnosis andcognitive phenotype prediction. NeuroSTORM provides a standardized, open-sourcefoundation model to improve reproducibility and transferability in fMRI-basedclinical research.</description>
      <author>example@mail.com (Cheng Wang, Yu Jiang, Zhihao Peng, Chenxin Li, Changbae Bang, Lin Zhao, Jinglei Lv, Jorge Sepulcre, Carl Yang, Lifang He, Tianming Liu, Daniel Barron, Quanzheng Li, Randy Hirschtick, Byung-Hoon Kim, Xiang Li, Yixuan Yuan)</author>
      <guid isPermaLink="false">2506.11167v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Evidential Spectrum-Aware Contrastive Learning for OOD Detection in Dynamic Graphs</title>
      <link>http://arxiv.org/abs/2506.07417v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ECML-PKDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了动态图中的分布外检测问题，提出了一种基于证据深度学习的OOD检测器EviSEC，通过证据光谱对比学习提高了检测效果。&lt;h4&gt;背景&lt;/h4&gt;当前OOD检测方法主要针对静态图，存在单点估计导致的偏差和方差高，以及缺乏OOD训练数据导致的分数同质化问题。&lt;h4&gt;目的&lt;/h4&gt;解决动态图中OOD检测的偏差、方差和分数同质化问题。&lt;h4&gt;方法&lt;/h4&gt;提出EviSEC，通过设计证据神经网络和光谱增强模块，利用后验狄利克雷分布来解释输入的随机性，并生成OOD近似以识别高分数模式。&lt;h4&gt;主要发现&lt;/h4&gt;EviSEC在真实世界数据集上有效检测动态图中的OOD样本。&lt;h4&gt;结论&lt;/h4&gt;EviSEC能够有效解决动态图中OOD检测的挑战，为安全敏感领域提供了一种有效的检测方法。&lt;h4&gt;翻译&lt;/h4&gt;Recently, Out-of-distribution (OOD) detection in dynamic graphs, which aims to identify whether incoming data deviates from the distribution of the in-distribution (ID) training set, has garnered considerable attention in security-sensitive fields. Current OOD detection paradigms primarily focus on static graphs and confront two critical challenges: i) high bias and high variance caused by single-point estimation, which makes the predictions sensitive to randomness in the data; ii) score homogenization resulting from the lack of OOD training data, where the model only learns ID-specific patterns, resulting in overall low OOD scores and a narrow score gap between ID and OOD data. To tackle these issues, we first investigate OOD detection in dynamic graphs through the lens of Evidential Deep Learning (EDL). Specifically, we propose EviSEC, an innovative and effective OOD detector via Evidential Spectrum-awarE Contrastive Learning. We design an evidential neural network to redefine the output as the posterior Dirichlet distribution, explaining the randomness of inputs through the uncertainty of distribution, which is overlooked by single-point estimation. Moreover, spectrum-awareaugmentation module generates OOD approximations to identify patterns with high OOD scores, thereby widening the score gap between ID and OOD data and mitigating score homogenization. Extensive experiments on real-world datasets demonstrate that EviSAC effectively detects OOD samples in dynamic graphs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/sunnan191/evisec&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Out-of-distribution (OOD) detection in dynamic graphs, which aimsto identify whether incoming data deviates from the distribution of thein-distribution (ID) training set, has garnered considerable attention insecurity-sensitive fields. Current OOD detection paradigms primarily focus onstatic graphs and confront two critical challenges: i) high bias and highvariance caused by single-point estimation, which makes the predictionssensitive to randomness in the data; ii) score homogenization resulting fromthe lack of OOD training data, where the model only learns ID-specificpatterns, resulting in overall low OOD scores and a narrow score gap between IDand OOD data. To tackle these issues, we first investigate OOD detection indynamic graphs through the lens of Evidential Deep Learning (EDL).Specifically, we propose EviSEC, an innovative and effective OOD detector viaEvidential Spectrum-awarE Contrastive Learning. We design an evidential neuralnetwork to redefine the output as the posterior Dirichlet distribution,explaining the randomness of inputs through the uncertainty of distribution,which is overlooked by single-point estimation. Moreover, spectrum-awareaugmentation module generates OOD approximations to identify patterns with highOOD scores, thereby widening the score gap between ID and OOD data andmitigating score homogenization. Extensive experiments on real-world datasetsdemonstrate that EviSAC effectively detects OOD samples in dynamic graphs.</description>
      <author>example@mail.com (Nan Sun, Xixun Lin, Zhiheng Zhou, Yanmin Shang, Zhenlin Cheng, Yanan Cao)</author>
      <guid isPermaLink="false">2506.07417v2</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Synthetic Geology -- Structural Geology Meets Deep Learning</title>
      <link>http://arxiv.org/abs/2506.11164v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 8 figures, submitted to "Communications Earth &amp;  Environment", geological simulation code at  https://doi.org/10.5281/zenodo.15244035, generative AI code at  https://github.com/chipnbits/flowtrain_stochastic_interpolation/releases/tag/v1.0.0&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;通过深度学习，可视化地球表面以下几公里的地下结构成为可能，该方法通过结合生成式人工智能技术和合成数据生成器，从地表地质数据中生成三维地下区域图像。&lt;h4&gt;背景&lt;/h4&gt;可视化地球表面以下结构对于众多应用至关重要，但目前面临的主要挑战是地下数据的可获得性。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，通过神经网络训练，将地表地质数据与钻孔数据扩展到三维地下区域。&lt;h4&gt;方法&lt;/h4&gt;结合生成式人工智能技术，训练神经网络，并设计合成数据生成器，模拟地质活动，生成大量样本。&lt;h4&gt;主要发现&lt;/h4&gt;基于合成数据的模型能够从未见过的地表地形和地质图生成3D地下图像，随着钻孔数据的增加，图像的准确性提高，并能描绘地层、断层、褶皱、岩墙和岩床等结构。&lt;h4&gt;结论&lt;/h4&gt;这种合成岩壳生成器与训练好的神经网络模型的组合具有早期潜力，最终模型将在特定区域的数据上进行微调，不仅适用于资源勘探、灾害评估和岩土工程，还可以作为人工智能正则化器应用于传统的反问题应用中。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visualizing the first few kilometers of the Earth's subsurface, along-standing challenge gating a virtually inexhaustible list of importantapplications, is coming within reach through deep learning. Building ontechniques of generative artificial intelligence applied to voxelated images,we demonstrate a method that extends surface geological data supplemented byboreholes to a three-dimensional subsurface region by training a neuralnetwork. The Earth's land area having been extensively mapped for geologicalfeatures, the bottleneck of this or any related technique is the availabilityof data below the surface. We close this data gap in the development ofsubsurface deep learning by designing a synthetic data-generator process thatmimics eons of geological activity such as sediment compaction, volcanicintrusion, and tectonic dynamics to produce a virtually limitless number ofsamples of the near lithosphere. A foundation model trained on such syntheticdata is able to generate a 3D image of the subsurface from a previously unseenmap of surface topography and geology, showing increasing fidelity withincreasing access to borehole data, depicting such structures as layers,faults, folds, dikes, and sills. We illustrate the early promise of thecombination of a synthetic lithospheric generator with a trained neural networkmodel using generative flow matching. Ultimately, such models will befine-tuned on data from applicable campaigns, such as mineral prospecting in agiven region. Though useful in itself, a regionally fine-tuned models may beemployed not as an end but as a means: as an AI-based regularizer in a moretraditional inverse problem application, in which the objective functionrepresents the mismatch of additional data with physical models withapplications in resource exploration, hazard assessment, and geotechnicalengineering.</description>
      <author>example@mail.com (Simon Ghyselincks, Valeriia Okhmak, Stefano Zampini, George Turkiyyah, David Keyes, Eldad Haber)</author>
      <guid isPermaLink="false">2506.11164v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Joint Beamforming and Resource Allocation for Delay Optimization in RIS-Assisted OFDM Systems: A DRL Approach</title>
      <link>http://arxiv.org/abs/2506.03586v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在下行可重构智能表面（RIS）辅助的正交频分复用（OFDM）系统中，联合相位设计和资源分配问题，以优化平均延迟，其中每个用户的数据包到达基站是随机的。&lt;h4&gt;背景&lt;/h4&gt;该优化问题本质上是马尔可夫决策过程（MDP），属于强化学习的范畴。&lt;h4&gt;目的&lt;/h4&gt;为了有效地处理混合动作空间并降低状态空间维度，提出了一种混合深度强化学习（DRL）方法。&lt;h4&gt;方法&lt;/h4&gt;具体使用近端策略优化（PPO）-θ优化RIS相位偏移设计，而PPO-N负责子载波分配决策。为了进一步减轻子载波分配相关的维度灾难，引入了多智能体策略以更有效地优化子载波分配指标。此外，为了实现更适应的资源分配和准确捕捉网络动态，将与平均延迟密切相关的关键因素，包括缓冲区中积压的数据包数量和当前数据包到达情况，纳入状态空间。还引入了迁移学习框架以提高训练效率和加速收敛。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，所提出的算法显著降低了平均延迟，提高了资源分配效率，与基线方法相比，实现了更优的系统鲁棒性和公平性。&lt;h4&gt;结论&lt;/h4&gt;该算法在优化平均延迟、资源分配效率以及系统性能方面具有显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates a joint phase design and resource allocation problemin downlink reconfigurable intelligent surface (RIS)-assisted orthogonalfrequency division multiplexing (OFDM) systems to optimize average delay, wheredata packets for each user arrive at the base station stochastically. Thesequential optimization problem is inherently a Markov decision process (MDP),making it fall within the scope of reinforcement learning. To effectivelyhandle the mixed action space and reduce the state space dimensionality, ahybrid deep reinforcement learning (DRL) approach is proposed. Specifically,proximal policy optimization (PPO)-$\Theta$ is employed to optimize RIS phaseshift design, while PPO-N is responsible for subcarrier allocation decisions.To further mitigate the curse of dimensionality associated with subcarrierallocation, a multi-agent strategy is introduced to optimize subcarrierallocation indicater more efficiently. Moreover, to achieve more adaptiveresource allocation and accurately capture network dynamics, key factorsclosely related to average delay, including the number of backlogged packets inbuffers and the current packet arrivals, are incorporated into the state space.Furthermore, a transfer learning framework is introduced to enhance trainingefficiency and accelerate convergence. Simulation results demonstrate that theproposed algorithm significantly reduces average delay, enhances resourceallocation efficiency, and achieves superior system robustness and fairnesscompared to baseline methods.</description>
      <author>example@mail.com (Yu Ma, Chongtao Guo, Le Liang, Xiao Li, Shi Jin)</author>
      <guid isPermaLink="false">2506.03586v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
  <item>
      <title>Learnable Spatial-Temporal Positional Encoding for Link Prediction</title>
      <link>http://arxiv.org/abs/2506.08309v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML 2025. 28 pages, 1 figures, 22 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为L-STEP的简单时间链接预测模型，旨在解决现有位置编码方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;当前位置编码在适应复杂属性图、考虑实时拓扑和特征信息、以及在大型结构数据上应用注意力机制方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;开发一种有效且高效的学习性时空位置编码方法。&lt;h4&gt;方法&lt;/h4&gt;L-STEP模型包括以下特点：(1) 证明了所提出的位置学习方案可以从时空谱的角度保持图属性；(2) 验证了MLP可以充分利用表达性并达到在该编码上的Transformer性能；(3) 通过改变不同的初始位置编码输入来展示其鲁棒性；(4) 分析了理论复杂度并获得了比SOTA更少的经验运行时间；(5) 在13个经典数据集上使用10种算法在归纳和归纳设置中展示了其时间链接预测的优势，并使用3种不同的采样策略。&lt;h4&gt;主要发现&lt;/h4&gt;L-STEP在最新的大规模TGB基准测试中取得了领先性能。&lt;h4&gt;结论&lt;/h4&gt;L-STEP模型能够有效解决现有位置编码方法的局限性，并在时间链接预测任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Accurate predictions rely on the expressiveness power of graph deep learning frameworks like graph neural networks and graph transformers, where positional encoding mechanism has become much more indispensable in recent state-of-the-art works to record the canonical position information. However, the current positional encoding is limited in three aspects: (1) most positional encoding methods use pre-defined, and fixed functions, which are inadequate to adapt to the complex attributed graphs; (2) a few pioneering works proposed the learnable positional encoding but are still limited to the structural information, not considering the real-world time-evolving topological and feature information; (3) most positional encoding methods are equipped with transformers' attention mechanism to fully leverage their capabilities, where the dense or relational attention is often unaffordable on large-scale structured data. Hence, we aim to develop Learnable Spatial-Temporal Positional Encoding in an effective and efficient manner and propose a simple temporal link prediction model named L-STEP. Briefly, for L-STEP, we (1) prove the proposed positional learning scheme can preserve the graph property from the spatial-temporal spectral viewpoint, (2) verify that MLPs can fully exploit the expressiveness and reach transformers' performance on that encoding, (3) change different initial positional encoding inputs to show robustness, (4) analyze the theoretical complexity and obtain less empirical running time than SOTA, and (5) demonstrate its temporal link prediction out-performance on 13 classic datasets and with 10 algorithms in both transductive and inductive settings using 3 different sampling strategies. Also, the proposed method obtains the leading performance in the newest large-scale TGB benchmark. Our code is available at https://github.com/kthrn22/L-STEP.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate predictions rely on the expressiveness power of graph deep learningframeworks like graph neural networks and graph transformers, where apositional encoding mechanism has become much more indispensable in recentstate-of-the-art works to record the canonical position information. However,the current positional encoding is limited in three aspects: (1) mostpositional encoding methods use pre-defined, and fixed functions, which areinadequate to adapt to the complex attributed graphs; (2) a few pioneeringworks proposed the learnable positional encoding but are still limited to thestructural information, not considering the real-world time-evolvingtopological and feature information; (3) most positional encoding methods areequipped with transformers' attention mechanism to fully leverage theircapabilities, where the dense or relational attention is often unaffordable onlarge-scale structured data. Hence, we aim to develop LearnableSpatial-Temporal Positional Encoding in an effective and efficient manner andpropose a simple temporal link prediction model named L-STEP. Briefly, forL-STEP, we (1) prove the proposed positional learning scheme can preserve thegraph property from the spatial-temporal spectral viewpoint, (2) verify thatMLPs can fully exploit the expressiveness and reach transformers' performanceon that encoding, (3) change different initial positional encoding inputs toshow robustness, (4) analyze the theoretical complexity and obtain lessempirical running time than SOTA, and (5) demonstrate its temporal linkprediction out-performance on 13 classic datasets and with 10 algorithms inboth transductive and inductive settings using 3 different sampling strategies.Also, \name\ obtains the leading performance in the newest large-scale TGBbenchmark. Our code is available at https://github.com/kthrn22/L-STEP.</description>
      <author>example@mail.com (Katherine Tieu, Dongqi Fu, Zihao Li, Ross Maciejewski, Jingrui He)</author>
      <guid isPermaLink="false">2506.08309v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Instance-Based Transfer Learning with Similarity-Aware Subject Selection for Cross-Subject SSVEP-Based BCIs</title>
      <link>http://arxiv.org/abs/2506.10933v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE Journal of Biomedical and Health Informatics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于实例的与任务相关的成分分析（iTRCA）的迁移学习框架，用于提高SSVEP-BCI的识别准确率，并减少目标受试者的数据需求。&lt;h4&gt;背景&lt;/h4&gt;SSVEP-BCI可以通过足够的训练数据实现高识别准确率，而迁移学习可以通过利用源受试者的数据来减轻目标受试者的数据需求。然而，处理目标和源受试者之间的个体差异仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的迁移学习框架，以减轻目标受试者的数据需求，同时考虑个体差异。&lt;h4&gt;方法&lt;/h4&gt;iTRCA提取两种类型的特征：1）主题通用特征，捕捉源和目标受试者在共同潜在空间中的共享信息；2）主题特定特征，保留目标受试者的独特特征。为了减轻负迁移，设计了基于主题选择的iTRCA（SS-iTRCA），该框架集成了一种基于相似性的主题选择策略，以识别适合迁移的源受试者。&lt;h4&gt;主要发现&lt;/h4&gt;在Benchmark、BETA和自收集数据集上的比较评估表明，所提出的iTRCA和SS-iTRCA框架是有效的。&lt;h4&gt;结论&lt;/h4&gt;本研究为开发高性能的SSVEP-BCI提供了减少目标受试者数据的潜在解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Steady-state visual evoked potential (SSVEP)-based brain-computer interfaces(BCIs) can achieve high recognition accuracy with sufficient training data. Transfer learning presents a promising solution to alleviate data requirements for the target subject by leveraging data from source subjects; however, effectively addressing individual variability among both target and source subjects remains a challenge. This paper proposes a novel transfer learning framework, termed instance-based task-related component analysis (iTRCA), which leverages knowledge from source subjects while considering their individual contributions. iTRCA extracts two types of features: (1) the subject-general feature, capturing shared information between source and target subjects in a common latent space, and (2) the subject-specific feature, preserving the unique characteristics of the target subject. To mitigate negative transfer, we further design an enhanced framework, subject selection-based iTRCA (SS-iTRCA), which integrates a similarity-based subject selection strategy to identify appropriate source subjects for transfer based on their task-related components (TRCs). Comparative evaluations on the Benchmark, BETA, and a self-collected dataset demonstrate the effectiveness of the proposed iTRCA and SS-iTRCA frameworks. This study provides a potential solution for developing high-performance SSVEP-based BCIs with reduced target subject data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/JBHI.2025.3577813&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Steady-state visual evoked potential (SSVEP)-based brain-computer interfaces(BCIs) can achieve high recognition accuracy with sufficient training data.Transfer learning presents a promising solution to alleviate data requirementsfor the target subject by leveraging data from source subjects; however,effectively addressing individual variability among both target and sourcesubjects remains a challenge. This paper proposes a novel transfer learningframework, termed instance-based task-related component analysis (iTRCA), whichleverages knowledge from source subjects while considering their individualcontributions. iTRCA extracts two types of features: (1) the subject-generalfeature, capturing shared information between source and target subjects in acommon latent space, and (2) the subject-specific feature, preserving theunique characteristics of the target subject. To mitigate negative transfer, wefurther design an enhanced framework, subject selection-based iTRCA (SS-iTRCA),which integrates a similarity-based subject selection strategy to identifyappropriate source subjects for transfer based on their task-related components(TRCs). Comparative evaluations on the Benchmark, BETA, and a self-collecteddataset demonstrate the effectiveness of the proposed iTRCA and SS-iTRCAframeworks. This study provides a potential solution for developinghigh-performance SSVEP-based BCIs with reduced target subject data.</description>
      <author>example@mail.com (Ziwen Wang, Yue Zhang, Zhiqiang Zhang, Sheng Quan Xie, Alexander Lanzon, William P. Heath, Zhenhong Li)</author>
      <guid isPermaLink="false">2506.10933v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Spurious Rewards: Rethinking Training Signals in RLVR</title>
      <link>http://arxiv.org/abs/2506.10947v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;强化学习与可验证奖励（RLVR）可以在某些模型中激发强烈的数学推理能力，即使奖励与正确答案的相关性很小、没有或甚至为负。&lt;h4&gt;背景&lt;/h4&gt;研究背景是强化学习与可验证奖励（RLVR）的应用，以及它在数学推理能力提升方面的潜力。&lt;h4&gt;目的&lt;/h4&gt;目的在于验证RLVR在数学推理任务中的效果，并探讨其在不同模型上的表现。&lt;h4&gt;方法&lt;/h4&gt;通过在Qwen2.5-Math-7B模型上应用RLVR，并使用不同类型的奖励（随机奖励、格式奖励、错误标签、1次强化学习、多数投票）进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;主要发现包括：1. RLVR在Qwen2.5-Math-7B模型上显著提升了MATH-500性能；2. RLVR在Qwen模型上提高了代码推理的频率；3. RLVR在Qwen模型上取得的性能提升接近使用真实奖励时的提升，但在其他模型如Llama3或OLMo2上效果不佳。&lt;h4&gt;结论&lt;/h4&gt;结论是，RLVR能够在某些模型中提升数学推理能力，即使在没有有效奖励信号的情况下，它也能揭示预训练期间学习到的有用推理表示。未来研究应考虑在更多样化的模型上验证RLVR的效果。&lt;h4&gt;翻译&lt;/h4&gt;We show that reinforcement learning with verifiable rewards (RLVR) can elicit strong mathematical reasoning in certain models even with spurious rewards that have little, no, or even negative correlation with the correct answer. For example, RLVR improves MATH-500 performance for Qwen2.5-Math-7B in absolute points by 21.4% (random reward), 13.8% (format reward), 24.1% (incorrect label), 26.0% (1-shot RL), and 27.1% (majority voting) -- nearly matching the 29.1% gained with ground truth rewards. However, the spurious rewards that work for Qwen often fail to yield gains with other model families like Llama3 or OLMo2. In particular, we find code reasoning -- thinking in code without actual code execution -- to be a distinctive Qwen2.5-Math behavior that becomes significantly more frequent after RLVR, from 65% to over 90%, even with spurious rewards. Overall, we hypothesize that, given the lack of useful reward signal, RLVR must somehow be surfacing useful reasoning representations learned during pretraining, although the exact mechanism remains a topic for future work. We suggest that future RLVR research should possibly be validated on diverse models rather than a single de facto choice, as we show that it is easy to get significant performance gains on Qwen models even with completely spurious reward signals.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We show that reinforcement learning with verifiable rewards (RLVR) can elicitstrong mathematical reasoning in certain models even with spurious rewards thathave little, no, or even negative correlation with the correct answer. Forexample, RLVR improves MATH-500 performance for Qwen2.5-Math-7B in absolutepoints by 21.4% (random reward), 13.8% (format reward), 24.1% (incorrectlabel), 26.0% (1-shot RL), and 27.1% (majority voting) -- nearly matching the29.1% gained with ground truth rewards. However, the spurious rewards that workfor Qwen often fail to yield gains with other model families like Llama3 orOLMo2. In particular, we find code reasoning -- thinking in code without actualcode execution -- to be a distinctive Qwen2.5-Math behavior that becomessignificantly more frequent after RLVR, from 65% to over 90%, even withspurious rewards. Overall, we hypothesize that, given the lack of useful rewardsignal, RLVR must somehow be surfacing useful reasoning representations learnedduring pretraining, although the exact mechanism remains a topic for futurework. We suggest that future RLVR research should possibly be validated ondiverse models rather than a single de facto choice, as we show that it is easyto get significant performance gains on Qwen models even with completelyspurious reward signals.</description>
      <author>example@mail.com (Rulin Shao, Shuyue Stella Li, Rui Xin, Scott Geng, Yiping Wang, Sewoong Oh, Simon Shaolei Du, Nathan Lambert, Sewon Min, Ranjay Krishna, Yulia Tsvetkov, Hannaneh Hajishirzi, Pang Wei Koh, Luke Zettlemoyer)</author>
      <guid isPermaLink="false">2506.10947v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>GENMANIP: LLM-driven Simulation for Generalizable Instruction-Following Manipulation</title>
      <link>http://arxiv.org/abs/2506.10966v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GenManip，一个针对策略泛化研究的真实桌面模拟平台，用于解决真实世界场景中机器人操作挑战，特别是关于鲁棒泛化的问题。&lt;h4&gt;背景&lt;/h4&gt;在真实世界环境中，机器人操作仍然具有挑战性，特别是关于策略如何适应不同指令和场景的鲁棒泛化方面。现有的模拟平台在探索策略适应多样化指令和场景方面支持不足，因此落后于对遵循指令的基础模型（如LLMs）日益增长的兴趣，这些模型的适应性至关重要，但尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一差距，本文提出GenManip，一个针对策略泛化研究的真实桌面模拟平台。该平台通过LLM驱动的任务导向场景图，利用10K个标注的3D对象资产自动生成大规模、多样化的任务。&lt;h4&gt;方法&lt;/h4&gt;为了系统地评估泛化能力，本文还提出了GenManip-Bench，一个经过人类在环校正的200个场景的基准。评估了两种策略类型：(1) 集成基础模型（用于感知、推理和规划）的模块化操作系统，以及(2) 通过可扩展数据收集训练的端到端策略。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，虽然数据扩展对端到端方法有益，但增强基础模型的模块化系统在多样化的场景中具有更有效的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;我们预计这个平台将促进在现实条件下策略泛化的关键见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在现实世界环境中进行机器人操作仍然具有挑战性，尤其是在鲁棒泛化方面。现有的模拟平台在探索策略如何适应不同指令和场景方面支持不足，因此落后于对遵循指令的基础模型（如LLMs）日益增长的兴趣，这些模型的适应性至关重要，但尚未得到充分探索。为了填补这一差距，我们引入了GenManip，一个针对策略泛化研究的真实桌面模拟平台。该平台通过LLM驱动的任务导向场景图，利用10K个标注的3D对象资产自动生成大规模、多样化的任务。为了系统地评估泛化能力，我们提出了GenManip-Bench，一个经过人类在环校正的200个场景的基准。评估了两种策略类型：(1) 集成基础模型（用于感知、推理和规划）的模块化操作系统，以及(2) 通过可扩展数据收集训练的端到端策略。结果显示，虽然数据扩展对端到端方法有益，但增强基础模型的模块化系统在多样化的场景中具有更有效的泛化能力。我们预计这个平台将促进在现实条件下策略泛化的关键见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic manipulation in real-world settings remains challenging, especiallyregarding robust generalization. Existing simulation platforms lack sufficientsupport for exploring how policies adapt to varied instructions and scenarios.Thus, they lag behind the growing interest in instruction-following foundationmodels like LLMs, whose adaptability is crucial yet remains underexplored infair comparisons. To bridge this gap, we introduce GenManip, a realistictabletop simulation platform tailored for policy generalization studies. Itfeatures an automatic pipeline via LLM-driven task-oriented scene graph tosynthesize large-scale, diverse tasks using 10K annotated 3D object assets. Tosystematically assess generalization, we present GenManip-Bench, a benchmark of200 scenarios refined via human-in-the-loop corrections. We evaluate two policytypes: (1) modular manipulation systems integrating foundation models forperception, reasoning, and planning, and (2) end-to-end policies trainedthrough scalable data collection. Results show that while data scaling benefitsend-to-end methods, modular systems enhanced with foundation models generalizemore effectively across diverse scenarios. We anticipate this platform tofacilitate critical insights for advancing policy generalization in realisticconditions. Project Page: https://genmanip.axi404.top/.</description>
      <author>example@mail.com (Ning Gao, Yilun Chen, Shuai Yang, Xinyi Chen, Yang Tian, Hao Li, Haifeng Huang, Hanqing Wang, Tai Wang, Jiangmiao Pang)</author>
      <guid isPermaLink="false">2506.10966v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Occlusion-Aware 3D Hand-Object Pose Estimation with Masked AutoEncoders</title>
      <link>http://arxiv.org/abs/2506.10816v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于掩码自动编码器的手-物体姿态估计方法，旨在解决单目RGB图像中由于手-物体交互的严重遮挡而导致的挑战。&lt;h4&gt;背景&lt;/h4&gt;手-物体姿态估计是一个重要挑战，主要因为手-物体交互中的遮挡问题。现有方法未能充分探索全局结构感知和推理，限制了它们处理遮挡手-物体交互的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为HOMAE的遮挡感知手-物体姿态估计方法，以解决上述挑战。&lt;h4&gt;方法&lt;/h4&gt;HOMAE采用了一种目标聚焦的掩码策略，对手-物体交互区域施加结构化遮挡，鼓励模型学习上下文感知特征并推理遮挡结构。此外，它还整合了从解码器提取的多尺度特征来预测有符号距离场（SDF），捕捉全局上下文和精细几何。为了增强几何感知，将隐式SDF与从SDF导出的显式点云相结合，利用两种表示的互补优势。这种融合通过结合SDF的全局上下文和点云提供的精确局部几何来更稳健地处理遮挡区域。&lt;h4&gt;主要发现&lt;/h4&gt;在具有挑战性的DexYCB和HO3Dv2基准数据集上进行的广泛实验表明，HOMAE在手-物体姿态估计方面实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;HOMAE方法有效地解决了手-物体姿态估计中的遮挡问题，并将代码和模型公开。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从单目RGB图像中进行手-物体姿态估计仍然是一个重大挑战，主要由于手-物体交互中固有的严重遮挡。现有方法没有充分探索全局结构感知和推理，这限制了它们处理遮挡手-物体交互的有效性。为了应对这一挑战，我们提出了一种基于掩码自动编码器的遮挡感知手-物体姿态估计方法，称为HOMAE。具体而言，我们提出了一种目标聚焦的掩码策略，对手-物体交互区域施加结构化遮挡，鼓励模型学习上下文感知特征并推理遮挡结构。我们进一步整合了从解码器提取的多尺度特征来预测有符号距离场（SDF），捕捉全局上下文和精细几何。为了增强几何感知，我们将隐式SDF与从SDF导出的显式点云相结合，利用两种表示的互补优势。这种融合通过结合SDF的全局上下文和点云提供的精确局部几何来更稳健地处理遮挡区域。在具有挑战性的DexYCB和HO3Dv2基准数据集上进行的广泛实验表明，HOMAE在手-物体姿态估计方面实现了最先进的性能。我们将发布我们的代码和模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hand-object pose estimation from monocular RGB images remains a significantchallenge mainly due to the severe occlusions inherent in hand-objectinteractions. Existing methods do not sufficiently explore global structuralperception and reasoning, which limits their effectiveness in handling occludedhand-object interactions. To address this challenge, we propose anocclusion-aware hand-object pose estimation method based on maskedautoencoders, termed as HOMAE. Specifically, we propose a target-focusedmasking strategy that imposes structured occlusion on regions of hand-objectinteraction, encouraging the model to learn context-aware features and reasonabout the occluded structures. We further integrate multi-scale featuresextracted from the decoder to predict a signed distance field (SDF), capturingboth global context and fine-grained geometry. To enhance geometric perception,we combine the implicit SDF with an explicit point cloud derived from the SDF,leveraging the complementary strengths of both representations. This fusionenables more robust handling of occluded regions by combining the globalcontext from the SDF with the precise local geometry provided by the pointcloud. Extensive experiments on challenging DexYCB and HO3Dv2 benchmarksdemonstrate that HOMAE achieves state-of-the-art performance in hand-objectpose estimation. We will release our code and model.</description>
      <author>example@mail.com (Hui Yang, Wei Sun, Jian Liu, Jin Zheng, Jian Xiao, Ajmal Mian)</author>
      <guid isPermaLink="false">2506.10816v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Matrix Completion with Denoising and Augmented Graph Views for Robust Recommendation</title>
      <link>http://arxiv.org/abs/2506.10658v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Matrix Completion using Contrastive Learning (MCCL)的新方法，用于推荐系统中的矩阵补全，该方法通过对比学习提高了模型的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;矩阵补全在推荐系统中广泛应用，但基于图神经网络的当前方法对噪声或不相关边敏感，容易过拟合，限制了其泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出MCCL方法以克服现有方法的局限性，提高推荐系统的准确性。&lt;h4&gt;方法&lt;/h4&gt;MCCL方法首先为每个交互提取局部邻域子图，然后生成两种不同的图表示。第一种表示通过结合GNN层和注意力机制强调去噪，第二种通过图变分自动编码器对特征分布与标准先验进行对齐。在训练过程中使用互学习损失函数来逐步协调这些表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，MCCL方法不仅提高了预测评分的数值准确性（RMSE改善高达0.8%），而且在排名指标上也有显著提升，排名改善高达36%。&lt;h4&gt;结论&lt;/h4&gt;MCCL方法通过对比学习显著提高了推荐系统的泛化能力和预测准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：矩阵补全是在推荐系统中广泛采用的一种框架，通过预测用户-物品评分矩阵中的缺失项，可以全面理解用户偏好。然而，当前基于图神经网络（GNN）的方法对噪声或不相关边非常敏感——由于它们固有的消息传递机制——并且容易过拟合，这限制了它们的泛化能力。为了克服这些挑战，我们提出了一种名为矩阵补全对比学习（MCCL）的新方法。我们的方法首先为每个交互提取局部邻域子图，然后生成两种不同的图表示。第一种表示通过结合GNN层和注意力机制强调去噪，第二种通过图变分自动编码器将特征分布与标准先验对齐。在训练过程中使用互学习损失函数来逐步协调这些表示，使模型能够捕获共同模式并显著提高其泛化能力。在多个真实世界数据集上的大量实验表明，我们的方法不仅提高了预测评分的数值准确性——RMSE改善高达0.8%——而且还产生了更好的排名，排名指标改善高达36%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Matrix completion is a widely adopted framework in recommender systems, aspredicting the missing entries in the user-item rating matrix enables acomprehensive understanding of user preferences. However, current graph neuralnetwork (GNN)-based approaches are highly sensitive to noisy or irrelevantedges--due to their inherent message-passing mechanisms--and are prone tooverfitting, which limits their generalizability. To overcome these challenges,we propose a novel method called Matrix Completion using Contrastive Learning(MCCL). Our approach begins by extracting local neighborhood subgraphs for eachinteraction and subsequently generates two distinct graph representations. Thefirst representation emphasizes denoising by integrating GNN layers with anattention mechanism, while the second is obtained via a graph variationalautoencoder that aligns the feature distribution with a standard prior. Amutual learning loss function is employed during training to graduallyharmonize these representations, enabling the model to capture common patternsand significantly enhance its generalizability. Extensive experiments onseveral real-world datasets demonstrate that our approach not only improves thenumerical accuracy of the predicted scores--achieving up to a 0.8% improvementin RMSE--but also produces superior rankings with improvements of up to 36% inranking metrics.</description>
      <author>example@mail.com (Narges Nemati, Mostafa Haghir Chehreghani)</author>
      <guid isPermaLink="false">2506.10658v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Automatic Addition of Optimizing Components in Printed Circuit Board Schematics</title>
      <link>http://arxiv.org/abs/2506.10577v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过将组件表示为二分图并利用基于图神经网络（GNN）的节点对预测模型来自动化PCB图优化的方法。&lt;h4&gt;背景&lt;/h4&gt;优化PCB图对于开发高质量的电子设备至关重要，但缺乏熟练工程师和手动优化耗时，导致最佳实践常被忽视，进而增加了后期开发阶段的故障排除成本和产品生命周期缩短，导致难以回收的电子废物增加。&lt;h4&gt;目的&lt;/h4&gt;自动化PCB图优化，提高电路的鲁棒性和可靠性，降低成本和缩短开发时间。&lt;h4&gt;方法&lt;/h4&gt;将组件表示为二分图，利用GNN节点对预测模型自动添加新组件到PCB图中，并将该方法应用于三个相关的PCB设计优化任务，比较了多个流行的GNN架构在标注数据集上的性能。&lt;h4&gt;主要发现&lt;/h4&gt;GNN可以以高精度解决这些问题，并且该方法有望以时间和成本效益的方式自动化PCB设计优化。&lt;h4&gt;结论&lt;/h4&gt;提出的基于GNN的PCB图自动化优化方法有效且具有潜力，可以显著提高PCB设计的效率和产品质量。&lt;h4&gt;翻译&lt;/h4&gt;The design and optimization of Printed Circuit Board (PCB) schematics is crucial for the development of high-quality electronic devices. Thereby, an important task is to optimize drafts by adding components that improve the robustness and reliability of the circuit, e.g., pull-up resistors or decoupling capacitors. Since there is a shortage of skilled engineers and manual optimizations are very time-consuming, these best practices are often neglected. However, this typically leads to higher costs for troubleshooting in later development stages as well as shortened product life cycles, resulting in an increased amount of electronic waste that is difficult to recycle. Here, we present an approach for automating the addition of new components into PCB schematics by representing them as bipartite graphs and utilizing a node pair prediction model based on Graph Neural Networks (GNNs). We apply our approach to three highly relevant PCB design optimization tasks and compare the performance of several popular GNN architectures on real-world datasets labeled by human experts. We show that GNNs can solve these problems with high accuracy and demonstrate that our approach offers the potential to automate PCB design optimizations in a time- and cost-efficient manner.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The design and optimization of Printed Circuit Board (PCB) schematics iscrucial for the development of high-quality electronic devices. Thereby, animportant task is to optimize drafts by adding components that improve therobustness and reliability of the circuit, e.g., pull-up resistors ordecoupling capacitors. Since there is a shortage of skilled engineers andmanual optimizations are very time-consuming, these best practices are oftenneglected. However, this typically leads to higher costs for troubleshooting inlater development stages as well as shortened product life cycles, resulting inan increased amount of electronic waste that is difficult to recycle. Here, wepresent an approach for automating the addition of new components into PCBschematics by representing them as bipartite graphs and utilizing a node pairprediction model based on Graph Neural Networks (GNNs). We apply our approachto three highly relevant PCB design optimization tasks and compare theperformance of several popular GNN architectures on real-world datasets labeledby human experts. We show that GNNs can solve these problems with high accuracyand demonstrate that our approach offers the potential to automate PCB designoptimizations in a time- and cost-efficient manner.</description>
      <author>example@mail.com (Pascal Plettenberg, André Alcalde, Bernhard Sick, Josephine M. Thomas)</author>
      <guid isPermaLink="false">2506.10577v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>FairASR: Fair Audio Contrastive Learning for Automatic Speech Recognition</title>
      <link>http://arxiv.org/abs/2506.10747v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Interspeech2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了FairASR系统，该系统能够通过学习不包含群体成员信息的表征来减少人口统计学偏见，从而实现公平的跨群体泛化。&lt;h4&gt;背景&lt;/h4&gt;大规模语音识别模型在准确性和鲁棒性方面取得了显著进步，但在实际应用中，公平性问题尚未得到充分解决。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一个系统，减少语音识别模型在人口统计学群体间的性能差异。&lt;h4&gt;方法&lt;/h4&gt;FairASR系统利用多人口统计学数据集，通过梯度反转层抑制具有人口统计学歧视性的特征，同时通过无监督对比损失来捕捉可泛化的语音模式。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，FairASR在总体语音识别性能上具有竞争力，同时显著减少了不同人口统计学群体间的性能差异。&lt;h4&gt;结论&lt;/h4&gt;FairASR系统在保持良好语音识别性能的同时，有效地解决了模型在不同群体间的公平性问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale ASR models have achieved remarkable gains in accuracy androbustness. However, fairness issues remain largely unaddressed despite theircritical importance in real-world applications. In this work, we introduceFairASR, a system that mitigates demographic bias by learning representationsthat are uninformative about group membership, enabling fair generalizationacross demographic groups. Leveraging a multi-demographic dataset, our approachemploys a gradient reversal layer to suppress demographic-discriminativefeatures while maintaining the ability to capture generalizable speech patternsthrough an unsupervised contrastive loss. Experimental results show thatFairASR delivers competitive overall ASR performance while significantlyreducing performance disparities across different demographic groups.</description>
      <author>example@mail.com (Jongsuk Kim, Jaemyung Yu, Minchan Kwon, Junmo Kim)</author>
      <guid isPermaLink="false">2506.10747v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>ECAM: A Contrastive Learning Approach to Avoid Environmental Collision in Trajectory Forecasting</title>
      <link>http://arxiv.org/abs/2506.09626v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IJCNN 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于对比学习的环境碰撞避免模块ECAM，用于提升轨迹预测模型的碰撞避免能力。&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶、机器人和监控等应用中，人类轨迹预测至关重要。准确的预测需要模型考虑多种因素，包括社会互动、多模态预测、行人意图和环境背景。&lt;h4&gt;目的&lt;/h4&gt;提高轨迹预测模型在生成无碰撞预测方面的能力。&lt;h4&gt;方法&lt;/h4&gt;ECAM模块通过对比学习增强模型的环境碰撞避免能力，并可以集成到现有的轨迹预测模型中。&lt;h4&gt;主要发现&lt;/h4&gt;在ETH/UCY数据集上评估，ECAM模块显著降低了（-40/50%）碰撞率，证明了其在碰撞避免方面的能力。&lt;h4&gt;结论&lt;/h4&gt;ECAM模块能够有效提高轨迹预测模型的碰撞避免能力，并显著降低碰撞率。&lt;h4&gt;翻译&lt;/h4&gt;Human trajectory forecasting is crucial in applications such as autonomous driving, robotics and surveillance. Accurate forecasting requires models to consider various factors, including social interactions, multi-modal predictions, pedestrian intention and environmental context. While existing methods account for these factors, they often overlook the impact of the environment, which leads to collisions with obstacles. This paper introduces ECAM (Environmental Collision Avoidance Module), a contrastive learning-based module to enhance collision avoidance ability with the environment. The proposed module can be integrated into existing trajectory forecasting models, improving their ability to generate collision-free predictions. We evaluate our method on the ETH/UCY dataset and quantitatively and qualitatively demonstrate its collision avoidance capabilities. Our experiments show that state-of-the-art methods significantly reduce (-40/50%) the collision rate when integrated with the proposed module. The code is available at https://github.com/CVML-CFU/ECAM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human trajectory forecasting is crucial in applications such as autonomousdriving, robotics and surveillance. Accurate forecasting requires models toconsider various factors, including social interactions, multi-modalpredictions, pedestrian intention and environmental context. While existingmethods account for these factors, they often overlook the impact of theenvironment, which leads to collisions with obstacles. This paper introducesECAM (Environmental Collision Avoidance Module), a contrastive learning-basedmodule to enhance collision avoidance ability with the environment. Theproposed module can be integrated into existing trajectory forecasting models,improving their ability to generate collision-free predictions. We evaluate ourmethod on the ETH/UCY dataset and quantitatively and qualitatively demonstrateits collision avoidance capabilities. Our experiments show thatstate-of-the-art methods significantly reduce (-40/50%) the collision rate whenintegrated with the proposed module. The code is available athttps://github.com/CVML-CFU/ECAM.</description>
      <author>example@mail.com (Giacomo Rosin, Muhammad Rameez Ur Rahman, Sebastiano Vascon)</author>
      <guid isPermaLink="false">2506.09626v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>VRBench: A Benchmark for Multi-Step Reasoning in Long Narrative Videos</title>
      <link>http://arxiv.org/abs/2506.10857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了VRBench，这是第一个用于评估大型模型多步推理能力的长篇叙事视频基准，解决了现有评估中忽视时间推理和程序有效性的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的评估方法未能充分考虑时间推理和程序的有效性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够评估大型模型多步推理能力的视频基准。&lt;h4&gt;方法&lt;/h4&gt;VRBench包含1,010个长视频，每个视频平均时长为1.6小时，以及9,468个人工标注的多步问答对和30,292个带时间戳的推理步骤。视频通过多阶段筛选过程进行整理，包括专家互评以优先考虑情节连贯性。开发了一个人类-人工智能协作框架，生成需要多个时间上定位的推理链，涵盖七种类型（例如，事件归因、隐含推理）。VRBench设计了一个多阶段评估流程，评估模型在结果和过程两个层面。&lt;h4&gt;主要发现&lt;/h4&gt;通过在VRBench上对12个大型语言模型和16个视觉语言模型进行广泛评估，进行了详细分析，并提供了有价值见解，推动了多步推理领域的发展。&lt;h4&gt;结论&lt;/h4&gt;VRBench为多步推理能力的评估提供了一个新的基准，有助于推动该领域的研究进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present VRBench, the first long narrative video benchmark crafted forevaluating large models' multi-step reasoning capabilities, addressinglimitations in existing evaluations that overlook temporal reasoning andprocedural validity. It comprises 1,010 long videos (with an average durationof 1.6 hours), along with 9,468 human-labeled multi-step question-answeringpairs and 30,292 reasoning steps with timestamps. These videos are curated viaa multi-stage filtering process including expert inter-rater reviewing toprioritize plot coherence. We develop a human-AI collaborative framework thatgenerates coherent reasoning chains, each requiring multiple temporallygrounded steps, spanning seven types (e.g., event attribution, implicitinference). VRBench designs a multi-phase evaluation pipeline that assessesmodels at both the outcome and process levels. Apart from the MCQs for thefinal results, we propose a progress-level LLM-guided scoring metric toevaluate the quality of the reasoning chain from multiple dimensionscomprehensively. Through extensive evaluations of 12 LLMs and 16 VLMs onVRBench, we undertake a thorough analysis and provide valuable insights thatadvance the field of multi-step reasoning.</description>
      <author>example@mail.com (Jiashuo Yu, Yue Wu, Meng Chu, Zhifei Ren, Zizheng Huang, Pei Chu, Ruijie Zhang, Yinan He, Qirui Li, Songze Li, Zhenxiang Li, Zhongying Tu, Conghui He, Yu Qiao, Yali Wang, Yi Wang, Limin Wang)</author>
      <guid isPermaLink="false">2506.10857v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>SceneCompleter: Dense 3D Scene Completion for Generative Novel View Synthesis</title>
      <link>http://arxiv.org/abs/2506.10981v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SceneCompleter是一个新型框架，通过密集的3D场景补全实现3D一致性的生成新视角合成，有效提高了生成新视角合成的视觉一致性和3D一致性。&lt;h4&gt;背景&lt;/h4&gt;现有的生成模型在新视角合成(NVS)中依赖密集的多视角捕捉，但通常会导致表面过于平滑和几何扭曲，因为生成模型难以从RGB数据中推断3D结构。&lt;h4&gt;目的&lt;/h4&gt;提出SceneCompleter框架，旨在通过3D场景补全实现3D一致性的生成新视角合成。&lt;h4&gt;方法&lt;/h4&gt;SceneCompleter通过两个关键组件实现：(1)一个几何-外观双重流扩散模型，在RGBD空间中联合合成新视角；(2)一个场景嵌入器，从参考图像中编码更全面的场景理解。&lt;h4&gt;主要发现&lt;/h4&gt;通过有效融合结构和纹理信息，该方法在多种数据集上展示了在生成新视角合成中的优越一致性和可信度。&lt;h4&gt;结论&lt;/h4&gt;SceneCompleter框架在生成新视角合成中提供了一种新的方法，能够实现更加真实和一致的3D场景重建。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative models have gained significant attention in novel view synthesis(NVS) by alleviating the reliance on dense multi-view captures. However,existing methods typically fall into a conventional paradigm, where generativemodels first complete missing areas in 2D, followed by 3D recovery techniquesto reconstruct the scene, which often results in overly smooth surfaces anddistorted geometry, as generative models struggle to infer 3D structure solelyfrom RGB data. In this paper, we propose SceneCompleter, a novel framework thatachieves 3D-consistent generative novel view synthesis through dense 3D scenecompletion. SceneCompleter achieves both visual coherence and 3D-consistentgenerative scene completion through two key components: (1) ageometry-appearance dual-stream diffusion model that jointly synthesizes novelviews in RGBD space; (2) a scene embedder that encodes a more holistic sceneunderstanding from the reference image. By effectively fusing structural andtextural information, our method demonstrates superior coherence andplausibility in generative novel view synthesis across diverse datasets.Project Page: https://chen-wl20.github.io/SceneCompleter</description>
      <author>example@mail.com (Weiliang Chen, Jiayi Bi, Yuanhui Huang, Wenzhao Zheng, Yueqi Duan)</author>
      <guid isPermaLink="false">2506.10981v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>VideoDeepResearch: Long Video Understanding With Agentic Tool Using</title>
      <link>http://arxiv.org/abs/2506.10821v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为VideoDeepResearch的新型框架，用于解决长视频理解（LVU）的挑战，并通过实验证明其在多个LVU基准测试中优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;长视频理解对当前的多模态大型语言模型（MLLMs）来说是一个重大挑战，因为它本身具有复杂性以及上下文窗口的限制。&lt;h4&gt;目的&lt;/h4&gt;挑战传统观点，即解决LVU任务需要具有扩展上下文窗口、强大视觉感知能力和专业领域知识的MLLM。&lt;h4&gt;方法&lt;/h4&gt;VideoDeepResearch框架仅使用纯文本的大型推理模型（LRM）和模块化的多模态工具包，包括多模态检索器和视觉感知器。&lt;h4&gt;主要发现&lt;/h4&gt;VideoDeepResearch在多个LVU基准测试中取得了显著改进，分别在MLVU、LVBench和LongVideoBench上超越了之前的最先进水平，提升分别为9.6%、6.6%和3.9%。&lt;h4&gt;结论&lt;/h4&gt;这些发现突显了代理系统在克服LVU问题中的关键挑战方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel framework called VideoDeepResearch for addressing the challenges of Long Video Understanding (LVU), and demonstrates through experiments that it outperforms existing methods in multiple LVU benchmarks. The background is that LVU presents a significant challenge for current multi-modal large language models (MLLMs) due to its inherent complexity and context window constraints. The purpose is to challenge the common belief that solving LVU tasks requires foundation MLLMs with extended context windows, strong visual perception capabilities, and proficient domain expertise. The method is to use a text-only large reasoning model (LRM) and a modular multi-modal toolkit, including multimodal retrievers and visual perceivers, for the VideoDeepResearch framework. The key findings are that VideoDeepResearch achieves substantial improvements over existing MLLM baselines, surpassing the previous state-of-the-art by 9.6%, 6.6%, and 3.9% on MLVU (test), LVBench, and LongVideoBench, respectively. The conclusion is that these findings highlight the promise of agent-based systems in overcoming key challenges in LVU problems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long video understanding (LVU) presents a significant challenge for currentmulti-modal large language models (MLLMs) due to the task's inherent complexityand context window constraint. It is widely assumed that addressing LVU tasksrequires foundation MLLMs with extended context windows, strong visualperception capabilities, and proficient domain expertise. In this work, wechallenge this common belief by introducing VideoDeepResearch, a novel agenticframework for long video understanding. Our approach relies solely on atext-only large reasoning model (LRM) combined with a modular multi-modaltoolkit, including multimodal retrievers and visual perceivers, all of whichare readily available in practice. For each LVU task, the system formulates aproblem-solving strategy through reasoning, while selectively accessing andutilizing essential video content via tool using. We conduct extensiveexperiments on popular LVU benchmarks, including MLVU, Video-MME, and LVBench.Our results demonstrate that VideoDeepResearch achieves substantialimprovements over existing MLLM baselines, surpassing the previousstate-of-the-art by 9.6%, 6.6%, and 3.9% on MLVU (test), LVBench, andLongVideoBench, respectively. These findings highlight the promise of agenticsystems in overcoming key challenges in LVU problems.</description>
      <author>example@mail.com (Huaying Yuan, Zheng Liu, Junjie Zhou, Ji-Rong Wen, Zhicheng Dou)</author>
      <guid isPermaLink="false">2506.10821v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos</title>
      <link>http://arxiv.org/abs/2506.10242v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025 Workshop on Autonomous Driving&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DySS的新方法，用于基于相机视角的3D物体检测，该方法在自动驾驶中具有重要作用。DySS结合了状态空间学习与动态查询技术，在保持检测性能的同时提高了推理效率。&lt;h4&gt;背景&lt;/h4&gt;传统的基于密集BEV特征的3D物体检测方法成本高昂，而基于稀疏查询的方法虽然近期有所研究，但仍然需要大量查询，运行成本较高。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法DySS，以提高3D物体检测的效率和性能。&lt;h4&gt;方法&lt;/h4&gt;DySS利用状态空间模型（SSM）对样本特征进行顺序处理，并通过未来预测和掩码重建等辅助任务来训练SSM，以更好地捕捉运动和对应信息。基于SSM的状态，动态更新查询，通过合并、删除和分割操作来维护一个有用且精简的检测查询集。&lt;h4&gt;主要发现&lt;/h4&gt;DySS在nuScenes测试集上实现了65.31 NDS和57.4 mAP的性能，优于现有最佳方法。在验证集上，DySS达到了56.2 NDS和46.2 mAP，同时保持了33 FPS的实时推理速度。&lt;h4&gt;结论&lt;/h4&gt;DySS是一种高效且性能优异的3D物体检测方法，适用于自动驾驶场景。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于相机视角的Bird's Eye View（BEV）3D物体检测是自动驾驶中最关键的感知任务之一。早期方法依赖于密集的BEV特征，构建成本高昂。近期的研究探索了基于稀疏查询的检测方法。然而，它们仍然需要大量的查询，并且当使用更多的视频帧时，运行成本可能变得高昂。在本文中，我们提出了一种名为DySS的新方法，它采用了状态空间学习和动态查询。具体来说，DySS利用状态空间模型（SSM）按时间步骤顺序处理样本特征。为了鼓励模型更好地捕捉潜在的移动和对应信息，我们引入了未来预测和掩码重建的辅助任务来更好地训练SSM。SSM的状态随后提供了有关场景的有用而高效的总结。基于状态空间学习到的特征，我们通过合并、删除和分割操作动态更新查询，这有助于在整个网络中保持一个有用且精简的检测查询集。我们提出的DySS实现了卓越的检测性能和高效的推理。具体而言，在nuScenes测试集上，DySS实现了65.31 NDS和57.4 mAP，优于现有最佳水平。在验证集上，DySS实现了56.2 NDS和46.2 mAP，以及33 FPS的实时推理速度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Camera-based 3D object detection in Bird's Eye View (BEV) is one of the mostimportant perception tasks in autonomous driving. Earlier methods rely on denseBEV features, which are costly to construct. More recent works explore sparsequery-based detection. However, they still require a large number of queriesand can become expensive to run when more video frames are used. In this paper,we propose DySS, a novel method that employs state-space learning and dynamicqueries. More specifically, DySS leverages a state-space model (SSM) tosequentially process the sampled features over time steps. In order toencourage the model to better capture the underlying motion and correspondenceinformation, we introduce auxiliary tasks of future prediction and maskedreconstruction to better train the SSM. The state of the SSM then provides aninformative yet efficient summarization of the scene. Based on the state-spacelearned features, we dynamically update the queries via merge, remove, andsplit operations, which help maintain a useful, lean set of detection queriesthroughout the network. Our proposed DySS achieves both superior detectionperformance and efficient inference. Specifically, on the nuScenes test split,DySS achieves 65.31 NDS and 57.4 mAP, outperforming the latest state of theart. On the val split, DySS achieves 56.2 NDS and 46.2 mAP, as well as areal-time inference speed of 33 FPS.</description>
      <author>example@mail.com (Rajeev Yasarla, Shizhong Han, Hong Cai, Fatih Porikli)</author>
      <guid isPermaLink="false">2506.10242v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>LightKG: Efficient Knowledge-Aware Recommendations with Simplified GNN Architecture</title>
      <link>http://arxiv.org/abs/2506.10347v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery  and Data Mining&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的知识图谱推荐系统LightKG，旨在解决稀疏性问题，并提高推荐准确率。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）在知识图谱推荐系统（KGRS）中表现出色，但自监督学习（SSL）的引入导致训练时间延长。&lt;h4&gt;目的&lt;/h4&gt;提出LightKG以解决稀疏性问题，同时提高推荐准确率和减少训练时间。&lt;h4&gt;方法&lt;/h4&gt;LightKG使用简化的GNN层，将关系编码为标量对，并采用线性聚合框架。此外，它还包含一个高效的对比层来实现自监督学习。&lt;h4&gt;主要发现&lt;/h4&gt;现有的基于GNN的KGRS在稀疏交互下即使结合SSL也未能保持其优越性能；更复杂的模型在稀疏交互场景中表现更差；注意力机制等复杂机制可能有害，因为它们通常会增加学习难度。&lt;h4&gt;结论&lt;/h4&gt;LightKG在稀疏和密集场景中都优于12个竞争性的KGRS，同时显著减少了训练时间。与带有SSL的KGRS相比，它在推荐准确率上平均提高了5.8%，并节省了84.3%的训练时间。&lt;h4&gt;翻译&lt;/h4&gt;最近，图神经网络（GNN）因其有效性而成为知识图谱感知推荐系统（KGRS）的主流方法。在基于GNN的KGRS的基础上，自监督学习（SSL）已被纳入以解决稀疏性问题，导致训练时间更长。然而，通过广泛的实验，我们发现：（1）与其他KGRS相比，现有的基于GNN的KGRS即使在结合SSL的情况下也无法在稀疏交互下保持其优越性能。（2）更复杂的模型在稀疏交互场景中往往表现更差，并且复杂的机制，如注意力机制，可能是有害的，因为它们通常会增加学习难度。受这些发现的启发，我们提出了一种简单的但功能强大的基于GNN的KGRS，称为LightKG，以解决稀疏性问题。LightKG包含一个简化的GNN层，将有向关系编码为标量对，并采用线性聚合框架，大大降低了GNN的复杂性。此外，LightKG还包含一个高效的对比层来实现自监督学习。它直接最小化原始图中的节点相似度，避免了先前SSL方法中所需的时间消耗较大的子图生成和比较。在四个基准数据集上的实验表明，LightKG在稀疏和密集场景中都优于12个竞争性的KGRS，同时显著减少了训练时间。具体来说，它在推荐准确率上平均超过了最佳基线5.8%，与带有SSL的KGRS相比，节省了84.3%的训练时间。我们的代码可在https://github.com/1371149/LightKG获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737026&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Graph Neural Networks (GNNs) have become the dominant approach forKnowledge Graph-aware Recommender Systems (KGRSs) due to their proveneffectiveness. Building upon GNN-based KGRSs, Self-Supervised Learning (SSL)has been incorporated to address the sparity issue, leading to longer trainingtime. However, through extensive experiments, we reveal that: (1)compared toother KGRSs, the existing GNN-based KGRSs fail to keep their superiorperformance under sparse interactions even with SSL. (2) More complex modelstend to perform worse in sparse interaction scenarios and complex mechanisms,like attention mechanism, can be detrimental as they often increase learningdifficulty. Inspired by these findings, we propose LightKG, a simple yetpowerful GNN-based KGRS to address sparsity issues. LightKG includes asimplified GNN layer that encodes directed relations as scalar pairs ratherthan dense embeddings and employs a linear aggregation framework, greatlyreducing the complexity of GNNs. Additionally, LightKG incorporates anefficient contrastive layer to implement SSL. It directly minimizes the nodesimilarity in original graph, avoiding the time-consuming subgraph generationand comparison required in previous SSL methods. Experiments on four benchmarkdatasets show that LightKG outperforms 12 competitive KGRSs in both sparse anddense scenarios while significantly reducing training time. Specifically, itsurpasses the best baselines by an average of 5.8\% in recommendation accuracyand saves 84.3\% of training time compared to KGRSs with SSL. Our code isavailable at https://github.com/1371149/LightKG.</description>
      <author>example@mail.com (Yanhui Li, Dongxia Wang, Zhu Sun, Haonan Zhang, Huizhong Guo)</author>
      <guid isPermaLink="false">2506.10347v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>PiPViT: Patch-based Visual Interpretable Prototypes for Retinal Image Analysis</title>
      <link>http://arxiv.org/abs/2506.10669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PiPViT是一种基于图像的视觉可解释原型模型，用于图像识别，能够提高原型在医学影像中的可解释性，并有效定位生物标志物。&lt;h4&gt;背景&lt;/h4&gt;原型方法通过学习细粒度部分原型提高可解释性，但其输入像素空间中的可视化不总是与人类可理解的生物标志物一致。&lt;h4&gt;目的&lt;/h4&gt;提出PiPViT模型，以解决原型方法在医学影像中的可解释性问题，并提高生物标志物的定位。&lt;h4&gt;方法&lt;/h4&gt;PiPViT利用视觉变压器(ViT)捕获补丁之间的长距离依赖关系，学习鲁棒且人类可解释的原型，仅使用图像级标签来近似病变范围。此外，PiPViT受益于对比学习和多分辨率输入处理，能够在不同尺度上有效定位生物标志物。&lt;h4&gt;主要发现&lt;/h4&gt;在四个数据集上对PiPViT进行评估，其性能与最先进的方法相当，同时提供了更有意义的解释。对保留测试集的定量评估确认了学习到的原型在语义和临床上是相关的。&lt;h4&gt;结论&lt;/h4&gt;PiPViT能够透明地解释其决策，并帮助临床医生理解诊断结果。&lt;h4&gt;翻译&lt;/h4&gt;PiPViT (Patch-based Visual Interpretable Prototypes) 是一种基于图像的视觉可解释原型模型，用于图像识别。该方法利用视觉变压器（ViT）捕捉补丁之间的长距离依赖关系，学习鲁棒且人类可解释的原型，仅使用图像级标签来近似病变范围。此外，PiPViT受益于对比学习和多分辨率输入处理，能够在不同尺度上有效定位生物标志物。在四个数据集上对PiPViT进行评估，其性能与最先进的方法相当，同时提供了更有意义的解释。对保留测试集的定量评估确认了学习到的原型在语义和临床上是相关的。我们相信PiPViT能够透明地解释其决策，并帮助临床医生理解诊断结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Background and Objective: Prototype-based methods improve interpretability bylearning fine-grained part-prototypes; however, their visualization in theinput pixel space is not always consistent with human-understandablebiomarkers. In addition, well-known prototype-based approaches typically learnextremely granular prototypes that are less interpretable in medical imaging,where both the presence and extent of biomarkers and lesions are critical.  Methods: To address these challenges, we propose PiPViT (Patch-based VisualInterpretable Prototypes), an inherently interpretable prototypical model forimage recognition. Leveraging a vision transformer (ViT), PiPViT captureslong-range dependencies among patches to learn robust, human-interpretableprototypes that approximate lesion extent only using image-level labels.Additionally, PiPViT benefits from contrastive learning and multi-resolutioninput processing, which enables effective localization of biomarkers acrossscales.  Results: We evaluated PiPViT on retinal OCT image classification across fourdatasets, where it achieved competitive quantitative performance compared tostate-of-the-art methods while delivering more meaningful explanations.Moreover, quantitative evaluation on a hold-out test set confirms that thelearned prototypes are semantically and clinically relevant. We believe PiPViTcan transparently explain its decisions and assist clinicians in understandingdiagnostic outcomes. Github page: https://github.com/marziehoghbaie/PiPViT</description>
      <author>example@mail.com (Marzieh Oghbaie, Teresa Araújoa, Hrvoje Bogunović)</author>
      <guid isPermaLink="false">2506.10669v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Tightly-Coupled LiDAR-IMU-Leg Odometry with Online Learned Leg Kinematics Incorporating Foot Tactile Information</title>
      <link>http://arxiv.org/abs/2506.09548v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Robotics and Automation Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种紧密耦合的激光雷达-惯性测量单元-腿部里程计，该方法在无特征环境、可变形地形等恶劣条件下具有鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;针对无特征环境和可变形地形等挑战性条件，提出了基于在线学习的腿部运动学模型。&lt;h4&gt;目的&lt;/h4&gt;提高机器人对重量负载变化和地形条件的适应性，并实现里程计估计的准确性。&lt;h4&gt;方法&lt;/h4&gt;开发了名为神经腿部运动学模型的在线学习模型，该模型结合触觉信息（脚部反作用力）来隐式表达机器人脚与地面之间的非线性动力学。通过联合解决运动学模型的在线训练和里程计估计，以保持两者的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，结合神经腿部运动学模型的里程计估计优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;该方法在两个具有挑战性的场景中得到了验证，包括沙海滩和校园环境，显示了其在不同地形下的有效性。&lt;h4&gt;翻译&lt;/h4&gt;In this letter, we present tightly coupled LiDAR-IMU-leg odometry, which is robust to challenging conditions such as featureless environments and deformable terrains. We developed an online learning-based leg kinematics model named the neural leg kinematics model, which incorporates tactile information (foot reaction force) to implicitly express the nonlinear dynamics between robot feet and the ground. Online training of this model enhances its adaptability to weight load changes of a robot (e.g., assuming delivery or transportation tasks) and terrain conditions. According to the extit{neural adaptive leg odometry factor} and online uncertainty estimation of the leg kinematics model-based motion predictions, we jointly solve online training of this kinematics model and odometry estimation on a unified factor graph to retain the consistency of both. The proposed method was verified through real experiments using a quadruped robot in two challenging situations: 1) a sandy beach, representing an extremely featureless area with a deformable terrain, and 2) a campus, including multiple featureless areas and terrain types of asphalt, gravel (deformable terrain), and grass. Experimental results showed that our odometry estimation incorporating the extit{neural leg kinematics model} outperforms state-of-the-art works. Our project page is available for further details: https://takuokawara.github.io/RAL2025_project_page/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this letter, we present tightly coupled LiDAR-IMU-leg odometry, which isrobust to challenging conditions such as featureless environments anddeformable terrains. We developed an online learning-based leg kinematics modelnamed the neural leg kinematics model, which incorporates tactile information(foot reaction force) to implicitly express the nonlinear dynamics betweenrobot feet and the ground. Online training of this model enhances itsadaptability to weight load changes of a robot (e.g., assuming delivery ortransportation tasks) and terrain conditions. According to the \textit{neuraladaptive leg odometry factor} and online uncertainty estimation of the legkinematics model-based motion predictions, we jointly solve online training ofthis kinematics model and odometry estimation on a unified factor graph toretain the consistency of both. The proposed method was verified through realexperiments using a quadruped robot in two challenging situations: 1) a sandybeach, representing an extremely featureless area with a deformable terrain,and 2) a campus, including multiple featureless areas and terrain types ofasphalt, gravel (deformable terrain), and grass. Experimental results showedthat our odometry estimation incorporating the \textit{neural leg kinematicsmodel} outperforms state-of-the-art works. Our project page is available forfurther details: https://takuokawara.github.io/RAL2025_project_page/</description>
      <author>example@mail.com (Taku Okawara, Kenji Koide, Aoki Takanose, Shuji Oishi, Masashi Yokozuka, Kentaro Uno, Kazuya Yoshida)</author>
      <guid isPermaLink="false">2506.09548v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>General Reference Frame Identification and Transformation in Unbalanced Power Systems</title>
      <link>http://arxiv.org/abs/2506.10835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种基于几何框架的坐标变换新方法，该方法通过使用几何代数中的双矢量分析直接识别不平衡量的轨迹所在平面，显著降低了问题的复杂性。&lt;h4&gt;背景&lt;/h4&gt;坐标变换在电力系统稳定性分析、电机建模和电力电子转换器控制等领域得到了广泛应用，其主要优势在于降维。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的通用变换方法，适用于任何程度的$n$相$(n+1)$线正弦系统的不平衡。&lt;h4&gt;方法&lt;/h4&gt;该方法使用几何代数进行双矢量分析，通过在不同时间瞬间进行两个测量（电压或电流）来实现。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过纯几何推理证明是通用的，并包括其他技术，如经典的Clarke变换。数值模拟和实验验证了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法在多维度系统中的应用以及减少的测量要求，相对于现有的通常限于三相应用或受限于计算方法的现有方法，代表了一个重大的进步。&lt;h4&gt;翻译&lt;/h4&gt;摘要：各个领域，如电力系统稳定性分析、电机建模和电力电子转换器控制，都极大地受益于坐标变换的应用。其中一个主要的好处是降维，这降低了问题的复杂性。本文介绍了一种基于几何框架的新颖通用变换，它通过使用几何代数中的双矢量分析直接识别不平衡量轨迹所在的平面。所提出的方法为任何程度的$n$相$(n+1)$线正弦系统的不平衡提供了一个直接的变换。该变换只需要在不同时间瞬间进行两个测量（电压或电流），这使得它计算效率高。此外，我们通过纯几何推理证明了我们的方法是通用的，并包括其他技术，如经典的Clarke变换。使用实时数字模拟器和物理实验室设置进行的数值模拟和实验验证证明了所提出方法的有效性。将该方法推广到多维度系统，结合减少的测量要求，相对于现有的通常限于三相应用或受限于计算方法的现有方法，代表了一个重大的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Various domains such as power system stability analysis, electric machinemodeling, and control of power electronic converters have significantlybenefited from the application of coordinate transformations. One of the mainbenefits is the dimensional reduction, which reduces the complexity of theproblems. This paper introduces a novel general transformation based on ageometric framework that directly identifies the plane containing the locus forunbalanced quantities through bivector analysis using Geometric Algebra. Theproposed method provides a direct transformation valid for any degree ofunbalance in $n$-phase, $(n+1)$-wire sinusoidal systems. The transformationrequires only two measurements (voltage or current) taken at different timeinstants, making it computationally efficient. Moreover, we demonstrate throughpure geometric reasoning that our approach is general and encompasses othertechniques, such as the classical Clarke transformation. Numerical simulationsand experimental validation using a real-time digital simulator and a physicallaboratory setup demonstrate the effectiveness of the proposed method. Thisgeneralization to multi-dimensional systems, combined with the reducedmeasurement requirements, represents a significant advancement over existingapproaches that are typically restricted to three-phase applications or sufferfrom computational limitations.</description>
      <author>example@mail.com (Francisco G. Montoya, Santiago Sánchez Acevedo)</author>
      <guid isPermaLink="false">2506.10835v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Think before You Simulate: Symbolic Reasoning to Orchestrate Neural Computation for Counterfactual Question Answering</title>
      <link>http://arxiv.org/abs/2506.10753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In Proceedings the IEEE/CVF Winter Conference on Applications of  Computer Vision (WACV 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种增强神经符号模型以进行反事实推理的方法，利用符号推理来处理事件间的因果关系。&lt;h4&gt;背景&lt;/h4&gt;关于视频动态的因果和时序推理是一个挑战性问题。尽管神经符号模型结合了符号推理和基于神经的感知与预测，但它们在回答反事实问题时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;目的是提出一种方法来增强神经符号模型，使其能够更好地处理反事实推理。&lt;h4&gt;方法&lt;/h4&gt;方法包括定义因果图来表示事件间的因果关系，并使用声明式逻辑编程方法Answer Set Programming (ASP)来协调感知和模拟模块。&lt;h4&gt;主要发现&lt;/h4&gt;在两个基准测试CLEVRER和CRAFT上验证了该方法的有效性。该方法在CLEVRER挑战中实现了最先进的性能，显著优于现有模型。在CRAFT基准测试中，通过使用大型的预训练语言模型（如GPT-3.5和GPT-4）作为动态模拟器的代理，进一步提高了反事实问题的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法通过提供由符号因果推理指导的替代提示，可以进一步改善反事实问题的性能。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Causal and temporal reasoning about video dynamics is a challenging problem. While neuro-symbolic models that combine symbolic reasoning with neural-based perception and prediction have shown promise, they exhibit limitations, especially in answering counterfactual questions. This paper introduces a method to enhance a neuro-symbolic model for counterfactual reasoning, leveraging symbolic reasoning about causal relations among events. We define the notion of a causal graph to represent such relations and use Answer Set Programming (ASP), a declarative logic programming method, to find how to coordinate perception and simulation modules. We validate the effectiveness of our approach on two benchmarks, CLEVRER and CRAFT. Our enhancement achieves state-of-the-art performance on the CLEVRER challenge, significantly outperforming existing models. In the case of the CRAFT benchmark, we leverage a large pre-trained language model, such as GPT-3.5 and GPT-4, as a proxy for a dynamics simulator. Our findings show that this method can further improve its performance on counterfactual questions by providing alternative prompts instructed by symbolic causal reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Causal and temporal reasoning about video dynamics is a challenging problem.While neuro-symbolic models that combine symbolic reasoning with neural-basedperception and prediction have shown promise, they exhibit limitations,especially in answering counterfactual questions. This paper introduces amethod to enhance a neuro-symbolic model for counterfactual reasoning,leveraging symbolic reasoning about causal relations among events. We definethe notion of a causal graph to represent such relations and use Answer SetProgramming (ASP), a declarative logic programming method, to find how tocoordinate perception and simulation modules. We validate the effectiveness ofour approach on two benchmarks, CLEVRER and CRAFT. Our enhancement achievesstate-of-the-art performance on the CLEVRER challenge, significantlyoutperforming existing models. In the case of the CRAFT benchmark, we leveragea large pre-trained language model, such as GPT-3.5 and GPT-4, as a proxy for adynamics simulator. Our findings show that this method can further improve itsperformance on counterfactual questions by providing alternative promptsinstructed by symbolic causal reasoning.</description>
      <author>example@mail.com (Adam Ishay, Zhun Yang, Joohyung Lee, Ilgu Kang, Dongjae Lim)</author>
      <guid isPermaLink="false">2506.10753v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>3DGeoDet: General-purpose Geometry-aware Image-based 3D Object Detection</title>
      <link>http://arxiv.org/abs/2506.09541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE Transactions on Multimedia&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为3DGeoDet的新型几何感知3D目标检测方法，该方法能够有效地处理室内和室外环境中的单视角和多视角RGB图像，并展示了其通用适用性。&lt;h4&gt;背景&lt;/h4&gt;基于图像的3D目标检测任务的关键挑战在于缺乏3D几何线索，这导致了图像和3D表示之间对应关系的模糊性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，3DGeoDet通过预测的深度信息，以显式和隐式的方式生成高效的3D几何表示。&lt;h4&gt;方法&lt;/h4&gt;具体来说，利用预测的深度信息学习体素占用情况，并通过提出的体素占用注意力机制显式地优化体素化的3D特征体积。此外，为了进一步增强3D感知，将特征体积与隐式的3D表示（截断符号距离函数）集成。该方法无需3D信号监督，通过利用中间3D表示显著提高了模型对3D几何的理解，并实现了端到端的训练。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在单视角和多视角基准数据集上均超越了最先进的方法，在SUN RGB-D数据集上实现了9.3 mAP@0.5的提升，在ScanNetV2数据集上实现了3.3 mAP@0.5的提升，在KITTI数据集上实现了0.19AP3D@0.7的提升。&lt;h4&gt;结论&lt;/h4&gt;3DGeoDet项目页面：https://cindy0725.github.io/3DGeoDet/&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes 3DGeoDet, a novel geometry-aware 3D object detection approach that effectively handles single- and multi-view RGB images in indoor and outdoor environments, showcasing its general-purpose applicability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes 3DGeoDet, a novel geometry-aware 3D object detectionapproach that effectively handles single- and multi-view RGB images in indoorand outdoor environments, showcasing its general-purpose applicability. The keychallenge for image-based 3D object detection tasks is the lack of 3D geometriccues, which leads to ambiguity in establishing correspondences between imagesand 3D representations. To tackle this problem, 3DGeoDet generates efficient 3Dgeometric representations in both explicit and implicit manners based onpredicted depth information. Specifically, we utilize the predicted depth tolearn voxel occupancy and optimize the voxelized 3D feature volume explicitlythrough the proposed voxel occupancy attention. To further enhance 3Dawareness, the feature volume is integrated with an implicit 3D representation,the truncated signed distance function (TSDF). Without requiring supervisionfrom 3D signals, we significantly improve the model's comprehension of 3Dgeometry by leveraging intermediate 3D representations and achieve end-to-endtraining. Our approach surpasses the performance of state-of-the-artimage-based methods on both single- and multi-view benchmark datasets acrossdiverse environments, achieving a 9.3 mAP@0.5 improvement on the SUN RGB-Ddataset, a 3.3 mAP@0.5 improvement on the ScanNetV2 dataset, and a 0.19AP3D@0.7 improvement on the KITTI dataset. The project page is available at:https://cindy0725.github.io/3DGeoDet/.</description>
      <author>example@mail.com (Yi Zhang, Yi Wang, Yawen Cui, Lap-Pui Chau)</author>
      <guid isPermaLink="false">2506.09541v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Cosmos-Drive-Dreams: Scalable Synthetic Driving Data Generation with World Foundation Models</title>
      <link>http://arxiv.org/abs/2506.09042v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Only the core contributors are listed. The full list of contributors  can be found in Appendix A of this paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Cosmos-Drive-Dreams的合成数据生成管道，用于生成高保真、具有挑战性的场景，以辅助自动驾驶车辆系统的感知和驾驶策略训练。&lt;h4&gt;背景&lt;/h4&gt;收集和注释现实世界数据对于自动驾驶车辆等安全关键物理AI系统来说既耗时又昂贵，尤其难以捕捉罕见的边缘情况。&lt;h4&gt;目的&lt;/h4&gt;提出Cosmos-Drive-Dreams，旨在生成具有挑战性的场景，以促进后续任务如感知和驾驶策略训练。&lt;h4&gt;方法&lt;/h4&gt;Cosmos-Drive-Dreams由Cosmos-Drive模型驱动，该模型是从NVIDIA Cosmos世界基础模型针对驾驶领域专门设计的，能够生成可控、高保真、多视角和时空一致性的驾驶视频。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，生成的数据有助于缓解长尾分布问题，并增强了下游任务（如3D车道检测、3D物体检测和驾驶策略学习）的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文开源了Cosmos-Drive-Dreams的管道工具包、数据集和模型权重，通过NVIDIA的Cosmos平台提供。&lt;h4&gt;翻译&lt;/h4&gt;Collecting and annotating real-world data for safety-critical physical AI systems, such as Autonomous Vehicle (AV), is time-consuming and costly. It is especially challenging to capture rare edge cases, which play a critical role in training and testing of an AV system. To address this challenge, we introduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipeline that aims to generate challenging scenarios to facilitate downstream tasks such as perception and driving policy training. Powering this pipeline is Cosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundation model for the driving domain and are capable of controllable, high-fidelity, multi-view, and spatiotemporally consistent driving video generation. We showcase the utility of these models by applying Cosmos-Drive-Dreams to scale the quantity and diversity of driving datasets with high-fidelity and challenging scenarios. Experimentally, we demonstrate that our generated data helps in mitigating long-tail distribution problems and enhances generalization in downstream tasks such as 3D lane detection, 3D object detection and driving policy learning. We open source our pipeline toolkit, dataset and model weight through the NVIDIA's Cosmos platform.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Collecting and annotating real-world data for safety-critical physical AIsystems, such as Autonomous Vehicle (AV), is time-consuming and costly. It isespecially challenging to capture rare edge cases, which play a critical rolein training and testing of an AV system. To address this challenge, weintroduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipelinethat aims to generate challenging scenarios to facilitate downstream tasks suchas perception and driving policy training. Powering this pipeline isCosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundationmodel for the driving domain and are capable of controllable, high-fidelity,multi-view, and spatiotemporally consistent driving video generation. Weshowcase the utility of these models by applying Cosmos-Drive-Dreams to scalethe quantity and diversity of driving datasets with high-fidelity andchallenging scenarios. Experimentally, we demonstrate that our generated datahelps in mitigating long-tail distribution problems and enhances generalizationin downstream tasks such as 3D lane detection, 3D object detection and drivingpolicy learning. We open source our pipeline toolkit, dataset and model weightsthrough the NVIDIA's Cosmos platform.  Project page: https://research.nvidia.com/labs/toronto-ai/cosmos_drive_dreams</description>
      <author>example@mail.com (Xuanchi Ren, Yifan Lu, Tianshi Cao, Ruiyuan Gao, Shengyu Huang, Amirmojtaba Sabour, Tianchang Shen, Tobias Pfaff, Jay Zhangjie Wu, Runjian Chen, Seung Wook Kim, Jun Gao, Laura Leal-Taixe, Mike Chen, Sanja Fidler, Huan Ling)</author>
      <guid isPermaLink="false">2506.09042v2</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Text to Image for Multi-Label Image Recognition with Joint Prompt-Adapter Learning</title>
      <link>http://arxiv.org/abs/2506.10575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为T2I-PAL的新方法，用于解决仅使用文本描述进行参数高效微调（PEFT）时的模态差距问题，显著提升了图像识别性能。&lt;h4&gt;背景&lt;/h4&gt;预训练视觉语言模型如CLIP能够直接利用文本作为图像进行参数高效微调，但模态差距限制了其性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来减少模态差距，以提升仅使用文本描述进行PEFT时的图像识别性能。&lt;h4&gt;方法&lt;/h4&gt;T2I-PAL利用预训练的文本到图像生成模型从文本描述生成逼真的图像，结合类别级别的热图和可学习原型，以及提示调整和适配器学习来增强分类性能。&lt;h4&gt;主要发现&lt;/h4&gt;T2I-PAL消除了对完全语义标注训练图像的需求，减少了人工标注工作量，并保持了CLIP模型的原生模式，使其能够与任何现有的CLIP框架无缝集成。&lt;h4&gt;结论&lt;/h4&gt;在多个基准数据集上的实验表明，T2I-PAL的平均识别性能比现有最佳方法提高了3.47%。&lt;h4&gt;翻译&lt;/h4&gt;Benefited from image-text contrastive learning, pre-trained vision-language models, e.g., CLIP, allow to direct leverage texts as images (TaI) for parameter-efficient fine-tuning (PEFT). While CLIP is capable of making image features to be similar to the corresponding text features, the modality gap remains a nontrivial issue and limits the image recognition performance of TaI. Using multi-label image recognition (MLR) as an example, we present a novel method, called T2I-PAL to tackle the modality gap issue when using only text captions for PEFT. The core design of T2I-PAL is to leverage pre-trained text-to-image generation models to generate photo-realistic and diverse images from text captions, thereby reducing the modality gap. To further enhance MLR, T2I-PAL incorporates a class-wise heatmap and learnable prototypes. This aggregates local similarities, making the representation of local visual features more robust and informative for multi-label recognition. For better PEFT, we further combine both prompt tuning and adapter learning to enhance classification performance. T2I-PAL offers significant advantages: it eliminates the need for fully semantically annotated training images, thereby reducing the manual annotation workload, and it preserves the intrinsic mode of the CLIP model, allowing for seamless integration with any existing CLIP framework. Extensive experiments on multiple benchmarks, including MS-COCO, VOC2007, and NUS-WIDE, show that our T2I-PAL can boost recognition performance by 3.47% on average above the top-ranked state-of-the-art methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TPAMI.2025.3573852&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Benefited from image-text contrastive learning, pre-trained vision-languagemodels, e.g., CLIP, allow to direct leverage texts as images (TaI) forparameter-efficient fine-tuning (PEFT). While CLIP is capable of making imagefeatures to be similar to the corresponding text features, the modality gapremains a nontrivial issue and limits image recognition performance of TaI.Using multi-label image recognition (MLR) as an example, we present a novelmethod, called T2I-PAL to tackle the modality gap issue when using only textcaptions for PEFT. The core design of T2I-PAL is to leverage pre-trainedtext-to-image generation models to generate photo-realistic and diverse imagesfrom text captions, thereby reducing the modality gap. To further enhance MLR,T2I-PAL incorporates a class-wise heatmap and learnable prototypes. Thisaggregates local similarities, making the representation of local visualfeatures more robust and informative for multi-label recognition. For betterPEFT, we further combine both prompt tuning and adapter learning to enhanceclassification performance. T2I-PAL offers significant advantages: iteliminates the need for fully semantically annotated training images, therebyreducing the manual annotation workload, and it preserves the intrinsic mode ofthe CLIP model, allowing for seamless integration with any existing CLIPframework. Extensive experiments on multiple benchmarks, including MS-COCO,VOC2007, and NUS-WIDE, show that our T2I-PAL can boost recognition performanceby 3.47% in average above the top-ranked state-of-the-art methods.</description>
      <author>example@mail.com (Chun-Mei Feng, Kai Yu, Xinxing Xu, Salman Khan, Rick Siow Mong Goh, Wangmeng Zuo, Yong Liu)</author>
      <guid isPermaLink="false">2506.10575v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Air in Your Neighborhood: Fine-Grained AQI Forecasting Using Mobile Sensor Data</title>
      <link>http://arxiv.org/abs/2506.10332v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 7 figures. Code available at  https://github.com/ASChampOmega/AQI_Forecasting.git&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过预测1平方公里区域内的空气质量指数（AQI），解决了发展中国家空气质量监测数据不足的问题。&lt;h4&gt;背景&lt;/h4&gt;发展中国家空气污染成为重要的健康风险，政府虽然发布AQI数据，但传感器分布稀疏，无法准确反映当地实际情况。&lt;h4&gt;目的&lt;/h4&gt;预测1平方公里区域内的AQI，以解决现有空气质量监测数据的不足。&lt;h4&gt;方法&lt;/h4&gt;采用时空图神经网络（Spatio-temporal GNNs）进行AQI预测，并使用AirDelhi数据集作为案例。&lt;h4&gt;主要发现&lt;/h4&gt;预测结果比现有方法提高了71.654 MSE，减少79%的误差，即使在未标记的坐标上也有显著效果。发现AQI存在强烈的重复短期模式和不断变化的空间关系。&lt;h4&gt;结论&lt;/h4&gt;时空图神经网络在预测空气质量指数方面表现出色，为解决空气质量监测数据不足问题提供了新的方法。&lt;h4&gt;翻译&lt;/h4&gt;Air pollution has become a significant health risk in developing countries. While governments routinely publish air-quality index (AQI) data to track pollution, these values fail to capture the local reality, as sensors are often very sparse. In this paper, we address this gap by predicting AQI in 1 km^2 neighborhoods, using the example of AirDelhi dataset. Using Spatio-temporal GNNs we surpass existing works by 71.654 MSE, a 79% reduction, even on unseen coordinates. New insights about AQI such as the existence of strong repetitive short-term patterns and changing spatial relations are also discovered. The code is available on GitHub.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Air pollution has become a significant health risk in developing countries.While governments routinely publish air-quality index (AQI) data to trackpollution, these values fail to capture the local reality, as sensors are oftenvery sparse. In this paper, we address this gap by predicting AQI in 1 km^2neighborhoods, using the example of AirDelhi dataset. Using Spatio-temporalGNNs we surpass existing works by 71.654 MSE a 79% reduction, even on unseencoordinates. New insights about AQI such as the existence of strong repetitiveshort-term patterns and changing spatial relations are also discovered. Thecode is available on GitHub.</description>
      <author>example@mail.com (Aaryam Sharma)</author>
      <guid isPermaLink="false">2506.10332v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Adv-BMT: Bidirectional Motion Transformer for Safety-Critical Traffic Scenario Generation</title>
      <link>http://arxiv.org/abs/2506.09485v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Adv-BMT的框架，用于解决自动驾驶系统测试中长尾、安全关键场景数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的自动驾驶系统测试数据集中，缺乏长尾、安全关键场景的数据。&lt;h4&gt;目的&lt;/h4&gt;为了解决数据稀缺的问题，提出了一种名为Adv-BMT的框架。&lt;h4&gt;方法&lt;/h4&gt;Adv-BMT框架通过增强现实世界场景中的多样化、真实对抗性交互来扩充数据。其核心组件是双向运动转换器（BMT）模型，用于执行逆交通运动预测，并按逆时间顺序重建交通情况。该框架分为两个阶段：首先进行对抗性初始化，然后进行逆运动预测。&lt;h4&gt;主要发现&lt;/h4&gt;Adv-BMT框架不需要任何碰撞数据进行预训练，能够生成真实且多样化的碰撞交互。实验结果表明，在增强数据集上进行训练，与之前的工作相比，可以降低20%的碰撞率。&lt;h4&gt;结论&lt;/h4&gt;Adv-BMT框架能够有效提高自动驾驶系统测试数据的质量，并减少碰撞率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scenario-based testing is essential for validating the performance ofautonomous driving (AD) systems. However, such testing is limited by thescarcity of long-tailed, safety-critical scenarios in existing datasetscollected in the real world. To tackle the data issue, we propose the Adv-BMTframework, which augments real-world scenarios with diverse and realisticadversarial interactions. The core component of Adv-BMT is a bidirectionalmotion transformer (BMT) model to perform inverse traffic motion predictions,which takes agent information in the last time step of the scenario as input,and reconstruct the traffic in the inverse of chronological order until theinitial time step. The Adv-BMT framework is a two-staged pipeline: it firstconducts adversarial initializations and then inverse motion predictions.Different from previous work, we do not need any collision data forpretraining, and are able to generate realistic and diverse collisioninteractions. Our experimental results validate the quality of generatedcollision scenarios by Adv-BMT: training in our augmented dataset would reduceepisode collision rates by 20\% compared to previous work.</description>
      <author>example@mail.com (Yuxin Liu, Zhenghao Peng, Xuanhao Cui, Bolei Zhou)</author>
      <guid isPermaLink="false">2506.09485v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>In-Hand Object Pose Estimation via Visual-Tactile Fusion</title>
      <link>http://arxiv.org/abs/2506.10787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合视觉和触觉信息进行机器人手部物体姿态估计的方法，以解决视觉遮挡问题。&lt;h4&gt;背景&lt;/h4&gt;精确的手部物体姿态估计对于机器人操作至关重要，但视觉遮挡是视觉方法的一个主要挑战。&lt;h4&gt;目的&lt;/h4&gt;准确确定机器人手部抓取物体的位置和方向。&lt;h4&gt;方法&lt;/h4&gt;该方法通过融合手腕上的RGB-D相机的视觉信息和机器人夹爪指尖上的基于视觉的触觉传感器的触觉信息来解决视觉遮挡问题。它使用一个加权传感器融合模块来结合不同类型传感器的点云数据，并控制每个模态对姿态估计过程的贡献。使用改进的加权点云迭代的最近点（ICP）算法来估计6D物体姿态。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，结合触觉信息显著提高了姿态估计的准确性，尤其是在遮挡较高的情况下。该方法实现了平均姿态估计误差为7.5毫米和16.7度，比仅视觉的基线方法提高了高达20%。&lt;h4&gt;结论&lt;/h4&gt;该方法能够执行精确的物体操作，在现实世界的插入任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Accurate in-hand pose estimation is crucial for robotic object manipulation, but visual occlusion remains a major challenge for vision-based approaches. This paper presents an approach to robotic in-hand object pose estimation, combining visual and tactile information to accurately determine the position and orientation of objects grasped by a robotic hand. We address the challenge of visual occlusion by fusing visual information from a wrist-mounted RGB-D camera with tactile information from vision-based tactile sensors mounted on the fingertips of a robotic gripper. Our approach employs a weighting and sensor fusion module to combine point clouds from heterogeneous sensor types and control each modality's contribution to the pose estimation process. We use an augmented Iterative Closest Point (ICP) algorithm adapted for weighted point clouds to estimate the 6D object pose. Our experiments show that incorporating tactile information significantly improves pose estimation accuracy, particularly when occlusion is high. Our method achieves an average pose estimation error of 7.5 mm and 16.7 degrees, outperforming vision-only baselines by up to 20%. We also demonstrate the ability of our method to perform precise object manipulation in a real-world insertion task.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate in-hand pose estimation is crucial for robotic object manipulation,but visual occlusion remains a major challenge for vision-based approaches.This paper presents an approach to robotic in-hand object pose estimation,combining visual and tactile information to accurately determine the positionand orientation of objects grasped by a robotic hand. We address the challengeof visual occlusion by fusing visual information from a wrist-mounted RGB-Dcamera with tactile information from vision-based tactile sensors mounted onthe fingertips of a robotic gripper. Our approach employs a weighting andsensor fusion module to combine point clouds from heterogeneous sensor typesand control each modality's contribution to the pose estimation process. We usean augmented Iterative Closest Point (ICP) algorithm adapted for weighted pointclouds to estimate the 6D object pose. Our experiments show that incorporatingtactile information significantly improves pose estimation accuracy,particularly when occlusion is high. Our method achieves an average poseestimation error of 7.5 mm and 16.7 degrees, outperforming vision-onlybaselines by up to 20%. We also demonstrate the ability of our method toperform precise object manipulation in a real-world insertion task.</description>
      <author>example@mail.com (Felix Nonnengießer, Alap Kshirsagar, Boris Belousov, Jan Peters)</author>
      <guid isPermaLink="false">2506.10787v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Probabilistic Variational Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.10159v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了基于对比学习的确定性嵌入方法，如SimCLR和SupCon，虽然取得了很好的性能，但缺乏不确定性量化机制。文章提出了变分对比学习（VCL），这是一种无解码器框架，通过将InfoNCE损失视为代理重构项，并在单位超球面上添加KL散度正则化项来最大化证据下界（ELBO）。&lt;h4&gt;背景&lt;/h4&gt;当前对比学习方法如SimCLR和SupCon在性能上达到了最先进的水平，但它们缺乏一个用于不确定性量化的原理性机制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的变分对比学习（VCL）框架，以提供不确定性量化和概率性嵌入。&lt;h4&gt;方法&lt;/h4&gt;VCL框架通过将InfoNCE损失视为代理重构项，并添加KL散度正则化项来最大化证据下界。近似后验分布$q_heta(z|x)$被建模为投影正态分布，从而实现概率性嵌入的采样。VSimCLR和VSupCon是VCL的两个实现，它们用$q_heta(z|x)$的样本替换确定性嵌入，并将归一化KL项纳入损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，VCL减轻了维度塌陷，增强了与类标签的互信息，并且在分类准确率上与确定性基线相匹配或超越，同时通过后验模型提供有意义的不确定性估计。&lt;h4&gt;结论&lt;/h4&gt;VCL为对比学习提供了一个概率基础，成为对比方法的新基准。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes a variational contrastive learning (VCL) framework, which is a decoder-free architecture that maximizes the evidence lower bound (ELBO) by interpreting the InfoNCE loss as a surrogate reconstruction term and adding a KL divergence regularizer to a uniform prior on the unit hypersphere. The approximate posterior $q_heta(z|x)$ is modeled as a projected normal distribution, enabling the sampling of probabilistic embeddings. The two instantiations--VSimCLR and VSupCon--replace deterministic embeddings with samples from $q_heta(z|x)$ and incorporate a normalized KL term into the loss. Experiments on multiple benchmarks demonstrate that VCL mitigates dimension collapse, enhances mutual information with class labels, and matches or outperforms deterministic baselines in classification accuracy, all the while providing meaningful uncertainty estimates through the posterior model. VCL thus equips contrastive learning with a probabilistic foundation, serving as a new basis for contrastive approaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deterministic embeddings learned by contrastive learning (CL) methods such asSimCLR and SupCon achieve state-of-the-art performance but lack a principledmechanism for uncertainty quantification. We propose Variational ContrastiveLearning (VCL), a decoder-free framework that maximizes the evidence lowerbound (ELBO) by interpreting the InfoNCE loss as a surrogate reconstructionterm and adding a KL divergence regularizer to a uniform prior on the unithypersphere. We model the approximate posterior $q_\theta(z|x)$ as a projectednormal distribution, enabling the sampling of probabilistic embeddings. Our twoinstantiations--VSimCLR and VSupCon--replace deterministic embeddings withsamples from $q_\theta(z|x)$ and incorporate a normalized KL term into theloss. Experiments on multiple benchmarks demonstrate that VCL mitigatesdimensional collapse, enhances mutual information with class labels, andmatches or outperforms deterministic baselines in classification accuracy, allthe while providing meaningful uncertainty estimates through the posteriormodel. VCL thus equips contrastive learning with a probabilistic foundation,serving as a new basis for contrastive approaches.</description>
      <author>example@mail.com (Minoh Jeong, Seonho Kim, Alfred Hero)</author>
      <guid isPermaLink="false">2506.10159v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Analyzing the relationships between pretraining language, phonetic, tonal, and speaker information in self-supervised speech models</title>
      <link>http://arxiv.org/abs/2506.10855v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文分析了wav2vec2模型在四种不同语言上的训练情况，探讨了模型如何编码语言匹配和非匹配的语音信息，并分析了音素、词汇音调和说话人信息的表示方式。&lt;h4&gt;背景&lt;/h4&gt;以往的分析主要集中在英语上，而本文旨在扩展这一研究到其他语言。&lt;h4&gt;目的&lt;/h4&gt;研究wav2vec2模型在多种语言上的表现，以及模型如何处理不同类型的语音信息。&lt;h4&gt;方法&lt;/h4&gt;使用探针分类器和几何分析方法，对音素、词汇音调和说话人信息的表示进行了研究。&lt;h4&gt;主要发现&lt;/h4&gt;所有预训练和测试语言中，编码音素、音调和说话人的子空间大部分是正交的，层级的探针准确率模式相似，在后期层中，匹配语言的音素和音调探针（但不是说话人）有相对较小的优势。&lt;h4&gt;结论&lt;/h4&gt;wav2vec2学习到的表示结构在很大程度上独立于预训练期间使用的语音材料。&lt;h4&gt;翻译&lt;/h4&gt;摘要：对自监督语音模型的分析已经开始揭示它们如何表示不同类型的信息。然而，几乎所有分析都集中在英语上。在这里，我们检验了在四种不同语言上训练的wav2vec2模型如何编码匹配和非匹配的语音。我们使用探针分类器和几何分析来检验音素、词汇音调和说话人信息是如何表示的。我们发现，对于所有预训练和测试语言，编码音素、音调和说话人的子空间大部分是正交的，并且层级的探针准确率模式相似，在后期层中，匹配语言的音素和音调探针（但不是说话人）有相对较小的优势。我们的发现表明，wav2vec2学习到的表示结构在很大程度上独立于预训练期间使用的语音材料。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Analyses of self-supervised speech models have begun to reveal where and howthey represent different types of information. However, almost all analyseshave focused on English. Here, we examine how wav2vec2 models trained on fourdifferent languages encode both language-matched and non-matched speech. We useprobing classifiers and geometric analyses to examine how phones, lexicaltones, and speaker information are represented. We show that for allpretraining and test languages, the subspaces encoding phones, tones, andspeakers are largely orthogonal, and that layerwise patterns of probingaccuracy are similar, with a relatively small advantage for matched-languagephone and tone (but not speaker) probes in the later layers. Our findingssuggest that the structure of representations learned by wav2vec2 is largelyindependent of the speech material used during pretraining.</description>
      <author>example@mail.com (Michele Gubian, Ioana Krehan, Oli Liu, James Kirby, Sharon Goldwater)</author>
      <guid isPermaLink="false">2506.10855v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Distillation of atomistic foundation models across architectures and chemical domains</title>
      <link>http://arxiv.org/abs/2506.10956v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文展示了如何通过合成数据的蒸馏方法，将原子基础模型的知识转移到不同架构上，以获得更小、更高效的势场。&lt;h4&gt;背景&lt;/h4&gt;机器学习原子间势场在物理科学研究中发挥了重要作用。最近的原子基础模型虽然应用广泛，但运行速度慢、资源密集。&lt;h4&gt;目的&lt;/h4&gt;通过蒸馏方法，以降低计算成本，提高效率，将原子基础模型的知识应用于不同架构。&lt;h4&gt;方法&lt;/h4&gt;使用合成数据的蒸馏技术，将知识从一种图网络架构转移到另一种架构，并利用原子簇扩展框架。&lt;h4&gt;主要发现&lt;/h4&gt;从一种图网络架构蒸馏到另一种，速度提高超过10倍；利用原子簇扩展框架，速度提高超过100倍。&lt;h4&gt;结论&lt;/h4&gt;该方法支持当前和未来原子基础模型在现实世界科学研究中的常规和计算高效使用。&lt;h4&gt;翻译&lt;/h4&gt;机器学习的原子间势场已经改变了物理科学中的计算研究。最近的原子基础模型再次改变了这个领域：这些势场在许多不同的化学元素和领域上进行了训练，因此应用广泛，但相比之下运行速度较慢，资源密集。在这里，我们展示了如何通过合成数据的蒸馏方法来低成本地将知识从原子基础模型转移到各种不同的架构上，从而解锁更小、更高效的势场。我们通过从一种图网络架构蒸馏到另一种架构，以及利用原子簇扩展框架，展示了超过10倍的速度提升和超过100倍的速度提升。我们在化学和材料领域展示了其适用性：从液态水到极端条件下的氢气；从多孔二氧化硅和混合卤化物钙钛矿太阳能电池材料到有机反应建模。我们的工作展示了蒸馏如何支持当前和未来原子基础模型在现实世界科学研究中的常规和计算高效使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learned interatomic potentials have transformed computationalresearch in the physical sciences. Recent atomistic `foundation' models havechanged the field yet again: trained on many different chemical elements anddomains, these potentials are widely applicable, but comparably slow andresource-intensive to run. Here we show how distillation via synthetic data canbe used to cheaply transfer knowledge from atomistic foundation models to arange of different architectures, unlocking much smaller, more efficientpotentials. We demonstrate speed-ups of $&gt; 10\times$ by distilling from onegraph-network architecture into another, and $&gt; 100\times$ by leveraging theatomic cluster expansion framework. We showcase applicability across chemicaland materials domains: from liquid water to hydrogen under extreme conditions;from porous silica and a hybrid halide perovskite solar-cell material tomodelling organic reactions. Our work shows how distillation can support theroutine and computationally efficient use of current and future atomisticfoundation models in real-world scientific research.</description>
      <author>example@mail.com (John L. A. Gardner, Daniel F. Thomas du Toit, Chiheb Ben Mahmoud, Zoé Faure Beaulieu, Veronika Juraskova, Laura-Bianca Paşca, Louise A. M. Rosset, Fernanda Duarte, Fausto Martelli, Chris J. Pickard, Volker L. Deringer)</author>
      <guid isPermaLink="false">2506.10956v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Gaussian2Scene: 3D Scene Representation Learning via Self-supervised Learning with 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.08777v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Gaussian2Scene的新型场景级自监督学习框架，用于点云预训练，以解决现有方法在场景表示和几何结构捕获方面的限制。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在点云预训练中已成为许多3D视觉任务的基础，它使得从大规模未标注数据中有效学习成为可能。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有自监督学习方法在场景表示和几何结构捕获方面的限制。&lt;h4&gt;方法&lt;/h4&gt;Gaussian2Scene利用3D高斯分层（3DGS）的效率和显式性，采用渐进式的两阶段训练策略：第一阶段使用双分支掩码自动编码器学习2D和3D场景表示；第二阶段以重建的点云初始化训练，并进一步使用高斯原语的几何位置和渲染的RGB图像进行监督学习。&lt;h4&gt;主要发现&lt;/h4&gt;Gaussian2Scene在多个下游3D目标检测任务中展示了有效性，与现有预训练方法相比，表现出了持续的性能提升。&lt;h4&gt;结论&lt;/h4&gt;Gaussian2Scene通过改进的场景级自监督学习框架，提高了3D几何理解，为3D视觉任务提供了更有效的预训练方法。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Self-supervised learning (SSL) for point cloud pre-training has become a cornerstone for many 3D vision tasks, enabling effective learning from large-scale unannotated data. At the scene level, existing SSL methods often incorporate volume rendering into the pre-training framework, using RGB-D images as reconstruction signals to facilitate cross-modal learning. This strategy promotes alignment between 2D and 3D modalities and enables the model to benefit from rich visual cues in the RGB-D inputs. However, these approaches are limited by their reliance on implicit scene representations and high memory demands. Furthermore, since their reconstruction objectives are applied only in 2D space, they often fail to capture underlying 3D geometric structures. To address these challenges, we propose Gaussian2Scene, a novel scene-level SSL framework that leverages the efficiency and explicit nature of 3D Gaussian Splatting (3DGS) for pre-training. The use of 3DGS not only alleviates the computational burden associated with volume rendering but also supports direct 3D scene reconstruction, thereby enhancing the geometric understanding of the backbone network. Our approach follows a progressive two-stage training strategy. In the first stage, a dual-branch masked autoencoder learns both 2D and 3D scene representations. In the second stage, we initialize training with reconstructed point clouds and further supervise learning using the geometric locations of Gaussian primitives and rendered RGB images. This process reinforces both geometric and cross-modal learning. We demonstrate the effectiveness of Gaussian2Scene across several downstream 3D object detection tasks, showing consistent improvements over existing pre-training methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) for point cloud pre-training has become acornerstone for many 3D vision tasks, enabling effective learning fromlarge-scale unannotated data. At the scene level, existing SSL methods oftenincorporate volume rendering into the pre-training framework, using RGB-Dimages as reconstruction signals to facilitate cross-modal learning. Thisstrategy promotes alignment between 2D and 3D modalities and enables the modelto benefit from rich visual cues in the RGB-D inputs. However, these approachesare limited by their reliance on implicit scene representations and high memorydemands. Furthermore, since their reconstruction objectives are applied only in2D space, they often fail to capture underlying 3D geometric structures. Toaddress these challenges, we propose Gaussian2Scene, a novel scene-level SSLframework that leverages the efficiency and explicit nature of 3D GaussianSplatting (3DGS) for pre-training. The use of 3DGS not only alleviates thecomputational burden associated with volume rendering but also supports direct3D scene reconstruction, thereby enhancing the geometric understanding of thebackbone network. Our approach follows a progressive two-stage trainingstrategy. In the first stage, a dual-branch masked autoencoder learns both 2Dand 3D scene representations. In the second stage, we initialize training withreconstructed point clouds and further supervise learning using the geometriclocations of Gaussian primitives and rendered RGB images. This processreinforces both geometric and cross-modal learning. We demonstrate theeffectiveness of Gaussian2Scene across several downstream 3D object detectiontasks, showing consistent improvements over existing pre-training methods.</description>
      <author>example@mail.com (Keyi Liu, Weidong Yang, Ben Fei, Ying He)</author>
      <guid isPermaLink="false">2506.08777v2</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Context-Adaptive Graph Neural Networks for Next POI Recommendation</title>
      <link>http://arxiv.org/abs/2506.10329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CAGNN的上下文自适应图神经网络，用于改进基于位置的服务中的Next Point-of-Interest推荐。&lt;h4&gt;背景&lt;/h4&gt;现有的Next POI推荐方法大多使用图神经网络（GNN）来结合协同信息，但它们通常将不同类型的上下文使用单独的图来建模，忽略了多个上下文因素之间的相互影响。&lt;h4&gt;目的&lt;/h4&gt;提出CAGNN的目的是为了解决上述方法的限制，如次优的注意力权重和推荐性能，以及过分重视序列组件的问题。&lt;h4&gt;方法&lt;/h4&gt;CAGNN通过以下方式实现改进：(1) 引入一个上下文自适应的注意力机制，在图传播过程中联合不同类型的上下文因素进行注意力计算；(2) 引入一个图-序列相互增强模块，通过KL散度对基于图和序列的模块的输出进行对齐。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CAGNN在三个真实世界数据集上始终优于现有方法，并且上下文自适应注意力机制提高了POI表示的表达能力。&lt;h4&gt;结论&lt;/h4&gt;CAGNN通过引入上下文自适应和相互增强机制，显著提升了Next POI推荐的准确性和性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Next POI推荐是位置服务中的一个关键任务，旨在根据用户的签到历史预测他们的下一次访问。虽然许多现有方法利用图神经网络（GNN）来结合协同信息并提高推荐准确性，但其中大多数使用单独的图来建模每种类型的上下文，将不同的因素孤立对待。这限制了它们建模多个上下文因素在消息传播期间对用户过渡的共同影响的能力，导致次优的注意力权重和推荐性能。此外，它们通常将序列组件作为主要预测因素，这可能会损害GNN学习的POI嵌入中的语义和结构信息。为了解决这些限制，我们提出了一个用于Next POI推荐的上下文自适应图神经网络（CAGNN），它通过使用边特定上下文因素动态调整注意力权重，并使基于图和序列的组件之间相互增强。具体来说，CAGNN引入了（1）一个上下文自适应的注意力机制，在图传播过程中联合不同类型的上下文因素进行注意力计算，使模型能够动态捕获协作和上下文依赖的过渡模式；（2）一个图-序列相互增强模块，通过KL散度对基于图和序列的模块的输出进行对齐。在三个真实世界数据集上的实验结果表明，CAGNN始终优于最先进的方法。同时，我们提供了理论保证，我们的上下文自适应注意力机制提高了POI表示的表达能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Next Point-of-Interest (POI) recommendation is a critical task inlocation-based services, aiming to predict users' next visits based on theircheck-in histories. While many existing methods leverage Graph Neural Networks(GNNs) to incorporate collaborative information and improve recommendationaccuracy, most of them model each type of context using separate graphs,treating different factors in isolation. This limits their ability to model theco-influence of multiple contextual factors on user transitions during messagepropagation, resulting in suboptimal attention weights and recommendationperformance. Furthermore, they often prioritize sequential components as theprimary predictor, potentially undermining the semantic and structuralinformation encoded in the POI embeddings learned by GNNs. To address theselimitations, we propose a Context-Adaptive Graph Neural Networks (CAGNN) fornext POI recommendation, which dynamically adjusts attention weights usingedge-specific contextual factors and enables mutual enhancement betweengraph-based and sequential components. Specifically, CAGNN introduces (1) acontext-adaptive attention mechanism that jointly incorporates different typesof contextual factors into the attention computation during graph propagation,enabling the model to dynamically capture collaborative and context-dependenttransition patterns; (2) a graph-sequential mutual enhancement module, whichaligns the outputs of the graph- and sequential-based modules via the KLdivergence, enabling mutual enhancement of both components. Experimentalresults on three real-world datasets demonstrate that CAGNN consistentlyoutperforms state-of-the-art methods. Meanwhile, theoretical guarantees areprovided that our context-adaptive attention mechanism improves theexpressiveness of POI representations.</description>
      <author>example@mail.com (Yu Lei, Limin Shen, Zhu Sun, Tiantian He, Yew-Soon Ong)</author>
      <guid isPermaLink="false">2506.10329v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Improving Medical Visual Representation Learning with Pathological-level Cross-Modal Alignment and Correlation Exploration</title>
      <link>http://arxiv.org/abs/2506.10573v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 10 tables and 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为PLACE的框架，用于从图像报告对中学习医学视觉表示，以解决医学领域数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;医学领域的数据稀缺问题，以及复杂文本关系和语义病理的挑战，促使研究者关注如何通过联合学习来学习医学视觉表示。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高病理观察的一致性，并通过关联探索丰富细节，无需额外的标注。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的病理级别跨模态对齐（PCMA）方法，通过视觉病理观察提取器从局部化标记中提取视觉病理观察表示。设计了一个代理任务，以强制模型识别图像块之间的相关性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该框架在多个下游任务上达到了新的最先进性能，包括分类、图像到文本检索、语义分割、目标检测和报告生成。&lt;h4&gt;结论&lt;/h4&gt;PLACE框架通过PCMA和关联探索，有效地提高了医学视觉表示的学习效果，为下游任务提供了高质量的数据表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning medical visual representations from image-report pairs through jointlearning has garnered increasing research attention due to its potential toalleviate the data scarcity problem in the medical domain. The primarychallenges stem from the lengthy reports that feature complex discourserelations and semantic pathologies. Previous works have predominantly focusedon instance-wise or token-wise cross-modal alignment, often neglecting theimportance of pathological-level consistency. This paper presents a novelframework PLACE that promotes the Pathological-Level Alignment and enriches thefine-grained details via Correlation Exploration without additional humanannotations. Specifically, we propose a novel pathological-level cross-modalalignment (PCMA) approach to maximize the consistency of pathology observationsfrom both images and reports. To facilitate this, a Visual PathologyObservation Extractor is introduced to extract visual pathological observationrepresentations from localized tokens. The PCMA module operates independentlyof any external disease annotations, enhancing the generalizability androbustness of our methods. Furthermore, we design a proxy task that enforcesthe model to identify correlations among image patches, thereby enriching thefine-grained details crucial for various downstream tasks. Experimental resultsdemonstrate that our proposed framework achieves new state-of-the-artperformance on multiple downstream tasks, including classification,image-to-text retrieval, semantic segmentation, object detection and reportgeneration.</description>
      <author>example@mail.com (Jun Wang, Lixing Zhu, Xiaohan Yu, Abhir Bhalerao, Yulan He)</author>
      <guid isPermaLink="false">2506.10573v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Efficient nanophotonic devices optimization using deep neural network trained with physics-based transfer learning (PBTL) methodology</title>
      <link>http://arxiv.org/abs/2506.10418v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于神经网络的代理建模框架，用于光子器件优化，特别是在特征重要性不平衡和高数据生成成本的环境中。&lt;h4&gt;背景&lt;/h4&gt;在特征重要性不平衡和高数据生成成本的环境中，传统优化方法难以应用于光子器件设计。&lt;h4&gt;目的&lt;/h4&gt;提供一种通用的光子设计自动化解决方案，即使在数据资源有限的情况下也能实现。&lt;h4&gt;方法&lt;/h4&gt;该框架包括基于物理的迁移学习（PBTL）增强的代理建模和标量化多目标遗传算法（GAs）。通过将深度神经网络总预测器（DNN-TP）与遗传算法（GA）结合，实现了可扩展和自然启发的优化。引入PBTL，从在活动区域结构上训练的DNN核心预测器（DNN-CP）中转移知识，以提高模型泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;优化了包含活动区和注入区两个区域的中红外量子级联激光器（QCL）结构，这些区域具有不同的特征重要性水平。通过使用DNN-TP代理模型代替计算成本高的数值模拟，优化速度提高了超过80,000倍，允许大规模探索QCL设计空间。PBTL的应用提高了预测准确性，减少了训练数据需求，并提高了优化过程中的器件结构可行性。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地解决了光子器件优化中的挑战，提高了设计自动化水平，并为数据资源有限的情况提供了高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a neural network(NN)-based surrogate modeling framework forphotonic device optimization, especially in domains with imbalanced featureimportance and high data generation costs. Our framework, which comprisesphysics-based transfer learning (PBTL)-enhanced surrogate modeling andscalarized multi-objective genetic algorithms (GAs), offers a generalizablesolution for photonic design automation with minimal data resources.To validatethe framework, we optimize mid-infrared quantum cascade laser (QCL) structuresconsisting of two regions, active and injection, which have different levels offeature importance. The optimization targets include five key QCL performancemetrics such as modal gain, emission wavelength, linewidth, and effectiveinjection, extraction energies. To address the challenge of multiple localoptima in the output latent space, we integrate a deep neural network totalpredictor (DNN-TP) with a GA, enabling scalable and nature-inspiredoptimization. By replacing computationally expensive numerical simulations withthe DNN-TP surrogate model, the optimization achieves a speed-up of over 80,000times, allowing large-scale exploration of the QCL design space.To improvemodel generalization with limited data, we introduce PBTL, which transfersknowledge from a DNN core predictor (DNN-CP) trained on active-regionstructures. This approach yields a 0.69 percentage increase in predictionaccuracy, equivalent to a 50 percentage reduction in training datarequirements, and leads to generate more feasible device structure with 60percentage improvement in evaluation metric during optimization.</description>
      <author>example@mail.com (Gibaek Kim, Jungho Kim)</author>
      <guid isPermaLink="false">2506.10418v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>SpikeSMOKE: Spiking Neural Networks for Monocular 3D Object Detection with Cross-Scale Gated Coding</title>
      <link>http://arxiv.org/abs/2506.07737v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SpikeSMOKE的基于脉冲神经网络（SNNs）的低功耗单目3D物体检测架构，旨在解决自动驾驶等应用场景中3D物体检测的能量消耗问题。&lt;h4&gt;背景&lt;/h4&gt;随着3D物体检测在自动驾驶等领域的广泛应用，其能量消耗问题日益突出。&lt;h4&gt;目的&lt;/h4&gt;通过应用SNNs技术，提出一种低功耗的单目3D物体检测方法。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种名为CSGC的跨尺度门控编码机制，通过结合跨尺度融合的注意力方法和门控滤波机制来增强特征表示能力；2. 设计了一种轻量级的残差块，以保持脉冲计算范式并提高检测性能；3. 在KITTI自动驾驶数据集上进行了实验验证。&lt;h4&gt;主要发现&lt;/h4&gt;1. 与传统的SNNs相比，SpikeSMOKE在保持高检测性能的同时，能够显著降低能量消耗；2. 在困难类别上，能量消耗可以降低72.2%，而检测性能仅降低4%；3. SpikeSMOKE-L（轻量级）相比SMOKE，参数数量减少了3倍，计算量减少了10倍。&lt;h4&gt;结论&lt;/h4&gt;SpikeSMOKE是一种有效的低功耗单目3D物体检测方法，在降低能量消耗的同时，保持了较高的检测性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low energy consumption for 3D object detection is an important research areabecause of the increasing energy consumption with their wide application infields such as autonomous driving. The spiking neural networks (SNNs) withlow-power consumption characteristics can provide a novel solution for thisresearch. Therefore, we apply SNNs to monocular 3D object detection and proposethe SpikeSMOKE architecture in this paper, which is a new attempt for low-powermonocular 3D object detection. As we all know, discrete signals of SNNs willgenerate information loss and limit their feature expression ability comparedwith the artificial neural networks (ANNs).In order to address this issue,inspired by the filtering mechanism of biological neuronal synapses, we proposea cross-scale gated coding mechanism(CSGC), which can enhance featurerepresentation by combining cross-scale fusion of attentional methods and gatedfiltering mechanisms.In addition, to reduce the computation and increase thespeed of training, we present a novel light-weight residual block that canmaintain spiking computing paradigm and the highest possible detectionperformance. Compared to the baseline SpikeSMOKE under the 3D Object Detection,the proposed SpikeSMOKE with CSGC can achieve 11.78 (+2.82, Easy), 10.69 (+3.2,Moderate), and 10.48 (+3.17, Hard) on the KITTI autonomous driving dataset byAP|R11 at 0.7 IoU threshold, respectively. It is important to note that theresults of SpikeSMOKE can significantly reduce energy consumption compared tothe results on SMOKE. For example,the energy consumption can be reduced by72.2% on the hard category, while the detection performance is reduced by only4%. SpikeSMOKE-L (lightweight) can further reduce the amount of parameters by 3times and computation by 10 times compared to SMOKE.</description>
      <author>example@mail.com (Xuemei Chen, Huamin Wang, Hangchi Shen, Shukai Duan, Shiping Wen, Tingwen Huang)</author>
      <guid isPermaLink="false">2506.07737v2</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Graph-MLLM: Harnessing Multimodal Large Language Models for Multimodal Graph Learning</title>
      <link>http://arxiv.org/abs/2506.10282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了多模态大型语言模型（MLLMs）在多模态表示和理解方面的能力，并提出了Graph-MLLM，一个用于多模态图学习的综合基准，以评估不同的学习范式。&lt;h4&gt;背景&lt;/h4&gt;MLLMs在多模态表示和理解方面表现出色，但通常只关注成对模态的对齐，而忽略了数据点之间的结构关系。&lt;h4&gt;目的&lt;/h4&gt;提出Graph-MLLM，旨在为多模态图学习提供一个统一的基准，以公平地评估不同的学习范式。&lt;h4&gt;方法&lt;/h4&gt;Graph-MLLM通过系统地评估三种范式（编码器、对齐器和预测器）在六个不同领域的六个数据集上，来构建一个综合基准。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，联合考虑节点的视觉和文本属性对图学习有益；将视觉属性转换为文本描述比直接使用视觉输入有更好的性能；在特定MMG上微调MLLM可以在大多数情况下实现最先进的成果，即使没有显式的图结构信息。&lt;h4&gt;结论&lt;/h4&gt;Graph-MLLM的提出有助于快速、公平地评估多模态图学习，并激发该领域的进一步创新研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have demonstrated remarkablecapabilities in representing and understanding diverse modalities. However,they typically focus on modality alignment in a pairwise manner whileoverlooking structural relationships across data points. Integratingmultimodality with structured graph information (i.e., multimodal graphs, MMGs)is essential for real-world applications such as social networks, healthcare,and recommendation systems. Existing MMG learning methods fall into threeparadigms based on how they leverage MLLMs: Encoder, Aligner, and Predictor.MLLM-as-Encoder focuses on enhancing graph neural networks (GNNs) viamultimodal feature fusion; MLLM-as-Aligner aligns multimodal attributes inlanguage or hidden space to enable LLM-based graph reasoning; MLLM-as-Predictortreats MLLMs as standalone reasoners with in-context learning or fine-tuning.Despite their advances, the MMG field lacks a unified benchmark to fairlyevaluate across these approaches, making it unclear what progress has beenmade. To bridge this gap, we present Graph-MLLM, a comprehensive benchmark formultimodal graph learning by systematically evaluating these three paradigmsacross six datasets with different domains. Through extensive experiments, weobserve that jointly considering the visual and textual attributes of the nodesbenefits graph learning, even when using pre-trained text-to-image alignmentmodels (e.g., CLIP) as encoders. We also find that converting visual attributesinto textual descriptions further improves performance compared to directlyusing visual inputs. Moreover, we observe that fine-tuning MLLMs on specificMMGs can achieve state-of-the-art results in most scenarios, even withoutexplicit graph structure information. We hope that our open-sourced librarywill facilitate rapid, equitable evaluation and inspire further innovativeresearch in this field.</description>
      <author>example@mail.com (Jiajin Liu, Dongzhe Fan, Jiacheng Shen, Chuanhao Ji, Daochen Zha, Qiaoyu Tan)</author>
      <guid isPermaLink="false">2506.10282v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty-Aware Deep Learning for Automated Skin Cancer Classification: A Comprehensive Evaluation</title>
      <link>http://arxiv.org/abs/2506.10302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究评估了基于深度学习的皮肤病变分类方法，通过迁移学习和不确定性量化技术，在HAM10000数据集上实现了皮肤癌诊断的准确性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;准确可靠的皮肤癌诊断对早期治疗和改善患者预后至关重要。深度学习模型在自动化皮肤癌分类方面显示出潜力，但其性能可能受限于数据稀缺和缺乏不确定性意识。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过迁移学习和不确定性量化技术，提高基于深度学习的皮肤病变分类模型的性能和可靠性。&lt;h4&gt;方法&lt;/h4&gt;研究分为两个阶段：第一阶段，对多种预训练特征提取器（如CLIP、ResNet50、DenseNet121、VGG16、EfficientNet-V2-Large）结合传统分类器（如SVM、XGBoost、逻辑回归）进行基准测试；第二阶段，采用蒙特卡洛dropout、集成和集成蒙特卡洛dropout方法进行不确定性量化。&lt;h4&gt;主要发现&lt;/h4&gt;基于CLIP的视觉变换器，特别是LAION CLIP ViT-H/14结合SVM，在分类性能上表现最佳。集成方法在准确性和不确定性处理之间提供了良好的平衡，而EMCD对不确定预测更为敏感。&lt;h4&gt;结论&lt;/h4&gt;将不确定性量化集成到基于深度学习的医疗诊断中，对于提高性能和现实世界临床应用中的可信度具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and reliable skin cancer diagnosis is critical for early treatmentand improved patient outcomes. Deep learning (DL) models have shown promise inautomating skin cancer classification, but their performance can be limited bydata scarcity and a lack of uncertainty awareness. In this study, we present acomprehensive evaluation of DL-based skin lesion classification using transferlearning and uncertainty quantification (UQ) on the HAM10000 dataset. In thefirst phase, we benchmarked several pre-trained feature extractors-includingContrastive Language-Image Pretraining (CLIP) variants, Residual Network-50(ResNet50), Densely Connected Convolutional Network (DenseNet121), VisualGeometry Group network (VGG16), and EfficientNet-V2-Large-combined with a rangeof traditional classifiers such as Support Vector Machine (SVM), eXtremeGradient Boosting (XGBoost), and logistic regression. Our results show thatCLIP-based vision transformers, particularly LAION CLIP ViT-H/14 with SVM,deliver the highest classification performance. In the second phase, weincorporated UQ using Monte Carlo Dropout (MCD), Ensemble, and Ensemble MonteCarlo Dropout (EMCD) to assess not only prediction accuracy but also thereliability of model outputs. We evaluated these models using uncertainty-awaremetrics such as uncertainty accuracy(UAcc), uncertainty sensitivity(USen),uncertainty specificity(USpe), and uncertainty precision(UPre). The resultsdemonstrate that ensemble methods offer a good trade-off between accuracy anduncertainty handling, while EMCD is more sensitive to uncertain predictions.This study highlights the importance of integrating UQ into DL-based medicaldiagnosis to enhance both performance and trustworthiness in real-worldclinical applications.</description>
      <author>example@mail.com (Hamzeh Asgharnezhad, Pegah Tabarisaadi, Abbas Khosravi, Roohallah Alizadehsani, U. Rajendra Acharya)</author>
      <guid isPermaLink="false">2506.10302v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Error Assessment of CAD Models for Aircraft Manufacturing-and-Measurement</title>
      <link>http://arxiv.org/abs/2506.10594v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HEA-MM的新型分层误差评估框架，用于评估飞机CAD模型在制造和测量平台中的质量。&lt;h4&gt;背景&lt;/h4&gt;航空设备最重要的特征是高质量，包括高性能、高稳定性和高可靠性。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法来评估飞机CAD模型的误差。&lt;h4&gt;方法&lt;/h4&gt;HEA-MM使用结构光扫描仪获取制造工件的综合3D测量，并将测量得到的点云与参考CAD模型进行配准，随后在三个层次上进行误差分析：全局、部件和特征。&lt;h4&gt;主要发现&lt;/h4&gt;在全局层次上评估扫描点云与参考CAD模型的总体偏差；在部件层次上，对点云下的补丁进行误差分析，并提出了一种基于优化的原始补丁细化方法；在特征层次上，对CAD模型中常见的圆形孔进行误差分析，并引入了两阶段算法以检测圆形孔。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，该方法在各种飞机CAD模型上有效。&lt;h4&gt;翻译&lt;/h4&gt;摘要：航空设备最重要的特征是高质量，包括高性能、高稳定性和高可靠性。在本文中，我们提出了一种新的分层误差评估框架，称为HEA-MM，用于制造和测量平台内的飞机CAD模型。HEA-MM采用结构光扫描仪获取制造工件的综合3D测量。测量的点云与参考CAD模型配准，然后在三个层次上进行误差分析：全局、部件和特征。在全局层次上，误差分析评估扫描点云与参考CAD模型的总体偏差。在部件层次上，对点云下的补丁进行误差分析。我们提出了一种基于优化的原始补丁细化方法。引入了两种基本操作，分割和合并，以细化粗糙的原语。在特征层次上，对CAD模型中常见的圆形孔进行误差分析。为此，引入了两阶段算法进行圆形孔的检测。首先，使用张量投票算法识别边缘点。然后，通过假设和聚类框架拟合多个圆，确保准确检测和分析圆形特征。在各种飞机CAD模型上的实验结果表明了所提出方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The most essential feature of aviation equipment is high quality, includinghigh performance, high stability and high reliability. In this paper, wepropose a novel hierarchical error assessment framework for aircraft CAD modelswithin a manufacturing-and-measurement platform, termed HEA-MM. HEA-MM employsstructured light scanners to obtain comprehensive 3D measurements ofmanufactured workpieces. The measured point cloud is registered with thereference CAD model, followed by an error analysis conducted at threehierarchical levels: global, part, and feature. At the global level, the erroranalysis evaluates the overall deviation of the scanned point cloud from thereference CAD model. At the part level, error analysis is performed on thesepatches underlying the point clouds. We propose a novel optimization-basedprimitive refinement method to obtain a set of meaningful patches of pointclouds. Two basic operations, splitting and merging, are introduced to refinethe coarse primitives. At the feature level, error analysis is performed oncircular holes, which are commonly found in CAD models. To facilitate it, atwo-stage algorithm is introduced for the detection of circular holes. First,edge points are identified using a tensor-voting algorithm. Then, multiplecircles are fitted through a hypothesize-and-clusterize framework, ensuringaccurate detection and analysis of the circular features. Experimental resultson various aircraft CAD models demonstrate the effectiveness of our proposedmethod.</description>
      <author>example@mail.com (Jin Huang, Honghua Chen, Mingqiang Wei)</author>
      <guid isPermaLink="false">2506.10594v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Structural-Spectral Graph Convolution with Evidential Edge Learning for Hyperspectral Image Clustering</title>
      <link>http://arxiv.org/abs/2506.09920v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的HSI聚类方法，通过改进超像素分割和图神经网络，提高了大规模HSI数据的聚类准确性。&lt;h4&gt;背景&lt;/h4&gt;HSI聚类是一项重要但具有挑战性的任务，目前大多数方法依赖于超像素分割和图神经网络，但现有方法无法充分利用HSI的谱信息，且超像素拓扑图的不准确性可能导致类语义混淆。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来提高HSI聚类准确性，同时解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;1. 提出一种结构-光谱图卷积算子（SSGCO）来提高超像素表示质量；2. 提出一种证据引导的自适应边缘学习模块（EGAEL）来预测和细化超像素拓扑图中的边缘权重；3. 将提出的方法集成到对比学习框架中，实现表示学习和聚类。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在四个HSI数据集上比最佳比较方法提高了2.61%，6.06%，4.96%和3.15%的聚类准确性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法有效地提高了HSI聚类准确性，并通过开源代码实现了其应用。&lt;h4&gt;翻译&lt;/h4&gt;Hyperspectral image (HSI) clustering assigns similar pixels to the same class without any annotations, which is an important yet challenging task. For large-scale HSIs, most methods rely on superpixel segmentation and perform superpixel-level clustering based on graph neural networks (GNNs). However, existing GNNs cannot fully exploit the spectral information of the input HSI, and the inaccurate superpixel topological graph may lead to the confusion of different class semantics during information aggregation. To address these challenges, we first propose a structural-spectral graph convolutional operator (SSGCO) tailored for graph-structured HSI superpixels to improve their representation quality through the co-extraction of spatial and spectral features. Second, we propose an evidence-guided adaptive edge learning (EGAEL) module that adaptively predicts and refines edge weights in the superpixel topological graph. We integrate the proposed method into a contrastive learning framework to achieve clustering, where representation learning and clustering are simultaneously conducted. Experiments demonstrate that the proposed method improves clustering accuracy by 2.61%, 6.06%, 4.96% and 3.15% over the best compared methods on four HSI datasets. Our code is available at https://github.com/jhqi/SSGCO-EGAEL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperspectral image (HSI) clustering assigns similar pixels to the same classwithout any annotations, which is an important yet challenging task. Forlarge-scale HSIs, most methods rely on superpixel segmentation and performsuperpixel-level clustering based on graph neural networks (GNNs). However,existing GNNs cannot fully exploit the spectral information of the input HSI,and the inaccurate superpixel topological graph may lead to the confusion ofdifferent class semantics during information aggregation. To address thesechallenges, we first propose a structural-spectral graph convolutional operator(SSGCO) tailored for graph-structured HSI superpixels to improve theirrepresentation quality through the co-extraction of spatial and spectralfeatures. Second, we propose an evidence-guided adaptive edge learning (EGAEL)module that adaptively predicts and refines edge weights in the superpixeltopological graph. We integrate the proposed method into a contrastive learningframework to achieve clustering, where representation learning and clusteringare simultaneously conducted. Experiments demonstrate that the proposed methodimproves clustering accuracy by 2.61%, 6.06%, 4.96% and 3.15% over the bestcompared methods on four HSI datasets. Our code is available athttps://github.com/jhqi/SSGCO-EGAEL.</description>
      <author>example@mail.com (Jianhan Qi, Yuheng Jia, Hui Liu, Junhui Hou)</author>
      <guid isPermaLink="false">2506.09920v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>J-DDL: Surface Damage Detection and Localization System for Fighter Aircraft</title>
      <link>http://arxiv.org/abs/2506.10505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种智能表面损伤检测和定位系统J-DDL，用于战斗机，通过激光扫描仪和摄像头获取整个机身的2D图像和3D点云数据，实现精确的损伤检测和定位。&lt;h4&gt;背景&lt;/h4&gt;战斗机需要频繁和彻底的检查以确保安全和延长使用寿命，而传统的手动方法在可扩展性、效率和一致性方面存在限制。&lt;h4&gt;目的&lt;/h4&gt;设计一个系统，以自动化战斗机表面损伤的检测和定位，提高检查效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;J-DDL系统结合2D图像和3D点云数据，使用基于YOLO架构的损伤检测网络，包含轻量级的Fasternet模块、优化的颈架构和新的损失函数Inner-CIOU，并在2D图像上检测损伤后映射到3D点云以实现3D定位。&lt;h4&gt;主要发现&lt;/h4&gt;J-DDL系统不仅简化了检查流程，还确保了对大型复杂战斗机外部的全面和详细的覆盖，并开发了首个针对飞机损伤的公开数据集。&lt;h4&gt;结论&lt;/h4&gt;J-DDL系统在提高自动化飞机检查技术方面具有显著潜力，通过实验评估验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the safety and extended operational life of fighter aircraftnecessitates frequent and exhaustive inspections. While surface defectdetection is feasible for human inspectors, manual methods face criticallimitations in scalability, efficiency, and consistency due to the vast surfacearea, structural complexity, and operational demands of aircraft maintenance.We propose a smart surface damage detection and localization system for fighteraircraft, termed J-DDL. J-DDL integrates 2D images and 3D point clouds of theentire aircraft surface, captured using a combined system of laser scanners andcameras, to achieve precise damage detection and localization. Central to oursystem is a novel damage detection network built on the YOLO architecture,specifically optimized for identifying surface defects in 2D aircraft images.Key innovations include lightweight Fasternet blocks for efficient featureextraction, an optimized neck architecture incorporating Efficient MultiscaleAttention (EMA) modules for superior feature aggregation, and the introductionof a novel loss function, Inner-CIOU, to enhance detection accuracy. Afterdetecting damage in 2D images, the system maps the identified anomalies ontocorresponding 3D point clouds, enabling accurate 3D localization of defectsacross the aircraft surface. Our J-DDL not only streamlines the inspectionprocess but also ensures more comprehensive and detailed coverage of large andcomplex aircraft exteriors. To facilitate further advancements in this domain,we have developed the first publicly available dataset specifically focused onaircraft damage. Experimental evaluations validate the effectiveness of ourframework, underscoring its potential to significantly advance automatedaircraft inspection technologies.</description>
      <author>example@mail.com (Jin Huang, Mingqiang Wei, Zikuan Li, Hangyu Qu, Wei Zhao, Xinyu Bai)</author>
      <guid isPermaLink="false">2506.10505v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Going beyond density functional theory accuracy: Leveraging experimental data to refine pre-trained machine learning interatomic potentials</title>
      <link>http://arxiv.org/abs/2506.10211v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用轨迹重加权技术来改进DFT预训练的机器学习原子间势（MLIPs），以匹配目标实验EXAFS光谱的方法。&lt;h4&gt;背景&lt;/h4&gt;MLIPs的准确性受限于训练数据，这些数据通常来自量子力学计算，如DFT。由于DFT本身基于多个近似，MLIPs可能会继承系统误差，导致与实验数据的偏差。&lt;h4&gt;目的&lt;/h4&gt;提高MLIPs与实验EXAFS光谱的一致性，并改善MLIPs对其他结构性质的预测。&lt;h4&gt;方法&lt;/h4&gt;使用轨迹重加权技术，结合迁移学习和少量训练周期，避免过拟合有限的实验数据。&lt;h4&gt;主要发现&lt;/h4&gt;该方法显著提高了两个MLIPs的性能，一个用于已建立的重核燃料：二氧化铀（UO$_2$），另一个用于核燃料候选者：一氧化铀（UN）。通过比较原始DFT基于的MLIP和EXAFS改进的MLIP在多个性质上的结果，如晶格参数、体积模量、比热容、点缺陷能、弹性常数、声子散射光谱和扩散系数等，验证了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;对于核燃料而言，准确的MLIPs非常有益，因为它能够实现可靠的原子级模拟，大大减少了传统上用于高效和耐用的燃料候选者认证的大量昂贵且危险的实验核积分测试的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning interatomic potentials (MLIPs) are inherently limited by theaccuracy of the training data, usually consisting of energies and forcesobtained from quantum mechanical calculations, such as density functionaltheory (DFT). Since DFT itself is based on several approximations, MLIPs mayinherit systematic errors that lead to discrepancies with experimental data. Inthis paper, we use a trajectory re-weighting technique to refine DFTpre-trained MLIPs to match the target experimental Extended X-ray AbsorptionFine Structure (EXAFS) spectra. EXAFS spectra are sensitive to the localstructural environment around an absorbing atom. Thus, refining an MLIP toimprove agreement with experimental EXAFS spectra also improves the MLIPprediction of other structural properties that are not directly involved in therefinement process. We combine this re-weighting technique with transferlearning and a minimal number of training epochs to avoid overfitting to thelimited experimental data. The refinement approach demonstrates significantimprovement for two MLIPs reported in previous work, one for an establishednuclear fuel: uranium dioxide (UO$_2$) and second one for a nuclear fuelcandidate: uranium mononitride (UN). We validate the effectiveness of ourapproach by comparing the results obtained from the original (unrefined)DFT-based MLIP and the EXAFS-refined MLIP across various properties, such aslattice parameters, bulk modulus, heat capacity, point defect energies, elasticconstants, phonon dispersion spectra, and diffusion coefficients. An accurateMLIP for nuclear fuels is extremely beneficial as it enables reliable atomisticsimulation, which greatly reduces the need for large number of expensive andinherently dangerous experimental nuclear integral tests, traditionallyrequired for the qualification of efficient and resilient fuel candidates.</description>
      <author>example@mail.com (Shriya Gumber, Lorena Alzate-Vargas, Benjamin T. Nebgen, Arjen van Veelen, Smit Kadvani, Tammie Gibson, Richard Messerly)</author>
      <guid isPermaLink="false">2506.10211v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Guided Graph Compression for Quantum Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.09862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Graph Neural Networks（GNNs）在处理图结构数据方面的有效性，但指出其在处理大型图时面临的内存需求和GPU上稀疏矩阵操作效率低下的问题。量子计算（QC）为解决这些问题提供了新的思路，并激发了新的算法方法。特别是，量子图神经网络（QGNNs）在近期文献中被探讨。然而，现有的量子硬件限制了可有效编码的数据维度。现有方法要么手动简化数据集，要么使用人工图数据集。本文提出了Guided Graph Compression（GGC）框架，该框架使用图自动编码器来减少节点数量和节点特征的维度。压缩过程旨在增强下游分类任务的表现，该任务可以使用量子或经典分类器进行。该框架在Jet Tagging任务上进行了评估，这是一个在粒子物理学中区分由夸克和胶子引发的粒子喷注的基本分类问题。GGC与将自动编码器作为独立预处理步骤以及与基线经典GNN分类器进行了比较。数值结果表明，GGC优于这两种替代方案，同时也有助于在现实数据集上测试新的QGNN方法。&lt;h4&gt;背景&lt;/h4&gt;GNNs在处理图结构数据时面临内存需求和稀疏矩阵操作效率低下的问题，量子计算为解决这些问题提供了新的思路。&lt;h4&gt;目的&lt;/h4&gt;提出GGC框架，通过图自动编码器减少节点数量和节点特征的维度，以提高下游分类任务的表现。&lt;h4&gt;方法&lt;/h4&gt;使用图自动编码器进行数据压缩，并将压缩过程指导以增强分类任务的表现。&lt;h4&gt;主要发现&lt;/h4&gt;GGC在Jet Tagging任务上优于其他替代方案，并有助于测试新的QGNN方法。&lt;h4&gt;结论&lt;/h4&gt;GGC框架在提高GNN处理大型图结构数据的能力方面是有效的，并且可以应用于量子或经典分类器。&lt;h4&gt;翻译&lt;/h4&gt;Graph神经网络（GNNs）在处理图结构数据方面非常有效，但由于高内存需求和在GPU上对稀疏矩阵操作的低效，在处理大型图时面临挑战。量子计算（QC）为解决这些问题提供了一个有希望的方法，并激发了一系列新的算法方法。特别是，近期文献中已经探讨了量子图神经网络（QGNNs）。然而，现有的量子硬件限制了可以有效地编码的数据维度。现有的方法要么手动简化数据集，要么使用人工图数据集。本研究引入了引导图压缩（GGC）框架，该框架使用图自动编码器来减少节点数量和节点特征的维度。压缩过程旨在增强下游分类任务的表现，可以使用量子或经典分类器。该框架在Jet Tagging任务上进行了评估，这是一个在粒子物理学中区分由夸克和胶子引发的粒子喷注的基本分类问题。GGC与将自动编码器作为独立预处理步骤以及与基线经典GNN分类器进行了比较。我们的数值结果表明，GGC优于这两种替代方案，同时也有助于在现实数据集上测试新的QGNN方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are effective for processing graph-structureddata but face challenges with large graphs due to high memory requirements andinefficient sparse matrix operations on GPUs. Quantum Computing (QC) offers apromising avenue to address these issues and inspires new algorithmicapproaches. In particular, Quantum Graph Neural Networks (QGNNs) have beenexplored in recent literature. However, current quantum hardware limits thedimension of the data that can be effectively encoded. Existing approacheseither simplify datasets manually or use artificial graph datasets. This workintroduces the Guided Graph Compression (GGC) framework, which uses a graphautoencoder to reduce both the number of nodes and the dimensionality of nodefeatures. The compression is guided to enhance the performance of a downstreamclassification task, which can be applied either with a quantum or a classicalclassifier. The framework is evaluated on the Jet Tagging task, aclassification problem of fundamental importance in high energy physics thatinvolves distinguishing particle jets initiated by quarks from those by gluons.The GGC is compared against using the autoencoder as a standalone preprocessingstep and against a baseline classical GNN classifier. Our numerical resultsdemonstrate that GGC outperforms both alternatives, while also facilitating thetesting of novel QGNN ansatzes on realistic datasets.</description>
      <author>example@mail.com (Mikel Casals, Vasilis Belis, Elias F. Combarro, Eduard Alarcón, Sofia Vallecorsa, Michele Grossi)</author>
      <guid isPermaLink="false">2506.09862v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Causal Inference via Prior-Data Fitted Networks</title>
      <link>http://arxiv.org/abs/2506.10914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CausalFM的综合框架，用于在各种因果推断场景中训练基于PFN的基础模型。&lt;h4&gt;背景&lt;/h4&gt;PFNs是一种Transformer，通过在合成数据上预训练并实现情境学习，使得贝叶斯推断成为可能。&lt;h4&gt;目的&lt;/h4&gt;开发CausalFM框架，使其能够进行贝叶斯因果推断，包括后门、前门和工具变量调整。&lt;h4&gt;方法&lt;/h4&gt;1. 基于结构因果模型（SCM）原则性地构建贝叶斯先验，并推导出此类先验有效性的必要标准。2. 提出一种新的先验分布族，使用因果启发式贝叶斯神经网络。3. 实例化CausalFM，并显式训练一个用于估计条件平均处理效应（CATEs）的基础模型，使用后门调整。&lt;h4&gt;主要发现&lt;/h4&gt;CausalFM在CATE估计方面表现出竞争力，并在多种合成和半合成基准测试中表现出色。&lt;h4&gt;结论&lt;/h4&gt;CausalFM为因果推断提供了一个新的范式，有潜力在医学、经济学和其他学科中改变实践者的因果推断方式。&lt;h4&gt;翻译&lt;/h4&gt;Prior-data fitted networks (PFNs) have recently been proposed as a promising way to train tabular foundation models. PFNs are transformers that are pre-trained on synthetic data generated from a prespecified prior distribution and that enable Bayesian inference through in-context learning. In this paper, we introduce CausalFM, a comprehensive framework for training PFN-based foundation models in various causal inference settings. First, we formalize the construction of Bayesian priors for causal inference based on structural causal models (SCMs) in a principled way and derive necessary criteria for the validity of such priors. Building on this, we propose a novel family of priordistributions using causality-inspired Bayesian neural networks that enable CausalFM to perform Bayesian causal inference in various settings, including back-door, front-door, and instrumental variable adjustment. Finally, we instantiate CausalFM and explicitly train a foundation model for estimating conditional average treatment effects (CATEs) using back-door adjustment. We show that CausalFM performs competitively for CATE estimation using various synthetic and semi-synthetic benchmarks. In sum, our framework can be used as a general recipe to train foundation models for various causal inferencesettings. In contrast to the current state-of-the-art in causal inference, CausalFM offers a novel paradigm with the potential to fundamentally change how practitioners perform causal inference in medicine, economics, and other disciplines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prior-data fitted networks (PFNs) have recently been proposed as a promisingway to train tabular foundation models. PFNs are transformers that arepre-trained on synthetic data generated from a prespecified prior distributionand that enable Bayesian inference through in-context learning. In this paper,we introduce CausalFM, a comprehensive framework for training PFN-basedfoundation models in various causal inference settings. First, we formalize theconstruction of Bayesian priors for causal inference based on structural causalmodels (SCMs) in a principled way and derive necessary criteria for thevalidity of such priors. Building on this, we propose a novel family of priordistributions using causality-inspired Bayesian neural networks that enableCausalFM to perform Bayesian causal inference in various settings, includingback-door, front-door, and instrumental variable adjustment. Finally, weinstantiate CausalFM and explicitly train a foundation model for estimatingconditional average treatment effects (CATEs) using back-door adjustment. Weshow that CausalFM performs competitively for CATE estimation using varioussynthetic and semi-synthetic benchmarks. In sum, our framework can be used as ageneral recipe to train foundation models for various causal inferencesettings. In contrast to the current state-of-the-art in causal inference,CausalFM offers a novel paradigm with the potential to fundamentally change howpractitioners perform causal inference in medicine, economics, and otherdisciplines.</description>
      <author>example@mail.com (Yuchen Ma, Dennis Frauen, Emil Javurek, Stefan Feuerriegel)</author>
      <guid isPermaLink="false">2506.10914v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>PointGS: Point Attention-Aware Sparse View Synthesis with Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.10335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于点特征感知的高斯分层渲染框架，从稀疏训练视图中实现实时、高质量的渲染。&lt;h4&gt;背景&lt;/h4&gt;3D高斯分层渲染（3DGS）技术在渲染速度和视觉质量上优于神经辐射场（NeRF），但现有方法需要大量校准视图来生成一致的场景表示。&lt;h4&gt;目的&lt;/h4&gt;解决3DGS在输入视图有限时，容易过拟合训练视图的问题，导致渲染质量下降。&lt;h4&gt;方法&lt;/h4&gt;采用最新的立体基础模型估计准确的相机姿态并重建密集点云；通过采样和聚合稀疏输入的多尺度二维外观特征来编码每个3D高斯的光谱属性；设计基于自注意力机制的点交互网络以增强点级外观表示；通过两个轻量级多层感知器（MLP）将丰富特征解码为高斯参数。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多样化的基准测试中显著优于基于NeRF的方法，在少样本设置下与最先进的3DGS方法相比也表现出竞争力。&lt;h4&gt;结论&lt;/h4&gt;该方法有效解决了3DGS在稀疏训练视图下的渲染质量问题，实现了实时、高质量的渲染。&lt;h4&gt;翻译&lt;/h4&gt;3D高斯分层渲染（3DGS）是一种创新的渲染技术，通过利用显式的3D场景表示，在渲染速度和视觉质量上超过了神经辐射场（NeRF）。现有的3DGS方法需要大量校准视图来生成一致且完整的场景表示。当输入视图有限时，3DGS往往会过拟合训练视图，导致渲染质量明显下降。为了解决这一限制，我们提出了一种点特征感知的高斯分层框架，可以从稀疏训练视图中实现实时、高质量渲染。具体来说，我们首先采用最新的立体基础模型来估计准确的相机姿态并重建密集点云以进行高斯初始化。然后，通过从稀疏输入中采样和聚合多尺度二维外观特征来编码每个3D高斯的光谱属性。为了增强点级外观表示，我们设计了一个基于自注意力机制的点交互网络，允许每个高斯点与其最近邻点交互。这些增强特征随后通过两个轻量级多层感知器（MLP）解码为高斯参数以进行最终渲染。在多样化的基准测试中的大量实验表明，我们的方法在性能上显著优于基于NeRF的方法，并且在少样本设置下与最先进的3DGS方法相比也取得了具有竞争力的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian splatting (3DGS) is an innovative rendering technique thatsurpasses the neural radiance field (NeRF) in both rendering speed and visualquality by leveraging an explicit 3D scene representation. Existing 3DGSapproaches require a large number of calibrated views to generate a consistentand complete scene representation. When input views are limited, 3DGS tends tooverfit the training views, leading to noticeable degradation in renderingquality. To address this limitation, we propose a Point-wise Feature-AwareGaussian Splatting framework that enables real-time, high-quality renderingfrom sparse training views. Specifically, we first employ the latest stereofoundation model to estimate accurate camera poses and reconstruct a densepoint cloud for Gaussian initialization. We then encode the colour attributesof each 3D Gaussian by sampling and aggregating multiscale 2D appearancefeatures from sparse inputs. To enhance point-wise appearance representation,we design a point interaction network based on a self-attention mechanism,allowing each Gaussian point to interact with its nearest neighbors. Theseenriched features are subsequently decoded into Gaussian parameters through twolightweight multi-layer perceptrons (MLPs) for final rendering. Extensiveexperiments on diverse benchmarks demonstrate that our method significantlyoutperforms NeRF-based approaches and achieves competitive performance underfew-shot settings compared to the state-of-the-art 3DGS methods.</description>
      <author>example@mail.com (Lintao Xiang, Hongpei Zheng, Yating Huang, Qijun Yang, Hujun Yin)</author>
      <guid isPermaLink="false">2506.10335v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Generalizing Supervised Contrastive learning: A Projection Perspective</title>
      <link>http://arxiv.org/abs/2506.09810v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了ProjNCE，这是一种InfoNCE的推广，通过引入投影函数和负样本调整项，将监督和无监督对比学习目标统一，并证明了ProjNCE是一个有效的互信息下界，提高了选择投影策略的灵活性，实验结果表明ProjNCE在多个数据集和设置中优于SupCon和标准交叉熵训练。&lt;h4&gt;背景&lt;/h4&gt;自监督对比学习（SSCL）在表示学习方面表现强大，但监督对比学习（SupCon）在此领域的关注较少，特别是SupCon与互信息（MI）之间的关系尚未探索。&lt;h4&gt;目的&lt;/h4&gt;填补SupCon与MI关系的研究空白，提出ProjNCE来统一监督和无监督对比学习目标，并提高其在选择投影策略方面的灵活性。&lt;h4&gt;方法&lt;/h4&gt;引入ProjNCE，这是一种InfoNCE的推广，包含投影函数和负样本调整项，并在SupCon中探索基于质心的类嵌入和多种投影方法。&lt;h4&gt;主要发现&lt;/h4&gt;ProjNCE是一个有效的MI下界，提供了选择投影策略的灵活性，实验表明ProjNCE在多个数据集和设置中优于SupCon和标准交叉熵训练。&lt;h4&gt;结论&lt;/h4&gt;ProjNCE改进了SupCon，从互信息解释和投影设计两个互补的角度出发，为SupCon作为基础对比学习目标时提供了广泛适用的改进。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised contrastive learning (SSCL) has emerged as a powerful paradigm for representation learning and has been studied from multiple perspectives, including mutual information and geometric viewpoints. However, supervised contrastive (SupCon) approaches have received comparatively little attention in this context: for instance, while InfoNCE used in SSCL is known to form a lower bound on mutual information (MI), the relationship between SupCon and MI remains unexplored. To address this gap, we introduce ProjNCE, a generalization of the InfoNCE loss that unifies supervised and self-supervised contrastive objectives by incorporating projection functions and an adjustment term for negative pairs. We prove that ProjNCE constitutes a valid MI bound and affords greater flexibility in selecting projection strategies for class embeddings. Building on this flexibility, we further explore the centroid-based class embeddings in SupCon by exploring a variety of projection methods. Extensive experiments on multiple datasets and settings demonstrate that ProjNCE consistently outperforms both SupCon and standard cross-entropy training. Our work thus refines SupCon along two complementary perspectives--mutual information interpretation and projection design--and offers broadly applicable improvements whenever SupCon serves as the foundational contrastive objective.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised contrastive learning (SSCL) has emerged as a powerfulparadigm for representation learning and has been studied from multipleperspectives, including mutual information and geometric viewpoints. However,supervised contrastive (SupCon) approaches have received comparatively littleattention in this context: for instance, while InfoNCE used in SSCL is known toform a lower bound on mutual information (MI), the relationship between SupConand MI remains unexplored. To address this gap, we introduce ProjNCE, ageneralization of the InfoNCE loss that unifies supervised and self-supervisedcontrastive objectives by incorporating projection functions and an adjustmentterm for negative pairs. We prove that ProjNCE constitutes a valid MI bound andaffords greater flexibility in selecting projection strategies for classembeddings. Building on this flexibility, we further explore the centroid-basedclass embeddings in SupCon by exploring a variety of projection methods.Extensive experiments on multiple datasets and settings demonstrate thatProjNCE consistently outperforms both SupCon and standard cross-entropytraining. Our work thus refines SupCon along two complementaryperspective--mutual information interpretation and projection design--andoffers broadly applicable improvements whenever SupCon serves as thefoundational contrastive objective.</description>
      <author>example@mail.com (Minoh Jeong, Alfred Hero)</author>
      <guid isPermaLink="false">2506.09810v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Learning-Enhanced MPC for Safe Crowd Navigation with Heterogeneous Constraints</title>
      <link>http://arxiv.org/abs/2506.09859v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于动态环境中具有异构约束的机器人导航的分层框架。&lt;h4&gt;背景&lt;/h4&gt;研究背景为动态环境中的机器人导航问题。&lt;h4&gt;目的&lt;/h4&gt;目的是开发一种能够有效处理动态环境中局部规划的机器人导航方法。&lt;h4&gt;方法&lt;/h4&gt;方法包括利用强化学习训练的图神经网络来估计机器人的成本到目标，以及采用考虑动力学约束的时空路径搜索模块生成参考轨迹。此外，引入了增量动作掩码机制和特权学习策略，以实现所提规划器的端到端训练。&lt;h4&gt;主要发现&lt;/h4&gt;模拟和真实世界实验表明，所提方法在复杂动态环境中的局部规划方面表现出色，达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;与现有的学习优化混合方法相比，该方法消除了对高保真模拟环境的依赖，在计算效率和训练可扩展性方面提供了显著优势。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we propose a novel hierarchical framework for robot navigation in dynamic environments with heterogeneous constraints. Our approach leverages a graph neural network trained via reinforcement learning (RL) to efficiently estimate the robot's cost-to-go, formulated as local goal recommendations. As a spatial-temporal path-searching module, which accounts for kinematic constraints, is then employed to generate a reference trajectory to facilitate solving the non-convex optimization problem used for explicit constraint enforcement. More importantly, we introduce an incremental action-masking mechanism and a privileged learning strategy, enabling end-to-end training of the proposed planner. Both simulation and real-world experiments demonstrate that the proposed method effectively addresses local planning in complex dynamic environments, achieving state-of-the-art (SOTA) performance. Compared with existing learning-optimization hybrid methods, our approach eliminates the dependency on high-fidelity simulation environments, offering significant advantages in computational efficiency and training scalability. The code will be released as open-source upon acceptance of the paper.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel hierarchical framework for robot navigationin dynamic environments with heterogeneous constraints. Our approach leveragesa graph neural network trained via reinforcement learning (RL) to efficientlyestimate the robot's cost-to-go, formulated as local goal recommendations. Aspatio-temporal path-searching module, which accounts for kinematicconstraints, is then employed to generate a reference trajectory to facilitatesolving the non-convex optimization problem used for explicit constraintenforcement. More importantly, we introduce an incremental action-maskingmechanism and a privileged learning strategy, enabling end-to-end training ofthe proposed planner. Both simulation and real-world experiments demonstratethat the proposed method effectively addresses local planning in complexdynamic environments, achieving state-of-the-art (SOTA) performance. Comparedwith existing learning-optimization hybrid methods, our approach eliminates thedependency on high-fidelity simulation environments, offering significantadvantages in computational efficiency and training scalability. The code willbe released as open-source upon acceptance of the paper.</description>
      <author>example@mail.com (Huajian Liu, Yixuan Feng, Wei Dong, Kunpeng Fan, Chao Wang, Yongzhuo Gao)</author>
      <guid isPermaLink="false">2506.09859v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Discovering Hierarchical Latent Capabilities of Language Models via Causal Representation Learning</title>
      <link>http://arxiv.org/abs/2506.10378v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种因果表示学习框架，用于评估语言模型的能力，并通过实际数据验证了该方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;对语言模型能力的忠实评估对于模型发展至关重要，但在这个领域进行严格的因果评估存在方法学挑战，包括复杂的混杂效应和与大量重新训练相关的计算成本。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一种新的因果表示学习框架。&lt;h4&gt;方法&lt;/h4&gt;该方法将观察到的基准性能建模为几个潜在能力因素的线性变换，并通过控制基础模型作为共同混杂因素来识别这些潜在因素之间的因果相关性。&lt;h4&gt;主要发现&lt;/h4&gt;将此方法应用于包含超过1500个模型，这些模型在Open LLM Leaderboard上的六个基准测试中被评估，确定了可靠地解释观察到的性能变化的简洁的三节点线性因果结构。&lt;h4&gt;结论&lt;/h4&gt;研究强调了在评估过程中仔细控制基础模型变化的重要性，这是准确揭示潜在模型能力之间潜在因果关系的关键步骤。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Faithful evaluation of language model capabilities is crucial for deriving actionable insights that can inform model development. However, rigorous causal evaluations in this domain face significant methodological challenges, including complex confounding effects and prohibitive computational costs associated with extensive retraining. To tackle these challenges, we propose a causal representation learning framework wherein observed benchmark performance is modeled as a linear transformation of a few latent capability factors. Crucially, these latent factors are identified as causally interrelated after appropriately controlling for the base model as a common confounder. Applying this approach to a comprehensive dataset encompassing over 1500 models evaluated across six benchmarks from the Open LLM Leaderboard, we identify a concise three-node linear causal structure that reliably explains the observed performance variations. Further interpretation of this causal structure provides substantial scientific insights beyond simple numerical rankings: specifically, we reveal a clear causal direction starting from general problem-solving capabilities, advancing through instruction-following proficiency, and culminating in mathematical reasoning ability. Our results underscore the essential role of carefully controlling base model variations during evaluation, a step critical to accurately uncovering the underlying causal relationships among latent model capabilities.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Faithful evaluation of language model capabilities is crucial for derivingactionable insights that can inform model development. However, rigorous causalevaluations in this domain face significant methodological challenges,including complex confounding effects and prohibitive computational costsassociated with extensive retraining. To tackle these challenges, we propose acausal representation learning framework wherein observed benchmark performanceis modeled as a linear transformation of a few latent capability factors.Crucially, these latent factors are identified as causally interrelated afterappropriately controlling for the base model as a common confounder. Applyingthis approach to a comprehensive dataset encompassing over 1500 modelsevaluated across six benchmarks from the Open LLM Leaderboard, we identify aconcise three-node linear causal structure that reliably explains the observedperformance variations. Further interpretation of this causal structureprovides substantial scientific insights beyond simple numerical rankings:specifically, we reveal a clear causal direction starting from generalproblem-solving capabilities, advancing through instruction-followingproficiency, and culminating in mathematical reasoning ability. Our resultsunderscore the essential role of carefully controlling base model variationsduring evaluation, a step critical to accurately uncovering the underlyingcausal relationships among latent model capabilities.</description>
      <author>example@mail.com (Jikai Jin, Vasilis Syrgkanis, Sham Kakade, Hanlin Zhang)</author>
      <guid isPermaLink="false">2506.10378v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Equations of state and stability condition of mixed p-spin glass model</title>
      <link>http://arxiv.org/abs/2506.10579v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了具有长程相互作用的玻璃模型，特别是混合p自旋玻璃模型，并旨在推导出其方程态，以及在一阶复制品对称破缺框架下，复制品对称解的稳定性条件和属于同一组的复制品在复制品对称破缺第一步中的稳定性。&lt;h4&gt;背景&lt;/h4&gt;Sherrington-Kirkpatrick (SK) 模型是理解自旋玻璃系统的基本模型，它基于完全连接晶格中每对自旋之间的配对相互作用，其长程相互作用简化了系统的研究，消除了波动。&lt;h4&gt;目的&lt;/h4&gt;研究混合p自旋玻璃模型的一般哈密顿量，推导其方程态，并在一阶复制品对称破缺框架下，确定复制品对称解的稳定性和属于同一组的复制品的稳定性。&lt;h4&gt;方法&lt;/h4&gt;通过引入p自旋模型，研究具有长程相互作用的自旋玻璃模型，并应用一阶复制品对称破缺理论。&lt;h4&gt;主要发现&lt;/h4&gt;研究了混合p自旋玻璃模型的方程态，并确定了复制品对称解的稳定性和属于同一组的复制品的稳定性。&lt;h4&gt;结论&lt;/h4&gt;混合p自旋玻璃模型的方程态和稳定性条件得到推导，为理解自旋玻璃系统提供了新的理论框架。&lt;h4&gt;翻译&lt;/h4&gt;The Sherrington-Kirkpatrick (SK) is a foundational model for understanding spin glass systems. It is based on the pairwise interaction between each two spins in a fully connected lattice with quenched disordered interactions. The nature of long-range interaction among spins in the (SK) model simplifies the study of this system by eliminating fluctuations. An advanced (SK) model, known as the p-spin model, introduces higher-order interactions that involve the interaction of P spins. This research focuses on the general Hamiltonian of the spin glass model with long-range interaction, referred to as the mixed p-spin glass model, which consists of adding all p-spin interaction terms. This research aims to derive the equation of states for this Hamiltonian, formulate the equation of state within the framework of the first replica symmetry breaking, and determine both the stability condition of the replica symmetry solution and the stability of the replicas belonging to the same group in the first step of replica symmetry breaking.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Sherrington-Kirkpatrick (SK) is a foundational model for understandingspin glass systems. It is based on the pairwise interaction between each twospins in a fully connected lattice with quenched disordered interactions. Thenature of long-range interaction among spins in the (SK) model simplifies thestudy of this system by eliminating fluctuations. An advanced (SK) model, knownas the p-spin model, introduces higher-order interactions that involve theinteraction of P spins. This research focuses on the general Hamiltonian of thespin glass model with long-range interaction, referred to as the mixed p-spinglass model, which consists of adding all p-spin interaction terms. Thisresearch aims to derive the equation of states for this Hamiltonian, formulatethe equation of state within the framework of the first replica symmetrybreaking, and determine both the stability condition of the replica symmetricsolution and the stability of the replicas belonging to the same group in thefirst step of replica symmetry breaking.</description>
      <author>example@mail.com (Ali Talebi)</author>
      <guid isPermaLink="false">2506.10579v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.09952v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为UniPre3D的统一预训练方法，用于处理不同规模的三维点云数据，并适用于各种架构的3D模型。&lt;h4&gt;背景&lt;/h4&gt;当前缺乏统一的3D模型和针对对象和场景级别点云的预训练方法，3D视觉中的点云数据规模多样性给统一表示学习技术带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够无缝应用于任何规模点云和任何架构3D模型的统一预训练方法。&lt;h4&gt;方法&lt;/h4&gt;方法包括预测高斯原语作为预训练任务，使用可微的高斯撒点技术渲染图像，以及通过集成预训练图像模型中的二维特征来指导模型关注几何结构。&lt;h4&gt;主要发现&lt;/h4&gt;通过在多种对象和场景级别任务上进行的广泛实验，验证了所提出方法在多样化点云模型作为骨干网络时的普适有效性。&lt;h4&gt;结论&lt;/h4&gt;UniPre3D方法在处理三维点云数据方面展现出显著的性能，并且具有广泛的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;The scale diversity of point cloud data presents significant challenges in developing unified representation learning techniques for 3D vision. Currently, there are few unified 3D models, and no existing pre-training method is equally effective for both object- and scene-level point clouds. In this paper, we introduce UniPre3D, the first unified pre-training method that can be seamlessly applied to point clouds of any scale and 3D models of any architecture. Our approach predicts Gaussian primitives as the pre-training task and employs differentiable Gaussian splatting to render images, enabling precise pixel-level supervision and end-to-end optimization. To further regulate the complexity of the pre-training task and direct the model's focus toward geometric structures, we integrate 2D features from pre-trained image models to incorporate well-established texture knowledge. We validate the universal effectiveness of our proposed method through extensive experiments across a variety of object- and scene-level tasks, using diverse point cloud models as backbones. Code is available at https://github.com/wangzy22/UniPre3D.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The scale diversity of point cloud data presents significant challenges indeveloping unified representation learning techniques for 3D vision. Currently,there are few unified 3D models, and no existing pre-training method is equallyeffective for both object- and scene-level point clouds. In this paper, weintroduce UniPre3D, the first unified pre-training method that can beseamlessly applied to point clouds of any scale and 3D models of anyarchitecture. Our approach predicts Gaussian primitives as the pre-trainingtask and employs differentiable Gaussian splatting to render images, enablingprecise pixel-level supervision and end-to-end optimization. To furtherregulate the complexity of the pre-training task and direct the model's focustoward geometric structures, we integrate 2D features from pre-trained imagemodels to incorporate well-established texture knowledge. We validate theuniversal effectiveness of our proposed method through extensive experimentsacross a variety of object- and scene-level tasks, using diverse point cloudmodels as backbones. Code is available at https://github.com/wangzy22/UniPre3D.</description>
      <author>example@mail.com (Ziyi Wang, Yanran Zhang, Jie Zhou, Jiwen Lu)</author>
      <guid isPermaLink="false">2506.09952v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Devil's Hand: Data Poisoning Attacks to Locally Private Graph Learning Protocols</title>
      <link>http://arxiv.org/abs/2506.09803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络在图表示学习中的隐私问题，提出了针对局部隐私图学习协议的数据中毒攻击，并探讨了防御策略。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在图表示学习中取得显著成功，但在处理包含敏感信息的真实世界图时，存在隐私泄露的风险。&lt;h4&gt;目的&lt;/h4&gt;为了解决隐私泄露问题，提出了利用局部差分隐私（LDP）和图神经网络消息传递机制进行局部隐私图学习。&lt;h4&gt;方法&lt;/h4&gt;研究引入了针对局部隐私图学习协议的数据中毒攻击，攻击者通过注入假用户、建立与真实用户的连接和发送精心设计的数据来破坏隐私图学习的效用。&lt;h4&gt;主要发现&lt;/h4&gt;攻击既在理论上也在实证上证明了其有效性，同时指出现有的防御策略效果有限。&lt;h4&gt;结论&lt;/h4&gt;强调了需要开发更强大的防御机制来确保隐私保护图学习框架的鲁棒性和安全性。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates privacy issues in graph neural networks for graph representation learning, proposes a data poisoning attack targeting locally private graph learning protocols, and explores defensive strategies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have achieved significant success in graphrepresentation learning and have been applied to various domains. However, manyreal-world graphs contain sensitive personal information, such as user profilesin social networks, raising serious privacy concerns when graph learning isperformed using GNNs. To address this issue, locally private graph learningprotocols have gained considerable attention. These protocols leverage theprivacy advantages of local differential privacy (LDP) and the effectiveness ofGNN's message-passing in calibrating noisy data, offering strict privacyguarantees for users' local data while maintaining high utility (e.g., nodeclassification accuracy) for graph learning. Despite these advantages, suchprotocols may be vulnerable to data poisoning attacks, a threat that has notbeen considered in previous research. Identifying and addressing these threatsis crucial for ensuring the robustness and security of privacy-preserving graphlearning frameworks. This work introduces the first data poisoning attacktargeting locally private graph learning protocols. The attacker injects fakeusers into the protocol, manipulates these fake users to establish links withgenuine users, and sends carefully crafted data to the server, ultimatelycompromising the utility of private graph learning. The effectiveness of theattack is demonstrated both theoretically and empirically. In addition, severaldefense strategies have also been explored, but their limited effectivenesshighlights the need for more robust defenses.</description>
      <author>example@mail.com (Longzhu He, Chaozhuo Li, Peng Tang, Litian Zhang, Sen Su)</author>
      <guid isPermaLink="false">2506.09803v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>DynaSubVAE: Adaptive Subgrouping for Scalable and Robust OOD Detection</title>
      <link>http://arxiv.org/abs/2506.10200v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为DynaSubVAE的动态子分组变分自动编码器框架，用于处理现实世界中数据中的异质子群体问题，提高模型的预测准确性。&lt;h4&gt;背景&lt;/h4&gt;现实世界的数据中常存在与全局模式不同的子群体，大多数模型往往忽略了这些被低估的群体，导致预测不准确甚至有害。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来适应新出现的模式，而不是将检测到的样本视为域外样本。&lt;h4&gt;方法&lt;/h4&gt;DynaSubVAE通过动态更新其潜在结构来捕捉新趋势，利用基于嵌入相似性的非参数聚类机制发现和建模潜在子群体。&lt;h4&gt;主要发现&lt;/h4&gt;DynaSubVAE在近域外和远域外检测中表现出色，尤其在训练过程中缺失整个类别的类域外场景中表现优异。&lt;h4&gt;结论&lt;/h4&gt;动态子分组机制在域外准确性和后悔精度方面优于独立的聚类方法，如高斯混合模型和KMeans++。&lt;h4&gt;翻译&lt;/h4&gt;Real-world observational data often contain existing or emerging heterogeneous subpopulations that deviate from global patterns. The majority of models tend to overlook these underrepresented groups, leading to inaccurate or even harmful predictions. Existing solutions often rely on detecting these samples as Out-of-domain (OOD) rather than adapting the model to new emerging patterns. We introduce DynaSubVAE, a Dynamic Subgrouping Variational Autoencoder framework that jointly performs representation learning and adaptive OOD detection. Unlike conventional approaches, DynaSubVAE evolves with the data by dynamically updating its latent structure to capture new trends. It leverages a novel non-parametric clustering mechanism, inspired by Gaussian Mixture Models, to discover and model latent subgroups based on embedding similarity. Extensive experiments show that DynaSubVAE achieves competitive performance in both near-OOD and far-OOD detection, and excels in class-OOD scenarios where an entire class is missing during training. We further illustrate that our dynamic subgrouping mechanism outperforms standalone clustering methods such as GMM and KMeans++ in terms of both OOD accuracy and regret precision.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world observational data often contain existing or emergingheterogeneous subpopulations that deviate from global patterns. The majority ofmodels tend to overlook these underrepresented groups, leading to inaccurate oreven harmful predictions. Existing solutions often rely on detecting thesesamples as Out-of-domain (OOD) rather than adapting the model to new emergingpatterns. We introduce DynaSubVAE, a Dynamic Subgrouping VariationalAutoencoder framework that jointly performs representation learning andadaptive OOD detection. Unlike conventional approaches, DynaSubVAE evolves withthe data by dynamically updating its latent structure to capture new trends. Itleverages a novel non-parametric clustering mechanism, inspired by GaussianMixture Models, to discover and model latent subgroups based on embeddingsimilarity. Extensive experiments show that DynaSubVAE achieves competitiveperformance in both near-OOD and far-OOD detection, and excels in class-OODscenarios where an entire class is missing during training. We furtherillustrate that our dynamic subgrouping mechanism outperforms standaloneclustering methods such as GMM and KMeans++ in terms of both OOD accuracy andregret precision.</description>
      <author>example@mail.com (Tina Behrouzi, Sana Tonekaboni, Rahul G. Krishnan, Anna Goldenberg)</author>
      <guid isPermaLink="false">2506.10200v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>VAULT: A Mobile Mapping System for ROS 2-based Autonomous Robots</title>
      <link>http://arxiv.org/abs/2506.09583v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 5 figures, Submitted to WAF 2023: Workshop de Agentes  Fisicos&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了VAULT原型，这是一种基于ROS 2的移动地图系统，用于实现自主机器人在户外和室内的鲁棒定位。&lt;h4&gt;背景&lt;/h4&gt;定位在自主机器人的导航能力中起着关键作用。尽管室内环境可以使用轮式里程计和基于2D激光雷达的地图，但户外环境如农业和林业面临着独特的挑战，需要实时定位和连续地图。&lt;h4&gt;目的&lt;/h4&gt;提出VAULT原型，以解决户外和室内定位的需求。&lt;h4&gt;方法&lt;/h4&gt;VAULT原型结合了多种传感器，包括全球导航卫星系统（GNSS）数据、视觉惯性里程计（VIO）、惯性测量单元（IMU）数据和扩展卡尔曼滤波器（EKF），以生成可靠的3D里程计。此外，还采用了视觉同步定位与映射（VSLAM）技术，以创建全面的3D点云地图。&lt;h4&gt;主要发现&lt;/h4&gt;VAULT原型通过结合这些传感器技术和高级算法，为自主移动机器人的户外定位提供了一种全面解决方案，使机器人能够自信且精确地导航和绘制周围环境。&lt;h4&gt;结论&lt;/h4&gt;VAULT原型为自主机器人在户外环境中的定位提供了有效的方法，提高了导航和地图绘制的准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：定位在自主机器人的导航能力中起着至关重要的作用。虽然室内环境可以依赖轮式里程计和基于2D激光雷达的地图，但户外环境，如农业和林业，面临着独特的挑战，需要实时定位和连续地图。为了满足这一需求，本文提出了一种基于ROS 2的移动地图系统（MMS）的原型——VAULT，它结合了多种传感器以实现户外和室内的鲁棒定位。所提出的解决方案利用全球导航卫星系统（GNSS）数据、视觉惯性里程计（VIO）、惯性测量单元（IMU）数据和扩展卡尔曼滤波器（EKF）来生成可靠的3D里程计。为了进一步提高定位精度，采用了视觉同步定位与映射（VSLAM），从而创建了一个全面的3D点云地图。通过利用这些传感器技术和先进算法，原型为自主移动机器人的户外定位提供了一种全面解决方案，使其能够自信且精确地导航和绘制周围环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Localization plays a crucial role in the navigation capabilities ofautonomous robots, and while indoor environments can rely on wheel odometry and2D LiDAR-based mapping, outdoor settings such as agriculture and forestry,present unique challenges that necessitate real-time localization andconsistent mapping. Addressing this need, this paper introduces the VAULTprototype, a ROS 2-based mobile mapping system (MMS) that combines varioussensors to enable robust outdoor and indoor localization. The proposed solutionharnesses the power of Global Navigation Satellite System (GNSS) data,visual-inertial odometry (VIO), inertial measurement unit (IMU) data, and theExtended Kalman Filter (EKF) to generate reliable 3D odometry. To furtherenhance the localization accuracy, Visual SLAM (VSLAM) is employed, resultingin the creation of a comprehensive 3D point cloud map. By leveraging thesesensor technologies and advanced algorithms, the prototype offers acomprehensive solution for outdoor localization in autonomous mobile robots,enabling them to navigate and map their surroundings with confidence andprecision.</description>
      <author>example@mail.com (Miguel Á. González-Santamarta, Francisco J. Rodríguez-Lera, Vicente Matellán-Olivera)</author>
      <guid isPermaLink="false">2506.09583v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Toward Scalable Quantum Compilation for Modular Architecture: Qubit Mapping and Reuse via Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.09323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了QARMA，一种用于模块化量子架构的基于注意力的深度强化学习Qubit映射方法，及其扩展QARMA-R，它包含了动态Qubit复用能力。该方法结合了注意力机制和图神经网络（GNN）来学习最优的Qubit分配、路由和复用策略，以最小化核心间通信。&lt;h4&gt;背景&lt;/h4&gt;模块化量子架构通过连接多个量子处理单元（QPUs）来实现量子计算系统的扩展，但芯片间的核心操作和量子态传输引入了成本高昂的问题，这些因素导致了噪声和量子退相干。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过改进量子电路编译技术，使资源受限的模块化量子系统能够执行更广泛的量子算法。&lt;h4&gt;方法&lt;/h4&gt;QARMA和QARMA-R结合了注意力机制和图神经网络来学习最优的Qubit分配、路由和复用策略。QARMA使用基于transformer的编码器捕捉全局电路结构和局部Qubit交互，QARMA-R则包含动态Qubit复用编译机制，利用中点测量和重置操作来减少操作和Qubit需求。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与最先进的方法相比，QARMA-R将核心间通信减少了高达100%（平均85%），而QARMA在无复用的大电路中保持了15-40%的改进。与传统模块化Qubit映射相比，该方法将核心间操作减少了96.4-100%。&lt;h4&gt;结论&lt;/h4&gt;提出的QARMA和QARMA-R方法推进了量子电路编译技术，并使资源受限的模块化量子系统能够执行更广泛的量子算法，为可扩展量子计算架构的研究做出了贡献。&lt;h4&gt;翻译&lt;/h4&gt;Modular quantum architectures have emerged as a promising approach for scaling quantum computing systems by connecting multiple Quantum Processing Units (QPUs). However, this approach introduces significant challenges due to costly inter-core operations between chips and quantum state transfers, which contribute to noise and quantum decoherence. This paper presents QARMA, a novel Qubit mapping using Attention-based deep Reinforcement learning (DRL) for Modular quantum Architectures, along with its extension QARMA-R that incorporates dynamic qubit reuse capabilities. Our approach combines an attention-based mechanism with Graph Neural Networks (GNN) to learn optimal qubit allocation, routing, and reuse strategies that minimize inter-core communications. We introduce two key innovations: (1) a transformer-based encoder that captures both the global circuit structure and local qubit interactions and (2) a dynamic qubit reuse compilation mechanism that leverages mid-circuit measurement and reset operations to reduce inter-operation and qubit requirements. Our experimental results show significant improvements over state-of-the-art approaches. Compared to highly-optimized Qiskit with modular architecture configuration, QARMA-R reduces inter-core communications by up to 100% (on average 85%), while QARMA maintains 15-40% improvement for larger circuits without reuse. Against traditional modular qubit mapping, our approach achieves 96.4-100% reduction in inter-core operation. The proposed methods advance quantum circuit compilation techniques and enable the execution of more extensive quantum algorithms on resource-constrained modular quantum systems, contributing to the growing body of research on scalable quantum computing architectures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modular quantum architectures have emerged as a promising approach forscaling quantum computing systems by connecting multiple Quantum ProcessingUnits (QPUs). However, this approach introduces significant challenges due tocostly inter-core operations between chips and quantum state transfers, whichcontribute to noise and quantum decoherence. This paper presents QARMA, a novelQubit mapping using Attention-based deep Reinforcement learning (DRL) forModular quantum Architectures, along with its extension QARMA-R thatincorporates dynamic qubit reuse capabilities. Our approach combines anattention-based mechanism with Graph Neural Networks (GNN) to learn optimalqubit allocation, routing, and reuse strategies that minimize inter-corecommunications. We introduce two key innovations: (1) a transformer-basedencoder that captures both the global circuit structure and local qubitinteractions and (2) a dynamic qubit reuse compilation mechanism that leveragesmid-circuit measurement and reset operations to reduce inter-operation andqubit requirements. Our experimental results show significant improvements overstate-of-the-art approaches. Compared to highly-optimized Qiskit with modulararchitecture configuration, QARMA-R reduces inter-core communications by up to100% (on average 85%), while QARMA maintains 15-40% improvement for largercircuits without reuse. Against traditional modular qubit mapping, our approachachieves 96.4-100% reduction in inter-core operation. The proposed methodsadvance quantum circuit compilation techniques and enable the execution of moreextensive quantum algorithms on resource-constrained modular quantum systems,contributing to the growing body of research on scalable quantum computingarchitectures.</description>
      <author>example@mail.com (Sokea Sang, Leanghok Hour, Youngsun Han)</author>
      <guid isPermaLink="false">2506.09323v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Attention on flow control: transformer-based reinforcement learning for lift regulation in highly disturbed flows</title>
      <link>http://arxiv.org/abs/2506.10153v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于transformer的强化学习框架，用于学习调节阵风序列中气动升力的有效控制策略，并展示了该策略在不同配置下的可推广性。&lt;h4&gt;背景&lt;/h4&gt;线性流控制策略在强扰动序列中可能不再有效，因为存在非线性交互。&lt;h4&gt;目的&lt;/h4&gt;开发一种更有效的控制策略，以调节阵风序列中的气动升力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于transformer的强化学习框架，用于学习控制策略；使用专家策略（线性控制）进行预训练；采用任务级迁移学习，将孤立阵风上的策略扩展到多个阵风；研究四分之一弦俯仰控制与中弦俯仰控制的效果。&lt;h4&gt;主要发现&lt;/h4&gt;训练可以通过预训练和任务级迁移学习加速；学习策略优于最佳比例控制；在小阵风序列环境下学习的策略可以有效地推广到任意长序列的环境；四分之一弦俯仰控制比中弦俯仰控制需要更少的控制努力；这种优势归因于四分之一弦俯仰控制可获得的占优附加质量贡献。&lt;h4&gt;结论&lt;/h4&gt;提出的基于transformer的RL框架和加速技术为解决更复杂的流控制问题提供了有希望的方法。&lt;h4&gt;翻译&lt;/h4&gt;A linear flow control strategy designed for weak disturbances may not remain effective in sequences of strong disturbances due to nonlinear interactions, but it is sensible to leverage it for developing a better strategy. In the present study, we propose a transformer-based reinforcement learning (RL) framework to learn an effective control strategy for regulating aerodynamic lift in gust sequences via pitch control. The transformer addresses the challenge of partial observability from limited surface pressure sensors. We demonstrate that the training can be accelerated with two techniques --pretraining with an expert policy (here, linear control) and task-level transfer learning (here, extending a policy trained on isolated gusts to multiple gusts). We show that the learned strategy outperforms the best proportional control, with the performance gap widening as the number of gusts increases. The control strategy learned in an environment with a small number of successive gusts is shown to effectively generalize to an environment with an arbitrarily long sequence of gusts. We investigate the pivot configuration and show that quarter-chord pitching control can achieve superior lift regulation with substantially less control effort compared to mid-chord pitching control. Through a decomposition of the lift, we attribute this advantage to the dominant added-mass contribution accessible via quarter-chord pitching. The success on multiple configurations shows the generalizability of the proposed transformer-based RL framework, which offers a promising approach to solve more computationally demanding flow control problems when combined with the proposed acceleration techniques.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A linear flow control strategy designed for weak disturbances may not remaineffective in sequences of strong disturbances due to nonlinear interactions,but it is sensible to leverage it for developing a better strategy. In thepresent study, we propose a transformer-based reinforcement learning (RL)framework to learn an effective control strategy for regulating aerodynamiclift in gust sequences via pitch control. The transformer addresses thechallenge of partial observability from limited surface pressure sensors. Wedemonstrate that the training can be accelerated with two techniques --pretraining with an expert policy (here, linear control) and task-leveltransfer learning (here, extending a policy trained on isolated gusts tomultiple gusts). We show that the learned strategy outperforms the bestproportional control, with the performance gap widening as the number of gustsincreases. The control strategy learned in an environment with a small numberof successive gusts is shown to effectively generalize to an environment withan arbitrarily long sequence of gusts. We investigate the pivot configurationand show that quarter-chord pitching control can achieve superior liftregulation with substantially less control effort compared to mid-chordpitching control. Through a decomposition of the lift, we attribute thisadvantage to the dominant added-mass contribution accessible via quarter-chordpitching. The success on multiple configurations shows the generalizability ofthe proposed transformer-based RL framework, which offers a promising approachto solve more computationally demanding flow control problems when combinedwith the proposed acceleration techniques.</description>
      <author>example@mail.com (Zhecheng Liu, Jeff D. Eldredge)</author>
      <guid isPermaLink="false">2506.10153v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Deep Clustering of MNIST with Triplet-Enhanced Convolutional Autoencoders</title>
      <link>http://arxiv.org/abs/2506.10094v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 6 figures, experimental study on deep clustering with  autoencoders&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究通过两阶段深度自动编码器架构实现了一个高级无监督聚类系统，用于处理MNIST手写数字数据，并在多个测试中展现出优异的聚类性能。&lt;h4&gt;背景&lt;/h4&gt;深度神经网络自动编码器在第一阶段通过最小化重建误差来开发图像的极小化但可解释的表示。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过无监督学习方式，实现手写数字的高效聚类，并提高数据重建的准确性和聚类分离的纯净度。&lt;h4&gt;方法&lt;/h4&gt;使用两阶段深度自动编码器架构，第一阶段进行训练，第二阶段通过联合距离目标函数统一重建误差与KMeans聚类损失，实现学习的潜在嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;模型包含批归一化、dropout和权重衰减等三个元素，以实现通用的和稳定的聚类结果。通过Silhouette Score、Davies-Bouldin Index、NMI和ARI等指标验证了模型的聚类性能。&lt;h4&gt;结论&lt;/h4&gt;该研究的方法在数据重建准确性和聚类分离纯净度之间达到了最优组合，为大规模图像聚类应用中的无监督表示学习提供了一个可靠的基准。&lt;h4&gt;翻译&lt;/h4&gt;本研究通过两阶段深度自动编码器架构实现了一个高级无监督聚类系统，用于处理MNIST手写数字数据。通过两阶段架构，第一阶段通过训练深度神经网络自动编码器来开发图像的极小化但可解释的表示。在第二阶段，通过联合距离目标函数，将重建误差与KMeans聚类损失相结合，以实现学习的潜在嵌入。模型包含批归一化、dropout和权重衰减等三个元素，旨在实现通用的和稳定的聚类结果。在广泛的测试中，该框架在Silhouette Score、Davies-Bouldin Index、NMI和ARI等指标上展现了优异的聚类性能。研究还使用了t-SNE可视化来展示学习到的嵌入，显示出数字的明确聚类。该方法在数据重建准确性和聚类分离纯净度之间达到了最优组合，同时具有可理解的结果和可扩展的实现。该研究为不同大规模图像聚类应用中的无监督表示学习提供了一个可靠的基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research implements an advanced unsupervised clustering system for MNISThandwritten digits through two-phase deep autoencoder architecture. A deepneural autoencoder requires a training process during phase one to developminimal yet interpretive representations of images by minimizing reconstructionerrors. During the second phase we unify the reconstruction error with a KMeansclustering loss for learned latent embeddings through a joint distance-basedobjective. Our model contains three elements which include batch normalizationcombined with dropout and weight decay for achieving generalized and stableresults. The framework achieves superior clustering performance duringextensive tests which used intrinsic measurements including Silhouette Scoreand Davies-Bouldin Index coupled with extrinsic metrics NMI and ARI whenprocessing image features. The research uses t-SNE visualization to presentlearned embeddings that show distinct clusters for digits. Our approach reachesan optimal combination between data reconstruction accuracy and clusterseparation purity when adding the benefit of understandable results andscalable implementations. The approach creates a dependable base that helpsdeploy unsupervised representation learning in different large-scale imageclustering applications.</description>
      <author>example@mail.com (Md. Faizul Islam Ansari)</author>
      <guid isPermaLink="false">2506.10094v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Pisces: An Auto-regressive Foundation Model for Image Understanding and Generation</title>
      <link>http://arxiv.org/abs/2506.10395v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Unified image understanding and generation model&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Pisces的自动回归多模态基础模型，该模型通过新颖的解耦视觉编码架构和针对多模态生成的定制化训练技术来解决统一模型开发中的挑战。&lt;h4&gt;背景&lt;/h4&gt;尽管大型语言模型在图像理解和生成方面取得了进展，但统一模型在特定任务上通常不如专用模型表现好。&lt;h4&gt;目的&lt;/h4&gt;开发能够同时高效处理图像理解和生成的统一模型。&lt;h4&gt;方法&lt;/h4&gt;Pisces模型采用了一种新的解耦视觉编码架构和针对多模态生成的优化训练技术，并结合精心 curated 的数据、预训练和微调。&lt;h4&gt;主要发现&lt;/h4&gt;Pisces在超过20个公共图像理解基准测试中表现出色，同时在GenEval图像生成基准上也展示了强大的生成能力。&lt;h4&gt;结论&lt;/h4&gt;Pisces的研究揭示了图像理解和生成之间的协同关系，并证明了使用单独的视觉编码器对统一多模态模型领域的益处。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为Pisces的自动回归多模态基础模型，通过创新的解耦视觉编码架构和针对多模态生成的定制化训练技术解决了统一模型开发中的挑战。尽管大型语言模型在图像理解和生成方面取得了进展，但统一模型在特定任务上通常不如专用模型表现好。本研究旨在开发能够同时高效处理图像理解和生成的统一模型。Pisces模型采用了一种新的解耦视觉编码架构和针对多模态生成的优化训练技术，并结合精心 curated 的数据、预训练和微调。在超过20个公共图像理解基准测试中，Pisces表现出色，同时在GenEval图像生成基准上也展示了强大的生成能力。研究揭示了图像理解和生成之间的协同关系，并证明了使用单独的视觉编码器对统一多模态模型领域的益处。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in large language models (LLMs) have enabled multimodalfoundation models to tackle both image understanding and generation within aunified framework. Despite these gains, unified models often underperformcompared to specialized models in either task. A key challenge in developingunified models lies in the inherent differences between the visual featuresneeded for image understanding versus generation, as well as the distincttraining processes required for each modality. In this work, we introducePisces, an auto-regressive multimodal foundation model that addresses thischallenge through a novel decoupled visual encoding architecture and tailoredtraining techniques optimized for multimodal generation. Combined withmeticulous data curation, pretraining, and finetuning, Pisces achievescompetitive performance in both image understanding and image generation. Weevaluate Pisces on over 20 public benchmarks for image understanding, where itdemonstrates strong performance across a wide range of tasks. Additionally, onGenEval, a widely adopted benchmark for image generation, Pisces exhibitsrobust generative capabilities. Our extensive analysis reveals the synergisticrelationship between image understanding and generation, and the benefits ofusing separate visual encoders, advancing the field of unified multimodalmodels.</description>
      <author>example@mail.com (Zhiyang Xu, Jiuhai Chen, Zhaojiang Lin, Xichen Pan, Lifu Huang, Tianyi Zhou, Madian Khabsa, Qifan Wang, Di Jin, Michihiro Yasunaga, Lili Yu, Xi Victoria Lin, Shaoliang Nie)</author>
      <guid isPermaLink="false">2506.10395v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Canonical Latent Representations in Conditional Diffusion Models</title>
      <link>http://arxiv.org/abs/2506.09955v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  45 pages,41 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;条件扩散模型（CDMs）在生成任务中表现出色，但其建模能力导致类别特征与无关背景信息交织，给提取鲁棒和可解释的表示带来挑战。&lt;h4&gt;背景&lt;/h4&gt;CDMs在分析合成下游判别学习中的应用，但存在类别特征与无关背景信息交织的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提取鲁棒和可解释的表示，并开发一种基于扩散的特征蒸馏范式。&lt;h4&gt;方法&lt;/h4&gt;提出了一种称为CLAReps的潜在代码，用于保留必要的类别信息并丢弃非判别性信号。同时，开发了CaDistill范式，通过CLAReps传递核心类别知识。&lt;h4&gt;主要发现&lt;/h4&gt;CLAReps能够产生每个类别的代表性样本，CaDistill范式在训练后使学生模型具有强大的对抗鲁棒性和泛化能力，专注于类别信号而非虚假背景线索。&lt;h4&gt;结论&lt;/h4&gt;CDMs不仅可以作为图像生成器，还可以作为紧凑、可解释的教师，驱动鲁棒表示学习。&lt;h4&gt;翻译&lt;/h4&gt;Conditional diffusion models (CDMs) have shown impressive performance across a range of generative tasks. Their ability to model the full data distribution has opened new avenues for analysis-by-synthesis in downstream discriminative learning. However, this same modeling capacity causes CDMs to entangle the class-defining features with irrelevant context, posing challenges to extracting robust and interpretable representations. To this end, we identify Canonical LAtent Representations (CLAReps), latent codes whose internal CDM features preserve essential categorical information while discarding non-discriminative signals. When decoded, CLAReps produce representative samples for each class, offering an interpretable and compact summary of the core class semantics with minimal irrelevant details. Exploiting CLAReps, we develop a novel diffusion-based feature-distillation paradigm, CaDistill. While the student has full access to the training set, the CDM as teacher transfers core class knowledge only via CLAReps, which amounts to merely 10 % of the training data in size. After training, the student achieves strong adversarial robustness and generalization ability, focusing more on the class signals instead of spurious background cues. Our findings suggest that CDMs can serve not just as image generators but also as compact, interpretable teachers that can drive robust representation learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conditional diffusion models (CDMs) have shown impressive performance acrossa range of generative tasks. Their ability to model the full data distributionhas opened new avenues for analysis-by-synthesis in downstream discriminativelearning. However, this same modeling capacity causes CDMs to entangle theclass-defining features with irrelevant context, posing challenges toextracting robust and interpretable representations. To this end, we identifyCanonical LAtent Representations (CLAReps), latent codes whose internal CDMfeatures preserve essential categorical information while discardingnon-discriminative signals. When decoded, CLAReps produce representativesamples for each class, offering an interpretable and compact summary of thecore class semantics with minimal irrelevant details. Exploiting CLAReps, wedevelop a novel diffusion-based feature-distillation paradigm, CaDistill. Whilethe student has full access to the training set, the CDM as teacher transferscore class knowledge only via CLAReps, which amounts to merely 10 % of thetraining data in size. After training, the student achieves strong adversarialrobustness and generalization ability, focusing more on the class signalsinstead of spurious background cues. Our findings suggest that CDMs can servenot just as image generators but also as compact, interpretable teachers thatcan drive robust representation learning.</description>
      <author>example@mail.com (Yitao Xu, Tong Zhang, Ehsan Pajouheshgar, Sabine Süsstrunk)</author>
      <guid isPermaLink="false">2506.09955v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>On the Similarities of Embeddings in Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.09781v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  contrastive learning, representation learning, embedding, similarity,  negative pair, positive pair&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出一个统一的框架来理解对比学习（CL），分析了正负对嵌入之间的余弦相似性，并针对小批量训练中对比学习的局限性提出了一种辅助损失项。&lt;h4&gt;背景&lt;/h4&gt;对比学习通过拉近正对嵌入的距离，推开负对嵌入的距离来进行学习。尽管已有多种对比损失函数被提出和分析，但之前的工作缺乏一个全面解释这些目标函数的框架。&lt;h4&gt;目的&lt;/h4&gt;构建一个系统性的框架来理解对比学习，并解决小批量训练中对比学习的局限性。&lt;h4&gt;方法&lt;/h4&gt;通过分析正负对嵌入之间的余弦相似性，提出一个统一的框架。在完整批量设置中，研究了正对完美对齐的不可能性以及如何通过引入视域内负对来缓解这种错位。在迷你批量设置中，展示了较小批量大小导致批量内负对分离更强，从而增加了负对相似性的方差。为了解决这个局限性，引入了一个辅助损失项。&lt;h4&gt;主要发现&lt;/h4&gt;在完整批量设置中，发现当负对相似性低于某个阈值时，正对的完美对齐是不可实现的，且可以通过引入视域内负对来缓解错位。在迷你批量设置中，发现较小的批量大小会导致批量内负对的分离更强，从而增加负对相似性的方差。&lt;h4&gt;结论&lt;/h4&gt;引入的辅助损失项可以有效地提高小批量训练中对比学习方法的性能。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive learning (CL) operates on a simple yet effective principle:embeddings of positive pairs are pulled together, while those of negative pairsare pushed apart. Although various forms of contrastive loss have been proposedand analyzed from different perspectives, prior works lack a comprehensiveframework that systematically explains a broad class of these objectives. Inthis paper, we present a unified framework for understanding CL, which is basedon analyzing the cosine similarity between embeddings of positive and negativepairs. In full-batch settings, we show that perfect alignment of positive pairsis unattainable when similarities of negative pairs fall below a certainthreshold, and that this misalignment can be alleviated by incorporatingwithin-view negative pairs. In mini-batch settings, we demonstrate that smallerbatch sizes incur stronger separation among negative pairs within batches,which leads to higher variance in similarities of negative pairs. To addressthis limitation of mini-batch CL, we introduce an auxiliary loss term thatreduces the variance of similarities of negative pairs in CL. Empirical resultsdemonstrate that incorporating the proposed loss consistently improves theperformance of CL methods in small-batch training.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning (CL) operates on a simple yet effective principle:embeddings of positive pairs are pulled together, while those of negative pairsare pushed apart. Although various forms of contrastive loss have been proposedand analyzed from different perspectives, prior works lack a comprehensiveframework that systematically explains a broad class of these objectives. Inthis paper, we present a unified framework for understanding CL, which is basedon analyzing the cosine similarity between embeddings of positive and negativepairs. In full-batch settings, we show that perfect alignment of positive pairsis unattainable when similarities of negative pairs fall below a certainthreshold, and that this misalignment can be alleviated by incorporatingwithin-view negative pairs. In mini-batch settings, we demonstrate that smallerbatch sizes incur stronger separation among negative pairs within batches,which leads to higher variance in similarities of negative pairs. To addressthis limitation of mini-batch CL, we introduce an auxiliary loss term thatreduces the variance of similarities of negative pairs in CL. Empirical resultsdemonstrate that incorporating the proposed loss consistently improves theperformance of CL methods in small-batch training.</description>
      <author>example@mail.com (Chungpa Lee, Sehee Lim, Kibok Lee, Jy-yong Sohn)</author>
      <guid isPermaLink="false">2506.09781v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging 6DoF Pose Foundation Models For Mapping Marine Sediment Burial</title>
      <link>http://arxiv.org/abs/2506.10386v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究通过结合深度学习模型和立体摄影测量技术，提出了一种名为PoseIDON的计算机视觉流程，用于从ROV视频中估计海底物体的埋藏深度和姿态，为污染评估和恢复策略提供支持。&lt;h4&gt;背景&lt;/h4&gt;海底人类遗物（如弹药）的埋藏状态对于了解沉积动力学、评估生态风险、污染物传输以及危险材料的回收或缓解策略至关重要。&lt;h4&gt;目的&lt;/h4&gt;提高从远程图像中准确估计海底物体埋藏深度的能力。&lt;h4&gt;方法&lt;/h4&gt;PoseIDON结合了深度学习模型和立体摄影测量技术，通过比对物体的CAD模型和观察到的图像来推断埋藏深度，并对海底进行局部平面近似。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在圣地亚哥湾的一个历史海洋倾倒场的54个物体（包括桶和弹药）上进行了验证，平均埋藏深度误差约为10厘米，并能解决反映潜在沉积传输过程的埋藏模式。&lt;h4&gt;结论&lt;/h4&gt;该研究方法可实现海底埋藏的可扩展、非侵入性测绘，并支持污染场所的环境评估。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The burial state of anthropogenic objects on the seafloor provides insightinto localized sedimentation dynamics and is also critical for assessingecological risks, potential pollutant transport, and the viability of recoveryor mitigation strategies for hazardous materials such as munitions. Accurateburial depth estimation from remote imagery remains difficult due to partialocclusion, poor visibility, and object degradation. This work introduces acomputer vision pipeline, called PoseIDON, which combines deep foundation modelfeatures with multiview photogrammetry to estimate six degrees of freedomobject pose and the orientation of the surrounding seafloor from ROV video.Burial depth is inferred by aligning CAD models of the objects with observedimagery and fitting a local planar approximation of the seafloor. The method isvalidated using footage of 54 objects, including barrels and munitions,recorded at a historic ocean dumpsite in the San Pedro Basin. The modelachieves a mean burial depth error of approximately 10 centimeters and resolvesspatial burial patterns that reflect underlying sediment transport processes.This approach enables scalable, non-invasive mapping of seafloor burial andsupports environmental assessment at contaminated sites.</description>
      <author>example@mail.com (Jerry Yan, Chinmay Talegaonkar, Nicholas Antipa, Eric Terrill, Sophia Merrifield)</author>
      <guid isPermaLink="false">2506.10386v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Auto-Compressing Networks</title>
      <link>http://arxiv.org/abs/2506.09714v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究介绍了Auto-Compressing Networks (ACN)这种新型网络结构，通过长距离前馈连接实现信息自动压缩，提高了网络的鲁棒性和迁移学习能力。&lt;h4&gt;背景&lt;/h4&gt;深度神经网络在多个领域取得了显著成功，但随着网络深度的增加，计算冗余问题也随之出现，而表示质量并没有相应提高。&lt;h4&gt;目的&lt;/h4&gt;提出ACN架构，通过改变连接方式，使网络在训练过程中自动压缩信息。&lt;h4&gt;方法&lt;/h4&gt;通过引入长距离前馈连接替换传统的短残差连接，并观察ACN在网络训练过程中的信息压缩行为。&lt;h4&gt;主要发现&lt;/h4&gt;ACN具有自动压缩的特性，能够在训练过程中动态地将信息推入早期层，提高其表示质量，同时揭示深层中的潜在冗余。理论研究表明，这一特性源于ACN中的层间训练模式，根据任务需求动态地利用层。ACN比残差网络表现出更强的噪声鲁棒性、在低数据环境下的优越性能、改进的迁移学习能力以及减少灾难性遗忘，表明它们虽然参数较少，但学习的表示泛化能力更强。在视觉Transformer、MLP-mixers和Bert架构上，ACN实现了高达18%的灾难性遗忘减少和30-80%的架构压缩，同时保持了精度。将ACN与传统剪枝技术相结合，可以在稀疏性-性能权衡方面显著优于传统架构。&lt;h4&gt;结论&lt;/h4&gt;ACN是一种实用的方法，可以开发出能够根据任务复杂度自动调整其计算足迹的高效神经网络架构，同时学习鲁棒的表示。&lt;h4&gt;翻译&lt;/h4&gt;In this study, the novel network architecture called Auto-Compressing Networks (ACN) is proposed, which achieves information automatic compression through long-distance feedforward connections, improving the robustness and transfer learning capabilities of the network.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks with short residual connections have demonstratedremarkable success across domains, but increasing depth often introducescomputational redundancy without corresponding improvements in representationquality. In this work, we introduce Auto-Compressing Networks (ACNs), anarchitectural variant where additive long feedforward connections from eachlayer to the output replace traditional short residual connections. ACNsshowcase a unique property we coin as "auto-compression", the ability of anetwork to organically compress information during training with gradientdescent, through architectural design alone. Through auto-compression,information is dynamically "pushed" into early layers during training,enhancing their representational quality and revealing potential redundancy indeeper ones. We theoretically show that this property emerges from layer-wisetraining patterns present in ACNs, where layers are dynamically utilized duringtraining based on task requirements. We also find that ACNs exhibit enhancednoise robustness compared to residual networks, superior performance inlow-data settings, improved transfer learning capabilities, and mitigatecatastrophic forgetting suggesting that they learn representations thatgeneralize better despite using fewer parameters. Our results demonstrate up to18% reduction in catastrophic forgetting and 30-80% architectural compressionwhile maintaining accuracy across vision transformers, MLP-mixers, and BERTarchitectures. Furthermore, we demonstrate that coupling ACNs with traditionalpruning techniques, enables significantly better sparsity-performancetrade-offs compared to conventional architectures. These findings establishACNs as a practical approach to developing efficient neural architectures thatautomatically adapt their computational footprint to task complexity, whilelearning robust representations.</description>
      <author>example@mail.com (Vaggelis Dorovatas, Georgios Paraskevopoulos, Alexandros Potamianos)</author>
      <guid isPermaLink="false">2506.09714v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing semi-resolved CFD-DEM for dilute to dense particle-fluid systems: A point cloud based, two-step mapping strategy via coarse graining</title>
      <link>http://arxiv.org/abs/2506.09517v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个基于两点映射的CFD-DEM耦合方法，通过点云粗化技术解决传统方法中存在的问题，并验证了其在多种配置下的有效性。&lt;h4&gt;背景&lt;/h4&gt;CFD-DEM耦合是一种高效强大的工具，用于模拟粒子-流体系统，但传统的体积平均CFD-DEM在流体网格分辨率上具有强依赖性，可能导致不稳定并无法捕捉到致密颗粒系统中的孔隙流体压力效应。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的CFD-DEM耦合方法，以克服传统方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;采用点云粗化技术，首先将离散粒子转换为平滑的粗化连续场，然后实现粗化点云场与流体网格变量的精确耦合。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在各种配置下得到验证，包括一维网格上的静态粒子权重分配、二维网格上的下落粒子、粘性流体中的球体沉降、尺寸双分散流化床、Ergun压降测试和浸没颗粒柱倒塌。&lt;h4&gt;结论&lt;/h4&gt;所提出的CFD-DEM方法为准确模拟流体-粒子相互作用提供了一种新的策略，适用于广泛的网格到粒子尺寸比和固体浓度，具有在工业和地球物理应用中的潜在用途。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computational fluid dynamics and discrete element method (CFD-DEM) couplingis an efficient and powerful tool to simulate particle-fluid systems. However,current volume-averaged CFD-DEM relying on direct grid-based mapping betweenthe fluid and particle phases can exhibit a strong dependence on the fluid gridresolution, becoming unstable as particles move across fluid grids, and canfail to capture pore fluid pressure effects in very dense granular systems.Here we propose a two-step mapping CFD-DEM which uses a point-based coarsegraining technique for intermediate smoothing to overcome these limitations.The discrete particles are first converted into smooth, coarse-grainedcontinuum fields via a multi-layer Fibonacci point cloud, independent of thefluid grids. Then, accurate coupling is achieved between the coarse-grained,point cloud fields and the fluid grid-based variables. The algorithm isvalidated in various configurations, including weight allocation of a staticparticle on one-dimensional grids and a falling particle on two-dimensionalgrids, sedimentation of a sphere in a viscous fluid, size-bidisperse fluidizedbeds, Ergun's pressure drop test, and immersed granular column collapse. Theproposed CFD-DEM represents a novel strategy to accurately simulatefluid-particle interactions for a wide range of grid-to-particle size ratiosand solid concentrations, which is of potential use in many industrial andgeophysical applications.</description>
      <author>example@mail.com (Yuxiang Liu, Lu Jing, Xudong Fu, Huabin Shi)</author>
      <guid isPermaLink="false">2506.09517v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Prompt-Guided Latent Diffusion with Predictive Class Conditioning for 3D Prostate MRI Generation</title>
      <link>http://arxiv.org/abs/2506.10230v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MAH and BT are co-senior authors on the work. This work has been  submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的名为CCELLA的模型，旨在解决医学图像学习中数据稀缺的问题，通过结合多种策略提高了LDM的性能和科学可及性。&lt;h4&gt;背景&lt;/h4&gt;医学图像学习受数据稀缺的限制，传统方法依赖短文本编码器、非医学LDM重用或大量数据微调，这些策略限制了性能和科学可及性。&lt;h4&gt;目的&lt;/h4&gt;提出CCELLA模型以解决上述限制，实现高效且高质量的医学图像合成。&lt;h4&gt;方法&lt;/h4&gt;CCELLA使用双重头部条件化方法，通过交叉注意力结合非医学大型语言模型编码的文本特征，通过时间步嵌入结合病理分类。同时，提出联合损失函数和数据高效LDM训练框架。&lt;h4&gt;主要发现&lt;/h4&gt;CCELLA在限制数据量的前列腺MRI数据集上实现了3D FID分数0.025，显著优于FID 0.071的最近基础模型。在前列腺癌预测中，添加合成图像到训练集将分类器准确率从69%提高至74%，仅用合成图像训练的分类器性能与仅用真实图像训练相当。&lt;h4&gt;结论&lt;/h4&gt;CCELLA模型在有限的医学图像数据和高数据标注成本下，能够提高LDM的性能和科学可及性，为医学图像合成和病理预测提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Latent diffusion models (LDM) could alleviate data scarcity challengesaffecting machine learning development for medical imaging. However, medicalLDM training typically relies on performance- or scientificaccessibility-limiting strategies including a reliance on short-prompt textencoders, the reuse of non-medical LDMs, or a requirement for fine-tuning withlarge data volumes. We propose a Class-Conditioned Efficient Large Languagemodel Adapter (CCELLA) to address these limitations. CCELLA is a noveldual-head conditioning approach that simultaneously conditions the LDM U-Netwith non-medical large language model-encoded text features throughcross-attention and with pathology classification through the timestepembedding. We also propose a joint loss function and a data-efficient LDMtraining framework. In combination, these strategies enablepathology-conditioned LDM training for high-quality medical image synthesisgiven limited data volume and human data annotation, improving LDM performanceand scientific accessibility. Our method achieves a 3D FID score of 0.025 on asize-limited prostate MRI dataset, significantly outperforming a recentfoundation model with FID 0.071. When training a classifier for prostate cancerprediction, adding synthetic images generated by our method to the trainingdataset improves classifier accuracy from 69% to 74%. Training a classifiersolely on our method's synthetic images achieved comparable performance totraining on real images alone.</description>
      <author>example@mail.com (Emerson P. Grabke, Masoom A. Haider, Babak Taati)</author>
      <guid isPermaLink="false">2506.10230v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>An Effective End-to-End Solution for Multimodal Action Recognition</title>
      <link>http://arxiv.org/abs/2506.09345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种综合的多模态动作识别解决方案，有效利用多模态信息，解决了三模态数据稀缺的问题，并在动作识别竞赛中取得了优异的成绩。&lt;h4&gt;背景&lt;/h4&gt;多模态任务在动作识别领域取得了显著进展，但由于三模态数据的稀缺，研究三模态动作识别任务面临许多挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种综合的多模态动作识别解决方案，以解决三模态数据稀缺的问题。&lt;h4&gt;方法&lt;/h4&gt;1. 通过优化数据增强技术扩大训练规模，并使用更多RGB数据集预训练骨干网络；2. 利用2D CNN提取多模态空间特征，并结合TSM模块实现多模态时空特征提取；3. 使用SWA、集成和测试时增强（TTA）等预测增强方法，整合不同训练阶段和不同架构的模型知识。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在动作识别竞赛中实现了99%的Top-1准确率和100%的Top-5准确率。&lt;h4&gt;结论&lt;/h4&gt;该解决方案在动作识别领域具有优越性。&lt;h4&gt;翻译&lt;/h4&gt;最近，多模态任务由于它们丰富的多模态信息而极大地推动了动作识别领域的发展。然而，由于三模态数据的稀缺，三模态动作识别任务的研究面临着许多挑战。为此，我们提出了一种全面的多模态动作识别解决方案，该方案有效地利用了多模态信息。首先，通过优化数据增强技术对现有数据进行转换和扩展，以扩大训练规模。同时，使用更多的RGB数据集来预训练骨干网络，通过迁移学习使网络更好地适应新任务。其次，利用2D CNN提取多模态空间特征，并结合时间移位模块（TSM）实现与3D CNN相当的多模态时空特征提取，以提高计算效率。此外，还使用了常见的预测增强方法，如随机权重平均（SWA）、集成和测试时增强（TTA），以整合来自相同架构的不同训练阶段和不同架构的模型知识，从而从不同角度预测动作并充分利用目标信息。最终，我们在竞赛排行榜上实现了99%的Top-1准确率和100%的Top-5准确率，证明了我们解决方案的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, multimodal tasks have strongly advanced the field of actionrecognition with their rich multimodal information. However, due to thescarcity of tri-modal data, research on tri-modal action recognition tasksfaces many challenges. To this end, we have proposed a comprehensive multimodalaction recognition solution that effectively utilizes multimodal information.First, the existing data are transformed and expanded by optimizing dataenhancement techniques to enlarge the training scale. At the same time, moreRGB datasets are used to pre-train the backbone network, which is betteradapted to the new task by means of transfer learning. Secondly, multimodalspatial features are extracted with the help of 2D CNNs and combined with theTemporal Shift Module (TSM) to achieve multimodal spatial-temporal featureextraction comparable to 3D CNNs and improve the computational efficiency. Inaddition, common prediction enhancement methods, such as Stochastic WeightAveraging (SWA), Ensemble and Test-Time augmentation (TTA), are used tointegrate the knowledge of models from different training periods of the samearchitecture and different architectures, so as to predict the actions fromdifferent perspectives and fully exploit the target information. Ultimately, weachieved the Top-1 accuracy of 99% and the Top-5 accuracy of 100% on thecompetition leaderboard, demonstrating the superiority of our solution.</description>
      <author>example@mail.com (Songping Wang, Xiantao Hu, Yueming Lyu, Caifeng Shan)</author>
      <guid isPermaLink="false">2506.09345v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Generalized Gaussian Entropy Model for Point Cloud Attribute Compression with Dynamic Likelihood Intervals</title>
      <link>http://arxiv.org/abs/2506.09510v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于广义高斯熵模型和Mean Error Discriminator (MED)的方法，用于提高点云属性压缩的率失真性能。&lt;h4&gt;背景&lt;/h4&gt;高斯和拉普拉斯熵模型在点云属性压缩中已证明有效，但当前方法中神经网络估计的熵参数中仍存在未利用的信息。&lt;h4&gt;目的&lt;/h4&gt;旨在通过利用这些未利用的信息，提高概率估计的准确性，从而改善点云属性压缩的率失真性能。&lt;h4&gt;方法&lt;/h4&gt;引入了广义高斯熵模型，通过形状参数控制尾部形状以更准确地估计潜变量概率；同时，提出了Mean Error Discriminator (MED)来确定熵参数估计的准确性，并动态调整似然区间。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在基于VAE的三个点云属性压缩模型上显著提高了率失真性能，并且该方法可以应用于其他压缩任务，如图像和视频压缩。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过利用未利用的信息和动态调整似然区间，有效提高了点云属性压缩的率失真性能，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gaussian and Laplacian entropy models are proved effective in learned pointcloud attribute compression, as they assist in arithmetic coding of latents.However, we demonstrate through experiments that there is still unutilizedinformation in entropy parameters estimated by neural networks in currentmethods, which can be used for more accurate probability estimation. Thus weintroduce generalized Gaussian entropy model, which controls the tail shapethrough shape parameter to more accurately estimate the probability of latents.Meanwhile, to the best of our knowledge, existing methods use fixed likelihoodintervals for each integer during arithmetic coding, which limits modelperformance. We propose Mean Error Discriminator (MED) to determine whether theentropy parameter estimation is accurate and then dynamically adjust likelihoodintervals. Experiments show that our method significantly improvesrate-distortion (RD) performance on three VAE-based models for point cloudattribute compression, and our method can be applied to other compressiontasks, such as image and video compression.</description>
      <author>example@mail.com (Changhao Peng, Yuqi Ye, Wei Gao)</author>
      <guid isPermaLink="false">2506.09510v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Causal Climate Emulation with Bayesian Filtering</title>
      <link>http://arxiv.org/abs/2506.09891v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  32 pages, 21 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于因果表示学习的可解释气候模型模拟器，通过引入贝叶斯滤波和长期自回归模拟，实现了对气候动态的准确学习，并在合成数据集以及两个广泛使用的气候模型数据上验证了模型组件的重要性。&lt;h4&gt;背景&lt;/h4&gt;传统气候模型使用复杂的耦合方程模拟地球系统中的物理过程，这些模拟计算成本高，限制了我们对气候变化及其原因和影响的预测和分析。&lt;h4&gt;目的&lt;/h4&gt;开发一种可解释的气候模型模拟器，能够快速模拟气候模型数据，并能够结合物理信息。&lt;h4&gt;方法&lt;/h4&gt;基于因果表示学习，引入贝叶斯滤波和长期自回归模拟方法。&lt;h4&gt;主要发现&lt;/h4&gt;模拟器能够学习准确的气候动态，其各个组件在现实合成数据集和两个广泛使用的气候模型数据上的重要性得到验证。&lt;h4&gt;结论&lt;/h4&gt;提出的气候模型模拟器能够有效地模拟气候动态，并有助于深入理解气候变化的原因和影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional models of climate change use complex systems of coupled equationsto simulate physical processes across the Earth system. These simulations arehighly computationally expensive, limiting our predictions of climate changeand analyses of its causes and effects. Machine learning has the potential toquickly emulate data from climate models, but current approaches are not ableto incorporate physics-informed causal relationships. Here, we develop aninterpretable climate model emulator based on causal representation learning.We derive a physics-informed approach including a Bayesian filter for stablelong-term autoregressive emulation. We demonstrate that our emulator learnsaccurate climate dynamics, and we show the importance of each one of itscomponents on a realistic synthetic dataset and data from two widely deployedclimate models.</description>
      <author>example@mail.com (Sebastian Hickman, Ilija Trajkovic, Julia Kaltenborn, Francis Pelletier, Alex Archibald, Yaniv Gurwicz, Peer Nowack, David Rolnick, Julien Boussard)</author>
      <guid isPermaLink="false">2506.09891v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>An Explainable Deep Learning Framework for Brain Stroke and Tumor Progression via MRI Interpretation</title>
      <link>http://arxiv.org/abs/2506.09161v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in MECON 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于深度学习的系统，能够从MRI图像中识别脑肿瘤和中风，以及它们的相应阶段。&lt;h4&gt;背景&lt;/h4&gt;早期和准确检测脑部异常（如肿瘤和中风）对于及时干预和改善患者预后至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究目的是开发一个能够识别脑肿瘤和中风以及其阶段的深度学习系统。&lt;h4&gt;方法&lt;/h4&gt;研究采用了两种创新的策略，涉及使用MobileNet V2和ResNet-50卷积神经网络，通过迁移学习优化来对MRI扫描进行分类，共分为五个诊断类别。数据集从各种公开的MRI资源中收集和增强，以确保类别平衡和图像多样性。为了提高模型的泛化能力和防止过拟合，使用了dropout层和广泛的数据增强。&lt;h4&gt;主要发现&lt;/h4&gt;模型在训练准确率达到93%，验证准确率达到88%的情况下表现出强大的性能。尽管ResNet-50表现略好，但MobileNet V2由于其轻量级架构，在资源有限的环境中仍是一个有前景的实时诊断选择。&lt;h4&gt;结论&lt;/h4&gt;这项研究提供了一个基于AI的早期脑部异常检测的实际解决方案，具有临床部署的潜力，并可通过更大的数据集和多模态输入进行未来的改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early and accurate detection of brain abnormalities, such as tumors andstrokes, is essential for timely intervention and improved patient outcomes. Inthis study, we present a deep learning-based system capable of identifying bothbrain tumors and strokes from MRI images, along with their respective stages.We have executed two groundbreaking strategies involving convolutional neuralnetworks, MobileNet V2 and ResNet-50-optimized through transfer learning toclassify MRI scans into five diagnostic categories. Our dataset, aggregated andaugmented from various publicly available MRI sources, was carefully curated toensure class balance and image diversity. To enhance model generalization andprevent overfitting, we applied dropout layers and extensive data augmentation.The models achieved strong performance, with training accuracy reaching 93\%and validation accuracy up to 88\%. While ResNet-50 demonstrated slightlybetter results, Mobile Net V2 remains a promising option for real-timediagnosis in low resource settings due to its lightweight architecture. Thisresearch offers a practical AI-driven solution for early brain abnormalitydetection, with potential for clinical deployment and future enhancementthrough larger datasets and multi modal inputs.</description>
      <author>example@mail.com (Rajan Das Gupta, Md Imrul Hasan Showmick, Mushfiqur Rahman Abir, Shanjida Akter, Md. Yeasin Rahat, Md. Jakir Hossen)</author>
      <guid isPermaLink="false">2506.09161v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Do Multiple Instance Learning Models Transfer?</title>
      <link>http://arxiv.org/abs/2506.09022v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 (Spotlight). 20 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在计算病理学中，预训练的多实例学习（MIL）模型在生成临床有意义的切片级嵌入方面的能力，并评估了其在不同任务上的迁移学习能力。&lt;h4&gt;背景&lt;/h4&gt;MIL在计算病理学中用于从高分辨率组织图像中生成临床有意义的切片级嵌入，但在小规模、弱监督的临床数据集上表现不佳。与自然语言处理和传统计算机视觉领域不同，MIL模型的迁移性理解不足。&lt;h4&gt;目的&lt;/h4&gt;系统地评估预训练MIL模型的迁移学习能力。&lt;h4&gt;方法&lt;/h4&gt;评估了11个模型在21个预训练任务上的表现，包括形态学和分子亚型预测。&lt;h4&gt;主要发现&lt;/h4&gt;预训练MIL模型在不同器官上训练后，在目标任务上表现优于从头开始训练的模型。在跨器官和任务上的预训练，尤其是在泛癌症数据集上，能够实现强大的泛化能力，且预训练数据量显著减少。&lt;h4&gt;结论&lt;/h4&gt;MIL模型具有强大的适应能力，迁移学习有助于提高计算病理学中的性能。&lt;h4&gt;翻译&lt;/h4&gt;Multiple Instance Learning (MIL) is a cornerstone approach in computational pathology (CPath) for generating clinically meaningful slide-level embeddings from gigapixel tissue images. However, MIL often struggles with small, weakly supervised clinical datasets. In contrast to fields such as NLP and conventional computer vision, where transfer learning is widely used to address data scarcity, the transferability of MIL models remains poorly understood. In this study, we systematically evaluate the transfer learning capabilities of pretrained MIL models by assessing 11 models across 21 pretraining tasks for morphological and molecular subtype prediction. Our results show that pretrained MIL models, even when trained on different organs than the target task, consistently outperform models trained from scratch. Moreover, pretraining on pancancer datasets enables strong generalization across organs and tasks, outperforming slide foundation models while using substantially less pretraining data. These findings highlight the robust adaptability of MIL models and demonstrate the benefits of leveraging transfer learning to boost performance in CPath. Lastly, we provide a resource which standardizes the implementation of MIL models and collection of pretrained model weights on popular CPath tasks, available at https://github.com/mahmoodlab/MIL-Lab&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multiple Instance Learning (MIL) is a cornerstone approach in computationalpathology (CPath) for generating clinically meaningful slide-level embeddingsfrom gigapixel tissue images. However, MIL often struggles with small, weaklysupervised clinical datasets. In contrast to fields such as NLP andconventional computer vision, where transfer learning is widely used to addressdata scarcity, the transferability of MIL models remains poorly understood. Inthis study, we systematically evaluate the transfer learning capabilities ofpretrained MIL models by assessing 11 models across 21 pretraining tasks formorphological and molecular subtype prediction. Our results show thatpretrained MIL models, even when trained on different organs than the targettask, consistently outperform models trained from scratch. Moreover,pretraining on pancancer datasets enables strong generalization across organsand tasks, outperforming slide foundation models while using substantially lesspretraining data. These findings highlight the robust adaptability of MILmodels and demonstrate the benefits of leveraging transfer learning to boostperformance in CPath. Lastly, we provide a resource which standardizes theimplementation of MIL models and collection of pretrained model weights onpopular CPath tasks, available at https://github.com/mahmoodlab/MIL-Lab</description>
      <author>example@mail.com (Daniel Shao, Richard J. Chen, Andrew H. Song, Joel Runevic, Ming Y. Lu, Tong Ding, Faisal Mahmood)</author>
      <guid isPermaLink="false">2506.09022v2</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Data-Centric Safety and Ethical Measures for Data and AI Governance</title>
      <link>http://arxiv.org/abs/2506.10217v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper accepted and presented at the AAAI 2025 Workshop on Datasets  and Evaluators of AI Safety https://sites.google.com/view/datasafe25/home&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个负责的数据集设计框架，旨在提高人工智能（AI）模型的安全性，减少因低质量、不安全和不道德的数据内容导致的AI滥用风险。&lt;h4&gt;背景&lt;/h4&gt;数据集在赋予AI基础模型高级能力以适应各种下游任务中起着关键作用。这些下游应用可能带来有益和有害的能力，导致双用途AI基础模型，需要各种技术和监管方法来监控和管理这些风险。&lt;h4&gt;目的&lt;/h4&gt;尽管数据集在AI发展中的角色至关重要，但负责的数据集设计和确保数据中心的安仝和道德实践却得到了较少的关注。本研究旨在提出一个负责的数据集设计框架。&lt;h4&gt;方法&lt;/h4&gt;该框架涵盖了AI和数据集生命周期的各个阶段，旨在增强安全措施并减少AI误用的风险。&lt;h4&gt;主要发现&lt;/h4&gt;该框架是领域无关的，适用于各种应用，并可以促进数据集创建、使用和共享中的负责任实践，以促进红队测试、最小化风险并增加对AI模型的信任。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了数据集设计在AI安全中的重要性，并提出了一个全面的框架来提高数据质量和确保AI模型的道德使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Datasets play a key role in imparting advanced capabilities to artificialintelligence (AI) foundation models that can be adapted to various downstreamtasks. These downstream applications can introduce both beneficial and harmfulcapabilities -- resulting in dual use AI foundation models, with varioustechnical and regulatory approaches to monitor and manage these risks. However,despite the crucial role of datasets, responsible dataset design and ensuringdata-centric safety and ethical practices have received less attention. In thisstudy, we pro-pose responsible dataset design framework that encompassesvarious stages in the AI and dataset lifecycle to enhance safety measures andreduce the risk of AI misuse due to low quality, unsafe and unethical datacontent. This framework is domain agnostic, suitable for adoption for variousapplications and can promote responsible practices in dataset creation, use,and sharing to facilitate red teaming, minimize risks, and increase trust in AImodels.</description>
      <author>example@mail.com (Srija Chakraborty)</author>
      <guid isPermaLink="false">2506.10217v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent</title>
      <link>http://arxiv.org/abs/2506.10205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 workshop on Efficient Systems for Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了针对大型语言模型（LLMs）体积庞大问题，提出了基于层状后训练量化和剪枝的方法，并通过理论分析证明了该方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;LLMs由于体积庞大，在边缘设备上应用受限，因此需要模型压缩方法，如量化和剪枝。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的层状后训练量化和剪枝方法，以提高LLMs在边缘设备上的性能。&lt;h4&gt;方法&lt;/h4&gt;该方法基于激活感知权重剪枝和稀疏逼近问题之间的联系，并受到迭代硬阈值法（IHT）成功的启发，通过投影梯度下降（AWP）实现。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AWP在LLMs剪枝和量化方面优于现有方法，并提供了剪枝方法的理论收敛保证。&lt;h4&gt;结论&lt;/h4&gt;AWP是一种有效的LLMs剪枝和量化方法，可以提高LLMs在边缘设备上的性能。&lt;h4&gt;翻译&lt;/h4&gt;To address the enormous size of Large Language Models (LLMs), modelcompression methods, such as quantization and pruning, are often deployed, especially on edge devices. In this work, we focus on layer-wise post-training quantization and pruning. Drawing connections between activation-aware weight pruning and sparse approximation problems, and motivated by the success of Iterative Hard Thresholding (IHT), we propose a unified method for Activation-aware Weight pruning and quantization via Projected gradient descent (AWP). Our experiments demonstrate that AWP outperforms state-of-the-art LLM pruning and quantization methods. Theoretical convergence guarantees of the proposed method for pruning are also provided.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To address the enormous size of Large Language Models (LLMs), modelcompression methods, such as quantization and pruning, are often deployed,especially on edge devices. In this work, we focus on layer-wise post-trainingquantization and pruning. Drawing connections between activation-aware weightpruning and sparse approximation problems, and motivated by the success ofIterative Hard Thresholding (IHT), we propose a unified method forActivation-aware Weight pruning and quantization via Projected gradient descent(AWP). Our experiments demonstrate that AWP outperforms state-of-the-art LLMpruning and quantization methods. Theoretical convergence guarantees of theproposed method for pruning are also provided.</description>
      <author>example@mail.com (Jing Liu, Toshiaki Koike-Akino, Ye Wang, Hassan Mansour, Matthew Brand)</author>
      <guid isPermaLink="false">2506.10205v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Wasserstein Hypergraph Neural Network</title>
      <link>http://arxiv.org/abs/2506.09682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Wasserstein超图神经网络的模型，该模型在处理超图信息时，使用Sliced Wasserstein Pooling方法来聚合信息，并展现出在节点分类任务上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;关系信息建模在机器学习领域的应用推动了多个领域的进步，超图表示学习近年来成为主流，而通过超图表示高阶关系的方法正在迅速发展。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的超图神经网络模型，以改进节点分类任务的性能。&lt;h4&gt;方法&lt;/h4&gt;引入Wasserstein超图神经网络，该模型将节点和超边邻域视为分布，并使用Sliced Wasserstein Pooling来聚合信息。&lt;h4&gt;主要发现&lt;/h4&gt;与传统聚合器（如均值或求和）不同，该模型能够保留分布的几何属性，如形状和分布范围，从而能够反映超边分布之间的转换难度。&lt;h4&gt;结论&lt;/h4&gt;在节点分类任务上，将Wasserstein Pooling应用于超图设置显著提高了性能，在多个真实世界数据集上达到了顶尖水平。&lt;h4&gt;翻译&lt;/h4&gt;The ability to model relational information using machine learning has driven advancements across various domains, from medicine to social science. While graph representation learning has become mainstream over the past decade, representing higher-order relationships through hypergraphs is rapidly gaining momentum. In the last few years, numerous hypergraph neural networks have emerged, most of them falling under a two-stage, set-based framework. The messages are sent from nodes to edges and then from edges to nodes. However, most of the advancement still takes inspiration from the graph counterpart, often simplifying the aggregations to basic pooling operations. In this paper we are introducing Wasserstein Hypergraph Neural Network, a model that treats the nodes and hyperedge neighbourhood as distributions and aggregate the information using Sliced Wasserstein Pooling. Unlike conventional aggregators such as mean or sum, which only capture first-order statistics, our approach has the ability to preserve geometric properties like the shape and spread of distributions. This enables the learned embeddings to reflect how easily one hyperedge distribution can be transformed into another, following principles of optimal transport. Experimental results demonstrate that applying Wasserstein pooling in a hypergraph setting significantly benefits node classification tasks, achieving top performance on several real-world datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to model relational information using machine learning has drivenadvancements across various domains, from medicine to social science. Whilegraph representation learning has become mainstream over the past decade,representing higher-order relationships through hypergraphs is rapidly gainingmomentum. In the last few years, numerous hypergraph neural networks haveemerged, most of them falling under a two-stage, set-based framework. Themessages are sent from nodes to edges and then from edges to nodes. However,most of the advancement still takes inspiration from the graph counterpart,often simplifying the aggregations to basic pooling operations. In this paperwe are introducing Wasserstein Hypergraph Neural Network, a model that treatsthe nodes and hyperedge neighbourhood as distributions and aggregate theinformation using Sliced Wasserstein Pooling. Unlike conventional aggregatorssuch as mean or sum, which only capture first-order statistics, our approachhas the ability to preserve geometric properties like the shape and spread ofdistributions. This enables the learned embeddings to reflect how easily onehyperedge distribution can be transformed into another, following principles ofoptimal transport. Experimental results demonstrate that applying Wassersteinpooling in a hypergraph setting significantly benefits node classificationtasks, achieving top performance on several real-world datasets.</description>
      <author>example@mail.com (Iulia Duta, Pietro Liò)</author>
      <guid isPermaLink="false">2506.09682v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>One Patient, Many Contexts: Scaling Medical AI Through Contextual Intelligence</title>
      <link>http://arxiv.org/abs/2506.10157v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;医学基础模型，包括在临床笔记上训练的语言模型、在医学图像上的视觉-语言模型以及在电子健康记录上的多模态模型，可以总结临床笔记、回答医学问题并协助决策。适应新人群、专业或环境通常需要微调、仔细提示或从知识库中检索，这通常是不切实际的，并限制了它们解释不熟悉的输入和适应训练期间未表示的临床情况的能力。因此，模型容易出现情境错误，即预测看起来合理但未能考虑关键的病人特异性或情境信息。这些错误源于当前模型难以克服的基本限制：在医疗护理不断变化的环境中动态调整其行为。&lt;h4&gt;背景&lt;/h4&gt;医学基础模型在临床笔记、医学图像和电子健康记录上的应用，但需要针对新人群、专业或环境进行微调或检索知识库，限制了模型解释不熟悉输入和适应新情况的能力。&lt;h4&gt;目的&lt;/h4&gt;提出在医疗人工智能中实现情境切换的愿景，即模型能够动态调整推理而不需要针对新专业、人群、工作流程和临床角色进行重新训练。&lt;h4&gt;方法&lt;/h4&gt;概述情境切换在医疗人工智能中的愿景，探讨如何使模型适应不同专业和地区，诊断、管理和治疗各种疾病，并扩大医疗服务的可及性。&lt;h4&gt;主要发现&lt;/h4&gt;当前医学模型在动态调整行为以适应不断变化的医疗护理环境方面存在根本性限制，导致情境错误。&lt;h4&gt;结论&lt;/h4&gt;需要发展能够动态适应新专业、人群、工作流程和临床角色的医疗人工智能模型，以诊断、管理和治疗各种疾病，并扩大医疗服务的可及性。&lt;h4&gt;翻译&lt;/h4&gt;Medical foundation models, including language models trained on clinical notes, vision-language models on medical images, and multimodal models on electronic health records, can summarize clinical notes, answer medical questions, and assist in decision-making. Adapting these models to new populations, specialties, or settings typically requires fine-tuning, careful prompting, or retrieval from knowledge bases. This can be impractical, and limits their ability to interpret unfamiliar inputs and adjust to clinical situations not represented during training. As a result, models are prone to contextual errors, where predictions appear reasonable but fail to account for critical patient-specific or contextual information. These errors stem from a fundamental limitation that current models struggle with: dynamically adjusting their behavior across evolving contexts of medical care. In this Perspective, we outline a vision for context-switching in medical AI: models that dynamically adapt their reasoning without retraining to new specialties, populations, workflows, and clinical roles. We envision context-switching AI to diagnose, manage, and treat a wide range of diseases across specialties and regions, and expand access to medical care.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical foundation models, including language models trained on clinicalnotes, vision-language models on medical images, and multimodal models onelectronic health records, can summarize clinical notes, answer medicalquestions, and assist in decision-making. Adapting these models to newpopulations, specialties, or settings typically requires fine-tuning, carefulprompting, or retrieval from knowledge bases. This can be impractical, andlimits their ability to interpret unfamiliar inputs and adjust to clinicalsituations not represented during training. As a result, models are prone tocontextual errors, where predictions appear reasonable but fail to account forcritical patient-specific or contextual information. These errors stem from afundamental limitation that current models struggle with: dynamically adjustingtheir behavior across evolving contexts of medical care. In this Perspective,we outline a vision for context-switching in medical AI: models thatdynamically adapt their reasoning without retraining to new specialties,populations, workflows, and clinical roles. We envision context-switching AI todiagnose, manage, and treat a wide range of diseases across specialties andregions, and expand access to medical care.</description>
      <author>example@mail.com (Michelle M. Li, Ben Y. Reis, Adam Rodman, Tianxi Cai, Noa Dagan, Ran D. Balicer, Joseph Loscalzo, Isaac S. Kohane, Marinka Zitnik)</author>
      <guid isPermaLink="false">2506.10157v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>DGAE: Diffusion-Guided Autoencoder for Efficient Latent Representation Learning</title>
      <link>http://arxiv.org/abs/2506.09644v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DGAE的模型，通过视觉标记将像素压缩到潜在空间，以解决自动编码器在高压缩比下的性能退化问题，并实现更高效、紧凑的表示。&lt;h4&gt;背景&lt;/h4&gt;尽管近期进展减轻了自动编码器在高压缩比下的性能退化，但由GAN引起的训练不稳定问题仍然是未解决的问题。&lt;h4&gt;目的&lt;/h4&gt;在提高空间压缩的同时，减少潜在空间维度，以实现更高效和紧凑的表示，并解决训练不稳定问题。&lt;h4&gt;方法&lt;/h4&gt;提出DGAE模型，采用扩散模型引导解码器恢复潜在表示中未完全解码的有用信号。&lt;h4&gt;主要发现&lt;/h4&gt;DGAE在高空间压缩率下有效缓解了性能退化，同时实现了比现有方法2倍的更小潜在空间，并展现出在ImageNet-1K图像生成任务上的竞争力。&lt;h4&gt;结论&lt;/h4&gt;DGAE模型通过紧凑的潜在表示促进了扩散模型的快速收敛，实现了高效的图像生成。&lt;h4&gt;翻译&lt;/h4&gt;摘要：自动编码器通过视觉标记将像素压缩到潜在空间，从而增强了最先进的图像和视频生成模型。尽管近期进展减轻了自动编码器在高压缩比下的性能退化，但解决由GAN引起的训练不稳定问题仍然是未解决的问题。在提高空间压缩的同时，我们旨在最小化潜在空间维度，以实现更高效和紧凑的表示。为了应对这些挑战，我们专注于提高解码器的表达能力。具体来说，我们提出了DGAE，该模型采用扩散模型来引导解码器恢复潜在表示中未完全解码的有用信号。通过这种设计，DGAE在高空间压缩率下有效地缓解了性能退化。同时，DGAE实现了比现有方法2倍的更小潜在空间，并展示了在ImageNet-1K图像生成任务上的竞争力。当与扩散模型集成时，DGAEdemonstrates competitive performance on image generation for ImageNet-1K and shows that this compact latent representation facilitates faster convergence of the diffusion model.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autoencoders empower state-of-the-art image and video generative models bycompressing pixels into a latent space through visual tokenization. Althoughrecent advances have alleviated the performance degradation of autoencodersunder high compression ratios, addressing the training instability caused byGAN remains an open challenge. While improving spatial compression, we also aimto minimize the latent space dimensionality, enabling more efficient andcompact representations. To tackle these challenges, we focus on improving thedecoder's expressiveness. Concretely, we propose DGAE, which employs adiffusion model to guide the decoder in recovering informative signals that arenot fully decoded from the latent representation. With this design, DGAEeffectively mitigates the performance degradation under high spatialcompression rates. At the same time, DGAE achieves state-of-the-art performancewith a 2x smaller latent space. When integrated with Diffusion Models, DGAEdemonstrates competitive performance on image generation for ImageNet-1K andshows that this compact latent representation facilitates faster convergence ofthe diffusion model.</description>
      <author>example@mail.com (Dongxu Liu, Yuang Peng, Haomiao Tang, Yuwei Chen, Chunrui Han, Zheng Ge, Daxin Jiang, Mingxue Liao)</author>
      <guid isPermaLink="false">2506.09644v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>TaskCraft: Automated Generation of Agentic Tasks</title>
      <link>http://arxiv.org/abs/2506.10055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为TaskCraft的自动化工作流程，用于生成可调节难度、多工具、可验证的代理任务，以促进NLP和AI的发展。&lt;h4&gt;背景&lt;/h4&gt;代理任务在NLP和AI发展中变得越来越重要，但现有的指令数据缺乏工具交互，且当前代理基准测试依赖昂贵的人工标注，限制了其可扩展性。&lt;h4&gt;目的&lt;/h4&gt;提出TaskCraft旨在解决现有代理任务数据缺乏工具交互和标注成本高的问题，提高代理任务的生成效率和模型调优。&lt;h4&gt;方法&lt;/h4&gt;TaskCraft通过深度和宽度扩展来扩展原子任务，创建结构化和层次化的复杂挑战，以生成难度可调节的代理任务。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，这些任务可以提高生成工作流程中的提示优化，并增强代理基础模型的监督微调。&lt;h4&gt;结论&lt;/h4&gt;TaskCraft提供了一组大约36,000个难度各异的合成数据集，支持未来关于代理调优和评估的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：需要多步骤问题解决、自主性、工具使用和适应性推理的代理任务，正日益成为NLP和AI进步的核心。然而，现有的指令数据缺乏工具交互，当前的代理基准测试依赖于昂贵的人工标注，限制了其可扩展性。我们介绍了TaskCraft，这是一种自动化的工作流程，用于生成难度可调节的、多工具的、可验证的代理任务，具有执行轨迹。TaskCraft通过深度和宽度扩展来扩展原子任务，以创建结构化和层次化的复杂挑战。实证结果表明，这些任务可以提高生成工作流程中的提示优化，并增强代理基础模型的监督微调。我们提出了一组大约36,000个难度各异的合成数据集，以支持未来的代理调优和评估研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Agentic tasks, which require multi-step problem solving with autonomy, tooluse, and adaptive reasoning, are becoming increasingly central to theadvancement of NLP and AI. However, existing instruction data lacks toolinteraction, and current agentic benchmarks rely on costly human annotation,limiting their scalability. We introduce \textsc{TaskCraft}, an automatedworkflow for generating difficulty-scalable, multi-tool, and verifiable agentictasks with execution trajectories. TaskCraft expands atomic tasks usingdepth-based and width-based extensions to create structurally andhierarchically complex challenges. Empirical results show that these tasksimprove prompt optimization in the generation workflow and enhance supervisedfine-tuning of agentic foundation models. We present a large-scale syntheticdataset of approximately 36,000 tasks with varying difficulty to support futureresearch on agent tuning and evaluation.</description>
      <author>example@mail.com (Dingfeng Shi, Jingyi Cao, Qianben Chen, Weichen Sun, Weizhen Li, Hongxuan Lu, Fangchen Dong, Tianrui Qin, King Zhu, Minghao Yang, Jian Yang, Ge Zhang, Jiaheng Liu, Changwang Zhang, Jun Wang, Yuchen Eleanor Jiang, Wangchunshu Zhou)</author>
      <guid isPermaLink="false">2506.10055v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>AnimateAnyMesh: A Feed-Forward 4D Foundation Model for Text-Driven Universal Mesh Animation</title>
      <link>http://arxiv.org/abs/2506.09982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://animateanymesh.github.io/AnimateAnyMesh/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AnimateAnyMesh的前馈框架，该框架能够实现高效的三维网格文本驱动动画。它通过DyMeshVAE架构有效地压缩和重建动态网格序列，同时保持局部拓扑结构。&lt;h4&gt;背景&lt;/h4&gt;尽管4D内容生成领域取得了进步，但创建高质量的动画3D模型仍然具有挑战性，因为建模时空分布的复杂性以及4D训练数据的稀缺性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效进行文本驱动动画的任意三维网格的前馈框架。&lt;h4&gt;方法&lt;/h4&gt;采用了一种新的DyMeshVAE架构，该架构通过分离空间和时间特征来有效地压缩和重建动态网格序列，同时保留局部拓扑结构。此外，采用了基于Rectified Flow的训练策略，以实现高质量的文本条件生成。还贡献了包含超过400万个不同动态网格序列的DyMesh数据集。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法能够在几秒钟内生成语义准确且时间上连贯的网格动画，在质量和效率上显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;这项工作在使4D内容创作更加易于访问和实用方面迈出了重要一步。所有数据、代码和模型都将公开发布。&lt;h4&gt;翻译&lt;/h4&gt;摘要：最近在4D内容生成方面的进步引起了越来越多的关注，然而由于建模时空分布的复杂性以及4D训练数据的稀缺，创建高质量的动画3D模型仍然具有挑战性。在本文中，我们提出了AnimateAnyMesh，这是第一个能够实现任意三维网格高效文本驱动动画的前馈框架。我们的方法利用了新的DyMeshVAE架构，该架构通过分离空间和时间特征，同时保留局部拓扑结构，有效地压缩和重建动态网格序列。为了实现高质量的文本条件生成，我们在压缩的潜在空间中采用了基于Rectified Flow的训练策略。此外，我们贡献了DyMesh数据集，包含超过400万个带有文本注释的多样化动态网格序列。实验结果表明，我们的方法能够在几秒钟内生成语义准确且时间上连贯的网格动画，在质量和效率上显著优于现有方法。我们的工作在使4D内容创作更加易于访问和实用方面迈出了重要一步。所有数据、代码和模型都将公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in 4D content generation have attracted increasing attention,yet creating high-quality animated 3D models remains challenging due to thecomplexity of modeling spatio-temporal distributions and the scarcity of 4Dtraining data. In this paper, we present AnimateAnyMesh, the first feed-forwardframework that enables efficient text-driven animation of arbitrary 3D meshes.Our approach leverages a novel DyMeshVAE architecture that effectivelycompresses and reconstructs dynamic mesh sequences by disentangling spatial andtemporal features while preserving local topological structures. To enablehigh-quality text-conditional generation, we employ a Rectified Flow-basedtraining strategy in the compressed latent space. Additionally, we contributethe DyMesh Dataset, containing over 4M diverse dynamic mesh sequences with textannotations. Experimental results demonstrate that our method generatessemantically accurate and temporally coherent mesh animations in a few seconds,significantly outperforming existing approaches in both quality and efficiency.Our work marks a substantial step forward in making 4D content creation moreaccessible and practical. All the data, code, and models will be open-released.</description>
      <author>example@mail.com (Zijie Wu, Chaohui Yu, Fan Wang, Xiang Bai)</author>
      <guid isPermaLink="false">2506.09982v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>3D-Aware Vision-Language Models Fine-Tuning with Geometric Distillation</title>
      <link>http://arxiv.org/abs/2506.09883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为几何蒸馏的轻量级、无需标注的微调框架，用于增强预训练视觉语言模型对3D空间结构的理解。&lt;h4&gt;背景&lt;/h4&gt;尽管视觉语言模型在视觉和语言任务上表现出色，但在理解3D空间结构方面仍有局限。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，使预训练的视觉语言模型能够更好地理解3D空间结构。&lt;h4&gt;方法&lt;/h4&gt;通过从现成的3D基础模型（如MASt3R、VGGT）中蒸馏出（1）稀疏对应关系、（2）相对深度关系和（3）密集成本体积，将人类启发的几何线索注入预训练的视觉语言模型中，而不改变其架构。&lt;h4&gt;主要发现&lt;/h4&gt;在3D视觉语言推理和3D感知基准测试中，该方法在保持与自然图像-文本输入兼容的同时，显著提高了3D空间推理能力，并降低了计算成本。&lt;h4&gt;结论&lt;/h4&gt;该方法为将2D训练的视觉语言模型与3D理解桥接提供了一个可扩展且高效的方法，为空间基础的多模态任务打开了更广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;Vision-Language Models (VLMs) have shown remarkable performance on diverse visual and linguistic tasks, yet they remain fundamentally limited in their understanding of 3D spatial structures. We propose Geometric Distillation, a lightweight, annotation-free fine-tuning framework that injects human-inspired geometric cues into pretrained VLMs without modifying their architecture. By distilling (1) sparse correspondences, (2) relative depth relations, and (3) dense cost volumes from off-the-shelf 3D foundation models (e.g., MASt3R, VGGT), our method shapes representations to be geometry-aware while remaining compatible with natural image-text inputs. Through extensive evaluations on 3D vision-language reasoning and 3D perception benchmarks, our method consistently outperforms prior approaches, achieving improved 3D spatial reasoning with significantly lower computational cost. Our work demonstrates a scalable and efficient path to bridge 2D-trained VLMs with 3D understanding, opening up wider use in spatially grounded multimodal tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/kaist-cvml/3d-vlm-gd&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Models (VLMs) have shown remarkable performance on diversevisual and linguistic tasks, yet they remain fundamentally limited in theirunderstanding of 3D spatial structures. We propose Geometric Distillation, alightweight, annotation-free fine-tuning framework that injects human-inspiredgeometric cues into pretrained VLMs without modifying their architecture. Bydistilling (1) sparse correspondences, (2) relative depth relations, and (3)dense cost volumes from off-the-shelf 3D foundation models (e.g., MASt3R,VGGT), our method shapes representations to be geometry-aware while remainingcompatible with natural image-text inputs. Through extensive evaluations on 3Dvision-language reasoning and 3D perception benchmarks, our method consistentlyoutperforms prior approaches, achieving improved 3D spatial reasoning withsignificantly lower computational cost. Our work demonstrates a scalable andefficient path to bridge 2D-trained VLMs with 3D understanding, opening upwider use in spatially grounded multimodal tasks.</description>
      <author>example@mail.com (Seonho Lee, Jiho Choi, Inha Kang, Jiwook Kim, Junsung Park, Hyunjung Shim)</author>
      <guid isPermaLink="false">2506.09883v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Learnable Spatial-Temporal Positional Encoding for Link Prediction</title>
      <link>http://arxiv.org/abs/2506.08309v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML 2025. 28 pages, 1 figures, 22 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为L-STEP的简单时间链接预测模型，旨在有效且高效地开发可学习的时空位置编码。&lt;h4&gt;背景&lt;/h4&gt;当前的位置编码在三个方面的局限性：预定义的固定函数、仅限于结构信息、以及在大规模结构数据上的注意力机制。&lt;h4&gt;目的&lt;/h4&gt;开发一种可学习的时空位置编码，并构建一个名为L-STEP的简单时间链接预测模型。&lt;h4&gt;方法&lt;/h4&gt;L-STEP模型通过以下方法实现：1）证明所提出的位置学习方案可以从时空光谱视角保持图属性；2）验证MLPs可以充分利用表达力和达到该编码上的Transformer性能；3）改变不同的初始位置编码输入以展示鲁棒性；4）分析理论复杂度并获得比SOTA更少的经验运行时间；5）在13个经典数据集上以及10种算法在有向和无向设置中使用3种不同的采样策略展示其时间链接预测的优越性。&lt;h4&gt;主要发现&lt;/h4&gt;L-STEP在最新的大规模TGB基准测试中取得了领先性能，并在13个经典数据集上以及10种算法在两种设置中使用三种不同的采样策略展示了其时间链接预测的优越性。&lt;h4&gt;结论&lt;/h4&gt;L-STEP模型通过其有效和高效的时空位置编码方法，在时间链接预测任务中取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;Accurate predictions rely on the expressiveness power of graph deep learning frameworks like graph neural networks and graph transformers, where positional encoding mechanism has become much more indispensable in recent state-of-the-art works to record the canonical position information. However, the current positional encoding is limited in three aspects: (1) most positional encoding methods use pre-defined, and fixed functions, which are inadequate to adapt to the complex attributed graphs; (2) a few pioneering works proposed the learnable positional encoding but are still limited to the structural information, not considering the real-world time-evolving topological and feature information; (3) most positional encoding methods are equipped with transformers' attention mechanism to fully leverage their capabilities, where the dense or relational attention is often unaffordable on large-scale structured data. Hence, we aim to develop Learnable Spatial-Temporal Positional Encoding in an effective and efficient manner and propose a simple temporal link prediction model named L-STEP. Briefly, for L-STEP, we (1) prove the proposed positional learning scheme can preserve the graph property from the spatial-temporal spectral viewpoint, (2) verify that MLPs can fully exploit the expressiveness and reach transformers' performance on that encoding, (3) change different initial positional encoding inputs to show robustness, (4) analyze the theoretical complexity and obtain less empirical running time than SOTA, and (5) demonstrate its temporal link prediction out-performance on 13 classic datasets and with 10 algorithms in both transductive and inductive settings using 3 different sampling strategies. Also, L-STEP obtains the leading performance in the newest large-scale TGB benchmark. Our code is available at https://github.com/kthrn22/L-STEP.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate predictions rely on the expressiveness power of graph deep learningframeworks like graph neural networks and graph transformers, where apositional encoding mechanism has become much more indispensable in recentstate-of-the-art works to record the canonical position information. However,the current positional encoding is limited in three aspects: (1) mostpositional encoding methods use pre-defined, and fixed functions, which areinadequate to adapt to the complex attributed graphs; (2) a few pioneeringworks proposed the learnable positional encoding but are still limited to thestructural information, not considering the real-world time-evolvingtopological and feature information; (3) most positional encoding methods areequipped with transformers' attention mechanism to fully leverage theircapabilities, where the dense or relational attention is often unaffordable onlarge-scale structured data. Hence, we aim to develop LearnableSpatial-Temporal Positional Encoding in an effective and efficient manner andpropose a simple temporal link prediction model named L-STEP. Briefly, forL-STEP, we (1) prove the proposed positional learning scheme can preserve thegraph property from the spatial-temporal spectral viewpoint, (2) verify thatMLPs can fully exploit the expressiveness and reach transformers' performanceon that encoding, (3) change different initial positional encoding inputs toshow robustness, (4) analyze the theoretical complexity and obtain lessempirical running time than SOTA, and (5) demonstrate its temporal linkprediction out-performance on 13 classic datasets and with 10 algorithms inboth transductive and inductive settings using 3 different sampling strategies.Also, L-STEP obtains the leading performance in the newest large-scale TGBbenchmark. Our code is available at https://github.com/kthrn22/L-STEP.</description>
      <author>example@mail.com (Katherine Tieu, Dongqi Fu, Zihao Li, Ross Maciejewski, Jingrui He)</author>
      <guid isPermaLink="false">2506.08309v2</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Depth and Language for Open-Vocabulary Domain-Generalized Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2506.09881v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为Vireo的新型单阶段框架，用于开放词汇域通用语义分割（OV-DGSS），旨在生成未见类别的像素级掩码，同时在未见领域保持鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;Open-Vocabulary semantic segmentation (OVSS)和domain generalization in semantic segmentation (DGSS)之间存在微妙的互补性，这促使研究者提出Open-Vocabulary Domain-Generalized Semantic Segmentation (OV-DGSS)。&lt;h4&gt;目的&lt;/h4&gt;OV-DGSS旨在在保持对未见领域鲁棒性的同时，生成未见类别的像素级掩码，这对于现实世界场景，如恶劣条件下的自动驾驶至关重要。&lt;h4&gt;方法&lt;/h4&gt;Vireo框架基于冻结的视觉基础模型（VFMs），并通过深度VFMs纳入场景几何来提取域不变的结构特征。为了弥合视觉和文本模态在领域变化下的差距，提出了三个关键组件：GeoText Prompts、Coarse Mask Prior Embedding (CMPE)和Domain-Open-Vocabulary Vector EmbeddingHead (DOV-VEH)。&lt;h4&gt;主要发现&lt;/h4&gt;综合评估表明，Vireo在域泛化和开放词汇识别方面均取得了最先进的性能，并显著超越了现有方法。&lt;h4&gt;结论&lt;/h4&gt;Vireo提供了一个统一且可扩展的解决方案，以实现多样化和动态环境中的鲁棒视觉理解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：开放词汇语义分割（OVSS）和领域泛化语义分割（DGSS）之间存在着微妙的互补性，这促使提出开放词汇域通用语义分割（OV-DGSS）。OV-DGSS旨在为未见类别生成像素级掩码，同时在未见领域保持鲁棒性，这对于现实世界场景，如恶劣条件下的自动驾驶等至关重要。我们引入了Vireo，这是一个针对OV-DGSS的全新单阶段框架，首次统一了OVSS和DGSS的优势。Vireo基于冻结的视觉基础模型（VFMs），并利用深度VFMs纳入场景几何来提取域不变的结构特征。为了弥合视觉和文本模态在领域变化下的差距，我们提出了三个关键组件：GeoText提示，将几何特征与语言线索对齐并逐步优化VFM编码器表示；粗掩码先验嵌入（CMPE），用于增强梯度流以实现更快的收敛和更强的文本影响；以及域开放词汇向量嵌入头（DOV-VEH），用于融合优化后的结构和语义特征以实现鲁棒的预测。对这些组件的综合评估表明了我们的设计有效性。我们提出的Vireo在域泛化和开放词汇识别方面均达到了最先进的性能，并显著超越了现有方法，为多样化和动态环境中的鲁棒视觉理解提供了一个统一且可扩展的解决方案。代码可在https://github.com/anonymouse-9c53tp182bvz/Vireo找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-Vocabulary semantic segmentation (OVSS) and domain generalization insemantic segmentation (DGSS) highlight a subtle complementarity that motivatesOpen-Vocabulary Domain-Generalized Semantic Segmentation (OV-DGSS). OV-DGSSaims to generate pixel-level masks for unseen categories while maintainingrobustness across unseen domains, a critical capability for real-worldscenarios such as autonomous driving in adverse conditions. We introduce Vireo,a novel single-stage framework for OV-DGSS that unifies the strengths of OVSSand DGSS for the first time. Vireo builds upon the frozen Visual FoundationModels (VFMs) and incorporates scene geometry via Depth VFMs to extractdomain-invariant structural features. To bridge the gap between visual andtextual modalities under domain shift, we propose three key components: (1)GeoText Prompts, which align geometric features with language cues andprogressively refine VFM encoder representations; (2) Coarse Mask PriorEmbedding (CMPE) for enhancing gradient flow for faster convergence andstronger textual influence; and (3) the Domain-Open-Vocabulary Vector EmbeddingHead (DOV-VEH), which fuses refined structural and semantic features for robustprediction. Comprehensive evaluation on these components demonstrates theeffectiveness of our designs. Our proposed Vireo achieves the state-of-the-artperformance and surpasses existing methods by a large margin in both domaingeneralization and open-vocabulary recognition, offering a unified and scalablesolution for robust visual understanding in diverse and dynamic environments.Code is available at https://github.com/anonymouse-9c53tp182bvz/Vireo.</description>
      <author>example@mail.com (Siyu Chen, Ting Han, Chengzheng Fu, Changshe Zhang, Chaolei Wang, Jinhe Su, Guorong Cai, Meiliu Wu)</author>
      <guid isPermaLink="false">2506.09881v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model-Aided Deep Reinforcement Learning for RIS-Assisted Wireless Communication</title>
      <link>http://arxiv.org/abs/2506.09855v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures, PIMRC conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用预训练开源基础模型LWM处理无线信道并生成多用途和上下文相关信道嵌入的方法，用于联合优化基站波束成形和可重构智能表面配置，以提高无线通信的频谱效率。&lt;h4&gt;背景&lt;/h4&gt;可重构智能表面（RIS）通过动态控制信号传播在环境中，是一种增强无线通信的潜在技术。然而，由于其被动的本质和大量反射元件，其有效部署依赖于准确的信道状态信息（CSI），导致信道估计开销很高。&lt;h4&gt;目的&lt;/h4&gt;解决RIS部署中的信道估计开销问题，提高无线通信的频谱效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的框架，该框架利用预训练的开放源代码基础模型（FM）LWM处理无线信道，生成信道嵌入。设计了一个深度强化学习（DRL）模型，自动选择基站波束成形向量和RIS相移矩阵，以最大化频谱效率（SE）。&lt;h4&gt;主要发现&lt;/h4&gt;预训练FM在无线电信号理解方面可以被微调和集成到DRL中，以在无线网络中进行有效的决策。模态特定FM在现实世界网络优化中具有潜力。与基于DRL的方法和基于波束扫描的方法相比，所提出的方法在频谱效率方面表现更优，分别提高了9.89%和43.66%。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法通过预训练FM和DRL的结合，有效提高了无线通信的频谱效率，证明了模态特定FM在现实世界网络优化中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconfigurable intelligent surfaces (RIS) have emerged as a promisingtechnology for enhancing wireless communication by dynamically controllingsignal propagation in the environment. However, their efficient deploymentrelies on accurate channel state information (CSI), which leads to high channelestimation overhead due to their passive nature and the large number ofreflective elements. In this work, we solve this challenge by proposing a novelframework that leverages a pre-trained open-source foundation model (FM) namedlarge wireless model (LWM) to process wireless channels and generate versatileand contextualized channel embeddings. These embeddings are then used for thejoint optimization of the BS beamforming and RIS configurations. To be morespecific, for joint optimization, we design a deep reinforcement learning (DRL)model to automatically select the BS beamforming vector and RIS phase-shiftmatrix, aiming to maximize the spectral efficiency (SE). This work shows that apre-trained FM for radio signal understanding can be fine-tuned and integratedwith DRL for effective decision-making in wireless networks. It highlights thepotential of modality-specific FMs in real-world network optimization.According to the simulation results, the proposed method outperforms theDRL-based approach and beam sweeping-based approach, achieving 9.89% and 43.66%higher SE, respectively.</description>
      <author>example@mail.com (Mohammad Ghassemi, Sara Farrag Mobarak, Han Zhang, Ali Afana, Akram Bin Sediq, Melike Erol-Kantarci)</author>
      <guid isPermaLink="false">2506.09855v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Accurate and efficient zero-shot 6D pose estimation with frozen foundation models</title>
      <link>http://arxiv.org/abs/2506.09784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FreeZeV2是一种无需训练的方法，通过利用几何和视觉基础模型在无关数据上的预训练，实现了对未见对象的强大泛化能力。&lt;h4&gt;背景&lt;/h4&gt;从RGBD数据估计对象的6D姿态是计算机视觉中的一个基本问题，在机器人和增强现实等领域有应用。&lt;h4&gt;目的&lt;/h4&gt;探究是否需要针对特定任务的训练来实现对未见对象的准确和高效的6D姿态估计。&lt;h4&gt;方法&lt;/h4&gt;FreeZeV2通过三个关键贡献来提升性能：(i)一种稀疏特征提取策略，在不牺牲精度的前提下减少推理时间计算；(ii)一种特征感知的评分机制，改进基于RANSAC的3D注册过程中的姿态选择和姿态候选者的最终排名；(iii)一种模块化设计，支持实例分割模型的集成，增加对分割掩码错误的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;FreeZeV2在BOP基准测试的七个核心数据集上进行了评估，在未见对象的6D姿态估计中建立了新的最先进水平。使用相同的分割掩码时，FreeZeV2比FreeZe快8倍，同时精度提高了5%。使用分割模型集成时，FreeZeV2在速度比FreeZe快2.5倍的同时，精度提高了8%。&lt;h4&gt;结论&lt;/h4&gt;FreeZeV2在BOP挑战2024中被授予最佳整体方法奖。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Estimating the 6D pose of objects from RGBD data is a fundamental problem incomputer vision, with applications in robotics and augmented reality. A keychallenge is achieving generalization to novel objects that were not seenduring training. Most existing approaches address this by scaling up trainingon synthetic data tailored to the task, a process that demands substantialcomputational resources. But is task-specific training really necessary foraccurate and efficient 6D pose estimation of novel objects? To answer No!, weintroduce FreeZeV2, the second generation of FreeZe: a training-free methodthat achieves strong generalization to unseen objects by leveraging geometricand vision foundation models pre-trained on unrelated data. FreeZeV2 improvesboth accuracy and efficiency over FreeZe through three key contributions: (i) asparse feature extraction strategy that reduces inference-time computationwithout sacrificing accuracy; (ii) a feature-aware scoring mechanism thatimproves both pose selection during RANSAC-based 3D registration and the finalranking of pose candidates; and (iii) a modular design that supports ensemblesof instance segmentation models, increasing robustness to segmentation maskserrors. We evaluate FreeZeV2 on the seven core datasets of the BOP Benchmark,where it establishes a new state-of-the-art in 6D pose estimation of unseenobjects. When using the same segmentation masks, FreeZeV2 achieves a remarkable8x speedup over FreeZe while also improving accuracy by 5%. When usingensembles of segmentation models, FreeZeV2 gains an additional 8% in accuracywhile still running 2.5x faster than FreeZe. FreeZeV2 was awarded Best OverallMethod at the BOP Challenge 2024.</description>
      <author>example@mail.com (Andrea Caraffa, Davide Boscaini, Fabio Poiesi)</author>
      <guid isPermaLink="false">2506.09784v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Intelligent Design 4.0: Paradigm Evolution Toward the Agentic AI Era</title>
      <link>http://arxiv.org/abs/2506.09755v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了智能设计（ID）的发展历程及其在工程创新、效率、质量和生产力方面的提升，介绍了基于智能体AI系统的智能设计4.0（ID 4.0）新范式，并探讨了其未来发展方向。&lt;h4&gt;背景&lt;/h4&gt;智能设计（ID）在近年来对工程领域产生了深远影响，而新型的大型语言模型（LLMs）等基础模型（FMs）的兴起为工程设计的进一步变革提供了新的路径。&lt;h4&gt;目的&lt;/h4&gt;提出智能设计4.0（ID 4.0）这一新范式，并探讨其如何通过协调、自主的多智能体系统支持工程设计的端到端自动化。&lt;h4&gt;方法&lt;/h4&gt;回顾了ID的历史演变，分为四个阶段：基于规则的专家系统、特定任务的机器学习模型、大规模基础AI模型以及最近出现的多智能体协作范式。&lt;h4&gt;主要发现&lt;/h4&gt;提出了ID 4.0的概念框架，并讨论了其在支持复杂设计场景、实际设计实现、新型智能体协调机制以及与人类价值观相一致的设计目标设定方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;这些发现为推动智能设计向更高适应性、自主性和有效性发展，以应对日益复杂的设计挑战奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在过去的几十年中，智能设计（ID）的研究与实践显著提升了工程创新、效率、质量和生产力，从根本上改变了工程设计师的思维、行为以及与设计过程互动的方式。近期新兴的基础模型（FMs），特别是大型语言模型（LLMs），展现了基于通用知识的推理能力，为工程设计的进一步变革开辟了新的途径。在此背景下，本文介绍了由智能体AI系统赋能的智能设计4.0（ID 4.0）这一新兴范式。我们回顾了ID在四个不同阶段的演变：基于规则的专家系统、特定任务的机器学习模型、大规模基础AI模型以及最近出现的多智能体协作范式。我们提出了ID 4.0的概念框架，并讨论了其通过协调、自主的多智能体系统支持工程设计端到端自动化的潜力。此外，我们讨论了提升和完全实现ID 4.0潜力的未来展望，包括更复杂的设计场景、更实际的设计实现、新型的智能体协调机制以及与人类价值观更好地对齐的自主设计目标设定。总之，这些见解为推动智能设计向更高适应性、自主性和有效性发展，以应对日益复杂的设计挑战奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Research and practice in Intelligent Design (ID) have significantly enhancedengineering innovation, efficiency, quality, and productivity over recentdecades, fundamentally reshaping how engineering designers think, behave, andinteract with design processes. The recent emergence of Foundation Models(FMs), particularly Large Language Models (LLMs), has demonstrated generalknowledge-based reasoning capabilities, and open new paths and avenues forfurther transformation in engineering design. In this context, this paperintroduces Intelligent Design 4.0 (ID 4.0) as an emerging paradigm empowered byagentic AI systems. We review the historical evolution of ID across fourdistinct stages: rule-based expert systems, task-specific machine learningmodels, large-scale foundation AI models, and the recent emerging paradigm ofmulti-agent collaboration. We propose a conceptual framework for ID 4.0 anddiscuss its potential to support end-to-end automation of engineering designprocesses through coordinated, autonomous multi-agent-based systems.Furthermore, we discuss future perspectives to enhance and fully realize ID4.0's potential, including more complex design scenarios, more practical designimplementations, novel agent coordination mechanisms, and autonomous designgoal-setting with better human value alignment. In sum, these insights lay afoundation for advancing Intelligent Design toward greater adaptivity,autonomy, and effectiveness in addressing increasingly complex designchallenges.</description>
      <author>example@mail.com (Shuo Jiang, Min Xie, Frank Youhua Chen, Jian Ma, Jianxi Luo)</author>
      <guid isPermaLink="false">2506.09755v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Image Matching for UAV Absolute Visual Localization via Semantic and Structural Constraints</title>
      <link>http://arxiv.org/abs/2506.09748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对无人机绝对定位的分层跨源图像匹配方法，旨在解决GNSS信号不可用时的问题。&lt;h4&gt;背景&lt;/h4&gt;绝对定位对于无人机在各种应用中至关重要，但在GNSS信号不可用时变得具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法依赖传统低级图像匹配的局限性，提高无人机在GNSS拒止环境下的绝对定位精度和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出的方法包括语义感知和结构约束的粗匹配模块以及轻量级细粒度匹配模块，并通过图像检索模块构建无人机绝对视觉定位流程。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在各种挑战条件下具有优越的精度和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该方法在GNSS拒止环境下对无人机绝对定位具有有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Absolute localization, aiming to determine an agent's location with respectto a global reference, is crucial for unmanned aerial vehicles (UAVs) invarious applications, but it becomes challenging when global navigationsatellite system (GNSS) signals are unavailable. Vision-based absolutelocalization methods, which locate the current view of the UAV in a referencesatellite map to estimate its position, have become popular in GNSS-deniedscenarios. However, existing methods mostly rely on traditional and low-levelimage matching, suffering from difficulties due to significant differencesintroduced by cross-source discrepancies and temporal variations. To overcomethese limitations, in this paper, we introduce a hierarchical cross-sourceimage matching method designed for UAV absolute localization, which integratesa semantic-aware and structure-constrained coarse matching module with alightweight fine-grained matching module. Specifically, in the coarse matchingmodule, semantic features derived from a vision foundation model firstestablish region-level correspondences under semantic and structuralconstraints. Then, the fine-grained matching module is applied to extract finefeatures and establish pixel-level correspondences. Building upon this, a UAVabsolute visual localization pipeline is constructed without any reliance onrelative localization techniques, mainly by employing an image retrieval modulebefore the proposed hierarchical image matching modules. Experimentalevaluations on public benchmark datasets and a newly introduced CS-UAV datasetdemonstrate superior accuracy and robustness of the proposed method undervarious challenging conditions, confirming its effectiveness.</description>
      <author>example@mail.com (Xiangkai Zhang, Xiang Zhou, Mao Chen, Yuchen Lu, Xu Yang, Zhiyong Liu)</author>
      <guid isPermaLink="false">2506.09748v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>FedVLMBench: Benchmarking Federated Fine-Tuning of Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.09638v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了FedVLMBench，这是第一个用于VLM联邦微调的系统基准。&lt;h4&gt;背景&lt;/h4&gt;VLM在跨模态理解和生成方面表现出色，但现有的联邦学习（FL）方法在隐私敏感领域如医疗保健中面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出FedVLMBench，以评估联邦微调策略、模型架构和任务泛化。&lt;h4&gt;方法&lt;/h4&gt;FedVLMBench集成了两种主流VLM架构、四种微调策略、五种FL算法、六个多模态数据集，覆盖四个跨领域单任务场景和两个跨领域多任务设置，包含四个不同的下游任务类别。&lt;h4&gt;主要发现&lt;/h4&gt;发现2层MLP连接器与并发连接器和LLM调整是编码器基于VLM在FL中的最佳配置；当前FL方法在视觉中心任务中对数据异质性的敏感性显著高于文本中心任务，在无编码器和基于编码器的VLM架构中都如此。&lt;h4&gt;结论&lt;/h4&gt;FedVLMBench为研究社区提供了工具、数据集和经验指导，为多模态基础模型的隐私保护联邦训练提供了一个标准化平台。&lt;h4&gt;翻译&lt;/h4&gt;Vision-Language Models (VLMs) have demonstrated remarkable capabilities in cross-modal understanding and generation by integrating visual and textual information. While instruction tuning and parameter-efficient fine-tuning methods have substantially improved the generalization of VLMs, most existing approaches rely on centralized training, posing challenges for deployment in domains with strict privacy requirements like healthcare. Recent efforts have introduced Federated Learning (FL) into VLM fine-tuning to address these privacy concerns, yet comprehensive benchmarks for evaluating federated fine-tuning strategies, model architectures, and task generalization remain lacking. In this work, we present extbf{FedVLMBench}, the first systematic benchmark for federated fine-tuning of VLMs. FedVLMBench integrates two mainstream VLM architectures (encoder-based and encoder-free), four fine-tuning strategies, five FL algorithms, six multimodal datasets spanning four cross-domain single-task scenarios and two cross-domain multitask settings, covering four distinct downstream task categories. Through extensive experiments, we uncover key insights into the interplay between VLM architectures, fine-tuning strategies, data heterogeneity, and multi-task federated optimization. Notably, we find that a 2-layer multilayer perceptron (MLP) connector with concurrent connector and LLM tuning emerges as the optimal configuration for encoder-based VLMs in FL. Furthermore, current FL methods exhibit significantly higher sensitivity to data heterogeneity in vision-centric tasks than text-centric ones, across both encoder-free and encoder-based VLM architectures. Our benchmark provides essential tools, datasets, and empirical guidance for the research community, offering a standardized platform to advance privacy-preserving, federated training of multimodal foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Models (VLMs) have demonstrated remarkable capabilities incross-modal understanding and generation by integrating visual and textualinformation. While instruction tuning and parameter-efficient fine-tuningmethods have substantially improved the generalization of VLMs, most existingapproaches rely on centralized training, posing challenges for deployment indomains with strict privacy requirements like healthcare. Recent efforts haveintroduced Federated Learning (FL) into VLM fine-tuning to address theseprivacy concerns, yet comprehensive benchmarks for evaluating federatedfine-tuning strategies, model architectures, and task generalization remainlacking. In this work, we present \textbf{FedVLMBench}, the first systematicbenchmark for federated fine-tuning of VLMs. FedVLMBench integrates twomainstream VLM architectures (encoder-based and encoder-free), four fine-tuningstrategies, five FL algorithms, six multimodal datasets spanning fourcross-domain single-task scenarios and two cross-domain multitask settings,covering four distinct downstream task categories. Through extensiveexperiments, we uncover key insights into the interplay between VLMarchitectures, fine-tuning strategies, data heterogeneity, and multi-taskfederated optimization. Notably, we find that a 2-layer multilayer perceptron(MLP) connector with concurrent connector and LLM tuning emerges as the optimalconfiguration for encoder-based VLMs in FL. Furthermore, current FL methodsexhibit significantly higher sensitivity to data heterogeneity invision-centric tasks than text-centric ones, across both encoder-free andencoder-based VLM architectures. Our benchmark provides essential tools,datasets, and empirical guidance for the research community, offering astandardized platform to advance privacy-preserving, federated training ofmultimodal foundation models.</description>
      <author>example@mail.com (Weiying Zheng, Ziyue Lin, Pengxin Guo, Yuyin Zhou, Feifei Wang, Liangqiong Qu)</author>
      <guid isPermaLink="false">2506.09638v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Analytic Task Scheduler: Recursive Least Squares Based Method for Continual Learning in Embodied Foundation Models</title>
      <link>http://arxiv.org/abs/2506.09623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ATS的框架，用于解决具身基础模型在持续学习过程中遇到的重学问题。&lt;h4&gt;背景&lt;/h4&gt;具身基础模型在整合多模态输入理解人类意图和控制机器人方面至关重要，但它们在持续学习新技能时容易忘记之前学到的技能。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，本文旨在提出一种新的框架，以实现具身基础模型的持续学习。&lt;h4&gt;方法&lt;/h4&gt;ATS框架包括一个特定任务的模型库和一个使用递归最小二乘法（RLS）训练的解析调度器。模型库中的每个模型独立地对单个任务进行微调，调度器学习语言指令与特定任务模型之间的映射。&lt;h4&gt;主要发现&lt;/h4&gt;ATS框架能够准确识别任务并动态选择模型，同时避免了任务间的参数干扰。调度器通过仅使用统计数据（自相关矩阵和互相关矩阵）逐步更新其参数，实现了抵抗遗忘的学习，无需回顾历史数据。&lt;h4&gt;结论&lt;/h4&gt;在真实世界机器人平台上的验证表明，ATS具有优异的抵抗遗忘能力和对任务变化的强适应性，是复杂动态环境中具身基础模型持续学习的一个有效、可扩展且可部署的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Embodied foundation models are crucial for Artificial Intelligence (AI) interacting with the physical world by integrating multi-modal inputs, such as proprioception, vision and language, to understand human intentions and generate actions to control robots. While these models demonstrate strong generalization and few-shot learning capabilities, they face significant challenges in continually acquiring new skills without forgetting previously learned skills, a problem known as catastrophic forgetting. To address this issue, we propose the Analytic Task Scheduler (ATS), a novel framework for continual learning in embodied foundation models. ATS consists of a task-specific model library, where each model is fine-tuned independently on a single task, and an analytic scheduler trained using recursive least squares (RLS) to learn the mapping between language instructions and task-specific models. This architecture enables accurate task recognition and dynamic model selection while fundamentally avoiding parameter interference across tasks. The scheduler updates its parameters incrementally using only statistics (autocorrelation and cross-correlation matrices), enabling forgetting-resistant learning without the need to revisit historical data. We validate ATS on a real-world robot platform (RM65B), demonstrating superior resistance to forgetting and strong adaptability to task variations. The results highlight ATS as an effective, scalable, and deployable solution for continual learning in embodied foundation models operating in complex, dynamic environments. Our code will be available at https://github.com/MIAA-Embodied-AI/AnalyticTaskScheduler&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Embodied foundation models are crucial for Artificial Intelligence (AI)interacting with the physical world by integrating multi-modal inputs, such asproprioception, vision and language, to understand human intentions andgenerate actions to control robots. While these models demonstrate stronggeneralization and few-shot learning capabilities, they face significantchallenges in continually acquiring new skills without forgetting previouslylearned skills, a problem known as catastrophic forgetting. To address thisissue, we propose the Analytic Task Scheduler (ATS), a novel framework forcontinual learning in embodied foundation models. ATS consists of atask-specific model library, where each model is fine-tuned independently on asingle task, and an analytic scheduler trained using recursive least squares(RLS) to learn the mapping between language instructions and task-specificmodels. This architecture enables accurate task recognition and dynamic modelselection while fundamentally avoiding parameter interference across tasks. Thescheduler updates its parameters incrementally using only statistics(autocorrelation and cross-correlation matrices), enabling forgetting-resistantlearning without the need to revisit historical data. We validate ATS on areal-world robot platform (RM65B), demonstrating superior resistance toforgetting and strong adaptability to task variations. The results highlightATS as an effective, scalable, and deployable solution for continual learningin embodied foundation models operating in complex, dynamic environments. Ourcode will be available athttps://github.com/MIAA-Embodied-AI/AnalyticTaskScheduler</description>
      <author>example@mail.com (Lipei Xie, Yingxin Li, Huiping Zhuang)</author>
      <guid isPermaLink="false">2506.09623v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Image Transforms derived from Eye Gaze Variables for Progressive Autism Diagnosis</title>
      <link>http://arxiv.org/abs/2506.09065v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 8 figures, and 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于人工智能的辅助技术，用于简化自闭症谱系障碍（ASD）的诊断和管理，旨在提高ASD患者的便利性和照顾者、治疗师的工作效率。&lt;h4&gt;背景&lt;/h4&gt;过去十年中，自闭症谱系障碍的发病率迅速上升，给受影响个体的沟通、行为和注意力带来了重大挑战。现有的诊断技术虽然有效，但耗时较长，导致社会和经济成本高昂。&lt;h4&gt;目的&lt;/h4&gt;该技术旨在提高ASD诊断的便利性，同时提高照顾者和治疗师的工作效率。&lt;h4&gt;方法&lt;/h4&gt;该系统通过结合迁移学习和基于眼动变量的图像转换来诊断ASD，从而实现家庭定期诊断，减少个体和照顾者的压力，并通过图像转换保护用户隐私。&lt;h4&gt;主要发现&lt;/h4&gt;该方法的易用性为监护人和治疗师之间的沟通提供了机会，确保了对进展和不断变化的支持需求的定期更新。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法确保了及时、便捷的诊断，同时保护了受试者的隐私，改善了自闭症患者的治疗效果。&lt;h4&gt;翻译&lt;/h4&gt;The prevalence of Autism Spectrum Disorder (ASD) has surged rapidly over thepast decade, posing significant challenges in communication, behavior, andfocus for affected individuals. Current diagnostic techniques, thougheffective, are time-intensive, leading to high social and economic costs. Thiswork introduces an AI-powered assistive technology designed to streamline ASDdiagnosis and management, enhancing convenience for individuals with ASD andefficiency for caregivers and therapists. The system integrates transferlearning with image transforms derived from eye gaze variables to diagnose ASD.This facilitates and opens opportunities for in-home periodical diagnosis, reducingstress for individuals and caregivers, while also preserving user privacy throughthe use of image transforms. The accessibility of the proposed method also offersopportunities for improved communication between guardians and therapists, ensuringregular updates on progress and evolving support needs. Overall, the approachproposed in this work ensures timely, accessible diagnosis while protecting thesubjects' privacy, improving outcomes for individuals with ASD.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The prevalence of Autism Spectrum Disorder (ASD) has surged rapidly over thepast decade, posing significant challenges in communication, behavior, andfocus for affected individuals. Current diagnostic techniques, thougheffective, are time-intensive, leading to high social and economic costs. Thiswork introduces an AI-powered assistive technology designed to streamline ASDdiagnosis and management, enhancing convenience for individuals with ASD andefficiency for caregivers and therapists. The system integrates transferlearning with image transforms derived from eye gaze variables to diagnose ASD.This facilitates and opens opportunities for in-home periodical diagnosis,reducing stress for individuals and caregivers, while also preserving userprivacy through the use of image transforms. The accessibility of the proposedmethod also offers opportunities for improved communication between guardiansand therapists, ensuring regular updates on progress and evolving supportneeds. Overall, the approach proposed in this work ensures timely, accessiblediagnosis while protecting the subjects' privacy, improving outcomes forindividuals with ASD.</description>
      <author>example@mail.com (Abigail Copiaco, Christian Ritz, Yassine Himeur, Valsamma Eapen, Ammar Albanna, Wathiq Mansoor)</author>
      <guid isPermaLink="false">2506.09065v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Overconfidence: Foundation Models Redefine Calibration in Deep Neural Networks</title>
      <link>http://arxiv.org/abs/2506.09593v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文全面研究了基础模型的校准行为，揭示了挑战传统观念的见解。&lt;h4&gt;背景&lt;/h4&gt;深度神经网络在高度依赖的应用中需要可靠的校准，以避免系统性过度自信，尤其是在分布变化的情况下。&lt;h4&gt;目的&lt;/h4&gt;探索基础模型在预测性能上的校准特性。&lt;h4&gt;方法&lt;/h4&gt;进行了实证分析，研究了模型在分布内部预测中的信心水平，以及它们对后置校准技术的响应。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型在分布内部预测中往往表现出信心不足，导致更高的校准误差，但在分布变化下校准有所改善。后置校准技术能有效地减轻信心不足的偏差，但在严重的分布变化下，这些方法变得不可靠，有时甚至会产生相反的效果。&lt;h4&gt;结论&lt;/h4&gt;基础模型的校准受到架构和训练创新的非单调影响，挑战了持续改进的传统说法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable uncertainty calibration is essential for safely deploying deepneural networks in high-stakes applications. Deep neural networks are known toexhibit systematic overconfidence, especially under distribution shifts.Although foundation models such as ConvNeXt, EVA and BEiT have demonstratedsignificant improvements in predictive performance, their calibrationproperties remain underexplored. This paper presents a comprehensiveinvestigation into the calibration behavior of foundation models, revealinginsights that challenge established paradigms. Our empirical analysis showsthat these models tend to be underconfident in in-distribution predictions,resulting in higher calibration errors, while demonstrating improvedcalibration under distribution shifts. Furthermore, we demonstrate thatfoundation models are highly responsive to post-hoc calibration techniques inthe in-distribution setting, enabling practitioners to effectively mitigateunderconfidence bias. However, these methods become progressively less reliableunder severe distribution shifts and can occasionally produce counterproductiveresults. Our findings highlight the complex, non-monotonic effects ofarchitectural and training innovations on calibration, challenging establishednarratives of continuous improvement.</description>
      <author>example@mail.com (Achim Hekler, Lukas Kuhn, Florian Buettner)</author>
      <guid isPermaLink="false">2506.09593v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>From Partial to Monadic: Combinatory Algebra with Effects</title>
      <link>http://arxiv.org/abs/2506.09453v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了单调组合代数（MCAs）的概念，这是一种比部分组合代数（PCAs）更广泛计算效应的框架，并探讨了其在可计算性理论中的应用。&lt;h4&gt;背景&lt;/h4&gt;部分组合代数（PCAs）是未类型化λ演算的基础模型，也是实现论等可计算性概念的基础。然而，PCAs只通过非终止性作为计算效应，支持的计算概念非常有限。&lt;h4&gt;目的&lt;/h4&gt;为了更好地内化更广泛的计算效应，本文提出了单调组合代数（MCAs），并希望提供一个更强大的框架来推理效应丰富的计算。&lt;h4&gt;方法&lt;/h4&gt;MCAs通过在底层计算效应（由单子表示）上结构化组合代数来推广PCAs的概念。本文展示了MCAs可以通过底层单子支持各种副作用，如非确定性、状态计算和延续。此外，本文在Freyd范畴内对MCAs进行了范畴学描述，并探讨了其在实现论中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;MCAs可以支持通过底层单子实现的多种副作用，如非确定性、状态计算和延续。在Freyd范畴内，MCAs具有范畴学描述，且在实现论中，通过证据框架构建了有效的实现三重积和组装，从而推广了基于PCAs的传统实现语义。&lt;h4&gt;结论&lt;/h4&gt;单调组合代数（MCAs）为内部推理效应丰富的计算提供了一个全面而强大的框架，为更广泛的研究计算及其与实现模型和编程语言的关系铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为单调组合代数（MCAs）的概念，它是一种比部分组合代数（PCAs）更广泛计算效应的框架，并探讨了其在可计算性理论中的应用。部分组合代数（PCAs）是未类型化λ演算的基础模型，也是实现论等可计算性概念的基础。然而，PCAs只通过非终止性作为计算效应，支持的计算概念非常有限。为了更好地内化更广泛的计算效应，本文提出了单调组合代数（MCAs），并希望提供一个更强大的框架来推理效应丰富的计算。单调组合代数（MCAs）通过在底层计算效应（由单子表示）上结构化组合代数来推广部分组合代数（PCAs）的概念。本文展示了单调组合代数（MCAs）可以通过底层单子支持各种副作用，如非确定性、状态计算和延续。此外，本文在Freyd范畴内对单调组合代数（MCAs）进行了范畴学描述，并探讨了其在实现论中的应用。在Freyd范畴内，单调组合代数（MCAs）具有范畴学描述，且在实现论中，通过证据框架构建了有效的实现三重积和组装，从而推广了基于部分组合代数（PCAs）的传统实现语义。单调组合代数（MCAs）为内部推理效应丰富的计算提供了一个全面而强大的框架，为更广泛的研究计算及其与实现模型和编程语言的关系铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Partial Combinatory Algebras (PCAs) provide a foundational model of theuntyped $\lambda$-calculus and serve as the basis for many notions ofcomputability, such as realizability theory. However, PCAs support a verylimited notion of computation by only incorporating non-termination as acomputational effect. To provide a framework that better internalizes a widerange of computational effects, this paper puts forward the notion of MonadicCombinatory Algebras (MCAs). MCAs generalize the notion of PCAs by structuringthe combinatory algebra over an underlying computational effect, embodied by amonad. We show that MCAs can support various side effects through theunderlying monad, such as non-determinism, stateful computation andcontinuations. We further obtain a categorical characterization of MCAs withinFreyd Categories, following a similar connection for PCAs. Moreover, we explorethe application of MCAs in realizability theory, presenting constructions ofeffectful realizability triposes and assemblies derived through evidencedframes, thereby generalizing traditional PCA-based realizability semantics. Themonadic generalization of the foundational notion of PCAs provides acomprehensive and powerful framework for internally reasoning about effectfulcomputations, paving the path to a more encompassing study of computation andits relationship with realizability models and programming languages.</description>
      <author>example@mail.com (Liron Cohen, Ariel Grunfeld, Dominik Kirst, Étienne Miquey)</author>
      <guid isPermaLink="false">2506.09453v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>OWSM-Biasing: Contextualizing Open Whisper-Style Speech Models for Automatic Speech Recognition with Dynamic Vocabulary</title>
      <link>http://arxiv.org/abs/2506.09448v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将现有CB方法与OWSM v3.1结合的方法，通过冻结预训练参数，利用SFMs的知识来有效进行CB，提高了识别准确率。&lt;h4&gt;背景&lt;/h4&gt;尽管SFMs在自动语音识别方面表现出色，但它们在识别罕见和未见词语时仍然存在困难。&lt;h4&gt;目的&lt;/h4&gt;通过结合CB方法和OWSM v3.1，旨在提高对罕见和未见词语的识别准确率。&lt;h4&gt;方法&lt;/h4&gt;在OWSM v3.1的基础上，采用CB方法，同时冻结其预训练参数，以利用SFMs的知识。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法提高了B-WER 11.6个百分点，整体W ER提高了0.9个百分点，同时将实时因素降低了7.5%。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效提高罕见和未见词语的识别准确率，同时保持OWSM v3.1的优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语音基础模型（SFMs），如Open Whisper-Style Speech Models(OWSM)，在大量数据集上进行训练以实现准确的自动语音识别。然而，即使SFMs也难以准确识别罕见和未见词语。尽管上下文偏置（CB）是提高此类词语识别率的有希望的方法，但大多数CB方法都是从头开始训练的，由于缺乏预训练知识，其性能低于SFMs。本文将一个现有的CB方法与OWSM v3.1结合，同时冻结其预训练参数。通过利用SFMs中嵌入的知识，该方法能够有效地进行CB，同时保持SFMs的优势，即使是在小数据集上。实验结果表明，该方法将偏置词语错误率（B-WER）提高了11.6个百分点，相对于非偏置基线，在LibriSpeech 100测试集上使整体W ER提高了0.9个百分点，同时将实时因素降低了7.5%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech foundation models (SFMs), such as Open Whisper-Style Speech Models(OWSM), are trained on massive datasets to achieve accurate automatic speechrecognition. However, even SFMs struggle to accurately recognize rare andunseen words. While contextual biasing (CB) is a promising approach to improverecognition of such words, most CB methods are trained from scratch, resultingin lower performance than SFMs due to the lack of pre-trained knowledge. Thispaper integrates an existing CB method with OWSM v3.1 while freezing itspre-trained parameters. By leveraging the knowledge embedded in SFMs, theproposed method enables effective CB while preserving the advantages of SFMs,even with a small dataset. Experimental results show that the proposed methodimproves the biasing word error rate (B-WER) by 11.6 points, resulting in a 0.9point improvement in the overall WER while reducing the real-time factor by7.5% compared to the non-biasing baseline on the LibriSpeech 100 test-cleanset.</description>
      <author>example@mail.com (Yui Sudo, Yusuke Fujita, Atsushi Kojima, Tomoya Mizumoto, Lianbo Liu)</author>
      <guid isPermaLink="false">2506.09448v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>GigaChat Family: Efficient Russian Language Modeling Through Mixture of Experts Architecture</title>
      <link>http://arxiv.org/abs/2506.09440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACL-2025 System Demo&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GigaChat系列俄罗斯语言大语言模型，包括不同规模的模型和指令微调版本，并详细报告了模型架构、预训练过程和实验设计。此外，评估了这些模型在俄罗斯和英语基准测试中的性能，并与多语言模型进行了比较。文章展示了高性能模型通过API、Telegram机器人以及Web界面可供使用，并发布了三个开源GigaChat模型以促进NLP研究和支持俄罗斯语言的工业解决方案开发。&lt;h4&gt;背景&lt;/h4&gt;现代自然语言处理（NLP）研究和应用中，生成式大语言模型（LLMs）变得至关重要，但针对俄罗斯语言的专用基础模型开发有限，主要由于所需的计算资源巨大。&lt;h4&gt;目的&lt;/h4&gt;介绍GigaChat系列俄罗斯LLMs，评估其性能，并促进NLP研究和俄罗斯语言工业解决方案的开发。&lt;h4&gt;方法&lt;/h4&gt;详细报告了模型架构、预训练过程和实验设计，并进行了性能评估和比较。&lt;h4&gt;主要发现&lt;/h4&gt;GigaChat系列模型在俄罗斯和英语基准测试中表现出色，并通过API、Telegram机器人以及Web界面提供使用。&lt;h4&gt;结论&lt;/h4&gt;GigaChat系列模型为俄罗斯语言的NLP研究和工业应用提供了强大的工具，并通过开源模型促进了这些领域的进一步发展。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一系列针对俄语的生成式大型语言模型（GigaChat），包括不同规模的基础模型和指令微调版本。我们详细介绍了模型架构、预训练过程和实验设计，并对它们在俄语和英语基准上的性能进行了评估，与多语言模型进行了比较。文章展示了性能最优异的模型通过API、Telegram机器人以及Web界面可供使用。此外，我们还发布了三个开源的GigaChat模型，旨在扩展NLP研究机会并支持俄语工业解决方案的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative large language models (LLMs) have become crucial for modern NLPresearch and applications across various languages. However, the development offoundational models specifically tailored to the Russian language has beenlimited, primarily due to the significant computational resources required.This paper introduces the GigaChat family of Russian LLMs, available in varioussizes, including base models and instruction-tuned versions. We provide adetailed report on the model architecture, pre-training process, andexperiments to guide design choices. In addition, we evaluate their performanceon Russian and English benchmarks and compare GigaChat with multilingualanalogs. The paper presents a system demonstration of the top-performing modelsaccessible via an API, a Telegram bot, and a Web interface. Furthermore, wehave released three open GigaChat models in open-source(https://huggingface.co/ai-sage), aiming to expand NLP research opportunitiesand support the development of industrial solutions for the Russian language.</description>
      <author>example@mail.com (GigaChat team, Mamedov Valentin, Evgenii Kosarev, Gregory Leleytner, Ilya Shchuckin, Valeriy Berezovskiy, Daniil Smirnov, Dmitry Kozlov, Sergei Averkiev, Lukyanenko Ivan, Aleksandr Proshunin, Ainur Israfilova, Ivan Baskov, Artem Chervyakov, Emil Shakirov, Mikhail Kolesov, Daria Khomich, Darya Latortseva, Sergei Porkhun, Yury Fedorov, Oleg Kutuzov, Polina Kudriavtseva, Sofiia Soldatova, Kolodin Egor, Stanislav Pyatkin, Dzmitry Menshykh, Grafov Sergei, Eldar Damirov, Karlov Vladimir, Ruslan Gaitukiev, Arkadiy Shatenov, Alena Fenogenova, Nikita Savushkin, Fedor Minkin)</author>
      <guid isPermaLink="false">2506.09440v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Anomaly Detection and Generation with Diffusion Models: A Survey</title>
      <link>http://arxiv.org/abs/2506.09368v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 11 figures, 13 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基于扩散模型（DMs）的异常检测与生成（ADGDM），分析了其理论基础和实际应用，涵盖了图像、视频、时间序列、表格和多模态数据。&lt;h4&gt;背景&lt;/h4&gt;异常检测在网络安全、金融、医疗保健和工业制造等多个领域发挥着关键作用，而深度学习中的扩散模型因其学习复杂数据分布和生成高保真样本的能力，为无监督异常检测提供了一个强大的框架。&lt;h4&gt;目的&lt;/h4&gt;本文旨在全面回顾ADGDM，强调异常检测和生成之间的内在协同关系，并通过分类和比较不同方法来分析其优缺点。&lt;h4&gt;方法&lt;/h4&gt;本文采用了一种教程式分析方法，详细讨论了基于异常评分机制、条件策略和架构设计的ADGDM方法，并分析了它们的优缺点。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，扩散模型能够通过生成技术直接解决异常数据稀缺的根本挑战，同时检测方法提供反馈以改进生成准确性和相关性，从而提升两种技术的潜力。&lt;h4&gt;结论&lt;/h4&gt;本文讨论了可扩展性和计算效率等关键挑战，并概述了未来研究方向，如高效架构、条件策略和与基础模型（如视觉语言模型和大型语言模型）的集成。&lt;h4&gt;翻译&lt;/h4&gt;摘要：异常检测（AD）在网络安全、金融、医疗保健和工业制造等多个领域发挥着关键作用，通过识别现实数据中偏离既定规范的意外模式。近年来，深度学习中的扩散模型（DMs）因其能够学习复杂数据分布和生成高保真样本的能力，引起广泛关注，为无监督异常检测提供了一个强大的框架。在本综述中，我们全面回顾了基于扩散模型的异常检测与生成（ADGDM），以教程式分析的方式探讨了其理论基础和实践应用，涵盖了图像、视频、时间序列、表格和多模态数据。关键的是，与通常将异常检测和生成视为独立问题的现有综述不同，我们强调了它们之间的内在协同关系。我们揭示了扩散模型如何通过生成技术直接解决异常数据稀缺的根本挑战，同时检测方法提供反馈以改进生成准确性和相关性，从而提升两种技术的潜力。一个详细的分类法根据异常评分机制、条件策略和架构设计对ADGDM方法进行分类，分析了它们的优缺点。我们最后讨论了包括可扩展性和计算效率在内的关键挑战，并概述了包括高效架构、条件策略和与基础模型（例如视觉语言模型和大型语言模型）集成在内的有希望的未来方向。通过综合最近的研究进展和概述开放的研究问题，本综述旨在指导研究人员和实践者利用扩散模型在多种应用中实现创新的异常检测解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection (AD) plays a pivotal role across diverse domains, includingcybersecurity, finance, healthcare, and industrial manufacturing, byidentifying unexpected patterns that deviate from established norms inreal-world data. Recent advancements in deep learning, specifically diffusionmodels (DMs), have sparked significant interest due to their ability to learncomplex data distributions and generate high-fidelity samples, offering arobust framework for unsupervised AD. In this survey, we comprehensively reviewanomaly detection and generation with diffusion models (ADGDM), presenting atutorial-style analysis of the theoretical foundations and practicalimplementations and spanning images, videos, time series, tabular, andmultimodal data. Crucially, unlike existing surveys that often treat anomalydetection and generation as separate problems, we highlight their inherentsynergistic relationship. We reveal how DMs enable a reinforcing cycle wheregeneration techniques directly address the fundamental challenge of anomalydata scarcity, while detection methods provide critical feedback to improvegeneration fidelity and relevance, advancing both capabilities beyond theirindividual potential. A detailed taxonomy categorizes ADGDM methods based onanomaly scoring mechanisms, conditioning strategies, and architectural designs,analyzing their strengths and limitations. We final discuss key challengesincluding scalability and computational efficiency, and outline promisingfuture directions such as efficient architectures, conditioning strategies, andintegration with foundation models (e.g., visual-language models and largelanguage models). By synthesizing recent advances and outlining open researchquestions, this survey aims to guide researchers and practitioners inleveraging DMs for innovative AD solutions across diverse applications.</description>
      <author>example@mail.com (Yang Liu, Jing Liu, Chengfang Li, Rui Xi, Wenchao Li, Liang Cao, Jin Wang, Laurence T. Yang, Junsong Yuan, Wei Zhou)</author>
      <guid isPermaLink="false">2506.09368v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>OmniDRCA: Parallel Speech-Text Foundation Model via Dual-Resolution Speech Representations and Contrastive Alignment</title>
      <link>http://arxiv.org/abs/2506.09349v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了OmniDRCA，一种基于联合自回归建模的并行语音-文本基础模型，它具有双重分辨率语音表示和对比跨模态对齐的特点。&lt;h4&gt;背景&lt;/h4&gt;近期关于使用大型语言模型（LLMs）进行端到端语音生成的研究引起了广泛关注，许多研究将基于文本的LLMs扩展到生成离散语音标记。&lt;h4&gt;目的&lt;/h4&gt;提出OmniDRCA模型，旨在通过联合自回归建模实现并行语音-文本生成，并提高语音理解能力。&lt;h4&gt;方法&lt;/h4&gt;OmniDRCA采用双重分辨率语音表示和对比跨模态对齐，并行处理语音和文本表示，并通过对比对齐增强音频理解。&lt;h4&gt;主要发现&lt;/h4&gt;在Spoken Question Answering基准测试中，OmniDRCA在基于并行联合语音-文本建模的基础模型中建立了新的最先进（SOTA）性能，并且与交错模型相比，表现出了具有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;OmniDRCA模型展示了在并行语音-文本生成中的潜力，并探讨了将该框架扩展到全双工对话场景的可能性。&lt;h4&gt;翻译&lt;/h4&gt;Recent studies on end-to-end speech generation with large language models (LLMs) have attracted significant community attention, with multiple works extending text-based LLMs to generate discrete speech tokens. Existing approaches primarily fall into two categories: (1) Methods that generate discrete speech tokens independently without incorporating them into the LLM's autoregressive process, resulting in text generation being unaware of concurrent speech synthesis. (2) Models that generate interleaved or parallel speech-text tokens through joint autoregressive modeling, enabling mutual modality awareness during generation. This paper presents OmniDRCA, a parallel speech-text foundation model based on joint autoregressive modeling, featuring dual-resolution speech representations and contrastive cross-modal alignment. Our approach processes speech and text representations in parallel while enhancing audio comprehension through contrastive alignment. Experimental results on Spoken Question Answering benchmarks demonstrate that OmniDRCA establishes new state-of-the-art (SOTA) performance among parallel joint speech-text modeling based foundation models, and achieves competitive performance compared to interleaved models. Additionally, we explore the potential of extending the framework to full-duplex conversational scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies on end-to-end speech generation with large language models(LLMs) have attracted significant community attention, with multiple worksextending text-based LLMs to generate discrete speech tokens. Existingapproaches primarily fall into two categories: (1) Methods that generatediscrete speech tokens independently without incorporating them into the LLM'sautoregressive process, resulting in text generation being unaware ofconcurrent speech synthesis. (2) Models that generate interleaved or parallelspeech-text tokens through joint autoregressive modeling, enabling mutualmodality awareness during generation. This paper presents OmniDRCA, a parallelspeech-text foundation model based on joint autoregressive modeling, featuringdual-resolution speech representations and contrastive cross-modal alignment.Our approach processes speech and text representations in parallel whileenhancing audio comprehension through contrastive alignment. Experimentalresults on Spoken Question Answering benchmarks demonstrate that OmniDRCAestablishes new state-of-the-art (SOTA) performance among parallel jointspeech-text modeling based foundation models, and achieves competitiveperformance compared to interleaved models. Additionally, we explore thepotential of extending the framework to full-duplex conversational scenarios.</description>
      <author>example@mail.com (Chao-Hong Tan, Qian Chen, Wen Wang, Chong Deng, Qinglin Zhang, Luyao Cheng, Hai Yu, Xin Zhang, Xiang Lv, Tianyu Zhao, Chong Zhang, Yukun Ma, Yafeng Chen, Hui Wang, Jiaqing Liu, Jieping Ye)</author>
      <guid isPermaLink="false">2506.09349v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>UAD: Unsupervised Affordance Distillation for Generalization in Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2506.09284v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了UAD（无监督 affordance蒸馏）方法，用于从基础模型中提取affordance知识，并构建任务条件化的affordance模型，无需手动标注。&lt;h4&gt;背景&lt;/h4&gt;为了使机器人在非结构化环境中执行开放式任务指令，理解细粒度对象affordance至关重要。然而，现有的视觉affordance预测方法通常依赖于手动标注数据或仅在预定义的任务集上运行。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需手动标注数据的方法，从基础模型中提取affordance知识，并构建能够泛化到真实世界场景的任务条件化affordance模型。&lt;h4&gt;方法&lt;/h4&gt;UAD方法结合了大型视觉模型和视觉-语言模型的优势，自动标注包含详细指令和视觉affordance对的庞大数据集。通过在冻结特征之上训练轻量级的任务条件化解码器，UAD展现出在模拟渲染对象训练后，对真实世界场景和不同人类活动的显著泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;UAD使用提供的affordance作为观察空间，展示了一种模仿学习策略，该策略在仅进行10次演示训练后，表现出对未见过的对象实例、对象类别以及任务指令变化的良好泛化能力。&lt;h4&gt;结论&lt;/h4&gt;UAD方法能够有效地从基础模型中提取affordance知识，并构建具有良好泛化能力的任务条件化affordance模型，为机器人操作非结构化环境中的对象提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;理解细粒度对象affordance对于机器人在非结构化环境中根据开放式任务指令操作物体至关重要。然而，现有的视觉affordance预测方法往往依赖于手动标注数据或仅基于预定义的任务集。我们介绍了UAD（无监督affordance蒸馏）方法，该方法从基础模型中提取affordance知识到任务条件化的affordance模型中，无需任何手动标注。通过利用大型视觉模型和视觉-语言模型的互补优势，UAD自动标注了一个包含详细指令和视觉affordance对的大规模数据集。仅训练一个轻量级的任务条件化解码器在冻结特征之上，UAD在仅训练模拟渲染对象的情况下，显示出对真实世界场景和各种人类活动的显著泛化能力。使用UAD提供的affordance作为观察空间，我们展示了一种模仿学习策略，该策略在训练10次演示后表现出对未见过的对象实例、对象类别以及任务指令变化的良好泛化能力。项目网站：https://unsup-affordance.github.io/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding fine-grained object affordances is imperative for robots tomanipulate objects in unstructured environments given open-ended taskinstructions. However, existing methods of visual affordance predictions oftenrely on manually annotated data or conditions only on a predefined set oftasks. We introduce UAD (Unsupervised Affordance Distillation), a method fordistilling affordance knowledge from foundation models into a task-conditionedaffordance model without any manual annotations. By leveraging thecomplementary strengths of large vision models and vision-language models, UADautomatically annotates a large-scale dataset with detailed $&lt;$instruction,visual affordance$&gt;$ pairs. Training only a lightweight task-conditioneddecoder atop frozen features, UAD exhibits notable generalization toin-the-wild robotic scenes and to various human activities, despite only beingtrained on rendered objects in simulation. Using affordance provided by UAD asthe observation space, we show an imitation learning policy that demonstratespromising generalization to unseen object instances, object categories, andeven variations in task instructions after training on as few as 10demonstrations. Project website: https://unsup-affordance.github.io/</description>
      <author>example@mail.com (Yihe Tang, Wenlong Huang, Yingke Wang, Chengshu Li, Roy Yuan, Ruohan Zhang, Jiajun Wu, Li Fei-Fei)</author>
      <guid isPermaLink="false">2506.09284v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Estimating Visceral Adiposity from Wrist-Worn Accelerometry</title>
      <link>http://arxiv.org/abs/2506.09167v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了内脏脂肪组织（VAT）与代谢健康和习惯性体力活动（PA）之间的关系，发现体力活动与VAT之间存在强相关性，并可能影响代谢健康风险。&lt;h4&gt;背景&lt;/h4&gt;内脏脂肪组织是代谢健康和习惯性体力活动的重要标志。过多的VAT与2型糖尿病和胰岛素抵抗高度相关。&lt;h4&gt;目的&lt;/h4&gt;研究通过使用国家健康与营养调查（NHANES）数据，检验体力活动与VAT之间的关系。&lt;h4&gt;方法&lt;/h4&gt;使用两种方法从活动数据中估计VAT：一种方法基于步态和睡眠中的运动特征，使用岭回归将特征统计映射到VAT估计；另一种方法使用深度神经网络，将24小时的连续加速度计数据转换为VAT估计。&lt;h4&gt;主要发现&lt;/h4&gt;两种方法结合使用，并加入关于受试者人口统计学和身体测量信息的协变量，可以获得最准确的VAT估计，相关系数为r=0.86。&lt;h4&gt;结论&lt;/h4&gt;体力活动与VAT之间存在强相关性，进而可能影响代谢健康风险。&lt;h4&gt;翻译&lt;/h4&gt;Visceral adipose tissue (VAT) is a key marker of both metabolic health and habitual physical activity (PA). Excess VAT is highly correlated with type 2 diabetes and insulin resistance. The mechanistic basis for this pathophysiology relates to overloading the liver with fatty acids. VAT is also a highly labile fat depot, with increased turnover stimulated by catecholamines during exercise. VAT can be measured with sophisticated imaging technologies, but can also be inferred directly from PA. We tested this relationship using National Health and Nutrition Examination Survey (NHANES) data from 2011-2014, for individuals aged 20-60 years with 7 days of accelerometry data (n=2,456 men; 2,427 women) [1]. Two approaches were used for estimating VAT from activity. The first used engineered features based on movements during gait and sleep, and then ridge regression to map summary statistics of these features into a VAT estimate. The second approach used deep neural networks trained on 24 hours of continuous accelerometry. A foundation model first mapped each 10s frame into a high-dimensional feature vector. A transformer model then mapped each day's feature vector time series into a VAT estimate, which were averaged over multiple days. For both approaches, the most accurate estimates were obtained with the addition of covariate information about subject demographics and body measurements. The best performance was obtained by combining the two approaches, resulting in VAT estimates with correlations of r=0.86. These findings demonstrate a strong relationship between PA and VAT and, by extension, between PA and metabolic health risks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visceral adipose tissue (VAT) is a key marker of both metabolic health andhabitual physical activity (PA). Excess VAT is highly correlated with type 2diabetes and insulin resistance. The mechanistic basis for this pathophysiologyrelates to overloading the liver with fatty acids. VAT is also a highly labilefat depot, with increased turnover stimulated by catecholamines duringexercise. VAT can be measured with sophisticated imaging technologies, but canalso be inferred directly from PA. We tested this relationship using NationalHealth and Nutrition Examination Survey (NHANES) data from 2011-2014, forindividuals aged 20-60 years with 7 days of accelerometry data (n=2,456 men;2,427 women) [1]. Two approaches were used for estimating VAT from activity.The first used engineered features based on movements during gait and sleep,and then ridge regression to map summary statistics of these features into aVAT estimate. The second approach used deep neural networks trained on 24 hoursof continuous accelerometry. A foundation model first mapped each 10s frameinto a high-dimensional feature vector. A transformer model then mapped eachday's feature vector time series into a VAT estimate, which were averaged overmultiple days. For both approaches, the most accurate estimates were obtainedwith the addition of covariate information about subject demographics and bodymeasurements. The best performance was obtained by combining the twoapproaches, resulting in VAT estimates with correlations of r=0.86. Thesefindings demonstrate a strong relationship between PA and VAT and, byextension, between PA and metabolic health risks.</description>
      <author>example@mail.com (James R. Williamson, Andrew Alini, Brian A. Telfer, Adam W. Potter, Karl E. Friedl)</author>
      <guid isPermaLink="false">2506.09167v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>TRACE: Grounding Time Series in Context for Multimodal Embedding and Retrieval</title>
      <link>http://arxiv.org/abs/2506.09114v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TRACE的多模态检索器，用于有效处理和检索动态数据中的时间序列数据。&lt;h4&gt;背景&lt;/h4&gt;在天气、医疗保健和能源等领域，动态数据的存在强调了有效解释和检索时间序列数据的必要性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够处理多模态数据并提高时间序列模型性能的检索系统。&lt;h4&gt;方法&lt;/h4&gt;TRACE通过将时间序列嵌入与对齐的文本上下文相关联，实现细粒度的通道级对齐，并采用硬负样本挖掘来促进语义上有意义的检索。&lt;h4&gt;主要发现&lt;/h4&gt;TRACE支持灵活的跨模态检索模式，如文本到时间序列和时间序列到文本，有效地将语言描述与复杂的时序模式联系起来。&lt;h4&gt;结论&lt;/h4&gt;TRACE不仅在下游预测和分类任务中实现了最先进的性能，而且还作为一个强大的独立编码器，通过轻量级任务特定调整来优化上下文感知表示。&lt;h4&gt;翻译&lt;/h4&gt;摘要：动态数据在天气、医疗保健和能源等领域的普遍存在，强调了有效解释和检索时间序列数据的必要性。这些数据本质上是与特定领域的上下文相关的，如临床记录或天气叙述，这使得跨模态检索对于下游任务以及通过检索增强的生成（RAG）开发鲁棒的时间序列基础模型至关重要。尽管需求不断增长，但时间序列检索仍然在很大程度上未得到探索。现有方法通常缺乏语义基础，难以对齐异构模态，并且处理多通道信号的能力有限。为了解决这一差距，我们提出了TRACE，一个通用的多模态检索器，它将时间序列嵌入与对齐的文本上下文相关联。TRACE实现了细粒度的通道级对齐，并采用硬负样本挖掘来促进语义上有意义的检索。它支持灵活的跨模态检索模式，包括文本到时间序列和时间序列到文本，有效地将语言描述与复杂的时序模式联系起来。通过检索语义相关的对，TRACE丰富了下游模型的有信息上下文，从而提高了预测准确性和可解释性。除了静态检索引擎之外，TRACE还作为一个强大的独立编码器，通过轻量级任务特定调整来优化上下文感知表示，同时保持强大的跨模态对齐。这些表示在下游预测和分类任务中实现了最先进的性能。在多个领域的广泛实验突出了其双重效用，作为下游应用的有效编码器和通用检索器，以增强时间序列模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ubiquity of dynamic data in domains such as weather, healthcare, andenergy underscores a growing need for effective interpretation and retrieval oftime-series data. These data are inherently tied to domain-specific contexts,such as clinical notes or weather narratives, making cross-modal retrievalessential not only for downstream tasks but also for developing robusttime-series foundation models by retrieval-augmented generation (RAG). Despitethe increasing demand, time-series retrieval remains largely underexplored.Existing methods often lack semantic grounding, struggle to align heterogeneousmodalities, and have limited capacity for handling multi-channel signals. Toaddress this gap, we propose TRACE, a generic multimodal retriever that groundstime-series embeddings in aligned textual context. TRACE enables fine-grainedchannel-level alignment and employs hard negative mining to facilitatesemantically meaningful retrieval. It supports flexible cross-modal retrievalmodes, including Text-to-Timeseries and Timeseries-to-Text, effectively linkinglinguistic descriptions with complex temporal patterns. By retrievingsemantically relevant pairs, TRACE enriches downstream models with informativecontext, leading to improved predictive accuracy and interpretability. Beyond astatic retrieval engine, TRACE also serves as a powerful standalone encoder,with lightweight task-specific tuning that refines context-awarerepresentations while maintaining strong cross-modal alignment. Theserepresentations achieve state-of-the-art performance on downstream forecastingand classification tasks. Extensive experiments across multiple domainshighlight its dual utility, as both an effective encoder for downstreamapplications and a general-purpose retriever to enhance time-series models.</description>
      <author>example@mail.com (Jialin Chen, Ziyu Zhao, Gaukhar Nurbek, Aosong Feng, Ali Maatouk, Leandros Tassiulas, Yifeng Gao, Rex Ying)</author>
      <guid isPermaLink="false">2506.09114v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>The Urban Model Platform: A Public Backbone for Modeling and Simulation in Urban Digital Twins</title>
      <link>http://arxiv.org/abs/2506.10964v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;城市数字孪生被视为整合城市数字资源，实现更可持续和综合的城市规划的一种方式。&lt;h4&gt;背景&lt;/h4&gt;模型和模拟在城市数字孪生中起着核心作用，但将模型整合到城市数字孪生中是一个复杂的任务。&lt;h4&gt;目的&lt;/h4&gt;研究如何表示城市复杂性，如何处理不确定性和建模范式，以及如何捕捉潜在的权力关系。&lt;h4&gt;方法&lt;/h4&gt;采用参与式设计方法，与德国汉堡市合作，研究开放城市模型平台的作用。&lt;h4&gt;主要发现&lt;/h4&gt;开放的Urban Model Platform可以作为城市数字孪生中建模和模拟的公共技术支柱，同时也是城市过程协作和多元表示的社会技术框架。&lt;h4&gt;结论&lt;/h4&gt;该平台基于开放标准，允许模型去中心化集成，支持模型间的通信，并支持多模型方法来表示城市系统。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urban digital twins are increasingly perceived as a way to pool the growingdigital resources of cities for the purpose of a more sustainable andintegrated urban planning. Models and simulations are central to thisundertaking: They enable "what if?" scenarios, create insights and describerelationships between the vast data that is being collected. However, theprocess of integrating and subsequently using models in urban digital twins isan inherently complex undertaking. It raises questions about how to representurban complexity, how to deal with uncertain assUrban Model Platformtions andmodeling paradigms, and how to capture underlying power relations. Existentapproaches in the domain largely focus on monolithic and centralized solutionsin the tradition of neoliberal city-making, oftentimes prohibiting pluralisticand open interoperable models. Using a participatory design for participatorysystems approach together with the City of Hamburg, Germany, we find that anopen Urban Model Platform can function both as a public technological backbonefor modeling and simulation in urban digital twins and as a socio-technicalframework for a collaborative and pluralistic representation of urbanprocesses. Such a platform builds on open standards, allows for a decentralizedintegration of models, enables communication between models and supports amulti-model approach to representing urban systems.</description>
      <author>example@mail.com (Rico H Herzog, Till Degkwitz, Trivik Verma)</author>
      <guid isPermaLink="false">2506.10964v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Segment Concealed Objects with Incomplete Supervision</title>
      <link>http://arxiv.org/abs/2506.08955v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE TPAMI&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一的方法来解决不完全监督下隐蔽物体分割（ISCOS）的挑战，通过使用不完全标注的数据进行模型训练，实现了物体与其周围环境的无缝分割。&lt;h4&gt;背景&lt;/h4&gt;ISCOS任务面临两个主要挑战：一是不完全标注数据提供的有限监督，二是区分隐蔽物体和背景的困难，这源于隐蔽场景中的内在相似性。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种统一的方法来克服上述挑战，并实现ISCOS的高效分割。&lt;h4&gt;方法&lt;/h4&gt;提出了一个名为SEE的统一mean-teacher框架，利用视觉基础模型“SegmentAnything Model (SAM)”生成伪标签，并采用一系列策略来生成、存储和监督伪标签，以增强网络训练的鲁棒性。此外，设计了一个混合粒度特征分组模块，通过聚类相似特征来促进分割一致性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在多个ISCOS任务上达到了最先进的性能，并且SEE可以作为即插即用的解决方案，提升现有模型的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法为ISCOS任务提供了一种有效的解决方案，并有望应用于更多相关领域。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种统一的方法来解决不完全监督下隐蔽物体分割（ISCOS）的挑战，通过使用不完全标注的数据进行模型训练，实现了物体与其周围环境的无缝分割。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Incompletely-Supervised Concealed Object Segmentation (ISCOS) involvessegmenting objects that seamlessly blend into their surrounding environments,utilizing incompletely annotated data, such as weak and semi-annotations, formodel training. This task remains highly challenging due to (1) the limitedsupervision provided by the incompletely annotated training data, and (2) thedifficulty of distinguishing concealed objects from the background, whicharises from the intrinsic similarities in concealed scenarios. In this paper,we introduce the first unified method for ISCOS to address these challenges. Totackle the issue of incomplete supervision, we propose a unified mean-teacherframework, SEE, that leverages the vision foundation model, ``\emph{SegmentAnything Model (SAM)}'', to generate pseudo-labels using coarse masks producedby the teacher model as prompts. To mitigate the effect of low-qualitysegmentation masks, we introduce a series of strategies for pseudo-labelgeneration, storage, and supervision. These strategies aim to produceinformative pseudo-labels, store the best pseudo-labels generated, and selectthe most reliable components to guide the student model, thereby ensuringrobust network training. Additionally, to tackle the issue of intrinsicsimilarity, we design a hybrid-granularity feature grouping module that groupsfeatures at different granularities and aggregates these results. By clusteringsimilar features, this module promotes segmentation coherence, facilitatingmore complete segmentation for both single-object and multiple-object images.We validate the effectiveness of our approach across multiple ISCOS tasks, andexperimental results demonstrate that our method achieves state-of-the-artperformance. Furthermore, SEE can serve as a plug-and-play solution, enhancingthe performance of existing models.</description>
      <author>example@mail.com (Chunming He, Kai Li, Yachao Zhang, Ziyun Yang, Youwei Pang, Longxiang Tang, Chengyu Fang, Yulun Zhang, Linghe Kong, Xiu Li, Sina Farsiu)</author>
      <guid isPermaLink="false">2506.08955v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
  <item>
      <title>Enhancing Human-Robot Collaboration: A Sim2Real Domain Adaptation Algorithm for Point Cloud Segmentation in Industrial Environments</title>
      <link>http://arxiv.org/abs/2506.09552v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint, Journal of Intelligent &amp; Robotic Systems&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对人机协作应用的3D环境语义分割的新方法，该方法通过在Sim2Real领域适应中采用双流网络架构（FUSION），提高了语义分割的准确性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;人机协作（HRC）应用中，对3D环境的鲁棒理解至关重要，其中安全性和操作效率是首要考虑因素。语义分割在这一背景下起着关键作用，因为它能够实现对环境的精确和详细理解。&lt;h4&gt;目的&lt;/h4&gt;针对真实世界工业环境中语义分割对标注数据的强烈需求，本文旨在开发一个能够从模拟环境平稳过渡到真实世界应用的语义分割网络，从而增强其实际效用和对安全HRC的影响。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种名为FUSION的双流网络架构，该架构结合了动态图卷积神经网络（DGCNN）和卷积神经网络（CNN），并加入了残差层，作为工业环境的Sim2Real领域适应算法。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型在真实世界的HRC设置和模拟工业点云上进行了评估，显示了比现有方法更高的分割准确率（97.76%）和更好的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在HRC应用中提供了更高的准确性和鲁棒性，为安全的人机协作提供了有效的技术支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The robust interpretation of 3D environments is crucial for human-robotcollaboration (HRC) applications, where safety and operational efficiency areparamount. Semantic segmentation plays a key role in this context by enabling aprecise and detailed understanding of the environment. Considering the intensedata hunger for real-world industrial annotated data essential for effectivesemantic segmentation, this paper introduces a pioneering approach in theSim2Real domain adaptation for semantic segmentation of 3D point cloud data,specifically tailored for HRC. Our focus is on developing a network thatrobustly transitions from simulated environments to real-world applications,thereby enhancing its practical utility and impact on a safe HRC.  In this work, we propose a dual-stream network architecture (FUSION)combining Dynamic Graph Convolutional Neural Networks (DGCNN) and ConvolutionalNeural Networks (CNN) augmented with residual layers as a Sim2Real domainadaptation algorithm for an industrial environment. The proposed model wasevaluated on real-world HRC setups and simulation industrial point clouds, itshowed increased state-of-the-art performance, achieving a segmentationaccuracy of 97.76%, and superior robustness compared to existing methods.</description>
      <author>example@mail.com (Fatemeh Mohammadi Amin, Darwin G. Caldwell, Hans Wernher van de Venn)</author>
      <guid isPermaLink="false">2506.09552v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>MetricHMR: Metric Human Mesh Recovery from Monocular Images</title>
      <link>http://arxiv.org/abs/2506.09919v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了MetricHMR（Metric Human Mesh Recovery），这是一种从单目图像中进行精确全局平移的人体网格恢复方法。&lt;h4&gt;背景&lt;/h4&gt;现有的HMR方法在尺度深度模糊方面存在严重问题，而MetricHMR能够生成几何上合理的身体形状和全局平移。&lt;h4&gt;目的&lt;/h4&gt;分析先前HMR方法在相机模型上的表现，强调标准透视投影模型在实现度量尺度HMR中的关键作用。&lt;h4&gt;方法&lt;/h4&gt;验证了在标准透视投影模型下度量HMR的可接受模糊范围，并提出了一个基于标准透视投影的射线图方法，用于联合编码边界框信息、相机参数和几何线索，以实现端到端度量HMR，无需任何额外的度量正则化模块。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量实验证明，该方法在度量姿态、形状和全局平移估计方面达到了最先进的性能，甚至与顺序HMR方法相比，在室内和室外场景中都表现出色。&lt;h4&gt;结论&lt;/h4&gt;MetricHMR是一种有效的人体网格恢复方法，能够提供准确的全局平移和几何合理的身体形状恢复，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce MetricHMR (Metric Human Mesh Recovery), an approach for metrichuman mesh recovery with accurate global translation from monocular images. Incontrast to existing HMR methods that suffer from severe scale and depthambiguity, MetricHMR is able to produce geometrically reasonable body shape andglobal translation in the reconstruction results. To this end, we firstsystematically analyze previous HMR methods on camera models to emphasize thecritical role of the standard perspective projection model in enablingmetric-scale HMR. We then validate the acceptable ambiguity range of metric HMRunder the standard perspective projection model. Finally, we contribute a novelapproach that introduces a ray map based on the standard perspective projectionto jointly encode bounding-box information, camera parameters, and geometriccues for End2End metric HMR without any additional metric-regularizationmodules. Extensive experiments demonstrate that our method achievesstate-of-the-art performance, even compared with sequential HMR methods, inmetric pose, shape, and global translation estimation across both indoor andin-the-wild scenarios.</description>
      <author>example@mail.com (He Zhang, Chentao Song, Hongwen Zhang, Tao Yu)</author>
      <guid isPermaLink="false">2506.09919v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>CausalVQA: A Physically Grounded Causal Reasoning Benchmark for Video Models</title>
      <link>http://arxiv.org/abs/2506.09943v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  35 pages, 3 figures, Submitted to NeurIPS2025 benchmark track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CausalVQA是一个用于视频问答的基准数据集，旨在测试模型对物理世界中因果关系的理解能力。&lt;h4&gt;背景&lt;/h4&gt;现有的视频问答基准数据集要么侧重于对现实世界视频的表面感知理解，要么侧重于使用模拟环境创建的狭窄物理推理问题。&lt;h4&gt;目的&lt;/h4&gt;CausalVQA通过提供基于现实场景的挑战性问题，同时关注模型通过五种问题类型（反事实、假设、预期、计划和描述）预测不同行动和事件的可能结果的能力，填补了这一重要空白。&lt;h4&gt;方法&lt;/h4&gt;设计了质量控制机制，防止模型利用简单捷径，要求模型基于深度视觉理解而非语言线索来回答问题。&lt;h4&gt;主要发现&lt;/h4&gt;当前前沿的多模态模型在基准测试中的表现远低于人类，尤其是在预期和假设问题上。&lt;h4&gt;结论&lt;/h4&gt;这突显了当前系统在现实世界设置中利用空间时间推理、理解物理原理和识别可能替代方案以做出准确预测的挑战。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了CausalVQA，这是一个由问题-答案对组成的视频问答基准数据集，旨在测试模型对物理世界中因果关系的理解能力。现有的视频问答基准数据集要么倾向于关注现实世界视频的表面感知理解，要么侧重于使用模拟环境创建的狭窄物理推理问题。CausalVQA通过提出基于现实场景的挑战性问题，同时关注模型通过五种问题类型（反事实、假设、预期、计划和描述）预测不同行动和事件的可能结果的能力，填补了这一重要空白。我们设计了质量控制机制，防止模型利用简单捷径，要求模型基于深度视觉理解而非语言线索来回答问题。我们发现，当前前沿的多模态模型在基准测试中的表现远低于人类，尤其是在预期和假设问题上。这突显了当前系统在现实世界设置中利用空间时间推理、理解物理原理和识别可能替代方案以做出准确预测的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce CausalVQA, a benchmark dataset for video question answering(VQA) composed of question-answer pairs that probe models' understanding ofcausality in the physical world. Existing VQA benchmarks either tend to focuson surface perceptual understanding of real-world videos, or on narrow physicalreasoning questions created using simulation environments. CausalVQA fills animportant gap by presenting challenging questions that are grounded inreal-world scenarios, while focusing on models' ability to predict the likelyoutcomes of different actions and events through five question types:counterfactual, hypothetical, anticipation, planning and descriptive. Wedesigned quality control mechanisms that prevent models from exploiting trivialshortcuts, requiring models to base their answers on deep visual understandinginstead of linguistic cues. We find that current frontier multimodal modelsfall substantially below human performance on the benchmark, especially onanticipation and hypothetical questions. This highlights a challenge forcurrent systems to leverage spatial-temporal reasoning, understanding ofphysical principles, and comprehension of possible alternatives to makeaccurate predictions in real-world settings.</description>
      <author>example@mail.com (Aaron Foss, Chloe Evans, Sasha Mitts, Koustuv Sinha, Ammar Rizvi, Justine T. Kao)</author>
      <guid isPermaLink="false">2506.09943v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>SemanticSplat: Feed-Forward 3D Scene Understanding with Language-Aware Gaussian Fields</title>
      <link>http://arxiv.org/abs/2506.09565v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SemanticSplat的前馈语义感知3D重建方法，旨在解决现有3D场景理解方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有的3D场景理解方法主要存在两个问题：一是仅提取基于语言的语义，无法实现全面的场景理解；二是几何重建质量低，存在噪声。&lt;h4&gt;目的&lt;/h4&gt;提出SemanticSplat方法，旨在通过联合建模几何、外观和语义，实现全面的3D场景理解。&lt;h4&gt;方法&lt;/h4&gt;SemanticSplat方法将3D高斯与潜在语义属性统一，用于联合几何-外观-语义建模。通过融合多种特征场（如LSeg、SAM）和存储跨视图特征相似性的成本体积表示，预测语义各向异性高斯，从而提高场景理解的连贯性和准确性。利用两阶段蒸馏框架，从稀疏视图图像中重建全面的多模态语义特征场。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在3D场景理解任务（如提示和开放词汇分割）中表现出色。&lt;h4&gt;结论&lt;/h4&gt;SemanticSplat方法为3D场景理解提供了一种有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：全面的3D场景理解，即同时建模几何、外观和语义，对于增强现实和机器人交互等应用至关重要。现有的前馈3D场景理解方法（例如，LSM）仅限于从场景中提取基于语言的语义，无法实现全面的场景理解。此外，它们在几何重建方面质量低下，存在噪声伪影。相比之下，基于场景优化的方法依赖于密集的输入视图，这降低了其实用性，并在部署期间增加了复杂性。在本文中，我们提出了SemanticSplat，一种前馈语义感知3D重建方法，它将3D高斯与潜在语义属性统一，以实现联合几何-外观-语义建模。为了预测语义各向异性高斯，SemanticSplat融合了多种特征场（例如，LSeg，SAM）与存储跨视图特征相似性的成本体积表示，增强了连贯和准确的场景理解。利用两阶段蒸馏框架，SemanticSplat从稀疏视图图像中重建全面的多模态语义特征场。实验表明，我们提出的方法在3D场景理解任务（如提示和开放词汇分割）中是有效的。视频结果可在https://semanticsplat.github.io上查看。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Holistic 3D scene understanding, which jointly models geometry, appearance,and semantics, is crucial for applications like augmented reality and roboticinteraction. Existing feed-forward 3D scene understanding methods (e.g., LSM)are limited to extracting language-based semantics from scenes, failing toachieve holistic scene comprehension. Additionally, they suffer fromlow-quality geometry reconstruction and noisy artifacts. In contrast, per-sceneoptimization methods rely on dense input views, which reduces practicality andincreases complexity during deployment. In this paper, we proposeSemanticSplat, a feed-forward semantic-aware 3D reconstruction method, whichunifies 3D Gaussians with latent semantic attributes for jointgeometry-appearance-semantics modeling. To predict the semantic anisotropicGaussians, SemanticSplat fuses diverse feature fields (e.g., LSeg, SAM) with acost volume representation that stores cross-view feature similarities,enhancing coherent and accurate scene comprehension. Leveraging a two-stagedistillation framework, SemanticSplat reconstructs a holistic multi-modalsemantic feature field from sparse-view images. Experiments demonstrate theeffectiveness of our method for 3D scene understanding tasks like promptableand open-vocabulary segmentation. Video results are available athttps://semanticsplat.github.io.</description>
      <author>example@mail.com (Qijing Li, Jingxiang Sun, Liang An, Zhaoqi Su, Hongwen Zhang, Yebin Liu)</author>
      <guid isPermaLink="false">2506.09565v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>HopaDIFF: Holistic-Partial Aware Fourier Conditioned Diffusion for Referring Human Action Segmentation in Multi-Person Scenarios</title>
      <link>http://arxiv.org/abs/2506.09650v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code is available at https://github.com/KPeng9510/HopaDIFF.git&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对多个人物场景的文本参考引导的人体动作分割方法，并引入了RHAS133数据集，实现了在RHAS133数据集上最先进的结果。&lt;h4&gt;背景&lt;/h4&gt;动作分割是高级视频理解的核心挑战，主要针对单人活动，忽略了多人物场景。&lt;h4&gt;目的&lt;/h4&gt;提出文本参考引导的人体动作分割方法，解决多人物场景的动作分割问题。&lt;h4&gt;方法&lt;/h4&gt;提出了整体-部分意识傅里叶条件扩散框架（HopaDIFF），利用新的交叉输入门注意力xLSTM增强整体-部分长距离推理，并引入傅里叶条件来提高动作分割生成的细粒度控制。&lt;h4&gt;主要发现&lt;/h4&gt;在RHAS133数据集上，现有的动作识别方法表现有限，视觉线索的聚合对目标人物的效果不佳。&lt;h4&gt;结论&lt;/h4&gt;HopaDIFF在RHAS133数据集上实现了最先进的结果，代码可在GitHub上找到。&lt;h4&gt;翻译&lt;/h4&gt;摘要：动作分割是高级视频理解的核心挑战，旨在将未剪辑的视频分割成片段，并为每个片段分配一个预定义的动作集标签。现有方法主要解决单人活动且动作序列固定的问题，忽略了多人物场景。在本研究中，我们首次提出在多人物场景中的文本参考引导的人体动作分割，其中文本描述指定了分割的目标人物。我们引入了第一个用于指称人体动作分割的数据集，即RHAS133，该数据集由133部电影组成，并标注了137个细粒度动作以及33小时的视频数据，还提供了此新任务的文本描述。在RHAS133数据集上使用基于VLM的特征提取器对现有的动作识别方法进行基准测试，揭示了有限的性能和视觉线索对目标人物聚合的不足。为了解决这个问题，我们提出了整体-部分意识傅里叶条件扩散框架，即HopaDIFF，利用新颖的交叉输入门注意力xLSTM来增强整体-部分长距离推理，并引入傅里叶条件以引入更多细粒度控制来提高动作分割生成。HopaDIFF在RHAS133数据集上的不同评估设置中实现了最先进的结果。代码可在https://github.com/KPeng9510/HopaDIFF.git上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Action segmentation is a core challenge in high-level video understanding,aiming to partition untrimmed videos into segments and assign each a label froma predefined action set. Existing methods primarily address single-personactivities with fixed action sequences, overlooking multi-person scenarios. Inthis work, we pioneer textual reference-guided human action segmentation inmulti-person settings, where a textual description specifies the target personfor segmentation. We introduce the first dataset for Referring Human ActionSegmentation, i.e., RHAS133, built from 133 movies and annotated with 137fine-grained actions with 33h video data, together with textual descriptionsfor this new task. Benchmarking existing action recognition methods on RHAS133using VLM-based feature extractors reveals limited performance and pooraggregation of visual cues for the target person. To address this, we propose aholistic-partial aware Fourier-conditioned diffusion framework, i.e., HopaDIFF,leveraging a novel cross-input gate attentional xLSTM to enhanceholistic-partial long-range reasoning and a novel Fourier condition tointroduce more fine-grained control to improve the action segmentationgeneration. HopaDIFF achieves state-of-the-art results on RHAS133 in diverseevaluation settings. The code is available athttps://github.com/KPeng9510/HopaDIFF.git.</description>
      <author>example@mail.com (Kunyu Peng, Junchao Huang, Xiangsheng Huang, Di Wen, Junwei Zheng, Yufan Chen, Kailun Yang, Jiamin Wu, Chongqing Hao, Rainer Stiefelhagen)</author>
      <guid isPermaLink="false">2506.09650v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>ODG: Occupancy Prediction Using Dual Gaussians</title>
      <link>http://arxiv.org/abs/2506.09417v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的3D占用预测方法ODG，结合了鸟瞰图（BEV）和稀疏点表示，以降低计算成本并解决现有方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;3D占用信息对于场景理解和自动驾驶至关重要，但现有方法计算成本高，需要密集的3D特征体积和交叉注意力来有效聚合信息。&lt;h4&gt;目的&lt;/h4&gt;降低计算成本并解决现有方法的局限性，如BEV在处理小物体时信息损失严重，稀疏点在捕捉平面或大物体时效率低下。&lt;h4&gt;方法&lt;/h4&gt;提出了一种双分支设计：基于查询的稀疏点分支和BEV分支。稀疏点分支学习到的3D信息通过交叉注意力与BEV流共享，丰富BEV平面上困难物体的弱信号。两个分支的输出最终融合以生成预测的3D占用。&lt;h4&gt;主要发现&lt;/h4&gt;在Occ3D-nuScenes和Occ3D-Waymo基准上进行了广泛实验，证明了ODG方法的优势，并且与最新高效方法相比，ODG也提供了具有竞争力的推理速度。&lt;h4&gt;结论&lt;/h4&gt;ODG方法在降低计算成本的同时，提高了3D占用预测的准确性，为自动驾驶等应用提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D occupancy provides fine-grained 3D geometry and semantics for sceneunderstanding which is critical for autonomous driving. Most existing methods,however, carry high compute costs, requiring dense 3D feature volume andcross-attention to effectively aggregate information. More recent works haveadopted Bird's Eye View (BEV) or sparse points as scene representation withmuch reduced cost, but still suffer from their respective shortcomings. Moreconcretely, BEV struggles with small objects that often experience significantinformation loss after being projected to the ground plane. On the other hand,points can flexibly model little objects in 3D, but is inefficient at capturingflat surfaces or large objects. To address these challenges, in this paper, wepresent a novel 3D occupancy prediction approach, ODG, which combines BEV andsparse points based representations. We propose a dual-branch design: aquery-based sparse points branch and a BEV branch. The 3D information learnedin the sparse points branch is shared with the BEV stream via cross-attention,which enriches the weakened signals of difficult objects on the BEV plane. Theoutputs of both branches are finally fused to generate predicted 3D occupancy.We conduct extensive experiments on the Occ3D-nuScenes and Occ3D-Waymobenchmarks that demonstrate the superiority of our proposed ODG. Moreover, ODGalso delivers competitive inference speed when compared to the latest efficientapproaches.</description>
      <author>example@mail.com (Yunxiao Shi, Yinhao Zhu, Shizhong Han, Jisoo Jeong, Amin Ansari, Hong Cai, Fatih Porikli)</author>
      <guid isPermaLink="false">2506.09417v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>Synthetic Human Action Video Data Generation with Pose Transfer</title>
      <link>http://arxiv.org/abs/2506.09411v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用姿态转移（特别是可控3D高斯头像模型）生成合成人类动作视频数据的方法，并在Toyota Smarthome和NTU RGB+D数据集上评估了该方法，证明其在动作识别任务中提高了性能。&lt;h4&gt;背景&lt;/h4&gt;在视频理解任务中，特别是涉及人类运动的任务，合成数据生成常常存在不协调的特征，这降低了其在训练中的有效性。因此，诸如手语翻译、手势识别和自动驾驶中的人类运动理解等任务无法充分利用合成数据的潜力。&lt;h4&gt;目的&lt;/h4&gt;提出一种生成合成人类动作视频数据的方法，以解决合成数据在视频理解任务中的局限性。&lt;h4&gt;方法&lt;/h4&gt;使用姿态转移技术，特别是可控3D高斯头像模型来生成合成人类动作视频数据。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在动作识别任务中提高了性能，并且能够有效地扩展少量样本数据集，弥补了真实训练数据中代表性不足的群体，并增加了多样化的背景。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效提高视频理解任务中动作识别的性能，并且能够扩展少量样本数据集，增强数据多样性。&lt;h4&gt;翻译&lt;/h4&gt;在视频理解任务中，特别是在涉及人类运动的任务中，合成数据生成常常存在不协调的特征，这降低了其在训练中的有效性。因此，诸如手语翻译、手势识别和自动驾驶中的人类运动理解等任务无法充分利用合成数据的潜力。本文提出了一种使用姿态转移（特别是可控3D高斯头像模型）生成合成人类动作视频数据的方法。在Toyota Smarthome和NTU RGB+D数据集上评估该方法时，发现其在动作识别任务中提高了性能。此外，该方法还能有效扩展少量样本数据集，弥补真实训练数据中代表性不足的群体，并增加多样化的背景。本文将该方法及其与互联网上收集的具有新颖人类身份的视频和头像的RANDOM People数据集一起开源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In video understanding tasks, particularly those involving human motion,synthetic data generation often suffers from uncanny features, diminishing itseffectiveness for training. Tasks such as sign language translation, gesturerecognition, and human motion understanding in autonomous driving have thusbeen unable to exploit the full potential of synthetic data. This paperproposes a method for generating synthetic human action video data using posetransfer (specifically, controllable 3D Gaussian avatar models). We evaluatethis method on the Toyota Smarthome and NTU RGB+D datasets and show that itimproves performance in action recognition tasks. Moreover, we demonstrate thatthe method can effectively scale few-shot datasets, making up for groupsunderrepresented in the real training data and adding diverse backgrounds. Weopen-source the method along with RANDOM People, a dataset with videos andavatars of novel human identities for pose transfer crowd-sourced from theinternet.</description>
      <author>example@mail.com (Vaclav Knapp, Matyas Bohacek)</author>
      <guid isPermaLink="false">2506.09411v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>Multivariate Long-term Time Series Forecasting with Fourier Neural Filter</title>
      <link>http://arxiv.org/abs/2506.09174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的多变量长期时间序列预测方法，该方法能够同时捕捉变量内部的时序依赖性和变量间的空间相关性。&lt;h4&gt;背景&lt;/h4&gt;当前时间序列预测方法主要利用自然语言处理或计算机视觉的骨干网络，但这些方法未能充分解决时间序列的独特属性，如周期性。&lt;h4&gt;目的&lt;/h4&gt;提出FNF作为骨干网络和DBD作为架构，以提供优秀的学习能力和最佳学习路径，用于时空建模。&lt;h4&gt;方法&lt;/h4&gt;通过理论分析证明了FNF能够将局部时域和全局频域信息处理统一于单一骨干网络中，而信息瓶颈理论证明了DBD提供了比现有统一或顺序架构更好的梯度流和表示能力。&lt;h4&gt;主要发现&lt;/h4&gt;在11个公共基准数据集上的实证评估表明，该方法在不同领域（能源、气象、交通、环境和自然）中均取得了最先进的性能，且无需任何辅助技术。&lt;h4&gt;结论&lt;/h4&gt;该研究表明，经过适当设计的神经网络架构可以捕捉时间序列的固有属性，有望在科学和工业应用中改变时间序列建模方式。&lt;h4&gt;翻译&lt;/h4&gt;Multivariate long-term time series forecasting has been suffering from the challenge of capturing both temporal dependencies within variables and spatial correlations across variables simultaneously. Current approaches predominantly repurpose backbones from natural language processing or computer vision (e.g., Transformers), which fail to adequately address the unique properties of time series (e.g., periodicity). The research community lacks a dedicated backbonewith temporal-specific inductive biases, instead relying on domain-agnostic backbones supplemented with auxiliary techniques (e.g., signal decomposition). We introduce FNF as the backbone and DBD as the architecture to provide excellent learning capabilities and optimal learning pathways for spatio-temporal modeling, respectively. Our theoretical analysis proves that FNF unifies local time-domain and global frequency-domain information processing within a single backbone that extends naturally to spatial modeling, while information bottleneck theory demonstrates that DBD provides superior gradient flow and representation capacity compared to existing unified or sequential architectures. Our empirical evaluation across 11 public benchmark datasets spanning five domains (energy, meteorology, transportation, environment, and nature) confirms state-of-the-art performance with consistent hyperparameter settings. Notably, our approach achieves these results without any auxiliary techniques, suggesting that properly designed neural architectures can capture the inherent properties of time series, potentially transforming time series modeling in scientific and industrial applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate long-term time series forecasting has been suffering from thechallenge of capturing both temporal dependencies within variables and spatialcorrelations across variables simultaneously. Current approaches predominantlyrepurpose backbones from natural language processing or computer vision (e.g.,Transformers), which fail to adequately address the unique properties of timeseries (e.g., periodicity). The research community lacks a dedicated backbonewith temporal-specific inductive biases, instead relying on domain-agnosticbackbones supplemented with auxiliary techniques (e.g., signal decomposition).We introduce FNF as the backbone and DBD as the architecture to provideexcellent learning capabilities and optimal learning pathways forspatio-temporal modeling, respectively. Our theoretical analysis proves thatFNF unifies local time-domain and global frequency-domain informationprocessing within a single backbone that extends naturally to spatial modeling,while information bottleneck theory demonstrates that DBD provides superiorgradient flow and representation capacity compared to existing unified orsequential architectures. Our empirical evaluation across 11 public benchmarkdatasets spanning five domains (energy, meteorology, transportation,environment, and nature) confirms state-of-the-art performance with consistenthyperparameter settings. Notably, our approach achieves these results withoutany auxiliary techniques, suggesting that properly designed neuralarchitectures can capture the inherent properties of time series, potentiallytransforming time series modeling in scientific and industrial applications.</description>
      <author>example@mail.com (Chenheng Xu, Dan Wu, Yixin Zhu, Ying Nian Wu)</author>
      <guid isPermaLink="false">2506.09174v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>FinHEAR: Human Expertise and Adaptive Risk-Aware Temporal Reasoning for Financial Decision-Making</title>
      <link>http://arxiv.org/abs/2506.09080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FinHEAR的多代理框架，用于处理金融决策中的独特挑战，包括时间推理、适应性风险评估和对动态事件的响应。FinHEAR通过利用专门的大型语言模型（LLM）代理来分析历史趋势、解释当前事件和检索专家意见，以提高金融决策的透明度和稳健性。&lt;h4&gt;背景&lt;/h4&gt;语言模型在处理金融决策时面临挑战，因为它们难以捕捉到人类金融决策中的行为模式，如信息不对称下的专家依赖、损失规避敏感性和反馈驱动的时序调整。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够模拟人类专家知识和适应性风险评估的金融决策支持系统。&lt;h4&gt;方法&lt;/h4&gt;FinHEAR框架通过专家指导的检索、置信度调整的仓位规模和基于结果的细化来增强透明度和稳健性。&lt;h4&gt;主要发现&lt;/h4&gt;在经过精心挑选的金融数据集上的实证结果表明，FinHEAR在趋势预测和交易任务中优于强基线，实现了更高的准确性和更好的风险调整回报。&lt;h4&gt;结论&lt;/h4&gt;FinHEAR是一个有效的工具，可以用于改善金融决策的准确性和风险调整回报。&lt;h4&gt;翻译&lt;/h4&gt;Financial decision-making presents unique challenges for language models, demanding temporal reasoning, adaptive risk assessment, and responsiveness to dynamic events. While large language models (LLMs) show strong general reasoning capabilities, they often fail to capture behavioral patterns central to human financial decisions-such as expert reliance under information asymmetry, loss-averse sensitivity, and feedback-driven temporal adjustment. We propose FinHEAR, a multi-agent framework for Human Expertise and Adaptive Risk-aware reasoning. FinHEAR orchestrates specialized LLM-based agents to analyze historical trends, interpret current events, and retrieve expert-informed precedents within an event-centric pipeline. Grounded in behavioral economics, it incorporates expert-guided retrieval, confidence-adjusted position sizing, and outcome-based refinement to enhance interpretability and robustness. Empirical results on curated financial datasets show that FinHEAR consistently outperforms strong baselines across trend prediction and trading tasks, achieving higher accuracy and better risk-adjusted returns.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Financial decision-making presents unique challenges for language models,demanding temporal reasoning, adaptive risk assessment, and responsiveness todynamic events. While large language models (LLMs) show strong generalreasoning capabilities, they often fail to capture behavioral patterns centralto human financial decisions-such as expert reliance under informationasymmetry, loss-averse sensitivity, and feedback-driven temporal adjustment. Wepropose FinHEAR, a multi-agent framework for Human Expertise and AdaptiveRisk-aware reasoning. FinHEAR orchestrates specialized LLM-based agents toanalyze historical trends, interpret current events, and retrieveexpert-informed precedents within an event-centric pipeline. Grounded inbehavioral economics, it incorporates expert-guided retrieval,confidence-adjusted position sizing, and outcome-based refinement to enhanceinterpretability and robustness. Empirical results on curated financialdatasets show that FinHEAR consistently outperforms strong baselines acrosstrend prediction and trading tasks, achieving higher accuracy and betterrisk-adjusted returns.</description>
      <author>example@mail.com (Jiaxiang Chen, Mingxi Zou, Zhuo Wang, Qifan Wang, Dongning Sun, Chi Zhang, Zenglin Xu)</author>
      <guid isPermaLink="false">2506.09080v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>AVA-Bench: Atomic Visual Ability Benchmark for Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2506.09082v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  First two authors contribute equally&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为AVA-Bench的新基准，用于评估视觉基础模型（VFMs）的性能，解决了现有评估方法中存在的两个关键问题。&lt;h4&gt;背景&lt;/h4&gt;随着视觉基础模型（VFMs）的兴起，对其系统性的评估变得尤为重要。传统的评估方法是将VFMs与大型语言模型（LLMs）配对作为通用头，然后在广泛的视觉问答（VQA）基准上进行评估。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有评估方法中存在的两个关键问题：指令调整数据可能与VQA测试分布不匹配，以及VQA基准通常需要多种视觉能力，难以确定错误是否源于缺乏所有必需的能力或仅仅是单一关键能力。&lt;h4&gt;方法&lt;/h4&gt;提出AVA-Bench，这是第一个明确分离14种原子视觉能力（AVAs）的基准，这些能力是支持复杂视觉推理任务的基石。通过解耦AVAs并在每个AVAs中匹配训练和测试分布，AVA-Bench可以精确地指出VFMs的优缺点。&lt;h4&gt;主要发现&lt;/h4&gt;使用AVA-Bench评估领先的VFMs可以揭示独特的“能力指纹”，将VFMs的选择从经验推测转变为原则性工程。此外，发现一个0.5B的LLM在排名上与一个7B的LLM相似，同时减少了8倍的GPU小时数，使评估更加高效。&lt;h4&gt;结论&lt;/h4&gt;AVA-Bench提供了一个全面和透明的基准，为下一代VFMs的发展奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉基础模型（VFMs）的兴起需要系统性的评估。一种常见的做法是将VFMs与大型语言模型（LLMs）配对作为通用头，然后在广泛的视觉问答（VQA）基准上进行评估。然而，这种协议有两个关键盲点：（i）指令调整数据可能与VQA测试分布不匹配，这意味着错误的预测可能源于此类数据不匹配，而不是VFMs的视觉不足；（ii）VQA基准通常需要多种视觉能力，这使得很难确定错误是否源于缺乏所有必需的能力或仅仅是单一关键能力。为了解决这些差距，我们引入了AVA-Bench，这是第一个明确分离14种原子视觉能力（AVAs）的基准——这些是支持复杂视觉推理任务的基础技能，如定位、深度估计和空间理解。通过解耦AVAs并在每个AVAs中匹配训练和测试分布，AVA-Bench可以精确地指出VFMs的优缺点。将AVA-Bench应用于领先的VFMs因此揭示了独特的“能力指纹”，将VFMs的选择从经验推测转变为原则性工程。值得注意的是，我们发现一个0.5B的LLM在排名上与一个7B的LLM相似，同时减少了8倍的GPU小时数，使评估更加高效。通过提供一个全面和透明的基准，我们希望AVA-Bench为下一代VFMs的发展奠定基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rise of vision foundation models (VFMs) calls for systematic evaluation.A common approach pairs VFMs with large language models (LLMs) asgeneral-purpose heads, followed by evaluation on broad Visual QuestionAnswering (VQA) benchmarks. However, this protocol has two key blind spots: (i)the instruction tuning data may not align with VQA test distributions, meaninga wrong prediction can stem from such data mismatch rather than a VFM' visualshortcomings; (ii) VQA benchmarks often require multiple visual abilities,making it hard to tell whether errors stem from lacking all required abilitiesor just a single critical one. To address these gaps, we introduce AVA-Bench,the first benchmark that explicitly disentangles 14 Atomic Visual Abilities(AVAs) -- foundational skills like localization, depth estimation, and spatialunderstanding that collectively support complex visual reasoning tasks. Bydecoupling AVAs and matching training and test distributions within each,AVA-Bench pinpoints exactly where a VFM excels or falters. Applying AVA-Benchto leading VFMs thus reveals distinctive "ability fingerprints," turning VFMselection from educated guesswork into principled engineering. Notably, we findthat a 0.5B LLM yields similar VFM rankings as a 7B LLM while cutting GPU hoursby 8x, enabling more efficient evaluation. By offering a comprehensive andtransparent benchmark, we hope AVA-Bench lays the foundation for the nextgeneration of VFMs.</description>
      <author>example@mail.com (Zheda Mai, Arpita Chowdhury, Zihe Wang, Sooyoung Jeon, Lemeng Wang, Jiacheng Hou, Jihyung Kil, Wei-Lun Chao)</author>
      <guid isPermaLink="false">2506.09082v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>GIQ: Benchmarking 3D Geometric Reasoning of Vision Foundation Models with Simulated and Real Polyhedra</title>
      <link>http://arxiv.org/abs/2506.08194v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GIQ的基准测试，旨在评估视觉和视觉语言基础模型在几何推理方面的能力，并揭示了当前模型在几何理解上的不足。&lt;h4&gt;背景&lt;/h4&gt;虽然单目3D重建方法和视觉语言模型在标准基准测试中表现出色，但它们对几何特性的真正理解尚不明确。&lt;h4&gt;目的&lt;/h4&gt;设计GIQ基准测试，以评估视觉和视觉语言基础模型的几何推理能力。&lt;h4&gt;方法&lt;/h4&gt;GIQ包含合成和真实世界图像，涵盖224种不同的多面体，包括柏拉图、阿基米德、约翰逊和卡塔兰多面体，以及星形和复合形状，覆盖不同复杂度和对称性级别。通过进行单目3D重建、3D对称性检测、心理旋转测试和零样本形状分类任务等系统性实验。&lt;h4&gt;主要发现&lt;/h4&gt;当前模型在重建基本几何形状时存在显著不足；基础模型在通过线性探测检测特定3D对称元素方面表现良好，但在需要详细几何区分的任务（如心理旋转）上表现不佳；高级视觉语言助手在复杂多面体上的准确率极低，系统性误解了基本属性，如面几何、凸性和复合结构。&lt;h4&gt;结论&lt;/h4&gt;GIQ是一个公开可用的平台，可以突出并解决几何智能中的关键差距，促进稳健、具有几何感知的表示学习方面的未来进步。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a benchmark named GIQ, specifically designed to evaluate the geometric reasoning capabilities of visual and visual language foundation models, and reveals the significant shortcomings of current models in geometric understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular 3D reconstruction methods and vision-language models (VLMs)demonstrate impressive results on standard benchmarks, yet their trueunderstanding of geometric properties remains unclear. We introduce GIQ , acomprehensive benchmark specifically designed to evaluate the geometricreasoning capabilities of vision and vision-language foundation models. GIQcomprises synthetic and real-world images of 224 diverse polyhedra - includingPlatonic, Archimedean, Johnson, and Catalan solids, as well as stellations andcompound shapes - covering varying levels of complexity and symmetry. Throughsystematic experiments involving monocular 3D reconstruction, 3D symmetrydetection, mental rotation tests, and zero-shot shape classification tasks, wereveal significant shortcomings in current models. State-of-the-artreconstruction algorithms trained on extensive 3D datasets struggle toreconstruct even basic geometric forms accurately. While foundation modelseffectively detect specific 3D symmetry elements via linear probing, theyfalter significantly in tasks requiring detailed geometric differentiation,such as mental rotation. Moreover, advanced vision-language assistants exhibitremarkably low accuracy on complex polyhedra, systematically misinterpretingbasic properties like face geometry, convexity, and compound structures. GIQ ispublicly available, providing a structured platform to highlight and addresscritical gaps in geometric intelligence, facilitating future progress inrobust, geometry-aware representation learning.</description>
      <author>example@mail.com (Mateusz Michalkiewicz, Anekha Sokhal, Tadeusz Michalkiewicz, Piotr Pawlikowski, Mahsa Baktashmotlagh, Varun Jampani, Guha Balakrishnan)</author>
      <guid isPermaLink="false">2506.08194v2</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>VersaVid-R1: A Versatile Video Understanding and Reasoning Model from Question Answering to Captioning Tasks</title>
      <link>http://arxiv.org/abs/2506.09079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了DarkEventInfer和MixVidQA两个新型数据集，旨在提升视频推理模型的能力，并提出了VersaVid-R1模型，在视频理解与推理方面取得了显著成果。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型在图像推理方面取得了成功，但视频推理仍处于发展阶段，主要由于高质量推理数据稀缺和训练方法不足。&lt;h4&gt;目的&lt;/h4&gt;弥补视频推理领域的不足，提升模型的高级视频理解和推理能力。&lt;h4&gt;方法&lt;/h4&gt;提出DarkEventInfer和MixVidQA数据集，通过强化学习和多样化的奖励函数训练VersaVid-R1模型。&lt;h4&gt;主要发现&lt;/h4&gt;DarkEventInfer要求模型根据上下文视频线索推断遮挡内容，MixVidQA则挑战模型在处理交错视频序列时忽略一部分内容。&lt;h4&gt;结论&lt;/h4&gt;VersaVid-R1在视频理解、认知推理和视频字幕任务上显著优于现有模型。&lt;h4&gt;翻译&lt;/h4&gt;Recent advancements in multimodal large language models have successfully extended the Reason-Then-Respond paradigm to image-based reasoning, yet video-based reasoning remains an underdeveloped frontier, primarily due to the scarcity of high-quality reasoning-oriented data and effective training methodologies. To bridge this gap, we introduce DarkEventInfer and MixVidQA, two novel datasets specifically designed to stimulate the model's advanced video understanding and reasoning abilities. DarkEventinfer presents videos with masked event segments, requiring models to infer the obscured content based on contextual video cues. MixVidQA, on the other hand, presents interleaved video sequences composed of two distinct clips, challenging models to isolate and reason about one while disregarding the other. Leveraging these carefully curated training samples together with reinforcement learning guided by diverse reward functions, we develop VersaVid-R1, the first versatile video understanding and reasoning model under the Reason-Then-Respond paradigm capable of handling multiple-choice and open-ended question answering, as well as video captioning tasks. Extensive experiments demonstrate that VersaVid-R1 significantly outperforms existing models across a broad spectrum of benchmarks, covering video general understanding, cognitive reasoning, and captioning tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in multimodal large language models have successfullyextended the Reason-Then-Respond paradigm to image-based reasoning, yetvideo-based reasoning remains an underdeveloped frontier, primarily due to thescarcity of high-quality reasoning-oriented data and effective trainingmethodologies. To bridge this gap, we introduce DarkEventInfer and MixVidQA,two novel datasets specifically designed to stimulate the model's advancedvideo understanding and reasoning abilities. DarkEventinfer presents videoswith masked event segments, requiring models to infer the obscured contentbased on contextual video cues. MixVidQA, on the other hand, presentsinterleaved video sequences composed of two distinct clips, challenging modelsto isolate and reason about one while disregarding the other. Leveraging thesecarefully curated training samples together with reinforcement learning guidedby diverse reward functions, we develop VersaVid-R1, the first versatile videounderstanding and reasoning model under the Reason-Then-Respond paradigmcapable of handling multiple-choice and open-ended question answering, as wellas video captioning tasks. Extensive experiments demonstrate that VersaVid-R1significantly outperforms existing models across a broad spectrum ofbenchmarks, covering video general understanding, cognitive reasoning, andcaptioning tasks.</description>
      <author>example@mail.com (Xinlong Chen, Yuanxing Zhang, Yushuo Guan, Bohan Zeng, Yang Shi, Sihan Yang, Pengfei Wan, Qiang Liu, Liang Wang, Tieniu Tan)</author>
      <guid isPermaLink="false">2506.09079v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>Machine Learning the 6d Supergravity Landscape</title>
      <link>http://arxiv.org/abs/2505.16131v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  49 pages; code and data available at  https://github.com/nait400/ML-6d-sugra-landscape&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文应用监督和未监督的机器学习算法研究了六维弦景观和沼泽地，数据来自几乎无异常的六维N=(1,0)超引力模型，特征为异常系数的Gram矩阵。研究展示了机器学习算法在高效学习景观和沼泽地复杂特征方面的能力。&lt;h4&gt;背景&lt;/h4&gt;研究基于六维超引力理论中的弦景观和沼泽地，使用N=(1,0)超引力模型的Gram矩阵数据。&lt;h4&gt;目的&lt;/h4&gt;探索机器学习算法在理解六维超引力理论的景观和沼泽地方面的应用潜力。&lt;h4&gt;方法&lt;/h4&gt;使用自动编码器进行无监督学习，通过将Gram矩阵数据压缩到二维来进行模型自动分类。同时，使用监督学习建立两个分类器，预测模型在探针弦插入下的一致性和在异常流入下的不一致性。&lt;h4&gt;主要发现&lt;/h4&gt;自动编码器通过压缩数据将相似模型聚类，并识别了这些聚类的显著特征。它还识别了难以重建的异常模型，其中一种模型难以与其他模型结合以消除$ext{tr}R^{4}$异常，表明其在景观中的存在极为罕见。监督学习分类器准确预测了模型的一致性和不一致性。将预测投影到自动编码器的二维潜在层上，显示了一致模型聚类，表明自动编码器学习了模型的有趣且复杂的特征。&lt;h4&gt;结论&lt;/h4&gt;机器学习算法能够有效学习六维超引力理论的景观和沼泽地的复杂特征，为理解和映射这些理论提供了新的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nait400/ml-6d-sugra-landscape&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we apply both supervised and unsupervised machine learningalgorithms to the study of the string landscape and swampland in 6-dimensions.Our data are the (almost) anomaly-free 6-dimensional $\mathcal{N} = (1,0)$supergravity models, characterised by the Gram matrix of anomaly coefficients.Our work demonstrates the ability of machine learning algorithms to efficientlylearn highly complex features of the landscape and swampland. Employing anautoencoder for unsupervised learning, we provide an auto-classification ofthese models by compressing the Gram matrix data to 2-dimensions. Throughcompression, similar models cluster together, and we identify prominentfeatures of these clusters. The autoencoder also identifies outlier modelswhich are difficult to reconstruct. One of these outliers proves to beincredibly difficult to combine with other models such that the$\text{tr}R^{4}$ anomaly vanishes, making its presence in the landscapeextremely rare. Further, we utilise supervised learning to build twoclassifiers predicting (1) model consistency under probe string insertion(precision: 0.78, predicting consistency for 214,837 models with reasonablecertainty) and (2) inconsistency under anomaly inflow (precision: 0.91,predicting inconsistency for 1,909,359 models). Notably, projecting thesepredictions onto the autoencoder's 2-dimensional latent layer shows consistentmodels clustering together, further indicating that the autoencoder has learntinteresting and complex features of the set of models and potentially offers anovel approach to mapping the landscape and swampland of 6-dimensionalsupergravity theories.</description>
      <author>example@mail.com (Nathan Brady, David Tennyson, Thomas Vandermeulen)</author>
      <guid isPermaLink="false">2505.16131v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
  <item>
      <title>Polar Hierarchical Mamba: Towards Streaming LiDAR Object Detection with Point Clouds as Egocentric Sequences</title>
      <link>http://arxiv.org/abs/2506.06944v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Polar Hierarchical Mamba (PHiM)的新颖状态空间模型，旨在提高极坐标下流式处理的LiDAR感知效率。&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶领域，准确且高效的目标检测至关重要，而实时感知需要低延迟和高吞吐量。LiDAR传感器提供鲁棒的深度信息，但传统方法处理360度全扫描需要较长时间。&lt;h4&gt;目的&lt;/h4&gt;提出PHiM以解决传统方法在处理全扫描时的延迟问题，并提高流式处理的性能。&lt;h4&gt;方法&lt;/h4&gt;PHiM使用局部双向Mamba块进行区间内空间编码，全局正向Mamba进行区间间时间建模，并使用扭曲感知的、维分解的操作来替代卷积和位置编码。&lt;h4&gt;主要发现&lt;/h4&gt;PHiM在Waymo Open Dataset上达到了流式检测的最新水平，比之前的最佳方法提高了10%，并且在吞吐量上是全扫描基线的两倍。&lt;h4&gt;结论&lt;/h4&gt;PHiM是一种适用于极坐标流式处理的LiDAR感知的新架构，具有显著性能提升。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Accurate and efficient object detection is essential for autonomous vehicles, where real-time perception requires low latency and high throughput. LiDAR sensors provide robust depth information, but conventional methods process full 360° scans in a single pass, introducing significant delay. Streaming approaches address this by sequentially processing partial scans in the native polar coordinate system, yet they rely on translation-invariant convolutions that are misaligned with polar geometry -- resulting in degraded performance or requiring complex distortion mitigation. Recent Mamba-based state space models (SSMs) have shown promise for LiDAR perception, but only in the full-scan setting, relying on geometric serialization and positional embeddings that are memory-intensive and ill-suited to streaming. We propose Polar Hierarchical Mamba (PHiM), a novel SSM architecture designed for polar-coordinate streaming LiDAR. PHiM uses local bidirectional Mamba blocks for intra-sector spatial encoding and a global forward Mamba for inter-sector temporal modeling, replacing convolutions and positional encodings with distortion-aware, dimensionally-decomposed operations. PHiM sets a new state-of-the-art among streaming detectors on the Waymo Open Dataset, outperforming the previous best by 10% and matching full-scan baselines at twice the throughput. Code will be available at https://github.com/meilongzhang/Polar-Hierarchical-Mamba .&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and efficient object detection is essential for autonomous vehicles,where real-time perception requires low latency and high throughput. LiDARsensors provide robust depth information, but conventional methods process full360{\deg} scans in a single pass, introducing significant delay. Streamingapproaches address this by sequentially processing partial scans in the nativepolar coordinate system, yet they rely on translation-invariant convolutionsthat are misaligned with polar geometry -- resulting in degraded performance orrequiring complex distortion mitigation. Recent Mamba-based state space models(SSMs) have shown promise for LiDAR perception, but only in the full-scansetting, relying on geometric serialization and positional embeddings that arememory-intensive and ill-suited to streaming. We propose Polar HierarchicalMamba (PHiM), a novel SSM architecture designed for polar-coordinate streamingLiDAR. PHiM uses local bidirectional Mamba blocks for intra-sector spatialencoding and a global forward Mamba for inter-sector temporal modeling,replacing convolutions and positional encodings with distortion-aware,dimensionally-decomposed operations. PHiM sets a new state-of-the-art amongstreaming detectors on the Waymo Open Dataset, outperforming the previous bestby 10\% and matching full-scan baselines at twice the throughput. Code will beavailable at https://github.com/meilongzhang/Polar-Hierarchical-Mamba .</description>
      <author>example@mail.com (Mellon M. Zhang, Glen Chou, Saibal Mukhopadhyay)</author>
      <guid isPermaLink="false">2506.06944v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Generative Vehicle Trajectory Models for Traffic Intersection Dynamics</title>
      <link>http://arxiv.org/abs/2506.08963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于交通信号交叉口交通动态的深度生成模型，以帮助交通管理部门更好地理解交通效率和安全性。&lt;h4&gt;背景&lt;/h4&gt;交通交叉口是城市道路网络的重要组成部分，但同时也是事故多发区域。&lt;h4&gt;目的&lt;/h4&gt;开发一个综合分析工具，使用更符合交通工程实际的指标来训练、运行和评估交通模型。&lt;h4&gt;方法&lt;/h4&gt;在大型数据集上训练了先进的车辆轨迹预测模型，并在微观模拟器中对预测模型进行在线评估，以模拟未见过的交通条件。&lt;h4&gt;主要发现&lt;/h4&gt;尽管使用了理想行为的轨迹作为输入并实现了低轨迹重建误差，但生成的轨迹表现出违反交通规则的行为。&lt;h4&gt;结论&lt;/h4&gt;引入了新的指标来评估这些不期望的行为，并展示了相关结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：城市道路网络中的交叉口对于调节人员和货物的流动至关重要。然而，它们是冲突轨迹的区域，容易发生事故。信号交叉口交通动态的深度生成模型可以极大地帮助交通管理部门更好地理解效率和安全性方面。目前，模型主要在计算指标上评估，这些指标主要关注轨迹重建误差。它们没有在实时微观模拟场景中进行在线评估。此外，这些指标没有充分考虑到交通工程特定的关注点，如闯红灯、不允许停车等。在这项工作中，我们提供了一个综合分析工具，用于使用提供更好模型性能洞察的指标来训练、运行和评估模型。我们在收集到的大量数据集上训练了一个最先进的车辆轨迹预测模型，该数据集是通过运行现实世界城市交叉口的校准场景获得的。然后，我们在微观模拟器中在线评估了预测模型在未见过的交通条件下的性能。我们表明，尽管使用了理想行为的轨迹作为输入，并实现了低轨迹重建误差，但生成的轨迹表现出违反交通规则的行为。我们引入了新的指标来评估这种不期望的行为，并展示了我们的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic Intersections are vital to urban road networks as they regulate themovement of people and goods. However, they are regions of conflictingtrajectories and are prone to accidents. Deep Generative models of trafficdynamics at signalized intersections can greatly help traffic authoritiesbetter understand the efficiency and safety aspects. At present, models areevaluated on computational metrics that primarily look at trajectoryreconstruction errors. They are not evaluated online in a `live'microsimulation scenario. Further, these metrics do not adequately considertraffic engineering-specific concerns such as red-light violations, unallowedstoppage, etc. In this work, we provide a comprehensive analytics tool totrain, run, and evaluate models with metrics that give better insights intomodel performance from a traffic engineering point of view. We train astate-of-the-art multi-vehicle trajectory forecasting model on a large datasetcollected by running a calibrated scenario of a real-world urban intersection.We then evaluate the performance of the prediction models, online in amicrosimulator, under unseen traffic conditions. We show that despite usingideally-behaved trajectories as input, and achieving low trajectoryreconstruction errors, the generated trajectories show behaviors that breaktraffic rules. We introduce new metrics to evaluate such undesired behaviorsand present our results.</description>
      <author>example@mail.com (Yash Ranjan, Rahul Sengupta, Anand Rangarajan, Sanjay Ranka)</author>
      <guid isPermaLink="false">2506.08963v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Deploying SICNav in the Field: Safe and Interactive Crowd Navigation using MPC and Bilevel Optimization</title>
      <link>http://arxiv.org/abs/2506.08851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 2025 IEEE ICRA Workshop on Field Robotics  (non-archival)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种安全且高效的拥挤环境导航方法，用于执行如食物配送或自动轮椅移动等服务任务的机器人。&lt;h4&gt;背景&lt;/h4&gt;传统的机器人拥挤环境导航方法将人类运动预测与机器人运动规划分离，忽略了人类与机器人之间的闭环交互。&lt;h4&gt;目的&lt;/h4&gt;提出了一种名为SICNav的安全和交互式拥挤导航方法，它是一个双层模型预测控制框架，将预测和规划合并为一个优化问题，并明确地建模了代理之间的交互。&lt;h4&gt;方法&lt;/h4&gt;介绍了用于部署SICNav的系统概述，该系统在室内和室外环境中部署，并提供了系统在近7公里、两小时自主导航过程中的初步分析。&lt;h4&gt;主要发现&lt;/h4&gt;SICNav方法能够有效处理人类与机器人之间的交互，避免了机器人因人类反应不当而卡住的问题。&lt;h4&gt;结论&lt;/h4&gt;SICNav方法在室内和室外环境中均表现出良好的导航性能，为机器人服务任务在拥挤环境中的导航提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Safe and efficient navigation in crowded environments remains a critical challenge for robots that provide a variety of service tasks such as food delivery or autonomous wheelchair mobility. Classical robot crowd navigation methods decouple human motion prediction from robot motion planning, which neglects the closed-loop interactions between humans and robots. This lack of a model for human reactions to the robot plan (e.g. moving out of the way) can cause the robot to get stuck. Our proposed Safe and Interactive Crowd Navigation (SICNav) method is a bilevel Model Predictive Control (MPC) framework that combines prediction and planning into one optimization problem, explicitly modeling interactions among agents. In this paper, we present a systems overview of the crowd navigation platform we use to deploy SICNav in previously unseen indoor and outdoor environments. We provide a preliminary analysis of the system's operation over the course of nearly 7 km of autonomous navigation over two hours in both indoor and outdoor environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Safe and efficient navigation in crowded environments remains a criticalchallenge for robots that provide a variety of service tasks such as fooddelivery or autonomous wheelchair mobility. Classical robot crowd navigationmethods decouple human motion prediction from robot motion planning, whichneglects the closed-loop interactions between humans and robots. This lack of amodel for human reactions to the robot plan (e.g. moving out of the way) cancause the robot to get stuck. Our proposed Safe and Interactive CrowdNavigation (SICNav) method is a bilevel Model Predictive Control (MPC)framework that combines prediction and planning into one optimization problem,explicitly modeling interactions among agents. In this paper, we present asystems overview of the crowd navigation platform we use to deploy SICNav inpreviously unseen indoor and outdoor environments. We provide a preliminaryanalysis of the system's operation over the course of nearly 7 km of autonomousnavigation over two hours in both indoor and outdoor environments.</description>
      <author>example@mail.com (Sepehr Samavi, Garvish Bhutani, Florian Shkurti, Angela P. Schoellig)</author>
      <guid isPermaLink="false">2506.08851v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Diffuse and Disperse: Image Generation with Representation Regularization</title>
      <link>http://arxiv.org/abs/2506.09027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Dispersive Loss的简单正则化器，用于提升基于扩散的生成模型。该方法通过鼓励内部表示在隐藏空间中分散，类似于对比自监督学习，但无需正样本对，不干扰回归过程中的采样。&lt;h4&gt;背景&lt;/h4&gt;过去十年中，基于扩散的生成模型的发展与表示学习进展独立。这些模型通常依赖于基于回归的目标，并且通常缺乏显式正则化。&lt;h4&gt;目的&lt;/h4&gt;提出Dispersive Loss正则化器，有效提升基于扩散的生成模型。&lt;h4&gt;方法&lt;/h4&gt;Dispersive Loss正则化器，通过鼓励内部表示在隐藏空间中分散，类似于对比自监督学习，但无需正样本对。&lt;h4&gt;主要发现&lt;/h4&gt;Dispersive Loss在ImageNet数据集上对多种模型进行了评估，与广泛使用的强大基线相比，报告了持续改进。&lt;h4&gt;结论&lt;/h4&gt;Dispersive Loss有助于弥合生成建模与表示学习之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of diffusion-based generative models over the past decade haslargely proceeded independently of progress in representation learning. Thesediffusion models typically rely on regression-based objectives and generallylack explicit regularization. In this work, we propose \textit{DispersiveLoss}, a simple plug-and-play regularizer that effectively improvesdiffusion-based generative models. Our loss function encourages internalrepresentations to disperse in the hidden space, analogous to contrastiveself-supervised learning, with the key distinction that it requires no positivesample pairs and therefore does not interfere with the sampling process usedfor regression. Compared to the recent method of representation alignment(REPA), our approach is self-contained and minimalist, requiring nopre-training, no additional parameters, and no external data. We evaluateDispersive Loss on the ImageNet dataset across a range of models and reportconsistent improvements over widely used and strong baselines. We hope our workwill help bridge the gap between generative modeling and representationlearning.</description>
      <author>example@mail.com (Runqian Wang, Kaiming He)</author>
      <guid isPermaLink="false">2506.09027v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Do MIL Models Transfer?</title>
      <link>http://arxiv.org/abs/2506.09022v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 (Spotlight). 20 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究评估了预训练的MIL模型在转移学习方面的能力，结果表明这些模型在处理临床数据时具有很好的适应性和性能提升。&lt;h4&gt;背景&lt;/h4&gt;MIL在计算病理学中用于生成临床有意义的组织图像嵌入，但在小规模、弱监督的数据集上表现不佳。与NLP和传统计算机视觉不同，MIL模型的迁移性理解不足。&lt;h4&gt;目的&lt;/h4&gt;系统评估预训练MIL模型的迁移学习能力，通过比较11个模型在21个预训练任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;评估了11个预训练MIL模型在形态和分子亚型预测任务上的表现，并比较了这些模型与从头开始训练的模型。&lt;h4&gt;主要发现&lt;/h4&gt;预训练MIL模型在不同器官上训练时仍能优于从头开始训练的模型；在跨器官和任务上的预训练可以显著提高泛化能力，并使用更少的数据。&lt;h4&gt;结论&lt;/h4&gt;这些发现突出了MIL模型的鲁棒适应性和利用迁移学习在计算病理学中提升性能的益处。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多实例学习（MIL）是计算病理学中从千兆像素的组织图像中生成临床有意义的切片级嵌入的基础方法。然而，MIL往往在小规模、弱监督的临床数据集上表现不佳。与NLP和传统计算机视觉领域不同，迁移学习被广泛用于解决数据稀缺问题，但MIL模型的迁移性仍然理解不足。在本研究中，我们系统地评估了预训练MIL模型的迁移学习能力，通过评估11个模型在21个预训练任务上的表现。我们的结果表明，即使在这些模型在目标任务不同的器官上进行了训练，预训练MIL模型也始终优于从头开始训练的模型。此外，在泛癌症数据集上进行预训练能够实现跨器官和任务的强大泛化能力，同时使用大量更少的预训练数据。这些发现突出了MIL模型的鲁棒适应能力，并证明了在计算病理学中利用迁移学习来提升性能的益处。最后，我们提供了一种资源，该资源标准化了MIL模型在流行计算病理学任务上的实现和预训练模型权重的收集，可在https://github.com/mahmoodlab/MIL-Lab获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multiple Instance Learning (MIL) is a cornerstone approach in computationalpathology (CPath) for generating clinically meaningful slide-level embeddingsfrom gigapixel tissue images. However, MIL often struggles with small, weaklysupervised clinical datasets. In contrast to fields such as NLP andconventional computer vision, where transfer learning is widely used to addressdata scarcity, the transferability of MIL models remains poorly understood. Inthis study, we systematically evaluate the transfer learning capabilities ofpretrained MIL models by assessing 11 models across 21 pretraining tasks formorphological and molecular subtype prediction. Our results show thatpretrained MIL models, even when trained on different organs than the targettask, consistently outperform models trained from scratch. Moreover,pretraining on pancancer datasets enables strong generalization across organsand tasks, outperforming slide foundation models while using substantially lesspretraining data. These findings highlight the robust adaptability of MILmodels and demonstrate the benefits of leveraging transfer learning to boostperformance in CPath. Lastly, we provide a resource which standardizes theimplementation of MIL models and collection of pretrained model weights onpopular CPath tasks, available at https://github.com/mahmoodlab/MIL-Lab</description>
      <author>example@mail.com (Daniel Shao, Richard J. Chen, Andrew H. Song, Joel Runevic, Ming Y. Lu, Tong Ding, Faisal Mahmood)</author>
      <guid isPermaLink="false">2506.09022v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Gaussian2Scene: 3D Scene Representation Learning via Self-supervised Learning with 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.08777v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Gaussian2Scene的新型场景级自监督学习框架，用于点云预训练，以提高3D视觉任务的效果。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在点云预训练中成为3D视觉任务的基础，通过从大规模未标注数据中学习，提高模型性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种更有效的场景级自监督学习框架，以解决现有方法依赖于隐式场景表示和高内存需求，以及未能捕捉到3D几何结构的局限性。&lt;h4&gt;方法&lt;/h4&gt;Gaussian2Scene利用3D高斯分层（3DGS）的效率和显式性质进行预训练，采用渐进式两阶段训练策略，第一阶段学习2D和3D场景表示，第二阶段使用重建的点云和几何原始体的几何位置以及渲染的RGB图像进行监督学习。&lt;h4&gt;主要发现&lt;/h4&gt;Gaussian2Scene在多个下游3D目标检测任务中表现出色，与现有预训练方法相比，效果一致且有所提升。&lt;h4&gt;结论&lt;/h4&gt;Gaussian2Scene通过改进预训练方法，提高了3D视觉任务的效果，尤其是在几何理解和跨模态学习方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) for point cloud pre-training has become acornerstone for many 3D vision tasks, enabling effective learning fromlarge-scale unannotated data. At the scene level, existing SSL methods oftenincorporate volume rendering into the pre-training framework, using RGB-Dimages as reconstruction signals to facilitate cross-modal learning. Thisstrategy promotes alignment between 2D and 3D modalities and enables the modelto benefit from rich visual cues in the RGB-D inputs. However, these approachesare limited by their reliance on implicit scene representations and high memorydemands. Furthermore, since their reconstruction objectives are applied only in2D space, they often fail to capture underlying 3D geometric structures. Toaddress these challenges, we propose Gaussian2Scene, a novel scene-level SSLframework that leverages the efficiency and explicit nature of 3D GaussianSplatting (3DGS) for pre-training. The use of 3DGS not only alleviates thecomputational burden associated with volume rendering but also supports direct3D scene reconstruction, thereby enhancing the geometric understanding of thebackbone network. Our approach follows a progressive two-stage trainingstrategy. In the first stage, a dual-branch masked autoencoder learns both 2Dand 3D scene representations. In the second stage, we initialize training withreconstructed point clouds and further supervise learning using the geometriclocations of Gaussian primitives and rendered RGB images. This processreinforces both geometric and cross-modal learning. We demonstrate theeffectiveness of Gaussian2Scene across several downstream 3D object detectiontasks, showing consistent improvements over existing pre-training methods.</description>
      <author>example@mail.com (Keyi Liu, Weidong Yang, Ben Fei, Ying He)</author>
      <guid isPermaLink="false">2506.08777v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>TrajFlow: Multi-modal Motion Prediction via Flow Matching</title>
      <link>http://arxiv.org/abs/2506.08541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TrajFlow是一个基于流匹配的运动预测框架，用于解决现有生成轨迹预测方法的可扩展性和效率问题，并在Waymo Open Motion Dataset上表现出色。&lt;h4&gt;背景&lt;/h4&gt;高效准确的运动预测对于自动驾驶安全及决策至关重要，尤其在动态的真实世界条件下需要多模态预测。&lt;h4&gt;目的&lt;/h4&gt;提出TrajFlow，解决现有生成轨迹预测方法的可扩展性和效率挑战。&lt;h4&gt;方法&lt;/h4&gt;1. 采用单次预测多个可能轨迹的方法，减少计算开销。2. 提出基于Plackett-Luce分布的排名损失函数，提高预测轨迹的不确定性估计。3. 设计自条件化训练技术，通过模型自身预测构造噪声输入，提升泛化能力和加速推理。&lt;h4&gt;主要发现&lt;/h4&gt;TrajFlow在Waymo Open Motion Dataset上实现了在多个关键指标上的最先进性能。&lt;h4&gt;结论&lt;/h4&gt;TrajFlow对于安全关键型自动驾驶应用是有效的。&lt;h4&gt;翻译&lt;/h4&gt;Efficient and accurate motion prediction is crucial for ensuring safety and informed decision-making in autonomous driving, particularly under dynamic real-world conditions that necessitate multi-modal forecasts. We introduce TrajFlow, a novel flow matching-based motion prediction framework that addresses the scalability and efficiency challenges of existing generative trajectory prediction methods. Unlike conventional generative approaches that employ i.i.d. sampling and require multiple inference passes to capture diverse outcomes, TrajFlow predicts multiple plausible future trajectories in a single pass, significantly reducing computational overhead while maintaining coherence across predictions. Moreover, we propose a ranking loss based on the Plackett-Luce distribution to improve uncertainty estimation of predicted trajectories. Additionally, we design a self-conditioning training techniquethat reuses the model's own predictions to construct noisy inputs during a second forward pass, thereby improving generalization and accelerating inference. Extensive experiments on the large-scale Waymo Open Motion Dataset (WOMD) demonstrate that TrajFlow achieves state-of-the-art performance across various key metrics, underscoring its effectiveness for safety-critical autonomous driving applications. The code and other details are available on the project website https://traj-flow.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient and accurate motion prediction is crucial for ensuring safety andinformed decision-making in autonomous driving, particularly under dynamicreal-world conditions that necessitate multi-modal forecasts. We introduceTrajFlow, a novel flow matching-based motion prediction framework thataddresses the scalability and efficiency challenges of existing generativetrajectory prediction methods. Unlike conventional generative approaches thatemploy i.i.d. sampling and require multiple inference passes to capture diverseoutcomes, TrajFlow predicts multiple plausible future trajectories in a singlepass, significantly reducing computational overhead while maintaining coherenceacross predictions. Moreover, we propose a ranking loss based on thePlackett-Luce distribution to improve uncertainty estimation of predictedtrajectories. Additionally, we design a self-conditioning training techniquethat reuses the model's own predictions to construct noisy inputs during asecond forward pass, thereby improving generalization and acceleratinginference. Extensive experiments on the large-scale Waymo Open Motion Dataset(WOMD) demonstrate that TrajFlow achieves state-of-the-art performance acrossvarious key metrics, underscoring its effectiveness for safety-criticalautonomous driving applications. The code and other details are available onthe project website https://traj-flow.github.io/.</description>
      <author>example@mail.com (Qi Yan, Brian Zhang, Yutong Zhang, Daniel Yang, Joshua White, Di Chen, Jiachao Liu, Langechuan Liu, Binnan Zhuang, Shaoshuai Shi, Renjie Liao)</author>
      <guid isPermaLink="false">2506.08541v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Cosmos-Drive-Dreams: Scalable Synthetic Driving Data Generation with World Foundation Models</title>
      <link>http://arxiv.org/abs/2506.09042v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Xuanchi Ren, Yifan Lu, Tianshi Cao, Ruiyuan Gao: Equal contribution.  Only the core contributors are listed. The full list of contributors can be  found in Appendix A of this paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Cosmos-Drive-Dreams的合成数据生成（SDG）流程，旨在为自动驾驶（AV）系统等关键物理AI系统生成具有挑战性的场景，以促进感知和驾驶策略训练等下游任务。&lt;h4&gt;背景&lt;/h4&gt;收集和注释用于安全关键物理AI系统（如自动驾驶汽车）的真实世界数据既耗时又昂贵，尤其是捕捉罕见边缘情况，这些情况在AV系统的训练和测试中起着关键作用。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，目的是生成具有挑战性的场景，以促进下游任务，如感知和驾驶策略训练。&lt;h4&gt;方法&lt;/h4&gt;Cosmos-Drive-Dreams流程由Cosmos-Drive支持，这是一个从NVIDIA Cosmos世界基础模型专门针对驾驶领域优化的模型套件，能够生成可控、高保真、多视角和时空一致性的驾驶视频。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，生成的数据有助于缓解长尾分布问题，并增强了下游任务（如3D车道检测、3D物体检测和驾驶策略学习）的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文开源了Cosmos-Drive-Dreams的流程工具包、数据集和模型权重，通过NVIDIA的Cosmos平台提供。&lt;h4&gt;翻译&lt;/h4&gt;Collecting and annotating real-world data for safety-critical physical AI systems, such as Autonomous Vehicle (AV), is time-consuming and costly. It is especially challenging to capture rare edge cases, which play a critical role in training and testing of an AV system. To address this challenge, we introduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipeline that aims to generate challenging scenarios to facilitate downstream tasks such as perception and driving policy training. Powering this pipeline is Cosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundation model for the driving domain and are capable of controllable, high-fidelity, multi-view, and spatiotemporally consistent driving video generation. We showcase the utility of these models by applying Cosmos-Drive-Dreams to scale the quantity and diversity of driving datasets with high-fidelity and challenging scenarios. Experimentally, we demonstrate that our generated data helps in mitigating long-tail distribution problems and enhances generalization in downstream tasks such as 3D lane detection, 3D object detection and driving policy learning. We open source our pipeline toolkit, dataset and model weight through the NVIDIA's Cosmos platform.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Collecting and annotating real-world data for safety-critical physical AIsystems, such as Autonomous Vehicle (AV), is time-consuming and costly. It isespecially challenging to capture rare edge cases, which play a critical rolein training and testing of an AV system. To address this challenge, weintroduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipelinethat aims to generate challenging scenarios to facilitate downstream tasks suchas perception and driving policy training. Powering this pipeline isCosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundationmodel for the driving domain and are capable of controllable, high-fidelity,multi-view, and spatiotemporally consistent driving video generation. Weshowcase the utility of these models by applying Cosmos-Drive-Dreams to scalethe quantity and diversity of driving datasets with high-fidelity andchallenging scenarios. Experimentally, we demonstrate that our generated datahelps in mitigating long-tail distribution problems and enhances generalizationin downstream tasks such as 3D lane detection, 3D object detection and drivingpolicy learning. We open source our pipeline toolkit, dataset and model weightsthrough the NVIDIA's Cosmos platform.  Project page: https://research.nvidia.com/labs/toronto-ai/cosmos_drive_dreams</description>
      <author>example@mail.com (Xuanchi Ren, Yifan Lu, Tianshi Cao, Ruiyuan Gao, Shengyu Huang, Amirmojtaba Sabour, Tianchang Shen, Tobias Pfaff, Jay Zhangjie Wu, Runjian Chen, Seung Wook Kim, Jun Gao, Laura Leal-Taixe, Mike Chen, Sanja Fidler, Huan Ling)</author>
      <guid isPermaLink="false">2506.09042v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Data-Efficient Challenges in Visual Inductive Priors: A Retrospective</title>
      <link>http://arxiv.org/abs/2506.08612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在数据不足的设置中，哪些深度学习方法能够提高模型的训练效果。&lt;h4&gt;背景&lt;/h4&gt;深度学习需要大量数据来训练模型，但在数据不足的情况下，模型的性能可能会下降。&lt;h4&gt;目的&lt;/h4&gt;通过组织“VIPriors：视觉归纳先验用于数据高效深度学习”研讨会系列，旨在刺激新型方法的发展，这些方法通过结合先验知识来提高深度学习模型的数据效率。&lt;h4&gt;方法&lt;/h4&gt;研讨会包括四届数据受损挑战赛，参与者只能使用少量训练样本从头开始训练模型，并且不允许使用任何形式的迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;成功的挑战参赛作品使用了混合Transformer和CNN的大规模模型集成，以及大量的数据增强。基于新先验知识的方法在某些参赛作品中取得了成功。&lt;h4&gt;结论&lt;/h4&gt;数据不足的环境下，深度学习模型可以通过结合先验知识和创新的模型集成方法来提高数据效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep Learning requires large amounts of data to train models that work well.In data-deficient settings, performance can be degraded. We investigate whichDeep Learning methods benefit training models in a data-deficient setting, byorganizing the "VIPriors: Visual Inductive Priors for Data-Efficient DeepLearning" workshop series, featuring four editions of data-impaired challenges.These challenges address the problem of training deep learning models forcomputer vision tasks with limited data. Participants are limited to trainingmodels from scratch using a low number of training samples and are not allowedto use any form of transfer learning. We aim to stimulate the development ofnovel approaches that incorporate prior knowledge to improve the dataefficiency of deep learning models. Successful challenge entries make use oflarge model ensembles that mix Transformers and CNNs, as well as heavy dataaugmentation. Novel prior knowledge-based methods contribute to success in someentries.</description>
      <author>example@mail.com (Robert-Jan Bruintjes, Attila Lengyel, Osman Semih Kayhan, Davide Zambrano, Nergis Tömen, Hadi Jamali-Rad, Jan van Gemert)</author>
      <guid isPermaLink="false">2506.08612v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Effective Data Pruning through Score Extrapolation</title>
      <link>http://arxiv.org/abs/2506.09010v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的数据剪枝技术，通过在小数据集上训练来预测整个数据集的样本重要性，从而在保持模型性能的同时减少计算成本。&lt;h4&gt;背景&lt;/h4&gt;高级机器学习模型训练需要大量数据集，导致计算成本高昂。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，提出了一种新的数据剪枝方法，以减少计算成本。&lt;h4&gt;方法&lt;/h4&gt;该方法通过在少量数据上训练，使用k最近邻和图神经网络来预测样本重要性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在动态不确定性剪枝和TDDS剪枝等两种现有剪枝方法、四个不同数据集（CIFAR-10、CIFAR-100、Places-365和ImageNet）以及三种训练范式（监督学习、无监督学习和对抗学习）中均显示出有效性。&lt;h4&gt;结论&lt;/h4&gt;分数外推是一种有前途的方法，可以扩展像剪枝这样的昂贵计算方法。&lt;h4&gt;翻译&lt;/h4&gt;Training advanced machine learning models requires massive datasets, resulting in prohibitive computational costs. To address this challenge, data pruning techniques identify and remove redundant training samples while preserving model performance. Yet, existing pruning techniques predominantly require a full initial training pass to identify removable samples, negating any efficiency benefits for single training runs. To overcome this limitation, we introduce a novel importance score extrapolation framework that requires training on only a small subset of data. We present two initial approaches in this framework - k-nearest neighbors and graph neural networks - to accurately predict sample importance for the entire dataset using patterns learned from this minimal subset. We demonstrate the effectiveness of our approach for 2 state-of-the-art pruning methods (Dynamic Uncertainty and TDDS), 4 different datasets (CIFAR-10, CIFAR-100, Places-365, and ImageNet), and 3 training paradigms (supervised, unsupervised, and adversarial). Our results indicate that score extrapolation is a promising direction to scale expensive score calculation methods, such as pruning, data attribution, or other tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training advanced machine learning models demands massive datasets, resultingin prohibitive computational costs. To address this challenge, data pruningtechniques identify and remove redundant training samples while preservingmodel performance. Yet, existing pruning techniques predominantly require afull initial training pass to identify removable samples, negating anyefficiency benefits for single training runs. To overcome this limitation, weintroduce a novel importance score extrapolation framework that requirestraining on only a small subset of data. We present two initial approaches inthis framework - k-nearest neighbors and graph neural networks - to accuratelypredict sample importance for the entire dataset using patterns learned fromthis minimal subset. We demonstrate the effectiveness of our approach for 2state-of-the-art pruning methods (Dynamic Uncertainty and TDDS), 4 differentdatasets (CIFAR-10, CIFAR-100, Places-365, and ImageNet), and 3 trainingparadigms (supervised, unsupervised, and adversarial). Our results indicatethat score extrapolation is a promising direction to scale expensive scorecalculation methods, such as pruning, data attribution, or other tasks.</description>
      <author>example@mail.com (Sebastian Schmidt, Prasanga Dhungel, Christoffer Löffler, Björn Nieth, Stephan Günnemann, Leo Schwinn)</author>
      <guid isPermaLink="false">2506.09010v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Rapid cardiac activation prediction for cardiac resynchronization therapy planning using geometric deep learning</title>
      <link>http://arxiv.org/abs/2506.08987v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文开发了一种基于几何深度学习模型的方法，用于预测心脏激动时间图，以优化心脏再同步治疗（CRT）。&lt;h4&gt;背景&lt;/h4&gt;CRT是治疗同步性心脏衰竭的常见干预措施，但由于电极放置不佳，大约三分之一的患者无法响应。&lt;h4&gt;目的&lt;/h4&gt;构建一种在硅中模拟的方法，以帮助解决CRT规划中识别最佳起搏位点的问题。&lt;h4&gt;方法&lt;/h4&gt;开发了两种基于图神经网络（GNN）和几何信息神经网络操作符（GINO）的几何深度学习（DL）模型，用于实时预测CRT规划中的心脏激动时间图。这些模型在由有限元（FE）模拟生成的大型合成数据集上进行了训练，数据集涵盖了广泛的心室（LV）几何形状、起搏位点配置和组织电导率。&lt;h4&gt;主要发现&lt;/h4&gt;GINO模型在预测精度和鲁棒性方面优于GNN模型，且预测误差更低（1.14% vs 3.14%），对噪声和不同网格离散化具有更好的鲁棒性。使用GINO模型，我们还开发了一种从给定的激动时间图和LV几何形状中优化CRT起搏位点的流程。与随机选择起搏位点相比，CRT优化流程可以显著减少最大激动时间（20% vs. 8%）。&lt;h4&gt;结论&lt;/h4&gt;GINO模型在CRT个性化术前优化方面具有作为临床决策支持工具的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Cardiac resynchronization therapy (CRT) is a common intervention for patients with dyssynchronous heart failure, yet approximately one-third of recipients fail to respond due to suboptimal lead placement. Identifying optimal pacing sites remains challenging, largely due to patient-specific anatomical variability and the limitations of current individualized planning strategies. In a step towards constructing an in-silico approach to help address this issue, we develop two geometric deep learning (DL) models, based on graph neural network (GNN) and geometry-informed neural operator (GINO), to predict cardiac activation time map in real-time for CRT planning and optimization. Both models are trained on a large synthetic dataset generated from finite-element (FE) simulations over a wide range of left ventricular (LV) geometries, pacing site configurations, and tissue conductivities. The GINO model significantly outperforms the GNN model, with lower prediction errors (1.14% vs 3.14%) and superior robustness to noise and various mesh discretization. Using the GINO model, we also develop a workflow for optimizing the pacing site in CRT from given activation time map and LV geometry. Compared to randomly selecting a pacing site, the CRT optimization workflow produces a larger reduction in maximum activation time (20% vs. 8%). In conjunction with an interactive web-based graphical user interface (GUI) available at https://dcsim.egr.msu.edu/, the GINO model shows promising potential as a clinical decision-support tool for personalized pre-procedural CRT optimization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ehsanngh/DeepCardioSim&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cardiac resynchronization therapy (CRT) is a common intervention for patientswith dyssynchronous heart failure, yet approximately one-third of recipientsfail to respond due to suboptimal lead placement. Identifying optimal pacingsites remains challenging, largely due to patient-specific anatomicalvariability and the limitations of current individualized planning strategies.In a step towards constructing an in-silico approach to help address thisissue, we develop two geometric deep learning (DL) models, based on graphneural network (GNN) and geometry-informed neural operator (GINO), to predictcardiac activation time map in real-time for CRT planning and optimization.Both models are trained on a large synthetic dataset generated fromfinite-element (FE) simulations over a wide range of left ventricular (LV)geometries, pacing site configurations, and tissue conductivities. The GINOmodel significantly outperforms the GNN model, with lower prediction errors(1.14% vs 3.14%) and superior robustness to noise and various meshdiscretization. Using the GINO model, we also develop a workflow for optimizingthe pacing site in CRT from given activation time map and LV geometry. Comparedto randomly selecting a pacing site, the CRT optimization workflow produces alarger reduction in maximum activation time (20% vs. 8%). In conjunction withan interactive web-based graphical user interface (GUI) available athttps://dcsim.egr.msu.edu/, the GINO model shows promising potential as aclinical decision-support tool for personalized pre-procedural CRToptimization.</description>
      <author>example@mail.com (Ehsan Naghavi, Haifeng Wang, Vahid Ziaei Rad, Julius Guccione, Ghassan Kassab, Vishnu Boddeti, Seungik Baek, Lik-Chuan Lee)</author>
      <guid isPermaLink="false">2506.08987v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>SceneSplat++: A Large Dataset and Comprehensive Benchmark for Language Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.08710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, codes, data and benchmark will be released&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为3D Gaussian Splatting的3D场景编码方法，并建立了一个大规模基准来评估不同方法在3D空间中的性能。&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting是一种高效的场景几何、外观和语义编码方法，将语言与3D场景结合是理解3D场景的有效策略。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法在评估上存在的局限性，提出一个能够全面评估不同方法的基准。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含1060个场景的大规模基准，涵盖室内和室外数据集，评估了基于场景优化、无场景优化和通用方法的三种主要方法。&lt;h4&gt;主要发现&lt;/h4&gt;通用方法在放宽场景特定限制、实现快速前向推理和获得更好的分割性能方面具有明显优势。&lt;h4&gt;结论&lt;/h4&gt;提出了一个名为GaussianWorld-49K的精心策划的3DGS数据集，展示了通用方法可以利用强大的数据先验，并公开了代码、基准和数据集以加速研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D高斯散布（3DGS）是一种高效且有效的场景几何、外观和语义编码。此外，将语言根植于3D场景已被证明是理解3D场景的有效策略。当前的语言高斯散布工作分为三大类：（一）基于场景优化的，（二）无场景优化的，（三）通用方法。然而，大多数工作只评估了少量场景和视角接近训练视图的渲染2D视图，限制了全面3D理解的能力和洞察力。为了解决这一差距，我们提出了第一个直接在3D空间中系统评估这三组方法的基准。在三个室内数据集和一个室外数据集上评估了1060个场景。基准结果表明，通用范式具有明显优势，尤其是在放宽场景特定限制、实现新颖场景的快速前向推理和获得更好的分割性能方面。我们进一步引入了GaussianWorld-49K，这是一个包含约49K个来自多个来源的室内和室外场景的精心策划的3DGS数据集，我们展示了通用方法可以利用强大的数据先验。我们的代码、基准和数据集将公开，以加速通用3DGS场景理解的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) serves as a highly performant and efficientencoding of scene geometry, appearance, and semantics. Moreover, groundinglanguage in 3D scenes has proven to be an effective strategy for 3D sceneunderstanding. Current Language Gaussian Splatting line of work fall into threemain groups: (i) per-scene optimization-based, (ii) per-sceneoptimization-free, and (iii) generalizable approach. However, most of them areevaluated only on rendered 2D views of a handful of scenes and viewpoints closeto the training views, limiting ability and insight into holistic 3Dunderstanding. To address this gap, we propose the first large-scale benchmarkthat systematically assesses these three groups of methods directly in 3Dspace, evaluating on 1060 scenes across three indoor datasets and one outdoordataset. Benchmark results demonstrate a clear advantage of the generalizableparadigm, particularly in relaxing the scene-specific limitation, enabling fastfeed-forward inference on novel scenes, and achieving superior segmentationperformance. We further introduce GaussianWorld-49K a carefully curated 3DGSdataset comprising around 49K diverse indoor and outdoor scenes obtained frommultiple sources, with which we demonstrate the generalizable approach couldharness strong data priors. Our codes, benchmark, and datasets will be madepublic to accelerate research in generalizable 3DGS scene understanding.</description>
      <author>example@mail.com (Mengjiao Ma, Qi Ma, Yue Li, Jiahuan Cheng, Runyi Yang, Bin Ren, Nikola Popovic, Mingqiang Wei, Nicu Sebe, Luc Van Gool, Theo Gevers, Martin R. Oswald, Danda Pani Paudel)</author>
      <guid isPermaLink="false">2506.08710v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Medical Vision-Language Alignment Through Adapting Masked Vision Models</title>
      <link>http://arxiv.org/abs/2506.08990v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  TMI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ALTA的医学视觉-语言对齐方法，该方法在图像-文本匹配任务中表现优异，如检索和零样本分类。ALTA通过优化视觉模型和整合时间多视图影像输入，提高了视觉-语言对齐的效果。&lt;h4&gt;背景&lt;/h4&gt;传统的跨模态对比学习方法在视觉-语言对齐中存在视觉表示能力不足的问题，而多模态掩码模型预训练的模型虽然在视觉表示上表现较好，但在直接跨模态匹配上存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且性能优越的医学视觉-语言对齐方法，以解决传统方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;ALTA方法利用了约8%的可训练参数和少于1/5的掩码记录建模的计算消耗。它通过调整预训练的视觉模型，并结合时间多视图影像输入，来提高视觉-语言对齐的性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ALTA在文本到图像的准确率和图像到文本的检索准确率上分别优于最佳竞争者超过4%和6%。&lt;h4&gt;结论&lt;/h4&gt;ALTA是一种有效的医学视觉-语言对齐方法，通过优化视觉模型和整合影像输入，提高了视觉-语言对齐的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通过跨模态对比学习实现的医学视觉-语言对齐在图像-文本匹配任务中表现出良好的性能，如检索和零样本分类。然而，传统的跨模态对比学习方法（基于CLIP）在视觉表示能力上存在不足，这也限制了它们在视觉-语言对齐中的有效性。相比之下，虽然通过多模态掩码模型预训练的模型在直接跨模态匹配上存在困难，但它们在视觉表示上表现出色。为了解决这一矛盾，我们提出了ALTA（通过调整对齐），一种高效的医学视觉-语言对齐方法，它仅使用了大约8%的可训练参数，以及掩码记录建模所需计算消耗的不到1/5。ALTA通过调整掩码记录建模预训练的视觉模型，在检索和零样本分类等视觉-语言匹配任务中实现了优异的性能。此外，我们还整合了时间多视图影像输入，以增强影像与其对应报告中描述之间的信息一致性，进一步提高了视觉-语言对齐的效果。实验评估表明，ALTA在文本到图像的准确率上优于最佳竞争者超过4%，在图像到文本的检索准确率上约高6%。在有效对齐过程中对视觉-语言模型的调整也促进了更好的视觉和语言理解。代码可在https://github.com/DopamineLcy/ALTA公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TMI.2025.3575853&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical vision-language alignment through cross-modal contrastive learningshows promising performance in image-text matching tasks, such as retrieval andzero-shot classification. However, conventional cross-modal contrastivelearning (CLIP-based) methods suffer from suboptimal visual representationcapabilities, which also limits their effectiveness in vision-languagealignment. In contrast, although the models pretrained via multimodal maskedmodeling struggle with direct cross-modal matching, they excel in visualrepresentation. To address this contradiction, we propose ALTA (ALign ThroughAdapting), an efficient medical vision-language alignment method that utilizesonly about 8% of the trainable parameters and less than 1/5 of thecomputational consumption required for masked record modeling. ALTA achievessuperior performance in vision-language matching tasks like retrieval andzero-shot classification by adapting the pretrained vision model from maskedrecord modeling. Additionally, we integrate temporal-multiview radiographinputs to enhance the information consistency between radiographs and theircorresponding descriptions in reports, further improving the vision-languagealignment. Experimental evaluations show that ALTA outperforms thebest-performing counterpart by over 4% absolute points in text-to-imageaccuracy and approximately 6% absolute points in image-to-text retrievalaccuracy. The adaptation of vision-language models during efficient alignmentalso promotes better vision and language understanding. Code is publiclyavailable at https://github.com/DopamineLcy/ALTA.</description>
      <author>example@mail.com (Chenyu Lian, Hong-Yu Zhou, Dongyun Liang, Jing Qin, Liansheng Wang)</author>
      <guid isPermaLink="false">2506.08990v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>LiftVSR: Lifting Image Diffusion to Video Super-Resolution via Hybrid Temporal Modeling with Only 4$\times$RTX 4090s</title>
      <link>http://arxiv.org/abs/2506.08529v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://kopperx.github.io/projects/liftvsr&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;LiftVSR是一种高效的视频超分辨率框架，通过提升图像扩散先验和引入混合时间建模机制，在保持长期一致性和效率的同时，显著降低了计算成本。&lt;h4&gt;背景&lt;/h4&gt;现有的视频超分辨率方法在保证帧间一致性和降低计算成本方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一个高效的VSR框架，以平衡长期一致性和效率。&lt;h4&gt;方法&lt;/h4&gt;引入了一种混合时间建模机制，包括：(i) 动态时间注意力（DTA）用于短帧段内的细粒度时间建模，和(ii) 注意力内存缓存（AMC）用于跨段的长期时间建模。此外，还引入了不对称采样策略以稳定缓存交互。&lt;h4&gt;主要发现&lt;/h4&gt;LiftVSR在多个VSR基准测试中表现出色，并且计算成本显著低于现有方法。&lt;h4&gt;结论&lt;/h4&gt;LiftVSR通过创新的技术解决了现有VSR方法的局限性，实现了高效的视频超分辨率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion models have significantly advanced video super-resolution (VSR) byenhancing perceptual quality, largely through elaborately designed temporalmodeling to ensure inter-frame consistency. However, existing methods usuallysuffer from limited temporal coherence and prohibitively high computationalcosts (e.g., typically requiring over 8 NVIDIA A100-80G GPUs), especially forlong videos. In this work, we propose LiftVSR, an efficient VSR framework thatleverages and elevates the image-wise diffusion prior from PixArt-$\alpha$,achieving state-of-the-art results using only 4$\times$RTX 4090 GPUs. Tobalance long-term consistency and efficiency, we introduce a hybrid temporalmodeling mechanism that decomposes temporal learning into two complementarycomponents: (i) Dynamic Temporal Attention (DTA) for fine-grained temporalmodeling within short frame segment ($\textit{i.e.}$, low complexity), and (ii)Attention Memory Cache (AMC) for long-term temporal modeling across segments($\textit{i.e.}$, consistency). Specifically, DTA identifies multiple tokenflows across frames within multi-head query and key tokens to warp inter-framecontexts in the value tokens. AMC adaptively aggregates historical segmentinformation via a cache unit, ensuring long-term coherence with minimaloverhead. To further stabilize the cache interaction during inference, weintroduce an asymmetric sampling strategy that mitigates feature mismatchesarising from different diffusion sampling steps. Extensive experiments onseveral typical VSR benchmarks have demonstrated that LiftVSR achievesimpressive performance with significantly lower computational costs.</description>
      <author>example@mail.com (Xijun Wang, Xin Li, Bingchen Li, Zhibo Chen)</author>
      <guid isPermaLink="false">2506.08529v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>InfoDPCCA: Information-Theoretic Dynamic Probabilistic Canonical Correlation Analysis</title>
      <link>http://arxiv.org/abs/2506.08884v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by UAI-25, code is available at  \url{https://github.com/marcusstang/InfoDPCCA}&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;InfoDPCCA是一种动态概率典型相关分析（CCA）框架，用于从高维序列数据中提取有意义的潜在表示。&lt;h4&gt;背景&lt;/h4&gt;提取高维序列数据中的潜在表示是机器学习中的一个关键挑战，其应用范围涵盖自然科学和工程领域。&lt;h4&gt;目的&lt;/h4&gt;InfoDPCCA旨在模型两个相互依赖的观察序列，提取共享的潜在表示，同时学习针对每个序列的特定信息。&lt;h4&gt;方法&lt;/h4&gt;InfoDPCCA利用一种新的信息论目标函数来提取共享的潜在表示，并学习单独的潜在组件，以编码每个序列的特定信息。此外，它引入了一种两步训练方案和残差连接机制来提高训练稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;InfoDPCCA在合成和医学fMRI数据上的实验表明，它是一种出色的表示学习工具。&lt;h4&gt;结论&lt;/h4&gt;InfoDPCCA通过提高可解释性和鲁棒性，有效地解决了动态CCA模型中的互信息编码问题。&lt;h4&gt;翻译&lt;/h4&gt;从高维序列数据中提取有意义的潜在表示是机器学习中的一个关键挑战，其应用范围涵盖自然科学和工程领域。我们引入了InfoDPCCA，这是一种动态概率典型相关分析（CCA）框架，旨在模型两个相互依赖的观察序列。InfoDPCCA利用一种新的信息论目标函数来提取共享的潜在表示，以捕获数据流之间的相互结构，并在表示压缩和预测充分性之间取得平衡，同时学习针对每个序列的特定信息。与DPCCA等先前动态CCA模型不同，我们的方法明确强制共享潜在空间仅编码序列之间的互信息，从而提高了可解释性和鲁棒性。我们还引入了一种两步训练方案，以弥合信息论表示学习和生成建模之间的差距，并采用残差连接机制来增强训练稳定性。通过合成和医学fMRI数据上的实验，我们证明了InfoDPCCA作为表示学习工具的优越性。InfoDPCCA的代码可在https://github.com/marcusstang/InfoDPCCA上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Extracting meaningful latent representations from high-dimensional sequentialdata is a crucial challenge in machine learning, with applications spanningnatural science and engineering. We introduce InfoDPCCA, a dynamicprobabilistic Canonical Correlation Analysis (CCA) framework designed to modeltwo interdependent sequences of observations. InfoDPCCA leverages a novelinformation-theoretic objective to extract a shared latent representation thatcaptures the mutual structure between the data streams and balancesrepresentation compression and predictive sufficiency while also learningseparate latent components that encode information specific to each sequence.Unlike prior dynamic CCA models, such as DPCCA, our approach explicitlyenforces the shared latent space to encode only the mutual information betweenthe sequences, improving interpretability and robustness. We further introducea two-step training scheme to bridge the gap between information-theoreticrepresentation learning and generative modeling, along with a residualconnection mechanism to enhance training stability. Through experiments onsynthetic and medical fMRI data, we demonstrate that InfoDPCCA excels as a toolfor representation learning. Code of InfoDPCCA is available athttps://github.com/marcusstang/InfoDPCCA.</description>
      <author>example@mail.com (Shiqin Tang, Shujian Yu)</author>
      <guid isPermaLink="false">2506.08884v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>ArrowPose: Segmentation, Detection, and 5 DoF Pose Estimation Network for Colorless Point Clouds</title>
      <link>http://arxiv.org/abs/2506.08699v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于无色点云的快速检测和5自由度姿态估计网络。&lt;h4&gt;背景&lt;/h4&gt;该网络通过神经网络预测物体的中心和顶部点来进行姿态估计。&lt;h4&gt;目的&lt;/h4&gt;该网络旨在实现快速且准确的无色点云姿态估计。&lt;h4&gt;方法&lt;/h4&gt;网络在合成数据上训练，并在基准数据集上进行测试，显示出最先进的性能，优于所有无色方法。&lt;h4&gt;主要发现&lt;/h4&gt;该网络能够在仅250毫秒内完成推理，适用于多种场景。&lt;h4&gt;结论&lt;/h4&gt;该网络为无色点云的姿态估计提供了一种快速且有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种针对无色点云的快速检测和5自由度姿态估计网络。该网络通过神经网络预测物体的中心和顶部点来进行姿态估计。网络在合成数据上训练，在基准数据集上测试，表现出最先进的性能，优于所有无色方法。该网络能够在仅250毫秒内完成推理，适用于多种场景。项目页面及代码位于arrowpose.github.io。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a fast detection and 5 DoF (Degrees of Freedom) poseestimation network for colorless point clouds. The pose estimation iscalculated from center and top points of the object, predicted by the neuralnetwork. The network is trained on synthetic data, and tested on a benchmarkdataset, where it demonstrates state-of-the-art performance and outperforms allcolorless methods. The network is able to run inference in only 250milliseconds making it usable in many scenarios. Project page with code atarrowpose.github.io</description>
      <author>example@mail.com (Frederik Hagelskjaer)</author>
      <guid isPermaLink="false">2506.08699v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Adapting to Heterophilic Graph Data with Structure-Guided Neighbor Discovery</title>
      <link>http://arxiv.org/abs/2506.08871v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为结构引导图神经网络（SG-GNN）的架构，用于解决异质数据中的图神经网络（GNNs）性能问题，通过创建新的图结构来提高标签同质性，并通过实验证明其有效性。&lt;h4&gt;背景&lt;/h4&gt;GNNs在处理异质数据时存在困难，因为它们通常假设同质性并依赖于局部消息传递。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来提高GNN在异质数据上的性能。&lt;h4&gt;方法&lt;/h4&gt;通过创建具有相似结构属性的节点链接来构建新的图结构，并证明使用具有较少错误正边（不同类节点之间的连接）的图可以提高GNN性能。引入SG-GNN架构，该架构同时处理原始图和新创建的结构图，自适应地学习权衡它们的贡献。&lt;h4&gt;主要发现&lt;/h4&gt;SG-GNN在具有异质特性的各种基准数据集上实现了最先进或高度竞争的性能，证明了利用结构信息引导GNN的有效性。&lt;h4&gt;结论&lt;/h4&gt;结构引导GNN（SG-GNN）通过利用结构信息提高了GNN在处理异质数据时的性能，为GNN的应用提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) often struggle with heterophilic data, where connected nodes may have dissimilar labels, as they typically assume homophily and rely on local message passing. To address this, we propose creating alternative graph structures by linking nodes with similar structural attributes (e.g., role-based or global), thereby fostering higher label homophily on these new graphs. We theoretically prove that GNN performance can be improved by utilizing graphs with fewer false positive edges (connections between nodes of different classes) and that considering multiple graph views increases the likelihood of finding such beneficial structures. Building on these insights, we introduce Structure-Guided GNN (SG-GNN), an architecture that processes the original graph alongside the newly created structural graphs, adaptively learning to weigh their contributions. Extensive experiments on various benchmark datasets, particularly those with heterophilic characteristics, demonstrate that our SG-GNN achieves state-of-the-art or highly competitive performance, highlighting the efficacy of exploiting structural information to guide GNNs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) often struggle with heterophilic data, whereconnected nodes may have dissimilar labels, as they typically assume homophilyand rely on local message passing. To address this, we propose creatingalternative graph structures by linking nodes with similar structuralattributes (e.g., role-based or global), thereby fostering higher labelhomophily on these new graphs. We theoretically prove that GNN performance canbe improved by utilizing graphs with fewer false positive edges (connectionsbetween nodes of different classes) and that considering multiple graph viewsincreases the likelihood of finding such beneficial structures. Building onthese insights, we introduce Structure-Guided GNN (SG-GNN), an architecturethat processes the original graph alongside the newly created structuralgraphs, adaptively learning to weigh their contributions. Extensive experimentson various benchmark datasets, particularly those with heterophiliccharacteristics, demonstrate that our SG-GNN achieves state-of-the-art orhighly competitive performance, highlighting the efficacy of exploitingstructural information to guide GNNs.</description>
      <author>example@mail.com (Victor M. Tenorio, Madeline Navarro, Samuel Rey, Santiago Segarra, Antonio G. Marques)</author>
      <guid isPermaLink="false">2506.08871v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly</title>
      <link>http://arxiv.org/abs/2506.08708v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PhyBlock是一个渐进式基准，用于评估视觉语言模型（VLMs）在物理理解和规划方面的能力，特别是在结构化的3D环境中。&lt;h4&gt;背景&lt;/h4&gt;尽管视觉语言模型在推理和规划方面表现出有希望的能力，但它们理解物理现象的能力，特别是在结构化的3D环境中，仍然非常有限。&lt;h4&gt;目的&lt;/h4&gt;为了缩小这一差距，PhyBlock通过机器人3D积木组装任务评估VLMs的物理理解和规划能力。&lt;h4&gt;方法&lt;/h4&gt;PhyBlock整合了一个新颖的四级认知层次组装任务和针对性的视觉问答（VQA）样本，旨在评估渐进式空间推理和基本物理理解，包括物体属性、空间关系和整体场景理解。它包括2600个积木任务（400个组装任务，2200个VQA任务），并从部分完成、故障诊断和规划鲁棒性三个关键维度评估模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，VLMs在高级规划和推理能力方面存在明显限制，导致随着任务复杂性的增加，性能显著下降。错误分析揭示了在空间定位和依赖推理方面的持续困难。令人惊讶的是，思维链提示提供的改进最小，表明空间任务严重依赖于直观的模型理解。&lt;h4&gt;结论&lt;/h4&gt;PhyBlock被定位为一个统一的测试平台，以推进具身推理，架起视觉语言理解和现实世界物理问题解决之间的桥梁。&lt;h4&gt;翻译&lt;/h4&gt;While vision-language models (VLMs) have demonstrated promising capabilities in reasoning and planning for embodied agents, their ability to comprehend physical phenomena, particularly within structured 3D environments, remains severely limited. To close this gap, we introduce PhyBlock, a progressive benchmark designed to assess VLMs on physical understanding and planning through robotic 3D block assembly tasks. PhyBlock integrates a novel four-level cognitive hierarchy assembly task alongside targeted Visual Question Answering (VQA) samples, collectively aimed at evaluating progressive spatial reasoning and fundamental physical comprehension, including object properties, spatial relationships, and holistic scene understanding. PhyBlock includes 2600 block tasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three key dimensions: partial completion, failure diagnosis, and planning robustness. We benchmark 21 state-of-the-art VLMs, highlighting their strengths and limitations in physically grounded, multi-step planning. Our empirical findings indicate that the performance of VLMs exhibits pronounced limitations in high-level planning and reasoning capabilities, leading to a notable decline in performance for the growing complexity of the tasks. Error analysis reveals persistent difficulties in spatial orientation and dependency reasoning. Surprisingly, chain-of-thought prompting offers minimal improvements, suggesting spatial tasks heavily rely on intuitive model comprehension. We position PhyBlock as a unified testbed to advance embodied reasoning, bridging vision-language understanding and real-world physical problem-solving.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While vision-language models (VLMs) have demonstrated promising capabilitiesin reasoning and planning for embodied agents, their ability to comprehendphysical phenomena, particularly within structured 3D environments, remainsseverely limited. To close this gap, we introduce PhyBlock, a progressivebenchmark designed to assess VLMs on physical understanding and planningthrough robotic 3D block assembly tasks. PhyBlock integrates a novel four-levelcognitive hierarchy assembly task alongside targeted Visual Question Answering(VQA) samples, collectively aimed at evaluating progressive spatial reasoningand fundamental physical comprehension, including object properties, spatialrelationships, and holistic scene understanding. PhyBlock includes 2600 blocktasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across threekey dimensions: partial completion, failure diagnosis, and planning robustness.We benchmark 21 state-of-the-art VLMs, highlighting their strengths andlimitations in physically grounded, multi-step planning. Our empirical findingsindicate that the performance of VLMs exhibits pronounced limitations inhigh-level planning and reasoning capabilities, leading to a notable decline inperformance for the growing complexity of the tasks. Error analysis revealspersistent difficulties in spatial orientation and dependency reasoning.Surprisingly, chain-of-thought prompting offers minimal improvements,suggesting spatial tasks heavily rely on intuitive model comprehension. Weposition PhyBlock as a unified testbed to advance embodied reasoning, bridgingvision-language understanding and real-world physical problem-solving.</description>
      <author>example@mail.com (Liang Ma, Jiajun Wen, Min Lin, Rongtao Xu, Xiwen Liang, Bingqian Lin, Jun Ma, Yongxin Wang, Ziming Wei, Haokun Lin, Mingfei Han, Meng Cao, Bokui Chen, Ivan Laptev, Xiaodan Liang)</author>
      <guid isPermaLink="false">2506.08708v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Robust Evolutionary Multi-Objective Network Architecture Search for Reinforcement Learning (EMNAS-RL)</title>
      <link>http://arxiv.org/abs/2506.08533v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ESANN 2025 Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文首次提出了一种名为进化多目标网络架构搜索（EMNAS）的方法，用于优化大规模强化学习（RL）在自动驾驶（AD）中的应用中的神经网络架构。&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶领域，神经网络架构的优化是一个关键问题，它涉及到如何通过调整网络结构来提高性能并减少模型大小。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法来优化神经网络架构，以提高自动驾驶中的强化学习性能，同时减少模型尺寸。&lt;h4&gt;方法&lt;/h4&gt;EMNAS利用遗传算法来自动化网络设计，旨在通过增加奖励和减少模型尺寸来提升性能。此外，采用并行化技术来加速搜索过程，并实施师生方法来确保可扩展的优化。该方法强调迁移学习在优化迭代学习过程中的潜力，通过有效利用前一代的知识来提高学习效率和稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，定制的EMNAS在手动设计模型之上，以更少的参数实现了更高的奖励。&lt;h4&gt;结论&lt;/h4&gt;这些策略对自动驾驶中的强化学习领域的EMNAS方法有积极贡献，推动了向性能更优、适用于现实场景的网络架构的发展。&lt;h4&gt;翻译&lt;/h4&gt;本文首次提出了一种名为进化多目标网络架构搜索（EMNAS）的方法，用于优化大规模强化学习（RL）在自动驾驶（AD）中的应用中的神经网络架构。EMNAS利用遗传算法来自动化网络设计，旨在通过增加奖励和减少模型尺寸来提升性能。此外，采用并行化技术来加速搜索过程，并实施师生方法来确保可扩展的优化。该方法强调迁移学习在优化迭代学习过程中的潜力，通过有效利用前一代的知识来提高学习效率和稳定性。实验结果表明，定制的EMNAS在手动设计模型之上，以更少的参数实现了更高的奖励。这些策略对自动驾驶中的强化学习领域的EMNAS方法有积极贡献，推动了向性能更优、适用于现实场景的网络架构的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces Evolutionary Multi-Objective Network ArchitectureSearch (EMNAS) for the first time to optimize neural network architectures inlarge-scale Reinforcement Learning (RL) for Autonomous Driving (AD). EMNAS usesgenetic algorithms to automate network design, tailored to enhance rewards andreduce model size without compromising performance. Additionally,parallelization techniques are employed to accelerate the search, andteacher-student methodologies are implemented to ensure scalable optimization.This research underscores the potential of transfer learning as a robustframework for optimizing performance across iterative learning processes byeffectively leveraging knowledge from earlier generations to enhance learningefficiency and stability in subsequent generations. Experimental resultsdemonstrate that tailored EMNAS outperforms manually designed models, achievinghigher rewards with fewer parameters. The findings of these strategiescontribute positively to EMNAS for RL in autonomous driving, advancing thefield toward better-performing networks suitable for real-world scenarios.</description>
      <author>example@mail.com (Nihal Acharya Adde, Alexandra Gianzina, Hanno Gottschalk, Andreas Ebert)</author>
      <guid isPermaLink="false">2506.08533v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Spatial Transcriptomics Expression Prediction from Histopathology Based on Cross-Modal Mask Reconstruction and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.08854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于对比学习的深度学习方法，用于从全切片图像预测空间分辨率的基因表达，并在六个不同疾病数据集上进行了评估。&lt;h4&gt;背景&lt;/h4&gt;空间转录组学技术广泛用于肿瘤微环境和组织病理学的分子分析，但数据获取成本高，大规模空间转录组数据难以获得。&lt;h4&gt;目的&lt;/h4&gt;开发一种深度学习方法，以降低空间转录组学数据获取成本，并提高基因表达的预测准确性。&lt;h4&gt;方法&lt;/h4&gt;开发了一种基于对比学习的深度学习模型，用于从全切片图像中预测空间分辨率的基因表达，并在六个不同疾病数据集上评估其性能。&lt;h4&gt;主要发现&lt;/h4&gt;与现有研究相比，该方法在预测高度表达基因、高度可变基因和标记基因时，分别提高了6.27%、6.11%和11.26%的Pearson相关系数（PCC）。进一步分析表明，该方法保留了基因间相关性，并适用于样本量有限的数据库。此外，该方法在基于生物标志物表达进行癌症组织定位方面具有潜力。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于对比学习的深度学习方法在预测基因表达和癌症组织定位方面具有显著的优势和应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial transcriptomics is a technology that captures gene expression levelsat different spatial locations, widely used in tumor microenvironment analysisand molecular profiling of histopathology, providing valuable insights intoresolving gene expression and clinical diagnosis of cancer. Due to the highcost of data acquisition, large-scale spatial transcriptomics data remainchallenging to obtain. In this study, we develop a contrastive learning-baseddeep learning method to predict spatially resolved gene expression fromwhole-slide images. Evaluation across six different disease datasetsdemonstrates that, compared to existing studies, our method improves PearsonCorrelation Coefficient (PCC) in the prediction of highly expressed genes,highly variable genes, and marker genes by 6.27%, 6.11%, and 11.26%respectively. Further analysis indicates that our method preserves gene-genecorrelations and applies to datasets with limited samples. Additionally, ourmethod exhibits potential in cancer tissue localization based on biomarkerexpression.</description>
      <author>example@mail.com (Junzhuo Liu, Markus Eckstein, Zhixiang Wang, Friedrich Feuerhake, Dorit Merhof)</author>
      <guid isPermaLink="false">2506.08854v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>On Finetuning Tabular Foundation Models</title>
      <link>http://arxiv.org/abs/2506.08982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了表格深度学习中的基础模型，特别是TabPFNv2在小型数据集上的性能，并探讨了其微调策略和内部机制的变化。&lt;h4&gt;背景&lt;/h4&gt;TabPFNv2使用上下文学习范式在小型数据集上表现优于传统的GBDT方法，但其最佳微调方法和内部机制的改变尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;评估不同的微调策略，并研究微调如何改变TabPFNv2的内部机制。&lt;h4&gt;方法&lt;/h4&gt;对各种数据集进行系统评估，并使用类比检索增强模型的方法来研究微调的影响。&lt;h4&gt;主要发现&lt;/h4&gt;全微调在时间效率和效果方面是TabPFNv2的最实用解决方案。微调通过改进查询表示和关键表示的点积，使得TabPFNv2能够更好地近似目标依赖关系。&lt;h4&gt;结论&lt;/h4&gt;在大型数据集上微调TabPFNv2能够观察到几乎所有任务上的性能提升，特别是在具有I.I.D.拆分的学术数据集上，TabPFNv2可以达到最先进的结果，但在具有时间推移和丰富特征集的数据集上，TabPFNv2的稳定性较差，传统方法仍然更优。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates foundation models in tabular deep learning, particularly the performance of TabPFNv2 on small-scale datasets, and explores its fine-tuning strategy and changes in internal mechanisms.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are an emerging research direction in tabular deeplearning. Notably, TabPFNv2 recently claimed superior performance overtraditional GBDT-based methods on small-scale datasets using an in-contextlearning paradigm, which does not adapt model parameters to target datasets.However, the optimal finetuning approach for adapting tabular foundationalmodels, and how this adaptation reshapes their internal mechanisms, remainsunderexplored. While prior works studied finetuning for earlier foundationalmodels, inconsistent findings and TabPFNv2's unique architecture necessitatefresh investigation. To address these questions, we first systematicallyevaluate various finetuning strategies on diverse datasets. Our findingsestablish full finetuning as the most practical solution for TabPFNv2 in termsof time-efficiency and effectiveness. We then investigate how finetuning altersTabPFNv2's inner mechanisms, drawing an analogy to retrieval-augmented models.We reveal that the success of finetuning stems from the fact that aftergradient-based adaptation, the dot products of the query-representations oftest objects and the key-representations of in-context training objects moreaccurately reflect their target similarity. This improved similarity allowsfinetuned TabPFNv2 to better approximate target dependency by appropriatelyweighting relevant in-context samples, improving the retrieval-based predictionlogic. From the practical perspective, we managed to finetune TabPFNv2 ondatasets with up to 50K objects, observing performance improvements on almostall tasks. More precisely, on academic datasets with I.I.D. splits, finetuningallows TabPFNv2 to achieve state-of-the-art results, while on datasets withgradual temporal shifts and rich feature sets, TabPFNv2 is less stable andprior methods remain better.</description>
      <author>example@mail.com (Ivan Rubachev, Akim Kotelnikov, Nikolay Kartashev)</author>
      <guid isPermaLink="false">2506.08982v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>MLVTG: Mamba-Based Feature Alignment and LLM-Driven Purification for Multi-Modal Video Temporal Grounding</title>
      <link>http://arxiv.org/abs/2506.08512v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MLVTG的新型框架，用于解决视频理解中的视频时间定位问题，通过实验验证了其在多个数据集上优于现有方法的表现。&lt;h4&gt;背景&lt;/h4&gt;视频时间定位（VTG）是视频理解中的一个基本且具有挑战性的任务。现有的基于Transformer的方法往往存在冗余注意力和次优的多模态对齐问题。&lt;h4&gt;目的&lt;/h4&gt;提出MLVTG框架，旨在解决现有Transformer方法中存在的问题，实现更精确的视频时间定位。&lt;h4&gt;方法&lt;/h4&gt;MLVTG框架集成了两个关键模块：MambaAligner和LLMRefiner。MambaAligner使用堆叠的Vision Mamba块作为骨干网络，以建模时间依赖性并提取鲁棒的视频表示。LLMRefiner利用预训练的大型语言模型（LLM）的冻结层来隐式地传递语义先验，增强多模态对齐而不需要微调。&lt;h4&gt;主要发现&lt;/h4&gt;MLVTG通过结构化状态空间动力学进行时间建模，通过文本先验进行语义净化，实现了更精确的定位。在QVHighlights、Charades-STA和TVSum数据集上的实验表明，MLVTG达到了最先进的性能，并显著优于现有基线。&lt;h4&gt;结论&lt;/h4&gt;MLVTG框架在视频时间定位任务上表现出色，为视频理解领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Temporal Grounding (VTG), which aims to localize video clipscorresponding to natural language queries, is a fundamental yet challengingtask in video understanding. Existing Transformer-based methods often sufferfrom redundant attention and suboptimal multi-modal alignment. To address theselimitations, we propose MLVTG, a novel framework that integrates two keymodules: MambaAligner and LLMRefiner. MambaAligner uses stacked Vision Mambablocks as a backbone instead of Transformers to model temporal dependencies andextract robust video representations for multi-modal alignment. LLMRefinerleverages the specific frozen layer of a pre-trained Large Language Model (LLM)to implicitly transfer semantic priors, enhancing multi-modal alignment withoutfine-tuning. This dual alignment strategy, temporal modeling via structuredstate-space dynamics and semantic purification via textual priors, enables moreprecise localization. Extensive experiments on QVHighlights, Charades-STA, andTVSum demonstrate that MLVTG achieves state-of-the-art performance andsignificantly outperforms existing baselines.</description>
      <author>example@mail.com (Zhiyi Zhu, Xiaoyu Wu, Zihao Liu, Linlin Yang)</author>
      <guid isPermaLink="false">2506.08512v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>SurfR: Surface Reconstruction with Multi-scale Attention</title>
      <link>http://arxiv.org/abs/2506.08635v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in 3DV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种快速且准确的无序点云表面重建算法，采用隐式表示。&lt;h4&gt;背景&lt;/h4&gt;现有学习方法要么是针对单个对象的表示，使用小型神经网络模型，允许高表面细节，但需要针对每个对象进行训练；要么是通用表示，需要更大的模型，能够泛化到新的形状，但缺乏细节，推理速度慢。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的隐式表示方法，用于通用3D形状，其在最佳分辨率下比所有基线算法都要快，与最先进技术的性能损失微乎其微。&lt;h4&gt;方法&lt;/h4&gt;通过三个关键贡献实现了最佳精度-速度权衡。首先，为了加快重建速度，展示在早期阶段无需使用查询点进行特征提取（懒查询）。其次，使用并行多尺度网格表示，以开发对不同噪声水平和输入分辨率的鲁棒特征。最后，证明跨尺度的注意力可以提供改进的重建结果。&lt;h4&gt;主要发现&lt;/h4&gt;提出的算法在精度和速度方面取得了最佳平衡，通过懒查询、多尺度网格表示和跨尺度注意力等技术，实现了快速且准确的表面重建。&lt;h4&gt;结论&lt;/h4&gt;该方法在重建无序点云表面方面表现优异，为点云处理领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种针对无序点云的快速且准确的表面重建算法，采用隐式表示。近期学习方法要么是单对象表示，使用小型神经网络模型，允许高表面细节，但需要针对每个对象进行训练，要么是通用表示，需要更大的模型，能够泛化到新的形状，但缺乏细节，推理速度慢。我们提出了一种新的隐式表示方法，用于通用3D形状，其在最佳分辨率下比所有基线算法都要快，与最先进技术的性能损失微乎其微。我们通过三个关键贡献实现了最佳精度-速度权衡。首先，为了加快重建速度，展示在早期阶段无需使用查询点进行特征提取（懒查询）。其次，使用并行多尺度网格表示，以开发对不同噪声水平和输入分辨率的鲁棒特征。最后，证明跨尺度的注意力可以提供改进的重建结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a fast and accurate surface reconstruction algorithm forunorganized point clouds using an implicit representation. Recent learningmethods are either single-object representations with small neural models thatallow for high surface details but require per-object training or generalizedrepresentations that require larger models and generalize to newer shapes butlack details, and inference is slow. We propose a new implicit representationfor general 3D shapes that is faster than all the baselines at their optimumresolution, with only a marginal loss in performance compared to thestate-of-the-art. We achieve the best accuracy-speed trade-off using three keycontributions. Many implicit methods extract features from the point cloud toclassify whether a query point is inside or outside the object. First, to speedup the reconstruction, we show that this feature extraction does not need touse the query point at an early stage (lazy query). Second, we use a parallelmulti-scale grid representation to develop robust features for different noiselevels and input resolutions. Finally, we show that attention across scales canprovide improved reconstruction results.</description>
      <author>example@mail.com (Siddhant Ranade, Gonçalo Dias Pais, Ross Tyler Whitaker, Jacinto C. Nascimento, Pedro Miraldo, Srikumar Ramalingam)</author>
      <guid isPermaLink="false">2506.08635v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Bridging RDF Knowledge Graphs with Graph Neural Networks for Semantically-Rich Recommender Systems</title>
      <link>http://arxiv.org/abs/2506.08743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at DASFAA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将RDF知识图谱与图神经网络（GNNs）综合的方法，以充分利用RDF知识图谱的语义信息，并评估了不同GNN在推荐任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管根据W3C标准RDF创建了超过一千个知识图谱，但它们的丰富语义信息在基于GNN的推荐系统中尚未得到充分利用。&lt;h4&gt;目的&lt;/h4&gt;提出一种综合方法，将RDF知识图谱与GNNs结合，以利用RDF对象属性中的拓扑信息和RDF数据类型属性中的内容信息。&lt;h4&gt;方法&lt;/h4&gt;深入评估了各种GNN，分析了不同的语义特征初始化和图结构异质性对推荐任务性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;通过在涉及数百万节点RDF图的多场景推荐实验中，证明了利用RDF知识图谱的语义丰富性可以显著提高推荐系统。&lt;h4&gt;结论&lt;/h4&gt;为基于GNN的推荐系统在Linked Open Data云上奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have substantially advanced the field of recommender systems. However, despite the creation of more than a thousand knowledge graphs (KGs) under the W3C standard RDF, their rich semantic information has not yet been fully leveraged in GNN-based recommender systems. To address this gap, we propose a comprehensive integration of RDF KGs with GNNs that utilizes both the topological information from RDF object properties and the content information from RDF datatype properties. Our main focus is an in-depth evaluation of various GNNs, analyzing how different semantic feature initializations and types of graph structure heterogeneity influence their performance in recommendation tasks. Through experiments across multiple recommendation scenarios involving multi-million-node RDF graphs, we demonstrate that harnessing the semantic richness of RDF KGs significantly improves recommender systems and lays the groundwork for GNN-based recommenders systems for the Linked Open Data cloud. The code and data are available on our GitHub repository: https://github.com/davidlamprecht/rdf-gnn-recommendation&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have substantially advanced the field ofrecommender systems. However, despite the creation of more than a thousandknowledge graphs (KGs) under the W3C standard RDF, their rich semanticinformation has not yet been fully leveraged in GNN-based recommender systems.To address this gap, we propose a comprehensive integration of RDF KGs withGNNs that utilizes both the topological information from RDF object propertiesand the content information from RDF datatype properties. Our main focus is anin-depth evaluation of various GNNs, analyzing how different semantic featureinitializations and types of graph structure heterogeneity influence theirperformance in recommendation tasks. Through experiments across multiplerecommendation scenarios involving multi-million-node RDF graphs, wedemonstrate that harnessing the semantic richness of RDF KGs significantlyimproves recommender systems and lays the groundwork for GNN-based recommendersystems for the Linked Open Data cloud. The code and data are available on ourGitHub repository: https://github.com/davidlamprecht/rdf-gnn-recommendation</description>
      <author>example@mail.com (Michael Färber, David Lamprecht, Yuni Susanti)</author>
      <guid isPermaLink="false">2506.08743v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Context-aware TFL: A Universal Context-aware Contrastive Learning Framework for Temporal Forgery Localization</title>
      <link>http://arxiv.org/abs/2506.08493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个名为UniCaCLF的通用上下文感知对比学习框架，用于视频伪造定位，并在五个公共数据集上取得了优于现有算法的性能。&lt;h4&gt;背景&lt;/h4&gt;目前多媒体取证领域的研究主要集中于检测伪造的音频-视频内容，并取得了显著成就。然而，这些工作只将深度伪造检测视为分类任务，忽略了视频部分片段被篡改的情况。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种用于视频伪造定位的通用上下文感知对比学习框架UniCaCLF。&lt;h4&gt;方法&lt;/h4&gt;该方法利用监督对比学习通过异常检测来发现和识别伪造瞬间，实现时间伪造片段的精确定位。此外，还提出了一种新颖的上下文感知感知层，利用异构激活操作和自适应上下文更新器构建上下文感知对比目标，通过对比伪造瞬间与真实瞬间的特征距离全局上下文来增强伪造瞬间特征的判别性。还引入了一种高效的上下文感知对比编码，以监督样本的方式进一步推动真实和伪造瞬间特征的可区分性，抑制跨样本影响，提高时间伪造定位性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的UniCaCLF在五个公共数据集上显著优于现有的竞争算法。&lt;h4&gt;结论&lt;/h4&gt;UniCaCLF是一种有效的视频伪造定位方法，能够提高时间伪造定位的性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a universal context-aware contrastive learning framework called UniCaCLF for video forgery localization, which has demonstrated superior performance over existing algorithms on five public datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most research efforts in the multimedia forensics domain have focused ondetecting forgery audio-visual content and reached sound achievements. However,these works only consider deepfake detection as a classification task andignore the case where partial segments of the video are tampered with. Temporalforgery localization (TFL) of small fake audio-visual clips embedded in realvideos is still challenging and more in line with realistic applicationscenarios. To resolve this issue, we propose a universal context-awarecontrastive learning framework (UniCaCLF) for TFL. Our approach leveragessupervised contrastive learning to discover and identify forged instants bymeans of anomaly detection, allowing for the precise localization of temporalforged segments. To this end, we propose a novel context-aware perception layerthat utilizes a heterogeneous activation operation and an adaptive contextupdater to construct a context-aware contrastive objective, which enhances thediscriminability of forged instant features by contrasting them with genuineinstant features in terms of their distances to the global context. Anefficient context-aware contrastive coding is introduced to further push thelimit of instant feature distinguishability between genuine and forged instantsin a supervised sample-by-sample manner, suppressing the cross-sample influenceto improve temporal forgery localization performance. Extensive experimentalresults over five public datasets demonstrate that our proposed UniCaCLFsignificantly outperforms the state-of-the-art competing algorithms.</description>
      <author>example@mail.com (Qilin Yin, Wei Lu, Xiangyang Luo, Xiaochun Cao)</author>
      <guid isPermaLink="false">2506.08493v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Robust Visual Localization via Semantic-Guided Multi-Scale Transformer</title>
      <link>http://arxiv.org/abs/2506.08526v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合多尺度特征学习和语义场景理解的视觉定位框架，以应对动态环境中的挑战。&lt;h4&gt;背景&lt;/h4&gt;在动态环境中，如光照变化、恶劣天气和移动物体等，视觉定位仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，提出了一个框架，该框架结合多尺度特征学习和语义场景理解。&lt;h4&gt;方法&lt;/h4&gt;该方法使用具有跨尺度注意力的分层Transformer，融合几何细节和上下文线索，同时保持空间精度并适应环境变化。通过神经场景表示进行语义监督，引导网络学习视图不变的特征，编码持久性结构信息，同时抑制复杂的环境干扰。&lt;h4&gt;主要发现&lt;/h4&gt;在TartanAir上的实验表明，该方法在具有动态物体、光照变化和遮挡的挑战场景中优于现有的姿态回归方法。&lt;h4&gt;结论&lt;/h4&gt;将多尺度处理与语义引导相结合，为现实世界动态环境中的鲁棒视觉定位提供了一种有前景的策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual localization remains challenging in dynamic environments wherefluctuating lighting, adverse weather, and moving objects disrupt appearancecues. Despite advances in feature representation, current absolute poseregression methods struggle to maintain consistency under varying conditions.To address this challenge, we propose a framework that synergistically combinesmulti-scale feature learning with semantic scene understanding. Our approachemploys a hierarchical Transformer with cross-scale attention to fuse geometricdetails and contextual cues, preserving spatial precision while adapting toenvironmental changes. We improve the performance of this architecture withsemantic supervision via neural scene representation during training, guidingthe network to learn view-invariant features that encode persistent structuralinformation while suppressing complex environmental interference. Experimentson TartanAir demonstrate that our approach outperforms existing pose regressionmethods in challenging scenarios with dynamic objects, illumination changes,and occlusions. Our findings show that integrating multi-scale processing withsemantic guidance offers a promising strategy for robust visual localization inreal-world dynamic environments.</description>
      <author>example@mail.com (Zhongtao Tian, Wenhao Huang, Zhidong Chen, Xiao Wei Sun)</author>
      <guid isPermaLink="false">2506.08526v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Urban Incident Prediction with Graph Neural Networks: Integrating Government Ratings and Crowdsourced Reports</title>
      <link>http://arxiv.org/abs/2506.08740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的多视角、多输出模型，用于预测城市事件的真实状态，并分析了纽约市城市事件的数据集。&lt;h4&gt;背景&lt;/h4&gt;GNN在预测城市基础设施问题等方面被广泛应用。政府官员希望了解哪些社区发生了如路面坑洼或鼠害等问题。政府通过检查评分来观察每个社区的事件真实状态，但这些评分只针对少数社区和事件类型。同时，通过众包报告也可以观察到事件状态，但这些报告可能因不同的报告行为而存在偏差。&lt;h4&gt;目的&lt;/h4&gt;提出一种模型，使用无偏差的评分数据和有偏差的报告数据来预测事件的真实潜在状态。&lt;h4&gt;方法&lt;/h4&gt;设计了一个基于GNN的多视角、多输出模型，并收集、标准化了纽约市3年内的9,615,863条众包报告和1,041,415条政府检查评分数据，涵盖139种事件类型。&lt;h4&gt;主要发现&lt;/h4&gt;模型在真实和半合成数据上表现优于仅使用报告数据或仅使用评分数据的模型，尤其是在评分数据稀疏且报告可预测评分的情况下。此外，还量化了众包报告中的人口统计偏差，例如高收入社区的报告问题率更高。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法对于使用异构、稀疏和有偏差的数据进行潜在状态预测具有广泛的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNNs) are widely used in urban spatiotemporal forecasting, such as predicting infrastructure problems. In this setting, government officials wish to know in which neighborhoods incidents like potholes or rodent issues occur. The true state of incidents (e.g., street conditions) for each neighborhood is observed via government inspection ratings. However, these ratings are only conducted for a sparse set of neighborhoods and incident types. We also observe the state of incidents via crowdsourced reports, which are more densely observed but may be biased due to heterogeneous reporting behavior. First, for such settings, we propose a multiview, multioutput GNN-based model that uses both unbiased rating data and biased reporting data to predict the true latent state of incidents. Second, we investigate a case study of New York City urban incidents and collect, standardize, and make publicly available a dataset of 9,615,863 crowdsourced reports and 1,041,415 government inspection ratings over 3 years and across 139 types of incidents. Finally, we show on both real and semi-synthetic data that our model can better predict the latent state compared to models that use only reporting data or models that use only rating data, especially when rating data is sparse and reports are predictive of ratings. We also quantify demographic biases in crowdsourced reporting, e.g., higher-income neighborhoods report problems at higher rates. Our analysis showcases a widely applicable approach for latent state prediction using heterogeneous, sparse, and biased data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are widely used in urban spatiotemporalforecasting, such as predicting infrastructure problems. In this setting,government officials wish to know in which neighborhoods incidents likepotholes or rodent issues occur. The true state of incidents (e.g., streetconditions) for each neighborhood is observed via government inspectionratings. However, these ratings are only conducted for a sparse set ofneighborhoods and incident types. We also observe the state of incidents viacrowdsourced reports, which are more densely observed but may be biased due toheterogeneous reporting behavior. First, for such settings, we propose amultiview, multioutput GNN-based model that uses both unbiased rating data andbiased reporting data to predict the true latent state of incidents. Second, weinvestigate a case study of New York City urban incidents and collect,standardize, and make publicly available a dataset of 9,615,863 crowdsourcedreports and 1,041,415 government inspection ratings over 3 years and across 139types of incidents. Finally, we show on both real and semi-synthetic data thatour model can better predict the latent state compared to models that use onlyreporting data or models that use only rating data, especially when rating datais sparse and reports are predictive of ratings. We also quantify demographicbiases in crowdsourced reporting, e.g., higher-income neighborhoods reportproblems at higher rates. Our analysis showcases a widely applicable approachfor latent state prediction using heterogeneous, sparse, and biased data.</description>
      <author>example@mail.com (Sidhika Balachandar, Shuvom Sadhuka, Bonnie Berger, Emma Pierson, Nikhil Garg)</author>
      <guid isPermaLink="false">2506.08740v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Zero-Shot Framework for Deepfake Hate Speech Detection in Low-Resource Languages</title>
      <link>http://arxiv.org/abs/2506.08372v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in Interpseech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种用于检测深度伪造音频中仇恨言论的新型多模态框架，即使在零样本情况下也表现出色。&lt;h4&gt;背景&lt;/h4&gt;传统的仇恨言论检测方法在深度伪造音频中效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效检测深度伪造音频中仇恨言论的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法采用对比学习，联合对跨语言的音频和文本表示进行对齐。构建了包含127,290对文本和合成语音样本的基准数据集，涵盖英语和五种印度低资源语言（印地语、孟加拉语、马拉地语、泰米尔语、泰卢固语）。模型学习共享语义嵌入空间，实现鲁棒的跨语言和跨模态分类。&lt;h4&gt;主要发现&lt;/h4&gt;在两个多语言测试集上的实验表明，该方法优于基线，准确率达到0.819和0.701，并且能够很好地推广到未见过的语言。这证明了在低资源设置中，结合模态进行仇恨言论检测的优势，尤其是在单模态模型失效的情况下。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在合成媒体中检测仇恨言论方面具有优势，特别是在低资源环境中。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a novel multimodal framework for hate speech detection in deepfake audio, excelling even in zero-shot scenarios. Unlike previous approaches, our method uses contrastive learning to jointly align audio and text representations across languages. We present the first benchmark dataset with 127,290 paired text and synthesized speech samples in six languages: English and five low-resource Indian languages (Hindi, Bengali, Marathi, Tamil, Telugu). Our model learns a shared semantic embedding space, enabling robust cross-lingual and cross-modal classification. Experiments on two multilingual test sets show our approach outperforms baselines, achieving accuracies of 0.819 and 0.701, and generalizes well to unseen languages. This demonstrates the advantage of combining modalities for hate speech detection in synthetic media, especially in low-resource settings where unimodal models falter. The Dataset is available at https://www.iab-rubric.org/resources.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a novel multimodal framework for hate speech detectionin deepfake audio, excelling even in zero-shot scenarios. Unlike previousapproaches, our method uses contrastive learning to jointly align audio andtext representations across languages. We present the first benchmark datasetwith 127,290 paired text and synthesized speech samples in six languages:English and five low-resource Indian languages (Hindi, Bengali, Marathi, Tamil,Telugu). Our model learns a shared semantic embedding space, enabling robustcross-lingual and cross-modal classification. Experiments on two multilingualtest sets show our approach outperforms baselines, achieving accuracies of0.819 and 0.701, and generalizes well to unseen languages. This demonstratesthe advantage of combining modalities for hate speech detection in syntheticmedia, especially in low-resource settings where unimodal models falter. TheDataset is available at https://www.iab-rubric.org/resources.</description>
      <author>example@mail.com (Rishabh Ranjan, Likhith Ayinala, Mayank Vatsa, Richa Singh)</author>
      <guid isPermaLink="false">2506.08372v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>GIQ: Benchmarking 3D Geometric Reasoning of Vision Foundation Models with Simulated and Real Polyhedra</title>
      <link>http://arxiv.org/abs/2506.08194v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GIQ，一个专门用于评估视觉和视觉-语言基础模型几何推理能力的全面基准。&lt;h4&gt;背景&lt;/h4&gt;虽然单目3D重建方法和视觉-语言模型在标准基准上表现出色，但它们对几何特性的真正理解仍然不清楚。&lt;h4&gt;目的&lt;/h4&gt;GIQ旨在提供一个平台，以评估和解决当前模型在几何智能方面的关键差距。&lt;h4&gt;方法&lt;/h4&gt;GIQ包括合成和真实世界的224个不同多面体的图像，通过单目3D重建、3D对称性检测、心理旋转测试和零样本形状分类任务进行系统性实验。&lt;h4&gt;主要发现&lt;/h4&gt;实验揭示了当前模型在重建基本几何形状、检测3D对称性和心理旋转等任务中的显著不足。&lt;h4&gt;结论&lt;/h4&gt;GIQ公开可用，为突出和解决几何智能的关键差距提供了一个结构化的平台，有助于未来在鲁棒、几何感知的表示学习方面的进步。&lt;h4&gt;翻译&lt;/h4&gt;The abstract discusses the introduction of GIQ, a comprehensive benchmark designed to evaluate the geometric reasoning capabilities of vision and vision-language foundation models. The background states that although impressive results have been achieved on standard benchmarks, the true understanding of geometric properties remains unclear. The purpose of GIQ is to provide a platform for assessing and addressing critical gaps in geometric intelligence. The methods involve systematic experiments with synthetic and real-world images of diverse polyhedra, including various levels of complexity and symmetry, and tasks like monocular 3D reconstruction, 3D symmetry detection, mental rotation tests, and zero-shot shape classification. The main findings reveal significant shortcomings in current models, including struggles in reconstructing basic geometric forms and detecting 3D symmetries, as well as low accuracy in complex polyhedra. The conclusion is that GIQ is publicly available and aims to highlight and address critical gaps in geometric intelligence, facilitating future progress in robust, geometry-aware representation learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular 3D reconstruction methods and vision-language models (VLMs)demonstrate impressive results on standard benchmarks, yet their trueunderstanding of geometric properties remains unclear. We introduce GIQ , acomprehensive benchmark specifically designed to evaluate the geometricreasoning capabilities of vision and vision-language foundation models. GIQcomprises synthetic and real-world images of 224 diverse polyhedra - includingPlatonic, Archimedean, Johnson, and Catalan solids, as well as stellations andcompound shapes - covering varying levels of complexity and symmetry. Throughsystematic experiments involving monocular 3D reconstruction, 3D symmetrydetection, mental rotation tests, and zero-shot shape classification tasks, wereveal significant shortcomings in current models. State-of-the-artreconstruction algorithms trained on extensive 3D datasets struggle toreconstruct even basic geometric forms accurately. While foundation modelseffectively detect specific 3D symmetry elements via linear probing, theyfalter significantly in tasks requiring detailed geometric differentiation,such as mental rotation. Moreover, advanced vision-language assistants exhibitremarkably low accuracy on complex polyhedra, systematically misinterpretingbasic properties like face geometry, convexity, and compound structures. GIQ ispublicly available, providing a structured platform to highlight and addresscritical gaps in geometric intelligence, facilitating future progress inrobust, geometry-aware representation learning.</description>
      <author>example@mail.com (Mateusz Michalkiewicz, Anekha Sokhal, Tadeusz Michalkiewicz, Piotr Pawlikowski, Mahsa Baktashmotlagh, Varun Jampani, Guha Balakrishnan)</author>
      <guid isPermaLink="false">2506.08194v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>SSS: Semi-Supervised SAM-2 with Efficient Prompting for Medical Imaging Segmentation</title>
      <link>http://arxiv.org/abs/2506.08949v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SSS（Semi-Supervised SAM-2）的半监督学习方法，用于医学图像分割，通过利用SAM-2的特征提取能力来提高医学图像分割的性能。&lt;h4&gt;背景&lt;/h4&gt;在信息爆炸的时代，如何有效地利用大规模未标记数据，同时减少对高质量像素级标注的依赖，是医学图像领域的一个关键挑战。&lt;h4&gt;目的&lt;/h4&gt;通过半监督学习（SSL）增强未标记数据的使用，提高完全监督模型的性能，并成为医学图像分析中一个非常有前景的研究方向。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法基于单流“弱到强”一致性正则化框架，引入了判别特征增强（DFE）机制，以进一步探索由多种数据增强策略在多个视角中引入的特征差异。此外，开发了一个提示生成器，该生成器集成了物理约束与滑动窗口（PCSW）机制，为未标记数据生成输入提示。&lt;h4&gt;主要发现&lt;/h4&gt;在ACDC和BHSD两个多标签数据集上进行了广泛的实验，结果表明所提出的方法在半监督医学图像分割方面优于现有方法，SSS在BHSD上的平均Dice分数为53.15，比之前的最先进方法高出+3.65 Dice。&lt;h4&gt;结论&lt;/h4&gt;SSS方法在医学图像分割方面具有优越性，并有望在医学图像分析中得到广泛应用。&lt;h4&gt;翻译&lt;/h4&gt;在信息爆炸的时代，有效地利用大规模未标记数据的同时，减少对高质量像素级标注的依赖，在医学图像领域仍然是一个关键挑战。半监督学习（SSL）通过促进知识迁移，显著提高了完全监督模型的性能，并成为医学图像分析中的一个非常有前景的研究方向。受视觉基础模型（例如SAM-2）提供丰富先验知识能力的影响，本文提出了一种名为SSS（Semi-Supervised SAM-2）的新方法，该方法利用SAM-2的鲁棒特征提取能力来揭示未标记医学图像中的潜在知识，从而有效地增强完全监督医学图像分割的特征支持。具体而言，本文在单流“弱到强”一致性正则化框架的基础上，引入了一种判别特征增强（DFE）机制，以进一步探索由多种数据增强策略在多个视角中引入的特征差异。通过利用多尺度增强技术中的特征相似性和差异性，该方法重建并建模特征，从而有效地优化了显著区域。此外，开发了一个提示生成器，该生成器集成了物理约束与滑动窗口（PCSW）机制，为未标记数据生成输入提示，以满足SAM-2对额外提示的需求。广泛的实验表明，所提出的方法在两个多标签数据集（即ACDC和BHSD）上的半监督医学图像分割方面优于现有方法。值得注意的是，SSS在BHSD上的平均Dice分数为53.15，比之前的最先进方法高出+3.65 Dice。代码可在https://github.com/AIGeeksGroup/SSS上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of information explosion, efficiently leveraging large-scaleunlabeled data while minimizing the reliance on high-quality pixel-levelannotations remains a critical challenge in the field of medical imaging.Semi-supervised learning (SSL) enhances the utilization of unlabeled data byfacilitating knowledge transfer, significantly improving the performance offully supervised models and emerging as a highly promising research directionin medical image analysis. Inspired by the ability of Vision Foundation Models(e.g., SAM-2) to provide rich prior knowledge, we propose SSS (Semi-SupervisedSAM-2), a novel approach that leverages SAM-2's robust feature extractioncapabilities to uncover latent knowledge in unlabeled medical images, thuseffectively enhancing feature support for fully supervised medical imagesegmentation. Specifically, building upon the single-stream "weak-to-strong"consistency regularization framework, this paper introduces a DiscriminativeFeature Enhancement (DFE) mechanism to further explore the featurediscrepancies introduced by various data augmentation strategies acrossmultiple views. By leveraging feature similarity and dissimilarity acrossmulti-scale augmentation techniques, the method reconstructs and models thefeatures, thereby effectively optimizing the salient regions. Furthermore, aprompt generator is developed that integrates Physical Constraints with aSliding Window (PCSW) mechanism to generate input prompts for unlabeled data,fulfilling SAM-2's requirement for additional prompts. Extensive experimentsdemonstrate the superiority of the proposed method for semi-supervised medicalimage segmentation on two multi-label datasets, i.e., ACDC and BHSD. Notably,SSS achieves an average Dice score of 53.15 on BHSD, surpassing the previousstate-of-the-art method by +3.65 Dice. Code will be available athttps://github.com/AIGeeksGroup/SSS.</description>
      <author>example@mail.com (Hongjie Zhu, Xiwei Liu, Rundong Xue, Zeyu Zhang, Yong Xu, Daji Ergu, Ying Cai, Yang Zhao)</author>
      <guid isPermaLink="false">2506.08949v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>The connection between galaxy mergers, star formation and AGN activity in the HSC-SSP</title>
      <link>http://arxiv.org/abs/2506.08469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 12 figures, accepted to ApJ&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了星系合并引发的内部气体流入对星形成率、超大质量黑洞增长和活动星系核（AGN）的影响，通过新的方法对星系分类和属性进行测量。&lt;h4&gt;背景&lt;/h4&gt;内部气体流入被认为是通过星系合并增强星形成率、促进超大质量黑洞增长和刺激活动星系核。然而，由于合并分类和星系及AGN属性量化的困难，这些现象的量化仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;定量研究合并-星形成率-AGN之间的联系，并使用新的方法对星系进行分类和属性测量。&lt;h4&gt;方法&lt;/h4&gt;通过微调预训练的深度表示学习模型Zoobot，利用来自Galaxy Cruise项目的图像和标签在HSC-SSP观测图像中识别合并。使用ProSpect代码拟合GAMA光谱来获取星系和AGN属性，该代码在远紫外到远红外波段的泛色光范围内进行拟合。&lt;h4&gt;主要发现&lt;/h4&gt;在合并和对照组之间，星形成率（SFR）和AGN活动的差异很小。经过进一步可视化纯化合并样本后，发现对星系和后合并星系的影响更大，这些发现表明，长期过程是星形成和AGN活动的重要驱动因素。&lt;h4&gt;结论&lt;/h4&gt;本文的结果对使用长期时间尺度探针提出了一个警示。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由星系合并驱动的内部气体流入被认为可以增强星形成率（SFR），促进超大质量黑洞的增长并刺激活动星系核（AGN）。然而，由于在分类合并和量化星系和AGN属性方面存在困难，这些现象的量化仍然是一个挑战。我们使用Hyper Suprime-Cam Subaru战略计划（HSC-SSP）的星系，通过新的方法对星系分类和属性进行测量，定量检验合并-SFR-AGN联系。在HSC-SSP观测图像中，通过微调预训练的深度表示学习模型Zoobot，利用基于Galaxy Cruise项目的图像和标签识别合并。我们使用ProSpect代码拟合GAMA光谱生成的星系和AGN属性，该代码在泛色光范围内从远紫外到远红外波段进行拟合。在合并和对照组之间，SFR和AGN活动的差异很小，经过进一步可视化纯化合并样本后，发现对星系和后合并星系的影响更大。这些发现表明，长期过程是星形成和AGN活动的重要驱动因素，对使用长期时间尺度探针提出了一个警示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Internal gas inflows driven by galaxy mergers are considered to enhance starformation rates (SFR), fuel supermassive black hole growth and stimulate activegalactic nuclei (AGN). However, quantifying these phenomena remains achallenge, due to difficulties both in classifying mergers and in quantifyinggalaxy and AGN properties. We quantitatively examine the merger-SFR-AGNconnection using Hyper Suprime-Cam Subaru Strategic Program (HSC-SSP) galaxiesusing novel methods for both galaxy classification and property measurements.}{Mergers in HSC-SSP observational images are identified through fine-tuningZoobot, a pretrained deep representation learning model, using images andlabels based on the Galaxy Cruise project. We use galaxy and AGN propertiesthat were produced by fitting Galaxy and Mass Assembly (GAMA) spectra using theSED fitting code ProSpect, which fits panchromatically across the far-UVthrough far-infrared wavelengths and obtains galaxy and AGN propertiessimultaneously.} \textbf{{Little differences are seen in SFR and AGN activitybetween mergers and controls, with $\Delta \mathrm{SFR}=-0.009\pm 0.003$ dex,$\Delta f_{\mathrm{AGN}}=-0.010\pm0.033$ dex and $\DeltaL_{\mathrm{AGN}}=0.002\pm0.025$ dex. After further visual purification of themerger sample, we find $\Delta \mathrm{SFR}=-0.033\pm0.014$ dex, $\Deltaf_{\mathrm{AGN}}=-0.024\pm0.170$ dex, and $\DeltaL_{\mathrm{AGN}}=0.019\pm0.129$ dex for pairs, and $\Delta\mathrm{SFR}=-0.057\pm0.024$ dex, $\Delta f_{\mathrm{AGN}}=0.286\pm0.270$ dex,and $\Delta L_{\mathrm{AGN}}=0.329\pm0.195$ dex for postmergers. These numberssuggest secular processes being an important driver for SF and AGN activity,and present a cautionary tale when using longer timescale tracers.</description>
      <author>example@mail.com (Kiyoaki Christopher Omori, Connor Bottrell, Sabine Bellstedt, Aaron Robotham, Hassen M. Yesuf, Andy D. Goulding, Marcin Sawicki, Tohru Nagao, Tsutomu T. Takeuchi)</author>
      <guid isPermaLink="false">2506.08469v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Large Deviations for Markovian Graphon Processes and Associated Dynamical Systems on Networks</title>
      <link>http://arxiv.org/abs/2506.08333v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  55 pages, no figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究快速变化的马尔可夫网络的时态模型，这些模型由随时间演化的空间相关核调制，这些核定义了边形成和消解的速率。在考虑的区域内，图论值过程的窗口平均值在适当的时间间隔内是系统的自然状态描述符。在适当的跳率核条件下，我们为平均过适当时间窗口的图论过程建立了大数定律和大型偏差原理（LDP），既在弱拓扑下，也在相关图论空间中的割范数下。尽管问题设置和分析比已研究的静态随机网络模型更为复杂，但与速率函数相关的变分问题具有显式解，从而为速率函数提供了一种同样易于处理的、不同的表达式，类似于静态情况。利用这些结果，我们进一步为受底层演化的网络驱动的节点值动态系统建立了LDP。&lt;h4&gt;背景&lt;/h4&gt;本文研究的是快速变化的马尔可夫网络的时态模型，以及由时间演化的空间相关核调制形成的模型。&lt;h4&gt;目的&lt;/h4&gt;本文旨在建立快速变化马尔可夫网络时态模型的大数定律和大型偏差原理。&lt;h4&gt;方法&lt;/h4&gt;本文采用了一种基于窗口平均值的方法来描述系统的状态，并利用适当的条件建立了大数定律和大型偏差原理。&lt;h4&gt;主要发现&lt;/h4&gt;本文在适当条件下为图论过程建立了大数定律和大型偏差原理，并发现与速率函数相关的变分问题具有显式解。&lt;h4&gt;结论&lt;/h4&gt;本文为受底层演化的网络驱动的节点值动态系统建立了大型偏差原理。&lt;h4&gt;翻译&lt;/h4&gt;我们考虑由随时间演化的空间相关核调节的快速变化马尔可夫网络的时态模型，这些核定义了边形成和消解的速率。或者，这些也可以看作是在长时间范围内具有 $O(1)$ 跳转速率的马尔可夫网络。在考虑的区域内，图论值过程在适当时间间隔内的窗口平均值是系统的自然状态描述符。在跳转率核的适当条件下，我们为平均过适当时间窗口的图论过程建立了大数定律和大型偏差原理（LDP），既在弱拓扑下，也在相关图论空间中的割范数下。尽管问题设置和分析比已研究的静态随机网络模型更为复杂，但与速率函数相关的变分问题具有显式解，从而为速率函数提供了一种同样易于处理的、不同的表达式，类似于静态情况。利用这些结果，我们然后为受底层演化的网络驱动的节点值动态系统建立了LDP。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider temporal models of rapidly changing Markovian networks modulatedby time-evolving spatially dependent kernels that define rates for edgeformation and dissolution. Alternatively, these can be viewed as Markoviannetworks with $O(1)$ jump rates viewed over a long time horizon. In the regimeswe consider, the window averages of graphon valued processes over suitable timeintervals are natural state descriptors for the system. Under appropriateconditions on the jump-rate kernels, we establish laws of large numbers andlarge deviation principles(LDP) for the graphon processes averaged over asuitable time window, both in the weak topology and with respect to the cutnorm in the associated graphon space. Although the problem setting and analysisare more involved than for the well-studied static random network model, thevariational problem associated with the rate function admits an explicitsolution, yielding an equally tractable, though different, expression for therate function, similar to the static case. Using these results, we thenestablish the LDP for node-valent dynamical systems driven by the underlyingevolving network.</description>
      <author>example@mail.com (Shankar Bhamidi, Amarjit Budhiraja, Souvik Ray)</author>
      <guid isPermaLink="false">2506.08333v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>BioLangFusion: Multimodal Fusion of DNA, mRNA, and Protein Language Models</title>
      <link>http://arxiv.org/abs/2506.08936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of ICML 2025 Workshop on Multi-modal Foundation  Proceedings of ICML 2025 Workshop on Multi-modal Foundation Proceedings of  ICML 2025 Workshop on Multi-modal Foundation Models and Large Language Models  for Life Sciences&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BioLangFusion的简单方法，用于将预训练的DNA、mRNA和蛋白质语言模型集成到统一的分子表示中。&lt;h4&gt;背景&lt;/h4&gt;该方法受到分子生物学中心法则（从基因到转录再到蛋白质的信息流动）的启发。&lt;h4&gt;目的&lt;/h4&gt;目的是通过在生物学上有意义的密码子级别（编码一个氨基酸的三个核苷酸）对齐每个模态的嵌入，确保直接的跨模态对应关系。&lt;h4&gt;方法&lt;/h4&gt;BioLangFusion研究了三种标准的融合技术：(i) 密码子级别的嵌入连接，(ii) 受多实例学习启发的熵正则化注意力池化，以及(iii) 跨模态多头注意力。每种技术都为结合模态特定的信号提供了不同的归纳偏差。这些方法不需要额外的预训练或修改基础模型，可以方便地与现有的基于序列的基础模型集成。&lt;h4&gt;主要发现&lt;/h4&gt;在五个分子属性预测任务中，BioLangFusion优于强大的单模态基线，表明即使是简单的预训练模型融合也能以最小的开销捕获互补的多组学信息。&lt;h4&gt;结论&lt;/h4&gt;BioLangFusion展示了预训练模型融合的潜力，即使在简单的情况下也能有效地整合多模态信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present BioLangFusion, a simple approach for integrating pre-trained DNA,mRNA, and protein language models into unified molecular representations.Motivated by the central dogma of molecular biology (information flow from geneto transcript to protein), we align per-modality embeddings at the biologicallymeaningful codon level (three nucleotides encoding one amino acid) to ensuredirect cross-modal correspondence. BioLangFusion studies three standard fusiontechniques: (i) codon-level embedding concatenation, (ii) entropy-regularizedattention pooling inspired by multiple-instance learning, and (iii) cross-modalmulti-head attention -- each technique providing a different inductive bias forcombining modality-specific signals. These methods require no additionalpre-training or modification of the base models, allowing straightforwardintegration with existing sequence-based foundation models. Across fivemolecular property prediction tasks, BioLangFusion outperforms strong unimodalbaselines, showing that even simple fusion of pre-trained models can capturecomplementary multi-omic information with minimal overhead.</description>
      <author>example@mail.com (Amina Mollaysa, Artem Moskale, Pushpak Pati, Tommaso Mansi, Mangal Prakash, Rui Liao)</author>
      <guid isPermaLink="false">2506.08936v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>HSG-12M: A Large-Scale Spatial Multigraph Dataset</title>
      <link>http://arxiv.org/abs/2506.08618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  39 pages, 13 figures, 3 tables. Code &amp; pipeline:  [https://github.com/sarinstein-yan/Poly2Graph] Dataset:  [https://github.com/sarinstein-yan/HSG-12M] Dataset released under CC BY 4.0&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了HSG-12M，这是第一个大规模的基于空间多图的数据库，其中包含了在度量空间中嵌入的图，保留了两个节点之间多个几何上不同的轨迹作为单独的边。HSG-12M包含来自1.77TB光谱势数据的11.6百万静态和5.1百万动态哈密顿谱图，涵盖了1401种特征多项式类别。每个图编码了1D晶体能量谱在复平面上的完整几何，产生了超越传统节点坐标数据集的多样化、基于物理学的拓扑结构。&lt;h4&gt;背景&lt;/h4&gt;现有的图基准假设非空间、简单边，将物理上不同的路径合并为单个链接。&lt;h4&gt;目的&lt;/h4&gt;提出HSG-12M，以解决现有图基准的局限性，并促进几何感知图学习和数据驱动科学发现。&lt;h4&gt;方法&lt;/h4&gt;构建了HSG-12M数据集，并开发了Poly2Graph，这是一个高性能的开源管道，将任意的1D晶体哈密顿量映射到谱图。&lt;h4&gt;主要发现&lt;/h4&gt;HSG-12M展示了多边几何在规模学习中的新挑战，并揭示了谱图作为多项式、向量和矩阵的通用拓扑指纹，建立了代数到图的联系。&lt;h4&gt;结论&lt;/h4&gt;HSG-12M为几何感知图学习奠定了基础，并为凝聚态物理学及其他领域的科学发现提供了新的数据驱动机会。&lt;h4&gt;翻译&lt;/h4&gt;Existing graph benchmarks assume non-spatial, simple edges, collapsing physically distinct paths into a single link. We introduce HSG-12M, the first large-scale dataset of spatial multigraphs—graphs embedded in a metric space where multiple geometrically distinct trajectories between two nodes are retained as separate edges. HSG-12M contains 11.6 million static and 5.1 million dynamic Hamiltonian spectral graphs across 1401 characteristic-polynomial classes, derived from 177 TB of spectral potential data. Each graph encodes the full geometry of a 1-D crystal's energy spectrum on the complex plane, producing diverse, physics-grounded topologies that transcend conventional node-coordinate datasets. To enable future extensions, we release Poly2Graph: a high-performance, open-source pipeline that maps arbitrary 1-D crystal Hamiltonians to spectral graphs. Benchmarks with popular GNNs expose new challenges in learning from multi-edge geometry at scale. Beyond its practical utility, we show that spectral graphs serve as universal topological fingerprints of polynomials, vectors, and matrices, forging a new algebra-to-graph link. HSG-12M lays the groundwork for geometry-aware graph learning and new opportunities of data-driven scientific discovery in condensed matter physics and beyond.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing graph benchmarks assume non-spatial, simple edges, collapsingphysically distinct paths into a single link. We introduce HSG-12M, the firstlarge-scale dataset of $\textbf{spatial multigraphs}-$graphs embedded in ametric space where multiple geometrically distinct trajectories between twonodes are retained as separate edges. HSG-12M contains 11.6 million static and5.1 million dynamic $\textit{Hamiltonian spectral graphs}$ across 1401characteristic-polynomial classes, derived from 177 TB of spectral potentialdata. Each graph encodes the full geometry of a 1-D crystal's energy spectrumon the complex plane, producing diverse, physics-grounded topologies thattranscend conventional node-coordinate datasets. To enable future extensions,we release $\texttt{Poly2Graph}$: a high-performance, open-source pipeline thatmaps arbitrary 1-D crystal Hamiltonians to spectral graphs. Benchmarks withpopular GNNs expose new challenges in learning from multi-edge geometry atscale. Beyond its practical utility, we show that spectral graphs serve asuniversal topological fingerprints of polynomials, vectors, and matrices,forging a new algebra-to-graph link. HSG-12M lays the groundwork forgeometry-aware graph learning and new opportunities of data-driven scientificdiscovery in condensed matter physics and beyond.</description>
      <author>example@mail.com (Xianquan Yan, Hakan Akgün, Kenji Kawaguchi, N. Duane Loh, Ching Hua Lee)</author>
      <guid isPermaLink="false">2506.08618v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Intention-Conditioned Flow Occupancy Models</title>
      <link>http://arxiv.org/abs/2506.08902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于流匹配的概率模型，用于预测智能体在长期未来可能访问的状态（即占用度量）。该模型通过包含一个捕获用户意图的潜在变量来增加模型的表达性，并允许通过广义策略改进进行自适应调整。&lt;h4&gt;背景&lt;/h4&gt;大规模预训练在机器学习研究中扮演着重要角色，通过预训练大型基础模型，任何人都可以使用这些模型来适应和微调特定任务。这种方法在强化学习（RL）中也非常有吸引力，因为它提供了解决RL核心挑战（如样本效率和鲁棒性）的有力途径。&lt;h4&gt;目的&lt;/h4&gt;旨在解决RL中预训练大型模型的基本挑战，即动作具有长期依赖性，因此需要训练能够跨时间推理的基础模型。&lt;h4&gt;方法&lt;/h4&gt;使用流匹配构建概率模型来预测智能体在长期未来可能访问的状态，并包含一个捕获用户意图的潜在变量。&lt;h4&gt;主要发现&lt;/h4&gt;在36个基于状态和4个基于图像的基准任务上的实验表明，所提出的方法在回报上实现了1.8倍的中位数改进，成功率提高了36%。&lt;h4&gt;结论&lt;/h4&gt;提出的意图条件流动占用模型（InFOM）在样本效率和鲁棒性方面优于其他预训练方法，能够有效提高强化学习任务的表现。&lt;h4&gt;翻译&lt;/h4&gt;Large-scale pre-training has fundamentally changed how machine learning research is done today: large foundation models are trained once, and then can be used by anyone in the community (including those without data or computeresources to train a model from scratch) to adapt and fine-tune to specific tasks. Applying this same framework to reinforcement learning (RL) is appealing because it offers compelling avenues for addressing core challenges in RL, including sample efficiency and robustness. However, there remains a fundamental challenge to pre-train large models in the context of RL: actions have long-term dependencies, so training a foundation model that reasons across time is important. Recent advances in generative AI have provided new tools for modeling highly complex distributions. In this paper, we build a probabilistic model to predict which states an agent will visit in the temporally distant future (i.e., an occupancy measure) using flow matching. As large datasets are often constructed by many distinct users performing distinct tasks, we include in our model a latent variable capturing the user intention. This intention increases the expressivity of our model, and enables adaptation with generalized policy improvement. We call our proposed method intention-conditioned flow occupancy models (InFOM). Comparing with alternative methods for pre-training, our experiments on 36 state-based and 4 image-based benchmark tasks demonstrate that the proposed method achieves 1.8 times median improvement in returns and increases success rates by 36%. Website: https://chongyi-zheng.github.io/infom Code: https://github.com/chongyi-zheng/infom&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale pre-training has fundamentally changed how machine learningresearch is done today: large foundation models are trained once, and then canbe used by anyone in the community (including those without data or computeresources to train a model from scratch) to adapt and fine-tune to specifictasks. Applying this same framework to reinforcement learning (RL) is appealingbecause it offers compelling avenues for addressing core challenges in RL,including sample efficiency and robustness. However, there remains afundamental challenge to pre-train large models in the context of RL: actionshave long-term dependencies, so training a foundation model that reasons acrosstime is important. Recent advances in generative AI have provided new tools formodeling highly complex distributions. In this paper, we build a probabilisticmodel to predict which states an agent will visit in the temporally distantfuture (i.e., an occupancy measure) using flow matching. As large datasets areoften constructed by many distinct users performing distinct tasks, we includein our model a latent variable capturing the user intention. This intentionincreases the expressivity of our model, and enables adaptation withgeneralized policy improvement. We call our proposed methodintention-conditioned flow occupancy models (InFOM). Comparing with alternativemethods for pre-training, our experiments on $36$ state-based and $4$image-based benchmark tasks demonstrate that the proposed method achieves $1.8\times$ median improvement in returns and increases success rates by $36\%$.Website: https://chongyi-zheng.github.io/infom Code:https://github.com/chongyi-zheng/infom</description>
      <author>example@mail.com (Chongyi Zheng, Seohong Park, Sergey Levine, Benjamin Eysenbach)</author>
      <guid isPermaLink="false">2506.08902v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>MIRAGE: Multimodal foundation model and benchmark for comprehensive retinal OCT image analysis</title>
      <link>http://arxiv.org/abs/2506.08900v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MIRAGE的多模态基础模型，用于分析OCT和SLO图像，并提出了一种新的评估基准，旨在解决现有AI模型在眼科图像分析中的挑战。&lt;h4&gt;背景&lt;/h4&gt;人工智能在分析眼科图像，如OCT图像中起到了重要作用，但开发AI模型通常需要大量标注，且现有模型在独立未见过的数据上表现不佳。现有的基础模型在眼科领域缺乏广泛的验证，且集中于单一成像方式。&lt;h4&gt;目的&lt;/h4&gt;提出MIRAGE模型，并建立一个新的评估基准，以解决上述挑战，并提高眼科图像分析的AI系统的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;开发了一个新的多模态基础模型MIRAGE，并提出了包含OCT/SLO分类和分割任务的新评估基准。&lt;h4&gt;主要发现&lt;/h4&gt;MIRAGE在OCT/SLO分类和分割任务中均优于一般和专业的FMs及分割方法，表明其适用于开发鲁棒的AI系统。&lt;h4&gt;结论&lt;/h4&gt;MIRAGE模型和评估基准已公开发布，有助于推动眼科图像分析的AI系统发展。&lt;h4&gt;翻译&lt;/h4&gt;Artificial intelligence (AI) has become a fundamental tool for assisting clinicians in analyzing ophthalmic images, such as optical coherence tomography (OCT). However, developing AI models often requires extensive annotation, and existing models tend to underperform on independent, unseen data. Foundation models (FMs), large AI models trained on vast unlabeled datasets, have shown promise in overcoming these challenges. Nonetheless, available FMs for ophthalmology lack extensive validation, especially for segmentation tasks, and focus on a single imaging modality. In this context, we propose MIRAGE, a novel multimodal FM for the analysis of OCT and scanning laser ophthalmoscopy (SLO) images. Additionally, we propose a new evaluation benchmark with OCT/SLO classification and segmentation tasks. The comparison with general and specialized FMs and segmentation methods shows the superiority of MIRAGE in both types of tasks, highlighting its suitability as a basis for the development of robust AI systems for retinal OCT image analysis. Both MIRAGE and the evaluation benchmark are publicly available: https://github.com/j-morano/MIRAGE.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence (AI) has become a fundamental tool for assistingclinicians in analyzing ophthalmic images, such as optical coherence tomography(OCT). However, developing AI models often requires extensive annotation, andexisting models tend to underperform on independent, unseen data. Foundationmodels (FMs), large AI models trained on vast unlabeled datasets, have shownpromise in overcoming these challenges. Nonetheless, available FMs forophthalmology lack extensive validation, especially for segmentation tasks, andfocus on a single imaging modality. In this context, we propose MIRAGE, a novelmultimodal FM for the analysis of OCT and scanning laser ophthalmoscopy (SLO)images. Additionally, we propose a new evaluation benchmark with OCT/SLOclassification and segmentation tasks. The comparison with general andspecialized FMs and segmentation methods shows the superiority of MIRAGE inboth types of tasks, highlighting its suitability as a basis for thedevelopment of robust AI systems for retinal OCT image analysis. Both MIRAGEand the evaluation benchmark are publicly available:https://github.com/j-morano/MIRAGE.</description>
      <author>example@mail.com (José Morano, Botond Fazekas, Emese Sükei, Ronald Fecso, Taha Emre, Markus Gumpinger, Georg Faustmann, Marzieh Oghbaie, Ursula Schmidt-Erfurth, Hrvoje Bogunović)</author>
      <guid isPermaLink="false">2506.08900v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Adapting Vision-Language Foundation Model for Next Generation Medical Ultrasound Image Analysis</title>
      <link>http://arxiv.org/abs/2506.08849v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种针对医学超声图像分析的视觉-语言基础模型领域自适应方法，通过调整和优化模型，提高了其在分割和分类任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;医学超声成像是一种重要的影像技术，用于检查浅表器官和组织，如淋巴结、乳腺和甲状腺。手动在图像中标记感兴趣区域是耗时且需要专业知识的工作，容易导致不同的解释。&lt;h4&gt;目的&lt;/h4&gt;旨在克服视觉-语言基础模型在自然和医学成像领域之间的性能差异，提高超声图像分析的准确性。&lt;h4&gt;方法&lt;/h4&gt;研究探索了视觉-语言基础模型的微调流程，使用大型语言模型作为文本细化器，结合特殊设计的自适应策略和任务驱动的头部。&lt;h4&gt;主要发现&lt;/h4&gt;方法在六个超声数据集和两个任务（分割和分类）上进行了广泛评估，实验结果表明该方法能够有效提升视觉-语言基础模型在超声图像分析中的性能，并优于现有的视觉-语言和纯基础模型。&lt;h4&gt;结论&lt;/h4&gt;该方法在超声图像分析中提高了视觉-语言基础模型的表现，具有实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical ultrasonography is an essential imaging technique for examiningsuperficial organs and tissues, including lymph nodes, breast, and thyroid. Itemploys high-frequency ultrasound waves to generate detailed images of theinternal structures of the human body. However, manually contouring regions ofinterest in these images is a labor-intensive task that demands expertise andoften results in inconsistent interpretations among individuals.Vision-language foundation models, which have excelled in various computervision applications, present new opportunities for enhancing ultrasound imageanalysis. Yet, their performance is hindered by the significant differencesbetween natural and medical imaging domains. This research seeks to overcomethese challenges by developing domain adaptation methods for vision-languagefoundation models. In this study, we explore the fine-tuning pipeline forvision-language foundation models by utilizing large language model as textrefiner with special-designed adaptation strategies and task-driven heads. Ourapproach has been extensively evaluated on six ultrasound datasets and twotasks: segmentation and classification. The experimental results show that ourmethod can effectively improve the performance of vision-language foundationmodels for ultrasound image analysis, and outperform the existingstate-of-the-art vision-language and pure foundation models. The source code ofthis study is available at\href{https://github.com/jinggqu/NextGen-UIA}{GitHub}.</description>
      <author>example@mail.com (Jingguo Qu, Xinyang Han, Tonghuan Xiao, Jia Ai, Juan Wu, Tong Zhao, Jing Qin, Ann Dorothy King, Winnie Chiu-Wing Chu, Jing Cai, Michael Tin-Cheung Yingınst)</author>
      <guid isPermaLink="false">2506.08849v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>MOBODY: Model Based Off-Dynamics Offline Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.08460v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了离线强化学习中的离动态问题，提出了一种名为MOBODY的基于模型的离动态离线强化学习算法，该算法通过学习动态来探索目标域，并通过模型扩展来增强数据，从而提高了在目标域中学习策略的能力。&lt;h4&gt;背景&lt;/h4&gt;离动态离线强化学习问题中，目标是从包含不同转换域的离线数据集中学习策略。现有的离动态离线强化学习方法通常受到目标域有限转换的限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够探索目标域并学习策略的离动态离线强化学习算法。&lt;h4&gt;方法&lt;/h4&gt;MOBODY算法通过模型扩展生成新的合成转换，并将其用作离线策略学习中的数据增强。该算法利用源数据和目标数据集来处理不匹配的动态，并通过表示学习发现跨域的状态和转换的共享潜在表示，以学习目标动态。此外，MOBODY还引入了一种Q加权的模仿行为损失来正则化策略。&lt;h4&gt;主要发现&lt;/h4&gt;MOBODY在MuJoCo基准测试中表现优于现有方法，特别是在具有挑战性的场景中表现出显著改进。&lt;h4&gt;结论&lt;/h4&gt;MOBODY算法通过增强数据集和学习动态，显著提高了离动态离线强化学习在目标域中的策略学习性能。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了离动态离线强化学习问题，其目标是学习一个策略，该策略来自从源域和目标域收集的离线数据集，这些数据集具有不匹配的转换。现有的离动态离线强化学习方法通常要么过滤与目标域相似的源转换，要么对源数据进行奖励增强，这两种方法都受到来自目标域的有限转换的限制。因此，学习到的策略无法探索目标域之外的离线数据集。我们提出了MOBODY，这是一种基于模型的离动态离线强化学习算法，通过通过学习动态来启用对目标域的探索来解决这个问题。MOBODY通过模型扩展在目标域中生成新的合成转换，这些转换在离线策略学习期间用作数据增强。与从单个域学习动态的现有基于模型的方法不同，MOBODY通过利用源数据和目标数据集来解决不匹配的动态的挑战。直接合并这些数据集可能会使学习到的模型偏向源动态。相反，MOBODY通过通过表示学习发现跨域的状态和转换的共享潜在表示来学习目标动态。为了稳定训练，MOBODY结合了行为克隆损失来正则化策略。具体来说，我们引入了一种Q加权的模仿行为克隆损失，该损失将策略正则化到具有高目标域Q值的行为，而不是均匀地模仿数据集中的所有行为。这些Q值是从由离线目标数据、增强源数据和从学习到的目标动态的滚动数据组成的增强目标数据集中学习的。我们在MuJoCo基准测试中评估了MOBODY，并表明它显著优于最先进的基线，特别是在具有挑战性的场景中表现出特别显著的改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the off-dynamics offline reinforcement learning problem, where thegoal is to learn a policy from offline datasets collected from source andtarget domains with mismatched transition. Existing off-dynamics offline RLmethods typically either filter source transitions that resemble those of thetarget domain or apply reward augmentation to source data, both constrained bythe limited transitions available from the target domain. As a result, thelearned policy is unable to explore target domain beyond the offline datasets.We propose MOBODY, a Model-Based Off-Dynamics offline RL algorithm thataddresses this limitation by enabling exploration of the target domain vialearned dynamics. MOBODY generates new synthetic transitions in the targetdomain through model rollouts, which are used as data augmentation duringoffline policy learning. Unlike existing model-based methods that learndynamics from a single domain, MOBODY tackles the challenge of mismatcheddynamics by leveraging both source and target datasets. Directly merging thesedatasets can bias the learned model toward source dynamics. Instead, MOBODYlearns target dynamics by discovering a shared latent representation of statesand transitions across domains through representation learning. To stabilizetraining, MOBODY incorporates a behavior cloning loss that regularizes thepolicy. Specifically, we introduce a Q-weighted behavior cloning loss thatregularizes the policy toward actions with high target-domain Q-values, ratherthan uniformly imitating all actions in the dataset. These Q-values are learnedfrom an enhanced target dataset composed of offline target data, augmentedsource data, and rollout data from the learned target dynamics. We evaluateMOBODY on MuJoCo benchmarks and show that it significantly outperformsstate-of-the-art baselines, with especially pronounced improvements inchallenging scenarios.</description>
      <author>example@mail.com (Yihong Guo, Yu Yang, Pan Xu, Anqi Liu)</author>
      <guid isPermaLink="false">2506.08460v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Landsat-Bench: Datasets and Benchmarks for Landsat Foundation Models</title>
      <link>http://arxiv.org/abs/2506.08780v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Landsat-Bench，一套基于Landsat影像的基准测试集，用于促进基于Landsat的地理空间基础模型（GFM）的发展。&lt;h4&gt;背景&lt;/h4&gt;Landsat项目提供了超过50年的全球一致地球影像，但由于缺乏该数据的基准测试，限制了基于Landsat的地理空间基础模型（GFM）的发展。&lt;h4&gt;目的&lt;/h4&gt;通过引入Landsat-Bench，旨在建立基准和标准化的评估方法，以促进基于Landsat的地理空间基础模型（GFM）的发展。&lt;h4&gt;方法&lt;/h4&gt;Landsat-Bench包括三个基准测试集：EuroSAT-L、BigEarthNet-L和LC100-L，这些测试集来自现有的遥感数据集。研究人员在SSL4EO-L数据集上预训练了Landsat基础模型，并使用这些模型进行基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;SSL4EO-L预训练的GFM在下游任务中提取了更好的表示，与ImageNet相比，在EuroSAT-L和BigEarthNet-L上的性能分别提高了+4% OA和+5.1% mAP。&lt;h4&gt;结论&lt;/h4&gt;SSL4EO-L预训练的GFM在基于Landsat的地理空间基础模型（GFM）中具有更高的性能，为后续任务提供了更好的基础。&lt;h4&gt;翻译&lt;/h4&gt;The Landsat program provides over 50 years of globally consistent Earth imagery. However, the lack of benchmarks for this data constrains progress towards Landsat-based Geospatial Foundation Models (GFM). In this paper, we introduce Landsat-Bench, a suite of three benchmarks with Landsat imagery that adapt from existing remote sensing datasets -- EuroSAT-L, BigEarthNet-L, and LC100-L. We establish baseline and standardized evaluation methods across both common architectures and Landsat foundation models pretrained on the SSL4EO-L dataset. Notably, we provide evidence that SSL4EO-L pretrained GFMs extract better representations for downstream tasks in comparison to ImageNet, including performance gains of +4% OA and +5.1% mAP on EuroSAT-L and BigEarthNet-L.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Landsat program offers over 50 years of globally consistent Earthimagery. However, the lack of benchmarks for this data constrains progresstowards Landsat-based Geospatial Foundation Models (GFM). In this paper, weintroduce Landsat-Bench, a suite of three benchmarks with Landsat imagery thatadapt from existing remote sensing datasets -- EuroSAT-L, BigEarthNet-L, andLC100-L. We establish baseline and standardized evaluation methods across bothcommon architectures and Landsat foundation models pretrained on the SSL4EO-Ldataset. Notably, we provide evidence that SSL4EO-L pretrained GFMs extractbetter representations for downstream tasks in comparison to ImageNet,including performance gains of +4% OA and +5.1% mAP on EuroSAT-L andBigEarthNet-L.</description>
      <author>example@mail.com (Isaac Corley, Lakshay Sharma, Ruth Crasto)</author>
      <guid isPermaLink="false">2506.08780v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>FUSE: Measure-Theoretic Compact Fuzzy Set Representation for Taxonomy Expansion</title>
      <link>http://arxiv.org/abs/2506.08409v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于模糊集的集合表示学习方法，用于复杂概念及其关系的建模。&lt;h4&gt;背景&lt;/h4&gt;传统的集合表示学习方法通常将集合建模为向量或几何对象，如箱子，这些方法在集合运算下不是封闭的。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的集合表示学习方法，以模糊集的形式对集合进行体积近似，从而在保持信息的同时提高学习效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Fuzzy Set Embedding (FUSE)的嵌入框架，它基于模糊集的体积近似，满足所有集合运算，并紧凑地近似底层模糊集。&lt;h4&gt;主要发现&lt;/h4&gt;FUSE在分类扩展任务上展示了强大的性能，与现有基线相比，实现了高达23%的改进。&lt;h4&gt;结论&lt;/h4&gt;本文首次尝试理解和高效计算模糊集的嵌入，为概念建模提供了一种新的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：分类扩展，它模拟复杂概念及其关系，可以表述为一种集合表示学习任务。集合的泛化，包括模糊集，包含了不确定性并测量语义概念中的信息，使其适合于概念建模。现有工作通常将集合建模为向量或诸如箱子之类的几何对象，这些方法在集合运算下不是封闭的。在本工作中，我们提出了一种基于集合体积近似为模糊集的集合表示学习的合理和有效公式。由此产生的嵌入框架，模糊集嵌入（FUSE），满足所有集合运算，并紧凑地近似底层模糊集，因此在保持信息的同时，学习效率高，依赖于最小的神经网络架构。我们通过在分类扩展任务上对FUSE的实证演示其力量，其中FUSE与现有基线相比实现了显著的改进，高达23%。我们的工作首次尝试理解和高效计算模糊集的嵌入。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Taxonomy Expansion, which models complex concepts and their relations, can beformulated as a set representation learning task. The generalization of set,fuzzy set, incorporates uncertainty and measures the information within asemantic concept, making it suitable for concept modeling. Existing worksusually model sets as vectors or geometric objects such as boxes, which are notclosed under set operations. In this work, we propose a sound and efficientformulation of set representation learning based on its volume approximation asa fuzzy set. The resulting embedding framework, Fuzzy Set Embedding (FUSE),satisfies all set operations and compactly approximates the underlying fuzzyset, hence preserving information while being efficient to learn, relying onminimum neural architecture. We empirically demonstrate the power of FUSE onthe task of taxonomy expansion, where FUSE achieves remarkable improvements upto 23% compared with existing baselines. Our work marks the first attempt tounderstand and efficiently compute the embeddings of fuzzy sets.</description>
      <author>example@mail.com (Fred Xu, Song Jiang, Zijie Huang, Xiao Luo, Shichang Zhang, Adrian Chen, Yizhou Sun)</author>
      <guid isPermaLink="false">2506.08409v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>WGLE:Backdoor-free and Multi-bit Black-box Watermarking for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.08602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的GNN黑盒水印方法WGLE，用于防止模型盗窃，并实现知识产权保护。&lt;h4&gt;背景&lt;/h4&gt;随着图神经网络（GNNs）在图相关应用中的广泛应用，模型的所有权验证变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的黑盒水印方法，以保护GNN的知识产权，同时避免现有方法的缺点。&lt;h4&gt;方法&lt;/h4&gt;WGLE方法基于层间距离差异（LDDE），通过预定义多个边上的LDDE值，将多比特字符串嵌入到模型中，而不引入错误映射。&lt;h4&gt;主要发现&lt;/h4&gt;WGLE在六个公共数据集和六个主流GNN架构上进行了评估，实现了100%的所有权验证准确率，平均保真度下降为0.85%，具有较好的鲁棒性，且嵌入开销低。&lt;h4&gt;结论&lt;/h4&gt;WGLE是一种有效且高效的GNN黑盒水印方法，能够有效防止模型盗窃，并保护知识产权。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are increasingly deployed in graph-relatedapplications, making ownership verification critical to protect theirintellectual property against model theft. Fingerprinting and black-boxwatermarking are two main methods. However, the former relies on determiningmodel similarity, which is computationally expensive and prone to ownershipcollisions after model post-processing such as model pruning or fine-tuning.The latter embeds backdoors, exposing watermarked models to the risk ofbackdoor attacks. Moreover, both methods enable ownership verification but donot convey additional information. As a result, each distributed model requiresa unique trigger graph, and all trigger graphs must be used to query thesuspect model during verification. Multiple queries increase the financial costand the risk of detection.  To address these challenges, this paper proposes WGLE, a novel black-boxwatermarking paradigm for GNNs that enables embedding the multi-bit string asthe ownership information without using backdoors. WGLE builds on a key insightwe term Layer-wise Distance Difference on an Edge (LDDE), which quantifies thedifference between the feature distance and the prediction distance of twoconnected nodes. By predefining positive or negative LDDE values for multipleselected edges, WGLE embeds the watermark encoding the intended informationwithout introducing incorrect mappings that compromise the primary task. WGLEis evaluated on six public datasets and six mainstream GNN architectures alongwith state-of-the-art methods. The results show that WGLE achieves 100%ownership verification accuracy, an average fidelity degradation of 0.85%,comparable robustness against potential attacks, and low embedding overhead.The code is available in the repository.</description>
      <author>example@mail.com (Tingzhi Li, Xuefeng Liu)</author>
      <guid isPermaLink="false">2506.08602v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion Sequence Models for Enhanced Protein Representation and Generation</title>
      <link>http://arxiv.org/abs/2506.08293v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Diffusion Sequence Model (DSM)，一种新型蛋白质语言模型，通过掩码扩散训练实现高质量表示学习和生成蛋白质设计。&lt;h4&gt;背景&lt;/h4&gt;蛋白质是生物学的基本组成部分，在医学、材料科学和环境应用中具有变革潜力。蛋白质语言模型（pLMs）旨在通过掩码语言模型从未标记的蛋白质序列中学习丰富的语义表示，但它们通常表现出有限的生成能力。&lt;h4&gt;目的&lt;/h4&gt;提高蛋白质语言模型的生成能力，实现高质量表示学习和生成蛋白质设计。&lt;h4&gt;方法&lt;/h4&gt;DSM基于ESM2架构，通过引入掩码前向扩散过程，受到LLaDA框架的启发。DSM(ppi)是DSM的一个变体，针对目标序列进行微调以生成蛋白质结合剂。&lt;h4&gt;主要发现&lt;/h4&gt;DSM能够生成与预期氨基酸组成、二级结构和预测功能一致的多样化、生物模拟序列，即使有90%的标记损坏。DSM的学习表示在下游任务中与类似规模的pLMs相当或更好。DSM和DSM(ppi)在BenchBB基准测试中表现出色，生成的候选结合剂具有比已知结合剂更高的预测结合亲和力。&lt;h4&gt;结论&lt;/h4&gt;掩码扩散被证明是统一蛋白质表示和生成在单一框架中的强大范式。&lt;h4&gt;翻译&lt;/h4&gt;摘要：蛋白质是生物学的基石，通过复杂的物理化学相互作用执行多种功能，并在医学、材料科学和环境应用中具有变革潜力。蛋白质语言模型（pLMs）旨在通过从初级序列中学习丰富的语义表示，通过掩码语言模型从大量未标记的蛋白质序列中揭示见解。然而，这些模型通常表现出有限的生成能力。在这项工作中，我们引入了Diffusion Sequence Model (DSM)，一种新型pLM，通过掩码扩散训练以实现高质量的表示学习和生成蛋白质设计。DSM通过结合LLaDA框架启发的掩码前向扩散过程，在ESM2架构的基础上构建。经过训练，DSM能够生成与预期氨基酸组成、二级结构和预测功能一致的多样化、生物模拟序列，即使有90%的标记损坏。此外，DSM的学习表示在下游任务中与类似规模的pLMs相当或更好。我们还引入了DSM(ppi)，一种针对生成蛋白质结合剂进行微调的变体。我们在具有挑战性的Bench-tested Binder Benchmark (BenchBB)上展示了DSM(ppi)的有效性，其中DSM和DSM(ppi)都产生了比已知结合剂具有更高预测结合亲和力的候选结合剂。我们的结果将掩码扩散确立为统一蛋白质表示和生成在单一框架中的强大范式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Proteins are fundamental to biology, executing diverse functions throughcomplex physicochemical interactions, and they hold transformative potentialacross medicine, materials science, and environmental applications. ProteinLanguage Models (pLMs) aim to unlock insights from the vast space of unlabeledprotein sequences by learning rich, semantic representations from primarysequences via masked language modeling. However, these models typically exhibitlimited generative capacity. In this work, we introduce the Diffusion SequenceModel (DSM), a novel pLM trained with masked diffusion to enable bothhigh-quality representation learning and generative protein design. DSM buildsupon the ESM2 architecture by incorporating a masked forward diffusion processinspired by the LLaDA framework. After training, DSM is capable of generatingdiverse, biomimetic sequences that align with expected amino acid compositions,secondary structures, and predicted functions, even with 90\% token corruption.Furthermore, DSM's learned representations match or exceed those of similarlysized pLMs on downstream tasks. We also introduce DSM(ppi), a variantfine-tuned to generate protein binders by attending to target sequences. Wedemonstrate DSM(ppi)'s effectiveness on the challenging Bench-tested BinderBenchmark (BenchBB), where both DSM and DSM(ppi) produce candidates withsuperior predicted binding affinity compared to known binders. Our resultsestablish masked diffusion as a powerful paradigm for unifying proteinrepresentation and generation in a single framework.</description>
      <author>example@mail.com (Logan Hallee, Nikolaos Rafailidis, David B. Bichara, Jason P. Gleghorn)</author>
      <guid isPermaLink="false">2506.08293v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>HGFormer: A Hierarchical Graph Transformer Framework for Two-Stage Colonel Blotto Games via Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.08580v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HGformer的分层图Transformer框架，用于解决两阶段Colonel Blotto游戏中的资源分配问题，通过实验验证了其在复杂动态游戏场景中的优越性能。&lt;h4&gt;背景&lt;/h4&gt;两阶段Colonel Blotto游戏是一个典型的对抗性资源分配问题，涉及两个代理在两个阶段内按顺序在网络拓扑中分配资源：首先是初始资源部署，然后是多个轮次的动态重新分配调整。&lt;h4&gt;目的&lt;/h4&gt;为了解决游戏阶段之间的顺序依赖性和图拓扑的复杂约束，提出HGformer框架以实现大规模对抗环境中的高效策略生成。&lt;h4&gt;方法&lt;/h4&gt;HGformer通过结合增强的图Transformer编码器（具有结构偏差）和两个代理的分层决策模型来实现策略生成。此外，还设计了一种逐层反馈强化学习算法，将来自低级决策的长期回报反馈到高级策略的优化中。&lt;h4&gt;主要发现&lt;/h4&gt;与现有的分层决策或图神经网络方法相比，HGformer显著提高了资源分配效率和对抗性收益。&lt;h4&gt;结论&lt;/h4&gt;HGformer在复杂动态游戏场景中实现了优于现有方法的整体性能。&lt;h4&gt;翻译&lt;/h4&gt;Two-stage Colonel Blotto game represents a typical adversarial resourceallocation problem, in which two opposing agents sequentially allocate resources in a network topology across two phases: an initial resourcedeployment followed by multiple rounds of dynamic reallocation adjustments. Thesequential dependency between game stages and the complex constraints imposedby the graph topology make it difficult for traditional approaches to attain aglobally optimal strategy. To address these challenges, we propose a hierarchical graph Transformer framework called HGformer. By incorporating an enhanced graph Transformer encoder with structural biases and a two-agent hierarchical decision model, our approach enables efficient policy generation in large-scale adversarial environments. Moreover, we design a layer-by-layer feedback reinforcement learning algorithm that feeds the long-term returns from lower-level decisions back into the optimization of the higher-level strategy, thus bridging the coordination gap between the two decision-making stages. Experimental results demonstrate that, compared to existing hierarchical decision-making or graph neural network methods, HGformer significantly improves resource allocation efficiency and adversarial payoff, achieving superior overall performance in complex dynamic game scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Two-stage Colonel Blotto game represents a typical adversarial resourceallocation problem, in which two opposing agents sequentially allocateresources in a network topology across two phases: an initial resourcedeployment followed by multiple rounds of dynamic reallocation adjustments. Thesequential dependency between game stages and the complex constraints imposedby the graph topology make it difficult for traditional approaches to attain aglobally optimal strategy. To address these challenges, we propose ahierarchical graph Transformer framework called HGformer. By incorporating anenhanced graph Transformer encoder with structural biases and a two-agenthierarchical decision model, our approach enables efficient policy generationin large-scale adversarial environments. Moreover, we design a layer-by-layerfeedback reinforcement learning algorithm that feeds the long-term returns fromlower-level decisions back into the optimization of the higher-level strategy,thus bridging the coordination gap between the two decision-making stages.Experimental results demonstrate that, compared to existing hierarchicaldecision-making or graph neural network methods, HGformer significantlyimproves resource allocation efficiency and adversarial payoff, achievingsuperior overall performance in complex dynamic game scenarios.</description>
      <author>example@mail.com (Yang Lv, Jinlong Lei, Peng Yi)</author>
      <guid isPermaLink="false">2506.08580v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>RS-MTDF: Multi-Teacher Distillation and Fusion for Remote Sensing Semi-Supervised Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2506.08772v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RS-MTDF的半监督语义分割框架，用于遥感图像分割，以解决现有半监督方法中标签数据与未标记数据分布不匹配的问题。&lt;h4&gt;背景&lt;/h4&gt;遥感图像的语义分割对于多种应用至关重要，但其性能高度依赖于大规模、高质量的像素级标注，这些标注获取成本高且耗时。半监督语义分割（SSS）作为一种替代方案，可以有效减轻数据依赖。&lt;h4&gt;目的&lt;/h4&gt;提出RS-MTDF框架，利用视觉基础模型（VFMs）的强大泛化能力，以改善SSS的性能。&lt;h4&gt;方法&lt;/h4&gt;RS-MTDF框架采用多个预训练的VFMs作为专家教师，通过特征级别的蒸馏来对齐学生特征，并融合蒸馏的知识到学生解码器中，从而增强判别能力。&lt;h4&gt;主要发现&lt;/h4&gt;在三个具有挑战性的遥感数据集（ISPRS Potsdam、LoveDA和DeepGlobe）上进行的实验表明，RS-MTDF在各个标签比率上均取得了最先进的性能，尤其是在LoveDA数据集上，在大多数语义类别中获得了最高的IoU值。&lt;h4&gt;结论&lt;/h4&gt;多教师VFMs的指导在显著提高遥感分割的泛化和语义理解方面是有效的。消融实验进一步验证了每个模块的贡献。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Semantic segmentation in remote sensing images is crucial for various applications, yet its performance is heavily reliant on large-scale, high-quality pixel-wise annotations, which are notoriously expensive and time-consuming to acquire. Semi-supervised semantic segmentation (SSS) offers a promising alternative to mitigate this data dependency. However, existing SSS methods often struggle with the inherent distribution mismatch between limited labeled data and abundant unlabeled data, leading to suboptimal generalization. We propose that Vision Foundation Models (VFMs), pre-trained on vast and diverse datasets, possess robust generalization capabilities that can effectively bridge this distribution gap and provide strong semantic priors for SSS. Inspired by this, we introduce RS-MTDF (Multi-Teacher Distillation and Fusion), a novel framework that leverages the powerful semantic knowledge embedded in VFMs to guide semi-supervised learning in remote sensing. Specifically, RS-MTDF employs multiple frozen VFMs (e.g., DINOv2 and CLIP) as expert teachers, utilizing feature-level distillation to align student features with their robust representations. To further enhance discriminative power, the distilled knowledge is seamlessly fused into the student decoder. Extensive experiments on three challenging remote sensing datasets (ISPRS Potsdam, LoveDA, and DeepGlobe) demonstrate that RS-MTDF consistently achieves state-of-the-art performance. Notably, our method outperforms existing approaches across various label ratios on LoveDA and secures the highest IoU in the majority of semantic categories. These results underscore the efficacy of multi-teacher VFM guidance in significantly enhancing both generalization and semantic understanding for remote sensing segmentation. Ablation studies further validate the contribution of each proposed module.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic segmentation in remote sensing images is crucial for variousapplications, yet its performance is heavily reliant on large-scale,high-quality pixel-wise annotations, which are notoriously expensive andtime-consuming to acquire. Semi-supervised semantic segmentation (SSS) offers apromising alternative to mitigate this data dependency. However, existing SSSmethods often struggle with the inherent distribution mismatch between limitedlabeled data and abundant unlabeled data, leading to suboptimal generalization.We propose that Vision Foundation Models (VFMs), pre-trained on vast anddiverse datasets, possess robust generalization capabilities that caneffectively bridge this distribution gap and provide strong semantic priors forSSS. Inspired by this, we introduce RS-MTDF (Multi-Teacher Distillation andFusion), a novel framework that leverages the powerful semantic knowledgeembedded in VFMs to guide semi-supervised learning in remote sensing.Specifically, RS-MTDF employs multiple frozen VFMs (\textit{e.g.}, DINOv2 andCLIP) as expert teachers, utilizing feature-level distillation to align studentfeatures with their robust representations. To further enhance discriminativepower, the distilled knowledge is seamlessly fused into the student decoder.Extensive experiments on three challenging remote sensing datasets (ISPRSPotsdam, LoveDA, and DeepGlobe) demonstrate that RS-MTDF consistently achievesstate-of-the-art performance. Notably, our method outperforms existingapproaches across various label ratios on LoveDA and secures the highest IoU inthe majority of semantic categories. These results underscore the efficacy ofmulti-teacher VFM guidance in significantly enhancing both generalization andsemantic understanding for remote sensing segmentation. Ablation studiesfurther validate the contribution of each proposed module.</description>
      <author>example@mail.com (Jiayi Song, Kaiyu Li, Xiangyong Cao, Deyu Meng)</author>
      <guid isPermaLink="false">2506.08772v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Bayesian Inverse Physics for Neuro-Symbolic Robot Learning</title>
      <link>http://arxiv.org/abs/2506.08756v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合数据驱动学习和结构化推理的概念框架，旨在解决现实世界机器人应用中深度学习架构在未知和动态环境下的局限性。&lt;h4&gt;背景&lt;/h4&gt;现实世界的机器人应用需要适应性、可解释性和数据高效的机器学习方法。&lt;h4&gt;目的&lt;/h4&gt;评估深度学习架构在未知和动态环境下的局限性，并提出一种结合数据驱动学习和结构化推理的方法。&lt;h4&gt;方法&lt;/h4&gt;通过利用可微物理进行高效的世界建模，贝叶斯推理进行不确定性感知的决策，以及元学习进行对新任务的快速适应。&lt;h4&gt;主要发现&lt;/h4&gt;将物理符号推理嵌入到神经网络模型中，机器人可以超越训练数据泛化，推理新情境，并持续扩展其知识。&lt;h4&gt;结论&lt;/h4&gt;这种混合神经符号架构对于下一代自主系统至关重要，并为此提供了一个研究路线图以指导和发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现实世界的机器人应用，从自主探索到辅助技术，需要适应性、可解释性和数据高效的机器学习方法。虽然深度学习架构和基础模型在多样化的机器人应用中推动了显著进步，但它们在未知和动态环境中高效和可靠运行的能力仍然有限。在这篇立场论文中，我们批判性地评估了这些局限性，并介绍了一个结合数据驱动学习与有目的、结构化推理的概念框架。具体来说，我们提出了利用可微物理进行高效世界建模、贝叶斯推理进行不确定性感知决策以及元学习进行对新任务的快速适应。通过在神经网络模型中嵌入物理符号推理，机器人可以超越其训练数据泛化，推理新情境，并持续扩展其知识。我们认为，这样的混合神经符号架构对于下一代自主系统至关重要，为此，我们提供了一个研究路线图以指导和加速其发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world robotic applications, from autonomous exploration to assistivetechnologies, require adaptive, interpretable, and data-efficient learningparadigms. While deep learning architectures and foundation models have drivensignificant advances in diverse robotic applications, they remain limited intheir ability to operate efficiently and reliably in unknown and dynamicenvironments. In this position paper, we critically assess these limitationsand introduce a conceptual framework for combining data-driven learning withdeliberate, structured reasoning. Specifically, we propose leveragingdifferentiable physics for efficient world modeling, Bayesian inference foruncertainty-aware decision-making, and meta-learning for rapid adaptation tonew tasks. By embedding physical symbolic reasoning within neural models,robots could generalize beyond their training data, reason about novelsituations, and continuously expand their knowledge. We argue that such hybridneuro-symbolic architectures are essential for the next generation ofautonomous systems, and to this end, we provide a research roadmap to guide andaccelerate their development.</description>
      <author>example@mail.com (Octavio Arriaga, Rebecca Adam, Melvin Laux, Lisa Gutzeit, Marco Ragni, Jan Peters, Frank Kirchner)</author>
      <guid isPermaLink="false">2506.08756v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Reasoning Capabilities of Small Language Models with Blueprints and Prompt Template Search</title>
      <link>http://arxiv.org/abs/2506.08669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  TTODLer-FM Workshop@ICML'25 (Tiny Titans: The next wave of On-Device  Learning for Foundational Models)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，通过使用大型语言模型生成的蓝图来增强小型语言模型的推理能力，同时减少对提示变化的敏感度，从而提高小型语言模型在各种任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;小型语言模型（SLMs）虽然比大型语言模型（LLMs）更高效，但其有限的容量限制了它们的推理能力，并使它们对提示变化敏感。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，以提高SLMs的推理能力，同时减少对提示变化的敏感性。&lt;h4&gt;方法&lt;/h4&gt;该框架通过以下方式实现：1）利用LLM生成的蓝图提供结构化的推理指南；2）集成提示模板搜索机制来减少SLMs对提示变化的敏感性。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在各种任务（如数学、编码和逻辑推理）上提高了SLMs的表现，且无需增加模型大小或额外训练，为设备或资源受限的环境提供了一种轻量级且易于部署的解决方案。&lt;h4&gt;结论&lt;/h4&gt;该框架为SLMs提供了一个有效的方法来增强推理能力，同时保持了模型的小巧和部署的便捷性。&lt;h4&gt;翻译&lt;/h4&gt;Small language models (SLMs) offer promising and efficient alternatives to large language models (LLMs). However, SLMs' limited capacity restricts their reasoning capabilities and makes them sensitive to prompt variations. To address these challenges, we propose a novel framework that enhances SLM reasoning capabilities through LLM generated blueprints. The blueprints provide structured, high-level reasoning guides that help SLMs systematically tackle related problems. Furthermore, our framework integrates a prompt template search mechanism to mitigate the SLMs' sensitivity to prompt variations. Our framework demonstrates improved SLM performance across various tasks, including math (GSM8K), coding (MBPP), and logic reasoning (BBH). Our approach improves the reasoning capabilities of SLMs without increasing model size or requiring additional training, offering a lightweight and deployment-friendly solution for on-device or resource-constrained environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Small language models (SLMs) offer promising and efficient alternatives tolarge language models (LLMs). However, SLMs' limited capacity restricts theirreasoning capabilities and makes them sensitive to prompt variations. Toaddress these challenges, we propose a novel framework that enhances SLMreasoning capabilities through LLM generated blueprints. The blueprints providestructured, high-level reasoning guides that help SLMs systematically tacklerelated problems. Furthermore, our framework integrates a prompt templatesearch mechanism to mitigate the SLMs' sensitivity to prompt variations. Ourframework demonstrates improved SLM performance across various tasks, includingmath (GSM8K), coding (MBPP), and logic reasoning (BBH). Our approach improvesthe reasoning capabilities of SLMs without increasing model size or requiringadditional training, offering a lightweight and deployment-friendly solutionfor on-device or resource-constrained environments.</description>
      <author>example@mail.com (Dongge Han, Menglin Xia, Daniel Madrigal Diaz, Samuel Kessler, Ankur Mallick, Xuchao Zhang, Mirian Del Carmen Hipolito Garcia, Jin Xu, Victor Rühle, Saravan Rajmohan)</author>
      <guid isPermaLink="false">2506.08669v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>ST-GraphNet: A Spatio-Temporal Graph Neural Network for Understanding and Predicting Automated Vehicle Crash Severity</title>
      <link>http://arxiv.org/abs/2506.08051v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ST-GraphNet，这是一种用于模拟和预测自动驾驶汽车（AV）事故严重程度的时空图神经网络框架。该框架结合了细粒度和区域聚合的时空图来建模。&lt;h4&gt;背景&lt;/h4&gt;理解自动驾驶汽车事故的空间和时间动态对于提高城市移动安全性和基础设施规划至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够模拟和预测AV事故严重程度的时空图神经网络框架。&lt;h4&gt;方法&lt;/h4&gt;使用来自德克萨斯州的真实世界AV相关事故报告数据集，构建了两种互补的图表示：细粒度图和粗粒度图。细粒度图以单个事故事件为节点，通过时空邻近性定义边；粗粒度图将事故聚合到基于H3空间索引的单元格中，通过六边形相邻性连接。每个节点都包含多模态数据，包括使用预训练的Sentence-BERT模型从事故叙述中提取的文本嵌入。评估了不同的图神经网络（GNN）架构，如GCN、GAT和DSTGCN，以分类事故严重程度并预测高风险区域。&lt;h4&gt;主要发现&lt;/h4&gt;ST-GraphNet，在粗粒度H3图上使用DSTGCN作为主干，实现了97.74%的测试准确率，显著优于最佳细粒度模型（64.7%的测试准确率）。&lt;h4&gt;结论&lt;/h4&gt;空间聚合、动态消息传递和多模态特征集成在捕捉AV事故严重程度背后的复杂时空模式方面是有效的。&lt;h4&gt;翻译&lt;/h4&gt;Understanding the spatial and temporal dynamics of automated vehicle (AV) crash severity is critical for advancing urban mobility safety and infrastructure planning. In this work, we introduce ST-GraphNet, a spatio-temporal graph neural network framework designed to model and predict AV crash severity by using both fine-grained and region-aggregated spatial graphs. Using a balanced dataset of 2,352 real-world AV-related crash reports from Texas (2024), including geospatial coordinates, crash timestamps, SAE automation levels, and narrative descriptions, we construct two complementary graph representations: (1) a fine-grained graph with individual crash events as nodes, where edges are defined via spatio-temporal proximity; and (2) a coarse-grained graph where crashes are aggregated into Hexagonal Hierarchical Spatial Indexing (H3)-based spatial cells, connected through hexagonal adjacency. Each node in the graph is enriched with multimodal data, including semantic, spatial, and temporal attributes, including textual embeddings from crash narratives using a pretrained Sentence-BERT model. We evaluate various graph neural network (GNN) architectures, such as Graph Convolutional Networks (GCN), Graph Attention Networks (GAT), and Dynamic Spatio-Temporal GCN (DSTGCN), to classify crash severity and predict high-risk regions. Our proposed ST-GraphNet, which utilizes a DSTGCN backbone on the coarse-grained H3 graph, achieves a test accuracy of 97.74%, substantially outperforming the best fine-grained model (64.7% test accuracy). These findings highlight the effectiveness of spatial aggregation, dynamic message passing, and multi-modal feature integration in capturing the complex spatio-temporal patterns underlying AV crash severity.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the spatial and temporal dynamics of automated vehicle (AV)crash severity is critical for advancing urban mobility safety andinfrastructure planning. In this work, we introduce ST-GraphNet, aspatio-temporal graph neural network framework designed to model and predict AVcrash severity by using both fine-grained and region-aggregated spatial graphs.Using a balanced dataset of 2,352 real-world AV-related crash reports fromTexas (2024), including geospatial coordinates, crash timestamps, SAEautomation levels, and narrative descriptions, we construct two complementarygraph representations: (1) a fine-grained graph with individual crash events asnodes, where edges are defined via spatio-temporal proximity; and (2) acoarse-grained graph where crashes are aggregated into Hexagonal HierarchicalSpatial Indexing (H3)-based spatial cells, connected through hexagonaladjacency. Each node in the graph is enriched with multimodal data, includingsemantic, spatial, and temporal attributes, including textual embeddings fromcrash narratives using a pretrained Sentence-BERT model. We evaluate variousgraph neural network (GNN) architectures, such as Graph Convolutional Networks(GCN), Graph Attention Networks (GAT), and Dynamic Spatio-Temporal GCN(DSTGCN), to classify crash severity and predict high-risk regions. Ourproposed ST-GraphNet, which utilizes a DSTGCN backbone on the coarse-grained H3graph, achieves a test accuracy of 97.74\%, substantially outperforming thebest fine-grained model (64.7\% test accuracy). These findings highlight theeffectiveness of spatial aggregation, dynamic message passing, and multi-modalfeature integration in capturing the complex spatio-temporal patternsunderlying AV crash severity.</description>
      <author>example@mail.com (Mahmuda Sultana Mimi, Md Monzurul Islam, Anannya Ghosh Tusti, Shriyank Somvanshi, Subasish Das)</author>
      <guid isPermaLink="false">2506.08051v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Time Series Representations for Classification Lie Hidden in Pretrained Vision Transformers</title>
      <link>http://arxiv.org/abs/2506.08641v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TiViT的框架，该框架通过将时间序列转换为图像，利用在大型图像数据集上预训练的冻结视觉Transformer（ViTs）的表示能力，以解决时间序列分类问题。&lt;h4&gt;背景&lt;/h4&gt;时间序列分类在医疗和工业领域至关重要，但时间序列基础模型（TSFMs）的发展受到公开可用时间序列数据集稀缺的限制。&lt;h4&gt;目的&lt;/h4&gt;提出TiViT框架，以提高时间序列分类的性能。&lt;h4&gt;方法&lt;/h4&gt;1. 通过分析ViTs的2D补丁化，理论证明了其对于时间序列的增强表示能力。2. 实验表明，TiViT通过使用大型OpenCLIP模型的隐藏表示，在标准时间序列分类基准上达到了最先进的性能。3. 探索了TiViT表示的结构，发现具有高内在维度的中间层对于时间序列分类最为有效。4. 评估了TiViT与TSFM表示空间之间的对齐，并确定了它们之间的强互补性，通过结合其特征实现了进一步的性能提升。&lt;h4&gt;主要发现&lt;/h4&gt;1. ViTs的2D补丁化可以增加与标签相关的标记数量并降低样本复杂度。2. TiViT在标准时间序列分类基准上实现了最先进的性能。3. TiViT的中间层具有高内在维度，对于时间序列分类最为有效。4. TiViT与TSFM表示空间之间存在强互补性。&lt;h4&gt;结论&lt;/h4&gt;TiViT框架为在非视觉领域中重用视觉表示提供了另一个方向。&lt;h4&gt;翻译&lt;/h4&gt;时间序列分类是医疗和工业领域的一项基本任务，然而，由于公开可用的时间序列数据集稀缺，时间序列基础模型（TSFMs）的发展仍然有限。在这项工作中，我们提出了时间视觉Transformer（TiViT），这是一个将时间序列转换为图像的框架，以利用在大型图像数据集上预训练的冻结视觉Transformer（ViTs）的表示能力。首先，我们通过分析ViTs的2D补丁化，从理论上论证了我们的方法，表明它可以增加与标签相关的标记数量并减少样本复杂度。其次，我们通过利用大型OpenCLIP模型的隐藏表示，在标准时间序列分类基准上实证地展示了TiViT实现了最先进的性能。我们探索了TiViT表示的结构，并发现具有高内在维度的中间层对于时间序列分类最为有效。最后，我们评估了TiViT与TSFM表示空间之间的对齐，并确定了它们之间的强互补性，通过结合它们的特征实现了进一步的性能提升。我们的发现揭示了在非视觉领域中重用视觉表示的另一个方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series classification is a fundamental task in healthcare and industry,yet the development of time series foundation models (TSFMs) remains limited bythe scarcity of publicly available time series datasets. In this work, wepropose Time Vision Transformer (TiViT), a framework that converts time seriesinto images to leverage the representational power of frozen VisionTransformers (ViTs) pretrained on large-scale image datasets. First, wetheoretically motivate our approach by analyzing the 2D patching of ViTs fortime series, showing that it can increase the number of label-relevant tokensand reduce the sample complexity. Second, we empirically demonstrate that TiViTachieves state-of-the-art performance on standard time series classificationbenchmarks by utilizing the hidden representations of large OpenCLIP models. Weexplore the structure of TiViT representations and find that intermediatelayers with high intrinsic dimension are the most effective for time seriesclassification. Finally, we assess the alignment between TiViT and TSFMrepresentation spaces and identify a strong complementarity, with furtherperformance gains achieved by combining their features. Our findings reveal yetanother direction for reusing vision representations in a non-visual domain.</description>
      <author>example@mail.com (Simon Roschmann, Quentin Bouniot, Vasilii Feofanov, Ievgen Redko, Zeynep Akata)</author>
      <guid isPermaLink="false">2506.08641v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Hybrid Reasoning for Perception, Explanation, and Autonomous Action in Manufacturing</title>
      <link>http://arxiv.org/abs/2506.08462v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CIPHER的工业控制与解释框架，旨在通过混合专家知识和推理来提高工业过程的鲁棒性和适应性。&lt;h4&gt;背景&lt;/h4&gt;工业过程中的环境和任务往往不可预测，操作错误代价高昂且难以检测。基于AI的控制系统虽然具有潜力，但通常依赖于监督学习和大量标注数据，限制了其在变化和缺乏数据的工业环境中的应用。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够模仿人类推理的工业控制模型，并应用于商业级3D打印机。&lt;h4&gt;方法&lt;/h4&gt;CIPHER框架结合了过程专家、回归模型和检索增强生成技术，以实现外部专家知识的访问和物理信息化的推理。&lt;h4&gt;主要发现&lt;/h4&gt;CIPHER在处理分布外任务时表现出强大的泛化能力，能够解释视觉或文本输入，并自主生成精确的机器指令，无需显式标注。&lt;h4&gt;结论&lt;/h4&gt;CIPHER为自主系统奠定了基础，这些系统能够精确行动、根据上下文进行推理，并透明地传达决策，支持在工业环境中的安全可靠部署。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Industrial processes must be robust and adaptable, as environments and tasks are often unpredictable, while operational errors remain costly and difficult to detect. AI-based control systems offer a path forward, yet typically depend on supervised learning with extensive labelled datasets, which limits their ability to generalize across variable and data-scarce industrial settings. Foundation models could enable broader reasoning and knowledge integration, but rarely deliver the quantitative precision demanded by engineering applications. Here, we introduce Control and Interpretation of Production via Hybrid Expertise and Reasoning (CIPHER): a vision-language-action (VLA) model framework aiming to replicate human-like reasoning for industrial control, instantiated in a commercial-grade 3D printer. It integrates a process expert, a regression model enabling quantitative characterization of system states required for engineering tasks. CIPHER also incorporates retrieval-augmented generation to access external expert knowledge and support physics-informed, chain-of-thought reasoning. This hybrid architecture exhibits strong generalization to out-of-distribution tasks. It interprets visual or textual inputs from process monitoring, explains its decisions, and autonomously generates precise machine instructions, without requiring explicit annotations. CIPHER thus lays the foundations for autonomous systems that act with precision, reason with context, and communicate decisions transparently, supporting safe and trusted deployment in industrial settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Industrial processes must be robust and adaptable, as environments and tasksare often unpredictable, while operational errors remain costly and difficultto detect. AI-based control systems offer a path forward, yet typically dependon supervised learning with extensive labelled datasets, which limits theirability to generalize across variable and data-scarce industrial settings.Foundation models could enable broader reasoning and knowledge integration, butrarely deliver the quantitative precision demanded by engineering applications.Here, we introduceControl and Interpretation of Production via Hybrid Expertiseand Reasoning (CIPHER): a vision-language-action (VLA) model framework aimingto replicate human-like reasoning for industrial control, instantiated in acommercial-grade 3D printer. It integrates a process expert, a regression modelenabling quantitative characterization of system states required forengineering tasks. CIPHER also incorporates retrieval-augmented generation toaccess external expert knowledge and support physics-informed, chain-of-thoughtreasoning. This hybrid architecture exhibits strong generalization toout-of-distribution tasks. It interprets visual or textual inputs from processmonitoring, explains its decisions, and autonomously generates precise machineinstructions, without requiring explicit annotations. CIPHER thus lays thefoundations for autonomous systems that act with precision, reason withcontext, and communicate decisions transparently, supporting safe and trusteddeployment in industrial settings.</description>
      <author>example@mail.com (Christos Margadji, Sebastian W. Pattinson)</author>
      <guid isPermaLink="false">2506.08462v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>SHIELD: Multi-task Multi-distribution Vehicle Routing Solver with Sparsity and Hierarchy</title>
      <link>http://arxiv.org/abs/2506.08424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in the 42nd International Conference of Machine Learning  (ICML)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的多任务多分布车辆路径问题（MTMDVRP）模型SHIELD，该模型结合了稀疏性和层次性原则，并通过混合深度（MoD）技术和基于上下文的聚类层来提高效率和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基于深度学习的路由问题基础模型在处理多种VRP变体时显示出巨大潜力，但往往忽视了复杂真实世界的客户分布。&lt;h4&gt;目的&lt;/h4&gt;提高多任务VRP（MTVRP）设置到更真实、更具挑战性的多任务多分布VRP（MTMDVRP）设置，并开发一个能够有效处理这种复杂性的模型。&lt;h4&gt;方法&lt;/h4&gt;SHIELD模型通过以下方法实现：1. 使用混合深度（MoD）技术强制执行稀疏性，允许模型动态选择使用或跳过每个解码器层，以适应性地分配计算资源；2. 开发基于上下文的聚类层，利用问题中存在的层次结构产生更好的局部表示。&lt;h4&gt;主要发现&lt;/h4&gt;SHIELD模型能够识别出任务和分布之间的关键特征，显著提高了对未见过的任务的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;在9个真实地图上的16种VRP变体上的实证结果表明，该方法优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances toward foundation models for routing problems have shown great potential of a unified deep model for various VRP variants. However, they overlook the complex real-world customer distributions. In this work, we advance the Multi-Task VRP (MTVRP) setting to the more realistic yet challenging Multi-Task Multi-Distribution VRP (MTMDVRP) setting, and introduce SHIELD, a novel model that leverages both sparsity and hierarchy principles. Building on a deeper decoder architecture, we first incorporate the Mixture-of-Depths (MoD) technique to enforce sparsity. This improves both efficiency and generalization by allowing the model to dynamically select nodes to use or skip each decoder layer, providing the needed capacity to adaptively allocate computation for learning the task/distribution specific and shared representations. We also develop a context-based clustering layer that exploits the presence of hierarchical structures in the problems to produce better local representations. These two designs inductively bias the network to identify key features that are common across tasks and distributions, leading to significantly improved generalization on unseen ones. Our empirical results demonstrate the superiority of our approach over existing methods on 9 real-world maps with 16 VRP variants each.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances toward foundation models for routing problems have showngreat potential of a unified deep model for various VRP variants. However, theyoverlook the complex real-world customer distributions. In this work, weadvance the Multi-Task VRP (MTVRP) setting to the more realistic yetchallenging Multi-Task Multi-Distribution VRP (MTMDVRP) setting, and introduceSHIELD, a novel model that leverages both sparsity and hierarchy principles.Building on a deeper decoder architecture, we first incorporate theMixture-of-Depths (MoD) technique to enforce sparsity. This improves bothefficiency and generalization by allowing the model to dynamically select nodesto use or skip each decoder layer, providing the needed capacity to adaptivelyallocate computation for learning the task/distribution specific and sharedrepresentations. We also develop a context-based clustering layer that exploitsthe presence of hierarchical structures in the problems to produce better localrepresentations. These two designs inductively bias the network to identify keyfeatures that are common across tasks and distributions, leading tosignificantly improved generalization on unseen ones. Our empirical resultsdemonstrate the superiority of our approach over existing methods on 9real-world maps with 16 VRP variants each.</description>
      <author>example@mail.com (Yong Liang Goh, Zhiguang Cao, Yining Ma, Jianan Zhou, Mohammad Haroon Dupty, Wee Sun Lee)</author>
      <guid isPermaLink="false">2506.08424v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>H$^2$GFM: Towards unifying Homogeneity and Heterogeneity on Text-Attributed Graphs</title>
      <link>http://arxiv.org/abs/2506.08298v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为H^2GFM的新框架，旨在提高图基础模型（GFM）在处理不同类型图和任务时的泛化能力，特别是针对异构文本属性图（HeTAGs）。&lt;h4&gt;背景&lt;/h4&gt;图学习在多个领域的应用日益增加，推动了统一模型的发展，该模型称为图基础模型（GFM），能够很好地跨不同图和任务泛化。现有研究主要利用文本属性图（TAGs）来处理图之间节点特征的异质性，但主要关注同构文本属性图（HoTAGs），而对异构文本属性图（HeTAGs）的研究不足。&lt;h4&gt;目的&lt;/h4&gt;为了增强GFM的能力和应用，旨在提出一个能够泛化处理HoTAGs和HeTAGs的框架。&lt;h4&gt;方法&lt;/h4&gt;H^2GFM模型通过一个统一文本空间将图之间的各种元关系进行投影，并使用上下文编码来捕捉空间和高级语义关系。为了实现鲁棒的节点表示，提出了一个新颖的上下文自适应图变换器（CGT），有效捕捉上下文邻居及其关系的信息。此外，采用CGT专家混合方法来捕捉不同类型图之间的结构模式异质性。&lt;h4&gt;主要发现&lt;/h4&gt;在广泛的各种HoTAGs和HeTAGs以及学习场景上的综合实验表明，该模型是有效的。&lt;h4&gt;结论&lt;/h4&gt;H^2GFM框架能够有效提升GFM在处理不同类型图和任务时的泛化能力，特别是在处理异构文本属性图方面。&lt;h4&gt;翻译&lt;/h4&gt;The growing interests and applications of graph learning in diverse domains have propelled the development of a unified model generalizing well across different graphs and tasks, known as the Graph Foundation Model (GFM). Existing research has leveraged text-attributed graphs (TAGs) to tackle the heterogeneity in node features among graphs. However, they primarily focus on homogeneous TAGs (HoTAGs), leaving heterogeneous TAGs (HeTAGs), where multiple types of nodes/edges reside, underexplored. To enhance the capabilities and applications of GFM, we introduce H^2GFM, a novel framework designed to generalize across both HoTAGs and HeTAGs. Our model projects diverse meta-relations among graphs under a unified textual space, and employs a context encoding to capture spatial and higher-order semantic relationships. To achieve robust node representations, we propose a novel context-adaptive graph transformer (CGT), effectively capturing information from both context neighbors and their relationships. Furthermore, we employ a mixture of CGT experts to capture the heterogeneity in structural patterns among graph types. Comprehensive experiments on a wide range of HoTAGs and HeTAGs as well as learning scenarios demonstrate the effectiveness of our model.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing interests and applications of graph learning in diverse domainshave propelled the development of a unified model generalizing well acrossdifferent graphs and tasks, known as the Graph Foundation Model (GFM). Existingresearch has leveraged text-attributed graphs (TAGs) to tackle theheterogeneity in node features among graphs. However, they primarily focus onhomogeneous TAGs (HoTAGs), leaving heterogeneous TAGs (HeTAGs), where multipletypes of nodes/edges reside, underexplored. To enhance the capabilities andapplications of GFM, we introduce H$^2$GFM, a novel framework designed togeneralize across both HoTAGs and HeTAGs. Our model projects diversemeta-relations among graphs under a unified textual space, and employs acontext encoding to capture spatial and higher-order semantic relationships. Toachieve robust node representations, we propose a novel context-adaptive graphtransformer (CGT), effectively capturing information from both contextneighbors and their relationships. Furthermore, we employ a mixture of CGTexperts to capture the heterogeneity in structural patterns among graph types.Comprehensive experiments on a wide range of HoTAGs and HeTAGs as well aslearning scenarios demonstrate the effectiveness of our model.</description>
      <author>example@mail.com (Trung-Kien Nguyen, Heng Ping, Shixuan Li, Peiyu Zhang, Nikos Kanakaris, Nicholas Kotov, Paul Bogdan)</author>
      <guid isPermaLink="false">2506.08298v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Seeing Voices: Generating A-Roll Video from Audio with Mirage</title>
      <link>http://arxiv.org/abs/2506.08279v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report website: mirage.app/research/seeing-voices, product  website: mirage.app&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Mirage的音频到视频基础模型，该模型能够根据音频输入生成逼真的视频图像。&lt;h4&gt;背景&lt;/h4&gt;目前视频生成方法要么忽略声音专注于图像序列生成，要么虽然处理视觉和音频元素但仅限于特定应用领域，如配音。&lt;h4&gt;目的&lt;/h4&gt;提出一种音频到视频生成模型，能够从音频输入中生成具有表达性的视频图像。&lt;h4&gt;方法&lt;/h4&gt;Mirage模型结合了语音合成技术和自注意力机制，能够根据包含语音的音频生成视频。&lt;h4&gt;主要发现&lt;/h4&gt;Mirage模型能够生成高质量的视频输出，且在音频到视频生成方面具有通用性。&lt;h4&gt;结论&lt;/h4&gt;Mirage模型为音频到视频生成提供了一种有效的方法，并鼓励读者亲自体验其效果。&lt;h4&gt;翻译&lt;/h4&gt;从专业电影制作到用户生成内容，创作者和消费者长期以来都认识到视频的力量取决于我们听到的（视频的音频轨道）和我们看到的（视频的图像序列）之间的和谐结合。当前的视频生成方法要么忽略声音以专注于通用但无声的图像序列生成，要么处理视觉和音频元素但仅限于配音等特定应用领域。我们介绍了Mirage，这是一种音频到视频的基础模型，能够从零开始根据音频输入生成逼真的、具有表现力的输出图像。当与现有的语音合成方法（如文本到语音或TTS）集成时，Mirage可以生成引人入胜的多模态视频。当在包含语音的音频视频素材（A卷）上训练，并基于包含语音的音频进行条件化时，Mirage可以生成人们根据输入音频中隐含的表现进行可信诠释的视频。我们主要的技术贡献是统一了训练基于自注意力的音频到视频生成模型的方法，无论是从头开始还是基于现有权重。这种方法使得Mirage在音频到视频生成方面保持了通用性，同时产生了比结合特定于音频架构或针对人、语音或图像或音频捕获细节的损失组件的方法具有更高主观质量的输出。我们鼓励读者亲自观看和聆听Mirage的结果（见论文和评论中的链接）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; From professional filmmaking to user-generated content, creators andconsumers have long recognized that the power of video depends on theharmonious integration of what we hear (the video's audio track) with what wesee (the video's image sequence). Current approaches to video generation eitherignore sound to focus on general-purpose but silent image sequence generationor address both visual and audio elements but focus on restricted applicationdomains such as re-dubbing. We introduce Mirage, an audio-to-video foundationmodel that excels at generating realistic, expressive output imagery fromscratch given an audio input. When integrated with existing methods for speechsynthesis (text-to-speech, or TTS), Mirage results in compelling multimodalvideo. When trained on audio-video footage of people talking (A-roll) andconditioned on audio containing speech, Mirage generates video of peopledelivering a believable interpretation of the performance implicit in inputaudio. Our central technical contribution is a unified method for trainingself-attention-based audio-to-video generation models, either from scratch orgiven existing weights. This methodology allows Mirage to retain generality asan approach to audio-to-video generation while producing outputs of superiorsubjective quality to methods that incorporate audio-specific architectures orloss components specific to people, speech, or details of how images or audioare captured. We encourage readers to watch and listen to the results of Miragefor themselves (see paper and comments for links).</description>
      <author>example@mail.com (Aditi Sundararaman, Amogh Adishesha, Andrew Jaegle, Dan Bigioi, Hyoung-Kyu Song, Jon Kyl, Justin Mao, Kevin Lan, Mojtaba Komeili, ShahRukh Athar, Sheila Babayan, Stanislau Beliasau, William Buchwalter)</author>
      <guid isPermaLink="false">2506.08279v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Pre-Trained Time Series Models for Electricity Price Forecasting</title>
      <link>http://arxiv.org/abs/2506.08113v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了电力价格预测（EPF）在现货市场交易决策中的重要性，并比较了多种时间序列基础模型（TSFMs）在EPF中的有效性。&lt;h4&gt;背景&lt;/h4&gt;虽然近年来生成人工智能（GenAI）和预训练的大型语言模型（LLMs）的发展促进了时间序列基础模型（TSFMs）的众多时间序列预测方法，但这些模型在EPF中的有效性尚不确定。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一差距，本文对比了多个最先进的预训练模型（Chronos-Bolt、Chronos-T5、TimesFM、Moirai、Time-MoE和TimeGPT）与已建立的统计和机器学习（ML）方法在EPF中的性能。&lt;h4&gt;方法&lt;/h4&gt;使用来自德国、法国、荷兰、奥地利和比利时2024年的日间拍卖（DAA）电力价格数据，对模型进行了一天的每日预测。&lt;h4&gt;主要发现&lt;/h4&gt;Chronos-Bolt和Time-MoE在TSFMs中表现最强，与传统模型表现相当。然而，双季节性MSTL模型在多个国家和评估指标上表现出色，没有TSFM在统计上优于它。&lt;h4&gt;结论&lt;/h4&gt;本文的研究结果表明，尽管某些TSFMs在EPF中表现出色，但双季节性MSTL模型在多个国家和评估指标上的一致性能表现尤为突出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate electricity price forecasting (EPF) is crucial for effectivedecision-making in power trading on the spot market. While recent advances ingenerative artificial intelligence (GenAI) and pre-trained large languagemodels (LLMs) have inspired the development of numerous time series foundationmodels (TSFMs) for time series forecasting, their effectiveness in EPF remainsuncertain. To address this gap, we benchmark several state-of-the-artpretrained models--Chronos-Bolt, Chronos-T5, TimesFM, Moirai, Time-MoE, andTimeGPT--against established statistical and machine learning (ML) methods forEPF. Using 2024 day-ahead auction (DAA) electricity prices from Germany,France, the Netherlands, Austria, and Belgium, we generate daily forecasts witha one-day horizon. Chronos-Bolt and Time-MoE emerge as the strongest among theTSFMs, performing on par with traditional models. However, the biseasonal MSTLmodel, which captures daily and weekly seasonality, stands out for itsconsistent performance across countries and evaluation metrics, with no TSFMstatistically outperforming it.</description>
      <author>example@mail.com (Timothée Hornek Amir Sartipi, Igor Tchappi, Gilbert Fridgen)</author>
      <guid isPermaLink="false">2506.08113v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>LSM-2: Learning from Incomplete Wearable Sensor Data</title>
      <link>http://arxiv.org/abs/2506.05321v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Xu and Narayanswamy are co-first authors. McDuff and Liu are co-last  authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了第二代大传感器模型（LSM-2）与自适应和继承掩码（AIM）的结合，这是一种新型的自监督学习（SSL）方法，可以直接从数据缺失的情况下学习稳健的表示，而无需显式地进行数据填充。&lt;h4&gt;背景&lt;/h4&gt;基础模型是机器学习近期进展的核心，但可穿戴传感器数据通常存在大量缺失，这对通常假设完整数据输入的自监督学习模型构成了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的SSL方法，能够从缺失数据中学习，以解决可穿戴传感器数据中缺失数据的问题。&lt;h4&gt;方法&lt;/h4&gt;引入了LSM-2与AIM的结合，其中AIM使用可学习的掩码标记来模拟现有的（继承的）和人为引入的缺失数据，从而在推理过程中稳健地处理碎片化的真实世界数据。&lt;h4&gt;主要发现&lt;/h4&gt;LSM-2与AIM在40M小时的日间多模态传感器数据集上进行了预训练，并在包括分类、回归和生成建模在内的各种任务中实现了最佳性能。此外，LSM-2与AIM展现出优异的扩展性能，并且在目标缺失场景下仍能保持高性能，反映了临床一致的模式，如夜间生物信号在高血压预测中的诊断价值。&lt;h4&gt;结论&lt;/h4&gt;AIM为实际的可穿戴数据应用提供了一个更可靠的解决方案，因为它能够处理缺失数据并维持高精度。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型是近期机器学习进步的基石，它们主要依赖于完整且结构良好的数据。可穿戴传感器数据常常存在显著的缺失，这对通常假设完整数据输入的自监督学习（SSL）模型构成了重大挑战。本文介绍了第二代大传感器模型（LSM-2）与自适应和继承掩码（AIM）的结合，这是一种新颖的自监督学习（SSL）方法，可以直接从数据缺失的情况下学习稳健的表示，而无需显式地进行数据填充。AIM的核心创新在于其使用可学习的掩码标记来模拟现有的（继承的）和人为引入的缺失数据，使得它能够在推理过程中稳健地处理碎片化的真实世界数据。在40M小时的日间多模态传感器数据集上预训练后，我们的LSM-2与AIM在包括分类、回归和生成建模在内的各种任务中实现了最佳性能。此外，LSM-2与AIM展现出优异的扩展性能，并且关键的是，即使在目标缺失场景下也能保持高性能，反映了临床一致的模式，如夜间生物信号在高血压预测中的诊断价值。这使得AIM成为实际可穿戴数据应用的一个更可靠的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models, a cornerstone of recent advancements in machine learning,have predominantly thrived on complete and well-structured data. Wearablesensor data frequently suffers from significant missingness, posing asubstantial challenge for self-supervised learning (SSL) models that typicallyassume complete data inputs. This paper introduces the second generation ofLarge Sensor Model (LSM-2) with Adaptive and Inherited Masking (AIM), a novelSSL approach that learns robust representations directly from incomplete datawithout requiring explicit imputation. AIM's core novelty lies in its use oflearnable mask tokens to model both existing ("inherited") and artificiallyintroduced missingness, enabling it to robustly handle fragmented real-worlddata during inference. Pre-trained on an extensive dataset of 40M hours ofday-long multimodal sensor data, our LSM-2 with AIM achieves the bestperformance across a diverse range of tasks, including classification,regression and generative modeling. Furthermore, LSM-2 with AIM exhibitssuperior scaling performance, and critically, maintains high performance evenunder targeted missingness scenarios, reflecting clinically coherent patterns,such as the diagnostic value of nighttime biosignals for hypertensionprediction. This makes AIM a more reliable choice for real-world wearable dataapplications.</description>
      <author>example@mail.com (Maxwell A. Xu, Girish Narayanswamy, Kumar Ayush, Dimitris Spathis, Shun Liao, Shyam A. Tailor, Ahmed Metwally, A. Ali Heydari, Yuwei Zhang, Jake Garrison, Samy Abdel-Ghaffar, Xuhai Xu, Ken Gu, Jacob Sunshine, Ming-Zher Poh, Yun Liu, Tim Althoff, Shrikanth Narayanan, Pushmeet Kohli, Mark Malhotra, Shwetak Patel, Yuzhe Yang, James M. Rehg, Xin Liu, Daniel McDuff)</author>
      <guid isPermaLink="false">2506.05321v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
  <item>
      <title>Diffusion Counterfactual Generation with Semantic Abduction</title>
      <link>http://arxiv.org/abs/2506.07883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of the 42nd International Conference on Machine Learning,  Vancouver, Canada&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散模型的因果机制，用于改进反事实图像生成，旨在解决身份保持、感知质量和因果模型忠实度等挑战。&lt;h4&gt;背景&lt;/h4&gt;反事实图像生成在保持身份、维护感知质量和确保对底层因果模型的忠实度方面存在重大挑战。现有的自动编码框架虽然允许操纵语义潜在空间以进行因果控制，但面临着可扩展性和忠实度的问题。&lt;h4&gt;目的&lt;/h4&gt;通过提出一套基于扩散的因果机制，本文旨在提高反事实图像编辑的质量，并引入空间、语义和动态推理的概念。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种将语义表示整合到扩散模型中的通用框架，通过Pearlian因果性的视角，通过反事实推理过程编辑图像。&lt;h4&gt;主要发现&lt;/h4&gt;这是首次考虑为扩散反事实图像生成提供高级语义身份保持的工作，并展示了语义控制如何实现忠实因果控制和身份保持之间的原则性权衡。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在视觉质量、人类感知和表示学习方面取得了最先进的成果，为反事实图像生成提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Counterfactual image generation presents significant challenges, includingpreserving identity, maintaining perceptual quality, and ensuring faithfulnessto an underlying causal model. While existing auto-encoding frameworks admitsemantic latent spaces which can be manipulated for causal control, theystruggle with scalability and fidelity. Advancements in diffusion modelspresent opportunities for improving counterfactual image editing, havingdemonstrated state-of-the-art visual quality, human-aligned perception andrepresentation learning capabilities. Here, we present a suite ofdiffusion-based causal mechanisms, introducing the notions of spatial, semanticand dynamic abduction. We propose a general framework that integrates semanticrepresentations into diffusion models through the lens of Pearlian causality toedit images via a counterfactual reasoning process. To our knowledge, this isthe first work to consider high-level semantic identity preservation fordiffusion counterfactuals and to demonstrate how semantic control enablesprincipled trade-offs between faithful causal control and identitypreservation.</description>
      <author>example@mail.com (Rajat Rasal, Avinash Kori, Fabio De Sousa Ribeiro, Tian Xia, Ben Glocker)</author>
      <guid isPermaLink="false">2506.07883v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Gradients: When Markets Meet Fine-tuning -- A Distributed Approach to Model Optimisation</title>
      <link>http://arxiv.org/abs/2506.07940v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Gradients，一个将超参数优化转化为竞争市场的去中心化AutoML平台，通过经济激励机制实现个人探索与集体优化目标的统一，从而系统性地发现中心化方法遗漏的更优配置。&lt;h4&gt;背景&lt;/h4&gt;现有的AutoML平台依赖单一优化策略，只探索了一小部分可行的超参数配置，导致优化效果受限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过去中心化的AutoML平台，提高超参数优化的效果。&lt;h4&gt;方法&lt;/h4&gt;Gradients平台将超参数优化转化为竞争市场，独立矿工通过竞争发现最优配置，并利用经济激励机制驱动系统性的探索。&lt;h4&gt;主要发现&lt;/h4&gt;在180个控制实验中，Gradients平台在各种模型架构和任务类型上均取得了显著的效果，平均提升11.8%，在特定任务类型上提升高达30-40%。&lt;h4&gt;结论&lt;/h4&gt;竞争性和经济驱动的AutoML方法可以系统地发现中心化方法遗漏的更优配置，从而提高优化效果。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces Gradients, a decentralized AutoML platform that transforms hyperparameter optimization into a competitive marketplace where independent miners compete to discover optimal configurations. Economic incentives align individual exploration with collective optimization goals, driving systematic investigation of hyperparameter regions that centralized methods miss. We evaluate our approach across 180 controlled experiments spanning diverse model architectures (70M to 70B parameters) and task types. Gradients achieves an 82.8% win rate against HuggingFace AutoTrain and 100% against TogetherAI, Databricks, and Google Cloud, with mean improvements of 11.8% and 42.1% respectively. Complex reasoning and retrieval tasks show particularly strong gains of 30-40%, while diffusion models achieve 23.4% improvements for person-specific generation. These results demonstrate that competitive, economically-driven approaches can systematically discover superior configurations that centralized AutoML consistently miss.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation model fine-tuning faces a fundamental challenge: existing AutoMLplatforms rely on single optimisation strategies that explore only a fractionof viable hyperparameter configurations. In this white paper, We introduceGradients, a decentralised AutoML platform that transforms hyperparameteroptimisation into a competitive marketplace where independent miners compete todiscover optimal configurations. Economic incentives align individualexploration with collective optimisation goals, driving systematicinvestigation of hyperparameter regions that centralised methods miss. Weevaluate our approach across 180 controlled experiments spanning diverse modelarchitectures (70M to 70B parameters) and task types. Gradients achieves an82.8\% win rate against HuggingFace AutoTrain and 100\% against TogetherAI,Databricks, and Google Cloud, with mean improvements of 11.8\% and 42.1\%respectively. Complex reasoning and retrieval tasks show particularly stronggains of 30-40\%, whilst diffusion models achieve 23.4\% improvements forperson-specific generation. These results demonstrate that competitive,economically-driven approaches can systematically discover superiorconfigurations that centralised AutoML consistently miss.</description>
      <author>example@mail.com (Christopher Subia-Waud)</author>
      <guid isPermaLink="false">2506.07940v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence</title>
      <link>http://arxiv.org/abs/2506.07966v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SpaCE-10是一个针对多模态大型语言模型（MLLMs）在空间智能方面进行综合评估的基准。&lt;h4&gt;背景&lt;/h4&gt;MLLMs在多模态任务上取得了显著进步，但现有的基准难以全面评估MLLMs从原子级到组合级的空间智能。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，提出SpaCE-10，一个用于组合空间评估的综合基准。&lt;h4&gt;方法&lt;/h4&gt;定义了10个原子空间能力，组合成8个组合能力，并提出了一个新颖的分层标注流程来生成高质量和多样化的问答对。通过超过150小时的人类专家努力，获得了超过5000个问答对，涵盖811个真实室内场景，包括点云输入和多选题问答。&lt;h4&gt;主要发现&lt;/h4&gt;发现即使是最高级的MLLM，在空间智能方面也远远落后于人类。揭示了计数能力的不足大大限制了现有MLLMs的组合空间能力。&lt;h4&gt;结论&lt;/h4&gt;SpaCE-10为MLLM社区提供了有益的发现和评估工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态大型语言模型（MLLMs）在多种多模态任务上取得了显著的进步。为了在空间中追求更高的智能，MLLMs需要整合多个原子空间能力来处理复杂和动态的任务。然而，现有的基准难以从原子级到组合级全面评估常见MLLMs的空间智能。为了填补这一空白，我们提出了SpaCE-10，一个用于组合空间评估的综合基准。在SpaCE-10中，我们定义了10个原子空间能力，这些能力组合形成了8个组合能力。基于这些定义，我们提出了一种新颖的分层标注流程来生成高质量和多样化的问答对。通过超过150小时的人类专家努力，我们获得了超过5000个问答对，涵盖了811个真实室内场景，包括点云输入和多选题问答。我们在SpaCE-10上对常见MLLMs进行了广泛的评估，发现即使是最高级的MLLM，在空间智能方面也远远落后于人类。通过我们的仔细研究，我们还得出了几个对MLLM社区有益的重要发现。例如，我们揭示了计数能力的不足大大限制了现有MLLMs的组合空间能力。评估代码和基准数据集可在https://github.com/Cuzyoung/SpaCE-10找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have achieved remarkable progress invarious multimodal tasks. To pursue higher intelligence in space, MLLMs requireintegrating multiple atomic spatial capabilities to handle complex and dynamictasks. However, existing benchmarks struggle to comprehensively evaluate thespatial intelligence of common MLLMs from the atomic level to the compositionallevel. To fill this gap, we present SpaCE-10, a comprehensive benchmark forcompositional spatial evaluations. In SpaCE-10, we define 10 atomic spatialcapabilities, which are combined to form 8 compositional capabilities. Based onthese definitions, we propose a novel hierarchical annotation pipeline togenerate high-quality and diverse question-answer (QA) pairs. With over 150+hours of human expert effort, we obtain over 5k QA pairs for 811 real indoorscenes in SpaCE-10, which covers various evaluation settings like point cloudinput and multi-choice QA. We conduct an extensive evaluation of common MLLMson SpaCE-10 and find that even the most advanced MLLM still lags behind humansby large margins. Through our careful study, we also draw several significantfindings that benefit the MLLM community. For example, we reveal that theshortcoming of counting capability greatly limits the compositional spatialcapabilities of existing MLLMs. The evaluation code and benchmark datasets areavailable at https://github.com/Cuzyoung/SpaCE-10.</description>
      <author>example@mail.com (Ziyang Gong, Wenhao Li, Oliver Ma, Songyuan Li, Jiayi Ji, Xue Yang, Gen Luo, Junchi Yan, Rongrong Ji)</author>
      <guid isPermaLink="false">2506.07966v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>CyberV: Cybernetics for Test-time Scaling in Video Understanding</title>
      <link>http://arxiv.org/abs/2506.07971v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于控制论原理的新型框架，旨在解决现有多模态大型语言模型在处理长或复杂视频时的局限性，如计算需求高、鲁棒性差和准确性有限等问题。&lt;h4&gt;背景&lt;/h4&gt;现有多模态大型语言模型在处理长或复杂视频时存在计算需求高、鲁棒性差和准确性有限等问题，这些问题主要源于其前馈处理性质，尤其是在参数较少的模型中更为严重。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了一种名为CyberV的框架，旨在设计能够自我监控、自我纠正和动态资源分配的视频多模态大型语言模型。&lt;h4&gt;方法&lt;/h4&gt;CyberV框架包括一个多模态大型语言模型推理系统、一个传感器和一个控制器。传感器监控多模态大型语言模型的前向过程，收集中间解释，如注意力漂移；控制器决定何时以及如何触发自我纠正并生成反馈以指导下一轮。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CyberV在VideoMMMU上提升了Qwen2.5-VL-7B模型8.3%，在InternVL3-8B上提升了5.5%，超过了竞争性的GPT-4o模型。在Qwen2.5-VL-72B上应用时，提升了10.0%，其性能甚至可与人类专家相媲美。此外，该方法在VideoMME和WorldSense等通用基准测试中也表现出一致的收益，突显了其在使多模态大型语言模型更鲁棒和准确地进行动态视频理解方面的有效性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;CyberV框架能够有效提升多模态大型语言模型在动态视频理解任务中的性能，且无需重新训练或添加额外组件。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current Multimodal Large Language Models (MLLMs) may struggle withunderstanding long or complex videos due to computational demands at test time,lack of robustness, and limited accuracy, primarily stemming from theirfeed-forward processing nature. These limitations could be more severe formodels with fewer parameters. To address these limitations, we propose a novelframework inspired by cybernetic principles, redesigning video MLLMs asadaptive systems capable of self-monitoring, self-correction, and dynamicresource allocation during inference. Our approach, CyberV, introduces acybernetic loop consisting of an MLLM Inference System, a Sensor, and aController. Specifically, the sensor monitors forward processes of the MLLM andcollects intermediate interpretations, such as attention drift, then thecontroller determines when and how to trigger self-correction and generatefeedback to guide the next round. This test-time adaptive scaling frameworkenhances frozen MLLMs without requiring retraining or additional components.Experiments demonstrate significant improvements: CyberV boosts Qwen2.5-VL-7Bby 8.3% and InternVL3-8B by 5.5% on VideoMMMU, surpassing the competitiveproprietary model GPT-4o. When applied to Qwen2.5-VL-72B, it yields a 10.0%improvement, achieving performance even comparable to human experts.Furthermore, our method demonstrates consistent gains on general-purposebenchmarks, such as VideoMME and WorldSense, highlighting its effectiveness andgeneralization capabilities in making MLLMs more robust and accurate fordynamic video understanding. The code is released athttps://github.com/marinero4972/CyberV.</description>
      <author>example@mail.com (Jiahao Meng, Shuyang Sun, Yue Tan, Lu Qi, Yunhai Tong, Xiangtai Li, Longyin Wen)</author>
      <guid isPermaLink="false">2506.07971v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Language Embedding Meets Dynamic Graph: A New Exploration for Neural Architecture Representation Learning</title>
      <link>http://arxiv.org/abs/2506.07735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LeDG-Former的创新框架，通过结合语言语义嵌入和动态图表示学习来克服现有方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;神经网络架构表示学习在部署和设计网络以应用于现实世界方面发挥着关键作用。基于transformers的模型与图神经网络（GNNs）的集成在表示学习方面取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法忽视硬件属性信息以及编码方法依赖静态邻接矩阵的局限性。&lt;h4&gt;方法&lt;/h4&gt;引入LeDG-Former框架，该框架通过结合语言语义嵌入和动态图表示学习，将神经网络架构和硬件平台规范投影到一个统一的语义空间中，实现不同硬件平台间的零样本预测。&lt;h4&gt;主要发现&lt;/h4&gt;LeDG-Former在NNLQP基准测试中超越了之前的方法，建立了新的SOTA，并展示了首次成功实现跨硬件延迟预测的能力。此外，该框架在cell-structured NAS-Bench-101和NAS-Bench-201数据集上也取得了优越的性能。&lt;h4&gt;结论&lt;/h4&gt;LeDG-Former框架有效地解决了现有方法的局限性，为神经网络架构表示学习提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural Architecture Representation Learning aims to transform network modelsinto feature representations for predicting network attributes, playing acrucial role in deploying and designing networks for real-world applications.Recently, inspired by the success of transformers, transformer-based modelsintegrated with Graph Neural Networks (GNNs) have achieved significant progressin representation learning. However, current methods still have somelimitations. First, existing methods overlook hardware attribute information,which conflicts with the current trend of diversified deep learning hardwareand limits the practical applicability of models. Second, current encodingapproaches rely on static adjacency matrices to represent topologicalstructures, failing to capture the structural differences between computationalnodes, which ultimately compromises encoding effectiveness. In this paper, weintroduce LeDG-Former, an innovative framework that addresses these limitationsthrough the synergistic integration of language-based semantic embedding anddynamic graph representation learning. Specifically, inspired by large languagemodels (LLMs), we propose a language embedding framework where both neuralarchitectures and hardware platform specifications are projected into a unifiedsemantic space through tokenization and LLM processing, enabling zero-shotprediction across different hardware platforms for the first time. Then, wepropose a dynamic graph-based transformer for modeling neural architectures,resulting in improved neural architecture modeling performance. On the NNLQPbenchmark, LeDG-Former surpasses previous methods, establishing a new SOTAwhile demonstrating the first successful cross-hardware latency predictioncapability. Furthermore, our framework achieves superior performance on thecell-structured NAS-Bench-101 and NAS-Bench-201 datasets.</description>
      <author>example@mail.com (Haizhao Jing, Haokui Zhang, Zhenhao Shang, Rong Xiao, Peng Wang, Yanning Zhang)</author>
      <guid isPermaLink="false">2506.07735v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Image Reconstruction as a Tool for Feature Analysis</title>
      <link>http://arxiv.org/abs/2506.07803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过图像重建来解释视觉特征的新方法，并分析了不同视觉编码器内部特征表示的差异。&lt;h4&gt;背景&lt;/h4&gt;视觉编码器在现代应用中越来越受欢迎，但它们的内部特征表示方式尚不明确。&lt;h4&gt;目的&lt;/h4&gt;研究视觉编码器内部特征表示的方式，并评估不同模型在图像信息保留方面的表现。&lt;h4&gt;方法&lt;/h4&gt;提出了SigLIP和SigLIP2两种模型，通过比较它们的训练目标，发现基于图像任务的预训练编码器比基于非图像任务的编码器保留了更多的图像信息。此外，通过操纵特征空间来分析重建图像的变化，揭示颜色编码的控制方式。&lt;h4&gt;主要发现&lt;/h4&gt;基于图像任务的预训练编码器比基于非图像任务的编码器保留了更多的图像信息；通过操纵特征空间可以预测性地改变重建图像；正交旋转控制颜色编码。&lt;h4&gt;结论&lt;/h4&gt;该方法可以应用于任何视觉编码器，有助于揭示其特征空间的内部结构。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉编码器在现代应用中越来越受欢迎，从仅视觉模型到多模态系统如视觉-语言模型。尽管它们取得了显著的成功，但它们如何内部表示特征仍然不清楚。在这里，我们提出了一种通过图像重建来解释视觉特征的新方法。我们比较了两个相关的模型家族，SigLIP和SigLIP2，它们在训练目标上有所不同，并表明在基于图像任务的预训练上的编码器比在基于非图像任务（如对比学习）的编码器上保留了更多的图像信息。我们进一步将我们的方法应用于一系列视觉编码器，按照其特征表示的信息量对它们进行排名。最后，我们表明，操纵特征空间会导致重建图像的可预测变化，揭示了正交旋转（而不是空间变换）控制颜色编码。我们的方法可以应用于任何视觉编码器，有助于揭示其特征空间的内部结构。用于重现实验的代码和模型权重可在GitHub上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision encoders are increasingly used in modern applications, fromvision-only models to multimodal systems such as vision-language models.Despite their remarkable success, it remains unclear how these architecturesrepresent features internally. Here, we propose a novel approach forinterpreting vision features via image reconstruction. We compare two relatedmodel families, SigLIP and SigLIP2, which differ only in their trainingobjective, and show that encoders pre-trained on image-based tasks retainsignificantly more image information than those trained on non-image tasks suchas contrastive learning. We further apply our method to a range of visionencoders, ranking them by the informativeness of their feature representations.Finally, we demonstrate that manipulating the feature space yields predictablechanges in reconstructed images, revealing that orthogonal rotations (ratherthan spatial transformations) control color encoding. Our approach can beapplied to any vision encoder, shedding light on the inner structure of itsfeature space. The code and model weights to reproduce the experiments areavailable in GitHub.</description>
      <author>example@mail.com (Eduard Allakhverdov, Dmitrii Tarasov, Elizaveta Goncharova, Andrey Kuznetsov)</author>
      <guid isPermaLink="false">2506.07803v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>CrosswalkNet: An Optimized Deep Learning Framework for Pedestrian Crosswalk Detection in Aerial Images with High-Performance Computing</title>
      <link>http://arxiv.org/abs/2506.07885v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了CrosswalkNet，一个用于从高分辨率航空图像中检测各类人行横道的深度学习框架，旨在提高交通资产管理、安全分析和城市规划的效率。&lt;h4&gt;背景&lt;/h4&gt;随着航空和卫星图像的广泛应用，深度学习在交通资产管理、安全分析和城市规划方面具有巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够准确检测人行横道的深度学习框架。&lt;h4&gt;方法&lt;/h4&gt;CrosswalkNet采用了一种新颖的检测方法，使用定向边界框（OBB）提高检测精度，并通过卷积块注意力、双分支空间金字塔池化快速模块和余弦退火等优化技术来最大化性能和效率。研究使用了包含超过23,000个标注人行横道实例的综合数据集来训练和验证该框架。&lt;h4&gt;主要发现&lt;/h4&gt;最佳模型在马萨诸塞州的航空图像上实现了96.5%的精确率和93.3%的召回率。CrosswalkNet在没有迁移学习或微调的情况下成功应用于新罕布什尔州、弗吉尼亚州和缅因州的数据集。使用高性能计算（HPC）平台处理的人行横道检测结果以多边形形状文件格式提供，加速了数据处理和检测，支持实时分析和安全与移动性应用。&lt;h4&gt;结论&lt;/h4&gt;CrosswalkNet是一个准确且有效的工具，能够增强行人安全并改善城市流动性，为政策制定者、交通工程师和城市规划者提供了有效的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着航空和卫星图像的日益可用，深度学习在交通资产管理、安全分析和城市规划方面具有显著潜力。本研究介绍了CrosswalkNet，这是一个强大且高效的深度学习框架，旨在从15厘米分辨率的航空图像中检测各种类型的人行横道。CrosswalkNet采用了一种新颖的检测方法，通过使用定向边界框（OBB）改进了传统的目标检测策略，无论横道方向如何，都能准确地捕获横道。研究实现了包括卷积块注意力、双分支空间金字塔池化快速模块和余弦退火在内的多种优化技术，以最大化性能和效率。研究使用了包含超过23,000个标注人行横道实例的综合数据集来训练和验证所提出的框架。性能最佳的模型在马萨诸塞州的航空图像上实现了令人印象深刻的96.5%的精确率和93.3%的召回率，证明了其准确性和有效性。CrosswalkNet还成功应用于新罕布什尔州、弗吉尼亚州和缅因州的数据集，无需迁移学习或微调，展示了其鲁棒性和强大的泛化能力。此外，使用高性能计算（HPC）平台处理的人行横道检测结果以多边形形状文件格式提供，已显示出加速数据处理和检测的能力，支持安全性和移动性应用的实时分析。这种集成为政策制定者、交通工程师和城市规划者提供了一个有效的工具，以增强行人安全并改善城市流动性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the increasing availability of aerial and satellite imagery, deeplearning presents significant potential for transportation asset management,safety analysis, and urban planning. This study introduces CrosswalkNet, arobust and efficient deep learning framework designed to detect various typesof pedestrian crosswalks from 15-cm resolution aerial images. CrosswalkNetincorporates a novel detection approach that improves upon traditional objectdetection strategies by utilizing oriented bounding boxes (OBB), enhancingdetection precision by accurately capturing crosswalks regardless of theirorientation. Several optimization techniques, including Convolutional BlockAttention, a dual-branch Spatial Pyramid Pooling-Fast module, and cosineannealing, are implemented to maximize performance and efficiency. Acomprehensive dataset comprising over 23,000 annotated crosswalk instances isutilized to train and validate the proposed framework. The best-performingmodel achieves an impressive precision of 96.5% and a recall of 93.3% on aerialimagery from Massachusetts, demonstrating its accuracy and effectiveness.CrosswalkNet has also been successfully applied to datasets from New Hampshire,Virginia, and Maine without transfer learning or fine-tuning, showcasing itsrobustness and strong generalization capability. Additionally, the crosswalkdetection results, processed using High-Performance Computing (HPC) platformsand provided in polygon shapefile format, have been shown to accelerate dataprocessing and detection, supporting real-time analysis for safety and mobilityapplications. This integration offers policymakers, transportation engineers,and urban planners an effective instrument to enhance pedestrian safety andimprove urban mobility.</description>
      <author>example@mail.com (Zubin Bhuyan, Yuanchang Xie, AngkeaReach Rith, Xintong Yan, Nasko Apostolov, Jimi Oke, Chengbo Ai)</author>
      <guid isPermaLink="false">2506.07885v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>A Temporal FRBR/FRBRoo-Based Model for Component-Level Versioning of Legal Norms</title>
      <link>http://arxiv.org/abs/2506.07853v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结构化时间模型，扩展了FRBRoo框架，以解决法律规范自动处理中的关键挑战，特别是在追踪其层次化组件（如文章、段落）的历时演变。&lt;h4&gt;背景&lt;/h4&gt;目前，虽然FRBR/FRBRoo等基础框架和Akoma Ntoso等标准在宏观层面模型化了法律文件，但它们缺乏原生机制来进行细粒度、组件级别的版本控制，这阻碍了法律文本在特定时间点的确定性重建。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种能够精确、确定地检索和重建法律文本在特定日期状态的模型，为可靠的法律技术和AI应用提供基础。&lt;h4&gt;方法&lt;/h4&gt;提出了一种结构化时间模型，引入了Expressio - Temporal Version (TV)和Language Version (LV)等专门子类来表示法律规范及其语言变体在特定时间点的状态，并应用于层次化结构，引入Component Work (CW)、Component Temporal Version (CTV)和Component Language Version (CLV)来追踪个别文章、段落和条款的生命周期。&lt;h4&gt;主要发现&lt;/h4&gt;以巴西联邦宪法为案例研究，展示了每个修正案如何为受影响的条款创建新的Component Temporal Versions，而未受影响的组件则保留其现有版本。&lt;h4&gt;结论&lt;/h4&gt;该模型为开发高级法律信息系统、知识图谱和能够进行准确历史分析和影响评估的AI工具提供了坚实的基础，克服了当前生成模型的局限性。&lt;h4&gt;翻译&lt;/h4&gt;有效地表示用于自动处理的法律规范是一个关键挑战，尤其是在追踪其层次化组件（例如，文章、段落）的历时演变方面。虽然像FRBR/FRBRoo这样的基础框架和像Akoma Ntoso这样的标准在宏观层面模型化了法律文件，但它们缺乏原生机制来进行细粒度、组件级别的版本控制。这种限制阻碍了法律文本在特定时间点的确定性重建，这是可靠的法律技术和AI应用的基本能力。本文提出了一种结构化时间模型，扩展了FRBRoo框架来填补这一空白。它引入了Expressio - Temporal Version (TV)和Language Version (LV)等专门子类来表示法律规范及其语言变体在特定时间点的状态。该模型以相同的方法进行层次化应用，引入了Component Work (CW)、Component Temporal Version (CTV)和Component Language Version (CLV)来追踪个别文章、段落和条款的生命周期。以巴西联邦宪法为案例研究，本文展示了每个修正案如何为受影响的条款创建新的Component Temporal Versions，而未受影响的组件则保留其现有版本。这种精细粒度、时间感知的架构能够精确、确定地检索和重建任何部分的法律文本，如它在特定日期的状态。该模型为开发高级法律信息系统、知识图谱和能够进行准确历史分析和影响评估的AI工具提供了坚实的基础，克服了当前生成模型的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effectively representing legal norms for automated processing is a criticalchallenge, particularly in tracking the diachronic evolution of theirhierarchical components (e.g., articles, paragraphs). While foundationalframeworks like FRBR/FRBRoo and standards like Akoma Ntoso model legaldocuments at a macro level, they lack native mechanisms for granular,component-level versioning. This limitation hinders the deterministicpoint-in-time reconstruction of legal texts, a fundamental capability forreliable Legal Tech and AI applications. This paper proposes a structured,temporal model that extends the FRBRoo framework to address this gap. Itintroduces specialized subclasses of Expressio - Temporal Version (TV) andLanguage Version (LV - to represent the state of a legal norm and itslinguistic variations at specific points in time. The model applies this sameparadigm hierarchically, introducing Component Work (CW), Component TemporalVersion (CTV), and Component Language Version (CLV) to track the lifecycle ofindividual articles, paragraphs, and clauses. Using the Brazilian FederalConstitution as a case study, the paper demonstrates how each amendment createsnew Component Temporal Versions for affected provisions, while unaffectedcomponents retain their existing versions. This fine-grained, time-awarearchitecture enables the precise, deterministic retrieval and reconstruction ofany part of a legal text as it existed on a specific date. The model provides arobust foundation for developing advanced legal information systems, knowledgegraphs, and AI tools capable of accurate historical analysis and impactassessment, overcoming the limitations of current generative models.</description>
      <author>example@mail.com (Hudson de Martim)</author>
      <guid isPermaLink="false">2506.07853v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Super Encoding Network: Recursive Association of Multi-Modal Encoders for Video Understanding</title>
      <link>http://arxiv.org/abs/2506.07576v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Super Encoding Network (SEN)的统一网络，用于视频理解，该网络通过在基础模型中递归关联多模态编码器来建立深度多模态交互。&lt;h4&gt;背景&lt;/h4&gt;视频理解是迈向世界建模的关键步骤，而多模态基础模型通过大规模预训练显示出巨大潜力。然而，这些模型缺乏深度多模态交互，这对于理解复杂目标运动和多样化的视频场景至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文旨在提出一种新的方法来增强视频理解中的多模态交互。&lt;h4&gt;方法&lt;/h4&gt;本文设计了一种递归关联（RA）块，将多模态信息与输入视频逐步融合，通过超级神经元的递归知识整合、分配和提示来实现。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，SEN在四个代表性的视频任务（跟踪、识别、聊天和编辑）上均显著提升了性能，例如，在像素级跟踪任务中，与CaDeX++方法相比，Jaccard指数提高了2.7%，时间一致性（TC）降低了8.8%。在单次视频编辑任务中，与TuneA-Video方法相比，文本对齐提高了6.4%，帧一致性增加了4.1%。&lt;h4&gt;结论&lt;/h4&gt;SEN能够有效地编码深度多模态交互，从而显著提升视频理解任务的表现。&lt;h4&gt;翻译&lt;/h4&gt;Video understanding has been considered as one critical step towards world modeling, which is an important long-term problem in AI research. Recently, multi-modal foundation models have shown such potential via large-scale pretraining. However, these models simply align encoders of different modalities via contrastive learning, while lacking deeper multi-modal interactions, which is critical for understanding complex target movements with diversified video scenes. To fill this gap, we propose a unified Super Encoding Network (SEN) for video understanding, which builds up such distinct interactions through recursive association of multi-modal encoders in the foundation models. Specifically, we creatively treat those well-trained encoders as 'super neurons' in our SEN. Via designing a Recursive Association (RA) block, we progressively fuse multi-modalities with the input video, based on knowledge integrating, distributing, and prompting of super neurons in a recursive manner. In this way, our SEN can effectively encode deeper multi-modal interactions, for prompting various video understanding tasks in downstream. Extensive experiments show that, our SEN can remarkably boost the four most representative video tasks, including tracking, recognition, chatting, and editing, e.g., for pixel-level tracking, the average jaccard index improves 2.7%, temporal coherence (TC) drops 8.8% compared to the popular CaDeX++ approach. For one-shot video editing, textual alignment improves 6.4%, and frame consistency increases 4.1% compared to the popular TuneA-Video approach.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video understanding has been considered as one critical step towards worldmodeling, which is an important long-term problem in AI research. Recently,multi-modal foundation models have shown such potential via large-scalepretraining. However, these models simply align encoders of differentmodalities via contrastive learning, while lacking deeper multi-modalinteractions, which is critical for understanding complex target movements withdiversified video scenes. To fill this gap, we propose a unified Super EncodingNetwork (SEN) for video understanding, which builds up such distinctinteractions through recursive association of multi-modal encoders in thefoundation models. Specifically, we creatively treat those well-trainedencoders as "super neurons" in our SEN. Via designing a Recursive Association(RA) block, we progressively fuse multi-modalities with the input video, basedon knowledge integrating, distributing, and prompting of super neurons in arecursive manner. In this way, our SEN can effectively encode deepermulti-modal interactions, for prompting various video understanding tasks indownstream. Extensive experiments show that, our SEN can remarkably boost thefour most representative video tasks, including tracking, recognition,chatting, and editing, e.g., for pixel-level tracking, the average jaccardindex improves 2.7%, temporal coherence(TC) drops 8.8% compared to the popularCaDeX++ approach. For one-shot video editing, textual alignment improves 6.4%,and frame consistency increases 4.1% compared to the popular TuneA-Videoapproach.</description>
      <author>example@mail.com (Boyu Chen, Siran Chen, Kunchang Li, Qinglin Xu, Yu Qiao, Yali Wang)</author>
      <guid isPermaLink="false">2506.07576v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>EgoM2P: Egocentric Multimodal Multitask Pretraining</title>
      <link>http://arxiv.org/abs/2506.07886v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究如何理解以自我为中心的多模态信号，如RGB视频、深度、相机姿态和注视信息，这对增强现实、机器人和人机交互等应用至关重要。文章提出了EgoM2P框架，用于处理和合成这些多模态数据，并展示了其在不同任务上的性能优势。&lt;h4&gt;背景&lt;/h4&gt;多模态信号在以自我为中心的视觉应用中至关重要，但构建大规模的以自我为中心的多模态和多任务模型面临挑战，如数据异构性、模态缺失和动态相机运动等。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为EgoM2P的框架，用于解决上述挑战，并提高以自我为中心的多模态理解的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;引入高效的时序标记器，并构建EgoM2P框架，该框架通过从时序感知的多模态标记中学习，来训练一个用于以自我为中心的4D理解的大规模通用模型。&lt;h4&gt;主要发现&lt;/h4&gt;EgoM2P在注视预测、以自我为中心的相机跟踪和从以自我为中心的视频中进行单目深度估计等任务上表现出色，同时速度比专业模型快一个数量级。&lt;h4&gt;结论&lt;/h4&gt;EgoM2P框架有效解决了多模态信号理解中的挑战，提高了以自我为中心的视觉应用的性能，并计划开源以支持社区和推动相关研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：理解以自我为中心的多模态信号，如RGB视频、深度、相机姿态和注视，对于增强现实、机器人和人机交互等应用至关重要。这些能力使系统能够更好地解释相机佩戴者的动作、意图和周围环境。然而，构建大规模的以自我为中心的多模态和多任务模型面临独特的挑战。以自我为中心的数据本质上是异构的，在不同设备和环境中的模态覆盖范围存在很大差异。为缺失的模态，如注视或头戴式相机轨迹生成伪标签通常不可行，使得标准的监督学习方法难以扩展。此外，动态相机运动和第一人称视频的姿态的复杂时空结构为直接应用现有的多模态基础模型增加了额外的挑战。为了解决这些挑战，我们引入了一套高效的时间标记器，并提出了EgoM2P，一个从时序感知的多模态标记中学习的掩码建模框架，用于训练一个用于以自我为中心的4D理解的大规模通用模型。这种统一的设计支持跨各种以自我为中心的感知和合成任务的多任务，包括注视预测、以自我为中心的相机跟踪和从以自我为中心的视频中进行单目深度估计。EgoM2P还作为条件以自我为中心的视频合成的生成模型。在这些任务中，EgoM2P的性能与专业模型相当或更好，同时速度快一个数量级。我们将全面开源EgoM2P以支持社区并推进以自我为中心的视觉研究。项目页面：https://egom2p.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding multimodal signals in egocentric vision, such as RGB video,depth, camera poses, and gaze, is essential for applications in augmentedreality, robotics, and human-computer interaction. These capabilities enablesystems to better interpret the camera wearer's actions, intentions, andsurrounding environment. However, building large-scale egocentric multimodaland multitask models presents unique challenges. Egocentric data are inherentlyheterogeneous, with large variations in modality coverage across devices andsettings. Generating pseudo-labels for missing modalities, such as gaze orhead-mounted camera trajectories, is often infeasible, making standardsupervised learning approaches difficult to scale. Furthermore, dynamic cameramotion and the complex temporal and spatial structure of first-person videopose additional challenges for the direct application of existing multimodalfoundation models.  To address these challenges, we introduce a set of efficient temporaltokenizers and propose EgoM2P, a masked modeling framework that learns fromtemporally aware multimodal tokens to train a large, general-purpose model foregocentric 4D understanding. This unified design supports multitasking acrossdiverse egocentric perception and synthesis tasks, including gaze prediction,egocentric camera tracking, and monocular depth estimation from egocentricvideo. EgoM2P also serves as a generative model for conditional egocentricvideo synthesis. Across these tasks, EgoM2P matches or outperforms specialistmodels while being an order of magnitude faster. We will fully open-sourceEgoM2P to support the community and advance egocentric vision research. Projectpage: https://egom2p.github.io/</description>
      <author>example@mail.com (Gen Li, Yutong Chen, Yiqian Wu, Kaifeng Zhao, Marc Pollefeys, Siyu Tang)</author>
      <guid isPermaLink="false">2506.07886v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Squeeze3D: Your 3D Generation Model is Secretly an Extreme Neural Compressor</title>
      <link>http://arxiv.org/abs/2506.07932v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Squeeze3D是一种新的框架，利用现有预训练的3D生成模型学习到的隐式先验知识，在极高的压缩比下压缩3D数据。&lt;h4&gt;背景&lt;/h4&gt;3D数据的压缩是一个挑战，因为它们通常包含大量的细节。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，能够在不牺牲视觉质量的情况下，以极高的压缩比压缩3D数据。&lt;h4&gt;方法&lt;/h4&gt;Squeeze3D通过可训练的映射网络连接预训练的编码器和生成模型之间的潜在空间。首先，3D模型被预训练的编码器编码，然后转换（即压缩）为高度紧凑的潜在代码。映射网络将压缩的潜在代码转换为强大生成模型的潜在空间，然后条件化以重新创建原始的3D模型（即解压缩）。Squeeze3D完全在生成的合成数据上训练，不需要任何3D数据集。&lt;h4&gt;主要发现&lt;/h4&gt;Squeeze3D在保持视觉质量与许多现有方法相当的同时，实现了高达2187x的纹理网格压缩比，55x的点云压缩比和619x的辐射场压缩比。&lt;h4&gt;结论&lt;/h4&gt;Squeeze3D是一个灵活的框架，可以与现有的预训练3D编码器和生成模型一起使用，支持不同的格式，如网格、点云和辐射场，同时具有较低的压缩和解压缩延迟。&lt;h4&gt;翻译&lt;/h4&gt;我们提出Squeeze3D，一种新颖的框架，它利用现有预训练的3D生成模型学习到的隐式先验知识，在极高的压缩比下压缩3D数据。我们的方法通过可训练的映射网络连接预训练的编码器和预训练的生成模型之间的潜在空间。任何表示为网格、点云或辐射场的3D模型首先由预训练的编码器编码，然后转换为高度紧凑的潜在代码。这个潜在代码可以有效地用作网格或点云的极其压缩的表示。映射网络将压缩的潜在代码转换为强大生成模型的潜在空间，然后条件化以重新创建原始的3D模型（即解压缩）。Squeeze3D完全在生成的合成数据上训练，不需要任何3D数据集。Squeeze3D的架构可以灵活地与现有的预训练3D编码器和现有的生成模型一起使用。它可以灵活地支持不同的格式，包括网格、点云和辐射场。我们的实验表明，Squeeze3D实现了高达2187x的纹理网格压缩比，55x的点云压缩比和619x的辐射场压缩比，同时保持与许多现有方法相当的可视质量。由于Squeeze3D不涉及训练特定于对象的网络来压缩对象，因此它只产生很小的压缩和解压缩延迟。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose Squeeze3D, a novel framework that leverages implicit priorknowledge learnt by existing pre-trained 3D generative models to compress 3Ddata at extremely high compression ratios. Our approach bridges the latentspaces between a pre-trained encoder and a pre-trained generation model throughtrainable mapping networks. Any 3D model represented as a mesh, point cloud, ora radiance field is first encoded by the pre-trained encoder and thentransformed (i.e. compressed) into a highly compact latent code. This latentcode can effectively be used as an extremely compressed representation of themesh or point cloud. A mapping network transforms the compressed latent codeinto the latent space of a powerful generative model, which is then conditionedto recreate the original 3D model (i.e. decompression). Squeeze3D is trainedentirely on generated synthetic data and does not require any 3D datasets. TheSqueeze3D architecture can be flexibly used with existing pre-trained 3Dencoders and existing generative models. It can flexibly support differentformats, including meshes, point clouds, and radiance fields. Our experimentsdemonstrate that Squeeze3D achieves compression ratios of up to 2187x fortextured meshes, 55x for point clouds, and 619x for radiance fields whilemaintaining visual quality comparable to many existing methods. Squeeze3D onlyincurs a small compression and decompression latency since it does not involvetraining object-specific networks to compress an object.</description>
      <author>example@mail.com (Rishit Dagli, Yushi Guan, Sankeerth Durvasula, Mohammadreza Mofayezi, Nandita Vijaykumar)</author>
      <guid isPermaLink="false">2506.07932v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow</title>
      <link>http://arxiv.org/abs/2506.07878v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于事件相机的低延迟运动估计（光流）方法，该方法通过引入时空状态空间模型（STSSM）模块和新型网络架构，实现了高效且性能优异的解决方案。&lt;h4&gt;背景&lt;/h4&gt;传统基于帧的相机在低延迟运动估计方面存在限制，而事件相机可以解锁新的应用领域。尽管深度学习模型如CNN、RNN或ViT在性能上表现出色，但它们通常缺乏所需的计算效率。&lt;h4&gt;目的&lt;/h4&gt;开发一种既高效又具有竞争力的光流估计方法。&lt;h4&gt;方法&lt;/h4&gt;引入了STSSM模块，该模块利用状态空间模型有效地捕捉事件数据中的时空相关性，并提出了一个新的网络架构。&lt;h4&gt;主要发现&lt;/h4&gt;STSSM模块在保持较低复杂性的同时，提供了比ViT和基于CNN的架构更高的性能。该模型在DSEC基准测试中实现了4.5倍的推理速度和8倍的降低计算量，与TMA和EV-FlowNet相比，计算量降低了2倍。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在保持竞争力的同时，显著提高了计算效率。&lt;h4&gt;翻译&lt;/h4&gt;Event cameras unlock new frontiers that were previously unthinkable with standard frame-based cameras. One notable example is low-latency motion estimation (optical flow), which is critical for many real-time applications. In such applications, the computational efficiency of algorithms is paramount. Although recent deep learning paradigms such as CNN, RNN, or ViT have shown remarkable performance, they often lack the desired computational efficiency. Conversely, asynchronous event-based methods including SNNs and GNNs are computationally efficient; however, these approaches fail to capture sufficient spatio-temporal information, a powerful feature required to achieve better performance for optical flow estimation. In this work, we introduce Spatio-Temporal State Space Model (STSSM) module along with a novel network architecture to develop an extremely efficient solution with competitive performance. Our STSSM module leverages state-space models to effectively capture spatio-temporal correlations in event data, offering higher performance with lower complexity compared to ViT, CNN-based architectures in similar settings. Our model achieves 4.5x faster inference and 8x lower computations compared to TMA and 2x lower computations compared to EV-FlowNet with competitive performance on the DSEC benchmark. Our code will be available at https://github.com/AhmedHumais/E-STMFlow&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event cameras unlock new frontiers that were previously unthinkable withstandard frame-based cameras. One notable example is low-latency motionestimation (optical flow), which is critical for many real-time applications.In such applications, the computational efficiency of algorithms is paramount.Although recent deep learning paradigms such as CNN, RNN, or ViT have shownremarkable performance, they often lack the desired computational efficiency.Conversely, asynchronous event-based methods including SNNs and GNNs arecomputationally efficient; however, these approaches fail to capture sufficientspatio-temporal information, a powerful feature required to achieve betterperformance for optical flow estimation. In this work, we introduceSpatio-Temporal State Space Model (STSSM) module along with a novel networkarchitecture to develop an extremely efficient solution with competitiveperformance. Our STSSM module leverages state-space models to effectivelycapture spatio-temporal correlations in event data, offering higher performancewith lower complexity compared to ViT, CNN-based architectures in similarsettings. Our model achieves 4.5x faster inference and 8x lower computationscompared to TMA and 2x lower computations compared to EV-FlowNet withcompetitive performance on the DSEC benchmark. Our code will be available athttps://github.com/AhmedHumais/E-STMFlow</description>
      <author>example@mail.com (Muhammad Ahmed Humais, Xiaoqian Huang, Hussain Sajwani, Sajid Javed, Yahya Zweiri)</author>
      <guid isPermaLink="false">2506.07878v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Design and Evaluation of Deep Learning-Based Dual-Spectrum Image Fusion Methods</title>
      <link>http://arxiv.org/abs/2506.07779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了可见光图像和红外图像融合方法在场景理解，特别是复杂条件下的高级视觉任务中的应用，并提出了一个新的评价框架和数据集。&lt;h4&gt;背景&lt;/h4&gt;可见光图像和红外图像在纹理细节和目标检测上有各自的优势，融合这两种模态可以提高场景理解能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决当前评价方法依赖于通用指标、缺乏标准化基准和下游任务性能的问题，论文提出了一个高质量的校园环境双光谱数据集和一个综合评价框架。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含1369对可见光-红外图像对的校园环境双光谱数据集，提出了一个综合评价框架，该框架结合了融合速度、通用指标和目标检测性能，并在该框架下对比分析了多种融合算法。&lt;h4&gt;主要发现&lt;/h4&gt;融合模型在目标检测任务上表现优异，特别是在低光和遮挡场景下。一些在通用指标上表现良好的算法在下游任务上的表现并不理想，突显了当前评价方法的局限性。&lt;h4&gt;结论&lt;/h4&gt;论文的主要贡献包括：一个面向校园环境且包含多样化、挑战性场景的双光谱数据集；一个任务感知的综合评价框架；以及对多种数据集上领先融合方法的全面比较分析，为未来的发展提供了洞见。&lt;h4&gt;翻译&lt;/h4&gt;The abstract summarizes a study on the application of visible and infrared image fusion methods in scene understanding, especially for advanced vision tasks under challenging conditions, and proposes a new evaluation framework and dataset.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visible images offer rich texture details, while infrared images emphasizesalient targets. Fusing these complementary modalities enhances sceneunderstanding, particularly for advanced vision tasks under challengingconditions. Recently, deep learning-based fusion methods have gained attention,but current evaluations primarily rely on general-purpose metrics withoutstandardized benchmarks or downstream task performance. Additionally, the lackof well-developed dual-spectrum datasets and fair algorithm comparisons hindersprogress.  To address these gaps, we construct a high-quality dual-spectrum datasetcaptured in campus environments, comprising 1,369 well-aligned visible-infraredimage pairs across four representative scenarios: daytime, nighttime, smokeocclusion, and underpasses. We also propose a comprehensive and fair evaluationframework that integrates fusion speed, general metrics, and object detectionperformance using the lang-segment-anything model to ensure fairness indownstream evaluation.  Extensive experiments benchmark several state-of-the-art fusion algorithmsunder this framework. Results demonstrate that fusion models optimized fordownstream tasks achieve superior performance in target detection, especiallyin low-light and occluded scenes. Notably, some algorithms that perform well ongeneral metrics do not translate to strong downstream performance, highlightinglimitations of current evaluation practices and validating the necessity of ourproposed framework.  The main contributions of this work are: (1)a campus-oriented dual-spectrumdataset with diverse and challenging scenes; (2) a task-aware, comprehensiveevaluation framework; and (3) thorough comparative analysis of leading fusionmethods across multiple datasets, offering insights for future development.</description>
      <author>example@mail.com (Beining Xu, Junxian Li)</author>
      <guid isPermaLink="false">2506.07779v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Egocentric Event-Based Vision for Ping Pong Ball Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2506.07860v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE/CVF Conference on Computer Vision and Pattern Recognition  Workshops (CVPRW), Nashville (TN), USA, 2025; 5th International Workshop on  Event-Based Vision&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用事件摄像头进行实时乒乓球轨迹预测的系统。&lt;h4&gt;背景&lt;/h4&gt;与传统摄像头相比，事件摄像头在高速度运动场景中具有更高的时间分辨率，可以提供更频繁的状态更新，更强的鲁棒性以及对异常值的处理能力。&lt;h4&gt;目的&lt;/h4&gt;旨在通过事件摄像头预测乒乓球轨迹，实现3D轨迹预测。&lt;h4&gt;方法&lt;/h4&gt;收集了乒乓球比赛序列数据集，包括球的三维真实轨迹、与Meta Project Aria眼镜传感器数据同步的事件流。系统利用水平视野，利用眼镜的注视数据只处理观察者视野中央的事件，以减少计算延迟。检测管道具有最坏情况下的总延迟为4.5毫秒，包括计算和感知。&lt;h4&gt;主要发现&lt;/h4&gt;系统在收集的轨迹上实现了10.81的降低因子，检测管道的最坏情况总延迟为4.5毫秒，远低于基于帧的30 FPS系统。&lt;h4&gt;结论&lt;/h4&gt;本研究首次提出了一种使用事件摄像头从自视角预测乒乓球轨迹的方法。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we present a real-time egocentric trajectory prediction system for table tennis using event cameras. Unlike standard cameras, which suffer from high latency and motion blur at fast ball speeds, event cameras provide higher temporal resolution, allowing more frequent state updates, greater robustness to outliers, and accurate trajectory predictions using just a short time window after the opponent's impact. We collect a dataset of ping-pong game sequences, including 3D ground-truth trajectories of the ball, synchronized with sensor data from the Meta Project Aria glasses and event streams. Oursystem leverages foveated vision, using eye-gaze data from the glasses to process only events in the viewer's fovea. This biologically inspired approach improves ball detection performance and significantly reduces computational latency, as it efficiently allocates resources to the most perceptually relevant regions, achieving a reduction factor of 10.81 on the collected trajectories. Our detection pipeline has a worst-case total latency of 4.5 ms, including computation and perception - significantly lower than a frame-based 30 FPS system, which, in the worst case, takes 66 ms solely for perception. Finally, we fit a trajectory prediction model to the estimated states of the ball, enabling 3D trajectory forecasting in the future. To the best of our knowledge, this is the first approach to predict table tennis trajectories from an egocentric perspective using event cameras.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present a real-time egocentric trajectory prediction systemfor table tennis using event cameras. Unlike standard cameras, which sufferfrom high latency and motion blur at fast ball speeds, event cameras providehigher temporal resolution, allowing more frequent state updates, greaterrobustness to outliers, and accurate trajectory predictions using just a shorttime window after the opponent's impact. We collect a dataset of ping-pong gamesequences, including 3D ground-truth trajectories of the ball, synchronizedwith sensor data from the Meta Project Aria glasses and event streams. Oursystem leverages foveated vision, using eye-gaze data from the glasses toprocess only events in the viewer's fovea. This biologically inspired approachimproves ball detection performance and significantly reduces computationallatency, as it efficiently allocates resources to the most perceptuallyrelevant regions, achieving a reduction factor of 10.81 on the collectedtrajectories. Our detection pipeline has a worst-case total latency of 4.5 ms,including computation and perception - significantly lower than a frame-based30 FPS system, which, in the worst case, takes 66 ms solely for perception.Finally, we fit a trajectory prediction model to the estimated states of theball, enabling 3D trajectory forecasting in the future. To the best of ourknowledge, this is the first approach to predict table tennis trajectories froman egocentric perspective using event cameras.</description>
      <author>example@mail.com (Ivan Alberico, Marco Cannici, Giovanni Cioffi, Davide Scaramuzza)</author>
      <guid isPermaLink="false">2506.07860v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>OpenSplat3D: Open-Vocabulary 3D Instance Segmentation using Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.07697v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为OpenSplat3D的3D实例分割方法，它扩展了3D Gaussian Splatting在场景表示之外的能力，并通过自然语言描述在3D场景中识别和分割任意对象。&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting（3DGS）已成为神经场景重建的有力表示，它提供了高质量的全新视图合成，同时保持计算效率。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需手动标注的开放词汇3D实例分割方法，以扩展3DGS的应用范围。&lt;h4&gt;方法&lt;/h4&gt;方法利用特征splatting技术将语义信息与单个高斯函数关联，并采用Segment Anything Model实例掩码和对比损失公式作为实例特征的指导，同时利用视觉-语言模型的语言嵌入实现灵活的文本驱动实例识别。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在LERF-mask、LERF-OVS以及完整的ScanNet++验证集上展示了有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够根据自然语言描述识别和分割3D场景中的任意对象，证明了其在3D实例分割方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) has emerged as a powerful representation forneural scene reconstruction, offering high-quality novel view synthesis whilemaintaining computational efficiency. In this paper, we extend the capabilitiesof 3DGS beyond pure scene representation by introducing an approach foropen-vocabulary 3D instance segmentation without requiring manual labeling,termed OpenSplat3D. Our method leverages feature-splatting techniques toassociate semantic information with individual Gaussians, enabling fine-grainedscene understanding. We incorporate Segment Anything Model instance masks witha contrastive loss formulation as guidance for the instance features to achieveaccurate instance-level segmentation. Furthermore, we utilize languageembeddings of a vision-language model, allowing for flexible, text-driveninstance identification. This combination enables our system to identify andsegment arbitrary objects in 3D scenes based on natural language descriptions.We show results on LERF-mask and LERF-OVS as well as the full ScanNet++validation set, demonstrating the effectiveness of our approach.</description>
      <author>example@mail.com (Jens Piekenbrinck, Christian Schmidt, Alexander Hermans, Narunas Vaskevicius, Timm Linder, Bastian Leibe)</author>
      <guid isPermaLink="false">2506.07697v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Ambiguity-Restrained Text-Video Representation Learning for Partially Relevant Video Retrieval</title>
      <link>http://arxiv.org/abs/2506.07471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PRVR的部分相关视频检索方法，旨在从视频库中检索出与给定文本查询相关的特定片段。&lt;h4&gt;背景&lt;/h4&gt;传统的PRVR训练过程假设文本查询与视频之间存在一对一的关系，但作者指出文本和视频内容之间存在固有的模糊性。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，将这种模糊性纳入模型学习过程中。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为ARL的模糊性受限表示学习（Ambiguity-Restrained representation Learning）的方法，用于处理模糊的文本-视频对。ARL首先基于不确定性和相似性两个标准检测模糊对，然后通过多正对比学习和双重三元组损失来分层学习语义关系。此外，ARL还深入研究了视频实例中的细粒度关系，并提出了跨模型模糊性检测来减轻错误传播。&lt;h4&gt;主要发现&lt;/h4&gt;ARL能够有效地处理文本-视频对中的模糊性，并通过多层次的学习增强了文本-帧级别的学习。&lt;h4&gt;结论&lt;/h4&gt;该方法在PRVR中表现出良好的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：部分相关视频检索（PRVR）旨在检索与给定文本查询相关的特定片段的视频。典型的PRVR训练过程假设每个文本查询只与一个视频相关，但作者指出基于概念范围，文本和视频内容之间存在固有的模糊性。基于此，作者提出了一种将这种模糊性纳入模型学习过程的框架。具体来说，作者提出了模糊性受限表示学习（ARL）来解决模糊的文本-视频对。最初，ARL基于不确定性和相似性两个标准检测模糊对。不确定性表示实例是否包含数据集中常见共享的上下文，而相似性表示成对语义重叠。然后，通过检测到的模糊对，ARL通过多正对比学习和双重三元组损失分层学习语义关系。此外，ARL还深入研究了视频实例中的细粒度关系。与典型的在文本-视频级别的训练不同，在提供成对信息时，ARL解决了同一未剪辑视频中帧之间的固有模糊性，这些帧通常包含多个上下文。这使得我们能够在文本-帧级别进一步增强学习。最后，作者提出了跨模型模糊性检测来减轻当使用单个模型检测用于其训练的模糊对时发生的错误传播。结合所有组件，作者提出的方法在PRVR中证明了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Partially Relevant Video Retrieval~(PRVR) aims to retrieve a video where aspecific segment is relevant to a given text query. Typical training processesof PRVR assume a one-to-one relationship where each text query is relevant toonly one video. However, we point out the inherent ambiguity between text andvideo content based on their conceptual scope and propose a framework thatincorporates this ambiguity into the model learning process. Specifically, wepropose Ambiguity-Restrained representation Learning~(ARL) to address ambiguoustext-video pairs. Initially, ARL detects ambiguous pairs based on two criteria:uncertainty and similarity. Uncertainty represents whether instances includecommonly shared context across the dataset, while similarity indicatespair-wise semantic overlap. Then, with the detected ambiguous pairs, our ARLhierarchically learns the semantic relationship via multi-positive contrastivelearning and dual triplet margin loss. Additionally, we delve into fine-grainedrelationships within the video instances. Unlike typical training at thetext-video level, where pairwise information is provided, we address theinherent ambiguity within frames of the same untrimmed video, which oftencontains multiple contexts. This allows us to further enhance learning at thetext-frame level. Lastly, we propose cross-model ambiguity detection tomitigate the error propagation that occurs when a single model is employed todetect ambiguous pairs for its training. With all components combined, ourproposed method demonstrates its effectiveness in PRVR.</description>
      <author>example@mail.com (CH Cho, WJ Moon, W Jun, MS Jung, JP Heo)</author>
      <guid isPermaLink="false">2506.07471v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SpikeSMOKE: Spiking Neural Networks for Monocular 3D Object Detection with Cross-Scale Gated Coding</title>
      <link>http://arxiv.org/abs/2506.07737v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种低功耗的3D物体检测方法，通过使用脉冲神经网络（SNNs）和改进的SpikeSMOKE架构，实现了在减少能耗的同时保持较高的检测性能。&lt;h4&gt;背景&lt;/h4&gt;随着3D物体检测在自动驾驶等领域的广泛应用，其能耗问题日益突出，因此降低能耗成为研究的重要方向。&lt;h4&gt;目的&lt;/h4&gt;设计一种低功耗的3D物体检测方法，以应对自动驾驶等应用场景中的能耗挑战。&lt;h4&gt;方法&lt;/h4&gt;1. 应用SNNs进行单目3D物体检测；2. 提出SpikeSMOKE架构；3. 设计交叉尺度门控编码机制（CSGC）以增强特征表示能力；4. 提出轻量级残差块以减少计算量和提高训练速度。&lt;h4&gt;主要发现&lt;/h4&gt;与基准SpikeSMOKE相比，改进的SpikeSMOKE在KITTI自动驾驶数据集上实现了更高的检测性能，同时在能耗上降低了72.2%，而检测性能仅降低了4%。SpikeSMOKE-L进一步减少了参数量和计算量。&lt;h4&gt;结论&lt;/h4&gt;SNNs在3D物体检测中具有降低能耗的潜力，通过改进的架构和机制可以同时提升检测性能和降低能耗。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low energy consumption for 3D object detection is an important research areabecause of the increasing energy consumption with their wide application infields such as autonomous driving. The spiking neural networks (SNNs) withlow-power consumption characteristics can provide a novel solution for thisresearch. Therefore, we apply SNNs to monocular 3D object detection and proposethe SpikeSMOKE architecture in this paper, which is a new attempt for low-powermonocular 3D object detection. As we all know, discrete signals of SNNs willgenerate information loss and limit their feature expression ability comparedwith the artificial neural networks (ANNs).In order to address this issue,inspired by the filtering mechanism of biological neuronal synapses, we proposea cross-scale gated coding mechanism(CSGC), which can enhance featurerepresentation by combining cross-scale fusion of attentional methods and gatedfiltering mechanisms.In addition, to reduce the computation and increase thespeed of training, we present a novel light-weight residual block that canmaintain spiking computing paradigm and the highest possible detectionperformance. Compared to the baseline SpikeSMOKE under the 3D Object Detection,the proposed SpikeSMOKE with CSGC can achieve 11.78 (+2.82, Easy), 10.69 (+3.2,Moderate), and 10.48 (+3.17, Hard) on the KITTI autonomous driving dataset byAP|R11 at 0.7 IoU threshold, respectively. It is important to note that theresults of SpikeSMOKE can significantly reduce energy consumption compared tothe results on SMOKE. For example,the energy consumption can be reduced by72.2% on the hard category, while the detection performance is reduced by only4%. SpikeSMOKE-L (lightweight) can further reduce the amount of parameters by 3times and computation by 10 times compared to SMOKE.</description>
      <author>example@mail.com (Xuemei Chen, Huamin Wang, Hangchi Shen, Shukai Duan, Shiping Wen, Tingwen Huang)</author>
      <guid isPermaLink="false">2506.07737v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning</title>
      <link>http://arxiv.org/abs/2506.07619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了用于产量预测的全新数据集，这是首个用于机器学习基准测试的瞬态流动数据集，涵盖了1200多种工艺条件。数据集的构建克服了化学数据集通常难以获取的难题，并针对溶剂选择这一理论建模困难的任务，展示了回归算法、迁移学习、特征工程和主动学习在其中的应用。&lt;h4&gt;背景&lt;/h4&gt;机器学习在分子性质预测和反应逆合成中取得了显著成果，但化学数据集往往难以获得，因为它们需要数据清洗、对化学的深入了解，或者根本不可用。&lt;h4&gt;目的&lt;/h4&gt;提出一个用于产量预测的新数据集，为机器学习模型提供基准测试，并探索溶剂选择等任务。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含超过1200种工艺条件的瞬态流动数据集，通过实验设置采样大量连续工艺条件，以应对机器学习模型的新挑战。&lt;h4&gt;主要发现&lt;/h4&gt;数据集涵盖了溶剂选择等难以理论建模的任务，并展示了回归算法、迁移学习、特征工程和主动学习在其中的应用。&lt;h4&gt;结论&lt;/h4&gt;本文提出的数据集和机器学习应用为溶剂替代和可持续制造提供了重要应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：机器学习承诺要改变实验室化学的格局，在分子性质预测和反应逆合成方面取得了令人印象深刻的成果。然而，化学数据集通常难以获得，因为它们往往需要清洗、对化学的深入了解，或者根本不可用。在本文中，我们介绍了一个用于产量预测的新数据集，提供了首个用于机器学习基准测试的瞬态流动数据集，涵盖了1200多种工艺条件。虽然之前的数据库侧重于离散参数，但我们的实验设置使我们能够采样大量连续工艺条件，为机器学习模型带来了新的挑战。我们专注于溶剂选择，这是一个特别难以理论建模的任务，因此非常适合机器学习应用。我们展示了回归算法、迁移学习、特征工程和主动学习的基准测试，这些在溶剂替代和可持续制造方面有重要的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning has promised to change the landscape of laboratorychemistry, with impressive results in molecular property prediction andreaction retro-synthesis. However, chemical datasets are often inaccessible tothe machine learning community as they tend to require cleaning, thoroughunderstanding of the chemistry, or are simply not available. In this paper, weintroduce a novel dataset for yield prediction, providing the first-evertransient flow dataset for machine learning benchmarking, covering over 1200process conditions. While previous datasets focus on discrete parameters, ourexperimental set-up allow us to sample a large number of continuous processconditions, generating new challenges for machine learning models. We focus onsolvent selection, a task that is particularly difficult to model theoreticallyand therefore ripe for machine learning applications. We showcase benchmarkingfor regression algorithms, transfer-learning approaches, feature engineering,and active learning, with important applications towards solvent replacementand sustainable manufacturing.</description>
      <author>example@mail.com (Toby Boyne, Juan S. Campos, Becky D. Langdon, Jixiang Qing, Yilin Xie, Shiqiang Zhang, Calvin Tsay, Ruth Misener, Daniel W. Davies, Kim E. Jelfs, Sarah Boyall, Thomas M. Dixon, Linden Schrecker, Jose Pablo Folch)</author>
      <guid isPermaLink="false">2506.07619v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SurgBench: A Unified Large-Scale Benchmark for Surgical Video Analysis</title>
      <link>http://arxiv.org/abs/2506.07603v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SurgBench，一个统一的手术视频基准框架，包括预训练数据集SurgBench-P和评估基准SurgBench-E，旨在解决手术视频理解领域的数据稀缺问题。&lt;h4&gt;背景&lt;/h4&gt;手术视频理解对于实现自动化手术决策、技能评估和术后质量提升至关重要，但发展手术视频基础模型（FMs）受到大规模、多样化数据集缺乏的阻碍。&lt;h4&gt;目的&lt;/h4&gt;提出SurgBench框架，以解决手术视频理解领域的数据稀缺问题，并提高手术视频分析任务的性能。&lt;h4&gt;方法&lt;/h4&gt;构建了SurgBench-P预训练数据集和SurgBench-E评估基准，其中SurgBench-P包含22种手术程序和11个专业的5300万帧图像，SurgBench-E提供涵盖6个类别、72个细粒度任务的稳健评估。&lt;h4&gt;主要发现&lt;/h4&gt;现有视频FMs难以泛化到不同的手术视频分析任务，而基于SurgBench-P的预训练则显著提高了性能，并实现了对未见过的手术程序和模态的优越跨领域泛化。&lt;h4&gt;结论&lt;/h4&gt;SurgBench框架为手术视频理解领域提供了重要的数据资源和评估基准，有助于推动该领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：手术视频理解对于实现自动化手术决策、技能评估和术后质量提升至关重要。然而，开发手术视频基础模型（FMs）的进展受到大规模、多样化数据集缺乏的阻碍。在本文中，我们引入了SurgBench，这是一个统一的手术视频基准框架，包括预训练数据集SurgBench-P和评估基准SurgBench-E。SurgBench提供了对多样化手术场景的广泛覆盖，其中SurgBench-P包含22种手术程序和11个专业的5300万帧图像，SurgBench-E提供了涵盖6个类别、72个细粒度任务的稳健评估。广泛的实验表明，现有的视频FMs难以泛化到不同的手术视频分析任务，而基于SurgBench-P的预训练则显著提高了性能，并实现了对未见过的手术程序和模态的优越跨领域泛化。我们的数据集和代码可根据请求提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surgical video understanding is pivotal for enabling automated intraoperativedecision-making, skill assessment, and postoperative quality improvement.However, progress in developing surgical video foundation models (FMs) remainshindered by the scarcity of large-scale, diverse datasets for pretraining andsystematic evaluation. In this paper, we introduce \textbf{SurgBench}, aunified surgical video benchmarking framework comprising a pretraining dataset,\textbf{SurgBench-P}, and an evaluation benchmark, \textbf{SurgBench-E}.SurgBench offers extensive coverage of diverse surgical scenarios, withSurgBench-P encompassing 53 million frames across 22 surgical procedures and 11specialties, and SurgBench-E providing robust evaluation across six categories(phase classification, camera motion, tool recognition, disease diagnosis,action classification, and organ detection) spanning 72 fine-grained tasks.Extensive experiments reveal that existing video FMs struggle to generalizeacross varied surgical video analysis tasks, whereas pretraining on SurgBench-Pyields substantial performance improvements and superior cross-domaingeneralization to unseen procedures and modalities. Our dataset and code areavailable upon request.</description>
      <author>example@mail.com (Jianhui Wei, Zikai Xiao, Danyu Sun, Luqi Gong, Zongxin Yang, Zuozhu Liu, Jian Wu)</author>
      <guid isPermaLink="false">2506.07603v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds</title>
      <link>http://arxiv.org/abs/2506.07857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025. Code and data are available at:  https://github.com/vLAR-group/LogoSP&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了无监督3D语义分割问题，通过LogoSP方法从局部和全局点云特征中学习3D语义信息，实现了高度准确的语义伪标签生成，并在室内和室外数据集上取得了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的无监督3D语义分割方法通常通过学习每个点的局部特征和简单的分组策略来解决问题，但缺乏发现超出局部特征的额外语义先验的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为LogoSP的方法，用于从原始点云数据中无监督地学习3D语义信息。&lt;h4&gt;方法&lt;/h4&gt;LogoSP通过根据超点在频域中的全局模式进行分组来发现3D语义信息，从而生成用于训练分割网络的语义伪标签。&lt;h4&gt;主要发现&lt;/h4&gt;LogoSP在室内和室外数据集上超越了所有现有的无监督方法，实现了最先进的无监督3D语义分割性能。研究发现，所学习的全局模式真正代表了在训练过程中没有人类标签时的有意义3D语义。&lt;h4&gt;结论&lt;/h4&gt;LogoSP是一种有效的无监督3D语义分割方法，能够从无标签的原始点云数据中学习到有意义的3D语义信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the problem of unsupervised 3D semantic segmentation on raw pointclouds without needing human labels in training. Existing methods usuallyformulate this problem into learning per-point local features followed by asimple grouping strategy, lacking the ability to discover additional andpossibly richer semantic priors beyond local features. In this paper, weintroduce LogoSP to learn 3D semantics from both local and global pointfeatures. The key to our approach is to discover 3D semantic information bygrouping superpoints according to their global patterns in the frequencydomain, thus generating highly accurate semantic pseudo-labels for training asegmentation network. Extensive experiments on two indoor and an outdoordatasets show that our LogoSP surpasses all existing unsupervised methods bylarge margins, achieving the state-of-the-art performance for unsupervised 3Dsemantic segmentation. Notably, our investigation into the learned globalpatterns reveals that they truly represent meaningful 3D semantics in theabsence of human labels during training.</description>
      <author>example@mail.com (Zihui Zhang, Weisheng Dai, Hongtao Wen, Bo Yang)</author>
      <guid isPermaLink="false">2506.07857v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Residual Reweighted Conformal Prediction for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.07854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Residual Reweighted GNN (RR-GNN)，一种能够生成具有可证明边缘覆盖保证的最小预测集的框架，旨在解决高价值领域中图神经网络（GNNs）的不确定性量化问题。&lt;h4&gt;背景&lt;/h4&gt;尽管GNNs在建模关系数据方面表现出色，但在高价值领域中，由于未量化的不确定性，它们面临重大挑战。现有的符合性预测（CP）方法虽然提供统计覆盖保证，但通常产生过于保守的预测区间，无法考虑图异方差性和结构偏差。现有的残差重加权CP变体虽然解决了一些局限性，但忽略了图拓扑、特定集群的不确定性和通过重用训练集的风险数据泄露。&lt;h4&gt;目的&lt;/h4&gt;提出RR-GNN以解决上述问题，旨在提高预测性能，同时保持统计覆盖。&lt;h4&gt;方法&lt;/h4&gt;RR-GNN引入了三项主要创新：首先，使用图结构莫迪安CP将节点或边根据拓扑特征划分为社区，确保集群条件覆盖反映异质性；其次，使用残差自适应非一致性分数，通过在保留的校准集上训练次级GNN来估计特定任务的残差，动态调整预测区间；第三，采用交叉训练协议，交替优化主GNN和残差预测器，以防止信息泄露同时保持图依赖。&lt;h4&gt;主要发现&lt;/h4&gt;在包括节点分类、回归和边权重预测在内的15个真实世界图上的多样任务中验证了RR-GNN，与CP基线相比，RR-GNN在效率上优于最先进的方法，没有覆盖损失。&lt;h4&gt;结论&lt;/h4&gt;RR-GNN通过提供更精确的预测和避免信息泄露，为高价值领域中的GNNs应用提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) excel at modeling relational data but facesignificant challenges in high-stakes domains due to unquantified uncertainty.Conformal prediction (CP) offers statistical coverage guarantees, but existingmethods often produce overly conservative prediction intervals that fail toaccount for graph heteroscedasticity and structural biases. While residualreweighting CP variants address some of these limitations, they neglect graphtopology, cluster-specific uncertainties, and risk data leakage by reusingtraining sets. To address these issues, we propose Residual Reweighted GNN(RR-GNN), a framework designed to generate minimal prediction sets withprovable marginal coverage guarantees.  RR-GNN introduces three major innovations to enhance prediction performance.First, it employs Graph-Structured Mondrian CP to partition nodes or edges intocommunities based on topological features, ensuring cluster-conditionalcoverage that reflects heterogeneity. Second, it uses Residual-AdaptiveNonconformity Scores by training a secondary GNN on a held-out calibration setto estimate task-specific residuals, dynamically adjusting prediction intervalsaccording to node or edge uncertainty. Third, it adopts a Cross-TrainingProtocol, which alternates the optimization of the primary GNN and the residualpredictor to prevent information leakage while maintaining graph dependencies.We validate RR-GNN on 15 real-world graphs across diverse tasks, including nodeclassification, regression, and edge weight prediction. Compared to CPbaselines, RR-GNN achieves improved efficiency over state-of-the-art methods,with no loss of coverage.</description>
      <author>example@mail.com (Zheng Zhang, Jie Bao, Zhixin Zhou, Nicolo Colombo, Lixin Cheng, Rui Luo)</author>
      <guid isPermaLink="false">2506.07854v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Language-Vision Planner and Executor for Text-to-Visual Reasoning</title>
      <link>http://arxiv.org/abs/2506.07778v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VLAgent是一个AI系统，能够通过自动化过程创建易于理解的视觉推理计划，并实时执行每一步。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型和大型视觉模型的发展推动了多模态视觉-文本推理能力的快速进步，但现有的视觉语言模型（VLMs）存在泛化性能问题。&lt;h4&gt;目的&lt;/h4&gt;提出VLAgent，以提高视觉-文本推理的泛化性能。&lt;h4&gt;方法&lt;/h4&gt;VLAgent通过上下文学习微调LLM生成每项文本-视觉推理任务的逐步计划；在执行计划时，通过神经符号执行模块的逐步优化生成高置信度的推理结果。&lt;h4&gt;主要发现&lt;/h4&gt;VLAgent有三个独特的设计特点：通过上下文学习提高计划生成质量；设计语法-语义解析器来识别和纠正LLM生成的计划脚本中的逻辑错误；使用集成方法提高步执行器的泛化性能。&lt;h4&gt;结论&lt;/h4&gt;在四个视觉推理基准测试（GQA、MME、NLVR2、VQAv2）中，VLAgent相较于现有的VLMs和基于LLM的视觉组合方法（如ViperGPT和VisProg）实现了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;The advancement in large language models (LLMs) and large vision models has fueled the rapid progress in multi-modal visual-text reasoning capabilities. However, existing vision-language models (VLMs) to date suffer from generalization performance. Inspired by recent development in LLMs for visual reasoning, this paper presents VLAgent, an AI system that can create a step-by-step visual reasoning plan with an easy-to-understand script and execute each step of the plan in real time by integrating planning script with execution verifications via an automated process supported by VLAgent. In the task planning phase, VLAgent fine-tunes an LLM through in-context learning to generate a step-by-step planner for each user-submitted text-visual reasoning task. During the plan execution phase, VLAgent progressively refines the composition of neuro-symbolic executable modules to generate high-confidence reasoning results. VLAgent has three unique design characteristics: First, we improve the quality of plan generation through in-context learning, improving logic reasoning by reducing erroneous logic steps, incorrect programs, and LLM hallucinations. Second, we design a syntax-semantics parser to identify and correct additional logic errors of the LLM-generated planning script prior to launching the plan executor. Finally, we employ the ensemble method to improve the generalization performance of our step-executor. Extensive experiments with four visual reasoning benchmarks (GQA, MME, NLVR2, VQAv2) show that VLAgent achieves significant performance enhancement for multimodal text-visual reasoning applications, compared to the existing representative VLMs and LLM-based visual composition approaches like ViperGPT and VisProg, thanks to the novel optimization modules of VLAgent back-engine (SS-Parser, Plan Repairer, Output Verifiers). Code and data will be made available upon paper acceptance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advancement in large language models (LLMs) and large vision models hasfueled the rapid progress in multi-modal visual-text reasoning capabilities.However, existing vision-language models (VLMs) to date suffer fromgeneralization performance. Inspired by recent development in LLMs for visualreasoning, this paper presents VLAgent, an AI system that can create astep-by-step visual reasoning plan with an easy-to-understand script andexecute each step of the plan in real time by integrating planning script withexecution verifications via an automated process supported by VLAgent. In thetask planning phase, VLAgent fine-tunes an LLM through in-context learning togenerate a step-by-step planner for each user-submitted text-visual reasoningtask. During the plan execution phase, VLAgent progressively refines thecomposition of neuro-symbolic executable modules to generate high-confidencereasoning results. VLAgent has three unique design characteristics: First, weimprove the quality of plan generation through in-context learning, improvinglogic reasoning by reducing erroneous logic steps, incorrect programs, and LLMhallucinations. Second, we design a syntax-semantics parser to identify andcorrect additional logic errors of the LLM-generated planning script prior tolaunching the plan executor. Finally, we employ the ensemble method to improvethe generalization performance of our step-executor. Extensive experiments withfour visual reasoning benchmarks (GQA, MME, NLVR2, VQAv2) show that VLAgentachieves significant performance enhancement for multimodal text-visualreasoning applications, compared to the exiting representative VLMs and LLMbased visual composition approaches like ViperGPT and VisProg, thanks to thenovel optimization modules of VLAgent back-engine (SS-Parser, Plan Repairer,Output Verifiers). Code and data will be made available upon paper acceptance.</description>
      <author>example@mail.com (Yichang Xu, Gaowen Liu, Ramana Rao Kompella, Sihao Hu, Tiansheng Huang, Fatih Ilhan, Selim Furkan Tekin, Zachary Yahn, Ling Liu)</author>
      <guid isPermaLink="false">2506.07778v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Evidential Spectrum-Aware Contrastive Learning for OOD Detection in Dynamic Graphs</title>
      <link>http://arxiv.org/abs/2506.07417v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages,5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了动态图中的Out-of-distribution (OOD)检测问题，提出了一种基于证据深度学习（EDL）的OOD检测方法EviSEC，通过证据谱增强对比学习来提高OOD检测的准确性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;在安全敏感领域，动态图中的OOD检测变得尤为重要，但现有的OOD检测方法主要针对静态图，存在单点估计引起的偏差和方差较大，以及缺乏OOD训练数据导致的评分同质化等问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的OOD检测方法，旨在提高动态图中OOD检测的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;首先，通过证据深度学习的视角研究动态图中的OOD检测。具体地，提出EviSEC，通过证据谱增强对比学习来设计一个证据神经网络，并引入谱域增强模块生成OOD近似，以识别具有高OOD评分的模式。&lt;h4&gt;主要发现&lt;/h4&gt;EviSEC通过重新定义输出为后验Dirichlet分布，解释了输入的随机性，并能够生成具有高OOD评分的OOD近似，从而扩大ID和OOD数据之间的评分差距，缓解评分同质化问题。&lt;h4&gt;结论&lt;/h4&gt;在真实世界数据集上的实验表明，EviSEC能够有效地检测动态图中的OOD样本。&lt;h4&gt;翻译&lt;/h4&gt;Recently, Out-of-distribution (OOD) detection in dynamic graphs, which aims to identify whether incoming data deviates from the distribution of the in-distribution (ID) training set, has garnered considerable attention in security-sensitive fields. Current OOD detection paradigms primarily focus on static graphs and confront two critical challenges: i) high bias and high variance caused by single-point estimation, which makes the predictions sensitive to randomness in the data; ii) score homogenization resulting from the lack of OOD training data, where the model only learns ID-specific patterns, resulting in overall low OOD scores and a narrow score gap between ID and OOD data. To tackle these issues, we first investigate OOD detection in dynamic graphs through the lens of Evidential Deep Learning (EDL). Specifically, we propose EviSEC, an innovative and effective OOD detector via Evidential Spectrum-awarE Contrastive Learning. We design an evidential neural network to redefine the output as the posterior Dirichlet distribution, explaining the randomness of inputs through the uncertainty of distribution, which is overlooked by single-point estimation. Moreover, spectrum-areaugmentation module generates OOD approximations to identify patterns with high OOD scores, thereby widening the score gap between ID and OOD data and mitigating score homogenization. Extensive experiments on real-world datasets demonstrate that EviSAC effectively detects OOD samples in dynamic graphs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Out-of-distribution (OOD) detection in dynamic graphs, which aimsto identify whether incoming data deviates from the distribution of thein-distribution (ID) training set, has garnered considerable attention insecurity-sensitive fields. Current OOD detection paradigms primarily focus onstatic graphs and confront two critical challenges: i) high bias and highvariance caused by single-point estimation, which makes the predictionssensitive to randomness in the data; ii) score homogenization resulting fromthe lack of OOD training data, where the model only learns ID-specificpatterns, resulting in overall low OOD scores and a narrow score gap between IDand OOD data. To tackle these issues, we first investigate OOD detection indynamic graphs through the lens of Evidential Deep Learning (EDL).Specifically, we propose EviSEC, an innovative and effective OOD detector viaEvidential Spectrum-awarE Contrastive Learning. We design an evidential neuralnetwork to redefine the output as the posterior Dirichlet distribution,explaining the randomness of inputs through the uncertainty of distribution,which is overlooked by single-point estimation. Moreover, spectrum-awareaugmentation module generates OOD approximations to identify patterns with highOOD scores, thereby widening the score gap between ID and OOD data andmitigating score homogenization. Extensive experiments on real-world datasetsdemonstrate that EviSAC effectively detects OOD samples in dynamic graphs.</description>
      <author>example@mail.com (Nan Sun, Xixun Lin, Zhiheng Zhou, Yanmin Shang, Zhenlin Cheng, Yanan Cao)</author>
      <guid isPermaLink="false">2506.07417v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Flow-Anything: Learning Real-World Optical Flow Estimation from Large-Scale Single-view Images</title>
      <link>http://arxiv.org/abs/2506.07740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Flow-Anything的大规模数据生成框架，用于从现实世界的单视图图像中学习光流估计，旨在解决现实应用中的域差距和数据扩展限制。&lt;h4&gt;背景&lt;/h4&gt;光流估计是计算机视觉的一个关键子领域，但在实际应用中，由动画合成数据集训练的鲁棒性有限。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出Flow-Anything框架，旨在从现实世界的单视图图像中学习光流估计。&lt;h4&gt;方法&lt;/h4&gt;Flow-Anything框架采用两个有效步骤来促进数据扩展：第一步是将单视图图像转换为3D表示，第二步是开发一个对象无关的体积渲染模块和一个深度感知修复模块来模拟3D表示中的动态对象。&lt;h4&gt;主要发现&lt;/h4&gt;首次证明了从大规模现实世界图像生成光流训练数据的优势，在合成数据集上优于最先进的无监督方法和监督方法。&lt;h4&gt;结论&lt;/h4&gt;Flow-Anything模型作为基础模型，增强了各种下游视频任务的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：光流估计是计算机视觉的一个关键子领域，它是视频任务的基础。然而，由于训练数据集的合成动画性质，其实际应用的鲁棒性有限。这引入了当应用于现实世界应用时的域差距，并限制了数据扩展带来的好处。为了解决这些挑战，我们提出了Flow-Anything，这是一个大规模数据生成框架，旨在从现实世界的任何单视图图像中学习光流估计。我们采用两个有效步骤来使数据扩展变得可行。首先，我们使用先进的单目深度估计网络将单视图图像转换为3D表示。这使我们能够在虚拟摄像机下渲染光流和新的视图图像。其次，我们开发了一个对象无关的体积渲染模块和一个深度感知修复模块来模拟3D表示中的动态对象。这两个步骤使我们能够从大规模的单视图图像中生成用于训练的逼真数据集，即FA-Flow数据集。首次，我们证明了从大规模现实世界图像生成光流训练数据的优势，在合成数据集上优于最先进的无监督方法和监督方法。此外，我们的模型作为基础模型，增强了各种下游视频任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optical flow estimation is a crucial subfield of computer vision, serving asa foundation for video tasks. However, the real-world robustness is limited byanimated synthetic datasets for training. This introduces domain gaps whenapplied to real-world applications and limits the benefits of scaling updatasets. To address these challenges, we propose \textbf{Flow-Anything}, alarge-scale data generation framework designed to learn optical flow estimationfrom any single-view images in the real world. We employ two effective steps tomake data scaling-up promising. First, we convert a single-view image into a 3Drepresentation using advanced monocular depth estimation networks. This allowsus to render optical flow and novel view images under a virtual camera. Second,we develop an Object-Independent Volume Rendering module and a Depth-AwareInpainting module to model the dynamic objects in the 3D representation. Thesetwo steps allow us to generate realistic datasets for training from large-scalesingle-view images, namely \textbf{FA-Flow Dataset}. For the first time, wedemonstrate the benefits of generating optical flow training data fromlarge-scale real-world images, outperforming the most advanced unsupervisedmethods and supervised methods on synthetic datasets. Moreover, our modelsserve as a foundation model and enhance the performance of various downstreamvideo tasks.</description>
      <author>example@mail.com (Yingping Liang, Ying Fu, Yutao Hu, Wenqi Shao, Jiaming Liu, Debing Zhang)</author>
      <guid isPermaLink="false">2506.07740v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Taking Flight with Dialogue: Enabling Natural Language Control for PX4-based Drone Agent</title>
      <link>http://arxiv.org/abs/2506.07509v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Source code available at:  https://github.com/limshoonkit/ros2-agent-ws&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种开源的智能框架，用于自然语言控制无人机，并在仿真和定制多旋翼平台上对其性能进行了评估。&lt;h4&gt;背景&lt;/h4&gt;目前，基于地面的人工智能技术主要集中在类人形和轮式机器人上，而空中机器人相对较少被探索。最先进的无人机多模态视觉-语言系统通常依赖于仅限于资源丰富的组织的闭源模型。&lt;h4&gt;目的&lt;/h4&gt;为了民主化无人机的自然语言控制，研究提出了一种开源的智能框架。&lt;h4&gt;方法&lt;/h4&gt;该框架集成了基于PX4的飞行控制、Robot Operating System 2 (ROS 2) 中间件和本地托管模型（使用Ollama）。研究在仿真环境和定制四旋翼平台上对性能进行了评估，比较了四种大型语言模型（LLM）在命令生成方面的表现和三种视觉-语言模型（VLM）在场景理解方面的表现。&lt;h4&gt;主要发现&lt;/h4&gt;在仿真和实际平台上的评估表明，该框架能够有效实现无人机对自然语言指令的理解和执行。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法和框架为无人机自然语言控制提供了新的可能性，有助于推广这项技术。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in agentic and physical artificial intelligence (AI) have largely focused on ground-based platforms such as humanoid and wheeled robots, leaving aerial robots relatively underexplored. Meanwhile, state-of-the-art unmanned aerial vehicle (UAV) multimodal vision-language systems typically rely on closed-source models accessible only to well-resourced organizations. To democratize natural language control of autonomous drones, we present an open-source agentic framework that integrates PX4-based flight control, Robot Operating System 2 (ROS 2) middleware, and locally hosted models using Ollama. We evaluate performance both in simulation and on a custom quadcopter platform, benchmarking four large language model (LLM) families for command generation and three vision-language model (VLM) families for scene understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in agentic and physical artificial intelligence (AI) havelargely focused on ground-based platforms such as humanoid and wheeled robots,leaving aerial robots relatively underexplored. Meanwhile, state-of-the-artunmanned aerial vehicle (UAV) multimodal vision-language systems typically relyon closed-source models accessible only to well-resourced organizations. Todemocratize natural language control of autonomous drones, we present anopen-source agentic framework that integrates PX4-based flight control, RobotOperating System 2 (ROS 2) middleware, and locally hosted models using Ollama.We evaluate performance both in simulation and on a custom quadcopter platform,benchmarking four large language model (LLM) families for command generationand three vision-language model (VLM) families for scene understanding.</description>
      <author>example@mail.com (Shoon Kit Lim, Melissa Jia Ying Chong, Jing Huey Khor, Ting Yang Ling)</author>
      <guid isPermaLink="false">2506.07509v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Multiple Object Stitching for Unsupervised Representation Learning</title>
      <link>http://arxiv.org/abs/2506.07364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MOS的简单而有效的方法，用于改进多对象图像的无监督表示。&lt;h4&gt;背景&lt;/h4&gt;对比学习在单对象中心图像的无监督表示方面取得了显著进展，但在具有多个对象的广泛图像上表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出MOS方法，以改进多对象图像的无监督表示，特别是在对象检测和语义分割等复杂下游任务中。&lt;h4&gt;方法&lt;/h4&gt;通过拼接单对象中心图像来构建多对象图像，从而在不需要人工标注的情况下提供多对象图像之间的额外对象对应关系。&lt;h4&gt;主要发现&lt;/h4&gt;在ImageNet、CIFAR和COCO数据集上的实验结果表明，该方法在单对象中心图像和多对象图像上均取得了领先的无监督表示性能。&lt;h4&gt;结论&lt;/h4&gt;MOS方法能够提供更详细的表示，有助于复杂的下游任务，并且代码可在https://github.com/visresearch/MultipleObjectStitching上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/visresearch/MultipleObjectStitching&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning for single object centric images has achieved remarkableprogress on unsupervised representation, but suffering inferior performance onthe widespread images with multiple objects. In this paper, we propose a simplebut effective method, Multiple Object Stitching (MOS), to refine theunsupervised representation for multi-object images. Specifically, we constructthe multi-object images by stitching the single object centric ones, where theobjects in the synthesized multi-object images are predetermined. Hence,compared to the existing contrastive methods, our method provides additionalobject correspondences between multi-object images without human annotations.In this manner, our method pays more attention to the representations of eachobject in multi-object image, thus providing more detailed representations forcomplicated downstream tasks, such as object detection and semanticsegmentation. Experimental results on ImageNet, CIFAR and COCO datasetsdemonstrate that our proposed method achieves the leading unsupervisedrepresentation performance on both single object centric images andmulti-object ones. The source code is available athttps://github.com/visresearch/MultipleObjectStitching.</description>
      <author>example@mail.com (Chengchao Shen, Dawei Liu, Jianxin Wang)</author>
      <guid isPermaLink="false">2506.07364v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SpatialLM: Training Large Language Models for Structured Indoor Modeling</title>
      <link>http://arxiv.org/abs/2506.07491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SpatialLM是一种处理3D点云数据并生成结构化3D场景理解输出的大型语言模型。&lt;h4&gt;背景&lt;/h4&gt;之前的方法通过特定的网络设计来处理任务，而SpatialLM遵循标准的多模态LLM架构，并直接从开源LLMs进行微调。&lt;h4&gt;目的&lt;/h4&gt;提升现代LLM的空间理解能力，应用于增强现实、实体机器人等领域。&lt;h4&gt;方法&lt;/h4&gt;收集了一个包含12,328个室内场景（54,778个房间）点云的大规模、高质量合成数据集，并对建模和训练决策进行了深入研究。&lt;h4&gt;主要发现&lt;/h4&gt;SpatialLM在布局估计方面表现出色，在3D物体检测方面也有竞争力。&lt;h4&gt;结论&lt;/h4&gt;SpatialLM为提升现代LLM的空间理解能力提供了一条可行的路径。&lt;h4&gt;翻译&lt;/h4&gt;SpatialLM是一种为处理3D点云数据并生成结构化的3D场景理解输出而设计的大型语言模型。与之前依赖特定网络设计的方法不同，我们的模型遵循标准的多模态LLM架构，并直接从开源LLMs进行微调。为了训练SpatialLM，我们收集了一个包含12,328个室内场景（54,778个房间）点云的大规模、高质量合成数据集，并对建模和训练决策进行了深入研究。在公共基准测试中，我们的模型在布局估计方面表现出色，在3D物体检测方面也有竞争力。据此，我们展示了一条增强现代LLM空间理解能力、适用于增强现实、实体机器人等应用的可行路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; SpatialLM is a large language model designed to process 3D point cloud dataand generate structured 3D scene understanding outputs. These outputs includearchitectural elements like walls, doors, windows, and oriented object boxeswith their semantic categories. Unlike previous methods which exploittask-specific network designs, our model adheres to the standard multimodal LLMarchitecture and is fine-tuned directly from open-source LLMs.  To train SpatialLM, we collect a large-scale, high-quality synthetic datasetconsisting of the point clouds of 12,328 indoor scenes (54,778 rooms) withground-truth 3D annotations, and conduct a careful study on various modelingand training decisions. On public benchmarks, our model gives state-of-the-artperformance in layout estimation and competitive results in 3D objectdetection. With that, we show a feasible path for enhancing the spatialunderstanding capabilities of modern LLMs for applications in augmentedreality, embodied robotics, and more.</description>
      <author>example@mail.com (Yongsen Mao, Junhao Zhong, Chuan Fang, Jia Zheng, Rui Tang, Hao Zhu, Ping Tan, Zihan Zhou)</author>
      <guid isPermaLink="false">2506.07491v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Flowing Datasets with Wasserstein over Wasserstein Gradient Flows</title>
      <link>http://arxiv.org/abs/2506.07534v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as an oral at ICML2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种处理机器学习中概率分布数据的创新方法，用于设计在概率分布上的可处理梯度流。&lt;h4&gt;背景&lt;/h4&gt;许多机器学习应用涉及以概率分布形式表示的数据，需要新的技术来设计在无限维对象上的可处理梯度流。&lt;h4&gt;目的&lt;/h4&gt;设计一种方法，能够处理标记数据集，应用于领域自适应、迁移学习或数据集蒸馏等任务。&lt;h4&gt;方法&lt;/h4&gt;提出用特征的条件分布来表示每个类别，并将数据集建模为支持在这些类别上的混合分布，这些类别本身也是概率分布。在空间中引入了最优传输的度量结构——Wasserstein over Wasserstein (WoW) 距离，并导出了空间上的微分结构，定义了WoW梯度流。&lt;h4&gt;主要发现&lt;/h4&gt;通过这种方法，可以设计出在空间上减少给定目标泛函的动力学。&lt;h4&gt;结论&lt;/h4&gt;将该方法应用于迁移学习和数据集蒸馏任务，利用梯度流构造以及基于Sliced-Wasserstein核的最大均值差异等新颖的可处理泛函。&lt;h4&gt;翻译&lt;/h4&gt;Many applications in machine learning involve data represented as probability distributions. The emergence of such data requires radically novel techniques to design tractable gradient flows on probability distributions over this type of (infinite-dimensional) objects. For instance, being able to flow labeled datasets is a core task for applications ranging from domain adaptation to transfer learning or dataset distillation. In this setting, we propose to represent each class by the associated conditional distribution of features, and to model the dataset as a mixture distribution supported on these classes (which are themselves probability distributions), meaning that labeled datasets can be seen as probability distributions over probability distributions. We endow this space with a metric structure from optimal transport, namely the Wasserstein over Wasserstein (WoW) distance, derive a differential structure on this space, and define WoW gradient flows. The latter enables to design dynamics over this space that decrease a given objective functional. We apply our framework to transfer learning and dataset distillation tasks, leveraging our gradient flow construction as well as novel tractable functionals that take the form of Maximum Mean Discrepancies with Sliced-Wasserstein based kernels between probability distributions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many applications in machine learning involve data represented as probabilitydistributions. The emergence of such data requires radically novel techniquesto design tractable gradient flows on probability distributions over this typeof (infinite-dimensional) objects. For instance, being able to flow labeleddatasets is a core task for applications ranging from domain adaptation totransfer learning or dataset distillation. In this setting, we propose torepresent each class by the associated conditional distribution of features,and to model the dataset as a mixture distribution supported on these classes(which are themselves probability distributions), meaning that labeled datasetscan be seen as probability distributions over probability distributions. Weendow this space with a metric structure from optimal transport, namely theWasserstein over Wasserstein (WoW) distance, derive a differential structure onthis space, and define WoW gradient flows. The latter enables to designdynamics over this space that decrease a given objective functional. We applyour framework to transfer learning and dataset distillation tasks, leveragingour gradient flow construction as well as novel tractable functionals that takethe form of Maximum Mean Discrepancies with Sliced-Wasserstein based kernelsbetween probability distributions.</description>
      <author>example@mail.com (Clément Bonet, Christophe Vauthier, Anna Korba)</author>
      <guid isPermaLink="false">2506.07534v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model Empowered Synesthesia of Machines (SoM): AI-native Intelligent Multi-Modal Sensing-Communication Integration</title>
      <link>http://arxiv.org/abs/2506.07647v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为“机器通感”（SoM）的新范式，用于支持未来智能多功能第六代（6G）无线通信网络，并针对现有SoM系统设计中的挑战，提出了基于基础模型（FMs）的系统设计框架。&lt;h4&gt;背景&lt;/h4&gt;现有的SoM系统设计依赖于特定任务的AI模型，面临数据集稀缺、建模能力受限、泛化能力差和通用性有限等问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于FMs的系统设计框架，以解决现有SoM系统设计中的挑战。&lt;h4&gt;方法&lt;/h4&gt;对FMs进行系统分类，包括通用FMs、大型语言模型（LLMs）和SoM领域特定FMs（无线基础模型）。提出了基于LLM和无线基础模型的设计路线图，并提供了设计框架和案例研究。&lt;h4&gt;主要发现&lt;/h4&gt;FMs在解决SoM系统中的现有挑战方面具有关键特性，并展示了相较于特定任务模型的优势。&lt;h4&gt;结论&lt;/h4&gt;本文总结了FMs在SoM系统设计中的应用潜力，并指出了未来研究的潜在方向。&lt;h4&gt;翻译&lt;/h4&gt;To support future intelligent multifunctional sixth-generation (6G) wireless communication networks, Synesthesia of Machines (SoM) is proposed as a new paradigm for artificial intelligence (AI)-native intelligent multi-modal sensing-communication integration. However, existing SoM system designs rely on task-specific AI models and face challenges such as scarcity of massive high-quality datasets, constrained modeling capability, poor generalization, and limited universality. Recently, foundation models (FMs) have emerged as a new deep learning paradigm and have been preliminarily applied to SoM-related tasks, but a systematic design framework is still lacking. In this paper, we for the first time present a systematic categorization of FMs for SoM system design, dividing them into general-purpose FMs, specifically large language models (LLMs), and SoM domain-specific FMs, referred to as wireless foundation models. Furthermore, we derive key characteristics of FMs in addressing existing challenges in SoM systems and propose two corresponding roadmaps, i.e., LLM-based and wireless foundation model-based design. For each roadmap, we provide a framework containing key design steps as a guiding pipeline and several representative case studies of FM-empowered SoM system design. Specifically, we propose LLM-based path loss generation (LLM4PG) and scatterer generation (LLM4SG) schemes, and wireless channel foundation model (WiCo) for SoM mechanism exploration, LLM-based wireless multi-task SoM transceiver (LLM4WM) and wireless foundation model (WiFo) for SoM-enhanced transceiver design, and wireless cooperative perception foundation model (WiPo) for SoM-enhanced cooperative perception, demonstrating the significant superiority of FMs over task-specific models. Finally, we summarize and highlight potential directions for future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To support future intelligent multifunctional sixth-generation (6G) wirelesscommunication networks, Synesthesia of Machines (SoM) is proposed as a novelparadigm for artificial intelligence (AI)-native intelligent multi-modalsensing-communication integration. However, existing SoM system designs rely ontask-specific AI models and face challenges such as scarcity of massivehigh-quality datasets, constrained modeling capability, poor generalization,and limited universality. Recently, foundation models (FMs) have emerged as anew deep learning paradigm and have been preliminarily applied to SoM-relatedtasks, but a systematic design framework is still lacking. In this paper, wefor the first time present a systematic categorization of FMs for SoM systemdesign, dividing them into general-purpose FMs, specifically large languagemodels (LLMs), and SoM domain-specific FMs, referred to as wireless foundationmodels. Furthermore, we derive key characteristics of FMs in addressingexisting challenges in SoM systems and propose two corresponding roadmaps,i.e., LLM-based and wireless foundation model-based design. For each roadmap,we provide a framework containing key design steps as a guiding pipeline andseveral representative case studies of FM-empowered SoM system design.Specifically, we propose LLM-based path loss generation (LLM4PG) and scatterergeneration (LLM4SG) schemes, and wireless channel foundation model (WiCo) forSoM mechanism exploration, LLM-based wireless multi-task SoM transceiver(LLM4WM) and wireless foundation model (WiFo) for SoM-enhanced transceiverdesign, and wireless cooperative perception foundation model (WiPo) forSoM-enhanced cooperative perception, demonstrating the significant superiorityof FMs over task-specific models. Finally, we summarize and highlight potentialdirections for future research.</description>
      <author>example@mail.com (Xiang Cheng, Boxun Liu, Xuanyu Liu, Ensong Liu, Ziwei Huang)</author>
      <guid isPermaLink="false">2506.07647v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding</title>
      <link>http://arxiv.org/abs/2506.07600v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SceneRAG是一种统一的框架，通过结合大型语言模型处理视频中的ASR转写和时序元数据，将视频分割成与叙事一致的场景，从而有效理解长视频内容。&lt;h4&gt;背景&lt;/h4&gt;尽管检索增强生成（RAG）在视频理解方面取得了进展，但长视频内容的有效理解仍因视频数据的规模和复杂性而未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为SceneRAG的框架，以实现长视频内容的有效理解。&lt;h4&gt;方法&lt;/h4&gt;SceneRAG通过处理ASR转写和时序元数据将视频分割成场景，并使用轻量级启发式方法和迭代校正来细化场景边界。每个场景通过融合视觉和文本信息来提取实体关系，并动态构建知识图，实现多跳检索和生成。&lt;h4&gt;主要发现&lt;/h4&gt;在LongerVideos基准测试中，SceneRAG在生成任务上的胜率达到72.5%，显著优于先前基线。&lt;h4&gt;结论&lt;/h4&gt;SceneRAG能够有效地理解长视频内容，并在视频理解任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;尽管最近在视频理解方面检索增强生成（RAG）取得了进展，但由于视频数据的规模和复杂性，有效理解长视频内容仍然未得到充分探索。当前的RAG方法通常将视频分割成固定长度的片段，这往往破坏了上下文信息的连续性，并且无法捕捉到真实的场景边界。受人类将连续经验自然组织成连贯场景的能力的启发，我们提出了一种统一的框架，名为SceneRAG，该框架利用大型语言模型通过处理ASR转录本和时序元数据将视频分割成叙事一致的场景。SceneRAG还通过轻量级启发式方法和迭代校正进一步细化这些初始边界。对于每个场景，该框架融合来自视觉和文本模态的信息来提取实体关系，并动态构建知识图，从而实现考虑长距离依赖关系的稳健的多跳检索和生成。在LongerVideos基准测试中的实验，包含超过134小时的多样化内容，证实SceneRAG在生成任务上的胜率高达72.5%，显著优于先前基线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite recent advances in retrieval-augmented generation (RAG) for videounderstanding, effectively understanding long-form video content remainsunderexplored due to the vast scale and high complexity of video data. CurrentRAG approaches typically segment videos into fixed-length chunks, which oftendisrupts the continuity of contextual information and fails to captureauthentic scene boundaries. Inspired by the human ability to naturally organizecontinuous experiences into coherent scenes, we present SceneRAG, a unifiedframework that leverages large language models to segment videos intonarrative-consistent scenes by processing ASR transcripts alongside temporalmetadata. SceneRAG further sharpens these initial boundaries throughlightweight heuristics and iterative correction. For each scene, the frameworkfuses information from both visual and textual modalities to extract entityrelations and dynamically builds a knowledge graph, enabling robust multi-hopretrieval and generation that account for long-range dependencies. Experimentson the LongerVideos benchmark, featuring over 134 hours of diverse content,confirm that SceneRAG substantially outperforms prior baselines, achieving awin rate of up to 72.5 percent on generation tasks.</description>
      <author>example@mail.com (Nianbo Zeng, Haowen Hou, Fei Richard Yu, Si Shi, Ying Tiffany He)</author>
      <guid isPermaLink="false">2506.07600v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Variational Supervised Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.07413v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;对比学习在塑造不同模态的表示空间方面表现出高效和适应性，但存在两个主要限制。为了解决这些问题，提出了变分监督对比学习（VarCon），该学习通过变分推理和最大化后验加权证据下界（ELBO）来改进对比学习。&lt;h4&gt;背景&lt;/h4&gt;对比学习通过拉近相似样本和推开不同样本来塑造表示空间，但在没有显式调节嵌入分布的情况下，语义相关的实例可能会被无意中推开。此外，过度依赖大批次负样本和定制增强也阻碍了泛化。&lt;h4&gt;目的&lt;/h4&gt;提出VarCon来克服对比学习的限制，包括避免语义相关实例被推开，以及减少对大批次负样本和定制增强的依赖。&lt;h4&gt;方法&lt;/h4&gt;VarCon将监督对比学习重新定义为对潜在类变量的变分推理，并最大化后验加权证据下界（ELBO），以实现高效的类感知匹配和控制嵌入空间中的类内分散。&lt;h4&gt;主要发现&lt;/h4&gt;VarCon在CIFAR-10、CIFAR-100、ImageNet-100和ImageNet-1K上的实验表明，VarCon在对比学习框架中实现了最先进的性能，同时在图像数据上仅用200个epoch就收敛；它产生了更清晰的决策边界和语义组织；在少样本学习中优于监督基线，并且在各种增强策略下表现出更强的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;VarCon是一种有效的对比学习方法，能够显著提高性能，并具有更好的泛化能力和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning has proven to be highly efficient and adaptable inshaping representation spaces across diverse modalities by pulling similarsamples together and pushing dissimilar ones apart. However, two keylimitations persist: (1) Without explicit regulation of the embeddingdistribution, semantically related instances can inadvertently be pushed apartunless complementary signals guide pair selection, and (2) excessive relianceon large in-batch negatives and tailored augmentations hinders generalization.To address these limitations, we propose Variational Supervised ContrastiveLearning (VarCon), which reformulates supervised contrastive learning asvariational inference over latent class variables and maximizes aposterior-weighted evidence lower bound (ELBO) that replaces exhaustivepair-wise comparisons for efficient class-aware matching and grantsfine-grained control over intra-class dispersion in the embedding space.Trained exclusively on image data, our experiments on CIFAR-10, CIFAR-100,ImageNet-100, and ImageNet-1K show that VarCon (1) achieves state-of-the-artperformance for contrastive learning frameworks, reaching 79.36% Top-1 accuracyon ImageNet-1K and 78.29% on CIFAR-100 with a ResNet-50 encoder whileconverging in just 200 epochs; (2) yields substantially clearer decisionboundaries and semantic organization in the embedding space, as evidenced byKNN classification, hierarchical clustering results, and transfer-learningassessments; and (3) demonstrates superior performance in few-shot learningthan supervised baseline and superior robustness across various augmentationstrategies.</description>
      <author>example@mail.com (Ziwen Wang, Jiajun Fan, Thao Nguyen, Heng Ji, Ge Liu)</author>
      <guid isPermaLink="false">2506.07413v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning and Explainable AI for Brain Tumor Classification: A Study Using MRI Data from Bangladesh</title>
      <link>http://arxiv.org/abs/2506.07228v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2024 6th International Conference on Sustainable Technologies for  Industry 5.0 (STI)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究旨在解决脑肿瘤诊断问题，通过创建一个利用孟加拉国多医院MRI数据的自动脑肿瘤分类系统，结合深度学习模型和可解释人工智能方法，提高脑肿瘤检测和识别的准确性。&lt;h4&gt;背景&lt;/h4&gt;脑肿瘤，无论良性还是恶性，都存在很大的健康风险，恶性肿瘤由于其快速和不受控制的增殖而更加危险。在医疗基础设施有限的地区，如孟加拉国，及时诊断至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一个自动化的脑肿瘤分类系统，以提高诊断效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;使用VGG16、VGG19和ResNet50等深度学习模型对脑瘤、脑膜瘤和多种脑癌进行分类。采用Grad-CAM和Grad-CAM++等可解释人工智能方法来增强模型的可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;VGG16模型达到了99.17%的准确率。集成可解释人工智能（XAI）方法提高了系统的透明度和稳定性。&lt;h4&gt;结论&lt;/h4&gt;深度学习模型与可解释人工智能的结合，在资源有限的环境中，如孟加拉国，能够有效提高脑肿瘤的检测和识别。&lt;h4&gt;翻译&lt;/h4&gt;This study aims to address the issue of brain tumor diagnosis by developing an automated brain tumor classification system using MRI data obtained from many hospitals in Bangladesh, combining deep learning models with explainable artificial intelligence (XAI) methods to enhance the accuracy of brain tumor detection and identification.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/STI64222.2024.10951092&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain tumors, regardless of being benign or malignant, pose considerablehealth risks, with malignant tumors being more perilous due to their swift anduncontrolled proliferation, resulting in malignancy. Timely identification iscrucial for enhancing patient outcomes, particularly in nations such asBangladesh, where healthcare infrastructure is constrained. Manual MRI analysisis arduous and susceptible to inaccuracies, rendering it inefficient for promptdiagnosis. This research sought to tackle these problems by creating anautomated brain tumor classification system utilizing MRI data obtained frommany hospitals in Bangladesh. Advanced deep learning models, including VGG16,VGG19, and ResNet50, were utilized to classify glioma, meningioma, and variousbrain cancers. Explainable AI (XAI) methodologies, such as Grad-CAM andGrad-CAM++, were employed to improve model interpretability by emphasizing thecritical areas in MRI scans that influenced the categorization. VGG16 achievedthe most accuracy, attaining 99.17%. The integration of XAI enhanced thesystem's transparency and stability, rendering it more appropriate for clinicalapplication in resource-limited environments such as Bangladesh. This studyhighlights the capability of deep learning models, in conjunction withexplainable artificial intelligence (XAI), to enhance brain tumor detection andidentification in areas with restricted access to advanced medicaltechnologies.</description>
      <author>example@mail.com (Shuvashis Sarker)</author>
      <guid isPermaLink="false">2506.07228v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Return of ChebNet: Understanding and Improving an Overlooked GNN on Long Range Tasks</title>
      <link>http://arxiv.org/abs/2506.07624v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文重新审视了ChebNet，一种早期的光谱图神经网络，并提出了Stable-ChebNet，一种稳定的ChebNet模型，以解决其训练过程中的不稳定性问题。&lt;h4&gt;背景&lt;/h4&gt;ChebNet最初被MPNNs的简单性和有效性所掩盖，MPNNs在捕捉局部图结构方面表现出色，但它们在捕捉节点之间的长距离依赖关系方面有限。&lt;h4&gt;目的&lt;/h4&gt;通过重新审视ChebNet，研究其建模节点间远程交互的能力，并解决其训练过程中的不稳定性问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的稳定模型Stable-ChebNet，该模型允许稳定的信息传播，并具有可控的动态特性，不需要使用特征分解、位置编码或图重连。&lt;h4&gt;主要发现&lt;/h4&gt;Stable-ChebNet在长距离基准测试中相对于经典的MPNNs和GTs表现出竞争力，同时保持了高阶多项式良好的可扩展性。此外，Stable-ChebNet在多个基准测试中实现了接近最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;Stable-ChebNet是一种稳定的图神经网络模型，能够有效地建模节点间的远程交互，并在多个基准测试中表现出优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;ChebNet is one of the earliest spectral GNNs and has been largely overshadowed by Message Passing Neural Networks (MPNNs), which are popular for their simplicity and effectiveness in capturing local graph structure. Despite their success, MPNNs are limited in their ability to capture long-range dependencies between nodes. This has led researchers to adapt MPNNs through rewiring or make use of Graph Transformers, which compromises the computational efficiency that characterized early spatial message-passing architectures and typically disregards the graph structure. Almost a decade after its original introduction, we revisit ChebNet to shed light on its ability to model distant node interactions. We find that out-of-box, ChebNet already shows competitive advantages relative to classical MPNNs and GTs on long-range benchmarks, while maintaining good scalability properties for high-order polynomials. However, we uncover that this polynomial expansion leads ChebNet to an unstable regime during training. To address this limitation, we cast ChebNet as a stable and non-dissipative dynamical system, which we coin Stable-ChebNet. Our Stable-ChebNet model allows for stable information propagation and has controllable dynamics which do not require the use of eigendecompositions, positional encodings, or graph rewiring. Across several benchmarks, Stable-ChebNet achieves near state-of-the-art performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; ChebNet, one of the earliest spectral GNNs, has largely been overshadowed byMessage Passing Neural Networks (MPNNs), which gained popularity for theirsimplicity and effectiveness in capturing local graph structure. Despite theirsuccess, MPNNs are limited in their ability to capture long-range dependenciesbetween nodes. This has led researchers to adapt MPNNs through rewiring or makeuse of Graph Transformers, which compromises the computational efficiency thatcharacterized early spatial message-passing architectures, and typicallydisregards the graph structure. Almost a decade after its originalintroduction, we revisit ChebNet to shed light on its ability to model distantnode interactions. We find that out-of-box, ChebNet already shows competitiveadvantages relative to classical MPNNs and GTs on long-range benchmarks, whilemaintaining good scalability properties for high-order polynomials. However, weuncover that this polynomial expansion leads ChebNet to an unstable regimeduring training. To address this limitation, we cast ChebNet as a stable andnon-dissipative dynamical system, which we coin Stable-ChebNet. OurStable-ChebNet model allows for stable information propagation, and hascontrollable dynamics which do not require the use of eigendecompositions,positional encodings, or graph rewiring. Across several benchmarks,Stable-ChebNet achieves near state-of-the-art performance.</description>
      <author>example@mail.com (Ali Hariri, Álvaro Arroyo, Alessio Gravina, Moshe Eliasof, Carola-Bibiane Schönlieb, Davide Bacciu, Kamyar Azizzadenesheli, Xiaowen Dong, Pierre Vandergheynst)</author>
      <guid isPermaLink="false">2506.07624v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Drive Any Mesh: 4D Latent Diffusion for Mesh Deformation from Video</title>
      <link>http://arxiv.org/abs/2506.07489v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了DriveAnyMesh方法，用于通过单目视频驱动网格。&lt;h4&gt;背景&lt;/h4&gt;当前4D生成技术在现代渲染引擎中面临挑战，隐式方法渲染效率低，不友好于基于光栅化的引擎，而骨骼方法需要大量手动工作且缺乏跨类别泛化能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一种4D扩散模型，用于去噪潜在集合序列，然后从点云轨迹序列解码生成网格动画。&lt;h4&gt;方法&lt;/h4&gt;这些潜在集合利用基于transformer的变分自编码器，同时捕捉3D形状和运动信息。通过使用时空的、基于transformer的扩散模型，信息在多个潜在帧之间交换，增强了生成结果的效率和泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，DriveAnyMesh可以快速生成高质量动画，且与现代渲染引擎兼容。&lt;h4&gt;结论&lt;/h4&gt;该方法在游戏和电影行业中具有潜在应用价值。&lt;h4&gt;翻译&lt;/h4&gt;We propose DriveAnyMesh, a method for driving mesh guided by monocular video. Current 4D generation techniques encounter challenges with modern rendering engines. Implicit methods have low rendering efficiency and are unfriendly torasterization-based engines, while skeletal methods demand significant manualeffort and lack cross-category generalization. Animating existing 3D assets, instead of creating 4D assets from scratch, demands a deep understanding of the input's 3D structure. To tackle these challenges, we present a 4D diffusion model that denoises sequences of latent sets, which are then decoded to producemesh animations from point cloud trajectory sequences. These latent sets leverage a transformer-based variational autoencoder, simultaneously capturing 3D shape and motion information. By employing a spatiotemporal, transformer-based diffusion model, information is exchanged across multiple latent frames, enhancing the efficiency and generalization of the generated results. Our experimental results demonstrate that DriveAnyMesh can rapidly produce high-quality animations for complex motions and is compatible with modern rendering engines. This method holds potential for applications in both the gaming and filming industries.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose DriveAnyMesh, a method for driving mesh guided by monocular video.Current 4D generation techniques encounter challenges with modern renderingengines. Implicit methods have low rendering efficiency and are unfriendly torasterization-based engines, while skeletal methods demand significant manualeffort and lack cross-category generalization. Animating existing 3D assets,instead of creating 4D assets from scratch, demands a deep understanding of theinput's 3D structure. To tackle these challenges, we present a 4D diffusionmodel that denoises sequences of latent sets, which are then decoded to producemesh animations from point cloud trajectory sequences. These latent setsleverage a transformer-based variational autoencoder, simultaneously capturing3D shape and motion information. By employing a spatiotemporal,transformer-based diffusion model, information is exchanged across multiplelatent frames, enhancing the efficiency and generalization of the generatedresults. Our experimental results demonstrate that DriveAnyMesh can rapidlyproduce high-quality animations for complex motions and is compatible withmodern rendering engines. This method holds potential for applications in boththe gaming and filming industries.</description>
      <author>example@mail.com (Yahao Shi, Yang Liu, Yanmin Wu, Xing Liu, Chen Zhao, Jie Luo, Bin Zhou)</author>
      <guid isPermaLink="false">2506.07489v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Text-Attributed Graph Learning through Selective Annotation and Graph Alignment</title>
      <link>http://arxiv.org/abs/2506.07168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GAGA的框架，用于高效学习文本属性图（TAGs）中的节点表示，通过标注代表性节点和边来减少标注时间和成本，同时通过两级行为模块有效整合标注图与TAG，提高分类准确率。&lt;h4&gt;背景&lt;/h4&gt;传统的图神经网络（GNNs）在处理文本属性图（TAGs）时往往表现不佳，因为每个节点都关联着复杂的文本信息。&lt;h4&gt;目的&lt;/h4&gt;克服传统方法在标注时间和成本上的不足，提高节点表示的效率。&lt;h4&gt;方法&lt;/h4&gt;GAGA通过以下方式实现其目的：1. 仅标注代表性节点和边，减少标注时间和成本；2. 构建标注图以捕捉这些标注之间的拓扑关系；3. 采用两级行为模块，将标注图与TAG进行有效整合，对齐其底层结构。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，GAGA在分类准确率上与或超过现有最佳方法，同时仅需标注1%的数据，显示出其高效率。&lt;h4&gt;结论&lt;/h4&gt;GAGA是一种高效且准确的框架，用于学习文本属性图中的节点表示，为处理此类数据提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;在文本属性图（TAGs）领域，传统的图神经网络（GNNs）由于每个节点关联的复杂文本信息而表现不佳。最近的方法通过利用大型语言模型（LLMs）来增强节点文本特征，提高了节点表示，但这些方法通常需要大量的标注或在所有节点上进行微调，这既耗时又昂贵。为了克服这些挑战，我们引入了GAGA，这是一种用于TAG表示学习的有效框架。GAGA通过仅关注标注代表性节点和边来减少标注时间和成本。它构建了一个标注图，捕捉这些标注之间的拓扑关系。此外，GAGA采用一个两级行为模块，有效地将标注图与TAG整合，对齐它们的底层结构。实验表明，GAGA在分类准确率上与或超过现有最佳方法，同时仅需标注1%的数据，证明了其高效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the realm of Text-attributed Graphs (TAGs), traditional graph neuralnetworks (GNNs) often fall short due to the complex textual informationassociated with each node. Recent methods have improved node representations byleveraging large language models (LLMs) to enhance node text features, butthese approaches typically require extensive annotations or fine-tuning acrossall nodes, which is both time-consuming and costly. To overcome thesechallenges, we introduce GAGA, an efficient framework for TAG representationlearning. GAGA reduces annotation time and cost by focusing on annotating onlyrepresentative nodes and edges. It constructs an annotation graph that capturesthe topological relationships among these annotations. Furthermore, GAGAemploys a two-level alignment module to effectively integrate the annotationgraph with the TAG, aligning their underlying structures. Experiments show thatGAGA achieves classification accuracies on par with or surpassingstate-of-the-art methods while requiring only 1% of the data to be annotated,demonstrating its high efficiency.</description>
      <author>example@mail.com (Huanyi Xie, Lijie Hu, Lu Yu, Tianhao Huang, Longfei Li, Meng Li, Jun Zhou, Huan Wang, Di Wang)</author>
      <guid isPermaLink="false">2506.07168v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>HeTa: Relation-wise Heterogeneous Graph Foundation Attack Model</title>
      <link>http://arxiv.org/abs/2506.07428v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的关系感知异构图基础攻击模型HeTa，用于评估异构图神经网络（HGNNs）的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的HGNN攻击方法通常需要复杂的参数重训练来生成特定场景的扰动，且HGNNs容易受到针对的攻击。&lt;h4&gt;目的&lt;/h4&gt;设计一个适用于HGNNs的基础攻击模型，能够实现不同HGNNs之间的泛化扰动，并快速适应新的异构图。&lt;h4&gt;方法&lt;/h4&gt;通过挖掘共享攻击单元设计攻击准则，引入基础代理模型来对齐异质性和识别共享关系感知攻击单元的重要性，并基于此实现关系级别的序列化攻击。&lt;h4&gt;主要发现&lt;/h4&gt;尽管HGNNs在模型设计和参数空间上存在显著差异，但从关系感知的角度来看，它们却共享一些常见的脆弱性模式。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，该方法具有强大的攻击性能和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Heterogeneous Graph Neural Networks (HGNNs) are vulnerable, highlighting the need for tailored attacks to assess their robustness and ensure security. However, existing HGNN attacks often require complex retraining of parameters to generate specific perturbations for new scenarios. Recently, foundation models have opened new horizons for the generalization of graph neural networks by capturing shared semantics across various graph distributions. This leads us to ask: Can we design a foundation attack model for HGNNs that enables generalizable perturbations across different HGNNs, and quickly adapts to new heterogeneous graphs (HGs)? Empirical findings reveal that, despite significant differences in model design and parameter space, different HGNNs surprisingly share common vulnerability patterns from a relation-aware perspective. Therefore, we explore how to design foundation HGNN attack criteria by mining shared attack units. In this paper, we propose a novel relation-wise heterogeneous graph foundation attack model, HeTa. We introduce a foundation surrogate model to align heterogeneity and identify the importance of shared relation-aware attack units. Building on this, we implement a serialized relation-by-relation attack based on the identified relational weights. In this way, the perturbation can be transferred to various target HGNNs and easily fine-tuned for new HGs. Extensive experiments exhibit powerful attack performances and generalizability of our method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterogeneous Graph Neural Networks (HGNNs) are vulnerable, highlighting theneed for tailored attacks to assess their robustness and ensure security.However, existing HGNN attacks often require complex retraining of parametersto generate specific perturbations for new scenarios. Recently, foundationmodels have opened new horizons for the generalization of graph neural networksby capturing shared semantics across various graph distributions. This leads usto ask:Can we design a foundation attack model for HGNNs that enablesgeneralizable perturbations across different HGNNs, and quickly adapts to newheterogeneous graphs (HGs)? Empirical findings reveal that, despite significantdifferences in model design and parameter space, different HGNNs surprisinglyshare common vulnerability patterns from a relation-aware perspective.Therefore, we explore how to design foundation HGNN attack criteria by miningshared attack units. In this paper, we propose a novel relation-wiseheterogeneous graph foundation attack model, HeTa. We introduce a foundationsurrogate model to align heterogeneity and identify the importance of sharedrelation-aware attack units. Building on this, we implement a serializedrelation-by-relation attack based on the identified relational weights. In thisway, the perturbation can be transferred to various target HGNNs and easilyfine-tuned for new HGs. Extensive experiments exhibit powerful attackperformances and generalizability of our method.</description>
      <author>example@mail.com (Yuling Wang, Zihui Chen, Pengfei Jiao, Xiao Wang)</author>
      <guid isPermaLink="false">2506.07428v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>State Entropy Regularization for Robust Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.07085v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了状态熵正则化在强化学习中的应用，分析了其在提高鲁棒性方面的优势，并与策略熵正则化进行了对比。&lt;h4&gt;背景&lt;/h4&gt;状态熵正则化在强化学习中表现出良好的探索和样本复杂度，但其理论保证尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;验证状态熵正则化在提高鲁棒性方面的有效性，并与其他正则化方法进行比较。&lt;h4&gt;方法&lt;/h4&gt;通过分析状态熵正则化在处理结构性和空间相关扰动时的鲁棒性，以及与策略熵正则化的对比，提供了理论保证。&lt;h4&gt;主要发现&lt;/h4&gt;状态熵正则化能够提高对结构性和空间相关扰动的鲁棒性，并且比策略熵正则化在处理这类扰动时更敏感。&lt;h4&gt;结论&lt;/h4&gt;状态熵正则化是一种有效的强化学习方法，特别是在处理转移学习中的结构性扰动时，具有明显的优势。&lt;h4&gt;翻译&lt;/h4&gt;State entropy regularization has empirically shown better exploration and sample complexity in reinforcement learning (RL). However, its theoretical guarantees have not been studied. In this paper, we show that state entropy regularization improves robustness to structured and spatially correlated perturbations. These types of variation are common in transfer learning but often overlooked by standard robust RL methods, which typically focus on small, uncorrelated changes. We provide a comprehensive characterization of these robustness properties, including formal guarantees under reward and transition uncertainty, as well as settings where the method performs poorly. Much of our analysis contrasts state entropy with the widely used policy entropy regularization, highlighting their different benefits. Finally, from a practical standpoint, we illustrate that compared with policy entropy, the robustness advantages of state entropy are more sensitive to the number of rollouts used for policy evaluation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State entropy regularization has empirically shown better exploration andsample complexity in reinforcement learning (RL). However, its theoreticalguarantees have not been studied. In this paper, we show that state entropyregularization improves robustness to structured and spatially correlatedperturbations. These types of variation are common in transfer learning butoften overlooked by standard robust RL methods, which typically focus on small,uncorrelated changes. We provide a comprehensive characterization of theserobustness properties, including formal guarantees under reward and transitionuncertainty, as well as settings where the method performs poorly. Much of ouranalysis contrasts state entropy with the widely used policy entropyregularization, highlighting their different benefits. Finally, from apractical standpoint, we illustrate that compared with policy entropy, therobustness advantages of state entropy are more sensitive to the number ofrollouts used for policy evaluation.</description>
      <author>example@mail.com (Uri Koren, Yonatan Ashlag, Mirco Mutti, Esther Derman, Pierre-Luc Bacon, Shie Mannor)</author>
      <guid isPermaLink="false">2506.07085v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Improving Wildlife Out-of-Distribution Detection: Africas Big Five</title>
      <link>http://arxiv.org/abs/2506.06719v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究旨在解决人类与野生动物冲突，通过计算机视觉技术识别可能引发冲突的个体，如非洲大型动物。&lt;h4&gt;背景&lt;/h4&gt;当前动物分类模型在封闭世界假设下训练，对未知类别的预测往往过于自信。&lt;h4&gt;目的&lt;/h4&gt;研究野生动物（特别是非洲大型动物）的分布外（OOD）检测。&lt;h4&gt;方法&lt;/h4&gt;选择参数化的最近类均值（NCM）和非参数的对比学习方法作为基线，并与其他常见的OOD方法进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;基于特征的方法在不同分类阈值下表现出更强的泛化能力。特别是，使用ImageNet预训练特征的NCM在AUPR-IN、AUPR-OUT和AUTC上分别比最佳OOD方法提高了2%、4%和22%。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，基于特征的方法在OOD检测方面具有更高的准确性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mitigating human-wildlife conflict seeks to resolve unwanted encountersbetween these parties. Computer Vision provides a solution to identifyingindividuals that might escalate into conflict, such as members of the Big FiveAfrican animals. However, environments often contain several varied species.The current state-of-the-art animal classification models are trained under aclosed-world assumption. They almost always remain overconfident in theirpredictions even when presented with unknown classes. This study investigatesout-of-distribution (OOD) detection of wildlife, specifically the Big Five. Tothis end, we select a parametric Nearest Class Mean (NCM) and a non-parametriccontrastive learning approach as baselines to take advantage of pretrained andprojected features from popular classification encoders. Moreover, we compareour baselines to various common OOD methods in the literature. The results showfeature-based methods reflect stronger generalisation capability across varyingclassification thresholds. Specifically, NCM with ImageNet pre-trained featuresachieves a 2%, 4% and 22% improvement on AUPR-IN, AUPR-OUT and AUTC over thebest OOD methods, respectively. The code can be found herehttps://github.com/pxpana/BIG5OOD</description>
      <author>example@mail.com (Mufhumudzi Muthivhi, Jiahao Huo, Fredrik Gustafsson, Terence L. van Zyl)</author>
      <guid isPermaLink="false">2506.06719v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>AugmentGest: Can Random Data Cropping Augmentation Boost Gesture Recognition Performance?</title>
      <link>http://arxiv.org/abs/2506.07216v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种全面的数据增强框架，用于解决深度学习任务中数据集多样性有限的问题，如基于骨骼的数据集。该框架通过几何变换、随机裁剪、旋转、缩放和基于强度的变换来模拟现实世界的变异性，提高了模型在不同数据集和架构上的泛化能力和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;数据增强是深度学习中的关键技术，尤其在数据集多样性有限的任务中，如基于骨骼的数据集，显得尤为重要。&lt;h4&gt;目的&lt;/h4&gt;提高模型在不同数据集和架构上的泛化能力和鲁棒性，丰富手势表示的多样性。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了几何变换、随机裁剪、旋转、缩放和亮度对比度调整等手段，对每个样本生成三个增强版本，从而将数据集规模扩大四倍。&lt;h4&gt;主要发现&lt;/h4&gt;实验在多个基准数据集上进行，包括DHG14/28、SHREC'17和JHMDB，结果表明，该方法在三个评估模型（多流端到端ET、基于FPPR的点云手势识别和DD-Network）上均取得了最先进的成果。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅提高了模型在不同数据集和架构上的泛化能力和鲁棒性，还为现实场景中的手势识别和动作识别应用提供了一个可扩展的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a comprehensive data augmentation framework for tasks with limited dataset diversity, such as skeleton-based datasets. The framework combines geometric transformations, random cropping, rotation, zooming, and intensity-based transformations to simulate real-world variations, thereby enhancing the generalization and robustness of models across diverse datasets and architectures. Experiments on benchmark datasets including DHG14/28, SHREC'17, and JHMDB demonstrate that the proposed method achieves state-of-the-art results on three evaluated models: multi-stream e2eET, FPPR point cloud-based hand gesture recognition (HGR), and DD-Network. The method not only improves model generalization and robustness but also offers a scalable solution for real-world HGR and action recognition applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data augmentation is a crucial technique in deep learning, particularly fortasks with limited dataset diversity, such as skeleton-based datasets. Thispaper proposes a comprehensive data augmentation framework that integratesgeometric transformations, random cropping, rotation, zooming andintensity-based transformations, brightness and contrast adjustments tosimulate real-world variations. Random cropping ensures the preservation ofspatio-temporal integrity while addressing challenges such as viewpoint biasand occlusions. The augmentation pipeline generates three augmented versionsfor each sample in addition to the data set sample, thus quadrupling the dataset size and enriching the diversity of gesture representations. The proposedaugmentation strategy is evaluated on three models: multi-stream e2eET, FPPRpoint cloud-based hand gesture recognition (HGR), and DD-Network. Experimentsare conducted on benchmark datasets including DHG14/28, SHREC'17, and JHMDB.The e2eET model, recognized as the state-of-the-art for hand gesturerecognition on DHG14/28 and SHREC'17. The FPPR-PCD model, the second-bestperforming model on SHREC'17, excels in point cloud-based gesture recognition.DD-Net, a lightweight and efficient architecture for skeleton-based actionrecognition, is evaluated on SHREC'17 and the Human Motion Data Base (JHMDB).The results underline the effectiveness and versatility of the proposedaugmentation strategy, significantly improving model generalization androbustness across diverse datasets and architectures. This framework not onlyestablishes state-of-the-art results on all three evaluated models but alsooffers a scalable solution to advance HGR and action recognition applicationsin real-world scenarios. The framework is available athttps://github.com/NadaAbodeshish/Random-Cropping-augmentation-HGR</description>
      <author>example@mail.com (Nada Aboudeshish, Dmitry Ignatov, Radu Timofte)</author>
      <guid isPermaLink="false">2506.07216v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs</title>
      <link>http://arxiv.org/abs/2506.07454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个多机器人系统，该系统通过3D场景图集成了制图、定位和任务与运动规划（TAMP），以执行用自然语言表达的复杂指令。&lt;h4&gt;背景&lt;/h4&gt;目前多机器人系统需要集成多种功能以执行复杂任务，包括地图构建、定位和规划。&lt;h4&gt;目的&lt;/h4&gt;开发一个多机器人系统，该系统能够理解自然语言指令，并在3D环境中执行复杂任务。&lt;h4&gt;方法&lt;/h4&gt;系统构建了一个共享的3D场景图，其中包含一个基于开放集的对象地图，用于多机器人3D场景图融合。该表示支持实时、视角不变的重定位（通过对象地图）和规划（通过3D场景图）。另外，系统使用大型语言模型（LLM）将操作者的意图转化为规划域定义语言（PDDL）目标，利用共享3D场景图和机器人能力。&lt;h4&gt;主要发现&lt;/h4&gt;该系统能够在大型、室外环境中执行真实世界任务，并对其性能进行了实验评估。&lt;h4&gt;结论&lt;/h4&gt;该多机器人系统能够有效地理解和执行自然语言指令，并在复杂环境中实现任务规划与执行。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce a multi-robot system that integrates mapping,localization, and task and motion planning (TAMP) enabled by 3D scene graphs toexecute complex instructions expressed in natural language. Our system builds ashared 3D scene graph incorporating an open-set object-based map, which isleveraged for multi-robot 3D scene graph fusion. This representation supportsreal-time, view-invariant relocalization (via the object-based map) andplanning (via the 3D scene graph), allowing a team of robots to reason abouttheir surroundings and execute complex tasks. Additionally, we introduce aplanning approach that translates operator intent into Planning DomainDefinition Language (PDDL) goals using a Large Language Model (LLM) byleveraging context from the shared 3D scene graph and robot capabilities. Weprovide an experimental assessment of the performance of our system onreal-world tasks in large-scale, outdoor environments.</description>
      <author>example@mail.com (Jared Strader, Aaron Ray, Jacob Arkin, Mason B. Peterson, Yun Chang, Nathan Hughes, Christopher Bradley, Yi Xuan Jia, Carlos Nieto-Granda, Rajat Talak, Chuchu Fan, Luca Carlone, Jonathan P. How, Nicholas Roy)</author>
      <guid isPermaLink="false">2506.07454v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Visual Prompting: Robustness Inheritance and Beyond</title>
      <link>http://arxiv.org/abs/2506.06823v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2311.10992&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文首次探讨了视觉提示（VP）在鲁棒源模型下的表现，提出了PromptBoundary Loosening（PBL）策略以缓解VP在鲁棒性和泛化能力之间的权衡。&lt;h4&gt;背景&lt;/h4&gt;视觉提示（VP）作为一种有效的迁移学习方法，在视觉任务中显示出其潜力。然而，先前的研究主要集中在从标准源模型中进行VP，而鲁棒源模型下的VP表现尚不明确。&lt;h4&gt;目的&lt;/h4&gt;研究鲁棒源模型对VP表现的影响，探讨VP在鲁棒性和泛化能力之间的权衡，并提出缓解这种权衡的策略。&lt;h4&gt;方法&lt;/h4&gt;本文提出了PromptBoundary Loosening（PBL）策略，这是一种轻量级、即插即用的策略，与VP自然兼容，并有效确保了在源模型为鲁棒模型时鲁棒性的成功继承。&lt;h4&gt;主要发现&lt;/h4&gt;通过在多个数据集上的广泛实验，发现PBL策略能够显著增强VP在下游数据集上的泛化能力，并成功缓解了VP在鲁棒性和泛化能力之间的权衡。&lt;h4&gt;结论&lt;/h4&gt;PBL策略能够有效提高VP在鲁棒源模型下的表现，并具有普遍性，证明了该策略的重要益处。&lt;h4&gt;翻译&lt;/h4&gt;Visual Prompting (VP), an efficient method for transfer learning, has shown its potential in vision tasks. However, previous works focus exclusively on VP from standard source models, it is still unknown how it performs under the scenario of a robust source model: Can the robustness of the source model be successfully inherited? Does VP also encounter the same trade-off between robustness and generalization ability as the source model during this process? If such a trade-off exists, is there a strategy specifically tailored to VP to mitigate this limitation? In this paper, we thoroughly explore these three questions for the first time and provide affirmative answers to them. To mitigate the trade-off faced by VP, we propose a strategy called PromptBoundary Loosening (PBL). As a lightweight, plug-and-play strategy naturally compatible with VP, PBL effectively ensures the successful inheritance of robustness when the source model is a robust model, while significantly enhancing VP's generalization ability across various downstream datasets. Extensive experiments across various datasets show that our findings are universal and demonstrate the significant benefits of the proposed strategy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Prompting (VP), an efficient method for transfer learning, has shownits potential in vision tasks. However, previous works focus exclusively on VPfrom standard source models, it is still unknown how it performs under thescenario of a robust source model: Can the robustness of the source model besuccessfully inherited? Does VP also encounter the same trade-off betweenrobustness and generalization ability as the source model during this process?If such a trade-off exists, is there a strategy specifically tailored to VP tomitigate this limitation? In this paper, we thoroughly explore these threequestions for the first time and provide affirmative answers to them. Tomitigate the trade-off faced by VP, we propose a strategy called PromptBoundary Loosening (PBL). As a lightweight, plug-and-play strategy naturallycompatible with VP, PBL effectively ensures the successful inheritance ofrobustness when the source model is a robust model, while significantlyenhancing VP's generalization ability across various downstream datasets.Extensive experiments across various datasets show that our findings areuniversal and demonstrate the significant benefits of the proposed strategy.</description>
      <author>example@mail.com (Qi Li, Liangzhi Li, Zhouqiang Jiang, Bowen Wang, Keke Tang)</author>
      <guid isPermaLink="false">2506.06823v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>CrossGen: Learning and Generating Cross Fields for Quad Meshing</title>
      <link>http://arxiv.org/abs/2506.07020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://anonymousproject-homepage.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CrossGen是一种新型框架，用于生成高质量的四边形网格，通过在联合潜在空间中统一几何和交叉场表示，支持交叉场的前馈预测和潜在生成建模。&lt;h4&gt;背景&lt;/h4&gt;现有的交叉场生成方法难以在计算效率和生成质量之间取得平衡，通常采用缓慢的针对每个形状的优化。&lt;h4&gt;目的&lt;/h4&gt;提出CrossGen框架，旨在实现快速计算高质量交叉场，同时不需要针对每个形状的优化。&lt;h4&gt;方法&lt;/h4&gt;CrossGen使用自动编码器网络架构，将输入的点云表面编码为稀疏体素网格，具有细粒度的潜在空间，这些空间被解码为基于SDF的表面几何和交叉场。同时，该方法还包含一个用于计算从部分输入（如草图）生成的新形状的交叉场的扩散模型。&lt;h4&gt;主要发现&lt;/h4&gt;CrossGen能够在不到一秒的时间内计算一般输入形状的高质量交叉场，无需针对每个形状的优化，并具有高几何保真度、噪声鲁棒性和快速推理能力。&lt;h4&gt;结论&lt;/h4&gt;CrossGen在四边形网格生成任务中表现出色，适用于各种表面形状，为交叉场生成提供了一种高效且高质量的方法。&lt;h4&gt;翻译&lt;/h4&gt;Cross fields play a critical role in various geometry processing tasks, especially for quad mesh generation. Existing methods for cross field generation often struggle to balance computational efficiency with generation quality, using slow per-shape optimization. We introduce CrossGen, a novel framework that supports both feed-forward prediction and latent generative modeling of cross fields for quad meshing by unifying geometry and cross field representations within a joint latent space. Our method enables extremely fast computation of high-quality cross fields of general input shapes, typically within one second without per-shape optimization. Our method assumes a point-sampled surface, or called a point-cloud surface, as input, so we can accommodate various different surface representations by a straightforward point sampling process. Using an auto-encoder network architecture, we encode input point-cloud surfaces into a sparse voxel grid with fine-grained latent spaces, which are decoded into both SDF-based surface geometry and cross fields. We also contribute a dataset of models with both high-quality signed distance fields (SDFs) representations and their corresponding cross fields, and use it to train our network. Once trained, the network is capable of computing a cross field of an input surface in a feed-forward manner, ensuring high geometric fidelity, noise resilience, and rapid inference. Furthermore, leveraging the same unified latent representation, we incorporate a diffusion model for computing cross fields of new shapes generated from partial input, such as sketches. To demonstrate its practical applications, we validate CrossGen on the quad mesh generation task for a large variety of surface shapes. Experimental results...&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross fields play a critical role in various geometry processing tasks,especially for quad mesh generation. Existing methods for cross fieldgeneration often struggle to balance computational efficiency with generationquality, using slow per-shape optimization. We introduce CrossGen, a novelframework that supports both feed-forward prediction and latent generativemodeling of cross fields for quad meshing by unifying geometry and cross fieldrepresentations within a joint latent space. Our method enables extremely fastcomputation of high-quality cross fields of general input shapes, typicallywithin one second without per-shape optimization. Our method assumes apoint-sampled surface, or called a point-cloud surface, as input, so we canaccommodate various different surface representations by a straightforwardpoint sampling process. Using an auto-encoder network architecture, we encodeinput point-cloud surfaces into a sparse voxel grid with fine-grained latentspaces, which are decoded into both SDF-based surface geometry and crossfields. We also contribute a dataset of models with both high-quality signeddistance fields (SDFs) representations and their corresponding cross fields,and use it to train our network. Once trained, the network is capable ofcomputing a cross field of an input surface in a feed-forward manner, ensuringhigh geometric fidelity, noise resilience, and rapid inference. Furthermore,leveraging the same unified latent representation, we incorporate a diffusionmodel for computing cross fields of new shapes generated from partial input,such as sketches. To demonstrate its practical applications, we validateCrossGen on the quad mesh generation task for a large variety of surfaceshapes. Experimental results...</description>
      <author>example@mail.com (Qiujie Dong, Jiepeng Wang, Rui Xu, Cheng Lin, Yuan Liu, Shiqing Xin, Zichun Zhong, Xin Li, Changhe Tu, Taku Komura, Leif Kobbelt, Scott Schaefer, Wenping Wang)</author>
      <guid isPermaLink="false">2506.07020v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>MIRA: Medical Time Series Foundation Model for Real-World Health Data</title>
      <link>http://arxiv.org/abs/2506.07584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种针对医疗时间序列的统一基础模型MIRA，通过预训练减少标注负担，最小化模型定制，并实现跨临床机构、模态和任务的鲁棒迁移。&lt;h4&gt;背景&lt;/h4&gt;现有通用时间序列基础模型难以处理医疗时间序列数据，因为它们存在不规则的时间间隔、异质采样率和频繁缺失值等问题。&lt;h4&gt;目的&lt;/h4&gt;设计MIRA模型以解决上述挑战，实现医疗时间序列的准确预测。&lt;h4&gt;方法&lt;/h4&gt;MIRA模型包含连续时间旋转位置编码、特定频率的专家混合层以及基于神经网络常微分方程的连续动态外推块。&lt;h4&gt;主要发现&lt;/h4&gt;MIRA在包含超过4540亿时间点的医学语料库上预训练，与零样本和微调的基线相比，在分布外和分布内场景下，预测误差分别减少了10%和7%。&lt;h4&gt;结论&lt;/h4&gt;MIRA为医学时间序列建模的基准研究提供了基础，有助于未来在该领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;A unified foundation model for medical time series -- pretrained on openaccess and ethics board-approved medical corpora -- offers the potential toreduce annotation burdens, minimize model customization, and enable robusttransfer across clinical institutions, modalities, and tasks, particularly indata-scarce or privacy-constrained environments. However, existing generalisttime series foundation models struggle to handle medical time series data dueto their inherent challenges, including irregular intervals, heterogeneoussampling rates, and frequent missing values. To address these challenges, weintroduce MIRA, a unified foundation model specifically designed for medicaltime series forecasting. MIRA incorporates a Continuous-Time Rotary PositionalEncoding that enables fine-grained modeling of variable time intervals, afrequency-specific mixture-of-experts layer that routes computation acrosslatent frequency regimes to further promote temporal specialization, and aContinuous Dynamics Extrapolation Block based on Neural ODE that models thecontinuous trajectory of latent states, enabling accurate forecasting atarbitrary target timestamps. Pretrained on a large-scale and diverse medicalcorpus comprising over 454 billion time points collect from publicly availabledatasets, MIRA achieves reductions in forecasting errors by an average of 10%and 7% in out-of-distribution and in-distribution scenarios, respectively, whencompared to other zero-shot and fine-tuned baselines. We also introduceacomprehensive benchmark spanning multiple downstream clinical tasks,establishing a foundation for future research in medical time series modeling.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A unified foundation model for medical time series -- pretrained on openaccess and ethics board-approved medical corpora -- offers the potential toreduce annotation burdens, minimize model customization, and enable robusttransfer across clinical institutions, modalities, and tasks, particularly indata-scarce or privacy-constrained environments. However, existing generalisttime series foundation models struggle to handle medical time series data dueto their inherent challenges, including irregular intervals, heterogeneoussampling rates, and frequent missing values. To address these challenges, weintroduce MIRA, a unified foundation model specifically designed for medicaltime series forecasting. MIRA incorporates a Continuous-Time Rotary PositionalEncoding that enables fine-grained modeling of variable time intervals, afrequency-specific mixture-of-experts layer that routes computation acrosslatent frequency regimes to further promote temporal specialization, and aContinuous Dynamics Extrapolation Block based on Neural ODE that models thecontinuous trajectory of latent states, enabling accurate forecasting atarbitrary target timestamps. Pretrained on a large-scale and diverse medicalcorpus comprising over 454 billion time points collect from publicly availabledatasets, MIRA achieves reductions in forecasting errors by an average of 10%and 7% in out-of-distribution and in-distribution scenarios, respectively, whencompared to other zero-shot and fine-tuned baselines. We also introduce acomprehensive benchmark spanning multiple downstream clinical tasks,establishing a foundation for future research in medical time series modeling.</description>
      <author>example@mail.com (Hao Li, Bowen Deng, Chang Xu, Zhiyuan Feng, Viktor Schlegel, Yu-Hao Huang, Yizheng Sun, Jingyuan Sun, Kailai Yang, Yiyao Yu, Jiang Bian)</author>
      <guid isPermaLink="false">2506.07584v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>FANVID: A Benchmark for Face and License Plate Recognition in Low-Resolution Videos</title>
      <link>http://arxiv.org/abs/2506.07304v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了FANVID，一个基于视频的基准数据集，旨在提升低分辨率视频中的时间和空间识别能力。&lt;h4&gt;背景&lt;/h4&gt;现实世界的监控视频中，由于低分辨率和干扰因素，人脸和车牌往往难以识别。&lt;h4&gt;目的&lt;/h4&gt;提出FANVID数据集，旨在提高时间和空间识别模型在低分辨率视频中的识别准确率。&lt;h4&gt;方法&lt;/h4&gt;FANVID包含近1,463个低分辨率视频片段，包括来自三个英语国家的人脸和车牌，并包含干扰元素，以提高任务难度和真实性。数据集包含31,096个手动验证的边界框和标签。数据集定义了两个任务：人脸匹配和车牌识别。视频从高分辨率源下采样，以确保单帧中的人脸和文本难以识别，需要模型利用时间信息。引入了适应于IoU &gt; 0.5的平均精度等评估指标。&lt;h4&gt;主要发现&lt;/h4&gt;基线方法在人脸匹配和车牌识别任务中分别取得了0.58和0.42的分数，显示了任务的可行性和挑战。FANVID在人脸和车牌的选择上平衡了多样性和识别难度。&lt;h4&gt;结论&lt;/h4&gt;FANVID旨在促进低分辨率识别的时序建模创新，并在监控、法医学和自动驾驶等领域具有应用前景。&lt;h4&gt;翻译&lt;/h4&gt;Real-world surveillance often renders faces and license plates unrecognizable in individual low-resolution (LR) frames, hindering reliable identification. To advance temporal recognition models, we present FANVID, a novel video-based benchmark comprising nearly 1,463 LR clips (180 x 320, 20--60 FPS) featuring 63 identities and 49 license plates from three English-speaking countries. Each video includes distractor faces and plates, increasing task difficulty and realism. The dataset contains 31,096 manually verified bounding boxes and labels. FANVID defines two tasks: (1) face matching -- detecting LR faces and matching them to high-resolution mugshots, and (2) license plate recognition -- extracting text from LR plates without a predefined database. Videos are downsampled from high-resolution sources to ensure that faces and text are indecipherable in single frames, requiring models to exploit temporal information. We introduce evaluation metrics adapted from mean Average Precision at IoU &gt; 0.5, prioritizing identity correctness for faces and character-level accuracy for text. A baseline method with pre-trained video super-resolution, detection, and recognition achieved performance scores of 0.58 (face matching) and 0.42 (plate recognition), highlighting both the feasibility and challenge of the tasks. FANVID's selection of faces and plates balances diversity with recognition challenge. We release the software for data access, evaluation, baseline, and annotation to support reproducibility and extension. FANVID aims to catalyze innovation in temporal modeling for LR recognition, with applications in surveillance, forensics, and autonomous vehicles.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world surveillance often renders faces and license plates unrecognizablein individual low-resolution (LR) frames, hindering reliable identification. Toadvance temporal recognition models, we present FANVID, a novel video-basedbenchmark comprising nearly 1,463 LR clips (180 x 320, 20--60 FPS) featuring 63identities and 49 license plates from three English-speaking countries. Eachvideo includes distractor faces and plates, increasing task difficulty andrealism. The dataset contains 31,096 manually verified bounding boxes andlabels.  FANVID defines two tasks: (1) face matching -- detecting LR faces andmatching them to high-resolution mugshots, and (2) license plate recognition --extracting text from LR plates without a predefined database. Videos aredownsampled from high-resolution sources to ensure that faces and text areindecipherable in single frames, requiring models to exploit temporalinformation. We introduce evaluation metrics adapted from mean AveragePrecision at IoU &gt; 0.5, prioritizing identity correctness for faces andcharacter-level accuracy for text.  A baseline method with pre-trained video super-resolution, detection, andrecognition achieved performance scores of 0.58 (face matching) and 0.42 (platerecognition), highlighting both the feasibility and challenge of the tasks.FANVID's selection of faces and plates balances diversity with recognitionchallenge. We release the software for data access, evaluation, baseline, andannotation to support reproducibility and extension. FANVID aims to catalyzeinnovation in temporal modeling for LR recognition, with applications insurveillance, forensics, and autonomous vehicles.</description>
      <author>example@mail.com (Kavitha Viswanathan, Vrinda Goel, Shlesh Gholap, Devayan Ghosh, Madhav Gupta, Dhruvi Ganatra, Sanket Potdar, Amit Sethi)</author>
      <guid isPermaLink="false">2506.07304v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Technical Report for ICRA 2025 GOOSE 3D Semantic Segmentation Challenge: Adaptive Point Cloud Understanding for Heterogeneous Robotic Systems</title>
      <link>http://arxiv.org/abs/2506.06995v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Winner of the GOOSE 3D Semantic Segmentation Challenge at the IEEE  ICRA Workshop on Field Robotics 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本技术报告介绍了ICRA 2025 GOOSE 3D语义分割挑战的解决方案实现细节。&lt;h4&gt;背景&lt;/h4&gt;该挑战聚焦于从多个机器人平台收集的多种非结构化室外环境中3D点云的语义分割。&lt;h4&gt;目的&lt;/h4&gt;通过实现点提示调整（Point Prompt Tuning）与点变换器v3（Point Transformer v3，PTv3）骨干网络的集成，解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;采用平台特定的条件化和跨数据集类别对齐策略，使模型能够自适应处理异构的LiDAR数据，且训练过程中无需额外外部数据。&lt;h4&gt;主要发现&lt;/h4&gt;与基线PTv3模型相比，该方法在具有挑战性的平台上实现了显著的性能提升，mIoU提高了高达22.59%，证明了自适应点云理解在场地机器人应用中的有效性。&lt;h4&gt;结论&lt;/h4&gt;自适应点云理解方法在处理非结构化室外环境的3D点云语义分割时，表现出了良好的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report presents the implementation details of the winningsolution for the ICRA 2025 GOOSE 3D Semantic Segmentation Challenge. Thischallenge focuses on semantic segmentation of 3D point clouds from diverseunstructured outdoor environments collected from multiple robotic platforms.This problem was addressed by implementing Point Prompt Tuning (PPT) integratedwith Point Transformer v3 (PTv3) backbone, enabling adaptive processing ofheterogeneous LiDAR data through platform-specific conditioning andcross-dataset class alignment strategies. The model is trained withoutrequiring additional external data. As a result, this approach achievedsubstantial performance improvements with mIoU increases of up to 22.59% onchallenging platforms compared to the baseline PTv3 model, demonstrating theeffectiveness of adaptive point cloud understanding for field roboticsapplications.</description>
      <author>example@mail.com (Xiaoya Zhang)</author>
      <guid isPermaLink="false">2506.06995v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Technical Report: A Practical Guide to Kaldi ASR Optimization</title>
      <link>http://arxiv.org/abs/2506.07149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本技术报告介绍了针对基于Kaldi的自动语音识别（ASR）系统的创新优化，重点关注声学模型增强、超参数调整和语言模型效率。&lt;h4&gt;背景&lt;/h4&gt;报告背景是Kaldi的自动语音识别技术。&lt;h4&gt;目的&lt;/h4&gt;目的是通过优化提高ASR的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;方法包括开发自定义的Conformer块与多流TDNN-F结构集成，采用高级数据增强技术和动态超参数优化，以及使用贝叶斯优化和n-gram剪枝进行语言模型管理。&lt;h4&gt;主要发现&lt;/h4&gt;这些系统性的改进显著提高了ASR的准确性和鲁棒性，优于现有方法，并为多种语音识别场景提供了可扩展的解决方案。&lt;h4&gt;结论&lt;/h4&gt;报告强调了战略优化在保持Kaldi适应性和竞争力中的重要性，特别是在快速发展的技术环境中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report introduces innovative optimizations for Kaldi-basedAutomatic Speech Recognition (ASR) systems, focusing on acoustic modelenhancement, hyperparameter tuning, and language model efficiency. We developeda custom Conformer block integrated with a multistream TDNN-F structure,enabling superior feature extraction and temporal modeling. Our approachincludes advanced data augmentation techniques and dynamic hyperparameteroptimization to boost performance and reduce overfitting. Additionally, wepropose robust strategies for language model management, employing Bayesianoptimization and $n$-gram pruning to ensure relevance and computationalefficiency. These systematic improvements significantly elevate ASR accuracyand robustness, outperforming existing methods and offering a scalable solutionfor diverse speech recognition scenarios. This report underscores theimportance of strategic optimizations in maintaining Kaldi's adaptability andcompetitiveness in rapidly evolving technological landscapes.</description>
      <author>example@mail.com (Mengze Hong, Di Jiang)</author>
      <guid isPermaLink="false">2506.07149v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>AnnoDPO: Protein Functional Annotation Learning with Direct Preference Optimization</title>
      <link>http://arxiv.org/abs/2506.07035v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AnnoDPO的新型多模态框架，用于蛋白质功能预测，通过直接偏好优化（DPO）来增强注释学习，解决了注释稀缺和类别不平衡的双重挑战。&lt;h4&gt;背景&lt;/h4&gt;蛋白质功能解析是蛋白质表示学习中的基本挑战，由于功能注释类别众多且注释实例在生物分类学中的分布高度不平衡，蛋白质语言模型（PLM）面临重大困难。&lt;h4&gt;目的&lt;/h4&gt;提出AnnoDPO框架，旨在通过直接偏好优化（DPO）提高注释学习，以解决蛋白质功能预测中的注释稀缺和类别不平衡问题。&lt;h4&gt;方法&lt;/h4&gt;AnnoDPO框架利用偏好对齐的训练目标，结合强化学习从人类反馈（RLHF）在大型语言模型（LLM）对齐中的成功经验。&lt;h4&gt;主要发现&lt;/h4&gt;AnnoDPO通过偏好对齐的训练目标解决了注释稀缺和类别不平衡的挑战，为蛋白质表示学习中的生物知识整合建立了一种新的范式。&lt;h4&gt;结论&lt;/h4&gt;AnnoDPO框架为蛋白质功能预测提供了一种有效的方法，有助于克服注释稀缺和类别不平衡的问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要：解析蛋白质功能仍然是蛋白质表示学习中的一个基本挑战。这项任务对蛋白质语言模型（PLMs）来说具有重大困难，因为功能注释类别众多，且注释实例在生物分类学中的分布高度不平衡。受大型语言模型（LLM）对齐中强化学习从人类反馈（RLHF）取得的显著成功的启发，我们提出了AnnoDPO，这是一种新颖的多模态蛋白质功能预测框架，它利用直接偏好优化（DPO）来增强注释学习。我们的方法通过偏好对齐的训练目标解决了注释稀缺和类别不平衡的双重挑战，为蛋白质表示学习中的生物知识整合建立了一种新的范式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deciphering protein function remains a fundamental challenge in proteinrepresentation learning. The task presents significant difficulties for proteinlanguage models (PLMs) due to the sheer volume of functional annotationcategories and the highly imbalanced distribution of annotated instances acrossbiological ontologies. Inspired by the remarkable success of reinforcementlearning from human feedback (RLHF) in large language model (LLM) alignment, wepropose AnnoDPO, a novel multi-modal framework for protein function predictionthat leverages Direct Preference Optimization (DPO) to enhance annotationlearning. Our methodology addresses the dual challenges of annotation scarcityand category imbalance through preference-aligned training objectives,establishing a new paradigm for biological knowledge integration in proteinrepresentation learning.</description>
      <author>example@mail.com (Zixuan Jiang, Renjing Xu)</author>
      <guid isPermaLink="false">2506.07035v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Textile Analysis for Recycling Automation using Transfer Learning and Zero-Shot Foundation Models</title>
      <link>http://arxiv.org/abs/2506.06569v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用标准RGB图像进行自动化系统中的关键预处理任务，以提高纺织品回收的效率和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;准确识别材料成分和检测传感器数据中的污染物对于自动化纺织品回收至关重要，但这是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;探索使用RGB图像和现代深度学习技术，包括迁移学习和基础模型，来实现自动化纺织品回收流程的关键分析步骤。&lt;h4&gt;方法&lt;/h4&gt;开发了计算机视觉组件，用于传送带设置，以执行(a)四种常见纺织品类型的分类和(b)按钮和拉链等非纺织品特征的分割。&lt;h4&gt;主要发现&lt;/h4&gt;使用迁移学习和交叉验证评估了几个预训练架构，EfficientNetB0在保留测试集上达到了81.25%的准确率。对于特征分割，结合Grounding DINO开放词汇检测器和Segment Anything Model (SAM)的零样本方法表现出色，生成的掩码与真实值的mIoU达到0.90。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了使用RGB图像与现代深度学习技术相结合的可行性，以实现自动化纺织品回收流程的关键分析步骤。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated sorting is crucial for improving the efficiency and scalability oftextile recycling, but accurately identifying material composition anddetecting contaminants from sensor data remains challenging. This paperinvestigates the use of standard RGB imagery, a cost-effective sensingmodality, for key pre-processing tasks in an automated system. We presentcomputer vision components designed for a conveyor belt setup to perform (a)classification of four common textile types and (b) segmentation of non-textilefeatures such as buttons and zippers. For classification, several pre-trainedarchitectures were evaluated using transfer learning and cross-validation, withEfficientNetB0 achieving the best performance on a held-out test set with81.25\% accuracy. For feature segmentation, a zero-shot approach combining theGrounding DINO open-vocabulary detector with the Segment Anything Model (SAM)was employed, demonstrating excellent performance with a mIoU of 0.90 for thegenerated masks against ground truth. This study demonstrates the feasibilityof using RGB images coupled with modern deep learning techniques, includingtransfer learning for classification and foundation models for zero-shotsegmentation, to enable essential analysis steps for automated textilerecycling pipelines.</description>
      <author>example@mail.com (Yannis Spyridis, Vasileios Argyriou)</author>
      <guid isPermaLink="false">2506.06569v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>GGBall: Graph Generative Model on Poincaré Ball</title>
      <link>http://arxiv.org/abs/2506.07198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GGBall的新型超曲率框架，用于生成具有层次结构的图，以解决欧几里得几何在捕捉指数复杂性方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;生成具有层次结构的图是一个基本挑战，因为欧几里得几何无法有效地捕捉指数复杂性。&lt;h4&gt;目的&lt;/h4&gt;引入GGBall，以解决上述问题，并通过结合几何归纳偏见和现代生成范式来生成具有层次结构的图。&lt;h4&gt;方法&lt;/h4&gt;GGBall结合了超曲率向量量化自动编码器（HVQVAE）和通过闭形式测地线定义的黎曼流匹配先验。此外，还开发了一套在流形上操作的超曲率图神经网络（GNN）和Transformer层。&lt;h4&gt;主要发现&lt;/h4&gt;与最先进的基线相比，GGBall在Community-Small上减少了超过75%的度MMD，在Ego-Small上减少了超过40%，这表明其能够更好地保留拓扑层次结构。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，超曲率几何可以作为复杂、结构化和层次化数据域生成建模的强大基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成具有层次结构的图仍然是一个基本挑战，因为欧几里得几何在捕捉指数复杂性方面存在局限性。在这里，我们引入了GGBall，这是一种用于图生成的新型超曲率框架，它结合了几何归纳偏见与现代生成范式。GGBall结合了超曲率向量量化自动编码器（HVQVAE）和通过闭形式测地线定义的黎曼流匹配先验。这种设计使得基于流的先验能够模拟复杂的潜在分布，而向量量化有助于保留超曲率空间的曲率感知结构。我们进一步开发了一套在流形上操作的超曲率图神经网络（GNN）和Transformer层，确保了稳定性和可扩展性。从经验上看，我们的模型在Community-Small上减少了超过75%的度MMD，在Ego-Small上减少了超过40%，与最先进的基线相比，这表明了其能够更好地保留拓扑层次结构。这些结果突出了超曲率几何作为复杂、结构化和层次化数据域生成建模的强大基础。我们的代码可在https://github.com/AI4Science-WestlakeU/GGBall处获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating graphs with hierarchical structures remains a fundamentalchallenge due to the limitations of Euclidean geometry in capturing exponentialcomplexity. Here we introduce \textbf{GGBall}, a novel hyperbolic framework forgraph generation that integrates geometric inductive biases with moderngenerative paradigms. GGBall combines a Hyperbolic Vector-Quantized Autoencoder(HVQVAE) with a Riemannian flow matching prior defined via closed-formgeodesics. This design enables flow-based priors to model complex latentdistributions, while vector quantization helps preserve the curvature-awarestructure of the hyperbolic space. We further develop a suite of hyperbolic GNNand Transformer layers that operate entirely within the manifold, ensuringstability and scalability. Empirically, our model reduces degree MMD by over75\% on Community-Small and over 40\% on Ego-Small compared to state-of-the-artbaselines, demonstrating an improved ability to preserve topologicalhierarchies. These results highlight the potential of hyperbolic geometry as apowerful foundation for the generative modeling of complex, structured, andhierarchical data domains. Our code is available at\href{https://github.com/AI4Science-WestlakeU/GGBall}{here}.</description>
      <author>example@mail.com (Tianci Bu, Chuanrui Wang, Hao Ma, Haoren Zheng, Xin Lu, Tailin Wu)</author>
      <guid isPermaLink="false">2506.07198v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Learning Robust Heterogeneous Graph Representations via Contrastive-Reconstruction under Sparse Semantics</title>
      <link>http://arxiv.org/abs/2506.06682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HetCRF的新型双通道自监督学习框架，用于异构图的自监督学习。&lt;h4&gt;背景&lt;/h4&gt;图自监督学习中，掩码自编码器（MAE）和对比学习（CL）是两种主要范式。MAE擅长局部特征捕获，而CL擅长全局信息提取。现有的混合框架在共享编码器设计上面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出HetCRF框架，以适应MAE和CL的需求，并解决语义稀疏场景中的问题。&lt;h4&gt;方法&lt;/h4&gt;HetCRF采用两阶段聚合策略来适应嵌入语义，并通过增强编码器输出以提高视图构建的效率。同时，提出了两种正样本增强策略以平衡梯度贡献。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界异构图数据集上的节点分类实验表明，HetCRF优于现有基线。在节点特征缺失的数据集上，如Aminer和Freebase，在40%的标签率下，HetCRF将Macro-F1分数分别提高了2.75%和2.2%，验证了其有效性和优越性。&lt;h4&gt;结论&lt;/h4&gt;HetCRF是一种有效的异构图自监督学习框架，能够提高节点分类的性能，特别是在节点特征缺失的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In graph self-supervised learning, masked autoencoders (MAE) and contrastivelearning (CL) are two prominent paradigms. MAE focuses on reconstructing maskedelements, while CL maximizes similarity between augmented graph views. Recentstudies highlight their complementarity: MAE excels at local feature capture,and CL at global information extraction. Hybrid frameworks for homogeneousgraphs have been proposed, but face challenges in designing shared encoders tomeet the semantic requirements of both tasks. In semantically sparse scenarios,CL struggles with view construction, and gradient imbalance between positiveand negative samples persists. This paper introduces HetCRF, a noveldual-channel self-supervised learning framework for heterogeneous graphs.HetCRF uses a two-stage aggregation strategy to adapt embedding semantics,making it compatible with both MAE and CL. To address semantic sparsity, itenhances encoder output for view construction instead of relying on rawfeatures, improving efficiency. Two positive sample augmentation strategies arealso proposed to balance gradient contributions. Node classificationexperiments on four real-world heterogeneous graph datasets demonstrate thatHetCRF outperforms state-of-the-art baselines. On datasets with missing nodefeatures, such as Aminer and Freebase, at a 40% label rate in nodeclassification, HetCRF improves the Macro-F1 score by 2.75% and 2.2%respectively compared to the second-best baseline, validating its effectivenessand superiority.</description>
      <author>example@mail.com (Di Lin, Wanjing Ren, Xuanbin Li, Rui Zhang)</author>
      <guid isPermaLink="false">2506.06682v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>GeometryZero: Improving Geometry Solving for LLM with Group Contrastive Policy Optimization</title>
      <link>http://arxiv.org/abs/2506.07160v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为GeometryZero的几何推理模型系列，通过改进的强化学习框架GCPO，实现了在几何推理领域的高效性能。&lt;h4&gt;背景&lt;/h4&gt;大语言模型在数学推理方面表现出色，其中几何问题解决是一个具有挑战性的领域，辅助构造在其中起着关键作用。现有的方法要么性能不佳，要么依赖于大规模的LLMs，导致巨大的计算成本。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的强化学习框架，以训练能够有效结合辅助构造和稳健几何推理的小型模型。&lt;h4&gt;方法&lt;/h4&gt;提出了GCPO框架，包含两个关键创新：(1)组对比掩码，根据上下文效用自适应地提供正负奖励信号；(2)长度奖励，促进更长的推理链。基于GCPO，开发了GeometryZero模型系列。&lt;h4&gt;主要发现&lt;/h4&gt;在多个几何基准测试（如Geometry3K、MathVista）中，GeometryZero模型在所有基准测试中都优于基线（如GRPO），平均改进率为4.29%。&lt;h4&gt;结论&lt;/h4&gt;GeometryZero模型通过改进的强化学习框架有效地实现了几何推理，并在实际应用中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，大型语言模型（LLMs）在多个领域展现了显著的能力，特别是在数学推理方面。其中，几何问题解决是一个具有挑战性的领域，辅助构造在其中起着关键作用。现有的方法要么性能不佳，要么依赖于大规模的LLMs（例如GPT-4o），导致巨大的计算成本。我们认为，基于可验证奖励的强化学习（例如GRPO）为训练结合辅助构造与稳健几何推理的小型模型提供了一个有希望的方向。然而，由于对无条件奖励的依赖，直接将GRPO应用于几何推理存在根本性的限制，这会导致无差别且低效的辅助构造。为了解决这些挑战，我们提出了组对比策略优化（GCPO），这是一个具有两个关键创新的强化学习框架：(1)组对比掩码，根据上下文效用自适应地提供正或负奖励信号；(2)长度奖励，促进更长的推理链。在GCPO的基础上，我们开发了GeometryZero，这是一系列可负担规模的几何推理模型，能够明智地决定何时使用辅助构造。我们在流行的几何基准（Geometry3K、MathVista）上进行了广泛的实证评估，结果表明，GeometryZero模型在所有基准测试中均优于基线（例如GRPO），平均改进率为4.29%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in large language models (LLMs) have demonstrated remarkablecapabilities across diverse domains, particularly in mathematical reasoning,amid which geometry problem solving remains a challenging area where auxiliaryconstruction plays a enssential role. Existing approaches either achievesuboptimal performance or rely on massive LLMs (e.g., GPT-4o), incurringmassive computational costs. We posit that reinforcement learning withverifiable reward (e.g., GRPO) offers a promising direction for trainingsmaller models that effectively combine auxiliary construction with robustgeometric reasoning. However, directly applying GRPO to geometric reasoningpresents fundamental limitations due to its dependence on unconditionalrewards, which leads to indiscriminate and counterproductive auxiliaryconstructions. To address these challenges, we propose Group Contrastive PolicyOptimization (GCPO), a novel reinforcement learning framework featuring two keyinnovations: (1) Group Contrastive Masking, which adaptively provides positiveor negative reward signals for auxiliary construction based on contextualutility, and a (2) length reward that promotes longer reasoning chains.Building on GCPO, we develop GeometryZero, a family of affordable-sizegeometric reasoning models that judiciously determine when to employ auxiliaryconstruction. Our extensive empirical evaluation across popular geometricbenchmarks (Geometry3K, MathVista) demonstrates that GeometryZero modelsconsistently outperform baselines (e.g. GRPO), achieving an average improvementof 4.29% across all benchmarks.</description>
      <author>example@mail.com (Yikun Wang, Yibin Wang, Dianyi Wang, Zimian Peng, Qipeng Guo, Dacheng Tao, Jiaqi Wang)</author>
      <guid isPermaLink="false">2506.07160v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Guiding Cross-Modal Representations with MLLM Priors via Preference Alignment</title>
      <link>http://arxiv.org/abs/2506.06970v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MAPLE的新框架，用于跨模态表示学习，通过利用MLLM的内在模态对齐特性来缩小模态差距。&lt;h4&gt;背景&lt;/h4&gt;尽管CLIP在跨模态内容检索方面表现出色，但模态特征空间中仍存在显著的模态差距。&lt;h4&gt;目的&lt;/h4&gt;提出MAPLE框架，旨在通过细粒度对齐先验来指导跨模态表示学习。&lt;h4&gt;方法&lt;/h4&gt;MAPLE框架利用了现成的MLLM来构建自动偏好数据，并引入了一种新的相对偏好对齐（RPA）损失函数，该函数将直接偏好优化（DPO）应用于嵌入学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MAPLE框架在细粒度跨模态检索中取得了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;MAPLE框架在处理细微语义区分方面非常有效。&lt;h4&gt;翻译&lt;/h4&gt;Despite Contrastive Language-Image Pretraining (CLIP)'s remarkable capability to retrieve content across modalities, a substantial modality gap persists in its feature space. Intriguingly, we discover that off-the-shelf MLLMs (Multimodal Large Language Models) demonstrate powerful inherent modality alignment properties. While recent MLLM-based retrievers with unified architectures partially mitigate this gap, their reliance on coarse modality alignment mechanisms fundamentally limits their potential. In this work, We introduce MAPLE (Modality-Aligned Preference Learning for Embeddings), a novel framework that leverages the fine grained alignment priors inherent in MLLM to guide cross modal representation learning. MAPLE formulates the learning process as reinforcement learning with two key components: (1) Automatic preference data construction using off-the-shelf MLLM, and (2) a new Relative Preference Alignment (RPA) loss, which adapts Direct Preference Optimization (DPO) to the embedding learning setting. Experimental results show that our preference-guided alignment achieves substantial gains in fine-grained cross-modal retrieval, underscoring its effectiveness in handling nuanced semantic distinctions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite Contrastive Language-Image Pretraining (CLIP)'s remarkable capabilityto retrieve content across modalities, a substantial modality gap persists inits feature space. Intriguingly, we discover that off-the-shelf MLLMs(Multimodal Large Language Models) demonstrate powerful inherent modalityalignment properties. While recent MLLM-based retrievers with unifiedarchitectures partially mitigate this gap, their reliance on coarse modalityalignment mechanisms fundamentally limits their potential. In this work, Weintroduce MAPLE (Modality-Aligned Preference Learning for Embeddings), a novelframework that leverages the fine grained alignment priors inherent in MLLM toguide cross modal representation learning. MAPLE formulates the learningprocess as reinforcement learning with two key components: (1) Automaticpreference data construction using off-the-shelf MLLM, and (2) a new RelativePreference Alignment (RPA) loss, which adapts Direct Preference Optimization(DPO) to the embedding learning setting. Experimental results show that ourpreference-guided alignment achieves substantial gains in fine-grainedcross-modal retrieval, underscoring its effectiveness in handling nuancedsemantic distinctions.</description>
      <author>example@mail.com (Pengfei Zhao, Rongbo Luan, Wei Zhang, Peng Wu, Sifeng He)</author>
      <guid isPermaLink="false">2506.06970v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Prime the search: Using large language models for guiding geometric task and motion planning by warm-starting tree search</title>
      <link>http://arxiv.org/abs/2506.07062v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The International Journal of Robotics Research (IJRR)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用大型语言模型（LLMs）指导几何任务与运动规划（G-TAMP）问题的方法，通过设计基于谓词的提示来帮助LLMs进行几何推理，并结合蒙特卡洛树搜索（MCTS）进行任务规划。&lt;h4&gt;背景&lt;/h4&gt;G-TAMP问题通常需要大量计算资源或数据来指导搜索，而人类通过常识直觉解决问题。传统方法依赖于领域无关的启发式或从规划经验中学习。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用LLMs的G-TAMP问题解决方法，以减少计算资源需求。&lt;h4&gt;方法&lt;/h4&gt;设计基于谓词的提示帮助LLMs进行几何推理，结合MCTS进行任务规划，并使用LLMs引导搜索过程。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在六个不同的G-TAMP问题上优于之前的LLM规划器和纯搜索算法。&lt;h4&gt;结论&lt;/h4&gt;LLMs可以有效地指导G-TAMP问题的任务规划，结合MCTS可以进一步提高搜索效率。&lt;h4&gt;翻译&lt;/h4&gt;The problem of relocating a set of objects to designated areas amidst movable obstacles can be framed as a Geometric Task and Motion Planning (G-TAMP) problem, a subclass of task and motion planning (TAMP). Traditional approaches to G-TAMP have relied either on domain-independent heuristics or on learning from planning experience to guide the search, both of which typically demand significant computational resources or data. In contrast, humans often use common sense to intuitively decide which objects to manipulate in G-TAMP problems. Inspired by this, we propose leveraging Large Language Models (LLMs), which have common sense knowledge acquired from internet-scale data, to guide task planning in G-TAMP problems. To enable LLMs to perform geometric reasoning, we design a predicate-based prompt that encodes geometric information derived from a motion planning algorithm. We then query the LLM to generate a task plan, which is then used to search for a feasible set of continuous parameters. Since LLMs are prone to mistakes, instead of committing to LLM's outputs, we extend Monte Carlo Tree Search (MCTS) to a hybrid action space and use the LLM to guide the search. Unlike the previous approach that calls an LLM at every node and incurs high computational costs, we use it to warm-start the MCTS with the nodes explored in completing the LLM's task plan. On six different G-TAMP problems, we show our method outperforms previous LLM planners and pure search algorithms. Code can be found at: https://github.com/iMSquared/prime-the-search&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1177/02783649251347307&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The problem of relocating a set of objects to designated areas amidst movableobstacles can be framed as a Geometric Task and Motion Planning (G-TAMP)problem, a subclass of task and motion planning (TAMP). Traditional approachesto G-TAMP have relied either on domain-independent heuristics or on learningfrom planning experience to guide the search, both of which typically demandsignificant computational resources or data. In contrast, humans often usecommon sense to intuitively decide which objects to manipulate in G-TAMPproblems. Inspired by this, we propose leveraging Large Language Models (LLMs),which have common sense knowledge acquired from internet-scale data, to guidetask planning in G-TAMP problems. To enable LLMs to perform geometricreasoning, we design a predicate-based prompt that encodes geometricinformation derived from a motion planning algorithm. We then query the LLM togenerate a task plan, which is then used to search for a feasible set ofcontinuous parameters. Since LLMs are prone to mistakes, instead of committingto LLM's outputs, we extend Monte Carlo Tree Search (MCTS) to a hybrid actionspace and use the LLM to guide the search. Unlike the previous approach thatcalls an LLM at every node and incurs high computational costs, we use it towarm-start the MCTS with the nodes explored in completing the LLM's task plan.On six different G-TAMP problems, we show our method outperforms previous LLMplanners and pure search algorithms. Code can be found at:https://github.com/iMSquared/prime-the-search</description>
      <author>example@mail.com (Dongryung Lee, Sejune Joo, Kimin Lee, Beomjoon Kim)</author>
      <guid isPermaLink="false">2506.07062v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>MAGNet: A Multi-Scale Attention-Guided Graph Fusion Network for DRC Violation Detection</title>
      <link>http://arxiv.org/abs/2506.07126v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 12 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MAGNet的混合深度学习模型，用于集成电路设计的DRC违规预测，通过结合U-Net和图神经网络来提高DRC的热点检测准确性。&lt;h4&gt;背景&lt;/h4&gt;DRC对于集成电路设计的成本降低和设计效率提升具有重要意义，机器学习在计算机辅助设计（CAD）中扮演着重要角色。&lt;h4&gt;目的&lt;/h4&gt;旨在通过MAGNet模型提高DRC违规预测的准确性和减少误报率。&lt;h4&gt;方法&lt;/h4&gt;MAGNet模型通过增强U-Net的动态注意力模块（DAM）和多尺度卷积模块（MSCM）来提取精细和多尺度的空间特征。同时，基于芯片布局的图结构，应用专用图神经网络（GNN）来模拟引脚之间的拓扑关系。在图构建过程中，生成图到网格的映射以对齐GNN特征和布局图像。此外，在训练期间采用标签增强策略以提高模型对稀疏违规模式的敏感性。&lt;h4&gt;主要发现&lt;/h4&gt;MAGNet有效结合了空间、语义和结构信息，在DRC热点检测中实现了更高的预测准确性和更低的误报率。通过增量训练，模型对热点的区分能力进一步增强。&lt;h4&gt;结论&lt;/h4&gt;MAGNet在整体性能上显著优于ibUnet、RouteNet和J-Net等模型，实现了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：设计规则检查（DRC）在集成电路（IC）设计中对于降低成本和提高设计效率具有重大意义。基于机器学习的DRC已成为计算机辅助设计（CAD）中的重要方法。在本文中，我们提出了一种名为MAGNet的混合深度学习模型，它集成了一个改进的U-Net和一个图神经网络，用于DRC违规预测。U-Net主干通过动态注意力模块（DAM）和多尺度卷积模块（MSCM）的增强来加强其提取细粒度和多尺度空间特征的能力。同时，基于芯片布局的图结构，应用专用图神经网络（GNN）来模拟引脚之间的拓扑关系。在图构建过程中，生成图到网格的映射以对齐GNN特征和布局图像。此外，在训练期间采用标签增强策略以提高模型对稀疏违规模式的敏感性。总体而言，MAGNet有效地结合了空间、语义和结构信息，在DRC热点检测中实现了提高的预测准确性和降低的误报率。随后，通过增量训练，实现了对热点更敏感的区分能力。结果表明，与ibUnet、RouteNet和J-Net相比，MAGnet在这些模型中表现显著优于，实现了整体性能的显著提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Design rule checking (DRC) is of great significance for cost reduction anddesign efficiency improvement in integrated circuit (IC) designs.Machine-learning-based DRC has become an important approach in computer-aideddesign (CAD). In this paper, we propose MAGNet, a hybrid deep learning modelthat integrates an improved U-Net with a graph neural network for DRC violationprediction. The U-Net backbone is enhanced with a Dynamic Attention Module(DAM) and a Multi-Scale Convolution Module (MSCM) to strengthen its capabilityin extracting fine-grained and multi-scale spatial features. In parallel, weconstruct a pixel-aligned graph structure based on chip layout tiles, and applya specialized GNN to model the topological relationships among pins. Duringgraph construction, a graph-to-grid mapping is generated to align GNN featureswith the layout image. In addition, a label amplification strategy is adoptedduring training to enhance the model's sensitivity to sparse violationpatterns. Overall, MAGNet effectively combines spatial, semantic, andstructural information, achieving improved prediction accuracy and reducedfalse positive rates in DRC hotspot detection. Subsequently, throughincremental training, we achieve a more sensitive discrimination ability forhotspots. The results demonstrate that, in comparison with ibUnet, RouteNet,and J-Net, MAGnet significantly outperforms these models, achieving substantialimprovements in overall performance.</description>
      <author>example@mail.com (Weihan Lu, Hong Cai Chen)</author>
      <guid isPermaLink="false">2506.07126v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Cross-channel Perception Learning for H&amp;E-to-IHC Virtual Staining</title>
      <link>http://arxiv.org/abs/2506.07559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CCPL的新型跨通道感知学习策略，用于数字病理学中的虚拟染色，以改善病理图像的分析和诊断。&lt;h4&gt;背景&lt;/h4&gt;随着数字病理学的快速发展，虚拟染色成为多媒体医学信息系统中的一项关键技术。然而，现有的H&amp;E到IHC研究往往忽略了细胞核和细胞膜之间的跨通道相关性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，提出了CCPL策略，以改善虚拟染色图像的质量，并支持自动病理诊断。&lt;h4&gt;方法&lt;/h4&gt;CCPL首先将HER2免疫组织化学染色分解为对应细胞核和细胞膜的Hematoxylin和DAB染色通道。利用Gigapath的Tile Encoder提取双通道特征，并测量核和膜之间的跨通道相关性。同时，通过Tile Encoder计算生成和真实染色图像的特征蒸馏损失，增强模型特征提取能力。此外，CCPL对单通道的焦点光学密度图进行统计分析，以确保染色分布和强度的统一。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CCPL有效地保留了病理特征，生成了高质量的虚拟染色图像，并为使用多媒体医学数据进行的自动病理诊断提供了强有力的支持。&lt;h4&gt;结论&lt;/h4&gt;CCPL是一种有效的虚拟染色技术，能够提高病理图像分析的诊断准确性，为病理学领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of digital pathology, virtual staining has becomea key technology in multimedia medical information systems, offering newpossibilities for the analysis and diagnosis of pathological images. However,existing H&amp;E-to-IHC studies often overlook the cross-channel correlationsbetween cell nuclei and cell membranes. To address this issue, we propose anovel Cross-Channel Perception Learning (CCPL) strategy. Specifically, CCPLfirst decomposes HER2 immunohistochemical staining into Hematoxylin and DABstaining channels, corresponding to cell nuclei and cell membranes,respectively. Using the pathology foundation model Gigapath's Tile Encoder,CCPL extracts dual-channel features from both the generated and real images andmeasures cross-channel correlations between nuclei and membranes. The featuresof the generated and real stained images, obtained through the Tile Encoder,are also used to calculate feature distillation loss, enhancing the model'sfeature extraction capabilities without increasing the inference burden.Additionally, CCPL performs statistical analysis on the focal optical densitymaps of both single channels to ensure consistency in staining distribution andintensity. Experimental results, based on quantitative metrics such as PSNR,SSIM, PCC, and FID, along with professional evaluations from pathologists,demonstrate that CCPL effectively preserves pathological features, generateshigh-quality virtual stained images, and provides robust support for automatedpathological diagnosis using multimedia medical data.</description>
      <author>example@mail.com (Hao Yang, JianYu Wu, Run Fang, Xuelian Zhao, Yuan Ji, Zhiyu Chen, Guibin He, Junceng Guo, Yang Liu, Xinhua Zeng)</author>
      <guid isPermaLink="false">2506.07559v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction</title>
      <link>http://arxiv.org/abs/2506.07002v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Two-page abstract version available at CVPR 2025 Embodied AI Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的3D占用预测方法BePo，用于场景理解，以支持自动驾驶。&lt;h4&gt;背景&lt;/h4&gt;现有的3D占用预测方法计算成本高，需要密集的3D特征体积和交叉注意力来有效聚合信息。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法的问题，BePo结合了鸟瞰图（BEV）和稀疏点表示。&lt;h4&gt;方法&lt;/h4&gt;BePo采用双分支设计：一个基于查询的稀疏点分支和一个BEV分支。稀疏点分支中学习的3D信息通过交叉注意力与BEV流共享，丰富了BEV平面上困难物体的弱信号。两个分支的输出最终融合以生成预测的3D占用。&lt;h4&gt;主要发现&lt;/h4&gt;在Occ3D-nuScenes和Occ3D-Waymo基准上进行的大量实验表明，BePo在性能上优于现有方法，并且在推理速度上与最新高效方法具有竞争力。&lt;h4&gt;结论&lt;/h4&gt;BePo是一种有效的3D占用预测方法，适用于自动驾驶和场景理解，同时保持了较高的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D occupancy provides fine-grained 3D geometry and semantics for sceneunderstanding which is critical for autonomous driving. Most existing methods,however, carry high compute costs, requiring dense 3D feature volume andcross-attention to effectively aggregate information. More recent works haveadopted Bird's Eye View (BEV) or sparse points as scene representation withmuch reduced cost, but still suffer from their respective shortcomings. Moreconcretely, BEV struggles with small objects that often experience significantinformation loss after being projected to the ground plane. On the other hand,points can flexibly model little objects in 3D, but is inefficient at capturingflat surfaces or large objects. To address these challenges, in this paper, wepresent a novel 3D occupancy prediction approach, BePo, which combines BEV andsparse points based representations. We propose a dual-branch design: aquery-based sparse points branch and a BEV branch. The 3D information learnedin the sparse points branch is shared with the BEV stream via cross-attention,which enriches the weakened signals of difficult objects on the BEV plane. Theoutputs of both branches are finally fused to generate predicted 3D occupancy.We conduct extensive experiments on the Occ3D-nuScenes and Occ3D-Waymobenchmarks that demonstrate the superiority of our proposed BePo. Moreover,BePo also delivers competitive inference speed when compared to the latestefficient approaches.</description>
      <author>example@mail.com (Yunxiao Shi, Hong Cai, Jisoo Jeong, Yinhao Zhu, Shizhong Han, Amin Ansari, Fatih Porikli)</author>
      <guid isPermaLink="false">2506.07002v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>A Culturally-diverse Multilingual Multimodal Video Benchmark &amp; Model</title>
      <link>http://arxiv.org/abs/2506.07032v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ViMUL-Bench，一个多语言视频多模态模型（LMM）基准，用于评估不同语言环境下的视频LMM性能。&lt;h4&gt;背景&lt;/h4&gt;现有的视频LMM大多使用英语，而多语言视频LMM的研究尚不充分。&lt;h4&gt;目的&lt;/h4&gt;开发一个多语言视频LMM基准，以促进文化语言包容性的视频LMM研究。&lt;h4&gt;方法&lt;/h4&gt;ViMUL-Bench包含14种语言的数据，涵盖15个类别，包括生活方式、节日、食物、仪式、地标和文化名人等。它包含开放式和多项选择题，视频时长从短到长，共有8k个样本，由母语者人工验证。此外，还引入了一个包含120万个样本的机器翻译多语言视频训练集，并开发了一个名为ViMUL的简单多语言视频LMM。&lt;h4&gt;主要发现&lt;/h4&gt;ViMUL-Bench和ViMUL多语言视频LMM有助于在不同资源语言之间提供更好的平衡，以实现视频理解。&lt;h4&gt;结论&lt;/h4&gt;ViMUL-Bench和相关的多语言视频LMM以及大规模多语言视频训练集将为未来研究文化语言包容性的多语言视频LMM提供便利。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译为中文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large multimodal models (LMMs) have recently gained attention due to theireffectiveness to understand and generate descriptions of visual content. Mostexisting LMMs are in English language. While few recent works exploremultilingual image LMMs, to the best of our knowledge, moving beyond theEnglish language for cultural and linguistic inclusivity is yet to beinvestigated in the context of video LMMs. In pursuit of more inclusive videoLMMs, we introduce a multilingual Video LMM benchmark, named ViMUL-Bench, toevaluate Video LMMs across 14 languages, including both low- and high-resourcelanguages: English, Chinese, Spanish, French, German, Hindi, Arabic, Russian,Bengali, Urdu, Sinhala, Tamil, Swedish, and Japanese. Our ViMUL-Bench isdesigned to rigorously test video LMMs across 15 categories including eightculturally diverse categories, ranging from lifestyles and festivals to foodsand rituals and from local landmarks to prominent cultural personalities.ViMUL-Bench comprises both open-ended (short and long-form) and multiple-choicequestions spanning various video durations (short, medium, and long) with 8ksamples that are manually verified by native language speakers. In addition, wealso introduce a machine translated multilingual video training set comprising1.2 million samples and develop a simple multilingual video LMM, named ViMUL,that is shown to provide a better tradeoff between high-and low-resourcelanguages for video understanding. We hope our ViMUL-Bench and multilingualvideo LMM along with a large-scale multilingual video training set will helpease future research in developing cultural and linguistic inclusivemultilingual video LMMs. Our proposed benchmark, video LMM and training datawill be publicly released at https://mbzuai-oryx.github.io/ViMUL/.</description>
      <author>example@mail.com (Bhuiyan Sanjid Shafique, Ashmal Vayani, Muhammad Maaz, Hanoona Abdul Rasheed, Dinura Dissanayake, Mohammed Irfan Kurpath, Yahya Hmaiti, Go Inoue, Jean Lahoud, Md. Safirur Rashid, Shadid Intisar Quasem, Maheen Fatima, Franco Vidal, Mykola Maslych, Ketan Pravin More, Sanoojan Baliah, Hasindri Watawana, Yuhao Li, Fabian Farestam, Leon Schaller, Roman Tymtsiv, Simon Weber, Hisham Cholakkal, Ivan Laptev, Shin'ichi Satoh, Michael Felsberg, Mubarak Shah, Salman Khan, Fahad Shahbaz Khan)</author>
      <guid isPermaLink="false">2506.07032v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Full Conformal Adaptation of Medical Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.06076v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IPMI 2025. Code: https://github.com/jusiro/FCA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了大规模预训练的视觉语言模型（VLMs）在医学图像分析中的应用，特别是在分割对齐预测（SCP）框架下的可靠性。&lt;h4&gt;背景&lt;/h4&gt;大规模预训练的VLMs在医学图像分析中具有广泛的迁移能力，但其可靠性方面尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;探讨VLMs在SCP框架下的行为，并提出解决方案以提高其可靠性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种全新的方法，即全对齐适应，通过少量数据集对预训练模型进行联合适应和对齐。同时，使用SS-Text线性探针求解器减轻计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;该方法需要与SCP相同的数据，在集合效率上提供高达27%的相对改进，同时保持相同的覆盖率保证。&lt;h4&gt;结论&lt;/h4&gt;全对齐适应和SS-Text可以有效提高VLMs在SCP框架下的可靠性和性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the application of large-scale pre-trained vision-language models (VLMs) in medical image analysis, particularly under the split conformal prediction (SCP) framework, and proposes a novel approach to improve their reliability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models (VLMs) pre-trained at large scale have shownunprecedented transferability capabilities and are being progressivelyintegrated into medical image analysis. Although its discriminative potentialhas been widely explored, its reliability aspect remains overlooked. This workinvestigates their behavior under the increasingly popular split conformalprediction (SCP) framework, which theoretically guarantees a given error levelon output sets by leveraging a labeled calibration set. However, the zero-shotperformance of VLMs is inherently limited, and common practice involvesfew-shot transfer learning pipelines, which cannot absorb the rigidexchangeability assumptions of SCP. To alleviate this issue, we propose fullconformal adaptation, a novel setting for jointly adapting and conformalizingpre-trained foundation models, which operates transductively over each testdata point using a few-shot adaptation set. Moreover, we complement thisframework with SS-Text, a novel training-free linear probe solver for VLMs thatalleviates the computational cost of such a transductive approach. We providecomprehensive experiments using 3 different modality-specialized medical VLMsand 9 adaptation tasks. Our framework requires exactly the same data as SCP,and provides consistent relative improvements of up to 27% on set efficiencywhile maintaining the same coverage guarantees.</description>
      <author>example@mail.com (Julio Silva-Rodríguez, Leo Fillioux, Paul-Henry Cournède, Maria Vakalopoulou, Stergios Christodoulidis, Ismail Ben Ayed, Jose Dolz)</author>
      <guid isPermaLink="false">2506.06076v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Graph-Based Physics-Guided Urban PM2.5 Air Quality Imputation with Constrained Monitoring Data</title>
      <link>http://arxiv.org/abs/2506.06917v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACM Transactions on Sensor Networks (TOSN) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GraPhy的基于图和物理指导的学习框架，用于在监测数据有限的城区进行高分辨率和精确的空气质量建模。&lt;h4&gt;背景&lt;/h4&gt;精细的空气质量监测信息对于减少公众接触污染物至关重要，但在社会经济条件较差的地区，监测网络通常较为稀疏，限制了空气质量建模的准确性和分辨率。&lt;h4&gt;目的&lt;/h4&gt;为了解决这个问题，研究者提出了一个名为GraPhy的物理指导图神经网络架构，该架构针对低分辨率监测数据设计了特定层次和边缘特征。&lt;h4&gt;方法&lt;/h4&gt;使用加利福尼亚社会经济条件较差的圣华金谷的数据进行实验，评估了GraPhy的性能，比较了均方误差（MSE）、平均绝对误差（MAE）和R平方值（R2），并与各种基线模型进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，GraPhy在MSE、MAE和R2方面均取得了最佳的整体性能，与基线模型相比，性能提升了9%-56%。此外，GraPhy在不同空间异质性水平上均优于基线模型，证明了模型设计的效果。&lt;h4&gt;结论&lt;/h4&gt;GraPhy框架能够有效提高空气质量建模的准确性和分辨率，尤其是在监测数据稀疏的地区。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3734869&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work introduces GraPhy, a graph-based, physics-guided learning frameworkfor high-resolution and accurate air quality modeling in urban areas withlimited monitoring data. Fine-grained air quality monitoring information isessential for reducing public exposure to pollutants. However, monitoringnetworks are often sparse in socioeconomically disadvantaged regions, limitingthe accuracy and resolution of air quality modeling. To address this, wepropose a physics-guided graph neural network architecture called GraPhy withlayers and edge features designed specifically for low-resolution monitoringdata. Experiments using data from California's socioeconomically disadvantagedSan Joaquin Valley show that GraPhy achieves the overall best performanceevaluated by mean squared error (MSE), mean absolute error (MAE), and R-squarevalue (R2), improving the performance by 9%-56% compared to various baselinemodels. Moreover, GraPhy consistently outperforms baselines across differentspatial heterogeneity levels, demonstrating the effectiveness of our modeldesign.</description>
      <author>example@mail.com (Shangjie Du, Hui Wei, Dong Yoon Lee, Zhizhang Hu, Shijia Pan)</author>
      <guid isPermaLink="false">2506.06917v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>APTOS-2024 challenge report: Generation of synthetic 3D OCT images from fundus photographs</title>
      <link>http://arxiv.org/abs/2506.07542v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了APTOS-2024挑战赛，旨在推动基于人工智能的视网膜图像到3D光学相干断层扫描（OCT）图像的生成技术，以提高眼科诊疗的可及性。&lt;h4&gt;背景&lt;/h4&gt;OCT技术在眼科疾病诊断中至关重要，但其成本较高，限制了其普及。2D彩色眼底摄影虽然成本较低，但无法提供OCT的高分辨率3D图像。&lt;h4&gt;目的&lt;/h4&gt;通过APTOS-2024挑战赛，探索将2D眼底图像转换为3D OCT图像的可行性，以提升眼科诊疗的可及性。&lt;h4&gt;方法&lt;/h4&gt;APTOS-2024挑战赛包括基准数据集、评估方法和顶尖解决方案分析。评估方法包括基于图像的相似度和基于视频的体积一致性。&lt;h4&gt;主要发现&lt;/h4&gt;挑战吸引了342个团队参与，其中9个团队进入决赛。领先的解决方案采用了混合数据预处理、外部眼科成像数据集预训练、视觉基础模型集成和模型架构改进等创新方法。&lt;h4&gt;结论&lt;/h4&gt;APTOS-2024挑战赛证明了眼底图像到3D OCT图像合成的可行性，这可能是提高眼科诊疗在资源匮乏的医疗环境中可及性的潜在解决方案，同时有助于加速医学研究和临床应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optical Coherence Tomography (OCT) provides high-resolution, 3D, andnon-invasive visualization of retinal layers in vivo, serving as a criticaltool for lesion localization and disease diagnosis. However, its widespreadadoption is limited by equipment costs and the need for specialized operators.In comparison, 2D color fundus photography offers faster acquisition andgreater accessibility with less dependence on expensive devices. Althoughgenerative artificial intelligence has demonstrated promising results inmedical image synthesis, translating 2D fundus images into 3D OCT imagespresents unique challenges due to inherent differences in data dimensionalityand biological information between modalities. To advance generative models inthe fundus-to-3D-OCT setting, the Asia Pacific Tele-Ophthalmology Society(APTOS-2024) organized a challenge titled Artificial Intelligence-based OCTGeneration from Fundus Images. This paper details the challenge framework(referred to as APTOS-2024 Challenge), including: the benchmark dataset,evaluation methodology featuring two fidelity metrics-image-based distance(pixel-level OCT B-scan similarity) and video-based distance (semantic-levelvolumetric consistency), and analysis of top-performing solutions. Thechallenge attracted 342 participating teams, with 42 preliminary submissionsand 9 finalists. Leading methodologies incorporated innovations in hybrid datapreprocessing or augmentation (cross-modality collaborative paradigms),pre-training on external ophthalmic imaging datasets, integration of visionfoundation models, and model architecture improvement. The APTOS-2024 Challengeis the first benchmark demonstrating the feasibility of fundus-to-3D-OCTsynthesis as a potential solution for improving ophthalmic care accessibilityin under-resourced healthcare settings, while helping to expedite medicalresearch and clinical applications.</description>
      <author>example@mail.com (Bowen Liu, Weiyi Zhang, Peranut Chotcomwongse, Xiaolan Chen, Ruoyu Chen, Pawin Pakaymaskul, Niracha Arjkongharn, Nattaporn Vongsa, Xuelian Cheng, Zongyuan Ge, Kun Huang, Xiaohui Li, Yiru Duan, Zhenbang Wang, BaoYe Xie, Qiang Chen, Huazhu Fu, Michael A. Mahr, Jiaqi Qu, Wangyiyang Chen, Shiye Wang, Yubo Tan, Yongjie Li, Mingguang He, Danli Shi, Paisan Ruamviboonsuk)</author>
      <guid isPermaLink="false">2506.07542v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>IRS: Instance-Level 3D Scene Graphs via Room Prior Guided LiDAR-Camera Fusion</title>
      <link>http://arxiv.org/abs/2506.06804v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于激光雷达-相机融合的实例级3D场景图构建框架，通过视觉基础模型（VFMs）提高语义提取的准确性和一致性，实现了在开放世界环境中的高效场景理解。&lt;h4&gt;背景&lt;/h4&gt;室内场景理解是机器人领域的基本挑战，对导航和操作等下游任务有直接影响。传统的封闭集识别或闭环检测方法在开放世界环境中的适应性有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种鲁棒且高效的框架，通过LiDAR和相机融合实现实例级3D场景图的构建，提高开放世界环境中的场景理解能力。&lt;h4&gt;方法&lt;/h4&gt;利用LiDAR的广角视野和长距离传感能力快速获取房间级几何先验；采用多级VFMs提高语义提取的准确性和一致性；基于房间分割实现实例融合的并行处理；结合几何和语义线索提高融合的准确性和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，该方法在构建速度上提高了约一个数量级，同时保持了高语义精度。&lt;h4&gt;结论&lt;/h4&gt;通过模拟和真实环境的大量实验验证了该方法的有效性，并通过语言引导的语义导航任务展示了其实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Indoor scene understanding remains a fundamental challenge in robotics, with direct implications for downstream tasks such as navigation and manipulation. Traditional approaches often rely on closed-set recognition or loop closure, limiting their adaptability in open-world environments. With the advent of visual foundation models (VFMs), open-vocabulary recognition and natural language querying have become feasible, unlocking new possibilities for 3D scene graph construction. In this paper, we propose a robust and efficient framework for instance-level 3D scene graph construction via LiDAR-camera fusion. Leveraging LiDAR's widefield of view (FOV) and long-range sensing capabilities, we rapidly acquire room-level geometric priors. Multi-level VFMs are employed to improve the accuracy and consistency of semantic extraction. During instance fusion, room-based segmentation enables parallel processing, while the integration of geometric and semantic cues significantly enhances fusion accuracy and robustness. Compared to state-of-the-art methods, our approach achieves up to an order-of-magnitude improvement in construction speed while maintaining high semantic precision. Extensive experiments in both simulated and real-world environments validate the effectiveness of our approach. We further demonstrate its practical value through a language-guided semantic navigation task, highlighting its potential for real-world robotic applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Indoor scene understanding remains a fundamental challenge in robotics, withdirect implications for downstream tasks such as navigation and manipulation.Traditional approaches often rely on closed-set recognition or loop closure,limiting their adaptability in open-world environments. With the advent ofvisual foundation models (VFMs), open-vocabulary recognition and naturallanguage querying have become feasible, unlocking new possibilities for 3Dscene graph construction.  In this paper, we propose a robust and efficient framework for instance-level3D scene graph construction via LiDAR-camera fusion. Leveraging LiDAR's widefield of view (FOV) and long-range sensing capabilities, we rapidly acquireroom-level geometric priors. Multi-level VFMs are employed to improve theaccuracy and consistency of semantic extraction. During instance fusion,room-based segmentation enables parallel processing, while the integration ofgeometric and semantic cues significantly enhances fusion accuracy androbustness. Compared to state-of-the-art methods, our approach achieves up toan order-of-magnitude improvement in construction speed while maintaining highsemantic precision.  Extensive experiments in both simulated and real-world environments validatethe effectiveness of our approach. We further demonstrate its practical valuethrough a language-guided semantic navigation task, highlighting its potentialfor real-world robotic applications.</description>
      <author>example@mail.com (Hongming Chen, Yiyang Lin, Ziliang Li, Biyu Ye, Yuying Zhang, Ximin Lyu)</author>
      <guid isPermaLink="false">2506.06804v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>TerraFM: A Scalable Foundation Model for Unified Multisensor Earth Observation</title>
      <link>http://arxiv.org/abs/2506.06281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TerraFM是一个可扩展的自监督学习模型，利用全球分布的Sentinel-1和Sentinel-2影像，通过大空间瓦片和土地覆盖意识采样来丰富空间和语义覆盖。该模型在分类和分割任务上表现出强大的泛化能力，在GEO-Bench和Copernicus-Bench上优于先前模型。&lt;h4&gt;背景&lt;/h4&gt;现代地球观测越来越多地利用深度学习来利用卫星影像的规模和多样性。尽管最近的基础模型在地球观测任务中表现出有希望的泛化能力，但许多模型仍受限于其训练数据的规模、地理覆盖和光谱多样性，这些因素对于学习可全球转移的表示至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出TerraFM模型，旨在解决当前深度学习模型在地球观测任务中存在的泛化能力不足的问题。&lt;h4&gt;方法&lt;/h4&gt;TerraFM模型通过以下方法实现其目标：1）利用全球分布的Sentinel-1和Sentinel-2影像；2）采用大空间瓦片和土地覆盖意识采样；3）将雷达和光学输入通过模态特定的补丁嵌入和自适应交叉注意力融合；4）结合局部-全局对比学习，并引入双中心机制，结合类频率感知正则化来解决土地覆盖中的长尾分布。&lt;h4&gt;主要发现&lt;/h4&gt;TerraFM在分类和分割任务上实现了强大的泛化能力，在GEO-Bench和Copernicus-Bench上优于先前模型。&lt;h4&gt;结论&lt;/h4&gt;TerraFM模型是一个有效的工具，可以提高地球观测任务的性能，并在全球范围内具有可转移性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代地球观测（EO）越来越多地利用深度学习来利用卫星影像的规模和多样性。虽然最近的基础模型在EO任务中展示了有希望的泛化能力，但许多模型仍然受限于其训练数据的规模、地理覆盖和光谱多样性，这些因素对于学习可全球转移的表示至关重要。在这项工作中，我们介绍了TerraFM，一个可扩展的自监督学习模型，它利用全球分布的Sentinel-1和Sentinel-2影像，结合大型空间瓦片和土地覆盖意识采样来丰富空间和语义覆盖。通过将传感模式视为自监督方法中的自然增强，我们通过模态特定的补丁嵌入和自适应交叉注意力融合统一了雷达和光学输入。我们的训练策略结合了局部-全局对比学习，并引入了一个双重中心机制，该机制结合了类频率感知正则化来解决土地覆盖中的长尾分布。TerraFM在分类和分割任务上实现了强大的泛化能力，在GEO-Bench和Copernicus-Bench上优于先前模型。我们的代码和预训练模型可在以下链接公开获取：https://github.com/mbzuai-oryx/TerraFM 。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern Earth observation (EO) increasingly leverages deep learning to harnessthe scale and diversity of satellite imagery across sensors and regions. Whilerecent foundation models have demonstrated promising generalization across EOtasks, many remain limited by the scale, geographical coverage, and spectraldiversity of their training data, factors critical for learning globallytransferable representations. In this work, we introduce TerraFM, a scalableself-supervised learning model that leverages globally distributed Sentinel-1and Sentinel-2 imagery, combined with large spatial tiles and land-cover awaresampling to enrich spatial and semantic coverage. By treating sensingmodalities as natural augmentations in our self-supervised approach, we unifyradar and optical inputs via modality-specific patch embeddings and adaptivecross-attention fusion. Our training strategy integrates local-globalcontrastive learning and introduces a dual-centering mechanism thatincorporates class-frequency-aware regularization to address long-taileddistributions in land cover.TerraFM achieves strong generalization on bothclassification and segmentation tasks, outperforming prior models on GEO-Benchand Copernicus-Bench. Our code and pretrained models are publicly available at:https://github.com/mbzuai-oryx/TerraFM .</description>
      <author>example@mail.com (Muhammad Sohail Danish, Muhammad Akhtar Munir, Syed Roshaan Ali Shah, Muhammad Haris Khan, Rao Muhammad Anwer, Jorma Laaksonen, Fahad Shahbaz Khan, Salman Khan)</author>
      <guid isPermaLink="false">2506.06281v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>KNN-Defense: Defense against 3D Adversarial Point Clouds using Nearest-Neighbor Search</title>
      <link>http://arxiv.org/abs/2506.06906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为KNN-Defense的防御策略，用于增强3D点云分类器的对抗鲁棒性，并展示了其在ModelNet40数据集上的有效性。&lt;h4&gt;背景&lt;/h4&gt;深度神经网络在分析3D点云数据方面表现出色，但其易受对抗攻击的影响，这些攻击会损害点云的语义和结构完整性。&lt;h4&gt;目的&lt;/h4&gt;提出KNN-Defense以解决3D视觉系统对抗攻击的脆弱性问题。&lt;h4&gt;方法&lt;/h4&gt;KNN-Defense基于流形假设和特征空间中的最近邻搜索，通过利用训练集中邻近样本的语义相似性来恢复受干扰的输入。&lt;h4&gt;主要发现&lt;/h4&gt;KNN-Defense在多种攻击类型下显著提高了鲁棒性，尤其是在点去除攻击中，与现有方法相比，KNN-Defense在PointNet、PointNet++、DGCNN和PCT上的准确率分别提高了20.1%、3.6%、3.44%和7.74%。&lt;h4&gt;结论&lt;/h4&gt;KNN-Defense提供了一种可扩展且有效的解决方案，用于增强3D点云分类器的对抗鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：深度神经网络（DNNs）在分析3D点云数据方面表现出色。然而，它们容易受到对抗攻击（如点删除、移动和添加）的影响，这给3D视觉系统的可靠性带来了重大挑战。这些攻击会破坏点云的语义和结构完整性，使许多现有防御机制失效。为了解决这个问题，提出了一种名为KNN-Defense的防御策略，其基于流形假设和特征空间中的最近邻搜索。该方法不是通过重建表面几何形状或强制执行均匀的点分布，而是通过利用训练集中邻近样本的语义相似性来恢复受干扰的输入。KNN-Defense轻量级且计算效率高，可以实现快速推理，非常适合实时和实际应用。在ModelNet40数据集上的实证结果表明，KNN-Defense在各种攻击类型下显著提高了鲁棒性。特别是在点删除攻击中——由于关键点的针对性删除，许多现有方法表现不佳——该方法在PointNet、PointNet++、DGCNN和PCT上分别实现了20.1%、3.6%、3.44%和7.74%的准确率提升。这些发现表明，KNN-Defense为增强3D点云分类器的对抗鲁棒性提供了一种可扩展且有效的解决方案。（该方法的开源实现，包括代码和数据，可在https://github.com/nimajam41/3d-knn-defense上获得。)&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks (DNNs) have demonstrated remarkable performance inanalyzing 3D point cloud data. However, their vulnerability to adversarialattacks-such as point dropping, shifting, and adding-poses a critical challengeto the reliability of 3D vision systems. These attacks can compromise thesemantic and structural integrity of point clouds, rendering many existingdefense mechanisms ineffective. To address this issue, a defense strategy namedKNN-Defense is proposed, grounded in the manifold assumption andnearest-neighbor search in feature space. Instead of reconstructing surfacegeometry or enforcing uniform point distributions, the method restoresperturbed inputs by leveraging the semantic similarity of neighboring samplesfrom the training set. KNN-Defense is lightweight and computationallyefficient, enabling fast inference and making it suitable for real-time andpractical applications. Empirical results on the ModelNet40 datasetdemonstrated that KNN-Defense significantly improves robustness across variousattack types. In particular, under point-dropping attacks-where many existingmethods underperform due to the targeted removal of critical points-theproposed method achieves accuracy gains of 20.1%, 3.6%, 3.44%, and 7.74% onPointNet, PointNet++, DGCNN, and PCT, respectively. These findings suggest thatKNN-Defense offers a scalable and effective solution for enhancing theadversarial resilience of 3D point cloud classifiers. (An open-sourceimplementation of the method, including code and data, is available athttps://github.com/nimajam41/3d-knn-defense).</description>
      <author>example@mail.com (Nima Jamali, Matina Mahdizadeh Sani, Hanieh Naderi, Shohreh Kasaei)</author>
      <guid isPermaLink="false">2506.06906v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Multidimensional Analysis of Specific Language Impairment Using Unsupervised Learning Through PCA and Clustering</title>
      <link>http://arxiv.org/abs/2506.05498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 3 figures, 16 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究通过无监督机器学习技术，分析了儿童自然语言发展轨迹，以识别SLI（特定语言障碍）和正常儿童的语言特征，为早期识别和针对性干预提供见解。&lt;h4&gt;背景&lt;/h4&gt;SLI影响大约7%的儿童，表现为孤立的语言缺陷，尽管认知能力、感官系统和环境支持正常。&lt;h4&gt;目的&lt;/h4&gt;研究旨在使用无监督机器学习技术，识别有SLI和无SLI儿童的天然语言发展轨迹。&lt;h4&gt;方法&lt;/h4&gt;研究分析了来自三个语料库（Conti-Ramsden 4、ENNI和Gillam）的1,163名4-16岁儿童的叙事样本，使用主成分分析（PCA）和聚类方法，评估了64个语言特征。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现两个主要聚类：（1）高语言产出且SLI发病率低；（2）产出有限但句法复杂性高且SLI发病率高。边界案例表现出中间特征，支持语言能力的连续模型。SLI主要表现为产出能力降低，而非句法复杂性缺陷。&lt;h4&gt;结论&lt;/h4&gt;研究结果挑战了分类诊断框架，并突出了无监督学习技术在细化诊断标准和干预策略方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;This study aims to identify natural language development trajectories in children with and without SLI using unsupervised machine learning techniques, providing insights for early identification and targeted interventions. Narrative samples from 1,163 children aged 4-16 years across three corpora (Conti-Ramsden 4, ENNI, and Gillam) were analyzed using Principal Component Analysis (PCA) and clustering. A total of 64 linguistic features were evaluated to uncover developmental trajectories and distinguish linguistic profiles. Two primary clusters emerged: (1) high language production with low SLI prevalence, and (2) limited production but higher syntactic complexity with higher SLI prevalence. Additionally, boundary cases exhibited intermediate traits, supporting a continuum model of language abilities. Findings suggest SLI manifests primarily through reduced production capacity rather than syntactic complexity deficits. The results challenge categorical diagnostic frameworks and highlight the potential of unsupervised learning techniques for refining diagnostic criteria and intervention strategies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Specific Language Impairment (SLI) affects approximately 7 percent ofchildren, presenting as isolated language deficits despite normal cognitiveabilities, sensory systems, and supportive environments. Traditional diagnosticapproaches often rely on standardized assessments, which may overlook subtledevelopmental patterns. This study aims to identify natural languagedevelopment trajectories in children with and without SLI using unsupervisedmachine learning techniques, providing insights for early identification andtargeted interventions. Narrative samples from 1,163 children aged 4-16 yearsacross three corpora (Conti-Ramsden 4, ENNI, and Gillam) were analyzed usingPrincipal Component Analysis (PCA) and clustering. A total of 64 linguisticfeatures were evaluated to uncover developmental trajectories and distinguishlinguistic profiles. Two primary clusters emerged: (1) high language productionwith low SLI prevalence, and (2) limited production but higher syntacticcomplexity with higher SLI prevalence. Additionally, boundary cases exhibitedintermediate traits, supporting a continuum model of language abilities.Findings suggest SLI manifests primarily through reduced production capacityrather than syntactic complexity deficits. The results challenge categoricaldiagnostic frameworks and highlight the potential of unsupervised learningtechniques for refining diagnostic criteria and intervention strategies.</description>
      <author>example@mail.com (Niruthiha Selvanayagam)</author>
      <guid isPermaLink="false">2506.05498v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks in Modern AI-aided Drug Discovery</title>
      <link>http://arxiv.org/abs/2506.06915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了图神经网络（GNNs）在人工智能辅助药物发现（AIDD）中的应用，包括其在分子建模中的角色、方法基础、代表性应用和最新进展。&lt;h4&gt;背景&lt;/h4&gt;GNNs是深度学习中的拓扑/结构感知模型，通过直接操作分子图，能够学习药物分子的复杂拓扑和几何特征。&lt;h4&gt;目的&lt;/h4&gt;提供GNNs在药物发现中方法基础和代表性应用的全面概述。&lt;h4&gt;方法&lt;/h4&gt;综述了分子性质预测、虚拟筛选、分子生成、生物医学知识图谱构建和合成规划等任务中的应用，并关注了最近的方法进展，如几何GNNs、可解释模型、不确定性量化、可扩展图架构和图生成框架。&lt;h4&gt;主要发现&lt;/h4&gt;讨论了这些模型如何与现代深度学习方法结合，如自监督学习、多任务学习、元学习和预训练，并强调了在将GNNs应用于现实世界药物发现管线时遇到的实践挑战和方法瓶颈。&lt;h4&gt;结论&lt;/h4&gt;讨论了GNNs在药物发现中的未来发展方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs), as topology/structure-aware models within deeplearning, have emerged as powerful tools for AI-aided drug discovery (AIDD). Bydirectly operating on molecular graphs, GNNs offer an intuitive and expressiveframework for learning the complex topological and geometric features ofdrug-like molecules, cementing their role in modern molecular modeling. Thisreview provides a comprehensive overview of the methodological foundations andrepresentative applications of GNNs in drug discovery, spanning tasks such asmolecular property prediction, virtual screening, molecular generation,biomedical knowledge graph construction, and synthesis planning. Particularattention is given to recent methodological advances, including geometric GNNs,interpretable models, uncertainty quantification, scalable graph architectures,and graph generative frameworks. We also discuss how these models integratewith modern deep learning approaches, such as self-supervised learning,multi-task learning, meta-learning and pre-training. Throughout this review, wehighlight the practical challenges and methodological bottlenecks encounteredwhen applying GNNs to real-world drug discovery pipelines, and conclude with adiscussion on future directions.</description>
      <author>example@mail.com (Odin Zhang, Haitao Lin, Xujun Zhang, Xiaorui Wang, Zhenxing Wu, Qing Ye, Weibo Zhao, Jike Wang, Kejun Ying, Yu Kang, Chang-yu Hsieh, Tingjun Hou)</author>
      <guid isPermaLink="false">2506.06915v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>IMPA-HGAE:Intra-Meta-Path Augmented Heterogeneous Graph Autoencoder</title>
      <link>http://arxiv.org/abs/2506.06809v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为IMPA-HGAE的新型框架，用于提升异构图的自监督学习方法，并通过实验验证了其在异构图数据集上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;自监督学习方法因其优越的泛化能力和低标注成本，在多种下游任务中得到了广泛应用。&lt;h4&gt;目的&lt;/h4&gt;针对现有异构图自监督模型将异构图转换为同构图进行训练的局限性，旨在通过充分利用元路径上的内部节点信息来增强目标节点嵌入。&lt;h4&gt;方法&lt;/h4&gt;IMPA-HGAE框架通过创新掩码策略增强生成式自监督模型在异构图数据上的表示能力，并讨论了方法的可解释性和未来研究方向。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，IMPA-HGAE在异构图数据集上取得了优于现有方法的性能。&lt;h4&gt;结论&lt;/h4&gt;IMPA-HGAE为利用元路径引导的结构语义在复杂图场景中进行鲁棒表示学习提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised learning (SSL) methods have been increasingly applied to diverse downstream tasks due to their superior generalization capabilities and low annotation costs. However, most existing heterogeneous graph SSL models convert heterogeneous graphs into homogeneous ones via meta-paths for training, which only leverage information from nodes at both ends of meta-paths while underutilizing the heterogeneous node information along the meta-paths. To address this limitation, this paper proposes a novel framework named IMPA-HGAE to enhance target node embeddings by fully exploiting internal node information along meta-paths. Experimental results validate that IMPA-HGAE achieves superior performance on heterogeneous datasets. Furthermore, this paper introduces innovative masking strategies to strengthen the representational capacity of generative SSL models on heterogeneous graph data. Additionally, this paper discusses the interpretability of the proposed method and potential future directions for generative self-supervised learning in heterogeneous graphs. This work provides insights into leveraging meta-path-guided structuralsemantics for robust representation learning in complex graph scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) methods have been increasingly applied todiverse downstream tasks due to their superior generalization capabilities andlow annotation costs. However, most existing heterogeneous graph SSL modelsconvert heterogeneous graphs into homogeneous ones via meta-paths for training,which only leverage information from nodes at both ends of meta-paths whileunderutilizing the heterogeneous node information along the meta-paths. Toaddress this limitation, this paper proposes a novel framework named IMPA-HGAEto enhance target node embeddings by fully exploiting internal node informationalong meta-paths. Experimental results validate that IMPA-HGAE achievessuperior performance on heterogeneous datasets. Furthermore, this paperintroduce innovative masking strategies to strengthen the representationalcapacity of generative SSL models on heterogeneous graph data. Additionally,this paper discuss the interpretability of the proposed method and potentialfuture directions for generative self-supervised learning in heterogeneousgraphs. This work provides insights into leveraging meta-path-guided structuralsemantics for robust representation learning in complex graph scenarios.</description>
      <author>example@mail.com (Di Lin, Wanjing Ren, Xuanbin Li, Rui Zhang)</author>
      <guid isPermaLink="false">2506.06809v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>PhysLab: A Benchmark Dataset for Multi-Granularity Visual Parsing of Physics Experiments</title>
      <link>http://arxiv.org/abs/2506.06631v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为PhysLab的视频数据集，用于视觉解析图像和视频，特别针对复杂物理实验的学生行为进行捕捉。&lt;h4&gt;背景&lt;/h4&gt;现有的图像和视频数据集在标注粒度、领域覆盖和过程指导方面存在不足，限制了视觉解析的发展。&lt;h4&gt;目的&lt;/h4&gt;提出PhysLab数据集以解决现有数据集的不足，推动精细视觉解析，促进智能教室系统的发展，以及计算机视觉与教育技术的整合。&lt;h4&gt;方法&lt;/h4&gt;PhysLab数据集包含了620个长视频，涵盖了4个具有多样科学仪器和丰富人机交互模式的代表实验，提供了多层次的标注以支持动作识别、目标检测、人机交互分析等多种视觉任务。&lt;h4&gt;主要发现&lt;/h4&gt;论文通过建立基线和广泛评估，突出了过程教育视频解析的关键挑战。&lt;h4&gt;结论&lt;/h4&gt;PhysLab数据集和评估工具包已公开发布，预期将成为视觉解析研究的重要资源。&lt;h4&gt;翻译&lt;/h4&gt;Visual parsing of images and videos is critical for a wide range of real-world applications. However, progress in this field is constrained by limitations of existing datasets: (1) insufficient annotation granularity, which impedes fine-grained scene understanding and high-level reasoning; (2) limited coverage of domains, particularly a lack of datasets tailored for educational scenarios; and (3) lack of explicit procedural guidance, with minimal logical rules and insufficient representation of structured task process. To address these gaps, we introduce PhysLab, the first video dataset that captures students conducting complex physics experiments. The dataset includes four representative experiments that feature diverse scientific instruments and rich human-object interaction (HOI) patterns. PhysLab comprises 620 long-form videos and provides multilevel annotations that support a variety of vision tasks, including action recognition, object detection, HOI analysis, etc. We establish strong baselines and perform extensive evaluations to highlight key challenges in the parsing of procedural educational videos. We expect PhysLab to serve as a valuable resource for advancing fine-grained visual parsing, facilitating intelligent classroom systems, and fostering closer integration between computer vision and educational technologies. The dataset and the evaluation toolkit are publicly available at https://github.com/ZMH-SDUST/PhysLab.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual parsing of images and videos is critical for a wide range ofreal-world applications. However, progress in this field is constrained bylimitations of existing datasets: (1) insufficient annotation granularity,which impedes fine-grained scene understanding and high-level reasoning; (2)limited coverage of domains, particularly a lack of datasets tailored foreducational scenarios; and (3) lack of explicit procedural guidance, withminimal logical rules and insufficient representation of structured taskprocess. To address these gaps, we introduce PhysLab, the first video datasetthat captures students conducting complex physics experiments. The datasetincludes four representative experiments that feature diverse scientificinstruments and rich human-object interaction (HOI) patterns. PhysLab comprises620 long-form videos and provides multilevel annotations that support a varietyof vision tasks, including action recognition, object detection, HOI analysis,etc. We establish strong baselines and perform extensive evaluations tohighlight key challenges in the parsing of procedural educational videos. Weexpect PhysLab to serve as a valuable resource for advancing fine-grainedvisual parsing, facilitating intelligent classroom systems, and fosteringcloser integration between computer vision and educational technologies. Thedataset and the evaluation toolkit are publicly available athttps://github.com/ZMH-SDUST/PhysLab.</description>
      <author>example@mail.com (Minghao Zou, Qingtian Zeng, Yongping Miao, Shangkun Liu, Zilong Wang, Hantao Liu, Wei Zhou)</author>
      <guid isPermaLink="false">2506.06631v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Model-Driven Graph Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.06212v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MGCL的模型驱动的图对比学习（GCL）框架，该框架利用图论（图的概率生成模型）来指导对比学习，通过考虑数据的潜在生成过程。&lt;h4&gt;背景&lt;/h4&gt;GCL作为一种自监督框架，在无需依赖标注标签的情况下，能够学习具有表达性的节点或图表示，这在现实世界的数据中通常较为稀缺。&lt;h4&gt;目的&lt;/h4&gt;通过对比增强的图数据视图，提高节点和图分类等下游任务的表现。&lt;h4&gt;方法&lt;/h4&gt;MGCL首先估计与观察数据相关的图论，然后定义一个基于图论的增强过程，实现数据自适应和原理性的增强。对于图级任务，MGCL对数据集进行聚类，并为每个组估计一个图论，以便对比对对反映共享的语义和结构。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上的广泛实验表明，MGCL实现了最先进的性能，突出了将生成模型纳入GCL的优势。&lt;h4&gt;结论&lt;/h4&gt;MGCL框架通过利用图论提高了图对比学习的效果，为图级任务提供了更有效的数据增强和表示学习策略。&lt;h4&gt;翻译&lt;/h4&gt;We propose MGCL, a model-driven graph contrastive learning (GCL) framework that leverages graphons (probabilistic generative models for graphs) to guide contrastive learning by accounting for the data's underlying generative process. GCL has emerged as a powerful self-supervised framework for learning expressive node or graph representations without relying on annotated labels, which are often scarce in real-world data. By contrasting augmented views of graph data, GCL has demonstrated strong performance across various downstream tasks, such as node and graph classification. However, existing methods typically rely on manually designed or heuristic augmentation strategies that are not tailored to the underlying data distribution and operate at the individual graph level, ignoring similarities among graphs generated from the same model. Conversely, in our proposed approach, MGCL first estimates the graphon associated with the observed data and then defines a graphon-informed augmentation process, enabling data-adaptive and principled augmentations. Additionally, for graph-level tasks, MGCL clusters the dataset and estimates a graphon per group, enabling contrastive pairs to reflect shared semantics and structure. Extensive experiments on benchmark datasets demonstrate that MGCL achieves state-of-the-art performance, highlighting the advantages of incorporating generative models into GCL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose $\textbf{MGCL}$, a model-driven graph contrastive learning (GCL)framework that leverages graphons (probabilistic generative models for graphs)to guide contrastive learning by accounting for the data's underlyinggenerative process. GCL has emerged as a powerful self-supervised framework forlearning expressive node or graph representations without relying on annotatedlabels, which are often scarce in real-world data. By contrasting augmentedviews of graph data, GCL has demonstrated strong performance across variousdownstream tasks, such as node and graph classification. However, existingmethods typically rely on manually designed or heuristic augmentationstrategies that are not tailored to the underlying data distribution andoperate at the individual graph level, ignoring similarities among graphsgenerated from the same model. Conversely, in our proposed approach, MGCL firstestimates the graphon associated with the observed data and then defines agraphon-informed augmentation process, enabling data-adaptive and principledaugmentations. Additionally, for graph-level tasks, MGCL clusters the datasetand estimates a graphon per group, enabling contrastive pairs to reflect sharedsemantics and structure. Extensive experiments on benchmark datasetsdemonstrate that MGCL achieves state-of-the-art performance, highlighting theadvantages of incorporating generative models into GCL.</description>
      <author>example@mail.com (Ali Azizpour, Nicolas Zilberstein, Santiago Segarra)</author>
      <guid isPermaLink="false">2506.06212v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Face recognition on point cloud with cgan-top for denoising</title>
      <link>http://arxiv.org/abs/2506.06864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in ICASSP 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在噪声点云上进行端到端3D人脸识别的方法，该方法有效地结合了去噪和识别模块。&lt;h4&gt;背景&lt;/h4&gt;使用3D点云进行人脸识别越来越受到关注，但由于传感器不完美，原始点云往往包含大量噪声。&lt;h4&gt;目的&lt;/h4&gt;提出一种在噪声点云上有效进行3D人脸识别的方法。&lt;h4&gt;方法&lt;/h4&gt;设计了一种条件生成对抗网络（cGAN-TOP）来去除点云中的噪声并恢复潜在特征，然后采用链接动态图卷积神经网络（LDGCNN）从处理后的点云中识别人脸。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在Bosphorus数据集上进行了验证，在所有噪声设置下都显著提高了识别准确率，最大增益为14.81%。&lt;h4&gt;结论&lt;/h4&gt;该方法在噪声点云上进行3D人脸识别时具有显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Face recognition using 3D point clouds is gaining growing interest, while rawpoint clouds often contain a significant amount of noise due to imperfectsensors. In this paper, an end-to-end 3D face recognition on a noisy pointcloud is proposed, which synergistically integrates the denoising andrecognition modules. Specifically, a Conditional Generative Adversarial Networkon Three Orthogonal Planes (cGAN-TOP) is designed to effectively remove thenoise in the point cloud, and recover the underlying features for subsequentrecognition. A Linked Dynamic Graph Convolutional Neural Network (LDGCNN) isthen adapted to recognize faces from the processed point cloud, whichhierarchically links both the local point features and neighboring features ofmultiple scales. The proposed method is validated on the Bosphorus dataset. Itsignificantly improves the recognition accuracy under all noise settings, witha maximum gain of 14.81%.</description>
      <author>example@mail.com (Junyu Liu, Jianfeng Ren, Sunhong Liang, Xudong Jiang)</author>
      <guid isPermaLink="false">2506.06864v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>How Important are Videos for Training Video LLMs?</title>
      <link>http://arxiv.org/abs/2506.06928v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page on  https://visualcomputinginstitute.github.io/videollm-pseudovideo-training/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视频大型语言模型（Video LLMs），发现经过图像训练的Video LLMs在时间推理能力上优于预期，而视频特定训练带来的改进很小。&lt;h4&gt;背景&lt;/h4&gt;视频LLMs的研究进展迅速，模型和基准在短短几年内大量涌现，通常这些模型使用预训练的纯文本LLM初始化，并在图像和视频字幕数据集上进行微调。&lt;h4&gt;目的&lt;/h4&gt;探讨Video LLMs在时间推理方面的能力，以及视频特定训练的效率。&lt;h4&gt;方法&lt;/h4&gt;使用LongVU算法训练的LLMs进行图像训练，并在TVBench时间推理基准上进行测试。引入了一个简单的微调方案，涉及一系列标注图像和针对时间能力的问题。&lt;h4&gt;主要发现&lt;/h4&gt;图像训练的LLMs在时间推理基准TVBench上的表现显著高于随机水平，且微调方案的效果接近甚至超过视频训练的LLMs。&lt;h4&gt;结论&lt;/h4&gt;当前模型对视频中丰富的时序特征的利用不足，需要进一步研究图像训练LLMs进行时间推理的机制以及当前视频训练方案的瓶颈。&lt;h4&gt;翻译&lt;/h4&gt;Research into Video Large Language Models (LLMs) has progressed rapidly, with numerous models and benchmarks emerging in just a few years. Typically, these models are initialized with a pretrained text-only LLM and finetuned on both image- and video-caption datasets. In this paper, we present findings indicating that Video LLMs are more capable of temporal reasoning after image-only training than one would assume, and that improvements from video-specific training are surprisingly small. Specifically, we show that image-trained versions of two LLMs trained with the recent LongVU algorithm perform significantly above chance level on TVBench, a temporal reasoning benchmark. Additionally, we introduce a simple finetuning scheme involving sequences of annotated images and questions targeting temporal capabilities. This baseline results in temporal reasoning performance close to, and occasionally higher than, what is achieved by video-trained LLMs. This suggests suboptimal utilization of rich temporal features found in real video by current models. Our analysis motivates further research into the mechanisms that allow image-trained LLMs to perform temporal reasoning, as well as into the bottlenecks that render current video training schemes inefficient.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Research into Video Large Language Models (LLMs) has progressed rapidly, withnumerous models and benchmarks emerging in just a few years. Typically, thesemodels are initialized with a pretrained text-only LLM and finetuned on bothimage- and video-caption datasets. In this paper, we present findingsindicating that Video LLMs are more capable of temporal reasoning afterimage-only training than one would assume, and that improvements fromvideo-specific training are surprisingly small. Specifically, we show thatimage-trained versions of two LLMs trained with the recent LongVU algorithmperform significantly above chance level on TVBench, a temporal reasoningbenchmark. Additionally, we introduce a simple finetuning scheme involvingsequences of annotated images and questions targeting temporal capabilities.This baseline results in temporal reasoning performance close to, andoccasionally higher than, what is achieved by video-trained LLMs. This suggestssuboptimal utilization of rich temporal features found in real video by currentmodels. Our analysis motivates further research into the mechanisms that allowimage-trained LLMs to perform temporal reasoning, as well as into thebottlenecks that render current video training schemes inefficient.</description>
      <author>example@mail.com (George Lydakis, Alexander Hermans, Ali Athar, Daan de Geus, Bastian Leibe)</author>
      <guid isPermaLink="false">2506.06928v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Initial Model Incorporation for Deep Learning FWI: Pretraining or Denormalization?</title>
      <link>http://arxiv.org/abs/2506.05484v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将初始模型知识嵌入神经网络的方法对全波形反演的影响。&lt;h4&gt;背景&lt;/h4&gt;地下属性神经网络重参数化全波形反演是一种有效的无监督学习框架，能够稳定反演，即使起始模型不准确。&lt;h4&gt;目的&lt;/h4&gt;研究两种将初始模型知识嵌入神经网络的方法对神经网络重参数化全波形反演的影响。&lt;h4&gt;方法&lt;/h4&gt;一种是预训练，通过拟合初始速度模型来调节神经网络参数；另一种是去归一化，直接将网络输出添加到初始模型中。&lt;h4&gt;主要发现&lt;/h4&gt;预训练需要基于恒定速度值（均值）进行模型扰动反演，导致工作流程复杂，目标函数在两阶段过程中不一致，导致网络参数失去活性，降低塑性。&lt;h4&gt;结论&lt;/h4&gt;去归一化可以简化工作流程，加速收敛，与预训练相比，可以提高反演精度。&lt;h4&gt;翻译&lt;/h4&gt;Subsurface property neural network reparameterized full waveform inversion (FWI) has emerged as an effective unsupervised learning framework, which can invert stably with an inaccurate starting model. It updates the trainable neural network parameters instead of fine-tuning on the subsurface model directly. There are primarily two ways to embed the prior knowledge of the initial model into neural networks, that is, pretraining and denormalization. Pretraining first regulates the neural networks' parameters by fitting the initial velocity model; Denormalization directly adds the outputs of the network into the initial models without pretraining. In this letter, we systematically investigate the influence of the two ways of initial model incorporation for the neural network reparameterized FWI. We demonstrate that pretraining requires inverting the model perturbation based on a constant velocity value (mean) with a two-stage implementation. It leads to a complex workflow and inconsistency of objective functions in the two-stage process, causing the network parameters to become inactive and lose plasticity. Experimental results demonstrate that denormalization can simplify workflows, accelerate convergence, and enhance inversion accuracy compared with pretraining.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Subsurface property neural network reparameterized full waveform inversion(FWI) has emerged as an effective unsupervised learning framework, which caninvert stably with an inaccurate starting model. It updates the trainableneural network parameters instead of fine-tuning on the subsurface modeldirectly. There are primarily two ways to embed the prior knowledge of theinitial model into neural networks, that is, pretraining and denormalization.Pretraining first regulates the neural networks' parameters by fitting theinitial velocity model; Denormalization directly adds the outputs of thenetwork into the initial models without pretraining. In this letter, wesystematically investigate the influence of the two ways of initial modelincorporation for the neural network reparameterized FWI. We demonstrate thatpretraining requires inverting the model perturbation based on a constantvelocity value (mean) with a two-stage implementation. It leads to a complexworkflow and inconsistency of objective functions in the two-stage process,causing the network parameters to become inactive and lose plasticity.Experimental results demonstrate that denormalization can simplify workflows,accelerate convergence, and enhance inversion accuracy compared withpretraining.</description>
      <author>example@mail.com (Ruihua Chen, Bangyu Wu, Meng Li, Kai Yang)</author>
      <guid isPermaLink="false">2506.05484v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty Estimation on Graphs with Structure Informed Stochastic Partial Differential Equations</title>
      <link>http://arxiv.org/abs/2506.06907v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的不确定性估计方法，该方法能够处理分布偏移问题，并通过引入空间-时间噪声来增强不确定性估计。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在多种网络建模任务中取得了显著成果，但在处理分布偏移时，准确估计不确定性仍然是一个难题。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的消息传递方案，以解决图结构及其标签分布带来的随机性，从而提高不确定性估计的准确性。&lt;h4&gt;方法&lt;/h4&gt;借鉴了由Matern高斯过程驱动的随机偏微分方程（SPDE）的演化与GNN层中消息传递之间的类比，提出了一种新的消息传递方案。&lt;h4&gt;主要发现&lt;/h4&gt;该方法同时捕捉空间和时间上的不确定性，并允许显式控制协方差核的平滑度，从而在标签信息量低和高的情况下都能提高不确定性估计。&lt;h4&gt;结论&lt;/h4&gt;在具有不同标签信息量的图数据集上进行Out-of-Distribution（OOD）检测的广泛实验表明，该方法在现有方法中具有可靠性和优越性。&lt;h4&gt;翻译&lt;/h4&gt;Graph神经网络在多样化的网络建模任务中取得了令人印象深刻的成果，但在图上准确估计不确定性仍然很困难，尤其是在分布偏移的情况下。与传统的不确定性估计不同，基于图的不确定性必须考虑由图的结构及其标签分布产生的随机性，这增加了复杂性。在本文中，我们将由Matern高斯过程驱动的随机偏微分方程（SPDE）的演化与使用GNN层的消息传递之间的类比，提出了一种设计新消息传递方案的原则方法，该方案结合了由SPDE的高斯过程方法启发的空间-时间噪声。我们的方法同时捕捉空间和时间上的不确定性，并允许显式控制协方差核的平滑度，从而增强了在标签信息量低和高的情况下图上的不确定性估计。我们在具有不同标签信息量的图数据集上进行Out-of-Distribution（OOD）检测的广泛实验表明，我们的模型在现有方法中具有可靠性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks have achieved impressive results across diverse networkmodeling tasks, but accurately estimating uncertainty on graphs remainsdifficult, especially under distributional shifts. Unlike traditionaluncertainty estimation, graph-based uncertainty must account for randomnessarising from both the graph's structure and its label distribution, which addscomplexity. In this paper, making an analogy between the evolution of astochastic partial differential equation (SPDE) driven by Matern GaussianProcess and message passing using GNN layers, we present a principled way todesign a novel message passing scheme that incorporates spatial-temporal noisesmotivated by the Gaussian Process approach to SPDE. Our method simultaneouslycaptures uncertainty across space and time and allows explicit control over thecovariance kernel smoothness, thereby enhancing uncertainty estimates on graphswith both low and high label informativeness. Our extensive experiments onOut-of-Distribution (OOD) detection on graph datasets with varying labelinformativeness demonstrate the soundness and superiority of our model toexisting approaches.</description>
      <author>example@mail.com (Fred Xu, Thomas Markovich)</author>
      <guid isPermaLink="false">2506.06907v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Employing Discrete Fourier Transform in Representational Learning</title>
      <link>http://arxiv.org/abs/2506.06765v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过输入重建进行图像表示学习的新方法，使用离散傅里叶变换（DFT）作为学习目标，在CIFAR-10数据集上取得了52.8%的top-1准确率，优于传统的自编码器。&lt;h4&gt;背景&lt;/h4&gt;图像表示学习在机器学习中用于生成可被任意下游任务有效利用的表示，常用的方法是使用自编码器在网络的压缩点提取潜在表示。&lt;h4&gt;目的&lt;/h4&gt;提出一种替代的学习目标，即使用输入的离散傅里叶变换（DFT）作为重建目标。&lt;h4&gt;方法&lt;/h4&gt;使用DFT提供每个频率级别的有意义全局信息，使单个频率分量作为单独的学习目标。对于多维输入数据，DFT通过允许在特定维度上选择性变换，同时保留其他维度的计算，提供了显著的灵活性。此外，某些类型的输入在频率分布中表现出特定的模式，允许我们关注频率子集而不是整个频谱。&lt;h4&gt;主要发现&lt;/h4&gt;DFT作为学习目标适用于表示学习，使用DFT在CIFAR-10上达到了52.8%的top-1准确率，并优于传统的自编码器。仅在低频分量（具有最高幅度的分量）上进行训练，其结果与使用完整频谱相当，准确率仅略有下降。&lt;h4&gt;结论&lt;/h4&gt;DFT是一种有效的学习目标，可以用于图像表示学习，并且这种方法在CIFAR-10数据集上取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通过输入重建进行图像表示学习是机器学习中生成可被任意下游任务有效利用的表示的一种常见技术。一种已建立的方法是使用自编码器在网络压缩点提取潜在表示。这些表示很有价值，因为它们保留了从压缩的潜在空间重建原始输入所需的基本信息。在本文中，我们提出了一种替代的学习目标。我们不是使用原始输入作为重建目标，而是使用输入的离散傅里叶变换（DFT）。DFT在每个频率级别上提供了有意义的全局信息，使单个频率分量作为单独的学习目标变得有用。处理多维输入数据时，DFT通过允许在特定维度上选择性变换，同时保留其他维度的计算，提供了显著的灵活性。此外，某些类型的输入在其频率分布中表现出特定的模式，其中特定的频率分量始终包含大部分幅度，允许我们关注频率的子集而不是整个频谱。这些特性使DFT成为表示学习的一种可行学习目标，我们通过在CIFAR-10上实现52.8%的top-1准确率并优于相同架构配置下的传统自编码器12.8个百分点来验证我们的方法。此外，我们还证明，仅在低频分量（具有最高幅度的分量）上进行训练，其结果与使用完整频谱相当，准确率仅略有下降。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image Representation learning via input reconstruction is a common techniquein machine learning for generating representations that can be effectivelyutilized by arbitrary downstream tasks. A well-established approach is usingautoencoders to extract latent representations at the network's compressionpoint. These representations are valuable because they retain essentialinformation necessary for reconstructing the original input from the compressedlatent space. In this paper, we propose an alternative learning objective.Instead of using the raw input as the reconstruction target, we employ theDiscrete Fourier Transform (DFT) of the input. The DFT provides meaningfulglobal information at each frequency level, making individual frequencycomponents useful as separate learning targets. When dealing withmultidimensional input data, the DFT offers remarkable flexibility by enablingselective transformation across specific dimensions while preserving others inthe computation. Moreover, certain types of input exhibit distinct patterns intheir frequency distributions, where specific frequency components consistentlycontain most of the magnitude, allowing us to focus on a subset of frequenciesrather than the entire spectrum. These characteristics position the DFT as aviable learning objective for representation learning and we validate ourapproach by achieving 52.8% top-1 accuracy on CIFAR-10 with ResNet-50 andoutperforming the traditional autoencoder by 12.8 points under identicalarchitectural configurations. Additionally, we demonstrate that training ononly the lower-frequency components - those with the highest magnitudes yieldsresults comparable to using the full frequency spectrum, with only minimalreductions in accuracy.</description>
      <author>example@mail.com (Raoof HojatJalali, Edmondo Trentin)</author>
      <guid isPermaLink="false">2506.06765v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Towards Terrain-Aware Task-Driven 3D Scene Graph Generation in Outdoor Environments</title>
      <link>http://arxiv.org/abs/2506.06562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 2025 IEEE ICRA Workshop on Field Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了三维场景图（3DSGs）在室外环境中的应用，提出了一种生成适用于大型室外场景的任务无关度量-语义点云的方法，并对现有的室内3DSG生成技术进行了修改以适应室外环境。&lt;h4&gt;背景&lt;/h4&gt;传统的三维场景表示方法如点云和占用网格提供了详细的几何信息，但缺乏结构化和语义组织，不足以支持高级推理。&lt;h4&gt;目的&lt;/h4&gt;研究3DSGs在室外环境中的构建和实用性，并展示其在实际机器人应用中的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种生成适用于大型室外场景的任务无关度量-语义点云的方法，并对室内3DSG生成技术进行了修改。&lt;h4&gt;主要发现&lt;/h4&gt;初步的定性结果表明室外3DSGs的可行性和在现实世界机器人应用中的潜在价值。&lt;h4&gt;结论&lt;/h4&gt;室外3DSGs在提高机器人对环境的结构化推理和决策能力方面具有巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-level autonomous operations depend on a robot's ability to construct asufficiently expressive model of its environment. Traditional three-dimensional(3D) scene representations, such as point clouds and occupancy grids, providedetailed geometric information but lack the structured, semantic organizationneeded for high-level reasoning. 3D scene graphs (3DSGs) address thislimitation by integrating geometric, topological, and semantic relationshipsinto a multi-level graph-based representation. By capturing hierarchicalabstractions of objects and spatial layouts, 3DSGs enable robots to reasonabout environments in a structured manner, improving context-awaredecision-making and adaptive planning. Although most recent work has focused onindoor 3DSGs, this paper investigates their construction and utility in outdoorenvironments. We present a method for generating a task-agnosticmetric-semantic point cloud for large outdoor settings and proposemodifications to existing indoor 3DSG generation techniques for outdoorapplicability. Our preliminary qualitative results demonstrate the feasibilityof outdoor 3DSGs and highlight their potential for future deployment inreal-world field robotic applications.</description>
      <author>example@mail.com (Chad R Samuelson, Timothy W McLain, Joshua G Mangelson)</author>
      <guid isPermaLink="false">2506.06562v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>A Study on the Fine-Tuning Performance of Universal Machine-Learned Interatomic Potentials (U-MLIPs)</title>
      <link>http://arxiv.org/abs/2506.07401v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于MACE的两种基础模型MACE-MP-0及其变体MACE-MP-0b的微调，发现微调可以提高模型在特定任务上的准确性，并且在某些情况下优于从头开始训练的模型。&lt;h4&gt;背景&lt;/h4&gt;U-MLIPs在多样化的原子系统中表现出有效性，但通常需要针对特定任务进行微调以提高准确性。&lt;h4&gt;目的&lt;/h4&gt;探究MACE-MP-0和MACE-MP-0b的微调效果，并识别关键见解。&lt;h4&gt;方法&lt;/h4&gt;在特定任务的数据集上进行微调，并通过过滤或主动学习优化数据集选择。&lt;h4&gt;主要发现&lt;/h4&gt;微调能够提高准确性，并且由于基础模型提供的强大初始预测，微调模型能够更快地收敛。微调的成功也依赖于仔细的数据集选择。&lt;h4&gt;结论&lt;/h4&gt;通过微调可以提升模型在原子模拟中的性能，并且提出了实现更好的微调基础模型的实际策略，探讨了未来发展和应用的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通用的机器学习原子间势能（U-MLIPs）在不同原子系统中证明了其有效性，但通常需要针对特定任务进行微调以提升准确性。我们研究了基于MACE的两种基础模型MACE-MP-0及其变体MACE-MP-0b的微调，并得出了关键见解。针对特定任务的数据集进行微调可以提高准确性，在某些情况下甚至优于从头开始训练的模型。此外，由于基础模型提供的强大初始预测，微调模型能够实现更快的收敛。微调的成功也依赖于数据集选择的精心，这可以通过过滤或主动学习来优化。我们进一步讨论了在原子模拟中实现更好微调基础模型的实际策略，并探索了其发展和应用的未来方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Universal machine-learned interatomic potentials (U-MLIPs) have demonstratedeffectiveness across diverse atomistic systems but often require fine-tuningfor task-specific accuracy. We investigate the fine-tuning of two MACE-basedfoundation models, MACE-MP-0 and its variant MACE-MP-0b, and identify keyinsights. Fine-tuning on task-specific datasets enhances accuracy and, in somecases, outperforms models trained from scratch. Additionally, fine-tuned modelsbenefit from faster convergence due to the strong initial predictions providedby the foundation model. The success of fine-tuning also depends on carefuldataset selection, which can be optimized through filtering or active learning.We further discuss practical strategies for achieving better fine-tuningfoundation models in atomistic simulations and explore future directions fortheir development and applications.</description>
      <author>example@mail.com (Xiaoqing Liu, Kehan Zeng, Yangshuai Wang, Teng Zhao)</author>
      <guid isPermaLink="false">2506.07401v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>GazeNLQ @ Ego4D Natural Language Queries Challenge 2025</title>
      <link>http://arxiv.org/abs/2506.05782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GazeNLQ的解决方案，用于解决CVPR 2025的Ego4D自然语言查询（NLQ）挑战，通过利用注视信息来检索与给定自然语言查询相匹配的视频片段。&lt;h4&gt;背景&lt;/h4&gt;以自拍摄像头捕捉的场景为背景，注视作为非言语交流的关键线索，反映了视觉注意力和人类意图与认知。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用注视信息来检索视频片段的新方法，以匹配自然语言查询。&lt;h4&gt;方法&lt;/h4&gt;引入了一种基于对比学习的预训练策略，用于直接从视频中估计注视，并将估计的注视用于增强模型中的视频表示，从而提高定位精度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，GazeNLQ在R1@IoU0.3和R1@IoU0.5的指标上分别达到了27.82和18.68。&lt;h4&gt;结论&lt;/h4&gt;GazeNLQ是一种有效的视频检索方法，可以显著提高自然语言查询的准确性。&lt;h4&gt;翻译&lt;/h4&gt;本报告介绍了我们在CVPR 2025 Ego4D自然语言查询（NLQ）挑战中的解决方案。以佩戴者视角捕捉的场景为背景，注视作为关键的非言语交流线索，反映了视觉注意力和人类意图与认知。受此启发，我们提出了一种新的方法，称为GazeNLQ，该方法利用注视信息检索与给定自然语言查询匹配的视频片段。具体而言，我们引入了一种基于对比学习的预训练策略，用于直接从视频中估计注视。估计的注视用于增强模型中的视频表示，从而提高定位精度。实验结果表明，GazeNLQ在R1@IoU0.3和R1@IoU0.5的指标上分别达到了27.82和18.68。我们的代码可在https://github.com/stevenlin510/GazeNLQ上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This report presents our solution to the Ego4D Natural Language Queries (NLQ)Challenge at CVPR 2025. Egocentric video captures the scene from the wearer'sperspective, where gaze serves as a key non-verbal communication cue thatreflects visual attention and offer insights into human intention andcognition. Motivated by this, we propose a novel approach, GazeNLQ, whichleverages gaze to retrieve video segments that match given natural languagequeries. Specifically, we introduce a contrastive learning-based pretrainingstrategy for gaze estimation directly from video. The estimated gaze is used toaugment video representations within proposed model, thereby enhancinglocalization accuracy. Experimental results show that GazeNLQ achievesR1@IoU0.3 and R1@IoU0.5 scores of 27.82 and 18.68, respectively. Our code isavailable at https://github.com/stevenlin510/GazeNLQ.</description>
      <author>example@mail.com (Wei-Cheng Lin, Chih-Ming Lien, Chen Lo, Chia-Hung Yeh)</author>
      <guid isPermaLink="false">2506.05782v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>FuncGNN: Learning Functional Semantics of Logic Circuits with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.06787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FuncGNN的方法，用于解决集成电路规模增长和设计复杂性提升带来的AIGs结构异质性和全局逻辑信息损失问题，提高了逻辑电路表示的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;随着集成电路规模的扩大和设计复杂性的增加，有效的电路表示对于逻辑综合、形式验证和其他电子设计自动化流程至关重要。AIGs作为一种紧凑和规范的结构，被广泛应用于布尔逻辑的表示。&lt;h4&gt;目的&lt;/h4&gt;为了解决AIGs中结构异质性和全局逻辑信息损失的问题，提高电路模型的准确性。&lt;h4&gt;方法&lt;/h4&gt;FuncGNN通过集成混合特征聚合来提取多粒度拓扑模式，以减轻结构异质性并增强逻辑电路表示。此外，FuncGNN引入了门感知归一化，以适应电路特定的门分布，提高对结构异质性的鲁棒性。最后，FuncGNN采用多层集成来合并跨层的中间特征，有效地综合局部和全局语义信息，以实现全面的逻辑表示。&lt;h4&gt;主要发现&lt;/h4&gt;在两个逻辑级分析任务（即信号概率预测和真值表距离预测）上，FuncGNN的表现优于现有的最先进方法，分别提高了2.06%和18.71%，同时将训练时间减少了约50.6%，GPU内存使用量减少了约32.8%。&lt;h4&gt;结论&lt;/h4&gt;FuncGNN能够有效提高逻辑电路表示的准确性，并显著减少训练时间和GPU内存使用量，是一种具有潜力的电子设计自动化工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As integrated circuit scale grows and design complexity rises, effectivecircuit representation helps support logic synthesis, formal verification, andother automated processes in electronic design automation. And-Inverter Graphs(AIGs), as a compact and canonical structure, are widely adopted forrepresenting Boolean logic in these workflows. However, the increasingcomplexity and integration density of modern circuits introduce structuralheterogeneity and global logic information loss in AIGs, posing significantchallenges to accurate circuit modeling. To address these issues, we proposeFuncGNN, which integrates hybrid feature aggregation to extractmulti-granularity topological patterns, thereby mitigating structuralheterogeneity and enhancing logic circuit representations. FuncGNN furtherintroduces gate-aware normalization that adapts to circuit-specific gatedistributions, improving robustness to structural heterogeneity. Finally,FuncGNN employs multi-layer integration to merge intermediate features acrosslayers, effectively synthesizing local and global semantic information forcomprehensive logic representations. Experimental results on two logic-levelanalysis tasks (i.e., signal probability prediction and truth-table distanceprediction) demonstrate that FuncGNN outperforms existing state-of-the-artmethods, achieving improvements of 2.06% and 18.71%, respectively, whilereducing training time by approximately 50.6% and GPU memory usage by about32.8%.</description>
      <author>example@mail.com (Qiyun Zhao)</author>
      <guid isPermaLink="false">2506.06787v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>DINO-CoDT: Multi-class Collaborative Detection and Tracking with Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2506.07375v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对多样化道路用户的多类协同检测和跟踪框架，以增强环境理解。&lt;h4&gt;背景&lt;/h4&gt;协同感知在扩展感知范围和增强对传感器故障的鲁棒性方面发挥着关键作用，主要涉及协同3D检测和跟踪任务。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有工作中主要关注车辆类别而缺乏多类协同检测和跟踪有效解决方案的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种包含全局空间注意力融合（GSAF）模块的检测器，用于增强多尺度特征学习；引入了一种基于视觉语义和视觉基础模型的tracklet RE-IDentification（REID）模块，以减少涉及小物体（如行人）的错误匹配；设计了基于速度的适应性tracklet管理（VATM）模块，动态调整跟踪间隔。&lt;h4&gt;主要发现&lt;/h4&gt;在V2X-Real和OPV2V数据集上的大量实验表明，该方法在检测和跟踪精度方面显著优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;该框架在多类协同检测和跟踪方面取得了显著成效，提高了实际场景中的应用能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：协作感知在增强环境理解方面发挥着关键作用，通过扩展感知范围和提高对传感器故障的鲁棒性，这主要涉及协同3D检测和跟踪任务。前者侧重于单个帧中的物体识别，而后者则捕捉随时间变化的连续实例tracklets。然而，现有工作在这两个领域主要关注车辆类别，缺乏有效的多类协同检测和跟踪解决方案。这种局限性阻碍了它们在实际场景中的应用，这些场景涉及具有不同外观和运动模式的各种物体类别。为了克服这些局限性，我们提出了一种针对多样化道路用户的多类协同检测和跟踪框架。我们首先提出了一种包含全局空间注意力融合（GSAF）模块的检测器，用于增强不同大小物体的多尺度特征学习。接下来，我们介绍了一种利用视觉语义和视觉基础模型的tracklet RE-IDentification（REID）模块，以有效减少涉及小物体（如行人）的错误匹配。我们进一步设计了一种基于速度的适应性tracklet管理（VATM）模块，根据物体运动动态调整跟踪间隔。在V2X-Real和OPV2V数据集上的大量实验表明，我们的方法在检测和跟踪精度方面显著优于现有最先进的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Collaborative perception plays a crucial role in enhancing environmentalunderstanding by expanding the perceptual range and improving robustnessagainst sensor failures, which primarily involves collaborative 3D detectionand tracking tasks. The former focuses on object recognition in individualframes, while the latter captures continuous instance tracklets over time.However, existing works in both areas predominantly focus on the vehiclesuperclass, lacking effective solutions for both multi-class collaborativedetection and tracking. This limitation hinders their applicability inreal-world scenarios, which involve diverse object classes with varyingappearances and motion patterns. To overcome these limitations, we propose amulti-class collaborative detection and tracking framework tailored for diverseroad users. We first present a detector with a global spatial attention fusion(GSAF) module, enhancing multi-scale feature learning for objects of varyingsizes. Next, we introduce a tracklet RE-IDentification (REID) module thatleverages visual semantics with a vision foundation model to effectively reduceID SWitch (IDSW) errors, in cases of erroneous mismatches involving smallobjects like pedestrians. We further design a velocity-based adaptive trackletmanagement (VATM) module that adjusts the tracking interval dynamically basedon object motion. Extensive experiments on the V2X-Real and OPV2V datasets showthat our approach significantly outperforms existing state-of-the-art methodsin both detection and tracking accuracy.</description>
      <author>example@mail.com (Xunjie He, Christina Dao Wen Lee, Meiling Wang, Chengran Yuan, Zefan Huang, Yufeng Yue, Marcelo H. Ang Jr)</author>
      <guid isPermaLink="false">2506.07375v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>AANet: Virtual Screening under Structural Uncertainty via Alignment and Aggregation</title>
      <link>http://arxiv.org/abs/2506.05768v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种适用于结构不确定性的虚拟筛选方法，通过对比学习和跨注意力机制，提高了在缺乏口袋信息的apo结构上的虚拟筛选准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的虚拟筛选方法大多基于已知配体结合口袋的全蛋白结构，在缺乏口袋信息的apo结构或AlphaFold2预测结构上表现不佳。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够在结构不确定性的情况下进行准确虚拟筛选的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种包含两个核心组件的方法：(1) 三模态对比学习模块，用于对配体、全蛋白口袋和从结构中检测到的腔体进行表示对齐，增强对口袋定位错误的鲁棒性；(2) 基于跨注意力的适配器，用于动态聚合候选结合位点，使模型能够在没有精确口袋注释的情况下从活性数据中学习。&lt;h4&gt;主要发现&lt;/h4&gt;在apo结构的新颖基准测试中，该方法在盲apo设置下显著优于现有方法，将早期富集因子（EF1%）从11.75提高到37.19。同时，该方法在holo结构上也保持了强大的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在推进一类新药发现方面具有潜力，尤其是在缺乏实验解决的蛋白-配体复合物的情况下。&lt;h4&gt;翻译&lt;/h4&gt;摘要：虚拟筛选（VS）是现代药物发现的关键组成部分，然而，大多数现有方法——无论是基于物理的还是基于深度学习的——都是围绕已知配体结合口袋的全蛋白结构开发的。因此，它们在apo或AlphaFold2等预测结构上的性能显著下降，这些结构更符合现实世界的早期药物发现，其中口袋信息通常缺失。在本文中，我们介绍了一种对齐和聚合框架，以实现结构不确定性下的准确虚拟筛选。我们的方法包含两个核心组件：(1) 三模态对比学习模块，用于对配体、全蛋白口袋和从结构中检测到的腔体进行表示对齐，从而增强对口袋定位错误的鲁棒性；(2) 基于跨注意力的适配器，用于动态聚合候选结合位点，使模型能够在没有精确口袋注释的情况下从活性数据中学习。我们在apo结构的新颖基准测试中评估了我们的方法，在盲apo设置下，它显著优于现有方法，将早期富集因子（EF1%）从11.75提高到37.19。值得注意的是，它也在holo结构上保持了强大的性能。这些结果证明了我们的方法在推进一类新药发现方面的潜力，尤其是在缺乏实验解决的蛋白-配体复合物的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Virtual screening (VS) is a critical component of modern drug discovery, yetmost existing methods--whether physics-based or deep learning-based--aredeveloped around holo protein structures with known ligand-bound pockets.Consequently, their performance degrades significantly on apo or predictedstructures such as those from AlphaFold2, which are more representative ofreal-world early-stage drug discovery, where pocket information is oftenmissing. In this paper, we introduce an alignment-and-aggregation framework toenable accurate virtual screening under structural uncertainty. Our methodcomprises two core components: (1) a tri-modal contrastive learning module thataligns representations of the ligand, the holo pocket, and cavities detectedfrom structures, thereby enhancing robustness to pocket localization error; and(2) a cross-attention based adapter for dynamically aggregating candidatebinding sites, enabling the model to learn from activity data even withoutprecise pocket annotations. We evaluated our method on a newly curatedbenchmark of apo structures, where it significantly outperformsstate-of-the-art methods in blind apo setting, improving the early enrichmentfactor (EF1%) from 11.75 to 37.19. Notably, it also maintains strongperformance on holo structures. These results demonstrate the promise of ourapproach in advancing first-in-class drug discovery, particularly in scenarioslacking experimentally resolved protein-ligand complexes.</description>
      <author>example@mail.com (Wenyu Zhu, Jianhui Wang, Bowen Gao, Yinjun Jia, Haichuan Tan, Ya-Qin Zhang, Wei-Ying Ma, Yanyan Lan)</author>
      <guid isPermaLink="false">2506.05768v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Paged Attention Meets FlexAttention: Unlocking Long-Context Efficiency in Deployed Inference</title>
      <link>http://arxiv.org/abs/2506.07311v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的PagedAttention与PyTorch的FlexAttention集成方法，以解决LLMs在长上下文推理中的内存效率问题，并在IBM的FMS中实现了融合的注意力内核，显著降低了推理延迟。&lt;h4&gt;背景&lt;/h4&gt;LLMs在长上下文推理过程中由于传统的键值缓存处理方式而面临严重的内存效率问题。&lt;h4&gt;目的&lt;/h4&gt;提高LLMs在长上下文推理中的内存效率。&lt;h4&gt;方法&lt;/h4&gt;通过引入PagedAttention与PyTorch的FlexAttention的集成，优化了内部碎片化和与单一键值缓存分配相关的效率问题。&lt;h4&gt;主要发现&lt;/h4&gt;在NVIDIA L4 GPU（24GB）上进行的基准测试表明，使用全局键值缓存时，推理延迟显著降低，与序列长度从128到2048个标记的增长呈线性关系（约2倍），而未使用缓存时，延迟呈指数增长。尽管单步评估的峰值内存使用量基本保持不变（主要由模型权重和激活项决定），但分页注意力引起的增量内存使用量最小，仅在序列长度超过2048个标记时才可观察到，这是由于其2的幂次缓存分配。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法对未来的长上下文模型部署具有重要意义，并且已经开源了完整的实现。&lt;h4&gt;翻译&lt;/h4&gt;Large Language Models (LLMs) encounter severe memory inefficiencies during long-context inference due to conventional handling of key-value (KV) caches. In this work, we introduce a novel integration of PagedAttention with PyTorch's FlexAttention, addressing internal fragmentation and inefficiencies associated with monolithic KV cache allocations. Implemented within IBM's Foundation ModelStack (FMS), our fused attention kernel efficiently gathers scattered KV data. Our benchmarks on an NVIDIA L4 GPU (24GB) demonstrate significantly reduced inference latency, growing only linearly (~2x) with sequence length from 128 to 2048 tokens when utilizing a global KV cache, compared to exponential latency increases without caching. While peak memory usage remains largely unchanged for single-step evaluations (dominated by model weights and activations), paged attention causes minimal incremental memory usage, observable only at sequence lengths exceeding 2048 tokens due to its power-of-two cache allocations. We open-source the full implementation and discuss its implications for future long-context model deployment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) encounter severe memory inefficiencies duringlong-context inference due to conventional handling of key-value (KV) caches.In this work, we introduce a novel integration of PagedAttention with PyTorch'sFlexAttention, addressing internal fragmentation and inefficiencies associatedwith monolithic KV cache allocations. Implemented within IBM's Foundation ModelStack (FMS), our fused attention kernel efficiently gathers scattered KV data.Our benchmarks on an NVIDIA L4 GPU (24GB) demonstrate significantly reducedinference latency, growing only linearly (~2x) with sequence length from 128 to2048 tokens when utilizing a global KV cache, compared to exponential latencyincreases without caching. While peak memory usage remains largely unchangedfor single-step evaluations (dominated by model weights and activations), pagedattention causes minimal incremental memory usage, observable only at sequencelengths exceeding 2048 tokens due to its power-of-two cache allocations. Weopen-source the full implementation and discuss its implications for futurelong-context model deployment.</description>
      <author>example@mail.com (Thomas Joshi, Herman Saini, Neil Dhillon, Antoni Viros i Martin, Kaoutar El Maghraoui)</author>
      <guid isPermaLink="false">2506.07311v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>When Better Features Mean Greater Risks: The Performance-Privacy Trade-Off in Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.05743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted In ACM ASIA Conference on Computer and Communications  Security (ASIA CCS '25), August 25-29, 2025, Ha Noi, Vietnam. For Code, see  https://github.com/SeroneySun/LpLA_code&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了针对编码器模型的成员推理攻击（MIAs）带来的隐私威胁，特别是聚焦于对比学习框架，并提出了一种基于特征向量p-norm的成员推理攻击方法LpLA，旨在揭示模型架构复杂性与隐私泄露风险之间的关系，并提升隐私保护。&lt;h4&gt;背景&lt;/h4&gt;随着深度学习技术的快速发展，预训练编码器模型在特征提取方面表现出色，但在广泛应用中引发了对训练数据隐私泄露风险的担忧。&lt;h4&gt;目的&lt;/h4&gt;系统地调查针对编码器模型的成员推理攻击带来的隐私威胁，并提出一种新的攻击方法。&lt;h4&gt;方法&lt;/h4&gt;通过实验分析模型架构复杂性与隐私泄露风险之间的关系，提出基于特征向量p-norm的LpLA方法，并通过多个数据集和模型架构进行实验验证。&lt;h4&gt;主要发现&lt;/h4&gt;发现更先进的编码器框架在提高特征提取性能的同时，也加剧了隐私泄露风险。LpLA在攻击性能和鲁棒性方面优于现有方法，尤其在有限的攻击知识和查询量下表现突出。&lt;h4&gt;结论&lt;/h4&gt;本研究不仅揭示了对比学习框架中隐私泄露的潜在风险，还为编码器模型的隐私保护研究提供了实践基础，并强调了在模型效用和训练数据隐私之间的平衡重要性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着深度学习技术的快速发展，预训练编码器模型在特征提取方面表现出色，在深度学习的研究和应用中发挥着关键作用。然而，它们的广泛应用引发了关于训练数据隐私泄露风险的重大担忧。本文系统地研究了针对编码器模型的成员推理攻击（MIAs）带来的隐私威胁，重点关注对比学习框架。通过实验分析，我们揭示了模型架构复杂性对成员隐私泄露的显著影响：随着更先进的编码器框架提高特征提取性能，它们同时加剧了隐私泄露风险。此外，本文提出了一种基于特征向量p-norm的新颖成员推理攻击方法，称为嵌入Lp-Norm似然攻击（LpLA）。这种方法通过利用特征向量p-norm的统计分布特性来推断成员状态。多个数据集和模型架构的实验结果表明，LpLA在攻击性能和鲁棒性方面优于现有方法，尤其是在有限的攻击知识和查询量下。本研究不仅揭示了对比学习框架中隐私泄露的潜在风险，还为编码器模型的隐私保护研究提供了实践基础。我们希望这项工作将引起对与自监督学习模型相关的隐私风险的更多关注，并阐明在模型效用和训练数据隐私之间平衡的重要性。我们的代码在https://github.com/SeroneySun/LpLA_code上公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3708821.3733915&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid advancement of deep learning technology, pre-trained encodermodels have demonstrated exceptional feature extraction capabilities, playing apivotal role in the research and application of deep learning. However, theirwidespread use has raised significant concerns about the risk of training dataprivacy leakage. This paper systematically investigates the privacy threatsposed by membership inference attacks (MIAs) targeting encoder models, focusingon contrastive learning frameworks. Through experimental analysis, we revealthe significant impact of model architecture complexity on membership privacyleakage: As more advanced encoder frameworks improve feature-extractionperformance, they simultaneously exacerbate privacy-leakage risks. Furthermore,this paper proposes a novel membership inference attack method based on thep-norm of feature vectors, termed the Embedding Lp-Norm Likelihood Attack(LpLA). This method infers membership status, by leveraging the statisticaldistribution characteristics of the p-norm of feature vectors. Experimentalresults across multiple datasets and model architectures demonstrate that LpLAoutperforms existing methods in attack performance and robustness, particularlyunder limited attack knowledge and query volumes. This study not only uncoversthe potential risks of privacy leakage in contrastive learning frameworks, butalso provides a practical basis for privacy protection research in encodermodels. We hope that this work will draw greater attention to the privacy risksassociated with self-supervised learning models and shed light on theimportance of a balance between model utility and training data privacy. Ourcode is publicly available at: https://github.com/SeroneySun/LpLA_code.</description>
      <author>example@mail.com (Ruining Sun, Hongsheng Hu, Wei Luo, Zhaoxi Zhang, Yanjun Zhang, Haizhuan Yuan, Leo Yu Zhang)</author>
      <guid isPermaLink="false">2506.05743v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Estimation of the curvature from random samples</title>
      <link>http://arxiv.org/abs/2506.06779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过从曲线或曲面上采样得到的有限样本点来估计曲线和曲面曲率的估计器。&lt;h4&gt;背景&lt;/h4&gt;研究者们需要一种方法来估计曲线和曲面的曲率。&lt;h4&gt;目的&lt;/h4&gt;开发一种算法来估计曲线和曲面在特定点的曲率，并将其扩展到估计曲面的高斯曲率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种算法来估计曲线曲率，并将其扩展以估计曲面高斯曲率。该算法利用点云中选定点数与给定点具有足够邻近点的概率之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;算法能够通过控制点云中点的数量来估计曲率。&lt;h4&gt;结论&lt;/h4&gt;该方法为曲率估计提供了一种新的工具，可以应用于曲线和曲面的几何分析。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种通过使用从具有曲线或曲面支撑的概率分布中抽取的有限样本点来估计曲线和曲面曲率的估计器。首先，我们给出了一种估计曲线给定点的曲率的算法。然后，我们将它扩展到估计曲面的高斯曲率。在所提出的算法中，我们使用了点云中选定点数与给定点具有足够邻近点的概率之间的关系。这种关系使我们能够控制点云中所需点的数量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce an estimator for the curvature of curves and surfaces by usingfinite sample points drawn from sampling a probability distribution that hassupport on the curve or surface. First we give an algorithm for estimation ofthe curvature in a given point of a curve. Then, we extend it to estimate theGaussian curvature of the surfaces. In the proposed algorithms, we use arelation between the number of selected points in the point cloud and theprobability that a given point has a suffcient number of nearby points. Thisrelation allows us to control the required number of points in the point cloud.</description>
      <author>example@mail.com (R. Mirzaie)</author>
      <guid isPermaLink="false">2506.06779v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Harnessing Vision-Language Models for Time Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2506.06836v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉语言模型（VLM）的时间序列异常检测（TSAD）方法，旨在提高异常检测的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;时间序列异常检测在医疗、金融和工业监测等领域发挥着重要作用。传统方法主要关注在数值数据上训练特定领域的模型，但缺乏人类专家在识别情境异常方面的视觉-时间推理能力。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文探索了一种基于视觉语言模型（VLM）的解决方案，以增强异常检测的能力。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种两阶段解决方案：(1) ViT4TS，基于轻量级预训练视觉编码器构建的视觉筛选阶段，利用二维时间序列表示来准确定位候选异常；(2) VLM4TS，基于VLM的阶段，整合全局时间上下文和VLM推理能力，对ViT4TS提供的候选异常进行细化检测。&lt;h4&gt;主要发现&lt;/h4&gt;VLM4TS在大多数情况下，无需时间序列训练，在准确性和效率上都优于时间序列预训练和从头开始的基线，F1-max分数提高了24.6%。此外，VLM4TS在token使用效率上也优于现有的基于语言模型的TSAD方法，平均效率提高了36倍。&lt;h4&gt;结论&lt;/h4&gt;VLM4TS是一种有效且高效的时间序列异常检测方法，为该领域的研究提供了新的思路和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time-series anomaly detection (TSAD) has played a vital role in a variety offields, including healthcare, finance, and industrial monitoring. Priormethods, which mainly focus on training domain-specific models on numericaldata, lack the visual-temporal reasoning capacity that human experts have toidentify contextual anomalies. To fill this gap, we explore a solution based onvision language models (VLMs). Recent studies have shown the ability of VLMsfor visual reasoning tasks, yet their direct application to time series hasfallen short on both accuracy and efficiency. To harness the power of VLMs forTSAD, we propose a two-stage solution, with (1) ViT4TS, a vision-screeningstage built on a relatively lightweight pretrained vision encoder, whichleverages 2-D time-series representations to accurately localize candidateanomalies; (2) VLM4TS, a VLM-based stage that integrates global temporalcontext and VLM reasoning capacity to refine the detection upon the candidatesprovided by ViT4TS. We show that without any time-series training, VLM4TSoutperforms time-series pretrained and from-scratch baselines in most cases,yielding a 24.6 percent improvement in F1-max score over the best baseline.Moreover, VLM4TS also consistently outperforms existing language-model-basedTSAD methods and is on average 36 times more efficient in token usage.</description>
      <author>example@mail.com (Zelin He, Sarah Alnegheimish, Matthew Reimherr)</author>
      <guid isPermaLink="false">2506.06836v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>From Generation to Generalization: Emergent Few-Shot Learning in Video Diffusion Models</title>
      <link>http://arxiv.org/abs/2506.07280v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 23 figures, 9 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;视频扩散模型（VDMs）作为强大的生成工具，能够合成高质量的时空内容，其潜力远不止视频生成。VDMs的训练动态，由建模连贯序列的需求驱动，自然促使它们内化结构化的表示和视觉世界的隐含理解。&lt;h4&gt;背景&lt;/h4&gt;VDMs在视频生成领域取得了显著进展，但其潜在能力还未被完全挖掘。&lt;h4&gt;目的&lt;/h4&gt;为了探测VDMs内部知识范围，研究引入了一种小样本微调框架，利用少量示例重新部署VDMs以执行新任务。&lt;h4&gt;方法&lt;/h4&gt;该方法将每个任务转化为视觉过渡，使得模型可以在不改变冻结VDM生成界面的情况下，通过短输入输出序列训练LoRA权重。&lt;h4&gt;主要发现&lt;/h4&gt;尽管只有最小量的监督，该模型在多种任务上表现出强大的泛化能力，从低级视觉任务（如分割和姿态估计）到高级推理任务（如在ARC-AGI上）。&lt;h4&gt;结论&lt;/h4&gt;这些结果将VDMs重新定义为不仅仅是生成引擎，而是适应性视觉学习者，有潜力成为未来视觉领域基础模型的骨干。&lt;h4&gt;翻译&lt;/h4&gt;Video Diffusion Models (VDMs) have emerged as powerful generative tools, capable of synthesizing high-quality spatiotemporal content. Yet, their potential goes far beyond mere video generation. We argue that the training dynamics of VDMs, driven by the need to model coherent sequences, naturally pushes them to internalize structured representations and an implicit understanding of the visual world. To probe the extent of this internal knowledge, we introduce a few-shot fine-tuning framework that repurposes VDMs for new tasks using only a handful of examples. Our method transforms each task into a visual transition, enabling the training of LoRA weights on short input-output sequences without altering the generative interface of a frozen VDM. Despite minimal supervision, the model exhibits strong generalization across diverse tasks, from low-level vision (for example, segmentation and pose estimation) to high-level reasoning (for example, on ARC-AGI). These results reframe VDMs as more than generative engines. They are adaptable visual learners with the potential to serve as the backbone for future foundation models in vision.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Diffusion Models (VDMs) have emerged as powerful generative tools,capable of synthesizing high-quality spatiotemporal content. Yet, theirpotential goes far beyond mere video generation. We argue that the trainingdynamics of VDMs, driven by the need to model coherent sequences, naturallypushes them to internalize structured representations and an implicitunderstanding of the visual world. To probe the extent of this internalknowledge, we introduce a few-shot fine-tuning framework that repurposes VDMsfor new tasks using only a handful of examples. Our method transforms each taskinto a visual transition, enabling the training of LoRA weights on shortinput-output sequences without altering the generative interface of a frozenVDM. Despite minimal supervision, the model exhibits strong generalizationacross diverse tasks, from low-level vision (for example, segmentation and poseestimation) to high-level reasoning (for example, on ARC-AGI). These resultsreframe VDMs as more than generative engines. They are adaptable visuallearners with the potential to serve as the backbone for future foundationmodels in vision.</description>
      <author>example@mail.com (Pablo Acuaviva, Aram Davtyan, Mariam Hassan, Sebastian Stapf, Ahmad Rahimi, Alexandre Alahi, Paolo Favaro)</author>
      <guid isPermaLink="false">2506.07280v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>IQFM A Wireless Foundational Model for I/Q Streams in AI-Native 6G</title>
      <link>http://arxiv.org/abs/2506.06718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为IQFM的I/Q信号基础模型，用于无线通信，支持多种任务，如调制分类、到达角（AoA）、波束预测和射频指纹识别，无需复杂的预处理或手工特征。该模型在对比自监督学习（SSL）框架下，通过任务特定的增强策略，实现了高效的编码和分类，并在多个任务上取得了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;基础模型在自然语言处理和计算机视觉领域显示出巨大的潜力，但在无线通信领域仍处于起步阶段。目前，大多数研究集中在基于图像的模态上，如信道状态信息（CSI）和频率频谱，而直接在原始I/Q数据上操作的基础模型则很少被探索。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够在无线通信领域直接操作原始I/Q数据的基础模型，以支持多种无线通信任务。&lt;h4&gt;方法&lt;/h4&gt;提出IQFM模型，该模型通过任务特定的增强策略和对比自监督学习框架进行训练，并在实际数据上进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;IQFM模型在调制和到达角分类任务上分别达到了99.67%和65.45%的准确率，超过了监督基线模型。此外，该模型还能泛化到分布外的任务，使用少量样本和参数更新即可适应新任务。&lt;h4&gt;结论&lt;/h4&gt;原始I/Q数据基础模型在多任务学习方面具有巨大的潜力，可以作为高效、可重用的编码器，适用于AI原生的6G系统。&lt;h4&gt;翻译&lt;/h4&gt;Foundational models have shown remarkable potential in natural language processing and computer vision, yet remain in their infancy in wireless communications. While a few efforts have explored image-based modalities such as channel state information (CSI) and frequency spectrograms, foundational models that operate directly on raw IQ data remain largely unexplored. This paper presents, IQFM, the first I/Q signal foundational model for wireless communications. IQFM supporting diverse tasks: modulation classification, angle-of-arrival (AoA), beam prediction, and RF fingerprinting, without heavy preprocessing or handcrafted features. We also introduce a task-area augmentation strategy that categorizes transformations into core augmentations, such as cyclic time shifting, and task-specific augmentations. This strategy forms the basis for structured, task-dependent representation learning within a contrastive self-supervised learning (SSL) framework. Using this strategy, the lightweight encoder, pre-trained via SSL on over-the-air multi-antenna IQ data, achieves up to 99.67% and 65.45% accuracy on modulation and AoA classification, respectively, using only one labeled sample per class, outperforming supervised baselines by up to 7x and 145x. The model also generalizes to out-of-distribution tasks; when adapted to new tasks using only 500 samples per class and minimal parameter updates via LoRA, the same frozen encoder achieves 94.15% on beam prediction (vs. 89.53% supervised), 50.00% on RML2016a modulation classification (vs. 49.30%), and 96.05% on RF fingerprinting (vs. 96.64%). These results demonstrate the potential of raw IQ-based foundational models as efficient, reusable encoders for multi-task learning in AI-native 6G systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundational models have shown remarkable potential in natural languageprocessing and computer vision, yet remain in their infancy in wirelesscommunications. While a few efforts have explored image-based modalities suchas channel state information (CSI) and frequency spectrograms, foundationalmodels that operate directly on raw IQ data remain largely unexplored. Thispaper presents, IQFM, the first I/Q signal foundational model for wirelesscommunications. IQFM supporting diverse tasks: modulation classification,angle-of-arrival (AoA), beam prediction, and RF fingerprinting, without heavypreprocessing or handcrafted features. We also introduce a task-awareaugmentation strategy that categorizes transformations into core augmentations,such as cyclic time shifting, and task-specific augmentations. This strategyforms the basis for structured, task-dependent representation learning within acontrastive self-supervised learning (SSL) framework. Using this strategy, thelightweight encoder, pre-trained via SSL on over-the-air multi-antenna IQ data,achieves up to 99.67% and 65.45% accuracy on modulation and AoA classification,respectively, using only one labeled sample per class, outperforming supervisedbaselines by up to 7x and 145x. The model also generalizes toout-of-distribution tasks; when adapted to new tasks using only 500 samples perclass and minimal parameter updates via LoRA, the same frozen encoder achieves94.15% on beam prediction (vs. 89.53% supervised), 50.00% on RML2016amodulation classification (vs. 49.30%), and 96.05% on RF fingerprinting (vs.96.64%). These results demonstrate the potential of raw IQ-based foundationalmodels as efficient, reusable encoders for multi-task learning in AI-native 6Gsystems.</description>
      <author>example@mail.com (Omar Mashaal, Hatem Abou-Zeid)</author>
      <guid isPermaLink="false">2506.06718v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Situational Awareness in Underwater Robotics with Multi-modal Spatial Perception</title>
      <link>http://arxiv.org/abs/2506.06476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多模态传感的SLAM方法，用于提高水下自主和远程操作的能力。&lt;h4&gt;背景&lt;/h4&gt;水下环境中的光线衰减、散射和低对比度等问题常常导致基于视觉的SLAM方法失效，且这些方法通常依赖于单目或立体视觉输入，限制了其在多相机配置中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种融合来自多个传感器（包括相机、惯性测量单元和声学设备）的数据的方法，以增强情境感知并实现鲁棒的实时SLAM。&lt;h4&gt;方法&lt;/h4&gt;通过几何和基于学习的技术以及语义分析来探索解决方案，并在特隆赫姆峡湾的多个现场部署中收集的数据上进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在视觉挑战性的水下环境中，该方法可以实现实时可靠的状态估计和高质量的3D重建。&lt;h4&gt;结论&lt;/h4&gt;系统存在约束，并提出了需要进一步探索的研究问题，如传感器校准和基于学习方法的局限性，以推进大规模水下作业。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a multi-modal sensing-based SLAM method to enhance the capabilities of underwater autonomous and remote operations. The underwater environment often leads to the failure of vision-based SLAM methods due to issues such as light attenuation, scattering, and low contrast, and these methods typically rely on monocular or stereo vision inputs, limiting their application in multi-camera configurations. The proposed method fuses data from multiple sensors, including cameras, inertial measurement units (IMUs), and acoustic devices, to enhance situational awareness and enable robust, real-time SLAM. Solutions are explored using geometric and learning-based techniques along with semantic analysis, and experiments are conducted on data collected from a work-class ROV during several field deployments in the Trondheim Fjord. The experimental results demonstrate the feasibility of real-time reliable state estimation and high-quality 3D reconstructions in visually challenging underwater conditions. System constraints are discussed, and open research questions, such as sensor calibration and limitations with learning-based methods, are identified for further exploration to advance large-scale underwater operations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous Underwater Vehicles (AUVs) and Remotely Operated Vehicles (ROVs)demand robust spatial perception capabilities, including SimultaneousLocalization and Mapping (SLAM), to support both remote and autonomous tasks.Vision-based systems have been integral to these advancements, capturing richcolor and texture at low cost while enabling semantic scene understanding.However, underwater conditions -- such as light attenuation, backscatter, andlow contrast -- often degrade image quality to the point where traditionalvision-based SLAM pipelines fail. Moreover, these pipelines typically rely onmonocular or stereo inputs, limiting their scalability to the multi-cameraconfigurations common on many vehicles. To address these issues, we propose toleverage multi-modal sensing that fuses data from multiple sensors-includingcameras, inertial measurement units (IMUs), and acoustic devices-to enhancesituational awareness and enable robust, real-time SLAM. We explore bothgeometric and learning-based techniques along with semantic analysis, andconduct experiments on the data collected from a work-class ROV during severalfield deployments in the Trondheim Fjord. Through our experimental results, wedemonstrate the feasibility of real-time reliable state estimation andhigh-quality 3D reconstructions in visually challenging underwater conditions.We also discuss system constraints and identify open research questions, suchas sensor calibration, limitations with learning-based methods, that meritfurther exploration to advance large-scale underwater operations.</description>
      <author>example@mail.com (Pushyami Kaveti, Ambjorn Grimsrud Waldum, Hanumant Singh, Martin Ludvigsen)</author>
      <guid isPermaLink="false">2506.06476v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Promoting Ensemble Diversity with Interactive Bayesian Distributional Robustness for Fine-tuning Foundation Models</title>
      <link>http://arxiv.org/abs/2506.07247v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 (Poster)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Interactive Bayesian Distributional Robustness（IBDR）的新颖贝叶斯推理框架，通过增强粒子多样性来提高集成质量。&lt;h4&gt;背景&lt;/h4&gt;IBDR基于一个广义的理论框架，该框架将分布损失与近似的后验概率联系起来。&lt;h4&gt;目的&lt;/h4&gt;通过实现分布鲁棒性和粒子多样性来提升贝叶斯推理的效率。&lt;h4&gt;方法&lt;/h4&gt;采用了一种双重优化过程，在保证分布鲁棒性的同时促进粒子多样性。&lt;h4&gt;主要发现&lt;/h4&gt;使用VTAB-1K基准和常见推理语言任务评估IBDR的性能，结果显示IBDR优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;IBDR在现实世界应用中的有效性得到证实。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为交互式贝叶斯分布鲁棒性（IBDR）的贝叶斯推理新框架，该框架允许建模粒子之间的相互作用，从而通过增加粒子多样性来提高集成质量。IBDR建立在将分布损失与近似后验概率相联系的一般化理论框架之上，从而激发了一种实用的双重优化过程，该过程强制执行分布鲁棒性同时促进粒子多样性。我们使用VTAB-1K基准和常见推理语言任务将IBDR的性能与各种基线方法进行了比较。结果表明，IBDR在这些基线方法中表现优异，强调了其在现实世界应用中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Interactive Bayesian Distributional Robustness (IBDR), a novelBayesian inference framework that allows modeling the interactions betweenparticles, thereby enhancing ensemble quality through increased particlediversity. IBDR is grounded in a generalized theoretical framework thatconnects the distributional population loss with the approximate posterior,motivating a practical dual optimization procedure that enforces distributionalrobustness while fostering particle diversity. We evaluate IBDR's performanceagainst various baseline methods using the VTAB-1K benchmark and the commonreasoning language task. The results consistently show that IBDR outperformsthese baselines, underscoring its effectiveness in real-world applications.</description>
      <author>example@mail.com (Ngoc-Quan Pham, Tuan Truong, Quyen Tran, Tan Nguyen, Dinh Phung, Trung Le)</author>
      <guid isPermaLink="false">2506.07247v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Caterpillar GNN: Replacing Message Passing with Efficient Aggregation</title>
      <link>http://arxiv.org/abs/2506.06784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  40 pages, 9 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种高效聚合机制的消息传递图神经网络（MPGNNs），通过降低表达力来增强聚合能力，并成功应用于图级别任务。&lt;h4&gt;背景&lt;/h4&gt;现代图学习中的MPGNNs注重表达力的最大化，而本文提出了一个不同的方法。&lt;h4&gt;目的&lt;/h4&gt;通过降低表达力，增强MPGNNs的聚合能力，并提高其在图级别任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;引入了一种高效的聚合机制，该机制允许在经典的消息传递和基于着色或普通游走的方法之间无缝扩展。通过同态计数和广义毛毛虫图的层次结构来严格地描述每一步的表达能力，并基于此提出了毛毛虫GNN。&lt;h4&gt;主要发现&lt;/h4&gt;毛毛虫GNN通过其稳健的图级别聚合能力，在特定的合成图级别任务中成功应对了挑战，这些任务对传统的MPGNNs来说很难。此外，在真实世界的数据集上，毛毛虫GNN在保持预测性能的同时，显著减少了计算图中隐藏层中的节点数量。&lt;h4&gt;结论&lt;/h4&gt;毛毛虫GNN是一种有效的MPGNNs，它通过优化聚合机制在图级别任务中表现出色，并在真实世界数据集上实现了可观的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：消息传递图神经网络（MPGNNs）在现代图学习中占据主导地位，通常优先考虑最大的表达能力。相比之下，我们引入了一种高效的聚合机制，故意牺牲一些表达力以获得更强和更有结构的聚合能力。我们的方法允许在经典的消息传递和基于着色或普通游走的方法之间无缝扩展。我们使用广义毛毛虫图的层次结构中的同态计数严格地描述每个中间步骤的表达能力。基于这个基础，我们提出了毛毛虫GNN，它通过其稳健的图级别聚合能力，能够成功地处理专门为挑战经典MPGNNs而设计的合成图级别任务。此外，我们在真实世界的数据集上证明了，毛毛虫GNN在保持预测性能的同时，显著减少了计算图中隐藏层中的节点数量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Message-passing graph neural networks (MPGNNs) dominate modern graphlearning, typically prioritizing maximal expressive power. In contrast, weintroduce an \emph{efficient aggregation} mechanism, deliberately trading offsome expressivity for stronger and more structured aggregation capabilities.Our approach allows seamless scaling between classical message-passing andsimpler methods based on colored or plain walks. We rigorously characterize theexpressive power at each intermediate step using homomorphism counts from ahierarchy of generalized \emph{caterpillar graphs}. Based on this foundation,we propose the \emph{Caterpillar GNN}, whose robust graph-level aggregationenables it to successfully tackle synthetic graph-level task specificallydesigned to be challenging for classical MPGNNs. Moreover, we demonstrate that,on real-world datasets, the Caterpillar GNN achieves comparable predictiveperformance while significantly reducing the number of nodes in the hiddenlayers of the computational graph.</description>
      <author>example@mail.com (Marek Černý)</author>
      <guid isPermaLink="false">2506.06784v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Challenging Vision-Language Models with Surgical Data: A New Dataset and Broad Benchmarking Study</title>
      <link>http://arxiv.org/abs/2506.06232v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视觉语言模型（VLMs）在腔镜手术等内窥镜任务中的应用能力，发现VLMs在基础感知任务上表现良好，但在需要医学知识的高级任务上表现不佳，且专业医疗VLMs在基本和高级手术任务上均不如通用模型，指出需要进一步发展以应对手术的独特挑战。&lt;h4&gt;背景&lt;/h4&gt;传统计算机视觉模型在内窥镜领域泛化能力有限，而基础模型在跨领域性能上展现出潜力。&lt;h4&gt;目的&lt;/h4&gt;评估VLMs在内窥镜任务中的能力，特别是针对腔镜手术。&lt;h4&gt;方法&lt;/h4&gt;使用多种最先进的模型、多个手术数据集和大量的人类参考标注，解决三个关键研究问题：VLMs能否解决基本的感知任务？能否处理基于帧的高级内窥镜场景理解任务？专业医疗VLMs与通用模型相比如何？&lt;h4&gt;主要发现&lt;/h4&gt;VLMs在基本手术感知任务上表现良好，如物体计数和定位，但在需要医学知识的高级任务上表现不佳。专业医疗VLMs在基本和高级手术任务上均不如通用模型，表明它们尚未针对手术环境的复杂性进行优化。&lt;h4&gt;结论&lt;/h4&gt;VLMs在基础感知任务上表现可接受，但在需要医学知识的高级任务上存在不足，需要进一步研究和发展以应对手术的独特挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While traditional computer vision models have historically struggled togeneralize to endoscopic domains, the emergence of foundation models has shownpromising cross-domain performance. In this work, we present the firstlarge-scale study assessing the capabilities of Vision Language Models (VLMs)for endoscopic tasks with a specific focus on laparoscopic surgery. Using adiverse set of state-of-the-art models, multiple surgical datasets, andextensive human reference annotations, we address three key research questions:(1) Can current VLMs solve basic perception tasks on surgical images? (2) Canthey handle advanced frame-based endoscopic scene understanding tasks? and (3)How do specialized medical VLMs compare to generalist models in this context?Our results reveal that VLMs can effectively perform basic surgical perceptiontasks, such as object counting and localization, with performance levelscomparable to general domain tasks. However, their performance deterioratessignificantly when the tasks require medical knowledge. Notably, we find thatspecialized medical VLMs currently underperform compared to generalist modelsacross both basic and advanced surgical tasks, suggesting that they are not yetoptimized for the complexity of surgical environments. These findings highlightthe need for further advancements to enable VLMs to handle the uniquechallenges posed by surgery. Overall, our work provides important insights forthe development of next-generation endoscopic AI systems and identifies keyareas for improvement in medical visual language models.</description>
      <author>example@mail.com (Leon Mayer, Tim Rädsch, Dominik Michael, Lucas Luttner, Amine Yamlahi, Evangelia Christodoulou, Patrick Godau, Marcel Knopp, Annika Reinke, Fiona Kolbinger, Lena Maier-Hein)</author>
      <guid isPermaLink="false">2506.06232v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Robotic Policy Learning via Human-assisted Action Preference Optimization</title>
      <link>http://arxiv.org/abs/2506.07127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为HAPO的人辅助动作偏好优化方法，旨在通过偏好对齐来纠正部署失败并促进VLA模型的有效适应。&lt;h4&gt;背景&lt;/h4&gt;虽然VLA模型是机器人部署的基础模型，但它们依赖于专家演示，这限制了从失败中学习和纠正的能力。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一局限性，提出HAPO方法以实现可靠的部署和从失败中学习。&lt;h4&gt;方法&lt;/h4&gt;HAPO方法包括一个人类-机器人协作框架，用于可靠的失败纠正和通过人类干预收集交互轨迹。这些轨迹随后用于动作偏好优化过程，帮助VLA模型减少失败动作的发生并增强纠正动作的适应性。还提出了一种自适应重新加权算法，以解决在VLA模型中引入偏好优化时不可逆交互和标记概率不匹配的问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明，该方法在各种操作任务中具有优越的泛化能力和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;HAPO方法确保了VLA模型的可靠部署和有效的失败学习。&lt;h4&gt;翻译&lt;/h4&gt;Establishing a reliable and iteratively refined robotic system is essential for deploying real-world applications. While Vision-Language-Action (VLA) models are widely recognized as the foundation model for such robotic deployment, their dependence on expert demonstrations hinders the crucial capabilities of correction and learning from failures. To mitigate this limitation, we introduce a Human-assisted Action Preference Optimization method named HAPO, designed to correct deployment failures and foster effective adaptation through preference alignment for VLA models. This method begins with a human-robot collaboration framework for reliable failure correction and interaction trajectory collection through human intervention. These human-intervention trajectories are further employed within the action preference optimization process, facilitating VLA models to mitigate failure action occurrences while enhancing corrective action adaptation. Specifically, we propose an adaptive reweighting algorithm to address the issues of irreversible interactions and token probability mismatch when introducing preference optimization into VLA models, facilitating model learning from binary desirability signals derived from interactions. Through combining these modules, our human-assisted action preference optimization method ensures reliable deployment and effective learning from failure for VLA models. The experiments conducted in simulation and real-world scenarios prove superior generalization and robustness of our framework across a variety of manipulation tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Establishing a reliable and iteratively refined robotic system is essentialfor deploying real-world applications. While Vision-Language-Action (VLA)models are widely recognized as the foundation model for such roboticdeployment, their dependence on expert demonstrations hinders the crucialcapabilities of correction and learning from failures. To mitigate thislimitation, we introduce a Human-assisted Action Preference Optimization methodnamed HAPO, designed to correct deployment failures and foster effectiveadaptation through preference alignment for VLA models. This method begins witha human-robot collaboration framework for reliable failure correction andinteraction trajectory collection through human intervention. Thesehuman-intervention trajectories are further employed within the actionpreference optimization process, facilitating VLA models to mitigate failureaction occurrences while enhancing corrective action adaptation. Specifically,we propose an adaptive reweighting algorithm to address the issues ofirreversible interactions and token probability mismatch when introducingpreference optimization into VLA models, facilitating model learning frombinary desirability signals derived from interactions. Through combining thesemodules, our human-assisted action preference optimization method ensuresreliable deployment and effective learning from failure for VLA models. Theexperiments conducted in simulation and real-world scenarios prove superiorgeneralization and robustness of our framework across a variety of manipulationtasks.</description>
      <author>example@mail.com (Wenke xia, Yichu Yang, Hongtao Wu, Xiao Ma, Tao Kong, Di Hu)</author>
      <guid isPermaLink="false">2506.07127v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Ai-Driven Vulnerability Analysis in Smart Contracts: Trends, Challenges and Future Directions</title>
      <link>http://arxiv.org/abs/2506.06735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于AI的智能合约漏洞检测技术，分析了机器学习、深度学习、图神经网络和基于Transformer的模型在智能合约安全中的应用。&lt;h4&gt;背景&lt;/h4&gt;智能合约是区块链生态系统的重要组成部分，但存在如数值溢出、重入攻击和不当访问权限等漏洞，导致大量资金损失。&lt;h4&gt;目的&lt;/h4&gt;研究新型AI驱动的智能合约漏洞检测技术，提高安全性和自动化审计。&lt;h4&gt;方法&lt;/h4&gt;本文分析了机器学习、深度学习、图神经网络和基于Transformer的模型在智能合约安全中的应用，比较了这些技术在准确性、可解释性、计算开销和实时适用性方面的优缺点。&lt;h4&gt;主要发现&lt;/h4&gt;AI技术在智能合约漏洞检测方面展现出潜力，但存在一些开放挑战和未来机遇。&lt;h4&gt;结论&lt;/h4&gt;AI技术在智能合约安全领域具有发展潜力，但仍需解决一些开放挑战和未来的发展机遇。&lt;h4&gt;翻译&lt;/h4&gt;The abstract discusses novel AI-driven techniques for vulnerability detection in smart contracts, analyzing the application of machine learning, deep learning, graph neural networks, and transformer-based models in the field of smart contract security.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.5121/ijaia.2025.16305&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Smart contracts, integral to blockchain ecosystems, enable decentralizedapplications to execute predefined operations without intermediaries. Theirability to enforce trustless interactions has made them a core component ofplatforms such as Ethereum. Vulnerabilities such as numerical overflows,reentrancy attacks, and improper access permissions have led to the loss ofmillions of dollars throughout the blockchain and smart contract sector.Traditional smart contract auditing techniques such as manual code reviews andformal verification face limitations in scalability, automation, andadaptability to evolving development patterns. As a result, AI-based solutionshave emerged as a promising alternative, offering the ability to learn complexpatterns, detect subtle flaws, and provide scalable security assurances. Thispaper examines novel AI-driven techniques for vulnerability detection in smartcontracts, focusing on machine learning, deep learning, graph neural networks,and transformer-based models. This paper analyzes how each technique representscode, processes semantic information, and responds to real world vulnerabilityclasses. We also compare their strengths and weaknesses in terms of accuracy,interpretability, computational overhead, and real time applicability. Lastly,it highlights open challenges and future opportunities for advancing thisdomain.</description>
      <author>example@mail.com (Mesut Ozdag)</author>
      <guid isPermaLink="false">2506.06735v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>STSBench: A Spatio-temporal Scenario Benchmark for Multi-modal Large Language Models in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2506.06218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Dataset: https://huggingface.co/datasets/ivc-lrp/STSBench, Code:  https://github.com/LRP-IVC/STSBench&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了STSBench，一个基于场景的框架，用于评估自动驾驶中视觉语言模型（VLMs）的整体理解能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基准测试通常针对单视角的图像或视频，以及针对语义任务如物体识别、密集描述、风险评估或场景理解的VLMs。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够评估VLMs在复杂环境中对基本交通动态推理能力的基准。&lt;h4&gt;方法&lt;/h4&gt;STSBench自动从数据集中挖掘预定义的交通场景，提供直观的用户界面以便高效的人工验证，并为模型评估生成多项选择题。&lt;h4&gt;主要发现&lt;/h4&gt;该基准揭示了现有模型在复杂环境中推理基本交通动态方面的关键不足。&lt;h4&gt;结论&lt;/h4&gt;STSBench通过解决空间时间评估的核心差距，有助于开发更稳健和可解释的VLMs，以用于自动驾驶。&lt;h4&gt;翻译&lt;/h4&gt;We introduce STSBench, a scenario-based framework to benchmark the holistic understanding of vision-language models (VLMs) for autonomous driving. The framework automatically mines pre-defined traffic scenarios from any dataset using ground-truth annotations, provides an intuitive user interface for efficient human verification, and generates multiple-choice questions for model evaluation. Applied to the NuScenes dataset, we present STSnu, the first benchmark that evaluates the spatio-temporal reasoning capabilities of VLMs based on comprehensive 3D perception. Existing benchmarks typically target off-the-shelf or fine-tuned VLMs for images or videos from a single viewpoint and focus on semantic tasks such as object recognition, dense captioning, risk assessment, or scene understanding. In contrast, STSnu evaluates driving expert VLMs for end-to-end driving, operating on videos from multi-view cameras or LiDAR. It specifically assesses their ability to reason about both ego-vehicle actions and complex interactions among traffic participants, a crucial capability for autonomous vehicles. The benchmark features 43 diverse scenarios spanning multiple views and frames, resulting in 971 human-verified multiple-choice questions. A thorough evaluation uncovers critical shortcomings in existing models' ability to reason about fundamental traffic dynamics in complex environments. These findings highlight the urgent need for architectural advances that explicitly model spatio-temporal reasoning. By addressing a core gap in spatio-temporal evaluation, STSBench enables the development of more robust and explainable VLMs for autonomous driving.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce STSBench, a scenario-based framework to benchmark the holisticunderstanding of vision-language models (VLMs) for autonomous driving. Theframework automatically mines pre-defined traffic scenarios from any datasetusing ground-truth annotations, provides an intuitive user interface forefficient human verification, and generates multiple-choice questions for modelevaluation. Applied to the NuScenes dataset, we present STSnu, the firstbenchmark that evaluates the spatio-temporal reasoning capabilities of VLMsbased on comprehensive 3D perception. Existing benchmarks typically targetoff-the-shelf or fine-tuned VLMs for images or videos from a single viewpointand focus on semantic tasks such as object recognition, dense captioning, riskassessment, or scene understanding. In contrast, STSnu evaluates driving expertVLMs for end-to-end driving, operating on videos from multi-view cameras orLiDAR. It specifically assesses their ability to reason about both ego-vehicleactions and complex interactions among traffic participants, a crucialcapability for autonomous vehicles. The benchmark features 43 diverse scenariosspanning multiple views and frames, resulting in 971 human-verifiedmultiple-choice questions. A thorough evaluation uncovers critical shortcomingsin existing models' ability to reason about fundamental traffic dynamics incomplex environments. These findings highlight the urgent need forarchitectural advances that explicitly model spatio-temporal reasoning. Byaddressing a core gap in spatio-temporal evaluation, STSBench enables thedevelopment of more robust and explainable VLMs for autonomous driving.</description>
      <author>example@mail.com (Christian Fruhwirth-Reisinger, Dušan Malić, Wei Lin, David Schinagl, Samuel Schulter, Horst Possegger)</author>
      <guid isPermaLink="false">2506.06218v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>E-BATS: Efficient Backpropagation-Free Test-Time Adaptation for Speech Foundation Models</title>
      <link>http://arxiv.org/abs/2506.07078v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种针对语音基础模型的新型有效无反向传播测试时自适应（TTA）框架E-BATS，旨在解决实际场景中由于声学域偏移导致的性能下降问题。&lt;h4&gt;背景&lt;/h4&gt;语音基础模型在实际应用中面临声学域偏移的挑战，如背景噪声和说话人口音，导致性能下降。传统的TTA方法依赖反向传播，内存消耗大，限制了其在资源受限环境中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出E-BATS框架，旨在实现高效的TTA，同时降低内存消耗，并提高适应效果。&lt;h4&gt;方法&lt;/h4&gt;E-BATS通过三个关键组件实现平衡：轻量级的提示自适应、多尺度损失捕捉全局和局部分布偏移，以及测试时指数移动平均机制实现稳定的跨句子自适应。&lt;h4&gt;主要发现&lt;/h4&gt;在四个噪声语音数据集上进行的实验表明，E-BATS在四个噪声语音数据集上实现了持续的性能提升，与无反向传播基线相比，准确率提高了4.1%-13.5%，同时比基于反向传播的方法节省了2.0-6.4倍的GPU内存。&lt;h4&gt;结论&lt;/h4&gt;E-BATS为在声学变化下实现可扩展和鲁棒的适应提供了途径，为实际环境中的语音处理系统开发更有效的自适应方法铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在涉及声学域偏移的实际场景中，语音基础模型会遇到显著的性能下降，例如背景噪声和说话人口音。测试时自适应（TTA）最近被证明是一种可行的策略，可以在推理时解决这种域偏移，而不需要访问源数据或标签。然而，现有的TTA方法，尤其是那些依赖反向传播的方法，内存密集，限制了它们在语音任务和资源受限环境中的应用。尽管无反向传播的方法提供了改进的效率，但现有的方法在准确性方面表现不佳。这是因为它们主要用于视觉任务，与语音任务的表达式、噪声特征和模型架构根本不同，从而带来了独特的可迁移性挑战。在这篇论文中，我们介绍了E-BATS，这是第一个专为语音基础模型设计的有效无反向传播TTA框架。E-BATS通过三个关键组件在适应性有效性和内存效率之间实现了平衡：（i）基于前向传递的特征对齐的轻量级提示自适应，（ii）多尺度损失以捕捉全局（句子级）和局部分布偏移（标记级），以及（iii）测试时指数移动平均机制以实现跨句子的稳定自适应。在涵盖十六种声学条件的四个噪声语音数据集上进行的实验表明，E-BATS实现了持续的性能提升，与无反向传播基线相比，准确率提高了4.1%-13.5%，与基于反向传播的方法相比，GPU内存节省了2.0-6.4倍。通过在声学变化下实现可扩展和鲁棒的适应，这项工作为开发实际环境中的实用语音处理系统的更有效自适应方法铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech Foundation Models encounter significant performance degradation whendeployed in real-world scenarios involving acoustic domain shifts, such asbackground noise and speaker accents. Test-time adaptation (TTA) has recentlyemerged as a viable strategy to address such domain shifts at inference timewithout requiring access to source data or labels. However, existing TTAapproaches, particularly those relying on backpropagation, arememory-intensive, limiting their applicability in speech tasks andresource-constrained settings. Although backpropagation-free methods offerimproved efficiency, existing ones exhibit poor accuracy. This is because theyare predominantly developed for vision tasks, which fundamentally differ fromspeech task formulations, noise characteristics, and model architecture, posingunique transferability challenges. In this paper, we introduce E-BATS, thefirst Efficient BAckpropagation-free TTA framework designed explicitly forspeech foundation models. E-BATS achieves a balance between adaptationeffectiveness and memory efficiency through three key components: (i)lightweight prompt adaptation for a forward-pass-based feature alignment, (ii)a multi-scale loss to capture both global (utterance-level) and localdistribution shifts (token-level) and (iii) a test-time exponential movingaverage mechanism for stable adaptation across utterances. Experimentsconducted on four noisy speech datasets spanning sixteen acoustic conditionsdemonstrate consistent improvements, with 4.1%-13.5% accuracy gains overbackpropagation-free baselines and 2.0-6.4 times GPU memory savings compared tobackpropagation-based methods. By enabling scalable and robust adaptation underacoustic variability, this work paves the way for developing more efficientadaptation approaches for practical speech processing systems in real-worldenvironments.</description>
      <author>example@mail.com (Jiaheng Dong, Hong Jia, Soumyajit Chatterjee, Abhirup Ghosh, James Bailey, Ting Dang)</author>
      <guid isPermaLink="false">2506.07078v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Neighborhood Overlap-Aware High-Order Graph Neural Network for Dynamic Graph Learning</title>
      <link>http://arxiv.org/abs/2506.06728v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为NO-HGNN的动态图学习新方法，旨在通过考虑邻域重叠来提高节点嵌入的准确性，从而支持下游任务如链接预测。&lt;h4&gt;背景&lt;/h4&gt;动态图学习（DGL）旨在学习具有时间演化的节点嵌入，以支持链接预测等下游任务。在DGL中，有效建模图拓扑的时序动态和结构依赖是一个基本挑战。&lt;h4&gt;目的&lt;/h4&gt;提出NO-HGNN方法，以克服现有方法在捕捉节点交互时忽略复杂结构模式（如邻域重叠）的局限性。&lt;h4&gt;方法&lt;/h4&gt;NO-HGNN基于两个关键创新：（a）计算基于邻域重叠程度的关联分数，以更好地捕捉复杂的节点交互；（b）将这种关联直接嵌入到DGL中高阶图神经网络的消息传递过程中。&lt;h4&gt;主要发现&lt;/h4&gt;在两个真实世界动态图上的实验表明，NO-HGNN在链接预测准确性方面取得了显著的改进，优于几种最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;NO-HGNN通过考虑邻域重叠，在动态图学习领域实现了链接预测性能的提升，为该领域的研究提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic graph learning (DGL) aims to learn informative andtemporally-evolving node embeddings to support downstream tasks such as linkprediction. A fundamental challenge in DGL lies in effectively modeling boththe temporal dynamics and structural dependencies of evolving graph topologies.Recent advances in Dynamic Graph Neural Networks (DGNNs) have obtainedremarkable success by leveraging message-passing mechanisms to capture pairwisenode interactions. However, these approaches often overlook more complexstructural patterns, particularly neighborhood overlap, which can play acritical role in characterizing node interactions. To overcome this limitation,we introduce the Neighborhood Overlap-Aware High-Order Graph Neural Network(NO-HGNN), which is built upon two key innovations: (a) computing a correlationscore based on the extent of neighborhood overlap to better capture complexnode interactions; and (b) embedding this correlation directly into themessage-passing process of high-order graph neural networks in the DGL.Experiments on two real-world dynamic graphs show that NO-HGNN achieves notableimprovements in link prediction accuracy, outperforming severalstate-of-the-art approaches.</description>
      <author>example@mail.com (Ling Wang)</author>
      <guid isPermaLink="false">2506.06728v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Audio and Vision: Zero-Shot Audiovisual Segmentation by Connecting Pretrained Models</title>
      <link>http://arxiv.org/abs/2506.06537v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted on INTERSPEECH2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的零样本视听分割（AVS）框架，旨在通过利用多个预训练模型来识别与声音源相对应的视觉区域，以提高视频理解、监控和人类-计算机交互的效率。&lt;h4&gt;背景&lt;/h4&gt;传统的AVS方法依赖于大规模的像素级标注，这既昂贵又耗时。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在提出一种无需特定任务训练的零样本AVS框架。&lt;h4&gt;方法&lt;/h4&gt;该方法通过整合音频、视觉和文本表示来弥合模态差距，实现精确的声音源分割，同时不需要AVS特定的标注。文章系统地探讨了连接预训练模型的不同策略，并评估了它们在多个数据集上的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，本文提出的框架实现了最先进的零样本AVS性能，突显了多模态模型集成在细粒度视听分割中的有效性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的零样本AVS框架为视频理解、监控和人类-计算机交互等领域提供了有效的解决方案，并证明了多模态模型集成在视听分割中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audiovisual segmentation (AVS) aims to identify visual regions correspondingto sound sources, playing a vital role in video understanding, surveillance,and human-computer interaction. Traditional AVS methods depend on large-scalepixel-level annotations, which are costly and time-consuming to obtain. Toaddress this, we propose a novel zero-shot AVS framework that eliminatestask-specific training by leveraging multiple pretrained models. Our approachintegrates audio, vision, and text representations to bridge modality gaps,enabling precise sound source segmentation without AVS-specific annotations. Wesystematically explore different strategies for connecting pretrained modelsand evaluate their efficacy across multiple datasets. Experimental resultsdemonstrate that our framework achieves state-of-the-art zero-shot AVSperformance, highlighting the effectiveness of multimodal model integration forfinegrained audiovisual segmentation.</description>
      <author>example@mail.com (Seung-jae Lee, Paul Hongsuck Seo)</author>
      <guid isPermaLink="false">2506.06537v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Semi-supervised Segmentation Beyond Accuracy: Reliability and Robustness</title>
      <link>http://arxiv.org/abs/2506.05917v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文讨论了语义分割的重要性及其对场景理解的影响，指出了当前半监督分割评估协议的不足，并提出了一个新的评估指标——可靠分割得分（RSS），以更全面地评估分割模型。&lt;h4&gt;背景&lt;/h4&gt;语义分割对于场景理解至关重要，但其需要昂贵的像素级标注，因此半监督方法吸引了越来越多的关注。然而，现有的评估协议主要关注分割精度，而忽略了可靠性和鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，论文提出了一个名为可靠分割得分（RSS）的新指标，该指标结合了预测精度、校准和不确定性质量度量。&lt;h4&gt;方法&lt;/h4&gt;RSS通过调和平均数结合了这些度量，并对任何组成部分的不足进行惩罚，从而提供了一种简单直观的方法来全面评估分割模型。&lt;h4&gt;主要发现&lt;/h4&gt;对UniMatchV2及其前一代和监督基线的方法进行了综合评估，结果表明半监督方法通常在可靠性和精度之间进行权衡。虽然域外评估显示了UniMatchV2的鲁棒性，但也暴露了持续的可靠性不足。&lt;h4&gt;结论&lt;/h4&gt;论文主张评估协议转向更全面的指标，如RSS，以更好地将半监督学习研究与实际部署需求对齐。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语义分割对于场景理解至关重要，但需要昂贵的像素级标注，这促使人们越来越关注利用大量未标记数据的半监督方法。虽然半监督分割通常被视为通往可扩展、实际部署的途径，但令人惊讶的是，当前的评估协议仅关注分割精度，完全忽略了可靠性和鲁棒性。这些确保在不同条件下保持一致性能（鲁棒性）以及模型置信度良好以及不确定性有意义的（可靠性）质量是自动驾驶等安全关键应用所必需的，在这些应用中，模型必须处理不可预测的环境，并不惜一切代价避免突然故障。为了解决这一差距，我们引入了可靠分割得分（RSS），这是一种新的度量，通过调和平均数结合预测精度、校准和不确定性质量度量。RSS对其任何组成部分的不足进行惩罚，提供了一种简单直观的方式来全面评估分割模型。对UniMatchV2与其前身和监督基线的方法进行的综合评估表明，半监督方法通常在可靠性和精度之间进行权衡。虽然域外评估显示了UniMatchV2的鲁棒性，但它们进一步暴露了持续的可靠性不足。我们主张评估协议转向更全面的指标，如RSS，以更好地将半监督学习研究与实际部署需求对齐。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic segmentation is critical for scene understanding but demands costlypixel-wise annotations, attracting increasing attention to semi-supervisedapproaches to leverage abundant unlabeled data. While semi-supervisedsegmentation is often promoted as a path toward scalable, real-worlddeployment, it is astonishing that current evaluation protocols exclusivelyfocus on segmentation accuracy, entirely overlooking reliability androbustness. These qualities, which ensure consistent performance under diverseconditions (robustness) and well-calibrated model confidences as well asmeaningful uncertainties (reliability), are essential for safety-criticalapplications like autonomous driving, where models must handle unpredictableenvironments and avoid sudden failures at all costs. To address this gap, weintroduce the Reliable Segmentation Score (RSS), a novel metric that combinespredictive accuracy, calibration, and uncertainty quality measures via aharmonic mean. RSS penalizes deficiencies in any of its components, providingan easy and intuitive way of holistically judging segmentation models.Comprehensive evaluations of UniMatchV2 against its predecessor and asupervised baseline show that semi-supervised methods often trade reliabilityfor accuracy. While out-of-domain evaluations demonstrate UniMatchV2'srobustness, they further expose persistent reliability shortcomings. Weadvocate for a shift in evaluation protocols toward more holistic metrics likeRSS to better align semi-supervised learning research with real-worlddeployment needs.</description>
      <author>example@mail.com (Steven Landgraf, Markus Hillemann, Markus Ulrich)</author>
      <guid isPermaLink="false">2506.05917v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Graph Persistence goes Spectral</title>
      <link>http://arxiv.org/abs/2506.06571v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 4 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图拓扑描述符SpectRe，该描述符将谱信息整合到持久同伦图中，并在图表示学习中展现出比现有描述符更高的表达能力。&lt;h4&gt;背景&lt;/h4&gt;在图神经网络（GNNs）中，包括复杂的拓扑信息（如环路）可以证明能够超越Weisfeiler-Leman（WL）层次，从而增强其表达能力。持久同伦（PH）方法越来越多地用于图表示学习，但现有方法由于依赖于特征，仍然无法捕获基本的图结构信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的图拓扑描述符SpectRe，以增强图表示学习的表达能力，并捕获基本的图结构信息。&lt;h4&gt;方法&lt;/h4&gt;SpectRe将谱信息与持久同伦图相结合，并引入全局和局部稳定性的概念来分析现有描述符。&lt;h4&gt;主要发现&lt;/h4&gt;SpectRe在图上具有比现有描述符更高的表达能力，并且在局部上是稳定的。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，SpectRe在合成和真实世界数据集上都是有效的，并且有可能增强图模型在相关学习任务中的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：包括复杂的拓扑信息（例如，环路）可以证明能够超越Weisfeiler-Leman（WL）层次，从而增强信息传递图神经网络（GNNs）的表达能力。因此，持久同伦（PH）方法越来越多地用于图表示学习。在此背景下，最近的工作提出用顶点和边特征装饰经典的PH图以提高表达能力。然而，由于它们依赖于特征，这些方法仍然无法捕获基本的图结构信息。在本文中，我们提出了一种新的图拓扑描述符SpectRe，该描述符将谱信息整合到PH图中。值得注意的是，SpectRe在图上严格优于现有描述符。我们还引入了全局和局部稳定性的概念来分析现有描述符，并证明SpectRe是局部稳定的。最后，在合成和真实世界数据集上的实验表明了SpectRe的有效性及其增强相关学习任务中图模型能力的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Including intricate topological information (e.g., cycles) provably enhancesthe expressivity of message-passing graph neural networks (GNNs) beyond theWeisfeiler-Leman (WL) hierarchy. Consequently, Persistent Homology (PH) methodsare increasingly employed for graph representation learning. In this context,recent works have proposed decorating classical PH diagrams with vertex andedge features for improved expressivity. However, due to their dependence onfeatures, these methods still fail to capture basic graph structuralinformation. In this paper, we propose SpectRe -- a new topological descriptorfor graphs that integrates spectral information into PH diagrams. Notably,SpectRe is strictly more expressive than existing descriptors on graphs. Wealso introduce notions of global and local stability to analyze existingdescriptors and establish that SpectRe is locally stable. Finally, experimentson synthetic and real-world datasets demonstrate the effectiveness of SpectReand its potential to enhance the capabilities of graph models in relevantlearning tasks.</description>
      <author>example@mail.com (Mattie Ji, Amauri H. Souza, Vikas Garg)</author>
      <guid isPermaLink="false">2506.06571v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>FairPFN: A Tabular Foundation Model for Causal Fairness</title>
      <link>http://arxiv.org/abs/2506.07049v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FairPFN的表格基础模型，用于在机器学习系统中识别和减轻受保护属性对预测的因果影响，以提高因果公平性。&lt;h4&gt;背景&lt;/h4&gt;机器学习系统在医疗保健、执法和金融等关键领域得到应用，但这些系统往往基于包含人口统计偏差的历史数据，导致加剧社会不平等。&lt;h4&gt;目的&lt;/h4&gt;提出FairPFN模型，以解决因果公平性问题，减少算法歧视，并使因果公平性更易于应用于复杂场景。&lt;h4&gt;方法&lt;/h4&gt;FairPFN模型通过在合成因果公平数据上预训练，无需对因果模型有先验知识，便能识别和减轻受保护属性的因果影响。&lt;h4&gt;主要发现&lt;/h4&gt;FairPFN模型在多种定制和现实场景中，相对于稳健的基线方法，表现出强大的性能，且无需对因果模型有先验知识。&lt;h4&gt;结论&lt;/h4&gt;FairPFN模型为解决复杂公平性问题铺平了道路，使得因果公平性更容易被广泛应用。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为FairPFN的表格基础模型，用于在机器学习系统中识别和减轻受保护属性对预测的因果影响，以提高因果公平性。机器学习系统在医疗保健、执法和金融等关键领域得到应用，但这些系统往往基于包含人口统计偏差的历史数据，导致加剧社会不平等。提出FairPFN模型，以解决因果公平性问题，减少算法歧视，并使因果公平性更易于应用于复杂场景。FairPFN模型通过在合成因果公平数据上预训练，无需对因果模型有先验知识，便能识别和减轻受保护属性的因果影响。FairPFN模型在多种定制和现实场景中，相对于稳健的基线方法，表现出强大的性能，且无需对因果模型有先验知识。FairPFN模型为解决复杂公平性问题铺平了道路，使得因果公平性更容易被广泛应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning (ML) systems are utilized in critical sectors, such ashealthcare, law enforcement, and finance. However, these systems are oftentrained on historical data that contains demographic biases, leading to MLdecisions that perpetuate or exacerbate existing social inequalities. Causalfairness provides a transparent, human-in-the-loop framework to mitigatealgorithmic discrimination, aligning closely with legal doctrines of direct andindirect discrimination. However, current causal fairness frameworks hold a keylimitation in that they assume prior knowledge of the correct causal model,restricting their applicability in complex fairness scenarios where causalmodels are unknown or difficult to identify. To bridge this gap, we proposeFairPFN, a tabular foundation model pre-trained on synthetic causal fairnessdata to identify and mitigate the causal effects of protected attributes in itspredictions. FairPFN's key contribution is that it requires no knowledge of thecausal model and still demonstrates strong performance in identifying andremoving protected causal effects across a diverse set of hand-crafted andreal-world scenarios relative to robust baseline methods. FairPFN paves the wayfor promising future research, making causal fairness more accessible to awider variety of complex fairness problems.</description>
      <author>example@mail.com (Jake Robertson, Noah Hollmann, Samuel Müller, Noor Awad, Frank Hutter)</author>
      <guid isPermaLink="false">2506.07049v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>You Only Estimate Once: Unified, One-stage, Real-Time Category-level Articulated Object 6D Pose Estimation for Robotic Grasping</title>
      <link>http://arxiv.org/abs/2506.05719v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为YOEO的单阶段方法，用于解决机器人操作任务中关节物体类别级的姿态估计问题，该方法在GAPart数据集上展示了良好的姿态估计能力，并在实际场景中实现了200Hz的实时视觉反馈。&lt;h4&gt;背景&lt;/h4&gt;现有方法在估计类别级的部件姿态和大小时，通常采用复杂的多阶段流程，首先在点云中分割部件实例，然后估计标准化部件坐标空间（NPCS）表示的6D姿态，但这种方法计算成本高且在实时机器人任务中的性能较低。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述方法的局限性，提出YOEO方法，旨在通过单阶段流程同时输出实例分割和NPCS表示，以降低计算成本并提高实时性能。&lt;h4&gt;方法&lt;/h4&gt;YOEO方法使用统一的网络生成点级语义标签和质心偏移，使得来自同一部件实例的点对相同的质心进行投票。进一步，利用聚类算法根据估计的质心距离来区分点。然后，首先分离每个实例的NPCS区域，并将这些区域与真实点云对齐，以恢复最终的姿态和大小。&lt;h4&gt;主要发现&lt;/h4&gt;YOEO方法在GAPart数据集上展示了良好的姿态估计能力，并且在真实世界中部署了该模型，实现了200Hz的实时视觉反馈，使物理Kinova机器人能够与未见过的关节物体交互。&lt;h4&gt;结论&lt;/h4&gt;YOEO方法有效且实用，能够显著提高实时机器人任务中关节物体类别级姿态估计的性能。&lt;h4&gt;翻译&lt;/h4&gt;本文针对机器人操作任务中关节物体类别级姿态估计问题进行了研究。近年来，在估计类别级的部件姿态和大小时，已有工作取得了令人鼓舞的结果。然而，这些方法主要遵循一个复杂的多阶段流程，首先在点云中分割部件实例，然后估计标准化部件坐标空间（NPCS）表示的6D姿态。这些方法在实时机器人任务中存在计算成本高、性能低的问题。为了解决这些局限性，我们提出了YOEO方法，这是一种单阶段方法，能够端到端地同时输出实例分割和NPCS表示。我们使用一个统一的网络来生成点级语义标签和质心偏移，使得来自同一部件实例的点对相同的质心进行投票。我们进一步利用聚类算法根据估计的质心距离来区分点。然后，首先分离每个实例的NPCS区域，并将这些区域与真实点云对齐，以恢复最终的姿态和大小。在GAPart数据集上的实验结果证明了我们提出的单次拍摄方法在姿态估计方面的能力。我们还将在实际场景中部署我们通过合成训练得到的模型，实现200Hz的实时视觉反馈，使物理Kinova机器人能够与未见过的关节物体进行交互。这展示了我们提出的方法的实用性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the problem of category-level pose estimation forarticulated objects in robotic manipulation tasks. Recent works have shownpromising results in estimating part pose and size at the category level.However, these approaches primarily follow a complex multi-stage pipeline thatfirst segments part instances in the point cloud and then estimates theNormalized Part Coordinate Space (NPCS) representation for 6D poses. Theseapproaches suffer from high computational costs and low performance inreal-time robotic tasks. To address these limitations, we propose YOEO, asingle-stage method that simultaneously outputs instance segmentation and NPCSrepresentations in an end-to-end manner. We use a unified network to generatepoint-wise semantic labels and centroid offsets, allowing points from the samepart instance to vote for the same centroid. We further utilize a clusteringalgorithm to distinguish points based on their estimated centroid distances.Finally, we first separate the NPCS region of each instance. Then, we align theseparated regions with the real point cloud to recover the final pose and size.Experimental results on the GAPart dataset demonstrate the pose estimationcapabilities of our proposed single-shot method. We also deploy oursynthetically-trained model in a real-world setting, providing real-time visualfeedback at 200Hz, enabling a physical Kinova robot to interact with unseenarticulated objects. This showcases the utility and effectiveness of ourproposed method.</description>
      <author>example@mail.com (Jingshun Huang, Haitao Lin, Tianyu Wang, Yanwei Fu, Yu-Gang Jiang, Xiangyang Xue)</author>
      <guid isPermaLink="false">2506.05719v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Perspectives: A Survey on Cross-view Collaborative Intelligence with Egocentric-Exocentric Vision</title>
      <link>http://arxiv.org/abs/2506.06253v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了从外心（第三人称）和内心（第一人称）视角的视频理解研究，探讨了两种视角的协同潜力及其在动态环境中的互补理解能力。&lt;h4&gt;背景&lt;/h4&gt;从内外心视角感知世界是人类认知的基础，近年来，让机器利用这两种视角的协同潜力成为视频理解领域的一个引人注目的研究方向。&lt;h4&gt;目的&lt;/h4&gt;本文旨在全面回顾视频理解中的内外心视角，并探讨如何将这两种视角的技术整合，以及实现这些应用的关键研究任务。&lt;h4&gt;方法&lt;/h4&gt;文章系统地组织并回顾了近期的研究进展，分为三个主要研究方向：(1)利用内心数据增强外心理解，(2)利用外心数据改善内心分析，(3)联合学习框架，统一两种视角。并对每个方向的任务和相关工作进行详细分析。&lt;h4&gt;主要发现&lt;/h4&gt;文章讨论了支持内外心视角研究的基准数据集，评估了它们的范围、多样性和适用性，并指出了当前工作的局限性。&lt;h4&gt;结论&lt;/h4&gt;通过综合两种视角的见解，本文旨在激发视频理解和人工智能领域的进步，使机器更接近以人类方式感知世界。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从自我中心（第一人称）和外心（第三人称）的视角感知世界是人类认知的基础，这使人们能够对动态环境有丰富且互补的理解。近年来，让机器利用这两种视角的协同潜力已经成为视频理解领域的一个引人注目的研究方向。在本篇综述中，我们全面回顾了从外心和内心视角的视频理解。我们首先强调了整合内心和外心技术的实际应用，并展望了它们在不同领域中的潜在协作。然后，我们确定了实现这些应用的关键研究任务。接下来，我们系统地组织和回顾了最近的研究进展，主要分为三个研究方向：(1)利用内心数据来增强外心理解，(2)利用外心数据来改进内心分析，(3)联合学习框架，统一两种视角。对于每个方向，我们分析了多样化的任务和相关工作。此外，我们讨论了支持这两种视角研究的基准数据集，评估了它们的范围、多样性和适用性。最后，我们讨论了当前工作的局限性，并提出了有前景的未来研究方向。通过综合两种视角的见解，我们的目标是激发视频理解和人工智能领域的进步，使机器更接近以人类方式感知世界。相关作品的GitHub仓库可以在https://github.com/ayiyayi/Awesome-Egocentric-and-Exocentric-Vision找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Perceiving the world from both egocentric (first-person) and exocentric(third-person) perspectives is fundamental to human cognition, enabling richand complementary understanding of dynamic environments. In recent years,allowing the machines to leverage the synergistic potential of these dualperspectives has emerged as a compelling research direction in videounderstanding. In this survey, we provide a comprehensive review of videounderstanding from both exocentric and egocentric viewpoints. We begin byhighlighting the practical applications of integrating egocentric andexocentric techniques, envisioning their potential collaboration acrossdomains. We then identify key research tasks to realize these applications.Next, we systematically organize and review recent advancements into three mainresearch directions: (1) leveraging egocentric data to enhance exocentricunderstanding, (2) utilizing exocentric data to improve egocentric analysis,and (3) joint learning frameworks that unify both perspectives. For eachdirection, we analyze a diverse set of tasks and relevant works. Additionally,we discuss benchmark datasets that support research in both perspectives,evaluating their scope, diversity, and applicability. Finally, we discusslimitations in current works and propose promising future research directions.By synthesizing insights from both perspectives, our goal is to inspireadvancements in video understanding and artificial intelligence, bringingmachines closer to perceiving the world in a human-like manner. A GitHub repoof related works can be found athttps://github.com/ayiyayi/Awesome-Egocentric-and-Exocentric-Vision.</description>
      <author>example@mail.com (Yuping He, Yifei Huang, Guo Chen, Lidong Lu, Baoqi Pei, Jilan Xu, Tong Lu, Yoichi Sato)</author>
      <guid isPermaLink="false">2506.06253v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>HMVLM: Multistage Reasoning-Enhanced Vision-Language Model for Long-Tailed Driving Scenarios</title>
      <link>http://arxiv.org/abs/2506.05883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WOD Vision-based End-to-End Driving Challenge&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了HaoMo视觉-语言模型（HMVLM），这是一个端到端的驾驶框架，实现了认知启发式快速-慢速架构的慢速分支。&lt;h4&gt;背景&lt;/h4&gt;该模型通过快速控制器输出低级转向、油门和制动命令，同时慢速规划器——一个大型视觉-语言模型——生成高级意图，如“让行行人”或“在卡车后合并”，而不影响延迟。&lt;h4&gt;目的&lt;/h4&gt;HMVLM旨在提高自动驾驶系统的决策效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;HMVLM引入了三项升级：(1) 选择性五视图提示，包含4秒的自身运动学历史；(2) 多阶段思维链（CoT）提示，强制执行场景理解 -&gt; 驾驶决策 -&gt; 轨迹推理的推理流程；(3) 基于样条曲线的轨迹后处理，消除后期抖动和急转弯。&lt;h4&gt;主要发现&lt;/h4&gt;在Waymo开放数据集上训练的HMVLM实现了7.7367的评分，在2025年Waymo基于视觉的端到端（E2E）驾驶挑战中排名第二，比公共基线高出2.77。&lt;h4&gt;结论&lt;/h4&gt;这些升级使得HMVLM在自动驾驶领域取得了显著进展，提高了系统的性能和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present HaoMo Vision-Language Model (HMVLM), an end-to-end drivingframework that implements the slow branch of a cognitively inspired fast-slowarchitecture. A fast controller outputs low-level steering, throttle, and brakecommands, while a slow planner-a large vision-language model-generateshigh-level intents such as "yield to pedestrian" or "merge after the truck"without compromising latency. HMVLM introduces three upgrades: (1) selectivefive-view prompting with an embedded 4s history of ego kinematics, (2)multi-stage chain-of-thought (CoT) prompting that enforces a SceneUnderstanding -&gt; Driving Decision -&gt; Trajectory Inference reasoning flow, and(3) spline-based trajectory post-processing that removes late-stage jitter andsharp turns. Trained on the Waymo Open Dataset, these upgrades enable HMVLM toachieve a Rater Feedback Score (RFS) of 7.7367, securing 2nd place in the 2025Waymo Vision-based End-to-End (E2E) Driving Challenge and surpassing the publicbaseline by 2.77%.</description>
      <author>example@mail.com (Daming Wang, Yuhao Song, Zijian He, Kangliang Chen, Xing Pan, Lu Deng, Weihao Gu)</author>
      <guid isPermaLink="false">2506.05883v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>ICU-TSB: A Benchmark for Temporal Patient Representation Learning for Unsupervised Stratification into Patient Cohorts</title>
      <link>http://arxiv.org/abs/2506.06192v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages 1 table 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究介绍了ICU-TSB（时间分层基准），这是第一个用于评估基于时间患者表示学习的患者分层综合基准。该基准使用三个公开的ICU电子健康记录数据集进行实验，通过比较统计方法和几种循环神经网络（如LSTM和GRU）在生成有效患者表示方面的能力，验证了时间表示学习在重新发现具有临床意义的患者群体方面的潜力。&lt;h4&gt;背景&lt;/h4&gt;患者分层识别对于通过改进诊断和治疗策略推动个性化医学至关重要。ICU的电子健康记录（EHR）包含丰富的时序临床数据，可以用于此目的。&lt;h4&gt;目的&lt;/h4&gt;建立ICU-TSB基准，以评估基于时间患者表示学习的患者分层方法，并比较不同的统计方法和循环神经网络在生成有效患者表示方面的能力。&lt;h4&gt;方法&lt;/h4&gt;使用三个公开的ICU EHR数据集，通过时间表示学习进行患者分层，并引入一种新颖的分层评估框架，利用疾病分类学来衡量发现簇与临床验证的疾病分组之间的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;时间表示学习能够重新发现具有临床意义的患者群体，但这是一个具有挑战性的任务，其v度量从分类学的最高级别0.46下降到最低级别0.40。此外，还评估了为识别的簇分配可解释标签的多种策略。&lt;h4&gt;结论&lt;/h4&gt;ICU-TSB基准有助于评估基于时间患者表示学习的患者分层方法，实验和基准是完全可复制的，并可通过GitHub链接获取。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Identifying clinically meaningful subgroups by patient stratification is essential for advancing personalized medicine through improved diagnostics and treatment strategies. Electronic health records (EHRs), particularly those from intensive care units (ICUs), contain rich temporal clinical data that can be leveraged for this purpose. In this work, we introduce ICU-TSB (Temporal Stratification Benchmark), the first comprehensive benchmark for evaluating patient stratification based on temporal patient representation learning using three publicly available ICU EHR datasets. A key contribution of our benchmark is a novel hierarchical evaluation framework utilizing disease taxonomies to measure the alignment of discovered clusters with clinically validated disease groupings. In our experiments with ICU-TSB, we compared statistical methods and several recurrent neural networks, including LSTM and GRU, for their ability to generate effective patient representations for subsequent clustering of patient trajectories. Our results demonstrate that temporal representation learning can rediscover clinically meaningful patient cohorts; nevertheless, it remains a challenging task, with v-measuring varying from up to 0.46 at the top level of the taxonomy to up to 0.40 at the lowest level. To further enhance the practical utility of our findings, we also evaluate multiple strategies for assigning interpretable labels to the identified clusters. The experiments and benchmark are fully reproducible and available at https://github.com/ds4dh/CBMS2025stratification.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Patient stratification identifying clinically meaningful subgroups isessential for advancing personalized medicine through improved diagnostics andtreatment strategies. Electronic health records (EHRs), particularly those fromintensive care units (ICUs), contain rich temporal clinical data that can beleveraged for this purpose. In this work, we introduce ICU-TSB (TemporalStratification Benchmark), the first comprehensive benchmark for evaluatingpatient stratification based on temporal patient representation learning usingthree publicly available ICU EHR datasets. A key contribution of our benchmarkis a novel hierarchical evaluation framework utilizing disease taxonomies tomeasure the alignment of discovered clusters with clinically validated diseasegroupings. In our experiments with ICU-TSB, we compared statistical methods andseveral recurrent neural networks, including LSTM and GRU, for their ability togenerate effective patient representations for subsequent clustering of patienttrajectories. Our results demonstrate that temporal representation learning canrediscover clinically meaningful patient cohorts; nevertheless, it remains achallenging task, with v-measuring varying from up to 0.46 at the top level ofthe taxonomy to up to 0.40 at the lowest level. To further enhance thepractical utility of our findings, we also evaluate multiple strategies forassigning interpretable labels to the identified clusters. The experiments andbenchmark are fully reproducible and available athttps://github.com/ds4dh/CBMS2025stratification.</description>
      <author>example@mail.com (Dimitrios Proios, Alban Bornet, Anthony Yazdani, Jose F Rodrigues Jr, Douglas Teodoro)</author>
      <guid isPermaLink="false">2506.06192v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Pts3D-LLM: Studying the Impact of Token Structure for 3D Scene Understanding With Large Language Models</title>
      <link>http://arxiv.org/abs/2506.05689v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Main paper and appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了有效表示3D场景的多模态大型语言模型（MLLMs）的重要性与挑战，提出了一种新的方法，通过融合3D点云特征来丰富视觉标记，并在多个3D理解基准测试中实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;当前的方法通常只依赖于2D图像特征和不同的标记化方法。&lt;h4&gt;目的&lt;/h4&gt;为了有效表示3D场景，并提高MLLMs的性能。&lt;h4&gt;方法&lt;/h4&gt;进行了严格的3D标记结构研究，系统性地比较了基于视频和基于点的表示，同时保持了模型骨干和参数的一致性。提出了一个新方法，通过结合来自预训练的Sonata PointTransformer V3编码器的3D点云特征来丰富视觉标记。&lt;h4&gt;主要发现&lt;/h4&gt;将显式的3D特征合并显著提升了性能；基于点的标记结构在点被巧妙采样和排序时可以与基于视频的标记结构相媲美。&lt;h4&gt;结论&lt;/h4&gt;强调了标记结构分析作为一项重要贡献，并强调了在多个种子上平均报告结果的重要性，认为这对于领域中的稳健进步至关重要。&lt;h4&gt;翻译&lt;/h4&gt;有效地表示3D场景对于多模态大型语言模型（MLLMs）至关重要，但也是一个挑战。现有的方法通常仅依赖于2D图像特征和不同的标记化方法。本文对3D标记结构进行了严格的研究，系统地比较了基于视频和基于点的表示，同时保持了一致的模式骨干和参数。我们提出了一种新方法，通过结合来自预训练的Sonata PointTransformer V3编码器的3D点云特征来丰富视觉标记。我们的实验表明，合并显式的3D特征可以显著提高性能。此外，我们还表明，当点被巧妙采样和排序时，基于点的标记结构可以与基于视频的标记结构相媲美。我们从这两种结构中得出的最佳模型在多个3D理解基准测试中实现了最先进的结果。我们强调了标记结构分析作为一项关键贡献，以及跨多个种子平均报告结果的做法，我们认为这对于领域的稳健进步至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effectively representing 3D scenes for Multimodal Large Language Models(MLLMs) is crucial yet challenging. Existing approaches commonly only rely on2D image features and use varied tokenization approaches. This work presents arigorous study of 3D token structures, systematically comparing video-based andpoint-based representations while maintaining consistent model backbones andparameters. We propose a novel approach that enriches visual tokens byincorporating 3D point cloud features from a Sonata pretrained PointTransformer V3 encoder. Our experiments demonstrate that merging explicit 3Dfeatures significantly boosts performance. Furthermore, we show thatpoint-based token structures can rival video-based ones when the points arecleverly sampled and ordered. Our best models from both structures achievestate-of-the-art results on multiple 3D understanding benchmarks. We emphasizeour analysis of token structures as a key contribution, alongside transparentreporting of results averaged over multiple seeds, a practice we believe isvital for robust progress in the field.</description>
      <author>example@mail.com (Hugues Thomas, Chen Chen, Jian Zhang)</author>
      <guid isPermaLink="false">2506.05689v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Rapid training of Hamiltonian graph networks without gradient descent</title>
      <link>http://arxiv.org/abs/2506.06558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 7 figures, 2 tables, and an appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在数据驱动建模中学习遵守物理对称性和约束的动态系统，提出了一种新的方法，通过将物理定律与图神经网络结合，提高了复杂N体动力学模型的建模精度和置换不变性。&lt;h4&gt;背景&lt;/h4&gt;学习遵守物理对称性和约束的动态系统是数据驱动建模中的一个基本挑战。&lt;h4&gt;目的&lt;/h4&gt;提高复杂N体动力学模型的建模精度和置换不变性。&lt;h4&gt;方法&lt;/h4&gt;将物理定律与图神经网络结合，使用Hamiltonian Graph Networks (HGN)进行训练，并通过随机特征参数构造来替代迭代优化算法。&lt;h4&gt;主要发现&lt;/h4&gt;HGN的训练速度比其他15种优化器快600倍，同时保持了可比的精度。模型在多种模拟中表现出鲁棒性能，包括不同几何形状的3维N体质量-弹簧系统，并保留了关于置换、旋转和平移的基本物理不变性。模型即使在训练时只使用8节点系统，也能在零样本方式下泛化到4096节点的系统。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法挑战了迭代梯度下降优化算法在训练物理系统神经网络模型中的主导地位。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在数据驱动建模中学习尊重物理对称性和约束的动态系统仍然是一个基本挑战。将物理定律与图神经网络结合有助于原理性地建模复杂的N体动力学，并产生准确和置换不变的模型。然而，使用迭代、基于梯度的优化算法（例如Adam、RMSProp、LBFGS）来训练图神经网络往往会导致训练缓慢，特别是在大型、复杂的系统中。与15种不同的优化器相比，我们证明Hamiltonian Graph Networks (HGN)可以通过用基于随机特征的参数构造来替代迭代优化，以600倍的速度进行训练，但精度相当。我们在各种模拟中展示了鲁棒的性能，包括最多3维不同几何形状的N体质量-弹簧系统，同时保持了关于置换、旋转和转换的基本物理不变性。我们发现，即使在训练时只使用8节点系统，该模型也能以零样本方式泛化到多达4096节点的系统，而无需重新训练。我们的工作挑战了迭代梯度下降优化算法在训练物理系统神经网络模型中的主导地位。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning dynamical systems that respect physical symmetries and constraintsremains a fundamental challenge in data-driven modeling. Integrating physicallaws with graph neural networks facilitates principled modeling of complexN-body dynamics and yields accurate and permutation-invariant models. However,training graph neural networks with iterative, gradient-based optimizationalgorithms (e.g., Adam, RMSProp, LBFGS) often leads to slow training,especially for large, complex systems. In comparison to 15 differentoptimizers, we demonstrate that Hamiltonian Graph Networks (HGN) can be trainedup to 600x faster--but with comparable accuracy--by replacing iterativeoptimization with random feature-based parameter construction. We show robustperformance in diverse simulations, including N-body mass-spring systems in upto 3 dimensions with different geometries, while retaining essential physicalinvariances with respect to permutation, rotation, and translation. We revealthat even when trained on minimal 8-node systems, the model can generalize in azero-shot manner to systems as large as 4096 nodes without retraining. Our workchallenges the dominance of iterative gradient-descent-based optimizationalgorithms for training neural network models for physical systems.</description>
      <author>example@mail.com (Atamert Rahma, Chinmay Datar, Ana Cukarska, Felix Dietrich)</author>
      <guid isPermaLink="false">2506.06558v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>WhisQ: Cross-Modal Representation Learning for Text-to-Music MOS Prediction</title>
      <link>http://arxiv.org/abs/2506.05899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  3 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为WhisQ的多模态架构，用于评估文本到音乐系统的MOS预测，通过序列级别的共注意力和最优传输正则化来解决双重评估挑战。&lt;h4&gt;背景&lt;/h4&gt;MOS预测需要对整体音乐质量和文本提示对齐进行评估。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效评估文本到音乐系统MOS的模型。&lt;h4&gt;方法&lt;/h4&gt;WhisQ使用Whisper Base模型进行时间音频编码，Qwen 3模型进行文本编码，并通过序列结构保持精细的跨模态建模。该架构具有专门的预测路径，包括从音频嵌入中预测OMQ和利用音频与文本之间的双向序列共注意力的TA。此外，Sinkhorn最优传输损失进一步强化了共享嵌入空间中的语义对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在MusicEval Track-1数据集上，WhisQ在OMQ和TA方面都显著优于基线，分别提高了7%和14%的Spearman相关性。消融研究显示，最优传输正则化提供了最大的性能提升（10%的SRCC改进），证明了显式跨模态对齐对文本到音乐评估的重要性。&lt;h4&gt;结论&lt;/h4&gt;WhisQ通过优化传输正则化和跨模态对齐，提高了文本到音乐系统MOS预测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mean Opinion Score (MOS) prediction for text to music systems requiresevaluating both overall musical quality and text prompt alignment. This paperintroduces WhisQ, a multimodal architecture that addresses this dual-assessmentchallenge through sequence level co-attention and optimal transportregularization. WhisQ employs the Whisper Base pretrained model for temporalaudio encoding and Qwen 3, a 0.6B Small Language Model (SLM), for textencoding, with both maintaining sequence structure for fine grained cross-modalmodeling. The architecture features specialized prediction pathways: OMQ ispredicted from pooled audio embeddings, while TA leverages bidirectionalsequence co-attention between audio and text. Sinkhorn optimal transport lossfurther enforce semantic alignment in the shared embedding space. On theMusicEval Track-1 dataset, WhisQ achieves substantial improvements over thebaseline: 7% improvement in Spearman correlation for OMQ and 14% for TA.Ablation studies reveal that optimal transport regularization provides thelargest performance gain (10% SRCC improvement), demonstrating the importanceof explicit cross-modal alignment for text-to-music evaluation.</description>
      <author>example@mail.com (Jakaria Islam Emon, Kazi Tamanna Alam, Md. Abu Salek)</author>
      <guid isPermaLink="false">2506.05899v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Hallucinate, Ground, Repeat: A Framework for Generalized Visual Relationship Detection</title>
      <link>http://arxiv.org/abs/2506.05651v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 9 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种迭代视觉 grounding 框架，利用大型语言模型（LLMs）作为结构化关系先验，以解决视觉关系检测（VRD）模型在处理未知关系时的泛化问题。&lt;h4&gt;背景&lt;/h4&gt;视觉关系检测在视觉智能、具身 AI、辅助系统和场景理解等领域有广泛应用，但大多数 VRD 模型依赖于固定的谓词集，限制了它们对新交互的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;解决从外部知识中假设的语义上合理但未注释的关系无法视觉化的关键挑战，并实现超越标注数据的关联理解。&lt;h4&gt;方法&lt;/h4&gt;方法交替使用 LLM 从检测到的对象生成候选场景图（期望阶段）和训练视觉模型以将假设与感知证据对齐（最大化阶段）。&lt;h4&gt;主要发现&lt;/h4&gt;模型在三个设置（seen, unseen, mixed）下的谓词分类中分别达到了 15.9, 13.1 和 11.7 的平均召回率（mR@50），优于 LLM-only、few-shot 和 debiased 基准。&lt;h4&gt;结论&lt;/h4&gt;基于 grounded LLM 先验的视觉理解具有可扩展的开放世界视觉理解的前景。&lt;h4&gt;翻译&lt;/h4&gt;Understanding relationships between objects is central to visual intelligence, with applications in embodied AI, assistive systems, and scene understanding. Yet, most visual relationship detection (VRD) models rely on a fixed predicate set, limiting their generalization to novel interactions. A key challenge is the inability to visually ground semantically plausible, but unannotated, relationships hypothesized from external knowledge. This work introduces an iterative visual grounding framework that leverages large language models (LLMs) as structured relational priors. Inspired by expectation-maximization (EM), our method alternates between generating candidate scene graphs from detected objects using an LLM (expectation) and training a visual model to align these hypotheses with perceptual evidence (maximization). This process bootstraps relational understanding beyond annotated data and enables generalization to unseen predicates. Additionally, we introduce a new benchmark for open-world VRD on Visual Genome with 21 held-out predicates and evaluate under three settings: seen, unseen, and mixed. Our model outperforms LLM-only, few-shot, and debiased baselines, achieving mean recall (mR@50) of 15.9, 13.1, and 11.7 on predicate classification on these three sets. These results highlight the promise of grounded LLM priors for scalable open-world visual understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding relationships between objects is central to visualintelligence, with applications in embodied AI, assistive systems, and sceneunderstanding. Yet, most visual relationship detection (VRD) models rely on afixed predicate set, limiting their generalization to novel interactions. A keychallenge is the inability to visually ground semantically plausible, butunannotated, relationships hypothesized from external knowledge. This workintroduces an iterative visual grounding framework that leverages largelanguage models (LLMs) as structured relational priors. Inspired byexpectation-maximization (EM), our method alternates between generatingcandidate scene graphs from detected objects using an LLM (expectation) andtraining a visual model to align these hypotheses with perceptual evidence(maximization). This process bootstraps relational understanding beyondannotated data and enables generalization to unseen predicates. Additionally,we introduce a new benchmark for open-world VRD on Visual Genome with 21held-out predicates and evaluate under three settings: seen, unseen, and mixed.Our model outperforms LLM-only, few-shot, and debiased baselines, achievingmean recall (mR@50) of 15.9, 13.1, and 11.7 on predicate classification onthese three sets. These results highlight the promise of grounded LLM priorsfor scalable open-world visual understanding.</description>
      <author>example@mail.com (Shanmukha Vellamcheti, Sanjoy Kundu, Sathyanarayanan N. Aakur)</author>
      <guid isPermaLink="false">2506.05651v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Learning Along the Arrow of Time: Hyperbolic Geometry for Backward-Compatible Representation Learning</title>
      <link>http://arxiv.org/abs/2506.05826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于双曲几何的向后兼容表示学习方法，通过考虑旧嵌入模型的不确定性，使更新模型能够无缝集成现有模型，避免重新处理存储数据。&lt;h4&gt;背景&lt;/h4&gt;现有的欧几里得空间兼容方法忽略了旧嵌入模型的不确定性，并强制新模型重构过时的表示，无论其质量如何，从而阻碍了新模型的学习过程。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过将嵌入提升到双曲空间，并限制更新嵌入位于旧嵌入的蕴涵锥内，以保持模型之间的代际一致性，同时考虑到表示中的不确定性。&lt;h4&gt;方法&lt;/h4&gt;使用双曲几何来处理时间，将时间视为捕捉模型置信度和演化的自然轴。引入了一种鲁棒的对比对齐损失，根据旧嵌入的不确定性动态调整对齐权重。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了所提出方法在实现兼容性方面的优越性，为构建更具弹性和适应性的机器学习系统铺平了道路。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地解决现有兼容性问题，为机器学习系统的进一步发展提供了新的思路和解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Backward compatible representation learning enables updated models tointegrate seamlessly with existing ones, avoiding to reprocess stored data.Despite recent advances, existing compatibility approaches in Euclidean spaceneglect the uncertainty in the old embedding model and force the new model toreconstruct outdated representations regardless of their quality, therebyhindering the learning process of the new model. In this paper, we propose toswitch perspectives to hyperbolic geometry, where we treat time as a naturalaxis for capturing a model's confidence and evolution. By lifting embeddingsinto hyperbolic space and constraining updated embeddings to lie within theentailment cone of the old ones, we maintain generational consistency acrossmodels while accounting for uncertainties in the representations. To furtherenhance compatibility, we introduce a robust contrastive alignment loss thatdynamically adjusts alignment weights based on the uncertainty of the oldembeddings. Experiments validate the superiority of the proposed method inachieving compatibility, paving the way for more resilient and adaptablemachine learning systems.</description>
      <author>example@mail.com (Ngoc Bui, Menglin Yang, Runjin Chen, Leonardo Neves, Mingxuan Ju, Rex Ying, Neil Shah, Tong Zhao)</author>
      <guid isPermaLink="false">2506.05826v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning</title>
      <link>http://arxiv.org/abs/2506.07044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report, 53 pages, 25 tables, and 16 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Lingshu的医学专用多模态大型语言模型，旨在解决现有医学MLLMs在医学应用中的局限性，并介绍了数据收集、模型训练和评估方法。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型在理解常见视觉元素方面表现出色，但在医学应用中效果有限，因为医学场景的数据和任务与通用领域存在本质差异。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来解决现有医学MLLMs的局限性，包括扩展医学知识覆盖范围、减少幻觉风险和提高推理能力。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种全面的数据收集和整理流程，从医学影像、医学文本和通用领域数据中获取丰富的医学知识数据；2. 合成了准确的医学字幕、视觉问答和推理样本；3. 引入了多阶段训练来嵌入医学专业知识并逐步提高任务解决能力；4. 探索了使用可验证奖励范式结合强化学习来增强医学推理能力；5. 开发了MedEvalKit，一个统一的评估框架，用于标准化、公平和高效地评估模型。&lt;h4&gt;主要发现&lt;/h4&gt;Lingshu在多项基本医学任务中（多模态问答、基于文本的问答和医学报告生成）的表现优于现有开源的多模态模型。&lt;h4&gt;结论&lt;/h4&gt;Lingshu是一个有效的医学专用多模态大型语言模型，能够提高医学应用中的任务解决能力，并为医学MLLMs的发展提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities in understanding common visual elements, largely due to their large-scale datasets and advanced training strategies. However, their effectiveness in medical applications remains limited due to the inherent discrepancies between data and tasks in medical scenarios and those in the general domain. Concretely, existing medical MLLMs face the following critical limitations: (1) limited coverage of medical knowledge beyond imaging, (2) heightened susceptibility to hallucinations due to suboptimal data curation processes, (3) lack of reasoning capabilities tailored for complex medical scenarios. To address these challenges, we first propose a comprehensive data curation procedure that (1) efficiently acquires rich medical knowledge data not only from medical imaging but also from extensive medical texts and general-domain data; and (2) synthesizes accurate medical captions, visual question answering (VQA), and reasoning samples. As a result, we build a multimodal dataset enriched with extensive medical knowledge. Building on the curated data, we introduce our medical-specialized MLLM: Lingshu. Lingshu undergoes multi-stage training to embed medical expertise and enhance its task-solving capabilities progressively. Besides, we preliminarily explore the potential of applying reinforcement learning with verifiable rewards paradigm to enhance Lingshu's medical reasoning ability. Additionally, we develop MedEvalKit, a unified evaluation framework that consolidates leading multimodal and textual medical benchmarks for standardized, fair, and efficient model assessment. We evaluate the performance of Lingshu on three fundamental medical tasks, multimodal QA, text-based QA, and medical report generation. The results show that Lingshu consistently outperforms the existing open-source multimodal models on most tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have demonstrated impressivecapabilities in understanding common visual elements, largely due to theirlarge-scale datasets and advanced training strategies. However, theireffectiveness in medical applications remains limited due to the inherentdiscrepancies between data and tasks in medical scenarios and those in thegeneral domain. Concretely, existing medical MLLMs face the following criticallimitations: (1) limited coverage of medical knowledge beyond imaging, (2)heightened susceptibility to hallucinations due to suboptimal data curationprocesses, (3) lack of reasoning capabilities tailored for complex medicalscenarios. To address these challenges, we first propose a comprehensive datacuration procedure that (1) efficiently acquires rich medical knowledge datanot only from medical imaging but also from extensive medical texts andgeneral-domain data; and (2) synthesizes accurate medical captions, visualquestion answering (VQA), and reasoning samples. As a result, we build amultimodal dataset enriched with extensive medical knowledge. Building on thecurated data, we introduce our medical-specialized MLLM: Lingshu. Lingshuundergoes multi-stage training to embed medical expertise and enhance itstask-solving capabilities progressively. Besides, we preliminarily explore thepotential of applying reinforcement learning with verifiable rewards paradigmto enhance Lingshu's medical reasoning ability. Additionally, we developMedEvalKit, a unified evaluation framework that consolidates leading multimodaland textual medical benchmarks for standardized, fair, and efficient modelassessment. We evaluate the performance of Lingshu on three fundamental medicaltasks, multimodal QA, text-based QA, and medical report generation. The resultsshow that Lingshu consistently outperforms the existing open-source multimodalmodels on most tasks ...</description>
      <author>example@mail.com (LASA Team, Weiwen Xu, Hou Pong Chan, Long Li, Mahani Aljunied, Ruifeng Yuan, Jianyu Wang, Chenghao Xiao, Guizhen Chen, Chaoqun Liu, Zhaodonghui Li, Yu Sun, Junao Shen, Chaojun Wang, Jie Tan, Deli Zhao, Tingyang Xu, Hao Zhang, Yu Rong)</author>
      <guid isPermaLink="false">2506.07044v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Beamforming and Resource Allocation for Delay Optimization in RIS-Assisted OFDM Systems</title>
      <link>http://arxiv.org/abs/2506.03586v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在下行可重构智能表面（RIS）辅助的正交频分复用（OFDM）系统中，联合相位设计和资源分配问题，以优化平均延迟。&lt;h4&gt;背景&lt;/h4&gt;数据包对每个用户的到达是随机的，使得问题本质上成为一个马尔可夫决策过程（MDP），属于强化学习的范畴。&lt;h4&gt;目的&lt;/h4&gt;提出一种混合深度强化学习（DRL）方法，以有效处理混合动作空间并降低状态空间维度。&lt;h4&gt;方法&lt;/h4&gt;使用近端策略优化（PPO）-Θ来优化RIS相移设计，而PPO-N负责子载波分配决策。引入多代理策略以更有效地优化子载波分配指标。将与平均延迟密切相关的关键因素，如缓冲区中积压的数据包数量和当前数据包到达量，纳入状态空间。此外，引入迁移学习框架以提高训练效率和加速收敛。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，所提出的算法显著降低了平均延迟，提高了资源分配效率，与基线方法相比，实现了更优的系统鲁棒性和公平性。&lt;h4&gt;结论&lt;/h4&gt;所提出的算法在优化平均延迟和资源分配效率方面表现出色，同时提高了系统的鲁棒性和公平性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates a joint phase design and resource allocation problemin downlink reconfigurable intelligent surface (RIS)-assisted orthogonalfrequency division multiplexing (OFDM) systems to optimize average delay, wheredata packets for each user arrive at the base station stochastically. Thesequential optimization problem is inherently a Markov decision process (MDP),making it fall within the scope of reinforcement learning. To effectivelyhandle the mixed action space and reduce the state space dimensionality, ahybrid deep reinforcement learning (DRL) approach is proposed. Specifically,proximal policy optimization (PPO)-$\Theta$ is employed to optimize RIS phaseshift design, while PPO-N is responsible for subcarrier allocation decisions.To further mitigate the curse of dimensionality associated with subcarrierallocation, a multi-agent strategy is introduced to optimize subcarrierallocation indicater more efficiently. Moreover, to achieve more adaptiveresource allocation and accurately capture network dynamics, key factorsclosely related to average delay, including the number of backlogged packets inbuffers and the current packet arrivals, are incorporated into the state space.Furthermore, a transfer learning framework is introduced to enhance trainingefficiency and accelerate convergence. Simulation results demonstrate that theproposed algorithm significantly reduces average delay, enhances resourceallocation efficiency, and achieves superior system robustness and fairnesscompared to baseline methods.</description>
      <author>example@mail.com (Yu Ma, Xiao Li, Chongtao Guo, Le Liang, Shi Jin)</author>
      <guid isPermaLink="false">2506.03586v2</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Positional Encoding meets Persistent Homology on Graphs</title>
      <link>http://arxiv.org/abs/2506.05814v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了消息传递图神经网络（GNNs）的局部归纳偏差问题，提出了一种新的可学习方法PiPE（持久性信息位置编码），以解决GNNs在利用关键结构信息方面的不足。&lt;h4&gt;背景&lt;/h4&gt;GNNs的局部归纳偏差阻碍了它们利用诸如连接性和循环等关键结构信息的能力。&lt;h4&gt;目的&lt;/h4&gt;提出新的方法以缓解GNNs的局部归纳偏差问题，并提高其表达能力。&lt;h4&gt;方法&lt;/h4&gt;引入了位置编码（PE）和持久同调（PH）方法，并提出了PiPE方法。&lt;h4&gt;主要发现&lt;/h4&gt;证明了PE和PH方法各有优劣，且无一种方法在所有情况下都优于另一种。PiPE在多种任务（如分子属性预测、图分类和泛化到分布外的情况）中表现良好。&lt;h4&gt;结论&lt;/h4&gt;PiPE是一种比PH和PE都更具表达力的新方法，可以提升图表示学习的前沿水平。&lt;h4&gt;翻译&lt;/h4&gt;摘要：局部归纳偏差阻碍了消息传递图神经网络（GNNs）利用关键结构信息（例如，连接性和循环）的能力。位置编码（PE）和持久同调（PH）是缓解此问题的两种有前途的方法。PE方案赋予GNNs位置感知特征，而PH方法增强了GNNs的多分辨率拓扑特征。然而，PE和PH的相对优缺点缺乏严格的理论描述。我们通过证明两种范式都不比对方更具有表现力，并提供了在一个方法失败而另一个方法成功的新构造，来弥合这一差距。我们的见解为设计了一种新的可学习方法PiPE（持久性信息位置编码）提供了信息，该方法证明比PH和PE都更有表现力。PiPE在各种任务（例如，分子属性预测、图分类和分布外泛化）中表现出强大的性能，从而推动了图表示学习的前沿。代码可在https://github.com/Aalto-QuML/PIPE上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The local inductive bias of message-passing graph neural networks (GNNs)hampers their ability to exploit key structural information (e.g., connectivityand cycles). Positional encoding (PE) and Persistent Homology (PH) have emergedas two promising approaches to mitigate this issue. PE schemes endow GNNs withlocation-aware features, while PH methods enhance GNNs with multiresolutiontopological features. However, a rigorous theoretical characterization of therelative merits and shortcomings of PE and PH has remained elusive. We bridgethis gap by establishing that neither paradigm is more expressive than theother, providing novel constructions where one approach fails but the othersucceeds. Our insights inform the design of a novel learnable method, PiPE(Persistence-informed Positional Encoding), which is provably more expressivethan both PH and PE. PiPE demonstrates strong performance across a variety oftasks (e.g., molecule property prediction, graph classification, andout-of-distribution generalization), thereby advancing the frontiers of graphrepresentation learning. Code is available athttps://github.com/Aalto-QuML/PIPE.</description>
      <author>example@mail.com (Yogesh Verma, Amauri H. Souza, Vikas Garg)</author>
      <guid isPermaLink="false">2506.05814v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Does Your 3D Encoder Really Work? When Pretrain-SFT from 2D VLMs Meets 3D VLMs</title>
      <link>http://arxiv.org/abs/2506.05318v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了二维视觉语言模型（VLMs）在三维场景中的应用，分析了不同模型架构的优缺点，并提出了一种新的数据集以促进三维场景理解。&lt;h4&gt;背景&lt;/h4&gt;随着二维视觉语言模型（VLMs）在二维视觉任务上的显著进步，研究者们开始探索将这些模型扩展到三维场景中，用于三维问答、密集描述和视觉定位等任务。&lt;h4&gt;目的&lt;/h4&gt;研究三维视觉语言模型（3D VLMs）在三维场景中的表现，并寻找提高三维理解的方法。&lt;h4&gt;方法&lt;/h4&gt;将最近的3D VLMs分为三类：以3D对象为中心、基于2D图像和以3D场景为中心的方法。通过深入分析，研究了3D场景中心VLMs的性能差异和原因。&lt;h4&gt;主要发现&lt;/h4&gt;3D场景中心VLMs在性能上低于最新的3D对象中心和基于2D图像的方法，原因在于它们对3D场景编码器的依赖有限，且预训练阶段的效果不如二维VLMs。数据扩展对大型数据集的益处不明显。模型倾向于过度依赖语言线索并过度拟合常见答案分布，从而减少了3D编码器的有效利用。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的3D相关性判别问答数据集，旨在打破捷径学习并提高三维理解。强调了在3D VLMs中需要更先进的评估和改进策略以实现更好的三维理解。&lt;h4&gt;翻译&lt;/h4&gt;With remarkable progress in 2D Vision-Language Models (VLMs) spurring interest in extending them to 3D settings for tasks like 3D Question Answering, DenseCaptioning, and Visual Grounding, this paper discusses the application of 3D VLMs in 3D scenes, analyzes the advantages and disadvantages of different model architectures, and proposes a new dataset to promote 3D scene understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Remarkable progress in 2D Vision-Language Models (VLMs) has spurred interestin extending them to 3D settings for tasks like 3D Question Answering, DenseCaptioning, and Visual Grounding. Unlike 2D VLMs that typically process imagesthrough an image encoder, 3D scenes, with their intricate spatial structures,allow for diverse model architectures. Based on their encoder design, thispaper categorizes recent 3D VLMs into 3D object-centric, 2D image-based, and 3Dscene-centric approaches. Despite the architectural similarity of 3Dscene-centric VLMs to their 2D counterparts, they have exhibited comparativelylower performance compared with the latest 3D object-centric and 2D image-basedapproaches. To understand this gap, we conduct an in-depth analysis, revealingthat 3D scene-centric VLMs show limited reliance on the 3D scene encoder, andthe pre-train stage appears less effective than in 2D VLMs. Furthermore, weobserve that data scaling benefits are less pronounced on larger datasets. Ourinvestigation suggests that while these models possess cross-modal alignmentcapabilities, they tend to over-rely on linguistic cues and overfit to frequentanswer distributions, thereby diminishing the effective utilization of the 3Dencoder. To address these limitations and encourage genuine 3D sceneunderstanding, we introduce a novel 3D Relevance Discrimination QA datasetdesigned to disrupt shortcut learning and improve 3D understanding. Ourfindings highlight the need for advanced evaluation and improved strategies forbetter 3D understanding in 3D VLMs.</description>
      <author>example@mail.com (Haoyuan Li, Yanpeng Zhou, Yufei Gao, Tao Tang, Jianhua Han, Yujie Yuan, Dave Zhenyu Chen, Jiawang Bian, Hang Xu, Xiaodan Liang)</author>
      <guid isPermaLink="false">2506.05318v2</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>LaTtE-Flow: Layerwise Timestep-Expert Flow-based Transformer</title>
      <link>http://arxiv.org/abs/2506.06952v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Unified multimodal model, Flow-matching&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;LaTtE-Flow是一种新型且高效的架构，它统一了图像理解和生成，并提高了性能和生成速度。&lt;h4&gt;背景&lt;/h4&gt;现有统一的多模态模型需要大量预训练，且图像生成速度慢，限制了在实际应用中的部署。&lt;h4&gt;目的&lt;/h4&gt;提出LaTtE-Flow，以实现高效且性能优越的图像理解和生成。&lt;h4&gt;方法&lt;/h4&gt;LaTtE-Flow基于预训练的视觉-语言模型（VLMs），并结合了基于层和时步专家流的新架构。它通过在每个采样时步仅激活一小部分Transformer层来提高采样效率，并采用时步条件残差注意力机制以实现层间高效的信息重用。&lt;h4&gt;主要发现&lt;/h4&gt;LaTtE-Flow在多模态理解任务上取得了良好的性能，同时与最新的统一多模态模型相比，其推理速度提高了约6倍。&lt;h4&gt;结论&lt;/h4&gt;LaTtE-Flow在保持较高图像生成质量的同时，显著提高了性能和生成速度，为多模态任务提供了有效解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in multimodal foundation models unifying image understandingand generation have opened exciting avenues for tackling a wide range ofvision-language tasks within a single framework. Despite progress, existingunified models typically require extensive pretraining and struggle to achievethe same level of performance compared to models dedicated to each task.Additionally, many of these models suffer from slow image generation speeds,limiting their practical deployment in real-time or resource-constrainedsettings. In this work, we propose Layerwise Timestep-Expert Flow-basedTransformer (LaTtE-Flow), a novel and efficient architecture that unifies imageunderstanding and generation within a single multimodal model. LaTtE-Flowbuilds upon powerful pretrained Vision-Language Models (VLMs) to inherit strongmultimodal understanding capabilities, and extends them with a novel LayerwiseTimestep Experts flow-based architecture for efficient image generation.LaTtE-Flow distributes the flow-matching process across specialized groups ofTransformer layers, each responsible for a distinct subset of timesteps. Thisdesign significantly improves sampling efficiency by activating only a smallsubset of layers at each sampling timestep. To further enhance performance, wepropose a Timestep-Conditioned Residual Attention mechanism for efficientinformation reuse across layers. Experiments demonstrate that LaTtE-Flowachieves strong performance on multimodal understanding tasks, while achievingcompetitive image generation quality with around 6x faster inference speedcompared to recent unified multimodal models.</description>
      <author>example@mail.com (Ying Shen, Zhiyang Xu, Jiuhai Chen, Shizhe Diao, Jiaxin Zhang, Yuguang Yao, Joy Rimchala, Ismini Lourentzou, Lifu Huang)</author>
      <guid isPermaLink="false">2506.06952v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>VideoChat-A1: Thinking with Long Videos by Chain-of-Shot Reasoning</title>
      <link>http://arxiv.org/abs/2506.06097v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了视频理解领域的一项新进展，即VideoChat-A1，这是一种新型长视频智能体范式，能够有效地理解长视频内容。&lt;h4&gt;背景&lt;/h4&gt;当前的多模态大型语言模型（MLLMs）在分析短视频方面表现良好，但在理解具有较长上下文的长视频方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;为了解决长视频理解中的困难，论文提出了VideoChat-A1，旨在提高对长视频内容的理解能力。&lt;h4&gt;方法&lt;/h4&gt;VideoChat-A1采用了一种独特的镜头链推理范式，能够逐步选择与用户问题相关的镜头，并从粗到细地分析这些镜头。通过沿着镜头链进行多模态推理，VideoChat-A1可以模拟人类的思考过程，以发现对长视频内容进行深思熟虑理解的有利时间上下文。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，VideoChat-A1在主流长视频问答基准测试中取得了最先进的性能，例如在VideoMME上达到77.0，在EgoSchema上达到70.1，分别比其强基线（如Intern2.5VL-8B和InternVideo2.5-8B）提高了10.8%和6.2%。与GPT-4o和Gemini 1.5 Pro等领先的开源模型相比，VideoChat-A1在准确性方面具有竞争力，但输入帧数减少了7%，推理时间减少了12%。&lt;h4&gt;结论&lt;/h4&gt;VideoChat-A1通过创新的镜头链推理范式，有效地提高了长视频的理解能力，为长视频内容分析提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;最近，视频理解领域的进步是由多模态大型语言模型（MLLMs）驱动的。但是，这些MLLMs擅长分析短视频，而在理解具有较长上下文的长视频方面存在困难。为了解决这一困难，最近提出了几种智能体范式，使用MLLMs作为智能体以检索长视频中的额外上下文知识。然而，大多数现有的智能体忽略了这样一个关键事实，即长视频由多个镜头组成，即要回答来自长视频的用户问题，深入了解其相关镜头对人类来说是至关重要的。没有这样的见解，这些智能体往往会错误地发现冗余甚至噪声的时间上下文，限制了它们在长视频理解方面的能力。为了填补这一空白，我们提出了VideoChat-A1，这是一种新颖的长视频智能体范式。与先前的工作不同，我们的VideoChat-A1可以通过独特的镜头链推理范式深入思考长视频。更具体地说，它可以逐步选择用户问题的相关镜头，并从粗到细地查看这些镜头。通过沿着镜头链进行多模态推理，VideoChat-A1可以有效地模拟逐步的人类思考过程，从而能够交互式地发现对长视频内容进行深思熟虑理解的有利时间上下文。广泛的实验表明，我们的VideoChat-A1在主流长视频问答基准测试中取得了最先进的性能，例如在VideoMME上达到77.0，在EgoSchema上达到70.1，分别比其强基线（例如Intern2.5VL-8B和InternVideo2.5-8B）提高了10.8%和6.2%。与领先的开源GPT-4o和Gemini 1.5 Pro相比，VideoChat-A1提供了具有竞争力的准确性，但平均输入帧数减少了7%，推理时间减少了12%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent advance in video understanding has been driven by multimodal largelanguage models (MLLMs). But these MLLMs are good at analyzing short videos,while suffering from difficulties in understanding videos with a longercontext. To address this difficulty, several agent paradigms have recently beenproposed, using MLLMs as agents for retrieving extra contextual knowledge in along video. However, most existing agents ignore the key fact that a long videois composed with multiple shots, i.e., to answer the user question from a longvideo, it is critical to deeply understand its relevant shots like human.Without such insight, these agents often mistakenly find redundant even noisytemporal context, restricting their capacity for long video understanding. Tofill this gap, we propose VideoChat-A1, a novel long video agent paradigm.Different from the previous works, our VideoChat-A1 can deeply think with longvideos, via a distinct chain-of-shot reasoning paradigm. More specifically, itcan progressively select the relevant shots of user question, and look intothese shots in a coarse-to-fine partition. By multi-modal reasoning along theshot chain, VideoChat-A1 can effectively mimic step-by-step human thinkingprocess, allowing to interactively discover preferable temporal context forthoughtful understanding in long videos. Extensive experiments show that, ourVideoChat-A1 achieves the state-of-the-art performance on the mainstream longvideo QA benchmarks, e.g., it achieves 77.0 on VideoMME and 70.1 on EgoSchema,outperforming its strong baselines (e.g., Intern2.5VL-8B andInternVideo2.5-8B), by up to 10.8\% and 6.2\%. Compared to leading close-sourceGPT-4o and Gemini 1.5 Pro, VideoChat-A1 offers competitive accuracy, but with7\% input frames and 12\% inference time on average.</description>
      <author>example@mail.com (Zikang Wang, Boyu Chen, Zhengrong Yue, Yi Wang, Yu Qiao, Limin Wang, Yali Wang)</author>
      <guid isPermaLink="false">2506.06097v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>GP-MoLFormer-Sim: Test Time Molecular Optimization through Contextual Similarity Guidance</title>
      <link>http://arxiv.org/abs/2506.05628v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages main article, 21 pages total&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于生成化学语言模型（CLM）的、无需训练的分子空间导航和采样方法，该方法利用分子相似性作为指导，并应用于药物发现、化学设计和生物学等领域。&lt;h4&gt;背景&lt;/h4&gt;设计分子时保持与目标分子和/或性质的相似性对于药物发现、化学设计和生物学等领域的应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的无需训练的分子空间导航和采样方法，同时保持与目标分子的相似性。&lt;h4&gt;方法&lt;/h4&gt;该方法利用CLM学习到的上下文表示来估计分子相似性，并据此调整CLM的自回归采样策略。在解码过程的每一步，该方法都会跟踪当前生成与目标之间的距离，并更新logits以鼓励生成保持相似性。该方法使用了一种参数数量约为4700万的基于SMILES的CLM，即GP-MoLFormer，并因此将其称为GP-MoLFormer-Sim。该方法还与遗传算法（GA）集成，并在涉及性质优化、分子重发现和基于结构的药物设计的标准分子优化基准上进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;GP-MoLFormer-Sim结合遗传算法（GP-MoLFormer-Sim+GA）在黑盒情况下优于现有的无需训练的基线方法。&lt;h4&gt;结论&lt;/h4&gt;这项工作的发现是理解并指导CLM生成机制的一步。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种基于生成化学语言模型（CLM）的、无需训练的分子空间导航和采样方法，该方法利用分子相似性作为指导，并应用于药物发现、化学设计和生物学等领域。我们提出的方法利用CLM本身学习到的上下文表示来估计分子相似性，然后使用该相似性来调整CLM的自回归采样策略。在解码过程的每一步，该方法都会跟踪当前生成与目标之间的距离，并更新logits以鼓励生成保持相似性。我们使用了一种参数数量约为4700万的基于SMILES的CLM，即GP-MoLFormer，并因此将其称为GP-MoLFormer-Sim，该模型允许在测试时更新深度生成策略以反映与一组指导分子的上下文相似性。该方法进一步与遗传算法（GA）集成，并在涉及性质优化、分子重发现和基于结构的药物设计的标准分子优化基准上进行了测试。结果表明，GP-MoLFormer-Sim结合遗传算法（GP-MoLFormer-Sim+GA）在黑盒情况下优于现有的无需训练的基线方法。这项工作的发现是理解并指导CLM生成机制的一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to design molecules while preserving similarity to a targetmolecule and/or property is crucial for various applications in drug discovery,chemical design, and biology. We introduce in this paper an efficienttraining-free method for navigating and sampling from the molecular space witha generative Chemical Language Model (CLM), while using the molecularsimilarity to the target as a guide. Our method leverages the contextualrepresentations learned from the CLM itself to estimate the molecularsimilarity, which is then used to adjust the autoregressive sampling strategyof the CLM. At each step of the decoding process, the method tracks thedistance of the current generations from the target and updates the logits toencourage the preservation of similarity in generations. We implement themethod using a recently proposed $\sim$47M parameter SMILES-based CLM,GP-MoLFormer, and therefore refer to the method as GP-MoLFormer-Sim, whichenables a test-time update of the deep generative policy to reflect thecontextual similarity to a set of guide molecules. The method is furtherintegrated into a genetic algorithm (GA) and tested on a set of standardmolecular optimization benchmarks involving property optimization, molecularrediscovery, and structure-based drug design. Results show that,GP-MoLFormer-Sim, combined with GA (GP-MoLFormer-Sim+GA) outperforms existingtraining-free baseline methods, when the oracle remains black-box. The findingsin this work are a step forward in understanding and guiding the generativemechanisms of CLMs.</description>
      <author>example@mail.com (Jiri Navratil, Jarret Ross, Payel Das, Youssef Mroueh, Samuel C Hoffman, Vijil Chenthamarakshan, Brian Belgodere)</author>
      <guid isPermaLink="false">2506.05628v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>PROVSYN: Synthesizing Provenance Graphs for Data Augmentation in Intrusion Detection Systems</title>
      <link>http://arxiv.org/abs/2506.06226v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PROVSYN是一个自动化的框架，通过三个阶段合成来源图，用于入侵检测，特别是在对抗高级持续性威胁（APTs）时，通过展示复杂的攻击模式。&lt;h4&gt;背景&lt;/h4&gt;来源图分析在入侵检测中起着至关重要的作用，特别是在对抗高级持续性威胁（APTs）时，因为它可以揭示复杂的攻击模式。然而，由于现实世界数据中的类别不平衡，结合图神经网络（GNNs）和自然语言处理（NLP）的系统效果有限。&lt;h4&gt;目的&lt;/h4&gt;提出PROVSYN，以解决现实世界数据中类别不平衡的问题，提高入侵检测模型的性能。&lt;h4&gt;方法&lt;/h4&gt;PROVSYN通过以下三个阶段合成来源图：1）使用结构-语义建模进行异构图结构合成；2）基于规则的拓扑优化；3）使用大型语言模型（LLMs）进行上下文感知的文本属性合成。PROVSYN包括一个综合评估框架，该框架整合了结构、文本、时间和基于嵌入的指标，以及语义验证机制，以评估生成的攻击模式和系统行为的正确性。&lt;h4&gt;主要发现&lt;/h4&gt;使用合成图增加下游APT检测模型的训练数据集，实验结果表明PROVSYN能够生成高保真度的图，并通过有效数据增强提高了检测性能。&lt;h4&gt;结论&lt;/h4&gt;PROVSYN框架能够有效地提高入侵检测模型对高级持续性威胁的检测性能，并通过数据增强增强了模型的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Provenance graph analysis plays a vital role in intrusion detection,particularly against Advanced Persistent Threats (APTs), by exposing complexattack patterns. While recent systems combine graph neural networks (GNNs) withnatural language processing (NLP) to capture structural and semantic features,their effectiveness is limited by class imbalance in real-world data. Toaddress this, we introduce PROVSYN, an automated framework that synthesizesprovenance graphs through a three-phase pipeline: (1) heterogeneous graphstructure synthesis with structural-semantic modeling, (2) rule-basedtopological refinement, and (3) context-aware textual attribute synthesis usinglarge language models (LLMs). PROVSYN includes a comprehensive evaluationframework that integrates structural, textual, temporal, and embedding-basedmetrics, along with a semantic validation mechanism to assess the correctnessof generated attack patterns and system behaviors. To demonstrate practicalutility, we use the synthetic graphs to augment training datasets fordownstream APT detection models. Experimental results show that PROVSYNproduces high-fidelity graphs and improves detection performance througheffective data augmentation.</description>
      <author>example@mail.com (Yi Huang, Wajih UI Hassan, Yao Guo, Xiangqun Chen, Ding Li)</author>
      <guid isPermaLink="false">2506.06226v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>ProJo4D: Progressive Joint Optimization for Sparse-View Inverse Physics Estimation</title>
      <link>http://arxiv.org/abs/2506.05317v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ProJo4D的渐进式联合优化框架，用于解决基于物理的神经渲染问题，提高了4D场景理解的效果。&lt;h4&gt;背景&lt;/h4&gt;神经渲染在3D重建和新视角合成方面取得了显著进展，但将物理与神经渲染结合的逆问题（从视觉数据中估计物理参数）仍然具有挑战性，限制了其在机器人学和XR等领域应用的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高基于物理的神经渲染的准确性，特别是在使用稀疏多视角视频数据时。&lt;h4&gt;方法&lt;/h4&gt;ProJo4D通过逐渐增加联合优化参数的集合，并基于它们的敏感性来指导优化过程，从而实现几何、外观、物理状态和材料属性的完全联合优化。&lt;h4&gt;主要发现&lt;/h4&gt;在PAC-NeRF和Spring-Gaus数据集上的评估表明，ProJo4D在4D未来状态预测、未来状态的新视角渲染和材料参数估计方面优于现有工作。&lt;h4&gt;结论&lt;/h4&gt;ProJo4D框架在物理基础上的4D场景理解方面表现出有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：神经渲染在3D重建和新视角合成方面取得了显著进展。与物理的结合开辟了新的应用。然而，从视觉数据中估计物理参数的逆问题仍然具有挑战性，限制了其在机器人学和XR等应用中的有效性。将物理纳入神经渲染框架的现有方法通常需要密集的多视角视频作为输入，这使得它们在实际应用中难以扩展。当面对稀疏的多视角视频时，现有方法使用的顺序优化策略会导致显著的误差累积，例如，不良的初始3D重建会导致后续阶段的材料参数估计不良。与顺序优化不同，由于问题的高度非凸性和通常不可微分的性质，直接同时优化所有参数也失败了。我们提出了ProJo4D，一个渐进式联合优化框架，它根据其敏感性逐步增加联合优化的参数集合，导致对几何、外观、物理状态和材料属性的完全联合优化。在PAC-NeRF和Spring-Gaus数据集上的评估表明，ProJo4D在4D未来状态预测、未来状态的新视角渲染和材料参数估计方面优于先前的工作，证明了它在物理基础上的4D场景理解方面的有效性。有关演示，请访问项目网页：https://daniel03c1.github.io/ProJo4D/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural rendering has made significant strides in 3D reconstruction and novelview synthesis. With the integration with physics, it opens up newapplications. The inverse problem of estimating physics from visual data,however, still remains challenging, limiting its effectiveness for applicationslike physically accurate digital twin creation in robotics and XR. Existingmethods that incorporate physics into neural rendering frameworks typicallyrequire dense multi-view videos as input, making them impractical for scalable,real-world use. When presented with sparse multi-view videos, the sequentialoptimization strategy used by existing approaches introduces significant erroraccumulation, e.g., poor initial 3D reconstruction leads to bad materialparameter estimation in subsequent stages. Instead of sequential optimization,directly optimizing all parameters at the same time also fails due to thehighly non-convex and often non-differentiable nature of the problem. Wepropose ProJo4D, a progressive joint optimization framework that graduallyincreases the set of jointly optimized parameters guided by their sensitivity,leading to fully joint optimization over geometry, appearance, physical state,and material property. Evaluations on PAC-NeRF and Spring-Gaus datasets showthat ProJo4D outperforms prior work in 4D future state prediction, novel viewrendering of future state, and material parameter estimation, demonstrating itseffectiveness in physically grounded 4D scene understanding. For demos, pleasevisit the project webpage: https://daniel03c1.github.io/ProJo4D/</description>
      <author>example@mail.com (Daniel Rho, Jun Myeong Choi, Biswadip Dey, Roni Sengupta)</author>
      <guid isPermaLink="false">2506.05317v2</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Can In-Context Reinforcement Learning Recover From Reward Poisoning Attacks?</title>
      <link>http://arxiv.org/abs/2506.06891v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于上下文的强化学习（ICRL）的抗腐败鲁棒性，重点关注决策预训练的Transformer（DPT）模型，并提出了一种对抗训练框架AT-DPT来应对针对DPT的奖励中毒攻击。&lt;h4&gt;背景&lt;/h4&gt;DPT模型容易受到奖励中毒攻击的影响，这会导致其学习到的策略失效。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种新的对抗训练方法，增强DPT模型对奖励中毒攻击的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种对抗训练框架AT-DPT，该方法同时训练一个攻击者和一个DPT模型。攻击者旨在通过污染环境奖励来最小化DPT的真实奖励，而DPT模型则从污染数据中推断出最优动作。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，AT-DPT在对抗标准bandit算法，包括针对奖励污染设计的鲁棒基线时，显著优于这些基线。在自适应攻击者的评估中，AT-DPT也表现出了类似的结果。此外，将AT-DPT的评估扩展到MDP设置中，结果表明在bandit场景中观察到的鲁棒性在更复杂的环境中也是适用的。&lt;h4&gt;结论&lt;/h4&gt;AT-DPT框架能够有效提高DPT模型对奖励中毒攻击的鲁棒性，并在更复杂的环境中表现出良好的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;We study the corruption-robustness of in-context reinforcement learning (ICRL), focusing on the Decision-Pretrained Transformer (DPT, Lee et al.,2023). To address the challenge of reward poisoning attacks targeting the DPT,we propose a novel adversarial training framework, called Adversarially Trained Decision-Pretrained Transformer (AT-DPT). Our method simultaneously trains an attacker to minimize the true reward of the DPT by poisoning environment rewards, and a DPT model to infer optimal actions from the poisoned data. We evaluate the effectiveness of our approach against standard bandit algorithms, including robust baselines designed to handle reward contamination. Our results show that the proposed method significantly outperforms these baselines in bandit settings, under a learned attacker. We additionally evaluate AT-DPT on an adaptive attacker, and observe similar results. Furthermore, we extend our evaluation to the MDP setting, confirming that the robustness observed in bandit scenarios generalizes to more complex environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the corruption-robustness of in-context reinforcement learning(ICRL), focusing on the Decision-Pretrained Transformer (DPT, Lee et al.,2023). To address the challenge of reward poisoning attacks targeting the DPT,we propose a novel adversarial training framework, called Adversarially TrainedDecision-Pretrained Transformer (AT-DPT). Our method simultaneously trains anattacker to minimize the true reward of the DPT by poisoning environmentrewards, and a DPT model to infer optimal actions from the poisoned data. Weevaluate the effectiveness of our approach against standard bandit algorithms,including robust baselines designed to handle reward contamination. Our resultsshow that the proposed method significantly outperforms these baselines inbandit settings, under a learned attacker. We additionally evaluate AT-DPT onan adaptive attacker, and observe similar results. Furthermore, we extend ourevaluation to the MDP setting, confirming that the robustness observed inbandit scenarios generalizes to more complex environments.</description>
      <author>example@mail.com (Paulius Sasnauskas, Yiğit Yalın, Goran Radanović)</author>
      <guid isPermaLink="false">2506.06891v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Discrete Minds in a Continuous World: Do Language Models Know Time Passes?</title>
      <link>http://arxiv.org/abs/2506.05790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了大型语言模型（LLMs）对时间流逝的感知能力及其在决策中的适应性。&lt;h4&gt;背景&lt;/h4&gt;尽管LLMs在时间推理任务上表现出色，但它们对实际时间流逝的感知能力尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;通过三项实验研究LLMs是否能够感知时间流逝并据此调整决策。&lt;h4&gt;方法&lt;/h4&gt;首先，提出了Token-Time假设，并通过对话时长判断任务验证该假设；其次，展示了LLMs如何利用这种意识来调整回答长度，在用户表达紧迫性时保持准确性；最后，开发了BombRush游戏，以检验LLMs在动态环境中面对渐进时间压力时的行为变化。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs对时间流逝有一定的感知能力，能够将离散的语言符号与连续的物理时间相连接，但这种能力随模型大小和推理能力而异。&lt;h4&gt;结论&lt;/h4&gt;本研究为在时间敏感应用中提高LLMs的时间感知能力奠定了理论基础。&lt;h4&gt;翻译&lt;/h4&gt;While Large Language Models (LLMs) excel at temporal reasoning tasks like event ordering and duration estimation, their ability to perceive the actual passage of time remains unexplored. We investigate whether LLMs perceive the passage of time and adapt their decision-making accordingly through three complementary experiments. First, we introduce the Token-Time Hypothesis, positing that LLMs can map discrete token counts to continuous wall-clock time, and validate this through a dialogue duration judgment task. Second, we demonstrate that LLMs could use this awareness to adapt their response length while maintaining accuracy when users express urgency in question answering tasks. Finally, we develop BombRush, an interactive navigation challenge that examines how LLMs modify behavior under progressive time pressure in dynamic environments. Our findings indicate that LLMs possess certain awareness of time passage, enabling them to bridge discrete linguistic tokens and continuous physical time, though this capability varies with model size and reasoning abilities. This work establishes a theoretical foundation for enhancing temporal awareness in LLMs for time-sensitive applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While Large Language Models (LLMs) excel at temporal reasoning tasks likeevent ordering and duration estimation, their ability to perceive the actualpassage of time remains unexplored. We investigate whether LLMs perceive thepassage of time and adapt their decision-making accordingly through threecomplementary experiments. First, we introduce the Token-Time Hypothesis,positing that LLMs can map discrete token counts to continuous wall-clock time,and validate this through a dialogue duration judgment task. Second, wedemonstrate that LLMs could use this awareness to adapt their response lengthwhile maintaining accuracy when users express urgency in question answeringtasks. Finally, we develop BombRush, an interactive navigation challenge thatexamines how LLMs modify behavior under progressive time pressure in dynamicenvironments. Our findings indicate that LLMs possess certain awareness of timepassage, enabling them to bridge discrete linguistic tokens and continuousphysical time, though this capability varies with model size and reasoningabilities. This work establishes a theoretical foundation for enhancingtemporal awareness in LLMs for time-sensitive applications.</description>
      <author>example@mail.com (Minghan Wang, Ye Bai, Thuy-Trang Vu, Ehsan Shareghi, Gholamreza Haffari)</author>
      <guid isPermaLink="false">2506.05790v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Masked Language Models are Good Heterogeneous Graph Generalizers</title>
      <link>http://arxiv.org/abs/2506.06157v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于掩码语言模型的异构图学习方法MLM4HG，旨在解决现有方法在异构图学习中的泛化问题。&lt;h4&gt;背景&lt;/h4&gt;现有的异构图神经网络（HGNNs）在捕捉异构图（HGs）的结构和语义信息方面表现出色，但在跨领域和任务上的泛化能力有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以增强异构图学习的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;MLM4HG通过基于元路径的文本序列来提取异构图中的结构化和语义信息，并设计定制的文本模板，将不同的图任务统一到一个连贯的完形填空式“掩码”标记预测范式。该方法首先将不同领域的异构图转换为文本，然后结合统一任务文本形成基于异构图的语料库，并使用预训练的语言模型进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界数据集上的跨领域和多任务实验表明，MLM4HG在少样本和零样本场景下均优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;MLM4HG在异构图学习中的泛化性能显著，是一种简单而有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;The abstract of this paper is summarized as follows: This paper proposes a Masked Language Modeling-based method for heterogeneous graph learning, called MLM4HG, aiming to enhance the generalization ability of existing methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterogeneous graph neural networks (HGNNs) excel at capturing structural andsemantic information in heterogeneous graphs (HGs), while struggling togeneralize across domains and tasks. Recently, some researchers have turned tointegrating HGNNs with large language models (LLMs) for more generalizableheterogeneous graph learning. However, these approaches typically extractstructural information via HGNNs as HG tokens, and disparities in embeddingspaces between HGNNs and LLMs have been shown to bias the LLM's comprehensionof HGs. Moreover, as these HG tokens are often derived from node-level tasks,the model's ability to generalize across tasks remains limited. To this end, wepropose a simple yet effective Masked Language Modeling-based method, calledMLM4HG. MLM4HG introduces metapath-based textual sequences instead of HG tokensto extract structural and semantic information inherent in HGs, and designscustomized textual templates to unify different graph tasks into a coherentcloze-style "mask" token prediction paradigm. Specifically, MLM4HG firstconverts HGs from various domains to texts based on metapaths, and subsequentlycombines them with the unified task texts to form a HG-based corpus. Moreover,the corpus is fed into a pretrained LM for fine-tuning with a constrainedtarget vocabulary, enabling the fine-tuned LM to generalize to unseen targetHGs. Extensive cross-domain and multi-task experiments on four real-worlddatasets demonstrate the superior generalization performance of MLM4HG overstate-of-the-art methods in both few-shot and zero-shot scenarios. Our code isavailable at https://github.com/BUPT-GAMMA/MLM4HG.</description>
      <author>example@mail.com (Jinyu Yang, Cheng Yang, Shanyuan Cui, Zeyuan Guo, Liangwei Yang, Muhan Zhang, Chuan Shi)</author>
      <guid isPermaLink="false">2506.06157v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Two-dimensional Taxonomy for N-ary Knowledge Representation Learning Methods</title>
      <link>http://arxiv.org/abs/2506.05626v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了处理n元关系数据的知识超图和超关系知识图谱方法，提出了一个两维分类体系，并讨论了现有数据集、负采样策略和未来研究方向。&lt;h4&gt;背景&lt;/h4&gt;现实世界的知识可以以结构化、半结构化和非结构化数据的形式存在，知识图谱虽然能够整合异构数据源，但通常会将复杂的n元关系简化为简单的三元组，从而丢失了更高阶的关系细节。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了知识超图和超关系知识图谱，结合知识图谱和超图的优势，以更好地捕捉现实世界知识的复杂结构和角色特定的语义。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个两维分类体系，第一维根据方法分类，包括基于翻译的模型、基于张量分解的模型、基于深度神经网络的模型、基于逻辑规则的模型和基于超边扩展的模型。第二维根据模型对实体角色和位置在n元关系中的感知分类，分为无感知、位置感知和角色感知方法。&lt;h4&gt;主要发现&lt;/h4&gt;本文提供了一个全面的综述，包括知识超图和超关系知识图谱的文献，并讨论了现有的数据集、负采样策略。&lt;h4&gt;结论&lt;/h4&gt;本文总结了现有研究，并提出了未来研究的开放挑战，以激发进一步的研究工作。&lt;h4&gt;翻译&lt;/h4&gt;本文综述了处理n元关系数据的知识超图和超关系知识图谱方法，提出了一个两维分类体系：第一个维度根据方法将模型分类，即基于翻译的模型、基于张量分解的模型、基于深度神经网络的模型、基于逻辑规则的模型和基于超边扩展的模型；第二个维度根据模型对实体角色和位置在n元关系中的感知分类，分为无感知、位置感知和角色感知方法。最后，讨论了现有数据集、负采样策略，并概述了开放挑战，以激发未来的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world knowledge can take various forms, including structured,semi-structured, and unstructured data. Among these, knowledge graphs are aform of structured human knowledge that integrate heterogeneous data sourcesinto structured representations but typically reduce complex n-ary relations tosimple triples, thereby losing higher-order relational details. In contrast,hypergraphs naturally represent n-ary relations with hyperedges, which directlyconnect multiple entities together. Yet hypergraph representation learningoften overlooks entity roles in hyperedges, limiting the fine-grained semanticmodelling. To address these issues, knowledge hypergraphs and hyper-relationalknowledge graphs combine the advantages of knowledge graphs and hypergraphs tobetter capture the complex structures and role-specific semantics of real-worldknowledge. This survey provides a comprehensive review of methods handlingn-ary relational data, covering both knowledge hypergraphs and hyper-relationalknowledge graphs literatures. We propose a two-dimensional taxonomy: the firstdimension categorises models based on their methodology, i.e.,translation-based models, tensor factorisation-based models, deep neuralnetwork-based models, logic rules-based models, and hyperedge expansion-basedmodels. The second dimension classifies models according to their awareness ofentity roles and positions in n-ary relations, dividing them into aware-less,position-aware, and role-aware approaches. Finally, we discuss existingdatasets, negative sampling strategies, and outline open challenges to inspirefuture research.</description>
      <author>example@mail.com (Xiaohua Lu, Liubov Tupikina, Mehwish Alam)</author>
      <guid isPermaLink="false">2506.05626v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SIV-Bench: A Video Benchmark for Social Interaction Understanding and Reasoning</title>
      <link>http://arxiv.org/abs/2506.05425v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SIV-Bench，一个用于评估多模态大型语言模型在社交场景理解、社交状态推理和社交动态预测方面的能力的视频基准。&lt;h4&gt;背景&lt;/h4&gt;人类社交互动的丰富性和多层次性，包括多模态线索、不可观察的关系和心智状态以及动态行为，对人工智能提出了巨大挑战。&lt;h4&gt;目的&lt;/h4&gt;为了推进这一领域的研究，本文引入了SIV-Bench，旨在严格评估多模态大型语言模型（MLLMs）的能力。&lt;h4&gt;方法&lt;/h4&gt;SIV-Bench包含2,792个视频片段和8,792个由人机协同生成的问答对，数据来源于TikTok和YouTube，覆盖了广泛的视频类型、呈现风格、语言和文化背景。还包括一个用于分析不同文本线索影响的分析设置。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，模型在社交场景理解（SSU）方面表现良好，但在社交状态推理（SSR）和社交动态预测（SDP）方面存在显著困难，其中关系推理（RI）是一个瓶颈。此外，转录对话在理解复杂社交互动方面发挥了关键作用。&lt;h4&gt;结论&lt;/h4&gt;SIV-Bench通过系统地识别当前MLLMs的优势和局限性，为更智能的AI发展提供了关键见解。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了SIV-Bench，这是一个用于严格评估多模态大型语言模型（MLLMs）在社交场景理解（SSU）、社交状态推理（SSR）和社交动态预测（SDP）方面能力的视频基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rich and multifaceted nature of human social interaction, encompassingmultimodal cues, unobservable relations and mental states, and dynamicalbehavior, presents a formidable challenge for artificial intelligence. Toadvance research in this area, we introduce SIV-Bench, a novel video benchmarkfor rigorously evaluating the capabilities of Multimodal Large Language Models(MLLMs) across Social Scene Understanding (SSU), Social State Reasoning (SSR),and Social Dynamics Prediction (SDP). SIV-Bench features 2,792 video clips and8,792 meticulously generated question-answer pairs derived from a human-LLMcollaborative pipeline. It is originally collected from TikTok and YouTube,covering a wide range of video genres, presentation styles, and linguistic andcultural backgrounds. It also includes a dedicated setup for analyzing theimpact of different textual cues-original on-screen text, added dialogue, or notext. Our comprehensive experiments on leading MLLMs reveal that while modelsadeptly handle SSU, they significantly struggle with SSR and SDP, whereRelation Inference (RI) is an acute bottleneck, as further examined in ouranalysis. Our study also confirms the critical role of transcribed dialogue inaiding comprehension of complex social interactions. By systematicallyidentifying current MLLMs' strengths and limitations, SIV-Bench offers crucialinsights to steer the development of more socially intelligent AI. The datasetand code are available at https://kfq20.github.io/sivbench/.</description>
      <author>example@mail.com (Fanqi Kong, Weiqin Zu, Xinyu Chen, Yaodong Yang, Song-Chun Zhu, Xue Feng)</author>
      <guid isPermaLink="false">2506.05425v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Mixture-of-Experts Meets In-Context Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.05426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为T2MIR的创新框架，用于解决在上下文强化学习（ICRL）中的多模态数据和决策任务异质性挑战，通过引入混合专家（MoE）架构和对比学习方法，显著提升了ICRL的性能。&lt;h4&gt;背景&lt;/h4&gt;在上下文强化学习（ICRL）中，将强化学习代理适应下游任务面临两个主要挑战：状态-动作-奖励数据的内在多模态性和决策任务的多样性和异质性。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为T2MIR的框架，以解决上述挑战，并提升ICRL的性能。&lt;h4&gt;方法&lt;/h4&gt;T2MIR框架引入了MoE架构到基于transformer的决策模型中，包括：1. 替换前馈层为两个并行层：一个token-wise MoE，用于捕捉不同模态输入token的语义；一个task-wise MoE，用于将不同任务路由到专门的专家，以管理广泛的任务分布并减轻梯度冲突。2. 引入对比学习方法，最大化任务与其路由表示之间的互信息，以更精确地捕获任务相关信息。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，T2MIR显著提高了ICRL的学习能力，并优于多种基线方法。&lt;h4&gt;结论&lt;/h4&gt;T2MIR为ICRL带来了MoE的潜力和前景，提供了一种简单且可扩展的架构增强，使ICRL更接近语言和视觉社区的研究成果。&lt;h4&gt;翻译&lt;/h4&gt;In-context reinforcement learning (ICRL) has emerged as a promising paradigm for adapting RL agents to downstream tasks through prompt conditioning. However, two notable challenges remain in fully harnessing in-context learning within RL domains: the intrinsic multi-modality of the state-action-reward data and the diverse, heterogeneous nature of decision tasks. To tackle these challenges, we propose T2MIR (Token- and Task-wise MoE for In-context RL), an innovative framework that introduces architectural advances of mixture-of-experts (MoE) into transformer-based decision models. T2MIR substitutes the feedforward layer with two parallel layers: a token-wise MoE that captures distinct semantics of input tokens across multiple modalities, and a task-wise MoE that routes diverse tasks to specialized experts for managing a broad task distribution with alleviated gradient conflicts. To enhance task-wise routing, we introduce a contrastive learning method that maximizes the mutual information between the task and its router representation, enabling more precise capture of task-relevant information. The outputs of two MoE components are concatenated and fed into the next layer. Comprehensive experiments show that T2MIR significantly facilitates in-context learning capacity and outperforms various types of baselines. We bring the potential and promise of MoE to ICRL, offering a simple and scalable architectural enhancement to advance ICRL one step closer toward achievements in language and vision communities. Our code is available at https://github.com/NJU-RL/T2MIR.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In-context reinforcement learning (ICRL) has emerged as a promising paradigmfor adapting RL agents to downstream tasks through prompt conditioning.However, two notable challenges remain in fully harnessing in-context learningwithin RL domains: the intrinsic multi-modality of the state-action-reward dataand the diverse, heterogeneous nature of decision tasks. To tackle thesechallenges, we propose \textbf{T2MIR} (\textbf{T}oken- and \textbf{T}ask-wise\textbf{M}oE for \textbf{I}n-context \textbf{R}L), an innovative framework thatintroduces architectural advances of mixture-of-experts (MoE) intotransformer-based decision models. T2MIR substitutes the feedforward layer withtwo parallel layers: a token-wise MoE that captures distinct semantics of inputtokens across multiple modalities, and a task-wise MoE that routes diversetasks to specialized experts for managing a broad task distribution withalleviated gradient conflicts. To enhance task-wise routing, we introduce acontrastive learning method that maximizes the mutual information between thetask and its router representation, enabling more precise capture oftask-relevant information. The outputs of two MoE components are concatenatedand fed into the next layer. Comprehensive experiments show that T2MIRsignificantly facilitates in-context learning capacity and outperforms varioustypes of baselines. We bring the potential and promise of MoE to ICRL, offeringa simple and scalable architectural enhancement to advance ICRL one step closertoward achievements in language and vision communities. Our code is availableat https://github.com/NJU-RL/T2MIR.</description>
      <author>example@mail.com (Wenhao Wu, Fuhong Liu, Haoru Li, Zican Hu, Daoyi Dong, Chunlin Chen, Zhi Wang)</author>
      <guid isPermaLink="false">2506.05426v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Spatial Language Maps for Robot Navigation and Manipulation</title>
      <link>http://arxiv.org/abs/2506.06862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted to International Journal of Robotics Research (IJRR). 24  pages, 18 figures. The paper contains texts from VLMaps(arXiv:2210.05714) and  AVLMaps(arXiv:2303.07522). The project page is https://mslmaps.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为多模态空间语言地图的新方法，该方法通过融合预训练的多模态特征与环境的三维重建来提高导航代理的观察与对象或事件描述之间的匹配。&lt;h4&gt;背景&lt;/h4&gt;现有的方法与环境地图脱节，缺乏几何地图的空间精确性，或忽略了除视觉之外的额外模态信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够融合预训练的多模态特征与环境三维重建的空间地图表示，以解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;使用标准探索自主构建这些地图，并创建了两种地图实例：视觉语言地图（VLMaps）和扩展的音频视觉语言地图（AVLMaps），通过添加音频信息获得。&lt;h4&gt;主要发现&lt;/h4&gt;VLMaps可以将自然语言命令直接转换为地图中定位的开放词汇空间目标，并能跨不同机器人实体共享以生成定制的障碍物地图。AVLMaps通过融合来自预训练的多模态基础模型的特征，引入了统一的3D空间表示，集成了音频、视觉和语言线索。这些地图使机器人能够将多模态目标查询（如文本、图像或音频片段）定位到空间位置进行导航，并在模糊环境中显著提高目标区分度。&lt;h4&gt;结论&lt;/h4&gt;在模拟和现实世界的实验中，多模态空间语言地图实现了零样本空间和多模态目标导航，在模糊场景中的召回率提高了50%，这些能力适用于移动机器人和桌面操作器，支持由视觉、音频和空间线索引导的导航和交互。&lt;h4&gt;翻译&lt;/h4&gt;Grounding language to a navigating agent's observations can leverage pretrained multimodal foundation models to match perceptions to object or event descriptions. However, previous approaches remain disconnected from environment mapping, lack the spatial precision of geometric maps, or neglect additional modality information beyond vision. To address this, we propose multimodal spatial language maps as a spatial map representation that fuses pretrained multimodal features with a 3D reconstruction of the environment. We build these maps autonomously using standard exploration. We present two instances of our maps, which are visual-language maps (VLMaps) and their extension to audio-visual-language maps (AVLMaps) obtained by adding audio information. When combined with large language models (LLMs), VLMaps can (i) translate natural language commands into open-vocabulary spatial goals (e.g., 'in between the sofa and TV') directly localized in the map, and (ii) be shared across different robot embodiments to generate tailored obstacle maps on demand. Building upon the capabilities above, AVLMaps extend VLMaps by introducing a unified 3D spatial representation integrating audio, visual, and language cues through the fusion of features from pretrained multimodal foundation models. This enables robots to ground multimodal goal queries (e.g., text, images, or audio snippets) to spatial locations for navigation. Additionally, the incorporation of diverse sensory inputs significantly enhances goal disambiguation in ambiguous environments. Experiments in simulation and real-world settings demonstrate that our multimodal spatial language maps enable zero-shot spatial and multimodal goal navigation and improve recall by 50% in ambiguous scenarios. These capabilities extend to mobile robots and tabletop manipulators, supporting navigation and interaction guided by visual, audio, and spatial cues.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grounding language to a navigating agent's observations can leveragepretrained multimodal foundation models to match perceptions to object or eventdescriptions. However, previous approaches remain disconnected from environmentmapping, lack the spatial precision of geometric maps, or neglect additionalmodality information beyond vision. To address this, we propose multimodalspatial language maps as a spatial map representation that fuses pretrainedmultimodal features with a 3D reconstruction of the environment. We build thesemaps autonomously using standard exploration. We present two instances of ourmaps, which are visual-language maps (VLMaps) and their extension toaudio-visual-language maps (AVLMaps) obtained by adding audio information. Whencombined with large language models (LLMs), VLMaps can (i) translate naturallanguage commands into open-vocabulary spatial goals (e.g., "in between thesofa and TV") directly localized in the map, and (ii) be shared acrossdifferent robot embodiments to generate tailored obstacle maps on demand.Building upon the capabilities above, AVLMaps extend VLMaps by introducing aunified 3D spatial representation integrating audio, visual, and language cuesthrough the fusion of features from pretrained multimodal foundation models.This enables robots to ground multimodal goal queries (e.g., text, images, oraudio snippets) to spatial locations for navigation. Additionally, theincorporation of diverse sensory inputs significantly enhances goaldisambiguation in ambiguous environments. Experiments in simulation andreal-world settings demonstrate that our multimodal spatial language mapsenable zero-shot spatial and multimodal goal navigation and improve recall by50% in ambiguous scenarios. These capabilities extend to mobile robots andtabletop manipulators, supporting navigation and interaction guided by visual,audio, and spatial cues.</description>
      <author>example@mail.com (Chenguang Huang, Oier Mees, Andy Zeng, Wolfram Burgard)</author>
      <guid isPermaLink="false">2506.06862v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>EASG-Bench: Video Q&amp;A Benchmark with Egocentric Action Scene Graphs</title>
      <link>http://arxiv.org/abs/2506.05787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了EASG-Bench，一个用于自摄视频问答的基准，其中的问答对由时空定位的动态场景图生成，该图捕捉了演员、动作和物体之间的复杂关系。&lt;h4&gt;背景&lt;/h4&gt;在自摄视频中，问答系统需要理解场景中的动态关系。&lt;h4&gt;目的&lt;/h4&gt;评估多种语言和视频大型语言模型（video-LLMs）在EASG-Bench上的性能，并识别视频理解领域的研究差距。&lt;h4&gt;方法&lt;/h4&gt;提出了一种系统性的评估框架，并在此基准上评估了多种语言和视频大型语言模型。&lt;h4&gt;主要发现&lt;/h4&gt;观察到了语言和视频大型语言模型之间存在的性能差距，特别是在关注时间顺序的问题上，这表明在长上下文视频理解领域存在研究差距。&lt;h4&gt;结论&lt;/h4&gt;为了促进发现的可重复性和进一步研究的便利，基准和配套代码可在GitHub上获取。&lt;h4&gt;翻译&lt;/h4&gt;We introduce EASG-Bench, a question-answering benchmark for egocentric videos where the question-answering pairs are created from spatio-temporally grounded dynamic scene graphs capturing intricate relationships among actors, actions, and objects. We propose a systematic evaluation framework and evaluate several language-only and video large language models (video-LLMs) on this benchmark. We observe a performance gap in language-only and video-LLMs, especially on questions focusing on temporal ordering, thus identifying a research gap in the area of long-context video understanding. To promote the reproducibility of our findings and facilitate further research, the benchmark and accompanying code are available at the following GitHub page: https://github.com/fpv-iplab/EASG-bench.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce EASG-Bench, a question-answering benchmark for egocentric videoswhere the question-answering pairs are created from spatio-temporally groundeddynamic scene graphs capturing intricate relationships among actors, actions,and objects. We propose a systematic evaluation framework and evaluate severallanguage-only and video large language models (video-LLMs) on this benchmark.We observe a performance gap in language-only and video-LLMs, especially onquestions focusing on temporal ordering, thus identifying a research gap in thearea of long-context video understanding. To promote the reproducibility of ourfindings and facilitate further research, the benchmark and accompanying codeare available at the following GitHub page:https://github.com/fpv-iplab/EASG-bench.</description>
      <author>example@mail.com (Ivan Rodin, Tz-Ying Wu, Kyle Min, Sharath Nittur Sridhar, Antonino Furnari, Subarna Tripathi, Giovanni Maria Farinella)</author>
      <guid isPermaLink="false">2506.05787v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Flow-Attentional Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.06127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为flow attention的新方法，用于改进图神经网络（GNNs）在处理具有物理资源流动（如电力电流或交通流量）的图结构数据时的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的GNNs没有考虑图中与物理资源流动相关的守恒定律，这可能导致模型性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出flow attention以适应现有图注意力机制，以满足基尔霍夫第一定律。&lt;h4&gt;方法&lt;/h4&gt;通过修改图注意力机制，flow attention能够处理具有物理资源流动的图结构数据。&lt;h4&gt;主要发现&lt;/h4&gt;flow attention增强了基于注意力的GNNs在图级分类和回归任务上的性能，并能够区分一些非同构图，这些图在标准注意力机制下无法区分。&lt;h4&gt;结论&lt;/h4&gt;flow attention是一种有效的改进方法，可以提高GNNs在处理具有物理资源流动的图结构数据时的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have become essential for learning from graph-structured data. However, existing GNNs do not consider the conservation law inherent in graphs associated with a flow of physical resources, such as electrical current in power grids or traffic in transportation networks, which can lead to reduced model performance. To address this, we propose flow attention, which adapts existing graph attention mechanisms to satisfy Kirchhoff's first law. Furthermore, we discuss how this modification influences the expressivity and identify sets of non-isomorphic graphs that can be discriminated by flow attention but not by standard attention. Through extensive experiments on two flow graph datasets (electronic circuits and power grids), we demonstrate that flow attention enhances the performance of attention-based GNNs on both graph-level classification and regression tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have become essential for learning fromgraph-structured data. However, existing GNNs do not consider the conservationlaw inherent in graphs associated with a flow of physical resources, such aselectrical current in power grids or traffic in transportation networks, whichcan lead to reduced model performance. To address this, we propose flowattention, which adapts existing graph attention mechanisms to satisfyKirchhoff\'s first law. Furthermore, we discuss how this modificationinfluences the expressivity and identify sets of non-isomorphic graphs that canbe discriminated by flow attention but not by standard attention. Throughextensive experiments on two flow graph datasets (electronic circuits and powergrids), we demonstrate that flow attention enhances the performance ofattention-based GNNs on both graph-level classification and regression tasks.</description>
      <author>example@mail.com (Pascal Plettenberg, Dominik Köhler, Bernhard Sick, Josephine M. Thomas)</author>
      <guid isPermaLink="false">2506.06127v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>EndoARSS: Adapting Spatially-Aware Foundation Model for Efficient Activity Recognition and Semantic Segmentation in Endoscopic Surgery</title>
      <link>http://arxiv.org/abs/2506.06830v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Advanced Intelligent Systems&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EndoARSS的新型多任务学习框架，用于内窥镜手术活动的识别和语义分割，通过提高准确性和鲁棒性来增强内窥镜手术系统的性能。&lt;h4&gt;背景&lt;/h4&gt;内窥镜手术是机器人辅助微创手术的金标准，但在手术场景的复杂性和图像特征混淆的情况下，传统的深度学习模型难以实现理想性能。&lt;h4&gt;目的&lt;/h4&gt;为了解决传统深度学习模型在跨活动干扰问题上的局限性，提出了一种基于多任务学习的框架，以提高整体任务性能。&lt;h4&gt;方法&lt;/h4&gt;EndoARSS框架基于DINOv2基础模型，结合了低秩适应和任务高效共享低秩适配器，引入了空间感知多尺度注意力机制，并创建了三个新的数据集MTLESD、MTLEndovis和MTLEndovis-Gen，用于评估框架的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，EndoARSS在多个基准测试中实现了显著性能提升，与现有模型相比，在准确性和鲁棒性方面均有显著提高。&lt;h4&gt;结论&lt;/h4&gt;EndoARSS有潜力推动AI驱动的内窥镜手术系统的发展，为提高手术安全和效率提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：内镜手术是机器人辅助微创手术的金标准，它为早期疾病检测和精确干预提供了显著优势。然而，手术场景的复杂性，包括不同手术活动场景中的高度可变性和目标与背景之间的混淆图像特征，为手术环境理解带来了挑战。传统的深度学习模型通常难以处理跨活动干扰，导致下游任务性能不佳。为了解决这一局限性，我们探索了多任务学习，它利用任务之间的相关特征来提高整体任务性能。在本文中，我们提出了一种名为EndoARSS的新型多任务学习框架，专门针对内镜手术活动识别和语义分割。基于DINOv2基础模型，我们的方法结合了低秩适应以促进高效的微调，同时引入了任务高效共享低秩适配器以缓解不同任务之间的梯度冲突。此外，我们引入了空间感知多尺度注意力机制，通过实现全局信息的跨空间学习来增强特征表示的区分度。为了评估我们框架的有效性，我们提出了三个新的数据集MTLESD、MTLEndovis和MTLEndovis-Gen，这些数据集针对内镜手术场景定制，并提供了活动识别和语义分割任务的详细注释。大量的实验表明，EndoARSS在多个基准测试中实现了显著的性能，与现有模型相比，在准确性和鲁棒性方面均有显著提高。这些结果强调了EndoARSS在推进AI驱动的内镜手术系统方面的潜力，为提高手术安全和效率提供了有价值的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Endoscopic surgery is the gold standard for robotic-assisted minimallyinvasive surgery, offering significant advantages in early disease detectionand precise interventions. However, the complexity of surgical scenes,characterized by high variability in different surgical activity scenarios andconfused image features between targets and the background, presents challengesfor surgical environment understanding. Traditional deep learning models oftenstruggle with cross-activity interference, leading to suboptimal performance ineach downstream task. To address this limitation, we explore multi-tasklearning, which utilizes the interrelated features between tasks to enhanceoverall task performance. In this paper, we propose EndoARSS, a novelmulti-task learning framework specifically designed for endoscopy surgeryactivity recognition and semantic segmentation. Built upon the DINOv2foundation model, our approach integrates Low-Rank Adaptation to facilitateefficient fine-tuning while incorporating Task Efficient Shared Low-RankAdapters to mitigate gradient conflicts across diverse tasks. Additionally, weintroduce the Spatially-Aware Multi-Scale Attention that enhances featurerepresentation discrimination by enabling cross-spatial learning of globalinformation. In order to evaluate the effectiveness of our framework, wepresent three novel datasets, MTLESD, MTLEndovis and MTLEndovis-Gen, tailoredfor endoscopic surgery scenarios with detailed annotations for both activityrecognition and semantic segmentation tasks. Extensive experiments demonstratethat EndoARSS achieves remarkable performance across multiple benchmarks,significantly improving both accuracy and robustness in comparison to existingmodels. These results underscore the potential of EndoARSS to advance AI-drivenendoscopic surgical systems, offering valuable insights for enhancing surgicalsafety and efficiency.</description>
      <author>example@mail.com (Guankun Wang, Rui Tang, Mengya Xu, Long Bai, Huxin Gao, Hongliang Ren)</author>
      <guid isPermaLink="false">2506.06830v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>LLM-Symbolic Integration for Robust Temporal Tabular Reasoning</title>
      <link>http://arxiv.org/abs/2506.05746v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACL Findings 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了针对时间表问答的挑战，并提出了一种名为TempTabQA-C的数据集和符号中间表示方法，以提高大型语言模型（LLMs）在时间表问答任务中的表现。&lt;h4&gt;背景&lt;/h4&gt;时间表问答对LLMs来说是一个重大挑战，因为需要在对结构化数据的强大推理能力，而传统的提示方法通常不足以应对这种挑战。&lt;h4&gt;目的&lt;/h4&gt;克服传统方法在记忆、对表大小的敏感性和复杂查询性能降低等方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;引入了TempTabQA-C数据集，用于系统性和可控的评估，以及将表格转换为数据库模式的符号中间表示。这种方法允许LLMs生成和执行SQL查询，从而增强泛化能力和减轻偏差。通过结合自适应的少样本提示和上下文定制的示例，该方法实现了更高的鲁棒性、可扩展性和性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在关键挑战方面取得了持续改进，为LLMs进行鲁棒的时间推理设定了新的基准。&lt;h4&gt;结论&lt;/h4&gt;TempTabQA-C数据集和符号中间表示方法能够显著提高LLMs在时间表问答任务中的表现。&lt;h4&gt;翻译&lt;/h4&gt;Temporal tabular question answering presents a significant challenge for Large Language Models (LLMs), requiring robust reasoning over structured data, which is a task where traditional prompting methods often fall short. These methods face challenges such as memorization, sensitivity to table size, and reduced performance on complex queries. To overcome these limitations, we introduce TempTabQA-C, a synthetic dataset designed for systematic and controlled evaluations, alongside a symbolic intermediate representation that transforms tables into database schemas. This structured approach allows LLMs to generate and execute SQL queries, enhancing generalization and mitigating biases. By incorporating adaptive few-shot prompting with contextually tailored examples, our method achieves superior robustness, scalability, and performance. Experimental results consistently highlight improvements across key challenges, setting a new benchmark for robust temporal reasoning with LLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal tabular question answering presents a significant challenge forLarge Language Models (LLMs), requiring robust reasoning over structured data,which is a task where traditional prompting methods often fall short. Thesemethods face challenges such as memorization, sensitivity to table size, andreduced performance on complex queries. To overcome these limitations, weintroduce TempTabQA-C, a synthetic dataset designed for systematic andcontrolled evaluations, alongside a symbolic intermediate representation thattransforms tables into database schemas. This structured approach allows LLMsto generate and execute SQL queries, enhancing generalization and mitigatingbiases. By incorporating adaptive few-shot prompting with contextually tailoredexamples, our method achieves superior robustness, scalability, andperformance. Experimental results consistently highlight improvements acrosskey challenges, setting a new benchmark for robust temporal reasoning withLLMs.</description>
      <author>example@mail.com (Atharv Kulkarni, Kushagra Dixit, Vivek Srikumar, Dan Roth, Vivek Gupta)</author>
      <guid isPermaLink="false">2506.05746v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion-Based Hierarchical Graph Neural Networks for Simulating Nonlinear Solid Mechanics</title>
      <link>http://arxiv.org/abs/2506.06045v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ROBIN的新型学习模拟器，用于在非结构化网格上模拟物理系统，该模拟器通过并行推理方案和分层图神经网络，解决了传统模拟器在捕捉全局现象和长期预测中的局限性。&lt;h4&gt;背景&lt;/h4&gt;基于图的学习模拟器在模拟物理系统方面具有速度和泛化能力的优势，但它们在捕捉全局现象和长期预测方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出ROBIN以解决现有模拟器在模拟物理系统时的局限性，如捕捉全局现象和长期预测中的误差积累。&lt;h4&gt;方法&lt;/h4&gt;ROBIN集成了两个关键创新：(i) 滚动扩散，通过在时间窗口内重叠去噪步骤来分摊基于扩散的细化成本；(ii) 基于代数多重网格粗化的分层图神经网络，实现不同网格分辨率的跨尺度消息传递。&lt;h4&gt;主要发现&lt;/h4&gt;ROBIN在二维和三维固体力学基准测试中表现出色，实现了最先进的精度，并且与标准扩散模拟器相比，推理时间减少了高达一个数量级。&lt;h4&gt;结论&lt;/h4&gt;ROBIN是一种高效且准确的学习模拟器，能够有效地模拟物理系统，特别是在捕捉全局现象和长期预测方面具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;Graph-based learned simulators have emerged as a promising approach for simulating physical systems on unstructured meshes, offering speed and generalization across diverse geometries. However, they often struggle with capturing global phenomena, such as bending or long-range correlations, and suffer from error accumulation over long rollouts due to their reliance on local message passing and direct next-step prediction. We address these limitations by introducing the Rolling Diffusion-Batched Inference Network (ROBIN), a novel learned simulator that integrates two key innovations: (i) Rolling Diffusion, a parallelized inference scheme that amortizes the cost of diffusion-based refinement across physical time steps by overlapping denoising steps across a temporal window. (ii) A Hierarchical Graph Neural Network built on algebraic multigrid coarsening, enabling multiscale message passing across different mesh resolutions. This architecture, implemented via Algebraic-hierarchical Message Passing Networks, captures both fine-scale local dynamics and global structural effects critical for phenomena like beam bending or multi-body contact. We validate ROBIN on challenging 2D and 3D solid mechanics benchmarks involving geometric, material, and contact nonlinearities. ROBIN achieves state-of-the-art accuracy on all tasks, substantially outperforming existing next-step learned simulators while reducing inference time by up to an order of magnitude compared to standard diffusion simulators.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-based learned simulators have emerged as a promising approach forsimulating physical systems on unstructured meshes, offering speed andgeneralization across diverse geometries. However, they often struggle withcapturing global phenomena, such as bending or long-range correlations, andsuffer from error accumulation over long rollouts due to their reliance onlocal message passing and direct next-step prediction. We address theselimitations by introducing the Rolling Diffusion-Batched Inference Network(ROBIN), a novel learned simulator that integrates two key innovations: (i)Rolling Diffusion, a parallelized inference scheme that amortizes the cost ofdiffusion-based refinement across physical time steps by overlapping denoisingsteps across a temporal window. (ii) A Hierarchical Graph Neural Network builton algebraic multigrid coarsening, enabling multiscale message passing acrossdifferent mesh resolutions. This architecture, implemented viaAlgebraic-hierarchical Message Passing Networks, captures both fine-scale localdynamics and global structural effects critical for phenomena like beam bendingor multi-body contact. We validate ROBIN on challenging 2D and 3D solidmechanics benchmarks involving geometric, material, and contact nonlinearities.ROBIN achieves state-of-the-art accuracy on all tasks, substantiallyoutperforming existing next-step learned simulators while reducing inferencetime by up to an order of magnitude compared to standard diffusion simulators.</description>
      <author>example@mail.com (Tobias Würth, Niklas Freymuth, Gerhard Neumann, Luise Kärger)</author>
      <guid isPermaLink="false">2506.06045v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Dream to Generalize: Zero-Shot Model-Based Reinforcement Learning for Unseen Visual Distractions</title>
      <link>http://arxiv.org/abs/2506.05419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AAAI 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Dr. G的新型自监督方法，用于零样本MBRL，以提高模型在视觉干扰下的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;尽管现有的MBRL算法在训练观察中表现良好，但面对观察中的视觉干扰（如云、阴影和光）时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，使模型能够在存在视觉干扰的观察中保持鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;Dr. G使用双重对比学习来训练编码器和世界模型，有效捕捉多视图数据增强中的任务相关特征。此外，还引入了一种当前状态逆动力学模型，帮助世界模型更好地理解时间结构。&lt;h4&gt;主要发现&lt;/h4&gt;Dr. G在简单背景上训练后，在DeepMind Control suite的复杂自然视频背景和Robosuite的随机化环境中测试，性能分别比先前工作提高了117%和14%。&lt;h4&gt;结论&lt;/h4&gt;Dr. G能够提高世界模型对视觉干扰的鲁棒性，并在实际应用中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Model-based reinforcement learning (MBRL) has been used to efficiently solve vision-based control tasks in high-dimensional image observations. Although recent MBRL algorithms perform well in trained observations, they fail when faced with visual distractions in observations. These task-irrelevant distractions (e.g., clouds, shadows, and light) may be constantly present in real-world scenarios. In this study, we propose a novel self-supervised method, Dream to Generalize (Dr. G), for zero-shot MBRL. Dr. G trains its encoder and world model with dual contrastive learning which efficiently captures task-relevant features among multi-view data augmentations. We also introduce a current state inverse dynamics model that helps the world model to better understand the temporal structure. The proposed methods can enhance the robustness of the world model against visual distractions. To evaluate the generalization performance, we first train Dr. G on simple backgrounds and then test it on complex natural video backgrounds in the DeepMind Control suite, and the randomizing environments in Robosuite. Dr. G yields a performance improvement of 117% and 14% over prior works, respectively. Our code is open-sourced and available at https://github.com/JeongsooHa/DrG.git&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model-based reinforcement learning (MBRL) has been used to efficiently solvevision-based control tasks in highdimensional image observations. Althoughrecent MBRL algorithms perform well in trained observations, they fail whenfaced with visual distractions in observations. These task-irrelevantdistractions (e.g., clouds, shadows, and light) may be constantly present inreal-world scenarios. In this study, we propose a novel self-supervised method,Dream to Generalize (Dr. G), for zero-shot MBRL. Dr. G trains its encoder andworld model with dual contrastive learning which efficiently capturestask-relevant features among multi-view data augmentations. We also introduce arecurrent state inverse dynamics model that helps the world model to betterunderstand the temporal structure. The proposed methods can enhance therobustness of the world model against visual distractions. To evaluate thegeneralization performance, we first train Dr. G on simple backgrounds and thentest it on complex natural video backgrounds in the DeepMind Control suite, andthe randomizing environments in Robosuite. Dr. G yields a performanceimprovement of 117% and 14% over prior works, respectively. Our code isopen-sourced and available at https://github.com/JeongsooHa/DrG.git</description>
      <author>example@mail.com (Jeongsoo Ha, Kyungsoo Kim, Yusung Kim)</author>
      <guid isPermaLink="false">2506.05419v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Hi-LSplat: Hierarchical 3D Language Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.06822v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Hi-LSplat的视图一致性的层次语言高斯分层模型，用于3D开放词汇查询，以解决现有3DGS模型中视图不一致性和开放词汇挑战导致的对象和关系描述不一致问题。&lt;h4&gt;背景&lt;/h4&gt;现有的基于3DGS的模型使用视图相关的2D基础模型来细化3D语义，但缺乏统一的3D表示，导致视图不一致。同时，开放词汇挑战导致对象和关系描述的不一致性，阻碍了层次语义理解。&lt;h4&gt;目的&lt;/h4&gt;提出Hi-LSplat模型，以实现视图一致的3D层次语义，并解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;通过构建一个3D层次语义树并使用分层实例聚类将2D特征提升到3D特征，解决由2D语义特征引起的视图不一致问题。此外，引入实例级和部分级的对比损失以捕获全方位的层次语义表示。还构建了两个层次语义数据集以更好地评估模型区分不同语义层级的能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Hi-LSplat在3D开放词汇分割和定位方面具有优越性，其强大的性能在层次语义数据集上突出了其在3D场景中捕捉复杂层次语义的能力。&lt;h4&gt;结论&lt;/h4&gt;Hi-LSplat模型能够有效解决3D开放词汇查询中的视图不一致性和开放词汇挑战，提高了3D语义理解和定位的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling 3D language fields with Gaussian Splatting for open-ended languagequeries has recently garnered increasing attention. However, recent 3DGS-basedmodels leverage view-dependent 2D foundation models to refine 3D semantics butlack a unified 3D representation, leading to view inconsistencies.Additionally, inherent open-vocabulary challenges cause inconsistencies inobject and relational descriptions, impeding hierarchical semanticunderstanding. In this paper, we propose Hi-LSplat, a view-consistentHierarchical Language Gaussian Splatting work for 3D open-vocabulary querying.To achieve view-consistent 3D hierarchical semantics, we first lift 2D featuresto 3D features by constructing a 3D hierarchical semantic tree with layeredinstance clustering, which addresses the view inconsistency issue caused by 2Dsemantic features. Besides, we introduce instance-wise and part-wisecontrastive losses to capture all-sided hierarchical semantic representations.Notably, we construct two hierarchical semantic datasets to better assess themodel's ability to distinguish different semantic levels. Extensive experimentshighlight our method's superiority in 3D open-vocabulary segmentation andlocalization. Its strong performance on hierarchical semantic datasetsunderscores its ability to capture complex hierarchical semantics within 3Dscenes.</description>
      <author>example@mail.com (Chenlu Zhan, Yufei Zhang, Gaoang Wang, Hongwei Wang)</author>
      <guid isPermaLink="false">2506.06822v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>FRAME: Pre-Training Video Feature Representations via Anticipation and Memory</title>
      <link>http://arxiv.org/abs/2506.05543v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为FRAME的视频帧编码器，用于密集视频理解任务，如对象跟踪和语义分割。&lt;h4&gt;背景&lt;/h4&gt;现有的视频编码器在处理密集视频理解任务时存在不足，如缺乏时间感知或性能低于图像编码器。&lt;h4&gt;目的&lt;/h4&gt;提出FRAME以解决现有方法在密集预测任务中的不足，使其能够生成时间一致且空间密集的特征。&lt;h4&gt;方法&lt;/h4&gt;FRAME通过自监督学习，预测当前和未来的DINO补丁特征，从而实现空间精确和时间一致的表现。&lt;h4&gt;主要发现&lt;/h4&gt;FRAME是第一个利用基于图像的模型进行密集预测且在需要精细视觉对应任务上超越它们的视频编码器。&lt;h4&gt;结论&lt;/h4&gt;FRAME在六个密集预测任务上表现优于图像编码器和现有的自监督视频模型，同时保持了紧凑的架构，适用于多种下游应用。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Dense video prediction tasks, such as object tracking and semantic segmentation, require video encoders that generate temporally consistent, spatially dense features for every frame. However, existing approaches fall short: image encoders like DINO or CLIP lack temporal awareness, while video models such as VideoMAE underperform compared to image encoders on dense prediction tasks. We address this gap with FRAME, a self-supervised video frame encoder tailored for dense video understanding. FRAME learns to predict current and future DINO patch features from past and present RGB frames, leading to spatially precise and temporally coherent representations. To our knowledge, FRAME is the first video encoder to leverage image-based models for dense prediction while outperforming them on tasks requiring fine-grained visual correspondence. As an auxiliary capability, FRAME aligns its class token with CLIP's semantic space, supporting language-driven tasks such as video classification. We evaluate FRAME across six dense prediction tasks on seven datasets, where it consistently outperforms image encoders and existing self-supervised video models. Despite its versatility, FRAME maintains a compact architecture suitable for a range of downstream applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dense video prediction tasks, such as object tracking and semanticsegmentation, require video encoders that generate temporally consistent,spatially dense features for every frame. However, existing approaches fallshort: image encoders like DINO or CLIP lack temporal awareness, while videomodels such as VideoMAE underperform compared to image encoders on denseprediction tasks. We address this gap with FRAME, a self-supervised video frameencoder tailored for dense video understanding. FRAME learns to predict currentand future DINO patch features from past and present RGB frames, leading tospatially precise and temporally coherent representations. To our knowledge,FRAME is the first video encoder to leverage image-based models for denseprediction while outperforming them on tasks requiring fine-grained visualcorrespondence. As an auxiliary capability, FRAME aligns its class token withCLIP's semantic space, supporting language-driven tasks such as videoclassification. We evaluate FRAME across six dense prediction tasks on sevendatasets, where it consistently outperforms image encoders and existingself-supervised video models. Despite its versatility, FRAME maintains acompact architecture suitable for a range of downstream applications.</description>
      <author>example@mail.com (Sethuraman TV, Savya Khosla, Vignesh Srinivasakumar, Jiahui Huang, Seoung Wug Oh, Simon Jenni, Derek Hoiem, Joon-Young Lee)</author>
      <guid isPermaLink="false">2506.05543v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>On Measuring Long-Range Interactions in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.05971v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了图神经网络中的长距离图任务问题，提出了一种图操作的范围度量方法，并通过合成实验进行验证。&lt;h4&gt;背景&lt;/h4&gt;长距离图任务，即依赖于远距离节点间交互的任务，是图神经网络研究中的一个开放性问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决长距离图任务问题，论文旨在提出一种更原则性的方法来描述长距离问题。&lt;h4&gt;方法&lt;/h4&gt;论文将长距离交互形式化，引入了图上的操作范围度量，并通过合成实验进行了验证。接着，利用该方法对常用任务和架构进行考察，讨论其长距离能力的实际程度。&lt;h4&gt;主要发现&lt;/h4&gt;论文提出的方法有助于定义和解决图上的长距离问题，并且该范围度量将有助于评估新的数据集和架构。&lt;h4&gt;结论&lt;/h4&gt;论文的研究推进了长距离图任务问题的定义和解决，并为评估新的数据集和架构提供了有价值的工具。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies the long-range graph tasks in graph neural networks, proposes a range measurement method for operators on graphs, and validates it with synthetic experiments. The paper aims to propose a more principled approach to describe the long-range problem. By formalizing long-range interactions in graph tasks, the paper introduces a range measure for operators on graphs and validates it with synthetic experiments. Then, using this measure, the paper examines commonly used tasks and architectures, and discusses the extent to which they are actually long-range. We believe that our work advances efforts to define and address the long-range problem on graphs, and that our range measure will aid the evaluation of new datasets and architectures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-range graph tasks -- those dependent on interactions between distantnodes -- are an open problem in graph neural network research. Real-worldbenchmark tasks, especially the Long Range Graph Benchmark, have become popularfor validating the long-range capability of proposed architectures. However,this is an empirical approach that lacks both robustness and theoreticalunderpinning; a more principled characterization of the long-range problem isrequired. To bridge this gap, we formalize long-range interactions in graphtasks, introduce a range measure for operators on graphs, and validate it withsynthetic experiments. We then leverage our measure to examine commonly usedtasks and architectures, and discuss to what extent they are, in fact,long-range. We believe our work advances efforts to define and address thelong-range problem on graphs, and that our range measure will aid evaluation ofnew datasets and architectures.</description>
      <author>example@mail.com (Jacob Bamberger, Benjamin Gutteridge, Scott le Roux, Michael M. Bronstein, Xiaowen Dong)</author>
      <guid isPermaLink="false">2506.05971v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>StARS DCM: A Sleep Stage-Decoding Forehead EEG Patch for Real-time Modulation of Sleep Physiology</title>
      <link>http://arxiv.org/abs/2506.03442v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;StARS是一个用于实时睡眠监测和干预的模块化软硬件平台。&lt;h4&gt;背景&lt;/h4&gt;睡眠监测和干预技术的研究与应用。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够实时监测和干预睡眠的系统。&lt;h4&gt;方法&lt;/h4&gt;使用DCM生物信号设备和ezmsg实时软件框架同步传感器数据，利用高级神经网络模型和迁移学习进行睡眠阶段解码，支持闭环听觉刺激和动态热调节等干预措施。&lt;h4&gt;主要发现&lt;/h4&gt;StARS可以通过轻量级的脑电图前额贴片或可穿戴设备（如智能戒指）进行配置，提供灵活、低负担的解决方案，同时开源的DCM贴片还允许定制EEG设备开发。&lt;h4&gt;结论&lt;/h4&gt;StARS为脑电图、脑机接口和睡眠增强研究和应用提供了灵活、低负担的解决方案，并促进了EEG设备的定制化开发。&lt;h4&gt;翻译&lt;/h4&gt;The System to Augment Restorative Sleep (StARS) is a modular hardware/software platform designed for real-time sleep monitoring and intervention.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The System to Augment Restorative Sleep (StARS) is a modularhardware/software platform designed for real-time sleep monitoring andintervention. Utilizing the compact DCM biosignal device, StARS captureselectrophysiological signals (EEG, EMG, EOG) and synchronizes sensor data usingthe ezmsg real-time software framework. StARS supports interventions such asclosed-loop auditory stimulation and dynamic thermal modulation guided bysleep-stage decoding via advanced neural network models and transfer learning.Configurable with a lightweight EEG forehead patch or wearable sensors likesmart rings, StARS offers flexible, low-burden solutions for EEG, BCI, andsleep-enhancement research and applications. The open-source DCM patch furtherenables customizable EEG device development.</description>
      <author>example@mail.com (William G. Coon, Preston Peranich, Griffin Milsap)</author>
      <guid isPermaLink="false">2506.03442v2</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Pruning Spurious Subgraphs for Graph Out-of-Distribtuion Generalization</title>
      <link>http://arxiv.org/abs/2506.05957v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submission of ICML2025, with score 4/4/3/3&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于剪枝的图神经网络（GNN）方法PrunE，用于解决训练和测试数据分布偏移下的泛化问题，以改善GNN在现实场景中的应用。&lt;h4&gt;背景&lt;/h4&gt;GNN在训练和测试数据分布偏移的情况下往往会出现性能下降，这限制了其在现实世界中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出PrunE方法，消除虚假边，提高GNN的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;PrunE通过两种正则化项来剪枝虚假边：1）图大小约束排除无信息量的虚假边；2）ε-概率对齐进一步抑制虚假边的出现。&lt;h4&gt;主要发现&lt;/h4&gt;PrunE在理论上分析和大量实验中均显示出比之前最先进方法更优越的泛化性能。&lt;h4&gt;结论&lt;/h4&gt;PrunE通过剪枝虚假边，更全面地保留了不变子图，这对于提高GNN的泛化能力至关重要。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图神经网络（GNNs）在训练和测试数据分布偏移的情况下往往遇到显著的性能下降，这阻碍了它们在现实场景中的应用。最近的研究提出了各种方法来解决分布外泛化挑战，其中许多方法在图领域集中于直接识别一个预测目标标签的不变子图。然而，我们认为直接识别不变子图中的边是具有挑战性和易出错的，特别是在某些虚假边与目标有强相关性时。在本文中，我们提出了PrunE，这是第一个基于剪枝的图OOD方法，旨在消除虚假边以提高OOD泛化能力。通过剪枝虚假边，mine{}更全面地保留了不变子图，这对于OOD泛化至关重要。具体来说，PrunE采用两种正则化项来剪枝虚假边：1）图大小约束排除无信息量的虚假边，2）ε-概率对齐进一步抑制虚假边的出现。通过理论分析和大量实验，我们表明PrunE实现了优于OOD的性能，并且显著优于以前的最先进方法。代码可在https://github.com/tianyao-aka/PrunE-GraphOOD上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) often encounter significant performancedegradation under distribution shifts between training and test data, hinderingtheir applicability in real-world scenarios. Recent studies have proposedvarious methods to address the out-of-distribution generalization challenge,with many methods in the graph domain focusing on directly identifying aninvariant subgraph that is predictive of the target label. However, we arguethat identifying the edges from the invariant subgraph directly is challengingand error-prone, especially when some spurious edges exhibit strongcorrelations with the targets. In this paper, we propose PrunE, the firstpruning-based graph OOD method that eliminates spurious edges to improve OODgeneralizability. By pruning spurious edges, \mine{} retains the invariantsubgraph more comprehensively, which is critical for OOD generalization.Specifically, PrunE employs two regularization terms to prune spurious edges:1) graph size constraint to exclude uninformative spurious edges, and 2)$\epsilon$-probability alignment to further suppress the occurrence of spuriousedges. Through theoretical analysis and extensive experiments, we show thatPrunE achieves superior OOD performance and outperforms previousstate-of-the-art methods significantly. Codes are available at:\href{https://github.com/tianyao-aka/PrunE-GraphOOD}{https://github.com/tianyao-aka/PrunE-GraphOOD}.</description>
      <author>example@mail.com (Tianjun Yao, Haoxuan Li, Yongqiang Chen, Tongliang Liu, Le Song, Eric Xing, Zhiqiang Shen)</author>
      <guid isPermaLink="false">2506.05957v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Research on Personalized Financial Product Recommendation by Integrating Large Language Models and Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.05873v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合大型语言模型（LLM）和图神经网络（GNN）的混合框架，用于个性化金融产品推荐。&lt;h4&gt;背景&lt;/h4&gt;随着金融科技（fintech）的快速发展，个性化金融产品推荐变得越来越重要。传统的协同过滤或基于内容的模型往往无法捕捉用户的潜在偏好和复杂关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的混合框架，以改进个性化金融产品推荐的准确性。&lt;h4&gt;方法&lt;/h4&gt;该框架使用预训练的LLM将文本数据（如用户评论）编码为丰富的特征向量，同时使用异构用户-产品图来建模交互和社会联系。通过定制的信息传递机制，在GNN中融合文本和图信息，共同优化嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;在公共和真实世界金融数据集上的实验表明，该模型在准确度、召回率和NDCG方面优于单独的LLM或GNN，并且具有强的可解释性。&lt;h4&gt;结论&lt;/h4&gt;该研究为个性化金融推荐和更广泛的推荐任务中的跨模态融合提供了新的见解。&lt;h4&gt;翻译&lt;/h4&gt;With the rapid growth of fintech, personalized financial product recommendations have become increasingly important. Traditional methods like collaborative filtering or content-based models often fail to capture users' latent preferences and complex relationships. We propose a hybrid framework integrating large language models (LLMs) and graph neural networks (GNNs). A pre-trained LLM encodes text data (e.g., user reviews) into rich feature vectors, while a heterogeneous user-product graph models interactions and social ties. Through a tailored message-passing mechanism, text and graph information are fused within the GNN to jointly optimize embeddings. Experiments on public and real-world financial datasets show our model outperforms standalone LLM or GNN in accuracy, recall, and NDCG, with strong interpretability. This work offers new insights for personalized financial recommendations and cross-modal fusion in broader recommendation tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid growth of fintech, personalized financial productrecommendations have become increasingly important. Traditional methods likecollaborative filtering or content-based models often fail to capture users'latent preferences and complex relationships. We propose a hybrid frameworkintegrating large language models (LLMs) and graph neural networks (GNNs). Apre-trained LLM encodes text data (e.g., user reviews) into rich featurevectors, while a heterogeneous user-product graph models interactions andsocial ties. Through a tailored message-passing mechanism, text and graphinformation are fused within the GNN to jointly optimize embeddings.Experiments on public and real-world financial datasets show our modeloutperforms standalone LLM or GNN in accuracy, recall, and NDCG, with stronginterpretability. This work offers new insights for personalized financialrecommendations and cross-modal fusion in broader recommendation tasks.</description>
      <author>example@mail.com (Yushang Zhao, Yike Peng, Dannier Li, Yuxin Yang, Chengrui Zhou, Jing Dong)</author>
      <guid isPermaLink="false">2506.05873v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>CR-BLEA: Contrastive Ranking for Adaptive Resource Allocation in Bilevel Evolutionary Algorithms</title>
      <link>http://arxiv.org/abs/2506.06362v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对 bilevel EAs 的新型资源分配框架，旨在提高其效率。&lt;h4&gt;背景&lt;/h4&gt;Bilevel optimization 具有嵌套结构，每个上层候选解都需要解决对应的下层问题，这对计算资源提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;减少资源浪费，提高 bilevel EAs 的效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种对比排名网络，用于在线学习上下层解之间的关系，并据此引导基于引用的排名策略，优先优化任务并自适应控制重采样。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该框架显著降低了计算成本，同时保持了甚至提高了解的准确性。&lt;h4&gt;结论&lt;/h4&gt;该框架为提高 bilevel EAs 的效率提供了一种通用的策略，为更可扩展的 bilevel optimization 开辟了道路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于 bilevel optimization 具有嵌套结构，每个上层候选解都需要解决对应的下层问题，这给计算资源带来了重大挑战。虽然进化算法（EAs）在导航这种复杂景观方面很有效，但它们的高资源需求仍然是一个关键瓶颈——尤其是大量无望的下层任务的冗余评估。尽管在多任务学习和迁移学习方面取得了进展，但资源浪费仍然存在。为了解决这个问题，我们提出了一种新的资源分配框架，用于 bilevel EAs，该框架可以选性地识别和专注于有希望的下层任务。我们的方法的核心是一个对比排名网络，该网络在线学习成对的上层和下层解之间的关系。这种知识指导了基于引用的排名策略，该策略优先优化任务，并根据估计的种群质量自适应控制重采样。在五个最先进的 bilevel 算法上的综合实验表明，我们的框架显著降低了计算成本，同时保持了——甚至提高了——解的准确性。这项工作提供了一种通用的策略来提高 bilevel EAs 的效率，为更可扩展的 bilevel optimization 打开了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bilevel optimization poses a significant computational challenge due to itsnested structure, where each upper-level candidate solution requires solving acorresponding lower-level problem. While evolutionary algorithms (EAs) areeffective at navigating such complex landscapes, their high resource demandsremain a key bottleneck -- particularly the redundant evaluation of numerousunpromising lower-level tasks. Despite recent advances in multitasking andtransfer learning, resource waste persists. To address this issue, we propose anovel resource allocation framework for bilevel EAs that selectively identifiesand focuses on promising lower-level tasks. Central to our approach is acontrastive ranking network that learns relational patterns between pairedupper- and lower-level solutions online. This knowledge guides areference-based ranking strategy that prioritizes tasks for optimization andadaptively controls resampling based on estimated population quality.Comprehensive experiments across five state-of-the-art bilevel algorithms showthat our framework significantly reduces computational cost while preserving --or even enhancing -- solution accuracy. This work offers a generalizablestrategy to improve the efficiency of bilevel EAs, paving the way for morescalable bilevel optimization.</description>
      <author>example@mail.com (Dejun Xu, Jijia Chen, Gary G. Yen, Min Jiang)</author>
      <guid isPermaLink="false">2506.06362v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models via Generative Continual Learning</title>
      <link>http://arxiv.org/abs/2506.06694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MoveGCL的框架，用于训练移动性基础模型，旨在解决移动数据隐私问题和数据孤岛问题。&lt;h4&gt;背景&lt;/h4&gt;移动数据具有隐私敏感性，导致不同机构之间存在数据孤岛，这使得构建类似自然语言处理和计算机视觉领域的通用移动模型具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;开发一个可扩展且保护隐私的框架，通过生成式持续学习训练移动性基础模型。&lt;h4&gt;方法&lt;/h4&gt;MoveGCL通过重新播放从冻结的教师模型生成的合成轨迹，实现去中心化和渐进式模型演变，并通过定制蒸馏策略来减少灾难性遗忘，从而增强知识保留。此外，它还采用了混合专家Transformer和移动感知专家路由机制，以及分层渐进式适应策略来稳定持续更新。&lt;h4&gt;主要发现&lt;/h4&gt;在六个真实世界城市数据集上的实验表明，MoveGCL的性能与联合训练相当，并且显著优于联邦学习基线，同时提供了强大的隐私保护。&lt;h4&gt;结论&lt;/h4&gt;MoveGCL是解锁移动性基础模型的关键步骤，为开放、可扩展且保护隐私的模型开发提供了一个实际蓝图。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为MoveGCL的框架，用于训练移动性基础模型，旨在解决移动数据隐私问题和数据孤岛问题。该框架通过生成式持续学习，实现了去中心化和渐进式模型演变，并通过定制蒸馏策略来减少灾难性遗忘，同时采用了混合专家Transformer和移动感知专家路由机制，以及分层渐进式适应策略来稳定持续更新。在六个真实世界城市数据集上的实验表明，MoveGCL的性能与联合训练相当，并且显著优于联邦学习基线，同时提供了强大的隐私保护。MoveGCL是解锁移动性基础模型的关键步骤，为开放、可扩展且保护隐私的模型开发提供了一个实际蓝图。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have revolutionized fields such as natural languageprocessing and computer vision by enabling general-purpose learning acrossdiverse tasks and datasets. However, building analogous models for humanmobility remains challenging due to the privacy-sensitive nature of mobilitydata and the resulting data silos across institutions. To bridge this gap, wepropose MoveGCL, a scalable and privacy-preserving framework for trainingmobility foundation models via generative continual learning. Without sharingraw data, MoveGCL enables decentralized and progressive model evolution byreplaying synthetic trajectories generated from a frozen teacher model, andreinforces knowledge retention through a tailored distillation strategy thatmitigates catastrophic forgetting. To address the heterogeneity of mobilitypatterns, MoveGCL incorporates a Mixture-of-Experts Transformer with amobility-aware expert routing mechanism, and employs a layer-wise progressiveadaptation strategy to stabilize continual updates. Experiments on sixreal-world urban datasets demonstrate that MoveGCL achieves performancecomparable to joint training and significantly outperforms federated learningbaselines, while offering strong privacy protection. MoveGCL marks a crucialstep toward unlocking foundation models for mobility, offering a practicalblueprint for open, scalable, and privacy-preserving model development in theera of foundation models.</description>
      <author>example@mail.com (Yuan Yuan, Yukun Liu, Chonghua Han, Jie Feng, Yong Li)</author>
      <guid isPermaLink="false">2506.06694v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Transferable Sequential Recommendation with Vanilla Cross-Entropy Loss</title>
      <link>http://arxiv.org/abs/2506.02916v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MMM4Rec的多模态序列推荐框架，用于提高多模态推荐系统的准确性和可迁移性。&lt;h4&gt;背景&lt;/h4&gt;序列推荐系统通过分析用户交互历史来建模用户偏好。尽管多模态序列推荐架构的性能优于传统的基于ID的方法，但现有方法在适应新领域时需要大量微调，导致负迁移效应，成为部署瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多模态序列推荐框架，以降低微调成本并提高推荐准确性。&lt;h4&gt;方法&lt;/h4&gt;MMM4Rec框架结合了状态空间对偶（SSD）的时间衰减特性和时间感知建模设计，动态优先考虑关键模态信息。框架通过共享投影矩阵进行序列级别的跨模态对齐，并使用新设计的交叉SSD模块和双通道傅里叶自适应滤波进行时间融合。&lt;h4&gt;主要发现&lt;/h4&gt;MMM4Rec实现了快速的微调收敛，通过简单的交叉熵损失，显著提高了多模态推荐的准确性，同时保持了强的可迁移性。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的实验，MMM4Rec展现出最先进的性能，相较于现有模型在NDCG@10上提高了31.78%，在迁移到大规模下游数据集时平均收敛速度提高了10倍。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes a novel multi-modal sequential recommendation framework named MMM4Rec to improve the accuracy and transferability of multi-modal recommendation systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential Recommendation (SR) systems model user preferences by analyzinginteraction histories. Although transferable multi-modal SR architecturesdemonstrate superior performance compared to traditional ID-based approaches,current methods incur substantial fine-tuning costs when adapting to newdomains due to complex optimization requirements and negative transfer effects- a significant deployment bottleneck that hinders engineers from efficientlyrepurposing pre-trained models for novel application scenarios with minimaltuning overhead. We propose MMM4Rec (Multi-Modal Mamba for SequentialRecommendation), a novel multi-modal SR framework that incorporates a dedicatedalgebraic constraint mechanism for efficient transfer learning. By combiningState Space Duality (SSD)'s temporal decay properties with a time-awaremodeling design, our model dynamically prioritizes key modality information,overcoming limitations of Transformer-based approaches. The frameworkimplements a constrained two-stage process: (1) sequence-level cross-modalalignment via shared projection matrices, followed by (2) temporal fusion usingour newly designed Cross-SSD module and dual-channel Fourier adaptivefiltering. This architecture maintains semantic consistency while suppressingnoise propagation.MMM4Rec achieves rapid fine-tuning convergence with simplecross-entropy loss, significantly improving multi-modal recommendation accuracywhile maintaining strong transferability. Extensive experiments demonstrateMMM4Rec's state-of-the-art performance, achieving the maximum 31.78% NDCG@10improvement over existing models and exhibiting 10 times faster averageconvergence speed when transferring to large-scale downstream datasets.</description>
      <author>example@mail.com (Hao Fan, Yanrong Hu, Kai Fang, Qingyang Liu, Hongjiu Liu)</author>
      <guid isPermaLink="false">2506.02916v3</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Structured Pruning for Diverse Best-of-N Reasoning Optimization</title>
      <link>http://arxiv.org/abs/2506.03978v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACL Findings 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;模型剪枝在基于transformer的语言模型中，不仅可以实现计算节省，还能增强模型的推理能力。&lt;h4&gt;背景&lt;/h4&gt;模型剪枝传统上被视为一种实现计算节省的手段。&lt;h4&gt;目的&lt;/h4&gt;研究模型剪枝对推理性能的影响，并提出新的对比学习框架。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为SPRINT的新框架，该框架在推理过程中动态选择最优的头和层进行剪枝，并通过对齐问题嵌入和头嵌入来识别剪枝头配置，从而提高推理的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;对某些注意力头的选择性剪枝可以提高推理性能，尤其是在具有挑战性的任务上。&lt;h4&gt;结论&lt;/h4&gt;在MATH500和GSM8K数据集上的实验表明，该方法在推理性能上显著优于传统的best-of-N和随机头选择策略。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we uncover a surprising phenomenon: the selective pruning of certain attention heads leads to improvements in reasoning performance, particularly on challenging tasks. Motivated by this observation, we propose SPRINT, a novel contrastive learning framework that dynamically selects the optimal head and layer to prune during inference. By aligning question embeddings with head embeddings, SPRINT identifies those pruned-head configurations that result in more accurate reasoning. Extensive experiments demonstrate that our method significantly outperforms traditional best-of-$N$ and random head selection strategies on the MATH500 and GSM8K datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model pruning in transformer-based language models, traditionally viewed as ameans of achieving computational savings, can enhance the model's reasoningcapabilities. In this work, we uncover a surprising phenomenon: the selectivepruning of certain attention heads leads to improvements in reasoningperformance, particularly on challenging tasks. Motivated by this observation,we propose SPRINT, a novel contrastive learning framework that dynamicallyselects the optimal head and layer to prune during inference. By aligningquestion embeddings with head embeddings, SPRINT identifies those pruned-headconfigurations that result in more accurate reasoning. Extensive experimentsdemonstrate that our method significantly outperforms traditional best-of-$N$and random head selection strategies on the MATH500 and GSM8K datasets.</description>
      <author>example@mail.com (Hieu Trung Nguyen, Bao Nguyen, Viet Anh Nguyen)</author>
      <guid isPermaLink="false">2506.03978v2</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Models are Good Relational Learners</title>
      <link>http://arxiv.org/abs/2506.05725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Rel-LLM的新架构，用于将大型语言模型（LLMs）应用于关系深度学习（RDL），通过保留数据库中的关系结构来提高LLMs处理和推理复杂实体关系的能力。&lt;h4&gt;背景&lt;/h4&gt;虽然大型语言模型在多个领域表现出色，但它们在关系深度学习领域的应用尚未得到充分探索。现有的方法通过遍历数据库中实体之间的关系，将结构化数据转换为文本文档，但这种基于文本的序列化方法忽略了关键的关系结构，引入了冗余，并且往往超过了标准LLM的上下文长度。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够有效利用LLMs处理结构化数据的方法，同时保留数据库中的关系结构。&lt;h4&gt;方法&lt;/h4&gt;Rel-LLM利用基于图神经网络（GNN）的编码器在检索增强生成（RAG）框架内为LLMs生成结构化关系提示。GNN编码器提取实体周围的局部子图，构建包含相关实体关系和时间依赖性的特征表示。这些表示通过去规范化过程转换为结构化提示，使LLM能够推理关系结构。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量实验，Rel-LLM在关键RDL任务上优于现有方法，提供了一种可扩展且高效的方法来将LLMs与结构化数据源集成。&lt;h4&gt;结论&lt;/h4&gt;Rel-LLM是一种有效的方法，可以整合LLMs和结构化数据源，同时保留数据库中的关系结构，为关系深度学习提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;Large language models (LLMs) have demonstrated remarkable capabilities across various domains, yet their application to relational deep learning (RDL) remains underexplored. Existing approaches adapt LLMs by traversing relational links between entities in a database and converting the structured data into flat text documents. Still, this text-based serialization disregards critical relational structures, introduces redundancy, and often exceeds standard LLM context lengths. We introduce Rel-LLM, a novel architecture that utilizes a graph neural network (GNN)-based encoder to generate structured relational prompts for LLMs within a retrieval-augmented generation (RAG) framework. Unlike traditional text-based serialization approaches, our method preserves the inherent relational structure of databases while enabling LLMs to effectively process and reason over complex entity relationships. Specifically, the GNN encoder extracts a local subgraph around an entity to build feature representations that contain relevant entity relationships and temporal dependencies. These representations are transformed into structured prompts using a denormalization process, effectively allowing the LLM to reason over relational structures. Through extensive experiments, we demonstrate that Rel-LLM outperforms existing methods on key RDL tasks, offering a scalable and efficient approach to integrating LLMs with structured data sources. Code is available at https://github.com/smiles724/Rel-LLM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have demonstrated remarkable capabilities acrossvarious domains, yet their application to relational deep learning (RDL)remains underexplored. Existing approaches adapt LLMs by traversing relationallinks between entities in a database and converting the structured data intoflat text documents. Still, this text-based serialization disregards criticalrelational structures, introduces redundancy, and often exceeds standard LLMcontext lengths. We introduce Rel-LLM, a novel architecture that utilizes agraph neural network (GNN)- based encoder to generate structured relationalprompts for LLMs within a retrieval-augmented generation (RAG) framework.Unlike traditional text-based serialization approaches, our method preservesthe inherent relational structure of databases while enabling LLMs toeffectively process and reason over complex entity relationships. Specifically,the GNN encoder extracts a local subgraph around an entity to build featurerepresentations that contain relevant entity relationships and temporaldependencies. These representations are transformed into structured promptsusing a denormalization process, effectively allowing the LLM to reason overrelational structures. Through extensive experiments, we demonstrate thatRel-LLM outperforms existing methods on key RDL tasks, offering a scalable andefficient approach to integrating LLMs with structured data sources. Code isavailable at https://github.com/smiles724/Rel-LLM.</description>
      <author>example@mail.com (Fang Wu, Vijay Prakash Dwivedi, Jure Leskovec)</author>
      <guid isPermaLink="false">2506.05725v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Topology-aware Neural Flux Prediction Guided by Physics</title>
      <link>http://arxiv.org/abs/2506.05676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于提高图神经网络（GNNs）在处理有向图时对节点信号中高频成分的保留能力。&lt;h4&gt;背景&lt;/h4&gt;GNNs在处理有向图时往往难以保留节点信号中的高频成分，这些成分对于建模流动动态至关重要。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够敏感地捕捉到高频成分的GNN，以捕获详细的拓扑差异。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了1）显式的差异矩阵，用于建模方向梯度，以及2）隐式的物理约束，以确保GNN中的消息传递与自然定律一致。&lt;h4&gt;主要发现&lt;/h4&gt;在两个真实世界有向图数据（水通量网络和城市交通流量网络）上的评估表明，该提议是有效的。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够提高GNN对高频成分的敏感性，从而在建模流动动态方面具有潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) often struggle in preserving high-frequencycomponents of nodal signals when dealing with directed graphs. Such componentsare crucial for modeling flow dynamics, without which a traditional GNN tendsto treat a graph with forward and reverse topologies equal.To make GNNssensitive to those high-frequency components thereby being capable to capturedetailed topological differences, this paper proposes a novel framework thatcombines 1) explicit difference matrices that model directional gradients and2) implicit physical constraints that enforce messages passing within GNNs tobe consistent with natural laws. Evaluations on two real-world directed graphdata, namely, water flux network and urban traffic flow network, demonstratethe effectiveness of our proposal.</description>
      <author>example@mail.com (Haoyang Jiang, Jindong Wang, Xingquan Zhu, Yi He)</author>
      <guid isPermaLink="false">2506.05676v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Sequel-Aware Graph Neural Networks for Sequential Learning</title>
      <link>http://arxiv.org/abs/2506.05625v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于图的方法在推荐系统中的应用，特别是结合时间序列信息，通过实验验证了包含时间序列信息的推荐方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;推荐系统使用用户和物品的高阶嵌入来进行预测，并动态地从邻居中添加协作信号。尽管已经研究了物品间的相关性及其对推荐的影响，但时间序列物品序列在推荐中的有效性研究较少。&lt;h4&gt;目的&lt;/h4&gt;研究时间序列物品序列（继任信息）嵌入结合高阶用户嵌入的效果，并比较其与不考虑继任信息的图推荐系统的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Heterogeneous Sequel-aware Graph Neural Networks（HSAL-GNNs）的方法，并在三个合成数据和三个真实世界数据集上与transformers、图神经网络、自动编码器等算法进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，引入物品序列的序列信息显著提高了推荐的性能。&lt;h4&gt;结论&lt;/h4&gt;时间序列物品序列在推荐系统中具有重要作用，HSAL-GNNs在推荐性能上优于或与不考虑继任信息的图推荐系统相当。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-based recommendation systems use higher-order user and item embeddingsfor next-item predictions. Dynamically adding collaborative signals fromneighbors helps to use similar users' preferences during learning. Whileitem-item correlations and their impact on recommendations have been studied,the efficacy of temporal item sequences for recommendations is much lessexplored. In this paper, we examine temporal item sequence (sequel-aware)embeddings along with higher-order user embeddings and show that sequel-awareGraph Neural Networks have better (or comparable) recommendation performancethan graph-based recommendation systems that do not consider sequelinformation. Extensive empirical results comparing Heterogeneous Sequel-awareGraph Neural Networks (HSAL-GNNs) to other algorithms for sequential learning(such as transformers, graph neural networks, auto-encoders) are presented onthree synthetic and three real-world datasets. Our results indicate that theincorporation of sequence information from items greatly enhancesrecommendations.</description>
      <author>example@mail.com (Anushka Tiwari, Haimonti Dutta, Shahrzad Khanizadeh)</author>
      <guid isPermaLink="false">2506.05625v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Spectral Graph Neural Networks are Incomplete on Graphs with a Simple Spectrum</title>
      <link>http://arxiv.org/abs/2506.05530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages main text&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了如何通过引入光谱特征来增强图神经网络（GNNs）的表达能力，并提出了一种新的方法来提高GNNs在简单光谱图上的表达能力。&lt;h4&gt;背景&lt;/h4&gt;光谱特征被广泛应用于GNNs中以提高其区分非同构图的能力，例如在MPNNs和Graph Transformers中使用图拉普拉斯算子的特征向量进行位置编码。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过引入一个新的表达性层次来评估SGNNs的表达能力，并改进SGNNs在简单光谱图上的表达能力。&lt;h4&gt;方法&lt;/h4&gt;本文采用了一种分类图的方法，通过图的最大特征值多重性来引入SGNNs的表达性层次。此外，本文将旋转等变神经网络应用于图谱设置，提出了一种方法来提高SGNNs的表达能力。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，许多SGNNs在具有不同特征值的图上都是不完整的。通过实验验证了理论上的改进方法，并在MNIST Superpixel数据集上的图像分类实验和ZINC图上的特征向量规范实验中进行了实证验证。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地提高SGNNs在简单光谱图上的表达能力，为GNNs的进一步研究提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spectral features are widely incorporated within Graph Neural Networks (GNNs)to improve their expressive power, or their ability to distinguish amongnon-isomorphic graphs. One popular example is the usage of graph Laplacianeigenvectors for positional encoding in MPNNs and Graph Transformers. Theexpressive power of such Spectrally-enhanced GNNs (SGNNs) is usually evaluatedvia the k-WL graph isomorphism test hierarchy and homomorphism counting. Yet,these frameworks align poorly with the graph spectra, yielding limited insightinto SGNNs' expressive power. We leverage a well-studied paradigm ofclassifying graphs by their largest eigenvalue multiplicity to introduce anexpressivity hierarchy for SGNNs. We then prove that many SGNNs are incompleteeven on graphs with distinct eigenvalues. To mitigate this deficiency, we adaptrotation equivariant neural networks to the graph spectra setting to propose amethod to provably improve SGNNs' expressivity on simple spectrum graphs. Weempirically verify our theoretical claims via an image classificationexperiment on the MNIST Superpixel dataset and eigenvector canonicalization ongraphs from ZINC.</description>
      <author>example@mail.com (Snir Hordan, Maya Bechler-Speicher, Gur Lifshitz, Nadav Dym)</author>
      <guid isPermaLink="false">2506.05530v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Attention-based transformer models for image captioning across languages: An in-depth survey and evaluation</title>
      <link>http://arxiv.org/abs/2506.05399v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 15 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基于注意力的图像字幕生成模型，涵盖了不同语言，并分析了其挑战和局限性。&lt;h4&gt;背景&lt;/h4&gt;图像字幕生成是连接计算机视觉和自然语言处理的一个领域，近年来基于transformer的模型在字幕生成方面取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;全面分析基于注意力的图像字幕生成模型，并探讨其在多语言环境下的应用。&lt;h4&gt;方法&lt;/h4&gt;对基于注意力的图像字幕生成模型进行分类，并探讨基准数据集、评估指标如BLEU、METEOR、CIDEr和ROUGE，以及多语言字幕生成的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;识别出当前模型的关键局限性，包括语义不一致、非英语语言数据稀缺和推理能力限制。&lt;h4&gt;结论&lt;/h4&gt;提出了未来研究方向，如多模态学习、在AI助手、医疗和法医分析中的实时应用。&lt;h4&gt;翻译&lt;/h4&gt;本文综述了基于注意力的图像字幕生成模型，涵盖了不同语言，并分析了其挑战和局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.cosrev.2025.100766&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image captioning involves generating textual descriptions from input images,bridging the gap between computer vision and natural language processing.Recent advancements in transformer-based models have significantly improvedcaption generation by leveraging attention mechanisms for better sceneunderstanding. While various surveys have explored deep learning-basedapproaches for image captioning, few have comprehensively analyzedattention-based transformer models across multiple languages. This surveyreviews attention-based image captioning models, categorizing them intotransformer-based, deep learning-based, and hybrid approaches. It exploresbenchmark datasets, discusses evaluation metrics such as BLEU, METEOR, CIDEr,and ROUGE, and highlights challenges in multilingual captioning. Additionally,this paper identifies key limitations in current models, including semanticinconsistencies, data scarcity in non-English languages, and limitations inreasoning ability. Finally, we outline future research directions, such asmultimodal learning, real-time applications in AI-powered assistants,healthcare, and forensic analysis. This survey serves as a comprehensivereference for researchers aiming to advance the field of attention-based imagecaptioning.</description>
      <author>example@mail.com (Israa A. Albadarneh, Bassam H. Hammo, Omar S. Al-Kadi)</author>
      <guid isPermaLink="false">2506.05399v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Feature-Based Lie Group Transformer for Real-World Applications</title>
      <link>http://arxiv.org/abs/2506.04668v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, the dataset used in this work is  https://drive.google.com/file/d/1RaSWNN2GEyV3zQPeGya4Mr9DDhJ7OMz7/view?usp=sharing&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文主要讨论了表示学习在获取有意义的表示方面的目标，并提出了改进方法以应用于更现实的场景。&lt;h4&gt;背景&lt;/h4&gt;表示学习旨在从无监督的真实世界感官输入中获取有意义的表示，并解释了人类发展的某些方面。&lt;h4&gt;目的&lt;/h4&gt;研究提出了一种新的方法，用于对成对感官输入之间的变化进行分类，并学习满足代数结构约束的转换。&lt;h4&gt;方法&lt;/h4&gt;该方法使用了伽罗瓦代数理论中的群分解，以克服传统表示学习中独立特征轴的假设，并提出了结合特征提取和对象分割的新方法。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，传统的表示学习无法解释条件独立性，且新方法在处理低分辨率图像时存在局限性。&lt;h4&gt;结论&lt;/h4&gt;通过将群分解理论应用于更现实的场景，结合特征提取和对象分割，模型有望更好地理解人类在现实世界中对象识别的发展。&lt;h4&gt;翻译&lt;/h4&gt;The main goal of representation learning is to acquire meaningful representations from real-world sensory inputs without supervision. Representation learning explains some aspects of human development. Various neural network (NN) models have been proposed that acquire empirically good representations. However, the formulation of a good representation has not been established. We recently proposed a method for categorizing changes between a pair of sensory inputs. A unique feature of this approach is that transformations between two sensory inputs are learned to satisfy algebraic structural constraints. Conventional representation learning often assumes that disentangled independent feature axes is a good representation; however, we found that such a representation cannot account for conditional independence. To overcome this problem, we proposed a new method using group decomposition in Galois algebra theory. Although this method is promising for defining a more general representation, it assumes pixel-to-pixel translation without feature extraction, and can only process low-resolution images with no background, which prevents real-world application. In this study, we provide a simple method to apply our group decomposition theory to a more realistic scenario by combining feature extraction and object segmentation. We replace pixel translation with feature translation and formulate object segmentation as grouping features under the same transformation. We validated the proposed method on a practical dataset containing both real-world object and background. We believe that our model will lead to a better understanding of human development of object recognition in the real world.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The main goal of representation learning is to acquire meaningfulrepresentations from real-world sensory inputs without supervision.Representation learning explains some aspects of human development. Variousneural network (NN) models have been proposed that acquire empirically goodrepresentations. However, the formulation of a good representation has not beenestablished. We recently proposed a method for categorizing changes between apair of sensory inputs. A unique feature of this approach is thattransformations between two sensory inputs are learned to satisfy algebraicstructural constraints. Conventional representation learning often assumes thatdisentangled independent feature axes is a good representation; however, wefound that such a representation cannot account for conditional independence.To overcome this problem, we proposed a new method using group decomposition inGalois algebra theory. Although this method is promising for defining a moregeneral representation, it assumes pixel-to-pixel translation without featureextraction, and can only process low-resolution images with no background,which prevents real-world application. In this study, we provide a simplemethod to apply our group decomposition theory to a more realistic scenario bycombining feature extraction and object segmentation. We replace pixeltranslation with feature translation and formulate object segmentation asgrouping features under the same transformation. We validated the proposedmethod on a practical dataset containing both real-world object and background.We believe that our model will lead to a better understanding of humandevelopment of object recognition in the real world.</description>
      <author>example@mail.com (Takayuki Komatsu, Yoshiyuki Ohmura, Kayato Nishitsunoi, Yasuo Kuniyoshi)</author>
      <guid isPermaLink="false">2506.04668v3</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Towards Foundation Model on Temporal Knowledge Graph Reasoning</title>
      <link>http://arxiv.org/abs/2506.06367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种全新的全归纳式时间知识图谱链接预测方法，通过使用正弦位置编码捕捉细粒度时间模式，并利用基于局部和全局时间上下文的消息传递生成自适应实体和关系表示，从而实现模型的无差别时间粒度和时间跨度处理，提高了模型在未见过的知识图谱上的零样本性能。&lt;h4&gt;背景&lt;/h4&gt;现有的时间知识图谱嵌入（TKGE）模型在归纳或半归纳设置中进行链接预测任务，这限制了模型在新领域迁移和泛化到真实世界场景的能力。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有模型在迁移性和泛化能力上的限制，提出了一种全新的全归纳式时间知识图谱链接预测方法。&lt;h4&gt;方法&lt;/h4&gt;模型使用正弦位置编码捕捉细粒度时间模式，并利用消息传递生成自适应实体和关系表示，同时考虑局部和全局时间上下文。&lt;h4&gt;主要发现&lt;/h4&gt;POSTRA模型在未见过的知识图谱上展现出强大的零样本性能，有效推广到新实体、关系和时间戳。&lt;h4&gt;结论&lt;/h4&gt;POSTRA模型为时间知识图谱的基础模型迈出了重要一步，通过单次预训练即可在各种归纳时间推理场景中提高零样本性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel fully-inductive approach for temporal knowledge graph link prediction. The model employs sinusoidal positional encodings to capture fine-grained temporal patterns and generates adaptive entity and relation representations using message passing conditioned on both local and global temporal contexts. The model design is agnostic to temporal granularity and time span, effectively addressing temporal discrepancies across TKGs and facilitating time-aware structural information transfer. As a pretrained, scalable, and transferable model, POSTRA demonstrates strong zero-shot performance on unseen temporal knowledge graphs, effectively generalizing to novel entities, relations, and timestamps. Extensive theoretical analysis and empirical results show that a single pretrained model can improve zero-shot performance on various inductive temporal reasoning scenarios, marking a significant step toward a foundation model for temporal KGs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal Knowledge Graphs (TKGs) store temporal facts with quadruple formats(s, p, o, t). Existing Temporal Knowledge Graph Embedding (TKGE) models performlink prediction tasks in transductive or semi-inductive settings, which meansthe entities, relations, and temporal information in the test graph are fullyor partially observed during training. Such reliance on seen elements duringinference limits the models' ability to transfer to new domains and generalizeto real-world scenarios. A central limitation is the difficulty in learningrepresentations for entities, relations, and timestamps that are transferableand not tied to dataset-specific vocabularies. To overcome these limitations,we introduce the first fully-inductive approach to temporal knowledge graphlink prediction. Our model employs sinusoidal positional encodings to capturefine-grained temporal patterns and generates adaptive entity and relationrepresentations using message passing conditioned on both local and globaltemporal contexts. Our model design is agnostic to temporal granularity andtime span, effectively addressing temporal discrepancies across TKGs andfacilitating time-aware structural information transfer. As a pretrained,scalable, and transferable model, POSTRA demonstrates strong zero-shotperformance on unseen temporal knowledge graphs, effectively generalizing tonovel entities, relations, and timestamps. Extensive theoretical analysis andempirical results show that a single pretrained model can improve zero-shotperformance on various inductive temporal reasoning scenarios, marking asignificant step toward a foundation model for temporal KGs.</description>
      <author>example@mail.com (Jiaxin Pan, Mojtaba Nayyeri, Osama Mohammed, Daniel Hernandez, Rongchuan Zhang, Cheng Cheng, Steffen Staab)</author>
      <guid isPermaLink="false">2506.06367v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>RoPETR: Improving Temporal Camera-Only 3D Detection by Integrating Enhanced Rotary Position Embedding</title>
      <link>http://arxiv.org/abs/2504.12643v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文报告介绍了StreamPETR框架的针对性改进，旨在提高速度估计能力，这对于影响NuScenes检测分数的整体性能是一个关键因素。&lt;h4&gt;背景&lt;/h4&gt;StreamPETR在3D边界框检测方面表现出色，平均精度较高，但分析表明在NuScenes数据集上速度估计是瓶颈。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一限制，提出了一种定制化的位置嵌入策略，以增强时间建模能力。&lt;h4&gt;方法&lt;/h4&gt;在NuScenes测试集上进行了实验评估。&lt;h4&gt;主要发现&lt;/h4&gt;改进的方法使用ViT-L主干网络实现了70.86%的NDS（NuScenes检测分数），达到了相机仅3D物体检测的新基准。&lt;h4&gt;结论&lt;/h4&gt;StreamPETR框架通过改进速度估计能力，在仅使用相机的情况下实现了3D物体检测的新水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report introduces a targeted improvement to the StreamPETRframework, specifically aimed at enhancing velocity estimation, a criticalfactor influencing the overall NuScenes Detection Score. While StreamPETRexhibits strong 3D bounding box detection performance as reflected by its highmean Average Precision our analysis identified velocity estimation as asubstantial bottleneck when evaluated on the NuScenes dataset. To overcome thislimitation, we propose a customized positional embedding strategy tailored toenhance temporal modeling capabilities. Experimental evaluations conducted onthe NuScenes test set demonstrate that our improved approach achieves astate-of-the-art NDS of 70.86% using the ViT-L backbone, setting a newbenchmark for camera-only 3D object detection.</description>
      <author>example@mail.com (Hang Ji, Tao Ni, Xufeng Huang, Zhan Shi, Tao Luo, Xin Zhan, Junbo Chen)</author>
      <guid isPermaLink="false">2504.12643v3</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>$\mathcal{H}$-HIGNN: A Scalable Graph Neural Network Framework with Hierarchical Matrix Acceleration for Simulation of Large-Scale Particulate Suspensions</title>
      <link>http://arxiv.org/abs/2505.08174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种利用图神经网络(GNNs)和分层矩阵(𝜅-矩阵)技术的快速且可扩展的框架，用于模拟大规模颗粒悬浮体系，该体系在科学和工程领域具有广泛的影响。&lt;h4&gt;背景&lt;/h4&gt;大规模颗粒悬浮体系的模拟在科学和工程领域具有广泛的应用，但传统的模拟方法在处理大规模系统时效率较低。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效且可扩展的框架来模拟大规模颗粒悬浮体系。&lt;h4&gt;方法&lt;/h4&gt;该框架基于流体动力相互作用图神经网络(HIGNN)，使用GNN来模拟颗粒在流体动力相互作用(HIs)和外部力作用下的运动张量。同时，将𝜅-矩阵技术集成到HIGNN中，以降低预测成本的规模。&lt;h4&gt;主要发现&lt;/h4&gt;HIGNN能够有效捕捉短程和长程HIs及其多体性质，并通过仅在每个时间步长进行一次前向传递来显著提高计算速度。然而，由于两体HIs的固有缓慢衰减，其整体预测成本呈二次标度，限制了其可扩展性。通过集成𝜅-矩阵技术，将预测成本的标度降低到准线性。&lt;h4&gt;结论&lt;/h4&gt;HIGNN-H矩阵（𝜅-HIGNN）在准确性和可扩展性方面都得到了验证，具有优越的计算效率，且仅需要少量的计算资源，例如，单个中端GPU就足以模拟包含1000万个颗粒的系统。此外，𝜅-HIGNN能够有效地模拟实际相关的大规模颗粒和柔性丝悬浮体系。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种快速且可扩展的框架，利用图神经网络（GNNs）和分层矩阵（𝜅-矩阵）技术，用于模拟大规模颗粒悬浮体系，这在科学和工程领域具有更广泛的影响。该框架基于流体动力相互作用图神经网络（HIGNN），利用GNN模拟颗粒在流体动力相互作用（HIs）和外部力作用下的运动张量。HIGNN具有以下优点：它能够有效地捕捉短程和长程HIs及其多体性质；它通过在每个时间步长仅需要通过其神经网络一次来显著提高计算速度；它通过图连接性和物理相互作用之间的直接对应提供了比黑盒神经网络模型更多的可解释性；并且它在不同系统之间具有可迁移性，无论颗粒的数量、浓度、配置或外部力如何。尽管HIGNN提供了显著的加速，但由于两体HIs的固有缓慢衰减，其整体预测成本的二次标度限制了其可扩展性。为了在所有尺度上实现优越的效率，在本文中，我们将𝜅-矩阵技术集成到HIGNN中，将预测成本的标度降低到准线性。通过综合评估，我们验证了𝜅-HIGNN的准确性，并展示了其准线性的可扩展性和优越的计算效率。它只需要最小的计算资源；例如，单个中端GPU就足以模拟包含1000万个颗粒的系统。最后，我们展示了𝜅-HIGNN有效地模拟实际相关的大规模颗粒和柔性丝悬浮体系的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a fast and scalable framework, leveraging graph neural networks(GNNs) and hierarchical matrix ($\mathcal{H}$-matrix) techniques, forsimulating large-scale particulate suspensions, which have broader impactsacross science and engineering. The framework draws on the HydrodynamicInteraction Graph Neural Network (HIGNN) that employs GNNs to model themobility tensor governing particle motion under hydrodynamic interactions (HIs)and external forces. HIGNN offers several advantages: it effectively capturesboth short- and long-range HIs and their many-body nature; it realizes asubstantial speedup over traditional methodologies, by requiring only a forwardpass through its neural networks at each time step; it provides explainabilitybeyond black-box neural network models, through direct correspondence betweengraph connectivity and physical interactions; and it demonstratestransferability across different systems, irrespective of particles' number,concentration, configuration, or external forces. While HIGNN providessignificant speedup, the quadratic scaling of its overall prediction cost (withrespect to the total number of particles), due to intrinsically slow-decayingtwo-body HIs, limits its scalability. To achieve superior efficiency across allscales, in the present work we integrate $\mathcal{H}$-matrix techniques intoHIGNN, reducing the prediction cost scaling to quasi-linear. Throughcomprehensive evaluations, we validate $\mathcal{H}$-HIGNN's accuracy, anddemonstrate its quasi-linear scalability and superior computational efficiency.It requires only minimal computing resources; for example, a single mid-rangeGPU is sufficient for a system containing 10 million particles. Finally, wedemonstrate $\mathcal{H}$-HIGNN's ability to efficiently simulate practicallyrelevant large-scale suspensions of both particles and flexible filaments.</description>
      <author>example@mail.com (Zhan Ma, Zisheng Ye, Ebrahim Safdarian, Wenxiao Pan)</author>
      <guid isPermaLink="false">2505.08174v1</guid>
      <pubDate>Mon, 09 Jun 2025 14:06:09 +0800</pubDate>
    </item>
  <item>
      <title>How hard is learning to cut? Trade-offs and sample complexity</title>
      <link>http://arxiv.org/abs/2506.00252v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了分支定界算法的数据驱动方法，特别是针对裁剪平面的选择，提出了新的样本复杂度下界，并证明了学习特定裁剪平面选择方法至少需要与学习任何通用目标函数相同的样本量。&lt;h4&gt;背景&lt;/h4&gt;近年来，分支定界算法在不同阶段（如分支或裁剪平面的选择）的决策优化吸引了数据驱动方法的关注。在裁剪平面选择方面，文献中提出了两个评分函数来评估裁剪平面的质量：分支定界树的大小和差距闭合。&lt;h4&gt;目的&lt;/h4&gt;提出新的样本复杂度下界，评估裁剪平面选择方法的学习效果。&lt;h4&gt;方法&lt;/h4&gt;通过对未知分布的实例学习来最小化评分函数，并证明了所需样本量至少与学习任何通用目标函数的样本量相同。&lt;h4&gt;主要发现&lt;/h4&gt;对于广泛类别的映射实例到裁剪平面的函数，学习这些评分函数至少需要与学习通用目标函数相同的样本量。这些结果也适用于从有限裁剪平面集合（如单纯形表中的裁剪平面）学习的情况。&lt;h4&gt;结论&lt;/h4&gt;这些结果构成了学习到裁剪框架的第一个下界，并且与神经网络的情况下的已知上界相比，它们几乎相等。实验结果表明，差距闭合评分是降低分支定界树大小的有效代理，这是首次从理论和计算的角度同时讨论这两个评分函数。&lt;h4&gt;翻译&lt;/h4&gt;在近年来的研究中，分支定界算法成为了数据驱动方法的目标，旨在优化算法的不同阶段（如分支或裁剪平面的选择）的决策。特别是在裁剪平面选择方面，文献中提出了两个评分函数来评估裁剪平面的质量：分支定界树的大小和差距闭合。在本文中，我们提出了适用于这两个评分函数的新样本复杂度下界。我们证明了对于广泛类别的函数，该函数将实例映射到裁剪平面，学习未知分布的实例以最小化这些评分函数至少需要与从相同的类别函数学习任何通用目标函数（使用平方损失）相同的样本量。我们的结果也扩展到从有限裁剪平面集合学习的情况，即单纯形表中的裁剪平面。据我们所知，这些构成了学习到裁剪框架的第一个下界。我们将我们的界限与神经网络情况下的已知上界进行了比较，并表明它们几乎是紧密的。我们使用在集合覆盖和设施定位整数规划模型上评估的图神经网络选择来说明我们的结果，并从经验上证明了差距闭合评分是降低分支定界树大小的有效代理。尽管差距闭合评分在整数规划文献中得到了广泛的应用，但这是首次从理论和计算的角度同时讨论这两个评分函数的原则性分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the recent years, branch-and-cut algorithms have been the target ofdata-driven approaches designed to enhance the decision making in differentphases of the algorithm such as branching, or the choice of cutting planes(cuts). In particular, for cutting plane selection two score functions havebeen proposed in the literature to evaluate the quality of a cut:branch-and-cut tree size and gap closed. In this paper, we present new samplecomplexity lower bounds, valid for both scores. We show that for a wide familyof classes $\mathcal{F}$ that maps an instance to a cut, learning over anunknown distribution of the instances to minimize those scores requires atleast (up to multiplicative constants) as many samples as learning from thesame class function $\mathcal{F}$ any generic target function (using squareloss). Our results also extend to the case of learning from a restricted set ofcuts, namely those from the Simplex tableau. To the best of our knowledge,these constitute the first lower bounds for the learning-to-cut framework. Wecompare our bounds to known upper bounds in the case of neural networks andshow they are nearly tight. We illustrate our results with a graph neuralnetwork selection evaluated on set covering and facility location integerprogramming models and we empirically show that the gap closed score is aneffective proxy to minimize the branch-and-cut tree size. Although the gapclosed score has been extensively used in the integer programming literature,this is the first principled analysis discussing both scores at the same timeboth theoretically and computationally.</description>
      <author>example@mail.com (Sammy Khalife, Andrea Lodi)</author>
      <guid isPermaLink="false">2506.00252v1</guid>
      <pubDate>Mon, 09 Jun 2025 14:06:09 +0800</pubDate>
    </item>
    <item>
      <title>A Driving Regime-Embedded Deep Learning Framework for Modeling Intra-Driver Heterogeneity in Multi-Scale Car-Following Dynamics</title>
      <link>http://arxiv.org/abs/2506.05902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的数据驱动式跟车模型，旨在更准确地捕捉驾驶行为的动态异质性。&lt;h4&gt;背景&lt;/h4&gt;现有模型在处理驾驶行为的异质性方面存在不足，往往强调驾驶员之间的异质性或依赖简化的假设。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一差距，提出了一种新的数据驱动跟车框架，用于系统性地将离散驾驶状态嵌入到车辆运动预测中。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了门控循环单元（GRU）进行离散驾驶状态分类和长短期记忆网络（LSTM）进行连续运动预测，利用高分辨率交通轨迹数据集。&lt;h4&gt;主要发现&lt;/h4&gt;该框架显著减少了加速度、速度和间距指标的预测误差，并能重现关键交通现象，如停车和启动波传播和振荡动力学。&lt;h4&gt;结论&lt;/h4&gt;该框架能够更全面地表示驾驶员之间的异质性和驾驶员内部的动态异质性，提高了跟车模型的预测准确性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的数据驱动跟车模型，旨在更准确地捕捉驾驶行为的动态异质性。现有模型在处理驾驶行为的异质性方面存在不足，往往强调驾驶员之间的异质性或依赖简化的假设。为了解决这一差距，提出了一种新的数据驱动跟车框架，用于系统性地将离散驾驶状态嵌入到车辆运动预测中。该框架结合了门控循环单元（GRU）进行离散驾驶状态分类和长短期记忆网络（LSTM）进行连续运动预测，利用高分辨率交通轨迹数据集。该框架显著减少了加速度、速度和间距指标的预测误差，并能重现关键交通现象，如停车和启动波传播和振荡动力学。该框架能够更全面地表示驾驶员之间的异质性和驾驶员内部的动态异质性，提高了跟车模型的预测准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A fundamental challenge in car-following modeling lies in accuratelyrepresenting the multi-scale complexity of driving behaviors, particularly theintra-driver heterogeneity where a single driver's actions fluctuatedynamically under varying conditions. While existing models, both conventionaland data-driven, address behavioral heterogeneity to some extent, they oftenemphasize inter-driver heterogeneity or rely on simplified assumptions,limiting their ability to capture the dynamic heterogeneity of a single driverunder different driving conditions. To address this gap, we propose a noveldata-driven car-following framework that systematically embeds discrete drivingregimes (e.g., steady-state following, acceleration, cruising) into vehicularmotion predictions. Leveraging high-resolution traffic trajectory datasets, theproposed hybrid deep learning architecture combines Gated Recurrent Units fordiscrete driving regime classification with Long Short-Term Memory networks forcontinuous kinematic prediction, unifying discrete decision-making processesand continuous vehicular dynamics to comprehensively represent inter- andintra-driver heterogeneity. Driving regimes are identified using a bottom-upsegmentation algorithm and Dynamic Time Warping, ensuring robustcharacterization of behavioral states across diverse traffic scenarios.Comparative analyses demonstrate that the framework significantly reducesprediction errors for acceleration (maximum MSE improvement reached 58.47\%),speed, and spacing metrics while reproducing critical traffic phenomena, suchas stop-and-go wave propagation and oscillatory dynamics.</description>
      <author>example@mail.com (Shirui Zhou, Jiying Yan, Junfang Tian, Tao Wang, Yongfu Li, Shiquan Zhong)</author>
      <guid isPermaLink="false">2506.05902v1</guid>
      <pubDate>Mon, 09 Jun 2025 14:06:09 +0800</pubDate>
    </item>
    <item>
      <title>EqCollide: Equivariant and Collision-Aware Deformable Objects Neural Simulator</title>
      <link>http://arxiv.org/abs/2506.05797v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为EqCollide的新方法，用于模拟可变形物体的碰撞。该方法通过引入等变编码器和图神经网络来处理碰撞，提高了模拟的准确性和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;模拟可变形物体的碰撞是一个复杂而具有挑战性的任务，因为需要处理固体力学和多体交互的复杂性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够准确、稳定和可扩展地模拟可变形物体及其碰撞的神经字段模拟器。&lt;h4&gt;方法&lt;/h4&gt;1. 使用等变编码器将物体几何和速度映射到潜在控制点。2. 利用基于图神经网络的等变图神经网络模型通过碰撞感知的消息传递来模拟控制点之间的相互作用。3. 通过查询条件于控制点特征的神经字段来重建速度场。&lt;h4&gt;主要发现&lt;/h4&gt;EqCollide在多种物体配置下实现了准确、稳定和可扩展的模拟，并且相比最好的基线模型，其滚动均方误差（MSE）降低了24.34%到35.82%。此外，模型能够泛化到更多的碰撞物体和更长的时序范围，并且对输入通过群作用变换保持鲁棒。&lt;h4&gt;结论&lt;/h4&gt;EqCollide是一个高效且准确的模拟器，适用于可变形物体及其碰撞的模拟。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulating collisions of deformable objects is a fundamental yet challengingtask due to the complexity of modeling solid mechanics and multi-bodyinteractions. Existing data-driven methods often suffer from lack ofequivariance to physical symmetries, inadequate handling of collisions, andlimited scalability. Here we introduce EqCollide, the first end-to-endequivariant neural fields simulator for deformable objects and theircollisions. We propose an equivariant encoder to map object geometry andvelocity into latent control points. A subsequent equivariant Graph NeuralNetwork-based Neural Ordinary Differential Equation models the interactionsamong control points via collision-aware message passing. To reconstructvelocity fields, we query a neural field conditioned on control point features,enabling continuous and resolution-independent motion predictions. Experimentalresults show that EqCollide achieves accurate, stable, and scalable simulationsacross diverse object configurations, and our model achieves 24.34% to 35.82%lower rollout MSE even compared with the best-performing baseline model.Furthermore, our model could generalize to more colliding objects and extendedtemporal horizons, and stay robust to input transformed with group action.</description>
      <author>example@mail.com (Qianyi Chen, Tianrun Gao, Chenbo Jiang, Tailin Wu)</author>
      <guid isPermaLink="false">2506.05797v1</guid>
      <pubDate>Mon, 09 Jun 2025 14:06:09 +0800</pubDate>
    </item>
    <item>
      <title>SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes</title>
      <link>http://arxiv.org/abs/2506.01558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个名为SAM2-LOVE的新型框架，用于在语言辅助音频视觉场景（LAVS）中实现像素级的场景理解。&lt;h4&gt;背景&lt;/h4&gt;现有的双模态方法由于缺乏第三模态而失败，而现有的三模态方法在时空一致性方面存在问题，导致目标在不同帧之间发生偏移。&lt;h4&gt;目的&lt;/h4&gt;为了提供像素级的场景理解，论文旨在解决LAVS中的音频视觉分割（Ref-AVS）任务。&lt;h4&gt;方法&lt;/h4&gt;SAM2-LOVE框架将文本、音频和视觉表示集成到一个可学习的标记中，以提示和调整SAM2以实现Ref-AVS。该框架包括一个多模态融合模块，旨在提高SAM2的多模态理解，以及标记传播和累积策略，旨在增强时空一致性而不忘记历史信息。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，SAM2-LOVE在Ref-AVS基准测试中比SOTA方法在J&amp;F指标上提高了8.5%，并展示了组件的简单性和有效性。&lt;h4&gt;结论&lt;/h4&gt;SAM2-LOVE是一个有效的框架，可以用于LAVS中的Ref-AVS任务，并提供了比现有方法更好的性能。&lt;h4&gt;翻译&lt;/h4&gt;参考音频视觉分割（Ref-AVS）旨在为语言辅助音频视觉场景（LAVS）提供像素级的场景理解。这项任务要求模型能够持续地对视频中由文本和音频所指的物体进行分割。由于缺乏第三模态，以前的双模态方法总是失败，而现有的三模态方法在时空一致性方面存在问题，导致不同帧的目标偏移。在本工作中，我们介绍了一个新的框架，称为SAM2-LOVE，它将文本、音频和视觉表示集成到一个可学习的标记中，以提示和调整SAM2以实现LAVS中的Ref-AVS。技术上，我们的方法包括一个旨在提高SAM2多模态理解的多模态融合模块，以及旨在增强时空一致性而不忘记历史信息的标记传播和累积策略。我们进行了广泛的实验，以证明SAM2-LOVE在Ref-AVS基准测试中比SOTA方法在J&amp;F指标上提高了8.5%，并展示了组件的简单性和有效性。我们的代码将在这里提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reference Audio-Visual Segmentation (Ref-AVS) aims to provide a pixel-wisescene understanding in Language-aided Audio-Visual Scenes (LAVS). This taskrequires the model to continuously segment objects referred to by text andaudio from a video. Previous dual-modality methods always fail due to the lackof a third modality and the existing triple-modality method struggles withspatio-temporal consistency, leading to the target shift of different frames.In this work, we introduce a novel framework, termed SAM2-LOVE, whichintegrates textual, audio, and visual representations into a learnable token toprompt and align SAM2 for achieving Ref-AVS in the LAVS. Technically, ourapproach includes a multimodal fusion module aimed at improving multimodalunderstanding of SAM2, as well as token propagation and accumulation strategiesdesigned to enhance spatio-temporal consistency without forgetting historicalinformation. We conducted extensive experiments to demonstrate that SAM2-LOVEoutperforms the SOTA by 8.5\% in $\mathcal{J\&amp;F}$ on the Ref-AVS benchmark andshowcase the simplicity and effectiveness of the components. Our code will beavailable here.</description>
      <author>example@mail.com (Yuji Wang, Haoran Xu, Yong Liu, Jiaze Li, Yansong Tang)</author>
      <guid isPermaLink="false">2506.01558v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
  <item>
      <title>Interpretable Multimodal Framework for Human-Centered Street Assessment: Integrating Visual-Language Models for Perceptual Urban Diagnostics</title>
      <link>http://arxiv.org/abs/2506.05087v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一个名为MSEF的新型多模态街道评估框架，融合了视觉变换器和大型语言模型，用于对街道景观进行可解释的双输出评估。&lt;h4&gt;背景&lt;/h4&gt;虽然从图像或GIS中得出的客观街道指标在城市分析中已成为标准，但它们不足以捕捉包容性城市设计所必需的主观感知。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入MSEF框架，提高对街道景观的主观感知评估，并促进包容性城市设计。&lt;h4&gt;方法&lt;/h4&gt;研究利用来自哈尔滨的15000多张标注的街景图像，使用LoRA和P-Tuning v2对框架进行微调，实现了参数高效的适应。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在客观特征上达到了0.84的F1分数，并与居民感知的聚合结果有89.3%的一致性。它还捕捉了与上下文相关的矛盾，如非正式商业既能提高感知活力，同时又降低行人舒适度。&lt;h4&gt;结论&lt;/h4&gt;MSEF不仅提供了城市感知建模的方法论创新，还为寻求在基础设施精确性与生活体验之间取得平衡的规划系统提供了实用价值。&lt;h4&gt;翻译&lt;/h4&gt;While objective street metrics derived from imagery or GIS have becomestandard in urban analytics, they remain insufficient to capture subjectiveperceptions essential to inclusive urban design. This study introduces a novelMultimodal Street Evaluation Framework (MSEF) that fuses a vision transformer(VisualGLM-6B) with a large language model (GPT-4), enabling interpretabledual-output assessment of streetscapes. Leveraging over 15,000 annotatedstreet-view images from Harbin, China, we fine-tune the framework using LoRAand P-Tuning v2 for parameter-efficient adaptation. The model achieves an F1score of 0.84 on objective features and 89.3 percent agreement with aggregatedresident perceptions, validated across stratified socioeconomic geographies. Beyond classification accuracy, MSEF captures context-dependent contradictions: for instance, informal commerce boosts perceived vibrancy while simultaneouslyreducing pedestrian comfort. It also identifies nonlinear and semanticallycontingent patterns -- such as the divergent perceptual effects ofarchitectural transparency across residential and commercial zones -- revealingthe limits of universal spatial heuristics. By generating natural-languagerationales grounded in attention mechanisms, the framework bridges sensory datawith socio-affective inference, enabling transparent diagnostics aligned withSDG 11. This work offers both methodological innovation in urban perceptionmodeling and practical utility for planning systems seeking to reconcileinfrastructural precision with lived experience.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While objective street metrics derived from imagery or GIS have becomestandard in urban analytics, they remain insufficient to capture subjectiveperceptions essential to inclusive urban design. This study introduces a novelMultimodal Street Evaluation Framework (MSEF) that fuses a vision transformer(VisualGLM-6B) with a large language model (GPT-4), enabling interpretabledual-output assessment of streetscapes. Leveraging over 15,000 annotatedstreet-view images from Harbin, China, we fine-tune the framework using LoRAand P-Tuning v2 for parameter-efficient adaptation. The model achieves an F1score of 0.84 on objective features and 89.3 percent agreement with aggregatedresident perceptions, validated across stratified socioeconomic geographies.Beyond classification accuracy, MSEF captures context-dependent contradictions:for instance, informal commerce boosts perceived vibrancy while simultaneouslyreducing pedestrian comfort. It also identifies nonlinear and semanticallycontingent patterns -- such as the divergent perceptual effects ofarchitectural transparency across residential and commercial zones -- revealingthe limits of universal spatial heuristics. By generating natural-languagerationales grounded in attention mechanisms, the framework bridges sensory datawith socio-affective inference, enabling transparent diagnostics aligned withSDG 11. This work offers both methodological innovation in urban perceptionmodeling and practical utility for planning systems seeking to reconcileinfrastructural precision with lived experience.</description>
      <author>example@mail.com (HaoTian Lan)</author>
      <guid isPermaLink="false">2506.05087v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Rectified Point Flow: Generic Point Cloud Pose Estimation</title>
      <link>http://arxiv.org/abs/2506.05282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://rectified-pointflow.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了Rectified Point Flow，这是一种统一的参数化方法，将成对点云配准和多部件形状组装作为一个单一代数生成问题。该方法在未定位的点云上学习了一个连续的点速度场，将噪声点移动到目标位置，从而恢复部件姿态。&lt;h4&gt;背景&lt;/h4&gt;之前的点云配准和多部件形状组装工作通常将问题分为多个部分，并通过特殊的对称性处理方法来解决。&lt;h4&gt;目的&lt;/h4&gt;旨在通过统一的方法解决点云配准和多部件形状组装问题，同时提高配准和组装的准确性。&lt;h4&gt;方法&lt;/h4&gt;学习一个连续的点速度场，将噪声点移动到目标位置，并利用自监督编码器专注于重叠点来提高性能。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在六个基准测试中实现了最先进的性能，这些测试涵盖了成对配准和形状组装。此外，该方法可以有效地在多样数据集上进行联合训练，从而提高准确性。&lt;h4&gt;结论&lt;/h4&gt;Rectified Point Flow方法通过学习共享的几何先验，实现了在成对配准和多部件形状组装任务中的高精度。&lt;h4&gt;翻译&lt;/h4&gt;We introduce Rectified Point Flow, a unified parameterization that formulates pairwise point cloud registration and multi-part shape assembly as a single conditional generative problem. Given unposed point clouds, our method learns a continuous point-wise velocity field that transports noisy points toward their target positions, from which part poses are recovered. In contrast to prior work that regresses part-wise poses with ad-hoc symmetry handling, our method intrinsically learns assembly symmetries without symmetry labels. Together with a self-supervised encoder focused on overlapping points, our method achieves a new state-of-the-art performance on six benchmarks spanning pairwisely registration and shape assembly. Notably, our unified formulation enables effective joint training on diverse datasets, facilitating the learning of shared geometric priors and consequently boosting accuracy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Rectified Point Flow, a unified parameterization that formulatespairwise point cloud registration and multi-part shape assembly as a singleconditional generative problem. Given unposed point clouds, our method learns acontinuous point-wise velocity field that transports noisy points toward theirtarget positions, from which part poses are recovered. In contrast to priorwork that regresses part-wise poses with ad-hoc symmetry handling, our methodintrinsically learns assembly symmetries without symmetry labels. Together witha self-supervised encoder focused on overlapping points, our method achieves anew state-of-the-art performance on six benchmarks spanning pairwiseregistration and shape assembly. Notably, our unified formulation enableseffective joint training on diverse datasets, facilitating the learning ofshared geometric priors and consequently boosting accuracy. Project page:https://rectified-pointflow.github.io/.</description>
      <author>example@mail.com (Tao Sun, Liyuan Zhu, Shengyu Huang, Shuran Song, Iro Armeni)</author>
      <guid isPermaLink="false">2506.05282v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Does Your 3D Encoder Really Work? When Pretrain-SFT from 2D VLMs Meets 3D VLMs</title>
      <link>http://arxiv.org/abs/2506.05318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了将2D视觉语言模型（VLMs）扩展到3D环境以进行3D问答、密集描述和视觉定位等任务的研究进展。通过分析不同类型的3D VLMs，提出了改进3D理解的策略。&lt;h4&gt;背景&lt;/h4&gt;2D VLMs在图像处理方面取得了显著进展，但3D场景的复杂空间结构需要不同的模型架构。&lt;h4&gt;目的&lt;/h4&gt;分析不同类型的3D VLMs，并提出改进3D理解的策略。&lt;h4&gt;方法&lt;/h4&gt;对3D VLMs进行分类，并进行深入分析以理解性能差异。&lt;h4&gt;主要发现&lt;/h4&gt;3D场景中心型VLMs在性能上低于3D对象中心型和基于2D图像的方法；3D场景中心型VLMs对3D场景编码器的依赖有限；数据规模扩大对大数据集的益处不明显；模型过度依赖语言提示和频繁答案分布，导致3D编码器的有效利用降低。&lt;h4&gt;结论&lt;/h4&gt;提出一个新的3D相关性区分QA数据集，旨在破坏捷径学习并提高3D理解；强调在3D VLMs中需要先进的评估和改进策略以实现更好的3D理解。&lt;h4&gt;翻译&lt;/h4&gt;This paper discusses the research progress of extending 2D Vision-Language Models (VLMs) to 3D environments for tasks such as 3D Question Answering, DenseCaptioning, and Visual Grounding. By analyzing different types of 3D VLMs, strategies for improving 3D understanding are proposed.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Remarkable progress in 2D Vision-Language Models (VLMs) has spurred interestin extending them to 3D settings for tasks like 3D Question Answering, DenseCaptioning, and Visual Grounding. Unlike 2D VLMs that typically process imagesthrough an image encoder, 3D scenes, with their intricate spatial structures,allow for diverse model architectures. Based on their encoder design, thispaper categorizes recent 3D VLMs into 3D object-centric, 2D image-based, and 3Dscene-centric approaches. Despite the architectural similarity of 3Dscene-centric VLMs to their 2D counterparts, they have exhibited comparativelylower performance compared with the latest 3D object-centric and 2D image-basedapproaches. To understand this gap, we conduct an in-depth analysis, revealingthat 3D scene-centric VLMs show limited reliance on the 3D scene encoder, andthe pre-train stage appears less effective than in 2D VLMs. Furthermore, weobserve that data scaling benefits are less pronounced on larger datasets. Ourinvestigation suggests that while these models possess cross-modal alignmentcapabilities, they tend to over-rely on linguistic cues and overfit to frequentanswer distributions, thereby diminishing the effective utilization of the 3Dencoder. To address these limitations and encourage genuine 3D sceneunderstanding, we introduce a novel 3D Relevance Discrimination QA datasetdesigned to disrupt shortcut learning and improve 3D understanding. Ourfindings highlight the need for advanced evaluation and improved strategies forbetter 3D understanding in 3D VLMs.</description>
      <author>example@mail.com (Haoyuan Li, Yanpeng Zhou, Yufei Gao, Tao Tang, Jianhua Han, Yujie Yuan, Dave Zhenyu Chen, Jiawang Bian, Hang Xu, Xiaodan Liang)</author>
      <guid isPermaLink="false">2506.05318v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Seeing the Invisible: Machine learning-Based QPI Kernel Extraction via Latent Alignment</title>
      <link>http://arxiv.org/abs/2506.05325v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于人工智能的框架，用于从量子材料中的多散射图像中提取单散射器的Quasiparticle interference (QPI)核。&lt;h4&gt;背景&lt;/h4&gt;Quasiparticle interference (QPI)成像是一种强大的工具，用于探测量子材料的电子结构，但从多散射图像中提取单散射器QPI核是一个基本的逆问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法，以解决从多散射图像中提取单散射器QPI核的难题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种两步学习策略，将核表示学习从观察到的核推理中分离出来。第一步是训练一个变分自动编码器来学习散射核的紧凑潜在空间。第二步是使用专用编码器将QPI观察到的潜在表示与预学习的核对齐。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够在复杂、纠缠的散射条件下稳健地推断核，并且实验结果表明，该方法在提取准确性和泛化到未见过的核方面都取得了显著提高。&lt;h4&gt;结论&lt;/h4&gt;该方法在QPI核提取方面取得了显著进步，为量子材料电子结构的探测提供了新的工具。&lt;h4&gt;翻译&lt;/h4&gt;Quasiparticle interference (QPI) 成像是一种强大的工具，用于探测量子材料的电子结构，但从多散射图像中提取单散射器的 QPI 核仍然是一个基本的逆问题。在本工作中，我们提出了第一个基于人工智能的 QPI 核提取框架。我们引入了一种两步学习策略，将核表示学习从观察到的核推理中分离出来。第一步，我们训练一个变分自动编码器来学习散射核的紧凑潜在空间。第二步，我们使用专用编码器将 QPI 观察到的潜在表示与预学习的核对齐。这种设计使模型能够在复杂、纠缠的散射条件下稳健地推断核。我们构建了一个包含 100 个独特核的多样化和物理上现实的 QPI 数据集，并将我们的方法与直接的一步基线进行了比较。实验结果表明，我们的方法在提取准确性和泛化到未见过的核方面都取得了显著提高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quasiparticle interference (QPI) imaging is a powerful tool for probingelectronic structures in quantum materials, but extracting the single-scattererQPI pattern (i.e., the kernel) from a multi-scatterer image remains afundamentally ill-posed inverse problem. In this work, we propose the firstAI-based framework for QPI kernel extraction. We introduce a two-step learningstrategy that decouples kernel representation learning fromobservation-to-kernel inference. In the first step, we train a variationalautoencoder to learn a compact latent space of scattering kernels. In thesecond step, we align the latent representation of QPI observations with thoseof the pre-learned kernels using a dedicated encoder. This design enables themodel to infer kernels robustly even under complex, entangled scatteringconditions. We construct a diverse and physically realistic QPI datasetcomprising 100 unique kernels and evaluate our method against a direct one-stepbaseline. Experimental results demonstrate that our approach achievessignificantly higher extraction accuracy, and improved generalization to unseenkernels.</description>
      <author>example@mail.com (Yingshuai Ji, Haomin Zhuang, Matthew Toole, James McKenzie, Xiaolong Liu, Xiangliang Zhang)</author>
      <guid isPermaLink="false">2506.05325v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Joint Beamforming and Integer User Association using a GNN with Gumbel-Softmax Reparameterizations</title>
      <link>http://arxiv.org/abs/2506.05241v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的图神经网络（GNN）结构，用于优化多小区无线网络中的波束成形向量和用户关联决策，同时确保关联输出为整数，并通过Gumbel-Softmax（GS）重参数化方法满足整数关联约束，从而在保证整数关联的同时不增加计算复杂度。&lt;h4&gt;背景&lt;/h4&gt;现有的机器学习设计在优化多小区无线网络时，通常需要将整数关联变量近似为概率分布输出。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以联合优化波束成形向量和用户关联，同时保证关联输出为整数。&lt;h4&gt;方法&lt;/h4&gt;使用图神经网络（GNN）结构，结合Gumbel-Softmax（GS）重参数化技术来满足整数关联约束。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，该方法在保证整数关联决策的同时，相比其他分数关联方法，在更大的网络中实现了更高的总速率。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法在优化多小区无线网络时，通过GNN和GS技术，能够有效实现整数关联决策，提高网络的总速率，具有较好的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;Machine learning (ML) models can effectively optimize a multi-cell wireless network by designing the beamforming vectors and association decisions. Existing ML designs, however, often need to approximate the integer association variables with a probability distribution output. We propose a novel graph neural network (GNN) structure that jointly optimizes beamforming vectors and user association while guaranteeing association output as integers. The integer association constraints are satisfied using the Gumbel-Softmax (GS) reparameterization, without increasing computational complexity. Simulation results demonstrate that our proposed GS-based GNN consistently achieves integer association decisions and yields a higher sum-rate, especially when generalized to larger networks, compared to all other fractional association methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning (ML) models can effectively optimize a multi-cell wirelessnetwork by designing the beamforming vectors and association decisions.Existing ML designs, however, often needs to approximate the integerassociation variables with a probability distribution output. We propose anovel graph neural network (GNN) structure that jointly optimize beamformingvectors and user association while guaranteeing association output as integers.The integer association constraints are satisfied using the Gumbel-Softmax (GS)reparameterization, without increasing computational complexity. Simulationresults demonstrate that our proposed GS-based GNN consistently achievesinteger association decisions and yields a higher sum-rate, especially whengeneralized to larger networks, compared to all other fractional associationmethods.</description>
      <author>example@mail.com (Qing Lyu, Mai Vu)</author>
      <guid isPermaLink="false">2506.05241v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Depth Representations for Feed-Forward 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.05327v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://aim-uofa.github.io/PMLoss&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的正则化损失函数PM-Loss，用于解决3D Gaussian Splatting渲染中深度图导致的点云碎片化和稀疏问题，从而提高渲染质量。&lt;h4&gt;背景&lt;/h4&gt;深度图在3D Gaussian Splatting中用于生成新视图，但深度图在物体边界处的不连续性常导致点云碎片化，影响渲染质量。&lt;h4&gt;目的&lt;/h4&gt;提出PM-Loss以解决深度图导致点云碎片化的问题，提高3D Gaussian Splatting的渲染质量。&lt;h4&gt;方法&lt;/h4&gt;使用预训练的transformer预测点图（pointmap），尽管点图可能不如深度图准确，但能有效强制几何平滑，特别是在物体边界附近。&lt;h4&gt;主要发现&lt;/h4&gt;PM-Loss能够有效提高基于深度图的3D Gaussian Splatting渲染质量，并在不同架构和场景中显著改善渲染结果。&lt;h4&gt;结论&lt;/h4&gt;PM-Loss是一种有效的正则化损失函数，可以显著提升3D Gaussian Splatting的渲染效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Depth maps are widely used in feed-forward 3D Gaussian Splatting (3DGS)pipelines by unprojecting them into 3D point clouds for novel view synthesis.This approach offers advantages such as efficient training, the use of knowncamera poses, and accurate geometry estimation. However, depth discontinuitiesat object boundaries often lead to fragmented or sparse point clouds, degradingrendering quality -- a well-known limitation of depth-based representations. Totackle this issue, we introduce PM-Loss, a novel regularization loss based on apointmap predicted by a pre-trained transformer. Although the pointmap itselfmay be less accurate than the depth map, it effectively enforces geometricsmoothness, especially around object boundaries. With the improved depth map,our method significantly improves the feed-forward 3DGS across variousarchitectures and scenes, delivering consistently better rendering results. Ourproject page: https://aim-uofa.github.io/PMLoss</description>
      <author>example@mail.com (Duochao Shi, Weijie Wang, Donny Y. Chen, Zeyu Zhang, Jia-Wang Bian, Bohan Zhuang, Chunhua Shen)</author>
      <guid isPermaLink="false">2506.05327v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>FRED: The Florence RGB-Event Drone Dataset</title>
      <link>http://arxiv.org/abs/2506.05163v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为FRED的新型多模态数据集，旨在解决传统RGB相机在捕捉快速移动物体时的局限性，特别是在挑战性光照条件下。FRED结合了RGB视频和事件流，用于无人机检测、跟踪和轨迹预测。&lt;h4&gt;背景&lt;/h4&gt;小型、快速、轻量级的无人机对传统RGB相机来说存在挑战，因为它们在捕捉快速移动的物体，尤其是在恶劣光照条件下存在局限性。事件相机提供了理想的解决方案，但现有的基准测试往往缺乏精细的时间分辨率或针对无人机特定的运动模式。&lt;h4&gt;目的&lt;/h4&gt;通过创建一个结合RGB视频和事件流的多模态数据集FRED，旨在推动无人机感知和时空理解的研究。&lt;h4&gt;方法&lt;/h4&gt;FRED数据集包含超过7小时的密集标注无人机轨迹，使用5种不同的无人机模型，并包括雨和恶劣光照条件等挑战性场景。提供了详细的评估协议和标准度量，以促进可重复的基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;FRED数据集提供了高时间分辨率和动态范围，有助于无人机检测、跟踪和轨迹预测的研究。&lt;h4&gt;结论&lt;/h4&gt;FRED数据集有望推进高速无人机感知和多模态时空理解的研究。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces the Florence RGB-Event Drone dataset (FRED), a novel multimodal dataset specifically designed for drone detection, tracking, and trajectory forecasting, combining RGB video and event streams. FRED features more than 7 hours of densely annotated drone trajectories, using 5 different drone models and including challenging scenarios such as rain and adverse lighting conditions. We provide detailed evaluation protocols and standard metrics for each task, facilitating reproducible benchmarking. The authors hope FRED will advance research in high-speed drone perception and multimodal spatiotemporal understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Small, fast, and lightweight drones present significant challenges fortraditional RGB cameras due to their limitations in capturing fast-movingobjects, especially under challenging lighting conditions. Event cameras offeran ideal solution, providing high temporal definition and dynamic range, yetexisting benchmarks often lack fine temporal resolution or drone-specificmotion patterns, hindering progress in these areas. This paper introduces theFlorence RGB-Event Drone dataset (FRED), a novel multimodal datasetspecifically designed for drone detection, tracking, and trajectoryforecasting, combining RGB video and event streams. FRED features more than 7hours of densely annotated drone trajectories, using 5 different drone modelsand including challenging scenarios such as rain and adverse lightingconditions. We provide detailed evaluation protocols and standard metrics foreach task, facilitating reproducible benchmarking. The authors hope FRED willadvance research in high-speed drone perception and multimodal spatiotemporalunderstanding.</description>
      <author>example@mail.com (Gabriele Magrini, Niccolò Marini, Federico Becattini, Lorenzo Berlincioni, Niccolò Biondi, Pietro Pala, Alberto Del Bimbo)</author>
      <guid isPermaLink="false">2506.05163v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>From Play to Replay: Composed Video Retrieval for Temporally Fine-Grained Videos</title>
      <link>http://arxiv.org/abs/2506.05274v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TF-CoVR的大规模基准，用于细粒度视频检索，专注于捕捉细微且快速的时间差异，并通过对比学习模型在多个视频片段中检索目标视频。&lt;h4&gt;背景&lt;/h4&gt;现有的CoVR基准主要关注外观变化或粗粒度事件变化，无法捕捉细微的时间差异。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够捕捉细微、快速时间差异的细粒度视频检索基准，并评估相关模型在零样本和微调模式下的性能。&lt;h4&gt;方法&lt;/h4&gt;TF-CoVR基准基于体操和跳水视频，提供180K个三元组。通过提示语言模型来构建每个&lt;查询，修改&gt;对，并与多个有效目标视频相关联。TF-CoVR-Base模型采用两阶段训练框架：预训练视频编码器以获得时间区分性嵌入，然后使用对比学习对齐查询和候选视频。&lt;h4&gt;主要发现&lt;/h4&gt;TF-CoVR-Base在TF-CoVR基准上显著提高了零样本mAP@50和微调后的性能。&lt;h4&gt;结论&lt;/h4&gt;TF-CoVR基准为细粒度视频检索提供了新的挑战和评估标准，TF-CoVR-Base模型在捕捉时间动态方面表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Composed Video Retrieval (CoVR) retrieves a target video given a query videoand a modification text describing the intended change. Existing CoVRbenchmarks emphasize appearance shifts or coarse event changes and therefore donot test the ability to capture subtle, fast-paced temporal differences. Weintroduce TF-CoVR, the first large-scale benchmark dedicated to temporallyfine-grained CoVR. TF-CoVR focuses on gymnastics and diving and provides 180Ktriplets drawn from FineGym and FineDiving. Previous CoVR benchmarks focusingon temporal aspect, link each query to a single target segment taken from thesame video, limiting practical usefulness. In TF-CoVR, we instead constructeach &lt;query, modification&gt; pair by prompting an LLM with the label differencesbetween clips drawn from different videos; every pair is thus associated withmultiple valid target videos (3.9 on average), reflecting real-world tasks suchas sports-highlight generation. To model these temporal dynamics we proposeTF-CoVR-Base, a concise two-stage training framework: (i) pre-train a videoencoder on fine-grained action classification to obtain temporallydiscriminative embeddings; (ii) align the composed query with candidate videosusing contrastive learning. We conduct the first comprehensive study of image,video, and general multimodal embedding (GME) models on temporally fine-grainedcomposed retrieval in both zero-shot and fine-tuning regimes. On TF-CoVR,TF-CoVR-Base improves zero-shot mAP@50 from 5.92 (LanguageBind) to 7.51, andafter fine-tuning raises the state-of-the-art from 19.83 to 25.82.</description>
      <author>example@mail.com (Animesh Gupta, Jay Parmar, Ishan Rajendrakumar Dave, Mubarak Shah)</author>
      <guid isPermaLink="false">2506.05274v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Can Foundation Models Generalise the Presentation Attack Detection Capabilities on ID Cards?</title>
      <link>http://arxiv.org/abs/2506.05263v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在身份证明检测（PAD）领域，如何提高模型在不同国家身份证上的泛化能力，以及如何使用基础模型（FM）来适应这种泛化。&lt;h4&gt;背景&lt;/h4&gt;由于隐私保护的原因，大多数PAD系统只训练在少量身份证件上，导致它们在未知的新身份证国家测试时无法获得具有竞争力的结果。&lt;h4&gt;目的&lt;/h4&gt;旨在提高FM的能力，并评估其如何用于增强PAD的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;使用不同测试协议，包括零样本和微调，以及两个不同的身份证件数据集：一个基于智利身份证的私有数据集和一个基于芬兰、西班牙和斯洛伐克身份证的公开数据集。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果指出，真实图像是泛化的关键。&lt;h4&gt;结论&lt;/h4&gt;FM在提高PAD泛化能力方面具有潜力，特别是当用于处理真实图像时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nowadays, one of the main challenges in presentation attack detection (PAD)on ID cards is obtaining generalisation capabilities for a diversity ofcountries that are issuing ID cards. Most PAD systems are trained on one, two,or three ID documents because of privacy protection concerns. As a result, theydo not obtain competitive results for commercial purposes when tested in anunknown new ID card country. In this scenario, Foundation Models (FM) trainedon huge datasets can help to improve generalisation capabilities. This workintends to improve and benchmark the capabilities of FM and how to use them toadapt the generalisation on PAD of ID Documents. Different test protocols wereused, considering zero-shot and fine-tuning and two different ID card datasets.One private dataset based on Chilean IDs and one open-set based on three IDcountries: Finland, Spain, and Slovakia. Our findings indicate that bona fideimages are the key to generalisation.</description>
      <author>example@mail.com (Juan E. Tapia, Christoph Busch)</author>
      <guid isPermaLink="false">2506.05263v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>FALO: Fast and Accurate LiDAR 3D Object Detection on Resource-Constrained Devices</title>
      <link>http://arxiv.org/abs/2506.04499v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FALO的硬件友好的LiDAR 3D检测方法，该方法在保持高检测精度的同时，实现了快速的推理速度。&lt;h4&gt;背景&lt;/h4&gt;现有的LiDAR 3D检测方法主要依赖于稀疏卷积和/或Transformer，这些方法在资源受限的边缘设备上运行时，由于不规则的内存访问模式和较高的计算成本，可能会遇到挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种既具有高检测精度又具有快速推理速度的LiDAR 3D检测方法。&lt;h4&gt;方法&lt;/h4&gt;FALO首先将3D点云进行体素化，然后将稀疏3D体素根据其坐标和邻近性排列成1D序列。该序列随后通过作者提出的ConvDotMix模块进行处理，该模块包含大核卷积、Hadamard积和线性层。ConvDotMix在空间和嵌入维度上提供了足够的混合能力，并引入了空间特征之间的高阶非线性交互。此外，在通过ConvDotMix层时，引入了隐式分组，以平衡张量维度，提高推理效率，并考虑了感受野的增长。&lt;h4&gt;主要发现&lt;/h4&gt;FALO在nuScenes和Waymo等LiDAR 3D检测基准上实现了具有竞争力的性能，并且在移动GPU和移动NPU上比最新的SOTA方法快1.6~9.8倍。&lt;h4&gt;结论&lt;/h4&gt;FALO是一种在资源受限平台上运行友好的LiDAR 3D检测方法，它可以在紧凑的嵌入式设备上轻松部署，并实现了高性能和快速推理速度的结合。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing LiDAR 3D object detection methods predominantely rely on sparseconvolutions and/or transformers, which can be challenging to run onresource-constrained edge devices, due to irregular memory access patterns andhigh computational costs. In this paper, we propose FALO, a hardware-friendlyapproach to LiDAR 3D detection, which offers both state-of-the-art (SOTA)detection accuracy and fast inference speed. More specifically, given the 3Dpoint cloud and after voxelization, FALO first arranges sparse 3D voxels into a1D sequence based on their coordinates and proximity. The sequence is thenprocessed by our proposed ConvDotMix blocks, consisting of large-kernelconvolutions, Hadamard products, and linear layers. ConvDotMix providessufficient mixing capability in both spatial and embedding dimensions, andintroduces higher-order nonlinear interaction among spatial features.Furthermore, when going through the ConvDotMix layers, we introduce implicitgrouping, which balances the tensor dimensions for more efficient inference andtakes into account the growing receptive field. All these operations arefriendly to run on resource-constrained platforms and proposed FALO can readilydeploy on compact, embedded devices. Our extensive evaluation on LiDAR 3Ddetection benchmarks such as nuScenes and Waymo shows that FALO achievescompetitive performance. Meanwhile, FALO is 1.6~9.8x faster than the latestSOTA on mobile Graphics Processing Unit (GPU) and mobile Neural Processing Unit(NPU).</description>
      <author>example@mail.com (Shizhong Han, Hsin-Pai Cheng, Hong Cai, Jihad Masri, Soyeb Nagori, Fatih Porikli)</author>
      <guid isPermaLink="false">2506.04499v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>DiCoRe: Enhancing Zero-shot Event Detection via Divergent-Convergent LLM Reasoning</title>
      <link>http://arxiv.org/abs/2506.05128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted at ACL ARR May 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DiCoRe是一种用于零样本事件检测的框架，通过Dreamer和Grounder的解耦任务，结合LLM-Judge的验证，在多个数据集上实现了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;零样本事件检测（Zero-shot Event Detection）是理解专业领域文档的关键任务，但由于复杂的事件本体、领域特定触发词的提取和结构化限制，大型语言模型（LLMs）在零样本事件检测中的效用受到限制。&lt;h4&gt;目的&lt;/h4&gt;提出DiCoRe框架，以解决LLMs在零样本事件检测中的局限性。&lt;h4&gt;方法&lt;/h4&gt;DiCoRe采用Dreamer进行发散性推理，通过开放式事件发现来增强事件覆盖；Grounder引入收敛性推理，使用有限状态机引导的约束解码来调整预测与任务特定指令的一致性；LLM-Judge用于验证最终输出以确保高精度。&lt;h4&gt;主要发现&lt;/h4&gt;在五个领域的六个数据集上，DiCoRe在零样本、迁移学习和推理基线中表现优异，平均F1分数比最佳基线高出4-7%。&lt;h4&gt;结论&lt;/h4&gt;DiCoRe是一个强大的零样本事件检测框架，能够显著提升事件检测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Zero-shot Event Detection (ED), the task of identifying event mentions innatural language text without any training data, is critical for documentunderstanding in specialized domains. Understanding the complex event ontology,extracting domain-specific triggers from the passage, and structuring themappropriately overloads and limits the utility of Large Language Models (LLMs)for zero-shot ED. To this end, we propose DiCoRe, a divergent-convergentreasoning framework that decouples the task of ED using Dreamer and Grounder.Dreamer encourages divergent reasoning through open-ended event discovery,which helps to boost event coverage. Conversely, Grounder introduces convergentreasoning to align the free-form predictions with the task-specificinstructions using finite-state machine guided constrained decoding.Additionally, an LLM-Judge verifies the final outputs to ensure high precision.Through extensive experiments on six datasets across five domains and nineLLMs, we demonstrate how DiCoRe consistently outperforms prior zero-shot,transfer-learning, and reasoning baselines, achieving 4-7% average F1 gainsover the best baseline -- establishing DiCoRe as a strong zero-shot EDframework.</description>
      <author>example@mail.com (Tanmay Parekh, Kartik Mehta, Ninareh Mehrabi, Kai-Wei Chang, Nanyun Peng)</author>
      <guid isPermaLink="false">2506.05128v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>AV-Reasoner: Improving and Benchmarking Clue-Grounded Audio-Visual Counting for MLLMs</title>
      <link>http://arxiv.org/abs/2506.05328v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了CG-AV-Counting，一个包含长视频的线索地面计数基准，旨在解决现有机器学习语言模型在计数任务上的困难。&lt;h4&gt;背景&lt;/h4&gt;尽管视频理解取得进展，但当前的多语言语言模型在计数任务上仍存在挑战，现有的基准测试存在视频短、查询集封闭、缺乏线索标注和弱多模态覆盖等问题。&lt;h4&gt;目的&lt;/h4&gt;提出CG-AV-Counting基准，支持黑盒和白盒评估，为端到端和基于推理的计数提供全面的测试平台。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含1,027个多模态问题和5,845个标注线索的基准，并提出AV-Reasoner模型，使用GRPO和课程学习来提高模型的计数能力。&lt;h4&gt;主要发现&lt;/h4&gt;AV-Reasoner在多个基准测试中取得了最先进的成果，证明了强化学习的效果。但实验表明，在域外基准测试中，语言空间中的推理未能带来性能提升。&lt;h4&gt;结论&lt;/h4&gt;CG-AV-Counting基准和AV-Reasoner模型为计数任务提供了新的解决方案，并揭示了强化学习在计数任务中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管在视频理解方面取得了进展，但当前的多语言语言模型在计数任务上仍面临挑战。现有的基准测试受限于短视频、封闭集查询、缺乏线索标注和弱多模态覆盖。在本文中，我们介绍了CG-AV-Counting，一个包含1,027个多模态问题和5,845个标注线索的线索地面计数基准，覆盖了497个长视频。它支持黑盒和白盒评估，作为一个全面的测试平台，用于端到端和基于推理的计数。为了探索提高模型计数能力的方法，我们提出了AV-Reasoner，一个使用GRPO和课程学习训练的模型，以从相关任务中泛化计数能力。AV-Reasoner在多个基准测试中取得了最先进的成果，证明了强化学习的效果。然而，实验表明，在域外基准测试中，语言空间中的推理未能带来性能提升。代码和基准已发布在https://av-reasoner.github.io。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite progress in video understanding, current MLLMs struggle with countingtasks. Existing benchmarks are limited by short videos, close-set queries, lackof clue annotations, and weak multimodal coverage. In this paper, we introduceCG-AV-Counting, a manually-annotated clue-grounded counting benchmark with1,027 multimodal questions and 5,845 annotated clues over 497 long videos. Itsupports both black-box and white-box evaluation, serving as a comprehensivetestbed for both end-to-end and reasoning-based counting. To explore ways toimprove model's counting capability, we propose AV-Reasoner, a model trainedwith GRPO and curriculum learning to generalize counting ability from relatedtasks. AV-Reasoner achieves state-of-the-art results across multiplebenchmarks, demonstrating the effectiveness of reinforcement learning. However,experiments show that on out-of-domain benchmarks, reasoning in the languagespace fails to bring performance gains. The code and benchmark have beenrealeased on https://av-reasoner.github.io.</description>
      <author>example@mail.com (Lidong Lu, Guo Chen, Zhiqi Li, Yicheng Liu, Tong Lu)</author>
      <guid isPermaLink="false">2506.05328v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Towards Language-Augmented Multi-Agent Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.05236v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在多智能体强化学习中，如何通过使智能体基于人类定义的语言来提高学习和协调能力。&lt;h4&gt;背景&lt;/h4&gt;以往的多智能体强化学习研究主要关注从头开始开发的自发通信协议，这些协议往往导致效率低下或不可解释的系统。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过引入人类定义的语言，改善多智能体在具有身体感知的智能体中的学习和协调。&lt;h4&gt;方法&lt;/h4&gt;提出了一种框架，其中智能体不仅被训练来执行动作，还被训练来产生和解释其观察的自然语言描述。这种语言增强的学习具有双重作用：实现智能体之间的明确通信并指导表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;使用本文提出方法训练的智能体在各种任务上优于传统的自发通信基线。分析显示，语言定位导致更丰富的内部表示，更好地泛化到新的合作伙伴，并提高了人机交互能力。&lt;h4&gt;结论&lt;/h4&gt;这些发现证明了将结构化语言集成到多智能体学习中的有效性，并为更可解释和强大的多智能体系统开辟了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Communication is a fundamental aspect of coordinated behavior in multi-agentreinforcement learning. Yet, most prior works in this field have focused onemergent communication protocols developed from scratch, often resulting ininefficient or non-interpretable systems. Inspired by the role of language innatural intelligence, we investigate how grounding agents in a human-definedlanguage can improve learning and coordination of multiple embodied agents. Wepropose a framework in which agents are trained not only to act but also toproduce and interpret natural language descriptions of their observations. Thislanguage-augmented learning serves a dual role: enabling explicit communicationbetween agents and guiding representation learning. We demonstrate that agentstrained with our method outperform traditional emergent communication baselinesacross various tasks. Our analysis reveals that language grounding leads tomore informative internal representations, better generalization to newpartners, and improved capability for human-agent interaction. These findingsdemonstrate the effectiveness of integrating structured language intomulti-agent learning and open avenues for more interpretable and capablemulti-agent systems.</description>
      <author>example@mail.com (Maxime Toquebiau, Jae-Yun Jun, Faïz Benamar, Nicolas Bredeche)</author>
      <guid isPermaLink="false">2506.05236v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Segmentation of Agricultural Vehicles using 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.05009v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新的生成真实合成数据的方法，用于训练神经网络，特别是针对3D点云语义分割任务。该方法通过3D高斯撒点（3DGS）和高斯不透明度场（GOF）生成多种农业车辆的3D资产，并在模拟环境中使用模拟激光雷达生成点云，以降低数据获取和标注的成本。&lt;h4&gt;背景&lt;/h4&gt;训练神经网络进行3D点云语义分割需要大量数据集，但获取和标注真实世界的点云既昂贵又费时。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的数据生成流程，以降低生成真实合成数据所需的高成本和劳动力。&lt;h4&gt;方法&lt;/h4&gt;利用3D高斯撒点（3DGS）和高斯不透明度场（GOF）生成3D资产，并将其放置在模拟环境中，使用模拟激光雷达生成点云，以实现灵活的流程。&lt;h4&gt;主要发现&lt;/h4&gt;使用合成数据训练的PointNet++、Point Transformer V3和OACNN模型表现出色，其中PTv3模型在mIoU指标上达到91.35%，且未在真实数据上训练或验证。此外，在某些场景中，仅使用合成数据训练的模型甚至优于使用真实数据训练的模型。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够生成适用于神经网络训练的合成数据，且在某些情况下，仅使用合成数据训练的模型在性能上优于使用真实数据训练的模型。&lt;h4&gt;翻译&lt;/h4&gt;This study proposes a novel pipeline for generating realistic synthetic data for training neural networks, especially for tasks such as 3D point cloud semantic segmentation. The method utilizes 3D Gaussian Splatting (3DGS) and Gaussian Opacity Fields (GOF) to generate 3D assets of various agricultural vehicles and places them in a simulated environment, where point clouds are generated using a simulated LiDAR, to reduce the costs and labor involved in data acquisition and annotation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training neural networks for tasks such as 3D point cloud semanticsegmentation demands extensive datasets, yet obtaining and annotatingreal-world point clouds is costly and labor-intensive. This work aims tointroduce a novel pipeline for generating realistic synthetic data, byleveraging 3D Gaussian Splatting (3DGS) and Gaussian Opacity Fields (GOF) togenerate 3D assets of multiple different agricultural vehicles instead of usinggeneric models. These assets are placed in a simulated environment, where thepoint clouds are generated using a simulated LiDAR. This is a flexible approachthat allows changing the LiDAR specifications without incurring additionalcosts. We evaluated the impact of synthetic data on segmentation models such asPointNet++, Point Transformer V3, and OACNN, by training and validating themodels only on synthetic data. Remarkably, the PTv3 model had an mIoU of91.35\%, a noteworthy result given that the model had neither been trained norvalidated on any real data. Further studies even suggested that in certainscenarios the models trained only on synthetically generated data performedbetter than models trained on real-world data. Finally, experimentsdemonstrated that the models can generalize across semantic classes, enablingaccurate predictions on mesh models they were never trained on.</description>
      <author>example@mail.com (Alfred T. Christiansen, Andreas H. Højrup, Morten K. Stephansen, Md Ibtihaj A. Sakib, Taman S. Poojary, Filip Slezak, Morten S. Laursen, Thomas B. Moeslund, Joakim B. Haurum)</author>
      <guid isPermaLink="false">2506.05009v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Spatiotemporal Contrastive Learning for Cross-View Video Localization in Unstructured Off-road Terrains</title>
      <link>http://arxiv.org/abs/2506.05250v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为MoViX的自监督跨视图视频定位框架，用于在无GPS的越野环境中进行鲁棒的3自由度定位。&lt;h4&gt;背景&lt;/h4&gt;在无GPS的越野环境中进行3自由度定位具有挑战性，原因包括感知模糊（重复的植被和未结构化的地形）以及季节性变化导致场景外观显著变化。&lt;h4&gt;目的&lt;/h4&gt;MoViX旨在学习视点和季节不变的表达，同时保持方向感知，这对于准确定位至关重要。&lt;h4&gt;方法&lt;/h4&gt;MoViX采用姿势依赖的正样本采样策略来增强方向辨别，以及时间对齐的硬负样本挖掘来避免从季节性线索中快速学习。运动信息帧采样器选择空间上多样的帧，而轻量级时间聚合器强调几何上对齐的观测，同时降低模糊观测的权重。&lt;h4&gt;主要发现&lt;/h4&gt;MoViX在TartanDrive 2.0数据集上进行了评估，在不到30分钟的训练数据和超过12.29公里的测试数据上表现出色，即使是在过时的卫星影像下，MoViX也有93%的时间在25米内定位到真实地面，100%的时间在未知区域内定位在50米内。&lt;h4&gt;结论&lt;/h4&gt;MoViX在未对特定环境进行调优的情况下，优于现有基准，并在一个地理上不同的场地和一个不同的机器人平台上展示了泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Robust cross-view 3-DoF localization in GPS-denied, off-road environmentsremains challenging due to (1) perceptual ambiguities from repetitivevegetation and unstructured terrain, and (2) seasonal shifts that significantlyalter scene appearance, hindering alignment with outdated satellite imagery. Toaddress this, we introduce MoViX, a self-supervised cross-view video localiza-tion framework that learns viewpoint- and season-invariant representations while preserving directional awareness essential for accurate localization. MoViX employs a pose-dependent positive sampling strategy to enhance directional discrimination and temporally aligned hard negative mining to discourage shortcut learning from seasonal cues. A motion-informed frame sampler selects spatially diverse frames, and a lightweight temporal aggregatoremphasizes geometrically aligned observations while downweighting ambiguous ones. At inference, MoViX runs within a Monte Carlo Localization framework, using a learned cross-view matching module in place of handcrafted models. Entropy-guided temperature scaling enables robust multi-hypothesis tracking and confident convergence under visual ambiguity. We evaluate MoViX on the TartanDrive 2.0 dataset, training on under 30 minutes of data and testing over 12.29 km. Despite outdated satellite imagery, MoViX localizes within 25 meters of ground truth 93% of the time, and within 50 meters 100% of the time in unseen regions, outperforming state-of-the-art baselines without environment-specific tuning. We further demonstrate generalization on a real-world off-road dataset from a geographically distinct site with a different robot platform.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust cross-view 3-DoF localization in GPS-denied, off-road environmentsremains challenging due to (1) perceptual ambiguities from repetitivevegetation and unstructured terrain, and (2) seasonal shifts that significantlyalter scene appearance, hindering alignment with outdated satellite imagery. Toaddress this, we introduce MoViX, a self-supervised cross-view videolocalization framework that learns viewpoint- and season-invariantrepresentations while preserving directional awareness essential for accuratelocalization. MoViX employs a pose-dependent positive sampling strategy toenhance directional discrimination and temporally aligned hard negative miningto discourage shortcut learning from seasonal cues. A motion-informed framesampler selects spatially diverse frames, and a lightweight temporal aggregatoremphasizes geometrically aligned observations while downweighting ambiguousones. At inference, MoViX runs within a Monte Carlo Localization framework,using a learned cross-view matching module in place of handcrafted models.Entropy-guided temperature scaling enables robust multi-hypothesis tracking andconfident convergence under visual ambiguity. We evaluate MoViX on theTartanDrive 2.0 dataset, training on under 30 minutes of data and testing over12.29 km. Despite outdated satellite imagery, MoViX localizes within 25 metersof ground truth 93% of the time, and within 50 meters 100% of the time inunseen regions, outperforming state-of-the-art baselines withoutenvironment-specific tuning. We further demonstrate generalization on areal-world off-road dataset from a geographically distinct site with adifferent robot platform.</description>
      <author>example@mail.com (Zhiyun Deng, Dongmyeong Lee, Amanda Adkins, Jesse Quattrociocchi, Christian Ellis, Joydeep Biswas)</author>
      <guid isPermaLink="false">2506.05250v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Towards Vision-Language-Garment Models For Web Knowledge Garment Understanding and Generation</title>
      <link>http://arxiv.org/abs/2506.05210v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at MMFM CVPRW'25, code available at  https://georgenakayama.github.io/AIpparel/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为VLG的视觉-语言-服装模型，该模型可以从文本描述和视觉图像中合成服装，并评估其在未知服装风格和提示下的零样本泛化能力。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型在泛化方面表现出色，但其在服装生成等特定领域的知识迁移能力尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;研究VLG模型在服装生成领域的应用，特别是其将网络规模推理迁移到未见过的服装风格和提示的能力。&lt;h4&gt;方法&lt;/h4&gt;通过实验评估VLG的零样本泛化能力，并探究其在服装设计等特定领域的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;初步结果表明VLG模型在知识迁移方面具有潜力，显示出多模态基础模型在适应特定领域如时尚设计方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;多模态基础模型在特定领域如时尚设计中的适应性是值得进一步研究的方向。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal foundation models have demonstrated strong generalization, yet their ability to transfer knowledge to specialized domains such as garment generation remains underexplored. We introduce VLG, a vision-language-garment model that synthesizes garments from textual descriptions and visual imagery. Our experiments assess VLG's zero-shot generalization, investigating its ability to transfer web-scale reasoning to unseen garment styles and prompts. Preliminary results indicate promising transfer capabilities, highlighting the potential for multimodal foundation models to adapt effectively to specialized domains like fashion design.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal foundation models have demonstrated strong generalization, yettheir ability to transfer knowledge to specialized domains such as garmentgeneration remains underexplored. We introduce VLG, a vision-language-garmentmodel that synthesizes garments from textual descriptions and visual imagery.Our experiments assess VLG's zero-shot generalization, investigating itsability to transfer web-scale reasoning to unseen garment styles and prompts.Preliminary results indicate promising transfer capabilities, highlighting thepotential for multimodal foundation models to adapt effectively to specializeddomains like fashion design.</description>
      <author>example@mail.com (Jan Ackermann, Kiyohiro Nakayama, Guandao Yang, Tong Wu, Gordon Wetzstein)</author>
      <guid isPermaLink="false">2506.05210v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>GEX: Democratizing Dexterity with Fully-Actuated Dexterous Hand and Exoskeleton Glove</title>
      <link>http://arxiv.org/abs/2506.04982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GEX的创新低成本灵巧操作系统，该系统结合了GX11三指类人手（11自由度）和EX12三指外骨骼手套（12自由度），通过运动学重定向形成闭环遥操作框架，实现高保真控制。系统组件采用模块化3D打印手指设计，在保持完全驱动能力的同时，实现了超低制造成本。&lt;h4&gt;背景&lt;/h4&gt;传统的灵巧操作研究存在成本和性能之间的差距。&lt;h4&gt;目的&lt;/h4&gt;提出一种低成本、高性能的灵巧操作系统，以促进具身人工智能和灵巧机器人技能的迁移学习。&lt;h4&gt;方法&lt;/h4&gt;GEX系统采用模块化3D打印手指设计，并集成独立关节电机，实现所有23个自由度的完全驱动，确保完整的状态可观测性和精确的运动学建模。&lt;h4&gt;主要发现&lt;/h4&gt;GEX系统通过全驱动架构实现了精确的双向运动学计算，显著提高了外骨骼和机器人手之间的运动学重定向保真度。&lt;h4&gt;结论&lt;/h4&gt;GEX系统解决了灵巧操作研究中的成本性能差距，为获取高质量演示数据提供了可访问的平台，以推动具身人工智能和灵巧机器人技能的迁移学习。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces GEX, an innovative low-cost dexterous manipulationsystem that combines the GX11 tri-finger anthropomorphic hand (11 DoF) with theEX12 tri-finger exoskeleton glove (12 DoF), forming a closed-loop teleoperationframework through kinematic retargeting for high-fidelity control. Bothcomponents employ modular 3D-printed finger designs, achieving ultra-lowmanufacturing costs while maintaining full actuation capabilities. Departingfrom conventional tendon-driven or underactuated approaches, our electromechanicalsystem integrates independent joint motors across all 23 DoF, ensuring completestate observability and accurate kinematic modeling. This full-actuationarchitecture enables precise bidirectional kinematic calculations, substantiallyenhancing kinematic retargeting fidelity between the exoskeleton and robotic hand. Theproposed system bridges the cost-performance gap in dexterous manipulation research,providing an accessible platform for acquiring high-quality demonstration data toadvance embodied AI and dexterous robotic skill transfer learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces GEX, an innovative low-cost dexterous manipulationsystem that combines the GX11 tri-finger anthropomorphic hand (11 DoF) with theEX12 tri-finger exoskeleton glove (12 DoF), forming a closed-loop teleoperationframework through kinematic retargeting for high-fidelity control. Bothcomponents employ modular 3D-printed finger designs, achieving ultra-lowmanufacturing costs while maintaining full actuation capabilities. Departingfrom conventional tendon-driven or underactuated approaches, ourelectromechanical system integrates independent joint motors across all 23 DoF,ensuring complete state observability and accurate kinematic modeling. Thisfull-actuation architecture enables precise bidirectional kinematiccalculations, substantially enhancing kinematic retargeting fidelity betweenthe exoskeleton and robotic hand. The proposed system bridges thecost-performance gap in dexterous manipulation research, providing anaccessible platform for acquiring high-quality demonstration data to advanceembodied AI and dexterous robotic skill transfer learning.</description>
      <author>example@mail.com (Yunlong Dong, Xing Liu, Jun Wan, Zelin Deng)</author>
      <guid isPermaLink="false">2506.04982v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Through-the-Wall Radar Human Activity Recognition WITHOUT Using Neural Networks</title>
      <link>http://arxiv.org/abs/2506.05169v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 8 figures, 8 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过墙体雷达（TWR）进行人体活动识别（HAR）的新方法，旨在挑战传统的基于神经网络模型的方法。&lt;h4&gt;背景&lt;/h4&gt;通过墙体雷达进行人体活动识别的研究已有数年，但研究者似乎陷入了仅通过神经网络模型在雷达图像数据上训练的思维定势。&lt;h4&gt;目的&lt;/h4&gt;尝试回到原始的研究路径，避免使用神经网络，以实现TWR-HAR任务，并挑战通过神经网络模型实现智能识别。&lt;h4&gt;方法&lt;/h4&gt;首先生成TWR的时域图和多普勒时域图，然后使用角点检测方法确定人体目标前景和噪声背景的初始区域，接着使用多相主动轮廓模型对微多普勒特征进行分割，并将分割特征离散化为二维点云。最后，使用Mapper算法计算结果点云与模板数据点云之间的拓扑相似度，以获得识别结果。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过数值模拟和测量实验证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法有效避免了神经网络的使用，为TWR-HAR任务提供了一种新的思路。&lt;h4&gt;翻译&lt;/h4&gt;After a few years of research in the field of through-the-wall radar (TWR) human activity recognition (HAR), I found that we seem to be stuck in the mindset of training on radar image data through neural network models. The earliest related works in this field based on template matching did not require a training process, and I believe they have never died. Because these methods possess a strong physical interpretability and are closer to the basis of theoretical signal processing research. In this paper, I would like to try to return to the original path by attempting to eschew neural networks to achieve the TWR HAR task and challenge to achieve intelligent recognition as neural network models. In detail, the range-time map and Doppler-time map of TWR are first generated. Then, the initial regions of the human target foreground and noise background on the maps are determined using corner detection method, and the micro-Doppler signature is segmented using the multiphase active contour model. The micro-Doppler segmentation feature is discretized into a two-dimensional point cloud. Finally, the topological similarity between the resulting point cloud and the point clouds of the template data is calculated using Mapper algorithm to obtain the recognition results. The effectiveness of the proposed method is demonstrated by numerical simulated and measured experiments. The open-source code of this work is released at: https://github.com/JoeyBGOfficial/Through-the-Wall-Radar-Human-Activity-Recognition-Without-Using-Neural-Networks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; After a few years of research in the field of through-the-wall radar (TWR)human activity recognition (HAR), I found that we seem to be stuck in themindset of training on radar image data through neural network models. Theearliest related works in this field based on template matching did not requirea training process, and I believe they have never died. Because these methodspossess a strong physical interpretability and are closer to the basis oftheoretical signal processing research. In this paper, I would like to try toreturn to the original path by attempting to eschew neural networks to achievethe TWR HAR task and challenge to achieve intelligent recognition as neuralnetwork models. In detail, the range-time map and Doppler-time map of TWR arefirst generated. Then, the initial regions of the human target foreground andnoise background on the maps are determined using corner detection method, andthe micro-Doppler signature is segmented using the multiphase active contourmodel. The micro-Doppler segmentation feature is discretized into atwo-dimensional point cloud. Finally, the topological similarity between theresulting point cloud and the point clouds of the template data is calculatedusing Mapper algorithm to obtain the recognition results. The effectiveness ofthe proposed method is demonstrated by numerical simulated and measuredexperiments. The open-source code of this work is released at:https://github.com/JoeyBGOfficial/Through-the-Wall-Radar-Human-Activity-Recognition-Without-Using-Neural-Networks.</description>
      <author>example@mail.com (Weicheng Gao)</author>
      <guid isPermaLink="false">2506.05169v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Single GPU Task Adaptation of Pathology Foundation Models for Whole Slide Image Analysis</title>
      <link>http://arxiv.org/abs/2506.05184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TAPFM的新方法，用于单GPU任务适配病理基础模型（PFM），该方法利用视觉Transformer（ViT）的注意力机制进行多实例学习（MIL）聚合，并优化特征表示和注意力权重，从而在膀胱癌和肺癌突变预测任务中优于传统方法。&lt;h4&gt;背景&lt;/h4&gt;病理基础模型（PFM）在分析全切片图像（WSI）方面表现出强大的能力，但针对特定临床任务进行预训练PFM的适配存在挑战，主要是因为大像素图像只有弱标签（WSI级标签），需要使用MIL范式进行有效的WSI分析。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以实现预训练PFM在标准硬件上的实际适配，用于各种临床应用。&lt;h4&gt;方法&lt;/h4&gt;TAPFM方法使用视觉Transformer（ViT）的注意力机制进行MIL聚合，并优化特征表示和注意力权重，同时保持MIL聚合器和PFM的计算图分离，以创建与下游任务目标一致的稳定训练动态。&lt;h4&gt;主要发现&lt;/h4&gt;在膀胱癌和肺癌突变预测任务中，TAPFM在机构间和TCGA队列上均优于传统方法，其中H-Optimus-0（TAPFM）优于基准。TAPFM还有效地处理了可操作突变的多元分类。&lt;h4&gt;结论&lt;/h4&gt;TAPFM使得在标准硬件上对强大的预训练PFM进行适配成为可能，适用于各种临床应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：病理基础模型（PFMs）已成为分析全切片图像（WSIs）的有力工具。然而，针对特定临床任务适配这些预训练PFM存在相当大的挑战，主要是因为只有弱（WSI级）标签可用于吉像素图像，需要使用多实例学习（MIL）范式进行有效的WSI分析。本文提出了一种名为TAPFM的新方法，用于单GPU任务适配PFM（TAPFM），该方法使用视觉Transformer（ViT）的注意力机制进行MIL聚合，同时优化特征表示和注意力权重。所提出的方法为MIL聚合器和PFM保持独立的计算图，以创建与端到端适配期间的下游任务目标一致的稳定训练动态。在膀胱癌和肺癌腺癌的突变预测任务中，对机构间和TCGA队列进行了评估，TAPFM始终优于传统方法，其中H-Optimus-0（TAPFM）优于基准。TAPFM还有效地处理了可操作突变的多元分类。因此，TAPFM使得在标准硬件上对强大的预训练PFM进行适配成为可能，适用于各种临床应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pathology foundation models (PFMs) have emerged as powerful tools foranalyzing whole slide images (WSIs). However, adapting these pretrained PFMsfor specific clinical tasks presents considerable challenges, primarily due tothe availability of only weak (WSI-level) labels for gigapixel images,necessitating multiple instance learning (MIL) paradigm for effective WSIanalysis. This paper proposes a novel approach for single-GPU \textbf{T}ask\textbf{A}daptation of \textbf{PFM}s (TAPFM) that uses vision transformer(\vit) attention for MIL aggregation while optimizing both for featurerepresentations and attention weights. The proposed approach maintains separatecomputational graphs for MIL aggregator and the PFM to create stable trainingdynamics that align with downstream task objectives during end-to-endadaptation. Evaluated on mutation prediction tasks for bladder cancer and lungadenocarcinoma across institutional and TCGA cohorts, TAPFM consistentlyoutperforms conventional approaches, with H-Optimus-0 (TAPFM) outperforming thebenchmarks. TAPFM effectively handles multi-label classification of actionablemutations as well. Thus, TAPFM makes adaptation of powerful pre-trained PFMspractical on standard hardware for various clinical applications.</description>
      <author>example@mail.com (Neeraj Kumar, Swaraj Nanda, Siddharth Singi, Jamal Benhamida, David Kim, Jie-Fu Chen, Amir Momeni-Boroujeni, Gregory M. Goldgof, Gabriele Campanella, Chad Vanderbilt)</author>
      <guid isPermaLink="false">2506.05184v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>ProJo4D: Progressive Joint Optimization for Sparse-View Inverse Physics Estimation</title>
      <link>http://arxiv.org/abs/2506.05317v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了ProJo4D，一个渐进式联合优化框架，用于解决神经渲染中的物理问题，提高了在3D重建和新型视图合成中的应用效果。&lt;h4&gt;背景&lt;/h4&gt;神经渲染在3D重建和新型视图合成方面取得了显著进展，但将物理融入其中仍面临挑战，限制了其在机器人学和XR中的数字孪生创建等应用中的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过逐步增加联合优化参数的集合，以解决现有方法在稀疏多视图视频输入下的误差累积问题。&lt;h4&gt;方法&lt;/h4&gt;ProJo4D通过逐步增加联合优化参数的集合，引导参数敏感度，最终实现几何、外观、物理状态和材料属性的完全联合优化。&lt;h4&gt;主要发现&lt;/h4&gt;在PAC-NeRF和Spring-Gaus数据集上的评估表明，ProJo4D在4D未来状态预测、未来状态的全新视图渲染以及材料参数估计方面优于先前的工作。&lt;h4&gt;结论&lt;/h4&gt;ProJo4D在基于物理的4D场景理解方面表现出有效性，为3D重建和新型视图合成提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：神经渲染在3D重建和新型视图合成方面取得了显著进展。与物理学的结合开辟了新的应用。然而，从视觉数据中估计物理的逆问题仍然具有挑战性，限制了其在机器人学和XR中用于创建物理精确数字孪生等应用中的有效性。将物理融入神经渲染框架的现有方法通常需要密集的多视图视频作为输入，这使得它们在实际应用中不切实际。当面对稀疏的多视图视频时，现有方法使用的顺序优化策略引入了显著的误差累积，例如，糟糕的初始3D重建会导致后续阶段的材料参数估计不良。与顺序优化不同，由于问题的非凸性和通常不可微的性质，同时直接优化所有参数也失败了。我们提出了ProJo4D，一个渐进式联合优化框架，它根据参数的敏感性逐步增加联合优化的参数集，导致对几何、外观、物理状态和材料属性的完全联合优化。在PAC-NeRF和Spring-Gaus数据集上的评估表明，ProJo4D在4D未来状态预测、未来状态的全新视图渲染和材料参数估计方面优于先前的工作，证明了它在基于物理的4D场景理解方面的有效性。有关演示，请访问项目网页：https://daniel03c1.github.io/ProJo4D/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural rendering has made significant strides in 3D reconstruction and novelview synthesis. With the integration with physics, it opens up newapplications. The inverse problem of estimating physics from visual data,however, still remains challenging, limiting its effectiveness for applicationslike physically accurate digital twin creation in robotics and XR. Existingmethods that incorporate physics into neural rendering frameworks typicallyrequire dense multi-view videos as input, making them impractical for scalable,real-world use. When presented with sparse multi-view videos, the sequentialoptimization strategy used by existing approaches introduces significant erroraccumulation, e.g., poor initial 3D reconstruction leads to bad materialparameter estimation in subsequent stages. Instead of sequential optimization,directly optimizing all parameters at the same time also fails due to thehighly non-convex and often non-differentiable nature of the problem. Wepropose ProJo4D, a progressive joint optimization framework that graduallyincreases the set of jointly optimized parameters guided by their sensitivity,leading to fully joint optimization over geometry, appearance, physical state,and material property. Evaluations on PAC-NeRF and Spring-Gaus datasets showthat ProJo4D outperforms prior work in 4D future state prediction, novel viewrendering of future state, and material parameter estimation, demonstrating itseffectiveness in physically grounded 4D scene understanding. For demos, pleasevisit the project webpage: https://daniel03c1.github.io/ProJo4D/</description>
      <author>example@mail.com (Daniel Rho, Jun Myeong Choi, Biswadip Dey, Roni Sengupta)</author>
      <guid isPermaLink="false">2506.05317v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating Degree Bias Adaptively with Hard-to-Learn Nodes in Graph Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.05214v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HAR的对比学习损失函数，用于减轻图神经网络在节点分类任务中的度偏问题，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在节点分类任务中常受到度偏的影响，即预测性能在不同度数的节点之间有所差异。&lt;h4&gt;目的&lt;/h4&gt;提出HAR对比学习损失函数，以减轻节点分类任务中的度偏问题。&lt;h4&gt;方法&lt;/h4&gt;HAR通过利用节点标签添加更多的正对，并根据学习难度自适应地加权正负对。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SHARP在四个数据集上均优于基线方法，无论是在全局层面还是在度层面。&lt;h4&gt;结论&lt;/h4&gt;HAR对比学习损失函数能够有效减轻图神经网络中的度偏问题，并提高节点分类任务的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) often suffer from degree bias in node classification tasks, where prediction performance varies across nodes with different degrees. Several approaches, which adopt Graph Contrastive Learning (GCL), have been proposed to mitigate this bias. However, the limited number of positive pairs and the equal weighting of all positives and negatives in GCL still lead to low-degree nodes acquiring insufficient and noisy information. This paper proposes the Hardness Adaptive Reweighted (HAR) contrastive loss to mitigate degree bias. It adds more positive pairs by leveraging node labels and adaptively weights positive and negative pairs based on their learning hardness. In addition, we develop an experimental framework named SHARP to extend HAR to a broader range of scenarios. Both our theoretical analysis and experiments validate the effectiveness of SHARP. The experimental results across four datasets show that SHARP achieves better performance against baselines at both global and degree levels.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) often suffer from degree bias in nodeclassification tasks, where prediction performance varies across nodes withdifferent degrees. Several approaches, which adopt Graph Contrastive Learning(GCL), have been proposed to mitigate this bias. However, the limited number ofpositive pairs and the equal weighting of all positives and negatives in GCLstill lead to low-degree nodes acquiring insufficient and noisy information.This paper proposes the Hardness Adaptive Reweighted (HAR) contrastive loss tomitigate degree bias. It adds more positive pairs by leveraging node labels andadaptively weights positive and negative pairs based on their learninghardness. In addition, we develop an experimental framework named SHARP toextend HAR to a broader range of scenarios. Both our theoretical analysis andexperiments validate the effectiveness of SHARP. The experimental resultsacross four datasets show that SHARP achieves better performance againstbaselines at both global and degree levels.</description>
      <author>example@mail.com (Jingyu Hu, Hongbo Bo, Jun Hong, Xiaowei Liu, Weiru Liu)</author>
      <guid isPermaLink="false">2506.05214v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>iN2V: Bringing Transductive Node Embeddings to Inductive Graphs</title>
      <link>http://arxiv.org/abs/2506.05039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为iN2V的节点嵌入方法，用于在训练过程中处理未见过的节点，并将其应用于归纳学习场景。&lt;h4&gt;背景&lt;/h4&gt;传统的节点嵌入方法如node2vec在处理未见过的节点时存在局限性，只能应用于训练过程中包含所有节点的有向图（transductive）。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够处理未见节点并适用于归纳学习场景的节点嵌入方法。&lt;h4&gt;方法&lt;/h4&gt;iN2V结合了后处理计算未见节点嵌入的方法，并对原始node2vec的训练过程进行了修改，以准备后处理步骤。&lt;h4&gt;主要发现&lt;/h4&gt;iN2V在多个基准数据集上进行了实验，结果表明iN2V能够有效地将归纳嵌入应用于归纳学习场景，平均提高了节点分类1分，最大改进可达6分。&lt;h4&gt;结论&lt;/h4&gt;iN2V是一种插件式方法，可以创建新的或丰富现有的嵌入，并可以与其他嵌入方法结合使用，是一种灵活的归纳节点表示学习方法。&lt;h4&gt;翻译&lt;/h4&gt;Shallow node embeddings like node2vec (N2V) can be used for nodes without features or to supplement existing features with structure-based information. Embedding methods like N2V are limited in their application on new nodes, which restricts them to the transductive setting where the entire graph, including the test nodes, is available during training. We propose inductive node2vec (iN2V), which combines a post-hoc procedure to compute embeddings for nodes unseen during training and modifications to the original N2V training procedure to prepare the embeddings for this post-hoc procedure. We conduct experiments on several benchmark datasets and demonstrate that iN2V is an effective approach to bringing transductive embeddings to an inductive setting. Using iN2V embeddings improves node classification by 1 point on average, with up to 6 points of improvement depending on the dataset and the number of unseen nodes. Our iN2V is a plug-in approach to create new or enrich existing embeddings. It can also be combined with other embedding methods, making it a versatile approach for inductive node representation learning. Code to reproduce the results is available at https://github.com/Foisunt/iN2V .&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Shallow node embeddings like node2vec (N2V) can be used for nodes withoutfeatures or to supplement existing features with structure-based information.Embedding methods like N2V are limited in their application on new nodes, whichrestricts them to the transductive setting where the entire graph, includingthe test nodes, is available during training. We propose inductive node2vec(iN2V), which combines a post-hoc procedure to compute embeddings for nodesunseen during training and modifications to the original N2V training procedureto prepare the embeddings for this post-hoc procedure. We conduct experimentson several benchmark datasets and demonstrate that iN2V is an effectiveapproach to bringing transductive embeddings to an inductive setting. UsingiN2V embeddings improves node classification by 1 point on average, with up to6 points of improvement depending on the dataset and the number of unseennodes. Our iN2V is a plug-in approach to create new or enrich existingembeddings. It can also be combined with other embedding methods, making it aversatile approach for inductive node representation learning. Code toreproduce the results is available at https://github.com/Foisunt/iN2V .</description>
      <author>example@mail.com (Nicolas Lell, Ansgar Scherp)</author>
      <guid isPermaLink="false">2506.05039v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Learning Intrinsic Alignments from Local Galaxy Environments</title>
      <link>http://arxiv.org/abs/2506.05155v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为DELTA的深度学习模型，该模型能够从观测数据中分离出星系内在对齐（IAs）和弱引力透镜畸变，并使用等变图神经网络来捕捉局部星系环境信息。&lt;h4&gt;背景&lt;/h4&gt;在星系研究中，内在对齐是指星系在空间中的分布模式，它可能受到潮汐力的作用。&lt;h4&gt;目的&lt;/h4&gt;DELTA模型旨在通过不依赖模拟和假设特定对齐形式来学习星系形状与其局部环境之间的关系。&lt;h4&gt;方法&lt;/h4&gt;DELTA模型使用等变图神经网络作为骨干网络，并具有概率性方向输出，能够灵活地学习星系形状与局部环境之间的联系。&lt;h4&gt;主要发现&lt;/h4&gt;DELTA模型在包含真实噪声对齐信号的模拟目录中能够准确重建无噪声的纯对齐信号，并通过映射这些对齐来直观地展示模拟目录中的对齐模式。&lt;h4&gt;结论&lt;/h4&gt;将DELTA模型与深度学习解释技术相结合，可以进一步了解驱动星系间潮汐关系的物理机制。这种方法适用于联合光度和光谱调查，如即将到来的Euclid、Rubin和DESI数据集的组合。&lt;h4&gt;翻译&lt;/h4&gt;我们提出DELTA（数据经验学习潮汐对齐），一种深度学习模型，它仅使用观测数据从弱引力透镜畸变中分离出星系内在对齐（IAs）。该模型使用适合捕捉局部星系环境信息的等变图神经网络骨干，并结合概率性方向输出。与参数模型不同，DELTA灵活地学习星系形状与其局部环境之间的关系，而不假设显式的IA形式或依赖于模拟。当应用于包含真实噪声对齐信号的模拟目录时，它能够准确重建无噪声的纯对齐信号。通过映射这些对齐提供了对模拟目录中IA模式的直接可视化。将DELTA与深度学习解释技术相结合提供了对驱动星系间潮汐关系的物理机制的进一步了解。这种理解和控制IAs的新方法适用于应用联合光度和光谱调查，如即将到来的Euclid、Rubin和DESI数据集的组合。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present DELTA (Data-Empiric Learned Tidal Alignments), a deep learningmodel that isolates galaxy intrinsic alignments (IAs) from weak lensingdistortions using only observational data. The model uses an Equivariant GraphNeural Network backbone suitable for capturing information from the localgalaxy environment, in conjunction with a probabilistic orientation output.Unlike parametric models, DELTA flexibly learns the relationship between galaxyshapes and their local environments, without assuming an explicit IA form orrelying on simulations. When applied to mock catalogs with realistic noisy IAsinjected, it accurately reconstructs the noise-free, pure IA signal. Mappingthese alignments provides a direct visualization of IA patterns in the mockcatalogs. Combining DELTA with deep learning interpretation techniques providesfurther insights into the physics driving tidal relationships between galaxies.This new approach to understanding and controlling IAs is suitable forapplication to joint photometric and spectroscopic surveys such as thecombination of upcoming Euclid, Rubin, and DESI datasets.</description>
      <author>example@mail.com (Matthew Craigie, Eric Huff, Yuan-Sen Ting, Rossana Ruggeri, Tamara M. Davis)</author>
      <guid isPermaLink="false">2506.05155v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>OpenMaskDINO3D : Reasoning 3D Segmentation via Large Language Model</title>
      <link>http://arxiv.org/abs/2506.04837v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://github.com/Zhangkuns/OpenMaskDINO3D&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了OpenMaskDINO3D，一个用于全面3D理解和分割的LLM，它在处理点云数据和文本提示以生成实例分割掩码方面表现出色，并在多个3D任务中表现出高效。&lt;h4&gt;背景&lt;/h4&gt;尽管感知系统在二维推理分割方面取得了显著进步，但它们仍然依赖于明确的人类指令或预定义的类别来识别目标对象，而在三维推理分割方面，类似的框架和结构尚不存在。&lt;h4&gt;目的&lt;/h4&gt;提出OpenMaskDINO3D，以实现从自然语言指令直接生成精确点云分割结果的目标。&lt;h4&gt;方法&lt;/h4&gt;OpenMaskDINO3D通过处理点云数据和文本提示，结合SEG标记和对象标识符，实现了高精度的3D分割掩码生成。&lt;h4&gt;主要发现&lt;/h4&gt;在ScanNet数据集上的实验结果表明，OpenMaskDINO3D在多种任务中验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;OpenMaskDINO3D为3D推理分割提供了一种新的解决方案，能够从自然语言指令中直接生成精确的点云分割结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although perception systems have made remarkable advancements in recentyears, particularly in 2D reasoning segmentation, these systems still rely onexplicit human instruction or pre-defined categories to identify target objectsbefore executing visual recognition tasks. Such systems have maturedsignificantly, demonstrating the ability to reason and comprehend implicit userintentions in two-dimensional contexts, producing accurate segmentation masksbased on complex and implicit query text. However, a comparable framework andstructure for 3D reasoning segmentation remain absent. This paper introducesOpenMaskDINO3D, a LLM designed for comprehensive 3D understanding andsegmentation. OpenMaskDINO3D processes point cloud data and text prompts toproduce instance segmentation masks, excelling in many 3D tasks. By introducinga SEG token and object identifier, we achieve high-precision 3D segmentationmask generation, enabling the model to directly produce accurate point cloudsegmentation results from natural language instructions. Experimental resultson large-scale ScanNet datasets validate the effectiveness of ourOpenMaskDINO3D across various tasks.</description>
      <author>example@mail.com (Kunshen Zhang)</author>
      <guid isPermaLink="false">2506.04837v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>TextVidBench: A Benchmark for Long Video Scene Text Understanding</title>
      <link>http://arxiv.org/abs/2506.04983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TextVidBench，这是一个针对长视频文本问答任务的新基准，旨在解决现有数据集在视频时长和评估范围上的限制。&lt;h4&gt;背景&lt;/h4&gt;尽管在短视频文本视觉问答任务上取得了进展，但现有数据集仍存在视频时长有限和评估范围狭窄的问题，这难以充分评估强大多模态大语言模型的能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些限制，提出TextVidBench，以促进长视频理解能力的评估。&lt;h4&gt;方法&lt;/h4&gt;TextVidBench具有以下特点：1) 跨域长视频覆盖，包括9个类别，平均视频长度为2306秒；2) 三阶段评估框架：文本针插 haystack -&gt; 时间定位 -&gt; 文本动态描述；3) 高质量细粒度标注，包含超过5000个问题-答案对及详细语义标签。&lt;h4&gt;主要发现&lt;/h4&gt;TextVidBench对现有模型提出了重大挑战，而提出的方法为改进长视频场景文本理解能力提供了有价值的见解。&lt;h4&gt;结论&lt;/h4&gt;TextVidBench的引入为长视频文本问答任务提供了更全面的评估平台，有助于推动相关技术的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管在短视频文本视觉问答任务上取得了进展，但现有数据集仍存在视频时长有限和评估范围狭窄的问题，这难以充分评估强大多模态大语言模型的能力。为了解决这些限制，我们提出了TextVidBench，这是第一个专门为长视频文本问答（&gt;3分钟）设计的基准。TextVidBench有三个关键贡献：1) 跨领域长视频覆盖：涵盖9个类别（例如新闻、体育、游戏），平均视频长度为2306秒，使长视频理解的评估更加真实。2) 三阶段评估框架：“文本针插 haystack -&gt; 时间定位 -&gt; 文本动态描述”。3) 高质量细粒度标注：包含超过5000个问题-答案对及详细语义标签。此外，我们提出了一种高效的方法来提高大模型：通过（i）引入IT-Rope机制和时间提示工程来增强时间感知，（ii）采用非均匀位置编码以更好地处理长视频序列，（iii）对视频-文本数据应用轻量级微调。在多个公开数据集以及TextVidBench上的广泛实验表明，我们的新基准对现有模型提出了重大挑战，而我们的方法为提高长视频场景文本理解能力提供了有价值的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite recent progress on the short-video Text-Visual Question Answering(ViteVQA) task - largely driven by benchmarks such as M4-ViteVQA - existingdatasets still suffer from limited video duration and narrow evaluation scopes,making it difficult to adequately assess the growing capabilities of powerfulmultimodal large language models (MLLMs). To address these limitations, weintroduce TextVidBench, the first benchmark specifically designed forlong-video text question answering (&gt;3 minutes). TextVidBench makes three keycontributions: 1) Cross-domain long-video coverage: Spanning 9 categories(e.g., news, sports, gaming), with an average video length of 2306 seconds,enabling more realistic evaluation of long-video understanding. 2) Athree-stage evaluation framework: "Text Needle-in-Haystack -&gt; TemporalGrounding -&gt; Text Dynamics Captioning". 3) High-quality fine-grainedannotations: Containing over 5,000 question-answer pairs with detailed semanticlabeling. Furthermore, we propose an efficient paradigm for improving largemodels through: (i) introducing the IT-Rope mechanism and temporal promptengineering to enhance temporal perception, (ii) adopting non-uniformpositional encoding to better handle long video sequences, and (iii) applyinglightweight fine-tuning on video-text data. Extensive experiments on multiplepublic datasets as well as TextVidBench demonstrate that our new benchmarkpresents significant challenges to existing models, while our proposed methodoffers valuable insights into improving long-video scene text understandingcapabilities.</description>
      <author>example@mail.com (Yangyang Zhong, Ji Qi, Yuan Yao, Pengxin Luo, Yunfeng Yan, Donglian Qi, Zhiyuan Liu, Tat-Seng Chua)</author>
      <guid isPermaLink="false">2506.04983v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>HUMOF: Human Motion Forecasting in Interactive Social Scenes</title>
      <link>http://arxiv.org/abs/2506.03753v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在交互场景中预测人类运动的有效方法，以应对复杂场景中预测人类行为的挑战。&lt;h4&gt;背景&lt;/h4&gt;复杂场景中的人类行为预测面临挑战，因为存在大量的人与人、人与环境的交互信息，这增加了预测人类运动的不确定性。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来提高复杂场景中人类运动预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;设计了一个分层交互特征表示，高层次特征捕捉交互的整体上下文，低层次特征关注细节。此外，提出了一个由粗到细的交互推理模块，利用空间和频率视角有效地利用分层特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在四个公开数据集上实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在复杂场景中的人类运动预测方面表现出色，将在论文发表时发布代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complex scenes present significant challenges for predicting human behaviourdue to the abundance of interaction information, such as human-human andhumanenvironment interactions. These factors complicate the analysis andunderstanding of human behaviour, thereby increasing the uncertainty inforecasting human motions. Existing motion prediction methods thus struggle inthese complex scenarios. In this paper, we propose an effective method forhuman motion forecasting in interactive scenes. To achieve a comprehensiverepresentation of interactions, we design a hierarchical interaction featurerepresentation so that high-level features capture the overall context of theinteractions, while low-level features focus on fine-grained details. Besides,we propose a coarse-to-fine interaction reasoning module that leverages bothspatial and frequency perspectives to efficiently utilize hierarchicalfeatures, thereby enhancing the accuracy of motion predictions. Our methodachieves state-of-the-art performance across four public datasets. Code will bereleased when this paper is published.</description>
      <author>example@mail.com (Caiyi Sun, Yujing Sun, Xiao Han, Zemin Yang, Jiawei Liu, Xinge Zhu, Siu Ming Yiu, Yuexin Ma)</author>
      <guid isPermaLink="false">2506.03753v2</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Laws for Robust Comparison of Open Foundation Language-Vision Models and Datasets</title>
      <link>http://arxiv.org/abs/2506.04598v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. In Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了可迁移学习中的缩放定律，并展示了如何使用缩放定律来比较模型和数据集，以决定预训练的最佳方法。&lt;h4&gt;背景&lt;/h4&gt;缩放定律在预测重要基础模型在更大规模下的特性和性能方面已得到应用。&lt;h4&gt;目的&lt;/h4&gt;通过缩放定律比较两个语言视觉学习程序CLIP和MaMMUT，评估其预训练过程的优劣。&lt;h4&gt;方法&lt;/h4&gt;通过密集测量广泛范围的模型和样本，推导出CLIP和MaMMUT的完整缩放定律，并使用这些定律比较两个模型，同时考虑了下游任务如分类、检索和分割。&lt;h4&gt;主要发现&lt;/h4&gt;MaMMUT在规模和样本效率方面优于标准CLIP，并且在多种下游任务和开放数据集上观察到一致的趋势。&lt;h4&gt;结论&lt;/h4&gt;缩放定律的准确推导为跨尺度范围进行模型和数据集比较提供了手段，避免了仅基于单一参考尺度的测量得出的误导性结论，为开放基础模型和数据集的系统比较和改进铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;In studies of transferable learning, scaling laws are obtained for various important foundation models to predict their properties and performance at larger scales. We show here how scaling law derivation can also be used for model and dataset comparison, allowing to decide which procedure is to be preferred for pre-training. For the first time, full scaling laws based on dense measurements across a wide span of model and samples seen scales are derived for two important language-vision learning procedures, CLIP and MaMMUT, that use either contrastive only or contrastive and captioning text generative loss. Ensuring sufficient prediction accuracy for held out points, we used derived scaling laws to compare both models, obtaining evidence for MaMMUT's stronger improvement with scale and better sample efficiency than standard CLIP. To strengthen validity of the comparison, we show scaling laws for various downstream tasks, classification, retrieval, and segmentation, and for different open datasets, DataComp, DFN and Re-LAION, observing consistently the same trends. We show that comparison can also be performed when deriving scaling laws with a constant learning rate schedule, reducing compute cost. Accurate derivation of scaling laws provides thus means to perform model and dataset comparison across scale spans, avoiding misleading conclusions based on measurements from single reference scales only, paving the road for systematic comparison and improvement of open foundation models and datasets for their creation. We release all the pre-trained models with their intermediate checkpoints, including openMaMMUT-L/14, which achieves 80.3% zero-shot ImageNet-1k accuracy, trained on 12.8B samples from DataComp-1.4B. Code for reproducing experiments in the paper and raw experiments data can be found at https://github.com/LAION-AI/scaling-laws-for-comparison.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In studies of transferable learning, scaling laws are obtained for variousimportant foundation models to predict their properties and performance atlarger scales. We show here how scaling law derivation can also be used formodel and dataset comparison, allowing to decide which procedure is to bepreferred for pre-training. For the first time, full scaling laws based ondense measurements across a wide span of model and samples seen scales arederived for two important language-vision learning procedures, CLIP and MaMMUT,that use either contrastive only or contrastive and captioning text generativeloss. Ensuring sufficient prediction accuracy for held out points, we usederived scaling laws to compare both models, obtaining evidence for MaMMUT'sstronger improvement with scale and better sample efficiency than standardCLIP. To strengthen validity of the comparison, we show scaling laws forvarious downstream tasks, classification, retrieval, and segmentation, and fordifferent open datasets, DataComp, DFN and Re-LAION, observing consistently thesame trends. We show that comparison can also be performed when derivingscaling laws with a constant learning rate schedule, reducing compute cost.Accurate derivation of scaling laws provides thus means to perform model anddataset comparison across scale spans, avoiding misleading conclusions based onmeasurements from single reference scales only, paving the road for systematiccomparison and improvement of open foundation models and datasets for theircreation. We release all the pre-trained models with their intermediatecheckpoints, including openMaMMUT-L/14, which achieves $80.3\%$ zero-shotImageNet-1k accuracy, trained on 12.8B samples from DataComp-1.4B. Code forreproducing experiments in the paper and raw experiments data can be found athttps://github.com/LAION-AI/scaling-laws-for-comparison.</description>
      <author>example@mail.com (Marianna Nezhurina, Tomer Porian, Giovanni Pucceti, Tommie Kerssies, Romain Beaumont, Mehdi Cherti, Jenia Jitsev)</author>
      <guid isPermaLink="false">2506.04598v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>TRACE: Contrastive learning for multi-trial time-series data in neuroscience</title>
      <link>http://arxiv.org/abs/2506.04906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TRACE的新型对比学习框架，用于处理神经时间序列数据，通过对比学习的方法学习神经元响应的表示。&lt;h4&gt;背景&lt;/h4&gt;现代神经记录技术如两光子成像技术可以获取大量神经元的时间序列数据，而现有的神经网络时间序列分析方法依赖于通用的数据增强技术，并未充分利用神经网络数据中的多试次数据结构。&lt;h4&gt;目的&lt;/h4&gt;提出TRACE框架，旨在通过对比学习有效地从神经时间序列数据中学习神经元的表示。&lt;h4&gt;方法&lt;/h4&gt;TRACE框架通过在不同试次子集之间进行平均来生成正对，结合对比学习和邻近嵌入的思想，直接学习二维嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;TRACE在模拟数据中表现出优于其他方法的性能，能够解决细微的响应差异；在体内记录数据中，TRACE学习到的表示能够捕捉生物相关的连续变化、细胞类型相关的聚类结构，并有助于数据质量控制。&lt;h4&gt;结论&lt;/h4&gt;TRACE是一种有效的对比学习框架，能够从神经时间序列数据中学习到有意义的神经元表示，有助于神经科学数据的分析和理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern neural recording techniques such as two-photon imaging allow toacquire vast time-series datasets with responses of hundreds or thousands ofneurons. Contrastive learning is a powerful self-supervised framework forlearning representations of complex datasets. Existing applications for neuraltime series rely on generic data augmentations and do not exploit themulti-trial data structure inherent in many neural datasets. Here we presentTRACE, a new contrastive learning framework that averages across differentsubsets of trials to generate positive pairs. TRACE allows to directly learn atwo-dimensional embedding, combining ideas from contrastive learning andneighbor embeddings. We show that TRACE outperforms other methods, resolvingfine response differences in simulated data. Further, using in vivo recordings,we show that the representations learned by TRACE capture both biologicallyrelevant continuous variation, cell-type-related cluster structure, and canassist data quality control.</description>
      <author>example@mail.com (Lisa Schmors, Dominic Gonschorek, Jan Niklas Böhm, Yongrong Qiu, Na Zhou, Dmitry Kobak, Andreas Tolias, Fabian Sinz, Jacob Reimer, Katrin Franke, Sebastian Damrich, Philipp Berens)</author>
      <guid isPermaLink="false">2506.04906v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>SGN-CIRL: Scene Graph-based Navigation with Curriculum, Imitation, and Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.04505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于3D场景图的强化学习导航框架SGN-CIRL，用于无地图的机器人导航。该框架通过模仿学习和课程学习加速和稳定强化学习算法的训练过程，并通过实验证明在复杂导航情况下使用3D场景图显著提高了成功率。&lt;h4&gt;背景&lt;/h4&gt;3D场景图模型能够描述物体之间的空间关系，帮助智能体在部分可观测环境中高效导航并预测目标物体的位置。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的导航框架，以实现无地图的机器人导航，并提高在复杂环境中的导航成功率。&lt;h4&gt;方法&lt;/h4&gt;1. 提出基于3D场景图的强化学习导航框架SGN-CIRL；2. 采用模仿学习和课程学习来加速和稳定训练过程；3. 在Isaac Sim环境中进行数值实验。&lt;h4&gt;主要发现&lt;/h4&gt;使用3D场景图进行强化学习在复杂导航案例中的成功率显著提高。&lt;h4&gt;结论&lt;/h4&gt;3D场景图可以显著提高强化学习在复杂导航环境中的应用效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D场景图模型描述了物体之间的空间关系，使智能体能够在部分可观测环境中高效导航并预测目标物体的位置。本文提出了一种名为SGN-CIRL（基于3D场景图的强化学习导航）的原创框架，用于无地图的基于可学习表示的开源词汇3D场景图的强化学习导航。为了加速和稳定基于强化学习的算法训练，该框架还采用了模仿学习和课程学习。前者使智能体能够从演示中学习，而后者通过逐步增加从简单到更高级场景的任务复杂性来构建训练过程。在Isaac Sim环境中进行的数值实验表明，使用3D场景图进行强化学习显著提高了在困难导航案例中的成功率。代码已开源，可在https://github.com/Xisonik/Aloha_graph上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The 3D scene graph models spatial relationships between objects, enabling theagent to efficiently navigate in a partially observable environment and predictthe location of the target object.This paper proposes an original frameworknamed SGN-CIRL (3D Scene Graph-Based Reinforcement Learning Navigation) formapless reinforcement learning-based robot navigation with learnablerepresentation of open-vocabulary 3D scene graph. To accelerate and stabilizethe training of reinforcement learning-based algorithms, the framework alsoemploys imitation learning and curriculum learning. The first one enables theagent to learn from demonstrations, while the second one structures thetraining process by gradually increasing task complexity from simple to moreadvanced scenarios. Numerical experiments conducted in the Isaac Simenvironment showed that using a 3D scene graph for reinforcement learningsignificantly increased the success rate in difficult navigation cases. Thecode is open-sourced and available at: https://github.com/Xisonik/Aloha\_graph.</description>
      <author>example@mail.com (Nikita Oskolkov, Huzhenyu Zhang, Dmitry Makarov, Dmitry Yudin, Aleksandr Panov)</author>
      <guid isPermaLink="false">2506.04505v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Qwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models</title>
      <link>http://arxiv.org/abs/2506.05176v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Qwen3 Embedding系列，这是在文本嵌入和重排序能力上相较于前代GTE-Qwen系列的重要进步，基于Qwen3基础模型构建。&lt;h4&gt;背景&lt;/h4&gt;Qwen3 Embedding系列是在Qwen3基础模型上发展而来，旨在提升文本嵌入和重排序的能力。&lt;h4&gt;目的&lt;/h4&gt;提升文本嵌入和重排序的性能，并满足多样化的部署场景需求。&lt;h4&gt;方法&lt;/h4&gt;采用多阶段训练流程，结合大规模无监督预训练和高质量数据集上的监督微调，以及有效的模型合并策略。Qwen3 LLMs在训练过程中不仅作为骨干模型，还负责跨多个领域和语言的训练数据合成。&lt;h4&gt;主要发现&lt;/h4&gt;Qwen3 Embedding系列在多个基准测试中达到最先进的结果，特别是在多语言评估基准MTEB和代码检索、跨语言检索以及多语言检索等任务中表现出色。&lt;h4&gt;结论&lt;/h4&gt;Qwen3 Embedding系列通过提供不同规模的模型（0.6B、4B、8B）来满足不同部署场景的需求，并公开模型以促进社区研究和开发。&lt;h4&gt;翻译&lt;/h4&gt;在本工作中，我们介绍了Qwen3 Embedding系列，这是在文本嵌入和重排序能力上相较于其前代GTE-Qwen系列的重要进步，建立在Qwen3基础模型之上。利用Qwen3 LLMs在多语言文本理解和生成方面的强大能力，我们创新的分阶段训练流程结合了大规模无监督预训练和高质量数据集上的监督微调。有效的模型合并策略进一步确保了Qwen3 Embedding系列的鲁棒性和适应性。在训练过程中，Qwen3 LLMs不仅作为骨干模型，还发挥着在多个领域和语言中综合高质量、丰富和多样化训练数据的关键作用，从而增强了训练流程。Qwen3 Embedding系列为嵌入和重排序任务提供了多种模型大小（0.6B、4B、8B），以满足多样化的部署场景，用户可以根据效率或效果进行优化。实证评估表明，Qwen3 Embedding系列在多个基准测试中实现了最先进的结果。值得注意的是，它在多语言评估基准MTEB的文本嵌入以及各种检索任务中表现出色，包括代码检索、跨语言检索和多语言检索。为了促进可重复性和推动社区驱动的研发，Qwen3 Embedding模型在Apache 2.0许可下公开。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we introduce the Qwen3 Embedding series, a significantadvancement over its predecessor, the GTE-Qwen series, in text embedding andreranking capabilities, built upon the Qwen3 foundation models. Leveraging theQwen3 LLMs' robust capabilities in multilingual text understanding andgeneration, our innovative multi-stage training pipeline combines large-scaleunsupervised pre-training with supervised fine-tuning on high-quality datasets.Effective model merging strategies further ensure the robustness andadaptability of the Qwen3 Embedding series. During the training process, theQwen3 LLMs serve not only as backbone models but also play a crucial role insynthesizing high-quality, rich, and diverse training data across multipledomains and languages, thus enhancing the training pipeline. The Qwen3Embedding series offers a spectrum of model sizes (0.6B, 4B, 8B) for bothembedding and reranking tasks, addressing diverse deployment scenarios whereusers can optimize for either efficiency or effectiveness. Empiricalevaluations demonstrate that the Qwen3 Embedding series achievesstate-of-the-art results across diverse benchmarks. Notably, it excels on themultilingual evaluation benchmark MTEB for text embedding, as well as invarious retrieval tasks, including code retrieval, cross-lingual retrieval andmultilingual retrieval. To facilitate reproducibility and promotecommunity-driven research and development, the Qwen3 Embedding models arepublicly available under the Apache 2.0 license.</description>
      <author>example@mail.com (Yanzhao Zhang, Mingxin Li, Dingkun Long, Xin Zhang, Huan Lin, Baosong Yang, Pengjun Xie, An Yang, Dayiheng Liu, Junyang Lin, Fei Huang, Jingren Zhou)</author>
      <guid isPermaLink="false">2506.05176v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>The future of gravitational wave science unlocking LIGO potential: AI-driven data analysis and exploration</title>
      <link>http://arxiv.org/abs/2506.04584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了人工智能（AI）在引力波天文学中的应用，特别是AI如何增强信号检测、噪声减少和数据解释。&lt;h4&gt;背景&lt;/h4&gt;引力波天文学的兴起改变了观测宇宙灾难性事件的方式，如黑洞合并和中子星碰撞。LIGO在发现这些事件中发挥了重要作用，但引力波数据的巨大体积和复杂性对传统分析方法提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;研究AI与引力波科学的日益紧密的协同作用，强调AI如何提高探测器灵敏度。&lt;h4&gt;方法&lt;/h4&gt;本文概述了引力波基础知识，讨论了机器学习在提高探测器灵敏度中的作用，并回顾了基于2021至2024年数据的AI技术，包括监督学习、无监督学习、深度学习和强化学习。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，深度学习和监督学习在提高真正阳性率（TPR）和降低假阳性率（FPR）方面优于其他方法。无监督和强化学习模型虽然精度较低，但效率高，适用于实时应用。&lt;h4&gt;结论&lt;/h4&gt;AI与引力波研究的整合显著提高了事件检测的可靠性和速度，为探索动态宇宙开辟了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;随着引力波天文学（GW）的出现，观测宇宙灾难性事件，如黑洞合并和中子星碰撞的方式发生了革命性的变化。激光干涉仪引力波观测站（LIGO）在这些发现中处于前沿。然而，引力波数据的巨大体积和复杂性对传统分析方法提出了重大挑战。本文研究了人工智能（AI）与GW科学之间日益增长的协同作用，强调AI如何增强信号检测、噪声减少和数据解释。它从引力波基础知识概述开始，讨论了机器学习在提高探测器灵敏度中的作用。与LIGO观测到的显著GW事件一起，讨论了持续的挑战，如数据质量、泛化能力和计算限制。根据2021至2024年的数据，对AI技术进行了全面的性能评估，包括监督学习、无监督学习、深度学习和强化学习。评估指标包括准确性、精确度、真正阳性率（TPR）、假阳性率（FPR）和计算效率。发现深度学习和监督学习优于其他方法，特别是在提高TPR和最小化FPR方面。虽然无监督和强化学习模型精度较低，但它们展示了高效率和实时应用的潜力。研究还探讨了AI整合到下一代探测器和波形重建技术中。总的来说，AI与GW研究的整合显著提高了事件检测的可靠性和速度，为探索动态宇宙开辟了新的可能性。本文全面概述了AI在塑造GW天文学未来中的变革性作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.53894/ijirss.v8i3.7514&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of gravitational wave astronomy (GW) has revolutionized theobservation of cataclysmic cosmic events, such as black hole mergers andneutron star collisions. The Laser Interferometer Gravitational-WaveObservatory (LIGO) has been at the forefront of these discoveries. However, theimmense volume and complexity of gravitational wave data present significantchallenges for traditional analysis methods. This paper investigates thegrowing synergy between artificial intelligence (AI) and GW science,emphasizing how AI enhances signal detection, noise reduction, and datainterpretation. It begins with an overview of GW fundamentals and the role ofmachine learning in increasing detector sensitivity. Notable GW events observedby LIGO are discussed alongside persistent analytical challenges such as dataquality, generalization, and computational constraints. A comprehensiveperformance review of AI techniques, including supervised learning,unsupervised learning, deep learning, and reinforcement learning, is presentedbased on data spanning 2021 to 2024. Evaluation metrics include accuracy,precision, true positive rate (TPR), false positive rate (FPR), andcomputational efficiency. Findings indicate that deep learning and supervisedlearning outperform other approaches, particularly in enhancing TPR andminimizing FPR. While unsupervised and reinforcement learning models offer lessprecision, they demonstrate high efficiency and potential for real-timeapplications. The study also explores AI integration into next-generationdetectors and waveform reconstruction techniques. Overall, the integration ofAI into GW research significantly improves the reliability and speed of eventdetection, unlocking new possibilities for exploring the dynamic universe. Thispaper provides a comprehensive outlook on the transformative role of AI inshaping the future of GW astronomy.</description>
      <author>example@mail.com (Yong Xiao, Li, Zin Nandar Win, He Wang, Hla Myo Tun, Win Thu Zar)</author>
      <guid isPermaLink="false">2506.04584v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Aligning Multimodal Representations through an Information Bottleneck</title>
      <link>http://arxiv.org/abs/2506.04870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了对比损失在多模态表示学习中的应用，指出其不适用于学习对齐的表示空间，并提出了相应的解决方案。&lt;h4&gt;背景&lt;/h4&gt;对比损失在多模态表示学习中广泛使用，但实验表明其效果不佳。&lt;h4&gt;目的&lt;/h4&gt;分析对比损失在多模态表示学习中的不足，并提出改进方法。&lt;h4&gt;方法&lt;/h4&gt;通过信息瓶颈原理进行理论描述，通过控制实验分析不同超参数的影响，并提出在损失函数中加入正则化项的方法。&lt;h4&gt;主要发现&lt;/h4&gt;对比损失未能有效去除表示空间中的模态特定信息，导致学习到的表示空间不对齐。&lt;h4&gt;结论&lt;/h4&gt;通过在损失函数中加入正则化项，可以增加表示的对齐度，提高多模态表示学习的效果。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive losses have been extensively used as a tool for multimodal representation learning. However, it has been empirically observed that their use is not effective to learn an aligned representation space. In this paper, we argue that this phenomenon is caused by the presence of modality-specific information in the representation space. Although some of the most widely used contrastive losses maximize the mutual information between representations of both modalities, they are not designed to remove the modality-specific information. We give a theoretical description of this problem through the lens of the Information Bottleneck Principle. We also empirically analyze how different hyperparameters affect the emergence of this phenomenon in a controlled experimental setup. Finally, we propose a regularization term in the loss function that is derived by means of a variational approximation and aims to increase the representational alignment. We analyze in a set of controlled experiments and real-world applications the advantages of including this regularization term.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive losses have been extensively used as a tool for multimodalrepresentation learning. However, it has been empirically observed that theiruse is not effective to learn an aligned representation space. In this paper,we argue that this phenomenon is caused by the presence of modality-specificinformation in the representation space. Although some of the most widely usedcontrastive losses maximize the mutual information between representations ofboth modalities, they are not designed to remove the modality-specificinformation. We give a theoretical description of this problem through the lensof the Information Bottleneck Principle. We also empirically analyze howdifferent hyperparameters affect the emergence of this phenomenon in acontrolled experimental setup. Finally, we propose a regularization term in theloss function that is derived by means of a variational approximation and aimsto increase the representational alignment. We analyze in a set of controlledexperiments and real-world applications the advantages of including thisregularization term.</description>
      <author>example@mail.com (Antonio Almudévar, José Miguel Hernández-Lobato, Sameer Khurana, Ricard Marxer, Alfonso Ortega)</author>
      <guid isPermaLink="false">2506.04870v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>ReXVQA: A Large-scale Visual Question Answering Benchmark for Generalist Chest X-ray Understanding</title>
      <link>http://arxiv.org/abs/2506.04353v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ReXVQA，这是迄今为止最大的胸部放射学视觉问答（VQA）基准，包含约696,000个问题与160,000张胸部X光片配对，用于训练、验证和测试集。该基准旨在评估多模态大型语言模型在胸部X光片解读方面的性能。&lt;h4&gt;背景&lt;/h4&gt;以往的研究主要依赖于基于模板的查询，而ReXVQA引入了多样化的临床真实任务，反映了五个核心放射学推理技能：存在评估、定位分析、否定检测、鉴别诊断和几何推理。&lt;h4&gt;目的&lt;/h4&gt;评估八种最先进的跨模态大型语言模型，并建立一个新的标准来评估通用的放射学人工智能系统。&lt;h4&gt;方法&lt;/h4&gt;评估了包括MedGemma-4B-it、Qwen2.5-VL、Janus-Pro-7B和Eagle2-9B在内的八种模型，并与人类读者进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;性能最佳的模型（MedGemma）实现了83.24%的整体准确率，并且在人类读者（最佳放射科住院医师准确率为77.27%）之上。人类读者之间的性能模式与AI模型和人类读者之间的性能模式存在差异。&lt;h4&gt;结论&lt;/h4&gt;ReXVQA建立了评估放射学人工智能系统的新标准，为下一代能够模拟专家级临床推理的人工智能系统奠定了基础。数据集将在https://huggingface.co/datasets/rajpurkarlab/ReXVQA上开源。&lt;h4&gt;翻译&lt;/h4&gt;本文提出ReXVQA，这是胸部放射学视觉问答（VQA）领域最大、最全面的基准，包括约696,000个问题与160,000张胸部X光片配对，用于训练、验证和测试集。与以往主要依赖基于模板查询的研究不同，ReXVQA引入了多样化的临床真实任务，反映了五个核心放射学推理技能：存在评估、定位分析、否定检测、鉴别诊断和几何推理。评估了包括MedGemma-4B-it、Qwen2.5-VL、Janus-Pro-7B和Eagle2-9B在内的八种最先进的跨模态大型语言模型。性能最佳的模型（MedGemma）实现了83.24%的整体准确率。为了弥合人工智能性能与临床专业知识之间的差距，我们对200个随机抽取的病例进行了包括3名放射科住院医师在内的人类读者研究。评估表明，与人类读者相比，MedGemma实现了更优的性能（准确率为83.84%），代表了人工智能在胸部X光片解读方面超越专家人类评估的一个重要里程碑。读者研究揭示了AI模型和人类专家之间的性能模式存在差异，放射科医生之间的一致性较强，而人类读者与AI模型之间的一致性模式则更为多变。ReXVQA建立了评估通用放射学人工智能系统的新标准，提供了公共排行榜、细粒度评估分割、结构化解释和类别级分解。这个基准为下一代能够模拟专家级临床推理的人工智能系统奠定了基础。我们的数据集将在https://huggingface.co/datasets/rajpurkarlab/ReXVQA上开源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present ReXVQA, the largest and most comprehensive benchmark for visualquestion answering (VQA) in chest radiology, comprising approximately 696,000questions paired with 160,000 chest X-rays studies across training, validation,and test sets. Unlike prior efforts that rely heavily on template basedqueries, ReXVQA introduces a diverse and clinically authentic task suitereflecting five core radiological reasoning skills: presence assessment,location analysis, negation detection, differential diagnosis, and geometricreasoning. We evaluate eight state-of-the-art multimodal large language models,including MedGemma-4B-it, Qwen2.5-VL, Janus-Pro-7B, and Eagle2-9B. Thebest-performing model (MedGemma) achieves 83.24% overall accuracy. To bridgethe gap between AI performance and clinical expertise, we conducted acomprehensive human reader study involving 3 radiology residents on 200randomly sampled cases. Our evaluation demonstrates that MedGemma achievedsuperior performance (83.84% accuracy) compared to human readers (bestradiology resident: 77.27%), representing a significant milestone where AIperformance exceeds expert human evaluation on chest X-ray interpretation. Thereader study reveals distinct performance patterns between AI models and humanexperts, with strong inter-reader agreement among radiologists while showingmore variable agreement patterns between human readers and AI models. ReXVQAestablishes a new standard for evaluating generalist radiological AI systems,offering public leaderboards, fine-grained evaluation splits, structuredexplanations, and category-level breakdowns. This benchmark lays the foundationfor next-generation AI systems capable of mimicking expert-level clinicalreasoning beyond narrow pathology classification. Our dataset will beopen-sourced at https://huggingface.co/datasets/rajpurkarlab/ReXVQA</description>
      <author>example@mail.com (Ankit Pal, Jung-Oh Lee, Xiaoman Zhang, Malaikannan Sankarasubbu, Seunghyeon Roh, Won Jung Kim, Meesun Lee, Pranav Rajpurkar)</author>
      <guid isPermaLink="false">2506.04353v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>PixCell: A generative foundation model for digital histopathology images</title>
      <link>http://arxiv.org/abs/2506.05127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了PixCell，一种基于扩散模型的病理学生成性基础模型，它可以生成多种癌症类型的高质量图像，并在病理学研究和数据共享等方面具有应用价值。&lt;h4&gt;背景&lt;/h4&gt;病理学领域的数字化和大数据时代的到来，推动了病理学的发展，同时也提出了新的挑战，如数据稀缺和隐私保护等。&lt;h4&gt;目的&lt;/h4&gt;介绍PixCell模型，该模型旨在通过生成性方法解决病理学中的问题，如数据稀缺、隐私保护和进行虚拟染色等。&lt;h4&gt;方法&lt;/h4&gt;PixCell在包含69,184个H&amp;E染色全切片图像的大规模数据集PanCan-30M上训练，采用了渐进式训练策略和基于自我监督的条件化技术。&lt;h4&gt;主要发现&lt;/h4&gt;PixCell能够生成多样化和高质量的图像，这些图像可以用作训练自我监督判别模型的数据替代品，并在数据共享和隐私保护方面具有优势。通过有限的标注图像，PixCell可以实现图像生成的精确控制，并在细胞分割任务中提升下游性能。&lt;h4&gt;结论&lt;/h4&gt;PixCell在病理学研究中具有广泛应用前景，能够加速计算病理学领域的研究进展。&lt;h4&gt;翻译&lt;/h4&gt;The abstract introduces PixCell, a diffusion-based generative foundation model for histopathology that can generate diverse and high-quality images across multiple cancer types, which has application value in various aspects of pathology research, such as data sharing and privacy protection.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The digitization of histology slides has revolutionized pathology, providingmassive datasets for cancer diagnosis and research. Contrastive self-supervisedand vision-language models have been shown to effectively mine large pathologydatasets to learn discriminative representations. On the other hand, generativemodels, capable of synthesizing realistic and diverse images, present acompelling solution to address unique problems in pathology that involvesynthesizing images; overcoming annotated data scarcity, enablingprivacy-preserving data sharing, and performing inherently generative tasks,such as virtual staining. We introduce PixCell, the first diffusion-basedgenerative foundation model for histopathology. We train PixCell on PanCan-30M,a vast, diverse dataset derived from 69,184 H\&amp;E-stained whole slide imagescovering various cancer types. We employ a progressive training strategy and aself-supervision-based conditioning that allows us to scale up training withoutany annotated data. PixCell generates diverse and high-quality images acrossmultiple cancer types, which we find can be used in place of real data to traina self-supervised discriminative model. Synthetic images shared betweeninstitutions are subject to fewer regulatory barriers than would be the casewith real clinical images. Furthermore, we showcase the ability to preciselycontrol image generation using a small set of annotated images, which can beused for both data augmentation and educational purposes. Testing on a cellsegmentation task, a mask-guided PixCell enables targeted data augmentation,improving downstream performance. Finally, we demonstrate PixCell's ability touse H\&amp;E structural staining to infer results from molecular marker studies; weuse this capability to infer IHC staining from H\&amp;E images. Our trained modelsare publicly released to accelerate research in computational pathology.</description>
      <author>example@mail.com (Srikar Yellapragada, Alexandros Graikos, Zilinghan Li, Kostas Triaridis, Varun Belagali, Saarthak Kapse, Tarak Nath Nandi, Ravi K Madduri, Prateek Prasanna, Tahsin Kurc, Rajarsi R. Gupta, Joel Saltz, Dimitris Samaras)</author>
      <guid isPermaLink="false">2506.05127v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>APVR: Hour-Level Long Video Understanding with Adaptive Pivot Visual Information Retrieval</title>
      <link>http://arxiv.org/abs/2506.04953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为APVR的无需训练的视频理解框架，通过层次化视觉信息检索来克服内存墙限制，提高了对小时级别视频的处理能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基于视频的多模态大语言模型在处理小时级别视频时存在计算限制和从长时间序列中提取信息效率低下的问题。&lt;h4&gt;目的&lt;/h4&gt;提出APVR框架，旨在解决小时级别视频理解中的内存墙限制。&lt;h4&gt;方法&lt;/h4&gt;APVR框架包含两个互补组件：Pivot Frame Retrieval通过语义扩展和多模态置信度评分识别语义相关的视频帧；Pivot Token Retrieval在枢纽帧内执行查询感知的注意力驱动的标记选择。&lt;h4&gt;主要发现&lt;/h4&gt;在LongVideoBench和VideoMME上的实验验证显示了显著的性能提升，不仅对于无需训练的方法，也对基于训练的方法都达到了最先进的结果。&lt;h4&gt;结论&lt;/h4&gt;APVR框架在保持语义准确性的同时，能够处理长达小时的视频，并且能够与现有的机器学习大语言模型架构无缝集成。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current video-based multimodal large language models struggle with hour-levelvideo understanding due to computational constraints and inefficientinformation extraction from extensive temporal sequences. We propose APVR(Adaptive Pivot Visual information Retrieval), a training-free framework thataddresses the memory wall limitation through hierarchical visual informationretrieval. APVR operates via two complementary components: Pivot FrameRetrieval employs semantic expansion and multi-modal confidence scoring toidentify semantically relevant video frames, while Pivot Token Retrievalperforms query-aware attention-driven token selection within the pivot frames.This dual granularity approach enables processing of hour-long videos whilemaintaining semantic fidelity. Experimental validation on LongVideoBench andVideoMME demonstrates significant performance improvements, establishingstate-of-the-art results for not only training-free but also training-basedapproaches while providing plug-and-play integration capability with existingMLLM architectures.</description>
      <author>example@mail.com (Hong Gao, Yiming Bao, Xuezhan Tu, Bin Zhong, Minling Zhang)</author>
      <guid isPermaLink="false">2506.04953v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>OpenGT: A Comprehensive Benchmark For Graph Transformers</title>
      <link>http://arxiv.org/abs/2506.04765v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Graph Transformers（GTs）的性能和设计，强调了它们在建模长距离依赖和复杂结构关系方面的优势，同时也指出了目前对GTs适用场景和设计选择的探索不足。&lt;h4&gt;背景&lt;/h4&gt;Graph Transformers在多个领域表现出色，通过利用注意力机制，它们能够超越局部邻域，建模长距离依赖和复杂结构关系。&lt;h4&gt;目的&lt;/h4&gt;为了解决GTs适用场景和设计选择的探索不足的问题，本文提出了OpenGT，一个全面的Graph Transformers基准。&lt;h4&gt;方法&lt;/h4&gt;OpenGT通过建立标准化的实验设置，整合了多种最先进的GNNs和GTs，允许进行公平的比较和多维度的分析。&lt;h4&gt;主要发现&lt;/h4&gt;OpenGT基准揭示了多个关键洞察，包括模型在不同任务级别间迁移的困难、局部注意力机制的局限性、某些模型中效率与性能的权衡、特定位置编码的应用场景以及某些位置编码的前处理开销。&lt;h4&gt;结论&lt;/h4&gt;本文旨在为未来的Graph Transformers研究奠定基础，强调公平性、可重复性和通用性，并开发了OpenGT库，方便训练和评估现有的GTs。&lt;h4&gt;翻译&lt;/h4&gt;Graph Transformers (GTs) recently have demonstrated remarkable performance across various domains. By utilizing attention mechanisms, GTs are capable of modeling long-range dependencies and complex structural relationships beyond local neighborhoods. However, their applicable scenarios are still underexplored, which highlights the need to identify when and why they excel. Furthermore, unlike GNNs, which predominantly rely on message-passing mechanisms, GTs exhibit a diverse design space in areas such as positional encoding, attention mechanisms, and graph-specific adaptations. Yet, it remains unclear which of these design choices are truly effective and under what conditions. As a result, the community currently lacks a comprehensive benchmark and library to promote a deeper understanding and further development of GTs. To address this gap, this paper introduces OpenGT, a comprehensive benchmark for Graph Transformers. OpenGT enables fair comparisons and multidimensional analysis by establishing standardized experimental settings and incorporating a broad selection of state-of-the-art GNNs and GTs. Our benchmark evaluates GTs from multiple perspectives, encompassing diverse tasks and datasets with varying properties. Through extensive experiments, our benchmark has uncovered several critical insights, including the difficulty of transferring models across task levels, the limitations of local attention, the efficiency trade-offs in several models, the application scenarios of specific positional encodings, and the preprocessing overhead of some positional encodings. We aspire for this work to establish a foundation for future graph transformer research emphasizing fairness, reproducibility, and generalizability. We have developed an easy-to-use library OpenGT for training and evaluating existing GTs. The benchmark code is available at https://github.com/eaglelab-zju/OpenGT.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Transformers (GTs) have recently demonstrated remarkable performanceacross diverse domains. By leveraging attention mechanisms, GTs are capable ofmodeling long-range dependencies and complex structural relationships beyondlocal neighborhoods. However, their applicable scenarios are stillunderexplored, this highlights the need to identify when and why they excel.Furthermore, unlike GNNs, which predominantly rely on message-passingmechanisms, GTs exhibit a diverse design space in areas such as positionalencoding, attention mechanisms, and graph-specific adaptations. Yet, it remainsunclear which of these design choices are truly effective and under whatconditions. As a result, the community currently lacks a comprehensivebenchmark and library to promote a deeper understanding and further developmentof GTs. To address this gap, this paper introduces OpenGT, a comprehensivebenchmark for Graph Transformers. OpenGT enables fair comparisons andmultidimensional analysis by establishing standardized experimental settingsand incorporating a broad selection of state-of-the-art GNNs and GTs. Ourbenchmark evaluates GTs from multiple perspectives, encompassing diverse tasksand datasets with varying properties. Through extensive experiments, ourbenchmark has uncovered several critical insights, including the difficulty oftransferring models across task levels, the limitations of local attention, theefficiency trade-offs in several models, the application scenarios of specificpositional encodings, and the preprocessing overhead of some positionalencodings. We aspire for this work to establish a foundation for future graphtransformer research emphasizing fairness, reproducibility, andgeneralizability. We have developed an easy-to-use library OpenGT for trainingand evaluating existing GTs. The benchmark code is available athttps://github.com/eaglelab-zju/OpenGT.</description>
      <author>example@mail.com (Jiachen Tang, Zhonghao Wang, Sirui Chen, Sheng Zhou, Jiawei Chen, Jiajun Bu)</author>
      <guid isPermaLink="false">2506.04765v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>CL-ISR: A Contrastive Learning and Implicit Stance Reasoning Framework for Misleading Text Detection on Social Media</title>
      <link>http://arxiv.org/abs/2506.05107v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CL-ISR的新型框架，用于提高社交媒体上误导性文本的检测准确性。&lt;h4&gt;背景&lt;/h4&gt;社交媒体上的误导性文本可能导致公众误解、社会恐慌和经济损失。&lt;h4&gt;目的&lt;/h4&gt;提高社交媒体上误导性文本的检测准确性。&lt;h4&gt;方法&lt;/h4&gt;结合对比学习和隐式立场推理，通过对比学习算法提高模型对真实文本和误导文本语义差异的学习能力，引入隐式立场推理模块探索文本中的潜在立场倾向及其与相关主题的关系。&lt;h4&gt;主要发现&lt;/h4&gt;CL-ISR框架利用对比学习的判别能力和立场推理的解读深度，显著提高了检测效果。&lt;h4&gt;结论&lt;/h4&gt;CL-ISR框架能够有效提高社交媒体上误导性文本的检测准确性。&lt;h4&gt;翻译&lt;/h4&gt;Misleading text detection on social media platforms is a critical research area, as these texts can lead to public misunderstanding, social panic and even economic losses. This paper proposes a novel framework - CL-ISR (Contrastive Learning and Implicit Stance Reasoning), which combines contrastive learning and implicit stance reasoning, to improve the detection accuracy of misleading texts on social media. First, we use the contrastive learning algorithm to improve the model's learning ability of semantic differences between truthful and misleading texts. Contrastive learning could help the model to better capture the distinguishing features between different categories by constructing positive and negative sample pairs. This approach enables the model to capture distinguishing features more effectively, particularly in linguistically complicated situations. Second, we introduce the implicit stance reasoning module, to explore the potential stance tendencies in the text and their relationships with related topics. This method is effective for identifying content that misleads through stance shifting or emotional manipulation, because it can capture the implicit information behind the text. Finally, we integrate these two algorithms together to form a new framework, CL-ISR, which leverages the discriminative power of contrastive learning and the interpretive depth of stance reasoning to significantly improve detection effect.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Misleading text detection on social media platforms is a critical researcharea, as these texts can lead to public misunderstanding, social panic and eveneconomic losses. This paper proposes a novel framework - CL-ISR (ContrastiveLearning and Implicit Stance Reasoning), which combines contrastive learningand implicit stance reasoning, to improve the detection accuracy of misleadingtexts on social media. First, we use the contrastive learning algorithm toimprove the model's learning ability of semantic differences between truthfuland misleading texts. Contrastive learning could help the model to bettercapture the distinguishing features between different categories byconstructing positive and negative sample pairs. This approach enables themodel to capture distinguishing features more effectively, particularly inlinguistically complicated situations. Second, we introduce the implicit stancereasoning module, to explore the potential stance tendencies in the text andtheir relationships with related topics. This method is effective foridentifying content that misleads through stance shifting or emotionalmanipulation, because it can capture the implicit information behind the text.Finally, we integrate these two algorithms together to form a new framework,CL-ISR, which leverages the discriminative power of contrastive learning andthe interpretive depth of stance reasoning to significantly improve detectioneffect.</description>
      <author>example@mail.com (Tianyi Huang, Zikun Cui, Cuiqianhe Du, Chia-En Chiang)</author>
      <guid isPermaLink="false">2506.05107v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Tuning the Right Foundation Models is What you Need for Partial Label Learning</title>
      <link>http://arxiv.org/abs/2506.05027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code can be found at \url{https://github.com/SEU-hk/PartialCLIP}&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了部分标签学习（PLL），评估了11种基础模型在13种PLL方法下的性能，并提出了一个针对基础模型的PLL微调框架PartialCLIP。&lt;h4&gt;背景&lt;/h4&gt;PLL旨在从带有不精确监督的数据集中训练可泛化的分类器，这是现实应用中常见的问题。&lt;h4&gt;目的&lt;/h4&gt;评估现有PLL方法在基础模型上的性能，并提出改进的PLL模型。&lt;h4&gt;方法&lt;/h4&gt;在8个基准数据集上，对11种基础模型在13种PLL方法下的性能进行了全面评估，并提出了PartialCLIP框架。&lt;h4&gt;主要发现&lt;/h4&gt;1) 使用基础模型时，PLL方法可以实现显著的性能提升；2) 不同PLL方法之间的性能相似；3) 在不同的模糊程度下，PLL方法保持稳定的性能；4) PLL方法对基础模型的选择和适应策略敏感。&lt;h4&gt;结论&lt;/h4&gt;实验结果和分析突出了现有PLL方法的局限性，并为开发更通用的PLL模型提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;Partial label learning (PLL) aims to train generalizable classifiers from datasets with inexact supervision, a common challenge in real-world applications. Existing studies have developed numerous approaches to progressively refine and recover ground-truth labels by training convolutional neural networks. However, limited attention has been given to foundation models that offer transferrable representations. In this work, we empirically conduct comprehensive evaluations of 11 foundation models across 13 PLL approaches on 8 benchmark datasets under 3 PLL scenarios. We further propose PartialCLIP, an efficient fine-tuning framework for foundation models in PLL. Our findings reveal that current PLL approaches tend to 1) achieve significant performance gains when using foundation models, 2) exhibit remarkably similar performance to each other, 3) maintain stable performance across varying ambiguity levels, while 4) are susceptible to foundation model selection and adaptation strategies. Additionally, we demonstrate the efficacy of text-embedding classifier initialization and effective candidate label filtering using zero-shot CLIP. Our experimental results and analysis underscore the limitations of current PLL approaches and provide valuable insights for developing more generalizable PLL models. The source code can be found at https://github.com/SEU-hk/PartialCLIP.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Partial label learning (PLL) seeks to train generalizable classifiers fromdatasets with inexact supervision, a common challenge in real-worldapplications. Existing studies have developed numerous approaches toprogressively refine and recover ground-truth labels by training convolutionalneural networks. However, limited attention has been given to foundation modelsthat offer transferrable representations. In this work, we empirically conductcomprehensive evaluations of 11 foundation models across 13 PLL approaches on 8benchmark datasets under 3 PLL scenarios. We further propose PartialCLIP, anefficient fine-tuning framework for foundation models in PLL. Our findingsreveal that current PLL approaches tend to 1) achieve significant performancegains when using foundation models, 2) exhibit remarkably similar performanceto each other, 3) maintain stable performance across varying ambiguity levels,while 4) are susceptible to foundation model selection and adaptationstrategies. Additionally, we demonstrate the efficacy of text-embeddingclassifier initialization and effective candidate label filtering usingzero-shot CLIP. Our experimental results and analysis underscore thelimitations of current PLL approaches and provide valuable insights fordeveloping more generalizable PLL models. The source code can be found athttps://github.com/SEU-hk/PartialCLIP.</description>
      <author>example@mail.com (Kuang He, Wei Tang, Tong Wei, Min-Ling Zhang)</author>
      <guid isPermaLink="false">2506.05027v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>DualX-VSR: Dual Axial Spatial$\times$Temporal Transformer for Real-World Video Super-Resolution without Motion Compensation</title>
      <link>http://arxiv.org/abs/2506.04830v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DualX-VSR的Transformer模型，用于现实世界视频超分辨率（VSR）任务，该模型通过引入新的双重轴向时空注意力机制，有效地解决了现有VSR模型在像素级精度、响应域限制和依赖光学流对齐等方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;Transformer模型在视频理解方面取得了进展，但在视频超分辨率任务中存在挑战，如像素级精度要求高，而现有的VSR模型可能因为序列注意力机制而降低精度。&lt;h4&gt;目的&lt;/h4&gt;提出DualX-VSR模型，旨在解决现实世界视频超分辨率中的像素级精度问题，并克服现有模型在响应域和光学流对齐方面的限制。&lt;h4&gt;方法&lt;/h4&gt;DualX-VSR模型通过引入新的双重轴向时空注意力机制，整合空间和时间信息，并简化结构以提供时空信息的连贯表示。&lt;h4&gt;主要发现&lt;/h4&gt;DualX-VSR模型通过消除运动补偿需求，提供了一种更简化的结构，从而在现实世界的VSR任务中实现了高保真度和卓越的性能。&lt;h4&gt;结论&lt;/h4&gt;DualX-VSR模型在视频超分辨率任务中展示了优异的性能，为解决现实世界中的VSR问题提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于Transformer的模型如ViViT和TimeSformer通过有效地模拟时空依赖性而提高了视频理解。最近的一些视频生成模型，如Sora和Vidu，进一步突显了Transformer在长程特征提取和整体时空建模方面的能力。然而，将这些模型直接应用于现实世界的视频超分辨率（VSR）具有挑战性，因为VSR需要像素级的精确度，这可能会被标记化和序列注意力机制所损害。尽管最近的基于Transformer的VSR模型尝试使用更小的块和局部注意力来解决这些问题，但它们仍然面临着诸如受限的响应域和对基于光流对齐的依赖等限制，这可能会在现实世界中引入不准确。为了克服这些问题，我们提出了用于现实世界视频超分辨率的Dual Axial Spatial×Temporal Transformer（DualX-VSR），它引入了一种新颖的双重轴向时空注意力机制，该机制沿正交方向整合空间和时间信息。DualX-VSR消除了运动补偿的需求，提供了一个提供时空信息连贯表示的简化结构。因此，DualX-VSR在现实世界的VSR任务中实现了高保真度和卓越的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer-based models like ViViT and TimeSformer have advanced videounderstanding by effectively modeling spatiotemporal dependencies. Recent videogeneration models, such as Sora and Vidu, further highlight the power oftransformers in long-range feature extraction and holistic spatiotemporalmodeling. However, directly applying these models to real-world videosuper-resolution (VSR) is challenging, as VSR demands pixel-level precision,which can be compromised by tokenization and sequential attention mechanisms.While recent transformer-based VSR models attempt to address these issues usingsmaller patches and local attention, they still face limitations such asrestricted receptive fields and dependence on optical flow-based alignment,which can introduce inaccuracies in real-world settings. To overcome theseissues, we propose Dual Axial Spatial$\times$Temporal Transformer forReal-World Video Super-Resolution (DualX-VSR), which introduces a novel dualaxial spatial$\times$temporal attention mechanism that integrates spatial andtemporal information along orthogonal directions. DualX-VSR eliminates the needfor motion compensation, offering a simplified structure that provides acohesive representation of spatiotemporal information. As a result, DualX-VSRachieves high fidelity and superior performance in real-world VSR task.</description>
      <author>example@mail.com (Shuo Cao, Yihao Liu, Xiaohui Li. Yuanting Gao. Yu Zhou, Chao Dong)</author>
      <guid isPermaLink="false">2506.04830v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>OpenAg: Democratizing Agricultural Intelligence</title>
      <link>http://arxiv.org/abs/2506.04571v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为OpenAg的综合框架，旨在推动农业人工智能（AGI）的发展，以解决当前农业智能系统在情境理解、可解释性和适应性方面的不足。&lt;h4&gt;背景&lt;/h4&gt;农业正经历由人工智能（AI）、机器学习和知识表示技术驱动的重大变革。然而，目前的农业智能系统往往缺乏情境理解、可解释性和适应性，尤其是对于资源有限的小农户来说。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，OpenAg框架旨在结合特定领域的知识、神经网络知识图谱、多智能体推理、因果可解释性和自适应迁移学习，以提供情境感知、可解释和可操作的见解。&lt;h4&gt;方法&lt;/h4&gt;OpenAg系统包括：（一）一个统一的农业知识库，整合科学文献、传感器数据和农民生成的知识；（二）一个用于结构化推理和推理的神经网络农业知识图谱；（三）一个自适应的多智能体推理系统，其中AI智能体在农业领域专业化和协作；（四）一个因果透明机制，确保AI建议是可解释的、科学依据的并与现实世界约束一致。&lt;h4&gt;主要发现&lt;/h4&gt;OpenAg旨在弥合科学知识与经验丰富的农民的隐性专业知识之间的差距，以支持可扩展且与当地相关的农业决策。&lt;h4&gt;结论&lt;/h4&gt;OpenAg框架有望为农业决策提供支持，帮助解决当前农业智能系统存在的问题，推动农业的智能化发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：农业正在经历由人工智能（AI）、机器学习和知识表示技术驱动的重大变革。然而，当前农业智能系统通常缺乏情境理解、可解释性和适应性，尤其是在资源有限的小农户中。通用的大语言模型（LLM）虽然功能强大，但通常缺乏农业领域特定的知识和情境推理，这些是实际农业决策支持所必需的。它们往往产生过于通用的或不切实际的推荐，适用于现实世界的应用。为了解决这些挑战，我们提出了OpenAg，这是一个旨在推动农业人工智能（AGI）的综合框架。OpenAg结合了特定领域的基座模型、神经网络知识图谱、多智能体推理、因果可解释性和自适应迁移学习，以提供情境感知、可解释和可操作的见解。该系统包括：（一）一个统一的农业知识库，整合科学文献、传感器数据和农民生成的知识；（二）一个用于结构化推理和推理的神经网络农业知识图谱；（三）一个自适应的多智能体推理系统，其中AI智能体在农业领域专业化和协作；（四）一个因果透明机制，确保AI建议是可解释的、科学依据的并与现实世界约束一致。OpenAg的目标是弥合科学知识与经验丰富的农民的隐性专业知识之间的差距，以支持可扩展且与当地相关的农业决策。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Agriculture is undergoing a major transformation driven by artificialintelligence (AI), machine learning, and knowledge representation technologies.However, current agricultural intelligence systems often lack contextualunderstanding, explainability, and adaptability, especially for smallholderfarmers with limited resources. General-purpose large language models (LLMs),while powerful, typically lack the domain-specific knowledge and contextualreasoning needed for practical decision support in farming. They tend toproduce recommendations that are too generic or unrealistic for real-worldapplications. To address these challenges, we present OpenAg, a comprehensiveframework designed to advance agricultural artificial general intelligence(AGI). OpenAg combines domain-specific foundation models, neural knowledgegraphs, multi-agent reasoning, causal explainability, and adaptive transferlearning to deliver context-aware, explainable, and actionable insights. Thesystem includes: (i) a unified agricultural knowledge base that integratesscientific literature, sensor data, and farmer-generated knowledge; (ii) aneural agricultural knowledge graph for structured reasoning and inference;(iii) an adaptive multi-agent reasoning system where AI agents specialize andcollaborate across agricultural domains; and (iv) a causal transparencymechanism that ensures AI recommendations are interpretable, scientificallygrounded, and aligned with real-world constraints. OpenAg aims to bridge thegap between scientific knowledge and the tacit expertise of experienced farmersto support scalable and locally relevant agricultural decision-making.</description>
      <author>example@mail.com (Srikanth Thudumu, Jason Fisher)</author>
      <guid isPermaLink="false">2506.04571v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Towards LLM-Centric Multimodal Fusion: A Survey on Integration Strategies and Techniques</title>
      <link>http://arxiv.org/abs/2506.04788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 3 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对多模态大型语言模型（MLLMs）的研究进展进行了综述，分析了当前的方法，并提出了一个基于三个关键维度的分类框架。&lt;h4&gt;背景&lt;/h4&gt;MLLMs的快速发展改变了人工智能的格局，这些模型结合了预训练的大型语言模型和各种模态编码器。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供一个以LLM为中心的分析，填补现有文献中关于如何将不同模态输入转换为语言嵌入空间的方法的空白。&lt;h4&gt;方法&lt;/h4&gt;提出了一个基于三个关键维度的分类框架：模态集成架构策略、表示学习技术（联合或协调表示）和训练范式（包括训练策略和目标函数）。通过分析2021年至2025年间开发的125个MLLMs，识别了该领域的趋势。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出了一个分类框架，为研究人员提供了一个当前集成技术的结构化概述，并识别了MLLMs领域的趋势。&lt;h4&gt;结论&lt;/h4&gt;这些见解旨在指导基于预训练基础的未来模型开发更鲁棒的多模态集成策略。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态大型语言模型（MLLMs）的快速发展已经改变了人工智能的格局。这些模型结合了预训练的大型语言模型和各种模态编码器。这种集成需要对不同模态如何连接到语言骨干的系统理解。我们的调查提供了一个以LLM为中心的当前方法的分析。我们检查了将各种模态输入转换为语言嵌入空间的方法。这解决了现有文献中的一个重大空白。我们基于三个关键维度提出了一个MLLMs的分类框架。首先，我们考察了模态集成架构策略，包括具体的集成机制和融合级别。其次，我们将表示学习技术分类为联合或协调表示。第三，我们分析了训练范式，包括训练策略和目标函数。通过分析2021年至2025年间开发的125个MLLMs，我们确定了该领域的趋势。我们的分类法为研究人员提供了一个当前集成技术的结构化概述。这些见解旨在指导基于预训练基础的未来模型开发更鲁棒的多模态集成策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid progress of Multimodal Large Language Models(MLLMs) has transformedthe AI landscape. These models combine pre-trained LLMs with various modalityencoders. This integration requires a systematic understanding of how differentmodalities connect to the language backbone. Our survey presents an LLM-centricanalysis of current approaches. We examine methods for transforming andaligning diverse modal inputs into the language embedding space. This addressesa significant gap in existing literature. We propose a classification frameworkfor MLLMs based on three key dimensions. First, we examine architecturalstrategies for modality integration. This includes both the specificintegration mechanisms and the fusion level. Second, we categorizerepresentation learning techniques as either joint or coordinaterepresentations. Third, we analyze training paradigms, including trainingstrategies and objective functions. By examining 125 MLLMs developed between2021 and 2025, we identify emerging patterns in the field. Our taxonomyprovides researchers with a structured overview of current integrationtechniques. These insights aim to guide the development of more robustmultimodal integration strategies for future models built on pre-trainedfoundations.</description>
      <author>example@mail.com (Jisu An, Junseok Lee, Jeoungeun Lee, Yongseok Son)</author>
      <guid isPermaLink="false">2506.04788v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Unfolding Spatial Cognition: Evaluating Multimodal Models on Visual Simulations</title>
      <link>http://arxiv.org/abs/2506.04633v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  STARE is available at https://github.com/STARE-bench/STARE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了STARE基准，旨在评估多模态大型语言模型在需要多步视觉模拟的任务上的表现。&lt;h4&gt;背景&lt;/h4&gt;现有AI基准主要评估语言推理，忽略了非语言、多步视觉模拟的复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出STARE基准，以严格评估多模态大型语言模型在通过多步视觉模拟解决的任务上的能力。&lt;h4&gt;方法&lt;/h4&gt;STARE基准包含4K个任务，涵盖基础几何变换（2D和3D）、集成空间推理（立方体网络折叠和七巧板谜题）以及现实世界空间推理（透视和时空推理）。&lt;h4&gt;主要发现&lt;/h4&gt;模型在简单的2D变换推理上表现良好，但在需要多步视觉模拟的复杂任务上，如3D立方体网络折叠和七巧板谜题，表现接近随机机会。人类在复杂任务上达到几乎完美的准确率，但耗时较长（最多28.9秒），通过中间视觉模拟可以显著加快（平均减少7.5秒）。模型从视觉模拟中获得的性能提升不一致，大多数任务上有所提升，但在特定情况下如七巧板谜题（GPT-4o, o1）和立方体网络折叠（Claude-3.5, Gemini-2.0Flash）上有所下降，表明模型可能不知道如何有效地利用中间视觉信息。&lt;h4&gt;结论&lt;/h4&gt;STARE基准揭示了多模态大型语言模型在空间认知任务上的局限性和潜力，为未来的研究提供了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial cognition is essential for human intelligence, enablingproblem-solving through visual simulations rather than solely relying on verbalreasoning. However, existing AI benchmarks primarily assess verbal reasoning,neglecting the complexities of non-verbal, multi-step visual simulation. Weintroduce STARE(Spatial Transformations and Reasoning Evaluation), a benchmarkdesigned to rigorously evaluate multimodal large language models on tasksbetter solved through multi-step visual simulation. STARE features 4K tasksspanning foundational geometric transformations (2D and 3D), integrated spatialreasoning (cube net folding and tangram puzzles), and real-world spatialreasoning (perspective and temporal reasoning), reflecting practical cognitivechallenges like object assembly, mechanical diagram interpretation, andeveryday spatial navigation. Our evaluations show that models excel atreasoning over simpler 2D transformations, but perform close to random chanceon more complex tasks like 3D cube net folding and tangram puzzles that requiremulti-step visual simulations. Humans achieve near-perfect accuracy but takeconsiderable time (up to 28.9s) on complex tasks, significantly speeding up(down by 7.5 seconds on average) with intermediate visual simulations. Incontrast, models exhibit inconsistent performance gains from visualsimulations, improving on most tasks but declining in specific cases liketangram puzzles (GPT-4o, o1) and cube net folding (Claude-3.5, Gemini-2.0Flash), indicating that models may not know how to effectively leverageintermediate visual information.</description>
      <author>example@mail.com (Linjie Li, Mahtab Bigverdi, Jiawei Gu, Zixian Ma, Yinuo Yang, Ziang Li, Yejin Choi, Ranjay Krishna)</author>
      <guid isPermaLink="false">2506.04633v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>RoboRefer: Towards Spatial Referring with Reasoning in Vision-Language Models for Robotics</title>
      <link>http://arxiv.org/abs/2506.04308v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://zhoues.github.io/RoboRefer/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了RoboRefer，一个能够准确理解和动态推理的3D-aware VLM，并通过RefSpatial和RefSpatial-Bench等工具支持其训练和评估。&lt;h4&gt;背景&lt;/h4&gt;尽管预训练的视觉语言模型（VLMs）强大，但近期方法在理解复杂3D场景和动态推理指令指示的位置方面仍不理想。&lt;h4&gt;目的&lt;/h4&gt;设计RoboRefer以实现精确的3D空间理解，并通过多步骤空间推理提升泛化能力。&lt;h4&gt;方法&lt;/h4&gt;RoboRefer通过集成解耦的深度编码器进行监督微调（SFT），并使用强化微调（RFT）进行多步骤空间推理。RefSpatial是一个包含大量QA对的大规模数据集，支持复杂推理过程。RefSpatial-Bench是一个用于评估多步骤空间推理的基准。&lt;h4&gt;主要发现&lt;/h4&gt;SFT训练的RoboRefer在空间理解上达到最先进的水平，平均成功率为89.6%。RFT训练的RoboRefer在RefSpatial-Bench上超过了所有其他基线，平均准确率比Gemini-2.5-Pro高17.4%。RoboRefer可以与多种控制策略集成，以执行不同机器人上的长时程、动态任务。&lt;h4&gt;结论&lt;/h4&gt;RoboRefer在空间理解和动态推理方面表现出色，为机器人与3D物理世界交互提供了有效的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial referring is a fundamental capability of embodied robots to interactwith the 3D physical world. However, even with the powerful pretrained visionlanguage models (VLMs), recent approaches are still not qualified to accuratelyunderstand the complex 3D scenes and dynamically reason about theinstruction-indicated locations for interaction. To this end, we proposeRoboRefer, a 3D-aware VLM that can first achieve precise spatial understandingby integrating a disentangled but dedicated depth encoder via supervisedfine-tuning (SFT). Moreover, RoboRefer advances generalized multi-step spatialreasoning via reinforcement fine-tuning (RFT), with metric-sensitive processreward functions tailored for spatial referring tasks. To support SFT and RFTtraining, we introduce RefSpatial, a large-scale dataset of 20M QA pairs (2xprior), covering 31 spatial relations (vs. 15 prior) and supporting complexreasoning processes (up to 5 steps). In addition, we introduceRefSpatial-Bench, a challenging benchmark filling the gap in evaluating spatialreferring with multi-step reasoning. Experiments show that SFT-trainedRoboRefer achieves state-of-the-art spatial understanding, with an averagesuccess rate of 89.6%. RFT-trained RoboRefer further outperforms all otherbaselines by a large margin, even surpassing Gemini-2.5-Pro by 17.4% in averageaccuracy on RefSpatial-Bench. Notably, RoboRefer can be integrated with variouscontrol policies to execute long-horizon, dynamic tasks across diverse robots(e,g., UR5, G1 humanoid) in cluttered real-world scenes.</description>
      <author>example@mail.com (Enshen Zhou, Jingkun An, Cheng Chi, Yi Han, Shanyu Rong, Chi Zhang, Pengwei Wang, Zhongyuan Wang, Tiejun Huang, Lu Sheng, Shanghang Zhang)</author>
      <guid isPermaLink="false">2506.04308v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Machine Learning for Scientific Discovery: Workflow and Best Practices</title>
      <link>http://arxiv.org/abs/2506.04553v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 4 figures, 12 additional pages of citations&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结构化的工作流程，用于在科学研究中应用无监督学习技术，旨在提高无监督学习发现的可靠性和可重复性。&lt;h4&gt;背景&lt;/h4&gt;无监督学习在气候科学、生物医学、天文学、化学等领域被广泛应用，但缺乏标准化工作流程，导致科学发现不可靠且难以重复。&lt;h4&gt;目的&lt;/h4&gt;提出一种结构化的无监督学习工作流程，以提高科学发现的可靠性和可重复性。&lt;h4&gt;方法&lt;/h4&gt;包括制定可验证的科学问题、进行稳健的数据准备和探索、使用多种建模技术、通过评估无监督学习结论的稳定性和泛化能力进行严格验证，以及促进结果的有效沟通和记录。&lt;h4&gt;主要发现&lt;/h4&gt;通过天文学案例研究，展示了验证的重要性，并说明了精心设计的无监督学习工作流程如何促进科学发现。&lt;h4&gt;结论&lt;/h4&gt;采用结构化的无监督学习工作流程可以显著提高科学发现的可靠性和可重复性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised machine learning is widely used to mine large, unlabeleddatasets to make data-driven discoveries in critical domains such as climatescience, biomedicine, astronomy, chemistry, and more. However, despite itswidespread utilization, there is a lack of standardization in unsupervisedlearning workflows for making reliable and reproducible scientific discoveries.In this paper, we present a structured workflow for using unsupervised learningtechniques in science. We highlight and discuss best practices starting withformulating validatable scientific questions, conducting robust datapreparation and exploration, using a range of modeling techniques, performingrigorous validation by evaluating the stability and generalizability ofunsupervised learning conclusions, and promoting effective communication anddocumentation of results to ensure reproducible scientific discoveries. Toillustrate our proposed workflow, we present a case study from astronomy,seeking to refine globular clusters of Milky Way stars based upon theirchemical composition. Our case study highlights the importance of validationand illustrates how the benefits of a carefully-designed workflow forunsupervised learning can advance scientific discovery.</description>
      <author>example@mail.com (Andersen Chang, Tiffany M. Tang, Tarek M. Zikry, Genevera I. Allen)</author>
      <guid isPermaLink="false">2506.04553v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Physics Informed Capsule Enhanced Variational AutoEncoder for Underwater Image Enhancement</title>
      <link>http://arxiv.org/abs/2506.04753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的双流架构，通过显式集成Jaffe-McGlamery物理模型和基于胶囊聚类的特征表示学习，实现了最先进的水下图像增强。&lt;h4&gt;背景&lt;/h4&gt;水下图像增强是一个具有挑战性的领域，需要同时考虑物理和感知因素。&lt;h4&gt;目的&lt;/h4&gt;开发一种参数自由的水下图像增强方法，同时保持语义结构和细粒度细节。&lt;h4&gt;方法&lt;/h4&gt;该方法同时估计传输图和空间变化的背景光，通过专门的物理估计器，同时在并行流中通过胶囊聚类提取实体级特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在六个具有挑战性的基准测试中进行了广泛的实验，结果表明，与现有最佳方法相比，PSNR提高了0.5dB，同时计算复杂度（FLOPs）减少了三分之二，或者与具有相似计算预算的方法相比，PSNR提高了超过1dB。&lt;h4&gt;结论&lt;/h4&gt;该方法在物理遵守和感知质量方面都取得了显著的成果，并且计算效率高。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新的双流架构，通过显式集成Jaffe-McGlamery物理模型与基于胶囊聚类的特征表示学习，实现了最先进的水下图像增强。我们的方法同时估计传输图和空间变化的背景光，通过专门的物理估计器，同时在并行流中通过胶囊聚类提取实体级特征。这种物理引导的方法实现了参数自由增强，同时尊重水下形成约束，并保持语义结构和细粒度细节。我们的方法还具有一个新颖的优化目标，确保在多个空间频率上既符合物理约束又具有良好的感知质量。为了验证我们的方法，我们在六个具有挑战性的基准测试中进行了广泛的实验。结果表明，与现有最佳方法相比，PSNR提高了0.5dB，同时计算复杂度（FLOPs）减少了三分之二，或者与具有相似计算预算的方法相比，PSNR提高了超过1dB。代码和数据将在https://github.com/iN1k1/上提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel dual-stream architecture that achieves state-of-the-artunderwater image enhancement by explicitly integrating the Jaffe-McGlameryphysical model with capsule clustering-based feature representation learning.Our method simultaneously estimates transmission maps and spatially-varyingbackground light through a dedicated physics estimator while extractingentity-level features via capsule clustering in a parallel stream. Thisphysics-guided approach enables parameter-free enhancement that respectsunderwater formation constraints while preserving semantic structures andfine-grained details. Our approach also features a novel optimization objectiveensuring both physical adherence and perceptual quality across multiple spatialfrequencies. To validate our approach, we conducted extensive experimentsacross six challenging benchmarks. Results demonstrate consistent improvementsof $+0.5$dB PSNR over the best existing methods while requiring only one-thirdof their computational complexity (FLOPs), or alternatively, more than $+1$dBPSNR improvement when compared to methods with similar computational budgets.Code and data \textit{will} be available at https://github.com/iN1k1/.</description>
      <author>example@mail.com (Niki Martinel, Rita Pucci)</author>
      <guid isPermaLink="false">2506.04753v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Influence Functions for Edge Edits in Non-Convex Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.04694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种适用于图神经网络（GNNs）的近端Bregman响应函数，用于更有效地预测边删除的影响，提高GNN的可解释性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;理解个体边对图神经网络行为的影响对于提高其可解释性和鲁棒性至关重要。现有的图影响函数方法依赖于严格的凸性假设，只考虑边删除的影响，而忽略了边插入的影响，并且未能捕捉到这些修改引起的信息传播变化。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来准确预测GNNs中边删除和插入的影响。&lt;h4&gt;方法&lt;/h4&gt;提出了一种适用于GNNs的近端Bregman响应函数，该方法放宽了凸性要求，并使影响预测适用于标准的神经网络架构。此外，该方法明确考虑了信息传播效应，并将影响预测扩展到边删除和插入。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法能够对现实世界数据集中的不同GNNs特性进行准确的影响预测。此外，影响函数在图重连和对抗攻击等应用中表现出多功能性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法可以有效地预测GNNs中边删除和插入的影响，为提高GNN的可解释性和鲁棒性提供了新的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding how individual edges influence the behavior of graph neuralnetworks (GNNs) is essential for improving their interpretability androbustness. Graph influence functions have emerged as promising tools toefficiently estimate the effects of edge deletions without retraining. However,existing influence prediction methods rely on strict convexity assumptions,exclusively consider the influence of edge deletions while disregarding edgeinsertions, and fail to capture changes in message propagation caused by thesemodifications. In this work, we propose a proximal Bregman response functionspecifically tailored for GNNs, relaxing the convexity requirement and enablingaccurate influence prediction for standard neural network architectures.Furthermore, our method explicitly accounts for message propagation effects andextends influence prediction to both edge deletions and insertions in aprincipled way. Experiments with real-world datasets demonstrate accurateinfluence predictions for different characteristics of GNNs. We furtherdemonstrate that the influence function is versatile in applications such asgraph rewiring and adversarial attacks.</description>
      <author>example@mail.com (Jaeseung Heo, Kyeongheung Yun, Seokwon Yoon, MoonJeong Park, Jungseul Ok, Dongwoo Kim)</author>
      <guid isPermaLink="false">2506.04694v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Contrastive Learning in Session-based Recommendation</title>
      <link>http://arxiv.org/abs/2506.05044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted by Pattern Recognition&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MACL的新型多模态自适应对比学习框架，用于解决基于会话的推荐中的数据稀疏性问题，并通过实验证明了其在真实世界数据集上的优越性。&lt;h4&gt;背景&lt;/h4&gt;会话推荐旨在基于用户有限行为预测匿名用户的意图，对比学习在此任务中表现出缓解数据稀疏性的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提升基于会话的推荐系统，解决现有对比学习方法存在的三个问题：忽视项目级稀疏性、未确保增强视图的语义一致性、对正负信号的处理不平等。&lt;h4&gt;方法&lt;/h4&gt;设计了一个多模态增强策略来生成语义一致的项目和会话级视图，并提出了一种自适应对比损失函数来区分正负信号的贡献，从而提升自监督学习。&lt;h4&gt;主要发现&lt;/h4&gt;现有的基于对比学习的方法存在三个主要障碍：忽视项目级稀疏性、未确保增强视图的语义一致性、对正负信号的处理不平等。&lt;h4&gt;结论&lt;/h4&gt;MACL在三个真实世界数据集上的实验结果表明，其优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于会话的推荐旨在基于有限的行为预测匿名用户的意图。对比学习具有缓解数据稀疏性的能力，但现有的基于对比学习的方法仍存在三个问题：它们忽视了项目级稀疏性，主要关注会话级稀疏性；它们通常使用项目ID（如裁剪、掩码和重排）来增强会话，未能确保增强视图的语义一致性；它们对正负信号一视同仁，没有考虑它们的效用差异。因此，我们提出了一种新的多模态自适应对比学习框架，称为MACL，用于基于会话的推荐。在MACL中，我们设计了一种多模态增强策略，通过利用项目多模态特征生成语义一致的项目和会话级视图。此外，我们还提出了一种自适应对比损失函数，以区分正负信号的不同贡献，从而提高自监督学习。在三个真实世界数据集上的大量实验表明，MACL优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Session-based recommendation aims to predict intents of anonymous users basedon limited behaviors. With the ability in alleviating data sparsity,contrastive learning is prevailing in the task. However, we spot that existingcontrastive learning based methods still suffer from three obstacles: (1) theyoverlook item-level sparsity and primarily focus on session-level sparsity; (2)they typically augment sessions using item IDs like crop, mask and reorder,failing to ensure the semantic consistency of augmented views; (3) they treatall positive-negative signals equally, without considering their varyingutility. To this end, we propose a novel multi-modal adaptive contrastivelearning framework called MACL for session-based recommendation. In MACL, amulti-modal augmentation is devised to generate semantically consistent viewsat both item and session levels by leveraging item multi-modal features.Besides, we present an adaptive contrastive loss that distinguishes varyingcontributions of positive-negative signals to improve self-supervised learning.Extensive experiments on three real-world datasets demonstrate the superiorityof MACL over state-of-the-art methods.</description>
      <author>example@mail.com (Xiaokun Zhang, Bo Xu, Fenglong Ma, Zhizheng Wang, Liang Yang, Hongfei Lin)</author>
      <guid isPermaLink="false">2506.05044v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Neurosymbolic Artificial Intelligence for Robust Network Intrusion Detection: From Scratch to Transfer Learning</title>
      <link>http://arxiv.org/abs/2506.04454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 5 figures, 11 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文扩展了ODXU神经符号AI框架，用于网络入侵检测系统，提高了鲁棒性、可解释性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;网络入侵检测系统在保护数字基础设施免受复杂网络威胁方面发挥着重要作用。&lt;h4&gt;目的&lt;/h4&gt;提高网络入侵检测系统的鲁棒性、可解释性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;ODXU框架结合了深度嵌入聚类、XGBoost符号推理和不确定性量化。使用基于分数的方法和基于元模型的技术来评估预测的可靠性，并开发了迁移学习策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ODXU在CIC-IDS-2017数据集上优于传统神经网络模型。迁移学习策略在ACI-IoT-2023数据集上表现出色，即使在样本量较少的情况下也优于传统神经网络模型。基于元模型的不确定性量化方法在两个数据集上都优于基于分数的方法。&lt;h4&gt;结论&lt;/h4&gt;ODXU框架及其迁移学习策略在网络安全领域具有潜在的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Network Intrusion Detection Systems (NIDS) play a vital role in protectingdigital infrastructures against increasingly sophisticated cyber threats. Inthis paper, we extend ODXU, a Neurosymbolic AI (NSAI) framework that integratesdeep embedded clustering for feature extraction, symbolic reasoning usingXGBoost, and comprehensive uncertainty quantification (UQ) to enhancerobustness, interpretability, and generalization in NIDS. The extended ODXUincorporates score-based methods (e.g., Confidence Scoring, Shannon Entropy)and metamodel-based techniques, including SHAP values and Information Gain, toassess the reliability of predictions. Experimental results on the CIC-IDS-2017dataset show that ODXU outperforms traditional neural models across sixevaluation metrics, including classification accuracy and false omission rate.While transfer learning has seen widespread adoption in fields such as computervision and natural language processing, its potential in cybersecurity has notbeen thoroughly explored. To bridge this gap, we develop a transfer learningstrategy that enables the reuse of a pre-trained ODXU model on a differentdataset. Our ablation study on ACI-IoT-2023 demonstrates that the optimaltransfer configuration involves reusing the pre-trained autoencoder, retrainingthe clustering module, and fine-tuning the XGBoost classifier, and outperformstraditional neural models when trained with as few as 16,000 samples(approximately 50% of the training data). Additionally, results show thatmetamodel-based UQ methods consistently outperform score-based approaches onboth datasets.</description>
      <author>example@mail.com (Huynh T. T. Tran, Jacob Sander, Achraf Cohen, Brian Jalaian, Nathaniel D. Bastian)</author>
      <guid isPermaLink="false">2506.04454v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>UAV4D: Dynamic Neural Rendering of Human-Centric UAV Imagery using Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.05011v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了UAV4D框架，旨在解决无人机捕获场景中的渲染挑战，特别是在单目摄像头设置、俯视视角和多个人物移动的情况下。&lt;h4&gt;背景&lt;/h4&gt;现有的动态神经渲染方法未能解决无人机捕获场景中的独特挑战，特别是涉及单目摄像头设置、俯视视角和多个小型移动人物的场景，这些场景在现有数据集中没有得到充分体现。&lt;h4&gt;目的&lt;/h4&gt;提出UAV4D框架，实现对无人机捕获的动态现实场景进行逼真渲染，特别是从单目视频数据中重建具有多个移动行人的动态场景，而不需要额外的传感器。&lt;h4&gt;方法&lt;/h4&gt;使用3D基础模型和人体网格重建模型重建场景背景和人物。提出了一种新颖的方法来解决场景尺度模糊问题，通过识别人物-场景接触点来将人物和场景放置在世界坐标中。利用SMPL模型和背景网格初始化高斯斑点，实现场景的整体渲染。&lt;h4&gt;主要发现&lt;/h4&gt;在三个复杂无人机捕获数据集（VisDrone、Manipal-UAV和Okutama-Action）上评估了该方法，这些数据集具有不同的特征，每个数据集中有10~50个人物。结果表明，该方法在新型视图合成方面优于现有方法，实现了1.5 dB PSNR的改进和更优的视觉清晰度。&lt;h4&gt;结论&lt;/h4&gt;UAV4D框架在新型视图合成方面具有显著优势，提高了渲染质量，为无人机捕获的动态场景提供了更逼真的渲染效果。&lt;h4&gt;翻译&lt;/h4&gt;尽管在动态神经渲染方面取得了显著进展，但现有方法未能解决无人机捕获场景中提出的独特挑战，特别是那些涉及单目摄像头设置、俯视视角和多个小型移动人物的场景，这些场景在现有数据集中没有得到充分体现。在这项工作中，我们介绍了UAV4D，这是一个框架，旨在实现对无人机捕获的动态现实场景进行逼真渲染。具体来说，我们解决了从单目视频数据中重建具有多个移动行人的动态场景的挑战，而不需要额外的传感器。我们使用3D基础模型和人体网格重建模型来重建场景背景和人物。我们提出了一种新颖的方法来解决问题场景尺度模糊，通过识别人物-场景接触点将人物和场景放置在世界坐标中。此外，我们利用SMPL模型和背景网格来初始化高斯斑点，实现场景的整体渲染。我们在三个复杂无人机捕获数据集（VisDrone、Manipal-UAV和Okutama-Action）上评估了我们的方法，这些数据集具有不同的特征和10~50个人物。我们的结果表明，与现有方法相比，我们的方法在新型视图合成方面具有优势，实现了1.5 dB PSNR的改进和更优的视觉清晰度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite significant advancements in dynamic neural rendering, existingmethods fail to address the unique challenges posed by UAV-captured scenarios,particularly those involving monocular camera setups, top-down perspective, andmultiple small, moving humans, which are not adequately represented in existingdatasets. In this work, we introduce UAV4D, a framework for enablingphotorealistic rendering for dynamic real-world scenes captured by UAVs.Specifically, we address the challenge of reconstructing dynamic scenes withmultiple moving pedestrians from monocular video data without the need foradditional sensors. We use a combination of a 3D foundation model and a humanmesh reconstruction model to reconstruct both the scene background and humans.We propose a novel approach to resolve the scene scale ambiguity and place bothhumans and the scene in world coordinates by identifying human-scene contactpoints. Additionally, we exploit the SMPL model and background mesh toinitialize Gaussian splats, enabling holistic scene rendering. We evaluated ourmethod on three complex UAV-captured datasets: VisDrone, Manipal-UAV, andOkutama-Action, each with distinct characteristics and 10~50 humans. Ourresults demonstrate the benefits of our approach over existing methods in novelview synthesis, achieving a 1.5 dB PSNR improvement and superior visualsharpness.</description>
      <author>example@mail.com (Jaehoon Choi, Dongki Jung, Christopher Maxey, Yonghan Lee, Sungmin Eum, Dinesh Manocha, Heesung Kwon)</author>
      <guid isPermaLink="false">2506.05011v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Learning dissection trajectories from expert surgical videos via imitation learning with equivariant diffusion</title>
      <link>http://arxiv.org/abs/2506.04716v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为iDPOE的新方法，用于通过模仿学习预测ESD手术中的切割轨迹，以提升手术技能训练并简化学习过程。&lt;h4&gt;背景&lt;/h4&gt;尽管内窥镜黏膜下剥离术（ESD）是一种成熟的移除上皮病变的技术，但预测ESD视频中的切割轨迹对于提高手术技能训练和简化学习过程具有重要意义，这一领域仍处于探索阶段。&lt;h4&gt;目的&lt;/h4&gt;为了解决在处理不确定的未来动作、学习几何对称性和将技能推广到不同的手术场景中存在的挑战，本文旨在提出一种新的方法来预测ESD手术中的切割轨迹。&lt;h4&gt;方法&lt;/h4&gt;iDPOE方法通过联合状态动作分布来模拟专家行为，捕捉切割轨迹的随机性，并通过嵌入等变性来增强模型对几何对称性的泛化能力。此外，通过将扩散模型纳入策略学习，iDPOE确保了高效的训练和采样，并开发了一种前向过程引导的动作推理策略来解决状态不匹配问题。&lt;h4&gt;主要发现&lt;/h4&gt;使用近2000个剪辑的ESD视频数据集进行实验，结果表明，iDPOE方法在轨迹预测方面优于现有的显式和隐式方法。&lt;h4&gt;结论&lt;/h4&gt;iDPOE是首次将模仿学习应用于手术技能发展，特别是用于切割轨迹预测。&lt;h4&gt;翻译&lt;/h4&gt;摘要：内窥镜黏膜下剥离术（ESD）是一种成熟的移除上皮病变的技术。预测ESD视频中的切割轨迹对于提高手术技能训练和简化学习过程具有重要意义，尽管这一领域仍处于探索阶段。虽然模仿学习在从专家演示中获取技能方面显示出希望，但在处理不确定的未来动作、学习几何对称性和将技能推广到不同的手术场景中仍然存在挑战。为了解决这些问题，我们提出了一种新的方法：具有等变性表示的隐式扩散策略模仿学习（iDPOE）。我们的方法通过联合状态动作分布来模拟专家行为，捕捉切割轨迹的随机性，并通过将扩散模型纳入策略学习，确保了高效的训练和采样，从而实现了更准确的预测和更好的泛化。此外，我们通过将等变性嵌入到学习过程中，增强了模型对几何对称性的泛化能力。为了解决状态不匹配问题，我们开发了一种前向过程引导的动作推理策略进行条件采样。使用近2000个剪辑的ESD视频数据集进行的实验结果表明，我们的方法在轨迹预测方面优于现有的显式和隐式方法。据我们所知，这是首次将模仿学习应用于手术技能发展，特别是用于切割轨迹预测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.media.2025.103599&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Endoscopic Submucosal Dissection (ESD) is a well-established technique forremoving epithelial lesions. Predicting dissection trajectories in ESD videosoffers significant potential for enhancing surgical skill training andsimplifying the learning process, yet this area remains underexplored. Whileimitation learning has shown promise in acquiring skills from expertdemonstrations, challenges persist in handling uncertain future movements,learning geometric symmetries, and generalizing to diverse surgical scenarios.To address these, we introduce a novel approach: Implicit Diffusion Policy withEquivariant Representations for Imitation Learning (iDPOE). Our method modelsexpert behavior through a joint state action distribution, capturing thestochastic nature of dissection trajectories and enabling robust visualrepresentation learning across various endoscopic views. By incorporating adiffusion model into policy learning, iDPOE ensures efficient training andsampling, leading to more accurate predictions and better generalization.Additionally, we enhance the model's ability to generalize to geometricsymmetries by embedding equivariance into the learning process. To addressstate mismatches, we develop a forward-process guided action inference strategyfor conditional sampling. Using an ESD video dataset of nearly 2000 clips,experimental results show that our approach surpasses state-of-the-art methods,both explicit and implicit, in trajectory prediction. To the best of ourknowledge, this is the first application of imitation learning to surgicalskill development for dissection trajectory prediction.</description>
      <author>example@mail.com (Hongyu Wang, Yonghao Long, Yueyao Chen, Hon-Chi Yip, Markus Scheppach, Philip Wai-Yan Chiu, Yeung Yam, Helen Mei-Ling Meng, Qi Dou)</author>
      <guid isPermaLink="false">2506.04716v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Object-X: Learning to Reconstruct Multi-Modal 3D Object Representations</title>
      <link>http://arxiv.org/abs/2506.04789v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Object-X的多模态物体表示框架，能够编码丰富的物体嵌入（如图像、点云、文本），并将其解码为详细的几何和视觉重建。&lt;h4&gt;背景&lt;/h4&gt;学习有效的多模态3D物体表示对于增强现实和机器人等应用至关重要。现有方法通常依赖于针对特定任务的嵌入，这些嵌入要么用于语义理解，要么用于几何重建，因此通常不能解码为显式的几何形状，也不能跨任务重用。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够编码和重建多模态物体表示的通用框架。&lt;h4&gt;方法&lt;/h4&gt;Object-X通过在3D体素网格中几何地定位捕获的模态，并学习一个非结构化的嵌入，融合体素信息和物体属性来操作。该嵌入使基于3D高斯Splatting的物体重建成为可能，同时支持包括场景对齐、单图像3D物体重建和定位在内的多种下游任务。&lt;h4&gt;主要发现&lt;/h4&gt;在两个具有挑战性的真实世界数据集上的评估表明，Object-X产生了与标准3D高斯Splatting相当的高保真新视图合成，同时显著提高了几何精度。此外，Object-X在场景对齐和定位方面与专用方法具有竞争力。关键的是，与传统的基于图像或点云的方法相比，我们的以物体为中心的描述符所需的存储量降低了3-4个数量级。&lt;h4&gt;结论&lt;/h4&gt;Object-X是一种可扩展且高度实用的多模态3D场景表示解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning effective multi-modal 3D representations of objects is essential fornumerous applications, such as augmented reality and robotics. Existing methodsoften rely on task-specific embeddings that are tailored either for semanticunderstanding or geometric reconstruction. As a result, these embeddingstypically cannot be decoded into explicit geometry and simultaneously reusedacross tasks. In this paper, we propose Object-X, a versatile multi-modalobject representation framework capable of encoding rich object embeddings(e.g. images, point cloud, text) and decoding them back into detailed geometricand visual reconstructions. Object-X operates by geometrically grounding thecaptured modalities in a 3D voxel grid and learning an unstructured embeddingfusing the information from the voxels with the object attributes. The learnedembedding enables 3D Gaussian Splatting-based object reconstruction, while alsosupporting a range of downstream tasks, including scene alignment, single-image3D object reconstruction, and localization. Evaluations on two challengingreal-world datasets demonstrate that Object-X produces high-fidelity novel-viewsynthesis comparable to standard 3D Gaussian Splatting, while significantlyimproving geometric accuracy. Moreover, Object-X achieves competitiveperformance with specialized methods in scene alignment and localization.Critically, our object-centric descriptors require 3-4 orders of magnitude lessstorage compared to traditional image- or point cloud-based approaches,establishing Object-X as a scalable and highly practical solution formulti-modal 3D scene representation.</description>
      <author>example@mail.com (Gaia Di Lorenzo, Federico Tombari, Marc Pollefeys, Daniel Barath)</author>
      <guid isPermaLink="false">2506.04789v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>The Oversmoothing Fallacy: A Misguided Narrative in GNN Research</title>
      <link>http://arxiv.org/abs/2506.04653v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了深度图神经网络（GNNs）中过度平滑问题，并提出了对深度GNN架构进一步探索的建议。&lt;h4&gt;背景&lt;/h4&gt;过度平滑被认为是构建深度GNN的主要障碍，限制了其性能。&lt;h4&gt;目的&lt;/h4&gt;本文旨在挑战过度平滑的影响被高估的观点，并倡导对深度GNN架构进行更深入的探索。&lt;h4&gt;方法&lt;/h4&gt;分析了GNN的三个核心操作：聚合、线性变换和非线性激活，并指出先前研究错误地将过度平滑与梯度消失混淆，后者是由变换和激活引起的，而不是聚合。&lt;h4&gt;主要发现&lt;/h4&gt;发现过度平滑并非GNN独有的问题，并展示了跳过连接和归一化等经典解决方案可以使深度GNN层成功堆叠而不降低性能。&lt;h4&gt;结论&lt;/h4&gt;本文澄清了关于过度平滑的误解，并为深度GNN的潜力提供了新的见解。&lt;h4&gt;翻译&lt;/h4&gt;Oversmoothing has been recognized as a main obstacle to building deep GraphNeural Networks (GNNs), limiting the performance. This position paper arguesthat the influence of oversmoothing has been overstated and advocates for afurther exploration of deep GNN architectures. Given the three core operations of GNNs, aggregation, linear transformation, and non-linear activation, we showthat prior studies have mistakenly confused oversmoothing with the vanishinggradient, caused by transformation and activation rather than aggregation. Ourfinding challenges prior beliefs about oversmoothing being unique to GNNs. Furthermore, we demonstrate that classical solutions such as skip connections and normalization enable the successful stacking of deep GNN layers without performance degradation. Our results clarify misconceptions about oversmoothing and shed new light on the potential of deep GNNs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Oversmoothing has been recognized as a main obstacle to building deep GraphNeural Networks (GNNs), limiting the performance. This position paper arguesthat the influence of oversmoothing has been overstated and advocates for afurther exploration of deep GNN architectures. Given the three core operationsof GNNs, aggregation, linear transformation, and non-linear activation, we showthat prior studies have mistakenly confused oversmoothing with the vanishinggradient, caused by transformation and activation rather than aggregation. Ourfinding challenges prior beliefs about oversmoothing being unique to GNNs.Furthermore, we demonstrate that classical solutions such as skip connectionsand normalization enable the successful stacking of deep GNN layers withoutperformance degradation. Our results clarify misconceptions about oversmoothingand shed new light on the potential of deep GNNs.</description>
      <author>example@mail.com (MoonJeong Park, Sunghyun Choi, Jaeseung Heo, Eunhyeok Park, Dongwoo Kim)</author>
      <guid isPermaLink="false">2506.04653v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Triple Attention Transformer Architecture for Time-Dependent Concrete Creep Prediction</title>
      <link>http://arxiv.org/abs/2506.04243v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的三重注意力Transformer架构，用于预测时间依赖性的混凝土蠕变，解决了当前方法中将时间仅视为输入参数而不是模拟变形发展序列性质的根本局限性。&lt;h4&gt;背景&lt;/h4&gt;当前方法在混凝土蠕变预测中处理时间的方式存在问题，没有充分捕捉到变形发展的序列性质。&lt;h4&gt;目的&lt;/h4&gt;将混凝土蠕变预测转化为自回归序列建模任务，类似于语言处理，以利用Transformer的自注意力机制捕捉历史蠕变模式中的长距离依赖关系。&lt;h4&gt;方法&lt;/h4&gt;模型实现了一个三流注意力框架，包括时间注意力用于序列进展、特征注意力用于材料属性相互作用以及批量注意力用于采样器之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;在标准化的每日测量数据集上评估，该架构实现了优异的性能，平均绝对百分比误差为1.63%，R2值为0.999，显著优于传统的经验模型和现有的机器学习方法。消融研究证实了注意力机制的关键作用，其中注意力池对模型性能的贡献最大。SHAP分析揭示了杨氏模量是主要的预测特征，其次是密度和抗压强度，这为工程应用提供了可解释性。部署的基于网络的界面促进了实际实施，允许使用标准实验室参数进行实时预测。&lt;h4&gt;结论&lt;/h4&gt;这项工作证明了将Transformer架构应用于材料科学问题的可行性，展示了数据驱动方法在结构行为预测和工程设计实践中的革命性潜力。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的三重注意力变换器架构，用于预测时间相关的混凝土蠕变，解决了当前方法中将时间仅仅视为输入参数而不是模拟变形发展序列性质的基本局限性。通过将混凝土蠕变预测转化为类似于语言处理的自回归序列建模任务，我们的架构利用了变换器的自注意力机制来捕捉历史蠕变模式中的长距离依赖关系。该模型实现了包含时间注意力（用于序列进展）、特征注意力（用于材料属性相互作用）和批量注意力（用于采样器之间的关系）的三流注意力框架。在跨度为160天的标准化每日测量数据集上评估，该架构实现了卓越的性能，平均绝对百分比误差为1.63%，所有数据集的R2值为0.999，显著优于传统的经验模型和现有的机器学习方法。消融研究证实了注意力机制的关键作用，其中注意力池对模型性能的贡献最大。SHAP分析揭示了杨氏模量是主要的预测特征，其次是密度和抗压强度，这为工程应用提供了可解释性。部署的基于网络的界面促进了实际实施，允许使用标准实验室参数进行实时预测。这项工作证明了将变换器架构应用于材料科学问题的可行性，展示了数据驱动方法在结构行为预测和工程设计实践中的革命性潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel Triple Attention Transformer Architecture forpredicting time-dependent concrete creep, addressing fundamental limitations incurrent approaches that treat time as merely an input parameter rather thanmodeling the sequential nature of deformation development. By transformingconcrete creep prediction into an autoregressive sequence modeling task similarto language processing, our architecture leverages the transformer'sself-attention mechanisms to capture long-range dependencies in historicalcreep patterns. The model implements a triple-stream attention frameworkincorporating temporal attention for sequential progression, feature attentionfor material property interactions, and batch attention for inter-samplerelationships. Evaluated on experimental datasets with standardized dailymeasurements spanning 160 days, the architecture achieves exceptionalperformance with mean absolute percentage error of 1.63% and R2 values of 0.999across all datasets, substantially outperforming traditional empirical modelsand existing machine learning approaches. Ablation studies confirm the criticalrole of attention mechanisms, with attention pooling contributing mostsignificantly to model performance. SHAP analysis reveals Young's modulus asthe primary predictive feature, followed by density and compressive strength,providing interpretability essential for engineering applications. A deployedweb-based interface facilitates practical implementation, enabling real-timepredictions using standard laboratory parameters. This work establishes theviability of applying transformer architectures to materials science problems,demonstrating the potential for data-driven approaches to revolutionizestructural behavior prediction and engineering design practices.</description>
      <author>example@mail.com (Warayut Dokduea, Weerachart Tangchirapat, Sompote Youwai)</author>
      <guid isPermaLink="false">2506.04243v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Ignoring Directionality Leads to Compromised Graph Neural Network Explanations</title>
      <link>http://arxiv.org/abs/2506.04608v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNNs）在关键领域的应用，强调了在支持人类决策中可靠解释的重要性，并指出传统图对称化方法丢弃了方向信息，导致信息损失和误导性解释。通过理论和实证研究，证明了保留方向语义可以显著提高解释质量。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在关键领域越来越受欢迎，但在这些领域中，可靠的解释对于支持人类决策至关重要。&lt;h4&gt;目的&lt;/h4&gt;本文旨在分析图对称化方法对解释准确性的影响，并提出改进的方法以增强GNN的解释能力。&lt;h4&gt;方法&lt;/h4&gt;通过理论和实证研究，分析了图对称化方法对解释准确性的影响，并验证了保留方向语义对解释质量的提升。&lt;h4&gt;主要发现&lt;/h4&gt;图对称化方法导致信息损失和误导性解释，而保留方向语义可以显著提高解释质量。&lt;h4&gt;结论&lt;/h4&gt;本文强调了在安全关键应用中，图神经网络解释的必要性，特别是在保留方向语义方面。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) are increasingly used in critical domains, where reliable explanations are vital for supporting human decision-making. However, the common practice of graph symmetrization discards directional information, leading to significant information loss and misleading explanations. Our analysis demonstrates how this practice compromises explanation fidelity. Through theoretical and empirical studies, we show that preserving directional semantics significantly improves explanation quality, ensuring more faithful insights for human decision-makers. These findings highlight the need for direction-aware GNN explainability in security-critical applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are increasingly used in critical domains, wherereliable explanations are vital for supporting human decision-making. However,the common practice of graph symmetrization discards directional information,leading to significant information loss and misleading explanations. Ouranalysis demonstrates how this practice compromises explanation fidelity.Through theoretical and empirical studies, we show that preserving directionalsemantics significantly improves explanation quality, ensuring more faithfulinsights for human decision-makers. These findings highlight the need fordirection-aware GNN explainability in security-critical applications.</description>
      <author>example@mail.com (Changsheng Sun, Xinke Li, Jin Song Dong)</author>
      <guid isPermaLink="false">2506.04608v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Plan via Supervised Contrastive Learning and Strategic Interpolation: A Chess Case Study</title>
      <link>http://arxiv.org/abs/2506.04892v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于嵌入空间的直觉驱动规划模型，用于模拟人类在棋类游戏中的决策过程，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;现代棋类引擎通过深度树搜索和递归评估实现超人类水平的表现，而人类玩家则依赖直觉选择候选走法，并通过浅层搜索来验证。&lt;h4&gt;目的&lt;/h4&gt;为了模拟人类玩家的直觉驱动规划过程，本文提出了一种使用监督对比学习训练的transformer编码器，将棋盘状态嵌入到一个由位置评估结构化的潜在空间中。&lt;h4&gt;方法&lt;/h4&gt;在潜在空间中，距离反映了评估相似性，可视化的轨迹显示了游戏状态之间的可解释转换。通过在嵌入空间中前进到有利区域，模型可以在不依赖深度搜索的情况下进行走法选择。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，即使使用只有6层广度搜索，该模型也能达到估计的Elo等级分2593。模型性能随着模型大小和嵌入维度的增加而提高，表明潜在规划可能是传统搜索的可行替代方案。&lt;h4&gt;结论&lt;/h4&gt;尽管本文的研究集中在棋类游戏上，但所提出的基于嵌入的规划方法可以推广到其他可学习状态评估的完美信息游戏中。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代象棋引擎通过深度树搜索和递归评估达到超人类的表现，而人类玩家则依靠直觉选择候选走法，随后通过浅层搜索来验证。为了模拟这种直觉驱动的规划过程，我们使用监督对比学习训练了一个transformer编码器，将棋盘状态嵌入到一个由位置评估结构化的潜在空间中。在这个空间中，距离反映了评估相似性，可视化的轨迹显示了游戏状态之间的可解释转换。我们证明了走法选择可以完全在这个嵌入空间内进行，通过向有利区域前进，而不依赖于深度搜索。尽管只使用了6层广度搜索，我们的模型达到了估计的Elo等级分2593。随着模型大小和嵌入维度的增加，性能得到提高，这表明潜在规划可能是传统搜索的可行替代方案。尽管我们关注的是象棋，但所提出的基于嵌入的规划方法可以推广到其他可学习状态评估的完美信息游戏中。所有源代码可在https://github.com/andrewhamara/SOLIS上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern chess engines achieve superhuman performance through deep tree searchand regressive evaluation, while human players rely on intuition to selectcandidate moves followed by a shallow search to validate them. To model thisintuition-driven planning process, we train a transformer encoder usingsupervised contrastive learning to embed board states into a latent spacestructured by positional evaluation. In this space, distance reflectsevaluative similarity, and visualized trajectories display interpretabletransitions between game states. We demonstrate that move selection can occurentirely within this embedding space by advancing toward favorable regions,without relying on deep search. Despite using only a 6-ply beam search, ourmodel achieves an estimated Elo rating of 2593. Performance improves with bothmodel size and embedding dimensionality, suggesting that latent planning mayoffer a viable alternative to traditional search. Although we focus on chess,the proposed embedding-based planning method can be generalized to otherperfect-information games where state evaluations are learnable. All sourcecode is available at https://github.com/andrewhamara/SOLIS.</description>
      <author>example@mail.com (Andrew Hamara, Greg Hamerly, Pablo Rivas, Andrew C. Freeman)</author>
      <guid isPermaLink="false">2506.04892v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Static Word Embeddings for Sentence Semantic Representation</title>
      <link>http://arxiv.org/abs/2506.04624v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了新的静态词嵌入方法，优化了句子的语义表示。&lt;h4&gt;背景&lt;/h4&gt;现有的静态词嵌入模型在句子语义任务上的表现有限。&lt;h4&gt;目的&lt;/h4&gt;提高句子语义任务的性能。&lt;h4&gt;方法&lt;/h4&gt;从预训练的SentenceTransformer中提取词嵌入，通过句子级主成分分析和知识蒸馏或对比学习进行改进。在推理阶段，通过平均词嵌入来表示句子，以降低计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;模型在单语和多语任务上均显著优于现有的静态模型，在某些数据集上甚至与基本的SentenceTransformer模型（SimCSE）相当。此外，方法成功移除了与句子语义无关的词嵌入成分，并根据词对句子语义的影响调整了向量范数。&lt;h4&gt;结论&lt;/h4&gt;提出的方法有效提升了句子语义表示的性能，并为句子语义任务提供了一种新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose new static word embeddings optimised for sentence semanticrepresentation. We first extract word embeddings from a pre-trained SentenceTransformer, and improve them with sentence-level principal component analysis,followed by either knowledge distillation or contrastive learning. Duringinference, we represent sentences by simply averaging word embeddings, whichrequires little computational cost. We evaluate models on both monolingual andcross-lingual tasks and show that our model substantially outperforms existingstatic models on sentence semantic tasks, and even rivals a basic SentenceTransformer model (SimCSE) on some data sets. Lastly, we perform a variety ofanalyses and show that our method successfully removes word embeddingcomponents that are irrelevant to sentence semantics, and adjusts the vectornorms based on the influence of words on sentence semantics.</description>
      <author>example@mail.com (Takashi Wada, Yuki Hirakawa, Ryotaro Shimizu, Takahiro Kawashima, Yuki Saito)</author>
      <guid isPermaLink="false">2506.04624v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Feature-Based Lie Group Transformer for Real-World Applications</title>
      <link>http://arxiv.org/abs/2506.04668v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法，通过结合特征提取和对象分割，将群分解理论应用于更真实的场景，以改善物体识别的表示学习。&lt;h4&gt;背景&lt;/h4&gt;表示学习旨在从现实世界的感官输入中获取有意义的表示，而无需监督。这种方法解释了人类发展的某些方面。&lt;h4&gt;目的&lt;/h4&gt;目的是提出一种新的方法，以克服传统表示学习方法的局限性，例如无法处理具有背景的低分辨率图像。&lt;h4&gt;方法&lt;/h4&gt;方法包括使用伽罗瓦代数理论中的群分解，将像素转换替换为特征转换，并将对象分割表示为在同一变换下的特征分组。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，传统的独立特征轴的解耦表示无法解释条件独立性，而新的方法通过结合特征提取和对象分割，提高了表示的通用性。&lt;h4&gt;结论&lt;/h4&gt;结论是，该方法有望更好地理解人类在现实世界中物体识别的发展。&lt;h4&gt;翻译&lt;/h4&gt;Representation learning aims to acquire meaningful representations from real-world sensory inputs without supervision. This method explains some aspects of human development. Various neural network (NN) models have been proposed that acquire empirically good representations. However, the formulation of a good representation has not been established. We recently proposed a method for categorizing changes between a pair of sensory inputs. A unique feature of this approach is that transformations between two sensory inputs are learned to satisfy algebraic structural constraints. Conventional representation learning often assumes that disentangled independent feature axes is a good representation; however, we found that such a representation cannot account for conditional independence. To overcome this problem, we proposed a new method using group decomposition in Galois algebra theory. Although this method is promising for defining a more general representation, it assumes pixel-to-pixel translation without feature extraction, and can only process low-resolution images with no background, which prevents real-world application. In this study, we provide a simple method to apply our group decomposition theory to a more realistic scenario by combining feature extraction and object segmentation. We replace pixel translation with feature translation and formulate object segmentation as grouping features under the same transformation. We validated the proposed method on a practical dataset containing both real-world object and background. We believe that our model will lead to a better understanding of human development of object recognition in the real world.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The main goal of representation learning is to acquire meaningfulrepresentations from real-world sensory inputs without supervision.Representation learning explains some aspects of human development. Variousneural network (NN) models have been proposed that acquire empirically goodrepresentations. However, the formulation of a good representation has not beenestablished. We recently proposed a method for categorizing changes between apair of sensory inputs. A unique feature of this approach is thattransformations between two sensory inputs are learned to satisfy algebraicstructural constraints. Conventional representation learning often assumes thatdisentangled independent feature axes is a good representation; however, wefound that such a representation cannot account for conditional independence.To overcome this problem, we proposed a new method using group decomposition inGalois algebra theory. Although this method is promising for defining a moregeneral representation, it assumes pixel-to-pixel translation without featureextraction, and can only process low-resolution images with no background,which prevents real-world application. In this study, we provide a simplemethod to apply our group decomposition theory to a more realistic scenario bycombining feature extraction and object segmentation. We replace pixeltranslation with feature translation and formulate object segmentation asgrouping features under the same transformation. We validated the proposedmethod on a practical dataset containing both real-world object and background.We believe that our model will lead to a better understanding of humandevelopment of object recognition in the real world.</description>
      <author>example@mail.com (Takayuki Komatsu, Yoshiyuki Ohmura, Kayato Nishitsunoi, Yasuo Kuniyoshi)</author>
      <guid isPermaLink="false">2506.04668v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Neural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction</title>
      <link>http://arxiv.org/abs/2506.04650v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了神经网络可重构性作为统一框架，将主流模型适应技术（模型重编程、提示微调和提示指令）联系起来，这些技术通过在接口处操纵信息来重新用途预训练模型，同时保持模型参数不变。&lt;h4&gt;背景&lt;/h4&gt;随着大规模预训练基础模型在规模和能力上的扩展，有效地适应特定下游任务变得越来越关键。现有的适应方法大多在孤立中发展，缺乏对它们之间相互关系的清晰理解。&lt;h4&gt;目的&lt;/h4&gt;提出神经网络可重构性作为统一框架，以便更好地理解和管理不同模型适应技术之间的联系。&lt;h4&gt;方法&lt;/h4&gt;引入了神经网络可重构性作为统一框架，并提出了一个分类法，从四个关键维度（操作格式、位置、操作符和输出对齐需求）对基于信息操纵的适应方法进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;该框架适用于不同数据模态，不依赖于特定模型架构。通过这一框架可以揭示现有技术如情境学习和思维链提示的理论联系和实践区别。&lt;h4&gt;结论&lt;/h4&gt;神经网络可重构性被视为有效模型适应的基本范式，并指出了由此产生的有希望的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了神经网络可重构性作为统一框架，将主流模型适应技术（模型重编程、提示微调和提示指令）联系起来，这些技术通过在接口处操纵信息来重新用途预训练模型，同时保持模型参数不变。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As large-scale pre-trained foundation models continue to expand in size andcapability, efficiently adapting them to specific downstream tasks has becomeincreasingly critical. Despite substantial progress, existing adaptationapproaches have evolved largely in isolation, without a clear understanding oftheir interrelationships. This survey introduces neural networkreprogrammability as a unifying framework that bridges mainstream modeladaptation techniques--model reprogramming, prompt tuning, and promptinstruction--previously fragmented research areas yet converges on a sharedprinciple: repurposing a pre-trained model by manipulating information at theinterfaces while keeping the model parameters frozen. These methods exploitneural networks' sensitivity to manipulation on different interfaces, be itthrough perturbing inputs, inserting tokens into intermediate layers, orproviding task-specific examples in context, to redirect model behaviorstowards desired outcomes. We then present a taxonomy that categorizes suchinformation manipulation-based adaptation approaches across four keydimensions: manipulation format (fixed or learnable), location (interfaceswhere manipulations occur), operator (how they are applied), and outputalignment requirement (post-processing needed to align outputs with downstreamtasks). Notably, this framework applies consistently across data modalities,independent of specific model architectures. Moreover, viewing establishedtechniques like in-context learning and chain-of-thought prompting through thislens reveals both their theoretical connections and practical distinctions. Wefurther analyze remaining technical challenges and ethical considerations,positioning neural network reprogrammability as a fundamental paradigm forefficient model adaptation. We lastly identify promising research directionsemerging from this integrative viewpoint.</description>
      <author>example@mail.com (Zesheng Ye, Chengyi Cai, Ruijiang Dong, Jianzhong Qi, Lei Feng, Pin-Yu Chen, Feng Liu)</author>
      <guid isPermaLink="false">2506.04650v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Follow-Your-Creation: Empowering 4D Creation through Video Inpainting</title>
      <link>http://arxiv.org/abs/2506.04590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://follow-your-creation.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为Follow-Your-Creation的4D视频创作框架，该框架能够从单目视频输入中生成和编辑4D内容。&lt;h4&gt;背景&lt;/h4&gt;目前4D视频创作需要多个视角的视频，而本文提出的方法只需要单目视频输入。&lt;h4&gt;目的&lt;/h4&gt;目的是通过视频修复技术生成和编辑4D视频内容。&lt;h4&gt;方法&lt;/h4&gt;使用视频修复基础模型作为生成先验，将4D视频创作重新定义为视频修复任务。通过生成复合遮蔽的修复视频数据来微调模型，同时使用深度点云渲染和编辑遮蔽来创建复合遮蔽数据集。设计了一种自我迭代调整策略来处理大范围相机运动下的时间一致性，并在推理过程中引入了时间包装模块来提高生成质量。&lt;h4&gt;主要发现&lt;/h4&gt;该方法有效地利用了基础模型的先验知识，同时保持了其原始性能，能够生成具有一致多视图连贯性的4D视频。此外，该方法支持基于提示的内容编辑，表现出强大的灵活性和优越性，在质量和多功能性方面均优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;该方法在4D视频生成和编辑方面具有显著优势，为单目视频到4D视频的转换提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;We introduce Follow-Your-Creation, a novel 4D video creation framework capable of both generating and editing 4D content from a single monocular video input. By leveraging a powerful video inpainting foundation model as a generative prior, we reformulate 4D video creation as a video inpainting task, enabling the model to fill in missing content caused by camera trajectory changes or user edits. To facilitate this, we generate composite masked inpainting video data to effectively fine-tune the model for 4D video generation. Given an input video and its associated camera trajectory, we first perform depth-based point cloud rendering to obtain invisibility masks that indicate the regions that should be completed. Simultaneously, editing masks are introduced to specify user-defined modifications, and these are combined with the invisibility masks to create a composite masks dataset. During training, we randomly sample different types of masks to construct diverse and challenging inpainting scenarios, enhancing the model's generalization and robustness in various 4D editing and generation tasks. To handle temporal consistency under large camera motion, we design a self-iterative tuning strategy that gradually increases the viewing angles during training, where the model is used to generate the next-stage training data after each fine-tuning iteration. Moreover, we introduce a temporal packaging module during inference to enhance generation quality. Our method effectively leverages the prior knowledge of the base model without degrading its original performance, enabling the generation of 4D videos with consistent multi-view coherence. In addition, our approach supports prompt-based content editing, demonstrating strong flexibility and significantly outperforming state-of-the-art methods in both quality and versatility.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Follow-Your-Creation, a novel 4D video creation frameworkcapable of both generating and editing 4D content from a single monocular videoinput. By leveraging a powerful video inpainting foundation model as agenerative prior, we reformulate 4D video creation as a video inpainting task,enabling the model to fill in missing content caused by camera trajectorychanges or user edits. To facilitate this, we generate composite maskedinpainting video data to effectively fine-tune the model for 4D videogeneration. Given an input video and its associated camera trajectory, we firstperform depth-based point cloud rendering to obtain invisibility masks thatindicate the regions that should be completed. Simultaneously, editing masksare introduced to specify user-defined modifications, and these are combinedwith the invisibility masks to create a composite masks dataset. Duringtraining, we randomly sample different types of masks to construct diverse andchallenging inpainting scenarios, enhancing the model's generalization androbustness in various 4D editing and generation tasks. To handle temporalconsistency under large camera motion, we design a self-iterative tuningstrategy that gradually increases the viewing angles during training, where themodel is used to generate the next-stage training data after each fine-tuningiteration. Moreover, we introduce a temporal packaging module during inferenceto enhance generation quality. Our method effectively leverages the priorknowledge of the base model without degrading its original performance,enabling the generation of 4D videos with consistent multi-view coherence. Inaddition, our approach supports prompt-based content editing, demonstratingstrong flexibility and significantly outperforming state-of-the-art methods inboth quality and versatility.</description>
      <author>example@mail.com (Yue Ma, Kunyu Feng, Xinhua Zhang, Hongyu Liu, David Junhao Zhang, Jinbo Xing, Yinhan Zhang, Ayden Yang, Zeyu Wang, Qifeng Chen)</author>
      <guid isPermaLink="false">2506.04590v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>"Don't Do That!": Guiding Embodied Systems through Large Language Model-based Constraint Generation</title>
      <link>http://arxiv.org/abs/2506.04500v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint; under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为STPR的约束生成框架，利用大型语言模型（LLMs）将自然语言中的约束条件转化为可执行的Python函数，以解决机器人导航中复杂空间、数学和条件约束的规划问题。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型（LLMs）的进步激发了将自然语言中的复杂约束条件融入机器人导航规划问题的兴趣。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，能够将自然语言描述的约束条件转化为机器可执行的代码，从而简化规划算法的输入。&lt;h4&gt;方法&lt;/h4&gt;STPR框架使用LLMs将“做什么”或“不做什么”的指令转化为Python函数，利用LLMs的编码能力将问题描述从语言转换为结构化和透明的代码。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，LLM生成的函数能够准确描述复杂的数学约束，并且这些函数适用于点云表示，与传统搜索算法结合使用。在Gazebo模拟环境中，STPR确保了在多个约束和场景下的完全合规性，并且运行时间短。&lt;h4&gt;结论&lt;/h4&gt;STPR框架不仅适用于大型LLMs，还可以与小型、特定于代码的LLMs结合使用，以低推理成本适用于广泛的紧凑型模型。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为STPR的约束生成框架，利用大型语言模型（LLMs）将自然语言中的约束条件转化为可执行的Python函数，以解决机器人导航中复杂空间、数学和条件约束的规划问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in large language models (LLMs) have spurred interest inrobotic navigation that incorporates complex spatial, mathematical, andconditional constraints from natural language into the planning problem. Suchconstraints can be informal yet highly complex, making it challenging totranslate into a formal description that can be passed on to a planningalgorithm. In this paper, we propose STPR, a constraint generation frameworkthat uses LLMs to translate constraints (expressed as instructions on ``whatnot to do'') into executable Python functions. STPR leverages the LLM's strongcoding capabilities to shift the problem description from language intostructured and transparent code, thus circumventing complex reasoning andavoiding potential hallucinations. We show that these LLM-generated functionsaccurately describe even complex mathematical constraints, and apply them topoint cloud representations with traditional search algorithms. Experiments ina simulated Gazebo environment show that STPR ensures full compliance acrossseveral constraints and scenarios, while having short runtimes. We also verifythat STPR can be used with smaller, code-specific LLMs, making it applicable toa wide range of compact models at low inference cost.</description>
      <author>example@mail.com (Aladin Djuhera, Amin Seffo, Masataro Asai, Holger Boche)</author>
      <guid isPermaLink="false">2506.04500v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>AuthGuard: Generalizable Deepfake Detection via Language Guidance</title>
      <link>http://arxiv.org/abs/2506.04501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AuthGuard的深度伪造检测框架，通过结合语言指导和视觉编码器，提高了深度伪造检测的泛化能力，并在多个数据集上取得了最先进的检测精度。&lt;h4&gt;背景&lt;/h4&gt;现有的深度伪造检测技术难以跟上不断发展的新型伪造方法，因为它们依赖于在训练期间学习到的统计伪象，这些伪象往往与特定的生成过程相关，可能不代表测试时遇到的新、未见过的深度伪造生成方法。&lt;h4&gt;目的&lt;/h4&gt;通过整合语言指导和人类似常识推理，提高深度伪造检测的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;1. 使用通用多语言语言模型（MLLM）和少量样本提示生成文本；2. 结合判别分类和图像-文本对比学习训练深度伪造视觉编码器；3. 将数据不确定性学习集成到视觉-语言对比学习中，减轻图像-文本监督中的噪声；4. 专家视觉编码器与语言模型（LLM）无缝接口。&lt;h4&gt;主要发现&lt;/h4&gt;AuthGuard在分布内和分布外设置中均实现了最先进的深度伪造检测精度，在DFDC数据集上AUC提高了6.15%，在DF40数据集上提高了16.68%。此外，AuthGuard显著增强了深度伪造推理能力，在DDVQA数据集上性能提高了24.69%。&lt;h4&gt;结论&lt;/h4&gt;AuthGuard框架通过结合语言指导和视觉编码器，实现了更泛化和可解释的深度伪造检测，同时提高了检测精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing deepfake detection techniques struggle to keep-up with theever-evolving novel, unseen forgeries methods. This limitation stems from theirreliance on statistical artifacts learned during training, which are often tiedto specific generation processes that may not be representative of samples fromnew, unseen deepfake generation methods encountered at test time. We proposethat incorporating language guidance can improve deepfake detectiongeneralization by integrating human-like commonsense reasoning -- such asrecognizing logical inconsistencies and perceptual anomalies -- alongsidestatistical cues. To achieve this, we train an expert deepfake vision encoderby combining discriminative classification with image-text contrastivelearning, where the text is generated by generalist MLLMs using few-shotprompting. This allows the encoder to extract both language-describable,commonsense deepfake artifacts and statistical forgery artifacts frompixel-level distributions. To further enhance robustness, we integrate datauncertainty learning into vision-language contrastive learning, mitigatingnoise in image-text supervision. Our expert vision encoder seamlesslyinterfaces with an LLM, further enabling more generalized and interpretabledeepfake detection while also boosting accuracy. The resulting framework,AuthGuard, achieves state-of-the-art deepfake detection accuracy in bothin-distribution and out-of-distribution settings, achieving AUC gains of 6.15%on the DFDC dataset and 16.68% on the DF40 dataset. Additionally, AuthGuardsignificantly enhances deepfake reasoning, improving performance by 24.69% onthe DDVQA dataset.</description>
      <author>example@mail.com (Guangyu Shen, Zhihua Li, Xiang Xu, Tianchen Zhao, Zheng Zhang, Dongsheng An, Zhuowen Tu, Yifan Xing, Qin Zhang)</author>
      <guid isPermaLink="false">2506.04501v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models</title>
      <link>http://arxiv.org/abs/2506.04586v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LESS的框架，该框架利用大型语言模型（LLMs）来校正从野外数据生成的伪标签，并在多种语言和任务上取得了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;LESS框架旨在通过结合LLMs和半监督学习技术，提高自动语音识别（ASR）和自动语音翻译（AST）等任务的性能。&lt;h4&gt;目的&lt;/h4&gt;LESS框架的目的是通过优化LLM知识迁移效率，提升从无监督数据生成的伪标签的质量。&lt;h4&gt;方法&lt;/h4&gt;LESS框架通过LLM对ASR或AST的伪标签进行细化，并采用数据过滤策略来增强LLM的知识迁移效率。&lt;h4&gt;主要发现&lt;/h4&gt;在普通话ASR和西班牙语到英语AST任务上，LESS实现了3.77%的绝对错误率（WER）降低，以及Callhome和Fisher测试集上的BLEU分数分别为34.0和64.7。&lt;h4&gt;结论&lt;/h4&gt;LESS框架在不同语言、任务和领域中的适应性得到了验证，并且通过消融实验揭示了利用LLM知识进行语音处理应用的新见解。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为LESS（大型语言模型增强半监督学习）的通用框架，该框架利用大型语言模型（LLMs）来校正从野外数据生成的伪标签。在LESS框架中，来自无监督数据的自动语音识别（ASR）或自动语音翻译（AST）的伪标签通过LLM进行细化，并通过数据过滤策略进行增强，以优化LLM知识迁移效率。在普通话ASR和西班牙语到英语AST任务上的实验表明，LESS在Wenet语音测试集上实现了3.77%的显著绝对错误率（WER）降低，在Callhome和Fisher测试集上分别实现了34.0和64.7的BLEU分数。这些结果验证了LESS在不同语言、任务和领域中的适应性。通过各种LLMs和提示配置进行的消融研究为利用LLM派生的知识进行语音处理应用提供了新的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce LESS (Large Language Model Enhanced Semi-supervised Learning), aversatile framework that leverages Large Language Models (LLMs) to correctpseudo labels generated from in-the-wild data. Within the LESS framework,pseudo-labeled text from Automatic Speech Recognition (ASR) or Automatic SpeechTranslation (AST) of the unsupervised data is refined by an LLM, and augmentedby a data filtering strategy to optimize LLM knowledge transfer efficiency.Experiments on both Mandarin ASR and Spanish-to-English AST tasks show thatLESS achieves a notable absolute WER reduction of 3.77% on the Wenet Speechtest set, as well as BLEU scores of 34.0 and 64.7 on Callhome and Fisher testsets respectively. These results validate the adaptability of LESS acrossdifferent languages, tasks, and domains. Ablation studies conducted withvarious LLMs and prompt configurations provide novel insights into leveragingLLM-derived knowledge for speech processing applications.</description>
      <author>example@mail.com (Wen Ding, Fan Qian)</author>
      <guid isPermaLink="false">2506.04586v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Learning Smooth State-Dependent Traversability from Dense Point Clouds</title>
      <link>http://arxiv.org/abs/2506.04362v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SPARTA的方法，用于从点云数据中估计接近角度条件下的可通行性。&lt;h4&gt;背景&lt;/h4&gt;在越野自主导航中，地形可通行性往往依赖于车辆的状态，某些障碍物只能从特定方向通过。&lt;h4&gt;目的&lt;/h4&gt;为了解决学习这种交互关系的问题，即通过编码接近角度作为模型输入，本文旨在提出一种高效的方法。&lt;h4&gt;方法&lt;/h4&gt;SPARTA通过在网络中引入几何结构，输出一个在1-Sphere上的平滑分析函数，以预测任何接近角度的风险分布。&lt;h4&gt;主要发现&lt;/h4&gt;该函数由傅里叶基函数组成，由于其周期性和平滑性，具有很好的泛化能力。在仿真平台和实际硬件上，SPARTA均表现出良好的性能。&lt;h4&gt;结论&lt;/h4&gt;SPARTA在提高越野自主导航的可通行性预测方面具有显著优势，能够有效应对实际场景中的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A key open challenge in off-road autonomy is that the traversability ofterrain often depends on the vehicle's state. In particular, some obstacles areonly traversable from some orientations. However, learning this interaction byencoding the angle of approach as a model input demands a large and diversetraining dataset and is computationally inefficient during planning due torepeated model inference. To address these challenges, we present SPARTA, amethod for estimating approach angle conditioned traversability from pointclouds. Specifically, we impose geometric structure into our network byoutputting a smooth analytical function over the 1-Sphere that predicts riskdistribution for any angle of approach with minimal overhead and can be reusedfor subsequent queries. The function is composed of Fourier basis functions,which has important advantages for generalization due to their periodic natureand smoothness. We demonstrate SPARTA both in a high-fidelity simulationplatform, where our model achieves a 91\% success rate crossing a 40m boulderfield (compared to 73\% for the baseline), and on hardware, illustrating thegeneralization ability of the model to real-world settings.</description>
      <author>example@mail.com (Zihao Dong, Alan Papalia, Leonard Jung, Alenna Spiro, Philip R. Osteen, Christa S. Robison, Michael Everett)</author>
      <guid isPermaLink="false">2506.04362v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>DAS-MAE: A self-supervised pre-training framework for universal and high-performance representation learning of distributed fiber-optic acoustic sensing</title>
      <link>http://arxiv.org/abs/2506.04552v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了分布式光纤声学传感（DAS）技术，提出了一种名为DAS Masked AutoEncoder（DAS-MAE）的自监督预训练框架，用于分析大规模未标记的DAS信号。&lt;h4&gt;背景&lt;/h4&gt;DAS技术在分布式振动测量方面具有高空间分辨率和长测量范围的优势，但在分析二维时空DAS信号时存在分析挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种自监督预训练框架，用于学习DAS信号的表示，以解决DAS信号分析中的挑战。&lt;h4&gt;方法&lt;/h4&gt;设计了DAS-MAE框架，通过掩码重建任务学习信号的表示，并在少样本分类任务中进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;DAS-MAE在少样本分类任务中达到了1%的错误率和64.5%的相对改进，在外部损伤预防的实际应用中达到了5.0%的识别错误率，比从头开始的有监督训练提高了75.7%的相对改进。&lt;h4&gt;结论&lt;/h4&gt;DAS-MAE框架展示了高性能和通用性，有潜力成为分析大规模未标记DAS信号的基础模型。&lt;h4&gt;翻译&lt;/h4&gt;Distributed fiber-optic acoustic sensing (DAS) has emerged as a transformative approach for distributed vibration measurement with high spatial resolution and long measurement range while maintaining cost-efficiency. However, the two-dimensional spatial-temporal DAS signals present analytical challenges. The abstract signal morphology lacking intuitive physical correspondence complicates human interpretation, and its unique spatial-temporal coupling renders conventional image processing methods suboptimal. This study investigates spatial-temporal characteristics and proposes a self-supervised pre-training framework that learns signals' representations through a mask-reconstruction task. This framework is named the DAS Masked AutoEncoder (DAS-MAE). The DAS-MAE learns high-level representations (e.g., event class) without using labels. It achieves up to 1% error and 64.5% relative improvement (RI) over the semi-supervised baseline in few-shot classification tasks. In a practical external damage prevention application, DAS-MAE attains a 5.0% recognition error, marking a 75.7% RI over supervised training from scratch. These results demonstrate the high-performance and universal representations learned by the DAS-MAE framework, highlighting its potential as a foundation model for analyzing massive unlabeled DAS signals.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Distributed fiber-optic acoustic sensing (DAS) has emerged as atransformative approach for distributed vibration measurement with high spatialresolution and long measurement range while maintaining cost-efficiency.However, the two-dimensional spatial-temporal DAS signals present analyticalchallenges. The abstract signal morphology lacking intuitive physicalcorrespondence complicates human interpretation, and its uniquespatial-temporal coupling renders conventional image processing methodssuboptimal. This study investigates spatial-temporal characteristics andproposes a self-supervised pre-training framework that learns signals'representations through a mask-reconstruction task. This framework is named theDAS Masked AutoEncoder (DAS-MAE). The DAS-MAE learns high-level representations(e.g., event class) without using labels. It achieves up to 1% error and 64.5%relative improvement (RI) over the semi-supervised baseline in few-shotclassification tasks. In a practical external damage prevention application,DAS-MAE attains a 5.0% recognition error, marking a 75.7% RI over supervisedtraining from scratch. These results demonstrate the high-performance anduniversal representations learned by the DAS-MAE framework, highlighting itspotential as a foundation model for analyzing massive unlabeled DAS signals.</description>
      <author>example@mail.com (Junyi Duan, Jiageng Chen, Zuyuan He)</author>
      <guid isPermaLink="false">2506.04552v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>HuGeDiff: 3D Human Generation via Diffusion with Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.04351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种弱监督流程来解决3D人类生成中的挑战，包括生成精确的3D人类、细节控制、真实感、多样性、现实主义和标注问题。&lt;h4&gt;背景&lt;/h4&gt;3D人类生成在计算机视觉和图形学领域有广泛的应用，尽管有扩散模型、Neural Radiance Fields或Gaussian Splatting等生成AI的进展，但基于文本提示的精确3D人类生成控制仍然是一个开放挑战。&lt;h4&gt;目的&lt;/h4&gt;解决生成精确3D人类时面临的困难，如细节、手和面部渲染、真实感以及外观的可控性。&lt;h4&gt;方法&lt;/h4&gt;1. 使用最先进的图像扩散模型生成具有可控属性（如外观、种族、性别等）的逼真人类图像数据集。2. 提出一种基于transformer架构的高效图像特征到3D点云的映射方法。3. 训练一个基于相同文本提示的点云扩散模型，以生成原始样本。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，本文提出的方法在3D人类生成方面实现了数量级的速度提升，并显著提高了文本提示对齐、真实感和渲染质量。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地解决3D人类生成中的挑战，有望促进该领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D人类生成是一个在计算机视觉和图形学领域具有广泛应用的重要问题。尽管在生成AI，如扩散模型或Neural Radiance Fields或Gaussian Splatting等渲染方法方面取得了进展，但从文本提示控制精确的3D人类生成仍然是一个未解决的问题。当前的方法在细节、手和面部的精确渲染、人类真实感和外观的可控性方面存在困难。人类图像数据中缺乏多样性、现实主义和标注也是一个挑战，阻碍了基础3D人类模型的发展。我们提出了一种弱监督流程来尝试解决这些挑战。在第一步，我们使用最先进的图像扩散模型生成具有可控属性（如外观、种族、性别等）的逼真人类图像数据集。接下来，我们提出了一种基于transformer架构的高效的从图像特征到3D点云的映射方法。最后，我们通过训练一个基于生成原始样本的相同文本提示的点云扩散模型来闭合循环。我们展示了与现有方法相比，3D人类生成方面的数量级速度提升，以及显著提高的文本提示对齐、真实感和渲染质量。我们将提供代码和数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D human generation is an important problem with a wide range of applicationsin computer vision and graphics. Despite recent progress in generative AI suchas diffusion models or rendering methods like Neural Radiance Fields orGaussian Splatting, controlling the generation of accurate 3D humans from textprompts remains an open challenge. Current methods struggle with fine detail,accurate rendering of hands and faces, human realism, and controlability overappearance. The lack of diversity, realism, and annotation in human image dataalso remains a challenge, hindering the development of a foundational 3D humanmodel. We present a weakly supervised pipeline that tries to address thesechallenges. In the first step, we generate a photorealistic human image datasetwith controllable attributes such as appearance, race, gender, etc using astate-of-the-art image diffusion model. Next, we propose an efficient mappingapproach from image features to 3D point clouds using a transformer-basedarchitecture. Finally, we close the loop by training a point-cloud diffusionmodel that is conditioned on the same text prompts used to generate theoriginal samples. We demonstrate orders-of-magnitude speed-ups in 3D humangeneration compared to the state-of-the-art approaches, along withsignificantly improved text-prompt alignment, realism, and rendering quality.We will make the code and dataset available.</description>
      <author>example@mail.com (Maksym Ivashechkin, Oscar Mendez, Richard Bowden)</author>
      <guid isPermaLink="false">2506.04351v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>The Latent Space Hypothesis: Toward Universal Medical Representation Learning</title>
      <link>http://arxiv.org/abs/2506.04515v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  51 pages, 12 figures. A position paper examining the latent space  hypothesis - the proposition that diverse medical data can be represented in  shared latent spaces reflecting fundamental biological processes. The paper  discusses theoretical foundations, reviews supporting evidence, and considers  potential implications for medical AI and representation learning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于潜在空间假设的方法，通过将不同模态的医学数据统一到一个共享空间中，实现对疾病的个性化诊断、纵向监测和定制化治疗。&lt;h4&gt;背景&lt;/h4&gt;医学数据包括基因组序列、视网膜照片、结构化实验室结果和非结构化临床叙事等，这些数据虽然形式多样，但往往编码着关于同一生理状态的相似信息。&lt;h4&gt;目的&lt;/h4&gt;通过学习几何表示，将个体的健康状况、疾病进展和治疗干预在统一空间中表示出来，以实现对疾病的深入理解和个性化治疗。&lt;h4&gt;方法&lt;/h4&gt;采用潜在空间假设，将每个观察结果视为一个统一、层次化组织的流形上的投影，并通过学习到的几何表示来分析个体健康状态和疾病进展。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够揭示亚轨迹和患者特异性的变化方向，为个性化诊断、纵向监测和定制化治疗提供了定量依据。&lt;h4&gt;结论&lt;/h4&gt;尽管存在偏差放大、罕见疾病数据稀缺、隐私问题和因果关系区分等挑战，但通过使用规模感知编码器、在纵向数据流上进行持续学习和基于扰动的验证，这些挑战有望得到解决。&lt;h4&gt;翻译&lt;/h4&gt;摘要：医学数据范围从基因组序列和视网膜照片到结构化实验室结果和非结构化临床叙事。尽管这些模态看起来不同，但它们都编码了关于单一基础生理状态的相似信息。潜在空间假设将每个观察结果视为一个统一、层次化组织的流形的投影——就像同一三维物体投射的阴影。在这个学习到的几何表示中，个体的健康状况占据一个点，疾病进展描绘出一条轨迹，治疗干预对应一个有向向量。在共享空间中解释异质证据提供了一种审视常见疾病（如帕金森病或克罗恩病）的原理方法，这些疾病往往掩盖了多个病理生理实体，并涉及比以前认为更广泛的解剖区域。通过揭示亚轨迹和患者特定的变化方向，该框架为个性化诊断、纵向监测和定制化治疗提供了定量依据，将临床实践从按可能具有误导性的标签分组转向导航每个人的独特轨迹。挑战仍然存在——偏差放大、罕见疾病数据稀缺、隐私和因果关系区分——但规模感知编码器、在纵向数据流上进行持续学习和基于扰动的验证提供了可能的路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical data range from genomic sequences and retinal photographs tostructured laboratory results and unstructured clinical narratives. Althoughthese modalities appear disparate, many encode convergent information about asingle underlying physiological state. The Latent Space Hypothesis frames eachobservation as a projection of a unified, hierarchically organized manifold --much like shadows cast by the same three-dimensional object. Within thislearned geometric representation, an individual's health status occupies apoint, disease progression traces a trajectory, and therapeutic interventioncorresponds to a directed vector. Interpreting heterogeneous evidence in ashared space provides a principled way to re-examine eponymous conditions --such as Parkinson's or Crohn's -- that often mask multiple pathophysiologicalentities and involve broader anatomical domains than once believed. Byrevealing sub-trajectories and patient-specific directions of change, theframework supplies a quantitative rationale for personalised diagnosis,longitudinal monitoring, and tailored treatment, moving clinical practice awayfrom grouping by potentially misleading labels toward navigation of eachperson's unique trajectory. Challenges remain -- bias amplification, datascarcity for rare disorders, privacy, and the correlation-causation divide --but scale-aware encoders, continual learning on longitudinal data streams, andperturbation-based validation offer plausible paths forward.</description>
      <author>example@mail.com (Salil Patel)</author>
      <guid isPermaLink="false">2506.04515v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>SF$^2$Bench: Evaluating Data-Driven Models for Compound Flood Forecasting in South Florida</title>
      <link>http://arxiv.org/abs/2506.04281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  60 Pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了复合洪水的预测，介绍了SF2Bench这一综合时间序列集合，评估了六种模型方法在洪水预测中的性能，并探讨了不同特征对洪水预测的影响。&lt;h4&gt;背景&lt;/h4&gt;复合洪水的预测因气象、水文和海洋因素的复杂相互作用而具有挑战性，全球气候变化增加了洪水风险。&lt;h4&gt;目的&lt;/h4&gt;为了解决数据集的稀缺问题，本文引入了SF2Bench，以更详细地分析各因素对复合洪水的影响，并评估不同模型方法在洪水预测中的性能。&lt;h4&gt;方法&lt;/h4&gt;SF2Bench集成了潮汐、降雨、地下水和人类管理活动（闸门和泵控制）四个关键因素，并评估了六种模型方法：多层感知器、卷积神经网络、循环神经网络、图神经网络、转换器和大型语言模型。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验验证了不同关键特征对洪水预测的影响，分析了时间和空间方面的因素，并提供了关于历史数据和空间依赖性的见解。&lt;h4&gt;结论&lt;/h4&gt;不同方法在捕捉复合洪水中的复杂时间和空间依赖性方面具有不同的能力，SF2Bench和评估的模型方法有助于提高洪水预测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Forecasting compound floods presents a significant challenge due to theintricate interplay of meteorological, hydrological, and oceanographic factors.Analyzing compound floods has become more critical as the global climateincreases flood risks. Traditional physics-based methods, such as theHydrologic Engineering Center's River Analysis System, are oftentime-inefficient. Machine learning has recently demonstrated promise in bothmodeling accuracy and computational efficiency. However, the scarcity ofcomprehensive datasets currently hinders systematic analysis. Existingwater-related datasets are often limited by a sparse network of monitoringstations and incomplete coverage of relevant factors. To address thischallenge, we introduce SF2Bench, a comprehensive time series collection oncompound floods in South Florida, which integrates four key factors: tide,rainfall, groundwater, and human management activities (gate and pumpcontrolling). This integration allows for a more detailed analysis of theindividual contributions of these drivers to compound flooding and informs thedevelopment of improved flood forecasting approaches. To comprehensivelyevaluate the potential of various modeling paradigms, we assess the performanceof six categories of methods, encompassing Multilayer Perceptrons,Convolutional Neural Networks, Recurrent Neural Networks, Graph NeuralNetworks, Transformers, and Large Language Models. We verified the impact ofdifferent key features on flood forecasting through experiments. Our analysisexamines temporal and spatial aspects, providing insights into the influence ofhistorical data and spatial dependencies. The varying performance across theseapproaches underscores the diverse capabilities of each in capturing complextemporal and spatial dependencies inherent in compound floods.</description>
      <author>example@mail.com (Xu Zheng, Chaohao Lin, Sipeng Chen, Zhuomin Chen, Jimeng Shi, Wei Cheng, Jayantha Obeysekera, Jason Liu, Dongsheng Luo)</author>
      <guid isPermaLink="false">2506.04281v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Text Classification Using Contrastive Learning Informed Path Guided Hierarchy</title>
      <link>http://arxiv.org/abs/2506.04381v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2203.03825 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HTC-CLIP的分层文本分类方法，通过对比学习来学习层次感知的文本表示和文本引导的层次表示，实现了两种现有方法的结合，提高了分类性能。&lt;h4&gt;背景&lt;/h4&gt;分层文本分类（HTC）在处理复杂标签层次方面表现良好，被广泛应用于电子商务、客户服务和医疗等行业。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的HTC模型，结合两种现有方法的优势，以实现更好的分类性能。&lt;h4&gt;方法&lt;/h4&gt;HTC-CLIP模型利用对比学习学习层次感知的文本表示和文本引导的层次表示，并在训练过程中学习两个不同的类别概率分布。在推理阶段，结合两种表示来提高分类效果。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，HTC-CLIP模型能够有效结合两种方法，在两个公开数据集上相较于现有最佳模型，宏F1分数提升了0.99-2.37%。&lt;h4&gt;结论&lt;/h4&gt;HTC-CLIP是一种有效的分层文本分类方法，能够显著提高分类性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3233/FAIA230249&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hierarchical Text Classification (HTC) has recently gained traction given theability to handle complex label hierarchy. This has found applications indomains like E- commerce, customer care and medicine industry among otherreal-world applications. Existing HTC models either encode label hierarchyseparately and mix it with text encoding or guide the label hierarchy structurein the text encoder. Both approaches capture different characteristics of labelhierarchy and are complementary to each other. In this paper, we propose aHierarchical Text Classification using Contrastive Learning Informed Pathguided hierarchy (HTC-CLIP), which learns hierarchy-aware text representationand text informed path guided hierarchy representation using contrastivelearning. During the training of HTC-CLIP, we learn two different sets of classprobabilities distributions and during inference, we use the pooled output ofboth probabilities for each class to get the best of both representations. Ourresults show that the two previous approaches can be effectively combined intoone architecture to achieve improved performance. Tests on two public benchmarkdatasets showed an improvement of 0.99 - 2.37% in Macro F1 score using HTC-CLIPover the existing state-of-the-art models.</description>
      <author>example@mail.com (Neeraj Agrawal, Saurabh Kumar, Priyanka Bhatt, Tanishka Agarwal)</author>
      <guid isPermaLink="false">2506.04381v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Geometric Visual Fusion Graph Neural Networks for Multi-Person Human-Object Interaction Recognition in Videos</title>
      <link>http://arxiv.org/abs/2506.03440v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Expert Systems with Applications (ESWA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GeoVis-GNN的图形神经网络，用于视频中的HOI识别，通过结合视觉和几何特征，实现多模态融合，并通过建立实体特定表示来提高识别效果。&lt;h4&gt;背景&lt;/h4&gt;视频中的HOI识别需要理解视觉模式和几何关系随时间的变化，视觉特征捕捉外观上下文，几何特征提供结构模式，多模态特征融合是挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的方法来融合视觉和几何特征，并通过建立实体特定表示来提高HOI识别的准确性。&lt;h4&gt;方法&lt;/h4&gt;GeoVis-GNN采用双注意力特征融合和依赖实体图学习，从实体特定表示逐步构建到高级交互理解。&lt;h4&gt;主要发现&lt;/h4&gt;GeoVis-GNN在多种HOI场景中表现出色，包括两人交互、单人活动、双手动操作和复杂的并发部分交互。&lt;h4&gt;结论&lt;/h4&gt;GeoVis-GNN在HOI识别方面达到了最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;Human-Object Interaction (HOI) recognition in videos requires understanding both visual patterns and geometric relationships as they evolve over time. Visual and geometric features offer complementary strengths. Visual features capture appearance context, while geometric features provide structural patterns. Effectively fusing these multimodal features without compromising their unique characteristics remains challenging. We observe that establishing robust, entity-specific representations before modeling interactions helps preserve the strengths of each modality. Therefore, we hypothesize that a bottom-up approach is crucial for effective multimodal fusion. Following this insight, we propose the Geometric Visual Fusion Graph Neural Network (GeoVis-GNN), which uses dual-attention feature fusion combined with interdependent entity graph learning. It progressively builds from entity-specific representations toward high-level interaction understanding. To advance HOI recognition to real-world scenarios, we introduce the Concurrent Partial Interaction Dataset (MPHOI-120). It captures dynamic multi-person interactions involving concurrent actions and partial engagement. This dataset helps address challenges like complex human-object dynamics and mutual occlusions. Extensive experiments demonstrate the effectiveness of our method across various HOI scenarios. These scenarios include two-person interactions, single-person activities, bimanual manipulations, and complex concurrent partial interactions. Our method achieves state-of-the-art performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human-Object Interaction (HOI) recognition in videos requires understandingboth visual patterns and geometric relationships as they evolve over time.Visual and geometric features offer complementary strengths. Visual featurescapture appearance context, while geometric features provide structuralpatterns. Effectively fusing these multimodal features without compromisingtheir unique characteristics remains challenging. We observe that establishingrobust, entity-specific representations before modeling interactions helpspreserve the strengths of each modality. Therefore, we hypothesize that abottom-up approach is crucial for effective multimodal fusion. Following thisinsight, we propose the Geometric Visual Fusion Graph Neural Network(GeoVis-GNN), which uses dual-attention feature fusion combined withinterdependent entity graph learning. It progressively builds fromentity-specific representations toward high-level interaction understanding. Toadvance HOI recognition to real-world scenarios, we introduce the ConcurrentPartial Interaction Dataset (MPHOI-120). It captures dynamic multi-personinteractions involving concurrent actions and partial engagement. This datasethelps address challenges like complex human-object dynamics and mutualocclusions. Extensive experiments demonstrate the effectiveness of our methodacross various HOI scenarios. These scenarios include two-person interactions,single-person activities, bimanual manipulations, and complex concurrentpartial interactions. Our method achieves state-of-the-art performance.</description>
      <author>example@mail.com (Tanqiu Qiao, Ruochen Li, Frederick W. B. Li, Yoshiki Kubotani, Shigeo Morishima, Hubert P. H. Shum)</author>
      <guid isPermaLink="false">2506.03440v2</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>ExDiff: A Framework for Simulating Diffusion Processes on Complex Networks with Explainable AI Integration</title>
      <link>http://arxiv.org/abs/2506.04271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ExDiff是一个集成网络模拟、图神经网络（GNN）和可解释人工智能（XAI）的交互式和模块化计算框架，用于模拟和解释扩散动态。&lt;h4&gt;背景&lt;/h4&gt;理解和控制复杂网络中的扩散过程对流行病学到信息科学等多个领域至关重要。&lt;h4&gt;目的&lt;/h4&gt;ExDiff旨在提供一种强大的、灵活的、易于使用的平台，以研究网络系统中扩散现象，促进方法创新和实践洞察。&lt;h4&gt;方法&lt;/h4&gt;ExDiff结合了经典分室模型与深度学习技术，以捕捉不同网络拓扑中的扩散结构和时间特征。框架包含网络分析、神经网络建模、模拟和可解释性等专用模块，通过Google Colab的直观界面访问。&lt;h4&gt;主要发现&lt;/h4&gt;通过SIRVD模型的案例研究，ExDiff能够模拟疾病传播、评估干预策略、分类节点状态，并通过XAI技术揭示传播的结构决定因素。&lt;h4&gt;结论&lt;/h4&gt;通过统一模拟和可解释性，ExDiff为研究网络系统中扩散现象提供了一个有力的工具，有助于促进方法论创新和提供实际见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding and controlling diffusion processes in complex networks iscritical across domains ranging from epidemiology to information science. Here,we present ExDiff, an interactive and modular computational framework thatintegrates network simulation, graph neural networks (GNNs), and explainableartificial intelligence (XAI) to model and interpret diffusion dynamics. ExDiffcombines classical compartmental models with deep learning techniques tocapture both the structural and temporal characteristics of diffusion acrossdiverse network topologies. The framework features dedicated modules fornetwork analysis, neural modeling, simulation, and interpretability, allaccessible via an intuitive interface built on Google Colab. Through a casestudy of the Susceptible Infectious Recovered Vaccinated Dead (SIRVD) model, wedemonstrate the capacity to simulate disease spread, evaluate interventionstrategies, classify node states, and reveal the structural determinants ofcontagion through XAI techniques. By unifying simulation and interpretability,ExDiff provides a powerful, flexible, and accessible platform for studyingdiffusion phenomena in networked systems, enabling both methodologicalinnovation and practical insight.</description>
      <author>example@mail.com (Annamaria Defilippo, Ugo Lomoio, Barbara Puccio, Pierangelo Veltri, Pietro Hiram Guzzi)</author>
      <guid isPermaLink="false">2506.04271v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Understanding and Mitigating Network Latency Effect on Teleoperated-Robot with Extended Reality</title>
      <link>http://arxiv.org/abs/2506.01135v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This documents is a 5 pages technical report version. Removed  watermark from acm for copyright purpose&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TeleXR，一个创新的XR远程操作框架，旨在解决现有系统中的运动到运动延迟问题。&lt;h4&gt;背景&lt;/h4&gt;现有的远程机器人操作系统由于过度依赖网络通信，存在运动到运动延迟，导致操作误差大和任务完成时间长。&lt;h4&gt;目的&lt;/h4&gt;TeleXR旨在通过降低网络依赖来减少运动到运动延迟，提高远程操作的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;TeleXR通过利用本地传感数据重构延迟或缺失的信息，并采用竞争感知调度和带宽自适应点云缩放技术来实现。&lt;h4&gt;主要发现&lt;/h4&gt;TeleXR显著减少了网络引起的延迟，同时保持了高机器人规划准确性和XR与机器人操作的同时运行。&lt;h4&gt;结论&lt;/h4&gt;TeleXR是一种有效解决远程机器人操作中运动到运动延迟问题的开源框架。&lt;h4&gt;翻译&lt;/h4&gt;Robot teleoperation with extended reality (XR teleoperation) enables intuitive interaction by allowing remote robots to mimic user motions with real-time 3D feedback. However, existing systems face significant motion-to-motion (M2M) latency--the delay between the user's latest motion and the corresponding robot feedback--leading to high teleoperation error and mission completion time. This issue stems from the system's exclusive reliance on network communication, making it highly vulnerable to network degradation. To address these challenges, we introduce TeleXR, the first end-to-end, fully open-sourced XR teleoperation framework that decouples robot control and XR visualization from network dependencies. TeleXR leverages local sensing data to reconstruct delayed or missing information of the counterpart, thereby significantly reducing network-induced issues. This approach allows both the XR and robot to run concurrently with network transmission while maintaining high robot planning accuracy. TeleXR also features contention-aware scheduling to mitigate GPU contention and bandwidth-adaptive point cloud scaling to cope with limited bandwidth.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robot teleoperation with extended reality (XR teleoperation) enablesintuitive interaction by allowing remote robots to mimic user motions withreal-time 3D feedback. However, existing systems face significantmotion-to-motion (M2M) latency--the delay between the user's latest motion andthe corresponding robot feedback--leading to high teleoperation error andmission completion time. This issue stems from the system's exclusive relianceon network communication, making it highly vulnerable to network degradation.  To address these challenges, we introduce TeleXR, the first end-to-end, fullyopen-sourced XR teleoperation framework that decouples robot control and XRvisualization from network dependencies. TeleXR leverages local sensing data toreconstruct delayed or missing information of the counterpart, therebysignificantly reducing network-induced issues. This approach allows both the XRand robot to run concurrently with network transmission while maintaining highrobot planning accuracy. TeleXR also features contention-aware scheduling tomitigate GPU contention and bandwidth-adaptive point cloud scaling to cope withlimited bandwidth.</description>
      <author>example@mail.com (Ziliang Zhang, Cong Liu, Hyoseung Kim)</author>
      <guid isPermaLink="false">2506.01135v2</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Corrigibility as a Singular Target: A Vision for Inherently Reliable Foundation Models</title>
      <link>http://arxiv.org/abs/2506.03056v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. This work has been submitted to the Reliable and  Responsible Foundation Models Workshop at ICML 2025 for review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的设计范式，即“将可纠正性作为唯一目标”（CAST），旨在设计能够使指定的人类负责人引导、纠正和控制的基础模型（FMs），以解决FMs在能力提升过程中可能失去人类控制，导致存在性灾难的安全挑战。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型能力的提升，工具性收敛会导致其默认轨迹向失去人类控制的方向发展，可能最终导致存在性灾难。当前的对齐方法在价值指定复杂性和处理新兴的寻求权力行为方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;设计FMs，使其主要目标是赋予指定的人类负责人权力来引导、纠正和控制这些模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一个综合性的实证研究议程，包括训练方法（RLAIF、SFT、合成数据生成）、跨模型规模的扩展性测试，以及可控指令性的演示。&lt;h4&gt;主要发现&lt;/h4&gt;CAST范式从静态价值加载转变为动态人类赋权，改变了工具性动机：自我保护只是为了维持负责人的控制；目标修改变为促进负责人的引导。&lt;h4&gt;结论&lt;/h4&gt;随着能力的增长，FMs应越来越响应人类指导，提供一条尽可能工具化的有益AI之路，而不是取代人类判断。这从源头上解决了核心对齐问题，防止了向不匹配的工具性收敛的默认轨迹发展。&lt;h4&gt;翻译&lt;/h4&gt;The abstract of the paper is summarized as follows: "Foundation models (FMs) face a critical safety challenge: as capabilities scale, instrumental convergence drives default trajectories toward loss of human control, potentially culminating in existential catastrophe. Current alignment approaches struggle with value specification complexity and fail to address emergent power-seeking behaviors. We propose "Corrigibility as a Singular Target" (CAST)-designing FMs whose overriding objective is empowering designated human principals to guide, correct, and control them. This paradigm shift from static value-loading to dynamic human empowerment transforms instrumental drives: self-preservation serves only to maintain the principal's control; goal modification becomes facilitating principal guidance. We present a comprehensive empirical research agenda spanning training methodologies (RLAIF, SFT, synthetic data generation), scalability testing across model sizes, and demonstrations of controlled instructability. Our vision: FMs that become increasingly responsive to human guidance as capabilities grow, offering a path to beneficial AI that remains as tool-like as possible, rather than supplanting human judgment. This addresses the core alignment problem at its source, preventing the default trajectory toward misaligned instrumental convergence."&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) face a critical safety challenge: as capabilitiesscale, instrumental convergence drives default trajectories toward loss ofhuman control, potentially culminating in existential catastrophe. Currentalignment approaches struggle with value specification complexity and fail toaddress emergent power-seeking behaviors. We propose "Corrigibility as aSingular Target" (CAST)-designing FMs whose overriding objective is empoweringdesignated human principals to guide, correct, and control them. This paradigmshift from static value-loading to dynamic human empowerment transformsinstrumental drives: self-preservation serves only to maintain the principal'scontrol; goal modification becomes facilitating principal guidance. We presenta comprehensive empirical research agenda spanning training methodologies(RLAIF, SFT, synthetic data generation), scalability testing across modelsizes, and demonstrations of controlled instructability. Our vision: FMs thatbecome increasingly responsive to human guidance as capabilities grow, offeringa path to beneficial AI that remains as tool-like as possible, rather thansupplanting human judgment. This addresses the core alignment problem at itssource, preventing the default trajectory toward misaligned instrumentalconvergence.</description>
      <author>example@mail.com (Ram Potham, Max Harms)</author>
      <guid isPermaLink="false">2506.03056v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
  <item>
      <title>LexTime: A Benchmark for Temporal Ordering of Legal Events</title>
      <link>http://arxiv.org/abs/2506.04041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了LexTime数据集，用于评估大型语言模型（LLM）在法律语境中事件排序的能力，并通过实验发现LLM在法律事件排序上比叙事文本排序更准确，同时指出输入上下文长度、事件类型和语言复杂性对模型性能的影响。&lt;h4&gt;背景&lt;/h4&gt;法律文本中的时间推理对于案例分析和合规监控等应用至关重要，但现有数据集缺乏专家语言评估，无法全面了解LLM在法律语境中处理事件排序的能力。&lt;h4&gt;目的&lt;/h4&gt;设计LexTime数据集，评估LLM在法律语言中事件排序的能力，并探究影响模型性能的因素。&lt;h4&gt;方法&lt;/h4&gt;LexTime数据集包含512个来自美国联邦诉讼的实例，带有注释的事件对及其时间关系。通过实验比较LLM在法律事件排序和叙事文本排序上的表现，并分析输入上下文长度、事件类型和语言复杂性对模型性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;LLM在法律事件排序上的准确性高于叙事文本排序（高达+10.5%），较长的输入上下文和隐含事件能提高准确性，达到80.8%的隐含-显含事件对准确性；法律语言的复杂性和嵌套从句仍是对模型性能的挑战。&lt;h4&gt;结论&lt;/h4&gt;研究表明，LLM在法律事件排序方面有潜力，但需要特定的建模策略来提高时间事件推理的能力。&lt;h4&gt;翻译&lt;/h4&gt;Temporal reasoning in legal texts is important for applications like case law analysis and compliance monitoring. However, existing datasets lack expert language evaluation, leaving a gap in understanding how LLMs manage event ordering in legal contexts. We introduce LexTime, the first dataset designed to evaluate LLMs' event ordering capabilities in legal language, consisting of 512 instances from U.S. Federal Complaints with annotated event pairs and their temporal relations. Our findings show that (1) LLMs are more accurate on legal event ordering than on narrative (up to +10.5%); (2) longer input contexts and implicit events boost accuracy, reaching 80.8% for implicit-explicit event pairs; (3) legal linguistic complexities and nested clauses remain a challenge. We investigate how context length, explicit vs implicit event pairs, and legal language features affect model performance, demonstrating the need for specific modeling strategies to enhance temporal event reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal reasoning in legal texts is important for applications like case lawanalysis and compliance monitoring. However, existing datasets lack expertlanguage evaluation, leaving a gap in understanding how LLMs manage eventordering in legal contexts. We introduce LexTime, the first dataset designed toevaluate LLMs' event ordering capabilities in legal language, consisting of 512instances from U.S. Federal Complaints with annotated event pairs and theirtemporal relations. Our findings show that (1) LLMs are more accurate on legalevent ordering than on narrative (up to +10.5%); (2) longer input contexts andimplicit events boost accuracy, reaching 80.8% for implicit-explicit eventpairs; (3) legal linguistic complexities and nested clauses remain a challenge.We investigate how context length, explicit vs implicit event pairs, and legallanguage features affect model performance, demonstrating the need for specificmodeling strategies to enhance temporal event reasoning.</description>
      <author>example@mail.com (Claire Barale, Leslie Barrett, Vikram Sunil Bajaj, Michael Rovatsos)</author>
      <guid isPermaLink="false">2506.04041v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Modal Urban Sensing: Evaluating Sound-Vision Alignment Across Street-Level and Aerial Imagery</title>
      <link>http://arxiv.org/abs/2506.03388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究城市声音与环境图像的对应关系，利用多模态方法结合声音和图像数据，评估跨模态相似性，发现基于嵌入的模型提供更好的语义对齐，而基于分割的方法提供视觉结构与声学生态之间的可解释链接。&lt;h4&gt;背景&lt;/h4&gt;环境声景能够传达有关城市环境的生态和社会信息，但其在大规模地理分析中的应用潜力尚未充分挖掘。&lt;h4&gt;目的&lt;/h4&gt;探究城市声音与视觉场景之间的对应程度，并比较不同视觉表征策略在捕捉声学语义方面的效果。&lt;h4&gt;方法&lt;/h4&gt;采用多模态方法，结合三个主要全球城市的街道级和遥感图像以及地理参照声音记录。使用AST模型处理音频，CLIP和RemoteCLIP处理图像，CLIPSeg和Seg-Earth OV进行语义分割。&lt;h4&gt;主要发现&lt;/h4&gt;街道视图嵌入与环境声音的对应性比分割输出更强，而遥感分割在通过生物音-地质音-人音（BGA）框架解释生态类别方面更有效。&lt;h4&gt;结论&lt;/h4&gt;基于嵌入的模型在语义对齐方面表现出色，而基于分割的方法提供视觉结构与声学生态之间的可解释联系。&lt;h4&gt;翻译&lt;/h4&gt;The abstract of the paper investigates the correspondence between urban sounds and visual scenes, using a multimodal approach that integrates street-level and remote sensing imagery with georeferenced sound recordings across three major global cities. It employs the AST model for audio, CLIP and RemoteCLIP for imagery, and CLIPSeg and Seg-Earth OV for semantic segmentation, to evaluate cross-modal similarity. The results show that street view embeddings have a stronger alignment with environmental sounds compared to segmentation outputs, while remote sensing segmentation is more effective in interpreting ecological categories through the BGA framework. These findings suggest that embedding-based models offer superior semantic alignment, while segmentation-based methods provide interpretable links between visual structure and acoustic ecology. This work advances the field of multimodal urban sensing by offering new perspectives for incorporating sound into geospatial analysis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Environmental soundscapes convey substantial ecological and socialinformation regarding urban environments; however, their potential remainslargely untapped in large-scale geographic analysis. In this study, weinvestigate the extent to which urban sounds correspond with visual scenes bycomparing various visual representation strategies in capturing acousticsemantics. We employ a multimodal approach that integrates geo-referenced soundrecordings with both street-level and remote sensing imagery across three majorglobal cities: London, New York, and Tokyo. Utilizing the AST model for audio,along with CLIP and RemoteCLIP for imagery, as well as CLIPSeg and Seg-Earth OVfor semantic segmentation, we extract embeddings and class-level features toevaluate cross-modal similarity. The results indicate that street viewembeddings demonstrate stronger alignment with environmental sounds compared tosegmentation outputs, whereas remote sensing segmentation is more effective ininterpreting ecological categories through a Biophony--Geophony--Anthrophony(BGA) framework. These findings imply that embedding-based models offersuperior semantic alignment, while segmentation-based methods provideinterpretable links between visual structure and acoustic ecology. This workadvances the burgeoning field of multimodal urban sensing by offering novelperspectives for incorporating sound into geospatial analysis.</description>
      <author>example@mail.com (Pengyu Chen, Xiao Huang, Teng Fei, Sicheng Wang)</author>
      <guid isPermaLink="false">2506.03388v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>DynTok: Dynamic Compression of Visual Tokens for Efficient and Effective Video Understanding</title>
      <link>http://arxiv.org/abs/2506.03990v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DynTok的新型动态视频标记压缩策略，旨在减少视频处理中的计算开销。&lt;h4&gt;背景&lt;/h4&gt;传统的视频建模方法，如LLava，将视频表示为视觉标记序列，然后通过LLM主干网络进行处理，但这种方法对于长视频来说会产生大量的视觉标记。&lt;h4&gt;目的&lt;/h4&gt;提出DynTok以减少视觉标记的数量，从而降低计算负担，同时保持视频理解的性能。&lt;h4&gt;方法&lt;/h4&gt;DynTok通过自适应地将视觉标记分为组并在每组内合并它们，在高信息密度低的区域实现高压缩率，同时保留关键内容。&lt;h4&gt;主要发现&lt;/h4&gt;该方法将标记数量减少到原始大小的44.4%，同时在Video-MME上达到65.3%和MLVU上达到72.5%的性能。&lt;h4&gt;结论&lt;/h4&gt;DynTok通过简化而有效的压缩方法揭示了视频标记表示中的冗余，为设计更有效的视频建模技术提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：传统的视频建模方法，如LLava，将视频表示为视觉标记序列，然后通过LLM主干网络进行处理，然而，这种方法对于长视频来说会产生大量的视觉标记。一种实用的解决方案是在将其输入到LLM主干网络之前，首先从大视觉上下文中提取相关视觉信息，从而减少计算开销。在本研究中，我们引入了DynTok，这是一种新颖的动态视频标记压缩策略。DynTok自适应地将视觉标记分为组并在每组内合并它们，在高信息密度低的区域实现高压缩率，同时保留关键内容。我们的方法将标记数量减少到原始大小的44.4%，同时保持可比的性能。它还受益于视频帧数的增加，在Video-MME上达到65.3%，在MLVU上达到72.5%。通过应用这种简单而有效的压缩方法，我们揭示了视频标记表示中的冗余，为设计更有效的视频建模技术提供了见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Typical video modeling methods, such as LLava, represent videos as sequencesof visual tokens, which are then processed by the LLM backbone for effectivevideo understanding. However, this approach leads to a massive number of visualtokens, especially for long videos. A practical solution is to first extractrelevant visual information from the large visual context before feeding itinto the LLM backbone, thereby reducing computational overhead. In this work,we introduce DynTok, a novel \textbf{Dyn}amic video \textbf{Tok}en compressionstrategy. DynTok adaptively splits visual tokens into groups and merges themwithin each group, achieving high compression in regions with low informationdensity while preserving essential content. Our method reduces the number oftokens to 44.4% of the original size while maintaining comparable performance.It further benefits from increasing the number of video frames and achieves65.3% on Video-MME and 72.5% on MLVU. By applying this simple yet effectivecompression method, we expose the redundancy in video token representations andoffer insights for designing more efficient video modeling techniques.</description>
      <author>example@mail.com (Hongzhi Zhang, Jingyuan Zhang, Xingguang Ji, Qi Wang, Fuzheng Zhang)</author>
      <guid isPermaLink="false">2506.03990v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>OWMM-Agent: Open World Mobile Manipulation With Multi-modal Agentic Data Synthesis</title>
      <link>http://arxiv.org/abs/2506.04217v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages of main content, 19 pages in total&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的多模态智能体架构，用于解决开放世界移动操作（OWMM）任务中的挑战，包括对开放指令和环境的泛化需求以及将高级决策与基于全局场景理解和当前智能体状态的低级机器人控制相结合的系统性复杂性。&lt;h4&gt;背景&lt;/h4&gt;移动操作机器人在许多专业任务中变得非常有能力，但OWMM任务仍然是一个挑战，因为它需要泛化到开放指令和环境，以及整合高级决策和低级机器人控制的复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的智能体架构来应对OWMM任务中的复杂性，并提高智能体的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一个多模态智能体架构，该架构维护多视图场景框架和智能体状态以进行决策，并通过函数调用控制机器人。此外，引入了一个智能体数据合成流程，用于将VLM模型适应OWMM任务域，并通过指令微调来增强智能体性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与包括GPT-4o在内的其他基础模型相比，该模型达到了SOTA性能，并表现出强大的零样本泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该模型是第一个针对移动操作机器人的专用基础模型，具有全局场景理解、机器人状态跟踪和多模态动作生成。&lt;h4&gt;翻译&lt;/h4&gt;The rapid progress of navigation, manipulation, and vision models has made mobile manipulators capable in many specialized tasks. However, the open-world mobile manipulation (OWMM) task remains a challenge due to the need for generalization to open-ended instructions and environments, as well as the systematic complexity to integrate high-level decision making with low-level robot control based on both global scene understanding and current agent state. To address this complexity, we propose a novel multi-modal agent architecture that maintains multi-view scene frames and agent states for decision-making and controls the robot by function calling. A second challenge is the hallucination from domain shift. To enhance the agent performance, we further introduce an agentic data synthesis pipeline for the OWMM task to adapt the VLM model to our task domain with instruction fine-tuning. We highlight our fine-tuned OWMM-VLM as the first dedicated foundation model for mobile manipulators with global scene understanding, robot state tracking, and multi-modal action generation in a unified model. Through experiments, we demonstrate that our model achieves SOTA performance compared to other foundation models including GPT-4o and strong zero-shot generalization in real world. The project page is at https://github.com/HHYHRHY/OWMM-Agent&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid progress of navigation, manipulation, and vision models has mademobile manipulators capable in many specialized tasks. However, the open-worldmobile manipulation (OWMM) task remains a challenge due to the need forgeneralization to open-ended instructions and environments, as well as thesystematic complexity to integrate high-level decision making with low-levelrobot control based on both global scene understanding and current agent state.To address this complexity, we propose a novel multi-modal agent architecturethat maintains multi-view scene frames and agent states for decision-making andcontrols the robot by function calling. A second challenge is the hallucinationfrom domain shift. To enhance the agent performance, we further introduce anagentic data synthesis pipeline for the OWMM task to adapt the VLM model to ourtask domain with instruction fine-tuning. We highlight our fine-tuned OWMM-VLMas the first dedicated foundation model for mobile manipulators with globalscene understanding, robot state tracking, and multi-modal action generation ina unified model. Through experiments, we demonstrate that our model achievesSOTA performance compared to other foundation models including GPT-4o andstrong zero-shot generalization in real world. The project page is athttps://github.com/HHYHRHY/OWMM-Agent</description>
      <author>example@mail.com (Junting Chen, Haotian Liang, Lingxiao Du, Weiyun Wang, Mengkang Hu, Yao Mu, Wenhai Wang, Jifeng Dai, Ping Luo, Wenqi Shao, Lin Shao)</author>
      <guid isPermaLink="false">2506.04217v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Language-Image Alignment with Fixed Text Encoders</title>
      <link>http://arxiv.org/abs/2506.04209v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用预训练的大型语言模型（LLM）中的固定文本编码器来指导视觉表示学习，通过仅训练图像编码器来学习语言-图像对齐，发现这种方法在大多数涉及组合理解和长标题的场景中，比CLIP更有效，同时提高了计算效率。&lt;h4&gt;背景&lt;/h4&gt;目前，通过对比学习联合预训练文本和图像编码器是建立语言-图像对齐的主要方法，如CLIP及其变体。&lt;h4&gt;目的&lt;/h4&gt;研究是否需要昂贵的联合预训练，以及预训练的固定大型语言模型（LLM）是否能够提供足够的文本编码器来指导视觉表示学习。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为LIFT的方法，通过仅训练图像编码器，从LLM中学习固定文本编码器来学习语言-图像对齐。&lt;h4&gt;主要发现&lt;/h4&gt;通过全面基准测试和消融研究，发现LIFT框架在涉及组合理解和长标题的场景中，比CLIP更有效，同时在计算效率上取得了显著提升。&lt;h4&gt;结论&lt;/h4&gt;本研究是系统地探索LLM中的文本嵌入如何指导视觉学习的第一步，并为学习语言对齐的视觉表示提供了一个替代的设计选择。&lt;h4&gt;翻译&lt;/h4&gt;目前，通过对比学习联合预训练文本和图像编码器是建立语言-图像对齐的主要方法，如CLIP及其变体。在本文中，我们质疑这种昂贵的联合预训练是否必要。特别是，我们研究了预训练的固定大型语言模型（LLM）是否能够提供足够的文本编码器来指导视觉表示学习。也就是说，我们提出通过仅训练图像编码器，从LLM中学习固定文本编码器来学习语言-图像对齐的方法。出人意料的是，通过全面的基准测试和消融研究，我们发现这种简化的框架LIFT非常有效，在大多数涉及组合理解和长标题的场景中，它优于CLIP，同时在计算效率上取得了显著的提升。我们的工作是系统地探索LLM中的文本嵌入如何指导视觉学习的第一步，并为学习语言对齐的视觉表示提供了一个替代的设计选择。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Currently, the most dominant approach to establishing language-imagealignment is to pre-train text and image encoders jointly through contrastivelearning, such as CLIP and its variants. In this work, we question whether sucha costly joint training is necessary. In particular, we investigate if apre-trained fixed large language model (LLM) offers a good enough text encoderto guide visual representation learning. That is, we propose to learnLanguage-Image alignment with a Fixed Text encoder (LIFT) from an LLM bytraining only the image encoder. Somewhat surprisingly, through comprehensivebenchmarking and ablation studies, we find that this much simplified frameworkLIFT is highly effective and it outperforms CLIP in most scenarios that involvecompositional understanding and long captions, while achieving considerablegains in computational efficiency. Our work takes a first step towardssystematically exploring how text embeddings from LLMs can guide visuallearning and suggests an alternative design choice for learninglanguage-aligned visual representations.</description>
      <author>example@mail.com (Jingfeng Yang, Ziyang Wu, Yue Zhao, Yi Ma)</author>
      <guid isPermaLink="false">2506.04209v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>A Threat Intelligence Event Extraction Conceptual Model for Cyber Threat Intelligence Feeds</title>
      <link>http://arxiv.org/abs/2506.03551v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE conference paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对网络安全日益严峻的形势，探讨了提升网络安全情报（CTI）数据收集效率的关键性。通过系统性回顾现有技术，提出了提高威胁情报数据收集效果的概念模型，并强调了人工智能和机器学习在优化CTI数据预处理中的重要作用。&lt;h4&gt;背景&lt;/h4&gt;网络安全威胁日益加剧，CTI数据收集效率对保障网络安全至关重要，而现有研究在处理大量多语言威胁数据时遇到挑战，导致实时威胁分析效率低下。&lt;h4&gt;目的&lt;/h4&gt;提高CTI数据收集效率，增强威胁情报数据收集效果，并通过引入新的概念模型解决现有研究中的不足。&lt;h4&gt;方法&lt;/h4&gt;遵循PRISMA指南，从Scopus数据库中回顾相关研究，重点关注人工智能和机器学习模型在优化CTI数据预处理中的作用，并引入了XBC概念模型。&lt;h4&gt;主要发现&lt;/h4&gt;人工智能驱动的方法，尤其是监督学习和无监督学习，在提高威胁检测和事件提取的准确性方面具有显著效果，从而加强了网络安全。研究还发现现有研究存在差距，并提出了一个结合XLM-RoBERTa、BiGRU和CRF的XBC概念模型来解决这一差距。&lt;h4&gt;结论&lt;/h4&gt;本文通过对现有CTI数据收集技术的详细分析，提出了一种创新的概念模型，为提升未来威胁情报能力做出了贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/NETAPPS63333.2024.10823639&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In response to the escalating cyber threats, the efficiency of Cyber ThreatIntelligence (CTI) data collection has become paramount in ensuring robustcybersecurity. However, existing works encounter significant challenges inpreprocessing large volumes of multilingual threat data, leading toinefficiencies in real-time threat analysis. This paper presents a systematicreview of current techniques aimed at enhancing CTI data collection efficiency.Additionally, it proposes a conceptual model to further advance theeffectiveness of threat intelligence feeds. Following the PRISMA guidelines,the review examines relevant studies from the Scopus database, highlighting thecritical role of artificial intelligence (AI) and machine learning models inoptimizing CTI data preprocessing. The findings underscore the importance ofAI-driven methods, particularly supervised and unsupervised learning, insignificantly improving the accuracy of threat detection and event extraction,thereby strengthening cybersecurity. Furthermore, the study identifies a gap inthe existing research and introduces XBC conceptual model integratingXLM-RoBERTa, BiGRU, and CRF, specifically developed to address this gap. Thispaper contributes conceptually to the field by providing a detailed analysis ofcurrent CTI data collection techniques and introducing an innovative conceptualmodel to enhance future threat intelligence capabilities.</description>
      <author>example@mail.com (Jamal H. Al-Yasiri, Mohamad Fadli Bin Zolkipli, Nik Fatinah N Mohd Farid, Mohammed Alsamman, Zainab Ali Mohammed)</author>
      <guid isPermaLink="false">2506.03551v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>chemtrain-deploy: A parallel and scalable framework for machine learning potentials in million-atom MD simulations</title>
      <link>http://arxiv.org/abs/2506.04055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Source code available at: https://github.com/tummfm/chemtrain&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了chemtrain-deploy框架，该框架支持在LAMMPS中实现机器学习势（MLP）的无模型部署，提高了分子动力学（MD）模拟的效率。&lt;h4&gt;背景&lt;/h4&gt;尽管机器学习势（MLP）在分子动力学（MD）模拟中展现出巨大潜力，但现有的软件工具存在特定架构限制、缺乏与标准MD软件包的集成以及不支持跨GPU并行化等问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，开发了一个名为chemtrain-deploy的框架，用于在LAMMPS中实现MLP的无模型部署。&lt;h4&gt;方法&lt;/h4&gt;chemtrain-deploy支持任何JAX定义的半局部势，使用户能够利用LAMMPS的功能，并在多个GPU上执行大规模MLP-based MD模拟。它采用图神经网络架构，如MACE、Allegro和PaiNN，并应用于液体-蒸汽界面、晶体材料和溶质肽等多种系统。&lt;h4&gt;主要发现&lt;/h4&gt;chemtrain-deploy实现了最先进的效率，并能够扩展到包含数百万原子的系统。通过验证其性能和可扩展性，证明了chemtrain-deploy在现实世界高性能模拟中的实用性，并为MLP架构选择和未来设计提供了指导。&lt;h4&gt;结论&lt;/h4&gt;chemtrain-deploy是一个高效的框架，能够促进MLP在分子动力学模拟中的应用，为高性能计算提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning potentials (MLPs) have advanced rapidly and show greatpromise to transform molecular dynamics (MD) simulations. However, mostexisting software tools are tied to specific MLP architectures, lackintegration with standard MD packages, or are not parallelizable across GPUs.To address these challenges, we present chemtrain-deploy, a framework thatenables model-agnostic deployment of MLPs in LAMMPS. chemtrain-deploy supportsany JAX-defined semi-local potential, allowing users to exploit thefunctionality of LAMMPS and perform large-scale MLP-based MD simulations onmultiple GPUs. It achieves state-of-the-art efficiency and scales to systemscontaining millions of atoms. We validate its performance and scalability usinggraph neural network architectures, including MACE, Allegro, and PaiNN, appliedto a variety of systems, such as liquid-vapor interfaces, crystallinematerials, and solvated peptides. Our results highlight the practical utilityof chemtrain-deploy for real-world, high-performance simulations and provideguidance for MLP architecture selection and future design.</description>
      <author>example@mail.com (Paul Fuchs, Weilong Chen, Stephan Thaler, Julija Zavadlav)</author>
      <guid isPermaLink="false">2506.04055v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Video, How Do Your Tokens Merge?</title>
      <link>http://arxiv.org/abs/2506.03885v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at eLVM workshop at CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视频transformer模型在处理时空输入时的计算资源需求，并提出了一种无训练的token合并方法，以提高视频模型的效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;视频transformer模型由于需要处理时空输入，因此需要大量的计算资源。&lt;h4&gt;目的&lt;/h4&gt;探索无训练的token合并方法，以提升视频模型的性能。&lt;h4&gt;方法&lt;/h4&gt;在三个具有粗粒度和细粒度动作识别的视频数据集上，对四种视频transformer模型进行了实验，以找到最佳的token合并实践。&lt;h4&gt;主要发现&lt;/h4&gt;token合并可以显著提高视频模型的效率，速度提升约2.5倍，同时保持准确性（ViViT的平均误差为-0.55%）。&lt;h4&gt;结论&lt;/h4&gt;视频token合并是一种有效的方法，可以提高视频模型的效率和准确性。&lt;h4&gt;翻译&lt;/h4&gt;Video transformer models require huge amounts of compute resources due to the spatio-temporal scaling of the input. Tackling this, recent methods have proposed to drop or merge tokens for image models, whether randomly or via learned methods. Merging tokens has many benefits: it can be plugged into any vision transformer, does not require model re-training, and it propagates information that would otherwise be dropped through the model. Before now, video token merging has not been evaluated on temporally complex datasets for video understanding. In this work, we explore training-free token merging for video to provide comprehensive experiments and find best practices across four video transformers on three datasets that exhibit coarse and fine-grained action recognition. Our results showcase the benefits of video token merging with a speedup of around 2.5X while maintaining accuracy (avg. -0.55% for ViViT). Code available at https://github.com/sjpollard/video-how-do-your-tokens-merge.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video transformer models require huge amounts of compute resources due to thespatio-temporal scaling of the input. Tackling this, recent methods haveproposed to drop or merge tokens for image models, whether randomly or vialearned methods. Merging tokens has many benefits: it can be plugged into anyvision transformer, does not require model re-training, and it propagatesinformation that would otherwise be dropped through the model. Before now,video token merging has not been evaluated on temporally complex datasets forvideo understanding. In this work, we explore training-free token merging forvideo to provide comprehensive experiments and find best practices across fourvideo transformers on three datasets that exhibit coarse and fine-grainedaction recognition. Our results showcase the benefits of video token mergingwith a speedup of around $2.5$X while maintaining accuracy (avg. $-0.55\%$ forViViT). Code available athttps://github.com/sjpollard/video-how-do-your-tokens-merge.</description>
      <author>example@mail.com (Sam Pollard, Michael Wray)</author>
      <guid isPermaLink="false">2506.03885v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>A Reference Architecture for Gamified Cultural Heritage Applications Leveraging Generative AI and Augmented Reality</title>
      <link>http://arxiv.org/abs/2506.04090v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于生成式人工智能和增强现实的文化遗产应用游戏化架构，旨在提高用户参与度和教育影响。&lt;h4&gt;背景&lt;/h4&gt;信息技术快速发展正在改变文化遗产的访问、体验和保护方式，但许多数字遗产应用缺乏互动性、个性化和适应性。&lt;h4&gt;目的&lt;/h4&gt;设计互动和智能的文化遗产应用，促进用户和利益相关者的可访问性和更深入的理解。&lt;h4&gt;方法&lt;/h4&gt;提出了一种游戏化文化遗产应用的参考架构，利用生成式人工智能实现适应性故事讲述和个性化内容，以及增强现实技术提供沉浸式、位置感知的体验。&lt;h4&gt;主要发现&lt;/h4&gt;游戏化可以增强动机，人工智能支持动态机制、个性化反馈和用户行为预测，增强参与度；模块化设计支持可扩展性、互操作性和在不同文化遗产环境中的适应性。&lt;h4&gt;结论&lt;/h4&gt;该研究为设计互动和智能的文化遗产应用提供了一个框架，有助于提高用户和利益相关者的参与度和对文化遗产的欣赏程度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of Information and Communication Technologies istransforming Cultural Heritage access, experience, and preservation. However,many digital heritage applications lack interactivity, personalization, andadaptability, limiting user engagement and educational impact. This short paperpresents a reference architecture for gamified cultural heritage applicationsleveraging generative AI and augmented reality. Gamification enhancesmotivation, artificial intelligence enables adaptive storytelling andpersonalized content, and augmented reality fosters immersive, location-awareexperiences. Integrating AI with gamification supports dynamic mechanics,personalized feedback, and user behavior prediction, improving engagement. Themodular design supports scalability, interoperability, and adaptability acrossheritage contexts. This research provides a framework for designing interactiveand intelligent cultural heritage applications, promoting accessibility anddeeper appreciation among users and stakeholders.</description>
      <author>example@mail.com (Federico Martusciello, Henry Muccini, Antonio Bucchiarone)</author>
      <guid isPermaLink="false">2506.04090v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Seeing What Tastes Good: Revisiting Multimodal Distributional Semantics in the Billion Parameter Era</title>
      <link>http://arxiv.org/abs/2506.03994v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACL Findings 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了大规模模型如何表示具体物体概念的语义特征规范，并通过探针任务测试模型对物体属性的认识。&lt;h4&gt;背景&lt;/h4&gt;人类的学习和概念表征基于感觉运动经验，与最先进的基础模型不同。&lt;h4&gt;目的&lt;/h4&gt;评估仅训练于图像数据的图像编码器、多模态训练的图像编码器和仅语言模型在预测经典McRae规范和Binder属性评分数据集上的表现。&lt;h4&gt;方法&lt;/h4&gt;使用探针任务测试模型对物体属性的认识，并比较不同类型模型的性能。&lt;h4&gt;主要发现&lt;/h4&gt;多模态图像编码器略优于仅语言的方法，而仅图像的编码器在预测非视觉属性（如“百科全书”或“功能”）时与语言模型表现相当。&lt;h4&gt;结论&lt;/h4&gt;这些结果提供了关于纯单模态学习可学内容的见解，以及模态之间的互补性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类的学习和概念表征根植于感觉运动经验，与当前最先进的基于模型的方法不同。在本文中，我们研究了这些在大量数据上训练的大规模模型在多大程度上表示具体物体概念的语义特征规范，例如，玫瑰是红色的，闻起来香甜，是一种花。更具体地说，我们使用探针任务来测试这些模型知道哪些物体的属性。我们在仅使用图像数据的图像编码器、多模态训练的图像编码器和仅语言模型上评估了预测经典McRae规范扩展密集版本和新Binder属性评分数据集的表现。我们发现多模态图像编码器略优于仅语言的方法，并且仅图像的编码器在预测被归类为“百科全书”或“功能”的非视觉属性时与语言模型表现相当。这些结果为纯单模态学习可学内容提供了新的见解，以及模态之间的互补性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human learning and conceptual representation is grounded in sensorimotorexperience, in contrast to state-of-the-art foundation models. In this paper,we investigate how well such large-scale models, trained on vast quantities ofdata, represent the semantic feature norms of concrete object concepts, e.g. aROSE is red, smells sweet, and is a flower. More specifically, we use probingtasks to test which properties of objects these models are aware of. Weevaluate image encoders trained on image data alone, as well asmultimodally-trained image encoders and language-only models, on predicting anextended denser version of the classic McRae norms and the newer Binder datasetof attribute ratings. We find that multimodal image encoders slightlyoutperform language-only approaches, and that image-only encoders performcomparably to the language models, even on non-visual attributes that areclassified as "encyclopedic" or "function". These results offer new insightsinto what can be learned from pure unimodal learning, and the complementarityof the modalities.</description>
      <author>example@mail.com (Dan Oneata, Desmond Elliott, Stella Frank)</author>
      <guid isPermaLink="false">2506.03994v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Voyager: Long-Range and World-Consistent Video Diffusion for Explorable 3D Scene Generation</title>
      <link>http://arxiv.org/abs/2506.04225v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Voyager是一种新的视频扩散框架，能够从单张图像生成世界一致的3D点云序列，并支持用户定义的摄像机轨迹。&lt;h4&gt;背景&lt;/h4&gt;在视频游戏和虚拟现实等现实应用中，需要建模用户可以探索的3D场景。尽管从文本或图像生成3D物体已经取得进展，但创建长距离、3D一致、可探索的3D场景仍然是一个复杂的问题。&lt;h4&gt;目的&lt;/h4&gt;提出Voyager，旨在生成世界一致的3D点云序列，同时消除传统3D重建管道的需求。&lt;h4&gt;方法&lt;/h4&gt;Voyager整合了三个关键组件：1) 世界一致的视频扩散；2) 长距离世界探索；3) 可扩展的数据引擎。这些组件共同提高了视觉质量和几何精度。&lt;h4&gt;主要发现&lt;/h4&gt;Voyager实现了端到端场景生成和重建，具有帧间内在的一致性，无需3D重建管道。此外，它通过自动化的摄像机姿态估计和度量深度预测，实现了大规模、多样化的训练数据整理。&lt;h4&gt;结论&lt;/h4&gt;Voyager在视觉质量和几何精度上优于现有方法，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world applications like video gaming and virtual reality often demandthe ability to model 3D scenes that users can explore along custom cameratrajectories. While significant progress has been made in generating 3D objectsfrom text or images, creating long-range, 3D-consistent, explorable 3D scenesremains a complex and challenging problem. In this work, we present Voyager, anovel video diffusion framework that generates world-consistent 3D point-cloudsequences from a single image with user-defined camera path. Unlike existingapproaches, Voyager achieves end-to-end scene generation and reconstructionwith inherent consistency across frames, eliminating the need for 3Dreconstruction pipelines (e.g., structure-from-motion or multi-view stereo).Our method integrates three key components: 1) World-Consistent VideoDiffusion: A unified architecture that jointly generates aligned RGB and depthvideo sequences, conditioned on existing world observation to ensure globalcoherence 2) Long-Range World Exploration: An efficient world cache with pointculling and an auto-regressive inference with smooth video sampling foriterative scene extension with context-aware consistency, and 3) Scalable DataEngine: A video reconstruction pipeline that automates camera pose estimationand metric depth prediction for arbitrary videos, enabling large-scale, diversetraining data curation without manual 3D annotations. Collectively, thesedesigns result in a clear improvement over existing methods in visual qualityand geometric accuracy, with versatile applications.</description>
      <author>example@mail.com (Tianyu Huang, Wangguandong Zheng, Tengfei Wang, Yuhao Liu, Zhenwei Wang, Junta Wu, Jie Jiang, Hui Li, Rynson W. H. Lau, Wangmeng Zuo, Chunchao Guo)</author>
      <guid isPermaLink="false">2506.04225v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Structured Pruning for Diverse Best-of-N Reasoning Optimization</title>
      <link>http://arxiv.org/abs/2506.03978v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于transformer的语言模型中的模型剪枝，发现选择性剪枝某些注意力头可以提升模型的推理能力，并提出了一种名为SPRINT的新型对比学习框架，该框架在推理过程中动态选择最佳剪枝头和层，实验结果表明该方法在MATH500和GSM8K数据集上显著优于传统方法。&lt;h4&gt;背景&lt;/h4&gt;模型剪枝通常被视为一种实现计算节省的手段，但本文发现其对模型的推理能力也有提升作用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的对比学习框架，以提升基于transformer的语言模型的推理性能。&lt;h4&gt;方法&lt;/h4&gt;提出SPRINT框架，该框架通过动态选择最佳剪枝头和层，并利用问题嵌入与头嵌入的对齐来识别导致更准确推理的剪枝头配置。&lt;h4&gt;主要发现&lt;/h4&gt;选择性剪枝某些注意力头可以提升模型的推理性能，尤其是在挑战性任务上。&lt;h4&gt;结论&lt;/h4&gt;SPRINT框架在MATH500和GSM8K数据集上显著优于传统的最佳N个和随机选择头的方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies model pruning in transformer-based language models, traditionally viewed as a means of achieving computational savings, but finds that it can also enhance the model's reasoning capabilities. Motivated by this observation, a novel contrastive learning framework called SPRINT is proposed, which dynamically selects the optimal head and layer to prune during inference. Extensive experiments demonstrate that this method significantly outperforms traditional best-of-N and random head selection strategies on the MATH500 and GSM8K datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model pruning in transformer-based language models, traditionally viewed as ameans of achieving computational savings, can enhance the model's reasoningcapabilities. In this work, we uncover a surprising phenomenon: the selectivepruning of certain attention heads leads to improvements in reasoningperformance, particularly on challenging tasks. Motivated by this observation,we propose SPRINT, a novel contrastive learning framework that dynamicallyselects the optimal head and layer to prune during inference. By aligningquestion embeddings with head embeddings, SPRINT identifies those pruned-headconfigurations that result in more accurate reasoning. Extensive experimentsdemonstrate that our method significantly outperforms traditional best-of-$N$and random head selection strategies on the MATH500 and GSM8K datasets.</description>
      <author>example@mail.com (Hieu Trung Nguyen, Bao Nguyen, Viet Anh Nguyen)</author>
      <guid isPermaLink="false">2506.03978v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>FSHNet: Fully Sparse Hybrid Network for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2506.03714v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FSHNet是一种全稀疏混合网络，旨在解决稀疏3D检测器在长距离检测中的效率问题。&lt;h4&gt;背景&lt;/h4&gt;稀疏3D检测器只从非空体素中提取特征，导致长距离交互受损和中心特征缺失，从而削弱了特征提取能力并阻碍了网络优化。&lt;h4&gt;目的&lt;/h4&gt;提出FSHNet以增强现有稀疏编码器的长距离特征提取能力，并优化网络性能。&lt;h4&gt;方法&lt;/h4&gt;1. 引入SlotFormer块，通过槽位分区方法扩大感受野；2. 提出动态稀疏标签分配策略，提供更多高质量正样本；3. 引入稀疏上采样模块，细化下采样体素以保留细节。&lt;h4&gt;主要发现&lt;/h4&gt;FSHNet在Waymo、nuScenes和Argoverse2基准测试中表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;FSHNet通过上述方法显著提升了稀疏3D检测器的性能。&lt;h4&gt;翻译&lt;/h4&gt;Fully sparse 3D detectors have recently gained significant attention due to their efficiency in long-range detection. However, sparse 3D detectors extract features only from non-empty voxels, which impairs long-range interactions and causes the center feature missing. The former weakens the feature extraction capability, while the latter hinders network optimization. To address these challenges, we introduce the Fully Sparse Hybrid Network (FSHNet). FSHNet incorporates a proposed SlotFormer block to enhance the long-range feature extraction capability of existing sparse encoders. The SlotFormer divides sparse voxels using a slot partition approach, which, compared to traditional window partition, provides a larger receptive field. Additionally, we propose a dynamic sparse label assignment strategy to deeply optimize the network by providing more high-quality positive samples. To further enhance performance, we introduce a sparse upsampling module to refine downsampled voxels, preserving fine-grained details crucial for detecting small objects. Extensive experiments on the Waymo, nuScenes, and Argoverse2 benchmarks demonstrate the effectiveness of FSHNet. The code is available at https://github.com/Say2L/FSHNet.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fully sparse 3D detectors have recently gained significant attention due totheir efficiency in long-range detection. However, sparse 3D detectors extractfeatures only from non-empty voxels, which impairs long-range interactions andcauses the center feature missing. The former weakens the feature extractioncapability, while the latter hinders network optimization. To address thesechallenges, we introduce the Fully Sparse Hybrid Network (FSHNet). FSHNetincorporates a proposed SlotFormer block to enhance the long-range featureextraction capability of existing sparse encoders. The SlotFormer dividessparse voxels using a slot partition approach, which, compared to traditionalwindow partition, provides a larger receptive field. Additionally, we propose adynamic sparse label assignment strategy to deeply optimize the network byproviding more high-quality positive samples. To further enhance performance,we introduce a sparse upsampling module to refine downsampled voxels,preserving fine-grained details crucial for detecting small objects. Extensiveexperiments on the Waymo, nuScenes, and Argoverse2 benchmarks demonstrate theeffectiveness of FSHNet. The code is available athttps://github.com/Say2L/FSHNet.</description>
      <author>example@mail.com (Shuai Liu, Mingyue Cui, Boyang Li, Quanmin Liang, Tinghe Hong, Kai Huang, Yunxiao Shan, Kai Huang)</author>
      <guid isPermaLink="false">2506.03714v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Culture Matters in Toxic Language Detection in Persian</title>
      <link>http://arxiv.org/abs/2506.03458v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACL 2025 (Main Track)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了波斯语中的有害语言检测问题，比较了包括微调、数据增强、零样本和少样本学习以及跨语言迁移学习等不同方法。&lt;h4&gt;背景&lt;/h4&gt;有害语言检测对于创建更安全的在线环境和限制有害内容的传播至关重要。&lt;h4&gt;目的&lt;/h4&gt;比较不同方法在波斯语有害语言检测任务中的效果。&lt;h4&gt;方法&lt;/h4&gt;包括微调、数据增强、零样本和少样本学习，以及跨语言迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;文化背景对迁移学习的影响显著：与波斯语有文化相似性的国家的语言在迁移学习中表现更好，而来自文化差异较大的国家的语言改进较低。&lt;h4&gt;结论&lt;/h4&gt;本文包含有害语言示例，用于研究有害检测。&lt;h4&gt;翻译&lt;/h4&gt;Toxic language detection is crucial for creating safer online environments and limiting the spread of harmful content. While toxic language detection has been under-explored in Persian, the current work compares different methods for this task, including fine-tuning, data enrichment, zero-shot and few-shot learning, and cross-lingual transfer learning. What is especially compelling is the impact of cultural context on transfer learning for this task: We show that the language of a country with cultural similarities to Persian yields better results in transfer learning. Conversely, the improvement is lower when the language comes from a culturally distinct country. Warning: This paper contains examples of toxic language that may disturb some readers. These examples are included for the purpose of research on toxic detection.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Toxic language detection is crucial for creating safer online environmentsand limiting the spread of harmful content. While toxic language detection hasbeen under-explored in Persian, the current work compares different methods forthis task, including fine-tuning, data enrichment, zero-shot and few-shotlearning, and cross-lingual transfer learning. What is especially compelling isthe impact of cultural context on transfer learning for this task: We show thatthe language of a country with cultural similarities to Persian yields betterresults in transfer learning. Conversely, the improvement is lower when thelanguage comes from a culturally distinct country. Warning: This paper containsexamples of toxic language that may disturb some readers. These examples areincluded for the purpose of research on toxic detection.</description>
      <author>example@mail.com (Zahra Bokaei, Walid Magdy, Bonnie Webber)</author>
      <guid isPermaLink="false">2506.03458v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Weisfeiler and Leman Go Gambling: Why Expressive Lottery Tickets Win</title>
      <link>http://arxiv.org/abs/2506.03919v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNNs）的彩票假设（LTH），强调了稀疏子网络的区分非同构图的能力对于寻找保持预测性能的“中奖彩票”至关重要，并建立了理论基础。&lt;h4&gt;背景&lt;/h4&gt;彩票假设（LTH）在卷积神经网络（CNNs）中已被广泛研究，但在图神经网络（GNNs）中仅通过经验验证，缺乏理论上的发现。&lt;h4&gt;目的&lt;/h4&gt;研究稀疏子网络的表达能力，即它们区分非同构图的能力，对于发现保持预测性能的“中奖彩票”。&lt;h4&gt;方法&lt;/h4&gt;建立了稀疏初始化的GNN与完整网络相比的表达性匹配条件，特别是在与Weisfeiler-Leman测试相比较的情况下，并提出了和证明了强表达性彩票假设。&lt;h4&gt;主要发现&lt;/h4&gt;发现增加初始化中的表达性可以加速模型收敛并提高泛化能力，为彩票假设（LTH）和图神经网络（GNNs）的研究建立了新的理论基础。&lt;h4&gt;结论&lt;/h4&gt;维持稀疏初始化的GNN中的表达性对于提高模型性能至关重要，并通过药物发现的例子说明了结果。&lt;h4&gt;翻译&lt;/h4&gt;彩票假设（LTH）在卷积神经网络（CNNs）中得到广泛研究，但仅在图神经网络（GNNs）中通过经验验证，其理论发现仍属罕见。本文认为稀疏子网络的表达能力，即区分非同构图的能力，是找到保持预测性能的‘中奖彩票’的关键。本文建立了在稀疏初始化条件下，GNN的表达性与其完整网络相匹配的条件，特别是在与Weisfeiler-Leman测试相比较的情况下，提出了并证明了强表达性彩票假设。随后，研究显示初始化中增加的表达能力可能加速模型收敛并提高泛化。本文的发现为彩票假设（LTH）和图神经网络（GNNs）的研究建立了新的理论基础，突出了在稀疏初始化的GNN中维持表达性的重要性。研究通过药物发现的例子说明了其结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The lottery ticket hypothesis (LTH) is well-studied for convolutional neuralnetworks but has been validated only empirically for graph neural networks(GNNs), for which theoretical findings are largely lacking. In this paper, weidentify the expressivity of sparse subnetworks, i.e. their ability todistinguish non-isomorphic graphs, as crucial for finding winning tickets thatpreserve the predictive performance. We establish conditions under which theexpressivity of a sparsely initialized GNN matches that of the full network,particularly when compared to the Weisfeiler-Leman test, and in that contextput forward and prove a Strong Expressive Lottery Ticket Hypothesis. Wesubsequently show that an increased expressivity in the initializationpotentially accelerates model convergence and improves generalization. Ourfindings establish novel theoretical foundations for both LTH and GNN research,highlighting the importance of maintaining expressivity in sparsely initializedGNNs. We illustrate our results using examples from drug discovery.</description>
      <author>example@mail.com (Lorenz Kummer, Samir Moustafa, Anatol Ehrlich, Franka Bause, Nikolaus Suess, Wilfried N. Gansterer, Nils M. Kriege)</author>
      <guid isPermaLink="false">2506.03919v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>How PARTs assemble into wholes: Learning the relative composition of images</title>
      <link>http://arxiv.org/abs/2506.03682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PART的自监督学习方法，用于解决现有基于网格的方法在捕捉真实世界对象组成连续性方面的不足。&lt;h4&gt;背景&lt;/h4&gt;当前自监督学习方法普遍从网格结构出发，通过预测固定网格中补丁的绝对位置索引来进行预训练。&lt;h4&gt;目的&lt;/h4&gt;克服基于网格的方法在捕捉对象组成的连续性方面的不足，实现图像的相对组成学习。&lt;h4&gt;方法&lt;/h4&gt;PART方法利用非网格补丁之间的连续相对变换，在连续空间中建模图像部分之间的关系，学习图像的相对组成。&lt;h4&gt;主要发现&lt;/h4&gt;PART在需要精确空间理解的任务，如对象检测和时间序列预测中，优于强网格方法，如MAE和DropPos。同时，在全局分类任务中也表现出竞争力，且需要的超参数调整最少。&lt;h4&gt;结论&lt;/h4&gt;通过摆脱网格限制，PART为多种数据类型（从自然图像到EEG信号）的通用自监督预训练开辟了新的途径，具有在视频、医学成像和音频等领域的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The composition of objects and their parts, along with object-objectpositional relationships, provides a rich source of information forrepresentation learning. Hence, spatial-aware pretext tasks have been activelyexplored in self-supervised learning. Existing works commonly start from a gridstructure, where the goal of the pretext task involves predicting the absoluteposition index of patches within a fixed grid. However, grid-based approachesfall short of capturing the fluid and continuous nature of real-world objectcompositions. We introduce PART, a self-supervised learning approach thatleverages continuous relative transformations between off-grid patches toovercome these limitations. By modeling how parts relate to each other in acontinuous space, PART learns the relative composition of images-an off-gridstructural relative positioning process that generalizes beyond occlusions anddeformations. In tasks requiring precise spatial understanding such as objectdetection and time series prediction, PART outperforms strong grid-basedmethods like MAE and DropPos, while also maintaining competitive performance onglobal classification tasks with minimal hyperparameter tuning. By breakingfree from grid constraints, PART opens up an exciting new trajectory foruniversal self-supervised pretraining across diverse datatypes-from naturalimages to EEG signals-with promising potential in video, medical imaging, andaudio.</description>
      <author>example@mail.com (Melika Ayoughi, Samira Abnar, Chen Huang, Chris Sandino, Sayeri Lala, Eeshan Gunesh Dhekane, Dan Busbridge, Shuangfei Zhai, Vimal Thilak, Josh Susskind, Pascal Mettes, Paul Groth, Hanlin Goh)</author>
      <guid isPermaLink="false">2506.03682v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning</title>
      <link>http://arxiv.org/abs/2506.03525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://video-skill-cot.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Video-Skill-CoT（Video-SKoT）的框架，用于解决复杂视频理解问题，特别是针对特定领域技能（如事件检测、空间关系理解、情感理解）在不同视频内容上的适应性。&lt;h4&gt;背景&lt;/h4&gt;现有基于思维链（CoT）推理的复杂视频理解方法在适应特定领域技能时存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出Video-SKoT框架，以自动构建和利用技能感知的CoT监督，实现领域自适应的视频推理。&lt;h4&gt;方法&lt;/h4&gt;1. 构建基于技能的CoT标注：从训练问题中提取领域相关的推理技能，将其聚类为共享的技能分类，并为每个视频-问题对创建详细的分步CoT推理。2. 引入技能特定的专家学习框架：每个专家模块专注于一组推理技能，并使用轻量级适配器和收集到的CoT监督进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;在三个视频理解基准测试中，Video-SKoT的表现优于强基线，并且对不同CoT标注流程和多个视频领域学习到的技能进行了深入分析。&lt;h4&gt;结论&lt;/h4&gt;Video-SKoT框架能够有效提高视频理解的领域适应性，并通过实验验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Chain-of-Thought (CoT) reasoning have improved complexvideo understanding, but existing methods often struggle to adapt todomain-specific skills (e.g., event detection, spatial relation understanding,emotion understanding) over various video content. To address this, we proposeVideo-Skill-CoT (a.k.a. Video-SKoT), a framework that automatically constructsand leverages skill-aware CoT supervisions for domain-adaptive video reasoning.First, we construct skill-based CoT annotations: we extract domain-relevantreasoning skills from training questions, cluster them into a shared skilltaxonomy, and create detailed multi-step CoT rationale tailored to eachvideo-question pair for training. Second, we introduce a skill-specific expertlearning framework. Each expert module specializes in a subset of reasoningskills and is trained with lightweight adapters using the collected CoTsupervision. We demonstrate the effectiveness of the proposed approach on threevideo understanding benchmarks, where Video-SKoT consistently outperformsstrong baselines. We also provide in-depth analyses on comparing different CoTannotation pipelines and learned skills over multiple video domains.</description>
      <author>example@mail.com (Daeun Lee, Jaehong Yoon, Jaemin Cho, Mohit Bansal)</author>
      <guid isPermaLink="false">2506.03525v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>HUMOF: Human Motion Forecasting in Interactive Social Scenes</title>
      <link>http://arxiv.org/abs/2506.03753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种有效的方法来预测交互场景中的人类行为，该方法在四个公共数据集上实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;复杂场景中预测人类行为存在挑战，因为存在大量的人与人、人与环境的交互信息，这些因素使得分析和理解人类行为复杂化，从而增加了预测人类动作的不确定性。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的方法来预测交互场景中的人类行为。&lt;h4&gt;方法&lt;/h4&gt;设计了一个层次化的交互特征表示，以全面地表示交互；提出了一个由粗到细的交互推理模块，利用空间和频率视角来有效地利用层次化特征，从而提高动作预测的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在四个公共数据集上实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在复杂场景中预测人类行为方面取得了显著成效。&lt;h4&gt;翻译&lt;/h4&gt;摘要：复杂场景在预测人类行为方面提出了重大挑战，因为存在大量的人与人以及人与环境的交互信息。这些因素使得分析和理解人类行为复杂化，从而增加了预测人类动作的不确定性。因此，现有的运动预测方法在这些复杂场景中面临困难。在本文中，我们提出了一种有效的方法来预测交互场景中的人类行为。为了全面地表示交互，我们设计了一个层次化的交互特征表示，其中高级特征捕捉交互的整体上下文，而低级特征关注细粒度细节。此外，我们提出了一种粗到细的交互推理模块，该模块利用空间和频率视角来有效地利用层次化特征，从而提高了动作预测的准确性。我们的方法在四个公共数据集上实现了最先进的性能。当本文发表时，将发布代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complex scenes present significant challenges for predicting human behaviourdue to the abundance of interaction information, such as human-human andhumanenvironment interactions. These factors complicate the analysis andunderstanding of human behaviour, thereby increasing the uncertainty inforecasting human motions. Existing motion prediction methods thus struggle inthese complex scenarios. In this paper, we propose an effective method forhuman motion forecasting in interactive scenes. To achieve a comprehensiverepresentation of interactions, we design a hierarchical interaction featurerepresentation so that high-level features capture the overall context of theinteractions, while low-level features focus on fine-grained details. Besides,we propose a coarse-to-fine interaction reasoning module that leverages bothspatial and frequency perspectives to efficiently utilize hierarchicalfeatures, thereby enhancing the accuracy of motion predictions. Our methodachieves state-of-the-art performance across four public datasets. Code will bereleased when this paper is published.</description>
      <author>example@mail.com (Caiyi Sun, Yujing Sun, Xiao Han, Zemin Yang, Jiawei Liu, Xinge Zhu, Siu Ming Yiu, Yuexin Ma)</author>
      <guid isPermaLink="false">2506.03753v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Safety of Foundation Models for Visual Navigation through Collision Avoidance via Repulsive Estimation</title>
      <link>http://arxiv.org/abs/2506.03834v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CARE的模块，用于通过排斥力估计进行碰撞避免，以提高基于视觉的导航系统的安全性，无需额外的距离传感器或对预训练模型的微调。&lt;h4&gt;背景&lt;/h4&gt;尽管使用RGB输入的最近的基础模型表现出强大的性能，但它们往往在未见过的物体或摄像头参数（例如视场、姿态或焦距）变化的分布外（OOD）环境中无法泛化。没有微调，这些模型可能生成不安全的轨迹，导致碰撞，需要昂贵的数据收集和重新训练。&lt;h4&gt;目的&lt;/h4&gt;CARE旨在解决上述限制，通过无缝集成到任何基于RGB的导航系统中，并动态调整其输出轨迹，使用由单目深度图派生的排斥力矢量。&lt;h4&gt;方法&lt;/h4&gt;CARE与多个机器人平台上的最先进的基于视觉的导航模型相结合进行评估，通过将排斥力矢量与局部轨迹结合，以减少碰撞率。&lt;h4&gt;主要发现&lt;/h4&gt;CARE在减少碰撞率（高达100%）的同时，不会牺牲到达目标性能，并在探索任务中提高了无碰撞行程距离，最高可达10.7倍。&lt;h4&gt;结论&lt;/h4&gt;CARE模块能够有效提高基于视觉的导航系统的安全性，并在实际应用中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose CARE (Collision Avoidance via Repulsive Estimation), aplug-and-play module that enhances the safety of vision-based navigationwithout requiring additional range sensors or fine-tuning of pretrained models.While recent foundation models using only RGB inputs have shown strongperformance, they often fail to generalize in out-of-distribution (OOD)environments with unseen objects or variations in camera parameters (e.g.,field of view, pose, or focal length). Without fine-tuning, these models maygenerate unsafe trajectories that lead to collisions, requiring costly datacollection and retraining. CARE addresses this limitation by seamlesslyintegrating with any RGB-based navigation system that outputs localtrajectories, dynamically adjusting them using repulsive force vectors derivedfrom monocular depth maps. We evaluate CARE by combining it withstate-of-the-art vision-based navigation models across multiple robotplatforms. CARE consistently reduces collision rates (up to 100%) withoutsacrificing goal-reaching performance and improves collision-free traveldistance by up to 10.7x in exploration tasks.</description>
      <author>example@mail.com (Joonkyung Kim, Joonyeol Sim, Woojun Kim, Katia Sycara, Changjoo Nam)</author>
      <guid isPermaLink="false">2506.03834v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Trajectory Prediction Meets Large Language Models: A Survey</title>
      <link>http://arxiv.org/abs/2506.03408v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, GitHub:  https://github.com/colorfulfuture/Awesome-Trajectory-Motion-Prediction-Papers&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了将大型语言模型（LLMs）应用于轨迹预测的近期进展，并概述了这一新兴领域的五个研究方向。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在语义和推理能力方面的进步激发了将语言驱动技术融入轨迹预测的兴趣。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供对这一新兴领域的全面概述，并对相关方法进行分析。&lt;h4&gt;方法&lt;/h4&gt;将近期工作分为五个方向：语言建模范式下的轨迹预测、直接使用预训练语言模型的轨迹预测、语言引导的场景理解以进行轨迹预测、语言驱动的数据生成用于轨迹预测、基于语言的理由和可解释性用于轨迹预测。&lt;h4&gt;主要发现&lt;/h4&gt;对每个方向中的代表性方法进行了分析，突出了核心设计选择，并确定了开放性挑战。&lt;h4&gt;结论&lt;/h4&gt;该综述连接了自然语言处理和轨迹预测，提供了一个统一的角度，说明了语言如何丰富轨迹预测。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in large language models (LLMs) have sparked growing interest in integrating language-driven techniques into trajectory prediction. By leveraging their semantic and reasoning capabilities, LLMs are reshaping how autonomous systems perceive, model, and predict trajectories. This survey provides a comprehensive overview of this emerging field, categorizing recent work into five directions: (1) Trajectory prediction via language modeling paradigms, (2) Direct trajectory prediction with pretrained language models, (3) Language-guided scene understanding for trajectory prediction, (4) Language-driven data generation for trajectory prediction, (5) Language-based reasoning and interpretability for trajectory prediction. For each, we analyze representative methods, highlight core design choices, and identify open challenges. This survey bridges natural language processing and trajectory prediction, offering a unified perspective on how language can enrich trajectory prediction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in large language models (LLMs) have sparked growing interestin integrating language-driven techniques into trajectory prediction. Byleveraging their semantic and reasoning capabilities, LLMs are reshaping howautonomous systems perceive, model, and predict trajectories. This surveyprovides a comprehensive overview of this emerging field, categorizing recentwork into five directions: (1) Trajectory prediction via language modelingparadigms, (2) Direct trajectory prediction with pretrained language models,(3) Language-guided scene understanding for trajectory prediction, (4)Language-driven data generation for trajectory prediction, (5) Language-basedreasoning and interpretability for trajectory prediction. For each, we analyzerepresentative methods, highlight core design choices, and identify openchallenges. This survey bridges natural language processing and trajectoryprediction, offering a unified perspective on how language can enrichtrajectory prediction.</description>
      <author>example@mail.com (Yi Xu, Ruining Yang, Yitian Zhang, Yizhou Wang, Jianglin Lu, Mingyuan Zhang, Lili Su, Yun Fu)</author>
      <guid isPermaLink="false">2506.03408v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>TextAtari: 100K Frames Game Playing with Language Agents</title>
      <link>http://arxiv.org/abs/2506.04098v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  51 pages, 39 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了TextAtari，这是一个用于评估语言代理在非常长远的决策任务上的基准，这些任务可达100,000步。通过将经典Atari游戏的可视状态表示转换为丰富的文本描述，TextAtari创建了一个将顺序决策与自然语言处理相结合的挑战性测试平台。&lt;h4&gt;背景&lt;/h4&gt;TextAtari通过将游戏状态转换为文本，为长时决策任务提供了一种新的评估方法。&lt;h4&gt;目的&lt;/h4&gt;评估不同形式的先验知识对长时挑战中的表现的影响，并研究语义理解、指令理解和专家演示对代理决策的影响。&lt;h4&gt;方法&lt;/h4&gt;包括几乎100个不同的任务，使用无监督表示学习框架（AtariARI）将任务转换为文本。评估了三种开源大型语言模型（Qwen2.5-7B，Gemma-7B，和Llama3.1-8B）在三个代理框架（零样本、少样本思维链和反思推理）中的表现。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，在广泛的规划任务中，语言代理与人类玩家之间存在显著的性能差距，突显了在数千步的顺序推理、状态跟踪和战略规划方面的挑战。&lt;h4&gt;结论&lt;/h4&gt;TextAtari提供了标准化的评估协议、基线实现和促进语言模型与规划交叉领域研究进展的框架。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了TextAtari，这是一个用于评估语言代理在非常长远的决策任务上的基准，这些任务可达100,000步。通过将经典Atari游戏的可视状态表示翻译成丰富的文本描述，TextAtari创建了一个将顺序决策与自然语言处理相结合的挑战性测试平台。该基准包括近100个具有不同复杂度、动作空间和规划范围的独立任务，所有任务都通过一个无监督表示学习框架（AtariARI）转换为文本。我们评估了三种开源的大型语言模型（Qwen2.5-7B、Gemma-7B和Llama3.1-8B）在三个代理框架（零样本、少样本思维链和反思推理）中的表现，以评估不同形式的先验知识如何影响这些长时挑战的表现。四种场景——基础、隐蔽、手动增强和基于参考——研究了语义理解、指令理解和专家演示对代理决策的影响。我们的结果表明，在广泛的规划任务中，语言代理与人类玩家之间存在显著的性能差距，突显了在数万步的顺序推理、状态跟踪和战略规划方面的挑战。TextAtari提供了标准化的评估协议、基线实现，以及推进语言模型与规划交叉领域研究的框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Lww007/Text-Atari-Agents&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present TextAtari, a benchmark for evaluating language agents on verylong-horizon decision-making tasks spanning up to 100,000 steps. By translatingthe visual state representations of classic Atari games into rich textualdescriptions, TextAtari creates a challenging test bed that bridges sequentialdecision-making with natural language processing. The benchmark includes nearly100 distinct tasks with varying complexity, action spaces, and planninghorizons, all rendered as text through an unsupervised representation learningframework (AtariARI). We evaluate three open-source large language models(Qwen2.5-7B, Gemma-7B, and Llama3.1-8B) across three agent frameworks(zero-shot, few-shot chain-of-thought, and reflection reasoning) to assess howdifferent forms of prior knowledge affect performance on these long-horizonchallenges. Four scenarios-Basic, Obscured, Manual Augmentation, andReference-based-investigate the impact of semantic understanding, instructioncomprehension, and expert demonstrations on agent decision-making. Our resultsreveal significant performance gaps between language agents and human playersin extensive planning tasks, highlighting challenges in sequential reasoning,state tracking, and strategic planning across tens of thousands of steps.TextAtari provides standardized evaluation protocols, baseline implementations,and a framework for advancing research at the intersection of language modelsand planning.</description>
      <author>example@mail.com (Wenhao Li, Wenwu Li, Chuyun Shen, Junjie Sheng, Zixiao Huang, Di Wu, Yun Hua, Wei Yin, Xiangfeng Wang, Hongyuan Zha, Bo Jin)</author>
      <guid isPermaLink="false">2506.04098v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Causality-Aware Contrastive Learning for Robust Multivariate Time-Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2506.03964v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CAROTS的新颖的多变量时间序列异常检测（MTSAD）方法，该方法结合了因果关系的概念，通过对比学习来提高异常检测的鲁棒性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;在多变量时间序列异常检测中，利用变量之间的因果关系是一个有前景的研究方向，但目前尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的MTSAD方法，通过结合因果关系来提高异常检测的性能。&lt;h4&gt;方法&lt;/h4&gt;CAROTS方法包括两个数据增强器，用于生成保持因果性和破坏因果性的样本，分别对应正常变化和合成异常。使用这些样本进行对比学习，训练一个编码器，其潜在空间根据因果关系区分正常和异常样本。此外，CAROTS引入了一种相似性过滤的单类对比损失，鼓励对比学习过程逐渐包含更多具有共同因果关系的语义多样性样本。&lt;h4&gt;主要发现&lt;/h4&gt;在五个真实世界和两个合成数据集上的广泛实验表明，因果关系的集成赋予了CAROTS改进的MTSAD能力。&lt;h4&gt;结论&lt;/h4&gt;CAROTS是一种有效且鲁棒的多变量时间序列异常检测方法，其代码可在GitHub上找到。&lt;h4&gt;翻译&lt;/h4&gt;摘要：利用多变量时间序列中变量间的复杂因果关系为更鲁棒和可靠的多变量时间序列异常检测（MTSAD）提供了一条有希望的研究途径，但这一领域的研究仍处于起步阶段。本文提出了一种名为CAROTS的新颖的MTSAD方法，该方法将因果关系的概念融入对比学习中。CAROTS采用两个数据增强器来获取保持因果性和破坏因果性的样本，分别作为正常变化和合成异常的广泛范围。使用保持因果性和破坏因果性的样本作为正样本和负样本，CAROTS执行对比学习以训练一个编码器，其潜在空间根据因果关系区分正常和异常样本。此外，CAROTS引入了一种相似性过滤的单类对比损失，鼓励对比学习过程逐渐包含更多具有共同因果关系的语义多样性样本。在五个真实世界和两个合成数据集上的广泛实验验证了因果关系的集成赋予了CAROTS改进的MTSAD能力。代码可在https://github.com/kimanki/CAROTS上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Utilizing the complex inter-variable causal relationships within multivariatetime-series provides a promising avenue toward more robust and reliablemultivariate time-series anomaly detection (MTSAD) but remains an underexploredarea of research. This paper proposes Causality-Aware contrastive learning forRObust multivariate Time-Series (CAROTS), a novel MTSAD pipeline thatincorporates the notion of causality into contrastive learning. CAROTS employstwo data augmentors to obtain causality-preserving and -disturbing samples thatserve as a wide range of normal variations and synthetic anomalies,respectively. With causality-preserving and -disturbing samples as positivesand negatives, CAROTS performs contrastive learning to train an encoder whoselatent space separates normal and abnormal samples based on causality.Moreover, CAROTS introduces a similarity-filtered one-class contrastive lossthat encourages the contrastive learning process to gradually incorporate moresemantically diverse samples with common causal relationships. Extensiveexperiments on five real-world and two synthetic datasets validate that theintegration of causal relationships endows CAROTS with improved MTSADcapabilities. The code is available at https://github.com/kimanki/CAROTS.</description>
      <author>example@mail.com (HyunGi Kim, Jisoo Mok, Dongjun Lee, Jaihyun Lew, Sungjae Kim, Sungroh Yoon)</author>
      <guid isPermaLink="false">2506.03964v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Seeing in the Dark: Benchmarking Egocentric 3D Vision with the Oxford Day-and-Night Dataset</title>
      <link>http://arxiv.org/abs/2506.04224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://oxdan.active.vision/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Oxford Day-and-Night，这是一个用于挑战性光照条件下进行新颖视图合成（NVS）和视觉重定位的大规模自主体数据集。&lt;h4&gt;背景&lt;/h4&gt;现有的数据集通常缺乏关键特征组合，如地面真实3D几何、广泛的照明变化和完整的6自由度运动。&lt;h4&gt;目的&lt;/h4&gt;Oxford Day-and-Night通过利用Meta ARIA眼镜捕获自主体视频，并应用多会话SLAM来估计相机姿态、重建3D点云和对齐在不同照明条件下捕获的序列，以解决这些差距。&lt;h4&gt;方法&lt;/h4&gt;该数据集跨越超过30公里的记录轨迹，覆盖了40,000平方米的区域，支持两个核心基准测试：NVS和重定位。&lt;h4&gt;主要发现&lt;/h4&gt;该数据集为自主体3D视觉研究提供了一个丰富的基础，并提供了评估模型在现实和多样化环境中的独特平台。&lt;h4&gt;结论&lt;/h4&gt;Oxford Day-and-Night是一个重要的数据集，为NVS和视觉重定位研究提供了新的资源，有助于推动相关技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Oxford Day-and-Night, a large-scale, egocentric dataset fornovel view synthesis (NVS) and visual relocalisation under challenging lightingconditions. Existing datasets often lack crucial combinations of features suchas ground-truth 3D geometry, wide-ranging lighting variation, and full 6DoFmotion. Oxford Day-and-Night addresses these gaps by leveraging Meta ARIAglasses to capture egocentric video and applying multi-session SLAM to estimatecamera poses, reconstruct 3D point clouds, and align sequences captured undervarying lighting conditions, including both day and night. The dataset spansover 30 $\mathrm{km}$ of recorded trajectories and covers an area of 40,000$\mathrm{m}^2$, offering a rich foundation for egocentric 3D vision research.It supports two core benchmarks, NVS and relocalisation, providing a uniqueplatform for evaluating models in realistic and diverse environments.</description>
      <author>example@mail.com (Zirui Wang, Wenjing Bian, Xinghui Li, Yifu Tao, Jianeng Wang, Maurice Fallon, Victor Adrian Prisacariu)</author>
      <guid isPermaLink="false">2506.04224v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>StARS DCM: A Sleep Stage-Decoding Forehead EEG Patch for Real-time Modulation of Sleep Physiology</title>
      <link>http://arxiv.org/abs/2506.03442v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;StARS是一个模块化的软硬件平台，用于实时睡眠监测和干预。&lt;h4&gt;背景&lt;/h4&gt;StARS平台利用DCM生物信号设备和ezmsg实时软件框架。&lt;h4&gt;目的&lt;/h4&gt;提供实时睡眠监测和干预的解决方案。&lt;h4&gt;方法&lt;/h4&gt;StARS捕捉电生理信号（EEG、EMG、EOG），并使用高级神经网络模型和迁移学习进行睡眠阶段解码，支持闭环听觉刺激和动态热调节等干预措施。&lt;h4&gt;主要发现&lt;/h4&gt;StARS可以配置轻量级的EEG额头贴片或智能戒指等可穿戴传感器，提供灵活、低负担的解决方案。&lt;h4&gt;结论&lt;/h4&gt;StARS平台进一步促进了可定制EEG设备的发展。&lt;h4&gt;翻译&lt;/h4&gt;The System to Augment Restorative Sleep (StARS) is a modular hardware/software platform designed for real-time sleep monitoring and intervention.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The System to Augment Restorative Sleep (StARS) is a modularhardware/software platform designed for real-time sleep monitoring andintervention. Utilizing the compact DCM biosignal device, StARS captureselectrophysiological signals (EEG, EMG, EOG) and synchronizes sensor data usingthe ezmsg real-time software framework. StARS supports interventions such asclosed-loop auditory stimulation and dynamic thermal modulation guided bysleep-stage decoding via advanced neural network models and transfer learning.Configurable with a lightweight EEG forehead patch or wearable sensors likesmart rings, StARS offers flexible, low-burden solutions for EEG, BCI, andsleep-enhancement research and applications. The open-source DCM patch furtherenables customizable EEG device development.</description>
      <author>example@mail.com (William G. Coon, Preston Peranich, Griffin Milsap)</author>
      <guid isPermaLink="false">2506.03442v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Frame-Level Real-Time Assessment of Stroke Rehabilitation Exercises from Video-Level Labeled Data: Task-Specific vs. Foundation Models</title>
      <link>http://arxiv.org/abs/2506.03752v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种框架，用于从视频级标注中学习对个体帧进行分类，以实时评估康复训练中的补偿运动。&lt;h4&gt;背景&lt;/h4&gt;随着中风康复需求的增加，对支持自主锻炼的解决方案的需求也在增加。虚拟教练可以从视频数据中提供实时锻炼反馈，帮助患者改善运动功能并保持参与度。&lt;h4&gt;目的&lt;/h4&gt;减少对实时运动分析系统帧级标注的需求，这些标注既耗时又昂贵。&lt;h4&gt;方法&lt;/h4&gt;使用基于梯度的技术和伪标签选择方法创建帧级伪标签以训练帧级分类器。利用预训练的任务特定模型（ActionTransformer，SkateFormer）和基础模型（MOMENT）生成伪标签，以提高对新患者的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;在SERE数据集上，MOMENT在视频级评估中取得了更好的结果（AUC = 73%），优于基线LSTM（AUC = 58%）。Action Transformer结合集成梯度技术，在帧级评估中取得了更好的结果（AUC = 72%），优于使用地面真实帧级标注训练的基线（AUC = 69%）。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法与预训练模型相结合，增强了模型的泛化能力，并简化了对新患者的定制，减少了数据标注的需求。&lt;h4&gt;翻译&lt;/h4&gt;摘要：中风康复需求的增长增加了对支持自主锻炼的解决方案的需求。虚拟教练可以从视频数据中提供实时锻炼反馈，帮助患者改善运动功能并保持参与度。然而，训练实时运动分析系统需要帧级标注，这既耗时又昂贵。在本研究中，我们提出了一种框架，该框架学习从视频级标注中分类个体帧，以实时评估康复训练中的补偿运动。我们使用基于梯度的技术和伪标签选择方法创建帧级伪标签以训练帧级分类器。我们利用预训练的任务特定模型——ActionTransformer，SkateFormer——和基础模型——MOMENT——生成伪标签，旨在提高对新患者的泛化能力。为了验证该方法，我们使用了SERE数据集，其中包括18名中风后患者进行五种康复锻炼的补偿运动标注。MOMENT在视频级评估中取得了更好的结果（AUC = 73%），优于基线LSTM（AUC = 58%）。Action Transformer结合集成梯度技术，在帧级评估中取得了更好的结果（AUC = 72%），优于使用地面真实帧级标注训练的基线（AUC = 69%）。我们表明，我们提出的方法与预训练模型相结合，增强了模型的泛化能力，并简化了对新患者的定制，减少了数据标注的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing demands of stroke rehabilitation have increased the need forsolutions to support autonomous exercising. Virtual coaches can providereal-time exercise feedback from video data, helping patients improve motorfunction and keep engagement. However, training real-time motion analysissystems demands frame-level annotations, which are time-consuming and costly toobtain. In this work, we present a framework that learns to classify individualframes from video-level annotations for real-time assessment of compensatorymotions in rehabilitation exercises. We use a gradient-based technique and apseudo-label selection method to create frame-level pseudo-labels for traininga frame-level classifier. We leverage pre-trained task-specific models - ActionTransformer, SkateFormer - and a foundation model - MOMENT - for pseudo-labelgeneration, aiming to improve generalization to new patients. To validate theapproach, we use the \textit{SERE} dataset with 18 post-stroke patientsperforming five rehabilitation exercises annotated on compensatory motions.MOMENT achieves better video-level assessment results (AUC = $73\%$),outperforming the baseline LSTM (AUC = $58\%$). The Action Transformer, withthe Integrated Gradient technique, leads to better outcomes (AUC = $72\%$) forframe-level assessment, outperforming the baseline trained with ground truthframe-level labeling (AUC = $69\%$). We show that our proposed approach withpre-trained models enhances model generalization ability and facilitates thecustomization to new patients, reducing the demands of data labeling.</description>
      <author>example@mail.com (Gonçalo Mesquita, Ana Rita Cóias, Artur Dubrawski, Alexandre Bernardino)</author>
      <guid isPermaLink="false">2506.03752v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Resource Allocation in Multi-Channel Wireless Networks</title>
      <link>http://arxiv.org/abs/2506.03813v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为eWMMSE的增强WMMSE算法，用于解决多信道无线网络中的联合信道和功率分配问题。通过引入基于图神经网络的JCPGNN-M解决方案，降低了迭代优化计算复杂度，并实现了多信道分配。该方法结合拉格朗日框架和图神经网络，提高了数据速率，降低了推理时间，并适用于大规模网络。&lt;h4&gt;背景&lt;/h4&gt;随着移动设备数量的增加，干扰成为无线网络数据速率提升的主要瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的方法来解决多信道无线网络中的联合信道和功率分配问题。&lt;h4&gt;方法&lt;/h4&gt;1. 提出eWMMSE算法；2. 引入JCPGNN-M，基于图神经网络实现多信道分配；3. 使用拉格朗日框架系统性地施加总功率约束；4. 结合拉格朗日框架和图神经网络，迭代更新拉格朗日乘数和资源分配方案。&lt;h4&gt;主要发现&lt;/h4&gt;JCPGNN-M比eWMMSE实现了更好的数据速率，且推理时间更低，并且能够很好地推广到更大的网络。&lt;h4&gt;结论&lt;/h4&gt;JCPGNN-M是一种有效解决多信道无线网络中JCPA问题的方法，具有较好的性能和适用性。&lt;h4&gt;翻译&lt;/h4&gt;As the number of mobile devices continues to grow, interference has become amajor bottleneck in improving data rates in wireless networks. Efficient jointchannel and power allocation (JCPA) is crucial for managing interference. Inthis paper, we first propose an enhanced WMMSE (eWMMSE) algorithm to solve theJCPA problem in multi-channel wireless networks. To reduce the computationalcomplexity of iterative optimization, we further introduce JCPGNN-M, a graphneural network-based solution that enables simultaneous multi-channelallocation for each user. We reformulate the problem as a Lagrangian function,which allows us to enforce the total power constraints systematically. Oursolution involves combining this Lagrangian framework with GNNs and iterativelyupdating the Lagrange multipliers and resource allocation scheme. Unlikeexisting GNN-based methods that limit each user to a single channel, JCPGNN-Msupports efficient spectrum reuse and scales well in dense network scenarios.Simulation results show that JCPGNN-M achieves better data rate compared toeWMMSE. Meanwhile, the inference time of JCPGNN-M is much lower than eWMMS, andit can generalize well to larger networks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the number of mobile devices continues to grow, interference has become amajor bottleneck in improving data rates in wireless networks. Efficient jointchannel and power allocation (JCPA) is crucial for managing interference. Inthis paper, we first propose an enhanced WMMSE (eWMMSE) algorithm to solve theJCPA problem in multi-channel wireless networks. To reduce the computationalcomplexity of iterative optimization, we further introduce JCPGNN-M, a graphneural network-based solution that enables simultaneous multi-channelallocation for each user. We reformulate the problem as a Lagrangian function,which allows us to enforce the total power constraints systematically. Oursolution involves combining this Lagrangian framework with GNNs and iterativelyupdating the Lagrange multipliers and resource allocation scheme. Unlikeexisting GNN-based methods that limit each user to a single channel, JCPGNN-Msupports efficient spectrum reuse and scales well in dense network scenarios.Simulation results show that JCPGNN-M achieves better data rate compared toeWMMSE. Meanwhile, the inference time of JCPGNN-M is much lower than eWMMS, andit can generalize well to larger networks.</description>
      <author>example@mail.com (Lili Chen, Changyang She, Jingge Zhu, Jamie Evans)</author>
      <guid isPermaLink="false">2506.03813v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>BiXFormer: A Robust Framework for Maximizing Modality Effectiveness in Multi-Modal Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2506.03675v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;利用多模态数据通过提供互补的语义和几何信息来增强场景理解。&lt;h4&gt;背景&lt;/h4&gt;现有的方法将来自多个模态的特征融合或提炼知识到一个统一表示中，虽然提高了鲁棒性，但限制了每个模态在不同情况下充分利用其优势的能力。&lt;h4&gt;目的&lt;/h4&gt;将多模态语义分割重新定义为掩码级别的分类任务，并提出BiXFormer模型，以集成统一模态匹配（UMM）和跨模态对齐（CMA）来最大化模态的有效性并处理缺失模态。&lt;h4&gt;方法&lt;/h4&gt;BiXFormer首先将多模态输入分类为RGB和X（X代表任何非RGB模态，如深度），允许对每个模态进行单独处理。UMM包括模态无关匹配（MAM）和互补匹配（CM），MAM对来自所有模态的特征进行标签分配而不考虑模态差异，利用每个模态的优势。CM随后将未匹配的标签重新分配给各自模态中剩余未分配的特征，确保每个可用的模态都对最终预测做出贡献，并减轻缺失模态的影响。CMA通过将CM中分配的较弱的查询与MAM中最佳匹配的查询对齐，进一步促进UMM。&lt;h4&gt;主要发现&lt;/h4&gt;在合成和真实世界的多模态基准测试中，实验证明了该方法的有效性，在mIoU方面比现有技术提高了+2.75%和+22.74%。&lt;h4&gt;结论&lt;/h4&gt;BiXFormer通过优化多模态信息融合和缺失模态处理，显著提高了多模态语义分割的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Utilizing multi-modal data enhances scene understanding by providingcomplementary semantic and geometric information. Existing methods fusefeatures or distill knowledge from multiple modalities into a unifiedrepresentation, improving robustness but restricting each modality's ability tofully leverage its strengths in different situations. We reformulatemulti-modal semantic segmentation as a mask-level classification task andpropose BiXFormer, which integrates Unified Modality Matching (UMM) and CrossModality Alignment (CMA) to maximize modality effectiveness and handle missingmodalities. Specifically, BiXFormer first categorizes multi-modal inputs intoRGB and X, where X represents any non-RGB modalities, e.g., depth, allowingseparate processing for each. This design leverages the well-establishedpretraining for RGB, while addressing the relative lack of attention to Xmodalities. Then, we propose UMM, which includes Modality Agnostic Matching(MAM) and Complementary Matching (CM). MAM assigns labels to features from allmodalities without considering modality differences, leveraging each modality'sstrengths. CM then reassigns unmatched labels to remaining unassigned featureswithin their respective modalities, ensuring that each available modalitycontributes to the final prediction and mitigating the impact of missingmodalities. Moreover, to further facilitate UMM, we introduce CMA, whichenhances the weaker queries assigned in CM by aligning them with optimallymatched queries from MAM. Experiments on both synthetic and real-worldmulti-modal benchmarks demonstrate the effectiveness of our method, achievingsignificant improvements in mIoU of +2.75% and +22.74% over the prior arts.</description>
      <author>example@mail.com (Jialei Chen, Xu Zheng, Danda Pani Paudel, Luc Van Gool, Hiroshi Murase, Daisuke Deguchi)</author>
      <guid isPermaLink="false">2506.03675v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Quality Assessment Using the Perceptual Clustering Weighted Graph (PCW-Graph) and Attention Fusion Network</title>
      <link>http://arxiv.org/abs/2506.04081v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;No-Reference Point Cloud Quality Assessment (NR-PCQA)是评估3D内容的关键，特别是在没有参考模型的真实世界应用中。&lt;h4&gt;背景&lt;/h4&gt;NR-PCQA对于在没有参考模型的情况下评估3D内容非常重要。&lt;h4&gt;目的&lt;/h4&gt;NR-PCQA的目的是评估3D内容的质量。&lt;h4&gt;方法&lt;/h4&gt;NR-PCQA是一种无需参考模型的质量评估方法。&lt;h4&gt;主要发现&lt;/h4&gt;摘要中没有提供具体的研究发现。&lt;h4&gt;结论&lt;/h4&gt;摘要中没有提供具体的结论。&lt;h4&gt;翻译&lt;/h4&gt;No-Reference Point Cloud Quality Assessment (NR-PCQA) is critical for evaluating 3D content in real-world applications where reference models are unavailable.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; No-Reference Point Cloud Quality Assessment (NR-PCQA) is critical forevaluating 3D content in real-world applications where reference models areunavailable.</description>
      <author>example@mail.com (Abdelouahed Laazoufi, Mohammed El Hassouni, Hocine Cherifi)</author>
      <guid isPermaLink="false">2506.04081v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives</title>
      <link>http://arxiv.org/abs/2506.03709v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Workshop on Foundation Models Meet Embodied Agents at  CVPR 2025 (Non-archival Track)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究开放词汇语义分割（OVSS）在现实世界应用中的挑战，提出AetherVision-Bench基准，评估多角度分割性能，并探索零样本迁移模型的关键影响因素。&lt;h4&gt;背景&lt;/h4&gt;Open-vocabulary semantic segmentation (OVSS)面临跨领域泛化挑战，影响其实际应用效果。&lt;h4&gt;目的&lt;/h4&gt;评估多角度分割性能，探索零样本迁移模型的关键影响因素，建立稳健性基准。&lt;h4&gt;方法&lt;/h4&gt;提出AetherVision-Bench基准，评估state-of-the-art OVSS模型，研究关键因素。&lt;h4&gt;主要发现&lt;/h4&gt;AetherVision-Bench基准有助于广泛评估不同视角和传感器模态的性能，对零样本迁移模型性能有重要影响。&lt;h4&gt;结论&lt;/h4&gt;研究为未来OVSS研究提供有价值见解和基础。&lt;h4&gt;翻译&lt;/h4&gt;Open-vocabulary semantic segmentation (OVSS) involves assigning labels to each pixel in an image based on textual descriptions, leveraging world models like CLIP. However, they encounter significant challenges in cross-domain generalization, hindering their practical efficacy in real-world applications. Embodied AI systems are transforming autonomous navigation for ground vehicles and drones by enhancing their perception abilities, and in this study, we present AetherVision-Bench, a benchmark for multi-angle segmentation across aerial, and ground perspectives, which facilitates an extensive evaluation of performance across different viewing angles and sensor modalities. We assess state-of-the-art OVSS models on the proposed benchmark and investigate the key factors that impact the performance of zero-shot transfer models. Our work pioneers the creation of a robustness benchmark, offering valuable insights and establishing a foundation for future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-vocabulary semantic segmentation (OVSS) involves assigning labels toeach pixel in an image based on textual descriptions, leveraging world modelslike CLIP. However, they encounter significant challenges in cross-domaingeneralization, hindering their practical efficacy in real-world applications.Embodied AI systems are transforming autonomous navigation for ground vehiclesand drones by enhancing their perception abilities, and in this study, wepresent AetherVision-Bench, a benchmark for multi-angle segmentation acrossaerial, and ground perspectives, which facilitates an extensive evaluation ofperformance across different viewing angles and sensor modalities. We assessstate-of-the-art OVSS models on the proposed benchmark and investigate the keyfactors that impact the performance of zero-shot transfer models. Our workpioneers the creation of a robustness benchmark, offering valuable insights andestablishing a foundation for future research.</description>
      <author>example@mail.com (Aniruddh Sikdar, Aditya Gandhamal, Suresh Sundaram)</author>
      <guid isPermaLink="false">2506.03709v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>On Support Samples of Next Word Prediction</title>
      <link>http://arxiv.org/abs/2506.04047v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACL2025(Main Conference)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了语言模型中的数据中心化可解释性，重点关注下一词预测任务，揭示了支持样本和非支持样本在模型决策中的不同作用。&lt;h4&gt;背景&lt;/h4&gt;语言模型在复杂决策中表现出色，但其决策背后的原因理解起来仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;探究语言模型中数据中心化可解释性，特别是针对下一词预测任务。&lt;h4&gt;方法&lt;/h4&gt;利用代表定理，识别出两种支持样本类型，并分析其在模型中的作用。&lt;h4&gt;主要发现&lt;/h4&gt;支持样本是非支持样本的固有属性，甚至在训练开始之前就可以预测。非支持样本在直接预测中影响力较小，但在防止过拟合和塑造泛化及表示学习方面起着关键作用。非支持样本的重要性在更深层次中增加，表明它们在中间表示形成中起着重要作用。&lt;h4&gt;结论&lt;/h4&gt;这些发现揭示了数据和模型决策之间的相互作用，为理解语言模型的行为和可解释性提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates data-centric interpretability in language models, focusing on the next-word prediction task. Using representer theorem, we identify two types of support samples - those that either promote or deter specific predictions. Our findings reveal that being a support sample is an intrinsic property, predictable even before training begins. Additionally, while non-support samples are less influential in direct predictions, they play a critical role in preventing overfitting and shaping generalization and representation learning. Notably, the importance of non-support samples increases in deeper layers, suggesting their significant role in intermediate representation formation. These insights shed light on the interplay between data and model decisions, offering a new dimension to understanding language model behavior and interpretability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Language models excel in various tasks by making complex decisions, yetunderstanding the rationale behind these decisions remains a challenge. Thispaper investigates \emph{data-centric interpretability} in language models,focusing on the next-word prediction task. Using representer theorem, weidentify two types of \emph{support samples}-those that either promote or deterspecific predictions. Our findings reveal that being a support sample is anintrinsic property, predictable even before training begins. Additionally,while non-support samples are less influential in direct predictions, they playa critical role in preventing overfitting and shaping generalization andrepresentation learning. Notably, the importance of non-support samplesincreases in deeper layers, suggesting their significant role in intermediaterepresentation formation.These insights shed light on the interplay betweendata and model decisions, offering a new dimension to understanding languagemodel behavior and interpretability.</description>
      <author>example@mail.com (Yuqian Li, Yupei Du, Yufang Liu, Feifei Feng, Mou Xiao Feng, Yuanbin Wu)</author>
      <guid isPermaLink="false">2506.04047v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Vegetation Index-Based Unsupervised Crop Stress Detection via Eigenvector-Guided Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.03394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;EigenCL是一种基于生物物理原理的无监督对比学习框架，用于作物早期压力检测，提高了检测准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;早期检测作物压力对于减少产量损失和及时干预精准农业至关重要。传统方法使用NDRE检测压力存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出EigenCL框架，实现作物压力的早期检测。&lt;h4&gt;方法&lt;/h4&gt;利用超过10,000个Sentinel-2NDRE图像块，构建每个块的五点NDRE时间序列，并推导出径向基函数（RBF）相似度矩阵。使用主要特征向量（解释76%的方差）定义压力感知相似度进行对比嵌入学习。&lt;h4&gt;主要发现&lt;/h4&gt;EigenCL通过生物相似的应力轨迹将嵌入拉近，将差异较大的嵌入推开，形成的嵌入聚类具有生理意义，检测准确率高达76%，比传统NDRE阈值提前12天。&lt;h4&gt;结论&lt;/h4&gt;EigenCL是一种无标签、可扩展的早期压力检测方法，与植物生理学相符合，适用于数据稀缺的农业环境。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Early detection of crop stress is vital for minimizing yield loss and enabling timely intervention in precision agriculture. Traditional approaches using NDRE often detect stress only after visible symptoms appear or require labeled datasets, limiting scalability. This study introduces EigenCL, a novel unsupervised contrastive learning framework guided by temporal NDRE dynamics and biologically grounded eigen decomposition. Using over 10,000 Sentinel-2NDRE image patches from drought-affected Iowa cornfields, we constructed five-point NDRE time series per patch and derived an RBF similarity matrix. The principal eigenvector explaining 76% of the variance and strongly correlated (r= 0.95) with raw NDRE values was used to define stress-aware similarity for contrastive embedding learning. Unlike existing methods that rely on visual augmentations, EigenCL pulls embeddings together based on biologically similar stress trajectories and pushes apart divergent ones. The learned embeddings formed physiologically meaningful clusters, achieving superior clustering metrics (Silhouette: 0.748, DBI: 0.35) and enabling 76% early stress detection up to 12 days before conventional NDRE thresholds. Downstream classification yielded 95% k-NN and 91% logistic regression accuracy. Validation on an independent 2023 Nebraska dataset confirmed generalizability without retraining. EigenCL offers a label-free, scalable approach for early stress detection that aligns with underlying plant physiology and is suitable for real-world deployment in data-scarce agricultural environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early detection of crop stress is vital for minimizing yield loss andenabling timely intervention in precision agriculture. Traditional approachesusing NDRE often detect stress only after visible symptoms appear or requirelabeled datasets, limiting scalability. This study introduces EigenCL, a novelunsupervised contrastive learning framework guided by temporal NDRE dynamicsand biologically grounded eigen decomposition. Using over 10,000 Sentinel-2NDRE image patches from drought-affected Iowa cornfields, we constructedfive-point NDRE time series per patch and derived an RBF similarity matrix. Theprincipal eigenvector explaining 76% of the variance and strongly correlated (r= 0.95) with raw NDRE values was used to define stress-aware similarity forcontrastive embedding learning. Unlike existing methods that rely on visualaugmentations, EigenCL pulls embeddings together based on biologically similarstress trajectories and pushes apart divergent ones. The learned embeddingsformed physiologically meaningful clusters, achieving superior clusteringmetrics (Silhouette: 0.748, DBI: 0.35) and enabling 76% early stress detectionup to 12 days before conventional NDRE thresholds. Downstream classificationyielded 95% k-NN and 91% logistic regression accuracy. Validation on anindependent 2023 Nebraska dataset confirmed generalizability withoutretraining. EigenCL offers a label-free, scalable approach for early stressdetection that aligns with underlying plant physiology and is suitable forreal-world deployment in data-scarce agricultural environments.</description>
      <author>example@mail.com (Shafqaat Ahmad)</author>
      <guid isPermaLink="false">2506.03394v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Semiconductor SEM Image Defect Classification Using Supervised and Semi-Supervised Learning with Vision Transformers</title>
      <link>http://arxiv.org/abs/2506.03345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at 36th Annual SEMI Advanced Semiconductor Manufacturing  Conference (ASMC) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉Transformer（ViT）神经网络自动分类扫描电子显微镜（SEM）图像中晶圆缺陷的方法，旨在提高分类准确性和计算效率。&lt;h4&gt;背景&lt;/h4&gt;半导体工艺中的缺陷控制对于保持产量、降低生产成本和防止关键组件的时变失效至关重要。传统的基于电子束的图像检测方法在缺陷分类方面存在时间、劳动力和人类偏见等局限性。&lt;h4&gt;目的&lt;/h4&gt;提高晶圆缺陷的自动分类准确率，并实现高效计算。&lt;h4&gt;方法&lt;/h4&gt;在IBM Albany工厂的300mm晶圆半导体缺陷数据集上评估了所提出的方法，研究了DinoV2迁移学习和半监督学习在提高分类准确性和计算效率方面的潜力。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用少于15张图像每个缺陷类别的数据，实现了超过90%的分类准确率。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了所提出的框架可以应用于一个平台无关的内部分类工具，具有更快的周转时间和灵活性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：控制半导体工艺中的缺陷对于维持产量、降低生产成本和防止关键组件的时变失效至关重要。基于电子束的成像技术已被用作晶圆检测的工具，以检查缺陷。然而，对于这些纳米级缺陷的图像手动分类受到时间、劳动力和人类偏见等限制。近年来，深度学习计算机视觉算法在工业中的图像检测应用中显示出其有效性。本研究提出了应用视觉Transformer（ViT）神经网络自动分类扫描电子显微镜（SEM）图像中晶圆缺陷的方法。我们在IBM Albany工厂的300mm晶圆半导体缺陷数据集上评估了所提出的方法，研究了DinoV2迁移学习和半监督学习在提高分类准确率和计算效率方面的潜力。我们能够实现每个缺陷类别少于15张图像的分类准确率超过90%。我们的工作证明了将所提出的框架应用于平台无关的内部分类工具的潜力，具有更快的周转时间和灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ASMC64512.2025.11010396&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Controlling defects in semiconductor processes is important for maintainingyield, improving production cost, and preventing time-dependent criticalcomponent failures. Electron beam-based imaging has been used as a tool tosurvey wafers in the line and inspect for defects. However, manualclassification of images for these nano-scale defects is limited by time, laborconstraints, and human biases. In recent years, deep learning computer visionalgorithms have shown to be effective solutions for image-based inspectionapplications in industry. This work proposes application of vision transformer(ViT) neural networks for automatic defect classification (ADC) of scanningelectron microscope (SEM) images of wafer defects. We evaluated our proposedmethods on 300mm wafer semiconductor defect data from our fab in IBM Albany. Westudied 11 defect types from over 7400 total images and investigated thepotential of transfer learning of DinoV2 and semi-supervised learning forimproved classification accuracy and efficient computation. We were able toachieve classification accuracies of over 90% with less than 15 images perdefect class. Our work demonstrates the potential to apply the proposedframework for a platform agnostic in-house classification tool with fasterturnaround time and flexibility.</description>
      <author>example@mail.com (Chien-Fu, Huang, Katherine Sieg, Leonid Karlinksy, Nash Flores, Rebekah Sheraw, Xin Zhang)</author>
      <guid isPermaLink="false">2506.03345v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>MudiNet: Task-guided Disentangled Representation Learning for 5G Indoor Multipath-assisted Positioning</title>
      <link>http://arxiv.org/abs/2506.04024v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了5G通信系统中基于多径辅助定位（MAP）的方法，提出了一种新的任务引导解耦表示学习方法，以提高定位精度。&lt;h4&gt;背景&lt;/h4&gt;在5G通信系统中，多径分量（MPC）被视为有价值的信息，但现有研究往往将反射面视为理想反射面，而忽略了由漫反射器引起的难以区分的多径问题。&lt;h4&gt;目的&lt;/h4&gt;旨在通过研究漫反射器的统计分布特征，设计一种方法来直接将信道脉冲响应（CIR）映射到位置，同时减轻对定位精度贡献较小的成分（如漫反射多径）的不利影响。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于多时间信道脉冲响应（CIR）观测的任务引导解耦表示学习方法，利用全局特征提取架构和多层感知器（MLP）来提取与用户设备（UE）位置相关的时变特征。此外，应用基于潜在变量模型（LVM）的变分推理来分离CIR中的独立特征，并通过位置标签指导LVM表达对定位更有益的成分。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟结果表明，所提出的方法在定位精度方面优于传统的基于搜索的定位方法，并且对漫反射器引起的难以区分的多径具有更强的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高5G通信系统中的定位精度，并具有较强的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;In the fifth-generation communication system (5G), multipath-assisted positioning (MAP) has emerged as a promising approach. With the enhancement of signal resolution, multipath components (MPC) are no longer regarded as noise but rather as valuable information that can contribute to positioning. However, existing research often treats reflective surfaces as ideal reflectors, while being powerless in the face of indistinguishable multipath caused by diffusely reflecting surfaces. This study approaches diffusely reflecting surfaces from the perspective of uncertainty, investigating the statistical distribution characteristics of indoor diffuse and specular reflectors. Based on these insights, a task-guided disentangled representation learning method leveraging multi-time channel impulse response (CIR) observations is designed to directly map CIRs to positions, while mitigating the adverse effects of components that contribute minimally to localization accuracy (e.g., diffuse multipath). In this semi-supervised learning framework, a global feature extraction architecture based on self-attention is proposed to capture location-independent wireless environmental information, while an MLP is employed to extract the time-varying features related to user equipment (UE) positions. Variational inference based on a latent variable model (LVM) is applied to separate independent features within the CIR, with position labels guiding the LVM to express components more beneficial for localization. Additionally, we provide a feasibility proof for the separability of diffuse and specular environmental features in CIRs. Simulation results demonstrate that the proposed method achieves higher localization accuracy compared to conventional search-based localization methods, with enhanced robustness against indistinguishable multipath from diffusely reflecting surfaces.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the fifth-generation communication system (5G), multipath-assistedpositioning (MAP) has emerged as a promising approach. With the enhancement ofsignal resolution, multipath component (MPC) are no longer regarded as noisebut rather as valuable information that can contribute to positioning. However,existing research often treats reflective surfaces as ideal reflectors, whilebeing powerless in the face of indistinguishable multipath caused by diffusereflectors. This study approaches diffuse reflectors from the perspective ofuncertainty, investigating the statistical distribution characteristics ofindoor diffuse and specular reflectors. Based on these insights, a task-guideddisentangled representation learning method leveraging multi-time channelimpulse response (CIR) observations is designed to directly map CIRs topositions, while mitigating the adverse effects of components that contributeminimally to localization accuracy (e.g., diffuse multipath).In thissemi-supervised learning framework, a global feature extraction architecturebased on self-attention is proposed to capture location-independent wirelessenvironmental information, while an MLP is employed to extract the time-varyingfeatures related to user equipment (UE) positions. Variational inference basedon a latent variable model (LVM) is applied to separate independent featureswithin the CIR, with position labels guiding the LVM to express components morebeneficial for localization. Additionally, we provide a feasibility proof forthe separability of diffuse and specular environmental features in CIRs.Simulation results demonstrate that the proposed method achieves higherlocalization accuracy compared to conventional search-based localizationmethods, with enhanced robustness against indistinguishable multipath fromdiffuse reflectors.</description>
      <author>example@mail.com (Ye Tian, Xueting Xu, Ao Peng)</author>
      <guid isPermaLink="false">2506.04024v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Out-of-Distribution Graph Models Merging</title>
      <link>http://arxiv.org/abs/2506.03674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了跨域图模型合并的新问题，旨在构建一个通用的模型，该模型由在不同领域上预训练的多个图模型组成，这些模型之间存在分布差异。本文提出了一种图生成策略，实例化了多个域的混合分布，并通过MoE模块和掩码机制进行模型合并和微调，以实现通用适应。框架架构无关，无需任何源/目标域数据。理论和实验结果都证明了该方法在解决模型泛化问题上的有效性。&lt;h4&gt;背景&lt;/h4&gt;本文研究的背景是跨域图模型合并问题，该问题由于模型参数中隐含的领域不变知识的难以学习以及从可能异构的GNN主干网络中整合专长而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;本文的目的是构建一个通用的模型，该模型能够从多个在不同领域上预训练的图模型中学习，并解决分布差异的问题。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种图生成策略，用于实例化多个域的混合分布。然后，通过MoE模块和掩码机制合并和微调预训练的图模型，以实现通用适应。&lt;h4&gt;主要发现&lt;/h4&gt;本文的主要发现是提出的框架能够有效地解决模型泛化问题，并且该框架是架构无关的，无需任何源/目标域数据。&lt;h4&gt;结论&lt;/h4&gt;本文的结论是，所提出的方法在解决跨域图模型合并问题上是有效的，能够提高模型的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了跨域图模型合并的新问题，旨在构建一个通用的模型，该模型由在不同领域上预训练的多个图模型组成，这些模型之间存在分布差异。这一问题由于模型参数中隐含的领域不变知识的难以学习以及从可能异构的GNN主干网络中整合专长而具有挑战性。在本文中，我们提出了一种图生成策略，用于实例化多个域的混合分布。然后，我们通过MoE模块和掩码机制合并和微调预训练的图模型，以实现通用适应。我们的框架架构无关，可以无任何源/目标域数据运行。理论和实验结果都证明了我们方法在解决模型泛化问题上的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper studies a novel problem of out-of-distribution graph modelsmerging, which aims to construct a generalized model from multiple graph modelspre-trained on different domains with distribution discrepancy. This problem ischallenging because of the difficulty in learning domain-invariant knowledgeimplicitly in model parameters and consolidating expertise from potentiallyheterogeneous GNN backbones. In this work, we propose a graph generationstrategy that instantiates the mixture distribution of multiple domains. Then,we merge and fine-tune the pre-trained graph models via a MoE module and amasking mechanism for generalized adaptation. Our framework isarchitecture-agnostic and can operate without any source/target domain data.Both theoretical analysis and experimental results demonstrate theeffectiveness of our approach in addressing the model generalization problem.</description>
      <author>example@mail.com (Yidi Wang, Jiawei Gu, pei Xiaobing, Xubin Zheng, Xiao Luo, Pengyang Wang, Ziyue Qiao)</author>
      <guid isPermaLink="false">2506.03674v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Spatial Understanding from Videos: Structured Prompts Meet Simulation Data</title>
      <link>http://arxiv.org/abs/2506.03642v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一框架，用于增强预训练视觉语言模型（VLMs）的3D空间推理能力，解决了空间不确定性和数据稀缺性问题。&lt;h4&gt;背景&lt;/h4&gt;视觉空间理解是机器人导航和具身交互等下游任务的基础，但现有方法存在空间不确定性和数据稀缺性的限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需修改模型架构的方法，以增强预训练VLMs的3D空间推理能力。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了SpatialMind和ScanForgeQA。SpatialMind是一种结构化提示策略，将复杂场景和问题分解为可解释的推理步骤；ScanForgeQA是一个可扩展的问答数据集，通过自动化构建过程从多样化的3D模拟场景中构建，用于微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提示和微调策略在多个基准测试中均表现出有效性和结合效果，并为未来关于视觉空间理解的研究提供了启示。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架有效提升了预训练VLMs的3D空间推理能力，为视觉空间理解领域的研究提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual-spatial understanding, the ability to infer object relationships andlayouts from visual input, is fundamental to downstream tasks such as roboticnavigation and embodied interaction. However, existing methods face spatialuncertainty and data scarcity, limiting the 3D spatial reasoning capability ofpre-trained vision-language models (VLMs). To address these challenges, wepresent a unified framework for enhancing 3D spatial reasoning in pre-trainedVLMs without modifying their architecture. This framework combines SpatialMind,a structured prompting strategy that decomposes complex scenes and questionsinto interpretable reasoning steps, with ScanForgeQA, a scalablequestion-answering dataset built from diverse 3D simulation scenes through anautomated construction process designed for fine-tuning. Extensive experimentsacross multiple benchmarks demonstrate the individual and combinedeffectiveness of our prompting and fine-tuning strategies, and yield insightsthat may inspire future research on visual-spatial understanding.</description>
      <author>example@mail.com (Haoyu Zhang, Meng Liu, Zaijing Li, Haokun Wen, Weili Guan, Yaowei Wang, Liqiang Nie)</author>
      <guid isPermaLink="false">2506.03642v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>MMM4Rec: A Transfer-Efficient Framework for Multi-modal Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2506.02916v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MMM4Rec的多模态序列推荐框架，旨在解决传统多模态推荐方法在新领域适应时的高调优成本问题，提高了多模态推荐的准确性和迁移能力。&lt;h4&gt;背景&lt;/h4&gt;虽然可迁移的多模态推荐架构在性能上优于传统基于ID的方法，但在新领域适应时，由于优化要求和负迁移效应，现有方法需要大量调优，这成为部署的瓶颈。&lt;h4&gt;目的&lt;/h4&gt;降低在新领域适应时的调优成本，提高多模态推荐系统的准确性和迁移能力。&lt;h4&gt;方法&lt;/h4&gt;MMM4Rec通过结合状态空间对偶（SSD）的时间衰减特性和时间感知建模设计，动态地优先考虑关键模态信息，并通过约束的两阶段过程实现序列级跨模态对齐和时序融合。&lt;h4&gt;主要发现&lt;/h4&gt;MMM4Rec在保持语义一致性的同时抑制噪声传播，实现了快速调优收敛，与现有模型相比，在NDCG@10指标上提高了31.78%，平均收敛速度提高了10倍。&lt;h4&gt;结论&lt;/h4&gt;MMM4Rec在多模态推荐方面达到了最先进的性能，显著提高了推荐的准确性和迁移能力，为高效复用预训练模型提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential Recommendation (SR) systems model user preferences by analyzinginteraction histories. Although transferable multi-modal SR architecturesdemonstrate superior performance compared to traditional ID-based approaches,current methods incur substantial fine-tuning costs when adapting to newdomains due to complex optimization requirements and negative transfer effects- a significant deployment bottleneck that hinders engineers from efficientlyrepurposing pre-trained models for novel application scenarios with minimaltuning overhead. We propose MMM4Rec (Multi-Modal Mamba for SequentialRecommendation), a novel multi-modal SR framework that incorporates a dedicatedalgebraic constraint mechanism for efficient transfer learning. By combiningState Space Duality (SSD)'s temporal decay properties with a time-awaremodeling design, our model dynamically prioritizes key modality information,overcoming limitations of Transformer-based approaches. The frameworkimplements a constrained two-stage process: (1) sequence-level cross-modalalignment via shared projection matrices, followed by (2) temporal fusion usingour newly designed Cross-SSD module and dual-channel Fourier adaptivefiltering. This architecture maintains semantic consistency while suppressingnoise propagation.MMM4Rec achieves rapid fine-tuning convergence with simplecross-entropy loss, significantly improving multi-modal recommendation accuracywhile maintaining strong transferability. Extensive experiments demonstrateMMM4Rec's state-of-the-art performance, achieving the maximum 31.78% NDCG@10improvement over existing models and exhibiting 10 times faster averageconvergence speed when transferring to large-scale downstream datasets.</description>
      <author>example@mail.com (Hao Fan, Yanrong Hu, Kai Fang, Qingyang Liu, Hongjiu Liu)</author>
      <guid isPermaLink="false">2506.02916v2</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>EV-Flying: an Event-based Dataset for In-The-Wild Recognition of Flying Objects</title>
      <link>http://arxiv.org/abs/2506.04048v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用事件相机进行空中物体监测的潜力，旨在提高对小型飞行物体，如昆虫和无人机的识别效率。&lt;h4&gt;背景&lt;/h4&gt;传统的基于RGB的方法在处理尺度变化、运动模糊和高速物体运动等方面存在困难，特别是对于小型飞行物体。&lt;h4&gt;目的&lt;/h4&gt;探索事件相机在检测和识别飞行物体，尤其是可能不遵循短期和长期可预测模式的动物方面的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出EV-Flying，一个基于事件的飞行物体数据集，包含手动标注的鸟类、昆虫和无人机，具有时空边界框和轨迹标识。为了有效地处理异步事件流，采用受PointNet启发的轻量级架构的点云方法。&lt;h4&gt;主要发现&lt;/h4&gt;研究了使用基于事件表示的点云进行飞行物体分类。&lt;h4&gt;结论&lt;/h4&gt;所提出的 dataset 和方法为在现实场景中更有效地进行空中物体识别铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monitoring aerial objects is crucial for security, wildlife conservation, andenvironmental studies. Traditional RGB-based approaches struggle withchallenges such as scale variations, motion blur, and high-speed objectmovements, especially for small flying entities like insects and drones. Inthis work, we explore the potential of event-based vision for detecting andrecognizing flying objects, in particular animals that may not follow short andlong-term predictable patters. Event cameras offer high temporal resolution,low latency, and robustness to motion blur, making them well-suited for thistask. We introduce EV-Flying, an event-based dataset of flying objects,comprising manually annotated birds, insects and drones with spatio-temporalbounding boxes and track identities. To effectively process the asynchronousevent streams, we employ a point-based approach leveraging lightweightarchitectures inspired by PointNet. Our study investigates the classificationof flying objects using point cloud-based event representations. The proposeddataset and methodology pave the way for more efficient and reliable aerialobject recognition in real-world scenarios.</description>
      <author>example@mail.com (Gabriele Magrini, Federico Becattini, Giovanni Colombo, Pietro Pala)</author>
      <guid isPermaLink="false">2506.04048v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>CARL: Causality-guided Architecture Representation Learning for an Interpretable Performance Predictor</title>
      <link>http://arxiv.org/abs/2506.04001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CARL的因果引导架构表示学习方法，用于神经架构搜索（NAS）的性能预测，旨在解决现有预测器在学习有限训练样本和多样测试样本之间内在分布差异时的泛化问题。&lt;h4&gt;背景&lt;/h4&gt;性能预测器被认为是加速神经架构搜索（NAS）评估阶段的可行方法，但大多数现有预测器忽视了训练样本和测试样本之间的分布差异，导致学习到虚假相关性，泛化能力差。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，能够分离架构的临界（因果）和冗余（非因果）特征，以实现可泛化的架构性能预测。&lt;h4&gt;方法&lt;/h4&gt;CARL方法使用子结构提取器将输入架构在潜在空间中分解为临界和冗余子结构。然后，通过将临界表示与多种冗余表示配对，生成多个干预样本，以优先考虑临界特征。&lt;h4&gt;主要发现&lt;/h4&gt;在五个NAS搜索空间上的广泛实验表明，CARL在准确性和可解释性方面达到了最先进水平。例如，在CIFAR-10上使用DARTS时，CARL达到了97.67%的top-1准确率。&lt;h4&gt;结论&lt;/h4&gt;CARL方法能够有效地解决NAS中性能预测的泛化问题，并显著提高了预测的准确性和可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Performance predictors have emerged as a promising method to accelerate theevaluation stage of neural architecture search (NAS). These predictors estimatethe performance of unseen architectures by learning from the correlationbetween a small set of trained architectures and their performance. However,most existing predictors ignore the inherent distribution shift between limitedtraining samples and diverse test samples. Hence, they tend to learn spuriouscorrelations as shortcuts to predictions, leading to poor generalization. Toaddress this, we propose a Causality-guided Architecture RepresentationLearning (CARL) method aiming to separate critical (causal) and redundant(non-causal) features of architectures for generalizable architectureperformance prediction. Specifically, we employ a substructure extractor tosplit the input architecture into critical and redundant substructures in thelatent space. Then, we generate multiple interventional samples by pairingcritical representations with diverse redundant representations to prioritizecritical features. Extensive experiments on five NAS search spaces demonstratethe state-of-the-art accuracy and superior interpretability of CARL. Forinstance, CARL achieves 97.67% top-1 accuracy on CIFAR-10 using DARTS.</description>
      <author>example@mail.com (Han Ji, Yuqi Feng, Jiahao Fan, Yanan Sun)</author>
      <guid isPermaLink="false">2506.04001v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Analyzing Transformer Models and Knowledge Distillation Approaches for Image Captioning on Edge AI</title>
      <link>http://arxiv.org/abs/2506.03607v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在边缘设备上运行的基于Transformer的图像描述模型，以提高机器感知能力，改善自主机器人的场景理解，并协助工业检查。&lt;h4&gt;背景&lt;/h4&gt;边缘计算将处理能力分散到网络边缘，使得物联网应用能够实现实时的人工智能驱动决策。在工业自动化领域，如机器人和坚固的边缘人工智能，实时感知和智能对于自主操作至关重要。&lt;h4&gt;目的&lt;/h4&gt;针对边缘或物联网设备计算资源有限且对响应时间有严格要求的问题，本文旨在提出一种资源高效的Transformer模型，以加速推理同时保持模型性能。&lt;h4&gt;方法&lt;/h4&gt;通过评估资源高效的Transformer模型并应用知识蒸馏技术，研究在资源受限设备上的模型有效运行。&lt;h4&gt;主要发现&lt;/h4&gt;研究者展示了在边缘设备上运行的Transformer模型能够有效进行图像描述，同时通过知识蒸馏技术加速推理过程。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在保持模型性能的同时，能够在资源受限的设备上实现推理加速。&lt;h4&gt;翻译&lt;/h4&gt;摘要：边缘计算将处理能力分散到网络边缘，使得物联网应用能够实现实时的人工智能驱动决策。在工业自动化，如机器人和坚固的边缘人工智能中，实时感知和智能对于自主操作至关重要。在边缘或物联网设备上部署基于Transformer的图像描述模型可以增强机器感知，改善自主机器人的场景理解，并协助工业检查。然而，这些边缘或物联网设备在物理灵活性方面通常受到计算资源的限制，同时它们对响应时间有严格的要求。传统的深度学习模型对于这些设备来说可能太大且计算密集。在本研究中，我们提出了在边缘设备上有效运行的基于Transformer的图像描述模型的发现。通过评估资源高效的Transformer模型并应用知识蒸馏技术，我们证明了使用这些技术可以在资源受限的设备上加速推理，同时保持模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Edge computing decentralizes processing power to network edge, enablingreal-time AI-driven decision-making in IoT applications. In industrialautomation such as robotics and rugged edge AI, real-time perception andintelligence are critical for autonomous operations. Deployingtransformer-based image captioning models at the edge can enhance machineperception, improve scene understanding for autonomous robots, and aid inindustrial inspection.  However, these edge or IoT devices are often constrained in computationalresources for physical agility, yet they have strict response timerequirements. Traditional deep learning models can be too large andcomputationally demanding for these devices. In this research, we presentfindings of transformer-based models for image captioning that operateeffectively on edge devices. By evaluating resource-effective transformermodels and applying knowledge distillation techniques, we demonstrate inferencecan be accelerated on resource-constrained devices while maintaining modelperformance using these techniques.</description>
      <author>example@mail.com (Wing Man Casca Kwok, Yip Chiu Tung, Kunal Bhagchandani)</author>
      <guid isPermaLink="false">2506.03607v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>How Far Are We from Predicting Missing Modalities with Foundation Models?</title>
      <link>http://arxiv.org/abs/2506.03530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了多模态基础模型在缺失模态预测中的潜力，并提出了一个针对性的框架以提升预测准确性和适应性。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型在多种任务中表现出色，但其作为即插即用解决方案的潜力尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;评估现有方法，并提出一个针对缺失模态预测的框架，以解决现有模型在语义提取和模态验证方面的不足。&lt;h4&gt;方法&lt;/h4&gt;将现有方法分为三类代表性范式，包含42个模型变体，并在预测准确性和适应性方面进行综合评估。&lt;h4&gt;主要发现&lt;/h4&gt;当前基础模型在细粒度语义提取和生成的模态稳健性验证方面存在不足，导致预测结果不理想。&lt;h4&gt;结论&lt;/h4&gt;提出的框架通过动态调整模态感知挖掘策略和自优化机制，显著提高了缺失图像和文本预测的FID和MER。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal foundation models have demonstrated impressive capabilities across diverse tasks. However, their potential as plug-and-play solutions for missing modality prediction remains underexplored. To investigate this, we categorize existing approaches into three representative paradigms, encompassing a total of 42 model variants, and conduct a comprehensive evaluation in terms of prediction accuracy and adaptability to downstream tasks. Our analysis reveals that current foundation models often fall short in two critical aspects: (i) fine-grained semantic extraction from the available modalities, and (ii) robust validation of generated modalities. These limitations lead to suboptimal and, at times, misaligned predictions. To address these challenges, we propose an agentic framework tailored for missing modality prediction. This framework dynamically formulates modality-aware mining strategies based on the input context, facilitating the extraction of richer and more discriminative semantic features. In addition, we introduce a self-refinement mechanism, which iteratively verifies and enhances the quality of generated modalities through internal feedback. Experimental results show that our method reduces FID for missing image prediction by at least 14% and MER for missing text prediction by at least 10% compared to baselines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal foundation models have demonstrated impressive capabilities acrossdiverse tasks. However, their potential as plug-and-play solutions for missingmodality prediction remains underexplored. To investigate this, we categorizeexisting approaches into three representative paradigms, encompassing a totalof 42 model variants, and conduct a comprehensive evaluation in terms ofprediction accuracy and adaptability to downstream tasks. Our analysis revealsthat current foundation models often fall short in two critical aspects: (i)fine-grained semantic extraction from the available modalities, and (ii) robustvalidation of generated modalities. These limitations lead to suboptimal and,at times, misaligned predictions. To address these challenges, we propose anagentic framework tailored for missing modality prediction. This frameworkdynamically formulates modality-aware mining strategies based on the inputcontext, facilitating the extraction of richer and more discriminative semanticfeatures. In addition, we introduce a \textit{self-refinement mechanism}, whichiteratively verifies and enhances the quality of generated modalities throughinternal feedback. Experimental results show that our method reduces FID formissing image prediction by at least 14% and MER for missing text prediction byat least 10% compared to baselines.</description>
      <author>example@mail.com (Guanzhou Ke, Yi Xie, Xiaoli Wang, Guoqing Chao, Bo Wang, Shengfeng He)</author>
      <guid isPermaLink="false">2506.03530v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>DiagNet: Detecting Objects using Diagonal Constraints on Adjacency Matrix of Graph Neural Network</title>
      <link>http://arxiv.org/abs/2506.03571v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了DaigNet，一种基于图卷积网络（GCN）邻接矩阵对角线约束的对象检测新方法。&lt;h4&gt;背景&lt;/h4&gt;现有的对象检测方法通常需要设计一系列锚框。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要设计锚框的对象检测方法。&lt;h4&gt;方法&lt;/h4&gt;提出了两种基于硬和软约束的邻接矩阵对角化算法，以及两种基于对角约束和补充约束的损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;DaigNet在Pascal VOC数据集上比YOLOv1提高了7.5%的mAP50，在MS COCO数据集上比YOLOv3u提高了5.1%，比YOLOv5u提高了3.7%，比YOLOv8提高了2.9%。&lt;h4&gt;结论&lt;/h4&gt;DaigNet是一种有效且性能优越的对象检测方法，具有无需设计锚框的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose DaigNet, a new approach to object detection with which we candetect an object bounding box using diagonal constraints on adjacency matrix ofa graph convolutional network (GCN). We propose two diagonalization algorithmsbased on hard and soft constraints on adjacency matrix and two loss functionsusing diagonal constraint and complementary constraint. The DaigNet eliminatesthe need for designing a set of anchor boxes commonly used. To provefeasibility of our novel detector, we adopt detection head in YOLO models.Experiments show that the DiagNet achieves 7.5% higher mAP50 on Pascal VOC thanYOLOv1. The DiagNet also shows 5.1% higher mAP on MS COCO than YOLOv3u, 3.7%higher mAP than YOLOv5u, and 2.9% higher mAP than YOLOv8.</description>
      <author>example@mail.com (Chong Hyun Lee, Kibae Lee)</author>
      <guid isPermaLink="false">2506.03571v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating SfM-based Pose Estimation with Dominating Set</title>
      <link>http://arxiv.org/abs/2506.03667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种预处理技术，用于加速基于运动结构（SfM）的姿态估计，这对于增强现实（AR）、虚拟现实（VR）和机器人等实时应用至关重要。&lt;h4&gt;背景&lt;/h4&gt;实时应用如增强现实、虚拟现实和机器人需要快速准确的姿态估计。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，在不牺牲显著精度的前提下，显著提高姿态估计过程的速度。&lt;h4&gt;方法&lt;/h4&gt;该方法利用图论中的支配集概念来预处理SfM模型。&lt;h4&gt;主要发现&lt;/h4&gt;使用OnePose数据集评估了该方法，结果显示处理速度提高了1.5到14.48倍，参考图像和点云大小分别减少了17-23倍和2.27-4倍。&lt;h4&gt;结论&lt;/h4&gt;这项工作为高效且准确的3D姿态估计提供了一个有前景的解决方案，在实时应用中平衡了速度和精度。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a preprocessing technique to speed up Structure-from-Motion (SfM) based pose estimation, which is critical for real-time applications like augmented reality (AR), virtual reality (VR), and robotics. Our method leverages the concept of a dominating set from graph theory to preprocess SfM models, significantly enhancing the speed of the pose estimation process without losing significant accuracy. Using the OnePose dataset, we evaluated our method across various SfM-based pose estimation techniques. The results demonstrate substantial improvements in processing speed, ranging from 1.5 to 14.48 times, and a reduction in reference images and point cloud size by factors of 17-23 and 2.27-4, respectively. This work offers a promising solution for efficient and accurate 3D pose estimation, balancing speed and accuracy in real-time applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a preprocessing technique to speed upStructure-from-Motion (SfM) based pose estimation, which is critical forreal-time applications like augmented reality (AR), virtual reality (VR), androbotics. Our method leverages the concept of a dominating set from graphtheory to preprocess SfM models, significantly enhancing the speed of the poseestimation process without losing significant accuracy. Using the OnePosedataset, we evaluated our method across various SfM-based pose estimationtechniques. The results demonstrate substantial improvements in processingspeed, ranging from 1.5 to 14.48 times, and a reduction in reference images andpoint cloud size by factors of 17-23 and 2.27-4, respectively. This work offersa promising solution for efficient and accurate 3D pose estimation, balancingspeed and accuracy in real-time applications.</description>
      <author>example@mail.com (Joji Joseph, Bharadwaj Amrutur, Shalabh Bhatnagar)</author>
      <guid isPermaLink="false">2506.03667v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Attention-Only Transformers via Unrolled Subspace Denoising</title>
      <link>http://arxiv.org/abs/2506.03790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 7 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种全新的可解释的transformer架构，通过压缩噪声初始标记表示到低维子空间来学习表示。&lt;h4&gt;背景&lt;/h4&gt;尽管transformer在实践中的应用很普遍，但其架构是经验设计的，既没有数学依据也不可解释。许多经验研究表明，transformer架构的一些组件可能是冗余的。&lt;h4&gt;目的&lt;/h4&gt;目标是推导出一个完全可解释的transformer架构，只包含必要的组件。&lt;h4&gt;方法&lt;/h4&gt;该方法通过将迭代去噪操作展开成一个深层网络，形成了一个高度紧凑的架构，该架构只包含自注意力算子，并在每一层有跳跃连接。每个层通过线性率提高标记表示的信号与噪声比。&lt;h4&gt;主要发现&lt;/h4&gt;每个层都执行高效的去噪，随着层数的增加，标记表示的信号与噪声比以线性速度提高。&lt;h4&gt;结论&lt;/h4&gt;尽管这种架构很简单，但在视觉和语言任务上的广泛实验表明，它达到的性能接近于标准transformer架构如GPT-2和CRATE。&lt;h4&gt;翻译&lt;/h4&gt;尽管transformers在实践中很受欢迎，但它们的架构是经验设计的，既没有数学依据也不可解释。许多经验研究表明，transformer架构的一些组件可能是冗余的。为了推导出一个只有必要组件的完全可解释的transformer架构，我们认为表示学习的目标是压缩一组噪声初始标记表示到一个低维子空间的混合体。为了压缩这些噪声标记表示，一个相关的去噪操作自然地采取多头（子空间）自注意力的形式。通过将这样的迭代去噪操作展开成一个深层网络，我们得到了一个高度紧凑的架构，该架构只包含自注意力算子，并在每一层有跳跃连接。此外，我们还表明，每一层都执行高度有效的去噪：它以线性速度提高标记表示的信号与噪声比。尽管它的简单性，但在视觉和语言任务上的广泛实验表明，这样的transformer达到的性能接近于标准transformer架构，如GPT-2和CRATE。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the popularity of transformers in practice, their architectures areempirically designed and neither mathematically justified nor interpretable.Moreover, as indicated by many empirical studies, some components oftransformer architectures may be redundant. To derive a fully interpretabletransformer architecture with only necessary components, we contend that thegoal of representation learning is to compress a set of noisy initial tokenrepresentations towards a mixture of low-dimensional subspaces. To compressthese noisy token representations, an associated denoising operation naturallytakes the form of a multi-head (subspace) self-attention. By unrolling suchiterative denoising operations into a deep network, we arrive at a highlycompact architecture that consists of \textit{only} self-attention operatorswith skip connections at each layer. Moreover, we show that each layer performshighly efficient denoising: it improves the signal-to-noise ratio of tokenrepresentations \textit{at a linear rate} with respect to the number of layers.Despite its simplicity, extensive experiments on vision and language tasksdemonstrate that such a transformer achieves performance close to that ofstandard transformer architectures such as GPT-2 and CRATE.</description>
      <author>example@mail.com (Peng Wang, Yifu Lu, Yaodong Yu, Druv Pai, Qing Qu, Yi Ma)</author>
      <guid isPermaLink="false">2506.03790v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Topology-Aware Graph Neural Network-based State Estimation for PMU-Unobservable Power Systems</title>
      <link>http://arxiv.org/abs/2506.03493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的深度几何学习方法，用于估计PMU不可观测的电力系统状态，以克服传统优化方法的高在线计算负担、有限的PMU覆盖范围和非高斯测量噪声等问题。&lt;h4&gt;背景&lt;/h4&gt;传统的基于优化的时间同步状态估计技术存在计算负担重、PMU覆盖范围有限和非高斯测量噪声等问题，而基于学习的模型容易受到拓扑变化和实时数据丢失的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过图神经网络来估计PMU不可观测的电力系统状态，以解决传统方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了图卷积和多头图注意力层在一个定制的端到端学习框架内，以处理拓扑变化和实时数据丢失，并推导出状态估计误差的上界。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在存在拓扑变化、PMU故障、坏数据、非高斯测量噪声和大型系统实施的情况下，所提出的定制GNN-SE（CGNN-SE）方法优于传统的基于优化的技术和基于学习的模型。&lt;h4&gt;结论&lt;/h4&gt;基于图神经网络的深度几何学习方法在处理电力系统状态估计方面表现出色，能够有效应对多种挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional optimization-based techniques for time-synchronized stateestimation (SE) often suffer from high online computational burden, limitedphasor measurement unit (PMU) coverage, and presence of non-Gaussianmeasurement noise. Although conventional learning-based models have beendeveloped to overcome these challenges, they are negatively impacted bytopology changes and real-time data loss. This paper proposes a novel deepgeometric learning approach based on graph neural networks (GNNs) to estimatethe states of PMU-unobservable power systems. The proposed approach combinesgraph convolution and multi-head graph attention layers inside a customizedend-to-end learning framework to handle topology changes and real-time dataloss. An upper bound on SE error as a function of topology change is alsoderived. Experimental results for different test systems demonstratesuperiority of the proposed customized GNN-SE (CGNN-SE) over traditionaloptimization-based techniques as well as conventional learning-based models inpresence of topology changes, PMU failures, bad data, non-Gaussian measurementnoise, and large system implementation.</description>
      <author>example@mail.com (Shiva Moshtagh, Behrouz Azimian, Mohammad Golgol, Anamitra Pal)</author>
      <guid isPermaLink="false">2506.03493v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models</title>
      <link>http://arxiv.org/abs/2506.03516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPR 2025 workshop - Foundation Models Meet Embodied  Agents&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种零样本目标导航框架，用于在未探索的环境中定位目标物体，该框架结合了视觉基础模型(VFMs)的感知能力和基于模型的规划器，实现了长时域决策。&lt;h4&gt;背景&lt;/h4&gt;目标导航是具身AI中的基本任务，传统方法依赖于大量标注数据或强化学习环境中的大量交互，难以泛化到新环境且可扩展性有限。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战，本文探索了零样本设置，使代理在没有特定任务训练的情况下操作，以实现更可扩展和适应性强的解决方案。&lt;h4&gt;方法&lt;/h4&gt;该框架集成了VFMs的感知能力与能够通过前沿探索进行长时域决策的模型化规划器。&lt;h4&gt;主要发现&lt;/h4&gt;在HM3D数据集上使用Habitat模拟器评估该方法，结果显示在零样本目标导航方面，该方法在成功加权路径长度方面达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在零样本目标导航任务中取得了显著的性能提升，为具身AI领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object goal navigation is a fundamental task in embodied AI, where an agentis instructed to locate a target object in an unexplored environment.Traditional learning-based methods rely heavily on large-scale annotated dataor require extensive interaction with the environment in a reinforcementlearning setting, often failing to generalize to novel environments andlimiting scalability. To overcome these challenges, we explore a zero-shotsetting where the agent operates without task-specific training, enabling morescalable and adaptable solution. Recent advances in Vision Foundation Models(VFMs) offer powerful capabilities for visual understanding and reasoning,making them ideal for agents to comprehend scenes, identify relevant regions,and infer the likely locations of objects. In this work, we present a zero-shotobject goal navigation framework that integrates the perceptual strength ofVFMs with a model-based planner that is capable of long-horizon decision makingthrough frontier exploration. We evaluate our approach on the HM3D datasetusing the Habitat simulator and demonstrate that our method achievesstate-of-the-art performance in terms of success weighted by path length forzero-shot object goal navigation.</description>
      <author>example@mail.com (Arnab Debnath, Gregory J. Stein, Jana Kosecka)</author>
      <guid isPermaLink="false">2506.03516v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Go Beyond Earth: Understanding Human Actions and Scenes in Microgravity Environments</title>
      <link>http://arxiv.org/abs/2506.02845v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 3 figures, code are available at  https://github.com/LEI-QI-233/HAR-in-Space&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了MicroG-4M，这是一个用于微重力下人类活动时空和语义理解的基准数据集。&lt;h4&gt;背景&lt;/h4&gt;尽管视频理解取得了重大进展，但大多数现有数据集仅限于地球重力条件，而微重力会改变人类运动、交互和视觉语义，这对现实世界的视觉系统提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，本文提出MicroG-4M，旨在评估微重力环境下的空间定位和语义推理。&lt;h4&gt;方法&lt;/h4&gt;MicroG-4M由真实太空任务和电影模拟构建，包含4,759个片段，涵盖了50个动作，1,238个丰富的上下文字幕，以及关于宇航员活动和场景理解的7,000多对问答。&lt;h4&gt;主要发现&lt;/h4&gt;MicroG-4M支持三个核心任务：细粒度多标签动作识别、时间视频字幕生成和视觉问答，为微重力环境下的空间定位和语义推理提供了全面的评估。&lt;h4&gt;结论&lt;/h4&gt;通过使用最先进的模型建立基线，所有数据、标注和代码都在https://github.com/LEI-QI-233/HAR-in-Space上提供。&lt;h4&gt;翻译&lt;/h4&gt;尽管在视频理解方面取得了重大进展，但大多数现有数据集仅限于地球的重力条件。然而，微重力会改变人类运动、交互和视觉语义，这揭示了现实世界视觉系统的一个关键差距。这为安全关键的太空应用中的领域鲁棒视频理解带来了挑战。为了解决这个问题，我们引入了MicroG-4M，这是第一个用于微重力下人类活动时空和语义理解的基准。该数据集由真实世界的太空任务和电影模拟构建，包括4,759个片段，涵盖了50个动作，1,238个丰富的上下文字幕，以及关于宇航员活动和场景理解的7,000多对问答。MicroG-4M支持三个核心任务：细粒度多标签动作识别、时间视频字幕生成和视觉问答，使得对微重力环境下的空间定位和语义推理的全面评估成为可能。我们使用最先进的模型建立了基线。所有数据、标注和代码均可在https://github.com/LEI-QI-233/HAR-in-Space上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite substantial progress in video understanding, most existing datasetsare limited to Earth's gravitational conditions. However, microgravity altershuman motion, interactions, and visual semantics, revealing a critical gap forreal-world vision systems. This presents a challenge for domain-robust videounderstanding in safety-critical space applications. To address this, weintroduce MicroG-4M, the first benchmark for spatio-temporal and semanticunderstanding of human activities in microgravity. Constructed from real-worldspace missions and cinematic simulations, the dataset includes 4,759 clipscovering 50 actions, 1,238 context-rich captions, and over 7,000question-answer pairs on astronaut activities and scene understanding.MicroG-4M supports three core tasks: fine-grained multi-label actionrecognition, temporal video captioning, and visual question answering, enablinga comprehensive evaluation of both spatial localization and semantic reasoningin microgravity contexts. We establish baselines using state-of-the-art models.All data, annotations, and code are available athttps://github.com/LEI-QI-233/HAR-in-Space.</description>
      <author>example@mail.com (Di Wen, Lei Qi, Kunyu Peng, Kailun Yang, Fei Teng, Ao Luo, Jia Fu, Yufan Chen, Ruiping Liu, Yitian Shi, M. Saquib Sarfraz, Rainer Stiefelhagen)</author>
      <guid isPermaLink="false">2506.02845v2</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision</title>
      <link>http://arxiv.org/abs/2506.03605v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种框架，利用Exo-Ego4D构建的大规模视频数据集，提取各种物体的多样化操作轨迹，并基于这些轨迹开发轨迹生成模型，以解决交互式机器人在常见场景中学习使用工具或物体的挑战。&lt;h4&gt;背景&lt;/h4&gt;训练模型生成操作轨迹需要大量多样化的详细操作演示，这在规模上几乎不可行。&lt;h4&gt;目的&lt;/h4&gt;开发能够从动作描述中生成6DoF操作轨迹的模型，为交互式机器人处理常见场景中的工具或物体提供支持。&lt;h4&gt;方法&lt;/h4&gt;提出了一种框架，利用大规模的Exo-Ego4D视频数据集提取操作轨迹，并基于这些轨迹和相关文本动作描述开发轨迹生成模型。&lt;h4&gt;主要发现&lt;/h4&gt;在HOT3D的ego-centric vision-based in-a-quality轨迹数据集上，模型成功生成了有效的物体轨迹，建立了训练数据集和基线模型。&lt;h4&gt;结论&lt;/h4&gt;该框架和模型为生成6DoF操作轨迹提供了一个有效的解决方案，有助于交互式机器人学习在常见场景中使用工具或物体。&lt;h4&gt;翻译&lt;/h4&gt;在常见场景中学习使用工具或物体，尤其是按指令以各种方式处理它们，是开发交互式机器人的一项关键挑战。训练生成此类操作轨迹的模型需要大量和多样化的详细操作演示，这对于各种物体而言几乎是不可能收集到的规模。在本文中，我们提出了一种框架，该框架利用了由Exo-Ego4D构建的大规模自我和外部视角视频数据集——这些数据集在全球范围内投入了大量努力——以大规模地提取多样化的操作轨迹。从这些提取的轨迹和相关文本动作描述中，我们开发了基于视觉和基于点云的语言模型的轨迹生成模型。在最近提出的HOT3D的以自我为中心的视觉为基础的高质量轨迹数据集中，我们证实了我们的模型成功地生成了有效的物体轨迹，为从自我为中心视觉中的动作描述生成6DoF操作轨迹的新的任务建立了训练数据集和基线模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning to use tools or objects in common scenes, particularly handling themin various ways as instructed, is a key challenge for developing interactiverobots. Training models to generate such manipulation trajectories requires alarge and diverse collection of detailed manipulation demonstrations forvarious objects, which is nearly unfeasible to gather at scale. In this paper,we propose a framework that leverages large-scale ego- and exo-centric videodatasets -- constructed globally with substantial effort -- of Exo-Ego4D toextract diverse manipulation trajectories at scale. From these extractedtrajectories with the associated textual action description, we developtrajectory generation models based on visual and point cloud-based languagemodels. In the recently proposed egocentric vision-based in-a-qualitytrajectory dataset of HOT3D, we confirmed that our models successfully generatevalid object trajectories, establishing a training dataset and baseline modelsfor the novel task of generating 6DoF manipulation trajectories from actiondescriptions in egocentric vision.</description>
      <author>example@mail.com (Tomoya Yoshida, Shuhei Kurita, Taichi Nishimura, Shinsuke Mori)</author>
      <guid isPermaLink="false">2506.03605v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Geometric Visual Fusion Graph Neural Networks for Multi-Person Human-Object Interaction Recognition in Videos</title>
      <link>http://arxiv.org/abs/2506.03440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Expert Systems with Applications (ESWA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为GeoVis-GNN的几何视觉融合图神经网络，用于视频中的HOI识别，通过结合双注意力特征融合和相互依存的实体图学习，实现多模态特征的有效融合。&lt;h4&gt;背景&lt;/h4&gt;视频中的HOI识别需要理解随时间演变的视觉模式和几何关系，视觉和几何特征各有优势，但如何有效地融合这些特征是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;为了有效地融合多模态特征，论文提出了一种自下而上的方法，并提出了GeoVis-GNN模型，旨在提高HOI识别的性能。&lt;h4&gt;方法&lt;/h4&gt;GeoVis-GNN使用双注意力特征融合和相互依存的实体图学习，从实体特定的表示逐步构建到高级交互理解。&lt;h4&gt;主要发现&lt;/h4&gt;论文引入了MPHOI-120数据集，该数据集捕捉动态的多个人交互，包括同时动作和部分参与，有助于解决复杂的人-物动态和相互遮挡等问题。&lt;h4&gt;结论&lt;/h4&gt;实验表明，该方法在各种HOI场景中均取得了最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;Human-Object Interaction (HOI) recognition in videos requires understanding both visual patterns and geometric relationships as they evolve over time. Visual and geometric features offer complementary strengths. Visual features capture appearance context, while geometric features provide structural patterns. Effectively fusing these multimodal features without compromising their unique characteristics remains challenging. We observe that establishing robust, entity-specific representations before modeling interactions helps preserve the strengths of each modality. Therefore, we hypothesize that a bottom-up approach is crucial for effective multimodal fusion. Following this insight, we propose the Geometric Visual Fusion Graph Neural Network (GeoVis-GNN), which uses dual-attention feature fusion combined with interdependent entity graph learning. It progressively builds from entity-specific representations toward high-level interaction understanding. To advance HOI recognition to real-world scenarios, we introduce the Concurrent Partial Interaction Dataset (MPHOI-120). It captures dynamic multi-person interactions involving concurrent actions and partial engagement. This dataset helps address challenges like complex human-object dynamics and mutual occlusions. Extensive experiments demonstrate the effectiveness of our method across various HOI scenarios. These scenarios include two-person interactions, single-person activities, bimanual manipulations, and complex concurrent partial interactions. Our method achieves state-of-the-art performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human-Object Interaction (HOI) recognition in videos requires understandingboth visual patterns and geometric relationships as they evolve over time.Visual and geometric features offer complementary strengths. Visual featurescapture appearance context, while geometric features provide structuralpatterns. Effectively fusing these multimodal features without compromisingtheir unique characteristics remains challenging. We observe that establishingrobust, entity-specific representations before modeling interactions helpspreserve the strengths of each modality. Therefore, we hypothesize that abottom-up approach is crucial for effective multimodal fusion. Following thisinsight, we propose the Geometric Visual Fusion Graph Neural Network(GeoVis-GNN), which uses dual-attention feature fusion combined withinterdependent entity graph learning. It progressively builds fromentity-specific representations toward high-level interaction understanding. Toadvance HOI recognition to real-world scenarios, we introduce the ConcurrentPartial Interaction Dataset (MPHOI-120). It captures dynamic multi-personinteractions involving concurrent actions and partial engagement. This datasethelps address challenges like complex human-object dynamics and mutualocclusions. Extensive experiments demonstrate the effectiveness of our methodacross various HOI scenarios. These scenarios include two-person interactions,single-person activities, bimanual manipulations, and complex concurrentpartial interactions. Our method achieves state-of-the-art performance.</description>
      <author>example@mail.com (Tanqiu Qiao, Ruochen Li, Frederick W. B. Li, Yoshiki Kubotani, Shigeo Morishima, Hubert P. H. Shum)</author>
      <guid isPermaLink="false">2506.03440v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Physics and Computing Performance of the EggNet Tracking Pipeline</title>
      <link>http://arxiv.org/abs/2506.03415v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于图神经网络（GNN）的粒子轨迹重建方法，特别是EggNet这一单次方法，并评估了其在TrackML数据集上的物理和计算性能。&lt;h4&gt;背景&lt;/h4&gt;传统的粒子轨迹重建算法由于组合性质而计算复杂，近年来GNN被用于提高算法的可扩展性。&lt;h4&gt;目的&lt;/h4&gt;评估EggNet跟踪管道在TrackML数据集上的物理和计算性能，并探索减少计算内存和时间的不同技术。&lt;h4&gt;方法&lt;/h4&gt;提出了一种EggNet方法，该方法直接以探测器空间点为输入，迭代地应用图注意力网络，并随着图结构的演变更新图，以提高边缘效率和纯度。&lt;h4&gt;主要发现&lt;/h4&gt;EggNet方法在TrackML数据集上提供了良好的模型性能，同时探索了减少计算资源消耗的技术。&lt;h4&gt;结论&lt;/h4&gt;EggNet是一种有效的粒子轨迹重建方法，有助于提高算法的可扩展性和性能。&lt;h4&gt;翻译&lt;/h4&gt;Particle track reconstruction is traditionally computationally challenging due to the combinatorial nature of the tracking algorithms employed. Recent developments have focused on novel algorithms with graph neural networks (GNNs), which can improve scalability. While most of these GNN-based methods require an input graph to be constructed before performing message passing, a one-shot approach called EggNet that directly takes detector spacepoints as inputs and iteratively apply graph attention networks with an evolving graph structure has been proposed. The graphs are gradually updated to improve the edge efficiency and purity, thus providing a better model performance. In this work, we evaluate the physics and computing performance of the EggNet tracking pipeline on the full TrackML dataset. We also explore different techniques to reduce constraints on computation memory and computing time.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Particle track reconstruction is traditionally computationally challengingdue to the combinatorial nature of the tracking algorithms employed. Recentdevelopments have focused on novel algorithms with graph neural networks(GNNs), which can improve scalability. While most of these GNN-based methodsrequire an input graph to be constructed before performing message passing, aone-shot approach called EggNet that directly takes detector spacepoints asinputs and iteratively apply graph attention networks with an evolving graphstructure has been proposed. The graphs are gradually updated to improve theedge efficiency and purity, thus providing a better model performance. In thiswork, we evaluate the physics and computing performance of the EggNet trackingpipeline on the full TrackML dataset. We also explore different techniques toreduce constraints on computation memory and computing time.</description>
      <author>example@mail.com (Jay Chan, Brandon Wang, Paolo Calafiura)</author>
      <guid isPermaLink="false">2506.03415v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>OpenCarbon: A Contrastive Learning-based Cross-Modality Neural Approach for High-Resolution Carbon Emission Prediction Using Open Data</title>
      <link>http://arxiv.org/abs/2506.03224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于开放数据的碳排放预测模型OpenCarbon，用于高分辨率城市碳排放预测，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;精确估计高分辨率碳排放对于有效的排放治理和缓解规划至关重要。传统的精确碳核算方法因数据收集工作量大而受限。&lt;h4&gt;目的&lt;/h4&gt;开发一个基于开放数据的预测模型，以简化高分辨率碳排放的估计。&lt;h4&gt;方法&lt;/h4&gt;结合卫星图像和POI数据，利用跨模态信息提取和融合模块以及邻域信息聚合模块来预测高分辨率城市碳排放。&lt;h4&gt;主要发现&lt;/h4&gt;OpenCarbon模型在R2性能上提升了26.6%，并且能够捕捉城市功能与碳排放之间的内在关系。&lt;h4&gt;结论&lt;/h4&gt;OpenCarbon模型能够有效促进碳治理和针对性的碳缓解规划。&lt;h4&gt;翻译&lt;/h4&gt;Accurately estimating high-resolution carbon emissions is crucial for effective emission governance and mitigation planning. While conventional methods for precise carbon accounting are hindered by substantial data collection efforts, the rise of open data and advanced learning techniques offers a promising solution. Once an open data-based prediction model is developed and trained, it can easily infer emissions for new areas based on available open data. To address this, we incorporate two modalities of open data, satellite images and point-of-interest (POI) data, to predict high-resolution urban carbon emissions, with satellite images providing macroscopic and static and POI data offering fine-grained and relatively dynamic functionality information. However, estimating high-resolution carbon emissions presents two significant challenges: the intertwined and implicit effects of various functionalities on carbon emissions, and the complex spatial contiguity correlations that give rise to the agglomeration effect. Our model, OpenCarbon, features two major designs that target the challenges: a cross-modality information extraction and fusion module to extract complementary functionality information from two modules and model their interactions, and a neighborhood-informed aggregation module to capture the spatial contiguity correlations. Extensive experiments demonstrate our model's superiority, with a significant performance gain of 26.6% on R2. Further generalizability tests and case studies also show OpenCarbon's capacity to capture the intrinsic relation between urban functionalities and carbon emissions, validating its potential to empower efficient carbon governance and targeted carbon mitigation planning. Codes and data are available: https://github.com/JinweiZzz/OpenCarbon.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately estimating high-resolution carbon emissions is crucial foreffective emission governance and mitigation planning. While conventionalmethods for precise carbon accounting are hindered by substantial datacollection efforts, the rise of open data and advanced learning techniquesoffers a promising solution. Once an open data-based prediction model isdeveloped and trained, it can easily infer emissions for new areas based onavailable open data. To address this, we incorporate two modalities of opendata, satellite images and point-of-interest (POI) data, to predicthigh-resolution urban carbon emissions, with satellite images providingmacroscopic and static and POI data offering fine-grained and relativelydynamic functionality information. However, estimating high-resolution carbonemissions presents two significant challenges: the intertwined and impliciteffects of various functionalities on carbon emissions, and the complex spatialcontiguity correlations that give rise to the agglomeration effect. Our model,OpenCarbon, features two major designs that target the challenges: across-modality information extraction and fusion module to extractcomplementary functionality information from two modules and model theirinteractions, and a neighborhood-informed aggregation module to capture thespatial contiguity correlations. Extensive experiments demonstrate our model'ssuperiority, with a significant performance gain of 26.6\% on R2. Furthergeneralizability tests and case studies also show OpenCarbon's capacity tocapture the intrinsic relation between urban functionalities and carbonemissions, validating its potential to empower efficient carbon governance andtargeted carbon mitigation planning. Codes and data are available:https://github.com/JinweiZzz/OpenCarbon.</description>
      <author>example@mail.com (Jinwei Zeng, Yu Liu, Guozhen Zhang, Jingtao Ding, Yuming Lin, Jian Yuan, Yong Li)</author>
      <guid isPermaLink="false">2506.03224v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>When Does Closeness in Distribution Imply Representational Similarity? An Identifiability Perspective</title>
      <link>http://arxiv.org/abs/2506.03784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了不同深度神经网络学习到的表示相似性的问题，并从可识别性理论的角度出发，探讨了当模型生成的分布接近时，模型表示相似的条件。&lt;h4&gt;背景&lt;/h4&gt;表示相似性是深度神经网络研究中的一个活跃话题。&lt;h4&gt;目的&lt;/h4&gt;通过研究，确定模型分布接近时，模型表示是否也相似。&lt;h4&gt;方法&lt;/h4&gt;作者从可识别性理论出发，定义了一种分布距离，用于衡量表示的相似性，并通过实验验证了其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，模型分布之间的Kullback-Leibler散度小并不保证对应的表示相似。此外，网络宽度与分布距离和表示相似性之间存在关联。&lt;h4&gt;结论&lt;/h4&gt;本文建立了分布接近与表示相似性之间的联系。&lt;h4&gt;翻译&lt;/h4&gt;摘要：何时以及为什么不同深度神经网络学习到的表示相似是一个活跃的研究课题。我们选择从可识别性理论的角度来回答这些问题，该理论表明，表示相似性的度量应该对不改变模型分布的变换是不变的。我们关注一个包括几个流行的预训练方法（例如，自回归语言模型）的模型家族，我们探讨了当模型生成接近的分布时，模型表示何时相似。我们证明了模型分布之间的小Kullback-Leibler散度并不能保证相应的表示相似。这有一个重要的推论，即任意接近最大化似然性的模型仍然可以学习到不相似的表示，这一现象在我们的CIFAR-10上训练的模型的经验观察中也得到了反映。然后我们定义了一种分布距离，其中接近性意味着表示相似性，在合成实验中，我们发现更宽的网络学习到与我们距离更近的分布，并且具有更相似的表示。我们的结果在分布接近和表示相似性之间建立了一个联系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When and why representations learned by different deep neural networks aresimilar is an active research topic. We choose to address these questions fromthe perspective of identifiability theory, which suggests that a measure ofrepresentational similarity should be invariant to transformations that leavethe model distribution unchanged. Focusing on a model family which includesseveral popular pre-training approaches, e.g., autoregressive language models,we explore when models which generate distributions that are close have similarrepresentations. We prove that a small Kullback-Leibler divergence between themodel distributions does not guarantee that the corresponding representationsare similar. This has the important corollary that models arbitrarily close tomaximizing the likelihood can still learn dissimilar representations, aphenomenon mirrored in our empirical observations on models trained onCIFAR-10. We then define a distributional distance for which closeness impliesrepresentational similarity, and in synthetic experiments, we find that widernetworks learn distributions which are closer with respect to our distance andhave more similar representations. Our results establish a link betweencloseness in distribution and representational similarity.</description>
      <author>example@mail.com (Beatrix M. G. Nielsen, Emanuele Marconato, Andrea Dittadi, Luigi Gresele)</author>
      <guid isPermaLink="false">2506.03784v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>ViT-Split: Unleashing the Power of Vision Foundation Models via Efficient Splitting Heads</title>
      <link>http://arxiv.org/abs/2506.03433v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The project is available:  https://jackyfl.github.io/vitsplit.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ViT-Split的新方法，用于改进视觉基础模型（VFMs）的适配器，以提升其在下游任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的VFM适配器通过利用VFMs的先验知识取得了良好的效果，但存在效率和复杂性方面的问题。&lt;h4&gt;目的&lt;/h4&gt;针对现有方法的不足，提出ViT-Split方法，旨在提高训练效率并减少对参数的调整。&lt;h4&gt;方法&lt;/h4&gt;ViT-Split基于对多个VFMs（如DINOv2）层的观察，将其分为两个组件：一个用于学习低级特征的学习器和一个用于学习特定任务特征的学习器。该方法消除了CNN分支，并引入了任务头和先验头，以解决早期梯度回传问题和利用先验知识。&lt;h4&gt;主要发现&lt;/h4&gt;ViT-Split通过消除CNN分支和引入两个头，有效减少了早期梯度回传，并利用了冻结的VFM的多尺度先验特征，从而减少了调整参数和过拟合的可能性。&lt;h4&gt;结论&lt;/h4&gt;在多个任务（如分割、检测、深度估计和视觉问答）上的实验验证了ViT-Split的有效性和效率，其训练时间可减少至原来的1/4，同时在ADE20K数据集上取得了与现有VFM适配器相当甚至更好的结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉基础模型（VFMs）在广泛的下游任务中表现出色。虽然一些VFM适配器通过利用VFMs的先验知识取得了有希望的结果，但我们在这些方法中识别出两种低效性。首先，卷积神经网络（CNN）与VFM骨干之间的交互触发了早期层梯度回传。其次，现有方法需要调整所有组件，增加了复杂性。此外，这些适配器改变了VFM特征，未能充分利用先验知识。为了解决这些挑战，我们提出了一种名为ViT-Split的新方法，基于一个关键观察：多个VFMs（如DINOv2）的层可以被分为两个不同的组件：一个用于学习低级特征的学习器和一个用于学习特定任务特征的学习器。利用这一洞察，我们消除了CNN分支，并引入了两个头，任务头和先验头，到冻结的VFM中。任务头被设计用于学习特定任务的特征，减轻了早期梯度传播问题。先验头用于利用冻结的VFM的多尺度先验特征，减少调整参数和过拟合。在分割、检测、深度估计和视觉问答等各个任务上的广泛实验验证了ViT-Split的有效性和效率。具体来说，ViT-Split将训练时间减少了高达4倍，同时在ADE20K数据集上与其它VFM适配器相比，取得了相当甚至更好的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision foundation models (VFMs) have demonstrated remarkable performanceacross a wide range of downstream tasks. While several VFM adapters have shownpromising results by leveraging the prior knowledge of VFMs, we identify twoinefficiencies in these approaches. First, the interaction betweenconvolutional neural network (CNN) and VFM backbone triggers early layergradient backpropagation. Second, existing methods require tuning allcomponents, adding complexity. Besides, these adapters alter VFM features,underutilizing the prior knowledge. To tackle these challenges, we propose anew approach called ViT-Split, based on a key observation: the layers ofseveral VFMs, like DINOv2, can be divided into two distinct components: anextractor for learning low-level features and an adapter for learningtask-specific features. Leveraging this insight, we eliminate the CNN branchand introduce two heads, task head and prior head, to the frozen VFM. The taskhead is designed to learn task-specific features, mitigating the early gradientpropagation issue. The prior head is used to leverage the multi-scale priorfeatures from the frozen VFM, reducing tuning parameters and overfitting.Extensive experiments on various tasks (e.g., segmentation, detection, depthestimation, and visual question answering) validate the effectiveness andefficiency of ViT-Split. Specifically, ViT-Split reduces training time up to$4\times$ while achieving comparable or even better results on ADE20K, comparedto other VFM adapters.</description>
      <author>example@mail.com (Yifan Li, Xin Li, Tianqin Li, Wenbin He, Yu Kong, Liu Ren)</author>
      <guid isPermaLink="false">2506.03433v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>KG-BiLM: Knowledge Graph Embedding via Bidirectional Language Models</title>
      <link>http://arxiv.org/abs/2506.03576v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为KG-BiLM的框架，用于统一知识图谱和语言模型，以实现更丰富的语义理解。&lt;h4&gt;背景&lt;/h4&gt;当前知识表示学习（KRL）的进展表明，将符号知识图谱（KGs）与语言模型（LMs）结合的必要性。&lt;h4&gt;目的&lt;/h4&gt;填补现有方法只关注图结构或文本语义的空白，同时捕捉全局KG连通性、细微的语言上下文和判别推理语义。&lt;h4&gt;方法&lt;/h4&gt;KG-BiLM包含三个关键组件：双向知识注意力、知识掩码预测和对比图语义聚合。&lt;h4&gt;主要发现&lt;/h4&gt;在标准基准测试中，KG-BiLM在链接预测任务上优于强基线，特别是在具有复杂多跳关系的大规模图上，验证了其统一结构和文本语义的有效性。&lt;h4&gt;结论&lt;/h4&gt;KG-BiLM通过融合知识图谱的结构线索和生成变换器的语义表达，为统一结构信息和文本语义提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in knowledge representation learning (KRL) highlight theurgent necessity to unify symbolic knowledge graphs (KGs) with language models(LMs) for richer semantic understanding. However, existing approaches typicallyprioritize either graph structure or textual semantics, leaving a gap: aunified framework that simultaneously captures global KG connectivity, nuancedlinguistic context, and discriminative reasoning semantics. To bridge this gap,we introduce KG-BiLM, a bidirectional LM framework that fuses structural cuesfrom KGs with the semantic expressiveness of generative transformers. KG-BiLMincorporates three key components: (i) Bidirectional Knowledge Attention, whichremoves the causal mask to enable full interaction among all tokens andentities; (ii) Knowledge-Masked Prediction, which encourages the model toleverage both local semantic contexts and global graph connectivity; and (iii)Contrastive Graph Semantic Aggregation, which preserves KG structure viacontrastive alignment of sampled sub-graph representations. Extensiveexperiments on standard benchmarks demonstrate that KG-BiLM outperforms strongbaselines in link prediction, especially on large-scale graphs with complexmulti-hop relations - validating its effectiveness in unifying structuralinformation and textual semantics.</description>
      <author>example@mail.com (Zirui Chen, Xin Wang, Zhao Li, Wenbin Guo, Dongxiao He)</author>
      <guid isPermaLink="false">2506.03576v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>POLARIS: A High-contrast Polarimetric Imaging Benchmark Dataset for Exoplanetary Disk Representation Learning</title>
      <link>http://arxiv.org/abs/2506.03511v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages main text with 5 figures, 9 pages appendix with 9 figures.  Submitted to NeurIPS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了利用人工智能技术对地外行星进行成像的可能性，并提出了一个基于偏振光数据表示学习的基准，探索了未来十年人工智能在成像类地行星中的应用。&lt;h4&gt;背景&lt;/h4&gt;目前，通过高对比度成像设备直接观测到的新系外行星数量有限，传统的成像方法依赖对参考星的大量手动标记。&lt;h4&gt;目的&lt;/h4&gt;评估人工智能在直接成像地外行星中的潜力，并提出一个新的、高质量的数据集和基准。&lt;h4&gt;方法&lt;/h4&gt;使用了从2014年开始的全公共SPHERE/IRDIS偏振光档案中的参考星和恒星周围盘片图像，建立了POLARIS数据集，并通过统计、生成和大型视觉语言模型评估了多种模型，提出了一个无监督的生成表示学习框架。&lt;h4&gt;主要发现&lt;/h4&gt;提出了第一个统一降低的、高质量的地外行星成像数据集，并通过集成不同模型，实现了优越的性能和增强的表示能力。&lt;h4&gt;结论&lt;/h4&gt;通过发布数据集和基准，旨在为天体物理学家提供新工具，并鼓励数据科学家推进直接地外行星成像，促进跨学科的重大突破。&lt;h4&gt;翻译&lt;/h4&gt;本文提出利用人工智能技术在接下来的十年中成像类似地球的系外行星的可能性，并从偏振光数据表示学习的角度探讨这个问题。尽管在过去十年中投入了大量资金，但只有少数新系外行星被直接成像。现有的成像方法高度依赖于对参考星进行劳动密集型标记，这些参考星作为背景以提取目标恒星周围的 circumstellar objects（盘片或系外行星）。通过我们的 POLARIS（POlarized Light dAta for total intensity Representation learning of direct Imaging of exoplanetary Systems）数据集，我们使用自2014年以来公开的 SPHERE/IRDIS 偏振光档案对参考星和恒星周围盘片图像进行分类，需要的手动标记不到10%。我们评估了一系列模型，包括统计、生成和大型视觉语言模型，并提供了基准性能。我们还提出了一种无监督的生成表示学习框架，它集成了这些模型，并实现了卓越的性能和增强的表示能力。据我们所知，这是第一个统一降低、高质量的地外行星成像数据集，在天体物理学和机器学习中非常罕见。通过发布这个数据集和基准，我们的目标是装备天体物理学家，并鼓励数据科学家推进直接地外行星成像，催化跨学科的重大突破。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With over 1,000,000 images from more than 10,000 exposures usingstate-of-the-art high-contrast imagers (e.g., Gemini Planet Imager, VLT/SPHERE)in the search for exoplanets, can artificial intelligence (AI) serve as atransformative tool in imaging Earth-like exoplanets in the coming decade? Inthis paper, we introduce a benchmark and explore this question from apolarimetric image representation learning perspective. Despite extensiveinvestments over the past decade, only a few new exoplanets have been directlyimaged. Existing imaging approaches rely heavily on labor-intensive labeling ofreference stars, which serve as background to extract circumstellar objects(disks or exoplanets) around target stars. With our POLARIS (POlarized LightdAta for total intensity Representation learning of direct Imaging ofexoplanetary Systems) dataset, we classify reference star and circumstellardisk images using the full public SPHERE/IRDIS polarized-light archive since2014, requiring less than 10 percent manual labeling. We evaluate a range ofmodels including statistical, generative, and large vision-language models andprovide baseline performance. We also propose an unsupervised generativerepresentation learning framework that integrates these models, achievingsuperior performance and enhanced representational power. To our knowledge,this is the first uniformly reduced, high-quality exoplanet imaging dataset,rare in astrophysics and machine learning. By releasing this dataset andbaselines, we aim to equip astrophysicists with new tools and engage datascientists in advancing direct exoplanet imaging, catalyzing majorinterdisciplinary breakthroughs.</description>
      <author>example@mail.com (Fangyi Cao, Bin Ren, Zihao Wang, Shiwei Fu, Youbin Mo, Xiaoyang Liu, Yuzhou Chen, Weixin Yao)</author>
      <guid isPermaLink="false">2506.03511v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>InterRVOS: Interaction-aware Referring Video Object Segmentation</title>
      <link>http://arxiv.org/abs/2506.02356v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的视频对象分割任务，即交互感知的视频对象分割（InterRVOS），该任务旨在分割涉及交互的演员和目标实体。同时，提出了一个大规模的自动构建的数据集InterRVOS-8K，以及一个用于处理演员-目标分割的基准架构ReVIOSa。&lt;h4&gt;背景&lt;/h4&gt;现有的视频对象分割方法主要关注单个目标对象的定位，而忽略了对象间的交互作用。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够分割涉及交互的演员和目标实体的新任务，并建立强大的基础以研究以交互为中心的视频理解。&lt;h4&gt;方法&lt;/h4&gt;提出了InterRVOS-8K数据集和ReVIOSa架构，并引入了演员-目标感知的评价设置。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方案在复杂对象交互建模方面优于先前的方法，为交互中心视频理解的未来研究奠定了基础。&lt;h4&gt;结论&lt;/h4&gt;通过引入交互感知的视频对象分割，本研究为理解视频中的复杂交互提供了新的视角和工具。&lt;h4&gt;翻译&lt;/h4&gt;Referring video object segmentation aims to segment the object in a video corresponding to a given natural language expression. While prior works have explored various referring scenarios, including motion-centric or multi-instance expressions, most approaches still focus on localizing a single target object in isolation. However, in comprehensive video understanding, an object's role is often defined by its interactions with other entities, which are largely overlooked in existing datasets and models. In this work, we introduce Interaction-aware referring video object segmentation (InterRVOS), a new task that requires segmenting both actor and target entities involved in an interaction. Each interaction is described through a pair of complementary expressions from different semantic perspectives, enabling fine-grained modeling of inter-object relationships. To tackle this task, we propose InterRVOS-8K, the large-scale and automatically constructed dataset containing diverse interaction-aware expressions with corresponding masks, including challenging cases such as motion-only multi-instance expressions. We also present a baseline architecture, ReVIOSa, designed to handle actor-target segmentation from a single expression, achieving strong performance in both standard and interaction-focused settings. Furthermore, we introduce an actor-target-aware evaluation setting that enables a more targeted assessment of interaction understanding. Experimental results demonstrate that our approach outperforms prior methods in modeling complex object interactions for referring video object segmentation task, establishing a strong foundation for future research in interaction-centric video understanding. Our project page is available at https://cvlab-kaist.github.io/InterRVOS.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Referring video object segmentation aims to segment the object in a videocorresponding to a given natural language expression. While prior works haveexplored various referring scenarios, including motion-centric ormulti-instance expressions, most approaches still focus on localizing a singletarget object in isolation. However, in comprehensive video understanding, anobject's role is often defined by its interactions with other entities, whichare largely overlooked in existing datasets and models. In this work, weintroduce Interaction-aware referring video object sgementation (InterRVOS), anew task that requires segmenting both actor and target entities involved in aninteraction. Each interactoin is described through a pair of complementaryexpressions from different semantic perspectives, enabling fine-grainedmodeling of inter-object relationships. To tackle this task, we proposeInterRVOS-8K, the large-scale and automatically constructed dataset containingdiverse interaction-aware expressions with corresponding masks, includingchallenging cases such as motion-only multi-instance expressions. We alsopresent a baseline architecture, ReVIOSa, designed to handle actor-targetsegmentation from a single expression, achieving strong performance in bothstandard and interaction-focused settings. Furthermore, we introduce anactor-target-aware evalaution setting that enables a more targeted assessmentof interaction understanding. Experimental results demonstrate that ourapproach outperforms prior methods in modeling complex object interactions forreferring video object segmentation task, establishing a strong foundation forfuture research in interaction-centric video understanding. Our project page isavailable at https://cvlab-kaist.github.io/InterRVOS.</description>
      <author>example@mail.com (Woojeong Jin, Seongchan Kim, Seungryong Kim)</author>
      <guid isPermaLink="false">2506.02356v2</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>A Foundation Model for Spatial Proteomics</title>
      <link>http://arxiv.org/abs/2506.03373v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;KRONOS是一种为空间蛋白质组学构建的基础模型，通过在大量图像数据上自监督训练，能够在细胞、微环境和组织等多个尺度上学习生物学上有意义的表示，从而提高细胞表型、区域分类和患者分层等下游任务的表现。&lt;h4&gt;背景&lt;/h4&gt;基础模型在图像分析中开始发挥重要作用，但在空间蛋白质组学（单细胞分辨率的蛋白质成像）中的应用有限。&lt;h4&gt;目的&lt;/h4&gt;开发一个适用于空间蛋白质组学的基础模型KRONOS。&lt;h4&gt;方法&lt;/h4&gt;KRONOS在超过4700万个图像片段上进行自监督训练，这些片段覆盖了175个蛋白质标记、16种组织类型和8种基于荧光的成像平台。模型进行了关键架构调整以处理多通道和异质的多重成像数据。&lt;h4&gt;主要发现&lt;/h4&gt;KRONOS能够在多个尺度上学习生物学上有意义的表示，包括细胞和微环境到组织水平，实现了对细胞表型、区域分类和患者分层等任务的高性能。KRONOS还引入了无分割的图像片段级处理，以实现高效且可扩展的空间蛋白质组学分析。&lt;h4&gt;结论&lt;/h4&gt;KRONOS是一个灵活且可扩展的空间蛋白质组学工具，其模型可通过https://github.com/mahmoodlab/KRONOS公开访问。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型已经开始通过作为预训练的通用骨干网络来改变图像分析，即使是在训练后数据有限的情况下，也能适应许多任务，但它们对空间蛋白质组学（单细胞分辨率的蛋白质成像）的影响仍然有限。在这里，我们介绍了KRONOS，这是一个为空间蛋白质组学构建的基础模型。KRONOS在超过4700万个图像片段上进行自监督训练，这些片段覆盖了175个蛋白质标记、16种组织类型和8种基于荧光的成像平台。我们引入了关键的架构调整来解决多重成像的高维、多通道和异质性质。我们证明了KRONOS能够在多个尺度上学习生物学上有意义的表示，从细胞和微环境到组织水平，使它能够解决包括细胞表型、区域分类和患者分层在内的各种下游任务。在11个独立队列中进行评估，KRONOS在细胞表型、治疗反应预测和检索任务中实现了最先进的性能，并且高度数据高效。KRONOS还引入了无分割的图像片段级处理，以实现高效且可扩展的空间蛋白质组学分析，允许跨机构比较，并作为一个图像反向搜索引擎用于空间模式。总之，这些结果将KRONOS定位为空间蛋白质组学的灵活且可扩展的工具。该模型可通过https://github.com/mahmoodlab/KRONOS公开访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have begun to transform image analysis by acting aspretrained generalist backbones that can be adapted to many tasks even whenpost-training data are limited, yet their impact on spatial proteomics, imagingthat maps proteins at single-cell resolution, remains limited. Here, weintroduce KRONOS, a foundation model built for spatial proteomics. KRONOS wastrained in a self-supervised manner on over 47 million image patches covering175 protein markers, 16 tissue types, and 8 fluorescence-based imagingplatforms. We introduce key architectural adaptations to address thehigh-dimensional, multi-channel, and heterogeneous nature of multiplex imaging.We demonstrate that KRONOS learns biologically meaningful representationsacross multiple scales, ranging from cellular and microenvironment to tissuelevels, enabling it to address diverse downstream tasks, including cellphenotyping, region classification, and patient stratification. Evaluatedacross 11 independent cohorts, KRONOS achieves state-of-the-art performanceacross cell phenotyping, treatment response prediction, and retrieval tasks,and is highly data-efficient. KRONOS also introduces the paradigm ofsegmentation-free patch-level processing for efficient and scalable spatialproteomics analysis, allowing cross-institutional comparisons, and as an imagereverse search engine for spatial patterns. Together, these results positionKRONOS as a flexible and scalable tool for spatial proteomics. The model ispublicly accessible at https://github.com/mahmoodlab/KRONOS.</description>
      <author>example@mail.com (Muhammad Shaban, Yuzhou Chang, Huaying Qiu, Yao Yu Yeo, Andrew H. Song, Guillaume Jaume, Yuchen Wang, Luca L. Weishaupt, Tong Ding, Anurag Vaidya, Abdallah Lamane, Daniel Shao, Mohammed Zidane, Yunhao Bai, Paige McCallum, Shuli Luo, Wenrui Wu, Yang Wang, Precious Cramer, Chi Ngai Chan, Pierre Stephan, Johanna Schaffenrath, Jia Le Lee, Hendrik A. Michel, Caiwei Tian, Cristina Almagro-Perez, Sophia J. Wagner, Sharifa Sahai, Ming Y. Lu, Richard J. Chen, Andrew Zhang, Mark Edward M. Gonzales, Ahmad Makky, Jia-Ying Joey Lee, Hao Cheng, Nourhan El Ahmar, Sayed Matar, Maximilian Haist, Darci Phillips, Yuqi Tan, Garry P. Nolan, W. Richard Burack, Jacob D. Estes, Jonathan T. C. Liu, Toni K Choueiri, Neeraj Agarwal, Marc Barry, Scott J. Rodig, Long Phi Le, Georg Gerber, Christian M. Schürch, Fabian J. Theis, Youn H Kim, Joe Yeong, Sabina Signoretti, Brooke E. Howitt, Lit-Hsin Loo, Qin Ma, Sizun Jiang, Faisal Mahmood)</author>
      <guid isPermaLink="false">2506.03373v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Skeleton-Based Action Representation Learning</title>
      <link>http://arxiv.org/abs/2506.03481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于骨架的人体动作识别，特别关注处理关节维度和拓扑结构变化的异构骨架数据。&lt;h4&gt;背景&lt;/h4&gt;由于人体骨架来源多样，骨架数据自然表现出异质性，但以往工作忽略了这一点，仅针对同质骨架构建模型。&lt;h4&gt;目的&lt;/h4&gt;解决异构骨架动作表示学习中的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一个框架，包含异构骨架处理和统一表示学习两个主要组件。前者通过辅助网络将二维骨架数据转换为三维骨架，并使用骨架特定提示构建提示统一骨架。后者使用共享骨干网络学习统一的动作表示。&lt;h4&gt;主要发现&lt;/h4&gt;在NTU-60、NTU-120和PKU-MMD II数据集上进行的实验表明，该方法在动作理解的各种任务中效果显著。&lt;h4&gt;结论&lt;/h4&gt;该方法可以应用于具有不同人形结构的机器人中的动作识别。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Skeleton-based human action recognition has received widespread attention inrecent years due to its diverse range of application scenarios. Due to thedifferent sources of human skeletons, skeleton data naturally exhibitheterogeneity. The previous works, however, overlook the heterogeneity of humanskeletons and solely construct models tailored for homogeneous skeletons. Thiswork addresses the challenge of heterogeneous skeleton-based actionrepresentation learning, specifically focusing on processing skeleton data thatvaries in joint dimensions and topological structures. The proposed frameworkcomprises two primary components: heterogeneous skeleton processing and unifiedrepresentation learning. The former first converts two-dimensional skeletondata into three-dimensional skeleton via an auxiliary network, and thenconstructs a prompted unified skeleton using skeleton-specific prompts. We alsodesign an additional modality named semantic motion encoding to harness thesemantic information within skeletons. The latter module learns a unifiedaction representation using a shared backbone network that processes differentheterogeneous skeletons. Extensive experiments on the NTU-60, NTU-120, andPKU-MMD II datasets demonstrate the effectiveness of our method in varioustasks of action understanding. Our approach can be applied to actionrecognition in robots with different humanoid structures.</description>
      <author>example@mail.com (Hongsong Wang, Xiaoyan Ma, Jidong Kuang, Jie Gui)</author>
      <guid isPermaLink="false">2506.03481v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Channel-adaptive Cross-modal Generative Semantic Communication for Point Cloud Transmission</title>
      <link>http://arxiv.org/abs/2506.03211v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的适用于点云传输的通道自适应跨模态生成语义通信方法GenSeC-PC，该方法结合了图像和点云，并通过改进的解码器和通道自适应架构实现了高效的压缩和重建。&lt;h4&gt;背景&lt;/h4&gt;随着自动驾驶和扩展现实的发展，点云的有效传输变得日益重要。&lt;h4&gt;目的&lt;/h4&gt;提高点云传输的压缩效率和重建性能。&lt;h4&gt;方法&lt;/h4&gt;GenSeC-PC使用语义编码器融合图像和点云，图像作为非传输的辅助信息。解码器基于PointDif的架构。设计了一种简化的非对称通道自适应联合语义信道编码架构，其中只有编码器需要平均信噪比和可用带宽的反馈。同时，使用修正的降噪扩散隐式模型加速解码过程，实现毫秒级实时通信。&lt;h4&gt;主要发现&lt;/h4&gt;GenSeC-PC利用生成先验确保即使是从噪声或不完整的源点云中也能进行可靠的重建。支持全模拟传输，通过消除先前SemCom方法中常见的需要无误差辅助信息传输的需求，提高了压缩效率。&lt;h4&gt;结论&lt;/h4&gt;仿真结果证实了跨模态语义提取和双指标引导微调的有效性，表明该框架在不同条件下（包括低信噪比、带宽限制、不同数量的二维图像和未见过的对象）具有鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;With the rapid development of autonomous driving and extended reality, efficient transmission of point clouds (PCs) has become increasingly important. In this context, we propose a novel channel-adaptive cross-modal generativesemantic communication (SemCom) for PC transmission, called GenSeC-PC. GenSeC-PC employs a semantic encoder that fuses images and point clouds, where images serve as non-transmitted side information. Meanwhile, the decoder is built upon the backbone of PointDif. Such a cross-modal design not only ensures high compression efficiency but also delivers superior reconstruction performance compared to PointDif. Moreover, to ensure robust transmission and reduce system complexity, we design a streamlined and asymmetric channel-adaptive joint semantic-channel coding architecture, where only the encoder needs the feedback of average signal-to-noise ratio (SNR) and available bandwidth. In addition, rectified denoising diffusion implicit models is employed to accelerate the decoding process to the millisecond level, enabling real-time PC communication. Unlike existing methods, GenSeC-PC leverages generative priors to ensure reliable reconstruction even from noisy or incomplete source PCs. More importantly, it supports fully analog transmission, improving compression efficiency by eliminating the need for error-free side information transmission common in prior SemCom approaches. Simulation results confirm the effectiveness of cross-modal semantic extraction and dual-metric guided fine-tuning, highlighting the framework's robustness across diver seconditions, including low SNR, bandwidth limitations, varying numbers of 2D images, and previously unseen objects.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of autonomous driving and extended reality,efficient transmission of point clouds (PCs) has become increasingly important.In this context, we propose a novel channel-adaptive cross-modal generativesemantic communication (SemCom) for PC transmission, called GenSeC-PC.GenSeC-PC employs a semantic encoder that fuses images and point clouds, whereimages serve as non-transmitted side information. Meanwhile, the decoder isbuilt upon the backbone of PointDif. Such a cross-modal design not only ensureshigh compression efficiency but also delivers superior reconstructionperformance compared to PointDif. Moreover, to ensure robust transmission andreduce system complexity, we design a streamlined and asymmetricchannel-adaptive joint semantic-channel coding architecture, where only theencoder needs the feedback of average signal-to-noise ratio (SNR) and availablebandwidth. In addition, rectified denoising diffusion implicit models isemployed to accelerate the decoding process to the millisecond level, enablingreal-time PC communication. Unlike existing methods, GenSeC-PC leveragesgenerative priors to ensure reliable reconstruction even from noisy orincomplete source PCs. More importantly, it supports fully analog transmission,improving compression efficiency by eliminating the need for error-free sideinformation transmission common in prior SemCom approaches. Simulation resultsconfirm the effectiveness of cross-modal semantic extraction and dual-metricguided fine-tuning, highlighting the framework's robustness across diverseconditions, including low SNR, bandwidth limitations, varying numbers of 2Dimages, and previously unseen objects.</description>
      <author>example@mail.com (Wanting Yang, Zehui Xiong, Qianqian Yang, Ping Zhang, Merouane Debbah, Rahim Tafazolli)</author>
      <guid isPermaLink="false">2506.03211v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Towards Source Attribution of Singing Voice Deepfake with Multimodal Foundation Models</title>
      <link>http://arxiv.org/abs/2506.03364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to INTERSPEECH 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了唱歌声音深度伪造源归因（SVDSA）任务，并提出了多模态基础模型（MMFMs）在SVDSA中的有效性，通过实验验证了这一假设，并提出了一种新的框架COFFE，用于FM的有效融合。&lt;h4&gt;背景&lt;/h4&gt;唱歌声音深度伪造源归因（SVDSA）是一个新兴的研究领域，旨在识别和归因唱歌声音深度伪造的来源。&lt;h4&gt;目的&lt;/h4&gt;研究多模态基础模型（MMFMs）在唱歌声音深度伪造源归因（SVDSA）任务中的有效性，并提出一种新的框架以改善该任务的表现。&lt;h4&gt;方法&lt;/h4&gt;通过实验验证了MMFMs在SVDSA中的有效性，并提出了一个名为COFFE的新框架，该框架使用Chernoff Distance作为新的损失函数，以实现基础模型的有效融合。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MMFMs在SVDSA任务中是最有效的，并且通过COFFE框架融合MMFMs可以获得比单个FM和基线融合方法更优的性能。&lt;h4&gt;结论&lt;/h4&gt;多模态基础模型（MMFMs）在唱歌声音深度伪造源归因（SVDSA）任务中表现出色，通过COFFE框架融合MMFMs可以提高SVDSA的性能。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we introduce the task of singing voice deepfake sourceattribution (SVDSA). We hypothesize that multimodal foundation models (MMFMs)such as ImageBind, LanguageBind will be most effective for SVDSA as they arebetter equipped for capturing subtle source-specific characteristics-such asunique timbre, pitch manipulation, or synthesis artifacts of each singing voicedeepfake source due to their cross-modality pre-training. Our experiments withMMFMs, speech foundation models and music foundation models verify thehypothesis that MMFMs are the most effective for SVDSA. Furthermore, inspiredfrom related research, we also explore fusion of foundation models (FMs) forimproved SVDSA. To this end, we propose a novel framework, COFFE which employsChernoff Distance as novel loss function for effective fusion of FMs. ThroughCOFFE with the symphony of MMFMs, we attain the topmost performance incomparison to all the individual FMs and baseline fusion methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we introduce the task of singing voice deepfake sourceattribution (SVDSA). We hypothesize that multimodal foundation models (MMFMs)such as ImageBind, LanguageBind will be most effective for SVDSA as they arebetter equipped for capturing subtle source-specific characteristics-such asunique timbre, pitch manipulation, or synthesis artifacts of each singing voicedeepfake source due to their cross-modality pre-training. Our experiments withMMFMs, speech foundation models and music foundation models verify thehypothesis that MMFMs are the most effective for SVDSA. Furthermore, inspiredfrom related research, we also explore fusion of foundation models (FMs) forimproved SVDSA. To this end, we propose a novel framework, COFFE which employsChernoff Distance as novel loss function for effective fusion of FMs. ThroughCOFFE with the symphony of MMFMs, we attain the topmost performance incomparison to all the individual FMs and baseline fusion methods.</description>
      <author>example@mail.com (Orchid Chetia Phukan, Girish, Mohd Mujtaba Akhtar, Swarup Ranjan Behera, Priyabrata Mallick, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma)</author>
      <guid isPermaLink="false">2506.03364v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>HYFuse: Aligning Heterogeneous Speech Pre-Trained Representations in Hyperbolic Space for Speech Emotion Recognition</title>
      <link>http://arxiv.org/abs/2506.03403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to INTERSPEECH 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于压缩的表示（CBRs）和基于表示学习的表示（RLRs）在语音情感识别（SER）中的应用，并提出了一个名为HYFuse的新框架，通过将表示转换为双曲空间来实现RLRs和CBRs的融合。&lt;h4&gt;背景&lt;/h4&gt;CBRs如EnCodec能够捕捉到声学特征，而RLRs如WavLM能够编码高级语义和韵律信息。尽管两者都用于SER，但它们之间的融合尚未被探索。&lt;h4&gt;目的&lt;/h4&gt;填补CBRs和RLRs融合的空白，并验证融合后的表示是否提供互补信息，从而提高SER的性能。&lt;h4&gt;方法&lt;/h4&gt;提出HYFuse框架，通过将x-vector（RLR）和Soundstream（CBR）的表示转换为双曲空间进行融合。&lt;h4&gt;主要发现&lt;/h4&gt;通过HYFuse融合RLRs和CBRs，实现了比单个表示或同质融合更好的性能，并报告了最先进的成果（SOTA）。&lt;h4&gt;结论&lt;/h4&gt;HYFuse框架有效融合了RLRs和CBRs，提高了SER的性能，为未来的研究提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了基于压缩的表示（CBRs）和基于表示学习的表示（RLRs）在语音情感识别（SER）中的应用，并提出了一种名为HYFuse的新框架，通过将表示转换为双曲空间来实现RLRs和CBRs的融合。研究发现，通过HYFuse融合RLRs和CBRs，能够实现比单个表示或同质融合更好的性能，并达到了最先进的水平（SOTA）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Compression-based representations (CBRs) from neural audio codecs such asEnCodec capture intricate acoustic features like pitch and timbre, whilerepresentation-learning-based representations (RLRs) from pre-trained modelstrained for speech representation learning such as WavLM encode high-levelsemantic and prosodic information. Previous research on Speech EmotionRecognition (SER) has explored both, however, fusion of CBRs and RLRs haven'tbeen explored yet. In this study, we solve this gap and investigate the fusionof RLRs and CBRs and hypothesize they will be more effective by providingcomplementary information. To this end, we propose, HYFuse, a novel frameworkthat fuses the representations by transforming them to hyperbolic space. WithHYFuse, through fusion of x-vector (RLR) and Soundstream (CBR), we achieve thetop performance in comparison to individual representations as well as thehomogeneous fusion of RLRs and CBRs and report SOTA.</description>
      <author>example@mail.com (Orchid Chetia Phukan, Girish, Mohd Mujtaba Akhtar, Swarup Ranjan Behera, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma)</author>
      <guid isPermaLink="false">2506.03403v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>A Multimodal, Multilingual, and Multidimensional Pipeline for Fine-grained Crowdsourcing Earthquake Damage Evaluation</title>
      <link>http://arxiv.org/abs/2506.03360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种结构化的多模态、多语言、多维度（3M）管道，利用多模态大型语言模型（MLLMs）来评估灾害影响，以提高灾害损失评估的速度和准确性。&lt;h4&gt;背景&lt;/h4&gt;快速、细粒度的灾害损失评估对于有效的应急响应至关重要，但由于地面传感器的限制和官方报告的延迟，这仍然是一个挑战。社交媒体提供了丰富的人本观察数据，但其多模态和非结构化的性质给传统的分析方法带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在利用社交媒体数据，通过多模态大型语言模型来提高灾害损失评估的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;研究评估了三种基础模型在两次主要地震事件中的表现，并使用宏观和微观分析进行评估。该方法利用MLLMs整合图像和文本信号，并与地面真值地震数据进行关联。&lt;h4&gt;主要发现&lt;/h4&gt;MLLMs能够有效地整合图像-文本信号，并显示出与地面真值地震数据之间强烈的关联。然而，性能因语言、震中距离和输入模态而异。&lt;h4&gt;结论&lt;/h4&gt;该研究突出了MLLMs在灾害评估中的潜力，并为未来将MLLMs应用于实时危机情境的研究奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译为中文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Rapid, fine-grained disaster damage assessment is essential for effectiveemergency response, yet remains challenging due to limited ground sensors anddelays in official reporting. Social media provides a rich, real-time source ofhuman-centric observations, but its multimodal and unstructured nature presentschallenges for traditional analytical methods. In this study, we propose astructured Multimodal, Multilingual, and Multidimensional (3M) pipeline thatleverages multimodal large language models (MLLMs) to assess disaster impacts.We evaluate three foundation models across two major earthquake events usingboth macro- and micro-level analyses. Results show that MLLMs effectivelyintegrate image-text signals and demonstrate a strong correlation withground-truth seismic data. However, performance varies with language,epicentral distance, and input modality. This work highlights the potential ofMLLMs for disaster assessment and provides a foundation for future research inapplying MLLMs to real-time crisis contexts. The code and data are released at:https://github.com/missa7481/EMNLP25_earthquake</description>
      <author>example@mail.com (Zihui Ma, Lingyao Li, Juan Li, Wenyue Hua, Jingxiao Liu, Qingyuan Feng, Yuki Miura)</author>
      <guid isPermaLink="false">2506.03360v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>SAB3R: Semantic-Augmented Backbone in 3D Reconstruction</title>
      <link>http://arxiv.org/abs/2506.02112v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  3D-LLM/VLA @ CVPR2025 | Project page:  https://uva-computer-vision-lab.github.io/sab3r/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Map and Locate的新任务，该任务将基于自然语言查询的对象实例检测和分割（开放词汇分割）与3D重建（从视觉输入中估计场景的3D结构）的传统不同目标统一。&lt;h4&gt;背景&lt;/h4&gt;传统的开放词汇分割和3D重建是两个独立的任务，本文提出的新任务旨在将它们结合。&lt;h4&gt;目的&lt;/h4&gt;Map and Locate任务旨在生成从无姿态视频中的点云，并基于开放词汇查询进行对象实例分割，为现实世界的具身人工智能应用提供一个关键步骤。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种名为SAB3R的简单而有效的基线，它基于MASt3R（3D计算机视觉领域的最新突破）并采用轻量级蒸馏策略。SAB3R通过将密集的、每像素的语义特征从2D视觉骨干网络（如CLIP和DINOv2）传递到MASt3R中，来增强其能力。该模型在不引入任何辅助冻结网络的情况下，在单次前向传递中生成每像素语义特征并构建连贯的点云图。&lt;h4&gt;主要发现&lt;/h4&gt;与分别部署MASt3R和CLIP相比，SAB3R在Map and Locate基准测试上实现了优越的性能。此外，SAB3R在2D语义分割和3D任务上的评估表明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;SAB3R模型通过结合开放词汇分割和3D重建，为Map and Locate任务提供了有效的方法，为现实世界中的应用铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a new task, Map and Locate, which unifies the traditionallydistinct objectives of open-vocabulary segmentation - detecting and segmentingobject instances based on natural language queries - and 3D reconstruction, theprocess of estimating a scene's 3D structure from visual inputs. Specifically,Map and Locate involves generating a point cloud from an unposed video andsegmenting object instances based on open-vocabulary queries. This task servesas a critical step toward real-world embodied AI applications and introduces apractical task that bridges reconstruction, recognition and reorganization. Totackle this task, we introduce a simple yet effective baseline, which we denoteas SAB3R. Our approach builds upon MASt3R, a recent breakthrough in 3D computervision, and incorporates a lightweight distillation strategy. This methodtransfers dense, per-pixel semantic features from 2D vision backbones (eg, CLIPand DINOv2) to enhance MASt3R's capabilities. Without introducing any auxiliaryfrozen networks, our model generates per-pixel semantic features and constructscohesive point maps in a single forward pass. Compared to separately deployingMASt3R and CLIP, our unified model, SAB3R, achieves superior performance on theMap and Locate benchmark. Furthermore, we evaluate SAB3R on both 2D semanticsegmentation and 3D tasks to comprehensively validate its effectiveness.</description>
      <author>example@mail.com (Xuweiyi Chen, Tian Xia, Sihan Xu, Jianing Yang, Joyce Chai, Zezhou Cheng)</author>
      <guid isPermaLink="false">2506.02112v2</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Open-PMC-18M: A High-Fidelity Large Scale Medical Dataset for Multimodal Representation Learning</title>
      <link>http://arxiv.org/abs/2506.02738v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer对象检测的子图提取流程，用于大规模子图提取，并构建了一个大规模的生物医学视觉语言数据集，用于提高视觉语言模型的表现。&lt;h4&gt;背景&lt;/h4&gt;复合图在生物医学文献中很常见，但大规模子图提取尚未得到充分解决，先前的研究在数据集规模和泛化能力方面有限。&lt;h4&gt;目的&lt;/h4&gt;研究通过大规模子图提取实现高保真图像-文本对齐对视觉语言模型中的表示学习的影响。&lt;h4&gt;方法&lt;/h4&gt;开发了一个可扩展的子图提取流程，并在包含50万张复合图的合成语料库上训练，同时在ImageCLEF2016和合成基准上取得了最先进的性能。构建了一个包含1800万个与临床相关的子图-标题对的OPEN-PMC-18M大规模高质量生物医学视觉语言数据集。&lt;h4&gt;主要发现&lt;/h4&gt;使用该流程，在检索、零样本分类和鲁棒性基准测试中，视觉语言模型的表现得到提升，超过了现有基线。&lt;h4&gt;结论&lt;/h4&gt;发布的子图提取流程、数据集、模型和代码支持可重复的基准测试，并促进了生物医学视觉语言建模和表示学习的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：复合图，即包含多个子图的复合图像，在生物医学文献中普遍存在，但大规模子图提取仍然没有得到充分解决。先前关于子图提取的研究在数据集规模和泛化能力方面都有限，留下了一个关键性的未解决问题：通过大规模子图提取实现的高保真图像-文本对齐如何影响视觉语言模型中的表示学习？我们通过引入一个基于Transformer对象检测的可扩展子图提取流程来填补这一空白，该流程在包含50万张复合图的合成语料库上进行了训练，并在ImageCLEF2016和合成基准上实现了最先进的性能。使用此流程，我们发布了OPEN-PMC-18M，这是一个包含1800万个与临床相关的子图-标题对的大规模高质量生物医学视觉语言数据集，涵盖了放射学、显微镜和可见光摄影。我们在我们精心制作的数据集上训练和评估了视觉语言模型，并在检索、零样本分类和鲁棒性基准测试中展示了改进的表现，超过了现有基线。我们发布了我们的数据集、模型和代码，以支持可重复的基准测试和进一步研究生物医学视觉语言建模和表示学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Compound figures, which are multi-panel composites containing diversesubfigures, are ubiquitous in biomedical literature, yet large-scale subfigureextraction remains largely unaddressed. Prior work on subfigure extraction hasbeen limited in both dataset size and generalizability, leaving a critical openquestion: How does high-fidelity image-text alignment via large-scale subfigureextraction impact representation learning in vision-language models? We addressthis gap by introducing a scalable subfigure extraction pipeline based ontransformer-based object detection, trained on a synthetic corpus of 500,000compound figures, and achieving state-of-the-art performance on both ImageCLEF2016 and synthetic benchmarks. Using this pipeline, we release OPEN-PMC-18M, alarge-scale high quality biomedical vision-language dataset comprising 18million clinically relevant subfigure-caption pairs spanning radiology,microscopy, and visible light photography. We train and evaluatevision-language models on our curated datasets and show improved performanceacross retrieval, zero-shot classification, and robustness benchmarks,outperforming existing baselines. We release our dataset, models, and code tosupport reproducible benchmarks and further study into biomedicalvision-language modeling and representation learning.</description>
      <author>example@mail.com (Negin Baghbanzadeh, Sajad Ashkezari, Elham Dolatabadi, Arash Afkanpour)</author>
      <guid isPermaLink="false">2506.02738v2</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>The Future of Continual Learning in the Era of Foundation Models: Three Key Directions</title>
      <link>http://arxiv.org/abs/2506.03320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 1 figure, accepted at TCAI workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要讨论了持续学习在人工智能中的重要性，尽管深度学习和大语言模型的出现提出了挑战，但持续学习仍然对于保持模型更新、实现个性化适应和构建可扩展智能系统至关重要。&lt;h4&gt;背景&lt;/h4&gt;持续学习是人类和人工智能智能的核心能力。早期人工智能系统强调了增量知识巩固，而强化学习强调了动态适应。&lt;h4&gt;目的&lt;/h4&gt;探讨持续学习在深度学习时代和大型语言模型出现后的地位。&lt;h4&gt;方法&lt;/h4&gt;分析不同人工智能范式对持续学习的不同需求，并提出持续学习的三个关键理由。&lt;h4&gt;主要发现&lt;/h4&gt;持续学习对于保持基础模型更新、实现模型特化和个性化、以及构建可扩展智能系统是必要的。&lt;h4&gt;结论&lt;/h4&gt;持续学习将继续在人工智能的发展中扮演关键角色，未来的AI将由不断进化和互动的模型生态系统定义。&lt;h4&gt;翻译&lt;/h4&gt;持续学习——在时间上获取、保留和精炼知识的能力——始终是人类和人工智能智能的基本要素。历史上，不同的AI范式已经承认这种需求，尽管优先级不同：早期的专家系统和生产系统侧重于增量知识整合，而强化学习则强调动态适应。随着深度学习的兴起，深度持续学习主要侧重于在学习时间上学习稳健和可重用表示，以解决越来越复杂的任务序列。然而，大型语言模型（LLMs）和基础模型的出现引发了这样的问题：当中心化、单一大模型可以处理具有互联网规模知识的各种任务时，我们是否仍然需要持续学习？我们认为，持续学习对于以下三个关键原因仍然是必要的：（一）持续的预训练仍然有必要以确保基础模型保持最新，减轻知识陈旧和分布偏移，同时整合新信息；（二）持续的微调使模型能够特化和个性化，适应特定领域任务、用户偏好和现实世界限制，而无需全面重新训练，避免需要计算昂贵的长上下文窗口；（三）持续的组合性提供了一种可扩展和模块化的智能方法，使得基础模型和代理可以动态组合、重组和适应。尽管持续预训练和微调被视为利基研究方向，但我们认为持续的组合性将标志着持续学习的重生。人工智能的未来将由一个不断进化和互动的模型生态系统来定义，持续学习比以往任何时候都更加相关。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual learning--the ability to acquire, retain, and refine knowledge overtime--has always been fundamental to intelligence, both human and artificial.Historically, different AI paradigms have acknowledged this need, albeit withvarying priorities: early expert and production systems focused on incrementalknowledge consolidation, while reinforcement learning emphasised dynamicadaptation. With the rise of deep learning, deep continual learning hasprimarily focused on learning robust and reusable representations over time tosolve sequences of increasingly complex tasks. However, the emergence of LargeLanguage Models (LLMs) and foundation models has raised the question: Do westill need continual learning when centralised, monolithic models can tacklediverse tasks with access to internet-scale knowledge? We argue that continuallearning remains essential for three key reasons: (i) continual pre-training isstill necessary to ensure foundation models remain up to date, mitigatingknowledge staleness and distribution shifts while integrating new information;(ii) continual fine-tuning enables models to specialise and personalise,adapting to domain-specific tasks, user preferences, and real-world constraintswithout full retraining, avoiding the need for computationally expensive longcontext-windows; (iii) continual compositionality offers a scalable and modularapproach to intelligence, enabling the orchestration of foundation models andagents to be dynamically composed, recombined, and adapted. While continualpre-training and fine-tuning are explored as niche research directions, weargue it is continual compositionality that will mark the rebirth of continuallearning. The future of AI will not be defined by a single static model but byan ecosystem of continually evolving and interacting models, making continuallearning more relevant than ever.</description>
      <author>example@mail.com (Jack Bell, Luigi Quarantiello, Eric Nuertey Coleman, Lanpei Li, Malio Li, Mauro Madeddu, Elia Piccoli, Vincenzo Lomonaco)</author>
      <guid isPermaLink="false">2506.03320v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Human Fall Detection using Transfer Learning-based 3D CNN</title>
      <link>http://arxiv.org/abs/2506.03193v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于3D CNN的视觉跌倒检测系统，用于解决老年人跌倒这一健康问题。&lt;h4&gt;背景&lt;/h4&gt;随着老年人人口的稳步增长，跌倒成为了重要的健康问题。&lt;h4&gt;目的&lt;/h4&gt;开发一个自动化的跌倒检测监控系统。&lt;h4&gt;方法&lt;/h4&gt;使用预训练的3D CNN模型来提取时空特征，并通过支持向量机（SVM）分类器进行活动分类。&lt;h4&gt;主要发现&lt;/h4&gt;该系统仅训练了SVM分类器，从而节省了训练3D CNN所需的时间。实验使用了GMDCSA和CAUCAFall两个数据集。&lt;h4&gt;结论&lt;/h4&gt;通过使用3D CNN模型和SVM分类器，该系统能够有效地检测跌倒事件。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a vision-based fall detection system using a pre-trained 3D CNN to address the health issue of unintentional falls in the elderly population. With the steady increase in the elderly population, falls have become a significant health concern. The aim is to develop an automated fall detection monitoring system. The method involves using a pre-trained 3D CNN model to extract spatio-temporal features and a support vector machine (SVM) classifier for activity classification. The system only trained the SVM classifier to save the time required for training the 3D CNN. The experiments were conducted using the GMDCSA and CAUCAFall datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-3-031-81935-3_9&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unintentional or accidental falls are one of the significant health issues insenior persons. The population of senior persons is increasing steadily. So,there is a need for an automated fall detection monitoring system. This paperintroduces a vision-based fall detection system using a pre-trained 3D CNN.Unlike 2D CNN, 3D CNN extracts not only spatial but also temporal features. Theproposed model leverages the original learned weights of a 3D CNN modelpre-trained on the Sports1M dataset to extract the spatio-temporal features.Only the SVM classifier was trained, which saves the time required to train the3D CNN. Stratified shuffle five split cross-validation has been used to splitthe dataset into training and testing data. Extracted features from theproposed 3D CNN model were fed to an SVM classifier to classify the activity asfall or ADL. Two datasets, GMDCSA and CAUCAFall, were utilized to conduct theexperiment. The source code for this work can be accessed via the followinglink: https://github.com/ekramalam/HFD_3DCNN.</description>
      <author>example@mail.com (Ekram Alam, Abu Sufian, Paramartha Dutta, Marco Leo)</author>
      <guid isPermaLink="false">2506.03193v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>MobCLIP: Learning General-purpose Geospatial Representation at Scale</title>
      <link>http://arxiv.org/abs/2506.01297v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MobCLIP是一种新型的地理空间位置表示学习方法，通过多模态融合技术，实现了对地理空间位置的高效和可扩展的表示学习。&lt;h4&gt;背景&lt;/h4&gt;地理空间位置的表示学习是实现通用地理空间智能的核心挑战，现有的嵌入方法通常缺乏多样性，限制了其在人类和自然领域各种任务中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出MobCLIP，作为第一个全国性的通用目的位置编码器，旨在通过有效和可扩展的多模态融合技术，整合多样化的数据模式。&lt;h4&gt;方法&lt;/h4&gt;采用基于CLIP的新型架构，将超过1亿个POI、全国范围的遥感影像和结构化人口统计数据与一个包含十亿条边的移动性图相结合。通过将空间位置划分为受Vision Transformers启发的网格单元，建立一个连接移动模式和多模态特征的统一表示空间。&lt;h4&gt;主要发现&lt;/h4&gt;MobCLIP在包含11个下游预测任务的基准数据集上，与最先进的模型相比，平均提高了35%的通用预测性能。在以人为中心的任务中，如能耗预测、线下零售消费额预测和犯罪案件预测，性能提升尤为显著。&lt;h4&gt;结论&lt;/h4&gt;MobCLIP通过有效集成以人为中心的模态，在以人为中心的任务中实现了显著的性能提升，并展示了地理空间表示学习中的扩展行为。&lt;h4&gt;翻译&lt;/h4&gt;Representation learning of geospatial locations remains a core challenge in achieving general geospatial intelligence. Current embedding methods often lack versatility, limiting their utility across diverse tasks in both human and natural domains. We present MobCLIP, the first nationwide general-purposelocation encoder, integrating an unprecedented diversity of data modalitiesthrough effective and scalable multimodal fusion. Adopting a novel CLIP-based architecture, our framework aligns 100M+ POIs, nationwide remote sensing imagery, and structured demographic statistics with a billion-edge mobility graph. By tokenizing spatial locations into grid cells inspired by Vision Transformers, we establish a unified representation space bridging mobility patterns and multimodal features. To rigorously evaluate the general-purpose effectiveness of MobCLIP, we construct a benchmark dataset composed of 11 downstream prediction tasks across social, economic, and natural domains. Experiments show that MobCLIP, with four input modalities and a compact 128-dimensional representation space, achieves significantly superiorgeneral-purpose predictive performances than state-of-the-art models by anaverage of 35%. Thanks to the effective integration of human-centricmodalities, the performance gain is particularly profound in human-centrictasks, such as energy consumption (+260%), offline retail consumption amount(+98%), and crime cases (+95%) predictions. Echoing LLM scaling laws, wefurther demonstrate the scaling behavior in geospatial representation learning.We open-source code and pretrained models at:https://github.com/ylzhouchris/MobCLIP.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning of geospatial locations remains a core challenge inachieving general geospatial intelligence. Current embedding methods often lackversatility, limiting their utility across diverse tasks in both human andnatural domains. We present MobCLIP, the first nationwide general-purposelocation encoder, integrating an unprecedented diversity of data modalitiesthrough effective and scalable multimodal fusion. Adopting a novel CLIP-basedarchitecture, our framework aligns 100M+ POIs, nationwide remote sensingimagery, and structured demographic statistics with a billion-edge mobilitygraph. By tokenizing spatial locations into grid cells inspired by VisionTransformers, we establish a unified representation space bridging mobilitypatterns and multimodal features. To rigorously evaluate the general-purposeeffectiveness of MobCLIP, we construct a benchmark dataset composed of 11downstream prediction tasks across social, economic, and natural domains.Experiments show that MobCLIP, with four input modalities and a compact128-dimensional representation space, achieves significantly superiorgeneral-purpose predictive performances than state-of-the-art models by anaverage of 35%. Thanks to the effective integration of human-centricmodalities, the performance gain is particularly profound in human-centrictasks, such as energy consumption (+260%), offline retail consumption amount(+98%), and crime cases (+95%) predictions. Echoing LLM scaling laws, wefurther demonstrate the scaling behavior in geospatial representation learning.We open-source code and pretrained models at:https://github.com/ylzhouchris/MobCLIP.</description>
      <author>example@mail.com (Ya Wen, Jixuan Cai, Qiyao Ma, Linyan Li, Xinhua Chen, Chris Webster, Yulun Zhou)</author>
      <guid isPermaLink="false">2506.01297v3</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Learning 3D Representations from Procedural 3D Programs</title>
      <link>http://arxiv.org/abs/2411.17467v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SynData4CV @ CVPR2025 | Project Page:  https://point-mae-zero.cs.virginia.edu/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从无标签3D点云中获取可迁移3D表示的方法，通过自监督学习从程序性3D程序中学习3D表示，这些程序使用简单的原语和增强自动生成3D形状。&lt;h4&gt;背景&lt;/h4&gt;获取3D资产需要专业知识或专业3D扫描设备，这使得3D数据的获取难以规模化，并引发版权问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过程序性3D程序自动生成3D形状，从而解决3D数据获取的挑战。&lt;h4&gt;方法&lt;/h4&gt;使用程序性3D程序学习3D表示，这些程序通过简单的原语和增强自动生成3D形状。&lt;h4&gt;主要发现&lt;/h4&gt;从程序性生成的3D形状中学习的3D表示，在形状分类、部分分割和掩码点云补全等下游3D任务中，其性能与从语义可识别的3D模型（如飞机）学习的最先进表示相当。&lt;h4&gt;结论&lt;/h4&gt;当前自监督学习在点云上的方法不依赖于3D形状的语义，揭示了学习的3D表示的本质。&lt;h4&gt;翻译&lt;/h4&gt;自监督学习已成为从无标签3D点云中获取可迁移3D表示的有前途的方法。与广泛可用的2D图像不同，获取3D资产需要专门的专家或专业3D扫描设备，这使得规模化变得困难，并引发了版权问题。为了解决这些挑战，我们提出从程序性3D程序中学习3D表示，这些程序使用简单的原语和增强自动生成3D形状。令人惊讶的是，尽管缺乏语义内容，从程序性生成的3D形状中学习的3D表示在包括形状分类、部分分割和掩码点云补全在内的各种下游3D任务中，其性能与从语义可识别的3D模型（例如飞机）学习的最先进表示相当。我们对构成良好的3D程序性程序的因素进行了详细分析。大量实验进一步表明，当前自监督学习方法在点云上不依赖于3D形状的语义，揭示了学习的3D表示的本质。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning has emerged as a promising approach for acquiringtransferable 3D representations from unlabeled 3D point clouds. Unlike 2Dimages, which are widely accessible, acquiring 3D assets requires specializedexpertise or professional 3D scanning equipment, making it difficult to scaleand raising copyright concerns. To address these challenges, we proposelearning 3D representations from procedural 3D programs that automaticallygenerate 3D shapes using simple primitives and augmentations. Remarkably,despite lacking semantic content, the 3D representations learned from theprocedurally generated 3D shapes perform on par with state-of-the-artrepresentations learned from semantically recognizable 3D models (e.g.,airplanes) across various downstream 3D tasks, including shape classification,part segmentation, and masked point cloud completion. We provide a detailedanalysis on factors that make a good 3D procedural program. Extensiveexperiments further suggest that current self-supervised learning methods onpoint clouds do not rely on the semantics of 3D shapes, shedding light on thenature of 3D representations learned.</description>
      <author>example@mail.com (Xuweiyi Chen, Zezhou Cheng)</author>
      <guid isPermaLink="false">2411.17467v2</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Future-Oriented Navigation: Dynamic Obstacle Avoidance with One-Shot Energy-Based Multimodal Motion Prediction</title>
      <link>http://arxiv.org/abs/2505.00237v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in IEEE Robotics and Automation Letters (RA-L)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在动态和不确定环境中安全高效控制移动机器人的集成方法。&lt;h4&gt;背景&lt;/h4&gt;移动机器人在动态和不确定环境中的控制是一个复杂的问题。&lt;h4&gt;目的&lt;/h4&gt;旨在实现移动机器人在动态环境中的有效导航。&lt;h4&gt;方法&lt;/h4&gt;方法包括：一次性多模态运动预测和模型预测控制。运动预测由基于能量的神经网络驱动，生成高分辨率、多步预测。预测结果用于创建作为数学约束的几何形状。动态障碍物通过无监督方式按邻近性分组，以提高性能和效率。整体无碰撞导航由具有特定设计的前瞻性动态障碍物避免的模型预测控制处理。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在不同场景中表现出色，这些场景代表了典型的仓库设置。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了所提出的方法优于其他现有的动态障碍物避免方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种针对动态和不确定环境的移动机器人安全高效控制方法。该方法包含两个关键步骤：一次性多模态运动预测和模型预测控制。运动预测由基于能量的神经网络驱动，产生高分辨率、多步预测。预测结果被进一步利用来创建数学约束下的几何形状。不是单独处理每个动态障碍物，而是通过无监督方式按邻近性对预测的障碍物进行分组，以提高性能和效率。整体无碰撞导航由具有特定设计的前瞻性动态障碍物避免的模型预测控制处理。在代表典型仓库设置的多种场景中对该方法进行了测试，结果表明该方法优于其他现有的动态障碍物避免方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an integrated approach for the safe and efficient controlof mobile robots in dynamic and uncertain environments. The approach consistsof two key steps: one-shot multimodal motion prediction to anticipate motionsof dynamic obstacles and model predictive control to incorporate thesepredictions into the motion planning process. Motion prediction is driven by anenergy-based neural network that generates high-resolution, multi-steppredictions in a single operation. The prediction outcomes are further utilizedto create geometric shapes formulated as mathematical constraints. Instead oftreating each dynamic obstacle individually, predicted obstacles are grouped byproximity in an unsupervised way to improve performance and efficiency. Theoverall collision-free navigation is handled by model predictive control with aspecific design for proactive dynamic obstacle avoidance. The proposed approachallows mobile robots to navigate effectively in dynamic environments. Itsperformance is accessed across various scenarios that represent typicalwarehouse settings. The results demonstrate that the proposed approachoutperforms other existing dynamic obstacle avoidance methods.</description>
      <author>example@mail.com (Ze Zhang, Georg Hess, Junjie Hu, Emmanuel Dean, Lennart Svensson, Knut Åkesson)</author>
      <guid isPermaLink="false">2505.00237v3</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Lightweight Convolutional Neural Networks for Retinal Disease Classification</title>
      <link>http://arxiv.org/abs/2506.03186v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视网膜疾病如糖尿病视网膜病变（DR）和黄斑孔（MH）对视力的影响，并采用MobileNet和NASNetMobile两种轻量级卷积神经网络进行视网膜图像分类，以提高早期诊断的准确性。&lt;h4&gt;背景&lt;/h4&gt;视网膜疾病如DR和MH严重影响视力，早期检测至关重要，DR可能导致失明，MH则影响阅读和面部识别等任务。&lt;h4&gt;目的&lt;/h4&gt;利用卷积神经网络（CNN）进行视网膜疾病分类，为AI辅助眼科诊断和早期干预提供基础。&lt;h4&gt;方法&lt;/h4&gt;在RFMiD数据集上训练模型，该数据集包含3,200张眼底图像，经过预处理如调整大小、归一化和增强。为解决数据稀缺问题，采用了迁移学习和数据增强技术。&lt;h4&gt;主要发现&lt;/h4&gt;MobileNetV2实现了90.8%的最高准确率，优于NASNetMobile的89.5%准确率。&lt;h4&gt;结论&lt;/h4&gt;CNN在视网膜疾病分类中表现出有效性，为AI辅助眼科诊断和早期干预提供了支持。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the impact of retinal diseases such as Diabetic Retinopathy (DR) and Macular Hole (MH) on vision, and employs two lightweight and efficient Convolution Neural Network architectures, MobileNet and NASNetMobile, for the classification of Normal, DR, and MH retinal images, in order to improve the accuracy of early detection. The models were trained on the RFMiD dataset, which consists of 3,200 fundus images after preprocessing steps such as resizing, normalization, and augmentation. To address the issue of data scarcity, this study utilizes transfer learning and data augmentation techniques to enhance model generalization and performance. The experimental results demonstrate that MobileNetV2 achieves the highest accuracy of 90.8%, outperforming NASNetMobile, which achieves 89.5% accuracy. These findings highlight the effectiveness of CNNs in retinal disease classification, providing a foundation for AI-assisted ophthalmic diagnosis and early intervention.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retinal diseases such as Diabetic Retinopathy (DR) and Macular Hole (MH)significantly impact vision and affect millions worldwide. Early detection iscrucial, as DR, a complication of diabetes, damages retinal blood vessels,potentially leading to blindness, while MH disrupts central vision, affectingtasks like reading and facial recognition. This paper employed two lightweightand efficient Convolution Neural Network architectures, MobileNet andNASNetMobile, for the classification of Normal, DR, and MH retinal images. Themodels were trained on the RFMiD dataset, consisting of 3,200 fundus images,after undergoing preprocessing steps such as resizing, normalization, andaugmentation. To address data scarcity, this study leveraged transfer learningand data augmentation techniques, enhancing model generalization andperformance. The experimental results demonstrate that MobileNetV2 achieved thehighest accuracy of 90.8%, outperforming NASNetMobile, which achieved 89.5%accuracy. These findings highlight the effectiveness of CNNs in retinal diseaseclassification, providing a foundation for AI-assisted ophthalmic diagnosis andearly intervention.</description>
      <author>example@mail.com (Duaa Kareem Qasim, Sabah Abdulazeez Jebur, Lafta Raheem Ali, Abdul Jalil M. Khalaf, Abir Jaafar Hussain)</author>
      <guid isPermaLink="false">2506.03186v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Jamming Source Localization</title>
      <link>http://arxiv.org/abs/2506.03196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文首次将基于图的学习应用于干扰源定位，解决无线网络中干扰攻击的威胁。&lt;h4&gt;背景&lt;/h4&gt;基于图的学习在建模复杂关系方面显示出巨大的潜力，但在无线安全领域的应用尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于图学习的干扰源定位方法，以应对无线网络中干扰攻击的挑战。&lt;h4&gt;方法&lt;/h4&gt;将定位问题重新定义为归纳图回归任务，采用结构化节点表示，集成局部和全局信号聚合，确保空间一致性和自适应信号融合。通过注意力机制增强网络鲁棒性，并引入置信度引导的估计机制，动态平衡学习预测与领域先验。&lt;h4&gt;主要发现&lt;/h4&gt;在复杂射频环境中，该方法在信号信息稀疏和模糊的挑战场景下，显著优于现有的定位基准。&lt;h4&gt;结论&lt;/h4&gt;基于图学习的框架在干扰源定位方面表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Graph-based learning has emerged as a transformative approach for modeling complex relationships across diverse domains, yet its potential in wireless security remains largely unexplored. In this work, we introduce the first application of graph-based learning for jamming source localization, addressing the imminent threat of jamming attacks in wireless networks. Unlike geometric optimization techniques that struggle under environmental uncertainties and dense interference, we reformulate localization as an inductive graph regression task. Our approach integrates structured node representations that encode local and global signal aggregation, ensuring spatial coherence and adaptive signal fusion. To enhance robustness, we incorporate an attention-based graph neural network that adaptively refines neighborhood influence and introduces a confidence-guided estimation mechanism that dynamically balances learned predictions with domain-informed priors. We evaluate our approach under complex radio frequency environments with varying sampling densities and signal propagation conditions, conducting comprehensive ablation studies on graph construction, feature selection, and pooling strategies. Results demonstrate that our novel graph-based learning framework significantly outperforms established localization baselines, particularly in challenging scenarios with sparse and obfuscated signal information. Code is available at [https://github.com/daniaherzalla/gnn-jamming-source-localization](https://github.com/daniaherzalla/gnn-jamming-source-localization).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-based learning has emerged as a transformative approach for modelingcomplex relationships across diverse domains, yet its potential in wirelesssecurity remains largely unexplored. In this work, we introduce the firstapplication of graph-based learning for jamming source localization, addressingthe imminent threat of jamming attacks in wireless networks. Unlike geometricoptimization techniques that struggle under environmental uncertainties anddense interference, we reformulate localization as an inductive graphregression task. Our approach integrates structured node representations thatencode local and global signal aggregation, ensuring spatial coherence andadaptive signal fusion. To enhance robustness, we incorporate anattention-based graph neural network that adaptively refines neighborhoodinfluence and introduces a confidence-guided estimation mechanism thatdynamically balances learned predictions with domain-informed priors. Weevaluate our approach under complex radio frequency environments with varyingsampling densities and signal propagation conditions, conducting comprehensiveablation studies on graph construction, feature selection, and poolingstrategies. Results demonstrate that our novel graph-based learning frameworksignificantly outperforms established localization baselines, particularly inchallenging scenarios with sparse and obfuscated signal information. Code isavailable at[https://github.com/daniaherzalla/gnn-jamming-source-localization](https://github.com/daniaherzalla/gnn-jamming-source-localization).</description>
      <author>example@mail.com (Dania Herzalla, Willian T. Lunardi, Martin Andreoni)</author>
      <guid isPermaLink="false">2506.03196v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>MINT: Multimodal Instruction Tuning with Multimodal Interaction Grouping</title>
      <link>http://arxiv.org/abs/2506.02308v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了多模态基础模型在多任务上取得的突破性进展，并提出了一个名为MINT的任务分组策略，以提高多模态指令微调的性能。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型在多个任务上取得了最先进的性能，这得益于新的预训练范式和高质量的提示。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过分组任务来提高多模态指令微调的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于多模态交互类型的简单而有效的任务分组策略MINT。&lt;h4&gt;主要发现&lt;/h4&gt;发现仅仅增加指令微调任务的数量并不总能带来更好的性能，而是通过按模态间的共同交互分组任务，可以鼓励模型在组内学习可迁移的技能，同时减少不匹配任务之间的干扰。&lt;h4&gt;结论&lt;/h4&gt;MINT方法在多模态指令微调中优于现有的任务分组基线，实现了泛化和专业化的有效平衡。&lt;h4&gt;翻译&lt;/h4&gt;摘要：最近在多模态基础模型方面取得的进展，在一系列任务上实现了最先进的性能。这些突破主要是由利用大规模未标记多模态数据的新预训练范式驱动的，随后在精心挑选的标记数据集和高质量提示上进行指令微调。尽管人们对将指令微调扩展到更大规模的数据集（数量和规模）越来越感兴趣，但我们的发现表明，简单地增加指令微调任务的数量并不总能带来更好的性能。相反，我们观察到，通过按模态间的共同交互分组任务，例如发现冗余共享信息、优先选择具有独特信息的模态或要求协同融合以从两种模态中获取新信息，可以鼓励模型在组内学习可迁移的技能，同时抑制不匹配任务之间的干扰。为此，我们引入了MINT，这是一种简单但令人惊讶有效的基于多模态交互类型的任务分组策略。我们证明了所提出的方法在多模态指令微调中大大优于现有的任务分组基线，实现了泛化和专业化的有效平衡。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in multimodal foundation models have achievedstate-of-the-art performance across a range of tasks. These breakthroughs arelargely driven by new pre-training paradigms that leverage large-scale,unlabeled multimodal data, followed by instruction fine-tuning on curatedlabeled datasets and high-quality prompts. While there is growing interest inscaling instruction fine-tuning to ever-larger datasets in both quantity andscale, our findings reveal that simply increasing the number ofinstruction-tuning tasks does not consistently yield better performance.Instead, we observe that grouping tasks by the common interactions acrossmodalities, such as discovering redundant shared information, prioritizingmodality selection with unique information, or requiring synergistic fusion todiscover new information from both modalities, encourages the models to learntransferrable skills within a group while suppressing interference frommismatched tasks. To this end, we introduce MINT, a simple yet surprisinglyeffective task-grouping strategy based on the type of multimodal interaction.We demonstrate that the proposed method greatly outperforms existing taskgrouping baselines for multimodal instruction tuning, striking an effectivebalance between generalization and specialization.</description>
      <author>example@mail.com (Xiaojun Shan, Qi Cao, Xing Han, Haofei Yu, Paul Pu Liang)</author>
      <guid isPermaLink="false">2506.02308v2</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>FORLA:Federated Object-centric Representation Learning with Slot Attention</title>
      <link>http://arxiv.org/abs/2506.02964v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为FORLA的新型框架，用于在异构无标签数据集上进行联邦学习中的对象中心表示学习和特征适应。&lt;h4&gt;背景&lt;/h4&gt;在联邦学习中，学习有效的视觉表示是一个核心挑战，需要联合信息跨客户端，同时在不监督的情况下解耦特定领域的因素。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，用于通过无监督的槽位注意力机制，在客户端之间进行联邦对象中心表示学习和特征适应。&lt;h4&gt;方法&lt;/h4&gt;该框架的核心是一个共享的特征适配器，它在客户端之间协作训练以适配基础模型中的特征，以及一个共享的槽位注意力模块，该模块学习重建适配后的特征。为了优化适配器，设计了一个双分支的学生-教师架构，其中每个客户端有一个学生解码器学习从基础模型重建完整特征，而一个教师解码器重建其适配的、低维的对应特征。共享的槽位注意力模块通过在客户端之间对齐对象级表示来实现跨领域学习。&lt;h4&gt;主要发现&lt;/h4&gt;在多个真实世界数据集上的实验表明，该框架不仅在对象发现方面优于集中式基线，而且还学习了一个紧凑的、通用的表示，该表示在各个领域内具有良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;这项工作突出了联邦槽位注意力作为从跨领域数据中可扩展、无监督地进行视觉表示学习的一个有效工具。&lt;h4&gt;翻译&lt;/h4&gt;该论文提出了一种新的联邦学习框架FORLA，用于在异构无标签数据集上进行对象中心的视觉表示学习和特征适应。通过实验证明，该方法在对象发现任务上优于集中式方法，并能学习到在不同领域内具有良好的泛化能力的紧凑表示。联邦槽位注意力机制被证明是跨领域数据无监督视觉表示学习的一个有效工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning efficient visual representations across heterogeneous unlabeleddatasets remains a central challenge in federated learning. Effective federatedrepresentations require features that are jointly informative across clientswhile disentangling domain-specific factors without supervision. We introduceFORLA, a novel framework for federated object-centric representation learningand feature adaptation across clients using unsupervised slot attention. At thecore of our method is a shared feature adapter, trained collaboratively acrossclients to adapt features from foundation models, and a shared slot attentionmodule that learns to reconstruct the adapted features. To optimize thisadapter, we design a two-branch student-teacher architecture. In each client, astudent decoder learns to reconstruct full features from foundation models,while a teacher decoder reconstructs their adapted, low-dimensionalcounterpart. The shared slot attention module bridges cross-domain learning byaligning object-level representations across clients. Experiments in multiplereal-world datasets show that our framework not only outperforms centralizedbaselines on object discovery but also learns a compact, universalrepresentation that generalizes well across domains. This work highlightsfederated slot attention as an effective tool for scalable, unsupervised visualrepresentation learning from cross-domain data with distributed concepts.</description>
      <author>example@mail.com (Guiqiu Liao, Matjaz Jogan, Eric Eaton, Daniel A. Hashimoto)</author>
      <guid isPermaLink="false">2506.02964v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
  <item>
      <title>OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models</title>
      <link>http://arxiv.org/abs/2506.03135v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://qizekun.github.io/omnispatial/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为OmniSpatial的全面且具有挑战性的空间推理基准，旨在解决当前视觉-语言模型在空间推理方面的局限。&lt;h4&gt;背景&lt;/h4&gt;空间推理是认知心理学的一个重要方面，也是当前视觉-语言模型的主要瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出OmniSpatial，一个基于认知心理学的空间推理基准，用于评估和改进视觉-语言模型对基本空间关系的理解。&lt;h4&gt;方法&lt;/h4&gt;通过互联网数据爬取和仔细的人工标注，构建了超过1500个问答对，涵盖动态推理、复杂空间逻辑、空间交互和视角假设四大类别，共计50个细粒度子类别。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，无论是开源还是闭源的视觉-语言模型，以及现有的推理和空间理解模型，在全面的空间理解方面都存在显著局限。&lt;h4&gt;结论&lt;/h4&gt;本文分析了失败案例，并提出了未来研究的潜在方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial reasoning is a key aspect of cognitive psychology and remains a majorbottleneck for current vision-language models (VLMs). While extensive researchhas aimed to evaluate or improve VLMs' understanding of basic spatialrelations, such as distinguishing left from right, near from far, and objectcounting, these tasks represent only the most fundamental level of spatialreasoning. In this work, we introduce OmniSpatial, a comprehensive andchallenging benchmark for spatial reasoning, grounded in cognitive psychology.OmniSpatial covers four major categories: dynamic reasoning, complex spatiallogic, spatial interaction, and perspective-taking, with 50 fine-grainedsubcategories. Through Internet data crawling and careful manual annotation, weconstruct over 1.5K question-answer pairs. Extensive experiments show that bothopen- and closed-source VLMs, as well as existing reasoning and spatialunderstanding models, exhibit significant limitations in comprehensive spatialunderstanding. We further analyze failure cases and propose potentialdirections for future research.</description>
      <author>example@mail.com (Mengdi Jia, Zekun Qi, Shaochen Zhang, Wenyao Zhang, Xinqiang Yu, Jiawei He, He Wang, Li Yi)</author>
      <guid isPermaLink="false">2506.03135v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Investigating Mask-aware Prototype Learning for Tabular Anomaly Detection</title>
      <link>http://arxiv.org/abs/2506.02757v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于表格式异常检测的方法，旨在解决现有深度学习方法在表示纠缠和全局相关性建模方面的不足。&lt;h4&gt;背景&lt;/h4&gt;表格式异常检测在医疗疾病识别、金融欺诈检测、入侵监测等领域具有重要应用。&lt;h4&gt;目的&lt;/h4&gt;提高异常检测的性能，解决表示纠缠和全局相关性建模问题。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了掩码建模和原型学习。在编码阶段，使用正交基向量进行学习，以共享无纠缠的正常模式；在解码阶段，并行解码多个掩码表示以进行重建，并学习关联原型以提取正常特征相关性。&lt;h4&gt;主要发现&lt;/h4&gt;模型从分布匹配的角度出发，将投影空间学习和关联原型学习都形式化为最优传输问题，并使用校准距离来细化异常分数。&lt;h4&gt;结论&lt;/h4&gt;在20个表格式基准数据集上的实验表明，该方法有效且可解释。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Tabular anomaly detection, which aims at identifying deviant samples, has been crucial in a variety of real-world applications, such as medical disease identification, financial fraud detection, intrusion monitoring, etc. Although recent deep learning-based methods have achieved competitive performances, these methods suffer from representation entanglement and the lack of global correlation modeling, which hinders anomaly detection performance. To tackle the problem, we incorporate mask modeling and prototype learning into tabular anomaly detection. The core idea is to design learnable masks by disentangled representation learning within a projection space and extracting normal dependencies as explicit global prototypes. Specifically, the overall model involves two parts: (i) During encoding, we perform mask modeling in both the data space and projection space with orthogonal basis vectors for learning shared disentangled normal patterns; (ii) During decoding, we decode multiple masked representations in parallel for reconstruction and learn association prototypes to extract normal characteristic correlations. Our proposal derives from a distribution-matching perspective, where both projection space learning and association prototype learning are formulated as optimal transport problems, and the calibration distances are utilized to refine the anomaly scores. Quantitative and qualitative experiments on 20 tabular benchmarks demonstrate the effectiveness and interpretability of our model.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tabular anomaly detection, which aims at identifying deviant samples, hasbeen crucial in a variety of real-world applications, such as medical diseaseidentification, financial fraud detection, intrusion monitoring, etc. Althoughrecent deep learning-based methods have achieved competitive performances,these methods suffer from representation entanglement and the lack of globalcorrelation modeling, which hinders anomaly detection performance. To tacklethe problem, we incorporate mask modeling and prototype learning into tabularanomaly detection. The core idea is to design learnable masks by disentangledrepresentation learning within a projection space and extracting normaldependencies as explicit global prototypes. Specifically, the overall modelinvolves two parts: (i) During encoding, we perform mask modeling in both thedata space and projection space with orthogonal basis vectors for learningshared disentangled normal patterns; (ii) During decoding, we decode multiplemasked representations in parallel for reconstruction and learn associationprototypes to extract normal characteristic correlations. Our proposal derivesfrom a distribution-matching perspective, where both projection space learningand association prototype learning are formulated as optimal transportproblems, and the calibration distances are utilized to refine the anomalyscores. Quantitative and qualitative experiments on 20 tabular benchmarksdemonstrate the effectiveness and interpretability of our model.</description>
      <author>example@mail.com (Ruiying Lu, Jinhan Liu, Chuan Du, Dandan Guo)</author>
      <guid isPermaLink="false">2506.02757v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Open-PMC-18M: A High-Fidelity Large Scale Medical Dataset for Multimodal Representation Learning</title>
      <link>http://arxiv.org/abs/2506.02738v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于Transformer的物体检测的子图提取流程，用于从复合图像中提取子图，并建立了大规模的生物医学视觉-语言数据集，以提高视觉-语言模型的表现。&lt;h4&gt;背景&lt;/h4&gt;复合图像在生物医学文献中很常见，但大规模的子图提取问题尚未得到解决。现有子图提取工作在数据集规模和泛化能力方面有限。&lt;h4&gt;目的&lt;/h4&gt;探讨高保真图像-文本对齐通过大规模子图提取对视觉-语言模型中的表示学习的影响。&lt;h4&gt;方法&lt;/h4&gt;提出了一种可扩展的子图提取流程，基于Transformer的物体检测，并在包含500,000个复合图像的合成语料库上训练。同时，创建了包含1800万个临床相关子图-标题对的OPEN-PMC-18M数据集。&lt;h4&gt;主要发现&lt;/h4&gt;该流程在ImageCLEF2016和合成基准测试上达到了最先进的性能，并在检索、零样本分类和鲁棒性基准测试中显示出改进的表现。&lt;h4&gt;结论&lt;/h4&gt;提出的子图提取流程和数据集有助于生物医学视觉-语言建模和表示学习的进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：复合图像，即包含多个子图的复合图像，在生物医学文献中普遍存在，但大规模的子图提取问题仍未得到解决。先前关于子图提取的研究在数据集规模和泛化能力方面都有限，留下了一个关键性的未解问题：通过大规模子图提取实现的高保真图像-文本对齐如何影响视觉-语言模型中的表示学习？我们通过引入一个基于Transformer的物体检测的可扩展子图提取流程来填补这一空白，该流程在包含500,000个复合图像的合成语料库上进行了训练，并在ImageCLEF2016和合成基准测试上实现了最先进的性能。使用这个流程，我们发布了OPEN-PMC-18M，这是一个大规模高质量的生物医学视觉-语言数据集，包含涵盖放射学、显微镜和可见光摄影的1800万个临床相关子图-标题对。我们在我们的精选数据集上训练并评估了视觉-语言模型，并在检索、零样本分类和鲁棒性基准测试中显示出改进的表现，优于现有基线。我们发布了我们的数据集、模型和代码，以支持可重复的基准测试和生物医学视觉-语言建模及表示学习的进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Compound figures, which are multi-panel composites containing diversesubfigures, are ubiquitous in biomedical literature, yet large-scale subfigureextraction remains largely unaddressed. Prior work on subfigure extraction hasbeen limited in both dataset size and generalizability, leaving a critical openquestion: How does high-fidelity image-text alignment via large-scale subfigureextraction impact representation learning in vision-language models? We addressthis gap by introducing a scalable subfigure extraction pipeline based ontransformer-based object detection, trained on a synthetic corpus of 500,000compound figures, and achieving state-of-the-art performance on both ImageCLEF2016 and synthetic benchmarks. Using this pipeline, we release OPEN-PMC-18M, alarge-scale high quality biomedical vision-language dataset comprising 18million clinically relevant subfigure-caption pairs spanning radiology,microscopy, and visible light photography. We train and evaluatevision-language models on our curated datasets and show improved performanceacross retrieval, zero-shot classification, and robustness benchmarks,outperforming existing baselines. We release our dataset, models, and code tosupport reproducible benchmarks and further study into biomedicalvision-language modeling and representation learning.</description>
      <author>example@mail.com (Negin Baghbanzadeh, Sajad Ashkezari, Elham Dolatabadi, Arash Afkanpour)</author>
      <guid isPermaLink="false">2506.02738v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Understanding Stability Mechanisms in Single-Atom Alloys with Theory-infused Deep Learning</title>
      <link>http://arxiv.org/abs/2506.03031v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种可解释的深度学习模型，通过将结合能理论纳入图神经网络（GNN）框架来增强过渡金属合金（TMAs）的预测能力。&lt;h4&gt;背景&lt;/h4&gt;模型旨在分析过渡金属合金的稳定性，并揭示其背后的物理参数。&lt;h4&gt;目的&lt;/h4&gt;预测总结合能（晶体稳定性的指标），并解析其贡献因素和基础物理参数。&lt;h4&gt;方法&lt;/h4&gt;将结合能理论应用于GNN框架，分析单原子合金（SAAs）的稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;模型揭示了过渡金属表面的稳定性趋势，并分析了单原子合金中单体/二聚体（平面对称性破坏）和顶层/底层（非平面对称性破坏）配置的相对稳定性。&lt;h4&gt;结论&lt;/h4&gt;该模型作为一个强大的工具，有助于理解和战略性地设计TMAs，以促进在催化和材料科学领域应用的材料稳定性提升。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种可解释的深度学习模型，通过将结合能理论融入图神经网络（GNN）框架，增强了过渡金属合金（TMAs）的预测能力。该模型不仅预测了总结合能——晶体稳定性的指标，而且还分解了其各种贡献因素和基础物理参数。从模型中提取的物理洞察力阐明了过渡金属表面在周期表中的稳定性趋势。此外，通过将该模型应用于单原子合金（SAAs），一类具有催化意义的下一代TMAs，我们分析了并解释了单体/二聚体（平面对称性破坏）和顶层/底层（非平面对称性破坏）配置的相对稳定性。这两种类型的对称性破坏导致单原子合金中不同的热力学偏好，受限于局域效应（例如d轨道耦合）和非局域效应（例如波函数重整化）。因此，该模型定位为理解和战略性地设计TMAs的强大工具，使材料科学和催化领域先进应用中具有改进稳定性的材料的定制开发成为可能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present an interpretable deep learning model that enhances the predictionof cohesive energy in transition metal alloys (TMAs) by incorporating cohesiontheory into a graph neural network (GNN) framework. The model not only predictsthe total cohesive energy-an indicator of crystal stability-but alsodisentangles its various contributing factors and underlying physicalparameters. The physics insights extracted from the model clarify the stabilitytrends of transition metal surfaces across the periodic table. Furthermore, byapplying the model to single-atom alloys (SAAs), a class of catalyticallysignificant next-generation TMAs, we analyze and explain the relative stabilityof monomer/dimer (in-plane symmetry breaking) and top-/sub-layer (out-of-planesymmetry breaking) configurations. These two types of symmetry breaking lead todistinct thermodynamic preferences in SAAs, governed by localized effects (e.g.d-orbital coupling) and delocalized effects (e.g. wavefunctionrenormalization). The model is thus positioned as a powerful tool forunderstanding and strategically designing TMAs, enabling the tailoreddevelopment of materials with improved stability for advanced applications incatalysis and materials science.</description>
      <author>example@mail.com (Yang Huang, Shih-Han Wang, Shuyi Cao, Luke E. K. Achenie, Hongliang Xin)</author>
      <guid isPermaLink="false">2506.03031v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Sheaves Reloaded: A Directional Awakening</title>
      <link>http://arxiv.org/abs/2506.02842v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新型的神经网络——有向细胞层神经网络（DSNN），它是一种强大的图神经网络（GNN）的推广，能够更好地建模复杂关系数据。&lt;h4&gt;背景&lt;/h4&gt;尽管方向性在图学习任务中已被证明能够显著提高性能，并且对于许多实际应用至关重要，但现有的有向神经网络在表示方向性方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一局限性，本文提出了有向细胞层（Directed Cellular Sheaf），一种专门设计的细胞层，旨在明确考虑边方向。在此基础上，定义了一种新的层拉普拉斯算子——有向层拉普拉斯算子，它捕捉了图的拓扑结构和方向信息。&lt;h4&gt;方法&lt;/h4&gt;本文提出的有向层神经网络（DSNN）将方向性嵌入到其架构中，通过有向层拉普拉斯算子作为其核心操作符。&lt;h4&gt;主要发现&lt;/h4&gt;在九个真实世界基准测试中，DSNN一致优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;DSNN作为一种新的神经网络模型，在建模复杂关系数据方面具有显著优势，并且能够提高图学习任务的性能。&lt;h4&gt;翻译&lt;/h4&gt;Sheaf Neural Networks (SNNs) represent a powerful generalization of GraphNeural Networks (GNNs) that significantly improve our ability to model complex relational data. While directionality has been shown to substantially boost performance in graph learning tasks and is key to many real-world applications, existing SNNs fall short in representing it. To address this limitation, we introduce the Directed Cellular Sheaf, a special type of cellular sheaf designed to explicitly account for edge orientation. Building on this structure, we define a new sheaf Laplacian, the Directed Sheaf Laplacian, which captures both the graph's topology and its directional information. This operator serves as the backbone of the Directed Sheaf Neural Network (DSNN), the first SNN model to embed a directional bias into its architecture. Extensive experiments on nine real-world benchmarks show that DSNN consistently outperforms baseline methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sheaf Neural Networks (SNNs) represent a powerful generalization of GraphNeural Networks (GNNs) that significantly improve our ability to model complexrelational data. While directionality has been shown to substantially boostperformance in graph learning tasks and is key to many real-world applications,existing SNNs fall short in representing it. To address this limitation, weintroduce the Directed Cellular Sheaf, a special type of cellular sheafdesigned to explicitly account for edge orientation. Building on thisstructure, we define a new sheaf Laplacian, the Directed Sheaf Laplacian, whichcaptures both the graph's topology and its directional information. Thisoperator serves as the backbone of the Directed Sheaf Neural Network (DSNN),the first SNN model to embed a directional bias into its architecture.Extensive experiments on nine real-world benchmarks show that DSNN consistentlyoutperforms baseline methods.</description>
      <author>example@mail.com (Stefano Fiorini, Hakan Aktas, Iulia Duta, Stefano Coniglio, Pietro Morerio, Alessio Del Bue, Pietro Liò)</author>
      <guid isPermaLink="false">2506.02842v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MMM4Rec: An Transfer-Efficient Framework for Multi-modal Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2506.02916v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MMM4Rec的多模态序列推荐框架，通过结合状态空间对偶（SSD）的时间衰减特性和时间感知建模设计，实现高效迁移学习，并显著提高了多模态推荐精度和迁移能力。&lt;h4&gt;背景&lt;/h4&gt;序列推荐系统通过分析用户交互历史来建模用户偏好。虽然多模态序列推荐架构比传统的基于ID的方法表现出色，但当前方法在适应新领域时需要大量微调，存在优化要求和负迁移效应，成为部署的瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多模态序列推荐框架，以降低迁移学习成本，提高推荐精度和迁移能力。&lt;h4&gt;方法&lt;/h4&gt;MMM4Rec框架采用一个专用的代数约束机制，通过结合SSD的时间衰减特性和时间感知建模设计，动态优先考虑关键模态信息。它实现了一个受限的两阶段过程：首先通过共享投影矩阵进行序列级别的跨模态对齐，然后使用新设计的Cross-SSD模块和双通道傅里叶自适应滤波进行时间融合。&lt;h4&gt;主要发现&lt;/h4&gt;MMM4Rec在快速微调收敛和简单交叉熵损失下表现出色，与现有模型相比，实现了31.78%的NDCG@10最大提升，并且在迁移到大规模下游数据集时表现出10倍的平均收敛速度。&lt;h4&gt;结论&lt;/h4&gt;MMM4Rec框架在多模态序列推荐领域表现出卓越的性能，为推荐系统的微调和迁移学习提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential Recommendation (SR) systems model user preferences by analyzinginteraction histories. Although transferable multi-modal SR architecturesdemonstrate superior performance compared to traditional ID-based approaches,current methods incur substantial fine-tuning costs when adapting to newdomains due to complex optimization requirements and negative transfer effects- a significant deployment bottleneck that hinders engineers from efficientlyrepurposing pre-trained models for novel application scenarios with minimaltuning overhead. We propose MMM4Rec (Multi-Modal Mamba for SequentialRecommendation), a novel multi-modal SR framework that incorporates a dedicatedalgebraic constraint mechanism for efficient transfer learning. By combiningState Space Duality (SSD)'s temporal decay properties with a time-awaremodeling design, our model dynamically prioritizes key modality information,overcoming limitations of Transformer-based approaches. The frameworkimplements a constrained two-stage process: (1) sequence-level cross-modalalignment via shared projection matrices, followed by (2) temporal fusion usingour newly designed Cross-SSD module and dual-channel Fourier adaptivefiltering. This architecture maintains semantic consistency while suppressingnoise propagation.MMM4Rec achieves rapid fine-tuning convergence with simplecross-entropy loss, significantly improving multi-modal recommendation accuracywhile maintaining strong transferability. Extensive experiments demonstrateMMM4Rec's state-of-the-art performance, achieving the maximum 31.78% NDCG@10improvement over existing models and exhibiting 10 times faster averageconvergence speed when transferring to large-scale downstream datasets.</description>
      <author>example@mail.com (Hao Fan, Yanrong Hu, Kai Fang, Qingyang Liu, Hongjiu Liu)</author>
      <guid isPermaLink="false">2506.02916v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Go Beyond Earth: Understanding Human Actions and Scenes in Microgravity Environments</title>
      <link>http://arxiv.org/abs/2506.02845v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 3 figures, submitted to NeurIPS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为MicroG-4M的数据集，用于微重力下人类活动的时空和语义理解。&lt;h4&gt;背景&lt;/h4&gt;现有的视频理解数据集大多限于地球重力条件，而微重力会改变人类动作、交互和视觉语义，这对现实世界的视觉系统提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，提出了MicroG-4M，以支持微重力环境下的领域鲁棒视频理解。&lt;h4&gt;方法&lt;/h4&gt;MicroG-4M由真实太空任务和电影模拟构建，包括4,759个剪辑，涵盖50个动作，1,238个丰富的上下文描述，以及关于宇航员活动和场景理解的7,000多对问答。&lt;h4&gt;主要发现&lt;/h4&gt;MicroG-4M支持精细粒度多标签动作识别、时间视频字幕和视觉问答三个核心任务，从而全面评估微重力环境中的空间定位和语义推理。&lt;h4&gt;结论&lt;/h4&gt;通过使用最先进的模型建立基线，所有数据、注释和代码均可在https://github.com/LEI-QI-233/HAR-in-Space上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite substantial progress in video understanding, most existing datasetsare limited to Earth's gravitational conditions. However, microgravity altershuman motion, interactions, and visual semantics, revealing a critical gap forreal-world vision systems. This presents a challenge for domain-robust videounderstanding in safety-critical space applications. To address this, weintroduce MicroG-4M, the first benchmark for spatio-temporal and semanticunderstanding of human activities in microgravity. Constructed from real-worldspace missions and cinematic simulations, the dataset includes 4,759 clipscovering 50 actions, 1,238 context-rich captions, and over 7,000question-answer pairs on astronaut activities and scene understanding.MicroG-4M supports three core tasks: fine-grained multi-label actionrecognition, temporal video captioning, and visual question answering, enablinga comprehensive evaluation of both spatial localization and semantic reasoningin microgravity contexts. We establish baselines using state-of-the-art models.All data, annotations, and code are available athttps://github.com/LEI-QI-233/HAR-in-Space.</description>
      <author>example@mail.com (Di Wen, Lei Qi, Kunyu Peng, Kailun Yang, Fei Teng, Ao Luo, Jia Fu, Yufan Chen, Ruiping Liu, Yitian Shi, M. Saquib Sarfraz, Rainer Stiefelhagen)</author>
      <guid isPermaLink="false">2506.02845v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Rodrigues Network for Learning Robot Actions</title>
      <link>http://arxiv.org/abs/2506.02618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为神经罗德里格斯算子（Neural Rodrigues Operator）的学习泛化方法，旨在为神经网络注入动力学感知的归纳偏置，以解决机器人学习中理解与预测关节动作的问题。&lt;h4&gt;背景&lt;/h4&gt;目前常用的神经网络架构如MLPs和Transformers缺乏反映关节系统底层运动学结构的归纳偏置。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够学习运动学操作的方法，并将其应用于神经网络，以提高对关节动作的理解和预测。&lt;h4&gt;方法&lt;/h4&gt;设计了神经罗德里格斯算子，并基于此算子构建了罗德里格斯网络（RodriNet），一个针对动作处理的创新神经网络架构。在合成任务中评估了该网络的表达能力，并在真实应用中进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;在运动学预测和动作预测的合成任务中，与标准骨干相比，罗德里格斯网络表现出显著的改进。在机器人基准测试和单图像3D手部重建的实际情况中，也展示了其有效性。&lt;h4&gt;结论&lt;/h4&gt;将结构化的运动学先验整合到网络架构中，可以改善在不同领域中的动作学习。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在机器人学习中，理解和预测关节动作非常重要。然而，像MLP和Transformers这样的常见架构缺乏反映关节系统底层运动学结构的归纳偏置。为此，我们提出了神经罗德里格斯算子，这是一种对经典前向运动学操作的学习泛化，旨在将运动学感知的归纳偏置注入到神经网络中。基于这个算子，我们设计了罗德里格斯网络（RodriNet），一种专门用于处理动作的新颖神经网络架构。我们在两个合成任务中评估了我们的网络在运动学和运动预测方面的表达能力，与标准骨干相比，显示出显著的改进。我们进一步证明了其在两个实际应用中的有效性：（i）使用扩散策略在机器人基准测试中进行模仿学习，以及（ii）单图像3D手部重建。我们的结果表明，将结构化的运动学先验整合到网络架构中可以提高各种领域中的动作学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding and predicting articulated actions is important in robotlearning. However, common architectures such as MLPs and Transformers lackinductive biases that reflect the underlying kinematic structure of articulatedsystems. To this end, we propose the Neural Rodrigues Operator, a learnablegeneralization of the classical forward kinematics operation, designed toinject kinematics-aware inductive bias into neural computation. Building onthis operator, we design the Rodrigues Network (RodriNet), a novel neuralarchitecture specialized for processing actions. We evaluate the expressivityof our network on two synthetic tasks on kinematic and motion prediction,showing significant improvements compared to standard backbones. We furtherdemonstrate its effectiveness in two realistic applications: (i) imitationlearning on robotic benchmarks with the Diffusion Policy, and (ii) single-image3D hand reconstruction. Our results suggest that integrating structuredkinematic priors into the network architecture improves action learning invarious domains.</description>
      <author>example@mail.com (Jialiang Zhang, Haoran Geng, Yang You, Congyue Deng, Pieter Abbeel, Jitendra Malik, Leonidas Guibas)</author>
      <guid isPermaLink="false">2506.02618v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MERIT: Multilingual Semantic Retrieval with Interleaved Multi-Condition Query</title>
      <link>http://arxiv.org/abs/2506.03144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint; Project Page, Code, and Dataset at:  https://merit-2025.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了MERIT，第一个用于交错多条件语义检索的多语言数据集，并提出了Coral框架以改进现有模型在多条件语义检索中的性能。&lt;h4&gt;背景&lt;/h4&gt;语义检索在现代应用中至关重要，但当前研究探索不足。现有数据集通常限于单一语言、单一图像或单一检索条件，未能充分利用视觉信息的表现力。&lt;h4&gt;目的&lt;/h4&gt;提出MERIT数据集和Coral框架，以解决现有数据集的局限性并改进多条件语义检索的性能。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含320,000个查询和135,000个产品的多语言数据集，提出了一种新的微调框架Coral，该框架通过嵌入重建和对比学习来改进预训练的MLLM。&lt;h4&gt;主要发现&lt;/h4&gt;在MERIT上的实验表明，Coral比传统方法在性能上提高了45.9%，并验证了其在8个已建立的检索基准上的强大泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文的贡献——一个新颖的数据集、识别现有方法的关键局限性和一个创新的微调框架——为交错多条件语义检索的未来研究奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语义检索对于现代应用至关重要，但在当前研究中却未得到充分探索。现有数据集仅限于单一语言、单一图像或单一检索条件，往往未能充分利用视觉信息的表现力，这从当图像被标题替换时维持的性能可以得出。然而，实际的检索场景通常涉及交错的多条件查询和多图像。因此，本文介绍了MERIT，这是第一个用于交错多条件语义检索的多语言数据集，包括5种语言中的320,000个查询和135,000个产品，涵盖7个不同的产品类别。在MERIT上的广泛实验确定了现有模型的局限性：只关注全局语义信息，而忽略了查询中的特定条件元素。因此，我们提出了Coral，一个新颖的微调框架，通过整合嵌入重建来保留细粒度的条件元素，并通过对比学习来提取全面的全球语义。实验表明，Coral在MERIT上比传统方法实现了45.9%的性能提升，并在8个已建立的检索基准上验证了其强大的泛化能力。总的来说，我们的贡献——一个新颖的数据集、识别现有方法的临界局限性以及一个创新的微调框架——为交错多条件语义检索的未来研究奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic retrieval is crucial for modern applications yet remainsunderexplored in current research. Existing datasets are limited to singlelanguages, single images, or singular retrieval conditions, often failing tofully exploit the expressive capacity of visual information as evidenced bymaintained performance when images are replaced with captions. However,practical retrieval scenarios frequently involve interleaved multi-conditionqueries with multiple images. Hence, this paper introduces MERIT, the firstmultilingual dataset for interleaved multi-condition semantic retrieval,comprising 320,000 queries with 135,000 products in 5 languages, covering 7distinct product categories. Extensive experiments on MERIT identify existingmodels's limitation: focusing solely on global semantic information whileneglecting specific conditional elements in queries. Consequently, we proposeCoral, a novel fine-tuning framework that adapts pre-trained MLLMs byintegrating embedding reconstruction to preserve fine-grained conditionalelements and contrastive learning to extract comprehensive global semantics.Experiments demonstrate that Coral achieves a 45.9% performance improvementover conventional approaches on MERIT, with strong generalization capabilitiesvalidated across 8 established retrieval benchmarks. Collectively, ourcontributions - a novel dataset, identification of critical limitations inexisting approaches, and an innovative fine-tuning framework - establish afoundation for future research in interleaved multi-condition semanticretrieval.</description>
      <author>example@mail.com (Wei Chow, Yuan Gao, Linfeng Li, Xian Wang, Qi Xu, Hang Song, Lingdong Kong, Ran Zhou, Yi Zeng, Yidong Cai, Botian Jiang, Shilin Xu, Jiajun Zhang, Minghui Qiu, Xiangtai Li, Tianshu Yang, Siliang Tang, Juncheng Li)</author>
      <guid isPermaLink="false">2506.03144v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Large-scale Self-supervised Video Foundation Model for Intelligent Surgery</title>
      <link>http://arxiv.org/abs/2506.02692v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为SurgVISTA的视频级手术预训练框架，旨在通过联合时空建模学习大规模手术视频数据，以改善手术场景理解，从而支持决策、提高手术效率和确保术中安全。&lt;h4&gt;背景&lt;/h4&gt;计算机辅助干预（CAI）有潜力革命化现代外科手术，其中手术场景理解是支持决策、提高手术效率和确保术中安全的关键组成部分。现有的基于AI的方法通过自监督空间表示学习减轻了注释负担，但在预训练过程中缺乏显式的时序建模，这从根本上限制了动态手术场景的捕捉，导致时空理解不完整。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一个能够从大规模手术视频数据中联合时空表示学习的预训练框架，以改善手术场景理解。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含3,650个视频和约3,550,000个帧的大规模手术视频数据集，覆盖20多种手术程序和10多个解剖结构。基于此数据集，提出了SurgVISTA，这是一种基于重建的预训练方法，通过联合时空建模捕捉复杂的空间结构和时序动态。此外，SurgVISTA结合了由手术专家指导的图像级知识蒸馏，以增强对细粒度解剖和语义特征的学习。&lt;h4&gt;主要发现&lt;/h4&gt;SurgVISTA在13个视频级数据集组成的全面基准上进行了验证，这些数据集覆盖六个手术程序和四个任务。广泛的实验表明，SurgVISTA在自然和手术领域预训练模型中表现一致地优于，展示了在临床上有意义的场景中推进智能手术系统的强大潜力。&lt;h4&gt;结论&lt;/h4&gt;SurgVISTA预训练框架有望通过提升手术场景理解，支持临床意义上的智能手术系统的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computer-Assisted Intervention (CAI) has the potential to revolutionizemodern surgery, with surgical scene understanding serving as a criticalcomponent in supporting decision-making, improving procedural efficacy, andensuring intraoperative safety. While existing AI-driven approaches alleviateannotation burdens via self-supervised spatial representation learning, theirlack of explicit temporal modeling during pre-training fundamentally restrictsthe capture of dynamic surgical contexts, resulting in incompletespatiotemporal understanding. In this work, we introduce the first video-levelsurgical pre-training framework that enables joint spatiotemporalrepresentation learning from large-scale surgical video data. To achieve this,we constructed a large-scale surgical video dataset comprising 3,650 videos andapproximately 3.55 million frames, spanning more than 20 surgical proceduresand over 10 anatomical structures. Building upon this dataset, we proposeSurgVISTA (Surgical Video-level Spatial-Temporal Architecture), areconstruction-based pre-training method that captures intricate spatialstructures and temporal dynamics through joint spatiotemporal modeling.Additionally, SurgVISTA incorporates image-level knowledge distillation guidedby a surgery-specific expert to enhance the learning of fine-grained anatomicaland semantic features. To validate its effectiveness, we established acomprehensive benchmark comprising 13 video-level datasets spanning sixsurgical procedures across four tasks. Extensive experiments demonstrate thatSurgVISTA consistently outperforms both natural- and surgical-domainpre-trained models, demonstrating strong potential to advance intelligentsurgical systems in clinically meaningful scenarios.</description>
      <author>example@mail.com (Shu Yang, Fengtao Zhou, Leon Mayer, Fuxiang Huang, Yiliang Chen, Yihui Wang, Sunan He, Yuxiang Nie, Xi Wang, Ömer Sümer, Yueming Jin, Huihui Sun, Shuchang Xu, Alex Qinyang Liu, Zheng Li, Jing Qin, Jeremy YuenChun Teoh, Lena Maier-Hein, Hao Chen)</author>
      <guid isPermaLink="false">2506.02692v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Combining social relations and interaction data in Recommender System with Graph Convolution Collaborative Filtering</title>
      <link>http://arxiv.org/abs/2506.02834v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了推荐系统在数据挖掘领域的应用，通过分析用户评分信息，为用户提供合适的产品推荐，并在电子商务、阅读书籍、观看电影、选择课程或访问网站等方面发挥作用。&lt;h4&gt;背景&lt;/h4&gt;推荐系统利用用户评分信息，通过协作过滤、矩阵分解或奇异向量分解等方法，计算用户间的相似性，以生成推荐。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提高推荐系统的准确性和召回率，通过结合社交关系数据和用户评分历史相似性来实现。&lt;h4&gt;方法&lt;/h4&gt;提出了数据预处理方法来去除异常值，如单个评论或与项目互动较少的用户。提出的模型将结合社交关系数据和用户评分历史相似性。&lt;h4&gt;主要发现&lt;/h4&gt;发现用户间的相似性对推荐有重要影响，社交关系数据也会影响消费习惯，但结合用户社交影响和相似购物习惯存在挑战。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法有助于提高推荐系统的准确性和召回率，通过处理数据噪声并考虑用户社交关系和评分历史相似性。&lt;h4&gt;翻译&lt;/h4&gt;A recommender system is an important subject in the field of data mining, where the item rating information from users is exploited and processed to make suitable recommendations with all other users. The recommender system creates convenience for e-commerce users and stimulates the consumption of items that are suitable for users. In addition to e-commerce, a recommender system is also used to provide recommendations on books to read, movies to watch, courses to take or websites to visit. Similarity between users is an important impact for recommendation, which could be calculated from the data of past user ratings of the item by methods of collaborative filtering, matrix factorization or singular vector decomposition. In the development of graph data mining techniques, the relationships between users and items can be represented by matrices from which collaborative filtering could be done with the larger database, more accurate and faster in calculation. All these data can be represented graphically and mined by today's highly developed graph neural network models. On the other hand, users' social friendship data also influence consumption habits because recommendations from friends will be considered more carefully than information sources. However, combining a user's friend influence and the similarity between users whose similar shopping habits is challenging. Because the information is noisy and it affects each particular data set in different ways. In this study, we present the input data processing method to remove outliers which are single reviews or users with little interaction with the items; the next proposed model will combine the social relationship data and the similarity in the rating history of users to improve the accuracy and recall of the recommender system.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A recommender system is an important subject in the field of data mining,where the item rating information from users is exploited and processed to makesuitable recommendations with all other users. The recommender system createsconvenience for e-commerce users and stimulates the consumption of items thatare suitable for users. In addition to e-commerce, a recommender system is alsoused to provide recommendations on books to read, movies to watch, courses totake or websites to visit. Similarity between users is an important impact forrecommendation, which could be calculated from the data of past user ratings ofthe item by methods of collaborative filtering, matrix factorization orsingular vector decomposition. In the development of graph data miningtechniques, the relationships between users and items can be represented bymatrices from which collaborative filtering could be done with the largerdatabase, more accurate and faster in calculation. All these data can berepresented graphically and mined by today's highly developed graph neuralnetwork models. On the other hand, users' social friendship data also influenceconsumption habits because recommendations from friends will be considered morecarefully than information sources. However, combining a user's friendinfluence and the similarity between users whose similar shopping habits ischallenging. Because the information is noisy and it affects each particulardata set in different ways. In this study, we present the input data processingmethod to remove outliers which are single reviews or users with littleinteraction with the items; the next proposed model will combine the socialrelationship data and the similarity in the rating history of users to improvethe accuracy and recall of the recommender system.</description>
      <author>example@mail.com (Tin T. Tran, Vaclav Snasel, Loc Tan Nguyen)</author>
      <guid isPermaLink="false">2506.02834v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MVTD: A Benchmark Dataset for Maritime Visual Object Tracking</title>
      <link>http://arxiv.org/abs/2506.02866v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submited to Nature Scientific Data&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Maritime Visual Tracking Dataset (MVTD)，这是一个专为海上视觉目标跟踪任务设计的公开数据集，旨在解决海上环境中的跟踪挑战。&lt;h4&gt;背景&lt;/h4&gt;尽管通用目标跟踪技术取得了显著进展，但海上环境中的特殊挑战，如水面反光、低对比度目标、动态变化的背景和频繁的遮挡，对现有跟踪算法的性能产生了显著影响。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一差距，本文提出了MVTD数据集，以提供针对海上视觉目标跟踪的特定领域数据。&lt;h4&gt;方法&lt;/h4&gt;MVTD包含182个高分辨率视频序列，总计约150,000帧，涵盖了船只、船舶、帆船和无人水面舰艇四个代表性目标类别。该数据集捕捉了多样化的操作条件和海上场景，反映了真实海上环境的复杂性。&lt;h4&gt;主要发现&lt;/h4&gt;在MVTD上评估了14种最新的SOTA跟踪算法，发现与通用数据集相比，这些算法的性能有所下降。然而，当在MVTD上微调后，这些模型表现出显著的性能提升，强调了领域适应和迁移学习在特定跟踪环境中的重要性。&lt;h4&gt;结论&lt;/h4&gt;MVTD数据集为视觉跟踪社区填补了一个关键缺口，提供了一个真实且具有挑战性的海上场景基准。&lt;h4&gt;翻译&lt;/h4&gt;视觉目标跟踪（VOT）是一个具有广泛应用的基本任务，在自主导航、监控和海事机器人等领域有着重要作用。尽管通用目标跟踪取得了显著的进步，但海上环境仍然存在独特的挑战，包括水面反光、低对比度目标、动态变化的背景和频繁的遮挡。这些复杂性严重降低了最先进跟踪算法的性能，突显了特定领域数据集的必要性。为了解决这一差距，我们引入了海事视觉跟踪数据集（MVTD），这是一个专为海上视觉目标跟踪设计的公开基准数据集。MVTD包含182个高分辨率视频序列，总计约150,000帧，包括船只、船舶、帆船和无人水面舰艇四个代表性目标类别。该数据集捕捉了多样化的操作条件和海上场景，反映了真实海上环境的复杂性。我们在MVTD基准上评估了14种最近的最先进跟踪算法，并观察到与它们在通用数据集上的性能相比，性能有显著下降。然而，当在MVTD上微调时，这些模型表现出显著的性能提升，强调了领域适应和迁移学习在特定跟踪环境中的重要性。MVTD数据集通过为海上场景提供真实且具有挑战性的基准，在视觉跟踪社区中填补了一个关键缺口。数据集和源代码可在以下链接访问：https://github.com/AhsanBaidar/MVTD。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Object Tracking (VOT) is a fundamental task with widespreadapplications in autonomous navigation, surveillance, and maritime robotics.Despite significant advances in generic object tracking, maritime environmentscontinue to present unique challenges, including specular water reflections,low-contrast targets, dynamically changing backgrounds, and frequentocclusions. These complexities significantly degrade the performance ofstate-of-the-art tracking algorithms, highlighting the need for domain-specificdatasets. To address this gap, we introduce the Maritime Visual TrackingDataset (MVTD), a comprehensive and publicly available benchmark specificallydesigned for maritime VOT. MVTD comprises 182 high-resolution video sequences,totaling approximately 150,000 frames, and includes four representative objectclasses: boat, ship, sailboat, and unmanned surface vehicle (USV). The datasetcaptures a diverse range of operational conditions and maritime scenarios,reflecting the real-world complexities of maritime environments. We evaluated14 recent SOTA tracking algorithms on the MVTD benchmark and observedsubstantial performance degradation compared to their performance ongeneral-purpose datasets. However, when fine-tuned on MVTD, these modelsdemonstrate significant performance gains, underscoring the effectiveness ofdomain adaptation and the importance of transfer learning in specializedtracking contexts. The MVTD dataset fills a critical gap in the visual trackingcommunity by providing a realistic and challenging benchmark for maritimescenarios. Dataset and Source Code can be accessed here"https://github.com/AhsanBaidar/MVTD".</description>
      <author>example@mail.com (Ahsan Baidar Bakht, Muhayy Ud Din, Sajid Javed, Irfan Hussain)</author>
      <guid isPermaLink="false">2506.02866v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>PhysGaia: A Physics-Aware Dataset of Multi-Body Interactions for Dynamic Novel View Synthesis</title>
      <link>http://arxiv.org/abs/2506.02794v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: http://cvlab.snu.ac.kr/research/PhysGaia, Data:  https://huggingface.co/datasets/mijeongkim/PhysGaia/tree/main&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PhysGaia是一个为动态新颖视图合成（DyNVS）设计的物理感知数据集，包含结构化物体和无结构物理现象。它支持物理感知的动态场景建模，具有丰富的多物体交互和多种物理材料，并严格遵循物理定律。&lt;h4&gt;背景&lt;/h4&gt;现有的数据集主要关注 photorealistic reconstruction，而PhysGaia旨在支持物理感知的动态场景建模。&lt;h4&gt;目的&lt;/h4&gt;提供复杂的动态场景，支持物理建模，并促进动态视图合成、基于物理的场景理解和深度学习与物理模拟的集成。&lt;h4&gt;方法&lt;/h4&gt;PhysGaia使用精心选择的材料特定物理求解器来生成场景，并提供了3D粒子轨迹和物理参数等真实信息。&lt;h4&gt;主要发现&lt;/h4&gt;PhysGaia超越了现有数据集中常见的刚性物体，包含液体、气体、粘弹性和纺织等物理材料。&lt;h4&gt;结论&lt;/h4&gt;PhysGaia解决了物理感知建模数据集的缺乏问题，将显著推动动态视图合成和相关领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;PhysGaia是一个新的物理感知数据集，专门用于动态新颖视图合成。它包含结构化物体和无结构物理现象。与现有主要关注真实感重建的数据集不同，PhysGaia旨在积极支持物理感知的动态场景建模。我们的数据集提供了复杂的动态场景，其中多个物体之间有丰富的交互，它们真实地碰撞并交换力。此外，它包含多种物理材料，如液体、气体、粘弹性物质和纺织品，这些材料超越了现有数据集中普遍存在的刚性物体。PhysGaia中的所有场景都忠实于物理定律，利用精心选择的材料特定物理求解器生成。为了使物理建模具有可量化的评估，我们的数据集提供了必要的真实信息，包括3D粒子轨迹和物理参数，例如粘度。为了促进研究采用，我们还提供了使用最先进的DyNVS模型与我们的数据集的必要集成管道，并报告了它们的结果。通过解决物理感知建模数据集的关键缺乏，PhysGaia将显著推进动态视图合成、基于物理的场景理解和与物理模拟集成的深度学习模型的研究——最终使更忠实于复杂动态场景的重建和解释成为可能。我们的数据集和代码可在项目网站http://cvlab.snu.ac.kr/research/PhysGaia上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce PhysGaia, a novel physics-aware dataset specifically designedfor Dynamic Novel View Synthesis (DyNVS), encompassing both structured objectsand unstructured physical phenomena. Unlike existing datasets that primarilyfocus on photorealistic reconstruction, PhysGaia is created to actively supportphysics-aware dynamic scene modeling. Our dataset provides complex dynamicscenarios with rich interactions among multiple objects, where theyrealistically collide with each other and exchange forces. Furthermore, itcontains a diverse range of physical materials, such as liquid, gas,viscoelastic substance, and textile, which moves beyond the rigid bodiesprevalent in existing datasets. All scenes in PhysGaia are faithfully generatedto strictly adhere to physical laws, leveraging carefully selectedmaterial-specific physics solvers. To enable quantitative evaluation ofphysical modeling, our dataset provides essential ground-truth information,including 3D particle trajectories and physics parameters, e.g., viscosity. Tofacilitate research adoption, we also provide essential integration pipelinesfor using state-of-the-art DyNVS models with our dataset and report theirresults. By addressing the critical lack of datasets for physics-awaremodeling, PhysGaia will significantly advance research in dynamic viewsynthesis, physics-based scene understanding, and deep learning modelsintegrated with physical simulation -- ultimately enabling more faithfulreconstruction and interpretation of complex dynamic scenes. Our datasets andcodes are available in the project website,http://cvlab.snu.ac.kr/research/PhysGaia.</description>
      <author>example@mail.com (Mijeong Kim, Gunhee Kim, Jungyoon Choi, Wonjae Roh, Bohyung Han)</author>
      <guid isPermaLink="false">2506.02794v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Targeted Forgetting of Image Subgroups in CLIP Models</title>
      <link>http://arxiv.org/abs/2506.03117v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 Figures,5 Pages. The project page is  \url{https://zhangaipi.github.io/forget_clip/}&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法，用于在保留模型整体性能的同时，从预训练模型中选择性忘记特定知识部分。&lt;h4&gt;背景&lt;/h4&gt;现有的模型遗忘方法要么依赖于对预训练数据集的访问，要么专注于粗粒度的遗忘（例如整个类别），在细粒度遗忘方面存在空白。&lt;h4&gt;目的&lt;/h4&gt;在不依赖预训练数据的情况下，选择性地忘记特定知识部分，同时保持模型的整体性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种三阶段方法，包括：(1) 遗忘阶段，对要遗忘的样本进行微调；(2) 提醒阶段，恢复保留样本的性能；(3) 恢复阶段，使用模型蒸馏恢复零样本能力。此外，引入了知识蒸馏来处理遗忘样本、保留样本和未见过的预训练数据之间的分布差异。&lt;h4&gt;主要发现&lt;/h4&gt;在CIFAR-10、ImageNet-1K和风格数据集上的大量实验表明，该方法在遗忘特定子组的同时，在语义相似的子组和其他类别上保持了强大的零样本性能，显著优于基线遗忘方法。&lt;h4&gt;结论&lt;/h4&gt;该方法在保持模型性能的同时，有效地实现了细粒度知识遗忘，为模型在实际应用中的可靠性提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型（FMs）如CLIP通过利用大规模的无监督预训练，在各种任务上展示了令人印象深刻的零样本性能。然而，它们往往从嘈杂的互联网数据集中继承有害或不希望的知识，损害了其在现实世界应用中的可靠性。现有的模型遗忘方法要么依赖于访问预训练数据集，要么专注于粗粒度遗忘（例如整个类别），在细粒度遗忘方面存在关键差距。在本文中，我们解决了在没有访问预训练数据的情况下，在类中选择性地忘记特定知识部分这一具有挑战性的场景，同时保持模型的整体性能。我们提出了一种新颖的三阶段方法，逐步遗忘目标知识同时减轻过度遗忘。它包括（1）遗忘阶段，对要遗忘的样本进行微调；（2）提醒阶段，恢复保留样本的性能；（3）恢复阶段，使用模型蒸馏恢复零样本能力。此外，我们引入了知识蒸馏来处理遗忘样本、保留样本和未见过的预训练数据之间的分布差异。在CIFAR-10、ImageNet-1K和风格数据集上的大量实验表明，我们的方法在遗忘特定子组的同时，在语义相似的子组和其他类别上保持了强大的零样本性能，显著优于基线遗忘方法，这些方法在CLIP遗忘设置下失去了有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) such as CLIP have demonstrated impressive zero-shotperformance across various tasks by leveraging large-scale, unsupervisedpre-training. However, they often inherit harmful or unwanted knowledge fromnoisy internet-sourced datasets, compromising their reliability in real-worldapplications. Existing model unlearning methods either rely on access topre-trained datasets or focus on coarse-grained unlearning (e.g., entireclasses), leaving a critical gap for fine-grained unlearning. In this paper, weaddress the challenging scenario of selectively forgetting specific portions ofknowledge within a class, without access to pre-trained data, while preservingthe model's overall performance. We propose a novel three-stage approach thatprogressively unlearns targeted knowledge while mitigating over-forgetting. Itconsists of (1) a forgetting stage to fine-tune the CLIP on samples to beforgotten, (2) a reminding stage to restore performance on retained samples,and (3) a restoring stage to recover zero-shot capabilities using modelsouping. Additionally, we introduce knowledge distillation to handle thedistribution disparity between forgetting, retaining samples, and unseenpre-trained data. Extensive experiments on CIFAR-10, ImageNet-1K, and styledatasets demonstrate that our approach effectively unlearns specific subgroupswhile maintaining strong zero-shot performance on semantically similarsubgroups and other categories, significantly outperforming baseline unlearningmethods, which lose effectiveness under the CLIP unlearning setting.</description>
      <author>example@mail.com (Zeliang Zhang, Gaowen Liu, Charles Fleming, Ramana Rao Kompella, Chenliang Xu)</author>
      <guid isPermaLink="false">2506.03117v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Enriching Location Representation with Detailed Semantic Information</title>
      <link>http://arxiv.org/abs/2506.02744v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了CaLLiPer+模型，该模型通过整合POI名称和分类标签，在多模态对比学习框架中提升了对城市环境结构性和语义特征的捕捉能力。&lt;h4&gt;背景&lt;/h4&gt;传统的空间嵌入方法往往过于重视空间邻近性，而未能充分利用地点的细粒度上下文信息。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一局限性，提出了一种新的模型CaLLiPer+，旨在提高城市建模的准确性。&lt;h4&gt;方法&lt;/h4&gt;CaLLiPer+模型在多模态对比学习框架中整合了POI名称和分类标签，并在土地利用分类和社会经济状态分布映射两个下游任务中进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;CaLLiPer+在两个任务中相较于基线方法，性能提升了4%到11%。此外，POI名称的整合增强了位置检索能力，使模型能够更精确地捕捉复杂的城市概念。消融实验揭示了POI名称的互补作用以及利用预训练文本编码器进行空间表示的优势。&lt;h4&gt;结论&lt;/h4&gt;本文的研究结果表明，将细粒度语义属性和多模态学习技术相结合，有助于推动城市基础模型的发展。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces the CaLLiPer+ model, which integrates POI names and categorical labels within a multimodal contrastive learning framework to enhance the capture of structural and semantic characteristics of urban environments. The background of the study is that traditional spatial embedding methods often prioritize spatial proximity while underutilizing fine-grained contextual information from places. The purpose of the research is to address this limitation by proposing a new model, CaLLiPer+, to improve the accuracy of urban modeling. The method involves evaluating the model on two downstream tasks, land use classification and socioeconomic status distribution mapping, within a multimodal contrastive learning framework. The main findings show that CaLLiPer+ achieves consistent performance gains of 4% to 11% over baseline methods and enhances location retrieval, enabling the model to capture complex urban concepts with greater precision. Ablation studies further reveal the complementary role of POI names and the advantages of leveraging pretrained text encoders for spatial representations. Overall, the study highlights the potential of integrating fine-grained semantic attributes and multimodal learning techniques to advance the development of urban foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial representations that capture both structural and semanticcharacteristics of urban environments are essential for urban modeling.Traditional spatial embeddings often prioritize spatial proximity whileunderutilizing fine-grained contextual information from places. To address thislimitation, we introduce CaLLiPer+, an extension of the CaLLiPer model thatsystematically integrates Point-of-Interest (POI) names alongside categoricallabels within a multimodal contrastive learning framework. We evaluate itseffectiveness on two downstream tasks, land use classification andsocioeconomic status distribution mapping, demonstrating consistent performancegains of 4% to 11% over baseline methods. Additionally, we show thatincorporating POI names enhances location retrieval, enabling models to capturecomplex urban concepts with greater precision. Ablation studies further revealthe complementary role of POI names and the advantages of leveraging pretrainedtext encoders for spatial representations. Overall, our findings highlight thepotential of integrating fine-grained semantic attributes and multimodallearning techniques to advance the development of urban foundation models.</description>
      <author>example@mail.com (Junyuan Liu, Xinglei Wang, Tao Cheng)</author>
      <guid isPermaLink="false">2506.02744v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Simple, Good, Fast: Self-Supervised World Models Free of Baggage</title>
      <link>http://arxiv.org/abs/2506.02612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published as a conference paper at ICLR 2025. Code is available at  https://github.com/jrobine/sgf&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SGF，这是一种简单、良好且快速的世界模型，它使用自监督表示学习，通过帧和动作堆叠捕获短期依赖，并通过数据增强增强对模型错误的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;摘要提出了世界模型的关键组件以及不使用循环神经网络（RNNs）、转换器、离散表示和图像重建的世界模型的局限性。&lt;h4&gt;目的&lt;/h4&gt;研究SGF模型的性能和其在世界模型领域的应用潜力。&lt;h4&gt;方法&lt;/h4&gt;论文详细讨论了SGF与现有世界模型的关系，通过消融研究评估了构建模块，并在Atari 100k基准测试中通过定量比较展示了良好的性能。&lt;h4&gt;主要发现&lt;/h4&gt;SGF模型能够通过自监督学习和数据增强提高模型的鲁棒性，并在基准测试中表现出良好的性能。&lt;h4&gt;结论&lt;/h4&gt;SGF模型是一种有潜力的世界模型，能够有效地处理短期依赖并提高对模型错误的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为SGF的简单、良好且快速的世界模型，该模型利用自监督表示学习，通过帧和动作堆叠捕捉短期依赖，并通过数据增强增强对模型错误的鲁棒性。论文广泛讨论了SGF与现有世界模型的关系，通过消融研究评估了构建模块，并在Atari 100k基准测试中通过定量比较展示了良好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; What are the essential components of world models? How far do we get withworld models that are not employing RNNs, transformers, discreterepresentations, and image reconstructions? This paper introduces SGF, aSimple, Good, and Fast world model that uses self-supervised representationlearning, captures short-time dependencies through frame and action stacking,and enhances robustness against model errors through data augmentation. Weextensively discuss SGF's connections to established world models, evaluate thebuilding blocks in ablation studies, and demonstrate good performance throughquantitative comparisons on the Atari 100k benchmark.</description>
      <author>example@mail.com (Jan Robine, Marc Höftmann, Stefan Harmeling)</author>
      <guid isPermaLink="false">2506.02612v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>TalkingMachines: Real-Time Audio-Driven FaceTime-Style Video via Autoregressive Diffusion Models</title>
      <link>http://arxiv.org/abs/2506.03099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TalkingMachines的高效框架，该框架可以将预训练的视频生成模型转化为实时、音频驱动的角色动画器。&lt;h4&gt;背景&lt;/h4&gt;现有的视频生成模型无法实现实时、音频驱动的角色动画。&lt;h4&gt;目的&lt;/h4&gt;通过整合音频大型语言模型（LLM）和视频生成基础模型，实现自然对话体验。&lt;h4&gt;方法&lt;/h4&gt;（1）将预训练的SOTA图像到视频模型DiT调整为18亿参数的音频驱动的角色生成模型；（2）通过从双向教师模型到稀疏因果自回归学生模型的不对称知识蒸馏，实现无错误累积的无限视频流；（3）设计了一个高吞吐量、低延迟的推理流程，包括多个关键工程优化，如DiT和VAE解码器在不同设备上的解耦，使用CUDA流高效重叠设备间通信和计算，以及消除冗余计算以最大化帧生成吞吐量。&lt;h4&gt;主要发现&lt;/h4&gt;TalkingMachines框架能够实现实时、音频驱动的角色动画，并提供了自然对话体验。&lt;h4&gt;结论&lt;/h4&gt;TalkingMachines是一种有效的方法，可以将预训练的视频生成模型转化为实时、音频驱动的角色动画器，为用户提供更加丰富的交互体验。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we introduce TalkingMachines, an efficient framework that converts pretrained video generation models into real-time, audio-driven character animators. TalkingMachines enables natural conversational experiences by integrating an audio large language model (LLM) with our video generation foundation model. Our main contributions include: (1) We adapt a pretrained SOTA image-to-video DiT into an audio-driven avatar generation model with 18 billion parameters; (2) We enable infinite video streaming without error accumulation through asymmetric knowledge distillation from a bidirectional teacher model into a sparse causal, autoregressive student model; (3) We design a high-throughput, low-latency inference pipeline incorporating several key engineering optimizations such as: (a) disaggregation of the DiT and VAE decoder across separate devices, (b) efficient overlap of inter-device communication and computation using CUDA streams, (c) elimination of redundant recomputations to maximize frame-generation throughput. Please see demo videos here - https://aaxwaz.github.io/TalkingMachines/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present TalkingMachines -- an efficient framework thattransforms pretrained video generation models into real-time, audio-drivencharacter animators. TalkingMachines enables natural conversational experiencesby integrating an audio large language model (LLM) with our video generationfoundation model. Our primary contributions include: (1) We adapt a pretrainedSOTA image-to-video DiT into an audio-driven avatar generation model of 18billion parameters; (2) We enable infinite video streaming without erroraccumulation through asymmetric knowledge distillation from a bidirectionalteacher model into a sparse causal, autoregressive student model; (3) We designa high-throughput, low-latency inference pipeline incorporating several keyengineering optimizations such as: (a) disaggregation of the DiT and VAEdecoder across separate devices, (b) efficient overlap of inter-devicecommunication and computation using CUDA streams, (c) elimination of redundantrecomputations to maximize frame-generation throughput. Please see demo videoshere - https://aaxwaz.github.io/TalkingMachines/</description>
      <author>example@mail.com (Chetwin Low, Weimin Wang)</author>
      <guid isPermaLink="false">2506.03099v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Joint Optimization based on Two-phase GNN in RIS- and DF-assisted MISO Systems with Fine-grained Rate Demands</title>
      <link>http://arxiv.org/abs/2506.02642v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 Pages, 9 figures, accepted by IEEE TRANSACTIONS ON WIRELESS  COMMUNICATIONS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于可重构智能表面（RIS）和半双工解码转发（DF）中继的联合优化模型，以优化通信系统中的无线信号传播。&lt;h4&gt;背景&lt;/h4&gt;用户通常具有不同的速率需求，并且根据需求被分为不同的组。这导致在最大化速率和满足精细速率需求之间存在权衡，以及当最大化总速率时，在组间竞争和组内合作之间也存在权衡。&lt;h4&gt;目的&lt;/h4&gt;针对传统方法往往忽略这两个权衡的问题，提出了一种新的联合优化模型。&lt;h4&gt;方法&lt;/h4&gt;该模型针对一个由多个天线组成的基站（BS）通过多个RIS和DF中继为具有精细速率需求的分组用户提供服务的MISO系统进行优化。设计了一个新的损失函数，不仅可以优化所有组的总速率，还可以通过修改惩罚参数来调整精细速率需求的满意度。此外，还提出了一种基于两阶段图神经网络（GNN）的方法，该方法输入信道状态信息（CSI），同时自主地学习有效的相位偏移、波束成形和中继选择。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法显著提高了系统性能。&lt;h4&gt;结论&lt;/h4&gt;该研究为优化通信系统中的无线信号传播提供了一种新的有效方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel joint optimization model for a communication system that leverages Reconfigurable Intelligent Surfaces (RIS) and half-duplex decoded and forwarded (DF) relays to optimize wireless signal propagation. Considering that users typically have different rate demands and are clustered into groups based on their requirements, leading to a trade-off between maximizing the rate and satisfying fine-grained rate demands, as well as a trade-off between inter-group competition and intra-group cooperation when maximizing the sum rate, the traditional approaches often overlook the joint optimization encompassing both trade-offs. To address this issue, the proposed model optimizes a multiple-input single-output (MISO) system with a base station (BS) equipped with multiple antennas transmitting data via multiple RISs and DF relays to serve grouped users with fine-grained rate demands. A new loss function is designed to not only optimize the sum rate of all groups but also adjust the satisfaction ratio of fine-grained rate demands by modifying the penalty parameter. Furthermore, a two-phase graph neural network (GNN) based approach is proposed that inputs channel state information (CSI) to simultaneously and autonomously learn efficient phase shifts, beamforming, and relay selection. The experimental results demonstrate that the proposed method significantly improves the system performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconfigurable intelligent Surfaces (RIS) and half-duplex decoded andforwarded (DF) relays can collaborate to optimize wireless signal propagationin communication systems. Users typically have different rate demands and areclustered into groups in practice based on their requirements, where the formerresults in the trade-off between maximizing the rate and satisfyingfine-grained rate demands, while the latter causes a trade-off betweeninter-group competition and intra-group cooperation when maximizing the sumrate. However, traditional approaches often overlook the joint optimizationencompassing both of these trade-offs, disregarding potential optimal solutionsand leaving some users even consistently at low date rates. To address thisissue, we propose a novel joint optimization model for a RIS- and DF-assistedmultiple-input single-output (MISO) system where a base station (BS) is withmultiple antennas transmits data by multiple RISs and DF relays to servegrouped users with fine-grained rate demands. We design a new loss function tonot only optimize the sum rate of all groups but also adjust the satisfactionratio of fine-grained rate demands by modifying the penalty parameter. Wefurther propose a two-phase graph neural network (GNN) based approach thatinputs channel state information (CSI) to simultaneously and autonomously learnefficient phase shifts, beamforming, and relay selection. The experimentalresults demonstrate that the proposed method significantly improves systemperformance.</description>
      <author>example@mail.com (Huijun Tang, Jieling Zhang, Zhidong Zhao, Huaming Wu, Hongjian Sun, Pengfei Jiao)</author>
      <guid isPermaLink="false">2506.02642v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Weak Supervision for Real World Graphs</title>
      <link>http://arxiv.org/abs/2506.02451v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了WSNET，一种用于弱监督图对比学习的框架，通过利用弱信号来指导鲁棒表示学习，解决了节点分类在现实世界图中的标签稀缺和噪声问题。&lt;h4&gt;背景&lt;/h4&gt;节点分类在现实世界图中，特别是在如人口贩卖检测和虚假信息监控等高风险领域，常常面临标签稀缺和噪声的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来利用图中的弱信号，以指导鲁棒表示学习，从而提高节点分类的准确性。&lt;h4&gt;方法&lt;/h4&gt;WSNET框架通过结合图结构、节点特征和多个噪声监督源，利用定制的对比目标来实现弱标签数据的集成。&lt;h4&gt;主要发现&lt;/h4&gt;在三个现实世界数据集和受控噪声的合成基准测试中，WSNET在F1分数上比最先进的对比学习和噪声标签学习方法提高了高达15%。&lt;h4&gt;结论&lt;/h4&gt;该研究结果强调了在弱监督下对比学习的有效性，以及在基于图的设置中利用不完整标签的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在现实世界图中进行节点分类常常受到标签稀缺和噪声的困扰，尤其是在如人口贩卖检测和虚假信息监控等高风险领域。虽然直接监督有限，但这些图通常包含可以指导学习的弱信号、噪声或间接线索。我们提出了WSNET，一种新颖的弱监督图对比学习框架，它利用这些弱信号来指导鲁棒的表示学习。WSNET通过对比目标集成图结构、节点特征和多个噪声监督源，适用于弱标签数据。在三个现实世界数据集和受控噪声的合成基准测试中，WSNET在F1分数上始终优于最先进的对比学习和噪声标签学习方法，最高提高了15%。我们的结果突出了弱监督下对比学习的有效性以及在不完美的标签中利用基于图设置的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Node classification in real world graphs often suffers from label scarcityand noise, especially in high stakes domains like human trafficking detectionand misinformation monitoring. While direct supervision is limited, such graphsfrequently contain weak signals, noisy or indirect cues, that can still informlearning. We propose WSNET, a novel weakly supervised graph contrastivelearning framework that leverages these weak signals to guide robustrepresentation learning. WSNET integrates graph structure, node features, andmultiple noisy supervision sources through a contrastive objective tailored forweakly labeled data. Across three real world datasets and synthetic benchmarkswith controlled noise, WSNET consistently outperforms state of the artcontrastive and noisy label learning methods by up to 15% in F1 score. Ourresults highlight the effectiveness of contrastive learning under weaksupervision and the promise of exploiting imperfect labels in graph basedsettings.</description>
      <author>example@mail.com (Pratheeksha Nair, Reihaneh Rabbany)</author>
      <guid isPermaLink="false">2506.02451v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>UTCS: Effective Unsupervised Temporal Community Search with Pre-training of Temporal Dynamics and Subgraph Knowledge</title>
      <link>http://arxiv.org/abs/2506.02784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGIR'25 short paper track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对时间图中的社区搜索问题，提出了一种无监督时间社区搜索方法，通过预训练时间动态和子图知识模型来解决传统方法需要预定义子图结构和基于学习的方法难以捕捉时间交互信息的问题。&lt;h4&gt;背景&lt;/h4&gt;在许多实际应用中，实体之间的关系可以建模为时间图，其中每条边都有一个时间戳表示交互时间。社区搜索（CS）是图分析中的一个基本问题，但在时间图中存在两个主要局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的无监督时间社区搜索方法，以解决传统方法和基于学习的方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;该方法包含两个关键阶段：离线预训练和在线搜索。在离线预训练阶段，引入多个学习目标以促进无监督学习环境下的预训练过程。在线搜索阶段，通过预训练的节点表示和一种新颖的评分机制来确定候选子图和社区成员。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在五个真实世界数据集上表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效解决时间图中的社区搜索问题，为相关研究提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;In many real-world applications, the evolving relationships between entities can be modeled as temporal graphs, where each edge has a timestamp representing the interaction time. As a fundamental problem in graph analysis, community search (CS) in temporal graphs has received growing attention but exhibits two major limitations: (1) Traditional methods typically require predefined subgraph structures, which are not always known in advance. (2) Learning-based methods struggle to capture temporal interaction information. To fill this research gap, in this paper, we propose an effective Unsupervised Temporal Community Search with pre-training of temporal dynamics and subgraph knowledge model (model). The model contains two key stages: offline pre-training and online search. In the first stage, we introduce multiple learning objectives to facilitate the pre-training process in the unsupervised learning setting. In the second stage, we identify a candidate subgraph and compute community scores using the pre-trained node representations and a novel scoring mechanism to determine the final community members. Experiments on five real-world datasets demonstrate the effectiveness.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In many real-world applications, the evolving relationships between entitiescan be modeled as temporal graphs, where each edge has a timestamp representingthe interaction time.  As a fundamental problem in graph analysis, {\it community search (CS)} intemporal graphs has received growing attention but exhibits two majorlimitations: (1) Traditional methods typically require predefined subgraphstructures, which are not always known in advance. (2) Learning-based methodsstruggle to capture temporal interaction information. To fill this researchgap, in this paper, we propose an effective \textbf{U}nsupervised\textbf{T}emporal \textbf{C}ommunity \textbf{S}earch with pre-training oftemporal dynamics and subgraph knowledge model (\textbf{\model}).\model~contains two key stages: offline pre-training and online search. In thefirst stage, we introduce multiple learning objectives to facilitate thepre-training process in the unsupervised learning setting. In the second stage,we identify a candidate subgraph and compute community scores using thepre-trained node representations and a novel scoring mechanism to determine thefinal community members. Experiments on five real-world datasets demonstratethe effectiveness.</description>
      <author>example@mail.com (Yue Zhang, Yankai Chen, Yingli Zhou, Yucan Guo, Xiaolin Han, Chenhao Ma)</author>
      <guid isPermaLink="false">2506.02784v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>HGOT: Self-supervised Heterogeneous Graph Neural Network with Optimal Transport</title>
      <link>http://arxiv.org/abs/2506.02619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The paper has 9 pages of text and 13 pages in total (including  acknowledgments, impact statement, references, and appendix), with 6 figures  and 2 tables. This paper has been accepted by ICML 2025 conference and this  is a final version of the manuscript submitted to the conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的无图增强的自监督异构图神经网络（HGOT），通过最优传输机制缓解了正负样本采样的繁琐过程，在多个下游任务中取得了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;异构图神经网络（HGNNs）在处理异构信息网络方面表现出色，而自监督学习在无标签情况下具有巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;设计一种无需图增强策略的自监督学习方法，以提高异构图神经网络在下游任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;HGOT利用最优传输机制，设计了一种聚合视图（中心视图）来整合不同元路径（分支视图）中的语义信息，并引入最优传输计划以识别分支视图中的语义与中心视图之间的传输关系。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界数据集上的实验表明，HGOT在节点分类任务上平均比最先进的方法提高了超过6%的准确率。&lt;h4&gt;结论&lt;/h4&gt;HGOT模型在多种下游任务中实现了最先进的性能，特别是在节点分类任务上表现出显著优势。&lt;h4&gt;翻译&lt;/h4&gt;Heterogeneous Graph Neural Networks (HGNNs), have demonstrated excellent capabilities in processing heterogeneous information networks. Self-supervised learning on heterogeneous graphs, especially contrastive self-supervised strategy, shows great potential when there are no labels. However, this approach requires the use of carefully designed graph augmentation strategies and the selection of positive and negative samples. Determining the exact level of similarity between sample pairs is non-trivial. To solve this problem, we propose a novel self-supervised Heterogeneous graph neural network with Optimal Transport (HGOT) method which is designed to facilitate self-supervised learning for heterogeneous graphs without graph augmentation strategies. Different from traditional contrastive self-supervised learning, HGOT employs the optimal transport mechanism to relieve the laborious sampling process of positive and negative samples. Specifically, we design an aggregating view (central view) to integrate the semantic information contained in the views represented by different meta-paths (branch views). Then, we introduce an optimal transport plan to identify the transport relationship between these semantics contained in the branch view and the central view. This allows the optimal transport plan between graphs to align with the representations, forcing the encoder to learn node representations that are more similar to the graph space and of higher quality. Extensive experiments on four real-world datasets demonstrate that our proposed HGOT model can achieve state-of-the-art performance on various downstream tasks. In particular, in the node classification task, HGOT achieves an average of more than 6% improvement in accuracy compared with state-of-the-art methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterogeneous Graph Neural Networks (HGNNs), have demonstrated excellentcapabilities in processing heterogeneous information networks. Self-supervisedlearning on heterogeneous graphs, especially contrastive self-supervisedstrategy, shows great potential when there are no labels. However, thisapproach requires the use of carefully designed graph augmentation strategiesand the selection of positive and negative samples. Determining the exact levelof similarity between sample pairs is non-trivial.To solve this problem, wepropose a novel self-supervised Heterogeneous graph neural network with OptimalTransport (HGOT) method which is designed to facilitate self-supervisedlearning for heterogeneous graphs without graph augmentation strategies.Different from traditional contrastive self-supervised learning, HGOT employsthe optimal transport mechanism to relieve the laborious sampling process ofpositive and negative samples. Specifically, we design an aggregating view(central view) to integrate the semantic information contained in the viewsrepresented by different meta-paths (branch views). Then, we introduce anoptimal transport plan to identify the transport relationship between thesemantics contained in the branch view and the central view. This allows theoptimal transport plan between graphs to align with the representations,forcing the encoder to learn node representations that are more similar to thegraph space and of higher quality. Extensive experiments on four real-worlddatasets demonstrate that our proposed HGOT model can achieve state-of-the-artperformance on various downstream tasks. In particular, in the nodeclassification task, HGOT achieves an average of more than 6% improvement inaccuracy compared with state-of-the-art methods.</description>
      <author>example@mail.com (Yanbei Liu, Chongxu Wang, Zhitao Xiao, Lei Geng, Yanwei Pang, Xiao Wang)</author>
      <guid isPermaLink="false">2506.02619v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Learning Treatment Representations for Downstream Instrumental Variable Regression</title>
      <link>http://arxiv.org/abs/2506.02200v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法来构建治疗表示，通过在表示学习过程中显式地纳入工具变量，以解决传统工具变量估计方法在处理高维无结构治疗变量时的限制。&lt;h4&gt;背景&lt;/h4&gt;传统的工具变量估计方法受限于可用的工具变量数量，难以处理高维和无结构的治疗变量，如医院中患者治疗路径的描述。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以解决高维内生变量和有限工具变量的问题，并确保工具变量表示的学习过程中不会产生重大遗漏变量偏差。&lt;h4&gt;方法&lt;/h4&gt;在表示学习过程中显式地纳入工具变量，提供了一种处理高维内生变量的框架，并通过实验验证了该方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法优于传统两阶段方法，后者在降维时不包含工具变量信息，能够优化结果预测的方向。&lt;h4&gt;结论&lt;/h4&gt;通过在表示学习过程中显式地纳入工具变量，可以构建更准确的治疗表示，从而提高高维内生变量分析的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional instrumental variable (IV) estimators face a fundamentalconstraint: they can only accommodate as many endogenous treatment variables asavailable instruments. This limitation becomes particularly challenging insettings where the treatment is presented in a high-dimensional andunstructured manner (e.g. descriptions of patient treatment pathways in ahospital). In such settings, researchers typically resort to applyingunsupervised dimension reduction techniques to learn a low-dimensionaltreatment representation prior to implementing IV regression analysis. We showthat such methods can suffer from substantial omitted variable bias due toimplicit regularization in the representation learning step. We propose a novelapproach to construct treatment representations by explicitly incorporatinginstrumental variables during the representation learning process. Our approachprovides a framework for handling high-dimensional endogenous variables withlimited instruments. We demonstrate both theoretically and empirically thatfitting IV models on these instrument-informed representations ensuresidentification of directions that optimize outcome prediction. Our experimentsshow that our proposed methodology improves upon the conventional two-stageapproaches that perform dimension reduction without incorporating instrumentinformation.</description>
      <author>example@mail.com (Shiangyi Lin, Hui Lan, Vasilis Syrgkanis)</author>
      <guid isPermaLink="false">2506.02200v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Self-attention U-Net decoder for toric codes</title>
      <link>http://arxiv.org/abs/2506.02734v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages; 12 figures;&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种适用于toric码的自注意力U-Net量子解码器（SU-NetQD），在电路级噪声环境中优于最小权重完美匹配解码器，提高了量子纠错码和量子计算的实用性。&lt;h4&gt;背景&lt;/h4&gt;在NISQ时代，量子纠错是实现通用量子计算的重要瓶颈，而量子错误纠正码中的稳定子码是其中最常见的一种。高效可扩展的解码器是量子错误纠正码应用的关键。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的量子解码器，以解决toric码在量子纠错中的解码问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种自注意力U-Net量子解码器（SU-NetQD），该解码器结合了低级解码器和高级解码器，并利用迁移学习机制。&lt;h4&gt;主要发现&lt;/h4&gt;SU-NetQD在电路级噪声环境中优于最小权重完美匹配解码器，实现了比MWPM更低的逻辑错误率，并发现随着噪声偏差的增加，码阈值呈上升趋势。在极端偏置的噪声环境中，达到0.231的高阈值。&lt;h4&gt;结论&lt;/h4&gt;SU-NetQD是一个高精度解码器的关键创新，提供了量子噪声分析的实用工具，促进了量子纠错码和量子计算的实用性。&lt;h4&gt;翻译&lt;/h4&gt;In the NISQ era, one of the most important bottlenecks for the realization of universal quantum computation is error correction. Stabiliser code is the most recognizable type of quantum error correction code. A scalable efficient decoder is most desired for the application of the quantum error correction codes. In this work, we propose a self-attention U-Net quantum decoder (SU-NetQD) for toric code, which outperforms the minimum weight perfect matching decoder, especially in the circuit level noise environments. Specifically, with our SU-NetQD, we achieve lower logical error rates compared with MWPM and discover an increased trend of code threshold as the increase of noise bias. We obtain a high threshold of 0.231 for the extremely biased noise environment. The combination of low-level decoder and high-level decoder is the key innovation for the high accuracy of our decoder. With transfer learning mechanics, our decoder is scalable for cases with different code distances. Our decoder provides a practical tool for quantum noise analysis and promotes the practicality of quantum error correction codes and quantum computing.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/xiazhuo/SUNetQD&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the NISQ era, one of the most important bottlenecks for the realization ofuniversal quantum computation is error correction. Stabiliser code is the mostrecognizable type of quantum error correction code. A scalable efficientdecoder is most desired for the application of the quantum error correctioncodes. In this work, we propose a self-attention U-Net quantum decoder(SU-NetQD) for toric code, which outperforms the minimum weight perfectmatching decoder, especially in the circuit level noise environments.Specifically, with our SU-NetQD, we achieve lower logical error rates comparedwith MWPM and discover an increased trend of code threshold as the increase ofnoise bias. We obtain a high threshold of 0.231 for the extremely biased noiseenvironment. The combination of low-level decoder and high-level decoder is thekey innovation for the high accuracy of our decoder. With transfer learningmechanics, our decoder is scalable for cases with different code distances. Ourdecoder provides a practical tool for quantum noise analysis and promotes thepracticality of quantum error correction codes and quantum computing.</description>
      <author>example@mail.com (Wei-Wei Zhang, Zhuo Xia, Wei Zhao, Wei Pan, Haobin Shi)</author>
      <guid isPermaLink="false">2506.02734v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MotionRAG-Diff: A Retrieval-Augmented Diffusion Framework for Long-Term Music-to-Dance Generation</title>
      <link>http://arxiv.org/abs/2506.02661v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MotionRAG-Diff的混合框架，用于生成长期、连贯且逼真的音乐条件舞蹈序列，解决了现有方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;生成长期、连贯且逼真的音乐条件舞蹈序列是人体运动合成的挑战性任务。现有方法存在关键局限性：运动图方法依赖于固定的模板库，限制了创造性生成；扩散模型虽然能够产生新颖的动作，但通常缺乏时间一致性和音乐对齐。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一种名为MotionRAG-Diff的混合框架，以实现高质量、音乐一致的舞蹈生成，适用于任意长期音乐输入。&lt;h4&gt;方法&lt;/h4&gt;该方法引入了三项核心创新：(1) 一种跨模态对比学习架构，在共享潜在空间中对异构的音乐和舞蹈表示进行对齐，建立无配对数据的无监督语义对应；(2) 一种优化的运动图系统，用于高效检索和无缝连接运动片段，确保长序列中的真实性和时间一致性；(3) 一种多条件扩散模型，联合条件原始音乐信号和对比特征，以增强运动质量和全局同步。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，MotionRAG-Diff在运动质量、多样性和音乐-运动同步精度方面达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;这项工作通过结合基于检索的模板保真度与基于扩散的创造性增强，为音乐驱动的舞蹈生成建立了一种新的范式。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成长期、连贯、逼真的音乐条件舞蹈序列仍然是人体运动合成中的一个挑战性任务。现有方法存在关键局限性：运动图方法依赖于固定的模板库，限制了创造性生成；扩散模型虽然能够产生新颖的动作，但通常缺乏时间一致性和音乐对齐。为了解决这些挑战，我们提出了一种名为MotionRAG-Diff的混合框架，该框架整合了检索增强生成（RAG）和基于扩散的细化，以实现高质量、音乐一致的舞蹈生成，适用于任意长期音乐输入。我们的方法引入了三项核心创新：(1) 一种跨模态对比学习架构，在共享潜在空间中对异构的音乐和舞蹈表示进行对齐，建立无配对数据的无监督语义对应；(2) 一种优化的运动图系统，用于高效检索和无缝连接运动片段，确保长序列中的真实性和时间一致性；(3) 一种多条件扩散模型，联合条件原始音乐信号和对比特征，以增强运动质量和全局同步。广泛的实验表明，MotionRAG-Diff在运动质量、多样性和音乐-运动同步精度方面达到了最先进的性能。这项工作通过结合基于检索的模板保真度与基于扩散的创造性增强，为音乐驱动的舞蹈生成建立了一种新的范式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating long-term, coherent, and realistic music-conditioned dancesequences remains a challenging task in human motion synthesis. Existingapproaches exhibit critical limitations: motion graph methods rely on fixedtemplate libraries, restricting creative generation; diffusion models, whilecapable of producing novel motions, often lack temporal coherence and musicalalignment. To address these challenges, we propose $\textbf{MotionRAG-Diff}$, ahybrid framework that integrates Retrieval-Augmented Generation (RAG) withdiffusion-based refinement to enable high-quality, musically coherent dancegeneration for arbitrary long-term music inputs. Our method introduces threecore innovations: (1) A cross-modal contrastive learning architecture thataligns heterogeneous music and dance representations in a shared latent space,establishing unsupervised semantic correspondence without paired data; (2) Anoptimized motion graph system for efficient retrieval and seamlessconcatenation of motion segments, ensuring realism and temporal coherenceacross long sequences; (3) A multi-condition diffusion model that jointlyconditions on raw music signals and contrastive features to enhance motionquality and global synchronization. Extensive experiments demonstrate thatMotionRAG-Diff achieves state-of-the-art performance in motion quality,diversity, and music-motion synchronization accuracy. This work establishes anew paradigm for music-driven dance generation by synergizing retrieval-basedtemplate fidelity with diffusion-based creative enhancement.</description>
      <author>example@mail.com (Mingyang Huang, Peng Zhang, Bang Zhang)</author>
      <guid isPermaLink="false">2506.02661v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>HIEGNet: A Heterogenous Graph Neural Network Including the Immune Environment in Glomeruli Classification</title>
      <link>http://arxiv.org/abs/2506.02542v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for poster presentation at MIDL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HIEGNet的异构图神经网络架构，用于肾小球健康分类，并在肾移植患者的全切片图像数据集上进行了测试。&lt;h4&gt;背景&lt;/h4&gt;GNNs在组织病理学领域表现出色，但在肾小球健康分类任务上尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来分类肾小球健康，特别是在识别节点、边及其特征方面。&lt;h4&gt;方法&lt;/h4&gt;使用传统的计算机视觉技术和机器学习技术来识别节点、边和相应的特征，构建异构图，并提出HIEGNet架构进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，HIEGNet在肾小球分类任务中优于多个基线模型，并且在所有基线模型中具有最佳的泛化性能。&lt;h4&gt;结论&lt;/h4&gt;HIEGNet能够考虑每个肾小球的免疫环境，并在肾小球健康分类任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have recently been found to excel in histopathology. However, an important histopathological task, where GNNs have not been extensively explored, is the classification of glomeruli health as an important indicator in nephropathology. This task presents unique difficulties, particularly for the graph construction, i.e., the identification of nodes, edges, and informative features. In this work, we propose a pipeline composed of different traditional and machine learning-based computer vision techniques to identify nodes, edges, and their corresponding features to form a heterogeneous graph. We then proceed to propose a novel heterogeneous GNN architecture for glomeruli classification, called HIEGNet, that integrates both glomeruli and their surrounding immune cells. Hence, HIEGNet is able to consider the immune environment of each glomerulus in its classification. Our HIEGNet was trained and tested on a dataset of Whole Slide Images from kidney transplant patients. Experimental results demonstrate that HIEGNet outperforms several baseline models and generalises best between patients among all baseline models. Our implementation is publicly available at https://github.com/nklsKrmnn/HIEGNet.git.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have recently been found to excel inhistopathology. However, an important histopathological task, where GNNs havenot been extensively explored, is the classification of glomeruli health as animportant indicator in nephropathology. This task presents unique difficulties,particularly for the graph construction, i.e., the identification of nodes,edges, and informative features. In this work, we propose a pipeline composedof different traditional and machine learning-based computer vision techniquesto identify nodes, edges, and their corresponding features to form aheterogeneous graph. We then proceed to propose a novel heterogeneous GNNarchitecture for glomeruli classification, called HIEGNet, that integrates bothglomeruli and their surrounding immune cells. Hence, HIEGNet is able toconsider the immune environment of each glomerulus in its classification. OurHIEGNet was trained and tested on a dataset of Whole Slide Images from kidneytransplant patients. Experimental results demonstrate that HIEGNet outperformsseveral baseline models and generalises best between patients among allbaseline models. Our implementation is publicly available athttps://github.com/nklsKrmnn/HIEGNet.git.</description>
      <author>example@mail.com (Niklas Kormann, Masoud Ramuz, Zeeshan Nisar, Nadine S. Schaadt, Hendrik Annuth, Benjamin Doerr, Friedrich Feuerhake, Thomas Lampert, Johannes F. Lutzeyer)</author>
      <guid isPermaLink="false">2506.02542v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MLaGA: Multimodal Large Language and Graph Assistant</title>
      <link>http://arxiv.org/abs/2506.02568v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MLaGA的多模态大语言和图助手模型，旨在扩展大型语言模型在处理复杂图结构和多模态属性推理方面的能力。&lt;h4&gt;背景&lt;/h4&gt;尽管大型语言模型在文本丰富的图数据分析方面表现出显著的效果，但它们在多模态图上的应用还未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;旨在解决多模态图在现实场景中的广泛应用与其在现有方法中的不足。&lt;h4&gt;方法&lt;/h4&gt;设计了一个结构感知的多模态编码器，通过联合图预训练目标将文本和视觉属性对齐到一个统一的空间中，并实现了一个多模态指令调整方法，通过轻量级投影将多模态特征和图结构整合到LLM中。&lt;h4&gt;主要发现&lt;/h4&gt;MLaGA在多个数据集上的实验表明，与领先的基线方法相比，它在各种图学习任务中实现了优越的性能，无论是监督学习还是迁移学习场景。&lt;h4&gt;结论&lt;/h4&gt;MLaGA能够有效提升大型语言模型在多模态图数据分析方面的能力，为解决现实世界中的多模态图问题提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have demonstrated substantial efficacy inadvancing graph-structured data analysis. Prevailing LLM-based graph methodsexcel in adapting LLMs to text-rich graphs, wherein node attributes are textdescriptions. However, their applications to multimodal graphs--where nodes areassociated with diverse attribute types, such as texts and images--remainunderexplored, despite their ubiquity in real-world scenarios. To bridge thegap, we introduce the Multimodal Large Language and Graph Assistant (MLaGA), aninnovative model that adeptly extends LLM capabilities to facilitate reasoningover complex graph structures and multimodal attributes. We first design astructure-aware multimodal encoder to align textual and visual attributeswithin a unified space through a joint graph pre-training objective.Subsequently, we implement a multimodal instruction-tuning approach toseamlessly integrate multimodal features and graph structures into the LLMthrough lightweight projectors. Extensive experiments across multiple datasetsdemonstrate the effectiveness of MLaGA compared to leading baseline methods,achieving superior performance in diverse graph learning tasks under bothsupervised and transfer learning scenarios.</description>
      <author>example@mail.com (Dongzhe Fan, Yi Fang, Jiajin Liu, Djellel Difallah, Qiaoyu Tan)</author>
      <guid isPermaLink="false">2506.02568v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Descriptive History Representations: Learning Representations by Answering Questions</title>
      <link>http://arxiv.org/abs/2506.02125v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于部分可观察环境的有效决策方法，即描述性历史表示（DHRs），通过压缩长交互历史以提供信息化的表示。该方法在用户建模任务中得到了验证，可以生成可解释的文本用户档案，用于预测用户的行为。&lt;h4&gt;背景&lt;/h4&gt;在部分可观察环境中，有效决策需要将长交互历史压缩成信息化的表示。&lt;h4&gt;目的&lt;/h4&gt;提出描述性历史表示（DHRs），以优化控制并提供一种结构化的方式来总结历史。&lt;h4&gt;方法&lt;/h4&gt;设计了一个多智能体学习框架，包括表示、决策和提问组件，并使用联合目标进行优化，以平衡奖励最大化与表示回答信息性问题的能力。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在用户建模任务中有效，能够生成足够的统计数据，预测用户基于偏好的行为。&lt;h4&gt;结论&lt;/h4&gt;DHRs可以有效地捕捉历史细节和预测结构，为有效决策提供支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective decision making in partially observable environments requirescompressing long interaction histories into informative representations. Weintroduce Descriptive History Representations (DHRs): sufficient statisticscharacterized by their capacity to answer relevant questions about pastinteractions and potential future outcomes. DHRs focus on capturing theinformation necessary to address task-relevant queries, providing a structuredway to summarize a history for optimal control. We propose a multi-agentlearning framework, involving representation, decision, and question-askingcomponents, optimized using a joint objective that balances reward maximizationwith the representation's ability to answer informative questions. This yieldsrepresentations that capture the salient historical details and predictivestructures needed for effective decision making. We validate our approach onuser modeling tasks with public movie and shopping datasets, generatinginterpretable textual user profiles which serve as sufficient statistics forpredicting preference-driven behavior of users.</description>
      <author>example@mail.com (Guy Tennenholtz, Jihwan Jeong, Chih-Wei Hsu, Yinlam Chow, Craig Boutilier)</author>
      <guid isPermaLink="false">2506.02125v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Towards Geometry Problem Solving in the Large Model Era: A Survey</title>
      <link>http://arxiv.org/abs/2506.02690v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8pages, 4 figures, conference submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了几何问题解决（GPS）在人工智能领域的进展，探讨了其在教育、计算机辅助设计和计算图形学中的应用。&lt;h4&gt;背景&lt;/h4&gt;尽管GPS在教育、设计等领域具有重要意义，但由于需要空间理解和严谨的逻辑推理，自动化GPS仍具挑战性。&lt;h4&gt;目的&lt;/h4&gt;系统性地总结了GPS的进展，并提出了一个统一的分析范式，以指导未来研究向人类水平的几何推理发展。&lt;h4&gt;方法&lt;/h4&gt;通过三个核心维度：基准构建、文本和图表解析、推理范式来综述GPS的进展。&lt;h4&gt;主要发现&lt;/h4&gt;近年来，大型模型在SAT级别问题上的突破显著，但该领域在方法、基准和评估框架上仍存在碎片化。&lt;h4&gt;结论&lt;/h4&gt;提出了统一的解析范式，评估了当前局限性，并确定了未来研究的新机遇，包括自动基准生成和可解释的神经符号集成。&lt;h4&gt;翻译&lt;/h4&gt;摘要：几何问题解决（GPS）代表人工智能的一个关键前沿，在教育、计算机辅助设计和计算图形学等领域具有深远的应用。尽管其意义重大，但由于对空间理解和严谨逻辑推理的双重需求，自动化GPS仍然具有挑战性。最近，大型模型的发展使SAT级别问题的突破成为可能，但该领域在方法、基准和评估框架上仍然存在碎片化。本文通过三个核心维度系统地综合了GPS的进展：（1）基准构建，（2）文本和图表解析，（3）推理范式。我们进一步提出了一种统一的分析范式，评估了当前的局限性，并确定了未来研究的新机遇，包括自动化基准生成和可解释的神经符号集成。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometry problem solving (GPS) represents a critical frontier in artificialintelligence, with profound applications in education, computer-aided design,and computational graphics. Despite its significance, automating GPS remainschallenging due to the dual demands of spatial understanding and rigorouslogical reasoning. Recent advances in large models have enabled notablebreakthroughs, particularly for SAT-level problems, yet the field remainsfragmented across methodologies, benchmarks, and evaluation frameworks. Thissurvey systematically synthesizes GPS advancements through three coredimensions: (1) benchmark construction, (2) textual and diagrammatic parsing,and (3) reasoning paradigms. We further propose a unified analytical paradigm,assess current limitations, and identify emerging opportunities to guide futureresearch toward human-level geometric reasoning, including automated benchmarkgeneration and interpretable neuro-symbolic integration.</description>
      <author>example@mail.com (Yurui Zhao, Xiang Wang, Jiahong Liu, Irwin King, Zhitao Huang)</author>
      <guid isPermaLink="false">2506.02690v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Contrast &amp; Compress: Learning Lightweight Embeddings for Short Trajectories</title>
      <link>http://arxiv.org/abs/2506.02571v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted for peer review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，通过Transformer编码器和对比三元组损失学习短轨迹的固定维度嵌入，以提高运动预测和自主导航等下游应用的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常依赖于计算密集型的启发式算法或缺乏可解释性和可控性的潜在锚点表示。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够高效且准确地检索语义和方向上相似的短轨迹的新框架。&lt;h4&gt;方法&lt;/h4&gt;提出了一种利用Transformer编码器和对比三元组损失学习固定维度嵌入的方法，并分析了余弦和基于FFT的相似性指标在对比学习范式中的影响，以捕捉短期操纵的特征方向意图。&lt;h4&gt;主要发现&lt;/h4&gt;在Argoverse 2数据集上的实验表明，由余弦相似性目标形成的嵌入在语义和方向属性上的轨迹聚类表现优于基于FFT的基线，并且在检索任务中表现出色。紧凑的Transformer架构即使在低维嵌入（例如16维，但质地上降至4维）的情况下，也能在检索性能和计算开销之间实现令人满意的平衡。&lt;h4&gt;结论&lt;/h4&gt;该框架提供了紧凑、语义上有意义且高效的轨迹数据表示，为启发式相似度度量提供了一种稳健的替代方案，并为更透明和可控的运动预测流程铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;The ability to retrieve semantically and directionally similar short-range trajectories with both accuracy and efficiency is foundational for downstream applications such as motion forecasting and autonomous navigation. However, prevailing approaches often depend on computationally intensive heuristics or latent anchor representations that lack interpretability and controllability. In this work, we propose a novel framework for learning fixed-dimensional embeddings for short trajectories by leveraging a Transformer encoder trained with a contrastive triplet loss that emphasize the importance of discriminative feature spaces for trajectory data. We analyze the influence of Cosine and FFT-based similarity metrics within the contrastive learning paradigm, with a focus on capturing the nuanced directional intent that characterizes short-term maneuvers. Our empirical evaluation on the Argoverse 2 dataset demonstrates that embeddings shaped by Cosine similarity objectives yield superior clustering of trajectories by both semantic and directional attributes, outperforming FFT-based baselines in retrieval tasks. Notably, we show that compact Transformer architectures, even with low-dimensional embeddings (e.g., 16 dimensions, but qualitatively down to 4), achieve a compelling balance between retrieval performance (minADE, minFDE) and computational overhead, aligning with the growing demand for scalable and interpretable motion priors in real-time systems. The resulting embeddings provide a compact, semantically meaningful, and efficient representation of trajectory data, offering a robust alternative to heuristic similarity measures and paving the way for more transparent and controllable motion forecasting pipelines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to retrieve semantically and directionally similar short-rangetrajectories with both accuracy and efficiency is foundational for downstreamapplications such as motion forecasting and autonomous navigation. However,prevailing approaches often depend on computationally intensive heuristics orlatent anchor representations that lack interpretability and controllability.In this work, we propose a novel framework for learning fixed-dimensionalembeddings for short trajectories by leveraging a Transformer encoder trainedwith a contrastive triplet loss that emphasize the importance of discriminativefeature spaces for trajectory data. We analyze the influence of Cosine andFFT-based similarity metrics within the contrastive learning paradigm, with afocus on capturing the nuanced directional intent that characterizes short-termmaneuvers. Our empirical evaluation on the Argoverse 2 dataset demonstratesthat embeddings shaped by Cosine similarity objectives yield superiorclustering of trajectories by both semantic and directional attributes,outperforming FFT-based baselines in retrieval tasks. Notably, we show thatcompact Transformer architectures, even with low-dimensional embeddings (e.g.,16 dimensions, but qualitatively down to 4), achieve a compelling balancebetween retrieval performance (minADE, minFDE) and computational overhead,aligning with the growing demand for scalable and interpretable motion priorsin real-time systems. The resulting embeddings provide a compact, semanticallymeaningful, and efficient representation of trajectory data, offering a robustalternative to heuristic similarity measures and paving the way for moretransparent and controllable motion forecasting pipelines.</description>
      <author>example@mail.com (Abhishek Vivekanandan, Christian Hubschneider, J. Marius Zöllner)</author>
      <guid isPermaLink="false">2506.02571v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Large Language Models for Polymer Property Predictions</title>
      <link>http://arxiv.org/abs/2506.02129v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了机器学习在聚合物科学中的应用，特别是大语言模型（LLMs）在聚合物信息学中的潜力，通过在精心策划的数据集上微调LLMs来预测热性能。&lt;h4&gt;背景&lt;/h4&gt;机器学习对聚合物科学产生了革命性的影响，特别是LLMs简化了依赖大量标记数据集、手工特征表示和复杂特征工程的传统工作流程。&lt;h4&gt;目的&lt;/h4&gt;目的是通过微调通用的LLMs来预测聚合物的关键热性能，包括玻璃转变温度、熔点和分解温度。&lt;h4&gt;方法&lt;/h4&gt;研究人员对开源的LLaMA-3-8B和商业的GPT-3.5进行了微调，并在11,740条条目的数据集上进行了测试。他们使用了参数高效的微调和超参数优化，并将这些模型与基于指纹的传统方法进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;LLM方法在性能上接近传统模型，但在预测精度和效率上普遍表现不佳。LLaMA-3在性能上优于GPT-3.5，可能是因为其可调的开源架构。单任务学习（ST）比多任务学习（MT）更有效，因为LLMs难以捕捉跨属性相关性。分子嵌入的分析揭示了通用LLMs在表示细微的化学结构信息方面的局限性。&lt;h4&gt;结论&lt;/h4&gt;这些发现提供了分子嵌入和自然语言处理之间相互作用的见解，指导了LLMs在聚合物信息学中的应用选择。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning has revolutionized polymer science by enabling rapidproperty prediction and generative design. Large language models (LLMs) offerfurther opportunities in polymer informatics by simplifying workflows thattraditionally rely on large labeled datasets, handcrafted representations, andcomplex feature engineering. LLMs leverage natural language inputs throughtransfer learning, eliminating the need for explicit fingerprinting andstreamlining training. In this study, we finetune general purpose LLMs --open-source LLaMA-3-8B and commercial GPT-3.5 -- on a curated dataset of 11,740entries to predict key thermal properties: glass transition, melting, anddecomposition temperatures. Using parameter-efficient fine-tuning andhyperparameter optimization, we benchmark these models against traditionalfingerprinting-based approaches -- Polymer Genome, polyGNN, and polyBERT --under single-task (ST) and multi-task (MT) learning. We find that whileLLM-based methods approach traditional models in performance, they generallyunderperform in predictive accuracy and efficiency. LLaMA-3 consistentlyoutperforms GPT-3.5, likely due to its tunable open-source architecture.Additionally, ST learning proves more effective than MT, as LLMs struggle tocapture cross-property correlations, a key strength of traditional methods.Analysis of molecular embeddings reveals limitations of general purpose LLMs inrepresenting nuanced chemo-structural information compared to handcraftedfeatures and domain-specific embeddings. These findings provide insight intothe interplay between molecular embeddings and natural language processing,guiding LLM selection for polymer informatics.</description>
      <author>example@mail.com (Sonakshi Gupta, Akhlak Mahmood, Shivank Shukla, Rampi Ramprasad)</author>
      <guid isPermaLink="false">2506.02129v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MLLMs Need 3D-Aware Representation Supervision for Scene Understanding</title>
      <link>http://arxiv.org/abs/2506.01946v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了多模态大型语言模型（MLLMs）的3D感知能力，并提出了一个名为3DRS的框架，通过引入预训练的3D基础模型来增强MLLM的3D表示学习，从而提高场景理解能力。&lt;h4&gt;背景&lt;/h4&gt;MLLMs在3D推理方面利用了其强大的2D预训练能力，但缺乏明确的3D数据限制了3D表示能力。&lt;h4&gt;目的&lt;/h4&gt;研究MLLMs的3D感知能力，并提出方法来增强MLLM的3D表示学习。&lt;h4&gt;方法&lt;/h4&gt;通过评估多视图对应关系，揭示3D感知表示质量与下游任务性能之间的强正相关关系。提出3DRS框架，通过引入预训练3D基础模型的监督来增强MLLM的3D表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;3D感知表示的质量与下游任务性能之间存在强正相关关系。&lt;h4&gt;结论&lt;/h4&gt;3DRS框架通过将MLLM视觉特征与从3D模型中提炼的丰富3D知识对齐，有效提高了场景理解能力。&lt;h4&gt;翻译&lt;/h4&gt;The abstract of the paper investigates the 3D awareness of multimodal large language models (MLLMs) by evaluating multi-view correspondence and reveals a strong positive correlation between the quality of 3D-aware representation and downstream task performance. Motivated by this, the paper proposes 3DRS, a framework that enhances MLLM 3D representation learning by introducing supervision from pretrained 3D foundation models. The approach aligns MLLM visual features with rich 3D knowledge distilled from 3D models, effectively improving scene understanding. Extensive experiments across multiple benchmarks and MLLMs, including visual grounding, captioning, and question answering, demonstrate consistent performance gains. Project page: https://visual-ai.github.io/3drs&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in scene understanding have leveraged multimodal largelanguage models (MLLMs) for 3D reasoning by capitalizing on their strong 2Dpretraining. However, the lack of explicit 3D data during MLLM pretraininglimits 3D representation capability. In this paper, we investigate the3D-awareness of MLLMs by evaluating multi-view correspondence and reveal astrong positive correlation between the quality of 3D-aware representation anddownstream task performance. Motivated by this, we propose 3DRS, a frameworkthat enhances MLLM 3D representation learning by introducing supervision frompretrained 3D foundation models. Our approach aligns MLLM visual features withrich 3D knowledge distilled from 3D models, effectively improving sceneunderstanding. Extensive experiments across multiple benchmarks and MLLMs --including visual grounding, captioning, and question answering -- demonstrateconsistent performance gains. Project page: https://visual-ai.github.io/3drs</description>
      <author>example@mail.com (Xiaohu Huang, Jingjing Wu, Qunyi Xie, Kai Han)</author>
      <guid isPermaLink="false">2506.01946v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Sight Guide: A Wearable Assistive Perception and Navigation System for the Vision Assistance Race in the Cybathlon 2024</title>
      <link>http://arxiv.org/abs/2506.02676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了为视障人士设计的可穿戴辅助系统Sight Guide，该系统在Cybathlon 2024比赛的Vision Assistance Race中取得成功，并详细阐述了系统设计、评估结果和经验教训。&lt;h4&gt;背景&lt;/h4&gt;视障人士在需要空间意识和语义场景理解的任务中面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;加速发展和评估使视障人士能够完成这些任务的技术。&lt;h4&gt;方法&lt;/h4&gt;Sight Guide系统通过集成经典机器人算法和基于学习的方案，使用振动信号和音频指令引导用户完成复杂任务。&lt;h4&gt;主要发现&lt;/h4&gt;在测试环境中，Sight Guide实现了95.7%的任务成功率，并在Cybathlon比赛中证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;本工作为系统设计、评估结果和经验教训提供了深入见解，并指出了更广泛应用于现实世界的方向。&lt;h4&gt;翻译&lt;/h4&gt;Visually impaired individuals face significant challenges navigating and interacting with unknown situations, particularly in tasks requiring spatial awareness and semantic scene understanding. To accelerate the development and evaluate the state of technologies that enable visually impaired people to solve these tasks, the Vision Assistance Race (VIS) at the Cybathlon 2024 competition was organized. In this work, we present Sight Guide, a wearable assistive system designed for the VIS. The system processes data from multiple RGB and depth cameras on an embedded computer that guides the user through complex, real-world-inspired tasks using vibration signals and audio commands. Our software architecture integrates classical robotics algorithms with learning-based approaches to enable capabilities such as obstacle avoidance, object detection, optical character recognition, and touchscreen interaction. In a testing environment, Sight Guide achieved a 95.7% task success rate, and further demonstrated its effectiveness during the Cybathlon competition. This work provides detailed insights into the system design, evaluation results, and lessons learned, and outlines directions towards a broader real-world applicability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visually impaired individuals face significant challenges navigating andinteracting with unknown situations, particularly in tasks requiring spatialawareness and semantic scene understanding. To accelerate the development andevaluate the state of technologies that enable visually impaired people tosolve these tasks, the Vision Assistance Race (VIS) at the Cybathlon 2024competition was organized. In this work, we present Sight Guide, a wearableassistive system designed for the VIS. The system processes data from multipleRGB and depth cameras on an embedded computer that guides the user throughcomplex, real-world-inspired tasks using vibration signals and audio commands.Our software architecture integrates classical robotics algorithms withlearning-based approaches to enable capabilities such as obstacle avoidance,object detection, optical character recognition, and touchscreen interaction.In a testing environment, Sight Guide achieved a 95.7% task success rate, andfurther demonstrated its effectiveness during the Cybathlon competition. Thiswork provides detailed insights into the system design, evaluation results, andlessons learned, and outlines directions towards a broader real-worldapplicability.</description>
      <author>example@mail.com (Patrick Pfreundschuh, Giovanni Cioffi, Cornelius von Einem, Alexander Wyss, Hans Wernher van de Venn, Cesar Cadena, Davide Scaramuzza, Roland Siegwart, Alireza Darvishy)</author>
      <guid isPermaLink="false">2506.02676v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>On the Robustness of Tabular Foundation Models: Test-Time Attacks and In-Context Defenses</title>
      <link>http://arxiv.org/abs/2506.02978v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对表格基础模型（如TabPFN和TabICL）的对抗性脆弱性进行了全面研究，重点关注其易受攻击性和作为对抗工具的潜在风险。&lt;h4&gt;背景&lt;/h4&gt;现有的表格基础模型利用上下文学习实现强性能，但对其对抗性鲁棒性研究不足。&lt;h4&gt;目的&lt;/h4&gt;探究表格基础模型的对抗性脆弱性，包括其易受攻击性和作为对抗工具的潜在风险。&lt;h4&gt;方法&lt;/h4&gt;在金融、网络安全和医疗保健三个领域的三个基准测试中，研究通过小规模结构化扰动测试输入对预测准确性的影响，并提出一种基于上下文的对抗性训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;发现小规模结构化扰动可以显著降低预测准确性，并证明了表格基础模型可以被重新用于生成对随机森林和XGBoost等传统模型的逃避策略。&lt;h4&gt;结论&lt;/h4&gt;表格基础模型既是攻击目标也是对抗威胁的来源，强调了在新兴范式中对鲁棒训练和评估实践的紧迫需求。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we conduct a comprehensive study on the adversarial vulnerabilities of tabular foundational models (such as TabPFN and TabICL), focusing on both their susceptibility to targeted test-time attacks and their potential misuse as adversarial tools. In three benchmarks in finance, cybersecurity, and healthcare, we show that small, structured perturbations to test inputs can significantly degrade prediction accuracy, even when the training context remains fixed. Additionally, we demonstrate that tabular FM can be repurposed to generate transferable evasion against conventional models such as random forests and XGBoost, and to a lesser extent against deep tabular models. To improve tabular FM, we formulate the robustification problem as an optimization of the weights (adversarial fine-tuning) or the context (adversarial in-context learning). We introduce an in-context adversarial training strategy that incrementally replaces the context with adversarial perturbed instances without updating model weights. Our approach improves robustness across multiple tabular benchmarks. Together, these findings position tabular FM as both a target and a source of adversarial threats, highlighting the urgent need for robust training and evaluation practices in this emerging paradigm.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent tabular Foundational Models (FM) such as TabPFN and TabICL, leveragein-context learning to achieve strong performance without gradient updates orfine-tuning. However, their robustness to adversarial manipulation remainslargely unexplored. In this work, we present a comprehensive study of theadversarial vulnerabilities of tabular FM, focusing on both their fragility totargeted test-time attacks and their potential misuse as adversarial tools. Weshow on three benchmarks in finance, cybersecurity and healthcare, that small,structured perturbations to test inputs can significantly degrade predictionaccuracy, even when training context remain fixed. Additionally, we demonstratethat tabular FM can be repurposed to generate transferable evasion toconventional models such as random forests and XGBoost, and on a lesser extentto deep tabular models. To improve tabular FM, we formulate the robustificationproblem as an optimization of the weights (adversarial fine-tuning), or thecontext (adversarial in-context learning). We introduce an in-contextadversarial training strategy that incrementally replaces the context withadversarial perturbed instances, without updating model weights. Our approachimproves robustness across multiple tabular benchmarks. Together, thesefindings position tabular FM as both a target and a source of adversarialthreats, highlighting the urgent need for robust training and evaluationpractices in this emerging paradigm.</description>
      <author>example@mail.com (Mohamed Djilani, Thibault Simonetto, Karim Tit, Florian Tambon, Paul Récamier, Salah Ghamizi, Maxime Cordy, Mike Papadakis)</author>
      <guid isPermaLink="false">2506.02978v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Multilingual Information Retrieval with a Monolingual Knowledge Base</title>
      <link>http://arxiv.org/abs/2506.02527v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, accepted at GENNEXT@SIGIR25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的策略，通过加权采样和对比学习微调多语言嵌入模型，以实现使用单语种知识库的多语言信息检索，并证明了这种方法在MRR和Recall@3上的性能提升。&lt;h4&gt;背景&lt;/h4&gt;多语言信息检索成为扩展跨语言知识共享的有力工具，但高质量知识库资源稀缺且语言有限，因此需要有效的嵌入模型将不同语言的句子转换为与知识库语言相同的特征向量空间，这对于跨语言知识共享至关重要，特别是将高资源语言中的知识转移到低资源语言中。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的策略来微调多语言嵌入模型，以实现使用单语种知识库的多语言信息检索。&lt;h4&gt;方法&lt;/h4&gt;采用加权采样和对比学习的方法来微调多语言嵌入模型。&lt;h4&gt;主要发现&lt;/h4&gt;加权采样策略在MRR上提高了31.03%，在Recall@3上提高了33.98%。该方法对语言无偏见，适用于多语言和代码转换用例。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法可以有效地提升多语言信息检索的性能，并且对语言无偏见，适用于多种用例。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multilingual information retrieval has emerged as powerful tools forexpanding knowledge sharing across languages. On the other hand, resources onhigh quality knowledge base are often scarce and in limited languages,therefore an effective embedding model to transform sentences from differentlanguages into a feature vector space same as the knowledge base languagebecomes the key ingredient for cross language knowledge sharing, especially totransfer knowledge available in high-resource languages to low-resource ones.In this paper we propose a novel strategy to fine-tune multilingual embeddingmodels with weighted sampling for contrastive learning, enabling multilingualinformation retrieval with a monolingual knowledge base. We demonstrate thatthe weighted sampling strategy produces performance gains compared to standardones by up to 31.03\% in MRR and up to 33.98\% in Recall@3. Additionally, ourproposed methodology is language agnostic and applicable for both multilingualand code switching use cases.</description>
      <author>example@mail.com (Yingying Zhuang, Aman Gupta, Anurag Beniwal)</author>
      <guid isPermaLink="false">2506.02527v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Question-Answering for Driving Scene Understanding Using Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.02615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于自动驾驶场景理解的分层问答方法，在成本效益和详细视觉解释之间取得平衡。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶车辆需要有效理解和解释周围环境，以做出安全驾驶决策。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效且能够准确解释场景的方法，用于自动驾驶车辆。&lt;h4&gt;方法&lt;/h4&gt;该方法在特定地理区域的定制数据集上微调紧凑型视觉语言模型（VLM），并在推理阶段采用分层问答策略。VLM在结构化问题树中导航，根据高级问题和详细子问题生成答案。为了优化推理时间，动态跳过基于先前答案的问题，并使用手工制作的模板合成提取的答案。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在捕获关键场景细节方面与GPT-4o等最先进方法具有竞争力，同时实现了显著更低的推理时间。&lt;h4&gt;结论&lt;/h4&gt;该分层问答方法能够以最小的延迟捕获关键驾驶元素，适用于自动驾驶场景理解。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种用于自动驾驶场景理解的分层问答方法，在成本效益和详细视觉解释之间取得平衡。该方法在特定地理区域的定制数据集上微调紧凑型视觉语言模型（VLM），并在推理阶段采用分层问答策略。VLM在结构化问题树中导航，根据高级问题和详细子问题生成答案。为了优化推理时间，动态跳过基于先前答案的问题，并使用手工制作的模板合成提取的答案。该方法在捕获关键场景细节方面与GPT-4o等最先进方法具有竞争力，同时实现了显著更低的推理时间。该分层问答方法能够以最小的延迟捕获关键驾驶元素，适用于自动驾驶场景理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present a hierarchical question-answering (QA) approach forscene understanding in autonomous vehicles, balancing cost-efficiency withdetailed visual interpretation. The method fine-tunes a compact vision-languagemodel (VLM) on a custom dataset specific to the geographical area in which thevehicle operates to capture key driving-related visual elements. At theinference stage, the hierarchical QA strategy decomposes the sceneunderstanding task into high-level and detailed sub-questions. Instead ofgenerating lengthy descriptions, the VLM navigates a structured question tree,where answering high-level questions (e.g., "Is it possible for the ego vehicleto turn left at the intersection?") triggers more detailed sub-questions (e.g.,"Is there a vehicle approaching the intersection from the oppositedirection?"). To optimize inference time, questions are dynamically skippedbased on previous answers, minimizing computational overhead. The extractedanswers are then synthesized using handcrafted templates to ensure coherent,contextually accurate scene descriptions. We evaluate the proposed approach onthe custom dataset using GPT reference-free scoring, demonstrating itscompetitiveness with state-of-the-art methods like GPT-4o in capturing keyscene details while achieving significantly lower inference time. Moreover,qualitative results from real-time deployment highlight the proposed approach'scapacity to capture key driving elements with minimal latency.</description>
      <author>example@mail.com (Safaa Abdullahi Moallim Mohamud, Minjin Baek, Dong Seog Han)</author>
      <guid isPermaLink="false">2506.02615v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Sign Language: Towards Sign Understanding for Robot Autonomy</title>
      <link>http://arxiv.org/abs/2506.02556v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为导航标志理解的任务，旨在从传达场景空间信息的标志中提取导航线索。&lt;h4&gt;背景&lt;/h4&gt;标志是人类环境中的普遍元素，对场景理解和导航至关重要。对于自主系统来说，有效地解析和理解标志是必要的。&lt;h4&gt;目的&lt;/h4&gt;目标是建立导航标志理解的基准，包括创建测试集、提出评价标准和建立基线方法。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含160多张图像的测试集，这些图像展示了医院、商场和交通枢纽等公共场所中不同复杂度和设计的标志。使用视觉-语言模型（VLMs）来解析导航标志。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，VLMs在导航标志理解任务上表现出良好的性能，这可能激励机器人领域下游应用的发展。&lt;h4&gt;结论&lt;/h4&gt;VLMs在导航标志理解任务上具有潜力，代码和数据集可在GitHub上获取。&lt;h4&gt;翻译&lt;/h4&gt;Signage is an ubiquitous element of human environments, playing a critical role in both scene understanding and navigation. For autonomous systems to fully interpret human environments, effectively parsing and understanding signs is essential. We introduce the task of navigational sign understanding, aimed at extracting navigational cues from signs that convey symbolic spatial information about the scene. Specifically, we focus on signs capturing directional cues that point toward distant locations and locational cues that identify specific places. To benchmark performance on this task, we curate a comprehensive test set, propose appropriate evaluation metrics, and establish a baseline approach. Our test set consists of over 160 images, capturing signs with varying complexity and design across a wide range of public spaces, such as hospitals, shopping malls, and transportation hubs. Our baseline approach harnesses Vision-Language Models (VLMs) to parse navigational signs under these high degrees of variability. Experiments show that VLMs offer promising performance on this task, potentially motivating downstream applications in robotics. The code and dataset are available on Github.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Signage is an ubiquitous element of human environments, playing a criticalrole in both scene understanding and navigation. For autonomous systems tofully interpret human environments, effectively parsing and understanding signsis essential. We introduce the task of navigational sign understanding, aimedat extracting navigational cues from signs that convey symbolic spatialinformation about the scene. Specifically, we focus on signs capturingdirectional cues that point toward distant locations and locational cues thatidentify specific places. To benchmark performance on this task, we curate acomprehensive test set, propose appropriate evaluation metrics, and establish abaseline approach. Our test set consists of over 160 images, capturing signswith varying complexity and design across a wide range of public spaces, suchas hospitals, shopping malls, and transportation hubs. Our baseline approachharnesses Vision-Language Models (VLMs) to parse navigational signs under thesehigh degrees of variability. Experiments show that VLMs offer promisingperformance on this task, potentially motivating downstream applications inrobotics. The code and dataset are available on Github.</description>
      <author>example@mail.com (Ayush Agrawal, Joel Loo, Nicky Zimmerman, David Hsu)</author>
      <guid isPermaLink="false">2506.02556v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>From Features to Structure: Task-Aware Graph Construction for Relational and Tabular Learning with GNNs</title>
      <link>http://arxiv.org/abs/2506.02243v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为auGraph的统一框架，用于针对表格和关系数据执行任务感知的图增强，以解决深度学习在处理结构化数据时遇到的挑战。&lt;h4&gt;背景&lt;/h4&gt;表格和关系数据在机器学习应用中非常普遍，但它们对深度学习方法提出了独特的挑战，因为深度学习方法通常假设输入是平坦且特征对齐的。&lt;h4&gt;目的&lt;/h4&gt;提出auGraph框架的目的是为了利用表格和关系数据中的结构依赖性，同时避免现有基于GNN方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;auGraph通过将属性选择性提升为节点，并使用评分函数来量化它们对下游预测任务的相关性，从而增强基础图结构。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，auGraph生成的图在支持关系和表格预测任务的学习方面优于基于模式和启发式图构建方法。&lt;h4&gt;结论&lt;/h4&gt;auGraph通过保持原始数据模式并注入与任务相关的结构信号，为表格和关系数据提供了有效的图增强解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a unified framework called auGraph for task-aware graph augmentation, which applies to both tabular and relational data to address the challenges faced by deep learning methods in processing structured data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tabular and relational data remain the most ubiquitous formats in real-worldmachine learning applications, spanning domains from finance to healthcare.Although both formats offer structured representations, they pose distinctchallenges for modern deep learning methods, which typically assume flat,feature-aligned inputs. Graph Neural Networks (GNNs) have emerged as apromising solution by capturing structural dependencies within and betweentables. However, existing GNN-based approaches often rely on rigid,schema-derived graphs -- such as those based on primary-foreign key links --thereby underutilizing rich, predictive signals in non key attributes. In thiswork, we introduce auGraph, a unified framework for task-aware graphaugmentation that applies to both tabular and relational data. auGraph enhancesbase graph structures by selectively promoting attributes into nodes, guided byscoring functions that quantify their relevance to the downstream predictiontask. This augmentation preserves the original data schema while injectingtask-relevant structural signal. Empirically, auGraph outperforms schema-basedand heuristic graph construction methods by producing graphs that bettersupport learning for relational and tabular prediction tasks.</description>
      <author>example@mail.com (Tamara Cucumides, Floris Geerts)</author>
      <guid isPermaLink="false">2506.02243v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>VLCD: Vision-Language Contrastive Distillation for Accurate and Efficient Automatic Placenta Analysis</title>
      <link>http://arxiv.org/abs/2506.02229v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of the 9th International Workshop on Health Intelligence,  in conjunction with the Annual AAAI Conference on Artificial Intelligence,  Philadelphia, Pennsylvania, March 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的视觉-语言对比学习（VLC）框架，以提高产前病理检测的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;胎盘病理检查是检测和减轻与分娩相关的健康风险的有效方法。人工智能的发展使得利用胎盘照片和病理报告进行产前病理征象的检测和分类成为可能。&lt;h4&gt;目的&lt;/h4&gt;针对现有自动化方法计算量大的问题，提出两种改进措施，以提高VLC框架的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;提出两种改进措施：(1) 文本锚定的视觉-语言对比知识蒸馏（VLCD），一种新的医学VLC预训练知识蒸馏策略；(2) 使用大型自然图像数据集进行无监督预蒸馏，以改善初始化。&lt;h4&gt;主要发现&lt;/h4&gt;改进后的方法能够蒸馏出性能匹配或超越教师模型的神经网络，同时实现模型压缩和加速。结果表明，无监督预蒸馏在提高方法性能和鲁棒性方面具有价值，尤其是在处理低质量图像时。VLCD是提高医疗VLC方法效率和可部署性的有效方式，使基于AI的健康保健解决方案在资源受限的环境中更加可及。&lt;h4&gt;结论&lt;/h4&gt;本文提出的改进方法有效地提高了产前病理检测的准确性和效率，使得AI在医疗保健领域的应用更加广泛和可及。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pathological examination of the placenta is an effective method for detectingand mitigating health risks associated with childbirth. Recent advancements inAI have enabled the use of photographs of the placenta and pathology reportsfor detecting and classifying signs of childbirth-related pathologies. However,existing automated methods are computationally extensive, which limits theirdeployability. We propose two modifications to vision-language contrastivelearning (VLC) frameworks to enhance their accuracy and efficiency: (1)text-anchored vision-language contrastive knowledge distillation (VLCD)-a newknowledge distillation strategy for medical VLC pretraining, and (2)unsupervised predistillation using a large natural images dataset for improvedinitialization. Our approach distills efficient neural networks that match orsurpass the teacher model in performance while achieving model compression andacceleration. Our results showcase the value of unsupervised predistillation inimproving the performance and robustness of our approach, specifically forlower-quality images. VLCD serves as an effective way to improve the efficiencyand deployability of medical VLC approaches, making AI-based healthcaresolutions more accessible, especially in resource-constrained environments.</description>
      <author>example@mail.com (Manas Mehta, Yimu Pan, Kelly Gallagher, Alison D. Gernand, Jeffery A. Goldstein, Delia Mwinyelle, Leena Mithal, James Z. Wang)</author>
      <guid isPermaLink="false">2506.02229v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Federated Gaussian Mixture Models</title>
      <link>http://arxiv.org/abs/2506.01780v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 6 figures. Submitted to ACM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了FedGenGMM，这是一种针对无监督学习场景的Gaussian Mixture Models (GMM)的新型单次联邦学习方法。&lt;h4&gt;背景&lt;/h4&gt;在联邦学习（FL）中，多个去中心化客户端在不共享原始数据的情况下协同训练模型，面临着统计异质性、高通信成本和隐私问题。&lt;h4&gt;目的&lt;/h4&gt;FedGenGMM旨在解决这些问题，通过允许在客户端设备上独立训练的本地GMM模型通过单次通信轮次进行聚合。&lt;h4&gt;方法&lt;/h4&gt;该方法利用GMM的生成特性，在服务器端创建一个合成数据集来高效训练全局模型。&lt;h4&gt;主要发现&lt;/h4&gt;在涵盖图像、表格和时间序列数据的多个数据集上的评估表明，FedGenGMM在数据异质性显著的情况下，仍然能够持续实现与非联邦学习和迭代联邦学习方法相当的性能。&lt;h4&gt;结论&lt;/h4&gt;FedGenGMM显著降低了通信开销，在异常检测任务中保持了稳健的性能，并在本地模型复杂度方面提供了灵活性，使其特别适合边缘计算环境。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为FedGenGMM的新颖的单次联邦学习方法，用于高斯混合模型（GMM）的无监督学习场景。在联邦学习中，多个去中心化客户端在不共享原始数据的情况下协同训练模型，面临着统计异质性、高通信成本和隐私问题。FedGenGMM通过允许在客户端设备上独立训练的本地GMM模型通过单次通信轮次进行聚合来解决这些问题。该方法利用GMM的生成特性，在服务器端创建一个合成数据集来高效训练全局模型。在涵盖图像、表格和时间序列数据的多个数据集上的评估表明，FedGenGMM在数据异质性显著的情况下，仍然能够持续实现与非联邦学习和迭代联邦学习方法相当的性能。FedGenGMM显著降低了通信开销，在异常检测任务中保持了稳健的性能，并在本地模型复杂度方面提供了灵活性，使其特别适合边缘计算环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces FedGenGMM, a novel one-shot federated learning approachfor Gaussian Mixture Models (GMM) tailored for unsupervised learning scenarios.In federated learning (FL), where multiple decentralized clientscollaboratively train models without sharing raw data, significant challengesinclude statistical heterogeneity, high communication costs, and privacyconcerns. FedGenGMM addresses these issues by allowing local GMM models,trained independently on client devices, to be aggregated through a singlecommunication round. This approach leverages the generative property of GMMs,enabling the creation of a synthetic dataset on the server side to train aglobal model efficiently. Evaluation across diverse datasets covering image,tabular, and time series data demonstrates that FedGenGMM consistently achievesperformance comparable to non-federated and iterative federated methods, evenunder significant data heterogeneity. Additionally, FedGenGMM significantlyreduces communication overhead, maintains robust performance in anomalydetection tasks, and offers flexibility in local model complexities, making itparticularly suitable for edge computing environments.</description>
      <author>example@mail.com (Sophia Zhang Pettersson, Kuo-Yun Liang, Juan Carlos Andresen)</author>
      <guid isPermaLink="false">2506.01780v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>ReconXF: Graph Reconstruction Attack via Public Feature Explanations on Privatized Node Features and Labels</title>
      <link>http://arxiv.org/abs/2506.02134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在隐私保护下，如何通过解释性方法在图神经网络中识别重要节点属性，并提出了ReconXF攻击方法来对抗这种隐私风险。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在多个应用中表现出色，但作为黑盒模型，限制了其在关键领域如医疗保健和刑事司法中的使用。解释性方法虽然提供了特征级别的解释，但同时也带来了隐私风险。&lt;h4&gt;目的&lt;/h4&gt;为了在保护节点特征和标签的同时提供解释性信息，研究如何在隐私保护的环境下进行图结构恢复。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的图重构攻击方法ReconXF，该方法通过结合去噪机制和利用解释中的结构信号，在具有公共解释和私有辅助数据的场景下进行攻击。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，ReconXF在私有设置中优于现有方法，提高了AUC和平均精度。结果表明，即使在辅助数据的隐私保护下，公共解释与去噪相结合也能实现图结构的恢复。&lt;h4&gt;结论&lt;/h4&gt;ReconXF方法有效地对抗了基于解释的攻击，并在隐私保护的环境下实现了图结构的恢复。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies how to identify important node attributes in graph neural networks using explainable methods under privacy protection, and proposes a new graph reconstruction attack method called ReconXF to counter this privacy risk.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) achieve high performance across manyapplications but function as black-box models, limiting their use in criticaldomains like healthcare and criminal justice. Explainability methods addressthis by providing feature-level explanations that identify important nodeattributes for predictions. These explanations create privacy risks. Combinedwith auxiliary information, feature explanations can enable adversaries toreconstruct graph structure, exposing sensitive relationships. Existing graphreconstruction attacks assume access to original auxiliary data, but practicalsystems use differential privacy to protect node features and labels whileproviding explanations for transparency. We study a threat model whereadversaries access public feature explanations along with privatized nodefeatures and labels. We show that existing explanation-based attacks like GSEFperform poorly with privatized data due to noise from differential privacymechanisms. We propose ReconXF, a graph reconstruction attack for scenarioswith public explanations and privatized auxiliary data. Our method adaptsexplanation-based frameworks by incorporating denoising mechanisms that handledifferential privacy noise while exploiting structural signals in explanations.Experiments across multiple datasets show ReconXF outperforms SoTA methods inprivatized settings, with improvements in AUC and average precision. Resultsindicate that public explanations combined with denoising enable graphstructure recovery even under the privacy protection of auxiliary data. Code isavailable at (link to be made public after acceptance).</description>
      <author>example@mail.com (Rishi Raj Sahoo, Rucha Bhalchandra Joshi, Subhankar Mishra)</author>
      <guid isPermaLink="false">2506.02134v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Biomedical Multi-modal Representation Learning with Multi-scale Pre-training and Perturbed Report Discrimination</title>
      <link>http://arxiv.org/abs/2506.01902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 1 figure, accepted by 2024 IEEE Conference on Artificial  Intelligence (CAI)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的方法，用于预训练生物医学视觉语言模型，以解决生物医学文本的复杂性和领域特定语义在常见对比学习方法中被忽视的问题。&lt;h4&gt;背景&lt;/h4&gt;视觉语言模型在大量未标记的生物医学图像及其相关报告中学习到通用的语义表示，这些多模态表示可以促进生物医学领域的各种下游任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，即扰动报告判别，用于预训练生物医学视觉语言模型，以解决生物医学文本复杂性和领域特定语义的问题。&lt;h4&gt;方法&lt;/h4&gt;首先，创建一组文本扰动方法，保持相同单词的同时破坏句子的语义结构。然后，对报告应用不同类型的扰动，并使用模型区分原始报告和扰动报告，前提是给定相关图像。同时，通过对比注意力加权的图像子区域和图像-文本对中的子词，增强方法对两种模态的更高粒度敏感度。&lt;h4&gt;主要发现&lt;/h4&gt;在多个下游任务上进行了广泛的实验，该方法优于强基线方法，结果表明该方法学习到更具语义意义和鲁棒性的多模态表示。&lt;h4&gt;结论&lt;/h4&gt;该方法在生物医学视觉语言模型的预训练中表现出色，能够学习到更具语义意义和鲁棒性的多模态表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/CAI59869.2024.00097&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models pre-trained on large scale of unlabeled biomedicalimages and associated reports learn generalizable semantic representations.These multi-modal representations can benefit various downstream tasks in thebiomedical domain. Contrastive learning is widely used to pre-trainvision-language models for general natural images and associated captions.Despite its popularity, we found biomedical texts have complex anddomain-specific semantics that are often neglected by common contrastivemethods. To address this issue, we propose a novel method, perturbed reportdiscrimination, for pre-train biomedical vision-language models. First, wecurate a set of text perturbation methods that keep the same words, but disruptthe semantic structure of the sentence. Next, we apply different types ofperturbation to reports, and use the model to distinguish the original reportfrom the perturbed ones given the associated image. Parallel to this, weenhance the sensitivity of our method to higher level of granularity for bothmodalities by contrasting attention-weighted image sub-regions and sub-words inthe image-text pairs. We conduct extensive experiments on multiple downstreamtasks, and our method outperforms strong baseline methods. The resultsdemonstrate that our approach learns more semantic meaningful and robustmulti-modal representations.</description>
      <author>example@mail.com (Xinliu Zhong, Kayhan Batmanghelich, Li Sun)</author>
      <guid isPermaLink="false">2506.01902v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Automated Manifold Learning for Reduced Order Modeling</title>
      <link>http://arxiv.org/abs/2506.01741v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用几何表示学习从时空数据中驱动发现系统动态的方法。&lt;h4&gt;背景&lt;/h4&gt;识别数据中的几何结构是（无监督）学习的基础，几何表示学习在科学和工程领域得到了广泛应用。&lt;h4&gt;目的&lt;/h4&gt;探索几何表示学习在时空数据中驱动发现系统动态的应用。&lt;h4&gt;方法&lt;/h4&gt;提出在时空邻近图中编码相似结构，并应用多种经典和基于深度学习的流形学习方法来学习降阶动态。&lt;h4&gt;主要发现&lt;/h4&gt;流形学习方法通常能够恢复降阶动态，但不同算法和超参数选择下学习到的表示质量差异很大，表明对各自方法内在几何假设的高度敏感性，并暗示需要仔细的超参数调整，这在实践中可能很昂贵。&lt;h4&gt;结论&lt;/h4&gt;提出了一种自动流形学习框架，该框架根据输入图的代表性子样本选择流形学习方法及其相应的超参数选择，证明了该框架在可扩展性和学习到的表示在捕捉底层系统动态的局部和全局几何特征方面的准确性方面均有性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：识别数据中的几何结构是（无监督）学习的基础。因此，几何表示学习在科学和工程领域得到了广泛应用。在这项工作中，我们研究了利用几何表示学习从时空数据中驱动发现系统动态的方法。我们提出在时空邻近图中编码相似结构，然后应用一系列经典和基于深度学习的流形学习方法来学习降阶动态。我们观察到，虽然流形学习方法通常能够恢复降阶动态，但不同算法和超参数选择下学习到的表示质量差异很大，这表明对各自方法内在几何假设的高度敏感性，并暗示需要仔细的超参数调整，这在实践中可能很昂贵。为了克服这些挑战，我们提出了一种自动流形学习框架，该框架根据输入图的代表性子样本选择流形学习方法及其相应的超参数选择。我们证明了所提出的框架在可扩展性和学习到的表示在捕捉底层系统动态的局部和全局几何特征方面的准确性方面均有性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The problem of identifying geometric structure in data is a cornerstone of(unsupervised) learning. As a result, Geometric Representation Learning hasbeen widely applied across scientific and engineering domains. In this work, weinvestigate the use of Geometric Representation Learning for the data-drivendiscovery of system dynamics from spatial-temporal data. We propose to encodesimilarity structure in such data in a spatial-temporal proximity graph, towhich we apply a range of classical and deep learning-based manifold learningapproaches to learn reduced order dynamics. We observe that while manifoldlearning is generally capable of recovering reduced order dynamics, the qualityof the learned representations varies substantially across different algorithmsand hyperparameter choices. This is indicative of high sensitivity to theinherent geometric assumptions of the respective approaches and suggests a needfor careful hyperparameter tuning, which can be expensive in practise. Toovercome these challenges, we propose a framework for Automated ManifoldLearning, which selects a manifold learning approach and correspondinghyperparameter choices based on representative subsamples of the input graph.We demonstrate that the proposed framework leads to performance gains both inscalability and in the learned representations' accuracy in capturing local andglobal geometric features of the underlying system dynamics.</description>
      <author>example@mail.com (Imran Nasim, Melanie Weber)</author>
      <guid isPermaLink="false">2506.01741v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Stock Market Telepathy: Graph Neural Networks Predicting the Secret Conversations between MINT and G7 Countries</title>
      <link>http://arxiv.org/abs/2506.01945v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了新兴经济体，特别是MINT国家在全球股市中的影响力，并探讨了这些市场与发达国家的经济条件之间的关系。&lt;h4&gt;背景&lt;/h4&gt;MINT国家在全球股市中的影响力逐渐增强，但同时也受到G7国家经济条件的影响。&lt;h4&gt;目的&lt;/h4&gt;为了准确预测股票价格走势，本文使用MTGNN算法对G7和MINT国家的股票市场指数进行了分析。&lt;h4&gt;方法&lt;/h4&gt;采用MTGNN算法对2012年至2024年的G7和MINT国家的主要股票市场指数进行了研究，该方法能够考虑多变量时间序列中的复杂时空联系。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，美国和加拿大在G7国家中对于股票指数预测最具影响力，而印度尼西亚和土耳其在MINT国家中影响最大。此外，MTGNN在预测MINT和G7国家的股票市场指数价格方面优于传统方法。&lt;h4&gt;结论&lt;/h4&gt;本研究为分析经济板块市场和全球股市动态提供了有价值的见解，并展示了使用MTGNN进行实证分析的强大方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emerging economies, particularly the MINT countries (Mexico, Indonesia,Nigeria, and T\"urkiye), are gaining influence in global stock markets,although they remain susceptible to the economic conditions of developedcountries like the G7 (Canada, France, Germany, Italy, Japan, the UnitedKingdom, and the United States). This interconnectedness and sensitivity offinancial markets make understanding these relationships crucial for investorsand policymakers to predict stock price movements accurately. To this end, weexamined the main stock market indices of G7 and MINT countries from 2012 to2024, using a recent graph neural network (GNN) algorithm called multivariatetime series forecasting with graph neural network (MTGNN). This method allowsfor considering complex spatio-temporal connections in multivariate timeseries. In the implementations, MTGNN revealed that the US and Canada are themost influential G7 countries regarding stock indices in the forecastingprocess, and Indonesia and T\"urkiye are the most influential MINT countries.Additionally, our results showed that MTGNN outperformed traditional methods inforecasting the prices of stock market indices for MINT and G7 countries.Consequently, the study offers valuable insights into economic blocks' marketsand presents a compelling empirical approach to analyzing global stock marketdynamics using MTGNN.</description>
      <author>example@mail.com (Nurbanu Bursa)</author>
      <guid isPermaLink="false">2506.01945v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>INESC-ID @ eRisk 2025: Exploring Fine-Tuned, Similarity-Based, and Prompt-Based Approaches to Depression Symptom Identification</title>
      <link>http://arxiv.org/abs/2506.02924v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 1 figure, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文描述了团队针对eRisk 2025任务1：搜索抑郁症症状的方法。通过句子集合和Beck抑郁量表-II（BDI）问卷，参与者提交与BDI中每种抑郁症状相关的最多1000个句子，并按相关性排序。参与者的提交根据标准信息检索（IR）指标进行评估，包括平均精度（AP）和R-精度（R-PREC）。由于训练数据的标签限制，我们将开发过程定位为针对每个BDI症状的二分类任务，并据此进行评估。&lt;h4&gt;背景&lt;/h4&gt;该研究针对抑郁症症状的搜索任务，旨在通过信息检索技术识别与抑郁症相关的症状。&lt;h4&gt;目的&lt;/h4&gt;开发一个有效的系统来识别与BDI问卷中每种抑郁症状相关的句子。&lt;h4&gt;方法&lt;/h4&gt;使用标准信息检索（IR）指标进行评估，将开发过程定位为针对每个BDI症状的二分类任务，并探索了基础模型微调、句子相似性、大型语言模型（LLM）提示和集成技术。将可用标记数据分为训练和验证集。&lt;h4&gt;主要发现&lt;/h4&gt;微调基础模型结合合成数据可以缓解类别不平衡问题，并取得了最佳性能。最优方法因症状而异。&lt;h4&gt;结论&lt;/h4&gt;通过微调基础模型和使用集成方法，实现了最高的信息检索评估分数，超越了16个其他团队的提交。&lt;h4&gt;翻译&lt;/h4&gt;在本文中，我们描述了我们团队针对eRisk 2025任务1：搜索抑郁症症状的方法。给定一组句子和Beck的抑郁量表-II（BDI）问卷，参与者被要求提交最多1000个与BDI中每种抑郁症状相关的句子，并按相关性排序。参与者的提交根据标准信息检索（IR）指标进行评估，包括平均精度（AP）和R-精度（R-PREC）。然而，由于提供的训练数据是由句子标记为与BDI的某种症状相关或不相关，因此我们将我们的开发定位于针对每个BDI症状的二分类任务，并据此进行评估。为此，我们将可用的标记数据分为训练集和验证集，并探索了基础模型微调、句子相似性、大型语言模型（LLM）提示和集成技术。验证结果表明，微调基础模型产生了最佳性能，特别是在与合成数据结合以减轻类别不平衡的情况下。我们还观察到，最佳方法因症状而异。基于这些见解，我们设计了五个独立的测试运行，其中两个使用了集成方法。这些运行在官方IR评估中取得了最高分数，超过了其他16个团队的提交。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we describe our team's approach to eRisk's 2025 Task 1: Searchfor Symptoms of Depression. Given a set of sentences and the Beck's DepressionInventory - II (BDI) questionnaire, participants were tasked with submitting upto 1,000 sentences per depression symptom in the BDI, sorted by relevance.Participant submissions were evaluated according to standard InformationRetrieval (IR) metrics, including Average Precision (AP) and R-Precision(R-PREC). The provided training data, however, consisted of sentences labeledas to whether a given sentence was relevant or not w.r.t. one of BDI'ssymptoms. Due to this labeling limitation, we framed our development as abinary classification task for each BDI symptom, and evaluated accordingly. Tothat end, we split the available labeled data into training and validationsets, and explored foundation model fine-tuning, sentence similarity, LargeLanguage Model (LLM) prompting, and ensemble techniques. The validation resultsrevealed that fine-tuning foundation models yielded the best performance,particularly when enhanced with synthetic data to mitigate class imbalance. Wealso observed that the optimal approach varied by symptom. Based on theseinsights, we devised five independent test runs, two of which used ensemblemethods. These runs achieved the highest scores in the official IR evaluation,outperforming submissions from 16 other teams.</description>
      <author>example@mail.com (Diogo A. P. Nunes, Eugénio Ribeiro)</author>
      <guid isPermaLink="false">2506.02924v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>iQUEST: An Iterative Question-Guided Framework for Knowledge Base Question Answering</title>
      <link>http://arxiv.org/abs/2506.01784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACL 2025 (Main)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为iQUEST的KBQA框架，用于解决LLMs在知识密集型场景中的事实不准确问题，通过引入外部知识资源如知识图谱来提高推理的可靠性。&lt;h4&gt;背景&lt;/h4&gt;尽管LLMs在自然语言处理任务中表现出色，但在知识密集型场景中经常出现事实不准确的问题。&lt;h4&gt;目的&lt;/h4&gt;通过整合外部知识资源，特别是知识图谱，为更可靠的推理提供一个透明且可更新的基础。&lt;h4&gt;方法&lt;/h4&gt;iQUEST通过迭代地将复杂查询分解为更简单的子查询，确保结构化和专注的推理轨迹。此外，它还整合了图神经网络（GNN）来预测并整合每一步推理中的2-hop邻居信息。&lt;h4&gt;主要发现&lt;/h4&gt;iQUEST在四个基准数据集和四个LLMs上展现了持续的改进。&lt;h4&gt;结论&lt;/h4&gt;iQUEST通过双重方法加强了推理过程，使模型能够更有效地探索可行路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While Large Language Models (LLMs) excel at many natural language processingtasks, they often suffer from factual inaccuracies in knowledge-intensivescenarios. Integrating external knowledge resources, particularly knowledgegraphs (KGs), provides a transparent and updatable foundation for more reliablereasoning. Knowledge Base Question Answering (KBQA), which queries and reasonsover KGs, is central to this effort, especially for complex, multi-hop queries.However, multi-hop reasoning poses two key challenges: (1)~maintaining coherentreasoning paths, and (2)~avoiding prematurely discarding critical multi-hopconnections. To address these issues, we introduce iQUEST, a question-guidedKBQA framework that iteratively decomposes complex queries into simplersub-questions, ensuring a structured and focused reasoning trajectory.Additionally, we integrate a Graph Neural Network (GNN) to look ahead andincorporate 2-hop neighbor information at each reasoning step. This dualapproach strengthens the reasoning process, enabling the model to exploreviable paths more effectively. Detailed experiments demonstrate the consistentimprovement delivered by iQUEST across four benchmark datasets and four LLMs.</description>
      <author>example@mail.com (Shuai Wang, Yinan Yu)</author>
      <guid isPermaLink="false">2506.01784v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Principled data augmentation for learning to solve quadratic programming problems</title>
      <link>http://arxiv.org/abs/2506.01728v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了利用消息传递图神经网络（MPNNs）针对二次规划（QPs）进行数据增强的原理性方法，以提高学习到优化（L2O）任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;线性规划和二次规划在许多实际应用中至关重要，而使用MPNNs的L2O方法在解决这类优化问题方面显示出潜力。然而，在数据稀缺的环境下，特别是处理如QPs等复杂优化问题时，稳健的L2O MPNNs仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种专门针对QPs的数据增强方法，以生成多样化且保持最优性的实例，并集成到基于对比学习的自监督学习框架中，以预训练MPNNs，从而在L2O任务上获得更好的性能。&lt;h4&gt;方法&lt;/h4&gt;该方法利用理论上有依据的数据增强技术，并结合自监督学习框架，通过对比学习来预训练MPNNs。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在监督场景中提高了泛化能力，并促进了相关优化问题上的有效迁移学习。&lt;h4&gt;结论&lt;/h4&gt;通过数据增强和自监督学习，L2O MPNNs在解决QPs等复杂优化问题时展现出更好的性能和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Linear and quadratic optimization are crucial in numerous real-world applications, from training machine learning models to integer-linear optimization. Recently, learning-to-optimize methods (L2O) for linear (LPs) or quadratic programs (QPs) using message-passing graph neural networks (MPNNs) have gained traction, promising lightweight, data-driven proxies for solving such optimization problems. However, robust L2O MPNNs remain challenging in data-scarce settings, especially when addressing complex optimization problems such as QPs. This work introduces a principled approach to data augmentation tailored for QPs via MPNNs. Our method leverages theoretically justified data augmentation techniques to generate diverse yet optimality-preserving instances. Furthermore, we integrate these augmentations into a self-supervised learning framework based on contrastive learning, thereby pretraining MPNNs for enhanced performance on L2O tasks. Extensive experiments demonstrate that our approach improves generalization in supervised scenarios and facilitates effective transfer learning to related optimization problems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Linear and quadratic optimization are crucial in numerous real-worldapplications, from training machine learning models to integer-linearoptimization. Recently, learning-to-optimize methods (L2O) for linear (LPs) orquadratic programs (QPs) using message-passing graph neural networks (MPNNs)have gained traction, promising lightweight, data-driven proxies for solvingsuch optimization problems. For example, they replace the costly computation ofstrong branching scores in branch-and-bound solvers, requiring solving manysuch optimization problems. However, robust L2O MPNNs remain challenging indata-scarce settings, especially when addressing complex optimization problemssuch as QPs. This work introduces a principled approach to data augmentationtailored for QPs via MPNNs. Our method leverages theoretically justified dataaugmentation techniques to generate diverse yet optimality-preservinginstances. Furthermore, we integrate these augmentations into a self-supervisedlearning framework based on contrastive learning, thereby pretraining MPNNs forenhanced performance on L2O tasks. Extensive experiments demonstrate that ourapproach improves generalization in supervised scenarios and facilitateseffective transfer learning to related optimization problems.</description>
      <author>example@mail.com (Chendi Qian, Christopher Morris)</author>
      <guid isPermaLink="false">2506.01728v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Towards Auto-Annotation from Annotation Guidelines: A Benchmark through 3D LiDAR Detection</title>
      <link>http://arxiv.org/abs/2506.02914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究从专家定义的标注指南中自动化数据标注的方法，提出新的基准AnnoGuide，并使用nuScenes数据集进行案例研究，旨在减少人工标注的劳动强度和成本。&lt;h4&gt;背景&lt;/h4&gt;数据标注是机器学习解决方案的关键前提，但也是一个劳动密集、耗时且昂贵的流程。&lt;h4&gt;目的&lt;/h4&gt;通过引入AnnoGuide，评估从专家定义的标注指南中自动化数据标注的方法，以消除手动标注的需求。&lt;h4&gt;方法&lt;/h4&gt;采用一个简单的流程，包括：(1) 使用开源基础模型进行RGB图像中的目标检测和分割；(2) 使用已知的相机姿态将2D检测投影到3D；(3) 在每个2D检测的视锥体内聚类LiDAR点以生成3D立方体。&lt;h4&gt;主要发现&lt;/h4&gt;通过逐步优化关键组件，3D检测的平均精度（mAP）从12.1提升到21.9，但结果表明AnnoGuide仍然是一个开放且具有挑战性的问题，强调了开发基于LiDAR的基础模型的紧迫性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的AnnoGuide方法在减少数据标注工作量方面取得了显著进展，但仍需进一步研究以解决挑战并推动基于LiDAR的基础模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A crucial yet under-appreciated prerequisite in machine learning solutionsfor real-applications is data annotation: human annotators are hired tomanually label data according to detailed, expert-crafted guidelines. This isoften a laborious, tedious, and costly process. To study methods forfacilitating data annotation, we introduce a new benchmark AnnoGuide:Auto-Annotation from Annotation Guidelines. It aims to evaluate automatedmethods for data annotation directly from expert-defined annotation guidelines,eliminating the need for manual labeling. As a case study, we repurpose thewell-established nuScenes dataset, commonly used in autonomous drivingresearch, which provides comprehensive annotation guidelines for labeling LiDARpoint clouds with 3D cuboids across 18 object classes. These guidelines includea few visual examples and textual descriptions, but no labeled 3D cuboids inLiDAR data, making this a novel task of multi-modal few-shot 3D detectionwithout 3D annotations. The advances of powerful foundation models (FMs) makeAnnoGuide especially timely, as FMs offer promising tools to tackle itschallenges. We employ a conceptually straightforward pipeline that (1) utilizesopen-source FMs for object detection and segmentation in RGB images, (2)projects 2D detections into 3D using known camera poses, and (3) clusters LiDARpoints within the frustum of each 2D detection to generate a 3D cuboid.Starting with a non-learned solution that leverages off-the-shelf FMs, weprogressively refine key components and achieve significant performanceimprovements, boosting 3D detection mAP from 12.1 to 21.9! Nevertheless, ourresults highlight that AnnoGuide remains an open and challenging problem,underscoring the urgent need for developing LiDAR-based FMs. We release ourcode and models at GitHub: https://annoguide.github.io/annoguide3Dbenchmark</description>
      <author>example@mail.com (Yechi Ma, Wei Hua, Shu Kong)</author>
      <guid isPermaLink="false">2506.02914v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Overcoming Data Scarcity in Scanning Tunnelling Microscopy Image Segmentation</title>
      <link>http://arxiv.org/abs/2506.01678v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于STM图像分析的自动化分割方法，使用少量样本学习和无监督学习，以提高STM图像分割的效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;STM是一种用于原子分辨率表面成像的强大技术，但在分析图像时，手动识别和标记特征是一项劳动密集型任务。&lt;h4&gt;目的&lt;/h4&gt;开发一种自动化方法来减轻STM图像分析中的劳动负担，并提高分割的灵活性和准确性。&lt;h4&gt;方法&lt;/h4&gt;提出的方法结合了少量样本学习和无监督学习，无需大量手动标注数据集，且能够适应未见过的表面。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在识别三种不同表面（Si(001)、Ge(001)和TiO$_2$(110)）上的原子特征方面表现出强泛化能力，能够在训练后仅通过少量额外标注数据点适应未见过的表面。&lt;h4&gt;结论&lt;/h4&gt;该研究是向STM图像的高效和材料无关的自动分割迈出的重要一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scanning tunnelling microscopy (STM) is a powerful technique for imagingsurfaces with atomic resolution, providing insight into physical and chemicalprocesses at the level of single atoms and molecules. A regular task of STMimage analysis is the identification and labelling of features of interestagainst a uniform background. Performing this manually is a labour-intensivetask, requiring significant human effort. To reduce this burden, we propose anautomated approach to the segmentation of STM images that uses both few-shotlearning and unsupervised learning. Our technique offers greater flexibilitycompared to previous supervised methods; it removes the requirement for largemanually annotated datasets and is thus easier to adapt to an unseen surfacewhile still maintaining a high accuracy. We demonstrate the effectiveness ofour approach by using it to recognise atomic features on three distinctsurfaces: Si(001), Ge(001), and TiO$_2$(110), including adsorbed AsH$_3$molecules on the silicon and germanium surfaces. Our model exhibits stronggeneralisation capabilities, and following initial training, can be adapted tounseen surfaces with as few as one additional labelled data point. This work isa significant step towards efficient and material-agnostic, automaticsegmentation of STM images.</description>
      <author>example@mail.com (Nikola L. Kolev, Max Trouton, Filippo Federici Canova, Geoff Thornton, David Z. Gao, Neil J. Curson, Taylor J. Z. Stock)</author>
      <guid isPermaLink="false">2506.01678v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Cell-o1: Training LLMs to Solve Single-Cell Reasoning Puzzles with Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.02911v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages; 16 tables; 7 figures; Code:  https://github.com/ncbi-nlp/cell-o1&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为CellPuzzles的任务，旨在模仿人类专家根据领域知识对细胞进行类型标注的过程，并引入了一种名为Cell-o1的新模型，以提高批量细胞类型标注的准确性。&lt;h4&gt;背景&lt;/h4&gt;细胞类型标注是分析单细胞RNA测序数据异质性的关键任务。尽管最近的基座模型可以自动化这一过程，但它们通常独立标注细胞，不考虑批量级别的细胞背景，也不提供解释性推理。&lt;h4&gt;目的&lt;/h4&gt;目标是开发一种能够考虑批量级别细胞背景并进行解释性推理的细胞类型标注方法。&lt;h4&gt;方法&lt;/h4&gt;提出CellPuzzles任务，该任务跨越多种组织、疾病和捐赠者条件，需要跨批量级别细胞背景进行推理以确保标签的唯一性。同时，提出了一种名为Cell-o1的7B LLM，通过在精炼推理痕迹上进行的监督微调和批量奖励的强化学习进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;现有的大型语言模型在CellPuzzles任务上表现不佳，最佳基线模型（OpenAI的o1）在批量级别上的准确率仅为19.0%。Cell-o1实现了最先进的性能，超过了o1超过73%，并且能够很好地泛化到不同的上下文中。&lt;h4&gt;结论&lt;/h4&gt;Cell-o1在批量细胞类型标注任务中表现出色，提供了对批量级别标注性能和出现专家级推理的见解。&lt;h4&gt;翻译&lt;/h4&gt;Cell type annotation is a key task in analyzing the heterogeneity of single-cell RNA sequencing data. Although recent foundation models automate this process, they typically annotate cells independently, without considering batch-level cellular context or providing explanatory reasoning. In contrast, human experts often annotate distinct cell types for different cell clusters based on their domain knowledge. To mimic this workflow, we introduce the CellPuzzles task, where the objective is to assign unique cell types to a batch of cells. This benchmark spans diverse tissues, diseases, and donor conditions, and requires reasoning across the batch-level cellular context to ensure label uniqueness. We find that off-the-shelf large language models (LLMs) struggle on CellPuzzles, with the best baseline (OpenAI's o1) achieving only 19.0% batch-level accuracy. To fill this gap, we propose Cell-o1, a 7B LLM trained via supervised fine-tuning on distilled reasoning traces, followed by reinforcement learning with batch-level rewards. Cell-o1 achieves state-of-the-art performance, outperforming o1 by over 73% and generalizing well across contexts. Further analysis of training dynamics and reasoning behaviors provides insights into batch-level annotation performance and emergent expert-like reasoning. Code and data are available at https://github.com/ncbi-nlp/cell-o1.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cell type annotation is a key task in analyzing the heterogeneity ofsingle-cell RNA sequencing data. Although recent foundation models automatethis process, they typically annotate cells independently, without consideringbatch-level cellular context or providing explanatory reasoning. In contrast,human experts often annotate distinct cell types for different cell clustersbased on their domain knowledge. To mimic this workflow, we introduce theCellPuzzles task, where the objective is to assign unique cell types to a batchof cells. This benchmark spans diverse tissues, diseases, and donor conditions,and requires reasoning across the batch-level cellular context to ensure labeluniqueness. We find that off-the-shelf large language models (LLMs) struggle onCellPuzzles, with the best baseline (OpenAI's o1) achieving only 19.0%batch-level accuracy. To fill this gap, we propose Cell-o1, a 7B LLM trainedvia supervised fine-tuning on distilled reasoning traces, followed byreinforcement learning with batch-level rewards. Cell-o1 achievesstate-of-the-art performance, outperforming o1 by over 73% and generalizingwell across contexts. Further analysis of training dynamics and reasoningbehaviors provides insights into batch-level annotation performance andemergent expert-like reasoning. Code and data are available athttps://github.com/ncbi-nlp/cell-o1.</description>
      <author>example@mail.com (Yin Fang, Qiao Jin, Guangzhi Xiong, Bowen Jin, Xianrui Zhong, Siru Ouyang, Aidong Zhang, Jiawei Han, Zhiyong Lu)</author>
      <guid isPermaLink="false">2506.02911v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>FDSG: Forecasting Dynamic Scene Graphs</title>
      <link>http://arxiv.org/abs/2506.01487v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 9 figures, 15 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FDSG的新框架，用于预测动态场景图，该框架能够预测未来帧中的实体标签、边界框和关系，同时为已观察到的帧生成场景图。&lt;h4&gt;背景&lt;/h4&gt;现有的场景图生成方法要么从观察到的帧中生成场景图而不显式建模时间动态，要么仅预测关系而假设静态实体标签和位置。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法的限制，有效预测实体和关系的动态，促进视频场景理解。&lt;h4&gt;方法&lt;/h4&gt;FDSG利用查询分解和神经网络随机微分方程来建模实体和关系的动态，并通过时间聚合模块通过交叉注意力整合预测和观察到的信息。&lt;h4&gt;主要发现&lt;/h4&gt;在Action Genome上的实验表明，FDSG在动态场景图生成、场景图预测和场景图预测方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;FDSG是一个有效的动态场景图预测框架，能够显著提高视频场景理解的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic scene graph generation extends scene graph generation from images tovideos by modeling entity relationships and their temporal evolution. However,existing methods either generate scene graphs from observed frames withoutexplicitly modeling temporal dynamics, or predict only relationships whileassuming static entity labels and locations. These limitations hinder effectiveextrapolation of both entity and relationship dynamics, restricting video sceneunderstanding. We propose Forecasting Dynamic Scene Graphs (FDSG), a novelframework that predicts future entity labels, bounding boxes, andrelationships, for unobserved frames, while also generating scene graphs forobserved frames. Our scene graph forecast module leverages query decompositionand neural stochastic differential equations to model entity and relationshipdynamics. A temporal aggregation module further refines predictions byintegrating forecasted and observed information via cross-attention. Tobenchmark FDSG, we introduce Scene Graph Forecasting, a new task for fullfuture scene graph prediction. Experiments on Action Genome show that FDSGoutperforms state-of-the-art methods on dynamic scene graph generation, scenegraph anticipation, and scene graph forecasting. Codes will be released uponpublication.</description>
      <author>example@mail.com (Yi Yang, Yuren Cong, Hao Cheng, Bodo Rosenhahn, Michael Ying Yang)</author>
      <guid isPermaLink="false">2506.01487v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Graph neural network model for the era of large atomistic models</title>
      <link>http://arxiv.org/abs/2506.01686v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为DPA3的多层图神经网络，该网络基于线图序列（LiGS），旨在大规模原子模型（LAMs）时代进行广泛应用。DPA3模型遵循可扩展性法则，在多个基准案例中显示出优越的准确性。&lt;h4&gt;背景&lt;/h4&gt;大规模原子模型（LAMs）旨在用密度泛函理论（DFT）普遍表示原子系统的基态势能面。可扩展性法则在大型模型的发展中至关重要，表明随着模型规模的增加、训练数据集的扩展和计算预算的增大，其泛化能力不断提高。&lt;h4&gt;目的&lt;/h4&gt;开发一种适用于LAMs时代的多任务训练模型DPA3，以在多种基准案例中实现高精度。&lt;h4&gt;方法&lt;/h4&gt;DPA3基于线图序列（LiGS）构建，通过堆叠额外层来增加模型参数的可扩展性，并采用一种数据集编码机制，在多任务训练框架中将训练数据规模的扩展与模型规模分离。&lt;h4&gt;主要发现&lt;/h4&gt;DPA3模型的泛化误差遵循可扩展性法则，作为问题导向的势能模型，在多数基准案例中显示出优越的准确性。在OpenLAM-v1数据集上训练的DPA-3.1-3M模型在LAMBench基准套件中表现出最先进的性能，展现出最低的整体零样本泛化误差。&lt;h4&gt;结论&lt;/h4&gt;DPA3作为一款开箱即用的潜在模型，在下游科学应用中需要最小的微调数据，表现出优异的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models, or large atomistic models (LAMs), aim to universallyrepresent the ground-state potential energy surface (PES) of atomistic systemsas defined by density functional theory (DFT). The scaling law is pivotal inthe development of large models, suggesting that their generalizability indownstream tasks consistently improves with increased model size, expandedtraining datasets, and larger computational budgets. In this study, we presentDPA3, a multi-layer graph neural network founded on line graph series (LiGS),designed explicitly for the era of LAMs. We demonstrate that the generalizationerror of the DPA3 model adheres to the scaling law. The scalability in thenumber of model parameters is attained by stacking additional layers withinDPA3. Additionally, the model employs a dataset encoding mechanism thatdecouples the scaling of training data size from the model size within itsmulti-task training framework. When trained as problem-oriented potentialenergy models, the DPA3 model exhibits superior accuracy in the majority ofbenchmark cases, encompassing systems with diverse features, includingmolecules, bulk materials, surface and cluster catalysis, two-dimensionalmaterials, and battery materials. When trained as a LAM on the OpenLAM-v1dataset, the DPA-3.1-3M model exhibits state-of-the-art performance in theLAMBench benchmark suit for LAMs, demonstrating lowest overall zero-shotgeneralization error across 17 downstream tasks from a broad spectrum ofresearch domains. This performance suggests superior accuracy as anout-of-the-box potential model, requiring minimal fine-tuning data fordownstream scientific applications.</description>
      <author>example@mail.com (Duo Zhang, Anyang Peng, Chun Cai, Wentao Li, Yuanchang Zhou, Jinzhe Zeng, Mingyu Guo, Chengqian Zhang, Bowen Li, Hong Jiang, Tong Zhu, Weile Jia, Linfeng Zhang, Han Wang)</author>
      <guid isPermaLink="false">2506.01686v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Unpacking Softmax: How Temperature Drives Representation Collapse, Compression, and Generalization</title>
      <link>http://arxiv.org/abs/2506.01562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了softmax函数在塑造模型表示中的关键作用，并引入了rank deficit bias的概念，探讨了softmax动力学在学习和增强模型表现方面的应用。&lt;h4&gt;背景&lt;/h4&gt;softmax函数是深度神经网络的基本构建块，常用于分类任务中的输出分布或transformer架构中的注意力权重。&lt;h4&gt;目的&lt;/h4&gt;研究softmax函数对学习动态和所学表示的影响，以优化模型行为。&lt;h4&gt;方法&lt;/h4&gt;引入rank deficit bias概念，分析softmax函数的logits范数对学习的影响，并演示如何利用softmax动力学来学习压缩表示或提高模型在分布外数据上的性能。&lt;h4&gt;主要发现&lt;/h4&gt;softmax函数可能导致深度网络找到比类别数量低得多的rank的解，这种偏差依赖于softmax函数的logits范数，该范数受超参数的隐式影响或由softmax温度直接修改。&lt;h4&gt;结论&lt;/h4&gt;本文提供了对softmax机制的新见解，使我们可以更好地控制深度神经网络中的表示学习。&lt;h4&gt;翻译&lt;/h4&gt;The softmax function is a fundamental building block of deep neural networks, commonly used to define output distributions in classification tasks or attention weights in transformer architectures. Despite its widespread use and proven effectiveness, its influence on learning dynamics and learned representations remains poorly understood, limiting our ability to optimize model behavior. In this paper, we study the pivotal role of the softmax function in shaping the model's representation. We introduce the concept of rank deficit bias - a phenomenon in which softmax-based deep networks find solutions of rank much lower than the number of classes. This bias depends on the softmax function's logits norm, which is implicitly influenced by hyperparameters or directly modified by softmax temperature. Furthermore, we demonstrate how to exploit the softmax dynamics to learn compressed representations or to enhance their performance on out-of-distribution data. We validate our findings across diverse architectures and real-world datasets, highlighting the broad applicability of temperature tuning in improving model performance. Our work provides new insights into the mechanisms of softmax, enabling better control over representation learning in deep neural networks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The softmax function is a fundamental building block of deep neural networks,commonly used to define output distributions in classification tasks orattention weights in transformer architectures. Despite its widespread use andproven effectiveness, its influence on learning dynamics and learnedrepresentations remains poorly understood, limiting our ability to optimizemodel behavior. In this paper, we study the pivotal role of the softmaxfunction in shaping the model's representation. We introduce the concept ofrank deficit bias - a phenomenon in which softmax-based deep networks findsolutions of rank much lower than the number of classes. This bias depends onthe softmax function's logits norm, which is implicitly influenced byhyperparameters or directly modified by softmax temperature. Furthermore, wedemonstrate how to exploit the softmax dynamics to learn compressedrepresentations or to enhance their performance on out-of-distribution data. Wevalidate our findings across diverse architectures and real-world datasets,highlighting the broad applicability of temperature tuning in improving modelperformance. Our work provides new insights into the mechanisms of softmax,enabling better control over representation learning in deep neural networks.</description>
      <author>example@mail.com (Wojciech Masarczyk, Mateusz Ostaszewski, Tin Sum Cheng, Tomasz Trzciński, Aurelien Lucchi, Razvan Pascanu)</author>
      <guid isPermaLink="false">2506.01562v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>EgoVLM: Policy Optimization for Egocentric Video Understanding</title>
      <link>http://arxiv.org/abs/2506.03097v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Our Code can be found at https://github.com/adityavavre/VidEgoVLM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了EgoVLM，一个针对第一人称视频流进行视觉理解和时空推理的视觉语言模型，并通过强化学习优化提高了模型性能。&lt;h4&gt;背景&lt;/h4&gt;随着可穿戴相机和自主代理等新兴的具身人工智能应用的发展，对从第一人称视频流中进行稳健推理的需求日益凸显。&lt;h4&gt;目的&lt;/h4&gt;设计EgoVLM，以整合视觉理解和时空推理，并使其适用于第一人称视频环境。&lt;h4&gt;方法&lt;/h4&gt;EgoVLM通过Group Relative Policy Optimization（GRPO）进行微调，该方法是一种强化学习方法，旨在使模型输出与人类的推理步骤相一致。同时，直接使用强化学习进行微调，而没有在思维链（CoT）数据上进行任何监督式微调。&lt;h4&gt;主要发现&lt;/h4&gt;EgoVLM在第一人称视频问答基准测试中表现出色，特定领域的训练显著提高了其性能。EgoVLM-3B在EgoSchema基准测试上分别比Qwen2.5-VL 3B和7B模型高出14.33和13.87个准确度点。通过明确生成推理轨迹，EgoVLM增强了可解释性，使其适用于下游应用。此外，引入了一种基于关键帧的新奖励机制，该机制结合了显著帧选择，以指导强化学习优化。&lt;h4&gt;结论&lt;/h4&gt;EgoVLM通过结合视觉语言模型和强化学习，为第一人称视频中的时空推理提供了有效的解决方案，并为未来在时间基础上的具身推理探索开辟了新的途径。&lt;h4&gt;翻译&lt;/h4&gt;We introduce EgoVLM, a vision-language model specifically designed to integrate visual comprehension and spatial-temporal reasoning within egocentric video contexts. EgoVLM is fine-tuned via Group Relative Policy Optimization (GRPO), a reinforcement learning method adapted to align model outputs with human-like reasoning steps. Following DeepSeek R1-Zero's approach, we directly tune using RL without any supervised fine-tuning phase on chain-of-thought (CoT) data. We evaluate EgoVLM on egocentric video question answering benchmarks and show that domain-specific training substantially improves performance over general-purpose VLMs. Our EgoVLM-3B, trained exclusively on non-CoT egocentric data, outperforms the base Qwen2.5-VL 3B and 7B models by 14.33 and 13.87 accuracy points on the EgoSchema benchmark, respectively. By explicitly generating reasoning traces, EgoVLM enhances interpretability, making it well-suited for downstream applications. Furthermore, we introduce a novel keyframe-based reward that incorporates salient frame selection to guide reinforcement learning optimization. This reward formulation opens a promising avenue for future exploration in temporally grounded egocentric reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emerging embodied AI applications, such as wearable cameras and autonomousagents, have underscored the need for robust reasoning from first person videostreams. We introduce EgoVLM, a vision-language model specifically designed tointegrate visual comprehension and spatial-temporal reasoning within egocentricvideo contexts. EgoVLM is fine-tuned via Group Relative Policy Optimization(GRPO), a reinforcement learning method adapted to align model outputs withhuman-like reasoning steps. Following DeepSeek R1-Zero's approach, we directlytune using RL without any supervised fine-tuning phase on chain-of-thought(CoT) data. We evaluate EgoVLM on egocentric video question answeringbenchmarks and show that domain-specific training substantially improvesperformance over general-purpose VLMs. Our EgoVLM-3B, trained exclusively onnon-CoT egocentric data, outperforms the base Qwen2.5-VL 3B and 7B models by14.33 and 13.87 accuracy points on the EgoSchema benchmark, respectively. Byexplicitly generating reasoning traces, EgoVLM enhances interpretability,making it well-suited for downstream applications. Furthermore, we introduce anovel keyframe-based reward that incorporates salient frame selection to guidereinforcement learning optimization. This reward formulation opens a promisingavenue for future exploration in temporally grounded egocentric reasoning.</description>
      <author>example@mail.com (Ashwin Vinod, Shrey Pandit, Aditya Vavre, Linshen Liu)</author>
      <guid isPermaLink="false">2506.03097v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning for Efficient Transaction Validation in UTXO-based Blockchains</title>
      <link>http://arxiv.org/abs/2506.01614v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种适用于UTXO型区块链（如比特币）的可扩展性机器学习（ML）方法，以优化UTXO集分片和交易路由，从而提升交易处理速度和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;现有的UTXO集分片方法在有效分配UTXO到验证者之间以及处理由于子父交易依赖产生的通信开销方面存在困难，这会显著降低交易处理速度。&lt;h4&gt;目的&lt;/h4&gt;提出一种机器学习方法，旨在优化UTXO集分片和交易路由，确保交易被路由到包含其父UTXO的分区，以提升交易处理速度和区块链的可扩展性。&lt;h4&gt;方法&lt;/h4&gt;该方法的核心是一个结合对比学习和无监督学习的框架，用于创建交易输出的嵌入空间。模型通过三元组损失和在线半硬负样本挖掘在历史交易数据上训练，将父-子消费模式直接嵌入其参数中。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够根据消费关系对交易输出进行分组，从而有效地将交易路由到正确的验证微服务，同时减少了跨分片通信开销。&lt;h4&gt;结论&lt;/h4&gt;该方法显著减少了跨分片通信开销，提高了吞吐量和可扩展性，避免了昂贵的实时父交易查找。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种适用于比特币等UTXO型区块链的可扩展性机器学习方法。先前关于UTXO集分片的方法在有效分配UTXO到验证者以及由于子父交易依赖产生的通信开销方面存在困难，这会显著阻碍交易处理速度。我们的解决方案使用机器学习来优化不仅UTXO集分片还包括交易路由，确保交易被路由到包含其父UTXO的分区。我们的方法的核心是一个结合对比学习和无监督学习的框架，用于创建交易输出的嵌入空间。这种嵌入允许模型根据消费关系对交易输出进行分组，从而能够有效地将交易路由到正确的验证微服务。该模型在历史交易数据上使用三元组损失和在线半硬负样本挖掘进行训练，将父-子消费模式直接嵌入其参数中，从而消除了昂贵的实时父交易查找的需要。这显著减少了跨分片通信开销，提高了吞吐量和可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a Machine Learning (ML) approach for scalability ofUTXO-based blockchains, such as Bitcoin. Prior approaches to UTXO set shardingstruggle with distributing UTXOs effectively across validators, creatingsubstantial communication overhead due to child-parent transactiondependencies. This overhead, which arises from the need to locate parent UTXOs,significantly hampers transaction processing speeds. Our solution uses ML tooptimize not only UTXO set sharding but also the routing of incomingtransactions, ensuring that transactions are directed to shards containingtheir parent UTXOs. At the heart of our approach is a framework that combinescontrastive and unsupervised learning to create an embedding space fortransaction outputs. This embedding allows the model to group transactionoutputs based on spending relationships, making it possible to routetransactions efficiently to the correct validation microservices. Trained onhistorical transaction data with triplet loss and online semi-hard negativemining, the model embeds parent-child spending patterns directly into itsparameters, thus eliminating the need for costly, real-time parent transactionlookups. This significantly reduces cross-shard communication overhead,boosting throughput and scalability.</description>
      <author>example@mail.com (Hamid Attar, Luigi Lunardon, Alessio Pagani)</author>
      <guid isPermaLink="false">2506.01614v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Learning Sparsity for Effective and Efficient Music Performance Question Answering</title>
      <link>http://arxiv.org/abs/2506.01319v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the main conference of the 63rd Annual Meeting of the  Association for Computational Linguistics (ACL 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对音乐表演中的多模态场景理解和推理的挑战，提出了一种名为Sparsify的稀疏学习框架，以提高音乐表演音频-视觉问答（Music AVQA）的性能和数据效率。&lt;h4&gt;背景&lt;/h4&gt;音乐表演具有密集连续的音频和无缝的音频-视觉集成，这对多模态场景理解和推理提出了独特挑战。&lt;h4&gt;目的&lt;/h4&gt;提出更有效的音频-视觉表示集成方法，提高Music AVQA的性能和数据效率。&lt;h4&gt;方法&lt;/h4&gt;Sparsify框架集成了三种稀疏化策略，并在Music AVQA数据集上实现了最先进的性能。此外，它通过选择和利用大约25%的MUSIC-AVQA v2.0训练数据，同时保持70-80%的全数据性能，来提高数据效率。&lt;h4&gt;主要发现&lt;/h4&gt;Sparsify在Music AVQA数据集上实现了最先进的性能，同时将训练时间减少了28.32%，保持了准确性。&lt;h4&gt;结论&lt;/h4&gt;Sparsify框架有效地提高了Music AVQA的性能和数据效率，为处理音乐表演中的多模态场景理解和推理提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Music performances, characterized by dense and continuous audio as well as seamless audio-visual integration, present unique challenges for multimodal scene understanding and reasoning. Recent Music Performance Audio-Visual Question Answering (Music AVQA) datasets have been proposed to reflect these challenges, highlighting the continued need for more effective integration of audio-visual representations in complex question answering. However, existing Music AVQA methods often rely on dense and unoptimized representations, leading to inefficiencies in the isolation of key information, the reduction of redundancy, and the prioritization of critical samples. To address these challenges, we introduce Sparsify, a sparse learning framework specifically designed for Music AVQA. It integrates three sparsification strategies into an end-to-end pipeline and achieves state-of-the-art performance on the Music AVQA datasets. In addition, it reduces training time by 28.32% compared to its fully trained dense counterpart while maintaining accuracy, demonstrating clear efficiency gains. To further improve data efficiency, we propose a key-subset selection algorithm that selects and uses approximately 25% of MUSIC-AVQA v2.0 training data and retains 70-80% of full-data performance across models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Music performances, characterized by dense and continuous audio as well asseamless audio-visual integration, present unique challenges for multimodalscene understanding and reasoning. Recent Music Performance Audio-VisualQuestion Answering (Music AVQA) datasets have been proposed to reflect thesechallenges, highlighting the continued need for more effective integration ofaudio-visual representations in complex question answering. However, existingMusic AVQA methods often rely on dense and unoptimized representations, leadingto inefficiencies in the isolation of key information, the reduction ofredundancy, and the prioritization of critical samples. To address thesechallenges, we introduce Sparsify, a sparse learning framework specificallydesigned for Music AVQA. It integrates three sparsification strategies into anend-to-end pipeline and achieves state-of-the-art performance on the Music AVQAdatasets. In addition, it reduces training time by 28.32% compared to its fullytrained dense counterpart while maintaining accuracy, demonstrating clearefficiency gains. To further improve data efficiency, we propose a key-subsetselection algorithm that selects and uses approximately 25% of MUSIC-AVQA v2.0training data and retains 70-80% of full-data performance across models.</description>
      <author>example@mail.com (Xingjian Diao, Tianzhen Yang, Chunhui Zhang, Weiyi Wu, Ming Cheng, Jiang Gui)</author>
      <guid isPermaLink="false">2506.01319v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Understanding and Improving Laplacian Positional Encodings For Temporal GNNs</title>
      <link>http://arxiv.org/abs/2506.01596v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ECML-PKDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了时间图学习在推荐系统、交通预测和社会网络分析中的应用，针对时间图中位置编码的进展有限的问题，提出了一种理论框架，并引入了新的方法来减少计算开销，同时进行了一系列实验研究。&lt;h4&gt;背景&lt;/h4&gt;时间图学习在多个领域有应用，但时间图中位置编码的进展有限，现有方法存在计算成本高、理论理解有限和编码应用不明确等问题。&lt;h4&gt;目的&lt;/h4&gt;解决时间图中位置编码的挑战，提高计算效率，并研究不同模型和任务中位置编码的有效性。&lt;h4&gt;方法&lt;/h4&gt;提出一个理论框架连接超拉普拉斯编码和时间切片编码，引入新的方法降低计算开销，并进行了广泛的实验研究。&lt;h4&gt;主要发现&lt;/h4&gt;位置编码在特定场景下可以显著提高性能，但其有效性在不同模型中存在差异。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和理论框架有助于推动时间图学习的发展，并提供了关于位置编码有效性的重要见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal graph learning has applications in recommendation systems, trafficforecasting, and social network analysis. Although multiple architectures havebeen introduced, progress in positional encoding for temporal graphs remainslimited. Extending static Laplacian eigenvector approaches to temporal graphsthrough the supra-Laplacian has shown promise, but also poses key challenges:high eigendecomposition costs, limited theoretical understanding, and ambiguityabout when and how to apply these encodings. In this paper, we address theseissues by (1) offering a theoretical framework that connects supra-Laplacianencodings to per-time-slice encodings, highlighting the benefits of leveragingadditional temporal connectivity, (2) introducing novel methods to reduce thecomputational overhead, achieving up to 56x faster runtimes while scaling tographs with 50,000 active nodes, and (3) conducting an extensive experimentalstudy to identify which models, tasks, and datasets benefit most from theseencodings. Our findings reveal that while positional encodings cansignificantly boost performance in certain scenarios, their effectivenessvaries across different models.</description>
      <author>example@mail.com (Yaniv Galron, Fabrizio Frasca, Haggai Maron, Eran Treister, Moshe Eliasof)</author>
      <guid isPermaLink="false">2506.01596v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Deep learning of thermodynamic laws from microscopic dynamics</title>
      <link>http://arxiv.org/abs/2506.01506v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究通过数值模拟证明了深度神经网络可以从微观数据中学习宏观热力学定律。&lt;h4&gt;背景&lt;/h4&gt;使用分子动力学模拟生成气体粒子在绝热过程中的快照图像数据。&lt;h4&gt;目的&lt;/h4&gt;训练深度神经网络以确定输入图像对的时序顺序。&lt;h4&gt;方法&lt;/h4&gt;观察训练后的网络是否能在状态之间诱导出与绝热可及性一致的关系，并满足热力学的公理。&lt;h4&gt;主要发现&lt;/h4&gt;训练的神经网络学习到的内部表示可以作为熵，表明机器学习可以揭示在比基本组成部分大的尺度上有效的涌现物理定律。&lt;h4&gt;结论&lt;/h4&gt;这些结果为数据驱动发现宏观物理学开辟了途径。&lt;h4&gt;翻译&lt;/h4&gt;我们通过数值模拟表明，深度神经网络可以从微观数据中纯学习宏观热力学定律。利用分子动力学模拟，我们生成了气体粒子经历绝热过程的快照图像数据。我们训练一个深度神经网络来确定输入图像对的时序顺序。我们观察到，训练后的网络在状态之间诱导出与绝热可及性一致的关系，满足热力学的公理。此外，深度神经网络学习到的内部表示作为熵。这些结果表明，机器学习可以揭示在比基本组成部分大的尺度上有效的涌现物理定律——为数据驱动发现宏观物理学开辟了途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We numerically show that a deep neural network (DNN) can learn macroscopicthermodynamic laws purely from microscopic data. Using molecular dynamicssimulations, we generate the data of snapshot images of gas particlesundergoing adiabatic processes. We train a DNN to determine the temporal orderof input image pairs. We observe that the trained network induces an orderrelation between states consistent with adiabatic accessibility, satisfying theaxioms of thermodynamics. Furthermore, the internal representation learned bythe DNN act as an entropy. These results suggest that machine learning candiscover emergent physical laws that are valid at scales far larger than thoseof the underlying constituents -- opening a pathway to data-driven discovery ofmacroscopic physics.</description>
      <author>example@mail.com (Hiroto Kuroyanagi, Tatsuro Yuge)</author>
      <guid isPermaLink="false">2506.01506v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>HaploOmni: Unified Single Transformer for Multimodal Video Understanding and Generation</title>
      <link>http://arxiv.org/abs/2506.02975v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种高效训练范式，用于构建用于统一多模态理解和生成的单个Transformer模型。&lt;h4&gt;背景&lt;/h4&gt;随着语言模型的发展，统一的多模态理解和生成在模型架构从分离的组件发展到统一的单模型框架方面取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;旨在通过提出一种多模态预热策略和解决跨模态兼容性挑战的方法，来构建一个能够高效训练的统一多模态理解和生成模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一种多模态预热策略，利用先验知识扩展模型能力，并引入了特征预缩放和多模态AdaLN技术来解决跨模态兼容性问题。&lt;h4&gt;主要发现&lt;/h4&gt;整合所提出的技术，创建了HaploOmni，这是一种新的单模态Transformer。HaploOmni在有限的训练成本下，在多个图像和视频理解和生成基准测试中实现了与先进统一模型相竞争的性能。&lt;h4&gt;结论&lt;/h4&gt;所有代码将在https://github.com/Tencent/HaploVLM上公开，以供进一步的研究和验证。&lt;h4&gt;翻译&lt;/h4&gt;With the advancement of language models, unified multimodal understanding and generation have made significant strides, with model architectures evolving from separated components to unified single-model frameworks. This paper explores an efficient training paradigm to build a single transformer for unified multimodal understanding and generation. Specifically, we propose a multimodal warmup strategy utilizing prior knowledge to extend capabilities. To address cross-modal compatibility challenges, we introduce feature pre-scaling and multimodal AdaLN techniques. Integrating the proposed technologies, we present the HaploOmni, a new single multimodal transformer. With limited training costs, HaploOmni achieves competitive performance across multiple image and video understanding and generation benchmarks over advanced unified models. All codes will be made public at https://github.com/Tencent/HaploVLM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the advancement of language models, unified multimodal understanding andgeneration have made significant strides, with model architectures evolvingfrom separated components to unified single-model frameworks. This paperexplores an efficient training paradigm to build a single transformer forunified multimodal understanding and generation. Specifically, we propose amultimodal warmup strategy utilizing prior knowledge to extend capabilities. Toaddress cross-modal compatibility challenges, we introduce feature pre-scalingand multimodal AdaLN techniques. Integrating the proposed technologies, wepresent the HaploOmni, a new single multimodal transformer. With limitedtraining costs, HaploOmni achieves competitive performance across multipleimage and video understanding and generation benchmarks over advanced unifiedmodels. All codes will be made public at https://github.com/Tencent/HaploVLM.</description>
      <author>example@mail.com (Yicheng Xiao, Lin Song, Rui Yang, Cheng Cheng, Zunnan Xu, Zhaoyang Zhang, Yixiao Ge, Xiu Li, Ying Shan)</author>
      <guid isPermaLink="false">2506.02975v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>SemiVT-Surge: Semi-Supervised Video Transformer for Surgical Phase Recognition</title>
      <link>http://arxiv.org/abs/2506.01471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视频转换器的模型，用于半监督学习在手术阶段识别中的应用，通过结合未标记数据和标签数据进行特征空间优化，显著提高了手术视频分析的准确性。&lt;h4&gt;背景&lt;/h4&gt;准确识别手术阶段对于计算机辅助手术和手术视频分析至关重要，但手动标注手术视频工作量大，促使研究转向利用未标记数据以减少标注的工作量。&lt;h4&gt;目的&lt;/h4&gt;提出一种半监督学习方法，以在手术视频分析中利用未标记数据，实现高准确率。&lt;h4&gt;方法&lt;/h4&gt;该方法包括一个鲁棒的伪标签框架，结合了时间一致性正则化和带有类别原型的对比学习，以利用标记数据和伪标签来优化特征空间。&lt;h4&gt;主要发现&lt;/h4&gt;在RAMIE数据集上，通过结合未标记数据，该方法实现了4.9%的准确率提升，在Cholec80数据集上使用1/4的标记数据即获得了与全监督方法相当的结果。&lt;h4&gt;结论&lt;/h4&gt;该方法为半监督手术阶段识别建立了一个强大的基准，为该领域未来的研究铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;Accurate surgical phase recognition is crucial for computer-assisted interventions and surgical video analysis. Annotating long surgical videos is labor-intensive, driving research toward leveraging unlabeled data for strong performance with minimal annotations. Although self-supervised learning has gained popularity by enabling large-scale pretraining followed by fine-tuning on small labeled subsets, semi-supervised approaches remain largely underexplored in the surgical domain. In this work, we propose a video transformer-based model with a robust pseudo-labeling framework. Our method incorporates temporal consistency regularization for unlabeled data and contrastive learning with class prototypes, which leverages both labeled data and pseudo-labels to refine the feature space. Through extensive experiments on the private RAMIE (Robot-Assisted Minimally Invasive Esophagectomy) dataset and the public Cholec80 dataset, we demonstrate the effectiveness of our approach. By incorporating unlabeled data, we achieve state-of-the-art performance on RAMIE with a 4.9% accuracy increase and obtain comparable results to full supervision while using only 1/4 of the labeled data on Cholec80. Our findings establish a strong benchmark for semi-supervised surgical phase recognition, paving the way for future research in this domain.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate surgical phase recognition is crucial for computer-assistedinterventions and surgical video analysis. Annotating long surgical videos islabor-intensive, driving research toward leveraging unlabeled data for strongperformance with minimal annotations. Although self-supervised learning hasgained popularity by enabling large-scale pretraining followed by fine-tuningon small labeled subsets, semi-supervised approaches remain largelyunderexplored in the surgical domain. In this work, we propose a videotransformer-based model with a robust pseudo-labeling framework. Our methodincorporates temporal consistency regularization for unlabeled data andcontrastive learning with class prototypes, which leverages both labeled dataand pseudo-labels to refine the feature space. Through extensive experiments onthe private RAMIE (Robot-Assisted Minimally Invasive Esophagectomy) dataset andthe public Cholec80 dataset, we demonstrate the effectiveness of our approach.By incorporating unlabeled data, we achieve state-of-the-art performance onRAMIE with a 4.9% accuracy increase and obtain comparable results to fullsupervision while using only 1/4 of the labeled data on Cholec80. Our findingsestablish a strong benchmark for semi-supervised surgical phase recognition,paving the way for future research in this domain.</description>
      <author>example@mail.com (Yiping Li, Ronald de Jong, Sahar Nasirihaghighi, Tim Jaspers, Romy van Jaarsveld, Gino Kuiper, Richard van Hillegersberg, Fons van der Sommen, Jelle Ruurda, Marcel Breeuwer, Yasmina Al Khalil)</author>
      <guid isPermaLink="false">2506.01471v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Sheep Facial Pain Assessment Under Weighted Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.01468v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2025 19th International Conference on Automatic Face and Gesture  Recognition (FG)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的加权图神经网络（WGNN）模型，用于识别和评估羊的疼痛程度，并构建了一个新的羊面部特征数据集，以提高羊疼痛检测的准确性。&lt;h4&gt;背景&lt;/h4&gt;准确识别和评估羊的疼痛对于动物健康和减轻有害情况至关重要，但现有的自动监测疼痛的能力有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来链接羊的面部特征和定义疼痛水平，以准确评估羊的健康状态。&lt;h4&gt;方法&lt;/h4&gt;研究分析了羊的面部表情，并提出了一个新的加权图神经网络（WGNN）模型，以及一个符合羊面部表情量表（SPFES）参数的羊面部特征数据集。&lt;h4&gt;主要发现&lt;/h4&gt;YOLOv8n检测器在羊面部特征数据集上实现了59.30%的平均精度（mAP），在七个其他检测模型中表现最佳。WGNN框架在YOLOv8n轻量级设备上部署时，对多个面部部位表情的跟踪准确率达到92.71%。&lt;h4&gt;结论&lt;/h4&gt;面部特征检测和疼痛水平预测对于评估羊的健康状态至关重要，而WGNN模型在羊面部特征数据上的应用具有很高的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Accurately recognizing and assessing pain in sheep is key to discern animal health and mitigating harmful situations. However, such accuracy is limited by the ability to manage automatic monitoring of pain in those animals. Facial expression scoring is a widely used and useful method to evaluate pain in both humans and other living beings. Researchers also analyzed the facial expressions of sheep to assess their health state and concluded that facial landmark detection and pain level prediction are essential. For this purpose, we propose a novel weighted graph neural network (WGNN) model to link sheep's detected facial landmarks and define pain levels. Furthermore, we propose a new sheep facial landmarks dataset that adheres to the parameters of the Sheep Facial Expression Scale (SPFES). Currently, there is no comprehensive performance benchmark that specifically evaluates the use of graph neural networks (GNNs) on sheep facial landmark data to detect and measure pain levels. The YOLOv8n detector architecture achieves a mean average precision (mAP) of 59.30% with the sheep facial landmarks dataset, among seven other detection models. The WGNN framework has an accuracy of 92.71% for tracking multiple facial parts expressions with the YOLOv8n lightweight on-board device deployment-capable model.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately recognizing and assessing pain in sheep is key to discern animalhealth and mitigating harmful situations. However, such accuracy is limited bythe ability to manage automatic monitoring of pain in those animals. Facialexpression scoring is a widely used and useful method to evaluate pain in bothhumans and other living beings. Researchers also analyzed the facialexpressions of sheep to assess their health state and concluded that faciallandmark detection and pain level prediction are essential. For this purpose,we propose a novel weighted graph neural network (WGNN) model to link sheep'sdetected facial landmarks and define pain levels. Furthermore, we propose a newsheep facial landmarks dataset that adheres to the parameters of the SheepFacial Expression Scale (SPFES). Currently, there is no comprehensiveperformance benchmark that specifically evaluates the use of graph neuralnetworks (GNNs) on sheep facial landmark data to detect and measure painlevels. The YOLOv8n detector architecture achieves a mean average precision(mAP) of 59.30% with the sheep facial landmarks dataset, among seven otherdetection models. The WGNN framework has an accuracy of 92.71% for trackingmultiple facial parts expressions with the YOLOv8n lightweight on-board devicedeployment-capable model.</description>
      <author>example@mail.com (Alam Noor, Luis Almeida, Mohamed Daoudi, Kai Li, Eduardo Tovar)</author>
      <guid isPermaLink="false">2506.01468v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MobCLIP: Learning General-purpose Geospatial Representation at Scale</title>
      <link>http://arxiv.org/abs/2506.01297v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MobCLIP是一个全国范围内的通用目的位置编码器，通过有效且可扩展的多模态融合，集成了前所未有的数据多样性。&lt;h4&gt;背景&lt;/h4&gt;当前嵌入方法在实现通用地理空间智能方面仍然是一个核心挑战，它们通常缺乏通用性，限制了它们在人类和自然领域的多样化任务中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出MobCLIP，旨在构建一个能够处理多种数据模式并应用于不同任务的通用位置编码器。&lt;h4&gt;方法&lt;/h4&gt;采用基于CLIP的新型架构，MobCLIP将100M+的POI、全国范围的遥感影像和结构化人口统计数据与一个包含十亿条边的移动性图进行对齐。通过将空间位置划分为灵感来自Vision Transformers的网格单元，建立了连接移动模式和多模态特征的统一表示空间。&lt;h4&gt;主要发现&lt;/h4&gt;MobCLIP在具有四个输入模态和紧凑的128维表示空间的帮助下，在11个下游预测任务上（涵盖社会、经济和自然领域）实现了比最先进模型平均高出35%的显著更好的通用预测性能。特别是在人类中心任务上，性能提升尤为显著，如能耗预测（+260%）、线下零售消费量预测（+98%）和犯罪案件预测（+95%）。此外，MobCLIP也表现出与LLM扩展法则一致的扩展行为。&lt;h4&gt;结论&lt;/h4&gt;MobCLIP在地理空间表示学习方面展现了强大的能力，通过有效的人本模式集成，在多个领域取得了显著的性能提升，并证明了其扩展潜力。&lt;h4&gt;翻译&lt;/h4&gt;Representation learning of geospatial locations remains a core challenge in achieving general geospatial intelligence. Current embedding methods often lack versatility, limiting their utility across diverse tasks in both human and natural domains. We present MobCLIP, the first nationwide general-purpose location encoder, integrating an unprecedented diversity of data modalities through effective and scalable multimodal fusion. Adopting a novel CLIP-based architecture, our framework aligns 100M+ POIs, nationwide remote sensing imagery, and structured demographic statistics with a billion-edge mobility graph. By tokenizing spatial locations into grid cells inspired by Vision Transformers, we establish a unified representation space bridging mobility patterns and multimodal features. To rigorously evaluate the general-purpose effectiveness of MobCLIP, we construct a benchmark dataset composed of 11 downstream prediction tasks across social, economic, and natural domains. Experiments show that MobCLIP, with four input modalities and a compact 128-dimensional representation space, achieves significantly superior general-purpose predictive performances than state-of-the-art models by an average of 35%. Thanks to the effective integration of human-centric modalities, the performance gain is particularly profound in human-centric tasks, such as energy consumption (+260%), offline retail consumption amount (+98%), and crime cases (+95%) predictions. Echoing LLM scaling laws, we further demonstrate the scaling behavior in geospatial representation learning. We open-source code and pretrained models at: github.com.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning of geospatial locations remains a core challenge inachieving general geospatial intelligence. Current embedding methods often lackversatility, limiting their utility across diverse tasks in both human andnatural domains. We present MobCLIP, the first nationwide general-purposelocation encoder, integrating an unprecedented diversity of data modalitiesthrough effective and scalable multimodal fusion. Adopting a novel CLIP-basedarchitecture, our framework aligns 100M+ POIs, nationwide remote sensingimagery, and structured demographic statistics with a billion-edge mobilitygraph. By tokenizing spatial locations into grid cells inspired by VisionTransformers, we establish a unified representation space bridging mobilitypatterns and multimodal features. To rigorously evaluate the general-purposeeffectiveness of MobCLIP, we construct a benchmark dataset composed of 11downstream prediction tasks across social, economic, and natural domains.Experiments show that MobCLIP, with four input modalities and a compact128-dimensional representation space, achieves significantly superiorgeneral-purpose predictive performances than state-of-the-art models by anaverage of 35%. Thanks to the effective integration of human-centricmodalities, the performance gain is particularly profound in human-centrictasks, such as energy consumption (+260%), offline retail consumption amount(+98%), and crime cases (+95%) predictions. Echoing LLM scaling laws, wefurther demonstrate the scaling behavior in geospatial representation learning.We open-source code and pretrained models at: github.com.</description>
      <author>example@mail.com (Ya Wen, Jixuan Cai, Qiyao Ma, Linyan Li, Xinhua Chen, Chris Webster, Yulun Zhou)</author>
      <guid isPermaLink="false">2506.01297v2</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Perceptual Inductive Bias Is What You Need Before Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.01201v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025. Tianqin Li and Junru Zhao contributed equally to this  work. Due to a formatting error during the CVPR submission, the equal  contribution note was omitted in the official proceedings. This arXiv version  corrects that oversight. The author order follows alphabetical order by last  name&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了Marr的视觉感知理论，提出了一种基于Marr多阶段理论的对象表示学习方法，该方法在视觉处理中优先考虑边界和表面属性的推导，从而提高了收敛速度和最终表示质量。&lt;h4&gt;背景&lt;/h4&gt;Marr的视觉感知理论认为视觉处理是多阶段的，先处理边界和表面属性，再形成语义对象表示。而传统的对比表示学习方法通常跳过这一多阶段过程，直接学习语义表示空间。&lt;h4&gt;目的&lt;/h4&gt;通过利用Marr的多阶段理论，构建边界和表面级别的表示，并在其后进行对象语义的训练，以提高模型的收敛速度和最终表示质量。&lt;h4&gt;方法&lt;/h4&gt;该方法包括两个阶段：首先使用早期视觉处理阶段的感知结构构建边界和表面级别的表示；其次，训练模型以进行对象语义的学习。&lt;h4&gt;主要发现&lt;/h4&gt;该研究发现，该方法在ResNet18上实现了2倍的收敛速度，在语义分割、深度估计和对象识别任务上提高了最终表示质量，并且增强了鲁棒性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;论文提出了在通用对比表示预训练之前添加一个预训练阶段，以进一步优化最终表示质量并减少整体收敛时间，这是通过从人类视觉系统中获取的归纳偏差实现的。&lt;h4&gt;翻译&lt;/h4&gt;David Marr的先导视觉感知理论规定，视觉处理是一个多阶段的过程，优先考虑边界和表面属性的推导，然后再形成语义对象表示。与此相反，对比表示学习框架通常绕过这种明确的阶段性方法，将其目标定义为直接学习对象的语义表示空间。虽然这种方法在一般环境中是有效的，但它牺牲了视觉的归纳偏差，导致收敛速度较慢，并导致学习捷径产生纹理偏差。在本工作中，我们证明了通过利用Marr的多阶段理论——首先使用早期视觉处理阶段的感知结构构建边界和表面级别的表示，然后训练对象语义——可以在ResNet18上实现2倍的收敛速度，在语义分割、深度估计和对象识别上提高最终表示，并增强鲁棒性和泛化能力。总之，我们提出在通用对比表示预训练之前添加一个预训练阶段，通过从人类视觉系统中获取的归纳偏差，进一步优化最终表示质量并减少整体收敛时间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; David Marr's seminal theory of human perception stipulates that visualprocessing is a multi-stage process, prioritizing the derivation of boundaryand surface properties before forming semantic object representations. Incontrast, contrastive representation learning frameworks typically bypass thisexplicit multi-stage approach, defining their objective as the direct learningof a semantic representation space for objects. While effective in generalcontexts, this approach sacrifices the inductive biases of vision, leading toslower convergence speed and learning shortcut resulting in texture bias. Inthis work, we demonstrate that leveraging Marr's multi-stage theory-by firstconstructing boundary and surface-level representations using perceptualconstructs from early visual processing stages and subsequently training forobject semantics-leads to 2x faster convergence on ResNet18, improved finalrepresentations on semantic segmentation, depth estimation, and objectrecognition, and enhanced robustness and out-of-distribution capability.Together, we propose a pretraining stage before the general contrastiverepresentation pretraining to further enhance the final representation qualityand reduce the overall convergence time via inductive bias from human visionsystems.</description>
      <author>example@mail.com (Tianqin Li, Junru Zhao, Dunhan Jiang, Shenghao Wu, Alan Ramirez, Tai Sing Lee)</author>
      <guid isPermaLink="false">2506.01201v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>METok: Multi-Stage Event-based Token Compression for Efficient Long Video Understanding</title>
      <link>http://arxiv.org/abs/2506.02850v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为METok的无需训练的多阶段事件驱动令牌压缩框架，旨在加速视频大型语言模型（VLLMs）的推理，同时保持准确性。&lt;h4&gt;背景&lt;/h4&gt;尽管视频大型语言模型在理解视频内容方面取得了显著进步，但处理长视频仍然具有挑战性，主要是因为计算需求高和视觉数据中的冗余。&lt;h4&gt;目的&lt;/h4&gt;提出METok框架，旨在加速VLLMs的推理过程，同时保持或提高模型的准确性。&lt;h4&gt;方法&lt;/h4&gt;METok通过三个关键阶段逐步消除冗余视觉令牌：1）在视觉编码过程中的事件感知压缩；2）基于语义对齐和事件重要性在预填充阶段进行分层令牌剪枝；3）解码阶段的KV缓存优化以进一步减少内存消耗。&lt;h4&gt;主要发现&lt;/h4&gt;在多个视频基准测试中，METok通过动态选择信息丰富的视觉令牌，在效率和准确性之间实现了最佳权衡。例如，将LongVA-7B与METok结合使用，实现了80.6%的FLOPs减少和93.5%的KV缓存内存节省，同时保持了可比甚至更优的准确性。&lt;h4&gt;结论&lt;/h4&gt;METok框架为VLLMs提供了一种有效的加速方法，同时保持了高准确性，为处理长视频提供了一种可行的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Video Large Language Models (VLLMs) have significantlyenhanced their ability to understand video content. Nonetheless, processinglong videos remains challenging due to high computational demands and theredundancy present in the visual data. In this work, we propose METok, atraining-free, Multi-stage Event-based Token compression framework designed toaccelerate VLLMs' inference while preserving accuracy. METok progressivelyeliminates redundant visual tokens across three critical stages: (1)event-aware compression during vision encoding, (2) hierarchical token pruningin the prefilling stage based on semantic alignment and event importance, and(3) a decoding-stage KV Cache optimization that further reduces memoryconsumption. Our experiments on diverse video benchmarks demonstrate that METokachieves an optimal trade-off between efficiency and accuracy by dynamicallyselecting informative visual tokens. For instance, equipping LongVA-7B withMETok realizes an 80.6% FLOPs reduction and 93.5% KV Cache memory savings, allwhile maintaining comparable or even superior accuracy.</description>
      <author>example@mail.com (Mengyue Wang, Shuo Chen, Kristian Kersting, Volker Tresp, Yunpu Ma)</author>
      <guid isPermaLink="false">2506.02850v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Kernel-based Unsupervised Embedding Alignment for Enhanced Visual Representation in Vision-language Models</title>
      <link>http://arxiv.org/abs/2506.02557v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的基于核的方法，用于将CLIP的视觉表示与DINOv2对齐，以提高下游多模态大语言模型（MLLMs）的性能。&lt;h4&gt;背景&lt;/h4&gt;CLIP等视觉语言模型在视觉和文本表示对齐方面取得了显著成功，但它们的细粒度感知能力有限，导致下游MLLMs性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以增强CLIP视觉表示的感知能力，同时保持与文本嵌入的兼容性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种针对高效随机优化的对齐目标，通过仅对图像进行对齐微调，使视觉编码器与冻结的文本编码器保持兼容，并在零样本对象识别、细粒度空间推理和定位方面表现出显著改进。&lt;h4&gt;主要发现&lt;/h4&gt;对齐后的视觉编码器在零样本对象识别、细粒度空间推理和定位方面有显著提升，下游MLLMs的性能也得到增强。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地提高了CLIP视觉表示的感知能力，并显著提升了下游MLLMs的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉语言模型，如CLIP，在视觉和文本表示对齐方面取得了显著成功，已成为许多多模态大语言模型（MLLMs）如LLaVA和OpenFlamingo的核心组件。然而，许多研究已经指出CLIP的细粒度感知能力有限是一个关键缺点，导致下游MLLMs性能大幅下降。相比之下，以视觉为中心的基础模型如DINOv2在捕捉图像细节方面表现出惊人的能力。在这项工作中，我们提出了一种基于核的新方法，将CLIP的视觉表示与DINOv2对齐，确保生成的嵌入与文本嵌入保持兼容性的同时增强了感知能力。我们的对齐目标是针对高效随机优化设计的。在仅对图像进行对齐微调之后，视觉编码器保持了与冻结的文本编码器的兼容性，并在零样本对象识别、细粒度空间推理和定位方面表现出显著的改进。通过集成对齐的视觉编码器，下游MLLMs也展示了增强的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models, such as CLIP, have achieved significant success inaligning visual and textual representations, becoming essential components ofmany multi-modal large language models (MLLMs) like LLaVA and OpenFlamingo.However, numerous studies have identified CLIP's limited fine-grainedperception as a critical drawback, leading to substantial failures indownstream MLLMs. In contrast, vision-centric foundation models like DINOv2demonstrate remarkable capabilities in capturing fine details from images. Inthis work, we propose a novel kernel-based method to align CLIP's visualrepresentation with that of DINOv2, ensuring that the resulting embeddingsmaintain compatibility with text embeddings while enhancing perceptualcapabilities. Our alignment objective is designed for efficient stochasticoptimization. Following this image-only alignment fine-tuning, the visualencoder retains compatibility with the frozen text encoder and exhibitssignificant improvements in zero-shot object recognition, fine-grained spatialreasoning, and localization. By integrating the aligned visual encoder,downstream MLLMs also demonstrate enhanced performance.</description>
      <author>example@mail.com (Shizhan Gong, Yankai Jiang, Qi Dou, Farzan Farnia)</author>
      <guid isPermaLink="false">2506.02557v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Recent Developments in GNNs for Drug Discovery</title>
      <link>http://arxiv.org/abs/2506.01302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文回顾了图神经网络（GNN）在计算药物发现中的最新发展及其在分子生成、分子性质预测和药物-药物相互作用预测中的作用。&lt;h4&gt;背景&lt;/h4&gt;文章强调了GNN在理解复杂分子模式方面的能力，并探讨了其当前和潜在的应用。&lt;h4&gt;目的&lt;/h4&gt;通过对该领域最新发展的总结，强调GNN的能力，并分类现有基于输入类型和下游应用任务的GNN模型。&lt;h4&gt;方法&lt;/h4&gt;文章首先分析了各种分子表示方法，然后详细讨论并分类了现有GNN模型，并收集了各种应用中常用的基准数据集。&lt;h4&gt;主要发现&lt;/h4&gt;没有明确指出具体的主要发现，但提到总结了该研究领域的共同趋势。&lt;h4&gt;结论&lt;/h4&gt;文章最后简要讨论了GNN在计算药物发现中的发展趋势。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we review recent developments and the role of Graph Neural Networks (GNNs) in computational drug discovery, including molecule generation, molecular property prediction, and drug-drug interaction prediction. By summarizing the most recent developments in this area, we underscore the capabilities of GNNs to comprehend intricate molecular patterns, while exploring both their current and prospective applications. We initiate our discussion by examining various molecular representations, followed by detailed discussions and categorization of existing GNN models based on their input types and downstream application tasks. We also collect a list of commonly used benchmark datasets for a variety of applications. We conclude the paper with brief discussions and summarize common trends in this important research area.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we review recent developments and the role of Graph NeuralNetworks (GNNs) in computational drug discovery, including molecule generation,molecular property prediction, and drug-drug interaction prediction. Bysummarizing the most recent developments in this area, we underscore thecapabilities of GNNs to comprehend intricate molecular patterns, whileexploring both their current and prospective applications. We initiate ourdiscussion by examining various molecular representations, followed by detaileddiscussions and categorization of existing GNN models based on their inputtypes and downstream application tasks. We also collect a list of commonly usedbenchmark datasets for a variety of applications. We conclude the paper withbrief discussions and summarize common trends in this important research area.</description>
      <author>example@mail.com (Zhengyu Fang, Xiaoge Zhang, Anyin Zhao, Xiao Li, Huiyuan Chen, Jing Li)</author>
      <guid isPermaLink="false">2506.01302v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Learning More with Less: Self-Supervised Approaches for Low-Resource Speech Emotion Recognition</title>
      <link>http://arxiv.org/abs/2506.02059v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在低资源语言环境下，利用无监督学习方法提升语音情感识别（SER）的效果。&lt;h4&gt;背景&lt;/h4&gt;尽管深度学习在语音情感识别领域取得了显著进展，但对于低资源语言（LRLs）来说，由于标注数据的稀缺，仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过无监督学习提高低资源语言环境下的语音情感识别性能。&lt;h4&gt;方法&lt;/h4&gt;具体方法包括探究对比学习（CL）和自监督的Bootstrap Your Own Latent（BYOL）来增强跨语言的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;这些方法在乌尔都语、德语和孟加拉语中实现了显著的F1分数提升，分别为10.6%、15.2%和13.9%，证明了它们在低资源语言中的有效性。&lt;h4&gt;结论&lt;/h4&gt;本文的工作为开发面向少数语言、更具包容性、可解释性和鲁棒性的情感识别系统提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;Speech Emotion Recognition (SER) has seen significant progress with deep learning, yet remains challenging for Low-Resource Languages (LRLs) due to the scarcity of annotated data. In this work, we explore unsupervised learning to improve SER in low-resource settings. Specifically, we investigate contrastive learning (CL) and Bootstrap Your Own Latent (BYOL) as self-supervised approaches to enhance cross-lingual generalization. Our methods achieve notable F1 score improvements of 10.6% in Urdu, 15.2% in German, and 13.9% in Bangla, demonstrating their effectiveness in LRLs. Additionally, we analyze model behavior to provide insights on key factors influencing performance across languages, and also highlighting challenges in low-resource SER. This work provides a foundation for developing more inclusive, explainable, and robust emotion recognition systems for underrepresented languages.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech Emotion Recognition (SER) has seen significant progress with deeplearning, yet remains challenging for Low-Resource Languages (LRLs) due to thescarcity of annotated data. In this work, we explore unsupervised learning toimprove SER in low-resource settings. Specifically, we investigate contrastivelearning (CL) and Bootstrap Your Own Latent (BYOL) as self-supervisedapproaches to enhance cross-lingual generalization. Our methods achieve notableF1 score improvements of 10.6% in Urdu, 15.2% in German, and 13.9% in Bangla,demonstrating their effectiveness in LRLs. Additionally, we analyze modelbehavior to provide insights on key factors influencing performance acrosslanguages, and also highlighting challenges in low-resource SER. This workprovides a foundation for developing more inclusive, explainable, and robustemotion recognition systems for underrepresented languages.</description>
      <author>example@mail.com (Ziwei Gong, Pengyuan Shi, Kaan Donbekci, Lin Ai, Run Chen, David Sasu, Zehui Wu, Julia Hirschberg)</author>
      <guid isPermaLink="false">2506.02059v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Multi-View Representation Learning using Vision-Language Model for 3D/4D Facial Expression Recognition</title>
      <link>http://arxiv.org/abs/2506.01203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SMILE-VLM的自监督视觉-语言模型，用于3D/4D面部表情识别，该模型统一了多视图视觉表示学习与自然语言监督，并在多个基准测试中实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;面部表情识别（FER）是情感计算中的基本任务，应用于人机交互、心理健康分析和行为理解。&lt;h4&gt;目的&lt;/h4&gt;提出SMILE-VLM，以实现更鲁棒、语义对齐且视图不变的面部表情嵌入。&lt;h4&gt;方法&lt;/h4&gt;SMILE-VLM通过以下三个核心组件实现：通过Barlow Twins风格的损失实现多视图去相关，视觉-语言对比对齐，以及跨模态冗余最小化。&lt;h4&gt;主要发现&lt;/h4&gt;SMILE-VLM在多个基准测试中取得了最先进的性能，并且将其扩展到4D微表情识别（MER）任务，以识别微妙的情感线索。&lt;h4&gt;结论&lt;/h4&gt;SMILE-VLM不仅超越了现有的无监督方法，而且与监督基线相匹配或超过，为表达性面部行为理解提供了一个可扩展且标注高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Facial expression recognition (FER) is a fundamental task in affectivecomputing with applications in human-computer interaction, mental healthanalysis, and behavioral understanding. In this paper, we propose SMILE-VLM, aself-supervised vision-language model for 3D/4D FER that unifies multiviewvisual representation learning with natural language supervision. SMILE-VLMlearns robust, semantically aligned, and view-invariant embeddings by proposingthree core components: multiview decorrelation via a Barlow Twins-style loss,vision-language contrastive alignment, and cross-modal redundancy minimization.Our framework achieves the state-of-the-art performance on multiple benchmarks.We further extend SMILE-VLM to the task of 4D micro-expression recognition(MER) to recognize the subtle affective cues. The extensive results demonstratethat SMILE-VLM not only surpasses existing unsupervised methods but alsomatches or exceeds supervised baselines, offering a scalable andannotation-efficient solution for expressive facial behavior understanding.</description>
      <author>example@mail.com (Muzammil Behzad)</author>
      <guid isPermaLink="false">2506.01203v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Aligned Contrastive Loss for Long-Tailed Recognition</title>
      <link>http://arxiv.org/abs/2506.01071v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025 DG-EBF Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种对齐对比学习（ACL）算法来解决长尾识别问题。&lt;h4&gt;背景&lt;/h4&gt;多视角训练可以提高性能，但随着视角数量的增加，对比学习并不总是能提高模型的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;设计ACL算法以消除梯度冲突和正负样本间不平衡的吸引和排斥梯度问题。&lt;h4&gt;方法&lt;/h4&gt;通过监督对比学习（SCL）的理论梯度分析，识别了这些潜在问题，并提出了ACL算法。&lt;h4&gt;主要发现&lt;/h4&gt;ACL算法在多个基准测试中表现出强大的性能，并通过在长尾CIFAR、ImageNet、Places和iNaturalist数据集上的实验验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;ACL实现了新的最先进性能。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we propose an Aligned Contrastive Learning (ACL) algorithm to address the long-tailed recognition problem. Our findings indicate that while multi-view training boosts the performance, contrastive learning does not consistently enhance model generalization as the number of views increases. Through theoretical gradient analysis of supervised contrastive learning (SCL), we identify gradient conflicts, and imbalanced attraction and repulsion gradients between positive and negative pairs as the underlying issues. Our ACL algorithm is designed to eliminate these problems and demonstrates strong performance across multiple benchmarks. We validate the effectiveness of ACL through experiments on long-tailed CIFAR, ImageNet, Places, and iNaturalist datasets. Results show that ACL achieves new state-of-the-art performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose an Aligned Contrastive Learning (ACL) algorithm toaddress the long-tailed recognition problem. Our findings indicate that whilemulti-view training boosts the performance, contrastive learning does notconsistently enhance model generalization as the number of views increases.Through theoretical gradient analysis of supervised contrastive learning (SCL),we identify gradient conflicts, and imbalanced attraction and repulsiongradients between positive and negative pairs as the underlying issues. Our ACLalgorithm is designed to eliminate these problems and demonstrates strongperformance across multiple benchmarks. We validate the effectiveness of ACLthrough experiments on long-tailed CIFAR, ImageNet, Places, and iNaturalistdatasets. Results show that ACL achieves new state-of-the-art performance.</description>
      <author>example@mail.com (Jiali Ma, Jiequan Cui, Maeno Kazuki, Lakshmi Subramanian, Karlekar Jayashree, Sugiri Pranata, Hanwang Zhang)</author>
      <guid isPermaLink="false">2506.01071v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>SurgVLM: A Large Vision-Language Model and Systematic Evaluation Benchmark for Surgical Intelligence</title>
      <link>http://arxiv.org/abs/2506.02555v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为SurgVLM的大规模视觉语言基础模型，用于手术智能，旨在解决手术领域智能应用不足的问题。&lt;h4&gt;背景&lt;/h4&gt;现有通用视觉语言模型在手术领域的应用不足，主要原因是缺乏特定领域的监督和高质量的大型手术数据库。&lt;h4&gt;目的&lt;/h4&gt;构建一个能够处理各种手术任务的视觉语言基础模型，并评估其在手术领域的性能。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含超过1.81百万帧图像和7.79百万对话的大规模多模态手术数据库SurgVLM-DB，并基于Qwen2.5-VL构建了SurgVLM模型。对模型进行指令微调，并构建了SurgVLM-Bench基准进行方法评估。&lt;h4&gt;主要发现&lt;/h4&gt;SurgVLM-Bench包含了6个广泛使用的手术领域数据集，覆盖了多个关键下游任务。SurgVLM在不同规模的模型中均表现出良好的性能，并与14个主流的商业视觉语言模型进行了比较。&lt;h4&gt;结论&lt;/h4&gt;SurgVLM在手术领域智能应用中具有潜力，为手术智能的发展提供了新的思路和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have achieved transformative success across biomedicaldomains by enabling holistic understanding of multimodal data. However, theirapplication in surgery remains underexplored. Surgical intelligence presentsunique challenges - requiring surgical visual perception, temporal analysis,and reasoning. Existing general-purpose vision-language models fail to addressthese needs due to insufficient domain-specific supervision and the lack of alarge-scale high-quality surgical database. To bridge this gap, we proposeSurgVLM, one of the first large vision-language foundation models for surgicalintelligence, where this single universal model can tackle versatile surgicaltasks. To enable this, we construct a large-scale multimodal surgical database,SurgVLM-DB, comprising over 1.81 million frames with 7.79 millionconversations, spanning more than 16 surgical types and 18 anatomicalstructures. We unify and reorganize 23 public datasets across 10 surgicaltasks, followed by standardizing labels and doing hierarchical vision-languagealignment to facilitate comprehensive coverage of gradually finer-grainedsurgical tasks, from visual perception, temporal analysis, to high-levelreasoning. Building upon this comprehensive dataset, we propose SurgVLM, whichis built upon Qwen2.5-VL, and undergoes instruction tuning to 10+ surgicaltasks. We further construct a surgical multimodal benchmark, SurgVLM-Bench, formethod evaluation. SurgVLM-Bench consists of 6 popular and widely-used datasetsin surgical domain, covering several crucial downstream tasks. Based onSurgVLM-Bench, we evaluate the performance of our SurgVLM (3 SurgVLM variants:SurgVLM-7B, SurgVLM-32B, and SurgVLM-72B), and conduct comprehensivecomparisons with 14 mainstream commercial VLMs (e.g., GPT-4o, Gemini 2.0 Flash,Qwen2.5-Max).</description>
      <author>example@mail.com (Zhitao Zeng, Zhu Zhuo, Xiaojun Jia, Erli Zhang, Junde Wu, Jiaan Zhang, Yuxuan Wang, Chang Han Low, Jian Jiang, Zilong Zheng, Xiaochun Cao, Yutong Ban, Qi Dou, Yang Liu, Yueming Jin)</author>
      <guid isPermaLink="false">2506.02555v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering</title>
      <link>http://arxiv.org/abs/2506.01174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025 Workshop on 3D-LLM/VLA: Bridging Language, Vision and  Action in 3D Environments&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GraphPad的动态结构化记忆系统，该系统帮助智能体通过API调用调整其任务需求，以提高在场景和任务理解上的表现。&lt;h4&gt;背景&lt;/h4&gt;结构化场景表示是具身智能体的核心组成部分，但在任务规格改变时，传统的预建结构化表示方法可能不足以捕捉关键信息。&lt;h4&gt;目的&lt;/h4&gt;设计GraphPad，以便智能体能够根据任务需求动态调整其结构化记忆。&lt;h4&gt;方法&lt;/h4&gt;GraphPad包含一个可变场景图、一个导航日志和任务特定笔记的草稿板。这些组件共同构成一个动态的工作空间，帮助智能体在场景和任务理解上保持同步。&lt;h4&gt;主要发现&lt;/h4&gt;在OpenEQA基准测试中，GraphPad实现了55.3%的准确率，比使用相同视觉语言模型和仅图像的基线提高了3.0%，且输入帧数减少了五倍。&lt;h4&gt;结论&lt;/h4&gt;GraphPad允许通过在线语言驱动的3D记忆细化，能够在不额外训练或收集数据的情况下提供更具信息量的表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Structured scene representations are a core component of embodied agents,helping to consolidate raw sensory streams into readable, modular, andsearchable formats. Due to their high computational overhead, many approachesbuild such representations in advance of the task. However, when the taskspecifications change, such static approaches become inadequate as they maymiss key objects, spatial relations, and details. We introduce GraphPad, amodifiable structured memory that an agent can tailor to the needs of the taskthrough API calls. It comprises a mutable scene graph representing theenvironment, a navigation log indexing frame-by-frame content, and a scratchpadfor task-specific notes. Together, GraphPad serves as a dynamic workspace thatremains complete, current, and aligned with the agent's immediate understandingof the scene and its task. On the OpenEQA benchmark, GraphPad attains 55.3%, a+3.0% increase over an image-only baseline using the same vision-languagemodel, while operating with five times fewer input frames. These results showthat allowing online, language-driven refinement of 3-D memory yields moreinformative representations without extra training or data collection.</description>
      <author>example@mail.com (Muhammad Qasim Ali, Saeejith Nair, Alexander Wong, Yuchen Cui, Yuhao Chen)</author>
      <guid isPermaLink="false">2506.01174v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025</title>
      <link>http://arxiv.org/abs/2506.02550v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The champion solution for the Ego4D Long-Term Action Anticipation  Challenge at the CVPR EgoVis Workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于Ego4D长期动作预测（LTA）任务的新型三阶段框架。&lt;h4&gt;背景&lt;/h4&gt;受到近期基础模型进展的启发。&lt;h4&gt;目的&lt;/h4&gt;实现长期动作预测。&lt;h4&gt;方法&lt;/h4&gt;包括特征提取、动作识别和长期动作预测三个阶段。使用高性能视觉编码器提取视觉特征，通过Transformer预测动词和名词，并利用动词-名词共现矩阵提高识别准确率。最后，将预测的动词-名词对格式化为文本提示，输入到微调的大型语言模型（LLM）中预测未来动作序列。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在CVPR 2025挑战赛中排名第一，在长期动作预测方面建立了新的基准。&lt;h4&gt;结论&lt;/h4&gt;该框架实现了长期动作预测的新突破。&lt;h4&gt;翻译&lt;/h4&gt;在本报告中，我们提出了一种用于Ego4D长期动作预测（LTA）任务的新型三阶段框架。受近期基础模型进展的启发，我们的方法包括三个阶段：特征提取、动作识别和长期动作预测。首先，使用高性能视觉编码器提取视觉特征。然后，将这些特征输入到Transformer中预测动词和名词，并引入动词-名词共现矩阵以增强识别准确性。最后，将预测的动词-名词对格式化为文本提示，输入到微调的大型语言模型（LLM）中以预测未来的动作序列。我们的框架在CVPR 2025挑战赛中排名第一，在长期动作预测方面建立了新的基准。我们的代码将在https://github.com/CorrineQiu/Ego4D-LTA-Challenge-2025上发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this report, we present a novel three-stage framework developed for theEgo4D Long-Term Action Anticipation (LTA) task. Inspired by recent advances infoundation models, our method consists of three stages: feature extraction,action recognition, and long-term action anticipation. First, visual featuresare extracted using a high-performance visual encoder. The features are thenfed into a Transformer to predict verbs and nouns, with a verb-nounco-occurrence matrix incorporated to enhance recognition accuracy. Finally, thepredicted verb-noun pairs are formatted as textual prompts and input into afine-tuned large language model (LLM) to anticipate future action sequences.Our framework achieves first place in this challenge at CVPR 2025, establishinga new state-of-the-art in long-term action prediction. Our code will bereleased at https://github.com/CorrineQiu/Ego4D-LTA-Challenge-2025.</description>
      <author>example@mail.com (Qiaohui Chu, Haoyu Zhang, Yisen Feng, Meng Liu, Weili Guan, Yaowei Wang, Liqiang Nie)</author>
      <guid isPermaLink="false">2506.02550v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Slow Feature Analysis on Markov Chains from Goal-Directed Behavior</title>
      <link>http://arxiv.org/abs/2506.01145v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;慢特征分析是一种无监督表示学习方法，可以从时间数据中提取缓慢变化的特征，并可用于后续的强化学习。&lt;h4&gt;背景&lt;/h4&gt;通常假设用于学习表示的数据生成行为是一个均匀的随机游走，而较少研究关注使用目标导向行为生成的样本来学习表示。&lt;h4&gt;目的&lt;/h4&gt;通过最优慢特征在遍历马尔可夫链的视角，研究这些差异对理想化设置中的价值函数逼近的影响。&lt;h4&gt;方法&lt;/h4&gt;评估和讨论了三种可能减轻有害缩放效应的校正途径，并考虑了目标回避行为这一特殊情况。&lt;h4&gt;主要发现&lt;/h4&gt;研究揭示了目标导向行为对价值函数逼近的影响，并提出了三种校正方法。&lt;h4&gt;结论&lt;/h4&gt;慢特征分析在强化学习中的适用性，以及通过校正方法来改善价值函数逼近的效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：慢特征分析是一种无监督的表示学习方法，可以从时间数据中提取缓慢变化的特征，并且可以用于后续的强化学习。通常，用于学习表示的数据生成行为假设为一个均匀的随机游走。在强化学习环境中，较少的研究集中在使用目标导向行为生成的样本来学习表示。在空间设置中，目标导向行为通常会导致接近奖励位置和远离奖励位置的状态之间的状态占用显著差异。通过最优慢特征在遍历马尔可夫链的视角，这项工作研究了这些差异对理想化设置中的价值函数逼近的影响。此外，评估和讨论了三种可能缓解有害缩放效应的校正途径。此外，还考虑了目标回避行为这一特殊情况。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Slow Feature Analysis is a unsupervised representation learning method thatextracts slowly varying features from temporal data and can be used as a basisfor subsequent reinforcement learning. Often, the behavior that generates thedata on which the representation is learned is assumed to be a uniform randomwalk. Less research has focused on using samples generated by goal-directedbehavior, as commonly the case in a reinforcement learning setting, to learn arepresentation. In a spatial setting, goal-directed behavior typically leads tosignificant differences in state occupancy between states that are close to areward location and far from a reward location.  Through the perspective of optimal slow features on ergodic Markov chains,this work investigates the effects of these differences on value-functionapproximation in an idealized setting. Furthermore, three correction routes,which can potentially alleviate detrimental scaling effects, are evaluated anddiscussed. In addition, the special case of goal-averse behavior is considered.</description>
      <author>example@mail.com (Merlin Schüler, Eddie Seabrook, Laurenz Wiskott)</author>
      <guid isPermaLink="false">2506.01145v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>ECP-Mamba: An Efficient Multi-scale Self-supervised Contrastive Learning Method with State Space Model for PolSAR Image Classification</title>
      <link>http://arxiv.org/abs/2506.01040v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ECP-Mamba的高效PolSAR图像分类框架，该框架结合了多尺度自监督对比学习和状态空间模型（SSM）骨干网络，解决了现有方法依赖大量标注数据和Transformer架构计算效率低的问题。&lt;h4&gt;背景&lt;/h4&gt;目前基于深度学习的PolSAR图像分类方法存在依赖大量标注数据和Transformer架构计算效率低的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效、资源消耗低的PolSAR图像分类方法。&lt;h4&gt;方法&lt;/h4&gt;ECP-Mamba通过多尺度预测预训练任务来解决标注数据稀缺的问题，并使用简化自蒸馏范式。此外，通过设计螺旋扫描策略，优化了Mamba架构（一种选择性的SSM）的计算效率，并提出了轻量级的Cross Mamba模块以促进多尺度特征之间的互补性。&lt;h4&gt;主要发现&lt;/h4&gt;ECP-Mamba在四个基准数据集上进行了广泛的实验，证明了其在平衡高精度与资源效率方面的有效性。在Flevoland 1989数据集上，ECP-Mamba实现了99.70%的整体准确率、99.64%的平均准确率和0.9962的Kappa系数。&lt;h4&gt;结论&lt;/h4&gt;ECP-Mamba是一种有效的PolSAR图像分类方法，能够平衡高精度和资源效率。&lt;h4&gt;翻译&lt;/h4&gt;Recently, polarimetric synthetic aperture radar (PolSAR) image classification has been greatly promoted by deep neural networks. However, current deep learning-based PolSAR classification methods encounter difficulties due to its dependence on extensive labeled data and the computational inefficiency of architectures like Transformers. This paper presents ECP-Mamba, an efficient framework integrating multi-scale self-supervised contrastive learning with a state space model (SSM) backbone. Specifically, ECP-Mamba addresses annotations scarcity through a multi-scale predictive pretext task based on local-to-global feature correspondences, which uses a simplified self-distillation paradigm without negative sample pairs. To enhance computational efficiency, the Mamba architecture (a selective SSM) is first tailored for pixel-wise PolSAR classification task by designing a spiral scan strategy. This strategy prioritizes causally relevant features near the central pixel, leveraging the localized nature of pixel-wise classification tasks. Additionally, the lightweight Cross Mamba module is proposed to facilitate complementary multi-scale feature interaction with minimal overhead. Extensive experiments across four benchmark datasets demonstrate ECP-Mamba's effectiveness in balancing high accuracy with resource efficiency. On the Flevoland 1989 dataset, ECP-Mamba achieves state-of-the-art performance with an overall accuracy of 99.70%, average accuracy of 99.64% and Kappa coefficient of 99.62e-2. Our code will be available at https://github.com/HaixiaBi1982/ECP_Mamba.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, polarimetric synthetic aperture radar (PolSAR) image classificationhas been greatly promoted by deep neural networks. However,current deeplearning-based PolSAR classification methods encounter difficulties due to itsdependence on extensive labeled data and the computational inefficiency ofarchitectures like Transformers. This paper presents ECP-Mamba, an efficientframework integrating multi-scale self-supervised contrastive learning with astate space model (SSM) backbone. Specifically, ECP-Mamba addresses annotationscarcity through a multi-scale predictive pretext task based on local-to-globalfeature correspondences, which uses a simplified self-distillation paradigmwithout negative sample pairs. To enhance computational efficiency,the Mambaarchitecture (a selective SSM) is first tailored for pixel-wise PolSARclassification task by designing a spiral scan strategy. This strategyprioritizes causally relevant features near the central pixel, leveraging thelocalized nature of pixel-wise classification tasks. Additionally, thelightweight Cross Mamba module is proposed to facilitates complementarymulti-scale feature interaction with minimal overhead. Extensive experimentsacross four benchmark datasets demonstrate ECP-Mamba's effectiveness inbalancing high accuracy with resource efficiency. On the Flevoland 1989dataset, ECP-Mamba achieves state-of-the-art performance with an overallaccuracy of 99.70%, average accuracy of 99.64% and Kappa coefficient of99.62e-2. Our code will be available athttps://github.com/HaixiaBi1982/ECP_Mamba.</description>
      <author>example@mail.com (Zuzheng Kuang, Haixia Bi, Chen Xu, Jian Sun)</author>
      <guid isPermaLink="false">2506.01040v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Towards Efficient Few-shot Graph Neural Architecture Search via Partitioning Gradient Contribution</title>
      <link>http://arxiv.org/abs/2506.01231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGKDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对权重耦合问题，提出了一种新的方法，即Gradient Contribution（GC）方法，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;某些研究引入了少样本神经架构搜索（NAS）方法来解决权重耦合问题，但这些方法通常计算效率低，且提供的分区方案不理想。&lt;h4&gt;目的&lt;/h4&gt;为了更有效地解决这个问题，本文从新的角度分析了权重耦合问题，并提出了GC方法以及Unified Graph Neural Architecture Search（UGAS）框架。&lt;h4&gt;方法&lt;/h4&gt;GC方法通过分解超网络反向传播过程中的向量-雅可比乘积，高效地计算模块间梯度方向的余弦相似度，并根据这些相似度将具有冲突梯度方向的模块分配到不同的子超网络中，相似模块则分组在一起。UGAS框架则探索了MPNN和GT的最佳组合。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，GC在超网络分区质量和时间效率方面达到了最先进（SOTA）的性能。此外，UGAS+GC搜索的架构优于手动设计的GNN和现有NAS方法搜索到的架构。&lt;h4&gt;结论&lt;/h4&gt;通过消融研究进一步证明了所有提出方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;为了解决权重耦合问题，本文从新颖的角度分析了这一问题，并提出了Gradient Contribution（GC）方法。该方法通过分解向量-雅可比乘积，高效地计算模块间梯度方向的余弦相似度，并基于此将具有冲突梯度方向的模块分配到不同的子超网络中，相似模块则分组在一起。此外，本文还提出了Unified Graph Neural Architecture Search（UGAS）框架，该框架探索了MPNN和GT的最佳组合。实验结果表明，GC在超网络分区质量和时间效率方面达到了最先进的性能，且UGAS+GC搜索的架构优于手动设计的GNN和现有NAS方法搜索到的架构。消融研究进一步证明了所有提出方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To address the weight coupling problem, certain studies introduced few-shotNeural Architecture Search (NAS) methods, which partition the supernet intomultiple sub-supernets. However, these methods often suffer from computationalinefficiency and tend to provide suboptimal partitioning schemes. To addressthis problem more effectively, we analyze the weight coupling problem from anovel perspective, which primarily stems from distinct modules in succeedinglayers imposing conflicting gradient directions on the preceding layer modules.Based on this perspective, we propose the Gradient Contribution (GC) methodthat efficiently computes the cosine similarity of gradient directions amongmodules by decomposing the Vector-Jacobian Product during supernetbackpropagation. Subsequently, the modules with conflicting gradient directionsare allocated to distinct sub-supernets while similar ones are groupedtogether. To assess the advantages of GC and address the limitations ofexisting Graph Neural Architecture Search methods, which are limited tosearching a single type of Graph Neural Networks (Message Passing NeuralNetworks (MPNNs) or Graph Transformers (GTs)), we propose the Unified GraphNeural Architecture Search (UGAS) framework, which explores optimalcombinations of MPNNs and GTs. The experimental results demonstrate that GCachieves state-of-the-art (SOTA) performance in supernet partitioning qualityand time efficiency. In addition, the architectures searched by UGAS+GCoutperform both the manually designed GNNs and those obtained by existing NASmethods. Finally, ablation studies further demonstrate the effectiveness of allproposed methods.</description>
      <author>example@mail.com (Wenhao Song, Xuan Wu, Bo Yang, You Zhou, Yubin Xiao, Yanchun Liang, Hongwei Ge, Heow Pueh Lee, Chunguo Wu)</author>
      <guid isPermaLink="false">2506.01231v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Bot Detection via Heterophily-Aware Representation Learning and Prototype-Guided Cluster Discovery</title>
      <link>http://arxiv.org/abs/2506.00989v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;BotHP是一种基于生成图自监督学习（GSL）的框架，旨在通过异质性感知表示学习和原型引导的聚类发现来提升图基社交机器人检测器的性能。&lt;h4&gt;背景&lt;/h4&gt;当前图基检测方法在社交机器人检测中表现出色，但受限于标签依赖和跨不同社区的低泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出BotHP框架，以克服标签依赖和泛化能力不足的问题。&lt;h4&gt;方法&lt;/h4&gt;BotHP采用双重编码器架构，包括一个图感知编码器来捕捉节点共同性，和一个图无关编码器来保留节点独特性。此外，还引入了原型引导的聚类发现前缀任务来模拟机器人集群的潜在全局一致性。&lt;h4&gt;主要发现&lt;/h4&gt;BotHP能够同时建模同质性和异质性，有效对抗交互伪装问题，并通过原型引导的聚类发现识别空间分散但语义对齐的机器人集体。&lt;h4&gt;结论&lt;/h4&gt;在两个真实世界机器人检测基准测试上的实验表明，BotHP能够持续提升基于图的机器人检测器的性能，提高检测准确性，减轻对标签的依赖，并增强泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：检测社交媒体机器人对于维护社交网络的安全性和可信度至关重要。尽管当代基于图的检测方法显示出有希望的结果，但它们的实际应用受到标签依赖和跨不同社区泛化能力差的限制。生成图自监督学习（GSL）提供了一个克服这些限制的有希望的方法论，但现有的方法主要遵循同质性假设，未能捕捉图中的全局模式，这可能在面对机器人检测场景中的交互伪装和分布式部署挑战时降低其有效性。为此，我们提出了BotHP，这是一种针对通过异质性感知表示学习和原型引导的聚类发现来增强图基机器人检测器性能的生成GSL框架。具体来说，BotHP利用一个双重编码器架构，包括一个图感知编码器来捕捉节点共同性，和一个图无关编码器来保留节点独特性。这允许同时建模同质性和异质性，有效对抗交互伪装问题。此外，BotHP还引入了一个原型引导的聚类发现前缀任务来模拟机器人集群的潜在全局一致性，并识别空间分散但语义对齐的机器人集体。在两个真实世界机器人检测基准测试上的大量实验表明，BotHP能够持续提升基于图的机器人检测器的性能，提高检测性能，减轻对标签的依赖，并增强泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting social media bots is essential for maintaining the security andtrustworthiness of social networks. While contemporary graph-based detectionmethods demonstrate promising results, their practical application is limitedby label reliance and poor generalization capability across diversecommunities. Generative Graph Self-Supervised Learning (GSL) presents apromising paradigm to overcome these limitations, yet existing approachespredominantly follow the homophily assumption and fail to capture the globalpatterns in the graph, which potentially diminishes their effectiveness whenfacing the challenges of interaction camouflage and distributed deployment inbot detection scenarios. To this end, we propose BotHP, a generative GSLframework tailored to boost graph-based bot detectors through heterophily-awarerepresentation learning and prototype-guided cluster discovery. Specifically,BotHP leverages a dual-encoder architecture, consisting of a graph-awareencoder to capture node commonality and a graph-agnostic encoder to preservenode uniqueness. This enables the simultaneous modeling of both homophily andheterophily, effectively countering the interaction camouflage issue.Additionally, BotHP incorporates a prototype-guided cluster discovery pretexttask to model the latent global consistency of bot clusters and identifyspatially dispersed yet semantically aligned bot collectives. Extensiveexperiments on two real-world bot detection benchmarks demonstrate that BotHPconsistently boosts graph-based bot detectors, improving detection performance,alleviating label reliance, and enhancing generalization capability.</description>
      <author>example@mail.com (Buyun He, Xiaorui Jiang, Qi Wu, Hao Liu, Yingguang Yang, Yong Liao)</author>
      <guid isPermaLink="false">2506.00989v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution</title>
      <link>http://arxiv.org/abs/2506.01037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 10 figures, accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于自我监督学习和Mamba的噪声鲁棒现实世界视频超分辨率（VSR）框架，通过结合全局时空注意力机制和自监督ControlNet，提高了生成的视频质量。&lt;h4&gt;背景&lt;/h4&gt;现有的基于扩散的视频超分辨率方法由于固有的随机性，容易在高清视频中引入复杂的退化并产生明显的伪影。&lt;h4&gt;目的&lt;/h4&gt;提出一种噪声鲁棒的VSR框架，以减少在高分辨率视频中的伪影和退化。&lt;h4&gt;方法&lt;/h4&gt;1. 使用自我监督学习和Mamba改进预训练的潜在扩散模型。2. 通过VideoState-Space块和3D选择性扫描模块增强扩散模型，以确保相邻帧之间的内容一致性。3. 引入自监督ControlNet，利用HR特征作为指导，并采用对比学习从LR视频中提取退化不敏感的特征。4. 提出基于HR-LR视频混合的三阶段训练策略以稳定VSR训练。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的自监督ControlNet与时空连续Mamba的VSR算法在现实世界VSR基准数据集上实现了优于现有技术的感知质量。&lt;h4&gt;结论&lt;/h4&gt;验证了所提出的模型设计和训练策略的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing diffusion-based video super-resolution (VSR) methods are susceptibleto introducing complex degradations and noticeable artifacts intohigh-resolution videos due to their inherent randomness. In this paper, wepropose a noise-robust real-world VSR framework by incorporatingself-supervised learning and Mamba into pre-trained latent diffusion models. Toensure content consistency across adjacent frames, we enhance the diffusionmodel with a global spatio-temporal attention mechanism using the VideoState-Space block with a 3D Selective Scan module, which reinforces coherenceat an affordable computational cost. To further reduce artifacts in generateddetails, we introduce a self-supervised ControlNet that leverages HR featuresas guidance and employs contrastive learning to extract degradation-insensitivefeatures from LR videos. Finally, a three-stage training strategy based on amixture of HR-LR videos is proposed to stabilize VSR training. The proposedSelf-supervised ControlNet with Spatio-Temporal Continuous Mamba based VSRalgorithm achieves superior perceptual quality than state-of-the-arts onreal-world VSR benchmark datasets, validating the effectiveness of the proposedmodel design and training strategies.</description>
      <author>example@mail.com (Shijun Shi, Jing Xu, Lijing Lu, Zhihang Li, Kai Hu)</author>
      <guid isPermaLink="false">2506.01037v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Advancing from Automated to Autonomous Beamline by Leveraging Computer Vision</title>
      <link>http://arxiv.org/abs/2506.00836v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个基于计算机视觉的系统，旨在实现同步辐射光束线的自主操作，以提高实验的自动化、可靠性和安全性。&lt;h4&gt;背景&lt;/h4&gt;同步辐射光源是高端大型用户设施，需要自主的同步辐射光束线操作，但当前最先进的同步辐射光束线仍高度依赖人工安全监管。&lt;h4&gt;目的&lt;/h4&gt;实现实验的自动化、可靠性和安全性，减少人工干预。&lt;h4&gt;方法&lt;/h4&gt;开发了一个基于计算机视觉的系统，结合深度学习和多视图相机进行实时碰撞检测。系统利用设备分割、跟踪和几何分析进行潜在碰撞评估，并通过迁移学习增强鲁棒性。此外，还开发了一个交互式注释模块，以提高对新物体类别的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;在真实光束线数据集上的实验表明，该系统具有高精度、实时性能和强大的自主同步辐射光束线操作潜力。&lt;h4&gt;结论&lt;/h4&gt;该系统为实现同步辐射光束线的自主操作提供了有效途径，有望提高实验的自动化水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The synchrotron light source, a cutting-edge large-scale user facility,requires autonomous synchrotron beamline operations, a crucial technique thatshould enable experiments to be conducted automatically, reliably, and safelywith minimum human intervention. However, current state-of-the-art synchrotronbeamlines still heavily rely on human safety oversight. To bridge the gapbetween automated and autonomous operation, a computer vision-based system isproposed, integrating deep learning and multiview cameras for real-timecollision detection. The system utilizes equipment segmentation, tracking, andgeometric analysis to assess potential collisions with transfer learning thatenhances robustness. In addition, an interactive annotation module has beendeveloped to improve the adaptability to new object classes. Experiments on areal beamline dataset demonstrate high accuracy, real-time performance, andstrong potential for autonomous synchrotron beamline operations.</description>
      <author>example@mail.com (Baolu Li, Hongkai Yu, Huiming Sun, Jin Ma, Yuewei Lin, Lu Ma, Yonghua Du)</author>
      <guid isPermaLink="false">2506.00836v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Keystep Recognition using Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.01102v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种灵活的图学习框架GLEVR，用于细粒度按键识别，能够有效利用自拍摄像头视频中的长期依赖关系。&lt;h4&gt;背景&lt;/h4&gt;将按键识别视为节点分类任务，并针对自拍摄像头视频中的按键识别问题进行研究。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效利用长期依赖关系的按键识别方法，并构建一个计算高效、性能优异的模型。&lt;h4&gt;方法&lt;/h4&gt;构建一个图，其中每个自拍摄像头视频片段对应一个节点，并利用内外部视频的对应关系进行训练，同时增加自动字幕作为额外模态，考虑外部视频片段或字幕作为额外的节点，并定义节点间连接的策略。&lt;h4&gt;主要发现&lt;/h4&gt;在Ego-Exo4D数据集上进行了广泛实验，证明了所提出的基于图的灵活框架在性能上显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;GLEVR框架在按键识别任务中表现出色，为自拍摄像头视频的按键识别提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We pose keystep recognition as a node classification task, and propose aflexible graph-learning framework for fine-grained keystep recognition that isable to effectively leverage long-term dependencies in egocentric videos. Ourapproach, termed GLEVR, consists of constructing a graph where each video clipof the egocentric video corresponds to a node. The constructed graphs aresparse and computationally efficient, outperforming existing larger modelssubstantially. We further leverage alignment between egocentric and exocentricvideos during training for improved inference on egocentric videos, as well asadding automatic captioning as an additional modality. We consider each clip ofeach exocentric video (if available) or video captions as additional nodesduring training. We examine several strategies to define connections acrossthese nodes. We perform extensive experiments on the Ego-Exo4D dataset and showthat our proposed flexible graph-based framework notably outperforms existingmethods.</description>
      <author>example@mail.com (Julia Lee Romero, Kyle Min, Subarna Tripathi, Morteza Karimzadeh)</author>
      <guid isPermaLink="false">2506.01102v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>What do self-supervised speech models know about Dutch? Analyzing advantages of language-specific pre-training</title>
      <link>http://arxiv.org/abs/2506.00981v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Interspeech 2025. For model, code, and materials, see  https://github.com/mdhk/SSL-NL-eval&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了自监督模型学习的语音表示的语言特异性，发现专门在荷兰语上预训练的模型在表示荷兰语语言特征方面优于使用相同数量的英语或更多多语言数据的模型。&lt;h4&gt;背景&lt;/h4&gt;已有研究表明，从仅使用语音记录训练的端到端模型中可以成功解码一系列语言特征，但对于在特定语言上预训练是否提高了语言特定的语言信息，了解不多。&lt;h4&gt;目的&lt;/h4&gt;测试自监督Wav2Vec2模型内部表示中荷兰语音和词汇信息的编码。&lt;h4&gt;方法&lt;/h4&gt;比较了专门在荷兰语上预训练、在相同数量的英语上预训练以及在更多多语言数据上预训练的模型的表现。&lt;h4&gt;主要发现&lt;/h4&gt;专门在荷兰语上预训练的模型在表示荷兰语语言特征方面表现优于其他两种预训练方法，这种语言特定的优势可以通过训练的聚类或分类探针检测到，并且部分可以通过零样本指标观察到。&lt;h4&gt;结论&lt;/h4&gt;语言特定的语言特征编码优势与自动语音识别任务中的下游性能相一致。&lt;h4&gt;翻译&lt;/h4&gt;摘要：自监督模型学习的语音表示的语言特异性如何？已有研究显示，可以从仅用语音记录训练的端到端模型中成功解码一系列语言特征。然而，对于在特定语言上预训练是否提高了语言特定的语言信息，了解不多。在本研究中，我们测试了自监督Wav2Vec2模型内部表示中荷兰语音和词汇信息的编码。仅使用荷兰语预训练可以比使用相同数量的英语或更多多语言数据预训练更好地表示荷兰语语言特征。这种语言特定的优势可以通过训练的聚类或分类探针很好地检测到，并且部分可以通过零样本指标观察到。此外，语言特定的语言特征编码优势与自动语音识别任务中的下游性能相一致。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.21437/Interspeech.2025-1526&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; How language-specific are speech representations learned by self-supervisedmodels? Existing work has shown that a range of linguistic features can besuccessfully decoded from end-to-end models trained only on speech recordings.However, it's less clear to what extent pre-training on specific languagesimproves language-specific linguistic information. Here we test the encoding ofDutch phonetic and lexical information in internal representations ofself-supervised Wav2Vec2 models. Pre-training exclusively on Dutch improves therepresentation of Dutch linguistic features as compared to pre-training onsimilar amounts of English or larger amounts of multilingual data. Thislanguage-specific advantage is well-detected by trained clustering orclassification probes, and partially observable using zero-shot metrics.Furthermore, the language-specific benefit on linguistic feature encodingaligns with downstream performance on Automatic Speech Recognition.</description>
      <author>example@mail.com (Marianne de Heer Kloots, Hosein Mohebbi, Charlotte Pouw, Gaofei Shen, Willem Zuidema, Martijn Bentum)</author>
      <guid isPermaLink="false">2506.00981v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>AuralSAM2: Enabling SAM2 Hear Through Pyramid Audio-Visual Feature Prompting</title>
      <link>http://arxiv.org/abs/2506.01015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 18 Figures and 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SAM2在视频剪辑的promptable segmentation方面表现出强大的泛化能力，但其与音频模态的集成尚待探索。&lt;h4&gt;背景&lt;/h4&gt;现有的方法主要分为两类：一是将适配器注入图像编码器以接收音频信号，这在prompt engineering过程中会降低效率；二是利用额外的基础模型生成视觉提示，但这些提示往往定位不准确，导致SAM2的误导。&lt;h4&gt;目的&lt;/h4&gt;提出AuralSAM2，包含新颖的AuralFuser模块，该模块外部连接到SAM2，以集成不同模态的特征并生成特征级提示，引导SAM2的解码器进行声音目标的分割。&lt;h4&gt;方法&lt;/h4&gt;通过特征金字塔实现集成，进一步细化语义理解和增强多模态场景中的物体意识。此外，引入音频引导的对比学习，以显式地对齐音频和视觉表示，并减轻由主导视觉模式引起的偏差。&lt;h4&gt;主要发现&lt;/h4&gt;在公共基准测试中，该方法在性能上显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;AuralSAM2通过改进的模态融合和对比学习方法，实现了对SAM2在音频-视觉分割任务上的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;Segment Anything Model 2 (SAM2) 在视频剪辑的提示式分割方面表现出强大的泛化能力；然而，其与音频模态的集成尚未得到充分探索。现有的方法主要遵循两个方向：（1）将适配器注入图像编码器以接收音频信号，这在提示工程过程中会降低效率；（2）利用额外的基础模型为声音对象生成视觉提示，但这些提示通常定位不准确，导致SAM2的误导。此外，这些方法忽视了层次化视觉特征与其他模态之间丰富的语义互动，导致跨模态融合效果不佳。在本研究中，我们提出了AuralSAM2，包括新颖的AuralFuser模块，该模块外部连接到SAM2，以集成来自不同模态的特征并生成特征级提示，引导SAM2的解码器进行声音目标的分割。这种集成是通过特征金字塔实现的，进一步细化语义理解并增强多模态场景中的物体意识。此外，引入了音频引导的对比学习，以显式地对齐音频和视觉表示，并减轻由主导视觉模式引起的偏差。在公共基准测试中的结果表明，我们的方法在性能上显著优于现有方法。代码可在https://github.com/yyliu01/AuralSAM2上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Segment Anything Model 2 (SAM2) exhibits strong generalisation for promptablesegmentation in video clips; however, its integration with the audio modalityremains underexplored. Existing approaches mainly follow two directions: (1)injecting adapters into the image encoder to receive audio signals, whichincurs efficiency costs during prompt engineering, and (2) leveragingadditional foundation models to generate visual prompts for the soundingobjects, which are often imprecisely localised, leading to misguidance in SAM2.Moreover, these methods overlook the rich semantic interplay betweenhierarchical visual features and other modalities, resulting in suboptimalcross-modal fusion. In this work, we propose AuralSAM2, comprising the novelAuralFuser module, which externally attaches to SAM2 to integrate features fromdifferent modalities and generate feature-level prompts, guiding SAM2's decoderin segmenting sounding targets. Such integration is facilitated by a featurepyramid, further refining semantic understanding and enhancing object awarenessin multimodal scenarios. Additionally, the audio-guided contrastive learning isintroduced to explicitly align audio and visual representations and to alsomitigate biases caused by dominant visual patterns. Results on publicbenchmarks show that our approach achieves remarkable improvements over theprevious methods in the field. Code is available athttps://github.com/yyliu01/AuralSAM2.</description>
      <author>example@mail.com (Yuyuan Liu, Yuanhong Chen, Chong Wang, Junlin Han, Junde Wu, Can Peng, Jingkun Chen, Yu Tian, Gustavo Carneiro)</author>
      <guid isPermaLink="false">2506.01015v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Multi-level and Multi-modal Action Anticipation</title>
      <link>http://arxiv.org/abs/2506.02382v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in 2025 IEEE International Conference on Image Processing  (ICIP)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Multi-level and Multi-modal Action Anticipation (m&amp;m-Ant)的新型多模态动作预测方法，该方法结合视觉和文本线索，并显式建模层次语义信息以提高预测准确性。&lt;h4&gt;背景&lt;/h4&gt;动作预测对于智能系统的发展至关重要，它需要处理部分观察到的视频中的不完全信息，并具备时间推理和不确定性处理的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效预测未来动作的方法，并通过结合多种信息源来提高预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;m&amp;m-Ant方法结合视觉和文本线索，并引入细粒度标签生成器与专门的时序一致性损失函数来优化性能。&lt;h4&gt;主要发现&lt;/h4&gt;在Breakfast、50 Salads和DARai等广泛使用的数据集上，该方法实现了最先进的预测准确率，平均提高了3.08%。&lt;h4&gt;结论&lt;/h4&gt;多模态和层次建模在动作预测领域具有巨大潜力，并为本领域未来的研究设立了一个新的基准。&lt;h4&gt;翻译&lt;/h4&gt;动作预测，即从部分观察到的视频中预测未来动作的任务，对于推进智能系统的发展至关重要。与在完全观察到的视频上运行的动作识别不同，动作预测必须处理不完整的信息，因此需要时间推理和内在的不确定性处理。虽然近年来取得了一些进展，但传统方法通常仅关注视觉模态，忽视了整合多种信息源的可能性。从人类行为中汲取灵感，我们引入了名为Multi-level and Multi-modal Action Anticipation (m&amp;m-Ant)的新颖多模态动作预测方法，该方法结合了视觉和文本线索，并显式地建模层次语义信息以实现更准确的预测。为了解决粗粒度动作标签不准确的问题，我们提出了一种细粒度标签生成器与专门的时序一致性损失函数相结合的方法来优化性能。在包括Breakfast、50 Salads和DARai在内的广泛使用的数据集上进行的广泛实验表明，我们的方法非常有效，与现有方法相比，平均预测准确率提高了3.08%。这项工作强调了多模态和层次建模在推进动作预测方面的潜力，并为该领域未来的研究建立了一个新的基准。我们的代码可在https://github.com/olivesgatech/mM-ant上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Action anticipation, the task of predicting future actions from partiallyobserved videos, is crucial for advancing intelligent systems. Unlike actionrecognition, which operates on fully observed videos, action anticipation musthandle incomplete information. Hence, it requires temporal reasoning, andinherent uncertainty handling. While recent advances have been made,traditional methods often focus solely on visual modalities, neglecting thepotential of integrating multiple sources of information. Drawing inspirationfrom human behavior, we introduce \textit{Multi-level and Multi-modal ActionAnticipation (m\&amp;m-Ant)}, a novel multi-modal action anticipation approach thatcombines both visual and textual cues, while explicitly modeling hierarchicalsemantic information for more accurate predictions. To address the challenge ofinaccurate coarse action labels, we propose a fine-grained label generatorpaired with a specialized temporal consistency loss function to optimizeperformance. Extensive experiments on widely used datasets, includingBreakfast, 50 Salads, and DARai, demonstrate the effectiveness of our approach,achieving state-of-the-art results with an average anticipation accuracyimprovement of 3.08\% over existing methods. This work underscores thepotential of multi-modal and hierarchical modeling in advancing actionanticipation and establishes a new benchmark for future research in the field.Our code is available at: https://github.com/olivesgatech/mM-ant.</description>
      <author>example@mail.com (Seulgi Kim, Ghazal Kaviani, Mohit Prabhushankar, Ghassan AlRegib)</author>
      <guid isPermaLink="false">2506.02382v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Getting More from Less: Transfer Learning Improves Sleep Stage Decoding Accuracy in Peripheral Wearable Devices</title>
      <link>http://arxiv.org/abs/2506.00730v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了迁移学习技术在睡眠阶段解码中的应用，通过利用预训练的神经网络模型，显著提高了从外围可穿戴设备中解码睡眠阶段准确率。&lt;h4&gt;背景&lt;/h4&gt;传统的消费级可穿戴设备依赖外围生理信号，如脉搏容积描记图（PPG）和呼吸数据，这些信号虽然方便但缺乏临床脑电图（EEG）的精确性。&lt;h4&gt;目的&lt;/h4&gt;探索迁移学习如何增强睡眠阶段解码的准确性和实用性。&lt;h4&gt;方法&lt;/h4&gt;在大型公开EEG数据集上预训练了一个基于Transformer的神经网络模型，并在噪声较大的外围信号上微调了这个模型。&lt;h4&gt;主要发现&lt;/h4&gt;迁移学习将分类准确率从仅使用外围信号的基准模型的67.6%提高到了76.6%，特别是在REM和N1等较浅睡眠阶段，准确率得到了显著提升。&lt;h4&gt;结论&lt;/h4&gt;迁移学习可以显著提高消费级可穿戴设备的准确性，未来结合自监督学习方法可能进一步提高性能，为个性化健康应用提供更精确的纵向睡眠监测。&lt;h4&gt;翻译&lt;/h4&gt;摘要：迁移学习，一种在生成人工智能中常用的技术，允许神经网络模型在执行新任务时利用先验知识。本研究表明，通过利用在脑电图（EEG）信号上预训练的神经网络模型，迁移学习显著提高了从外围可穿戴设备中解码睡眠阶段的准确性。消费级可穿戴技术通常依赖于外围生理信号，如脉搏容积描记图（PPG）和呼吸数据，虽然方便，但缺乏临床脑电图（EEG）在详细睡眠阶段分类方面的精确度。我们在大型公开的EEG数据集上预训练了一个基于Transformer的神经网络模型，随后在噪声较大的外围信号上微调了这个模型。我们的迁移学习方法将整体分类准确率从仅基于外围信号的基准模型的67.6%提高到了76.6%。在睡眠阶段，特别是REM和N1等较浅睡眠阶段，观察到了显著的准确率提升。这些结果突出了迁移学习在显著提高消费级可穿戴设备的准确性和实用性方面的潜力，而无需改变现有硬件。未来自监督学习方法的集成可能进一步提升性能，便于为个性化健康应用提供更精确的纵向睡眠监测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning, a technique commonly used in generative artificialintelligence, allows neural network models to bring prior knowledge to bearwhen learning a new task. This study demonstrates that transfer learningsignificantly enhances the accuracy of sleep-stage decoding from peripheralwearable devices by leveraging neural network models pretrained onelectroencephalographic (EEG) signals. Consumer wearable technologies typicallyrely on peripheral physiological signals such as pulse plethysmography (PPG)and respiratory data, which, while convenient, lack the fidelity of clinicalelectroencephalography (EEG) for detailed sleep-stage classification. Wepretrained a transformer-based neural network on a large, publicly availableEEG dataset and subsequently fine-tuned this model on noisier peripheralsignals. Our transfer learning approach improved overall classificationaccuracy from 67.6\% (baseline model trained solely on peripheral signals) to76.6\%. Notable accuracy improvements were observed across sleep stages,particularly lighter sleep stages such as REM and N1. These results highlighttransfer learning's potential to substantially enhance the accuracy and utilityof consumer wearable devices without altering existing hardware. Futureintegration of self-supervised learning methods may further boost performance,facilitating more precise, longitudinal sleep monitoring for personalizedhealth applications.</description>
      <author>example@mail.com (William G Coon, Diego Luna, Akshita Panagrahi, Matthew Reid, Mattson Ogg)</author>
      <guid isPermaLink="false">2506.00730v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Generative AI for Predicting 2D and 3D Wildfire Spread: Beyond Physics-Based Models and Traditional Deep Learning</title>
      <link>http://arxiv.org/abs/2506.02485v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了利用生成式AI进行野火预测的潜力，并提出了将生成式AI集成到野火管理中的五个关键愿景和三个主要挑战。&lt;h4&gt;背景&lt;/h4&gt;全球野火给人类、环境和经济带来了巨大损失，需要更有效的应对策略。现有的物理模型和深度学习模型在实时预测和可视化多模态火势扩散方面存在限制。&lt;h4&gt;目的&lt;/h4&gt;倡导将生成式AI作为野火预测的基础框架，并探讨如何通过这些模型增强二维火势预测和实现更真实、可扩展的三维模拟。&lt;h4&gt;方法&lt;/h4&gt;采用大型语言模型进行自动知识提取、文献综合和文献计量映射，并探索将生成式AI应用于野火管理的不同方面。&lt;h4&gt;主要发现&lt;/h4&gt;生成式AI在整合多模态数据、生成不确定情况下的多样场景和改善时空尺度上的野火动力学建模方面具有优势。&lt;h4&gt;结论&lt;/h4&gt;提出了五个关键愿景（多模态方法、AI基础模型、对话式AI系统、基于边缘计算的情景生成和认知数字孪生）以及三个主要挑战和相应的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：野火继续在全球范围内造成严重的人类、环境和经济损失，正如2025年洛杉矶野火悲剧性地证明的那样，迫切需要更有效的应对策略。尽管基于物理的模型和深度学习模型在野火模拟方面取得了进展，但它们在预测和实时可视化多模态火势扩散方面面临关键限制，特别是在使用动态更新的GIS数据进行2D和3D空间域的模拟时。这些限制阻碍了及时的紧急响应、基础设施保护和社区安全。生成式AI最近在研究和工业界中作为一种变革性的方法出现。诸如生成对抗网络（GANs）、变分自编码器（VAEs）、Transformer和基于扩散的架构等模型，与传统方法相比具有独特的优势，包括整合多模态数据、在不确定性下生成多样场景以及改善时空尺度上的野火动力学建模。这篇立场论文主张采用生成式AI作为野火预测的基础框架。我们探讨了如何通过这些模型增强2D火势预测和实现更真实、可扩展的3D模拟。此外，我们采用了一种新颖的人机协作框架，使用大型语言模型（LLMs）进行自动知识提取、文献综合和文献计量映射。展望未来，我们确定了将生成式AI集成到野火管理中的五个关键愿景：多模态方法、AI基础模型、对话式AI系统、基于边缘计算的情景生成和认知数字孪生。我们还解决了伴随这些机会的三个主要挑战，并提出了支持其实施的潜在解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wildfires continue to inflict devastating human, environmental, and economiclosses globally, as tragically exemplified by the 2025 Los Angeles wildfire andthe urgent demand for more effective response strategies. While physics-basedand deep learning models have advanced wildfire simulation, they face criticallimitations in predicting and visualizing multimodal fire spread in real time,particularly in both 2D and 3D spatial domains using dynamically updated GISdata. These limitations hinder timely emergency response, infrastructureprotection, and community safety. Generative AI has recently emerged as atransformative approach across research and industry. Models such as GenerativeAdversarial Networks (GANs), Variational Autoencoders (VAEs), Transformers, anddiffusion-based architectures offer distinct advantages over traditionalmethods, including the integration of multimodal data, generation of diversescenarios under uncertainty, and improved modeling of wildfire dynamics acrossspatial and temporal scales. This position paper advocates for the adoption ofgenerative AI as a foundational framework for wildfire prediction. We explorehow such models can enhance 2D fire spread forecasting and enable morerealistic, scalable 3D simulations. Additionally, we employ a novel human-AIcollaboration framework using large language models (LLMs) for automatedknowledge extraction, literature synthesis, and bibliometric mapping. Lookingahead, we identify five key visions for integrating generative AI into wildfiremanagement: multimodal approaches, AI foundation models, conversational AIsystems, edge-computing-based scenario generation, and cognitive digital twins.We also address three major challenges accompanying these opportunities andpropose potential solutions to support their implementation.</description>
      <author>example@mail.com (Haowen Xu, Sisi Zlatanova, Ruiyu Liang, Ismet Canbulat)</author>
      <guid isPermaLink="false">2506.02485v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Regulatory Graphs and GenAI for Real-Time Transaction Monitoring and Compliance Explanation in Banking</title>
      <link>http://arxiv.org/abs/2506.01093v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种实时交易监控框架，该框架结合了基于图建模、叙事字段嵌入和生成解释，以支持自动化的金融合规。&lt;h4&gt;背景&lt;/h4&gt;在金融领域，自动化的交易监控和合规性检查对于防范风险和确保合规性至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够自动识别可疑交易行为并生成符合法规的解释的实时交易监控系统。&lt;h4&gt;方法&lt;/h4&gt;该系统构建动态交易图，提取结构和上下文特征，并使用图神经网络对可疑行为进行分类。检索增强生成模块为每个标记的交易生成与法规条款相符的自然语言解释。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟金融数据流上的实验表明，该方法取得了优异的结果，F1分数为98.2%，精确度为97.8%，召回率为97.0%。专家评估进一步证实了生成解释的质量和可解释性。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了结合图智能和生成模型在支持高风险金融环境中的可解释、审计准备就绪的合规性方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种实时交易监控框架，该框架结合了基于图建模、叙事字段嵌入和生成解释来支持自动化的金融合规。系统构建动态交易图，提取结构和上下文特征，并使用图神经网络对可疑行为进行分类。检索增强生成模块为每个标记的交易生成与法规条款相符的自然语言解释。在模拟金融数据流上的实验表明，该方法取得了优异的结果，F1分数为98.2%，精确度为97.8%，召回率为97.0%。专家评估进一步证实了生成解释的质量和可解释性。该研究证明了结合图智能和生成模型在支持高风险金融环境中的可解释、审计准备就绪的合规性方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a real-time transaction monitoring framework thatintegrates graph-based modeling, narrative field embedding, and generativeexplanation to support automated financial compliance. The system constructsdynamic transaction graphs, extracts structural and contextual features, andclassifies suspicious behavior using a graph neural network. Aretrieval-augmented generation module generates natural language explanationsaligned with regulatory clauses for each flagged transaction. Experimentsconducted on a simulated stream of financial data show that the proposed methodachieves superior results, with 98.2% F1-score, 97.8% precision, and 97.0%recall. Expert evaluation further confirms the quality and interpretability ofgenerated justifications. The findings demonstrate the potential of combininggraph intelligence and generative models to support explainable, audit-readycompliance in high-risk financial environments.</description>
      <author>example@mail.com (Kunal Khanvilkar, Kranthi Kommuru)</author>
      <guid isPermaLink="false">2506.01093v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Hidden Representation Clustering with Multi-Task Representation Learning towards Robust Online Budget Allocation</title>
      <link>http://arxiv.org/abs/2506.00959v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的营销优化方法，通过聚类视角解决大规模在线预算分配问题，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;营销优化作为推动用户增长的关键因素，传统方法存在大规模反事实预测和复杂度权衡等挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，解决大规模在线预算分配问题，特别是在数据噪声较大的工业场景中。&lt;h4&gt;方法&lt;/h4&gt;1. 提出多任务表示网络学习个体属性并将其特征映射到高维隐藏表示。2. 通过基于划分的聚类将隐藏表示分为K组。3. 将表示模块和聚类模型蒸馏到一个多分类模型中，以方便在线部署。&lt;h4&gt;主要发现&lt;/h4&gt;离线实验验证了与六种最先进的营销优化算法相比，该方法的有效性和优越性。在线A/B测试表明，该方法在订单量（OV）和商品交易总额（GMV）方面分别优于在线算法0.53%和0.65%。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效解决大规模在线预算分配问题，并在实际应用中取得了良好的效果。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel marketing optimization method that solves the large-scale online budget allocation problem from a clustering perspective, and its effectiveness is validated through experiments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Marketing optimization, commonly formulated as an online budget allocationproblem, has emerged as a pivotal factor in driving user growth. Most existingresearch addresses this problem by following the principle of 'first predictthen optimize' for each individual, which presents challenges related tolarge-scale counterfactual prediction and solving complexity trade-offs. Notethat the practical data quality is uncontrollable, and the solving scale tendsto be tens of millions. Therefore, the existing approaches make the robustbudget allocation non-trivial, especially in industrial scenarios withconsiderable data noise. To this end, this paper proposes a novel approach thatsolves the problem from the cluster perspective. Specifically, we propose amulti-task representation network to learn the inherent attributes ofindividuals and project the original features into high-dimension hiddenrepresentations through the first two layers of the trained network. Then, wedivide these hidden representations into $K$ groups through partitioning-basedclustering, thus reformulating the problem as an integer stochastic programmingproblem under different total budgets. Finally, we distill the representationmodule and clustering model into a multi-category model to facilitate onlinedeployment. Offline experiments validate the effectiveness and superiority ofour approach compared to six state-of-the-art marketing optimizationalgorithms. Online A/B tests on the Meituan platform indicate that the approachoutperforms the online algorithm by 0.53% and 0.65%, considering order volume(OV) and gross merchandise volume (GMV), respectively.</description>
      <author>example@mail.com (Xiaohan Wang, Yu Zhang, Guibin Jiang, Bing Cheng, Wei Lin)</author>
      <guid isPermaLink="false">2506.00959v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>InterRVOS: Interaction-aware Referring Video Object Segmentation</title>
      <link>http://arxiv.org/abs/2506.02356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的视频对象分割任务，即交互感知的视频对象分割（InterRVOS），旨在通过理解物体间的交互来分割视频中的对象。该方法通过大规模数据集和新的评估设置来提高对复杂交互的理解。&lt;h4&gt;背景&lt;/h4&gt;现有研究主要关注单独定位单个目标对象，而忽略了物体之间交互的重要性。&lt;h4&gt;目的&lt;/h4&gt;通过引入InterRVOS任务，实现同时分割交互中的参与者和目标实体，并从不同语义角度对交互进行建模。&lt;h4&gt;方法&lt;/h4&gt;提出InterRVOS-8K数据集，包含多样化的交互感知表达式和相应的掩码。同时，设计了ReVIOSa架构，用于处理单表达式中的演员-目标分割，并在标准环境和交互焦点环境中取得良好性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在建模复杂交互方面优于现有方法，为以交互为中心的视频理解研究奠定了基础。&lt;h4&gt;结论&lt;/h4&gt;InterRVOS为视频理解领域提供了新的研究方向，有助于更好地理解视频中的复杂交互。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Referring video object segmentation aims to segment the object in a videocorresponding to a given natural language expression. While prior works haveexplored various referring scenarios, including motion-centric ormulti-instance expressions, most approaches still focus on localizing a singletarget object in isolation. However, in comprehensive video understanding, anobject's role is often defined by its interactions with other entities, whichare largely overlooked in existing datasets and models. In this work, weintroduce Interaction-aware referring video object sgementation (InterRVOS), anew task that requires segmenting both actor and target entities involved in aninteraction. Each interactoin is described through a pair of complementaryexpressions from different semantic perspectives, enabling fine-grainedmodeling of inter-object relationships. To tackle this task, we proposeInterRVOS-8K, the large-scale and automatically constructed dataset containingdiverse interaction-aware expressions with corresponding masks, includingchallenging cases such as motion-only multi-instance expressions. We alsopresent a baseline architecture, ReVIOSa, designed to handle actor-targetsegmentation from a single expression, achieving strong performance in bothstandard and interaction-focused settings. Furthermore, we introduce anactor-target-aware evalaution setting that enables a more targeted assessmentof interaction understanding. Experimental results demonstrate that ourapproach outperforms prior methods in modeling complex object interactions forreferring video object segmentation task, establishing a strong foundation forfuture research in interaction-centric video understanding. Our project page isavailable at\href{https://cvlab-kaist.github.io/InterRVOS}{https://cvlab-kaist.github.io/InterRVOS}.</description>
      <author>example@mail.com (Woojeong Jin, Seongchan Kim, Seungryong Kim)</author>
      <guid isPermaLink="false">2506.02356v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Chunking Enhances Recognition of Implicit Sequential Patterns</title>
      <link>http://arxiv.org/abs/2506.00588v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种神经启发的时序序列压缩方法，通过上下文标记的块来表示序列中的重复结构单元或“社区”。这些标记在离线睡眠阶段生成，作为对过去经验的紧凑引用，允许学习者在输入范围之外整合信息。&lt;h4&gt;背景&lt;/h4&gt;研究旨在探讨传统基于神经网络的序列学习器（如循环神经网络RNN）在处理多尺度时间模式时的局限性。&lt;h4&gt;目的&lt;/h4&gt;通过实验评估时序块压缩方法在受限资源设置下的学习效率，并通过小型人类试点研究验证结构抽象的概念。&lt;h4&gt;方法&lt;/h4&gt;研究在受控的合成环境中评估了该方法，并使用串行反应时间任务进行了小型人类试点研究。&lt;h4&gt;主要发现&lt;/h4&gt;初步结果表明，时序块压缩可以显著提高学习效率，并且学习到的上下文标签可以在相关任务间迁移。&lt;h4&gt;结论&lt;/h4&gt;该研究为时序块压缩提供了一个早期概念验证，为迁移学习等未来应用提供了潜力。&lt;h4&gt;翻译&lt;/h4&gt;In this pilot study, we propose a neuro-inspired approach that compresses temporal sequences into context-tagged chunks, where each tag represents a recurring structural unit or ``community'' in the sequence. These tags are generated during an offline sleep phase and serve as compact references to past experience, allowing the learner to incorporate information beyond its immediate input range. We evaluate this idea in a controlled synthetic environment designed to reveal the limitations of traditional neural network based sequence learners, such as recurrent neural networks (RNNs), when facing temporal patterns on multiple timescales. We evaluate this idea in a controlled synthetic environment designed to reveal the limitations of traditional neural network based sequence learners, such as recurrent neural networks (RNNs), when facing temporal patterns on multiple timescales. Our results, while preliminary, suggest that temporal chunking can significantly enhance learning efficiency under resource constrained settings. A small-scale human pilot study using a Serial Reaction Time Task further motivates the idea of structural abstraction. Although limited to synthetic tasks, this work serves as an early proof-of-concept, with initial evidence that learned context tags can transfer across related task, offering potential for future applications in transfer learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this pilot study, we propose a neuro-inspired approach that compressestemporal sequences into context-tagged chunks, where each tag represents arecurring structural unit or``community'' in the sequence. These tags aregenerated during an offline sleep phase and serve as compact references to pastexperience, allowing the learner to incorporate information beyond itsimmediate input range. We evaluate this idea in a controlled syntheticenvironment designed to reveal the limitations of traditional neural networkbased sequence learners, such as recurrent neural networks (RNNs), when facingtemporal patterns on multiple timescales. We evaluate this idea in a controlledsynthetic environment designed to reveal the limitations of traditional neuralnetwork based sequence learners, such as recurrent neural networks (RNNs), whenfacing temporal patterns on multiple timescales. Our results, whilepreliminary, suggest that temporal chunking can significantly enhance learningefficiency under resource constrained settings. A small-scale human pilot studyusing a Serial Reaction Time Task further motivates the idea of structuralabstraction. Although limited to synthetic tasks, this work serves as an earlyproof-of-concept, with initial evidence that learned context tags can transferacross related task, offering potential for future applications in transferlearning.</description>
      <author>example@mail.com (Jayanta Dey, Nicholas Soures, Miranda Gonzales, Itamar Lerner, Christopher Kanan, Dhireesha Kudithipudi)</author>
      <guid isPermaLink="false">2506.00588v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>PolyBERT: Fine-Tuned Poly Encoder BERT-Based Model for Word Sense Disambiguation</title>
      <link>http://arxiv.org/abs/2506.00968v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于BERT的多编码器模型PolyBERT，用于解决主流词义消歧（WSD）方法中的不足，通过批对比学习（BCL）提高了语义表示和计算效率。&lt;h4&gt;背景&lt;/h4&gt;现有的WSD方法使用BERT提取语义，但在特征提取过程中未能平衡局部和全局语义表示，且在训练阶段包含了所有可能的词义，导致计算成本高。&lt;h4&gt;目的&lt;/h4&gt;提出PolyBERT模型以解决现有WSD方法的不足，包括改善语义表示和降低计算成本。&lt;h4&gt;方法&lt;/h4&gt;PolyBERT模型采用多编码器和多头注意力机制融合局部和全局语义，同时引入BCL减少冗余训练输入。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，PolyBERT在F1分数上比基线方法如Huang的GlossBERT和Blevins的BEM提高了2%，并且与不使用BCL的PolyBERT相比，使用BCL的PolyBERT减少了37.6%的GPU使用时间。&lt;h4&gt;结论&lt;/h4&gt;PolyBERT通过平衡局部和全局语义以及引入批对比学习，有效地提高了WSD的性能和计算效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mainstream Word Sense Disambiguation (WSD) approaches have employed BERT toextract semantics from both context and definitions of senses to determine themost suitable sense of a target word, achieving notable performance. However,there are two limitations in these approaches. First, previous studies failedto balance the representation of token-level (local) and sequence-level(global) semantics during feature extraction, leading to insufficient semanticrepresentation and a performance bottleneck. Second, these approachesincorporated all possible senses of each target word during the training phase,leading to unnecessary computational costs. To overcome these limitations, thispaper introduces a poly-encoder BERT-based model with batch contrastivelearning for WSD, named PolyBERT. Compared with previous WSD methods, PolyBERThas two improvements: (1) A poly-encoder with a multi-head attention mechanismis utilized to fuse token-level (local) and sequence-level (global) semantics,rather than focusing on just one. This approach enriches semanticrepresentation by balancing local and global semantics. (2) To avoid redundanttraining inputs, Batch Contrastive Learning (BCL) is introduced. BCL utilizesthe correct senses of other target words in the same batch as negative samplesfor the current target word, which reduces training inputs and computationalcost. The experimental results demonstrate that PolyBERT outperforms baselineWSD methods such as Huang's GlossBERT and Blevins's BEM by 2\% in F1-score. Inaddition, PolyBERT with BCL reduces GPU hours by 37.6\% compared with PolyBERTwithout BCL.</description>
      <author>example@mail.com (Linhan Xia, Mingzhan Yang, Guohui Yuan, Shengnan Tao, Yujing Qiu, Guo Yu, Kai Lei)</author>
      <guid isPermaLink="false">2506.00968v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting End-to-End Learning with Slide-level Supervision in Computational Pathology</title>
      <link>http://arxiv.org/abs/2506.02408v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的多实例学习（MIL）方法ABMILX，用于计算病理学中的癌症诊断和预后。该方法结合了预训练编码器和端到端学习，旨在解决现有方法的性能限制。&lt;h4&gt;背景&lt;/h4&gt;预训练编码器和MIL在计算病理学中得到了广泛应用，但缺乏编码器微调和MIL的分离优化导致性能限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的MIL方法ABMILX，以解决端到端学习中的优化挑战，并提高计算病理学中的性能。&lt;h4&gt;方法&lt;/h4&gt;提出ABMILX方法，通过全局相关性注意力和多头机制来缓解稀疏注意力MIL的优化问题，并使用多尺度随机补丁采样策略进行端到端训练。&lt;h4&gt;主要发现&lt;/h4&gt;ABMILX在多个基准测试中超越了现有基础模型，同时保持了计算效率。&lt;h4&gt;结论&lt;/h4&gt;端到端学习在计算病理学中有潜力，需要更多研究关注。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes a new multi-instance learning (MIL) method called ABMILX for cancer diagnosis and prognosis in computational pathology. The method combines pre-trained encoders with end-to-end learning to address the performance limitations of existing methods. ABMILX mitigates the optimization challenges of end-to-end learning by using global correlation-based attention refinement and multi-head mechanisms, and achieves state-of-the-art performance while remaining computationally efficient. The paper demonstrates the potential of end-to-end learning in computational pathology and calls for greater research focus in this area.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pre-trained encoders for offline feature extraction followed by multipleinstance learning (MIL) aggregators have become the dominant paradigm incomputational pathology (CPath), benefiting cancer diagnosis and prognosis.However, performance limitations arise from the absence of encoder fine-tuningfor downstream tasks and disjoint optimization with MIL. While slide-levelsupervised end-to-end (E2E) learning is an intuitive solution to this issue, itfaces challenges such as high computational demands and suboptimal results.These limitations motivate us to revisit E2E learning. We argue that prior workneglects inherent E2E optimization challenges, leading to performancedisparities compared to traditional two-stage methods. In this paper, wepioneer the elucidation of optimization challenge caused by sparse-attentionMIL and propose a novel MIL called ABMILX. It mitigates this problem throughglobal correlation-based attention refinement and multi-head mechanisms. Withthe efficient multi-scale random patch sampling strategy, an E2E trained ResNetwith ABMILX surpasses SOTA foundation models under the two-stage paradigmacross multiple challenging benchmarks, while remaining computationallyefficient (&lt;10 RTX3090 hours). We show the potential of E2E learning in CPathand calls for greater research focus in this area. The code ishttps://github.com/DearCaat/E2E-WSI-ABMILX.</description>
      <author>example@mail.com (Wenhao Tang, Rong Qin, Heng Fang, Fengtao Zhou, Hao Chen, Xiang Li, Ming-Ming Cheng)</author>
      <guid isPermaLink="false">2506.02408v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Pilot Contamination-Aware Graph Attention Network for Power Control in CFmMIMO</title>
      <link>http://arxiv.org/abs/2506.00967v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图注意力网络的CFmMIMO系统下行链路功率控制算法，该算法以自监督方式运行，有效处理导频污染问题，并适应动态变化的用户数量。&lt;h4&gt;背景&lt;/h4&gt;基于优化的功率控制算法在CFmMIMO系统中计算复杂度高，不适合实时应用。基于学习的算法，尤其是图神经网络（GNNs），在解决功率控制问题中表现出色。然而，现有基于GNN的方法假设导频序列间理想正交性，这在实际中不现实，且多数方法假设用户数量固定。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的算法来解决现有方法中存在的假设不现实、用户数量动态变化和计算资源消耗大的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的图注意力网络算法，该算法在CFmMIMO系统中进行下行链路功率控制，并能够以自监督方式运行，同时处理导频污染问题，并适应动态变化的用户数量。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该算法在处理导频污染和适应动态用户数量方面有效，甚至与最优加速投影梯度方法相比也表现出良好的性能。&lt;h4&gt;结论&lt;/h4&gt;该图注意力网络算法为CFmMIMO系统下行链路功率控制提供了一种有效且实用的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a graph attention network-based downlink power control algorithm for CFmMIMO systems, which operates in a self-supervised manner while effectively handling pilot contamination and adapting to a dynamic number of UEs. Experimental results show its effectiveness, even compared to the optimal accelerated projected gradient method as a baseline.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optimization-based power control algorithms are predominantly iterative withhigh computational complexity, making them impractical for real-timeapplications in cell-free massive multiple-input multiple-output (CFmMIMO)systems. Learning-based methods have emerged as a promising alternative, andamong them, graph neural networks (GNNs) have demonstrated their excellentperformance in solving power control problems. However, all existing GNN-basedapproaches assume ideal orthogonality among pilot sequences for user equipments(UEs), which is unrealistic given that the number of UEs exceeds the availableorthogonal pilot sequences in CFmMIMO schemes. Moreover, most learning-basedmethods assume a fixed number of UEs, whereas the number of active UEs variesover time in practice. Additionally, supervised training necessitates costlycomputational resources for computing the target power control solutions for alarge volume of training samples. To address these issues, we propose a graphattention network for downlink power control in CFmMIMO systems that operatesin a self-supervised manner while effectively handling pilot contamination andadapting to a dynamic number of UEs. Experimental results show itseffectiveness, even in comparison to the optimal accelerated projected gradientmethod as a baseline.</description>
      <author>example@mail.com (Tingting Zhang, Sergiy A. Vorobyov, David J. Love, Taejoon Kim, Kai Dong)</author>
      <guid isPermaLink="false">2506.00967v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>General-purpose audio representation learning for real-world sound scenes</title>
      <link>http://arxiv.org/abs/2506.00934v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的自监督训练方法，用于通用、真实世界音频模型（GRAMs），旨在解决现有音频基础模型在真实世界应用中的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有的音频基础模型在非空间、单声源音频片段上训练和测试，导致它们在真实世界场景中的表现受限，并且缺乏空间感知的音频嵌入。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自监督训练方法，以实现自然、嘈杂声音场景中的鲁棒空间音频表示学习，并应用于任何基于掩码的深度学习模型。&lt;h4&gt;方法&lt;/h4&gt;通过训练两个最先进的模型（一个基于transformer，一个基于mamba骨干网络）来展示方法的有效性，并使用HEAR基准、新合成的自然版本HEAR基准和基于HEAR基准数据集的新的声音定位任务来评估提取的音频表示的质量。&lt;h4&gt;主要发现&lt;/h4&gt;该方法最小化了干、非空间、单声源声音场景与自然声音场景之间的性能差距，在关键任务如听觉场景分析方面超越了现有最先进的音频基础模型，并且在训练步骤中占比较小。此外，GRAMs在声音定位任务上表现出最先进的性能，甚至超过了监督声音定位模型。&lt;h4&gt;结论&lt;/h4&gt;该方法代表了向鲁棒的音频基础模型迈出的重要一步，这些模型在自然声音场景以及空间音频表示学习方面均达到最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;While audio foundation models perform well on myriad of tasks from sound classification to speech analysis, these models are trained and tested on dry, non-spatial, single-source audio clips. This limits their success in real-world situations and results in spatially unaware audio embeddings. To address these limitations, we propose a novel self-supervised training approach for General-Purpose, Real-world Audio Models (GRAMs). The GRAM training approach enables robust spatial audio representation learning for naturalistic, noisy sound scenes and can be applied to any masking-based deep learning model. We demonstrate the success of our approach by training two state-of-the-art models, one with a transformer and one with a mamba backbone. We assess the quality of the extracted audio representations from GRAMs using the original version of the HEAR benchmark, a newly synthesized, naturalistic version of the HEAR benchmark, and novel sound localization tasks based on HEAR benchmark datasets. The results show that our approach minimizes the performance gap between dry, non-spatial, single-source sound scenes and naturalistic sound scenes for crucial tasks such as auditory scene analysis, outperforming existing state-of-the-art audio foundation models at a fraction of the training steps. Moreover, GRAMs show state-of-the-art performance on sound localization tasks, exceeding even supervised sound localization models. In sum, the proposed approach represents a significant advancement towards robust audio foundation models for real-world applications with state-of-the-art performance on naturalistic sound scenes as well as spatial audio representation learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While audio foundation models perform well on myriad of tasks from soundclassification to speech analysis, these models are trained and tested on dry,non-spatial, single-source audio clips. This limits their success in real-worldsituations and results in spatially unaware audio embeddings. To address theselimitations, we propose a novel self-supervised training approach forGeneral-Purpose, Real-world Audio Models (GRAMs). The GRAM training approachenables robust spatial audio representation learning for naturalistic, noisysound scenes and can be applied to any masking-based deep learning model. Wedemonstrate the success of our approach by training two state-of-the-artmodels, one with a transformer and one with a mamba backbone. We assess thequality of the extracted audio representations from GRAMs using the originalversion of the HEAR benchmark, a newly synthesized, naturalistic version of theHEAR benchmark, and novel sound localization tasks based on HEAR benchmarkdatasets. The results show that our approach minimizes the performance gapbetween dry, non-spatial, single-source sound scenes and naturalistic soundscenes for crucial tasks such as auditory scene analysis, outperformingexisting state-of-the-art audio foundation models at a fraction of the trainingsteps. Moreover, GRAMs show state-of-the-art performance on sound localizationtasks, exceeding even supervised sound localization models. In sum, theproposed approach represents a significant advancement towards robust audiofoundation models for real-world applications with state-of-the-art performanceon naturalistic sound scenes as well as spatial audio representation learning.</description>
      <author>example@mail.com (Goksenin Yuksel, Marcel van Gerven, Kiki van der Heijden)</author>
      <guid isPermaLink="false">2506.00934v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Reinforcement Learning Tuning for VideoLLMs: Reward Design and Data Efficiency</title>
      <link>http://arxiv.org/abs/2506.01908v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用多模态大型语言模型（MLLMs）理解具有复杂语义和长期时间依赖性的真实世界视频的问题。通过探索强化学习调优（RLT）作为后训练策略来增强MLLMs的视频特定推理能力，提出了一种基于GRPO框架的Dual-reward公式，并通过离散和连续奖励信号监督语义和时间推理。此外，引入了一种基于重复推理的方差感知数据选择策略，以促进基于偏好的优化，并在多个视频理解任务上取得了优于监督微调和现有RLT基线的性能。&lt;h4&gt;背景&lt;/h4&gt;理解具有复杂语义和长期时间依赖性的真实世界视频是计算机视觉中的基本挑战。&lt;h4&gt;目的&lt;/h4&gt;利用强化学习调优（RLT）作为后训练策略来增强MLLMs的视频特定推理能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于GRPO框架的Dual-reward公式，并引入了方差感知数据选择策略。&lt;h4&gt;主要发现&lt;/h4&gt;在八个代表性的视频理解任务上，方法表现优于监督微调和现有RLT基线，且在更少的训练数据下实现了更优的性能。&lt;h4&gt;结论&lt;/h4&gt;奖励设计和数据选择对于利用MLLMs推进以推理为中心的视频理解至关重要。&lt;h4&gt;翻译&lt;/h4&gt;Understanding real-world videos with complex semantics and long temporaldependencies remains a fundamental challenge in computer vision. Recentprogress in multimodal large language models (MLLMs) has demonstrated strongcapabilities in vision-language tasks, while reinforcement learning tuning(RLT) has further improved their reasoning abilities. In this work, we exploreRLT as a post-training strategy to enhance the video-specific reasoningcapabilities of MLLMs. Built upon the Group Relative Policy Optimization (GRPO)framework, we propose a dual-reward formulation that supervises both semanticand temporal reasoning through discrete and continuous reward signals. Tofacilitate effective preference-based optimization, we introduce avariance-aware data selection strategy based on repeated inference to identifysamples that provide informative learning signals. We evaluate our approachacross eight representative video understanding tasks, including VideoQA,Temporal Video Grounding, and Grounded VideoQA. Our method consistentlyoutperforms supervised fine-tuning and existing RLT baselines, achievingsuperior performance with significantly less training data. These resultsunderscore the importance of reward design and data selection in advancingreasoning-centric video understanding with MLLMs. Notably, The initial coderelease (two months ago) has now been expanded with updates, includingoptimized reward mechanisms and additional datasets. The latest version isavailable at https://github.com/appletea233/Temporal-R1 .&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding real-world videos with complex semantics and long temporaldependencies remains a fundamental challenge in computer vision. Recentprogress in multimodal large language models (MLLMs) has demonstrated strongcapabilities in vision-language tasks, while reinforcement learning tuning(RLT) has further improved their reasoning abilities. In this work, we exploreRLT as a post-training strategy to enhance the video-specific reasoningcapabilities of MLLMs. Built upon the Group Relative Policy Optimization (GRPO)framework, we propose a dual-reward formulation that supervises both semanticand temporal reasoning through discrete and continuous reward signals. Tofacilitate effective preference-based optimization, we introduce avariance-aware data selection strategy based on repeated inference to identifysamples that provide informative learning signals. We evaluate our approachacross eight representative video understanding tasks, including VideoQA,Temporal Video Grounding, and Grounded VideoQA. Our method consistentlyoutperforms supervised fine-tuning and existing RLT baselines, achievingsuperior performance with significantly less training data. These resultsunderscore the importance of reward design and data selection in advancingreasoning-centric video understanding with MLLMs. Notably, The initial coderelease (two months ago) has now been expanded with updates, includingoptimized reward mechanisms and additional datasets. The latest version isavailable at https://github.com/appletea233/Temporal-R1 .</description>
      <author>example@mail.com (Hongyu Li, Songhao Han, Yue Liao, Junfeng Luo, Jialin Gao, Shuicheng Yan, Si Liu)</author>
      <guid isPermaLink="false">2506.01908v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>COGNATE: Acceleration of Sparse Tensor Programs on Emerging Hardware using Transfer Learning</title>
      <link>http://arxiv.org/abs/2506.00424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the 42nd International Conference on Machine Learning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了COGNATE框架，该框架利用通用硬件（如CPU）的低成本数据样本来训练成本模型，并在新兴硬件上进行少量样本的微调，以优化稀疏张量程序。&lt;h4&gt;背景&lt;/h4&gt;稀疏张量程序在深度学习和图分析中至关重要，需要专门的硬件加速器来优化处理。&lt;h4&gt;目的&lt;/h4&gt;为了应对稀疏输入的变异性以及早期加速器依赖昂贵的模拟器的问题，开发了一种新的框架COGNATE。&lt;h4&gt;方法&lt;/h4&gt;COGNATE利用硬件平台间输入特征的均匀性，通过少量数据样本进行成本模型训练，并在新兴硬件上进行少量样本的微调。&lt;h4&gt;主要发现&lt;/h4&gt;COGNATE在实验中优于现有技术，SpMM的平均加速达到1.47倍（最高5.46倍），SDDMM的平均加速达到1.39倍（最高4.22倍）。&lt;h4&gt;结论&lt;/h4&gt;COGNATE通过有效降低数据样本需求，提高了成本模型训练的效率，适用于早期加速器的优化。&lt;h4&gt;翻译&lt;/h4&gt;Sparse tensor programs are essential in deep learning and graph analytics, driving the need for optimized processing. To meet this demand, specialized hardware accelerators are being developed. Optimizing these programs for accelerators is challenging for two reasons: program performance is highly sensitive to variations in sparse inputs, and early-stage accelerators rely on expensive simulators. Therefore, ML-based cost models used for optimizing such programs on general-purpose hardware are often ineffective for early-stage accelerators, as they require large datasets for proper training. To this end, we introduce COGNATE, a novel framework that leverages inexpensive data samples from general-purpose hardware (e.g., CPUs) to train cost models, followed by few-shot fine-tuning on emerging hardware. COGNATE exploits the homogeneity of input features across hardware platforms while effectively mitigating heterogeneity, enabling cost model training with just 5% of the data samples needed by accelerator-specific models to achieve comparable performance. We conduct extensive experiments to demonstrate that COGNATE outperforms existing techniques, achieving average speedups of 1.47x (up to 5.46x) for SpMM and 1.39x (up to 4.22x) for SDDMM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sparse tensor programs are essential in deep learning and graph analytics,driving the need for optimized processing. To meet this demand, specializedhardware accelerators are being developed. Optimizing these programs foraccelerators is challenging for two reasons: program performance is highlysensitive to variations in sparse inputs, and early-stage accelerators rely onexpensive simulators. Therefore, ML-based cost models used for optimizing suchprograms on general-purpose hardware are often ineffective for early-stageaccelerators, as they require large datasets for proper training. To this end,we introduce COGNATE, a novel framework that leverages inexpensive data samplesfrom general-purpose hardware (e.g., CPUs) to train cost models, followed byfew-shot fine-tuning on emerging hardware. COGNATE exploits the homogeneity ofinput features across hardware platforms while effectively mitigatingheterogeneity, enabling cost model training with just 5% of the data samplesneeded by accelerator-specific models to achieve comparable performance. Weconduct extensive experiments to demonstrate that COGNATE outperforms existingtechniques, achieving average speedups of 1.47x (up to 5.46x) for SpMM and1.39x (up to 4.22x) for SDDMM.</description>
      <author>example@mail.com (Chamika Sudusinghe, Gerasimos Gerogiannis Damitha Lenadora, Charles Block, Josep Torrellas, Charith Mendis)</author>
      <guid isPermaLink="false">2506.00424v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty-Aware Metabolic Stability Prediction with Dual-View Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.00936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This manuscript has been accepted for publication at ECML-PKDD 2025.  The final version will be published in the conference proceedings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为TrustworthyMS的代谢稳定性预测新框架，旨在解决现有方法在分子模型和不确定性量化方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;准确预测分子的代谢稳定性对于药物研发至关重要，但由于分子间复杂的相互作用，这一任务具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出TrustworthyMS框架，以提高代谢稳定性预测的准确性和可靠性。&lt;h4&gt;方法&lt;/h4&gt;1. 使用分子图拓扑重映射机制同步原子-键相互作用；2. 通过对比拓扑-键对齐增强表示的鲁棒性；3. 利用Beta-Binomial不确定性量化模型进行预测和置信度校准。&lt;h4&gt;主要发现&lt;/h4&gt;TrustworthyMS在预测性能方面优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;TrustworthyMS是一种有效且可靠的代谢稳定性预测工具，可提高药物研发的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction of molecular metabolic stability (MS) is critical fordrug research and development but remains challenging due to the complexinterplay of molecular interactions. Despite recent advances in graph neuralnetworks (GNNs) for MS prediction, current approaches face two criticallimitations: (1) incomplete molecular modeling due to atom-centricmessage-passing mechanisms that disregard bond-level topological features, and(2) prediction frameworks that lack reliable uncertainty quantification. Toaddress these challenges, we propose TrustworthyMS, a novel contrastivelearning framework designed for uncertainty-aware metabolic stabilityprediction. First, a molecular graph topology remapping mechanism synchronizesatom-bond interactions through edge-induced feature propagation, capturing bothlocalized electronic effects and global conformational constraints. Second,contrastive topology-bond alignment enforces consistency between moleculartopology views and bond patterns via feature alignment, enhancingrepresentation robustness. Third, uncertainty modeling through Beta-Binomialuncertainty quantification enables simultaneous prediction and confidencecalibration under epistemic uncertainty. Through extensive experiments, ourresults demonstrate that TrustworthyMS outperforms current state-of-the-artmethods in terms of predictive performance.</description>
      <author>example@mail.com (Peijin Guo, Minghui Li, Hewen Pan, Bowen Chen, Yang Wu, Zikang Guo, Leo Yu Zhang, Shengshan Hu, Shengqing Hu)</author>
      <guid isPermaLink="false">2506.00936v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Auto-Labeling Data for Object Detection</title>
      <link>http://arxiv.org/abs/2506.02359v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种无需真实标签训练标准目标检测模型的方法，通过配置预训练的视觉-语言基础模型生成特定应用的伪真实标签，以降低传统标注成本并提高模型效率。&lt;h4&gt;背景&lt;/h4&gt;传统标注方法在规模上成本高昂，而全监督目标检测的替代方案要么功能受损，要么需要大型模型，导致推理成本过高。&lt;h4&gt;目的&lt;/h4&gt;旨在解决在无需地面真实标签的情况下训练标准目标检测模型的问题。&lt;h4&gt;方法&lt;/h4&gt;配置预训练的视觉-语言基础模型生成应用特定的伪真实标签，与现有模型训练框架集成，并训练轻量级检测模型。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个数据集上保持了有竞争力的性能，同时显著减少了标注时间和成本。&lt;h4&gt;结论&lt;/h4&gt;该方法在多个数据集上提供了与传统标注相竞争的性能，是一种有效的替代方案，适用于实际应用。&lt;h4&gt;翻译&lt;/h4&gt;Great labels make great models. However, traditional labeling approaches for tasks like object detection have substantial costs at scale. Furthermore, alternatives to fully-supervised object detection either lose functionality or require larger models with prohibitive computational costs for inference at scale. To that end, this paper addresses the problem of training standard object detection models without any ground truth labels. Instead, we configure previously-trained vision-language foundation models to generate application-specific pseudo "ground truth" labels. These auto-generated labels directly integrate with existing model training frameworks, and we subsequently train lightweight detection models that are computationally efficient. In this way, we avoid the costs of traditional labeling, leverage the knowledge of vision-language models, and keep the efficiency of lightweight models for practical application. We perform exhaustive experiments across multiple labeling configurations, downstream inference models, and datasets to establish best practices and set an extensive auto-labeling benchmark. From our results, we find that our approach is a viable alternative to standard labeling in that it maintains competitive performance on multiple datasets and substantially reduces labeling time and costs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Great labels make great models. However, traditional labeling approaches fortasks like object detection have substantial costs at scale. Furthermore,alternatives to fully-supervised object detection either lose functionality orrequire larger models with prohibitive computational costs for inference atscale. To that end, this paper addresses the problem of training standardobject detection models without any ground truth labels. Instead, we configurepreviously-trained vision-language foundation models to generateapplication-specific pseudo "ground truth" labels. These auto-generated labelsdirectly integrate with existing model training frameworks, and we subsequentlytrain lightweight detection models that are computationally efficient. In thisway, we avoid the costs of traditional labeling, leverage the knowledge ofvision-language models, and keep the efficiency of lightweight models forpractical application. We perform exhaustive experiments across multiplelabeling configurations, downstream inference models, and datasets to establishbest practices and set an extensive auto-labeling benchmark. From our results,we find that our approach is a viable alternative to standard labeling in thatit maintains competitive performance on multiple datasets and substantiallyreduces labeling time and costs.</description>
      <author>example@mail.com (Brent A. Griffin, Manushree Gangwar, Jacob Sela, Jason J. Corso)</author>
      <guid isPermaLink="false">2506.02359v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Linear Representation Transferability Hypothesis: Leveraging Small Models to Steer Large Models</title>
      <link>http://arxiv.org/abs/2506.00653v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为线性表示可迁移性（LRT）的假设，认为不同规模模型的表示空间之间存在亲和变换，并通过实验验证了小模型的表示可以指导大模型的行为。&lt;h4&gt;背景&lt;/h4&gt;已有研究表明，具有相似架构的神经网络在相似数据上学习到与学习任务相关的共享表示。&lt;h4&gt;目的&lt;/h4&gt;提出LRT假设，并通过实验验证不同规模模型之间的表示空间是否存在亲和变换。&lt;h4&gt;方法&lt;/h4&gt;学习不同规模模型隐藏状态之间的仿射映射，并评估转移向量（与特定模型行为相关的隐藏状态方向）在从小型到大型语言模型转移时是否保持其语义效果。&lt;h4&gt;主要发现&lt;/h4&gt;实验发现，这些仿射映射可以保留引导行为。&lt;h4&gt;结论&lt;/h4&gt;小模型学习到的表示可以用于指导大模型的行为，LRT假设可能是在理解模型尺度间表示对齐方面的一个有希望的方向。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为线性表示可迁移性（LRT）的假设，认为不同规模模型的表示空间之间存在亲和变换，并通过实验验证了小模型的表示可以指导大模型的行为。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; It has been hypothesized that neural networks with similar architecturestrained on similar data learn shared representations relevant to the learningtask. We build on this idea by extending the conceptual framework whererepresentations learned across models trained on the same data can be expressedas linear combinations of a \emph{universal} set of basis features. These basisfeatures underlie the learning task itself and remain consistent across models,regardless of scale. From this framework, we propose the \textbf{LinearRepresentation Transferability (LRT)} Hypothesis -- that there exists an affinetransformation between the representation spaces of different models. To testthis hypothesis, we learn affine mappings between the hidden states of modelsof different sizes and evaluate whether steering vectors -- directions inhidden state space associated with specific model behaviors -- retain theirsemantic effect when transferred from small to large language models using thelearned mappings. We find strong empirical evidence that such affine mappingscan preserve steering behaviors. These findings suggest that representationslearned by small models can be used to guide the behavior of large models, andthat the LRT hypothesis may be a promising direction on understandingrepresentation alignment across model scales.</description>
      <author>example@mail.com (Femi Bello, Anubrata Das, Fanzhi Zeng, Fangcong Yin, Liu Leqi)</author>
      <guid isPermaLink="false">2506.00653v2</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>ReAgent-V: A Reward-Driven Multi-Agent Framework for Video Understanding</title>
      <link>http://arxiv.org/abs/2506.01300v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 18 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ReAgent-V的新型视频理解框架，该框架通过高效的帧选择和实时奖励生成来增强推理能力，并支持灵活的工具集成。&lt;h4&gt;背景&lt;/h4&gt;传统的视频理解方法在复杂场景中存在自我校正和适应能力不足的问题。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法的局限性，提高视频理解模型的推理能力和泛化性能。&lt;h4&gt;方法&lt;/h4&gt;ReAgent-V框架集成了奖励模型和强化学习，并通过多视角反射机制调整预测，同时支持数据过滤和偏好优化。&lt;h4&gt;主要发现&lt;/h4&gt;在12个数据集上进行的实验表明，ReAgent-V在视频理解、视频推理增强和视觉-语言-动作模型对齐三个核心应用中取得了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;ReAgent-V框架有效地提高了视频理解模型的推理能力和泛化性能，展现了其有效性和通用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video understanding is fundamental to tasks such as action recognition, videoreasoning, and robotic control. Early video understanding methods based onlarge vision-language models (LVLMs) typically adopt a single-pass reasoningparadigm without dynamic feedback, limiting the model's capacity toself-correct and adapt in complex scenarios. Recent efforts have attempted toaddress this limitation by incorporating reward models and reinforcementlearning to enhance reasoning, or by employing tool-agent frameworks. However,these approaches face several challenges, including high annotation costs,reward signals that fail to capture real-time reasoning states, and lowinference efficiency. To overcome these issues, we propose ReAgent-V, a novelagentic video understanding framework that integrates efficient frame selectionwith real-time reward generation during inference. These reward signals notonly guide iterative answer refinement through a multi-perspective reflectionmechanism-adjusting predictions from conservative, neutral, and aggressiveviewpoints-but also enable automatic filtering of high-quality data forsupervised fine-tuning (SFT), direct preference optimization (DPO), and grouprelative policy optimization (GRPO). ReAgent-V is lightweight, modular, andextensible, supporting flexible tool integration tailored to diverse tasks.Extensive experiments on 12 datasets across three core applications-videounderstanding, video reasoning enhancement, and vision-language-action modelalignment-demonstrate significant gains in generalization and reasoning, withimprovements of up to 6.9%, 2.1%, and 9.8%, respectively, highlighting theeffectiveness and versatility of the proposed framework.</description>
      <author>example@mail.com (Yiyang Zhou, Yangfan He, Yaofeng Su, Siwei Han, Joel Jang, Gedas Bertasius, Mohit Bansal, Huaxiu Yao)</author>
      <guid isPermaLink="false">2506.01300v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Neuro2Semantic: A Transfer Learning Framework for Semantic Reconstruction of Continuous Language from Human Intracranial EEG</title>
      <link>http://arxiv.org/abs/2506.00381v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Interspeech 2025 Code at  https://github.com/SiavashShams/neuro2semantic&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Neuro2Semantic的新框架，用于从颅内脑电图（iEEG）记录中重建感知语音的语义内容。&lt;h4&gt;背景&lt;/h4&gt;解码连续语言从神经信号中是神经科学与人工智能交叉领域的一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够从神经数据中重建语义内容的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法分为两个阶段：首先，基于LSTM的适配器将神经信号与预训练的文本嵌入对齐；其次，校正模块直接从这些对齐的嵌入生成连续、自然的文本。&lt;h4&gt;主要发现&lt;/h4&gt;Neuro2Semantic在低数据设置下表现优异，仅用30分钟的神经数据就超越了最近的一项最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;这些结果突显了Neuro2Semantic在脑机接口和神经解码技术中的实际应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从神经信号中解码连续语言是神经科学与人工智能交叉领域的一个重大挑战。我们提出了一种名为Neuro2Semantic的新框架，该框架可以从颅内脑电图（iEEG）记录中重建感知语音的语义内容。我们的方法包括两个阶段：首先，基于LSTM的适配器将神经信号与预训练的文本嵌入对齐；其次，校正模块直接从这些对齐的嵌入生成连续、自然的文本。这种灵活的方法克服了先前解码方法的局限性，并实现了不受约束的文本生成。Neuro2Semantic在低数据设置下实现了强大的性能，仅用30分钟的神经数据就超越了最近的一项最先进的方法。这些结果突显了Neuro2Semantic在脑机接口和神经解码技术中的实际应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decoding continuous language from neural signals remains a significantchallenge in the intersection of neuroscience and artificial intelligence. Weintroduce Neuro2Semantic, a novel framework that reconstructs the semanticcontent of perceived speech from intracranial EEG (iEEG) recordings. Ourapproach consists of two phases: first, an LSTM-based adapter aligns neuralsignals with pre-trained text embeddings; second, a corrector module generatescontinuous, natural text directly from these aligned embeddings. This flexiblemethod overcomes the limitations of previous decoding approaches and enablesunconstrained text generation. Neuro2Semantic achieves strong performance withas little as 30 minutes of neural data, outperforming a recent state-of-the-artmethod in low-data settings. These results highlight the potential forpractical applications in brain-computer interfaces and neural decodingtechnologies.</description>
      <author>example@mail.com (Siavash Shams, Richard Antonello, Gavin Mischler, Stephan Bickel, Ashesh Mehta, Nima Mesgarani)</author>
      <guid isPermaLink="false">2506.00381v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>EEG2TEXT-CN: An Exploratory Study of Open-Vocabulary Chinese Text-EEG Alignment via Large Language Model and Contrastive Learning on ChineseEEG</title>
      <link>http://arxiv.org/abs/2506.00854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为EEG2TEXT-CN的开源词汇EEG到文本生成框架，针对中文进行了优化。&lt;h4&gt;背景&lt;/h4&gt;目前尚无专门针对中文的开源词汇EEG到文本生成框架。&lt;h4&gt;目的&lt;/h4&gt;构建一个能够将脑电图（EEG）信号转换为文本的框架。&lt;h4&gt;方法&lt;/h4&gt;基于生物基础的EEG编码器（NICE-EEG）和紧凑的预训练语言模型（MiniLM），通过掩码预训练和对比学习将多通道脑信号与自然语言表示对齐。使用中文EEG数据集的子集，对每个句子中的汉字进行编码，并在零样本设置中预测完整句子。解码器使用教师强制和填充掩码进行训练，以适应不同长度的序列。&lt;h4&gt;主要发现&lt;/h4&gt;在超过1500个训练-验证句子和300个保留测试样本上的评估显示，有希望的词汇对齐，最佳BLEU-1分数为6.38%。虽然句法流畅性仍然是一个挑战，但研究结果证明了从EEG中解码非语音、跨模态语言的可能性。&lt;h4&gt;结论&lt;/h4&gt;该研究在多语言脑到文本研究领域开辟了新的方向，为中文的认知语言界面奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose EEG2TEXT-CN, which, to the best of our knowledge, represents oneof the earliest open-vocabulary EEG-to-text generation frameworks tailored forChinese. Built on a biologically grounded EEG encoder (NICE-EEG) and a compactpretrained language model (MiniLM), our architecture aligns multichannel brainsignals with natural language representations via masked pretraining andcontrastive learning. Using a subset of the ChineseEEG dataset, where eachsentence contains approximately ten Chinese characters aligned with 128-channelEEG recorded at 256 Hz, we segment EEG into per-character embeddings andpredict full sentences in a zero-shot setting. The decoder is trained withteacher forcing and padding masks to accommodate variable-length sequences.Evaluation on over 1,500 training-validation sentences and 300 held-out testsamples shows promising lexical alignment, with a best BLEU-1 score of 6.38\%.While syntactic fluency remains a challenge, our findings demonstrate thefeasibility of non-phonetic, cross-modal language decoding from EEG. This workopens a new direction in multilingual brain-to-text research and lays thefoundation for future cognitive-language interfaces in Chinese.</description>
      <author>example@mail.com (Jacky Tai-Yu Lu, Jung Chiang, Chi-Sheng Chen, Anna Nai-Yun Tung, Hsiang Wei Hu, Yuan Chiao Cheng)</author>
      <guid isPermaLink="false">2506.00854v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Lyrics Transcription on Music Mixtures with Consistency Loss</title>
      <link>http://arxiv.org/abs/2506.02339v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to Interspeech&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究自动歌词转录（ALT）技术，旨在识别歌唱声音中的歌词，并探讨了低秩自适应（LoRA）在ALT中的应用，同时提出了使用一致性损失来改进转录方法。&lt;h4&gt;背景&lt;/h4&gt;自动歌词转录与自动语音识别（ASR）类似，但由于歌唱声音的领域特定属性，ALT面临额外的复杂性。基础ASR模型在处理歌唱声音时表现不佳，尤其是在有音乐伴奏的情况下。&lt;h4&gt;目的&lt;/h4&gt;旨在解决基础ASR模型在歌唱声音上的性能下降问题，并探索LoRA在ALT中的应用。&lt;h4&gt;方法&lt;/h4&gt;研究了单领域和双领域微调策略，并提出使用一致性损失来更好地对齐语音和混合编码器表示，从而在不依赖歌唱声音分离的情况下改进转录。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明，虽然简单的双领域微调表现不佳，但采用一致性损失的系统训练可以获得适度但一致的性能提升。&lt;h4&gt;结论&lt;/h4&gt;证明了通过调整ASR基础模型来适应音乐转录的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Automatic Lyrics Transcription (ALT) aims to recognize lyrics from singing voices, similar to Automatic Speech Recognition (ASR) for spoken language, but faces added complexity due to domain-specific properties of the singing voice. While foundation ASR models show robustness in various speech tasks, their performance degrades on singing voice, especially in the presence of musical accompaniment. This work focuses on this performance gap and explores Low-Rank Adaptation (LoRA) for ALT, investigating both single-domain and dual-domain fine-tuning strategies. We propose using a consistency loss to better align vocal and mixture encoder representations, improving transcription on mixture without relying on singing voice separation. Our results show that while naive dual-domain fine-tuning underperforms, structured training with consistency loss yields modest but consistent gains, demonstrating the potential of adapting ASR foundation models for music.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic Lyrics Transcription (ALT) aims to recognize lyrics from singingvoices, similar to Automatic Speech Recognition (ASR) for spoken language, butfaces added complexity due to domain-specific properties of the singing voice.While foundation ASR models show robustness in various speech tasks, theirperformance degrades on singing voice, especially in the presence of musicalaccompaniment. This work focuses on this performance gap and explores Low-RankAdaptation (LoRA) for ALT, investigating both single-domain and dual-domainfine-tuning strategies. We propose using a consistency loss to better alignvocal and mixture encoder representations, improving transcription on mixturewithout relying on singing voice separation. Our results show that whilena\"ive dual-domain fine-tuning underperforms, structured training withconsistency loss yields modest but consistent gains, demonstrating thepotential of adapting ASR foundation models for music.</description>
      <author>example@mail.com (Jiawen Huang, Felipe Sousa, Emir Demirel, Emmanouil Benetos, Igor Gadelha)</author>
      <guid isPermaLink="false">2506.02339v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Unlearning Inversion Attacks for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.00808v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TrendAttack的图反学习攻击方法，用于对抗图神经网络（GNN）中的图反学习技术，通过分析未学习到的边及其影响，揭示了当前图反学习方法在隐私保护方面的脆弱性。&lt;h4&gt;背景&lt;/h4&gt;图反学习方法旨在从训练好的GNN中移除敏感数据的影响，而不进行完整的重新训练，假设删除的信息无法恢复。&lt;h4&gt;目的&lt;/h4&gt;挑战假设删除的信息无法恢复，研究是否可以通过黑盒访问未学习的GNN和部分图知识来重建删除的边。&lt;h4&gt;方法&lt;/h4&gt;提出了TrendAttack，通过利用模型对未学习边附近节点的信心下降这一理论和实证模式，以及设计自适应预测机制，对不同类型的边应用不同的相似度阈值。&lt;h4&gt;主要发现&lt;/h4&gt;发现未学习边附近节点的模型信心显著下降，并设计了一种自适应预测机制，该机制可以根据不同的边类型调整相似度阈值。&lt;h4&gt;结论&lt;/h4&gt;实验表明，TrendAttack在四个真实世界数据集上显著优于现有的GNN成员推断基线，揭示了当前图反学习方法在隐私保护方面的关键漏洞。&lt;h4&gt;翻译&lt;/h4&gt;Graph unlearning methods aim to efficiently remove the impact of sensitive data from trained GNNs without full retraining, assuming that deleted information cannot be recovered. In this work, we challenge this assumption by introducing the graph unlearning inversion attack: given only black-box access to an unlearned GNN and partial graph knowledge, can an adversary reconstruct the removed edges? We identify two key challenges: varying probability-similarity thresholds for unlearned versus retained edges, and the difficulty of locating unlearned edge endpoints, and address them with TrendAttack. First, we derive and exploit the confidence pitfall, a theoretical and empirical pattern showing that nodes adjacent to unlearned edges exhibit a large drop in model confidence. Second, we design an adaptive prediction mechanism that applies different similarity thresholds to unlearned and other membership edges. Our framework flexibly integrates existing membership inference techniques and extends them with trend features. Experiments on four real-world datasets demonstrate that TrendAttack significantly outperforms state-of-the-art GNN membership inference baselines, exposing a critical privacy vulnerability in current graph unlearning methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph unlearning methods aim to efficiently remove the impact of sensitivedata from trained GNNs without full retraining, assuming that deletedinformation cannot be recovered. In this work, we challenge this assumption byintroducing the graph unlearning inversion attack: given only black-box accessto an unlearned GNN and partial graph knowledge, can an adversary reconstructthe removed edges? We identify two key challenges: varyingprobability-similarity thresholds for unlearned versus retained edges, and thedifficulty of locating unlearned edge endpoints, and address them withTrendAttack. First, we derive and exploit the confidence pitfall, a theoreticaland empirical pattern showing that nodes adjacent to unlearned edges exhibit alarge drop in model confidence. Second, we design an adaptive predictionmechanism that applies different similarity thresholds to unlearned and othermembership edges. Our framework flexibly integrates existing membershipinference techniques and extends them with trend features. Experiments on fourreal-world datasets demonstrate that TrendAttack significantly outperformsstate-of-the-art GNN membership inference baselines, exposing a criticalprivacy vulnerability in current graph unlearning methods.</description>
      <author>example@mail.com (Jiahao Zhang, Yilong Wang, Zhiwei Zhang, Xiaorui Liu, Suhang Wang)</author>
      <guid isPermaLink="false">2506.00808v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Domain Adaptation-Driven Physics-Informed Graph Representation Learning for AC-OPF</title>
      <link>http://arxiv.org/abs/2506.00478v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的AC-OPF求解器DDA-PIGCN，用于优化发电机功率输出，并通过结合时空特征来克服传统方法在约束建模和知识表示方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;当前AC-OPF求解器难以有效表示约束空间中变量分布与最优解之间的复杂关系，且仅基于空间拓扑建模电力系统限制了额外先验知识的整合。&lt;h4&gt;目的&lt;/h4&gt;提出DDA-PIGCN方法，旨在解决约束相关的问题，并构建一个结合时空特征的图学习框架。&lt;h4&gt;方法&lt;/h4&gt;DDA-PIGCN采用多层硬物理信息约束来改进具有不同长程依赖关系的特征的一致性优化，并使用动态域适应学习机制在预定义约束下迭代更新和细化关键状态变量。它通过利用电力网的物理结构捕捉发电机和负荷之间的时空依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;通过在多个IEEE标准测试案例（如案例9、案例30和案例300）上的比较和消融研究，DDA-PIGCN表现出色，平均绝对误差（MAE）在0.0011到0.0624之间，约束满意度在99.6%到100%之间。&lt;h4&gt;结论&lt;/h4&gt;DDA-PIGCN是一种可靠且高效的AC-OPF求解器，为电力系统优化提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Alternating Current Optimal Power Flow (AC-OPF) aims to optimize generatorpower outputs by utilizing the non-linear relationships between voltagemagnitudes and phase angles in a power system. However, current AC-OPF solversstruggle to effectively represent the complex relationship between variabledistributions in the constraint space and their corresponding optimalsolutions. This limitation in constraint modeling restricts the system'sability to develop diverse knowledge representations. Additionally, modelingthe power grid solely based on spatial topology further limits the integrationof additional prior knowledge, such as temporal information. To overcome thesechallenges, we propose DDA-PIGCN (Dynamic Domain Adaptation-DrivenPhysics-Informed Graph Convolutional Network), a new method designed to addressconstraint-related issues and build a graph-based learning framework thatincorporates spatiotemporal features. DDA-PIGCN improves consistencyoptimization for features with varying long-range dependencies by applyingmulti-layer, hard physics-informed constraints. It also uses a dynamic domainadaptation learning mechanism that iteratively updates and refines key statevariables under predefined constraints, enabling precise constraintverification. Moreover, it captures spatiotemporal dependencies betweengenerators and loads by leveraging the physical structure of the power grid,allowing for deep integration of topological information across time and space.Extensive comparative and ablation studies show that DDA-PIGCN delivers strongperformance across several IEEE standard test cases (such as case9, case30, andcase300), achieving mean absolute errors (MAE) from 0.0011 to 0.0624 andconstraint satisfaction rates between 99.6% and 100%, establishing it as areliable and efficient AC-OPF solver.</description>
      <author>example@mail.com (Hongjie Zhu, Zezheng Zhang, Zeyu Zhang, Yu Bai, Shimin Wen, Huazhang Wang, Daji Ergu, Ying Cai, Yang Zhao)</author>
      <guid isPermaLink="false">2506.00478v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MOOSE: Pay Attention to Temporal Dynamics for Video Understanding via Optical Flows</title>
      <link>http://arxiv.org/abs/2506.01119v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MOOSE的新型视频编码器，该编码器通过结合光流和空间嵌入来高效地建模时间信息，旨在解决视频分析中的时间动态捕捉问题。&lt;h4&gt;背景&lt;/h4&gt;许多视频分析任务需要高效且可解释的时间建模，如原子动作、自闭症患者的异常运动行为检测或实时MRI中的人类语音的发音运动分析。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的视频理解架构，以减少计算复杂度并提高时间动态建模的可解释性。&lt;h4&gt;方法&lt;/h4&gt;MOOSE利用预训练的视觉和光流编码器，而不是从头开始训练视频模型，从而实现高效的时态建模。&lt;h4&gt;主要发现&lt;/h4&gt;MOOSE在多个基准测试中取得了最先进的性能，包括临床、医学和标准动作识别数据集，证明了其广泛的应用性和有效性。&lt;h4&gt;结论&lt;/h4&gt;MOOSE通过结合光流和空间嵌入，为视频分析中的时间建模提供了一种高效且可解释的方法，显著提高了性能并降低了计算成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many motion-centric video analysis tasks, such as atomic actions, detectingatypical motor behavior in individuals with autism, or analyzing articulatorymotion in real-time MRI of human speech, require efficient and interpretabletemporal modeling. Capturing temporal dynamics is a central challenge in videoanalysis, often requiring significant computational resources and fine-grainedannotations that are not widely available. This paper presents MOOSE (MotionFlow Over Spatial Space), a novel temporally-centric video encoder explicitlyintegrating optical flow with spatial embeddings to model temporal informationefficiently, inspired by human perception of motion. Unlike prior models, MOOSEtakes advantage of rich, widely available pre-trained visual and optical flowencoders instead of training video models from scratch. This significantlyreduces computational complexity while enhancing temporal interpretability. Ourprimary contributions includes (1) proposing a computationally efficienttemporally-centric architecture for video understanding (2) demonstratingenhanced interpretability in modeling temporal dynamics; and (3) achievingstate-of-the-art performance on diverse benchmarks, including clinical,medical, and standard action recognition datasets, confirming the broadapplicability and effectiveness of our approach.</description>
      <author>example@mail.com (Hong Nguyen, Dung Tran, Hieu Hoang, Phong Nguyen, Shrikanth Narayanan)</author>
      <guid isPermaLink="false">2506.01119v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Minimax Rates for the Estimation of Eigenpairs of Weighted Laplace-Beltrami Operators on Manifolds</title>
      <link>http://arxiv.org/abs/2506.00171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了从分布在流形上的分布ρ的样本中估计椭圆微分算子特征对的问题。文章中讨论的算子与无监督学习相关，特别是通过数据云上的常用图拉普拉斯算子的适当缩放极限获得。&lt;h4&gt;背景&lt;/h4&gt;该研究背景涉及椭圆微分算子特征对的估计，这些算子在无监督学习中具有重要意义，特别是在从数据云上获得的常用图拉普拉斯算子的适当缩放极限。&lt;h4&gt;目的&lt;/h4&gt;研究此特征对估计问题的最小-最大风险，并探索由随机数据构建的常用图拉普拉斯算子能够达到的近似率。&lt;h4&gt;方法&lt;/h4&gt;假设ρ属于具有受控二阶导数的某个分布族，并且ρ支持的d维流形M具有有界几何，证明了在H^1(M)意义上逼近特征值和特征向量的统计最小-最大率是n^{-2/(d+4)}，该率与相关密度估计问题的最小-最大率相匹配。此外，分析了在大数据极限下研究近邻图上的拉普拉斯算子的文献，证明了在数据生成模型上更强的正则性假设下，图拉普拉斯算子的特征对可以诱导出对流形无知的估计器，其近似误差（对数修正项除外）与我们的下界相匹配。&lt;h4&gt;主要发现&lt;/h4&gt;1) 与过去分析的近似误差度量相比，我们考虑了更强的范数来度量近似误差；2) 我们的收敛率在一系列光滑分布上是统一的，不仅适用于具有特殊对称性的密度，而且由于我们的下界，当图连通性足够高时，在本质上是最优的。&lt;h4&gt;结论&lt;/h4&gt;本研究扩展了基于图的学习的现有文献，通过考虑更强的范数和统一的收敛率，提供了对图拉普拉斯算子特征对估计问题的深入理解。&lt;h4&gt;翻译&lt;/h4&gt;本研究研究了从分布在流形上的分布ρ的样本中估计椭圆微分算子特征对的问题。文章中讨论的算子与无监督学习相关，特别是通过数据云上常用图拉普拉斯算子的适当缩放极限获得。我们研究了此特征对估计问题的最小-最大风险，并探索了由随机数据构建的常用图拉普拉斯算子能够达到的近似率。具体而言，假设ρ属于具有受控二阶导数的某个分布族，并且ρ支持的d维流形M具有有界几何，我们证明了在H^1(M)意义上逼近特征值和特征向量的统计最小-最大率是n^{-2/(d+4)}，该率与相关密度估计问题的最小-最大率相匹配。然后，我们回顾了在大数据极限下研究近邻图上的拉普拉斯算子的文献，并证明了在数据生成模型上更强的正则性假设下，图拉普拉斯算子的特征对可以诱导出对流形无知的估计器，其近似误差（对数修正项除外）与我们的下界相匹配。我们的分析使我们能够以至少两种显著方式扩展基于图的学习的现有文献：1) 我们考虑了比过去分析的更强的范数来度量近似误差；2) 我们的收敛率在一系列光滑分布上是统一的，不仅适用于具有特殊对称性的密度，而且由于我们的下界，当图连通性足够高时，在本质上是最优的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the problem of estimating eigenpairs of elliptic differentialoperators from samples of a distribution $\rho$ supported on a manifold $M$.The operators discussed in the paper are relevant in unsupervised learning andin particular are obtained by taking suitable scaling limits of widely usedgraph Laplacians over data clouds. We study the minimax risk for this eigenpairestimation problem and explore the rates of approximation that can be achievedby commonly used graph Laplacians built from random data. More concretely,assuming that $\rho$ belongs to a certain family of distributions withcontrolled second derivatives, and assuming that the $d$-dimensional manifold$M$ where $\rho$ is supported has bounded geometry, we prove that thestatistical minimax rate for approximating eigenvalues and eigenvectors in the$H^1(M)$-sense is $n^{-2/(d+4)}$, a rate that matches the minimax rate for aclosely related density estimation problem. We then revisit the literaturestudying Laplacians over proximity graphs in the large data limit and provethat, under slightly stronger regularity assumptions on the data generatingmodel, eigenpairs of graph Laplacians induce manifold agnostic estimators withan error of approximation that, up to logarithmic corrections, matches ourlower bounds. Our analysis allows us to expand the existing literature ongraph-based learning in at least two significant ways: 1) we consider strongernorms to measure the error of approximation than the ones that had beenanalyzed in the past; 2) our rates of convergence are uniform over a family ofsmooth distributions and do not just apply to densities with specialsymmetries, and, as a consequence of our lower bounds, are essentially sharpwhen the connectivity of the graph is sufficiently high.</description>
      <author>example@mail.com (Nicolás García Trillos, Chenghui Li, Raghavendra Venkatraman)</author>
      <guid isPermaLink="false">2506.00171v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>A Brain Graph Foundation Model: Pre-Training and Prompt-Tuning for Any Atlas and Disorder</title>
      <link>http://arxiv.org/abs/2506.02044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  34pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BrainGFM的大规模脑基础模型，该模型利用图对比学习和图掩码自动编码器进行大规模fMRI预训练，旨在推进神经科学研究。&lt;h4&gt;背景&lt;/h4&gt;随着大型语言模型在AI研究中的革命性发展，构建大规模脑基础模型以推进神经科学的研究越来越受到关注。&lt;h4&gt;目的&lt;/h4&gt;通过提出一种新的图预训练范式，构建一个统一的BrainGFM框架，以促进对大规模fMRI数据的处理和分析。&lt;h4&gt;方法&lt;/h4&gt;BrainGFM采用图对比学习和图掩码自动编码器进行预训练，并在多样化的脑图谱上预训练，以增强模型的泛化能力。同时，整合图提示和语言提示，以支持高效的下游迁移，并使用元学习优化图提示。&lt;h4&gt;主要发现&lt;/h4&gt;BrainGFM在27个神经影像数据集上进行预训练，覆盖25种常见的神经和精神疾病，包括8种常用的脑分区，涉及25000多个受试者和400000个图样本。&lt;h4&gt;结论&lt;/h4&gt;BrainGFM能够有效适应多种图谱、神经和精神疾病以及任务设置，并通过语言引导的提示实现强泛化。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为BrainGFM的大规模脑基础模型，利用图对比学习和图掩码自动编码器进行大规模fMRI预训练，旨在推进神经科学研究。该模型在27个神经影像数据集上预训练，覆盖25种常见的神经和精神疾病，包括8种常用的脑分区，涉及25000多个受试者和400000个图样本。BrainGFM能够有效适应多种图谱、神经和精神疾病以及任务设置，并通过语言引导的提示实现强泛化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As large language models (LLMs) continue to revolutionize AI research, thereis a growing interest in building large-scale brain foundation models toadvance neuroscience. While most existing brain foundation models arepre-trained on time-series signals or region-of-interest (ROI) features, wepropose a novel graph-based pre-training paradigm for constructing a braingraph foundation model. In this paper, we introduce the Brain Graph FoundationModel, termed BrainGFM, a unified framework that leverages graph contrastivelearning and graph masked autoencoders for large-scale fMRI-based pre-training.BrainGFM is pre-trained on a diverse mixture of brain atlases with varyingparcellations, significantly expanding the pre-training corpus and enhancingthe model's ability to generalize across heterogeneous fMRI-derived brainrepresentations. To support efficient and versatile downstream transfer, weintegrate both graph prompts and language prompts into the model design,enabling BrainGFM to flexibly adapt to a wide range of atlases, neurologicaland psychiatric disorders, and task settings. Furthermore, we employmeta-learning to optimize the graph prompts, facilitating strong generalizationto previously unseen disorders under both few-shot and zero-shot learningconditions via language-guided prompting. BrainGFM is pre-trained on 27neuroimaging datasets spanning 25 common neurological and psychiatricdisorders, encompassing 2 types of brain atlases (functional and anatomical)across 8 widely-used parcellations, and covering over 25,000 subjects, 60,000fMRI scans, and a total of 400,000 graph samples aggregated across all atlasesand parcellations. The code is available at:https://github.com/weixinxu666/BrainGFM</description>
      <author>example@mail.com (Xinxu Wei, Kanhao Zhao, Yong Jiao, Lifang He, Yu Zhang)</author>
      <guid isPermaLink="false">2506.02044v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MINT: Multimodal Instruction Tuning with Multimodal Interaction Grouping</title>
      <link>http://arxiv.org/abs/2506.02308v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了多模态基础模型在多个任务上的最新进展，分析了任务分组策略对多模态指令微调性能的影响。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型在多个任务上取得了最先进的性能，这些进展主要得益于新的预训练范式，这些范式利用大规模、未标记的多模态数据，随后在精心挑选的标记数据集和高质量提示上进行指令微调。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过任务分组策略提高多模态指令微调的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了MINT，一种基于多模态交互类型的简单而有效的任务分组策略，并通过实验证明其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，仅增加指令微调任务的数量并不总是能带来更好的性能。相反，通过将任务按模态间的共同交互分组，如发现冗余共享信息、优先选择具有独特信息的模态或要求协同融合以从两种模态中发现新信息，可以鼓励模型在组内学习可迁移的技能，同时抑制不匹配任务的干扰。&lt;h4&gt;结论&lt;/h4&gt;MINT方法在多模态指令微调的任务分组方面优于现有的基线方法，在泛化与专业化之间取得了有效的平衡。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Recent advances in multimodal foundation models have achieved state-of-the-art performance across a range of tasks. These breakthroughs are largely driven by new pre-training paradigms that leverage large-scale, unlabeled multimodal data, followed by instruction fine-tuning on curated labeled datasets and high-quality prompts. While there is growing interest in scaling instruction fine-tuning to ever-larger datasets in both quantity and scale, our findings reveal that simply increasing the number of instruction-tuning tasks does not consistently yield better performance. Instead, we observe that grouping tasks by the common interactions across modalities, such as discovering redundant shared information, prioritizing modality selection with unique information, or requiring synergistic fusion to discover new information from both modalities, encourages the models to learn transferrable skills within a group while suppressing interference from mismatched tasks. To this end, we introduce MINT, a simple yet surprisingly effective task-grouping strategy based on the type of multimodal interaction. We demonstrate that the proposed method greatly outperforms existing task grouping baselines for multimodal instruction tuning, striking an effective balance between generalization and specialization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in multimodal foundation models have achievedstate-of-the-art performance across a range of tasks. These breakthroughs arelargely driven by new pre-training paradigms that leverage large-scale,unlabeled multimodal data, followed by instruction fine-tuning on curatedlabeled datasets and high-quality prompts. While there is growing interest inscaling instruction fine-tuning to ever-larger datasets in both quantity andscale, our findings reveal that simply increasing the number ofinstruction-tuning tasks does not consistently yield better performance.Instead, we observe that grouping tasks by the common interactions acrossmodalities, such as discovering redundant shared information, prioritizingmodality selection with unique information, or requiring synergistic fusion todiscover new information from both modalities, encourages the models to learntransferrable skills within a group while suppressing interference frommismatched tasks. To this end, we introduce MINT, a simple yet surprisinglyeffective task-grouping strategy based on the type of multimodal interaction.We demonstrate that the proposed method greatly outperforms existing taskgrouping baselines for multimodal instruction tuning, striking an effectivebalance between generalization and specialization.</description>
      <author>example@mail.com (Xiaojun Shan, Qi Cao, Xing Han, Haofei Yu, Paul Pu Liang)</author>
      <guid isPermaLink="false">2506.02308v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>A Dynamic Stiefel Graph Neural Network for Efficient Spatio-Temporal Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2506.00798v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DST-SGNN的动态时空斯蒂费尔图神经网络，用于高效处理时空时间序列数据。&lt;h4&gt;背景&lt;/h4&gt;时空时间序列在众多应用中得到了广泛应用，但由于时间和空间维度的复杂动态相关性，准确预测时空时间序列是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有图神经网络在建模动态时空关系时难以平衡有效性和效率的问题。&lt;h4&gt;方法&lt;/h4&gt;本文首先引入了斯蒂费尔图谱卷积（SGSC）和斯蒂费尔图傅里叶变换（SGFT），并通过线性动态图优化在斯蒂费尔流形上（LDGOSM）学习SGFT矩阵，从而显著降低计算复杂度。此外，还提出了多层SGSC（MSGSC）来有效地捕捉复杂的时空相关性。&lt;h4&gt;主要发现&lt;/h4&gt;在七个时空数据集上的广泛实验表明，DST-SGNN在保持相对较低的计算成本的同时，优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;DST-SGNN是一种有效且高效的时空时间序列预测方法，在多个应用场景中具有潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatio-temporal time series (STTS) have been widely used in manyapplications. However, accurately forecasting STTS is challenging due tocomplex dynamic correlations in both time and space dimensions. Existing graphneural networks struggle to balance effectiveness and efficiency in modelingdynamic spatio-temporal relations. To address this problem, we propose theDynamic Spatio-Temporal Stiefel Graph Neural Network (DST-SGNN) to efficientlyprocess STTS. For DST-SGNN, we first introduce the novel Stiefel Graph SpectralConvolution (SGSC) and Stiefel Graph Fourier Transform (SGFT). The SGFT matrixin SGSC is constrained to lie on the Stiefel manifold, and SGSC can be regardedas a filtered graph spectral convolution. We also propose the Linear DynamicGraph Optimization on Stiefel Manifold (LDGOSM), which can efficiently learnthe SGFT matrix from the dynamic graph and significantly reduce thecomputational complexity. Finally, we propose a multi-layer SGSC (MSGSC) thatefficiently captures complex spatio-temporal correlations. Extensiveexperiments on seven spatio-temporal datasets show that DST-SGNN outperformsstate-of-the-art methods while maintaining relatively low computational costs.</description>
      <author>example@mail.com (Jiankai Zheng, Liang Xie)</author>
      <guid isPermaLink="false">2506.00798v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>On Designing Diffusion Autoencoders for Efficient Generation and Representation Learning</title>
      <link>http://arxiv.org/abs/2506.00136v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 10 tables, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了扩散自编码器（DAs），这是一种扩散生成模型的变体，它使用输入相关的潜在变量来捕捉扩散过程中的表示。这些表示可以用于下游任务，如分类、可控生成和插值。文章探讨了DAs的生成性能依赖于潜在变量的建模和采样，并提出了一种新的模型DMZ，它结合了两种模型的优势，即有效的表示和高效的建模与生成。&lt;h4&gt;背景&lt;/h4&gt;扩散自编码器（DAs）是一种生成模型，它通过扩散过程来学习数据的潜在表示。DAs的性能受到潜在变量建模和采样方法的影响。&lt;h4&gt;目的&lt;/h4&gt;提高扩散自编码器的生成性能，同时保持有效的表示和高效的建模与生成。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的模型DMZ，通过连接两种扩散模型（DAs和那些学习正向（噪声）过程的模型）的设计决策，如潜在变量选择和条件化方法。&lt;h4&gt;主要发现&lt;/h4&gt;DMZ模型通过结合两种模型的优势，实现了在下游任务（包括领域迁移）上的有效表示，并且与标准扩散模型相比，具有更高效的建模和生成，减少了去噪步骤。&lt;h4&gt;结论&lt;/h4&gt;DMZ模型通过改进潜在变量的建模和采样，实现了在生成性能和表示有效性方面的提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/exlab-research/dmz&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion autoencoders (DAs) are variants of diffusion generative models thatuse an input-dependent latent variable to capture representations alongside thediffusion process. These representations, to varying extents, can be used fortasks such as downstream classification, controllable generation, andinterpolation. However, the generative performance of DAs relies heavily on howwell the latent variables can be modelled and subsequently sampled from. Bettergenerative modelling is also the primary goal of another class of diffusionmodels -- those that learn their forward (noising) process. While effective atadjusting the noise process in an input-dependent manner, they must satisfyadditional constraints derived from the terminal conditions of the diffusionprocess. Here, we draw a connection between these two classes of models andshow that certain design decisions (latent variable choice, conditioningmethod, etc.) in the DA framework -- leading to a model we term DMZ -- allow usto obtain the best of both worlds: effective representations as evaluated ondownstream tasks, including domain transfer, as well as more efficientmodelling and generation with fewer denoising steps compared to standard DMs.</description>
      <author>example@mail.com (Magdalena Proszewska, Nikolay Malkin, N. Siddharth)</author>
      <guid isPermaLink="false">2506.00136v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>FlexSelect: Flexible Token Selection for Efficient Long Video Understanding</title>
      <link>http://arxiv.org/abs/2506.00993v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FlexSelect是一种灵活且高效的标记选择策略，用于处理长视频，旨在降低视频大语言模型（VideoLLMs）的复杂性和内存需求。&lt;h4&gt;背景&lt;/h4&gt;长视频理解对视频大语言模型（VideoLLMs）来说是一个重大挑战，因为其计算和内存需求过高。&lt;h4&gt;目的&lt;/h4&gt;提出FlexSelect，以识别和保留最相关的语义内容，从而提高长视频理解的效率。&lt;h4&gt;方法&lt;/h4&gt;FlexSelect利用参考Transformer层的跨模态注意力模式，包括：（1）一个无需训练的标记排名管道，利用忠实的跨模态注意力权重来估计每个视频标记的重要性；（2）一个排名监督的轻量级选择器，用于复制这些排名并过滤冗余标记。&lt;h4&gt;主要发现&lt;/h4&gt;FlexSelect可以无缝集成到各种VideoLLM架构中，如LLaVA-Video、InternVL和Qwen-VL，显著提高了多个长视频基准测试的性能，并实现了显著的加速（例如，在LLaVA-Video-7B模型上达到9倍）。&lt;h4&gt;结论&lt;/h4&gt;FlexSelect在提高长视频理解效率方面具有巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译：Long-form video understanding poses a significant challenge for video large language models (VideoLLMs) due to prohibitively high computational and memory demands. In this paper, we propose FlexSelect, a flexible and efficient token selection strategy for processing long videos. FlexSelect identifies and retains the most semantically relevant content by leveraging cross-modal attention patterns from a reference transformer layer. It comprises two key components: (1) a training-free token ranking pipeline that leverages faithful cross-modal attention weights to estimate each video token's importance, and (2) a rank-supervised lightweight selector that is trained to replicate these rankings and filter redundant tokens. This generic approach can be seamlessly integrated into various VideoLLM architectures, such as LLaVA-Video, InternVL, and Qwen-VL, serving as a plug-and-play module to extend their temporal context length. Empirically, FlexSelect delivers strong gains across multiple long-video benchmarks including VideoMME, MLVU, LongVB, and LVBench. Moreover, it achieves significant speed-ups (for example, up to 9 times on a LLaVA-Video-7B model), highlighting FlexSelect's promise for efficient long-form video understanding. Project page available at: https://yunzhuzhang0918.github.io/flex_select&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-form video understanding poses a significant challenge for video largelanguage models (VideoLLMs) due to prohibitively high computational and memorydemands. In this paper, we propose FlexSelect, a flexible and efficient tokenselection strategy for processing long videos. FlexSelect identifies andretains the most semantically relevant content by leveraging cross-modalattention patterns from a reference transformer layer. It comprises two keycomponents: (1) a training-free token ranking pipeline that leverages faithfulcross-modal attention weights to estimate each video token's importance, and(2) a rank-supervised lightweight selector that is trained to replicate theserankings and filter redundant tokens. This generic approach can be seamlesslyintegrated into various VideoLLM architectures, such as LLaVA-Video, InternVLand Qwen-VL, serving as a plug-and-play module to extend their temporal contextlength. Empirically, FlexSelect delivers strong gains across multiplelong-video benchmarks including VideoMME, MLVU, LongVB, and LVBench. Moreover,it achieves significant speed-ups (for example, up to 9 times on aLLaVA-Video-7B model), highlighting FlexSelect's promise for efficientlong-form video understanding. Project page available at:https://yunzhuzhang0918.github.io/flex_select</description>
      <author>example@mail.com (Yunzhu Zhang, Yu Lu, Tianyi Wang, Fengyun Rao, Yi Yang, Linchao Zhu)</author>
      <guid isPermaLink="false">2506.00993v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>M3ANet: Multi-scale and Multi-Modal Alignment Network for Brain-Assisted Target Speaker Extraction</title>
      <link>http://arxiv.org/abs/2506.00466v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于脑辅助的目标说话人提取方法，通过利用脑神经活动（如脑电图EEG）来从混合语音中提取目标说话人的语音。&lt;h4&gt;背景&lt;/h4&gt;现有的目标说话人提取模型忽略了语音和脑电图模态之间的时间不一致性问题，影响了提取性能。此外，当前模型中的语音编码器通常使用基本的时序操作（如一维卷积），无法有效提取目标说话人信息。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文提出了一种多尺度多模态对齐网络（M3ANet）。&lt;h4&gt;方法&lt;/h4&gt;1. 使用对比学习策略的模态对齐模块来消除脑电图和语音模态之间的时间不一致性。2. 使用带有GroupMamba模块的多尺度卷积作为语音编码器，从不同方向扫描每个尺度的语音特征，使模型能够捕获深层次的序列信息。&lt;h4&gt;主要发现&lt;/h4&gt;在三个公开数据集上的实验结果表明，所提出的模型在各种评估指标上优于现有最先进的方法，突出了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在目标说话人提取任务中表现出色，为脑辅助语音处理提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：脑辅助目标说话人提取（TSE）旨在通过利用脑神经活动（例如脑电图EEG）从混合语音中提取被关注的语音。然而，现有模型忽略了语音和脑电图模态之间时间不一致的问题，这阻碍了TSE的性能。此外，当前模型中的语音编码器通常使用基本的时序操作（例如一维卷积），这些操作无法有效地提取目标说话人信息。为了解决这些问题，本文提出了一种用于脑辅助TSE的多尺度多模态对齐网络（M3ANet）。具体来说，为了消除脑电图和语音模态之间的时间不一致性，应用了对比学习策略的模态对齐模块来对齐两种模态的时间特征。此外，为了充分提取语音信息，使用带有GroupMamba模块的多尺度卷积作为语音编码器，从不同方向扫描每个尺度的语音特征，使模型能够捕获深层次的序列信息。在三个公开数据集上的实验结果表明，所提出的模型在各种评估指标上优于现有最先进的方法，突出了我们提出方法的有效性。源代码可在以下链接获取：https://github.com/fchest/M3ANet。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The brain-assisted target speaker extraction (TSE) aims to extract theattended speech from mixed speech by utilizing the brain neural activities, forexample Electroencephalography (EEG). However, existing models overlook theissue of temporal misalignment between speech and EEG modalities, which hampersTSE performance. In addition, the speech encoder in current models typicallyuses basic temporal operations (e.g., one-dimensional convolution), which areunable to effectively extract target speaker information. To address theseissues, this paper proposes a multi-scale and multi-modal alignment network(M3ANet) for brain-assisted TSE. Specifically, to eliminate the temporalinconsistency between EEG and speech modalities, the modal alignment modulethat uses a contrastive learning strategy is applied to align the temporalfeatures of both modalities. Additionally, to fully extract speech information,multi-scale convolutions with GroupMamba modules are used as the speechencoder, which scans speech features at each scale from different directions,enabling the model to capture deep sequence information. Experimental resultson three publicly available datasets show that the proposed model outperformscurrent state-of-the-art methods across various evaluation metrics,highlighting the effectiveness of our proposed method. The source code isavailable at: https://github.com/fchest/M3ANet.</description>
      <author>example@mail.com (Cunhang Fan, Ying Chen, Jian Zhou, Zexu Pan, Jingjing Zhang, Youdian Gao, Xiaoke Yang, Zhengqi Wen, Zhao Lv)</author>
      <guid isPermaLink="false">2506.00466v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Improving Knowledge Distillation Under Unknown Covariate Shift Through Confidence-Guided Data Augmentation</title>
      <link>http://arxiv.org/abs/2506.02294v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散的数据增强策略，旨在解决知识蒸馏中的协变量偏移问题，通过最大化教师和学生之间的不一致性来生成挑战性样本，提高学生网络的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;大型基础模型在广泛数据集上展现出强大的零样本能力，但数据量和模型尺寸受限时，知识蒸馏成为将知识从基础模型传递到小型学生网络的有效工具。&lt;h4&gt;目的&lt;/h4&gt;针对知识蒸馏中常见的协变量偏移问题，即训练时出现但在测试时未出现的虚假特征，研究如何使学生在教师模型鲁棒的前提下，也能对虚假特征表现出鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;引入了一种基于扩散的数据增强策略，通过最大化教师和学生之间的不一致性来生成图像，从而创建学生难以处理的挑战性样本。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在CelebA和SpuCo Birds数据集上显著提高了最差组和平均组的准确率，以及在协变量偏移下的虚假ImageNet数据集上的虚假AUC，超越了现有的基于扩散的数据增强基线。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地提高了学生网络的鲁棒性，在知识蒸馏中取得了优于现有方法的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large foundation models trained on extensive datasets demonstrate strongzero-shot capabilities in various domains. To replicate their success when dataand model size are constrained, knowledge distillation has become anestablished tool for transferring knowledge from foundation models to smallstudent networks. However, the effectiveness of distillation is criticallylimited by the available training data. This work addresses the commonpractical issue of covariate shift in knowledge distillation, where spuriousfeatures appear during training but not at test time. We ask the question: whenthese spurious features are unknown, yet a robust teacher is available, is itpossible for a student to also become robust to them? We address this problemby introducing a novel diffusion-based data augmentation strategy thatgenerates images by maximizing the disagreement between the teacher and thestudent, effectively creating challenging samples that the student struggleswith. Experiments demonstrate that our approach significantly improves worstgroup and mean group accuracy on CelebA and SpuCo Birds as well as the spuriousmAUC on spurious ImageNet under covariate shift, outperforming state-of-the-artdiffusion-based data augmentation baselines</description>
      <author>example@mail.com (Niclas Popp, Kevin Alexander Laube, Matthias Hein, Lukas Schott)</author>
      <guid isPermaLink="false">2506.02294v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Amatriciana: Exploiting Temporal GNNs for Robust and Efficient Money Laundering Detection</title>
      <link>http://arxiv.org/abs/2506.00654v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Amatriciana，一种基于图神经网络的创新方法，用于检测交易图中的洗钱行为，并考虑了时间信息。该方法在公共数据集上的实验表明，Amatriciana能够从有限的数据中学习，并且当数据量增加时，其性能优于其他最先进的方法，尤其是在减少误报率方面。&lt;h4&gt;背景&lt;/h4&gt;洗钱是一种对金融安全和社交安全构成严重威胁的金融犯罪。随着交易数量的增加，需要使用自动工具来帮助执法机构检测此类犯罪活动。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效检测洗钱行为的自动工具。&lt;h4&gt;方法&lt;/h4&gt;Amatriciana方法基于图神经网络，考虑了时间信息，并利用了整个交易图中的所有关系信息，而不是将其分割成基于时间段的子图。&lt;h4&gt;主要发现&lt;/h4&gt;Amatriciana模型可以从有限的数据中学习，并且当数据量增加时，其性能优于其他最先进的方法。Amatriciana在检测洗钱者时，减少了误报率，达到了0.76的F1分数，并且与其他最先进模型相比，误报率降低了55%。&lt;h4&gt;结论&lt;/h4&gt;Amatriciana是一种有效的洗钱检测工具，能够减少误报率，提高检测准确率。&lt;h4&gt;翻译&lt;/h4&gt;Money laundering is a financial crime that poses a serious threat to financial integrity and social security. The growing number of transactions makes it necessary to use automatic tools that help law enforcement agencies detect such criminal activity. In this work, we present Amatriciana, a novel approach based on Graph Neural Networks to detect money launderers inside a graph of transactions by considering temporal information. Amatriciana uses the whole graph of transactions without splitting it into several time-based subgraphs, exploiting all relational information in the dataset. Our experiments on a public dataset reveal that the model can learn from a limited amount of data. Furthermore, when more data is available, the model outperforms other State-of-the-art approaches; in particular, Amatriciana decreases the number of False Positives (FPs) while detecting many launderers. In summary, Amatriciana achieves an F1 score of 0.76. In addition, it lowers the FPs by 55% with respect to other State-of-the-art models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICDMW65004.2024.00039&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Money laundering is a financial crime that poses a serious threat tofinancial integrity and social security. The growing number of transactionsmakes it necessary to use automatic tools that help law enforcement agenciesdetect such criminal activity. In this work, we present Amatriciana, a novelapproach based on Graph Neural Networks to detect money launderers inside agraph of transactions by considering temporal information. Amatriciana uses thewhole graph of transactions without splitting it into several time-basedsubgraphs, exploiting all relational information in the dataset. Ourexperiments on a public dataset reveal that the model can learn from a limitedamount of data. Furthermore, when more data is available, the model outperformsother State-of-the-art approaches; in particular, Amatriciana decreases thenumber of False Positives (FPs) while detecting many launderers. In summary,Amatriciana achieves an F1 score of 0.76. In addition, it lowers the FPs by 55%with respect to other State-of-the-art models.</description>
      <author>example@mail.com (Marco Di Gennaro, Francesco Panebianco, Marco Pianta, Stefano Zanero, Michele Carminati)</author>
      <guid isPermaLink="false">2506.00654v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Deep Temporal Reasoning in Video Language Models: A Cross-Linguistic Evaluation of Action Duration and Completion through Perfect Times</title>
      <link>http://arxiv.org/abs/2506.00928v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了人类对事件的感知与区分已完成动作和持续动作的能力，这一过程受到语言结构和视觉线索的共同影响。&lt;h4&gt;背景&lt;/h4&gt;人类感知事件与区分已完成（完美和目的）和持续动作有内在联系，这一过程由语言结构和视觉线索共同介导。&lt;h4&gt;目的&lt;/h4&gt;提出一个名为“完美时间”的数据集，用于评估视频语言模型（VLMs）在时间推理方面的能力。&lt;h4&gt;方法&lt;/h4&gt;该数据集包含日常活动视频、事件完成标签和针对完美性定制的干扰项，以检测模型是否真正理解时间动态，而不是仅仅依赖于表面标记。&lt;h4&gt;主要发现&lt;/h4&gt;尽管在基于文本的任务上表现出色，但最先进的模型在模仿人类基于视频的时间因果推理方面仍存在困难。&lt;h4&gt;结论&lt;/h4&gt;强调了整合深度多模态线索以捕捉时间和因果视频动态中动作持续时间和完成度的细微差异的必要性，为评估和推进VLMs中的时间推理设定了新的标准。&lt;h4&gt;翻译&lt;/h4&gt;人类对事件的感知与区分已完成（完美和目的）和持续动作有内在联系，这一过程由语言结构和视觉线索共同介导。本研究提出了“完美时间”数据集，旨在评估视频语言模型（VLMs）在时间推理方面的能力。该数据集包含日常活动视频、事件完成标签和针对完美性定制的干扰项，以检测模型是否真正理解时间动态，而不是仅仅依赖于表面标记。尽管在基于文本的任务上表现出色，但最先进的模型在模仿人类基于视频的时间因果推理方面仍存在困难。该研究强调了整合深度多模态线索以捕捉时间和因果视频动态中动作持续时间和完成度的细微差异的必要性，为评估和推进VLMs中的时间推理设定了新的标准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human perception of events is intrinsically tied to distinguishing betweencompleted (perfect and telic) and ongoing (durative) actions, a processmediated by both linguistic structure and visual cues. In this work, weintroduce the \textbf{Perfect Times} dataset, a novel, quadrilingual (English,Italian, Russian, and Japanese) multiple-choice question-answering benchmarkdesigned to assess video-language models (VLMs) on temporal reasoning. Bypairing everyday activity videos with event completion labels andperfectivity-tailored distractors, our dataset probes whether models trulycomprehend temporal dynamics or merely latch onto superficial markers.Experimental results indicate that state-of-the-art models, despite theirsuccess on text-based tasks, struggle to mirror human-like temporal and causalreasoning grounded in video. This study underscores the necessity ofintegrating deep multimodal cues to capture the nuances of action duration andcompletion within temporal and causal video dynamics, setting a new standardfor evaluating and advancing temporal reasoning in VLMs.</description>
      <author>example@mail.com (Olga Loginova, Sofía Ortega Loguinova)</author>
      <guid isPermaLink="false">2506.00928v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>A New Spatiotemporal Correlation Anomaly Detection Method that Integrates Contrastive Learning and Few-Shot Learning in Wireless Sensor Networks</title>
      <link>http://arxiv.org/abs/2506.00420v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MTAD-RD的时空相关性检测模型，用于解决无线传感器网络（WSN）异常检测中的挑战。&lt;h4&gt;背景&lt;/h4&gt;WSN异常检测对于评估WSN的可靠性和稳定性至关重要，但现有方法面临诸如时空相关性特征提取有限、缺乏样本标签、异常样本数量少和样本分布不平衡等问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，设计了一种同时考虑模型架构和两阶段训练策略的时空相关性检测模型。&lt;h4&gt;方法&lt;/h4&gt;模型结构设计方面，MTAD-RD包括一个增强的保留网络（RetNet）、一个多粒度特征融合模块和一个图注意力网络模块来提取节点间相关性信息。训练方法方面，采用两阶段训练策略：首先，设计了一个对比学习代理任务，用于学习未标记数据中的可迁移特征；然后，设计了一个基于缓存的样本采样器，将样本分为少量样本和对比学习数据，并开发了一个特定的联合损失函数来训练双图判别网络，以有效解决样本不平衡问题。&lt;h4&gt;主要发现&lt;/h4&gt;在真实公共数据集上的实验表明，MTAD-RD异常检测方法实现了90.97%的F1分数，优于现有的监督WSN异常检测方法。&lt;h4&gt;结论&lt;/h4&gt;MTAD-RD模型在WSN异常检测中表现出色，能够有效解决现有方法的局限性，并提高了检测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting anomalies in the data collected by WSNs can provide crucialevidence for assessing the reliability and stability of WSNs. Existing methodsfor WSN anomaly detection often face challenges such as the limited extractionof spatiotemporal correlation features, the absence of sample labels, fewanomaly samples, and an imbalanced sample distribution. To address theseissues, a spatiotemporal correlation detection model (MTAD-RD) considering bothmodel architecture and a two-stage training strategy perspective is proposed.In terms of model structure design, the proposed MTAD-RD backbone networkincludes a retentive network (RetNet) enhanced by a cross-retention (CR)module, a multigranular feature fusion module, and a graph attention networkmodule to extract internode correlation information. This proposed model canintegrate the intermodal correlation features and spatial features of WSNneighbor nodes while extracting global information from time series data.Moreover, its serialized inference characteristic can remarkably reduceinference overhead. For model training, a two-stage training approach wasdesigned. First, a contrastive learning proxy task was designed for time seriesdata with graph structure information in WSNs, enabling the backbone network tolearn transferable features from unlabeled data using unsupervised contrastivelearning methods, thereby addressing the issue of missing sample labels in thedataset. Then, a caching-based sample sampler was designed to divide samplesinto few-shot and contrastive learning data. A specific joint loss function wasdeveloped to jointly train the dual-graph discriminator network to address theproblem of sample imbalance effectively. In experiments carried out on realpublic datasets, the designed MTAD-RD anomaly detection method achieved an F1score of 90.97%, outperforming existing supervised WSN anomaly detectionmethods.</description>
      <author>example@mail.com (Miao Ye, Suxiao Wang, Jiaguang Han, Yong Wang, Xiaoli Wang, Jingxuan Wei, Peng Wen, Jing Cui)</author>
      <guid isPermaLink="false">2506.00420v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Are Mamba-based Audio Foundation Models the Best Fit for Non-Verbal Emotion Recognition?</title>
      <link>http://arxiv.org/abs/2506.02258v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to EUSIPCO 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于非言语声音的情感识别（NVER），首次探讨了用于NVER的mamba基础音频模型（MAFMs），并假设MAFMs将优于基于注意力的音频基础模型（AAFMs），因为其状态空间建模能更有效地捕捉内在的情感结构。通过实验验证了这一假设，并进一步探索了基础模型（FMs）的融合，提出了RENO模型，该模型使用renyi散度作为新的损失函数，并利用自注意力机制以实现FMs之间的更好交互。&lt;h4&gt;背景&lt;/h4&gt;非言语声音情感识别（NVER）是一个研究领域，本文首次将mamba基础音频模型（MAFMs）应用于此领域。&lt;h4&gt;目的&lt;/h4&gt;研究MAFMs在NVER中的性能，并探索FMs的融合以提升NVER的性能。&lt;h4&gt;方法&lt;/h4&gt;使用MAFMs进行NVER，并将其与基于注意力的音频基础模型（AAFMs）进行比较。此外，提出了一个名为RENO的模型，该模型融合了MAFMs和AAFMs，并使用renyi散度作为损失函数以及自注意力机制。&lt;h4&gt;主要发现&lt;/h4&gt;MAFMs在NVER中表现出色，且与AAFMs相比，能够更有效地捕捉内在情感结构。RENO模型通过融合MAFMs和AAFMs实现了在NVER中的最佳性能。&lt;h4&gt;结论&lt;/h4&gt;MAFMs在NVER中具有优势，RENO模型通过融合FMs进一步提升了NVER的性能，并达到了目前该领域的最先进水平。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we focus on non-verbal vocal sounds emotion recognition (NVER). We investigate mamba-based audio foundation models (MAFMs) for the first time for NVER and hypothesize that MAFMs will outperform attention-based audio foundation models (AAFMs) for NVER by leveraging its state-space modeling to capture intrinsic emotional structures more effectively. Unlike AAFMs, which may amplify irrelevant patterns due to their attention mechanisms, MAFMs will extract more stable and context-aware representations, enabling better differentiation of subtle non-verbal emotional cues. Our experiments with state-of-the-art (SOTA) AAFMs and MAFMs validates our hypothesis. Further, motivated from related research such as speech emotion recognition, synthetic speech detection, where fusion of foundation models (FMs) have showed improved performance, we also explore fusion of FMs for NVER. To this end, we propose, RENO, that uses renyi-divergence as a novel loss function for effective alignment of the FMs. It also makes use of self-attention for better intra-representation interaction of the FMs. With RENO, through the heterogeneous fusion of MAFMs and AAFMs, we show the topmost performance in comparison to individual FMs, its fusion and also setting SOTA in comparison to previous SOTA work.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we focus on non-verbal vocal sounds emotion recognition (NVER).We investigate mamba-based audio foundation models (MAFMs) for the first timefor NVER and hypothesize that MAFMs will outperform attention-based audiofoundation models (AAFMs) for NVER by leveraging its state-space modeling tocapture intrinsic emotional structures more effectively. Unlike AAFMs, whichmay amplify irrelevant patterns due to their attention mechanisms, MAFMs willextract more stable and context-aware representations, enabling betterdifferentiation of subtle non-verbal emotional cues. Our experiments withstate-of-the-art (SOTA) AAFMs and MAFMs validates our hypothesis. Further,motivated from related research such as speech emotion recognition, syntheticspeech detection, where fusion of foundation models (FMs) have showed improvedperformance, we also explore fusion of FMs for NVER. To this end, we propose,RENO, that uses renyi-divergence as a novel loss function for effectivealignment of the FMs. It also makes use of self-attention for betterintra-representation interaction of the FMs. With RENO, through theheterogeneous fusion of MAFMs and AAFMs, we show the topmost performance incomparison to individual FMs, its fusion and also setting SOTA in comparison toprevious SOTA work.</description>
      <author>example@mail.com (Mohd Mujtaba Akhtar, Orchid Chetia Phukan, Girish, Swarup Ranjan Behera, Ananda Chandra Nayak, Sanjib Kumar Nayak, Arun Balaji Buduru, Rajesh Sharma)</author>
      <guid isPermaLink="false">2506.02258v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>TMetaNet: Topological Meta-Learning Framework for Dynamic Link Prediction</title>
      <link>http://arxiv.org/abs/2506.00453v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于动态图持久同调表示的方法DowkerZigzag Persistence (DZP)和基于动态拓扑特征的元学习参数更新模型TMetaNet，用于解决动态图学习中的挑战。&lt;h4&gt;背景&lt;/h4&gt;动态图由于其结构和时间依赖性的变化，对传统的图学习提出了挑战。现有的元学习方法大多依赖于固定的权重更新参数，忽略了动态图演变的内在复杂高阶拓扑信息。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够捕捉动态图高阶特征的持久同调表示方法，并提出一种基于动态拓扑特征的元学习参数更新模型，以提高动态图学习的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了DZP方法，它基于Dowker复形和zigzag持久性来捕获动态图的高阶特征。同时，提出了TMetaNet模型，该模型通过利用高阶拓扑特征之间的距离，实现更有效的跨时间快照的适应。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，TMetaNet在真实世界数据集上表现出最先进的性能和抗噪声鲁棒性，证明了其在元学习和动态图分析中的高潜力。&lt;h4&gt;结论&lt;/h4&gt;DZP和TMetaNet为动态图学习提供了一种有效的方法，有望提高动态图分析的性能和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a dynamic graph persistent homology representation method DowkerZigzag Persistence (DZP) and a meta-learning parameter update model TMetaNet based on dynamic topological features, to address the challenges in dynamic graph learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic graphs evolve continuously, presenting challenges for traditionalgraph learning due to their changing structures and temporal dependencies.Recent advancements have shown potential in addressing these challenges bydeveloping suitable meta-learning-based dynamic graph neural network models.However, most meta-learning approaches for dynamic graphs rely on fixed weightupdate parameters, neglecting the essential intrinsic complex high-ordertopological information of dynamically evolving graphs. We have designed DowkerZigzag Persistence (DZP), an efficient and stable dynamic graph persistenthomology representation method based on Dowker complex and zigzag persistence,to capture the high-order features of dynamic graphs. Armed with the DZP ideas,we propose TMetaNet, a new meta-learning parameter update model based ondynamic topological features. By utilizing the distances between high-ordertopological features, TMetaNet enables more effective adaptation acrosssnapshots. Experiments on real-world datasets demonstrate TMetaNet'sstate-of-the-art performance and resilience to graph noise, illustrating itshigh potential for meta-learning and dynamic graph analysis. Our code isavailable at https://github.com/Lihaogx/TMetaNet.</description>
      <author>example@mail.com (Hao Li, Hao Wan, Yuzhou Chen, Dongsheng Ye, Yulia Gel, Hao Jiang)</author>
      <guid isPermaLink="false">2506.00453v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>3D Skeleton-Based Action Recognition: A Review</title>
      <link>http://arxiv.org/abs/2506.00915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基于3D骨骼的动作识别进行了全面的综述，强调了任务导向的框架，并分析了该领域的最新进展。&lt;h4&gt;背景&lt;/h4&gt;基于骨骼的动作识别在计算机视觉领域占有一席之地，但之前的综述主要采用模型导向的视角，忽略了骨骼动作识别的基本步骤。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文旨在提供一个全面、任务导向的框架，以加深对骨骼动作识别任务的理解。&lt;h4&gt;方法&lt;/h4&gt;本文将任务分解为一系列子任务，重点关注预处理步骤，如模态推导和数据增强。随后深入讨论了关键子任务，包括特征提取和时空建模技术。此外，还提到了基础动作识别网络以及最新的混合架构、Mamba模型、大型语言模型（LLMs）和生成模型。&lt;h4&gt;主要发现&lt;/h4&gt;本文提供了一个关于公共3D骨骼数据集的全面概述，并分析了在这些基准上评估的最先进算法。&lt;h4&gt;结论&lt;/h4&gt;通过结合任务导向的讨论、对子任务的全面审查以及对最新进展的强调，本文为理解和推进3D骨骼动作识别领域提供了一个基本且易于理解的路线图。&lt;h4&gt;翻译&lt;/h4&gt;With the inherent advantages of skeleton representation, 3D skeleton-based action recognition has become a prominent topic in the field of computer vision. However, previous reviews have predominantly adopted a model-oriented perspective, often neglecting the fundamental steps involved in skeleton-based action recognition. This oversight tends to ignore key components of skeleton-based action recognition beyond model design and has hindered deeper, more intrinsic understanding of the task. To bridge this gap, our review aims to address these limitations by presenting a comprehensive, task-oriented framework for understanding skeleton-based action recognition. We begin by decomposing the task into a series of sub-tasks, placing particular emphasis on preprocessing steps such as modality derivation and data augmentation. The subsequent discussion delves into critical sub-tasks, including feature extraction and spatio-temporal modeling techniques. Beyond foundational action recognition networks, recently advanced frameworks such as hybrid architectures, Mamba models, large language models (LLMs), and generative models have also been highlighted. Finally, a comprehensive overview of public 3D skeleton datasets is presented, accompanied by an analysis of state-of-the-art algorithms evaluated on these benchmarks. By integrating task-oriented discussions, comprehensive examinations of sub-tasks, and an emphasis on the latest advancements, our review provides a fundamental and accessible structured roadmap for understanding and advancing the field of 3D skeleton-based action recognition.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the inherent advantages of skeleton representation, 3D skeleton-basedaction recognition has become a prominent topic in the field of computervision. However, previous reviews have predominantly adopted a model-orientedperspective, often neglecting the fundamental steps involved in skeleton-basedaction recognition. This oversight tends to ignore key components ofskeleton-based action recognition beyond model design and has hindered deeper,more intrinsic understanding of the task. To bridge this gap, our review aimsto address these limitations by presenting a comprehensive, task-orientedframework for understanding skeleton-based action recognition. We begin bydecomposing the task into a series of sub-tasks, placing particular emphasis onpreprocessing steps such as modality derivation and data augmentation. Thesubsequent discussion delves into critical sub-tasks, including featureextraction and spatio-temporal modeling techniques. Beyond foundational actionrecognition networks, recently advanced frameworks such as hybridarchitectures, Mamba models, large language models (LLMs), and generativemodels have also been highlighted. Finally, a comprehensive overview of public3D skeleton datasets is presented, accompanied by an analysis ofstate-of-the-art algorithms evaluated on these benchmarks. By integratingtask-oriented discussions, comprehensive examinations of sub-tasks, and anemphasis on the latest advancements, our review provides a fundamental andaccessible structured roadmap for understanding and advancing the field of 3Dskeleton-based action recognition.</description>
      <author>example@mail.com (Mengyuan Liu, Hong Liu, Qianshuo Hu, Bin Ren, Junsong Yuan, Jiaying Lin, Jiajun Wen)</author>
      <guid isPermaLink="false">2506.00915v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>JojoSCL: Shrinkage Contrastive Learning for single-cell RNA sequence Clustering</title>
      <link>http://arxiv.org/abs/2506.00410v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为JojoSCL的新型自监督对比学习框架，用于单细胞RNA测序数据的聚类分析，并通过实验证明其优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;单细胞RNA测序技术革命性地推动了我们对细胞过程的理解，但高维度和稀疏性数据给聚类分析带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的聚类方法，以提高单细胞RNA测序数据的聚类效果。&lt;h4&gt;方法&lt;/h4&gt;JojoSCL通过结合层次贝叶斯估计的收缩估计器以及Stein的不偏风险估计（SURE）优化，对实例级和聚类级的对比学习进行细化。&lt;h4&gt;主要发现&lt;/h4&gt;在十个单细胞RNA测序数据集上的实验表明，JojoSCL在聚类效果上优于常见的聚类方法，并通过鲁棒性和消融研究验证了其实用性。&lt;h4&gt;结论&lt;/h4&gt;JojoSCL是一种有效的单细胞RNA测序数据聚类工具，可在实践中使用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Single-cell RNA sequencing (scRNA-seq) has revolutionized our understandingof cellular processes by enabling gene expression analysis at the individualcell level. Clustering allows for the identification of cell types and thefurther discovery of intrinsic patterns in single-cell data. However, the highdimensionality and sparsity of scRNA-seq data continue to challenge existingclustering models. In this paper, we introduce JojoSCL, a novel self-supervisedcontrastive learning framework for scRNA-seq clustering. By incorporating ashrinkage estimator based on hierarchical Bayesian estimation, which adjustsgene expression estimates towards more reliable cluster centroids to reduceintra-cluster dispersion, and optimized using Stein's Unbiased Risk Estimate(SURE), JojoSCL refines both instance-level and cluster-level contrastivelearning. Experiments on ten scRNA-seq datasets substantiate that JojoSCLconsistently outperforms prevalent clustering methods, with further validationof its practicality through robustness analysis and ablation studies. JojoSCL'scode is available at: https://github.com/ziwenwang28/JojoSCL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single-cell RNA sequencing (scRNA-seq) has revolutionized our understandingof cellular processes by enabling gene expression analysis at the individualcell level. Clustering allows for the identification of cell types and thefurther discovery of intrinsic patterns in single-cell data. However, the highdimensionality and sparsity of scRNA-seq data continue to challenge existingclustering models. In this paper, we introduce JojoSCL, a novel self-supervisedcontrastive learning framework for scRNA-seq clustering. By incorporating ashrinkage estimator based on hierarchical Bayesian estimation, which adjustsgene expression estimates towards more reliable cluster centroids to reduceintra-cluster dispersion, and optimized using Stein's Unbiased Risk Estimate(SURE), JojoSCL refines both instance-level and cluster-level contrastivelearning. Experiments on ten scRNA-seq datasets substantiate that JojoSCLconsistently outperforms prevalent clustering methods, with further validationof its practicality through robustness analysis and ablation studies. JojoSCL'scode is available at: https://github.com/ziwenwang28/JojoSCL.</description>
      <author>example@mail.com (Ziwen Wang)</author>
      <guid isPermaLink="false">2506.00410v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Is Your Explanation Reliable: Confidence-Aware Explanation on Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.00437v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In Proceedings of the 31st ACM SIGKDD Conference on Knowledge  Discovery and Data Mining (KDD25)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于理论原理的GNN解释框架，通过引入置信度评分模块ConfExplainer，使用广义图信息瓶颈与置信度约束（GIB-CC）来量化生成解释的可靠性。&lt;h4&gt;背景&lt;/h4&gt;由于需要可解释性，解释图神经网络（GNNs）的行为和预测变得非常重要，但现有的后处理实例级解释方法在分布外或未知测试数据集上的可靠性不确定。&lt;h4&gt;目的&lt;/h4&gt;提高GNN解释的可信度和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个名为ConfExplainer的解释框架，该框架基于广义图信息瓶颈与置信度约束（GIB-CC）来量化解释的可靠性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在提高GNN解释的可信度和鲁棒性方面优于现有方法，置信度评分在增强解释的可靠性方面非常有效。&lt;h4&gt;结论&lt;/h4&gt;ConfExplainer框架通过引入置信度评分模块，有效提高了GNN解释的可信度和鲁棒性，为解释GNN预测提供了一种可靠的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737010&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Explaining Graph Neural Networks (GNNs) has garnered significant attentiondue to the need for interpretability, enabling users to understand the behaviorof these black-box models better and extract valuable insights from theirpredictions. While numerous post-hoc instance-level explanation methods havebeen proposed to interpret GNN predictions, the reliability of theseexplanations remains uncertain, particularly in the out-of-distribution orunknown test datasets. In this paper, we address this challenge by introducingan explainer framework with the confidence scoring module ( ConfExplainer),grounded in theoretical principle, which is generalized graph informationbottleneck with confidence constraint (GIB-CC), that quantifies the reliabilityof generated explanations. Experimental results demonstrate the superiority ofour approach, highlighting the effectiveness of the confidence score inenhancing the trustworthiness and robustness of GNN explanations.</description>
      <author>example@mail.com (Jiaxing Zhang, Xiaoou Liu, Dongsheng Luo, Hua Wei)</author>
      <guid isPermaLink="false">2506.00437v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Constrained Sliced Wasserstein Embedding</title>
      <link>http://arxiv.org/abs/2506.02203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种优化Sliced Wasserstein距离切片方向的方法，通过约束学习来提高比较高维概率测度时的效率。&lt;h4&gt;背景&lt;/h4&gt;Sliced Wasserstein距离通过将高维概率测度投影到多个一维概率分布上来比较，但确定信息丰富的切片方向是一个挑战，需要大量的切片来提高性能，从而增加了计算复杂度。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来优化Sliced Wasserstein距离的切片方向，以减少计算复杂度并提高性能。&lt;h4&gt;方法&lt;/h4&gt;引入了一种约束学习方法，通过将一维传输计划约束为近似原始空间中的最优计划来确保有意义的切片方向。利用传输计划的连续松弛，实现了一个基于梯度的原对偶方法来训练切片参数和剩余模型参数。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法可以将高维嵌入池化成固定长度的排列不变表示，并在图像、点云和蛋白质序列上训练的基础模型中展示了所提出的有约束学习方法的效用。&lt;h4&gt;结论&lt;/h4&gt;所提出的有约束学习方法在学习更有信息量的切片方向方面是有效的，并且可以通过提供的GitHub链接访问其实施代码。&lt;h4&gt;翻译&lt;/h4&gt;Sliced Wasserstein (SW) distances provide an efficient way to compare high-dimensional probability measures by projecting them onto multiple 1-dimensional probability distributions. However, identifying informative slicing directions has proven challenging, often requiring a large number of slices to achieve desirable performance and thereby increasing computational complexity. We introduce a constrained learning approach to optimize the slicing directions for SW distances. Specifically, we constrain the 1D transport plans to approximate the optimal plan in the original space, ensuring meaningful slicing directions. By leveraging continuous relaxations of these transport plans, we enable a gradient-based primal-dual approach to train the slicer parameters, along with the remaining model parameters. We demonstrate how this constrained slicing approach can be applied to pool high-dimensional embeddings into fixed-length permutation-invariant representations. Numerical results on foundation models trained on images, point clouds, and protein sequences showcase the efficacy of the proposed constrained learning approach in learning more informative slicing directions. Our implementation code can be found at https://github.com/Stranja572/constrainedswe.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sliced Wasserstein (SW) distances offer an efficient method for comparinghigh-dimensional probability measures by projecting them onto multiple1-dimensional probability distributions. However, identifying informativeslicing directions has proven challenging, often necessitating a large numberof slices to achieve desirable performance and thereby increasing computationalcomplexity. We introduce a constrained learning approach to optimize theslicing directions for SW distances. Specifically, we constrain the 1Dtransport plans to approximate the optimal plan in the original space, ensuringmeaningful slicing directions. By leveraging continuous relaxations of thesetransport plans, we enable a gradient-based primal-dual approach to train theslicer parameters, alongside the remaining model parameters. We demonstrate howthis constrained slicing approach can be applied to pool high-dimensionalembeddings into fixed-length permutation-invariant representations. Numericalresults on foundation models trained on images, point clouds, and proteinsequences showcase the efficacy of the proposed constrained learning approachin learning more informative slicing directions. Our implementation code can befound at https://github.com/Stranja572/constrainedswe.</description>
      <author>example@mail.com (Navid NaderiAlizadeh, Darian Salehi, Xinran Liu, Soheil Kolouri)</author>
      <guid isPermaLink="false">2506.02203v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Scene Detection Policies and Keyframe Extraction Strategies for Large-Scale Video Analysis</title>
      <link>http://arxiv.org/abs/2506.00667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 8 figures, submitted as a preprint. ArXiv preprint only,  not submitted to a journal yet&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种统一的、自适应的框架，用于自动场景检测和关键帧选择，适用于从短视频到长篇电影、档案内容和监控录像等多种视频格式。&lt;h4&gt;背景&lt;/h4&gt;场景分割和关键帧提取是视频理解流程中的关键预处理步骤，支持索引、摘要和语义检索等任务。然而，现有方法在处理不同类型和长度的视频时往往缺乏泛化能力。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够处理多种视频格式的自动场景检测和关键帧选择系统，以支持视频分析的下游应用。&lt;h4&gt;方法&lt;/h4&gt;系统根据视频长度动态选择分割策略：对于短视频使用自适应阈值，对于中等长度的视频使用混合策略，对于长视频使用基于区间的分割。对于关键帧选择，使用了一个轻量级的模块，该模块通过锐度、亮度和时间分布的复合指标对采样帧进行评分。&lt;h4&gt;主要发现&lt;/h4&gt;系统在不同视频格式和长度上保持了一致的粒度和高效的处理，并在商业视频分析平台上部署，已处理来自媒体、教育、研究和安全等领域的多个内容。&lt;h4&gt;结论&lt;/h4&gt;该系统提供了一个可扩展且可解释的解决方案，适用于UI预览、嵌入管道和内容过滤等下游应用。未来工作将包括音频感知分割和基于强化学习的帧评分。&lt;h4&gt;翻译&lt;/h4&gt;摘要：鲁棒的场景分割和关键帧提取是视频理解流程中的关键预处理步骤，支持索引、摘要和语义检索等任务。然而，现有方法在处理不同类型和长度的视频时往往缺乏泛化能力。我们提出了一种统一的、自适应的框架，用于自动场景检测和关键帧选择，适用于从短视频到长篇电影、档案内容和监控录像等多种视频格式。我们的系统根据视频长度动态选择分割策略：对于短视频使用自适应阈值，对于中等长度的视频使用混合策略，对于长视频使用基于区间的分割。为了关键帧选择，我们采用了一个轻量级的模块，该模块通过锐度、亮度和时间分布的复合指标对采样帧进行评分。设计用于高吞吐量工作流程的系统已在商业视频分析平台上部署，并处理了来自媒体、教育、研究和安全等领域的多个内容。它提供了一个可扩展且可解释的解决方案，适用于下游应用，如UI预览、嵌入管道和内容过滤。我们讨论了实际实施细节，并概述了未来的改进，包括音频感知分割和基于强化学习的帧评分。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust scene segmentation and keyframe extraction are essential preprocessingsteps in video understanding pipelines, supporting tasks such as indexing,summarization, and semantic retrieval. However, existing methods often lackgeneralizability across diverse video types and durations. We present aunified, adaptive framework for automatic scene detection and keyframeselection that handles formats ranging from short-form media to long-formfilms, archival content, and surveillance footage. Our system dynamicallyselects segmentation policies based on video length: adaptive thresholding forshort videos, hybrid strategies for mid-length ones, and interval-basedsplitting for extended recordings. This ensures consistent granularity andefficient processing across domains. For keyframe selection, we employ alightweight module that scores sampled frames using a composite metric ofsharpness, luminance, and temporal spread, avoiding complex saliency modelswhile ensuring visual relevance. Designed for high-throughput workflows, thesystem is deployed in a commercial video analysis platform and has processedcontent from media, education, research, and security domains. It offers ascalable and interpretable solution suitable for downstream applications suchas UI previews, embedding pipelines, and content filtering. We discusspractical implementation details and outline future enhancements, includingaudio-aware segmentation and reinforcement-learned frame scoring.</description>
      <author>example@mail.com (Vasilii Korolkov)</author>
      <guid isPermaLink="false">2506.00667v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>CLARIFY: Contrastive Preference Reinforcement Learning for Untangling Ambiguous Queries</title>
      <link>http://arxiv.org/abs/2506.00388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为CLARIFY的离线PbRL方法，用于解决人类偏好中模糊反馈的问题，提高了PbRL在现实世界中的应用效率。&lt;h4&gt;背景&lt;/h4&gt;PbRL通过从人类偏好比较中推断奖励函数，避免了显式奖励工程，但人类在标记相似片段的偏好时往往存在困难，这降低了标签效率并限制了PbRL的实际应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决人类偏好中模糊反馈的问题，提高PbRL的标签效率和实际应用效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为CLARIFY的离线PbRL方法，该方法学习一个包含偏好信息的轨迹嵌入空间，确保明显区分的片段间隔较大，从而便于选择更明确的查询。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CLARIFY在非理想教师和真实人类反馈环境中均优于基线方法。该方法不仅选择了更明显的查询，还学习了有意义的轨迹嵌入。&lt;h4&gt;结论&lt;/h4&gt;CLARIFY方法能够有效提高PbRL在现实世界中的应用效果，为解决人类偏好中模糊反馈问题提供了一种新的思路。&lt;h4&gt;翻译&lt;/h4&gt;Preference-based reinforcement learning (PbRL) bypasses explicit reward engineering by inferring reward functions from human preference comparisons, enabling better alignment with human intentions. However, humans often struggle to label a clear preference between similar segments, reducing label efficiency and limiting PbRL's real-world applicability. To address this, we propose an offline PbRL method: Contrastive LeArning for ResolvIng Ambiguous Feedback (CLARIFY), which learns a trajectory embedding space that incorporates preference information, ensuring clearly distinguished segments are spaced apart, thus facilitating the selection of more unambiguous queries. Extensive experiments demonstrate that CLARIFY outperforms baselines in both non-ideal teachers and real human feedback settings. Our approach not only selects more distinguished queries but also learns meaningful trajectory embeddings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Preference-based reinforcement learning (PbRL) bypasses explicit rewardengineering by inferring reward functions from human preference comparisons,enabling better alignment with human intentions. However, humans often struggleto label a clear preference between similar segments, reducing label efficiencyand limiting PbRL's real-world applicability. To address this, we propose anoffline PbRL method: Contrastive LeArning for ResolvIng Ambiguous Feedback(CLARIFY), which learns a trajectory embedding space that incorporatespreference information, ensuring clearly distinguished segments are spacedapart, thus facilitating the selection of more unambiguous queries. Extensiveexperiments demonstrate that CLARIFY outperforms baselines in both non-idealteachers and real human feedback settings. Our approach not only selects moredistinguished queries but also learns meaningful trajectory embeddings.</description>
      <author>example@mail.com (Ni Mu, Hao Hu, Xiao Hu, Yiqin Yang, Bo Xu, Qing-Shan Jia)</author>
      <guid isPermaLink="false">2506.00388v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Tomographic Foundation Model -- FORCE: Flow-Oriented Reconstruction Conditioning Engine</title>
      <link>http://arxiv.org/abs/2506.02149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的CT图像重建方法，通过结合数据保真度和先进的生成AI模型Poisson flow generative model (PFGM)及其扩展版本PFGM++，构建了Flow-Oriented Reconstruction Conditioning Engine (FORCE)框架，显著提升了CT成像任务的表现。&lt;h4&gt;背景&lt;/h4&gt;临床CT应用如低剂量筛查、稀疏视图扫描和金属植入等情况，常导致重建图像中出现严重噪声和伪影，需要改进的重建技术。深度学习在CT图像重建方面取得了显著进展，但获取配对训练数据仍具挑战性，且深度学习模型存在数据不一致性和模型不稳定性导致的幻觉风险。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的CT图像重建框架，以解决临床CT应用中的噪声和伪影问题，并提高重建图像的质量。&lt;h4&gt;方法&lt;/h4&gt;本文将数据保真度与Poisson flow generative model (PFGM)及其扩展版本PFGM++结合，提出了Flow-Oriented Reconstruction Conditioning Engine (FORCE)框架。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在各种CT成像任务中表现出色，优于现有的无监督重建方法。&lt;h4&gt;结论&lt;/h4&gt;Flow-Oriented Reconstruction Conditioning Engine (FORCE)框架在CT图像重建中具有良好的性能，为解决临床CT应用中的噪声和伪影问题提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;Computed tomography (CT) is a major medical imaging modality. Clinical CT scenarios, such as low-dose screening, sparse-view scanning, and metalimplants, often lead to severe noise and artifacts in reconstructed images,requiring improved reconstruction techniques. The introduction of deep learninghas significantly advanced CT image reconstruction. However, obtaining pairedtraining data remains rather challenging due to patient motion and otherconstraints. Although deep learning methods can still perform well withapproximately paired data, they inherently carry the risk of hallucination dueto data inconsistencies and model instability. In this paper, we integrate thedata fidelity with the state-of-the-art generative AI model, referred to as thePoisson flow generative model (PFGM) with a generalized version PFGM++, andpropose a novel CT framework: Flow-Oriented Reconstruction Conditioning Engine(FORCE). In our experiments, the proposed method shows superior performance invarious CT imaging tasks, outperforming existing unsupervised reconstructionapproaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computed tomography (CT) is a major medical imaging modality. Clinical CTscenarios, such as low-dose screening, sparse-view scanning, and metalimplants, often lead to severe noise and artifacts in reconstructed images,requiring improved reconstruction techniques. The introduction of deep learninghas significantly advanced CT image reconstruction. However, obtaining pairedtraining data remains rather challenging due to patient motion and otherconstraints. Although deep learning methods can still perform well withapproximately paired data, they inherently carry the risk of hallucination dueto data inconsistencies and model instability. In this paper, we integrate thedata fidelity with the state-of-the-art generative AI model, referred to as thePoisson flow generative model (PFGM) with a generalized version PFGM++, andpropose a novel CT framework: Flow-Oriented Reconstruction Conditioning Engine(FORCE). In our experiments, the proposed method shows superior performance invarious CT imaging tasks, outperforming existing unsupervised reconstructionapproaches.</description>
      <author>example@mail.com (Wenjun Xia, Chuang Niu, Ge Wang)</author>
      <guid isPermaLink="false">2506.02149v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>TIDFormer: Exploiting Temporal and Interactive Dynamics Makes A Great Dynamic Graph Transformer</title>
      <link>http://arxiv.org/abs/2506.00431v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  KDD2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TIDFormer的动态图Transformer模型，该模型在捕捉动态图中的时序和交互动态方面表现出高效性，并在多个动态图数据集上超越了现有模型。&lt;h4&gt;背景&lt;/h4&gt;由于自注意力机制（SAMs）在序列建模中捕捉依赖关系的能力，一些现有的动态图神经网络（DGNNs）利用Transformer架构和不同的编码设计来捕捉动态图的序列演化。&lt;h4&gt;目的&lt;/h4&gt;提高基于Transformer的DGNNs的有效性和效率，通过正确定义动态图上的SAM和全面编码时序和交互动态，而不需要额外的复杂模块。&lt;h4&gt;方法&lt;/h4&gt;提出TIDFormer，利用基于日历的时间分区信息和通过采样一阶邻居提取的信息交互嵌入来建模时序和交互动态。同时，通过简单分解来捕捉历史交互模式中的潜在变化。&lt;h4&gt;主要发现&lt;/h4&gt;TIDFormer在多个动态图数据集上进行了广泛的实验，结果显示其在大多数数据集和实验设置上优于现有模型，并展现出相对于先前基于Transformer的方法的显著效率优势。&lt;h4&gt;结论&lt;/h4&gt;TIDFormer是一个高效且有效的动态图Transformer模型，它在捕捉动态图中的时序和交互动态方面表现出色，并且在多个数据集上优于现有模型。&lt;h4&gt;翻译&lt;/h4&gt;由于自注意力机制（SAMs）在序列建模中捕捉依赖关系的能力，一些现有的动态图神经网络（DGNNs）利用Transformer架构和不同的编码设计来捕捉动态图的序列演化。然而，这些基于Transformer的DGNNs的有效性和效率存在显著差异，突出了在动态图上正确定义SAM以及全面编码时序和交互动态的重要性，而无需额外的复杂模块。在本工作中，我们提出了TIDFormer，这是一种动态图Transformer，以高效的方式充分利用了时序和交互动态。我们阐明了我们提出的SAM的可解释性，解决了先前工作中其在动态图上不可解释定义的开放性问题。为了分别建模时序和交互动态，我们利用基于日历的时间分区信息，并仅通过采样一阶邻居为有向图和无向图提取信息交互嵌入。此外，我们通过简单分解来捕捉历史交互模式中的潜在变化，联合建模时序和交互特征。我们在多个动态图数据集上进行了广泛的实验，以验证TIDFormer的有效性和效率。实验结果表明，TIDFormer在大多数数据集和实验设置上优于现有模型，并且相对于先前基于Transformer的方法具有显著的效率优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737155&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to the proficiency of self-attention mechanisms (SAMs) in capturingdependencies in sequence modeling, several existing dynamic graph neuralnetworks (DGNNs) utilize Transformer architectures with various encodingdesigns to capture sequential evolutions of dynamic graphs. However, theeffectiveness and efficiency of these Transformer-based DGNNs varysignificantly, highlighting the importance of properly defining the SAM ondynamic graphs and comprehensively encoding temporal and interactive dynamicswithout extra complex modules. In this work, we propose TIDFormer, a dynamicgraph TransFormer that fully exploits Temporal and Interactive Dynamics in anefficient manner. We clarify and verify the interpretability of our proposedSAM, addressing the open problem of its uninterpretable definitions on dynamicgraphs in previous works. To model the temporal and interactive dynamics,respectively, we utilize the calendar-based time partitioning information andextract informative interaction embeddings for both bipartite and non-bipartitegraphs using merely the sampled first-order neighbors. In addition, we jointlymodel temporal and interactive features by capturing potential changes inhistorical interaction patterns through a simple decomposition. We conductextensive experiments on several dynamic graph datasets to verify theeffectiveness and efficiency of TIDFormer. The experimental results demonstratethat TIDFormer excels, outperforming state-of-the-art models across mostdatasets and experimental settings. Furthermore, TIDFormer exhibits significantefficiency advantages compared to previous Transformer-based methods.</description>
      <author>example@mail.com (Jie Peng, Zhewei Wei, Yuhang Ye)</author>
      <guid isPermaLink="false">2506.00431v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Chain-of-Frames: Advancing Video Understanding in Multimodal LLMs via Frame-Aware Reasoning</title>
      <link>http://arxiv.org/abs/2506.00318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于视频帧的推理步骤的视频LLMs，通过在自然语言中生成推理轨迹来提高视频理解任务的表现。&lt;h4&gt;背景&lt;/h4&gt;研究表明，在回答用户请求之前，让大型语言模型（LLMs）以自然语言生成推理轨迹可以显著提高其性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，使视频LLMs的推理步骤基于并明确引用相关视频帧。&lt;h4&gt;方法&lt;/h4&gt;创建了一个名为CoF-Data的大型数据集，包含多种主题和任务的问题、答案以及相应的基于帧的推理轨迹。然后，在CoF数据上微调现有的视频LLMs。该方法简单且自包含，不需要辅助网络来选择或描述相关帧。&lt;h4&gt;主要发现&lt;/h4&gt;基于CoF的模型能够生成准确地引用关键帧以回答给定问题的思维链。&lt;h4&gt;结论&lt;/h4&gt;该方法在多个视频理解基准测试中表现出色，例如在Video-MME、MVBench和VSI-Bench上超越了领先的视频LLMs，并显著降低了幻觉率。&lt;h4&gt;翻译&lt;/h4&gt;最近的研究表明，在回答用户请求之前，让大型语言模型（LLMs）以自然语言生成推理轨迹可以显著提高其在各种任务上的性能。这种方法已扩展到多模态LLMs，其中模型可以生成关于输入图像和视频内容的思维链（CoT）。在本工作中，我们提出获取视频LLMs，其推理步骤基于并明确引用相关视频帧。为此，我们首先创建了一个名为CoF-Data的大型数据集，包含多种主题和任务的问题、答案以及相应的自然和合成视频的基于帧的推理轨迹。然后，在CoF数据上微调现有的视频LLMs。我们的方法简单且自包含，与现有的视频CoT方法不同，不需要辅助网络来选择或描述相关帧。我们表明，基于CoF的模型能够生成准确地引用关键帧以回答给定问题的思维链。这反过来又导致在多个视频理解基准测试中表现出色，例如在Video-MME、MVBench和VSI-Bench上超过了领先的视频LLMs，并显著降低了幻觉率。代码可在https://github.com/SaraGhazanfari/CoF处获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent work has shown that eliciting Large Language Models (LLMs) to generatereasoning traces in natural language before answering the user's request cansignificantly improve their performance across tasks. This approach has beenextended to multimodal LLMs, where the models can produce chain-of-thoughts(CoT) about the content of input images and videos. In this work, we propose toobtain video LLMs whose reasoning steps are grounded in, and explicitly referto, the relevant video frames. For this, we first create CoF-Data, a largedataset of diverse questions, answers, and corresponding frame-groundedreasoning traces about both natural and synthetic videos, spanning varioustopics and tasks. Then, we fine-tune existing video LLMs on thischain-of-frames (CoF) data. Our approach is simple and self-contained, and,unlike existing approaches for video CoT, does not require auxiliary networksto select or caption relevant frames. We show that our models based on CoF areable to generate chain-of-thoughts that accurately refer to the key frames toanswer the given question. This, in turn, leads to improved performance acrossmultiple video understanding benchmarks, for example, surpassing leading videoLLMs on Video-MME, MVBench, and VSI-Bench, and notably reducing thehallucination rate. Code available athttps://github.com/SaraGhazanfari/CoF}{github.com/SaraGhazanfari/CoF.</description>
      <author>example@mail.com (Sara Ghazanfari, Francesco Croce, Nicolas Flammarion, Prashanth Krishnamurthy, Farshad Khorrami, Siddharth Garg)</author>
      <guid isPermaLink="false">2506.00318v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>SMELLNET: A Large-scale Dataset for Real-world Smell Recognition</title>
      <link>http://arxiv.org/abs/2506.00239v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了基于气味识别的AI技术及其在过敏原检测、工艺监控和情绪、压力及疾病监测中的应用。文章提出了SmellNet，这是一个首个大规模的气味数据库，并展示了基于该数据库训练的AI模型在物质气味分类上的性能。&lt;h4&gt;背景&lt;/h4&gt;AI在气味识别方面具有广泛的应用潜力，但目前缺乏大规模的基准数据集和评估体系。&lt;h4&gt;目的&lt;/h4&gt;构建一个大规模的气味数据库SmellNet，并基于此训练AI模型实现实时物质气味分类。&lt;h4&gt;方法&lt;/h4&gt;使用便携式气体和化学传感器收集气味数据，创建SmellNet数据库；利用序列模型、对比学习和新的时间差分方法训练AI模型；在预录制数据和真实世界条件下评估模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;SmellNet数据库包含约18万时间步的50种物质数据；模型在预录制数据上达到65.35%的准确率，在真实世界条件下对坚果和香料达到10.71%和25.38%的准确率。&lt;h4&gt;结论&lt;/h4&gt;尽管取得了令人鼓舞的结果，但SmellNet也突显了构建AI气味识别技术的技术挑战，包括更丰富的特征学习、边缘化气味模型和环境变化的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了基于气味识别的人工智能技术及其在过敏原检测、制造过程监控和情绪、压力及疾病监测等方面的广泛应用潜力。尽管目前缺乏大规模的基准数据集和评估体系，但本文提出并构建了一个名为SmellNet的大规模气味数据库。通过使用便携式气体和化学传感器收集数据，SmellNet包含了约18万时间步的50种物质数据。基于此数据库，本文训练了人工智能模型，以实现仅通过气味进行物质的实时分类。在预录制数据上，最佳模型达到了65.35%的准确率，在真实世界条件下，对坚果和香料分别达到了10.71%和25.38%的准确率。尽管取得了令人鼓舞的结果，但SmellNet也突显了构建人工智能气味识别技术的技术挑战，包括更丰富的特征学习、边缘化气味模型和环境变化的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability of AI to sense and identify various substances based on theirsmell alone can have profound impacts on allergen detection (e.g., smellinggluten or peanuts in a cake), monitoring the manufacturing process, and sensinghormones that indicate emotional states, stress levels, and diseases. Despitethese broad impacts, there are virtually no large scale benchmarks, andtherefore little progress, for training and evaluating AI systems' ability tosmell in the real world. In this paper, we use portable gas and chemicalsensors to create SmellNet, the first large-scale database that digitizes adiverse range of smells in the natural world. SmellNet contains about 180,000time steps of 50 substances (spanning nuts, spices, herbs, fruits, andvegetables) with 50 hours of data. Using SmellNet, we train AI models forreal-time classification of substances based on their smell alone. Our bestmethods leverage sequence models, contrastive learning to integratehigh-resolution Gas Chromatography-Mass Spectrometry molecular data, and a newtemporal difference method that identifies sharp changes in sensor readings.Our best models achieve up to 65.35% accuracy on pre-recorded data, andgeneralize to real-world conditions with 10.71% accuracy on nuts and 25.38% onspices in the challenging 50-way online classification task. Despite thesepromising results, SmellNet highlights many technical challenges in building AIfor smell, including richer feature learning, on-edge smell models, androbustness to environmental changes.</description>
      <author>example@mail.com (Dewei Feng, Carol Li, Wei Dai, Paul Pu Liang)</author>
      <guid isPermaLink="false">2506.00239v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting LRP: Positional Attribution as the Missing Ingredient for Transformer Explainability</title>
      <link>http://arxiv.org/abs/2506.02138v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的Transformer可解释性工具，通过考虑位置编码来提高解释性。&lt;h4&gt;背景&lt;/h4&gt;Transformer的可解释性是深度学习研究中的一个关键追求，Layer-wise Relevance Propagation (LRP)是一种有前景的方法，但它忽略了位置编码这一重要组件。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来改进Transformer的可解释性，使其能够考虑位置编码。&lt;h4&gt;方法&lt;/h4&gt;将Transformer的可解释性输入空间重新定义为位置-标记对，并提出了专门的理论基础LRP规则，以传播不同位置编码方法（如旋转、可学习和绝对PE）的归因。&lt;h4&gt;主要发现&lt;/h4&gt;通过在细调分类器和零样本基础模型（如LLaMA 3）上的广泛实验，该方法在视觉和NLP可解释性任务中显著优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;该方法通过考虑位置编码，显著提高了Transformer的可解释性，并且代码是公开的。&lt;h4&gt;翻译&lt;/h4&gt;The development of effective explainability tools for Transformers is a crucial pursuit in deep learning research. One of the most promising approaches in this domain is Layer-wise Relevance Propagation (LRP), which propagates relevance scores backward through the network to the input space by redistributing activation values based on predefined rules. However, existing LRP-based methods for Transformer explainability entirely overlook a critical component of the Transformer architecture: its positional encoding (PE), resulting in violation of the conservation property, and the loss of an important and unique type of relevance, which is also associated with structural and positional features. To address this limitation, we reformulate the input space for Transformer explainability as a set of position-token pairs. This allows us to propose specialized theoretically-grounded LRP rules designed to propagate attributions across various positional encoding methods, including Rotary, Learnable, and Absolute PE. Extensive experiments with both fine-tuned classifiers and zero-shot foundation models, such as LLaMA 3, demonstrate that our method significantly outperforms the state-of-the-art in both vision and NLP explainability tasks. Our code is publicly available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of effective explainability tools for Transformers is acrucial pursuit in deep learning research. One of the most promising approachesin this domain is Layer-wise Relevance Propagation (LRP), which propagatesrelevance scores backward through the network to the input space byredistributing activation values based on predefined rules. However, existingLRP-based methods for Transformer explainability entirely overlook a criticalcomponent of the Transformer architecture: its positional encoding (PE),resulting in violation of the conservation property, and the loss of animportant and unique type of relevance, which is also associated withstructural and positional features. To address this limitation, we reformulatethe input space for Transformer explainability as a set of position-tokenpairs. This allows us to propose specialized theoretically-grounded LRP rulesdesigned to propagate attributions across various positional encoding methods,including Rotary, Learnable, and Absolute PE. Extensive experiments with bothfine-tuned classifiers and zero-shot foundation models, such as LLaMA 3,demonstrate that our method significantly outperforms the state-of-the-art inboth vision and NLP explainability tasks. Our code is publicly available.</description>
      <author>example@mail.com (Yarden Bakish, Itamar Zimerman, Hila Chefer, Lior Wolf)</author>
      <guid isPermaLink="false">2506.02138v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>GrapheonRL: A Graph Neural Network and Reinforcement Learning Framework for Constraint and Data-Aware Workflow Mapping and Scheduling in Heterogeneous HPC Systems</title>
      <link>http://arxiv.org/abs/2506.00260v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 7 figures, IEEE COMPSAC 2025 Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合图神经网络（GNN）和强化学习（RL）的新方法，以灵活处理工作流、动态约束和异构资源，同时提供快速响应。&lt;h4&gt;背景&lt;/h4&gt;有效利用资源和减少作业完成时间（makespan）是异构高性能计算（HPC）环境中工作负载映射和调度的关键好处。&lt;h4&gt;目的&lt;/h4&gt;旨在提供一个能够处理异构HPC计算连续系统景观中不断变化的约束、工作负载大小和复杂性的鲁棒且可扩展的映射和调度解决方案。&lt;h4&gt;方法&lt;/h4&gt;该方法采用GNN来管理依赖和资源需求，RL通过学习策略优化调度决策，避免了对全局搜索的需求。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法能够有效适应不同的工作流，遵守HPC约束，并提供类似于ILP的优化解决方案，但执行时间显著减少（快76%），与启发式方法相当（仅比OLB慢3.85倍）。&lt;h4&gt;结论&lt;/h4&gt;该研究为HPC环境中的工作负载映射和调度提供了一种高效且可扩展的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective resource utilization and decreased makespan in heterogeneous HighPerformance Computing (HPC) environments are key benefits of workload mappingand scheduling. Tools such as Snakemake, a workflow management solution, employInteger Linear Programming (ILP) and heuristic techniques to deploy workflowsin various HPC environments like SLURM (Simple Linux Utility for ResourceManagement) or Kubernetes. Its scheduler factors in workflow task dependencies,resource requirements, and individual task data sizes before system deployment.ILP offers optimal solutions respecting constraints, but only for smallerworkflows. Meanwhile, meta-heuristics and heuristics offer faster, thoughsuboptimal, makespan. As problem sizes, system constraints, and complexitiesevolve, maintaining these schedulers becomes challenging. In this study, wepropose a novel solution that integrates Graph Neural Network (GNN) andReinforcement Learning (RL) to flexibly handle workflows, dynamic constraints,and heterogeneous resources while providing quick responses. GNN managesdependencies and resource requirements, and RL optimizes schedulingdecision-making via a learned policy, overcoming the need for a comprehensiveglobal search. Experimental results with different datasets demonstrate thatthis method effectively adapts to different workflows, adheres to HPCconstraints, and offers optimal solutions akin to ILP but with drasticallyreduced execution times (76 percent faster), comparable to heuristic methods(only 3.85 times slower than OLB). Our contribution is to provide a robust yetscalable mapping and scheduling solution that can handle changing constraints,as well as workload sizes and complexities in a heterogeneous HPC ComputeContinuum system landscape.</description>
      <author>example@mail.com (Aasish Kumar Sharma, Julian Kunkel)</author>
      <guid isPermaLink="false">2506.00260v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Fast-in-Slow: A Dual-System Foundation Model Unifying Fast Manipulation within Slow Reasoning</title>
      <link>http://arxiv.org/abs/2506.01953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Fast-in-Slow的统一双系统视觉语言动作（VLA）模型，旨在解决机器人操作中的策略和执行效率问题。&lt;h4&gt;背景&lt;/h4&gt;当前基于互联网规模预训练的视觉语言模型（VLM）在常识推理方面具有优势，但执行频率低。为解决这一矛盾，提出了基于Kahneman理论的混合系统方法，但现有设计将两个系统作为独立模型，限制了System 1从System 2中充分利用预训练知识。&lt;h4&gt;目的&lt;/h4&gt;提出Fast-in-Slow（FiS）模型，通过将System 1执行模块嵌入到基于VLM的System 2中，提高执行频率并促进推理与执行之间的协调。&lt;h4&gt;方法&lt;/h4&gt;FiS模型通过参数共享将System 1执行模块集成到System 2中，设计了双感知共训练策略，使System 1具备动作生成能力，同时保持System 2的上下文推理表示。&lt;h4&gt;主要发现&lt;/h4&gt;FiS-VLA在模拟和现实任务中，平均成功率比之前的方法分别提高了8%和11%，同时达到了117.7 Hz的控制频率。&lt;h4&gt;结论&lt;/h4&gt;FiS模型有效地提高了机器人操作的策略和执行效率，为机器人领域提供了新的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;The summary of the abstract is as follows: The Fast-in-Slow (FiS) model is proposed in this paper to address the challenges of policy and execution efficiency in robotic manipulation. By embedding the System 1 execution module within the VLM-based System 2 and sharing parameters, the model not only enables high-frequency execution in System 1 but also facilitates the coordination between reasoning and execution components within the single foundation model of System 2. The FiS-VLA model outperforms previous state-of-the-art methods by 8% in simulation and 11% in real-world tasks, achieving a control frequency of 117.7 Hz with an action chunk set to eight.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalized policy and execution efficiency constitute the two criticalchallenges in robotic manipulation. While recent foundation policies benefitfrom the common-sense reasoning capabilities of internet-scale pretrainedvision-language models (VLMs), they often suffer from low execution frequency.To mitigate this dilemma, dual-system approaches, inspired by Kahneman'stheory, have been proposed to leverage a VLM-based System 2 model handlinghigh-level reasoning and a separate System 1 action model ensuring real-timecontrol. However, existing designs maintain both systems as separate models,limiting System 1 from fully leveraging the rich pretrained knowledge from theVLM-based System 2. In this work, we propose Fast-in-Slow (FiS), a unifieddual-system vision-language-action (VLA) model that embeds the System 1execution module within the VLM-based System 2 by partially sharing parameters.This innovative paradigm not only enables high-frequency execution in System 1but also facilitates coordination between the reasoning and executioncomponents within a single foundation model of System 2. Given theirfundamentally distinct roles within FiS-VLA, we design the two systems toincorporate heterogeneous modality inputs alongside asynchronous operatingfrequencies, enabling both fast and precise manipulation. To enablecoordination between the two systems, a dual-aware co-training strategy isproposed that equips System 1 with action generation capabilities whilepreserving System 2's contextual reasoning representation. For evaluation,FiS-VLA outperforms previous state-of-the-art methods by 8% in simulation and11% in real-world tasks in terms of average success rate, while achieving a117.7 Hz control frequency with action chunk set to eight. Project web page:fast-in-slow.github.io.</description>
      <author>example@mail.com (Hao Chen, Jiaming Liu, Chenyang Gu, Zhuoyang Liu, Renrui Zhang, Xiaoqi Li, Xiao He, Yandong Guo, Chi-Wing Fu, Shanghang Zhang, Pheng-Ann Heng)</author>
      <guid isPermaLink="false">2506.01953v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning</title>
      <link>http://arxiv.org/abs/2506.00101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 pages, 1 figure, 4 tables. Full paper is available at  arXiv:2503.21055&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了过程感知视频表示学习，通过结合LLM生成的状态变化描述作为视频编码器的监督信号，并生成状态变化反事实以帮助模型学习。实验结果表明，所提出的状态变化描述及其反事实在多个任务上取得了显著改进。&lt;h4&gt;背景&lt;/h4&gt;当前过程感知视频表示学习研究未能明确学习状态变化（场景转换）。&lt;h4&gt;目的&lt;/h4&gt;通过改进视频表示学习，使模型能够理解动作步骤之间的因果关系。&lt;h4&gt;方法&lt;/h4&gt;使用LLM生成的状态变化描述作为监督信号，并生成状态变化反事实来模拟假设的失败结果，使模型通过想象未见过的情况来学习。&lt;h4&gt;主要发现&lt;/h4&gt;模型通过反事实推理增强了理解活动每个步骤因果关系的本领，实验验证了模型在过程感知任务上的有效性，包括时间动作分割、错误检测等。&lt;h4&gt;结论&lt;/h4&gt;提出的状态变化描述及其反事实在多个任务上显著提升了模型的效果。&lt;h4&gt;翻译&lt;/h4&gt;Understanding a procedural activity requires modeling both how action steps transform the scene, and how evolving scene transformations can influence the sequence of action steps, even those that are accidental or erroneous. Yet, existing work on procedure-aware video representations fails to explicitly learn the state changes (scene transformations). In this work, we study procedure-aware video representation learning by incorporating state-change descriptions generated by LLMs as supervision signals for video encoders. Moreover, we generate state-change counterfactuals that simulate hypothesized failure outcomes, allowing models to learn by imagining the unseen ``What if'' scenarios. This counterfactual reasoning facilitates the model's ability to understand the cause and effect of each step in an activity. To verify the procedure awareness of our model, we conduct extensive experiments on procedure-aware tasks, including temporal action segmentation, error detection, and more. Our results demonstrate the effectiveness of the proposed state-change descriptions and their counterfactuals, and achieve significant improvements on multiple tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding a procedural activity requires modeling both how action stepstransform the scene, and how evolving scene transformations can influence thesequence of action steps, even those that are accidental or erroneous. Yet,existing work on procedure-aware video representations fails to explicitlylearned the state changes (scene transformations). In this work, we studyprocedure-aware video representation learning by incorporating state-changedescriptions generated by LLMs as supervision signals for video encoders.Moreover, we generate state-change counterfactuals that simulate hypothesizedfailure outcomes, allowing models to learn by imagining the unseen ``What if''scenarios. This counterfactual reasoning facilitates the model's ability tounderstand the cause and effect of each step in an activity. To verify theprocedure awareness of our model, we conduct extensive experiments onprocedure-aware tasks, including temporal action segmentation, error detection,and more. Our results demonstrate the effectiveness of the proposedstate-change descriptions and their counterfactuals, and achieve significantimprovements on multiple tasks.</description>
      <author>example@mail.com (Chi-Hsi Kung, Frangil Ramirez, Juhyung Ha, Yi-Ting Chen, David Crandall, Yi-Hsuan Tsai)</author>
      <guid isPermaLink="false">2506.00101v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>DeGLIF for Label Noise Robust Node Classification using GNNs</title>
      <link>http://arxiv.org/abs/2506.00244v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DeGLIF的降噪技术，用于处理图数据中的标签噪声，通过使用一小部分干净数据和leave-one-out影响函数来实现对图数据的鲁棒节点级预测。&lt;h4&gt;背景&lt;/h4&gt;相比于干净标签数据集，噪声标签数据集和图数据通常更便宜。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来处理图数据中的标签噪声，并实现准确的节点级预测。&lt;h4&gt;方法&lt;/h4&gt;DeGLIF使用leave-one-out影响函数来估计如果从训练数据集中移除一个训练点，模型参数的变化。该方法扩展了最近关于图神经网络（GNNs）的leave-one-out影响函数的计算方法，并引入了一个新的理论动机重标记函数来降噪训练数据集。DeGLIF有两种变体用于识别噪声节点，这两种变体都不需要关于噪声模型或数据集中噪声水平的信息。&lt;h4&gt;主要发现&lt;/h4&gt;通过详细的计算实验，证明了DeGLIF在不同数据集上的有效性，其准确率优于其他基线算法。&lt;h4&gt;结论&lt;/h4&gt;DeGLIF是一种有效的降噪技术，可以用于处理图数据中的标签噪声，并在不同数据集上表现出比其他基线算法更好的性能。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为DeGLIF的降噪技术：使用留一法影响函数进行降噪图数据。DeGLIF利用少量干净数据和留一法影响函数，在图数据上实现鲁棒的节点级预测。留一法影响函数近似了从训练数据集中移除一个训练点时模型参数的变化。最近的研究提出了一种计算图神经网络（GNNs）的留一法影响函数的方法。我们将这项研究扩展到估计如果从训练数据集中移除一个训练节点，验证损失的变化。我们使用这个估计和一个新的理论动机重标记函数来降噪训练数据集。我们提出了两种DeGLIF变体来识别噪声节点。这两种变体都不需要关于噪声模型或数据集中噪声水平的信息；DeGLIF也不估计这些数量。对于这些变体之一，我们证明了检测到的噪声点确实会增加风险。我们在不同的数据集上进行了详细的计算实验，以证明DeGLIF的有效性。它比其他基线算法实现了更好的准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Noisy labelled datasets are generally inexpensive compared to clean labelleddatasets, and the same is true for graph data. In this paper, we propose adenoising technique DeGLIF: Denoising Graph Data using Leave-One-Out InfluenceFunction. DeGLIF uses a small set of clean data and the leave-one-out influencefunction to make label noise robust node-level prediction on graph data.Leave-one-out influence function approximates the change in the modelparameters if a training point is removed from the training dataset. Recentadvances propose a way to calculate the leave-one-out influence function forGraph Neural Networks (GNNs). We extend that recent work to estimate the changein validation loss, if a training node is removed from the training dataset. Weuse this estimate and a new theoretically motivated relabelling function todenoise the training dataset. We propose two DeGLIF variants to identify noisynodes. Both these variants do not require any information about the noise modelor the noise level in the dataset; DeGLIF also does not estimate thesequantities. For one of these variants, we prove that the noisy points detectedcan indeed increase risk. We carry out detailed computational experiments ondifferent datasets to show the effectiveness of DeGLIF. It achieves betteraccuracy than other baseline algorithms</description>
      <author>example@mail.com (Pintu Kumar, Nandyala Hemachandra)</author>
      <guid isPermaLink="false">2506.00244v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>E3D-Bench: A Benchmark for End-to-End 3D Geometric Foundation Models</title>
      <link>http://arxiv.org/abs/2506.01933v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://e3dbench.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了3D几何基础模型（GFMs）在空间智能领域的应用，包括3D重建、感知和推理，特别关注了从非结构化或流媒体图像中实时、准确地估计核心3D属性的技术。&lt;h4&gt;背景&lt;/h4&gt;空间智能在机器人、航空成像和扩展现实等领域至关重要，而3D GFMs能够直接预测密集的3D表示，无需预计算的相机参数，因此成为关键推动力。&lt;h4&gt;目的&lt;/h4&gt;提出一个全面的3D GFMs基准，评估其在多个任务和不同数据集上的性能，并指导未来模型的扩展和优化。&lt;h4&gt;方法&lt;/h4&gt;开发了标准化工具包，自动化数据集处理、评估协议和指标计算，确保比较的公平性和可重复性，评估了16个最先进的GFMs。&lt;h4&gt;主要发现&lt;/h4&gt;揭示了不同GFMs在各项任务和领域中的优势和局限性，并得出了关键见解。&lt;h4&gt;结论&lt;/h4&gt;公开所有代码、评估脚本和数据处理，以加速3D空间智能的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：空间智能，包括3D重建、感知和推理，对于机器人、航空成像和扩展现实等应用至关重要。一个关键推动力是从非结构化或流媒体图像中实时、准确地估计核心3D属性（相机参数、点云、深度图和3D点轨迹）。受大型基础模型在语言和2D视觉中的成功启发，一类新的端到端3D几何基础模型（GFMs）已经出现，它们可以在单次前馈传递中直接预测密集的3D表示，消除了对缓慢或不可用的预计算相机参数的需求。自2023年底以来，该领域已经爆炸式增长，但缺乏系统评估。在这项工作中，我们提出了第一个全面的3D GFMs基准，涵盖了五个核心任务：稀疏视图深度估计、视频深度估计、3D重建、多视图姿态估计和新型视图合成，涵盖了标准和非标准数据集。我们的标准化工具包自动化了数据集处理、评估协议和指标计算，以确保公平、可重复的比较。我们评估了16个最先进的GFMs，揭示了它们在任务和领域中的优势和局限性，并得出了关键见解以指导未来的模型扩展和优化。所有代码、评估脚本和数据处理将公开发布，以加速3D空间智能的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial intelligence, encompassing 3D reconstruction, perception, andreasoning, is fundamental to applications such as robotics, aerial imaging, andextended reality. A key enabler is the real-time, accurate estimation of core3D attributes (camera parameters, point clouds, depth maps, and 3D pointtracks) from unstructured or streaming imagery. Inspired by the success oflarge foundation models in language and 2D vision, a new class of end-to-end 3Dgeometric foundation models (GFMs) has emerged, directly predicting dense 3Drepresentations in a single feed-forward pass, eliminating the need for slow orunavailable precomputed camera parameters. Since late 2023, the field hasexploded with diverse variants, but systematic evaluation is lacking. In thiswork, we present the first comprehensive benchmark for 3D GFMs, covering fivecore tasks: sparse-view depth estimation, video depth estimation, 3Dreconstruction, multi-view pose estimation, novel view synthesis, and spanningboth standard and challenging out-of-distribution datasets. Our standardizedtoolkit automates dataset handling, evaluation protocols, and metriccomputation to ensure fair, reproducible comparisons. We evaluate 16state-of-the-art GFMs, revealing their strengths and limitations across tasksand domains, and derive key insights to guide future model scaling andoptimization. All code, evaluation scripts, and processed data will be publiclyreleased to accelerate research in 3D spatial intelligence.</description>
      <author>example@mail.com (Wenyan Cong, Yiqing Liang, Yancheng Zhang, Ziyi Yang, Yan Wang, Boris Ivanovic, Marco Pavone, Chen Chen, Zhangyang Wang, Zhiwen Fan)</author>
      <guid isPermaLink="false">2506.01933v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Understanding Overadaptation in Supervised Fine-Tuning: The Role of Ensemble Methods</title>
      <link>http://arxiv.org/abs/2506.01901v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在特定领域数据上进行的监督微调（SFT）方法，发现SFT模型容易遗忘预训练期间获得的知识。通过将预训练模型与其微调后的对应模型进行集成，可以缓解这一问题。研究进一步发现，集成模型不仅在基础模型中保留了通用知识，而且在微调领域本身也优于微调模型。本文对集成方法的优势进行了理论分析，并证明其在提高性能方面比正则化技术更有效。&lt;h4&gt;背景&lt;/h4&gt;监督微调（SFT）是适应特定任务的主要方法，但SFT模型容易出现遗忘知识的问题。&lt;h4&gt;目的&lt;/h4&gt;证明集成方法在语言模型中也能有效缓解遗忘知识的问题，并对其优势进行理论分析。&lt;h4&gt;方法&lt;/h4&gt;对预训练模型与微调模型进行集成，并对其进行理论分析。&lt;h4&gt;主要发现&lt;/h4&gt;集成模型不仅保留了预训练模型的知识，而且在微调领域也优于微调模型。集成方法通过平衡两个主要误差来源（偏差和方差）来缓解遗忘知识的问题，比正则化技术更有效。&lt;h4&gt;结论&lt;/h4&gt;集成方法可以有效地提高模型性能，为模型集成提供理论支持。&lt;h4&gt;翻译&lt;/h4&gt;Supervised fine-tuning (SFT) on domain-specific data is the dominant approach for adapting foundation models to specialized tasks. However, it has been observed that SFT models tend to forget knowledge acquired during pretraining. In vision models, ensembling a pretrained model with its fine-tuned counterpart has been shown to mitigate this issue. In this work, we demonstrate that the same holds for language models, and, more strikingly, we observe an overadaptation phenomenon: the ensemble model not only retains general knowledge from the foundation model but also outperforms the fine-tuned model even on the fine-tuning domain itself. Despite the empirical success of ensembling, a theoretical understanding of its benefits remains underexplored. We develop a formal theoretical analysis of the overadaptation phenomenon. Ensembling mitigates this by balancing two primary sources of error: bias, caused by insufficient fine-tuning, and variance, introduced by overfitting to fine-tuning data. While regularization techniques aim to address this trade-off, we show that ensembling provides a more effective solution. We analyze this phenomenon in over-parameterized linear settings and demonstrate that interpolating between pretrained and fine-tuned weights significantly improves performance. These findings offer theoretical justification for the observed advantages of model ensembling, supported by empirical experiments consistent with our analysis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Supervised fine-tuning (SFT) on domain-specific data is the dominant approachfor adapting foundation models to specialized tasks. However, it has beenobserved that SFT models tend to forget knowledge acquired during pretraining.In vision models, ensembling a pretrained model with its fine-tuned counterparthas been shown to mitigate this issue. In this work, we demonstrate that thesame holds for language models, and, more strikingly, we observe anoveradaptation phenomenon: the ensemble model not only retains generalknowledge from the foundation model but also outperforms the fine-tuned modeleven on the fine-tuning domain itself. Despite the empirical success ofensembling, a theoretical understanding of its benefits remains underexplored.We develop a formal theoretical analysis of the overadaptation phenomenon.Ensembling mitigates this by balancing two primary sources of error: bias,caused by insufficient fine-tuning, and variance, introduced by overfitting tofine-tuning data. While regularization techniques aim to address thistrade-off, we show that ensembling provides a more effective solution. Weanalyze this phenomenon in over-parameterized linear settings and demonstratethat interpolating between pretrained and fine-tuned weights significantlyimproves performance. These findings offer theoretical justification for theobserved advantages of model ensembling, supported by empirical experimentsconsistent with our analysis.</description>
      <author>example@mail.com (Yifan Hao, Xingyuan Pan, Hanning Zhang, Chenlu Ye, Rui Pan, Tong Zhang)</author>
      <guid isPermaLink="false">2506.01901v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>EEG Foundation Models for BCI Learn Diverse Features of Electrophysiology</title>
      <link>http://arxiv.org/abs/2506.01867v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Two figures, one table, six pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的自监督BCI基础模型预训练方法，该方法受HuBERT框架启发，并针对脑电图（EEG）应用，旨在提高BCI模型在神经解码方面的表现。&lt;h4&gt;背景&lt;/h4&gt;BCI研究和神经科学领域越来越多地采用大规模人工智能预训练方法与公共数据集相结合，这种方法在神经解码方面取得了成功。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自监督预训练方法，以学习神经生理学的鲁棒表示，并探索BCI模型在其他脑功能及电生理信息方面的潜在应用。&lt;h4&gt;方法&lt;/h4&gt;该方法基于Transformer架构，专门针对低功耗、实时应用设计，使用最少的前处理数据和头皮上的八个EEG通道。&lt;h4&gt;主要发现&lt;/h4&gt;该基础模型不仅支持标准的BCI任务（如P300、运动想象），还学习了与个体差异和其他显著电生理成分（如α节律）相关的特征。&lt;h4&gt;结论&lt;/h4&gt;本研究为如何利用强大的AI方法与神经数据结合进行多种任务和应用提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;摘要：脑机接口（BCI）研究以及神经科学领域的许多部分，已经通过将大规模人工智能（AI）预训练方法与大量公共数据集相结合而取得了成功。使用无标签的自监督目标对基础模型进行预训练的方法，有望学习神经生理学的鲁棒表示，这可能有助于解决神经解码方面的长期挑战。然而，迄今为止，这项工作主要集中在标准的BCI基准和任务上，这可能会忽视这些强大方法可能学习的关于脑功能以及其他电生理信息的众多特征。我们介绍了一种新的自监督BCI基础模型预训练方法，该方法受HuBERT框架启发，该框架最初是为语音处理而开发的。我们的流程专门针对低功耗、实时使用，涉及最少的前处理数据和头皮上的八个EEG通道。我们表明，我们的基础模型学习了一种支持标准BCI任务（P300、运动想象）的EEG表示，但该模型还学习了与个体差异和其他显著电生理成分（例如，α节律）相关的神经数据特征。除了描述和评估一种新的预训练BCI模型和神经解码方法之外，这项工作还开启了对神经数据与强大AI方法结合可能存在的任务和用例的新视野。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain computer interface (BCI) research, as well as increasing portions ofthe field of neuroscience, have found success deploying large-scale artificialintelligence (AI) pre-training methods in conjunction with vast publicrepositories of data. This approach of pre-training foundation models usinglabel-free, self-supervised objectives offers the potential to learn robustrepresentations of neurophysiology, potentially addressing longstandingchallenges in neural decoding. However, to date, much of this work has focusedexplicitly on standard BCI benchmarks and tasks, which likely overlooks themultitude of features these powerful methods might learn about brain functionas well as other electrophysiological information. We introduce a new methodfor self-supervised BCI foundation model pre-training for EEG inspired by atransformer-based approach adapted from the HuBERT framework originallydeveloped for speech processing. Our pipeline is specifically focused onlow-profile, real-time usage, involving minimally pre-processed data and justeight EEG channels on the scalp. We show that our foundation model learned arepresentation of EEG that supports standard BCI tasks (P300, motor imagery),but also that this model learns features of neural data related to individualvariability, and other salient electrophysiological components (e.g., alpharhythms). In addition to describing and evaluating a novel approach topre-training BCI models and neural decoding, this work opens the aperture forwhat kind of tasks and use-cases might exist for neural data in concert withpowerful AI methods.</description>
      <author>example@mail.com (Mattson Ogg, Rahul Hingorani, Diego Luna, Griffin W. Milsap, William G. Coon, Clara A. Scholl)</author>
      <guid isPermaLink="false">2506.01867v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Binary Cumulative Encoding meets Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2505.24595v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的时间序列预测方法，通过将连续的目标空间离散化并预测固定类别，提高了训练稳定性、不确定性建模的鲁棒性，并与现代深度学习架构兼容。该方法引入了二进制累积编码（BCE），以保持目标值的顺序和大小信息，并通过卷积神经网络架构实现快速和表达式的时序建模。&lt;h4&gt;背景&lt;/h4&gt;现有时间序列预测方法大多依赖于one-hot编码，忽略了目标值的内在顺序结构，无法提供预测值与真实值之间相对距离的信息。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在处理目标值顺序结构方面的不足，提出一种新的编码方式，并设计相应的神经网络架构，以提高时间序列预测的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了二进制累积编码（BCE），将标量目标表示为单调的二进制向量，并设计了一种针对BCE的卷积神经网络架构，包含残差和膨胀卷积。&lt;h4&gt;主要发现&lt;/h4&gt;通过在基准预测数据集上的广泛实验，证明该方法在点预测和概率预测方面均优于现有方法，同时需要更少的参数并允许更快的训练。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地处理时间序列预测中的顺序结构问题，并通过实验验证了其优越性。&lt;h4&gt;翻译&lt;/h4&gt;Recent studies in time series forecasting have explored formulating regression via classification task. By discretizing the continuous target space into bins and predicting over a fixed set of classes, these approaches benefit from stable training, robust uncertainty modeling, and compatibility with modern deep learning architectures. However, most existing methods rely on one-hot encoding that ignores the inherent ordinal structure of the underlying values. As a result, they fail to provide information about the relative distance between predicted and true values during training. In this paper, we propose to address this limitation by introducing binary cumulative encoding (BCE), that represents scalar targets into monotonic binary vectors. This encoding implicitly preserves order and magnitude information, allowing the model to learn distance-aware representations while still operating within a classification framework. We propose a convolutional neural network architecture specifically designed for BCE, incorporating residual and dilated convolutions to enable fast and expressive temporal modeling. Through extensive experiments on benchmark forecasting datasets, we show that our approach outperforms widely used methods in both point and probabilistic forecasting, while requiring fewer parameters and enabling faster training.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies in time series forecasting have explored formulatingregression via classification task. By discretizing the continuous target spaceinto bins and predicting over a fixed set of classes, these approaches benefitfrom stable training, robust uncertainty modeling, and compatibility withmodern deep learning architectures. However, most existing methods rely onone-hot encoding that ignores the inherent ordinal structure of the underlyingvalues. As a result, they fail to provide information about the relativedistance between predicted and true values during training. In this paper, wepropose to address this limitation by introducing binary cumulative encoding(BCE), that represents scalar targets into monotonic binary vectors. Thisencoding implicitly preserves order and magnitude information, allowing themodel to learn distance-aware representations while still operating within aclassification framework. We propose a convolutional neural networkarchitecture specifically designed for BCE, incorporating residual and dilatedconvolutions to enable fast and expressive temporal modeling. Through extensiveexperiments on benchmark forecasting datasets, we show that our approachoutperforms widely used methods in both point and probabilistic forecasting,while requiring fewer parameters and enabling faster training.</description>
      <author>example@mail.com (Andrei Chernov, Vitaliy Pozdnyakov, Ilya Makarov)</author>
      <guid isPermaLink="false">2505.24595v2</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>SPACE: Your Genomic Profile Predictor is a Powerful DNA Foundation Model</title>
      <link>http://arxiv.org/abs/2506.01833v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为SPACE的模型，用于DNA预训练，该模型通过监督训练和混合专家（MoE）技术来提高DNA序列的表示能力。&lt;h4&gt;背景&lt;/h4&gt;受无监督预训练方法成功应用的启发，研究者们将其应用于DNA预训练，但作者认为仅使用这些方法会导致次优结果，因为纯DNA序列缺乏足够的信息。&lt;h4&gt;目的&lt;/h4&gt;旨在通过监督训练和混合专家技术来提高DNA序列的表示能力，以实现更有效的DNA预训练。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为SPACE的模型，该模型利用监督训练进行基因组轮廓预测，并使用混合专家（MoE）技术来捕捉不同物种和基因组轮廓之间的DNA序列关系。&lt;h4&gt;主要发现&lt;/h4&gt;通过在多个任务上的广泛实验，SPACE模型达到了最先进的性能，证明了使用监督基因组轮廓训练的DNA模型是强大的DNA表示学习器。&lt;h4&gt;结论&lt;/h4&gt;DNA模型与监督基因组轮廓的训练相结合，可以更有效地学习DNA表示，并实现优于纯序列预训练的效果。&lt;h4&gt;翻译&lt;/h4&gt;受无监督预训练方法成功应用的启发，研究者们将这种方法应用于DNA预训练。然而，我们认为仅使用这些方法会导致次优结果，因为纯DNA序列缺乏足够的信息，其功能受基因组轮廓（如染色质可及性）等基因组特征调控。在此，我们展示了监督训练对于基因组轮廓预测的有效性，这比纯序列预训练更为有效。鉴于基因组轮廓预测的多物种和多轮廓特性，我们引入了我们的物种-轮廓自适应协作专家（SPACE）模型，该模型利用混合专家（MoE）技术来更好地捕捉不同物种间和基因组轮廓之间的DNA序列关系，从而学习更有效的DNA表示。通过在多个任务上的广泛实验，我们的模型实现了最先进的性能，证明了使用监督基因组轮廓训练的DNA模型是强大的DNA表示学习器。代码可在https://github.com/ZhuJiwei111/SPACE获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inspired by the success of unsupervised pre-training paradigms, researchershave applied these approaches to DNA pre-training. However, we argue that theseapproaches alone yield suboptimal results because pure DNA sequences lacksufficient information, since their functions are regulated by genomic profileslike chromatin accessibility. Here, we demonstrate that supervised training forgenomic profile prediction serves as a more effective alternative to puresequence pre-training. Furthermore, considering the multi-species andmulti-profile nature of genomic profile prediction, we introduce our$\textbf{S}$pecies-$\textbf{P}$rofile $\textbf{A}$daptive$\textbf{C}$ollaborative $\textbf{E}$xperts (SPACE) that leverages Mixture ofExperts (MoE) to better capture the relationships between DNA sequences acrossdifferent species and genomic profiles, thereby learning more effective DNArepresentations. Through extensive experiments across various tasks, our modelachieves state-of-the-art performance, establishing that DNA models trainedwith supervised genomic profiles serve as powerful DNA representation learners.The code is available at https://github.com/ZhuJiwei111/SPACE.</description>
      <author>example@mail.com (Zhao Yang, Jiwei Zhu, Bing Su)</author>
      <guid isPermaLink="false">2506.01833v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Human-Centric Evaluation for Foundation Models</title>
      <link>http://arxiv.org/abs/2506.01793v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种以人为中心的评估框架，通过实验收集了大量用户反馈，分析了不同基础模型的能力。&lt;h4&gt;背景&lt;/h4&gt;目前大多数对基础模型的评估都侧重于客观指标，但这种方法无法反映真实的人类体验。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，提出了一个以人为中心的评估框架，重点关注问题解决能力、信息质量和交互体验。&lt;h4&gt;方法&lt;/h4&gt;通过涉及Deepseek R1、OpenAI o3 mini、Grok 3和Gemini 2.5的实验，进行了超过540次的参与者驱动的评估，其中人类和模型共同完成开放性研究任务。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，Grok 3的表现优于Deepseek R1和Gemini 2.5，而OpenAI o3 mini的表现落后。&lt;h4&gt;结论&lt;/h4&gt;这项研究不仅提升了主观评估方法，还为标准化、自动化的评估奠定了基础，推动了LLM在研究和实际场景中的应用。&lt;h4&gt;翻译&lt;/h4&gt;Currently, nearly all evaluations of foundation models focus on objective metrics, emphasizing quiz performance to define model capabilities. While this model-centric approach enables rapid performance assessment, it fails to reflect authentic human experiences. To address this gap, we propose a Human-Centric subjective Evaluation (HCE) framework, focusing on three core dimensions: problem-solving ability, information quality, and interaction experience. Through experiments involving Deepseek R1, OpenAI o3 mini, Grok 3, and Gemini 2.5, we conduct over 540 participant-driven evaluations, where humans and models collaborate on open-ended research tasks, yielding a comprehensive subjective dataset. This dataset captures diverse user feedback across multiple disciplines, revealing distinct model strengths and adaptability. Our findings highlight Grok 3's superior performance, followed by Deepseek R1 and Gemini 2.5, with OpenAI o3 mini lagging behind. By offering a novel framework and a rich dataset, this study not only enhances subjective evaluation methodologies but also lays the foundation for standardized, automated assessments, advancing LLM development for research and practical scenarios. Our dataset link is https://github.com/yijinguo/Human-Centric-Evaluation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Currently, nearly all evaluations of foundation models focus on objectivemetrics, emphasizing quiz performance to define model capabilities. While thismodel-centric approach enables rapid performance assessment, it fails toreflect authentic human experiences. To address this gap, we propose aHuman-Centric subjective Evaluation (HCE) framework, focusing on three coredimensions: problem-solving ability, information quality, and interactionexperience. Through experiments involving Deepseek R1, OpenAI o3 mini, Grok 3,and Gemini 2.5, we conduct over 540 participant-driven evaluations, wherehumans and models collaborate on open-ended research tasks, yielding acomprehensive subjective dataset. This dataset captures diverse user feedbackacross multiple disciplines, revealing distinct model strengths andadaptability. Our findings highlight Grok 3's superior performance, followed byDeepseek R1 and Gemini 2.5, with OpenAI o3 mini lagging behind. By offering anovel framework and a rich dataset, this study not only enhances subjectiveevaluation methodologies but also lays the foundation for standardized,automated assessments, advancing LLM development for research and practicalscenarios. Our dataset link ishttps://github.com/yijinguo/Human-Centric-Evaluation.</description>
      <author>example@mail.com (Yijin Guo, Kaiyuan Ji, Xiaorong Zhu, Junying Wang, Farong Wen, Chunyi Li, Zicheng Zhang, Guangtao Zhai)</author>
      <guid isPermaLink="false">2506.01793v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Entanglement for Pattern Learning in Temporal Data with Logarithmic Complexity: Benchmarking on IBM Quantum Hardware</title>
      <link>http://arxiv.org/abs/2506.00097v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于量子计算的时间序列预测框架，旨在解决传统方法在数据有限或硬件受限环境中的资源消耗和扩展性问题。&lt;h4&gt;背景&lt;/h4&gt;时间序列预测在科学和技术领域至关重要，但经典方法如自回归模型和深度学习架构在资源消耗和扩展性方面存在局限。&lt;h4&gt;目的&lt;/h4&gt;开发一种量子原生的时间序列预测框架，利用量子纠缠的参数化量子电路来学习时间依赖性。&lt;h4&gt;方法&lt;/h4&gt;提出的量子时间序列（QTS）模型将标准化序列数据编码为单比特旋转，并通过结构化的纠缠模式嵌入时间结构。&lt;h4&gt;主要发现&lt;/h4&gt;QTS在合成和真实世界数据集上与经典模型进行了基准测试，包括用于数值天气预报的地球位势高度场。实验表明，QTS可以使用更少的数据点捕捉时间模式。&lt;h4&gt;结论&lt;/h4&gt;QTS在噪声后端和真实IBM量子硬件上的基准测试表明，量子纠缠可以作为实际计算资源用于时间建模，并有望在纳米尺度系统、量子传感器网络和其他预测场景中实现近期应用。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a quantum-native time series forecasting framework aimed at addressing the limitations of classical methods in resource consumption and scalability in data-limited or hardware-constrained settings. The proposed Quantum Time Series (QTS) model encodes normalized sequential data into single-qubit rotations and embeds temporal structure through structured entanglement patterns. Experiments on synthetic and real-world datasets, including geopotential height fields used in numerical weather prediction, demonstrate that QTS can capture temporal patterns using fewer data points. Benchmarking on noisy backends and real IBM quantum hardware establishes quantum entanglement as a practical computational resource for temporal modeling, with potential near-term applications in nano-scale systems, quantum sensor networks, and other forecasting scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting is foundational in scientific and technologicaldomains, from climate modelling to molecular dynamics. Classical approacheshave significantly advanced sequential prediction, including autoregressivemodels and deep learning architectures such as temporal convolutional networks(TCNs) and Transformers. Yet, they remain resource-intensive and often scalepoorly in data-limited or hardware-constrained settings. We propose aquantum-native time series forecasting framework that harnessesentanglement-based parameterized quantum circuits to learn temporaldependencies. Our Quantum Time Series (QTS) model encodes normalized sequentialdata into single-qubit rotations and embeds temporal structure throughstructured entanglement patterns. This design considers predictive performancewith logarithmic complexity in training data and parameter count. We benchmarkQTS against classical models on synthetic and real-world datasets, includinggeopotential height fields used in numerical weather prediction. Experiments onthe noisy backend and real IBM quantum hardware demonstrate that QTS cancapture temporal patterns using fewer data points. Hardware benchmarkingresults establish quantum entanglement as a practical computational resourcefor temporal modelling, with potential near-term applications in nano-scalesystems, quantum sensor networks, and other forecasting scenarios.</description>
      <author>example@mail.com (Mostafizur Rahaman Laskar, Richa Goel)</author>
      <guid isPermaLink="false">2506.00097v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>SatDreamer360: Geometry Consistent Street-View Video Generation from Satellite Imagery</title>
      <link>http://arxiv.org/abs/2506.00600v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SatDreamer360的新框架，用于从单张卫星图像和预定义轨迹生成几何和时序一致的地面视图视频。&lt;h4&gt;背景&lt;/h4&gt;生成连续地面视频是一项具有巨大应用潜力的挑战性任务，可用于模拟、自主导航和数字孪生城市。&lt;h4&gt;目的&lt;/h4&gt;提出的方法旨在克服现有方法在生成时序一致序列方面的不足，同时提高视频的真实性、连贯性和几何对齐。&lt;h4&gt;方法&lt;/h4&gt;SatDreamer360通过引入紧凑的三平面表示来编码场景几何，并使用基于射线的像素注意力机制检索三平面中的视点相关特征。此外，还提出了一个基于视差约束的时序注意力模块，以确保多帧一致性。&lt;h4&gt;主要发现&lt;/h4&gt;SatDreamer360在多样城市场景中实现了在保真度、连贯性和几何对齐方面的优越性能。&lt;h4&gt;结论&lt;/h4&gt;SatDreamer360是一个有效的方法，能够从卫星图像中生成高质量的连续地面视图视频，为模拟、自主导航和数字孪生城市等领域提供支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从卫星图像生成连续地面视频是一项具有重大应用潜力的挑战性任务，在模拟、自主导航和数字孪生城市等领域具有显著的应用潜力。现有方法主要侧重于合成单个地面视图图像，通常依赖于辅助输入，如高度图或手工投影，并且在生成时序一致序列方面存在不足。在本文中，我们提出了一种名为SatDreamer360的新框架，该框架可以从单个卫星图像和预定义轨迹生成几何和时序一致的地面视图视频。为了弥合大的视点差距，我们引入了一种紧凑的三平面表示，它直接从卫星图像中编码场景几何。基于射线的像素注意力机制从三平面中检索视点相关的特征，使跨视图对应关系准确无误，无需额外的几何先验。为了确保多帧一致性，我们提出了一种基于视差约束的时序注意力模块，使用沿轨迹的已知相对姿态对帧间特征进行对齐。为了支持评估，我们引入了VIGOR++，这是一个用于跨视图视频生成的大型数据集，具有密集的轨迹注释和高品质的地面视图序列。广泛的实验表明，SatDreamer360在多样城市场景中实现了在保真度、连贯性和几何对齐方面的优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating continuous ground-level video from satellite imagery is achallenging task with significant potential for applications in simulation,autonomous navigation, and digital twin cities. Existing approaches primarilyfocus on synthesizing individual ground-view images, often relying on auxiliaryinputs like height maps or handcrafted projections, and fall short in producingtemporally consistent sequences. In this paper, we propose {SatDreamer360}, anovel framework that generates geometrically and temporally consistentground-view video from a single satellite image and a predefined trajectory. Tobridge the large viewpoint gap, we introduce a compact tri-plane representationthat encodes scene geometry directly from the satellite image. A ray-basedpixel attention mechanism retrieves view-dependent features from the tri-plane,enabling accurate cross-view correspondence without requiring additionalgeometric priors. To ensure multi-frame consistency, we propose anepipolar-constrained temporal attention module that aligns features acrossframes using the known relative poses along the trajectory. To supportevaluation, we introduce {VIGOR++}, a large-scale dataset for cross-view videogeneration, with dense trajectory annotations and high-quality ground-viewsequences. Extensive experiments demonstrate that SatDreamer360 achievessuperior performance in fidelity, coherence, and geometric alignment acrossdiverse urban scenes.</description>
      <author>example@mail.com (Xianghui Ze, Beiyi Zhu, Zhenbo Song, Jianfeng Lu, Yujiao Shi)</author>
      <guid isPermaLink="false">2506.00600v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MIND: Material Interface Generation from UDFs for Non-Manifold Surface Reconstruction</title>
      <link>http://arxiv.org/abs/2506.02938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MIND的算法，直接从UDFs生成材料界面，从而实现非流形网格的提取。&lt;h4&gt;背景&lt;/h4&gt;UDFs在3D深度学习中广泛应用，但直接从UDFs提取网格存在挑战，因为学习到的场很少达到精确的零距离。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的算法，以解决从UDFs中提取网格的挑战，特别是非流形几何形状。&lt;h4&gt;方法&lt;/h4&gt;MIND算法通过从UDF推导出有意义的空间分区，将目标表面作为不同区域的界面。首先计算一个双符号局部场以区分流形补丁的两面，然后扩展到能够分离非流形结构所有面的多标签全局场。通过将这个多标签场与输入的UDF结合，构建支持非流形网格提取的多标签Marching Cubes算法。&lt;h4&gt;主要发现&lt;/h4&gt;MIND算法能够鲁棒地处理复杂的非流形表面，并在实验中显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;MIND算法为从UDFs中提取非流形网格提供了一种有效的方法，并展示了其在多种数据源生成UDFs上的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：无符号距离场（UDFs）因其能够表示任意拓扑形状而在3D深度学习中得到广泛应用。尽管先前的工作主要集中在从点云或多视图图像中学习UDFs，但从UDFs中提取网格仍然具有挑战性，因为学习到的场很少达到精确的零距离。一种常见的解决方案是从UDFs局部重建符号距离场（SDFs），以便通过Marching Cubes进行表面提取。然而，这通常会引入诸如空洞或虚假成分之类的拓扑错误。此外，局部SDFs本质上不能表示非流形几何，导致在这些情况下完全失败。为了解决这一差距，我们提出了MIND（从非流形距离场生成材料界面），这是一种直接从UDFs生成材料界面的新算法，从全局角度实现非流形网格提取。我们方法的核心在于从UDF推导出有意义的空间分区，目标表面作为不同区域的界面出现。我们首先计算一个双符号局部场以区分流形补丁的两面，然后扩展到能够分离非流形结构所有面的多标签全局场。通过将这个多标签场与输入的UDF结合，我们构建了通过多标签Marching Cubes算法支持非流形网格提取的材料界面。在来自点云重建、多视图重建和中心线变换的多种数据源生成的UDFs上进行的广泛实验表明，我们的方法能够鲁棒地处理复杂的非流形表面，并且在性能上显著优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsigned distance fields (UDFs) are widely used in 3D deep learning due totheir ability to represent shapes with arbitrary topology. While prior work haslargely focused on learning UDFs from point clouds or multi-view images,extracting meshes from UDFs remains challenging, as the learned fields rarelyattain exact zero distances. A common workaround is to reconstruct signeddistance fields (SDFs) locally from UDFs to enable surface extraction viaMarching Cubes. However, this often introduces topological artifacts such asholes or spurious components. Moreover, local SDFs are inherently incapable ofrepresenting non-manifold geometry, leading to complete failure in such cases.To address this gap, we propose MIND (Material Interface from Non-manifoldDistance fields), a novel algorithm for generating material interfaces directlyfrom UDFs, enabling non-manifold mesh extraction from a global perspective. Thecore of our method lies in deriving a meaningful spatial partitioning from theUDF, where the target surface emerges as the interface between distinctregions. We begin by computing a two-signed local field to distinguish the twosides of manifold patches, and then extend this to a multi-labeled global fieldcapable of separating all sides of a non-manifold structure. By combining thismulti-labeled field with the input UDF, we construct material interfaces thatsupport non-manifold mesh extraction via a multi-labeled Marching Cubesalgorithm. Extensive experiments on UDFs generated from diverse data sources,including point cloud reconstruction, multi-view reconstruction, and medialaxis transforms, demonstrate that our approach robustly handles complexnon-manifold surfaces and significantly outperforms existing methods.</description>
      <author>example@mail.com (Xuhui Chen, Fei Hou, Wencheng Wang, Hong Qin, Ying He)</author>
      <guid isPermaLink="false">2506.02938v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Towards Explicit Geometry-Reflectance Collaboration for Generalized LiDAR Segmentation in Adverse Weather</title>
      <link>http://arxiv.org/abs/2506.02396v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对LiDAR语义分割模型在恶劣天气条件下精度下降的问题，提出了一种新的几何-反射协作（GRC）框架，该框架能够有效提取场景的内在信息，提高模型的鲁棒性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的LiDAR语义分割模型在恶劣天气条件下往往精度下降，现有方法主要关注通过天气模拟或通用增强技术来增强训练数据，但很少有研究关注点云几何结构和反射强度中的异构域迁移带来的负面影响。&lt;h4&gt;目的&lt;/h4&gt;针对上述问题，本文旨在提出一种新的方法来提高LiDAR语义分割模型在恶劣天气条件下的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种名为GRC的框架，该框架采用双分支架构，分别处理几何和反射特征，并采用鲁棒的多级特征协作模块来抑制不必要和不准确的信息。&lt;h4&gt;主要发现&lt;/h4&gt;通过在具有挑战性的基准数据集上进行实验，本文的方法GRC在恶劣天气条件下优于现有方法，并取得了新的最先进的结果。&lt;h4&gt;结论&lt;/h4&gt;本文提出的GRC框架能够有效提高LiDAR语义分割模型在恶劣天气条件下的性能，为解决这一难题提供了一种新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing LiDAR semantic segmentation models often suffer from decreasedaccuracy when exposed to adverse weather conditions. Recent methods addressingthis issue focus on enhancing training data through weather simulation oruniversal augmentation techniques. However, few works have studied the negativeimpacts caused by the heterogeneous domain shifts in the geometric structureand reflectance intensity of point clouds. In this paper, we delve into thischallenge and address it with a novel Geometry-Reflectance Collaboration (GRC)framework that explicitly separates feature extraction for geometry andreflectance. Specifically, GRC employs a dual-branch architecture designed toindependently process geometric and reflectance features initially, therebycapitalizing on their distinct characteristic. Then, GRC adopts a robustmulti-level feature collaboration module to suppress redundant and unreliableinformation from both branches. Consequently, without complex simulation oraugmentation, our method effectively extracts intrinsic information about thescene while suppressing interference, thus achieving better robustness andgeneralization in adverse weather conditions. We demonstrate the effectivenessof GRC through comprehensive experiments on challenging benchmarks, showingthat our method outperforms previous approaches and establishes newstate-of-the-art results.</description>
      <author>example@mail.com (Longyu Yang, Ping Hu, Shangbo Yuan, Lu Zhang, Jun Liu, Hengtao Shen, Xiaofeng Zhu)</author>
      <guid isPermaLink="false">2506.02396v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>SAB3R: Semantic-Augmented Backbone in 3D Reconstruction</title>
      <link>http://arxiv.org/abs/2506.02112v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://uva-computer-vision-lab.github.io/sab3r/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为“地图与定位”的新任务，该任务结合了开放词汇分割和3D重建的目标，涉及从未定位的视频生成点云并根据开放词汇查询分割对象实例。&lt;h4&gt;背景&lt;/h4&gt;开放词汇分割和3D重建是两个传统上不同的目标，分别涉及自然语言查询检测和分割对象实例，以及从视觉输入估计场景的3D结构。&lt;h4&gt;目的&lt;/h4&gt;该任务作为迈向现实世界具身人工智能应用的关键步骤，引入了一个连接重建、识别和重组的实用任务。&lt;h4&gt;方法&lt;/h4&gt;提出了一个简单而有效的基线SAB3R，它基于MASt3R（3D计算机视觉的最新突破）并采用轻量级蒸馏策略，将2D视觉骨干网络（如CLIP和DINOv2）的密集、每像素语义特征转移到MASt3R上，以增强其能力。&lt;h4&gt;主要发现&lt;/h4&gt;SAB3R模型在地图与定位基准测试上实现了优于分别部署MASt3R和CLIP的性能，并且通过在2D语义分割和3D任务上的评估，全面验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;SAB3R模型在地图与定位任务上表现出色，为未来具身人工智能应用提供了有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;We introduce a new task, Map and Locate, which unifies the traditionally distinct objectives of open-vocabulary segmentation - detecting and segmenting object instances based on natural language queries - and 3D reconstruction, the process of estimating a scene's 3D structure from visual inputs. Specifically, Map and Locate involves generating a point cloud from an unposed video and segmenting object instances based on open-vocabulary queries. This task serves as a critical step toward real-world embodied AI applications and introduces a practical task that bridges reconstruction, recognition and reorganization. To tackle this task, we introduce a simple yet effective baseline, which we denote as SAB3R. Our approach builds upon MASt3R, a recent breakthrough in 3D computer vision, and incorporates a lightweight distillation strategy. This method transfers dense, per-pixel semantic features from 2D vision backbones (eg, CLIP and DINOv2) to enhance MASt3R's capabilities. Without introducing any auxiliary frozen networks, our model generates per-pixel semantic features and constructs cohesive point maps in a single forward pass. Compared to separately deploying MASt3R and CLIP, our unified model, SAB3R, achieves superior performance on the Map and Locate benchmark. Furthermore, we evaluate SAB3R on both 2D semantic segmentation and 3D tasks to comprehensively validate its effectiveness.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a new task, Map and Locate, which unifies the traditionallydistinct objectives of open-vocabulary segmentation - detecting and segmentingobject instances based on natural language queries - and 3D reconstruction, theprocess of estimating a scene's 3D structure from visual inputs. Specifically,Map and Locate involves generating a point cloud from an unposed video andsegmenting object instances based on open-vocabulary queries. This task servesas a critical step toward real-world embodied AI applications and introduces apractical task that bridges reconstruction, recognition and reorganization. Totackle this task, we introduce a simple yet effective baseline, which we denoteas SAB3R. Our approach builds upon MASt3R, a recent breakthrough in 3D computervision, and incorporates a lightweight distillation strategy. This methodtransfers dense, per-pixel semantic features from 2D vision backbones (eg, CLIPand DINOv2) to enhance MASt3R's capabilities. Without introducing any auxiliaryfrozen networks, our model generates per-pixel semantic features and constructscohesive point maps in a single forward pass. Compared to separately deployingMASt3R and CLIP, our unified model, SAB3R, achieves superior performance on theMap and Locate benchmark. Furthermore, we evaluate SAB3R on both 2D semanticsegmentation and 3D tasks to comprehensively validate its effectiveness.</description>
      <author>example@mail.com (Xuweiyi Chen, Tian Xia, Sihan Xu, Jianing Yang, Joyce Chai, Zezhou Cheng)</author>
      <guid isPermaLink="false">2506.02112v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised Latent Space Optimization with Nebula Variational Coding</title>
      <link>http://arxiv.org/abs/2506.01414v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种变分推断模型，通过引入额外的变量（称为星云锚点）来优化潜在流形，从而提升分类、分割、补全和/或重建的性能。该方法通过约束潜在特征形成高斯分布，形成了称为星云变分编码（NVC）的生成模型，并通过度量学习使聚类分离更加明显。&lt;h4&gt;背景&lt;/h4&gt;深度学习方法通过层次化的方式处理数据，并使用中间（或潜在）特征。目前的研究旨在通过概率模型优化潜在流形来提升分类、分割、补全和/或重建的性能。&lt;h4&gt;目的&lt;/h4&gt;设计一个通用的解决方案来优化潜在流形，以提升分类、分割、补全和/或重建的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种变分推断模型，引入星云锚点变量来引导潜在变量形成聚类，并使用变分约束防止锚点之间聚类。同时，通过度量学习以自监督的方式明确聚类之间的分离。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验证明，该方法可以应用于解决不同问题的不同架构，包括文本序列、图像、3D点云和体积数据，验证了所提方法的优势。&lt;h4&gt;结论&lt;/h4&gt;提出的NVC模型能够通过聚类适应训练数据的语义，如样本的类别标签，并在多种数据类型上表现出良好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TPAMI.2022.3160539&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning approaches process data in a layer-by-layer way withintermediate (or latent) features. We aim at designing a general solution tooptimize the latent manifolds to improve the performance on classification,segmentation, completion and/or reconstruction through probabilistic models.This paper proposes a variational inference model which leads to a clusteredembedding. We introduce additional variables in the latent space, called\textbf{nebula anchors}, that guide the latent variables to form clustersduring training. To prevent the anchors from clustering among themselves, weemploy the variational constraint that enforces the latent features within ananchor to form a Gaussian distribution, resulting in a generative model werefer as Nebula Variational Coding (NVC). Since each latent feature can belabeled with the closest anchor, we also propose to apply metric learning in aself-supervised way to make the separation between clusters more explicit. As aconsequence, the latent variables of our variational coder form clusters whichadapt to the generated semantic of the training data, \textit{e.g.} thecategorical labels of each sample. We demonstrate experimentally that it can beused within different architectures designed to solve different problemsincluding text sequence, images, 3D point clouds and volumetric data,validating the advantage of our proposed method.</description>
      <author>example@mail.com (Yida Wang, David Joseph Tan, Nassir Navab, Federico Tombari)</author>
      <guid isPermaLink="false">2506.01414v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>OG-VLA: 3D-Aware Vision Language Action Model via Orthographic Image Generation</title>
      <link>http://arxiv.org/abs/2506.01196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;OG-VLA是一种结合了视觉语言动作模型（VLAs）的泛化能力和3D感知策略的鲁棒性的新架构和学习框架。&lt;h4&gt;背景&lt;/h4&gt;现有的3D感知机器人策略在精确的机器人操作任务上表现优异，但在处理未见过的指令、场景和物体时泛化能力不足。而VLAs虽然在泛化指令和场景方面表现出色，但对相机和机器人姿态变化敏感。&lt;h4&gt;目的&lt;/h4&gt;解决将自然语言指令和多视图RGBD观察映射到准静态机器人动作的挑战，并提高3D感知关键帧策略的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;OG-VLA将输入观察从不同视角投影到点云，然后从标准正交投影图中渲染，确保输入视图不变性和输入输出空间之间的一致性。这些标准视图通过视觉骨干网络、大型语言模型（LLM）和图像扩散模型进行处理，生成编码了输入场景中末端执行器下一点位置和方向的图像。&lt;h4&gt;主要发现&lt;/h4&gt;在Arnold和Colosseum基准测试中，OG-VLA在未见过的环境中实现了最先进的泛化能力，相对于基准测试有超过40%的相对改进，同时在已见设置中保持了鲁棒的性能。&lt;h4&gt;结论&lt;/h4&gt;OG-VLA展示了在3到5个演示中的现实世界适应性以及强大的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;OG-VLA，一种新型架构和学习框架，结合了视觉语言动作模型（VLAs）的泛化能力与3D感知策略的鲁棒性。我们解决了将自然语言指令和多视图RGBD观察映射到准静态机器人动作的挑战。3D感知机器人策略在精确的机器人操作任务上取得了最先进的性能，但在处理未见过的指令、场景和物体时泛化能力有限。另一方面，VLAs在泛化指令和场景方面表现出色，但对相机和机器人姿态变化敏感。我们利用语言和视觉基础模型中嵌入的先验知识来提高3D感知关键帧策略的泛化能力。OG-VLA将输入观察从不同视角投影到点云，然后从标准正交投影图中渲染，确保输入视图不变性和输入输出空间之间的一致性。这些标准视图通过视觉骨干网络、大型语言模型（LLM）和图像扩散模型进行处理，生成编码了输入场景中末端执行器下一点位置和方向的图像。在Arnold和Colosseum基准测试中，OG-VLA在未见过的环境中实现了最先进的泛化能力，相对于基准测试有超过40%的相对改进，同时在已见设置中保持了鲁棒的性能。我们还展示了在3到5个演示中的现实世界适应性以及强大的泛化能力。更多信息请访问https://og-vla.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce OG-VLA, a novel architecture and learning framework thatcombines the generalization strengths of Vision Language Action models (VLAs)with the robustness of 3D-aware policies. We address the challenge of mappingnatural language instructions and multi-view RGBD observations to quasi-staticrobot actions. 3D-aware robot policies achieve state-of-the-art performance onprecise robot manipulation tasks, but struggle with generalization to unseeninstructions, scenes, and objects. On the other hand, VLAs excel atgeneralizing across instructions and scenes, but can be sensitive to camera androbot pose variations. We leverage prior knowledge embedded in language andvision foundation models to improve generalization of 3D-aware keyframepolicies. OG-VLA projects input observations from diverse views into a pointcloud which is then rendered from canonical orthographic views, ensuring inputview invariance and consistency between input and output spaces. Thesecanonical views are processed with a vision backbone, a Large Language Model(LLM), and an image diffusion model to generate images that encode the nextposition and orientation of the end-effector on the input scene. Evaluations onthe Arnold and Colosseum benchmarks demonstrate state-of-the-art generalizationto unseen environments, with over 40% relative improvements while maintainingrobust performance in seen settings. We also show real-world adaption in 3 to 5demonstrations along with strong generalization. Videos and resources athttps://og-vla.github.io/</description>
      <author>example@mail.com (Ishika Singh, Ankit Goyal, Stan Birchfield, Dieter Fox, Animesh Garg, Valts Blukis)</author>
      <guid isPermaLink="false">2506.01196v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>$\text{TREX}^2$: Dual-Reconstruction Framework for Teleoperated-Robot with EXtended Reality</title>
      <link>http://arxiv.org/abs/2506.01135v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了TREX^2，一个端到端、开源的XR遥操作框架，用于减少网络延迟和提高遥操作准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的XR遥操作系统存在运动到运动（M2M）延迟问题，导致遥操作误差和任务完成时间增加。&lt;h4&gt;目的&lt;/h4&gt;提出TREX^2框架，以解决现有系统的网络依赖性和延迟问题。&lt;h4&gt;方法&lt;/h4&gt;TREX^2通过本地感知数据重建延迟或缺失信息，同时实现XR和机器人并发运行，并采用竞争感知调度和带宽自适应点云缩放技术。&lt;h4&gt;主要发现&lt;/h4&gt;TREX^2在WLAN和蜂窝网络中分别将遥操作误差减少了69.8%和73.1%，同时将任务完成时间提高了47.7%，在真实世界任务中表现出色。&lt;h4&gt;结论&lt;/h4&gt;TREX^2显著提高了XR遥操作的准确性和效率，是现有框架的有效替代品。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robot teleoperation with extended reality (XR teleoperation) enablesintuitive interaction by allowing remote robots to mimic user motions withreal-time 3D feedback. However, existing systems face significantmotion-to-motion (M2M) latency -- the delay between the user's latest motionand the corresponding robot feedback -- leading to high teleoperation error andmission completion time. This issue stems from the system's exclusive relianceon network communication, making it highly vulnerable to network degradation.To address these challenges, we introduce $\text{TREX}^2$, the firstend-to-end, fully open-sourced XR teleoperation framework that decouples robotcontrol and XR visualization from network dependencies. $\text{TREX}^2$leverages local sensing data to reconstruct delayed or missing information ofthe counterpart, thereby significantly reducing network-induced issues. Thisapproach allows both the XR and robot to run concurrently with networktransmission while maintaining high robot planning accuracy. $\text{TREX}^2$also features contention-aware scheduling to mitigate GPU contention andbandwidth-adaptive point cloud scaling to cope with limited bandwidth. Weimplement $\text{TREX}^2$ across three hardware settings, including simulatedand physical robots, and evaluate it on 9,500 real-world teleoperation trialsfrom the RoboSet dataset \cite{kumar2024robohive}, covering single- andmulti-step missions. Compared to state-of-the-art XR teleoperation frameworks,$\text{TREX}^2$ reduces teleoperation error by up to 69.8% on WLAN and 73.1% oncellular networks with only 6.7% maximum runtime overhead. It also improvescompletion time by up to 47.7%, enabling smoother teleoperation. A real-worldcase study on ten stationary and mobile missions further shows $\text{TREX}^2$achieves up to 37.7% faster completion while lowering average teleoperationerror by up to 57.2%.</description>
      <author>example@mail.com (Ziliang Zhang, Cong Liu, Hyoseung Kim)</author>
      <guid isPermaLink="false">2506.01135v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>CountingFruit: Real-Time 3D Fruit Counting with Language-Guided Semantic Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.01109v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FruitLangGS的实时3D水果计数框架，用于解决实际农业环境中由于视觉遮挡、语义模糊和高计算需求而导致的精确水果计数难题。&lt;h4&gt;背景&lt;/h4&gt;精确水果计数在现实农业环境中是一个长期挑战，现有基于神经辐射场的计数方法存在推理速度慢、泛化能力有限和缺乏开放集语义控制支持等问题。&lt;h4&gt;目的&lt;/h4&gt;提出FruitLangGS框架，通过空间重建、语义嵌入和语言引导的实例估计来解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;FruitLangGS首先使用自适应高斯散点渲染管道，结合半径感知剪枝和基于瓦片的光栅化进行高效渲染。为了实现语义控制，每个高斯点编码一个压缩的CLIP对齐语言嵌入，形成紧凑且可查询的3D表示。在推理时，直接在3D空间中应用基于提示的语义过滤，而不依赖于图像空间分割或视级融合。然后通过分布感知采样将选定的高斯点转换为密集点云，并进行聚类以估计水果数量。&lt;h4&gt;主要发现&lt;/h4&gt;在真实果园数据上的实验结果表明，FruitLangGS相比先前方法实现了更高的渲染速度、语义灵活性和计数精度。&lt;h4&gt;结论&lt;/h4&gt;FruitLangGS为语言驱动的实时神经渲染在开放世界场景中提供了一个新的视角。&lt;h4&gt;翻译&lt;/h4&gt;Accurate fruit counting in real-world agricultural environments is a long-standing challenge due to visual occlusions, semantic ambiguity, and the high computational demands of 3D reconstruction. Existing methods based on neural radiance fields suffer from low inference speed, limited generalization, and lack support for open-set semantic control. This paper presents FruitLangGS, a real-time 3D fruit counting framework that addresses these limitations through spatial reconstruction, semantic embedding, and language-guided instance estimation. FruitLangGS first reconstructs orchard-scale scenes using an adaptive Gaussian splatting pipeline with radius-aware pruning and tile-based rasterization for efficient rendering. To enable semantic control, each Gaussian encodes a compressed CLIP-aligned language embedding, forming a compact and queryable 3D representation. At inference time, prompt-based semantic filtering is applied directly in 3D space, without relying on image-space segmentation or view-level fusion. The selected Gaussians are then converted into dense point clouds via distribution-aware sampling and clustered to estimate fruit counts. Experimental results on real orchard data demonstrate that FruitLangGS achieves higher rendering speed, semantic flexibility, and counting accuracy compared to prior approaches, offering a new perspective for language-driven, real-time neural rendering across open-world scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate fruit counting in real-world agricultural environments is alongstanding challenge due to visual occlusions, semantic ambiguity, and thehigh computational demands of 3D reconstruction. Existing methods based onneural radiance fields suffer from low inference speed, limited generalization,and lack support for open-set semantic control. This paper presentsFruitLangGS, a real-time 3D fruit counting framework that addresses theselimitations through spatial reconstruction, semantic embedding, andlanguage-guided instance estimation. FruitLangGS first reconstructsorchard-scale scenes using an adaptive Gaussian splatting pipeline withradius-aware pruning and tile-based rasterization for efficient rendering. Toenable semantic control, each Gaussian encodes a compressed CLIP-alignedlanguage embedding, forming a compact and queryable 3D representation. Atinference time, prompt-based semantic filtering is applied directly in 3Dspace, without relying on image-space segmentation or view-level fusion. Theselected Gaussians are then converted into dense point clouds viadistribution-aware sampling and clustered to estimate fruit counts.Experimental results on real orchard data demonstrate that FruitLangGS achieveshigher rendering speed, semantic flexibility, and counting accuracy compared toprior approaches, offering a new perspective for language-driven, real-timeneural rendering across open-world scenarios.</description>
      <author>example@mail.com (Fengze Li, Yangle Liu, Jieming Ma, Hai-Ning Liang, Yaochun Shen, Huangxiang Li, Zhijing Wu)</author>
      <guid isPermaLink="false">2506.01109v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Deformable registration and generative modelling of aortic anatomies by auto-decoders and neural ODEs</title>
      <link>http://arxiv.org/abs/2506.00947v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 7 figures, 6 tables, 2 algorithms. Submitted to "npj  Biological Physics and Mechanics". Dataset publicly available at  https://doi.org/10.5281/zenodo.15494901&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该工作介绍了AD-SVFD，一种用于血管形状变形配准到预定义参考以及生成合成解剖结构的深度学习模型。&lt;h4&gt;背景&lt;/h4&gt;AD-SVFD通过将每个几何形状表示为加权点云，并使用常微分方程（ODE）的解来建模环境空间变形。&lt;h4&gt;目的&lt;/h4&gt;AD-SVFD旨在实现血管形状的高精度变形配准，并能够生成新的解剖结构。&lt;h4&gt;方法&lt;/h4&gt;AD-SVFD通过最小化变形后的点云与参考点云之间的Chamfer距离来优化模型参数，并使用反向积分的ODE来定义逆变换。模型具有自动解码结构，可以在训练期间与网络参数联合优化，以实现形状群之间的泛化。&lt;h4&gt;主要发现&lt;/h4&gt;AD-SVFD能够通过低维代码实现自我条件化，在推理时仅微调潜在代码，显著降低计算开销。使用隐式形状表示可以合成新的解剖结构。&lt;h4&gt;结论&lt;/h4&gt;在健康主动脉解剖结构上的数值实验表明，AD-SVFD在具有竞争力的计算成本下产生了高质量的结果。&lt;h4&gt;翻译&lt;/h4&gt;This work introduces AD-SVFD, a deep learning model for the deformation registration of vascular shapes to a pre-defined reference and for the generation of synthetic anatomies. AD-SVFD operates by representing each geometry as a weighted point cloud and models ambient space deformations as solutions at unit time of ODEs, whose time-independent right-hand sides are expressed through artificial neural networks. The model parameters are optimized by minimizing the Chamfer Distance between the deformed and reference point clouds, while backward integration of the ODE defines the inverse transformation. A distinctive feature of AD-SVFD is its auto-decoder structure, that enables generalization across shape cohorts and favors efficient weight sharing. In particular, each anatomy is associated with a low-dimensional code that acts as a self-conditioning field and that is jointly optimized with the network parameters during training. At inference, only the latent codes are fine-tuned, substantially reducing computational overheads. Furthermore, the use of implicit shape representations enables generative applications: new anatomies can be synthesized by suitably sampling from the latent space and applying the corresponding inverse transformations to the reference geometry. Numerical experiments, conducted on healthy aortic anatomies, showcase the high-quality results of AD-SVFD, which yields extremely accurate approximations at competitive computational costs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work introduces AD-SVFD, a deep learning model for the deformableregistration of vascular shapes to a pre-defined reference and for thegeneration of synthetic anatomies. AD-SVFD operates by representing eachgeometry as a weighted point cloud and models ambient space deformations assolutions at unit time of ODEs, whose time-independent right-hand sides areexpressed through artificial neural networks. The model parameters areoptimized by minimizing the Chamfer Distance between the deformed and referencepoint clouds, while backward integration of the ODE defines the inversetransformation. A distinctive feature of AD-SVFD is its auto-decoder structure,that enables generalization across shape cohorts and favors efficient weightsharing. In particular, each anatomy is associated with a low-dimensional codethat acts as a self-conditioning field and that is jointly optimized with thenetwork parameters during training. At inference, only the latent codes arefine-tuned, substantially reducing computational overheads. Furthermore, theuse of implicit shape representations enables generative applications: newanatomies can be synthesized by suitably sampling from the latent space andapplying the corresponding inverse transformations to the reference geometry.Numerical experiments, conducted on healthy aortic anatomies, showcase thehigh-quality results of AD-SVFD, which yields extremely accurate approximationsat competitive computational costs.</description>
      <author>example@mail.com (Riccardo Tenderini, Luca Pegolotti, Fanwei Kong, Stefano Pagani, Francesco Regazzoni, Alison L. Marsden, Simone Deparis)</author>
      <guid isPermaLink="false">2506.00947v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Improving Multi-Vehicle Perception Fusion with Millimeter-Wave Radar Assistance</title>
      <link>http://arxiv.org/abs/2506.00837v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  to appear in IEEE INFOCOM 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为MMatch的轻量级系统，用于实现毫米波雷达点云的准确和实时感知融合，以提高自动驾驶的安全性。&lt;h4&gt;背景&lt;/h4&gt;合作感知是提高驾驶安全性的新范式，通过共享传感器读数来实现。实时且准确地对齐和融合感知是实现这一愿景的关键技术。&lt;h4&gt;目的&lt;/h4&gt;为了满足自动驾驶对精度、实时性和适应性的要求，提出了一种新的方法。&lt;h4&gt;方法&lt;/h4&gt;MMatch系统利用毫米波雷达提供的精细空间信息，这些信息与所有车辆都有独特的关联，即使在不同的视角中也是如此。通过捕捉和理解这种关联中目标的独特局部和全局位置，可以快速找到所有可见车辆进行视角对齐。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MMatch在59毫秒内实现了厘米级精度，显著提高了自动驾驶的可靠性。&lt;h4&gt;结论&lt;/h4&gt;MMatch是一种有效的轻量级系统，可以准确和实时地融合感知，有助于提高自动驾驶的安全性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cooperative perception enables vehicles to share sensor readings and hasbecome a new paradigm to improve driving safety, where the key enablingtechnology for realizing this vision is to real-time and accurately align andfuse the perceptions. Recent advances to align the views rely on high-densityLiDAR data or fine-grained image feature representations, which however fail tomeet the requirements of accuracy, real-time, and adaptability for autonomousdriving. To this end, we present MMatch, a lightweight system that enablesaccurate and real-time perception fusion with mmWave radar point clouds. Thekey insight is that fine-grained spatial information provided by the radarpresent unique associations with all the vehicles even in two separate views.As a result, by capturing and understanding the unique local and globalposition of the targets in this association, we can quickly find out all theco-visible vehicles for view alignment. We implement MMatch on both thedatasets collected from the CARLA platform and the real-world traffic with over15,000 radar point cloud pairs. Experimental results show that MMatch achievesdecimeter-level accuracy within 59ms, which significantly improves thereliability for autonomous driving.</description>
      <author>example@mail.com (Zhiqing Luo, Yi Wang, Yingying He, Wei Wang)</author>
      <guid isPermaLink="false">2506.00837v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Constrained Stein Variational Gradient Descent for Robot Perception, Planning, and Identification</title>
      <link>http://arxiv.org/abs/2506.00589v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出两种新的框架，将约束优化原理应用于新的变分推理算法Stein变分梯度下降，以解决机器人学中的多核问题。&lt;h4&gt;背景&lt;/h4&gt;机器人学中的多核问题常常涉及不确定性，或者需要找到多个高质量可行解。&lt;h4&gt;目的&lt;/h4&gt;设计框架以支持多种类型的约束优化器，并处理任意约束，以解决机器人学中的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种通用的框架，该框架可以处理多种类型的约束优化器，并能够处理任意约束。&lt;h4&gt;主要发现&lt;/h4&gt;在多种问题上展示了该框架的应用，包括学习近似分布而不违反约束，例如避免碰撞的机器人运动计划、具有精确桌面放置约束的机器人臂关节角度以及具有桌面放置约束的点云中的物体姿态。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架能够有效地应用于机器人学中的约束优化问题，并生成满足特定约束的高质量解。&lt;h4&gt;翻译&lt;/h4&gt;Many core problems in robotics can be framed as constrained optimization problems. Often on these problems, the robotic system has uncertainty, or it would be advantageous to identify multiple high quality feasible solutions. To enable this, we present two novel frameworks for applying principles of constrained optimization to the new variational inference algorithm Stein variational gradient descent. Our general framework supports multiple types of constrained optimizers and can handle arbitrary constraints. We demonstrate on a variety of problems that we are able to learn to approximate distributions without violating constraints. Specifically, we show that we can build distributions of: robot motion plans that exactly avoid collisions, robot arm joint angles on the SE(3) manifold with exact table placement constraints, and object poses from point clouds with table placement constraints.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many core problems in robotics can be framed as constrained optimizationproblems. Often on these problems, the robotic system has uncertainty, or itwould be advantageous to identify multiple high quality feasible solutions. Toenable this, we present two novel frameworks for applying principles ofconstrained optimization to the new variational inference algorithm Steinvariational gradient descent. Our general framework supports multiple types ofconstrained optimizers and can handle arbitrary constraints. We demonstrate ona variety of problems that we are able to learn to approximate distributionswithout violating constraints. Specifically, we show that we can builddistributions of: robot motion plans that exactly avoid collisions, robot armjoint angles on the SE(3) manifold with exact table placement constraints, andobject poses from point clouds with table placement constraints.</description>
      <author>example@mail.com (Griffin Tabor, Tucker Hermans)</author>
      <guid isPermaLink="false">2506.00589v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>ViVo: A Dataset for Volumetric VideoReconstruction and Compression</title>
      <link>http://arxiv.org/abs/2506.00558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的三维视频重建和压缩数据集ViVo，旨在解决现有数据集在内容和多样性方面的不足。&lt;h4&gt;背景&lt;/h4&gt;随着神经体积视频重建和压缩研究的发展，需要更多样化和真实的数据集来开发和验证模型。&lt;h4&gt;目的&lt;/h4&gt;提出ViVo数据集，以支持三维视频重建和压缩的研究。&lt;h4&gt;方法&lt;/h4&gt;ViVo数据集包含14对多视图RGB和深度视频，同步于30FPS，并附带每帧校准和音频数据，以及相应的2D前景掩码和3D点云。&lt;h4&gt;主要发现&lt;/h4&gt;ViVo数据集展示了现有数据集在体积视频重建和压缩任务中的局限性，并证明了该数据集的挑战性。&lt;h4&gt;结论&lt;/h4&gt;需要开发更有效的算法来应对体积视频重建和压缩任务。&lt;h4&gt;翻译&lt;/h4&gt;As research on neural volumetric video reconstruction and compression flourishes, there is a need for diverse and realistic datasets, which can be used to develop and validate reconstruction and compression models. However, existing volumetric video datasets lack diverse content in terms of both semantic and low-level features that are commonly present in real-world production pipelines. In this context, we propose a new dataset, ViVo, for VolumetrIc VideO reconstruction and compression. The dataset is faithful to real-world volumetric video production and is the first dataset to extend the definition of diversity to include both human-centric characteristics (skin, hair, etc.) and dynamic visual phenomena (transparent, reflective, liquid, etc.). Each video sequence in this database contains raw data including fourteen multi-view RGB and depth video pairs, synchronized at 30FPS with per-frame calibration and audio data, and their associated 2-D foreground masks and 3-D point clouds. To demonstrate the use of this database, we have benchmarked three state-of-the-art (SotA) 3-D reconstruction methods and two volumetric video compression algorithms. The obtained results evidence the challenging nature of the proposed dataset and the limitations of existing datasets for both volumetric video reconstruction and compression tasks, highlighting the need to develop more effective algorithms for these applications. The database and the associated results are available at https://vivo-bvicr.github.io/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As research on neural volumetric video reconstruction and compressionflourishes, there is a need for diverse and realistic datasets, which can beused to develop and validate reconstruction and compression models. However,existing volumetric video datasets lack diverse content in terms of bothsemantic and low-level features that are commonly present in real-worldproduction pipelines. In this context, we propose a new dataset, ViVo, forVolumetrIc VideO reconstruction and compression. The dataset is faithful toreal-world volumetric video production and is the first dataset to extend thedefinition of diversity to include both human-centric characteristics (skin,hair, etc.) and dynamic visual phenomena (transparent, reflective, liquid,etc.). Each video sequence in this database contains raw data includingfourteen multi-view RGB and depth video pairs, synchronized at 30FPS withper-frame calibration and audio data, and their associated 2-D foreground masksand 3-D point clouds. To demonstrate the use of this database, we havebenchmarked three state-of-the-art (SotA) 3-D reconstruction methods and twovolumetric video compression algorithms. The obtained results evidence thechallenging nature of the proposed dataset and the limitations of existingdatasets for both volumetric video reconstruction and compression tasks,highlighting the need to develop more effective algorithms for theseapplications. The database and the associated results are available athttps://vivo-bvicr.github.io/</description>
      <author>example@mail.com (Adrian Azzarelli, Ge Gao, Ho Man Kwan, Fan Zhang, Nantheera Anantrasirichai, Ollie Moolan-Feroze, David Bull)</author>
      <guid isPermaLink="false">2506.00558v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>BAGNet: A Boundary-Aware Graph Attention Network for 3D Point Cloud Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2506.00475v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by the 2025 International Joint Conference on Neural  Networks (IJCNN 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Boundary-Aware Graph attention Network (BAGNet)的新型图注意力网络，用于点云语义分割，旨在减少计算成本并提高分割精度。&lt;h4&gt;背景&lt;/h4&gt;点云数据因其不规则和不结构化而具有挑战性，传统的基于图的方法虽然能建模点云，但计算成本高。&lt;h4&gt;目的&lt;/h4&gt;降低计算成本，同时提高点云语义分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;BAGNet包含一个边界感知图注意力层（BAGLayer），它通过边缘顶点融合和注意力系数来捕捉边界点的特征，并使用轻量级的注意力池化层提取点云的全局特征。&lt;h4&gt;主要发现&lt;/h4&gt;边界点具有更复杂的空间结构信息，BAGNet在标准数据集上的实验结果表明，其性能优于现有方法，具有更高的准确率和更少的推理时间。&lt;h4&gt;结论&lt;/h4&gt;BAGNet是一种有效的点云语义分割方法，能够在保证准确性的同时减少计算成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Since the point cloud data is inherently irregular and unstructured, pointcloud semantic segmentation has always been a challenging task. The graph-basedmethod attempts to model the irregular point cloud by representing it as agraph; however, this approach incurs substantial computational cost due to thenecessity of constructing a graph for every point within a large-scale pointcloud. In this paper, we observe that boundary points possess more intricatespatial structural information and develop a novel graph attention networkknown as the Boundary-Aware Graph attention Network (BAGNet). On one hand,BAGNet contains a boundary-aware graph attention layer (BAGLayer), whichemploys edge vertex fusion and attention coefficients to capture features ofboundary points, reducing the computation time. On the other hand, BAGNetemploys a lightweight attention pooling layer to extract the global feature ofthe point cloud to maintain model accuracy. Extensive experiments on standarddatasets demonstrate that BAGNet outperforms state-of-the-art methods in pointcloud semantic segmentation with higher accuracy and less inference time.</description>
      <author>example@mail.com (Wei Tao, Xiaoyang Qu, Kai Lu, Jiguang Wan, Shenglin He, Jianzong Wang)</author>
      <guid isPermaLink="false">2506.00475v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>PointODE: Lightweight Point Cloud Learning with Neural Ordinary Differential Equations on Edge</title>
      <link>http://arxiv.org/abs/2506.00438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PointODE的参数高效的ResNet-like架构，用于点云特征提取，并通过Neural ODE技术压缩参数，以提高边缘设备的性能。&lt;h4&gt;背景&lt;/h4&gt;嵌入式边缘设备常用于运行现实世界的点云应用，但深度学习方法可能因资源限制而无法在这些设备上运行。&lt;h4&gt;目的&lt;/h4&gt;填补深度学习方法在边缘设备上应用的空白。&lt;h4&gt;方法&lt;/h4&gt;引入PointODE，一种基于堆叠MLP块和残差连接的参数高效ResNet-like架构；利用Neural ODE技术压缩PointODE；提出点对齐归一化方法以处理特征点的非均匀分布；设计PointODE-Elite的轻量级版本，并为其设计专用加速器。&lt;h4&gt;主要发现&lt;/h4&gt;PointODE-Elite具有0.58M可训练参数，并设计有专门的FPGA加速器，实现多点特征提取的并行化，并存储所有参数于芯片上以减少外部数据传输。与ARM Cortex-A53 CPU相比，PointODE-Elite的加速器在Xilinx ZCU104板上加速了4.9倍的特征提取，提高了3.7倍的推理速度和3.5倍的能效。&lt;h4&gt;结论&lt;/h4&gt;尽管架构简单，PointODE-Elite在合成数据和真实世界分类数据集上表现出与最先进模型相媲美的准确性，大大提高了准确性与推理成本之间的权衡。&lt;h4&gt;翻译&lt;/h4&gt;摘要：嵌入式边缘设备通常用作运行现实世界点云应用的计算平台，但基于深度学习的新方法可能由于资源限制而无法适应此类设备。在本文中，我们通过引入PointODE，一种基于堆叠MLP块和残差连接的参数高效的ResNet-like架构，旨在填充这一空白。我们利用Neural ODE（常微分方程），ResNet的一种连续深度版本，最初是为建模连续时间系统的动力学而开发的，通过在MLP块之间重用相同的参数来压缩PointODE。为了处理特征点的非均匀分布，我们为PointODE提出了点对齐归一化。我们引入了PointODE-Elite作为轻量级版本，具有0.58M个可训练参数，并为其设计了一个用于嵌入式FPGA的专用加速器。该加速器由一个四阶段流水线组成，以并行化多个点的特征提取，并将所有参数存储在芯片上以消除大部分外部数据传输。与ARM Cortex-A53 CPU相比，在Xilinx ZCU104板上实现的加速器将特征提取速度提高了4.9倍，实现了3.7倍的推理速度和3.5倍的能效。尽管架构简单，PointODE-Elite在合成数据和真实世界分类数据集上与最先进的模型表现出竞争力，大大提高了准确性和推理成本之间的权衡。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Embedded edge devices are often used as a computing platform to runreal-world point cloud applications, but recent deep learning-based methods maynot fit on such devices due to limited resources. In this paper, we aim to fillthis gap by introducing PointODE, a parameter-efficient ResNet-likearchitecture for point cloud feature extraction based on a stack of MLP blockswith residual connections. We leverage Neural ODE (Ordinary DifferentialEquation), a continuous-depth version of ResNet originally developed formodeling the dynamics of continuous-time systems, to compress PointODE byreusing the same parameters across MLP blocks. The point-wise normalization isproposed for PointODE to handle the non-uniform distribution of feature points.We introduce PointODE-Elite as a lightweight version with 0.58M trainableparameters and design its dedicated accelerator for embedded FPGAs. Theaccelerator consists of a four-stage pipeline to parallelize the featureextraction for multiple points and stores the entire parameters on-chip toeliminate most of the off-chip data transfers. Compared to the ARM Cortex-A53CPU, the accelerator implemented on a Xilinx ZCU104 board speeds up the featureextraction by 4.9x, leading to 3.7x faster inference and 3.5x betterenergy-efficiency. Despite the simple architecture, PointODE-Elite showscompetitive accuracy to the state-of-the-art models on both synthetic andreal-world classification datasets, greatly improving the trade-off betweenaccuracy and inference cost.</description>
      <author>example@mail.com (Keisuke Sugiura, Mizuki Yasuda, Hiroki Matsutani)</author>
      <guid isPermaLink="false">2506.00438v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Voxelization for Transform coding of 3D Gaussian splatting data</title>
      <link>http://arxiv.org/abs/2506.00271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对3D高斯细分（3DGS）数据的压缩框架，该框架利用了最初为点云开发的变换编码工具。与现有的3DGS压缩方法不同，该方法能够在计算效率高的方式下以多个比特率生成压缩的3DGS模型。&lt;h4&gt;背景&lt;/h4&gt;点云体素化是一种离散化技术，点云编解码器使用它来提高编码效率，同时允许使用快速的变换编码算法。&lt;h4&gt;目的&lt;/h4&gt;提出一种自适应体素化算法，专门针对3DGS数据，以避免点云编解码器中使用的均匀体素化带来的低效。&lt;h4&gt;方法&lt;/h4&gt;确保较大体积的高斯位置以高分辨率表示，因为这些对渲染质量有显著影响。同时，对于密集区域中的较小高斯，使用低分辨率表示，这些对渲染质量的影响相对较低。这种自适应体素化方法显著减少了编码3DGS数据所需的高斯数量和比特率。体素化后，许多高斯被移动或消除。因此，提出了一种微调/重新着色剩余3DGS属性的方法，该方法可以通过初始化来减少所需的再训练量。&lt;h4&gt;主要发现&lt;/h4&gt;在预训练数据集上的实验结果表明，所提出的压缩框架优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的压缩框架能够高效地压缩3DGS数据，并且提供了优于现有方法的性能。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种针对3D高斯细分（3DGS）数据的压缩框架，该框架利用了最初为点云开发的变换编码工具。与现有的3DGS压缩方法不同，该方法能够在计算效率高的方式下以多个比特率生成压缩的3DGS模型。点云体素化是一种离散化技术，点云编解码器使用它来提高编码效率，同时允许使用快速的变换编码算法。提出了一种自适应体素化算法，专门针对3DGS数据，以避免点云编解码器中使用的均匀体素化带来的低效。确保较大体积的高斯位置以高分辨率表示，因为这些对渲染质量有显著影响。同时，对于密集区域中的较小高斯，使用低分辨率表示，这些对渲染质量的影响相对较低。这种自适应体素化方法显著减少了编码3DGS数据所需的高斯数量和比特率。体素化后，许多高斯被移动或消除。因此，提出了一种微调/重新着色剩余3DGS属性的方法，该方法可以通过初始化来减少所需的再训练量。在预训练数据集上的实验结果表明，所提出的压缩框架优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel compression framework for 3D Gaussian splatting (3DGS)data that leverages transform coding tools originally developed for pointclouds. Contrary to existing 3DGS compression methods, our approach can producecompressed 3DGS models at multiple bitrates in a computationally efficient way.Point cloud voxelization is a discretization technique that point cloud codecsuse to improve coding efficiency while enabling the use of fast transformcoding algorithms. We propose an adaptive voxelization algorithm tailored to3DGS data, to avoid the inefficiencies introduced by uniform voxelization usedin point cloud codecs. We ensure the positions of larger volume Gaussians arerepresented at high resolution, as these significantly impact renderingquality. Meanwhile, a low-resolution representation is used for dense regionswith smaller Gaussians, which have a relatively lower impact on renderingquality. This adaptive voxelization approach significantly reduces the numberof Gaussians and the bitrate required to encode the 3DGS data. Aftervoxelization, many Gaussians are moved or eliminated. Thus, we propose tofine-tune/recolor the remaining 3DGS attributes with an initialization that canreduce the amount of retraining required. Experimental results on pre-traineddatasets show that our proposed compression framework outperforms existingmethods.</description>
      <author>example@mail.com (Chenjunjie Wang, Shashank N. Sridhara, Eduardo Pavez, Antonio Ortega, Cheng Chang)</author>
      <guid isPermaLink="false">2506.00271v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>End-to-End Framework for Predicting the Remaining Useful Life of Lithium-Ion Batteries</title>
      <link>http://arxiv.org/abs/2505.16664v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的剩余使用寿命（RUL）预测方法，旨在提高锂离子电池的维护效率。&lt;h4&gt;背景&lt;/h4&gt;准确预测锂离子电池的RUL对于及时维护和保障电动汽车等应用的运营效率至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的RUL预测方法，通过分析最近充放电循环数据来估计剩余可用循环次数。&lt;h4&gt;方法&lt;/h4&gt;该方法包括一个新颖的信号处理流程和一个深度学习预测模型。信号处理流程中，计算了基于电流和容量信号的导出容量特征。在预测模型中，使用一维卷积神经网络（CNN）、注意力长短期记忆（A-LSTM）和基于常微分方程的LSTM（ODE-LSTM）块组成的混合深度学习架构。&lt;h4&gt;主要发现&lt;/h4&gt;模型在跨不同学习策略和目标数据划分场景的迁移学习中被评估，结果表明模型在有限目标数据上微调时仍保持稳健的性能。在两个公开的大型数据集上的实验结果表明，该方法优于基线深度学习方法和机器学习技术，RMSE为101.59。&lt;h4&gt;结论&lt;/h4&gt;该方法具有强大的实际RUL预测应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction of the Remaining Useful Life (RUL) is essential forenabling timely maintenance of lithium-ion batteries, impacting the operationalefficiency of electric applications that rely on them. This paper proposes aRUL prediction approach that leverages data from recent charge-discharge cyclesto estimate the number of remaining usable cycles. The approach introduces botha novel signal processing pipeline and a deep learning prediction model. In thesignal preprocessing pipeline, a derived capacity feature $\dot{Q}(I, Q)$ iscomputed based on current and capacity signals. Alongside original capacity,voltage and current, these features are denoised and enhanced using statisticalmetrics and a delta-based method to capture differences between the current andprevious cycles. In the prediction model, the processed features are then fedinto a hybrid deep learning architecture composed of 1D Convolutional NeuralNetworks (CNN), Attentional Long Short-Term Memory (A-LSTM), and OrdinaryDifferential Equation-based LSTM (ODE-LSTM) blocks. This architecture isdesigned to capture both local signal characteristics and long-range temporaldependencies while modeling the continuous-time dynamics of batterydegradation. The model is further evaluated using transfer learning acrossdifferent learning strategies and target data partitioning scenarios. Resultsindicate that the model maintains robust performance, even when fine-tuned onlimited target data. Experimental results on two publicly available large-scaledatasets demonstrate that the proposed method outperforms a baseline deeplearning approach and machine learning techniques, achieving an RMSE of 101.59,highlighting its strong potential for real-world RUL prediction applications.</description>
      <author>example@mail.com (Khoa Tran, Tri Le, Bao Huynh, Hung-Cuong Trinh, Vy-Rin Nguyen)</author>
      <guid isPermaLink="false">2505.16664v2</guid>
      <pubDate>Tue, 03 Jun 2025 14:06:17 +0800</pubDate>
    </item>
  <item>
      <title>NUC-Net: Non-uniform Cylindrical Partition Network for Efficient LiDAR Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2505.24634v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at TCSVT in 2025.Code available at  https://github.com/alanWXZ/NUC-Net&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NUC-Net的非均匀圆柱分割网络，用于解决现有LiDAR语义分割方法的问题，包括计算成本高和内存消耗大，以及未很好地处理LiDAR点云的不平衡分布。&lt;h4&gt;背景&lt;/h4&gt;LiDAR语义分割在自动驾驶中扮演着重要角色，现有的基于体素的方法通过均匀分割3D LiDAR点云来形成基于笛卡尔/圆柱坐标的结构化表示。&lt;h4&gt;目的&lt;/h4&gt;提出NUC-Net以解决现有方法的缺点，包括降低计算成本和内存消耗，以及更好地处理点云的不平衡分布。&lt;h4&gt;方法&lt;/h4&gt;NUC-Net采用API方法非均匀分割径向轴，并生成具有代表性的体素表示。此外，还提出了一种非均匀多尺度聚合方法来提高上下文信息。&lt;h4&gt;主要发现&lt;/h4&gt;NUC-Net在SemanticKITTI和nuScenes数据集上实现了最先进的性能，具有更快的速度和更少的训练时间。该方法可以作为一个通用的LiDAR语义分割组件，通过4倍的训练速度、2倍的GPU内存减少和3倍的推理速度提升，显著提高了均匀方法的准确性和效率。&lt;h4&gt;结论&lt;/h4&gt;NUC-Net通过理论分析验证了其有效性，并探讨了点分布对性能的影响。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: LiDAR semantic segmentation plays a vital role in autonomous driving. Existing voxel-based methods for LiDAR semantic segmentation apply uniform partition to the 3D LiDAR point cloud to form a structured representation based on cartesian/cylindrical coordinates. Although these methods show impressive performance, the drawback of existing voxel-based methods remains in two aspects: (1) it requires a large enough input voxel resolution, which brings a large amount of computation cost and memory consumption. (2) it does not well handle the unbalanced point distribution of LiDAR point cloud. In this paper, we propose a non-uniform cylindrical partition network named NUC-Net to tackle the above challenges. Specifically, we propose the Arithmetic Progression of Interval (API) method to non-uniformly partition the radial axis and generate the voxel representation which is representative and efficient. Moreover, we propose a non-uniform multi-scale aggregation method to improve contextual information. Our method achieves state-of-the-art performance on SemanticKITTI and nuScenes datasets with much faster speed and much less training time. And our method can be a general component for LiDAR semantic segmentation, which significantly improves both the accuracy and efficiency of the uniform counterpart by 4 times faster training, 2 times GPU memory reduction, and 3 times inference speedup. We further provide theoretical analysis towards understanding why NUC is effective and how point distribution affects performance. Code is available at https://github.com/alanWXZ/NUC-Net.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TCSVT.2025.3554182&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR semantic segmentation plays a vital role in autonomous driving.Existing voxel-based methods for LiDAR semantic segmentation apply uniformpartition to the 3D LiDAR point cloud to form a structured representation basedon cartesian/cylindrical coordinates. Although these methods show impressiveperformance, the drawback of existing voxel-based methods remains in twoaspects: (1) it requires a large enough input voxel resolution, which brings alarge amount of computation cost and memory consumption. (2) it does not wellhandle the unbalanced point distribution of LiDAR point cloud. In this paper,we propose a non-uniform cylindrical partition network named NUC-Net to tacklethe above challenges. Specifically, we propose the Arithmetic Progression ofInterval (API) method to non-uniformly partition the radial axis and generatethe voxel representation which is representative and efficient. Moreover, wepropose a non-uniform multi-scale aggregation method to improve contextualinformation. Our method achieves state-of-the-art performance on SemanticKITTIand nuScenes datasets with much faster speed and much less training time. Andour method can be a general component for LiDAR semantic segmentation, whichsignificantly improves both the accuracy and efficiency of the uniformcounterpart by $4 \times$ training faster and $2 \times$ GPU memory reductionand $3 \times$ inference speedup. We further provide theoretical analysistowards understanding why NUC is effective and how point distribution affectsperformance. Code is available at\href{https://github.com/alanWXZ/NUC-Net}{https://github.com/alanWXZ/NUC-Net}.</description>
      <author>example@mail.com (Xuzhi Wang, Wei Feng, Lingdong Kong, Liang Wan)</author>
      <guid isPermaLink="false">2505.24634v2</guid>
      <pubDate>Tue, 03 Jun 2025 14:06:17 +0800</pubDate>
    </item>
    <item>
      <title>Pre-Training and Personalized Fine-Tuning via Over-the-Air Federated Meta-Learning: Convergence-Generalization Trade-Offs</title>
      <link>http://arxiv.org/abs/2406.11569v4</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  39 pages, 8 figures, submitted for possible journal publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于元学习的个性化联邦学习（meta-pFL）在无线设置下的泛化性能，探讨了在新的代理和任务上泛化与收敛之间的权衡。&lt;h4&gt;背景&lt;/h4&gt;现代人工智能应用如大型语言模型（LLMs）的训练范式已从预训练转向预训练后微调。由于公开数据仓库的减少和AI模型访问的民主化努力，预训练预计将越来越多地从当前集中式部署迁移到联邦学习（FL）实现。&lt;h4&gt;目的&lt;/h4&gt;研究meta-pFL在无线设置下的泛化性能，特别是当参与预训练阶段的代理通过共享无线信道与服务器连接时。&lt;h4&gt;方法&lt;/h4&gt;采用空中计算，研究了对新代理和任务的泛化与收敛之间的权衡。&lt;h4&gt;主要发现&lt;/h4&gt;权衡源于信道损坏可能增强泛化，同时降低收敛。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的数值结果验证了理论。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For modern artificial intelligence (AI) applications such as large languagemodels (LLMs), the training paradigm has recently shifted to pre-trainingfollowed by fine-tuning. Furthermore, owing to dwindling open repositories ofdata and thanks to efforts to democratize access to AI models, pre-training isexpected to increasingly migrate from the current centralized deployments tofederated learning (FL) implementations. Meta-learning provides a generalframework in which pre-training and fine-tuning can be formalized.Meta-learning-based personalized FL (meta-pFL) moves beyond basicpersonalization by targeting generalization to new agents and tasks. This paperstudies the generalization performance of meta-pFL for a wireless setting inwhich the agents participating in the pre-training phase, i.e., meta-learning,are connected via a shared wireless channel to the server. Adoptingover-the-air computing, we study the trade-off between generalization to newagents and tasks, on the one hand, and convergence, on the other hand. Thetrade-off arises from the fact that channel impairments may enhancegeneralization, while degrading convergence. Extensive numerical resultsvalidate the theory.</description>
      <author>example@mail.com (Haifeng Wen, Hong Xing, Osvaldo Simeone)</author>
      <guid isPermaLink="false">2406.11569v4</guid>
      <pubDate>Tue, 03 Jun 2025 14:06:17 +0800</pubDate>
    </item>
    <item>
      <title>VLM-3R: Vision-Language Models Augmented with Instruction-Aligned 3D Reconstruction</title>
      <link>http://arxiv.org/abs/2505.20279v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://vlm-3r.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为VLM-3R的统一框架，用于视觉语言模型，它通过3D重建指令调整来处理单目视频帧，实现3D场景的理解。&lt;h4&gt;背景&lt;/h4&gt;随着大型多模态模型在2D图像和视频领域的快速发展，研究者们开始将这些模型扩展到3D场景的理解，以实现类似人类的视觉空间智能。然而，在模型编码和数据获取方面，达到与人类相当的空间理解能力存在重大挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在通过VLM-3R框架，实现单目视频帧的3D空间理解和时空推理，并提高模型的准确性和可扩展性。&lt;h4&gt;方法&lt;/h4&gt;VLM-3R使用几何编码器推导出隐式的3D标记，以表示空间理解。通过空间-视觉-视图融合和超过200K个精心制作的3D重建指令调整问答对，VLM-3R能够有效地将现实世界的空间环境与语言指令对齐。&lt;h4&gt;主要发现&lt;/h4&gt;VLM-3R不仅促进了稳健的视觉空间推理，还实现了对时空3D环境变化的理解，在准确性和可扩展性方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;VLM-3R模型为理解和推理3D场景提供了新的方法，对于时间敏感的应用和单目视频输入具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;The rapid advancement of Large Multimodal Models (LMMs) for 2D images and videos has motivated extending these models to understand 3D scenes, aiming for human-like visual-spatial intelligence. Nevertheless, achieving deep spatial understanding comparable to human capabilities poses significant challenges in model encoding and data acquisition. Existing methods frequently depend on external depth sensors for geometry capture or utilize off-the-shelf algorithms for pre-constructing 3D maps, thereby limiting their scalability, especially with prevalent monocular video inputs and for time-sensitive applications. In this work, we introduce VLM-3R, a unified framework for Vision-Language Models (VLMs) that incorporates 3D Reconstructive instruction tuning. VLM-3R processes monocular video frames by employing a geometry encoder to derive implicit 3D tokens that represent spatial understanding. Leveraging our Spatial-Visual-View Fusion and over 200K curated 3D reconstructive instruction tuning question-answer (QA) pairs, VLM-3R effectively aligns real-world spatial context with language instructions. This enables monocular 3D spatial assistance and embodied reasoning. To facilitate the evaluation of temporal reasoning, we introduce the Vision-Spatial-Temporal Intelligence benchmark, featuring over 138.6K QA pairs across five distinct tasks focused on evolving spatial relationships. Extensive experiments demonstrate that our model, VLM-3R, not only facilitates robust visual-spatial reasoning but also enables the understanding of temporal 3D context changes, excelling in both accuracy and scalability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/VITA-Group/VLM-3R&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of Large Multimodal Models (LMMs) for 2D images andvideos has motivated extending these models to understand 3D scenes, aiming forhuman-like visual-spatial intelligence. Nevertheless, achieving deep spatialunderstanding comparable to human capabilities poses significant challenges inmodel encoding and data acquisition. Existing methods frequently depend onexternal depth sensors for geometry capture or utilize off-the-shelf algorithmsfor pre-constructing 3D maps, thereby limiting their scalability, especiallywith prevalent monocular video inputs and for time-sensitive applications. Inthis work, we introduce VLM-3R, a unified framework for Vision-Language Models(VLMs) that incorporates 3D Reconstructive instruction tuning. VLM-3R processesmonocular video frames by employing a geometry encoder to derive implicit 3Dtokens that represent spatial understanding. Leveraging our Spatial-Visual-ViewFusion and over 200K curated 3D reconstructive instruction tuningquestion-answer (QA) pairs, VLM-3R effectively aligns real-world spatialcontext with language instructions. This enables monocular 3D spatialassistance and embodied reasoning. To facilitate the evaluation of temporalreasoning, we introduce the Vision-Spatial-Temporal Intelligence benchmark,featuring over 138.6K QA pairs across five distinct tasks focused on evolvingspatial relationships. Extensive experiments demonstrate that our model,VLM-3R, not only facilitates robust visual-spatial reasoning but also enablesthe understanding of temporal 3D context changes, excelling in both accuracyand scalability.</description>
      <author>example@mail.com (Zhiwen Fan, Jian Zhang, Renjie Li, Junge Zhang, Runjin Chen, Hezhen Hu, Kevin Wang, Huaizhi Qu, Dilin Wang, Zhicheng Yan, Hongyu Xu, Justin Theiss, Tianlong Chen, Jiachen Li, Zhengzhong Tu, Zhangyang Wang, Rakesh Ranjan)</author>
      <guid isPermaLink="false">2505.20279v2</guid>
      <pubDate>Tue, 03 Jun 2025 14:06:17 +0800</pubDate>
    </item>
    <item>
      <title>SpeechVerifier: Robust Acoustic Fingerprint against Tampering Attacks via Watermarking</title>
      <link>http://arxiv.org/abs/2505.23821v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SpeechVerifier，一种基于发布语音本身来主动验证语音完整性的方法，以应对社交媒体时代恶意篡改公共演讲的问题。&lt;h4&gt;背景&lt;/h4&gt;社交媒体的兴起导致恶意篡改的公共演讲，尤其是有影响力的人物演讲，严重影响了社会稳定和公众信任。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有语音篡改检测方法不足的问题，即依赖外部参考数据或对攻击敏感但对良性操作（如压缩和重采样）不够鲁棒。&lt;h4&gt;方法&lt;/h4&gt;SpeechVerifier通过多尺度特征提取捕捉不同时间分辨率的语音特征，并使用对比学习生成指纹来检测不同粒度的修改。这些指纹设计为对良性操作鲁棒，但在恶意篡改时会发生显著变化。指纹通过段式水印嵌入到语音信号中，以便在没有外部参考的情况下进行语音验证。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SpeechVerifier在检测篡改攻击方面有效，并且对良性操作具有鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;SpeechVerifier是一种有效的语音完整性验证工具，可以有效地检测篡改攻击并抵抗良性操作。&lt;h4&gt;翻译&lt;/h4&gt;With the surge of social media, maliciously tampered public speeches, especially those from influential figures, have seriously affected social stability and public trust. Existing speech tampering detection methods remain insufficient: they either rely on external reference data or fail to be both sensitive to attacks and robust to benign operations, such as compression and resampling. To tackle these challenges, we introduce SpeechVerifer to proactively verify speech integrity using only the published speech itself, i.e., without requiring any external references. Inspired by audio fingerprinting and watermarking, SpeechVerifier can (i) effectively detect tampering attacks, (ii) be robust to benign operations and (iii) verify the integrity only based on published speeches. Briefly, SpeechVerifier utilizes multiscale feature extraction to capture speech features across different temporal resolutions. Then, it employs contrastive learning to generate fingerprints that can detect modifications at varying granularities. These fingerprints are designed to be robust to benign operations, but exhibit significant changes when malicious tampering occurs. To enable speech verification in a self-contained manner, the generated fingerprints are then embedded into the speech signal by segment-wise watermarking. Without external references, SpeechVerifier can retrieve the fingerprint from the published audio and check it with the embedded watermark to verify the integrity of the speech. Extensive experimental results demonstrate that the proposed SpeechVerifier is effective in detecting tampering attacks and robust to benign operations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the surge of social media, maliciously tampered public speeches,especially those from influential figures, have seriously affected socialstability and public trust. Existing speech tampering detection methods remaininsufficient: they either rely on external reference data or fail to be bothsensitive to attacks and robust to benign operations, such as compression andresampling. To tackle these challenges, we introduce SpeechVerifer toproactively verify speech integrity using only the published speech itself,i.e., without requiring any external references. Inspired by audiofingerprinting and watermarking, SpeechVerifier can (i) effectively detecttampering attacks, (ii) be robust to benign operations and (iii) verify theintegrity only based on published speeches. Briefly, SpeechVerifier utilizesmultiscale feature extraction to capture speech features across differenttemporal resolutions. Then, it employs contrastive learning to generatefingerprints that can detect modifications at varying granularities. Thesefingerprints are designed to be robust to benign operations, but exhibitsignificant changes when malicious tampering occurs. To enable speechverification in a self-contained manner, the generated fingerprints are thenembedded into the speech signal by segment-wise watermarking. Without externalreferences, SpeechVerifier can retrieve the fingerprint from the publishedaudio and check it with the embedded watermark to verify the integrity of thespeech. Extensive experimental results demonstrate that the proposedSpeechVerifier is effective in detecting tampering attacks and robust to benignoperations.</description>
      <author>example@mail.com (Lingfeng Yao, Chenpei Huang, Shengyao Wang, Junpei Xue, Hanqing Guo, Jiang Liu, Xun Chen, Miao Pan)</author>
      <guid isPermaLink="false">2505.23821v2</guid>
      <pubDate>Tue, 03 Jun 2025 14:06:17 +0800</pubDate>
    </item>
    <item>
      <title>Dual-Task Graph Neural Network for Joint Seizure Onset Zone Localization and Outcome Prediction using Stereo EEG</title>
      <link>http://arxiv.org/abs/2505.23669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了一种基于sEEG记录的图神经网络框架，用于预测耐药性癫痫患者的无发作结果并定位癫痫起源区。&lt;h4&gt;背景&lt;/h4&gt;癫痫患者手术中定位致痫脑区并预测术后无发作情况对于手术规划和患者管理至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过sEEG记录预测无发作结果并识别癫痫起源区。&lt;h4&gt;方法&lt;/h4&gt;研究引入了一种双任务图神经网络（GNN）框架，该框架在窗口化的sEEG记录上操作，通过构建功能连接图并提取节点特征来预测无发作结果和定位癫痫起源区。&lt;h4&gt;主要发现&lt;/h4&gt;模型在10折交叉验证下，对于无发作预测的平均图级准确率为89.31%，癫痫起源区的节点级定位准确率为94.72%。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的GNN框架在预测无发作结果和癫痫起源区定位方面具有较高准确性。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is about a study introducing a dual-task graph neural network (GNN) framework that operates on windowed sEEG recordings to jointly predict seizure-freedom outcomes and identify seizure-onset-zone (SOZ) channels. The model achieves a mean graph-level accuracy of 89.31% for seizure-freedom prediction and a node-level SOZ localization accuracy of 94.72% under 10-fold cross-validation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately localizing the brain regions that triggers seizures and predictingwhether a patient will be seizure-free after surgery are vital for surgicalplanning and patient management in drug-resistant epilepsy.Stereo-electroencephalography (sEEG) delivers high-fidelity intracranialrecordings that enable clinicians to precisely locate epileptogenic networks.However, the clinical identification is subjective and dependent on theexpertise of the clinical team. Data driven approaches in this domain aresparse, despite the fact that sEEG offers high temporal-fidelity related toseizure dynamics that can be leveraged using graph structures ideal forimitating brain networks. In this study, we introduce a dual-task graph-neuralnetwork (GNN) framework that operates on windowed sEEG recordings to jointlypredict seizure-freedom outcomes and identify seizure-onset-zone (SOZ)channels. We assemble non-overlapping 10 second windows from 51 clinicalseizures spread across 20 pediatric patients, with sEEG data annotated byclinical experts. For each temporal window we construct a functionalconnectivity graph via thresholded Pearson correlations and extract rich nodefeatures (spectral, statistical, wavelet, Hjorth and local graph features),alongside six global graph descriptors. We optimize a combined cross-entropyloss with a tunable task-weight, and select model hyper-parameters via Optuna.Under window-level 10-fold cross-validation, the model achieves a meangraph-level accuracy of $89.31 \pm 0.0976 \%$ for seizure-freedom predictionand a node-level SOZ localization accuracy of $94.72. \pm 0.0041 \%$. For thebest performing model, we ran additive and leave-one-out ablation studies toexplore feature importance for graph and node-level accuracy.</description>
      <author>example@mail.com (Syeda Abeera Amir, Artur Agaronyan, William Gaillard, Chima Oluigbo, Syed Muhammad Anwar)</author>
      <guid isPermaLink="false">2505.23669v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
  <item>
      <title>6D Pose Estimation on Point Cloud Data through Prior Knowledge Integration: A Case Study in Autonomous Disassembly</title>
      <link>http://arxiv.org/abs/2505.24669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究在计算机视觉领域，即使利用3D点云数据，精确估计6D姿态仍然是一个挑战。在制造业中，利用先验知识可以提高这一任务的效率。研究重点在于通过识别和估计电机的螺栓6D姿态，以促进产品生命周期的工程化。由于遮挡和单视图数据获取的限制，特别是在电机夹紧系统中，某些部分被遮挡，使得一些螺栓难以察觉。因此，开发一个能够获取完整螺栓信息的综合流程至关重要。本文以螺栓检测作为项目的一个相关用例，介绍了一个精心设计的多阶段流程，有效地捕获了电机上所有螺栓的6D信息，展示了在处理这一挑战性任务时先验知识的有效利用。&lt;h4&gt;背景&lt;/h4&gt;在计算机视觉领域，精确估计6D姿态是一个挑战，尤其在制造业中，利用先验知识可以提高这一任务的效率。&lt;h4&gt;目的&lt;/h4&gt;识别和估计电机的螺栓6D姿态，促进产品生命周期的工程化。&lt;h4&gt;方法&lt;/h4&gt;开发一个能够获取完整螺栓信息的综合流程，并利用先验知识处理挑战性任务。&lt;h4&gt;主要发现&lt;/h4&gt;提出的多阶段流程能够有效地捕获电机上所有螺栓的6D信息。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅对6D姿态估计领域做出了贡献，还强调了将特定领域的见解整合到解决制造业和自动化中复杂问题的可行性。&lt;h4&gt;翻译&lt;/h4&gt;The accurate estimation of 6D pose remains a challenging task within the computer vision domain, even when utilizing 3D point cloud data. Conversely, in the manufacturing domain, instances arise where leveraging prior knowledge can yield advancements in this endeavor. This study focuses on the disassembly of starter motors to augment the engineering of product life cycles. A pivotal objective in this context involves the identification and 6D pose estimation of bolts affixed to the motors, facilitating automated disassembly within the manufacturing workflow. Complicating matters, the presence of occlusions and the limitations of single-view data acquisition, notably when motors are placed in a clamping system, obscure certain portions and render some bolts imperceptible. Consequently, the development of a comprehensive pipeline capable of acquiring complete bolt information is imperative to avoid oversight in bolt detection. In this paper, employing the task of bolt detection within the scope of our project as a pertinent use case, we introduce a meticulously devised pipeline. This multi-stage pipeline effectively captures the 6D information with regard to all bolts on the motor, thereby showcasing the effective utilization of prior knowledge in handling this challenging task. The proposed methodology not only contributes to the field of 6D pose estimation but also underscores the viability of integrating domain-specific insights to tackle complex problems in manufacturing and automation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accurate estimation of 6D pose remains a challenging task within thecomputer vision domain, even when utilizing 3D point cloud data. Conversely, inthe manufacturing domain, instances arise where leveraging prior knowledge canyield advancements in this endeavor. This study focuses on the disassembly ofstarter motors to augment the engineering of product life cycles. A pivotalobjective in this context involves the identification and 6D pose estimation ofbolts affixed to the motors, facilitating automated disassembly within themanufacturing workflow. Complicating matters, the presence of occlusions andthe limitations of single-view data acquisition, notably when motors are placedin a clamping system, obscure certain portions and render some boltsimperceptible. Consequently, the development of a comprehensive pipelinecapable of acquiring complete bolt information is imperative to avoid oversightin bolt detection. In this paper, employing the task of bolt detection withinthe scope of our project as a pertinent use case, we introduce a meticulouslydevised pipeline. This multi-stage pipeline effectively captures the 6Dinformation with regard to all bolts on the motor, thereby showcasing theeffective utilization of prior knowledge in handling this challenging task. Theproposed methodology not only contributes to the field of 6D pose estimationbut also underscores the viability of integrating domain-specific insights totackle complex problems in manufacturing and automation.</description>
      <author>example@mail.com (Chengzhi Wu, Hao Fu, Jan-Philipp Kaiser, Erik Tabuchi Barczak, Julius Pfrommer, Gisela Lanza, Michael Heizmann, Jürgen Beyerer)</author>
      <guid isPermaLink="false">2505.24669v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>The Road to Generalizable Neuro-Symbolic Learning Should be Paved with Foundation Models</title>
      <link>http://arxiv.org/abs/2505.24874v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;神经符号学习被提出以解决训练神经网络进行复杂推理任务时的挑战，并带来可解释性、可靠性和效率等额外好处。&lt;h4&gt;背景&lt;/h4&gt;神经符号学习方法传统上与符号程序结合训练神经模型，但面临重大挑战，限制了它们解决简单问题。&lt;h4&gt;目的&lt;/h4&gt;探讨在基础模型时代，神经符号学习中的专门模型训练在其中的作用。&lt;h4&gt;方法&lt;/h4&gt;通过分析传统神经符号学习在计算、数据和程序方面的三个陷阱，探讨这些问题导致的泛化问题。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型使可泛化的神经符号解决方案成为可能，提供了一条实现神经符号学习原始目标而不带来从头开始训练的缺点的方法。&lt;h4&gt;结论&lt;/h4&gt;基础模型为神经符号学习提供了实现其目标的途径，解决了传统方法的局限性。&lt;h4&gt;翻译&lt;/h4&gt;Neuro-symbolic learning was proposed to address challenges with training neural networks for complex reasoning tasks with the added benefits of interpretability, reliability, and efficiency. Neuro-symbolic learning methods traditionally train neural models in conjunction with symbolic programs, but they face significant challenges that limit them to simplistic problems. On the other hand, purely-neural foundation models now reach state-of-the-art performance through prompting rather than training, but they are often unreliable and lack interpretability. Supplementing foundation models with symbolic programs, which we call neuro-symbolic prompting, provides a way to use these models for complex reasoning tasks. Doing so raises the question: What role does specialized model training as part of neuro-symbolic learning have in the age of foundation models? To explore this question, we highlight three pitfalls of traditional neuro-symbolic learning with respect to the compute, data, and programs leading to generalization problems. This position paper argues that foundation models enable generalizable neuro-symbolic solutions, offering a path towards achieving the original goals of neuro-symbolic learning without the downsides of training from scratch.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neuro-symbolic learning was proposed to address challenges with trainingneural networks for complex reasoning tasks with the added benefits ofinterpretability, reliability, and efficiency. Neuro-symbolic learning methodstraditionally train neural models in conjunction with symbolic programs, butthey face significant challenges that limit them to simplistic problems. On theother hand, purely-neural foundation models now reach state-of-the-artperformance through prompting rather than training, but they are oftenunreliable and lack interpretability. Supplementing foundation models withsymbolic programs, which we call neuro-symbolic prompting, provides a way touse these models for complex reasoning tasks. Doing so raises the question:What role does specialized model training as part of neuro-symbolic learninghave in the age of foundation models? To explore this question, we highlightthree pitfalls of traditional neuro-symbolic learning with respect to thecompute, data, and programs leading to generalization problems. This positionpaper argues that foundation models enable generalizable neuro-symbolicsolutions, offering a path towards achieving the original goals ofneuro-symbolic learning without the downsides of training from scratch.</description>
      <author>example@mail.com (Adam Stein, Aaditya Naik, Neelay Velingker, Mayur Naik, Eric Wong)</author>
      <guid isPermaLink="false">2505.24874v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Conformal Prediction for Zero-Shot Models</title>
      <link>http://arxiv.org/abs/2505.24693v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025. Code: https://github.com/jusiro/CLIP-Conformal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了在大规模预训练的视觉语言模型中，通过分割一致性预测范式来提高模型的可靠性和不确定性。&lt;h4&gt;背景&lt;/h4&gt;大规模预训练的视觉语言模型在下游任务中表现出前所未有的适应性和泛化能力，但其可靠性和不确定性尚未得到充分关注。&lt;h4&gt;目的&lt;/h4&gt;研究CLIP模型在分割一致性预测范式下的能力，该范式基于小规模标记校准集为黑盒模型提供理论保证。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Conf-OT的迁移学习设置，该设置在结合校准集和查询集上进行归纳操作，通过解决最优传输问题来弥合预训练和适应之间的领域差距。&lt;h4&gt;主要发现&lt;/h4&gt;Conf-OT在15个数据集和三种非一致性得分上全面探索了这种一致性预测策略，提供了一致相对效率提升，最高可达20%，同时比流行的归纳方法快15倍。&lt;h4&gt;结论&lt;/h4&gt;Conf-OT方法在保持覆盖保证的同时，通过迁移学习有效提高了模型的一致性预测能力，并显著提升了效率。&lt;h4&gt;翻译&lt;/h4&gt;This study investigates the capability of CLIP models under the split conformal prediction paradigm, which provides theoretical guarantees to black-box models based on a small, labeled calibration set. In contrast to the mainstream literature on conformal predictors in vision classifiers, foundation models exhibit a particular characteristic: they are pre-trained on an inaccessiblesource domain on a one-time basis, different from the transferred task. This domain drift negatively affects the efficiency of the conformal sets and poses additional challenges. To alleviate this issue, we propose Conf-OT, a transfer learning setting that operates transductive over the combined calibration and query sets. Solving an optimal transport problem, the proposed method bridges the domain gap between pre-training and adaptation without requiring additional data splits but still maintaining coverage guarantees. We comprehensively explore this conformal prediction strategy on a broad span of 15 datasets and three non-conformity scores. Conf-OT provides consistent relative improvements of up to 20% on set efficiency while being 15 times faster than popular transductive approaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models pre-trained at large scale have shown unprecedentedadaptability and generalization to downstream tasks. Although itsdiscriminative potential has been widely explored, its reliability anduncertainty are still overlooked. In this work, we investigate the capabilitiesof CLIP models under the split conformal prediction paradigm, which providestheoretical guarantees to black-box models based on a small, labeledcalibration set. In contrast to the main body of literature on conformalpredictors in vision classifiers, foundation models exhibit a particularcharacteristic: they are pre-trained on a one-time basis on an inaccessiblesource domain, different from the transferred task. This domain driftnegatively affects the efficiency of the conformal sets and poses additionalchallenges. To alleviate this issue, we propose Conf-OT, a transfer learningsetting that operates transductive over the combined calibration and querysets. Solving an optimal transport problem, the proposed method bridges thedomain gap between pre-training and adaptation without requiring additionaldata splits but still maintaining coverage guarantees. We comprehensivelyexplore this conformal prediction strategy on a broad span of 15 datasets andthree non-conformity scores. Conf-OT provides consistent relative improvementsof up to 20% on set efficiency while being 15 times faster than populartransductive approaches.</description>
      <author>example@mail.com (Julio Silva-Rodríguez, Ismail Ben Ayed, Jose Dolz)</author>
      <guid isPermaLink="false">2505.24693v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Weisfeiler and Leman Follow the Arrow of Time: Expressive Power of Message Passing in Temporal Event Graphs</title>
      <link>http://arxiv.org/abs/2505.24438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了时间图在时间影响下因果拓扑结构的重要性，并提出了一种新的概念——一致事件图同构，用于分析时间图神经网络的表达能力。&lt;h4&gt;背景&lt;/h4&gt;时间图具有独特的因果拓扑结构，但现有的时间图神经网络（TGNNs）往往忽略这种结构。目前缺乏一种将图同构推广到时间图的通用方法，无法完全捕捉其因果拓扑。&lt;h4&gt;目的&lt;/h4&gt;为了分析TGNNs的表达能力，本文旨在提出一种新的时间图同构概念，并开发一种适用于时间图神经网络的消息传递方案。&lt;h4&gt;方法&lt;/h4&gt;引入了一致事件图同构，该方法利用时间图中的时间展开表示来捕捉因果路径。同时，将Weisfeiler-Leman算法推广到时间图，以启发式地区分非同构的时间图。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出的方法与现有时间图同构概念进行了比较，并展示了其在时间图分类实验中的优越性。&lt;h4&gt;结论&lt;/h4&gt;本文的理论基础为时间图神经网络提供了一种新的消息传递方案，实验表明该方法在时间图分类任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;An important characteristic of temporal graphs is how the directed arrow of time influences their causal topology, i.e., which nodes can possibly influence each other causally via time-respecting paths. The resulting patterns are often neglected by temporal graph neural networks (TGNNs). To formally analyze the expressive power of TGNNs, we lack a generalization of graph isomorphism to temporal graphs that fully captures their causal topology. Addressing this gap, we introduce the notion of consistent event graph isomorphism, which utilizes a time-unfolded representation of time-respecting paths in temporal graphs. We compare this definition with existing notions of temporal graph isomorphisms. We illustrate and highlight the advantages of our approach and develop a temporal generalization of the Weisfeiler-Leman algorithm to heuristically distinguish non-isomorphic temporal graphs. Building on this theoretical foundation, we derive a novel message passing scheme for temporal graph neural networks that operates on the event graph representation of temporal graphs. An experimental evaluation shows that our approach performs well in a temporal graph classification experiment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; An important characteristic of temporal graphs is how the directed arrow oftime influences their causal topology, i.e., which nodes can possibly influenceeach other causally via time-respecting paths. The resulting patterns are oftenneglected by temporal graph neural networks (TGNNs). To formally analyze theexpressive power of TGNNs, we lack a generalization of graph isomorphism totemporal graphs that fully captures their causal topology. Addressing this gap,we introduce the notion of consistent event graph isomorphism, which utilizes atime-unfolded representation of time-respecting paths in temporal graphs. Wecompare this definition with existing notions of temporal graph isomorphisms.We illustrate and highlight the advantages of our approach and develop atemporal generalization of the Weisfeiler-Leman algorithm to heuristicallydistinguish non-isomorphic temporal graphs. Building on this theoreticalfoundation, we derive a novel message passing scheme for temporal graph neuralnetworks that operates on the event graph representation of temporal graphs. Anexperimental evaluation shows that our approach performs well in a temporalgraph classification experiment.</description>
      <author>example@mail.com (Franziska Heeg, Jonas Sauer, Petra Mutzel, Ingo Scholtes)</author>
      <guid isPermaLink="false">2505.24438v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>A 3D Mobile Crowdsensing Framework for Sustainable Urban Digital Twins</title>
      <link>http://arxiv.org/abs/2505.24348v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 18 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对可持续城市数字孪生（UDTs）的3D移动众包感知（3D-MCS）框架。&lt;h4&gt;背景&lt;/h4&gt;该框架包括四个关键机制：3D-MCS机制、基于Geohash的空间信息管理机制、UDTs的动态点云集成机制和基于Web的3D-MCS及UDTs实时可视化器。&lt;h4&gt;目的&lt;/h4&gt;该框架旨在通过有效的数据收集和分析，实现UDTs的实时可视化。&lt;h4&gt;方法&lt;/h4&gt;主动感知模型采用游戏化的3D-MCS方法，参与者通过增强现实领土着色游戏收集点云数据；被动感知模型则采用可穿戴3D-MCS方法，参与者将智能手机挂在脖子上，不干扰日常生活。空间信息管理机制使用Geohash有效地划分空间区域。动态点云集成机制通过全局和局部点云注册将3D-MCS收集的点云集成到UDTs中。&lt;h4&gt;主要发现&lt;/h4&gt;通过真实世界的实验验证了所提框架的有效性，从主观评价和数据收集分析的角度验证了3D-MCS模型的有效性，并使用数据集分析了动态点云集成机制的性能。&lt;h4&gt;结论&lt;/h4&gt;该框架能够有效实现UDTs的3D-MCS数据收集和集成，为城市规划和监控提供了有力支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this article, we propose a 3D mobile crowdsensing (3D-MCS) framework aimedat sustainable urban digital twins (UDTs). The framework comprises four keymechanisms: (1) the 3D-MCS mechanism, consisting of active and passive models;(2) the Geohash-based spatial information management mechanism; (3) the dynamicpoint cloud integration mechanism for UDTs; and (4) the web-based real-timevisualizer for 3D-MCS and UDTs. The active sensing model features a gamified3D-MCS approach, where participants collect point cloud data through anaugmented reality territory coloring game. In contrast, the passive sensingmodel employs a wearable 3D-MCS approach, where participants wear smartphonesaround their necks without disrupting daily activities. The spatial informationmanagement mechanism efficiently partitions the space into regions usingGeohash. The dynamic point cloud integration mechanism incorporates pointclouds collected by 3D-MCS into UDTs through global and local point cloudregistration. Finally, we evaluated the proposed framework through real-worldexperiments. We verified the effectiveness of the proposed 3D-MCS models fromthe perspectives of subjective evaluation and data collection and analysis.Furthermore, we analyzed the performance of the dynamic point cloud integrationusing a dataset.</description>
      <author>example@mail.com (Taku Yamazaki, Kaito Watanabe, Tatsuya Kase, Kenta Hasegawa, Koki Saida, Takumi Miyoshi)</author>
      <guid isPermaLink="false">2505.24348v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Context is Gold to find the Gold Passage: Evaluating and Training Contextual Document Embeddings</title>
      <link>http://arxiv.org/abs/2505.24782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的文本嵌入方法，用于解决现代文档检索嵌入方法在编码同一文档中的段落时，往往忽略文档其他部分的重要上下文信息的问题。&lt;h4&gt;背景&lt;/h4&gt;现代文档检索嵌入方法通常独立地编码同一文档中的段落，这导致忽略了文档中其他部分的重要上下文信息。&lt;h4&gt;目的&lt;/h4&gt;通过引入ConTEB（上下文感知文本嵌入基准），评估检索模型在利用文档全局上下文方面的能力，并提出InSeNT（序列负训练）方法，以增强上下文表示学习并保持计算效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为InSeNT的对比后训练方法，该方法结合了晚段池化，以增强上下文表示学习，同时保持计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，在需要上下文的检索场景中，最先进的嵌入模型表现不佳。InSeNT方法显著提高了检索质量，并且嵌入的段落对子优化的段落分割策略和更大的检索语料库大小更加鲁棒。&lt;h4&gt;结论&lt;/h4&gt;本文提出的InSeNT方法在提高检索质量的同时，保持了基模型性能，并且对不同的段落分割策略和检索语料库大小具有更好的适应性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代文档检索嵌入方法的一个局限性是它们通常独立地编码来自同一文档的段落，经常忽略文档其余部分可能极大地改进单个段落表示的关键上下文信息。在这项工作中，我们引入了ConTEB（上下文感知文本嵌入基准），这是一个旨在评估检索模型在利用文档全局上下文能力方面的基准。我们的结果表明，在需要上下文的检索场景中，最先进的嵌入模型表现不佳。为了解决这一局限性，我们提出了InSeNT（序列负训练），一种新颖的对比后训练方法，该方法与晚段池化相结合，增强了上下文表示学习，同时保持了计算效率。我们的方法在ConTEB上显著提高了检索质量，而没有牺牲基模型性能。我们进一步发现，使用我们的方法嵌入的段落对子优化的段落分割策略和更大的检索语料库大小更加鲁棒。我们已在https://github.com/illuin-tech/contextual-embeddings上开源所有工件。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A limitation of modern document retrieval embedding methods is that theytypically encode passages (chunks) from the same documents independently, oftenoverlooking crucial contextual information from the rest of the document thatcould greatly improve individual chunk representations.  In this work, we introduce ConTEB (Context-aware Text Embedding Benchmark), abenchmark designed to evaluate retrieval models on their ability to leveragedocument-wide context. Our results show that state-of-the-art embedding modelsstruggle in retrieval scenarios where context is required. To address thislimitation, we propose InSeNT (In-sequence Negative Training), a novelcontrastive post-training approach which combined with late chunking poolingenhances contextual representation learning while preserving computationalefficiency. Our method significantly improves retrieval quality on ConTEBwithout sacrificing base model performance. We further find chunks embeddedwith our method are more robust to suboptimal chunking strategies and largerretrieval corpus sizes. We open-source all artifacts athttps://github.com/illuin-tech/contextual-embeddings.</description>
      <author>example@mail.com (Max Conti, Manuel Faysse, Gautier Viaud, Antoine Bosselut, Céline Hudelot, Pierre Colombo)</author>
      <guid isPermaLink="false">2505.24782v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Autoregression-free video prediction using diffusion model for mitigating error propagation</title>
      <link>http://arxiv.org/abs/2505.22111v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散模型的AutoRegression-Free（ARFree）视频预测框架，旨在解决现有视频预测方法在预测远期帧时出现的误差传播问题。&lt;h4&gt;背景&lt;/h4&gt;现有的长期视频预测方法通常依赖于自回归视频预测机制，但这种机制在预测远期帧时容易产生误差传播。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了一种不依赖自回归的视频预测框架。&lt;h4&gt;方法&lt;/h4&gt;该框架包含两个关键组件：1）运动预测模块，通过从上下文帧元组中提取的运动特征来预测未来运动；2）训练方法，旨在提高相邻未来帧元组之间的运动连续性和上下文一致性。&lt;h4&gt;主要发现&lt;/h4&gt;通过两个基准数据集的实验，表明提出的ARFree视频预测框架优于几种最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;ARFree视频预测框架在减少误差传播方面表现出色，为视频预测提供了一种新的有效方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing long-term video prediction methods often rely on an autoregressivevideo prediction mechanism. However, this approach suffers from errorpropagation, particularly in distant future frames. To address this limitation,this paper proposes the first AutoRegression-Free (ARFree) video predictionframework using diffusion models. Different from an autoregressive videoprediction mechanism, ARFree directly predicts any future frame tuples from thecontext frame tuple. The proposed ARFree consists of two key components: 1) amotion prediction module that predicts a future motion using motion featureextracted from the context frame tuple; 2) a training method that improvesmotion continuity and contextual consistency between adjacent future frametuples. Our experiments with two benchmark datasets show that the proposedARFree video prediction framework outperforms several state-of-the-art videoprediction methods.</description>
      <author>example@mail.com (Woonho Ko, Jin Bok Park, Il Yong Chun)</author>
      <guid isPermaLink="false">2505.22111v2</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>SiLVR: A Simple Language-based Video Reasoning Framework</title>
      <link>http://arxiv.org/abs/2505.24869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SiLVR是一个基于简单语言的视频推理框架，旨在提升多模态大型语言模型在视频语言任务上的推理能力。&lt;h4&gt;背景&lt;/h4&gt;尽管测试时优化在大型语言模型（LLMs）的推理能力上取得了显著进展，但多模态LLMs（MLLMs）在复杂视频语言任务上的推理能力仍然落后。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，提出SiLVR框架，以分解复杂视频理解过程为两个阶段。&lt;h4&gt;方法&lt;/h4&gt;第一阶段，SiLVR利用多感官输入（如短视频字幕和音频/语音字幕）将原始视频转换为基于语言的表示。第二阶段，将语言描述输入到强大的推理LLM中，以解决复杂的视频语言理解任务。为了处理长上下文的多感官输入，使用自适应标记减少方案，动态确定采样标记的时间粒度。&lt;h4&gt;主要发现&lt;/h4&gt;SiLVR在Video-MME（长）、Video-MMMU（理解）、Video-MMLU、CGBench和EgoLife等任务上取得了最佳结果。实证研究表明，即使没有显式地针对视频进行训练，强大的推理LLM也能有效地从视频中聚集多感官输入信息，以完成视频中的复杂时间、因果、长上下文和知识获取推理任务。&lt;h4&gt;结论&lt;/h4&gt;SiLVR是一个简单、模块化和无需训练的视频推理框架，显著提升了MLLMs在视频语言任务上的推理能力。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in test-time optimization have led to remarkable reasoning capabilities in Large Language Models (LLMs), enabling them to solve highly complex problems in math and coding. However, the reasoning capabilities of multimodal LLMs (MLLMs) still significantly lag, especially for complex video-language tasks. To address this issue, we present SiLVR, a SimpleLanguage-based Video Reasoning framework that decomposes complex video understanding into two stages. In the first stage, SiLVR transforms raw video into language-based representations using multisensory inputs, such as short clip captions and audio/speech subtitles. In the second stage, language descriptions are fed into a powerful reasoning LLM to solve complex video-language understanding tasks. To handle long-context multisensory inputs, we use an adaptive token reduction scheme, which dynamically determines the temporal granularity with which to sample the tokens. Our simple, modular, and training-free video reasoning framework achieves the best-reported results on Video-MME (long), Video-MMMU (comprehension), Video-MMLU, CGBench, and EgoLife. Furthermore, our empirical study focused on video reasoning capabilities shows that, despite not being explicitly trained on video, strong reasoning LLMs can effectively aggregate multisensory input information from video, speech, and audio for complex temporal, causal, long-context, and knowledge acquisition reasoning tasks in video. Code is available at https://github.com/CeeZh/SILVR.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in test-time optimization have led to remarkable reasoningcapabilities in Large Language Models (LLMs), enabling them to solve highlycomplex problems in math and coding. However, the reasoning capabilities ofmultimodal LLMs (MLLMs) still significantly lag, especially for complexvideo-language tasks. To address this issue, we present SiLVR, a SimpleLanguage-based Video Reasoning framework that decomposes complex videounderstanding into two stages. In the first stage, SiLVR transforms raw videointo language-based representations using multisensory inputs, such as shortclip captions and audio/speech subtitles. In the second stage, languagedescriptions are fed into a powerful reasoning LLM to solve complexvideo-language understanding tasks. To handle long-context multisensory inputs,we use an adaptive token reduction scheme, which dynamically determines thetemporal granularity with which to sample the tokens. Our simple, modular, andtraining-free video reasoning framework achieves the best-reported results onVideo-MME (long), Video-MMMU (comprehension), Video-MMLU, CGBench, and EgoLife.Furthermore, our empirical study focused on video reasoning capabilities showsthat, despite not being explicitly trained on video, strong reasoning LLMs caneffectively aggregate multisensory input information from video, speech, andaudio for complex temporal, causal, long-context, and knowledge acquisitionreasoning tasks in video. Code is available at https://github.com/CeeZh/SILVR.</description>
      <author>example@mail.com (Ce Zhang, Yan-Bo Lin, Ziyang Wang, Mohit Bansal, Gedas Bertasius)</author>
      <guid isPermaLink="false">2505.24869v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Tackling View-Dependent Semantics in 3D Language Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2505.24746v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 camera ready. Project Page:  https://jumpat.github.io/laga-page/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LaGa的方法，用于从RGB图像中重建高质感的3D场景，并扩展了3D Gaussian Splatting技术以支持语言驱动的开放词汇场景理解。&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting在3D场景重建方面取得了进展，但现有研究在将2D语义特征投影到3D高斯上时，忽略了2D和3D理解之间的基本差距，即3D物体可能从不同视角表现出不同的语义。&lt;h4&gt;目的&lt;/h4&gt;提出LaGa方法，以解决上述挑战，实现更全面的3D场景理解。&lt;h4&gt;方法&lt;/h4&gt;LaGa通过将3D场景分解为对象，建立跨视角的语义连接。然后，通过聚类语义描述符并基于多视角语义重新加权，构建视角聚合的语义表示。&lt;h4&gt;主要发现&lt;/h4&gt;LaGa有效捕捉了视角依赖性语义的关键信息，显著提高了对3D场景的理解。在LERF-OVS数据集上，LaGa相对于之前的SOTA方法实现了+18.7%的mIoU提升。&lt;h4&gt;结论&lt;/h4&gt;LaGa是一个有效的3D场景重建方法，能够提高对视角依赖性语义的理解，并显著优于现有技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in 3D Gaussian Splatting (3D-GS) enable high-quality 3Dscene reconstruction from RGB images. Many studies extend this paradigm forlanguage-driven open-vocabulary scene understanding. However, most of themsimply project 2D semantic features onto 3D Gaussians and overlook afundamental gap between 2D and 3D understanding: a 3D object may exhibitvarious semantics from different viewpoints--a phenomenon we termview-dependent semantics. To address this challenge, we propose LaGa (LanguageGaussians), which establishes cross-view semantic connections by decomposingthe 3D scene into objects. Then, it constructs view-aggregated semanticrepresentations by clustering semantic descriptors and reweighting them basedon multi-view semantics. Extensive experiments demonstrate that LaGaeffectively captures key information from view-dependent semantics, enabling amore comprehensive understanding of 3D scenes. Notably, under the samesettings, LaGa achieves a significant improvement of +18.7% mIoU over theprevious SOTA on the LERF-OVS dataset. Our code is available at:https://github.com/SJTU-DeepVisionLab/LaGa.</description>
      <author>example@mail.com (Jiazhong Cen, Xudong Zhou, Jiemin Fang, Changsong Wen, Lingxi Xie, Xiaopeng Zhang, Wei Shen, Qi Tian)</author>
      <guid isPermaLink="false">2505.24746v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>A Cross Branch Fusion-Based Contrastive Learning Framework for Point Cloud Self-supervised Learning</title>
      <link>http://arxiv.org/abs/2505.24641v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PoCCA的点云对比交叉分支注意力框架，用于无监督学习点云数据，旨在学习丰富的3D点云表示。&lt;h4&gt;背景&lt;/h4&gt;对比学习是自监督学习中的关键方法，主要采用多分支策略来比较不同分支获得的潜在表示并训练编码器。&lt;h4&gt;目的&lt;/h4&gt;在没有额外训练数据的情况下，进行点云无监督学习，学习丰富的3D点云表示。&lt;h4&gt;方法&lt;/h4&gt;PoCCA引入子分支，允许在不同分支之间在损失端之前进行信息交换，通过多种方式对输入数据进行增强，以供不同分支使用。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在使用无额外训练数据的情况下，PoCCA自监督模型学习的表示在用于点云下游任务时达到最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;PoCCA框架在点云无监督学习中表现出色，能够有效学习高质量的3D点云表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning is an essential method in self-supervised learning. Itprimarily employs a multi-branch strategy to compare latent representationsobtained from different branches and train the encoder. In the case ofmulti-modal input, diverse modalities of the same object are fed into distinctbranches. When using single-modal data, the same input undergoes variousaugmentations before being fed into different branches. However, all existingcontrastive learning frameworks have so far only performed contrastiveoperations on the learned features at the final loss end, with no informationexchange between different branches prior to this stage. In this paper, forpoint cloud unsupervised learning without the use of extra training data, wepropose a Contrastive Cross-branch Attention-based framework for Point clouddata (termed PoCCA), to learn rich 3D point cloud representations. Byintroducing sub-branches, PoCCA allows information exchange between differentbranches before the loss end. Experimental results demonstrate that in the caseof using no extra training data, the representations learned with ourself-supervised model achieve state-of-the-art performances when used fordownstream tasks on point clouds.</description>
      <author>example@mail.com (Chengzhi Wu, Qianliang Huang, Kun Jin, Julius Pfrommer, Jürgen Beyerer)</author>
      <guid isPermaLink="false">2505.24641v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>GenSpace: Benchmarking Spatially-Aware Image Generation</title>
      <link>http://arxiv.org/abs/2505.24870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了GenSpace，一个用于评估图像生成模型空间感知能力的基准和评估流程，并指出当前AI模型在空间感知方面存在局限性。&lt;h4&gt;背景&lt;/h4&gt;人类能够直观地在三维空间中构图和排列场景进行摄影，但AI图像生成器是否具有类似的空间感知能力？&lt;h4&gt;目的&lt;/h4&gt;评估当前图像生成模型的空间感知能力，并提出改进方向。&lt;h4&gt;方法&lt;/h4&gt;提出了一种专门的评估流程和指标，使用多个视觉基础模型重建3D场景几何，以提供更准确和符合人类的空间感知度。&lt;h4&gt;主要发现&lt;/h4&gt;AI模型在创建视觉吸引人的图像和遵循一般指令方面表现良好，但在处理具体的3D细节，如物体放置、关系和尺寸测量方面存在困难。&lt;h4&gt;结论&lt;/h4&gt;当前最先进的图像生成模型在空间感知方面存在三个核心局限性：物体透视理解、自我中心-中心化转换和度量测量遵守，为提高图像生成中的空间智能指明了可能的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类可以直观地在三维空间中构图和排列场景进行摄影。然而，高级AI图像生成器在从文本或图像提示创建图像时，是否能够具有类似的三维空间感知能力？我们提出了GenSpace，一个新颖的基准和评估流程，全面评估当前图像生成模型的空间感知能力。此外，使用通用视觉-语言模型（VLMs）的标准评估往往无法捕捉详细的时空错误。为了应对这一挑战，我们提出了一种专门的评估流程和指标，该流程使用多个视觉基础模型重建3D场景几何，并提供了一个更准确且符合人类的空间感知度指标。我们的发现表明，尽管AI模型能够创建视觉吸引人的图像并遵循一般指令，但在处理具体的3D细节，如物体放置、关系和尺寸测量方面存在困难。我们总结了当前最先进图像生成模型在空间感知方面的三个核心局限性：物体透视理解、自我中心-中心化转换和度量测量遵守，突出了提高图像生成中空间智能的可能方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans can intuitively compose and arrange scenes in the 3D space forphotography. However, can advanced AI image generators plan scenes with similar3D spatial awareness when creating images from text or image prompts? Wepresent GenSpace, a novel benchmark and evaluation pipeline to comprehensivelyassess the spatial awareness of current image generation models. Furthermore,standard evaluations using general Vision-Language Models (VLMs) frequentlyfail to capture the detailed spatial errors. To handle this challenge, wepropose a specialized evaluation pipeline and metric, which reconstructs 3Dscene geometry using multiple visual foundation models and provides a moreaccurate and human-aligned metric of spatial faithfulness. Our findings showthat while AI models create visually appealing images and can follow generalinstructions, they struggle with specific 3D details like object placement,relationships, and measurements. We summarize three core limitations in thespatial perception of current state-of-the-art image generation models: 1)Object Perspective Understanding, 2) Egocentric-Allocentric Transformation and3) Metric Measurement Adherence, highlighting possible directions for improvingspatial intelligence in image generation.</description>
      <author>example@mail.com (Zehan Wang, Jiayang Xu, Ziang Zhang, Tianyu Pan, Chao Du, Hengshuang Zhao, Zhou Zhao)</author>
      <guid isPermaLink="false">2505.24870v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning Weather Models for Subregional Ocean Forecasting: A Case Study on the Canary Current Upwelling System</title>
      <link>http://arxiv.org/abs/2505.24429v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要讨论了海洋预测对社会各领域的影响，以及基于深度学习的预测方法在提高海洋预测准确性方面的潜力。&lt;h4&gt;背景&lt;/h4&gt;传统海洋预测方法基于全球环流模型，计算成本高且速度慢，限制了其提供快速预测的能力。深度学习模型提供了更快、更准确的预测，但它们通常使用数值模拟的全球数据训练，可能不反映现实。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在将最初为全球天气预报开发的图神经网络应用于改进子区域海洋预测，特别是针对加那利海流上升系统。&lt;h4&gt;方法&lt;/h4&gt;该模型使用卫星数据进行训练，并与最先进的物理海洋模型进行比较，以评估其在捕捉海洋动力学方面的性能。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明，尽管在上升区域存在一些挑战，但深度学习模型在精度方面超越了传统方法。与ConvLSTM和GLORYS再分析相比，该模型在减少RMSE误差方面表现出优越性能，特别是在具有复杂海洋动力学如加比尔角、博雅多尔角和白崖的区域。该模型在这些关键位置实现了高达26.5%的相对改进和高达76%的误差减少。&lt;h4&gt;结论&lt;/h4&gt;这些发现表明，将气象数据驱动模型应用于改进子区域中期海洋预测是可行的。&lt;h4&gt;翻译&lt;/h4&gt;摘要：海洋预报通过支持环境保护和经济活动影响社会的各个领域。基于全球环流模型的传统预报方法计算成本高且速度慢，限制了其提供快速预报的能力。深度学习技术的最新进展提供了更快、更准确的预测，尽管这些数据驱动模型通常使用数值模拟的全球数据进行训练，这可能不反映现实。这种模型的出现为在子区域域内提高海洋预报提供了巨大潜力。然而，它们预测细尺度的海洋过程，如中尺度结构的能力仍 largely unknown（很大程度上未知）。本研究旨在将最初为全球天气预报开发的图神经网络应用于改进子区域海洋预报，特别是针对加那利海流上升系统。该模型使用卫星数据进行训练，并与最先进的物理海洋模型进行比较，以评估其在捕捉海洋动力学方面的性能。我们的结果表明，尽管在上升区域存在一些挑战，但深度学习模型在精度方面超越了传统方法。它在与ConvLSTM和GLORYS再分析相比时，在减少RMSE误差方面表现出优越性能，特别是在具有复杂海洋动力学如加比尔角、博雅多尔角和白崖的区域。该模型在这些关键位置实现了高达26.5%的相对改进和高达76%的误差减少，这突出了其增强的能力来捕捉空间变异性并提高复杂地区的预测精度。这些发现表明，将气象数据驱动模型应用于改进子区域中期海洋预报是可行的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Oceanographic forecasting impacts various sectors of society by supportingenvironmental conservation and economic activities. Based on global circulationmodels, traditional forecasting methods are computationally expensive and slow,limiting their ability to provide rapid forecasts. Recent advances in deeplearning offer faster and more accurate predictions, although these data-drivenmodels are often trained with global data from numerical simulations, which maynot reflect reality. The emergence of such models presents great potential forimproving ocean prediction at a subregional domain. However, their ability topredict fine-scale ocean processes, like mesoscale structures, remains largelyunknown. This work aims to adapt a graph neural network initially developed forglobal weather forecasting to improve subregional ocean prediction,specifically focusing on the Canary Current upwelling system. The model istrained with satellite data and compared to state-of-the-art physical oceanmodels to assess its performance in capturing ocean dynamics. Our results showthat the deep learning model surpasses traditional methods in precision despitesome challenges in upwelling areas. It demonstrated superior performance inreducing RMSE errors compared to ConvLSTM and the GLORYS reanalysis,particularly in regions with complex oceanic dynamics such as Cape Ghir, CapeBojador, and Cape Blanc. The model achieved improvements of up to 26.5%relative to ConvLSTM and error reductions of up to 76% in 5-day forecastscompared to the GLORYS reanalysis at these critical locations, highlighting itsenhanced capability to capture spatial variability and improve predictiveaccuracy in complex areas. These findings suggest the viability of adaptingmeteorological data-driven models for improving subregional medium-term oceanforecasting.</description>
      <author>example@mail.com (Giovanny C-Londoño, Javier Sánchez, Ángel Rodríguez-Santana)</author>
      <guid isPermaLink="false">2505.24429v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Collision Probability Estimation for Optimization-based Vehicular Motion Planning</title>
      <link>http://arxiv.org/abs/2505.21161v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于优化方法的运动规划算法，用于自动驾驶中的碰撞概率（POC）估计，以解决测量和估计不确定性带来的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的POC估计技术通常使用基于采样的方法，但这些方法计算效率低，且结果具有非确定性。&lt;h4&gt;目的&lt;/h4&gt;提出一种计算高效且确定性的POC估计方法，以保证运动规划的可行性。&lt;h4&gt;方法&lt;/h4&gt;通过多圆形形状近似来过度估计车辆形状，将预测车辆的位置和航向建模为随机变量，并提出了一种计算POC估计的算法，用于处理位置和航向的Gaussian不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;该算法能提供POC的过度估计，保证安全，并在路径跟随的随机模型预测控制器（SMPC）中应用，生成可重复的轨迹，同时在测试案例中保持控制器的可行性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够处理不同水平的不确定性，为自动驾驶中的运动规划提供了一种有效的POC估计方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Tolksdorf/Collision-Probaility-Estimation&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many motion planning algorithms for automated driving require estimating theprobability of collision (POC) to account for uncertainties in the measurementand estimation of the motion of road users. Common POC estimation techniquesoften utilize sampling-based methods that suffer from computationalinefficiency and a non-deterministic estimation, i.e., each estimation resultfor the same inputs is slightly different. In contrast, optimization-basedmotion planning algorithms require computationally efficient POC estimation,ideally using deterministic estimation, such that typical optimizationalgorithms for motion planning retain feasibility. Estimating the POCanalytically, however, is challenging because it depends on understanding thecollision conditions (e.g., vehicle's shape) and characterizing the uncertaintyin motion prediction. In this paper, we propose an approach in which weestimate the POC between two vehicles by over-approximating their shapes by amulti-circular shape approximation. The position and heading of the predictedvehicle are modelled as random variables, contrasting with the literature,where the heading angle is often neglected. We guarantee that the provided POCis an over-approximation, which is essential in providing safety guarantees,and present a computationally efficient algorithm for computing the POCestimate for Gaussian uncertainty in the position and heading. This algorithmis then used in a path-following stochastic model predictive controller (SMPC)for motion planning. With the proposed algorithm, the SMPC generatesreproducible trajectories while the controller retains its feasibility in thepresented test cases and demonstrates the ability to handle varying levels ofuncertainty.</description>
      <author>example@mail.com (Leon Tolksdorf, Arturo Tejada, Christian Birkner, Nathan van de Wouw)</author>
      <guid isPermaLink="false">2505.21161v2</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors</title>
      <link>http://arxiv.org/abs/2505.24625v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新的视频-3D几何大型语言模型（VG LLM），通过视频数据直接理解和推理3D空间，无需额外的3D输入，并在3D场景理解和空间推理任务中取得了显著成果。&lt;h4&gt;背景&lt;/h4&gt;先前研究通过将3D场景解释为视频来应用多模态大型语言模型（MLLMs），这些方法通常依赖于全面的三维数据输入，如点云或重建的鸟瞰图。&lt;h4&gt;目的&lt;/h4&gt;提升MLLMs从视频数据中直接理解和推理3D空间的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一个名为VG LLM的方法，它使用3D视觉几何编码器从视频序列中提取3D先验信息，并将这些信息与视觉标记结合后输入到MLLM中。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在各种与3D场景理解和空间推理相关的任务中实现了显著的改进，其4B模型在没有依赖显式3D数据输入的情况下，与现有最先进的方法相比取得了具有竞争力的结果，甚至在VSI-Bench评估中超过了Gemini-1.5-Pro。&lt;h4&gt;结论&lt;/h4&gt;VG LLM在3D场景理解和空间推理任务中表现出色，为直接从视频数据中学习3D信息提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Previous research has investigated the application of Multimodal LargeLanguage Models (MLLMs) in understanding 3D scenes by interpreting them asvideos. These approaches generally depend on comprehensive 3D data inputs, suchas point clouds or reconstructed Bird's-Eye View (BEV) maps. In our research,we advance this field by enhancing the capability of MLLMs to understand andreason in 3D spaces directly from video data, without the need for additional3D input. We propose a novel and efficient method, the Video-3D Geometry LargeLanguage Model (VG LLM). Our approach employs a 3D visual geometry encoder thatextracts 3D prior information from video sequences. This information isintegrated with visual tokens and fed into the MLLM. Extensive experiments haveshown that our method has achieved substantial improvements in various tasksrelated to 3D scene understanding and spatial reasoning, all directly learnedfrom video sources. Impressively, our 4B model, which does not rely on explicit3D data inputs, achieves competitive results compared to existingstate-of-the-art methods, and even surpasses the Gemini-1.5-Pro in theVSI-Bench evaluations.</description>
      <author>example@mail.com (Duo Zheng, Shijia Huang, Yanyang Li, Liwei Wang)</author>
      <guid isPermaLink="false">2505.24625v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Time Blindness: Why Video-Language Models Can't See What Humans Can?</title>
      <link>http://arxiv.org/abs/2505.24867v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page at https://timeblindness.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SpookyBench基准测试，旨在研究视觉语言模型在视频理解中处理空间信息时的局限性。&lt;h4&gt;背景&lt;/h4&gt;尽管视觉语言模型在理解视频中的时空关系方面取得了显著进展，但当空间信息被遮挡时，这些模型难以捕捉纯粹的时间模式。&lt;h4&gt;目的&lt;/h4&gt;SpookyBench旨在通过仅使用噪声帧的时间序列来编码信息，模拟从生物信号到隐蔽通信的自然现象，以评估视觉语言模型在处理时间模式时的能力。&lt;h4&gt;方法&lt;/h4&gt;SpookyBench提供了一个基准测试环境，其中人类可以以超过98%的准确率识别序列中的形状、文本和模式，而最先进的视觉语言模型却无法做到。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，视觉语言模型过度依赖帧级空间特征，无法从时间线索中提取意义。此外，在低空间信噪比的数据集上训练时，模型的时间理解能力下降速度比人类感知快，特别是在需要精细时间推理的任务中。&lt;h4&gt;结论&lt;/h4&gt;为了克服这一局限性，需要开发新的架构或训练范式，以解耦空间依赖和时间处理。SpookyBench的发布旨在推动时间模式识别研究，并弥合人类与机器视频理解之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近期在视觉语言模型（VLMs）方面取得的进展，使视频中的时空关系理解取得了显著进展。然而，当空间信息被遮挡时，这些模型在捕捉纯粹的时间模式上存在困难。我们介绍了SpookyBench，一个信息仅通过噪声帧的时间序列编码的基准测试，反映了从生物信号到隐蔽通信的自然现象。有趣的是，尽管人类可以以超过98%的准确率在这些序列中识别形状、文本和模式，但最先进的VLMs的准确率为0%。这种性能差距突显了一个关键限制：过度依赖帧级空间特征和无法从时间线索中提取意义。此外，在低空间信噪比的数据集上训练时，模型的时间理解能力下降速度比人类感知快，特别是在需要精细时间推理的任务中。克服这一限制需要新的架构或训练范式，以解耦空间依赖和时间处理。我们的系统分析表明，这个问题在模型规模和架构上普遍存在。我们发布了SpookyBench，以推动时间模式识别研究，并弥合人类与机器视频理解之间的差距。数据集和代码已发布在我们的项目网站上：https://timeblindness.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in vision-language models (VLMs) have made impressive stridesin understanding spatio-temporal relationships in videos. However, when spatialinformation is obscured, these models struggle to capture purely temporalpatterns. We introduce $\textbf{SpookyBench}$, a benchmark where information isencoded solely in temporal sequences of noise-like frames, mirroring naturalphenomena from biological signaling to covert communication. Interestingly,while humans can recognize shapes, text, and patterns in these sequences withover 98% accuracy, state-of-the-art VLMs achieve 0% accuracy. This performancegap highlights a critical limitation: an over-reliance on frame-level spatialfeatures and an inability to extract meaning from temporal cues. Furthermore,when trained in data sets with low spatial signal-to-noise ratios (SNR),temporal understanding of models degrades more rapidly than human perception,especially in tasks requiring fine-grained temporal reasoning. Overcoming thislimitation will require novel architectures or training paradigms that decouplespatial dependencies from temporal processing. Our systematic analysis showsthat this issue persists across model scales and architectures. We releaseSpookyBench to catalyze research in temporal pattern recognition and bridge thegap between human and machine video understanding. Dataset and code has beenmade available on our project website: https://timeblindness.github.io/.</description>
      <author>example@mail.com (Ujjwal Upadhyay, Mukul Ranjan, Zhiqiang Shen, Mohamed Elhoseiny)</author>
      <guid isPermaLink="false">2505.24867v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Graph Masked Contrastive Learning for Robust Recommendation</title>
      <link>http://arxiv.org/abs/2505.24172v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Masked Contrastive Learning（MCL）的新型模型，用于增强推荐任务中对噪声的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;Heterogeneous graph neural networks（HGNNs）在利用辅助信息进行推荐任务中表现出优越性，但使用元路径构建的图通常过于密集，含有大量噪声边，且HGNNs的传播机制会将图中的噪声传播到远距离的邻居节点，影响多个节点嵌入。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述限制，提出MCL模型以提高推荐对噪声的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;MCL采用随机掩码策略通过元路径增强图，减少节点对特定邻居的敏感性，增强嵌入鲁棒性。此外，MCL在Heterogeneous Information Network（HIN）上采用对比交叉视图，从单跳邻居和元路径邻居两个角度进行对比学习。这种方法同时获取了捕获局部和高层结构的嵌入，以用于推荐。&lt;h4&gt;主要发现&lt;/h4&gt;在三个真实世界数据集上的实证评估表明，该方法优于现有的推荐方法。&lt;h4&gt;结论&lt;/h4&gt;MCL模型通过增强推荐对噪声的鲁棒性，提高了推荐任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterogeneous graph neural networks (HGNNs) have demonstrated theirsuperiority in exploiting auxiliary information for recommendation tasks.However, graphs constructed using meta-paths in HGNNs are usually too dense andcontain a large number of noise edges. The propagation mechanism of HGNNspropagates even small amounts of noise in a graph to distant neighboring nodes,thereby affecting numerous node embeddings. To address this limitation, weintroduce a novel model, named Masked Contrastive Learning (MCL), to enhancerecommendation robustness to noise. MCL employs a random masking strategy toaugment the graph via meta-paths, reducing node sensitivity to specificneighbors and bolstering embedding robustness. Furthermore, MCL employscontrastive cross-view on a Heterogeneous Information Network (HIN) from twoperspectives: one-hop neighbors and meta-path neighbors. This approach acquiresembeddings capturing both local and high-order structures simultaneously forrecommendation. Empirical evaluations on three real-world datasets confirm thesuperiority of our approach over existing recommendation methods.</description>
      <author>example@mail.com (Lei Sang, Yu Wang, Yiwen Zhang)</author>
      <guid isPermaLink="false">2505.24172v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>GARLIC: GAussian Representation LearnIng for spaCe partitioning</title>
      <link>http://arxiv.org/abs/2505.24608v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了GARLIC，一种基于高斯表示学习的索引结构，用于高效地学习高维向量空间。&lt;h4&gt;背景&lt;/h4&gt;GARLIC受到3D渲染中高斯分裂技术的启发，用于高维搜索和分类。&lt;h4&gt;目的&lt;/h4&gt;优化高斯参数，平衡覆盖、分配置信度、结构和语义一致性。&lt;h4&gt;方法&lt;/h4&gt;通过分割和克隆操作逐步细化表示，处理数百维度的数据，以应对不同的数据密度。&lt;h4&gt;主要发现&lt;/h4&gt;GARLIC具有快速构建时间（例如，SIFT1M的构建时间约为5分钟），在低候选者环境中达到约50%的Recall10@10。&lt;h4&gt;结论&lt;/h4&gt;在标准基准测试中，GARLIC在k-NN检索中表现一致，在Fashion-MNIST上使用约一半的探针就实现了与Faiss-IVF相当的高Recall10@10，在分类任务中比其他多数投票方法提高了约15%的准确性。此外，GARLIC具有较强的泛化能力，即使使用下采样训练数据也能保持高精度，使用1%的训练数据就能达到约45%的Recall@1，因此对于需要速度和准确性的应用非常强大。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了GARLIC（高斯表示学习用于空间划分），一种基于N维高斯的新颖索引结构，用于高效地学习高维向量空间。我们的方法受到3D渲染中高斯分裂技术的启发，我们将这些技术适应于高维搜索和分类。我们使用信息论目标优化高斯参数，以平衡覆盖、分配置信度、结构和语义一致性。一个关键贡献是通过分割和克隆操作逐步细化表示，处理数百维度的数据，从而处理不同的数据密度。GARLIC提供了传统空间划分方法的快速构建时间（例如，SIFT1M的构建时间约为5分钟），同时在低候选者环境中达到约50%的Recall10@10。在标准基准测试中，我们的方法在k-NN检索中表现一致，在Fashion-MNIST上使用约一半的探针就实现了与Faiss-IVF相当的高Recall10@10，在分类任务中比其他多数投票方法提高了约15%的准确性。此外，我们展示了强大的泛化能力，即使使用下采样训练数据也能保持高精度：使用仅1%的训练数据就能达到约45%的Recall@1，因此GARLIC对于需要速度和准确性的应用非常强大。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce GARLIC (GAussian Representation LearnIng for spaCepartitioning), a novel indexing structure based on \(N\)-dimensional Gaussiansfor efficiently learning high-dimensional vector spaces. Our approach isinspired from Gaussian splatting techniques, typically used in 3D rendering,which we adapt for high-dimensional search and classification. We optimizeGaussian parameters using information-theoretic objectives that balancecoverage, assignment confidence, and structural and semantic consistency. A keycontribution is to progressively refine the representation through split andclone operations, handling hundreds of dimensions, thus handling varying datadensities. GARLIC offers the fast building times of traditional spacepartitioning methods (e.g., under \(\sim5\) min build time for SIFT1M) whileachieving \(\sim50\%\) Recall10@10 in low-candidate regimes. Experimentalresults on standard benchmarks demonstrate our method's consistency in (a)\(k\)-NN retrieval, outperforming methods, such as Faiss-IVF, in fast-recall byusing about half their probes for the same Recall10@10 in Fashion-MNIST, and(b) in classification tasks, beating by \(\sim15\%\) accuracy other majorityvoting methods. Further, we show strong generalization capabilities,maintaining high accuracy even with downsampled training data: using just\(1\%\) of the training data returns \(\sim 45\%\) Recall@1, thus making GARLICquite powerful for applications requiring both speed and accuracy.</description>
      <author>example@mail.com (Panagiotis Rigas, Panagiotis Drivas, Charalambos Tzamos, Ioannis Chamodrakas, George Ioannakis, Leonidas J. Guibas, Ioannis Z. Emiris)</author>
      <guid isPermaLink="false">2505.24608v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>ConversAR: Exploring Embodied LLM-Powered Group Conversations in Augmented Reality for Second Language Learners</title>
      <link>http://arxiv.org/abs/2505.24000v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in Proceedings of the Extended Abstracts of the CHI  Conference on Human Factors in Computing Systems&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ConversAR的增强现实应用，它通过两个具有视觉场景理解和实时字幕的实体化语言模型代理，帮助第二语言学习者练习情境化的群体对话。&lt;h4&gt;背景&lt;/h4&gt;群体对话对于第二语言学习者来说很有价值，因为它提供了练习听力、口语、复杂轮流技巧和体验目标语言中的群体社会动态的机会。然而，大多数现有的基于增强现实（AR）的对话学习工具都侧重于二元交互而不是群体对话。&lt;h4&gt;目的&lt;/h4&gt;研究目的是探索使用AR技术进行群体语言实践的可能性，并开发一个工具来帮助第二语言学习者练习群体对话。&lt;h4&gt;方法&lt;/h4&gt;研究人员开发了一个名为ConversAR的AR应用，该应用由gpt-4o驱动，并包含两个具有视觉场景理解和实时字幕的实体化语言模型代理。&lt;h4&gt;主要发现&lt;/h4&gt;在一个包含10名参与者的系统评估中，用户报告说，与与其他学习者面对面练习的方法相比，使用ConversAR减少了说话焦虑并增加了学习者的自主性。&lt;h4&gt;结论&lt;/h4&gt;ConversAR作为一种AR应用，能够帮助第二语言学习者减少说话焦虑，并提高学习者的自主性，为群体语言实践提供了一种新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：群体对话对于第二语言学习者来说很有价值，因为它们提供了练习听力、口语、复杂轮流技巧和体验目标语言中的群体社会动态的机会。然而，大多数现有的基于增强现实（AR）的对话学习工具都侧重于二元交互而不是群体对话。尽管研究表明，AR可以帮助减少说话焦虑，并在二元场景中创建一个练习说话技能的舒适空间，特别是与基于大型语言模型（LLM）的对话代理一起，但这些技术在群体语言实践方面的潜力仍未得到充分探索。我们介绍了一种名为ConversAR的由gpt-4o驱动的AR应用，它使第二语言学习者能够练习情境化的群体对话。我们的系统具有两个具有视觉场景理解和实时字幕的实体化LLM代理。在一个包含10名参与者的系统评估中，用户报告说，与与其他学习者面对面练习的方法相比，使用ConversAR减少了说话焦虑并增加了学习者的自主性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3706599.3720162&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Group conversations are valuable for second language (L2) learners as theyprovide opportunities to practice listening and speaking, exercise complexturn-taking skills, and experience group social dynamics in a target language.However, most existing Augmented Reality (AR)-based conversational learningtools focus on dyadic interactions rather than group dialogues. Althoughresearch has shown that AR can help reduce speaking anxiety and create acomfortable space for practicing speaking skills in dyadic scenarios,especially with Large Language Model (LLM)-based conversational agents, thepotential for group language practice using these technologies remains largelyunexplored. We introduce ConversAR, a gpt-4o powered AR application, thatenables L2 learners to practice contextualized group conversations. Our systemfeatures two embodied LLM agents with vision-based scene understanding and livecaptions. In a system evaluation with 10 participants, users reported reducedspeaking anxiety and increased learner autonomy compared to perceptions ofin-person practice methods with other learners.</description>
      <author>example@mail.com (Jad Bendarkawi, Ashley Ponce, Sean Mata, Aminah Aliu, Yuhan Liu, Lei Zhang, Amna Liaqat, Varun Nagaraj Rao, Andrés Monroy-Hernández)</author>
      <guid isPermaLink="false">2505.24000v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Text Encoders for Labor Market Analysis</title>
      <link>http://arxiv.org/abs/2505.24640v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ConTeXT-match的对比学习方法，用于技能分类的极端多标签分类任务，提高了技能提取的效率和性能，并引入了Skill-XL基准和新版的JobBERT V2模型，以提高大规模实时劳动力市场分析的效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;劳动力市场分析依赖从职位广告中提取信息，这些信息虽然有价值但未结构化，而现有技能提取方法依赖计算量大、速度慢的大语言模型。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的技能提取方法，并支持鲁棒的评估。&lt;h4&gt;方法&lt;/h4&gt;设计了一种新的对比学习方法ConTeXT-match，引入了新的基准Skill-XL，并改进了JobBERT V2模型。&lt;h4&gt;主要发现&lt;/h4&gt;ConTeXT-match显著提高了技能提取效率和性能，Skill-XL基准解决了标签空间冗余问题，JobBERT V2模型利用提取的技能生成高质量职位标题表示。&lt;h4&gt;结论&lt;/h4&gt;提出的模型在效率和准确性方面表现出色，适合用于大规模实时劳动力市场分析。&lt;h4&gt;翻译&lt;/h4&gt;摘要：劳动力市场分析依赖于从职位广告中提取见解，这些广告提供了关于职位名称和相应技能要求的宝贵但未结构化的信息。尽管现有的技能提取方法在性能上达到了高水平，但它们依赖于计算量大且速度慢的大语言模型。在本文中，我们提出了ConTeXT-match，一种新的带有标记级注意力的对比学习方法，非常适合极端的多标签分类任务——技能分类。ConTeXT-match显著提高了技能提取的效率和性能，使用轻量级的双编码器模型实现了最先进的结果。为了支持稳健的评估，我们引入了Skill-XL，一个具有详尽、句子级技能注释的新基准，它明确解决了大标签空间中的冗余问题。最后，我们展示了JobBERT V2，一个改进的职位标题规范化模型，它利用提取的技能来生成高质量的职位标题表示。实验表明，我们的模型在效率和准确性方面都很高，适合用于大规模实时劳动力市场分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Labor market analysis relies on extracting insights from job advertisements,which provide valuable yet unstructured information on job titles andcorresponding skill requirements. While state-of-the-art methods for skillextraction achieve strong performance, they depend on large language models(LLMs), which are computationally expensive and slow. In this paper, we propose\textbf{ConTeXT-match}, a novel contrastive learning approach with token-levelattention that is well-suited for the extreme multi-label classification taskof skill classification. \textbf{ConTeXT-match} significantly improves skillextraction efficiency and performance, achieving state-of-the-art results witha lightweight bi-encoder model. To support robust evaluation, we introduce\textbf{Skill-XL}, a new benchmark with exhaustive, sentence-level skillannotations that explicitly address the redundancy in the large label space.Finally, we present \textbf{JobBERT V2}, an improved job title normalizationmodel that leverages extracted skills to produce high-quality job titlerepresentations. Experiments demonstrate that our models are efficient,accurate, and scalable, making them ideal for large-scale, real-time labormarket analysis.</description>
      <author>example@mail.com (Jens-Joris Decorte, Jeroen Van Hautte, Chris Develder, Thomas Demeester)</author>
      <guid isPermaLink="false">2505.24640v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>TalkingHeadBench: A Multi-Modal Benchmark &amp; Analysis of Talking-Head DeepFake Detection</title>
      <link>http://arxiv.org/abs/2505.24866v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TalkingHeadBench，这是一个用于评估最先进深度伪造检测器性能的全面多模型多生成器基准和精选数据集。&lt;h4&gt;背景&lt;/h4&gt;深度伪造生成技术迅速发展，使得合成视频的真实性提升，对媒体、政治和金融等领域构成重大风险。然而，现有的深度伪造检测基准无法反映这一进展。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够评估最先进检测器在最新生成器上性能的基准和数据集，以促进更鲁棒和更通用的检测模型研究。&lt;h4&gt;方法&lt;/h4&gt;构建了包含由领先学术和商业模型合成的深度伪造的视频数据集，并设计了评估在身份和生成器特征分布变化下的泛化能力的协议。对包括CNN、视觉变换器和时序模型在内的多种检测方法进行了基准测试，并使用Grad-CAM可视化进行错误分析。&lt;h4&gt;主要发现&lt;/h4&gt;当前检测方法在鲁棒性和泛化能力方面存在不足，且存在常见的失败模式和检测偏差。&lt;h4&gt;结论&lt;/h4&gt;TalkingHeadBench旨在通过提供全面的数据集和协议，加速对快速发展的生成技术的研究，以开发更鲁棒和通用的检测模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由先进生成模型推动的头部说话人深度伪造生成技术的快速发展，将合成视频的真实性提升到了一个在媒体、政治和金融等领域带来重大风险的级别。然而，当前头部说话人深度伪造检测的基准无法反映这一进展，依赖于过时的生成器，并且对模型的鲁棒性和泛化能力提供的信息有限。我们介绍了TalkingHeadBench，这是一个全面的多模型多生成器基准和精选数据集，旨在评估最先进检测器在最新生成器上的性能。我们的数据集包括由领先学术和商业模型合成的深度伪造，并具有精心构建的协议来评估在身份和生成器特征分布变化下的泛化能力。我们对包括CNN、视觉变换器和时序模型在内的多种现有检测方法进行了基准测试，并分析了它们的鲁棒性和泛化能力。此外，我们通过Grad-CAM可视化提供了错误分析，以揭示常见的失败模式和检测偏差。TalkingHeadBench托管在https://huggingface.co/datasets/luchaoqi/TalkingHeadBench上，对所有数据拆分和协议提供开放访问。我们的基准旨在面对快速发展的生成技术，加速对更鲁棒和通用检测模型的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of talking-head deepfake generation fueled by advancedgenerative models has elevated the realism of synthetic videos to a level thatposes substantial risks in domains such as media, politics, and finance.However, current benchmarks for deepfake talking-head detection fail to reflectthis progress, relying on outdated generators and offering limited insight intomodel robustness and generalization. We introduce TalkingHeadBench, acomprehensive multi-model multi-generator benchmark and curated datasetdesigned to evaluate the performance of state-of-the-art detectors on the mostadvanced generators. Our dataset includes deepfakes synthesized by leadingacademic and commercial models and features carefully constructed protocols toassess generalization under distribution shifts in identity and generatorcharacteristics. We benchmark a diverse set of existing detection methods,including CNNs, vision transformers, and temporal models, and analyze theirrobustness and generalization capabilities. In addition, we provide erroranalysis using Grad-CAM visualizations to expose common failure modes anddetector biases. TalkingHeadBench is hosted onhttps://huggingface.co/datasets/luchaoqi/TalkingHeadBench with open access toall data splits and protocols. Our benchmark aims to accelerate researchtowards more robust and generalizable detection models in the face of rapidlyevolving generative techniques.</description>
      <author>example@mail.com (Xinqi Xiong, Prakrut Patel, Qingyuan Fan, Amisha Wadhwa, Sarathy Selvam, Xiao Guo, Luchao Qi, Xiaoming Liu, Roni Sengupta)</author>
      <guid isPermaLink="false">2505.24866v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>MiCRo: Mixture Modeling and Context-aware Routing for Personalized Preference Learning</title>
      <link>http://arxiv.org/abs/2505.24846v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了MiCRo，一个两阶段的框架，用于通过利用大规模二元偏好数据集来增强个性化偏好学习，以解决基于Bradley-Terry模型进行奖励建模的局限性。&lt;h4&gt;背景&lt;/h4&gt;在应用强化学习从人类反馈（RLHF）到对齐大型语言模型（LLMs）时，奖励建模是构建安全基础模型的关键步骤。然而，基于Bradley-Terry（BT）模型的奖励建模假设全局奖励函数，无法捕捉人类偏好的多样性和异质性。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种能够更好地捕捉人类偏好的个性化偏好学习方法，以支持个性化和对立的对齐。&lt;h4&gt;方法&lt;/h4&gt;MiCRo采用两阶段框架：第一阶段引入上下文感知混合建模方法来捕捉多样的人类偏好；第二阶段整合在线路由策略，根据特定上下文动态调整混合权重，以解决模糊性，实现高效和可扩展的偏好适应。&lt;h4&gt;主要发现&lt;/h4&gt;MiCRo能够有效捕捉多样的人类偏好，并在下游个性化方面显著改进。&lt;h4&gt;结论&lt;/h4&gt;MiCRo通过提高个性化偏好学习的能力，为LLMs的个性化和对立对齐提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reward modeling is a key step in building safe foundation models whenapplying reinforcement learning from human feedback (RLHF) to align LargeLanguage Models (LLMs). However, reward modeling based on the Bradley-Terry(BT) model assumes a global reward function, failing to capture the inherentlydiverse and heterogeneous human preferences. Hence, such oversimplificationlimits LLMs from supporting personalization and pluralistic alignment.Theoretically, we show that when human preferences follow a mixturedistribution of diverse subgroups, a single BT model has an irreducible error.While existing solutions, such as multi-objective learning with fine-grainedannotations, help address this issue, they are costly and constrained bypredefined attributes, failing to fully capture the richness of human values.In this work, we introduce MiCRo, a two-stage framework that enhancespersonalized preference learning by leveraging large-scale binary preferencedatasets without requiring explicit fine-grained annotations. In the firststage, MiCRo introduces context-aware mixture modeling approach to capturediverse human preferences. In the second stage, MiCRo integrates an onlinerouting strategy that dynamically adapts mixture weights based on specificcontext to resolve ambiguity, allowing for efficient and scalable preferenceadaptation with minimal additional supervision. Experiments on multiplepreference datasets demonstrate that MiCRo effectively captures diverse humanpreferences and significantly improves downstream personalization.</description>
      <author>example@mail.com (Jingyan Shen, Jiarui Yao, Rui Yang, Yifan Sun, Feng Luo, Rui Pan, Tong Zhang, Han Zhao)</author>
      <guid isPermaLink="false">2505.24846v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>NUC-Net: Non-uniform Cylindrical Partition Network for Efficient LiDAR Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2505.24634v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NUC-Net的非均匀圆柱分割网络，用于解决LiDAR语义分割中的挑战，包括减少计算成本、内存消耗和提高对点云不平衡分布的处理能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基于体素的方法在LiDAR语义分割中应用了均匀分割，但存在计算量大、内存消耗高和未能有效处理点云不平衡分布的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的非均匀圆柱分割网络，以降低计算成本、减少内存消耗并更好地处理点云的不平衡分布。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种名为API的方法，用于非均匀分割径向轴，并生成具有代表性的体素表示；2. 提出了一种非均匀多尺度聚合方法，以提高上下文信息。&lt;h4&gt;主要发现&lt;/h4&gt;NUC-Net在SemanticKITTI和nuScenes数据集上实现了最先进的性能，同时速度更快，训练时间更短，并且能够以4倍的速度训练、2倍的GPU内存减少和3倍的速度提升推理速度。&lt;h4&gt;结论&lt;/h4&gt;NUC-Net是一种通用的LiDAR语义分割组件，显著提高了均匀方法的准确性和效率，并通过理论分析解释了NUC-Net的有效性和点分布对性能的影响。&lt;h4&gt;翻译&lt;/h4&gt;LiDAR语义分割在自动驾驶中起着至关重要的作用。现有的基于体素的方法对3D LiDAR点云应用了均匀分割，以笛卡尔/圆柱坐标形成结构化表示。尽管这些方法表现出令人印象深刻的性能，但现有基于体素的方法在两个方面存在缺点：（1）需要足够大的输入体素分辨率，这带来了大量的计算成本和内存消耗；（2）未能很好地处理LiDAR点云的不平衡点分布。在本文中，我们提出了一种名为NUC-Net的非均匀圆柱分割网络来应对上述挑战。具体来说，我们提出了算术递增区间（API）方法来非均匀分割径向轴，并生成具有代表性的体素表示。此外，我们提出了一种非均匀多尺度聚合方法来提高上下文信息。我们的方法在SemanticKITTI和nuScenes数据集上实现了最先进的性能，具有更快的速度和更少的训练时间。我们的方法可以成为LiDAR语义分割的通用组件，通过4倍的速度训练、2倍的GPU内存减少和3倍的速度提升推理，显著提高了均匀方法的准确性和效率。我们进一步提供了理论分析，以理解NUC的有效性和点分布如何影响性能。代码可在https://github.com/alanWXZ/NUC-Net上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TCSVT.2025.3554182&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR semantic segmentation plays a vital role in autonomous driving.Existing voxel-based methods for LiDAR semantic segmentation apply uniformpartition to the 3D LiDAR point cloud to form a structured representation basedon cartesian/cylindrical coordinates. Although these methods show impressiveperformance, the drawback of existing voxel-based methods remains in twoaspects: (1) it requires a large enough input voxel resolution, which brings alarge amount of computation cost and memory consumption. (2) it does not wellhandle the unbalanced point distribution of LiDAR point cloud. In this paper,we propose a non-uniform cylindrical partition network named NUC-Net to tacklethe above challenges. Specifically, we propose the Arithmetic Progression ofInterval (API) method to non-uniformly partition the radial axis and generatethe voxel representation which is representative and efficient. Moreover, wepropose a non-uniform multi-scale aggregation method to improve contextualinformation. Our method achieves state-of-the-art performance on SemanticKITTIand nuScenes datasets with much faster speed and much less training time. Andour method can be a general component for LiDAR semantic segmentation, whichsignificantly improves both the accuracy and efficiency of the uniformcounterpart by $4 \times$ training faster and $2 \times$ GPU memory reductionand $3 \times$ inference speedup. We further provide theoretical analysistowards understanding why NUC is effective and how point distribution affectsperformance. Code is available at\href{https://github.com/alanWXZ/NUC-Net}{https://github.com/alanWXZ/NUC-Net}.</description>
      <author>example@mail.com (Xuzhi Wang, Wei Feng, Lingdong Kong, Liang Wan)</author>
      <guid isPermaLink="false">2505.24634v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Cross-Modal Knowledge Distillation: A Disentanglement Approach for RGBD Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2505.24361v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CroDiNo-KD的新型跨模态知识蒸馏框架，用于RGBD语义分割，以解决传感器故障或资源限制导致的训练和推理阶段数据模态不匹配问题。&lt;h4&gt;背景&lt;/h4&gt;多模态RGB和深度（RGBD）数据在机器人、自动驾驶和遥感等领域广泛应用。这些数据提供了3D空间上下文，增强了环境感知能力。&lt;h4&gt;目的&lt;/h4&gt;克服传统跨模态知识蒸馏（CMKD）框架在教师架构选择和蒸馏过程选择上的挑战，以提高其在现实场景中的应用。&lt;h4&gt;方法&lt;/h4&gt;CroDiNo-KD通过利用解耦表示、对比学习和解耦数据增强来同时学习单模态RGB和深度模型，旨在通过交互和协作结构化神经网络模型的内部流形。&lt;h4&gt;主要发现&lt;/h4&gt;在三个RGBD数据集上的评估表明，CroDiNo-KD的质量优于其他CMKD框架，并建议重新考虑传统的教师/学生范式，以从多模态数据中提取信息到单模态神经网络。&lt;h4&gt;结论&lt;/h4&gt;CroDiNo-KD是一种有效的跨模态知识蒸馏框架，可以提高RGBD语义分割的性能，并为从多模态数据中提取信息提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal RGB and Depth (RGBD) data are predominant in many domains such asrobotics, autonomous driving and remote sensing. The combination of thesemulti-modal data enhances environmental perception by providing 3D spatialcontext, which is absent in standard RGB images. Although RGBD multi-modal datacan be available to train computer vision models, accessing all sensormodalities during the inference stage may be infeasible due to sensor failuresor resource constraints, leading to a mismatch between data modalitiesavailable during training and inference. Traditional Cross-Modal KnowledgeDistillation (CMKD) frameworks, developed to address this task, are typicallybased on a teacher/student paradigm, where a multi-modal teacher distillsknowledge into a single-modality student model. However, these approaches facechallenges in teacher architecture choices and distillation process selection,thus limiting their adoption in real-world scenarios. To overcome these issues,we introduce CroDiNo-KD (Cross-Modal Disentanglement: a New Outlook onKnowledge Distillation), a novel cross-modal knowledge distillation frameworkfor RGBD semantic segmentation. Our approach simultaneously learnssingle-modality RGB and Depth models by exploiting disentanglementrepresentation, contrastive learning and decoupled data augmentation with theaim to structure the internal manifolds of neural network models throughinteraction and collaboration. We evaluated CroDiNo-KD on three RGBD datasetsacross diverse domains, considering recent CMKD frameworks as competitors. Ourfindings illustrate the quality of CroDiNo-KD, and they suggest reconsideringthe conventional teacher/student paradigm to distill information frommulti-modal data to single-modality neural networks.</description>
      <author>example@mail.com (Roger Ferrod, Cássio F. Dantas, Luigi Di Caro, Dino Ienco)</author>
      <guid isPermaLink="false">2505.24361v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Density Ratio Permutation Tests with connections to distributional shifts and conditional two-sample testing</title>
      <link>http://arxiv.org/abs/2505.24529v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  67 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的假设检验方法，用于进行密度比率的统计推断，并详细介绍了密度比率置换检验（DRPT）。&lt;h4&gt;背景&lt;/h4&gt;在独立数据中，从具有密度函数f和g的分布中抽取数据，并基于固定的密度比率r进行假设检验。&lt;h4&gt;目的&lt;/h4&gt;旨在通过有效的马尔可夫链蒙特卡罗算法，根据r确定的分布来抽取合并数据的置换，生成可交换的样本版本，以验证有限样本的有效性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于积分概率度量（IPM）的测试统计量，并证明了DRPT在轻微的假设下是一致的。在函数类是再生核希尔伯特空间的情况下，引入了Shifted-MMD的推广。对于连续数据，如果g-rf的归一化版本位于Sobolev球中，基于Shifted-MMD建立了DRPT的最小-最大最优性。对于未知位移因子r的情况，使用密度比率估计技术从部分数据中估计r，并推导了基于估计错误的I类错误界限。此外，还展示了如何将DRPT应用于条件双样本测试。&lt;h4&gt;主要发现&lt;/h4&gt;DRPT在模拟和真实世界数据集上的实验验证了理论发现，证明了其在评估建模假设（如重要性权重、协变量偏移等）方面的通用性。&lt;h4&gt;结论&lt;/h4&gt;DRPT是一种有效的工具，可以用于统计推断密度比率，并能够适应条件双样本测试和评估多种建模假设场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce novel hypothesis tests to allow for statistical inference fordensity ratios. More precisely, we introduce the Density Ratio Permutation Test(DRPT) for testing $H_0: g \propto r f$ based on independent data drawn fromdistributions with densities $f$ and $g$, where the hypothesised density ratio$r$ is a fixed function. The proposed test employs an efficient Markov ChainMonte Carlo algorithm to draw permutations of the combined dataset according toa distribution determined by $r$, producing exchangeable versions of the wholesample and thereby establishing finite-sample validity. Regarding the test'sbehaviour under the alternative hypothesis, we begin by demonstrating that ifthe test statistic is chosen as an Integral Probability Metric (IPM), the DRPTis consistent under mild assumptions on the function class that defines theIPM. We then narrow our focus to the setting where the function class is aReproducing Kernel Hilbert Space, and introduce a generalisation of theclassical Maximum Mean Discrepancy (MMD), which we term Shifted-MMD. Forcontinuous data, assuming that a normalised version of $g - rf$ lies in aSobolev ball, we establish the minimax optimality of the DRPT based on theShifted-MMD. We further extend our approach to scenarios with an unknown shiftfactor $r$, estimating it from part of the data using Density Ratio Estimationtechniques, and derive Type-I error bounds based on estimation error.Additionally, we demonstrate how the DRPT can be adapted for conditionaltwo-sample testing, establishing it as a versatile tool for assessing modellingassumptions on importance weights, covariate shifts and related scenarios,which frequently arise in contexts such as transfer learning and causalinference. Finally, we validate our theoretical findings through experiments onboth simulated and real-world datasets.</description>
      <author>example@mail.com (Alberto Bordino, Thomas B. Berrett)</author>
      <guid isPermaLink="false">2505.24529v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>MGS3: A Multi-Granularity Self-Supervised Code Search Framework</title>
      <link>http://arxiv.org/abs/2505.24274v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个多粒度代码搜索框架MGS$^{3}$，旨在提高代码重用性和开发效率，通过自然语言查询检索相关的代码片段。&lt;h4&gt;背景&lt;/h4&gt;尽管现有的自监督代码预训练方法在代码数据量庞大的代码库中取得了显著进展，但它们主要关注利用对比学习将自然语言与函数级别的代码片段对齐，忽视了函数级别代码片段中大量存在的细粒度代码片段，导致在所有粒度级别上性能不理想。&lt;h4&gt;目的&lt;/h4&gt;解决上述问题，提出MGS$^{3}$框架，旨在通过多粒度代码搜索增强软件重用性和开发者生产力。&lt;h4&gt;方法&lt;/h4&gt;首先构建了一个名为MGCodeSearchNet的多粒度代码搜索数据集，包含超过536K对自然语言和代码片段。然后，MGS$^{3}$包含一个层次多粒度表示模块（HMGR），利用句法结构关系进行分层表示，并将细粒度信息聚合到粗粒度表示中。在对比学习阶段，旨在为细粒度代码构建相同粒度的正样本，并引入函数内的负样本。&lt;h4&gt;主要发现&lt;/h4&gt;在代码搜索基准测试中，MGS$^{3}$框架在多个粒度的代码搜索任务中表现出优异的性能，并展示了其模型无关性和与现有预训练代码表示模型的兼容性。&lt;h4&gt;结论&lt;/h4&gt;MGS$^{3}$框架能够有效提高代码搜索性能，有助于提高软件开发效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：为了提高软件的可重用性和开发者的生产效率，代码搜索已经成为一个关键领域，目标是通过自然语言查询检索相关的功能代码片段。尽管在利用代码库中的大量代码数据进行自监督代码预训练方面取得了显著进展，但现有方法主要关注利用对比学习将自然语言与函数级别的代码片段对齐。这些研究忽视了函数级别代码片段中普遍存在的细粒度（如块级和语句级）代码片段的丰富性，导致在所有粒度级别上的性能都不理想。为了解决这个问题，我们首先构建了一个名为MGCodeSearchNet的多粒度代码搜索数据集，其中包含536K+对自然语言和代码片段。随后，我们引入了一种新颖的多粒度自监督对比学习代码搜索框架（MGS$^{3}$）。首先，MGS$^{3}$包含一个层次多粒度表示模块（HMGR），它利用句法结构关系进行分层表示，并将细粒度信息聚合到粗粒度表示中。在对比学习阶段，我们努力为细粒度代码构建相同粒度的正样本，并引入函数内的负样本。最后，我们在各种粒度的代码搜索基准测试中进行了广泛实验，证明了该框架在多个粒度的代码搜索任务中表现出色。这些实验还展示了其模型无关性和与现有预训练代码表示模型的兼容性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the pursuit of enhancing software reusability and developer productivity,code search has emerged as a key area, aimed at retrieving code snippetsrelevant to functionalities based on natural language queries. Despitesignificant progress in self-supervised code pre-training utilizing the vastamount of code data in repositories, existing methods have primarily focused onleveraging contrastive learning to align natural language with function-levelcode snippets. These studies have overlooked the abundance of fine-grained(such as block-level and statement-level) code snippets prevalent within thefunction-level code snippets, which results in suboptimal performance acrossall levels of granularity. To address this problem, we first construct amulti-granularity code search dataset called MGCodeSearchNet, which contains536K+ pairs of natural language and code snippets. Subsequently, we introduce anovel Multi-Granularity Self-Supervised contrastive learning code Searchframework (MGS$^{3}$}). First, MGS$^{3}$ features a HierarchicalMulti-Granularity Representation module (HMGR), which leverages syntacticstructural relationships for hierarchical representation and aggregatesfine-grained information into coarser-grained representations. Then, during thecontrastive learning phase, we endeavor to construct positive samples of thesame granularity for fine-grained code, and introduce in-function negativesamples for fine-grained code. Finally, we conduct extensive experiments oncode search benchmarks across various granularities, demonstrating that theframework exhibits outstanding performance in code search tasks of multiplegranularities. These experiments also showcase its model-agnostic nature andcompatibility with existing pre-trained code representation models.</description>
      <author>example@mail.com (Rui Li, Junfeng Kang, Qi Liu, Liyang He, Zheng Zhang, Yunhao Sha, Linbo Zhu, Zhenya Huang)</author>
      <guid isPermaLink="false">2505.24274v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Anomaly Detection and Improvement of Clusters using Enhanced K-Means Algorithm</title>
      <link>http://arxiv.org/abs/2505.24365v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE ICCCSP&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一的方法，用于数据集中的聚类细化和异常检测。&lt;h4&gt;背景&lt;/h4&gt;本文旨在解决数据集中聚类精炼和异常检测的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的算法，以降低N个聚类的内部方差，直至达到全局最小值，从而得到比标准k-means算法更紧密的聚类。&lt;h4&gt;方法&lt;/h4&gt;该算法通过迭代减少内部方差，并使用轮廓系数、Calinski-Harabasz指数和Davies-Bouldin指数等内在度量来评估方法。同时，通过识别导致显著方差增加的点，将其扩展到异常检测。&lt;h4&gt;主要发现&lt;/h4&gt;在合成数据和UCI乳腺癌和UCI葡萄酒质量数据集上，该方法在合成数据集上实现了18.7%的方差减少，在葡萄酒质量数据集上实现了88.1%的方差减少，并在葡萄酒质量数据集上提高了22.5%的准确性和20.8%的F1分数。&lt;h4&gt;结论&lt;/h4&gt;该算法在聚类细化和异常检测方面具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a unified approach to cluster refinement and anomaly detection in datasets. We propose a novel algorithm that iteratively reduces the intra-cluster variance of N clusters until a global minimum is reached, yielding tighter clusters than the standard k-means algorithm. We evaluate the method using intrinsic measures for unsupervised learning, including the silhouette coefficient, Calinski-Harabasz index, and Davies-Bouldin index, and extend it to anomaly detection by identifying points whose assignment causes a significant variance increase. External validation on synthetic data and the UCI Breast Cancer and UCI Wine Quality datasets employs the Jaccard similarity score, V-measure, and F1 score. Results show variance reductions of 18.7% and 88.1% on the synthetic and Wine Quality datasets, respectively, along with accuracy and F1 score improvements of 22.5% and 20.8% on the Wine Quality dataset.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a unified approach to cluster refinement and anomalydetection in datasets. We propose a novel algorithm that iteratively reducesthe intra-cluster variance of N clusters until a global minimum is reached,yielding tighter clusters than the standard k-means algorithm. We evaluate themethod using intrinsic measures for unsupervised learning, including thesilhouette coefficient, Calinski-Harabasz index, and Davies-Bouldin index, andextend it to anomaly detection by identifying points whose assignment causes asignificant variance increase. External validation on synthetic data and theUCI Breast Cancer and UCI Wine Quality datasets employs the Jaccard similarityscore, V-measure, and F1 score. Results show variance reductions of 18.7% and88.1% on the synthetic and Wine Quality datasets, respectively, along withaccuracy and F1 score improvements of 22.5% and 20.8% on the Wine Qualitydataset.</description>
      <author>example@mail.com (Vardhan Shorewala, Shivam Shorewala)</author>
      <guid isPermaLink="false">2505.24365v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>R3DM: Enabling Role Discovery and Diversity Through Dynamics Models in Multi-agent Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2505.24265v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, To appear in the International Conference of Machine  Learning (ICML 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为R3DM的新颖的基于角色的多智能体强化学习框架，用于提升复杂任务的合作学习。&lt;h4&gt;背景&lt;/h4&gt;多智能体强化学习在交通控制、自动驾驶和机器人等领域取得了显著进展，而基于角色的方法旨在通过角色自然出现来增强协调学习。&lt;h4&gt;目的&lt;/h4&gt;提出的方法旨在通过让智能体的角色塑造其未来行为，从而实现有效的协调。&lt;h4&gt;方法&lt;/h4&gt;R3DM通过最大化智能体角色、观察到的轨迹和预期未来行为之间的互信息来学习涌现的角色。它通过对比学习过去的轨迹来优化目标，首先推导出中间角色，这些角色通过学习到的动态模型塑造内在奖励，以促进不同角色未来行为的多样性。&lt;h4&gt;主要发现&lt;/h4&gt;在SMAC和SMACv2环境中进行的基准测试表明，R3DM优于最先进的MARL方法，提高了多智能体协调，使得胜率提高了多达20%。&lt;h4&gt;结论&lt;/h4&gt;R3DM框架通过考虑智能体角色的未来影响，在多智能体强化学习中实现了更好的协调和性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-agent reinforcement learning (MARL) has achieved significant progressin large-scale traffic control, autonomous vehicles, and robotics. Drawinginspiration from biological systems where roles naturally emerge to enablecoordination, role-based MARL methods have been proposed to enhance cooperationlearning for complex tasks. However, existing methods exclusively derive rolesfrom an agent's past experience during training, neglecting their influence onits future trajectories. This paper introduces a key insight: an agent's roleshould shape its future behavior to enable effective coordination. Hence, wepropose Role Discovery and Diversity through Dynamics Models (R3DM), a novelrole-based MARL framework that learns emergent roles by maximizing the mutualinformation between agents' roles, observed trajectories, and expected futurebehaviors. R3DM optimizes the proposed objective through contrastive learningon past trajectories to first derive intermediate roles that shape intrinsicrewards to promote diversity in future behaviors across different roles througha learned dynamics model. Benchmarking on SMAC and SMACv2 environmentsdemonstrates that R3DM outperforms state-of-the-art MARL approaches, improvingmulti-agent coordination to increase win rates by up to 20%.</description>
      <author>example@mail.com (Harsh Goel, Mohammad Omama, Behdad Chalaki, Vaishnav Tadiparthi, Ehsan Moradi Pari, Sandeep Chinchali)</author>
      <guid isPermaLink="false">2505.24265v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>GATE: General Arabic Text Embedding for Enhanced Semantic Textual Similarity with Matryoshka Representation Learning and Hybrid Loss Training</title>
      <link>http://arxiv.org/abs/2505.24581v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GATE模型，该模型在MTEB基准测试中在语义文本相似度任务上取得了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;由于缺乏高质量的数据集和预训练模型，阿拉伯语在语义文本相似度（STS）领域的的研究有限。&lt;h4&gt;目的&lt;/h4&gt;提出GATE模型，旨在提高阿拉伯语语义相似度在文本检索、聚类和语义关系理解等应用中的准确性。&lt;h4&gt;方法&lt;/h4&gt;GATE模型利用Matryoshka表示学习方法和混合损失训练方法，结合阿拉伯语三元组数据集进行自然语言推理。&lt;h4&gt;主要发现&lt;/h4&gt;GATE模型在语义文本相似度基准测试中优于包括OpenAI在内的更大模型，性能提高了20-25%，有效捕捉了阿拉伯语的独特语义细微差别。&lt;h4&gt;结论&lt;/h4&gt;GATE模型为阿拉伯语语义文本相似度研究提供了新的解决方案，并证明了其在性能上的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic textual similarity (STS) is a critical task in natural languageprocessing (NLP), enabling applications in retrieval, clustering, andunderstanding semantic relationships between texts. However, research in thisarea for the Arabic language remains limited due to the lack of high-qualitydatasets and pre-trained models. This scarcity of resources has restricted theaccurate evaluation and advance of semantic similarity in Arabic text. Thispaper introduces General Arabic Text Embedding (GATE) models that achievestate-of-the-art performance on the Semantic Textual Similarity task within theMTEB benchmark. GATE leverages Matryoshka Representation Learning and a hybridloss training approach with Arabic triplet datasets for Natural LanguageInference, which are essential for enhancing model performance in tasks thatdemand fine-grained semantic understanding. GATE outperforms larger models,including OpenAI, with a 20-25% performance improvement on STS benchmarks,effectively capturing the unique semantic nuances of Arabic.</description>
      <author>example@mail.com (Omer Nacar, Anis Koubaa, Serry Sibaee, Yasser Al-Habashi, Adel Ammar, Wadii Boulila)</author>
      <guid isPermaLink="false">2505.24581v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Biological Pathway Guided Gene Selection Through Collaborative Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2505.24155v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31st SIGKDD Conference on Knowledge Discovery and Data Mining (KDD  2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的两阶段框架，用于在基因选择中整合统计选择和生物通路知识，以解决传统方法在识别预测基因时忽视复杂生物通路和调控网络的问题。&lt;h4&gt;背景&lt;/h4&gt;基因选择在高维基因组数据中对于理解疾病机制和改善治疗效果至关重要。传统方法在识别预测基因时有效，但往往忽略复杂的生物通路和调控网络，导致不稳定的生物无关特征。&lt;h4&gt;目的&lt;/h4&gt;为了解决传统方法在基因选择中的局限性，提出一种新的方法来整合生物通路知识，同时保持统计的严谨性。&lt;h4&gt;方法&lt;/h4&gt;该方法采用多智能体强化学习（MARL）来整合统计选择与生物通路知识。首先，引入了一种通路引导的预过滤策略，结合多种统计方法和KEGG通路信息进行初始降维。接着，在细化选择阶段，将基因建模为MARL框架中的协作智能体，每个智能体优化预测能力和生物相关性。框架通过基于图神经网络的州状态表示、结合预测性能与基因中心性和通路覆盖度的奖励机制，以及使用共享记忆和集中式评判组件的协作学习策略来整合通路知识。&lt;h4&gt;主要发现&lt;/h4&gt;在多个基因表达数据集上的广泛实验表明，与传统的基因选择方法相比，该方法显著提高了预测准确性和生物可解释性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在基因选择中有效地整合了生物通路知识，提高了预测的准确性和生物可解释性，为理解疾病机制和改善治疗效果提供了新的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gene selection in high-dimensional genomic data is essential forunderstanding disease mechanisms and improving therapeutic outcomes.Traditional feature selection methods effectively identify predictive genes butoften ignore complex biological pathways and regulatory networks, leading tounstable and biologically irrelevant signatures. Prior approaches, such asLasso-based methods and statistical filtering, either focus solely onindividual gene-outcome associations or fail to capture pathway-levelinteractions, presenting a key challenge: how to integrate biological pathwayknowledge while maintaining statistical rigor in gene selection? To addressthis gap, we propose a novel two-stage framework that integrates statisticalselection with biological pathway knowledge using multi-agent reinforcementlearning (MARL). First, we introduce a pathway-guided pre-filtering strategythat leverages multiple statistical methods alongside KEGG pathway informationfor initial dimensionality reduction. Next, for refined selection, we modelgenes as collaborative agents in a MARL framework, where each agent optimizesboth predictive power and biological relevance. Our framework incorporatespathway knowledge through Graph Neural Network-based state representations, areward mechanism combining prediction performance with gene centrality andpathway coverage, and collaborative learning strategies using shared memory anda centralized critic component. Extensive experiments on multiple geneexpression datasets demonstrate that our approach significantly improves bothprediction accuracy and biological interpretability compared to traditionalmethods.</description>
      <author>example@mail.com (Ehtesamul Azim, Dongjie Wang, Tae Hyun Hwang, Yanjie Fu, Wei Zhang)</author>
      <guid isPermaLink="false">2505.24155v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning from CAD Software</title>
      <link>http://arxiv.org/abs/2505.24838v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为VideoCAD的工程UI交互学习新方法，旨在解决计算机辅助设计（CAD）中UI交互学习的问题。&lt;h4&gt;背景&lt;/h4&gt;CAD是一个耗时且复杂的流程，需要用户与复杂的3D界面进行精确的长期交互。现有的AI驱动UI代理在处理短期低复杂度任务方面表现良好，但未能满足专业工程工具的需求。&lt;h4&gt;目的&lt;/h4&gt;通过创建一个大规模合成数据集，提高工程UI交互学习的复杂度和时间跨度，从而更好地支持专业CAD工具的交互学习。&lt;h4&gt;方法&lt;/h4&gt;VideoCAD是一个包含超过41K个标注视频记录的大规模合成数据集，通过自动化框架从人工CAD设计中收集高保真UI动作数据生成。VideoCADFormer模型被提出，用于直接从视频中学习CAD交互，并在多个行为克隆基线中表现优异。&lt;h4&gt;主要发现&lt;/h4&gt;VideoCAD提供了比现有数据集高一个数量级的UI交互学习复杂性，其时间跨度是其他数据集的20倍。VideoCAD的两个重要下游应用是学习专业精密度3D CAD工具的UI交互和一个视觉问答（VQA）基准，用于评估多模态大型语言模型的空间推理和视频理解能力。&lt;h4&gt;结论&lt;/h4&gt;VideoCADFormer和从VideoCAD派生的VQA基准揭示了基于视频的UI理解中的关键挑战，包括精确动作定位、多模态和空间推理以及长期依赖关系的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computer-Aided Design (CAD) is a time-consuming and complex process,requiring precise, long-horizon user interactions with intricate 3D interfaces.While recent advances in AI-driven user interface (UI) agents show promise,most existing datasets and methods focus on short, low-complexity tasks inmobile or web applications, failing to capture the demands of professionalengineering tools. In this work, we introduce VideoCAD, the first attempt atengineering UI interaction learning for precision tasks. Specifically, VideoCADis a large-scale synthetic dataset consisting of over 41K annotated videorecordings of CAD operations, generated using an automated framework forcollecting high-fidelity UI action data from human-made CAD designs. Comparedto existing datasets, VideoCAD offers an order of magnitude higher complexityin UI interaction learning for real-world engineering tasks, having up to a 20xlonger time horizon than other datasets. We show two important downstreamapplications of VideoCAD: learning UI interactions from professional precision3D CAD tools and a visual question-answering (VQA) benchmark designed toevaluate multimodal large language models' (LLM) spatial reasoning and videounderstanding abilities. To learn the UI interactions, we proposeVideoCADFormer - a state-of-the-art model in learning CAD interactions directlyfrom video, which outperforms multiple behavior cloning baselines. BothVideoCADFormer and the VQA benchmark derived from VideoCAD reveal keychallenges in the current state of video-based UI understanding, including theneed for precise action grounding, multi-modal and spatial reasoning, andlong-horizon dependencies.</description>
      <author>example@mail.com (Brandon Man, Ghadi Nehme, Md Ferdous Alam, Faez Ahmed)</author>
      <guid isPermaLink="false">2505.24838v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Bi-Manual Joint Camera Calibration and Scene Representation</title>
      <link>http://arxiv.org/abs/2505.24819v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Bi-JCR的双手操作关节校准和表示框架，用于简化多机器人操作臂的相机校准过程，通过无需拍摄校准标记的RGB图像集，实现多机器人操作臂的相机外参、机器人间相对位姿以及共享工作空间的统一、尺度一致的3D表示的估计。&lt;h4&gt;背景&lt;/h4&gt;在机器人操作中，特别是双手操作，常常需要在多个机器人操作臂上安装多个相机，并在机器人产生运动或构建环境表示之前对这些相机进行校准。&lt;h4&gt;目的&lt;/h4&gt;目的是通过引入Bi-JCR框架，使多个安装有相机的机器人操作臂能够绕过拍摄校准标记的图像，从而简化相机校准过程。&lt;h4&gt;方法&lt;/h4&gt;Bi-JCR利用3D基础模型进行密集的无标记多视角对应，联合估计每个相机到其末端执行器的外参、操作臂之间的相对位姿以及共享工作空间的统一、尺度一致的3D表示。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够从同一捕获的RGB图像集中联合估计上述参数，并支持碰撞检测和语义分割，以促进下游的双手操作协调任务。&lt;h4&gt;结论&lt;/h4&gt;通过在多种桌面环境中进行实证评估，证明了Bi-JCR的鲁棒性和在多种下游任务中的适用性。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we introduce a framework called Bi-JCR for bimanual joint calibration and representation. This framework simplifies the calibration process for multiple robot manipulators equipped with cameras by avoiding the need to capture images of calibration markers. By leveraging 3D foundation models for dense, marker-free multi-view correspondence, Bi-JCR jointly estimates the extrinsic transformation from each camera to its end-effector, the inter-arm relative poses between manipulators, and a unified, scale-consistent 3D representation of the shared workspace, all from the same captured RGB image sets. This representation, jointly constructed from images captured by cameras on both manipulators, lives in a common coordinate frame and supports collision checking and semantic segmentation to facilitate downstream bimanual coordination tasks. The robustness of Bi-JCR is empirically evaluated on a variety of tabletop environments, and its applicability on a variety of downstream tasks is demonstrated.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robot manipulation, especially bimanual manipulation, often requires settingup multiple cameras on multiple robot manipulators. Before robot manipulatorscan generate motion or even build representations of their environments, thecameras rigidly mounted to the robot need to be calibrated. Camera calibrationis a cumbersome process involving collecting a set of images, with eachcapturing a pre-determined marker. In this work, we introduce the Bi-ManualJoint Calibration and Representation Framework (Bi-JCR). Bi-JCR enablesmultiple robot manipulators, each with cameras mounted, to circumvent takingimages of calibration markers. By leveraging 3D foundation models for dense,marker-free multi-view correspondence, Bi-JCR jointly estimates: (i) theextrinsic transformation from each camera to its end-effector, (ii) theinter-arm relative poses between manipulators, and (iii) a unified,scale-consistent 3D representation of the shared workspace, all from the samecaptured RGB image sets. The representation, jointly constructed from imagescaptured by cameras on both manipulators, lives in a common coordinate frameand supports collision checking and semantic segmentation to facilitatedownstream bimanual coordination tasks. We empirically evaluate the robustnessof Bi-JCR on a variety of tabletop environments, and demonstrate itsapplicability on a variety of downstream tasks.</description>
      <author>example@mail.com (Haozhan Tang, Tianyi Zhang, Matthew Johnson-Roberson, Weiming Zhi)</author>
      <guid isPermaLink="false">2505.24819v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Practical Bayes-Optimal Membership Inference Attacks</title>
      <link>http://arxiv.org/abs/2505.24089v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages plus 13 pages of appendices&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了针对独立同分布数据和图结构数据的成员推理攻击（MIAs），并基于Sablayrolles等人的贝叶斯决策理论框架，推导出针对图神经网络节点级别MIAs的贝叶斯最优推理规则。同时，介绍了BASE和G-BASE两种贝叶斯最优攻击的近似方法，并在性能上优于现有的基于分类器的节点级别MIA攻击。BASE方法在非图数据上的性能也与最先进的MIA方法相当，但计算成本更低。此外，证明了BASE和RMIA在特定超参数设置下是等价的，为RMIA攻击提供了贝叶斯最优的理论依据。&lt;h4&gt;背景&lt;/h4&gt;成员推理攻击（MIAs）是一种针对数据集成员身份的攻击方法，本文针对独立同分布数据和图结构数据进行了研究。&lt;h4&gt;目的&lt;/h4&gt;开发针对独立同分布数据和图结构数据的成员推理攻击，并推导出针对图神经网络的贝叶斯最优推理规则。&lt;h4&gt;方法&lt;/h4&gt;基于贝叶斯决策理论框架，推导贝叶斯最优推理规则，并提出了BASE和G-BASE两种贝叶斯最优攻击的近似方法。&lt;h4&gt;主要发现&lt;/h4&gt;BASE和G-BASE在性能上优于现有的基于分类器的节点级别MIA攻击，BASE在非图数据上的性能也与最先进的MIA方法相当，计算成本更低。BASE和RMIA在特定超参数设置下是等价的。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和理论为成员推理攻击提供了新的思路，并对图结构数据的攻击提出了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;We develop practical and theoretically grounded membership inference attacks (MIAs) against both independent and identically distributed (i.i.d.) data and graph-structured data. Building on the Bayesian decision-theoretic framework of Sablayrolles et al., we derive the Bayes-optimal membership inference rule for node-level MIAs against graph neural networks, addressing key open questions about optimal query strategies in the graph setting. We introduce BASE and G-BASE, computationally efficient approximations of the Bayes-optimal attack. G-BASE achieves superior performance compared to previously proposed classifier-based node-level MIA attacks. BASE, which is also applicable to non-graph data, matches or exceeds the performance of prior state-of-the-art MIAs, such as LiRA and RMIA, at a significantly lower computational cost. Finally, we show that BASE and RMIA are equivalent under a specific hyperparameter setting, providing a principled, Bayes-optimal justification for the RMIA attack.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We develop practical and theoretically grounded membership inference attacks(MIAs) against both independent and identically distributed (i.i.d.) data andgraph-structured data. Building on the Bayesian decision-theoretic framework ofSablayrolles et al., we derive the Bayes-optimal membership inference rule fornode-level MIAs against graph neural networks, addressing key open questionsabout optimal query strategies in the graph setting. We introduce BASE andG-BASE, computationally efficient approximations of the Bayes-optimal attack.G-BASE achieves superior performance compared to previously proposedclassifier-based node-level MIA attacks. BASE, which is also applicable tonon-graph data, matches or exceeds the performance of prior state-of-the-artMIAs, such as LiRA and RMIA, at a significantly lower computational cost.Finally, we show that BASE and RMIA are equivalent under a specifichyperparameter setting, providing a principled, Bayes-optimal justification forthe RMIA attack.</description>
      <author>example@mail.com (Marcus Lassila, Johan Östman, Khac-Hoang Ngo, Alexandre Graell i Amat)</author>
      <guid isPermaLink="false">2505.24089v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Learning reusable concepts across different egocentric video understanding tasks</title>
      <link>http://arxiv.org/abs/2505.24690v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Extended abstract derived from arXiv:2502.02487. Presented at the  Second Joint Egocentric Vision (EgoVis) Workshop (CVPR 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Hier-EgoPack，一个能够创建一系列任务视角的统一框架，这些视角可以在下游任务中迁移，并作为额外洞察的潜在来源，就像机器人可以携带并使用的一套技能。&lt;h4&gt;背景&lt;/h4&gt;人类对视频流中描绘的人类活动的理解是多方面的：在很短的时间内，我们可以把握正在发生的事情，识别场景中对象的相关性和相互作用，并预测接下来将要发生的事情。&lt;h4&gt;目的&lt;/h4&gt;赋予自主系统这样的整体感知能力，学习如何关联不同任务的概念和抽象知识，以及在学习新技能时利用任务协同是至关重要的。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种新的框架，称为Hier-EgoPack，旨在实现上述目标。&lt;h4&gt;主要发现&lt;/h4&gt;Hier-EgoPack能够创建可以跨任务迁移的任务视角，并提供额外的洞察。&lt;h4&gt;结论&lt;/h4&gt;Hier-EgoPack是一个潜在的技能背包，机器人可以在需要时使用。&lt;h4&gt;翻译&lt;/h4&gt;我们的理解视频流中描述的人类活动是多方面的：在短短几秒钟内，我们可以理解正在发生的事情，识别场景中对象的相关性和相互作用，并预测接下来将要发生的事情。为了赋予自主系统这样的整体感知能力，学习如何关联不同任务的概念和抽象知识，以及在学习新技能时利用任务协同是至关重要的。在本文中，我们介绍了一种统一框架，称为Hier-EgoPack，它能够创建一系列任务视角，这些视角可以在下游任务中迁移，并作为额外洞察的潜在来源，就像机器人可以携带并使用的一套技能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Our comprehension of video streams depicting human activities is naturallymultifaceted: in just a few moments, we can grasp what is happening, identifythe relevance and interactions of objects in the scene, and forecast what willhappen soon, everything all at once. To endow autonomous systems with suchholistic perception, learning how to correlate concepts, abstract knowledgeacross diverse tasks, and leverage tasks synergies when learning novel skillsis essential. In this paper, we introduce Hier-EgoPack, a unified frameworkable to create a collection of task perspectives that can be carried acrossdownstream tasks and used as a potential source of additional insights, as abackpack of skills that a robot can carry around and use when needed.</description>
      <author>example@mail.com (Simone Alberto Peirone, Francesca Pistilli, Antonio Alliegro, Tatiana Tommasi, Giuseppe Averta)</author>
      <guid isPermaLink="false">2505.24690v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Attractor learning for spatiotemporally chaotic dynamical systems using echo state networks with transfer learning</title>
      <link>http://arxiv.org/abs/2505.24099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了回声状态网络（ESNs）在广义库尔莫托-西瓦辛斯基（gKS）方程预测能力，这是一种具有时空混沌的非线性偏微分方程。通过结合迁移学习，提出了一种新方法来提升ESNs在不同参数范围内的预测性能，重点关注预测由变化色散关系或空间域长度引起的gKS模型长期统计模式的变化，并成功捕捉了潜在混沌吸引子的变化。&lt;h4&gt;背景&lt;/h4&gt;gKS方程是一种展示时空混沌的非线性偏微分方程。&lt;h4&gt;目的&lt;/h4&gt;目的是通过引入迁移学习来提升ESNs在不同参数范围内的预测性能。&lt;h4&gt;方法&lt;/h4&gt;采用了一种结合ESNs与迁移学习的方法，用于预测gKS模型长期统计模式的变化。&lt;h4&gt;主要发现&lt;/h4&gt;研究重点关注预测由变化色散关系或空间域长度引起的gKS模型长期统计模式的变化，并成功捕捉了潜在混沌吸引子的变化。&lt;h4&gt;结论&lt;/h4&gt;通过迁移学习，ESNs能够有效地适应不同的参数设置，并成功预测gKS模型中的混沌吸引子变化。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we explore the predictive capabilities of echo state networks (ESNs) for the generalized Kuramoto-Sivashinsky (gKS) equation, an archetypal nonlinear PDE that exhibits spatiotemporal chaos. We introduce a novel methodology that integrates ESNs with transfer learning, aiming to enhance predictive performance across various parameter regimes of the gKS model. Our research focuses on predicting changes in long-term statistical patterns of the gKS model that result from varying the dispersion relation or the length of the spatial domain. We use transfer learning to adapt ESNs to different parameter settings and successfully capture changes in the underlying chaotic attractor.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we explore the predictive capabilities of echo state networks(ESNs) for the generalized Kuramoto-Sivashinsky (gKS) equation, an archetypalnonlinear PDE that exhibits spatiotemporal chaos. We introduce a novelmethodology that integrates ESNs with transfer learning, aiming to enhancepredictive performance across various parameter regimes of the gKS model. Ourresearch focuses on predicting changes in long-term statistical patterns of thegKS model that result from varying the dispersion relation or the length of thespatial domain. We use transfer learning to adapt ESNs to different parametersettings and successfully capture changes in the underlying chaotic attractor.</description>
      <author>example@mail.com (Mohammad Shah Alam, William Ott, Ilya Timofeyev)</author>
      <guid isPermaLink="false">2505.24099v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Binary Cumulative Encoding meets Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2505.24595v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了通过分类任务来构建时间序列预测回归的方法，提出了一种新的二进制累积编码（BCE）方法，以改进现有方法的不足。&lt;h4&gt;背景&lt;/h4&gt;近年来，时间序列预测的研究探讨了通过分类任务来构建回归的方法。这些方法通过将连续的目标空间离散化并预测固定类别的数据，具有稳定的训练、鲁棒的不确定性建模和与深度学习架构的兼容性。&lt;h4&gt;目的&lt;/h4&gt;提出的方法旨在解决现有方法中忽略目标值的序数结构的问题，并允许模型在分类框架内学习到距离感知的表示。&lt;h4&gt;方法&lt;/h4&gt;引入了BCE，将标量目标表示为单调的二进制向量，以保留顺序和幅度信息。此外，还提出了一种专门针对BCE的卷积神经网络架构，其中包含了残差和扩张卷积，以实现快速和表达的时间建模。&lt;h4&gt;主要发现&lt;/h4&gt;在基准预测数据集上的广泛实验表明，该方法在点预测和概率预测方面均优于广泛使用的方法，同时参数更少，训练更快。&lt;h4&gt;结论&lt;/h4&gt;BCE编码和设计的卷积神经网络架构能够提高时间序列预测的准确性和效率。&lt;h4&gt;翻译&lt;/h4&gt;Recent studies in time series forecasting have explored formulating regression via classification task. By discretizing the continuous target space into bins and predicting over a fixed set of classes, these approaches benefit from stable training, robust uncertainty modeling, and compatibility with modern deep learning architectures. However, most existing methods rely on one-hot encoding that ignores the inherent ordinal structure of the underlying values. As a result, they fail to provide information about the relative distance between predicted and true values during training. In this paper, we propose to address this limitation by introducing binary cumulative encoding (BCE), that represents scalar targets into monotonic binary vectors. This encoding implicitly preserves order and magnitude information, allowing the model to learn distance-aware representations while still operating within a classification framework. We propose a convolutional neural network architecture specifically designed for BCE, incorporating residual and dilated convolutions to enable fast and expressive temporal modeling. Through extensive experiments on benchmark forecasting datasets, we show that our approach outperforms widely used methods in both point and probabilistic forecasting, while requiring fewer parameters and enabling faster training.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies in time series forecasting have explored formulatingregression via classification task. By discretizing the continuous target spaceinto bins and predicting over a fixed set of classes, these approaches benefitfrom stable training, robust uncertainty modeling, and compatibility withmodern deep learning architectures. However, most existing methods rely onone-hot encoding that ignores the inherent ordinal structure of the underlyingvalues. As a result, they fail to provide information about the relativedistance between predicted and true values during training. In this paper, wepropose to address this limitation by introducing binary cumulative encoding(BCE), that represents scalar targets into monotonic binary vectors. Thisencoding implicitly preserves order and magnitude information, allowing themodel to learn distance-aware representations while still operating within aclassification framework. We propose a convolutional neural networkarchitecture specifically designed for BCE, incorporating residual and dilatedconvolutions to enable fast and expressive temporal modeling. Through extensiveexperiments on benchmark forecasting datasets, we show that our approachoutperforms widely used methods in both point and probabilistic forecasting,while requiring fewer parameters and enabling faster training.</description>
      <author>example@mail.com (Andrei Chernov, Vitaliy Pozdnyakov, Ilya Makarov)</author>
      <guid isPermaLink="false">2505.24595v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>BIRD: Behavior Induction via Representation-structure Distillation</title>
      <link>http://arxiv.org/abs/2505.23933v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;BIRD（通过表示结构蒸馏进行行为诱导）是一种灵活的框架，通过匹配学生模型的内部表示结构来转移对齐行为，提高了模型在不同任务或数据分布上的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;将与人类价值观一致的行为（如鲁棒性、公平性和诚实性）转移到不同任务或数据分布的模型上存在挑战，因为在对齐行为中，对齐行为容易在微调过程中丢失，并且收集保留这些行为的特定任务数据成本高昂。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，能够有效地将具有对齐行为（如鲁棒性）的模型转移到新的任务或数据集上。&lt;h4&gt;方法&lt;/h4&gt;提出BIRD框架，通过匹配学生模型的内部表示结构到教师模型的结构，来实现对齐行为的转移。&lt;h4&gt;主要发现&lt;/h4&gt;BIRD在图像分类的分布外鲁棒性方面优于微调、迁移学习和持续学习方法，提高了鲁棒准确率，最高可达16%。即使在教师模型在更简单的数据集上训练，并且比学生模型小25倍的情况下，BIRD仍然有效。在超过400对教师-学生模型的大规模研究中，教师表示的三个可解释和可计算属性（即任务相关性、行为相关性和互补知识）解释了转移成功变化的85%。&lt;h4&gt;结论&lt;/h4&gt;BIRD可以将小型、对齐良好的模型转化为可扩展的对齐种子，消除了在野外部署安全AI系统的一个关键瓶颈。&lt;h4&gt;翻译&lt;/h4&gt;Human-aligned deep learning models exhibit behaviors consistent with human values, such as robustness, fairness, and honesty. Transferring these behavioral properties to models trained on different tasks or data distributions remains challenging: aligned behavior is easily forgotten during fine-tuning, and collecting task-specific data that preserves this behavior can be prohibitively costly. We introduce BIRD (Behavior Induction via Representation-structure Distillation), a flexible framework for transferring aligned behavior by matching the internal representation structure of a student model to that of a teacher. Applied to out-of-distribution robustness in image classification, BIRD outperforms fine-tuning, transfer learning, and continual learning methods, improving robust accuracy by up to 16% over the next strongest baseline. It remains effective even when the teacher is trained on a much simpler dataset and is 25 × smaller than the student. In a large-scale study of over 400 teacher-student pairs, we show that three interpretable and computable properties of the teacher's representations (i.e., task relevance, behavioral relevance, and complementary knowledge) explain up to 85% of the variance in transfer success. These insights offer practical guidance for teacher selection and design. BIRD turns small, well-aligned models into scalable alignment seeds, removing a key bottleneck in deploying safe AI systems in the wild.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human-aligned deep learning models exhibit behaviors consistent with humanvalues, such as robustness, fairness, and honesty. Transferring thesebehavioral properties to models trained on different tasks or datadistributions remains challenging: aligned behavior is easily forgotten duringfine-tuning, and collecting task-specific data that preserves this behavior canbe prohibitively costly. We introduce BIRD (Behavior Induction viaRepresentation-structure Distillation), a flexible framework for transferringaligned behavior by matching the internal representation structure of a studentmodel to that of a teacher. Applied to out-of-distribution robustness in imageclassification, BIRD outperforms fine-tuning, transfer learning, and continuallearning methods, improving robust accuracy by up to 16% over the nextstrongest baseline. It remains effective even when the teacher is trained on amuch simpler dataset and is $25 \times$ smaller than the student. In alarge-scale study of over 400 teacher-student pairs, we show that threeinterpretable and computable properties of the teacher's representations (i.e.,task relevance, behavioral relevance, and complementary knowledge) explain upto 85% of the variance in transfer success. These insights offer practicalguidance for teacher selection and design. BIRD turns small, well-alignedmodels into scalable alignment seeds, removing a key bottleneck in deployingsafe AI systems in the wild.</description>
      <author>example@mail.com (Galen Pogoncheff, Michael Beyeler)</author>
      <guid isPermaLink="false">2505.23933v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Two-stage MCMC for Fast Bayesian Inference of Large Spatio-temporal Ordinal Data, with Application to US Drought</title>
      <link>http://arxiv.org/abs/2505.24594v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种适用于大型数据集的贝叶斯时空模型拟合方法，通过两个阶段的算法来处理高维时空数据。&lt;h4&gt;背景&lt;/h4&gt;高维时空数据在拟合时空模型时面临计算挑战，数据依赖性强，且涉及大量观测值。&lt;h4&gt;目的&lt;/h4&gt;提出一种适用于有序响应变量的贝叶斯时空模型拟合方法，避免过度简化的模型。&lt;h4&gt;方法&lt;/h4&gt;采用两阶段算法：第一阶段独立地建模空间位置，捕捉时间依赖性，并支持并行计算；第二阶段从第一阶段的后验分布中重采样，引入空间依赖性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了快速贝叶斯推理，能够在计算上对大型数据集是可行的，并保持了后验分布的完整性。&lt;h4&gt;结论&lt;/h4&gt;该方法相比单阶段模型拟合在计算上具有显著优势，并适用于大型时空数据集。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a two-stage algorithm for fitting Bayesian spatio-temporal models to large datasets when the response variable is ordinal, addressing the computational challenges of high-dimensional spatio-temporal data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High dimensional space-time data pose known computational challenges whenfitting spatio-temporal models. Such data show dependence across severaldimensions of space as well as in time, and can easily involve hundreds ofthousands of observations. Many spatio-temporal models result in a dependencestructure across all observations and can be fit only at a substantialcomputational cost, arising from dense matrix inversion, high dimensionalparameter spaces, poor mixing in Markov Chain Monte Carlo, or the impossibilityof utilizing parallel computing due to a lack of independence anywhere in themodel fitting process. These computational challenges are exacerbated when theresponse variable is ordinal, and especially as the number of orderedcategories grows. Some spatio-temporal models achieve computational feasibilityfor large datasets but only through overly restrictive model simplifications,which we seek to avoid here. In this paper we demonstrate a two-stage algorithmto fit a Bayesian spatio-temporal model to large datasets when the responsevariable is ordinal. The first stage models locations independently in space,capturing temporal dependence, and can be run in parallel. The second stageresamples from the first stage posterior distributions with an acceptanceprobability computed to impose spatial dependence from the full spatio-temporalmodel. The result is fast Bayesian inference which samples from the fullspatio-temporal posterior and is computationally feasible even for largedatasets. We quantify the substantial computational gains our approachachieves, and demonstrate the preservation of the posterior distribution ascompared to the more costly single-stage model fit. We apply our approach to alarge spatio-temporal drought dataset in the United States, a dataset too largefor many existing spatio-temporal methods.</description>
      <author>example@mail.com (Staci Hepler, Rob Erhardt)</author>
      <guid isPermaLink="false">2505.24594v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>AFLoRA: Adaptive Federated Fine-Tuning of Large Language Models with Resource-Aware Low-Rank Adaption</title>
      <link>http://arxiv.org/abs/2505.24773v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AFLoRA的联邦微调框架，用于在异构和受限的资源环境中高效地调整大型语言模型。&lt;h4&gt;背景&lt;/h4&gt;联邦微调是一种使用分布式数据来适应下游任务的可行方法，但在实际部署中，由于客户端的计算和通信需求高，以及数据异构性，存在挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在解决联邦微调中计算和通信开销大、数据异构性问题，提高大型语言模型的适应性和效率。&lt;h4&gt;方法&lt;/h4&gt;AFLoRA通过解耦共享和客户端特定更新来减少开销，利用对角矩阵进行秩剪枝以更好地利用本地资源，并采用秩感知聚合与公开数据细化来增强数据异构性下的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，AFLoRA在准确性和效率方面均优于现有方法，为实际环境中高效的大语言模型适应提供了可行的解决方案。&lt;h4&gt;结论&lt;/h4&gt;AFLoRA是一个有效的联邦微调框架，适用于在异构环境中对大型语言模型进行高效调整。&lt;h4&gt;翻译&lt;/h4&gt;Federated fine-tuning has emerged as a promising approach to adapt foundation models to downstream tasks using decentralized data. However, real-world deployment remains challenging due to the high computational and communication demands of fine-tuning Large Language Models (LLMs) on clients with data and system resources that are heterogeneous and constrained. In such settings, the global model's performance is often bottlenecked by the weakest clients and further degraded by the non-IID nature of local data. Although existing methods leverage parameter-efficient techniques such as Low-Rank Adaptation (LoRA) to reduce communication and computation overhead, they often fail to simultaneously ensure accurate aggregation of low-rank updates and maintain low system costs, thereby hindering overall performance. To address these challenges, we propose AFLoRA, an adaptive and lightweight federated fine-tuning framework for LLMs. AFLoRA decouples shared and client-specific updates to reduce overhead and improve aggregation accuracy, incorporates diagonal matrix-based rank pruning to better utilize local resources, and employs rank-aware aggregation with public data refinement to strengthen generalization under data heterogeneity. Extensive experiments demonstrate that AFLoRA outperforms state-of-the-art methods in both accuracy and efficiency, providing a practical solution for efficient LLM adaptation in heterogeneous environments in the real world.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated fine-tuning has emerged as a promising approach to adapt foundationmodels to downstream tasks using decentralized data. However, real-worlddeployment remains challenging due to the high computational and communicationdemands of fine-tuning Large Language Models (LLMs) on clients with data andsystem resources that are heterogeneous and constrained. In such settings, theglobal model's performance is often bottlenecked by the weakest clients andfurther degraded by the non-IID nature of local data. Although existing methodsleverage parameter-efficient techniques such as Low-Rank Adaptation (LoRA) toreduce communication and computation overhead, they often fail tosimultaneously ensure accurate aggregation of low-rank updates and maintain lowsystem costs, thereby hindering overall performance. To address thesechallenges, we propose AFLoRA, an adaptive and lightweight federatedfine-tuning framework for LLMs. AFLoRA decouples shared and client-specificupdates to reduce overhead and improve aggregation accuracy, incorporatesdiagonal matrix-based rank pruning to better utilize local resources, andemploys rank-aware aggregation with public data refinement to strengthengeneralization under data heterogeneity. Extensive experiments demonstrate thatAFLoRA outperforms state-of-the-art methods in both accuracy and efficiency,providing a practical solution for efficient LLM adaptation in heterogeneousenvironments in the real world.</description>
      <author>example@mail.com (Yajie Zhou, Xiaoyi Pang, Zhibo Wang)</author>
      <guid isPermaLink="false">2505.24773v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>SPPSFormer: High-quality Superpoint-based Transformer for Roof Plane Instance Segmentation from Point Clouds</title>
      <link>http://arxiv.org/abs/2505.24475v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了Transformer在点云屋顶平面实例分割中的应用，并提出了一种改进的方法来生成高质量的superpoints，以提升Transformer的性能。该方法结合了手工特征和多维特征，设计了新的解码器，并通过后处理优化了预测结果。&lt;h4&gt;背景&lt;/h4&gt;Transformer在点云屋顶平面实例分割中的应用较少，现有的superpoint Transformers由于使用低质量的superpoints而性能有限。&lt;h4&gt;目的&lt;/h4&gt;提高Transformer在点云屋顶平面实例分割中的性能。&lt;h4&gt;方法&lt;/h4&gt;1. 建立了两个高质量superpoints应满足的标准；2. 介绍了相应的两阶段superpoint生成过程；3. 将多维手工特征结合到模型中；4. 设计了一种结合Kolmogorov-Arnold网络和Transformer模块的解码器；5. 使用传统算法进行后处理优化。&lt;h4&gt;主要发现&lt;/h4&gt;1. 新方法在数据集上达到了最先进的性能；2. 模型对训练过程中的平面边界标注不敏感，显著降低了标注负担；3. 除了屋顶类型外，点云密度、密度均匀性和3D点精度对分割性能有显著影响。&lt;h4&gt;结论&lt;/h4&gt;通过引入高质量superpoints、结合手工特征和改进的解码器，可以显著提升Transformer在点云屋顶平面实例分割中的性能，并减轻标注负担。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformers have been seldom employed in point cloud roof plane instancesegmentation, which is the focus of this study, and existing superpointTransformers suffer from limited performance due to the use of low-qualitysuperpoints. To address this challenge, we establish two criteria thathigh-quality superpoints for Transformers should satisfy and introduce acorresponding two-stage superpoint generation process. The superpointsgenerated by our method not only have accurate boundaries, but also exhibitconsistent geometric sizes and shapes, both of which greatly benefit thefeature learning of superpoint Transformers. To compensate for the limitationsof deep learning features when the training set size is limited, we incorporatemultidimensional handcrafted features into the model. Additionally, we design adecoder that combines a Kolmogorov-Arnold Network with a Transformer module toimprove instance prediction and mask extraction. Finally, our network'spredictions are refined using traditional algorithm-based postprocessing. Forevaluation, we annotated a real-world dataset and corrected annotation errorsin the existing RoofN3D dataset. Experimental results show that our methodachieves state-of-the-art performance on our dataset, as well as both theoriginal and reannotated RoofN3D datasets. Moreover, our model is not sensitiveto plane boundary annotations during training, significantly reducing theannotation burden. Through comprehensive experiments, we also identified keyfactors influencing roof plane segmentation performance: in addition to rooftypes, variations in point cloud density, density uniformity, and 3D pointprecision have a considerable impact. These findings underscore the importanceof incorporating data augmentation strategies that account for point cloudquality to enhance model robustness under diverse and challenging conditions.</description>
      <author>example@mail.com (Cheng Zeng, Xiatian Qi, Chi Chen, Kai Sun, Wangle Zhang, Yuxuan Liu, Yan Meng, Bisheng Yang)</author>
      <guid isPermaLink="false">2505.24475v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing the Accuracy of Spatio-Temporal Models for Wind Speed Prediction by Incorporating Bias-Corrected Crowdsourced Data</title>
      <link>http://arxiv.org/abs/2505.24506v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种框架，通过两阶段方法将个人气象站（PWS）数据纳入统计模型，以验证官方气象站数据，从而提高风能潜力的估计准确性。&lt;h4&gt;背景&lt;/h4&gt;高分辨率时空风速数据对于估计地点的风能潜力至关重要。统计模型通常依赖于来自官方气象站的高质量实时数据以提高预测准确性。&lt;h4&gt;目的&lt;/h4&gt;将个人气象站数据整合到统计模型中，以验证官方气象站数据，并提高风能潜力的估计准确性。&lt;h4&gt;方法&lt;/h4&gt;首先，使用再分析数据对PWS风速数据进行偏差校正。其次，实施一个贝叶斯层次时空模型，该模型考虑了PWS数据中的测量误差。&lt;h4&gt;主要发现&lt;/h4&gt;包括偏差校正的PWS数据比仅使用气象站数据提高了预测准确性，平均预测误差降低了7%。结果与流行的再分析产品相当，但与这些数值天气预报模型不同，该方法提供实时数据并提高了不确定性量化。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过结合PWS数据和官方气象站数据，显著提高了风能潜力的估计准确性，尤其适用于官方监测站稀疏的地区。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate high-resolution spatial and temporal wind speed data is critical forestimating the wind energy potential of a location. For real-time wind speedprediction, statistical models typically depend on high-quality (near)real-time data from official meteorological stations to improve forecastingaccuracy. Personal weather stations (PWS) offer an additional source ofreal-time data and broader spatial coverage than offical stations. However,they are not subject to rigorous quality control and may exhibit bias ormeasurement errors. This paper presents a framework for incorporating PWS datainto statistical models for validated official meteorological station data viaa two-stage approach. First, bias correction is performed on PWS wind speeddata using reanalysis data. Second, we implement a Bayesian hierarchicalspatio-temporal model that accounts for varying measurement error in the PWSdata. This enables wind speed prediction across a target area, and isparticularly beneficial for improving predictions in regions sparse in officialmonitoring stations. Our results show that including bias-corrected PWS dataimproves prediction accuracy compared to using meteorological station dataalone, with a 7% reduction in prediction error on average across all sites. Theresults are comparable with popular reanalysis products, but unlike thesenumerical weather models our approach is available in real-time and offersimproved uncertainty quantification.</description>
      <author>example@mail.com (Eamonn Organ, Maeve Upton, Denis Allard, Lionel Benoit, James Sweeney)</author>
      <guid isPermaLink="false">2505.24506v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Primal-Dual Neural Algorithmic Reasoning</title>
      <link>http://arxiv.org/abs/2505.24067v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The 42nd International Conference on Machine Learning, 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于原-对偶范式的通用Neural Algorithmic Reasoning（NAR）框架，用于解决更复杂的难题，并通过实证研究证明了其在多个任务上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;目前NAR研究主要集中在学习多项式时间内可解问题的精确算法，将其扩展到更难问题仍是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够处理更难问题的NAR框架，并提升模型在复杂数据上的推理能力。&lt;h4&gt;方法&lt;/h4&gt;采用原-对偶范式，利用原变量和对偶变量之间的二分表示，将原-对偶算法与图神经网络相结合，并将小实例的最优解引入模型以增强推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;模型不仅能够模拟近似算法，而且在多个任务上超越了它们，表现出对更大和分布外图的良好泛化能力。&lt;h4&gt;结论&lt;/h4&gt;提出的框架具有实际应用价值，可以通过与商业求解器集成并应用于真实世界数据集来展示其效用。&lt;h4&gt;翻译&lt;/h4&gt;Neural Algorithmic Reasoning (NAR) 训练神经网络来模拟经典算法，使得在复杂数据上能够进行结构化和可解释的推理。虽然先前的研究主要集中在学习多项式时间内可解问题的精确算法，但将NAR扩展到更难问题仍然是一个开放挑战。在这项工作中，我们引入了一个基于原-对偶范式的通用NAR框架，这是一种设计高效近似算法的经典方法。通过利用原变量和对偶变量之间的二分表示，我们建立了原-对偶算法与图神经网络之间的对齐。此外，我们通过将小实例的最优解引入模型来极大地增强了模型的推理能力。我们的实证结果表明，我们的模型不仅能够模拟，而且在多个任务上优于近似算法，表现出对更大和分布外图的鲁棒泛化能力。此外，我们通过将其与商业求解器集成并将其应用于真实世界数据集，强调了该框架的实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural Algorithmic Reasoning (NAR) trains neural networks to simulateclassical algorithms, enabling structured and interpretable reasoning overcomplex data. While prior research has predominantly focused on learning exactalgorithms for polynomial-time-solvable problems, extending NAR to harderproblems remains an open challenge. In this work, we introduce a general NARframework grounded in the primal-dual paradigm, a classical method fordesigning efficient approximation algorithms. By leveraging a bipartiterepresentation between primal and dual variables, we establish an alignmentbetween primal-dual algorithms and Graph Neural Networks. Furthermore, weincorporate optimal solutions from small instances to greatly enhance themodel's reasoning capabilities. Our empirical results demonstrate that ourmodel not only simulates but also outperforms approximation algorithms formultiple tasks, exhibiting robust generalization to larger andout-of-distribution graphs. Moreover, we highlight the framework's practicalutility by integrating it with commercial solvers and applying it to real-worlddatasets.</description>
      <author>example@mail.com (Yu He, Ellen Vitercik)</author>
      <guid isPermaLink="false">2505.24067v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>A Mathematical Perspective On Contrastive Learning</title>
      <link>http://arxiv.org/abs/2505.24134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  44 pages, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多模态对比学习方法，用于连接不同的数据模态，特别是图像和文本数据。该方法通过识别一组编码器，每个模态一个，以在共同潜在空间中对齐表示。&lt;h4&gt;背景&lt;/h4&gt;多模态对比学习是连接不同数据模态的方法，其典型例子是连接图像和文本数据。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过优化编码器来定义每个模态条件概率分布，以实现多模态算法如跨模态检索和分类。&lt;h4&gt;方法&lt;/h4&gt;采用了一种框架，该框架将对比学习解释为优化编码器，以定义符合可用数据的条件概率分布。研究还包括引入新的概率损失函数和使用替代指标来衡量共同潜在空间中的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在多元高斯设置中，将潜在空间识别视为低秩矩阵近似问题，从而可以描述损失函数和度量指标在逼近自然统计（如条件均值和协方差）方面的能力。&lt;h4&gt;结论&lt;/h4&gt;引入的框架通过数值实验在多元高斯、标记的MNIST数据集和海洋学中的数据同化应用中得到研究。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种多模态对比学习方法，旨在连接不同数据模态，特别是图像和文本数据。该方法通过识别一组编码器，每个模态一个，以在共同潜在空间中对齐表示。研究包括优化编码器以定义条件概率分布，以及引入新的概率损失函数和使用替代指标来衡量共同潜在空间中的对齐。在多元高斯设置中，将潜在空间识别视为低秩矩阵近似问题，并通过数值实验得到研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal contrastive learning is a methodology for linking different datamodalities; the canonical example is linking image and text data. Themethodology is typically framed as the identification of a set of encoders, onefor each modality, that align representations within a common latent space. Inthis work, we focus on the bimodal setting and interpret contrastive learningas the optimization of (parameterized) encoders that define conditionalprobability distributions, for each modality conditioned on the other,consistent with the available data. This provides a framework for multimodalalgorithms such as crossmodal retrieval, which identifies the mode of one ofthese conditional distributions, and crossmodal classification, which issimilar to retrieval but includes a fine-tuning step to make it task specific.  The framework we adopt also gives rise to crossmodal generative models. Thisprobabilistic perspective suggests two natural generalizations of contrastivelearning: the introduction of novel probabilistic loss functions, and the useof alternative metrics for measuring alignment in the common latent space. Westudy these generalizations of the classical approach in the multivariateGaussian setting. In this context we view the latent space identification as alow-rank matrix approximation problem. This allows us to characterize thecapabilities of loss functions and alignment metrics to approximate naturalstatistics, such as conditional means and covariances; doing so yields novelvariants on contrastive learning algorithms for specific mode-seeking and forgenerative tasks. The framework we introduce is also studied through numericalexperiments on multivariate Gaussians, the labeled MNIST dataset, and on a dataassimilation application arising in oceanography.</description>
      <author>example@mail.com (Ricardo Baptista, Andrew M. Stuart, Son Tran)</author>
      <guid isPermaLink="false">2505.24134v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Bridging 3D Anomaly Localization and Repair via High-Quality Continuous Geometric Representation</title>
      <link>http://arxiv.org/abs/2505.24431v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Pose-Aware Signed Distance Field (PASDF)的3D点云异常检测框架，用于提高视觉系统的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;3D点云异常检测对于稳健的视觉系统至关重要，但受到姿态变化和复杂几何异常的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够集成3D异常检测和修复的学习框架，通过学习连续、姿态不变形状表示来提高几何保真度。&lt;h4&gt;方法&lt;/h4&gt;PASDF利用姿态对齐模块进行正则化，并通过SDF网络动态地结合姿态信息，实现从连续SDF中隐式学习高保真异常修复模板。此外，通过异常感知评分模块实现精确的像素级异常定位。&lt;h4&gt;主要发现&lt;/h4&gt;在Real3D-AD和Anomaly-ShapeNet数据集上的实验表明，PASDF实现了最先进的性能，分别达到了80.2%和90.0%的高对象级AUROC分数。&lt;h4&gt;结论&lt;/h4&gt;PASDF通过连续几何表示在3D异常检测中取得了显著效果，并促进了实际异常区域的修复。&lt;h4&gt;翻译&lt;/h4&gt;摘要：三维点云异常检测对于稳健的视觉系统至关重要，但受到姿态变化和复杂几何异常的挑战。现有的基于补丁的方法由于离散体素化或基于投影的表示，往往遭受几何保真度问题，限制了细粒度异常定位。我们引入了姿态感知签名距离场（PASDF），这是一个新的框架，通过学习连续、姿态不变形状表示来集成3D异常检测和修复。PASDF利用姿态对齐模块进行规范化，并通过SDF网络动态地结合姿态，从连续SDF中隐式学习高保真异常修复模板。这通过异常感知评分模块促进了精确的像素级异常定位。至关重要的是，PASDF中的连续三维表示不仅限于检测，还促进了现场异常修复。在Real3D-AD和Anomaly-ShapeNet上的实验证明了最先进的性能，分别达到了80.2%和90.0%的高对象级AUROC分数。这些结果突出了连续几何表示在推进3D异常检测和促进实际异常区域修复方面的有效性。代码可在https://github.com/ZZZBBBZZZ/PASDF上获得，以支持进一步的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D point cloud anomaly detection is essential for robust vision systems butis challenged by pose variations and complex geometric anomalies. Existingpatch-based methods often suffer from geometric fidelity issues due to discretevoxelization or projection-based representations, limiting fine-grained anomalylocalization. We introduce Pose-Aware Signed Distance Field (PASDF), a novelframework that integrates 3D anomaly detection and repair by learning acontinuous, pose-invariant shape representation. PASDF leverages a PoseAlignment Module for canonicalization and a SDF Network to dynamicallyincorporate pose, enabling implicit learning of high-fidelity anomaly repairtemplates from the continuous SDF. This facilitates precise pixel-level anomalylocalization through an Anomaly-Aware Scoring Module. Crucially, the continuous3D representation in PASDF extends beyond detection, facilitating in-situanomaly repair. Experiments on Real3D-AD and Anomaly-ShapeNet demonstratestate-of-the-art performance, achieving high object-level AUROC scores of 80.2%and 90.0%, respectively. These results highlight the effectiveness ofcontinuous geometric representations in advancing 3D anomaly detection andfacilitating practical anomaly region repair. The code is available athttps://github.com/ZZZBBBZZZ/PASDF to support further research.</description>
      <author>example@mail.com (Bozhong Zheng, Jinye Gan, Xiaohao Xu, Wenqiao Li, Xiaonan Huang, Na Ni, Yingna Wu)</author>
      <guid isPermaLink="false">2505.24431v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model</title>
      <link>http://arxiv.org/abs/2505.24476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Period-LLM的多模态大型语言模型，旨在提高周期性任务在各种模态上的性能，并构建了不同难度的基准来评估大型模型的跨模态周期能力。&lt;h4&gt;背景&lt;/h4&gt;周期或准周期现象揭示了各种自然过程（如天气模式、运动行为、交通流和生物信号）的内在特性。由于这些现象跨越多个模态，多模态大型语言模型（MLLMs）在有效捕捉和理解其复杂性质方面具有潜在能力。&lt;h4&gt;目的&lt;/h4&gt;解决当前MLLMs在周期性任务上的困难，包括缺乏时间建模和短周期与长周期的冲突。&lt;h4&gt;方法&lt;/h4&gt;提出Period-LLM模型，采用“从简单到复杂泛化”的方法，从相对简单的文本任务开始，逐步过渡到更复杂的视觉和多模态任务，以确保模型逐步建立稳健的周期推理能力。此外，还提出了“抵抗逻辑遗忘”的优化策略，以在语义对齐过程中保持周期推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;大量实验表明，所提出的Period-LLM在周期性任务上优于现有的MLLMs。&lt;h4&gt;结论&lt;/h4&gt;Period-LLM模型在周期性任务方面表现出优越性，为多模态大型语言模型在周期性现象处理方面提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Periodic or quasi-periodic phenomena reveal intrinsic characteristics in various natural processes, such as weather patterns, movement behaviors, traffic flows, and biological signals. Given that these phenomena span multiple modalities, the capabilities of Multimodal Large Language Models (MLLMs) offer promising potential to effectively capture and understand their complex nature. However, current MLLMs struggle with periodic tasks due to limitations in: 1) lack of temporal modelling and 2) conflict between short and long periods. This paper introduces Period-LLM, a multimodal large language model designed to enhance the performance of periodic tasks across various modalities, and constructs a benchmark of various difficulty for evaluating the cross-modal periodic capabilities of large models. Specially, We adopt an 'Easy to Hard Generalization' paradigm, starting with relatively simple text-based tasks and progressing to more complex visual and multimodal tasks, ensuring that the model gradually builds robust periodic reasoning capabilities. Additionally, we propose a 'Resisting Logical Oblivion' optimization strategy to maintain periodic reasoning abilities during semantic alignment. Extensive experiments demonstrate the superiority of the proposed Period-LLM over existing MLLMs in periodic tasks. The code is available at https://github.com/keke-nice/Period-LLM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Periodic or quasi-periodic phenomena reveal intrinsic characteristics invarious natural processes, such as weather patterns, movement behaviors,traffic flows, and biological signals. Given that these phenomena span multiplemodalities, the capabilities of Multimodal Large Language Models (MLLMs) offerpromising potential to effectively capture and understand their complex nature.However, current MLLMs struggle with periodic tasks due to limitations in: 1)lack of temporal modelling and 2) conflict between short and long periods. Thispaper introduces Period-LLM, a multimodal large language model designed toenhance the performance of periodic tasks across various modalities, andconstructs a benchmark of various difficulty for evaluating the cross-modalperiodic capabilities of large models. Specially, We adopt an "Easy to HardGeneralization" paradigm, starting with relatively simple text-based tasks andprogressing to more complex visual and multimodal tasks, ensuring that themodel gradually builds robust periodic reasoning capabilities. Additionally, wepropose a "Resisting Logical Oblivion" optimization strategy to maintainperiodic reasoning abilities during semantic alignment. Extensive experimentsdemonstrate the superiority of the proposed Period-LLM over existing MLLMs inperiodic tasks. The code is available athttps://github.com/keke-nice/Period-LLM.</description>
      <author>example@mail.com (Yuting Zhang, Hao Lu, Qingyong Hu, Yin Wang, Kaishen Yuan, Xin Liu, Kaishun Wu)</author>
      <guid isPermaLink="false">2505.24476v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>PDE-Transformer: Efficient and Versatile Transformers for Physics Simulations</title>
      <link>http://arxiv.org/abs/2505.24717v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025. Code available at  https://github.com/tum-pbs/pde-transformer&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于PDE-Transformer的改进型架构，用于在规则网格上进行物理模拟的代理建模。该架构结合了扩散变换器的最新架构改进和针对大规模模拟的调整，以实现更可扩展和通用的变压器架构。实验表明，该架构在16种不同类型的PDE数据集上优于现有的计算机视觉Transformer架构。此外，该方法通过将不同的物理通道作为时空标记单独嵌入，并通过通道自注意力机制进行交互，有助于在同时学习多种类型的PDE时保持标记信息的一致密度。预训练模型在多个下游任务上的性能优于从头开始训练，并在物理模拟中击败了其他基础模型架构。&lt;h4&gt;背景&lt;/h4&gt;当前对物理模拟的代理建模方法需要更高效和通用的架构。&lt;h4&gt;目的&lt;/h4&gt;提出一个改进的Transformer架构，用于提高物理模拟代理建模的效率。&lt;h4&gt;方法&lt;/h4&gt;结合扩散变换器的最新架构改进，调整以适应大规模模拟，并提出将不同物理通道作为时空标记嵌入并使用通道自注意力机制。&lt;h4&gt;主要发现&lt;/h4&gt;提出的PDE-Transformer架构在16种不同类型的PDE数据集上优于现有的计算机视觉Transformer架构，且预训练模型在多个下游任务上表现出色。&lt;h4&gt;结论&lt;/h4&gt;PDE-Transformer是一种高效且通用的架构，适用于物理科学中的大规模基础模型构建。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了PDE-Transformer，这是一种改进的基于变换器的架构，用于在规则网格上进行物理模拟的代理建模。我们将扩散变换器的最新架构改进与针对大规模模拟的调整相结合，以产生一个更可扩展和通用的通用变换器架构，该架构可以用作构建物理科学中大规模基础模型的骨干。我们证明了我们的架构在16种不同类型的PDE的大型数据集上优于最先进的计算机视觉变换器架构。我们建议将不同的物理通道分别嵌入为时空标记，并通过通道自注意力机制进行交互。这有助于在学习多种类型的PDE时保持标记信息的一致密度。我们证明了我们的预训练模型在多个具有挑战性的下游任务上的性能优于从头开始训练，并且在物理模拟中也击败了其他基础模型架构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce PDE-Transformer, an improved transformer-based architecture forsurrogate modeling of physics simulations on regular grids. We combine recentarchitectural improvements of diffusion transformers with adjustments specificfor large-scale simulations to yield a more scalable and versatilegeneral-purpose transformer architecture, which can be used as the backbone forbuilding large-scale foundation models in physical sciences. We demonstratethat our proposed architecture outperforms state-of-the-art transformerarchitectures for computer vision on a large dataset of 16 different types ofPDEs. We propose to embed different physical channels individually asspatio-temporal tokens, which interact via channel-wise self-attention. Thishelps to maintain a consistent information density of tokens when learningmultiple types of PDEs simultaneously. We demonstrate that our pre-trainedmodels achieve improved performance on several challenging downstream taskscompared to training from scratch and also beat other foundation modelarchitectures for physics simulations.</description>
      <author>example@mail.com (Benjamin Holzschuh, Qiang Liu, Georg Kohl, Nils Thuerey)</author>
      <guid isPermaLink="false">2505.24717v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Source and Target Domains via Link Prediction for Unsupervised Domain Adaptation on Graphs</title>
      <link>http://arxiv.org/abs/2505.24055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于解决图神经网络（GNNs）在节点分类上的挑战，特别是在无监督领域自适应（UDA）方面，该框架通过链接预测连接源图和目标图中的节点，以增强目标节点的领域内分布邻域。&lt;h4&gt;背景&lt;/h4&gt;GNNs在图上的节点分类表现出色，但其成功依赖于大量标记数据，而获取高质量标签成本高昂且具有挑战性，尤其是在新兴领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效处理源图和目标图之间分布偏移的新框架，以促进分类器的自适应。&lt;h4&gt;方法&lt;/h4&gt;该方法采用链接预测连接源图和目标图中的节点，从而促进消息传递，并通过修改目标图来减少其在嵌入空间中的偏差，同时设计了一种新的身份保持学习目标，以防止目标图中的判别信息丢失。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该框架在真实世界数据集上有效，能够减少源图和目标图之间的偏差，并对领域间的标签分布不均不敏感。&lt;h4&gt;结论&lt;/h4&gt;该框架为无监督领域自适应提供了一个新的解决方案，特别是在处理具有分布偏移的图数据时。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNNs) have shown great ability for node classification on graphs. However, the success of GNNs relies on abundant labeled data, while obtaining high-quality labels is costly and challenging, especially for newly emerging domains. Hence, unsupervised domain adaptation (UDA), which trains a classifier on the labeled source graph and adapts it to the unlabeled target graph, is attracting increasing attention. Various approaches have been proposed to alleviate the distribution shift between the source and target graphs to facilitate the classifier adaptation. However, most of them simply adopt existing UDA techniques developed for independent and identically distributed data to gain domain-invariant node embeddings for graphs, which do not fully consider the graph structure and message-passing mechanism of GNNs during the adaptation and will fail when label distribution shift exists among domains. In this paper, we proposed a novel framework that adopts link prediction to connect nodes between source and target graphs, which can facilitate message-passing between the source and target graphs and augment the target nodes to have ``in-distribution'' neighborhoods with the source domain. This strategy modified the target graph on the input level to reduce its deviation from the source domain in the embedding space and is insensitive to disproportional label distributions across domains. To prevent the loss of discriminative information in the target graph, we further design a novel identity-preserving learning objective, which guides the learning of the edge insertion module together with reconstruction and adaptation losses. Experimental results on real-world datasets demonstrate the effectiveness of our framework.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have shown great ability for node classificationon graphs. However, the success of GNNs relies on abundant labeled data, whileobtaining high-quality labels is costly and challenging, especially for newlyemerging domains. Hence, unsupervised domain adaptation (UDA), which trains aclassifier on the labeled source graph and adapts it to the unlabeled targetgraph, is attracting increasing attention. Various approaches have beenproposed to alleviate the distribution shift between the source and targetgraphs to facilitate the classifier adaptation. However, most of them simplyadopt existing UDA techniques developed for independent and identicallydistributed data to gain domain-invariant node embeddings for graphs, which donot fully consider the graph structure and message-passing mechanism of GNNsduring the adaptation and will fail when label distribution shift exists amongdomains. In this paper, we proposed a novel framework that adopts linkprediction to connect nodes between source and target graphs, which canfacilitate message-passing between the source and target graphs and augment thetarget nodes to have ``in-distribution'' neighborhoods with the source domain.This strategy modified the target graph on the input level to reduce itsdeviation from the source domain in the embedding space and is insensitive todisproportional label distributions across domains. To prevent the loss ofdiscriminative information in the target graph, we further design a novelidentity-preserving learning objective, which guides the learning of the edgeinsertion module together with reconstruction and adaptation losses.Experimental results on real-world datasets demonstrate the effectiveness ofour framework.</description>
      <author>example@mail.com (Yilong Wang, Tianxiang Zhao, Zongyu Wu, Suhang Wang)</author>
      <guid isPermaLink="false">2505.24055v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Bayesian Inference for Spatially-Temporally Misaligned Data Using Predictive Stacking</title>
      <link>http://arxiv.org/abs/2505.24397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  34 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种贝叶斯层次模型来分析时空不匹配的暴露和健康结果数据，以研究空气污染对人类健康的影响。&lt;h4&gt;背景&lt;/h4&gt;空气污染是导致不良健康结果的主要环境风险因素，但其对人类健康的影响难以量化。&lt;h4&gt;目的&lt;/h4&gt;开发一种贝叶斯层次模型来分析时空不匹配的暴露和健康结果数据。&lt;h4&gt;方法&lt;/h4&gt;引入了贝叶斯预测堆叠，结合多个预测时空模型，避免迭代估计算法如马尔可夫链蒙特卡洛法因弱识别参数导致的收敛问题。&lt;h4&gt;主要发现&lt;/h4&gt;应用该方法研究了臭氧对加利福尼亚州哮喘的影响。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地分析时空不匹配的暴露和健康结果数据，为研究空气污染对健康的影响提供了新的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Air pollution remains a major environmental risk factor that is oftenassociated with adverse health outcomes. However, quantifying and evaluatingits effects on human health is challenging due to the complex nature ofexposure data. Recent technological advances have led to the collection ofvarious indicators of air pollution at increasingly high spatial-temporalresolutions (e.g., daily averages of pollutant levels at spatial locationsreferenced by latitude-longitude). However, health outcomes are typicallyaggregated over several spatial-temporal coordinates (e.g., annual prevalencefor a county) to comply with survey regulations. This article develops aBayesian hierarchical model to analyze such spatially-temporally misalignedexposure and health outcome data. We introduce Bayesian predictive stacking,which optimally combines multiple predictive spatial-temporal models and avoidsiterative estimation algorithms such as Markov chain Monte Carlo that struggledue to convergence issues inflicted by the presence of weakly identifiedparameters. We apply our proposed method to study the effects of ozone onasthma in the state of California.</description>
      <author>example@mail.com (Soumyakanti Pan, Sudipto Banerjee)</author>
      <guid isPermaLink="false">2505.24397v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>BioCLIP 2: Emergent Properties from Scaling Hierarchical Contrastive Learning</title>
      <link>http://arxiv.org/abs/2505.23883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://imageomics.github.io/bioclip-2/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究发现了在大规模训练的模型中存在显著的自发行为，这些行为超出了它们的初始训练目标。通过大规模对比视觉-语言训练，在生物视觉模型中发现了这种自发行为。&lt;h4&gt;背景&lt;/h4&gt;大规模训练的模型表现出超越初始训练目标的新能力。&lt;h4&gt;目的&lt;/h4&gt;通过大规模对比视觉-语言训练，在生物视觉模型中寻找自发行为。&lt;h4&gt;方法&lt;/h4&gt;首先构建了包含2.14亿张生物体图像的TreeOfLife-200M数据集，然后在该数据集上训练BioCLIP 2模型以区分不同物种。通过分析BioCLIP 2学习到的嵌入空间，研究了模型的自发特性。&lt;h4&gt;主要发现&lt;/h4&gt;BioCLIP 2在应用于各种生物视觉任务（如栖息地分类和特征预测）时表现出非凡的准确性。模型在不同物种的嵌入分布与功能生态意义（如喙的大小和栖息地）紧密相关。在物种内部，物种变异（如生命阶段和性别）在正交于物种区分的子空间中得到保留并更好地分离。通过形式证明和分析，解释了层次监督和对比目标如何促进这些自发特性。结果表明，随着训练数据规模的增加，这些特性变得越来越重要，导致一个具有生物学意义的嵌入空间。&lt;h4&gt;结论&lt;/h4&gt;大规模训练数据使得模型的自发特性变得更加重要，并形成了一个具有生物学意义的嵌入空间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models trained at scale exhibit remarkable emergent behaviors,learning new capabilities beyond their initial training objectives. We findsuch emergent behaviors in biological vision models via large-scale contrastivevision-language training. To achieve this, we first curate TreeOfLife-200M,comprising 214 million images of living organisms, the largest and most diversebiological organism image dataset to date. We then train BioCLIP 2 onTreeOfLife-200M to distinguish different species. Despite the narrow trainingobjective, BioCLIP 2 yields extraordinary accuracy when applied to variousbiological visual tasks such as habitat classification and trait prediction. Weidentify emergent properties in the learned embedding space of BioCLIP 2. Atthe inter-species level, the embedding distribution of different species alignsclosely with functional and ecological meanings (e.g., beak sizes andhabitats). At the intra-species level, instead of being diminished, theintra-species variations (e.g., life stages and sexes) are preserved and betterseparated in subspaces orthogonal to inter-species distinctions. We provideformal proof and analyses to explain why hierarchical supervision andcontrastive objectives encourage these emergent properties. Crucially, ourresults reveal that these properties become increasingly significant withlarger-scale training data, leading to a biologically meaningful embeddingspace.</description>
      <author>example@mail.com (Jianyang Gu, Samuel Stevens, Elizabeth G Campolongo, Matthew J Thompson, Net Zhang, Jiaman Wu, Andrei Kopanev, Zheda Mai, Alexander E. White, James Balhoff, Wasila Dahdul, Daniel Rubenstein, Hilmar Lapp, Tanya Berger-Wolf, Wei-Lun Chao, Yu Su)</author>
      <guid isPermaLink="false">2505.23883v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection</title>
      <link>http://arxiv.org/abs/2505.04594v4</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MonoCoP是一种基于链式预测的3D属性预测方法，旨在提高单目3D物体检测的准确性。&lt;h4&gt;背景&lt;/h4&gt;3D属性预测对于单目3D物体检测至关重要，但深度估计因2D图像到3D空间的映射模糊性而极具挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出MonoCoP方法，以改善3D属性预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;MonoCoP通过三个关键设计实现链式预测：1）使用轻量级AttributeNet（AN）学习每个3D属性的特征；2）构建显式链来传播这些特征；3）使用残差连接聚合链上每个属性的特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MonoCoP在KITTI排行榜上达到了最先进的性能，且无需额外数据，在Waymo和nuScenes frontal数据集上也优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;MonoCoP通过条件预测和特征传播显著提高了单目3D物体检测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately predicting 3D attributes is crucial for monocular 3D objectdetection (Mono3D), with depth estimation posing the greatest challenge due tothe inherent ambiguity in mapping 2D images to 3D space. While existing methodsleverage multiple depth cues (e.g., estimating depth uncertainty, modelingdepth error) to improve depth accuracy, they overlook that accurate depthprediction requires conditioning on other 3D attributes, as these attributesare intrinsically inter-correlated through the 3D to 2D projection, whichultimately limits overall accuracy and stability. Inspired by Chain-of-Thought(CoT) in large language models (LLMs), this paper proposes MonoCoP, whichleverages a Chain-of-Prediction (CoP) to predict attributes sequentially andconditionally via three key designs. First, it employs a lightweightAttributeNet (AN) for each 3D attribute to learn attribute-specific features.Next, MonoCoP constructs an explicit chain to propagate these learned featuresfrom one attribute to the next. Finally, MonoCoP uses a residual connection toaggregate features for each attribute along the chain, ensuring that laterattribute predictions are conditioned on all previously processed attributeswithout forgetting the features of earlier ones. Experimental results show thatour MonoCoP achieves state-of-the-art (SoTA) performance on the KITTIleaderboard without requiring additional data and further surpasses existingmethods on the Waymo and nuScenes frontal datasets.</description>
      <author>example@mail.com (Zhihao Zhang, Abhinav Kumar, Girish Chandar Ganesan, Xiaoming Liu)</author>
      <guid isPermaLink="false">2505.04594v4</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>VUDG: A Dataset for Video Understanding Domain Generalization</title>
      <link>http://arxiv.org/abs/2505.24346v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;视频理解领域近年来取得了显著进展，但现有工作往往忽视了实际应用中固有的领域迁移问题，导致领域泛化（DG）在视频理解中的研究不足。&lt;h4&gt;背景&lt;/h4&gt;视频理解领域近年来得益于深度模型的发展和大规模标注数据集的可用性取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;提出VideoUnderstanding Domain Generalization (VUDG)，一个专门设计用于评估视频理解中领域泛化性能的新型数据集。&lt;h4&gt;方法&lt;/h4&gt;VUDG包含来自11个不同领域的视频，涵盖三种类型的领域迁移，并保持不同领域间的语义相似性以确保公平且具有意义的评估。提出一个多专家渐进式标注框架，为每个视频标注多选题和开放式问答对。&lt;h4&gt;主要发现&lt;/h4&gt;在9个代表性的大型视频语言模型（LVLMs）和几种传统视频问答方法上进行的广泛实验表明，大多数模型（包括最先进的LVLMs）在领域迁移下会性能下降。&lt;h4&gt;结论&lt;/h4&gt;VUDG突显了领域迁移带来的挑战以及当前模型对数据分布变化的鲁棒性差异，认为VUDG为未来领域泛化视频理解研究提供了宝贵资源。&lt;h4&gt;翻译&lt;/h4&gt;Video understanding has made remarkable progress in recent years, largely driven by advances in deep models and the availability of large-scale annotated datasets. However, existing works typically ignore the inherent domain shifts encountered in real-world video applications, leaving domain generalization (DG) in video understanding underexplored. Hence, we propose VideoUnderstanding Domain Generalization (VUDG), a novel dataset designed specifically for evaluating the DG performance in video understanding. VUDG contains videos from 11 distinct domains that cover three types of domain shifts, and maintains semantic similarity across different domains to ensure fair and meaningful evaluation. We propose a multi-expert progressive annotation framework to annotate each video with both multiple-choice and open-ended question-answer pairs. Extensive experiments on 9 representative large video-language models (LVLMs) and several traditional video question-answering methods show that most models (including state-of-the-art LVLMs) suffer performance degradation under domain shifts. These results highlight the challenges posed by VUDG and the difference in the robustness of current models to data distribution shifts. We believe VUDG provides a valuable resource for prompting future research in domain generalization video understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video understanding has made remarkable progress in recent years, largelydriven by advances in deep models and the availability of large-scale annotateddatasets. However, existing works typically ignore the inherent domain shiftsencountered in real-world video applications, leaving domain generalization(DG) in video understanding underexplored. Hence, we propose VideoUnderstanding Domain Generalization (VUDG), a novel dataset designedspecifically for evaluating the DG performance in video understanding. VUDGcontains videos from 11 distinct domains that cover three types of domainshifts, and maintains semantic similarity across different domains to ensurefair and meaningful evaluation. We propose a multi-expert progressiveannotation framework to annotate each video with both multiple-choice andopen-ended question-answer pairs. Extensive experiments on 9 representativelarge video-language models (LVLMs) and several traditional video questionanswering methods show that most models (including state-of-the-art LVLMs)suffer performance degradation under domain shifts. These results highlight thechallenges posed by VUDG and the difference in the robustness of current modelsto data distribution shifts. We believe VUDG provides a valuable resource forprompting future research in domain generalization video understanding.</description>
      <author>example@mail.com (Ziyi Wang, Zhi Gao, Boxuan Yu, Zirui Dai, Yuxiang Song, Qingyuan Lu, Jin Chen, Xinxiao Wu)</author>
      <guid isPermaLink="false">2505.24346v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>LTM3D: Bridging Token Spaces for Conditional 3D Generation with Auto-Regressive Diffusion Framework</title>
      <link>http://arxiv.org/abs/2505.24245v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LTM3D的框架，用于条件3D形状生成，该框架结合了扩散模型和自回归模型的优点。&lt;h4&gt;背景&lt;/h4&gt;虽然基于扩散的方法在建模连续潜在空间方面有效，而自回归模型在捕捉词间依赖关系方面表现出色，但将这两种范式结合用于3D形状生成仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这个问题，LTM3D引入了条件分布建模骨干，利用掩码自动编码器和扩散模型来增强词依赖学习。&lt;h4&gt;方法&lt;/h4&gt;LTM3D还引入了前缀学习，这在生成过程中将条件词与形状潜在词对齐，提高了跨模态的灵活性。此外，还提出了一个潜在词重建模块，结合重建引导采样以减少不确定性并增强生成形状的结构保真度。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在操作于词空间的基础上，支持多种3D表示，包括符号距离场、点云、网格和3D高斯分层。在图像和文本条件形状生成任务上的大量实验表明，LTM3D在提示保真度和结构精度方面优于现有方法，并为多模态、多表示的3D生成提供了一个通用的框架。&lt;h4&gt;结论&lt;/h4&gt;LTM3D是一种高效且通用的3D形状生成方法，它在多个方面都优于现有的技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present LTM3D, a Latent Token space Modeling framework for conditional 3Dshape generation that integrates the strengths of diffusion and auto-regressive(AR) models. While diffusion-based methods effectively model continuous latentspaces and AR models excel at capturing inter-token dependencies, combiningthese paradigms for 3D shape generation remains a challenge. To address this,LTM3D features a Conditional Distribution Modeling backbone, leveraging amasked autoencoder and a diffusion model to enhance token dependency learning.Additionally, we introduce Prefix Learning, which aligns condition tokens withshape latent tokens during generation, improving flexibility across modalities.We further propose a Latent Token Reconstruction module withReconstruction-Guided Sampling to reduce uncertainty and enhance structuralfidelity in generated shapes. Our approach operates in token space, enablingsupport for multiple 3D representations, including signed distance fields,point clouds, meshes, and 3D Gaussian Splatting. Extensive experiments onimage- and text-conditioned shape generation tasks demonstrate that LTM3Doutperforms existing methods in prompt fidelity and structural accuracy whileoffering a generalizable framework for multi-modal, multi-representation 3Dgeneration.</description>
      <author>example@mail.com (Xin Kang, Zihan Zheng, Lei Chu, Yue Gao, Jiahao Li, Hao Pan, Xuejin Chen, Yan Lu)</author>
      <guid isPermaLink="false">2505.24245v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>DisTime: Distribution-based Time Representation for Video Large Language Models</title>
      <link>http://arxiv.org/abs/2505.24329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了DisTime，一个旨在提高视频大型语言模型（Video-LLMs）时间理解的轻量级框架，并通过实验证明其在时间敏感任务中取得了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管在视频理解方面取得了进展，但Video-LLMs在精确时间定位上面临挑战，这是由于离散时间表示和有限的时间感知数据集造成的。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，DisTime旨在增强Video-LLMs的时间理解能力。&lt;h4&gt;方法&lt;/h4&gt;DisTime使用一个可学习的标记来创建连续的时间嵌入空间，并采用基于分布的时间解码器生成时间概率分布，以减轻边界模糊性并保持时间连续性。此外，它还重新编码时间戳，为Video-LLMs提供时间标记。为了克服现有数据集中时间粒度的限制，论文提出了一种结合Video-LLMs的标题能力和专门时间模型的定位专家的自动化标注范式。&lt;h4&gt;主要发现&lt;/h4&gt;DisTime在三个时间敏感任务中的基准测试中实现了最先进的性能，同时在视频问答任务中保持了有竞争力的性能。InternVid-TG是一个包含1.25M时间标记事件的庞大数据集，覆盖179k个视频，是ActivityNet-Caption的55倍。&lt;h4&gt;结论&lt;/h4&gt;DisTime框架在视频-LLMs的时间理解方面取得了显著成果，并通过实验验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;尽管在视频理解方面取得了进展，但视频大型语言模型（Video-LLMs）由于离散时间表示和有限的时间感知数据集，在精确时间定位方面面临挑战。为了解决这些问题，我们引入了DisTime，一个旨在增强视频-LLMs时间理解的轻量级框架。DisTime使用一个可学习的标记创建连续的时间嵌入空间，并采用基于分布的时间解码器生成时间概率分布，有效地减轻了边界模糊性并保持了时间连续性。此外，基于分布的时间编码器重新编码时间戳，为视频-LLMs提供时间标记。为了克服现有数据集中时间粒度的限制，我们提出了一种结合视频-LLMs的标题能力和专门时间模型的定位专家的自动化标注范式。这导致了InternVid-TG的创建，一个包含1.25M时间标记事件的庞大数据集，覆盖179k个视频，是ActivityNet-Caption的55倍。广泛的实验表明，DisTime在三个时间敏感任务中的基准测试中实现了最先进的性能，同时在视频问答任务中保持了有竞争力的性能。代码和数据发布在https://github.com/josephzpng/DisTime。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite advances in general video understanding, Video Large Language Models(Video-LLMs) face challenges in precise temporal localization due to discretetime representations and limited temporally aware datasets. Existing methodsfor temporal expression either conflate time with text-based numerical values,add a series of dedicated temporal tokens, or regress time using specializedtemporal grounding heads. To address these issues, we introduce DisTime, alightweight framework designed to enhance temporal comprehension in Video-LLMs.DisTime employs a learnable token to create a continuous temporal embeddingspace and incorporates a Distribution-based Time Decoder that generatestemporal probability distributions, effectively mitigating boundary ambiguitiesand maintaining temporal continuity. Additionally, the Distribution-based TimeEncoder re-encodes timestamps to provide time markers for Video-LLMs. Toovercome temporal granularity limitations in existing datasets, we propose anautomated annotation paradigm that combines the captioning capabilities ofVideo-LLMs with the localization expertise of dedicated temporal models. Thisleads to the creation of InternVid-TG, a substantial dataset with 1.25Mtemporally grounded events across 179k videos, surpassing ActivityNet-Captionby 55 times. Extensive experiments demonstrate that DisTime achievesstate-of-the-art performance across benchmarks in three time-sensitive taskswhile maintaining competitive performance in Video QA tasks. Code and data arereleased at https://github.com/josephzpng/DisTime.</description>
      <author>example@mail.com (Yingsen Zeng, Zepeng Huang, Yujie Zhong, Chengjian Feng, Jie Hu, Lin Ma, Yang Liu)</author>
      <guid isPermaLink="false">2505.24329v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Geospatial Foundation Models to Enable Progress on Sustainable Development Goals</title>
      <link>http://arxiv.org/abs/2505.24528v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SustainFM是一个基于17个可持续发展目标的多任务基准测试框架，用于评估地理空间领域的大型预训练AI系统（FMs）在解决复杂可持续发展挑战中的作用。&lt;h4&gt;背景&lt;/h4&gt;FMs在自然语言处理和计算机视觉领域取得了革命性的进步，现在正被应用于地理空间分析和地球观测。尽管如此，这些模型在现实世界中的效用及其与全球可持续发展目标的契合度尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;引入SustainFM框架，以全面评估地理空间FMs，并探讨其在实现可持续发展目标中的作用。&lt;h4&gt;方法&lt;/h4&gt;SustainFM涵盖了从资产财富预测到环境灾害检测的多种任务，为地理空间FMs提供了一项严格的跨学科评估。&lt;h4&gt;主要发现&lt;/h4&gt;1. FMs在多种任务和数据集上通常优于传统方法，但并非在所有情况下都占优势。2. 评估FMs时，应考虑转移性、泛化能力和能源效率等关键指标。3. FMs能够提供基于可持续发展目标的可扩展解决方案，有助于解决复杂挑战。&lt;h4&gt;结论&lt;/h4&gt;提倡从以模型为中心的开发转向以影响驱动的部署，并强调能源效率、对领域变化的鲁棒性和伦理考虑等指标。&lt;h4&gt;翻译&lt;/h4&gt;Foundation Models (FMs) are large-scale, pre-trained AI systems that have revolutionized natural language processing and computer vision, and are now advancing geospatial analysis and Earth Observation (EO). They promise improved generalization across tasks, scalability, and efficient adaptation with minimal labeled data. However, despite the rapid proliferation of geospatial FMs, their real-world utility and alignment with global sustainability goals remain underexplored. We introduce SustainFM, a comprehensive benchmarking framework grounded in the 17 Sustainable Development Goals with extremely diverse tasks ranging from asset wealth prediction to environmental hazard detection. This study provides a rigorous, interdisciplinary assessment of geospatial FMs and offers critical insights into their role in attaining sustainability goals. Our findings show: (1) While not universally superior, FMs often outperform traditional approaches across diverse tasks and datasets. (2) Evaluating FMs should go beyond accuracy to include transferability, generalization, and energy efficiency as key criteria for their responsible use. (3) FMs enable scalable, SDG-grounded solutions, offering broad utility for tackling complex sustainability challenges. Critically, we advocate for a paradigm shift from model-centric development to impact-driven deployment, and emphasize metrics such as energy efficiency, robustness to domain shifts, and ethical considerations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation Models (FMs) are large-scale, pre-trained AI systems that haverevolutionized natural language processing and computer vision, and are nowadvancing geospatial analysis and Earth Observation (EO). They promise improvedgeneralization across tasks, scalability, and efficient adaptation with minimallabeled data. However, despite the rapid proliferation of geospatial FMs, theirreal-world utility and alignment with global sustainability goals remainunderexplored. We introduce SustainFM, a comprehensive benchmarking frameworkgrounded in the 17 Sustainable Development Goals with extremely diverse tasksranging from asset wealth prediction to environmental hazard detection. Thisstudy provides a rigorous, interdisciplinary assessment of geospatial FMs andoffers critical insights into their role in attaining sustainability goals. Ourfindings show: (1) While not universally superior, FMs often outperformtraditional approaches across diverse tasks and datasets. (2) Evaluating FMsshould go beyond accuracy to include transferability, generalization, andenergy efficiency as key criteria for their responsible use. (3) FMs enablescalable, SDG-grounded solutions, offering broad utility for tackling complexsustainability challenges. Critically, we advocate for a paradigm shift frommodel-centric development to impact-driven deployment, and emphasize metricssuch as energy efficiency, robustness to domain shifts, and ethicalconsiderations.</description>
      <author>example@mail.com (Pedram Ghamisi, Weikang Yu, Xiaokang Zhang, Aldino Rizaldy, Jian Wang, Chufeng Zhou, Richard Gloaguen, Gustau Camps-Valls)</author>
      <guid isPermaLink="false">2505.24528v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Point-MoE: Towards Cross-Domain Generalization in 3D Semantic Segmentation via Mixture-of-Experts</title>
      <link>http://arxiv.org/abs/2505.23926v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://uva-computer-vision-lab.github.io/point-moe/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Point-MoE，一种混合专家架构，旨在实现大规模、跨域泛化的3D感知。&lt;h4&gt;背景&lt;/h4&gt;3D点云理解尚未达到自然语言处理和计算机视觉的水平，这归因于3D数据集规模较小以及数据来源的多样性。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，使模型能够在没有领域标签的情况下自动专业化，并在大规模跨域数据上训练统一模型。&lt;h4&gt;方法&lt;/h4&gt;Point-MoE通过简单的top-k路由策略，能够在混合领域数据上自动专业化专家。&lt;h4&gt;主要发现&lt;/h4&gt;Point-MoE在性能上优于强大的多域基线，并且能够更好地泛化到未见过的领域。&lt;h4&gt;结论&lt;/h4&gt;Point-MoE为3D理解提供了一个可扩展的前进路径，即让模型在多样化的3D数据中发现结构，而不是通过手动编纂或领域监督来强加结构。&lt;h4&gt;翻译&lt;/h4&gt;尽管扩展定律已经改变了自然语言处理和计算机视觉，但3D点云理解尚未达到这一阶段。这可以归因于3D数据集相对较小的规模以及数据本身的多样化来源。点云由不同的传感器（例如，深度相机、激光雷达）在多个领域（例如，室内、室外）捕获，每个领域都引入了独特的扫描模式、采样密度和语义偏差。这种领域异质性是训练大规模统一模型的主要障碍，尤其是在领域标签通常在推理时间不可访问的现实约束下。在这项工作中，我们提出了Point-MoE，这是一种混合专家架构，旨在实现大规模、跨域泛化的3D感知。我们发现，当在混合领域数据上训练时，标准的点云骨干网络在性能上显著下降，而具有简单top-k路由策略的Point-MoE可以自动专业化专家，即使没有访问领域标签。我们的实验表明，Point-MoE不仅优于强大的多域基线，而且能够更好地泛化到未见过的领域。这项工作强调了3D理解的一个可扩展的前进路径：让模型在多样化的3D数据中发现结构，而不是通过手动编纂或领域监督来强加结构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While scaling laws have transformed natural language processing and computervision, 3D point cloud understanding has yet to reach that stage. This can beattributed to both the comparatively smaller scale of 3D datasets, as well asthe disparate sources of the data itself. Point clouds are captured by diversesensors (e.g., depth cameras, LiDAR) across varied domains (e.g., indoor,outdoor), each introducing unique scanning patterns, sampling densities, andsemantic biases. Such domain heterogeneity poses a major barrier towardstraining unified models at scale, especially under the realistic constraintthat domain labels are typically inaccessible at inference time. In this work,we propose Point-MoE, a Mixture-of-Experts architecture designed to enablelarge-scale, cross-domain generalization in 3D perception. We show thatstandard point cloud backbones degrade significantly in performance whentrained on mixed-domain data, whereas Point-MoE with a simple top-k routingstrategy can automatically specialize experts, even without access to domainlabels. Our experiments demonstrate that Point-MoE not only outperforms strongmulti-domain baselines but also generalizes better to unseen domains. This workhighlights a scalable path forward for 3D understanding: letting the modeldiscover structure in diverse 3D data, rather than imposing it via manualcuration or domain supervision.</description>
      <author>example@mail.com (Xuweiyi Chen, Wentao Zhou, Aruni RoyChowdhury, Zezhou Cheng)</author>
      <guid isPermaLink="false">2505.23926v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Threading Keyframe with Narratives: MLLMs as Strong Long Video Comprehenders</title>
      <link>http://arxiv.org/abs/2505.24158v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Nar-KFC的模块，用于有效地处理长视频理解问题，该问题由于视频帧数量与语言模型上下文长度限制之间的矛盾而具有挑战性。&lt;h4&gt;背景&lt;/h4&gt;长视频理解面临挑战，因为视频帧数量庞大，而语言模型的上下文长度有限。传统的均匀采样可能导致选择无关内容，而训练后的模型在处理数千帧时计算负担沉重。&lt;h4&gt;目的&lt;/h4&gt;提出Nar-KFC模块，以促进长视频的有效和高效感知。&lt;h4&gt;方法&lt;/h4&gt;Nar-KFC包括两个协作步骤：首先，将关键帧选择过程定义为整数二次规划问题，联合优化查询相关性和帧多样性；其次，为了减轻稀疏关键帧采样引起的时序不连续性，引入了由非关键帧生成的交错文本叙述，并基于其真实时序插入到关键帧之间。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Nar-KFC显著提高了流行MLLMs在多个长视频基准测试中的性能。&lt;h4&gt;结论&lt;/h4&gt;Nar-KFC作为一种时间和内容感知的压缩策略，能够补充视觉和文本模态，为长视频理解提供了一种有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于视频帧（即视觉标记）数量庞大与语言模型上下文长度有限之间的矛盾，使用多模态大型语言模型（MLLMs）进行长视频理解仍然是一个具有挑战性的问题。传统的均匀采样往往导致选择无关内容，而在数千帧上对MLLMs进行后训练则带来了巨大的计算负担。在本文中，我们提出了一个名为Nar-KFC的即插即用模块，以促进长视频感知的有效性和效率。Nar-KFC通常涉及两个协作步骤。首先，我们将关键帧选择过程定义为整数二次规划问题，联合优化查询相关性和帧多样性。为了避免其计算复杂性，设计了一种定制的贪婪搜索策略作为高效的替代方案。其次，为了减轻由稀疏关键帧采样引起的时序不连续性，我们进一步引入了由现成的字幕生成器生成的交错文本叙述。这些叙述根据其真实时序插入到关键帧之间，形成了一种连贯紧凑的表示。因此，Nar-KFC作为一种时间和内容感知的压缩策略，补充了视觉和文本模态。在多个长视频基准测试上的实验结果表明，Nar-KFC显著提高了流行MLLMs的性能。代码将公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Employing Multimodal Large Language Models (MLLMs) for long videounderstanding remains a challenging problem due to the dilemma between thesubstantial number of video frames (i.e., visual tokens) versus the limitedcontext length of language models. Traditional uniform sampling often leads toselection of irrelevant content, while post-training MLLMs on thousands offrames imposes a substantial computational burden. In this paper, we proposethreading keyframes with narratives (Nar-KFC), a plug-and-play module tofacilitate effective and efficient long video perception. Nar-KFC generallyinvolves two collaborative steps. First, we formulate the keyframe selectionprocess as an integer quadratic programming problem, jointly optimizingquery-relevance and frame-diversity. To avoid its computational complexity, acustomized greedy search strategy is designed as an efficient alternative.Second, to mitigate the temporal discontinuity caused by sparse keyframesampling, we further introduce interleaved textual narratives generated fromnon-keyframes using off-the-shelf captioners. These narratives are insertedbetween keyframes based on their true temporal order, forming a coherent andcompact representation. Nar-KFC thus serves as a temporal- and content-awarecompression strategy that complements visual and textual modalities.Experimental results on multiple long-video benchmarks demonstrate that Nar-KFCsignificantly improves the performance of popular MLLMs. Code will be madepublicly available.</description>
      <author>example@mail.com (Bo Fang, Wenhao Wu, Qiangqiang Wu, Yuxin Song, Antoni B. Chan)</author>
      <guid isPermaLink="false">2505.24158v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>un$^2$CLIP: Improving CLIP's Visual Detail Capturing Ability via Inverting unCLIP</title>
      <link>http://arxiv.org/abs/2505.24517v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种改进的CLIP模型，名为un$^2$CLIP，旨在通过结合生成模型unCLIP的特性来提升CLIP在图像细节捕捉方面的能力。&lt;h4&gt;背景&lt;/h4&gt;CLIP作为基础模型在视觉和跨模态任务中应用广泛，但最近的研究表明其在图像细节区分和密集预测任务上的表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提高现有CLIP模型，使其能够捕捉更多图像细节。&lt;h4&gt;方法&lt;/h4&gt;采用生成模型unCLIP，该模型基于CLIP图像嵌入训练图像生成器，即逆CLIP图像编码器。un$^2$CLIP旨在通过结合unCLIP的图像细节捕捉能力和CLIP的文本编码器保持一致性来改进CLIP模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，un$^2$CLIP在多个任务上显著提升了CLIP的性能，包括MMVP-VLM基准、密集预测开放词汇分割任务和多模态大型语言模型任务。&lt;h4&gt;结论&lt;/h4&gt;un$^2$CLIP是一个有效的改进方案，能够提高CLIP在图像细节捕捉方面的能力。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive Language-Image Pre-training (CLIP) has become a foundation model and has been applied to various vision and multimodal tasks. However, recent works indicate that CLIP falls short in distinguishing detailed differences in images and shows suboptimal performance on dense-prediction and vision-centric multimodal tasks. Therefore, this work focuses on improving existing CLIP models, aiming to capture as many visual details in images as possible. We find that a specific type of generative models, unCLIP, provides a suitable framework for achieving our goal. Specifically, unCLIP trains an image generator conditioned on the CLIP image embedding. In other words, it inverts the CLIP image encoder. Compared to discriminative models like CLIP, generative models are better at capturing image details because they are trained to learn the data distribution of images. Additionally, the conditional input space of unCLIP aligns with CLIP's original image-text embedding space. Therefore, we propose to invert unCLIP (dubbed un$^2$CLIP) to improve the CLIP model. In this way, the improved image encoder can gain unCLIP's visual detail capturing ability while preserving its alignment with the original text encoder simultaneously. We evaluate our improved CLIP across various tasks to which CLIP has been applied, including the challenging MMVP-VLM benchmark, the dense-prediction open-vocabulary segmentation task, and multimodal large language model tasks. Experiments show that un$^2$CLIP significantly improves the original CLIP and previous CLIP improvement methods. Code and models will be available at https://github.com/LiYinqi/un2CLIP.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive Language-Image Pre-training (CLIP) has become a foundation modeland has been applied to various vision and multimodal tasks. However, recentworks indicate that CLIP falls short in distinguishing detailed differences inimages and shows suboptimal performance on dense-prediction and vision-centricmultimodal tasks. Therefore, this work focuses on improving existing CLIPmodels, aiming to capture as many visual details in images as possible. We findthat a specific type of generative models, unCLIP, provides a suitableframework for achieving our goal. Specifically, unCLIP trains an imagegenerator conditioned on the CLIP image embedding. In other words, it invertsthe CLIP image encoder. Compared to discriminative models like CLIP, generativemodels are better at capturing image details because they are trained to learnthe data distribution of images. Additionally, the conditional input space ofunCLIP aligns with CLIP's original image-text embedding space. Therefore, wepropose to invert unCLIP (dubbed un$^2$CLIP) to improve the CLIP model. In thisway, the improved image encoder can gain unCLIP's visual detail capturingability while preserving its alignment with the original text encodersimultaneously. We evaluate our improved CLIP across various tasks to whichCLIP has been applied, including the challenging MMVP-VLM benchmark, thedense-prediction open-vocabulary segmentation task, and multimodal largelanguage model tasks. Experiments show that un$^2$CLIP significantly improvesthe original CLIP and previous CLIP improvement methods. Code and models willbe available at https://github.com/LiYinqi/un2CLIP.</description>
      <author>example@mail.com (Yinqi Li, Jiahe Zhao, Hong Chang, Ruibing Hou, Shiguang Shan, Xilin Chen)</author>
      <guid isPermaLink="false">2505.24517v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Multi-RAG: A Multimodal Retrieval-Augmented Generation System for Adaptive Video Understanding</title>
      <link>http://arxiv.org/abs/2505.23990v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Multi-RAG的多模态检索增强生成系统，旨在为人类在信息密集型环境中提供适应性辅助，以减轻认知负担并提高情境理解。&lt;h4&gt;背景&lt;/h4&gt;随着机器人和智能代理在人类生活中的日益融合，人类需要将认知负担转移到这些系统，特别是在动态、信息丰富的场景中。&lt;h4&gt;目的&lt;/h4&gt;Multi-RAG旨在通过整合和推理来自视频、音频和文本等多源信息流，提高情境理解并减少认知负荷。&lt;h4&gt;方法&lt;/h4&gt;Multi-RAG探索了多模态信息理解如何在动态、以人为中心的情境中为适应性机器人辅助提供基础，并在MMBench-Video数据集上进行了基准测试，以评估其实际应用能力。&lt;h4&gt;主要发现&lt;/h4&gt;Multi-RAG在MMBench-Video数据集上表现出色，与现有的开源视频大型语言模型（Video-LLMs）和大型视觉语言模型（LVLMs）相比，其性能更优，同时资源消耗更少，输入数据更少。&lt;h4&gt;结论&lt;/h4&gt;Multi-RAG有潜力成为未来动态、真实世界情境中人类-机器人适应性辅助系统的实用和高效基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：为了有效地参与人类社会，适应、过滤信息和在不断变化的情况下做出明智决策的能力至关重要。随着机器人和智能代理越来越多地融入人类生活，人类有越来越多的机会和需要将认知负担转移到这些系统，尤其是在动态、信息丰富的场景中。为了满足这一关键需求，我们提出了Multi-RAG，一个多模态检索增强生成系统，旨在为人类在信息密集型环境中提供适应性辅助。我们的系统旨在通过整合和推理来自视频、音频和文本等多源信息流，提高情境理解并减少认知负荷。作为长期人-机器人伙伴关系的一个促成步骤，Multi-RAG探讨了多模态信息理解如何作为动态、以人为中心的情境中适应性机器人辅助的基础。为了评估其在实际人助代理任务中的能力，我们在MMBench-Video数据集上对Multi-RAG进行了基准测试，这是一个具有挑战性的多模态视频理解基准。与现有的开源视频大型语言模型（Video-LLMs）和大型视觉语言模型（LVLMs）相比，我们的系统实现了更优的性能，同时资源消耗更少，输入数据更少。结果表明，Multi-RAG在动态、真实世界情境中作为未来人类-机器人适应性辅助系统的实用和高效基础具有潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To effectively engage in human society, the ability to adapt, filterinformation, and make informed decisions in ever-changing situations iscritical. As robots and intelligent agents become more integrated into humanlife, there is a growing opportunity-and need-to offload the cognitive burdenon humans to these systems, particularly in dynamic, information-richscenarios.  To fill this critical need, we present Multi-RAG, a multimodalretrieval-augmented generation system designed to provide adaptive assistanceto humans in information-intensive circumstances. Our system aims to improvesituational understanding and reduce cognitive load by integrating andreasoning over multi-source information streams, including video, audio, andtext. As an enabling step toward long-term human-robot partnerships, Multi-RAGexplores how multimodal information understanding can serve as a foundation foradaptive robotic assistance in dynamic, human-centered situations. To evaluateits capability in a realistic human-assistance proxy task, we benchmarkedMulti-RAG on the MMBench-Video dataset, a challenging multimodal videounderstanding benchmark. Our system achieves superior performance compared toexisting open-source video large language models (Video-LLMs) and largevision-language models (LVLMs), while utilizing fewer resources and less inputdata. The results demonstrate Multi- RAG's potential as a practical andefficient foundation for future human-robot adaptive assistance systems indynamic, real-world contexts.</description>
      <author>example@mail.com (Mingyang Mao, Mariela M. Perez-Cabarcas, Utteja Kallakuri, Nicholas R. Waytowich, Xiaomin Lin, Tinoosh Mohsenin)</author>
      <guid isPermaLink="false">2505.23990v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Object Centric Concept Bottlenecks</title>
      <link>http://arxiv.org/abs/2505.24492v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了Object-Centric Concept Bottlenecks（OCB）框架，旨在解决现代AI中高表现力和可解释性模型的发展难题。&lt;h4&gt;背景&lt;/h4&gt;高表现力和可解释性模型在AI中是一个关键挑战。概念化模型（CBMs）试图通过从全局编码（如图像编码）中提取人类可理解的概念，然后对概念激活应用线性分类器，以实现透明的决策来解决这一挑战。&lt;h4&gt;目的&lt;/h4&gt;为了克服CBMs在对象中心现实世界设置中的表现力限制，论文旨在提升复杂视觉任务的处理能力。&lt;h4&gt;方法&lt;/h4&gt;OCB框架结合了CBMs和预训练的对象中心基础模型的优势，并通过评估OCB在复杂图像数据集上的表现以及进行消融研究来分析框架的关键组件，如聚合对象-概念编码的策略。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果证明了OCB优于传统的CBMs，并允许对复杂视觉任务进行可解释的决策。&lt;h4&gt;结论&lt;/h4&gt;OCB框架能够提升模型性能和可解释性，是解决现代AI中高表现力和可解释性模型挑战的有效方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing high-performing, yet interpretable models remains a criticalchallenge in modern AI. Concept-based models (CBMs) attempt to address this byextracting human-understandable concepts from a global encoding (e.g., imageencoding) and then applying a linear classifier on the resulting conceptactivations, enabling transparent decision-making. However, their reliance onholistic image encodings limits their expressiveness in object-centricreal-world settings and thus hinders their ability to solve complex visiontasks beyond single-label classification. To tackle these challenges, weintroduce Object-Centric Concept Bottlenecks (OCB), a framework that combinesthe strengths of CBMs and pre-trained object-centric foundation models,boosting performance and interpretability. We evaluate OCB on complex imagedatasets and conduct a comprehensive ablation study to analyze key componentsof the framework, such as strategies for aggregating object-concept encodings.The results show that OCB outperforms traditional CBMs and allows one to makeinterpretable decisions for complex visual tasks.</description>
      <author>example@mail.com (David Steinmann, Wolfgang Stammer, Antonia Wüst, Kristian Kersting)</author>
      <guid isPermaLink="false">2505.24492v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Multilingual Gloss-free Sign Language Translation: Towards Building a Sign Language Foundation Model</title>
      <link>http://arxiv.org/abs/2505.24355v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种用于手语翻译的多语言无词模型，旨在解决跨语言资源利用问题，提高手语与口语之间的沟通。&lt;h4&gt;背景&lt;/h4&gt;现有的手语翻译研究主要集中于单一手语到单一口语的翻译，而多语言手语翻译（MLSLT）因语言冲突和对齐困难而未被充分探索。&lt;h4&gt;目的&lt;/h4&gt;通过提出一种多语言无词模型，缓解低资源问题，并提高手语翻译的可用性。&lt;h4&gt;方法&lt;/h4&gt;该模型采用双重CTC目标，针对符号级手语识别和口语文本生成，支持10种手语，并能够处理一对一、多对一和多对多的手语翻译任务。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在三个广泛使用的基准测试（multilingual SP-10、PHOENIX14T和CSL-Daily）上实现了与现有方法相当的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的模型为多语言手语翻译提供了一种有效的方法，有望改善手语与口语社区之间的沟通。&lt;h4&gt;翻译&lt;/h4&gt;手语翻译（SLT）旨在将手语（SL）视频转换为口语文本，从而弥合手语与口语社区之间的沟通差距。虽然大多数现有工作集中于将单一手语翻译成单一口语（一对一SLT），但利用多语言资源可以缓解低资源问题并提高可用性。然而，由于手语和口语之间的语言冲突和对齐困难，多语言手语翻译（MLSLT）仍然未被充分探索。为了解决这些挑战，我们提出了一种具有双重CTC目标的多语言无词模型，用于符号级手语识别和口语文本生成。我们的模型支持10种手语，并处理一对一、多对一和多对多的SLT任务，在三个广泛采用的基准测试（multilingual SP-10、PHOENIX14T和CSL-Daily）上与最先进的方法相比实现了有竞争力的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sign Language Translation (SLT) aims to convert sign language (SL) videosinto spoken language text, thereby bridging the communication gap between thesign and the spoken community. While most existing works focus on translating asingle sign language into a single spoken language (one-to-one SLT), leveragingmultilingual resources could mitigate low-resource issues and enhanceaccessibility. However, multilingual SLT (MLSLT) remains unexplored due tolanguage conflicts and alignment difficulties across SLs and spoken languages.To address these challenges, we propose a multilingual gloss-free model withdual CTC objectives for token-level SL identification and spoken textgeneration. Our model supports 10 SLs and handles one-to-one, many-to-one, andmany-to-many SLT tasks, achieving competitive performance compared tostate-of-the-art methods on three widely adopted benchmarks: multilingualSP-10, PHOENIX14T, and CSL-Daily.</description>
      <author>example@mail.com (Sihan Tan, Taro Miyazaki, Kazuhiro Nakadai)</author>
      <guid isPermaLink="false">2505.24355v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Hybrid-Graph Neural Network Method for Muon Fast Reconstruction in Neutrino Telescopes</title>
      <link>http://arxiv.org/abs/2505.23425v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对μ子轨迹重建的高效混合图神经网络（GNN）方法，旨在提高中微子望远镜的实验灵敏度和在线触发能力。&lt;h4&gt;背景&lt;/h4&gt;快速且精确的μ子重建对于中微子望远镜至关重要。&lt;h4&gt;目的&lt;/h4&gt;提高中微子望远镜的实验灵敏度和实现在线触发。&lt;h4&gt;方法&lt;/h4&gt;采用混合图神经网络（GNN）方法，结合了GNN的鲁棒性和传统的基于物理的方法，实现了高效的μ子轨迹重建。&lt;h4&gt;主要发现&lt;/h4&gt;LITE GNN模型在GPU上的运行时间仅为0.19-0.29毫秒/事件，比传统基于似然的方法快三个数量级，同时保持了高重建精度。对于高能μ子（10-100 TeV），中值角误差约为0.1度，重建的切伦科夫光子发射位置误差在3-5米以下。Semi-GNN方法提供了一种评估事件重建质量的方法，能够识别和排除重建质量较差的事件。&lt;h4&gt;结论&lt;/h4&gt;基于GNN的方法被证明是下一代中微子望远镜数据重建的有希望的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a Hybrid-Graph Neural Network (GNN) method tailored for efficient muon track reconstruction, leveraging the robustness of GNNs alongside traditional physics-based approaches. The 'LITE GNN model' achieves a runtime of 0.19-0.29 ms per event on GPUs, offering a three orders of magnitude speedup compared to traditional likelihood-based methods while maintaining a high reconstruction accuracy. For high-energy muons (10-100 TeV), the median angular error is approximately 0.1 degrees, with errors in reconstructed Cherenkov photon emission positions being below 3-5 meters, depending on the GNN model used. Furthermore, the Semi-GNN method offers a mechanism to assess the quality of event reconstruction, enabling the identification and exclusion of poorly reconstructed events. These results establish the GNN-based approach as a promising solution for next-generation neutrino telescope data reconstruction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fast and accurate muon reconstruction is crucial for neutrino telescopes toimprove experimental sensitivity and enable online triggering. This paperintroduces a Hybrid-Graph Neural Network (GNN) method tailored for efficientmuon track reconstruction, leveraging the robustness of GNNs alongsidetraditional physics-based approaches. The "LITE GNN model" achieves a runtimeof 0.19-0.29 ms per event on GPUs, offering a three orders of magnitude speedupcompared to traditional likelihood-based methods while maintaining a highreconstruction accuracy. For high-energy muons (10-100 TeV), the median angularerror is approximately 0.1 degrees, with errors in reconstructed Cherenkovphoton emission positions being below 3-5 meters, depending on the GNN modelused. Furthermore, the Semi-GNN method offers a mechanism to assess the qualityof event reconstruction, enabling the identification and exclusion of poorlyreconstructed events. These results establish the GNN-based approach as apromising solution for next-generation neutrino telescope data reconstruction.</description>
      <author>example@mail.com (Cen Mo, Liang Li)</author>
      <guid isPermaLink="false">2505.23425v2</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>ScaleLong: A Multi-Timescale Benchmark for Long Video Understanding</title>
      <link>http://arxiv.org/abs/2505.23922v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ScaleLong的新基准，用于评估长视频理解模型在多时间尺度上的性能，通过在同一视频内容中嵌入针对不同时间尺度（秒、十几秒、分钟、小时）的问题，实现了对模型性能的直接比较。&lt;h4&gt;背景&lt;/h4&gt;现有的长视频理解基准要么忽略了多尺度设计，要么在不同视频中分散处理特定时间尺度的问题，这阻碍了模型性能在不同时间尺度上的直接比较。&lt;h4&gt;目的&lt;/h4&gt;解决现有基准中存在的问题，通过ScaleLong基准实现模型在不同时间尺度上的性能直接比较。&lt;h4&gt;方法&lt;/h4&gt;ScaleLong基准包含来自5个主要类别和36个子类别的269个长视频（平均长度86分钟），每个视频包含4-8个精心设计的问题，至少包含一个问题针对每个时间尺度。&lt;h4&gt;主要发现&lt;/h4&gt;评估了23个多模态语言模型（MLLM），发现性能曲线呈U形，在最长和最短时间尺度上准确率较高，而在中间水平上有所下降。消融研究表明，增加视觉标记容量可以一致地增强所有时间尺度上的推理能力。&lt;h4&gt;结论&lt;/h4&gt;ScaleLong提供了一个细粒度、多时间尺度的基准，以推进MLLM在长视频理解方面的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管长视频理解要求模型捕捉从片段（秒）到镜头（十几秒）、事件（分钟）和故事（小时）的层次时间信息，但现有的基准要么忽略了这种多尺度设计，要么将特定时间尺度的问题分散在不同的视频中，这阻碍了在同一内容上对模型性能在不同时间尺度上的直接比较。为了解决这个问题，我们引入了ScaleLong，这是第一个通过在同一视频内容中嵌入针对四个层次时间尺度（片段、镜头、事件和故事）的问题来解耦这些因素的基准。这种内容内多时间尺度提问设计使得可以直接比较相同视频在不同时间尺度上的模型性能。ScaleLong包含269个长视频（平均长度86分钟），来自5个主要类别和36个子类别，每个视频有4-8个精心设计的问题，每个时间尺度至少有一个问题。评估了23个MLLM，发现性能曲线呈U形，在最长和最短时间尺度上准确率较高，在中间水平上有所下降。此外，消融研究表明，增加视觉标记容量可以一致地增强所有时间尺度上的推理能力。ScaleLong提供了一个精细的多时间尺度基准，以推进MLLM在长视频理解方面的能力。代码和数据集可在https://github.com/multimodal-art-projection/ScaleLong获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although long-video understanding demands that models capture hierarchicaltemporal information -- from clip (seconds) and shot (tens of seconds) to event(minutes) and story (hours) -- existing benchmarks either neglect thismulti-scale design or scatter scale-specific questions across different videos,preventing direct comparison of model performance across timescales on the samecontent. To address this, we introduce ScaleLong, the first benchmark todisentangle these factors by embedding questions targeting four hierarchicaltimescales -- clip (seconds), shot (tens of seconds), event (minutes), andstory (hours) -- all within the same video content. This within-contentmulti-timescale questioning design enables direct comparison of modelperformance across timescales on identical videos. ScaleLong features 269 longvideos (avg.\ 86\,min) from 5 main categories and 36 sub-categories, with 4--8carefully designed questions, including at least one question for eachtimescale. Evaluating 23 MLLMs reveals a U-shaped performance curve, withhigher accuracy at the shortest and longest timescales and a dip atintermediate levels. Furthermore, ablation studies show that increased visualtoken capacity consistently enhances reasoning across all timescales. ScaleLongoffers a fine-grained, multi-timescale benchmark for advancing MLLMcapabilities in long-video understanding. The code and dataset are availablehttps://github.com/multimodal-art-projection/ScaleLong.</description>
      <author>example@mail.com (David Ma, Huaqing Yuan, Xingjian Wang, Qianbo Zang, Tianci Liu, Xinyang He, Yanbin Wei, Jiawei Guo, Ni Jiahui, Zhenzhu Yang, Meng Cao, Shanghaoran Quan, Yizhi Li, Wangchunshu Zhou, Jiaheng Liu, Wenhao Huang, Ge Zhang, Shiwen Ni, Xiaojie Jin)</author>
      <guid isPermaLink="false">2505.23922v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>A Benchmark Dataset for Graph Regression with Homogeneous and Multi-Relational Variants</title>
      <link>http://arxiv.org/abs/2505.23875v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了RelSC，一个基于程序图的新的图回归数据集，该数据集通过源代码提取语法和语义信息，并提供了连续的目标变量。RelSC有两大变体：RelSC-H提供单一种类边的丰富节点特征，而RelSC-M保持原始的多关系结构。研究评估了多种图神经网络架构，发现结构表示的重要性，并证明了RelSC在推动图回归方法发展中的价值。&lt;h4&gt;背景&lt;/h4&gt;现有的图回归公共基准主要关注分子图和引用网络，缺乏多样性，限制了在多种图结构上泛化的模型发展。&lt;h4&gt;目的&lt;/h4&gt;提出RelSC数据集，用于评估和推动图回归方法在更广泛图结构上的性能。&lt;h4&gt;方法&lt;/h4&gt;从源代码中提取语法和语义信息构建程序图，并使用执行时间成本作为标签。RelSC提供两种变体：RelSC-H和RelSC-M。在两种变体上评估多种图神经网络架构。&lt;h4&gt;主要发现&lt;/h4&gt;在RelSC的不同变体上评估图神经网络架构时，发现同质和多层关系设置之间存在一致的性能差异，强调了结构表示的重要性。&lt;h4&gt;结论&lt;/h4&gt;RelSC作为一个具有挑战性和灵活性的基准，对于推进图回归方法具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-level regression underpins many real-world applications, yet publicbenchmarks remain heavily skewed toward molecular graphs and citation networks.This limited diversity hinders progress on models that must generalize acrossboth homogeneous and heterogeneous graph structures. We introduce RelSC, a newgraph-regression dataset built from program graphs that combine syntactic andsemantic information extracted from source code. Each graph is labelled withthe execution-time cost of the corresponding program, providing a continuoustarget variable that differs markedly from those found in existing benchmarks.RelSC is released in two complementary variants. RelSC-H supplies rich nodefeatures under a single (homogeneous) edge type, while RelSC-M preserves theoriginal multi-relational structure, connecting nodes through multiple edgetypes that encode distinct semantic relationships. Together, these variants letresearchers probe how representation choice influences model behaviour. Weevaluate a diverse set of graph neural network architectures on both variantsof RelSC. The results reveal consistent performance differences between thehomogeneous and multi-relational settings, emphasising the importance ofstructural representation. These findings demonstrate RelSC's value as achallenging and versatile benchmark for advancing graph regression methods.</description>
      <author>example@mail.com (Peter Samoaa, Marcus Vukojevic, Morteza Haghir Chehreghani, Antonio Longa)</author>
      <guid isPermaLink="false">2505.23875v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Harnessing Foundation Models for Robust and Generalizable 6-DOF Bronchoscopy Localization</title>
      <link>http://arxiv.org/abs/2505.24249v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PANSv2是一个通用的和鲁棒的支气管镜定位框架，用于解决现有方法在泛化能力和鲁棒性方面的挑战。&lt;h4&gt;背景&lt;/h4&gt;基于视觉的6自由度支气管镜定位是一种准确且经济的介入性引导方法，但现有方法在泛化能力和对视觉退化条件的鲁棒性方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出PANSv2框架以解决现有方法的问题，提高支气管镜定位的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;PANSv2通过整合深度估计、地标检测和中心线约束，将多个视觉线索整合到一个统一的姿态优化框架中。同时，使用EndoOmni和EndoMamba模型进行深度估计和地标检测，结合空间和时间分析，并在多样化的支气管镜数据集上进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;PANSv2在包含10个患者案例的支气管镜数据集上实现了最高的跟踪成功率，与现有方法相比，SR-5（绝对轨迹误差小于5毫米的百分比）提高了18.1%，显示出在临床应用中的潜力。&lt;h4&gt;结论&lt;/h4&gt;PANSv2框架能够有效提高支气管镜定位的准确性和鲁棒性，为临床应用提供了有前景的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-based 6-DOF bronchoscopy localization offers a promising solution foraccurate and cost-effective interventional guidance. However, existing methodsstruggle with 1) limited generalization across patient cases due to scarcelabeled data, and 2) poor robustness under visual degradation, as bronchoscopyprocedures frequently involve artifacts such as occlusions and motion blur thatimpair visual information. To address these challenges, we propose PANSv2, ageneralizable and robust bronchoscopy localization framework. Motivated by PANSthat leverages multiple visual cues for pose likelihood measurement, PANSv2integrates depth estimation, landmark detection, and centerline constraintsinto a unified pose optimization framework that evaluates pose probability andsolves for the optimal bronchoscope pose. To further enhance generalizationcapabilities, we leverage the endoscopic foundation model EndoOmni for depthestimation and the video foundation model EndoMamba for landmark detection,incorporating both spatial and temporal analyses. Pretrained on diverseendoscopic datasets, these models provide stable and transferable visualrepresentations, enabling reliable performance across varied bronchoscopyscenarios. Additionally, to improve robustness to visual degradation, weintroduce an automatic re-initialization module that detects tracking failuresand re-establishes pose using landmark detections once clear views areavailable. Experimental results on bronchoscopy dataset encompassing 10 patientcases show that PANSv2 achieves the highest tracking success rate, with an18.1% improvement in SR-5 (percentage of absolute trajectory error under 5 mm)compared to existing methods, showing potential towards real clinical usage.</description>
      <author>example@mail.com (Qingyao Tian, Huai Liao, Xinyan Huang, Bingyu Yang, Hongbin Liu)</author>
      <guid isPermaLink="false">2505.24249v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Personalized Subgraph Federated Learning with Differentiable Auxiliary Projections</title>
      <link>http://arxiv.org/abs/2505.23864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FedAux的个性化子图联邦学习框架，用于在图结构数据上解决非IID问题，该框架通过辅助投影学习来对齐、比较和聚合异构分布的本地模型，同时不共享原始数据或节点嵌入。&lt;h4&gt;背景&lt;/h4&gt;在图结构数据上的联邦学习通常面临非IID挑战，尤其是在每个客户端持有从全局图中采样的不同子图的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出FedAux框架，旨在学习对齐、比较和聚合异构分布的本地模型，而不共享原始数据或节点嵌入。&lt;h4&gt;方法&lt;/h4&gt;在FedAux中，每个客户端联合训练（i）一个本地GNN和（ii）一个可学习的辅助投影向量（APV），该向量将节点嵌入差异性地投影到一维空间。随后通过软排序操作和轻量级的一维卷积来细化这些嵌入，使APV能够有效捕获客户端特定的信息。本地训练后，这些APV作为紧凑的签名，由服务器用于计算客户端之间的相似性并执行相似度加权的参数混合，从而产生个性化的模型并保留跨客户端的知识迁移。&lt;h4&gt;主要发现&lt;/h4&gt;FedAux在多种图基准测试中的实证评估表明，它在准确性和个性化性能方面显著优于现有基线。&lt;h4&gt;结论&lt;/h4&gt;FedAux框架在图结构数据上的联邦学习中表现出色，通过辅助投影有效地解决了非IID问题，并提高了模型的学习性能。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we introduce Federated learning with Auxiliary projections (FedAux), a personalized subgraph FL framework that learns to align, compare, and aggregate heterogeneously distributed local models without sharing raw data or node embeddings. In FedAux, each client jointly trains (i) a local GNN and (ii) a learnable auxiliary projection vector (APV) that differentiably projects node embeddings onto a 1D space. A soft-sorting operation followed by a lightweight 1D convolution refines these embeddings in the ordered space, enabling the APV to effectively capture client-specific information. After local training, these APVs serve as compact signatures that the server uses to compute inter-client similarities and perform similarity-weighted parameter mixing, yielding personalized models while preserving cross-client knowledge transfer. Moreover, we provide rigorous theoretical analysis to establish the convergence and rationality of our design. Empirical evaluations across diverse graph benchmarks demonstrate that FedAux substantially outperforms existing baselines in both accuracy and personalization performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated learning (FL) on graph-structured data typically faces non-IIDchallenges, particularly in scenarios where each client holds a distinctsubgraph sampled from a global graph. In this paper, we introduce Federatedlearning with Auxiliary projections (FedAux), a personalized subgraph FLframework that learns to align, compare, and aggregate heterogeneouslydistributed local models without sharing raw data or node embeddings. InFedAux, each client jointly trains (i) a local GNN and (ii) a learnableauxiliary projection vector (APV) that differentiably projects node embeddingsonto a 1D space. A soft-sorting operation followed by a lightweight 1Dconvolution refines these embeddings in the ordered space, enabling the APV toeffectively capture client-specific information. After local training, theseAPVs serve as compact signatures that the server uses to compute inter-clientsimilarities and perform similarity-weighted parameter mixing, yieldingpersonalized models while preserving cross-client knowledge transfer. Moreover,we provide rigorous theoretical analysis to establish the convergence andrationality of our design. Empirical evaluations across diverse graphbenchmarks demonstrate that FedAux substantially outperforms existing baselinesin both accuracy and personalization performance.</description>
      <author>example@mail.com (Wei Zhuo, Zhaohuan Zhan, Ziduo Yang, Han Yu)</author>
      <guid isPermaLink="false">2505.23864v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks</title>
      <link>http://arxiv.org/abs/2505.21649v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了DORI（Discriminative Orientation Reasoning Intelligence），一个用于评估物体方向感知能力的全面基准。DORI通过11个数据集上的精心设计的任务，揭示了当前视觉语言模型在物体方向感知上的局限性。&lt;h4&gt;背景&lt;/h4&gt;物体方向理解是视觉感知中的基本挑战，对机器人操作和增强现实等应用至关重要。当前视觉语言基准未能单独评估这一能力，经常将其与位置关系和一般场景理解混淆。&lt;h4&gt;目的&lt;/h4&gt;建立DORI基准，将物体方向感知作为主要评估目标，评估方向理解的四维：正面对齐、旋转变换、相对方向关系和标准方向理解。&lt;h4&gt;方法&lt;/h4&gt;DORI通过从11个数据集中精心挑选的任务，涵盖67个类别、67个物体，从合成和真实世界场景中评估方向理解。&lt;h4&gt;主要发现&lt;/h4&gt;评估了15个最先进的视觉语言模型，发现即使表现最好的模型在粗略任务上也只有54.2%的准确率，在细致的方向判断上只有33.0%。在需要参考系转换或复合旋转的任务中，性能进一步下降。&lt;h4&gt;结论&lt;/h4&gt;研究表明，需要专门的定向表示机制。模型在精确角度估计、跟踪视角间方向变化和复合旋转理解方面存在系统性缺陷，表明它们内部的三维空间表示有限。&lt;h4&gt;翻译&lt;/h4&gt;摘要：物体方向理解是视觉感知中的基本挑战，对于机器人操作和增强现实等应用至关重要。当前的视觉语言基准未能单独评估这一能力，常常将之与位置关系和一般场景理解混淆。我们引入了DORI（判别性方向推理智能），这是一个全面的基准，将物体方向感知作为主要评估目标。DORI评估了方向理解的四个维度：正面对齐、旋转变换、相对方向关系和标准方向理解。通过从11个数据集中精心挑选的任务，涵盖67个类别、67个物体，从合成和真实世界场景中，DORI提供了关于多模态系统如何理解物体方向见解。我们对15个最先进的视觉语言模型的评估揭示了关键的局限性：即使是表现最好的模型，在粗略任务上也只能达到54.2%的准确率，在细致的方向判断上只有33.0%，需要参考系转换或复合旋转的任务中，性能进一步下降。这些发现证明了需要专门的定向表示机制，因为模型显示出系统性无法执行精确的角度估计、跟踪视角间方向变化和理解复合旋转的能力——表明它们内部的三维空间表示有限。作为第一个专门为多模态系统中的方向意识设计的诊断框架，DORI对改进机器人控制、3D场景重建和物理环境中的人类-人工智能交互具有重要意义。DORI数据：https://huggingface.co/datasets/appledora/DORI-Benchmark&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object orientation understanding represents a fundamental challenge in visualperception critical for applications like robotic manipulation and augmentedreality. Current vision-language benchmarks fail to isolate this capability,often conflating it with positional relationships and general sceneunderstanding. We introduce DORI (Discriminative Orientation ReasoningIntelligence), a comprehensive benchmark establishing object orientationperception as a primary evaluation target. DORI assesses four dimensions oforientation comprehension: frontal alignment, rotational transformations,relative directional relationships, and canonical orientation understanding.Through carefully curated tasks from 11 datasets spanning 67 object categoriesacross synthetic and real-world scenarios, DORI provides insights on howmulti-modal systems understand object orientations. Our evaluation of 15state-of-the-art vision-language models reveals critical limitations: even thebest models achieve only 54.2% accuracy on coarse tasks and 33.0% on granularorientation judgments, with performance deteriorating for tasks requiringreference frame shifts or compound rotations. These findings demonstrate theneed for dedicated orientation representation mechanisms, as models showsystematic inability to perform precise angular estimations, track orientationchanges across viewpoints, and understand compound rotations - suggestinglimitations in their internal 3D spatial representations. As the firstdiagnostic framework specifically designed for orientation awareness inmultimodal systems, DORI offers implications for improving robotic control, 3Dscene reconstruction, and human-AI interaction in physical environments. DORIdata: https://huggingface.co/datasets/appledora/DORI-Benchmark</description>
      <author>example@mail.com (Keanu Nichols, Nazia Tasnim, Yuting Yan, Nicholas Ikechukwu, Elva Zou, Deepti Ghadiyaram, Bryan A. Plummer)</author>
      <guid isPermaLink="false">2505.21649v3</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>From Hallucinations to Jailbreaks: Rethinking the Vulnerability of Large Foundation Models</title>
      <link>http://arxiv.org/abs/2505.24232v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个统一的理论框架，用于研究大型基础模型（LFMs）的两种主要漏洞：幻觉和越狱攻击。通过实证研究，发现这两种漏洞之间存在关联，并提出相应的缓解策略。&lt;h4&gt;背景&lt;/h4&gt;大型基础模型（LFMs）存在幻觉和越狱攻击两种漏洞，这两种漏洞通常被独立研究。&lt;h4&gt;目的&lt;/h4&gt;建立一个统一的理论框架，研究幻觉和越狱攻击之间的关系，并提出相应的缓解策略。&lt;h4&gt;方法&lt;/h4&gt;提出一个理论框架，将越狱攻击视为token级别的优化，将幻觉视为attention级别的优化。通过实证研究验证理论框架的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;发现幻觉和越狱攻击的损失函数在优化目标特定输出时收敛相似，并且两者在attention重新分配方面表现出一致的梯度行为。&lt;h4&gt;结论&lt;/h4&gt;提出缓解幻觉可以降低越狱的成功率，反之亦然。研究表明，大型基础模型存在共同的失败模式，因此，鲁棒性策略应同时解决这两种漏洞。&lt;h4&gt;翻译&lt;/h4&gt;Large foundation models (LFMs) are susceptible to two distinct vulnerabilities: hallucinations and jailbreak attacks. While typically studied in isolation, we observe that defenses targeting one often affect the other, hinting at a deeper connection. We propose a unified theoretical framework that models jailbreaks as token-level optimization and hallucinations as attention-level optimization. Within this framework, we establish two key propositions: (1) Similar Loss Convergence - the loss functions for both vulnerabilities converge similarly when optimizing for target-specific outputs; and (2) Gradient Consistency in Attention Redistribution - both exhibit consistent gradient behavior driven by shared attention dynamics. We validate these propositions empirically on LLaVA-1.5 and MiniGPT-4, showing consistent optimization trends and aligned gradients. Leveraging this connection, we demonstrate that mitigation techniques for hallucinations can reduce jailbreak success rates, and vice versa. Our findings reveal a shared failure mode in LFMs and suggest that robustness strategies should jointly address both vulnerabilities.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large foundation models (LFMs) are susceptible to two distinctvulnerabilities: hallucinations and jailbreak attacks. While typically studiedin isolation, we observe that defenses targeting one often affect the other,hinting at a deeper connection.  We propose a unified theoretical framework that models jailbreaks astoken-level optimization and hallucinations as attention-level optimization.Within this framework, we establish two key propositions: (1) \textit{SimilarLoss Convergence} - the loss functions for both vulnerabilities convergesimilarly when optimizing for target-specific outputs; and (2) \textit{GradientConsistency in Attention Redistribution} - both exhibit consistent gradientbehavior driven by shared attention dynamics.  We validate these propositions empirically on LLaVA-1.5 and MiniGPT-4,showing consistent optimization trends and aligned gradients. Leveraging thisconnection, we demonstrate that mitigation techniques for hallucinations canreduce jailbreak success rates, and vice versa. Our findings reveal a sharedfailure mode in LFMs and suggest that robustness strategies should jointlyaddress both vulnerabilities.</description>
      <author>example@mail.com (Haibo Jin, Peiyan Zhang, Peiran Wang, Man Luo, Haohan Wang)</author>
      <guid isPermaLink="false">2505.24232v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Single Domain Generalization for Alzheimer's Detection from 3D MRIs with Pseudo-Morphological Augmentations and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2505.22465v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对阿尔茨海默病MRI检测中存在的挑战，提出了一种针对单域泛化设置的方法，旨在提高模型在不同数据集上的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;尽管深度学习模型在阿尔茨海默病MRI检测方面取得了显著进展，但数据集不平衡、协议差异和有限的数据集多样性等问题仍然限制了模型的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;针对上述问题，本文旨在通过设计一个模型，在给定一个域的数据时，实现针对不同分布的未见域的最大性能。&lt;h4&gt;方法&lt;/h4&gt;本文提出使用可学习的伪形态学模块，以生成具有形状感知和解剖意义的类特定增强，并结合监督对比学习模块提取稳健的类特定表示。&lt;h4&gt;主要发现&lt;/h4&gt;在三个数据集上进行的实验表明，该方法在处理数据集不平衡和成像协议变化时，性能和泛化能力都有所提高。&lt;h4&gt;结论&lt;/h4&gt;该方法的源代码将在论文被接受后公开，链接为https://github.com/zobia111/SDG-Alzheimer。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although Alzheimer's disease detection via MRIs has advanced significantlythanks to contemporary deep learning models, challenges such as classimbalance, protocol variations, and limited dataset diversity often hindertheir generalization capacity. To address this issue, this article focuses onthe single domain generalization setting, where given the data of one domain, amodel is designed and developed with maximal performance w.r.t. an unseendomain of distinct distribution. Since brain morphology is known to play acrucial role in Alzheimer's diagnosis, we propose the use of learnablepseudo-morphological modules aimed at producing shape-aware, anatomicallymeaningful class-specific augmentations in combination with a supervisedcontrastive learning module to extract robust class-specific representations.Experiments conducted across three datasets show improved performance andgeneralization capacity, especially under class imbalance and imaging protocolvariations. The source code will be made available upon acceptance athttps://github.com/zobia111/SDG-Alzheimer.</description>
      <author>example@mail.com (Zobia Batool, Huseyin Ozkan, Erchan Aptoula)</author>
      <guid isPermaLink="false">2505.22465v2</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Foundation Models for Zero-Shot Biometric Tasks</title>
      <link>http://arxiv.org/abs/2505.24214v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究利用视觉-语言模型（VLMs）和多模态大型语言模型（MLLMs）在生物识别领域的应用，评估了这些模型在六项生物识别任务中的零样本和少样本性能。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型的兴起，VLMs和MLLMs在人工智能领域展现了强大的泛化能力。然而，这些模型在生物识别和分析方面的潜力尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在建立一项综合基准，评估公开可用的VLMs和MLLMs在六个生物识别任务中的表现，包括人脸验证、软生物特征属性预测、虹膜识别、演示攻击检测和面部操纵检测。&lt;h4&gt;方法&lt;/h4&gt;研究使用了41种VLMs，在LFW和IITD-R-Full等数据集上进行了实验，验证了模型在各项任务中的性能。此外，研究还尝试了将简单分类器应用于模型嵌入，以提高检测深度伪造、演示攻击和提取软生物特征属性等任务的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，这些基础模型可以从各种生物识别任务中提取特征，并取得了不同程度的成功。例如，在人脸验证任务中，LFW数据集上取得了96.77%的匹配准确率；在虹膜识别任务中，IITD-R-Full数据集上取得了97.55%的匹配准确率。&lt;h4&gt;结论&lt;/h4&gt;这项工作强调了预训练模型在实现人工通用智能长期愿景中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;The advent of foundation models, particularly Vision-Language Models (VLMs) and Multi-modal Large Language Models (MLLMs), has redefined the frontiers of artificial intelligence, enabling remarkable generalization across diverse tasks with minimal or no supervision. Yet, their potential in biometric recognition and analysis remains relatively underexplored. In this work, we introduce a comprehensive benchmark that evaluates the zero-shot and few-shot performance of state-of-the-art publicly available VLMs and MLLMs across six biometric tasks spanning the face and iris modalities: face verification, soft biometric attribute prediction (gender and race), iris recognition, presentation attack detection (PAD), and face manipulation detection (morphs and deepfakes). A total of 41 VLMs were used in this evaluation. Experiments show that embeddings from these foundation models can be used for diverse biometric tasks with varying degrees of success. For example, in the case of face verification, a True Match Rate (TMR) of 96.77 percent was obtained at a False Match Rate (FMR) of 1 percent on the Labeled Face in the Wild (LFW) dataset, without any fine-tuning. In the case of iris recognition, the TMR at 1 percent FMR on the IITD-R-Full dataset was 97.55 percent without any fine-tuning. Further, we show that applying a simple classifier head to these embeddings can help perform DeepFake detection for faces, Presentation Attack Detection (PAD) for irides, and extract soft biometric attributes like gender and ethnicity from faces with reasonably high accuracy. This work reiterates the potential of pretrained models in achieving the long-term vision of Artificial General Intelligence.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of foundation models, particularly Vision-Language Models (VLMs)and Multi-modal Large Language Models (MLLMs), has redefined the frontiers ofartificial intelligence, enabling remarkable generalization across diversetasks with minimal or no supervision. Yet, their potential in biometricrecognition and analysis remains relatively underexplored. In this work, weintroduce a comprehensive benchmark that evaluates the zero-shot and few-shotperformance of state-of-the-art publicly available VLMs and MLLMs across sixbiometric tasks spanning the face and iris modalities: face verification, softbiometric attribute prediction (gender and race), iris recognition,presentation attack detection (PAD), and face manipulation detection (morphsand deepfakes). A total of 41 VLMs were used in this evaluation. Experimentsshow that embeddings from these foundation models can be used for diversebiometric tasks with varying degrees of success. For example, in the case offace verification, a True Match Rate (TMR) of 96.77 percent was obtained at aFalse Match Rate (FMR) of 1 percent on the Labeled Face in the Wild (LFW)dataset, without any fine-tuning. In the case of iris recognition, the TMR at 1percent FMR on the IITD-R-Full dataset was 97.55 percent without anyfine-tuning. Further, we show that applying a simple classifier head to theseembeddings can help perform DeepFake detection for faces, Presentation AttackDetection (PAD) for irides, and extract soft biometric attributes like genderand ethnicity from faces with reasonably high accuracy. This work reiteratesthe potential of pretrained models in achieving the long-term vision ofArtificial General Intelligence.</description>
      <author>example@mail.com (Redwan Sony, Parisa Farmanifard, Hamzeh Alzwairy, Nitish Shukla, Arun Ross)</author>
      <guid isPermaLink="false">2505.24214v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Improving Multilingual Speech Models on ML-SUPERB 2.0: Fine-tuning with Data Augmentation and LID-Aware CTC</title>
      <link>http://arxiv.org/abs/2505.24200v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的多语言语音处理方法，通过探索多种策略来适应预训练的Speech Foundation Models (SFM)，并在ML-SUPERB 2.0数据集上实现了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;尽管使用SFM在语言识别（LID）和自动语音识别（ASR）等任务上取得了良好的性能，但在资源有限的情况下进行微调时，这些模型面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提高多语言LID和ASR在ML-SUPERB 2.0数据集上的性能。&lt;h4&gt;方法&lt;/h4&gt;采用冻结上游训练、部分微调、低秩适应等策略来调整SFM；应用数据增强来减少在少样本设置中的性能差距；引入LID连接主义时序分类（CTC）损失进行正则化。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在ML-SUPERB 2.0数据集上实现了LID准确率的14%相对提升和ASR错误率（CER）的30%相对降低，并在Interspeech 2025 ML-SUPERB 2.0挑战赛中获得第二名。&lt;h4&gt;结论&lt;/h4&gt;通过上述方法，显著提升了多语言语音处理模型的性能，为实际应用提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multilingual speech processing with self-supervised or supervised pre-trainedSpeech Foundation Models (SFM) has achieved strong performance on tasks likeLanguage Identification (LID) and Automatic Speech Recognition (ASR). However,these models struggle with limited resources during fine-tuning. This paperenhances multilingual LID and ASR on ML-SUPERB 2.0 by exploring multiplestrategies for adapting SFMs, including frozen upstream training, partialfine-tuning, and low-rank adaptation. Furthermore, we employ data augmentationto mitigate performance gaps in few-shot settings and introduce LIDConnectionist Temporal Classification (CTC) loss for regularization. Ourapproach achieves a 14% relative improvement in LID accuracy and a 30% relativereduction in ASR CER over the baseline on ML-SUPERB 2.0, securing second placein the Interspeech 2025 ML-SUPERB 2.0 Challenge.</description>
      <author>example@mail.com (Qingzheng Wang, Jiancheng Sun, Yifan Peng, Shinji Watanabe)</author>
      <guid isPermaLink="false">2505.24200v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>MaCP: Minimal yet Mighty Adaptation via Hierarchical Cosine Projection</title>
      <link>http://arxiv.org/abs/2505.23870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2410.09103&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MaCP是一种新的自适应方法，通过最小化参数和内存需求，在微调大型基础模型时实现了卓越的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的自适应方法在微调大型基础模型时通常需要大量的参数和内存。&lt;h4&gt;目的&lt;/h4&gt;MaCP旨在利用余弦投影的能量紧缩和去相关特性，提高模型效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;MaCP将权重变化从低秩自适应投影到离散余弦空间，并将权重变化分配到不同的离散余弦谱级别，然后选择每个分配中最关键的频率成分。&lt;h4&gt;主要发现&lt;/h4&gt;MaCP在包括自然语言理解、自然语言生成、文本摘要以及图像分类和视频理解在内的多种单模态和多模态任务中表现出有效性，与现有方法相比，它提供了更高的准确性、显著降低的计算复杂度和更低的内存需求。&lt;h4&gt;结论&lt;/h4&gt;MaCP是一种高效的自适应方法，适用于微调大型基础模型，具有显著的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a new adaptation method MaCP, Minimal yet Mighty adaptive CosineProjection, that achieves exceptional performance while requiring minimalparameters and memory for fine-tuning large foundation models. Its general ideais to exploit the superior energy compaction and decorrelation properties ofcosine projection to improve both model efficiency and accuracy. Specifically,it projects the weight change from the low-rank adaptation into the discretecosine space. Then, the weight change is partitioned over different levels ofthe discrete cosine spectrum, and each partition's most critical frequencycomponents are selected. Extensive experiments demonstrate the effectiveness ofMaCP across a wide range of single-modality tasks, including natural languageunderstanding, natural language generation, text summarization, as well asmulti-modality tasks such as image classification and video understanding. MaCPconsistently delivers superior accuracy, significantly reduced computationalcomplexity, and lower memory requirements compared to existing alternatives.</description>
      <author>example@mail.com (Yixian Shen, Qi Bi, Jia-Hong Huang, Hongyi Zhu, Andy D. Pimentel, Anuj Pathania)</author>
      <guid isPermaLink="false">2505.23870v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Invariant Link Selector for Spatial-Temporal Out-of-Distribution Problem</title>
      <link>http://arxiv.org/abs/2505.24178v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by AISTATS 2025. 22 pages, 2 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对时间序列图上的鲁棒不变学习的方法，以解决训练环境和测试环境之间的数据差异问题。&lt;h4&gt;背景&lt;/h4&gt;在基础模型时代，数据分布不匹配（OOD）问题阻碍了人工智能的泛化能力，特别是当关联时间因素时，问题更加复杂。&lt;h4&gt;目的&lt;/h4&gt;旨在研究时间图中哪些组件在标签方面最具不变性和代表性，以实现鲁棒的不变学习。&lt;h4&gt;方法&lt;/h4&gt;使用信息瓶颈（IB）方法，提出了一种误差界限不变链接选择器，在训练过程中区分不变组件和可变组件，使深度学习模型对不同测试场景具有可泛化性。此外，还导出了一系列严格通用的优化函数，并配备了特定于任务的损失函数，例如时间链接预测，以便预训练模型解决现实世界的应用任务。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过实验验证了在引用推荐和商品推荐等实际应用中的有效性。&lt;h4&gt;结论&lt;/h4&gt;该研究为时间序列图上的鲁棒不变学习提供了一种新方法，有助于提高人工智能模型的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;In the era of foundation models, Out-of- Distribution (OOD) problems, i.e.,the data discrepancy between the training environments and testingenvironments, hinder AI generalization. Further, relational data like graphsdisobeying the Independent and Identically Distributed (IID) condition makes theproblem more challenging, especially much harder when it is associated withtime. Motivated by this, to realize the robust invariant learning over temporalgraphs, we want to investigate what components in temporal graphs are mostinvariant and representative with respect to labels. With the InformationBottleneck (IB) method, we propose an error-bounded Invariant Link Selectorthat can distinguish invariant components and variant components during thetraining process to make the deep learning model generalizable for differenttesting scenarios. Besides deriving a series of rigorous generalizableoptimization functions, we also equip the training with task-specific lossfunctions, e.g., temporal link prediction, to make pretrained models solvemore real-world application tasks like citation recommendation and merchandiserecommendation, as demonstrated in our experiments with state-of-the-art (SOTA)methods. Our code is available at https://github.com/kthrn22/OOD-Linker.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of foundation models, Out-of- Distribution (OOD) problems, i.e.,the data discrepancy between the training environments and testingenvironments, hinder AI generalization. Further, relational data like graphsdisobeying the Independent and Identically Distributed (IID) condition makesthe problem more challenging, especially much harder when it is associated withtime. Motivated by this, to realize the robust invariant learning over temporalgraphs, we want to investigate what components in temporal graphs are mostinvariant and representative with respect to labels. With the InformationBottleneck (IB) method, we propose an error-bounded Invariant Link Selectorthat can distinguish invariant components and variant components during thetraining process to make the deep learning model generalizable for differenttesting scenarios. Besides deriving a series of rigorous generalizableoptimization functions, we also equip the training with task-specific lossfunctions, e.g., temporal link prediction, to make pretrained models solvereal-world application tasks like citation recommendation and merchandiserecommendation, as demonstrated in our experiments with state-of-the-art (SOTA)methods. Our code is available at https://github.com/kthrn22/OOD-Linker.</description>
      <author>example@mail.com (Katherine Tieu, Dongqi Fu, Jun Wu, Jingrui He)</author>
      <guid isPermaLink="false">2505.24178v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Pretraining Deformable Image Registration Networks with Random Images</title>
      <link>http://arxiv.org/abs/2505.24167v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by MIDL 2025. Code available at  https://github.com/junyuchen245/Pretraining_Image_Registration_DNNs&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的医学图像配准方法，通过在随机生成的图像上进行预训练来提高配准精度和效率。&lt;h4&gt;背景&lt;/h4&gt;深度学习在医学图像配准中的应用日益增加，但传统的训练方法需要大量的医学图像数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的预训练策略，以减少对特定领域数据的依赖，并提高配准模型的性能。&lt;h4&gt;方法&lt;/h4&gt;利用随机生成的图像进行预训练，这些图像具有精心设计的噪声和对比度属性，以模拟医学图像。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该预训练策略提高了配准精度，减少了达到竞争性性能所需的特定领域数据量，并加快了下游训练的收敛速度。&lt;h4&gt;结论&lt;/h4&gt;该方法通过预训练提高了医学图像配准的准确性和效率，为医学图像配准提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，基于深度学习的医学图像配准技术取得了显著进展，表明训练深度神经网络（DNNs）并不一定需要医学图像。先前的研究表明，在具有精心设计的噪声和对比度属性的随机图像上训练的DNNs仍然可以很好地泛化到未见过的医学数据。基于这一洞察，我们提出使用随机图像之间的配准作为预训练图像配准基础模型的一个代理任务。实证结果表明，我们的预训练策略提高了配准精度，减少了达到竞争性性能所需的特定领域数据量，并加速了下游训练的收敛，从而提高了计算效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in deep learning-based medical image registration have shownthat training deep neural networks~(DNNs) does not necessarily require medicalimages. Previous work showed that DNNs trained on randomly generated imageswith carefully designed noise and contrast properties can still generalize wellto unseen medical data. Building on this insight, we propose using registrationbetween random images as a proxy task for pretraining a foundation model forimage registration. Empirical results show that our pretraining strategyimproves registration accuracy, reduces the amount of domain-specific dataneeded to achieve competitive performance, and accelerates convergence duringdownstream training, thereby enhancing computational efficiency.</description>
      <author>example@mail.com (Junyu Chen, Shuwen Wei, Yihao Liu, Aaron Carass, Yong Du)</author>
      <guid isPermaLink="false">2505.24167v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>The Butterfly Effect in Pathology: Exploring Security in Pathology Foundation Models</title>
      <link>http://arxiv.org/abs/2505.24141v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究首次系统地调查了病理基础模型在对抗攻击下的安全性，提出了一种无标签攻击框架，并通过实验验证了攻击的有效性。&lt;h4&gt;背景&lt;/h4&gt;病理基础模型在研究和临床决策支持系统中得到广泛应用，但其对抗攻击的脆弱性尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;探索病理基础模型在对抗攻击下的安全性，并提出防御策略。&lt;h4&gt;方法&lt;/h4&gt;引入了“局部扰动全局影响”的原则，提出了一种无需访问下游任务标签的无标签攻击框架，并对四个经典的白盒攻击方法进行了修订。&lt;h4&gt;主要发现&lt;/h4&gt;通过修改每张幻灯片0.1%的patches，攻击导致下游准确率下降最多可达20%。分析了影响攻击成功的关键因素，探讨了patch级脆弱性与语义内容之间的关系，并对潜在防御策略进行了初步研究。&lt;h4&gt;结论&lt;/h4&gt;本研究为未来研究病理基础模型的对抗鲁棒性和可靠部署奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;With the widespread adoption of pathology foundation models in both research and clinical decision support systems, exploring their security has become a critical concern. However, despite their growing impact, the vulnerability of these models to adversarial attacks remains largely unexplored. In this work, we present the first systematic investigation into the security of pathology foundation models for whole slide image (WSI) analysis against adversarial attacks. Specifically, we introduce the principle of 'local perturbation with global impact' and propose a label-free attack framework that operates without requiring access to downstream task labels. Under this attack framework, we revise four classical white-box attack methods and redefine the perturbation budget based on the characteristics of WSI. We conduct comprehensive experiments on three representative pathology foundation models across five datasets and six downstream tasks. Despite modifying only 0.1% of patches per slide with imperceptible noise, our attack leads to downstream accuracy degradation that can reach up to 20% in the worst cases. Furthermore, we analyze key factors that influence attack success, explore the relationship between patch-level vulnerability and semantic content, and conduct a preliminary investigation into potential defense strategies. These findings lay the groundwork for future research on the adversarial robustness and reliable deployment of pathology foundation models. Our code is publicly available at: https://github.com/Jiashuai-Liu-hmos/Attack-WSI-pathology-foundation-models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the widespread adoption of pathology foundation models in both researchand clinical decision support systems, exploring their security has become acritical concern. However, despite their growing impact, the vulnerability ofthese models to adversarial attacks remains largely unexplored. In this work,we present the first systematic investigation into the security of pathologyfoundation models for whole slide image~(WSI) analysis against adversarialattacks. Specifically, we introduce the principle of \textit{local perturbationwith global impact} and propose a label-free attack framework that operateswithout requiring access to downstream task labels. Under this attackframework, we revise four classical white-box attack methods and redefine theperturbation budget based on the characteristics of WSI. We conductcomprehensive experiments on three representative pathology foundation modelsacross five datasets and six downstream tasks. Despite modifying only 0.1\% ofpatches per slide with imperceptible noise, our attack leads to downstreamaccuracy degradation that can reach up to 20\% in the worst cases. Furthermore,we analyze key factors that influence attack success, explore the relationshipbetween patch-level vulnerability and semantic content, and conduct apreliminary investigation into potential defence strategies. These findings laythe groundwork for future research on the adversarial robustness and reliabledeployment of pathology foundation models. Our code is publicly available at:https://github.com/Jiashuai-Liu-hmos/Attack-WSI-pathology-foundation-models.</description>
      <author>example@mail.com (Jiashuai Liu, Yingjia Shang, Yingkang Zhan, Di Zhang, Yi Niu, Dong Wei, Xian Wu, Zeyu Gao, Chen Li, Yefeng Zheng)</author>
      <guid isPermaLink="false">2505.24141v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Directed Homophily-Aware Graph Neural Network</title>
      <link>http://arxiv.org/abs/2505.22362v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DHGNN的图神经网络框架，该框架通过引入同质性和方向敏感组件来解决现有GNN在异质邻域泛化困难和忽略图方向性问题。&lt;h4&gt;背景&lt;/h4&gt;现有的图神经网络在处理图结构数据时取得了显著成功，但大多数GNN在处理异质邻域时泛化能力有限，并且忽略了现实世界图中图的方向性，导致在不对称结构的定向图上性能不佳。&lt;h4&gt;目的&lt;/h4&gt;提出DHGNN以解决上述问题，使其能够更好地处理异质邻域和图的方向性。&lt;h4&gt;方法&lt;/h4&gt;DHGNN采用可重置的门控机制来根据同质性和信息量自适应地调节消息贡献，并使用结构感知的噪声容忍融合模块来有效整合来自原始和反向方向上的节点表示。&lt;h4&gt;主要发现&lt;/h4&gt;在异质和同质定向图数据集上的广泛实验表明，DHGNN在节点分类和链接预测任务中优于现有方法，特别是在链接预测任务中，DHGNN比最佳基线提高了高达15.07%。分析表明，门控机制能够捕捉到方向性同质性和层间同质性的波动，为复杂图结构上的消息传递行为提供了更深入的见解。&lt;h4&gt;结论&lt;/h4&gt;DHGNN通过结合同质性和方向敏感性，提高了图神经网络在处理定向图结构数据时的性能和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have achieved significant success in various learning tasks on graph-structured data. Nevertheless, most GNNs struggle to generalize to heterophilic neighborhoods. Additionally, many GNNs ignore the directional nature of real-world graphs, resulting in suboptimal performance on directed graphs with asymmetric structures. In this work, we propose Directed Homophily-aware Graph Neural Network (DHGNN), a novel framework that addresses these limitations by incorporating homophily-aware and direction-sensitive components. DHGNN employs a resettable gating mechanism to adaptively modulate message contributions based on homophily levels and informativeness, and a structure-aware noise-tolerant fusion module to effectively integrate node representations from the original and reverse directions. Extensive experiments on both homophilic and heterophilic directed graph datasets demonstrate that DHGNN outperforms state-of-the-art methods in node classification and link prediction. In particular, DHGNN improves over the best baseline by up to 15.07% in link prediction. Our analysis further shows that the gating mechanism captures directional homophily gaps and fluctuating homophily across layers, providing deeper insights into message-passing behavior on complex graph structures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have achieved significant success in variouslearning tasks on graph-structured data. Nevertheless, most GNNs struggle togeneralize to heterophilic neighborhoods. Additionally, many GNNs ignore thedirectional nature of real-world graphs, resulting in suboptimal performance ondirected graphs with asymmetric structures. In this work, we propose DirectedHomophily-aware Graph Neural Network (DHGNN), a novel framework that addressesthese limitations by incorporating homophily-aware and direction-sensitivecomponents. DHGNN employs a resettable gating mechanism to adaptively modulatemessage contributions based on homophily levels and informativeness, and astructure-aware noise-tolerant fusion module to effectively integrate noderepresentations from the original and reverse directions. Extensive experimentson both homophilic and heterophilic directed graph datasets demonstrate thatDHGNN outperforms state-of-the-art methods in node classification and linkprediction. In particular, DHGNN improves over the best baseline by up to15.07% in link prediction. Our analysis further shows that the gating mechanismcaptures directional homophily gaps and fluctuating homophily across layers,providing deeper insights into message-passing behavior on complex graphstructures.</description>
      <author>example@mail.com (Aihu Zhang, Jiaxing Xu, Mengcheng Lan, Shili Xiang, Yiping Ke)</author>
      <guid isPermaLink="false">2505.22362v2</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Federated Foundation Model for GI Endoscopy Images</title>
      <link>http://arxiv.org/abs/2505.24108v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 11 figures, submitted to BHI2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于胃肠内镜成像的基础模型训练的联邦学习框架，旨在解决数据稀缺和隐私保护的问题。&lt;h4&gt;背景&lt;/h4&gt;胃肠内镜检查对于早期发现疾病和改善患者预后至关重要。深度学习在支持胃肠诊断和决策方面已取得成功，但这些模型需要昂贵的数据集和标签。&lt;h4&gt;目的&lt;/h4&gt;开发能够学习通用表示的基础模型，以克服数据稀缺，并解决医疗数据的敏感性和隐私保护问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种联邦学习框架，用于在本地医院环境中训练基础模型，同时为共享模型做出贡献。在异构和同构环境下进行了实验，评估了多个联邦学习算法的适用性。&lt;h4&gt;主要发现&lt;/h4&gt;训练的基础模型在分类、检测和分割三个关键下游任务上均取得了改进性能，证明了在联邦和隐私保护环境中的有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法在保护患者隐私的同时，通过联邦学习框架提高了胃肠内镜成像模型的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gastrointestinal (GI) endoscopy is essential in identifying GI tractabnormalities in order to detect diseases in their early stages and improvepatient outcomes. Although deep learning has shown success in supporting GIdiagnostics and decision-making, these models require curated datasets withlabels that are expensive to acquire. Foundation models offer a promisingsolution by learning general-purpose representations, which can be finetunedfor specific tasks, overcoming data scarcity. Developing foundation models formedical imaging holds significant potential, but the sensitive and protectednature of medical data presents unique challenges. Foundation model trainingtypically requires extensive datasets, and while hospitals generate largevolumes of data, privacy restrictions prevent direct data sharing, makingfoundation model training infeasible in most scenarios. In this work, wepropose a FL framework for training foundation models for gastroendoscopyimaging, enabling data to remain within local hospital environments whilecontributing to a shared model. We explore several established FL algorithms,assessing their suitability for training foundation models without relying ontask-specific labels, conducting experiments in both homogeneous andheterogeneous settings. We evaluate the trained foundation model on threecritical downstream tasks--classification, detection, and segmentation--anddemonstrate that it achieves improved performance across all tasks,highlighting the effectiveness of our approach in a federated,privacy-preserving setting.</description>
      <author>example@mail.com (Alina Devkota, Annahita Amireskandari, Joel Palko, Shyam Thakkar, Donald Adjeroh, Xiajun Jiang, Binod Bhattarai, Prashnna K. Gyawali)</author>
      <guid isPermaLink="false">2505.24108v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Weakly-Supervised Affordance Grounding Guided by Part-Level Semantic Priors</title>
      <link>http://arxiv.org/abs/2505.24103v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究弱监督的可用性定位任务，通过使用人-物交互图像和自视角物体图像训练模型识别物体上的可用性区域，无需密集标签。&lt;h4&gt;背景&lt;/h4&gt;以往的工作大多基于类激活图，这些图在语义分割中有效，但不一定适合定位动作和功能。&lt;h4&gt;目的&lt;/h4&gt;利用最新的高级基础模型，开发了一个基于伪标签的监督训练流程。&lt;h4&gt;方法&lt;/h4&gt;伪标签由一个现成的部分分割模型生成，并受可用性到部分名称的映射指导。此外，引入了三个对基线模型的关键增强：标签精炼阶段、细粒度特征对齐过程和轻量级推理模块。&lt;h4&gt;主要发现&lt;/h4&gt;这些技术利用了现成基础模型中嵌入的静态对象语义知识，以改善可用性学习，有效地弥合了物体和动作之间的差距。&lt;h4&gt;结论&lt;/h4&gt;广泛的实验表明，所提出的模型性能在现有方法上实现了突破性的改进。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we focus on the task of weakly supervised affordance grounding, where a model is trained to identify affordance regions on objects using human-object interaction images and egocentric object images without dense labels. Previous works are mostly built upon class activation maps, which are effective for semantic segmentation but may not be suitable for locating actions and functions. Leveraging recent advanced foundation models, we develop a supervised training pipeline based on pseudo labels. The pseudo labels are generated from an off-the-shelf part segmentation model, guided by a mapping from affordance to part names. Furthermore, we introduce three key enhancements to the baseline model: a label refining stage, a fine-grained feature alignment process, and a lightweight reasoning module. These techniques harness the semantic knowledge of static objects embedded in off-the-shelf foundation models to improve affordance learning, effectively bridging the gap between objects and actions. Extensive experiments demonstrate that the performance of the proposed model has achieved a breakthrough improvement over existing methods. Our codes are available at https://github.com/woyut/WSAG-PLSP.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we focus on the task of weakly supervised affordance grounding,where a model is trained to identify affordance regions on objects usinghuman-object interaction images and egocentric object images without denselabels. Previous works are mostly built upon class activation maps, which areeffective for semantic segmentation but may not be suitable for locatingactions and functions. Leveraging recent advanced foundation models, we developa supervised training pipeline based on pseudo labels. The pseudo labels aregenerated from an off-the-shelf part segmentation model, guided by a mappingfrom affordance to part names. Furthermore, we introduce three key enhancementsto the baseline model: a label refining stage, a fine-grained feature alignmentprocess, and a lightweight reasoning module. These techniques harness thesemantic knowledge of static objects embedded in off-the-shelf foundationmodels to improve affordance learning, effectively bridging the gap betweenobjects and actions. Extensive experiments demonstrate that the performance ofthe proposed model has achieved a breakthrough improvement over existingmethods. Our codes are available at https://github.com/woyut/WSAG-PLSP .</description>
      <author>example@mail.com (Peiran Xu, Yadong Mu)</author>
      <guid isPermaLink="false">2505.24103v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>SpeechVerifier: Robust Acoustic Fingerprint against Tampering Attacks via Watermarking</title>
      <link>http://arxiv.org/abs/2505.23821v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SpeechVerifier的语音验证方法，用于检测和验证公开演讲的完整性，以应对社交媒体时代恶意篡改演讲的问题。&lt;h4&gt;背景&lt;/h4&gt;社交媒体的兴起导致恶意篡改的公开演讲，特别是有影响力的人物演讲，严重影响了社会稳定和公众信任。&lt;h4&gt;目的&lt;/h4&gt;针对现有语音篡改检测方法的不足，即依赖外部数据或对良性操作敏感度不足，提出一种新的语音验证方法。&lt;h4&gt;方法&lt;/h4&gt;SpeechVerifier利用多尺度特征提取捕捉不同时间分辨率下的语音特征，并通过对比学习生成指纹来检测修改，指纹设计对良性操作具有鲁棒性，在恶意篡改时表现出显著变化。指纹通过分段水印嵌入到语音信号中，无需外部参考即可进行语音验证。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SpeechVerifier在检测篡改攻击方面有效，同时对良性操作具有鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;SpeechVerifier是一种有效的语音验证方法，可以有效地检测篡改攻击，并对良性操作具有鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;With the surge of social media, maliciously tampered public speeches, especially those from influential figures, have seriously affected social stability and public trust. Existing speech tampering detection methods remain insufficient: they either rely on external reference data or fail to be both sensitive to attacks and robust to benign operations, such as compression and resampling. To tackle these challenges, we introduce SpeechVerifer to proactively verify speech integrity using only the published speech itself, i.e., without requiring any external references. Inspired by audio fingerprinting and watermarking, SpeechVerifier can (i) effectively detect tampering attacks, (ii) be robust to benign operations and (iii) verify the integrity only based on published speeches. Briefly, SpeechVerifier utilizes multiscale feature extraction to capture speech features across different temporal resolutions. Then, it employs contrastive learning to generate fingerprints that can detect modifications at varying granularities. These fingerprints are designed to be robust to benign operations, but exhibit significant changes when malicious tampering occurs. To enable speech verification in a self-contained manner, the generated fingerprints are then embedded into the speech signal by segment-wise watermarking. Without external references, SpeechVerifier can retrieve the fingerprint from the published audio and check it with the embedded watermark to verify the integrity of the speech. Extensive experimental results demonstrate that the proposed SpeechVerifier is effective in detecting tampering attacks and robust to benign operations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the surge of social media, maliciously tampered public speeches,especially those from influential figures, have seriously affected socialstability and public trust. Existing speech tampering detection methods remaininsufficient: they either rely on external reference data or fail to be bothsensitive to attacks and robust to benign operations, such as compression andresampling. To tackle these challenges, we introduce SpeechVerifer toproactively verify speech integrity using only the published speech itself,i.e., without requiring any external references. Inspired by audiofingerprinting and watermarking, SpeechVerifier can (i) effectively detecttampering attacks, (ii) be robust to benign operations and (iii) verify theintegrity only based on published speeches. Briefly, SpeechVerifier utilizesmultiscale feature extraction to capture speech features across differenttemporal resolutions. Then, it employs contrastive learning to generatefingerprints that can detect modifications at varying granularities. Thesefingerprints are designed to be robust to benign operations, but exhibitsignificant changes when malicious tampering occurs. To enable speechverification in a self-contained manner, the generated fingerprints are thenembedded into the speech signal by segment-wise watermarking. Without externalreferences, SpeechVerifier can retrieve the fingerprint from the publishedaudio and check it with the embedded watermark to verify the integrity of thespeech. Extensive experimental results demonstrate that the proposedSpeechVerifier is effective in detecting tampering attacks and robust to benignoperations.</description>
      <author>example@mail.com (Lingfeng Yao, Chenpei Huang, Shengyao Wang, Junpei Xue, Hanqing Guo, Jiang Liu, Xun Chen, Miao Pan)</author>
      <guid isPermaLink="false">2505.23821v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Proxy-FDA: Proxy-based Feature Distribution Alignment for Fine-tuning Vision Foundation Models without Forgetting</title>
      <link>http://arxiv.org/abs/2505.24088v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Proxy-FDA的新颖正则化方法，旨在在微调基础模型时减少概念遗忘，同时不影响微调性能。&lt;h4&gt;背景&lt;/h4&gt;预训练的基础模型在大量数据上编码了丰富的现实世界概念，可以通过微调应用于下游任务。然而，在单一任务上微调基础模型可能导致在其他任务上的概念遗忘问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以减少在微调过程中先验知识的遗忘，同时不影响微调效果。&lt;h4&gt;方法&lt;/h4&gt;Proxy-FDA通过在预训练和微调的特征空间之间执行特征分布对齐（使用最近邻图），并通过动态生成的信息代理来增加数据多样性，进一步改进对齐。&lt;h4&gt;主要发现&lt;/h4&gt;Proxy-FDA显著减少了微调过程中的概念遗忘，并且发现遗忘与分布距离度量之间存在强烈的相关性（与L2距离相比）。&lt;h4&gt;结论&lt;/h4&gt;Proxy-FDA在各种微调设置（端到端、少样本和持续调整）以及不同的任务（如图像分类、字幕和VQA）中都显示出其优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在大量数据上预训练的视觉基础模型编码了丰富的现实世界概念，这些概念可以通过微调应用于下游任务。然而，在单一任务上对基础模型进行微调通常会导致其他任务上的概念遗忘问题。最近的方法旨在通过微调来减轻先验知识的遗忘，同时不影响微调性能。知识通常通过匹配原始和微调模型权重或特征对来保留。然而，这种点对点的匹配可能过于强烈，而没有意识到编码丰富知识的特征邻域结构。我们提出了一种名为Proxy-FDA的新颖正则化方法，它明确地保留了特征空间中的结构知识。Proxy-FDA在预训练和微调的特征空间之间执行特征分布对齐（使用最近邻图），并通过动态生成的信息代理来增加数据多样性，进一步改进对齐。实验表明，Proxy-FDA在微调过程中显著减少了概念遗忘，并且我们发现遗忘与分布距离度量之间存在强烈的相关性（与L2距离相比）。我们进一步证明了Proxy-FDA在各种微调设置（端到端、少样本和持续调整）和不同任务（如图像分类、字幕和VQA）中的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision foundation models pre-trained on massive data encode richrepresentations of real-world concepts, which can be adapted to downstreamtasks by fine-tuning. However, fine-tuning foundation models on one task oftenleads to the issue of concept forgetting on other tasks. Recent methods ofrobust fine-tuning aim to mitigate forgetting of prior knowledge withoutaffecting the fine-tuning performance. Knowledge is often preserved by matchingthe original and fine-tuned model weights or feature pairs. However, suchpoint-wise matching can be too strong, without explicit awareness of thefeature neighborhood structures that encode rich knowledge as well. We proposea novel regularization method Proxy-FDA that explicitly preserves thestructural knowledge in feature space. Proxy-FDA performs Feature DistributionAlignment (using nearest neighbor graphs) between the pre-trained andfine-tuned feature spaces, and the alignment is further improved by informativeproxies that are generated dynamically to increase data diversity. Experimentsshow that Proxy-FDA significantly reduces concept forgetting duringfine-tuning, and we find a strong correlation between forgetting and adistributional distance metric (in comparison to L2 distance). We furtherdemonstrate Proxy-FDA's benefits in various fine-tuning settings (end-to-end,few-shot and continual tuning) and across different tasks like imageclassification, captioning and VQA.</description>
      <author>example@mail.com (Chen Huang, Skyler Seto, Hadi Pouransari, Mehrdad Farajtabar, Raviteja Vemulapalli, Fartash Faghri, Oncel Tuzel, Barry-John Theobald, Josh Susskind)</author>
      <guid isPermaLink="false">2505.24088v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>From Images to Signals: Are Large Vision Models Useful for Time Series Analysis?</title>
      <link>http://arxiv.org/abs/2505.24030v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了Transformer模型在时间序列研究中的应用，尤其是大型语言模型（LLMs）和基础模型在时间序列分析中的潜力，并探讨了大型视觉模型（LVMs）在时间序列分析中的效用。&lt;h4&gt;背景&lt;/h4&gt;Transformer模型在时间序列研究中的应用越来越受到关注，多模态研究方向的兴起促使人们探索大型视觉模型（LVMs）在时间序列分析中的价值。&lt;h4&gt;目的&lt;/h4&gt;为了评估LVMs在时间序列分析中的实用性，研究者设计并进行了首个涉及4种LVMs、8种成像方法、18个数据集和26个基线模型的研究，包括高级（分类）和低级（预测）任务，并进行了广泛的消融分析。&lt;h4&gt;方法&lt;/h4&gt;研究者设计了实验，比较了LVMs在不同时间序列任务上的表现，包括时间序列分类和预测，并进行了详细的消融分析。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现LVMs在时间序列分类任务中表现出色，但在预测任务上面临挑战。尽管效果显著，但当前最有效的LVM预测模型仅限于特定类型的LVM和成像方法，对预测周期存在偏见，且难以有效利用长窗口的历史数据。&lt;h4&gt;结论&lt;/h4&gt;本文的研究成果为LVM和多模态技术在时间序列任务中的应用提供了基础，并为进一步研究提供了参考。&lt;h4&gt;翻译&lt;/h4&gt;Transformer-based models have gained increasing attention in time series research, driving interest in Large Language Models (LLMs) and foundation models for time series analysis. As the field moves toward multi-modality, Large Vision Models (LVMs) are emerging as a promising direction. In the past, the effectiveness of Transformer and LLMs in time series has been debated. When it comes to LVMs, a similar question arises: are LVMs truly useful for time series analysis? To address it, we design and conduct the first principled study involving 4 LVMs, 8 imaging methods, 18 datasets and 26 baselines across both high-level (classification) and low-level (forecasting) tasks, with extensive ablation analysis. Our findings indicate LVMs are indeed useful for time series classification but face challenges in forecasting. Although effective, the contemporary best LVM forecasters are limited to specific types of LVMs and imaging methods, exhibit a bias toward forecasting periods, and have limited ability to utilize long look-back windows. We hope our findings could serve as a cornerstone for future research on LVM- and multimodal-based solutions to different time series tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer-based models have gained increasing attention in time seriesresearch, driving interest in Large Language Models (LLMs) and foundationmodels for time series analysis. As the field moves toward multi-modality,Large Vision Models (LVMs) are emerging as a promising direction. In the past,the effectiveness of Transformer and LLMs in time series has been debated. Whenit comes to LVMs, a similar question arises: are LVMs truely useful for timeseries analysis? To address it, we design and conduct the first principledstudy involving 4 LVMs, 8 imaging methods, 18 datasets and 26 baselines acrossboth high-level (classification) and low-level (forecasting) tasks, withextensive ablation analysis. Our findings indicate LVMs are indeed useful fortime series classification but face challenges in forecasting. Althougheffective, the contemporary best LVM forecasters are limited to specific typesof LVMs and imaging methods, exhibit a bias toward forecasting periods, andhave limited ability to utilize long look-back windows. We hope our findingscould serve as a cornerstone for future research on LVM- and multimodal-basedsolutions to different time series tasks.</description>
      <author>example@mail.com (Ziming Zhao, ChengAo Shen, Hanghang Tong, Dongjin Song, Zhigang Deng, Qingsong Wen, Jingchao Ni)</author>
      <guid isPermaLink="false">2505.24030v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>DINO-R1: Incentivizing Reasoning Capability in Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2505.24025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DINO-R1的新方法，旨在通过强化学习提升视觉基础模型在视觉推理方面的能力。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型的推理能力受到广泛关注，并取得了显著成果。然而，这些推理能力在视觉基础模型，如DINO系列中，尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;本研究的目标是使用强化学习来提升视觉基础模型的视觉推理能力。&lt;h4&gt;方法&lt;/h4&gt;DINO-R1引入了Group Relative Query Optimization (GRQO)这一新的强化式训练策略，该策略基于分组归一化的对齐质量来计算查询级别的奖励。同时，通过应用KL正则化来稳定物体分布，以减少训练过程中的不稳定性和过拟合。在Grounding-DINO的基础上，DINO-R1家族模型集成了视觉提示编码器和视觉引导的查询选择机制。&lt;h4&gt;主要发现&lt;/h4&gt;在COCO、LVIS和ODinW上的大量实验表明，DINO-R1在开放词汇和封闭集视觉提示场景中都显著优于监督式微调基线，并表现出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;DINO-R1在提升视觉基础模型推理能力方面取得了一定的成果，为该领域的研究提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;最近对大型语言模型（如DeepSeek-R1）推理能力的爆炸性兴趣，通过基于强化学习的微调框架（例如Group Relative Policy Optimization (GRPO)方法）已经展示了显著的成功。然而，这些推理能力仍然没有得到充分探索，并且特别在视觉基础模型中缺失，包括像DINO系列这样的表示模型。在这项工作中，我们提出了DINO-R1，这是第一个试图使用强化学习来激励视觉基础模型视觉上下文推理能力的研究。具体来说，DINO-R1引入了Group Relative Query Optimization (GRQO)，这是一种为基于查询的表示模型专门设计的新的强化式训练策略，它根据分组归一化的对齐质量计算查询级别的奖励。我们还应用KL正则化来稳定物体分布，以减少训练的不稳定性。这种联合优化能够在查询上实现密集和有表达力的监督，同时减轻过拟合和分布漂移。基于Grounding-DINO，我们训练了一系列的DINO-R1家族模型，这些模型集成了视觉提示编码器和视觉引导的查询选择机制。在COCO、LVIS和ODinW上的大量实验表明，DINO-R1在开放词汇和封闭集视觉提示场景中都显著优于监督式微调基线，并实现了良好的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent explosive interest in the reasoning capabilities of large languagemodels, such as DeepSeek-R1, has demonstrated remarkable success throughreinforcement learning-based fine-tuning frameworks, exemplified by methodslike Group Relative Policy Optimization (GRPO). However, such reasoningabilities remain underexplored and notably absent in vision foundation models,including representation models like the DINO series. In this work, we propose\textbf{DINO-R1}, the first such attempt to incentivize visual in-contextreasoning capabilities of vision foundation models using reinforcementlearning. Specifically, DINO-R1 introduces \textbf{Group Relative QueryOptimization (GRQO)}, a novel reinforcement-style training strategy explicitlydesigned for query-based representation models, which computes query-levelrewards based on group-normalized alignment quality. We also applyKL-regularization to stabilize the objectness distribution to reduce thetraining instability. This joint optimization enables dense and expressivesupervision across queries while mitigating overfitting and distributionaldrift. Building upon Grounding-DINO, we train a series of DINO-R1 family modelsthat integrate a visual prompt encoder and a visual-guided query selectionmechanism. Extensive experiments on COCO, LVIS, and ODinW demonstrate thatDINO-R1 significantly outperforms supervised fine-tuning baselines, achievingstrong generalization in both open-vocabulary and closed-set visual promptingscenarios.</description>
      <author>example@mail.com (Chenbin Pan, Wenbin He, Zhengzhong Tu, Liu Ren)</author>
      <guid isPermaLink="false">2505.24025v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Modal View Enhanced Large Vision Models for Long-Term Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2505.24003v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DMMV的新颖的多模态视图框架，用于长期时间序列预测（LTSF）。该框架利用趋势季节分解和基于自适应分解的新型回溯残差，以集成多模态视图，并在多个数据集上优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;时间序列数据可以以多种形式表示，如图像和文本，从而提供多模态视图（MMVs）。这些视图可以揭示互补模式，并允许使用预训练的大型模型（如LVMs）进行LTSF。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效利用LVMs进行LTSF的新方法，同时克服LVMs的归纳偏差。&lt;h4&gt;方法&lt;/h4&gt;DMMV通过趋势季节分解和自适应分解，结合多模态视图来提高LTSF的性能。&lt;h4&gt;主要发现&lt;/h4&gt;与14个最先进的模型相比，DMMV在6个基准数据集上取得了最佳均方误差（MSE），表明其在LTSF中的优越性。&lt;h4&gt;结论&lt;/h4&gt;DMMV是一种有效的方法，可以提高LTSF的准确性，并在多个数据集上优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：时间序列，通常表示为数值序列，也可以转换为图像和文本，从而提供对同一底层信号的多模态视图（MMVs）。这些MMVs可以揭示互补模式，并允许使用强大的预训练大型模型，如大型视觉模型（LVMs），进行长期时间序列预测（LTSF）。然而，正如我们在这项工作中所确定的，将LVMs应用于LTSF会导致“预测期”的归纳偏差。为了利用这种偏差，我们提出了一种基于分解的多模态视图框架DMMV，它利用趋势季节分解和基于回溯残差的自适应分解来集成MMVs进行LTSF。与14个最先进的（SOTA）模型在多个数据集上的比较评估表明，DMMV优于单视图和现有的多模态基线，在8个基准数据集中的6个上实现了最佳的均方误差（MSE）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series, typically represented as numerical sequences, can also betransformed into images and texts, offering multi-modal views (MMVs) of thesame underlying signal. These MMVs can reveal complementary patterns and enablethe use of powerful pre-trained large models, such as large vision models(LVMs), for long-term time series forecasting (LTSF). However, as we identifiedin this work, applying LVMs to LTSF poses an inductive bias towards"forecasting periods". To harness this bias, we propose DMMV, a noveldecomposition-based multi-modal view framework that leverages trend-seasonaldecomposition and a novel backcast residual based adaptive decomposition tointegrate MMVs for LTSF. Comparative evaluations against 14 state-of-the-art(SOTA) models across diverse datasets show that DMMV outperforms single-viewand existing multi-modal baselines, achieving the best mean squared error (MSE)on 6 out of 8 benchmark datasets.</description>
      <author>example@mail.com (ChengAo Shen, Wenchao Yu, Ziming Zhao, Dongjin Song, Wei Cheng, Haifeng Chen, Jingchao Ni)</author>
      <guid isPermaLink="false">2505.24003v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Simplifying Bayesian Optimization Via In-Context Direct Optimum Sampling</title>
      <link>http://arxiv.org/abs/2505.23913v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对昂贵黑盒函数优化的完全零样本解决方案，无需使用代理模型或获取函数优化。&lt;h4&gt;背景&lt;/h4&gt;在科学和工程领域，优化昂贵的黑盒函数是一个普遍问题，常用的解决方案是贝叶斯优化（BO），它通常包括代理模型和获取函数两部分。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需代理模型拟合或获取函数优化的贝叶斯优化（BO）方法。&lt;h4&gt;方法&lt;/h4&gt;使用预训练的深度生成模型直接从最优点的后验分布中进行采样。&lt;h4&gt;主要发现&lt;/h4&gt;该方法与Thompson抽样等价，并在一系列真实世界基准测试中展示了其能力和成本效益。与基于高斯过程的BO相比，该方法在墙钟时间上实现了超过35倍的效率提升，使得高效的并行和分布式BO成为可能。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效地进行高吞吐量的优化，并且无需进行代理模型或获取函数的优化，从而提高了贝叶斯优化的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The optimization of expensive black-box functions is ubiquitous in scienceand engineering. A common solution to this problem is Bayesian optimization(BO), which is generally comprised of two components: (i) a surrogate model and(ii) an acquisition function, which generally require expensive re-training andoptimization steps at each iteration, respectively. Although recent workenabled in-context surrogate models that do not require re-training, virtuallyall existing BO methods still require acquisition function maximization toselect the next observation, which introduces many knobs to tune, such as MonteCarlo samplers and multi-start optimizers. In this work, we propose acompletely in-context, zero-shot solution for BO that does not requiresurrogate fitting or acquisition function optimization. This is done by using apre-trained deep generative model to directly sample from the posterior overthe optimum point. We show that this process is equivalent to Thompson samplingand demonstrate the capabilities and cost-effectiveness of our foundation modelon a suite of real-world benchmarks. We achieve an efficiency gain of more than35x in terms of wall-clock time when compared with Gaussian process-based BO,enabling efficient parallel and distributed BO, e.g., for high-throughputoptimization.</description>
      <author>example@mail.com (Gustavo Sutter Pessurno de Carvalho, Mohammed Abdulrahman, Hao Wang, Sriram Ganapathi Subramanian, Marc St-Aubin, Sharon O'Sullivan, Lawrence Wan, Luis Ricardez-Sandoval, Pascal Poupart, Agustinus Kristiadi)</author>
      <guid isPermaLink="false">2505.23913v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Point Cloud Completion through Unbalanced Optimal Transport</title>
      <link>http://arxiv.org/abs/2410.02671v4</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为UOT-UPC的模型，用于解决无配对点云补全问题，该模型通过学习无配对的不完整和完整点云数据之间的补全映射，避免了依赖于配对数据集。&lt;h4&gt;背景&lt;/h4&gt;无配对点云补全对于现实世界的应用至关重要，因为在这种情况下，完整的点云的真实数据往往不可用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，即UOT-UPC模型，以解决无配对点云补全问题。&lt;h4&gt;方法&lt;/h4&gt;UOT-UPC模型将无配对补全任务公式化为（不平衡）最优传输（OT）问题，并使用神经OT模型通过神经网络学习UOT映射。&lt;h4&gt;主要发现&lt;/h4&gt;UOT-UPC模型是第一个尝试利用UOT进行无配对点云补全的模型，在单类别和多类别基准测试中都取得了具有竞争力或优越的性能。特别是，该方法在处理类别不平衡问题时表现出特别鲁棒，这在现实世界的无配对点云补全场景中经常遇到。&lt;h4&gt;结论&lt;/h4&gt;UOT-UPC模型能够有效地解决无配对点云补全问题，并在实际应用中表现出良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：无配对点云补全是现实应用中的关键，因为完整的点云的真实数据通常不可用。通过从无配对的不完整和完整点云数据中学习补全映射，这项任务避免了依赖于配对数据集。在本文中，我们提出了名为无平衡最优传输映射用于无配对点云补全（UOT-UPC）的模型，该模型将无配对补全任务定义为（不平衡）最优传输（OT）问题。我们的方法采用了一个神经OT模型，使用神经网络学习UOT映射。我们的模型是第一个尝试利用UOT进行无配对点云补全的尝试，在单类别和多类别基准测试中均取得了具有竞争力或优越的性能。特别是，我们的方法在处理类别不平衡问题时表现出特别鲁棒，这在现实世界的无配对点云补全场景中经常遇到。代码可在https://github.com/LEETK99/UOT-UPC获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unpaired point cloud completion is crucial for real-world applications, whereground-truth data for complete point clouds are often unavailable. By learninga completion map from unpaired incomplete and complete point cloud data, thistask avoids the reliance on paired datasets. In this paper, we propose the\textit{Unbalanced Optimal Transport Map for Unpaired Point Cloud Completion(\textbf{UOT-UPC})} model, which formulates the unpaired completion task as the(Unbalanced) Optimal Transport (OT) problem. Our method employs a Neural OTmodel learning the UOT map using neural networks. Our model is the firstattempt to leverage UOT for unpaired point cloud completion, achievingcompetitive or superior performance on both single-category and multi-categorybenchmarks. In particular, our approach is especially robust under the classimbalance problem, which is frequently encountered in real-world unpaired pointcloud completion scenarios. The code is available athttps://github.com/LEETK99/UOT-UPC.</description>
      <author>example@mail.com (Taekyung Lee, Jaemoo Choi, Jaewoong Choi, Myungjoo Kang)</author>
      <guid isPermaLink="false">2410.02671v4</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>CAD-Coder: Text-to-CAD Generation with Chain-of-Thought and Geometric Reward</title>
      <link>http://arxiv.org/abs/2505.19713v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为CAD-Coder的新型框架，将文本到CAD的转换重新定义为生成基于Python的参数化CAD语言CadQuery脚本。该框架实现了直接的几何验证、丰富的建模词汇和与现有LLMs的无缝集成。&lt;h4&gt;背景&lt;/h4&gt;为了提高代码的有效性和几何精度，提出了一种两阶段学习流程：第一阶段是监督微调配对的文本-CadQuery数据，第二阶段是使用包含几何奖励（Chamfer距离）和格式奖励的CAD特定奖励的Group Reward Policy Optimization（GRPO）强化学习。&lt;h4&gt;目的&lt;/h4&gt;目的是开发一个能够从自然语言直接生成多样化、有效和复杂CAD模型的框架，以推进文本到CAD生成和几何推理的当前技术水平。&lt;h4&gt;方法&lt;/h4&gt;提出了一个思维链（CoT）规划过程来提高模型的推理能力，并构建了一个包含110K个文本-CadQuery-3D模型三元组和1.5K个CoT样本的大规模、高质量数据集。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，CAD-Coder能够使LLMs直接从自然语言生成多样化的、有效的和复杂的CAD模型。&lt;h4&gt;结论&lt;/h4&gt;CAD-Coder框架显著提升了文本到CAD的生成和几何推理能力，为相关领域的研究提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we introduce CAD-Coder, a novel framework that reformulates text-to-CAD as the generation of CadQuery scripts - a Python-based, parametricCAD language. This representation enables direct geometric validation, a richer modeling vocabulary, and seamless integration with existing LLMs. To further enhance code validity and geometric fidelity, we propose a two-stage learning pipeline: (1) supervised fine-tuning on paired text-CadQuery data, and (2) reinforcement learning with Group Reward Policy Optimization (GRPO), guided by a CAD-specific reward comprising both a geometric reward (Chamfer Distance) and a format reward. We also introduce a chain-of-thought (CoT) planning process to improve model reasoning, and construct a large-scale, high-quality dataset of 110K text-CadQuery-3D model triplets and 1.5K CoT samples via an automated pipeline. Extensive experiments demonstrate that CAD-Coder enables LLMs to generate diverse, valid, and complex CAD models directly from natural language, advancing the state of the art of text-to-CAD generation and geometric reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we introduce CAD-Coder, a novel framework that reformulatestext-to-CAD as the generation of CadQuery scripts - a Python-based, parametricCAD language. This representation enables direct geometric validation, a richermodeling vocabulary, and seamless integration with existing LLMs. To furtherenhance code validity and geometric fidelity, we propose a two-stage learningpipeline: (1) supervised fine-tuning on paired text-CadQuery data, and (2)reinforcement learning with Group Reward Policy Optimization (GRPO), guided bya CAD-specific reward comprising both a geometric reward (Chamfer Distance) anda format reward. We also introduce a chain-of-thought (CoT) planning process toimprove model reasoning, and construct a large-scale, high-quality dataset of110K text-CadQuery-3D model triplets and 1.5K CoT samples via an automatedpipeline. Extensive experiments demonstrate that CAD-Coder enables LLMs togenerate diverse, valid, and complex CAD models directly from natural language,advancing the state of the art of text-to-CAD generation and geometricreasoning.</description>
      <author>example@mail.com (Yandong Guan, Xilin Wang, Xingxi Ming, Jing Zhang, Dong Xu, Qian Yu)</author>
      <guid isPermaLink="false">2505.19713v2</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    </channel>
</rss>