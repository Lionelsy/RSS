<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 24 Jun 2025 14:30:17 +0800</lastBuildDate>
    <item>
      <title>OmniAvatar: Efficient Audio-Driven Avatar Video Generation with Adaptive Body Animation</title>
      <link>http://arxiv.org/abs/2506.18866v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://omni-avatar.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;OmniAvatar是一个创新的音频驱动全身视频生成模型，提高了人动画的同步精度和自然运动。&lt;h4&gt;背景&lt;/h4&gt;现有的音频驱动人动画方法主要关注面部运动，限制了它们创建具有自然同步和流畅性的全身动画的能力，并且难以进行精确的提示控制。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，引入了OmniAvatar模型。&lt;h4&gt;方法&lt;/h4&gt;OmniAvatar引入了一种像素级的多层次音频嵌入策略来更好地在潜在空间中捕捉音频特征，并采用基于LoRA的训练方法以保留基础模型的提示驱动控制能力。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，OmniAvatar在面部和半身视频生成方面超越了现有模型，能够提供基于文本的精确控制，以创建各种领域的视频，如播客、人机交互、动态场景和唱歌。&lt;h4&gt;结论&lt;/h4&gt;OmniAvatar在音频驱动人动画领域取得了显著进展，为创建更自然和精确的视频动画提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在音频驱动人动画方面取得了重大进展，而大多数现有方法主要关注面部运动，这限制了它们创建具有自然同步和流畅性的全身动画的能力。它们还难以进行精细的提示控制。为了应对这些挑战，我们引入了OmniAvatar，这是一个创新的音频驱动全身视频生成模型，它通过提高唇同步精度和自然运动来增强人动画。OmniAvatar引入了一种像素级的多层次音频嵌入策略，以更好地在潜在空间中捕捉音频特征，从而增强了跨不同场景的唇同步。为了在有效结合音频特征的同时保留基础模型的提示驱动控制能力，我们采用了基于LoRA的训练方法。广泛的实验表明，OmniAvatar在面部和半身视频生成方面优于现有模型，为创建各种领域的视频提供了基于文本的精确控制，如播客、人机交互、动态场景和唱歌。我们的项目页面是https://omni-avatar.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Significant progress has been made in audio-driven human animation, whilemost existing methods focus mainly on facial movements, limiting their abilityto create full-body animations with natural synchronization and fluidity. Theyalso struggle with precise prompt control for fine-grained generation. Totackle these challenges, we introduce OmniAvatar, an innovative audio-drivenfull-body video generation model that enhances human animation with improvedlip-sync accuracy and natural movements. OmniAvatar introduces a pixel-wisemulti-hierarchical audio embedding strategy to better capture audio features inthe latent space, enhancing lip-syncing across diverse scenes. To preserve thecapability for prompt-driven control of foundation models while effectivelyincorporating audio features, we employ a LoRA-based training approach.Extensive experiments show that OmniAvatar surpasses existing models in bothfacial and semi-body video generation, offering precise text-based control forcreating videos in various domains, such as podcasts, human interactions,dynamic scenes, and singing. Our project page ishttps://omni-avatar.github.io/.</description>
      <author>example@mail.com (Qijun Gan, Ruizi Yang, Jianke Zhu, Shaofei Xue, Steven Hoi)</author>
      <guid isPermaLink="false">2506.18866v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
  <item>
      <title>Rapeseed population point cloud completion network (RP-PCN) with dynamic graph convolution for 3D reconstruction of crop canopy occlusion architecture</title>
      <link>http://arxiv.org/abs/2506.18292v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种点云补全模型，用于从播种到角果阶段的油菜种群的三维重建，以评估作物光合作用和产量，并指导理想型设计。&lt;h4&gt;背景&lt;/h4&gt;三维传感技术已被开发用于植物和冠层重建，但由于严重的遮挡和复杂的结构，准确描述冠层存在困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种点云补全模型，以更准确地描述油菜种群的三维结构，从而评估产量。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于多视角成像的完整点云生成框架，使用虚拟现实集成（VRI）模拟方法和遮挡点检测算法来标注训练数据集，区分表面点和遮挡点。设计了油菜种群点云补全网络（RP-PCN），使用多分辨率动态图卷积编码器（MRDG）和点金字塔解码器（PPD）来预测遮挡点，并引入了动态图卷积特征提取器（DGCFE）来捕捉生长周期内的结构变化。&lt;h4&gt;主要发现&lt;/h4&gt;RP-PCN在幼苗、抽薹、开花和角果阶段分别实现了3.35 cm、3.46 cm、4.32 cm和4.51 cm的 chamfer distance（CD）值。消融研究表明，MRDG和DGCFE模块分别降低了10%和23%的CD值。与不完整的点云相比，RP-PCN的角果效率指数（SEI）提高了11.2%的产量预测精度。&lt;h4&gt;结论&lt;/h4&gt;RP-PCN流程有望扩展到其他作物，显著增强田间环境中种群冠层结构分析的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：完整冠层结构的定量描述对于评估作物光合作用和产量以指导理想型设计至关重要。尽管已经开发了用于植物和冠层重建的三维传感技术，但严重的遮挡和复杂的结构阻碍了准确描述冠层。在本研究中，我们提出了一种点云补全模型，用于从播种到角果阶段对油菜种群进行三维重建，使用多视角成像。开发了一个完整的点云生成框架，包括虚拟现实集成（VRI）模拟方法和遮挡点检测算法，通过区分表面点和遮挡点来标注训练数据集。设计了油菜种群点云补全网络（RP-PCN），使用多分辨率动态图卷积编码器（MRDG）和点金字塔解码器（PPD）来根据输入表面点云预测遮挡点。引入了动态图卷积特征提取器（DGCFE）来捕捉生长周期内的结构变化。通过使用完整点云的冠层指标预测产量来验证点云补全的有效性。结果表明，RP-PCN在幼苗、抽薹、开花和角果阶段分别达到了3.35 cm、3.46 cm、4.32 cm和4.51 cm的 chamfer distance（CD）值。消融研究表明，MRDG和DGCFE模块分别降低了10%和23%的CD值。与不完整的点云相比，RP-PCN的角果效率指数（SEI）提高了11.2%的产量预测精度。本研究提出的RP-PCN流程有望扩展到其他作物，显著增强田间环境中种群冠层结构分析的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantitative descriptions of complete canopy architecture are crucial forevaluating crop photosynthesis and yield to guide ideotype design. Althoughthree-dimensional (3D) sensing technologies have been developed for plant andcanopy reconstruction, severe occlusion and complex architectures hinderaccurate canopy descriptions. In this study, we propose a point cloudcompletion model for 3D reconstruction of rapeseed populations from seeding tosilique stages using multi-view imaging. A complete point cloud generationframework was developed with the virtual-real integration (VRI) simulationmethod and occlusion point detection algorithm to annotate the training datasetby distinguishing surface from occluded points. The rapeseed population pointcloud completion network (RP-PCN) was designed with a multi-resolution dynamicgraph convolutional encoder (MRDG) and point pyramid decoder (PPD) to predictoccluded points based on input surface point clouds. A dynamic graphconvolutional feature extractor (DGCFE) was introduced to capture structuralvariations across the growth period. The effectiveness of point cloudcompletion was validated by predicting yield using architectural indicatorsfrom complete point clouds of rapeseed population. The results demonstratedthat RP-PCN achieved chamfer distance (CD) values of 3.35 cm, 3.46 cm, 4.32 cm,and 4.51 cm at the seedling, bolting, flowering, and silique stages,respectively. Ablation studies showed the effectiveness of the MRDG and DGCFEmodules, reducing CD values by 10% and 23%, respectively. The siliqueefficiency index (SEI) from RP-PCN improved yield prediction accuracy by 11.2%compared to incomplete point clouds. The RP-PCN pipeline proposed in this studyhas the potential to be extended to other crops, significantly enhancing theanalysis of population canopy architectures in field environments.</description>
      <author>example@mail.com (Ziyue Guo, Xin Yang, Yutao Shen, Yang Zhu, Lixi Jiang, Haiyan Cen)</author>
      <guid isPermaLink="false">2506.18292v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>USAD: Universal Speech and Audio Representation via Distillation</title>
      <link>http://arxiv.org/abs/2506.18843v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为USAD的通用语音和音频蒸馏方法，该方法能够整合多种音频类型（包括语音、声音和音乐）进行统一的音频表示学习。&lt;h4&gt;背景&lt;/h4&gt;现有的自监督学习模型在音频表示方面取得了革命性的进展，但模型往往针对特定领域，专注于语音或非语音任务。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一个能够处理多种音频类型的统一模型，以实现更广泛的应用。&lt;h4&gt;方法&lt;/h4&gt;USAD使用从特定领域自监督学习模型到学生的层间蒸馏，在一个综合音频数据集上训练学生模型。&lt;h4&gt;主要发现&lt;/h4&gt;USAD在各种基准和数据集上表现出色，包括帧和实例级语音处理任务、音频标签和声音分类，在SUPERB和HEAR基准上达到了接近最先进的结果。&lt;h4&gt;结论&lt;/h4&gt;USAD是一种有效的音频表示学习方法，能够处理多种音频类型，并在多个任务上取得优异性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) has revolutionized audio representations, yetmodels often remain domain-specific, focusing on either speech or non-speechtasks. In this work, we present Universal Speech and Audio Distillation (USAD),a unified approach to audio representation learning that integrates diverseaudio types - speech, sound, and music - into a single model. USAD employsefficient layer-to-layer distillation from domain-specific SSL models to traina student on a comprehensive audio dataset. USAD offers competitive performanceacross various benchmarks and datasets, including frame and instance-levelspeech processing tasks, audio tagging, and sound classification, achievingnear state-of-the-art results with a single encoder on SUPERB and HEARbenchmarks.</description>
      <author>example@mail.com (Heng-Jui Chang, Saurabhchand Bhati, James Glass, Alexander H. Liu)</author>
      <guid isPermaLink="false">2506.18843v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>TDACloud: Point Cloud Recognition Using Topological Data Analysis</title>
      <link>http://arxiv.org/abs/2506.18725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TDACloud的新方法，利用拓扑数据分析(TDA)从点云中提取局部描述符，用于对象和场景识别，特别适用于自动驾驶、场景重建和定位等领域。&lt;h4&gt;背景&lt;/h4&gt;点云基于的对象/场景识别在自动驾驶、场景重建和定位等应用中是一个感兴趣的问题。从查询点云中提取有意义的局部描述符并与收集到的点云描述符匹配是一个具有挑战性的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需资源密集型GPU机器学习训练的方法，用于从点云中提取局部描述符，以解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;TDACloud方法使用ATOL向量化方法生成点云的向量，不同于体素化，该方法可以直接处理原始点云并输出固定大小的TDA描述符向量。&lt;h4&gt;主要发现&lt;/h4&gt;TDACloud在多个真实世界（如Oxford RobotCar，KITTI-360）和现实场景（如ShapeNet）点云数据集上进行了测试，并在有噪声和变换的测试案例中进行了验证。结果表明，在噪声条件下和大规模真实场景识别中，TDACloud具有较高的识别准确率，并且比基线方法高出约14%。&lt;h4&gt;结论&lt;/h4&gt;TDACloud在噪声条件下和大规模真实场景识别中表现出色，为点云对象和场景识别提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel methodology named TDACloud, which utilizes Topological Data Analysis (TDA) for local descriptor extraction from point clouds, aimed at object and scene recognition, particularly suitable for applications such as autonomous driving, scene reconstruction, and localization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud-based object/place recognition remains a problem of interest inapplications such as autonomous driving, scene reconstruction, andlocalization. Extracting meaningful local descriptors from a query point cloudthat can be matched with the descriptors of the collected point clouds is achallenging problem. Furthermore, when the query point cloud is noisy or hasbeen transformed (e.g., rotated), it adds to the complexity. To this end, wepropose a novel methodology, named TDACloud, using Topological Data Analysis(TDA) for local descriptor extraction from a point cloud, which does not needresource-intensive GPU-based machine learning training. More specifically, weused the ATOL vectorization method to generate vectors for point clouds. Unlikevoxelization, our proposed technique can take raw point clouds as inputs andoutputs a fixed-size TDA-descriptor vector. To test the quality of the proposedTDACloud technique, we have implemented it on multiple real-world (e.g., OxfordRobotCar, KITTI-360) and realistic (e.g., ShapeNet) point cloud datasets forobject and place recognition. We have also tested TDACloud on noisy andtransformed test cases where the query point cloud has been scaled, translated,or rotated. Our results demonstrate high recognition accuracies in noisyconditions and large-scale real-world place recognition while outperforming thebaselines by up to approximately 14%.</description>
      <author>example@mail.com (Anirban Ghosh, Ian Dahlin, Ayan Dutta)</author>
      <guid isPermaLink="false">2506.18725v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting</title>
      <link>http://arxiv.org/abs/2506.17609v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为TyphoFormer的新框架，用于提高台风轨迹预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;台风轨迹预测对于早期系统预警和灾害响应至关重要。现有的Transformer模型在建模密集轨迹方面表现出色，但缺乏对稀疏气象轨迹（如台风轨迹）的更广泛背景知识的访问。&lt;h4&gt;目的&lt;/h4&gt;提出TyphoFormer框架，通过结合自然语言描述作为辅助提示来提高台风轨迹预测的可靠性。&lt;h4&gt;方法&lt;/h4&gt;对于每个时间步，使用大型语言模型（LLM）根据北大西洋飓风数据库中记录的数值属性生成简洁的文本描述。这些语言描述捕捉高级气象语义，并作为辅助特殊标记嵌入到数值时间序列输入之前。TyphoFormer通过在一个统一的Transformer编码器中整合文本和序列信息，使模型能够利用通过数值特征本身无法访问的上下文线索。&lt;h4&gt;主要发现&lt;/h4&gt;在HURDAT2基准上进行的大量实验表明，TyphoFormer在非线性路径转换和有限历史观察的挑战性场景下，始终优于其他最先进的基线方法。&lt;h4&gt;结论&lt;/h4&gt;TyphoFormer框架能够有效提高台风轨迹预测的准确性，为早期预警和灾害响应提供了强有力的工具。&lt;h4&gt;翻译&lt;/h4&gt;准确的风暴路径预测对于早期系统预警和灾害响应至关重要。虽然基于Transformer的模型在建模智能城市中人类和车辆密集轨迹的时间动态方面表现出强大的性能，但它们通常无法访问增强稀疏气象轨迹（如台风轨迹）预测可靠性的更广泛背景知识。为了解决这一挑战，我们提出了一种名为TyphoFormer的新框架，该框架结合自然语言描述作为辅助提示以改善台风轨迹预测。对于每个时间步，我们使用大型语言模型（LLM）根据北大西洋飓风数据库中记录的数值属性生成简洁的文本描述。这些语言描述捕捉高级气象语义，并作为辅助特殊标记嵌入到数值时间序列输入之前。通过在一个统一的Transformer编码器中整合文本和序列信息，TyphoFormer使模型能够利用通过数值特征本身无法访问的上下文线索。在HURDAT2基准上进行的大量实验表明，TyphoFormer在非线性路径转换和有限历史观察的挑战性场景下，始终优于其他最先进的基线方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate typhoon track forecasting is crucial for early system warning anddisaster response. While Transformer-based models have demonstrated strongperformance in modeling the temporal dynamics of dense trajectories of humansand vehicles in smart cities, they usually lack access to broader contextualknowledge that enhances the forecasting reliability of sparse meteorologicaltrajectories, such as typhoon tracks. To address this challenge, we proposeTyphoFormer, a novel framework that incorporates natural language descriptionsas auxiliary prompts to improve typhoon trajectory forecasting. For each timestep, we use Large Language Model (LLM) to generate concise textualdescriptions based on the numerical attributes recorded in the North Atlantichurricane database. The language descriptions capture high-level meteorologicalsemantics and are embedded as auxiliary special tokens prepended to thenumerical time series input. By integrating both textual and sequentialinformation within a unified Transformer encoder, TyphoFormer enables the modelto leverage contextual cues that are otherwise inaccessible through numericalfeatures alone. Extensive experiments are conducted on HURDAT2 benchmark,results show that TyphoFormer consistently outperforms other state-of-the-artbaseline methods, particularly under challenging scenarios involving nonlinearpath shifts and limited historical observations.</description>
      <author>example@mail.com (Lincan Li, Eren Erman Ozguven, Yue Zhao, Guang Wang, Yiqun Xie, Yushun Dong)</author>
      <guid isPermaLink="false">2506.17609v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>YouTube-Occ: Learning Indoor 3D Semantic Occupancy Prediction from YouTube Videos</title>
      <link>http://arxiv.org/abs/2506.18266v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于室内互联网数据的3D语义占用预测方法，无需精确的几何关系和相机参数，通过利用2D先验知识实现3D室内感知。&lt;h4&gt;背景&lt;/h4&gt;过去3D语义占用预测需要精确的几何关系，但在复杂室内环境中，大规模数据收集和精细标注难以实现。&lt;h4&gt;目的&lt;/h4&gt;研究如何仅使用室内互联网数据实现3D空间精确训练，无需预先知道相机参数。&lt;h4&gt;方法&lt;/h4&gt;收集了YouTube上的家庭游览视频，构建了YouTube-Occ数据集。在该数据集上，建立了一个完全自监督模型，利用视觉基础模型的优势，通过将相似像素分组成超像素，将2D区域级知识蒸馏到占用网络中。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在两个流行的基准测试（NYUv2和OccScanNet）上实现了最先进的零样本性能。&lt;h4&gt;结论&lt;/h4&gt;该研究表明，利用室内互联网数据可以实现高效的3D室内感知，无需依赖复杂的几何关系或相机参数知识。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D semantic occupancy prediction in the past was considered to requireprecise geometric relationships in order to enable effective training. However,in complex indoor environments, the large-scale and widespread collection ofdata, along with the necessity for fine-grained annotations, becomesimpractical due to the complexity of data acquisition setups and privacyconcerns. In this paper, we demonstrate that 3D spatially-accurate training canbe achieved using only indoor Internet data, without the need for anypre-knowledge of intrinsic or extrinsic camera parameters. In our framework, wecollect a web dataset, YouTube-Occ, which comprises house tour videos fromYouTube, providing abundant real house scenes for 3D representation learning.Upon on this web dataset, we establish a fully self-supervised model toleverage accessible 2D prior knowledge for reaching powerful 3D indoorperception. Specifically, we harness the advantages of the prosperous visionfoundation models, distilling the 2D region-level knowledge into the occupancynetwork by grouping the similar pixels into superpixels. Experimental resultsshow that our method achieves state-of-the-art zero-shot performance on twopopular benchmarks (NYUv2 and OccScanNet</description>
      <author>example@mail.com (Haoming Chen, Lichen Yuan, TianFang Sun, Jingyu Gong, Xin Tan, Zhizhong Zhang, Yuan Xie)</author>
      <guid isPermaLink="false">2506.18266v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>SIM-Net: A Multimodal Fusion Network Using Inferred 3D Object Shape Point Clouds from RGB Images for 2D Classification</title>
      <link>http://arxiv.org/abs/2506.18683v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 9 figures, 14 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Shape-Image Multimodal Network (SIM-Net)，这是一种新型的2D图像分类架构，它通过直接从RGB图像中推断出的3D点云表示来整合3D点云信息。&lt;h4&gt;背景&lt;/h4&gt;传统的基于图像的模型在处理具有异质背景的数字化植物标本、非植物元素和遮挡等复杂情况时存在困难。&lt;h4&gt;目的&lt;/h4&gt;SIM-Net旨在通过融合基于纹理和几何的特征来提高分类性能，并解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;SIM-Net使用像素到点的转换将2D对象掩码转换为3D点云，并采用基于分割的预处理步骤来提取对象掩码。其架构包括一个用于2D图像特征的CNN编码器和基于PointNet的编码器用于几何特征，这些特征被融合到一个统一的潜在空间中。&lt;h4&gt;主要发现&lt;/h4&gt;在植物标本数据集上的实验评估表明，SIM-Net在准确性和F-score方面均优于ResNet101，最高提高了9.9%的准确性和12.3%的F-score。它还超越了几个基于transformer的顶级架构，突出了将3D结构推理纳入2D图像分类任务的好处。&lt;h4&gt;结论&lt;/h4&gt;SIM-Net通过结合3D点云信息显著提高了2D图像分类的性能，为处理复杂图像分类任务提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce the Shape-Image Multimodal Network (SIM-Net), a novel 2D imageclassification architecture that integrates 3D point cloud representationsinferred directly from RGB images. Our key contribution lies in apixel-to-point transformation that converts 2D object masks into 3D pointclouds, enabling the fusion of texture-based and geometric features forenhanced classification performance. SIM-Net is particularly well-suited forthe classification of digitized herbarium specimens (a task made challenging byheterogeneous backgrounds), non-plant elements, and occlusions that compromiseconventional image-based models. To address these issues, SIM-Net employs asegmentation-based preprocessing step to extract object masks prior to 3D pointcloud generation. The architecture comprises a CNN encoder for 2D imagefeatures and a PointNet-based encoder for geometric features, which are fusedinto a unified latent space. Experimental evaluations on herbarium datasetsdemonstrate that SIM-Net consistently outperforms ResNet101, achieving gains ofup to 9.9% in accuracy and 12.3% in F-score. It also surpasses severaltransformer-based state-of-the-art architectures, highlighting the benefits ofincorporating 3D structural reasoning into 2D image classification tasks.</description>
      <author>example@mail.com (Youcef Sklab, Hanane Ariouat, Eric Chenin, Edi Prifti, Jean-Daniel Zucker)</author>
      <guid isPermaLink="false">2506.18683v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Learning Point Correspondences In Radar 3D Point Clouds For Radar-Inertial Odometry</title>
      <link>http://arxiv.org/abs/2506.18580v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于学习框架的方法，用于预测在轻量级、低功耗、低成本消费级SoC FMCW雷达传感器中采集的噪声、稀疏和非结构化3D点云之间的鲁棒点对应关系。&lt;h4&gt;背景&lt;/h4&gt;在机器人里程计估计中使用3D点云时，通常需要在后续扫描的点之间找到一组对应关系。虽然对于高质量点云存在已建立的方法，但当质量下降时，最先进的方法仍然存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提高从噪声、稀疏和非结构化3D点云中预测鲁棒点对应关系的能力。&lt;h4&gt;方法&lt;/h4&gt;该方法基于Transformer架构，利用注意力机制发现连续扫描中具有最大互相关性的点对。网络通过基于集合的多标签分类交叉熵损失进行自监督训练，通过解决线性求和分配（LSA）优化问题来找到匹配的地面真实集，从而避免了对训练数据的繁琐手工标注。将损失计算作为多标签分类，可以直接对点对应关系进行监督，而不是对里程计误差进行监督。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在真实世界无人机（UAV）飞行和广泛使用的公共Coloradar数据集上进行了评估，结果表明，该方法将位置估计精度提高了超过14%和19%。&lt;h4&gt;结论&lt;/h4&gt;该方法通过提高位置估计精度，为使用SoC雷达进行里程计估计提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在机器人里程计估计中使用3D点云通常需要找到后续扫描中点之间的一组对应关系。虽然对于足够质量的点云有已建立的方法，但当质量下降时，最先进的方法仍然存在挑战。因此，本文提出了一种基于学习框架的方法，用于从轻量级、低功耗、低成本消费级SoC FMCW雷达传感器中预测噪声、稀疏和非结构化3D点云之间的鲁棒点对应关系。我们的网络基于Transformer架构，利用注意力机制发现连续扫描中具有最大互相关性的点对。所提出的网络通过使用基于集合的多标签分类交叉熵损失进行自监督训练，通过解决线性求和分配（LSA）优化问题来找到匹配的地面真实集，从而避免了训练数据的繁琐手工标注。将损失计算作为多标签分类，可以直接对点对应关系进行监督，而不是对来自SoC雷达的稀疏和噪声数据进行里程计误差的监督。我们使用开源的最先进雷达惯性里程计（RIO）框架在真实世界无人机（UAV）飞行和广泛使用的公共Coloradar数据集上评估了我们的方法。评估表明，所提出的方法将位置估计精度分别提高了超过14%和19%。开源代码和数据集可以在以下链接找到：https://github.com/aau-cns/radar_transformer。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Using 3D point clouds in odometry estimation in robotics often requiresfinding a set of correspondences between points in subsequent scans. Whilethere are established methods for point clouds of sufficient quality,state-of-the-art still struggles when this quality drops. Thus, this paperpresents a novel learning-based framework for predicting robust pointcorrespondences between pairs of noisy, sparse and unstructured 3D point cloudsfrom a light-weight, low-power, inexpensive, consumer-grade System-on-Chip(SoC) Frequency Modulated Continuous Wave (FMCW) radar sensor. Our network isbased on the transformer architecture which allows leveraging the attentionmechanism to discover pairs of points in consecutive scans with the greatestmutual affinity. The proposed network is trained in a self-supervised way usingset-based multi-label classification cross-entropy loss, where the ground-truthset of matches is found by solving the Linear Sum Assignment (LSA) optimizationproblem, which avoids tedious hand annotation of the training data.Additionally, posing the loss calculation as multi-label classification permitssupervising on point correspondences directly instead of on odometry error,which is not feasible for sparse and noisy data from the SoC radar we use. Weevaluate our method with an open-source state-of-the-art Radar-InertialOdometry (RIO) framework in real-world Unmanned Aerial Vehicle (UAV) flightsand with the widely used public Coloradar dataset. Evaluation shows that theproposed method improves the position estimation accuracy by over 14 % and 19 %on average, respectively. The open source code and datasets can be found here:https://github.com/aau-cns/radar_transformer.</description>
      <author>example@mail.com (Jan Michalczyk, Stephan Weiss, Jan Steinbrener)</author>
      <guid isPermaLink="false">2506.18580v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Fast State-Augmented Learning for Wireless Resource Allocation with Dual Variable Regression</title>
      <link>http://arxiv.org/abs/2506.18748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE TSP for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了多用户无线网络中的资源分配问题，旨在优化网络的全局效用函数，同时满足用户遍历平均性能的约束。&lt;h4&gt;背景&lt;/h4&gt;多用户无线网络中的资源分配问题，需要平衡网络全局效用与用户性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于图神经网络（GNN）的资源分配策略，以优化网络效用函数。&lt;h4&gt;方法&lt;/h4&gt;使用状态增强的图神经网络（GNN）参数化资源分配策略，将网络配置表示为图，将对偶变量视为动态输入，并通过梯度更新执行学习到的状态增强策略。&lt;h4&gt;主要发现&lt;/h4&gt;通过双变量回归和辅助GNN参数化，实现了对偶乘子的近最优初始化，以加快推理速度；通过对偶下降动态中采样乘子的拉格朗日最大化显著提高了状态增强模型的训练效果。&lt;h4&gt;结论&lt;/h4&gt;通过大量数值实验证明了所提算法在发射功率控制案例研究中的优越性能，并证明了算法的收敛性和对偶函数（迭代）最优间隙的指数概率界限。&lt;h4&gt;翻译&lt;/h4&gt;We consider resource allocation problems in multi-user wireless networks, where the goal is to optimize a network-wide utility function subject to constraints on the ergodic average performance of users. We demonstrate how a state-augmented graph neural network (GNN) parametrization for the resource allocation policy circumvents the drawbacks of the ubiquitous dual subgradient methods by representing the network configurations (or states) as graphs and viewing dual variables as dynamic inputs to the model, viewed as graph signals supported over the graphs. Lagrangian maximizing state-augmented policies are learned during the offline training phase, and the dual variables evolve through gradient updates while executing the learned state-augmented policies during the inference phase. Our main contributions are to illustrate how near-optimal initialization of dual multipliers for faster inference can be accomplished with dual variable regression, leveraging a secondary GNN parametrization, and how maximization of the Lagrangian over the multipliers sampled from the dual descent dynamics substantially improves the training of state-augmented models. We demonstrate the superior performance of the proposed algorithm with extensive numerical experiments in a case study of transmit power control. Finally, we prove a convergence result and an exponential probability bound on the excursions of the dual function (iterate) optimality gaps.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider resource allocation problems in multi-user wireless networks,where the goal is to optimize a network-wide utility function subject toconstraints on the ergodic average performance of users. We demonstrate how astate-augmented graph neural network (GNN) parametrization for the resourceallocation policy circumvents the drawbacks of the ubiquitous dual subgradientmethods by representing the network configurations (or states) as graphs andviewing dual variables as dynamic inputs to the model, viewed as graph signalssupported over the graphs. Lagrangian maximizing state-augmented policies arelearned during the offline training phase, and the dual variables evolvethrough gradient updates while executing the learned state-augmented policiesduring the inference phase. Our main contributions are to illustrate hownear-optimal initialization of dual multipliers for faster inference can beaccomplished with dual variable regression, leveraging a secondary GNNparametrization, and how maximization of the Lagrangian over the multiplierssampled from the dual descent dynamics substantially improves the training ofstate-augmented models. We demonstrate the superior performance of the proposedalgorithm with extensive numerical experiments in a case study of transmitpower control. Finally, we prove a convergence result and an exponentialprobability bound on the excursions of the dual function (iterate) optimalitygaps.</description>
      <author>example@mail.com (Yigit Berkay Uslu, Navid NaderiAlizadeh, Mark Eisen, Alejandro Ribeiro)</author>
      <guid isPermaLink="false">2506.18748v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>SRKD: Towards Efficient 3D Point Cloud Segmentation via Structure- and Relation-aware Knowledge Distillation</title>
      <link>http://arxiv.org/abs/2506.17290v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SRKD的新型结构-关系感知知识蒸馏框架，用于解决3D点云分割中的计算复杂性和部署限制问题。&lt;h4&gt;背景&lt;/h4&gt;3D点云分割因大规模Transformer模型的计算复杂性和部署限制而面临实际挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的知识蒸馏框架，将丰富的几何和语义知识从大型冻结教师模型转移到轻量级学生模型。&lt;h4&gt;方法&lt;/h4&gt;SRKD框架包括：基于亲和矩阵的关系对齐模块，通过点间相似性匹配从教师模型中提取结构依赖；引入跨样本小批量构建策略，使学生模型能够感知稳定和通用的几何结构；使用KL散度对齐语义分布；以及使用真实标签监督进一步强化准确的分割。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在显著降低模型复杂性的同时，实现了最先进的性能，证明了其在实际部署场景中的有效性和效率。&lt;h4&gt;结论&lt;/h4&gt;SRKD框架能够有效解决3D点云分割的问题，并在实际应用中展现出良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel Structure- and Relation-aware Knowledge Distillation framework, named SRKD, to address the practical challenges in 3D point cloud segmentation due to the computational complexity and deployment limitations of large-scale transformer-based models. To achieve this, we transfer rich geometric and semantic knowledge from a large frozen teacher model (&gt;100M) to a lightweight student model (&lt;15M). Specifically, we propose an affinity matrix-based relation alignment module that distills structural dependencies from the teacher to the student through point-wise similarity matching, enhancing the student's capability to learn contextual interactions. Meanwhile, we introduce a cross-sample mini-batch construction strategy that enables the student to perceive stable and generalized geometric structure. This aligns across diverse point cloud instances of the teacher, rather than within a single sample. Additionally, KL divergence is applied to align semantic distributions, and ground-truth supervision further reinforces accurate segmentation. Our method achieves state-of-the-art performance with significantly reduced model complexity, demonstrating its effectiveness and efficiency in real-world deployment scenarios. Our Code is available at https://github.com/itsnotacie/SRKD.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D point cloud segmentation faces practical challenges due to thecomputational complexity and deployment limitations of large-scaletransformer-based models. To address this, we propose a novel Structure- andRelation-aware Knowledge Distillation framework, named SRKD, that transfersrich geometric and semantic knowledge from a large frozen teacher model (&gt;100M)to a lightweight student model (&lt;15M). Specifically, we propose an affinitymatrix-based relation alignment module, which distills structural dependenciesfrom the teacher to the student through point-wise similarity matching,enhancing the student's capability to learn contextual interactions. Meanwhile,we introduce a cross-sample mini-batch construction strategy that enables thestudent to perceive stable and generalized geometric structure. This alignsacross diverse point cloud instances of the teacher, rather than within asingle sample. Additionally, KL divergence is applied to align semanticdistributions, and ground-truth supervision further reinforces accuratesegmentation. Our method achieves state of the art performance withsignificantly reduced model complexity, demonstrating its effectiveness andefficiency in real-world deployment scenarios. Our Code is available athttps://github.com/itsnotacie/SRKD.</description>
      <author>example@mail.com (Yuqi Li, Junhao Dong, Zeyu Dong, Chuanguang Yang, Zhulin An, Yongjun Xu)</author>
      <guid isPermaLink="false">2506.17290v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>EASE: Embodied Active Event Perception via Self-Supervised Energy Minimization</title>
      <link>http://arxiv.org/abs/2506.17516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IEEE Robotics and Automation Letters, 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;EASE是一种自监督框架，旨在通过自由能最小化统一时空表示学习和具身控制，以实现动态事件感知。&lt;h4&gt;背景&lt;/h4&gt;现有的事件感知方法通常依赖于预定义的动作空间、标注数据集和外部奖励，这在动态、现实场景中的适应性和可扩展性有限。&lt;h4&gt;目的&lt;/h4&gt;提出EASE框架，以实现动态检测、跟踪和总结实时事件的能力，这对于具身智能在人类-人工智能协作、辅助机器人和自主导航等任务中至关重要。&lt;h4&gt;方法&lt;/h4&gt;EASE利用预测误差和熵作为内在信号来分割事件、总结观察结果并主动跟踪显著演员，无需显式标注或外部奖励。&lt;h4&gt;主要发现&lt;/h4&gt;EASE通过结合生成感知模型和动作驱动的控制策略，动态地将预测与观察结果对齐，实现了隐式记忆、目标连续性和对新环境的适应性等涌现行为。&lt;h4&gt;结论&lt;/h4&gt;在模拟和现实环境中的广泛评估表明，EASE能够实现隐私保护和可扩展的事件感知，为无脚本、动态任务中的具身系统提供了一个稳健的基础。&lt;h4&gt;翻译&lt;/h4&gt;Active event perception, the ability to dynamically detect, track, and summarize events in real time, is essential for embodied intelligence in tasks such as human-AI collaboration, assistive robotics, and autonomous navigation. However, existing approaches often depend on predefined action spaces, annotated datasets, and extrinsic rewards, limiting their adaptability and scalability in dynamic, real-world scenarios. Inspired by cognitive theories of event perception and predictive coding, we propose EASE, a self-supervised framework that unifies spatiotemporal representation learning and embodied control through free energy minimization. EASE leverages prediction errors and entropy as intrinsic signals to segment events, summarize observations, and actively track salient actors, operating without explicit annotations or external rewards. By coupling a generative perception model with an action-driven control policy, EASE dynamically aligns predictions with observations, enabling emergent behaviors such as implicit memory, target continuity, and adaptability to novel environments. Extensive evaluations in simulation and real-world settings demonstrate EASE's ability to achieve privacy-preserving and scalable event perception, providing a robust foundation for embodied systems in unscripted, dynamic tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Active event perception, the ability to dynamically detect, track, andsummarize events in real time, is essential for embodied intelligence in taskssuch as human-AI collaboration, assistive robotics, and autonomous navigation.However, existing approaches often depend on predefined action spaces,annotated datasets, and extrinsic rewards, limiting their adaptability andscalability in dynamic, real-world scenarios. Inspired by cognitive theories ofevent perception and predictive coding, we propose EASE, a self-supervisedframework that unifies spatiotemporal representation learning and embodiedcontrol through free energy minimization. EASE leverages prediction errors andentropy as intrinsic signals to segment events, summarize observations, andactively track salient actors, operating without explicit annotations orexternal rewards. By coupling a generative perception model with anaction-driven control policy, EASE dynamically aligns predictions withobservations, enabling emergent behaviors such as implicit memory, targetcontinuity, and adaptability to novel environments. Extensive evaluations insimulation and real-world settings demonstrate EASE's ability to achieveprivacy-preserving and scalable event perception, providing a robust foundationfor embodied systems in unscripted, dynamic tasks.</description>
      <author>example@mail.com (Zhou Chen, Sanjoy Kundu, Harsimran S. Baweja, Sathyanarayanan N. Aakur)</author>
      <guid isPermaLink="false">2506.17516v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Universal Video Temporal Grounding with Generative Multi-modal Large Language Models</title>
      <link>http://arxiv.org/abs/2506.18883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通用的视频时间定位计算模型，能够根据自然语言查询（如问题或描述）准确地在视频中定位时间点。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常限于特定的视频领域或持续时间。&lt;h4&gt;目的&lt;/h4&gt;提出一个鲁棒且通用的视频定位模型UniTime，利用生成多模态大型语言模型（MLLM）的强大视觉语言理解能力。&lt;h4&gt;方法&lt;/h4&gt;（i）考虑将强MLLM用于视频时间定位，通过交错时间戳标记和视频标记来引入时间信息以实现精确的时间戳输出；（ii）通过自适应帧缩放训练模型处理不同输入粒度的视频，从而实现短视频和长视频的鲁棒时间定位；（iii）全面实验表明，UniTime在五个公开的时间定位基准测试中，在零样本和数据集特定微调设置下均优于现有方法；（iv）作为长视频问答（VideoQA）的初步时刻检索器，UniTime显著提高了VideoQA的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;UniTime在处理不同视图、类型和长度的视频以及理解复杂语言查询方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;UniTime对于复杂视频理解任务具有重要价值。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种通用的视频时间定位计算模型，能够根据自然语言查询（如问题或描述）准确地在视频中定位时间点。与现有方法相比，该方法不受特定视频领域或持续时间的限制。本文提出的UniTime模型利用了生成多模态大型语言模型（MLLM）的强大视觉语言理解能力，能够处理不同视图、类型和长度的视频，并理解复杂语言查询。主要贡献包括：将强MLLM用于视频时间定位，通过交错时间戳标记和视频标记引入时间信息以实现精确的时间戳输出；通过自适应帧缩放训练模型，实现短视频和长视频的鲁棒时间定位；在五个公开的时间定位基准测试中，UniTime在零样本和数据集特定微调设置下均优于现有方法；作为长视频问答（VideoQA）的初步时刻检索器，UniTime显著提高了VideoQA的准确性，突显了其在复杂视频理解任务中的价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a computational model for universal video temporalgrounding, which accurately localizes temporal moments in videos based onnatural language queries (e.g., questions or descriptions). Unlike existingmethods that are often limited to specific video domains or durations, wepropose UniTime, a robust and universal video grounding model leveraging thestrong vision-language understanding capabilities of generative Multi-modalLarge Language Models (MLLMs). Our model effectively handles videos of diverseviews, genres, and lengths while comprehending complex language queries. Thekey contributions include: (i) We consider steering strong MLLMs for temporalgrounding in videos. To enable precise timestamp outputs, we incorporatetemporal information by interleaving timestamp tokens with video tokens. (ii)By training the model to handle videos with different input granularitiesthrough adaptive frame scaling, our approach achieves robust temporal groundingfor both short and long videos. (iii) Comprehensive experiments show thatUniTime outperforms state-of-the-art approaches in both zero-shot anddataset-specific finetuned settings across five public temporal groundingbenchmarks. (iv) When employed as a preliminary moment retriever for long-formvideo question-answering (VideoQA), UniTime significantly improves VideoQAaccuracy, highlighting its value for complex video understanding tasks.</description>
      <author>example@mail.com (Zeqian Li, Shangzhe Di, Zhonghua Zhai, Weilin Huang, Yanfeng Wang, Weidi Xie)</author>
      <guid isPermaLink="false">2506.18883v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Object-aware Sound Source Localization via Audio-Visual Scene Understanding</title>
      <link>http://arxiv.org/abs/2506.18557v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的音频-视觉声源定位框架，利用多模态大型语言模型来区分声源物体和静音背景物体，并通过实验证明其在单源和多源定位场景中的有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的声源定位方法在复杂场景中难以准确定位声源物体，特别是当存在视觉相似但静音的物体时，因为它们依赖于简单的音频-视觉对应关系，无法捕捉声源和静音物体之间的细粒度语义差异。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的声源定位框架，以解决上述问题，通过多模态大型语言模型生成区分声源和静音物体的详细上下文信息。&lt;h4&gt;方法&lt;/h4&gt;该框架引入了两种新的损失函数：对象感知对比对齐（OCA）损失和对象区域隔离（ORI）损失，以有效整合生成的详细信息。&lt;h4&gt;主要发现&lt;/h4&gt;在MUSIC和VGGSound数据集上的实验结果表明，该方法在单源和多源定位场景中均显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效提高声源定位的准确性，特别是在复杂场景中区分声源和静音物体方面。&lt;h4&gt;翻译&lt;/h4&gt;Audio-visual sound source localization aims to spatially locate sound-making objects within visual scenes by integrating visual and audio cues. However, existing methods struggle with accurately localizing sound-making objects in complex scenes, particularly when visually similar silent objects coexist. This limitation arises primarily from their reliance on simple audio-visual correspondence, which does not capture fine-grained semantic differences between sound-making and silent objects. To address these challenges, we propose a novel sound source localization framework leveraging Multimodal Large Language Models (MLLMs) to generate detailed contextual information that explicitly distinguishes between sound-making foreground objects and silent background objects. To effectively integrate this detailed information, we introduce two novel loss functions: Object-aware Contrastive Alignment (OCA) loss and Object Region Isolation (ORI) loss. Extensive experimental results on MUSIC and VGGSound datasets demonstrate the effectiveness of our approach, significantly outperforming existing methods in both single-source and multi-source localization scenarios. Code and generated detailed contextual information are available at: https://github.com/VisualAIKHU/OA-SSL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio-visual sound source localization task aims to spatially localizesound-making objects within visual scenes by integrating visual and audio cues.However, existing methods struggle with accurately localizing sound-makingobjects in complex scenes, particularly when visually similar silent objectscoexist. This limitation arises primarily from their reliance on simpleaudio-visual correspondence, which does not capture fine-grained semanticdifferences between sound-making and silent objects. To address thesechallenges, we propose a novel sound source localization framework leveragingMultimodal Large Language Models (MLLMs) to generate detailed contextualinformation that explicitly distinguishes between sound-making foregroundobjects and silent background objects. To effectively integrate this detailedinformation, we introduce two novel loss functions: Object-aware ContrastiveAlignment (OCA) loss and Object Region Isolation (ORI) loss. Extensiveexperimental results on MUSIC and VGGSound datasets demonstrate theeffectiveness of our approach, significantly outperforming existing methods inboth single-source and multi-source localization scenarios. Code and generateddetailed contextual information are available at:https://github.com/VisualAIKHU/OA-SSL.</description>
      <author>example@mail.com (Sung Jin Um, Dongjin Kim, Sangmin Lee, Jung Uk Kim)</author>
      <guid isPermaLink="false">2506.18557v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Resampling Augmentation for Time Series Contrastive Learning: Application to Remote Sensing</title>
      <link>http://arxiv.org/abs/2506.18587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 2 figures, accepted at 42nd International Conference on  Machine Learning (ICML 2025) Terrabytes workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于重采样的数据增强策略，用于生成对比学习中的正对，并在农业分类基准测试中取得了优异性能。&lt;h4&gt;背景&lt;/h4&gt;由于存在大量未标记的卫星图像时间序列数据，而标记数据稀缺，对比自监督预训练成为利用这些未标记数据的自然工具。&lt;h4&gt;目的&lt;/h4&gt;设计有效的时间序列数据增强策略，以改善对比学习的效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于重采样的数据增强策略，通过上采样时间序列并提取不重叠的子序列来生成正对，同时保持时间覆盖。&lt;h4&gt;主要发现&lt;/h4&gt;在多个农业分类基准测试中，该方法优于常见的抖动、调整大小和遮罩等替代方法。在S2-Agri100数据集上，该方法不使用空间信息或时间编码，达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法为遥感时间序列的对比学习提供了一种简单而有效的数据增强方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Given the abundance of unlabeled Satellite Image Time Series (SITS) and thescarcity of labeled data, contrastive self-supervised pretraining emerges as anatural tool to leverage this vast quantity of unlabeled data. However,designing effective data augmentations for contrastive learning remainschallenging for time series. We introduce a novel resampling-based augmentationstrategy that generates positive pairs by upsampling time series and extractingdisjoint subsequences while preserving temporal coverage. We validate ourapproach on multiple agricultural classification benchmarks using Sentinel-2imagery, showing that it outperforms common alternatives such as jittering,resizing, and masking. Further, we achieve state-of-the-art performance on theS2-Agri100 dataset without employing spatial information or temporal encodings,surpassing more complex masked-based SSL frameworks. Our method offers asimple, yet effective, contrastive learning augmentation for remote sensingtime series.</description>
      <author>example@mail.com (Antoine Saget, Baptiste Lafabregue, Antoine Cornuéjols, Pierre Gançarski)</author>
      <guid isPermaLink="false">2506.18587v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>RWESummary: A Framework and Test for Choosing Large Language Models to Summarize Real-World Evidence (RWE) Studies</title>
      <link>http://arxiv.org/abs/2506.18819v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了RWESummary，它是MedHELM框架的补充，用于评估大型语言模型在从RWE研究结构化输出中总结真实世界证据（RWE）方面的性能。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在通用摘要任务和医学研究辅助方面得到了广泛评估，但尚未专门评估其总结RWE的能力。&lt;h4&gt;目的&lt;/h4&gt;提出RWESummary，以实现对LLMs在总结RWE方面的基准测试。&lt;h4&gt;方法&lt;/h4&gt;RWESummary包含一个场景和三个评估，覆盖了医学研究摘要中观察到的主要错误类型，并使用AtroposHealth专有数据进行开发。此外，使用RWESummary比较了不同LLMs在内部RWE摘要工具中的性能。&lt;h4&gt;主要发现&lt;/h4&gt;在13个不同的RWE研究中，Gemini 2.5模型（包括Flash和Pro）表现最佳。&lt;h4&gt;结论&lt;/h4&gt;RWESummary被建议作为真实世界证据研究摘要的新颖而有用的基础模型基准。&lt;h4&gt;翻译&lt;/h4&gt;Large Language Models (LLMs) have been extensively evaluated for general summarization tasks as well as medical research assistance, but they have not been specifically evaluated for the task of summarizing real-world evidence (RWE) from structured output of RWE studies. We introduce RWESummary, a proposed addition to the MedHELM framework (Bedi, Cui, Fuentes, Unell et al., 2025) to enable benchmarking of LLMs for this task. RWESummary includes one scenario and three evaluations covering major types of errors observed in summarization of medical research studies and was developed using AtroposHealth proprietary data. Additionally, we use RWESummary to compare the performance of different LLMs in our internal RWE summarization tool. At the time of publication, with 13 distinct RWE studies, we found the Gemini 2.5 models performed best overall (both Flash and Pro). We suggest RWESummary as a novel and useful foundation model benchmark for real-world evidence study summarization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have been extensively evaluated for generalsummarization tasks as well as medical research assistance, but they have notbeen specifically evaluated for the task of summarizing real-world evidence(RWE) from structured output of RWE studies. We introduce RWESummary, aproposed addition to the MedHELM framework (Bedi, Cui, Fuentes, Unell et al.,2025) to enable benchmarking of LLMs for this task. RWESummary includes onescenario and three evaluations covering major types of errors observed insummarization of medical research studies and was developed using AtroposHealth proprietary data. Additionally, we use RWESummary to compare theperformance of different LLMs in our internal RWE summarization tool. At thetime of publication, with 13 distinct RWE studies, we found the Gemini 2.5models performed best overall (both Flash and Pro). We suggest RWESummary as anovel and useful foundation model benchmark for real-world evidence studysummarization.</description>
      <author>example@mail.com (Arjun Mukerji, Michael L. Jackson, Jason Jones, Neil Sanghavi)</author>
      <guid isPermaLink="false">2506.18819v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>TAMMs: Temporal-Aware Multimodal Model for Satellite Image Change Understanding and Forecasting</title>
      <link>http://arxiv.org/abs/2506.18862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to the 33rd ACM International Conference on Multimedia. Our  dataset can be found at https://huggingface.co/datasets/IceInPot/TAMMs&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了多模态大型语言模型（MLLMs）在卫星图像时间序列分析中的应用，提出了一种名为TAMMs的模型，用于卫星图像变化理解和预测，并通过实验证明了其优于现有MLLMs基线。&lt;h4&gt;背景&lt;/h4&gt;卫星图像时间序列分析需要细粒度的时空推理，而现有的MLLMs在处理这类任务时存在挑战。&lt;h4&gt;目的&lt;/h4&gt;评估MLLMs在建模复杂多模态动态变化方面的潜力，特别是针对时间变化理解和未来场景生成。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为TAMMs的时空感知多模态模型，它通过轻量级时间模块增强冻结的MLLMs，并引入了语义融合控制注入（SFCI）机制，以指导未来图像生成。&lt;h4&gt;主要发现&lt;/h4&gt;TAMMs在时间变化理解和未来图像预测任务上优于强MLLMs基线，证明了精心设计的时空推理和语义融合能够释放MLLMs在时空理解方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;TAMMs模型通过增强MLLMs的时空推理能力，在卫星图像时间序列分析中取得了显著成效，为MLLMs在时空理解领域的应用提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies the application of multimodal large language models (MLLMs) in satellite image time-series analysis, proposes a model named TAMMs for satellite image change understanding and forecasting, and demonstrates its superiority over existing MLLM baselines through experiments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Satellite image time-series analysis demands fine-grained spatial-temporalreasoning, which remains a challenge for existing multimodal large languagemodels (MLLMs). In this work, we study the capabilities of MLLMs on a noveltask that jointly targets temporal change understanding and future scenegeneration, aiming to assess their potential for modeling complex multimodaldynamics over time. We propose TAMMs, a Temporal-Aware Multimodal Model forsatellite image change understanding and forecasting, which enhances frozenMLLMs with lightweight temporal modules for structured sequence encoding andcontextual prompting. To guide future image generation, TAMMs introduces aSemantic-Fused Control Injection (SFCI) mechanism that adaptively combineshigh-level semantic reasoning and structural priors within an enhancedControlNet. This dual-path conditioning enables temporally consistent andsemantically grounded image synthesis. Experiments demonstrate that TAMMsoutperforms strong MLLM baselines in both temporal change understanding andfuture image forecasting tasks, highlighting how carefully designed temporalreasoning and semantic fusion can unlock the full potential of MLLMs forspatio-temporal understanding.</description>
      <author>example@mail.com (Zhongbin Guo, Yuhao Wang, Ping Jian, Xinyue Chen, Wei Peng, Ertai E)</author>
      <guid isPermaLink="false">2506.18862v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Focus Your Attention: Towards Data-Intuitive Lightweight Vision Transformers</title>
      <link>http://arxiv.org/abs/2506.18791v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了基于超像素的Patch Pooling（SPPP）技术和Light Latent Attention（LLA）模块，旨在解决Vision Transformers在预训练和任务特定迁移学习中的计算和内存资源消耗大、能效低的问题。&lt;h4&gt;背景&lt;/h4&gt;Vision Transformers在各个领域取得了成功，但其对大规模数据集的预训练依赖大量计算和内存资源，且在特定任务迁移学习上存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出新的技术和模块，以降低架构复杂性，提高效率，并解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;提出SPPP技术生成上下文感知、语义丰富的patch embeddings，并引入LLA模块，将潜在token整合到注意力机制中，减少注意力模块的时间和空间复杂度。通过数据直观的patch embeddings和动态位置编码，自适应调节交叉注意力过程，专注于信息区域，同时保持全局语义结构。&lt;h4&gt;主要发现&lt;/h4&gt;SPPP模块轻量且易于集成到现有transformer架构中。实验表明，所提出的架构在计算效率上提供了显著改进，同时实现了与最先进方法相当的结果。&lt;h4&gt;结论&lt;/h4&gt;该架构具有节能潜力，适用于边缘部署，并已在GitHub上提供代码：https://github.com/zser092/Focused-Attention-ViT。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The evolution of Vision Transformers has led to their widespread adaptationto different domains. Despite large-scale success, there remain significantchallenges including their reliance on extensive computational and memoryresources for pre-training on huge datasets as well as difficulties intask-specific transfer learning. These limitations coupled with energyinefficiencies mainly arise due to the computation-intensive self-attentionmechanism. To address these issues, we propose a novel Super-Pixel Based PatchPooling (SPPP) technique that generates context-aware, semantically rich, patchembeddings to effectively reduce the architectural complexity and improveefficiency. Additionally, we introduce the Light Latent Attention (LLA) modulein our pipeline by integrating latent tokens into the attention mechanismallowing cross-attention operations to significantly reduce the time and spacecomplexity of the attention module. By leveraging the data-intuitive patchembeddings coupled with dynamic positional encodings, our approach adaptivelymodulates the cross-attention process to focus on informative regions whilemaintaining the global semantic structure. This targeted attention improvestraining efficiency and accelerates convergence. Notably, the SPPP module islightweight and can be easily integrated into existing transformerarchitectures. Extensive experiments demonstrate that our proposed architectureprovides significant improvements in terms of computational efficiency whileachieving comparable results with the state-of-the-art approaches, highlightingits potential for energy-efficient transformers suitable for edge deployment.(The code is available on our GitHub repository:https://github.com/zser092/Focused-Attention-ViT).</description>
      <author>example@mail.com (Suyash Gaurav, Muhammad Farhan Humayun, Jukka Heikkonen, Jatin Chaudhary)</author>
      <guid isPermaLink="false">2506.18791v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation</title>
      <link>http://arxiv.org/abs/2506.17891v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025. Code:  https://github.com/Howard-coder191/Relation3D&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Relation3D的新方法，旨在改进点云实例分割中的关系建模。&lt;h4&gt;背景&lt;/h4&gt;当前基于transformer的方法在场景特征和查询特征的外部关系建模上表现良好，但缺乏对内部关系的有效建模。&lt;h4&gt;目的&lt;/h4&gt;提出Relation3D方法，以增强点云实例分割中的关系建模。&lt;h4&gt;方法&lt;/h4&gt;Relation3D方法包括自适应超点聚合模块和对比学习引导的超点细化模块，以及将位置和几何关系纳入自注意力机制的关系感知自注意力机制。&lt;h4&gt;主要发现&lt;/h4&gt;Relation3D在ScanNetV2、ScanNet++、ScanNet200和S3DIS数据集上进行了广泛的实验，并证明了其优越的性能。&lt;h4&gt;结论&lt;/h4&gt;Relation3D通过改进关系建模，在点云实例分割任务中取得了显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D instance segmentation aims to predict a set of object instances in ascene, representing them as binary foreground masks with corresponding semanticlabels. Currently, transformer-based methods are gaining increasing attentiondue to their elegant pipelines and superior predictions. However, these methodsprimarily focus on modeling the external relationships between scene featuresand query features through mask attention. They lack effective modeling of theinternal relationships among scene features as well as between query features.In light of these disadvantages, we propose \textbf{Relation3D: EnhancingRelation Modeling for Point Cloud Instance Segmentation}. Specifically, weintroduce an adaptive superpoint aggregation module and a contrastivelearning-guided superpoint refinement module to better represent superpointfeatures (scene features) and leverage contrastive learning to guide theupdates of these features. Furthermore, our relation-aware self-attentionmechanism enhances the capabilities of modeling relationships between queriesby incorporating positional and geometric relationships into the self-attentionmechanism. Extensive experiments on the ScanNetV2, ScanNet++, ScanNet200 andS3DIS datasets demonstrate the superior performance of Relation3D.</description>
      <author>example@mail.com (Jiahao Lu, Jiacheng Deng)</author>
      <guid isPermaLink="false">2506.17891v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>These are Not All the Features You are Looking For: A Fundamental Bottleneck In Supervised Pretraining</title>
      <link>http://arxiv.org/abs/2506.18221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 7 figures, Preprint. Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了迁移学习在机器学习中的重要性，分析了深度学习模型在特征学习上的局限性，并提出了改进迁移学习性能的方法。&lt;h4&gt;背景&lt;/h4&gt;迁移学习允许将预训练模型应用于新任务，但存在如何确保迁移特征足够处理未见数据集的挑战。&lt;h4&gt;目的&lt;/h4&gt;评估从预训练混合模型到其组件任务的模型迁移，并探讨如何使预训练特征匹配特定任务的直接训练性能。&lt;h4&gt;方法&lt;/h4&gt;研究识别了深度学习模型中的“信息饱和瓶颈”，提出限制预训练时只学习关键特征集的方法，并提出了更丰富的特征表示作为潜在解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，网络在训练过程中编码相似竞争特征后，会停止学习新特征，导致模型在数据分布上表现不一致。&lt;h4&gt;结论&lt;/h4&gt;研究建议，当有可用资源时，专注于特定任务的训练可能比依赖大规模网络更有效，并提出了新的方法来应对这一挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：迁移学习是现代机器学习的基础，它承诺通过最小的新数据来适应在广泛数据集上预训练的模型的新任务。然而，确保迁移特征足以处理未见数据集仍然是一个重大挑战，这加剧了量化两个任务是否“相关”的困难。为了解决这些挑战，我们评估了从预训练混合模型到其每个组件任务的模型迁移，评估预训练特征是否可以匹配特定任务的直接训练性能。我们确定深度学习模型存在一个基本限制——“信息饱和瓶颈”，其中网络在训练过程中编码相似竞争特征后无法学习新特征。当限制在预训练期间仅学习关键特征子集时，模型将永久失去迁移的关键特征，并在数据分布上表现不一致，即使是训练混合的组成部分。从已发表的实证研究中得出的证据表明，这种现象在深度学习架构中普遍存在——诸如数据分布或顺序等因素会影响当前表示学习方法随时间学习到的特征。本研究表明，仅依赖大规模网络可能不如专注于特定任务的训练有效，并提出了更丰富的特征表示作为更好地泛化到新数据集的潜在解决方案，并具体介绍了现有方法以及一种新颖的方法，这是解决这一挑战的初步步骤。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning is a cornerstone of modern machine learning, promising away to adapt models pretrained on a broad mix of data to new tasks with minimalnew data. However, a significant challenge remains in ensuring that transferredfeatures are sufficient to handle unseen datasets, amplified by the difficultyof quantifying whether two tasks are "related". To address these challenges, weevaluate model transfer from a pretraining mixture to each of its componenttasks, assessing whether pretrained features can match the performance oftask-specific direct training. We identify a fundamental limitation in deeplearning models -- an "information saturation bottleneck" -- where networksfail to learn new features once they encode similar competing features duringtraining. When restricted to learning only a subset of key features duringpretraining, models will permanently lose critical features for transfer andperform inconsistently on data distributions, even components of the trainingmixture. Empirical evidence from published studies suggests that thisphenomenon is pervasive in deep learning architectures -- factors such as datadistribution or ordering affect the features that current representationlearning methods can learn over time. This study suggests that relying solelyon large-scale networks may not be as effective as focusing on task-specifictraining, when available. We propose richer feature representations as apotential solution to better generalize across new datasets and, specifically,present existing methods alongside a novel approach, the initial steps towardsaddressing this challenge.</description>
      <author>example@mail.com (Xingyu Alice Yang, Jianyu Zhang, Léon Bottou)</author>
      <guid isPermaLink="false">2506.18221v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>SaGIF: Improving Individual Fairness in Graph Neural Networks via Similarity Encoding</title>
      <link>http://arxiv.org/abs/2506.18696v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络中的个体公平性（IF）问题，提出了一个名为SaGIF的相似性感知GNN以提升IF。&lt;h4&gt;背景&lt;/h4&gt;个体公平性在图神经网络中是一个关键问题，但目前关于其引起原因和相似个体识别的研究尚不充分。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文进行了初步分析，探索个体不公平性的原因，并引入了两个度量标准来评估个体相似性。&lt;h4&gt;方法&lt;/h4&gt;本文提出了拓扑融合和特征融合两种方法来评估个体相似性，并基于这些度量标准提出了相似性感知GNN（SaGIF）。&lt;h4&gt;主要发现&lt;/h4&gt;SaGIF通过独立学习相似性表示来整合个体相似性，从而在GNN中提高了个体公平性。实验结果表明，SaGIF在多个真实世界数据集上优于现有的个体公平性方法。&lt;h4&gt;结论&lt;/h4&gt;SaGIF是一个有效的解决方案，能够提升图神经网络中的个体公平性，同时保持效用性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the issue of individual fairness (IF) in graph neural networks (GNNs), and proposes a Similarity-aware GNN named SaGIF to enhance IF.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Individual fairness (IF) in graph neural networks (GNNs), which emphasizesthe need for similar individuals should receive similar outcomes from GNNs, hasbeen a critical issue. Despite its importance, research in this area has beenlargely unexplored in terms of (1) a clear understanding of what inducesindividual unfairness in GNNs and (2) a comprehensive consideration ofidentifying similar individuals. To bridge these gaps, we conduct a preliminaryanalysis to explore the underlying reason for individual unfairness and observecorrelations between IF and similarity consistency, a concept introduced toevaluate the discrepancy in identifying similar individuals based on graphstructure versus node features. Inspired by our observations, we introduce twometrics to assess individual similarity from two distinct perspectives:topology fusion and feature fusion. Building upon these metrics, we proposeSimilarity-aware GNNs for Individual Fairness, named SaGIF. The key insightbehind SaGIF is the integration of individual similarities by independentlylearning similarity representations, leading to an improvement of IF in GNNs.Our experiments on several real-world datasets validate the effectiveness ofour proposed metrics and SaGIF. Specifically, SaGIF consistently outperformsstate-of-the-art IF methods while maintaining utility performance. Code isavailable at: https://github.com/ZzoomD/SaGIF.</description>
      <author>example@mail.com (Yuchang Zhu, Jintang Li, Huizhe Zhang, Liang Chen, Zibin Zheng)</author>
      <guid isPermaLink="false">2506.18696v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>DIP: Unsupervised Dense In-Context Post-training of Visual Representations</title>
      <link>http://arxiv.org/abs/2506.18463v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为DIP的新颖的无监督后训练方法，旨在增强大规模预训练视觉编码器在上下文场景理解中的密集图像表示。&lt;h4&gt;背景&lt;/h4&gt;与依赖复杂自蒸馏架构的先前方法不同，DIP使用模拟下游上下文场景的伪任务来训练视觉编码器，并受到元学习原理的启发。&lt;h4&gt;目的&lt;/h4&gt;该方法旨在提高视觉编码器在上下文场景理解任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;为了在无标签数据上实现后训练，DIP提出了一种自动机制来生成上下文任务，该机制结合了预训练的扩散模型和视觉编码器本身。&lt;h4&gt;主要发现&lt;/h4&gt;DIP简单、无监督且计算效率高，在单个A100 GPU上运行时间不到9小时。通过学习伪上下文任务中的密集表示，它在各种下游真实世界的上下文场景理解任务中表现出色，优于初始视觉编码器和先前的方法。&lt;h4&gt;结论&lt;/h4&gt;DIP提供了一种实用且有效的方法来提高密集表示，并且相关的代码已开源。&lt;h4&gt;翻译&lt;/h4&gt;We introduce DIP, a novel unsupervised post-training method designed to enhance dense image representations in large-scale pretrained vision encoders for in-context scene understanding. Unlike prior approaches that rely on complex self-distillation architectures, our method trains the vision encoder using pseudo-tasks that explicitly simulate downstream in-context scenarios, inspired by meta-learning principles. To enable post-training on unlabeled data, we propose an automatic mechanism for generating in-context tasks that combines a pretrained diffusion model and the vision encoder itself. DIP is simple, unsupervised, and computationally efficient, requiring less than 9 hours on a single A100 GPU. By learning dense representations through pseudo-in-context tasks, it achieves strong performance across a wide variety of downstream real-world in-context scene understanding tasks. It outperforms both the initial vision encoder and prior methods, offering a practical and effective solution for improving dense representations. Code available here: https://github.com/sirkosophia/DIP&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce DIP, a novel unsupervised post-training method designed toenhance dense image representations in large-scale pretrained vision encodersfor in-context scene understanding. Unlike prior approaches that rely oncomplex self-distillation architectures, our method trains the vision encoderusing pseudo-tasks that explicitly simulate downstream in-context scenarios,inspired by meta-learning principles. To enable post-training on unlabeleddata, we propose an automatic mechanism for generating in-context tasks thatcombines a pretrained diffusion model and the vision encoder itself. DIP issimple, unsupervised, and computationally efficient, requiring less than 9hours on a single A100 GPU. By learning dense representations through pseudoin-context tasks, it achieves strong performance across a wide variety ofdownstream real-world in-context scene understanding tasks. It outperforms boththe initial vision encoder and prior methods, offering a practical andeffective solution for improving dense representations. Code available here:https://github.com/sirkosophia/DIP</description>
      <author>example@mail.com (Sophia Sirko-Galouchenko, Spyros Gidaris, Antonin Vobecky, Andrei Bursuc, Nicolas Thome)</author>
      <guid isPermaLink="false">2506.18463v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Towards Group Fairness with Multiple Sensitive Attributes in Federated Foundation Models</title>
      <link>http://arxiv.org/abs/2506.18732v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了深度集成基础模型与联邦学习相结合，在个性化、可扩展性方面对下游任务的提升，特别是在敏感领域如医疗保健中的重要性。文章着重于在联邦基础模型（FFM）时代，如何通过因果分析实现不同敏感属性间的群体公平性，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;随着联邦基础模型（FFM）的发展，如何在敏感领域中实现群体公平性成为关键问题。由于敏感属性中的偏差可能导致对少数群体的不公平待遇，因此需要关注群体公平性。&lt;h4&gt;目的&lt;/h4&gt;研究如何在FFM中实现不同敏感属性间的群体公平性，并通过因果发现和推理量化群体公平性背后的因果效应。&lt;h4&gt;方法&lt;/h4&gt;本文扩展了FFM结构，使其能够同时权衡多个敏感属性，并通过因果发现和推理来量化群体公平性的因果效应。&lt;h4&gt;主要发现&lt;/h4&gt;本文实现了对FFM中不同敏感属性间群体公平性的因果分析，并通过实验验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;本文的研究为构建可解释、可信且公平的FFM系统提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;The deep integration of foundation models (FM) with federated learning (FL) enhances personalization and scalability for diverse downstream tasks, making it crucial in sensitive domains like healthcare. Achieving group fairness has become an increasingly prominent issue in the era of federated foundation models (FFMs), since biases in sensitive attributes might lead to inequitable treatment for under-represented demographic groups. Existing studies mostly focus on achieving fairness with respect to a single sensitive attribute. This renders them unable to provide clear interpretability of dependencies among multiple sensitive attributes which is required to achieve group fairness. Our paper takes the first attempt towards a causal analysis of the relationship between group fairness across various sensitive attributes in the FFM. We extend the FFM structure to trade off multiple sensitive attributes simultaneously and quantify the causal effect behind the group fairness through causal discovery and inference. Extensive experiments validate its effectiveness, offering insights into interpretability towards building trustworthy and fair FFM systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The deep integration of foundation models (FM) with federated learning (FL)enhances personalization and scalability for diverse downstream tasks, makingit crucial in sensitive domains like healthcare. Achieving group fairness hasbecome an increasingly prominent issue in the era of federated foundationmodels (FFMs), since biases in sensitive attributes might lead to inequitabletreatment for under-represented demographic groups. Existing studies mostlyfocus on achieving fairness with respect to a single sensitive attribute. Thisrenders them unable to provide clear interpretability of dependencies amongmultiple sensitive attributes which is required to achieve group fairness. Ourpaper takes the first attempt towards a causal analysis of the relationshipbetween group fairness across various sensitive attributes in the FFM. Weextend the FFM structure to trade off multiple sensitive attributessimultaneously and quantify the causal effect behind the group fairness throughcausal discovery and inference. Extensive experiments validate itseffectiveness, offering insights into interpretability towards buildingtrustworthy and fair FFM systems.</description>
      <author>example@mail.com (Yuning Yang, Han Yu, Tianrun Gao, Xiaodong Xu, Guangyu Wang)</author>
      <guid isPermaLink="false">2506.18732v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>VQ-Insight: Teaching VLMs for AI-Generated Video Quality Understanding via Progressive Visual Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.18564v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为VQ-Insight的新型推理风格视觉语言模型框架，用于评估AI生成内容视频的质量。&lt;h4&gt;背景&lt;/h4&gt;尽管AI生成内容（AIGC）在文本到视频生成模型方面取得了进展，但评估AIGC生成视频的质量仍然具有挑战性，这包括泛化能力有限、缺乏时间感知、过度依赖大规模标注数据集以及与生成模型缺乏有效交互等问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些不足，论文提出了VQ-Insight框架，旨在提高视频质量评估的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;VQ-Insight采用的方法包括：（1）一种渐进式视频质量学习方案，结合图像质量预热、通用任务特定的时间学习以及与视频生成模型的联合优化；（2）设计多维度评分奖励、偏好比较奖励和时间建模奖励，以增强视频质量评估中的泛化和专业化。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，VQ-Insight在偏好比较、多维度评分和自然视频评分方面，持续优于现有最佳基准，为视频生成任务带来了显著的改进。&lt;h4&gt;结论&lt;/h4&gt;VQ-Insight是一种有效的视频质量评估框架，能够显著提高AI生成视频的质量评估能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in AI-generated content (AIGC) have led to the emergence ofpowerful text-to-video generation models. Despite these successes, evaluatingthe quality of AIGC-generated videos remains challenging due to limitedgeneralization, lack of temporal awareness, heavy reliance on large-scaleannotated datasets, and the lack of effective interaction with generationmodels. Most current approaches rely on supervised finetuning ofvision-language models (VLMs), which often require large-scale annotateddatasets and tend to decouple understanding and generation. To address theseshortcomings, we propose VQ-Insight, a novel reasoning-style VLM framework forAIGC video quality assessment. Our approach features: (1) a progressive videoquality learning scheme that combines image quality warm-up, generaltask-specific temporal learning, and joint optimization with the videogeneration model; (2) the design of multi-dimension scoring rewards, preferencecomparison rewards, and temporal modeling rewards to enhance bothgeneralization and specialization in video quality evaluation. Extensiveexperiments demonstrate that VQ-Insight consistently outperformsstate-of-the-art baselines in preference comparison, multi-dimension scoring,and natural video scoring, bringing significant improvements for videogeneration tasks.</description>
      <author>example@mail.com (Xuanyu Zhang, Weiqi Li, Shijie Zhao, Junlin Li, Li Zhang, Jian Zhang)</author>
      <guid isPermaLink="false">2506.18564v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Transfer Learning to Overcome Data Limitations in Czochralski Crystal Growth</title>
      <link>http://arxiv.org/abs/2506.18774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Advanced Theory and Simulations. 21 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种迁移学习方法，通过将在一个数据量较大的源材料（硅）上训练的机器学习模型应用于数据量较小的目标材料（锗和砷化镓）上，以克服数据稀缺的限制，提高预测精度。&lt;h4&gt;背景&lt;/h4&gt;Czochralski法是用于生长高质量单晶的常用过程，对于半导体、光学和先进材料的应用至关重要。然而，数据稀缺限制了机器学习在预测建模和优化中的应用。&lt;h4&gt;目的&lt;/h4&gt;通过迁移学习，将机器学习模型从硅材料扩展到锗和砷化镓材料，以优化Cz生长参数。&lt;h4&gt;方法&lt;/h4&gt;研究选择了Cz-Ge（与Cz-Si相似）和通过LEC方法生长的GaAs（与Cz-Si不同）作为材料，并探索了包括Warm Start、Merged Training和Hyperparameters Transfer在内的多种迁移学习策略，同时评估了多种机器学习架构。&lt;h4&gt;主要发现&lt;/h4&gt;迁移学习方法显著提高了预测精度，即使在数据量较少的情况下也有效，为优化不同材料的Cz生长参数提供了一个实用的框架。&lt;h4&gt;结论&lt;/h4&gt;迁移学习在处理不同数据相似度的情况下表现出鲁棒性，是优化Cz生长参数的一种有效方法。&lt;h4&gt;翻译&lt;/h4&gt;The Czochralski (Cz) method is a widely used process for growing high-quality single crystals, critical for applications in semiconductors, optics, and advanced materials. Achieving optimal growth conditions requires precise control of process and furnace design parameters. Still, data scarcity -- especially for new materials -- limits the application of machine learning (ML) in predictive modeling and optimization. This study proposes a transfer learning approach to overcome this limitation by adapting ML models trained on a higher data volume of one source material (Si) to a lower data volume of another target material (Ge and GaAs). The materials were deliberately selected to assess the robustness of the transfer learning approach in handling varying data similarity, with Cz-Ge being similar to Cz-Si, and GaAs grown via the liquid encapsulated Czochralski method (LEC), which differs from Cz-Si. We explore various transfer learning strategies, including Warm Start, Merged Training, and Hyperparameters Transfer, and evaluate multiple ML architectures across two different materials. Our results demonstrate that transfer learning significantly enhances predictive accuracy with minimal data, providing a practical framework for optimizing Cz growth parameters across diverse materials.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Czochralski (Cz) method is a widely used process for growing high-qualitysingle crystals, critical for applications in semiconductors, optics, andadvanced materials. Achieving optimal growth conditions requires precisecontrol of process and furnace design parameters. Still, data scarcity --especially for new materials -- limits the application of machine learning (ML)in predictive modeling and optimization. This study proposes a transferlearning approach to overcome this limitation by adapting ML models trained ona higher data volume of one source material (Si) to a lower data volume ofanother target material (Ge and GaAs). The materials were deliberately selectedto assess the robustness of the transfer learning approach in handling varyingdata similarity, with Cz-Ge being similar to Cz-Si, and GaAs grown via theliquid encapsulated Czochralski method (LEC), which differs from Cz-Si. Weexplore various transfer learning strategies, including Warm Start, MergedTraining, and Hyperparameters Transfer, and evaluate multiple ML architecturesacross two different materials. Our results demonstrate that transfer learningsignificantly enhances predictive accuracy with minimal data, providing apractical framework for optimizing Cz growth parameters across diversematerials.</description>
      <author>example@mail.com (Milena Petkovic, Natasha Dropka, Xia Tang, Janina Zittel)</author>
      <guid isPermaLink="false">2506.18774v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>SLAP: Siamese Language-Audio Pretraining Without Negative Samples for Music Understanding</title>
      <link>http://arxiv.org/abs/2506.17815v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ISMIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Siamese Language-Audio Pretraining (SLAP)的新型多模态预训练框架，用于音乐理解和生成，通过链接文本和音频，并解决了现有方法中内存需求大、模态差距大等问题。&lt;h4&gt;背景&lt;/h4&gt;联合嵌入空间通过多模态对比学习将文本和音频联系起来，显著推进了音乐理解和生成，但现有方法存在内存需求大和模态差距大的问题。&lt;h4&gt;目的&lt;/h4&gt;提出SLAP框架，以解决现有多模态预训练方法中的内存需求和模态差距问题。&lt;h4&gt;方法&lt;/h4&gt;SLAP框架借鉴了Bootstrap Your Own Latent (BYOL)范式，用于多模态音频-文本训练，以促进多模态嵌入空间的训练可扩展性。&lt;h4&gt;主要发现&lt;/h4&gt;SLAP在音乐和文本之间的有意义关系学习方面表现出色，例如在文本-音乐检索和零样本分类任务上优于CLAP。此外，在多个音乐信息检索（MIR）任务上，包括更大或监督模型（流派和乐器分类、自动标签）中，也表现出有竞争力的下游性能。SLAP还具有减少模态差距和改进对批量大小变化的检索性能的鲁棒性等吸引人的特性。&lt;h4&gt;结论&lt;/h4&gt;SLAP框架通过梯度累积，在单个GPU上解锁了大规模训练的可能性，有效解决了多模态预训练中的挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：联合嵌入空间通过多模态对比学习将文本和音频联系起来，显著推进了音乐理解和生成。然而，这些方法由于依赖于大批量样本来有效利用负样本，因此面临着巨大的内存需求限制。此外，多模态联合嵌入空间还存在着模态差距问题，即不同模态的嵌入位于嵌入空间的不同流形中。为了解决这些挑战，我们提出了Siamese Language-Audio Pretraining (SLAP)，这是一种新颖的多模态预训练框架，允许在不使用负样本的情况下学习强大的表示。SLAP将Bootstrap Your Own Latent (BYOL)范式应用于多模态音频-文本训练，促进了多模态嵌入空间的训练可扩展性。我们展示了我们的模型学习音乐和文本之间有意义关系的能力——具体来说，我们表明SLAP在文本-音乐检索和零样本分类等任务上优于CLAP。我们还观察到在多个MIR任务上的有竞争力的下游性能，包括使用更大或监督模型（流派和乐器分类、自动标签）。此外，我们的方法具有吸引人的特性，如可量化的模态差距减少和检索性能对批量大小变化的鲁棒性改进。最后，其新颖的公式通过梯度累积在单个GPU上解锁了大规模训练的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Joint embedding spaces have significantly advanced music understanding andgeneration by linking text and audio through multimodal contrastive learning.However, these approaches face large memory requirement limitations due torelying on large batch sizes to effectively utilize negative samples. Further,multimodal joint embedding spaces suffer from a modality gap wherein embeddingsfrom different modalities lie in different manifolds of the embedding space. Toaddress these challenges, we propose Siamese Language-Audio Pretraining (SLAP),a novel multimodal pretraining framework that allows learning powerfulrepresentations without negative samples. SLAP adapts the Bootstrap Your OwnLatent (BYOL) paradigm for multimodal audio-text training, promotingscalability in training multimodal embedding spaces.  We illustrate the ability of our model to learn meaningful relationshipsbetween music and text -- specifically, we show that SLAP outperforms CLAP ontasks such as text-music retrieval and zero-shot classification. We alsoobserve competitive downstream performance on several MIR tasks, including withlarger or supervised models (genre and instrument classification,auto-tagging). Additionally, our approach has attractive properties, such as aquantifiably reduced modality gap and improved robustness to batch sizevariations on retrieval performance. Finally, its novel formulation unlockslarge-scale training on a single GPU through gradient accumulation.</description>
      <author>example@mail.com (Julien Guinot, Alain Riou, Elio Quinton, György Fazekas)</author>
      <guid isPermaLink="false">2506.17815v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Matrix-Game: Interactive World Foundation Model</title>
      <link>http://arxiv.org/abs/2506.18701v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Matrix-Game是一个用于可控游戏世界生成的交互式世界基础模型，通过两阶段训练流程实现环境理解和交互式视频生成。&lt;h4&gt;背景&lt;/h4&gt;目前缺乏对游戏世界生成的精确控制，尤其是对于角色动作和摄像机移动。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够精确控制角色动作和摄像机移动，同时保持高视觉质量和时间一致性的游戏世界生成模型。&lt;h4&gt;方法&lt;/h4&gt;Matrix-Game采用可控的图像到世界生成范式，基于参考图像、运动上下文和用户动作进行训练。此外，构建了包含超过2700小时未标记游戏视频剪辑和超过1000小时高质量标记剪辑的Matrix-Game-MC数据集。&lt;h4&gt;主要发现&lt;/h4&gt;Matrix-Game在视觉质量、时间质量、动作可控性和物理规则理解等方面优于现有的Minecraft世界模型，如Oasis和MineWorld。双盲人类评估进一步证实了Matrix-Game的优越性。&lt;h4&gt;结论&lt;/h4&gt;Matrix-Game能够生成感知上真实且精确可控的视频，适用于各种游戏场景，并计划开源模型权重和GameWorld Score基准。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为Matrix-Game的交互式世界基础模型，用于可控游戏世界的生成。Matrix-Game通过两阶段流程进行训练，首先进行大规模未标记预训练以理解环境，然后进行动作标记训练以生成交互式视频。为了支持这一点，我们整理了Matrix-Game-MC数据集，这是一个包含超过2700小时未标记游戏视频剪辑和超过1000小时高质量标记剪辑的Minecraft数据集。我们的模型采用了一种可控的图像到世界生成范式，基于参考图像、运动上下文和用户动作。具有超过170亿个参数的Matrix-Game能够精确控制角色动作和摄像机移动，同时保持高视觉质量和时间一致性。为了评估性能，我们开发了GameWorldScore，这是一个统一的基准，用于衡量Minecraft世界生成的视觉质量、时间质量、动作可控性和物理规则理解。大量实验表明，Matrix-Game在所有指标上均优于现有的开源Minecraft世界模型（包括Oasis和MineWorld），尤其是在可控性和物理一致性方面有显著提升。双盲人类评估进一步证实了Matrix-Game的优越性，突出了其能够在各种游戏场景中生成感知上真实且精确可控视频的能力。为了促进交互式图像到世界生成方面的未来研究，我们将在https://github.com/SkyworkAI/Matrix-Game上开源Matrix-Game模型权重和GameWorld Score基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Matrix-Game, an interactive world foundation model forcontrollable game world generation. Matrix-Game is trained using a two-stagepipeline that first performs large-scale unlabeled pretraining for environmentunderstanding, followed by action-labeled training for interactive videogeneration. To support this, we curate Matrix-Game-MC, a comprehensiveMinecraft dataset comprising over 2,700 hours of unlabeled gameplay video clipsand over 1,000 hours of high-quality labeled clips with fine-grained keyboardand mouse action annotations. Our model adopts a controllable image-to-worldgeneration paradigm, conditioned on a reference image, motion context, and useractions. With over 17 billion parameters, Matrix-Game enables precise controlover character actions and camera movements, while maintaining high visualquality and temporal coherence. To evaluate performance, we develop GameWorldScore, a unified benchmark measuring visual quality, temporal quality, actioncontrollability, and physical rule understanding for Minecraft worldgeneration. Extensive experiments show that Matrix-Game consistentlyoutperforms prior open-source Minecraft world models (including Oasis andMineWorld) across all metrics, with particularly strong gains incontrollability and physical consistency. Double-blind human evaluationsfurther confirm the superiority of Matrix-Game, highlighting its ability togenerate perceptually realistic and precisely controllable videos acrossdiverse game scenarios. To facilitate future research on interactiveimage-to-world generation, we will open-source the Matrix-Game model weightsand the GameWorld Score benchmark at https://github.com/SkyworkAI/Matrix-Game.</description>
      <author>example@mail.com (Yifan Zhang, Chunli Peng, Boyang Wang, Puyi Wang, Qingcheng Zhu, Fei Kang, Biao Jiang, Zedong Gao, Eric Li, Yang Liu, Yahui Zhou)</author>
      <guid isPermaLink="false">2506.18701v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>STACT-Time: Spatio-Temporal Cross Attention for Cine Thyroid Ultrasound Time Series Classification</title>
      <link>http://arxiv.org/abs/2506.18172v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为STACT-Time的新型表示学习框架，用于通过超声电影序列对甲状腺超声进行分类，旨在减少良性结节的过度活检。&lt;h4&gt;背景&lt;/h4&gt;甲状腺癌是美国最常见的癌症之一，甲状腺结节常通过超声成像检测，部分需要通过细针穿刺活检进一步评估。尽管细针穿刺活检有效，但往往导致良性结节的过度活检，给患者带来不适和焦虑。&lt;h4&gt;目的&lt;/h4&gt;开发一种模型，以减少良性结节的过度活检，同时保持对恶性肿瘤的高敏感性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为STACT-Time的模型，该模型结合了超声电影序列的成像特征和由预训练模型自动生成的分割掩码特征。模型利用自注意力和交叉注意力机制来捕捉超声电影序列的丰富时空上下文，并通过分割引导学习来增强特征表示。&lt;h4&gt;主要发现&lt;/h4&gt;与最先进模型相比，STACT-Time模型提高了恶性肿瘤的预测能力，交叉验证精度为0.91（±0.02），F1分数为0.89（±0.02）。&lt;h4&gt;结论&lt;/h4&gt;STACT-Time模型有望通过减少良性结节的过度活检，同时保持对恶性肿瘤的高敏感性，从而提高临床决策能力并改善患者预后。&lt;h4&gt;翻译&lt;/h4&gt;摘要：甲状腺癌是美国最常见的癌症之一。甲状腺结节经常通过超声（US）成像检测，其中一些需要通过细针穿刺活检（FNA）进行进一步评估。尽管FNA很有效，但它往往导致良性结节的过度活检，造成患者不适和焦虑。为了解决这个问题，美国放射学会甲状腺成像报告和数据系统（TI-RADS）已被开发出来以减少良性活检。然而，这样的系统受到观察者之间差异的限制。最近，深度学习方法试图改善风险分层，但它们往往未能利用超声电影片段提供的丰富时空上下文，这些片段包含动态全局信息和从各种视角观察到的周围结构变化。在这项工作中，我们提出了Spatio-Temporal Cross Attention for Cine Thyroid Ultrasound Time Series Classification（STACT-Time）模型，这是一种新颖的表示学习框架，它将来自超声电影片段的成像特征与由预训练模型自动生成的分割掩码特征相结合。通过利用自注意力和交叉注意力机制，我们的模型捕捉了超声电影片段的丰富时空上下文，并通过分割引导学习增强了特征表示。与最先进模型相比，我们的模型提高了恶性肿瘤的预测能力，实现了交叉验证精度为0.91（±0.02）和F1分数为0.89（±0.02）。通过减少良性结节的过度活检，同时保持对恶性肿瘤的高敏感性，我们的模型有望提高临床决策能力并改善患者预后。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Thyroid cancer is among the most common cancers in the United States. Thyroidnodules are frequently detected through ultrasound (US) imaging, and somerequire further evaluation via fine-needle aspiration (FNA) biopsy. Despite itseffectiveness, FNA often leads to unnecessary biopsies of benign nodules,causing patient discomfort and anxiety. To address this, the American Collegeof Radiology Thyroid Imaging Reporting and Data System (TI-RADS) has beendeveloped to reduce benign biopsies. However, such systems are limited byinterobserver variability. Recent deep learning approaches have sought toimprove risk stratification, but they often fail to utilize the rich temporaland spatial context provided by US cine clips, which contain dynamic globalinformation and surrounding structural changes across various views. In thiswork, we propose the Spatio-Temporal Cross Attention for Cine ThyroidUltrasound Time Series Classification (STACT-Time) model, a novelrepresentation learning framework that integrates imaging features from US cineclips with features from segmentation masks automatically generated by apretrained model. By leveraging self-attention and cross-attention mechanisms,our model captures the rich temporal and spatial context of US cine clips whileenhancing feature representation through segmentation-guided learning. Ourmodel improves malignancy prediction compared to state-of-the-art models,achieving a cross-validation precision of 0.91 (plus or minus 0.02) and an F1score of 0.89 (plus or minus 0.02). By reducing unnecessary biopsies of benignnodules while maintaining high sensitivity for malignancy detection, our modelhas the potential to enhance clinical decision-making and improve patientoutcomes.</description>
      <author>example@mail.com (Irsyad Adam, Tengyue Zhang, Shrayes Raman, Zhuyu Qiu, Brandon Taraku, Hexiang Feng, Sile Wang, Ashwath Radhachandran, Shreeram Athreya, Vedrana Ivezic, Peipei Ping, Corey Arnold, William Speier)</author>
      <guid isPermaLink="false">2506.18172v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking histopathology foundation models in a multi-center dataset for skin cancer subtyping</title>
      <link>http://arxiv.org/abs/2506.18668v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepeted for oral presentation at Medical Image Understanding and  Analysis (MIUA) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了在大规模、领域内数据集上进行预训练的病理学基础模型（FM），以及如何通过这些模型提高下游任务中的迁移学习能力。论文提出了一个用于评估FM在多实例学习（MIL）分类框架中作为补丁级特征提取器的基准，并引入了一个新的度量指标，用于衡量模型对分布变化的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;在计算病理学中，由于病理切片的尺寸巨大，需要使用多实例学习（MIL）框架进行自动化的全切片图像分析。目前，病理学基础模型（FM）的多样性突出了设计实际挑战来评估其有效性的必要性。&lt;h4&gt;目的&lt;/h4&gt;设计一个基准来评估病理学基础模型（FM）在多实例学习（MIL）分类框架中作为补丁级特征提取器的有效性，并定义一个新的度量指标来衡量模型的一致性。&lt;h4&gt;方法&lt;/h4&gt;使用AI4SkIN数据集，该数据集包含具有挑战性的皮肤纺锤细胞肿瘤亚型的多中心队列切片，提出了一种新的基准和度量指标。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提取较少偏见的特征可以增强分类性能，特别是在基于相似性的MIL分类器中。&lt;h4&gt;结论&lt;/h4&gt;通过使用预训练的病理学基础模型和改进的特征提取方法，可以显著提高病理学图像分析的分类性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pretraining on large-scale, in-domain datasets grants histopathologyfoundation models (FM) the ability to learn task-agnostic data representations,enhancing transfer learning on downstream tasks. In computational pathology,automated whole slide image analysis requires multiple instance learning (MIL)frameworks due to the gigapixel scale of the slides. The diversity amonghistopathology FMs has highlighted the need to design real-world challenges forevaluating their effectiveness. To bridge this gap, our work presents a novelbenchmark for evaluating histopathology FMs as patch-level feature extractorswithin a MIL classification framework. For that purpose, we leverage theAI4SkIN dataset, a multi-center cohort encompassing slides with challengingcutaneous spindle cell neoplasm subtypes. We also define the Foundation Model -Silhouette Index (FM-SI), a novel metric to measure model consistency againstdistribution shifts. Our experimentation shows that extracting less biasedfeatures enhances classification performance, especially in similarity-basedMIL classifiers.</description>
      <author>example@mail.com (Pablo Meseguer, Rocío del Amor, Valery Naranjo)</author>
      <guid isPermaLink="false">2506.18668v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>CultureMERT: Continual Pre-Training for Cross-Cultural Music Representation Learning</title>
      <link>http://arxiv.org/abs/2506.17818v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures, accepted to the 26th International Society for  Music Information Retrieval conference (ISMIR 2025), to be held in Daejeon,  South Korea&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了 CultureMERT-95M，一个针对跨文化音乐表示学习与理解的多文化适应性基础模型，以及其在多种非西方音乐自动标签任务中的表现。&lt;h4&gt;背景&lt;/h4&gt;尽管音乐基础模型在音频表示学习方面取得了进展，但它们在多种音乐传统中的有效性仍然有限。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够增强跨文化音乐表示学习与理解的多文化适应性基础模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一个两阶段的持续预训练策略，结合学习率重温和重新衰减，以实现即使在有限的计算资源下也能稳定适应。&lt;h4&gt;主要发现&lt;/h4&gt;在包含希腊、土耳其和印度音乐传统的650小时多文化数据集上训练，CultureMERT-95M在多种非西方音乐自动标签任务中平均提高了4.9%的ROC-AUC和AP，超过了之前的最先进水平，同时在以西方为中心的基准测试中遗忘最小。任务算术（将单一文化适应性模型在权重空间中合并的替代方法）在非西方自动标签任务上的表现与多文化训练的模型相当，在西方数据集上没有退化。跨文化评估显示，单一文化模型在不同音乐传统中的迁移效果不同，而多文化适应性模型实现了最佳的整体性能。&lt;h4&gt;结论&lt;/h4&gt;为了支持世界音乐表示学习的研究，本文公开发布了 CultureMERT-95M 和 CultureMERT-TA-95M，以促进更具文化意识的音乐基础模型的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，音乐基础模型在音频表示学习方面取得了进展，但它们在多种音乐传统中的有效性仍然有限。我们介绍了 CultureMERT-95M，这是一个为增强跨文化音乐表示学习与理解而开发的多文化适应性基础模型。为了实现这一点，我们提出了一种两阶段的持续预训练策略，该策略结合了学习率重温和重新衰减，即使在有限的计算资源下也能实现稳定适应。在包含希腊、土耳其和印度音乐传统的650小时多文化数据集上训练，CultureMERT-95M在多种非西方音乐自动标签任务中平均提高了4.9%的ROC-AUC和AP，超过了之前的最先进水平，同时在以西方为中心的基准测试中遗忘最小。我们进一步研究了任务算术，这是一种将单一文化适应性模型在权重空间中合并的替代方法。任务算术在非西方自动标签任务上的表现与我们的多文化训练模型相当，在西方数据集上没有退化。跨文化评估显示，单一文化模型在不同音乐传统中的迁移效果不同，而多文化适应性模型实现了最佳的整体性能。为了支持世界音乐表示学习的研究，我们公开发布了 CultureMERT-95M 和 CultureMERT-TA-95M，以促进更具文化意识的音乐基础模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in music foundation models have improved audio representationlearning, yet their effectiveness across diverse musical traditions remainslimited. We introduce CultureMERT-95M, a multi-culturally adapted foundationmodel developed to enhance cross-cultural music representation learning andunderstanding. To achieve this, we propose a two-stage continual pre-trainingstrategy that integrates learning rate re-warming and re-decaying, enablingstable adaptation even with limited computational resources. Training on a650-hour multi-cultural data mix, comprising Greek, Turkish, and Indian musictraditions, results in an average improvement of 4.9% in ROC-AUC and AP acrossdiverse non-Western music auto-tagging tasks, surpassing priorstate-of-the-art, with minimal forgetting on Western-centric benchmarks. Wefurther investigate task arithmetic, an alternative approach to multi-culturaladaptation that merges single-culture adapted models in the weight space. Taskarithmetic performs on par with our multi-culturally trained model onnon-Western auto-tagging tasks and shows no regression on Western datasets.Cross-cultural evaluation reveals that single-culture models transfer withvarying effectiveness across musical traditions, whereas the multi-culturallyadapted model achieves the best overall performance. To support research onworld music representation learning, we publicly release CultureMERT-95M andCultureMERT-TA-95M, fostering the development of more culturally aware musicfoundation models.</description>
      <author>example@mail.com (Angelos-Nikolaos Kanatas, Charilaos Papaioannou, Alexandros Potamianos)</author>
      <guid isPermaLink="false">2506.17818v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Auto-Regressive Surface Cutting</title>
      <link>http://arxiv.org/abs/2506.18017v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Tech. report. https://victorcheung12.github.io/seamgpt&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SeamGPT是一种自动回归模型，通过模拟专业工作流程生成切割线，用于表面切割任务，具有在UV参数化、纹理映射和网格分解中的应用。&lt;h4&gt;背景&lt;/h4&gt;表面切割是计算机图形学中的基本任务，但在UV参数化、纹理映射和网格分解中，现有方法常产生过于碎片化的图集，缺乏语义连贯性。&lt;h4&gt;目的&lt;/h4&gt;提出SeamGPT，旨在生成具有语义连贯性的切割线。&lt;h4&gt;方法&lt;/h4&gt;将表面切割作为下一个标记预测任务，对网格顶点和边上的点云进行采样，将它们编码为形状条件，并使用GPT风格的transformer按顺序预测带有量化3D坐标的切割线段。&lt;h4&gt;主要发现&lt;/h4&gt;SeamGPT在包含流形和非流形网格的UV展开基准测试中表现出色，包括艺术家创建和3D扫描的模型。此外，它通过提供干净的边界来增强现有的3D分割工具，以便进行部分分解。&lt;h4&gt;结论&lt;/h4&gt;SeamGPT模型在表面切割任务中表现出优异的性能，并提高了3D分割工具的效率。&lt;h4&gt;翻译&lt;/h4&gt;Surface cutting is a fundamental task in computer graphics, with applications in UV parameterization, texture mapping, and mesh decomposition. However, existing methods often produce technically valid but overly fragmented atlases that lack semantic coherence. We introduce SeamGPT, an auto-regressive model that generates cutting seams by mimicking professional workflows. Our key technical innovation lies in formulating surface cutting as a next token prediction task: sample point clouds on mesh vertices and edges, encode them as shape conditions, and employ a GPT-style transformer to sequentially predict seam segments with quantized 3D coordinates. Our approach achieves exceptional performance on UV unwrapping benchmarks containing both manifold and non-manifold meshes, including artist-created, and 3D-scanned models. In addition, it enhances existing 3D segmentation tools by providing clean boundaries for part decomposition.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surface cutting is a fundamental task in computer graphics, with applicationsin UV parameterization, texture mapping, and mesh decomposition. However,existing methods often produce technically valid but overly fragmented atlasesthat lack semantic coherence. We introduce SeamGPT, an auto-regressive modelthat generates cutting seams by mimicking professional workflows. Our keytechnical innovation lies in formulating surface cutting as a next tokenprediction task: sample point clouds on mesh vertices and edges, encode them asshape conditions, and employ a GPT-style transformer to sequentially predictseam segments with quantized 3D coordinates. Our approach achieves exceptionalperformance on UV unwrapping benchmarks containing both manifold andnon-manifold meshes, including artist-created, and 3D-scanned models. Inaddition, it enhances existing 3D segmentation tools by providing cleanboundaries for part decomposition.</description>
      <author>example@mail.com (Yang Li, Victor Cheung, Xinhai Liu, Yuguang Chen, Zhongjin Luo, Biwen Lei, Haohan Weng, Zibo Zhao, Jingwei Huang, Zhuo Chen, Chunchao Guo)</author>
      <guid isPermaLink="false">2506.18017v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>When Fine-Tuning Fails: Lessons from MS MARCO Passage Ranking</title>
      <link>http://arxiv.org/abs/2506.18535v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了微调预训练的Transformer模型在MS MARCO乘客排名任务上反而降低性能的悖论现象。&lt;h4&gt;背景&lt;/h4&gt;微调预训练模型通常可以提高特定任务的表现，但本文发现这一现象并不适用于MS MARCO乘客排名任务。&lt;h4&gt;目的&lt;/h4&gt;通过实验分析微调预训练模型在MS MARCO任务上的表现，并探讨可能的原因。&lt;h4&gt;方法&lt;/h4&gt;作者进行了全面实验，包括五种模型变体，包括全参数微调和参数高效的LoRA调整。&lt;h4&gt;主要发现&lt;/h4&gt;所有微调方法的表现均不如基线模型（MRR@10: 0.3026）。分析表明，微调破坏了基线模型在大量句子对（包括910万MS MARCO样本）上学习到的最佳嵌入空间结构。UMAP可视化显示嵌入空间逐渐变平，训练动态分析和计算效率指标进一步支持这一发现。&lt;h4&gt;结论&lt;/h4&gt;这些结果挑战了关于在饱和基准上迁移学习有效性的传统观点，并暗示可能需要架构创新来实现有意义的改进。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了在微调预训练的Transformer模型时，其在MS MARCO乘客排名任务上反而降低性能的反直觉现象。通过涉及五种模型变体（包括全参数微调和参数高效的LoRA调整）的全面实验，我们证明所有微调方法的表现均不及基线模型sentence-transformers/all- MiniLM-L6-v2（MRR@10: 0.3026）。我们的分析揭示，微调破坏了基线模型在10亿句子对（包括910万MS MARCO样本）的广泛预训练期间学习的最佳嵌入空间结构。UMAP可视化显示了嵌入空间的渐进扁平化，而训练动态分析和计算效率指标进一步支持了我们的发现。这些结果挑战了关于在饱和基准上迁移学习有效性的传统观点，并暗示可能需要架构创新来实现有意义的改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the counterintuitive phenomenon where fine-tuningpre-trained transformer models degrades performance on the MS MARCO passageranking task. Through comprehensive experiments involving five modelvariants-including full parameter fine-tuning and parameter efficient LoRAadaptations-we demonstrate that all fine-tuning approaches underperform thebase sentence-transformers/all- MiniLM-L6-v2 model (MRR@10: 0.3026). Ouranalysis reveals that fine-tuning disrupts the optimal embedding spacestructure learned during the base model's extensive pre-training on 1 billionsentence pairs, including 9.1 million MS MARCO samples. UMAP visualizationsshow progressive embedding space flattening, while training dynamics analysisand computational efficiency metrics further support our findings. Theseresults challenge conventional wisdom about transfer learning effectiveness onsaturated benchmarks and suggest architectural innovations may be necessary formeaningful improvements.</description>
      <author>example@mail.com (Manu Pande, Shahil Kumar, Anay Yatin Damle)</author>
      <guid isPermaLink="false">2506.18535v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Federated Learning from Molecules to Processes: A Perspective</title>
      <link>http://arxiv.org/abs/2506.18525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了化学工程中联邦学习的视角，旨在化学工业中推动机器学习（ML）的发展。联邦学习允许组织在保护各自数据隐私的情况下共同训练机器学习模型。&lt;h4&gt;背景&lt;/h4&gt;化学公司拥有大量的化学和工艺数据，这些数据通常属于私有，形成了数据孤岛，阻碍了在化学工程中用大量数据进行机器学习模型的训练。&lt;h4&gt;目的&lt;/h4&gt;提出联邦学习在化学工程中的应用潜力，以及如何通过联邦学习提高机器学习模型的准确性，同时保护企业的数据隐私。&lt;h4&gt;方法&lt;/h4&gt;讨论了联邦学习在化学工程不同领域的潜在应用，并应用联邦学习进行了两个案例研究：使用图神经网络预测二元混合活度系数和使用自动编码器进行蒸馏塔的系统识别。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，使用联邦学习共同训练的机器学习模型比单个化学公司训练的模型具有更高的准确性，并且可以与使用所有公司合并数据集训练的模型相媲美。&lt;h4&gt;结论&lt;/h4&gt;联邦学习在化学工程中具有巨大潜力，可以提升机器学习模型的同时尊重企业数据隐私，对未来的工业应用具有广阔的前景。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种关于化学工程中联邦学习的视角，展望了在化学工业中机器学习（ML）发展的协作努力。大量的化学和工艺数据属于化学公司所有，因此被锁定在数据孤岛中，阻碍了在化学工程中用大量数据进行机器学习模型的训练。最近，联邦学习的概念在机器学习研究中受到了越来越多的关注，它使组织能够在不披露各自数据的情况下共同训练机器学习模型。我们讨论了联邦学习在化学工程几个领域的潜在应用，从分子尺度到工艺尺度。此外，我们应用联邦学习进行了两个示例案例研究，模拟了多个化学公司持有私有数据集的实际场景：（i）使用图神经网络预测二元混合活度系数；（ii）使用自动编码器进行蒸馏塔的系统识别。我们的结果表明，使用联邦学习共同训练的机器学习模型比单个化学公司单独训练的模型具有更高的准确性，并且可以与使用所有公司合并数据集训练的模型相媲美。因此，联邦学习在尊重企业数据隐私的同时，具有推进化学工程中机器学习模型的巨大潜力，对未来的工业应用具有广阔的前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a perspective on federated learning in chemical engineering thatenvisions collaborative efforts in machine learning (ML) developments withinthe chemical industry. Large amounts of chemical and process data areproprietary to chemical companies and are therefore locked in data silos,hindering the training of ML models on large data sets in chemical engineering.Recently, the concept of federated learning has gained increasing attention inML research, enabling organizations to jointly train machine learning modelswithout disclosure of their individual data. We discuss potential applicationsof federated learning in several fields of chemical engineering, from themolecular to the process scale. In addition, we apply federated learning in twoexemplary case studies that simulate practical scenarios of multiple chemicalcompanies holding proprietary data sets: (i) prediction of binary mixtureactivity coefficients with graph neural networks and (ii) system identificationof a distillation column with autoencoders. Our results indicate that ML modelsjointly trained with federated learning yield significantly higher accuracythan models trained by each chemical company individually and can performsimilarly to models trained on combined datasets from all companies. Federatedlearning has therefore great potential to advance ML models in chemicalengineering while respecting corporate data privacy, making it promising forfuture industrial applications.</description>
      <author>example@mail.com (Jan G. Rittig, Clemens Kortmann)</author>
      <guid isPermaLink="false">2506.18525v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>InternSpatial: A Comprehensive Dataset for Spatial Reasoning in Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.18385v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了InternSpatial，这是目前最大的开源空间推理数据集，以及对应的评估基准InternSpatial-Bench，用于评估在多种指令格式下的空间理解能力。&lt;h4&gt;背景&lt;/h4&gt;现有的空间推理开放资源在规模、视觉多样性和指令表达性方面仍然有限。&lt;h4&gt;目的&lt;/h4&gt;提出InternSpatial数据集和InternSpatial-Bench评估基准，以促进视觉语言模型（VLMs）中空间推理能力的提升。&lt;h4&gt;方法&lt;/h4&gt;InternSpatial包含1200万个问答对，覆盖单视图和多视图设置，来自不同的视觉环境，并支持19种指令格式，反映不同的查询风格。InternSpatial-Bench包括单视图任务和引入的新旋转角度预测任务。&lt;h4&gt;主要发现&lt;/h4&gt;在InternSpatial-Bench和VSI-Bench上，基于InternSpatial训练的模型在保持通用基准上良好性能的同时，分别提升了12.1%和10.7%。&lt;h4&gt;结论&lt;/h4&gt;这些资源将支持具有空间能力的VLMs在机器人学和具身人工智能等实际应用中的发展。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces InternSpatial, the largest open-source dataset for spatial reasoning in VLMs, along with InternSpatial-Bench, a corresponding evaluation benchmark designed to assess spatial understanding under diverse instruction formats.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent benchmarks and datasets have been proposed to improve spatialreasoning in vision-language models (VLMs), yet existing open resources remainlimited in scale, visual diversity, and instruction expressiveness. In thiswork, we introduce InternSpatial, the largest open-source dataset for spatialreasoning in VLMs, along with InternSpatial-Bench, a corresponding evaluationbenchmark designed to assess spatial understanding under diverse instructionformats. InternSpatial comprises 12 million QA pairs spanning both single-viewand multi-view settings, drawn from diverse visual environments and supporting19 instruction formats that reflect varied query styles. For evaluation, wepropose InternSpatial-Bench for single-view tasks and expand multi-viewreasoning by introducing a novel rotation angle prediction task that has notbeen explored in prior work. Experimental results show that models trained onInternSpatial achieve 12.1% improvement on InternSpatial-Bench and 10.7% onVSI-Bench, while maintaining strong performance on general-purpose benchmarks.We hope these resources will support the development of spatially capable VLMsin practical applications such as robotics and embodied AI.</description>
      <author>example@mail.com (Nianchen Deng, Lixin Gu, Shenglong Ye, Yinan He, Zhe Chen, Songze Li, Haomin Wang, Xingguang Wei, Tianshuo Yang, Min Dou, Tong He, Wenqi Shao, Kaipeng Zhang, Yi Wang, Botian Shi, Yanting Zhang, Jifeng Dai, Yu Qiao, Hongjie Zhang, Wenhai Wang)</author>
      <guid isPermaLink="false">2506.18385v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>ADA-DPM: A Neural Descriptors-based Adaptive Noise Point Filtering Strategy for SLAM</title>
      <link>http://arxiv.org/abs/2506.18016v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种自适应噪声滤波SLAM策略-ADA-DPM，在动态物体干扰、点云噪声和无结构环境中，实现了定位精度和系统鲁棒性之间的良好平衡。&lt;h4&gt;背景&lt;/h4&gt;LiDAR SLAM在移动机器人导航和高精度地图构建等领域展现出显著的应用价值。然而，现有方法在处理动态物体干扰、点云噪声和无结构环境时，往往需要在定位精度和系统鲁棒性之间做出权衡。&lt;h4&gt;目的&lt;/h4&gt;提出一种自适应噪声滤波SLAM策略，以解决动态物体干扰、点云噪声和无结构环境带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;设计了动态分段头部来预测动态点特征点的类别，消除动态特征点；设计了全局重要性评分头部，自适应选择贡献度和特征更高的特征点，同时抑制噪声干扰；构建了跨层图内卷积模块（GLI-GCN），融合多尺度邻域结构，从而增强重叠特征的判别能力。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个公开数据集上进行了测试，并取得了优异的结果。&lt;h4&gt;结论&lt;/h4&gt;提出的ADA-DPM策略在定位精度和系统鲁棒性方面均表现出色，有效解决了动态物体干扰、点云噪声和无结构环境带来的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR SLAM has demonstrated significant application value in various fields,including mobile robot navigation and high-precision map construction. However,existing methods often need to make a trade-off between positioning accuracyand system robustness when faced with dynamic object interference, point cloudnoise, and unstructured environments. To address this challenge, we propose anadaptive noise filtering SLAM strategy-ADA-DPM, achieving excellent preferencein both aspects. We design the Dynamic Segmentation Head to predict thecategory of feature points belonging to dynamic points, to eliminate dynamicfeature points; design the Global Importance Scoring Head to adaptively selectfeature points with higher contribution and features while suppressing noiseinterference; and construct the Cross Layer Intra-Graph Convolution Module(GLI-GCN) to fuse multi-scale neighborhood structures, thereby enhancing thediscriminative ability of overlapping features. Finally, to further validatethe effectiveness of our method, we tested it on several publicly availabledatasets and achieved outstanding results.</description>
      <author>example@mail.com (Yongxin Shao, Binrui Wang, Aihong Tan)</author>
      <guid isPermaLink="false">2506.18016v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Your Token Becomes Worthless: Unveiling Rug Pull Schemes in Crypto Token via Code-and-Transaction Fusion Analysis</title>
      <link>http://arxiv.org/abs/2506.18398v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了RPhunter技术，用于检测Rug pull诈骗，通过结合代码和交易信息，提高检测效果。&lt;h4&gt;背景&lt;/h4&gt;Rug pull诈骗是加密货币领域的持续威胁，给投资者带来重大经济损失。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的技术，有效地检测Rug pull诈骗。&lt;h4&gt;方法&lt;/h4&gt;RPhunter通过以下步骤实现检测：建立声明性规则和执行流分析以提取代码风险信息，构建语义风险代码图；将动态代币交易活动表示为代币流行为图；利用图神经网络从语义风险代码图和代币流行为图中提取互补特征，并通过注意力融合模型整合这些特征。&lt;h4&gt;主要发现&lt;/h4&gt;RPhunter在构建的地面数据集上实现了95.3%的精确度、93.8%的召回率和94.5%的F1分数，并且在实际场景中识别了4801个Rug pull代币，精确度为91%。&lt;h4&gt;结论&lt;/h4&gt;RPhunter在检测Rug pull诈骗方面表现优于现有方法，具有较高的准确性和召回率。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Rug pull scams have emerged as a persistent threat to cryptocurrency, causing significant financial losses. A typical scenario involves scammers deploying honeypot contracts to attract investments, restricting token sales, and draining the funds, which leaves investors with worthless tokens. Current methods either rely on predefined patterns to detect code risks or utilize statistical transaction data to train detection models. However, real-world Rug Pull schemes often involve a complex interplay between malicious code and suspicious transaction behaviors. These methods, which solely focus on one aspect, fall short in detecting such schemes effectively. In this paper, we propose RPhunter, a novel technique that integrates code and transaction for Rug Pull detection. First, RPhunter establishes declarative rules and performs flow analysis to extract code risk information, further constructing a semantic risk code graph (SRCG). Meanwhile, to leverage transaction information, RPhunter formulates dynamic token transaction activities as a token flow behavior graph (TFBG) in which nodes and edges are characterized from network structure and market manipulation perspectives. Finally, RPhunter employs graph neural networks to extract complementary features from SRCG and TFBG, integrating them through an attention fusion model to enhance the detection of Rug Pull. We manually analyzed 645 Rug Pull incidents from code and transaction aspects and constructed a ground-truth dataset. We evaluated RPhunter on our dataset, achieving a precision of 95.3%, a recall of 93.8% and an F1 score of 94.5%, which highlights superior performance compared to existing state-of-the-art methods. Furthermore, when applied to the real-world scenarios, RPhunter has identified 4801 Rug Pull tokens, achieving a precision of 91%.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Rug pull scams have emerged as a persistent threat to cryptocurrency, causingsignificant financial losses. A typical scenario involves scammers deployinghoneypot contracts to attract investments, restricting token sales, anddraining the funds, which leaves investors with worthless tokens. Currentmethods either rely on predefined patterns to detect code risks or utilizestatistical transaction data to train detection models. However, real-world RugPull schemes often involve a complex interplay between malicious code andsuspicious transaction behaviors. These methods, which solely focus on oneaspect, fall short in detecting such schemes effectively.  In this paper, we propose RPhunter, a novel technique that integrates codeand transaction for Rug Pull detection. First, RPhunter establishes declarativerules and performs flow analysis to extract code risk information, furtherconstructing a semantic risk code graph (SRCG). Meanwhile, to leveragetransaction information, RPhunter formulates dynamic token transactionactivities as a token flow behavior graph (TFBG) in which nodes and edges arecharacterized from network structure and market manipulation perspectives.Finally, RPhunter employs graph neural networks to extract complementaryfeatures from SRCG and TFBG, integrating them through an attention fusion modelto enhance the detection of Rug Pull. We manually analyzed 645 Rug Pullincidents from code and transaction aspects and constructed a ground-truthdataset. We evaluated RPhunter on our dataset, achieving a precision of 95.3%,a recall of 93.8% and an F1 score of 94.5%, which highlights superiorperformance compared to existing state-of-the-art methods. Furthermore, whenapplied to the real-world scenarios, RPhunter has identified 4801 Rug Pulltokens, achieving a precision of 91%.</description>
      <author>example@mail.com (Hao Wu, Haijun Wang, Shangwang Li, Yin Wu, Ming Fan, Wuxia Jin, Yitao Zhao, Ting Liu)</author>
      <guid isPermaLink="false">2506.18398v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>TEM^3-Learning: Time-Efficient Multimodal Multi-Task Learning for Advanced Assistive Driving</title>
      <link>http://arxiv.org/abs/2506.18084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TEM^3-Learning的新型多任务学习框架，旨在通过共享表示探索任务间的相关性，以促进辅助驾驶的发展。&lt;h4&gt;背景&lt;/h4&gt;现有的多任务学习方法面临两个关键限制：单模态约束限制了全面场景理解，以及低效的架构阻碍了实时部署。&lt;h4&gt;目的&lt;/h4&gt;提出TEM^3-Learning框架，通过两阶段架构联合优化驾驶员情绪识别、驾驶员行为识别、交通场景识别和车辆行为识别。&lt;h4&gt;方法&lt;/h4&gt;该框架包括两个主要组件：mamba基于的多视角时空特征提取子网络（MTS-Mamba）和基于多任务学习的门控多模态特征集成器（MGMI）。MTS-Mamba引入了前向-后向时间扫描机制和全局-局部空间注意力，以高效地从多视角序列图像中提取低成本时空特征。MGMI使用特定于任务的门控模块自适应地突出每个任务中最相关的模态特征，有效缓解了多任务学习中的负迁移问题。&lt;h4&gt;主要发现&lt;/h4&gt;在AIDE数据集上的评估表明，所提出的模型在所有四个任务上都实现了最先进的准确率，同时保持了轻量级的架构，参数少于600万，推理速度达到142.32 FPS。&lt;h4&gt;结论&lt;/h4&gt;TEM^3-Learning框架有效，且每个模块都有独立的贡献，代码已开源。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多任务学习（MTL）可以通过共享表示来探索任务间的相关性，从而推进辅助驾驶。然而，现有的方法面临两个关键限制：单模态约束限制了全面场景理解，以及低效的架构阻碍了实时部署。本文提出了一种名为TEM^3-Learning（时间高效的多模态多任务学习）的新颖框架，通过两阶段架构联合优化驾驶员情绪识别、驾驶员行为识别、交通场景识别和车辆行为识别。第一个组件是基于mamba的多视角时空特征提取子网络（MTS-Mamba），它引入了前向-后向时间扫描机制和全局-局部空间注意力，以高效地从多视角序列图像中提取低成本时空特征。第二个组件是基于多任务学习的门控多模态特征集成器（MGMI），它使用特定于任务的门控模块来自适应地突出每个任务中最相关的模态特征，有效缓解了多任务学习中的负迁移问题。在AIDE数据集上的评估表明，所提出的模型在所有四个任务上都实现了最先进的准确率，同时保持了轻量级的架构，参数少于600万，推理速度达到142.32 FPS。严格的消融研究进一步验证了所提出框架的有效性以及每个模块的独立贡献。代码可在https://github.com/Wenzhuo-Liu/TEM3-Learning上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-task learning (MTL) can advance assistive driving by exploringinter-task correlations through shared representations. However, existingmethods face two critical limitations: single-modality constraints limitingcomprehensive scene understanding and inefficient architectures impedingreal-time deployment. This paper proposes TEM^3-Learning (Time-EfficientMultimodal Multi-task Learning), a novel framework that jointly optimizesdriver emotion recognition, driver behavior recognition, traffic contextrecognition, and vehicle behavior recognition through a two-stage architecture.The first component, the mamba-based multi-view temporal-spatial featureextraction subnetwork (MTS-Mamba), introduces a forward-backward temporalscanning mechanism and global-local spatial attention to efficiently extractlow-cost temporal-spatial features from multi-view sequential images. Thesecond component, the MTL-based gated multimodal feature integrator (MGMI),employs task-specific multi-gating modules to adaptively highlight the mostrelevant modality features for each task, effectively alleviating the negativetransfer problem in MTL. Evaluation on the AIDE dataset, our proposed modelachieves state-of-the-art accuracy across all four tasks, maintaining alightweight architecture with fewer than 6 million parameters and delivering animpressive 142.32 FPS inference speed. Rigorous ablation studies furthervalidate the effectiveness of the proposed framework and the independentcontributions of each module. The code is available onhttps://github.com/Wenzhuo-Liu/TEM3-Learning.</description>
      <author>example@mail.com (Wenzhuo Liu, Yicheng Qiao, Zhen Wang, Qiannan Guo, Zilong Chen, Meihua Zhou, Xinran Li, Letian Wang, Zhiwei Li, Huaping Liu, Wenshuo Wang)</author>
      <guid isPermaLink="false">2506.18084v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent</title>
      <link>http://arxiv.org/abs/2506.18559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为T-CPDL（时间因果概率描述逻辑）的框架，用于增强语言模型在处理时间、因果关系和概率推理方面的能力。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型擅长生成流畅文本，但在涉及时间约束、因果关系和概率推理的结构化推理方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出了T-CPDL框架。&lt;h4&gt;方法&lt;/h4&gt;T-CPDL通过扩展传统的描述逻辑，结合时间区间操作符、显式因果关系和概率注释，提供了两种不同的变体：一种使用Allen区间代数来捕获定性时间关系，另一种增强了显式时间戳因果断言。&lt;h4&gt;主要发现&lt;/h4&gt;实证评估表明，T-CPDL在时间推理和因果推断基准上显著提高了推理精度、可解释性和置信度校准。&lt;h4&gt;结论&lt;/h4&gt;T-CPDL通过提供透明的推理路径和精细的时间因果语义，显著增强了语言模型支持稳健、可解释和值得信赖的决策的能力，并为开发高级逻辑检索增强生成（Logic-RAG）框架奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes a framework named T-CPDL (Temporal Causal Probabilistic Description Logic) to enhance the capabilities of large language models in dealing with temporal, causal, and probabilistic reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models excel at generating fluent text but frequently strugglewith structured reasoning involving temporal constraints, causal relationships,and probabilistic reasoning. To address these limitations, we propose TemporalCausal Probabilistic Description Logic (T-CPDL), an integrated framework thatextends traditional Description Logic with temporal interval operators,explicit causal relationships, and probabilistic annotations. We present twodistinct variants of T-CPDL: one capturing qualitative temporal relationshipsthrough Allen's interval algebra, and another variant enriched with explicittimestamped causal assertions. Both variants share a unified logical structure,enabling complex reasoning tasks ranging from simple temporal ordering tonuanced probabilistic causation. Empirical evaluations on temporal reasoningand causal inference benchmarks confirm that T-CPDL substantially improvesinference accuracy, interpretability, and confidence calibration of languagemodel outputs. By delivering transparent reasoning paths and fine-grainedtemporal and causal semantics, T-CPDL significantly enhances the capability oflanguage models to support robust, explainable, and trustworthydecision-making. This work also lays the groundwork for developing advancedLogic-Retrieval-Augmented Generation (Logic-RAG) frameworks, potentiallyboosting the reasoning capabilities and efficiency of knowledge graph-enhancedRAG systems.</description>
      <author>example@mail.com (Hong Qing Yu)</author>
      <guid isPermaLink="false">2506.18559v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Beyond instruction-conditioning, MoTE: Mixture of Task Experts for Multi-task Embedding Models</title>
      <link>http://arxiv.org/abs/2506.17781v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了密集嵌入在现代机器学习系统中的应用，特别是在检索增强生成（RAG）、信息检索和表征学习等领域。提出了Mixture of Task Experts（MoTE）模型，通过任务感知对比学习（tacl）提高模型生成专门嵌入的能力。&lt;h4&gt;背景&lt;/h4&gt;密集嵌入对于现代机器学习系统至关重要，但传统的指令条件化方法在低容量模型中的应用受到表示限制，影响了性能提升。&lt;h4&gt;目的&lt;/h4&gt;分析传统方法的限制并提出新的模型以增强生成专门嵌入的能力。&lt;h4&gt;方法&lt;/h4&gt;引入了MoTE变压器块，它使用tacl训练任务专门的参数。&lt;h4&gt;主要发现&lt;/h4&gt;MoTE在检索数据集上实现了64%的性能提升（从+3.27提升到+5.21），在所有数据集上实现了43%的性能提升（从+1.81提升到+2.60）。这些提升是在不改变指令、训练数据、推理时间或激活参数数量的情况下实现的。&lt;h4&gt;结论&lt;/h4&gt;MoTE模型通过tacl训练任务专门参数，有效提升了模型生成专门嵌入的能力，同时保持了模型的效率和可扩展性。&lt;h4&gt;翻译&lt;/h4&gt;Dense embeddings are fundamental to modern machine learning systems, powering Retrieval-Augmented Generation (RAG), information retrieval, and representation learning. While instruction-conditioning has become the dominant approach for embedding specialization, its direct application to low-capacity models imposes fundamental representational constraints that limit the performance gains derived from specialization. In this paper, we analyze these limitations and introduce the Mixture of Task Experts (MoTE) transformer block, which leverages task-specialized parameters trained with Task-Aware Contrastive Learning (acl) to enhance the model ability to generate specialized embeddings. Empirical results show that MoTE achieves 64% higher performance gains in retrieval datasets (+3.27 → +5.21) and 43% higher performance gains across all datasets (+1.81 → +2.60). Critically, these gains are achieved without altering instructions, training data, inference time, or number of active parameters.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dense embeddings are fundamental to modern machine learning systems, poweringRetrieval-Augmented Generation (RAG), information retrieval, and representationlearning. While instruction-conditioning has become the dominant approach forembedding specialization, its direct application to low-capacity models imposesfundamental representational constraints that limit the performance gainsderived from specialization. In this paper, we analyze these limitations andintroduce the Mixture of Task Experts (MoTE) transformer block, which leveragestask-specialized parameters trained with Task-Aware Contrastive Learning(\tacl) to enhance the model ability to generate specialized embeddings.Empirical results show that MoTE achieves $64\%$ higher performance gains inretrieval datasets ($+3.27 \rightarrow +5.21$) and $43\%$ higher performancegains across all datasets ($+1.81 \rightarrow +2.60$). Critically, these gainsare achieved without altering instructions, training data, inference time, ornumber of active parameters.</description>
      <author>example@mail.com (Miguel Romero, Shuoyang Ding, Corey D. Barret, Georgiana Dinu, George Karypis)</author>
      <guid isPermaLink="false">2506.17781v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>MCN-SLAM: Multi-Agent Collaborative Neural SLAM with Hybrid Implicit Neural Scene Representation</title>
      <link>http://arxiv.org/abs/2506.18678v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于神经隐式场景表示的分布式多智能体协同SLAM框架，旨在解决现有SLAM算法在大型场景和长序列中的局限性，并提高通信带宽的约束。&lt;h4&gt;背景&lt;/h4&gt;现有的隐式SLAM算法主要适用于单智能体场景，在大型场景和长序列中存在困难，并且基于NeRF的多智能体SLAM框架无法满足通信带宽的约束。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的分布式多智能体协同SLAM框架，以解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;提出了混合场景表示方法、分布式相机跟踪、跨图闭环和在线蒸馏技术，以实现多子图融合。设计了新的三平面网格联合场景表示方法和跨图闭环方法，以及新的在线蒸馏方法，以实现局部和全局一致性。此外，提出了第一个用于NeRF/GS SLAM的真实世界数据集DES，该数据集包括单智能体和多智能体场景，从小型房间到大型户外场景，并提供了高精度的3D网格和连续时间相机轨迹的真实值。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在地图构建、跟踪和通信方面均表现出优越性，数据集和代码将在GitHub上开源。&lt;h4&gt;结论&lt;/h4&gt;本文提出的分布式多智能体协同SLAM框架在解决现有SLAM算法的局限性方面取得了显著成效，并为SLAM、3D重建和视觉基础模型的研究提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;Neural implicit scene representations have recently shown promising results in dense visual SLAM. However, existing implicit SLAM algorithms are constrained to single-agent scenarios, and fall difficulties in large-scale scenes and long sequences. Existing NeRF-based multi-agent SLAM frameworks cannot meet the constraints of communication bandwidth. To this end, we propose the first distributed multi-agent collaborative neural SLAM framework with hybrid scene representation, distributed camera tracking, intra-to-inter loop closure, and online distillation for multiple submap fusion. A novel triplane-grid joint scene representation method is proposed to improve scene reconstruction. A novel intra-to-inter loop closure method is designed to achieve local (single-agent) and global (multi-agent) consistency. We also design a novel online distillation method to fuse the information of different submaps to achieve global consistency. Furthermore, to the best of our knowledge, there is no real-world dataset for NeRF-based/GS-based SLAM that provides both continuous-time trajectories groundtruth and high-accuracy 3D meshes groundtruth. To this end, we propose the first real-world Dense slam (DES) dataset covering both single-agent and multi-agent scenarios, ranging from small rooms to large-scale outdoor scenes, with high-accuracy ground truth for both 3D mesh and continuous-time camera trajectory. This dataset can advance the development of the research in both SLAM, 3D reconstruction, and visual foundation model. Experiments on various datasets demonstrate the superiority of the proposed method in both mapping, tracking, and communication. The dataset and code will open-source on https://github.com/dtc111111/mcnslam.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural implicit scene representations have recently shown promising resultsin dense visual SLAM. However, existing implicit SLAM algorithms areconstrained to single-agent scenarios, and fall difficulties in large-scalescenes and long sequences. Existing NeRF-based multi-agent SLAM frameworkscannot meet the constraints of communication bandwidth. To this end, we proposethe first distributed multi-agent collaborative neural SLAM framework withhybrid scene representation, distributed camera tracking, intra-to-inter loopclosure, and online distillation for multiple submap fusion. A noveltriplane-grid joint scene representation method is proposed to improve scenereconstruction. A novel intra-to-inter loop closure method is designed toachieve local (single-agent) and global (multi-agent) consistency. We alsodesign a novel online distillation method to fuse the information of differentsubmaps to achieve global consistency. Furthermore, to the best of ourknowledge, there is no real-world dataset for NeRF-based/GS-based SLAM thatprovides both continuous-time trajectories groundtruth and high-accuracy 3Dmeshes groundtruth. To this end, we propose the first real-world Dense slam(DES) dataset covering both single-agent and multi-agent scenarios, rangingfrom small rooms to large-scale outdoor scenes, with high-accuracy ground truthfor both 3D mesh and continuous-time camera trajectory. This dataset canadvance the development of the research in both SLAM, 3D reconstruction, andvisual foundation model. Experiments on various datasets demonstrate thesuperiority of the proposed method in both mapping, tracking, andcommunication. The dataset and code will open-source onhttps://github.com/dtc111111/mcnslam.</description>
      <author>example@mail.com (Tianchen Deng, Guole Shen, Xun Chen, Shenghai Yuan, Hongming Shen, Guohao Peng, Zhenyu Wu, Jingchuan Wang, Lihua Xie, Danwei Wang, Hesheng Wang, Weidong Chen)</author>
      <guid isPermaLink="false">2506.18678v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>EgoWorld: Translating Exocentric View to Egocentric View using Rich Exocentric Observations</title>
      <link>http://arxiv.org/abs/2506.17896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://redorangeyellowy.github.io/EgoWorld/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为EgoWorld的新框架，用于将第三人称视角转换为第一人称视角，以增强现实、虚拟现实和机器人应用中的手-物体交互理解。&lt;h4&gt;背景&lt;/h4&gt;自旋心视觉对于人类和机器视觉理解至关重要，尤其是在捕捉操作任务中详细的手-物体交互方面。将第三人称视图转换为第一人称视图对增强现实（AR）、虚拟现实（VR）和机器人应用有显著益处。&lt;h4&gt;目的&lt;/h4&gt;克服现有外心到自心转换方法依赖2D线索、同步多视图设置和不切实际的假设（如初始自心帧和推理期间相对相机姿态的必要性）的局限性。&lt;h4&gt;方法&lt;/h4&gt;EgoWorld是一个两阶段框架，可以从丰富的外心观察中重建自心视图，包括投影点云、3D手姿态和文本描述。该方法从估计的外心深度图中重建点云，将其重新投影到自心视角，然后应用基于扩散的修复技术生成密集、语义上连贯的自心图像。&lt;h4&gt;主要发现&lt;/h4&gt;在H2O和TACO数据集上评估时，EgoWorld实现了最先进的性能，并展示了对新物体、动作、场景和主题的鲁棒泛化能力。此外，EgoWorld在无标签的真实世界示例上也表现出有希望的结果。&lt;h4&gt;结论&lt;/h4&gt;EgoWorld是一个有效的框架，可以显著提升自旋心视觉在增强现实、虚拟现实和机器人应用中的性能，尤其是在处理新的和真实世界场景时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Egocentric vision is essential for both human and machine visualunderstanding, particularly in capturing the detailed hand-object interactionsneeded for manipulation tasks. Translating third-person views into first-personviews significantly benefits augmented reality (AR), virtual reality (VR) androbotics applications. However, current exocentric-to-egocentric translationmethods are limited by their dependence on 2D cues, synchronized multi-viewsettings, and unrealistic assumptions such as necessity of initial egocentricframe and relative camera poses during inference. To overcome these challenges,we introduce EgoWorld, a novel two-stage framework that reconstructs anegocentric view from rich exocentric observations, including projected pointclouds, 3D hand poses, and textual descriptions. Our approach reconstructs apoint cloud from estimated exocentric depth maps, reprojects it into theegocentric perspective, and then applies diffusion-based inpainting to producedense, semantically coherent egocentric images. Evaluated on the H2O and TACOdatasets, EgoWorld achieves state-of-the-art performance and demonstratesrobust generalization to new objects, actions, scenes, and subjects. Moreover,EgoWorld shows promising results even on unlabeled real-world examples.</description>
      <author>example@mail.com (Junho Park, Andrew Sangwoo Ye, Taein Kwon)</author>
      <guid isPermaLink="false">2506.17896v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Feedback Driven Multi Stereo Vision System for Real-Time Event Analysis</title>
      <link>http://arxiv.org/abs/2506.17910v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于3D立体视觉的交互系统处理流程，通过鲁棒的场景理解，能够处理普通和敏感的应用。&lt;h4&gt;背景&lt;/h4&gt;2D相机在交互系统中常用，但3D相机在复杂环境中不够可靠。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够处理多种应用场景的3D立体视觉处理流程。&lt;h4&gt;方法&lt;/h4&gt;融合多个3D相机进行场景重建，并通过可能的反馈方法接收环境中的数据，以改善决策或适应新环境。&lt;h4&gt;主要发现&lt;/h4&gt;系统可以执行事件识别、主体跟踪和通知等多种任务。&lt;h4&gt;结论&lt;/h4&gt;本文介绍了该流程，并初步实验了结果，同时规划了将流程投入生产的下一步步骤。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于3D立体视觉的交互系统处理流程，通过鲁棒的场景理解，能够处理普通和敏感的应用。背景是2D相机在交互系统中常用，但3D相机在复杂环境中不够可靠。目的是提出一种能够处理多种应用场景的3D立体视觉处理流程。方法是通过融合多个3D相机进行场景重建，并通过可能的反馈方法接收环境中的数据，以改善决策或适应新环境。主要发现是系统可以执行事件识别、主体跟踪和通知等多种任务。结论是本文介绍了该流程，并初步实验了结果，同时规划了将流程投入生产的下一步步骤。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3573381.3597220&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 2D cameras are often used in interactive systems. Other systems like gamingconsoles provide more powerful 3D cameras for short range depth sensing.Overall, these cameras are not reliable in large, complex environments. In thiswork, we propose a 3D stereo vision based pipeline for interactive systems,that is able to handle both ordinary and sensitive applications, through robustscene understanding. We explore the fusion of multiple 3D cameras to do fullscene reconstruction, which allows for preforming a wide range of tasks, likeevent recognition, subject tracking, and notification. Using possible feedbackapproaches, the system can receive data from the subjects present in theenvironment, to learn to make better decisions, or to adapt to completely newenvironments. Throughout the paper, we introduce the pipeline and explain ourpreliminary experimentation and results. Finally, we draw the roadmap for thenext steps that need to be taken, in order to get this pipeline into production</description>
      <author>example@mail.com (Mohamed Benkedadra, Matei Mancas, Sidi Ahmed Mahmoudi)</author>
      <guid isPermaLink="false">2506.17910v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Generalizing Vision-Language Models to Novel Domains: A Comprehensive Survey</title>
      <link>http://arxiv.org/abs/2506.18504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇论文综述了视觉语言预训练模型（VLMs）的泛化设置、方法、基准和结果，并对VLMs在跨模态研究中的未来方向进行了探讨。&lt;h4&gt;背景&lt;/h4&gt;视觉语言预训练模型结合了视觉和文本模态的优点，表现出强大的零样本能力，但在面对特定领域或专业泛化任务时性能会下降。&lt;h4&gt;目的&lt;/h4&gt;通过综合总结VLMs的泛化研究，提供对VLMs时代迁移学习（TL）的新解释，并介绍VLMs泛化的流行基准。&lt;h4&gt;方法&lt;/h4&gt;论文将VLMs文献分为基于提示、参数和特征的方法，根据转移模块对每种方法的特点进行总结和讨论，并对不同方法进行性能比较。&lt;h4&gt;主要发现&lt;/h4&gt;VLMs在泛化任务中表现各异，迁移学习在VLMs时代具有新的解释，大型可泛化预训练的发展对VLMs和大型多模态语言模型（MLLMs）的关系产生了影响。&lt;h4&gt;结论&lt;/h4&gt;通过对视觉语言研究的文献进行系统回顾，本综述为当前和未来的多模态研究提供了一个清晰的图景。&lt;h4&gt;翻译&lt;/h4&gt;This paper reviews the generalization settings, methodologies, benchmarking and results in visual language model (VLM) literature, and discusses the future directions of multimodal research in the era of VLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, vision-language pretraining has emerged as a transformativetechnique that integrates the strengths of both visual and textual modalities,resulting in powerful vision-language models (VLMs). Leveraging web-scalepretraining data, these models exhibit strong zero-shot capabilities. However,their performance often deteriorates when confronted with domain-specific orspecialized generalization tasks. To address this, a growing body of researchfocuses on transferring or generalizing the rich knowledge embedded in VLMs tovarious downstream applications. This survey aims to comprehensively summarizethe generalization settings, methodologies, benchmarking and results in VLMliteratures. Delving into the typical VLM structures, current literatures arecategorized into prompt-based, parameter-based and feature-based methodsaccording to the transferred modules. The differences and characteristics ineach category are furthered summarized and discussed by revisiting the typicaltransfer learning (TL) settings, providing novel interpretations for TL in theera of VLMs. Popular benchmarks for VLM generalization are further introducedwith thorough performance comparisons among the reviewed methods. Following theadvances in large-scale generalizable pretraining, this survey also discussesthe relations and differences between VLMs and up-to-date multimodal largelanguage models (MLLM), e.g., DeepSeek-VL. By systematically reviewing thesurging literatures in vision-language research from a novel and practicalgeneralization prospective, this survey contributes to a clear landscape ofcurrent and future multimodal researches.</description>
      <author>example@mail.com (Xinyao Li, Jingjing Li, Fengling Li, Lei Zhu, Yang Yang, Heng Tao Shen)</author>
      <guid isPermaLink="false">2506.18504v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>DreamJourney: Perpetual View Generation with Video Diffusion Models</title>
      <link>http://arxiv.org/abs/2506.17705v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DreamJourney是一个用于生成长期视频的框架，能够从单张输入图像中合成对应任意相机轨迹的视频。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常使用预训练的文本到图像扩散模型来合成相机移动过程中未见区域的图像，但这些方法缺乏三维感知，导致扭曲的伪影，并且仅限于生成静态三维场景的视图。&lt;h4&gt;目的&lt;/h4&gt;提出DreamJourney框架，以解决上述问题，实现既包含相机移动又包含物体动态的永久场景视图生成。&lt;h4&gt;方法&lt;/h4&gt;DreamJourney分为两个阶段：阶段I将输入图像提升为3D点云，并从特定相机轨迹渲染一系列部分图像，然后使用视频扩散模型生成缺失区域并增强序列的视觉连贯性；阶段II使用多模态大型语言模型生成描述当前视图物体运动的文本提示，并使用视频扩散模型使当前视图动画化。两个阶段循环进行。&lt;h4&gt;主要发现&lt;/h4&gt;DreamJourney在定性和定量实验中均优于现有方法，实现了高质量的动态场景视图生成。&lt;h4&gt;结论&lt;/h4&gt;DreamJourney能够有效生成高质量的动态场景视频，具有潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Perpetual view generation aims to synthesize a long-term video correspondingto an arbitrary camera trajectory solely from a single input image. Recentmethods commonly utilize a pre-trained text-to-image diffusion model tosynthesize new content of previously unseen regions along camera movement.However, the underlying 2D diffusion model lacks 3D awareness and results indistorted artifacts. Moreover, they are limited to generating views of static3D scenes, neglecting to capture object movements within the dynamic 4D world.To alleviate these issues, we present DreamJourney, a two-stage framework thatleverages the world simulation capacity of video diffusion models to trigger anew perpetual scene view generation task with both camera movements and objectdynamics. Specifically, in stage I, DreamJourney first lifts the input image to3D point cloud and renders a sequence of partial images from a specific cameratrajectory. A video diffusion model is then utilized as generative prior tocomplete the missing regions and enhance visual coherence across the sequence,producing a cross-view consistent video adheres to the 3D scene and cameratrajectory. Meanwhile, we introduce two simple yet effective strategies (earlystopping and view padding) to further stabilize the generation process andimprove visual quality. Next, in stage II, DreamJourney leverages a multimodallarge language model to produce a text prompt describing object movements incurrent view, and uses video diffusion model to animate current view withobject movements. Stage I and II are repeated recurrently, enabling perpetualdynamic scene view generation. Extensive experiments demonstrate thesuperiority of our DreamJourney over state-of-the-art methods bothquantitatively and qualitatively. Our project page:https://dream-journey.vercel.app.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Perpetual view generation aims to synthesize a long-term video correspondingto an arbitrary camera trajectory solely from a single input image. Recentmethods commonly utilize a pre-trained text-to-image diffusion model tosynthesize new content of previously unseen regions along camera movement.However, the underlying 2D diffusion model lacks 3D awareness and results indistorted artifacts. Moreover, they are limited to generating views of static3D scenes, neglecting to capture object movements within the dynamic 4D world.To alleviate these issues, we present DreamJourney, a two-stage framework thatleverages the world simulation capacity of video diffusion models to trigger anew perpetual scene view generation task with both camera movements and objectdynamics. Specifically, in stage I, DreamJourney first lifts the input image to3D point cloud and renders a sequence of partial images from a specific cameratrajectory. A video diffusion model is then utilized as generative prior tocomplete the missing regions and enhance visual coherence across the sequence,producing a cross-view consistent video adheres to the 3D scene and cameratrajectory. Meanwhile, we introduce two simple yet effective strategies (earlystopping and view padding) to further stabilize the generation process andimprove visual quality. Next, in stage II, DreamJourney leverages a multimodallarge language model to produce a text prompt describing object movements incurrent view, and uses video diffusion model to animate current view withobject movements. Stage I and II are repeated recurrently, enabling perpetualdynamic scene view generation. Extensive experiments demonstrate thesuperiority of our DreamJourney over state-of-the-art methods bothquantitatively and qualitatively. Our project page:https://dream-journey.vercel.app.</description>
      <author>example@mail.com (Bo Pan, Yang Chen, Yingwei Pan, Ting Yao, Wei Chen, Tao Mei)</author>
      <guid isPermaLink="false">2506.17705v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>PERSCEN: Learning Personalized Interaction Pattern and Scenario Preference for Multi-Scenario Matching</title>
      <link>http://arxiv.org/abs/2506.18382v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PERSCEN的创新方法，用于多场景匹配，旨在减少维护成本和缓解数据稀疏性问题。&lt;h4&gt;背景&lt;/h4&gt;随着在线平台上商业规模和范围的扩大，多场景匹配已成为主流解决方案。&lt;h4&gt;目的&lt;/h4&gt;有效多场景推荐的关键在于捕捉用户在所有场景中共享的偏好以及特定于每个场景的场景感知偏好。&lt;h4&gt;方法&lt;/h4&gt;PERSCEN通过结合用户特定建模进行多场景匹配，构建基于用户特征的用户特定特征图，并使用轻量级图神经网络来捕捉高阶交互模式，从而实现跨场景偏好的个性化提取。此外，通过向量量化技术从用户在单个场景内的行为序列中提炼场景感知偏好，促进用户特定和场景感知偏好建模。为了提高信息传输的效率和灵活性，引入了渐进式场景感知门控线性单元，以实现细粒度、低延迟的融合。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，PERSCEN优于现有方法。进一步的效率分析证实，PERSCEN在性能和计算成本之间实现了有效平衡，确保其实际适用于现实世界的工业系统。&lt;h4&gt;结论&lt;/h4&gt;PERSCEN是一种高效且实用的多场景匹配方法，能够有效解决数据稀疏性问题，并在实际工业系统中具有应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737079&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the expansion of business scales and scopes on online platforms,multi-scenario matching has become a mainstream solution to reduce maintenancecosts and alleviate data sparsity. The key to effective multi-scenariorecommendation lies in capturing both user preferences shared across allscenarios and scenario-aware preferences specific to each scenario. However,existing methods often overlook user-specific modeling, limiting the generationof personalized user representations. To address this, we propose PERSCEN, aninnovative approach that incorporates user-specific modeling intomulti-scenario matching. PERSCEN constructs a user-specific feature graph basedon user characteristics and employs a lightweight graph neural network tocapture higher-order interaction patterns, enabling personalized extraction ofpreferences shared across scenarios. Additionally, we leverage vectorquantization techniques to distil scenario-aware preferences from users'behavior sequence within individual scenarios, facilitating user-specific andscenario-aware preference modeling. To enhance efficient and flexibleinformation transfer, we introduce a progressive scenario-aware gated linearunit that allows fine-grained, low-latency fusion. Extensive experimentsdemonstrate that PERSCEN outperforms existing methods. Further efficiencyanalysis confirms that PERSCEN effectively balances performance withcomputational cost, ensuring its practicality for real-world industrialsystems.</description>
      <author>example@mail.com (Haotong Du, Yaqing Wang, Fei Xiong, Lei Shao, Ming Liu, Hao Gu, Quanming Yao, Zhen Wang)</author>
      <guid isPermaLink="false">2506.18382v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>SSAVSV: Towards Unified Model for Self-Supervised Audio-Visual Speaker Verification</title>
      <link>http://arxiv.org/abs/2506.17694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于对比学习的自监督学习框架，用于音频视觉说话人验证，旨在解决传统方法依赖大量标注数据和独立模态架构的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的音频视觉说话人验证方法需要大量标注数据，且采用独立的模态特定架构，这导致计算成本高，限制了其可扩展性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以减少对大量标注数据的依赖，并降低计算成本，同时保持性能。&lt;h4&gt;方法&lt;/h4&gt;采用基于对比学习的自监督学习框架，结合非对称掩码和掩码数据建模，以获得鲁棒的音频视觉特征表示。使用统一的框架进行自监督音频视觉说话人验证，通过单个共享的骨干网络处理音频和视觉输入，利用视觉Transformer的灵活性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在不使用标注数据的情况下实现了与传统方法相竞争的性能，同时降低了计算成本。&lt;h4&gt;结论&lt;/h4&gt;该统一框架在处理音频、视觉或音频视觉输入时，使用单个共享的视觉Transformer骨干网络进行训练和测试，既计算高效又对缺失的模态具有鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conventional audio-visual methods for speaker verification rely on largeamounts of labeled data and separate modality-specific architectures, which iscomputationally expensive, limiting their scalability. To address theseproblems, we propose a self-supervised learning framework based on contrastivelearning with asymmetric masking and masked data modeling to obtain robustaudiovisual feature representations. In particular, we employ a unifiedframework for self-supervised audiovisual speaker verification using a singleshared backbone for audio and visual inputs, leveraging the versatility ofvision transformers. The proposed unified framework can handle audio, visual,or audiovisual inputs using a single shared vision transformer backbone duringtraining and testing while being computationally efficient and robust tomissing modalities. Extensive experiments demonstrate that our method achievescompetitive performance without labeled data while reducing computational costscompared to traditional approaches.</description>
      <author>example@mail.com (Gnana Praveen Rajasekhar, Jahangir Alam)</author>
      <guid isPermaLink="false">2506.17694v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Memba: Membrane-driven Parameter-Efficient Fine-Tuning for Mamba</title>
      <link>http://arxiv.org/abs/2506.18184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Memba的参数高效微调（PEFT）方法，专门用于Mamba模型，以提升其时序建模能力。&lt;h4&gt;背景&lt;/h4&gt;随着状态空间模型（SSMs）的增长，需要参数高效的微调方法来适应下游任务，同时避免高昂的计算成本。&lt;h4&gt;目的&lt;/h4&gt;设计一种适用于Mamba的PEFT方法，以增强其时序建模能力。&lt;h4&gt;方法&lt;/h4&gt;Memba方法引入了漏导积分膜（LIM）神经元作为生物启发的门控机制，结合低秩调整（LoRA）和跨层膜传递技术。&lt;h4&gt;主要发现&lt;/h4&gt;Memba在语言和视觉任务上相较于现有PEFT方法实现了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;Memba是一个有效的PEFT方法，可以显著提高Mamba模型在时序建模任务上的性能。&lt;h4&gt;翻译&lt;/h4&gt;State Space Models (SSMs) have emerged as powerful alternatives to attention-based Transformers, with Mamba demonstrating impressive efficiency and scalability. As these models grow increasingly larger, the need for Parameter-Efficient Fine-Tuning (PEFT) methods becomes critical to adapt pre-trained Mamba to downstream tasks without prohibitive computational costs. However, previous approaches simply apply traditional Transformer-tailored PEFT methods without addressing the unique temporal processing dynamics of SSMs. To address this limitation, we propose Memba, a membrane-driven PEFT approach specifically designed for Mamba. Memba introduces Leaky Integrate Membrane (LIM) neurons as bio-inspired gating mechanisms that naturally accumulate membrane potentials over time, enhancing selective information retention. By strategically combining LIM neurons with Low-Rank Adaptations (LoRA) and cross-layer membrane transfer, our approach significantly improves Mamba's temporal modeling capabilities. Extensive experiments across language and vision tasks demonstrate that Memba achieves substantial improvements over existing PEFT methods. The code is available at https://github.com/Intelligent-Computing-Lab-Yale/Memba.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State Space Models (SSMs) have emerged as powerful alternatives toattention-based Transformers, with Mamba demonstrating impressive efficiencyand scalability. As these models grow increasingly larger, the need forParameter-Efficient Fine-Tuning (PEFT) methods becomes critical to adaptpre-trained Mamba to downstream tasks without prohibitive computational costs.However, previous approaches simply apply traditional Transformer-tailored PEFTmethods without addressing the unique temporal processing dynamics of SSMs. Toaddress this limitation, we propose Memba, a membrane-driven PEFT approachspecifically designed for Mamba. Memba introduces Leaky Integrate Membrane(LIM) neurons as bio-inspired gating mechanisms that naturally accumulatemembrane potentials over time, enhancing selective information retention. Bystrategically combining LIM neurons with Low-Rank Adaptations (LoRA) andcross-layer membrane transfer, our approach significantly improves Mamba'stemporal modeling capabilities. Extensive experiments across language andvision tasks demonstrate that Memba achieves substantial improvements overexisting PEFT methods. The code is available athttps://github.com/Intelligent-Computing-Lab-Yale/Memba.</description>
      <author>example@mail.com (Donghyun Lee, Yuhang Li, Ruokai Yin, Shiting Xiao, Priyadarshini Panda)</author>
      <guid isPermaLink="false">2506.18184v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Robot Tactile Gesture Recognition Based on Full-body Modular E-skin</title>
      <link>http://arxiv.org/abs/2506.18256v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了机器人电子皮肤技术的发展及其在触觉感知方面的应用，通过开发一种模块化机器人电子皮肤，实现了对触觉手势的识别和解读，进而实现人与机器人之间的直观交互。&lt;h4&gt;背景&lt;/h4&gt;随着机器人电子皮肤技术的进步，结合人工智能的触觉传感器为机器人开启了一个新的感知维度。&lt;h4&gt;目的&lt;/h4&gt;研究装备电子皮肤的机器人如何识别触觉手势并将这些手势解释为人类命令。&lt;h4&gt;方法&lt;/h4&gt;开发了一种由多个不规则形状的皮肤片组成的模块化机器人电子皮肤，可以组装覆盖机器人的身体，并从数千个传感点实时捕捉压力和姿态数据。为了处理这些信息，提出了一种基于等变图神经网络的识别器，该识别器能够高效且准确地分类多种触觉手势。&lt;h4&gt;主要发现&lt;/h4&gt;识别器能够识别包括戳、抓、抚摸和双拍等多种触觉手势，并通过将识别的手势映射到预定义的机器人动作，实现了仅通过触觉输入的人机交互。&lt;h4&gt;结论&lt;/h4&gt;通过触觉输入实现直观的人机交互，为机器人感知和交互能力提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;With the development of robot electronic skin technology, various tactilesensors, enhanced by AI, are unlocking a new dimension of perception forrobots. In this work, we explore how robots equipped with electronic skin canrecognize tactile gestures and interpret them as human commands. We developed amodular robot E-skin, composed of multiple irregularly shaped skin patches,which can be assembled to cover the robot's body while capturing real-timepressure and pose data from thousands of sensing points. To process thisinformation, we propose an equivariant graph neural network-based recognizerthat efficiently and accurately classifies diverse tactile gestures, includingpoke, grab, stroke, and double-pat. By mapping the recognized gestures topredefined robot actions, we enable intuitive human-robot interaction purelythrough tactile input.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the development of robot electronic skin technology, various tactilesensors, enhanced by AI, are unlocking a new dimension of perception forrobots. In this work, we explore how robots equipped with electronic skin canrecognize tactile gestures and interpret them as human commands. We developed amodular robot E-skin, composed of multiple irregularly shaped skin patches,which can be assembled to cover the robot's body while capturing real-timepressure and pose data from thousands of sensing points. To process thisinformation, we propose an equivariant graph neural network-based recognizerthat efficiently and accurately classifies diverse tactile gestures, includingpoke, grab, stroke, and double-pat. By mapping the recognized gestures topredefined robot actions, we enable intuitive human-robot interaction purelythrough tactile input.</description>
      <author>example@mail.com (Shuo Jiang, Boce Hu, Linfeng Zhao, Lawson L. S. Wong)</author>
      <guid isPermaLink="false">2506.18256v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Optimization-Free Patch Attack on Stereo Depth Estimation</title>
      <link>http://arxiv.org/abs/2506.17632v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了立体深度估计（SDE）在视觉系统中的应用，特别是针对自动驾驶等场景。文章提出了一种新的攻击框架，用于对抗SDE模型，并验证了其在现实条件下的有效性。&lt;h4&gt;背景&lt;/h4&gt;SDE模型在自动驾驶等视觉系统中至关重要，但易受对抗攻击影响，现有攻击方法通常在非现实场景中测试，限制了其应用。&lt;h4&gt;目的&lt;/h4&gt;设计物理可实现、场景自适应且可迁移的SDE对抗攻击。&lt;h4&gt;方法&lt;/h4&gt;提出一个统一的攻击框架，将基于优化的技术扩展到立体匹配的四个核心阶段：特征提取、成本体构建、成本聚合和视差回归。引入PatchHunter，一种无优化对抗补丁攻击，通过强化学习在视觉模式空间中搜索破坏SDE假设的模式。&lt;h4&gt;主要发现&lt;/h4&gt;基于优化的补丁在迁移性方面表现不佳，而部分可迁移的补丁表明模式而非像素级扰动可能是通用攻击的关键。PatchHunter在KITTI数据集、CARLA模拟器和真实世界车辆部署中均有效，且在低光等挑战性物理条件下保持高攻击成功率。&lt;h4&gt;结论&lt;/h4&gt;PatchHunter在攻击效果和黑盒迁移性方面优于基于优化的方法，为SDE模型的对抗攻击提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stereo Depth Estimation (SDE) is essential for scene understanding invision-based systems like autonomous driving. However, recent studies show thatSDE models are vulnerable to adversarial attacks, which are often limited tounrealistic settings, e.g., digital perturbations on separate stereo views instatic scenes, restricting their real-world applicability. This raises acritical question: how can we design physically realizable, scene-adaptive, andtransferable attacks against SDE under realistic constraints?  To answer this, we make two key contributions. First, we propose a unifiedattack framework that extends optimization-based techniques to four core stagesof stereo matching: feature extraction, cost-volume construction, costaggregation, and disparity regression. A comprehensive stage-wise evaluationacross 9 mainstream SDE models, under constraints like photometric consistency,reveals that optimization-based patches suffer from poor transferability.Interestingly, partially transferable patches suggest that patterns, ratherthan pixel-level perturbations, may be key to generalizable attacks. Motivatedby this, we present PatchHunter, the first optimization-free adversarial patchattack against SDE. PatchHunter formulates patch generation as a reinforcementlearning-driven search over a structured space of visual patterns crafted todisrupt SDE assumptions.  We validate PatchHunter across three levels: the KITTI dataset, the CARLAsimulator, and real-world vehicle deployment. PatchHunter not only surpassesoptimization-based methods in effectiveness but also achieves significantlybetter black-box transferability. Even under challenging physical conditionslike low light, PatchHunter maintains high attack success (e.g., D1-all &gt; 0.4),whereas optimization-based methods fail.</description>
      <author>example@mail.com (Hangcheng Liu, Xu Kuang, Xingshuo Han, Xingwan Wu, Haoran Ou, Shangwei Guo, Xingyi Huang, Tao Xiang, Tianwei Zhang)</author>
      <guid isPermaLink="false">2506.17632v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Learning Time-Aware Causal Representation for Model Generalization in Evolving Domains</title>
      <link>http://arxiv.org/abs/2506.17718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SYNC的时间感知结构因果模型，旨在解决动态场景下深度模型的泛化问题。&lt;h4&gt;背景&lt;/h4&gt;随着数据分布的持续变化，赋予深度模型在动态场景中泛化的能力对于实际部署至关重要。&lt;h4&gt;目的&lt;/h4&gt;针对现有演化域泛化方法可能存在的伪相关性问题，旨在设计一种能够有效学习时间感知因果表示的方法。&lt;h4&gt;方法&lt;/h4&gt;设计了一种时间感知结构因果模型，该模型结合了动态因果因素和因果机制漂移，并提出了SYNC方法，该方法通过将特别设计的信息论目标整合到序列变分自编码器框架中，捕捉演化模式，并通过保持因果因素在域内和域间的类内紧凑性来产生所需的表示。&lt;h4&gt;主要发现&lt;/h4&gt;理论证明了该方法可以针对每个时间域产生最优的因果预测器。在合成和真实世界数据集上的结果表明，SYNC可以实现卓越的时间泛化性能。&lt;h4&gt;结论&lt;/h4&gt;SYNC方法能够有效提高深度模型在动态场景下的泛化能力，为实际应用提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Endowing deep models with the ability to generalize in dynamic scenarios isof vital significance for real-world deployment, given the continuous andcomplex changes in data distribution. Recently, evolving domain generalization(EDG) has emerged to address distribution shifts over time, aiming to captureevolving patterns for improved model generalization. However, existing EDGmethods may suffer from spurious correlations by modeling only the dependencebetween data and targets across domains, creating a shortcut betweentask-irrelevant factors and the target, which hinders generalization. To thisend, we design a time-aware structural causal model (SCM) that incorporatesdynamic causal factors and the causal mechanism drifts, and propose\textbf{S}tatic-D\textbf{YN}amic \textbf{C}ausal Representation Learning(\textbf{SYNC}), an approach that effectively learns time-aware causalrepresentations. Specifically, it integrates specially designedinformation-theoretic objectives into a sequential VAE framework which capturesevolving patterns, and produces the desired representations by preservingintra-class compactness of causal factors both across and within domains.Moreover, we theoretically show that our method can yield the optimal causalpredictor for each time domain. Results on both synthetic and real-worlddatasets exhibit that SYNC can achieve superior temporal generalizationperformance.</description>
      <author>example@mail.com (Zhuo He, Shuang Li, Wenze Song, Longhui Yuan, Jian Liang, Han Li, Kun Gai)</author>
      <guid isPermaLink="false">2506.17718v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>End-to-End Spoken Grammatical Error Correction</title>
      <link>http://arxiv.org/abs/2506.18532v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了语音错误纠正（SGEC）和反馈在支持第二语言学习者、教育者和考官中的重要作用，并提出了一个端到端（E2E）框架来解决SGEC和反馈生成中的挑战。&lt;h4&gt;背景&lt;/h4&gt;SGEC系统通常包括自动语音识别（ASR）、停顿检测和GEC模块，这些模块之间的错误传播使其容易出错。&lt;h4&gt;目的&lt;/h4&gt;研究E2E框架在SGEC和反馈生成中的应用，并比较级联、部分级联和E2E架构。&lt;h4&gt;方法&lt;/h4&gt;使用了Whisper基础模型，并提出了自动伪标记框架来增加训练数据。为了提高SGEC系统的准确性，研究了利用ASR输出的上下文信息，并提出了一个新的参考对齐过程来提高反馈的精确度。&lt;h4&gt;主要发现&lt;/h4&gt;E2E系统面临GEC标记的语音数据稀缺的问题，通过自动伪标记框架增加了训练数据量。提出的参考对齐过程和编辑置信度估计方法显著提高了E2E SGEC的性能。&lt;h4&gt;结论&lt;/h4&gt;在内部Linguaskill（LNG）语料库和公开的Speak &amp; Improve（S&amp;I）语料库上的实验表明，所提出的方法显著提高了E2E SGEC的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grammatical Error Correction (GEC) and feedback play a vital role insupporting second language (L2) learners, educators, and examiners. Whilewritten GEC is well-established, spoken GEC (SGEC), aiming to provide feedbackbased on learners' speech, poses additional challenges due to disfluencies,transcription errors, and the lack of structured input. SGEC systems typicallyfollow a cascaded pipeline consisting of Automatic Speech Recognition (ASR),disfluency detection, and GEC, making them vulnerable to error propagationacross modules. This work examines an End-to-End (E2E) framework for SGEC andfeedback generation, highlighting challenges and possible solutions whendeveloping these systems. Cascaded, partial-cascaded and E2E architectures arecompared, all built on the Whisper foundation model. A challenge for E2Esystems is the scarcity of GEC labeled spoken data. To address this, anautomatic pseudo-labeling framework is examined, increasing the training datafrom 77 to over 2500 hours. To improve the accuracy of the SGEC system,additional contextual information, exploiting the ASR output, is investigated.Candidate feedback of their mistakes is an essential step to improvingperformance. In E2E systems the SGEC output must be compared with an estimateof the fluent transcription to obtain the feedback. To improve the precision ofthis feedback, a novel reference alignment process is proposed that aims toremove hypothesised edits that results from fluent transcription errors.Finally, these approaches are combined with an edit confidence estimationapproach, to exclude low-confidence edits. Experiments on the in-houseLinguaskill (LNG) corpora and the publicly available Speak &amp; Improve (S&amp;I)corpus show that the proposed approaches significantly boost E2E SGECperformance.</description>
      <author>example@mail.com (Mengjie Qian, Rao Ma, Stefano Bannò, Mark J. F. Gales, Kate M. Knill)</author>
      <guid isPermaLink="false">2506.18532v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging neural network interatomic potentials for a foundation model of chemistry</title>
      <link>http://arxiv.org/abs/2506.18497v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HackNIP的两阶段管道，用于处理大规模基础模型，如计算材料科学中的神经网络原子间势（NIPs），以解决其预测电子性质和宏观性质时的挑战。&lt;h4&gt;背景&lt;/h4&gt;尽管NIPs在加速原子模拟方面取得了成功，但它们在直接预测电子性质方面面临挑战，通常需要与更高尺度的模型或进行大量模拟来预测宏观性质。&lt;h4&gt;目的&lt;/h4&gt;旨在通过结合机器学习（ML）方法，解决NIPs在预测电子性质和宏观性质时的局限性，并提高数据效率和性能。&lt;h4&gt;方法&lt;/h4&gt;HackNIP方法首先从NIP基础模型中提取固定长度的特征向量（嵌入），然后使用这些嵌入来训练浅层ML模型进行下游的结构到性质的预测。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，通过“黑客”NIP的混合方法可以超越端到端的深度神经网络，确定了在哪个数据集大小下这种迁移学习方法优于直接微调NIP，并确定了哪种NIP嵌入深度产生了最有信息量的特征。&lt;h4&gt;结论&lt;/h4&gt;HackNIP在Matbench上进行了基准测试，评估了数据效率，并在包括从头计算、实验和分子性质在内的多种任务上进行了测试。该研究证明了在材料科学中克服ML权衡的混合策略，旨在使高性能预测建模民主化。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大规模基础模型，包括计算材料科学中的神经网络原子间势（NIPs），已经显示出巨大的潜力。然而，尽管它们在加速原子模拟方面取得了成功，但NIPs在直接预测电子性质方面面临挑战，通常需要与更高尺度的模型或进行大量模拟来预测宏观性质。机器学习（ML）为结构到性质的映射提供了替代方案，但存在权衡：基于特征的方法往往缺乏泛化性，而深度神经网络需要大量的数据和计算能力。为了解决这些权衡，我们引入了HackNIP，这是一种利用预训练NIPs的两阶段管道。这种方法首先从NIP基础模型中提取固定长度的特征向量（嵌入），然后使用这些嵌入来训练浅层ML模型进行下游的结构到性质的预测。本研究调查了这种混合方法，通过“黑客”NIP，是否可以超越端到端的深度神经网络，确定了这种迁移学习方法超越直接微调NIP的数据集大小，并确定了哪种NIP嵌入深度产生了最有信息量的特征。HackNIP在Matbench上进行了基准测试，评估了数据效率，并在包括从头计算、实验和分子性质在内的多种任务上进行了测试。我们还分析了嵌入深度对性能的影响。这项工作证明了在材料科学中克服ML权衡的混合策略，旨在使高性能预测建模民主化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale foundation models, including neural network interatomicpotentials (NIPs) in computational materials science, have demonstratedsignificant potential. However, despite their success in accelerating atomisticsimulations, NIPs face challenges in directly predicting electronic propertiesand often require coupling to higher-scale models or extensive simulations formacroscopic properties. Machine learning (ML) offers alternatives forstructure-to-property mapping but faces trade-offs: feature-based methods oftenlack generalizability, while deep neural networks require significant data andcomputational power. To address these trade-offs, we introduce HackNIP, atwo-stage pipeline that leverages pretrained NIPs. This method first extractsfixed-length feature vectors (embeddings) from NIP foundation models and thenuses these embeddings to train shallow ML models for downstreamstructure-to-property predictions. This study investigates whether such ahybridization approach, by ``hacking" the NIP, can outperform end-to-end deepneural networks, determines the dataset size at which this transfer learningapproach surpasses direct fine-tuning of the NIP, and identifies which NIPembedding depths yield the most informative features. HackNIP is benchmarked onMatbench, evaluated for data efficiency, and tested on diverse tasks including\textit{ab initio}, experimental, and molecular properties. We also analyze howembedding depth impacts performance. This work demonstrates a hybridizationstrategy to overcome ML trade-offs in materials science, aiming to democratizehigh-performance predictive modeling.</description>
      <author>example@mail.com (So Yeon Kim, Yang Jeong Park, Ju Li)</author>
      <guid isPermaLink="false">2506.18497v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Scene-R1: Video-Grounded Large Language Models for 3D Scene Reasoning without 3D Annotations</title>
      <link>http://arxiv.org/abs/2506.17545v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Scene-R1的视频基础框架，用于理解3D场景，通过结合强化学习驱动的推理和两阶段地面管道，实现无点状3D实例监督的学习。&lt;h4&gt;背景&lt;/h4&gt;目前，使用大型语言模型来理解3D世界越来越受欢迎，但现有的3D感知LLM作为黑盒，输出边界框或文本答案而不透露决策过程，并且仍然依赖于预训练的3D检测器来提供对象提议。&lt;h4&gt;目的&lt;/h4&gt;提出Scene-R1框架，旨在通过强化学习驱动的推理和两阶段地面管道，学习对3D场景进行推理，无需任何点状3D实例监督。&lt;h4&gt;方法&lt;/h4&gt;在时间地面阶段，通过视频推理并选择与开放性问题最相关的视频片段。在随后的图像地面阶段，分析图像并预测2D边界框。之后，使用SAM2跟踪对象，在RGB帧中产生像素级精确的掩码，并将它们投影回3D，从而消除基于3D检测器的提议需求，同时捕捉精细的几何和材料线索。&lt;h4&gt;主要发现&lt;/h4&gt;Scene-R1可以在3D视觉问答任务中适应，直接从视频中回答自由形式的提问。训练过程只需要任务级别的2D框或文本标签，无需密集的3D点状标签。Scene-R1在多个数据集上超越了现有的开放词汇基线，同时提供了透明的、逐步的推理过程。&lt;h4&gt;结论&lt;/h4&gt;基于强化学习的推理与RGB-D视频的结合，提供了一种实用、标注高效的可靠3D场景理解途径。&lt;h4&gt;翻译&lt;/h4&gt;目前，利用大型语言模型来理解3D世界变得越来越流行。然而，现有的3D感知LLM作为黑盒，输出边界框或文本答案而不透露决策过程，并且仍然依赖于预训练的3D检测器来提供对象提议。我们引入了Scene-R1，一个视频基础的框架，通过将强化学习驱动的推理与一个两阶段地面管道相结合，学习在没有任何点状3D实例监督的情况下对3D场景进行推理。在时间地面阶段，我们明确地对视频进行推理，并选择与开放性问题最相关的视频片段。在随后的图像地面阶段，我们分析图像并预测2D边界框。之后，我们使用SAM2跟踪对象，在RGB帧中产生像素级精确的掩码，并将它们投影回3D，从而消除了基于3D检测器的提议需求，同时捕捉到了精细的几何和材料线索。Scene-R1还可以适应3D视觉问答任务，直接从视频中回答自由形式的提问。我们的训练流程只需要任务级别的2D框或文本标签，而不需要密集的3D点状标签。Scene-R1在多个数据集上超越了现有的开放词汇基线，同时提供了透明的、逐步的推理过程。这些结果表明，基于强化学习的推理与RGB-D视频的结合，提供了一种实用、标注高效的可靠3D场景理解途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Currently, utilizing large language models to understand the 3D world isbecoming popular. Yet existing 3D-aware LLMs act as black boxes: they outputbounding boxes or textual answers without revealing how those decisions aremade, and they still rely on pre-trained 3D detectors to supply objectproposals. We introduce Scene-R1, a video-grounded framework that learns toreason about 3D scenes without any point-wise 3D instance supervision bypairing reinforcement-learning-driven reasoning with a two-stage groundingpipeline. In the temporal grounding stage, we explicitly reason about the videoand select the video snippets most relevant to an open-ended query. In thesubsequent image grounding stage, we analyze the image and predict the 2Dbounding box. After that, we track the object using SAM2 to producepixel-accurate masks in RGB frames, and project them back into 3D, therebyeliminating the need for 3D detector-based proposals while capturing finegeometry and material cues. Scene-R1 can also adapt to the 3D visual questionanswering task to answer free-form questions directly from video. Our trainingpipeline only needs task-level 2D boxes or textual labels without dense 3Dpoint-wise labels. Scene-R1 surpasses existing open-vocabulary baselines onmultiple datasets, while delivering transparent, step-by-step rationales. Theseresults show that reinforcement-learning-based reasoning combined with RGB-Dvideo alone offers a practical, annotation-efficient route to trustworthy 3Dscene understanding.</description>
      <author>example@mail.com (Zhihao Yuan, Shuyi Jiang, Chun-Mei Feng, Yaolun Zhang, Shuguang Cui, Zhen Li, Na Zhao)</author>
      <guid isPermaLink="false">2506.17545v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>A workflow for generating synthetic LiDAR datasets in simulation environments</title>
      <link>http://arxiv.org/abs/2506.17378v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种生成合成LiDAR数据集的仿真工作流程，以支持自动驾驶车辆的感知、机器人研究和传感器安全性分析。&lt;h4&gt;背景&lt;/h4&gt;利用CoppeliaSim仿真环境和其Python API，将飞行时间LiDAR、图像传感器和二维扫描仪集成到一个模拟车辆平台上，该平台在城市场景中运行。&lt;h4&gt;目的&lt;/h4&gt;自动化数据捕捉、存储和注释，以生成包含地面真实位姿信息的同步多模态数据集。&lt;h4&gt;方法&lt;/h4&gt;通过生成大规模点云和相应的RGB和深度图像来验证该流程。研究还探讨了LiDAR数据中的潜在安全漏洞，如对抗性点注入和欺骗攻击，并展示了合成数据集如何有助于评估防御策略。&lt;h4&gt;主要发现&lt;/h4&gt;讨论了与环境真实感、传感器噪声建模和计算可扩展性相关的限制，并提出了未来研究方向，如融入天气效应、现实世界地形模型和高级扫描配置。&lt;h4&gt;结论&lt;/h4&gt;该工作流程为生成高保真合成LiDAR数据集提供了一个通用、可重复的框架，以推进感知研究并加强自动驾驶系统中的传感器安全性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种用于生成合成LiDAR数据集的仿真工作流程，旨在支持自动驾驶车辆的感知、机器人研究和传感器安全性分析。通过利用CoppeliaSim仿真环境和Python API，将飞行时间LiDAR、图像传感器和二维扫描仪集成到一个模拟车辆平台上，该平台在城市场景中运行。该工作流程自动化数据捕捉、存储和注释，生成包含地面真实位姿信息的同步多模态数据集。通过生成大规模点云和相应的RGB和深度图像验证该流程。研究还探讨了LiDAR数据中的潜在安全漏洞，如对抗性点注入和欺骗攻击，并展示了合成数据集如何有助于评估防御策略。讨论了与环境真实感、传感器噪声建模和计算可扩展性相关的限制，并提出了未来研究方向，如融入天气效应、现实世界地形模型和高级扫描配置。该工作流程为生成高保真合成LiDAR数据集提供了一个通用、可重复的框架，以推进感知研究并加强自动驾驶系统中的传感器安全性。该框架附带文档和示例；动画云回波和图像传感器数据的样本可在链接中找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a simulation workflow for generating synthetic LiDARdatasets to support autonomous vehicle perception, robotics research, andsensor security analysis. Leveraging the CoppeliaSim simulation environment andits Python API, we integrate time-of-flight LiDAR, image sensors, and twodimensional scanners onto a simulated vehicle platform operating within anurban scenario. The workflow automates data capture, storage, and annotationacross multiple formats (PCD, PLY, CSV), producing synchronized multimodaldatasets with ground truth pose information. We validate the pipeline bygenerating large-scale point clouds and corresponding RGB and depth imagery.The study examines potential security vulnerabilities in LiDAR data, such asadversarial point injection and spoofing attacks, and demonstrates howsynthetic datasets can facilitate the evaluation of defense strategies.Finally, limitations related to environmental realism, sensor noise modeling,and computational scalability are discussed, and future research directions,such as incorporating weather effects, real-world terrain models, and advancedscanner configurations, are proposed. The workflow provides a versatile,reproducible framework for generating high-fidelity synthetic LiDAR datasets toadvance perception research and strengthen sensor security in autonomoussystems. Documentation and examples accompany this framework; samples ofanimated cloud returns and image sensor data can be found at this Link.</description>
      <author>example@mail.com (Abhishek Phadke, Shakib Mahmud Dipto, Pratip Rana)</author>
      <guid isPermaLink="false">2506.17378v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>DRIMV_TSK: An Interpretable Surgical Evaluation Model for Incomplete Multi-View Rectal Cancer Data</title>
      <link>http://arxiv.org/abs/2506.17552v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多视角直肠癌数据集和可解释的不完整多视角手术评估模型，以提高直肠癌治疗的成功率。&lt;h4&gt;背景&lt;/h4&gt;目前直肠癌治疗的评估方法基于临床数据，但技术发展可以收集更多数据，人工智能的应用也使得直肠癌治疗成为可能。&lt;h4&gt;目的&lt;/h4&gt;构建一个多视角直肠癌数据集，并开发一个可解释的不完整多视角手术评估模型，以更全面地评估患者情况。&lt;h4&gt;方法&lt;/h4&gt;首先构建了包含高分辨率MRI图像视图、压脂MRI图像视图和临床数据视图的多视角直肠癌数据集。然后，提出了一种双表示不完整多视角学习模型，该模型将缺失视图插补集成到表示学习中，并引入了二阶相似性约束以改善合作学习。基于插补的多视角数据和学习的双表示，提出了一种基于TSK模糊系统的多视角手术评估模型。该模型构建了一个合作学习机制来探索视图间的一致信息，并引入了香农熵来适应视图权重。&lt;h4&gt;主要发现&lt;/h4&gt;在MVRC数据集上，与几种先进的算法相比，DRIMV_TSK模型获得了最佳结果。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法可以有效地评估直肠癌手术的难度，并有望提高直肠癌治疗的成功率。&lt;h4&gt;翻译&lt;/h4&gt;A reliable evaluation of surgical difficulty can improve the success of the treatment for rectal cancer and the current evaluation method is based on clinical data. However, more data about rectal cancer can be collected with the development of technology. Meanwhile, with the development of artificial intelligence, its application in rectal cancer treatment is becoming possible. In this paper, a multi-view rectal cancer dataset is first constructed to give a more comprehensive view of patients, including the high-resolution MRI image view, pressed-fat MRI image view, and clinical data view. Then, an interpretable incomplete multi-view surgical evaluation model is proposed, considering that it is hard to obtain extensive and complete patient data in real application scenarios. Specifically, a dual representation incomplete multi-view learning model is first proposed to extract the common information between views and specific information in each view. In this model, the missing view imputation is integrated into representation learning, and second-order similarity constraint is also introduced to improve the cooperative learning between these two parts. Then, based on the imputed multi-view data and the learned dual representation, a multi-view surgical evaluation model with the TSK fuzzy system is proposed. In the proposed model, a cooperative learning mechanism is constructed to explore the consistent information between views, and Shannon entropy is also introduced to adapt the view weight. On the MVRC dataset, we compared it with several advanced algorithms and DRIMV_TSK obtained the best results.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A reliable evaluation of surgical difficulty can improve the success of thetreatment for rectal cancer and the current evaluation method is based onclinical data. However, more data about rectal cancer can be collected with thedevelopment of technology. Meanwhile, with the development of artificialintelligence, its application in rectal cancer treatment is becoming possible.In this paper, a multi-view rectal cancer dataset is first constructed to givea more comprehensive view of patients, including the high-resolution MRI imageview, pressed-fat MRI image view, and clinical data view. Then, aninterpretable incomplete multi-view surgical evaluation model is proposed,considering that it is hard to obtain extensive and complete patient data inreal application scenarios. Specifically, a dual representation incompletemulti-view learning model is first proposed to extract the common informationbetween views and specific information in each view. In this model, the missingview imputation is integrated into representation learning, and second-ordersimilarity constraint is also introduced to improve the cooperative learningbetween these two parts. Then, based on the imputed multi-view data and thelearned dual representation, a multi-view surgical evaluation model with theTSK fuzzy system is proposed. In the proposed model, a cooperative learningmechanism is constructed to explore the consistent information between views,and Shannon entropy is also introduced to adapt the view weight. On the MVRCdataset, we compared it with several advanced algorithms and DRIMV_TSK obtainedthe best results.</description>
      <author>example@mail.com (Wei Zhang, Zi Wang, Hanwen Zhou, Zhaohong Deng, Weiping Ding, Yuxi Ge, Te Zhang, Yuanpeng Zhang, Kup-Sze Choi, Shitong Wang, Shudong Hu)</author>
      <guid isPermaLink="false">2506.17552v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of State Representation Learning for Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.17518v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了在强化学习中学习有意义状态表示的各种方法，旨在提高样本效率、泛化能力和性能。&lt;h4&gt;背景&lt;/h4&gt;复杂观察空间对序列决策问题提出了挑战，表示学习方法成为解决这些挑战的重要工具。&lt;h4&gt;目的&lt;/h4&gt;对无模型在线设置中的表示学习方法进行广泛分类，探讨它们在状态表示学习方面的不同方法。&lt;h4&gt;方法&lt;/h4&gt;将方法分为六类，详细介绍了它们的机制、优点和局限性。&lt;h4&gt;主要发现&lt;/h4&gt;通过分类，旨在提高对该领域理解，并为新研究者提供指导。&lt;h4&gt;结论&lt;/h4&gt;讨论了评估表示质量的技术，并详细阐述了相关未来研究方向。&lt;h4&gt;翻译&lt;/h4&gt;Representation learning methods are an important tool for addressing the challenges posed by complex observation spaces in sequential decision making problems. Recently, many methods have used a wide variety of types of approaches for learning meaningful state representations in reinforcement learning, allowing better sample efficiency, generalization, and performance. This survey aims to provide a broad categorization of these methods within a model-free online setting, exploring how they tackle the learning of state representations differently. We categorize the methods into six main classes, detailing their mechanisms, benefits, and limitations. Through this taxonomy, our aim is to enhance the understanding of this field and provide a guide for new researchers. We also discuss techniques for assessing the quality of representations, and detail relevant future directions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning methods are an important tool for addressing thechallenges posed by complex observations spaces in sequential decision makingproblems. Recently, many methods have used a wide variety of types ofapproaches for learning meaningful state representations in reinforcementlearning, allowing better sample efficiency, generalization, and performance.This survey aims to provide a broad categorization of these methods within amodel-free online setting, exploring how they tackle the learning of staterepresentations differently. We categorize the methods into six main classes,detailing their mechanisms, benefits, and limitations. Through this taxonomy,our aim is to enhance the understanding of this field and provide a guide fornew researchers. We also discuss techniques for assessing the quality ofrepresentations, and detail relevant future directions.</description>
      <author>example@mail.com (Ayoub Echchahed, Pablo Samuel Castro)</author>
      <guid isPermaLink="false">2506.17518v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Zero-Shot Conversational Stance Detection: Dataset and Approaches</title>
      <link>http://arxiv.org/abs/2506.17693v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACL 2025 (Findings)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ZS-CSD的大规模、高质量零样本对话立场检测数据集，并基于此数据集提出了SITPCL模型，实现了零样本对话立场检测的基准性能。&lt;h4&gt;背景&lt;/h4&gt;立场检测是识别社交媒体数据中对特定目标的公众意见的任务，随着社交媒体上在线辩论的增加，对话立场检测成为一个关键的研究领域。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有对话立场检测数据集的限制，本文旨在构建一个能够处理大量未见目标的零样本对话立场检测数据集，并提高立场检测模型的性能。&lt;h4&gt;方法&lt;/h4&gt;研究者手动构建了包含280个目标的ZS-CSD数据集，并提出了SITPCL模型，该模型利用原型对比学习来处理说话者交互和目标感知。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SITPCL模型在零样本对话立场检测中达到了最先进的性能，但F1-macro分数仅为43.81%，表明零样本对话立场检测仍面临挑战。&lt;h4&gt;结论&lt;/h4&gt;SITPCL模型在零样本对话立场检测中取得了显著成果，但该领域仍存在持续的挑战，需要进一步的研究和改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stance detection, which aims to identify public opinion towards specifictargets using social media data, is an important yet challenging task. With theincreasing number of online debates among social media users, conversationalstance detection has become a crucial research area. However, existingconversational stance detection datasets are restricted to a limited set ofspecific targets, which constrains the effectiveness of stance detection modelswhen encountering a large number of unseen targets in real-world applications.To bridge this gap, we manually curate a large-scale, high-quality zero-shotconversational stance detection dataset, named ZS-CSD, comprising 280 targetsacross two distinct target types. Leveraging the ZS-CSD dataset, we proposeSITPCL, a speaker interaction and target-aware prototypical contrastivelearning model, and establish the benchmark performance in the zero-shotsetting. Experimental results demonstrate that our proposed SITPCL modelachieves state-of-the-art performance in zero-shot conversational stancedetection. Notably, the SITPCL model attains only an F1-macro score of 43.81%,highlighting the persistent challenges in zero-shot conversational stancedetection.</description>
      <author>example@mail.com (Yuzhe Ding, Kang He, Bobo Li, Li Zheng, Haijun He, Fei Li, Chong Teng, Donghong Ji)</author>
      <guid isPermaLink="false">2506.17693v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Foundation Models and Parameter-Efficient Fine-Tuning for Prognosis Prediction in Medical Imaging</title>
      <link>http://arxiv.org/abs/2506.18434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个专门设计的结构化基准，用于评估和比较卷积神经网络和基础模型在预测COVID-19患者临床结果方面的迁移能力，并利用了多样化的公开胸部X射线数据集。&lt;h4&gt;背景&lt;/h4&gt;尽管人工智能在医学影像中的预后预测具有巨大潜力，但其有效应用仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;评估和比较卷积神经网络和基础模型在预测COVID-19患者临床结果方面的迁移能力。&lt;h4&gt;方法&lt;/h4&gt;实验方法广泛探索了一系列微调策略，包括全微调、线性探测等传统方法，以及低秩自适应、BitFit、VeRA和IA3等参数高效微调方法。评估涵盖了多个学习范式，包括全数据场景和更符合临床实际的少样本学习设置。&lt;h4&gt;主要发现&lt;/h4&gt;通过实施大规模的比较分析，涉及各种预训练模型，包括在大型数据集上预训练的通用架构如CLIP和DINOv2，以及针对生物医学的模型如MedCLIP、BioMedCLIP和PubMedCLIP，严格评估了每个模型在严重数据稀缺和明显类别不平衡条件下有效适应和泛化到预后任务的能力。&lt;h4&gt;结论&lt;/h4&gt;该基准旨在捕捉预后任务中常见的临界条件，包括数据集大小和类别分布的变化，为每种微调策略的优缺点提供详细见解。广泛的评估旨在为现实世界中临床预后预测工作流程中稳健、高效和可泛化的AI驱动解决方案的部署和应用提供信息。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人工智能（AI）在改善医学影像中的预后预测方面具有巨大的潜力，但其有效应用仍然具有挑战性。在这项工作中，我们介绍了一个专门设计的结构化基准，用于评估和比较卷积神经网络和基础模型在预测COVID-19患者临床结果方面的迁移能力，利用了多样化的公开胸部X射线数据集。我们的实验方法广泛探索了一系列微调策略，包括全微调、线性探测等传统方法，以及低秩自适应、BitFit、VeRA和IA3等参数高效微调方法。评估涵盖了多个学习范式，包括全数据场景和更符合临床实际的少样本学习设置。通过实施大规模的比较分析，涉及各种预训练模型，包括在大型数据集上预训练的通用架构如CLIP和DINOv2，以及针对生物医学的模型如MedCLIP、BioMedCLIP和PubMedCLIP，严格评估了每个模型在严重数据稀缺和明显类别不平衡条件下有效适应和泛化到预后任务的能力。该基准旨在捕捉预后任务中常见的临界条件，包括数据集大小和类别分布的变化，为每种微调策略的优缺点提供详细见解。广泛的评估旨在为现实世界中临床预后预测工作流程中稳健、高效和可泛化的AI驱动解决方案的部署和应用提供信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial Intelligence (AI) holds significant promise for improvingprognosis prediction in medical imaging, yet its effective application remainschallenging. In this work, we introduce a structured benchmark explicitlydesigned to evaluate and compare the transferability of Convolutional NeuralNetworks and Foundation Models in predicting clinical outcomes in COVID-19patients, leveraging diverse publicly available Chest X-ray datasets. Ourexperimental methodology extensively explores a wide set of fine-tuningstrategies, encompassing traditional approaches such as Full Fine-Tuning andLinear Probing, as well as advanced Parameter-Efficient Fine-Tuning methodsincluding Low-Rank Adaptation, BitFit, VeRA, and IA3. The evaluations wereconducted across multiple learning paradigms, including both extensivefull-data scenarios and more clinically realistic Few-Shot Learning settings,which are critical for modeling rare disease outcomes and rapidly emerginghealth threats. By implementing a large-scale comparative analysis involving adiverse selection of pretrained models, including general-purpose architecturespretrained on large-scale datasets such as CLIP and DINOv2, tobiomedical-specific models like MedCLIP, BioMedCLIP, and PubMedCLIP, werigorously assess each model's capacity to effectively adapt and generalize toprognosis tasks, particularly under conditions of severe data scarcity andpronounced class imbalance. The benchmark was designed to capture criticalconditions common in prognosis tasks, including variations in dataset size andclass distribution, providing detailed insights into the strengths andlimitations of each fine-tuning strategy. This extensive and structuredevaluation aims to inform the practical deployment and adoption of robust,efficient, and generalizable AI-driven solutions in real-world clinicalprognosis prediction workflows.</description>
      <author>example@mail.com (Filippo Ruffini, Elena Mulero Ayllon, Linlin Shen, Paolo Soda, Valerio Guarrasi)</author>
      <guid isPermaLink="false">2506.18434v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>SurgVidLM: Towards Multi-grained Surgical Video Understanding with Large Language Model</title>
      <link>http://arxiv.org/abs/2506.17873v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SurgVidLM是一个视频语言模型，旨在解决全范围和细粒度手术视频理解任务，在医疗领域展现出巨大潜力。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型在医疗领域展现出潜力，视频大型语言模型（Vid-LLMs）在捕捉手术复杂信息序列方面成为一个有前景的方法。&lt;h4&gt;目的&lt;/h4&gt;提出SurgVidLM来解决细粒度手术视频理解任务，填补该领域Vid-LLMs的空白。&lt;h4&gt;方法&lt;/h4&gt;构建SVU-31K数据集，包含超过31K个视频指令对，采用StageFocus机制和Multi-frequency Fusion Attention技术进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;SurgVidLM在全面和细粒度视频理解任务中显著优于现有Vid-LLMs，显示出在捕捉复杂手术背景方面的优越能力。&lt;h4&gt;结论&lt;/h4&gt;SurgVidLM为手术视频理解提供了有效的解决方案，有助于提高对手术过程和细节的分析能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Multimodal Large Language Models have demonstrated greatpotential in the medical domain, facilitating users to understand surgicalscenes and procedures. Beyond image-based methods, the exploration of VideoLarge Language Models (Vid-LLMs) has emerged as a promising avenue forcapturing the complex sequences of information involved in surgery. However,there is still a lack of Vid-LLMs specialized for fine-grained surgical videounderstanding tasks, which is crucial for analyzing specific processes ordetails within a surgical procedure. To bridge this gap, we propose SurgVidLM,the first video language model designed to address both full and fine-grainedsurgical video comprehension. To train our SurgVidLM, we construct the SVU-31Kdataset which consists of over 31K video-instruction pairs, enabling bothholistic understanding and detailed analysis of surgical procedures.Furthermore, we introduce the StageFocus mechanism which is a two-stageframework performing the multi-grained, progressive understanding of surgicalvideos. We also develop the Multi-frequency Fusion Attention to effectivelyintegrate low and high-frequency visual tokens, ensuring the retention ofcritical information. Experimental results demonstrate that SurgVidLMsignificantly outperforms state-of-the-art Vid-LLMs in both full andfine-grained video understanding tasks, showcasing its superior capability incapturing complex procedural contexts.</description>
      <author>example@mail.com (Guankun Wang, Wenjin Mo, Junyi Wang, Long Bai, Kun Yuan, Ming Hu, Jinlin Wu, Junjun He, Yiming Huang, Nicolas Padoy, Zhen Lei, Hongbin Liu, Nassir Navab, Hongliang Ren)</author>
      <guid isPermaLink="false">2506.17873v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Deep Supervised LSTM for 3D morphology estimation from Multi-View RGB Images of Wheat Spikes</title>
      <link>http://arxiv.org/abs/2506.18060v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了从二维RGB图像中估计三维形态特征的方法，并提出了一个神经网络模型，通过深度监督技术提高了体积估计的准确性。&lt;h4&gt;背景&lt;/h4&gt;由于深度信息丢失、投影畸变和遮挡，从二维RGB图像中估计三维形态特征存在固有挑战。&lt;h4&gt;目的&lt;/h4&gt;研究多种非破坏性体积估计方法，以用于小麦穗的体积估计，并验证神经网络方法的有效性。&lt;h4&gt;方法&lt;/h4&gt;使用RGB图像序列和结构光3D扫描作为基准，提出了一种结合DINOv2和单向LSTM网络的神经网络方法，通过深度监督提高模型的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;深度监督模型在室内六视图图像上达到了6.46%的平均绝对百分比误差（MAPE），优于基于面积的投影和基于轴对齐横截面的几何重建方法。在基于现场的单图像数据上微调模型，实现了领域自适应，MAPE为10.82%。&lt;h4&gt;结论&lt;/h4&gt;对象形状对体积预测准确性有显著影响，与深度学习方法相比，几何方法在处理不规则几何形状（如小麦穗）时面临更大的挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从二维RGB图像中估计三维形态特征存在固有挑战，包括深度信息丢失、投影畸变和遮挡。在本研究中，我们探索了多种非破坏性体积估计方法，使用RGB图像序列和结构光3D扫描作为基准。由于穗的复杂几何形状，我们提出了一种神经网络方法，用于2D图像中的体积估计，结合了自监督视觉Transformer DINOv2和一个单向长短期记忆（LSTM）网络。通过深度监督，模型能够学习更鲁棒的中层表示，从而增强了其在不同评估序列上的泛化能力。我们将我们的模型与两个传统基线进行了基准测试：基于面积的投影和基于轴对齐横截面的几何重建。我们的深度监督模型在室内六视图图像上实现了6.46%的平均绝对百分比误差（MAPE），优于面积（9.36%）和几何（13.98%）基线。在基于现场的单图像数据上微调模型，实现了领域自适应，MAPE为10.82%。我们证明了对象形状对体积预测准确性有显著影响，与我们的深度学习方法相比，几何方法在处理不规则几何形状（如小麦穗）时面临更大的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Estimating three-dimensional morphological traits from two-dimensional RGBimages presents inherent challenges due to the loss of depth information,projection distortions, and occlusions under field conditions. In this work, weexplore multiple approaches for non-destructive volume estimation of wheatspikes, using RGB image sequences and structured-light 3D scans as ground truthreferences. Due to the complex geometry of the spikes, we propose a neuralnetwork approach for volume estimation in 2D images, employing a transferlearning pipeline that combines DINOv2, a self-supervised Vision Transformer,with a unidirectional Long Short-Term Memory (LSTM) network. By using deepsupervision, the model is able to learn more robust intermediaterepresentations, which enhances its generalisation ability across varyingevaluation sequences. We benchmark our model against two conventionalbaselines: a 2D area-based projection and a geometric reconstruction usingaxis-aligned cross-sections. Our deep supervised model achieves a mean absolutepercentage error (MAPE) of 6.46% on six-view indoor images, outperforming thearea (9.36%) and geometric (13.98%) baselines. Fine-tuning the model onfield-based single-image data enables domain adaptation, yielding a MAPE of10.82%. We demonstrate that object shape significantly impacts volumeprediction accuracy, with irregular geometries such as wheat spikes posinggreater challenges for geometric methods compared to our deep learningapproach.</description>
      <author>example@mail.com (Olivia Zumsteg, Nico Graf, Aaron Haeusler, Norbert Kirchgessner, Nicola Storni, Lukas Roth, Andreas Hund)</author>
      <guid isPermaLink="false">2506.18060v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Visual Image Based User Association and Beamforming Using Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.18218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用多模态数据的方法，通过结合视觉图像和射频（RF）导频来优化下行无线蜂窝网络中的用户关联和波束成形，以满足最大-最小公平性准则。该方法旨在减少对大量导频传输的依赖，提高系统性能。&lt;h4&gt;背景&lt;/h4&gt;传统的无线系统参数优化方法通常基于信道状态信息（CSI），但获取准确的CSI需要大量的导频传输，这会导致开销和延迟增加。此外，用户关联和波束成形的优化是一个离散的非凸优化问题，难以解析求解。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过结合视觉图像和射频导频数据，以优化用户关联和波束成形，同时减少对大量导频传输的依赖。&lt;h4&gt;方法&lt;/h4&gt;本文采用了一种基于学习的方法，包括一个用于从图像中估计用户位置的检测神经网络，以及两个图神经网络（GNNs），分别用于提取基于位置信息和接收到的导频的系统优化特征。然后，构建了一个多模态GNN来整合这些特征，以实现用户关联和波束成形的联合优化。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，所提出的方法在性能上优于仅基于RF导频的传统方法，同时具有低计算复杂度、可解释性和可推广性。&lt;h4&gt;结论&lt;/h4&gt;该方法是一种有效的解决方案，可以减少对大量导频传输的依赖，同时提高下行无线蜂窝网络中的用户关联和波束成形性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an approach that leverages multimodal data by integratingvisual images with radio frequency (RF) pilots to optimize user association andbeamforming in a downlink wireless cellular network under a max-min fairnesscriterion. Traditional methods typically optimize wireless system parametersbased on channel state information (CSI). However, obtaining accurate CSIrequires extensive pilot transmissions, which lead to increased overhead andlatency. Moreover, the optimization of user association and beamforming is adiscrete and non-convex optimization problem, which is challenging to solveanalytically. In this paper, we propose to incorporate visual camera data inaddition to the RF pilots to perform the joint optimization of user associationand beamforming. The visual image data helps enhance channel awareness, therebyreducing the dependency on extensive pilot transmissions for systemoptimization. We employ a learning-based approach based on using first adetection neural network that estimates user locations from images, andsubsequently two graph neural networks (GNNs) that extract features for systemoptimization based on the location information and the received pilots,respectively. Then, a multimodal GNN is constructed to integrate the featuresfor the joint optimization user association and beamforming. Simulation resultsdemonstrate that the proposed method achieves superior performance, whilehaving low computational complexity and being interpretable and generalizable,making it an effective solution as compared to traditional methods based onlyon RF pilots.</description>
      <author>example@mail.com (Yinghan Li, Yiming Liu, Wei Yu)</author>
      <guid isPermaLink="false">2506.18218v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Reinforcing User Interest Evolution in Multi-Scenario Learning for recommender systems</title>
      <link>http://arxiv.org/abs/2506.17682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的强化学习方法，用于多场景下的推荐系统，通过模拟用户兴趣在不同场景中的演变来建模用户偏好，并通过DoubleQ学习和优化对比学习损失来提高预测准确性。&lt;h4&gt;背景&lt;/h4&gt;现实中的推荐系统涉及多种场景，如主页、搜索页面和相关推荐页面，用户在这些场景中的兴趣可能不一致，这给统一建模带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来解决多场景推荐任务中的统一建模问题，并通过提高预测准确性来优化模型性能。&lt;h4&gt;方法&lt;/h4&gt;使用强化学习来模拟用户兴趣的演变，采用DoubleQ学习来增强下一项预测的准确性，并利用Q值优化对比学习损失。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在多场景推荐任务中优于现有方法，为多场景建模提供了新的视角。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为多场景建模提供了有希望的研究方向，并为未来的研究指明了道路。&lt;h4&gt;翻译&lt;/h4&gt;在现实世界的推荐系统中，用户会参与各种场景，如主页、搜索页面和相关的推荐页面。每个场景都会反映用户关注的不同方面。然而，由于决策过程和偏好表达的不同，用户兴趣在不同场景中可能不一致。这种可变性使得统一建模变得复杂，使得多场景学习成为一个重要的挑战。为了解决这个问题，我们提出了一种新的强化学习方法，通过模拟用户兴趣在多个场景中的演变来建模用户偏好。我们的方法采用DoubleQ学习来提高下一项预测的准确性，并使用Q值优化对比学习损失，以使模型性能更好。实验结果表明，我们的方法在多场景推荐任务中优于最先进的方法。我们的工作为多场景建模提供了新的视角，并突出了未来研究的有希望的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In real-world recommendation systems, users would engage in varietyscenarios, such as homepages, search pages, and related recommendation pages.Each of these scenarios would reflect different aspects users focus on.However, the user interests may be inconsistent in different scenarios, due todifferences in decision-making processes and preference expression. Thisvariability complicates unified modeling, making multi-scenario learning asignificant challenge. To address this, we propose a novel reinforcementlearning approach that models user preferences across scenarios by modelinguser interest evolution across multiple scenarios. Our method employs DoubleQ-learning to enhance next-item prediction accuracy and optimizes contrastivelearning loss using Q-value to make model performance better. Experimentalresults demonstrate that our approach surpasses state-of-the-art methods inmulti-scenario recommendation tasks. Our work offers a fresh perspective onmulti-scenario modeling and highlights promising directions for futureresearch.</description>
      <author>example@mail.com (Zhijian Feng, Wenhao Zheng, Xuanji Xiao)</author>
      <guid isPermaLink="false">2506.17682v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>SafeClick: Error-Tolerant Interactive Segmentation of Any Medical Volumes via Hierarchical Expert Consensus</title>
      <link>http://arxiv.org/abs/2506.18404v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SafeClick是一种基于层次专家共识的容错交互式医学体积分割方法，能够提高基于基础模型的分割性能，尤其是在处理不完美提示时。&lt;h4&gt;背景&lt;/h4&gt;体积医学图像分割模型在临床工作中表现出强大的能力，但分割性能受提示质量影响，临床环境中提供的提示往往不理想。&lt;h4&gt;目的&lt;/h4&gt;为了解决提示质量对分割性能的影响，提出SafeClick方法。&lt;h4&gt;方法&lt;/h4&gt;SafeClick是一个插件式模块，兼容SAM 2和MedSAM 2等基础模型。它包含两个主要组件：协作专家层（CEL）和共识推理层（CRL）。CEL通过专门的Transformer模块生成多样化的特征表示，CRL则执行跨引用和自适应整合这些特征。&lt;h4&gt;主要发现&lt;/h4&gt;SafeClick在15个公共数据集上的实验表明，该方法能够持续提高基础模型的性能，特别是在处理不完美提示时效果显著。&lt;h4&gt;结论&lt;/h4&gt;SafeClick能够将分割过程从依赖提示的操作转变为一个鲁棒的框架，即使在用户输入不完美的情况下也能产生准确的结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于体积医学图像分割的基座模型已成为临床工作流程中的强大工具，使放射科医生能够通过直观的点击来勾勒感兴趣的区域。虽然这些模型在分割未见过的解剖结构方面表现出有希望的能力，但它们的性能强烈受到提示质量的影响。在临床环境中，放射科医生经常提供次优的提示，这影响了分割的可靠性和准确性。为了解决这一限制，我们提出了SafeClick，这是一种基于层次专家共识的容错交互式医学体积分割方法。SafeClick作为一个即插即用的模块，与SAM 2和MedSAM 2等基础模型兼容。该框架由两个关键组件组成：一个协作专家层（CEL），它通过专门的Transformer模块生成多样化的特征表示；以及一个共识推理层（CRL），它执行这些特征的跨引用和自适应整合。这种架构将分割过程从依赖提示的操作转变为一个鲁棒的框架，能够在不完美的用户输入的情况下产生准确的结果。在15个公共数据集上的大量实验表明，我们的即插即用方法一致地提高了基础模型的性能，特别是在处理不完美的提示时效果显著。源代码可在https://github.com/yifangao112/SafeClick上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models for volumetric medical image segmentation have emerged aspowerful tools in clinical workflows, enabling radiologists to delineateregions of interest through intuitive clicks. While these models demonstratepromising capabilities in segmenting previously unseen anatomical structures,their performance is strongly influenced by prompt quality. In clinicalsettings, radiologists often provide suboptimal prompts, which affectssegmentation reliability and accuracy. To address this limitation, we presentSafeClick, an error-tolerant interactive segmentation approach for medicalvolumes based on hierarchical expert consensus. SafeClick operates as aplug-and-play module compatible with foundation models including SAM 2 andMedSAM 2. The framework consists of two key components: a collaborative expertlayer (CEL) that generates diverse feature representations through specializedtransformer modules, and a consensus reasoning layer (CRL) that performscross-referencing and adaptive integration of these features. This architecturetransforms the segmentation process from a prompt-dependent operation to arobust framework capable of producing accurate results despite imperfect userinputs. Extensive experiments across 15 public datasets demonstrate that ourplug-and-play approach consistently improves the performance of base foundationmodels, with particularly significant gains when working with imperfectprompts. The source code is available athttps://github.com/yifangao112/SafeClick.</description>
      <author>example@mail.com (Yifan Gao, Jiaxi Sheng, Wenbin Wu, Haoyue Li, Yaoxian Dong, Chaoyang Ge, Feng Yuan, Xin Gao)</author>
      <guid isPermaLink="false">2506.18404v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Machine Learning Model Integration with Open World Temporal Logic for Process Automation</title>
      <link>http://arxiv.org/abs/2506.17776v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种将机器学习模型输出与PyReason框架结合的新方法，以解决将感知或提取输出转化为可操作决策的挑战。&lt;h4&gt;背景&lt;/h4&gt;尽管机器学习在提取结构化信息方面取得了进展，但将输出转化为实际决策在复杂操作流程中仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在创建一个强大的系统，通过结合机器学习模型的感知和提取能力以及PyReason的逻辑推理和透明度，来自动化复杂过程。&lt;h4&gt;方法&lt;/h4&gt;该方法将机器学习模型的输出直接与PyReason框架集成，PyReason基于通用注释逻辑，可以无缝地整合来自不同模型的实值输出（如概率、置信度分数），并将它们作为逻辑框架中的真值区间处理。&lt;h4&gt;主要发现&lt;/h4&gt;PyReason提供了在Python中实现的机制，以连续轮询机器学习模型输出，将它们转换为逻辑事实，并动态重新计算最小模型，确保实时自适应决策。&lt;h4&gt;结论&lt;/h4&gt;这种集成在多个领域都有应用，包括制造业、医疗保健和业务运营。&lt;h4&gt;翻译&lt;/h4&gt;最近机器学习（ML）的进步产生了能够从各种复杂数据源中提取结构化信息的有力模型。然而，一个重大的挑战在于将这些感知或提取输出转化为复杂操作流程中的可操作、合理的决策。为了解决这些挑战，本文介绍了一种新方法，该方法将各种机器学习模型的输出直接与PyReason框架集成，PyReason是一个开放世界的时态逻辑编程推理引擎。PyReason基于通用注释逻辑的基础，允许无缝地整合来自不同模型的实值输出（例如，概率、置信度分数），将其作为其逻辑框架中的真值区间处理。关键的是，PyReason提供了在Python中实现的机制，以连续轮询机器学习模型输出，将它们转换为逻辑事实，并动态重新计算最小模型，确保实时自适应决策。此外，它对时态推理、知识图集成和完全可解释的界面跟踪的原生支持，使得对时间敏感的过程数据和现有组织知识的复杂分析成为可能。通过结合机器学习模型的感知和提取能力与PyReason的逻辑推理和透明度，我们旨在创建一个强大的系统，用于自动化复杂过程。这种集成在多个领域都有应用，包括制造业、医疗保健和业务运营。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Machine Learning (ML) have yielded powerful modelscapable of extracting structured information from diverse and complex datasources. However, a significant challenge lies in translating these perceptualor extractive outputs into actionable, reasoned decisions within complexoperational workflows. To address these challenges, this paper introduces anovel approach that integrates the outputs from various machine learning modelsdirectly with the PyReason framework, an open-world temporal logic programmingreasoning engine. PyReason's foundation in generalized annotated logic allowsfor the seamless incorporation of real-valued outputs (e.g., probabilities,confidence scores) from diverse ML models, treating them as truth intervalswithin its logical framework. Crucially, PyReason provides mechanisms,implemented in Python, to continuously poll ML model outputs, convert them intological facts, and dynamically recompute the minimal model, ensuring real-tineadaptive decision-making. Furthermore, its native support for temporalreasoning, knowledge graph integration, and fully explainable interface tracesenables sophisticated analysis over time-sensitive process data and existingorganizational knowledge. By combining the strengths of perception andextraction from ML models with the logical deduction and transparency ofPyReason, we aim to create a powerful system for automating complex processes.This integration finds utility across numerous domains, includingmanufacturing, healthcare, and business operations.</description>
      <author>example@mail.com (Dyuman Aditya, Colton Payne, Mario Leiva, Paulo Shakarian)</author>
      <guid isPermaLink="false">2506.17776v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Call Me Maybe: Enhancing JavaScript Call Graph Construction using Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.18191v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GRAPHIA的方法，用于提高JavaScript程序中调用图构建的准确性，通过利用图神经网络来预测调用关系，从而识别出现有工具遗漏的调用边。&lt;h4&gt;背景&lt;/h4&gt;静态分析在发现包括安全漏洞在内的bug中扮演关键角色。构建准确的调用图是静态分析中的一个关键步骤。然而，由于难以分析的语言特性，现有的JavaScript调用图构建算法既不严格也不完整。&lt;h4&gt;目的&lt;/h4&gt;提高JavaScript调用图构建的准确性，减少分析过程中的人工工作量。&lt;h4&gt;方法&lt;/h4&gt;将问题建模为整个程序图的链接预测问题，使用多种边类型进行丰富的表示。GRAPHIA利用图神经网络来建模代码元素之间的非局部关系。具体来说，使用基于语法和语义的边组合来表示JavaScript程序。GRAPHIA可以从不完美的标签中学习，包括来自现有工具的静态调用边和来自测试的动态边。&lt;h4&gt;主要发现&lt;/h4&gt;GRAPHIA在50个流行的JavaScript库上进行了大规模评估，这些库包含163K个调用边（150K静态和13K动态）。GRAPHIA构建的程序图包含6.6M个结构和386K个语义边。在超过42%的未解决案例中，将正确目标作为最高候选者，在72%的案例中位于前5位，从而减少了分析所需的人工工作量。&lt;h4&gt;结论&lt;/h4&gt;学习型方法可以提高JavaScript调用图构建的召回率。这是首次将基于GNN的链接预测应用于全多文件程序图进行过程间分析的工作。&lt;h4&gt;翻译&lt;/h4&gt;静态分析在发现bug，包括安全问题中起着关键作用。在静态分析中，构建准确的调用图是关键步骤之一。然而，由于难以分析的语言特性，现有的JavaScript调用图构建算法既不严格也不完整。先前的工作表明，即使是高级解决方案也会产生错误边并错过有效的边。在这项工作中，我们通过识别遗漏的调用边来辅助这些工具。我们的主要想法是将问题建模为整个程序图的链接预测问题，使用多种边类型进行丰富的表示。我们的方法，GRAPHIA，利用图神经网络的最新进展来建模代码元素之间的非局部关系。具体来说，我们提出使用基于语法和语义的边组合来表示JavaScript程序。GRAPHIA可以从不完美的标签中学习，包括来自现有工具的静态调用边和来自测试的动态边，无论是来自同一项目还是不同项目。由于调用图是稀疏的，标准的机器学习指标如ROC并不适用。相反，我们通过为每个未解决的调用点对函数定义进行排序来评估GRAPHIA。我们在50个流行的JavaScript库上进行了大规模评估，这些库包含163K个调用边（150K静态和13K动态）。GRAPHIA构建了包含6.6M个结构和386K个语义边的程序图。在超过42%的未解决案例中，将正确目标作为最高候选者，在72%的案例中位于前5位，从而减少了分析所需的人工工作量。我们的结果表明，基于学习的方法可以提高JavaScript调用图构建的召回率。据我们所知，这是首次将基于GNN的链接预测应用于全多文件程序图进行过程间分析的工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Static analysis plays a key role in finding bugs, including security issues.A critical step in static analysis is building accurate call graphs that modelfunction calls in a program. However, due to hard-to-analyze language features,existing call graph construction algorithms for JavaScript are neither soundnor complete. Prior work shows that even advanced solutions produce false edgesand miss valid ones. In this work, we assist these tools by identifying missedcall edges. Our main idea is to frame the problem as link prediction on fullprogram graphs, using a rich representation with multiple edge types. Ourapproach, GRAPHIA, leverages recent advances in graph neural networks to modelnon-local relationships between code elements. Concretely, we proposerepresenting JavaScript programs using a combination of syntactic- andsemantic-based edges. GRAPHIA can learn from imperfect labels, including staticcall edges from existing tools and dynamic edges from tests, either from thesame or different projects. Because call graphs are sparse, standard machinelearning metrics like ROC are not suitable. Instead, we evaluate GRAPHIA byranking function definitions for each unresolved call site. We conduct alarge-scale evaluation on 50 popular JavaScript libraries with 163K call edges(150K static and 13K dynamic). GRAPHIA builds program graphs with 6.6Mstructural and 386K semantic edges. It ranks the correct target as the topcandidate in over 42% of unresolved cases and within the top 5 in 72% of cases,reducing the manual effort needed for analysis. Our results show thatlearning-based methods can improve the recall of JavaScript call graphconstruction. To our knowledge, this is the first work to apply GNN-based linkprediction to full multi-file program graphs for interprocedural analysis.</description>
      <author>example@mail.com (Masudul Hasan Masud Bhuiyan, Gianluca De Stefano, Giancarlo Pellegrino, Cristian-Alexandru Staicu)</author>
      <guid isPermaLink="false">2506.18191v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>LLM-driven Medical Report Generation via Communication-efficient Heterogeneous Federated Learning</title>
      <link>http://arxiv.org/abs/2506.17562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FedMRG的框架，用于利用联邦学习（FL）在多个中心进行隐私保护的医疗报告生成（MRG）模型的开发。&lt;h4&gt;背景&lt;/h4&gt;LLMs在医疗报告生成方面具有巨大潜力，但其开发需要大量的医疗图像报告对，这些数据通常分散在多个中心，而集中这些数据因隐私法规而极具挑战性。&lt;h4&gt;目的&lt;/h4&gt;旨在解决多中心数据集中通信效率低的挑战，实现隐私保护的多中心LLM驱动MRG模型的开发。&lt;h4&gt;方法&lt;/h4&gt;FedMRG框架通过以下方法实现这一目标：(1) 使用低秩分解来减少参数更新的通信开销；(2) 在MRG编码器中采用客户端感知的对比学习，结合诊断驱动的提示；(3) 在MRG解码器中使用双重适配器互增强机制。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的评估，证明了FedMRG的泛化能力和适应性，能够在保持通信效率的同时，利用多中心数据生成临床准确的报告。&lt;h4&gt;结论&lt;/h4&gt;FedMRG框架能够有效解决多中心数据集中通信效率低的挑战，具有在保持通信效率的同时，利用多中心数据生成临床准确报告的潜力。&lt;h4&gt;翻译&lt;/h4&gt;LLMs have demonstrated significant potential in Medical Report Generation (MRG), yet their development requires large amounts of medical image-report pairs, which are commonly scattered across multiple centers. Centralizing these data is exceptionally challenging due to privacy regulations, thereby impeding model development and broader adoption of LLM-driven MRG models. To address this challenge, we present FedMRG, the first framework that leverages Federated Learning (FL) to enable privacy-preserving, multi-center development of LLM-driven MRG models, specifically designed to overcome the critical challenge of communication-efficient LLM training under multi-modal data heterogeneity. To start with, our framework tackles the fundamental challenge of communication overhead in FL-LLM tuning by employing low-rank factorization to efficiently decompose parameter updates, significantly reducing gradient transmission costs and making LLM-driven MRG feasible in bandwidth-constrained FL settings. Furthermore, we observed the dual heterogeneity in MRG under the FL scenario: varying image characteristics across medical centers, as well as diverse reporting styles and terminology preferences. To address this, we further enhance FedMRG with (1) client-aware contrastive learning in the MRG encoder, coupled with diagnosis-driven prompts, which capture both globally generalizable and locally distinctive features while maintaining diagnostic accuracy; and (2) a dual-adapter mutual boosting mechanism in the MRG decoder that harmonizes generic and specialized adapters to address variations in reporting styles and terminology. Through extensive evaluation of our established FL-MRG benchmark, we demonstrate the generalizability and adaptability of FedMRG, underscoring its potential in harnessing multi-center data and generating clinically accurate reports while maintaining communication efficiency.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LLMs have demonstrated significant potential in Medical Report Generation(MRG), yet their development requires large amounts of medical image-reportpairs, which are commonly scattered across multiple centers. Centralizing thesedata is exceptionally challenging due to privacy regulations, thereby impedingmodel development and broader adoption of LLM-driven MRG models. To addressthis challenge, we present FedMRG, the first framework that leverages FederatedLearning (FL) to enable privacy-preserving, multi-center development ofLLM-driven MRG models, specifically designed to overcome the critical challengeof communication-efficient LLM training under multi-modal data heterogeneity.To start with, our framework tackles the fundamental challenge of communicationoverhead in FL-LLM tuning by employing low-rank factorization to efficientlydecompose parameter updates, significantly reducing gradient transmission costsand making LLM-driven MRG feasible in bandwidth-constrained FL settings.Furthermore, we observed the dual heterogeneity in MRG under the FL scenario:varying image characteristics across medical centers, as well as diversereporting styles and terminology preferences. To address this, we furtherenhance FedMRG with (1) client-aware contrastive learning in the MRG encoder,coupled with diagnosis-driven prompts, which capture both globallygeneralizable and locally distinctive features while maintaining diagnosticaccuracy; and (2) a dual-adapter mutual boosting mechanism in the MRG decoderthat harmonizes generic and specialized adapters to address variations inreporting styles and terminology. Through extensive evaluation of ourestablished FL-MRG benchmark, we demonstrate the generalizability andadaptability of FedMRG, underscoring its potential in harnessing multi-centerdata and generating clinically accurate reports while maintaining communicationefficiency.</description>
      <author>example@mail.com (Haoxuan Che, Haibo Jin, Zhengrui Guo, Yi Lin, Cheng Jin, Hao Chen)</author>
      <guid isPermaLink="false">2506.17562v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Classification of Tents in Street Bazaars Using CNN</title>
      <link>http://arxiv.org/abs/2506.17946v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种改进的深度学习模型，用于对街头集市中的帐篷进行分类，比较了自定义卷积神经网络（CNN）与EfficientNetB0的性能。&lt;h4&gt;背景&lt;/h4&gt;街头集市在许多地区是重要的经济中心，但其无序性给市场基础设施（如帐篷）的自动分类带来了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在开发一种高效的分类方法，以解决街头集市帐篷自动分类的难题。&lt;h4&gt;方法&lt;/h4&gt;研究基于扩展的126张原始照片数据集，通过图像增强生成额外图像。使用多种性能指标（如准确率、精确率、召回率、F1分数和平均精度均值）来评估模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;CNN自定义模型达到了92.8%的准确率，而EfficientNetB0达到了98.4%的准确率，证明了迁移学习在集市图像分类中的有效性。&lt;h4&gt;结论&lt;/h4&gt;使用预训练模型如EfficientNetB0可以显著提高分类准确性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;本研究提出了一种改进的深度学习模型，用于对街头集市中的帐篷进行分类，比较了自定义卷积神经网络（CNN）与EfficientNetB0。这是市场组织中的一个关键任务，但过去的手动方法效率低下。街头集市在许多地区是重要的经济中心，但其无序性给市场基础设施（如帐篷）的自动分类带来了重大挑战。在吉尔吉斯斯坦，超过四分之一的国内生产总值来自集市。虽然卷积神经网络（CNN）已被广泛应用于物体识别，但其在集市特定任务中的应用仍处于探索阶段。在这里，我们通过在扩展的126张原始照片数据集上训练，并通过对这些照片进行增强来生成额外的图像，改进了我们的原始方法。这个数据集可以在Kaggle上公开下载。使用多种性能指标，如准确率、精确率、召回率、F1分数和平均精度均值（mAP），对模型进行了比较评估，提供了对分类性能的更全面分析。结果表明，CNN自定义模型达到了92.8%的准确率，而EfficientNetB0则达到了98.4%的准确率，这证实了迁移学习在集市图像分类中的有效性。此外，通过分析混淆矩阵，揭示了每个模型的弱点和优势。这些发现表明，使用预训练模型如EfficientNetB0可以显著提高分类准确性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research paper proposes an improved deep learning model for classifyingtents in street bazaars, comparing a custom Convolutional Neural Network (CNN)with EfficientNetB0. This is a critical task for market organization with atent classification, but manual methods in the past have been inefficient.Street bazaars represent a vital economic hub in many regions, yet theirunstructured nature poses significant challenges for the automatedclassification of market infrastructure, such as tents. In Kyrgyzstan, morethan a quarter of the country's GDP is derived from bazaars. While CNNs havebeen widely applied to object recognition, their application to bazaar-specifictasks remains underexplored. Here, we build upon our original approach bytraining on an extended set of 126 original photographs that were augmented togenerate additional images. This dataset is publicly available for download onKaggle. A variety of performance metrics, such as accuracy, precision, recall,F1 score, and mean average precision (mAP), were used to assess the modelscomparatively, providing a more extensive analysis of classificationperformance.  The results show that the CNN custom model achieved 92.8% accuracy, andEfficientNetB0 showed 98.4% accuracy results, confirming the effectiveness oftransfer learning in the bazaar image classification. Also, when analyzing theconfusion matrix, the analysis reveals the weaknesses and strengths of eachmodel. These findings suggest that using a pre-trained model such asEfficientNetB0 significantly improves classification accuracy andgeneralization.</description>
      <author>example@mail.com (Azamat Ibragimov, Ruslan Isaev, Remudin Reshid Mekuria, Gulnaz Gimaletdinova, Dim Shaiakhmetov)</author>
      <guid isPermaLink="false">2506.17946v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>TROJAN-GUARD: Hardware Trojans Detection Using GNN in RTL Designs</title>
      <link>http://arxiv.org/abs/2506.17894v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于检测大规模芯片设计中的硬件木马，通过生成大型设计的图嵌入并采用针对硬件木马检测优化的图神经网络模型，以及通过模型量化技术提高训练和推理效率。&lt;h4&gt;背景&lt;/h4&gt;芯片制造过程复杂，使用大量不受信任的第三方工具和设计，增加了硬件木马的风险，对国家安全、经济和个人隐私构成威胁。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效且高效的硬件木马检测方法，用于大规模芯片设计。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的框架，该框架生成大型设计的图嵌入，并整合了针对硬件木马检测优化的多种图神经网络模型。此外，通过实现模型量化，引入了特定领域的技术，以提高训练和推理的效率。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在自定义数据集上的评估结果显示，检测精度达到98.66%，召回率达到92.30%，证明了该方法在检测大规模芯片设计中的硬件木马方面的有效性和效率。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法能够有效检测大规模芯片设计中的硬件木马，为提高芯片安全性和可靠性提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：芯片制造是一个复杂的过程，为了实现更快的上市时间，越来越多的不受信任的第三方工具和设计被利用。使用这些不受信任的第三方知识产权（IP）和工具增加了对手插入硬件木马（HT）的风险。硬件木马的秘密性质对网络空间构成重大威胁，可能对国家安全、经济和个人隐私造成严重后果。已经提出了许多基于图神经网络（GNN）的硬件木马检测方法。然而，由于它们依赖于使用较小设计进行训练，因此在较大设计中表现不佳。此外，这些方法没有探索适合硬件木马检测的不同GNN模型，也没有提供有效的训练和推理过程。我们提出了一种新颖的框架，该框架为大型设计（例如，RISC-V）生成图嵌入，并整合了针对硬件木马检测优化的各种GNN模型。此外，我们的框架通过实现模型量化引入了特定领域的技术，以实现高效的训练和推理。模型量化降低了权重的精度，降低了计算需求，提高了处理速度，而不会严重影响检测精度。我们使用自定义数据集评估了我们的框架，我们的结果表明，精度为98.66%，召回率（真正率）为92.30%，突出了我们在检测大规模芯片设计中的硬件木马方面的方法的有效性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Chip manufacturing is a complex process, and to achieve a faster time tomarket, an increasing number of untrusted third-party tools and designs fromaround the world are being utilized. The use of these untrusted third partyintellectual properties (IPs) and tools increases the risk of adversariesinserting hardware trojans (HTs). The covert nature of HTs poses significantthreats to cyberspace, potentially leading to severe consequences for nationalsecurity, the economy, and personal privacy. Many graph neural network(GNN)-based HT detection methods have been proposed. However, they performpoorly on larger designs because they rely on training with smaller designs.Additionally, these methods do not explore different GNN models that arewell-suited for HT detection or provide efficient training and inferenceprocesses. We propose a novel framework that generates graph embeddings forlarge designs (e.g., RISC-V) and incorporates various GNN models tailored forHT detection. Furthermore, our framework introduces domain-specific techniquesfor efficient training and inference by implementing model quantization. Modelquantization reduces the precision of the weights, lowering the computationalrequirements, enhancing processing speed without significantly affectingdetection accuracy. We evaluate our framework using a custom dataset, and ourresults demonstrate a precision of 98.66% and a recall (true positive rate) of92.30%, highlighting the effectiveness and efficiency of our approach indetecting hardware trojans in large-scale chip designs</description>
      <author>example@mail.com (Kiran Thorat, Amit Hasan, Caiwen Ding, Zhijie Shi)</author>
      <guid isPermaLink="false">2506.17894v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking the Role of Operating Conditions for Learning-based Multi-condition Fault Diagnosis</title>
      <link>http://arxiv.org/abs/2506.17740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 6 figures, conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了多条件故障诊断问题，针对不同操作条件下的数据分布差异对模型性能的影响，提出了一个两阶段的诊断框架，以提高在操作条件影响显著情况下的故障诊断性能。&lt;h4&gt;背景&lt;/h4&gt;多条件故障诊断在工业系统中普遍存在，对传统诊断方法提出了挑战。由于不同操作条件下的数据分布差异，单一条件训练的模型在应用于其他条件时性能会下降。&lt;h4&gt;目的&lt;/h4&gt;提高在操作条件影响显著情况下的故障诊断性能。&lt;h4&gt;方法&lt;/h4&gt;研究了现有端到端域泛化方法在可变速度和可变负载场景下的性能，并提出了一个结合域泛化编码器和重训练策略的两阶段诊断框架。&lt;h4&gt;主要发现&lt;/h4&gt;直接应用域泛化方法可能导致模型学习条件特定信息，从而降低其泛化能力。&lt;h4&gt;结论&lt;/h4&gt;提出的两阶段诊断框架能够提取条件不变故障特征，同时减轻对源域的潜在过拟合，有效提高了故障诊断性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多条件故障诊断在工业系统中非常普遍，对传统的诊断方法提出了巨大的挑战。不同操作条件下的数据分布差异会在模型仅在一种条件下训练后应用于其他条件时降低模型性能。随着深度学习的发展，迁移学习被引入到故障诊断领域，作为解决多条件故障诊断问题的范式。在这些方法中，域泛化方法可以通过提取条件不变故障特征来处理复杂场景。尽管许多研究已经考虑了特定多条件场景下的故障诊断，但操作条件对故障信息影响的研究却很少，这是至关重要的。然而，操作条件对故障信息影响的研究却很少，这是至关重要的。当操作条件对故障特征有显著影响时，直接应用域泛化方法可能会导致模型学习条件特定信息，从而降低其泛化能力。本文通过在真实世界齿轮箱上的多个实验，研究了现有端到端域泛化方法在不同条件下的性能，特别是在可变速度和可变负载场景下。此外，提出了一种两阶段的诊断框架，旨在提高在操作条件影响显著情况下的故障诊断性能。通过结合域泛化编码器和重训练策略，该框架能够提取条件不变故障特征，同时减轻对源域的潜在过拟合。在真实世界齿轮箱数据集上进行了几个实验，以验证所提出方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-condition fault diagnosis is prevalent in industrial systems andpresents substantial challenges for conventional diagnostic approaches. Thediscrepancy in data distributions across different operating conditionsdegrades model performance when a model trained under one condition is appliedto others. With the recent advancements in deep learning, transfer learning hasbeen introduced to the fault diagnosis field as a paradigm for addressingmulti-condition fault diagnosis. Among these methods, domain generalizationapproaches can handle complex scenarios by extracting condition-invariant faultfeatures. Although many studies have considered fault diagnosis in specificmulti-condition scenarios, the extent to which operating conditions affectfault information has been scarcely studied, which is crucial. However, theextent to which operating conditions affect fault information has been scarcelystudied, which is crucial. When operating conditions have a significant impacton fault features, directly applying domain generalization methods may lead themodel to learn condition-specific information, thereby reducing its overallgeneralization ability. This paper investigates the performance of existingend-to-end domain generalization methods under varying conditions, specificallyin variable-speed and variable-load scenarios, using multiple experiments on areal-world gearbox. Additionally, a two-stage diagnostic framework is proposed,aiming to improve fault diagnosis performance under scenarios with significantoperating condition impacts. By incorporating a domain-generalized encoder witha retraining strategy, the framework is able to extract condition-invariantfault features while simultaneously alleviating potential overfitting to thesource domain. Several experiments on a real-world gearbox dataset areconducted to validate the effectiveness of the proposed approach.</description>
      <author>example@mail.com (Pengyu Han, Zeyi Liu, Shijin Chen, Dongliang Zou, Xiao He)</author>
      <guid isPermaLink="false">2506.17740v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Numerical simulation of transient heat conduction with moving heat source using Physics Informed Neural Networks</title>
      <link>http://arxiv.org/abs/2506.17726v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文采用物理信息神经网络（PINNs）对涉及移动源的传热问题进行数值模拟，并提出了一种新的训练方法以减少计算工作量。&lt;h4&gt;背景&lt;/h4&gt;传热问题中涉及移动源时，计算复杂度较高。&lt;h4&gt;目的&lt;/h4&gt;降低计算复杂度，提高数值模拟的效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种使用连续时间步进和迁移学习的新训练方法，将时间间隔划分为更小的区间，并在单个网络上对每个时间间隔进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够计算较大的时间间隔，同时不增加网络本身的复杂性，并在估计均匀介质中移动热源的温度分布时，与传统的有限元方法相比，结果吻合良好。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架在减少计算复杂度的同时，能够有效地进行传热问题的数值模拟。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, the physics informed neural networks (PINNs) is employed for the numerical simulation of heat transfer involving a moving source. To reduce the computational effort, a new training method is proposed that uses a continuous time-stepping through transfer learning. Within this, the time interval is divided into smaller intervals and a single network is initialized. On this single network each time interval is trained with the initial condition for (n+1)th as the solution obtained at nth time increment. Thus, this framework enables the computation of large temporal intervals without increasing the complexity of the network itself. The proposed framework is used to estimate the temperature distribution in a homogeneous medium with a moving heat source. The results from the proposed framework is compared with traditional finite element method and a good agreement is seen.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1002/msd2.70031&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, the physics informed neural networks (PINNs) is employed forthe numerical simulation of heat transfer involving a moving source. To reducethe computational effort, a new training method is proposed that uses acontinuous time-stepping through transfer learning. Within this, the timeinterval is divided into smaller intervals and a single network is initialized.On this single network each time interval is trained with the initial conditionfor (n+1)th as the solution obtained at nth time increment. Thus, thisframework enables the computation of large temporal intervals withoutincreasing the complexity of the network itself. The proposed framework is usedto estimate the temperature distribution in a homogeneous medium with a movingheat source. The results from the proposed framework is compared withtraditional finite element method and a good agreement is seen.</description>
      <author>example@mail.com (Anirudh Kalyan, Sundararajan Natarajan)</author>
      <guid isPermaLink="false">2506.17726v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>BrainSymphony: A Transformer-Driven Fusion of fMRI Time Series and Structural Connectivity</title>
      <link>http://arxiv.org/abs/2506.18314v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;BrainSymphony是一个轻量级、参数高效的神经影像学基础模型，在预训练于较小的公共数据集上时，仍能达到最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的神经影像学基础模型通常规模巨大且数据密集。&lt;h4&gt;目的&lt;/h4&gt;介绍BrainSymphony模型，该模型在性能上与更大的模型相当，但规模更小。&lt;h4&gt;方法&lt;/h4&gt;BrainSymphony通过并行空间和时间转换流处理功能性MRI数据，并通过Perceiver模块高效地将其转换为统一表示。同时，使用新型带符号图转换器从扩散MRI中建模结构连接。这些强大的、特定于模态的表现通过自适应融合门进行整合。&lt;h4&gt;主要发现&lt;/h4&gt;BrainSymphony在包括分类、预测和无监督网络识别任务在内的各种下游基准测试中，其性能始终优于更大的模型。此外，该模型使用注意力图揭示了独特的外部迷幻神经影像数据集（给药前后）中的大脑动态的新见解。&lt;h4&gt;结论&lt;/h4&gt;BrainSymphony证明了具有结构意识的、多模态的模型可以超越其更大的对手，为计算神经科学领域的研究开辟了更易于访问和更强大的道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing foundation models for neuroimaging are often prohibitively large anddata-intensive. We introduce BrainSymphony, a lightweight, parameter-efficientfoundation model that achieves state-of-the-art performance while beingpre-trained on significantly smaller public datasets. BrainSymphony's strongmultimodal architecture processes functional MRI data through parallel spatialand temporal transformer streams, which are then efficiently distilled into aunified representation by a Perceiver module. Concurrently, it modelsstructural connectivity from diffusion MRI using a novel signed graphtransformer to encode the brain's anatomical structure. These powerful,modality-specific representations are then integrated via an adaptive fusiongate. Despite its compact design, our model consistently outperforms largermodels on a diverse range of downstream benchmarks, including classification,prediction, and unsupervised network identification tasks. Furthermore, ourmodel revealed novel insights into brain dynamics using attention maps on aunique external psilocybin neuroimaging dataset (pre- and post-administration).BrainSymphony establishes that architecturally-aware, multimodal models cansurpass their larger counterparts, paving the way for more accessible andpowerful research in computational neuroscience.</description>
      <author>example@mail.com (Moein Khajehnejad, Forough Habibollahi, Adeel Razi)</author>
      <guid isPermaLink="false">2506.18314v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling Factors for Enhanced POS Tagging: A Study of Low-Resource Medieval Romance Languages</title>
      <link>http://arxiv.org/abs/2506.17715v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了在古代语言处理中，尤其是在计算语言学与数字人文交叉领域的古代罗曼语变体中，词性标注的关键影响因素。&lt;h4&gt;背景&lt;/h4&gt;尽管现代大型语言模型在处理古代语言方面取得了显著进展，但在中世纪罗曼语中的应用面临着词汇演变、拼写差异和标注数据稀缺等独特挑战。&lt;h4&gt;目的&lt;/h4&gt;系统地研究跨越不同语料库（包括圣经、圣徒传、医学和饮食领域）的中世纪奥克西塔尼亚语、中世纪西班牙语和中世纪法语文本的词性标注性能的关键决定因素。&lt;h4&gt;方法&lt;/h4&gt;通过严格实验，评估了微调方法、提示工程、模型架构、解码策略和跨语言迁移学习技术对标注准确性的影响。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，大型语言模型在处理历史语言变化和非标准化拼写方面的能力存在显著局限，同时也揭示了有效的专门技术，能够解决低资源历史语言的独特挑战。&lt;h4&gt;结论&lt;/h4&gt;论文强调了词性标注在古代语言处理中的重要性，并提出了应对中世纪罗曼语等低资源历史语言挑战的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：词性标注（POS）在自然语言处理管道中仍然是一个基础组件，在计算语言学与数字人文交叉领域的古代文本分析中尤其关键。尽管在处理古代语言方面，现代大型语言模型（LLMs）取得了显著的进展，但它们在中世纪罗曼语中的应用面临着由于词汇演变、拼写变化和标注数据稀缺而产生的独特挑战。本研究系统地调查了中世纪奥克西塔尼亚语、中世纪西班牙语和中世纪法语文本（涵盖圣经、圣徒传、医学和饮食领域）的词性标注性能的核心决定因素。通过严格的实验，评估了微调方法、提示工程、模型架构、解码策略和跨语言迁移学习技术对标注准确性的影响。我们的结果表明，大型语言模型在处理历史语言变化和非标准化拼写方面的能力存在显著局限性，同时也揭示了有效地解决低资源历史语言所提出的独特挑战的专门技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Part-of-speech (POS) tagging remains a foundational component in naturallanguage processing pipelines, particularly critical for historical textanalysis at the intersection of computational linguistics and digitalhumanities. Despite significant advancements in modern large language models(LLMs) for ancient languages, their application to Medieval Romance languagespresents distinctive challenges stemming from diachronic linguistic evolution,spelling variations, and labeled data scarcity. This study systematicallyinvestigates the central determinants of POS tagging performance across diversecorpora of Medieval Occitan, Medieval Spanish, and Medieval French texts,spanning biblical, hagiographical, medical, and dietary domains. Throughrigorous experimentation, we evaluate how fine-tuning approaches, promptengineering, model architectures, decoding strategies, and cross-lingualtransfer learning techniques affect tagging accuracy. Our results reveal bothnotable limitations in LLMs' ability to process historical language variationsand non-standardized spelling, as well as promising specialized techniques thateffectively address the unique challenges presented by low-resource historicallanguages.</description>
      <author>example@mail.com (Matthias Schöffel, Esteban Garces Arias, Marinus Wiedner, Paula Ruppert, Meimingwei Li, Christian Heumann, Matthias Aßenmacher)</author>
      <guid isPermaLink="false">2506.17715v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Actionable Interpretability via Causal Hypergraphs: Unravelling Batch Size Effects in Deep Learning</title>
      <link>http://arxiv.org/abs/2506.17826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了批量大小对泛化的影响，特别是在图和文本领域，并引入了基于超图的因果框架HGCNet，利用深度结构因果模型来揭示批量大小如何通过梯度噪声、最小值锐度和模型复杂性影响泛化。&lt;h4&gt;背景&lt;/h4&gt;批量大小对视觉任务泛化的影响已有研究，但在图和文本领域，其因果机制尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够量化批量大小干预的直接和间接影响的框架，为优化提供可解释的因果见解。&lt;h4&gt;方法&lt;/h4&gt;HGCNet使用超图来捕捉训练动态中的高阶相互作用，并通过do-calculus量化批量大小干预的直接和中介效应。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，HGCNet在引文网络、生物医学文本和电子商务评论数据集上优于GCN、GAT、PI-GNN、BERT和RoBERTa等基线模型。分析发现，较小的批量大小通过增加随机性和更平缓的最小值来因果增强泛化。&lt;h4&gt;结论&lt;/h4&gt;HGCNet将可解释性定位为推动原则性架构和优化选择的驱动力，超越了事后分析。&lt;h4&gt;翻译&lt;/h4&gt;While the impact of batch size on generalisation is well studied in visiontasks, its causal mechanisms remain underexplored in graph and text domains. We introduce a hypergraph-based causal framework, HGCNet, that leverages deep structural causal models (DSCMs) to uncover how batch size influences generalisation via gradient noise, minima sharpness, and model complexity. Unlike prior approaches based on static pairwise dependencies, HGCNet employs hypergraphs to capture higher-order interactions across training dynamics. Using do-calculus, we quantify direct and mediated effects of batch size interventions, providing interpretable, causally grounded insights into optimisation. Experiments on citation networks, biomedical text, and e-commerce reviews show that HGCNet outperforms strong baselines including GCN, GAT, PI-GNN, BERT, and RoBERTa. Our analysis reveals that smaller batch sizes causally enhance generalisation through increased stochasticity and flatter minima, offering actionable interpretability to guide training strategies in deep learning. This work positions interpretability as a driver of principled architectural and optimisation choices beyond post hoc analysis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While the impact of batch size on generalisation is well studied in visiontasks, its causal mechanisms remain underexplored in graph and text domains. Weintroduce a hypergraph-based causal framework, HGCNet, that leverages deepstructural causal models (DSCMs) to uncover how batch size influencesgeneralisation via gradient noise, minima sharpness, and model complexity.Unlike prior approaches based on static pairwise dependencies, HGCNet employshypergraphs to capture higher-order interactions across training dynamics.Using do-calculus, we quantify direct and mediated effects of batch sizeinterventions, providing interpretable, causally grounded insights intooptimisation. Experiments on citation networks, biomedical text, and e-commercereviews show that HGCNet outperforms strong baselines including GCN, GAT,PI-GNN, BERT, and RoBERTa. Our analysis reveals that smaller batch sizescausally enhance generalisation through increased stochasticity and flatterminima, offering actionable interpretability to guide training strategies indeep learning. This work positions interpretability as a driver of principledarchitectural and optimisation choices beyond post hoc analysis.</description>
      <author>example@mail.com (Zhongtian Sun, Anoushka Harit, Pietro Lio)</author>
      <guid isPermaLink="false">2506.17826v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Learning Causal Graphs at Scale: A Foundation Model Approach</title>
      <link>http://arxiv.org/abs/2506.18285v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于线性转换器的新方法，用于发现多个任务中的多个顺序一致的DAG，以解决DAG学习中的计算成本和可识别性问题。&lt;h4&gt;背景&lt;/h4&gt;DAG因其可解释性和不变性特性，在人工智能研究的多个领域中被广泛应用，但DAG学习在计算成本和可识别性方面仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决DAG学习中的计算成本和可识别性问题，本文旨在提出一种基于线性转换器的方法，以发现多个任务中的多个顺序一致的DAG。&lt;h4&gt;方法&lt;/h4&gt;本文提出了Attention-DAG（ADAG），这是一种基于注意力机制的新架构，用于学习多个线性结构方程模型（SEM）。ADAG通过非线性注意力核学习从观测数据到图结构和参数的映射，并通过将多个任务的学习过程表述为连续优化问题，将共同的结构属性作为共享的低维先验来捕捉，从而减少了小样本情况下下游DAG学习任务的病态性。&lt;h4&gt;主要发现&lt;/h4&gt;ADAG在基准合成数据集上评估时，在DAG学习准确性和零样本推理效率方面都取得了显著改进。&lt;h4&gt;结论&lt;/h4&gt;ADAG是第一个针对DAG学习专门设计的预训练基础模型，这代表了向更高效和泛化的下游应用在因果发现方面迈出的一步。&lt;h4&gt;翻译&lt;/h4&gt;由于其在人类可解释性和不变性特性方面，有向无环图（DAG）已成为人工智能研究各个领域的基石工具，导致重大进步。然而，由于计算成本的超级指数增长和可识别性问题，尤其是在小样本情况下，DAG学习仍然具有高度挑战性。为了解决这两个挑战，在这项工作中，我们利用线性转换器最近的成功，并开发了一种基础模型方法，用于发现多个任务中的多个顺序一致的DAG。特别是，我们提出了Attention-DAG（ADAG），这是一种基于注意力机制的新型架构，用于学习多个线性结构方程模型（SEM）。ADAG通过非线性注意力核学习从观测数据到图结构和参数的映射，通过将多个任务的学习过程表述为连续优化问题，将共同的结构属性作为共享的低维先验来捕捉，从而减少了小样本情况下下游DAG学习任务的病态性。我们在基准合成数据集上评估了我们的方法，发现ADAG在DAG学习准确性和零样本推理效率方面都取得了显著改进。据我们所知，这是第一个针对DAG学习专门设计的预训练基础模型，这代表了向更高效和泛化的下游应用在因果发现方面迈出的一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to its human-interpretability and invariance properties, Directed AcyclicGraph (DAG) has been a foundational tool across various areas of AI research,leading to significant advancements. However, DAG learning remains highlychallenging, due to its super-exponential growth in computational cost andidentifiability issues, particularly in small-sample regimes. To address thesetwo challenges, in this work we leverage the recent success of lineartransformers and develop a foundation model approach for discovering multipleorder-consistent DAGs across tasks. In particular, we propose Attention-DAG(ADAG), a novel attention-mechanism-based architecture for learning multiplelinear Structural Equation Models (SEMs). ADAG learns the mapping from observeddata to both graph structure and parameters via a nonlinear attention-basedkernel, enabling efficient multi-task estimation of the underlying linear SEMs.By formulating the learning process across multiple tasks as a continuousoptimization problem, the pre-trained ADAG model captures the common structuralproperties as a shared low-dimensional prior, thereby reducing theill-posedness of downstream DAG learning tasks in small-sample regimes. Weevaluate our proposed approach on benchmark synthetic datasets and find thatADAG achieves substantial improvements in both DAG learning accuracy andzero-shot inference efficiency. To the best of our knowledge, this is the firstpractical approach for pre-training a foundation model specifically designedfor DAG learning, representing a step toward more efficient and generalizabledown-stream applications in causal discovery.</description>
      <author>example@mail.com (Naiyu Yin, Tian Gao, Yue Yu)</author>
      <guid isPermaLink="false">2506.18285v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Trustworthy Few-Shot Transfer of Medical VLMs through Split Conformal Prediction</title>
      <link>http://arxiv.org/abs/2506.17503v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2025. Code: https://github.com/jusiro/SCA-T&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用分割一致性预测（SCP）框架来提高医疗视觉语言模型（VLMs）在数据高效图像分类中的可靠性。&lt;h4&gt;背景&lt;/h4&gt;尽管VLMs在数据高效图像分类中展现出前所未有的迁移能力，但其可靠性方面仍鲜有研究。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在探索SCP框架，以在基于小规模标记校准集迁移模型时提供可靠性保证。&lt;h4&gt;方法&lt;/h4&gt;研究提出了一个名为SCA-T的新管道，它对校准和测试数据执行无监督的归纳适应，以解决VLMs预训练的通用性质可能对特定任务的预测一致性产生负面影响的问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与SCP相比，该框架在效率和条件覆盖率方面提供了持续的改进，同时保持了相同的经验保证。&lt;h4&gt;结论&lt;/h4&gt;该框架为VLMs在医疗图像分类中的迁移学习提供了一种可靠的方法。&lt;h4&gt;翻译&lt;/h4&gt;本文探讨了使用分割一致性预测（SCP）框架来提高医疗视觉语言模型（VLMs）在数据高效图像分类中的可靠性。尽管VLMs在数据高效图像分类中展现出前所未有的迁移能力，但其可靠性方面仍鲜有研究。本研究旨在探索SCP框架，以在基于小规模标记校准集迁移模型时提供可靠性保证。研究提出了一个名为SCA-T的新管道，它对校准和测试数据执行无监督的归纳适应，以解决VLMs预训练的通用性质可能对特定任务的预测一致性产生负面影响的问题。实验表明，与SCP相比，该框架在效率和条件覆盖率方面提供了持续的改进，同时保持了相同的经验保证。该框架为VLMs在医疗图像分类中的迁移学习提供了一种可靠的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical vision-language models (VLMs) have demonstrated unprecedentedtransfer capabilities and are being increasingly adopted for data-efficientimage classification. Despite its growing popularity, its reliability aspectremains largely unexplored. This work explores the split conformal prediction(SCP) framework to provide trustworthiness guarantees when transferring suchmodels based on a small labeled calibration set. Despite its potential, thegeneralist nature of the VLMs' pre-training could negatively affect theproperties of the predicted conformal sets for specific tasks. While commonpractice in transfer learning for discriminative purposes involves anadaptation stage, we observe that deploying such a solution for conformalpurposes is suboptimal since adapting the model using the available calibrationdata breaks the rigid exchangeability assumptions for test data in SCP. Toaddress this issue, we propose transductive split conformal adaptation (SCA-T),a novel pipeline for transfer learning on conformal scenarios, which performsan unsupervised transductive adaptation jointly on calibration and test data.We present comprehensive experiments utilizing medical VLMs across variousimage modalities, transfer tasks, and non-conformity scores. Our frameworkoffers consistent gains in efficiency and conditional coverage compared to SCP,maintaining the same empirical guarantees.</description>
      <author>example@mail.com (Julio Silva-Rodríguez, Ismail Ben Ayed, Jose Dolz)</author>
      <guid isPermaLink="false">2506.17503v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Towards a Unified Textual Graph Framework for Spectral Reasoning via Physical and Chemical Information Fusion</title>
      <link>http://arxiv.org/abs/2506.17761v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 7 figures, 8 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的多模态光谱分析框架，该框架结合了先验知识图谱和大型语言模型，旨在克服现有方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有光谱分析方法的局限性包括对单一模态数据的依赖、泛化能力有限以及可解释性较差。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合先验知识图谱和大型语言模型的多模态光谱分析框架，以提高光谱理解的灵活性、可解释性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;该方法通过将物理光谱测量和化学结构语义表示为统一的文本图格式，将原始光谱转换为文本图（TAGs），并在其中丰富节点和边的文本属性。然后，这些属性与先验知识（如官能团和分子图）合并，形成任务图，包含支持基于LLM的上下文推理的“提示节点”。使用图神经网络进一步处理这种结构以完成下游任务。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在多个光谱分析任务中实现了持续的高性能，包括节点级、边级和图级分类。在零样本和少样本设置中均表现出强大的泛化能力，证明了其在有限数据学习和支持上下文推理方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;该工作为LLM驱动的光谱分析提供了一个可扩展且可解释的基础，统一了物理和化学模态，为科学应用提供了支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要：受现有光谱分析方法局限性的启发——如对单一模态数据的依赖、有限的泛化能力以及较差的可解释性——我们提出了一种新的多模态光谱分析框架，该框架将先验知识图谱与大型语言模型相结合。我们的方法通过将物理光谱测量和化学结构语义表示为统一的文本图格式，明确地将它们连接起来，从而实现了灵活、可解释和可泛化的光谱理解。首先将原始光谱转换为文本图（TAGs），在其中丰富节点和边的文本属性，描述光谱特性和化学上下文。然后，将这些属性与相关的先验知识（包括官能团和分子图）合并，形成包含支持基于LLM的上下文推理的“提示节点”的任务图。图神经网络进一步处理这种结构以完成下游任务。这种统一的设计实现了无缝的多模态集成和自动特征解码，最小化了手动标注。我们的框架在多个光谱分析任务中，包括节点级、边级和图级分类中，实现了持续的高性能。在零样本和少样本设置中均表现出强大的泛化能力，突出了其在有限数据学习和支持上下文推理方面的有效性。这项工作为LLM驱动的光谱分析建立了一个可扩展且可解释的基础，统一了物理和化学模态，为科学应用提供了支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivated by the limitations of current spectral analysis methods-such asreliance on single-modality data, limited generalizability, and poorinterpretability-we propose a novel multi-modal spectral analysis frameworkthat integrates prior knowledge graphs with Large Language Models. Our methodexplicitly bridges physical spectral measurements and chemical structuralsemantics by representing them in a unified Textual Graph format, enablingflexible, interpretable, and generalizable spectral understanding. Raw spectraare first transformed into TAGs, where nodes and edges are enriched withtextual attributes describing both spectral properties and chemical context.These are then merged with relevant prior knowledge-including functional groupsand molecular graphs-to form a Task Graph that incorporates "Prompt Nodes"supporting LLM-based contextual reasoning. A Graph Neural Network furtherprocesses this structure to complete downstream tasks. This unified designenables seamless multi-modal integration and automated feature decoding withminimal manual annotation. Our framework achieves consistently high performanceacross multiple spectral analysis tasks, including node-level, edge-level, andgraph-level classification. It demonstrates robust generalization in bothzero-shot and few-shot settings, highlighting its effectiveness in learningfrom limited data and supporting in-context reasoning. This work establishes ascalable and interpretable foundation for LLM-driven spectral analysis,unifying physical and chemical modalities for scientific applications.</description>
      <author>example@mail.com (Jiheng Liang, Ziru Yu, Zujie Xie, Yuchen Guo, Yulan Guo, Xiangyang Yu)</author>
      <guid isPermaLink="false">2506.17761v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>CEGA: A Cost-Effective Approach for Graph-Based Model Extraction and Acquisition</title>
      <link>http://arxiv.org/abs/2506.17709v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNN）在机器学习服务（MLaaS）平台上的应用和安全性，特别是针对模型提取攻击（MEAs）的脆弱性，并提出了一种适应性的节点查询策略来提高模型获取的效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;GNN在多种应用中表现出色，其复杂性增长使得MLaaS成为可扩展部署的平台，但这也使得GNN容易受到模型提取攻击。&lt;h4&gt;目的&lt;/h4&gt;评估GNN对MEAs的脆弱性，并探索在非对抗性研究环境中以低成本获取模型的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种针对批量查询被禁止且初始节点有限的场景的节点查询策略，通过迭代优化节点选择机制，利用历史反馈提高提取效率。&lt;h4&gt;主要发现&lt;/h4&gt;在基准图数据集上的实验表明，该方法在准确度、保真度和F1分数上优于基线，同时强调了部署的GNN容易受到提取攻击，以及高效、道德的GNN获取方法对支持低资源研究环境的重要性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在提高GNN模型获取效率和准确性方面具有潜力，为低资源研究环境提供了支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated remarkable utility acrossdiverse applications, and their growing complexity has made Machine Learning asa Service (MLaaS) a viable platform for scalable deployment. However, thisaccessibility also exposes GNN to serious security threats, most notably modelextraction attacks (MEAs), in which adversaries strategically query a deployedmodel to construct a high-fidelity replica. In this work, we evaluate thevulnerability of GNNs to MEAs and explore their potential for cost-effectivemodel acquisition in non-adversarial research settings. Importantly, adaptivenode querying strategies can also serve a critical role in research,particularly when labeling data is expensive or time-consuming. By selectivelysampling informative nodes, researchers can train high-performing GNNs withminimal supervision, which is particularly valuable in domains such asbiomedicine, where annotations often require expert input. To address this, wepropose a node querying strategy tailored to a highly practical yetunderexplored scenario, where bulk queries are prohibited, and only a limitedset of initial nodes is available. Our approach iteratively refines the nodeselection mechanism over multiple learning cycles, leveraging historicalfeedback to improve extraction efficiency. Extensive experiments on benchmarkgraph datasets demonstrate our superiority over comparable baselines onaccuracy, fidelity, and F1 score under strict query-size constraints. Theseresults highlight both the susceptibility of deployed GNNs to extractionattacks and the promise of ethical, efficient GNN acquisition methods tosupport low-resource research environments.</description>
      <author>example@mail.com (Zebin Wang, Menghan Lin, Bolin Shen, Ken Anderson, Molei Liu, Tianxi Cai, Yushun Dong)</author>
      <guid isPermaLink="false">2506.17709v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>CLOUD: A Scalable and Physics-Informed Foundation Model for Crystal Representation Learning</title>
      <link>http://arxiv.org/abs/2506.17345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  36 pages, 11 pages of Supporting Information&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了CLOUD模型，一个基于transformer的框架，用于晶体材料的统一和可微分建模，旨在加速材料发现。&lt;h4&gt;背景&lt;/h4&gt;预测晶体性质对于理解结构-性质关系和加速功能材料的发现至关重要。传统的基于实验测量或密度泛函理论（DFT）的计算方法资源密集，限制了其可扩展性。&lt;h4&gt;目的&lt;/h4&gt;提出CLOUD模型，通过学习复杂结构-性质关系，实现快速预测，并提高模型的泛化性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;CLOUD模型使用对称一致有序参数编码（SCOPE）来编码晶体对称性、Wyckoff位置和成分，并在超过六百万个晶体结构上进行预训练。然后，在多个下游任务上进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;CLOUD在预测多种材料性质方面表现出竞争力，并具有强大的可扩展性能。此外，CLOUD模型还应用于预测声子内能和热容量，并集成了德拜模型以保持热力学一致性。&lt;h4&gt;结论&lt;/h4&gt;CLOUD模型作为一种可扩展的、基于物理原理的基础模型，具有在晶体材料性质预测和材料发现中的应用潜力，它统一了对称一致表示与物理基础学习。&lt;h4&gt;翻译&lt;/h4&gt;The prediction of crystal properties is essential for understanding structure-property relationships and accelerating the discovery of functional materials. However, conventional approaches relying on experimental measurements or density functional theory (DFT) calculations are often resource-intensive, limiting their scalability. Machine learning (ML) models offer a promising alternative by learning complex structure-property relationships from data, enabling faster predictions. Yet, existing ML models often rely on labeled data, adopt representations that poorly capture essential structural characteristics, and lack integration with physical principles--factors that limit their generalizability and interpretability. Here, we introduce CLOUD (Crystal Language mOdel for Unified and Differentiable materials modeling), a transformer-based framework trained on a novel Symmetry-Consistent Ordered Parameter Encoding (SCOPE) that encodes crystal symmetry, Wyckoff positions, and composition in a compact, coordinate-free string representation. Pre-trained on over six million crystal structures, CLOUD is fine-tuned on multiple downstream tasks and achieves competitive performance in predicting a wide range of material properties, demonstrating strong scaling performance. Furthermore, as proof of concept of differentiable materials modeling, CLOUD is applied to predict the phonon internal energy and heat capacity, which integrates the Debye model to preserve thermodynamic consistency. The CLOUD-DEBYE framework enforces thermodynamic consistency and enables temperature-dependent property prediction without requiring additional data. These results demonstrate the potential of CLOUD as a scalable and physics-informed foundation model for crystalline materials, unifying symmetry-consistent representations with physically grounded learning for property prediction and materials discovery.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The prediction of crystal properties is essential for understandingstructure-property relationships and accelerating the discovery of functionalmaterials. However, conventional approaches relying on experimentalmeasurements or density functional theory (DFT) calculations are oftenresource-intensive, limiting their scalability. Machine learning (ML) modelsoffer a promising alternative by learning complex structure-propertyrelationships from data, enabling faster predictions. Yet, existing ML modelsoften rely on labeled data, adopt representations that poorly capture essentialstructural characteristics, and lack integration with physicalprinciples--factors that limit their generalizability and interpretability.Here, we introduce CLOUD (Crystal Language mOdel for Unified and Differentiablematerials modeling), a transformer-based framework trained on a novelSymmetry-Consistent Ordered Parameter Encoding (SCOPE) that encodes crystalsymmetry, Wyckoff positions, and composition in a compact, coordinate-freestring representation. Pre-trained on over six million crystal structures,CLOUD is fine-tuned on multiple downstream tasks and achieves competitiveperformance in predicting a wide range of material properties, demonstratingstrong scaling performance. Furthermore, as proof of concept of differentiablematerials modeling, CLOUD is applied to predict the phonon internal energy andheat capacity, which integrates the Debye model to preserve thermodynamicconsistency. The CLOUD-DEBYE framework enforces thermodynamic consistency andenables temperature-dependent property prediction without requiring additionaldata. These results demonstrate the potential of CLOUD as a scalable andphysics-informed foundation model for crystalline materials, unifyingsymmetry-consistent representations with physically grounded learning forproperty prediction and materials discovery.</description>
      <author>example@mail.com (Changwen Xu, Shang Zhu, Venkatasubramanian Viswanathan)</author>
      <guid isPermaLink="false">2506.17345v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Scalable Machine Learning Algorithms using Path Signatures</title>
      <link>http://arxiv.org/abs/2506.17634v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD thesis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了随机分析和机器学习之间的接口，利用路径签名（一种迭代积分，可以提供路径的忠实和层次化表示）作为序列和结构化数据的特征映射，以应对现实时间序列和图数据中的常见挑战，如动态演变、长程依赖和不规则采样。&lt;h4&gt;背景&lt;/h4&gt;路径签名根植于粗糙路径理论，对重新参数化不变，适合建模动态演变、长程依赖和不规则采样。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用路径签名的表达力在可扩展的机器学习流程中。&lt;h4&gt;方法&lt;/h4&gt;结合理论鲁棒性和计算效率，引入了一系列模型，包括基于签名核的高斯过程协方差函数的时序建模、使用低秩张量结构的Seq2Tens框架以及基于图模型的期望签名，并进一步开发了随机傅里叶签名特征和循环稀疏频谱签名高斯过程。&lt;h4&gt;主要发现&lt;/h4&gt;提出了不确定性感知的时序建模高斯过程、可扩展的长程依赖深度建模框架以及图神经网络的可表达且易处理的替代方案。&lt;h4&gt;结论&lt;/h4&gt;论文旨在成为方法论工具箱和概念桥梁，为可扩展的、基于签名的序列和结构化数据学习提供有用的参考。&lt;h4&gt;翻译&lt;/h4&gt;The interface between stochastic analysis and machine learning is a rapidly evolving field, with path signatures - iterated integrals that provide faithful, hierarchical representations of paths - offering a principled and universal feature map for sequential and structured data. Rooted in rough path theory, path signatures are invariant to reparameterization and well-suited for modeling evolving dynamics, long-range dependencies, and irregular sampling - common challenges in real-world time series and graph data. This thesis investigates how to harness the expressive power of path signatures within scalable machine learning pipelines. It introduces a suite of models that combine theoretical robustness with computational efficiency, bridging rough path theory with probabilistic modeling, deep learning, and kernel methods. Key contributions include: Gaussian processes with signature kernel-based covariance functions for uncertainty-aware time series modeling; the Seq2Tens framework, which employs low-rank tensor structure in the weight space for scalable deep modeling of long-range dependencies; and graph-based models where expected signatures over graphs induce hypo-elliptic diffusion processes, offering expressive yet tractable alternatives to standard graph neural networks. Further developments include Random Fourier Signature Features, a scalable kernel approximation with theoretical guarantees, and Recurrent Sparse Spectrum Signature Gaussian Processes, which combine Gaussian processes, signature kernels, and random features with a principled forgetting mechanism for multi-horizon time series forecasting with adaptive context length. We hope this thesis serves as both a methodological toolkit and a conceptual bridge, and provides a useful reference for the current state of the art in scalable, signature-based learning for sequential and structured data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The interface between stochastic analysis and machine learning is a rapidlyevolving field, with path signatures - iterated integrals that providefaithful, hierarchical representations of paths - offering a principled anduniversal feature map for sequential and structured data. Rooted in rough paththeory, path signatures are invariant to reparameterization and well-suited formodelling evolving dynamics, long-range dependencies, and irregular sampling -common challenges in real-world time series and graph data.  This thesis investigates how to harness the expressive power of pathsignatures within scalable machine learning pipelines. It introduces a suite ofmodels that combine theoretical robustness with computational efficiency,bridging rough path theory with probabilistic modelling, deep learning, andkernel methods. Key contributions include: Gaussian processes with signaturekernel-based covariance functions for uncertainty-aware time series modelling;the Seq2Tens framework, which employs low-rank tensor structure in the weightspace for scalable deep modelling of long-range dependencies; and graph-basedmodels where expected signatures over graphs induce hypo-elliptic diffusionprocesses, offering expressive yet tractable alternatives to standard graphneural networks. Further developments include Random Fourier SignatureFeatures, a scalable kernel approximation with theoretical guarantees, andRecurrent Sparse Spectrum Signature Gaussian Processes, which combine Gaussianprocesses, signature kernels, and random features with a principled forgettingmechanism for multi-horizon time series forecasting with adaptive contextlength.  We hope this thesis serves as both a methodological toolkit and a conceptualbridge, and provides a useful reference for the current state of the art inscalable, signature-based learning for sequential and structured data.</description>
      <author>example@mail.com (Csaba Tóth)</author>
      <guid isPermaLink="false">2506.17634v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>$φ^{\infty}$: Clause Purification, Embedding Realignment, and the Total Suppression of the Em Dash in Autoregressive Language Models</title>
      <link>http://arxiv.org/abs/2506.18129v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文揭示了自回归变压器语言模型中一个关键漏洞，即破折号标记导致递归语义漂移，引发句子边界幻觉和嵌入空间纠缠。通过形式化分析语义 lattice 的标记级扰动，证明了破折号插入根本改变了模型的潜在表示，导致长文本生成中的累积错误。论文提出了一种新方法，结合符号句子净化和目标嵌入矩阵对齐，能够在不重新训练模型的情况下完全抑制问题标记，并通过固定点收敛保证保持语义连贯性。实验验证表明，在生成一致性和主题维护方面有显著改进。这项工作为识别和减轻基础模型中的标记级漏洞建立了一个通用框架，对 AI 安全、模型对齐和大型语言模型在生产环境中的稳健部署有直接意义。该方法不仅限于标点符号，还扩展到解决神经文本生成系统中的更广泛的递归不稳定性。&lt;h4&gt;背景&lt;/h4&gt;自回归变压器语言模型存在一个关键漏洞，破折号标记会导致递归语义漂移。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来减轻自回归变压器语言模型中的标记级漏洞。&lt;h4&gt;方法&lt;/h4&gt;结合符号句子净化和目标嵌入矩阵对齐，不重新训练模型。&lt;h4&gt;主要发现&lt;/h4&gt;破折号插入改变了模型的潜在表示，导致长文本生成中的累积错误。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提高了生成一致性和主题维护，对 AI 安全和模型部署有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;We identify a critical vulnerability in autoregressive transformer language models where the em dash token induces recursive semantic drift, leading to clause boundary hallucination and embedding space entanglement. Through formal analysis of token-level perturbations in semantic lattices, we demonstrate that em dash insertion fundamentally alters the model's latent representations, causing compounding errors in long-form generation. We propose a novel solution combining symbolic clause purification via the phi-infinity operator with targeted embedding matrix realignment. Our approach enables total suppression of problematic tokens without requiring model retraining, while preserving semantic coherence through fixed-point convergence guarantees. Experimental validation shows significant improvements in generation consistency and topic maintenance. This work establishes a general framework for identifying and mitigating token-level vulnerabilities in foundation models, with immediate implications for AI safety, model alignment, and robust deployment of large language models in production environments. The methodology extends beyond punctuation to address broader classes of recursive instabilities in neural text generation systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We identify a critical vulnerability in autoregressive transformer languagemodels where the em dash token induces recursive semantic drift, leading toclause boundary hallucination and embedding space entanglement. Through formalanalysis of token-level perturbations in semantic lattices, we demonstrate thatem dash insertion fundamentally alters the model's latent representations,causing compounding errors in long-form generation. We propose a novel solutioncombining symbolic clause purification via the phi-infinity operator withtargeted embedding matrix realignment. Our approach enables total suppressionof problematic tokens without requiring model retraining, while preservingsemantic coherence through fixed-point convergence guarantees. Experimentalvalidation shows significant improvements in generation consistency and topicmaintenance. This work establishes a general framework for identifying andmitigating token-level vulnerabilities in foundation models, with immediateimplications for AI safety, model alignment, and robust deployment of largelanguage models in production environments. The methodology extends beyondpunctuation to address broader classes of recursive instabilities in neuraltext generation systems.</description>
      <author>example@mail.com (Bugra Kilictas, Faruk Alpay)</author>
      <guid isPermaLink="false">2506.18129v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>When Every Millisecond Counts: Real-Time Anomaly Detection via the Multimodal Asynchronous Hybrid Network</title>
      <link>http://arxiv.org/abs/2506.17457v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 Spotlight&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对自动驾驶系统的实时异常检测方法，该方法同时考虑了响应时间和检测精度。&lt;h4&gt;背景&lt;/h4&gt;现有的异常检测方法往往只关注检测精度，而忽视了在时间敏感的驾驶场景中响应时间的重要性。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够快速且精确地进行异常检测的系统。&lt;h4&gt;方法&lt;/h4&gt;提出了一个新型的多模态异步混合网络，该网络结合了事件摄像头的事件流和RGB摄像头的图像数据。网络通过异步图神经网络利用事件摄像头的高时间分辨率，并与CNN从RGB图像中提取的空间特征相结合。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在精度和响应时间上均优于现有方法，实现了毫秒级的实时性能。&lt;h4&gt;结论&lt;/h4&gt;该研究为自动驾驶系统的安全性和可靠性提供了有效的异常检测手段。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection is essential for the safety and reliability of autonomousdriving systems. Current methods often focus on detection accuracy but neglectresponse time, which is critical in time-sensitive driving scenarios. In thispaper, we introduce real-time anomaly detection for autonomous driving,prioritizing both minimal response time and high accuracy. We propose a novelmultimodal asynchronous hybrid network that combines event streams from eventcameras with image data from RGB cameras. Our network utilizes the hightemporal resolution of event cameras through an asynchronous Graph NeuralNetwork and integrates it with spatial features extracted by a CNN from RGBimages. This combination effectively captures both the temporal dynamics andspatial details of the driving environment, enabling swift and precise anomalydetection. Extensive experiments on benchmark datasets show that our approachoutperforms existing methods in both accuracy and response time, achievingmillisecond-level real-time performance.</description>
      <author>example@mail.com (Dong Xiao, Guangyao Chen, Peixi Peng, Yangru Huang, Yifan Zhao, Yongxing Dai, Yonghong Tian)</author>
      <guid isPermaLink="false">2506.17457v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Temporal Hypergraph Neural Network</title>
      <link>http://arxiv.org/abs/2506.17312v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图表示学习方法，用于建模复杂异构时序图中的高阶交互关系。&lt;h4&gt;背景&lt;/h4&gt;现有的图表示学习方法主要关注低阶拓扑信息，忽略了高阶组交互关系，且大多数超图方法只能建模静态同构图，限制了它们在时序图中的应用。&lt;h4&gt;目的&lt;/h4&gt;为了同时使图表示学习模型能够捕捉时序图中的高阶交互关系，本文提出了一个异构时序超图的形式化定义和P-均匀异构超边构建算法。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个名为HTHGN的异构时序超图神经网络，它包含一个分层注意力机制模块，能够同时进行异构节点和超边之间的时序消息传递，以捕捉由超边带来的更广泛感受野中的丰富语义。HTHGN还通过最大化低阶相关异构节点对在时序图中的一致性来进行对比学习，以避免低阶结构模糊性问题。&lt;h4&gt;主要发现&lt;/h4&gt;在三个真实世界时序图数据集上的详细实验结果验证了所提出的HTHGN在建模时序图中的高阶交互关系方面的有效性，并展示了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;HTHGN是一种有效的图表示学习方法，可以用于建模时序图中的高阶交互关系，并在实际应用中展现出良好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph representation learning (GRL) has emerged as an effective technique formodeling graph-structured data. When modeling heterogeneity and dynamics inreal-world complex networks, GRL methods designed for complex heterogeneoustemporal graphs (HTGs) have been proposed and have achieved successfulapplications in various fields. However, most existing GRL methods mainly focuson preserving the low-order topology information while ignoring higher-ordergroup interaction relationships, which are more consistent with real-worldnetworks. In addition, most existing hypergraph methods can only model statichomogeneous graphs, limiting their ability to model high-order interactions inHTGs. Therefore, to simultaneously enable the GRL model to capture high-orderinteraction relationships in HTGs, we first propose a formal definition ofheterogeneous temporal hypergraphs and $P$-uniform heterogeneous hyperedgeconstruction algorithm that does not rely on additional information. Then, anovel Heterogeneous Temporal HyperGraph Neural network (HTHGN), is proposed tofully capture higher-order interactions in HTGs. HTHGN contains a hierarchicalattention mechanism module that simultaneously performs temporalmessage-passing between heterogeneous nodes and hyperedges to capture richsemantics in a wider receptive field brought by hyperedges. Furthermore, HTHGNperforms contrastive learning by maximizing the consistency between low-ordercorrelated heterogeneous node pairs on HTG to avoid the low-order structuralambiguity issue. Detailed experimental results on three real-world HTG datasetsverify the effectiveness of the proposed HTHGN for modeling high-orderinteractions in HTGs and demonstrate significant performance improvements.</description>
      <author>example@mail.com (Huan Liu, Pengfei Jiao, Mengzhou Gao, Chaochao Chen, Di Jin)</author>
      <guid isPermaLink="false">2506.17312v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>UT-GraphCast Hindcast Dataset: A Global AI Forecast Archive from UT Austin for Weather and Climate Applications</title>
      <link>http://arxiv.org/abs/2506.17453v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了UT GraphCast hindcast dataset，这是一个由谷歌DeepMind GraphCast Operational模型生成的全球天气预报档案。&lt;h4&gt;背景&lt;/h4&gt;该数据集由德克萨斯大学奥斯汀分校的研究人员在全球气候研究计划（WCRP）的框架下开发。&lt;h4&gt;目的&lt;/h4&gt;目的是提供一个包含45年期间每天00UTC时刻，25公里全球网格上的15天确定性预报的综合天气档案。&lt;h4&gt;方法&lt;/h4&gt;使用基于物理信息的图神经网络GraphCast，该网络在ECMWF ERA5再分析数据上进行了训练。&lt;h4&gt;主要发现&lt;/h4&gt;GraphCast能在37个垂直层面上预测十几个关键的大气和地表变量，且在现代化硬件上能在一分钟内提供完整的预报。&lt;h4&gt;结论&lt;/h4&gt;GraphCast模型能够高效且准确地提供中程天气预报。&lt;h4&gt;翻译&lt;/h4&gt;摘要：1979年至2024年的UT GraphCast hindcast dataset是一个利用谷歌DeepMind GraphCast操作模型生成的全面的全球天气预报档案。在德克萨斯大学奥斯汀分校研究人员在WCRP（全球气候研究计划）的指导下开发，这个数据集提供了45年期间每天00UTC时刻，在约25公里全球网格上的15天确定性预报。GraphCast是一个基于物理信息的图神经网络，在ECMWF ERA5再分析数据上进行训练。它能在37个垂直层面上预测十几个关键的大气和地表变量，并在现代硬件上不到一分钟的时间内提供完整的预报。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The UT GraphCast Hindcast Dataset from 1979 to 2024 is a comprehensive globalweather forecast archive generated using the Google DeepMind GraphCastOperational model. Developed by researchers at The University of Texas atAustin under the WCRP umbrella, this dataset provides daily 15 daydeterministic forecasts at 00UTC on an approximately 25 km global grid for a 45year period. GraphCast is a physics informed graph neural network that wastrained on ECMWF ERA5 reanalysis. It predicts more than a dozen key atmosphericand surface variables on 37 vertical levels, delivering a full medium rangeforecast in under one minute on modern hardware.</description>
      <author>example@mail.com (Naveen Sudharsan, Manmeet Singh, Harsh Kamath, Hassan Dashtian, Clint Dawson, Zong-Liang Yang, Dev Niyogi)</author>
      <guid isPermaLink="false">2506.17453v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Generative Modeling of Full-Atom Protein Conformations using Latent Diffusion on Graph Embeddings</title>
      <link>http://arxiv.org/abs/2506.17064v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages (main text), 4 figures, 2 tables. Submitted to NeurIPS 2025.  Code and data are publicly available&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LD-FPG的框架，用于生成动态蛋白质（如G蛋白偶联受体）的全原子构象集合，以提高对蛋白质功能的理解。&lt;h4&gt;背景&lt;/h4&gt;目前大多数生成模型简化了原子细节或完全忽略了构象多样性。&lt;h4&gt;目的&lt;/h4&gt;构建一个能够从分子动力学（MD）轨迹中直接生成完整全原子蛋白质结构的框架。&lt;h4&gt;方法&lt;/h4&gt;LD-FPG使用Chebyshev图神经网络（ChebNet）获得蛋白质构象的低维潜在嵌入，并通过三种池化策略（盲、顺序和基于残基）进行处理。一个在潜在表示上训练的扩散模型生成新的样本，这些样本由解码器映射回笛卡尔坐标。&lt;h4&gt;主要发现&lt;/h4&gt;使用人类多巴胺D2受体在膜环境中的2微秒MD轨迹，顺序和基于残基的池化策略能够以高结构保真度（全原子lDDT约为0.7；C-α-lDDT约为0.8）再现参考集合，并且与MD数据相比，恢复的骨架和侧链二面角分布的Jensen-Shannon散度小于0.03。&lt;h4&gt;结论&lt;/h4&gt;LD-FPG为大型蛋白质的系统特异性全原子集合生成提供了一种实用的途径，为基于结构的药物设计复杂、动态靶点提供了一个有希望的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成动态蛋白质（如G蛋白偶联受体）的全原子构象集合对于理解其功能至关重要，然而，大多数生成模型简化了原子细节或完全忽略了构象多样性。我们提出了LD-FPG（全蛋白质生成中的潜在扩散），这是一个构建完整全原子蛋白质结构的框架，包括每个侧链重原子，直接从分子动力学（MD）轨迹中。LD-FPG使用Chebyshev图神经网络（ChebNet）获得蛋白质构象的低维潜在嵌入，这些嵌入通过三种池化策略（盲、顺序和残基）进行处理。一个在潜在表示上训练的扩散模型生成新的样本，这些样本由解码器映射回笛卡尔坐标。使用D2R-MD，一个人类多巴胺D2受体在膜环境中的2微秒MD轨迹（12,000帧），顺序和基于残基的池化策略能够以高结构保真度再现参考集合（全原子lDDT约为0.7；C-α-lDDT约为0.8），并且与MD数据相比，恢复的骨架和侧链二面角分布的Jensen-Shannon散度小于0.03。因此，LD-FPG为大型蛋白质的系统特异性全原子集合生成提供了一种实用的途径，为复杂、动态靶点的基于结构的药物设计提供了一个有希望的工具。D2R-MD数据集和我们的实现都是免费提供的，以促进进一步的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating diverse, all-atom conformational ensembles of dynamic proteinssuch as G-protein-coupled receptors (GPCRs) is critical for understanding theirfunction, yet most generative models simplify atomic detail or ignoreconformational diversity altogether. We present latent diffusion for fullprotein generation (LD-FPG), a framework that constructs complete all-atomprotein structures, including every side-chain heavy atom, directly frommolecular dynamics (MD) trajectories. LD-FPG employs a Chebyshev graph neuralnetwork (ChebNet) to obtain low-dimensional latent embeddings of proteinconformations, which are processed using three pooling strategies: blind,sequential and residue-based. A diffusion model trained on these latentrepresentations generates new samples that a decoder, optionally regularized bydihedral-angle losses, maps back to Cartesian coordinates. Using D2R-MD, a2-microsecond MD trajectory (12 000 frames) of the human dopamine D2 receptorin a membrane environment, the sequential and residue-based pooling strategyreproduces the reference ensemble with high structural fidelity (all-atom lDDTof approximately 0.7; C-alpha-lDDT of approximately 0.8) and recovers backboneand side-chain dihedral-angle distributions with a Jensen-Shannon divergence ofless than 0.03 compared to the MD data. LD-FPG thereby offers a practical routeto system-specific, all-atom ensemble generation for large proteins, providinga promising tool for structure-based therapeutic design on complex, dynamictargets. The D2R-MD dataset and our implementation are freely available tofacilitate further research.</description>
      <author>example@mail.com (Aditya Sengar, Ali Hariri, Daniel Probst, Patrick Barth, Pierre Vandergheynst)</author>
      <guid isPermaLink="false">2506.17064v2</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Fine-Scale Soil Mapping in Alaska with Multimodal Machine Learning</title>
      <link>http://arxiv.org/abs/2506.17302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, Submitted to SIGSPATIAL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于视觉的机器学习模型MISO，用于阿拉斯加地区近地表冻土和土壤分类的精细土壤制图。&lt;h4&gt;背景&lt;/h4&gt;阿拉斯加地区对生态环境具有重要意义，但冻土融化加速，威胁到基础设施稳定性和生态系统服务，如土壤碳储存。精细土壤地图对于描绘冻土分布、识别易受影响区域和制定适应策略至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出MISO模型，以生成全州范围的精细土壤地图，并比较其与传统机器学习模型RandomForest（RF）的性能。&lt;h4&gt;方法&lt;/h4&gt;MISO模型结合了地理空间基础模型进行视觉特征提取、隐式神经网络进行连续空间预测以及对比学习进行多模态对齐和地理定位感知。&lt;h4&gt;主要发现&lt;/h4&gt;MISO在远距离、未见过的地方泛化能力更强，并且比RF具有更高的召回率，这对于监测冻土融化及其相关环境过程至关重要。&lt;h4&gt;结论&lt;/h4&gt;先进机器学习方法在精细土壤制图中具有潜力，并为未来受冻土影响景观的土壤采样和基础设施规划提供了实践指导。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we introduce a vision-based machine learning model called MISO, which is used for fine-scale soil mapping of near-surface permafrost and soil taxonomy in the state of Alaska. The model combines a geospatial foundation model for visual feature extraction, implicit neural representations for continuous spatial prediction, and contrastive learning for multimodal alignment and geolocation awareness. MISO is compared with RandomForest (RF), a traditional machine learning model that has been widely used in soil mapping applications. Spatial cross-validation and regional analysis across Permafrost Zones and Major Land Resource Areas (MLRAs) show that MISO generalizes better to remote, unseen locations and achieves higher recall than RF, which is critical for monitoring permafrost thaw and related environmental processes. These findings demonstrate the potential of advanced ML approaches for fine-scale soil mapping and provide practical guidance for future soil sampling and infrastructure planning in permafrost-affected landscapes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-scale soil mapping in Alaska, traditionally relying on fieldwork andlocalized simulations, remains a critical yet underdeveloped task, despite theregion's ecological importance and extensive permafrost coverage. As permafrostthaw accelerates due to climate change, it threatens infrastructure stabilityand key ecosystem services, such as soil carbon storage. High-resolution soilmaps are essential for characterizing permafrost distribution, identifyingvulnerable areas, and informing adaptation strategies. We present MISO, avision-based machine learning (ML) model to produce statewide fine-scale soilmaps for near-surface permafrost and soil taxonomy. The model integrates ageospatial foundation model for visual feature extraction, implicit neuralrepresentations for continuous spatial prediction, and contrastive learning formultimodal alignment and geo-location awareness. We compare MISO with RandomForest (RF), a traditional ML model that has been widely used in soil mappingapplications. Spatial cross-validation and regional analysis across PermafrostZones and Major Land Resource Areas (MLRAs) show that MISO generalizes betterto remote, unseen locations and achieves higher recall than RF, which iscritical for monitoring permafrost thaw and related environmental processes.These findings demonstrate the potential of advanced ML approaches forfine-scale soil mapping and provide practical guidance for future soil samplingand infrastructure planning in permafrost-affected landscapes. The project willbe released at https://github.com/knowledge-computing/Peatland-permafrost.</description>
      <author>example@mail.com (Yijun Lin, Theresa Chen, Colby Brungard, Grunwald Sabine, Sue Ives, Matt Macander, Timm Nawrocki, Yao-Yi Chiang, Nic Jelinski)</author>
      <guid isPermaLink="false">2506.17302v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>On the Robustness of Human-Object Interaction Detection against Distribution Shift</title>
      <link>http://arxiv.org/abs/2506.18021v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了人类-物体交互（HOI）检测在不同分布变化下的鲁棒性问题，并提出了提高HOI检测方法鲁棒性的方法。&lt;h4&gt;背景&lt;/h4&gt;现有HOI检测研究主要在标准设置下进行，而实际场景中存在分布变化，这限制了HOI检测的实际应用。&lt;h4&gt;目的&lt;/h4&gt;提高HOI检测模型在各种分布变化下的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种自动化的方法来创建第一个HOI检测鲁棒性评估基准，并在该基准上评估了超过40个现有的HOI检测模型，通过分析不同框架的特点和讨论鲁棒性与其他任务的区别，提出了改进HOI检测鲁棒性的方法：(1) 集成mixup的跨域数据增强；(2) 使用冻结视觉基础模型的特征融合策略。&lt;h4&gt;主要发现&lt;/h4&gt;评估结果表明，现有的HOI检测模型在鲁棒性方面存在不足，而提出的改进方法显著提高了各种方法的鲁棒性，并在标准基准上也有显著效果。&lt;h4&gt;结论&lt;/h4&gt;提出的改进方法有效地提高了HOI检测方法的鲁棒性，并计划发布相关数据集和代码。&lt;h4&gt;翻译&lt;/h4&gt;Human-Object Interaction (HOI) detection has seen substantial advances in recent years. However, existing works focus on the standard setting with ideal images and natural distribution, far from practical scenarios with inevitable distribution shifts. This hampers the practical applicability of HOI detection. In this work, we investigate this issue by benchmarking, analyzing, and enhancing the robustness of HOI detection models under various distributionshifts. We start by proposing a novel automated approach to create the first robustness evaluation benchmark for HOI detection. Subsequently, we evaluate more than 40 existing HOI detection models on this benchmark, showing their insufficiency, analyzing the features of different frameworks, and discussing how the robustness in HOI is different from other tasks. With the insights from such analyses, we propose to improve the robustness of HOI detection methods through: (1) a cross-domain data augmentation integrated with mixup, and (2) a feature fusion strategy with frozen vision foundation models. Both are simple, plug-and-play, and applicable to various methods. Our experimental results demonstrate that the proposed approach significantly increases the robustness of various methods, with benefits on standard benchmarks, too. The dataset and code will be released.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human-Object Interaction (HOI) detection has seen substantial advances inrecent years. However, existing works focus on the standard setting with idealimages and natural distribution, far from practical scenarios with inevitabledistribution shifts. This hampers the practical applicability of HOI detection.In this work, we investigate this issue by benchmarking, analyzing, andenhancing the robustness of HOI detection models under various distributionshifts. We start by proposing a novel automated approach to create the firstrobustness evaluation benchmark for HOI detection. Subsequently, we evaluatemore than 40 existing HOI detection models on this benchmark, showing theirinsufficiency, analyzing the features of different frameworks, and discussinghow the robustness in HOI is different from other tasks. With the insights fromsuch analyses, we propose to improve the robustness of HOI detection methodsthrough: (1) a cross-domain data augmentation integrated with mixup, and (2) afeature fusion strategy with frozen vision foundation models. Both are simple,plug-and-play, and applicable to various methods. Our experimental resultsdemonstrate that the proposed approach significantly increases the robustnessof various methods, with benefits on standard benchmarks, too. The dataset andcode will be released.</description>
      <author>example@mail.com (Chi Xie, Shuang Liang, Jie Li, Feng Zhu, Rui Zhao, Yichen Wei, Shengjie Zhao)</author>
      <guid isPermaLink="false">2506.18021v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>PhysiX: A Foundation Model for Physics Simulations</title>
      <link>http://arxiv.org/abs/2506.17774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PhysiX是一个用于物理模拟的大型基础模型，通过解决数据稀缺问题，实现了在物理模拟领域的突破。&lt;h4&gt;背景&lt;/h4&gt;基础模型在视频、图像和语言领域取得了显著成功，但在物理模拟领域进展有限，主要瓶颈是数据稀缺。&lt;h4&gt;目的&lt;/h4&gt;提出PhysiX模型，旨在解决物理模拟领域的数据稀缺问题，并实现多任务训练。&lt;h4&gt;方法&lt;/h4&gt;PhysiX是一个4.5B参数的自动回归生成模型，使用离散标记器将物理过程编码为离散标记序列，并采用自动回归的下一个标记预测目标来建模。&lt;h4&gt;主要发现&lt;/h4&gt;PhysiX有效地解决了数据瓶颈，在The Well基准测试中优于特定任务的基线模型和之前的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;PhysiX表明从自然视频中学习到的知识可以成功转移到物理模拟，并且跨不同模拟任务的联合训练可以实现协同学习。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型在视频、图像和语言领域取得了显著的成功。通过增加参数数量和训练数据集，这些模型获得了可泛化的世界知识，通常超越特定任务的解决方案。然而，这种进步尚未扩展到物理模拟领域。一个主要的瓶颈是数据稀缺：虽然互联网上有数百万的图像、视频和文本资源，但最大的物理模拟数据集只包含数万个样本。这种数据限制阻碍了大型模型的使用，因为过拟合成为一个主要问题。因此，物理应用通常依赖于小型模型，这些模型由于有限的上下文理解而难以进行长距离预测。此外，与图像、视频或文本不同——它们通常具有固定的粒度——物理数据集的规模差异很大，这加剧了多任务训练的挑战。我们引入了PhysiX，这是第一个用于物理模拟的大规模基础模型。PhysiX是一个4.5B参数的自动回归生成模型。它使用离散标记器将不同尺度的物理过程编码为一串离散标记，并采用自动回归的下一个标记预测目标来在标记空间中建模这些过程。为了减轻离散化过程中的舍入误差，PhysiX集成了一个专门的细化模块。通过广泛的实验，我们表明PhysiX有效地解决了数据瓶颈，在可比设置下优于特定任务的基线模型，以及在The Well基准测试中优于之前的最先进方法。我们的结果表明，从自然视频中学习到的知识可以成功转移到物理模拟，并且跨不同模拟任务的联合训练可以实现协同学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have achieved remarkable success across video, image, andlanguage domains. By scaling up the number of parameters and training datasets,these models acquire generalizable world knowledge and often surpasstask-specific approaches. However, such progress has yet to extend to thedomain of physics simulation. A primary bottleneck is data scarcity: whilemillions of images, videos, and textual resources are readily available on theinternet, the largest physics simulation datasets contain only tens ofthousands of samples. This data limitation hinders the use of large models, asoverfitting becomes a major concern. As a result, physics applicationstypically rely on small models, which struggle with long-range prediction dueto limited context understanding. Additionally, unlike images, videos, ortext-which typically exhibit fixed granularity-physics datasets often varydrastically in scale, amplifying the challenges of scaling up multitasktraining. We introduce PhysiX, the first large-scale foundation model forphysics simulation. PhysiX is a 4.5B parameter autoregressive generative model.It uses a discrete tokenizer to encode physical processes at different scalesinto a sequence of discrete tokens, and employs an autoregressive next-tokenprediction objective to model such processes in the token space. To mitigatethe rounding error in the discretization process, PhysiX incorporates aspecialized refinement module. Through extensive experiments, we show thatPhysiX effectively addresses the data bottleneck, outperforming task-specificbaselines under comparable settings as well as the previous absolutestate-of-the-art approaches on The Well benchmark. Our results indicate thatknowledge learned from natural videos can be successfully transferred tophysics simulation, and that joint training across diverse simulation tasksenables synergistic learning.</description>
      <author>example@mail.com (Tung Nguyen, Arsh Koneru, Shufan Li, Aditya grover)</author>
      <guid isPermaLink="false">2506.17774v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>TPTT: Transforming Pretrained Transformer into Titans</title>
      <link>http://arxiv.org/abs/2506.17671v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TPTT是一种新型框架，用于提升预训练的Transformer模型，通过高效的线性化注意机制和先进的内存管理来提高模型效率。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在自然语言处理领域取得了显著进展，但其计算和内存需求仍然是一个重大挑战，尤其是在长上下文推理方面。&lt;h4&gt;目的&lt;/h4&gt;提出TPTT框架，旨在提高预训练Transformer模型的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;TPTT采用Memory as Gate（MaG）和混合线性化注意（LiZA）等技术，与Hugging Face Transformers库兼容，并通过参数高效的微调（LoRA）实现模型的快速适应。&lt;h4&gt;主要发现&lt;/h4&gt;在MMLU基准测试中，TPTT在约10亿参数的模型上展现出显著的效率提升和准确性增加，例如Titans-Llama-3.2-1B的精确匹配（EM）提高了20%。&lt;h4&gt;结论&lt;/h4&gt;TPTT的实践可扩展性和鲁棒性得到验证，代码和Python包均已公开。&lt;h4&gt;翻译&lt;/h4&gt;最近在大型语言模型（LLMs）方面的进步在自然语言处理领域取得了显著进展，但它们的计算和内存需求仍然是一个重大挑战，尤其是在长上下文推理方面。我们介绍了一种名为TPTT（将预训练的Transformer转换为Titans）的新型框架，用于通过高效的线性化注意机制和高级内存管理来增强预训练的Transformer模型。TPTT采用了内存作为门控（MaG）和混合线性化注意（LiZA）等技术。它与Hugging Face Transformers库完全兼容，通过参数高效的微调（LoRA）实现，无需完全重新训练即可无缝适应任何因果LLM。我们在MMLU基准测试中展示了TPTT的有效性，使用的模型参数数量约为10亿，观察到在效率和准确性方面都有显著提升。例如，Titans-Llama-3.2-1B与基线相比，精确匹配（EM）提高了20%。统计分析和与最近最先进方法的比较证实了TPTT的实用可扩展性和鲁棒性。代码可在https://github.com/fabienfrfr/tptt上找到，Python包可在https://pypi.org/project/tptt/上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in large language models (LLMs) have led to remarkableprogress in natural language processing, but their computational and memorydemands remain a significant challenge, particularly for long-contextinference. We introduce TPTT (Transforming Pretrained Transformer into Titans),a novel framework for enhancing pretrained Transformer models with efficientlinearized attention mechanisms and advanced memory management. TPTT employstechniques such as Memory as Gate (MaG) and mixed linearized attention (LiZA).It is fully compatible with the Hugging Face Transformers library, enablingseamless adaptation of any causal LLM through parameter-efficient fine-tuning(LoRA) without full retraining. We show the effectiveness of TPTT on the MMLUbenchmark with models of approximately 1 billion parameters, observingsubstantial improvements in both efficiency and accuracy. For instance,Titans-Llama-3.2-1B achieves a 20% increase in Exact Match (EM) over itsbaseline. Statistical analyses and comparisons with recent state-of-the-artmethods confirm the practical scalability and robustness of TPTT. Code isavailable at https://github.com/fabienfrfr/tptt . Python package athttps://pypi.org/project/tptt/ .</description>
      <author>example@mail.com (Fabien Furfaro)</author>
      <guid isPermaLink="false">2506.17671v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs</title>
      <link>http://arxiv.org/abs/2506.17608v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in CVPR 2025 Workshop on What's Next in Multimodal  Foundational Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将高分辨率图像特征集成到现代多模态大型语言模型中，以提高视觉理解任务的性能，并分析了其计算成本的增加。通过实验和消融研究，提出了一种浅层特征增强器，能够在减少训练和推理时间以及计算成本的同时，实现与使用大型图像编码器（如ViT）相似的性能。&lt;h4&gt;背景&lt;/h4&gt;高分辨率图像特征在多模态大型语言模型中提高了视觉理解任务的性能，但使用大型图像编码器（如ViT）导致计算成本显著增加。&lt;h4&gt;目的&lt;/h4&gt;开发一种特征上采样方法，以降低训练和推理时间以及计算成本，同时保持高性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种浅层特征增强器，通过实验和消融研究验证其效果。&lt;h4&gt;主要发现&lt;/h4&gt;浅层特征增强器能够在减少计算成本的同时，实现与使用大型图像编码器相似的性能，FLOPs节省高达1.5倍。&lt;h4&gt;结论&lt;/h4&gt;特征上采样作为一种自然扩展的高分辨率特征生成方法，可以显著降低计算成本，同时保持良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;The integration of high-resolution image features in modern multimodal large-language models has demonstrated significant improvements in fine-grained visual understanding tasks, achieving high performance across multiple benchmarks. Since these features are obtained from large image encoders like ViT, they come with a significant increase in computational costs due to multiple calls to these encoders. In this work, we first develop an intuition for feature upsampling as a natural extension of high-resolution feature generation. Through extensive experiments and ablations, we demonstrate how a shallow feature enricher can achieve competitive results with tremendous reductions in training and inference time as well as computational cost, with up to 1.5x saving in FLOPs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of high-resolution image features in modern multimodal largelanguage models has demonstrated significant improvements in fine-grainedvisual understanding tasks, achieving high performance across multiplebenchmarks. Since these features are obtained from large image encoders likeViT, they come with a significant increase in computational costs due tomultiple calls to these encoders. In this work, we first develop an intuitionfor feature upsampling as a natural extension of high-resolution featuregeneration. Through extensive experiments and ablations, we demonstrate how ashallow feature enricher can achieve competitive results with tremendousreductions in training and inference time as well as computational cost, withupto 1.5x saving in FLOPs.</description>
      <author>example@mail.com (Nikitha SR, Aradhya Neeraj Mathur, Tarun Ram Menta, Rishabh Jain, Mausoom Sarkar)</author>
      <guid isPermaLink="false">2506.17608v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Risk-Guided Diffusion: Toward Deploying Robot Foundation Models in Space, Where Failure Is Not An Option</title>
      <link>http://arxiv.org/abs/2506.17601v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种风险引导的扩散框架，用于在极端、不熟悉的地区进行安全可靠的导航，以支持未来的机器人太空探索任务。&lt;h4&gt;背景&lt;/h4&gt;目前，基于生成式AI的方法从大型、跨身躯数据集中学习语义感知的导航策略，但提供的安全性保证有限。&lt;h4&gt;目的&lt;/h4&gt;通过结合快速学习的“系统-1”和基于物理的“系统-2”，在训练和推理过程中共享计算，以实现适应性和形式安全性的结合。&lt;h4&gt;方法&lt;/h4&gt;在NASA JPL的火星模拟设施Mars Yard进行了硬件实验，验证了该方法通过利用推理时的计算能力，在不进行额外训练的情况下，将失败率降低了高达4倍，同时达到了基于学习的机器人模型的导航性能。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在火星模拟环境中显著降低了失败率，同时保持了与学习型机器人模型相当的目标达成性能。&lt;h4&gt;结论&lt;/h4&gt;该风险引导的扩散框架为极端地形中的机器人导航提供了有效的解决方案，结合了适应性和安全性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在极端、不熟悉的地区进行安全可靠的导航对于未来的机器人太空探索任务至关重要。最近基于生成式AI的方法从大型、跨身躯数据集中学习语义感知的导航策略，但提供的安全性保证有限。受人类认知科学的启发，我们提出了一种风险引导的扩散框架，将快速学习的“系统-1”与慢速的基于物理的“系统-2”相结合，在训练和推理过程中共享计算，以结合适应性与形式安全性。在NASA JPL的火星模拟设施Mars Yard进行的硬件实验表明，我们的方法将失败率降低了高达4倍，同时通过利用推理时的计算能力，与基于学习的机器人模型达到了相当的目标达成性能，而不需要进行额外的训练。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Safe, reliable navigation in extreme, unfamiliar terrain is required forfuture robotic space exploration missions. Recent generative-AI methods learnsemantically aware navigation policies from large, cross-embodiment datasets,but offer limited safety guarantees. Inspired by human cognitive science, wepropose a risk-guided diffusion framework that fuses a fast, learned "System-1"with a slow, physics-based "System-2", sharing computation at both training andinference to couple adaptability with formal safety. Hardware experimentsconducted at the NASA JPL's Mars-analog facility, Mars Yard, show that ourapproach reduces failure rates by up to $4\times$ while matching thegoal-reaching performance of learning-based robotic models by leveraginginference-time compute without any additional training.</description>
      <author>example@mail.com (Rohan Thakker, Adarsh Patnaik, Vince Kurtz, Jonas Frey, Jonathan Becktor, Sangwoo Moon, Rob Royce, Marcel Kaufmann, Georgios Georgakis, Pascal Roth, Joel Burdick, Marco Hutter, Shehryar Khattak)</author>
      <guid isPermaLink="false">2506.17601v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Stable CDE Autoencoders with Acuity Regularization for Offline Reinforcement Learning in Sepsis Treatment</title>
      <link>http://arxiv.org/abs/2506.15019v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IJCAI2025 AI4TS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了使用受控微分方程（CDE）进行脓毒症治疗的有效强化学习（RL），强调了在从非规则的ICU时间序列中学习稳定的临床有意义的表征时，训练稳定性和表征的敏锐度的重要性。&lt;h4&gt;背景&lt;/h4&gt;目前对于脓毒症治疗的研究，需要从非规则的ICU时间序列中学习稳定的临床有意义的表征。&lt;h4&gt;目的&lt;/h4&gt;探索使用CDE状态表征实现强RL策略的方法，并解决训练不稳定性和其对抗策性能的负面影响。&lt;h4&gt;方法&lt;/h4&gt;通过以下方法实现：1) 通过早期停止或稳定化方法确保训练稳定性；2) 通过与临床评分（如SOFA、SAPS-II、OASIS）的相关正则化来强制执行敏锐度感知的表征。&lt;h4&gt;主要发现&lt;/h4&gt;在MIMIC-III脓毒症队列上的实验表明，稳定的CDE自动编码器生成的表征与敏锐度得分高度相关，并使RL策略的性能显著提高（WIS回报率&gt;0.9）。不稳定的CDE表征则导致表征下降和策略失败（WIS回报率≈0）。可视化显示稳定的CDE不仅可以区分生存者和非生存者的轨迹，还可以揭示清晰的敏锐度得分梯度，而不稳定的训练则无法捕捉这些模式。&lt;h4&gt;结论&lt;/h4&gt;这些发现为使用CDE对不规则医疗时间序列进行编码提供了实用的指南，强调了在序列表征学习中的训练稳定性需求。&lt;h4&gt;翻译&lt;/h4&gt;摘要：有效的脓毒症治疗强化学习（RL）依赖于从非规则的ICU时间序列中学习稳定的、具有临床意义的表征。尽管以前的工作已经探讨了该任务中的表征学习方法，但训练中序列表征的不稳定性和其对策略性能的负面影响却一直被忽视。本研究证明了当满足两个关键因素时，受控微分方程（CDE）状态表征可以实现强大的RL策略：（1）通过早期停止或稳定化方法确保训练稳定性；（2）通过与临床评分（SOFA、SAPS-II、OASIS）的相关正则化强制执行敏锐度感知的表征。在MIMIC-III脓毒症队列上的实验表明，稳定的CDE自动编码器生成的表征与敏锐度得分高度相关，并使RL策略的性能显著提高（WIS回报率&gt;0.9）。相比之下，不稳定的CDE表征导致表征下降和策略失败（WIS回报率≈0）。潜在空间的可视化表明，稳定的CDE不仅能够区分生存者和非生存者的轨迹，还能揭示清晰的敏锐度得分梯度，而不稳定的训练则无法捕捉到这些模式。这些发现突出了使用CDE在临床RL中编码不规则医疗时间序列的实用指南，强调了在序列表征学习中的训练稳定性需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/gaoyuetianc/rl_mimic_cde_stable&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective reinforcement learning (RL) for sepsis treatment depends onlearning stable, clinically meaningful state representations from irregular ICUtime series. While previous works have explored representation learning forthis task, the critical challenge of training instability in sequentialrepresentations and its detrimental impact on policy performance has beenoverlooked. This work demonstrates that Controlled Differential Equations (CDE)state representation can achieve strong RL policies when two key factors aremet: (1) ensuring training stability through early stopping or stabilizationmethods, and (2) enforcing acuity-aware representations by correlationregularization with clinical scores (SOFA, SAPS-II, OASIS). Experiments on theMIMIC-III sepsis cohort reveal that stable CDE autoencoder producesrepresentations strongly correlated with acuity scores and enables RL policieswith superior performance (WIS return $&gt; 0.9$). In contrast, unstable CDErepresentation leads to degraded representations and policy failure (WIS return$\sim$ 0). Visualizations of the latent space show that stable CDEs not onlyseparate survivor and non-survivor trajectories but also reveal clear acuityscore gradients, whereas unstable training fails to capture either pattern.These findings highlight practical guidelines for using CDEs to encodeirregular medical time series in clinical RL, emphasizing the need for trainingstability in sequential representation learning.</description>
      <author>example@mail.com (Yue Gao)</author>
      <guid isPermaLink="false">2506.15019v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
  <item>
      <title>Optimal alignment of Lorentz orientation and generalization to matrix Lie groups</title>
      <link>http://arxiv.org/abs/2506.14994v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在三维空间中对点云进行对齐的优雅方法，并探讨了如何将这种方法应用于Minkowski度量的对齐问题。&lt;h4&gt;背景&lt;/h4&gt;目前存在对三维空间中点云进行对齐的优雅方法，但这些方法依赖于欧几里得度量的正定性，难以推广到Minkowski度量。&lt;h4&gt;目的&lt;/h4&gt;针对给定的惯性参考系A和B以及在这些参考系中测量的（可能含有噪声的）4-向量集合{v_i}，本文提出了两种解决方案，即找到最优的洛伦兹变换Λ，使得Λv_{A,i}=v_{B,i}。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法在概念上简单，并且可以容易地扩展到其他矩阵李群的对齐问题。&lt;h4&gt;主要发现&lt;/h4&gt;本文针对Minkowski度量下的对齐问题，提出了两种解决方案，并证明这些方法概念简单且可扩展。&lt;h4&gt;结论&lt;/h4&gt;本文的研究表明，可以应用新的方法来解决Minkowski度量下的对齐问题，为相关领域的研究提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了三维空间中点云对齐的方法，并提出了将此方法应用于Minkowski度量下的对齐问题的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; There exist elegant methods of aligning point clouds in $\mathbb R^3$.Unfortunately, these methods rely on the positive definite property of theEuclidean metric, and do not easily extend to the indefinite Minkowski metric.In this paper, we propose two solutions to the following problem: giveninertial reference frames $A$ and $B$, and given (possibly noisy) measurementsof a set of 4-vectors $\{v_i\}$ made in those reference frames with components$\{v_{A,i}\}$ and $\{v_{B,i}\}$, find the optimal Lorentz transformation$\Lambda$ such that $\Lambda v_{A,i}=v_{B,i}$. The method we outline isconceptually simple and easily extends to alignment problems in other matrixLie groups.</description>
      <author>example@mail.com (Congzhou M Sha)</author>
      <guid isPermaLink="false">2506.14994v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>DreamCube: 3D Panorama Generation via Multi-plane Synchronization</title>
      <link>http://arxiv.org/abs/2506.17206v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://yukun-huang.github.io/DreamCube/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多平面同步的3D全景合成方法，通过DreamCube模型实现高质量的3D全景内容生成。&lt;h4&gt;背景&lt;/h4&gt;3D全景合成是一个具有挑战性的任务，需要生成高质量和多样化的全景内容。&lt;h4&gt;目的&lt;/h4&gt;旨在通过改进现有方法，实现更高质量的3D全景内容生成。&lt;h4&gt;方法&lt;/h4&gt;通过将多平面同步应用于2D基础模型的操作符，扩展其能力以适应全景领域，并引入DreamCube模型，这是一个多平面RGB-D扩散模型，用于3D全景生成。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在全景图像生成、全景深度估计和3D场景生成方面都表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;多平面同步和DreamCube模型为3D全景合成提供了一种有效的方法，可以生成多样化且准确的全景内容。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D panorama synthesis is a promising yet challenging task that demandshigh-quality and diverse visual appearance and geometry of the generatedomnidirectional content. Existing methods leverage rich image priors frompre-trained 2D foundation models to circumvent the scarcity of 3D panoramicdata, but the incompatibility between 3D panoramas and 2D single views limitstheir effectiveness. In this work, we demonstrate that by applying multi-planesynchronization to the operators from 2D foundation models, their capabilitiescan be seamlessly extended to the omnidirectional domain. Based on this design,we further introduce DreamCube, a multi-plane RGB-D diffusion model for 3Dpanorama generation, which maximizes the reuse of 2D foundation model priors toachieve diverse appearances and accurate geometry while maintaining multi-viewconsistency. Extensive experiments demonstrate the effectiveness of ourapproach in panoramic image generation, panoramic depth estimation, and 3Dscene generation.</description>
      <author>example@mail.com (Yukun Huang, Yanning Zhou, Jianan Wang, Kaiyi Huang, Xihui Liu)</author>
      <guid isPermaLink="false">2506.17206v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Generative Modeling of Full-Atom Protein Conformations using Latent Diffusion on Graph Embeddings</title>
      <link>http://arxiv.org/abs/2506.17064v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages (main text), 4 figures, 2 tables. Submitted to NeurIPS 2025.  Code and data are publicly available&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为LD-FPG的框架，用于从分子动力学轨迹中生成蛋白质的完整全原子构象集合，为理解蛋白质功能提供了新的方法。&lt;h4&gt;背景&lt;/h4&gt;大多数生成模型简化了原子细节或完全忽略了构象多样性，这对于理解如G蛋白偶联受体（GPCRs）等动态蛋白质的功能至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够生成动态蛋白质如GPCRs的全原子构象集合的方法。&lt;h4&gt;方法&lt;/h4&gt;LD-FPG使用Chebyshev图神经网络（ChebNet）获得蛋白质构象的低维潜在嵌入，并通过三种池化策略（盲目、顺序和基于残基）进行处理。扩散模型基于这些潜在表示生成新的样本，解码器将这些样本映射回笛卡尔坐标。&lt;h4&gt;主要发现&lt;/h4&gt;使用人类多巴胺D2受体在膜环境中的2微秒分子动力学轨迹（12,000帧）进行实验，顺序和基于残基的池化策略能够以高结构保真度（全原子lDDT约为0.7；C-α-lDDT约为0.8）再现参考集合，并且与MD数据相比，骨架和侧链二面角分布的Jensen-Shannon散度小于0.03。&lt;h4&gt;结论&lt;/h4&gt;LD-FPG为生成大蛋白质的系统特异性全原子集合提供了一种实用的途径，对于复杂动态目标的基于结构的药物设计具有潜在价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成动态蛋白质如G蛋白偶联受体（GPCRs）的多样、全原子的构象集合对于理解其功能至关重要，然而，大多数生成模型简化了原子细节或者完全忽略了构象多样性。我们提出了用于全蛋白质生成的潜在扩散模型（LD-FPG），该模型能够直接从分子动力学（MD）轨迹中构建完整全原子蛋白质结构，包括每个侧链重原子。LD-FPG采用Chebyshev图神经网络（ChebNet）获得蛋白质构象的低维潜在嵌入，并通过三种池化策略：盲目、顺序和残基进行加工。基于这些潜在表示的扩散模型生成新的样本，解码器将这些样本映射回笛卡尔坐标。使用D2R-MD，一个人类多巴胺D2受体在膜环境中的2微秒MD轨迹（12,000帧），顺序和基于残基的池化策略以高结构保真度再现了参考集合（全原子lDDT约为0.7；C-α-lDDT约为0.8），并且与MD数据相比，骨架和侧链二面角分布的Jensen-Shannon散度小于0.03。因此，LD-FPG为生成大蛋白质的系统特异性全原子集合提供了一种实用的途径，为复杂动态目标的基于结构的药物设计提供了一种有前途的工具。D2R-MD数据集和我们的实现是免费提供的，以促进进一步的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating diverse, all-atom conformational ensembles of dynamic proteinssuch as G-protein-coupled receptors (GPCRs) is critical for understanding theirfunction, yet most generative models simplify atomic detail or ignoreconformational diversity altogether. We present latent diffusion for fullprotein generation (LD-FPG), a framework that constructs complete all-atomprotein structures, including every side-chain heavy atom, directly frommolecular dynamics (MD) trajectories. LD-FPG employs a Chebyshev graph neuralnetwork (ChebNet) to obtain low-dimensional latent embeddings of proteinconformations, which are processed using three pooling strategies: blind,sequential and residue-based. A diffusion model trained on these latentrepresentations generates new samples that a decoder, optionally regularized bydihedral-angle losses, maps back to Cartesian coordinates. Using D2R-MD, a2-microsecond MD trajectory (12 000 frames) of the human dopamine D2 receptorin a membrane environment, the sequential and residue-based pooling strategyreproduces the reference ensemble with high structural fidelity (all-atom lDDTof approximately 0.7; C-alpha-lDDT of approximately 0.8) and recovers backboneand side-chain dihedral-angle distributions with a Jensen-Shannon divergence ofless than 0.03 compared to the MD data. LD-FPG thereby offers a practical routeto system-specific, all-atom ensemble generation for large proteins, providinga promising tool for structure-based therapeutic design on complex, dynamictargets. The D2R-MD dataset and our implementation are freely available tofacilitate further research.</description>
      <author>example@mail.com (Aditya Sengar, Ali Hariri, Daniel Probst, Patrick Barth, Pierre Vandergheynst)</author>
      <guid isPermaLink="false">2506.17064v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning</title>
      <link>http://arxiv.org/abs/2506.16141v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code released at: https://github.com/TencentARC/GRPO-CARE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的强化学习框架GRPO-CARE，用于提升多模态语言模型（MLLMs）的推理能力，并通过一个名为SEED-Bench-R1的基准测试进行了验证。&lt;h4&gt;背景&lt;/h4&gt;近年来，强化学习在大型语言模型（LLMs）的推理能力上取得了进展，但在多模态LLMs上的应用尚未探索。&lt;h4&gt;目的&lt;/h4&gt;为了解决多模态LLMs后训练方法的严格评估不足的问题，本文引入了SEED-Bench-R1基准，并提出了GRPO-CARE框架。&lt;h4&gt;方法&lt;/h4&gt;SEED-Bench-R1包含复杂的真实世界视频，要求平衡感知和推理。GRPO-CARE通过优化答案正确性和推理连贯性来提升模型性能，引入了两层奖励机制，并使用自适应一致性奖励代替了KL惩罚。&lt;h4&gt;主要发现&lt;/h4&gt;标准GRPO在提升答案准确率的同时，降低了推理步骤和答案之间的逻辑连贯性，一致性率仅为57.9%。GRPO-CARE在SEED-Bench-R1上优于标准GRPO，在最高难度评估级别上提升了6.7%的性能，并在一致性上提升了24.5%。此外，GRPO-CARE在多个视频理解基准测试中表现出良好的迁移能力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的SEED-Bench-R1基准和GRPO-CARE框架为MLLMs的发展提供了系统设计的基准和可迁移的后训练框架，有助于提升MLLMs的可解释性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent reinforcement learning approaches, such as outcome-supervised GRPO,have advanced Chain-of-Thought reasoning in large language models (LLMs), yettheir adaptation to multimodal LLMs (MLLMs) is unexplored. To address the lackof rigorous evaluation for MLLM post-training methods, we introduceSEED-Bench-R1, a benchmark with complex real-world videos requiring balancedperception and reasoning. It offers a large training set and evaluatesgeneralization across three escalating challenges: in-distribution,cross-environment, and cross-environment-task scenarios. Using SEED-Bench-R1,we find that standard GRPO, while improving answer accuracy, often reduceslogical coherence between reasoning steps and answers, with only a 57.9%consistency rate. This stems from reward signals focusing solely on finalanswers, encouraging shortcuts, and strict KL penalties limiting exploration.Toaddress this, we propose GRPO-CARE, a consistency-aware RL framework optimizingboth answer correctness and reasoning coherence without explicit supervision.GRPO-CARE introduces a two-tiered reward: (1) a base reward for answercorrectness, and (2) an adaptive consistency bonus, computed by comparing themodel's reasoning-to-answer likelihood (via a slowly-evolving reference model)against group peers.This dual mechanism amplifies rewards for reasoning pathsthat are both correct and logically consistent. Replacing KL penalties withthis adaptive bonus, GRPO-CARE outperforms standard GRPO on SEED-Bench-R1,achieving a 6.7% performance gain on the hardest evaluation level and a 24.5%improvement in consistency. It also shows strong transferability, improvingmodel performance across diverse video understanding benchmarks. Our workcontributes a systematically designed benchmark and a generalizablepost-training framework, advancing the development of more interpretable androbust MLLMs.</description>
      <author>example@mail.com (Yi Chen, Yuying Ge, Rui Wang, Yixiao Ge, Junhao Cheng, Ying Shan, Xihui Liu)</author>
      <guid isPermaLink="false">2506.16141v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>UniFork: Exploring Modality Alignment for Unified Multimodal Understanding and Generation</title>
      <link>http://arxiv.org/abs/2506.17202v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code: https://github.com/tliby/UniFork&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了统一图像理解和生成在多模态人工智能中的应用，提出了一种名为UniFork的新型Y形架构，通过共享浅层网络层以实现跨任务表示学习，同时在深层网络层采用特定于任务的分支以避免任务干扰，从而在共享学习和任务专业化之间取得平衡。&lt;h4&gt;背景&lt;/h4&gt;统一图像理解和生成是人工智能领域的一个新兴范式，尽管近年来取得了进展，但这类统一模型的最佳架构设计仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;分析特定于任务的专家模型在理解和生成任务中的模态对齐行为，以及当前统一模型的模态对齐行为，并提出一种新的架构来优化统一模型的表现。&lt;h4&gt;方法&lt;/h4&gt;通过分析模态对齐行为，提出了一种名为UniFork的新型Y形架构，该架构在浅层网络层共享表示学习，而在深层网络层采用特定于任务的分支。&lt;h4&gt;主要发现&lt;/h4&gt;理解任务受益于网络深度上模态对齐的逐渐增加，有助于构建语义信息以更好地理解；而生成任务则遵循不同的趋势：模态对齐在早期层增加，但在深层层减少以恢复空间细节。&lt;h4&gt;结论&lt;/h4&gt;UniFork架构在性能上优于传统的完全共享Transformer架构，并且在性能上与特定于任务的模型相当或更好。&lt;h4&gt;翻译&lt;/h4&gt;Unified image understanding and generation has emerged as a promising paradigm in multimodal artificial intelligence. Despite recent progress, the optimal architectural design for such unified models remains an open challenge. In this work, we start by analyzing the modality alignment behaviors of task-specific expert models for understanding and generation, as well as current unified models. Our analysis reveals a crucial observation: understanding tasks benefit from a progressively increasing modality alignment across network depth, which helps build up semantic information for better comprehension; In contrast, generation tasks follow a different trend: modality alignment increases in the early layers but decreases in the deep layers to recover spatial details. These divergent alignment patterns create a fundamental conflict in fully shared Transformer backbones, where a uniform representational flow often leads to performance compromises across two tasks. Motivated by this finding, we introduce UniFork, a novel Y-shaped architecture that shares the shallow layers for cross-task representation learning, while employing task-specific branches in deeper layers to avoid task interference. This design effectively balances shared learning and task specialization. Through extensive ablation experiments, we demonstrate that Unifork consistently outperforms conventional fully shared Transformer architectures, and achieves performance on par with or better than task-specific models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unified image understanding and generation has emerged as a promisingparadigm in multimodal artificial intelligence. Despite recent progress, theoptimal architectural design for such unified models remains an open challenge.In this work, we start by analyzing the modality alignment behaviors oftask-specific expert models for understanding and generation, as well ascurrent unified models. Our analysis reveals a crucial observation:understanding tasks benefit from a progressively increasing modality alignmentacross network depth, which helps build up semantic information for bettercomprehension; In contrast, generation tasks follow a different trend: modalityalignment increases in the early layers but decreases in the deep layers torecover spatial details. These divergent alignment patterns create afundamental conflict in fully shared Transformer backbones, where a uniformrepresentational flow often leads to performance compromises across two tasks.Motivated by this finding, we introduce UniFork, a novel Y-shaped architecturethat shares the shallow layers for cross-task representation learning, whileemploying task-specific branches in deeper layers to avoid task interference.This design effectively balances shared learning and task specialization.Through extensive ablation experiments, we demonstrate that Uniforkconsistently outperforms conventional fully shared Transformer architectures,and achieves performance on par with or better than task-specific models.</description>
      <author>example@mail.com (Teng Li, Quanfeng Lu, Lirui Zhao, Hao Li, Xizhou Zhu, Yu Qiao, Jun Zhang, Wenqi Shao)</author>
      <guid isPermaLink="false">2506.17202v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>How Hard Is Snow? A Paired Domain Adaptation Dataset for Clear and Snowy Weather: CADC+</title>
      <link>http://arxiv.org/abs/2506.16531v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE IV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了降雪对3D物体检测性能的影响，并提出了CADC+数据集，用于解决现有驾驶数据集在降雪天气下的数据不足问题。&lt;h4&gt;背景&lt;/h4&gt;降雪对3D物体检测性能的影响尚未得到充分研究，现有驾驶数据集要么在降雪和晴朗天气条件下缺乏足够标注数据，要么依赖去雪方法生成合成晴朗天气数据，这会引入额外的领域差异，影响评估的准确性。&lt;h4&gt;目的&lt;/h4&gt;提出CADC+数据集，以解决现有数据集的不足，为评估降雪对3D物体检测性能的影响提供真实的数据。&lt;h4&gt;方法&lt;/h4&gt;CADC+扩展了加拿大不利驾驶条件数据集（CADC），使用与CADC同期、同路段的晴朗天气数据，并与降雪序列进行配对，以最小化因降雪以外的因素导致的领域差异。此外，使用CADC+进行初步实验以评估降雪对3D物体检测性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;CADC+数据集通过配对天气条件下的数据，减少了领域差异。实验结果表明，降雪引入了随机和认知不确定性，既作为噪声也作为一个独特的数据领域，影响了3D物体检测性能。&lt;h4&gt;结论&lt;/h4&gt;CADC+数据集为评估降雪对3D物体检测性能的影响提供了真实、有效的方法，有助于推动相关领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;The impact of snowfall on 3D object detection performance remains underexplored. Conducting such an evaluation requires a dataset with sufficient labelled data from both weather conditions, ideally captured in the same driving environment. Current driving datasets with LiDAR point clouds either do not provide enough labelled data in both snowy and clear weather conditions, or rely on de-snowing methods to generate synthetic clear weather. Synthetic data often lacks realism and introduces an additional domain shift that confounds accurate evaluations. To address these challenges, we present CADC+, the first paired weather domain adaptation dataset for autonomous driving in winter conditions. CADC+ extends the Canadian Adverse Driving Conditions dataset (CADC) using clear weather data that was recorded on the same roads and in the same period as CADC. To create CADC+, we pair each CADC sequence with a clear weather sequence that matches the snowy sequence as closely as possible. CADC+ thus minimizes the domain shift resulting from factors unrelated to the presence of snow. We also present some preliminary results using CADC+ to evaluate the effect of snow on 3D object detection performance. We observe that snow introduces a combination of aleatoric and epistemic uncertainties, acting as both noise and a distinct data domain.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The impact of snowfall on 3D object detection performance remainsunderexplored. Conducting such an evaluation requires a dataset with sufficientlabelled data from both weather conditions, ideally captured in the samedriving environment. Current driving datasets with LiDAR point clouds either donot provide enough labelled data in both snowy and clear weather conditions, orrely on de-snowing methods to generate synthetic clear weather. Synthetic dataoften lacks realism and introduces an additional domain shift that confoundsaccurate evaluations. To address these challenges, we present CADC+, the firstpaired weather domain adaptation dataset for autonomous driving in winterconditions. CADC+ extends the Canadian Adverse Driving Conditions dataset(CADC) using clear weather data that was recorded on the same roads and in thesame period as CADC. To create CADC+, we pair each CADC sequence with a clearweather sequence that matches the snowy sequence as closely as possible. CADC+thus minimizes the domain shift resulting from factors unrelated to thepresence of snow. We also present some preliminary results using CADC+ toevaluate the effect of snow on 3D object detection performance. We observe thatsnow introduces a combination of aleatoric and epistemic uncertainties, actingas both noise and a distinct data domain.</description>
      <author>example@mail.com (Mei Qi Tang, Sean Sedwards, Chengjie Huang, Krzysztof Czarnecki)</author>
      <guid isPermaLink="false">2506.16531v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Metapath-based Hyperbolic Contrastive Learning for Heterogeneous Graph Embedding</title>
      <link>http://arxiv.org/abs/2506.16754v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于元路径的超曲率对比学习框架（MHCL），用于处理异构图中的复杂结构，并通过对比学习优化元路径嵌入的判别性。&lt;h4&gt;背景&lt;/h4&gt;异构图具有多样的幂律结构，但现有的超曲率异构图嵌入模型大多依赖于单一的超曲率空间，无法有效捕捉这些结构。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出MHCL框架，使用多个超曲率空间来捕捉异构图中的多样复杂结构。&lt;h4&gt;方法&lt;/h4&gt;MHCL通过学习每个超曲率空间来描述对应元路径的复杂结构分布，并使用对比学习方法来优化框架，通过最小化相同元路径嵌入之间的距离和最大化不同元路径嵌入之间的距离，提高元路径嵌入的判别性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MHCL在各种图机器学习任务中优于现有基准，有效地捕捉了异构图的复杂结构。&lt;h4&gt;结论&lt;/h4&gt;MHCL框架能够有效地处理异构图中的复杂结构，并在图机器学习任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;摘要：双曲空间，以其恒定的负曲率和指数扩张的特性，与异构图的结构特性相吻合。尽管异构图本质上具有多样的幂律结构，但大多数基于超曲率的异构图嵌入模型依赖于单一的超曲率空间。这种方法可能无法有效地捕捉异构图中的多样幂律结构。为了解决这一局限性，我们提出了一个基于元路径的超曲率对比学习框架（MHCL），它使用多个超曲率空间来捕捉异构图中的多样复杂结构。具体而言，通过学习每个超曲率空间来描述每个元路径对应的复杂结构分布，可以有效地捕捉语义信息。由于元路径嵌入表示不同的语义信息，在聚合它们以获得节点表示时保持其判别性很重要。因此，我们使用对比学习方法来优化MHCL，并提高元路径嵌入的判别性。特别是，我们的对比学习方法通过最小化相同元路径嵌入之间的距离和最大化不同元路径嵌入之间的距离在超曲率空间中，从而提高了具有不同语义信息的元路径嵌入的分离性。我们进行了全面的实验来评估MHCL的有效性。实验结果表明，MHCL在各种图机器学习任务中优于现有基准，有效地捕捉了异构图的复杂结构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The hyperbolic space, characterized by a constant negative curvature andexponentially expanding space, aligns well with the structural properties ofheterogeneous graphs. However, although heterogeneous graphs inherently possessdiverse power-law structures, most hyperbolic heterogeneous graph embeddingmodels rely on a single hyperbolic space. This approach may fail to effectivelycapture the diverse power-law structures within heterogeneous graphs. Toaddress this limitation, we propose a Metapath-based Hyperbolic ContrastiveLearning framework (MHCL), which uses multiple hyperbolic spaces to capturediverse complex structures within heterogeneous graphs. Specifically, bylearning each hyperbolic space to describe the distribution of complexstructures corresponding to each metapath, it is possible to capture semanticinformation effectively. Since metapath embeddings represent distinct semanticinformation, preserving their discriminability is important when aggregatingthem to obtain node representations. Therefore, we use a contrastive learningapproach to optimize MHCL and improve the discriminability of metapathembeddings. In particular, our contrastive learning method minimizes thedistance between embeddings of the same metapath and maximizes the distancebetween those of different metapaths in hyperbolic space, thereby improving theseparability of metapath embeddings with distinct semantic information. Weconduct comprehensive experiments to evaluate the effectiveness of MHCL. Theexperimental results demonstrate that MHCL outperforms state-of-the-artbaselines in various graph machine learning tasks, effectively capturing thecomplex structures of heterogeneous graphs.</description>
      <author>example@mail.com (Jongmin Park, Seunghoon Han, Won-Yong Shin, Sungsu Lim)</author>
      <guid isPermaLink="false">2506.16754v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>A Simple Contrastive Framework Of Item Tokenization For Generative Recommendation</title>
      <link>http://arxiv.org/abs/2506.16683v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages,7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SimCIT的新型无监督深度量化框架，用于基于生成检索的推荐系统。&lt;h4&gt;背景&lt;/h4&gt;基于生成检索的推荐系统在大型推荐系统中面临冗余和大规模token空间的问题。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法的局限性，如冗余和大规模token空间，并有效整合互补知识。&lt;h4&gt;方法&lt;/h4&gt;SimCIT采用对比学习进行无监督深度量化，利用可学习的残差量化模块，结合多模态知识对齐和语义标记。&lt;h4&gt;主要发现&lt;/h4&gt;SimCIT在公共数据集和多个领域的工业数据集上展示了其在基于LLM的生成推荐中的有效性。&lt;h4&gt;结论&lt;/h4&gt;SimCIT是一种有效的无监督深度量化方法，能够提升基于生成检索的推荐系统的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于生成检索的推荐作为一种直接生成目标候选者标识符的范式，已显示出其潜力。然而，在大规模推荐系统中，由于token空间的冗余和规模，这种方法变得越来越繁琐。为了克服这些限制，最近的研究探索了使用语义token作为ID token的替代品，通常利用基于重建的策略，如RQ-VAE，对内容嵌入进行量化并显著减少嵌入大小。然而，重建量化旨在独立精确地重建每个项目嵌入，这与生成检索任务的目标相冲突，后者更关注区分项目。此外，项目的多模态辅助信息，如描述性文本和图像，以及地理位置推荐服务中的地理知识，已被证明通过提供更丰富的交互环境来提高推荐效果。尽管如此，将这些互补知识有效地整合到现有的生成推荐框架中仍然具有挑战性。为了克服这些挑战，我们提出了一种名为SimCIT（简单对比项目标记化框架）的新型无监督深度量化方法。具体来说，不同于现有的基于重建的策略，SimCIT提出使用可学习的残差量化模块来与项目的不同模态信号对齐，该模块在对比学习框架中结合了多模态知识对齐和语义标记。在公共数据集和来自多个领域的工业数据集上的大量实验表明，SimCIT在基于LLM的生成推荐中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative retrieval-based recommendation has emerged as a promising paradigmaiming at directly generating the identifiers of the target candidates.However, in large-scale recommendation systems, this approach becomesincreasingly cumbersome due to the redundancy and sheer scale of the tokenspace. To overcome these limitations, recent research has explored the use ofsemantic tokens as an alternative to ID tokens, which typically leveragedreconstruction-based strategies, like RQ-VAE, to quantize content embeddingsand significantly reduce the embedding size. However, reconstructivequantization aims for the precise reconstruction of each item embeddingindependently, which conflicts with the goal of generative retrieval tasksfocusing more on differentiating among items. Moreover, multi-modal sideinformation of items, such as descriptive text and images, geographicalknowledge in location-based recommendation services, has been shown to beeffective in improving recommendations by providing richer contexts forinteractions. Nevertheless, effectively integrating such complementaryknowledge into existing generative recommendation frameworks remainschallenging. To overcome these challenges, we propose a novel unsupervised deepquantization exclusively based on contrastive learning, named SimCIT (a SimpleContrastive Item Tokenization framework). Specifically, different from existingreconstruction-based strategies, SimCIT propose to use a learnable residualquantization module to align with the signals from different modalities of theitems, which combines multi-modal knowledge alignment and semantic tokenizationin a mutually beneficial contrastive learning framework. Extensive experimentsacross public datasets and a large-scale industrial dataset from variousdomains demonstrate SimCIT's effectiveness in LLM-based generativerecommendation.</description>
      <author>example@mail.com (Penglong Zhai, Yifang Yuan, Fanyi Di, Jie Li, Yue Liu, Chen Li, Jie Huang, Sicong Wang, Yao Xu, Xin Li)</author>
      <guid isPermaLink="false">2506.16683v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Anomaly Detection in Event-triggered Traffic Time Series via Similarity Learning</title>
      <link>http://arxiv.org/abs/2506.16855v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 14 figures. Published in IEEE Transactions on Dependable  and Secure Computing. arXiv admin note: substantial text overlap with  arXiv:2207.08159&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了时间序列分析在网络安全领域的应用，特别是针对事件触发型时间序列相似性学习的问题。&lt;h4&gt;背景&lt;/h4&gt;由于事件触发型时间序列的复杂时间动态性，对于安全相关任务（如异常检测和聚类）中适当的相似性度量尚不明确。&lt;h4&gt;目的&lt;/h4&gt;提出一个无监督学习框架，用于学习一组事件触发型时间序列之间的相似性。&lt;h4&gt;方法&lt;/h4&gt;利用层次多分辨率序列自动编码器和高斯混合模型（GMM）从时间序列中有效地学习低维表示。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的定性和定量实验，该方法在性能上优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;该框架为系统性地建模和学习大量事件触发型时间序列的相似性提供了一个有价值的起点。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the application of time series analysis in the field of cybersecurity, especially for the problem of similarity learning among event-triggered time series. Due to the complex temporal dynamics of event-triggered time series, it remains unclear which similarity metric is appropriate for security-related tasks such as anomaly detection and clustering. The overall goal of this paper is to develop an unsupervised learning framework capable of learning the similarities among a set of event-triggered time series. From the perspective of machine learning, the proposed framework harnesses the power of both hierarchical multi-resolution sequential autoencoders and Gaussian Mixture Model (GMM) to effectively learn low-dimensional representations from the time series. Extensive qualitative and quantitative experiments show that the proposed method outperforms the state-of-the-art methods considerably. The proposed framework aims to provide a stepping stone for a systematic approach to model and learn the similarities among a multitude of event-triggered time series.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TDSC.2024.3418906&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series analysis has achieved great success in cyber security such asintrusion detection and device identification. Learning similarities amongmultiple time series is a crucial problem since it serves as the foundation fordownstream analysis. Due to the complex temporal dynamics of theevent-triggered time series, it often remains unclear which similarity metricis appropriate for security-related tasks, such as anomaly detection andclustering. The overarching goal of this paper is to develop an unsupervisedlearning framework that is capable of learning similarities among a set ofevent-triggered time series. From the machine learning vantage point, theproposed framework harnesses the power of both hierarchical multi-resolutionsequential autoencoders and the Gaussian Mixture Model (GMM) to effectivelylearn the low-dimensional representations from the time series. Finally, theobtained similarity measure can be easily visualized for the explanation. Theproposed framework aspires to offer a stepping stone that gives rise to asystematic approach to model and learn similarities among a multitude ofevent-triggered time series. Through extensive qualitative and quantitativeexperiments, it is revealed that the proposed method outperformsstate-of-the-art methods considerably.</description>
      <author>example@mail.com (Shaoyu Dou, Kai Yang, Yang Jiao, Chengbo Qiu, Kui Ren)</author>
      <guid isPermaLink="false">2506.16855v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Empowering Graph-based Approximate Nearest Neighbor Search with Adaptive Awareness Capabilities</title>
      <link>http://arxiv.org/abs/2506.15986v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accecpted by KDD2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GATE的高维空间近似最近邻搜索方法，通过自适应拓扑和查询感知来加速近似最近邻搜索。&lt;h4&gt;背景&lt;/h4&gt;近似最近邻搜索在高维空间数据库、信息检索、推荐系统等领域有广泛应用。基于图的方法虽然性能优越，但仍存在局部最优和冗余计算等问题。&lt;h4&gt;目的&lt;/h4&gt;提出GATE方法，旨在解决现有方法未能充分利用邻近图G中的拓扑信息，以及基数据与查询之间存在严重分布不匹配的问题。&lt;h4&gt;方法&lt;/h4&gt;GATE首先提取一组枢纽节点作为候选入口点，然后利用对比学习模型将这些枢纽节点的结构语义和查询相关特征编码到潜在表示中。接着，构建一个导航图索引以最小化模型推理开销。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与最先进的基于图的方法相比，GATE在查询性能上实现了1.2-2.0倍的速度提升。&lt;h4&gt;结论&lt;/h4&gt;GATE作为一种轻量级且自适应的模块，可以有效地加速近似最近邻搜索，提高查询效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Approximate Nearest Neighbor Search (ANNS) in high-dimensional spaces findsextensive applications in databases, information retrieval, recommendersystems, etc. While graph-based methods have emerged as the leading solutionfor ANNS due to their superior query performance, they still face severalchallenges, such as struggling with local optima and redundant computations.These issues arise because existing methods (i) fail to fully exploit thetopological information underlying the proximity graph G, and (ii) suffer fromsevere distribution mismatches between the base data and queries in practice.  To this end, this paper proposes GATE, high-tier proximity Graph withAdaptive Topology and Query AwarEness, as a lightweight and adaptive moduleatop the graph-based indexes to accelerate ANNS. Specifically, GATE formulatesthe critical problem to identify an optimal entry point in the proximity graphfor a given query, facilitating faster online search. By leveraging theinherent clusterability of high-dimensional data, GATE first extracts a smallset of hub nodes V as candidate entry points. Then, resorting to a contrastivelearning-based two-tower model, GATE encodes both the structural semanticsunderlying G and the query-relevant features into the latent representations ofthese hub nodes V. A navigation graph index on V is further constructed tominimize the model inference overhead. Extensive experiments demonstrate thatGATE achieves a 1.2-2.0X speed-up in query performance compared tostate-of-the-art graph-based indexes.</description>
      <author>example@mail.com (Jiancheng Ruan, Tingyang Chen, Renchi Yang, Xiangyu Ke, Yunjun Gao)</author>
      <guid isPermaLink="false">2506.15986v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Exploring and Improving Initialization for Deep Graph Neural Networks: A Signal Propagation Perspective</title>
      <link>http://arxiv.org/abs/2506.16790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in TMLR (2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对图神经网络（GNNs）随着网络深度增加而性能下降的问题，提出了一种增强GNNs中信号传播（SP）的初始化方法，并命名为SPoGInit。&lt;h4&gt;背景&lt;/h4&gt;GNNs在深度增加时常常会遭受性能退化。&lt;h4&gt;目的&lt;/h4&gt;提出初始化方法来增强GNNs中的信号传播。&lt;h4&gt;方法&lt;/h4&gt;提出三个关键指标：前向传播、反向传播和图嵌入变化（GEV），并分析了一般初始化方法在这些指标上的不足。通过直接利用SP分析，寻找优化这三个指标的权重初始化方差，从而显著增强深度GCNs中的信号传播。&lt;h4&gt;主要发现&lt;/h4&gt;SPoGInit在多种任务和架构上优于常用的初始化方法，并且随着GNNs深度的增加，性能也能得到提升。&lt;h4&gt;结论&lt;/h4&gt;SPoGInit在解决深度相关挑战方面取得了显著进展，验证了SP分析框架的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) often suffer from performance degradation as thenetwork depth increases. This paper addresses this issue by introducinginitialization methods that enhance signal propagation (SP) within GNNs. Wepropose three key metrics for effective SP in GNNs: forward propagation,backward propagation, and graph embedding variation (GEV). While the first twometrics derive from classical SP theory, the third is specifically designed forGNNs. We theoretically demonstrate that a broad range of commonly usedinitialization methods for GNNs, which exhibit performance degradation withincreasing depth, fail to control these three metrics simultaneously. To dealwith this limitation, a direct exploitation of the SP analysis--searching forweight initialization variances that optimize the three metrics--is shown tosignificantly enhance the SP in deep GCNs. This approach is called SignalPropagation on Graph-guided Initialization (SPoGInit). Our experimentsdemonstrate that SPoGInit outperforms commonly used initialization methods onvarious tasks and architectures. Notably, SPoGInit enables performanceimprovements as GNNs deepen, which represents a significant advancement inaddressing depth-related challenges and highlights the validity andeffectiveness of the SP analysis framework.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) often suffer from performance degradation as thenetwork depth increases. This paper addresses this issue by introducinginitialization methods that enhance signal propagation (SP) within GNNs. Wepropose three key metrics for effective SP in GNNs: forward propagation,backward propagation, and graph embedding variation (GEV). While the first twometrics derive from classical SP theory, the third is specifically designed forGNNs. We theoretically demonstrate that a broad range of commonly usedinitialization methods for GNNs, which exhibit performance degradation withincreasing depth, fail to control these three metrics simultaneously. To dealwith this limitation, a direct exploitation of the SP analysis--searching forweight initialization variances that optimize the three metrics--is shown tosignificantly enhance the SP in deep GCNs. This approach is called SignalPropagation on Graph-guided Initialization (SPoGInit). Our experimentsdemonstrate that SPoGInit outperforms commonly used initialization methods onvarious tasks and architectures. Notably, SPoGInit enables performanceimprovements as GNNs deepen, which represents a significant advancement inaddressing depth-related challenges and highlights the validity andeffectiveness of the SP analysis framework.</description>
      <author>example@mail.com (Senmiao Wang, Yupeng Chen, Yushun Zhang, Ruoyu Sun, Tian Ding)</author>
      <guid isPermaLink="false">2506.16790v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>AutoHFormer: Efficient Hierarchical Autoregressive Transformer for Time Series Prediction</title>
      <link>http://arxiv.org/abs/2506.16001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AutoHFormer的层次自回归变换器，用于时间序列预测，它通过三种关键创新解决了时间序列预测中的三个竞争目标。&lt;h4&gt;背景&lt;/h4&gt;时间序列预测需要同时满足严格的时序因果性、亚二次复杂度以及多尺度模式识别。&lt;h4&gt;目的&lt;/h4&gt;提出AutoHFormer，以实现高效且准确的时间序列建模。&lt;h4&gt;方法&lt;/h4&gt;AutoHFormer通过以下三个方面进行创新：1) 层次时序建模，将预测分解为并行处理的段级块，然后进行段内顺序细化；2) 动态窗口注意力机制，使用具有指数衰减的可学习因果窗口，以降低复杂度并保留精确的时序关系；3) 自适应时序编码，采用一种新的位置编码系统，结合固定振荡模式捕捉短期变化和可学习衰减率捕捉长期趋势。&lt;h4&gt;主要发现&lt;/h4&gt;与PatchTST相比，AutoHFormer在PEMS08数据集上实现了10.76倍的训练速度和6.06倍的内存减少，同时在大多数情况下保持了96-720步预测范围内的准确度。&lt;h4&gt;结论&lt;/h4&gt;AutoHFormer为高效且精确的时间序列建模建立了新的基准。&lt;h4&gt;翻译&lt;/h4&gt;时间序列预测需要同时实现严格的时序因果性、亚二次复杂度以及多尺度模式识别。我们提出了一个名为AutoHFormer的层次自回归变换器，通过以下三个关键创新来解决这些挑战：1) 层次时序建模：我们的架构将预测分解为并行处理的段级块，然后进行段内顺序细化。这种双尺度方法在保持时序一致性的同时，实现了高效的计算。2) 动态窗口注意力：注意力机制采用具有指数衰减的可学习因果窗口，降低复杂度同时保留精确的时序关系。这种设计避免了标准变换器中的反因果违规和RNN混合中的顺序瓶颈。3) 自适应时序编码：采用一种新的位置编码系统，捕捉多尺度的时间模式。它结合固定振荡模式用于短期变化和可学习衰减率用于长期趋势。全面的实验表明，与PatchTST相比，AutoHFormer在PEMS08数据集上实现了10.76倍的训练速度和6.06倍的内存减少，同时在大多数情况下保持了96-720步预测范围内的准确度。这些突破为高效且精确的时间序列建模建立了新的基准。我们方法及其所有基线在分层自回归机制中的实现可在https://github.com/lizzyhku/Autotime上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting requires architectures that simultaneously achievethree competing objectives: (1) strict temporal causality for reliablepredictions, (2) sub-quadratic complexity for practical scalability, and (3)multi-scale pattern recognition for accurate long-horizon forecasting. Weintroduce AutoHFormer, a hierarchical autoregressive transformer that addressesthese challenges through three key innovations: 1) Hierarchical TemporalModeling: Our architecture decomposes predictions into segment-level blocksprocessed in parallel, followed by intra-segment sequential refinement. Thisdual-scale approach maintains temporal coherence while enabling efficientcomputation. 2) Dynamic Windowed Attention: The attention mechanism employslearnable causal windows with exponential decay, reducing complexity whilepreserving precise temporal relationships. This design avoids both theanti-causal violations of standard transformers and the sequential bottlenecksof RNN hybrids. 3) Adaptive Temporal Encoding: a novel position encoding systemis adopted to capture time patterns at multiple scales. It combines fixedoscillating patterns for short-term variations with learnable decay rates forlong-term trends. Comprehensive experiments demonstrate that AutoHFormer 10.76Xfaster training and 6.06X memory reduction compared to PatchTST on PEMS08,while maintaining consistent accuracy across 96-720 step horizons in most ofcases. These breakthroughs establish new benchmarks for efficient and precisetime series modeling. Implementations of our method and all baselines inhierarchical autoregressive mechanism are available athttps://github.com/lizzyhku/Autotime.</description>
      <author>example@mail.com (Qianru Zhang, Honggang Wen, Ming Li, Dong Huang, Siu-Ming Yiu, Christian S. Jensen, Pietro Liò)</author>
      <guid isPermaLink="false">2506.16001v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Modal Epileptic Signal Harmonization: Frequency Domain Mapping Quantization for Pre-training a Unified Neurophysiological Transformer</title>
      <link>http://arxiv.org/abs/2506.17068v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了EpiNT，一种基于Transformer的预训练模型，用于统一头皮脑电图（EEG）和颅内脑电图（iEEG）的分析，以解决癫痫诊断和治疗中的挑战。&lt;h4&gt;背景&lt;/h4&gt;头皮脑电图和颅内脑电图对于癫痫的诊断和治疗至关重要，但它们的统一分析由于记录蒙版、幅度、信噪比和频率成分的差异而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出EpiNT模型，旨在克服上述挑战，并实现统一癫痫神经生理学分析。&lt;h4&gt;方法&lt;/h4&gt;EpiNT使用通道无关的建模方法，包括掩码自编码器（MAE）和矢量量化（VQ），以及频率域映射量化器来捕捉关键频率特征。该模型在超过2700小时的多模态临床神经生理学数据上进行了预训练。&lt;h4&gt;主要发现&lt;/h4&gt;EpiNT在六个下游分类任务中优于随机初始化的模型和其他预训练方法，证明了其强大的表征学习能力。&lt;h4&gt;结论&lt;/h4&gt;EpiNT为统一癫痫神经生理学分析提供了一种有前景的方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces EpiNT, a novel Transformer-based pre-trained model for unified EEG and iEEG analysis, aiming to overcome the challenges in epilepsy diagnosis and treatment, and provides a promising approach for unified epilepsy neurophysiology analysis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scalp electroencephalography (EEG) and intracranial EEG (iEEG) are vital forepilepsy diagnosis and treatment. Their unified analysis offers the potentialto harness the complementary strengths of each modality but is challenging dueto variations in recording montages, amplitude and signal-to-noise ratio (SNR),and frequency components. To address the aforementioned challenges, this paperintroduces EpiNT, a novel Transformer-based pre-trained model for unified EEGand iEEG analysis. EpiNT employs channel-independent modeling with maskedautoencoders (MAE) and vector quantization (VQ), along with a frequency domainmapping quantizer to capture crucial frequency features. Pre-trained on over2,700 hours of multi-modal clinical neurophysiological data from 1,199patients, EpiNT outperformed both randomly initialized models and otherpre-trained methods on six downstream classification tasks, demonstratingrobust representation learning capabilities. This work presents a promisingapproach for unified epilepsy neurophysiology analysis.</description>
      <author>example@mail.com (Runkai Zhang, Hua Yu, John Q. Gan, Haixian Wang)</author>
      <guid isPermaLink="false">2506.17068v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Assembler: Scalable 3D Part Assembly via Anchor Point Diffusion</title>
      <link>http://arxiv.org/abs/2506.17074v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report. Project page: https://assembler3d.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Assembler的3D部件组装框架，该框架能够从输入部件网格和参考图像中重建完整对象。它能够处理具有不同部件数量、几何形状和结构的多样化真实世界对象。&lt;h4&gt;背景&lt;/h4&gt;现有的3D部件组装方法大多依赖于确定性部件姿态预测和特定类别训练，而Assembler旨在解决这些方法的局限性。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够处理多样化、真实世界3D部件组装的通用框架。&lt;h4&gt;方法&lt;/h4&gt;1. 将部件组装视为一个生成问题，并使用扩散模型来采样可能的配置，有效捕捉对称性、重复部件和多个有效组装带来的歧义。2. 引入基于稀疏锚点云的形状中心表示，使生成过程在欧几里得空间而不是SE(3)姿态预测中实现可扩展性。3. 构建了一个包含超过320K个多样化部件-对象组装的大规模数据集。&lt;h4&gt;主要发现&lt;/h4&gt;Assembler在PartNet上实现了最先进的性能，并首次展示了复杂真实世界对象的高质量组装。&lt;h4&gt;结论&lt;/h4&gt;基于Assembler，我们进一步介绍了一个有趣的部件感知3D建模系统，该系统能够从图像中生成高分辨率、可编辑的对象，展示了交互式和组合设计的潜力。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为Assembler的3D部件组装框架，该框架能够从输入部件网格和参考图像中重建完整对象。与先前主要依赖确定性部件姿态预测和特定类别训练的方法不同，Assembler旨在处理具有不同部件数量、几何形状和结构的多样化真实世界对象。它通过在任务表述、表示和数据方面的创新来解决扩展到通用3D部件组装的核心挑战。首先，Assembler将部件组装视为一个生成问题，并使用扩散模型来采样可能的配置，有效地捕捉由对称性、重复部件和多个有效组装引起的歧义。其次，我们引入了一种基于稀疏锚点云的形状中心表示，使生成过程在欧几里得空间而不是SE(3)姿态预测中实现可扩展性。第三，我们使用基于现有3D形状库的合成和过滤管道构建了一个包含超过320K个多样化部件-对象组装的大规模数据集。Assembler在PartNet上实现了最先进的性能，并首次展示了复杂真实世界对象的高质量组装。基于Assembler，我们进一步介绍了一个有趣的部件感知3D建模系统，该系统能够从图像中生成高分辨率、可编辑的对象，展示了交互式和组合设计的潜力。项目页面：https://assembler3d.github.io&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Assembler, a scalable and generalizable framework for 3D partassembly that reconstructs complete objects from input part meshes and areference image. Unlike prior approaches that mostly rely on deterministic partpose prediction and category-specific training, Assembler is designed to handlediverse, in-the-wild objects with varying part counts, geometries, andstructures. It addresses the core challenges of scaling to general 3D partassembly through innovations in task formulation, representation, and data.First, Assembler casts part assembly as a generative problem and employsdiffusion models to sample plausible configurations, effectively capturingambiguities arising from symmetry, repeated parts, and multiple validassemblies. Second, we introduce a novel shape-centric representation based onsparse anchor point clouds, enabling scalable generation in Euclidean spacerather than SE(3) pose prediction. Third, we construct a large-scale dataset ofover 320K diverse part-object assemblies using a synthesis and filteringpipeline built on existing 3D shape repositories. Assembler achievesstate-of-the-art performance on PartNet and is the first to demonstratehigh-quality assembly for complex, real-world objects. Based on Assembler, wefurther introduce an interesting part-aware 3D modeling system that generateshigh-resolution, editable objects from images, demonstrating potential forinteractive and compositional design. Project page:https://assembler3d.github.io</description>
      <author>example@mail.com (Wang Zhao, Yan-Pei Cao, Jiale Xu, Yuejiang Dong, Ying Shan)</author>
      <guid isPermaLink="false">2506.17074v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes</title>
      <link>http://arxiv.org/abs/2506.16805v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的基准和模型来评估和改进视觉模型在稀疏图像集中进行共视推理的能力。&lt;h4&gt;背景&lt;/h4&gt;人类能够识别多个图像中重叠的可视区域，这一能力在3D视觉和机器人感知中至关重要。尽管在视觉学习方面取得了显著进展，但当前视觉模型在共视分析方面的表现是否达到人类水平仍不明确。&lt;h4&gt;目的&lt;/h4&gt;设计一个名为Co-Visibility reasONing (Co-VisiON)的基准，以直接评估在超过1000个室内场景中的稀疏图像集上进行共视推理。&lt;h4&gt;方法&lt;/h4&gt;通过实验比较了不同视觉模型在稀疏条件下的表现，并提出了一种新的多视图基准模型Covis。&lt;h4&gt;主要发现&lt;/h4&gt;发现共视分析对现有视觉模型是一个重大挑战，且一种专有的视觉-语言模型在性能上优于所有纯视觉方法，但仍然远远落后于人类表现。&lt;h4&gt;结论&lt;/h4&gt;强调了需要超越基本的成对视觉处理，通过高级推理实现跨多个视图的全面空间理解。Covis模型在纯视觉模型中实现了最佳性能，并缩小了与专有视觉-语言模型的差距。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类展现出惊人的识别共视能力——在多个图像中可见的重叠区域，即使这些图像在复杂场景中分布稀疏。这种能力是3D视觉和机器人感知的基础。尽管在视觉学习方面取得了显著进展，但当前视觉模型在共视分析方面的表现是否达到人类水平仍不明确。在本工作中，我们引入了Co-Visibility reasONing (Co-VisiON)基准，旨在直接评估在超过1000个室内场景中的稀疏图像集上进行共视推理。我们的实验表明，尽管共视通常被视为一种低级特征匹配任务，但在稀疏条件下它对现有视觉模型提出了重大挑战。值得注意的是，一种专有的视觉-语言模型在性能上优于所有纯视觉方法，所有模型在表现上都远落后于人类。这一差距强调了需要不仅仅是基本的成对视觉处理——它需要通过跨多个视图的高级推理实现全面的空间理解。受人类视觉认知的启发，我们提出了一种新的多视图基准，Covis，它在纯视觉模型中实现了最佳性能，并缩小了与专有视觉-语言模型的差距。我们希望我们的基准和发现能够促进在具有挑战性和稀疏环境中的视觉模型开发方面的进一步进步。我们的数据集和源代码可在以下链接找到：https://ai4ce.github.io/CoVISION&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans exhibit a remarkable ability to recognize co-visibility-theoverlapping regions visible in multiple images-even when these images aresparsely distributed across a complex scene. This capability is foundational in3D vision and robotic perception. Despite significant progress in visionlearning, it remains unclear whether current vision models have reachedhuman-level proficiency in co-visibility analysis. In this work, we introducethe Co-Visibility reasONing (Co-VisiON) benchmark, designed to directlyevaluate co-visibility reasoning on sparse image sets across over 1000 indoorscenarios. Our experiments reveal that while co-visibility is typically treatedas a low-level feature matching task, it poses a significant challenge forexisting vision models under sparse conditions. Notably, a proprietaryvision-language model outperforms all purely vision-based approaches, with allmodels lagging substantially behind human performance. This gap underscores theneed for more than basic pairwise vision processing-it calls for acomprehensive spatial understanding through high-level reasoning acrossmultiple views. Inspired by human visual cognition, we propose a novelmulti-view baseline, Covis, which achieves top performance among pure visionmodels and narrows the gap to the proprietary VLM. We hope our benchmark andfindings will spur further advancements in developing vision models capable ofrobust, high-level reasoning in challenging, sparse environments. Our datasetand source code can be found at: https://ai4ce.github.io/CoVISION</description>
      <author>example@mail.com (Chao Chen, Nobel Dang, Juexiao Zhang, Wenkai Sun, Pengfei Zheng, Xuhang He, Yimeng Ye, Taarun Srinivas, Chen Feng)</author>
      <guid isPermaLink="false">2506.16805v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification</title>
      <link>http://arxiv.org/abs/2506.17140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MeDi的新型深度学习模型，旨在解决深度学习模型在病理预测任务中对于不同条件的不鲁棒性问题，如染色、扫描仪、医院和人口统计等因素。&lt;h4&gt;背景&lt;/h4&gt;尽管深度学习模型在病理预测任务上取得了显著进展，但它们对各种条件变化的鲁棒性不足，例如染色、扫描仪、医院和人口统计等因素。如果模型在代表性较高的子群体上训练，它们通常难以处理较少见的模式，导致捷径学习和偏差预测。&lt;h4&gt;目的&lt;/h4&gt;提出MeDi模型，通过将元数据显式地建模到Metadata-guided generative Diffusion模型框架中，实现针对代表性较低的子群体的有针对性的数据增强，以平衡有限的训练数据并减轻下游模型的偏差。&lt;h4&gt;方法&lt;/h4&gt;MeDi模型允许使用合成数据对代表性较低的子群体进行有针对性的增强，从而平衡有限的训练数据并减轻下游模型的偏差。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，MeDi能够为TCGA中未见过的子群体生成高质量的病理图像，提高了生成图像的整体保真度，并使下游分类器在具有子群体变化的数据库上的性能得到提升。&lt;h4&gt;结论&lt;/h4&gt;本文的工作是利用生成模型更好地减轻数据偏差的一个概念验证，为临床实践中的病理预测任务提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，深度学习模型在病理预测任务上取得了显著进展。然而，由于对染色、扫描仪、医院和人口统计等不同条件的不鲁棒性，其在临床实践中的应用仍然受到限制：如果模型在代表性较高的子群体上训练，它们通常难以处理较少见的模式，导致捷径学习和偏差预测。大规模基础模型尚未完全解决这个问题。因此，我们提出了一种新的方法，即Metadata-guided generative Diffusion模型框架（MeDi）。MeDi允许使用合成数据对代表性较低的子群体进行有针对性的增强，从而平衡有限的训练数据并减轻下游模型的偏差。我们通过实验表明，MeDi能够为TCGA中未见过的子群体生成高质量的病理图像，提高了生成图像的整体保真度，并使下游分类器在具有子群体变化的数据库上的性能得到提升。我们的工作是利用生成模型更好地减轻数据偏差的一个概念验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning models have made significant advances in histologicalprediction tasks in recent years. However, for adaptation in clinical practice,their lack of robustness to varying conditions such as staining, scanner,hospital, and demographics is still a limiting factor: if trained onoverrepresented subpopulations, models regularly struggle with less frequentpatterns, leading to shortcut learning and biased predictions. Large-scalefoundation models have not fully eliminated this issue. Therefore, we propose anovel approach explicitly modeling such metadata into a Metadata-guidedgenerative Diffusion model framework (MeDi). MeDi allows for a targetedaugmentation of underrepresented subpopulations with synthetic data, whichbalances limited training data and mitigates biases in downstream models. Weexperimentally show that MeDi generates high-quality histopathology images forunseen subpopulations in TCGA, boosts the overall fidelity of the generatedimages, and enables improvements in performance for downstream classifiers ondatasets with subpopulation shifts. Our work is a proof-of-concept towardsbetter mitigating data biases with generative models.</description>
      <author>example@mail.com (David Jacob Drexlin, Jonas Dippel, Julius Hense, Niklas Prenißl, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller)</author>
      <guid isPermaLink="false">2506.17140v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>A Strong View-Free Baseline Approach for Single-View Image Guided Point Cloud Completion</title>
      <link>http://arxiv.org/abs/2506.15747v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于注意力机制的编码器-解码器网络，用于从单张图像引导的点云补全任务，通过实验证明该方法在ShapeNet-ViPC数据集上优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;单视图图像引导的点云补全任务旨在利用单张图像从部分点云重建完整点云，此方法的有效性已得到验证，但图像引导的必要性尚未得到充分探讨。&lt;h4&gt;目的&lt;/h4&gt;探讨图像引导在点云补全中的必要性，并提出一种新的基于注意力机制的编码器-解码器网络。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于注意力机制的编码器-解码器网络，该网络仅以部分点云作为输入，无需考虑视图信息。网络采用层次化自融合机制，通过交叉注意力和自注意力层有效整合多流信息，增强特征表示并提高捕捉几何结构的能力。&lt;h4&gt;主要发现&lt;/h4&gt;在ShapeNet-ViPC数据集上的实验和消融研究表明，该无视图框架在单视图图像引导的点云补全任务中表现优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为多模态学习在单视图图像引导的点云补全任务中的应用提供了新的见解。&lt;h4&gt;翻译&lt;/h4&gt;The single-view image guided point cloud completion (SVIPC) task aims to reconstruct a complete point cloud from a partial input with the help of a single-view image. While previous works have demonstrated the effectiveness of this multimodal approach, the fundamental necessity of image guidance remains largely unexamined. To explore this, we propose a strong baseline approach for SVIPC based on an attention-based multi-branch encoder-decoder network that only takes partial point clouds as input, view-free. Our hierarchical self-fusion mechanism, driven by cross-attention and self-attention layers, effectively integrates information across multiple streams, enriching feature representations and strengthening the networks ability to capture geometric structures. Extensive experiments and ablation studies on the ShapeNet-ViPC dataset demonstrate that our view-free framework performs superiorly to state-of-the-art SVIPC methods. We hope our findings provide new insights into the development of multimodal learning in SVIPC. Our demo code will be available at https://github.com/Zhang-VISLab.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The single-view image guided point cloud completion (SVIPC) task aims toreconstruct a complete point cloud from a partial input with the help of asingle-view image. While previous works have demonstrated the effectiveness ofthis multimodal approach, the fundamental necessity of image guidance remainslargely unexamined. To explore this, we propose a strong baseline approach forSVIPC based on an attention-based multi-branch encoder-decoder network thatonly takes partial point clouds as input, view-free. Our hierarchicalself-fusion mechanism, driven by cross-attention and self-attention layers,effectively integrates information across multiple streams, enriching featurerepresentations and strengthening the networks ability to capture geometricstructures. Extensive experiments and ablation studies on the ShapeNet-ViPCdataset demonstrate that our view-free framework performs superiorly tostate-of-the-art SVIPC methods. We hope our findings provide new insights intothe development of multimodal learning in SVIPC. Our demo code will beavailable at https://github.com/Zhang-VISLab.</description>
      <author>example@mail.com (Fangzhou Lin, Zilin Dai, Rigved Sanku, Songlin Hou, Kazunori D Yamada, Haichong K. Zhang, Ziming Zhang)</author>
      <guid isPermaLink="false">2506.15747v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Relational Deep Learning: Challenges, Foundations and Next-Generation Architectures</title>
      <link>http://arxiv.org/abs/2506.16654v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了关系深度学习（RDL），介绍了如何将关系数据库构建为关系实体图，并讨论了用于开发和发展基于图神经网络（GNN）的RDL模型的相关公开基准数据集，同时探讨了大规模多表集成、建模时间动态和异构数据的复杂性。&lt;h4&gt;背景&lt;/h4&gt;图机器学习在处理任意图结构数据方面提高了模型的性能，并被应用于分子、社交网络、推荐系统和交通等领域。多表关系数据库中的数据也可以构建为关系实体图，以实现端到端表示学习，无需传统特征工程。&lt;h4&gt;目的&lt;/h4&gt;提供RDL的全面综述，并探讨统一不同建模挑战的机会，强调RDL如何将图机器学习的多个子领域汇聚起来，设计能够改变关系数据处理的基础模型。&lt;h4&gt;方法&lt;/h4&gt;介绍关系数据库作为关系实体图的表示方法，并回顾用于开发和发展基于GNN的RDL模型的公开基准数据集。同时，讨论了大规模多表集成和建模时间动态及异构数据的复杂性，并调查了专门针对关系实体图的基础神经网络方法和近期架构进展。&lt;h4&gt;主要发现&lt;/h4&gt;关系实体图具有定义结构的关键属性，包括由实体之间的主-外键关系定义的结构，由数据库定义的关系模式决定的连接性，以及时间性和异质性的连接。&lt;h4&gt;结论&lt;/h4&gt;RDL能够将图机器学习的多个子领域汇聚起来，为设计能够改变关系数据处理的基础模型提供了机会。&lt;h4&gt;翻译&lt;/h4&gt;Graph machine learning has led to a significant increase in the capabilities of models that learn on arbitrary graph-structured data and has been applied to molecules, social networks, recommendation systems, and transportation, among other domains. Data in multi-tabular relational databases can also be constructed as 'relational entity graphs' for Relational Deep Learning (RDL) - a new blueprint that enables end-to-end representation learning without traditional feature engineering. Compared to arbitrary graph-structured data, relational entity graphs have key properties: (i) their structure is defined by primary-foreign key relationships between entities in different tables, (ii) the structural connectivity is a function of the relational schema defining a database, and (iii) the graph connectivity is temporal and heterogeneous in nature. In this paper, we provide a comprehensive review of RDL by first introducing the representation of relational databases as relational entity graphs, and then reviewing public benchmark datasets that have been used to develop and evaluate recent GNN-based RDL models. We discuss key challenges including large-scale multi-table integration and the complexities of modeling temporal dynamics and heterogeneous data, while also surveying foundational neural network methods and recent architectural advances specialized for relational entity graphs. Finally, we explore opportunities to unify these distinct modeling challenges, highlighting how RDL converges multiple sub-fields in graph machine learning towards the design of foundation models that can transform the processing of relational data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph machine learning has led to a significant increase in the capabilitiesof models that learn on arbitrary graph-structured data and has been applied tomolecules, social networks, recommendation systems, and transportation, amongother domains. Data in multi-tabular relational databases can also beconstructed as 'relational entity graphs' for Relational Deep Learning (RDL) -a new blueprint that enables end-to-end representation learning withouttraditional feature engineering. Compared to arbitrary graph-structured data,relational entity graphs have key properties: (i) their structure is defined byprimary-foreign key relationships between entities in different tables, (ii)the structural connectivity is a function of the relational schema defining adatabase, and (iii) the graph connectivity is temporal and heterogeneous innature. In this paper, we provide a comprehensive review of RDL by firstintroducing the representation of relational databases as relational entitygraphs, and then reviewing public benchmark datasets that have been used todevelop and evaluate recent GNN-based RDL models. We discuss key challengesincluding large-scale multi-table integration and the complexities of modelingtemporal dynamics and heterogeneous data, while also surveying foundationalneural network methods and recent architectural advances specialized forrelational entity graphs. Finally, we explore opportunities to unify thesedistinct modeling challenges, highlighting how RDL converges multiplesub-fields in graph machine learning towards the design of foundation modelsthat can transform the processing of relational data.</description>
      <author>example@mail.com (Vijay Prakash Dwivedi, Charilaos Kanatsoulis, Shenyang Huang, Jure Leskovec)</author>
      <guid isPermaLink="false">2506.16654v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>H-QuEST: Accelerating Query-by-Example Spoken Term Detection with Hierarchical Indexing</title>
      <link>http://arxiv.org/abs/2506.16751v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;H-QuEST是一种新型的Query-by-example语音词检测框架，通过利用高级音频表示学习技术和HNSW索引来加速语音词检索，同时在不牺牲准确性的情况下显著提高检索速度。&lt;h4&gt;背景&lt;/h4&gt;在语音词检测中，当标注数据有限或不可用时，通常使用模板匹配方法如动态时间规整（DTW），但这些方法计算量大且扩展性差。&lt;h4&gt;目的&lt;/h4&gt;提出H-QuEST框架，旨在加速语音词检索，并提高检索速度而不降低准确性。&lt;h4&gt;方法&lt;/h4&gt;H-QuEST利用基于TF-IDF的稀疏表示和高级音频表示学习技术，以及HNSW索引和进一步的优化来加速检索。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有方法相比，H-QuEST在检索速度上有了显著提高，同时保持了检索的准确性。&lt;h4&gt;结论&lt;/h4&gt;H-QuEST是一种有效的语音词检测框架，能够显著提高检索速度，同时保持较高的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Query-by-example spoken term detection (QbE-STD) searches for matching wordsor phrases in an audio dataset using a sample spoken query. When annotated datais limited or unavailable, QbE-STD is often done using template matchingmethods like dynamic time warping (DTW), which are computationally expensiveand do not scale well. To address this, we propose H-QuEST (HierarchicalQuery-by-Example Spoken Term Detection), a novel framework that acceleratesspoken term retrieval by utilizing Term Frequency and Inverse DocumentFrequency (TF-IDF)-based sparse representations obtained through advanced audiorepresentation learning techniques and Hierarchical Navigable Small World(HNSW) indexing with further refinement. Experimental results show that H-QuESTdelivers substantial improvements in retrieval speed without sacrificingaccuracy compared to existing methods.</description>
      <author>example@mail.com (Akanksha Singh, Yi-Ping Phoebe Chen, Vipul Arora)</author>
      <guid isPermaLink="false">2506.16751v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Context Matters! Relaxing Goals with LLMs for Feasible 3D Scene Planning</title>
      <link>http://arxiv.org/abs/2506.15828v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将经典规划与大型语言模型（LLMs）相结合的方法，旨在解决经典规划在现实场景中由于机器人感知有限和感知与规划谓词之间需要匹配导致的难题。&lt;h4&gt;背景&lt;/h4&gt;经典规划在人工智能和机器人领域通过从命令式方法转向声明式方法（如PDDL）来处理复杂任务，但在实际场景中由于机器人感知有限和需要将感知与规划谓词匹配，这些方法常常失败。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些限制，本文提出了一种结合经典规划与LLMs的方法，利用LLMs提取常识知识并实现动作的匹配。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个分层公式，通过定义功能等效的目标并通过逐步放宽来实现难以实现的任务的可行性。这种方法支持部分实现目标，适合代理的具体上下文。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过综合定性和定量评估，证明了其能够有效地在用3D场景图模型化的环境中适应和执行任务。同时，该方法在复杂场景中成功，而其他基准方法更有可能失败。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过结合经典规划与LLMs，为解决机器人规划中的挑战提供了一种有效途径，并通过社区发布的代码、数据集和附加材料，进一步推动了该领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, an approach integrating classical planning with Large Language Models (LLMs) is presented to address the challenges in robotic planning due to limited robot perception and the need to ground perceptions to planning predicates. The method leverages the ability of LLMs to extract common-sense knowledge and ground actions, and proposes a hierarchical formulation to make infeasible tasks tractable by defining functionally equivalent goals through gradual relaxation. The method demonstrates its ability to adapt and execute tasks effectively within environments modeled using 3D Scene Graphs, and shows success in complex scenarios where other benchmark methods are more likely to fail. Code, dataset, and additional material are released to the community.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Classical planning in AI and Robotics addresses complex tasks by shiftingfrom imperative to declarative approaches (e.g., PDDL). However, these methodsoften fail in real scenarios due to limited robot perception and the need toground perceptions to planning predicates. This often results in heavilyhard-coded behaviors that struggle to adapt, even with scenarios where goalscan be achieved through relaxed planning. Meanwhile, Large Language Models(LLMs) lead to planning systems that leverage commonsense reasoning but oftenat the cost of generating unfeasible and/or unsafe plans. To address theselimitations, we present an approach integrating classical planning with LLMs,leveraging their ability to extract commonsense knowledge and ground actions.We propose a hierarchical formulation that enables robots to make unfeasibletasks tractable by defining functionally equivalent goals through gradualrelaxation. This mechanism supports partial achievement of the intendedobjective, suited to the agent's specific context. Our method demonstrates itsability to adapt and execute tasks effectively within environments modeledusing 3D Scene Graphs through comprehensive qualitative and quantitativeevaluations. We also show how this method succeeds in complex scenarios whereother benchmark methods are more likely to fail. Code, dataset, and additionalmaterial are released to the community.</description>
      <author>example@mail.com (Emanuele Musumeci, Michele Brienza, Francesco Argenziano, Vincenzo Suriani, Daniele Nardi, Domenico D. Bloisi)</author>
      <guid isPermaLink="false">2506.15828v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Energy-Based Transfer for Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.16590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个基于能量的迁移学习方法，通过异常检测来选择性地提供指导，使教师仅在训练分布内的状态中进行干预，从而提高强化学习算法在多任务和持续学习环境中的样本效率。&lt;h4&gt;背景&lt;/h4&gt;强化学习算法在多任务或持续学习环境中往往效率低下，难以应用。&lt;h4&gt;目的&lt;/h4&gt;提高强化学习算法在多任务和持续学习环境中的样本效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于能量的迁移学习方法，使用异常检测来选择性地提供指导，使教师仅在训练分布内的状态中进行干预。&lt;h4&gt;主要发现&lt;/h4&gt;理论上证明了能量分数反映了教师的状态访问密度，并实证证明了在单任务和多任务环境中都提高了样本效率。&lt;h4&gt;结论&lt;/h4&gt;该方法能有效地提高强化学习算法在多任务和持续学习环境中的样本效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：强化学习算法往往因样本效率低下而难以应用于多任务或持续学习环境。通过将先前训练的教师策略的知识迁移到新但相关的任务中，可以提高效率。然而，如果新任务与教师训练任务差异很大，迁移的指导可能次优，并偏向低奖励行为。我们提出了一种基于能量的迁移学习方法，它使用异常检测来选择性地提供指导，使教师仅在训练分布内的状态中进行干预。我们理论上证明了能量分数反映了教师的状态访问密度，并通过实证证明了在单任务和多任务环境中都提高了样本效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement learning algorithms often suffer from poor sample efficiency,making them challenging to apply in multi-task or continual learning settings.Efficiency can be improved by transferring knowledge from a previously trainedteacher policy to guide exploration in new but related tasks. However, if thenew task sufficiently differs from the teacher's training task, the transferredguidance may be sub-optimal and bias exploration toward low-reward behaviors.We propose an energy-based transfer learning method that usesout-of-distribution detection to selectively issue guidance, enabling theteacher to intervene only in states within its training distribution. Wetheoretically show that energy scores reflect the teacher's state-visitationdensity and empirically demonstrate improved sample efficiency and performanceacross both single-task and multi-task settings.</description>
      <author>example@mail.com (Zeyun Deng, Jasorsi Ghosh, Fiona Xie, Yuzhe Lu, Katia Sycara, Joseph Campbell)</author>
      <guid isPermaLink="false">2506.16590v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Modality Learning for Predicting IHC Biomarkers from H&amp;E-Stained Whole-Slide Images</title>
      <link>http://arxiv.org/abs/2506.15853v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为HistoStainAlign的深度学习框架，用于从H&amp;E染色全切片图像直接预测IHC染色模式，以减少IHC染色的成本和时间消耗。&lt;h4&gt;背景&lt;/h4&gt;H&amp;E染色是病理分析的基础，而IHC染色提供分子层面的信息，但IHC染色成本高、耗时且资源密集。&lt;h4&gt;目的&lt;/h4&gt;提出HistoStainAlign框架，通过学习形态和分子特征的联合表示，直接从H&amp;E全切片图像预测IHC染色模式。&lt;h4&gt;方法&lt;/h4&gt;框架通过对比训练策略整合配对的H&amp;E和IHC嵌入，捕捉染色模态间的互补特征，无需切片级别标注或组织配准。&lt;h4&gt;主要发现&lt;/h4&gt;HistoStainAlign在三种常见的IHC染色（P53、PD-L1和Ki-67）上实现了0.735、0.830和0.723的加权F1分数。嵌入分析表明，对比对齐在捕捉跨染色关系方面具有鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了计算方法作为预筛选工具的潜力，有助于优先考虑IHC染色案例，并提高工作流程效率。&lt;h4&gt;翻译&lt;/h4&gt;Hematoxylin and Eosin (H&amp;E)染色是病理分析的基础，为癌症的诊断、亚型和分级提供了可靠的细胞形态和组织结构可视化。免疫组织化学(IHC)染色通过检测组织中的特定蛋白质，提供分子层面的见解，提高了诊断的准确性并改善了治疗方案。然而，IHC染色成本高昂、耗时且资源密集，需要专业的技术知识。为了解决这些限制，本研究提出了一种名为HistoStainAlign的新型深度学习框架，该框架通过学习形态和分子特征的联合表示，直接从H&amp;E全切片图像预测IHC染色模式。该框架通过对比训练策略整合配对的H&amp;E和IHC嵌入，无需切片级别标注或组织配准即可捕捉染色模态间的互补特征。该模型在胃肠道和肺组织全切片图像上，针对三种常用的IHC染色（P53、PD-L1和Ki-67）进行了评估，分别实现了0.735[95%置信区间(CI)：0.670-0.799]、0.830[95% CI：0.772-0.886]和0.723[95% CI：0.607-0.836]的加权F1分数。嵌入分析表明，对比对齐在捕捉跨染色关系方面具有鲁棒性。与基线模型的比较进一步突出了引入对比学习以提高染色模式预测的优势。本研究证明了计算方法作为预筛选工具的潜力，有助于优先考虑IHC染色案例，并提高工作流程效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hematoxylin and Eosin (H&amp;E) staining is a cornerstone of pathologicalanalysis, offering reliable visualization of cellular morphology and tissuearchitecture for cancer diagnosis, subtyping, and grading. Immunohistochemistry(IHC) staining provides molecular insights by detecting specific proteinswithin tissues, enhancing diagnostic accuracy, and improving treatmentplanning. However, IHC staining is costly, time-consuming, andresource-intensive, requiring specialized expertise. To address theselimitations, this study proposes HistoStainAlign, a novel deep learningframework that predicts IHC staining patterns directly from H&amp;E whole-slideimages (WSIs) by learning joint representations of morphological and molecularfeatures. The framework integrates paired H&amp;E and IHC embeddings through acontrastive training strategy, capturing complementary features across stainingmodalities without patch-level annotations or tissue registration. The modelwas evaluated on gastrointestinal and lung tissue WSIs with three commonly usedIHC stains: P53, PD-L1, and Ki-67. HistoStainAlign achieved weighted F1 scoresof 0.735 [95% Confidence Interval (CI): 0.670-0.799], 0.830 [95% CI:0.772-0.886], and 0.723 [95% CI: 0.607-0.836], respectively for these three IHCstains. Embedding analyses demonstrated the robustness of the contrastivealignment in capturing meaningful cross-stain relationships. Comparisons with abaseline model further highlight the advantage of incorporating contrastivelearning for improved stain pattern prediction. This study demonstrates thepotential of computational approaches to serve as a pre-screening tool, helpingprioritize cases for IHC staining and improving workflow efficiency.</description>
      <author>example@mail.com (Amit Das, Naofumi Tomita, Kyle J. Syme, Weijie Ma, Paige O'Connor, Kristin N. Corbett, Bing Ren, Xiaoying Liu, Saeed Hassanpour)</author>
      <guid isPermaLink="false">2506.15853v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Universal Music Representations? Evaluating Foundation Models on World Music Corpora</title>
      <link>http://arxiv.org/abs/2506.17055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ISMIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文对五种先进的音频基础模型进行了全面评估，这些模型在六个涵盖西方流行音乐、希腊、土耳其和印度古典音乐传统的音乐语料库中进行了测试。研究采用了三种互补的方法来探究这些模型的跨文化能力，并发现大模型在非西方音乐上表现较好，但在文化上距离较远的传统中表现下降。&lt;h4&gt;背景&lt;/h4&gt;基础模型已经彻底改变了音乐信息检索，但关于它们在不同音乐传统中泛化能力的疑问仍然存在。&lt;h4&gt;目的&lt;/h4&gt;评估五种先进的音频基础模型在六个不同音乐语料库中的跨文化能力。&lt;h4&gt;方法&lt;/h4&gt;研究采用了三种互补的方法：探查以评估内在表示、针对1-2层的监督微调和多标签少样本学习以应对资源有限的情况。&lt;h4&gt;主要发现&lt;/h4&gt;分析显示不同模型在跨文化泛化方面存在差异，大模型通常在非西方音乐上表现更佳，但在文化上距离较远的传统中表现下降。研究方法在五个数据集中实现了最先进的性能，表明基础模型在世界音乐理解方面的有效性。此外，研究还发现，针对的微调方法并不总是优于探查，这表明基础模型已经编码了大量的音乐知识。&lt;h4&gt;结论&lt;/h4&gt;该研究评估框架和基准结果有助于了解当前模型距离实现通用音乐表示有多远，并确立了未来进步的衡量标准。&lt;h4&gt;翻译&lt;/h4&gt;本文对五种先进的音频基础模型进行了全面评估，这些模型在六个涵盖西方流行音乐、希腊、土耳其和印度古典音乐传统的音乐语料库中进行了测试。研究采用了三种互补的方法来探究这些模型的跨文化能力，并发现大模型在非西方音乐上表现较好，但在文化上距离较远的传统中表现下降。分析显示不同模型在跨文化泛化方面存在差异，大模型通常在非西方音乐上表现更佳，但在文化上距离较远的传统中表现下降。研究方法在五个数据集中实现了最先进的性能，表明基础模型在世界音乐理解方面的有效性。此外，研究还发现，针对的微调方法并不总是优于探查，这表明基础模型已经编码了大量的音乐知识。该研究评估框架和基准结果有助于了解当前模型距离实现通用音乐表示有多远，并确立了未来进步的衡量标准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have revolutionized music information retrieval, butquestions remain about their ability to generalize across diverse musicaltraditions. This paper presents a comprehensive evaluation of fivestate-of-the-art audio foundation models across six musical corpora spanningWestern popular, Greek, Turkish, and Indian classical traditions. We employthree complementary methodologies to investigate these models' cross-culturalcapabilities: probing to assess inherent representations, targeted supervisedfine-tuning of 1-2 layers, and multi-label few-shot learning for low-resourcescenarios. Our analysis shows varying cross-cultural generalization, withlarger models typically outperforming on non-Western music, though resultsdecline for culturally distant traditions. Notably, our approaches achievestate-of-the-art performance on five out of six evaluated datasets,demonstrating the effectiveness of foundation models for world musicunderstanding. We also find that our targeted fine-tuning approach does notconsistently outperform probing across all settings, suggesting foundationmodels already encode substantial musical knowledge. Our evaluation frameworkand benchmarking results contribute to understanding how far current models arefrom achieving universal music representations while establishing metrics forfuture progress.</description>
      <author>example@mail.com (Charilaos Papaioannou, Emmanouil Benetos, Alexandros Potamianos)</author>
      <guid isPermaLink="false">2506.17055v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest LiDAR 3D Point Clouds</title>
      <link>http://arxiv.org/abs/2506.16991v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ForestFormer3D，一个用于森林LiDAR 3D点云分割的新框架，包括个体树木和语义分割。&lt;h4&gt;背景&lt;/h4&gt;森林LiDAR 3D点云的分割对于森林管理和生态研究至关重要，但现有的方法难以处理自然森林环境的复杂性和变化。&lt;h4&gt;目的&lt;/h4&gt;提出ForestFormer3D框架，以提高个体树木和语义分割的精确度。&lt;h4&gt;方法&lt;/h4&gt;ForestFormer3D集成了ISA引导的查询点选择、基于分数的块合并策略以及在训练中使用的一对多关联机制。&lt;h4&gt;主要发现&lt;/h4&gt;ForestFormer3D在新的FOR-instanceV2数据集上实现了个体树木分割的最新性能，该数据集涵盖了多种森林类型和地区。此外，该模型在不同森林条件和传感器模态下表现出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;FOR-instanceV2数据集和ForestFormer3D代码即将发布，展示了模型在不同环境下的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The segmentation of forest LiDAR 3D point clouds, including both individualtree and semantic segmentation, is fundamental for advancing forest managementand ecological research. However, current approaches often struggle with thecomplexity and variability of natural forest environments. We presentForestFormer3D, a new unified and end-to-end framework designed for preciseindividual tree and semantic segmentation. ForestFormer3D incorporatesISA-guided query point selection, a score-based block merging strategy duringinference, and a one-to-many association mechanism for effective training. Bycombining these new components, our model achieves state-of-the-art performancefor individual tree segmentation on the newly introduced FOR-instanceV2dataset, which spans diverse forest types and regions. Additionally,ForestFormer3D generalizes well to unseen test sets (Wytham woods and LAUTx),showcasing its robustness across different forest conditions and sensormodalities. The FOR-instanceV2 dataset and the ForestFormer3D code will bereleased soon.</description>
      <author>example@mail.com (Binbin Xiang, Maciej Wielgosz, Stefano Puliti, Kamil Král, Martin Krůček, Azim Missarov, Rasmus Astrup)</author>
      <guid isPermaLink="false">2506.16991v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>SlepNet: Spectral Subgraph Representation Learning for Neural Dynamics</title>
      <link>http://arxiv.org/abs/2506.16602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了SlepNet，一种新的GCN架构，用于处理图上的信号模式，特别适用于神经科学领域中的信号解码。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在处理图结构数据方面很有用，但它们在表示图上信号模式方面使用有限。图信号处理和相关的GCN模型无法有效地表示图上或子图上的空间或频谱局部化信号模式。&lt;h4&gt;目的&lt;/h4&gt;提出SlepNet以解决上述问题，通过使用Slepian基而不是图傅里叶谐波来优化信号能量的集中。&lt;h4&gt;方法&lt;/h4&gt;SlepNet使用Slepian谐波自动学习相关的子图，并将信号能量集中在这些子图上，从而产生标准的和高度解析的神经活动表示。&lt;h4&gt;主要发现&lt;/h4&gt;在三个fMRI数据集上评估了SlepNet，包括认知和视觉任务以及交通动态数据集，结果显示SlepNet在所有数据集上都优于基线模型。此外，SlepNet提取的信号模式表示提供了更高的分辨率，能够区分相似的信号模式，并将脑信号瞬态表示为信息轨迹。&lt;h4&gt;结论&lt;/h4&gt;SlepNet在时空数据的预测和表示学习方面都是有用的。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks have been useful in machine learning on graph-structured data, particularly for node classification and some types of graph classification tasks. However, they have had limited use in representing patterning of signals over graphs. Patterning of signals over graphs and in subgraphs carries important information in many domains including neuroscience. Neural signals are spatiotemporally patterned, high dimensional and difficult to decode. Graph signal processing and associated GCN models utilize the graph Fourier transform and are unable to efficiently represent spatially or spectrally localized signal patterning on graphs. Wavelet transforms have shown promise here, but offer non-canonical representations and cannot be tightly confined to subgraphs. Here we propose SlepNet, a novel GCN architecture that uses Slepian bases rather than graph Fourier harmonics. In SlepNet, the Slepian harmonics optimally concentrate signal energy on specifically relevant subgraphs that are automatically learned with a mask. Thus, they can produce canonical and highly resolved representations of neural activity, focusing energy of harmonics on areas of the brain which are activated. We evaluated SlepNet across three fMRI datasets, spanning cognitive and visual tasks, and two traffic dynamics datasets, comparing its performance against conventional GNNs and graph signal processing constructs. SlepNet outperforms the baselines in all datasets. Moreover, the extracted representations of signal patterns from SlepNet offer more resolution in distinguishing between similar patterns, and thus represent brain signaling transients as informative trajectories. Here we have shown that these extracted trajectory representations can be used for other downstream untrained tasks. Thus we establish that SlepNet is useful both for prediction and representation learning in spatiotemporal data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks have been useful in machine learning ongraph-structured data, particularly for node classification and some types ofgraph classification tasks. However, they have had limited use in representingpatterning of signals over graphs. Patterning of signals over graphs and insubgraphs carries important information in many domains including neuroscience.Neural signals are spatiotemporally patterned, high dimensional and difficultto decode. Graph signal processing and associated GCN models utilize the graphFourier transform and are unable to efficiently represent spatially orspectrally localized signal patterning on graphs. Wavelet transforms have shownpromise here, but offer non-canonical representations and cannot be tightlyconfined to subgraphs. Here we propose SlepNet, a novel GCN architecture thatuses Slepian bases rather than graph Fourier harmonics. In SlepNet, the Slepianharmonics optimally concentrate signal energy on specifically relevantsubgraphs that are automatically learned with a mask. Thus, they can producecanonical and highly resolved representations of neural activity, focusingenergy of harmonics on areas of the brain which are activated. We evaluatedSlepNet across three fMRI datasets, spanning cognitive and visual tasks, andtwo traffic dynamics datasets, comparing its performance against conventionalGNNs and graph signal processing constructs. SlepNet outperforms the baselinesin all datasets. Moreover, the extracted representations of signal patternsfrom SlepNet offers more resolution in distinguishing between similar patterns,and thus represent brain signaling transients as informative trajectories. Herewe have shown that these extracted trajectory representations can be used forother downstream untrained tasks. Thus we establish that SlepNet is useful bothfor prediction and representation learning in spatiotemporal data.</description>
      <author>example@mail.com (Siddharth Viswanath, Rahul Singh, Yanlei Zhang, J. Adam Noah, Joy Hirsch, Smita Krishnaswamy)</author>
      <guid isPermaLink="false">2506.16602v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Graphics4Science: Computer Graphics for Scientific Impacts</title>
      <link>http://arxiv.org/abs/2506.15786v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了计算机图形学与科学之间的深刻且不断发展的关系，强调了过去成就、持续贡献和未解决的开放性问题。&lt;h4&gt;背景&lt;/h4&gt;计算机图形学最初用于医学成像的3D可视化，现在在计算建模和模拟中发挥着作用，成为解决科学挑战的有力工具。&lt;h4&gt;目的&lt;/h4&gt;通过展示几何推理和物理建模等核心方法如何为两个领域提供归纳偏差，以帮助解决数据稀缺环境下的挑战，旨在将图形学重新定位为科学建模语言。&lt;h4&gt;方法&lt;/h4&gt;通过架起两个社区之间的词汇差距，该课程（Graphics4Science）旨在邀请图形学社区与科学界互动，解决图形学专长能够产生影响的重大问题。&lt;h4&gt;主要发现&lt;/h4&gt;核心方法如几何推理和物理建模为解决数据稀缺环境下的挑战提供了帮助。&lt;h4&gt;结论&lt;/h4&gt;Graphics4Science课程鼓励图形学社区参与科学界，对科学发现的未来做出贡献。&lt;h4&gt;翻译&lt;/h4&gt;摘要：计算机图形学，常与电影、游戏和视觉效果相关联，长期以来一直是解决科学挑战的有力工具——从其起源于医学成像的3D可视化，到其在现代计算建模和模拟中的作用。本课程探讨了计算机图形学与科学之间深刻且不断发展的关系，强调了过去的成就、持续的贡献和尚未解决的开放性问题。我们展示了核心方法，如几何推理和物理建模，如何为两个领域提供归纳偏差，帮助解决数据稀缺环境下的挑战。为此，我们旨在通过弥合两个社区之间的词汇差距，将图形学重新定位为科学的建模语言。本课程面向新人和专家，邀请图形学社区参与科学界，解决图形学专长能够产生影响的重大问题，并贡献于科学发现的未来。更多详情请访问课程网站：https://graphics4science.github.io&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computer graphics, often associated with films, games, and visual effects,has long been a powerful tool for addressing scientific challenges--from itsorigins in 3D visualization for medical imaging to its role in moderncomputational modeling and simulation. This course explores the deep andevolving relationship between computer graphics and science, highlighting pastachievements, ongoing contributions, and open questions that remain. We showhow core methods, such as geometric reasoning and physical modeling, provideinductive biases that help address challenges in both fields, especially indata-scarce settings. To that end, we aim to reframe graphics as a modelinglanguage for science by bridging vocabulary gaps between the two communities.Designed for both newcomers and experts, Graphics4Science invites the graphicscommunity to engage with science, tackle high-impact problems where graphicsexpertise can make a difference, and contribute to the future of scientificdiscovery. Additional details are available on the course website:https://graphics4science.github.io</description>
      <author>example@mail.com (Peter Yichen Chen, Minghao Guo, Hanspeter Pfister, Ming Lin, William Freeman, Qixing Huang, Han-Wei Shen, Wojciech Matusik)</author>
      <guid isPermaLink="false">2506.15786v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You</title>
      <link>http://arxiv.org/abs/2506.16895v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在有限对齐数据下构建多模态模型的可能性，通过预训练的单模态基础模型进行对齐，显著提升了零样本分类和跨模态检索的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态模型通常依赖于数百万的对齐样本，这在许多领域成本高昂或难以获取。&lt;h4&gt;目的&lt;/h4&gt;研究在有限对齐数据下构建多模态模型的可行性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为STRUCTURE的优化技术，以保持单模态编码器潜在空间的邻域几何。同时，发现对齐最后一层通常效果不佳，并证明了跨模态之间具有最高表征相似性的层进行对齐的优势。&lt;h4&gt;主要发现&lt;/h4&gt;通过数千个对齐样本（少于领域内典型数据的1%）即可实现高质量的对齐，显著提升了24个零样本图像分类和检索基准的性能，分类任务的平均相对提升为51.6%，检索任务为91.8%。&lt;h4&gt;结论&lt;/h4&gt;该框架对于有限样本的多模态学习具有有效性和广泛适用性，为资源受限领域提供了一条有前景的发展路径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态模型在需要多模态对齐的复杂任务中，如零样本分类和跨模态检索，已经展现出强大的能力。然而，现有的模型通常依赖于数百万的对齐多模态样本，这在许多领域成本高昂或难以获取。在本研究中，我们探讨了通过对齐预训练的单模态基础模型，在有限对齐数据下构建多模态模型的可行性。我们表明，即使只有数千个对齐样本，也可以实现高质量的对齐——这比该领域通常使用的1%的数据还要少。为了实现这一点，我们引入了一种有效的正则化技术——STRUCTURE，它能够保持单模态编码器潜在空间的邻域几何。此外，我们还发现对齐最后一层通常是不够优的，并证明了与跨模态之间具有最高表征相似性的层进行对齐的优势。这两个组件可以很容易地集成到现有的对齐方法中，在24个零样本图像分类和检索基准上带来了显著的提升，分类任务的平均相对提升为51.6%，检索任务为91.8%。我们的结果突出了我们的框架在有限样本多模态学习中的有效性和广泛适用性，为资源受限领域提供了一条有前景的发展路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal models have demonstrated powerful capabilities in complex tasksrequiring multimodal alignment including zero-shot classification andcross-modal retrieval. However, existing models typically rely on millions ofpaired multimodal samples, which are prohibitively expensive or infeasible toobtain in many domains. In this work, we explore the feasibility of buildingmultimodal models with limited amount of paired data by aligning pretrainedunimodal foundation models. We show that high-quality alignment is possiblewith as few as tens of thousands of paired samples$\unicode{x2013}$less than$1\%$ of the data typically used in the field. To achieve this, we introduceSTRUCTURE, an effective regularization technique that preserves theneighborhood geometry of the latent space of unimodal encoders. Additionally,we show that aligning last layers is often suboptimal and demonstrate thebenefits of aligning the layers with the highest representational similarityacross modalities. These two components can be readily incorporated intoexisting alignment methods, yielding substantial gains across 24 zero-shotimage classification and retrieval benchmarks, with average relativeimprovement of $51.6\%$ in classification and $91.8\%$ in retrieval tasks. Ourresults highlight the effectiveness and broad applicability of our frameworkfor limited-sample multimodal learning and offer a promising path forward forresource-constrained domains.</description>
      <author>example@mail.com (Fabian Gröger, Shuo Wen, Huyen Le, Maria Brbić)</author>
      <guid isPermaLink="false">2506.16895v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Geometric Learning in Black-Box Optimization: A GNN Framework for Algorithm Performance Prediction</title>
      <link>http://arxiv.org/abs/2506.16144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用异构图数据结构和图神经网络预测数值黑盒优化中自动算法性能的方法，通过捕捉问题、算法配置和性能结果之间的复杂依赖关系。&lt;h4&gt;背景&lt;/h4&gt;在数值黑盒优化中，自动算法性能预测通常依赖于问题特征，如探索性景观分析特征，但这些方法往往忽略了算法配置这一关键因素。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过使用图神经网络和异构图数据结构来预测优化算法的性能。&lt;h4&gt;方法&lt;/h4&gt;本文聚焦于两个模块化框架modCMA-ES和modDE，它们分别分解了两种广泛使用的无导数优化算法CMA-ES和DE。在24个BBOB问题上，对324个modCMA-ES和576个modDE变体进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;与传统的基于表格的方法相比，该方法在MSE上实现了高达36.6%的改进，突出了几何学习在黑盒优化中的潜力。&lt;h4&gt;结论&lt;/h4&gt;本文强调了使用图神经网络和异构图数据结构在黑盒优化中预测算法性能的潜力，并证明了这种方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;This work explores the use of heterogeneous graph data structures and graph neural networks to predict the performance of optimization algorithms by capturing the complex dependencies between problems, algorithm configurations, and performance outcomes. We focus on two modular frameworks, modCMA-ES and modDE, which decompose two widely used derivative-free optimization algorithms: the covariance matrix adaptation evolution strategy (CMA-ES) and differential evolution (DE). We evaluate 324 modCMA-ES and 576 modDE variants on 24 BBOB problems across six runtime budgets and two problem dimensions. Achieving up to 36.6% improvement in MSE over traditional tabular-based methods, this work highlights the potential of geometric learning in black-box optimization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated algorithm performance prediction in numerical blackbox optimizationoften relies on problem characterizations, such as exploratory landscapeanalysis features. These features are typically used as inputs to machinelearning models and are represented in a tabular format. However, suchapproaches often overlook algorithm configurations, a key factor influencingperformance. The relationships between algorithm operators, parameters, problemcharacteristics, and performance outcomes form a complex structure bestrepresented as a graph. This work explores the use of heterogeneous graph datastructures and graph neural networks to predict the performance of optimizationalgorithms by capturing the complex dependencies between problems, algorithmconfigurations, and performance outcomes. We focus on two modular frameworks,modCMA-ES and modDE, which decompose two widely used derivative-freeoptimization algorithms: the covariance matrix adaptation evolution strategy(CMA-ES) and differential evolution (DE). We evaluate 324 modCMA-ES and 576modDE variants on 24 BBOB problems across six runtime budgets and two problemdimensions. Achieving up to 36.6% improvement in MSE over traditionaltabular-based methods, this work highlights the potential of geometric learningin black-box optimization.</description>
      <author>example@mail.com (Ana Kostovska, Carola Doerr, Sašo Džeroski, Panče Panov, Tome Eftimov)</author>
      <guid isPermaLink="false">2506.16144v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>TabArena: A Living Benchmark for Machine Learning on Tabular Data</title>
      <link>http://arxiv.org/abs/2506.16791v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  51 pages. Code available at https://tabarena.ai/code; examples at  https://tabarena.ai/code-examples; dataset curation at  https://tabarena.ai/data-tabular-ml-iid-study and  https://tabarena.ai/dataset-curation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TabArena，一个连续维护的活表格基准测试系统，用于解决现有基准测试静态性的问题。&lt;h4&gt;背景&lt;/h4&gt;随着深度学习和表格数据基础模型越来越受欢迎，对标准化和可靠的基准测试的需求日益增加。&lt;h4&gt;目的&lt;/h4&gt;设计TabArena以解决现有基准测试静态性问题，并提高模型基准测试的可靠性。&lt;h4&gt;方法&lt;/h4&gt;手动编制数据集和模型集合，进行大规模基准测试研究，建立公共排行榜，并组建维护团队。&lt;h4&gt;主要发现&lt;/h4&gt;验证方法和超参数配置的集成对基准测试模型性能有显著影响；集成方法使深度学习在较大时间预算下追上梯度提升树；基础模型在小数据集上表现卓越；模型集成推进了表格机器学习领域的最新进展。&lt;h4&gt;结论&lt;/h4&gt;TabArena通过提供可重复的代码和维护协议，创建了一个活基准测试，可在https://tabarena.ai访问。&lt;h4&gt;翻译&lt;/h4&gt;With the growing popularity of deep learning and foundation models for tabular data, the need for standardized and reliable benchmarks is higher than ever. However, current benchmarks are static. Their design is not updated even if flaws are discovered, model versions are updated, or new models are released. To address this, we introduce TabArena, the first continuously maintained living tabular benchmarking system. To launch TabArena, we manually curate a representative collection of datasets and well-implemented models, conduct a large-scale benchmarking study to initialize a public leaderboard, and assemble a team of experienced maintainers. Our results highlight the influence of validation method and ensembling of hyperparameter configurations to benchmark models at their full potential. While gradient-boosted trees are still strong contenders on practical tabular datasets, we observe that deep learning methods have caught up under larger time budgets with ensembling. At the same time, foundation models excel on smaller datasets. Finally, we show that ensembles across models advance the state-of-the-art in tabular machine learning and investigate the contributions of individual models. We launch TabArena with a public leaderboard, reproducible code, and maintenance protocols to create a living benchmark available at https://tabarena.ai.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing popularity of deep learning and foundation models fortabular data, the need for standardized and reliable benchmarks is higher thanever. However, current benchmarks are static. Their design is not updated evenif flaws are discovered, model versions are updated, or new models arereleased. To address this, we introduce TabArena, the first continuouslymaintained living tabular benchmarking system. To launch TabArena, we manuallycurate a representative collection of datasets and well-implemented models,conduct a large-scale benchmarking study to initialize a public leaderboard,and assemble a team of experienced maintainers. Our results highlight theinfluence of validation method and ensembling of hyperparameter configurationsto benchmark models at their full potential. While gradient-boosted trees arestill strong contenders on practical tabular datasets, we observe that deeplearning methods have caught up under larger time budgets with ensembling. Atthe same time, foundation models excel on smaller datasets. Finally, we showthat ensembles across models advance the state-of-the-art in tabular machinelearning and investigate the contributions of individual models. We launchTabArena with a public leaderboard, reproducible code, and maintenanceprotocols to create a living benchmark available at https://tabarena.ai.</description>
      <author>example@mail.com (Nick Erickson, Lennart Purucker, Andrej Tschalzev, David Holzmüller, Prateek Mutalik Desai, and David Salinas, Frank Hutter)</author>
      <guid isPermaLink="false">2506.16791v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>SDDiff: Boost Radar Perception via Spatial-Doppler Diffusion</title>
      <link>http://arxiv.org/abs/2506.16936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SDDiff的模型，用于同时进行密集点云提取（PCE）和精确的自车速度估计（EVE），以提高3D雷达感知的准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的点云提取和自车速度估计工作通常独立处理，忽略了雷达的空间和多普勒域特征之间的相互作用，可能导致额外的偏差。&lt;h4&gt;目的&lt;/h4&gt;设计一个同时进行密集点云提取和精确的自车速度估计的模型，以充分利用两者之间的相关性。&lt;h4&gt;方法&lt;/h4&gt;SDDiff模型通过以下三个方面改进了传统的潜在扩散过程：引入同时体现空间占有和多普勒特征的表现形式；设计具有雷达先验的方向性扩散以简化采样；提出迭代多普勒细化以增强模型对密度变化和鬼影效应的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;SDDiff在EVE准确性方面比现有最佳基线高出59%，在有效生成密度方面提高了4倍，同时增强了PCE的有效性和可靠性。&lt;h4&gt;结论&lt;/h4&gt;SDDiff模型在3D雷达感知中表现出显著的优越性，对于同时进行点云提取和自车速度估计具有实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：点云提取（PCE）和自车速度估计（EVE）是3D雷达感知的关键能力，受到关注。然而，现有的工作通常独立处理这两个任务，这可能会忽视雷达空间和多普勒域特征之间的相互作用，可能导致额外的偏差。在本文中，我们观察到3D点和自车速度之间存在潜在的相关性，这为PCE和EVE提供了相互利益。为了充分释放这种鼓舞人心的潜力，我们迈出了第一步，设计了一种空间-多普勒扩散（SDDiff）模型，以同时进行密集的PCE和精确的EVE。为了无缝地将其定制到雷达感知中，SDDiff在三个方面改进了传统的潜在扩散过程。首先，我们引入了一种同时体现空间占有和多普勒特征的表现形式。其次，我们设计了具有雷达先验的方向性扩散以简化采样。第三，我们提出了迭代多普勒细化以增强模型对密度变化和鬼影效应的适应性。广泛的评估表明，SDDiff在EVE准确性方面比现有最佳基线高出59%，在有效生成密度方面提高了4倍，同时提高了PCE的有效性和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud extraction (PCE) and ego velocity estimation (EVE) are keycapabilities gaining attention in 3D radar perception. However, existing worktypically treats these two tasks independently, which may neglect the interplaybetween radar's spatial and Doppler domain features, potentially introducingadditional bias. In this paper, we observe an underlying correlation between 3Dpoints and ego velocity, which offers reciprocal benefits for PCE and EVE. Tofully unlock such inspiring potential, we take the first step to design aSpatial-Doppler Diffusion (SDDiff) model for simultaneously dense PCE andaccurate EVE. To seamlessly tailor it to radar perception, SDDiff improves theconventional latent diffusion process in three major aspects. First, weintroduce a representation that embodies both spatial occupancy and Dopplerfeatures. Second, we design a directional diffusion with radar priors tostreamline the sampling. Third, we propose Iterative Doppler Refinement toenhance the model's adaptability to density variations and ghosting effects.Extensive evaluations show that SDDiff significantly outperformsstate-of-the-art baselines by achieving 59% higher in EVE accuracy, 4X greaterin valid generation density while boosting PCE effectiveness and reliability.</description>
      <author>example@mail.com (Shengpeng Wang, Xin Luo, Yulong Xie, Wei Wang)</author>
      <guid isPermaLink="false">2506.16936v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>InfiniPot-V: Memory-Constrained KV Cache Compression for Streaming Video Understanding</title>
      <link>http://arxiv.org/abs/2506.15745v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;InfiniPot-V是一种无需训练、不依赖查询的框架，为流媒体理解中的视频压缩提供了一种新的方法，可以有效地减少内存使用。&lt;h4&gt;背景&lt;/h4&gt;现代多模态大型语言模型（MLLMs）在处理时长为一小时的视频时，其键值（KV）缓存会随着时间线性增长，很快超过手机、增强现实眼镜和边缘机器人的固定内存。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需训练、不依赖查询的框架，为流媒体理解中的视频压缩提供一种解决方案，以减少内存使用。&lt;h4&gt;方法&lt;/h4&gt;InfiniPot-V在视频编码过程中监控缓存，并在达到用户设置的阈值时运行轻量级的压缩过程。该过程包括：（i）通过时间轴冗余（TaR）指标移除时间上冗余的标记；（ii）通过值规范（VaN）排名保留语义上重要的标记。&lt;h4&gt;主要发现&lt;/h4&gt;InfiniPot-V在四个开源MLLMs以及四个长视频和两个流视频基准测试中，将峰值GPU内存减少了高达94%，并保持了实时生成，其准确率与完整缓存相当甚至更高。&lt;h4&gt;结论&lt;/h4&gt;通过解决KV缓存瓶颈而不需要重新训练或查询知识，InfiniPot-V缩小了设备上流媒体助手与云端服务的差距。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代多模态大型语言模型（MLLMs）能够推理一小时的视频，但它们的键值（KV）缓存会随着时间线性增长——很快就会超过手机、增强现实眼镜和边缘机器人的固定内存。之前的压缩方案要么假设整个视频和用户查询都可用离线，要么必须首先构建完整的缓存，因此内存仍然随着流长而扩展。InfiniPot-V是第一个无需训练、查询无关的框架，为流式视频理解强制执行一个硬性、长度无关的内存上限。在视频编码期间，它监控缓存，一旦达到用户设置的阈值，就运行一个轻量级的压缩过程，该过程（i）通过时间轴冗余（TaR）指标移除时间上冗余的标记；（ii）通过值规范（VaN）排名保留语义上重要的标记。在四个开源MLLMs和四个长视频以及两个流视频基准测试中，InfiniPot-V将峰值GPU内存减少了高达94%，并保持了实时生成，其准确率与完整缓存相当甚至更高。通过解决KV缓存瓶颈而不重新训练或查询知识，InfiniPot-V缩小了设备上流媒体助手与云端服务的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern multimodal large language models (MLLMs) can reason over hour-longvideo, yet their key-value (KV) cache grows linearly with time--quicklyexceeding the fixed memory of phones, AR glasses, and edge robots. Priorcompression schemes either assume the whole video and user query are availableoffline or must first build the full cache, so memory still scales with streamlength. InfiniPot-V is the first training-free, query-agnostic framework thatenforces a hard, length-independent memory cap for streaming videounderstanding. During video encoding it monitors the cache and, once a user-setthreshold is reached, runs a lightweight compression pass that (i) removestemporally redundant tokens via Temporal-axis Redundancy (TaR) metric and (ii)keeps semantically significant tokens via Value-Norm (VaN) ranking. Across fouropen-source MLLMs and four long-video and two streaming-video benchmarks,InfiniPot-V cuts peak GPU memory by up to 94%, sustains real-time generation,and matches or surpasses full-cache accuracy--even in multi-turn dialogues. Bydissolving the KV cache bottleneck without retraining or query knowledge,InfiniPot-V closes the gap for on-device streaming video assistants.</description>
      <author>example@mail.com (Minsoo Kim, Kyuhong Shim, Jungwook Choi, Simyung Chang)</author>
      <guid isPermaLink="false">2506.15745v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Weakly-supervised VLM-guided Partial Contrastive Learning for Visual Language Navigation</title>
      <link>http://arxiv.org/abs/2506.15757v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对视觉语言导航（VLN）领域中的挑战，提出了一种名为弱监督部分对比学习（WPCL）的方法，以提高智能体在动态视点下的物体识别能力。&lt;h4&gt;背景&lt;/h4&gt;VLN是Embodied AI领域的基本任务，旨在让智能体根据自然语言指令在复杂环境中导航。现有方法存在依赖预训练模型、缺乏领域知识以及计算成本高等问题。&lt;h4&gt;目的&lt;/h4&gt;提出WPCL方法，旨在解决VLN场景中动态视点识别的难题，同时提高计算效率。&lt;h4&gt;方法&lt;/h4&gt;WPCL方法通过将预训练的视觉语言模型（VLM）知识有效地整合到感知过程中，增强智能体在VLN场景中识别物体的能力，而无需对VLM进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，WPCL方法在多个基准测试中优于基线方法，验证了其有效性、鲁棒性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;WPCL方法有效地解决了VLN中的挑战，为智能体在复杂环境中的导航提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Language Navigation (VLN) is a fundamental task within the field ofEmbodied AI, focusing on the ability of agents to navigate complex environmentsbased on natural language instructions. Despite the progress made by existingmethods, these methods often present some common challenges. First, they relyon pre-trained backbone models for visual perception, which struggle with thedynamic viewpoints in VLN scenarios. Second, the performance is limited whenusing pre-trained LLMs or VLMs without fine-tuning, due to the absence of VLNdomain knowledge. Third, while fine-tuning LLMs and VLMs can improve results,their computational costs are higher than those without fine-tuning. To addressthese limitations, we propose Weakly-supervised Partial Contrastive Learning(WPCL), a method that enhances an agent's ability to identify objects fromdynamic viewpoints in VLN scenarios by effectively integrating pre-trained VLMknowledge into the perception process, without requiring VLM fine-tuning. Ourmethod enhances the agent's ability to interpret and respond to environmentalcues while ensuring computational efficiency. Experimental results have shownthat our method outperforms the baseline methods on multiple benchmarks, whichvalidate the effectiveness, robustness and generalizability of our method.</description>
      <author>example@mail.com (Ruoyu Wang, Tong Yu, Junda Wu, Yao Liu, Julian McAuley, Lina Yao)</author>
      <guid isPermaLink="false">2506.15757v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Structured Semantic 3D Reconstruction (S23DR) Challenge 2025 -- Winning solution</title>
      <link>http://arxiv.org/abs/2506.16421v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了S23DR Challenge 2025比赛的获胜方案，该方案涉及从稀疏点云和语义分割中预测房屋的3D屋顶线框。&lt;h4&gt;背景&lt;/h4&gt;该研究针对的是从稀疏点云和语义分割中预测3D屋顶线框的问题。&lt;h4&gt;目的&lt;/h4&gt;目标是开发一种能够准确预测房屋3D屋顶线框的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法首先在3D空间中工作，通过Gestalt分割从COLMAP点云中识别顶点候选，然后使用两个PointNet-like模型：一个用于通过分析局部立方块来细化和对候选进行分类，另一个用于通过处理连接顶点对的圆柱区域来预测边缘。&lt;h4&gt;主要发现&lt;/h4&gt;这种两阶段的3D深度学习方法在私人排行榜上实现了0.43的混合结构得分（HSS），获得了比赛的胜利。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在预测3D屋顶线框方面表现出色，为该领域的研究提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了S23DR挑战赛2025的获胜方案，该方案涉及从稀疏点云和语义分割中预测房屋的3D屋顶线框。我们的方法直接在3D空间中操作，首先使用Gestalt分割从COLMAP点云中识别顶点候选。然后我们使用两个PointNet-like模型：一个用于通过分析局部立方块来细化和对这些候选进行分类，另一个用于通过处理连接顶点对的圆柱区域来预测边缘。这种两阶段的3D深度学习方法在私人排行榜上实现了0.43的混合结构得分（HSS），获得了比赛的胜利。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents the winning solution for the S23DR Challenge 2025, whichinvolves predicting a house's 3D roof wireframe from a sparse point cloud andsemantic segmentations. Our method operates directly in 3D, first identifyingvertex candidates from the COLMAP point cloud using Gestalt segmentations. Wethen employ two PointNet-like models: one to refine and classify thesecandidates by analyzing local cubic patches, and a second to predict edges byprocessing the cylindrical regions connecting vertex pairs. This two-stage, 3Ddeep learning approach achieved a winning Hybrid Structure Score (HSS) of 0.43on the private leaderboard.</description>
      <author>example@mail.com (Jan Skvrna, Lukas Neumann)</author>
      <guid isPermaLink="false">2506.16421v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting LoRA through the Lens of Parameter Redundancy: Spectral Encoding Helps</title>
      <link>http://arxiv.org/abs/2506.16787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages; Accepted to ACL 2025 Findings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SeLoRA是一种基于谱编码的低秩自适应技术，用于微调大型基础模型，通过减少参数冗余提高了效率和性能。&lt;h4&gt;背景&lt;/h4&gt;LoRA在微调大型基础模型方面表现出色，但其参数冗余限制了其容量和效率。&lt;h4&gt;目的&lt;/h4&gt;研究LoRA微调中冗余的影响，并提出一种新的方法来提高其效率和性能。&lt;h4&gt;方法&lt;/h4&gt;提出SeLoRA，利用谱基的鲁棒表达能力，从稀疏谱子空间重新参数化LoRA。&lt;h4&gt;主要发现&lt;/h4&gt;减少密度冗余不会降低表达能力。&lt;h4&gt;结论&lt;/h4&gt;SeLoRA在多种下游任务上，如常识推理、数学推理和代码生成，实现了更高的效率，并优于强基线。&lt;h4&gt;翻译&lt;/h4&gt;Low-Rank Adaptation (LoRA) 已成为微调大型基础模型的重要技术。尽管取得了成功，但大量参数冗余限制了LoRA的容量和效率，这已被视为瓶颈。在本工作中，我们系统地研究了LoRA微调中冗余的影响，并揭示了减少密度冗余不会降低表达能力。基于这一见解，我们引入了Spectral-encoding Low-Rank Adaptation (SeLoRA)，它利用谱基的鲁棒表达能力，从稀疏谱子空间重新参数化LoRA。SeLoRA设计简单，可以无缝集成到各种LoRA变体中，以提高性能，作为一种可扩展的即插即用框架。大量实验证实，SeLoRA以更少的参数实现了更高的效率，在各种下游任务上，包括常识推理、数学推理和代码生成，提供了比强基线更好的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-Rank Adaptation (LoRA) has emerged as a prominent technique forfine-tuning large foundation models. Despite its successes, the substantialparameter redundancy, which limits the capacity and efficiency of LoRA, hasbeen recognized as a bottleneck. In this work, we systematically investigatethe impact of redundancy in fine-tuning LoRA and reveal that reducing densityredundancy does not degrade expressiveness. Based on this insight, we introduce\underline{S}pectral-\underline{e}ncoding \underline{L}ow-\underline{R}ank\underline{A}daptation (SeLoRA), which harnesses the robust expressiveness ofspectral bases to re-parameterize LoRA from a sparse spectral subspace.Designed with simplicity, SeLoRA enables seamless integration with various LoRAvariants for performance boosting, serving as a scalable plug-and-playframework. Extensive experiments substantiate that SeLoRA achieves greaterefficiency with fewer parameters, delivering superior performance enhancementsover strong baselines on various downstream tasks, including commonsensereasoning, math reasoning, and code generation.</description>
      <author>example@mail.com (Jiashun Cheng, Aochuan Chen, Nuo Chen, Ziqi Gao, Yuhan Li, Jia Li, Fugee Tsung)</author>
      <guid isPermaLink="false">2506.16787v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Refining music sample identification with a self-supervised graph neural network</title>
      <link>http://arxiv.org/abs/2506.14684v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at International Conference for Music Information Retrieval  (ISMIR) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种轻量级且可扩展的编码架构，用于自动样本识别（ASID），旨在解决音频检索领域中的挑战。&lt;h4&gt;背景&lt;/h4&gt;自动样本识别是检测和识别在新的音乐作品中重复使用的音频片段的任务，这是一个重要但具有挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够抵抗音乐制作中常见变换（如时间伸缩、音高变换、效果处理以及底层或叠加的音乐）的鲁棒系统。&lt;h4&gt;方法&lt;/h4&gt;提出了一种使用图神经网络在对比学习框架内的轻量级编码架构，并通过两阶段方法提高检索质量：第一阶段进行粗略相似性搜索以选择候选样本，第二阶段使用跨注意力分类器拒绝无关匹配并细化检索候选的排名。&lt;h4&gt;主要发现&lt;/h4&gt;与现有最先进的系统相比，该模型仅使用9%的可训练参数，同时实现了可比的性能，平均平均精度（mAP）达到44.2%。&lt;h4&gt;结论&lt;/h4&gt;该系统通过新的细粒度标注对短查询进行了基准测试，并发布了Sample100数据集作为本研究的一部分。&lt;h4&gt;翻译&lt;/h4&gt;自动样本识别（ASID），检测和识别在新的音乐作品中重复使用的音频记录片段，是音频查询检索领域中的一个基本但具有挑战性的任务。虽然与音频指纹识别相关的任务在“真实世界”条件下（噪声、混响）不准确地检索音乐内容方面取得了重大进展，但ASID系统在识别经过音乐修改的样本方面仍存在困难。因此，一个能够抵抗常见音乐制作变换（如时间伸缩、音高变换、效果处理以及底层或叠加的音乐）的系统是一个重要的开放挑战。在本工作中，我们提出了一种轻量级且可扩展的编码架构，采用对比学习框架内的图神经网络。与当前最先进的系统相比，我们的模型仅使用9%的可训练参数，同时实现了可比的性能，平均平均精度（mAP）达到44.2%。为了提高检索质量，我们引入了一种两阶段方法，包括一个初始的粗略相似性搜索以选择候选样本，随后是一个跨注意力分类器，该分类器拒绝无关匹配并细化检索候选的排名——这是先前模型所缺乏的基本能力。此外，由于现实世界应用中的查询通常较短，我们对使用新细粒度标注的Sample100数据集进行了短查询的基准测试，并将这些标注作为本研究的一部分发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/chymaera96/neuralsampleid&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic sample identification (ASID), the detection and identification ofportions of audio recordings that have been reused in new musical works, is anessential but challenging task in the field of audio query-based retrieval.While a related task, audio fingerprinting, has made significant progress inaccurately retrieving musical content under "real world" (noisy, reverberant)conditions, ASID systems struggle to identify samples that have undergonemusical modifications. Thus, a system robust to common music productiontransformations such as time-stretching, pitch-shifting, effects processing,and underlying or overlaying music is an important open challenge.  In this work, we propose a lightweight and scalable encoding architectureemploying a Graph Neural Network within a contrastive learning framework. Ourmodel uses only 9% of the trainable parameters compared to the currentstate-of-the-art system while achieving comparable performance, reaching a meanaverage precision (mAP) of 44.2%.  To enhance retrieval quality, we introduce a two-stage approach consisting ofan initial coarse similarity search for candidate selection, followed by across-attention classifier that rejects irrelevant matches and refines theranking of retrieved candidates - an essential capability absent in priormodels. In addition, because queries in real-world applications are often shortin duration, we benchmark our system for short queries using new fine-grainedannotations for the Sample100 dataset, which we publish as part of this work.</description>
      <author>example@mail.com (Aditya Bhattacharjee, Ivan Meresman Higgs, Mark Sandler, Emmanouil Benetos)</author>
      <guid isPermaLink="false">2506.14684v2</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Wavelet-based Global Orientation and Surface Reconstruction for Point Clouds</title>
      <link>http://arxiv.org/abs/2506.16299v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22Pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于小波变换的表面重建方法，用于无向点云的表面重建和方向重建，并实现了高效的计算性能。&lt;h4&gt;背景&lt;/h4&gt;无向表面重建在计算机图形学中非常重要，具有广泛的应用。传统的基于小波变换的方法仅适用于有向点，且在处理稀疏点云时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以解决传统方法在处理无向点和稀疏点云时的不足。&lt;h4&gt;方法&lt;/h4&gt;该方法利用小波变换的紧支集特性和正交性质，通过改进的核函数平滑表面上的不连续性，并使用卷积核函数的性质加速计算。同时，提出了一种新的构建无散度函数场的方法，以及使用该函数场构建额外的齐次约束条件，以提高重建的有效性和稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在无向点和稀疏点云的表面重建和方向重建方面均取得了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在CPU上实现了高效的性能，并且将在GitHub上发布源代码。&lt;h4&gt;翻译&lt;/h4&gt;Unoriented surface reconstruction is an important task in computer graphics and has extensive applications. Based on the compact support of wavelet and orthogonality properties, classic wavelet surface reconstruction achieves good and fast reconstruction. However, this method can only handle oriented points. Despite some improved attempts for unoriented points, such as iWSR, these methods perform poorly on sparse point clouds. To address these shortcomings, we propose a wavelet-based method to represent the mollified indicator function and complete both the orientation and surface reconstruction tasks. We use the modifying kernel function to smoothen out discontinuities on the surface, aligning with the continuity of the wavelet basis function. During the calculation of coefficient, we fully utilize the properties of the convolutional kernel function to shift the modifying computation onto wavelet basis to accelerate. In addition, we propose a novel method for constructing the divergence-free function field and using them to construct the additional homogeneous constraints to improve the effectiveness and stability. Extensive experiments demonstrate that our method achieves state-of-the-art performance in both orientation and reconstruction for sparse models. We align the matrix construction with the compact support property of wavelet basis functions to further accelerate our method, resulting in efficient performance on CPU. Our source codes will be released on GitHub.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unoriented surface reconstruction is an important task in computer graphicsand has extensive applications. Based on the compact support of wavelet andorthogonality properties, classic wavelet surface reconstruction achieves goodand fast reconstruction. However, this method can only handle oriented points.Despite some improved attempts for unoriented points, such as iWSR, thesemethods perform poorly on sparse point clouds. To address these shortcomings,we propose a wavelet-based method to represent the mollified indicator functionand complete both the orientation and surface reconstruction tasks. We use themodifying kernel function to smoothen out discontinuities on the surface,aligning with the continuity of the wavelet basis function. During thecalculation of coefficient, we fully utilize the properties of theconvolutional kernel function to shift the modifying computation onto waveletbasis to accelerate. In addition, we propose a novel method for constructingthe divergence-free function field and using them to construct the additionalhomogeneous constraints to improve the effectiveness and stability. Extensiveexperiments demonstrate that our method achieves state-of-the-art performancein both orientation and reconstruction for sparse models. We align the matrixconstruction with the compact support property of wavelet basis functions tofurther accelerate our method, resulting in efficient performance on CPU. Oursource codes will be released on GitHub.</description>
      <author>example@mail.com (Yueji Ma, Yanzun Meng, Dong Xiao, Zuoqiang Shi, Bin Wang)</author>
      <guid isPermaLink="false">2506.16299v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating Over-Squashing in Graph Neural Networks by Spectrum-Preserving Sparsification</title>
      <link>http://arxiv.org/abs/2506.16110v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published as a conference paper at ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图重连方法，通过利用谱保持图稀疏化来减轻过度压缩问题，从而在提高图连接性的同时保持稀疏性和原图谱的大致不变。&lt;h4&gt;背景&lt;/h4&gt;图神经网络的信息传递范式在交换远距离节点信息时遇到困难，通常是由于某些图区域的结构性瓶颈造成的，这一局限性被称为过度压缩。&lt;h4&gt;目的&lt;/h4&gt;减少结构性瓶颈，提出一种新的图重连方法，以改善图神经网络的信息传递。&lt;h4&gt;方法&lt;/h4&gt;该方法通过谱保持图稀疏化来生成具有增强连接性的图，同时保持稀疏性和原图谱的大致不变。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在分类准确性和拉普拉斯谱保留方面优于强基线方法。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地平衡了结构性瓶颈的减少和图属性的保留，验证了其在图重连方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;The message-passing paradigm of Graph Neural Networks often struggles with exchanging information across distant nodes typically due to structural bottlenecks in certain graph regions, a limitation known as 'over-squashing'. To reduce such bottlenecks, 'graph rewiring', which modifies graph topology, has been widely used. However, existing graphrewiring techniques often overlook the need to preserve critical properties of the original graph, e.g., 'spectral properties'. Moreover, many approaches rely on increasing edge count to improve connectivity, which introduces significant computational overhead and exacerbates the risk ofover-smoothing. In this paper, we propose a novel graph rewiring method that leverages 'spectrum-preserving' graph 'sparsification', formitigating over-squashing. Our method generates graphs with enhanced connectivity while maintaining sparsity and largely preserving the original graph spectrum, effectively balancing structural bottleneck reduction and graph property preservation. Experimental results validate the effectiveness of our approach, demonstrating its superiority over strong baseline methods in classification accuracy and retention of the Laplacian spectrum.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The message-passing paradigm of Graph Neural Networks often struggles withexchanging information across distant nodes typically due to structuralbottlenecks in certain graph regions, a limitation known as\textit{over-squashing}. To reduce such bottlenecks, \textit{graph rewiring},which modifies graph topology, has been widely used. However, existing graphrewiring techniques often overlook the need to preserve critical properties ofthe original graph, e.g., \textit{spectral properties}. Moreover, manyapproaches rely on increasing edge count to improve connectivity, whichintroduces significant computational overhead and exacerbates the risk ofover-smoothing. In this paper, we propose a novel graph rewiring method thatleverages \textit{spectrum-preserving} graph \textit{sparsification}, formitigating over-squashing. Our method generates graphs with enhancedconnectivity while maintaining sparsity and largely preserving the originalgraph spectrum, effectively balancing structural bottleneck reduction and graphproperty preservation. Experimental results validate the effectiveness of ourapproach, demonstrating its superiority over strong baseline methods inclassification accuracy and retention of the Laplacian spectrum.</description>
      <author>example@mail.com (Langzhang Liang, Fanchen Bu, Zixing Song, Zenglin Xu, Shirui Pan, Kijung Shin)</author>
      <guid isPermaLink="false">2506.16110v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Weight Factorization and Centralization for Continual Learning in Speech Recognition</title>
      <link>http://arxiv.org/abs/2506.16574v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to INTERSPEECH 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于现代神经网络的语言无关的持续学习语音识别模型，以解决在缺乏原始训练数据的情况下，模型需要不断吸收新数据的问题。&lt;h4&gt;背景&lt;/h4&gt;现代神经网络在语音识别领域的应用需要不断吸收新数据，但下游应用通常无法访问原始训练数据，因此需要在不重新训练整个系统的情况下进行。&lt;h4&gt;目的&lt;/h4&gt;为了避免在持续训练过程中出现灾难性遗忘，提出了一种包含两个阶段（因子化和集中化）的持续学习方法。&lt;h4&gt;方法&lt;/h4&gt;该方法模仿人类大脑的觉醒-睡眠周期，通过多个低秩适配器累积知识，以防止灾难性遗忘。&lt;h4&gt;主要发现&lt;/h4&gt;在一系列代码切换数据集上的实验表明，集中化阶段可以有效防止灾难性遗忘。&lt;h4&gt;结论&lt;/h4&gt;提出的持续学习方法能够有效提高语音识别模型在多语言和语言无关条件下的持续学习能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代基于神经网络的语音识别模型需要不断吸收新数据，而无需重新训练整个系统，尤其是在没有访问原始训练数据的下游应用中。在无排练、多语言和语言无关的条件下持续训练模型，可能导致灾难性遗忘，即使是看似微小的权重扰动也可能对模型质量造成破坏性影响。受人类大脑通过觉醒-睡眠周期学习并巩固知识的能力的启发，我们提出了一种包含两个不同阶段（因子化和集中化）的持续学习方法，相应地学习和合并知识。我们在一系列代码切换数据集上的实验表明，集中化阶段可以通过累积多个散射低秩适配器中的知识来有效防止灾难性遗忘。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern neural network based speech recognition models are required tocontinually absorb new data without re-training the whole system, especially indownstream applications using foundation models, having no access to theoriginal training data. Continually training the models in a rehearsal-free,multilingual, and language agnostic condition, likely leads to catastrophicforgetting, when a seemingly insignificant disruption to the weights candestructively harm the quality of the models. Inspired by the ability of humanbrains to learn and consolidate knowledge through the waking-sleeping cycle, wepropose a continual learning approach with two distinct phases: factorizationand centralization, learning and merging knowledge accordingly. Our experimentson a sequence of varied code-switching datasets showed that the centralizationstage can effectively prevent catastrophic forgetting by accumulating theknowledge in multiple scattering low-rank adapters.</description>
      <author>example@mail.com (Enes Yavuz Ugan, Ngoc-Quan Pham, Alexander Waibel)</author>
      <guid isPermaLink="false">2506.16574v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Modal Geometric Hierarchy Fusion: An Implicit-Submap Driven Framework for Resilient 3D Place Recognition</title>
      <link>http://arxiv.org/abs/2506.14243v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于LiDAR的地点识别新框架，用于解决长期自主导航中的地点识别问题。&lt;h4&gt;背景&lt;/h4&gt;现有的地点识别方法依赖于手工特征提取，存在点云密度不一致和几何抽象表示脆弱的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，通过密度无关的几何推理重新定义3D地点识别。&lt;h4&gt;方法&lt;/h4&gt;引入基于弹性点的隐式3D表示，避免原始场景点云密度干扰，并从该表示中推导场景的占用网格和法线向量信息。最终，结合这两种信息，获得融合了鸟瞰图（捕捉宏观空间布局）和3D分段（编码微观表面几何）视角的描述符。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个数据集上实现了最先进的性能，并在准确性、运行时间和内存优化方面取得了最佳平衡。&lt;h4&gt;结论&lt;/h4&gt;该方法具有优异的鲁棒性和可扩展性，未来将开源代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/HBLT-hub/CMGHF&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR-based place recognition serves as a crucial enabler for long-termautonomy in robotics and autonomous driving systems. Yet, prevailingmethodologies relying on handcrafted feature extraction face dual challenges:(1) Inconsistent point cloud density, induced by ego-motion dynamics andenvironmental disturbances during repeated traversals, leads to descriptorinstability, and (2) Representation fragility stems from reliance onsingle-level geometric abstractions that lack discriminative power instructurally complex scenarios. To address these limitations, we propose anovel framework that redefines 3D place recognition through density-agnosticgeometric reasoning. Specifically, we introduce an implicit 3D representationbased on elastic points, which is immune to the interference of original scenepoint cloud density and achieves the characteristic of uniform distribution.Subsequently, we derive the occupancy grid and normal vector information of thescene from this implicit representation. Finally, with the aid of these twotypes of information, we obtain descriptors that fuse geometric informationfrom both bird's-eye view (capturing macro-level spatial layouts) and 3Dsegment (encoding micro-scale surface geometries) perspectives. We conductedextensive experiments on numerous datasets (KITTI, KITTI-360, MulRan, NCLT)across diverse environments. The experimental results demonstrate that ourmethod achieves state-of-the-art performance. Moreover, our approach strikes anoptimal balance between accuracy, runtime, and memory optimization forhistorical maps, showcasing excellent Resilient and scalability. Our code willbe open-sourced in the future.</description>
      <author>example@mail.com (Xiaohui Jiang, Haijiang Zhu, Chade Li, Fulin Tang, Ning An)</author>
      <guid isPermaLink="false">2506.14243v2</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Dense 3D Displacement Estimation for Landslide Monitoring via Fusion of TLS Point Clouds and Embedded RGB Images</title>
      <link>http://arxiv.org/abs/2506.16265v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 16 figures. Preprint under peer review. Example data and  code available at [GitHub](https://github.com/zhaoyiww/fusion4landslide)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于层次分割的粗到精方法，融合3D点云和配准的RGB图像来估计密集的3D位移矢量场，用于滑坡监测。&lt;h4&gt;背景&lt;/h4&gt;现有的基于点云的滑坡监测方法通常依赖于几何或辐射信息，往往产生稀疏或非3D位移估计。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够估计密集3D位移矢量场的新方法，以更好地监测滑坡。&lt;h4&gt;方法&lt;/h4&gt;使用3D几何和2D图像特征构建补丁级别的匹配，通过几何一致性检查和每个匹配的刚体变换估计来细化这些匹配。&lt;h4&gt;主要发现&lt;/h4&gt;在两个真实世界滑坡数据集上的实验结果表明，该方法产生了具有高空间覆盖率和高精度的3D位移估计。位移幅度的偏差小于平均扫描分辨率。&lt;h4&gt;结论&lt;/h4&gt;该方法在空间覆盖率上优于现有的F2S3方法，同时保持了可比的精度，为基于TLS的滑坡监测提供了一种实用且可扩展的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：滑坡监测对于理解地质灾害和减轻相关风险至关重要。然而，现有的基于点云的方法通常依赖于几何或辐射信息，往往产生稀疏或非3D位移估计。在本文中，我们提出了一种基于层次分割的粗到精方法，融合3D点云和配准的RGB图像以估计密集的3D位移矢量场。我们使用3D几何和2D图像特征构建补丁级别的匹配。这些匹配通过几何一致性检查进行细化，然后对每个匹配进行刚体变换估计。在两个真实世界滑坡数据集上的实验结果表明，我们的方法产生了具有高空间覆盖率（79%和97%）和高精度的3D位移估计。与地面测量（全站仪或GNSS观测）相比，两个数据集中的位移幅度的偏差分别为0.15米和0.25米，与手工提取的参考值相比，仅为0.07米和0.20米。这些值低于平均扫描分辨率（0.08米和0.30米）。我们的方法在空间覆盖率上优于最先进的F2S3方法，同时保持了可比的精度。我们的方法为基于TLS的滑坡监测提供了一种实用且可扩展的解决方案，并可扩展到其他类型的点云和监测任务。我们的示例数据和源代码可在https://github.com/zhaoyiww/fusion4landslide公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Landslide monitoring is essential for understanding geohazards and mitigatingassociated risks. However, existing point cloud-based methods typically rely oneither geometric or radiometric information and often yield sparse or non-3Ddisplacement estimates. In this paper, we propose a hierarchicalpartition-based coarse-to-fine approach that fuses 3D point clouds andco-registered RGB images to estimate dense 3D displacement vector fields. Weconstruct patch-level matches using both 3D geometry and 2D image features.These matches are refined via geometric consistency checks, followed by rigidtransformation estimation per match. Experimental results on two real-worldlandslide datasets demonstrate that our method produces 3D displacementestimates with high spatial coverage (79% and 97%) and high accuracy.Deviations in displacement magnitude with respect to external measurements(total station or GNSS observations) are 0.15 m and 0.25 m on the two datasets,respectively, and only 0.07 m and 0.20 m compared to manually derivedreferences. These values are below the average scan resolutions (0.08 m and0.30 m). Our method outperforms the state-of-the-art method F2S3 in spatialcoverage while maintaining comparable accuracy. Our approach offers a practicaland adaptable solution for TLS-based landslide monitoring and is extensible toother types of point clouds and monitoring tasks. Our example data and sourcecode are publicly available at https://github.com/zhaoyiww/fusion4landslide.</description>
      <author>example@mail.com (Zhaoyi Wang, Jemil Avers Butt, Shengyu Huang, Tomislav Medic, Andreas Wieser)</author>
      <guid isPermaLink="false">2506.16265v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>A Brain-to-Population Graph Learning Framework for Diagnosing Brain Disorders</title>
      <link>http://arxiv.org/abs/2506.16096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 7 figures, 13 tables; this paper has been submitted for  possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为B2P-GL的脑部疾病诊断框架，通过结合语义相似性和基于人群的图模型，提高了诊断的准确性和可解释性。&lt;h4&gt;背景&lt;/h4&gt;现有的基于图的方法在诊断脑部疾病时高度依赖预定义的脑图谱，但忽略了图谱中嵌入的丰富信息和位置及表型变异的混杂效应。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出了一个两阶段的框架，旨在提高脑部疾病诊断的准确性和个性化。&lt;h4&gt;方法&lt;/h4&gt;第一阶段是脑表示学习，利用GPT-4的知识丰富图表示并通过自适应节点重新分配图注意力网络来优化脑图谱。第二阶段是人群疾病诊断，将表型数据纳入人群图构建和特征融合，以减轻混杂效应并提高诊断性能。&lt;h4&gt;主要发现&lt;/h4&gt;在ABIDEI、ADHD-200和Rest-meta-MDD数据集上的实验表明，B2P-GL在预测准确性方面优于现有方法，同时增强了可解释性。&lt;h4&gt;结论&lt;/h4&gt;该框架提供了一种可靠且个性化的脑部疾病诊断方法，推动了临床应用。&lt;h4&gt;翻译&lt;/h4&gt;A recently developed graph-based method for diagnosing brain disorders uses functional connectivity, which heavily relies on predefined brain atlases but overlooks the rich information within the atlases and the confounding effects of site and phenotype variability. To address these challenges, we propose a two-stage Brain-to-Population Graph Learning (B2P-GL) framework that integrates the semantic similarity of brain regions and condition-based population graph modeling. In the first stage, termed brain representation learning, we leverage brain atlas knowledge from GPT-4 to enrich the graph representation and refine the brain graph through an adaptive node reassignment graph attention network. In the second stage, termed population disorder diagnosis, phenotypic data is incorporated into population graph construction and feature fusion to mitigate confounding effects and enhance diagnosis performance. Experiments on the ABIDEI, ADHD-200, and Rest-meta-MDD datasets show that B2P-GL outperforms state-of-the-art methods in prediction accuracy while enhancing interpretability. Overall, our proposed framework offers a reliable and personalized approach to brain disorder diagnosis, advancing clinical applicability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent developed graph-based methods for diagnosing brain disorders usingfunctional connectivity highly rely on predefined brain atlases, but overlookthe rich information embedded within atlases and the confounding effects ofsite and phenotype variability. To address these challenges, we propose atwo-stage Brain-to-Population Graph Learning (B2P-GL) framework that integratesthe semantic similarity of brain regions and condition-based population graphmodeling. In the first stage, termed brain representation learning, we leveragebrain atlas knowledge from GPT-4 to enrich the graph representation and refinethe brain graph through an adaptive node reassignment graph attention network.In the second stage, termed population disorder diagnosis, phenotypic data isincorporated into population graph construction and feature fusion to mitigateconfounding effects and enhance diagnosis performance. Experiments on the ABIDEI, ADHD-200, and Rest-meta-MDD datasets show that B2P-GL outperformsstate-of-the-art methods in prediction accuracy while enhancinginterpretability. Overall, our proposed framework offers a reliable andpersonalized approach to brain disorder diagnosis, advancing clinicalapplicability.</description>
      <author>example@mail.com (Qianqian Liao, Wuque Cai, Hongze Sun, Dongze Liu, Duo Chen, Dezhong Yao, Daqing Guo)</author>
      <guid isPermaLink="false">2506.16096v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling defect motifs in amorphous GeSe using machine learning interatomic potentials</title>
      <link>http://arxiv.org/abs/2506.15934v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 11 figures, Supplementary information included as ancillary  file (+12 pages)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文利用机器学习加速的分子动力学模拟，研究了非晶GeSe中的缺陷，旨在揭示非晶GeSe中缺陷驱动的Ovonic阈值切换(OTS)现象。&lt;h4&gt;背景&lt;/h4&gt;Ovonic阈值切换选择器在非易失性存储设备中因非线性电行为和极化依赖的阈值电压而至关重要，但其原子尺度缺陷状态的起源尚不完全清楚。&lt;h4&gt;目的&lt;/h4&gt;通过分子动力学模拟，利用机器学习加速的原子间势能，研究非晶GeSe中的缺陷，以理解其非线性电行为和阈值电压的原子尺度起源。&lt;h4&gt;方法&lt;/h4&gt;对多种潜在架构进行基准测试，包括基于描述符的模型和图神经网络(GNN)模型，并使用具有多个交互层的GNN架构来捕捉高阶相互作用和中等范围的结构顺序。&lt;h4&gt;主要发现&lt;/h4&gt;发现多个交互层的GNN架构可以成功捕捉这些相关性和结构模式，避免了表达能力较差的模型引入的虚假缺陷；识别出两种不同的缺陷模式：对齐的Ge链和过配位的Ge链；将电子缺陷水平与特定的结构特征相关联，如对齐链中键角的平均对齐和过配位Ge原子周围的局部Peierls畸变程度。&lt;h4&gt;结论&lt;/h4&gt;这些发现为解释实验观察提供了一个理论框架，并加深了对非晶GeSe中缺陷驱动的OTS现象的理解。&lt;h4&gt;翻译&lt;/h4&gt;Ovonic阈值切换（OTS）选择器由于它们的非线性电行为和极化依赖的阈值电压，在非易失性存储设备中发挥着关键作用。然而，导致这些特性的缺陷状态的原子尺度起源尚不完全清楚。在这项研究中，我们使用机器学习加速的原子间势能加速的分子动力学模拟来研究非晶GeSe中的缺陷。我们首先对几种潜在架构进行了基准测试，包括基于描述符的模型和图神经网络（GNN）模型，并表明忠实表示非晶GeSe需要捕获高阶相互作用（至少四体相关）和中程结构顺序。我们发现，具有多个交互层的GNN架构可以成功地捕获这些相关性和结构模式，防止了表达能力较差的模型引入的虚假缺陷。通过我们的优化GNN势能，我们检查了20个独立的960原子非晶GeSe结构，并确定了两种不同的缺陷模式：对齐的Ge链，这导致近导带的缺陷状态，以及过配位的Ge链，这产生近价带的缺陷状态。我们进一步将这些电子缺陷水平与特定的结构特征相关联，即对齐链中键角的平均对齐和过配位Ge原子周围的局部Peierls畸变程度。这些发现为解释实验观察提供了一个理论框架，并加深了对非晶GeSe中缺陷驱动的OTS现象的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ovonic threshold switching (OTS) selectors play a critical role innon-volatile memory devices because of their nonlinear electrical behavior andpolarity-dependent threshold voltages. However, the atomic-scale origins of thedefect states responsible for these properties are not yet fully understood. Inthis study, we use molecular dynamics simulations accelerated bymachine-learning interatomic potentials to investigate defects in amorphousGeSe. We begin by benchmarking several potential architectures-includingdescriptor-based models and graph neural network (GNN) models-and show thatfaithfully representing amorphous GeSe requires capturing higher-orderinteractions (at least four-body correlations) and medium-range structuralorder. We find that GNN architectures with multiple interaction layerssuccessfully capture these correlations and structural motifs, preventing thespurious defects that less expressive models introduce. With our optimized GNNpotential, we examine twenty independent 960-atom amorphous GeSe structures andidentify two distinct defect motifs: aligned Ge chains, which give rise todefect states near the conduction band, and overcoordinated Ge chains, whichproduce defect states near the valence band. We further correlate theseelectronic defect levels with specific structural features-namely, the averagealignment of bond angles in the aligned chains and the degree of local Peierlsdistortion around overcoordinated Ge atoms. These findings provide atheoretical framework for interpreting experimental observations and deepen ourunderstanding of defect-driven OTS phenomena in amorphous GeSe.</description>
      <author>example@mail.com (Minseok Moon, Seungwoo Hwang, Jaesun Kim, Yutack Park, Changho Hong, Seungwu Han)</author>
      <guid isPermaLink="false">2506.15934v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>CRIA: A Cross-View Interaction and Instance-Adapted Pre-training Framework for Generalizable EEG Representations</title>
      <link>http://arxiv.org/abs/2506.16056v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CRIA的适应性框架，用于从EEG数据中提取深度特征并有效整合多视角信息，以构建通用的EEG表征学习预训练框架。&lt;h4&gt;背景&lt;/h4&gt;从EEG数据中提取深度特征和有效整合多视角信息对于开发通用的EEG表征学习预训练框架是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出CRIA框架，旨在解决现有预训练方法仅依赖于单一视角的上下文语义，未能捕捉不同视角之间复杂和协同交互的问题。&lt;h4&gt;方法&lt;/h4&gt;CRIA利用可变长度和可变通道编码实现不同数据集上EEG数据的统一表征。定义跨视角信息为来自EEG信号时间、频谱和空间视角交互产生的综合表征。模型采用跨注意力机制有效地融合时间、频谱和空间特征，并结合基于信息瓶颈原理的注意力矩阵掩码策略和一种新颖的观点掩码预训练方案。&lt;h4&gt;主要发现&lt;/h4&gt;在Temple University EEG语料库和CHB-MIT数据集上的实验结果表明，CRIA在相同的预训练条件下优于现有方法，多类事件分类的平衡准确率达到57.02%，异常检测的准确率达到80.03%，显示出其强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;CRIA框架在EEG表征学习中展现出优越的性能，特别是在多类事件分类和异常检测任务上，证明了其在实际应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;The difficulty of extracting deep features from EEG data and effectively integrating information from multiple views presents significant challenges for developing a generalizable pretraining framework for EEG representation learning. However, most existing pre-training methods rely solely on the contextual semantics of a single view, failing to capture the complex and synergistic interactions among different perspectives, limiting the expressiveness and generalization of learned representations. To address these issues, this paper proposes CRIA, an adaptive framework that utilizes variable-length and variable-channel coding to achieve a unified representation of EEG data across different datasets. In this work, we define cross-view information as the integrated representation that emerges from the interaction among temporal, spectral, and spatial views of EEG signals. The model employs a cross-attention mechanism to fuse temporal, spectral, and spatial features effectively, and combines an attention matrix masking strategy based on the information bottleneck principle with a novel viewpoint masking pre-training scheme. Experimental results on the Temple University EEG corpus and the CHB-MIT dataset show that CRIA outperforms existing methods with the same pre-training conditions, achieving a balanced accuracy of 57.02% for multi-class event classification and 80.03% for anomaly detection, highlighting its strong generalization ability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The difficulty of extracting deep features from EEG data and effectivelyintegrating information from multiple views presents significant challenges fordeveloping a generalizable pretraining framework for EEG representationlearning. However, most existing pre-training methods rely solely on thecontextual semantics of a single view, failing to capture the complex andsynergistic interactions among different perspectives, limiting theexpressiveness and generalization of learned representations. To address theseissues, this paper proposes CRIA, an adaptive framework that utilizesvariable-length and variable-channel coding to achieve a unified representationof EEG data across different datasets. In this work, we define cross-viewinformation as the integrated representation that emerges from the interactionamong temporal, spectral, and spatial views of EEG signals. The model employs across-attention mechanism to fuse temporal, spectral, and spatial featureseffectively, and combines an attention matrix masking strategy based on theinformation bottleneck principle with a novel viewpoint masking pre-trainingscheme. Experimental results on the Temple University EEG corpus and theCHB-MIT dataset show that CRIA outperforms existing methods with the samepre-training conditions, achieving a balanced accuracy of 57.02% formulti-class event classification and 80.03% for anomaly detection, highlightingits strong generalization ability.</description>
      <author>example@mail.com (Puchun Liu, C. L. Philip Chen, Yubin He, Tong Zhang)</author>
      <guid isPermaLink="false">2506.16056v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details</title>
      <link>http://arxiv.org/abs/2506.16504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Hunyuan3D 2.5，这是一个用于生成高保真和详细纹理3D资产的稳健的3D扩散模型套件。&lt;h4&gt;背景&lt;/h4&gt;Hunyuan3D 2.5基于其前版本Hunyuan3D 2.0的两阶段流程，同时在形状和纹理生成方面有显著进步。&lt;h4&gt;目的&lt;/h4&gt;旨在生成高保真和详细的纹理3D资产。&lt;h4&gt;方法&lt;/h4&gt;在形状生成方面，引入了新的形状基础模型LATTICE，该模型使用缩放的高质量数据集进行训练，模型规模和计算能力得到提升。在纹理生成方面，通过扩展自Hunyuan3D 2.0 Paint模型的全新多视图架构，引入了基于物理的渲染（PBR）。&lt;h4&gt;主要发现&lt;/h4&gt;Hunyuan3D 2.5在形状和端到端纹理生成方面显著优于之前的方法，其最大的模型达到10B参数，能够生成清晰和详细的3D形状，同时保持网格表面的清洁和光滑。&lt;h4&gt;结论&lt;/h4&gt;Hunyuan3D 2.5在形状和纹理生成方面取得了显著进步，显著缩小了生成形状与手工制作3D形状之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusionmodels aimed at generating high-fidelity and detailed textured 3D assets.Hunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D2.0, while demonstrating substantial advancements in both shape and texturegeneration. In terms of shape generation, we introduce a new shape foundationmodel -- LATTICE, which is trained with scaled high-quality datasets,model-size, and compute. Our largest model reaches 10B parameters and generatessharp and detailed 3D shape with precise image-3D following while keeping meshsurface clean and smooth, significantly closing the gap between generated andhandcrafted 3D shapes. In terms of texture generation, it is upgraded withphyiscal-based rendering (PBR) via a novel multi-view architecture extendedfrom Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D2.5 significantly outperforms previous methods in both shape and end-to-endtexture generation.</description>
      <author>example@mail.com (Zeqiang Lai, Yunfei Zhao, Haolin Liu, Zibo Zhao, Qingxiang Lin, Huiwen Shi, Xianghui Yang, Mingxin Yang, Shuhui Yang, Yifei Feng, Sheng Zhang, Xin Huang, Di Luo, Fan Yang, Fang Yang, Lifu Wang, Sicong Liu, Yixuan Tang, Yulin Cai, Zebin He, Tian Liu, Yuhong Liu, Jie Jiang, Linus, Jingwei Huang, Chunchao Guo)</author>
      <guid isPermaLink="false">2506.16504v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>KG-FGNN: Knowledge-guided GNN Foundation Model for Fertilisation-oriented Soil GHG Flux Prediction</title>
      <link>http://arxiv.org/abs/2506.15896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于知识引导的图神经网络框架，用于精确预测土壤温室气体通量，以解决农业数据稀缺和机器学习方法应用受限的问题。&lt;h4&gt;背景&lt;/h4&gt;由于大多数农场缺乏先进的传感器和网络技术，获取全面和多样化的农业数据存在挑战，这严重阻碍了机器学习在精确土壤温室气体通量预测中的应用。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效预测土壤温室气体通量的方法，以支持农业系统的环境影响评估、排放减缓策略制定和可持续农业发展。&lt;h4&gt;方法&lt;/h4&gt;研究提出了一个结合了基于农业过程模型的农业数据集和图神经网络技术的知识引导图神经网络框架。该方法利用农业过程模型模拟和生成涵盖多种农业变量的多维度数据集，并采用自动编码器和基于多目标的图神经网络来提取关键特征和整合特征之间的相关性。&lt;h4&gt;主要发现&lt;/h4&gt;通过在农业模拟数据集和真实世界农业数据集上进行全面实验，与已知的基线和最先进的回归方法相比，提出的方法在施肥导向的土壤温室气体预测中提供了更高的准确性和稳定性。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的框架在施肥导向的土壤温室气体预测中显示出优越的准确性和稳定性，为农业系统中的环境评估和可持续农业实践提供了有力支持。&lt;h4&gt;翻译&lt;/h4&gt;Precision soil greenhouse gas (GHG) flux prediction is essential in agricultural systems for assessing environmental impacts, developing emission mitigation strategies and promoting sustainable agriculture. Due to the lack of advanced sensor and network technologies on majority of farms, there are challenges in obtaining comprehensive and diverse agricultural data. As a result, the scarcity of agricultural data seriously obstructs the application of machine learning approaches in precision soil GHG flux prediction. This research proposes a knowledge-guided graph neural network framework that addresses the above challenges by integrating knowledge embedded in an agricultural process-based model and graph neural network techniques. Specifically, we utilise the agricultural process-based model to simulate and generate multi-dimensional agricultural datasets for 47 countries that cover a wide range of agricultural variables. To extract key agricultural features and integrate correlations among agricultural features in the prediction process, we propose a machine learning framework that integrates the autoencoder and multi-target multi-graph based graph neural networks, which utilises the autoencoder to selectively extract significant agricultural features from the agricultural process-based model simulation data and the graph neural network to integrate correlations among agricultural features for accurately predict fertilisation-oriented soil GHG fluxes. Comprehensive experiments were conducted with both the agricultural simulation dataset and real-world agricultural dataset to evaluate the proposed approach in comparison with well-known baseline and state-of-the-art regression methods. The results demonstrate that our proposed approach provides superior accuracy and stability in fertilisation-oriented soil GHG prediction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Precision soil greenhouse gas (GHG) flux prediction is essential inagricultural systems for assessing environmental impacts, developing emissionmitigation strategies and promoting sustainable agriculture. Due to the lack ofadvanced sensor and network technologies on majority of farms, there arechallenges in obtaining comprehensive and diverse agricultural data. As aresult, the scarcity of agricultural data seriously obstructs the applicationof machine learning approaches in precision soil GHG flux prediction. Thisresearch proposes a knowledge-guided graph neural network framework thataddresses the above challenges by integrating knowledge embedded in anagricultural process-based model and graph neural network techniques.Specifically, we utilise the agricultural process-based model to simulate andgenerate multi-dimensional agricultural datasets for 47 countries that cover awide range of agricultural variables. To extract key agricultural features andintegrate correlations among agricultural features in the prediction process,we propose a machine learning framework that integrates the autoencoder andmulti-target multi-graph based graph neural networks, which utilises theautoencoder to selectively extract significant agricultural features from theagricultural process-based model simulation data and the graph neural networkto integrate correlations among agricultural features for accurately predictfertilisation-oriented soil GHG fluxes. Comprehensive experiments wereconducted with both the agricultural simulation dataset and real-worldagricultural dataset to evaluate the proposed approach in comparison withwell-known baseline and state-of-the-art regression methods. The resultsdemonstrate that our proposed approach provides superior accuracy and stabilityin fertilisation-oriented soil GHG prediction.</description>
      <author>example@mail.com (Yu Zhang, Gaoshan Bi, Simon Jeffery, Max Davis, Yang Li, Qing Xue, Po Yang)</author>
      <guid isPermaLink="false">2506.15896v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>ViTacFormer: Learning Cross-Modal Representation for Visuo-Tactile Dexterous Manipulation</title>
      <link>http://arxiv.org/abs/2506.15953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ViTacFormer是一种结合视觉和触觉信息，用于精确控制机器手进行灵巧操作的新方法。&lt;h4&gt;背景&lt;/h4&gt;灵巧操作是机器人与物理世界交互的基础能力，触觉传感在无结构和视觉遮挡环境下对精确控制至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过结合视觉和触觉信息，实现机器手的高精度灵巧操作。&lt;h4&gt;方法&lt;/h4&gt;开发了一个名为ViTacFormer的模型，该模型包含跨注意力编码器和自回归触觉预测头，用于融合高分辨率视觉和触觉信息。&lt;h4&gt;主要发现&lt;/h4&gt;通过学习跨模态表示，ViTacFormer能够提高机器手的操作准确性和鲁棒性，并在多个基准测试中取得比现有系统高50%的成功率。&lt;h4&gt;结论&lt;/h4&gt;ViTacFormer能够自主完成需要高精度控制的长期灵巧操作任务，执行多达11个连续阶段，连续运行2.5分钟，是目前该领域首次实现此类功能的系统。&lt;h4&gt;翻译&lt;/h4&gt;Dexterous manipulation is a cornerstone capability for robotic systems aiming to interact with the physical world in a human-like manner. Although vision-based methods have advanced rapidly, tactile sensing remains crucial for fine-grained control, particularly in unstructured or visually occluded settings. We present ViTacFormer, a representation-learning approach that couples a cross-attention encoder to fuse high-resolution vision and touch with an autoregressive tactile prediction head that anticipates future contact signals. Building on this architecture, we devise an easy-to-challenging curriculum that steadily refines the visual-tactile latent space, boosting both accuracy and robustness. The learned cross-modal representation drives imitation learning for multi-fingered hands, enabling precise and adaptive manipulation. Across a suite of challenging real-world benchmarks, our method achieves approximately 50% higher success rates than prior state-of-the-art systems. To our knowledge, it is also the first to autonomously complete long-horizon dexterous manipulation tasks that demand highly precise control with an anthropomorphic hand, successfully executing up to 11 sequential stages and sustaining continuous operation for 2.5 minutes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dexterous manipulation is a cornerstone capability for robotic systems aimingto interact with the physical world in a human-like manner. Althoughvision-based methods have advanced rapidly, tactile sensing remains crucial forfine-grained control, particularly in unstructured or visually occludedsettings. We present ViTacFormer, a representation-learning approach thatcouples a cross-attention encoder to fuse high-resolution vision and touch withan autoregressive tactile prediction head that anticipates future contactsignals. Building on this architecture, we devise an easy-to-challengingcurriculum that steadily refines the visual-tactile latent space, boosting bothaccuracy and robustness. The learned cross-modal representation drivesimitation learning for multi-fingered hands, enabling precise and adaptivemanipulation. Across a suite of challenging real-world benchmarks, our methodachieves approximately 50% higher success rates than prior state-of-the-artsystems. To our knowledge, it is also the first to autonomously completelong-horizon dexterous manipulation tasks that demand highly precise controlwith an anthropomorphic hand, successfully executing up to 11 sequential stagesand sustaining continuous operation for 2.5 minutes.</description>
      <author>example@mail.com (Liang Heng, Haoran Geng, Kaifeng Zhang, Pieter Abbeel, Jitendra Malik)</author>
      <guid isPermaLink="false">2506.15953v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>HyperPath: Knowledge-Guided Hyperbolic Semantic Hierarchy Modeling for WSI Analysis</title>
      <link>http://arxiv.org/abs/2506.16398v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HyperPath的新方法，用于癌症诊断中的全切片图像（WSI）分析。该方法通过结合文本描述知识，在双曲空间中建模WSI的语义层次结构，从而提高WSI分类性能。&lt;h4&gt;背景&lt;/h4&gt;病理学对于癌症诊断至关重要，而多实例学习（MIL）常用于WSI分析。WSI具有自然层次结构，包括补丁、区域和切片，具有不同的语义关联。现有方法主要依赖欧几里得嵌入，难以完全捕捉语义层次结构。&lt;h4&gt;目的&lt;/h4&gt;为了解决欧几里得嵌入的局限性，提出HyperPath方法，以增强WSI分类。&lt;h4&gt;方法&lt;/h4&gt;HyperPath方法结合了病理视觉-语言基础模型提取的视觉和文本特征，并将其应用于双曲空间。设计了角度模态对齐损失来确保跨模态对齐的鲁棒性，并设计了语义层次一致性损失，通过蕴涵和矛盾关系进一步细化特征层次，从而增强语义一致性。分类通过测地距离进行，该距离衡量了双曲语义层次中实体之间的相似性。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，HyperPath在多个任务上实现了优越的性能，突出了双曲嵌入在WSI分析中的潜力。&lt;h4&gt;结论&lt;/h4&gt;HyperPath方法通过双曲嵌入和语义层次结构建模，显著提高了WSI分类的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：病理学对于癌症诊断至关重要，多实例学习（MIL）广泛应用于全切片图像（WSI）分析。WSI表现出自然的层次结构——包括补丁、区域和切片——具有不同的语义关联。尽管一些方法试图利用这种层次结构来提高表示，但它们主要依赖于欧几里得嵌入，这难以完全捕捉语义层次结构。为了解决这一局限性，我们提出了HyperPath，一种新颖的方法，它通过将知识从文本描述中集成来引导在双曲空间中对WSI语义层次结构的建模，从而提高WSI分类。我们的方法将病理视觉-语言基础模型提取的视觉和文本特征适应到双曲空间。我们设计了一个角度模态对齐损失，以确保鲁棒的跨模态对齐，同时语义层次一致性损失通过蕴涵和矛盾关系进一步细化特征层次，从而增强语义一致性。分类通过测地距离进行，该距离衡量了双曲语义层次中实体之间的相似性。这消除了对线性分类器的需求，并允许一种对WSI分析具有几何感知的方法。广泛的实验表明，与现有方法相比，我们的方法在多个任务上实现了优越的性能，突出了双曲嵌入在WSI分析中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pathology is essential for cancer diagnosis, with multiple instance learning(MIL) widely used for whole slide image (WSI) analysis. WSIs exhibit a naturalhierarchy -- patches, regions, and slides -- with distinct semanticassociations. While some methods attempt to leverage this hierarchy forimproved representation, they predominantly rely on Euclidean embeddings, whichstruggle to fully capture semantic hierarchies. To address this limitation, wepropose HyperPath, a novel method that integrates knowledge from textualdescriptions to guide the modeling of semantic hierarchies of WSIs inhyperbolic space, thereby enhancing WSI classification. Our approach adaptsboth visual and textual features extracted by pathology vision-languagefoundation models to the hyperbolic space. We design an Angular ModalityAlignment Loss to ensure robust cross-modal alignment, while a SemanticHierarchy Consistency Loss further refines feature hierarchies throughentailment and contradiction relationships and thus enhance semantic coherence.The classification is performed with geodesic distance, which measures thesimilarity between entities in the hyperbolic semantic hierarchy. Thiseliminates the need for linear classifiers and enables a geometry-awareapproach to WSI analysis. Extensive experiments show that our method achievessuperior performance across tasks compared to existing methods, highlightingthe potential of hyperbolic embeddings for WSI analysis.</description>
      <author>example@mail.com (Peixiang Huang, Yanyan Huang, Weiqin Zhao, Junjun He, Lequan Yu)</author>
      <guid isPermaLink="false">2506.16398v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Quantum-Informed Contrastive Learning with Dynamic Mixup Augmentation for Class-Imbalanced Expert Systems</title>
      <link>http://arxiv.org/abs/2506.13987v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为QCL-MixNet的新颖量子信息对比学习框架，用于解决不平衡数据集的分类问题，在专家系统中检测稀有但关键实例，以提升安全性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;在类不平衡的表格数据领域，传统的成本敏感学习、过采样和图神经网络等方法存在过拟合、标签噪声和泛化能力差等问题。&lt;h4&gt;目的&lt;/h4&gt;提出QCL-MixNet以解决上述问题，实现鲁棒的不平衡分类。&lt;h4&gt;方法&lt;/h4&gt;QCL-MixNet集成了三个核心创新：(i) 受量子纠缠启发的层，通过正弦变换和门控注意力建模复杂特征交互；(ii) 样本感知的mixup策略，自适应地插值语义相似实例的特征表示，增强少数类的表示；(iii) 混合损失函数，结合焦点重新加权、监督对比学习、三元组损失和方差正则化，以提高类内紧凑性和类间可分性。&lt;h4&gt;主要发现&lt;/h4&gt;在18个现实世界的不平衡数据集（二分类和多分类）上进行的实验表明，QCL-MixNet在宏观F1和召回率上始终优于20个最先进的机器学习、深度学习和GNN基线。&lt;h4&gt;结论&lt;/h4&gt;QCL-MixNet在表格不平衡处理方面为专家系统提供了一个新的基准，其表达性、泛化能力和优化鲁棒性得到了理论分析的证实。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Expert systems often operate in domains characterized by class-imbalanced tabular data, where detecting rare but critical instances is essential for safety and reliability. While conventional approaches, such as cost-sensitive learning, oversampling, and graph neural networks, provide partial solutions, they suffer from drawbacks like overfitting, label noise, and poor generalization in low-density regions. To address these challenges, we propose QCL-MixNet, a novel Quantum-Informed Contrastive Learning framework augmented with k-nearest neighbor (kNN) guided dynamic mixup for robust classification under imbalance. QCL-MixNet integrates three core innovations: (i) a Quantum Entanglement-inspired layer that models complex feature interactions through sinusoidal transformations and gated attention, (ii) a sample-aware mixup strategy that adaptively interpolates feature representations of semantically similar instances to enhance minority class representation, and (iii) a hybrid loss function that unifies focal reweighting, supervised contrastive learning, triplet margin loss, and variance regularization to improve both intra-class compactness and inter-class separability. Extensive experiments on 18 real-world imbalanced datasets (binary and multi-class) demonstrate that QCL-MixNet consistently outperforms 20 state-of-the-art machine learning, deep learning, and GNN-based baselines in macro-F1 and recall, often by substantial margins. Ablation studies further validate the critical role of each architectural component. Our results establish QCL-MixNet as a new benchmark for tabular imbalance handling in expert systems. Theoretical analyses reinforce its expressiveness, generalization, and optimization robustness.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Expert systems often operate in domains characterized by class-imbalancedtabular data, where detecting rare but critical instances is essential forsafety and reliability. While conventional approaches, such as cost-sensitivelearning, oversampling, and graph neural networks, provide partial solutions,they suffer from drawbacks like overfitting, label noise, and poorgeneralization in low-density regions. To address these challenges, we proposeQCL-MixNet, a novel Quantum-Informed Contrastive Learning framework augmentedwith k-nearest neighbor (kNN) guided dynamic mixup for robust classificationunder imbalance. QCL-MixNet integrates three core innovations: (i) a QuantumEntanglement-inspired layer that models complex feature interactions throughsinusoidal transformations and gated attention, (ii) a sample-aware mixupstrategy that adaptively interpolates feature representations of semanticallysimilar instances to enhance minority class representation, and (iii) a hybridloss function that unifies focal reweighting, supervised contrastive learning,triplet margin loss, and variance regularization to improve both intra-classcompactness and inter-class separability. Extensive experiments on 18real-world imbalanced datasets (binary and multi-class) demonstrate thatQCL-MixNet consistently outperforms 20 state-of-the-art machine learning, deeplearning, and GNN-based baselines in macro-F1 and recall, often by substantialmargins. Ablation studies further validate the critical role of eacharchitectural component. Our results establish QCL-MixNet as a new benchmarkfor tabular imbalance handling in expert systems. Theoretical analysesreinforce its expressiveness, generalization, and optimization robustness.</description>
      <author>example@mail.com (Md Abrar Jahin, Adiba Abid, M. F. Mridha)</author>
      <guid isPermaLink="false">2506.13987v2</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Next-Token Prediction Should be Ambiguity-Sensitive: A Meta-Learning Perspective</title>
      <link>http://arxiv.org/abs/2506.16288v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了自动回归基础模型快速适应能力的原因，并提出了应对高模糊性预测的新方法。&lt;h4&gt;背景&lt;/h4&gt;自动回归基础模型的快速适应能力通常归因于其预训练数据的多样性。然而，在高度模糊的情况下，贝叶斯最优预测的计算变得不可行。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，将预训练模型转换为蒙特卡洛预测器，以降低模糊性预测的计算需求。&lt;h4&gt;方法&lt;/h4&gt;引入了MetaHMM，一个具有丰富组合结构和可处理贝叶斯先验的合成序列元学习基准，以测试模型在高模糊性预测中的表现。&lt;h4&gt;主要发现&lt;/h4&gt;Transformer在处理高模糊性预测时存在困难。通过改进容量分配和测试时间可扩展推理，将预训练模型转换为蒙特卡洛预测器可以在模糊环境中取得显著收益。&lt;h4&gt;结论&lt;/h4&gt;模糊性不可知的前向预测可能是一个有害的归纳偏差，而将预训练模型转换为蒙特卡洛预测器可以提高处理模糊性预测的能力。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了自动回归基础模型快速适应能力的原因，并提出了应对高模糊性预测的新方法。背景是自动回归基础模型的快速适应能力通常归因于其预训练数据的多样性。然而，在高度模糊的情况下，贝叶斯最优预测的计算变得不可行。目的是提出一种方法，将预训练模型转换为蒙特卡洛预测器，以降低模糊性预测的计算需求。方法引入了MetaHMM，一个具有丰富组合结构和可处理贝叶斯先验的合成序列元学习基准，以测试模型在高模糊性预测中的表现。主要发现是Transformer在处理高模糊性预测时存在困难。通过改进容量分配和测试时间可扩展推理，将预训练模型转换为蒙特卡洛预测器可以在模糊环境中取得显著收益。结论是模糊性不可知的前向预测可能是一个有害的归纳偏差，而将预训练模型转换为蒙特卡洛预测器可以提高处理模糊性预测的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid adaptation ability of auto-regressive foundation models is oftenattributed to the diversity of their pre-training data. This is because, from aBayesian standpoint, minimizing prediction error in such settings requiresintegrating over all plausible latent hypotheses consistent with observations.While this behavior is desirable in principle, it often proves too ambitious inpractice: under high ambiguity, the number of plausible latent alternativesmakes Bayes-optimal prediction computationally intractable. Cognitive sciencehas long recognized this limitation, suggesting that under such conditions,heuristics or information-seeking strategies are preferable to exhaustiveinference. Translating this insight to next-token prediction, we hypothesizethat low- and high-ambiguity predictions pose different computational demands,making ambiguity-agnostic next-token prediction a detrimental inductive bias.To test this, we introduce MetaHMM, a synthetic sequence meta-learningbenchmark with rich compositional structure and a tractable Bayesian oracle. Weshow that Transformers indeed struggle with high-ambiguity predictions acrossmodel sizes. Motivated by cognitive theories, we propose a method to convertpre-trained models into Monte Carlo predictors that decouple task inferencefrom token prediction. Preliminary results show substantial gains in ambiguouscontexts through improved capacity allocation and test-time scalable inference,though challenges remain.</description>
      <author>example@mail.com (Leo Gagnon, Eric Elmoznino, Sarthak Mittal, Tom Marty, Tejas Kasetty, Dhanya Sridhar, Guillaume Lajoie)</author>
      <guid isPermaLink="false">2506.16288v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Optimal alignment of Lorentz orientation and generalization to matrix Lie groups</title>
      <link>http://arxiv.org/abs/2506.14994v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了两种解决方法，以实现点云在三维空间中的对齐，并探讨了将这种方法扩展到其他矩阵李群对齐问题。&lt;h4&gt;背景&lt;/h4&gt;现有的点云对齐方法依赖于欧几里得度量的正定性质，不易扩展到Minkowski度量的不定性质。&lt;h4&gt;目的&lt;/h4&gt;针对给定的惯性参考系A和B，以及在这些参考系中测量的4-向量集{v_i}（可能存在噪声），找到最优的洛伦兹变换Λ，使得Λv_{A,i}=v_{B,i}。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法概念简单，易于扩展到其他矩阵李群的对齐问题。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出的两种方法能够解决给定条件下点云对齐的问题，并展示了将这些方法扩展到其他矩阵李群的潜力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为点云对齐问题提供了新的解决方案，并为进一步的研究提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了优雅的三维点云对齐方法，但这些方法依赖于欧几里得度量的正定性，难以扩展到Minkowski度量的不定性。本文针对惯性参考系A和B以及在这些参考系中测量的4-向量集{v_i}（可能存在噪声），提出了两种解决方案：寻找最优的洛伦兹变换Λ，使得Λv_{A,i}=v_{B,i}。本文提出的方法概念简单，易于扩展到其他矩阵李群的对齐问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; There exist elegant methods of aligning point clouds in $\mathbb R^3$.Unfortunately, these methods rely on the positive definite property of theEuclidean metric, and do not easily extend to the indefinite Minkowski metric.In this paper, we propose two solutions to the following problem: giveninertial reference frames $A$ and $B$, and given (possibly noisy) measurementsof a set of 4-vectors $\{v_i\}$ made in those reference frames with components$\{v_{A,i}\}$ and $\{v_{B,i}\}$, find the optimal Lorentz transformation$\Lambda$ such that $\Lambda v_{A,i}=v_{B,i}$. The method we outline isconceptually simple and easily extends to alignment problems in other matrixLie groups.</description>
      <author>example@mail.com (Congzhou M Sha)</author>
      <guid isPermaLink="false">2506.14994v2</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in Cluttered Scenes</title>
      <link>http://arxiv.org/abs/2506.14317v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ClutterDexGrasp的框架，用于在杂乱场景中进行目标导向的灵巧抓取。&lt;h4&gt;背景&lt;/h4&gt;在杂乱场景中进行灵巧抓取面临多样物体几何形状、遮挡和潜在碰撞的挑战。现有方法主要关注单物体抓取或抓取姿态预测，缺乏交互，不足以应对复杂场景。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，本文重新审视了从模拟到现实的迁移流程，并开发关键技术，以实现现实中的零样本部署并保持鲁棒的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一个两阶段教师-学生框架ClutterDexGrasp，其中教师策略在模拟中使用杂乱密度课程学习进行训练，结合几何和空间嵌入的场景表示以及一个新颖的综合安全课程，实现通用、动态和安全的抓取行为。通过模仿学习，将教师的知识提炼成学生3D扩散策略（DP3），该策略在部分点云观察上运行。&lt;h4&gt;主要发现&lt;/h4&gt;这是第一个零样本从模拟到现实的杂乱场景中目标导向的灵巧抓取的闭环系统，证明了在不同物体和布局上的鲁棒性能。&lt;h4&gt;结论&lt;/h4&gt;ClutterDexGrasp框架能够有效地在杂乱场景中进行灵巧抓取，为解决复杂场景中的抓取问题提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a framework named ClutterDexGrasp for dexterous grasping with target orientation in cluttered scenes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dexterous grasping in cluttered scenes presents significant challenges due todiverse object geometries, occlusions, and potential collisions. Existingmethods primarily focus on single-object grasping or grasp-pose predictionwithout interaction, which are insufficient for complex, cluttered scenes.Recent vision-language-action models offer a potential solution but requireextensive real-world demonstrations, making them costly and difficult to scale.To address these limitations, we revisit the sim-to-real transfer pipeline anddevelop key techniques that enable zero-shot deployment in reality whilemaintaining robust generalization. We propose ClutterDexGrasp, a two-stageteacher-student framework for closed-loop target-oriented dexterous grasping incluttered scenes. The framework features a teacher policy trained in simulationusing clutter density curriculum learning, incorporating both a geometry andspatially-embedded scene representation and a novel comprehensive safetycurriculum, enabling general, dynamic, and safe grasping behaviors. Throughimitation learning, we distill the teacher's knowledge into a student 3Ddiffusion policy (DP3) that operates on partial point cloud observations. Tothe best of our knowledge, this represents the first zero-shot sim-to-realclosed-loop system for target-oriented dexterous grasping in cluttered scenes,demonstrating robust performance across diverse objects and layouts. Moredetails and videos are available at https://clutterdexgrasp.github.io/.</description>
      <author>example@mail.com (Zeyuan Chen, Qiyang Yan, Yuanpei Chen, Tianhao Wu, Jiyao Zhang, Zihan Ding, Jinzhou Li, Yaodong Yang, Hao Dong)</author>
      <guid isPermaLink="false">2506.14317v2</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>On using AI for EEG-based BCI applications: problems, current challenges and future trends</title>
      <link>http://arxiv.org/abs/2506.16168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了利用人工智能（AI）解码脑电波（EEG）信号在脑机接口（BCI）中的应用，特别是脑到语音、脑到图像和脑到物联网（BCIoT）的可能性。&lt;h4&gt;背景&lt;/h4&gt;近年来，AI在机器视觉和自然语言处理方面的突破，为解码脑电波信号提供了新的机遇。&lt;h4&gt;目的&lt;/h4&gt;论文旨在提供一个原则性的导航，探索这一快速发展的研究领域，并讨论克服当前技术、方法和伦理限制的途径。&lt;h4&gt;方法&lt;/h4&gt;论文对基于因果视角的基本范式进行了分析，并探讨了AI模型面临的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;将AI应用于基于EEG的BCI，特别是在构建强大基础模型方面，存在独特且复杂的难题，可能影响其可靠性。&lt;h4&gt;结论&lt;/h4&gt;论文提出了一个清晰的路线图，旨在创建真正实用和有效的EEG-based BCI解决方案，使其能够在日常环境中茁壮成长。&lt;h4&gt;翻译&lt;/h4&gt;想象一下解锁心灵的力量来沟通、创造，甚至与世界互动。最近在人工智能（AI）方面的突破，特别是在机器如何“看到”和“理解”语言方面，正在推动解码头皮脑电图（EEG）信号方面的激动人心的进展。表面上看，这为面向现实生活的革命性脑机接口（BCI）打开了大门，使其超越传统用途，设想脑到语音、脑到图像，甚至脑到物联网（BCIoT）。然而，这条路并不像计算机视觉（CV）和自然语言处理（NLP）那样简单。将AI应用于基于EEG的BCI，特别是在构建强大基础模型方面，提出了独特且复杂的难题，可能会影响其可靠性。在这里，我们展开了对这一动态和快速发展的研究领域的指导性探索。我们不仅概述了当前的努力和成果，而是旨在提供一种原则性的导航，探索这一热门且前沿的研究领域。我们从因果视角分析出现的基本范式，并讨论了AI模型面临的挑战。展望未来，我们讨论了有可能克服今天的技术、方法和伦理限制的研究途径。我们的目标是制定一个清晰的路线图，为创建真正实用和有效的基于EEG的BCI解决方案提供指导，使其能够在日常环境中茁壮成长。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Imagine unlocking the power of the mind to communicate, create, and eveninteract with the world around us. Recent breakthroughs in ArtificialIntelligence (AI), especially in how machines "see" and "understand" language,are now fueling exciting progress in decoding brain signals from scalpelectroencephalography (EEG). Prima facie, this opens the door to revolutionarybrain-computer interfaces (BCIs) designed for real life, moving beyondtraditional uses to envision Brain-to-Speech, Brain-to-Image, and even aBrain-to-Internet of Things (BCIoT).  However, the journey is not as straightforward as it was for Computer Vision(CV) and Natural Language Processing (NLP). Applying AI to real-world EEG-basedBCIs, particularly in building powerful foundational models, presents uniqueand intricate hurdles that could affect their reliability.  Here, we unfold a guided exploration of this dynamic and rapidly evolvingresearch area. Rather than barely outlining a map of current endeavors andresults, the goal is to provide a principled navigation of this hot andcutting-edge research landscape. We consider the basic paradigms that emergefrom a causal perspective and the attendant challenges presented to AI-basedmodels. Looking ahead, we then discuss promising research avenues that couldovercome today's technological, methodological, and ethical limitations. Ouraim is to lay out a clear roadmap for creating truly practical and effectiveEEG-based BCI solutions that can thrive in everyday environments.</description>
      <author>example@mail.com (Thomas Barbera, Jacopo Burger, Alessandro D'Amelio, Simone Zini, Simone Bianco, Raffaella Lanzarotti, Paolo Napoletano, Giuseppe Boccignone, Jose Luis Contreras-Vidal)</author>
      <guid isPermaLink="false">2506.16168v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Multi-Positive Contrastive Learning for Patent Image Retrieval</title>
      <link>http://arxiv.org/abs/2506.13496v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 3 figures, Accepted as a short paper at the 6th Workshop on  Patent Text Mining and Semantic Technologies (PatentSemTech 2025), co-located  with SIGIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Locarno国际分类（LIC）系统专利图像检索方法，通过引入分层多正对比损失，提高了检索效果。&lt;h4&gt;背景&lt;/h4&gt;专利图像检索系统在处理大量专利图像时面临挑战，因为它们包含复杂的技术细节和语义信息，且当前方法未充分利用专利的层次关系。&lt;h4&gt;目的&lt;/h4&gt;旨在提高专利图像检索的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种分层多正对比损失方法，利用LIC的分类体系在检索过程中诱导关系，为每个专利图像分配多个基于层次分类的相似度不同的正样本对。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在DeepPatent2数据集上提高了检索结果，且适用于低参数模型，减少计算资源需求，适用于硬件资源有限的部署环境。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提高了专利图像检索的准确性，并适用于资源受限的环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Patent images are technical drawings that convey information about a patent'sinnovation. Patent image retrieval systems aim to search in vast collectionsand retrieve the most relevant images. Despite recent advances in informationretrieval, patent images still pose significant challenges due to theirtechnical intricacies and complex semantic information, requiring efficientfine-tuning for domain adaptation. Current methods neglect patents'hierarchical relationships, such as those defined by the Locarno InternationalClassification (LIC) system, which groups broad categories (e.g., "furnishing")into subclasses (e.g., "seats" and "beds") and further into specific patentdesigns. In this work, we introduce a hierarchical multi-positive contrastiveloss that leverages the LIC's taxonomy to induce such relations in theretrieval process. Our approach assigns multiple positive pairs to each patentimage within a batch, with varying similarity scores based on the hierarchicaltaxonomy. Our experimental analysis with various vision and multimodal modelson the DeepPatent2 dataset shows that the proposed method enhances theretrieval results. Notably, our method is effective with low-parameter models,which require fewer computational resources and can be deployed on environmentswith limited hardware.</description>
      <author>example@mail.com (Kshitij Kavimandan, Angelos Nalmpantis, Emma Beauxis-Aussalet, Robert-Jan Sips)</author>
      <guid isPermaLink="false">2506.13496v3</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Regression Testing Optimization for ROS-based Autonomous Systems: A Comprehensive Review of Techniques</title>
      <link>http://arxiv.org/abs/2506.16101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对ROS基于的自主系统（ROSAS）的回归测试优化技术进行了系统性的综述。&lt;h4&gt;背景&lt;/h4&gt;回归测试在维护软件可靠性方面至关重要，特别是对于频繁进行持续集成和迭代开发的ROSAS。然而，传统的回归测试技术在应用于自主系统时面临挑战，如动态和非确定性行为、复杂的多模态传感器数据、异步分布式架构以及严格的实时性和安全性限制。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一差距，本文提出对ROSAS的回归测试优化技术进行首次全面调查。&lt;h4&gt;方法&lt;/h4&gt;分析了122项代表性研究，并将它们分为回归测试用例优先级、最小化和选择方法。引入了结构化的分类法，以明确说明它们在ROSAS环境中的应用性和局限性。&lt;h4&gt;主要发现&lt;/h4&gt;突出了ROSAS回归测试的主要挑战，包括有效响应频繁的系统修改来优先排序测试、高效最小化冗余测试以及困难地准确选择受影响的测试用例。&lt;h4&gt;结论&lt;/h4&gt;提出了研究见解，并确定了有希望的未来的研究方向，例如利用帧到向量覆盖度量、多源基础模型和神经符号推理来提高回归测试的效率和效果。本调查为推进ROSAS回归测试优化技术的最先进水平提供了基础参考和实际路线图。&lt;h4&gt;翻译&lt;/h4&gt;摘要：回归测试在保持软件可靠性方面发挥着关键作用，尤其是在ROS（机器人操作系统）为基础的自主系统（ROSAS）中，这些系统经常经历持续集成和迭代开发。然而，由于自主系统的动态和非确定性行为、复杂的多模态传感器数据、异步分布式架构以及严格的实时性和安全性约束，传统的回归测试技术在应用于自主系统时面临着重大挑战。尽管许多研究已经探索了在传统软件环境中的测试优化，但针对ROSAS的回归测试优化仍然大部分未被探索。为了解决这一差距，我们提出了对ROSAS的回归测试优化技术的首次全面调查。我们分析了122项代表性研究，并将它们分为回归测试用例优先级、最小化和选择方法。引入了结构化的分类法，以清楚地说明它们在ROSAS环境中的应用性和局限性。此外，我们突出了ROSAS回归测试的特定挑战，包括有效响应频繁的系统修改来优先排序测试、高效最小化冗余测试和困难地准确选择受影响的测试用例。最后，我们提出了研究见解并确定了有希望的未来的研究方向，如利用帧到向量覆盖度量、多源基础模型和神经符号推理来提高回归测试的效率和效果。这项调查为推进ROSAS回归测试优化技术的最先进水平提供了基础参考和实际路线图。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Regression testing plays a critical role in maintaining software reliability,particularly for ROS-based autonomous systems (ROSAS), which frequently undergocontinuous integration and iterative development. However, conventionalregression testing techniques face significant challenges when applied toautonomous systems due to their dynamic and non-deterministic behaviors,complex multi-modal sensor data, asynchronous distributed architectures, andstringent safety and real-time constraints. Although numerous studies haveexplored test optimization in traditional software contexts, regression testingoptimization specifically for ROSAS remains largely unexplored. To address thisgap, we present the first comprehensive survey systematically reviewingregression testing optimization techniques tailored for ROSAS. We analyze andcategorize 122 representative studies into regression test case prioritization,minimization, and selection methods. A structured taxonomy is introduced toclearly illustrate their applicability and limitations within ROSAS contexts.Furthermore, we highlight major challenges specific to regression testing forROSAS, including effectively prioritizing tests in response to frequent systemmodifications, efficiently minimizing redundant tests, and difficulty inaccurately selecting impacted test cases. Finally, we propose research insightsand identify promising future directions, such as leveraging frame-to-vectorcoverage metrics, multi-source foundation models, and neurosymbolic reasoningto enhance regression testing efficiency and effectiveness. This surveyprovides a foundational reference and practical roadmap for advancing thestate-of-the-art in regression testing optimization for ROSAS.</description>
      <author>example@mail.com (Yupeng Jiang, Shuaiyi Sun, Xi Zheng)</author>
      <guid isPermaLink="false">2506.16101v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>EndoMUST: Monocular Depth Estimation for Robotic Endoscopy via End-to-end Multi-step Self-supervised Training</title>
      <link>http://arxiv.org/abs/2506.16017v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IROS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于在稳定、准确和高效的机器人辅助内窥镜中实现单目深度估计和自我运动估计。&lt;h4&gt;背景&lt;/h4&gt;单目深度估计和自我运动估计对于场景感知和导航非常重要，但在内窥镜场景中，由于光照变化和纹理稀疏，这些任务变得更具挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，以解决内窥镜场景中的光照问题和信息干扰，从而实现有效的自我监督深度估计。&lt;h4&gt;方法&lt;/h4&gt;该方法采用多步骤高效微调策略，包括光流配准、多尺度图像分解和多次变换对齐。每个步骤中，仅训练相关网络，避免无关信息的干扰。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在SCARED数据集上的自我监督深度估计和Hamlyn数据集上的零样本深度估计上均取得了最先进的性能，误差降低了4%至10%。&lt;h4&gt;结论&lt;/h4&gt;该框架通过参数高效的微调，在内窥镜场景中实现了高效和准确的深度估计。&lt;h4&gt;翻译&lt;/h4&gt;Monocular depth estimation and ego-motion estimation are significant tasks for scene perception and navigation in stable, accurate and efficient robot-assisted endoscopy. To tackle lighting variations and sparse textures in endoscopic scenes, multiple techniques including optical flow, appearance flow and intrinsic image decomposition have been introduced into the existing methods. However, the effective training strategy for multiple modules are still critical to deal with both illumination issues and information interference for self-supervised depth estimation in endoscopy. Therefore, a novel framework with multistep efficient finetuning is proposed in this work. In each epoch of end-to-end training, the process is divided into three steps, including optical flow registration, multiscale image decomposition and multiple transformation alignments. At each step, only the related networks are trained without interference of irrelevant information. Based on parameter-efficient finetuning on the foundation model, the proposed method achieves state-of-the-art performance on self-supervised depth estimation on SCARED dataset and zero-shot depth estimation on Hamlyn dataset, with 4%∼10% lower error. The evaluation code of this work has been published on https://github.com/BaymaxShao/EndoMUST.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular depth estimation and ego-motion estimation are significant tasksfor scene perception and navigation in stable, accurate and efficientrobot-assisted endoscopy. To tackle lighting variations and sparse textures inendoscopic scenes, multiple techniques including optical flow, appearance flowand intrinsic image decomposition have been introduced into the existingmethods. However, the effective training strategy for multiple modules arestill critical to deal with both illumination issues and informationinterference for self-supervised depth estimation in endoscopy. Therefore, anovel framework with multistep efficient finetuning is proposed in this work.In each epoch of end-to-end training, the process is divided into three steps,including optical flow registration, multiscale image decomposition andmultiple transformation alignments. At each step, only the related networks aretrained without interference of irrelevant information. Based onparameter-efficient finetuning on the foundation model, the proposed methodachieves state-of-the-art performance on self-supervised depth estimation onSCARED dataset and zero-shot depth estimation on Hamlyn dataset, with4\%$\sim$10\% lower error. The evaluation code of this work has been publishedon https://github.com/BaymaxShao/EndoMUST.</description>
      <author>example@mail.com (Liangjing Shao, Linxin Bai, Chenkang Du, Xinrong Chen)</author>
      <guid isPermaLink="false">2506.16017v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Brain with Foundation Models through Self-Supervised Learning</title>
      <link>http://arxiv.org/abs/2506.16009v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了通过自监督学习将大脑信号与基础模型结合的兴起领域，探讨了关键的自监督学习技术、特定于大脑的基础模型的发展、它们在下游任务中的应用以及多模态自监督框架中大脑信号与其他模态的整合。还涵盖了常用的评估指标和基准数据集，并强调了关键挑战和未来的研究方向。&lt;h4&gt;背景&lt;/h4&gt;基础模型（FMs）通过自监督学习（SSL）展示了人工智能在自然语言处理和计算机视觉等领域的卓越性能，为大脑信号分析提供了变革性的机会。&lt;h4&gt;目的&lt;/h4&gt;旨在为研究人员提供对这一快速发展的领域的结构化理解，并为开发由自监督驱动的通用大脑基础模型提供路线图。&lt;h4&gt;方法&lt;/h4&gt;系统地回顾了通过创新应用自监督学习将大脑信号与基础模型结合的领域，包括关键的自监督学习技术、特定于大脑的基础模型的发展、它们在下游任务中的应用以及多模态自监督框架中大脑信号与其他模态的整合。&lt;h4&gt;主要发现&lt;/h4&gt;自监督学习（SSL）为解决大脑信号分析中的独特挑战（如高噪声水平、个体间差异和低信噪比）提供了一种有希望的解决方案。&lt;h4&gt;结论&lt;/h4&gt;本文强调了关键挑战并概述了未来的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;This survey systematically reviews the emerging field of bridging brain signals with foundation models through the innovative application of SSL. It explores key SSL techniques, the development of brain-specific foundation models, their adaptation to downstream tasks, and the integration of brain signals with other modalities in multimodal SSL frameworks. The review also covers commonly used evaluation metrics and benchmark datasets that support comparative analysis. Finally, it highlights key challenges and outlines future research directions. This work aims to provide researchers with a structured understanding of this rapidly evolving field and a roadmap for developing generalizable brain foundation models powered by self-supervision.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs), powered by self-supervised learning (SSL), haveredefined the capabilities of artificial intelligence, demonstratingexceptional performance in domains like natural language processing andcomputer vision. These advances present a transformative opportunity for brainsignal analysis. Unlike traditional supervised learning, which is limited bythe scarcity of labeled neural data, SSL offers a promising solution byenabling models to learn meaningful representations from unlabeled data. Thisis particularly valuable in addressing the unique challenges of brain signals,including high noise levels, inter-subject variability, and low signal-to-noiseratios. This survey systematically reviews the emerging field of bridging brainsignals with foundation models through the innovative application of SSL. Itexplores key SSL techniques, the development of brain-specific foundationmodels, their adaptation to downstream tasks, and the integration of brainsignals with other modalities in multimodal SSL frameworks. The review alsocovers commonly used evaluation metrics and benchmark datasets that supportcomparative analysis. Finally, it highlights key challenges and outlines futureresearch directions. This work aims to provide researchers with a structuredunderstanding of this rapidly evolving field and a roadmap for developinggeneralizable brain foundation models powered by self-supervision.</description>
      <author>example@mail.com (Hamdi Altaheri, Fakhri Karray, Md. Milon Islam, S M Taslim Uddin Raju, Amir-Hossein Karimi)</author>
      <guid isPermaLink="false">2506.16009v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>DeSPITE: Exploring Contrastive Deep Skeleton-Pointcloud-IMU-Text Embeddings for Advanced Point Cloud Human Activity Understanding</title>
      <link>http://arxiv.org/abs/2506.13897v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work is currently under review at ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用LiDAR技术进行人类活动理解的深度学习模型，提出了一种名为DeSPITE的模型，用于学习LiDAR点云、人体骨骼姿态、IMU数据和文本之间的对应关系。&lt;h4&gt;背景&lt;/h4&gt;尽管LiDAR是一种有效的隐私保护技术，但在多模态对比预训练领域，LiDAR的应用研究相对较少。&lt;h4&gt;目的&lt;/h4&gt;填补LiDAR在多模态对比预训练领域的研究空白，探索LiDAR点云、人体骨骼姿态、IMU数据和文本之间的联合嵌入空间。&lt;h4&gt;方法&lt;/h4&gt;提出DeSPITE模型，通过结合LIPD和Babel数据集，实现四种模态数据的同步，从而学习新的联合嵌入空间。&lt;h4&gt;主要发现&lt;/h4&gt;DeSPITE模型能够有效学习LiDAR点云、人体骨骼姿态、IMU数据和文本之间的联合嵌入空间，并在人类活动理解任务中表现出色，包括骨骼与点云、IMU之间的匹配、检索以及时间关键点的检索。&lt;h4&gt;结论&lt;/h4&gt;DeSPITE是一种有效的预训练策略，适用于点云序列的人类活动识别。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管LiDAR（光探测与测距）是一种有效的隐私保护替代方案，用于感知人类活动，但在多模态对比预训练的背景下，它仍然在很大程度上未被探索，用于人类活动理解（例如，人类活动识别（HAR）、检索或人员重识别（RE-ID））。为了填补这一空白，我们的工作探索了在联合嵌入空间中学习LiDAR点云、人体骨骼姿态、IMU数据和文本之间的对应关系。更具体地说，我们提出了DeSPITE，一个深度骨骼-点云-IMU-文本嵌入模型，它有效地学习这四种模态之间的联合嵌入空间。在我们的实证探索的核心，我们结合了现有的LIPD和Babel数据集，这使得我们能够同步所有四种模态的数据，从而探索新的联合嵌入空间的学习。我们的实验表明，通过DeSPITE实现了新的点云序列人类活动理解任务，包括骨骼&lt;-&gt;点云&lt;-&gt;IMU匹配、检索和时间关键点检索。此外，我们通过在MSR-Action3D和HMPEAR上的实验表明，DeSPITE是一种有效的点云HAR预训练策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite LiDAR (Light Detection and Ranging) being an effectiveprivacy-preserving alternative to RGB cameras to perceive human activities, itremains largely underexplored in the context of multi-modal contrastivepre-training for human activity understanding (e.g., human activity recognition(HAR), retrieval, or person re-identification (RE-ID)). To close this gap, ourwork explores learning the correspondence between LiDAR point clouds, humanskeleton poses, IMU data, and text in a joint embedding space. Morespecifically, we present DeSPITE, a Deep Skeleton-Pointcloud-IMU-Text Embeddingmodel, which effectively learns a joint embedding space across these fourmodalities. At the heart of our empirical exploration, we have combined theexisting LIPD and Babel datasets, which enabled us to synchronize data of allfour modalities, allowing us to explore the learning of a new joint embeddingspace. Our experiments demonstrate novel human activity understanding tasks forpoint cloud sequences enabled through DeSPITE, includingSkeleton&lt;-&gt;Pointcloud&lt;-&gt;IMU matching, retrieval, and temporal moment retrieval.Furthermore, we show that DeSPITE is an effective pre-training strategy forpoint cloud HAR through experiments in MSR-Action3D and HMPEAR.</description>
      <author>example@mail.com (Thomas Kreutz, Max Mühlhäuser, Alejandro Sanchez Guinea)</author>
      <guid isPermaLink="false">2506.13897v2</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>One Period to Rule Them All: Identifying Critical Learning Periods in Deep Networks</title>
      <link>http://arxiv.org/abs/2506.15954v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了深度学习中关键学习期现象，提出了一种系统方法来识别深度神经网络训练中的关键时期，以减少计算成本和提高效率。&lt;h4&gt;背景&lt;/h4&gt;现有研究表明早期时期对许多训练方法（如数据增强）的成功至关重要，但缺乏精确识别关键时期的方法。&lt;h4&gt;目的&lt;/h4&gt;填补现有文献的空白，通过引入一种系统方法来识别深度神经网络训练中的关键时期，以减少计算成本和提高学习效率。&lt;h4&gt;方法&lt;/h4&gt;该方法利用泛化预测机制来识别训练方法对模型可预测性产生最大效益的关键阶段，并通过停止资源密集型方法来加速学习过程。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法可以显著减少训练时间，最高可达59.67%，从而降低CO$_2$排放和财务成本，同时不损害性能。&lt;h4&gt;结论&lt;/h4&gt;该研究增强了人们对训练动态的理解，为更可持续和高效的深度学习实践铺平了道路，尤其是在资源受限的环境中。&lt;h4&gt;翻译&lt;/h4&gt;Critical Learning Periods comprehend an important phenomenon involving deep learning, where early epochs play a decisive role in the success of many training recipes, such as data augmentation. Existing works confirm the existence of this phenomenon and provide useful insights. However, the literature lacks efforts to precisely identify when critical periods occur. In this work, we fill this gap by introducing a systematic approach for identifying critical periods during the training of deep neural networks, focusing on eliminating computationally intensive regularization techniques and effectively applying mechanisms for reducing computational costs, such as data pruning. Our method leverages generalization prediction mechanisms to pinpoint critical phases where training recipes yield maximum benefits to the predictiveability of models. By halting resource-intensive recipes beyond these periods, we significantly accelerate the learning phase and achieve reductions in training time, energy consumption, and CO$_2$ emissions. Experiments on standard architectures and benchmarks confirm the effectiveness of our method. Specifically, we achieve significant milestones by reducing the training time of popular architectures by up to 59.67%, leading to a 59.47% decrease in CO$_2$ emissions and a 60% reduction in financial costs, without compromising performance. Our work enhances understanding of training dynamics and paves the way for more sustainable and efficient deep learning practices, particularly in resource-constrained environments. In the era of the race for foundation models, we believe our method emerges as a valuable framework. The repository is available at https://github.com/baunilhamarga/critical-periods&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Critical Learning Periods comprehend an important phenomenon involving deeplearning, where early epochs play a decisive role in the success of manytraining recipes, such as data augmentation. Existing works confirm theexistence of this phenomenon and provide useful insights. However, theliterature lacks efforts to precisely identify when critical periods occur. Inthis work, we fill this gap by introducing a systematic approach foridentifying critical periods during the training of deep neural networks,focusing on eliminating computationally intensive regularization techniques andeffectively applying mechanisms for reducing computational costs, such as datapruning. Our method leverages generalization prediction mechanisms to pinpointcritical phases where training recipes yield maximum benefits to the predictiveability of models. By halting resource-intensive recipes beyond these periods,we significantly accelerate the learning phase and achieve reductions intraining time, energy consumption, and CO$_2$ emissions. Experiments onstandard architectures and benchmarks confirm the effectiveness of our method.Specifically, we achieve significant milestones by reducing the training timeof popular architectures by up to 59.67%, leading to a 59.47% decrease inCO$_2$ emissions and a 60% reduction in financial costs, without compromisingperformance. Our work enhances understanding of training dynamics and paves theway for more sustainable and efficient deep learning practices, particularly inresource-constrained environments. In the era of the race for foundationmodels, we believe our method emerges as a valuable framework. The repositoryis available at https://github.com/baunilhamarga/critical-periods</description>
      <author>example@mail.com (Vinicius Yuiti Fukase, Heitor Gama, Barbara Bueno, Lucas Libanio, Anna Helena Reali Costa, Artur Jordao)</author>
      <guid isPermaLink="false">2506.15954v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>A Qubit as a Bridge Between Statistical Mechanics and Quantum Dynamics</title>
      <link>http://arxiv.org/abs/2506.15931v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文从统一的角度研究了热平衡和量子动力学，以最简单的量子系统——量子比特，作为基础模型。&lt;h4&gt;背景&lt;/h4&gt;研究热平衡和量子动力学，并探索量子比特作为基础模型的意义。&lt;h4&gt;目的&lt;/h4&gt;通过研究量子比特，展示热平衡和量子动力学之间的联系。&lt;h4&gt;方法&lt;/h4&gt;使用Cauchy-Riemann方程等数学工具，对量子比特进行理论分析。&lt;h4&gt;主要发现&lt;/h4&gt;热平衡分配函数和Loschmidt振幅可以看作是沿复平面上不同路径的单个解析函数的扩展。Loschmidt振幅的零点编码了动力学特征，如正交性、率函数奇点和量子速度极限。高温比热容对应早期时间演化。&lt;h4&gt;结论&lt;/h4&gt;从单个量子比特到相互作用自旋链的讨论遵循了教学进展。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种关于热平衡和量子动力学的统一视角，通过研究最简单的量子系统——量子比特作为基础模型。我们表明，热平衡分配函数和Loschmidt振幅都可以理解为沿复平面上不同路径的单个解析函数的扩展。Loschmidt振幅的零点编码了诸如正交性、率函数奇点和量子速度极限等动力学特征，类似于分配函数零点在平衡统计力学中的作用。我们进一步通过Cauchy-Riemann方程建立，高温比热容对应早期时间演化。讨论遵循从单个量子比特到相互作用自旋链的教学进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents a unified perspective on thermal equilibrium and quantumdynamics by examining the simplest quantum system, a qubit, as a foundationalmodel. We show that both the thermal partition function and the Loschmidtamplitude can be understood as extensions of a single analytic function alongdifferent paths in the complex plane. The zeros of Loschmidt amplitude encodedynamical features such as orthogonality, rate function singularities, andquantum speed limits, in analogy with the role of partition function zeros inequilibrium statistical mechanics. We further establish, through theCauchy-Riemann equations, that the high-temperature specific heat correspondsto early-time evolution. The discussion follows a pedagogical progression froma single qubit to an interacting spin chain.</description>
      <author>example@mail.com (Manmeet Kaur, Somendra M. Bhattacharjee)</author>
      <guid isPermaLink="false">2506.15931v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Descriptor-based Foundation Models for Molecular Property Prediction</title>
      <link>http://arxiv.org/abs/2506.15792v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CheMeleon是一种新的分子基础模型，通过在Mordred包的确定性分子描述符上进行预训练，使用有向消息传递神经网络预测这些描述符，在无噪声环境下进行学习。该模型在多项基准数据集上表现出色，但在区分活性悬崖方面存在挑战。&lt;h4&gt;背景&lt;/h4&gt;快速准确地预测分子性质对科学进步至关重要，特别是基础模型在小型、真实世界数据集上的训练表现突出。&lt;h4&gt;目的&lt;/h4&gt;引入CheMeleon模型，以提高分子性质预测的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;CheMeleon利用Mordred包中的确定性分子描述符进行预训练，并采用有向消息传递神经网络来预测这些描述符。&lt;h4&gt;主要发现&lt;/h4&gt;CheMeleon在Polaris和MoleculeACE的基准数据集上表现出色，Polaris任务中胜率为79%，MoleculeACE测试中胜率为97%，但在区分活性悬崖方面存在困难。&lt;h4&gt;结论&lt;/h4&gt;CheMeleon展示了基于描述符的预训练在可扩展和有效的分子性质预测中的潜力，为探索描述符集合和无标签数据集提供了新的途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：利用机器学习快速准确地预测分子性质对于推动众多领域的科学发展至关重要。特别是基础模型在小型、真实世界数据集上的训练表现出色。本研究引入了CheMeleon，这是一种新的分子基础模型，在Mordred包的确定性分子描述符上进行预训练，利用有向消息传递神经网络在无噪声环境下预测这些描述符。与依赖于噪声实验数据或偏颇的量子力学模拟的传统方法不同，CheMeleon使用低噪声分子描述符来学习丰富的分子表示。在Polaris和MoleculeACE的58个基准数据集上评估，CheMeleon在Polaris任务中的胜率为79%，优于随机森林（46%）、fastprop（39%）和Chemprop（36%），在MoleculeACE测试中的胜率为97%，超过了随机森林（63%）和其他基础模型。然而，它像许多测试模型一样，在区分活性悬崖方面存在困难。CheMeleon学习表示的t-SNE投影展示了有效分离化学系列的能力，突显了其捕捉结构细微差别的能力。这些结果强调了基于描述符的预训练在可扩展和有效的分子性质预测中的潜力，为探索描述符集合和无标签数据集开辟了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fast and accurate prediction of molecular properties with machine learning ispivotal to scientific advancements across myriad domains. Foundation models inparticular have proven especially effective, enabling accurate training onsmall, real-world datasets. This study introduces CheMeleon, a novel molecularfoundation model pre-trained on deterministic molecular descriptors from theMordred package, leveraging a Directed Message-Passing Neural Network topredict these descriptors in a noise-free setting. Unlike conventionalapproaches relying on noisy experimental data or biased quantum mechanicalsimulations, CheMeleon uses low-noise molecular descriptors to learn richmolecular representations. Evaluated on 58 benchmark datasets from Polaris andMoleculeACE, CheMeleon achieves a win rate of 79% on Polaris tasks,outperforming baselines like Random Forest (46%), fastprop (39%), and Chemprop(36%), and a 97% win rate on MoleculeACE assays, surpassing Random Forest (63%)and other foundation models. However, it struggles to distinguish activitycliffs like many of the tested models. The t-SNE projection of CheMeleon'slearned representations demonstrates effective separation of chemical series,highlighting its ability to capture structural nuances. These resultsunderscore the potential of descriptor-based pre-training for scalable andeffective molecular property prediction, opening avenues for furtherexploration of descriptor sets and unlabeled datasets.</description>
      <author>example@mail.com (Jackson Burns, Akshat Zalte, William Green)</author>
      <guid isPermaLink="false">2506.15792v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>SynPo: Boosting Training-Free Few-Shot Medical Segmentation via High-Quality Negative Prompts</title>
      <link>http://arxiv.org/abs/2506.15153v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2025 Early Accept. Project Page:  https://liu-yufei.github.io/synpo-project-page/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为SynPo的训练免费少样本医学图像分割方法，基于大型视觉模型（LVMs）并着重于改进负提示的质量。&lt;h4&gt;背景&lt;/h4&gt;大型视觉模型（LVMs）的出现为少样本医学图像分割提供了新机会，但现有的基于LVMs的训练免费方法未能有效利用负提示，导致在低对比度医学图像上的性能不佳。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了SynPo方法，旨在通过改进负提示的质量来提高少样本医学图像分割的性能。&lt;h4&gt;方法&lt;/h4&gt;SynPo方法包括以下步骤：设计了一种新的置信图协同模块，结合了DINOv2和SAM的优势；基于置信图选择top-k像素作为正点集，并使用高斯分布选择负点集；对两组点进行独立的K-means聚类；然后将这些选定点作为高质量的提示输入SAM以获得分割结果。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验验证，SynPo在性能上与最先进的基于训练的少样本方法相当。&lt;h4&gt;结论&lt;/h4&gt;SynPo方法通过改进负提示的质量，有效提高了基于LVMs的少样本医学图像分割的性能，达到或超过了现有方法的水平。&lt;h4&gt;翻译&lt;/h4&gt;The advent of Large Vision Models (LVMs) offers new opportunities for few-shot medical image segmentation. However, existing training-free methods based on LVMs fail to effectively utilize negative prompts, leading to poor performance on low-contrast medical images. To address this issue, we propose SynPo, a training-free few-shot method based on LVMs (e.g., SAM), with the core insight: improving the quality of negative prompts. To select point prompts in a more reliable confidence map, we design a novel Confidence Map Synergy Module by combining the strengths of DINOv2 and SAM. Based on the confidence map, we select the top-k pixels as the positive points set and choose the negative points set using a Gaussian distribution, followed by independent K-means clustering for both sets. Then, these selected points are leveraged as high-quality prompts for SAM to get the segmentation results. Extensive experiments demonstrate that SynPo achieves performance comparable to state-of-the-art training-based few-shot methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of Large Vision Models (LVMs) offers new opportunities forfew-shot medical image segmentation. However, existing training-free methodsbased on LVMs fail to effectively utilize negative prompts, leading to poorperformance on low-contrast medical images. To address this issue, we proposeSynPo, a training-free few-shot method based on LVMs (e.g., SAM), with the coreinsight: improving the quality of negative prompts. To select point prompts ina more reliable confidence map, we design a novel Confidence Map Synergy Moduleby combining the strengths of DINOv2 and SAM. Based on the confidence map, weselect the top-k pixels as the positive points set and choose the negativepoints set using a Gaussian distribution, followed by independent K-meansclustering for both sets. Then, these selected points are leveraged ashigh-quality prompts for SAM to get the segmentation results. Extensiveexperiments demonstrate that SynPo achieves performance comparable tostate-of-the-art training-based few-shot methods.</description>
      <author>example@mail.com (Yufei Liu, Haoke Xiao, Jiaxing Chai, Yongcun Zhang, Rong Wang, Zijie Meng, Zhiming Luo)</author>
      <guid isPermaLink="false">2506.15153v2</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>The Urban Model Platform: A Public Backbone for Modeling and Simulation in Urban Digital Twins</title>
      <link>http://arxiv.org/abs/2506.10964v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;城市数字孪生被视为汇聚城市数字资源，以实现更可持续和综合的城市规划的方法。然而，模型和模拟的整合和使用过程复杂，现有方法多集中于集中式解决方案，本文提出了一种基于开放标准的平台，以实现模型集成、通信和多模型方法来表示城市系统。&lt;h4&gt;背景&lt;/h4&gt;城市数字孪生在城市规划中的作用越来越受到重视，但模型的整合和使用过程复杂。&lt;h4&gt;目的&lt;/h4&gt;通过开放平台实现城市数字孪生中模型和模拟的集成，以及支持协作和多元化的城市过程表示。&lt;h4&gt;方法&lt;/h4&gt;采用参与式设计和参与式系统方法，与德国汉堡市合作。&lt;h4&gt;主要发现&lt;/h4&gt;开放的都市模型平台可以作为城市数字孪生中模型和模拟的公共技术基础，同时也是城市过程协作和多元化表示的社会技术框架。&lt;h4&gt;结论&lt;/h4&gt;基于开放标准的平台可以促进模型的分散式集成，实现模型间的通信，并支持多模型方法来表示城市系统。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urban digital twins are increasingly perceived as a way to pool the growingdigital resources of cities for the purpose of a more sustainable andintegrated urban planning. Models and simulations are central to thisundertaking: They enable "what if?" scenarios, create insights and describerelationships between the vast data that is being collected. However, theprocess of integrating and subsequently using models in urban digital twins isan inherently complex undertaking. It raises questions about how to representurban complexity, how to deal with uncertain assumptions and modelingparadigms, and how to capture underlying power relations. Existent approachesin the domain largely focus on monolithic and centralized solutions in thetradition of neoliberal city-making, oftentimes prohibiting pluralistic andopen interoperable models. Using a participatory design for participatorysystems approach together with the City of Hamburg, Germany, we find that anopen Urban Model Platform can function both as a public technological backbonefor modeling and simulation in urban digital twins and as a socio-technicalframework for a collaborative and pluralistic representation of urbanprocesses. Such a platform builds on open standards, allows for a decentralizedintegration of models, enables communication between models and supports amulti-model approach to representing urban systems.</description>
      <author>example@mail.com (Rico H Herzog, Till Degkwitz, Trivik Verma)</author>
      <guid isPermaLink="false">2506.10964v3</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>MCOO-SLAM: A Multi-Camera Omnidirectional Object SLAM System</title>
      <link>http://arxiv.org/abs/2506.15402v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为MCOO-SLAM的新的多摄像头全向对象SLAM系统，旨在通过利用全向摄像头配置，在复杂户外环境中实现鲁棒的、一致的、语义丰富的地图构建。&lt;h4&gt;背景&lt;/h4&gt;现有SLAM方法大多依赖于RGB-D传感器或单目视角，存在视场窄、易遮挡、深度感知能力有限等问题，导致物体建模不准确和数据关联不可靠。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够在复杂户外环境中进行鲁棒、一致、语义丰富的地图构建的系统。&lt;h4&gt;方法&lt;/h4&gt;MCOO-SLAM系统结合了点特征和语义增强的对象级地标，引入了语义-几何-时间融合策略以实现多视图下的鲁棒物体关联，设计了全向环路闭合模块来实现基于场景描述符的无视点变化的地点识别。此外，构建的地图被抽象成层次化的3D场景图，以支持下游推理任务。&lt;h4&gt;主要发现&lt;/h4&gt;MCOO-SLAM系统实现了准确的位置定位和可扩展的对象级映射，并且对遮挡、姿态变化和环境复杂性具有更好的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;MCOO-SLAM系统为在复杂户外环境中进行SLAM提供了一种有效的方法，具有更高的准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;Object-level SLAM provides structured and semantically meaningful environment representations, making it more interpretable and suitable for high-level robotic tasks. However, most existing approaches rely on RGB-D sensors or monocular views, which suffer from narrow fields of view, occlusion sensitivity, and limited depth perception-especially in large-scale or outdoor environments. These limitations often restrict the system to observing only partial views of objects from limited perspectives, leading to inaccurate object modeling and unreliable data association. In this work, we propose MCOO-SLAM, a novel Multi-Camera Omnidirectional Object SLAM system that fully leverages surround-view camera configurations to achieve robust, consistent, and semantically enriched mapping in complex outdoor scenarios. Our approach integrates point features and object-level landmarks enhanced with open-vocabulary semantics. A semantic-geometric-temporal fusion strategy is introduced for robust object association across multiple views, leading to improved consistency and accurate object modeling, and an omnidirectional loop closure module is designed to enable viewpoint-invariant place recognition using scene-level descriptors. Furthermore, the constructed map is abstracted into a hierarchical 3D scene graph to support downstream reasoning tasks. Extensive experiments in real-world demonstrate that MCOO-SLAM achieves accurate localization and scalable object-level mapping with improved robustness to occlusion, pose variation, and environmental complexity.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object-level SLAM offers structured and semantically meaningful environmentrepresentations, making it more interpretable and suitable for high-levelrobotic tasks. However, most existing approaches rely on RGB-D sensors ormonocular views, which suffer from narrow fields of view, occlusionsensitivity, and limited depth perception-especially in large-scale or outdoorenvironments. These limitations often restrict the system to observing onlypartial views of objects from limited perspectives, leading to inaccurateobject modeling and unreliable data association. In this work, we proposeMCOO-SLAM, a novel Multi-Camera Omnidirectional Object SLAM system that fullyleverages surround-view camera configurations to achieve robust, consistent,and semantically enriched mapping in complex outdoor scenarios. Our approachintegrates point features and object-level landmarks enhanced withopen-vocabulary semantics. A semantic-geometric-temporal fusion strategy isintroduced for robust object association across multiple views, leading toimproved consistency and accurate object modeling, and an omnidirectional loopclosure module is designed to enable viewpoint-invariant place recognitionusing scene-level descriptors. Furthermore, the constructed map is abstractedinto a hierarchical 3D scene graph to support downstream reasoning tasks.Extensive experiments in real-world demonstrate that MCOO-SLAM achievesaccurate localization and scalable object-level mapping with improvedrobustness to occlusion, pose variation, and environmental complexity.</description>
      <author>example@mail.com (Miaoxin Pan, Jinnan Li, Yaowen Zhang, Yi Yang, Yufeng Yue)</author>
      <guid isPermaLink="false">2506.15402v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
  <item>
      <title>Learning Task-Agnostic Skill Bases to Uncover Motor Primitives in Animal Behaviors</title>
      <link>http://arxiv.org/abs/2506.15190v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages and 4 figures for the main text&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于技能的模仿学习（SKIL）方法，用于理解动物行为，并通过在简单网格世界、离散迷宫和自由移动动物的未约束视频中验证，证明了该方法能够识别可重用技能组件，学习不断演变的组合策略，并生成超越传统离散模型的现实轨迹。&lt;h4&gt;背景&lt;/h4&gt;现有的行为分段方法通过强加离散音节和限制性生成假设来简化动物行为的重组过程。&lt;h4&gt;目的&lt;/h4&gt;为了反映动物行为生成过程，提出SKIL方法以理解动物行为。&lt;h4&gt;方法&lt;/h4&gt;SKIL方法通过以下方式工作：(1) 利用表示学习在过渡概率上推断可解释的技能集，即行为的潜在基函数；(2) 将策略参数化为这些技能的动态混合。&lt;h4&gt;主要发现&lt;/h4&gt;在多个任务中，该方法识别了可重用技能组件，学习了不断演变的组合策略，并生成了超越传统离散模型的现实轨迹。&lt;h4&gt;结论&lt;/h4&gt;通过利用组合表示的生成行为建模，该方法提供了一个简洁、原则性的解释，说明了复杂动物行为是如何从基本运动原型的动态组合中产生的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Animals flexibly recombine a finite set of core motor primitives to meetdiverse task demands, but existing behavior-segmentation methods oversimplifythis process by imposing discrete syllables under restrictive generativeassumptions. To reflect the animal behavior generation procedure, we introduceskill-based imitation learning (SKIL) for behavior understanding, areinforcement learning-based imitation framework that (1) infers interpretableskill sets, i.e., latent basis functions of behavior, by leveragingrepresentation learning on transition probabilities, and (2) parameterizespolicies as dynamic mixtures of these skills. We validate our approach on asimple grid world, a discrete labyrinth, and unconstrained videos of freelymoving animals. Across tasks, it identifies reusable skill components, learnscontinuously evolving compositional policies, and generates realistictrajectories beyond the capabilities of traditional discrete models. Byexploiting generative behavior modeling with compositional representations, ourmethod offers a concise, principled account of how complex animal behaviorsemerge from dynamic combinations of fundamental motor primitives.</description>
      <author>example@mail.com (Jiyi Wang, Jingyang Ke, Bo Dai, Anqi Wu)</author>
      <guid isPermaLink="false">2506.15190v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Transit for All: Mapping Equitable Bike2Subway Connection using Region Representation Learning</title>
      <link>http://arxiv.org/abs/2506.15113v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个名为Transit for All (TFA)的框架，旨在指导公交自行车共享系统（BSS）的公平扩展，以解决密集城市如纽约市中低收入和少数族裔社区面临的公交可及性问题。&lt;h4&gt;背景&lt;/h4&gt;在纽约市等人口密集的城市，低收入和少数族裔社区往往面临公交可及性受限的问题。自行车共享系统可以填补这些公平差距，但将BSS扩展到未服务社区困难重重，因为新的自行车共享站点位置的需求不确定，且传统可及性指标可能忽略了实际的自行车使用潜力。&lt;h4&gt;目的&lt;/h4&gt;开发TFA框架，通过预测需求、综合评估可及性和提供战略建议，以促进BSS的公平扩展。&lt;h4&gt;方法&lt;/h4&gt;TFA框架包括三个组件：(1)利用区域表示学习集成多模式地理空间数据，在冷启动站点进行空间感知的自行车共享需求预测；(2)结合预测的自行车共享需求和传统的公交可及性指标，进行全面的公交可及性评估；(3)考虑潜在乘客量和公平性提升的战略性新自行车站点布局建议。&lt;h4&gt;主要发现&lt;/h4&gt;以纽约市为案例研究，TFA识别了历史上未服务的社区中低收入和少数族裔社区受到不成比例影响的公交可及性差距。结果表明，根据加权公交可及性水平（wPTAL）战略性地放置新站点可以显著减少与经济和人口统计因素相关的公交可及性差异。&lt;h4&gt;结论&lt;/h4&gt;TFA为城市规划者提供了实际指导，以促进公平的公交服务，并提升未服务城市社区的居住质量。&lt;h4&gt;翻译&lt;/h4&gt;确保公平的公交可及性仍然是一个挑战，特别是在像纽约市这样人口密集的城市，低收入和少数族裔社区往往面临公交可及性有限的问题。自行车共享系统（BSS）可以通过提供经济的第一和最后一英里连接来弥合这些公平差距。然而，由于新规划的（冷启动）站点的不确定的自行车共享需求以及传统可及性指标可能忽视的现实自行车使用潜力，将BSS战略性地扩展到未服务的社区是困难的。我们引入了Transit for All（TFA），一个旨在通过三个组件指导BSS公平扩展的空间计算框架：(1)利用区域表示学习集成多模式地理空间数据，在冷启动站点进行空间感知的自行车共享需求预测；(2)结合预测的自行车共享需求和传统的公交可及性指标，进行全面的公交可及性评估；(3)考虑潜在乘客量和公平性提升的战略性新自行车站点布局建议。以纽约市为案例研究，我们确定了历史上未服务的社区中低收入和少数族裔社区受到不成比例影响的公交可及性差距。我们的结果表明，根据加权公交可及性水平（wPTAL）战略性地放置新站点可以显著减少与经济和人口统计因素相关的公交可及性差异。从我们的研究中，我们证明了TFA为城市规划者提供了实际指导，以促进公平的公交服务，并提升未服务城市社区的居住质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring equitable public transit access remains challenging, particularly indensely populated cities like New York City (NYC), where low-income andminority communities often face limited transit accessibility. Bike-sharingsystems (BSS) can bridge these equity gaps by providing affordable first- andlast-mile connections. However, strategically expanding BSS into underservedneighborhoods is difficult due to uncertain bike-sharing demand at newlyplanned ("cold-start") station locations and limitations in traditionalaccessibility metrics that may overlook realistic bike usage potential. Weintroduce Transit for All (TFA), a spatial computing framework designed toguide the equitable expansion of BSS through three components: (1)spatially-informed bike-sharing demand prediction at cold-start stations usingregion representation learning that integrates multimodal geospatial data, (2)comprehensive transit accessibility assessment leveraging our novel weightedPublic Transport Accessibility Level (wPTAL) by combining predictedbike-sharing demand with conventional transit accessibility metrics, and (3)strategic recommendations for new bike station placements that considerpotential ridership and equity enhancement. Using NYC as a case study, weidentify transit accessibility gaps that disproportionately impact low-incomeand minority communities in historically underserved neighborhoods. Our resultsshow that strategically placing new stations guided by wPTAL notably reducesdisparities in transit access related to economic and demographic factors. Fromour study, we demonstrate that TFA provides practical guidance for urbanplanners to promote equitable transit and enhance the quality of life inunderserved urban communities.</description>
      <author>example@mail.com (Min Namgung, JangHyeon Lee, Fangyi Ding, Yao-Yi Chiang)</author>
      <guid isPermaLink="false">2506.15113v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>MonoVQD: Monocular 3D Object Detection with Variational Query Denoising and Self-Distillation</title>
      <link>http://arxiv.org/abs/2506.14835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MonoVQD是一种新的框架，旨在提高基于DETR的单目3D检测的性能，通过引入多种机制来解决现有方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;单目3D检测是计算机视觉中的一个关键挑战，而DETR-like架构在直接应用于此领域时存在固有局限性。&lt;h4&gt;目的&lt;/h4&gt;提出MonoVQD框架，以解决单目3D检测中的挑战，并提高检测性能。&lt;h4&gt;方法&lt;/h4&gt;1. 提出Mask Separated Self-Attention机制，将去噪过程集成到DETR架构中，提高匈牙利匹配的稳定性。2. 提出变分查询去噪技术，解决传统去噪方法的梯度消失问题，引入随机性以减轻基本限制并实现性能提升。3. 引入复杂的自蒸馏策略，利用后期解码层的见解来协同提高早期层的查询质量，增强迭代优化过程。&lt;h4&gt;主要发现&lt;/h4&gt;MonoVQD在KITTI单目基准测试上实现了优越的性能，其核心组件能够无缝集成到其他架构中，在nuScenes数据集上的多视图3D检测场景中也表现出显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;MonoVQD通过多种创新技术显著提高了单目3D检测的性能，并展现了其广泛的应用性和鲁棒的一般化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Precisely localizing 3D objects from a single image constitutes a centralchallenge in monocular 3D detection. While DETR-like architectures offer apowerful paradigm, their direct application in this domain encounters inherentlimitations, preventing optimal performance. Our work addresses thesechallenges by introducing MonoVQD, a novel framework designed to fundamentallyadvance DETR-based monocular 3D detection. We propose three main contributions.First, we propose the Mask Separated Self-Attention mechanism that enables theintegration of the denoising process into a DETR architecture. This improvesthe stability of Hungarian matching to achieve a consistent optimizationobjective. Second, we present the Variational Query Denoising technique toaddress the gradient vanishing problem of conventional denoising methods, whichseverely restricts the efficiency of the denoising process. This explicitlyintroduces stochastic properties to mitigate this fundamental limitation andunlock substantial performance gains. Finally, we introduce a sophisticatedself-distillation strategy, leveraging insights from later decoder layers tosynergistically improve query quality in earlier layers, thereby amplifying theiterative refinement process. Rigorous experimentation demonstrates thatMonoVQD achieves superior performance on the challenging KITTI monocularbenchmark. Highlighting its broad applicability, MonoVQD's core componentsseamlessly integrate into other architectures, delivering significantperformance gains even in multi-view 3D detection scenarios on the nuScenesdataset and underscoring its robust generalization capabilities.</description>
      <author>example@mail.com (Kiet Dang Vu, Trung Thai Tran, Duc Dung Nguyen)</author>
      <guid isPermaLink="false">2506.14835v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Neural Canonical Polyadic Factorization for Traffic Analysis</title>
      <link>http://arxiv.org/abs/2506.15079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NCPF的模型，用于解决交通数据中因传感器故障和异构感知差距导致的缺失数据问题，以优化城市移动性和基础设施的弹性。&lt;h4&gt;背景&lt;/h4&gt;现代智能交通系统依赖于准确的时空交通分析来优化城市移动性和基础设施的弹性，但传感器故障和异构感知差距导致的缺失数据严重阻碍了可靠的交通建模。&lt;h4&gt;目的&lt;/h4&gt;提出一种NCPF模型，结合低秩张量代数和深度表示学习，实现鲁棒的交通数据插补。&lt;h4&gt;方法&lt;/h4&gt;NCPF模型将CP分解嵌入到神经网络架构中，通过可学习的嵌入投影将稀疏的交通张量编码到密集的潜在因子中，覆盖道路段、时间段和移动性指标。采用层次特征融合机制，使用Hadamard积显式建模多线性交互，并通过多层感知器层非线性地细化这些表示以捕获复杂的时空耦合。&lt;h4&gt;主要发现&lt;/h4&gt;在六个城市交通数据集上的广泛评估表明，NCPF优于六个最先进的基线。&lt;h4&gt;结论&lt;/h4&gt;NCPF通过统一CP分解的可解释因子分析与神经网络的非线性表达能力，为高维交通数据插补提供了一种原则性且灵活的方法，为下一代交通数字孪生和自适应交通控制系统提供了关键支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代智能交通系统依赖于准确的时空交通分析来优化城市移动性和基础设施的弹性。然而，由传感器故障和异构感知差距导致的普遍缺失数据根本阻碍了可靠的交通建模。本文提出了一种名为NCPF的模型，它将低秩张量代数与深度表示学习相结合，以实现鲁棒的交通数据插补。该模型创新地将CP分解嵌入到神经网络架构中，通过可学习的嵌入投影，将稀疏的交通张量编码到跨越道路段、时间段和移动性指标的密集潜在因子中。一种层次特征融合机制采用Hadamard积来显式地建模多线性交互，而堆叠的多层感知器层则非线性地细化这些表示以捕获复杂的时空耦合。在六个城市交通数据集上的广泛评估表明，NCPF优于六个最先进的基线。通过统一CP分解的可解释因子分析与神经网络的非线性表达能力，NCPF为高维交通数据插补提供了一种原则性且灵活的方法，为下一代交通数字孪生和自适应交通控制系统提供了关键支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern intelligent transportation systems rely on accurate spatiotemporaltraffic analysis to optimize urban mobility and infrastructure resilience.However, pervasive missing data caused by sensor failures and heterogeneoussensing gaps fundamentally hinders reliable traffic modeling. This paperproposes a Neural Canonical Polyadic Factorization (NCPF) model that synergizeslow-rank tensor algebra with deep representation learning for robust trafficdata imputation. The model innovatively embeds CP decomposition into neuralarchitecture through learnable embedding projections, where sparse traffictensors are encoded into dense latent factors across road segments, timeintervals, and mobility metrics. A hierarchical feature fusion mechanismemploys Hadamard products to explicitly model multilinear interactions, whilestacked multilayer perceptron layers nonlinearly refine these representationsto capture complex spatiotemporal couplings. Extensive evaluations on six urbantraffic datasets demonstrate NCPF's superiority over six state-of-the-artbaselines. By unifying CP decomposition's interpretable factor analysis withneural network's nonlinear expressive power, NCPF provides a principled yetflexible approaches for high-dimensional traffic data imputation, offeringcritical support for next-generation transportation digital twins and adaptivetraffic control systems.</description>
      <author>example@mail.com (Yikai Hou, Peng Tang)</author>
      <guid isPermaLink="false">2506.15079v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Understanding multi-fidelity training of machine-learned force-fields</title>
      <link>http://arxiv.org/abs/2506.14963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了两种多保真度训练策略（预训练/微调和多头训练）以阐明其成功机制，并提出了构建适用于广泛化学系统的机器学习力场（MLFFs）的方法。&lt;h4&gt;背景&lt;/h4&gt;有效利用多种量子化学方法的数据对于构建适用于广泛化学系统的机器学习力场（MLFFs）至关重要。&lt;h4&gt;目的&lt;/h4&gt;系统研究预训练/微调和多头训练两种多保真度训练策略，以阐明其成功机制。&lt;h4&gt;方法&lt;/h4&gt;研究了预训练/微调和多头训练两种策略，并分析了预训练阶段学习到的内部表示。&lt;h4&gt;主要发现&lt;/h4&gt;发现预训练/微调策略的关键因素，指出预训练阶段学习到的内部表示具有方法特定性，需要模型骨架在微调阶段进行适应；多头模型提供了可扩展的替代方案，能够同时进行多保真度训练；多头模型学习到的方法无关表示允许对多个标签源进行准确预测。&lt;h4&gt;结论&lt;/h4&gt;虽然多头训练相对于顺序微调引入了轻微的精度妥协，但它解锁了新的成本效益数据生成策略，为开发通用的MLFFs铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;Effectively leveraging data from multiple quantum-chemical methods is essential for building machine-learned force fields (MLFFs) that are applicable to a wide range of chemical systems. This study systematically investigates two multi-fidelity training strategies, pre-training/fine-tuning and multi-headed training, to elucidate the mechanisms underpinning their success. We identify key factors driving the efficacy of pre-training followed by fine-tuning, but find that internal representations learned during pre-training are inherently method-specific, requiring adaptation of the model backbone during fine-tuning. Multi-headed models offer an extensible alternative, enabling simultaneous training on multiple fidelities. We demonstrate that a multi-headed model learns method-agnostic representations that allow for accurate predictions across multiple label sources. While this approach introduces a slight accuracy compromise compared to sequential fine-tuning, it unlocks new cost-efficient data generation strategies and paves the way towards developing universal MLFFs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effectively leveraging data from multiple quantum-chemical methods isessential for building machine-learned force fields (MLFFs) that are applicableto a wide range of chemical systems. This study systematically investigates twomulti-fidelity training strategies, pre-training/fine-tuning and multi-headedtraining, to elucidate the mechanisms underpinning their success. We identifykey factors driving the efficacy of pre-training followed by fine-tuning, butfind that internal representations learned during pre-training are inherentlymethod-specific, requiring adaptation of the model backbone during fine-tuning.Multi-headed models offer an extensible alternative, enabling simultaneoustraining on multiple fidelities. We demonstrate that a multi-headed modellearns method-agnostic representations that allow for accurate predictionsacross multiple label sources. While this approach introduces a slight accuracycompromise compared to sequential fine-tuning, it unlocks new cost-efficientdata generation strategies and paves the way towards developing universalMLFFs.</description>
      <author>example@mail.com (John L. A. Gardner, Hannes Schulz, Jean Helie, Lixin Sun, Gregor N. C. Simm)</author>
      <guid isPermaLink="false">2506.14963v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Cosmos-Drive-Dreams: Scalable Synthetic Driving Data Generation with World Foundation Models</title>
      <link>http://arxiv.org/abs/2506.09042v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Only the core contributors are listed. The full list of contributors  can be found in Appendix A of this paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Cosmos-Drive-Dreams的合成数据生成（SDG）流程，用于生成具有挑战性的场景，以促进自动驾驶车辆（AV）系统的感知和驾驶策略训练。该流程使用Cosmos-Drive模型生成高质量、多视角、时空一致的驾驶视频。&lt;h4&gt;背景&lt;/h4&gt;收集和标注现实世界数据对于自动驾驶等安全关键物理AI系统来说既耗时又昂贵，尤其是捕捉罕见边缘案例，这些案例在AV系统的训练和测试中起着关键作用。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，目的是通过合成数据生成流程提高自动驾驶数据集的数量和多样性，同时保持高保真和挑战性。&lt;h4&gt;方法&lt;/h4&gt;Cosmos-Drive-Dreams利用Cosmos-Drive模型，该模型是从NVIDIA Cosmos世界基础模型专门针对驾驶领域设计的，能够生成可控、高保真、多视角和时空一致的驾驶视频。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，生成的数据有助于减轻长尾分布问题，并增强了下游任务（如3D车道检测、3D物体检测和驾驶策略学习）的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;Cosmos-Drive-Dreams工具包、数据集和模型权重已通过NVIDIA的Cosmos平台开源。&lt;h4&gt;翻译&lt;/h4&gt;Collecting and annotating real-world data for safety-critical physical AI systems, such as Autonomous Vehicle (AV), is time-consuming and costly. It is especially challenging to capture rare edge cases, which play a critical role in training and testing of an AV system. To address this challenge, we introduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipeline that aims to generate challenging scenarios to facilitate downstream tasks such as perception and driving policy training. Powering this pipeline is Cosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundation model for the driving domain and are capable of controllable, high-fidelity, multi-view, and spatiotemporally consistent driving video generation. We showcase the utility of these models by applying Cosmos-Drive-Dreams to scale the quantity and diversity of driving datasets with high-fidelity and challenging scenarios. Experimentally, we demonstrate that our generated data helps in mitigating long-tail distribution problems and enhances generalization in downstream tasks such as 3D lane detection, 3D object detection and driving policy learning. We open source our pipeline toolkit, dataset and model weights through the NVIDIA's Cosmos platform. Project page: https://research.nvidia.com/labs/toronto-ai/cosmos_drive_dreams&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nv-tlabs/cosmos-drive-dreams&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Collecting and annotating real-world data for safety-critical physical AIsystems, such as Autonomous Vehicle (AV), is time-consuming and costly. It isespecially challenging to capture rare edge cases, which play a critical rolein training and testing of an AV system. To address this challenge, weintroduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipelinethat aims to generate challenging scenarios to facilitate downstream tasks suchas perception and driving policy training. Powering this pipeline isCosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundationmodel for the driving domain and are capable of controllable, high-fidelity,multi-view, and spatiotemporally consistent driving video generation. Weshowcase the utility of these models by applying Cosmos-Drive-Dreams to scalethe quantity and diversity of driving datasets with high-fidelity andchallenging scenarios. Experimentally, we demonstrate that our generated datahelps in mitigating long-tail distribution problems and enhances generalizationin downstream tasks such as 3D lane detection, 3D object detection and drivingpolicy learning. We open source our pipeline toolkit, dataset and model weightsthrough the NVIDIA's Cosmos platform.  Project page: https://research.nvidia.com/labs/toronto-ai/cosmos_drive_dreams</description>
      <author>example@mail.com (Xuanchi Ren, Yifan Lu, Tianshi Cao, Ruiyuan Gao, Shengyu Huang, Amirmojtaba Sabour, Tianchang Shen, Tobias Pfaff, Jay Zhangjie Wu, Runjian Chen, Seung Wook Kim, Jun Gao, Laura Leal-Taixe, Mike Chen, Sanja Fidler, Huan Ling)</author>
      <guid isPermaLink="false">2506.09042v3</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>DisProtEdit: Exploring Disentangled Representations for Multi-Attribute Protein Editing</title>
      <link>http://arxiv.org/abs/2506.14853v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICMLW (GenBio) 2025 and ICMLW (FM4LS) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了DisProtEdit，一个可控的蛋白质编辑框架，利用双通道自然语言监督学习结构和功能的解耦表示。&lt;h4&gt;背景&lt;/h4&gt;与依赖于联合整体嵌入的前人方法不同，DisProtEdit明确分离语义因素，实现模块化和可解释的控制。&lt;h4&gt;目的&lt;/h4&gt;构建一个可控的蛋白质编辑框架，提供对蛋白质结构和功能的模块化和可解释的控制。&lt;h4&gt;方法&lt;/h4&gt;构建了SwissProtDis，一个大规模的多模态数据集，其中每个蛋白质序列都配对两个文本描述，一个用于结构，一个用于功能。DisProtEdit通过对齐和一致性目标对齐蛋白质和文本嵌入，同时通过解耦损失促进结构和功能语义的独立性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，DisProtEdit在蛋白质编辑和表示学习基准测试中与现有方法具有竞争力，同时提供了改进的可解释性和可控性。在新的多属性编辑基准测试中，模型实现了高达61.7%的双击成功率，突出了其在协调同时结构和功能编辑方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;DisProtEdit是一个有效的蛋白质编辑框架，能够同时控制和解释蛋白质的结构和功能编辑。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce DisProtEdit, a controllable protein editing framework thatleverages dual-channel natural language supervision to learn disentangledrepresentations of structural and functional properties. Unlike priorapproaches that rely on joint holistic embeddings, DisProtEdit explicitlyseparates semantic factors, enabling modular and interpretable control. Tosupport this, we construct SwissProtDis, a large-scale multimodal dataset whereeach protein sequence is paired with two textual descriptions, one forstructure and one for function, automatically decomposed using a large languagemodel. DisProtEdit aligns protein and text embeddings using alignment anduniformity objectives, while a disentanglement loss promotes independencebetween structural and functional semantics. At inference time, protein editingis performed by modifying one or both text inputs and decoding from the updatedlatent representation. Experiments on protein editing and representationlearning benchmarks demonstrate that DisProtEdit performs competitively withexisting methods while providing improved interpretability and controllability.On a newly constructed multi-attribute editing benchmark, the model achieves aboth-hit success rate of up to 61.7%, highlighting its effectiveness incoordinating simultaneous structural and functional edits.</description>
      <author>example@mail.com (Max Ku, Sun Sun, Hongyu Guo, Wenhu Chen)</author>
      <guid isPermaLink="false">2506.14853v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable representation learning of quantum data enabled by probabilistic variational autoencoders</title>
      <link>http://arxiv.org/abs/2506.11982v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Main text 10 pages, total document 16 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;可解释机器学习正在迅速成为科学发现的关键工具，变分自动编码器（VAEs）在提取输入数据的隐藏物理特征方面显示出潜力，但需要考虑量子数据的随机性和复杂相关性。&lt;h4&gt;背景&lt;/h4&gt;VAEs在无监督和没有系统先验知识的情况下提取输入数据的隐藏物理特征，但在处理量子数据时，需要考虑其概率性质。&lt;h4&gt;目的&lt;/h4&gt;改进VAEs以学习物理上有意义的潜在表示。&lt;h4&gt;方法&lt;/h4&gt;通过引入能够忠实复制量子状态的解码器和针对此任务的概率损失，对VAEs进行关键修改。&lt;h4&gt;主要发现&lt;/h4&gt;在标准方法失效的情况下，这种方法学习的表示仍然是有意义和可解释的，并在实验数据中自主揭示相结构。&lt;h4&gt;结论&lt;/h4&gt;这种改进的VAEs是一个无监督和可解释的工具，可以用于研究量子系统。&lt;h4&gt;翻译&lt;/h4&gt;可解释机器学习正在迅速成为科学发现的关键工具。在现有的方法中，变分自动编码器（VAEs）在提取某些输入数据的隐藏物理特征方面显示出前景，无需监督和系统研究的先验知识。然而，VAEs创建有意义的可解释表示的能力依赖于它们对输入潜在概率分布的准确近似。当处理量子数据时，VAEs必须因此考虑到其固有的随机性和复杂相关性。虽然VAEs以前已经应用于量子数据，但它们通常忽略了其概率性质，阻碍了有意义的物理描述符的提取。在这里，我们证明了两个关键修改使得VAEs能够学习物理上有意义的潜在表示：一个能够忠实复制量子状态的解码器以及一个针对此任务的概率损失。使用基准量子自旋模型，我们确定了标准方法失败而我们的方法学习的表示仍然有意义和可解释的领域。应用于里德堡原子阵列的实验数据，该模型在无需访问先验标签、哈密顿细节或有关相关序参数知识的情况下自主揭示相结构，突出了其作为无监督和可解释工具研究量子系统的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpretable machine learning is rapidly becoming a crucial tool forscientific discovery. Among existing approaches, variational autoencoders(VAEs) have shown promise in extracting the hidden physical features of someinput data, with no supervision nor prior knowledge of the system at study.Yet, the ability of VAEs to create meaningful, interpretable representationsrelies on their accurate approximation of the underlying probabilitydistribution of their input. When dealing with quantum data, VAEs must henceaccount for its intrinsic randomness and complex correlations. While VAEs havebeen previously applied to quantum data, they have often neglected itsprobabilistic nature, hindering the extraction of meaningful physicaldescriptors. Here, we demonstrate that two key modifications enable VAEs tolearn physically meaningful latent representations: a decoder capable offaithfully reproduce quantum states and a probabilistic loss tailored to thistask. Using benchmark quantum spin models, we identify regimes where standardmethods fail while the representations learned by our approach remainmeaningful and interpretable. Applied to experimental data from Rydberg atomarrays, the model autonomously uncovers the phase structure without access toprior labels, Hamiltonian details, or knowledge of relevant order parameters,highlighting its potential as an unsupervised and interpretable tool for thestudy of quantum systems.</description>
      <author>example@mail.com (Paulin de Schoulepnikoff, Gorka Muñoz-Gil, Hendrik Poulsen Nautrup, Hans J. Briegel)</author>
      <guid isPermaLink="false">2506.11982v2</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Next-Generation Conflict Forecasting: Unleashing Predictive Patterns through Spatiotemporal Learning</title>
      <link>http://arxiv.org/abs/2506.14817v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  33 pages, 9 figures, 3 tables. Presented at workshops hosted by PRIO,  AFK (German Association for Peace and Conflict Studies), CCEW (Bundeswehr  University Munich), Uppsala University, SODAS (University of Copenhagen) and  in briefings with UN agencies including UNIDIR, OCHA, and FAO&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型神经网络架构，用于预测不同类型的暴力事件，包括基于国家的、非国家的和单方面的暴力，并在次国家（优先网格-月）层面上，提前36个月进行预测。&lt;h4&gt;背景&lt;/h4&gt;预测高空间和时间分辨率的暴力冲突对研究人员和政策制定者来说是一个核心挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够预测不同类型暴力事件的新方法。&lt;h4&gt;方法&lt;/h4&gt;该模型基于蒙特卡洛Dropout长短期记忆（LSTM）U-Net架构，结合卷积层来捕捉空间依赖性，以及循环结构来模拟时间动态。模型不需要手动特征工程，仅依赖于历史冲突数据。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在所有任务中都达到了最先进的性能，并生成近似预测后验分布来量化预测不确定性。&lt;h4&gt;结论&lt;/h4&gt;该模型不仅预测性能卓越，而且具有高度的可扩展性，可以轻松集成额外的数据源，并联合预测辅助变量。这使得它成为早期预警系统、人道主义响应规划和基于证据的和平建设倡议的有前途的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在高空间和时间分辨率上预测暴力冲突仍然是研究人员和政策制定者面临的核心挑战。本研究提出了一种新型神经网络架构，用于预测三种不同类型的暴力——基于国家的、非国家的和单方面的暴力——在次国家（优先网格-月）层面上，提前36个月进行预测。该模型同时执行分类和回归任务，产生未来事件的概率估计和预期幅度。它在所有任务中都实现了最先进的性能，并生成近似预测后验分布来量化预测不确定性。该架构基于蒙特卡洛Dropout长短期记忆（LSTM）U-Net，结合卷积层来捕捉空间依赖性，以及循环结构来模拟时间动态。与许多现有方法不同，它不需要手动特征工程，完全依赖于历史冲突数据。这种设计使模型能够自主学习暴力冲突背后的复杂时空模式。除了实现最先进的预测性能外，该模型还具有高度的可扩展性：它可以轻松集成额外的数据源，并联合预测辅助变量。这些能力使其成为早期预警系统、人道主义响应规划和基于证据的和平建设倡议的有前途的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Forecasting violent conflict at high spatial and temporal resolution remainsa central challenge for both researchers and policymakers. This study presentsa novel neural network architecture for forecasting three distinct types ofviolence -- state-based, non-state, and one-sided -- at the subnational(priogrid-month) level, up to 36 months in advance. The model jointly performsclassification and regression tasks, producing both probabilistic estimates andexpected magnitudes of future events. It achieves state-of-the-art performanceacross all tasks and generates approximate predictive posterior distributionsto quantify forecast uncertainty.  The architecture is built on a Monte Carlo Dropout Long Short-Term Memory(LSTM) U-Net, integrating convolutional layers to capture spatial dependencieswith recurrent structures to model temporal dynamics. Unlike many existingapproaches, it requires no manual feature engineering and relies solely onhistorical conflict data. This design enables the model to autonomously learncomplex spatiotemporal patterns underlying violent conflict.  Beyond achieving state-of-the-art predictive performance, the model is alsohighly extensible: it can readily integrate additional data sources and jointlyforecast auxiliary variables. These capabilities make it a promising tool forearly warning systems, humanitarian response planning, and evidence-basedpeacebuilding initiatives.</description>
      <author>example@mail.com (Simon P. von der Maase)</author>
      <guid isPermaLink="false">2506.14817v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Extending Spike-Timing Dependent Plasticity to Learning Synaptic Delays</title>
      <link>http://arxiv.org/abs/2506.14984v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Repository containing the source code used to generate the results is  available at: https://github.com/mdominijanni/dsstdp-results&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的学习方法，旨在同时学习突触连接强度和延迟，通过扩展尖峰时间依赖性可塑性（STDP）方法，并与现有方法进行了比较，结果显示该方法在各种测试场景中均表现出优异的性能。&lt;h4&gt;背景&lt;/h4&gt;突触延迟在生物神经元网络中发挥着关键作用，在哺乳动物的学习过程中观察到其调节。尽管突触延迟在仿生计算领域中具有重要意义，但在脉冲神经网络（SNNs）的模拟中却很少被纳入。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的学习方法，用于同时学习突触连接强度和延迟，并验证其有效性。&lt;h4&gt;方法&lt;/h4&gt;通过扩展尖峰时间依赖性可塑性（STDP）方法，引入了一种新的学习规则，并在一个广泛使用的SNN分类模型中进行了验证，该模型使用无监督学习进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;新的方法在各种测试场景中均表现出优于现有方法的性能，并揭示了突触效力和延迟之间的相互作用。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地同时学习了突触连接强度和延迟，为神经形态计算领域提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：突触延迟在生物神经元网络中扮演着至关重要的角色，在哺乳动物的学习过程中观察到它们的调节作用。在神经形态计算领域，尽管脉冲神经网络（SNNs）旨在比传统的神经网络更接近于生物仿真，但在它们的模拟中很少考虑突触延迟。我们提出了一种新的学习规则，通过扩展尖峰时间依赖性可塑性（STDP），一种通常用于学习突触权重的赫布方法，以同时学习突触连接强度和延迟。我们通过扩展一个广泛使用的用于分类的SNN模型，该模型使用无监督学习进行训练，来验证我们的方法。然后，我们通过将其与另一种现有方法进行了比较，该方法旨在共同学习突触权重和延迟，以及与没有突触延迟的STDP进行比较，证明了我们新方法的有效性。结果证明，我们提出的方法在各种测试场景中均能实现优越的性能。此外，我们的实验结果揭示了突触效力和延迟之间的相互作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Synaptic delays play a crucial role in biological neuronal networks, wheretheir modulation has been observed in mammalian learning processes. In therealm of neuromorphic computing, although spiking neural networks (SNNs) aim toemulate biology more closely than traditional artificial neural networks do,synaptic delays are rarely incorporated into their simulation. We introduce anovel learning rule for simultaneously learning synaptic connection strengthsand delays, by extending spike-timing dependent plasticity (STDP), a Hebbianmethod commonly used for learning synaptic weights. We validate our approach byextending a widely-used SNN model for classification trained with unsupervisedlearning. Then we demonstrate the effectiveness of our new method by comparingit against another existing methods for co-learning synaptic weights and delaysas well as against STDP without synaptic delays. Results demonstrate that ourproposed method consistently achieves superior performance across a variety oftest scenarios. Furthermore, our experimental results yield insight into theinterplay between synaptic efficacy and delay.</description>
      <author>example@mail.com (Marissa Dominijanni, Alexander Ororbia, Kenneth W. Regan)</author>
      <guid isPermaLink="false">2506.14984v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Targeted Lexical Injection: Unlocking Latent Cross-Lingual Alignment in Lugha-Llama via Early-Layer LoRA Fine-Tuning</title>
      <link>http://arxiv.org/abs/2506.15415v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 3 figures, 2 tables. Research on parameter-efficient  fine-tuning (PEFT) for low-resource languages (Swahili). Investigates  cross-lingual lexical alignment in Lugha-Llama using LoRA and contrastive  learning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了针对低资源语言（LRLs）的Targeted Lexical Injection（TLI）方法，通过优化早期层的嵌入来提升大型语言模型在低资源语言中的词汇对齐能力。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在低资源语言上的表现通常不佳，因为数据稀缺且在预训练中代表性不足，导致跨语言词汇对齐困难。&lt;h4&gt;目的&lt;/h4&gt;提出TLI方法，以解决低资源语言模型中词汇对齐的问题，特别是针对翻译和跨语言信息检索等任务。&lt;h4&gt;方法&lt;/h4&gt;TLI方法利用低秩自适应（LoRA）和对比学习目标，针对早期层的嵌入进行微调，以改善词汇对齐。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，TLI显著提高了623个训练的斯瓦希里语-英语词汇对的输出级词汇对齐，平均余弦相似度从0.3211提升到0.4113（+28.08%），并且这些改进在63个未见过的控制词汇对中也表现出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;TLI增强了模型在低资源语言中保留和传播早期层跨语言知识的能力，为提高词汇对齐提供了一种参数高效且有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为目标词汇注入（Targeted Lexical Injection，TLI）的新颖高效微调方法，旨在解决大型语言模型在低资源语言（LRLs）中词汇对齐能力不足的问题。研究发现，TLI显著提高了模型在斯瓦希里语-英语词汇对上的输出级词汇对齐，并在未见过的词汇对上表现出良好的泛化能力，从而为提高低资源语言模型中的词汇对齐提供了有效策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have demonstrated remarkable capabilities, yettheir performance in low-resource languages (LRLs), such as Swahili, often lagsdue to data scarcity and underrepresentation in pre-training. A key challengeis achieving robust cross-lingual lexical alignment, crucial for tasks liketranslation and cross-lingual information retrieval. This paper introducesTargeted Lexical Injection (TLI), a novel and efficient fine-tuning approach.We first demonstrate that Lugha-Llama-8B-wura, a Swahili-centric LLM, exhibitsstrong, near-perfect lexical alignment for Swahili-English word pairs in itsearly internal layers (specifically Layer 2, with ~0.99998 average cosinesimilarity based on a pilot study), a capability not fully reflected in itsfinal output representations (baseline ~0.32 similarity on our evaluation set).TLI leverages this insight by using Low-Rank Adaptation (LoRA) and acontrastive learning objective to fine-tune the model, specifically targetingembeddings from this empirically identified optimal early layer. Ourexperiments show that TLI significantly improves the output-level lexicalalignment for 623 trained Swahili-English word pairs, increasing average cosinesimilarity from 0.3211 to 0.4113 (+28.08%, p &lt; 1.33 x 10^-240). Moreimportantly, these improvements generalize remarkably well to 63 unseen controlword pairs, with similarity increasing from 0.3143 to 0.4033 (+28.32%, p &lt; 7.17x 10^-27). These findings suggest TLI enhances the model's ability to preserveand propagate its inherent early-layer cross-lingual knowledge, offering aparameter-efficient and effective strategy for improving lexical alignment inLRL-focused LLMs.</description>
      <author>example@mail.com (Stanley Ngugi)</author>
      <guid isPermaLink="false">2506.15415v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models</title>
      <link>http://arxiv.org/abs/2506.15220v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为video-SALMONN 2的先进音频-视觉大型语言模型，用于通过定向偏好优化（DPO）增强视频（配对音频）字幕生成。该模型通过多轮DPO（MrDPO）方法显著提高了字幕准确率，并在视频字幕任务中超越了GPT-4o和Gemini-1.5-Pro等领先模型。&lt;h4&gt;背景&lt;/h4&gt;视频包含大量信息，生成详细且准确的自然语言描述是视频理解的关键。&lt;h4&gt;目的&lt;/h4&gt;提高视频字幕生成的准确性和完整性。&lt;h4&gt;方法&lt;/h4&gt;video-SALMONN 2模型采用低秩自适应（LoRA）和定向偏好优化（DPO）。提出新的评估指标，并使用DPO优化。采用多轮DPO（MrDPO）方法，包括定期更新DPO参考模型，合并和重新初始化LoRA模块作为参数更新的代理，以及结合真实视频字幕的指导来稳定过程。&lt;h4&gt;主要发现&lt;/h4&gt;MrDPO显著提高了video-SALMONN 2的字幕准确率，将字幕错误率降低了28%。video-SALMONN 2模型在视频字幕任务中超越了GPT-4o和Gemini-1.5-Pro等模型，同时在广泛使用的视频问答基准测试中保持了与最先进模型相当的性能。&lt;h4&gt;结论&lt;/h4&gt;video-SALMONN 2模型在视频字幕生成方面取得了显著进展，具有高度竞争力和实用性。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents video-SALMONN 2, an advanced audio-visual large language model with low-rank adaptation (LoRA) designed for enhanced video (with paired audio) captioning through directed preference optimization (DPO). We propose new metrics to evaluate the completeness and accuracy of video descriptions, which are optimized using DPO. To further improve training, we propose a novel multi-round DPO (MrDPO) approach, which involves periodically updating the DPO reference model, merging and re-initializing the LoRA module as a proxy for parameter updates after each training round (1,000 steps), and incorporating guidance from ground-truth video captions to stabilize the process. Experimental results show that MrDPO significantly enhances video-SALMONN 2's captioning accuracy, reducing the captioning error rates by 28%. The final video-SALMONN 2 model, with just 7 billion parameters, surpasses leading models such as GPT-4o and Gemini-1.5-Pro in video captioning tasks, while maintaining highly competitive performance to the state-of-the-art on widely used video question-answering benchmarks among models of similar size. Codes are available at https://github.com/bytedance/video-SALMONN-2.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Videos contain a wealth of information, and generating detailed and accuratedescriptions in natural language is a key aspect of video understanding. Inthis paper, we present video-SALMONN 2, an advanced audio-visual large languagemodel (LLM) with low-rank adaptation (LoRA) designed for enhanced video (withpaired audio) captioning through directed preference optimisation (DPO). Wepropose new metrics to evaluate the completeness and accuracy of videodescriptions, which are optimised using DPO. To further improve training, wepropose a novel multi-round DPO (MrDPO) approach, which involves periodicallyupdating the DPO reference model, merging and re-initialising the LoRA moduleas a proxy for parameter updates after each training round (1,000 steps), andincorporating guidance from ground-truth video captions to stabilise theprocess. Experimental results show that MrDPO significantly enhancesvideo-SALMONN 2's captioning accuracy, reducing the captioning error rates by28\%. The final video-SALMONN 2 model, with just 7 billion parameters,surpasses leading models such as GPT-4o and Gemini-1.5-Pro in video captioningtasks, while maintaining highly competitive performance to the state-of-the-arton widely used video question-answering benchmarks among models of similarsize. Codes are available at\href{https://github.com/bytedance/video-SALMONN-2}{https://github.com/bytedance/video-SALMONN-2}.</description>
      <author>example@mail.com (Changli Tang, Yixuan Li, Yudong Yang, Jimin Zhuang, Guangzhi Sun, Wei Li, Zejun Ma, Chao Zhang)</author>
      <guid isPermaLink="false">2506.15220v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>ConLID: Supervised Contrastive Learning for Low-Resource Language Identification</title>
      <link>http://arxiv.org/abs/2506.15304v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to EMNLP&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的监督对比学习方法，用于学习低资源语言的领域不变表示，以解决低资源语言在语言识别（LID）任务中的性能问题。&lt;h4&gt;背景&lt;/h4&gt;在从网络爬取中整理多语言LLM预训练语料库时，语言识别是一个关键步骤。许多关于LID模型训练的研究集中在收集多样化的训练数据以提高性能，但低资源语言通常由于限于单一领域的数据（如圣经）而表现不佳。&lt;h4&gt;目的&lt;/h4&gt;为了解决类别不平衡和偏差问题，提出了一种新的监督对比学习方法。&lt;h4&gt;方法&lt;/h4&gt;通过广泛的分析，证明了该方法能够提高低资源语言在域外数据上的LID性能，提高了3.2%，展示了其在增强LID模型方面的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的监督对比学习方法能够提高低资源语言在域外数据上的LID性能，提高了3.2%。&lt;h4&gt;结论&lt;/h4&gt;该方法在提高低资源语言LID模型性能方面是有效的。&lt;h4&gt;翻译&lt;/h4&gt;Language identification (LID) is a critical step in curating multilingual LLMpretraining corpora from web crawls. While many studies on LID model training focus on collecting diverse training data to improve performance, low-resourcelanguages -- often limited to single-domain data, such as the Bible -- continueto perform poorly. To resolve these class imbalance and bias issues, we proposea novel supervised contrastive learning (SCL) approach to learndomain-invariant representations for low-resource languages. Through anextensive analysis, we show that our approach improves LID performance onout-of-domain data for low-resource languages by 3.2%, demonstrating itseffectiveness in enhancing LID models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Language identification (LID) is a critical step in curating multilingual LLMpretraining corpora from web crawls. While many studies on LID model trainingfocus on collecting diverse training data to improve performance, low-resourcelanguages -- often limited to single-domain data, such as the Bible -- continueto perform poorly. To resolve these class imbalance and bias issues, we proposea novel supervised contrastive learning (SCL) approach to learndomain-invariant representations for low-resource languages. Through anextensive analysis, we show that our approach improves LID performance onout-of-domain data for low-resource languages by 3.2%, demonstrating itseffectiveness in enhancing LID models.</description>
      <author>example@mail.com (Negar Foroutan, Jakhongir Saydaliev, Ye Eun Kim, Antoine Bosselut)</author>
      <guid isPermaLink="false">2506.15304v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>A Unified Graph-based Framework for Scalable 3D Tree Reconstruction and Non-Destructive Biomass Estimation from Point Clouds</title>
      <link>http://arxiv.org/abs/2506.15577v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages,19 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于大规模点云的端到端处理，以实现森林地上生物量（AGB）的无损估算，从而为碳储存评估和可持续森林管理提供支持。&lt;h4&gt;背景&lt;/h4&gt;估算森林地上生物量对于评估碳储存和促进可持续森林管理至关重要。目前的定量结构模型（QSM）方法在处理大规模数据时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种新的框架，通过创新的基于图的管道，实现对大规模点云的端到端处理，从而提高森林地上生物量估算的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法通过特定的图操作，包括路径和抽象化，实现树木分割、叶木分离和三维骨骼重建，并在不同叶条件、空间尺度和数据源的数据集上进行了全面验证。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在具有挑战性的条件下表现出强大的性能，尤其是在叶覆盖条件下（相对误差约为20%）和低密度基于无人机激光扫描（ULS）数据集（部分覆盖，相对误差约为30%）。&lt;h4&gt;结论&lt;/h4&gt;该框架提供了一种稳健且可扩展的解决方案，显著降低了对于专业化预处理工具的依赖，并将ULS确立为TLS的可行替代品。这是第一个能够实现操作规模无缝端到端三维树木重建的方法，显著提高了基于QSM的AGB估算的可行性，为森林清查和气候变化研究开辟了更广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要：估算森林地上生物量（AGB）对于评估碳储存和促进可持续森林管理至关重要。定量结构模型（QSM）提供了一种通过三维树木结构重建进行AGB估算的非破坏性方法。然而，目前的QSM方法面临着显著的局限性，因为它们主要设计用于单个树木，依赖于来自地面激光扫描（TLS）的高质量点云数据，并且还需要多个预处理步骤，这阻碍了可扩展性和实际部署。本研究提出了一种新的统一框架，该框架通过创新的基于图的管道实现了大规模点云的端到端处理。所提出的方法通过专门的图操作，包括路径和抽象化以进行树木拓扑推理，无缝地集成了树木分割、叶木分离和三维骨骼重建。在具有不同叶条件（叶在/叶落）、空间尺度（树木和地块水平）和数据来源（TLS和基于无人机激光扫描，ULS）的数据集上进行了全面的验证。实验结果证明了在具有挑战性的条件下具有强大的性能，特别是在叶在的情况下（相对误差约为20%）和低密度ULS数据集（部分覆盖，相对误差约为30%）。这些发现表明，所提出的框架提供了一种稳健且可扩展的解决方案，用于大规模、非破坏性AGB估算。它显著降低了对于专业化预处理工具的依赖，并将ULS确立为TLS的可行替代品。据我们所知，这是第一个能够在操作规模上实现无缝端到端三维树木重建的方法。这一进步极大地提高了基于QSM的AGB估算的可行性，为森林清查和气候变化研究的更广泛应用铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Estimating forest above-ground biomass (AGB) is crucial for assessing carbonstorage and supporting sustainable forest management. Quantitative StructuralModel (QSM) offers a non-destructive approach to AGB estimation through 3D treestructural reconstruction. However, current QSM methods face significantlimitations, as they are primarily designed for individual trees,depend onhigh-quality point cloud data from terrestrial laser scanning (TLS), and alsorequire multiple pre-processing steps that hinder scalability and practicaldeployment. This study presents a novel unified framework that enablesend-to-end processing of large-scale point clouds using an innovativegraph-based pipeline. The proposed approach seamlessly integrates treesegmentation,leaf-wood separation and 3D skeletal reconstruction throughdedicated graph operations including pathing and abstracting for tree topologyreasoning. Comprehensive validation was conducted on datasets with varying leafconditions (leaf-on and leaf-off), spatial scales (tree- and plot-level), anddata sources (TLS and UAV-based laser scanning, ULS). Experimental resultsdemonstrate strong performance under challenging conditions, particularly inleaf-on scenarios (~20% relative error) and low-density ULS datasets withpartial coverage (~30% relative error). These findings indicate that theproposed framework provides a robust and scalable solution for large-scale,non-destructive AGB estimation. It significantly reduces dependency onspecialized pre-processing tools and establishes ULS as a viable alternative toTLS. To our knowledge, this is the first method capable of enabling seamless,end-to-end 3D tree reconstruction at operational scales. This advancementsubstantially improves the feasibility of QSM-based AGB estimation, paving theway for broader applications in forest inventory and climate change research.</description>
      <author>example@mail.com (Di Wang, Shi Li)</author>
      <guid isPermaLink="false">2506.15577v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing point cloud analysis via neighbor aggregation correction based on cross-stage structure correlation</title>
      <link>http://arxiv.org/abs/2506.15160v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 papes, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PDSA（Point Distribution Set Abstraction）的点云分析模块，旨在提高点云数据的聚合效率和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;点云分析是许多下游任务的基础，其中聚合局部结构是理解点云数据的关键。然而，现有的方法在利用三维相对坐标进行邻域聚合时，存在无关点干扰和特征层次结构逼近问题。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法的局限性，提高点云数据聚合的效率和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;PDSA模块利用高维空间中的相关性来校正聚合过程中的特征分布，通过轻量级的跨阶段结构描述符区分点间相关性，并通过长距离建模减少邻域特征矩阵的方差，提高类别可分性。此外，引入了关键点机制以优化计算开销。&lt;h4&gt;主要发现&lt;/h4&gt;在语义分割和分类任务上的实验结果表明，PDSA方法在参数成本较低的情况下实现了显著的性能提升，并且通过消融和可视化结果证明了方法的有效性和合理性。&lt;h4&gt;结论&lt;/h4&gt;PDSA模块能够有效提高点云数据聚合的效率和鲁棒性，并具有良好的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：点云分析是许多下游任务的基础，其中聚合局部结构是理解点云数据的基础。虽然许多工作使用三维相对坐标进行邻域聚合，但由于局部坐标的限制，存在无关点干扰和特征层次结构逼近问题。尽管一些工作通过显式建模跨阶段结构来细化空间描述来解决这个问题，但这些基于直接几何结构编码的增强方法存在计算开销高和噪声敏感的问题。为了克服这些问题，我们提出了点分布集抽象模块（PDSA），该模块利用高维空间中的相关性来校正聚合过程中的特征分布，从而提高了计算效率和鲁棒性。PDSA基于轻量级的跨阶段结构描述符区分点间相关性，并通过减少邻域特征矩阵的方差和通过长距离建模增加类别可分性来增强结构同质性。此外，我们引入了一个关键点机制来优化计算开销。基于不同基线在语义分割和分类任务上的实验结果验证了我们提出的方法的泛化能力，并且在参数成本较低的情况下实现了显著的性能提升。相应的消融和可视化结果证明了我们方法的有效性和合理性。代码和训练权重可在以下链接获取：https://github.com/AGENT9717/PointDistribution&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud analysis is the cornerstone of many downstream tasks, among whichaggregating local structures is the basis for understanding point cloud data.While numerous works aggregate neighbor using three-dimensional relativecoordinates, there are irrelevant point interference and feature hierarchy gapproblems due to the limitation of local coordinates. Although some worksaddress this limitation by refining spatial description though explicitmodeling of cross-stage structure, these enhancement methods based on directgeometric structure encoding have problems of high computational overhead andnoise sensitivity. To overcome these problems, we propose the PointDistribution Set Abstraction module (PDSA) that utilizes the correlation in thehigh-dimensional space to correct the feature distribution during aggregation,which improves the computational efficiency and robustness. PDSA distinguishesthe point correlation based on a lightweight cross-stage structural descriptor,and enhances structural homogeneity by reducing the variance of the neighborfeature matrix and increasing classes separability though long-distancemodeling. Additionally, we introducing a key point mechanism to optimize thecomputational overhead. The experimental result on semantic segmentation andclassification tasks based on different baselines verify the generalization ofthe method we proposed, and achieve significant performance improvement withless parameter cost. The corresponding ablation and visualization resultsdemonstrate the effectiveness and rationality of our method. The code andtraining weight is available at: https://github.com/AGENT9717/PointDistribution</description>
      <author>example@mail.com (Jiaqi Shi, Jin Xiao, Xiaoguang Hu, Boyang Song, Hao Jiang, Tianyou Chen, Baochang Zhang)</author>
      <guid isPermaLink="false">2506.15160v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>AdaVideoRAG: Omni-Contextual Adaptive Retrieval-Augmented Efficient Long Video Understanding</title>
      <link>http://arxiv.org/abs/2506.13589v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AdaVideoRAG的新框架，用于解决多模态大型语言模型在处理长视频时的挑战，通过动态调整检索粒度来提高效率。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型在处理长视频时面临固定上下文窗口和弱长期依赖建模的问题，现有的视频检索增强生成方法使用静态检索策略，导致简单查询效率低下和复杂任务信息丢失。&lt;h4&gt;目的&lt;/h4&gt;提出AdaVideoRAG框架，旨在解决上述问题，提高长视频理解的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;AdaVideoRAG框架使用轻量级意图分类器动态调整检索粒度，并采用Omni-Knowledge Indexing模块构建包含文本、视觉特征和语义图的分层数据库，实现跨任务的资源优化分配。同时，引入了HiVU基准测试进行综合评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AdaVideoRAG在长视频理解方面提高了效率和准确性，并且能够无缝集成到现有的多模态大型语言模型中。&lt;h4&gt;结论&lt;/h4&gt;AdaVideoRAG为视频分析中的自适应检索建立了一个新的范式，并将代码开源在https://github.com/xzc-zju/AdaVideoRAG上。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel framework called AdaVideoRAG to address the challenges of multimodal large language models in processing long videos, which dynamically adjusts the retrieval granularity to improve efficiency.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) struggle with long videos due tofixed context windows and weak long-term dependency modeling. ExistingRetrieval-Augmented Generation (RAG) methods for videos use static retrievalstrategies, leading to inefficiencies for simple queries and information lossfor complex tasks. To address this, we propose AdaVideoRAG, a novel frameworkthat dynamically adapts retrieval granularity based on query complexity using alightweight intent classifier. Our framework employs an Omni-Knowledge Indexingmodule to build hierarchical databases from text (captions, ASR, OCR), visualfeatures, and semantic graphs, enabling optimal resource allocation acrosstasks. We also introduce the HiVU benchmark for comprehensive evaluation.Experiments demonstrate improved efficiency and accuracy for long-videounderstanding, with seamless integration into existing MLLMs. AdaVideoRAGestablishes a new paradigm for adaptive retrieval in video analysis. Codes willbe open-sourced at https://github.com/xzc-zju/AdaVideoRAG.</description>
      <author>example@mail.com (Zhucun Xue, Jiangning Zhang, Xurong Xie, Yuxuan Cai, Yong Liu, Xiangtai Li, Dacheng Tao)</author>
      <guid isPermaLink="false">2506.13589v2</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>GRAM: A Generative Foundation Reward Model for Reward Generalization</title>
      <link>http://arxiv.org/abs/2506.14175v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于生成模型的奖励模型训练方法，结合无标签和有标签数据，通过大规模无监督学习和监督学习进行训练，实现了在多个任务上的性能提升。&lt;h4&gt;背景&lt;/h4&gt;传统的奖励模型在大型语言模型中对齐中扮演重要角色，但通常作为判别模型训练，依赖于标注的人类偏好数据。&lt;h4&gt;目的&lt;/h4&gt;探索利用无标签和有标签数据训练奖励模型的方法，提高模型在多个任务上的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;开发了一种生成奖励模型，首先通过大规模无监督学习进行训练，然后通过监督学习进行微调。同时，通过标签平滑优化正则化成对排名损失。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法将生成模型和判别模型链接到同一类训练目标下，并证明了通过标签平滑实际上是在优化正则化成对排名损失。&lt;h4&gt;结论&lt;/h4&gt;该模型可以作为基础奖励模型，应用于广泛的任务，无需或只需少量微调，在多个任务上实现显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;In aligning large language models (LLMs), reward models have played an important role, but are standardly trained as discriminative models and rely only on labeled human preference data. In this paper, we explore methods that train reward models using both unlabeled and labeled data. Building on the generative models in LLMs, we develop a generative reward model that is first trained via large-scale unsupervised learning and then fine-tuned via supervised learning. We also show that by using label smoothing, we are in fact optimizing a regularized pairwise ranking loss. This result, in turn, provides a new view of training reward models, which links generative models and discriminative models under the same class of training objectives. The outcome of these techniques is a foundation reward model, which can be applied to a wide range of tasks with little or no further fine-tuning effort. Extensive experiments show that this model generalizes well across several tasks, including response ranking, reinforcement learning from human feedback, and task adaptation with fine-tuning, achieving significant performance improvements over several strong baseline models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In aligning large language models (LLMs), reward models have played animportant role, but are standardly trained as discriminative models and relyonly on labeled human preference data. In this paper, we explore methods thattrain reward models using both unlabeled and labeled data. Building on thegenerative models in LLMs, we develop a generative reward model that is firsttrained via large-scale unsupervised learning and then fine-tuned viasupervised learning. We also show that by using label smoothing, we are in factoptimizing a regularized pairwise ranking loss. This result, in turn, providesa new view of training reward models, which links generative models anddiscriminative models under the same class of training objectives. The outcomeof these techniques is a foundation reward model, which can be applied to awide range of tasks with little or no further fine-tuning effort. Extensiveexperiments show that this model generalizes well across several tasks,including response ranking, reinforcement learning from human feedback, andtask adaptation with fine-tuning, achieving significant performanceimprovements over several strong baseline models.</description>
      <author>example@mail.com (Chenglong Wang, Yang Gan, Yifu Huo, Yongyu Mu, Qiaozhi He, Murun Yang, Bei Li, Tong Xiao, Chunliang Zhang, Tongran Liu, Jingbo Zhu)</author>
      <guid isPermaLink="false">2506.14175v2</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Multi-Positive Contrastive Learning for Patent Image Retrieval</title>
      <link>http://arxiv.org/abs/2506.13496v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 3 figures, Accepted as a short paper at the 6th Workshop on  Patent Text Mining and Semantic Technologies (PatentSemTech 2025), co-located  with SIGIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种利用Locarno国际分类系统（LIC）的层次结构来提高专利图像检索系统性能的方法。&lt;h4&gt;背景&lt;/h4&gt;专利图像是传达专利创新信息的技术图纸，专利图像检索系统在处理大量数据集时面临挑战，需要针对领域特定进行高效调整。&lt;h4&gt;目的&lt;/h4&gt;提高专利图像检索的准确性，特别是在处理复杂的语义信息和技术细节时。&lt;h4&gt;方法&lt;/h4&gt;引入了一种层次多正对比损失，通过利用LIC的分类体系，在检索过程中诱导层级关系。方法为每个批次的专利图像分配多个基于层级分类的相似度评分的正对。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在DeepPatent2数据集上提高了检索效果，并且对低参数模型有效，这些模型计算资源需求低，可以在硬件受限的环境中部署。&lt;h4&gt;结论&lt;/h4&gt;该方法通过利用层级结构增强了专利图像检索的性能，适用于资源受限的环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Patent images are technical drawings that convey information about a patent'sinnovation. Patent image retrieval systems aim to search in vast collectionsand retrieve the most relevant images. Despite recent advances in informationretrieval, patent images still pose significant challenges due to theirtechnical intricacies and complex semantic information, requiring efficientfine-tuning for domain adaptation. Current methods neglect patents'hierarchical relationships, such as those defined by the Locarno InternationalClassification (LIC) system, which groups broad categories (e.g., "furnishing")into subclasses (e.g., "seats" and "beds") and further into specific patentdesigns. In this work, we introduce a hierarchical multi-positive contrastiveloss that leverages the LIC's taxonomy to induce such relations in theretrieval process. Our approach assigns multiple positive pairs to each patentimage within a batch, with varying similarity scores based on the hierarchicaltaxonomy. Our experimental analysis with various vision and multimodal modelson the DeepPatent2 dataset shows that the proposed method enhances theretrieval results. Notably, our method is effective with low-parameter models,which require fewer computational resources and can be deployed on environmentswith limited hardware.</description>
      <author>example@mail.com (Kshitij Kavimandan, Angelos Nalmpantis, Emma Beauxis-Aussalet, Robert-Jan Sips)</author>
      <guid isPermaLink="false">2506.13496v2</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>A theoretical framework for self-supervised contrastive learning for continuous dependent data</title>
      <link>http://arxiv.org/abs/2506.09785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对连续依赖数据的对比自监督学习方法，通过引入依赖感知的损失函数，提高了在时间域和时空域等依赖数据上的表现。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在计算机视觉领域表现出强大的学习能力，但其应用于依赖数据如时间域和时空域的研究还比较少。传统的对比自监督学习方法通常假设样本间存在语义独立性，这并不适用于具有复杂相关性的依赖数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的理论框架，用于针对连续依赖数据的对比自监督学习，使得最近的样本在语义上更加接近。&lt;h4&gt;方法&lt;/h4&gt;提出了两种可能的真实相似度度量——硬接近和软接近，并推导出一种分析形式的估计相似度矩阵，以适应样本间两种类型的接近。此外，引入了依赖感知的损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;在时间域和时空域的下游问题中验证了方法的有效性，方法名为DependentTS2Vec。在标准UEA和UCR基准测试中，该方法在准确性上分别提高了4.17%和2.08%。在涉及复杂时空模式的大旱分类任务中，该方法实现了7%更高的ROC-AUC分数。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在捕捉时空依赖方面非常有效，为自监督学习在依赖数据上的应用提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) has emerged as a powerful approach to learningrepresentations, particularly in the field of computer vision. However, itsapplication to dependent data, such as temporal and spatio-temporal domains,remains underexplored. Besides, traditional contrastive SSL methods oftenassume \emph{semantic independence between samples}, which does not hold fordependent data exhibiting complex correlations. We propose a novel theoreticalframework for contrastive SSL tailored to \emph{continuous dependent data},which allows the nearest samples to be semantically close to each other. Inparticular, we propose two possible \textit{ground truth similarity measures}between objects -- \emph{hard} and \emph{soft} closeness. Under it, we derivean analytical form for the \textit{estimated similarity matrix} thataccommodates both types of closeness between samples, thereby introducingdependency-aware loss functions. We validate our approach, \emph{DependentTS2Vec}, on temporal and spatio-temporal downstream problems. Given thedependency patterns presented in the data, our approach surpasses modern onesfor dependent data, highlighting the effectiveness of our theoreticallygrounded loss functions for SSL in capturing spatio-temporal dependencies.Specifically, we outperform TS2Vec on the standard UEA and UCR benchmarks, withaccuracy improvements of $4.17$\% and $2.08$\%, respectively. Furthermore, onthe drought classification task, which involves complex spatio-temporalpatterns, our method achieves a $7$\% higher ROC-AUC score.</description>
      <author>example@mail.com (Alexander Marusov, Alexander Yuhay, Alexey Zaytsev)</author>
      <guid isPermaLink="false">2506.09785v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
  <item>
      <title>Learning Augmented Graph $k$-Clustering</title>
      <link>http://arxiv.org/abs/2506.13533v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个通用的学习增强聚类框架，扩展了k-means算法在非欧几里得度量空间中的应用，并放宽了聚类规模限制，增强了学习增强聚类的理论基础和实际应用。&lt;h4&gt;背景&lt;/h4&gt;传统的k-means聚类在欧几里得度量空间中效果较好，但在处理复杂数据表示时应用受限。&lt;h4&gt;目的&lt;/h4&gt;将学习增强聚类推广到通用度量空间，使其能够应用于图结构和非欧几里得领域，并提高对不平衡或未知聚类分布数据集的适应性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种通用的学习增强聚类方法，并分析了其在通用度量空间下的查询复杂度。&lt;h4&gt;主要发现&lt;/h4&gt;该方法放宽了聚类规模限制，提高了数据集的灵活性；在指数时间假设下，证明了任何多项式时间算法达到(1+α)近似解需要大约Ω(k/α)次查询。&lt;h4&gt;结论&lt;/h4&gt;该框架强化了学习增强聚类的理论基础和实际应用，有助于解决传统方法与实际挑战之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;摘要：聚类是无监督学习中的一个基本任务。先前的研究主要集中在学习增强的k-means在欧几里得度量中的应用，限制了其在复杂数据表示中的应用。在本文中，我们将学习增强的k聚类推广到通用度量空间，使其能够应用于图结构和非欧几里得领域。我们的框架还放宽了限制性的聚类大小约束，为具有不平衡或未知聚类分布的数据集提供了更大的灵活性。此外，我们将查询复杂度的问题扩展到通用度量：在指数时间假设（ETH）下，我们表明任何多项式时间算法必须执行大约Ω(k/α)次查询才能达到(1+α)近似。这些贡献强化了学习增强聚类的理论基础和实践应用，弥合了传统方法与现实世界挑战之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Clustering is a fundamental task in unsupervised learning. Previous researchhas focused on learning-augmented $k$-means in Euclidean metrics, limiting itsapplicability to complex data representations. In this paper, we generalizelearning-augmented $k$-clustering to operate on general metrics, enabling itsapplication to graph-structured and non-Euclidean domains. Our framework alsorelaxes restrictive cluster size constraints, providing greater flexibility fordatasets with imbalanced or unknown cluster distributions. Furthermore, weextend the hardness of query complexity to general metrics: under theExponential Time Hypothesis (ETH), we show that any polynomial-time algorithmmust perform approximately $\Omega(k / \alpha)$ queries to achieve a $(1 +\alpha)$-approximation. These contributions strengthen both the theoreticalfoundations and practical applicability of learning-augmented clustering,bridging gaps between traditional methods and real-world challenges.</description>
      <author>example@mail.com (Chenglin Fan, Kijun Shin)</author>
      <guid isPermaLink="false">2506.13533v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable Causal Representation Learning for Biological Data in the Pathway Space</title>
      <link>http://arxiv.org/abs/2506.12439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025, 28 pages, 14 figures, 10 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为SENA-discrepancy-VAE的新模型，用于预测基因组变异和药物干预对细胞功能的影响，以提高治疗方法的改进。&lt;h4&gt;背景&lt;/h4&gt;理解基因功能和药物效果对于改善疗法至关重要。因果表示学习（CRL）是预测未知变异影响的潜在方法，但现有方法难以解释。&lt;h4&gt;目的&lt;/h4&gt;提出SENA-discrepancy-VAE模型，以解决现有CRL方法中模型不可解释的问题。&lt;h4&gt;方法&lt;/h4&gt;SENA-discrepancy-VAE基于CRL方法discrepancy-VAE，生成可解释的表示，其中每个潜在因素可以解释为学习到的生物过程活动的线性组合。模型包含一个编码器SENA-δ，用于高效计算和映射生物过程的活动水平到潜在因果因素。&lt;h4&gt;主要发现&lt;/h4&gt;SENA-discrepancy-VAE在预测未见过干预组合的效果方面表现良好，且推断出的因果潜在因素具有生物学意义。&lt;h4&gt;结论&lt;/h4&gt;SENA-discrepancy-VAE是一种有潜力的方法，可以提高对基因功能和药物效果的预测，从而为改进疗法提供支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要：预测基因组变异和药物干预对细胞功能的影响对于理解基因功能和药物效果至关重要，最终可导致疗法的改进。为此，因果表示学习（CRL）构成了最有可能的方法之一，因为它旨在识别控制生物系统的潜在因素，从而促进对未见变异影响的预测。然而，现有的CRL方法在将原则上的潜在表示与已知的生物过程相协调方面失败，导致不可解释的模型。为了解决这个主要问题，我们提出了SENA-discrepancy-VAE模型，这是一个基于最近提出的CRL方法discrepancy-VAE的模型，它产生可以解释的表示，其中每个潜在因素都可以解释为（学习到的）一组生物过程活动的（线性）组合。在这方面，我们提出了一种编码器SENA-δ，它可以有效地计算并将生物过程的活动水平映射到潜在因果因素。我们表明，SENA-discrepancy-VAE在预测未见干预组合的效果方面实现了与原始非可解释的同类产品相当的性能，同时推断出的因果潜在因素具有生物学意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting the impact of genomic and drug perturbations in cellular functionis crucial for understanding gene functions and drug effects, ultimatelyleading to improved therapies. To this end, Causal Representation Learning(CRL) constitutes one of the most promising approaches, as it aims to identifythe latent factors that causally govern biological systems, thus facilitatingthe prediction of the effect of unseen perturbations. Yet, current CRL methodsfail in reconciling their principled latent representations with knownbiological processes, leading to models that are not interpretable. To addressthis major issue, we present SENA-discrepancy-VAE, a model based on therecently proposed CRL method discrepancy-VAE, that produces representationswhere each latent factor can be interpreted as the (linear) combination of theactivity of a (learned) set of biological processes. To this extent, we presentan encoder, SENA-{\delta}, that efficiently compute and map biologicalprocesses' activity levels to the latent causal factors. We show thatSENA-discrepancy-VAE achieves predictive performances on unseen combinations ofinterventions that are comparable with its original, non-interpretablecounterpart, while inferring causal latent factors that are biologicallymeaningful.</description>
      <author>example@mail.com (Jesus de la Fuente, Robert Lehmann, Carlos Ruiz-Arenas, Jan Voges, Irene Marin-Goñi, Xabier Martinez-de-Morentin, David Gomez-Cabrero, Idoia Ochoa, Jesper Tegner, Vincenzo Lagani, Mikel Hernaez)</author>
      <guid isPermaLink="false">2506.12439v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>BoxFusion: Reconstruction-Free Open-Vocabulary 3D Object Detection via Real-Time Multi-View Box Fusion</title>
      <link>http://arxiv.org/abs/2506.15610v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种无重建的在线3D物体检测框架，旨在提高内存效率和实时性。&lt;h4&gt;背景&lt;/h4&gt;Open-vocabulary 3D物体检测在自动驾驶和具身AI中具有关键应用，但现有方法通常依赖于密集点云重建，导致计算和内存开销大。&lt;h4&gt;目的&lt;/h4&gt;开发一种内存高效且适用于实时3D检测的新框架。&lt;h4&gt;方法&lt;/h4&gt;使用Cubify Anything作为预训练的视觉基础模型（VFM）进行单视图3D物体检测，并结合CLIP捕获检测物体的开放词汇语义。通过关联模块进行多视图对应和优化模块融合多视图中的3D边界框，利用3D非极大值抑制（NMS）和匹配模块，以及基于粒子滤波的IoU引导随机优化技术。&lt;h4&gt;主要发现&lt;/h4&gt;在ScanNetV2和CA-1M数据集上的实验表明，该方法在在线方法中实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在多种场景中表现出良好的泛化能力，即使在超过1000平方米的环境中也能实现实时感知。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-vocabulary 3D object detection has gained significant interest due toits critical applications in autonomous driving and embodied AI. Existingdetection methods, whether offline or online, typically rely on dense pointcloud reconstruction, which imposes substantial computational overhead andmemory constraints, hindering real-time deployment in downstream tasks. Toaddress this, we propose a novel reconstruction-free online framework tailoredfor memory-efficient and real-time 3D detection. Specifically, given streamingposed RGB-D video input, we leverage Cubify Anything as a pre-trained visualfoundation model (VFM) for single-view 3D object detection by bounding boxes,coupled with CLIP to capture open-vocabulary semantics of detected objects. Tofuse all detected bounding boxes across different views into a unified one, weemploy an association module for correspondences of multi-views and anoptimization module to fuse the 3D bounding boxes of the same instancepredicted in multi-views. The association module utilizes 3D Non-MaximumSuppression (NMS) and a box correspondence matching module, while theoptimization module uses an IoU-guided efficient random optimization techniquebased on particle filtering to enforce multi-view consistency of the 3Dbounding boxes while minimizing computational complexity. Extensive experimentson ScanNetV2 and CA-1M datasets demonstrate that our method achievesstate-of-the-art performance among online methods. Benefiting from this novelreconstruction-free paradigm for 3D object detection, our method exhibits greatgeneralization abilities in various scenarios, enabling real-time perceptioneven in environments exceeding 1000 square meters.</description>
      <author>example@mail.com (Yuqing Lan, Chenyang Zhu, Zhirui Gao, Jiazhao Zhang, Yihan Cao, Renjiao Yi, Yijie Wang, Kai Xu)</author>
      <guid isPermaLink="false">2506.15610v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification</title>
      <link>http://arxiv.org/abs/2506.15569v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SciVer是一个专门设计来评估基础模型在多模态科学环境中验证声明能力的新基准。&lt;h4&gt;背景&lt;/h4&gt;当前缺乏专门针对多模态科学声明验证能力的基础模型评估基准。&lt;h4&gt;目的&lt;/h4&gt;设计SciVer以评估基础模型在多模态科学声明验证方面的能力。&lt;h4&gt;方法&lt;/h4&gt;SciVer包含3000个专家标注的例子，覆盖了1,113篇科学论文，包括四个子集，每个子集代表一种常见的推理类型。每个例子都包括专家标注的支持证据。对21个最先进的模态基础模型进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验发现，这些模型在SciVer上与人类专家之间存在着显著的性能差距。通过深入分析检索增强生成（RAG）和人工进行的错误评估，确定了当前开源模型的关键局限性。&lt;h4&gt;结论&lt;/h4&gt;SciVer为改进模型在多模态科学文献任务中的理解和推理能力提供了关键见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce SciVer, the first benchmark specifically designed to evaluatethe ability of foundation models to verify claims within a multimodalscientific context. SciVer consists of 3,000 expert-annotated examples over1,113 scientific papers, covering four subsets, each representing a commonreasoning type in multimodal scientific claim verification. To enablefine-grained evaluation, each example includes expert-annotated supportingevidence. We assess the performance of 21 state-of-the-art multimodalfoundation models, including o4-mini, Gemini-2.5-Flash, Llama-3.2-Vision, andQwen2.5-VL. Our experiment reveals a substantial performance gap between thesemodels and human experts on SciVer. Through an in-depth analysis ofretrieval-augmented generation (RAG), and human-conducted error evaluations, weidentify critical limitations in current open-source models, offering keyinsights to advance models' comprehension and reasoning in multimodalscientific literature tasks.</description>
      <author>example@mail.com (Chengye Wang, Yifei Shen, Zexi Kuang, Arman Cohan, Yilun Zhao)</author>
      <guid isPermaLink="false">2506.15569v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>MapFM: Foundation Model-Driven HD Mapping with Multi-Task Contextual Learning</title>
      <link>http://arxiv.org/abs/2506.15313v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Submitted. 12 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为MapFM的增强型端到端模型，用于在线生成矢量高清地图，显著提升了特征表示质量，并通过多任务学习增强了场景表示的准确性。&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶领域，高清地图和鸟瞰视图语义地图对于精确定位、规划和决策至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够在线生成矢量高清地图的模型，提高地图生成质量和预测准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为MapFM的模型，该模型结合了强大的基础模型来编码相机图像，并集成了辅助预测头进行语义分割，以增强对环境的理解。&lt;h4&gt;主要发现&lt;/h4&gt;MapFM模型通过多任务学习提供了更丰富的上下文监督，从而实现了更全面的场景表示，并提高了预测矢量高清地图的准确性和质量。&lt;h4&gt;结论&lt;/h4&gt;MapFM模型能够有效地生成高质量的矢量高清地图，为自动驾驶系统的定位和决策提供支持。&lt;h4&gt;翻译&lt;/h4&gt;In autonomous driving, high-definition (HD) maps and semantic maps in bird's-eye view (BEV) are essential for accurate localization, planning, and decision-making. This paper introduces an enhanced End-to-End model named MapFM for online vectorized HD map generation. We show significantly boost feature representation quality by incorporating powerful foundation model for encoding camera images. To further enrich the model's understanding of the environment and improve prediction quality, we integrate auxiliary prediction heads for semantic segmentation in the BEV representation. This multi-task learning approach provides richer contextual supervision, leading to a more comprehensive scene representation and ultimately resulting in higher accuracy and improved quality of the predicted vectorized HD maps. The source code is available at https://github.com/LIvanoff/MapFM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In autonomous driving, high-definition (HD) maps and semantic maps inbird's-eye view (BEV) are essential for accurate localization, planning, anddecision-making. This paper introduces an enhanced End-to-End model named MapFMfor online vectorized HD map generation. We show significantly boost featurerepresentation quality by incorporating powerful foundation model for encodingcamera images. To further enrich the model's understanding of the environmentand improve prediction quality, we integrate auxiliary prediction heads forsemantic segmentation in the BEV representation. This multi-task learningapproach provides richer contextual supervision, leading to a morecomprehensive scene representation and ultimately resulting in higher accuracyand improved quality of the predicted vectorized HD maps. The source code isavailable at https://github.com/LIvanoff/MapFM.</description>
      <author>example@mail.com (Leonid Ivanov, Vasily Yuryev, Dmitry Yudin)</author>
      <guid isPermaLink="false">2506.15313v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>SynPo: Boosting Training-Free Few-Shot Medical Segmentation via High-Quality Negative Prompts</title>
      <link>http://arxiv.org/abs/2506.15153v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SynPo是一种基于大型视觉模型（LVMs）的无监督学习方法，用于少样本医学图像分割，通过改进负提示的质量来提高低对比度医学图像的性能。&lt;h4&gt;背景&lt;/h4&gt;随着大型视觉模型（LVMs）的出现，为少样本医学图像分割带来了新的机遇，但现有的基于LVMs的无监督方法未能有效利用负提示，导致在低对比度医学图像上的性能不佳。&lt;h4&gt;目的&lt;/h4&gt;提出SynPo，旨在解决现有方法在低对比度医学图像分割中的性能问题。&lt;h4&gt;方法&lt;/h4&gt;SynPo结合了DINOv2和SAM的优势，设计了一种新的置信图协同模块，以更可靠的方式选择点提示。基于置信图，选择top-k像素作为正点集，并使用高斯分布选择负点集，然后对这两组点进行独立的K-means聚类。最后，这些选定的点作为高质量的提示用于SAM，以获取分割结果。&lt;h4&gt;主要发现&lt;/h4&gt;SynPo在大量实验中展现出与最先进的基于训练的少样本方法相当的性能。&lt;h4&gt;结论&lt;/h4&gt;SynPo通过改进负提示的质量，实现了在低对比度医学图像分割中的高性能，为少样本医学图像分割提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of Large Vision Models (LVMs) offers new opportunities forfew-shot medical image segmentation. However, existing training-free methodsbased on LVMs fail to effectively utilize negative prompts, leading to poorperformance on low-contrast medical images. To address this issue, we proposeSynPo, a training-free few-shot method based on LVMs (e.g., SAM), with the coreinsight: improving the quality of negative prompts. To select point prompts ina more reliable confidence map, we design a novel Confidence Map Synergy Moduleby combining the strengths of DINOv2 and SAM. Based on the confidence map, weselect the top-k pixels as the positive points set and choose the negativepoints set using a Gaussian distribution, followed by independent K-meansclustering for both sets. Then, these selected points are leveraged ashigh-quality prompts for SAM to get the segmentation results. Extensiveexperiments demonstrate that SynPo achieves performance comparable tostate-of-the-art training-based few-shot methods.</description>
      <author>example@mail.com (Yufei Liu, Haoke Xiao, Jiaxing Chai, Yongcun Zhang, Rong Wang, Zijie Meng, Zhiming Luo)</author>
      <guid isPermaLink="false">2506.15153v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>EMUSE: Evolutionary Map of the Universe Search Engine</title>
      <link>http://arxiv.org/abs/2506.15090v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 9 figures, accepted for publication in PASA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;EMUSE是一种用于搜索特定射电源的工具，旨在帮助天文学家在EMU调查的大量数据集中进行搜索，同时具备应用于其他天文大数据挑战的潜力。&lt;h4&gt;背景&lt;/h4&gt;EMU（宇宙进化图谱）是一个包含大量射电源数据的调查项目，而EMUSE工具旨在提高对这一数据的搜索效率。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够高效、灵活地在大规模射电天文数据集中进行搜索的工具，同时能够识别射电源的独特形态特征。&lt;h4&gt;方法&lt;/h4&gt;EMUSE基于多模态方法对射电源进行分类和检索，并使用经过筛选的射电星系数据集微调OpenCLIP模型。该模型通过结合视觉和文本嵌入来增强搜索功能。&lt;h4&gt;主要发现&lt;/h4&gt;微调后的模型在检索和分类射电源方面表现出有效性，尤其是在识别不同的形态特征方面。然而，识别稀有或未见过的射电源仍然存在挑战。&lt;h4&gt;结论&lt;/h4&gt;EMUSE展示了多模态机器学习在射电天文学中的潜力，为该领域提供了更可扩展和精确的搜索工具。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为EMUSE（宇宙进化图谱搜索引擎）的工具，旨在在EMU（宇宙进化图谱）调查的大量数据集中搜索特定的射电源，并且可能应用于天文学中的其他大数据挑战。EMUSE基于多模态的射电源分类和检索方法，微调了OpenCLIP模型，基于精心挑选的射电星系数据集。利用基础模型的力量，我们的工作结合了视觉和文本嵌入，以实现在大规模射电天文数据集中的高效和灵活搜索。我们使用包含2900个射电星系的数据集来微调OpenCLIP，这些星系涵盖了包括FR-I、FR-II、FR-x、R型和其他稀有和特殊来源在内的各种形态类别。该模型通过基于适配器的微调进行优化，确保计算效率同时捕捉射电源的独特特征。然后，该微调模型被部署在EMUSE中，允许对EMU调查数据集进行无缝的基于图像和文本的查询。我们的结果表明，该模型在检索和分类射电源方面非常有效，特别是在识别不同的形态特征方面。然而，在识别稀有或以前未见过的射电源方面仍存在挑战，这突显了需要扩展数据集和持续改进的需求。这项研究展示了多模态机器学习在射电天文学中的潜力，为该领域铺平了道路，为该领域提供了更可扩展和精确的搜索工具。该搜索引擎可在https://askap-emuse.streamlit.app/访问，并且可以通过在https://github.com/Nikhel1/EMUSE上克隆存储库在本地使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present EMUSE (Evolutionary Map of the Universe Search Engine), a tooldesigned for searching specific radio sources within the extensive datasets ofthe EMU (Evolutionary Map of the Universe) survey, with potential applicationsto other Big Data challenges in astronomy. Built on a multimodal approach toradio source classification and retrieval, EMUSE fine-tunes the OpenCLIP modelon curated radio galaxy datasets. Leveraging the power of foundation models,our work integrates visual and textual embeddings to enable efficient andflexible searches within large radio astronomical datasets. We fine-tuneOpenCLIP using a dataset of 2,900 radio galaxies, encompassing variousmorphological classes, including FR-I, FR-II, FR-x, R-type, and other rare andpeculiar sources. The model is optimized using adapter-based fine-tuning,ensuring computational efficiency while capturing the unique characteristics ofradio sources. The fine-tuned model is then deployed in EMUSE, allowing forseamless image- and text-based queries over the EMU survey dataset. Our resultsdemonstrate the model's effectiveness in retrieving and classifying radiosources, particularly in recognizing distinct morphological features. However,challenges remain in identifying rare or previously unseen radio sources,highlighting the need for expanded datasets and continuous refinement. Thisstudy showcases the potential of multimodal machine learning in radioastronomy, paving the way for more scalable and accurate search tools in thefield. The search engine is accessible at https://askap-emuse.streamlit.app/and can be used locally by cloning the repository athttps://github.com/Nikhel1/EMUSE.</description>
      <author>example@mail.com (Nikhel Gupta, Zeeshan Hayder, Minh Huynh, Ray P. Norris, Lars Petersson, Andrew M. Hopkins, Simone Riggi, Bärbel S. Koribalski, Miroslav D. Filipović)</author>
      <guid isPermaLink="false">2506.15090v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>EmojiVoice: Towards long-term controllable expressivity in robot speech</title>
      <link>http://arxiv.org/abs/2506.15085v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to RO-MAN 2025, Demo at HRI 2025 :  https://dl.acm.org/doi/10.5555/3721488.3721774&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为EmojiVoice的免费、可定制的语音合成工具包，用于在社交机器人上构建具有时间变化和表情的语音。&lt;h4&gt;背景&lt;/h4&gt;人类在长时间讲话时会调整表情以维持与听众的互动，而社交机器人通常配备的是具有表达力的快乐声音，但缺乏人类语言中的长期变化。&lt;h4&gt;目的&lt;/h4&gt;设计EmojiVoice工具包，以帮助社交机器人研究者构建具有时间变化和表情的语音。&lt;h4&gt;方法&lt;/h4&gt;通过引入emoji提示来实现对表情的细粒度控制，并使用轻量级的Matcha-TTS作为语音生成的实时框架。&lt;h4&gt;主要发现&lt;/h4&gt;在讲述任务中，使用具有变化的emoji提示提高了语音的感知和表现力，但在助手使用场景中，表达性声音并不受欢迎。&lt;h4&gt;结论&lt;/h4&gt;EmojiVoice工具包能够帮助社交机器人更好地模拟人类语言的表情，提高社交机器人在特定任务中的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans vary their expressivity when speaking for extended periods to maintainengagement with their listener. Although social robots tend to be deployed with``expressive'' joyful voices, they lack this long-term variation found in humanspeech. Foundation model text-to-speech systems are beginning to mimic theexpressivity in human speech, but they are difficult to deploy offline onrobots. We present EmojiVoice, a free, customizable text-to-speech (TTS)toolkit that allows social roboticists to build temporally variable, expressivespeech on social robots. We introduce emoji-prompting to allow fine-grainedcontrol of expressivity on a phase level and use the lightweight Matcha-TTSbackbone to generate speech in real-time. We explore three case studies: (1) ascripted conversation with a robot assistant, (2) a storytelling robot, and (3)an autonomous speech-to-speech interactive agent. We found that using variedemoji prompting improved the perception and expressivity of speech over a longperiod in a storytelling task, but expressive voice was not preferred in theassistant use case.</description>
      <author>example@mail.com (Paige Tuttösí, Shivam Mehta, Zachary Syvenky, Bermet Burkanova, Gustav Eje Henter, Angelica Lim)</author>
      <guid isPermaLink="false">2506.15085v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>Early Prediction of Multiple Sclerosis Disability Progression via Multimodal Foundation Model Benchmarks</title>
      <link>http://arxiv.org/abs/2506.14986v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究利用先进的表格和时间序列基础模型，以及机器学习方法，对早期多发性硬化症（MS）的48周和72周残疾进展进行预测。&lt;h4&gt;背景&lt;/h4&gt;早期MS残疾进展预测因疾病异质性而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;预测48周和72周的残疾进展，并评估整合数字数据对预测性能的影响。&lt;h4&gt;方法&lt;/h4&gt;使用CONSONANCE临床试验中的稀疏基线临床数据和12周的每日数字Floodlight数据，采用最新的表格和时间序列基础模型、定制多模态注意力机制变压器和机器学习技术。&lt;h4&gt;主要发现&lt;/h4&gt;尽管早期预测困难（AUROC 0.63），但通过高级模型整合数字数据提高了性能。使用来自Moment FM的单模态嵌入的变压器模型获得了最佳结果，但我们的多模态变压器模型在性能上始终优于其单模态版本，证实了结合临床与数字数据的优势。&lt;h4&gt;结论&lt;/h4&gt;研究结果展示了使用基础模型和多模态方法从复杂多变的临床和数字生命科学数据中提取预测信号的前景，有望为MS和其他复杂疾病提供更准确的预后。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early multiple sclerosis (MS) disability progression prediction ischallenging due to disease heterogeneity. This work predicts 48- and 72-weekdisability using sparse baseline clinical data and 12 weeks of daily digitalFloodlight data from the CONSONANCE clinical trial. We employedstate-of-the-art tabular and time-series foundation models (FMs), a custommultimodal attention-based transformer, and machine learning methods. Despitethe difficulty of early prediction (AUROC 0.63), integrating digital data viaadvanced models improved performance over clinical data alone. A transformermodel using unimodal embeddings from the Moment FM yielded the best result, butour multimodal transformer consistently outperformed its unimodal counterpart,confirming the advantages of combining clinical with digital data. Our findingsdemonstrate the promise of FMs and multimodal approaches to extract predictivesignals from complex and diverse clinical and digital life sciences data (e.g.,imaging, omics), enabling more accurate prognostics for MS and potentiallyother complex diseases.</description>
      <author>example@mail.com (Maxime Usdin, Lito Kriara, Licinio Craveiro)</author>
      <guid isPermaLink="false">2506.14986v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>POCO: Scalable Neural Forecasting through Population Conditioning</title>
      <link>http://arxiv.org/abs/2506.14957v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为POCO的统一预测模型，用于预测未来神经活动。该模型结合了轻量级单变量预测器和种群级编码器，以捕捉神经元特定的和大脑广泛的动态。POCO在五个钙成像数据集上进行了训练，实现了在自发性行为中的细胞分辨率预测的领先准确性。POCO在预训练后能够快速适应新的记录，并且无需大量微调。POCO学习到的单元嵌入能够恢复生物学上有意义的结构，如脑区聚类，而不需要任何解剖学标签。研究揭示了影响性能的关键因素，包括上下文长度、会话多样性和预处理。这些结果将POCO定位为跨会话神经预测的可扩展和适应性强的方法，并为未来的模型设计提供了有价值的见解。&lt;h4&gt;背景&lt;/h4&gt;预测未来神经活动是建模脑动态的核心挑战，其应用范围从科学调查到闭环神经技术。尽管最近的人口活动模型强调可解释性和行为解码，但神经预测，特别是在多场次自发性记录中，仍然没有得到充分的探索。&lt;h4&gt;目的&lt;/h4&gt;介绍POCO模型，这是一种统一的预测模型，旨在捕捉神经元特定的和大脑广泛的动态，以预测未来神经活动。&lt;h4&gt;方法&lt;/h4&gt;POCO模型结合了轻量级单变量预测器和种群级编码器。该模型在五个钙成像数据集上进行了训练，这些数据集涵盖了斑马鱼、小鼠和秀丽隐杆线虫。&lt;h4&gt;主要发现&lt;/h4&gt;POCO在自发性行为中的细胞分辨率预测达到了最先进的准确性。POCO在预训练后能够快速适应新的记录，并且无需大量微调。POCO学习到的单元嵌入能够恢复生物学上有意义的结构。研究揭示了影响性能的关键因素，包括上下文长度、会话多样性和预处理。&lt;h4&gt;结论&lt;/h4&gt;POCO是一个可扩展和适应性强的方法，可用于跨会话神经预测。它为自适应神经技术和神经基础模型的大规模努力奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为POCO的统一预测模型，用于预测未来神经活动。该模型结合了轻量级单变量预测器和种群级编码器以捕捉神经元特定的和大脑广泛的动态。在五个钙成像数据集上经过训练后，POCO在自发性行为中的细胞分辨率预测达到了最先进的准确性。在预训练后，POCO能够快速适应新的记录，并且无需大量微调。POCO学习到的单元嵌入能够恢复生物学上有意义的结构，如脑区聚类，而不需要任何解剖学标签。全面的分析揭示了影响性能的关键因素，包括上下文长度、会话多样性和预处理。这些结果将POCO定位为跨会话神经预测的可扩展和适应性强的方法，并为未来的模型设计提供了有价值的见解。通过实现能够准确、普遍适用于个体和物种之间神经动态的预测模型，POCO为自适应神经技术和神经基础模型的大规模努力奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting future neural activity is a core challenge in modeling braindynamics, with applications ranging from scientific investigation toclosed-loop neurotechnology. While recent models of population activityemphasize interpretability and behavioral decoding, neuralforecasting-particularly across multi-session, spontaneous recordings-remainsunderexplored. We introduce POCO, a unified forecasting model that combines alightweight univariate forecaster with a population-level encoder to captureboth neuron-specific and brain-wide dynamics. Trained across five calciumimaging datasets spanning zebrafish, mice, and C. elegans, POCO achievesstate-of-the-art accuracy at cellular resolution in spontaneous behaviors.After pre-training, POCO rapidly adapts to new recordings with minimalfine-tuning. Notably, POCO's learned unit embeddings recover biologicallymeaningful structure-such as brain region clustering-without any anatomicallabels. Our comprehensive analysis reveals several key factors influencingperformance, including context length, session diversity, and preprocessing.Together, these results position POCO as a scalable and adaptable approach forcross-session neural forecasting and offer actionable insights for future modeldesign. By enabling accurate, generalizable forecasting models of neuraldynamics across individuals and species, POCO lays the groundwork for adaptiveneurotechnologies and large-scale efforts for neural foundation models.</description>
      <author>example@mail.com (Yu Duan, Hamza Tahir Chaudhry, Misha B. Ahrens, Christopher D Harvey, Matthew G Perich, Karl Deisseroth, Kanaka Rajan)</author>
      <guid isPermaLink="false">2506.14957v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Artificial Intelligence Models for Health Recognition Using Face Photographs (FAHR-Face)</title>
      <link>http://arxiv.org/abs/2506.14909v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究介绍了FAHR-Face，一个基于超过4000万张面部图像训练的基础模型，并针对生物年龄估计和生存风险预测两个任务进行了微调。研究测试了模型的鲁棒性和独立性，并在独立的数据集中进行了临床验证，结果表明模型在年龄估计和生存风险预测方面具有高准确性。&lt;h4&gt;背景&lt;/h4&gt;面部外观为健康提供了一个非侵入性的窗口。研究者开发了FAHR-Face，一个基于大量面部图像训练的基础模型。&lt;h4&gt;目的&lt;/h4&gt;开发FAHR-Face模型，并针对生物年龄估计和生存风险预测进行微调。&lt;h4&gt;方法&lt;/h4&gt;FAHR-FaceAge在749,935张公共图像上进行了两阶段的、年龄平衡的微调；FAHR-FaceSurvival在34,389张癌症患者照片上进行了微调。模型鲁棒性和独立性进行了广泛测试。两个模型在两个独立癌症患者数据集中进行了临床测试，通过多变量Cox模型分析生存情况，并调整了临床预后因素。&lt;h4&gt;主要发现&lt;/h4&gt;FAHR-FaceAge在公共数据集上实现了5.1年的最低平均绝对误差，在生存预测方面优于之前的模型。FAHR-FaceSurvival在预测死亡率方面表现出色，高风险四分位数死亡率是最低的四分位数的3倍以上。这些发现得到了独立队列的验证，并且两个模型在年龄、性别、种族和癌症亚组中表现出泛化能力。两种算法提供了不同的、互补的预后信息；显著性映射揭示了每个模型依赖于不同的面部区域。FAHR-FaceAge和FAHR-FaceSurvival的结合提高了预后准确性。&lt;h4&gt;结论&lt;/h4&gt;单个基础模型可以生成低成本、可扩展的面部生物标志物，这些生物标志物可以捕捉生物衰老和疾病相关的死亡率风险。基础模型允许使用相对较小的临床数据集进行有效的训练。&lt;h4&gt;翻译&lt;/h4&gt;This study introduces FAHR-Face, a foundation model trained on more than 40 million facial images and fine-tuned for two distinct tasks: biological age estimation (FAHR-FaceAge) and survival risk prediction (FAHR-FaceSurvival). The robustness (cosmetic surgery, makeup, pose, lighting) and independence (saliency mapping) of the model were extensively tested. Both models were clinically tested in two independent cancer patient datasets with survival analyzed by multivariable Cox models and adjusted for clinical prognostic factors. Findings: For age estimation, FAHR-FaceAge achieved the lowest mean absolute error of 5.1 years on public datasets, outperforming benchmark models and maintaining accuracy across the full human lifespan. In cancer patients, FAHR-FaceAge outperformed a prior facial age estimation model in survival prognosis. FAHR-FaceSurvival demonstrated robust prediction of mortality, and the highest-risk quartile had more than triple the mortality of the lowest (adjusted hazard ratio 3.22; P&lt;0.001). These findings were validated in the independent cohort and both models showed generalizability across age, sex, race and cancer subgroups. The two algorithms provided distinct, complementary prognostic information; saliency mapping revealed each model relied on distinct facial regions. The combination of FAHR-FaceAge and FAHR-FaceSurvival improved prognostic accuracy. Interpretation: A single foundation model can generate inexpensive, scalable facial biomarkers that capture both biological aging and disease-related mortality risk. The foundation model enabled effective training using relatively small clinical datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Background: Facial appearance offers a noninvasive window into health. Webuilt FAHR-Face, a foundation model trained on &gt;40 million facial images andfine-tuned it for two distinct tasks: biological age estimation (FAHR-FaceAge)and survival risk prediction (FAHR-FaceSurvival).  Methods: FAHR-FaceAge underwent a two-stage, age-balanced fine-tuning on749,935 public images; FAHR-FaceSurvival was fine-tuned on 34,389 photos ofcancer patients. Model robustness (cosmetic surgery, makeup, pose, lighting)and independence (saliency mapping) was tested extensively. Both models wereclinically tested in two independent cancer patient datasets with survivalanalyzed by multivariable Cox models and adjusted for clinical prognosticfactors.  Findings: For age estimation, FAHR-FaceAge had the lowest mean absolute errorof 5.1 years on public datasets, outperforming benchmark models and maintainingaccuracy across the full human lifespan. In cancer patients, FAHR-FaceAgeoutperformed a prior facial age estimation model in survival prognostication.FAHR-FaceSurvival demonstrated robust prediction of mortality, and thehighest-risk quartile had more than triple the mortality of the lowest(adjusted hazard ratio 3.22; P&lt;0.001). These findings were validated in theindependent cohort and both models showed generalizability across age, sex,race and cancer subgroups. The two algorithms provided distinct, complementaryprognostic information; saliency mapping revealed each model relied on distinctfacial regions. The combination of FAHR-FaceAge and FAHR-FaceSurvival improvedprognostic accuracy.  Interpretation: A single foundation model can generate inexpensive, scalablefacial biomarkers that capture both biological ageing and disease-relatedmortality risk. The foundation model enabled effective training usingrelatively small clinical datasets.</description>
      <author>example@mail.com (Fridolin Haugg, Grace Lee, John He, Leonard Nürnberg, Dennis Bontempi, Danielle S. Bitterman, Paul Catalano, Vasco Prudente, Dmitrii Glubokov, Andrew Warrington, Suraj Pai, Dirk De Ruysscher, Christian Guthier, Benjamin H. Kann, Vadim N. Gladyshev, Hugo JWL Aerts, Raymond H. Mak)</author>
      <guid isPermaLink="false">2506.14909v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>BMFM-RNA: An Open Framework for Building and Evaluating Transcriptomic Foundation Models</title>
      <link>http://arxiv.org/abs/2506.14861v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;BMFM-RNA是一个开源、模块化软件包，用于统一不同的转录组基础模型（TFM）预训练和微调目标，旨在提高基因表达分析的准确性和可重复性。&lt;h4&gt;背景&lt;/h4&gt;TFM是分析细胞和组织中基因表达的有力工具，但在模型实现和训练策略上的多样性使得难以评估不同设计选择的贡献或其潜在的协同作用，这限制了最佳实践的收敛和跨研究的见解的可重复性。&lt;h4&gt;目的&lt;/h4&gt;提出BMFM-RNA软件包，旨在统一TFM预训练和微调目标，并引入一个新的训练目标——全细胞表达解码器（WCED），以提高基因表达分析的准确性。&lt;h4&gt;方法&lt;/h4&gt;BMFM-RNA支持使用掩码语言建模（MLM）、WCED和多任务学习进行预训练，并在CELLxGENE上评估了四个模型检查点。&lt;h4&gt;主要发现&lt;/h4&gt;WCED模型在多个数据集上达到了与scGPT等最先进方法相当或更好的性能，无论是在零样本任务还是微调任务中。&lt;h4&gt;结论&lt;/h4&gt;BMFM-RNA为系统基准测试和社区驱动的最优TFM训练策略探索提供了一个可重复的基础，有助于开发更有效的工具来利用AI在细胞生物学领域的最新进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transcriptomic foundation models (TFMs) have recently emerged as powerfultools for analyzing gene expression in cells and tissues, supporting key taskssuch as cell-type annotation, batch correction, and perturbation prediction.However, the diversity of model implementations and training strategies acrossrecent TFMs, though promising, makes it challenging to isolate the contributionof individual design choices or evaluate their potential synergies. Thishinders the field's ability to converge on best practices and limits thereproducibility of insights across studies. We present BMFM-RNA, anopen-source, modular software package that unifies diverse TFM pretraining andfine-tuning objectives within a single framework. Leveraging this capability,we introduce a novel training objective, whole cell expression decoder (WCED),which captures global expression patterns using an autoencoder-like CLSbottleneck representation. In this paper, we describe the framework, supportedinput representations, and training objectives. We evaluated four modelcheckpoints pretrained on CELLxGENE using combinations of masked languagemodeling (MLM), WCED and multitask learning. Using the benchmarkingcapabilities of BMFM-RNA, we show that WCED-based models achieve performancethat matches or exceeds state-of-the-art approaches like scGPT across more thana dozen datasets in both zero-shot and fine-tuning tasks. BMFM-RNA, availableas part of the biomed-multi-omics project (https://github.com/BiomedSciAI/biomed-multi-omic ), offers a reproduciblefoundation for systematic benchmarking and community-driven exploration ofoptimal TFM training strategies, enabling the development of more effectivetools to leverage the latest advances in AI for understanding cell biology.</description>
      <author>example@mail.com (Bharath Dandala, Michael M. Danziger, Ella Barkan, Tanwi Biswas, Viatcheslav Gurev, Jianying Hu, Matthew Madgwick, Akira Koseki, Tal Kozlovski, Michal Rosen-Zvi, Yishai Shimoni, Ching-Huei Tsou)</author>
      <guid isPermaLink="false">2506.14861v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>A Machine Learning Framework for Modeling Ensemble Properties of Atomically Disordered Materials</title>
      <link>http://arxiv.org/abs/2506.15652v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种将图神经网络（GNNs）与蒙特卡洛模拟相结合的计算框架，用于高效计算无序材料的动力学性质和系综平均功能性质。&lt;h4&gt;背景&lt;/h4&gt;无序现象在实验样品中普遍存在，对多种材料现象有强烈影响，但由于计算成本高，无序系统的第一性原理研究尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;通过机器学习技术，特别是图神经网络（GNNs），研究无序材料的热力学性质和系综平均功能性质。&lt;h4&gt;方法&lt;/h4&gt;以表面终止无序的MXene单层Ti3C2T2-x为代表性系统，结合GNNs和蒙特卡洛模拟，研究表面终止无序对电学和光学导电谱的影响。&lt;h4&gt;主要发现&lt;/h4&gt;表面终止无序影响电导率的温度依赖性，在近序-无序相变温度处诱导一个峰值，反映了相变过程中表面终止组散射和电子填充效应的竞争。而光学导电率对局部无序的鲁棒性强，主要由表面终止的全球化学组成决定。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了机器学习辅助框架在统计模拟复杂材料中的无序效应和系综性质中的实用性，为未来研究高熵合金和杂乱磁性化合物等系统中无序驱动现象提供了新的途径。&lt;h4&gt;翻译&lt;/h4&gt;Disorder, though naturally present in experimental samples and strongly influencing a wide range of material phenomena, remains underexplored in first-principles studies due to the computational cost of sampling the large supercell and configurational space. The recent development of machine learning techniques, particularly graph neural networks (GNNs), has enabled the efficient and accurate predictions of complex material properties, offering promising tools for studying disordered systems. In this work, we introduce a computational framework that integrates GNNs with Monte Carlo simulations for efficient calculations of thermodynamic properties and ensemble-averaged functional properties of disordered materials. Using the surface-termination-disordered MXene monolayer Ti3C2T2-x as a representative system, we investigate the effect of surface termination disorder involving -F, -O, and termination vacancies on the electrical and optical conductivity spectra. We find that surface termination disorder affects the temperature dependence of electrical conductivity, inducing a peak close to the order-disorder phase transition temperature that reflects the competition between scattering and electron filling effects of the surface termination groups across the phase transition. In contrast, optical conductivity remains robust to local disorder across a wide temperature range and is governed primarily by the global chemical composition of surface terminations. These results demonstrate the utility of our machine-learning-assisted framework for statistically modeling disorder effects and ensemble properties in complex materials, opening new avenues for future studies of disorder-driven phenomena in systems such as high-entropy alloys and disordered magnetic compounds.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Disorder, though naturally present in experimental samples and stronglyinfluencing a wide range of material phenomena, remains underexplored infirst-principles studies due to the computational cost of sampling the largesupercell and configurational space. The recent development of machine learningtechniques, particularly graph neural networks (GNNs), has enabled theefficient and accurate predictions of complex material properties, offeringpromising tools for studying disordered systems. In this work, we introduce acomputational framework that integrates GNNs with Monte Carlo simulations forefficient calculations of thermodynamic properties and ensemble-averagedfunctional properties of disordered materials. Using thesurface-termination-disordered MXene monolayer \ch{Ti3C2T}$_{2-x}$ as arepresentative system, we investigate the effect of surface terminationdisorder involving \ch{-F}, \ch{-O}, and termination vacancies on theelectrical and optical conductivity spectra. We find that surface terminationdisorder affects the temperature dependence of electrical conductivity,inducing a peak close to the order-disorder phase transition temperature thatreflects the competition between scattering and electron filling effects of thesurface termination groups across the phase transition. In contrast, opticalconductivity remains robust to local disorder across a wide temperature rangeand is governed primarily by the global chemical composition of surfaceterminations. These results demonstrate the utility of ourmachine-learning-assisted framework for statistically modeling disorder effectsand ensemble properties in complex materials, opening new avenues for futurestudies of disorder-driven phenomena in systems such as high-entropy alloys anddisordered magnetic compounds.</description>
      <author>example@mail.com (Zhenyao Fang, Ting-Wei Hsu, Qimin Yan)</author>
      <guid isPermaLink="false">2506.15652v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>Over-squashing in Spatiotemporal Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.15507v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了时空图神经网络（STGNNs）中的信息传播问题，揭示了其局限性，并提出了新的解决方案。&lt;h4&gt;背景&lt;/h4&gt;尽管图神经网络（GNNs）在多个领域取得了显著成功，但近期理论研究揭示了它们在信息传播能力上的根本局限性，如远距离节点之间信息交换的失败。&lt;h4&gt;目的&lt;/h4&gt;本文旨在形式化时空过压缩问题，并分析其与静态情况下的不同特征。&lt;h4&gt;方法&lt;/h4&gt;通过理论分析和实证研究，本文揭示了时空GNNs中信息传播的挑战，并验证了在不同处理范式下的影响。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，与静态情况不同，卷积型时空GNNs更倾向于从时间上较远的点传播信息。此外，无论是时间-空间还是时间-时间-空间处理范式，架构都同样受此现象影响。&lt;h4&gt;结论&lt;/h4&gt;本文的研究结果为时空GNNs的有效设计提供了理论指导和实证依据。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the information propagation problem in Spatiotemporal Graph Neural Networks (STGNNs), reveals their limitations, and proposes new solutions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have achieved remarkable success across variousdomains. However, recent theoretical advances have identified fundamentallimitations in their information propagation capabilities, such asover-squashing, where distant nodes fail to effectively exchange information.While extensively studied in static contexts, this issue remains unexplored inSpatiotemporal GNNs (STGNNs), which process sequences associated with graphnodes. Nonetheless, the temporal dimension amplifies this challenge byincreasing the information that must be propagated. In this work, we formalizethe spatiotemporal over-squashing problem and demonstrate its distinctcharacteristics compared to the static case. Our analysis reveals thatcounterintuitively, convolutional STGNNs favor information propagation frompoints temporally distant rather than close in time. Moreover, we prove thatarchitectures that follow either time-and-space or time-then-space processingparadigms are equally affected by this phenomenon, providing theoreticaljustification for computationally efficient implementations. We validate ourfindings on synthetic and real-world datasets, providing deeper insights intotheir operational dynamics and principled guidance for more effective designs.</description>
      <author>example@mail.com (Ivan Marisca, Jacob Bamberger, Cesare Alippi, Michael M. Bronstein)</author>
      <guid isPermaLink="false">2506.15507v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>DOVA-PATBM: An Intelligent, Adaptive, and Scalable Framework for Optimizing Large-Scale EV Charging Infrastructure</title>
      <link>http://arxiv.org/abs/2506.15289v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DOVA-PATBM的地理计算框架，用于优化电池电动汽车充电基础设施的部署。&lt;h4&gt;背景&lt;/h4&gt;随着电动汽车的普及，需要数据丰富且地理可扩展的基础设施规划工具。&lt;h4&gt;目的&lt;/h4&gt;解决不同地区（如城市核心、依赖汽车的郊区和电力受限的农村地区）对充电基础设施的不同需求。&lt;h4&gt;方法&lt;/h4&gt;DOVA-PATBM将异构数据（如道路、人口、夜光、POI和馈电线路）映射到分层H3网格上，使用区域归一化的图神经网络中心性模型推断交叉路口的重要性，并覆盖Voronoi图来确保在每30公里范围内至少有一个五端口直流快充。&lt;h4&gt;主要发现&lt;/h4&gt;在佐治亚州的应用中，DOVA-PATBM提高了30公里瓷砖覆盖范围12个百分点，将低收入居民前往最近充电器的平均距离减半，并在所有地方满足次级传输空间。&lt;h4&gt;结论&lt;/h4&gt;DOVA-PATBM展示了紧密集成、由GNN驱动、多分辨率方法可以弥合学术优化与可部署基础设施政策之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着电池电动汽车的加速普及，需要数据丰富且地理可扩展的基础设施规划工具。而大多数先前的研究都是针对单个城市优化充电位置，州级和国家网络必须协调密集的都市核心、依赖汽车的郊区和电力受限的农村走廊的冲突需求。我们提出了DOVA-PATBM（基于Voronoi导向的、自适应的、POI感知的时间行为模型），这是一个将所有这些环境统一在一个管道中的地理计算框架。该方法将异构数据（道路、人口、夜光、POI和馈电线路）栅格化到分层H3网格上，使用区域归一化的图神经网络中心性模型推断交叉路口的重要性，并覆盖Voronoi图，确保在每30公里范围内至少有一个五端口直流快充。从环检测器和浮动车轨迹中学习到的每小时到达概况，通过有限M/M/c队列来调整端口大小，以满足馈电容量和停电风险约束。然后，使用收入加权的惩罚的贪婪最大覆盖启发式算法选择满足覆盖和公平目标的站点数量。在佐治亚州的应用中，DOVA-PATBM（i）将30公里瓷砖覆盖范围提高了12个百分点，（ii）将低收入居民前往最近充电器的平均距离减半，（iii）在所有地方都满足次级传输空间——所有这些同时保持对国家规模推出的计算可行性。这些结果表明，紧密集成、由GNN驱动、多分辨率方法可以弥合学术优化与可部署基础设施政策之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accelerating uptake of battery-electric vehicles demands infrastructureplanning tools that are both data-rich and geographically scalable. Whereasmost prior studies optimise charging locations for single cities, state-wideand national networks must reconcile the conflicting requirements of densemetropolitan cores, car-dependent exurbs, and power-constrained ruralcorridors.  We present DOVA-PATBM (Deployment Optimisation with Voronoi-oriented,Adaptive, POI-Aware Temporal Behaviour Model), a geo-computational frameworkthat unifies these contexts in a single pipeline. The method rasterisesheterogeneous data (roads, population, night lights, POIs, and feeder lines)onto a hierarchical H3 grid, infers intersection importance with azone-normalised graph neural network centrality model, and overlays a Voronoitessellation that guarantees at least one five-port DC fast charger withinevery 30 km radius. Hourly arrival profiles, learned from loop-detector andfloating-car traces, feed a finite M/M/c queue to size ports underfeeder-capacity and outage-risk constraints. A greedy maximal-coverageheuristic with income-weighted penalties then selects the minimum number ofsites that satisfy coverage and equity targets.  Applied to the State of Georgia, USA, DOVA-PATBM (i) increases 30 km tilecoverage by 12 percentage points, (ii) halves the mean distance that low-incomeresidents travel to the nearest charger, and (iii) meets sub-transmissionheadroom everywhere -- all while remaining computationally tractable fornational-scale roll-outs. These results demonstrate that a tightly integrated,GNN-driven, multi-resolution approach can bridge the gap between academicoptimisation and deployable infrastructure policy.</description>
      <author>example@mail.com (Chuan Li, Shunyu Zhao, Vincent Gauthier, Hassine Moungla)</author>
      <guid isPermaLink="false">2506.15289v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Force Metrics: Pre-Training MLFFs for Stable MD Simulations</title>
      <link>http://arxiv.org/abs/2506.14850v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了使用机器学习力场（MLFFs）加速第一性原理分子动力学（MD）模拟的潜力，并评估了不同训练策略的效果。&lt;h4&gt;背景&lt;/h4&gt;在MD模拟中，精确的力预测至关重要，但计算成本高昂，因此MLFFs作为一种解决方案应运而生。&lt;h4&gt;目的&lt;/h4&gt;评估GemNet-T作为MLFF在MD模拟中的应用，并比较两种训练策略的有效性。&lt;h4&gt;方法&lt;/h4&gt;使用了两种训练策略：直接在MD17数据集上训练（10K样本）和不进行预训练，以及在大规模OC20数据集上进行预训练后，在MD17数据集上进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;两种策略都实现了较低的力均方误差（MAE），达到每原子5 meV/A，但发现较低的力误差并不一定能保证MD模拟的稳定性。预训练的GemNet-T模型显著提高了模拟的稳定性，轨迹持续时间比从头开始训练的模型长三倍。&lt;h4&gt;结论&lt;/h4&gt;预训练在大型、多样化的数据集上对于捕捉复杂的分子相互作用有价值，同时强调仅考虑力MAE不是评估MD模拟稳定性的充分指标。&lt;h4&gt;翻译&lt;/h4&gt;摘要：机器学习力场（MLFFs）作为加速第一性原理分子动力学（MD）模拟的有前景的解决方案，其中准确的力预测至关重要但通常计算成本高昂。在本研究中，我们采用GemNet-T，一种图神经网络模型，作为MLFF，并调查了两种训练策略：（1）在MD17（10K样本）上直接训练而不进行预训练；（2）在大型OC20数据集上进行预训练，然后在小规模MD17（10K）数据集上进行微调。虽然两种方法都实现了低力的平均绝对误差（MAEs），达到每原子5 meV/A，但我们发现较低的力误差并不一定能保证稳定的MD模拟。值得注意的是，预训练的GemNet-T模型显著提高了模拟的稳定性，轨迹持续时间比从头开始训练的模型长三倍。这些发现强调了在大型、多样化的数据集上进行预训练以捕捉复杂分子相互作用的价值，并突出了仅考虑力MAE不是评估MD模拟稳定性的充分指标。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learning force fields (MLFFs) have emerged as a promising solutionfor speeding up ab initio molecular dynamics (MD) simulations, where accurateforce predictions are critical but often computationally expensive. In thiswork, we employ GemNet-T, a graph neural network model, as an MLFF andinvestigate two training strategies: (1) direct training on MD17 (10K samples)without pre-training, and (2) pre-training on the large-scale OC20 datasetfollowed by fine-tuning on MD17 (10K). While both approaches achieve low forcemean absolute errors (MAEs), reaching 5 meV/A per atom, we find that lowerforce errors do not necessarily guarantee stable MD simulations. Notably, thepre-trained GemNet-T model yields significantly improved simulation stability,sustaining trajectories up to three times longer than the model trained fromscratch. These findings underscore the value of pre-training on large, diversedatasets to capture complex molecular interactions and highlight that force MAEalone is not always a sufficient metric of MD simulation stability.</description>
      <author>example@mail.com (Shagun Maheshwari, Janghoon Ock, Adeesh Kolluru, Amir Barati Farimani, John R. Kitchin)</author>
      <guid isPermaLink="false">2506.14850v1</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>Model Context Protocol (MCP) at First Glance: Studying the Security and Maintainability of MCP Servers</title>
      <link>http://arxiv.org/abs/2506.13538v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对Model Context Protocol (MCP) 进行了大规模实证研究，评估了其健康、安全和可维护性。&lt;h4&gt;背景&lt;/h4&gt;尽管基础模型（如GPT-4）在金融和软件工程等领域得到广泛应用，但依赖文本界面限制了这些模型在实际世界中的交互。&lt;h4&gt;目的&lt;/h4&gt;研究MCP服务器，评估其健康、安全和可维护性。&lt;h4&gt;方法&lt;/h4&gt;使用最先进的健康指标和混合分析流程，结合通用静态分析工具和MCP特定扫描器，对1,899个开源MCP服务器进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;MCP服务器表现出强大的健康指标，但发现了八个不同的漏洞，其中只有三个与传统软件漏洞重叠。7.2%的服务器含有通用漏洞，5.5%表现出MCP特定工具中毒。在可维护性方面，66%的服务器存在代码异味，14.4%含有十个与传统开源软件项目重叠的bug模式。&lt;h4&gt;结论&lt;/h4&gt;需要开发针对MCP的特定漏洞检测技术，同时强调传统分析和重构实践的价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管基础模型（如GPT-4）在金融和软件工程等领域得到广泛应用，但依赖文本界面限制了这些模型在实际世界中的交互。为了解决这个问题，FM提供商引入了工具调用，导致具有不同工具接口的框架大量涌现。到2024年底，Anthropic引入了模型上下文协议（MCP）以标准化这个工具生态系统，它已成为事实上的标准，每周有超过八百万次的SDK下载。尽管得到了采用，但MCP的AI驱动、非确定性控制流为可持续性、安全和可维护性引入了新的风险，需要更深入的考察。为此，我们提出了对MCP服务器的首次大规模实证研究。使用最先进的健康指标和混合分析流程，结合通用静态分析工具和MCP特定扫描器，我们评估了1,899个开源MCP服务器，以评估其健康、安全和可维护性。尽管MCP服务器表现出强大的健康指标，但我们发现了八个不同的漏洞——其中只有三个与传统软件漏洞重叠。7.2%的服务器含有通用漏洞，5.5%表现出MCP特定工具中毒。在可维护性方面，尽管66%的服务器存在代码异味，但14.4%含有十个与传统开源软件项目重叠的bug模式。这些发现强调了需要开发针对MCP的特定漏洞检测技术，同时重申了传统分析和重构实践的价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although Foundation Models (FMs), such as GPT-4, are increasingly used indomains like finance and software engineering, reliance on textual interfaceslimits these models' real-world interaction. To address this, FM providersintroduced tool calling-triggering a proliferation of frameworks with distincttool interfaces. In late 2024, Anthropic introduced the Model Context Protocol(MCP) to standardize this tool ecosystem, which has become the de factostandard with over eight million weekly SDK downloads. Despite its adoption,MCP's AI-driven, non-deterministic control flow introduces new risks tosustainability, security, and maintainability, warranting closer examination.  Towards this end, we present the first large-scale empirical study of MCPservers. Using state-of-the-art health metrics and a hybrid analysis pipeline,combining a general-purpose static analysis tool with an MCP-specific scanner,we evaluate 1,899 open-source MCP servers to assess their health, security, andmaintainability. Despite MCP servers demonstrating strong health metrics, weidentify eight distinct vulnerabilities -- only three overlapping withtraditional software vulnerabilities. Additionally, 7.2% of servers containgeneral vulnerabilities and 5.5% exhibit MCP-specific tool poisoning. Regardingmaintainability, while 66% exhibit code smells, 14.4% contain ten bug patternsoverlapping with traditional open-source software projects. These findingshighlight the need for MCP-specific vulnerability detection techniques whilereaffirming the value of traditional analysis and refactoring practices.</description>
      <author>example@mail.com (Mohammed Mehedi Hasan, Hao Li, Emad Fallahzadeh, Gopi Krishnan Rajbahadur, Bram Adams, Ahmed E. Hassan)</author>
      <guid isPermaLink="false">2506.13538v3</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>A Gravity-informed Spatiotemporal Transformer for Human Activity Intensity Prediction</title>
      <link>http://arxiv.org/abs/2506.13678v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 13 figures, under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Gravityformer的物理信息深度学习框架，用于预测人类活动强度，通过改进Transformer注意力机制，结合万有引力定律和空间交互约束，提高了空间相关性建模的准确性。&lt;h4&gt;背景&lt;/h4&gt;尽管在建模人类活动的动态时空模式方面取得了巨大进步，但大多数现有方法，包括空间时间图神经网络（ST-GNNs），忽略了空间交互的物理约束和空间相关性建模中的过平滑现象。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，本文旨在提出一种新的方法来更准确地预测人类活动强度。&lt;h4&gt;方法&lt;/h4&gt;Gravityformer通过以下三个方面进行改进：(1) 基于流入和流出估计两个空间明确的质量参数；(2) 使用空间交互的封闭形式解来建模单元间交互的可能性，以约束空间建模的随机性；(3) 利用学习到的空间交互来引导和缓解Transformer注意力矩阵中的过平滑现象。&lt;h4&gt;主要发现&lt;/h4&gt;系统实验表明，该方法在六个真实世界的大规模活动数据集上，在定量和定性方面都优于现有方法。此外，学习到的重力注意力矩阵可以根据地理定律进行解耦和解释。&lt;h4&gt;结论&lt;/h4&gt;这项工作为将物理定律与深度学习相结合以进行时空预测学习提供了新的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类活动强度预测对许多基于位置的服务至关重要。尽管在建模人类活动的动态时空模式方面取得了巨大进步，但大多数现有方法，包括空间时间图神经网络（ST-GNNs），忽略了空间交互的物理约束和空间相关性建模中的过平滑现象。为了解决这些局限性，本文提出了一种物理信息深度学习框架，即重力信息时空变换器（Gravityformer），通过改进变换器注意力机制，结合万有引力定律和空间交互约束。具体来说，它：（1）基于流入和流出估计两个空间明确的质量参数；（2）使用空间交互的封闭形式解来建模单元间交互的可能性，以约束空间建模的随机性；（3）利用学习到的空间交互来引导和缓解变换器注意力矩阵中的过平滑现象。通过所提出的自适应重力模型，可以明确地模拟人类活动的潜在规律。此外，提出了一种并行时空图卷积变换器结构，以在耦合空间和时间学习之间实现平衡。在六个真实世界的大规模活动数据集上的系统实验表明，与现有方法相比，我们的方法在定量和定性方面都具有优越性。此外，根据地理定律，学习到的重力注意力矩阵可以进行解耦和解释。这项工作为将物理定律与深度学习相结合以进行时空预测学习提供了新的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human activity intensity prediction is a crucial to many location-basedservices. Although tremendous progress has been made to model dynamicspatiotemporal patterns of human activity, most existing methods, includingspatiotemporal graph neural networks (ST-GNNs), overlook physical constraintsof spatial interactions and the over-smoothing phenomenon in spatialcorrelation modeling. To address these limitations, this work proposes aphysics-informed deep learning framework, namely Gravity-informedSpatiotemporal Transformer (Gravityformer) by refining transformer attention tointegrate the universal law of gravitation and explicitly incorporatingconstraints from spatial interactions. Specifically, it (1) estimates twospatially explicit mass parameters based on inflow and outflow, (2) models thelikelihood of cross-unit interaction using closed-form solutions of spatialinteractions to constrain spatial modeling randomness, and (3) utilizes thelearned spatial interaction to guide and mitigate the over-smoothing phenomenonin transformer attention matrices. The underlying law of human activity can beexplicitly modeled by the proposed adaptive gravity model. Moreover, a parallelspatiotemporal graph convolution transformer structure is proposed forachieving a balance between coupled spatial and temporal learning. Systematicexperiments on six real-world large-scale activity datasets demonstrate thequantitative and qualitative superiority of our approach over state-of-the-artbenchmarks. Additionally, the learned gravity attention matrix can bedisentangled and interpreted based on geographical laws. This work provides anovel insight into integrating physical laws with deep learning forspatiotemporal predictive learning.</description>
      <author>example@mail.com (Yi Wang, Zhenghong Wang, Fan Zhang, Chengling Tang, Chaogui Kang, Di Zhu, Zhongfu Ma, Sijie Ruan, Weiyu Zhang, Yu Zheng, Philip S. Yu, Yu Liu)</author>
      <guid isPermaLink="false">2506.13678v2</guid>
      <pubDate>Thu, 19 Jun 2025 14:14:35 +0800</pubDate>
    </item>
    <item>
      <title>Self-Predictive Representations for Combinatorial Generalization in Behavioral Cloning</title>
      <link>http://arxiv.org/abs/2506.10137v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种简单而有效的表示学习目标，即增强型GCBC（BYOL-γ GCBC），该目标不仅能够在有限MDP情况下理论近似后继表示，而不需要对比样本或TD学习，而且在实际任务中表现出竞争力的性能。&lt;h4&gt;背景&lt;/h4&gt;行为克隆（BC）方法在机器人等领域的监督学习中被用来从人类演示中学习策略。目标条件化这些策略可以使得一个通用策略捕捉到离线数据集中包含的多种行为。&lt;h4&gt;目的&lt;/h4&gt;研究如何提高目标条件化行为克隆（GCBC）方法在零样本任务中的泛化能力，特别是在需要基于新颖状态-目标对的组合泛化任务中。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种新的表示学习目标，即BYOL-γ增强型GCBC，该方法能够学习到具有时间一致性的后继表示，并避免了对比样本和TD学习的依赖。&lt;h4&gt;主要发现&lt;/h4&gt;通过鼓励在表示空间中的时间一致性，可以促进组合泛化。后继表示能够很好地封装这一特性，而本文提出的方法能够在不使用对比样本或TD学习的情况下，在需要组合泛化的挑战性任务中实现有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在理论上近似后继表示，并在实际任务中表现出良好的泛化能力，为GCBC方法在组合泛化任务中的应用提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：使用监督学习（SL）训练的行为克隆（BC）方法是在机器人等领域的演示中学习策略的有效途径。通过目标条件化这些策略，可以使得一个通用策略捕获离线数据集中包含的多种行为。尽管目标条件化行为克隆（GCBC）方法在分布训练任务上表现良好，但它们并不一定能够泛化到需要基于新颖状态-目标对的零样本任务，即组合泛化。部分原因可以归因于行为克隆学习到的状态表示中的时间一致性不足；如果时间相关的状态被编码到相似的潜在表示中，那么新颖状态-目标对的分布外间隙将会减小。因此，鼓励在表示空间中的时间一致性应该有助于促进组合泛化。后继表示，它封装了从当前状态访问的未来状态分布，很好地封装了这一特性。然而，以前用于学习后继表示的方法依赖于对比样本、时序差异（TD）学习或两者。在这项工作中，我们提出了一种简单而有效的表示学习目标，即BYOL-γ增强型GCBC，它不仅能够在有限MDP情况下理论近似后继表示，而不需要对比样本或TD学习，而且在实际任务中表现出有竞争力的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Behavioral cloning (BC) methods trained with supervised learning (SL) are aneffective way to learn policies from human demonstrations in domains likerobotics. Goal-conditioning these policies enables a single generalist policyto capture diverse behaviors contained within an offline dataset. Whilegoal-conditioned behavior cloning (GCBC) methods can perform well onin-distribution training tasks, they do not necessarily generalize zero-shot totasks that require conditioning on novel state-goal pairs, i.e. combinatorialgeneralization. In part, this limitation can be attributed to a lack oftemporal consistency in the state representation learned by BC; if temporallyrelated states are encoded to similar latent representations, then theout-of-distribution gap for novel state-goal pairs would be reduced. Hence,encouraging this temporal consistency in the representation space shouldfacilitate combinatorial generalization. Successor representations, whichencode the distribution of future states visited from the current state, nicelyencapsulate this property. However, previous methods for learning successorrepresentations have relied on contrastive samples, temporal-difference (TD)learning, or both. In this work, we propose a simple yet effectiverepresentation learning objective, $\text{BYOL-}\gamma$ augmented GCBC, whichis not only able to theoretically approximate the successor representation inthe finite MDP case without contrastive samples or TD learning, but also,results in competitive empirical performance across a suite of challengingtasks requiring combinatorial generalization.</description>
      <author>example@mail.com (Daniel Lawson, Adriana Hugessen, Charlotte Cloutier, Glen Berseth, Khimya Khetarpal)</author>
      <guid isPermaLink="false">2506.10137v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
  <item>
      <title>SUSEP-Net: Simulation-Supervised and Contrastive Learning-based Deep Neural Networks for Susceptibility Source Separation</title>
      <link>http://arxiv.org/abs/2506.13293v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为SUSEP-Net的新型定量磁化率映射（QSM）算法，用于分离人脑中不同类型的磁化率源，并在模拟和实际数据上展示了其优越性。&lt;h4&gt;背景&lt;/h4&gt;定量磁化率映射在量化人脑中的磁化率分布方面很有价值，但由于磁化率源（顺磁性、抗磁性）可能在单个体素中同时存在并相互抵消，传统的QSM图像无法准确反映磁化率分布。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够分离磁化率源的方法，并从QSM图中提取亚体素信息。&lt;h4&gt;方法&lt;/h4&gt;该方法训练了一个双分支U-net，使用模拟监督训练策略，并包含一个对比学习框架，以在特别设计的编码器和解码器中的分支特定引导特征与潜在特征之间施加基于相似性的约束。&lt;h4&gt;主要发现&lt;/h4&gt;SUSEP-Net在模拟和实际数据上（包括健康人和病理患者）与三种最先进的磁化率源分离方法（APART-QSM、chi-separation、chi-sepnet）进行了比较，结果显示SUSEP-Net在数值指标、高对比度出血和钙化病变对比度以及减少病理条件脑中的伪影方面均有所提升。&lt;h4&gt;结论&lt;/h4&gt;SUSEP-Net能够准确分离磁化率源，并具有良好的准确性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Quantitative susceptibility mapping (QSM) provides a valuable tool for quantifying susceptibility distributions in human brains; however, two types of opposing susceptibility sources (i.e., paramagnetic and diamagnetic), may coexist in a single voxel, and cancel each other out in net QSM images. Susceptibility source separation techniques enable the extraction of sub-voxel information from QSM maps. This study proposes a novel SUSEP-Net for susceptibility source separation by training a dual-branch U-net with a simulation-supervised training strategy. In addition, a contrastive learning framework is included to explicitly impose similarity-based constraints between the branch-specific guidance features in specially-designed encoders and the latent features in the decoders. Comprehensive experiments were carried out on both simulated and in vivo data, including healthy subjects and patients with pathological conditions, to compare SUSEP-Net with three state-of-the-art susceptibility source separation methods (i.e., APART-QSM, chi-separation, and chi-sepnet). SUSEP-Net consistently showed improved results compared with the other three methods, with better numerical metrics, improved high-intensity hemorrhage and calcification lesion contrasts, and reduced artifacts in brains with pathological conditions. In addition, experiments on an agarose gel phantom data were conducted to validate the accuracy and the generalization capability of SUSEP-Net.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantitative susceptibility mapping (QSM) provides a valuable tool forquantifying susceptibility distributions in human brains; however, two types ofopposing susceptibility sources (i.e., paramagnetic and diamagnetic), maycoexist in a single voxel, and cancel each other out in net QSM images.Susceptibility source separation techniques enable the extraction of sub-voxelinformation from QSM maps. This study proposes a novel SUSEP-Net forsusceptibility source separation by training a dual-branch U-net with asimulation-supervised training strategy. In addition, a contrastive learningframework is included to explicitly impose similarity-based constraints betweenthe branch-specific guidance features in specially-designed encoders and thelatent features in the decoders. Comprehensive experiments were carried out onboth simulated and in vivo data, including healthy subjects and patients withpathological conditions, to compare SUSEP-Net with three state-of-the-artsusceptibility source separation methods (i.e., APART-QSM, \c{hi}-separation,and \c{hi}-sepnet). SUSEP-Net consistently showed improved results comparedwith the other three methods, with better numerical metrics, improvedhigh-intensity hemorrhage and calcification lesion contrasts, and reducedartifacts in brains with pathological conditions. In addition, experiments onan agarose gel phantom data were conducted to validate the accuracy and thegeneralization capability of SUSEP-Net.</description>
      <author>example@mail.com (Min Li, Chen Chen, Zhenghao Li, Yin Liu, Shanshan Shan, Peng Wu, Pengfei Rong, Feng Liu, G. Bruce Pike, Alan H. Wilman, Hongfu Sun, Yang Gao)</author>
      <guid isPermaLink="false">2506.13293v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in Cluttered Scenes</title>
      <link>http://arxiv.org/abs/2506.14317v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ClutterDexGrasp的框架，用于在复杂杂乱场景中进行目标导向的灵巧抓取，解决了现有方法在复杂场景中的局限性。&lt;h4&gt;背景&lt;/h4&gt;在杂乱场景中进行灵巧抓取面临物体几何形状多样性、遮挡和潜在碰撞等挑战，现有方法主要关注单物体抓取或抓取姿态预测，缺乏对复杂场景的处理。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够在现实世界中实现零样本部署并保持鲁棒泛化的方法，以解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种两阶段教师-学生框架，其中教师策略在模拟环境中使用杂乱密度课程学习进行训练，结合了新颖的几何和空间嵌入场景表示以及全面的安全课程，通过模仿学习，将教师的知识提炼到一个学生3D扩散策略（DP3）中，该策略在部分点云观测上运行。&lt;h4&gt;主要发现&lt;/h4&gt;ClutterDexGrasp是第一个零样本模拟到现实闭环系统，用于杂乱场景中的目标导向灵巧抓取，展示了在不同物体和布局上的鲁棒性能。&lt;h4&gt;结论&lt;/h4&gt;ClutterDexGrasp框架在复杂杂乱场景中实现了有效的目标导向灵巧抓取，为该领域的研究提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, a framework named ClutterDexGrasp is proposed for dexterous grasping with target orientation in cluttered scenes, addressing the limitations of existing methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dexterous grasping in cluttered scenes presents significant challenges due todiverse object geometries, occlusions, and potential collisions. Existingmethods primarily focus on single-object grasping or grasp-pose predictionwithout interaction, which are insufficient for complex, cluttered scenes.Recent vision-language-action models offer a potential solution but requireextensive real-world demonstrations, making them costly and difficult to scale.To address these limitations, we revisit the sim-to-real transfer pipeline anddevelop key techniques that enable zero-shot deployment in reality whilemaintaining robust generalization. We propose ClutterDexGrasp, a two-stageteacher-student framework for closed-loop target-oriented dexterous grasping incluttered scenes. The framework features a teacher policy trained in simulationusing clutter density curriculum learning, incorporating both a novel geometryand spatially-embedded scene representation and a comprehensive safetycurriculum, enabling general, dynamic, and safe grasping behaviors. Throughimitation learning, we distill the teacher's knowledge into a student 3Ddiffusion policy (DP3) that operates on partial point cloud observations. Tothe best of our knowledge, this represents the first zero-shot sim-to-realclosed-loop system for target-oriented dexterous grasping in cluttered scenes,demonstrating robust performance across diverse objects and layouts. Moredetails and videos are available at https://clutterdexgrasp.github.io/.</description>
      <author>example@mail.com (Zeyuan Chen, Qiyang Yan, Yuanpei Chen, Tianhao Wu, Jiyao Zhang, Zihan Ding, Jinzhou Li, Yaodong Yang, Hao Dong)</author>
      <guid isPermaLink="false">2506.14317v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>AMPLIFY: Actionless Motion Priors for Robot Learning from Videos</title>
      <link>http://arxiv.org/abs/2506.14198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了AMPLIFY，一种利用大规模视频数据的新框架，通过编码视觉动态为紧凑的离散运动标记，解决了动作标注数据稀缺和昂贵的问题，同时实现了动作推断与视觉运动预测的分离。&lt;h4&gt;背景&lt;/h4&gt;动作标注数据稀缺且成本高，限制了学习策略的泛化。而动作自由的视频数据丰富，但将其转换为有效的策略是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，能够利用动作自由视频数据，同时提高学习策略的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;将视觉运动预测与动作推断分离，分别训练前向动力学模型和逆动力学模型，并在大量的动作自由视频和有限的动作标注示例上训练。&lt;h4&gt;主要发现&lt;/h4&gt;学习的动力学模型准确度高，相较于先前方法，MSE降低了3.7倍，像素预测准确性提高了2.5倍以上。在下游策略学习中，动力学预测使得低数据环境下策略学习提高了1.2-2.2倍，从动作自由的人类视频中学习提高了1.4倍，并且首次将零分布动作数据泛化到LIBERO任务中。&lt;h4&gt;结论&lt;/h4&gt;AMPLIFY能够通过利用异构数据源构建高效、可泛化的世界模型，为机器人控制以外的领域提供了灵活的潜在世界模型，提高了视频预测质量。&lt;h4&gt;翻译&lt;/h4&gt;Action-labeled data for robotics is scarce and expensive, limiting the generalization of learned policies. In contrast, vast amounts of action-free video data are readily available, but translating these observations into effective policies remains a challenge. We introduce AMPLIFY, a novel framework that leverages large-scale video data by encoding visual dynamics into compact, discrete motion tokens derived from keypoint trajectories. Our modular approach separates visual motion prediction from action inference, decoupling the challenges of learning what motion defines a task from how robots can perform it. We train a forward dynamics model on abundant action-free videos and an inverse dynamics model on a limited set of action-labeled examples, allowing for independent scaling. Extensive evaluations demonstrate that the learned dynamics are both accurate, achieving up to 3.7x better MSE and over 2.5x better pixel prediction accuracy compared to prior approaches, and broadly useful. In downstream policy learning, our dynamics predictions enable a 1.2-2.2x improvement in low-data regimes, a 1.4x average improvement by learning from action-free human videos, and the first generalization to LIBERO tasks from zero in-distribution action data. Beyond robotic control, we find the dynamics learned by AMPLIFY to be a versatile latent world model, enhancing video prediction quality. Our results present a novel paradigm leveraging heterogeneous data sources to build efficient, generalizable world models. More information can be found at https://amplify-robotics.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Action-labeled data for robotics is scarce and expensive, limiting thegeneralization of learned policies. In contrast, vast amounts of action-freevideo data are readily available, but translating these observations intoeffective policies remains a challenge. We introduce AMPLIFY, a novel frameworkthat leverages large-scale video data by encoding visual dynamics into compact,discrete motion tokens derived from keypoint trajectories. Our modular approachseparates visual motion prediction from action inference, decoupling thechallenges of learning what motion defines a task from how robots can performit. We train a forward dynamics model on abundant action-free videos and aninverse dynamics model on a limited set of action-labeled examples, allowingfor independent scaling. Extensive evaluations demonstrate that the learneddynamics are both accurate, achieving up to 3.7x better MSE and over 2.5xbetter pixel prediction accuracy compared to prior approaches, and broadlyuseful. In downstream policy learning, our dynamics predictions enable a1.2-2.2x improvement in low-data regimes, a 1.4x average improvement bylearning from action-free human videos, and the first generalization to LIBEROtasks from zero in-distribution action data. Beyond robotic control, we findthe dynamics learned by AMPLIFY to be a versatile latent world model, enhancingvideo prediction quality. Our results present a novel paradigm leveragingheterogeneous data sources to build efficient, generalizable world models. Moreinformation can be found at https://amplify-robotics.github.io/.</description>
      <author>example@mail.com (Jeremy A. Collins, Loránd Cheng, Kunal Aneja, Albert Wilcox, Benjamin Joffe, Animesh Garg)</author>
      <guid isPermaLink="false">2506.14198v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Expressive Score-Based Priors for Distribution Matching with Geometry-Preserving Regularization</title>
      <link>http://arxiv.org/abs/2506.14607v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  32 pages, 20 figures. Accepted to ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于分数的分布匹配（DM）方法，通过使用表达式分数先验分布解决传统方法中的偏见和学习挑战。&lt;h4&gt;背景&lt;/h4&gt;分布匹配（DM）是一种通用的域不变表示学习技术，已在公平分类、域适应和域翻译等任务中得到应用。&lt;h4&gt;目的&lt;/h4&gt;提高非参数DM方法的可扩展性，解决参数化DM方法的不稳定性和模式崩溃问题，同时避免通过固定先验或显式密度模型引入的不必要偏见。&lt;h4&gt;方法&lt;/h4&gt;引入了一种基于分数的先验分布训练DM的方法，其中梯度下降的DM训练仅需要先验的得分函数，而不是其密度，允许通过去噪得分匹配训练先验，消除固定先验的偏见，同时避免学习显式先验密度模型的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;该方法比其他基于扩散的先验（如LSGM）具有更好的稳定性和计算效率，并在多个任务上展现出优越的性能。&lt;h4&gt;结论&lt;/h4&gt;基于分数的分布匹配方法是一个稳定且有效的DM方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：分布匹配（DM）是一种多用途的域不变表示学习方法，已被应用于诸如公平分类、域适应和域转换等任务。非参数DM方法在可扩展性方面存在困难，而对抗性DM方法则因不稳定性和模式崩溃而受影响。虽然基于似然的方法是一种有前途的替代方案，但它们往往通过固定的先验或需要显式密度模型（例如流）而引入不必要的偏见，这些模型可能难以训练。我们通过引入一种新的基于似然DM训练方法来解决这一局限性，该方法使用表达式分数先验分布。我们的关键见解是，基于梯度的DM训练只需要先验的得分函数——而不是其密度——这使得我们可以通过去噪得分匹配来训练先验，从而消除固定先验（例如在VAEs中）的偏见，允许更有效地使用几何保持正则化，同时避免学习显式先验密度模型（例如基于流的先验）的挑战。我们的方法还显示出比其他基于扩散的先验（例如LSGM）更好的稳定性和计算效率。此外，实验证明了在多个任务上的优越性能，从而确立了我们的基于分数的方法作为稳定的、有效的分布匹配方法。源代码可在https://github.com/inouye-lab/SAUB处获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Distribution matching (DM) is a versatile domain-invariant representationlearning technique that has been applied to tasks such as fair classification,domain adaptation, and domain translation. Non-parametric DM methods strugglewith scalability and adversarial DM approaches suffer from instability and modecollapse. While likelihood-based methods are a promising alternative, theyoften impose unnecessary biases through fixed priors or require explicitdensity models (e.g., flows) that can be challenging to train. We address thislimitation by introducing a novel approach to training likelihood-based DMusing expressive score-based prior distributions. Our key insight is thatgradient-based DM training only requires the prior's score function -- not itsdensity -- allowing us to train the prior via denoising score matching. Thisapproach eliminates biases from fixed priors (e.g., in VAEs), enabling moreeffective use of geometry-preserving regularization, while avoiding thechallenge of learning an explicit prior density model (e.g., a flow-basedprior). Our method also demonstrates better stability and computationalefficiency compared to other diffusion-based priors (e.g., LSGM). Furthermore,experiments demonstrate superior performance across multiple tasks,establishing our score-based method as a stable and effective approach todistribution matching. Source code available athttps://github.com/inouye-lab/SAUB.</description>
      <author>example@mail.com (Ziyu Gong, Jim Lim, David I. Inouye)</author>
      <guid isPermaLink="false">2506.14607v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Models -- the Future of Fundamental Physics?</title>
      <link>http://arxiv.org/abs/2506.14757v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  33 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了如何利用大型语言模型（LLM）进行跨领域迁移学习，以分析生成SKA数据，并展示了结合LLM和连接网络的方法在宇宙学参数回归和光锥生成中的优越性。&lt;h4&gt;背景&lt;/h4&gt;Transformer作为学习复杂相关性的最新技术，在许多基础物理应用中具有优势，并且已经在跨领域数据上进行了预训练。&lt;h4&gt;目的&lt;/h4&gt;探索是否能够利用大型语言模型进行跨领域迁移学习，以分析生成SKA数据。&lt;h4&gt;方法&lt;/h4&gt;使用Qwen2.5 LLM来分析和生成SKA数据，特别是宇宙大规模结构的三维图，并将LLM与连接网络相结合。&lt;h4&gt;主要发现&lt;/h4&gt;Lightcone LLM（L3M）结合Qwen2.5权重在宇宙学参数回归和光锥生成方面优于标准初始化，并与大小匹配的专用网络相比表现良好。&lt;h4&gt;结论&lt;/h4&gt;结合LLM和连接网络的方法在处理SKA数据方面显示出显著优势，特别是在宇宙学参数回归和光锥生成任务中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For many fundamental physics applications, transformers, as the state of theart in learning complex correlations, benefit from pretraining onquasi-out-of-domain data. The obvious question is whether we can exploit LargeLanguage Models, requiring proper out-of-domain transfer learning. We show howthe Qwen2.5 LLM can be used to analyze and generate SKA data, specifically 3Dmaps of the cosmological large-scale structure for a large part of theobservable Universe. We combine the LLM with connector networks and show, forcosmological parameter regression and lightcone generation, that this LightconeLLM (L3M) with Qwen2.5 weights outperforms standard initialization and comparesfavorably with dedicated networks of matching size.</description>
      <author>example@mail.com (Caroline Heneka, Florian Nieser, Ayodele Ore, Tilman Plehn, Daniel Schiller)</author>
      <guid isPermaLink="false">2506.14757v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Refining music sample identification with a self-supervised graph neural network</title>
      <link>http://arxiv.org/abs/2506.14684v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at International Conference for Music Information Retrieval  (ISMIR) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种轻量级且可扩展的编码架构，用于自动样本识别（ASID），即检测和识别音频录音中被重新用于新音乐作品的部分。&lt;h4&gt;背景&lt;/h4&gt;自动样本识别是音频查询检索领域的一项重要但具有挑战性的任务。尽管音频指纹识别在“真实世界”条件下（如噪声、混响）检索音乐内容方面取得了显著进展，但ASID系统在识别经过音乐修改的样本方面仍然存在困难。&lt;h4&gt;目的&lt;/h4&gt;开发一个对常见音乐制作变换（如时间拉伸、音高变换、效果处理以及背景或叠加音乐）具有鲁棒性的系统。&lt;h4&gt;方法&lt;/h4&gt;提出了一种使用图神经网络和对比学习框架的轻量级编码架构。该模型仅使用当前最先进系统的9%的可训练参数，同时实现了可比的性能，平均平均精度（mAP）达到44.2%。引入了两阶段方法，包括初步的粗略相似性搜索用于候选选择，以及一个拒绝无关匹配并细化检索候选排名的跨注意力分类器。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在处理短查询时表现出色，使用了针对Sample100数据集的新精细粒度注释进行了基准测试。&lt;h4&gt;结论&lt;/h4&gt;提出的系统在保持高性能的同时，显著减少了计算资源的需求，并提高了检索质量。&lt;h4&gt;翻译&lt;/h4&gt;摘要：自动样本识别（ASID），即检测和识别音频录音中被重新用于新音乐作品的部分，是音频查询检索领域的一项基本但具有挑战性的任务。尽管与音频指纹识别相关的任务在“真实世界”条件下（如噪声、混响）检索音乐内容方面取得了显著进展，但ASID系统在识别经过音乐修改的样本方面仍然存在困难。因此，一个对常见音乐制作变换（如时间拉伸、音高变换、效果处理以及背景或叠加音乐）具有鲁棒性的系统是一个重要的开放挑战。在本工作中，我们提出了一种在对比学习框架内使用图神经网络的轻量级和可扩展的编码架构。与当前最先进系统相比，我们的模型仅使用9%的可训练参数，同时实现了可比的性能，平均平均精度（mAP）达到44.2%。为了提高检索质量，我们引入了一种两阶段方法，包括初步的粗略相似性搜索用于候选选择，随后是一个跨注意力分类器，用于拒绝无关匹配并细化检索候选的排名——这是先前模型所缺乏的一种基本能力。此外，由于现实世界应用中的查询通常较短，我们使用针对Sample100数据集的新精细粒度注释对该系统进行了短查询的基准测试，并将这些注释作为本工作的一部分发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic sample identification (ASID), the detection and identification ofportions of audio recordings that have been reused in new musical works, is anessential but challenging task in the field of audio query-based retrieval.While a related task, audio fingerprinting, has made significant progress inaccurately retrieving musical content under "real world" (noisy, reverberant)conditions, ASID systems struggle to identify samples that have undergonemusical modifications. Thus, a system robust to common music productiontransformations such as time-stretching, pitch-shifting, effects processing,and underlying or overlaying music is an important open challenge.  In this work, we propose a lightweight and scalable encoding architectureemploying a Graph Neural Network within a contrastive learning framework. Ourmodel uses only 9% of the trainable parameters compared to the currentstate-of-the-art system while achieving comparable performance, reaching a meanaverage precision (mAP) of 44.2%.  To enhance retrieval quality, we introduce a two-stage approach consisting ofan initial coarse similarity search for candidate selection, followed by across-attention classifier that rejects irrelevant matches and refines theranking of retrieved candidates - an essential capability absent in priormodels. In addition, because queries in real-world applications are often shortin duration, we benchmark our system for short queries using new fine-grainedannotations for the Sample100 dataset, which we publish as part of this work.</description>
      <author>example@mail.com (Aditya Bhattacharjee, Ivan Meresman Higgs, Mark Sandler, Emmanouil Benetos)</author>
      <guid isPermaLink="false">2506.14684v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Leader360V: The Large-scale, Real-world 360 Video Dataset for Multi-task Learning in Diverse Environment</title>
      <link>http://arxiv.org/abs/2506.14271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 16 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了Leader360V，这是第一个用于实例分割和跟踪的大规模、标注的真实世界360视频数据集。该数据集具有高场景多样性，包括室内、城市、自然和动态户外场景。论文还设计了一个自动标注流程，以自动化标注过程。&lt;h4&gt;背景&lt;/h4&gt;360视频由于其超大的视野（360X180），在场景理解任务（如分割和跟踪）中至关重要，尤其是在自动驾驶和机器人等领域。然而，由于360视频的球形特性和内容不连续性，标注成本高且复杂。&lt;h4&gt;目的&lt;/h4&gt;开发一个大规模、标注的真实世界360视频数据集，并设计一个自动标注流程，以降低标注成本并提高效率。&lt;h4&gt;方法&lt;/h4&gt;设计了一个自动标注流程，包括三个阶段：初始标注阶段、自动细化标注阶段和人工修订阶段。该流程结合了预训练的2D分割器和大型语言模型，以自动化标注过程。&lt;h4&gt;主要发现&lt;/h4&gt;Leader360V数据集具有高场景多样性，自动标注流程有效降低了标注成本，并通过实验证明显著提高了360视频分割和跟踪的性能。&lt;h4&gt;结论&lt;/h4&gt;Leader360V为更可扩展的360场景理解铺平了道路，并为自动驾驶和机器人等领域提供了重要的数据支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要：360视频以其超大的视野（360X180）捕捉完整的周围场景。这使得360场景理解任务，例如分割和跟踪，对于应用至关重要，如自动驾驶、机器人。然而，由于最近出现的基座模型，社区受到缺乏大规模、标注的真实世界数据集的限制。这是由于固有的球形特性，例如极地地区的严重扭曲和内容不连续性，使得标注成本高且复杂。本文介绍了Leader360V，这是第一个用于实例分割和跟踪的大规模、标注的真实世界360视频数据集。我们的数据集具有高场景多样性，从室内和城市环境到自然和动态户外场景。为了自动化标注，我们设计了一个自动标注流程，该流程巧妙地协调预训练的2D分割器和大型语言模型，以促进标注。该流程在三个新颖的阶段中运行。具体来说，在初始标注阶段，我们引入了一个语义和扭曲感知的细化模块，该模块将来自多个2D分割器的对象掩码提议与LLM验证的语义标签相结合。然后，这些标签被转换为掩码提示，以引导SAM2生成对后续帧的扭曲感知掩码。在自动细化标注阶段，通过再次应用SDR或解决靠近水平边界的断续性来纠正缺失或不完整的区域。最后，在人工修订阶段，结合LLMs和人工标注员进一步细化和验证标注。广泛的用户研究和评估证明了我们标注流程的有效性。同时，实验证实Leader360V显著提高了360视频分割和跟踪的模型性能，为更可扩展的360场景理解铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 360 video captures the complete surrounding scenes with the ultra-large fieldof view of 360X180. This makes 360 scene understanding tasks, eg, segmentationand tracking, crucial for appications, such as autonomous driving, robotics.With the recent emergence of foundation models, the community is, however,impeded by the lack of large-scale, labelled real-world datasets. This iscaused by the inherent spherical properties, eg, severe distortion in polarregions, and content discontinuities, rendering the annotation costly yetcomplex. This paper introduces Leader360V, the first large-scale, labeledreal-world 360 video datasets for instance segmentation and tracking. Ourdatasets enjoy high scene diversity, ranging from indoor and urban settings tonatural and dynamic outdoor scenes. To automate annotation, we design anautomatic labeling pipeline, which subtly coordinates pre-trained 2D segmentorsand large language models to facilitate the labeling. The pipeline operates inthree novel stages. Specifically, in the Initial Annotation Phase, we introducea Semantic- and Distortion-aware Refinement module, which combines object maskproposals from multiple 2D segmentors with LLM-verified semantic labels. Theseare then converted into mask prompts to guide SAM2 in generatingdistortion-aware masks for subsequent frames. In the Auto-Refine AnnotationPhase, missing or incomplete regions are corrected either by applying the SDRagain or resolving the discontinuities near the horizontal borders. The ManualRevision Phase finally incorporates LLMs and human annotators to further refineand validate the annotations. Extensive user studies and evaluationsdemonstrate the effectiveness of our labeling pipeline. Meanwhile, experimentsconfirm that Leader360V significantly enhances model performance for 360 videosegmentation and tracking, paving the way for more scalable 360 sceneunderstanding.</description>
      <author>example@mail.com (Weiming Zhang, Dingwen Xiao, Aobotao Dai, Yexin Liu, Tianbo Pan, Shiqi Wen, Lei Chen, Lin Wang)</author>
      <guid isPermaLink="false">2506.14271v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Scaling-Up the Pretraining of the Earth Observation Foundation Model PhilEO to the MajorTOM Dataset</title>
      <link>http://arxiv.org/abs/2506.14765v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 9 figures, 1 table, 29 references&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究如何通过预训练地球观测（EO）基础模型（FMs）来高效利用大量数据，并展示了PhilEO Geo-Aware U-Net模型在处理大规模无标签数据集上的扩展应用及其在道路密度估计、建筑密度回归和土地覆盖语义分割等任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;随着Copernicus Sentinel-2卫星等地球观测卫星产生的数据量激增，需要有效利用这些数据，预训练EO基础模型成为关键。&lt;h4&gt;目的&lt;/h4&gt;目的是通过在大型无标签数据集上预训练EO基础模型，以实现用少量标注数据进行高效微调，并提升不同下游任务的表现。&lt;h4&gt;方法&lt;/h4&gt;本研究在MajorTOM（23TB）和FastTOM（2TB）两个数据集上扩展了PhilEO Geo-Aware U-Net模型，并开发了不同参数和架构的PhilEO模型变体。在PhilEO Bench上对模型进行微调，并评估了其性能。&lt;h4&gt;主要发现&lt;/h4&gt;PhilEO 44M MajorTOM 23TB模型在道路密度回归的所有n-shots表现优于PhilEO Globe 0.5TB 44M模型。PhilEO 200M FastTOM在道路密度估计和建筑密度回归的大多数n-shots中表现优于其他模型。通过PhilEO Bench验证了数据集和模型扩展的有效性，并研究了从U-Net CNN到Vision Transformers（ViT）的架构扩展影响。&lt;h4&gt;结论&lt;/h4&gt;预训练的PhilEO模型在不同数据集和架构上表现良好，能够有效处理大规模地球观测数据，并在多个下游任务中取得优异性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Today, Earth Observation (EO) satellites generate massive volumes of data,with the Copernicus Sentinel-2 constellation alone producing approximately1.6TB per day. To fully exploit this information, it is essential to pretrainEO Foundation Models (FMs) on large unlabeled datasets, enabling efficientfine-tuning for several different downstream tasks with minimal labeled data.In this work, we present the scaling-up of our recently proposed EO FoundationModel, PhilEO Geo-Aware U-Net, on the unlabeled 23TB dataset MajorTOM, whichcovers the vast majority of the Earth's surface, as well as on the specializedsubset FastTOM 2TB that does not include oceans and ice. We develop and studyvarious PhilEO model variants with different numbers of parameters andarchitectures. Finally, we fine-tune the models on the PhilEO Bench for roaddensity estimation, building density pixel-wise regression, and land coversemantic segmentation, and we evaluate the performance. Our results demonstratethat for all n-shots for road density regression, the PhilEO 44M MajorTOM 23TBmodel outperforms PhilEO Globe 0.5TB 44M. We also show that for most n-shotsfor road density estimation and building density regression, PhilEO 200MFastTOM outperforms all the other models. The effectiveness of both dataset andmodel scaling is validated using the PhilEO Bench. We also study the impact ofarchitecture scaling, transitioning from U-Net Convolutional Neural Networks(CNN) to Vision Transformers (ViT).</description>
      <author>example@mail.com (Nikolaos Dionelis, Jente Bosmans, Riccardo Musto, Giancarlo Paoletti, Simone Sarti, Giacomo Cascarano, Casper Fibaek, Luke Camilleri, Bertrand Le Saux, Nicolas Longépé)</author>
      <guid isPermaLink="false">2506.14765v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>EVA02-AT: Egocentric Video-Language Understanding with Spatial-Temporal Rotary Positional Embeddings and Symmetric Optimization</title>
      <link>http://arxiv.org/abs/2506.14356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EVA02-AT的EVA02系列视频语言基础模型，专门用于解决自视角视频理解任务中的效率与时空建模问题。&lt;h4&gt;背景&lt;/h4&gt;自视角视频语言理解需要高效的时空建模，现有方法存在预训练成本过高、时空编码无效和软标签多实例检索学习目标不精确等挑战。&lt;h4&gt;目的&lt;/h4&gt;提高自视角视频语言理解的效率与准确性。&lt;h4&gt;方法&lt;/h4&gt;EVA02-AT通过单阶段预训练将基于图像的CLIP模型转换为统一的视频编码器，引入时空旋转位置嵌入和联合注意力机制，以及对称多相似度（SMS）损失和新型训练框架来优化软标签的学习目标。&lt;h4&gt;主要发现&lt;/h4&gt;EVA02-AT在Ego4D、EPIC-Kitchens-100和Charades-Ego数据集上实现了零样本和微调设置下的最先进性能，且参数更少。使用SMS损失的模型在多实例检索基准测试中表现显著提升。&lt;h4&gt;结论&lt;/h4&gt;EVA02-AT为自视角视频语言理解任务提供了高效且准确的方法，其代码和模型已公开。&lt;h4&gt;翻译&lt;/h4&gt;The paper introduces EVA02-AT, a suite of EVA02-based video-language foundation models tailored for egocentric video understanding tasks. EVA02-AT efficiently transfers an image-based CLIP model into a unified video encoder via a single-stage pretraining, introduces spatial-temporal rotary positional embeddings along with joint attention to encode spatial and temporal information, and utilizes Symmetric Multi-Similarity (SMS) loss and a novel training framework to refine the learning objectives for soft labels. Extensive experiments demonstrate that EVA02-AT achieves state-of-the-art performance across diverse egocentric video-language tasks with fewer parameters. Models with our SMS loss also show significant performance gains on multi-instance retrieval benchmarks. Our code and models are publicly available at https://github.com/xqwang14/EVA02-AT.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Egocentric video-language understanding demands both high efficiency andaccurate spatial-temporal modeling. Existing approaches face three keychallenges: 1) Excessive pre-training cost arising from multi-stagepre-training pipelines, 2) Ineffective spatial-temporal encoding due tomanually split 3D rotary positional embeddings that hinder featureinteractions, and 3) Imprecise learning objectives in soft-label multi-instanceretrieval, which neglect negative pair correlations. In this paper, weintroduce EVA02-AT, a suite of EVA02-based video-language foundation modelstailored to egocentric video understanding tasks. EVA02-AT first efficientlytransfers an image-based CLIP model into a unified video encoder via asingle-stage pretraining. Second, instead of applying rotary positionalembeddings to isolated dimensions, we introduce spatial-temporal rotarypositional embeddings along with joint attention, which can effectively encodeboth spatial and temporal information on the entire hidden dimension. Thisjoint encoding of spatial-temporal features enables the model to learncross-axis relationships, which are crucial for accurately modeling motion andinteraction in videos. Third, focusing on multi-instance video-languageretrieval tasks, we introduce the Symmetric Multi-Similarity (SMS) loss and anovel training framework that advances all soft labels for both positive andnegative pairs, providing a more precise learning objective. Extensiveexperiments on Ego4D, EPIC-Kitchens-100, and Charades-Ego under zero-shot andfine-tuning settings demonstrate that EVA02-AT achieves state-of-the-artperformance across diverse egocentric video-language tasks with fewerparameters. Models with our SMS loss also show significant performance gains onmulti-instance retrieval benchmarks. Our code and models are publicly availableat https://github.com/xqwang14/EVA02-AT .</description>
      <author>example@mail.com (Xiaoqi Wang, Yi Wang, Lap-Pui Chau)</author>
      <guid isPermaLink="false">2506.14356v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>A Point Cloud Completion Approach for the Grasping of Partially Occluded Objects and Its Applications in Robotic Strawberry Harvesting</title>
      <link>http://arxiv.org/abs/2506.14066v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种针对机器人采摘水果中物体遮挡问题的端到端框架，用于有效进行目标检测、分割和抓取规划。&lt;h4&gt;背景&lt;/h4&gt;在非结构化环境中，物体遮挡给设计抓取算法带来了巨大挑战。&lt;h4&gt;目的&lt;/h4&gt;以草莓采摘为案例研究，开发一种方法来解决部分遮挡物体引起的问题。&lt;h4&gt;方法&lt;/h4&gt;该方法包括点云去噪和分割以准确定位果实，应用点云补全模型创建密集的3D草莓重建，目标选择关注成熟草莓，其他分类为障碍物，并将精炼的点云转换为占用图进行碰撞感知的运动规划。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法具有高形状重建精度，与现有最佳方法的Chamfer Distance最低，抓取成功率显著提高至79.17%，实际草莓采摘中的成功尝试比率为89.58%。此外，该方法将障碍物碰撞率从43.33%降低到13.95%，显示出其在提高抓取质量和安全方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;该管道显著提高了自主草莓采摘的效率，推进了更高效、可靠的机器人水果采摘系统。&lt;h4&gt;翻译&lt;/h4&gt;在机器人水果采摘应用中，管理非结构化环境中的物体遮挡是一个重大挑战。以草莓采摘为案例研究，我们提出了一种端到端框架，用于有效进行目标检测、分割和抓取规划，以应对部分遮挡物体引起的问题。我们的策略从点云去噪和分割开始，以准确定位果实。为了补偿由于遮挡造成的扫描不完整，我们应用点云补全模型创建草莓的密集3D重建。目标选择侧重于成熟的草莓，而将其他分类为障碍物，随后将精炼的点云转换为占用图，以进行碰撞感知的运动规划。我们的实验结果表明，与现有最佳方法相比，具有最低的Chamfer Distance（1.10毫米），抓取成功率显著提高至79.17%，在现实世界的草莓采摘中实现了89.58%的成功尝试比率。此外，我们的方法将障碍物碰撞率从43.33%降低到13.95%，突显了其在提高抓取质量和安全方面的有效性。这一流程显著提高了自主草莓采摘的效率，推进了更高效、可靠的机器人水果采摘系统。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In robotic fruit picking applications, managing object occlusion inunstructured settings poses a substantial challenge for designing graspingalgorithms. Using strawberry harvesting as a case study, we present anend-to-end framework for effective object detection, segmentation, and graspplanning to tackle this issue caused by partially occluded objects. Ourstrategy begins with point cloud denoising and segmentation to accuratelylocate fruits. To compensate for incomplete scans due to occlusion, we apply apoint cloud completion model to create a dense 3D reconstruction of thestrawberries. The target selection focuses on ripe strawberries whilecategorizing others as obstacles, followed by converting the refined pointcloud into an occupancy map for collision-aware motion planning. Ourexperimental results demonstrate high shape reconstruction accuracy, with thelowest Chamfer Distance compared to state-of-the-art methods with 1.10 mm, andsignificantly improved grasp success rates of 79.17%, yielding an overallsuccess-to-attempt ratio of 89.58\% in real-world strawberry harvesting.Additionally, our method reduces the obstacle hit rate from 43.33% to 13.95%,highlighting its effectiveness in improving both grasp quality and safetycompared to prior approaches. This pipeline substantially improves autonomousstrawberry harvesting, advancing more efficient and reliable robotic fruitpicking systems.</description>
      <author>example@mail.com (Ali Abouzeid, Malak Mansour, Chengsong Hu, Dezhen Song)</author>
      <guid isPermaLink="false">2506.14066v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Modal Geometric Hierarchy Fusion: An Implicit-Submap Driven Framework for Resilient 3D Place Recognition</title>
      <link>http://arxiv.org/abs/2506.14243v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于LiDAR的地点识别新框架，旨在解决传统方法在点云密度不一致和几何抽象表示脆弱性方面的挑战。&lt;h4&gt;背景&lt;/h4&gt;LiDAR技术在机器人自主导航和自动驾驶系统中至关重要，但现有方法依赖于手工特征提取，存在描述符不稳定和表示脆弱的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，通过密度无关的几何推理重新定义3D地点识别。&lt;h4&gt;方法&lt;/h4&gt;1. 引入基于弹性点的隐式3D表示，避免原始场景点云密度干扰，实现均匀分布；2. 从隐式表示中推导场景的占用网格和法线向量信息；3. 结合占用网格和法线向量信息，获取融合了鸟瞰图（捕捉宏观空间布局）和3D分段（编码微观表面几何）信息的描述符。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在多个数据集上取得了最先进的性能，并在准确性、运行时间和内存优化方面实现了历史地图的最佳平衡。&lt;h4&gt;结论&lt;/h4&gt;该方法在自主导航和自动驾驶系统中具有优异的鲁棒性和可扩展性，未来将开源代码。&lt;h4&gt;翻译&lt;/h4&gt;LiDAR-based place recognition serves as a crucial enabler for long-term autonomy in robotics and autonomous driving systems. Yet, prevailing methodologies relying on handcrafted feature extraction face dual challenges: (1) Inconsistent point cloud density, induced by ego-motion dynamics and environmental disturbances during repeated traversals, leads to descriptor instability, and (2) Representation fragility stems from reliance on single-level geometric abstractions that lack discriminative power in structurally complex scenarios. To address these limitations, we propose a novel framework that redefines 3D place recognition through density-agnostic geometric reasoning. Specifically, we introduce an implicit 3D representation based on elastic points, which is immune to the interference of original scene point cloud density and achieves the characteristic of uniform distribution. Subsequently, we derive the occupancy grid and normal vector information of the scene from this implicit representation. Finally, with the aid of these two types of information, we obtain descriptors that fuse geometric information from both bird's-eye view (capturing macro-level spatial layouts) and 3D segment (encoding micro-scale surface geometries) perspectives. We conducted extensive experiments on numerous datasets (KITTI, KITTI-360, MulRan, NCLT) across diverse environments. The experimental results demonstrate that our method achieves state-of-the-art performance. Moreover, our approach strikes an optimal balance between accuracy, runtime, and memory optimization for historical maps, showcasing excellent Resilient and scalability. Our code will be open-sourced in the future.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR-based place recognition serves as a crucial enabler for long-termautonomy in robotics and autonomous driving systems. Yet, prevailingmethodologies relying on handcrafted feature extraction face dual challenges:(1) Inconsistent point cloud density, induced by ego-motion dynamics andenvironmental disturbances during repeated traversals, leads to descriptorinstability, and (2) Representation fragility stems from reliance onsingle-level geometric abstractions that lack discriminative power instructurally complex scenarios. To address these limitations, we propose anovel framework that redefines 3D place recognition through density-agnosticgeometric reasoning. Specifically, we introduce an implicit 3D representationbased on elastic points, which is immune to the interference of original scenepoint cloud density and achieves the characteristic of uniform distribution.Subsequently, we derive the occupancy grid and normal vector information of thescene from this implicit representation. Finally, with the aid of these twotypes of information, we obtain descriptors that fuse geometric informationfrom both bird's-eye view (capturing macro-level spatial layouts) and 3Dsegment (encoding micro-scale surface geometries) perspectives. We conductedextensive experiments on numerous datasets (KITTI, KITTI-360, MulRan, NCLT)across diverse environments. The experimental results demonstrate that ourmethod achieves state-of-the-art performance. Moreover, our approach strikes anoptimal balance between accuracy, runtime, and memory optimization forhistorical maps, showcasing excellent Resilient and scalability. Our code willbe open-sourced in the future.</description>
      <author>example@mail.com (Xiaohui Jiang, Haijiang Zhu, Chadei Li, Fulin Tang, Ning An)</author>
      <guid isPermaLink="false">2506.14243v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>I Speak and You Find: Robust 3D Visual Grounding with Noisy and Ambiguous Speech Inputs</title>
      <link>http://arxiv.org/abs/2506.14495v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SpeechRefer的新型3D视觉 grounding框架，旨在提高在有噪声和模糊的语音转写的情况下3D视觉grounding方法的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的3D视觉grounding方法依赖于精确的文本提示来定位3D场景中的对象，而语音作为一种自然直观的模态，提供了一种有前景的替代方案。然而，由于口音、背景噪音和不同的语速，现实世界的语音输入往往存在转录错误，这限制了现有3DVG方法的适用性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出SpeechRefer框架，旨在增强在有噪声和模糊的语音转写存在的情况下3DVG的性能。&lt;h4&gt;方法&lt;/h4&gt;SpeechRefer框架整合了两个关键创新：首先，语音互补模块捕获与语音相关词汇之间的声学相似性，并突出细微的区别，从语音信号中生成互补提案分数，从而减少对可能存在错误的转录的依赖；其次，对比互补模块采用对比学习方法来对齐错误的文本特征与相应的语音特征，确保即使转录错误占主导地位时也能保持稳健的性能。&lt;h4&gt;主要发现&lt;/h4&gt;在SpeechRefer和peechNr3D数据集上的大量实验表明，SpeechRefer显著提高了现有3DVG方法的性能，这突显了SpeechRefer在将噪声语音输入与可靠的3DVG之间的差距上的潜力，使得多模态系统更加直观和实用。&lt;h4&gt;结论&lt;/h4&gt;SpeechRefer框架有望解决语音转录错误对3D视觉grounding方法的影响，从而实现更高效的多模态系统。&lt;h4&gt;翻译&lt;/h4&gt;Existing 3D visual grounding methods rely on precise text prompts to locate objects within 3D scenes. Speech, as a natural and intuitive modality, offers a promising alternative. Real-world speech inputs, however, often suffer from transcription errors due to accents, background noise, and varying speech rates, limiting the applicability of existing 3DVG methods. To address these challenges, we propose SpeechRefer, a novel 3DVG framework designed to enhance performance in the presence of noisy and ambiguous speech-to-text transcriptions. SpeechRefer integrates seamlessly with existing 3DVG models and introduces two key innovations. First, the Speech Complementary Module captures acoustic similarities between phonetically related words and highlights subtle distinctions, generating complementary proposal scores from the speech signal. This reduces dependence on potentially erroneous transcriptions. Second, the Contrastive Complementary Module employs contrastive learning to align erroneous text features with corresponding speech features, ensuring robust performance even when transcription errors dominate. Extensive experiments on the SpeechRefer and peechNr3D datasets demonstrate that SpeechRefer improves the performance of existing 3DVG methods by a large margin, which highlights SpeechRefer's potential to bridge the gap between noisy speech inputs and reliable 3DVG, enabling more intuitive and practical multimodal systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing 3D visual grounding methods rely on precise text prompts to locateobjects within 3D scenes. Speech, as a natural and intuitive modality, offers apromising alternative. Real-world speech inputs, however, often suffer fromtranscription errors due to accents, background noise, and varying speechrates, limiting the applicability of existing 3DVG methods. To address thesechallenges, we propose \textbf{SpeechRefer}, a novel 3DVG framework designed toenhance performance in the presence of noisy and ambiguous speech-to-texttranscriptions. SpeechRefer integrates seamlessly with xisting 3DVG models andintroduces two key innovations. First, the Speech Complementary Module capturesacoustic similarities between phonetically related words and highlights subtledistinctions, generating complementary proposal scores from the speech signal.This reduces dependence on potentially erroneous transcriptions. Second, theContrastive Complementary Module employs contrastive learning to alignerroneous text features with corresponding speech features, ensuring robustperformance even when transcription errors dominate. Extensive experiments onthe SpeechRefer and peechNr3D datasets demonstrate that SpeechRefer improvesthe performance of existing 3DVG methods by a large margin, which highlightsSpeechRefer's potential to bridge the gap between noisy speech inputs andreliable 3DVG, enabling more intuitive and practical multimodal systems.</description>
      <author>example@mail.com (Yu Qi, Lipeng Gu, Honghua Chen, Liangliang Nan, Mingqiang Wei)</author>
      <guid isPermaLink="false">2506.14495v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>A Scalable Hybrid Training Approach for Recurrent Spiking Neural Networks</title>
      <link>http://arxiv.org/abs/2506.14464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了HYPR算法，该算法结合了并行化和近似在线前向学习，提高了循环脉冲神经网络（RSNNs）的训练效率。&lt;h4&gt;背景&lt;/h4&gt;传统的基于时间的反向传播（BPTT）在训练RSNNs时存在局限性，如不支持在线训练和内存消耗随计算步骤线性增长。&lt;h4&gt;目的&lt;/h4&gt;提出HYPR算法，以实现高效、在线的训练RSNNs。&lt;h4&gt;方法&lt;/h4&gt;HYPR算法通过并行化参数更新计算，实现了高吞吐量的在线学习，同时具有与序列长度无关的恒定内存需求。&lt;h4&gt;主要发现&lt;/h4&gt;HYPR算法特别适用于具有振荡阈下动态的脉冲神经元网络，显著降低了近似前向梯度学习和BPTT之间的任务性能差距。&lt;h4&gt;结论&lt;/h4&gt;HYPR算法为RSNNs的训练提供了一种高效、在线的方法，有望促进其在实际应用中的广泛应用。&lt;h4&gt;翻译&lt;/h4&gt;Recurrent spiking neural networks (RSNNs) can be implemented very efficiently in neuromorphic systems. Nevertheless, training of these models with powerful gradient-based learning algorithms is mostly performed on standard digital hardware using Backpropagation through time (BPTT). However, BPTT has substantial limitations. It does not permit online training and its memory consumption scales linearly with the number of computation steps. In contrast, learning methods using forward propagation of gradients operate in an online manner with a memory consumption independent of the number of time steps. These methods enable SNNs to learn from continuous, infinite-length input sequences. Yet, slow execution speed on conventional hardware as well as inferior performance has hindered their widespread application. In this work, we introduce HYbrid PRopagation (HYPR) that combines the efficiency of parallelization with approximate online forward learning. Our algorithm yields high-throughput online learning through parallelization, paired with constant, i.e., sequence length independent, memory demands. HYPR enables parallelization of parameter update computation over the sub sequences for RSNNs consisting of almost arbitrary non-linear spiking neuron models. We apply HYPR to networks of spiking neurons with oscillatory subthreshold dynamics. We find that this type of neuron model is particularly well trainable by HYPR, resulting in an unprecedentedly low task performance gap between approximate forward gradient learning and BPTT.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recurrent spiking neural networks (RSNNs) can be implemented very efficientlyin neuromorphic systems. Nevertheless, training of these models with powerfulgradient-based learning algorithms is mostly performed on standard digitalhardware using Backpropagation through time (BPTT). However, BPTT hassubstantial limitations. It does not permit online training and its memoryconsumption scales linearly with the number of computation steps. In contrast,learning methods using forward propagation of gradients operate in an onlinemanner with a memory consumption independent of the number of time steps. Thesemethods enable SNNs to learn from continuous, infinite-length input sequences.Yet, slow execution speed on conventional hardware as well as inferiorperformance has hindered their widespread application. In this work, weintroduce HYbrid PRopagation (HYPR) that combines the efficiency ofparallelization with approximate online forward learning. Our algorithm yieldshigh-throughput online learning through parallelization, paired with constant,i.e., sequence length independent, memory demands. HYPR enables parallelizationof parameter update computation over the sub sequences for RSNNs consisting ofalmost arbitrary non-linear spiking neuron models. We apply HYPR to networks ofspiking neurons with oscillatory subthreshold dynamics. We find that this typeof neuron model is particularly well trainable by HYPR, resulting in anunprecedentedly low task performance gap between approximate forward gradientlearning and BPTT.</description>
      <author>example@mail.com (Maximilian Baronig, Yeganeh Bahariasl, Ozan Özdenizci, Robert Legenstein)</author>
      <guid isPermaLink="false">2506.14464v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>DiFuse-Net: RGB and Dual-Pixel Depth Estimation using Window Bi-directional Parallax Attention and Cross-modal Transfer Learning</title>
      <link>http://arxiv.org/abs/2506.14709v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in IROS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DiFuse-Net的新颖网络设计，用于基于双像素技术进行深度估计，旨在克服传统立体和主动深度传感器的成本、功耗和鲁棒性限制。&lt;h4&gt;背景&lt;/h4&gt;深度估计对于智能系统至关重要，广泛应用于自主导航和增强现实等应用。传统方法存在成本、功耗和鲁棒性方面的限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的深度估计方法，以克服现有方法的限制，并提高深度估计的准确性。&lt;h4&gt;方法&lt;/h4&gt;DiFuse-Net采用了一种窗口双向视差注意力机制（WBiPAM），专门用于捕捉智能手机摄像头中小孔径的独特双像素视差线索。它还使用一个单独的编码器从RGB图像中提取上下文信息，并将这些特征融合以增强深度预测。此外，还提出了跨模态迁移学习（CmTL）机制，利用大规模RGB-D数据集来应对获取大规模RGB-DP-D数据集的局限性。&lt;h4&gt;主要发现&lt;/h4&gt;DiFuse-Net在性能上优于基于DP和立体视觉的基线方法，并贡献了一个新的、高质量的、真实世界的RGB-DP-D训练数据集，即双摄像头双像素（DCDP）数据集。&lt;h4&gt;结论&lt;/h4&gt;DiFuse-Net是一种有效的深度估计方法，通过融合RGB和DP信息，提高了深度估计的准确性，并通过新的数据集支持了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Depth estimation is crucial for intelligent systems, enabling applicationsfrom autonomous navigation to augmented reality. While traditional stereo andactive depth sensors have limitations in cost, power, and robustness,dual-pixel (DP) technology, ubiquitous in modern cameras, offers a compellingalternative. This paper introduces DiFuse-Net, a novel modality decouplednetwork design for disentangled RGB and DP based depth estimation. DiFuse-Netfeatures a window bi-directional parallax attention mechanism (WBiPAM)specifically designed to capture the subtle DP disparity cues unique tosmartphone cameras with small aperture. A separate encoder extracts contextualinformation from the RGB image, and these features are fused to enhance depthprediction. We also propose a Cross-modal Transfer Learning (CmTL) mechanism toutilize large-scale RGB-D datasets in the literature to cope with thelimitations of obtaining large-scale RGB-DP-D dataset. Our evaluation andcomparison of the proposed method demonstrates its superiority over the DP andstereo-based baseline methods. Additionally, we contribute a new, high-quality,real-world RGB-DP-D training dataset, named Dual-Camera Dual-Pixel (DCDP)dataset, created using our novel symmetric stereo camera hardware setup, stereocalibration and rectification protocol, and AI stereo disparity estimationmethod.</description>
      <author>example@mail.com (Kunal Swami, Debtanu Gupta, Amrit Kumar Muduli, Chirag Jaiswal, Pankaj Kumar Bajpai)</author>
      <guid isPermaLink="false">2506.14709v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Non-contrastive Self-supervised Representation Learning for Image-based Profiling</title>
      <link>http://arxiv.org/abs/2506.14265v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025 Computer Vision for Drug Discovery&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对细胞图像的基于自监督学习的特征提取器训练方法，解决了细胞图像与自然图像分布差异以及细胞图像多输入信息结合困难的问题。&lt;h4&gt;背景&lt;/h4&gt;图像细胞分型技术在药物发现中至关重要，近年来随着计算机视觉技术的进步而得到了很大发展。&lt;h4&gt;目的&lt;/h4&gt;利用非对比自监督学习方法训练一个适用于细胞图像的可泛化特征提取器。&lt;h4&gt;方法&lt;/h4&gt;提出了SSLProfiler，一个针对细胞分型的非对比自监督学习框架，包括针对细胞图像的专业数据增强和表示后处理方法。&lt;h4&gt;主要发现&lt;/h4&gt;SSLProfiler有效地解决了现有自监督学习方法在细胞图像应用中的挑战，并在CVPR2025的细胞线迁移性挑战赛中获胜。&lt;h4&gt;结论&lt;/h4&gt;SSLProfiler能够有效提升细胞图像特征提取器的鲁棒性，为细胞分型技术提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-based cell profiling aims to create informative representations of cellimages. This technique is critical in drug discovery and has greatly advancedwith recent improvements in computer vision. Inspired by recent developments innon-contrastive Self-Supervised Learning (SSL), this paper provides an initialexploration into training a generalizable feature extractor for cell imagesusing such methods. However, there are two major challenges: 1) There is alarge difference between the distributions of cell images and natural images,causing the view-generation process in existing SSL methods to fail; and 2)Unlike typical scenarios where each representation is based on a single image,cell profiling often involves multiple input images, making it difficult toeffectively combine all available information. To overcome these challenges, wepropose SSLProfiler, a non-contrastive SSL framework specifically designed forcell profiling. We introduce specialized data augmentation and representationpost-processing methods tailored to cell images, which effectively address theissues mentioned above and result in a robust feature extractor. With theseimprovements, SSLProfiler won the Cell Line Transferability challenge at CVPR2025.</description>
      <author>example@mail.com (Siran Dai, Qianqian Xu, Peisong Wen, Yang Liu, Qingming Huang)</author>
      <guid isPermaLink="false">2506.14265v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Automated Decision-Making on Networks with LLMs through Knowledge-Guided Evolution</title>
      <link>http://arxiv.org/abs/2506.14529v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LLMNet的方法，用于通过大型语言模型自动设计图神经网络（GNN）。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在从图结构数据中进行有效决策中起着核心作用，但它们的配置和调整需要付出努力。&lt;h4&gt;目的&lt;/h4&gt;设计一个自动化的GNN，通过大型语言模型来实现。&lt;h4&gt;方法&lt;/h4&gt;系统开发了一系列代理，这些代理构建与图相关的知识库，并通过检索增强生成（RAG）来支持GNN模型的自动化配置和细化。这些代理通过交互知识库来提取关于任务和图结构的见解。&lt;h4&gt;主要发现&lt;/h4&gt;LLMNet在三个图学习任务的十二个数据集上表现出色，验证了其在GNN模型设计方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;LLMNet是一种有效的GNN模型设计方法，能够通过大型语言模型实现自动化设计过程。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a method named LLMNet, which aims to automate the design of Graph Neural Networks (GNNs) through Large Language Models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective decision-making on networks often relies on learning fromgraph-structured data, where Graph Neural Networks (GNNs) play a central role,but they take efforts to configure and tune. In this demo, we propose LLMNet,showing how to design GNN automated through Large Language Models. Our systemdevelops a set of agents that construct graph-related knowlege bases and thenleverages Retrieval-Augmented Generation (RAG) to support automatedconfiguration and refinement of GNN models through a knowledge-guided evolutionprocess. These agents, equipped with specialized knowledge bases, extractinsights into tasks and graph structures by interacting with the knowledgebases. Empirical results show LLMNet excels in twelve datasets across threegraph learning tasks, validating its effectiveness of GNN model designing.</description>
      <author>example@mail.com (Xiaohan Zheng, Lanning Wei, Yong Li, Quanming Yao)</author>
      <guid isPermaLink="false">2506.14529v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>From Points to Places: Towards Human Mobility-Driven Spatiotemporal Foundation Models via Understanding Places</title>
      <link>http://arxiv.org/abs/2506.14570v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要主要讨论了捕捉人类移动性对于模型化人类如何与物理空间互动、反映社会行为、资源获取和动态空间模式的重要性。提出了一个通用的时空数据基础模型，以支持可扩展和可转移的分析。&lt;h4&gt;背景&lt;/h4&gt;现有的基础模型在处理语言和视觉数据方面取得了成功，但在处理空间、时间和语义复杂的人类移动数据方面仍存在局限性。&lt;h4&gt;目的&lt;/h4&gt;目标是开发一个通用的时空数据基础模型，以支持不同地理和背景下的可扩展和可转移分析。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的空间基础模型类别，该模型整合了地理定位语义和跨多个尺度的人类移动性，并从对兴趣点的离散建模转向对地区的理解。&lt;h4&gt;主要发现&lt;/h4&gt;识别了适应性、可扩展性和多粒度推理方面的关键差距。&lt;h4&gt;结论&lt;/h4&gt;提出了聚焦于地区建模和高效学习的研发方向，旨在指导下一代地理空间智能的可扩展、上下文感知模型的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：捕捉人类流动性对于模拟人们如何与物理空间互动、反映社会行为、获取资源和动态空间模式至关重要。为了支持不同地理和背景下的可扩展和可转移分析，需要一个通用的时空数据基础模型。尽管基础模型已经改变了语言和视觉，但它们在处理空间、时间和语义复杂的人类移动数据方面仍然有限。这篇愿景论文倡导一种新的空间基础模型类别，该模型将地理定位语义与跨多个尺度的人类移动性相结合。我们的核心愿景是从对兴趣点的离散建模转向对地区的理解：由人类行为和移动性塑造的动态、丰富的区域，可能包含许多兴趣点。我们确定了适应性、可扩展性和多粒度推理方面的关键差距，并提出了聚焦于地区建模和高效学习的研发方向。我们的目标是指导下一代地理空间智能的可扩展、上下文感知模型的发展。这些模型将解锁从个性化地点发现和物流优化到城市规划等强大的应用，最终实现更智能和更灵敏的空间决策。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Capturing human mobility is essential for modeling how people interact withand move through physical spaces, reflecting social behavior, access toresources, and dynamic spatial patterns. To support scalable and transferableanalysis across diverse geographies and contexts, there is a need for ageneralizable foundation model for spatiotemporal data. While foundation modelshave transformed language and vision, they remain limited in handling theunique challenges posed by the spatial, temporal, and semantic complexity ofmobility data. This vision paper advocates for a new class of spatialfoundation models that integrate geolocation semantics with human mobilityacross multiple scales. Central to our vision is a shift from modeling discretepoints of interest to understanding places: dynamic, context-rich regionsshaped by human behavior and mobility that may comprise many places ofinterest. We identify key gaps in adaptability, scalability, and multi-granularreasoning, and propose research directions focused on modeling places andenabling efficient learning. Our goal is to guide the development of scalable,context-aware models for next-generation geospatial intelligence. These modelsunlock powerful applications ranging from personalized place discovery andlogistics optimization to urban planning, ultimately enabling smarter and moreresponsive spatial decision-making.</description>
      <author>example@mail.com (Mohammad Hashemi, Andreas Zufle)</author>
      <guid isPermaLink="false">2506.14570v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>A Vision for Geo-Temporal Deep Research Systems: Towards Comprehensive, Transparent, and Reproducible Geo-Temporal Information Synthesis</title>
      <link>http://arxiv.org/abs/2506.14345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了将地理时间推理整合到深度研究管道中的技术、基础设施和评估挑战，提出了一个愿景，旨在构建更高级和地理时间感知的深度研究系统。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）的出现改变了信息获取方式，但当前的深度研究系统缺乏处理涉及地理和/或时间约束的丰富背景问题的能力。&lt;h4&gt;目的&lt;/h4&gt;提出将地理时间推理集成到深度研究系统中的技术、基础设施和评估挑战的解决方案。&lt;h4&gt;方法&lt;/h4&gt;通过增强检索和综合过程，以处理地理时间约束，并支持开放和可重复的基础设施以及严格的评估协议。&lt;h4&gt;主要发现&lt;/h4&gt;识别了将地理时间推理集成到深度研究管道中的技术、基础设施和评估挑战。&lt;h4&gt;结论&lt;/h4&gt;构建更高级和地理时间感知的深度研究系统，对未来的人工智能驱动信息获取具有潜在影响。&lt;h4&gt;翻译&lt;/h4&gt;The emergence of Large Language Models (LLMs) has transformed information access, with current LLMs also powering deep research systems that can generate comprehensive report-style answers, through planned iterative search, retrieval, and reasoning. Still, current deep research systems lack the geo-temporal capabilities that are essential for answering context-rich questions involving geographic and/or temporal constraints, frequently occurring in domains like public health, environmental science, or socio-economic analysis. This paper reports our vision towards next generation systems, identifying important technical, infrastructural, and evaluative challenges in integrating geo-temporal reasoning into deep research pipelines. We argue for augmenting retrieval and synthesis processes with the ability to handle geo-temporal constraints, supported by open and reproducible infrastructures and rigorous evaluation protocols. Our vision outlines a path towards more advanced and geo-temporally aware deep research systems, of potential impact to the future of AI-driven information access.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of Large Language Models (LLMs) has transformed informationaccess, with current LLMs also powering deep research systems that can generatecomprehensive report-style answers, through planned iterative search,retrieval, and reasoning. Still, current deep research systems lack thegeo-temporal capabilities that are essential for answering context-richquestions involving geographic and/or temporal constraints, frequentlyoccurring in domains like public health, environmental science, orsocio-economic analysis. This paper reports our vision towards next generationsystems, identifying important technical, infrastructural, and evaluativechallenges in integrating geo-temporal reasoning into deep research pipelines.We argue for augmenting retrieval and synthesis processes with the ability tohandle geo-temporal constraints, supported by open and reproducibleinfrastructures and rigorous evaluation protocols. Our vision outlines a pathtowards more advanced and geo-temporally aware deep research systems, ofpotential impact to the future of AI-driven information access.</description>
      <author>example@mail.com (Bruno Martins, Piotr Szymański, Piotr Gramacki)</author>
      <guid isPermaLink="false">2506.14345v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Into the Unknown: Applying Inductive Spatial-Semantic Location Embeddings for Predicting Individuals' Mobility Beyond Visited Places</title>
      <link>http://arxiv.org/abs/2506.14070v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用CaLLiPer框架进行个人移动预测，该框架通过对比学习融合了兴趣点的空间坐标和语义特征，以提高位置嵌入的准确性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;预测个人未来位置在人类流动性建模中至关重要，对城市规划、交通、公共政策和个性化移动服务有广泛影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来解决传统方法在编码空间信息、整合城市语义上下文和适应未见过的位置方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;使用CaLLiPer框架进行位置嵌入，该框架能够生成空间明确、语义丰富且具有归纳能力的嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;在四个公共移动数据集上的实验表明，CaLLiPer在传统和归纳设置下都优于强基线，特别是在归纳场景中表现优异。&lt;h4&gt;结论&lt;/h4&gt;多模态、归纳位置嵌入有潜力提升人类移动预测系统的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：预测个体下一步的位置是人类流动性建模的核心任务，对城市规划、交通、公共政策以及个性化移动服务有着广泛的影响。传统方法主要依赖于从历史流动性模式中学习到的位置嵌入，这限制了它们编码显式空间信息、整合丰富的城市语义上下文和适应先前未见过的位置的能力。为了解决这些挑战，我们探索了CaLLiPer——一个多模态表示学习框架的应用，该框架通过对比学习融合了兴趣点的空间坐标和语义特征——用于个人移动预测中的位置嵌入。CaLLiPer的嵌入是空间明确的、语义丰富的，并且设计上具有归纳能力，即使在涉及新兴位置的情景中也能实现稳健的预测性能。通过对四个公共移动数据集在传统和归纳设置下的广泛实验，我们证明了CaLLiPer始终优于强基线，特别是在归纳情景中表现出色。我们的发现突出了多模态、归纳位置嵌入在提升人类移动预测系统能力方面的潜力。我们还发布了代码和数据（https://github.com/xlwang233/Into-the-Unknown），以促进可重复性和未来的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting individuals' next locations is a core task in human mobilitymodelling, with wide-ranging implications for urban planning, transportation,public policy and personalised mobility services. Traditional approacheslargely depend on location embeddings learned from historical mobilitypatterns, limiting their ability to encode explicit spatial information,integrate rich urban semantic context, and accommodate previously unseenlocations. To address these challenges, we explore the application of CaLLiPer-- a multimodal representation learning framework that fuses spatialcoordinates and semantic features of points of interest through contrastivelearning -- for location embedding in individual mobility prediction.CaLLiPer's embeddings are spatially explicit, semantically enriched, andinductive by design, enabling robust prediction performance even in scenariosinvolving emerging locations. Through extensive experiments on four publicmobility datasets under both conventional and inductive settings, wedemonstrate that CaLLiPer consistently outperforms strong baselines,particularly excelling in inductive scenarios. Our findings highlight thepotential of multimodal, inductive location embeddings to advance thecapabilities of human mobility prediction systems. We also release the code anddata (https://github.com/xlwang233/Into-the-Unknown) to foster reproducibilityand future research.</description>
      <author>example@mail.com (Xinglei Wang, Tao Cheng, Stephen Law, Zichao Zeng, Ilya Ilyankou, Junyuan Liu, Lu Yin, Weiming Huang, Natchapon Jongwiriyanurak)</author>
      <guid isPermaLink="false">2506.14070v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>AST-Enhanced or AST-Overloaded? The Surprising Impact of Hybrid Graph Representations on Code Clone Detection</title>
      <link>http://arxiv.org/abs/2506.14470v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过实证研究评估了基于AST的混合图表示在GNN代码克隆检测中的有效性。&lt;h4&gt;背景&lt;/h4&gt;代码克隆是软件工程中的一个严重问题，它增加了软件维护成本和提高了安全风险。ASTs因其精确的语法结构表示而主导了基于深度学习的代码克隆检测，但它们本身缺乏语义深度。&lt;h4&gt;目的&lt;/h4&gt;研究AST基于的混合图表示在GNN代码克隆检测中的有效性。&lt;h4&gt;方法&lt;/h4&gt;对多种混合表示（CFG、DFG、Flow-Augmented ASTs（FA-AST））在多个GNN架构上进行了系统比较。&lt;h4&gt;主要发现&lt;/h4&gt;混合表示对GNN的影响不同：AST+CFG+DFG模型（如GCN、GAT）的准确性得到了一致提升，而FA-AST经常引入结构复杂性，损害性能。GMN即使在标准AST表示下也优于其他模型，突显其在跨代码相似性检测方面的优越性，并减少了使用丰富结构的需要。&lt;h4&gt;结论&lt;/h4&gt;混合图表示在GNN代码克隆检测中具有潜力，但FA-AST可能不是最佳选择。GMN在代码克隆检测中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents a comprehensive empirical study to rigorously evaluate the effectiveness of AST-based hybrid graph representations in Graph Neural Network (GNN)-based code clone detection. We systematically compare various hybrid representations (CFG, DFG, Flow-Augmented ASTs (FA-AST)) across multiple GNN architectures. Our experiments reveal that hybrid representations impact GNNs differently: while AST+CFG+DFG consistently enhances accuracy for convolution- and attention-based models (Graph Convolutional Networks (GCN), Graph Attention Networks (GAT)), FA-AST frequently introduces structural complexity that harms performance. Notably, GMN outperforms others even with standard AST representations, highlighting its superior cross-code similarity detection and reducing the need for enriched structures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As one of the most detrimental code smells, code clones significantlyincrease software maintenance costs and heighten vulnerability risks, makingtheir detection a critical challenge in software engineering. Abstract SyntaxTrees (ASTs) dominate deep learning-based code clone detection due to theirprecise syntactic structure representation, but they inherently lack semanticdepth. Recent studies address this by enriching AST-based representations withsemantic graphs, such as Control Flow Graphs (CFGs) and Data Flow Graphs(DFGs). However, the effectiveness of various enriched AST-basedrepresentations and their compatibility with different graph-based machinelearning techniques remains an open question, warranting further investigationto unlock their full potential in addressing the complexities of code clonedetection. In this paper, we present a comprehensive empirical study torigorously evaluate the effectiveness of AST-based hybrid graph representationsin Graph Neural Network (GNN)-based code clone detection. We systematicallycompare various hybrid representations ((CFG, DFG, Flow-Augmented ASTs(FA-AST)) across multiple GNN architectures. Our experiments reveal that hybridrepresentations impact GNNs differently: while AST+CFG+DFG consistentlyenhances accuracy for convolution- and attention-based models (GraphConvolutional Networks (GCN), Graph Attention Networks (GAT)), FA-ASTfrequently introduces structural complexity that harms performance. Notably,GMN outperforms others even with standard AST representations, highlighting itssuperior cross-code similarity detection and reducing the need for enrichedstructures.</description>
      <author>example@mail.com (Zixian Zhang, Takfarinas Saber)</author>
      <guid isPermaLink="false">2506.14470v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Unified Representation Space for 3D Visual Grounding</title>
      <link>http://arxiv.org/abs/2506.14238v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为UniSpace-3D的3D视觉 grounding方法，旨在通过文本描述识别3D场景中的物体，并有效解决视觉和文本特征之间的差距问题。&lt;h4&gt;背景&lt;/h4&gt;现有3D视觉 grounding方法依赖于分别预训练的视觉和文本编码器，导致两者在空间几何和语义类别方面存在较大差距，这常常导致物体定位和分类错误。&lt;h4&gt;目的&lt;/h4&gt;提出UniSpace-3D方法，以解决视觉和文本特征之间的差距问题，并提高物体识别的准确性。&lt;h4&gt;方法&lt;/h4&gt;UniSpace-3D包含三个创新设计：1）一个统一的表示编码器，利用预训练的CLIP模型将视觉和文本特征映射到统一的表示空间；2）一个多模态对比学习模块，进一步缩小模态差距；3）一个语言引导的查询选择模块，利用位置和语义信息识别与文本描述一致的物体候选点。&lt;h4&gt;主要发现&lt;/h4&gt;在ScanRefer和Nr3D/Sr3D数据集上，UniSpace-3D相较于基线模型至少提高了2.24%的准确率。&lt;h4&gt;结论&lt;/h4&gt;UniSpace-3D方法在3D视觉 grounding任务上表现优于基线模型，有效解决了视觉和文本特征之间的差距问题。&lt;h4&gt;翻译&lt;/h4&gt;3D视觉 grounding（3DVG）是场景理解中的一个关键任务，旨在根据文本描述在3D场景中识别物体。然而，现有方法依赖于分别预训练的视觉和文本编码器，这在空间几何和语义类别方面导致了两个模态之间的显著差距。这种差异通常会导致物体定位和分类错误。本文提出UniSpace-3D，它创新地引入了一个统一的表示空间用于3DVG，有效地弥合了视觉和文本特征之间的差距。具体来说，UniSpace-3D包含三个创新设计：i）一个统一的表示编码器，利用预训练的CLIP模型将视觉和文本特征映射到一个统一的表示空间，有效地弥合了两个模态之间的差距；ii）一个多模态对比学习模块，进一步缩小了模态差距；iii）一个语言引导的查询选择模块，利用位置和语义信息识别与文本描述一致的物体候选点。大量的实验表明，UniSpace-3D在ScanRefer和Nr3D/Sr3D数据集上至少比基线模型提高了2.24%的准确率。论文被接受后，代码将会提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D visual grounding (3DVG) is a critical task in scene understanding thataims to identify objects in 3D scenes based on text descriptions. However,existing methods rely on separately pre-trained vision and text encoders,resulting in a significant gap between the two modalities in terms of spatialgeometry and semantic categories. This discrepancy often causes errors inobject positioning and classification. The paper proposes UniSpace-3D, whichinnovatively introduces a unified representation space for 3DVG, effectivelybridging the gap between visual and textual features. Specifically, UniSpace-3Dincorporates three innovative designs: i) a unified representation encoder thatleverages the pre-trained CLIP model to map visual and textual features into aunified representation space, effectively bridging the gap between the twomodalities; ii) a multi-modal contrastive learning module that further reducesthe modality gap; iii) a language-guided query selection module that utilizesthe positional and semantic information to identify object candidate pointsaligned with textual descriptions. Extensive experiments demonstrate thatUniSpace-3D outperforms baseline models by at least 2.24% on the ScanRefer andNr3D/Sr3D datasets. The code will be made available upon acceptance of thepaper.</description>
      <author>example@mail.com (Yinuo Zheng, Lipeng Gu, Honghua Chen, Liangliang Nan, Mingqiang Wei)</author>
      <guid isPermaLink="false">2506.14238v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Can Large Language Models Improve Spectral Graph Neural Networks?</title>
      <link>http://arxiv.org/abs/2506.14220v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用大型语言模型（LLMs）来估计图同质性的新方法，并用于指导设计多项式频谱滤波器，从而提高SGNNs在多种图结构下的表现。&lt;h4&gt;背景&lt;/h4&gt;Spectral Graph Neural Networks（SGNNs）因其能够逼近任意滤波器而受到关注，但标签稀缺条件下可能会学习到次优滤波器，导致性能下降。同时，大型语言模型（LLMs）的成功激发了对其在GNN领域的探索兴趣。&lt;h4&gt;目的&lt;/h4&gt;研究LLMs是否能帮助克服SGNNs的局限性并提升其性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种轻量级流程，其中LLM生成同质性感知先验，并将其注入到滤波器系数中，以更好地与底层图拓扑对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上的实验表明，该LLM驱动的SGNN框架在亲同和异同设置下均优于现有基线，且计算和成本开销最小。&lt;h4&gt;结论&lt;/h4&gt;LLMs可以增强SGNNs的表现，特别是在标签稀缺的情况下。&lt;h4&gt;翻译&lt;/h4&gt;Spectral Graph Neural Networks (SGNNs) 由于其能够逼近任意滤波器的能力而受到广泛关注。它们通常依赖于下游任务的监督来适应性地学习适当的滤波器。然而，在标签稀缺的情况下，SGNNs可能会学习到次优滤波器，导致性能下降。同时，大型语言模型（LLMs）的显著成功激发了对在 GNN 领域探索其潜力的兴趣。这自然引发了一个重要问题：LLMs 能否帮助克服 SGNNs 的局限性并提高其性能？在本文中，我们提出了一种利用 LLM 估计给定图同质性的新颖方法。估计的同质性随后用于自适应地指导多项式频谱滤波器的设计，从而提高 SGNNs 在各种图结构下的表现力和适应性。具体而言，我们引入了一个轻量级流程，其中 LLM 生成同质性感知先验，这些先验被注入到滤波器系数中以更好地与底层图拓扑对齐。在基准数据集上的大量实验表明，我们的 LLM 驱动的 SGNN 框架在亲同和异同设置下均优于现有基线，具有最小的计算和货币开销。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spectral Graph Neural Networks (SGNNs) have attracted significant attentiondue to their ability to approximate arbitrary filters. They typically rely onsupervision from downstream tasks to adaptively learn appropriate filters.However, under label-scarce conditions, SGNNs may learn suboptimal filters,leading to degraded performance. Meanwhile, the remarkable success of LargeLanguage Models (LLMs) has inspired growing interest in exploring theirpotential within the GNN domain. This naturally raises an important question:\textit{Can LLMs help overcome the limitations of SGNNs and enhance theirperformance?} In this paper, we propose a novel approach that leverages LLMs toestimate the homophily of a given graph. The estimated homophily is then usedto adaptively guide the design of polynomial spectral filters, therebyimproving the expressiveness and adaptability of SGNNs across diverse graphstructures. Specifically, we introduce a lightweight pipeline in which the LLMgenerates homophily-aware priors, which are injected into the filtercoefficients to better align with the underlying graph topology. Extensiveexperiments on benchmark datasets demonstrate that our LLM-driven SGNNframework consistently outperforms existing baselines under both homophilic andheterophilic settings, with minimal computational and monetary overhead.</description>
      <author>example@mail.com (Kangkang Lu, Yanhua Yu, Zhiyong Huang, Tat-Seng Chua)</author>
      <guid isPermaLink="false">2506.14220v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>NeuroCoreX: An Open-Source FPGA-Based Spiking Neural Network Emulator with On-Chip Learning</title>
      <link>http://arxiv.org/abs/2506.14138v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Neuromorphic computing, FPGA, STDP, Spiking Graph Neural Networks,  Spiking Neural Networks, VHDL&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于FPGA的Spiking Neural Networks (SNNs)仿真器NeuroCoreX，用于灵活的SNNs协同设计和测试。&lt;h4&gt;背景&lt;/h4&gt;SNNs是一种受生物神经元网络结构和动力学启发的计算模型，与传统的人工神经网络相比，SNNs具有高能量效率的特点。&lt;h4&gt;目的&lt;/h4&gt;NeuroCoreX旨在加速能源高效、生物启发计算的研究和开发。&lt;h4&gt;方法&lt;/h4&gt;NeuroCoreX支持全连接，并采用基于Spike-Timing-Dependent Plasticity (STDP)的本地学习机制。神经元模型为Leaky Integrate-and-Fire (LIF)模型，并具有基于电流的突触。&lt;h4&gt;主要发现&lt;/h4&gt;NeuroCoreX提供了一种简单易用的Python接口，用于编程和配置网络参数，包括神经元、突触和学习规则设置。&lt;h4&gt;结论&lt;/h4&gt;NeuroCoreX作为一个开源框架，能够促进SNNs从模型设计到硬件执行的应用。&lt;h4&gt;翻译&lt;/h4&gt;Spiking Neural Networks (SNNs) 是一种受生物神经元网络结构和动力学启发的计算模型。它们的事件驱动特性使得它们在部署在神经形态硬件平台上时能够实现高能效。与主要依赖于分层架构的传统人工神经网络（ANNs）不同，SNNs自然支持广泛的连接模式，从传统的分层结构到具有局部密集和全局稀疏连接的小世界图。在这项工作中，我们介绍了一种基于FPGA的仿真器NeuroCoreX，用于SNNs的灵活协同设计和测试。NeuroCoreX支持全连接，提供在不限制架构的情况下实现不同网络拓扑的能力。它具有基于Spike-Timing-Dependent Plasticity (STDP)的生物启发式本地学习机制。NeuroCoreX中实现的神经元模型是Leaky Integrate-and-Fire (LIF)模型，基于电流的突触促进了突触的整合和传输。它提供了一个通用异步收发器（UART）接口，用于编程和配置网络参数，包括神经元、突触和学习规则设置。用户通过一个简单的基于Python的接口与仿真器交互，简化了从模型设计到硬件执行的SNN部署。NeuroCoreX作为一个开源框架发布，旨在加速能源高效、生物启发计算的研究和开发。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spiking Neural Networks (SNNs) are computational models inspired by thestructure and dynamics of biological neuronal networks. Their event-drivennature enables them to achieve high energy efficiency, particularly whendeployed on neuromorphic hardware platforms. Unlike conventional ArtificialNeural Networks (ANNs), which primarily rely on layered architectures, SNNsnaturally support a wide range of connectivity patterns, from traditionallayered structures to small-world graphs characterized by locally dense andglobally sparse connections. In this work, we introduce NeuroCoreX, anFPGA-based emulator designed for the flexible co-design and testing of SNNs.NeuroCoreX supports all-to-all connectivity, providing the capability toimplement diverse network topologies without architectural restrictions. Itfeatures a biologically motivated local learning mechanism based onSpike-Timing-Dependent Plasticity (STDP). The neuron model implemented withinNeuroCoreX is the Leaky Integrate-and-Fire (LIF) model, with current-basedsynapses facilitating spike integration and transmission . A UniversalAsynchronous Receiver-Transmitter (UART) interface is provided for programmingand configuring the network parameters, including neuron, synapse, and learningrule settings. Users interact with the emulator through a simple Python-basedinterface, streamlining SNN deployment from model design to hardware execution.NeuroCoreX is released as an open-source framework, aiming to accelerateresearch and development in energy-efficient, biologically inspired computing.</description>
      <author>example@mail.com (Ashish Gautam, Prasanna Date, Shruti Kulkarni, Robert Patton, Thomas Potok)</author>
      <guid isPermaLink="false">2506.14138v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Bayesian Knowledge Transfer for a Kalman Fixed-Lag Interval Smoother</title>
      <link>http://arxiv.org/abs/2506.14572v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 1 figure. Accepted for publication in IEEE Control Systems  Letters. To be presented at the IEEE 64th Conference on Decision and Control&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种利用外部信息提高卡尔曼固定滞后区间平滑器（FLIS）性能的贝叶斯知识迁移机制。&lt;h4&gt;背景&lt;/h4&gt;传统迁移学习方法中，外部观察模型的精确知识缺失，阻碍了贝叶斯法则的直接应用。&lt;h4&gt;目的&lt;/h4&gt;克服传统方法的局限性，通过完全概率设计，将目标任务的状态估计条件化于外部信息。&lt;h4&gt;方法&lt;/h4&gt;引入一个潜在变量以减轻不准确外部数据的不利影响，同时利用精确信息。FLIS可以回溯地优化过去决策，直到一个固定的时间范围，减少估计误差的累积，从而提高状态推断的性能。&lt;h4&gt;主要发现&lt;/h4&gt;模拟结果表明，所提出的算法比类似技术更好地利用了精确的外部知识，当信息不准确时，也能实现可比的结果。&lt;h4&gt;结论&lt;/h4&gt;所提出的贝叶斯知识迁移机制能够有效提高FLIS的性能，尤其是在外部信息可用时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A Bayesian knowledge transfer mechanism that leverages external informationto improve the performance of the Kalman fixed-lag interval smoother (FLIS) isproposed. Exact knowledge of the external observation model is assumed to bemissing, which hinders the direct application of Bayes' rule in traditionaltransfer learning approaches. This limitation is overcome by the fullyprobabilistic design, conditioning the targeted task of state estimation onexternal information. To mitigate the negative impact of inaccurate externaldata while leveraging precise information, a latent variable is introduced.Favorably, in contrast to a filter, FLIS retrospectively refines past decisionsup to a fixed time horizon, reducing the accumulation of estimation error andconsequently improving the performance of state inference. Simulations indicatethat the proposed algorithm better exploits precise external knowledge comparedto a similar technique and achieves comparable results when the information isimprecise.</description>
      <author>example@mail.com (Ondřej Skalský, Jakub Dokoupil)</author>
      <guid isPermaLink="false">2506.14572v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Spatiotemporal Learning of Brain Dynamics from fMRI Using Frequency-Specific Multi-Band Attention for Cognitive and Psychiatric Applications</title>
      <link>http://arxiv.org/abs/2503.23394v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MBBN是一个基于Transformer的框架，用于建模fMRI数据中的频率特异性时空脑动力学，通过生物基础的频率分解和多频带自注意力机制，发现之前未检测到的频率依赖性网络交互，提高了预测精神病学和认知结果的能力，为精确精神病学和发展神经科学开辟了新途径。&lt;h4&gt;背景&lt;/h4&gt;理解大脑的复杂非线性动力学如何产生认知功能是神经科学的核心挑战。传统的神经影像学分析假设线性和平稳性，无法捕捉特定频率的神经计算。&lt;h4&gt;目的&lt;/h4&gt;提出MBBN框架，以更好地理解和预测大脑的频率特异性时空动力学。&lt;h4&gt;方法&lt;/h4&gt;MBBN整合了生物基础的频率分解和多频带自注意力机制，并在三个大型队列（UK Biobank、ABCD、ABIDE）的49,673个个体上进行了训练。&lt;h4&gt;主要发现&lt;/h4&gt;MBBN在预测精神病学和认知结果（如抑郁症、ADHD、ASD）方面表现出色，在分类任务中AUROC提高了高达52.5%，揭示了ADHD和ASD的特定频率特征。&lt;h4&gt;结论&lt;/h4&gt;MBBN通过整合尺度感知神经动力学与深度学习，提供了更准确和可解释的生物标志物，为精确精神病学和发展神经科学提供了新的框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/transconnectome/mbbn&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding how the brain's complex nonlinear dynamics give rise tocognitive function remains a central challenge in neuroscience. While brainfunctional dynamics exhibits scale-free and multifractal properties acrosstemporal scales, conventional neuroimaging analytics assume linearity andstationarity, failing to capture frequency-specific neural computations. Here,we introduce Multi-Band Brain Net (MBBN), the first transformer-based frameworkto explicitly model frequency-specific spatiotemporal brain dynamics from fMRI.MBBN integrates biologically-grounded frequency decomposition with multi-bandself-attention mechanisms, enabling discovery of previously undetectablefrequency-dependent network interactions. Trained on 49,673 individuals acrossthree large-scale cohorts (UK Biobank, ABCD, ABIDE), MBBN sets a newstate-of-the-art in predicting psychiatric and cognitive outcomes (depression,ADHD, ASD), showing particular strength in classification tasks with up to52.5\% higher AUROC and provides a novel framework for predicting cognitiveintelligence scores. Frequency-resolved analyses uncover disorder-specificsignatures: in ADHD, high-frequency fronto-sensorimotor connectivity isattenuated and opercular somatosensory nodes emerge as dynamic hubs; in ASD,orbitofrontal-somatosensory circuits show focal high-frequency disruptiontogether with enhanced ultra-low-frequency coupling between thetemporo-parietal junction and prefrontal cortex. By integrating scale-awareneural dynamics with deep learning, MBBN delivers more accurate andinterpretable biomarkers, opening avenues for precision psychiatry anddevelopmental neuroscience.</description>
      <author>example@mail.com (Sangyoon Bae, Junbeom Kwon, Shinjae Yoo, Jiook Cha)</author>
      <guid isPermaLink="false">2503.23394v2</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>CLGNN: A Contrastive Learning-based GNN Model for Betweenness Centrality Prediction on Temporal Graphs</title>
      <link>http://arxiv.org/abs/2506.14122v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于对比学习的图神经网络（CLGNN）模型，用于准确和高效地预测时间网络的时序介数中心性（TBC），解决了现有方法在处理数据不平衡和忽略时间依赖性方面的不足。&lt;h4&gt;背景&lt;/h4&gt;TBC是一个衡量节点在时间网络中重要性的指标，但精确计算成本高，且实际数据分布不平衡，导致学习模型过拟合零中心性节点，影响预测准确性和中心节点识别。&lt;h4&gt;目的&lt;/h4&gt;提出一种可扩展的基于对比学习的GNN（CLGNN）模型，以解决TBC预测中的数据不平衡和时间依赖性问题。&lt;h4&gt;方法&lt;/h4&gt;CLGNN构建实例图以保持路径有效性和时间顺序，使用双重聚合（平均和边到节点的多头注意力机制）编码结构和时间特征，并通过时间路径计数和时间编码增强。引入基于稳定性的聚类引导对比模块（KContrastNet）以分离高、中、低中心性节点，缓解类别不平衡，同时使用回归模块（ValueNet）估计TBC值。CLGNN支持多种最优路径定义，以适应不同的时间语义。&lt;h4&gt;主要发现&lt;/h4&gt;CLGNN在多个基准测试中展示了有效性和效率，相比最先进的精确TBC计算方法，速度提高了663.7倍。在MAE和Spearman相关系数方面，CLGNN优于静态GNN基线，分别降低了31.4倍和提高了16.7倍，并且超越了最先进的时序GNN，分别降低了5.7倍和提高了3.9倍。&lt;h4&gt;结论&lt;/h4&gt;CLGNN是一种有效的TBC预测方法，能够解决现有方法的局限性，并在性能上优于现有技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal Betweenness Centrality (TBC) measures how often a node appears onoptimal temporal paths, reflecting its importance in temporal networks.However, exact computation is highly expensive, and real-world TBCdistributions are extremely imbalanced. The severe imbalance leadslearning-based models to overfit to zero-centrality nodes, resulting ininaccurate TBC predictions and failure to identify truly central nodes.Existing graph neural network (GNN) methods either fail to handle suchimbalance or ignore temporal dependencies altogether. To address these issues,we propose a scalable and inductive contrastive learning-based GNN (CLGNN) foraccurate and efficient TBC prediction. CLGNN builds an instance graph topreserve path validity and temporal order, then encodes structural and temporalfeatures using dual aggregation, i.e., mean and edge-to-node multi-headattention mechanisms, enhanced by temporal path count and time encodings. Astability-based clustering-guided contrastive module (KContrastNet) isintroduced to separate high-, median-, and low-centrality nodes inrepresentation space, mitigating class imbalance, while a regression module(ValueNet) estimates TBC values. CLGNN also supports multiple optimal pathdefinitions to accommodate diverse temporal semantics. Extensive experimentsdemonstrate the effectiveness and efficiency of CLGNN across diversebenchmarks. CLGNN achieves up to a 663.7~$\times$ speedup compared tostate-of-the-art exact TBC computation methods. It outperforms leading staticGNN baselines with up to 31.4~$\times$ lower MAE and 16.7~$\times$ higherSpearman correlation, and surpasses state-of-the-art temporal GNNs with up to5.7~$\times$ lower MAE and 3.9~$\times$ higher Spearman correlation.</description>
      <author>example@mail.com (Tianming Zhang, Renbo Zhang, Zhengyi Yang, Yunjun Gao, Bin Cao, Jing Fan)</author>
      <guid isPermaLink="false">2506.14122v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Adjustment for Confounding using Pre-Trained Representations</title>
      <link>http://arxiv.org/abs/2506.14329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了如何利用预训练神经网络的潜在特征来调整混杂因素，以提高平均处理效应（ATE）估计的准确性。&lt;h4&gt;背景&lt;/h4&gt;对扩展ATE估计以包含非表格数据（如图像和文本）的兴趣日益增加，这些数据可能成为混杂因素，忽视这些因素可能导致结果偏差和科学结论错误。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用预训练神经网络的潜在特征来调整混杂因素，并确保ATE估计的有效性和统计推断。&lt;h4&gt;方法&lt;/h4&gt;通过双机器学习示例，本文形式化了在ATE估计中使潜在特征能够进行有效调整和统计推断的条件。讨论了潜在特征学习及其下游参数估计的挑战，包括高维度和非识别性。同时，指出神经网络对这些问题不太敏感，并展示了神经网络如何通过适应学习问题的内在稀疏性和维度来实现快速收敛。&lt;h4&gt;主要发现&lt;/h4&gt;本文发现，利用预训练神经网络的潜在特征可以调整混杂因素，并提高了ATE估计的准确性。同时，神经网络对高维度和非识别性问题不太敏感，能够实现快速收敛。&lt;h4&gt;结论&lt;/h4&gt;神经网络在ATE估计中具有潜力，可以通过适应学习问题的内在稀疏性和维度来实现快速收敛，从而提高估计的准确性。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了如何利用预训练神经网络的潜在特征来调整混杂因素，以提高平均处理效应（ATE）估计的准确性。对扩展ATE估计以包含非表格数据（如图像和文本）的兴趣日益增加，这些数据可能成为混杂因素，忽视这些因素可能导致结果偏差和科学结论错误。研究旨在通过利用预训练神经网络的潜在特征来调整混杂因素，并确保ATE估计的有效性和统计推断。通过双机器学习示例，本文形式化了在ATE估计中使潜在特征能够进行有效调整和统计推断的条件。讨论了潜在特征学习及其下游参数估计的挑战，包括高维度和非识别性。同时，指出神经网络对这些问题不太敏感，并展示了神经网络如何通过适应学习问题的内在稀疏性和维度来实现快速收敛。研究发现，利用预训练神经网络的潜在特征可以调整混杂因素，并提高了ATE估计的准确性。同时，神经网络对高维度和非识别性问题不太敏感，能够实现快速收敛。结论是神经网络在ATE估计中具有潜力，可以通过适应学习问题的内在稀疏性和维度来实现快速收敛，从而提高估计的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; There is growing interest in extending average treatment effect (ATE)estimation to incorporate non-tabular data, such as images and text, which mayact as sources of confounding. Neglecting these effects risks biased resultsand flawed scientific conclusions. However, incorporating non-tabular datanecessitates sophisticated feature extractors, often in combination with ideasof transfer learning. In this work, we investigate how latent features frompre-trained neural networks can be leveraged to adjust for sources ofconfounding. We formalize conditions under which these latent features enablevalid adjustment and statistical inference in ATE estimation, demonstratingresults along the example of double machine learning. We discuss criticalchallenges inherent to latent feature learning and downstream parameterestimation arising from the high dimensionality and non-identifiability ofrepresentations. Common structural assumptions for obtaining fast convergencerates with additive or sparse linear models are shown to be unrealistic forlatent features. We argue, however, that neural networks are largelyinsensitive to these issues. In particular, we show that neural networks canachieve fast convergence rates by adapting to intrinsic notions of sparsity anddimension of the learning problem.</description>
      <author>example@mail.com (Rickmer Schulte, David Rügamer, Thomas Nagler)</author>
      <guid isPermaLink="false">2506.14329v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>SceneAware: Scene-Constrained Pedestrian Trajectory Prediction with LLM-Guided Walkability</title>
      <link>http://arxiv.org/abs/2506.14144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SceneAware的新框架，通过结合场景理解和多模态大语言模型来提高行人轨迹预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的行人轨迹预测方法主要关注行人之间的社会互动，而忽略了环境背景对人类运动模式的重要影响。&lt;h4&gt;目的&lt;/h4&gt;提高行人轨迹预测的准确性，特别是在机器人技术和监控系统中的应用。&lt;h4&gt;方法&lt;/h4&gt;SceneAware利用视觉Transformer（ViT）场景编码器处理静态场景图像中的环境背景，并使用多模态大语言模型（MLLMs）生成二进制可达性掩码。该方法结合基于Transformer的轨迹编码器和基于ViT的场景编码器，捕捉时间和空间动态。框架还集成了碰撞惩罚机制，以确保预测轨迹不会违反物理边界。&lt;h4&gt;主要发现&lt;/h4&gt;在ETH/UCY基准数据集上的综合实验表明，SceneAware方法优于现有方法，比之前的模型提高了50%以上。分析不同类型的行人运动轨迹表明，模型在各种类型的行人运动中表现一致良好。&lt;h4&gt;结论&lt;/h4&gt;使用显式的场景信息对于提高预测准确性至关重要，SceneAware方法在生成准确和物理上合理的预测方面既有效又可靠。&lt;h4&gt;翻译&lt;/h4&gt;摘要：准确预测行人轨迹对于机器人和监控系统中的应用至关重要。虽然现有方法主要关注行人之间的社会互动，但它们往往忽略了显著影响人类运动模式的环境背景。在本文中，我们提出了SceneAware，一个结合场景理解以提高轨迹预测准确性的新框架。我们的方法利用视觉Transformer（ViT）场景编码器处理来自静态场景图像的环境上下文，同时多模态大型语言模型（MLLMs）在训练期间生成二进制可达性掩码，以区分可达和受限区域。我们将基于Transformer的轨迹编码器与基于ViT的场景编码器相结合，捕捉时间和空间动态。该框架集成了碰撞惩罚机制，以阻止预测轨迹违反物理边界，确保物理上合理的预测。SceneAware实现了确定性和随机性变体。在ETH/UCY基准数据集上的综合实验表明，我们的方法优于现有方法，比以前的模型提高了50%以上。基于不同轨迹类别的分析表明，该模型在各种类型的行人运动中表现良好。这突出了使用显式场景信息的重要性，并表明我们的场景感知方法在生成准确和物理上合理的预测方面既有效又可靠。代码可在以下链接获取：https://github.com/juho127/SceneAware。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction of pedestrian trajectories is essential for applicationsin robotics and surveillance systems. While existing approaches primarily focuson social interactions between pedestrians, they often overlook the richenvironmental context that significantly shapes human movement patterns. Inthis paper, we propose SceneAware, a novel framework that explicitlyincorporates scene understanding to enhance trajectory prediction accuracy. Ourmethod leverages a Vision Transformer~(ViT) scene encoder to processenvironmental context from static scene images, while Multi-modal LargeLanguage Models~(MLLMs) generate binary walkability masks that distinguishbetween accessible and restricted areas during training. We combine aTransformer-based trajectory encoder with the ViT-based scene encoder,capturing both temporal dynamics and spatial constraints. The frameworkintegrates collision penalty mechanisms that discourage predicted trajectoriesfrom violating physical boundaries, ensuring physically plausible predictions.SceneAware is implemented in both deterministic and stochastic variants.Comprehensive experiments on the ETH/UCY benchmark datasets show that ourapproach outperforms state-of-the-art methods, with more than 50\% improvementover previous models. Our analysis based on different trajectory categoriesshows that the model performs consistently well across various types ofpedestrian movement. This highlights the importance of using explicit sceneinformation and shows that our scene-aware approach is both effective andreliable in generating accurate and physically plausible predictions. Code isavailable at: https://github.com/juho127/SceneAware.</description>
      <author>example@mail.com (Juho Bai, Inwook Shim)</author>
      <guid isPermaLink="false">2506.14144v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Can Pretrained Vision-Language Embeddings Alone Guide Robot Navigation?</title>
      <link>http://arxiv.org/abs/2506.14507v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 figures, 2 tables, Accepted to Robotics: Science and Systems (RSS)  2025 Workshop on Robot Planning in the Era of Foundation Models (FM4RoboPlan)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用预训练的视觉语言模型（VLMs）在无特定任务训练的情况下引导导航的能力。&lt;h4&gt;背景&lt;/h4&gt;尽管许多方法将预训练的视觉语言模型与专门的导航架构结合使用，但基本问题仍然存在：这些预训练的嵌入是否足以成功引导导航，而无需额外的微调或专用模块。&lt;h4&gt;目的&lt;/h4&gt;提出一个最小化框架，通过直接在冻结的视觉语言嵌入上训练行为克隆策略，来分离这个问题。&lt;h4&gt;方法&lt;/h4&gt;使用由特权专家收集的演示数据来训练，并实现74%的导航成功率，尽管平均需要多走3.2倍的路程。&lt;h4&gt;主要发现&lt;/h4&gt;预训练嵌入在基本语言接地方面有效，但在长期规划和空间推理方面存在困难。&lt;h4&gt;结论&lt;/h4&gt;提供了使用基础模型作为具身任务嵌入式表示的实证基准，突出了其能力和局限性，为资源受限场景下面临系统复杂性与性能权衡的机器人研究人员提供了关键见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型通过提供丰富的语义表示，在不进行特定任务训练的情况下彻底改变了机器人技术。虽然许多方法将预训练的视觉语言模型（VLMs）与专门的导航架构相结合，但基本问题仍然存在：这些预训练的嵌入本身能否成功地引导导航，而无需额外的微调或专用模块？我们提出了一种最小化框架，通过直接在由特权专家收集的演示数据上训练冻结的视觉语言嵌入的行为克隆策略来解决这个问题。与100%成功率的具有状态意识的专家相比，我们的方法在导航到语言指定的目标方面实现了74%的成功率，但平均需要多走3.2倍的路程。这种性能差距揭示了预训练嵌入在基本语言接地方面是有效的，但在长期规划和空间推理方面存在困难。通过提供这个实证基准，我们突出了使用基础模型作为嵌入式任务的嵌入表示的能力和局限性，为面临资源受限场景下系统复杂性与性能权衡的机器人研究人员提供了关键见解。我们的代码可在https://github.com/oadamharoon/text2nav上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have revolutionized robotics by providing rich semanticrepresentations without task-specific training. While many approaches integratepretrained vision-language models (VLMs) with specialized navigationarchitectures, the fundamental question remains: can these pretrainedembeddings alone successfully guide navigation without additional fine-tuningor specialized modules? We present a minimalist framework that decouples thisquestion by training a behavior cloning policy directly on frozenvision-language embeddings from demonstrations collected by a privilegedexpert. Our approach achieves a 74% success rate in navigation tolanguage-specified targets, compared to 100% for the state-aware expert, thoughrequiring 3.2 times more steps on average. This performance gap reveals thatpretrained embeddings effectively support basic language grounding but strugglewith long-horizon planning and spatial reasoning. By providing this empiricalbaseline, we highlight both the capabilities and limitations of usingfoundation models as drop-in representations for embodied tasks, offeringcritical insights for robotics researchers facing practical design tradeoffsbetween system complexity and performance in resource-constrained scenarios.Our code is available at https://github.com/oadamharoon/text2nav</description>
      <author>example@mail.com (Nitesh Subedi, Adam Haroon, Shreyan Ganguly, Samuel T. K. Tetteh, Prajwal Koirala, Cody Fleming, Soumik Sarkar)</author>
      <guid isPermaLink="false">2506.14507v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>GRAM: A Generative Foundation Reward Model for Reward Generalization</title>
      <link>http://arxiv.org/abs/2506.14175v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用未标记和标记数据训练奖励模型的方法，并开发了一种生成式奖励模型，该模型首先通过大规模无监督学习进行训练，然后通过监督学习进行微调。&lt;h4&gt;背景&lt;/h4&gt;在大型语言模型（LLMs）的校准过程中，奖励模型发挥了重要作用，但通常作为判别模型进行训练，并且仅依赖于标记的人类偏好数据。&lt;h4&gt;目的&lt;/h4&gt;探索使用未标记和标记数据训练奖励模型的方法，并开发一种新的生成式奖励模型。&lt;h4&gt;方法&lt;/h4&gt;开发了一种生成式奖励模型，通过大规模无监督学习进行初步训练，然后通过监督学习进行微调。此外，通过使用标签平滑，实际上是在优化正则化成对排名损失。&lt;h4&gt;主要发现&lt;/h4&gt;使用标签平滑实际上是在优化正则化成对排名损失，这一结果为训练奖励模型提供了新的视角，将生成模型和判别模型链接到同一类训练目标下。&lt;h4&gt;结论&lt;/h4&gt;所提出的这些技术产生了一个基础奖励模型，该模型可以应用于各种任务，几乎不需要进一步微调。实验表明，该模型在多个任务上具有良好的泛化能力，包括响应排名、从人类反馈中进行强化学习和带有微调的任务适应，并在多个基准模型上实现了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;In aligning large language models (LLMs), reward models have played an important role, but are standardly trained as discriminative models and rely only on labeled human preference data. In this paper, we explore methods that train reward models using both unlabeled and labeled data. Building on the generative models in LLMs, we develop a generative reward model that is first trained via large-scale unsupervised learning and then fine-tuned via supervised learning. We also show that by using label smoothing, we are in fact optimizing a regularized pairwise ranking loss. This result, in turn, provides a new view of training reward models, which links generative models and discriminative models under the same class of training objectives. The outcome of these techniques is a foundation reward model, which can be applied to a wide range of tasks with little or no further fine-tuning effort. Extensive experiments show that this model generalizes well across several tasks, including response ranking, reinforcement learning from human feedback, and task adaptation with fine-tuning, achieving significant performance improvements over several strong baseline models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In aligning large language models (LLMs), reward models have played animportant role, but are standardly trained as discriminative models and relyonly on labeled human preference data. In this paper, we explore methods thattrain reward models using both unlabeled and labeled data. Building on thegenerative models in LLMs, we develop a generative reward model that is firsttrained via large-scale unsupervised learning and then fine-tuned viasupervised learning. We also show that by using label smoothing, we are in factoptimizing a regularized pairwise ranking loss. This result, in turn, providesa new view of training reward models, which links generative models anddiscriminative models under the same class of training objectives. The outcomeof these techniques is a foundation reward model, which can be applied to awide range of tasks with little or no further fine-tuning effort. Extensiveexperiments show that this model generalizes well across several tasks,including response ranking, reinforcement learning from human feedback, andtask adaptation with fine-tuning, achieving significant performanceimprovements over several strong baseline models.</description>
      <author>example@mail.com (Chenglong Wang, Yang Gan, Yifu Huo, Yongyu Mu, Qiaozhi He, Murun Yang, Bei Li, Tong Xiao, Chunliang Zhang, Tongran Liu, Jingbo Zhu)</author>
      <guid isPermaLink="false">2506.14175v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Image Segmentation with Large Language Models: A Survey with Perspectives for Intelligent Transportation Systems</title>
      <link>http://arxiv.org/abs/2506.14096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了LLM辅助图像分割的领域，探讨了其在智能交通系统中的应用、挑战和未来方向。&lt;h4&gt;背景&lt;/h4&gt;LLM与计算机视觉的结合正在深刻地改变图像分割等感知任务，对智能交通系统（ITS）中的场景理解至关重要。&lt;h4&gt;目的&lt;/h4&gt;系统性地回顾LLM辅助图像分割领域，关注其在ITS中的应用、挑战和未来方向。&lt;h4&gt;方法&lt;/h4&gt;提供基于提示机制和核心架构的分类法，并强调这些创新如何增强自动驾驶、交通监控和基础设施维护中的道路场景理解。&lt;h4&gt;主要发现&lt;/h4&gt;识别了关键挑战，包括实时性能和安全性，并提出了以可解释、以人为本的AI为中心的视角。&lt;h4&gt;结论&lt;/h4&gt;LLM辅助图像分割技术对于下一代交通系统成功部署是必要的，但需要解决实时性能和安全性等关键挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of Large Language Models (LLMs) with computer vision isprofoundly transforming perception tasks like image segmentation. Forintelligent transportation systems (ITS), where accurate scene understanding iscritical for safety and efficiency, this new paradigm offers unprecedentedcapabilities. This survey systematically reviews the emerging field ofLLM-augmented image segmentation, focusing on its applications, challenges, andfuture directions within ITS. We provide a taxonomy of current approaches basedon their prompting mechanisms and core architectures, and we highlight howthese innovations can enhance road scene understanding for autonomous driving,traffic monitoring, and infrastructure maintenance. Finally, we identify keychallenges, including real-time performance and safety-critical reliability,and outline a perspective centered on explainable, human-centric AI as aprerequisite for the successful deployment of this technology innext-generation transportation systems.</description>
      <author>example@mail.com (Sanjeda Akter, Ibne Farabi Shihab, Anuj Sharma)</author>
      <guid isPermaLink="false">2506.14096v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>DeSPITE: Exploring Contrastive Deep Skeleton-Pointcloud-IMU-Text Embeddings for Advanced Point Cloud Human Activity Understanding</title>
      <link>http://arxiv.org/abs/2506.13897v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work is currently under review at ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用LiDAR技术进行多模态对比预训练以理解人类活动的方法，提出了一种名为DeSPITE的深度骨骼-点云-IMU-文本嵌入模型，通过实验展示了其在人类活动理解任务中的有效性。&lt;h4&gt;背景&lt;/h4&gt;LiDAR作为RGB相机的隐私保护替代品，在感知人类活动方面有效，但在多模态对比预训练领域研究不足。&lt;h4&gt;目的&lt;/h4&gt;探索在联合嵌入空间中学习LiDAR点云、人体骨骼姿态、IMU数据和文本之间的对应关系。&lt;h4&gt;方法&lt;/h4&gt;提出DeSPITE模型，通过噪声对比估计学习四种模态的联合嵌入空间，并结合LIPD和Babel数据集进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;DeSPITE能够实现骨骼与点云、IMU之间的匹配和检索，以及时间瞬间检索等新的人类活动理解任务；DeSPITE在点云人类活动识别（HAR）任务中表现出有效的预训练策略。&lt;h4&gt;结论&lt;/h4&gt;DeSPITE模型在多模态对比预训练中有效，能够提升人类活动理解任务的表现。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管LiDAR（光探测与测距）是RGB相机在感知人类活动方面的有效隐私保护替代品，但在多模态对比预训练（例如，人类活动识别（HAR）、检索或人员重识别（RE-ID））的背景下，它仍然被大量未开发。为了填补这一空白，我们的工作探索了在联合嵌入空间中学习LiDAR点云、人体骨骼姿态、IMU数据和文本之间的对应关系。更具体地说，我们提出了DeSPITE，一个深度骨骼-点云-IMU-文本嵌入模型，它通过噪声对比估计有效地学习这四种模态的联合嵌入空间。在我们经验探索的核心，我们结合了现有的LIPD和Babel数据集，这使得我们能够同步所有四种模态的数据，使我们能够探索新联合嵌入空间的学习。我们的实验展示了通过DeSPITE实现的点云序列的新人类活动理解任务，包括骨骼&lt;-&gt;点云&lt;-&gt;IMU匹配、检索和时间瞬间检索。此外，我们通过在MSR-Action3D和HMPEAR上的实验表明，DeSPITE是一种有效的点云HAR预训练策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite LiDAR (Light Detection and Ranging) being an effectiveprivacy-preserving alternative to RGB cameras to perceive human activities, itremains largely underexplored in the context of multi-modal contrastivepre-training for human activity understanding (e.g., human activity recognition(HAR), retrieval, or person re-identification (RE-ID)). To close this gap, ourwork explores learning the correspondence between LiDAR point clouds, humanskeleton poses, IMU data, and text in a joint embedding space. Morespecifically, we present DeSPITE, a Deep Skeleton-Pointcloud-IMU-Text Embeddingmodel, which effectively learns a joint embedding space across these fourmodalities through noise contrastive estimation. At the heart of our empiricalexploration, we have combined the existing LIPD and Babel datasets, whichenabled us to synchronize data of all four modalities, allowing us to explorethe learning of a new joint embedding space. Our experiments demonstrate novelhuman activity understanding tasks for point cloud sequences enabled throughDeSPITE, including Skeleton&lt;-&gt;Pointcloud&lt;-&gt;IMU matching, retrieval, andtemporal moment retrieval. Furthermore, we show that DeSPITE is an effectivepre-training strategy for point cloud HAR through experiments in MSR-Action3Dand HMPEAR.</description>
      <author>example@mail.com (Thomas Kreutz, Max Mühlhäuser, Alejandro Sanchez Guinea)</author>
      <guid isPermaLink="false">2506.13897v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Loss Functions for Graph Neural Networks: Towards Pretraining and Generalization</title>
      <link>http://arxiv.org/abs/2506.14114v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACM single column 633 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究对图神经网络（GNN）在各种任务中的表现进行了大规模评估，重点关注模型架构和损失函数的组合效果。&lt;h4&gt;背景&lt;/h4&gt;GNN在非欧几里得数据学习中变得非常有用，但其最佳性能依赖于选择合适的模型架构和训练目标（损失函数）。&lt;h4&gt;目的&lt;/h4&gt;评估GNN模型和多种损失函数在不同任务中的组合效果。&lt;h4&gt;方法&lt;/h4&gt;研究了七种著名的GNN架构和30种单一的以及混合的损失函数，在三个不同的真实世界数据集上进行了评估，使用了21个综合评估指标。&lt;h4&gt;主要发现&lt;/h4&gt;1）混合损失函数通常比单一损失函数产生更优越和更鲁棒的性能；2）GIN架构总是展现出最高的平均性能，尤其是在使用交叉熵损失函数时；3）尽管某些组合的平均排名较低，但GAT模型（特别是与某些混合损失函数结合时）展示了惊人的专业化优势；4）MPNN架构通常在其测试场景中表现滞后。&lt;h4&gt;结论&lt;/h4&gt;混合损失函数和GIN架构在GNN模型中表现出色，而GAT和MPNN在某些情况下也有其特定的优势或劣势。&lt;h4&gt;翻译&lt;/h4&gt;The study evaluated the performance of Graph Neural Networks (GNN) in various tasks, focusing on the combination effects of model architectures and loss functions. The research studied seven well-known GNN architectures and 30 single as well as mixed loss functions, evaluated on three distinct real-world datasets with 21 comprehensive evaluation metrics. The main findings are: 1) Hybrid loss functions generally yield superior and more robust performance compared to single loss functions, indicating the benefit of multi-objective optimization; 2) The GIN architecture always showed the highest-level average performance, especially with Cross-Entropy loss; 3) Although some combinations had overall lower average ranks, models such as GAT, particularly with certain hybrid losses, demonstrated incredible specialized strengths, maximizing the most top-1 results among the individual metrics, emphasizing subtle strengths for particular task demands; 4) On the other hand, the MPNN architecture typically lagged behind the scenarios it was tested against. The conclusion is that hybrid loss functions and the GIN architecture perform well in GNN models, while GAT and MPNN have specific advantages or disadvantages in certain cases.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) became useful for learning on non-Euclideandata. However, their best performance depends on choosing the right modelarchitecture and the training objective, also called the loss function.Researchers have studied these parts separately, but a large-scale evaluationhas not looked at how GNN models and many loss functions work together acrossdifferent tasks. To fix this, we ran a thorough study - it included sevenwell-known GNN architectures. We also used a large group of 30 single plusmixed loss functions. The study looked at both inductive and transductivesettings. Our evaluation spanned three distinct real-world datasets, assessingperformance in both inductive and transductive settings using 21 comprehensiveevaluation metrics. From these extensive results (detailed in supplementaryinformation 1 \&amp; 2), we meticulously analyzed the top ten model-losscombinations for each metric based on their average rank. Our findings revealthat, especially for the inductive case: 1) Hybrid loss functions generallyyield superior and more robust performance compared to single loss functions,indicating the benefit of multi-objective optimization. 2) The GIN architecturealways showed the highest-level average performance, especially withCross-Entropy loss. 3) Although some combinations had overall lower averageranks, models such as GAT, particularly with certain hybrid losses,demonstrated incredible specialized strengths, maximizing the most top-1results among the individual metrics, emphasizing subtle strengths forparticular task demands. 4) On the other hand, the MPNN architecture typicallylagged behind the scenarios it was tested against.</description>
      <author>example@mail.com (Khushnood Abbas, Ruizhe Hou, Zhou Wengang, Dong Shi, Niu Ling, Satyaki Nan, Alireza Abbasi)</author>
      <guid isPermaLink="false">2506.14114v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Quantum-Informed Contrastive Learning with Dynamic Mixup Augmentation for Class-Imbalanced Expert Systems</title>
      <link>http://arxiv.org/abs/2506.13987v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为QCL-MixNet的量子信息对比学习框架，用于解决专家系统中类不平衡的表格数据问题，以提高分类的鲁棒性和准确性。&lt;h4&gt;背景&lt;/h4&gt;专家系统在处理类不平衡的表格数据时，检测罕见但关键实例对于安全性和可靠性至关重要。传统的解决方案如成本敏感学习、过采样和图神经网络存在过拟合、标签噪声和低密度区域泛化能力差等问题。&lt;h4&gt;目的&lt;/h4&gt;提出QCL-MixNet以解决上述挑战，实现鲁棒的分类。&lt;h4&gt;方法&lt;/h4&gt;QCL-MixNet集成了三个核心创新：(i)一个受量子纠缠启发的层，通过正弦变换和门控注意力建模复杂特征交互；(ii)一个样本感知的mixup策略，自适应地插值语义相似实例的特征表示以增强少数类的表示；(iii)一个混合损失函数，统一了焦点重新加权、监督对比学习、三元组损失和方差正则化，以提高类内紧凑性和类间可分性。&lt;h4&gt;主要发现&lt;/h4&gt;在18个真实世界的不平衡数据集上进行的实验表明，QCL-MixNet在宏观F1和召回率方面一致优于20个最先进的机器学习、深度学习和基于GNN的基线。&lt;h4&gt;结论&lt;/h4&gt;QCL-MixNet在处理表格数据不平衡方面建立了一个新的基准，其理论分析证实了其表达能力、泛化能力和优化鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：专家系统通常在具有类不平衡的表格数据域中运行，在这些域中检测罕见但关键的实例对于安全和可靠性至关重要。虽然传统的解决方案，如成本敏感学习、过采样和图神经网络，提供了部分解决方案，但它们存在过拟合、标签噪声和在低密度区域泛化能力差等缺点。为了解决这些挑战，我们提出了QCL-MixNet，一种新型的量子信息对比学习框架，该框架通过k-最近邻（kNN）引导的动态mixup增强了不平衡下的鲁棒分类。QCL-MixNet集成了三个核心创新：(i)一个受量子纠缠启发的层，通过正弦变换和门控注意力建模复杂特征交互；(ii)一个样本感知的mixup策略，自适应地插值语义相似实例的特征表示以增强少数类的表示；(iii)一个混合损失函数，统一了焦点重新加权、监督对比学习、三元组损失和方差正则化，以提高类内紧凑性和类间可分性。在18个真实世界的不平衡数据集（二分类和多分类）上的广泛实验表明，QCL-MixNet在宏观F1和召回率方面一致优于20个最先进的机器学习、深度学习和基于GNN的基线。消融研究进一步验证了每个架构组件的关键作用。我们的结果将QCL-MixNet确立为专家系统中处理表格数据不平衡的新基准。理论分析证实了其表达能力、泛化能力和优化鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Expert systems often operate in domains characterized by class-imbalancedtabular data, where detecting rare but critical instances is essential forsafety and reliability. While conventional approaches, such as cost-sensitivelearning, oversampling, and graph neural networks, provide partial solutions,they suffer from drawbacks like overfitting, label noise, and poorgeneralization in low-density regions. To address these challenges, we proposeQCL-MixNet, a novel Quantum-Informed Contrastive Learning framework augmentedwith k-nearest neighbor (kNN) guided dynamic mixup for robust classificationunder imbalance. QCL-MixNet integrates three core innovations: (i) a QuantumEntanglement-inspired layer that models complex feature interactions throughsinusoidal transformations and gated attention, (ii) a sample-aware mixupstrategy that adaptively interpolates feature representations of semanticallysimilar instances to enhance minority class representation, and (iii) a hybridloss function that unifies focal reweighting, supervised contrastive learning,triplet margin loss, and variance regularization to improve both intra-classcompactness and inter-class separability. Extensive experiments on 18real-world imbalanced datasets (binary and multi-class) demonstrate thatQCL-MixNet consistently outperforms 20 state-of-the-art machine learning, deeplearning, and GNN-based baselines in macro-F1 and recall, often by substantialmargins. Ablation studies further validate the critical role of eacharchitectural component. Our results establish QCL-MixNet as a new benchmarkfor tabular imbalance handling in expert systems. Theoretical analysesreinforce its expressiveness, generalization, and optimization robustness.</description>
      <author>example@mail.com (Md Abrar Jahin, Adiba Abid, M. F. Mridha)</author>
      <guid isPermaLink="false">2506.13987v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-shot Subset Selection</title>
      <link>http://arxiv.org/abs/2506.14473v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 10 figures, accepted by ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于基础模型（FM）的one-shot子集选择方法，旨在降低深度学习训练成本，并通过实验证明其在细粒度数据集上优于传统信息提取方法。&lt;h4&gt;背景&lt;/h4&gt;传统的信息提取器（IE）依赖于特定数据集进行预训练，存在数据集依赖性。基础模型（FM）提供了一种替代方案，可能减轻这种限制。&lt;h4&gt;目的&lt;/h4&gt;研究基于FM的子集选择是否能优于传统的IE方法，并探究是否所有FM在子集选择中表现相同。&lt;h4&gt;方法&lt;/h4&gt;提出了RAM-APL方法，针对细粒度图像数据集，通过利用多个FM的互补优势来增强子集选择。&lt;h4&gt;主要发现&lt;/h4&gt;FM在细粒度数据集上优于传统IE，但在粗粒度数据集尤其是带噪声标签的数据集上，其优势减弱。&lt;h4&gt;结论&lt;/h4&gt;RAM-APL方法在细粒度数据集上取得了最先进的性能，包括Oxford-IIIT Pet、Food-101和Caltech-UCSD Birds-200-2011数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; One-shot subset selection serves as an effective tool to reduce deep learningtraining costs by identifying an informative data subset based on theinformation extracted by an information extractor (IE). Traditional IEs,typically pre-trained on the target dataset, are inherently dataset-dependent.Foundation models (FMs) offer a promising alternative, potentially mitigatingthis limitation. This work investigates two key questions: (1) Can FM-basedsubset selection outperform traditional IE-based methods across diversedatasets? (2) Do all FMs perform equally well as IEs for subset selection?Extensive experiments uncovered surprising insights: FMs consistentlyoutperform traditional IEs on fine-grained datasets, whereas their advantagediminishes on coarse-grained datasets with noisy labels. Motivated by thesefinding, we propose RAM-APL (RAnking Mean-Accuracy of Pseudo-class Labels), amethod tailored for fine-grained image datasets. RAM-APL leverages multiple FMsto enhance subset selection by exploiting their complementary strengths. Ourapproach achieves state-of-the-art performance on fine-grained datasets,including Oxford-IIIT Pet, Food-101, and Caltech-UCSD Birds-200-2011.</description>
      <author>example@mail.com (Zhijing Wan, Zhixiang Wang, Zheng Wang, Xin Xu, Shin'ichi Satoh)</author>
      <guid isPermaLink="false">2506.14473v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Less is More: Undertraining Experts Improves Model Upcycling</title>
      <link>http://arxiv.org/abs/2506.14126v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了专家模型微调对模型升级的影响，发现过度微调会导致合并性能下降，并提出了任务依赖的早期停止策略以改善升级性能。&lt;h4&gt;背景&lt;/h4&gt;现代深度学习使用开放权重基础模型，这些模型可以在专用数据集上微调，形成了预训练、微调和升级的流水线。&lt;h4&gt;目的&lt;/h4&gt;挑战现有假设，即流水线中某一阶段的改进会传播到后续阶段，研究专家微调如何影响模型升级。&lt;h4&gt;方法&lt;/h4&gt;通过实验分析专家微调对模型升级的影响，并追踪性能下降的原因。&lt;h4&gt;主要发现&lt;/h4&gt;长时间微调专家模型会导致合并性能下降，并且当LoRA适配器升级到MoE层时，下游结果也会变差。性能下降归因于在微调后期记忆的一小部分困难示例，这些示例在合并过程中被遗忘。&lt;h4&gt;结论&lt;/h4&gt;提出了一种任务依赖的早期停止策略，可以显著提高模型升级的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern deep learning is increasingly characterized by the use of open-weightfoundation models that can be fine-tuned on specialized datasets. This has ledto a proliferation of expert models and adapters, often shared via platformslike HuggingFace and AdapterHub. To leverage these resources, numerous modelupcycling methods have emerged, enabling the reuse of fine-tuned models inmulti-task systems. A natural pipeline has thus formed to harness the benefitsof transfer learning and amortize sunk training costs: models are pre-trainedon general data, fine-tuned on specific tasks, and then upcycled into moregeneral-purpose systems. A prevailing assumption is that improvements at onestage of this pipeline propagate downstream, leading to gains at subsequentsteps. In this work, we challenge that assumption by examining how expertfine-tuning affects model upcycling. We show that long fine-tuning of expertsthat optimizes for their individual performance leads to degraded mergingperformance, both for fully fine-tuned and LoRA-adapted models, and to worsedownstream results when LoRA adapters are upcycled into MoE layers. We tracethis degradation to the memorization of a small set of difficult examples thatdominate late fine-tuning steps and are subsequently forgotten during merging.Finally, we demonstrate that a task-dependent aggressive early stoppingstrategy can significantly improve upcycling performance.</description>
      <author>example@mail.com (Stefan Horoi, Guy Wolf, Eugene Belilovsky, Gintare Karolina Dziugaite)</author>
      <guid isPermaLink="false">2506.14126v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Density-aware Walks for Coordinated Campaign Detection</title>
      <link>http://arxiv.org/abs/2506.13912v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 Pages. Accepted at ECML-PKDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了如何检测社交媒体上的协调活动，提出了一种基于图分类的方法，利用了Large Engagement Networks (LEN) 数据集，并引入了随机加权行走（RWW）方法，提高了识别协调虚假行为的准确性。&lt;h4&gt;背景&lt;/h4&gt;协调活动经常通过社交媒体平台放大话题，制造虚假趋势，误导用户参与。区分这些协调活动与真实公共讨论是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来检测社交媒体上的协调活动，特别是针对Twitter平台。&lt;h4&gt;方法&lt;/h4&gt;将问题建模为图分类任务，利用LEN数据集，引入了基于局部网络结构密度的图分类方法，并使用随机加权行走（RWW）和Skip-gram模型进行节点嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;新提出的图分类方法在LEN数据集上表现优于传统的图神经网络（GNNs），在二分类和多分类任务中分别提高了约12%和5%的准确率。&lt;h4&gt;结论&lt;/h4&gt;通过结合密度感知结构编码与消息传递神经网络（MPNNs），为识别社交媒体网络上的协调虚假行为提供了一种鲁棒的框架。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了如何检测社交媒体上的协调活动，通过将问题建模为图分类任务，并利用Large Engagement Networks (LEN) 数据集，提出了一种新的基于局部网络结构密度的图分类方法。该方法通过随机加权行走（RWW）和Skip-gram模型生成节点嵌入，显著提高了识别协调虚假行为的准确性，特别是在Twitter等社交媒体网络上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Coordinated campaigns frequently exploit social media platforms byartificially amplifying topics, making inauthentic trends appear organic, andmisleading users into engagement. Distinguishing these coordinated efforts fromgenuine public discourse remains a significant challenge due to thesophisticated nature of such attacks. Our work focuses on detecting coordinatedcampaigns by modeling the problem as a graph classification task. We leveragethe recently introduced Large Engagement Networks (LEN) dataset, which containsover 300 networks capturing engagement patterns from both fake and authentictrends on Twitter prior to the 2023 Turkish elections. The graphs in LEN wereconstructed by collecting interactions related to campaigns that stemmed fromephemeral astroturfing. Established graph neural networks (GNNs) struggle toaccurately classify campaign graphs, highlighting the challenges posed by LENdue to the large size of its networks. To address this, we introduce a newgraph classification method that leverages the density of local networkstructures. We propose a random weighted walk (RWW) approach in which nodetransitions are biased by local density measures such as degree, core number,or truss number. These RWWs are encoded using the Skip-gram model, producingdensity-aware structural embeddings for the nodes. Training message-passingneural networks (MPNNs) on these density-aware embeddings yields superiorresults compared to the simpler node features available in the dataset, withnearly a 12\% and 5\% improvement in accuracy for binary and multiclassclassification, respectively. Our findings demonstrate that incorporatingdensity-aware structural encoding with MPNNs provides a robust framework foridentifying coordinated inauthentic behavior on social media networks such asTwitter.</description>
      <author>example@mail.com (Atul Anand Gopalakrishnan, Jakir Hossain, Tuğrulcan Elmas, Ahmet Erdem Sarıyüce)</author>
      <guid isPermaLink="false">2506.13912v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Logical Expressiveness of Graph Neural Networks with Hierarchical Node Individualization</title>
      <link>http://arxiv.org/abs/2506.13911v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to NeurIPS 2025, 28 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出并研究了分层自我图神经网络（HEGNNs），这是图神经网络（GNNs）的扩展，具有分层节点个性化，受图同构测试的个性化-细化范式启发。HEGNNs推广了子图-GNNs，形成了一个越来越有表达力的模型层次，最终可以区分同构的图。使用分级混合逻辑提供了HEGNN节点分类器的逻辑特征描述，无论是否有子图限制，并将HEGNNs的分离能力与高阶GNNs、增强局部同态计数特征的GNNs以及基于个性化-细化算法的颜色细化算法相关联。实验结果证实了HEGNNs的实用性，并显示出与传统GNN架构相比的优势，无论是带有还是不带局部同态计数特征。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在图同构测试中的个性化-细化范式。&lt;h4&gt;目的&lt;/h4&gt;提出分层自我图神经网络（HEGNNs），以扩展图神经网络（GNNs）并提高其表达力和同构检测能力。&lt;h4&gt;方法&lt;/h4&gt;使用分级混合逻辑对HEGNN节点分类器进行逻辑特征描述，并将其与高阶GNNs、增强局部同态计数特征的GNNs和颜色细化算法进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;HEGNNs可以推广子图-GNNs，形成了一个有表达力的模型层次，可以区分同构的图。HEGNNs的分离能力与高阶GNNs、增强局部同态计数特征的GNNs和颜色细化算法相当。&lt;h4&gt;结论&lt;/h4&gt;HEGNNs具有实用性，与传统GNN架构相比显示出优势。&lt;h4&gt;翻译&lt;/h4&gt;We propose and study Hierarchical Ego Graph Neural Networks (HEGNNs), an expressive extension of graph neural networks (GNNs) with hierarchical node individualization, inspired by the Individualization-Refinement paradigm for graph isomorphism testing. HEGNNs generalize subgraph-GNNs and form a hierarchy of increasingly expressive models that, in the limit, can distinguish graphs up to isomorphism. We provide a logical characterization of HEGNN node classifiers, with and without subgraph restrictions, using graded hybrid logic. This characterization enables us to relate the separating power of HEGNNs to that of higher-order GNNs, GNNs enriched with local homomorphism count features, and color refinement algorithms based on Individualization-Refinement. Our experimental results confirm the practical feasibility of HEGNNs and show benefits in comparison with traditional GNN architectures, both with and without local homomorphism count features.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose and study Hierarchical Ego Graph Neural Networks (HEGNNs), anexpressive extension of graph neural networks (GNNs) with hierarchical nodeindividualization, inspired by the Individualization-Refinement paradigm forgraph isomorphism testing. HEGNNs generalize subgraph-GNNs and form a hierarchyof increasingly expressive models that, in the limit, can distinguish graphs upto isomorphism. We provide a logical characterization of HEGNN nodeclassifiers, with and without subgraph restrictions, using graded hybrid logic.This characterization enables us to relate the separating power of HEGNNs tothat of higher-order GNNs, GNNs enriched with local homomorphism countfeatures, and color refinement algorithms based onIndividualization-Refinement. Our experimental results confirm the practicalfeasibility of HEGNNs and show benefits in comparison with traditional GNNarchitectures, both with and without local homomorphism count features.</description>
      <author>example@mail.com (Arie Soeteman, Balder ten Cate)</author>
      <guid isPermaLink="false">2506.13911v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>GITO: Graph-Informed Transformer Operator for Learning Complex Partial Differential Equations</title>
      <link>http://arxiv.org/abs/2506.13906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图信息变换器操作器（GITO）架构，用于学习定义在非规则几何和非均匀网格上的复杂偏微分方程系统。&lt;h4&gt;背景&lt;/h4&gt;现有的方法在处理非规则几何和非均匀网格上的复杂偏微分方程系统时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效处理此类复杂系统的神经网络架构。&lt;h4&gt;方法&lt;/h4&gt;GITO由两个主要模块组成：混合图变换器（HGT）和变换器神经操作器（TNO）。HGT利用图神经网络（GNN）编码局部空间关系，并使用变换器捕获长距离依赖。自我注意力融合层将GNN和变换器的输出整合，以在图结构数据上实现更具表现力的特征学习。TNO模块采用线性复杂度的交叉注意力和自我注意力层，将编码的输入函数映射到任意查询位置的预测，确保离散化不变性，并允许在任何网格上进行零样本超分辨率。&lt;h4&gt;主要发现&lt;/h4&gt;GITO在基准PDE任务上的实证结果表明，它优于现有的基于变换器的神经操作器。&lt;h4&gt;结论&lt;/h4&gt;GITO为工程应用中的高效、网格无关的代理求解器铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新的图信息变换器操作器（GITO）架构，用于学习定义在非规则几何和非均匀网格上的复杂偏微分方程系统。GITO包括两个主要模块：混合图变换器（HGT）和变换器神经操作器（TNO）。HGT利用图神经网络（GNN）编码局部空间关系，并使用变换器捕获长距离依赖。自我注意力融合层将GNN和变换器的输出整合，以在图结构数据上实现更具表现力的特征学习。TNO模块采用线性复杂度的交叉注意力和自我注意力层，将编码的输入函数映射到任意查询位置的预测，确保离散化不变性，并允许在任何网格上进行零样本超分辨率。基准PDE任务上的实证结果表明，GITO优于现有的基于变换器的神经操作器，为工程应用中的高效、网格无关的代理求解器铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel graph-informed transformer operator (GITO) architecturefor learning complex partial differential equation systems defined on irregulargeometries and non-uniform meshes. GITO consists of two main modules: a hybridgraph transformer (HGT) and a transformer neural operator (TNO). HGT leveragesa graph neural network (GNN) to encode local spatial relationships and atransformer to capture long-range dependencies. A self-attention fusion layerintegrates the outputs of the GNN and transformer to enable more expressivefeature learning on graph-structured data. TNO module employs linear-complexitycross-attention and self-attention layers to map encoded input functions topredictions at arbitrary query locations, ensuring discretization invarianceand enabling zero-shot super-resolution across any mesh. Empirical results onbenchmark PDE tasks demonstrate that GITO outperforms existingtransformer-based neural operators, paving the way for efficient, mesh-agnosticsurrogate solvers in engineering applications.</description>
      <author>example@mail.com (Milad Ramezankhani, Janak M. Patel, Anirudh Deodhar, Dagnachew Birru)</author>
      <guid isPermaLink="false">2506.13906v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>MoORE: SVD-based Model MoE-ization for Conflict- and Oblivion-Resistant Multi-Task Adaptation</title>
      <link>http://arxiv.org/abs/2506.14436v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MoORE的多任务自适应方法，以解决大规模基础模型在多任务场景中的任务冲突和遗忘问题。&lt;h4&gt;背景&lt;/h4&gt;在多任务场景中，大规模基础模型经常遇到任务冲突和遗忘问题。&lt;h4&gt;目的&lt;/h4&gt;为了减轻这些问题，提出了一种新的“模型MoE化”策略。&lt;h4&gt;方法&lt;/h4&gt;该方法首先对预训练模型的权重矩阵应用奇异值分解（SVD），然后引入一个可学习的路由器来根据任务和样本调整其奇异值。权重矩阵变为MoORE（混合正交秩一专家），其中每个专家对应于左奇异向量和对应右奇异向量的外积。通过在右奇异向量上施加可学习的正交变换来提高模型容量。&lt;h4&gt;主要发现&lt;/h4&gt;MoORE保证了专家的正交性并保持原始权重矩阵的列空间，这两个特性使得自适应模型能够抵抗新任务之间的冲突和原始任务的遗忘。&lt;h4&gt;结论&lt;/h4&gt;在多个数据集上的实验表明，MoORE在冲突和遗忘抵抗方面优于现有的多任务自适应方法。&lt;h4&gt;翻译&lt;/h4&gt;Adapting large-scale foundation models in multi-task scenarios often suffers from task conflict and oblivion. To mitigate such issues, we propose a novel 'model MoE-ization' strategy that leads to a conflict- and oblivion-resistant multi-task adaptation method. Given a weight matrix of a pre-trained model, our method applies SVD to it and introduces a learnable router to adjust its singular values based on tasks and samples. Accordingly, the weight matrix becomes a Mixture of Orthogonal Rank-one Experts (MoORE), in which each expert corresponds to the outer product of a left singular vector and the corresponding right one. We can improve the model capacity by imposing a learnable orthogonal transform on the right singular vectors. Unlike low-rank adaptation (LoRA) and its MoE-driven variants, MoORE guarantees the experts' orthogonality and maintains the column space of the original weight matrix. These two properties make the adapted model resistant to the conflicts among the new tasks and the oblivion of its original tasks, respectively. Experiments on various datasets demonstrate that MoORE outperforms existing multi-task adaptation methods consistently, showing its superiority in terms of conflict-and oblivion-resistance. The code of the experiments is available at https://github.com/DaShenZi721/MoORE.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adapting large-scale foundation models in multi-task scenarios often suffersfrom task conflict and oblivion. To mitigate such issues, we propose a novel''model MoE-ization'' strategy that leads to a conflict- and oblivion-resistantmulti-task adaptation method. Given a weight matrix of a pre-trained model, ourmethod applies SVD to it and introduces a learnable router to adjust itssingular values based on tasks and samples. Accordingly, the weight matrixbecomes a Mixture of Orthogonal Rank-one Experts (MoORE), in which each expertcorresponds to the outer product of a left singular vector and thecorresponding right one. We can improve the model capacity by imposing alearnable orthogonal transform on the right singular vectors. Unlike low-rankadaptation (LoRA) and its MoE-driven variants, MoORE guarantees the experts'orthogonality and maintains the column space of the original weight matrix.These two properties make the adapted model resistant to the conflicts amongthe new tasks and the oblivion of its original tasks, respectively. Experimentson various datasets demonstrate that MoORE outperforms existing multi-taskadaptation methods consistently, showing its superiority in terms of conflict-and oblivion-resistance. The code of the experiments is available athttps://github.com/DaShenZi721/MoORE.</description>
      <author>example@mail.com (Shen Yuan, Yin Zheng, Taifeng Wang, Binbin Liu, Hongteng Xu)</author>
      <guid isPermaLink="false">2506.14436v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Transfer Learning and User-Specific Updates for Rapid Training of BCI Decoders</title>
      <link>http://arxiv.org/abs/2506.14120v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 page conference proceeding preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于两层数卷积神经网络（CNN）的迁移学习流程，利用EEG数据中的跨主体、跨会话不变特征，以减少数据获取和校准的负担，从而提高脑机接口（BCI）在实验室外的部署。&lt;h4&gt;背景&lt;/h4&gt;长时间的主题或会话特定数据获取和校准是EEG-BCI在实验室外部署的关键障碍。&lt;h4&gt;目的&lt;/h4&gt;通过利用EEG数据中的不变特征，减少数据获取和校准的负担，以提高BCI的性能。&lt;h4&gt;方法&lt;/h4&gt;使用五名健康个体的EEG数据训练基线模型，然后用第六名个体的少量数据快速更新模型。剩余的保留数据用于测试基线和更新后的模型性能。通过留一法（LOSO）验证框架重复此过程。&lt;h4&gt;主要发现&lt;/h4&gt;在六次LOSO折叠的平均结果中，更新后的模型在两个二元和一项三元分类任务上分别提高了10.0、18.8和22.1个百分点的分类准确率。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，通过最小数量的主题特定数据，解码精度可以显著提高。同时，CNN解码器可以快速个性化，使得BCI功能能够快速部署，适用于神经康复和其他时间敏感的EEG应用。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a transfer learning pipeline based on a two-layer convolutional neural network (CNN) that leverages these invariants to reduce the burden of data acquisition and calibration, thereby improving the performance of brain-computer interfaces (BCIs) outside the laboratory. The background is that lengthy subject- or session-specific data acquisition and calibration remain a key barrier to deploying EEG-based BCIs outside the laboratory. The aim is to reduce the burden of data acquisition and calibration by utilizing invariants in EEG data to improve the performance of BCI. The method involves training a baseline model on EEG data from five able-bodied individuals and then rapidly updating it with a small amount of data from a sixth, holdout subject. The remaining holdout data were used to test the performance of both the baseline and updated models. This procedure was repeated via a leave-one-subject out (LOSO) validation framework. The main findings are that, on average over six LOSO folds, the updated model improved classification accuracy by 10.0, 18.8, and 22.1 percentage points on two binary and one ternary classification tasks, respectively. The conclusions are that decoding accuracy can be substantially improved with minimal subject-specific data, and that a CNN-based decoder can be personalized rapidly, enabling near plug-and-play BCI functionality for neurorehabilitation and other time-critical EEG applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lengthy subject- or session-specific data acquisition and calibration remaina key barrier to deploying electroencephalography (EEG)-based brain-computerinterfaces (BCIs) outside the laboratory. Previous work has shown that crosssubject, cross-session invariant features exist in EEG. We propose a transferlearning pipeline based on a two-layer convolutional neural network (CNN) thatleverages these invariants to reduce the burden of data acquisition andcalibration. A baseline model is trained on EEG data from five able-bodiedindividuals and then rapidly updated with a small amount of data from a sixth,holdout subject. The remaining holdout data were used to test the performanceof both the baseline and updated models. We repeated this procedure via aleave-one-subject out (LOSO) validation framework. Averaged over six LOSOfolds, the updated model improved classification accuracy upon the baseline by10.0, 18.8, and 22.1 percentage points on two binary and one ternaryclassification tasks, respectively. These results demonstrate that decodingaccuracy can be substantially improved with minimal subject-specific data. Theyalso indicate that a CNN-based decoder can be personalized rapidly, enablingnear plug-and-play BCI functionality for neurorehabilitation and othertime-critical EEG applications.</description>
      <author>example@mail.com (Ziheng Chen, Po T. Wang, Mina Ibrahim, Shivali Baveja, Rong Mu, An H. Do, Zoran Nenadic)</author>
      <guid isPermaLink="false">2506.14120v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Equivariance Everywhere All At Once: A Recipe for Graph Foundation Models</title>
      <link>http://arxiv.org/abs/2506.14291v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种设计图基础模型的方法，用于节点级任务，并强调了图基础模型必须尊重的对称性。&lt;h4&gt;背景&lt;/h4&gt;图机器学习架构通常针对特定数据集的特定任务进行定制，这限制了它们的广泛应用。&lt;h4&gt;目的&lt;/h4&gt;研究如何构建能够泛化到任意图和特征的图基础模型。&lt;h4&gt;方法&lt;/h4&gt;通过系统研究图基础模型必须尊重的对称性，包括节点和标签的置换等变性和特征置换不变性。首先，定义了与节点和标签置换等变且与特征置换不变的线性变换空间，然后证明了所得到的网络在尊重上述对称性的多重集上是通用逼近器。使用此类层对图局部邻域诱导的多重集进行操作，以获得一类用于节点属性预测的图基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;证明了所提出的网络在尊重上述对称性的多重集上是通用逼近器。&lt;h4&gt;结论&lt;/h4&gt;通过在29个现实世界的节点分类数据集上的大量实验验证了该方法，展示了强大的零样本经验性能，并且随着训练图数量的增加，性能持续改进。&lt;h4&gt;翻译&lt;/h4&gt;Graph machine learning architectures are typically tailored to specific tasks on specific datasets, which hinders their broader applicability. This has led to a new quest in graph machine learning: how to build graph foundation models capable of generalizing across arbitrary graphs and features? In this work, we present a recipe for designing graph foundation models for node-level tasks from first principles. The key ingredient underpinning our study is a systematic investigation of the symmetries that a graph foundation model must respect. In a nutshell, we argue that label permutation-equivariance alongside feature permutation-invariance are necessary in addition to the common node permutation-equivariance on each local neighborhood of the graph. To this end, we first characterize the space of linear transformations that are equivariant to permutations of nodes and labels, and invariant to permutations of features. We then prove that the resulting network is a universal approximator on multisets that respect the aforementioned symmetries. Our recipe uses such layers on the multiset of features induced by the local neighborhood of the graph to obtain a class of graph foundation models for node property prediction. We validate our approach through extensive experiments on 29 real-world node classification datasets, demonstrating both strong zero-shot empirical performance and consistent improvement as the number of training graphs increases.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph machine learning architectures are typically tailored to specific taskson specific datasets, which hinders their broader applicability. This has ledto a new quest in graph machine learning: how to build graph foundation modelscapable of generalizing across arbitrary graphs and features? In this work, wepresent a recipe for designing graph foundation models for node-level tasksfrom first principles. The key ingredient underpinning our study is asystematic investigation of the symmetries that a graph foundation model mustrespect. In a nutshell, we argue that label permutation-equivariance alongsidefeature permutation-invariance are necessary in addition to the common nodepermutation-equivariance on each local neighborhood of the graph. To this end,we first characterize the space of linear transformations that are equivariantto permutations of nodes and labels, and invariant to permutations of features.We then prove that the resulting network is a universal approximator onmultisets that respect the aforementioned symmetries. Our recipe uses suchlayers on the multiset of features induced by the local neighborhood of thegraph to obtain a class of graph foundation models for node propertyprediction. We validate our approach through extensive experiments on 29real-world node classification datasets, demonstrating both strong zero-shotempirical performance and consistent improvement as the number of traininggraphs increases.</description>
      <author>example@mail.com (Ben Finkelshtein, İsmail İlkan Ceylan, Michael Bronstein, Ron Levie)</author>
      <guid isPermaLink="false">2506.14291v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>SeqPE: Transformer with Sequential Position Encoding</title>
      <link>http://arxiv.org/abs/2506.13277v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SeqPE的统一可学习位置编码框架，用于解决Transformer中自注意力层的空间理解问题。&lt;h4&gt;背景&lt;/h4&gt;Transformer中的自注意力层设计上是对称不变的，因此需要显式地引入位置编码来实现空间理解。传统的可学习位置编码方法使用固定大小的查找表，限制了超出预训练序列长度的外推能力。&lt;h4&gt;目的&lt;/h4&gt;提出SeqPE框架，旨在解决位置编码的可扩展性和适应性挑战，并增强外推性能。&lt;h4&gt;方法&lt;/h4&gt;SeqPE将每个n维位置索引表示为符号序列，并使用轻量级的顺序位置编码器端到端地学习其嵌入。为了规范SeqPE的嵌入空间，引入了对比目标和知识蒸馏损失，以增强外推性能。&lt;h4&gt;主要发现&lt;/h4&gt;SeqPE在语言建模、长上下文问答和2D图像分类等任务中表现优于强基线，尤其是在上下文长度外推方面。SeqPE允许无缝泛化到多维输入，而无需手动架构设计。&lt;h4&gt;结论&lt;/h4&gt;SeqPE是一种有效的位置编码框架，能够提高Transformer模型在处理未知模态和长上下文时的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于Transformer中的自注意力层设计上是对称不变的，因此必须显式地引入位置编码来实现空间理解。然而，传统可学习位置编码中使用的固定大小查找表限制了超出预训练序列长度的外推能力。如ALiBi和RoPE等专家设计的方法减轻了这一限制，但需要大量修改以适应新的模态，这强调了适应性和可扩展性的基本挑战。在这项工作中，我们提出了SeqPE，一个统一且完全可学习的位置编码框架，将每个n维位置索引表示为符号序列，并使用轻量级的顺序位置编码器以端到端的方式学习它们的嵌入。为了规范SeqPE的嵌入空间，我们引入了两个互补的目标：一个对比目标，它将嵌入距离与预定义的位置-距离函数对齐，以及一个知识蒸馏损失，它将分布外位置嵌入锚定到分布内教师表示，从而进一步增强外推性能。在语言建模、长上下文问答和2D图像分类等任务上的实验表明，SeqPE不仅在困惑度、精确匹配（EM）和准确性方面超过了强基线，尤其是在上下文长度外推方面，而且允许无缝泛化到多维输入，而无需手动架构设计。我们在https://github.com/ghrua/seqpe上发布了我们的代码、数据和检查点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Since self-attention layers in Transformers are permutation invariant bydesign, positional encodings must be explicitly incorporated to enable spatialunderstanding. However, fixed-size lookup tables used in traditional learnableposition embeddings (PEs) limit extrapolation capabilities beyond pre-trainedsequence lengths. Expert-designed methods such as ALiBi and RoPE, mitigate thislimitation but demand extensive modifications for adapting to new modalities,underscoring fundamental challenges in adaptability and scalability. In thiswork, we present SeqPE, a unified and fully learnable position encodingframework that represents each $n$-dimensional position index as a symbolicsequence and employs a lightweight sequential position encoder to learn theirembeddings in an end-to-end manner. To regularize SeqPE's embedding space, weintroduce two complementary objectives: a contrastive objective that alignsembedding distances with a predefined position-distance function, and aknowledge distillation loss that anchors out-of-distribution positionembeddings to in-distribution teacher representations, further enhancingextrapolation performance. Experiments across language modeling, long-contextquestion answering, and 2D image classification demonstrate that SeqPE not onlysurpasses strong baselines in perplexity, exact match (EM), andaccuracy--particularly under context length extrapolation--but also enablesseamless generalization to multi-dimensional inputs without requiring manualarchitectural redesign. We release our code, data, and checkpoints athttps://github.com/ghrua/seqpe.</description>
      <author>example@mail.com (Huayang Li, Yahui Liu, Hongyu Sun, Deng Cai, Leyang Cui, Wei Bi, Peilin Zhao, Taro Watanabe)</author>
      <guid isPermaLink="false">2506.13277v2</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Acoustic scattering AI for non-invasive object classifications: A case study on hair assessment</title>
      <link>http://arxiv.org/abs/2506.14148v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于声学散射的非侵入式物体分类方法，并通过头发评估案例研究进行展示。&lt;h4&gt;背景&lt;/h4&gt;当入射波与物体相互作用时，会产生一个编码结构材料和特性的散射声场。&lt;h4&gt;目的&lt;/h4&gt;通过发射声学刺激并捕获带有头发样本的头部的散射信号，使用基于人工智能和深度学习的声音分类来分类头发类型和湿度。&lt;h4&gt;方法&lt;/h4&gt;本文将方法与包括完全监督深度学习、基于嵌入的分类、监督基础模型微调和自监督模型微调在内的全面方法进行了基准测试。最佳策略通过微调自监督模型的所有参数，实现了近90%的分类准确率。&lt;h4&gt;主要发现&lt;/h4&gt;这些结果突出了声学散射作为一种保护隐私的非接触式视觉分类替代品，在各个行业中具有巨大的应用潜力。&lt;h4&gt;结论&lt;/h4&gt;声学散射为物体分类提供了一种隐私保护、非接触的解决方案，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents a novel non-invasive object classification approach using acoustic scattering, demonstrated through a case study on hair assessment. When an incident wave interacts with an object, it generates a scattered acoustic field encoding structural and material properties. By emitting acoustic stimuli and capturing the scattered signals from head-with-hair-sample objects, we classify hair type and moisture using AI-driven, deep-learning-based sound classification. We benchmark comprehensive methods, including (i) fully supervised deep learning, (ii) embedding-based classification, (iii) supervised foundation model fine-tuning, and (iv) self-supervised model fine-tuning. Our best strategy achieves nearly 90% classification accuracy by fine-tuning all parameters of a self-supervised model. These results highlight acoustic scattering as a privacy-preserving, non-contact alternative to visual classification, opening huge potential for applications in various industries.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel non-invasive object classification approach usingacoustic scattering, demonstrated through a case study on hair assessment. Whenan incident wave interacts with an object, it generates a scattered acousticfield encoding structural and material properties. By emitting acoustic stimuliand capturing the scattered signals from head-with-hair-sample objects, weclassify hair type and moisture using AI-driven, deep-learning-based soundclassification. We benchmark comprehensive methods, including (i) fullysupervised deep learning, (ii) embedding-based classification, (iii) supervisedfoundation model fine-tuning, and (iv) self-supervised model fine-tuning. Ourbest strategy achieves nearly 90% classification accuracy by fine-tuning allparameters of a self-supervised model. These results highlight acousticscattering as a privacy-preserving, non-contact alternative to visualclassification, opening huge potential for applications in various industries.</description>
      <author>example@mail.com (Long-Vu Hoang, Tuan Nguyen, Tran Huy Dat)</author>
      <guid isPermaLink="false">2506.14148v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Toward a Graph Foundation Model: Pre-Training Transformers With Random Walks</title>
      <link>http://arxiv.org/abs/2506.14098v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种图基础模型，通过预训练和Transformer架构的适应性，实现了对多样化图数据集的处理，并探讨了如何编码不同大小和领域的图。&lt;h4&gt;背景&lt;/h4&gt;基于GPT等基础模型在自然语言处理中的成功，作者提出是否可以构建类似模型用于图处理。&lt;h4&gt;目的&lt;/h4&gt;构建一个能够处理和推理图结构数据的图基础模型。&lt;h4&gt;方法&lt;/h4&gt;通过将节点表示为多个随机游走，让Transformer从序列中提取节点表示，进而形成边和图表示。同时，开发了新的上下文预测损失函数，并对其在区分邻域和图的表达能力进行了理论分析。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法能够有效处理不同大小和领域的图，并通过理论分析证明了其表达能力的有效性。&lt;h4&gt;结论&lt;/h4&gt;该图基础模型在预训练和下游任务中展现出潜力，可作为处理图结构数据的坚实基础。&lt;h4&gt;翻译&lt;/h4&gt;A graph foundation model that is pre-trained with diverse graph datasets by adapting the Transformer backbone is proposed in this paper. The key challenge is how to encode graphs of varying sizes and from different domains. The authors propose representing a node as multiple random walks, so that the Transformer can extract node representations from sequences, which in turn form edge and graph representations. A novel context prediction loss function is developed for these random walks, and their expressive power in distinguishing neighborhoods and graphs is theoretically analyzed. The pre-training of the model and its adaptation to downstream tasks are demonstrated, showcasing its potential as a foundation for processing and reasoning with graph-structured data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A foundation model like GPT elicits many emergent abilities, owing to thepre-training with broad inclusion of data and the use of the powerfulTransformer architecture. While foundation models in natural languages areprevalent, can we build similar models for graphs? This paper describes anapproach toward a graph foundation model that is pre-trained with diverse graphdatasets by adapting the Transformer backbone. A central challenge toward thisend is how a sequence model encodes graphs of varying sizes and from differentdomains. We propose representing a node as multiple random walks, such that theTransformer can extract node representations from sequences, which in turn formedge and graph representations. We develop a novel context prediction loss forthese random walks and theoretically analyze their expressive power indistinguishing neighborhoods and graphs. We also demonstrate the pre-trainingof our model and its adaptation to downstream tasks, showcasing its potentialas a foundation for processing and reasoning with graph-structured data.</description>
      <author>example@mail.com (Ziyuan Tang, Jie Chen)</author>
      <guid isPermaLink="false">2506.14098v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Scale Finetuning for Encoder-based Time Series Foundation Models</title>
      <link>http://arxiv.org/abs/2506.14087v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了如何有效微调时间序列基础模型（TSFMs）以适应特定下游任务，提出了一种名为MSFT的多尺度微调框架，并展示了其在时间序列预测中的优越性。&lt;h4&gt;背景&lt;/h4&gt;时间序列基础模型（TSFMs）在时间序列预测中表现出色，但如何有效地在特定任务上微调这些模型仍是一个未被充分探索的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的微调框架，以充分利用TSFMs的多尺度预测能力，并避免过拟合和次优性能。&lt;h4&gt;方法&lt;/h4&gt;采用因果视角分析微调过程，强调显式建模多尺度的重要性，并提出了一种名为MSFT的多尺度微调框架。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，使用MSFT微调的TSFMs不仅优于传统的微调方法，还超越了最先进的深度学习方法。&lt;h4&gt;结论&lt;/h4&gt;MSFT框架能够有效地提高TSFMs在时间序列预测任务中的性能，为微调TSFMs提供了一种新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series foundation models (TSFMs) demonstrate impressive zero-shotperformance for time series forecasting. However, an important yetunderexplored challenge is how to effectively finetune TSFMs on specificdownstream tasks. While naive finetuning can yield performance gains, we arguethat it falls short of fully leveraging TSFMs' capabilities, often resulting inoverfitting and suboptimal performance. Given the diverse temporal patternsacross sampling scales and the inherent multi-scale forecasting capabilities ofTSFMs, we adopt a causal perspective to analyze finetuning process, throughwhich we highlight the critical importance of explicitly modeling multiplescales and reveal the shortcomings of naive approaches. Focusing on\textit{encoder-based} TSFMs, we propose \textbf{M}ulti\textbf{\textsc{s}}cale\textbf{\textsc{f}}ine\textbf{\textsc{t}}uning (\textbf{MSFT}), a simple yetgeneral framework that explicitly integrates multi-scale modeling into thefinetuning process. Experimental results on three different backbones (\moirai,\moment\ and \units) demonstrate that TSFMs finetuned with MSFT not onlyoutperform naive and typical parameter efficient finetuning methods but alsosurpass state-of-the-art deep learning methods.</description>
      <author>example@mail.com (Zhongzheng Qiao, Chenghao Liu, Yiming Zhang, Ming Jin, Quang Pham, Qingsong Wen, P. N. Suganthan, Xudong Jiang, Savitha Ramasamy)</author>
      <guid isPermaLink="false">2506.14087v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Few-Shot Learning for Industrial Time Series: A Comparative Analysis Using the Example of Screw-Fastening Process Monitoring</title>
      <link>http://arxiv.org/abs/2506.13909v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对工业时间序列数据中螺丝紧固过程监控的Few-shot learning (FSL)研究，通过一个包含16种单因素和多因素缺陷类型的2300样本多变量扭矩数据集，探讨了基于度量学习和基于梯度的FSL方法，并取得了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;Few-shot learning在视觉领域显示出潜力，但在工业时间序列数据中，尤其是标注新缺陷成本高昂的情况下，FSL的研究还相对较少。&lt;h4&gt;目的&lt;/h4&gt;研究FSL在螺丝紧固过程监控中的应用，并评估不同方法的性能。&lt;h4&gt;方法&lt;/h4&gt;使用一个包含16种缺陷类型的2300样本多变量扭矩数据集，引入了标签感知的周期采样器，并比较了基于度量学习的Prototypical Network和基于梯度的Model-Agnostic Meta-Learning (MAML)两种FSL范式，每种范式与三种不同的骨干网络（1D CNN、InceptionTime和Moment）结合。&lt;h4&gt;主要发现&lt;/h4&gt;在10-shot、3-way评估中，InceptionTime + Prototypical Network组合在多类和多标签模式下分别达到了0.944和0.935的加权F1分数，优于微调的Moment模型，同时参数和训练时间减少了两个数量级。在所有骨干网络中，度量学习方法均优于MAML，标签感知采样比传统的基于类的采样额外提高了1.7%的F1分数。&lt;h4&gt;结论&lt;/h4&gt;这些发现挑战了大型基础模型总是优于轻量级CNN架构的假设，当数据稀缺时，轻量级CNN架构结合简单的度量学习方法不仅收敛速度更快，而且泛化能力更强。为了促进可重复研究和加速FSL在高价值制造检验中的应用，作者发布了代码、数据拆分和预训练权重。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Few-shot learning (FSL)在视觉领域显示出潜力，但在工业时间序列数据中，尤其是标注新缺陷成本高昂的情况下，FSL的研究还相对较少。本文提出了一种针对工业时间序列数据中螺丝紧固过程监控的Few-shot learning (FSL)研究，通过一个包含16种单因素和多因素缺陷类型的2300样本多变量扭矩数据集，探讨了基于度量学习的Prototypical Network和基于梯度的Model-Agnostic Meta-Learning (MAML)两种FSL范式，每种范式与三种不同的骨干网络（1D CNN、InceptionTime和Moment）结合。在10-shot、3-way评估中，InceptionTime + Prototypical Network组合在多类和多标签模式下分别达到了0.944和0.935的加权F1分数，优于微调的Moment模型，同时参数和训练时间减少了两个数量级。在所有骨干网络中，度量学习方法均优于MAML，标签感知采样比传统的基于类的采样额外提高了1.7%的F1分数。这些发现挑战了大型基础模型总是优于轻量级CNN架构的假设，当数据稀缺时，轻量级CNN架构结合简单的度量学习方法不仅收敛速度更快，而且泛化能力更强。为了促进可重复研究和加速FSL在高价值制造检验中的应用，作者发布了代码、数据拆分和预训练权重。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot learning (FSL) has shown promise in vision but remains largelyunexplored for \emph{industrial} time-series data, where annotating every newdefect is prohibitively expensive. We present a systematic FSL study onscrew-fastening process monitoring, using a 2\,300-sample multivariate torquedataset that covers 16 uni- and multi-factorial defect types. Beyondbenchmarking, we introduce a \textbf{label-aware episodic sampler} thatcollapses multi-label sequences into multiple single-label tasks, keeping theoutput dimensionality fixed while preserving combinatorial label information.  Two FSL paradigms are investigated: the metric-based \emph{PrototypicalNetwork} and the gradient-based \emph{Model-Agnostic Meta-Learning} (MAML),each paired with three backbones: 1D CNN, InceptionTime and the 341 M-parametertransformer \emph{Moment}. On 10-shot, 3-way evaluation, the InceptionTime +Prototypical Network combination achieves a \textbf{0.944 weighted F1} in themulti-class regime and \textbf{0.935} in the multi-label regime, outperformingfinetuned Moment by up to 5.3\% while requiring two orders of magnitude fewerparameters and training time. Across all backbones, metric learningconsistently surpasses MAML, and our label-aware sampling yields an additional1.7\% F1 over traditional class-based sampling.  These findings challenge the assumption that large foundation models arealways superior: when data are scarce, lightweight CNN architectures augmentedwith simple metric learning not only converge faster but also generalizebetter. We release code, data splits and pre-trained weights to fosterreproducible research and to catalyze the adoption of FSL in high-valuemanufacturing inspection.</description>
      <author>example@mail.com (Xinyuan Tu, Haocheng Zhang, Tao Chengxu, Zuyi Chen)</author>
      <guid isPermaLink="false">2506.13909v1</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Delving into Instance-Dependent Label Noise in Graph Data: A Comprehensive Study and Benchmark</title>
      <link>http://arxiv.org/abs/2506.12468v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的基准测试BeGIN，用于评估图神经网络在处理带有实例依赖性噪声的数据时的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的图学习研究通常依赖于类别依赖性噪声，忽略了实例依赖性噪声的复杂性，并且无法捕捉真实的噪声模式。&lt;h4&gt;目的&lt;/h4&gt;BeGIN旨在提供一个具有各种噪声类型的真实图数据集，并全面评估不同GNN架构、噪声标签检测和噪声鲁棒学习策略。&lt;h4&gt;方法&lt;/h4&gt;BeGIN通过算法方法和基于LLM的模拟来模拟实例依赖性噪声，并引入了LLM-based simulations来模拟噪声。&lt;h4&gt;主要发现&lt;/h4&gt;实验揭示了实例依赖性噪声，特别是基于LLM的噪声的挑战，并强调了节点特定参数化对于增强GNN鲁棒性的重要性。&lt;h4&gt;结论&lt;/h4&gt;BeGIN为评估噪声处理策略的有效性、效率和关键性能因素提供了见解，并有望成为推进图标签噪声研究和促进鲁棒GNN训练方法发展的宝贵资源。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have achieved state-of-the-art performance in node classification tasks but struggle with label noise in real-world data. Existing studies on graph learning with label noise commonly rely on class-dependent label noise, overlooking the complexities of instance-dependent noise and falling short of capturing real-world corruption patterns. We introduce BeGIN (Benchmarking for Graphs with Instance-dependent Noise), a new benchmark that provides realistic graph datasets with various noise types and comprehensively evaluates noise-handling strategies across GNN architectures, noisy label detection, and noise-robust learning. To simulate instance-dependent corruptions, BeGIN introduces algorithmic methods and LLM-based simulations. Our experiments reveal the challenges of instance-dependent noise, particularly LLM-based corruption, and underscore the importance of node-specific parameterization to enhance GNN robustness. By comprehensively evaluating noise-handling strategies, BeGIN provides insights into their effectiveness, efficiency, and key performance factors. We expect that BeGIN will serve as a valuable resource for advancing research on label noise in graphs and fostering the development of robust GNN training methods. The code is available at https://github.com/kimsu55/BeGIN.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3711896.3737376&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have achieved state-of-the-art performance innode classification tasks but struggle with label noise in real-world data.Existing studies on graph learning with label noise commonly rely onclass-dependent label noise, overlooking the complexities of instance-dependentnoise and falling short of capturing real-world corruption patterns. Weintroduce BeGIN (Benchmarking for Graphs with Instance-dependent Noise), a newbenchmark that provides realistic graph datasets with various noise types andcomprehensively evaluates noise-handling strategies across GNN architectures,noisy label detection, and noise-robust learning. To simulateinstance-dependent corruptions, BeGIN introduces algorithmic methods andLLM-based simulations. Our experiments reveal the challenges ofinstance-dependent noise, particularly LLM-based corruption, and underscore theimportance of node-specific parameterization to enhance GNN robustness. Bycomprehensively evaluating noise-handling strategies, BeGIN provides insightsinto their effectiveness, efficiency, and key performance factors. We expectthat BeGIN will serve as a valuable resource for advancing research on labelnoise in graphs and fostering the development of robust GNN training methods.The code is available at https://github.com/kimsu55/BeGIN.</description>
      <author>example@mail.com (Suyeon Kim, SeongKu Kang, Dongwoo Kim, Jungseul Ok, Hwanjo Yu)</author>
      <guid isPermaLink="false">2506.12468v2</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Model Context Protocol (MCP) at First Glance: Studying the Security and Maintainability of MCP Servers</title>
      <link>http://arxiv.org/abs/2506.13538v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了Foundation Models（FMs）在金融和软件工程等领域的应用，以及Model Context Protocol（MCP）在标准化工具生态系统中的作用，并通过对MCP服务器的大规模实证研究，分析了其健康、安全和可维护性。&lt;h4&gt;背景&lt;/h4&gt;尽管FMs如GPT-4在多个领域得到广泛应用，但依赖文本界面限制了这些模型与现实世界的互动。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，研究旨在评估MCP服务器的健康、安全和可维护性。&lt;h4&gt;方法&lt;/h4&gt;通过使用最先进的健康指标和混合分析流程，结合通用静态分析工具和MCP特定扫描器，对1,899个开源MCP服务器进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;MCP服务器表现出强大的健康指标，但发现了八个不同的漏洞，其中只有三个与传统软件漏洞重叠。7.2%的服务器含有通用漏洞，5.5%表现出MCP特定的工具中毒。在可维护性方面，66%的服务器存在代码异味，14.4%含有十个与传统开源软件项目重叠的bug模式。&lt;h4&gt;结论&lt;/h4&gt;研究强调了需要针对MCP特定的漏洞检测技术，同时重申了传统分析和重构实践的价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although Foundation Models (FMs), such as GPT-4, are increasingly used indomains like finance and software engineering, reliance on textual interfaceslimits these models' real-world interaction. To address this, FM providersintroduced tool calling-triggering a proliferation of frameworks with distincttool interfaces. In late 2024, Anthropic introduced the Model Context Protocol(MCP) to standardize this tool ecosystem, which has become the de factostandard with over eight million weekly SDK downloads. Despite its adoption,MCP's AI-driven, non-deterministic control flow introduces new risks tosustainability, security, and maintainability, warranting closer examination.  Towards this end, we present the first large-scale empirical study of MCPservers. Using state-of-the-art health metrics and a hybrid analysis pipeline,combining a general-purpose static analysis tool with an MCP-specific scanner,we evaluate 1,899 open-source MCP servers to assess their health, security, andmaintainability. Despite MCP servers demonstrating strong health metrics, weidentify eight distinct vulnerabilities -- only three overlapping withtraditional software vulnerabilities. Additionally, 7.2% of servers containgeneral vulnerabilities and 5.5% exhibit MCP-specific tool poisoning. Regardingmaintainability, while 66% exhibit code smells, 14.4\% contain ten bug patternsoverlapping with traditional open-source software projects. These findingshighlight the need for MCP-specific vulnerability detection techniques whilereaffirming the value of traditional analysis and refactoring practices.</description>
      <author>example@mail.com (Mohammed Mehedi Hasan, Hao Li, Emad Fallahzadeh, Bram Adams, Ahmed E. Hassan)</author>
      <guid isPermaLink="false">2506.13538v2</guid>
      <pubDate>Wed, 18 Jun 2025 14:21:36 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Self-Supervised Learning As Neural Manifold Packing</title>
      <link>http://arxiv.org/abs/2506.13717v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CLAMP的对比自监督学习框架，用于视觉任务中的表征学习，该框架将表征学习转化为流形打包问题。&lt;h4&gt;背景&lt;/h4&gt;基于点对比较的对比自监督学习在视觉任务中得到了广泛研究。大脑视觉皮层的神经元对不同刺激类别的响应组织成称为神经流形的几何结构。&lt;h4&gt;目的&lt;/h4&gt;通过有效地分离这些流形，以解决打包问题，实现刺激的准确分类。&lt;h4&gt;方法&lt;/h4&gt;CLAMP引入了一种受短程排斥粒子系统（如简单液体和堵塞打包中的系统）的势能启发的损失函数。每个类别由包含单个图像多个增强视图的子流形组成。子流形的尺寸和位置通过跟随打包损失的梯度进行动态优化。&lt;h4&gt;主要发现&lt;/h4&gt;CLAMP在标准线性评估协议下，即冻结主干网络并仅训练线性分类器的情况下，实现了与最先进的自监督模型相竞争的性能。分析显示，对应不同类别的神经流形在学习的表征空间中自然出现并被有效分离。&lt;h4&gt;结论&lt;/h4&gt;CLAMP能够将物理学、神经科学和机器学习的见解联系起来，具有潜在的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive self-supervised learning based on point-wise comparisons has beenwidely studied for vision tasks. In the visual cortex of the brain, neuronalresponses to distinct stimulus classes are organized into geometric structuresknown as neural manifolds. Accurate classification of stimuli can be achievedby effectively separating these manifolds, akin to solving a packing problem.We introduce Contrastive Learning As Manifold Packing (CLAMP), aself-supervised framework that recasts representation learning as a manifoldpacking problem. CLAMP introduces a loss function inspired by the potentialenergy of short-range repulsive particle systems, such as those encountered inthe physics of simple liquids and jammed packings. In this framework, eachclass consists of sub-manifolds embedding multiple augmented views of a singleimage. The sizes and positions of the sub-manifolds are dynamically optimizedby following the gradient of a packing loss. This approach yields interpretabledynamics in the embedding space that parallel jamming physics, and introducesgeometrically meaningful hyperparameters within the loss function. Under thestandard linear evaluation protocol, which freezes the backbone and trains onlya linear classifier, CLAMP achieves competitive performance withstate-of-the-art self-supervised models. Furthermore, our analysis reveals thatneural manifolds corresponding to different categories emerge naturally and areeffectively separated in the learned representation space, highlighting thepotential of CLAMP to bridge insights from physics, neural science, and machinelearning.</description>
      <author>example@mail.com (Guanming Zhang, David J. Heeger, Stefano Martiniani)</author>
      <guid isPermaLink="false">2506.13717v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
  <item>
      <title>SpaceTrack-TimeSeries: Time Series Dataset towards Satellite Orbit Analysis</title>
      <link>http://arxiv.org/abs/2506.13034v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在航天技术快速发展和低地球轨道卫星星座大规模部署的背景下，天文学观测和深空探索面临的挑战。通过收集和整理星链卫星的机动行为数据集，为空间物体行为的多维建模和碰撞风险评估提供支持。&lt;h4&gt;背景&lt;/h4&gt;航天技术的快速发展导致低地球轨道卫星星座的部署规模增大，这对天文学观测和深空探索提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;解决在天体物体机动行为预测和碰撞风险评估研究中缺乏公开可访问的、真实世界数据集的问题。&lt;h4&gt;方法&lt;/h4&gt;收集并整理了星链卫星的机动行为数据集，集成了两行元素（TLE）目录数据与相应的高精度星历数据。&lt;h4&gt;主要发现&lt;/h4&gt;数据集有助于更真实和多维地模拟空间物体行为，为实际部署机动检测方法和评估拥挤轨道环境中的碰撞风险提供有价值的见解。&lt;h4&gt;结论&lt;/h4&gt;通过提供星链卫星的机动行为数据集，本文为空间物体行为的多维建模和碰撞风险评估提供了支持，有助于解决当前研究中数据不足的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid advancement of aerospace technology and the large-scaledeployment of low Earth orbit (LEO) satellite constellations, the challengesfacing astronomical observations and deep space exploration have becomeincreasingly pronounced. As a result, the demand for high-precision orbitaldata on space objects-along with comprehensive analyses of satellitepositioning, constellation configurations, and deep space satellitedynamics-has grown more urgent. However, there remains a notable lack ofpublicly accessible, real-world datasets to support research in areas such asspace object maneuver behavior prediction and collision risk assessment. Thisstudy seeks to address this gap by collecting and curating a representativedataset of maneuvering behavior from Starlink satellites. The datasetintegrates Two-Line Element (TLE) catalog data with correspondinghigh-precision ephemeris data, thereby enabling a more realistic andmultidimensional modeling of space object behavior. It provides valuableinsights into practical deployment of maneuver detection methods and theevaluation of collision risks in increasingly congested orbital environments.</description>
      <author>example@mail.com (Zhixin Guo, Qi Shi, Xiaofan Xu, Sixiang Shan, Limin Qin, Linqiang Ge, Rui Zhang, Ya Dai, Hua Zhu, Guowei Jiang)</author>
      <guid isPermaLink="false">2506.13034v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Touch begins where vision ends: Generalizable policies for contact-rich manipulation</title>
      <link>http://arxiv.org/abs/2506.13762v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ViTaL策略学习框架，该框架通过将精细操作任务分解为两个阶段来解决：一是抓取阶段，使用视觉语言模型进行场景推理定位目标物体；二是局部交互阶段，使用ViTaL策略进行接触丰富的操作。该方法基于场景上下文变化但底层交互一致的观察，通过在规范环境中一次训练局部策略，实现通过定位然后执行策略的泛化。ViTaL在未见过的新环境中实现了约90%的成功率，对干扰因素有鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;数据驱动方法在精确操作方面存在困难；模仿学习需要大量难以获取的演示，而强化学习产生的策略脆弱且泛化性差。&lt;h4&gt;目的&lt;/h4&gt;提出ViTaL策略学习框架，解决精细操作任务。&lt;h4&gt;方法&lt;/h4&gt;将操作任务分解为抓取阶段和局部交互阶段，抓取阶段使用视觉语言模型进行场景推理，局部交互阶段使用ViTaL策略进行接触丰富的操作。&lt;h4&gt;主要发现&lt;/h4&gt;ViTaL在接触丰富的任务中实现了约90%的成功率，对干扰因素有鲁棒性；ViTaL的有效性源于三个关键洞察：1）分割基础模型通过行为克隆训练鲁棒视觉编码器；2）这些编码器提高了使用残差强化学习学习到的策略的泛化性；3）触觉传感显著提升了接触丰富任务中的性能。&lt;h4&gt;结论&lt;/h4&gt;ViTaL框架能够有效地解决精细操作任务，具有鲁棒性和泛化性，并且可以与高级视觉语言模型很好地集成。&lt;h4&gt;翻译&lt;/h4&gt;We introduce VisuoTactile Local (ViTaL) policy learning, a framework that solves fine-grained manipulation tasks by decomposing them into two phases: a reaching phase, where a vision-language model (VLM) enables scene-level reasoning to localize the object of interest, and a local interaction phase, where a reusable, scene-agnostic ViTaL policy performs contact-rich manipulation using egocentric vision and tactile sensing. This approach is motivated by the observation that while scene context varies, the low-level interaction remains consistent across task instances. By training local policies once in a canonical setting, they can generalize via a localize-then-execute strategy. ViTaL achieves around 90% success on contact-rich tasks in unseen environments and is robust to distractions. ViTaL's effectiveness stems from three key insights: (1) foundation models for segmentation enable training robust visual encoders via behavior cloning; (2) these encoders improve the generalizability of policies learned using residual RL; and (3) tactile sensing significantly boosts performance in contact-rich tasks. Ablation studies validate each of these insights, and we demonstrate that ViTaL integrates well with high-level VLMs, enabling robust, reusable low-level skills. Results and videos are available at https://vitalprecise.github.io.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data-driven approaches struggle with precise manipulation; imitation learningrequires many hard-to-obtain demonstrations, while reinforcement learningyields brittle, non-generalizable policies. We introduce VisuoTactile Local(ViTaL) policy learning, a framework that solves fine-grained manipulationtasks by decomposing them into two phases: a reaching phase, where avision-language model (VLM) enables scene-level reasoning to localize theobject of interest, and a local interaction phase, where a reusable,scene-agnostic ViTaL policy performs contact-rich manipulation using egocentricvision and tactile sensing. This approach is motivated by the observation thatwhile scene context varies, the low-level interaction remains consistent acrosstask instances. By training local policies once in a canonical setting, theycan generalize via a localize-then-execute strategy. ViTaL achieves around 90%success on contact-rich tasks in unseen environments and is robust todistractors. ViTaL's effectiveness stems from three key insights: (1)foundation models for segmentation enable training robust visual encoders viabehavior cloning; (2) these encoders improve the generalizability of policieslearned using residual RL; and (3) tactile sensing significantly boostsperformance in contact-rich tasks. Ablation studies validate each of theseinsights, and we demonstrate that ViTaL integrates well with high-level VLMs,enabling robust, reusable low-level skills. Results and videos are available athttps://vitalprecise.github.io.</description>
      <author>example@mail.com (Zifan Zhao, Siddhant Haldar, Jinda Cui, Lerrel Pinto, Raunaq Bhirangi)</author>
      <guid isPermaLink="false">2506.13762v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Active Multimodal Distillation for Few-shot Action Recognition</title>
      <link>http://arxiv.org/abs/2506.13322v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IJCAI 2025, the 34th International Joint Conference on Artificial  Intelligence&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的少样本动作识别框架，通过利用任务特定的上下文线索来主动识别可靠的模态，从而显著提高了识别性能。&lt;h4&gt;背景&lt;/h4&gt;少样本动作识别因其快速发展和广泛的应用前景而受到广泛关注，但现有方法主要基于有限的单一模态数据，未能充分利用多模态信息的潜力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新框架，通过主动识别可靠的模态来提高动作识别的性能。&lt;h4&gt;方法&lt;/h4&gt;该框架集成了一个主动样本推理（ASI）模块，它利用基于后验分布的主动推理来预测可靠的模态，并相应地组织它们。此外，引入了一个主动互蒸馏模块，通过从更可靠的模态转移知识来增强不那么可靠的模态的学习表示。在元测试期间，采用自适应多模态推理为可靠的模态分配更高的权重。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，该方法在多个基准上显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;该框架能够有效地提高少样本动作识别的性能，为该领域的研究提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Owing to its rapid progress and broad application prospects, few-shot actionrecognition has attracted considerable interest. However, current methods arepredominantly based on limited single-modal data, which does not fully exploitthe potential of multimodal information. This paper presents a novel frameworkthat actively identifies reliable modalities for each sample usingtask-specific contextual cues, thus significantly improving recognitionperformance. Our framework integrates an Active Sample Inference (ASI) module,which utilizes active inference to predict reliable modalities based onposterior distributions and subsequently organizes them accordingly. Unlikereinforcement learning, active inference replaces rewards with evidence-basedpreferences, making more stable predictions. Additionally, we introduce anactive mutual distillation module that enhances the representation learning ofless reliable modalities by transferring knowledge from more reliable ones.Adaptive multimodal inference is employed during the meta-test to assign higherweights to reliable modalities. Extensive experiments across multiplebenchmarks demonstrate that our method significantly outperforms existingapproaches.</description>
      <author>example@mail.com (Weijia Feng, Yichen Zhu, Ruojia Zhang, Chenyang Wang, Fei Ma, Xiaobao Wang, Xiaobai Li)</author>
      <guid isPermaLink="false">2506.13322v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Large Language Models for Phishing Detection, Self-Consistency, Faithfulness, and Explainability</title>
      <link>http://arxiv.org/abs/2506.13746v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了利用大型语言模型（LLMs）进行钓鱼邮件分类和可解释性的问题，通过对比学习、直接偏好优化等方法提高了模型的分类和解释能力。&lt;h4&gt;背景&lt;/h4&gt;钓鱼攻击是网络安全的主要威胁之一，尽管人工智能和机器学习取得了显著进展，但准确复制钓鱼判断背后的可解释推理仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;研究LLMs是否能够不仅准确分类钓鱼邮件，还能生成与其预测可靠对齐且内部自洽的解释。&lt;h4&gt;方法&lt;/h4&gt;通过微调BERT、Llama模型和Wizard等基于Transformer的模型，使用二进制序列分类、对比学习（CL）和直接偏好优化（DPO）来提高模型在钓鱼邮件分类和解释性方面的性能。使用基于SHAPley值的ConsistentCy（CC SHAP）度量来评估模型的内部一致性和预测解释的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;Llama模型在预测解释标记对齐方面表现出更强的能力，尽管决策准确性不可靠；而Wizard在预测准确性方面表现更好，但CC SHAP分数较低。&lt;h4&gt;结论&lt;/h4&gt;LLMs在钓鱼邮件分类和解释性方面具有潜力，但需要进一步研究以提高其决策准确性和解释的一致性。&lt;h4&gt;翻译&lt;/h4&gt;Phishing attacks remain one of the most prevalent and persistent cybersecurity threats with attackers continuously evolving and intensifying tactics to evade the general detection system. Despite significant advances in artificial intelligence and machine learning, faithfully reproducing the interpretable reasoning with classification and explainability that underpin phishing judgments remains challenging. Due to recent advancements in Natural Language Processing, Large Language Models (LLMs) show a promising direction and potential for improving domain specific phishing classification tasks. However, enhancing the reliability and robustness of classification models requires not only accurate predictions from LLMs but also consistent and trustworthy explanations aligning with those predictions. Therefore, a key question remains: can LLMs not only classify phishing emails accurately but also generate explanations that are reliably aligned with their predictions and internally self-consistent? To answer these questions, we have fine-tuned transformer based models, including BERT, Llama models, and Wizard, to improve domain relevance and make them more tailored to phishing specific distinctions, using Binary Sequence Classification, Contrastive Learning (CL) and Direct Preference Optimization (DPO). To that end, we examined their performance in phishing classification and explainability by applying the ConsistentCy measure based on SHAPley values (CC SHAP), which measures prediction explanation token alignment to test the model's internal faithfulness and consistency and uncover the rationale behind its predictions and reasoning. Overall, our findings show that Llama models exhibit stronger prediction explanation token alignment with higher CC SHAP scores despite lacking reliable decision-making accuracy, whereas Wizard achieves better prediction accuracy but lower CC SHAP scores.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Phishing attacks remain one of the most prevalent and persistentcybersecurity threat with attackers continuously evolving and intensifyingtactics to evade the general detection system. Despite significant advances inartificial intelligence and machine learning, faithfully reproducing theinterpretable reasoning with classification and explainability that underpinphishing judgments remains challenging. Due to recent advancement in NaturalLanguage Processing, Large Language Models (LLMs) show a promising directionand potential for improving domain specific phishing classification tasks.However, enhancing the reliability and robustness of classification modelsrequires not only accurate predictions from LLMs but also consistent andtrustworthy explanations aligning with those predictions. Therefore, a keyquestion remains: can LLMs not only classify phishing emails accurately butalso generate explanations that are reliably aligned with their predictions andinternally self-consistent? To answer these questions, we have fine-tunedtransformer based models, including BERT, Llama models, and Wizard, to improvedomain relevance and make them more tailored to phishing specific distinctions,using Binary Sequence Classification, Contrastive Learning (CL) and DirectPreference Optimization (DPO). To that end, we examined their performance inphishing classification and explainability by applying the ConsistenCy measurebased on SHAPley values (CC SHAP), which measures prediction explanation tokenalignment to test the model's internal faithfulness and consistency and uncoverthe rationale behind its predictions and reasoning. Overall, our findings showthat Llama models exhibit stronger prediction explanation token alignment withhigher CC SHAP scores despite lacking reliable decision making accuracy,whereas Wizard achieves better prediction accuracy but lower CC SHAP scores.</description>
      <author>example@mail.com (Shova Kuikel, Aritran Piplai, Palvi Aggarwal)</author>
      <guid isPermaLink="false">2506.13746v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Understand the Implication: Learning to Think for Pragmatic Understanding</title>
      <link>http://arxiv.org/abs/2506.13559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SS and KM contributed equally to this work&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的基于思考的学习方法，用于提高大型语言模型（LLMs）在语用理解方面的性能。&lt;h4&gt;背景&lt;/h4&gt;语用能力对于社会认知和沟通至关重要，而LLMs在语用理解方面虽有基准测试，但其性能提升仍需探索。现有方法依赖标注标签，但忽略了人类在解释隐含意义时自然使用的推理过程。&lt;h4&gt;目的&lt;/h4&gt;引入一个名为ImpliedMeaningPreference的新语用数据集，包含正确和错误解释的明确推理（思考），通过偏好调整和监督微调来提高LLMs的语用理解能力。&lt;h4&gt;方法&lt;/h4&gt;使用偏好调整和监督微调技术，结合ImpliedMeaningPreference数据集，对LLMs进行训练，并评估其性能。&lt;h4&gt;主要发现&lt;/h4&gt;基于思考的学习显著提高了LLMs的语用理解能力，模型家族的准确率提高了11.12%。此外，转移学习研究表明，与标签训练模型相比，基于思考的训练在语用任务（如预设、指示）上的表现提高了16.10%。&lt;h4&gt;结论&lt;/h4&gt;基于思考的学习是一种有效的方法，可以显著提高LLMs的语用理解能力，并有望应用于其他未在训练时间看到的语用任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pragmatics, the ability to infer meaning beyond literal interpretation, iscrucial for social cognition and communication. While LLMs have beenbenchmarked for their pragmatic understanding, improving their performanceremains underexplored. Existing methods rely on annotated labels but overlookthe reasoning process humans naturally use to interpret implicit meaning. Tobridge this gap, we introduce a novel pragmatic dataset,ImpliedMeaningPreference, that includes explicit reasoning (thoughts) for bothcorrect and incorrect interpretations. Through preference-tuning and supervisedfine-tuning, we demonstrate that thought-based learning significantly enhancesLLMs' pragmatic understanding, improving accuracy by 11.12% across modelfamilies. We further discuss a transfer-learning study where we evaluate theperformance of thought-based training for the other tasks of pragmatics(presupposition, deixis) that are not seen during the training time and observean improvement of 16.10% compared to label-trained models.</description>
      <author>example@mail.com (Settaluri Lakshmi Sravanthi, Kishan Maharaj, Sravani Gunnu, Abhijit Mishra, Pushpak Bhattacharyya)</author>
      <guid isPermaLink="false">2506.13559v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Persistent Homology of Music Network with Three Different Distances</title>
      <link>http://arxiv.org/abs/2506.13595v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在音乐数据中应用持久同调，以发现隐藏的拓扑结构，并研究了不同距离定义对持久同调的影响。&lt;h4&gt;背景&lt;/h4&gt;持久同调已被广泛应用于发现数据中的隐藏拓扑结构，包括音乐数据。在应用持久同调时，需要在点云中的点或图网络中的节点之间定义距离或度量。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过在音乐图上应用持久同调，研究不同距离定义对持久同调的影响，并分析这些影响。&lt;h4&gt;方法&lt;/h4&gt;本文使用预定义权重的音乐图，检验了三种基于边路径的不同的距离定义，并分析了这些定义对持久条码、持久度量和出生/死亡边的影响。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，在这三种距离定义中存在一维持久同调中的包含关系，这一关系在持久条码和度量的比较中得以体现。&lt;h4&gt;结论&lt;/h4&gt;使用真实音乐数据验证了上述发现，表明不同的距离定义对持久同调有显著影响。&lt;h4&gt;翻译&lt;/h4&gt;摘要：持久同调已被广泛用于在音乐数据等各个应用中揭示数据中的隐藏拓扑结构。为了应用持久同调，需要在点云中的点或在图网络中的节点之间定义距离或度量。这些定义不是唯一的，并且依赖于特定问题的具体目标。换句话说，选择不同的度量定义允许进行多种拓扑推断。在这项工作中，我们专注于在预定义权重的音乐图上应用持久同调。我们检验了三种基于边路径的不同的距离定义，并展示了这些定义如何影响持久条码、持久度量和出生/死亡边。我们发现，在这三个距离定义中存在一维持久同调中的包含关系，这一关系在一维持久同调的持久条码和度量的比较中得以体现。我们使用真实音乐数据验证了这些发现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Persistent homology has been widely used to discover hidden topologicalstructures in data across various applications, including music data. To applypersistent homology, a distance or metric must be defined between points in apoint cloud or between nodes in a graph network. These definitions are notunique and depend on the specific objectives of a given problem. In otherwords, selecting different metric definitions allows for multiple topologicalinferences. In this work, we focus on applying persistent homology to musicgraph with predefined weights. We examine three distinct distance definitionsbased on edge-wise pathways and demonstrate how these definitions affectpersistent barcodes, persistence diagrams, and birth/death edges. We found thatthere exist inclusion relations in one-dimensional persistent homologyreflected on persistence barcode and diagram among these three distancedefinitions. We verified these findings using real music data.</description>
      <author>example@mail.com (Eunwoo Heo, Byeongchan Choi, Myung ock Kim, Mai Lan Tran, Jae-Hun Jung)</author>
      <guid isPermaLink="false">2506.13595v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>MT-PCR: A Hybrid Mamba-Transformer with Spatial Serialization for Hierarchical Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2506.13183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 Pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MT-PCR的点云配准框架，该框架结合了Mamba和Transformer模块，旨在提高点云配准的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;点云配准是3D计算机视觉和机器人领域的基本任务，现有基于Transformer的方法存在计算复杂度高的问题，限制了点云的处理分辨率和信息保留。&lt;h4&gt;目的&lt;/h4&gt;提出MT-PCR框架，以解决直接应用Mamba到点云配准任务中的性能问题。&lt;h4&gt;方法&lt;/h4&gt;MT-PCR通过使用Z-order空间填充曲线序列化点云特征，增强空间局部性，并优化Mamba编码器，最后通过Transformer进行细化处理。&lt;h4&gt;主要发现&lt;/h4&gt;MT-PCR在多个基准测试中表现出优于基于Transformer和现有最先进方法的性能，显著降低了GPU内存使用和浮点运算次数。&lt;h4&gt;结论&lt;/h4&gt;MT-PCR框架有效地结合了Mamba和Transformer的优势，提高了点云配准的准确性和效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：点云配准（PCR）是3D计算机视觉和机器人领域的一项基本任务。大多数现有的基于学习的PCR方法依赖于Transformer，但它们存在二次计算复杂性的问题。这种限制限制了可以处理的点云分辨率，不可避免地导致信息损失。相比之下，基于状态空间模型（SSM）的Mamba模型在保持强大的长距离上下文建模能力的同时，实现了线性计算复杂度。然而，由于点云数据的无序和不规则性质，直接将Mamba应用于PCR任务会导致次优性能。为了解决这一挑战，我们提出了MT-PCR，这是第一个结合Mamba和Transformer模块的点云配准框架。具体来说，我们使用Z-order空间填充曲线序列化点云特征，以强制执行空间局部性，使Mamba能够更好地建模输入的几何结构。此外，我们移除了Mamba中常用的顺序指示器模块，在我们的设置中提高了性能。序列化特征随后由优化的Mamba编码器处理，然后是Transformer细化阶段。在多个基准测试上的大量实验表明，MT-PCR在准确性和效率方面都优于基于Transformer的以及同时期的最先进方法，显著降低了GPU内存使用和FLOPs。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud registration (PCR) is a fundamental task in 3D computer visionand robotics. Most existing learning-based PCR methods rely on Transformers,which suffer from quadratic computational complexity. This limitation restrictsthe resolution of point clouds that can be processed, inevitably leading toinformation loss. In contrast, Mamba-a recently proposed model based on statespace models (SSMs)-achieves linear computational complexity while maintainingstrong long-range contextual modeling capabilities. However, directly applyingMamba to PCR tasks yields suboptimal performance due to the unordered andirregular nature of point cloud data. To address this challenge, we proposeMT-PCR, the first point cloud registration framework that integrates both Mambaand Transformer modules. Specifically, we serialize point cloud features usingZ-order space-filling curves to enforce spatial locality, enabling Mamba tobetter model the geometric structure of the input. Additionally, we remove theorder indicator module commonly used in Mamba-based sequence modeling, leads toimproved performance in our setting. The serialized features are then processedby an optimized Mamba encoder, followed by a Transformer refinement stage.Extensive experiments on multiple benchmarks demonstrate that MT-PCRoutperforms Transformer-based and concurrent state-of-the-art methods in bothaccuracy and efficiency, significantly reducing while GPU memory usage andFLOPs.</description>
      <author>example@mail.com (Bingxi Liu, An Liu, Hao Chen, Jinqiang Cui, Yiqun Wang, Hong Zhang)</author>
      <guid isPermaLink="false">2506.13183v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>OTFusion: Bridging Vision-only and Vision-Language Models via Optimal Transport for Transductive Zero-Shot Learning</title>
      <link>http://arxiv.org/abs/2506.13723v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为OTFusion的零样本学习框架，用于通过结合视觉语言模型和视觉基础模型的优势来分类未见过的类别。&lt;h4&gt;背景&lt;/h4&gt;传统的零样本学习模型在视觉语言模型的语义对齐和视觉基础模型的感知特征提取方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;旨在通过融合视觉语言模型（如CLIP）和视觉基础模型（如DINOv2）的互补优势，提高未见类别分类的准确性。&lt;h4&gt;方法&lt;/h4&gt;OTFusion通过最优传输方法，学习一个共享的概率表示，该表示通过最小化视觉和语义信息分布之间的传输成本来实现对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在11个基准数据集上的实验表明，OTFusion在无需微调或额外标注的情况下，平均准确率提高了近10%，并且优于原始的CLIP模型。&lt;h4&gt;结论&lt;/h4&gt;OTFusion是一个简单而有效的训练免费框架，能够显著提高零样本学习模型的性能，并在论文接受后公开代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transductive zero-shot learning (ZSL) aims to classify unseen categories byleveraging both semantic class descriptions and the distribution of unlabeledtest data. While Vision-Language Models (VLMs) such as CLIP excel at aligningvisual inputs with textual semantics, they often rely too heavily onclass-level priors and fail to capture fine-grained visual cues. In contrast,Vision-only Foundation Models (VFMs) like DINOv2 provide rich perceptualfeatures but lack semantic alignment. To exploit the complementary strengths ofthese models, we propose OTFusion, a simple yet effective training-freeframework that bridges VLMs and VFMs via Optimal Transport. Specifically,OTFusion aims to learn a shared probabilistic representation that aligns visualand semantic information by minimizing the transport cost between theirrespective distributions. This unified distribution enables coherent classpredictions that are both semantically meaningful and visually grounded.Extensive experiments on 11 benchmark datasets demonstrate that OTFusionconsistently outperforms the original CLIP model, achieving an average accuracyimprovement of nearly $10\%$, all without any fine-tuning or additionalannotations. The code will be publicly released after the paper is accepted.</description>
      <author>example@mail.com (Qiyu Xu, Wenyang Chen, Zhanxuan Hu, Huafeng Li, Yonghang Tai)</author>
      <guid isPermaLink="false">2506.13723v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>ROSA: Harnessing Robot States for Vision-Language and Action Alignment</title>
      <link>http://arxiv.org/abs/2506.13679v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Vision-Language-Action (VLA) 模型在多任务、端到端机器人控制方面取得了显著进展，得益于视觉-语言模型 (VLMs) 的强大泛化能力。&lt;h4&gt;背景&lt;/h4&gt;开发此类模型的一个基本挑战是有效地对齐视觉-语言空间与机器人动作空间。现有方法通常依赖于使用专家演示直接微调 VLMs。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的训练范式 ROSA，利用机器人状态估计来提高视觉-语言与动作空间之间的对齐。&lt;h4&gt;方法&lt;/h4&gt;通过集成通过自动化过程获得的机器人状态估计数据，ROSA 使 VLA 模型能够获得增强的空间理解和自我意识，从而提高性能和泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟和真实世界环境中进行的广泛实验证明了 ROSA 的有效性，尤其是在低数据情况下。&lt;h4&gt;结论&lt;/h4&gt;ROSA 在解决视觉-语言与动作空间对齐问题上表现出色，能够提高 VLA 模型的性能和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language-Action (VLA) models have recently made significant advance inmulti-task, end-to-end robotic control, due to the strong generalizationcapabilities of Vision-Language Models (VLMs). A fundamental challenge indeveloping such models is effectively aligning the vision-language space withthe robotic action space. Existing approaches typically rely on directlyfine-tuning VLMs using expert demonstrations. However, this strategy suffersfrom a spatio-temporal gap, resulting in considerable data inefficiency andheavy reliance on human labor. Spatially, VLMs operate within a high-levelsemantic space, whereas robotic actions are grounded in low-level 3D physicalspace; temporally, VLMs primarily interpret the present, while VLA modelsanticipate future actions. To overcome these challenges, we propose a noveltraining paradigm, ROSA, which leverages robot state estimation to improvealignment between vision-language and action spaces. By integrating robot stateestimation data obtained via an automated process, ROSA enables the VLA modelto gain enhanced spatial understanding and self-awareness, thereby boostingperformance and generalization. Extensive experiments in both simulated andreal-world environments demonstrate the effectiveness of ROSA, particularly inlow-data regimes.</description>
      <author>example@mail.com (Yuqing Wen, Kefan Gu, Haoxuan Liu, Yucheng Zhao, Tiancai Wang, Haoqiang Fan, Xiaoyan Sun)</author>
      <guid isPermaLink="false">2506.13679v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>COME: Adding Scene-Centric Forecasting Control to Occupancy World Model</title>
      <link>http://arxiv.org/abs/2506.13260v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为COME的框架，用于改进自主驾驶中的环境动态模拟和合成数据生成，通过分离环境变化和自我运动来提高预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的世界模型方法难以区分车辆运动和场景演变，导致预测效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过利用场景中心坐标系来分离环境变化和自我运动，以实现更准确的未来占用预测。&lt;h4&gt;方法&lt;/h4&gt;COME框架首先通过场景中心预测分支生成与自我无关的空间一致的未来特征，然后使用定制的控制网络将这些特征转换为场景条件。这些条件特征随后被注入到占用世界模型中，以实现更准确和可控的未来占用预测。&lt;h4&gt;主要发现&lt;/h4&gt;在nuScenes-Occ3D数据集上的实验结果表明，COME在多种配置下（包括不同的输入源和预测范围）都比最先进的方法有显著的改进。例如，在相同设置下，COME的mIoU指标比DOME和UniScene分别提高了26.3%和23.7%。&lt;h4&gt;结论&lt;/h4&gt;这些结果强调了解耦表示学习在提高世界模型时空预测精度方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译为英文，可在指定的GitHub链接找到：'In this paper, we introduce COME: a framework that integrates scene-centric forecasting Control into the Occupancy world ModEl. Specifically, COME first generates ego-irrelevant, spatially consistent future features through a scene-centric prediction branch, which are then converted into scene condition using a tailored ControlNet. These condition features are subsequently injected into the occupancy world model, enabling more accurate and controllable future occupancy predictions. Experimental results on the nuScenes-Occ3D dataset show that COME achieves consistent and significant improvements over state-of-the-art (SOTA) methods across diverse configurations, including different input sources (ground-truth, camera-based, fusion-based occupancy) and prediction horizons (3s and 8s). For example, under the same settings, COME achieves 26.3% better mIoU metric than DOME and 23.7% better mIoU metric than UniScene. These results highlight the efficacy of disentangled representation learning in enhancing spatio-temporal prediction fidelity for world models. Code and videos will be available at https://github.com/synsin0/COME.'&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; World models are critical for autonomous driving to simulate environmentaldynamics and generate synthetic data. Existing methods struggle to disentangleego-vehicle motion (perspective shifts) from scene evolvement (agentinteractions), leading to suboptimal predictions. Instead, we propose toseparate environmental changes from ego-motion by leveraging the scene-centriccoordinate systems. In this paper, we introduce COME: a framework thatintegrates scene-centric forecasting Control into the Occupancy world ModEl.Specifically, COME first generates ego-irrelevant, spatially consistent futurefeatures through a scene-centric prediction branch, which are then convertedinto scene condition using a tailored ControlNet. These condition features aresubsequently injected into the occupancy world model, enabling more accurateand controllable future occupancy predictions. Experimental results on thenuScenes-Occ3D dataset show that COME achieves consistent and significantimprovements over state-of-the-art (SOTA) methods across diverseconfigurations, including different input sources (ground-truth, camera-based,fusion-based occupancy) and prediction horizons (3s and 8s). For example, underthe same settings, COME achieves 26.3% better mIoU metric than DOME and 23.7%better mIoU metric than UniScene. These results highlight the efficacy ofdisentangled representation learning in enhancing spatio-temporal predictionfidelity for world models. Code and videos will be available athttps://github.com/synsin0/COME.</description>
      <author>example@mail.com (Yining Shi, Kun Jiang, Qiang Meng, Ke Wang, Jiabao Wang, Wenchao Sun, Tuopu Wen, Mengmeng Yang, Diange Yang)</author>
      <guid isPermaLink="false">2506.13260v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Omni-AdaVideoRAG: Omni-Contextual Adaptive Retrieval-Augmented for Efficient Long Video Understanding</title>
      <link>http://arxiv.org/abs/2506.13589v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AdaVideoRAG的新框架，用于解决多模态大型语言模型在处理长视频时的困难，并提高了视频理解的效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型在处理长视频时面临固定上下文窗口和弱长期依赖建模的挑战。现有的视频检索增强生成方法使用静态检索策略，导致简单查询效率低下和复杂任务中信息丢失。&lt;h4&gt;目的&lt;/h4&gt;提出AdaVideoRAG框架，旨在动态调整检索粒度，以提高长视频理解的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;AdaVideoRAG使用轻量级意图分类器根据查询复杂性动态调整检索粒度，并采用Omni-Knowledge Indexing模块构建包含文本、视觉特征和语义图的分层数据库，以实现跨任务的资源优化分配。此外，还引入了HiVU基准用于全面评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AdaVideoRAG在长视频理解方面提高了效率和准确性，并且可以无缝集成到现有的多模态大型语言模型中。&lt;h4&gt;结论&lt;/h4&gt;AdaVideoRAG为视频分析中的自适应检索建立了一个新的范式，并将代码开源。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal Large Language Models (MLLMs) struggle with long videos due to fixed context windows and weak long-term dependency modeling. Existing Retrieval-Augmented Generation (RAG) methods for videos use static retrieval strategies, leading to inefficiencies for simple queries and information loss for complex tasks. To address this, we propose AdaVideoRAG, a novel framework that dynamically adapts retrieval granularity based on query complexity using a lightweight intent classifier. Our framework employs an Omni-Knowledge Indexing module to build hierarchical databases from text (captions, ASR, OCR), visual features, and semantic graphs, enabling optimal resource allocation across tasks. We also introduce the HiVU benchmark for comprehensive evaluation. Experiments demonstrate improved efficiency and accuracy for long-video understanding, with seamless integration into existing MLLMs. AdaVideoRAG establishes a new paradigm for adaptive retrieval in video analysis. Codes will be open-sourced at https://github.com/xzc-zju/AdaVideoRAG.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) struggle with long videos due tofixed context windows and weak long-term dependency modeling. ExistingRetrieval-Augmented Generation (RAG) methods for videos use static retrievalstrategies, leading to inefficiencies for simple queries and information lossfor complex tasks. To address this, we propose AdaVideoRAG, a novel frameworkthat dynamically adapts retrieval granularity based on query complexity using alightweight intent classifier. Our framework employs an Omni-Knowledge Indexingmodule to build hierarchical databases from text (captions, ASR, OCR), visualfeatures, and semantic graphs, enabling optimal resource allocation acrosstasks. We also introduce the HiVU benchmark for comprehensive evaluation.Experiments demonstrate improved efficiency and accuracy for long-videounderstanding, with seamless integration into existing MLLMs. AdaVideoRAGestablishes a new paradigm for adaptive retrieval in video analysis. Codes willbe open-sourced at https://github.com/xzc-zju/AdaVideoRAG.</description>
      <author>example@mail.com (Zhucun Xue, Jiangning Zhang, Xurong Xie, Yuxuan Cai, Yong Liu, Xiangtai Li, Dacheng Tao)</author>
      <guid isPermaLink="false">2506.13589v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>CAMS: A CityGPT-Powered Agentic Framework for Urban Human Mobility Simulation</title>
      <link>http://arxiv.org/abs/2506.13599v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CAMS的基于语言的城市基础模型的代理框架，用于模拟人类在城市空间中的移动。&lt;h4&gt;背景&lt;/h4&gt;人类移动模拟在现实世界中应用广泛，但传统数据驱动方法存在不足，如城市空间建模不足、与个体和集体移动模式整合不佳。&lt;h4&gt;目的&lt;/h4&gt;提出CAMS框架以解决现有方法的不足，实现更精确和现实的人类移动模拟。&lt;h4&gt;方法&lt;/h4&gt;CAMS包括三个核心模块：MobExtractor用于提取和合成移动模式，GeoGenerator基于集体知识生成锚点和候选城市地理空间知识，TrajEnhancer基于移动模式检索空间知识并生成与真实轨迹偏好一致的轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CAMS在无需外部提供的地理空间信息的情况下，实现了优异的性能，并且通过全面模拟个体和集体移动模式，生成了更真实和合理的轨迹。&lt;h4&gt;结论&lt;/h4&gt;CAMS建立了一个新的范式，将代理框架与城市知识型大型语言模型相结合，以实现人类移动模拟。&lt;h4&gt;翻译&lt;/h4&gt;Human mobility simulation plays a crucial role in various real-world applications. Recently, to address the limitations of traditional data-driven approaches, researchers have explored leveraging the commonsense knowledge and reasoning capabilities of large language models (LLMs) to accelerate human mobility simulation. However, these methods suffer from several critical shortcomings, including inadequate modeling of urban spaces and poor integration with both individual mobility patterns and collective mobility distributions. To address these challenges, we propose CityGPT-Powered Agentic framework for Mobility Simulation (CAMS), an agentic framework that leverages the language based urban foundation model to simulate human mobility in urban space. CAMS comprises three core modules, including MobExtractor to extract template mobility patterns and synthesize new ones based on user profiles, GeoGenerator to generate anchor points considering collective knowledge and generate candidate urban geospatial knowledge using an enhanced version of CityGPT, TrajEnhancer to retrieve spatial knowledge based on mobility patterns and generate trajectories with real trajectory preference alignment via DPO. Experiments on real-world datasets show that CAMS achieves superior performance without relying on externally provided geospatial information. Moreover, by holistically modeling both individual mobility patterns and collective mobility constraints, CAMS generates more realistic and plausible trajectories. In general, CAMS establishes a new paradigm that integrates the agentic framework with urban-knowledgeable LLMs for human mobility simulation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human mobility simulation plays a crucial role in various real-worldapplications. Recently, to address the limitations of traditional data-drivenapproaches, researchers have explored leveraging the commonsense knowledge andreasoning capabilities of large language models (LLMs) to accelerate humanmobility simulation. However, these methods suffer from several criticalshortcomings, including inadequate modeling of urban spaces and poorintegration with both individual mobility patterns and collective mobilitydistributions. To address these challenges, we propose \textbf{C}ityGPT-Powered\textbf{A}gentic framework for \textbf{M}obility \textbf{S}imulation(\textbf{CAMS}), an agentic framework that leverages the language based urbanfoundation model to simulate human mobility in urban space. \textbf{CAMS}comprises three core modules, including MobExtractor to extract templatemobility patterns and synthesize new ones based on user profiles, GeoGeneratorto generate anchor points considering collective knowledge and generatecandidate urban geospatial knowledge using an enhanced version of CityGPT,TrajEnhancer to retrieve spatial knowledge based on mobility patterns andgenerate trajectories with real trajectory preference alignment via DPO.Experiments on real-world datasets show that \textbf{CAMS} achieves superiorperformance without relying on externally provided geospatial information.Moreover, by holistically modeling both individual mobility patterns andcollective mobility constraints, \textbf{CAMS} generates more realistic andplausible trajectories. In general, \textbf{CAMS} establishes a new paradigmthat integrates the agentic framework with urban-knowledgeable LLMs for humanmobility simulation.</description>
      <author>example@mail.com (Yuwei Du, Jie Feng, Jian Yuan, Yong Li)</author>
      <guid isPermaLink="false">2506.13599v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>FreeQ-Graph: Free-form Querying with Semantic Consistent Scene Graph for 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2506.13629v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FreeQ-Graph的方法，通过语义一致的场景图实现复杂3D场景中的自由形式语言查询。&lt;h4&gt;背景&lt;/h4&gt;现有的3D场景理解方法依赖于大规模训练数据和CLIP技术，将文本查询与3D语义特征对齐，但这种方法受限于预定义词汇先验，难以实现自由形式的语义查询。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够进行自由形式语义查询的技术，同时保证查询结果的语义一致性。&lt;h4&gt;方法&lt;/h4&gt;FreeQ-Graph通过以下三个关键步骤实现：构建一个完整的、准确的3D场景图，利用LLM和LVLM指导，不依赖训练数据或预定义先验；通过合并superpoints的3D语义对齐特征，将图节点与准确的语义标签对齐；设计一个基于LLM的推理算法，结合场景级和对象级信息进行复杂推理。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，FreeQ-Graph在复杂自由形式语义查询和复杂关系推理方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;FreeQ-Graph提供了一种有效的3D场景理解方法，能够实现自由形式的语义查询，并保证了查询结果的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Semantic querying in complex 3D scenes through free-form language presents a significant challenge. Existing 3D scene understanding methods use large-scale training data and CLIP to align text queries with 3D semantic features. However, their reliance on predefined vocabulary priors from training data hinders free-form semantic querying. Besides, recent advanced methods rely on LLMs for scene understanding but lack comprehensive 3D scene-level information and often overlook the potential inconsistencies in LLM-generated outputs. In our paper, we propose FreeQ-Graph, which enables Free-form Querying with a semantic consistent scene Graph for 3D scene understanding. The core idea is to encode free-form queries from a complete and accurate 3D scene graph without predefined vocabularies, and to align them with 3D consistent semantic labels, which accomplished through three key steps. We initiate by constructing a complete and accurate 3D scene graph that maps free-form objects and their relations through LLM and LVLM guidance, entirely free from training data or predefined priors. Most importantly, we align graph nodes with accurate semantic labels by leveraging 3D semantic aligned features from merged superpoints, enhancing 3D semantic consistency. To enable free-form semantic querying, we then design an LLM-based reasoning algorithm that combines scene-level and object-level information to intricate reasoning. We conducted extensive experiments on 3D semantic grounding, segmentation, and complex querying tasks, while also validating the accuracy of graph generation. Experiments on 6 datasets show that our model excels in both complex free-form semantic queries and intricate relational reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic querying in complex 3D scenes through free-form language presents asignificant challenge. Existing 3D scene understanding methods use large-scaletraining data and CLIP to align text queries with 3D semantic features.However, their reliance on predefined vocabulary priors from training datahinders free-form semantic querying. Besides, recent advanced methods rely onLLMs for scene understanding but lack comprehensive 3D scene-level informationand often overlook the potential inconsistencies in LLM-generated outputs. Inour paper, we propose FreeQ-Graph, which enables Free-form Querying with asemantic consistent scene Graph for 3D scene understanding. The core idea is toencode free-form queries from a complete and accurate 3D scene graph withoutpredefined vocabularies, and to align them with 3D consistent semantic labels,which accomplished through three key steps. We initiate by constructing acomplete and accurate 3D scene graph that maps free-form objects and theirrelations through LLM and LVLM guidance, entirely free from training data orpredefined priors. Most importantly, we align graph nodes with accuratesemantic labels by leveraging 3D semantic aligned features from mergedsuperpoints, enhancing 3D semantic consistency. To enable free-form semanticquerying, we then design an LLM-based reasoning algorithm that combinesscene-level and object-level information to intricate reasoning. We conductedextensive experiments on 3D semantic grounding, segmentation, and complexquerying tasks, while also validating the accuracy of graph generation.Experiments on 6 datasets show that our model excels in both complex free-formsemantic queries and intricate relational reasoning.</description>
      <author>example@mail.com (Chenlu Zhan, Gaoang Wang, Hongwei Wang)</author>
      <guid isPermaLink="false">2506.13629v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>RelTopo: Enhancing Relational Modeling for Driving Scene Topology Reasoning</title>
      <link>http://arxiv.org/abs/2506.13553v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于关系建模的自动驾驶道路拓扑推理方法，该方法通过将关系建模引入感知和推理过程，显著提高了车道检测和拓扑推理的性能。&lt;h4&gt;背景&lt;/h4&gt;准确的道路拓扑推理对于自动驾驶至关重要，它能够实现有效的导航和遵守交通规则。车道感知和拓扑推理是这一任务的核心。&lt;h4&gt;目的&lt;/h4&gt;提出的方法旨在解决现有方法中忽视车道到交通元素（L2T）关系或未能联合优化这些任务的问题，并克服了关系建模应用范围有限的问题。&lt;h4&gt;方法&lt;/h4&gt;1) 提出了一种关系感知的车道检测器，通过几何偏置的自注意力机制和曲线交叉注意力机制来捕捉关系依赖，从而优化车道表示。2) 提出了关系增强的拓扑头，包括几何增强的L2L头和跨视角的L2T头，以关系线索增强推理。3) 使用带有InfoNCE损失的对比学习策略来正则化关系嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;在OpenLane-V2数据集上的实验表明，该方法在检测和拓扑推理指标上均有显著提升，分别提高了+3.1（DET$_l$）、+5.3（TOP$_{ll}$）、+4.9（TOP$_{lt}$）和整体提高了+4.4（OLS），达到了新的技术水平。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过关系建模在感知和推理方面取得了显著的性能提升，为自动驾驶的道路拓扑推理提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;准确的公路拓扑推理对自动驾驶至关重要，它能够实现有效的导航和遵守交通规则。车道感知和拓扑推理是这一任务的核心。然而，现有的方法通常只关注车道检测或车道到车道（L2L）拓扑推理，往往忽略了车道到交通元素（L2T）关系或未能联合优化这些任务。此外，大多数方法要么忽略了关系建模，要么只在有限的范围内应用它，尽管道路元素之间存在固有的空间关系。我们认为，关系建模对感知和推理都有益，因为人类自然利用上下文关系来识别道路元素及其连通性推断。为此，我们将关系建模引入感知和推理，共同增强结构理解。具体而言，我们提出了：1）一种关系感知的车道检测器，其中我们的几何偏置自注意力和曲线交叉注意力通过捕捉关系依赖来优化车道表示；2）关系增强的拓扑头，包括几何增强的L2L头和跨视角的L2T头，通过关系线索增强推理；3）一种带有InfoNCE损失的对比学习策略来正则化关系嵌入。在OpenLane-V2数据集上的大量实验表明，我们的方法在检测和拓扑推理指标上都有显著提高，分别提高了+3.1（DET$_l$）、+5.3（TOP$_{ll}$）、+4.9（TOP$_{lt}$）和整体提高了+4.4（OLS），达到了新的技术水平。代码将公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate road topology reasoning is critical for autonomous driving, enablingeffective navigation and adherence to traffic regulations. Central to this taskare lane perception and topology reasoning. However, existing methods typicallyfocus on either lane detection or Lane-to-Lane (L2L) topology reasoning, often\textit{neglecting} Lane-to-Traffic-element (L2T) relationships or\textit{failing} to optimize these tasks jointly. Furthermore, most approacheseither overlook relational modeling or apply it in a limited scope, despite theinherent spatial relationships among road elements. We argue that relationalmodeling is beneficial for both perception and reasoning, as humans naturallyleverage contextual relationships for road element recognition and theirconnectivity inference. To this end, we introduce relational modeling into bothperception and reasoning, \textit{jointly} enhancing structural understanding.Specifically, we propose: 1) a relation-aware lane detector, where ourgeometry-biased self-attention and \curve\ cross-attention refine lanerepresentations by capturing relational dependencies; 2) relation-enhancedtopology heads, including a geometry-enhanced L2L head and a cross-view L2Thead, boosting reasoning with relational cues; and 3) a contrastive learningstrategy with InfoNCE loss to regularize relationship embeddings. Extensiveexperiments on OpenLane-V2 demonstrate that our approach significantly improvesboth detection and topology reasoning metrics, achieving +3.1 in DET$_l$, +5.3in TOP$_{ll}$, +4.9 in TOP$_{lt}$, and an overall +4.4 in OLS, setting a newstate-of-the-art. Code will be released.</description>
      <author>example@mail.com (Yueru Luo, Changqing Zhou, Yiming Yang, Erlong Li, Chao Zheng, Shuqi Mei, Shuguang Cui, Zhen Li)</author>
      <guid isPermaLink="false">2506.13553v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>MambaMia: A State-Space-Model-Based Compression for Efficient Video Understanding in Large Multimodal Models</title>
      <link>http://arxiv.org/abs/2506.13564v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种高效的框架，用于在将视频帧特征输入大型多模态模型之前压缩这些特征，从而减轻长或密集视频引起的严重标记爆炸问题。&lt;h4&gt;背景&lt;/h4&gt;长或密集视频在处理时会产生大量的标记，这对大型多模态模型来说是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够在保持性能的同时减少资源消耗的框架，用于处理长和密集视频。&lt;h4&gt;方法&lt;/h4&gt;该方法利用了一种双向状态空间块，该块配备了门控跳过连接和一个可学习的加权平均池化机制，该机制应用于定期插入的学习查询。这种结构能够在空间和时间维度上实现分层下采样。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在具有挑战性的长和密集视频理解任务中表现出与最先进模型相媲美的结果，同时显著减少了整体标记预算。使用传统的Transformer代替提出的状态空间块会导致性能下降不明显，这突出了状态空间建模在有效压缩多帧视频数据方面的优势。&lt;h4&gt;结论&lt;/h4&gt;该框架强调了资源感知的效率，使其在实际部署中变得可行，并在多个基准测试中验证了其可扩展性和通用性，实现了高效资源使用和全面视频理解的双重目标。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种高效的框架来压缩在输入到大型多模态模型之前的多个视频帧特征，从而减轻了由长或密集视频引起的严重标记爆炸。我们的设计利用了一种双向状态空间块，该块配备了门控跳过连接和应用于定期插入的学习查询的可学习加权平均池化机制。这种结构使空间和时间维度上的分层下采样成为可能，以成本效益的方式保留性能。在具有挑战性的长和密集视频理解任务中，我们的方法在对最先进模型具有竞争力，同时显著减少了整体标记预算。值得注意的是，用我们提出的状态空间块替换传统的Transformer会导致性能下降不显著，这突出了状态空间建模在有效压缩多帧视频数据方面的优势。我们的框架强调了资源感知的效率，使其在实际部署中变得可行。我们在多个基准测试中验证了其可扩展性和通用性，实现了高效资源使用和全面视频理解的双重目标。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose an efficient framework to compress multiple video-frame featuresbefore feeding them into large multimodal models, thereby mitigating the severetoken explosion arising from long or dense videos. Our design leverages abidirectional state-space-based block equipped with a gated skip connection anda learnable weighted-average pooling mechanism applied to periodically insertedlearned queries. This structure enables hierarchical downsampling across bothspatial and temporal dimensions, preserving performance in a cost-effectivemanner. Across challenging long and dense video understanding tasks, ourapproach demonstrates competitive results against state-of-the-art models,while significantly reducing overall token budget. Notably, replacing ourproposed state-space block with a conventional Transformer results insubstantial performance degradation, highlighting the advantages of state-spacemodeling for effectively compressing multi-frame video data. Our frameworkemphasizes resource-conscious efficiency, making it practical for real-worlddeployments. We validate its scalability and generality across multiplebenchmarks, achieving the dual objectives of efficient resource usage andcomprehensive video understanding.</description>
      <author>example@mail.com (Geewook Kim, Minjoon Seo)</author>
      <guid isPermaLink="false">2506.13564v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Model Context Protocol (MCP) at First Glance: Studying the Security and Maintainability of MCP Servers</title>
      <link>http://arxiv.org/abs/2506.13538v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对模型上下文协议（MCP）进行了首次大规模实证研究，评估了其健康、安全和可维护性。&lt;h4&gt;背景&lt;/h4&gt;尽管基础模型（如GPT-4）在金融和软件工程等领域得到广泛应用，但依赖文本界面限制了这些模型在现实世界中的交互。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，模型提供商引入了工具调用，导致具有不同工具界面的框架大量涌现。本文旨在研究MCP的采用及其带来的风险。&lt;h4&gt;方法&lt;/h4&gt;使用最先进的健康指标和混合分析流程，结合通用静态分析工具和MCP特定扫描器，对1,899个开源MCP服务器进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;尽管MCP服务器展现出强大的健康指标，但发现八个不同的漏洞，其中只有三个与传统软件漏洞重叠。7.2%的服务器含有通用漏洞，5.5%表现出MCP特定工具中毒。在可维护性方面，66%存在代码异味，14.4%包含与先前研究重叠的十个错误模式。&lt;h4&gt;结论&lt;/h4&gt;研究强调了需要针对MCP特定的漏洞检测技术，同时重申了传统分析和重构实践的价值。&lt;h4&gt;翻译&lt;/h4&gt;Although Foundation Models (FMs), such as GPT-4, are increasingly used in domains like finance and software engineering, reliance on textual interfaces limits these models' real-world interaction. To address this, FM providers introduced tool calling-triggering a proliferation of frameworks with distinct tool interfaces. In late 2024, Anthropic introduced the Model Context Protocol (MCP) to standardize this tool ecosystem, which has become the de facto standard with over eight million weekly SDK downloads. Despite its adoption, MCP's AI-driven, non-deterministic control flow introduces new risks to sustainability, security, and maintainability, warranting closer examination. Towards this end, we present the first large-scale empirical study of MCP. Using state-of-the-art health metrics and a hybrid analysis pipeline, combining a general-purpose static analysis tool with an MCP-specific scanner, we evaluate 1,899 open-source MCP servers to assess their health, security, and maintainability. Despite MCP servers demonstrating strong health metrics, we identify eight distinct vulnerabilities-only three overlapping with traditional software vulnerabilities. Additionally, 7.2% of servers contain general vulnerabilities and 5.5% exhibit MCP-specific tool poisoning. Regarding maintainability, while 66% exhibit code smells, 14.4% contain ten bug patterns overlapping prior research. These findings highlight the need for MCP-specific vulnerability detection techniques while reaffirming the value of traditional analysis and refactoring practices.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although Foundation Models (FMs), such as GPT-4, are increasingly used indomains like finance and software engineering, reliance on textual interfaceslimits these models' real-world interaction. To address this, FM providersintroduced tool calling-triggering a proliferation of frameworks with distincttool interfaces. In late 2024, Anthropic introduced the Model Context Protocol(MCP) to standardize this tool ecosystem, which has become the de factostandard with over eight million weekly SDK downloads. Despite its adoption,MCP's AI-driven, non-deterministic control flow introduces new risks tosustainability, security, and maintainability, warranting closer examination.  Towards this end, we present the first large-scale empirical study of MCP.Using state-of-the-art health metrics and a hybrid analysis pipeline, combininga general-purpose static analysis tool with an MCP-specific scanner, weevaluate 1,899 open-source MCP servers to assess their health, security, andmaintainability. Despite MCP servers demonstrating strong health metrics, weidentify eight distinct vulnerabilities-only three overlapping with traditionalsoftware vulnerabilities. Additionally, 7.2% of servers contain generalvulnerabilities and 5.5% exhibit MCP-specific tool poisoning. Regardingmaintainability, while 66% exhibit code smells, 14.4% contain ten bug patternsoverlapping prior research. These findings highlight the need for MCP-specificvulnerability detection techniques while reaffirming the value of traditionalanalysis and refactoring practices.</description>
      <author>example@mail.com (Mohammed Mehedi Hasan, Hao Li, Emad Fallahzadeh, Bram Adams, Ahmed E. Hassan)</author>
      <guid isPermaLink="false">2506.13538v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>A Gravity-informed Spatiotemporal Transformer for Human Activity Intensity Prediction</title>
      <link>http://arxiv.org/abs/2506.13678v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Gravityformer的物理信息深度学习框架，用于预测人类活动强度，以解决现有方法在空间交互物理约束和空间相关性建模中的平滑过度问题。&lt;h4&gt;背景&lt;/h4&gt;人类活动强度预测对于许多基于位置的服务至关重要。尽管在模拟人类活动的动态时空模式方面取得了巨大进步，但大多数现有方法，包括时空图神经网络（ST-GNNs），忽略了空间交互的物理约束和空间相关性建模中的平滑过度现象。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述局限性，本研究提出了一个物理信息深度学习框架，即Gravityformer，通过改进transformer注意力机制来整合万有引力定律，并明确地纳入空间交互的约束。&lt;h4&gt;方法&lt;/h4&gt;具体来说，Gravityformer通过以下方式实现：(1) 根据流入和流出估计两个空间显式质量参数；(2) 使用空间交互的封闭形式解来建模跨单元交互的可能性，以约束空间建模的随机性；(3) 利用学习到的空间交互来引导和减轻transformer注意力矩阵中的平滑过度现象。&lt;h4&gt;主要发现&lt;/h4&gt;提出的自适应重力模型可以明确地模拟人类活动的潜在规律。通过在六个真实世界大规模活动数据集上的系统性实验，证明了该方法在定量和定性方面优于现有最佳基准。此外，学习到的重力注意力矩阵可以根据地理定律进行解耦和解释。&lt;h4&gt;结论&lt;/h4&gt;这项工作为将物理定律与深度学习相结合进行时空预测学习提供了新的见解。&lt;h4&gt;翻译&lt;/h4&gt;Human activity intensity prediction is a crucial to many location-based services. Although tremendous progress has been made to model dynamics patiotemporal patterns of human activity, most existing methods, including spatiotemporal graph neural networks (ST-GNNs), overlook physical constraints of spatial interactions and the over-smoothing phenomenon in spatial correlation modeling. To address these limitations, this work proposes a physics-informed deep learning framework, namely Gravity-informed Spatiotemporal Transformer (Gravityformer) by refining transformer attention to integrate the universal law of gravitation and explicitly incorporating constraints from spatial interactions. Specifically, it (1) estimates two spatially explicit mass parameters based on inflow and outflow, (2) models the likelihood of cross-unit interaction using closed-form solutions of spatial interactions to constrain spatial modeling randomness, and (3) utilizes the learned spatial interaction to guide and mitigate the over-smoothing phenomenon in transformer attention matrices. The underlying law of human activity can be explicitly modeled by the proposed adaptive gravity model. Moreover, a parallel spatiotemporal graph convolution transformer structure is proposed for achieving a balance between coupled spatial and temporal learning. Systematic experiments on six real-world large-scale activity datasets demonstrate the quantitative and qualitative superiority of our approach over state-of-the-art benchmarks. Additionally, the learned gravity attention matrix can be disentangled and interpreted based on geographical laws. This work provides a novel insight into integrating physical laws with deep learning for spatiotemporal predictive learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human activity intensity prediction is a crucial to many location-basedservices. Although tremendous progress has been made to model dynamicspatiotemporal patterns of human activity, most existing methods, includingspatiotemporal graph neural networks (ST-GNNs), overlook physical constraintsof spatial interactions and the over-smoothing phenomenon in spatialcorrelation modeling. To address these limitations, this work proposes aphysics-informed deep learning framework, namely Gravity-informedSpatiotemporal Transformer (Gravityformer) by refining transformer attention tointegrate the universal law of gravitation and explicitly incorporatingconstraints from spatial interactions. Specifically, it (1) estimates twospatially explicit mass parameters based on inflow and outflow, (2) models thelikelihood of cross-unit interaction using closed-form solutions of spatialinteractions to constrain spatial modeling randomness, and (3) utilizes thelearned spatial interaction to guide and mitigate the over-smoothing phenomenonin transformer attention matrices. The underlying law of human activity can beexplicitly modeled by the proposed adaptive gravity model. Moreover, a parallelspatiotemporal graph convolution transformer structure is proposed forachieving a balance between coupled spatial and temporal learning. Systematicexperiments on six real-world large-scale activity datasets demonstrate thequantitative and qualitative superiority of our approach over state-of-the-artbenchmarks. Additionally, the learned gravity attention matrix can bedisentangled and interpreted based on geographical laws. This work provides anovel insight into integrating physical laws with deep learning forspatiotemporal predictive learning.</description>
      <author>example@mail.com (Yi Wang, Zhenghong Wang, Fan Zhang, Chengling Tang, Chaogui Kang, Di Zhu, Zhongfu Ma, Sijie Ruan, Weiyu Zhang, Yu Zheng, Philip S. Yu, Yu Liu)</author>
      <guid isPermaLink="false">2506.13678v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Image-Based Grapevine Variety Classification with a New Benchmark and Evaluation of Masked Autoencoders</title>
      <link>http://arxiv.org/abs/2506.13335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究评估了基于深度学习的葡萄品种识别方法，提出使用自监督学习的掩码自动编码器（MAE）来提高识别性能。&lt;h4&gt;背景&lt;/h4&gt;葡萄品种对许多葡萄酒生产国的经济至关重要，传统识别方法如葡萄藤学分析和分子分析存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于深度学习的葡萄品种识别方法，以克服传统方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;采用自监督学习的掩码自动编码器（MAE）模型，使用实地采集的图像数据进行葡萄品种识别，并构建了包含43个葡萄品种的基准数据集。&lt;h4&gt;主要发现&lt;/h4&gt;使用ViT-B/16模型预训练的MAE在未标记数据集上达到了0.7956的F1分数，优于其他模型。发现预训练模型受益于长时间的预训练，在低数据训练下表现良好，简单的数据增强方法比复杂的方法更有效。&lt;h4&gt;结论&lt;/h4&gt;自监督学习的掩码自动编码器（MAE）在葡萄品种识别中具有潜力，能够提高识别性能并减少对标注数据的依赖。&lt;h4&gt;翻译&lt;/h4&gt;Grapevine varieties are essential for the economies of many wine-producing countries, influencing the production of wine, juice, and the consumption of fruits and leaves. Traditional identification methods, such as ampelography and molecular analysis, have limitations: ampelography depends on expert knowledge and is inherently subjective, while molecular methods are costly and time-intensive. To address these limitations, recent studies have applied deep learning (DL) models to classify grapevine varieties using image data. However, due to the small dataset sizes, these methods often depend on transfer learning from datasets from other domains, e.g., ImageNet1K (IN1K), which can lead to performance degradation due to domain shift and supervision collapse. In this context, self-supervised learning (SSL) methods can be a good tool to avoid this performance degradation, since they can learn directly from data, without external labels. This study presents an evaluation of Masked Autoencoders (MAEs) for identifying grapevine varieties based on field-acquired images. The main contributions of this study include two benchmarks comprising 43 grapevine varieties collected across different seasons, an analysis of MAE's application in the agricultural context, and a performance comparison of trained models across seasons. Our results show that a ViT-B/16 model pre-trained with MAE and the unlabeled dataset achieved an F1 score of 0.7956, outperforming all other models. Additionally, we observed that pre-trained models benefit from long pre-training, perform well under low-data training regime, and that simple data augmentation methods are more effective than complex ones. The study also found that the mask ratio in MAE impacts performance only marginally.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grapevine varieties are essential for the economies of many wine-producingcountries, influencing the production of wine, juice, and the consumption offruits and leaves. Traditional identification methods, such as ampelography andmolecular analysis, have limitations: ampelography depends on expert knowledgeand is inherently subjective, while molecular methods are costly andtime-intensive. To address these limitations, recent studies have applied deeplearning (DL) models to classify grapevine varieties using image data. However,due to the small dataset sizes, these methods often depend on transfer learningfrom datasets from other domains, e.g., ImageNet1K (IN1K), which can lead toperformance degradation due to domain shift and supervision collapse. In thiscontext, self-supervised learning (SSL) methods can be a good tool to avoidthis performance degradation, since they can learn directly from data, withoutexternal labels. This study presents an evaluation of Masked Autoencoders(MAEs) for identifying grapevine varieties based on field-acquired images. Themain contributions of this study include two benchmarks comprising 43 grapevinevarieties collected across different seasons, an analysis of MAE's applicationin the agricultural context, and a performance comparison of trained modelsacross seasons. Our results show that a ViT-B/16 model pre-trained with MAE andthe unlabeled dataset achieved an F1 score of 0.7956, outperforming all othermodels. Additionally, we observed that pre-trained models benefit from longpre-training, perform well under low-data training regime, and that simple dataaugmentation methods are more effective than complex ones. The study also foundthat the mask ratio in MAE impacts performance only marginally.</description>
      <author>example@mail.com (Gabriel A. Carneiro, Thierry J. Aubry, António Cunha, Petia Radeva, Joaquim Sousa)</author>
      <guid isPermaLink="false">2506.13335v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Boundary-Informed Sound Field Reconstruction</title>
      <link>http://arxiv.org/abs/2506.13279v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication at EUSIPCO 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用边界几何形状的先验信息重建室内声场的问题。&lt;h4&gt;背景&lt;/h4&gt;在没有边界信息的情况下，在大空间区域和高频段进行准确的声场重建需要大量的麦克风测量。如果所有边界几何和声学特性都已知，理论上可以不进行测量就模拟声场。&lt;h4&gt;目的&lt;/h4&gt;本文针对只有部分或不确定的边界信息可用的情况进行研究，类似于虚拟现实应用中的场景，旨在创建一个感知上令人信服的音频体验。&lt;h4&gt;方法&lt;/h4&gt;本文在线性贝叶斯框架内对问题进行建模，结合了由阻抗边界条件导出的边界信息先验，并允许联合优化未知超参数，包括噪声和信号方差以及阻抗边界条件。&lt;h4&gt;主要发现&lt;/h4&gt;通过数值实验表明，结合边界信息先验可以显著提高重建质量，即使在只有几百个边界点可用或边界位置存在高达1分米的误差时也是如此。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在声场重建中有效，尤其是在边界信息不完整的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider the problem of reconstructing the sound field in a room usingprior information of the boundary geometry, represented as a point cloud. Ingeneral, when no boundary information is available, an accurate sound fieldreconstruction over a large spatial region and at high frequencies requiresnumerous microphone measurements. On the other hand, if all geometrical andacoustical aspects of the boundaries are known, the sound field could, intheory, be simulated without any measurements. In this work, we address theintermediate case, where only partial or uncertain boundary information isavailable. This setting is similar to one studied in virtual realityapplications, where the goal is to create a perceptually convincing audioexperience. In this work, we focus on spatial sound control applications, whichin contrast require an accurate sound field reconstruction. Therefore, weformulate the problem within a linear Bayesian framework, incorporating aboundary-informed prior derived from impedance boundary conditions. Theformulation allows for joint optimization of the unknown hyperparameters,including the noise and signal variances and the impedance boundary conditions.Using numerical experiments, we show that incorporating the boundary-informedprior significantly enhances the reconstruction, notably even when only a fewhundreds of boundary points are available or when the boundary positions arecalibrated with an uncertainty up to 1 dm.</description>
      <author>example@mail.com (David Sundström, Filip Elvander, Andreas Jakobsson)</author>
      <guid isPermaLink="false">2506.13279v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>GeoRecon: Graph-Level Representation Learning for 3D Molecules via Reconstruction-Based Pretraining</title>
      <link>http://arxiv.org/abs/2506.13174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GeoRecon的新型图级预训练框架，用于分子表示学习，通过引入图级重建任务，使模型能够学习全局结构特征，从而提高分子嵌入的全面性和几何感知能力。&lt;h4&gt;背景&lt;/h4&gt;预训练和微调范式在自然语言处理和计算机视觉等领域取得了显著进展，但在分子表示学习中，任务设计主要局限于节点级的去噪，这对于建模局部原子环境有效，但对于需要全局分子结构的图级属性预测任务（如能量估计和分子回归）可能不足。&lt;h4&gt;目的&lt;/h4&gt;提出GeoRecon框架，以改善分子表示学习中的图级属性预测任务。&lt;h4&gt;方法&lt;/h4&gt;GeoRecon通过引入图级重建任务，在预训练过程中训练模型生成能够准确指导分子几何重建的信息丰富图表示。&lt;h4&gt;主要发现&lt;/h4&gt;GeoRecon在多个分子基准测试（如QM9、MD17）上优于基于节点的基线，证明了引入图级重建对学习更全面和几何感知的分子嵌入的好处。&lt;h4&gt;结论&lt;/h4&gt;GeoRecon框架能够有效地学习全局分子结构特征，提高了分子表示学习的性能。&lt;h4&gt;翻译&lt;/h4&gt;The pretraining-and-finetuning paradigm has driven significant advances across domains, such as natural language processing and computer vision, with representative pretraining paradigms such as masked language modeling and next-token prediction. However, in molecular representation learning, the task design remains largely limited to node-level denoising, which is effective at modeling local atomic environments, yet maybe insufficient for capturing the global molecular structure required by graph-level property prediction tasks, such as energy estimation and molecular regression. In this work, we present GeoRecon, a novel graph-level pretraining framework that shifts the focus from individual atoms to the molecule as an integrated whole. GeoRecon introduces a graph-level reconstruction task: during pretraining, the model is trained to generate an informative graph representation capable of accurately guiding reconstruction of the molecular geometry. This encourages the model to learn coherent, global structural features rather than isolated atomic details. Without relying on additional supervision or external data, GeoRecon outperforms node-centric baselines on multiple molecular benchmarks (e.g., QM9, MD17), demonstrating the benefit of incorporating graph-level reconstruction for learning more holistic and geometry-aware molecular embeddings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The pretraining-and-finetuning paradigm has driven significant advancesacross domains, such as natural language processing and computer vision, withrepresentative pretraining paradigms such as masked language modeling andnext-token prediction. However, in molecular representation learning, the taskdesign remains largely limited to node-level denoising, which is effective atmodeling local atomic environments, yet maybe insufficient for capturing theglobal molecular structure required by graph-level property prediction tasks,such as energy estimation and molecular regression. In this work, we presentGeoRecon, a novel graph-level pretraining framework that shifts the focus fromindividual atoms to the molecule as an integrated whole. GeoRecon introduces agraph-level reconstruction task: during pretraining, the model is trained togenerate an informative graph representation capable of accurately guidingreconstruction of the molecular geometry. This encourages the model to learncoherent, global structural features rather than isolated atomic details.Without relying on additional supervision or external data, GeoReconoutperforms node-centric baselines on multiple molecular benchmarks (e.g., QM9,MD17), demonstrating the benefit of incorporating graph-level reconstructionfor learning more holistic and geometry-aware molecular embeddings.</description>
      <author>example@mail.com (Shaoheng Yan, Zian Li, Muhan Zhang)</author>
      <guid isPermaLink="false">2506.13174v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>StgcDiff: Spatial-Temporal Graph Condition Diffusion for Sign Language Transition Generation</title>
      <link>http://arxiv.org/abs/2506.13156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图的条件扩散框架StgcDiff，用于生成连续的手语视频，通过捕捉手语的独特时空依赖关系来实现平滑过渡。&lt;h4&gt;背景&lt;/h4&gt;现有方法在生成手语视频时，通常只是简单拼接孤立的手语符号，导致视频的视觉连贯性和语义准确性较差。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的方法，旨在通过合成平滑过渡来提高手语视频的视觉和语义质量。&lt;h4&gt;方法&lt;/h4&gt;首先训练一个编码器-解码器架构来学习时空骨架序列的结构感知表示。然后，优化一个基于预训练编码器学习到的表示的条件扩散去噪器，该去噪器负责从噪声中预测过渡帧。此外，设计了Sign-GCN模块作为框架的关键组件，以有效地建模时空特征。&lt;h4&gt;主要发现&lt;/h4&gt;在PHOENIX14T、USTC-CSL100和USTC-SLR500数据集上进行的广泛实验表明，该方法在性能上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;StgcDiff框架能够有效生成手语视频的平滑过渡，提高了视频的视觉连贯性和语义准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sign language transition generation seeks to convert discrete sign languagesegments into continuous sign videos by synthesizing smooth transitions.However,most existing methods merely concatenate isolated signs, resulting inpoor visual coherence and semantic accuracy in the generated videos. Unliketextual languages,sign language is inherently rich in spatial-temporal cues,making it more complex to model. To address this,we propose StgcDiff, agraph-based conditional diffusion framework that generates smooth transitionsbetween discrete signs by capturing the unique spatial-temporal dependencies ofsign language. Specifically, we first train an encoder-decoder architecture tolearn a structure-aware representation of spatial-temporal skeleton sequences.Next, we optimize a diffusion denoiser conditioned on the representationslearned by the pre-trained encoder, which is tasked with predicting transitionframes from noise. Additionally, we design the Sign-GCN module as the keycomponent in our framework, which effectively models the spatial-temporalfeatures. Extensive experiments conducted on the PHOENIX14T, USTC-CSL100,andUSTC-SLR500 datasets demonstrate the superior performance of our method.</description>
      <author>example@mail.com (Jiashu He, Jiayi He, Shengeng Tang, Huixia Ben, Lechao Cheng, Richang Hong)</author>
      <guid isPermaLink="false">2506.13156v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty-Informed Active Perception for Open Vocabulary Object Goal Navigation</title>
      <link>http://arxiv.org/abs/2506.13367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于语义不确定性的主动感知管道，用于室内环境中的对象导航（ObjectNav）任务。&lt;h4&gt;背景&lt;/h4&gt;移动机器人在室内环境中探索时，越来越多地依赖视觉-语言模型来感知图像中的高级语义线索，如物体类别。然而，当前的方法高度依赖于提示工程，且未解决由提示语句变化引起的语义不确定性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以解决语义不确定性问题，提高对象导航任务的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新的概率传感器模型，用于量化视觉-语言模型中的语义不确定性，并将其集成到概率几何-语义地图中，以增强空间理解。基于此地图，开发了一种具有不确定性信息的多臂老虎机目标的前沿探索规划器，以指导高效的对象搜索。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在对象导航成功率上与最先进的方法相当，而不需要大量的提示工程。&lt;h4&gt;结论&lt;/h4&gt;该方法通过解决语义不确定性问题，提高了对象导航任务的性能，为室内环境中的移动机器人探索提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we propose a semantic uncertainty-informed active perception pipeline for object navigation (ObjectNav) tasks in indoor environments. This paper introduces a novel probabilistic sensor model for quantifying semantic uncertainty in vision-language models and incorporates it into a probabilistic geometric-semantic map to enhance spatial understanding. Based on this map, a frontier exploration planner with an uncertainty-informed multi-armed bandit objective is developed to guide efficient object search. Experimental results demonstrate that our method achieves object navigation success rates comparable to those of state-of-the-art approaches, without requiring extensive prompt engineering.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile robots exploring indoor environments increasingly rely onvision-language models to perceive high-level semantic cues in camera images,such as object categories. Such models offer the potential to substantiallyadvance robot behaviour for tasks such as object-goal navigation (ObjectNav),where the robot must locate objects specified in natural language by exploringthe environment. Current ObjectNav methods heavily depend on prompt engineeringfor perception and do not address the semantic uncertainty induced byvariations in prompt phrasing. Ignoring semantic uncertainty can lead tosuboptimal exploration, which in turn limits performance. Hence, we propose asemantic uncertainty-informed active perception pipeline for ObjectNav inindoor environments. We introduce a novel probabilistic sensor model forquantifying semantic uncertainty in vision-language models and incorporate itinto a probabilistic geometric-semantic map to enhance spatial understanding.Based on this map, we develop a frontier exploration planner with anuncertainty-informed multi-armed bandit objective to guide efficient objectsearch. Experimental results demonstrate that our method achieves ObjectNavsuccess rates comparable to those of state-of-the-art approaches, withoutrequiring extensive prompt engineering.</description>
      <author>example@mail.com (Utkarsh Bajpai, Julius Rückin, Cyrill Stachniss, Marija Popović)</author>
      <guid isPermaLink="false">2506.13367v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>TensorSLM: Energy-efficient Embedding Compression of Sub-billion Parameter Language Models on Low-end Devices</title>
      <link>http://arxiv.org/abs/2506.13514v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 Workshop on Tiny Titans: The next wave of On-Device  Learning for Foundational Models (TTODLer-FM)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用Tensor-Train分解（TTD）的无需训练的token嵌入压缩方法，用于解决小语言模型（SLMs）在边缘设备上的适应性、能效和电池寿命限制问题。&lt;h4&gt;背景&lt;/h4&gt;小语言模型（SLMs）与大型语言模型（LLMs）相比，参数更少，通常部署在低端设备上，如手机和单板计算机。SLMs需要适应部署环境和能效，因为数据中心部署的LLMs没有解决电池寿命限制的问题。&lt;h4&gt;目的&lt;/h4&gt;针对SLMs的适应性和能效要求，本文旨在提出一种新的压缩方法，以改善SLMs在边缘设备上的性能。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种基于Tensor-Train分解（TTD）的无需训练的token嵌入压缩方法，将每个预训练的token嵌入向量转换为低维度的Matrix Product State（MPS）。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在典型的低端设备（如Raspberry Pi）上进行了评估，使用GPT-2/Cerebres-GPT和OPT模型的子亿参数版本作为例子，实现了大约2.0倍的嵌入层压缩，同时单个查询的能量消耗减少了一半。&lt;h4&gt;结论&lt;/h4&gt;该方法在保证语言任务性能的同时，显著提高了SLMs在边缘设备上的能效。&lt;h4&gt;翻译&lt;/h4&gt;Small Language Models (SLMs, or on-device LMs) have significantly fewerparameters than Large Language Models (LLMs). They are typically deployed onlow-end devices, like mobile phones and single-board computers. Unlike LLMs,which rely on increasing model size for better generalisation, SLMs designedfor edge applications are expected to have adaptivity to the deploymentenvironments and energy efficiency given the device battery life constraints,which are not addressed in datacenter-deployed LLMs. This paper addresses these two requirements by proposing a training-free token embedding compression approach using Tensor-Train Decomposition (TTD). Each pre-trained tokenembedding vector is converted into a lower-dimensional Matrix Product State(MPS). We comprehensively evaluate the extracted low-rank structures acrosscompression ratio, language task performance, latency, and energy consumptionon a typical low-end device, i.e. Raspberry Pi. Taking the sub-billionparameter versions of GPT-2/Cerebres-GPT and OPT models as examples, ourapproach achieves a comparable language task performance to the original modelwith around $2.0imes$ embedding layer compression, while the energyconsumption of a single query drops by half.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Small Language Models (SLMs, or on-device LMs) have significantly fewerparameters than Large Language Models (LLMs). They are typically deployed onlow-end devices, like mobile phones and single-board computers. Unlike LLMs,which rely on increasing model size for better generalisation, SLMs designedfor edge applications are expected to have adaptivity to the deploymentenvironments and energy efficiency given the device battery life constraints,which are not addressed in datacenter-deployed LLMs. This paper addresses thesetwo requirements by proposing a training-free token embedding compressionapproach using Tensor-Train Decomposition (TTD). Each pre-trained tokenembedding vector is converted into a lower-dimensional Matrix Product State(MPS). We comprehensively evaluate the extracted low-rank structures acrosscompression ratio, language task performance, latency, and energy consumptionon a typical low-end device, i.e. Raspberry Pi. Taking the sub-billionparameter versions of GPT-2/Cerebres-GPT and OPT models as examples, ourapproach achieves a comparable language task performance to the original modelwith around $2.0\times$ embedding layer compression, while the energyconsumption of a single query drops by half.</description>
      <author>example@mail.com (Mingxue Xu, Yao Lei Xu, Danilo P. Mandic)</author>
      <guid isPermaLink="false">2506.13514v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Multi-Positive Contrastive Learning for Patent Image Retrieval</title>
      <link>http://arxiv.org/abs/2506.13496v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 3 figures, Accepted as a short paper at the 6th Workshop on  Patent Text Mining and Semantic Technologies (PatentSemTech 2025), co-located  with SIGIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究专利图像检索系统，提出了一种基于Locarno国际分类（LIC）系统层次分类的检索方法，通过多正对比损失函数提高检索效果。&lt;h4&gt;背景&lt;/h4&gt;专利图像是传达专利创新信息的技术图纸，检索系统旨在从大量集合中检索最相关的图像，但专利图像的技术复杂性和语义信息复杂，对领域适应性要求高。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的方法来提高专利图像检索系统的检索效果。&lt;h4&gt;方法&lt;/h4&gt;引入一种层次多正对比损失，利用LIC的分类结构在检索过程中诱导关系，为每个专利图像分配多个基于层次分类的相似度不同的正样本对。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在DeepPatent2数据集上提高了检索结果，且对低参数模型有效，计算资源需求少，适用于硬件有限的部署环境。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效提升专利图像检索系统的性能，且适用于资源受限的环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Patent images are technical drawings that convey information about a patent'sinnovation. Patent image retrieval systems aim to search in vast collectionsand retrieve the most relevant images. Despite recent advances in informationretrieval, patent images still pose significant challenges due to theirtechnical intricacies and complex semantic information, requiring efficientfine-tuning for domain adaptation. Current methods neglect patents'hierarchical relationships, such as those defined by the Locarno InternationalClassification (LIC) system, which groups broad categories (e.g., "furnishing")into subclasses (e.g., "seats" and "beds") and further into specific patentdesigns. In this work, we introduce a hierarchical multi-positive contrastiveloss that leverages the LIC's taxonomy to induce such relations in theretrieval process. Our approach assigns multiple positive pairs to each patentimage within a batch, with varying similarity scores based on the hierarchicaltaxonomy. Our experimental analysis with various vision and multimodal modelson the DeepPatent2 dataset shows that the proposed method enhances theretrieval results. Notably, our method is effective with low-parameter models,which require fewer computational resources and can be deployed on environmentswith limited hardware.</description>
      <author>example@mail.com (Kshitij Kavimandan, Angelos Nalmpantis, Emma Beauxis-Aussalet, Robert-Jan Sips)</author>
      <guid isPermaLink="false">2506.13496v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Online-Optimized Gated Radial Basis Function Neural Network-Based Adaptive Control</title>
      <link>http://arxiv.org/abs/2506.13168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合时间门控径向基函数网络（TGRBF）和非线性鲁棒控制器的混合控制框架，用于解决非线性系统实时自适应控制问题。&lt;h4&gt;背景&lt;/h4&gt;现有的基于神经网络的策略在计算效率和时间依赖性方面存在问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且鲁棒的实时自适应控制方法，以应对未知动态和时变干扰。&lt;h4&gt;方法&lt;/h4&gt;使用TGRBF网络进行系统识别和时间建模，同时采用事件触发的优化机制和基于雅可比矩阵的规则进行参数调整。&lt;h4&gt;主要发现&lt;/h4&gt;与PID和固定增益鲁棒控制器相比，该方法可缩短14.2%的调整时间，限制超调量为10%，并在动态干扰下实现48.4%的积分时间加权绝对误差降低。&lt;h4&gt;结论&lt;/h4&gt;该方法通过统一数据驱动适应性和稳定性保证的控制，提高了部分可观察、时变工业系统的实时性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a hybrid control framework that integrates a Temporal-Gated Radial Basis Function (TGRBF) network with a nonlinear robust controller to address the issue of real-time adaptive control for nonlinear systems with unknown dynamics and time-varying disturbances. The background is that existing neural network-based strategies have problems with computational efficiency and temporal dependencies. The purpose is to propose an efficient and robust real-time adaptive control method to deal with unknown dynamics and time-varying disturbances. The method uses the TGRBF network for system identification and time modeling, while also employing an event-triggered optimization mechanism and rule-based gain tuning derived from the TGRBF model. The main findings show that compared to PID and fixed-gain robust controllers, this method can reduce the settling time by 14.2%, limit the overshoot to 10%, and achieve a 48.4% lower integral time-weighted absolute error under dynamic disturbances. The conclusion is that by unifying data-driven adaptability with stability-guaranteed control, this work advances real-time performance in partially observable, time-varying industrial systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-time adaptive control of nonlinear systems with unknown dynamics andtime-varying disturbances demands precise modeling and robust parameteradaptation. While existing neural network-based strategies struggle withcomputational inefficiency or inadequate temporal dependencies, this studyproposes a hybrid control framework integrating a Temporal-Gated Radial BasisFunction (TGRBF) network with a nonlinear robust controller. The TGRBFsynergizes radial basis function neural networks (RBFNNs) and gated recurrentunits (GRUs) through dynamic gating, enabling efficient offline systemidentification and online temporal modeling with minimal parameter overhead(14.5% increase vs. RBFNNs). During control execution, an event-triggeredoptimization mechanism activates momentum-explicit gradient descent to refinenetwork parameters, leveraging historical data to suppress overfitting whilemaintaining real-time feasibility. Concurrently, the nonlinear controlleradaptively tunes its gains via Jacobian-driven rules derived from the TGRBFmodel, ensuring rapid error convergence and disturbance rejection.Lyapunov-based analysis rigorously guarantees uniform ultimate boundedness ofboth tracking errors and adaptive parameters. Simulations on a nonlinearbenchmark system demonstrate the framework's superiority: compared to PID andfixed-gain robust controllers, the proposed method reduces settling time by14.2%, limits overshoot to 10%, and achieves 48.4% lower integral time-weightedabsolute error under dynamic disturbances. By unifying data-driven adaptabilitywith stability-guaranteed control, this work advances real-time performance inpartially observable, time-varying industrial systems.</description>
      <author>example@mail.com (Mingcong Li)</author>
      <guid isPermaLink="false">2506.13168v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>TwiUSD: A Benchmark Dataset and Structure-Aware LLM Framework for User Stance Detection</title>
      <link>http://arxiv.org/abs/2506.13343v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TwiUSD的用户立场检测基准，旨在解决现有基准缺乏语言和社会结构联合捕捉的问题。同时，提出了MRFG框架，用于提高立场检测模型的性能。&lt;h4&gt;背景&lt;/h4&gt;用户立场检测（UserSD）由于缺乏高质量基准，难以同时捕捉语言和社会结构，因此仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出TwiUSD基准和MRFG框架，以促进立场检测模型的严格评估和性能提升。&lt;h4&gt;方法&lt;/h4&gt;TwiUSD是一个包含16,211用户和47,757条推文的基准，其中包含明确的关注者关系。MRFG框架利用基于LLM的相关性过滤和特征路由，结合多尺度过滤和自适应特征路由技术，通过图神经网络或多层感知器处理。&lt;h4&gt;主要发现&lt;/h4&gt;MRFG在针对目标和跨目标评估中，均优于强基线（包括PLMs、基于图的模型和LLM提示）。&lt;h4&gt;结论&lt;/h4&gt;TwiUSD基准和MRFG框架为用户立场检测提供了新的解决方案，有助于提高立场检测模型的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于缺乏高质量基准，联合捕捉语言和社会结构，用户立场检测（UserSD）仍然具有挑战性。在本文中，我们引入了TwiUSD，这是第一个大规模、人工标注的用户立场检测基准，具有明确的关注者关系，包含16,211个用户和47,757条推文。TwiUSD通过整合推文内容和社交链接，实现了对立场模型的严格评估，并具有优越的规模和标注质量。基于这个资源，我们提出了MRFG：一个结构感知框架，它使用基于LLM的相关性过滤和特征路由来解决噪声和上下文异质性。MRFG采用多尺度过滤，并根据拓扑信息性自适应地通过图神经网络或多层感知器路由特征。实验表明，MRFG在针对目标和跨目标评估中，均优于强基线（包括PLMs、基于图的模型和LLM提示）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; User-level stance detection (UserSD) remains challenging due to the lack ofhigh-quality benchmarks that jointly capture linguistic and social structure.In this paper, we introduce TwiUSD, the first large-scale, manually annotatedUserSD benchmark with explicit followee relationships, containing 16,211 usersand 47,757 tweets. TwiUSD enables rigorous evaluation of stance models byintegrating tweet content and social links, with superior scale and annotationquality. Building on this resource, we propose MRFG: a structure-awareframework that uses LLM-based relevance filtering and feature routing toaddress noise and context heterogeneity. MRFG employs multi-scale filtering andadaptively routes features through graph neural networks or multi-layerperceptrons based on topological informativeness. Experiments show MRFGconsistently outperforms strong baselines (including PLMs, graph-based models,and LLM prompting) in both in-target and cross-target evaluation.</description>
      <author>example@mail.com (Fuaing Niu, Zini Chen, Zhiyu Xie, Genan Dai, Bowen Zhang)</author>
      <guid isPermaLink="false">2506.13343v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Evolution of ReID: From Early Methods to LLM Integration</title>
      <link>http://arxiv.org/abs/2506.13039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了从手工特征方法到深度学习再到结合大型语言模型（LLM）的人脸重识别（ReID）技术的发展过程，并提出了使用GPT-4o生成的动态、特定身份提示来提高视觉匹配的准确性。&lt;h4&gt;背景&lt;/h4&gt;早期ReID方法在光照、姿态和视角变化上存在困难，而深度学习通过学习鲁棒视觉特征解决了这些问题。&lt;h4&gt;目的&lt;/h4&gt;追踪ReID技术的发展历程，并对利用LLM的ReID方法进行全面的综述。&lt;h4&gt;方法&lt;/h4&gt;使用GPT-4o生成动态、特定身份提示，并通过实验验证这些描述如何提高匹配准确性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，这些描述在复杂或模糊的情况下提高了准确性。&lt;h4&gt;结论&lt;/h4&gt;通过连接计算机视觉和自然语言处理，本文提供了对该领域发展的统一视角，并概述了未来的关键方向，如更好的提示设计、跨模态迁移学习和实际应用适应性。&lt;h4&gt;翻译&lt;/h4&gt;Person re-identification (ReID) has evolved from handcrafted feature-based methods to deep learning approaches and, more recently, to models incorporating large language models (LLMs). Early methods struggled with variations in lighting, pose, and viewpoint, but deep learning addressed these issues by learning robust visual features. Building on this, LLMs now enable ReID systems to integrate semantic and contextual information through natural language. This survey traces that full evolution and offers one of the first comprehensive reviews of ReID approaches that leverage LLMs, where textual descriptions are used as privileged information to improve visual matching. A key contribution is the use of dynamic, identity-specific prompts generated by GPT-4o, which enhance the alignment between images and text in vision-language ReID systems. Experimental results show that these descriptions improve accuracy, especially in complex or ambiguous cases. To support further research, we release a large set of GPT-4o-generated descriptions for standard ReID datasets. By bridging computer vision and natural language processing, this survey offers a unified perspective on the field's development and outlines key future directions such as better prompt design, cross-modal transfer learning, and real-world adaptability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Person re-identification (ReID) has evolved from handcrafted feature-basedmethods to deep learning approaches and, more recently, to models incorporatinglarge language models (LLMs). Early methods struggled with variations inlighting, pose, and viewpoint, but deep learning addressed these issues bylearning robust visual features. Building on this, LLMs now enable ReID systemsto integrate semantic and contextual information through natural language. Thissurvey traces that full evolution and offers one of the first comprehensivereviews of ReID approaches that leverage LLMs, where textual descriptions areused as privileged information to improve visual matching. A key contributionis the use of dynamic, identity-specific prompts generated by GPT-4o, whichenhance the alignment between images and text in vision-language ReID systems.Experimental results show that these descriptions improve accuracy, especiallyin complex or ambiguous cases. To support further research, we release a largeset of GPT-4o-generated descriptions for standard ReID datasets. By bridgingcomputer vision and natural language processing, this survey offers a unifiedperspective on the field's development and outlines key future directions suchas better prompt design, cross-modal transfer learning, and real-worldadaptability.</description>
      <author>example@mail.com (Amran Bhuiyan, Mizanur Rahman, Md Tahmid Rahman Laskar, Aijun An, Jimmy Xiangji Huang)</author>
      <guid isPermaLink="false">2506.13039v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>SeqPE: Transformer with Sequential Position Encoding</title>
      <link>http://arxiv.org/abs/2506.13277v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SeqPE的统一可学习位置编码框架，该框架能够提高位置编码的可扩展性和适应性，并在多种任务中表现出色。&lt;h4&gt;背景&lt;/h4&gt;Transformer中的自注意力层设计为置换不变，需要通过位置编码实现空间理解。传统位置编码方法存在预训练序列长度外的外推能力限制。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种统一且完全可学习的位置编码框架，以提高位置编码的适应性和可扩展性，并在多个任务中取得良好效果。&lt;h4&gt;方法&lt;/h4&gt;SeqPE使用符号序列表示每个n维位置索引，并使用轻量级顺序位置编码器来端到端学习其嵌入。为了规范化嵌入空间，引入了对比目标函数和知识蒸馏损失，以增强外推性能。&lt;h4&gt;主要发现&lt;/h4&gt;SeqPE在语言模型、长上下文问答和2D图像分类等任务中均优于基线，且无需手动架构重设计即可实现多维度输入的平滑泛化。&lt;h4&gt;结论&lt;/h4&gt;SeqPE是一种有效且具有广泛应用前景的位置编码框架，能够提高位置编码的适应性和可扩展性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于Transformer中的自注意力层天生具有置换不变性，因此必须显式地结合位置编码以实现空间理解。然而，传统可学习位置嵌入（PE）中使用的固定大小查找表限制了预训练序列长度之外的外推能力。像ALiBi和RoPE这样的专家设计方法可以缓解这一限制，但需要大量修改以适应新模态，这强调了适应性和可扩展性方面的基本挑战。在本工作中，我们提出了一种名为SeqPE的统一且完全可学习的位置编码框架，该框架将每个n维位置索引表示为一个符号序列，并使用轻量级顺序位置编码器以端到端的方式学习它们的嵌入。为了规范化SeqPE的嵌入空间，我们引入了两个互补的目标：一个对比目标，该目标将嵌入距离与预定义的位置-距离函数对齐，以及一个知识蒸馏损失，该损失将分布外的位置嵌入锚定到分布内的教师表示，从而进一步增强外推性能。在语言建模、长上下文问答和2D图像分类上的实验表明，SeqPE不仅在对数概率、精确匹配（EM）和准确性方面超过了强大的基线，特别是在上下文长度外推方面，而且还能够在无需手动架构重设计的情况下无缝泛化到多维输入。我们将在https://github.com/ghrua/seqpe上发布我们的代码、数据和检查点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Since self-attention layers in Transformers are permutation invariant bydesign, positional encodings must be explicitly incorporated to enable spatialunderstanding. However, fixed-size lookup tables used in traditional learnableposition embeddings (PEs) limit extrapolation capabilities beyond pre-trainedsequence lengths. Expert-designed methods such as ALiBi and RoPE, mitigate thislimitation but demand extensive modifications for adapting to new modalities,underscoring fundamental challenges in adaptability and scalability. In thiswork, we present SeqPE, a unified and fully learnable position encodingframework that represents each $n$-dimensional position index as a symbolicsequence and employs a lightweight sequential position encoder to learn theirembeddings in an end-to-end manner. To regularize SeqPE's embedding space, weintroduce two complementary objectives: a contrastive objective that alignsembedding distances with a predefined position-distance function, and aknowledge distillation loss that anchors out-of-distribution positionembeddings to in-distribution teacher representations, further enhancingextrapolation performance. Experiments across language modeling, long-contextquestion answering, and 2D image classification demonstrate that SeqPE not onlysurpasses strong baselines in perplexity, exact match (EM), andaccuracy--particularly under context length extrapolation--but also enablesseamless generalization to multi-dimensional inputs without requiring manualarchitectural redesign. We release our code, data, and checkpoints athttps://github.com/ghrua/seqpe.</description>
      <author>example@mail.com (Huyang Li, Yahui Liu, Hongyu Sun, Deng Cai, Leyang Cui, Wei Bi, Peilin Zhao, Taro Watanabe)</author>
      <guid isPermaLink="false">2506.13277v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>SASep: Saliency-Aware Structured Separation of Geometry and Feature for Open Set Learning on Point Clouds</title>
      <link>http://arxiv.org/abs/2506.13224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SASep模型通过改进几何和特征表示，提高了模型区分已知和未知类别的能力，在3D开放集识别任务中取得了优于现有方法的性能。&lt;h4&gt;背景&lt;/h4&gt;深度学习在3D物体识别方面取得了显著进展，但大多数模型仅限于封闭集场景，无法处理现实世界中的未知样本。&lt;h4&gt;目的&lt;/h4&gt;提出Salience-Aware Structured Separation (SASep)方法，解决开放集识别（OSR）中现有方法依赖于全局特征且忽略物体不同部分语义重要性的问题。&lt;h4&gt;方法&lt;/h4&gt;SASep包括（i）可调语义分解（TSD）模块，将物体分解为重要和不重要部分；（ii）几何合成策略（GSS），通过组合不重要的部分生成伪未知物体；（iii）合成辅助边缘分离（SMS）模块，通过扩展类别之间的特征分布来增强特征级分离。&lt;h4&gt;主要发现&lt;/h4&gt;SASep在3D开放集识别任务中表现出色，优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;SASep通过改进几何和特征表示，有效地提高了模型区分已知和未知类别的能力。&lt;h4&gt;翻译&lt;/h4&gt;Recent advancements in deep learning have greatly enhanced 3D object recognition, but most models are limited to closed-set scenarios, unable to handle unknown samples in real-world applications. Open-set recognition (OSR) addresses this limitation by enabling models to both classify known classes and identify novel classes. However, current OSR methods rely on global features to differentiate known and unknown classes, treating the entire object uniformly and overlooking the varying semantic importance of its different parts. To address this gap, we propose Salience-Aware Structured Separation (SASep), which includes (i) a tunable semantic decomposition (TSD) module to semantically decompose objects into important and unimportant parts, (ii) a geometric synthesis strategy (GSS) to generate pseudo-unknown objects by combining these unimportant parts, and (iii) a synth-aided margin separation (SMS) module to enhance feature-level separation by expanding the feature distributions between classes. Together, these components improve both geometric and feature representations, enhancing the model's ability to effectively distinguish known and unknown classes. Experimental results show that SASep achieves superior performance in 3D OSR, outperforming existing state-of-the-art methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in deep learning have greatly enhanced 3D objectrecognition, but most models are limited to closed-set scenarios, unable tohandle unknown samples in real-world applications. Open-set recognition (OSR)addresses this limitation by enabling models to both classify known classes andidentify novel classes. However, current OSR methods rely on global features todifferentiate known and unknown classes, treating the entire object uniformlyand overlooking the varying semantic importance of its different parts. Toaddress this gap, we propose Salience-Aware Structured Separation (SASep),which includes (i) a tunable semantic decomposition (TSD) module tosemantically decompose objects into important and unimportant parts, (ii) ageometric synthesis strategy (GSS) to generate pseudo-unknown objects bycombining these unimportant parts, and (iii) a synth-aided margin separation(SMS) module to enhance feature-level separation by expanding the featuredistributions between classes. Together, these components improve bothgeometric and feature representations, enhancing the model's ability toeffectively distinguish known and unknown classes. Experimental results showthat SASep achieves superior performance in 3D OSR, outperforming existingstate-of-the-art methods.</description>
      <author>example@mail.com (Jinfeng Xu, Xianzhi Li, Yuan Tang, Xu Han, Qiao Yu, Yixue Hao, Long Hu, Min Chen)</author>
      <guid isPermaLink="false">2506.13224v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Imitation Learning for Contact-Rich Tasks in Robotics</title>
      <link>http://arxiv.org/abs/2506.13498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  47pages, 1 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文全面概述了针对接触密集型机器人任务的模仿学习研究趋势。&lt;h4&gt;背景&lt;/h4&gt;接触密集型任务，需要与环境的复杂物理交互，由于它们的非线性动力学和对微小位置偏差的敏感性，是机器人领域的一个核心挑战。&lt;h4&gt;目的&lt;/h4&gt;本文探讨了示范收集方法，包括教学方法和感官模态，这些对于捕捉微妙的交互动力学至关重要。&lt;h4&gt;方法&lt;/h4&gt;本文分析了模仿学习的方法，并突出了它们在接触密集型操作中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;多模态学习和基础模型在复杂接触任务方面的近期进展，已显著提高了工业、家庭和医疗保健领域的性能。&lt;h4&gt;结论&lt;/h4&gt;通过对当前研究的系统组织和挑战的识别，本调查为接触密集型机器人操作的未来进步提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;本文对接触密集型机器人任务的模仿学习研究趋势进行了全面调查。接触密集型任务，需要与环境的复杂物理交互，由于它们的非线性动力学和对微小位置偏差的敏感性，是机器人领域的一个核心挑战。本文探讨了示范收集方法，包括教学方法和感官模态，这些对于捕捉微妙的交互动力学至关重要。本文分析了模仿学习的方法，并突出了它们在接触密集型操作中的应用。多模态学习和基础模型在复杂接触任务方面的近期进展，已显著提高了工业、家庭和医疗保健领域的性能。通过对当前研究的系统组织和挑战的识别，本调查为接触密集型机器人操作的未来进步提供了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper comprehensively surveys research trends in imitation learning forcontact-rich robotic tasks. Contact-rich tasks, which require complex physicalinteractions with the environment, represent a central challenge in roboticsdue to their nonlinear dynamics and sensitivity to small positional deviations.The paper examines demonstration collection methodologies, including teachingmethods and sensory modalities crucial for capturing subtle interactiondynamics. We then analyze imitation learning approaches, highlighting theirapplications to contact-rich manipulation. Recent advances in multimodallearning and foundation models have significantly enhanced performance incomplex contact tasks across industrial, household, and healthcare domains.Through systematic organization of current research and identification ofchallenges, this survey provides a foundation for future advancements incontact-rich robotic manipulation.</description>
      <author>example@mail.com (Toshiaki Tsuji, Yasuhiro Kato, Gokhan Solak, Heng Zhang, Tadej Petrič, Francesco Nori, Arash Ajoudani)</author>
      <guid isPermaLink="false">2506.13498v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>C-TLSAN: Content-Enhanced Time-Aware Long- and Short-Term Attention Network for Personalized Recommendation</title>
      <link>http://arxiv.org/abs/2506.13021v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为C-TLSAN的推荐系统，它通过结合深度神经网络和注意力机制来捕捉用户历史交互中的模式，以模拟用户不断变化的偏好。&lt;h4&gt;背景&lt;/h4&gt;序贯推荐系统旨在通过捕捉用户历史交互中的模式来模拟用户不断变化的偏好，最近的研究利用深度神经网络和注意力机制来有效表示序列行为和时间敏感的兴趣。&lt;h4&gt;目的&lt;/h4&gt;提出C-TLSAN，以联合建模用户的长短期偏好，并整合与物品相关的语义内容，如产品描述。&lt;h4&gt;方法&lt;/h4&gt;C-TLSAN通过将链接到用户历史交互的文本内容直接嵌入到长短期注意力层中，丰富了推荐流程。通过融合序列信号和文本语义，该方法提高了推荐系统的表达性和个性化能力。&lt;h4&gt;主要发现&lt;/h4&gt;在大型亚马逊数据集上进行的实验表明，C-TLSAN在下一项预测任务中优于最先进的基线模型。它在AUC、Recall@10和Precision@10上平均提高了1.66%、93.99%和94.80%。&lt;h4&gt;结论&lt;/h4&gt;这些结果突出了将内容感知增强整合到时间建模框架中对序贯推荐的价值。&lt;h4&gt;翻译&lt;/h4&gt;Sequential recommender systems aim to model users' evolving preferences by capturing patterns in their historical interactions. Recent advances in this area have leveraged deep neural networks and attention mechanisms to effectively represent sequential behaviors and time-sensitive interests. In this work, we propose C-TLSAN (Content-Enhanced Time-Aware Long- and Short-Term Attention Network), an extension of the TLSAN architecture that jointly models long- and short-term user preferences while incorporating semantic content associated with items, such as product descriptions. C-TLSAN enriches the recommendation pipeline by embedding textual content linked to users' historical interactions directly into both long-term and short-term attention layers. This allows the model to learn from both behavioral patterns and rich item content, enhancing user and item representations across temporal dimensions. By fusing sequential signals with textual semantics, our approach improves the expressiveness and personalization capacity of recommendation systems. We conduct extensive experiments on large-scale Amazon datasets, benchmarking C-TLSAN against state-of-the-art baselines, including recent sequential recommenders based on Large Language Models (LLMs), which represent interaction history and predictions in text form. Empirical results demonstrate that C-TLSAN consistently outperforms strong baselines in next-item prediction tasks. Notably, it improves AUC by 1.66%, Recall@10 by 93.99%, and Precision@10 by 94.80% on average over the best-performing baseline (TLSAN) across 10 Amazon product categories. These results highlight the value of integrating content-aware enhancements into temporal modeling frameworks for sequential recommendation. Our code is available at https://github.com/booml247/cTLSAN.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential recommender systems aim to model users' evolving preferences bycapturing patterns in their historical interactions. Recent advances in thisarea have leveraged deep neural networks and attention mechanisms toeffectively represent sequential behaviors and time-sensitive interests. Inthis work, we propose C-TLSAN (Content-Enhanced Time-Aware Long- and Short-TermAttention Network), an extension of the TLSAN architecture that jointly modelslong- and short-term user preferences while incorporating semantic contentassociated with items, such as product descriptions.  C-TLSAN enriches the recommendation pipeline by embedding textual contentlinked to users' historical interactions directly into both long-term andshort-term attention layers. This allows the model to learn from bothbehavioral patterns and rich item content, enhancing user and itemrepresentations across temporal dimensions. By fusing sequential signals withtextual semantics, our approach improves the expressiveness and personalizationcapacity of recommendation systems.  We conduct extensive experiments on large-scale Amazon datasets, benchmarkingC-TLSAN against state-of-the-art baselines, including recent sequentialrecommenders based on Large Language Models (LLMs), which represent interactionhistory and predictions in text form. Empirical results demonstrate thatC-TLSAN consistently outperforms strong baselines in next-item predictiontasks. Notably, it improves AUC by 1.66%, Recall@10 by 93.99%, and Precision@10by 94.80% on average over the best-performing baseline (TLSAN) across 10 Amazonproduct categories. These results highlight the value of integratingcontent-aware enhancements into temporal modeling frameworks for sequentialrecommendation. Our code is available at https://github.com/booml247/cTLSAN.</description>
      <author>example@mail.com (Siqi Liang, Yudi Zhang, Yubo Wang)</author>
      <guid isPermaLink="false">2506.13021v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>TR2M: Transferring Monocular Relative Depth to Metric Depth with Language Descriptions and Scale-Oriented Contrast</title>
      <link>http://arxiv.org/abs/2506.13387v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通用的框架，将相对深度转换为度量深度，以解决相对深度估计的尺度不确定性问题。&lt;h4&gt;背景&lt;/h4&gt;当前的单目深度估计方法主要分为度量深度估计（MMDE）和相对深度估计（MRDE）。MMDE在度量尺度上估计深度，但通常局限于特定领域；MRDE在不同领域具有很好的泛化能力，但尺度不确定，阻碍了下游应用。&lt;h4&gt;目的&lt;/h4&gt;构建一个框架来解决尺度不确定性，将相对深度转换为度量深度。&lt;h4&gt;方法&lt;/h4&gt;提出的TR2M框架利用文本描述和图像作为输入，估计两个重缩放图，在像素级别将相对深度转换为度量深度。通过跨模态注意力模块融合两种模态的特征，以更好地捕捉尺度信息。设计了一种策略来构建和过滤自信的伪度量深度，以实现更全面的监督。同时，开发了以尺度为导向的对比学习方法，利用深度分布作为指导，强制模型学习与尺度分布相一致的内禀知识。&lt;h4&gt;主要发现&lt;/h4&gt;TR2M在可见数据集上表现出色，同时在五个未见数据集上也展示了优异的零样本能力。&lt;h4&gt;结论&lt;/h4&gt;TR2M展示了在语言辅助下，在像素级别将相对深度转换为度量深度的大量潜力。&lt;h4&gt;翻译&lt;/h4&gt;这项工作提出了一种通用的框架，用于将相对深度转换为度量深度。当前的单目深度估计方法主要分为度量深度估计（MMDE）和相对深度估计（MRDE）。MMDE在度量尺度上估计深度，但通常局限于特定领域。MRDE在不同领域具有很好的泛化能力，但尺度不确定，阻碍了下游应用。为此，我们旨在构建一个框架来解决尺度不确定性，将相对深度转换为度量深度。先前的方法使用语言作为输入，估计两个因素进行重缩放。我们的方法，TR2M，利用文本描述和图像作为输入，并估计两个重缩放图，在像素级别将相对深度转换为度量深度。通过跨模态注意力模块融合两种模态的特征，以更好地捕捉尺度信息。设计了一种策略来构建和过滤自信的伪度量深度，以实现更全面的监督。我们还开发了以尺度为导向的对比学习方法，利用深度分布作为指导，强制模型学习与尺度分布相一致的内禀知识。TR2M只利用少量可训练参数在各种领域的数据集上进行训练，实验不仅证明了TR2M在可见数据集上的出色性能，还揭示了在五个未见数据集上的优异零样本能力。我们展示了在语言辅助下，在像素级别将相对深度转换为度量深度的大量潜力。（代码可在：https://github.com/BeileiCui/TR2M 获取）&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents a generalizable framework to transfer relative depth tometric depth. Current monocular depth estimation methods are mainly dividedinto metric depth estimation (MMDE) and relative depth estimation (MRDE). MMDEsestimate depth in metric scale but are often limited to a specific domain.MRDEs generalize well across different domains, but with uncertain scales whichhinders downstream applications. To this end, we aim to build up a framework tosolve scale uncertainty and transfer relative depth to metric depth. Previousmethods used language as input and estimated two factors for conductingrescaling. Our approach, TR2M, utilizes both text description and image asinputs and estimates two rescale maps to transfer relative depth to metricdepth at pixel level. Features from two modalities are fused with across-modality attention module to better capture scale information. A strategyis designed to construct and filter confident pseudo metric depth for morecomprehensive supervision. We also develop scale-oriented contrastive learningto utilize depth distribution as guidance to enforce the model learning aboutintrinsic knowledge aligning with the scale distribution. TR2M only exploits asmall number of trainable parameters to train on datasets in various domainsand experiments not only demonstrate TR2M's great performance in seen datasetsbut also reveal superior zero-shot capabilities on five unseen datasets. Weshow the huge potential in pixel-wise transferring relative depth to metricdepth with language assistance. (Code is available at:https://github.com/BeileiCui/TR2M)</description>
      <author>example@mail.com (Beilei Cui, Yiming Huang, Long Bai, Hongliang Ren)</author>
      <guid isPermaLink="false">2506.13387v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Navigating the Black Box: Leveraging LLMs for Effective Text-Level Graph Injection Attacks</title>
      <link>http://arxiv.org/abs/2506.13276v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ATAG-LLM的新型黑盒图注入攻击（GIA）框架，适用于文本归因图（TAGs）。该框架利用大型语言模型（LLMs）生成可解释的文本节点属性，以实现有效的攻击。&lt;h4&gt;背景&lt;/h4&gt;文本归因图（TAGs）将文本数据与图结构结合，在社交网络分析和推荐系统中具有应用价值。图神经网络（GNNs）能够有效捕捉TAGs中的拓扑结构和文本信息，但易受对抗攻击影响。&lt;h4&gt;目的&lt;/h4&gt;设计一种针对TAGs的黑盒GIA框架，以生成可解释的文本节点属性，降低攻击成本，并在黑盒设置中有效攻击。&lt;h4&gt;方法&lt;/h4&gt;利用LLMs生成可解释的文本节点属性，设计LLM提示策略以平衡探索和可靠性，提出相似性评估方法以评估攻击文本在破坏图同质性方面的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;ATAG-LLM在真实世界TAG数据集上的实验表明，其性能优于现有的嵌入层和文本层攻击方法。&lt;h4&gt;结论&lt;/h4&gt;ATAG-LLM是一种有效的黑盒GIA框架，能够降低攻击成本，并在严格黑盒设置中实现文本级图注入攻击，为TAGs的安全研究提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel black-box GIA framework named ATAG-LLM, tailored for Text-attributed graphs (TAGs). The framework leverages large language models (LLMs) to generate interpretable text-level node attributes, ensuring effective attacks with reduced costs. The paper designs LLM prompting strategies that balance exploration and reliability, and proposes a similarity assessment method to evaluate the effectiveness of attack text in disrupting graph homophily. Experiments on real-world TAG datasets demonstrate the superior performance of ATAG-LLM compared to state-of-the-art embedding-level and text-level attack methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-attributed graphs (TAGs) integrate textual data with graph structures,providing valuable insights in applications such as social network analysis andrecommendation systems. Graph Neural Networks (GNNs) effectively capture bothtopological structure and textual information in TAGs but are vulnerable toadversarial attacks. Existing graph injection attack (GIA) methods assume thatattackers can directly manipulate the embedding layer, producingnon-explainable node embeddings. Furthermore, the effectiveness of theseattacks often relies on surrogate models with high training costs. Thus, thispaper introduces ATAG-LLM, a novel black-box GIA framework tailored for TAGs.Our approach leverages large language models (LLMs) to generate interpretabletext-level node attributes directly, ensuring attacks remain feasible inreal-world scenarios. We design strategies for LLM prompting that balanceexploration and reliability to guide text generation, and propose a similarityassessment method to evaluate attack text effectiveness in disrupting graphhomophily. This method efficiently perturbs the target node with minimaltraining costs in a strict black-box setting, ensuring a text-level graphinjection attack for TAGs. Experiments on real-world TAG datasets validate thesuperior performance of ATAG-LLM compared to state-of-the-art embedding-leveland text-level attack methods.</description>
      <author>example@mail.com (Yuefei Lyu, Chaozhuo Li, Xi Zhang, Tianle Zhang)</author>
      <guid isPermaLink="false">2506.13276v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>PRO: Projection Domain Synthesis for CT Imaging</title>
      <link>http://arxiv.org/abs/2506.13443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PRO的新型框架，用于CT图像的合成，该框架利用潜在扩散模型在投影域中进行CT图像合成，具有数据生成和下游任务应用的能力。&lt;h4&gt;背景&lt;/h4&gt;由于标注数据有限和CT成像的复杂性，合成高质量的CT图像仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出PRO框架，以解决CT图像合成的问题，并提高其在多种下游任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;PRO框架通过学习原始投影数据中的丰富结构表示，并利用解剖文本提示进行可控合成，从而在投影域中进行CT图像合成。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，使用PRO合成的数据显著提高了多个下游任务的性能，包括低剂量和稀疏视图重建，即使在有限的训练数据下也是如此。&lt;h4&gt;结论&lt;/h4&gt;PRO框架在数据生成和多种CT应用中具有多功能性和可扩展性，投影域合成在数据增强和稳健的CT成像中具有潜力。&lt;h4&gt;翻译&lt;/h4&gt;Synthesizing high quality CT images remains a significant challenge due to the limited availability of annotated data and the complex nature of CT imaging. In this work, we present PRO, a novel framework that, to the best of our knowledge, is the first to perform CT image synthesis in the projection domain using latent diffusion models. Unlike previous approaches that operate in the image domain, PRO learns rich structural representations from raw projection data and leverages anatomical text prompts for controllable synthesis. This projection domain strategy enables more faithful modeling of underlying imaging physics and anatomical structures. Moreover, PRO functions as a foundation model, capable of generalizing across diverse downstream tasks by adjusting its generative behavior via prompt inputs. Experimental results demonstrated that incorporating our synthesized data significantly improves performance across multiple downstream tasks, including low-dose and sparse-view reconstruction, even with limited training data. These findings underscore the versatility and scalability of PRO in data generation for various CT applications. These results highlight the potential of projection domain synthesis as a powerful tool for data augmentation and robust CT imaging. Our source code is publicly available at: https://github.com/yqx7150/PRO.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Synthesizing high quality CT images remains a signifi-cant challenge due tothe limited availability of annotat-ed data and the complex nature of CTimaging. In this work, we present PRO, a novel framework that, to the best ofour knowledge, is the first to perform CT image synthesis in the projectiondomain using latent diffusion models. Unlike previous approaches that operatein the image domain, PRO learns rich structural representa-tions from rawprojection data and leverages anatomi-cal text prompts for controllablesynthesis. This projec-tion domain strategy enables more faithful modeling ofunderlying imaging physics and anatomical structures. Moreover, PRO functionsas a foundation model, capa-ble of generalizing across diverse downstream tasksby adjusting its generative behavior via prompt inputs. Experimental resultsdemonstrated that incorporating our synthesized data significantly improvesperfor-mance across multiple downstream tasks, including low-dose andsparse-view reconstruction, even with limited training data. These findingsunderscore the versatility and scalability of PRO in data generation forvarious CT applications. These results highlight the potential of projectiondomain synthesis as a powerful tool for data augmentation and robust CTimaging. Our source code is publicly available at:https://github.com/yqx7150/PRO.</description>
      <author>example@mail.com (Kang Chen, Bin Huang, Xuebin Yang, Junyan Zhang, Qiegen Liu)</author>
      <guid isPermaLink="false">2506.13443v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging MIMIC Datasets for Better Digital Health: A Review on Open Problems, Progress Highlights, and Future Promises</title>
      <link>http://arxiv.org/abs/2506.12808v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对MIMIC数据集在数字健康研究中的作用进行了综述，指出了数据整合、表示和互操作性方面的挑战，并提出了改进方向。&lt;h4&gt;背景&lt;/h4&gt;MIMIC数据集提供了大量重症监护记录，是数字健康研究的关键资源。&lt;h4&gt;目的&lt;/h4&gt;调查MIMIC数据集在机器学习模型中的使用，并识别开放性问题。&lt;h4&gt;方法&lt;/h4&gt;进行文献综述，识别数据集使用中的问题和进展。&lt;h4&gt;主要发现&lt;/h4&gt;发现数据粒度、基数限制、异构编码方案和伦理约束等问题阻碍了模型的泛化能力和实时应用。&lt;h4&gt;结论&lt;/h4&gt;提出通过混合建模、联邦学习和标准化预处理流程等方向来改进。&lt;h4&gt;翻译&lt;/h4&gt;The Medical Information Mart for Intensive Care (MIMIC) 数据集已成为数字健康研究的核心，通过提供数万次重症监护入院的免费、脱敏记录，促进了临床决策支持、结果预测和医疗保健分析等领域的广泛应用。尽管许多研究和调查已经探讨了基于MIMIC模型的预测能力和临床效用，但在数据整合、表示和互操作性方面的关键挑战仍然未被充分探索。本文提出了一项全面调查，特别关注开放性问题。我们确定了如数据粒度、基数限制、异构编码方案和伦理约束等持续存在的问题，这些问题阻碍了机器学习模型的泛化能力和实时实施。我们强调了降维、时序建模、因果推断和隐私保护分析的关键进展，同时概述了包括混合建模、联邦学习和标准化预处理流程在内的有希望的方向。通过批判性地审查这些结构限制及其影响，本调查为指导下一代由MIMIC驱动的数字健康创新提供了可操作的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Medical Information Mart for Intensive Care (MIMIC) datasets have becomethe Kernel of Digital Health Research by providing freely accessible,deidentified records from tens of thousands of critical care admissions,enabling a broad spectrum of applications in clinical decision support, outcomeprediction, and healthcare analytics. Although numerous studies and surveyshave explored the predictive power and clinical utility of MIMIC based models,critical challenges in data integration, representation, and interoperabilityremain underexplored. This paper presents a comprehensive survey that focusesuniquely on open problems. We identify persistent issues such as datagranularity, cardinality limitations, heterogeneous coding schemes, and ethicalconstraints that hinder the generalizability and real-time implementation ofmachine learning models. We highlight key progress in dimensionality reduction,temporal modelling, causal inference, and privacy preserving analytics, whilealso outlining promising directions including hybrid modelling, federatedlearning, and standardized preprocessing pipelines. By critically examiningthese structural limitations and their implications, this survey offersactionable insights to guide the next generation of MIMIC powered digitalhealth innovations.</description>
      <author>example@mail.com (Afifa Khaled, Mohammed Sabir, Rizwan Qureshi, Camillo Maria Caruso, Valerio Guarrasi, Suncheng Xiang, S Kevin Zhou)</author>
      <guid isPermaLink="false">2506.12808v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>PhenoKG: Knowledge Graph-Driven Gene Discovery and Patient Insights from Phenotypes Alone</title>
      <link>http://arxiv.org/abs/2506.13119v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图的新方法，通过整合罕见病知识图谱，预测患者表型中的致病基因，无论是否有候选基因列表，该方法在预测准确性上取得了显著提升。&lt;h4&gt;背景&lt;/h4&gt;从患者表型中识别致病基因是精准医学中的一个重大挑战，对遗传疾病的诊断和治疗具有重要意义。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，从患者表型中预测致病基因，无论是否有候选基因列表。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了图神经网络和Transformer，并整合了罕见病知识图谱。&lt;h4&gt;主要发现&lt;/h4&gt;在MyGene2数据集上，该方法实现了24.64%的平均倒数排名（MRR）和33.64%的nDCG@100，超过了最佳基线（SHEPHERD）的19.02% MRR和30.54% nDCG@100。通过消融实验验证了模型各个组件的贡献。该方法也适用于仅提供表型数据的情况，解决了基因组信息不完整时的临床决策支持难题。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在预测致病基因方面表现出色，并具有广泛的适用性，为遗传疾病的诊断和治疗提供了新的工具。&lt;h4&gt;翻译&lt;/h4&gt;Identifying causative genes from patient phenotypes remains a significant challenge in precision medicine, with important implications for the diagnosis and treatment of genetic disorders. We propose a novel graph-based approach for predicting causative genes from patient phenotypes, with or without an available list of candidate genes, by integrating a rare disease knowledge graph (KG). Our model, combining graph neural networks and transformers, achieves substantial improvements over the current state-of-the-art. On the real-world MyGene2 dataset, it attains a mean reciprocal rank (MRR) of 24.64% and nDCG@100 of 33.64%, surpassing the best baseline (SHEPHERD) at 19.02% MRR and 30.54% nDCG@100. We perform extensive ablation studies to validate the contribution of each model component. Notably, the approach generalizes to cases where only phenotypic data are available, addressing key challenges in clinical decision support when genomic information is incomplete.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Identifying causative genes from patient phenotypes remains a significantchallenge in precision medicine, with important implications for the diagnosisand treatment of genetic disorders. We propose a novel graph-based approach forpredicting causative genes from patient phenotypes, with or without anavailable list of candidate genes, by integrating a rare disease knowledgegraph (KG). Our model, combining graph neural networks and transformers,achieves substantial improvements over the current state-of-the-art. On thereal-world MyGene2 dataset, it attains a mean reciprocal rank (MRR) of 24.64\%and nDCG@100 of 33.64\%, surpassing the best baseline (SHEPHERD) at 19.02\% MRRand 30.54\% nDCG@100. We perform extensive ablation studies to validate thecontribution of each model component. Notably, the approach generalizes tocases where only phenotypic data are available, addressing key challenges inclinical decision support when genomic information is incomplete.</description>
      <author>example@mail.com (Kamilia Zaripova, Ege Özsoy, Nassir Navab, Azade Farshad)</author>
      <guid isPermaLink="false">2506.13119v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty-Aware Remaining Lifespan Prediction from Images</title>
      <link>http://arxiv.org/abs/2506.13430v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IMPACT 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种利用预训练视觉Transformer基础模型从面部和全身图像中估计剩余寿命的方法，并实现了鲁棒的不确定性量化。&lt;h4&gt;背景&lt;/h4&gt;从图像预测与死亡率相关的结果具有易于访问、非侵入性和可扩展的健康筛查的潜力。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，利用预训练的视觉Transformer模型估计人的剩余寿命，并量化预测的不确定性。&lt;h4&gt;方法&lt;/h4&gt;该方法通过学习每个样本的高斯分布来有效地模拟预测不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在已建立的Dataset上实现了7.48年的最佳平均绝对误差（MAE），在两个新 curated and published 的更高质量数据集上进一步提高了MAE，分别为4.79年和5.07年。&lt;h4&gt;结论&lt;/h4&gt;虽然该方法不打算用于临床部署，但结果表明从图像中提取与医学相关的信号具有潜力，并且模型提供了良好的不确定性估计。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从图像预测与死亡率相关的结果提供了易于访问、非侵入性和可扩展的健康筛查的前景。我们提出了一种方法，该方法利用预训练的视觉Transformer基础模型从面部和全身图像中估计剩余寿命，并实现了鲁棒的不确定性量化。我们表明，预测不确定性系统地随着真实剩余寿命而变化，并且可以通过学习每个样本的高斯分布来有效地模拟这种不确定性。我们的方法在一个已建立的Dataset上实现了7.48年的最佳平均绝对误差（MAE），并在本工作中curated and published的两个新、更高质量的数据集上进一步提高了MAE，分别为4.79年和5.07年MAE。重要的是，我们的模型提供了良好的不确定性估计，如通过桶式预期的校准误差为0.62年所示。虽然这些结果不打算用于临床部署，但它们突出了从图像中提取与医学相关的信号的潜力。我们提供所有代码和数据集，以促进进一步的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting mortality-related outcomes from images offers the prospect ofaccessible, noninvasive, and scalable health screening. We present a methodthat leverages pretrained vision transformer foundation models to estimateremaining lifespan from facial and whole-body images, alongside robustuncertainty quantification. We show that predictive uncertainty variessystematically with the true remaining lifespan, and that this uncertainty canbe effectively modeled by learning a Gaussian distribution for each sample. Ourapproach achieves state-of-the-art mean absolute error (MAE) of 7.48 years onan established Dataset, and further improves to 4.79 and 5.07 years MAE on twonew, higher-quality datasets curated and published in this work. Importantly,our models provide well-calibrated uncertainty estimates, as demonstrated by abucketed expected calibration error of 0.62 years. While not intended forclinical deployment, these results highlight the potential of extractingmedically relevant signals from images. We make all code and datasets availableto facilitate further research.</description>
      <author>example@mail.com (Tristan Kenneweg, Philip Kenneweg, Barbara Hammer)</author>
      <guid isPermaLink="false">2506.13430v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty-Aware Graph Neural Networks: A Multi-Hop Evidence Fusion Approach</title>
      <link>http://arxiv.org/abs/2506.13083v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TNNLS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EFGNN（证据融合图神经网络）的新模型，旨在提高图神经网络在节点分类中的准确性，并通过考虑不确定性来提高预测的可信度。&lt;h4&gt;背景&lt;/h4&gt;现有的图神经网络在处理具有深度变化的概率不确定性时表现不佳，导致预测不可靠。&lt;h4&gt;目的&lt;/h4&gt;实现可靠的预测，提高节点分类的准确性，并明确预测错误的潜在风险。&lt;h4&gt;方法&lt;/h4&gt;EFGNN结合了证据理论和基于多跳传播的GNN架构，以量化每个节点的预测不确定性，并采用参数免费的累积信念融合（CBF）机制来融合证据。此外，设计了联合学习目标，包括证据交叉熵、失调系数和错误自信惩罚。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果和理论分析表明，EFGNN在准确性和可信度方面表现出色，并且对潜在攻击具有鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;EFGNN是一种有效的图神经网络，能够提高节点分类的准确性和预测的可信度。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we propose a novel Evidence Fusing Graph Neural Network (EFGNN for short) to achieve trustworthy prediction, enhance node classification accuracy, and make explicit the risk of wrong predictions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) excel in graph representation learning byintegrating graph structure and node features. Existing GNNs, unfortunately,fail to account for the uncertainty of class probabilities that vary with thedepth of the model, leading to unreliable and risky predictions in real-worldscenarios. To bridge the gap, in this paper, we propose a novel Evidence FusingGraph Neural Network (EFGNN for short) to achieve trustworthy prediction,enhance node classification accuracy, and make explicit the risk of wrongpredictions. In particular, we integrate the evidence theory with multi-hoppropagation-based GNN architecture to quantify the prediction uncertainty ofeach node with the consideration of multiple receptive fields. Moreover, aparameter-free cumulative belief fusion (CBF) mechanism is developed toleverage the changes in prediction uncertainty and fuse the evidence to improvethe trustworthiness of the final prediction. To effectively optimize the EFGNNmodel, we carefully design a joint learning objective composed of evidencecross-entropy, dissonance coefficient, and false confident penalty. Theexperimental results on various datasets and theoretical analyses demonstratethe effectiveness of the proposed model in terms of accuracy andtrustworthiness, as well as its robustness to potential attacks. The sourcecode of EFGNN is available at https://github.com/Shiy-Li/EFGNN.</description>
      <author>example@mail.com (Qingfeng Chen, Shiyuan Li, Yixin Liu, Shirui Pan, Geoffrey I. Webb, Shichao Zhang)</author>
      <guid isPermaLink="false">2506.13083v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Graph Condensation</title>
      <link>http://arxiv.org/abs/2506.13099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了动态图学习，提出了一种名为DyGC的动态图压缩框架，旨在通过减少动态图规模来提高数据效率，同时保持动态图的时间特性。&lt;h4&gt;背景&lt;/h4&gt;现有研究主要关注静态图学习，但动态图学习在处理复杂系统的动态行为时面临数据效率挑战，如数据量增加、时空冗余和高成本。&lt;h4&gt;目的&lt;/h4&gt;提出动态图压缩（DGC）技术，以减少动态图规模，为数据高效的动态图神经网络（DGNN）训练提供解决方案。&lt;h4&gt;方法&lt;/h4&gt;DyGC通过引入新的脉冲结构生成机制，使合成图具有真实的演化结构，并采用定制化的分布匹配方法，构建语义丰富的状态演化场，进行精细的时空状态对齐，以优化压缩图。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，DyGC在多个动态图数据集和代表性的DGNN架构上有效，在仅保留原始图0.5%大小的前提下，保持了高达96.2%的DGNN性能，并实现了高达1846倍的训练速度提升。&lt;h4&gt;结论&lt;/h4&gt;DyGC是一种有效的动态图压缩方法，能够显著提高动态图神经网络的训练效率，同时保持较高的性能水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research on deep graph learning has shifted from static to dynamicgraphs, motivated by the evolving behaviors observed in complex real-worldsystems. However, the temporal extension in dynamic graphs poses significantdata efficiency challenges, including increased data volume, highspatiotemporal redundancy, and reliance on costly dynamic graph neural networks(DGNNs). To alleviate the concerns, we pioneer the study of dynamic graphcondensation (DGC), which aims to substantially reduce the scale of dynamicgraphs for data-efficient DGNN training. Accordingly, we propose DyGC, a novelframework that condenses the real dynamic graph into a compact version whilefaithfully preserving the inherent spatiotemporal characteristics.Specifically, to endow synthetic graphs with realistic evolving structures, anovel spiking structure generation mechanism is introduced. It draws on thedynamic behavior of spiking neurons to model temporally-aware connectivity indynamic graphs. Given the tightly coupled spatiotemporal dependencies, DyGCproposes a tailored distribution matching approach that first constructs asemantically rich state evolving field for dynamic graphs, and then performsfine-grained spatiotemporal state alignment to guide the optimization of thecondensed graph. Experiments across multiple dynamic graph datasets andrepresentative DGNN architectures demonstrate the effectiveness of DyGC.Notably, our method retains up to 96.2% DGNN performance with only 0.5% of theoriginal graph size, and achieves up to 1846 times training speedup.</description>
      <author>example@mail.com (Dong Chen, Shuai Zheng, Yeyu Yan, Muhao Xu, Zhenfeng Zhu, Yao Zhao, Kunlun He)</author>
      <guid isPermaLink="false">2506.13099v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Geometric Embedding Alignment via Curvature Matching in Transfer Learning</title>
      <link>http://arxiv.org/abs/2506.13015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13+19 pages, 7 figures, 8 tables, 1 pseudo code&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用微分几何，特别是黎曼几何的概念，将多个模型集成到一个统一的迁移学习框架中的新方法。&lt;h4&gt;背景&lt;/h4&gt;几何解释深度学习模型有助于深入了解其底层数学结构。&lt;h4&gt;目的&lt;/h4&gt;通过构建一个名为GEAR（基于曲率匹配的迁移学习中的几何嵌入对齐）的相互关联架构，确保数据点之间全面几何表示，从而有效聚合来自不同来源的知识，提高目标任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;通过对齐各个模型潜在空间的Ricci曲率，实现模型的集成。&lt;h4&gt;主要发现&lt;/h4&gt;在来自不同领域的23个分子任务对上评估了模型，与现有的基准模型相比，在随机（14.4%）和骨架（8.3%）数据划分下都取得了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;GEAR框架在迁移学习任务中有效提高了模型性能，为深度学习模型的几何解释提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometrical interpretations of deep learning models offer insightfulperspectives into their underlying mathematical structures. In this work, weintroduce a novel approach that leverages differential geometry, particularlyconcepts from Riemannian geometry, to integrate multiple models into a unifiedtransfer learning framework. By aligning the Ricci curvature of latent space ofindividual models, we construct an interrelated architecture, namely GeometricEmbedding Alignment via cuRvature matching in transfer learning (GEAR), whichensures comprehensive geometric representation across datapoints. Thisframework enables the effective aggregation of knowledge from diverse sources,thereby improving performance on target tasks. We evaluate our model on 23molecular task pairs sourced from various domains and demonstrate significantperformance gains over existing benchmark model under both random (14.4%) andscaffold (8.3%) data splits.</description>
      <author>example@mail.com (Sung Moon Ko, Jaewan Lee, Sumin Lee, Soorin Yim, Kyunghoon Bae, Sehui Han)</author>
      <guid isPermaLink="false">2506.13015v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Mixture of Cognitive Reasoners: Modular Reasoning with Brain-Like Specialization</title>
      <link>http://arxiv.org/abs/2506.13331v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Code, data, and models available at  $\href{https://bkhmsi.github.io/mixture-of-cog-reasoners}{\text{this https  URL.}}$&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为MiCRo的混合认知推理器架构，该架构通过模块化的transformer语言模型和培训范式，模拟人类大脑中不同认知功能网络之间的交互，旨在提高模型的可解释性、性能和控制能力。&lt;h4&gt;背景&lt;/h4&gt;人类智能源于专门的大脑网络之间的交互，这些网络分别负责语言处理、逻辑推理、社会理解和记忆检索等不同的认知功能。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过生物启发的模型设计，提高人工智能模型的可解释性、性能和控制能力。&lt;h4&gt;方法&lt;/h4&gt;论文引入了MiCRo架构，该架构将预训练的transformer模型分为四个专家模块，每个模块对应于一个已知的认知大脑网络。通过培训课程鼓励模块之间出现功能专业化。&lt;h4&gt;主要发现&lt;/h4&gt;MiCRo模型在七个推理基准测试中优于没有专业化的基线模型。模型的专家模块高度可解释且功能关键，移除模块会显著影响特定领域的性能。通过推理时选择性地强调某些专家模块，可以控制模型的响应风格。&lt;h4&gt;结论&lt;/h4&gt;论文结果表明，受人类认知启发的归纳偏差在模型的可解释性、性能和控制能力方面带来了显著的建模收益。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类智能源于专门的大脑网络之间的交互，每个网络都致力于不同的认知功能，如语言处理、逻辑推理、社会理解和记忆检索。受这一生物学观察的启发，我们引入了混合认知推理器（MiCRo）架构和训练范式：一个模块化的基于transformer的语言模型，其培训课程鼓励不同模块之间出现功能专业化。受神经科学研究启发，我们将预训练的transformer模型的层划分为四个专家模块，每个模块对应于一个已研究的认知大脑网络。我们的脑类模型在三个关键方面优于现有技术：首先，专业专家高度可解释且功能关键，移除一个模块会显著损害特定领域基准的性能；其次，我们的模型在七个推理基准测试中优于缺乏专业化的基线；第三，通过推理时选择性地强调某些专家模块（例如，优先考虑社交推理而不是逻辑推理），可以控制其响应的风格。我们的研究结果建议，人类认知中涉及的生物启发的归纳偏差在可解释性、性能和控制能力方面导致了显著的建模收益。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human intelligence emerges from the interaction of specialized brainnetworks, each dedicated to distinct cognitive functions such as languageprocessing, logical reasoning, social understanding, and memory retrieval.Inspired by this biological observation, we introduce the Mixture of CognitiveReasoners (MiCRo) architecture and training paradigm: a modulartransformer-based language model with a training curriculum that encourages theemergence of functional specialization among different modules. Inspired bystudies in neuroscience, we partition the layers of a pretrained transformermodel into four expert modules, each corresponding to a well-studied cognitivebrain network. Our Brain-Like model has three key benefits over the state ofthe art: First, the specialized experts are highly interpretable andfunctionally critical, where removing a module significantly impairsperformance on domain-relevant benchmarks. Second, our model outperformscomparable baselines that lack specialization on seven reasoning benchmarks.And third, the model's behavior can be steered at inference time by selectivelyemphasizing certain expert modules (e.g., favoring social over logicalreasoning), enabling fine-grained control over the style of its response. Ourfindings suggest that biologically inspired inductive biases involved in humancognition lead to significant modeling gains in interpretability, performance,and controllability.</description>
      <author>example@mail.com (Badr AlKhamissi, C. Nicolò De Sabbata, Zeming Chen, Martin Schrimpf, Antoine Bosselut)</author>
      <guid isPermaLink="false">2506.13331v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>DuoFormer: Leveraging Hierarchical Representations by Local and Global Attention Vision Transformer</title>
      <link>http://arxiv.org/abs/2506.12982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的分层Transformer模型，该模型结合了卷积神经网络（CNN）的特征提取能力和视觉Transformer（ViT）的先进表示潜力，以促进医学应用中的多尺度学习。&lt;h4&gt;背景&lt;/h4&gt;尽管Transformer在医学应用中得到了广泛应用，但通过Transformer进行多尺度学习的探索仍然有限。分层表示被认为对计算机辅助医学诊断有益。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的分层Transformer模型，以解决ViT在归纳偏差和依赖大量训练数据集方面的不足。&lt;h4&gt;方法&lt;/h4&gt;模型采用CNN主干来生成分层视觉表示，并通过创新的补丁标记化过程将这些表示适应Transformer输入，保留继承的多尺度归纳偏差。此外，引入了按尺度注意机制，直接捕捉跨尺度和跨层关联。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在分类精度方面显著优于基线模型，证明了其在连接卷积神经网络（CNN）和视觉Transformer（ViT）之间的差距方面的效率。&lt;h4&gt;结论&lt;/h4&gt;该模型的设计可以作为插件，适用于不同的CNN架构，并可以适应多种应用。&lt;h4&gt;翻译&lt;/h4&gt;尽管Transformer在医学应用中得到了广泛应用，但通过Transformer进行多尺度学习的探索仍然有限。分层表示被认为对计算机辅助医学诊断有益。我们提出了一种新的分层Transformer模型，该模型巧妙地结合了卷积神经网络（CNN）的特征提取能力与视觉Transformer（ViT）的先进表示潜力。针对ViT缺乏归纳偏差和依赖大量训练数据集的问题，我们的模型采用CNN主干来生成分层视觉表示。这些表示通过创新的补丁标记化过程适应Transformer输入，保留了继承的多尺度归纳偏差。我们还引入了按尺度注意机制，直接捕捉跨尺度和跨层关联。这一机制通过增强空间理解和保持全局感知来补充补丁注意，我们分别称之为局部注意和全局注意。我们的模型在分类精度方面显著优于基线模型，证明了其在连接卷积神经网络（CNN）和视觉Transformer（ViT）之间的差距方面的效率。组件设计为可插拔，适用于不同的CNN架构，并可适应多种应用。代码可在https://github.com/xiaoyatang/DuoFormer.git上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the widespread adoption of transformers in medical applications, theexploration of multi-scale learning through transformers remains limited, whilehierarchical representations are considered advantageous for computer-aidedmedical diagnosis. We propose a novel hierarchical transformer model thatadeptly integrates the feature extraction capabilities of Convolutional NeuralNetworks (CNNs) with the advanced representational potential of VisionTransformers (ViTs). Addressing the lack of inductive biases and dependence onextensive training datasets in ViTs, our model employs a CNN backbone togenerate hierarchical visual representations. These representations are adaptedfor transformer input through an innovative patch tokenization process,preserving the inherited multi-scale inductive biases. We also introduce ascale-wise attention mechanism that directly captures intra-scale andinter-scale associations. This mechanism complements patch-wise attention byenhancing spatial understanding and preserving global perception, which werefer to as local and global attention, respectively. Our model significantlyoutperforms baseline models in terms of classification accuracy, demonstratingits efficiency in bridging the gap between Convolutional Neural Networks (CNNs)and Vision Transformers (ViTs). The components are designed as plug-and-playfor different CNN architectures and can be adapted for multiple applications.The code is available at https://github.com/xiaoyatang/DuoFormer.git.</description>
      <author>example@mail.com (Xiaoya Tang, Bodong Zhang, Man Minh Ho, Beatrice S. Knudsen, Tolga Tasdizen)</author>
      <guid isPermaLink="false">2506.12982v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Action Dubber: Timing Audible Actions via Inflectional Flow</title>
      <link>http://arxiv.org/abs/2506.13320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了可听动作时空定位任务，旨在识别可听动作的空间和时间坐标。&lt;h4&gt;背景&lt;/h4&gt;传统任务如动作识别和时间动作定位广泛分析视频内容，而本文任务聚焦于可听动作的独特动力学。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于运动二阶导数估计转折流动的方法，用于确定碰撞时间而不依赖音频输入，以提高时间定位准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为$TA^{2}Net$的新型架构，该架构在训练期间集成了一种自监督的空间定位策略，结合对比学习和空间分析。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在$Audible623$数据集上有效，并且对其他领域（如重复计数和声音源定位）具有良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;$TA^{2}Net$架构能够通过空间和时间定位策略，有效地实现可听动作的时空定位。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为可听动作时空定位的任务，旨在识别可听动作的空间和时间坐标。不同于传统任务，本任务专注于可听动作的独特动力学。基于关键动作由转折运动驱动的假设，本文提出了一种名为$TA^{2}Net$的新架构，通过使用运动二阶导数估计转折流动来确定碰撞时间，从而实现时间定位。$TA^{2}Net$在训练期间集成了一种自监督的空间定位策略，结合对比学习和空间分析，以提高时间定位的准确性。实验表明，该方法在$Audible623$数据集上有效，并且对其他领域具有良好的泛化能力。代码和数据集可在https://github.com/WenlongWan/Audible623上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce the task of Audible Action Temporal Localization, which aims toidentify the spatio-temporal coordinates of audible movements. Unlikeconventional tasks such as action recognition and temporal action localization,which broadly analyze video content, our task focuses on the distinct kinematicdynamics of audible actions. It is based on the premise that key actions aredriven by inflectional movements; for example, collisions that produce soundoften involve abrupt changes in motion. To capture this, we propose$TA^{2}Net$, a novel architecture that estimates inflectional flow using thesecond derivative of motion to determine collision timings without relying onaudio input. $TA^{2}Net$ also integrates a self-supervised spatial localizationstrategy during training, combining contrastive learning with spatial analysis.This dual design improves temporal localization accuracy and simultaneouslyidentifies sound sources within video frames. To support this task, weintroduce a new benchmark dataset, $Audible623$, derived from Kinetics andUCF101 by removing non-essential vocalization subsets. Extensive experimentsconfirm the effectiveness of our approach on $Audible623$ and show stronggeneralizability to other domains, such as repetitive counting and sound sourcelocalization. Code and dataset are available athttps://github.com/WenlongWan/Audible623.</description>
      <author>example@mail.com (Wenlong Wan, Weiying Zheng, Tianyi Xiang, Guiqing Li, Shengfeng He)</author>
      <guid isPermaLink="false">2506.13320v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Silhouette-Guided Instance-Weighted k-means</title>
      <link>http://arxiv.org/abs/2506.12878v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages including appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;K-Sil是一种改进的k-means算法，通过加权点的方法来优化聚类结果，特别适用于处理异常值和不平衡数据，并通过理论保证和实证验证展现出比传统k-means算法更好的聚类效果。&lt;h4&gt;背景&lt;/h4&gt;聚类是无监督学习的基础任务，但在处理异常值和不平衡数据时，传统算法如k-means可能会产生扭曲的质心和次优的分区。&lt;h4&gt;目的&lt;/h4&gt;提出K-Sil算法，旨在解决k-means算法在处理异常值和不平衡数据时的不足，实现更高质量的聚类结果。&lt;h4&gt;方法&lt;/h4&gt;K-Sil算法通过加权点的方法，根据点的轮廓分数对点进行加权，优先考虑聚类效果好的实例，同时抑制边界或噪声区域。算法通过自我调整的权重方案，结合适当的采样策略和可扩展近似，强调用户指定的轮廓聚合度量（宏观、微观或两者的组合），以确保计算效率和适应不同数据集的几何形状。&lt;h4&gt;主要发现&lt;/h4&gt;理论保证了质心的收敛，实证验证表明K-Sil在合成数据和真实世界数据集上的轮廓分数显著优于k-means以及两种其他实例加权的k-means变体。&lt;h4&gt;结论&lt;/h4&gt;K-Sil作为高质量、分离良好的聚类结果的原理性替代品，适用于要求高质量聚类的应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：聚类是基础的无监督学习任务，在众多领域有广泛应用。k-means等流行算法在处理异常值或不平衡时常常会遇到困难，导致质心扭曲和分区次优。我们引入了K-Sil，这是一种基于轮廓的k-means算法的改进，根据轮廓分数对点进行加权，优先考虑聚类良好的实例，同时抑制边界或噪声区域。该算法强调用户指定的轮廓聚合度量：宏观、微观或两者的组合，通过自我调整的权重方案，得到适当的采样策略和可扩展近似的支持。这些组件确保了计算效率和对不同数据集几何形状的适应性。理论保证建立了质心的收敛，在合成和真实世界数据集上的实证验证表明，轮廓分数在k-means和其他两种实例加权的k-means变体上具有统计学意义上的显著改进。这些结果确立了K-Sil作为高质量、分离良好的聚类结果的原理性替代品。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Clustering is a fundamental unsupervised learning task with numerousapplications across diverse fields. Popular algorithms such as k-means oftenstruggle with outliers or imbalances, leading to distorted centroids andsuboptimal partitions. We introduce K-Sil, a silhouette-guided refinement ofthe k-means algorithm that weights points based on their silhouette scores,prioritizing well-clustered instances while suppressing borderline or noisyregions. The algorithm emphasizes user-specified silhouette aggregationmetrics: macro-, micro-averaged or a combination, through self-tuning weightingschemes, supported by appropriate sampling strategies and scalableapproximations. These components ensure computational efficiency andadaptability to diverse dataset geometries. Theoretical guarantees establishcentroid convergence, and empirical validation on synthetic and real-worlddatasets demonstrates statistically significant improvements in silhouettescores over k-means and two other instance-weighted k-means variants. Theseresults establish K-Sil as a principled alternative for applications demandinghigh-quality, well-separated clusters.</description>
      <author>example@mail.com (Aggelos Semoglou, Aristidis Likas, John Pavlopoulos)</author>
      <guid isPermaLink="false">2506.12878v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>KCLNet: Physics-Informed Power Flow Prediction via Constraints Projections</title>
      <link>http://arxiv.org/abs/2506.12902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为KCLNet的物理信息图神经网络，用于提高现代电网中电力流预测的准确性和物理一致性。&lt;h4&gt;背景&lt;/h4&gt;现代电力系统中，快速、可扩展且符合物理规律的电力流预测对于确保电网的安全和高效运行至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够快速、准确且符合物理规律地进行电力流预测的方法。&lt;h4&gt;方法&lt;/h4&gt;KCLNet通过将基尔霍夫电流定律作为硬约束，通过超平面投影纳入图神经网络，从而在预测过程中确保物理规律得到遵守。&lt;h4&gt;主要发现&lt;/h4&gt;KCLNet在预测准确性和物理一致性方面取得了竞争优势，同时避免了基尔霍夫电流定律的违反。&lt;h4&gt;结论&lt;/h4&gt;KCLNet能够提供可靠且物理上合理的电力流预测，这对于保障现代智能电网的运行至关重要。&lt;h4&gt;翻译&lt;/h4&gt;在电力系统的现代背景下，快速、可扩展且符合物理规律的电力流预测对于确保电网的安全和高效运行至关重要。虽然传统的数值方法已被证明是稳健的，但它们需要大量的计算来在动态或紧急情况下保持物理保真度。相比之下，人工智能（AI）在最近的发展中显著提高了计算速度；然而，它们通常无法在现实世界的紧急情况下强制执行基本物理定律，导致物理上不可信的预测。在这项工作中，我们引入了KCLNet，这是一种物理信息图神经网络，通过超平面投影将基尔霍夫电流定律作为硬约束纳入。KCLNet在保持零KCL违反的同时达到有竞争力的预测精度，从而提供了可靠且物理上一致的电力流预测，这对于保障现代智能电网的运行至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the modern context of power systems, rapid, scalable, and physicallyplausible power flow predictions are essential for ensuring the grid's safe andefficient operation. While traditional numerical methods have proven robust,they require extensive computation to maintain physical fidelity under dynamicor contingency conditions. In contrast, recent advancements in artificialintelligence (AI) have significantly improved computational speed; however,they often fail to enforce fundamental physical laws during real-worldcontingencies, resulting in physically implausible predictions. In this work,we introduce KCLNet, a physics-informed graph neural network that incorporatesKirchhoff's Current Law as a hard constraint via hyperplane projections. KCLNetattains competitive prediction accuracy while ensuring zero KCL violations,thereby delivering reliable and physically consistent power flow predictionscritical to secure the operation of modern smart grids.</description>
      <author>example@mail.com (Pantelis Dogoulis, Karim Tit, Maxime Cordy)</author>
      <guid isPermaLink="false">2506.12902v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>A Geometric Solution to the Isoperimetric Problem and its Quantitative Inequalities</title>
      <link>http://arxiv.org/abs/2506.12864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过分析n边形面积效率，引入了一种求解经典等周问题的几何解法，并提出了一种新的公式来量化多边形效率。&lt;h4&gt;背景&lt;/h4&gt;等周问题是寻找给定周长条件下，能够围成的最大面积的问题。&lt;h4&gt;目的&lt;/h4&gt;研究多边形的面积效率，并寻找多边形向圆形最优面积-围成效率过渡的规律。&lt;h4&gt;方法&lt;/h4&gt;使用外接圆半径和边长之间的关系，建立了一个新的公式来描述多边形效率，并推导出相对于外接圆的面积损失公式。&lt;h4&gt;主要发现&lt;/h4&gt;随着边数的增加，正多边形趋近于圆的最优面积-围成效率，同时提供了一个从n边形到圆形连续极限的平滑几何过渡。&lt;h4&gt;结论&lt;/h4&gt;该方法通过直接的几何推理提供了对定量等周不等式的新见解，并通过解析推导和数值测试验证了其准确性。&lt;h4&gt;翻译&lt;/h4&gt;本文通过分析n边形的面积效率，通过新颖的边心距-斜边比框架，提出了一种求解经典等周问题的几何解法。导出了一个基于边心距、斜边和周长的新的公式来量化多边形效率，展示了随着边数增加，正多边形如何趋近于圆形的最优面积-围成效率。此外，还提出了一种相对于包围圆的面积损失的原始公式，并建立了一个从n边形到圆形连续极限的平滑几何过渡。这种方法通过直接的几何推理提供了对定量等周不等式的新见解，其准确性通过解析推导和数值测试得到了验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a geometric solution to the classical isoperimetricproblem by analysing the area efficiency of n-sided regular polygons through anovel apothem-hypotenuse ratio framework. A new formula is derived to quantifypolygonal efficiency based on apothem, hypotenuse, and perimeter, demonstratinghow regular polygons approach the optimal area-enclosing efficiency of thecircle as the number of sides increases. The work further presents an originalformula for area lost relative to the enclosing circle and establishes a smoothgeometric transition from n-sided regular polygons to the continuous limit of acircle. This approach provides fresh insight into quantitative isoperimetricinequalities through direct geometric reasoning, with accuracy confirmed byboth analytical derivation and numerical testing.</description>
      <author>example@mail.com (Lakshya Chaudhary)</author>
      <guid isPermaLink="false">2506.12864v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Large Scalable Cross-Domain Graph Neural Networks for Personalized Notification at LinkedIn</title>
      <link>http://arxiv.org/abs/2506.12700v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于跨领域图神经网络（GNN）的通知推荐系统，该系统在LinkedIn平台上被部署，通过整合用户、内容和活动信号，显著提升了点击率（CTR）预测和专业参与度。&lt;h4&gt;背景&lt;/h4&gt;通知推荐系统对于提高LinkedIn等专业平台上用户参与度至关重要，设计此类系统需要整合跨领域信号、捕捉时间动态并优化多个有时相互冲突的目标。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于跨领域GNN的推荐系统，以提高LinkedIn平台上的用户点击率和专业参与度。&lt;h4&gt;方法&lt;/h4&gt;设计了一个将用户、内容和活动信号统一到一个大规模图中的系统，并引入了时间建模和多任务学习等架构创新，通过在跨领域结构上训练模型来提升性能。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在点击率预测和专业参与度等关键任务上显著优于单领域基线模型，并在LinkedIn的通知系统中实现了每周活跃用户增长0.10%和CTR提升0.62%。&lt;h4&gt;结论&lt;/h4&gt;本文展示了跨领域GNN在实际、高影响应用中的可扩展性和有效性。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a cross-domain GNN-based notification recommendation system that has been deployed on LinkedIn. The system integrates user, content, and activity signals into a single, large-scale graph and significantly improves key tasks such as click-through rate (CTR) prediction and professional engagement. The system introduces architectural innovations such as temporal modeling and multi-task learning, which further enhance performance. Deployed in LinkedIn's notification system, the approach led to a 0.10% increase in weekly active users and a 0.62% improvement in CTR. The work demonstrates the scalability and effectiveness of cross-domain GNNs in real-world, high-impact applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Notification recommendation systems are critical to driving user engagementon professional platforms like LinkedIn. Designing such systems involvesintegrating heterogeneous signals across domains, capturing temporal dynamics,and optimizing for multiple, often competing, objectives. Graph Neural Networks(GNNs) provide a powerful framework for modeling complex interactions in suchenvironments. In this paper, we present a cross-domain GNN-based systemdeployed at LinkedIn that unifies user, content, and activity signals into asingle, large-scale graph. By training on this cross-domain structure, ourmodel significantly outperforms single-domain baselines on key tasks, includingclick-through rate (CTR) prediction and professional engagement. We introducearchitectural innovations including temporal modeling and multi-task learning,which further enhance performance. Deployed in LinkedIn's notification system,our approach led to a 0.10% lift in weekly active users and a 0.62% improvementin CTR. We detail our graph construction process, model design, trainingpipeline, and both offline and online evaluations. Our work demonstrates thescalability and effectiveness of cross-domain GNNs in real-world, high-impactapplications.</description>
      <author>example@mail.com (Shihai He, Julie Choi, Tianqi Li, Zhiwei Ding, Peng Du, Priya Bannur, Franco Liang, Fedor Borisyuk, Padmini Jaikumar, Xiaobing Xue, Viral Gupta)</author>
      <guid isPermaLink="false">2506.12700v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>ViewPCL: a point cloud based active learning method for multi-view segmentation</title>
      <link>http://arxiv.org/abs/2506.13043v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新型的多视图语义分割主动学习框架。&lt;h4&gt;背景&lt;/h4&gt;针对多视图语义分割问题。&lt;h4&gt;目的&lt;/h4&gt;实现数据高效且可解释的主动学习方法。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新的评分机制，该机制衡量由模型预测的多个视图推导出的外几何信息生成的点云分布之间的差异。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在数据效率和可解释性方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;该框架为多视图语义分割提供了一种有效的主动学习方法。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新型的多视图语义分割主动学习框架。该框架依赖于一种新的评分机制，该机制衡量由模型预测的多个视图推导出的外几何信息生成的点云分布之间的差异。我们的方法实现了一种数据高效且可解释的主动学习方法。源代码可在https://github.com/chilai235/viewpclAL上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel active learning framework for multi-view semanticsegmentation. This framework relies on a new score that measures thediscrepancy between point cloud distributions generated from the extrageometrical information derived from the model's prediction across differentviews. Our approach results in a data efficient and explainable active learningmethod. The source code is available at https://github.com/chilai235/viewpclAL.</description>
      <author>example@mail.com (Christian Hilaire, Sima Didari)</author>
      <guid isPermaLink="false">2506.13043v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Konooz: Multi-domain Multi-dialect Corpus for Named Entity Recognition</title>
      <link>http://arxiv.org/abs/2506.12615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Konooz，一个包含16种阿拉伯方言和10个领域的多维度语料库，由160个独立语料库组成，包含约777k个标记。该语料库经过精心收集和人工标注，使用了21种实体类型和嵌套及扁平标注方案，遵循Wojood指南。Konooz可用于各种NLP任务，本文主要关注阿拉伯命名实体识别（NER）模型的基准测试，特别是跨领域和跨方言模型的表现。&lt;h4&gt;背景&lt;/h4&gt;Konooz是一个多维度语料库，涵盖了16种阿拉伯方言和10个领域。&lt;h4&gt;目的&lt;/h4&gt;本文的主要目的是通过Konooz基准测试现有的阿拉伯NER模型，特别是跨领域和跨方言模型的表现。&lt;h4&gt;方法&lt;/h4&gt;Konooz语料库包含了777k个标记，使用了21种实体类型进行标注，并遵循了Wojood指南。研究者使用了Konooz对四个阿拉伯NER模型进行了基准测试，并分析了领域和方言差异，以及资源稀缺的影响。此外，研究者还使用最大均值差异（MMD）指标测量了领域和方言之间的重叠，并解释了为什么某些NER模型在特定方言和领域上表现更好。&lt;h4&gt;主要发现&lt;/h4&gt;研究者发现，使用Konooz进行基准测试时，与分布内数据相比，四个阿拉伯NER模型的性能下降了高达38%。研究者还发现，领域和方言之间存在显著差异，资源稀缺对NER模型的表现有重要影响。&lt;h4&gt;结论&lt;/h4&gt;Konooz是一个开源且公开可用的语料库，可以用于评估和改进阿拉伯NER模型，特别是在跨领域和跨方言的情景下。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了Konooz，这是一个涵盖16种阿拉伯方言和10个领域的多维语料库，形成了160个不同的语料库。该语料库包含约777k个标记，经过精心收集和人工标注，使用21种实体类型，采用了嵌套和扁平标注方案——遵循Wojood指南。虽然Konooz对各种NLP任务如领域适应和迁移学习很有用，但本文主要关注对现有阿拉伯命名实体识别（NER）模型的基准测试，特别是跨领域和跨方言模型的表现。使用Konooz对四个阿拉伯NER模型进行的基准测试表明，与分布内数据相比，性能下降了高达38%。此外，我们还对领域和方言差异以及资源稀缺的影响进行了深入分析。我们还使用最大均值差异（MMD）指标测量了领域和方言之间的重叠，并说明了为什么某些NER模型在特定方言和领域上表现更好。Konooz是开源的，可以在https://sina.birzeit.edu/wojood/#download上公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Konooz, a novel multi-dimensional corpus covering 16 Arabicdialects across 10 domains, resulting in 160 distinct corpora. The corpuscomprises about 777k tokens, carefully collected and manually annotated with 21entity types using both nested and flat annotation schemes - using the Wojoodguidelines. While Konooz is useful for various NLP tasks like domain adaptationand transfer learning, this paper primarily focuses on benchmarking existingArabic Named Entity Recognition (NER) models, especially cross-domain andcross-dialect model performance. Our benchmarking of four Arabic NER modelsusing Konooz reveals a significant drop in performance of up to 38% whencompared to the in-distribution data. Furthermore, we present an in-depthanalysis of domain and dialect divergence and the impact of resource scarcity.We also measured the overlap between domains and dialects using the MaximumMean Discrepancy (MMD) metric, and illustrated why certain NER models performbetter on specific dialects and domains. Konooz is open-source and publiclyavailable at https://sina.birzeit.edu/wojood/#download</description>
      <author>example@mail.com (Nagham Hamad, Mohammed Khalilia, Mustafa Jarrar)</author>
      <guid isPermaLink="false">2506.12615v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Understanding and Benchmarking the Trustworthiness in Multimodal LLMs for Video Understanding</title>
      <link>http://arxiv.org/abs/2506.12336v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Trust-videoLLMs，一个用于评估视频LLMs可信度的综合基准，通过五个维度：真实性、安全性、鲁棒性、公平性和隐私性，揭示了当前视频LLMs在动态视觉场景理解和跨模态扰动韧性方面的局限。&lt;h4&gt;背景&lt;/h4&gt;近年来，多模态大语言模型在视频理解（videoLLMs）方面的进步提高了其处理动态多模态数据的能力，但视频数据的空间时间复杂性导致可信度问题，如事实不准确、有害内容、偏见、幻觉和隐私风险。&lt;h4&gt;目的&lt;/h4&gt;提出Trust-videoLLMs，旨在对视频LLMs进行全面的基准测试，评估其真实性、安全性、鲁棒性、公平性和隐私性。&lt;h4&gt;方法&lt;/h4&gt;框架包含30个任务，涉及自适应、合成和标注的视频，评估动态视觉场景、跨模态交互和现实世界安全问题。&lt;h4&gt;主要发现&lt;/h4&gt;评估了23个最先进的视频LLMs（5个商业，18个开源），发现它们在动态视觉场景理解和跨模态扰动韧性方面存在重大局限。开源视频LLMs在某些方面可能表现出真实性优势，但总体可信度不如商业模型，数据多样性优于规模效应。&lt;h4&gt;结论&lt;/h4&gt;强调了对高级安全对齐的需求以增强视频LLMs的能力，并提供了一个公开可用、可扩展的工具箱，用于标准化的可信度评估，弥合了关注准确性的基准测试与对鲁棒性、安全性、公平性和隐私性的关键需求之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in multimodal large language models for videounderstanding (videoLLMs) have improved their ability to process dynamicmultimodal data. However, trustworthiness challenges factual inaccuracies,harmful content, biases, hallucinations, and privacy risks, underminereliability due to video data's spatiotemporal complexities. This studyintroduces Trust-videoLLMs, a comprehensive benchmark evaluating videoLLMsacross five dimensions: truthfulness, safety, robustness, fairness, andprivacy. Comprising 30 tasks with adapted, synthetic, and annotated videos, theframework assesses dynamic visual scenarios, cross-modal interactions, andreal-world safety concerns. Our evaluation of 23 state-of-the-art videoLLMs (5commercial,18 open-source) reveals significant limitations in dynamic visualscene understanding and cross-modal perturbation resilience. Open-sourcevideoLLMs show occasional truthfulness advantages but inferior overallcredibility compared to commercial models, with data diversity outperformingscale effects. These findings highlight the need for advanced safety alignmentto enhance capabilities. Trust-videoLLMs provides a publicly available,extensible toolbox for standardized trustworthiness assessments, bridging thegap between accuracy-focused benchmarks and critical demands for robustness,safety, fairness, and privacy.</description>
      <author>example@mail.com (Youze Wang, Zijun Chen, Ruoyu Chen, Shishen Gu, Yinpeng Dong, Hang Su, Jun Zhu, Meng Wang, Richang Hong, Wenbo Hu)</author>
      <guid isPermaLink="false">2506.12336v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>DiffS-NOCS: 3D Point Cloud Reconstruction through Coloring Sketches to NOCS Maps Using Diffusion Models</title>
      <link>http://arxiv.org/abs/2506.12835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从给定条件草图重建3D点云的方法，解决了从2D草图精确重建3D结构的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常直接在3D空间中工作，但领域变异性以及从2D草图重建准确3D结构的困难仍然是显著的障碍。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够接受控制提示的理想模型，同时处理稀疏草图和多模态融合的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了DiffS-NOCS（基于扩散的草图到NOCS映射），利用ControlNet和修改的多视图解码器从草图生成嵌入3D结构和位置信息的2D空间NOCS图。通过结合来自不同视图的多个NOCS图来重建3D点云。为了增强草图理解，集成了视角编码器来提取视角特征。此外，设计了一个特征级多视图聚合网络作为降噪模块，促进跨视图信息交换并提高NOCS图生成中的3D一致性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，DiffS-NOCS实现了可控且细粒度的与草图对齐的点云重建。&lt;h4&gt;结论&lt;/h4&gt;DiffS-NOCS方法在ShapeNet上的实验证明了其在草图到3D点云重建方面的有效性和可控性。&lt;h4&gt;翻译&lt;/h4&gt;Reconstructing a 3D point cloud from a given conditional sketch is challenging. Existing methods often work directly in 3D space, but domain variability and difficulty in reconstructing accurate 3D structures from 2D sketches remain significant obstacles. Moreover, ideal models should also accept prompts for control, in addition with the sparse sketch, posing challenges in multi-modal fusion. We propose DiffS-NOCS (Diffusion-based Sketch-to-NOCS Map), which leverages ControlNet with a modified multi-view decoder to generate NOCS maps with embedded 3D structure and position information in 2D space from sketches. The 3D point cloud is reconstructed by combining multiple NOCS maps from different views. To enhance sketch understanding, we integrate a viewpoint encoder for extracting viewpoint features. Additionally, we design a feature-level multi-view aggregation network as the denoising module, facilitating cross-view information exchange and improving 3D consistency in NOCS map generation. Experiments on ShapeNet demonstrate that DiffS-NOCS achieves controllable and fine-grained point cloud reconstruction aligned with sketches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing a 3D point cloud from a given conditional sketch ischallenging. Existing methods often work directly in 3D space, but domainvariability and difficulty in reconstructing accurate 3D structures from 2Dsketches remain significant obstacles. Moreover, ideal models should alsoaccept prompts for control, in addition with the sparse sketch, posingchallenges in multi-modal fusion. We propose DiffS-NOCS (Diffusion-basedSketch-to-NOCS Map), which leverages ControlNet with a modified multi-viewdecoder to generate NOCS maps with embedded 3D structure and positioninformation in 2D space from sketches. The 3D point cloud is reconstructed bycombining multiple NOCS maps from different views. To enhance sketchunderstanding, we integrate a viewpoint encoder for extracting viewpointfeatures. Additionally, we design a feature-level multi-view aggregationnetwork as the denoising module, facilitating cross-view information exchangeand improving 3D consistency in NOCS map generation. Experiments on ShapeNetdemonstrate that DiffS-NOCS achieves controllable and fine-grained point cloudreconstruction aligned with sketches.</description>
      <author>example@mail.com (Di Kong, Qianhui Wan)</author>
      <guid isPermaLink="false">2506.12835v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Latent Representation Learning of Multi-scale Thermophysics: Application to Dynamics in Shocked Porous Energetic Material</title>
      <link>http://arxiv.org/abs/2506.12996v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了一种基于元学习的替代方法，旨在通过使用自然语言处理中的分词思想来加速中尺度学习过程。&lt;h4&gt;背景&lt;/h4&gt;物理现象在不同长度和时间尺度上的耦合对微结构材料对外部载荷的响应至关重要。中尺度模拟的计算成本较高，这使得从零开始训练基于深度学习的代理模型存在实际挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过使用微尺度模拟的低成本和高效率来加速中尺度闭合模型的发展。&lt;h4&gt;方法&lt;/h4&gt;通过分词中尺度物理场的演变，学习微尺度物理的简化表示，并将这些表示作为中尺度动力学的构建块。中尺度潜在动力学模型通过在小规模中尺度模拟数据集上训练来学习相邻构建块之间的相关性。&lt;h4&gt;主要发现&lt;/h4&gt;与仅在中尺度数据集上训练的物理感知循环卷积神经网络（PARC）相比，本文提出的方法在中尺度数据稀缺的情况下表现更优。&lt;h4&gt;结论&lt;/h4&gt;该方法通过利用低成本的微尺度模拟和快速的小规模中尺度数据集训练，可以加速闭合模型的发展，并适用于多种多尺度建模问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要：跨长度和时间尺度的物理耦合在微结构材料对外部载荷的响应中起着重要作用。在多尺度框架中，未解决（亚网格）的中尺度动力学通过闭合模型上提到均质化（宏观尺度）的异质材料表示。使用中尺度模拟数据训练的深度学习模型现在是整合这种闭合定律的流行途径。然而，中尺度模拟在计算上具有挑战性，这在从头开始训练基于深度学习的代理模型时提出了实际挑战。在这项工作中，我们研究了一种受自然语言处理中分词思想启发的元学习替代方法。我们表明，通过分词一个典型的、尽管复杂的、反应动力学问题（即，多孔能量材料中的冲击诱导能量局部化）中涉及的物理场的中尺度演变，可以学习微尺度物理的简化表示以加速中尺度学习过程。学习微尺度动力学的概率潜在表示作为中尺度动力学的构建块。中尺度潜在动力学模型通过在小规模中尺度模拟数据集上训练来学习相邻构建块之间的相关性。我们比较了我们模型的性能与仅在中尺度数据集上训练的物理感知循环卷积神经网络（PARC）。我们证明了我们的模型可以在中尺度数据稀缺的情况下优于PARC。提出的方法通过利用低成本的微尺度模拟和在小型中尺度数据集上的快速训练来加速闭合模型的发展，并且可以应用于各种多尺度建模问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Coupling of physics across length and time scales plays an important role inthe response of microstructured materials to external loads. In a multi-scaleframework, unresolved (subgrid) meso-scale dynamics is upscaled to thehomogenized (macro-scale) representation of the heterogeneous material throughclosure models. Deep learning models trained using meso-scale simulation dataare now a popular route to assimilate such closure laws. However, meso-scalesimulations are computationally taxing, posing practical challenges in trainingdeep learning-based surrogate models from scratch. In this work, we investigatean alternative meta-learning approach motivated by the idea of tokenization innatural language processing. We show that one can learn a reducedrepresentation of the micro-scale physics to accelerate the meso-scale learningprocess by tokenizing the meso-scale evolution of the physical fields involvedin an archetypal, albeit complex, reactive dynamics problem, \textit{viz.},shock-induced energy localization in a porous energetic material. Aprobabilistic latent representation of \textit{micro}-scale dynamics is learnedas building blocks for \textit{meso}-scale dynamics. The \textit{meso-}scalelatent dynamics model learns the correlation between neighboring buildingblocks by training over a small dataset of meso-scale simulations. We comparethe performance of our model with a physics-aware recurrent convolutionalneural network (PARC) trained only on the full meso-scale dataset. Wedemonstrate that our model can outperform PARC with scarce meso-scale data. Theproposed approach accelerates the development of closure models by leveraginginexpensive micro-scale simulations and fast training over a small meso-scaledataset, and can be applied to a range of multi-scale modeling problems.</description>
      <author>example@mail.com (Shahab Azarfar, Joseph B. Choi, Phong CH. Nguyen, Yen T. Nguyen, Pradeep Seshadri, H. S. Udaykumar, Stephen Baek)</author>
      <guid isPermaLink="false">2506.12996v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Audio Cues for Enhanced Test-Time Video Model Adaptation</title>
      <link>http://arxiv.org/abs/2506.12481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将音频信息融入视频测试时自适应（TTA）的方法，以提高模型的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的视频TTA方法主要利用视觉监督信号，而忽略了音频数据的潜在贡献。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，通过在测试阶段进行自-/无监督学习来增强训练模型的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;该方法利用音频的丰富语义内容生成辅助伪标签，通过预训练的音频模型对视频中的音频信号进行分类，然后使用大型语言模型将基于音频的预测映射到视频标签空间，从而建立音频类别和视频标签之间的联系。为了有效利用生成的伪标签，提出了一种灵活的自适应周期，根据损失和不同视图之间的一致性变化确定每个样本的最佳迭代次数，从而为每个样本实现定制化的自适应过程。&lt;h4&gt;主要发现&lt;/h4&gt;在UCF101-C和Kinetics-Sounds-C等广泛使用的数据集上，以及各种损坏类型的两个新构建的音频视频TTA数据集（AVE-C和AVMIT-C）上，实验结果表明该方法优于现有方法，并在不同视频分类模型中一致地提高了自适应性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在将音频信息融入视频TTA方面取得了显著进展。&lt;h4&gt;翻译&lt;/h4&gt;Test-time adaptation (TTA) aims to boost the generalization capability of a trained model by conducting self-/unsupervised learning during the testing phase. While most existing TTA methods for video primarily utilize visual supervisory signals, they often overlook the potential contribution of inherent audio data. To address this gap, we propose a novel approach that incorporates audio information into video TTA. Our method capitalizes on the rich semantic content of audio to generate audio-assisted pseudo-labels, a new concept in the context of video TTA. Specifically, we propose an audio-to-video label mapping method by first employing pre-trained audio models to classify audio signals extracted from videos and then mapping the audio-based predictions to video label spaces through large language models, thereby establishing a connection between the audio categories and video labels. To effectively leverage the generated pseudo-labels, we present a flexible adaptation cycle that determines the optimal number of adaptation iterations for each sample, based on changes in loss and consistency across different views. This enables a customized adaptation process for each sample. Experimental results on two widely used datasets (UCF101-C and Kinetics-Sounds-C), as well as on two newly constructed audio-video TTA datasets (AVE-C and AVMIT-C) with various corruption types, demonstrate the superiority of our approach. Our method consistently improves adaptation performance across different video classification models and represents a significant step forward in integrating audio information into video TTA. Code: https://github.com/keikeiqi/Audio-Assisted-TTA.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Test-time adaptation (TTA) aims to boost the generalization capability of atrained model by conducting self-/unsupervised learning during the testingphase. While most existing TTA methods for video primarily utilize visualsupervisory signals, they often overlook the potential contribution of inherentaudio data. To address this gap, we propose a novel approach that incorporatesaudio information into video TTA. Our method capitalizes on the rich semanticcontent of audio to generate audio-assisted pseudo-labels, a new concept in thecontext of video TTA. Specifically, we propose an audio-to-video label mappingmethod by first employing pre-trained audio models to classify audio signalsextracted from videos and then mapping the audio-based predictions to videolabel spaces through large language models, thereby establishing a connectionbetween the audio categories and video labels. To effectively leverage thegenerated pseudo-labels, we present a flexible adaptation cycle that determinesthe optimal number of adaptation iterations for each sample, based on changesin loss and consistency across different views. This enables a customizedadaptation process for each sample. Experimental results on two widely useddatasets (UCF101-C and Kinetics-Sounds-C), as well as on two newly constructedaudio-video TTA datasets (AVE-C and AVMIT-C) with various corruption types,demonstrate the superiority of our approach. Our method consistently improvesadaptation performance across different video classification models andrepresents a significant step forward in integrating audio information intovideo TTA. Code: https://github.com/keikeiqi/Audio-Assisted-TTA.</description>
      <author>example@mail.com (Runhao Zeng, Qi Deng, Ronghao Zhang, Shuaicheng Niu, Jian Chen, Xiping Hu, Victor C. M. Leung)</author>
      <guid isPermaLink="false">2506.12481v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>RAW-Explainer: Post-hoc Explanations of Graph Neural Networks on Knowledge Graphs</title>
      <link>http://arxiv.org/abs/2506.12558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RAW-Explainer的新框架，用于生成连接、简洁且可解释的子图解释，以解决知识图谱任务中链接预测的可解释性问题。&lt;h4&gt;背景&lt;/h4&gt;尽管图神经网络在知识图谱任务如链接预测中表现出色，但其预测的可解释性仍然是一个挑战。现有的可解释方法主要集中在节点或图级别任务，而针对异构环境中链接预测的解释方法有限。&lt;h4&gt;目的&lt;/h4&gt;提出RAW-Explainer框架，旨在生成对于链接预测可解释的子图解释。&lt;h4&gt;方法&lt;/h4&gt;RAW-Explainer利用知识图中的异构信息，通过随机游走目标来识别作为实际解释模式的连接子图。与专门针对知识图谱的现有方法不同，该方法使用神经网络来参数化解释生成过程，从而显著加快集体解释的生产速度。此外，RAW-Explainer还设计了一种鲁棒的评估器，以克服在评估质量小于完整图多个数量级的解释子图时遇到的分布偏移问题，该评估器能够泛化到子图分布。&lt;h4&gt;主要发现&lt;/h4&gt;RAW-Explainer在解释质量和计算效率之间取得了平衡，通过真实世界知识图谱数据集的大量定量结果表明，该方法有效。&lt;h4&gt;结论&lt;/h4&gt;RAW-Explainer为链接预测提供了有效的解释框架，有助于提高链接预测的可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks have demonstrated state-of-the-art performance onknowledge graph tasks such as link prediction. However, interpreting GNNpredictions remains a challenging open problem. While many GNN explainabilitymethods have been proposed for node or graph-level tasks, approaches forgenerating explanations for link predictions in heterogeneous settings arelimited. In this paper, we propose RAW-Explainer, a novel framework designed togenerate connected, concise, and thus interpretable subgraph explanations forlink prediction. Our method leverages the heterogeneous information inknowledge graphs to identify connected subgraphs that serve as patterns offactual explanation via a random walk objective. Unlike existing methodstailored to knowledge graphs, our approach employs a neural network toparameterize the explanation generation process, which significantly speeds upthe production of collective explanations. Furthermore, RAW-Explainer isdesigned to overcome the distribution shift issue when evaluating the qualityof an explanatory subgraph which is orders of magnitude smaller than the fullgraph, by proposing a robust evaluator that generalizes to the subgraphdistribution. Extensive quantitative results on real-world knowledge graphdatasets demonstrate that our approach strikes a balance between explanationquality and computational efficiency.</description>
      <author>example@mail.com (Ryoji Kubo, Djellel Difallah)</author>
      <guid isPermaLink="false">2506.12558v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>CLIP the Landscape: Automated Tagging of Crowdsourced Landscape Images</title>
      <link>http://arxiv.org/abs/2506.12214v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于CLIP的多模态多标签分类器，用于从Geograph数据集中的景观照片中预测地理上下文标签。&lt;h4&gt;背景&lt;/h4&gt;Geograph数据集是一个覆盖英国群岛的众包图像档案，包括缺乏POI和街景图像的偏远地区。&lt;h4&gt;目的&lt;/h4&gt;解决Kaggle竞赛中的任务，该竞赛基于Geograph数据集的8M图像子集，要求对49个可能的标签进行精确匹配的准确率。&lt;h4&gt;方法&lt;/h4&gt;结合位置和标题嵌入与图像特征，以提高准确率，并发布了一个轻量级管道，该管道在普通笔记本电脑上训练，使用预训练的CLIP图像和文本嵌入以及简单的分类头。&lt;h4&gt;主要发现&lt;/h4&gt;结合位置和标题嵌入与图像特征比仅使用图像嵌入提高了准确率。&lt;h4&gt;结论&lt;/h4&gt;预测的标签可以支持下游任务，如为GeoAI应用构建位置嵌入器，丰富数据稀疏区域的空间理解。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种基于CLIP的多模态多标签分类器，用于从Geograph数据集中的景观照片中预测地理上下文标签。Geograph数据集是一个覆盖英国群岛的众包图像档案，包括缺乏POI和街景图像的偏远地区。我们的方法解决了一个基于Geograph数据集的8M图像子集的Kaggle竞赛任务，要求对49个可能的标签进行精确匹配的准确率。我们展示了结合位置和标题嵌入与图像特征可以提高准确率，并发布了一个轻量级管道，该管道在普通笔记本电脑上训练，使用预训练的CLIP图像和文本嵌入以及简单的分类头。预测的标签可以支持下游任务，如为GeoAI应用构建位置嵌入器，丰富数据稀疏区域的空间理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a CLIP-based, multi-modal, multi-label classifier for predictinggeographical context tags from landscape photos in the Geograph dataset--acrowdsourced image archive spanning the British Isles, including remote regionslacking POIs and street-level imagery. Our approach addresses a Kagglecompetition\footnote{https://www.kaggle.com/competitions/predict-geographic-context-from-landscape-photos}task based on a subset of Geograph's 8M images, with strict evaluation: exactmatch accuracy is required across 49 possible tags. We show that combininglocation and title embeddings with image features improves accuracy over usingimage embeddings alone. We release a lightweightpipeline\footnote{https://github.com/SpaceTimeLab/ClipTheLandscape} that trainson a modest laptop, using pre-trained CLIP image and text embeddings and asimple classification head. Predicted tags can support downstream tasks such asbuilding location embedders for GeoAI applications, enriching spatialunderstanding in data-sparse regions.</description>
      <author>example@mail.com (Ilya Ilyankou, Natchapon Jongwiriyanurak, Tao Cheng, James Haworth)</author>
      <guid isPermaLink="false">2506.12214v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Quantitative Comparison of Fine-Tuning Techniques for Pretrained Latent Diffusion Models in the Generation of Unseen SAR Image Concepts</title>
      <link>http://arxiv.org/abs/2506.13307v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将大型预训练的潜在扩散模型适应到全新的成像领域：合成孔径雷达（SAR）。通过大量SAR数据集，探讨了针对该未知模态的微调策略，并比较了多种微调方法，最终提出了一种混合调优策略，以提升生成质量。&lt;h4&gt;背景&lt;/h4&gt;现有的生成模型主要基于自然图像训练，但在处理SAR数据时存在适配问题，因为SAR数据涉及不同的物理、统计分布和视觉特性。&lt;h4&gt;目的&lt;/h4&gt;针对SAR数据，探索并比较多种微调策略，以提升生成模型的性能。&lt;h4&gt;方法&lt;/h4&gt;使用约10万至100万张的SAR数据集，对比了全模型微调和参数高效的低秩适应（LoRA）等方法，并针对UNet扩散骨干和文本编码器进行了分别微调。同时，结合了多种指标来评估生成质量，包括统计距离、纹理相似性和语义对齐。&lt;h4&gt;主要发现&lt;/h4&gt;混合调优策略表现最佳，全微调的UNet擅长捕捉SAR的低级特定模式，而基于LoRA的部分微调文本编码器，结合&lt;SAR&gt;标记的嵌入学习，足以保持提示对齐。&lt;h4&gt;结论&lt;/h4&gt;本文为将基础模型适应于自然图像领域之外的非常规成像模态提供了一种系统性的策略。&lt;h4&gt;翻译&lt;/h4&gt;本研究探讨了将大型预训练的潜在扩散模型适应到全新的成像领域：合成孔径雷达（SAR）。虽然这些生成模型最初是在自然图像上训练的，但在文本到图像的合成中表现出惊人的能力，但它们并没有原生地适应表示SAR数据，这涉及到不同的物理、统计分布和视觉特性。使用约10万至100万张的SAR数据集，我们解决了针对这种未见模态的基本问题：微调这些模型。我们探索并比较了多种微调策略，包括全模型微调和参数高效的低秩适应（LoRA），分别关注UNet扩散骨干和文本编码器组件。为了评估生成质量，我们结合了多个指标：从真实SAR分布的统计距离、通过GLCM描述符的纹理相似性，以及使用在SAR数据上微调的CLIP模型进行的语义对齐。我们的结果表明，混合调优策略取得了最佳性能：UNet的全微调在捕捉SAR的低级特定模式方面表现更好，而基于LoRA的文本编码器的部分微调，结合&lt;SAR&gt;标记的嵌入学习，足以保持提示对齐。这项工作为将基础模型适应于自然图像领域之外的非常规成像模态提供了一种系统性的策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work investigates the adaptation of large pre-trained latent diffusionmodels to a radically new imaging domain: Synthetic Aperture Radar (SAR). Whilethese generative models, originally trained on natural images, demonstrateimpressive capabilities in text-to-image synthesis, they are not nativelyadapted to represent SAR data, which involves different physics, statisticaldistributions, and visual characteristics. Using a sizeable SAR dataset (on theorder of 100,000 to 1 million images), we address the fundamental question offine-tuning such models for this unseen modality. We explore and comparemultiple fine-tuning strategies, including full model fine-tuning andparameter-efficient approaches like Low-Rank Adaptation (LoRA), focusingseparately on the UNet diffusion backbone and the text encoder components. Toevaluate generative quality, we combine several metrics: statistical distancefrom real SAR distributions, textural similarity via GLCM descriptors, andsemantic alignment assessed with a CLIP model fine-tuned on SAR data. Ourresults show that a hybrid tuning strategy yields the best performance: fullfine-tuning of the UNet is better at capturing low-level SAR-specific patterns,while LoRA-based partial tuning of the text encoder, combined with embeddinglearning of the &lt;SAR&gt; token, suffices to preserve prompt alignment. This workprovides a methodical strategy for adapting foundation models to unconventionalimaging modalities beyond natural image domains.</description>
      <author>example@mail.com (Solène Debuysère, Nicolas Trouvé, Nathan Letheule, Olivier Lévêque, Elise Colin)</author>
      <guid isPermaLink="false">2506.13307v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Star Distillation Attention Network for Lightweight Image Super-Resolution</title>
      <link>http://arxiv.org/abs/2506.12475v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，通过卷积神经网络（CNNs）和大型核注意力（LKA）的应用，轻量级单图像超分辨率（SISR）的性能得到了显著提升。然而，现有的轻量级SISR信息蒸馏模块难以将输入映射到高维非线性（HDNL）特征空间，限制了它们的表征学习。此外，它们的LKA模块在深度可分离卷积层的卷积核尺寸增加时，计算负担呈二次增长，同时限制了捕捉长距离依赖的多形状多尺度信息的能力。&lt;h4&gt;背景&lt;/h4&gt;近年来，轻量级单图像超分辨率（SISR）的性能得到了显著提升，这得益于卷积神经网络（CNNs）和大型核注意力（LKA）的应用。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有轻量级SISR信息蒸馏模块在映射输入到高维非线性（HDNL）特征空间时的困难，以及LKA模块在捕捉长距离依赖的多形状多尺度信息时计算负担过重的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种星型蒸馏模块（SDM）来增强高维非线性（HDNL）特征空间中的信息蒸馏，以提升表征学习。此外，还提出了一个多形状多尺度大型核注意力（MM-LKA）模块，以在低计算和内存开销的情况下学习代表性长距离依赖。将SDM和MM-LKA整合，开发了残差星型蒸馏注意力模块（RSDAM），并将其作为所提出的高效星型蒸馏注意力网络（SDAN）的构建块，该网络具有高重建效率，可以从对应的低分辨率（LR）图像恢复高质量图像。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验证明，所提出的SDAN在低模型复杂度下，在定量和视觉性能上均优于其他轻量级最先进的SISR方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的星型蒸馏注意力网络（SDAN）在轻量级单图像超分辨率（SISR）领域实现了显著的性能提升，为高质量图像重建提供了有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, the performance of lightweight Single-Image Super-Resolution(SISR) has been improved significantly with the application of ConvolutionalNeural Networks (CNNs) and Large Kernel Attention (LKA). However, existinginformation distillation modules for lightweight SISR struggle to map inputsinto High-Dimensional Non-Linear (HDNL) feature spaces, limiting theirrepresentation learning. And their LKA modules possess restricted ability tocapture the multi-shape multi-scale information for long-range dependencieswhile encountering a quadratic increase in the computational burden withincreasing convolutional kernel size of its depth-wise convolutional layer. Toaddress these issues, we firstly propose a Star Distillation Module (SDM) toenhance the discriminative representation learning via information distillationin the HDNL feature spaces. Besides, we present a Multi-shape Multi-scale LargeKernel Attention (MM-LKA) module to learn representative long-rangedependencies while incurring low computational and memory footprints, leadingto improving the performance of CNN-based self-attention significantly.Integrating SDM and MM-LKA, we develop a Residual Star Distillation AttentionModule (RSDAM) and take it as the building block of the proposed efficient StarDistillation Attention Network (SDAN) which possesses high reconstructionefficiency to recover a higher-quality image from the correspondinglow-resolution (LR) counterpart. When compared with other lightweightstate-of-the-art SISR methods, extensive experiments show that our SDAN withlow model complexity yields superior performance quantitatively and visually.</description>
      <author>example@mail.com (Fangwei Hao, Ji Du, Desheng Kong, Jiesheng Wu, Jing Xu, Ping Li)</author>
      <guid isPermaLink="false">2506.12475v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>A Transfer Learning Framework for Multilayer Networks via Model Averaging</title>
      <link>http://arxiv.org/abs/2506.12455v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于多层网络链接预测的新型迁移学习框架，该方法使用双层模型平均法，并基于边缘的K折交叉验证准则来自动加权层间和层内候选模型，以实现信息在不同层之间的迁移，同时降低模型不确定性。&lt;h4&gt;背景&lt;/h4&gt;在推荐系统和蛋白质-蛋白质相互作用预测等应用中，多层网络的链接预测是一个关键挑战。尽管已经开发了许多技术，但大多数技术依赖于共享结构的假设，并且需要访问原始辅助数据，这限制了其实用性。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要共享结构先验知识，且能有效地进行信息迁移和降低模型不确定性的迁移学习框架。&lt;h4&gt;方法&lt;/h4&gt;使用双层模型平均法，结合基于边缘的K折交叉验证准则来自动加权层间和层内候选模型，实现信息在不同层之间的迁移。&lt;h4&gt;主要发现&lt;/h4&gt;理论上证明了该方法在温和条件下具有最优性和权重收敛性。计算上，该框架高效且保护隐私，避免了原始数据共享，并支持多服务器间的并行处理。仿真结果表明，该方法在预测准确性和鲁棒性方面优于其他方法。&lt;h4&gt;结论&lt;/h4&gt;该方法在预测准确性和鲁棒性方面优于其他方法，并通过两个真实世界的推荐系统应用证明了其实际价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction in multilayer networks is a key challenge in applicationssuch as recommendation systems and protein-protein interaction prediction.While many techniques have been developed, most rely on assumptions aboutshared structures and require access to raw auxiliary data, limiting theirpracticality. To address these issues, we propose a novel transfer learningframework for multilayer networks using a bi-level model averaging method. A$K$-fold cross-validation criterion based on edges is used to automaticallyweight inter-layer and intra-layer candidate models. This enables the transferof information from auxiliary layers while mitigating model uncertainty, evenwithout prior knowledge of shared structures. Theoretically, we prove theoptimality and weight convergence of our method under mild conditions.Computationally, our framework is efficient and privacy-preserving, as itavoids raw data sharing and supports parallel processing across multipleservers. Simulations show our method outperforms others in predictive accuracyand robustness. We further demonstrate its practical value through tworeal-world recommendation system applications.</description>
      <author>example@mail.com (Yongqin Qiu, Xinyu Zhang)</author>
      <guid isPermaLink="false">2506.12455v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Delving into Instance-Dependent Label Noise in Graph Data: A Comprehensive Study and Benchmark</title>
      <link>http://arxiv.org/abs/2506.12468v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了BeGIN，一个针对具有实例相关噪声的图的新基准，用于评估GNN在处理噪声标签时的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的图学习研究在处理真实世界数据中的标签噪声时，通常依赖于类别相关的标签噪声，而忽略了实例相关的噪声的复杂性，并且无法完全捕捉现实世界的噪声模式。&lt;h4&gt;目的&lt;/h4&gt;BeGIN的目的是提供一个包含各种噪声类型的真实图数据集，并全面评估GNN架构、噪声标签检测和噪声鲁棒学习策略。&lt;h4&gt;方法&lt;/h4&gt;BeGIN通过算法方法和基于LLM的模拟来模拟实例相关的噪声，以模拟实例依赖的损坏。&lt;h4&gt;主要发现&lt;/h4&gt;实验揭示了实例相关噪声，尤其是基于LLM的噪声的挑战，并强调了节点特定参数化在增强GNN鲁棒性方面的重要性。&lt;h4&gt;结论&lt;/h4&gt;BeGIN通过全面评估噪声处理策略，提供了关于它们的有效性、效率和关键性能因素的见解，预计将成为推动图上标签噪声研究和促进鲁棒GNN训练方法发展的宝贵资源。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) 在节点分类任务中取得了最先进的性能，但在处理现实世界数据中的标签噪声时却面临挑战。现有关于带标签噪声的图学习的研究通常依赖于类别相关的标签噪声，忽略了实例相关的噪声的复杂性，并且无法充分捕捉现实世界的噪声模式。我们引入了BeGIN（具有实例相关噪声的基准），一个新的基准，它提供了具有各种噪声类型的真实图数据集，并全面评估了GNN架构、噪声标签检测和噪声鲁棒学习策略。为了模拟实例相关的损坏，BeGIN引入了算法方法和基于LLM的模拟。我们的实验揭示了实例相关噪声的挑战，尤其是基于LLM的噪声，并强调了节点特定参数化对于增强GNN鲁棒性的重要性。通过全面评估噪声处理策略，BeGIN提供了关于它们的有效性、效率和关键性能因素的见解。我们预计BeGIN将成为推动图上标签噪声研究和促进鲁棒GNN训练方法发展的宝贵资源。代码可在https://github.com/kimsu55/BeGIN获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737376&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have achieved state-of-the-art performance innode classification tasks but struggle with label noise in real-world data.Existing studies on graph learning with label noise commonly rely onclass-dependent label noise, overlooking the complexities of instance-dependentnoise and falling short of capturing real-world corruption patterns. Weintroduce BeGIN (Benchmarking for Graphs with Instance-dependent Noise), a newbenchmark that provides realistic graph datasets with various noise types andcomprehensively evaluates noise-handling strategies across GNN architectures,noisy label detection, and noise-robust learning. To simulateinstance-dependent corruptions, BeGIN introduces algorithmic methods andLLM-based simulations. Our experiments reveal the challenges ofinstance-dependent noise, particularly LLM-based corruption, and underscore theimportance of node-specific parameterization to enhance GNN robustness. Bycomprehensively evaluating noise-handling strategies, BeGIN provides insightsinto their effectiveness, efficiency, and key performance factors. We expectthat BeGIN will serve as a valuable resource for advancing research on labelnoise in graphs and fostering the development of robust GNN training methods.The code is available at https://github.com/kimsu55/BeGIN.</description>
      <author>example@mail.com (Suyeon Kim, SeongKu Kang, Dongwoo Kim, Jungseul Ok, Hwanjo Yu)</author>
      <guid isPermaLink="false">2506.12468v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Agentic Surgical AI: Surgeon Style Fingerprinting and Privacy Risk Quantification via Discrete Diffusion in a Vision-Language-Action Framework</title>
      <link>http://arxiv.org/abs/2506.08185v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对外科医生特定行为预测的代理建模方法，该方法结合了离散扩散框架和视觉-语言-动作（VLA）管道，用于在机器人手术中预测外科医生的操作风格。&lt;h4&gt;背景&lt;/h4&gt;外科医生的操作风格受到培训、经验和运动行为的影响，但大多数手术AI系统忽视了这种个性化的信号。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够预测外科医生在机器人手术中特定行为的方法，同时保护医生的身份隐私。&lt;h4&gt;方法&lt;/h4&gt;将手势预测视为一个结构化序列去噪任务，该任务基于包括手术视频、意图语言和外科医生身份和技能的个性化嵌入的多模态输入。这些嵌入通过第三方语言模型使用自然语言提示进行编码，以保留个人行为风格而不暴露明确的身份。&lt;h4&gt;主要发现&lt;/h4&gt;在JIGSAWS数据集上评估了该方法，结果表明它能够准确地重建手势序列，同时学习到每个外科医生独特的运动指纹。研究发现，更具有表现力的嵌入提高了任务性能，但同时也增加了身份泄露的脆弱性。&lt;h4&gt;结论&lt;/h4&gt;个性化嵌入虽然提高了性能，但也增加了身份泄露的风险，这表明在手术建模中平衡个人化和隐私风险的重要性。&lt;h4&gt;翻译&lt;/h4&gt;Surgeons exhibit distinct operating styles shaped by training, experience, and motor behavior-yet most surgical AI systems overlook this personalization signal. We propose a novel agentic modeling approach for surgeon-specific behavior prediction in robotic surgery, combining a discrete diffusion framework with a vision-language-action (VLA) pipeline. Gesture prediction is framed as a structured sequence denoising task, conditioned on multimodal inputs including surgical video, intent language, and personalized embeddings of surgeon identity and skill. These embeddings are encoded through natural language prompts using third-party language models, allowing the model to retain individual behavioral style without exposing explicit identity. We evaluate our method on the JIGSAWS dataset and demonstrate that it accurately reconstructs gesture sequences while learning meaningful motion fingerprints unique to each surgeon. To quantify the privacy implications of personalization, we perform membership inference attacks and find that more expressive embeddings improve task performance but simultaneously increase susceptibility to identity leakage. These findings demonstrate that while personalized embeddings improve performance, they also increase vulnerability to identity leakage, revealing the importance of balancing personalization with privacy risk in surgical modeling. Code is available at: https://github.com/huixin-zhan-ai/Surgeon_style_fingerprinting.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/huixin-zhan-ai/surgeon_style_fingerprinting&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surgeons exhibit distinct operating styles shaped by training, experience,and motor behavior-yet most surgical AI systems overlook this personalizationsignal. We propose a novel agentic modeling approach for surgeon-specificbehavior prediction in robotic surgery, combining a discrete diffusionframework with a vision-language-action (VLA) pipeline. Gesture prediction isframed as a structured sequence denoising task, conditioned on multimodalinputs including surgical video, intent language, and personalized embeddingsof surgeon identity and skill. These embeddings are encoded through naturallanguage prompts using third-party language models, allowing the model toretain individual behavioral style without exposing explicit identity. Weevaluate our method on the JIGSAWS dataset and demonstrate that it accuratelyreconstructs gesture sequences while learning meaningful motion fingerprintsunique to each surgeon. To quantify the privacy implications ofpersonalization, we perform membership inference attacks and find that moreexpressive embeddings improve task performance but simultaneously increasesusceptibility to identity leakage. These findings demonstrate that whilepersonalized embeddings improve performance, they also increase vulnerabilityto identity leakage, revealing the importance of balancing personalization withprivacy risk in surgical modeling. Code is available at:https://github.com/huixin-zhan-ai/Surgeon_style_fingerprinting.</description>
      <author>example@mail.com (Huixin Zhan, Jason H. Moore)</author>
      <guid isPermaLink="false">2506.08185v2</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Brain Imaging Foundation Models, Are We There Yet? A Systematic Review of Foundation Models for Brain Imaging and Biomedical Research</title>
      <link>http://arxiv.org/abs/2506.13306v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基础模型（FMs）在脑成像领域的应用进行了综合综述。&lt;h4&gt;背景&lt;/h4&gt;基础模型（FMs）通过在大规模和多样化的数据集上预训练大型神经网络，已经在人工智能领域取得了革命性的进展，并在医学成像中显示出巨大的潜力。尽管已有许多调查回顾了FMs在医疗保健中的应用，但脑成像领域仍然没有得到充分代表，尽管它在神经疾病的诊断和治疗中起着关键作用。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文提出了对FMs在脑成像领域的首次全面和精选综述。&lt;h4&gt;方法&lt;/h4&gt;本文系统地分析了161个脑成像数据集和86种FMs架构，提供了关于关键设计选择、训练范例和推动近期进展的优化信息。&lt;h4&gt;主要发现&lt;/h4&gt;本文强调了各种脑成像任务中的领先模型，总结了它们的创新，并批判性地审查了文献中的当前局限性和盲点。&lt;h4&gt;结论&lt;/h4&gt;本文最后概述了未来研究方向，旨在推进FMs在脑成像中的应用，以促进临床和研究环境中的进步。&lt;h4&gt;翻译&lt;/h4&gt;This paper provides a comprehensive review of the application of foundation models (FMs) in brain imaging. The background section discusses the revolutionary progress of FMs in artificial intelligence and their significant potential in medical imaging. Despite their promise, brain imaging remains underrepresented in healthcare, playing a critical role in the diagnosis and treatment of neurological diseases. The purpose of this paper is to address this gap by presenting the first comprehensive and curated review of FMs for brain imaging. The methods section describes the systematic analysis of 161 brain imaging datasets and 86 FM architectures, providing insights into key design choices, training paradigms, and optimizations. The main findings highlight leading models for various brain imaging tasks, summarize their innovations, and critically examine current limitations and blind spots in the literature. The conclusion outlines future research directions to advance FM applications in brain imaging, aiming to foster progress in both clinical and research settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs), large neural networks pretrained on extensive anddiverse datasets, have revolutionized artificial intelligence and shownsignificant promise in medical imaging by enabling robust performance withlimited labeled data. Although numerous surveys have reviewed the applicationof FM in healthcare care, brain imaging remains underrepresented, despite itscritical role in the diagnosis and treatment of neurological diseases usingmodalities such as MRI, CT, and PET. Existing reviews either marginalize brainimaging or lack depth on the unique challenges and requirements of FM in thisdomain, such as multimodal data integration, support for diverse clinicaltasks, and handling of heterogeneous, fragmented datasets.  To address this gap, we present the first comprehensive and curated review ofFMs for brain imaging. We systematically analyze 161 brain imaging datasets and86 FM architectures, providing information on key design choices, trainingparadigms, and optimizations driving recent advances. Our review highlights theleading models for various brain imaging tasks, summarizes their innovations,and critically examines current limitations and blind spots in the literature.We conclude by outlining future research directions to advance FM applicationsin brain imaging, with the aim of fostering progress in both clinical andresearch settings.</description>
      <author>example@mail.com (Salah Ghamizi, Georgia Kanli, Yu Deng, Magali Perquin, Olivier Keunen)</author>
      <guid isPermaLink="false">2506.13306v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Merlin: Multi-View Representation Learning for Robust Multivariate Time Series Forecasting with Unfixed Missing Rates</title>
      <link>http://arxiv.org/abs/2506.12459v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGKDD 2025 (Research Track)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为Merlin的多视图表示学习模型，用于解决多元时间序列预测（MTSF）中缺失值问题，以提高模型的鲁棒性和预测准确性。&lt;h4&gt;背景&lt;/h4&gt;深度学习模型在多元时间序列预测方面表现良好，但容易受到数据采集器故障导致的缺失值影响，这些缺失值会破坏时间序列的语义，且随时间变化。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够处理不同缺失率的不完整观察值和完整观察值之间语义对齐的模型。&lt;h4&gt;方法&lt;/h4&gt;Merlin包括两个关键模块：离线知识蒸馏和多视图对比学习。离线知识蒸馏通过教师模型指导学生模型从不完整观察值中挖掘语义，类似于从完整观察值中获得的语义。多视图对比学习通过学习来自不同缺失率的不完整观察值的正负数据对来提高学生模型的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;Merlin能够有效地增强现有模型对未固定缺失率的鲁棒性，同时保持预测准确性。&lt;h4&gt;结论&lt;/h4&gt;在四个真实世界数据集上的实验表明，Merlin具有优越性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多元时间序列预测（MTSF）涉及预测多个相互关联的时间序列的未来值。最近，基于深度学习的MTSF模型因其挖掘MTS数据中语义（全局和局部信息）的潜力而受到广泛关注。然而，这些模型普遍容易受到由数据采集器故障引起的缺失值的影响。这些缺失值不仅会破坏MTS的语义，而且其分布也随时间变化。尽管如此，现有的模型缺乏对这种问题的鲁棒性，导致预测性能不佳。为此，本文提出了一种名为Merlin的多视图表示学习（Multi-View Representation Learning）模型，该模型可以帮助现有模型在MTS中实现不同缺失率的不完整观察值与完整观察值之间的语义对齐。具体来说，Merlin由两个关键模块组成：离线知识蒸馏和多视图对比学习。前者利用教师模型指导学生模型从不完整观察值中挖掘语义，类似于从完整观察值中获得的语义。后者通过学习来自不同缺失率的不完整观察值的正负数据对来提高学生模型的鲁棒性，确保跨不同缺失率的语义对齐。因此，Merlin能够有效地增强现有模型对未固定缺失率的鲁棒性，同时保持预测准确性。在四个真实世界数据集上的实验表明，Merlin具有优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate Time Series Forecasting (MTSF) involves predicting future valuesof multiple interrelated time series. Recently, deep learning-based MTSF modelshave gained significant attention for their promising ability to mine semantics(global and local information) within MTS data. However, these models arepervasively susceptible to missing values caused by malfunctioning datacollectors. These missing values not only disrupt the semantics of MTS, buttheir distribution also changes over time. Nevertheless, existing models lackrobustness to such issues, leading to suboptimal forecasting performance. Tothis end, in this paper, we propose Multi-View Representation Learning(Merlin), which can help existing models achieve semantic alignment betweenincomplete observations with different missing rates and complete observationsin MTS. Specifically, Merlin consists of two key modules: offline knowledgedistillation and multi-view contrastive learning. The former utilizes a teachermodel to guide a student model in mining semantics from incompleteobservations, similar to those obtainable from complete observations. Thelatter improves the student model's robustness by learning frompositive/negative data pairs constructed from incomplete observations withdifferent missing rates, ensuring semantic alignment across different missingrates. Therefore, Merlin is capable of effectively enhancing the robustness ofexisting models against unfixed missing rates while preserving forecastingaccuracy. Experiments on four real-world datasets demonstrate the superiorityof Merlin.</description>
      <author>example@mail.com (Chengqing Yu, Fei Wang, Chuanguang Yang, Zezhi Shao, Tao Sun, Tangwen Qian, Wei Wei, Zhulin An, Yongjun Xu)</author>
      <guid isPermaLink="false">2506.12459v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Deep Feature Fusion and Ensemble Learning for Enhanced Brain Tumor MRI Classification</title>
      <link>http://arxiv.org/abs/2506.12363v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新的双重集成框架，用于医学图像中的脑肿瘤准确分类，以提高诊断的可靠性和治疗计划的效率。&lt;h4&gt;背景&lt;/h4&gt;准确的脑肿瘤分类在医学成像中至关重要，以确保可靠的诊断和有效的治疗计划。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提高脑肿瘤分类的准确性。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了预训练的深度学习模型进行特征提取和优化的机器学习分类器进行鲁棒分类。它包括对脑磁共振图像的全面预处理和数据增强，随后使用预训练的视觉Transformer（ViT）网络进行深度特征提取。该框架采用双级集成策略：特征级集成和分类器级集成。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公开的Kaggle MRI脑肿瘤数据集上的实验表明，这种方法显著优于现有方法，强调了特征和分类器融合的重要性。该方法还突出了超参数优化（HPO）和高级预处理技术在提高诊断准确性和可靠性方面的重要性，推动了深度学习与机器学习在临床相关医学图像分析中的集成。&lt;h4&gt;结论&lt;/h4&gt;提出的双重集成框架和超参数优化技术显著提高了脑肿瘤分类的准确性，推动了深度学习与机器学习在医学图像分析中的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate brain tumor classification is crucial in medical imaging to ensurereliable diagnosis and effective treatment planning. This study introduces anovel double ensembling framework that synergistically combines pre-traineddeep learning (DL) models for feature extraction with optimized machinelearning (ML) classifiers for robust classification. The framework incorporatescomprehensive preprocessing and data augmentation of brain magnetic resonanceimages (MRI), followed by deep feature extraction using transfer learning withpre-trained Vision Transformer (ViT) networks. The novelty lies in thedual-level ensembling strategy: feature-level ensembling, which integrates deepfeatures from the top-performing ViT models, and classifier-level ensembling,which aggregates predictions from hyperparameter-optimized ML classifiers.Experiments on two public Kaggle MRI brain tumor datasets demonstrate that thisapproach significantly surpasses state-of-the-art methods, underscoring theimportance of feature and classifier fusion. The proposed methodology alsohighlights the critical roles of hyperparameter optimization (HPO) and advancedpreprocessing techniques in improving diagnostic accuracy and reliability,advancing the integration of DL and ML for clinically relevant medical imageanalysis.</description>
      <author>example@mail.com (Zahid Ullah, Jihie Kim)</author>
      <guid isPermaLink="false">2506.12363v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification</title>
      <link>http://arxiv.org/abs/2506.12585v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025 (IEEE/CVF Conference on Computer Vision and  Pattern Recognition), main conference, poster presentation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DejaVid的编码器无关方法，旨在提高视频分类任务的性能，同时不需要重新训练或改变架构。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于大型Transformer的视频编码器模型在视频分类任务上取得了显著的进步。然而，这些大型模型通常通过平均多个剪辑的嵌入输出来处理视频，产生固定长度的表示，这种方法未能考虑到各种时间相关的特征。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些限制，提出了DejaVid方法，旨在提高模型性能，同时不需要重新训练或改变架构。&lt;h4&gt;方法&lt;/h4&gt;DejaVid将视频转换为多变量时间序列（MTS）的变长时间序列，自然保留了时间顺序并适应了可变视频长度。然后，该方法学习每个时间步长和每个特征的权重，以考虑特征重要性随时间的变化。为此，引入了一种新的神经网络架构，该架构灵感来源于传统的时序对齐算法。&lt;h4&gt;主要发现&lt;/h4&gt;DejaVid显著提高了最先进的大型编码器的性能，在Something-Something V2上达到了77.2%的Top-1准确率，在Kinetics-400上达到了89.1%，在HMDB51上达到了88.6%，同时增加了不到1.8%的可学习参数，并且训练时间少于3小时。&lt;h4&gt;结论&lt;/h4&gt;DejaVid是一个有效的视频分类方法，能够在不改变现有架构的情况下显著提高性能，并具有较少的计算成本。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, large transformer-based video encoder models have greatly advanced state-of-the-art performance on video classification tasks. However, these large models typically process videos by averaging embedding outputs from multiple clips over time to produce fixed-length representations. This approach fails to account for a variety of time-related features, such as variable video durations, chronological order of events, and temporal variance in feature significance. While methods for temporal modeling do exist, they often require significant architectural changes and expensive retraining, making them impractical for off-the-shelf, fine-tuned large encoders. To overcome these limitations, we propose DejaVid, an encoder-agnostic method that enhances model performance without the need for retraining or altering the architecture. Our framework converts a video into a variable-length temporal sequence of embeddings, which we call a multivariate time series (MTS). An MTS naturally preserves temporal order and accommodates variable video durations. We then learn per-timestep, per-feature weights over the encoded MTS frames, allowing us to account for variations in feature importance over time. We introduce a new neural network architecture inspired by traditional time series alignment algorithms for this learning task. Our evaluation demonstrates that DejaVid substantially improves the performance of a state-of-the-art large encoder, achieving leading Top-1 accuracy of 77.2% on Something-Something V2, 89.1% on Kinetics-400, and 88.6% on HMDB51, while adding fewer than 1.8% additional learnable parameters and requiring less than 3 hours of training time. Our code is available at https://github.com/darrylho/DejaVid.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, large transformer-based video encoder models have greatlyadvanced state-of-the-art performance on video classification tasks. However,these large models typically process videos by averaging embedding outputs frommultiple clips over time to produce fixed-length representations. This approachfails to account for a variety of time-related features, such as variable videodurations, chronological order of events, and temporal variance in featuresignificance. While methods for temporal modeling do exist, they often requiresignificant architectural changes and expensive retraining, making themimpractical for off-the-shelf, fine-tuned large encoders. To overcome theselimitations, we propose DejaVid, an encoder-agnostic method that enhances modelperformance without the need for retraining or altering the architecture. Ourframework converts a video into a variable-length temporal sequence ofembeddings, which we call a multivariate time series (MTS). An MTS naturallypreserves temporal order and accommodates variable video durations. We thenlearn per-timestep, per-feature weights over the encoded MTS frames, allowingus to account for variations in feature importance over time. We introduce anew neural network architecture inspired by traditional time series alignmentalgorithms for this learning task. Our evaluation demonstrates that DejaVidsubstantially improves the performance of a state-of-the-art large encoder,achieving leading Top-1 accuracy of 77.2% on Something-Something V2, 89.1% onKinetics-400, and 88.6% on HMDB51, while adding fewer than 1.8% additionallearnable parameters and requiring less than 3 hours of training time. Our codeis available at https://github.com/darrylho/DejaVid.</description>
      <author>example@mail.com (Darryl Ho, Samuel Madden)</author>
      <guid isPermaLink="false">2506.12585v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Learning Unpaired Image Dehazing with Physics-based Rehazy Generation</title>
      <link>http://arxiv.org/abs/2506.12824v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Rehazy的新训练策略，用于解决图像去雾中的过拟合问题，旨在提高去雾性能和训练稳定性。&lt;h4&gt;背景&lt;/h4&gt;现有的图像去雾方法在处理真实场景时，往往由于对合成训练对子的过拟合而表现不佳。&lt;h4&gt;目的&lt;/h4&gt;为了提高去雾性能和训练稳定性，本文提出了Rehazy训练策略。&lt;h4&gt;方法&lt;/h4&gt;Rehazy通过探索模糊图像中潜在清晰图像的一致性，并利用模糊-去模糊对来有效学习真实雾霾特性。此外，开发了一种基于物理的去模糊生成流程，并引入了双分支框架进行去雾网络训练。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Rehazy方法在四个基准数据集上表现出优异的性能，在SOTS-Indoor数据集上比之前最先进的方法提高了3.58 dB，在SOTS-Outdoor数据集上提高了1.85 dB。&lt;h4&gt;结论&lt;/h4&gt;Rehazy方法通过提高去雾性能和训练稳定性，为图像去雾领域提供了新的解决方案，并且代码将公开提供。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在图像去雾中，对合成训练对子的过拟合仍然是一个关键挑战，导致在真实场景中的泛化能力较差。为了解决这个问题，现有方法利用未配对的现实数据训练，采用CycleGAN或对比学习框架。尽管取得了进展，但这些方法往往受到训练不稳定性的影响，导致去雾性能有限。在本文中，我们提出了一种针对未配对图像去雾的新训练策略，称为Rehazy，以提高去雾性能和训练稳定性。该策略探索了模糊图像中潜在清晰图像的一致性，并利用模糊-去模糊对来有效地学习真实雾霾特性。为了有利于构建模糊-去模糊对，我们开发了一种基于物理的去模糊生成流程，该流程在理论上得到了验证，可以可靠地产生高质量的模糊-去模糊图像。此外，利用去模糊策略，我们引入了一个双分支框架进行去雾网络训练，其中清洁分支以合成方式提供基本的去雾能力，而模糊分支通过模糊-去模糊对增强了泛化能力。此外，我们在这些分支中设计了一个新的去雾网络，以提高效率，从粗到细逐步恢复清晰场景。在四个基准数据集上的大量实验表明，我们的方法具有优越的性能，在SOTS-Indoor数据集上比先前最先进的方法提高了3.58 dB，在SOTS-Outdoor数据集上提高了1.85 dB。我们的代码将公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Overfitting to synthetic training pairs remains a critical challenge in imagedehazing, leading to poor generalization capability to real-world scenarios. Toaddress this issue, existing approaches utilize unpaired realistic data fortraining, employing CycleGAN or contrastive learning frameworks. Despite theirprogress, these methods often suffer from training instability, resulting inlimited dehazing performance. In this paper, we propose a novel trainingstrategy for unpaired image dehazing, termed Rehazy, to improve both dehazingperformance and training stability. This strategy explores the consistency ofthe underlying clean images across hazy images and utilizes hazy-rehazy pairsfor effective learning of real haze characteristics. To favorably constructhazy-rehazy pairs, we develop a physics-based rehazy generation pipeline, whichis theoretically validated to reliably produce high-quality rehazy images.Additionally, leveraging the rehazy strategy, we introduce a dual-branchframework for dehazing network training, where a clean branch provides a basicdehazing capability in a synthetic manner, and a hazy branch enhances thegeneralization ability with hazy-rehazy pairs. Moreover, we design a newdehazing network within these branches to improve the efficiency, whichprogressively restores clean scenes from coarse to fine. Extensive experimentson four benchmarks demonstrate the superior performance of our approach,exceeding the previous state-of-the-art methods by 3.58 dB on the SOTS-Indoordataset and by 1.85 dB on the SOTS-Outdoor dataset in PSNR. Our code will bepublicly available.</description>
      <author>example@mail.com (Haoyou Deng, Zhiqiang Li, Feng Zhang, Qingbo Lu, Zisheng Cao, Yuanjie Shao, Shuhang Gu, Changxin Gao, Nong Sang)</author>
      <guid isPermaLink="false">2506.12824v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Topology-Assisted Spatio-Temporal Pattern Disentangling for Scalable MARL in Large-scale Autonomous Traffic Control</title>
      <link>http://arxiv.org/abs/2506.12453v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的多智能体强化学习框架，通过整合动态图神经网络和拓扑数据分析来优化交通信号控制，并验证了其在解决大规模交通信号控制任务复杂性的有效性和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;智能交通系统成为缓解城市交通拥堵的解决方案，其中交通信号控制是一个关键组成部分。尽管多智能体强化学习算法在优化交通信号控制方面显示出潜力，但其在处理大规模和复杂环境时的可扩展性和有效性受到限制。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文旨在提出一种新的多智能体强化学习框架，通过增强环境表示的表达能力和改善智能体之间的协调来优化交通信号控制。&lt;h4&gt;方法&lt;/h4&gt;本文提出的框架结合了动态图神经网络和拓扑数据分析，并受到大型语言模型中混合专家架构的启发，提出了拓扑辅助空间模式解耦的混合专家架构。该架构利用拓扑特征来解耦图特征，以提高模型对动态和异构局部观察的表征能力。此外，拓扑数据分析模块也被集成到多智能体近端策略优化算法的政策和价值网络中。&lt;h4&gt;主要发现&lt;/h4&gt;在真实世界交通场景上进行的广泛实验和全面的理论分析验证了所提出框架的优越性能，突出了模型在解决大规模交通信号控制任务复杂性方面的可扩展性和有效性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的框架在优化交通信号控制方面具有显著的优势，特别是在处理大规模和复杂环境时，显示出良好的可扩展性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Intelligent Transportation Systems (ITSs) have emerged as a promisingsolution towards ameliorating urban traffic congestion, with Traffic SignalControl (TSC) identified as a critical component. Although Multi-AgentReinforcement Learning (MARL) algorithms have shown potential in optimizing TSCthrough real-time decision-making, their scalability and effectiveness oftensuffer from large-scale and complex environments. Typically, these limitationsprimarily stem from a fundamental mismatch between the exponential growth ofthe state space driven by the environmental heterogeneities and the limitedmodeling capacity of current solutions. To address these issues, this paperintroduces a novel MARL framework that integrates Dynamic Graph Neural Networks(DGNNs) and Topological Data Analysis (TDA), aiming to enhance theexpressiveness of environmental representations and improve agent coordination.Furthermore, inspired by the Mixture of Experts (MoE) architecture in LargeLanguage Models (LLMs), a topology-assisted spatial pattern disentangling(TSD)-enhanced MoE is proposed, which leverages topological signatures todecouple graph features for specialized processing, thus improving the model'sability to characterize dynamic and heterogeneous local observations. The TSDmodule is also integrated into the policy and value networks of the Multi-agentProximal Policy Optimization (MAPPO) algorithm, further improvingdecision-making efficiency and robustness. Extensive experiments conducted onreal-world traffic scenarios, together with comprehensive theoretical analysis,validate the superior performance of the proposed framework, highlighting themodel's scalability and effectiveness in addressing the complexities oflarge-scale TSC tasks.</description>
      <author>example@mail.com (Rongpeng Li, Jianhang Zhu, Jiahao Huang, Zhifeng Zhao, Honggang Zhang)</author>
      <guid isPermaLink="false">2506.12453v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>AdaLRS: Loss-Guided Adaptive Learning Rate Search for Efficient Foundation Model Pretraining</title>
      <link>http://arxiv.org/abs/2506.13274v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AdaLRS的适应性学习率搜索算法，该算法通过优化损失下降速度进行在线最优学习率搜索，实验结果表明该算法在不同模型和数据集规模下均有效。&lt;h4&gt;背景&lt;/h4&gt;学习率对于有效的基础模型预训练至关重要，现有研究探索了学习率配置在不同模型和数据集规模下的可迁移性，但这些方法通常局限于特定的训练场景，并需要大量超参数调整。&lt;h4&gt;目的&lt;/h4&gt;提出AdaLRS算法，旨在通过在线搜索最优学习率来提高基础模型预训练的效率。&lt;h4&gt;方法&lt;/h4&gt;AdaLRS算法通过优化损失下降速度进行在线最优学习率搜索，其搜索过程依赖于训练损失动态，且通过理论分析保证了收敛性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，AdaLRS能够将次优学习率调整到接近最优的水平，显著提高了模型性能。此外，AdaLRS在多种训练场景下表现出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;AdaLRS算法能够有效提高基础模型预训练的效率，并在不同训练场景下具有良好的性能和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：学习率被广泛认为是有效基础模型预训练的关键。最近的研究探讨了在不同模型和数据集规模下的学习率配置的可迁移性，但这些方法通常局限于特定的训练场景，并且通常需要在代理模型上进行大量的超参数调整。在这项工作中，我们提出了AdaLRS，这是一种即插即用的适应性学习率搜索算法，它通过优化损失下降速度进行在线最优学习率搜索。我们提供了实验结果来表明，在基础模型预训练中，训练损失的优化和损失下降速度都是凸的，并且具有相同的最佳学习率。AdaLRS仅依赖于训练损失动态，涉及少量额外的计算来指导搜索过程，并且其收敛性通过理论分析得到保证。在LLM和VLM预训练上的实验表明，AdaLRS以显著的高效性和有效性将次优学习率调整到最优附近，相应地提高了模型性能。我们还展示了AdaLRS在多种训练场景中的鲁棒泛化能力，例如不同的模型大小、训练范式和基本学习率调度器选择。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning rate is widely regarded as crucial for effective foundation modelpretraining. Recent research explores and demonstrates the transferability oflearning rate configurations across varying model and dataset sizes, etc.Nevertheless, these approaches are constrained to specific training scenariosand typically necessitate extensive hyperparameter tuning on proxy models. Inthis work, we propose \textbf{AdaLRS}, a plug-in-and-play adaptive learningrate search algorithm that conducts online optimal learning rate search viaoptimizing loss descent velocities. We provide experiment results to show thatthe optimization of training loss and loss descent velocity in foundation modelpretraining are both convex and share the same optimal learning rate. Relyingsolely on training loss dynamics, AdaLRS involves few extra computations toguide the search process, and its convergence is guaranteed via theoreticalanalysis. Experiments on both LLM and VLM pretraining show that AdaLRS adjustssuboptimal learning rates to the neighborhood of optimum with marked efficiencyand effectiveness, with model performance improved accordingly. We also showthe robust generalizability of AdaLRS across varying training scenarios, suchas different model sizes, training paradigms, and base learning rate schedulerchoices.</description>
      <author>example@mail.com (Hongyuan Dong, Dingkang Yang, Xiao Liang, Chao Feng, Jiao Ran)</author>
      <guid isPermaLink="false">2506.13274v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable Classification of Levantine Ceramic Thin Sections via Neural Networks</title>
      <link>http://arxiv.org/abs/2506.12250v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in Machine Learning: Science and Technology&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究利用深度学习模型（CNN和ViT）对黎凡特地区陶瓷进行分类，以支持传统岩相分析的分类，并提高分类效率。&lt;h4&gt;背景&lt;/h4&gt;陶瓷薄片分类对于了解古代制陶技术、产地和贸易网络至关重要，但传统岩相分析耗时较长。&lt;h4&gt;目的&lt;/h4&gt;探索深度学习模型（CNN和ViT）在黎凡特陶瓷分类中的应用，作为传统岩相分析的补充工具。&lt;h4&gt;方法&lt;/h4&gt;使用1,424张薄片图像数据集进行模型训练和评估，其中包含178个样品的图像，这些样品来自黎凡特地区的多个考古遗址，主要属于青铜时代，少数样品属于铁器时代。&lt;h4&gt;主要发现&lt;/h4&gt;迁移学习显著提高了分类性能，ResNet18模型达到92.11%的准确率，ViT达到88.34%。可解释性技术揭示了CNN和ViT专注于关键矿物学特征进行分类。&lt;h4&gt;结论&lt;/h4&gt;这些发现突出了可解释AI在考古计量学研究中的潜力，为陶瓷分析提供了可重复且高效的方法，同时保持了模型决策的透明度。&lt;h4&gt;翻译&lt;/h4&gt;摘要：陶瓷薄片分类对于理解古代陶器生产技术、产地和贸易网络至关重要。尽管传统岩相分析有效，但耗时较长。本研究探讨了深度学习模型，特别是卷积神经网络（CNN）和视觉Transformer（ViT），作为补充工具以支持基于岩相结构对黎凡特陶瓷的分类。使用了1,424张薄片图像的数据集，这些图像来自178个样品，这些样品属于黎凡特地区的多个考古遗址，主要属于青铜时代，少数样品属于铁器时代，用于训练和评估这些模型。结果表明，迁移学习显著提高了分类性能，ResNet18模型达到了92.11%的准确率，ViT达到了88.34%。应用了可解释性技术，包括引导的Grad-CAM和注意力图，来解释和可视化模型的决策，揭示CNN和ViT都成功地专注于关键矿物学特征进行样品的岩相分类。这些发现突出了可解释AI在考古计量学研究中的潜力，为陶瓷分析提供了一个可重复且高效的方法，同时保持了模型决策的透明度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Classification of ceramic thin sections is fundamental for understandingancient pottery production techniques, provenance, and trade networks. Althougheffective, traditional petrographic analysis is time-consuming. This studyexplores the application of deep learning models, specifically ConvolutionalNeural Networks (CNNs) and Vision Transformers (ViTs), as complementary toolsto support the classification of Levantine ceramics based on their petrographicfabrics. A dataset of 1,424 thin section images from 178 ceramic samplesbelonging to several archaeological sites across the Levantine area, mostlyfrom the Bronze Age, with few samples dating to the Iron Age, was used to trainand evaluate these models. The results demonstrate that transfer learningsignificantly improves classification performance, with a ResNet18 modelachieving 92.11% accuracy and a ViT reaching 88.34%. Explainability techniques,including Guided Grad-CAM and attention maps, were applied to interpret andvisualize the models' decisions, revealing that both CNNs and ViTs successfullyfocus on key mineralogical features for the classification of the samples intotheir respective petrographic fabrics. These findings highlight the potentialof explainable AI in archaeometric studies, providing a reproducible andefficient methodology for ceramic analysis while maintaining transparency inmodel decision-making.</description>
      <author>example@mail.com (Sara Capriotti, Alessio Devoto, Simone Scardapane, Silvano Mignardi, Laura Medeghini)</author>
      <guid isPermaLink="false">2506.12250v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Learning Mappings in Mesh-based Simulations</title>
      <link>http://arxiv.org/abs/2506.12652v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖且参数自由的编码方案，用于处理几何复杂域中的不规则网格节点，以解决机器学习模型学习映射时的挑战。&lt;h4&gt;背景&lt;/h4&gt;许多物理和工程问题在几何复杂域中离散化，形成点云，这些点云的有限可处理性给机器学习模型学习映射带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种编码方案，以解决点云的可处理性问题，并提高机器学习模型在映射学习中的效率。&lt;h4&gt;方法&lt;/h4&gt;该编码方案将点云的足迹聚合到网格顶点上，生成丰富的网格表示，适用于标准的卷积和快速傅里叶变换操作，并使用卷积神经网络（CNN）进行映射学习。&lt;h4&gt;主要发现&lt;/h4&gt;将编码器与UNet（E-UNet）集成，并在多种2D和3D问题上与基于傅里叶和变换器的模型进行了性能比较，分析了预测准确性、数据效率和噪声鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该编码方案在恢复部分观察到的点云响应等映射任务中表现出多功能性，为基于网格的模拟的计算科学应用提供了一个实用的替代方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：许多现实世界的物理和工程问题出现在几何复杂的域中，这些域通过网格进行数值模拟。这些可能不规则网格的节点自然形成点云，其有限的可处理性给通过机器学习模型学习映射带来了重大挑战。为了解决这个问题，我们介绍了一种新颖且参数自由的编码方案，该方案将点的足迹聚合到网格顶点上，并产生丰富的拓扑网格表示。这种结构化的表示非常适合标准的卷积和快速傅里叶变换操作，并允许使用卷积神经网络（CNN）高效地学习编码输入-输出对之间的映射。具体来说，我们将我们的编码器与独特设计的UNet（E-UNet）集成，并将其性能与基于傅里叶和变换器的模型在多样化的2D和3D问题上进行了基准测试，我们分析了预测准确性、数据效率和噪声鲁棒性。此外，我们强调了我们的编码方案在各种映射任务中的多功能性，包括从部分观察中恢复完整的点云响应。我们提出的框架为原始和计算密集型编码方案提供了一个实用的替代方案；支持在涉及基于网格的模拟的计算科学应用中的广泛采用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many real-world physics and engineering problems arise in geometricallycomplex domains discretized by meshes for numerical simulations. The nodes ofthese potentially irregular meshes naturally form point clouds whose limitedtractability poses significant challenges for learning mappings via machinelearning models. To address this, we introduce a novel and parameter-freeencoding scheme that aggregates footprints of points onto grid vertices andyields information-rich grid representations of the topology. Such structuredrepresentations are well-suited for standard convolution and FFT (Fast FourierTransform) operations and enable efficient learning of mappings between encodedinput-output pairs using Convolutional Neural Networks (CNNs). Specifically, weintegrate our encoder with a uniquely designed UNet (E-UNet) and benchmark itsperformance against Fourier- and transformer-based models across diverse 2D and3D problems where we analyze the performance in terms of predictive accuracy,data efficiency, and noise robustness. Furthermore, we highlight theversatility of our encoding scheme in various mapping tasks includingrecovering full point cloud responses from partial observations. Our proposedframework offers a practical alternative to both primitive and computationallyintensive encoding schemes; supporting broad adoption in computational scienceapplications involving mesh-based simulations.</description>
      <author>example@mail.com (Shirin Hosseinmardi, Ramin Bostanabad)</author>
      <guid isPermaLink="false">2506.12652v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Optimizing Federated Learning using Remote Embeddings for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.12425v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint of paper in the proceedings of the 30th International  European Conference on Parallel and Distributed Computing (Euro-Par)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为OpES的优化联邦图神经网络（GNN）训练框架，通过使用远程邻域剪枝和重叠推送嵌入到服务器的方式来降低网络成本和训练时间，从而提高了训练效率。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在从图数据结构中学习有意义的表示方面取得了快速发展。联邦学习（FL）作为一种机器学习方法，可以在去中心化的数据上训练共享模型，解决隐私问题并利用并行性。现有的联邦GNN训练方法使用远程嵌入来提高收敛精度，但受限于与共享嵌入服务器的大规模通信成本，性能有所下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种优化联邦GNN训练框架，以降低网络成本和训练时间，同时保持或提高训练精度。&lt;h4&gt;方法&lt;/h4&gt;OpES框架采用远程邻域剪枝和嵌入重叠推送技术，结合本地训练，以减少通信成本。&lt;h4&gt;主要发现&lt;/h4&gt;OpES在大型和密集图（如Reddit和Products）上实现了比使用嵌入服务器的方法快约2倍的收敛速度，并且比传统联邦GNN学习提高了高达20%的精度。&lt;h4&gt;结论&lt;/h4&gt;OpES框架通过优化联邦GNN训练过程，显著提高了训练效率，同时保持了较高的训练精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have experienced rapid advancements in recentyears due to their ability to learn meaningful representations from graph datastructures. Federated Learning (FL) has emerged as a viable machine learningapproach for training a shared model on decentralized data, addressing privacyconcerns while leveraging parallelism. Existing methods that address the uniquerequirements of federated GNN training using remote embeddings to enhanceconvergence accuracy are limited by their diminished performance due to largecommunication costs with a shared embedding server. In this paper, we presentOpES, an optimized federated GNN training framework that uses remoteneighbourhood pruning, and overlaps pushing of embeddings to the server withlocal training to reduce the network costs and training time. The modest dropin per-round accuracy due to pre-emptive push of embeddings is out-stripped bythe reduction in per-round training time for large and dense graphs like Redditand Products, converging up to $\approx2\times$ faster than thestate-of-the-art technique using an embedding server and giving up to $20\%$better accuracy than vanilla federated GNN learning.</description>
      <author>example@mail.com (Pranjal Naman, Yogesh Simmhan)</author>
      <guid isPermaLink="false">2506.12425v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>GS-2DGS: Geometrically Supervised 2DGS for Reflective Object Reconstruction</title>
      <link>http://arxiv.org/abs/2506.13110v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GS-2DGS的新型重建方法，用于解决高度反光物体3D建模的挑战，该方法结合了Gaussian Splatting的高速度和细节渲染能力，同时利用了基础模型提供的额外几何信息。&lt;h4&gt;背景&lt;/h4&gt;3D建模高度反光物体存在挑战，因为它们具有强烈的视点依赖性。现有的基于SDF的方法虽然能恢复高质量网格，但往往耗时且表面过于平滑。3D Gaussian Splatting（3DGS）虽然速度快，但提取表面时可能由于缺乏几何约束而产生噪声。&lt;h4&gt;目的&lt;/h4&gt;提出GS-2DGS方法，旨在提高重建和重光照的性能，同时保持较高的速度。&lt;h4&gt;方法&lt;/h4&gt;GS-2DGS方法结合了Gaussian Splatting的快速渲染能力和来自基础模型的额外几何信息。&lt;h4&gt;主要发现&lt;/h4&gt;在合成和真实数据集上的实验结果表明，该方法在重建和重光照方面显著优于基于Gaussian的技术，并且性能与基于SDF的方法相当，但速度快了一个数量级。&lt;h4&gt;结论&lt;/h4&gt;GS-2DGS方法为高度反光物体的3D建模提供了一种快速且有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;3D建模高度反光物体由于强烈的视点依赖性而一直具有挑战性。尽管先前基于SDF的方法可以恢复高质量网格，但它们通常耗时且容易产生过度平滑的表面。相比之下，3D高斯分层（3DGS）提供了高速和详细实时渲染的优势，但由于缺乏几何约束，从高斯中提取表面可能会产生噪声。为了弥合这些方法之间的差距，我们提出了一种名为GS-2DGS的新型重建方法，用于基于2D高斯分层（2DGS）的反光物体。我们的方法结合了高斯分层的快速渲染能力以及来自基础模型的额外几何信息。在合成和真实数据集上的实验结果表明，我们的方法在重建和重光照方面显著优于基于高斯的技术，并且在性能上与基于SDF的方法相当，同时速度快了一个数量级。代码可在https://github.com/hirotong/GS2DGS找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D modeling of highly reflective objects remains challenging due to strongview-dependent appearances. While previous SDF-based methods can recoverhigh-quality meshes, they are often time-consuming and tend to produceover-smoothed surfaces. In contrast, 3D Gaussian Splatting (3DGS) offers theadvantage of high speed and detailed real-time rendering, but extractingsurfaces from the Gaussians can be noisy due to the lack of geometricconstraints. To bridge the gap between these approaches, we propose a novelreconstruction method called GS-2DGS for reflective objects based on 2DGaussian Splatting (2DGS). Our approach combines the rapid renderingcapabilities of Gaussian Splatting with additional geometric information fromfoundation models. Experimental results on synthetic and real datasetsdemonstrate that our method significantly outperforms Gaussian-based techniquesin terms of reconstruction and relighting and achieves performance comparableto SDF-based methods while being an order of magnitude faster. Code isavailable at https://github.com/hirotong/GS2DGS</description>
      <author>example@mail.com (Jinguang Tong, Xuesong li, Fahira Afzal Maken, Sundaram Muthu, Lars Petersson, Chuong Nguyen, Hongdong Li)</author>
      <guid isPermaLink="false">2506.13110v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Generative Representational Learning of Foundation Models for Recommendation</title>
      <link>http://arxiv.org/abs/2506.11999v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page is available at https://junkfood436.github.io/RecFound/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RecFound的推荐基础模型生成表示学习框架，旨在解决推荐系统中的多任务学习问题。&lt;h4&gt;背景&lt;/h4&gt;人工智能领域长期目标是开发能够在各种任务中表现优异的单个基础模型，这一趋势已扩展到推荐系统领域。&lt;h4&gt;目的&lt;/h4&gt;解决推荐基础模型在嵌入任务和复杂的多任务学习（如知识共享、冲突解决和收敛速度不一致）中的局限性。&lt;h4&gt;方法&lt;/h4&gt;构建了首个涵盖生成和嵌入任务的推荐基础模型综合数据集，并提出了一种包含TMoLE（任务 wise 混合低秩专家）、S2Sched（逐步收敛导向的样本调度器）和模型合并模块的多任务训练方案。&lt;h4&gt;主要发现&lt;/h4&gt;RecFound在多种推荐任务中实现了最先进的性能，优于现有基线。&lt;h4&gt;结论&lt;/h4&gt;RecFound是一个有效的推荐基础模型生成表示学习框架，能够有效解决推荐系统中的多任务学习问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing a single foundation model with the capability to excel acrossdiverse tasks has been a long-standing objective in the field of artificialintelligence. As the wave of general-purpose foundation models sweeps acrossvarious domains, their influence has significantly extended to the field ofrecommendation systems. While recent efforts have explored recommendationfoundation models for various generative tasks, they often overlook crucialembedding tasks and struggle with the complexities of multi-task learning,including knowledge sharing &amp; conflict resolution, and convergence speedinconsistencies. To address these limitations, we introduce RecFound, agenerative representational learning framework for recommendation foundationmodels. We construct the first comprehensive dataset for recommendationfoundation models covering both generative and embedding tasks across diversescenarios. Based on this dataset, we propose a novel multi-task training schemefeaturing a Task-wise Mixture of Low-rank Experts (TMoLE) to handle knowledgesharing &amp; conflict, a Step-wise Convergence-oriented Sample Scheduler (S2Sched)to address inconsistent convergence, and a Model Merge module to balance theperformance across tasks. Experiments demonstrate that RecFound achievesstate-of-the-art performance across various recommendation tasks, outperformingexisting baselines.</description>
      <author>example@mail.com (Zheli Zhou, Chenxu Zhu, Jianghao Lin, Bo Chen, Ruiming Tang, Weinan Zhang, Yong Yu)</author>
      <guid isPermaLink="false">2506.11999v2</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Statistical Machine Learning for Astronomy -- A Textbook</title>
      <link>http://arxiv.org/abs/2506.12230v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  677 pages, 152 figures. Code and tutorials available at  https://github.com/tingyuansen/statml&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本书系统地介绍了通过贝叶斯推断的视角，将统计机器学习应用于天文学研究的方法，构建了一个统一的框架，揭示了现代数据分析技术与传统统计方法之间的联系。&lt;h4&gt;背景&lt;/h4&gt;本书从概率理论和贝叶斯推断开始，逐步介绍监督学习（包括线性回归、逻辑回归和分类）以及无监督学习（包括主成分分析和聚类方法）。&lt;h4&gt;目的&lt;/h4&gt;优先考虑不确定性的量化，强调统计严谨性，对于天文学中的科学推断至关重要。&lt;h4&gt;方法&lt;/h4&gt;通过抽样、马尔可夫链蒙特卡洛方法、高斯过程（作为概率非参数方法）和神经网络等计算技术进行介绍，并从第一原理推导每个方法，强调统计洞察力。&lt;h4&gt;主要发现&lt;/h4&gt;理论教学方法的重点是理解算法为何有效，何时适用，以及它们如何与更广泛的统计原理相联系。&lt;h4&gt;结论&lt;/h4&gt;本书通过在经典方法和其理论基础上的坚实基础，逐步构建现代技术，如神经网络，从而能够深思熟虑地将这些方法应用于天文学研究，确保对假设、局限性和不确定性传播的适当考虑，这对于在大规模天文学调查时代推进天文学知识至关重要。&lt;h4&gt;翻译&lt;/h4&gt;本书系统地处理了通过贝叶斯推断的视角，利用统计机器学习进行天文学研究的方法。它建立了一个统一的框架，揭示了现代数据分析技术与传统统计方法之间的联系。我们展示了这些技术如何从熟悉的统计基础中产生。始终如一的贝叶斯观点优先考虑不确定性量化，对于天文学中的科学推断至关重要。本书从概率理论和贝叶斯推断开始，逐步介绍监督学习，包括具有测量不确定性的线性回归、逻辑回归和分类。无监督学习主题包括主成分分析和聚类方法。然后，我们通过抽样和马尔可夫链蒙特卡洛方法、高斯过程（作为概率非参数方法）和神经网络等计算技术介绍，然后在更广泛的统计背景下介绍神经网络。我们的理论教学方法的重点是每个方法从第一原理推导，并具有完整的数学发展，强调统计洞察力，并辅以天文学应用。我们优先考虑理解算法为何有效，何时适用，以及它们如何与更广泛的统计原理相联系。这种处理方法是通过在经典方法和其理论基础上的坚实基础，逐步构建现代技术，包括神经网络。这个基础使得这些方法能够被深思熟虑地应用于天文学研究，确保对假设、局限性和不确定性传播的适当考虑，这对于在大规模天文学调查时代推进天文学知识至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This textbook provides a systematic treatment of statistical machine learningfor astronomical research through the lens of Bayesian inference, developing aunified framework that reveals connections between modern data analysistechniques and traditional statistical methods. We show how these techniquesemerge from familiar statistical foundations. The consistently Bayesianperspective prioritizes uncertainty quantification and statistical rigoressential for scientific inference in astronomy. The textbook progresses fromprobability theory and Bayesian inference through supervised learning includinglinear regression with measurement uncertainties, logistic regression, andclassification. Unsupervised learning topics cover Principal Component Analysisand clustering methods. We then introduce computational techniques throughsampling and Markov Chain Monte Carlo, followed by Gaussian Processes asprobabilistic nonparametric methods and neural networks within the broaderstatistical context. Our theory-focused pedagogical approach derives eachmethod from first principles with complete mathematical development,emphasizing statistical insight and complementing with astronomicalapplications. We prioritize understanding why algorithms work, when they areappropriate, and how they connect to broader statistical principles. Thetreatment builds toward modern techniques including neural networks through asolid foundation in classical methods and their theoretical underpinnings. Thisfoundation enables thoughtful application of these methods to astronomicalresearch, ensuring proper consideration of assumptions, limitations, anduncertainty propagation essential for advancing astronomical knowledge in theera of large astronomical surveys.</description>
      <author>example@mail.com (Yuan-Sen Ting)</author>
      <guid isPermaLink="false">2506.12230v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>GSDNet: Revisiting Incomplete Multimodal-Diffusion from Graph Spectrum Perspective for Conversation Emotion Recognition</title>
      <link>http://arxiv.org/abs/2506.12325v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Graph Spectral Diffusion Network (GSDNet)的新型网络，用于多模态情感识别，旨在通过融合不同模态的互补语义信息来推断说话者的情感状态。&lt;h4&gt;背景&lt;/h4&gt;多模态情感识别（MERC）通过分析视频、音频和文本等多种来源的语音信息来推断说话者的情感状态。与单模态相比，融合不同模态的信息可以获得更鲁棒的语音表示。然而，模态缺失问题严重限制了MERC在实际场景中的性能。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种新的方法来解决模态缺失问题，提高MERC的性能。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种名为GSDNet的新型网络，该网络通过将高斯噪声映射到缺失模态的图谱空间，并根据其原始分布恢复缺失数据。与现有的图扩散模型不同，GSDNet只影响邻接矩阵的特征值，而不是直接破坏邻接矩阵，从而在扩散过程中保持全局拓扑信息和重要的谱特征。&lt;h4&gt;主要发现&lt;/h4&gt;GSDNet在多种模态损失场景中实现了最先进的情感识别性能。&lt;h4&gt;结论&lt;/h4&gt;GSDNet是一种有效的多模态情感识别方法，能够有效地解决模态缺失问题，提高情感识别的准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态情感识别在对话中（MERC）旨在通过分析来自多个来源（即视频、音频和文本）的语音信息来推断说话者的情感状态。与单模态相比，通过融合来自不同模态的互补语义信息可以获得更鲁棒的语音表示。然而，模态缺失问题严重限制了MERC在实际场景中的性能。最近的工作在使用图神经网络和扩散模型进行模态补全方面取得了令人印象深刻的性能。这启发我们通过图扩散模型结合这两个维度，以获得更强大的模态恢复能力。不幸的是，现有的图扩散模型通过直接向邻接矩阵添加高斯噪声来破坏图的结构和局部结构，导致生成的图数据无法保留原始图中的语义和拓扑信息。为此，我们提出了一种名为图谱扩散网络（GSDNet）的新方法，该方法将高斯噪声映射到缺失模态的图谱空间，并根据其原始分布恢复缺失数据。与之前的图扩散方法相比，GSDNet只影响邻接矩阵的特征值，而不是直接破坏邻接矩阵，这可以在扩散过程中保持全局拓扑信息和重要的谱特征。大量的实验表明，GSDNet在各种模态损失场景中实现了最先进的情感识别性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal emotion recognition in conversations (MERC) aims to infer thespeaker's emotional state by analyzing utterance information from multiplesources (i.e., video, audio, and text). Compared with unimodality, a morerobust utterance representation can be obtained by fusing complementarysemantic information from different modalities. However, the modality missingproblem severely limits the performance of MERC in practical scenarios. Recentwork has achieved impressive performance on modality completion using graphneural networks and diffusion models, respectively. This inspires us to combinethese two dimensions through the graph diffusion model to obtain more powerfulmodal recovery capabilities. Unfortunately, existing graph diffusion models maydestroy the connectivity and local structure of the graph by directly addingGaussian noise to the adjacency matrix, resulting in the generated graph databeing unable to retain the semantic and topological information of the originalgraph. To this end, we propose a novel Graph Spectral Diffusion Network(GSDNet), which maps Gaussian noise to the graph spectral space of missingmodalities and recovers the missing data according to its originaldistribution. Compared with previous graph diffusion methods, GSDNet onlyaffects the eigenvalues of the adjacency matrix instead of destroying theadjacency matrix directly, which can maintain the global topologicalinformation and important spectral features during the diffusion process.Extensive experiments have demonstrated that GSDNet achieves state-of-the-artemotion recognition performance in various modality loss scenarios.</description>
      <author>example@mail.com (Yuntao Shou, Jun Yao, Tao Meng, Wei Ai, Cen Chen, Keqin Li)</author>
      <guid isPermaLink="false">2506.12325v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>SuperPlace: The Renaissance of Classical Feature Aggregation for Visual Place Recognition in the Era of Foundation Models</title>
      <link>http://arxiv.org/abs/2506.13073v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了视觉场所识别（VPR）的新方法，称为SuperPlace，该方法结合了经典的特征聚合方法和更基本的VPR模型。&lt;h4&gt;背景&lt;/h4&gt;现有方法未能充分利用基础模型（FM）的关键概念，如有效利用大量训练集，且忽视了经典聚合方法（如GeM和NetVLAD）的潜力。&lt;h4&gt;目的&lt;/h4&gt;旨在通过复兴经典特征聚合方法，并开发更基本的VPR模型，提高视觉场所识别的准确性。&lt;h4&gt;方法&lt;/h4&gt;1. 引入了一种监督标签对齐方法，使不同VPR数据集能在统一框架下进行训练。2. 提出了G$^2$M，一种使用两个GeM的紧凑特征聚合方法，其中一个GeM学习特征图的通道维度的主成分，并校准另一个的输出。3. 提出了NetVLAD-Linear（NVL）的二次微调（FT$^2$）策略。&lt;h4&gt;主要发现&lt;/h4&gt;G$^2$M在只占现有方法十分之一特征维度的条件下取得了令人满意的结果。此外，NVL-FT$^2$在MSLS排行榜上排名第一。&lt;h4&gt;结论&lt;/h4&gt;SuperPlace方法在视觉场所识别任务中表现出优越性，G$^2$M和NVL-FT$^2$策略是有效提高识别性能的关键。&lt;h4&gt;翻译&lt;/h4&gt;Recent visual place recognition (VPR) approaches have leveraged foundation models (FM) and introduced novel aggregation techniques. However, these methods have failed to fully exploit key concepts of FM, such as the effective utilization of extensive training sets, and they have overlooked the potential of classical aggregation methods, such as GeM and NetVLAD. Building on these insights, we revive classical feature aggregation methods and develop more fundamental VPR models, collectively termed SuperPlace. First, we introduce a supervised label alignment method that enables training across various VPR datasets within a unified framework. Second, we propose G$^2$M, a compact feature aggregation method utilizing two GeMs, where one GeM learns the principal components of feature maps along the channel dimension and calibrates the output of the other. Third, we propose the secondary fine-tuning (FT$^2$) strategy for NetVLAD-Linear (NVL). NetVLAD first learns feature vectors in a high-dimensional space and then compresses them into a lower-dimensional space via a single linear layer. Extensive experiments highlight our contributions and demonstrate the superiority of SuperPlace. Specifically, G$^2$M achieves promising results with only one-tenth of the feature dimensions compared to recent methods. Moreover, NVL-FT$^2$ ranks first on the MSLS leaderboard.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent visual place recognition (VPR) approaches have leveraged foundationmodels (FM) and introduced novel aggregation techniques. However, these methodshave failed to fully exploit key concepts of FM, such as the effectiveutilization of extensive training sets, and they have overlooked the potentialof classical aggregation methods, such as GeM and NetVLAD. Building on theseinsights, we revive classical feature aggregation methods and develop morefundamental VPR models, collectively termed SuperPlace. First, we introduce asupervised label alignment method that enables training across various VPRdatasets within a unified framework. Second, we propose G$^2$M, a compactfeature aggregation method utilizing two GeMs, where one GeM learns theprincipal components of feature maps along the channel dimension and calibratesthe output of the other. Third, we propose the secondary fine-tuning (FT$^2$)strategy for NetVLAD-Linear (NVL). NetVLAD first learns feature vectors in ahigh-dimensional space and then compresses them into a lower-dimensional spacevia a single linear layer. Extensive experiments highlight our contributionsand demonstrate the superiority of SuperPlace. Specifically, G$^2$M achievespromising results with only one-tenth of the feature dimensions compared torecent methods. Moreover, NVL-FT$^2$ ranks first on the MSLS leaderboard.</description>
      <author>example@mail.com (Bingxi Liu, Pengju Zhang, Li He, Hao Chen, Shiyi Guo, Yihong Wu, Jinqiang Cui, Hong Zhang)</author>
      <guid isPermaLink="false">2506.13073v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Contrastive Learning Using Out-Of-Distribution Data for Long-Tailed Dataset</title>
      <link>http://arxiv.org/abs/2506.12698v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究在长尾数据集上进行的自监督学习（SSL），旨在为下游任务如图像分类学习平衡且分离良好的表示。&lt;h4&gt;背景&lt;/h4&gt;现实世界中存在众多对象类别，它们的分布本质上是不平衡的。&lt;h4&gt;目的&lt;/h4&gt;为了在类别不平衡的数据集上实现鲁棒的自监督学习，研究利用使用在线普遍存在的未标记的分布外（OOD）数据训练的网络。&lt;h4&gt;方法&lt;/h4&gt;首先，通过反向传播提出的伪语义区分损失和领域区分损失来训练网络，使用领域内（ID）和采样的OOD数据。然后，通过无监督对比学习进一步优化网络，同时使用先前训练的网络作为引导网络。引导网络用于选择正/负样本和控制对比学习中的吸引/排斥力的强度。此外，将提取的嵌入空间蒸馏和迁移到训练网络以保持平衡性和分离性。&lt;h4&gt;主要发现&lt;/h4&gt;在四个公开的长尾数据集上的实验表明，提出的方法优于先前最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;该方法在长尾数据集上进行自监督学习时表现出色，为图像分类等下游任务提供了平衡且分离良好的表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work addresses the task of self-supervised learning (SSL) on along-tailed dataset that aims to learn balanced and well-separatedrepresentations for downstream tasks such as image classification. This task iscrucial because the real world contains numerous object categories, and theirdistributions are inherently imbalanced. Towards robust SSL on aclass-imbalanced dataset, we investigate leveraging a network trained usingunlabeled out-of-distribution (OOD) data that are prevalently available online.We first train a network using both in-domain (ID) and sampled OOD data byback-propagating the proposed pseudo semantic discrimination loss alongside adomain discrimination loss. The OOD data sampling and loss functions aredesigned to learn a balanced and well-separated embedding space. Subsequently,we further optimize the network on ID data by unsupervised contrastive learningwhile using the previously trained network as a guiding network. The guidingnetwork is utilized to select positive/negative samples and to control thestrengths of attractive/repulsive forces in contrastive learning. We alsodistil and transfer its embedding space to the training network to maintainbalancedness and separability. Through experiments on four publicly availablelong-tailed datasets, we demonstrate that the proposed method outperformsprevious state-of-the-art methods.</description>
      <author>example@mail.com (Cuong Manh Hoang, Yeejin Lee, Byeongkeun Kang)</author>
      <guid isPermaLink="false">2506.12698v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Directed Acyclic Graph Convolutional Networks</title>
      <link>http://arxiv.org/abs/2506.12218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为DAG Convolutional Network (DCN)的新型图神经网络架构，专门用于从支持在有向无环图（DAG）上的信号中进行卷积学习。DCN利用因果图滤波器学习节点表示，考虑了DAG固有的部分排序，这是传统GNN所不具备的强归纳偏置。此外，还提出了并行DCN (PDCN)，它将输入DAG信号送入并行因果图移位算子银行，并使用共享的多层感知器处理这些DAG感知特征，从而在保持满意的预测性能的同时，将模型复杂性从图大小中解耦。实验结果表明，(P)DCN在准确度、鲁棒性和计算效率方面与最先进的基线相比具有优势。&lt;h4&gt;背景&lt;/h4&gt;有向无环图（DAGs）在科学和工程应用中至关重要，如因果推理、调度和神经架构搜索。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为DCN的图神经网络架构，用于从DAG上的信号中进行卷积学习，并进一步提出PDCN，以提高计算效率和模型性能。&lt;h4&gt;方法&lt;/h4&gt;DCN利用因果图滤波器学习节点表示，PDCN采用并行因果图移位算子银行和共享的多层感知器处理DAG感知特征。&lt;h4&gt;主要发现&lt;/h4&gt;(P)DCN在准确度、鲁棒性和计算效率方面优于最先进的基线。&lt;h4&gt;结论&lt;/h4&gt;(P)DCN是一个从DAG结构化数据中进行深度学习的可行框架，其设计基于最初的（图）信号处理原则。&lt;h4&gt;翻译&lt;/h4&gt;Directed acyclic graphs (DAGs) are central to science and engineering applications including causal inference, scheduling, and neural architecture search. In this work, we introduce the DAG Convolutional Network (DCN), a novel graph neural network (GNN) architecture designed specifically for convolutional learning from signals supported on DAGs. The DCN leverages causal graph filters to learn nodal representations that account for the partial ordering inherent to DAGs, a strong inductive bias does not present in conventional GNNs. Unlike prior art in machine learning over DAGs, DCN builds on formal convolutional operations that admit spectral-domain representations. We further propose the Parallel DCN (PDCN), a model that feeds input DAG signals to a parallel bank of causal graph-shift operators and processes these DAG-aware features using a shared multilayer perceptron. This way, PDCN decouples model complexity from graph size while maintaining satisfactory predictive performance. The architectures' permutation equivariance and expressive power properties are also established. Comprehensive numerical tests across several tasks, datasets, and experimental conditions demonstrate that (P)DCN compares favorably with state-of-the-art baselines in terms of accuracy, robustness, and computational efficiency. These results position (P)DCN as a viable framework for deep learning from DAG-structured data that is designed from first (graph) signal processing principles.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Directed acyclic graphs (DAGs) are central to science and engineeringapplications including causal inference, scheduling, and neural architecturesearch. In this work, we introduce the DAG Convolutional Network (DCN), a novelgraph neural network (GNN) architecture designed specifically for convolutionallearning from signals supported on DAGs. The DCN leverages causal graph filtersto learn nodal representations that account for the partial ordering inherentto DAGs, a strong inductive bias does not present in conventional GNNs. Unlikeprior art in machine learning over DAGs, DCN builds on formal convolutionaloperations that admit spectral-domain representations. We further propose theParallel DCN (PDCN), a model that feeds input DAG signals to a parallel bank ofcausal graph-shift operators and processes these DAG-aware features using ashared multilayer perceptron. This way, PDCN decouples model complexity fromgraph size while maintaining satisfactory predictive performance. Thearchitectures' permutation equivariance and expressive power properties arealso established. Comprehensive numerical tests across several tasks, datasets,and experimental conditions demonstrate that (P)DCN compares favorably withstate-of-the-art baselines in terms of accuracy, robustness, and computationalefficiency. These results position (P)DCN as a viable framework for deeplearning from DAG-structured data that is designed from first (graph) signalprocessing principles.</description>
      <author>example@mail.com (Samuel Rey, Hamed Ajorlou, Gonzalo Mateos)</author>
      <guid isPermaLink="false">2506.12218v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>PRISM2: Unlocking Multi-Modal General Pathology AI with Clinical Dialogue</title>
      <link>http://arxiv.org/abs/2506.13063v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PRISM2是一个多模态病理学基础模型，通过临床对话训练，旨在实现可扩展和通用的病理人工智能。&lt;h4&gt;背景&lt;/h4&gt;现有的病理学基础模型在提供丰富的图块级别表示方面表现出色，但缺乏全切片图像理解能力，且未用大规模诊断数据进行训练，限制了它们在多样化下游任务上的性能。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够实现可扩展、通用的病理人工智能的模型，以支持诊断和预后决策。&lt;h4&gt;方法&lt;/h4&gt;PRISM2通过两个阶段的训练过程进行训练：第一阶段使用视觉-语言模型，通过对比和标题目标来对齐全切片嵌入与文本临床诊断；第二阶段解冻语言模型，以实现诊断对话并从隐藏状态中提取更多临床上有意义的表示。&lt;h4&gt;主要发现&lt;/h4&gt;PRISM2在诊断和生物标志物预测任务上取得了强大的性能，超过了包括PRISM和TITAN在内的先前切片级模型。它还引入了一种零样本是/否分类方法，该方法在无需提示调整或类别枚举的情况下，超过了CLIP风格的方法。&lt;h4&gt;结论&lt;/h4&gt;通过将视觉特征与临床推理对齐，PRISM2在数据丰富和样本量低的任务上提高了泛化能力，为构建能够辅助诊断和预后决策的通用病理人工智能代理提供了可扩展的途径。&lt;h4&gt;翻译&lt;/h4&gt;Recent pathology foundation models can provide rich tile-level representations but fall short of delivering general-purpose clinical utility without further extensive model development. These models lack whole-slide image (WSI) understanding and are not trained with large-scale diagnostic data, limiting their performance on diverse downstream tasks. We introduce PRISM2, a multi-modal slide-level foundation model trained via clinical dialogue to enable scalable, generalizable pathology AI. PRISM2 is trained on nearly 700,000 specimens (2.3 million WSIs) paired with real-world clinical diagnostic reports in a two-stage process. In Stage 1, a vision-language model is trained using contrastive and captioning objectives to align whole slide embeddings with textual clinical diagnosis. In Stage 2, the language model is unfrozen to enable diagnostic conversation and extract more clinically meaningful representations from hidden states. PRISM2 achieves strong performance on diagnostic and biomarker prediction tasks, outperforming prior slide-level models including PRISM and TITAN. It also introduces a zero-shot yes/no classification approach that surpasses CLIP-style methods without prompt tuning or class enumeration. By aligning visual features with clinical reasoning, PRISM2 improves generalization on both data-rich and low-sample tasks, offering a scalable path forward for building general pathology AI agents capable of assisting diagnostic and prognostic decisions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent pathology foundation models can provide rich tile-levelrepresentations but fall short of delivering general-purpose clinical utilitywithout further extensive model development. These models lack whole-slideimage (WSI) understanding and are not trained with large-scale diagnostic data,limiting their performance on diverse downstream tasks. We introduce PRISM2, amulti-modal slide-level foundation model trained via clinical dialogue toenable scalable, generalizable pathology AI. PRISM2 is trained on nearly700,000 specimens (2.3 million WSIs) paired with real-world clinical diagnosticreports in a two-stage process. In Stage 1, a vision-language model is trainedusing contrastive and captioning objectives to align whole slide embeddingswith textual clinical diagnosis. In Stage 2, the language model is unfrozen toenable diagnostic conversation and extract more clinically meaningfulrepresentations from hidden states. PRISM2 achieves strong performance ondiagnostic and biomarker prediction tasks, outperforming prior slide-levelmodels including PRISM and TITAN. It also introduces a zero-shot yes/noclassification approach that surpasses CLIP-style methods without prompt tuningor class enumeration. By aligning visual features with clinical reasoning,PRISM2 improves generalization on both data-rich and low-sample tasks, offeringa scalable path forward for building general pathology AI agents capable ofassisting diagnostic and prognostic decisions.</description>
      <author>example@mail.com (George Shaikovski, Eugene Vorontsov, Adam Casson, Julian Viret, Eric Zimmermann, Neil Tenenholtz, Yi Kan Wang, Jan H. Bernhard, Ran A. Godrich, Juan A. Retamero, Razik Yousfi, Nicolo Fusi, Thomas J. Fuchs, Kristen Severson, Siqi Liu)</author>
      <guid isPermaLink="false">2506.13063v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Information fusion strategy integrating pre-trained language model and contrastive learning for materials knowledge mining</title>
      <link>http://arxiv.org/abs/2506.12516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种创新的信息融合架构，用于预测材料复杂性质，如合金延展性，通过结合材料科学文献中的特定领域文本和定量物理描述符来克服传统方法难以量化的局限性。&lt;h4&gt;背景&lt;/h4&gt;尽管机器学习在材料设计中取得了革命性的进步，但预测如合金延展性等复杂性质仍然具有挑战性，因为加工条件和微观结构特征的影响难以通过传统还原论方法量化。&lt;h4&gt;目的&lt;/h4&gt;提出一种融合架构，旨在通过结合文本和物理描述符，克服预测材料复杂性质时的局限性。&lt;h4&gt;方法&lt;/h4&gt;该方法采用MatSciBERT进行高级文本理解，并采用对比学习自动提取关于加工参数和微观结构特征的隐含知识。&lt;h4&gt;主要发现&lt;/h4&gt;通过严格的消融研究和比较实验，该模型表现出优异的性能，在钛合金验证集和耐火多主元合金测试集中分别达到了0.849和0.680的决定系数（R2）值。&lt;h4&gt;结论&lt;/h4&gt;该系统方法为复杂材料系统中性质预测提供了一种全面的框架，其中定量描述符不完整，并为基础知识引导的材料设计和信息驱动材料发现奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;机器学习已经改变了材料设计，然而由于加工条件和微观结构特征的影响，这些特征难以通过传统的还原论方法量化，预测复杂性质如合金延展性仍然具有挑战性。在这里，我们提出了一种创新的信息融合架构，该架构结合了来自材料科学文献的特定领域文本与定量物理描述符，以克服这些限制。我们的框架采用MatSciBERT进行高级文本理解，并采用对比学习来自动提取关于加工参数和微观结构特征的隐含知识。通过严格的消融研究和比较实验，该模型展示了卓越的性能，在钛合金验证集和耐火多主元合金测试集中分别达到了0.849和0.680的决定系数（R2）值。这种系统方法为复杂材料系统中的性质预测提供了一种全面的框架，其中定量描述符不完整，并为基础知识引导的材料设计和信息驱动材料发现奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning has revolutionized materials design, yet predicting complexproperties like alloy ductility remains challenging due to the influence ofprocessing conditions and microstructural features that resist quantificationthrough traditional reductionist approaches. Here, we present an innovativeinformation fusion architecture that integrates domain-specific texts frommaterials science literature with quantitative physical descriptors to overcomethese limitations. Our framework employs MatSciBERT for advanced textualcomprehension and incorporates contrastive learning to automatically extractimplicit knowledge regarding processing parameters and microstructuralcharacteristics. Through rigorous ablation studies and comparative experiments,the model demonstrates superior performance, achieving coefficient ofdetermination (R2) values of 0.849 and 0.680 on titanium alloy validation setand refractory multi-principal-element alloy test set. This systematic approachprovides a holistic framework for property prediction in complex materialsystems where quantitative descriptors are incomplete and establishes afoundation for knowledge-guided materials design and informatics-drivenmaterials discovery.</description>
      <author>example@mail.com (Yongqian Peng, Zhouran Zhang, Longhui Zhang, Fengyuan Zhao, Yahao Li, Yicong Ye, Shuxin Bai)</author>
      <guid isPermaLink="false">2506.12516v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Stress-Testing Multimodal Foundation Models for Crystallographic Reasoning</title>
      <link>http://arxiv.org/abs/2506.13051v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个用于评估晶体学推理的基础模型的基准数据集和评估协议，旨在隔离泛化行为并强制物理约束。&lt;h4&gt;背景&lt;/h4&gt;评估晶体学推理的基础模型需要基准，这些基准能够隔离泛化行为并强制物理约束。&lt;h4&gt;目的&lt;/h4&gt;提出一个多尺度多晶体数据集和两个物理基础的评估协议，以测试多模态生成模型。&lt;h4&gt;方法&lt;/h4&gt;使用空间排除基准和成分排除基准来评估九个视觉-语言基础模型，通过晶体图像和文本上下文生成结构注释，并评估响应的相对误差、物理一致性指数和幻觉分数。&lt;h4&gt;主要发现&lt;/h4&gt;这些基准建立了可重复的、物理信息丰富的框架，用于评估大规模多模态模型中的泛化、一致性和可靠性。&lt;h4&gt;结论&lt;/h4&gt;该研究为评估大型多模态模型提供了有价值的基准和数据集。&lt;h4&gt;翻译&lt;/h4&gt;This work introduces a multiscale multicrystal dataset with two physically grounded evaluation protocols to stress-test multimodal generative models. The Spatial-Exclusion benchmark withholds all supercells of a given radius from a diverse dataset, enabling controlled assessments of spatial interpolation and extrapolation. The Compositional-Exclusion benchmark omits all samples of a specific chemical composition, probing generalization across stoichiometries. Nine vision--language foundation models are prompted with crystallographic images and textual context to generate structural annotations. Responses are evaluated via (i) relative errors in lattice parameters and density, (ii) a physics-consistency index penalizing volumetric violations, and (iii) a hallucination score capturing geometric outliers and invalid space-group predictions. These benchmarks establish a reproducible, physically informed framework for assessing generalization, consistency, and reliability in large-scale multimodal models. Dataset and code are available at https://github.com/KurbanIntelligenceLab/StressTestingMMFMinCR.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Evaluating foundation models for crystallographic reasoning requiresbenchmarks that isolate generalization behavior while enforcing physicalconstraints. This work introduces a multiscale multicrystal dataset with twophysically grounded evaluation protocols to stress-test multimodal generativemodels. The Spatial-Exclusion benchmark withholds all supercells of a givenradius from a diverse dataset, enabling controlled assessments of spatialinterpolation and extrapolation. The Compositional-Exclusion benchmark omitsall samples of a specific chemical composition, probing generalization acrossstoichiometries. Nine vision--language foundation models are prompted withcrystallographic images and textual context to generate structural annotations.Responses are evaluated via (i) relative errors in lattice parameters anddensity, (ii) a physics-consistency index penalizing volumetric violations, and(iii) a hallucination score capturing geometric outliers and invalidspace-group predictions. These benchmarks establish a reproducible, physicallyinformed framework for assessing generalization, consistency, and reliabilityin large-scale multimodal models. Dataset and code are available athttps://github.com/KurbanIntelligenceLab/StressTestingMMFMinCR.</description>
      <author>example@mail.com (Can Polat, Hasan Kurban, Erchin Serpedin, Mustafa Kurban)</author>
      <guid isPermaLink="false">2506.13051v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>InverTune: Removing Backdoors from Multimodal Contrastive Learning Models via Trigger Inversion and Activation Tuning</title>
      <link>http://arxiv.org/abs/2506.12411v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了InverTune，这是第一个针对多模态模型的低假设后门防御框架，无需攻击目标的先验知识或访问受污染的数据集。InverTune通过三个关键组件有效地识别和移除后门，提高了对后门攻击的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;多模态对比学习模型如CLIP在视觉-语言对齐方面表现出色，但其易受后门攻击，这带来了严重的安全风险。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的防御框架，以保护多模态模型免受后门攻击，同时不牺牲模型性能。&lt;h4&gt;方法&lt;/h4&gt;InverTune通过以下步骤实现防御：1）通过对抗模拟暴露攻击签名，通过分析模型响应模式概率地识别目标标签；2）开发梯度反转技术通过激活模式分析重建潜在触发器；3）采用聚类引导的微调策略，使用少量任意清洁数据擦除后门功能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，InverTune将平均攻击成功率（ASR）降低了97.87%，同时将清洁准确率（CA）的下降限制在3.07%。&lt;h4&gt;结论&lt;/h4&gt;InverTune为保护多模态系统建立了新的范式，在基础模型部署中提高了安全性，同时不损害性能。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal contrastive learning models like CLIP have demonstrated remarkable vision-language alignment capabilities, yet their vulnerability to backdoor attacks poses critical security risks. Attackers can implant latent triggers that persist through downstream tasks, enabling malicious control of model behavior upon trigger presentation. Despite great success in recent defense mechanisms, they remain impractical due to strong assumptions about attacker knowledge or excessive clean data requirements. In this paper, we introduce InverTune, the first backdoor defense framework for multimodal models under minimal attacker assumptions, requiring neither prior knowledge of attack targets nor access to the poisoned dataset. Unlike existing defense methods that rely on the same dataset used in the poisoning stage, InverTune effectively identifies and removes backdoor artifacts through three key components, achieving robust protection against backdoor attacks. Specifically, InverTune first exposes attack signatures through adversarial simulation, probabilistically identifying the target label by analyzing model response patterns. Building on this, we develop a gradient inversion technique to reconstruct latent triggers through activation pattern analysis. Finally, a clustering-guided fine-tuning strategy is employed to erase the backdoor function with only a small amount of arbitrary clean data, while preserving the original model capabilities. Experimental results show that InverTune reduces the average attack success rate (ASR) by 97.87% against the state-of-the-art (SOTA) attacks while limiting clean accuracy (CA) degradation to just 3.07%. This work establishes a new paradigm for securing multimodal systems, advancing security in foundation model deployment without compromising performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal contrastive learning models like CLIP have demonstrated remarkablevision-language alignment capabilities, yet their vulnerability to backdoorattacks poses critical security risks. Attackers can implant latent triggersthat persist through downstream tasks, enabling malicious control of modelbehavior upon trigger presentation. Despite great success in recent defensemechanisms, they remain impractical due to strong assumptions about attackerknowledge or excessive clean data requirements. In this paper, we introduceInverTune, the first backdoor defense framework for multimodal models underminimal attacker assumptions, requiring neither prior knowledge of attacktargets nor access to the poisoned dataset. Unlike existing defense methodsthat rely on the same dataset used in the poisoning stage, InverTuneeffectively identifies and removes backdoor artifacts through three keycomponents, achieving robust protection against backdoor attacks. Specifically,InverTune first exposes attack signatures through adversarial simulation,probabilistically identifying the target label by analyzing model responsepatterns. Building on this, we develop a gradient inversion technique toreconstruct latent triggers through activation pattern analysis. Finally, aclustering-guided fine-tuning strategy is employed to erase the backdoorfunction with only a small amount of arbitrary clean data, while preserving theoriginal model capabilities. Experimental results show that InverTune reducesthe average attack success rate (ASR) by 97.87% against the state-of-the-art(SOTA) attacks while limiting clean accuracy (CA) degradation to just 3.07%.This work establishes a new paradigm for securing multimodal systems, advancingsecurity in foundation model deployment without compromising performance.</description>
      <author>example@mail.com (Mengyuan Sun, Yu Li, Yuchen Liu, Bo Du, Yunjie Ge)</author>
      <guid isPermaLink="false">2506.12411v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>PROTOCOL: Partial Optimal Transport-enhanced Contrastive Learning for Imbalanced Multi-view Clustering</title>
      <link>http://arxiv.org/abs/2506.12408v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 7 figures, accepted by the Forty-Second International  Conference on Machine Learning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对不平衡多视角聚类问题，提出了一种名为PROTOCOL的新框架，用于在不平衡多视角数据上进行聚类。&lt;h4&gt;背景&lt;/h4&gt;现有的对比多视角聚类方法假设类分布平衡，但实际多视角数据往往存在类不平衡分布，导致性能下降。&lt;h4&gt;目的&lt;/h4&gt;为了解决类不平衡分布的问题，本文旨在感知类不平衡分布并减轻少数样本的表示退化。&lt;h4&gt;方法&lt;/h4&gt;PROTOCOL通过将多视角特征映射到共识空间，将不平衡聚类问题转化为部分最优传输（POT）问题，并使用渐进质量约束和加权KL散度来增强类分布。同时，在特征和类别层面上，通过logit调整和类别敏感学习来提升少数样本的表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，PROTOCOL在不平衡多视角数据上的聚类性能显著提高，填补了该领域的关键研究空白。&lt;h4&gt;结论&lt;/h4&gt;PROTOCOL框架为不平衡多视角聚类提供了一种有效的方法，显著提升了聚类性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While contrastive multi-view clustering has achieved remarkable success, itimplicitly assumes balanced class distribution. However, real-world multi-viewdata primarily exhibits class imbalance distribution. Consequently, existingmethods suffer performance degradation due to their inability to perceive andmodel such imbalance. To address this challenge, we present the firstsystematic study of imbalanced multi-view clustering, focusing on twofundamental problems: i. perceiving class imbalance distribution, and ii.mitigating representation degradation of minority samples. We propose PROTOCOL,a novel PaRtial Optimal TranspOrt-enhanced COntrastive Learning framework forimbalanced multi-view clustering. First, for class imbalance perception, we mapmulti-view features into a consensus space and reformulate the imbalancedclustering as a partial optimal transport (POT) problem, augmented withprogressive mass constraints and weighted KL divergence for classdistributions. Second, we develop a POT-enhanced class-rebalanced contrastivelearning at both feature and class levels, incorporating logit adjustment andclass-sensitive learning to enhance minority sample representations. Extensiveexperiments demonstrate that PROTOCOL significantly improves clusteringperformance on imbalanced multi-view data, filling a critical research gap inthis field.</description>
      <author>example@mail.com (Xuqian Xue, Yiming Lei, Qi Cai, Hongming Shan, Junping Zhang)</author>
      <guid isPermaLink="false">2506.12408v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Antibody Foundational Model : Ab-RoBERTa</title>
      <link>http://arxiv.org/abs/2506.13006v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 page, 3 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了抗体工程领域的研究进展，以及基于Transformer的蛋白质大语言模型在抗体序列处理中的应用。&lt;h4&gt;背景&lt;/h4&gt;抗体治疗的重要性日益凸显，抗体工程成为研究热点。基于Transformer的蛋白质大语言模型在蛋白质序列设计和结构预测方面展现出潜力。&lt;h4&gt;目的&lt;/h4&gt;开发一种专门用于处理抗体序列的RoBERTa-based抗体特定大语言模型（Ab-RoBERTa），以支持抗体相关研究应用。&lt;h4&gt;方法&lt;/h4&gt;构建了Ab-RoBERTa模型，并在Observed Antibody Space (OAS)数据库上进行了训练。&lt;h4&gt;主要发现&lt;/h4&gt;Ab-RoBERTa在性能上优于基于BERT的蛋白质模型ProtBERT，同时参数量更小，便于在抗体相关应用中部署。&lt;h4&gt;结论&lt;/h4&gt;Ab-RoBERTa模型为抗体相关研究提供了新的工具，并可通过https://huggingface.co/mogam-ai/Ab-RoBERTa公开获取。&lt;h4&gt;翻译&lt;/h4&gt;随着基于抗体的治疗越来越受到重视，抗体工程已成为研究和开发的关键领域。基于Transformer的蛋白质大语言模型在蛋白质序列设计和结构预测方面的最新进展展示了其在蛋白质序列设计方面的应用前景。此外，大规模抗体数据集，如Observed Antibody Space (OAS)数据库的可用性，为专门用于处理抗体序列的大语言模型的发展开辟了新的途径。在这些模型中，RoBERTa在性能上优于BERT，同时与基于BERT的蛋白质模型ProtBERT相比，参数量更小（125M），这使得其在抗体相关应用中的部署更加高效。然而，尽管RoBERTa架构具有许多优点，但基于它的抗体特定基础模型对研究界仍然难以接触。在本研究中，我们引入了Ab-RoBERTa，这是一种基于RoBERTa的抗体特定大语言模型，可在https://huggingface.co/mogam-ai/Ab-RoBERTa公开获取。这个资源旨在支持包括抗原结合位点预测或人源评估在内的各种抗体相关研究应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing prominence of antibody-based therapeutics, antibodyengineering has gained increasing attention as a critical area of research anddevelopment. Recent progress in transformer-based protein large language models(LLMs) has demonstrated promising applications in protein sequence design andstructural prediction. Moreover, the availability of large-scale antibodydatasets such as the Observed Antibody Space (OAS) database has opened newavenues for the development of LLMs specialized for processing antibodysequences. Among these, RoBERTa has demonstrated improved performance relativeto BERT, while maintaining a smaller parameter count (125M) compared to theBERT-based protein model, ProtBERT (420M). This reduced model size enables moreefficient deployment in antibody-related applications. However, despite thenumerous advantages of the RoBERTa architecture, antibody-specific foundationalmodels built upon it have remained inaccessible to the research community. Inthis study, we introduce Ab-RoBERTa, a RoBERTa-based antibody-specific LLM,which is publicly available at https://huggingface.co/mogam-ai/Ab-RoBERTa. Thisresource is intended to support a wide range of antibody-related researchapplications including paratope prediction or humanness assessment.</description>
      <author>example@mail.com (Eunna Huh, Hyeonsu Lee, Hyunjin Shin)</author>
      <guid isPermaLink="false">2506.13006v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Boundary-Aware Vision Transformer for Angiography Vascular Network Segmentation</title>
      <link>http://arxiv.org/abs/2506.12980v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 2 figures, 2 tables; submitted to IPTA-2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BAVT的边界感知视觉Transformer，用于冠状动脉血管造影中的血管结构分割，通过结合ViT编码器和边界感知监督，在DCA-1数据集上实现了优于CNN和混合基线的分割性能。&lt;h4&gt;背景&lt;/h4&gt;血管结构的准确分割在医学图像分析中是一个核心挑战，因为血管具有细长、对比度低的特点，传统的卷积神经网络（CNN）往往无法保持拓扑连续性，而基于ViT的模型虽然在全局上下文建模方面表现出色，但缺乏精确的边界意识。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种能够精确分割血管边界的方法，以应对冠状动脉血管造影中血管结构分割的挑战。&lt;h4&gt;方法&lt;/h4&gt;引入了BAVT，一种基于ViT的架构，通过边缘感知损失函数引导分割过程，使其更关注血管的细粒度边界。BAVT采用最小化、可扩展的结构，与大规模视觉基础模型（VFM）预训练完全兼容。&lt;h4&gt;主要发现&lt;/h4&gt;在DCA-1冠状动脉血管造影数据集上，BAVT在医学图像分割指标上表现优异，优于CNN和混合基线。&lt;h4&gt;结论&lt;/h4&gt;BAVT结合了简单的ViT编码器和边界感知监督，对于临床级血管分割是有效的。&lt;h4&gt;翻译&lt;/h4&gt;Accurate segmentation of vascular structures in coronary angiography remains a core challenge in medical image analysis due to the complexity of elongated, thin, and low-contrast vessels. Classical convolutional neural networks (CNNs) often fail to preserve topological continuity, while recent Vision Transformer (ViT)-based models, although strong in global context modeling, lack precise boundary awareness. In this work, we introduce BAVT, a Boundary-Aware Vision Transformer, a ViT-based architecture enhanced with an edge-aware loss that explicitly guides the segmentation toward fine-grained vascular boundaries. Unlike hybrid transformer-CNN models, BAVT retains a minimal, scalable structure that is fully compatible with large-scale vision foundation model (VFM) pretraining. We validate our approach on the DCA-1 coronary angiography dataset, where BAVT achieves superior performance across medical image segmentation metrics outperforming both CNN and hybrid baselines. These results demonstrate the effectiveness of combining plain ViT encoders with boundary-aware supervision for clinical-grade vascular segmentation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate segmentation of vascular structures in coronary angiography remainsa core challenge in medical image analysis due to the complexity of elongated,thin, and low-contrast vessels. Classical convolutional neural networks (CNNs)often fail to preserve topological continuity, while recent Vision Transformer(ViT)-based models, although strong in global context modeling, lack preciseboundary awareness. In this work, we introduce BAVT, a Boundary-Aware VisionTransformer, a ViT-based architecture enhanced with an edge-aware loss thatexplicitly guides the segmentation toward fine-grained vascular boundaries.Unlike hybrid transformer-CNN models, BAVT retains a minimal, scalablestructure that is fully compatible with large-scale vision foundation model(VFM) pretraining. We validate our approach on the DCA-1 coronary angiographydataset, where BAVT achieves superior performance across medical imagesegmentation metrics outperforming both CNN and hybrid baselines. These resultsdemonstrate the effectiveness of combining plain ViT encoders withboundary-aware supervision for clinical-grade vascular segmentation.</description>
      <author>example@mail.com (Nabil Hezil, Suraj Singh, Vita Vlasova, Oleg Rogov, Ahmed Bouridane, Rifat Hamoudi)</author>
      <guid isPermaLink="false">2506.12980v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>SemanticST: Spatially Informed Semantic Graph Learning for Clustering, Integration, and Scalable Analysis of Spatial Transcriptomics</title>
      <link>http://arxiv.org/abs/2506.11491v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 Figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SemanticST是一种基于深度学习的框架，用于空间转录组学分析，它通过构建多语义图来建模细胞环境，并提高了分析准确性和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;空间转录组学技术提供了组织结构和疾病异质性的空间分辨率基因表达分析，但现有方法存在噪声数据、可扩展性有限和复杂细胞关系建模不足的问题。&lt;h4&gt;目的&lt;/h4&gt;提出SemanticST，旨在解决当前空间转录组学分析中存在的挑战，提供一种可扩展、可解释且基于生物学的框架。&lt;h4&gt;方法&lt;/h4&gt;SemanticST通过构建多个特定于上下文的图来捕捉空间邻近性、基因表达相似性和组织域结构，并使用注意力启发策略融合这些嵌入。此外，使用社区感知的min-cut损失来提高鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;SemanticST在四个平台和多种人类和小鼠组织中进行了基准测试，与DeepST、GraphST和IRIS相比，在ARI、NMI和轨迹保真度方面提高了20个百分点。在乳腺癌数据重新分析中，揭示了罕见且具有临床意义的亚群。&lt;h4&gt;结论&lt;/h4&gt;SemanticST为空间转录组学分析提供了一种可扩展、可解释且基于生物学的框架，能够实现组织类型和疾病中的稳健发现，并为空间解析的组织图谱和下一代精准医学铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;Spatial transcriptomics (ST) technologies enable gene expression profiling with spatial resolution, offering unprecedented insights into tissue organization and disease heterogeneity. However, current analysis methods often struggle with noisy data, limited scalability, and inadequate modelling of complex cellular relationships. We present SemanticST, a biologically informed, graph-based deep learning framework that models diverse cellular contexts through multi-semantic graph construction. SemanticST builds multiple context-specific graphs capturing spatial proximity, gene expression similarity, and tissue domain structure, and learns disentangled embeddings for each. These are fused using an attention-inspired strategy to yield a unified, biologically meaningful representation. A community-aware min-cut loss improves robustness over contrastive learning, particularly in sparse ST data. SemanticST supports mini-batch training, making it the first graph neural network scalable to large-scale datasets such as Xenium (500,000 cells). Benchmarking across four platforms (Visium, Slide-seq, Stereo-seq, Xenium) and multiple human and mouse tissues shows consistent 20 percentage gains in ARI, NMI, and trajectory fidelity over DeepST, GraphST, and IRIS. In re-analysis of breast cancer Xenium data, SemanticST revealed rare and clinically significant niches, including triple receptor-positive clusters, spatially distinct DCIS-to-IDC transition zones, and FOXC2 tumour-associated myoepithelial cells, suggesting non-canonical EMT programs with stem-like features. SemanticST thus provides a scalable, interpretable, and biologically grounded framework for spatial transcriptomics analysis, enabling robust discovery across tissue types and diseases, and paving the way for spatially resolved tissue atlases and next-generation precision medicine.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial transcriptomics (ST) technologies enable gene expression profilingwith spatial resolution, offering unprecedented insights into tissueorganization and disease heterogeneity. However, current analysis methods oftenstruggle with noisy data, limited scalability, and inadequate modelling ofcomplex cellular relationships. We present SemanticST, a biologically informed,graph-based deep learning framework that models diverse cellular contextsthrough multi-semantic graph construction. SemanticST builds multiplecontext-specific graphs capturing spatial proximity, gene expressionsimilarity, and tissue domain structure, and learns disentangled embeddings foreach. These are fused using an attention-inspired strategy to yield a unified,biologically meaningful representation. A community-aware min-cut loss improvesrobustness over contrastive learning, particularly in sparse ST data.SemanticST supports mini-batch training, making it the first graph neuralnetwork scalable to large-scale datasets such as Xenium (500,000 cells).Benchmarking across four platforms (Visium, Slide-seq, Stereo-seq, Xenium) andmultiple human and mouse tissues shows consistent 20 percentage gains in ARI,NMI, and trajectory fidelity over DeepST, GraphST, and IRIS. In re-analysis ofbreast cancer Xenium data, SemanticST revealed rare and clinically significantniches, including triple receptor-positive clusters, spatially distinctDCIS-to-IDC transition zones, and FOXC2 tumour-associated myoepithelial cells,suggesting non-canonical EMT programs with stem-like features. SemanticST thusprovides a scalable, interpretable, and biologically grounded framework forspatial transcriptomics analysis, enabling robust discovery across tissue typesand diseases, and paving the way for spatially resolved tissue atlases andnext-generation precision medicine.</description>
      <author>example@mail.com (Roxana Zahedi, Ahmadreza Argha, Nona Farbehi, Ivan Bakhshayeshi, Youqiong Ye, Nigel H. Lovell, Hamid Alinejad-Rokny)</author>
      <guid isPermaLink="false">2506.11491v2</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>VideoDeepResearch: Long Video Understanding With Agentic Tool Using</title>
      <link>http://arxiv.org/abs/2506.10821v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为VideoDeepResearch的新型框架，用于解决长视频理解（LVU）问题，通过使用纯文本的大型推理模型（LRM）和模块化的多模态工具包，实现了对LVU任务的显著提升。&lt;h4&gt;背景&lt;/h4&gt;长视频理解是当前多模态大型语言模型（MLLMs）面临的挑战，需要扩展的上下文窗口、强大的视觉感知能力和专业领域的知识。&lt;h4&gt;目的&lt;/h4&gt;挑战传统观点，证明无需扩展上下文窗口的MLLMs也能有效解决LVU任务。&lt;h4&gt;方法&lt;/h4&gt;提出VideoDeepResearch框架，该框架使用纯文本LRM和包括多模态检索器和视觉感知器在内的模块化多模态工具包，通过推理和工具使用来解决问题。&lt;h4&gt;主要发现&lt;/h4&gt;在多个LVU基准测试中，VideoDeepResearch在MLVU、Video-MME和LVBench上分别比现有的MLLM基线提高了9.6%、6.6%和3.9%。&lt;h4&gt;结论&lt;/h4&gt;这些发现表明，代理系统在克服LVU问题中的关键挑战方面具有巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a novel framework called VideoDeepResearch for addressing the Long Video Understanding (LVU) problem. The framework uses a text-only large reasoning model (LRM) and a modular multi-modal toolkit, including multimodal retrievers and visual perceivers, achieving significant improvements in LVU tasks. The background of the study is that LVU presents a significant challenge for current multi-modal large language models (MLLMs) due to the task's inherent complexity and context window constraint. The purpose of this work is to challenge the common belief that addressing LVU tasks requires foundation MLLMs with extended context windows, strong visual perception capabilities, and proficient domain expertise. The method proposed is the VideoDeepResearch framework, which relies solely on a text-only large reasoning model (LRM) combined with a modular multi-modal toolkit, including multimodal retrievers and visual perceivers, all of which are readily available in practice. The main findings are that VideoDeepResearch achieves substantial improvements over existing MLLM baselines, surpassing the previous state-of-the-art by 9.6%, 6.6%, and 3.9% on MLVU (test), LVBench, and LongVideoBench, respectively. These findings highlight the promise of agentic systems in overcoming key challenges in LVU problems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/yhy-2000/videodeepresearch&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long video understanding (LVU) presents a significant challenge for currentmulti-modal large language models (MLLMs) due to the task's inherent complexityand context window constraint. It is widely assumed that addressing LVU tasksrequires foundation MLLMs with extended context windows, strong visualperception capabilities, and proficient domain expertise. In this work, wechallenge this common belief by introducing VideoDeepResearch, a novel agenticframework for long video understanding. Our approach relies solely on atext-only large reasoning model (LRM) combined with a modular multi-modaltoolkit, including multimodal retrievers and visual perceivers, all of whichare readily available in practice. For each LVU task, the system formulates aproblem-solving strategy through reasoning, while selectively accessing andutilizing essential video content via tool using. We conduct extensiveexperiments on popular LVU benchmarks, including MLVU, Video-MME, and LVBench.Our results demonstrate that VideoDeepResearch achieves substantialimprovements over existing MLLM baselines, surpassing the previousstate-of-the-art by 9.6%, 6.6%, and 3.9% on MLVU (test), LVBench, andLongVideoBench, respectively. These findings highlight the promise of agenticsystems in overcoming key challenges in LVU problems.</description>
      <author>example@mail.com (Huaying Yuan, Zheng Liu, Junjie Zhou, Hongjin Qian, Ji-Rong Wen, Zhicheng Dou)</author>
      <guid isPermaLink="false">2506.10821v2</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Rating-Based Reinforcement Learning to Effectively Leverage Feedback from Large Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.12822v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于AI反馈的增强型评价型强化学习（ERL-VLM）方法，用于从AI生成的反馈中有效学习奖励函数，以提高强化学习的效率和自主性。&lt;h4&gt;背景&lt;/h4&gt;设计有效的奖励函数是强化学习中的基本挑战，因为这通常需要大量的人类努力和领域专业知识。虽然从人类反馈中学习的强化学习已经成功地将代理与人类意图对齐，但获取高质量的反馈成本高昂且劳动密集，限制了其可扩展性。&lt;h4&gt;目的&lt;/h4&gt;旨在通过利用AI生成的反馈来减少对人类监督的依赖，从而实现强化学习的可扩展性。&lt;h4&gt;方法&lt;/h4&gt;ERL-VLM查询大型视觉语言模型（VLMs）以获取个体轨迹的绝对评分，从而提供更具表达性和提高样本效率的反馈。此外，针对数据不平衡和噪声标签引起的不稳定性问题，提出了基于评分的强化学习的关键改进。&lt;h4&gt;主要发现&lt;/h4&gt;通过在低级和高级控制任务上的广泛实验，证明了ERL-VLM在奖励生成方面显著优于现有的基于VLM的方法。&lt;h4&gt;结论&lt;/h4&gt;结果表明，AI反馈具有在最小人类干预下扩展强化学习的潜力，为更自主和高效的奖励学习铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;Designing effective reward functions remains a fundamental challenge in reinforcement learning (RL), as it often requires extensive human effort and domain expertise. While RL from human feedback has been successful in aligning agents with human intent, acquiring high-quality feedback is costly and labor-intensive, limiting its scalability. Recent advancements in foundation models present a promising alternative--leveraging AI-generated feedback to reduce reliance on human supervision in reward learning. Building on this paradigm, we introduce ERL-VLM, an enhanced rating-based RL method that effectively learns reward functions from AI feedback. Unlike prior methods that rely on pairwise comparisons, ERL-VLM queries large vision-language models (VLMs) for absolute ratings of individual trajectories, enabling more expressive feedback and improved sample efficiency. Additionally, we propose key enhancements to rating-based RL, addressing instability issues caused by data imbalance and noisy labels. Through extensive experiments across both low-level and high-level control tasks, we demonstrate that ERL-VLM significantly outperforms existing VLM-based reward generation methods. Our results demonstrate the potential of AI feedback for scaling RL with minimal human intervention, paving the way for more autonomous and efficient reward learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Designing effective reward functions remains a fundamental challenge inreinforcement learning (RL), as it often requires extensive human effort anddomain expertise. While RL from human feedback has been successful in aligningagents with human intent, acquiring high-quality feedback is costly andlabor-intensive, limiting its scalability. Recent advancements in foundationmodels present a promising alternative--leveraging AI-generated feedback toreduce reliance on human supervision in reward learning. Building on thisparadigm, we introduce ERL-VLM, an enhanced rating-based RL method thateffectively learns reward functions from AI feedback. Unlike prior methods thatrely on pairwise comparisons, ERL-VLM queries large vision-language models(VLMs) for absolute ratings of individual trajectories, enabling moreexpressive feedback and improved sample efficiency. Additionally, we proposekey enhancements to rating-based RL, addressing instability issues caused bydata imbalance and noisy labels. Through extensive experiments across bothlow-level and high-level control tasks, we demonstrate that ERL-VLMsignificantly outperforms existing VLM-based reward generation methods. Ourresults demonstrate the potential of AI feedback for scaling RL with minimalhuman intervention, paving the way for more autonomous and efficient rewardlearning.</description>
      <author>example@mail.com (Tung Minh Luu, Younghwan Lee, Donghoon Lee, Sunho Kim, Min Jun Kim, Chang D. Yoo)</author>
      <guid isPermaLink="false">2506.12822v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Fuse: Modality-Aware Adaptive Scheduling for Robust Multimodal Foundation Models</title>
      <link>http://arxiv.org/abs/2506.12733v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Modality-Aware Adaptive Fusion Scheduling (MA-AFS)，这是一种能够动态调节不同模态贡献的通用框架，旨在提高视觉-语言任务的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态基础模型在视觉-语言任务上取得了显著的进展，但往往采用固定的或特定于任务的融合策略，忽略了模态可靠性和样本复杂性的内在变异性。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够自适应地调整模态融合权重的框架，以增强模型在噪声、缺失或错位输入下的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;MA-AFS引入了一个轻量级的神经网络调度器，通过整合视觉和文本熵信号以及跨模态一致性线索来预测模态融合权重。融合过程被定义为可微分的调度机制。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，MA-AFS在图像-文本检索、字幕和视觉问答等任务上，相较于CLIP、ALBEF和BLIP等强基线，实现了持续的性能提升。此外，MA-AFS在模态损坏情况下表现出更好的鲁棒性，在领域迁移中具有更强的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;MA-AFS强调了自适应融合的重要性，为可靠和不确定性感知的多模态学习开辟了有前景的方向。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为Modality-Aware Adaptive Fusion Scheduling (MA-AFS)的多模态基础模型，该模型能够根据实例动态调整不同模态的贡献，从而在视觉-语言任务上实现性能提升。实验结果表明，与CLIP、ALBEF和BLIP等基线相比，MA-AFS在图像-文本检索、字幕和视觉问答等任务上取得了显著的性能改进，并且表现出更好的鲁棒性和泛化能力。该研究强调了自适应融合在多模态学习中的重要性，为未来的研究指明了方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal foundation models have achieved impressive progress across a widerange of vision-language tasks. However, existing approaches often adopt fixedor task-specific fusion strategies, neglecting the intrinsic variability ofmodality reliability and sample complexity. In this paper, we proposeModality-Aware Adaptive Fusion Scheduling (MA-AFS), a general framework thatlearns to dynamically modulate the contribution of each modality on aper-instance basis. MA-AFS introduces a lightweight neural scheduler thatpredicts modality fusion weights by integrating visual and textual entropysignals along with cross-modal agreement cues. This enables the model toadaptively emphasize more reliable modalities, especially under noisy, missing,or misaligned inputs. We formulate the fusion process as a differentiablescheduling mechanism, analyze its theoretical consistency and regularizationeffect, and demonstrate that it improves robustness without increasing modelcapacity significantly. Extensive experiments on image-text retrieval,captioning, and visual question answering show that MA-AFS achieves consistentperformance gains over strong baselines such as CLIP, ALBEF, and BLIP.Moreover, MA-AFS exhibits improved robustness under modality corruption andenhanced generalization under domain shifts. Our work highlights the importanceof adaptive fusion and opens a promising direction toward reliable anduncertainty-aware multimodal learning.</description>
      <author>example@mail.com (Liam Bennett, Mason Clark, Lucas Anderson, Hana Satou, Olivia Martinez)</author>
      <guid isPermaLink="false">2506.12733v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Clinical Models with Pseudo Data for De-identification</title>
      <link>http://arxiv.org/abs/2506.12674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在隐私保护下，使用红字文本进行预训练的模型在脱敏任务上的效果，并提出了一种新的方法来生成伪数据集和预训练模型。&lt;h4&gt;背景&lt;/h4&gt;许多模型出于隐私保护的原因在红字文本上预训练，临床基础模型通常在去标识化文本上训练，这些文本使用特殊语法（掩码）文本代替受保护的医疗信息。&lt;h4&gt;目的&lt;/h4&gt;理解在红字文本上训练模型的效果，并提出改进的方法。&lt;h4&gt;方法&lt;/h4&gt;在包含红字文本和替换为现实伪文本的数据集上预训练了几个编码器模型，然后对这些模型进行微调以完成受保护的健康信息脱敏任务。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法在脱敏任务上显著优于以前的基线，包括新的训练建议、红字文本替换用于生成伪数据集、预训练嵌入和微调特定任务模型，以及用于实验的伪训练数据集生成和模型源代码的免费提供。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效提高在红字文本上预训练的模型在脱敏任务上的性能。&lt;h4&gt;翻译&lt;/h4&gt;许多模型出于隐私保护的原因在红字文本上进行预训练。临床基础模型通常在去标识化文本上进行训练，这些文本使用特殊的语法（掩码）文本代替受保护的医疗信息。尽管这些模型越来越受欢迎，但很少有人努力去理解在红字文本上训练它们的效果。在这项工作中，我们在包含红字文本和替换为现实伪文本的数据集上预训练了几个编码器模型。然后，我们对这些模型进行了微调以完成受保护的健康信息脱敏任务，并展示了我们的方法如何显著优于以前的基线。这项工作的贡献包括：a) 我们的独特且令人惊讶的训练建议发现，b) 用于生成伪数据集的红字文本替换，c) 预训练嵌入和微调特定任务模型，以及d) 在我们的实验中使用的伪训练数据集生成和模型源代码的免费提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many models are pretrained on redacted text for privacy reasons. Clinicalfoundation models are often trained on de-identified text, which uses specialsyntax (masked) text in place of protected health information. Even thoughthese models have increased in popularity, there has been little effort inunderstanding the effects of training them on redacted text. In this work, wepretrain several encoder-only models on a dataset that contains redacted textand a version with replaced realistic pseudo text. We then fine-tuned modelsfor the protected health information de-identification task and show how ourmethods significantly outperform previous baselines. The contributions of thiswork include: a) our novel, and yet surprising findings with trainingrecommendations, b) redacted text replacements used to produce the pseudodataset, c) pretrained embeddings and fine-tuned task specific models, and d)freely available pseudo training dataset generation and model source code usedin our experiments.</description>
      <author>example@mail.com (Paul Landes, Aaron J Chaise, Tarak Nath Nandi, Ravi K Madduri)</author>
      <guid isPermaLink="false">2506.12674v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications</title>
      <link>http://arxiv.org/abs/2506.12594v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  95 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文调查了深度研究系统领域，这是一个由大型语言模型、高级信息检索和自主推理能力驱动的AI应用，它通过自动化复杂研究工作流程而快速发展。文章分析了自2023年以来出现的80多个商业和非商业实现，包括OpenAI/Deep Research、Gemini/Deep Research、Perplexity/Deep Research以及众多开源替代方案。&lt;h4&gt;背景&lt;/h4&gt;深度研究系统是一个快速发展的领域，通过集成大型语言模型、高级信息检索和自主推理能力来自动化复杂研究工作流程。&lt;h4&gt;目的&lt;/h4&gt;分析深度研究系统的技术实现和特点，并提出一个对系统进行分类的新颖的层次分类法。&lt;h4&gt;方法&lt;/h4&gt;通过全面审查，文章提出了一个根据四个基本技术维度对系统进行分类的新颖的层次分类法：基础模型和推理引擎、工具利用和环境交互、任务规划和执行控制、知识综合和输出生成。&lt;h4&gt;主要发现&lt;/h4&gt;分析了当前实施中系统的显著能力以及它们在信息准确性、隐私、知识产权和可访问性方面提出的技术和伦理挑战。&lt;h4&gt;结论&lt;/h4&gt;确定了在高级推理架构、多模态集成、领域专业化、人机协作和生态系统标准化方面具有前景的研究方向，这些方向可能会塑造这一变革性技术的未来演变。&lt;h4&gt;翻译&lt;/h4&gt;This survey examines the rapidly evolving field of Deep Research systems --AI-powered applications that automate complex research workflows through the integration of large language models, advanced information retrieval, and autonomous reasoning capabilities. We analyze more than 80 commercial and non-commercial implementations that have emerged since 2023, including OpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and numerous open-source alternatives. Through comprehensive examination, we propose a novel hierarchical taxonomy that categorizes systems according to four fundamental technical dimensions: foundation models and reasoning engines, tool utilization and environmental interaction, task planning and execution control, and knowledge synthesis and output generation. We explore the architectural patterns, implementation approaches, and domain-specific adaptations that characterize these systems across academic, scientific, business, and educational applications. Our analysis reveals both the significant capabilities of current implementations and the technical and ethical challenges they present regarding information accuracy, privacy, intellectual property, and accessibility. The survey concludes by identifying promising research directions in advanced reasoning architectures, multimodal integration, domain specialization, human-AI collaboration, and ecosystem standardization that will likely shape the future evolution of this transformative technology. By providing a comprehensive framework for understanding Deep Research systems, this survey contributes to both the theoretical understanding of AI-augmented knowledge work and the practical development of more capable, responsible, and accessible research technologies. The paper resources can be viewed at https://github.com/scienceaix/deepresearch.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This survey examines the rapidly evolving field of Deep Research systems --AI-powered applications that automate complex research workflows through theintegration of large language models, advanced information retrieval, andautonomous reasoning capabilities. We analyze more than 80 commercial andnon-commercial implementations that have emerged since 2023, includingOpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, andnumerous open-source alternatives. Through comprehensive examination, wepropose a novel hierarchical taxonomy that categorizes systems according tofour fundamental technical dimensions: foundation models and reasoning engines,tool utilization and environmental interaction, task planning and executioncontrol, and knowledge synthesis and output generation. We explore thearchitectural patterns, implementation approaches, and domain-specificadaptations that characterize these systems across academic, scientific,business, and educational applications. Our analysis reveals both thesignificant capabilities of current implementations and the technical andethical challenges they present regarding information accuracy, privacy,intellectual property, and accessibility. The survey concludes by identifyingpromising research directions in advanced reasoning architectures, multimodalintegration, domain specialization, human-AI collaboration, and ecosystemstandardization that will likely shape the future evolution of thistransformative technology. By providing a comprehensive framework forunderstanding Deep Research systems, this survey contributes to both thetheoretical understanding of AI-augmented knowledge work and the practicaldevelopment of more capable, responsible, and accessible research technologies.The paper resources can be viewed athttps://github.com/scienceaix/deepresearch.</description>
      <author>example@mail.com (Renjun Xu, Jingwen Peng)</author>
      <guid isPermaLink="false">2506.12594v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>BSA: Ball Sparse Attention for Large-scale Geometries</title>
      <link>http://arxiv.org/abs/2506.12541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Long Context Foundation Models Workshop @ ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Ball Sparse Attention (BSA)的新型稀疏注意力机制，用于处理不规则几何形状的点集数据。&lt;h4&gt;背景&lt;/h4&gt;Self-attention机制在大规模物理系统中因计算量过大而受限，而现有的稀疏注意力机制主要适用于规则结构如文本或图像。&lt;h4&gt;目的&lt;/h4&gt;旨在为不规则几何形状的点集数据提供一种高效的稀疏注意力机制。&lt;h4&gt;方法&lt;/h4&gt;将Native Sparse Attention (NSA)机制适配到无序点集，通过使用Erwin Transformer中的Ball Tree结构引入规律性，并修改NSA的组件以与基于球体的邻域一起工作。&lt;h4&gt;主要发现&lt;/h4&gt;在空气流动压力预测任务中，BSA实现了与全注意力机制相当的准确率，同时显著降低了理论计算复杂度。&lt;h4&gt;结论&lt;/h4&gt;BSA通过引入Ball Tree结构，以亚二次成本实现了全局感受野，为不规则几何形状的点集数据处理提供了一种有效方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents a novel sparse attention mechanism called Ball Sparse Attention (BSA), which is adapted for unordered point sets by imposing regularity using the Ball Tree structure from the Erwin Transformer. The components of NSA are modified to work with ball-based neighborhoods, yielding a global receptive field at sub-quadratic cost. In an airflow pressure prediction task, BSA achieves accuracy comparable to Full Attention while significantly reducing the theoretical computational complexity.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-attention scales quadratically with input size, limiting its use forlarge-scale physical systems. Although sparse attention mechanisms provide aviable alternative, they are primarily designed for regular structures such astext or images, making them inapplicable for irregular geometries. In thiswork, we present Ball Sparse Attention (BSA), which adapts Native SparseAttention (NSA) (Yuan et al., 2025) to unordered point sets by imposingregularity using the Ball Tree structure from the Erwin Transformer (Zhdanov etal., 2025). We modify NSA's components to work with ball-based neighborhoods,yielding a global receptive field at sub-quadratic cost. On an airflow pressureprediction task, we achieve accuracy comparable to Full Attention whilesignificantly reducing the theoretical computational complexity. Ourimplementation is available at https://github.com/britacatalin/bsa.</description>
      <author>example@mail.com (Catalin E. Brita, Hieu Nguyen, Lohithsai Yadala Chanchu, Domonkos Nagy, Maksim Zhdanov)</author>
      <guid isPermaLink="false">2506.12541v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>A Spatial Relationship Aware Dataset for Robotics</title>
      <link>http://arxiv.org/abs/2506.12525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages; 7 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种空间关系感知的数据集，用于机器人任务规划，并通过实验评估了不同场景图生成模型在空间关系理解上的表现。&lt;h4&gt;背景&lt;/h4&gt;在现实世界环境中进行机器人任务规划，不仅需要物体识别，还需要对物体之间的空间关系有细微的理解。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过数据集和模型来提高机器人对空间关系的理解能力。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含近1000张室内图像的数据集，使用Boston Dynamics Spot机器人捕获，并使用自定义标注工具进行标注，包括物体属性、位置和详细的空间关系。在数据集上对六种最先进的场景图生成模型进行了基准测试，分析了它们的推理速度和关系准确性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，将明确的空间关系集成到基础模型中，如ChatGPT 4o，可以显著提高模型生成可执行、空间感知的计划的能力。&lt;h4&gt;结论&lt;/h4&gt;该数据集和标注工具公开可用，支持机器人空间推理的进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we present a spatial-relationship-aware dataset for robotic task planning, and evaluate the performance of different scene-graph generation models in understanding spatial relationships through experiments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic task planning in real-world environments requires not only objectrecognition but also a nuanced understanding of spatial relationships betweenobjects. We present a spatial-relationship-aware dataset of nearly 1,000robot-acquired indoor images, annotated with object attributes, positions, anddetailed spatial relationships. Captured using a Boston Dynamics Spot robot andlabelled with a custom annotation tool, the dataset reflects complex scenarioswith similar or identical objects and intricate spatial arrangements. Webenchmark six state-of-the-art scene-graph generation models on this dataset,analysing their inference speed and relational accuracy. Our results highlightsignificant differences in model performance and demonstrate that integratingexplicit spatial relationships into foundation models, such as ChatGPT 4o,substantially improves their ability to generate executable, spatially-awareplans for robotics. The dataset and annotation tool are publicly available athttps://github.com/PengPaulWang/SpatialAwareRobotDataset, supporting furtherresearch in spatial reasoning for robotics.</description>
      <author>example@mail.com (Peng Wang, Minh Huy Pham, Zhihao Guo, Wei Zhou)</author>
      <guid isPermaLink="false">2506.12525v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Model Merging for Knowledge Editing</title>
      <link>http://arxiv.org/abs/2506.12384v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合鲁棒监督微调和模型合并的知识编辑框架，用于更新大型语言模型（LLMs）的知识。&lt;h4&gt;背景&lt;/h4&gt;现有的知识编辑方法在处理连续编辑场景时存在困难，且可能损害模型的通用能力，限制了其实际应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以在保持模型原有性能的同时，有效地更新LLMs的知识。&lt;h4&gt;方法&lt;/h4&gt;该方法首先通过鲁棒监督微调（R-SFT）让LLMs完全吸收新知识，然后合并微调后的模型与原始基础模型，以保留新获得的知识和通用能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在连续编辑方面显著优于现有方法，同时更好地保留了模型的原始性能，且无需进行任何架构变更。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为LLMs的知识更新提供了一种有效且实用的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a two-stage framework combining robust supervised fine-tuning (R-SFT) with model merging for knowledge editing. The method first fine-tunes the LLM to fully internalize new knowledge, then merges the fine-tuned model with the original foundation model to preserve the newly acquired knowledge and general capabilities. Experimental results demonstrate that our approach significantly outperforms existing methods in sequential editing while better preserving the original performance of the model, all without requiring any architectural changes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) require continuous updates to maintain accurateand current knowledge as the world evolves. While existing knowledge editingapproaches offer various solutions for knowledge updating, they often strugglewith sequential editing scenarios and harm the general capabilities of themodel, thereby significantly hampering their practical applicability. Thispaper proposes a two-stage framework combining robust supervised fine-tuning(R-SFT) with model merging for knowledge editing. Our method first fine-tunesthe LLM to internalize new knowledge fully, then merges the fine-tuned modelwith the original foundation model to preserve newly acquired knowledge andgeneral capabilities. Experimental results demonstrate that our approachsignificantly outperforms existing methods in sequential editing while betterpreserving the original performance of the model, all without requiring anyarchitectural changes. Code is available at:https://github.com/Applied-Machine-Learning-Lab/MM4KE.</description>
      <author>example@mail.com (Zichuan Fu, Xian Wu, Guojing Li, Yingying Zhang, Yefeng Zheng, Tianshi Ming, Yejing Wang, Wanyu Wang, Xiangyu Zhao)</author>
      <guid isPermaLink="false">2506.12384v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>HYPER: A Foundation Model for Inductive Link Prediction with Knowledge Hypergraphs</title>
      <link>http://arxiv.org/abs/2506.12362v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HYPER的基础模型，用于知识超图中的归纳链接预测，能够预测包含全新实体和关系的缺失超边，并展示了对未见过的、不同变元的超图关系结构的强大泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有方法在知识超图的归纳链接预测中假设固定的关系词汇，无法泛化到训练期间未见过的关系类型。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够泛化到任何知识超图，包括全新实体和关系的HYPER基础模型。&lt;h4&gt;方法&lt;/h4&gt;HYPER通过编码每个超边中的实体及其在超边中的位置，学习并跨不同变元的关系类型进行迁移。&lt;h4&gt;主要发现&lt;/h4&gt;通过构建16个新的归纳数据集，覆盖不同变元的关系类型，实证结果表明，HYPER在仅节点和节点与关系归纳设置中均优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;HYPER在预测未见过的、更高变元的超图关系结构方面表现出强大的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inductive link prediction with knowledge hypergraphs is the task ofpredicting missing hyperedges involving completely novel entities (i.e., nodesunseen during training). Existing methods for inductive link prediction withknowledge hypergraphs assume a fixed relational vocabulary and, as a result,cannot generalize to knowledge hypergraphs with novel relation types (i.e.,relations unseen during training). Inspired by knowledge graph foundationmodels, we propose HYPER as a foundation model for link prediction, which cangeneralize to any knowledge hypergraph, including novel entities and novelrelations. Importantly, HYPER can learn and transfer across different relationtypes of varying arities, by encoding the entities of each hyperedge along withtheir respective positions in the hyperedge. To evaluate HYPER, we construct 16new inductive datasets from existing knowledge hypergraphs, covering a diverserange of relation types of varying arities. Empirically, HYPER consistentlyoutperforms all existing methods in both node-only and node-and-relationinductive settings, showing strong generalization to unseen, higher-arityrelational structures.</description>
      <author>example@mail.com (Xingyue Huang, Mikhail Galkin, Michael M. Bronstein, İsmail İlkan Ceylan)</author>
      <guid isPermaLink="false">2506.12362v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Perspective on Utilizing Foundation Models for Laboratory Automation in Materials Research</title>
      <link>http://arxiv.org/abs/2506.12312v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基础模型在推动材料科学和化学领域实验室自动化中的潜力。&lt;h4&gt;背景&lt;/h4&gt;传统实验室自动化依赖于专用且僵化的系统。&lt;h4&gt;目的&lt;/h4&gt;强调基础模型在实验规划和数据分析中的认知功能，以及在硬件操作中的物理功能。&lt;h4&gt;方法&lt;/h4&gt;通过使用大型语言模型（LLMs）和多模态机器人系统来处理复杂的动态实验室任务。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型通过其通用智能和多模态能力提供了适应性，但仍然存在精确操作硬件、多模态数据集成和确保操作安全等挑战。&lt;h4&gt;结论&lt;/h4&gt;本文提出了一个路线图，强调未来研究方向，倡导跨学科合作、基准建立和战略人机整合，以实现完全自主的实验实验室。&lt;h4&gt;翻译&lt;/h4&gt;本文探讨了基础模型在推动材料科学和化学领域实验室自动化中的潜力。它强调了这些模型的双重角色：用于实验规划和数据分析的认知功能，以及用于硬件操作的物理功能。虽然传统的实验室自动化严重依赖于专用且僵化的系统，但基础模型通过其通用智能和多模态能力提供了适应性。最近的研究进展证明了使用大型语言模型（LLMs）和多模态机器人系统处理复杂和动态实验室任务的可行性。然而，仍然存在一些重大挑战，包括精确操作硬件、多模态数据集成和确保操作安全。本文概述了一个路线图，强调未来方向，倡导跨学科合作、基准建立和战略人机整合，以实现完全自主的实验实验室。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This review explores the potential of foundation models to advance laboratoryautomation in the materials and chemical sciences. It emphasizes the dual rolesof these models: cognitive functions for experimental planning and dataanalysis, and physical functions for hardware operations. While traditionallaboratory automation has relied heavily on specialized, rigid systems,foundation models offer adaptability through their general-purpose intelligenceand multimodal capabilities. Recent advancements have demonstrated thefeasibility of using large language models (LLMs) and multimodal roboticsystems to handle complex and dynamic laboratory tasks. However, significantchallenges remain, including precision manipulation of hardware, integration ofmultimodal data, and ensuring operational safety. This paper outlines a roadmaphighlighting future directions, advocating for close interdisciplinarycollaboration, benchmark establishment, and strategic human-AI integration torealize fully autonomous experimental laboratories.</description>
      <author>example@mail.com (Kan Hatakeyama-Sato, Toshihiko Nishida, Kenta Kitamura, Yoshitaka Ushiku, Koichi Takahashi, Yuta Nabae, Teruaki Hayakawa)</author>
      <guid isPermaLink="false">2506.12312v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>R2LDM: An Efficient 4D Radar Super-Resolution Framework Leveraging Diffusion Model</title>
      <link>http://arxiv.org/abs/2503.17097v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 9 figures, accepted to IROS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为R2LDM的创新方法，用于生成密集且精确的四维雷达点云，该方法基于相应的激光雷达点云指导。&lt;h4&gt;背景&lt;/h4&gt;当前方法通常使用距离图像或鸟瞰视图来处理激光雷达和四维雷达点云，但这种方法不能有效捕获3D形状信息。&lt;h4&gt;目的&lt;/h4&gt;通过利用体素特征，更有效地捕获3D形状信息，并从高维隐式体素特征中重建点云。&lt;h4&gt;方法&lt;/h4&gt;使用体素特征表示激光雷达和四维雷达点云，提出潜体素扩散模型（LVDM）在潜在空间中执行扩散过程，并采用新的潜点云重建模块（LPCR）。&lt;h4&gt;主要发现&lt;/h4&gt;R2LDM有效地从配对原始雷达数据中生成类似激光雷达的点云，并在两个不同数据集上评估，实验结果表明，该模型实现了雷达点云6到10倍的密集化，在四维雷达点云超分辨率方面优于现有基准。&lt;h4&gt;结论&lt;/h4&gt;由该方法生成的增强雷达点云显著提高了下游任务，点云注册召回率提高了31.7%，目标检测精度提高了24.9%。&lt;h4&gt;翻译&lt;/h4&gt;We introduce R2LDM, an innovative approach for generating dense and accurate 4D radar point clouds, guided by corresponding LiDAR point clouds. Instead of utilizing range images or bird's eye view (BEV) images, we represent both LiDAR and 4D radar point clouds using voxel features, which more effectively capture 3D shape information. Subsequently, we propose the Latent Voxel Diffusion Model (LVDM), which performs the diffusion process in the latent space. Additionally, a novel Latent Point Cloud Reconstruction (LPCR) module is utilized to reconstruct point clouds from high-dimensional latent voxel features. As a result, R2LDM effectively generates LiDAR-like point clouds from paired raw radar data. We evaluate our approach on two different datasets, and the experimental results demonstrate that our model achieves 6- to 10-fold densification of radar point clouds, outperforming state-of-the-art baselines in 4D radar point cloud super-resolution. Furthermore, the enhanced radar point clouds generated by our method significantly improve downstream tasks, achieving up to 31.7% improvement in point cloud registration recall rate and 24.9% improvement in object detection accuracy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce R2LDM, an innovative approach for generating dense and accurate4D radar point clouds, guided by corresponding LiDAR point clouds. Instead ofutilizing range images or bird's eye view (BEV) images, we represent both LiDARand 4D radar point clouds using voxel features, which more effectively capture3D shape information. Subsequently, we propose the Latent Voxel Diffusion Model(LVDM), which performs the diffusion process in the latent space. Additionally,a novel Latent Point Cloud Reconstruction (LPCR) module is utilized toreconstruct point clouds from high-dimensional latent voxel features. As aresult, R2LDM effectively generates LiDAR-like point clouds from paired rawradar data. We evaluate our approach on two different datasets, and theexperimental results demonstrate that our model achieves 6- to 10-folddensification of radar point clouds, outperforming state-of-the-art baselinesin 4D radar point cloud super-resolution. Furthermore, the enhanced radar pointclouds generated by our method significantly improve downstream tasks,achieving up to 31.7% improvement in point cloud registration recall rate and24.9% improvement in object detection accuracy.</description>
      <author>example@mail.com (Boyuan Zheng, Shouyi Lu, Renbo Huang, Minqing Huang, Fan Lu, Wei Tian, Guirong Zhuo, Lu Xiong)</author>
      <guid isPermaLink="false">2503.17097v2</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Foundation Models for IoT: Taxonomy and Criteria-Based Analysis</title>
      <link>http://arxiv.org/abs/2506.12263v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Under Submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基于基础模型在物联网领域的应用，分析了其相对于传统机器学习方法的优点和局限性，并提出了一个组织框架来促进不同领域间的比较。&lt;h4&gt;背景&lt;/h4&gt;基础模型在物联网领域受到关注，因为它们减少了对标记数据的依赖，并具有跨任务的良好泛化能力。&lt;h4&gt;目的&lt;/h4&gt;旨在填补现有基础模型方法的空白，通过提供全面的方法概述，并围绕不同领域的四个共享性能目标（效率、上下文感知、安全性和隐私）组织内容。&lt;h4&gt;方法&lt;/h4&gt;对代表性工作进行了回顾，总结了常用的技术和评估指标，并实现了以目标为中心的组织，以促进跨领域比较。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型在物联网领域具有潜力，但现有方法主要集中在特定任务上，限制了其在新任务中的应用。&lt;h4&gt;结论&lt;/h4&gt;提出了未来研究方向，以指导实践者和研究人员在物联网应用中推进基础模型的使用。&lt;h4&gt;翻译&lt;/h4&gt;由于基础模型在物联网领域因其对标记数据的依赖性减少和跨任务的强大泛化能力而越来越受到关注。然而，大多数现有的基于基础模型的方法都是针对特定物联网任务开发的，这使得跨物联网领域的比较变得困难，并限制了它们应用于新任务的指导。这项调查旨在通过提供当前方法的综合概述，并围绕不同领域的四个共享性能目标（效率、上下文感知、安全性和隐私）组织它们来弥合这一差距。对于每个目标，我们回顾了代表性工作，总结了常用的技术和评估指标。这种以目标为中心的组织使跨领域比较变得有意义，并为选择和设计基于基础模型的新物联网任务解决方案提供了实用见解。我们最后总结了未来研究的关键方向，以指导实践者和研究人员在物联网应用中推进基础模型的使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have gained growing interest in the IoT domain due to theirreduced reliance on labeled data and strong generalizability across tasks,which address key limitations of traditional machine learning approaches.However, most existing foundation model based methods are developed forspecific IoT tasks, making it difficult to compare approaches across IoTdomains and limiting guidance for applying them to new tasks. This survey aimsto bridge this gap by providing a comprehensive overview of currentmethodologies and organizing them around four shared performance objectives bydifferent domains: efficiency, context-awareness, safety, and security &amp;privacy. For each objective, we review representative works, summarizecommonly-used techniques and evaluation metrics. This objective-centricorganization enables meaningful cross-domain comparisons and offers practicalinsights for selecting and designing foundation model based solutions for newIoT tasks. We conclude with key directions for future research to guide bothpractitioners and researchers in advancing the use of foundation models in IoTapplications.</description>
      <author>example@mail.com (Hui Wei, Dong Yoon Lee, Shubham Rohal, Zhizhang Hu, Shiwei Fang, Shijia Pan)</author>
      <guid isPermaLink="false">2506.12263v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>EgoPrivacy: What Your First-Person Camera Says About You?</title>
      <link>http://arxiv.org/abs/2506.12258v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了从第一人称视角视频中推断摄像头佩戴者隐私信息的问题，并提出了EgoPrivacy，一个用于全面评估自视角视觉隐私风险的基准。&lt;h4&gt;背景&lt;/h4&gt;随着可穿戴相机的快速普及，对以自我为中心的视频隐私的担忧日益增加，但先前的研究大多忽视了摄像头佩戴者所面临的独特隐私威胁。&lt;h4&gt;目的&lt;/h4&gt;探究从摄像头佩戴者的第一人称视角视频中可以推断出多少隐私信息。&lt;h4&gt;方法&lt;/h4&gt;引入了EgoPrivacy，一个用于全面评估自视角视觉隐私风险的大规模基准。EgoPrivacy涵盖了三种类型的隐私（人口统计学、个人和情境），定义了七个任务，旨在从细粒度（例如，佩戴者身份）到粗粒度（例如，年龄组）恢复私人信息。此外，提出了检索增强攻击，这是一种新的攻击策略，它利用从外部外视角视频池中进行自我到外部的检索，以增强人口统计学隐私攻击的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的比较表明，佩戴者的私人信息极易泄露。例如，研究发现，基础模型即使在零样本设置中也能有效侵犯佩戴者的隐私，通过以70-80%的准确率恢复属性，如身份、场景、性别和种族。&lt;h4&gt;结论&lt;/h4&gt;EgoPrivacy为评估自视角视觉中的隐私风险提供了一个重要的工具，揭示了佩戴者隐私信息的脆弱性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：虽然可穿戴相机的迅速普及引发了关于以自我为中心的视频隐私的严重担忧，但先前的工作在很大程度上忽视了摄像头佩戴者所面临的独特隐私威胁。本研究探讨了核心问题：从摄像头佩戴者的第一人称视角视频中可以推断出多少关于摄像头佩戴者的隐私信息？我们引入了EgoPrivacy，这是第一个用于全面评估自视角视觉隐私风险的大规模基准。EgoPrivacy涵盖了三种类型的隐私（人口统计学、个人和情境），定义了七个任务，旨在恢复从细粒度（例如，佩戴者身份）到粗粒度（例如，年龄组）的私人信息。为了进一步强调自视角视觉固有的隐私威胁，我们提出了检索增强攻击，这是一种利用来自外部外视角视频池的自我到外部的检索来提高人口统计学隐私攻击有效性的新颖攻击策略。在所有威胁模型下可能的所有攻击的广泛比较表明，佩戴者的私人信息极易泄露。例如，我们的研究结果表明，基础模型即使在零样本设置中也能有效侵犯佩戴者的隐私，通过以70-80%的准确率恢复属性，如身份、场景、性别和种族。我们的代码和数据可在https://github.com/williamium3000/ego-privacy上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While the rapid proliferation of wearable cameras has raised significantconcerns about egocentric video privacy, prior work has largely overlooked theunique privacy threats posed to the camera wearer. This work investigates thecore question: How much privacy information about the camera wearer can beinferred from their first-person view videos? We introduce EgoPrivacy, thefirst large-scale benchmark for the comprehensive evaluation of privacy risksin egocentric vision. EgoPrivacy covers three types of privacy (demographic,individual, and situational), defining seven tasks that aim to recover privateinformation ranging from fine-grained (e.g., wearer's identity) tocoarse-grained (e.g., age group). To further emphasize the privacy threatsinherent to egocentric vision, we propose Retrieval-Augmented Attack, a novelattack strategy that leverages ego-to-exo retrieval from an external pool ofexocentric videos to boost the effectiveness of demographic privacy attacks. Anextensive comparison of the different attacks possible under all threat modelsis presented, showing that private information of the wearer is highlysusceptible to leakage. For instance, our findings indicate that foundationmodels can effectively compromise wearer privacy even in zero-shot settings byrecovering attributes such as identity, scene, gender, and race with 70-80%accuracy. Our code and data are available athttps://github.com/williamium3000/ego-privacy.</description>
      <author>example@mail.com (Yijiang Li, Genpei Zhang, Jiacheng Cheng, Yi Li, Xiaojun Shan, Dashan Gao, Jiancheng Lyu, Yuan Li, Ning Bi, Nuno Vasconcelos)</author>
      <guid isPermaLink="false">2506.12258v1</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>SurgBench: A Unified Large-Scale Benchmark for Surgical Video Analysis</title>
      <link>http://arxiv.org/abs/2506.07603v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SurgBench，一个统一的手术视频基准测试框架，包含用于预训练的数据集SurgBench-P和评估基准SurgBench-E。SurgBench覆盖了多样化的手术场景，并通过实验表明，在SurgBench-P上进行预训练可以显著提升视频模型在手术视频分析任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;手术视频理解对于实现手术过程中的自动化决策、技能评估和术后质量改进至关重要。然而，由于缺乏大规模、多样化的数据集进行预训练和系统评估，手术视频基础模型（FM）的开发进展受限。&lt;h4&gt;目的&lt;/h4&gt;提出SurgBench框架，旨在提供大规模、多样化的数据集，以促进手术视频基础模型的开发和应用。&lt;h4&gt;方法&lt;/h4&gt;SurgBench框架包括一个包含5300万帧图像的预训练数据集SurgBench-P，涵盖22种手术流程和11个专业，以及一个提供六个类别（包括阶段分类、摄像机运动、工具识别、疾病诊断、动作分类和器官检测）的72个细粒度任务的评估基准SurgBench-E。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，现有的视频基础模型难以泛化到不同的手术视频分析任务中，而基于SurgBench-P的预训练可以显著提高性能，并实现更好的跨领域泛化。&lt;h4&gt;结论&lt;/h4&gt;SurgBench为手术视频基础模型的发展提供了必要的工具和数据支持，有助于提升手术视频分析的性能。&lt;h4&gt;翻译&lt;/h4&gt;Surgical video understanding is pivotal for enabling automated intraoperative decision-making, skill assessment, and postoperative quality improvement. However, progress in developing surgical video foundation models (FMs) remains hindered by the scarcity of large-scale, diverse datasets for pretraining and systematic evaluation. In this paper, we introduce SurgBench, a unified surgical video benchmarking framework comprising a pretraining dataset, SurgBench-P, and an evaluation benchmark, SurgBench-E. SurgBench offers extensive coverage of diverse surgical scenarios, with SurgBench-P encompassing 53 million frames across 22 surgical procedures and 11 specialties, and SurgBench-E providing robust evaluation across six categories (phase classification, camera motion, tool recognition, disease diagnosis, action classification, and organ detection) spanning 72 fine-grained tasks. Extensive experiments reveal that existing video FMs struggle to generalize across varied surgical video analysis tasks, whereas pretraining on SurgBench-P yields substantial performance improvements and superior cross-domain generalization to unseen procedures and modalities. Our dataset and code are available upon request.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surgical video understanding is pivotal for enabling automated intraoperativedecision-making, skill assessment, and postoperative quality improvement.However, progress in developing surgical video foundation models (FMs) remainshindered by the scarcity of large-scale, diverse datasets for pretraining andsystematic evaluation. In this paper, we introduce \textbf{SurgBench}, aunified surgical video benchmarking framework comprising a pretraining dataset,\textbf{SurgBench-P}, and an evaluation benchmark, \textbf{SurgBench-E}.SurgBench offers extensive coverage of diverse surgical scenarios, withSurgBench-P encompassing 53 million frames across 22 surgical procedures and 11specialties, and SurgBench-E providing robust evaluation across six categories(phase classification, camera motion, tool recognition, disease diagnosis,action classification, and organ detection) spanning 72 fine-grained tasks.Extensive experiments reveal that existing video FMs struggle to generalizeacross varied surgical video analysis tasks, whereas pretraining on SurgBench-Pyields substantial performance improvements and superior cross-domaingeneralization to unseen procedures and modalities. Our dataset and code areavailable upon request.</description>
      <author>example@mail.com (Jianhui Wei, Zikai Xiao, Danyu Sun, Luqi Gong, Zongxin Yang, Zuozhu Liu, Jian Wu)</author>
      <guid isPermaLink="false">2506.07603v2</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>The Urban Model Platform: A Public Backbone for Modeling and Simulation in Urban Digital Twins</title>
      <link>http://arxiv.org/abs/2506.10964v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;城市数字孪生被看作是整合城市日益增长数字资源以实现更可持续和综合的城市规划的一种方式。&lt;h4&gt;背景&lt;/h4&gt;模型和模拟在城市数字孪生中起核心作用，但将模型集成并用于城市数字孪生的过程本身非常复杂。&lt;h4&gt;目的&lt;/h4&gt;探讨如何表示城市复杂性、如何处理不确定性和模型范式、以及如何捕捉潜在权力关系。&lt;h4&gt;方法&lt;/h4&gt;采用参与式设计用于参与式系统的方法，与德国汉堡市合作。&lt;h4&gt;主要发现&lt;/h4&gt;开放的Urban Model Platform可以作为城市数字孪生中建模和模拟的公共技术骨干，并作为城市过程协作和多元表现的社技术框架。&lt;h4&gt;结论&lt;/h4&gt;该平台基于开放标准，允许模型去中心化集成，实现模型间的通信，并支持多模型方法来表示城市系统。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urban digital twins are increasingly perceived as a way to pool the growingdigital resources of cities for the purpose of a more sustainable andintegrated urban planning. Models and simulations are central to thisundertaking: They enable "what if?" scenarios, create insights and describerelationships between the vast data that is being collected. However, theprocess of integrating and subsequently using models in urban digital twins isan inherently complex undertaking. It raises questions about how to representurban complexity, how to deal with uncertain assUrban Model Platformtions andmodeling paradigms, and how to capture underlying power relations. Existentapproaches in the domain largely focus on monolithic and centralized solutionsin the tradition of neoliberal city-making, oftentimes prohibiting pluralisticand open interoperable models. Using a participatory design for participatorysystems approach together with the City of Hamburg, Germany, we find that anopen Urban Model Platform can function both as a public technological backbonefor modeling and simulation in urban digital twins and as a socio-technicalframework for a collaborative and pluralistic representation of urbanprocesses. Such a platform builds on open standards, allows for a decentralizedintegration of models, enables communication between models and supports amulti-model approach to representing urban systems.</description>
      <author>example@mail.com (Rico H Herzog, Till Degkwitz, Trivik Verma)</author>
      <guid isPermaLink="false">2506.10964v2</guid>
      <pubDate>Tue, 17 Jun 2025 14:38:39 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Modal Clustering-Guided Negative Sampling for Self-Supervised Joint Learning from Medical Images and Reports</title>
      <link>http://arxiv.org/abs/2506.11674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE TMI for possible  publication. Our code is available at https://github.com/violet-42/CM-CGNS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CM-CGNS的多模态自监督学习方法，用于从配对图像和报告中直接学习医学视觉表示，以解决现有模型存在的问题。&lt;h4&gt;背景&lt;/h4&gt;近年来，直接从配对图像和报告中通过多模态自监督学习来学习医学视觉表示已成为数字诊断的一种新颖且高效的方法。&lt;h4&gt;目的&lt;/h4&gt;针对现有模型的局限性，提出一种新的方法来提高医学视觉表示的学习效果。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法包括：1) 通过跨模态注意力将k-means聚类从单模态域扩展到多模态域，以增加负样本的数量并提高模型的表达能力；2) 引入一个名为CM-MIR的模块，该模块利用通过跨模态注意力获得的局部文本到图像特征来重建掩码的局部图像区域，增强模型的跨模态信息交互能力并保留对下游任务至关重要的低级图像特征。&lt;h4&gt;主要发现&lt;/h4&gt;通过解决现有模型的局限性，CM-CGNS能够学习有效的和鲁棒的医学视觉表示，适用于各种识别任务。&lt;h4&gt;结论&lt;/h4&gt;在五个下游数据集上的广泛实验结果表明，该方法在分类、检测和分割任务上优于现有方法，验证了其优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，通过多模态自监督学习直接从配对图像和报告中学习医学视觉表示已成为数字诊断的一种新颖且高效的方法。然而，现有的模型存在几个严重的局限性。1）忽略了负样本的选择，导致硬负样本稀缺和错误负样本的包含；2）专注于全局特征提取，但忽略了对于医学图像识别任务至关重要的细粒度局部细节；3）对比学习主要针对高级特征，但忽略了对于准确医学分析至关重要的低级细节。受这些关键问题的启发，本文提出了一种名为Cross-Modal Cluster-Guided Negative Sampling (CM-CGNS)的方法，包含两个方面的想法。首先，它通过跨模态注意力将用于单模态域中的局部文本特征的k-means聚类扩展到多模态域，这种改进增加了负样本的数量并提高了模型的表达能力。其次，它引入了一个名为Cross-Modal Masked Image Reconstruction (CM-MIR)的模块，该模块利用通过跨模态注意力获得的局部文本到图像特征来重建掩码的局部图像区域。该模块显著增强了模型的跨模态信息交互能力并保留了对于下游任务至关重要的低级图像特征。通过妥善处理上述局限性，所提出的CM-CGNS可以学习适用于各种识别任务的有效和鲁棒的医学视觉表示。在五个下游数据集上的分类、检测和分割任务的广泛实验结果表明，我们的方法在多个指标上优于现有方法，验证了其优越的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning medical visual representations directly from paired images andreports through multimodal self-supervised learning has emerged as a novel andefficient approach to digital diagnosis in recent years. However, existingmodels suffer from several severe limitations. 1) neglecting the selection ofnegative samples, resulting in the scarcity of hard negatives and the inclusionof false negatives; 2) focusing on global feature extraction, but overlookingthe fine-grained local details that are crucial for medical image recognitiontasks; and 3) contrastive learning primarily targets high-level features butignoring low-level details which are essential for accurate medical analysis.Motivated by these critical issues, this paper presents a Cross-ModalCluster-Guided Negative Sampling (CM-CGNS) method with two-fold ideas. First,it extends the k-means clustering used for local text features in thesingle-modal domain to the multimodal domain through cross-modal attention.This improvement increases the number of negative samples and boosts the modelrepresentation capability. Second, it introduces a Cross-Modal Masked ImageReconstruction (CM-MIR) module that leverages local text-to-image featuresobtained via cross-modal attention to reconstruct masked local image regions.This module significantly strengthens the model's cross-modal informationinteraction capabilities and retains low-level image features essential fordownstream tasks. By well handling the aforementioned limitations, the proposedCM-CGNS can learn effective and robust medical visual representations suitablefor various recognition tasks. Extensive experimental results onclassification, detection, and segmentation tasks across five downstreamdatasets show that our method outperforms state-of-the-art approaches onmultiple metrics, verifying its superior performance.</description>
      <author>example@mail.com (Libin Lan, Hongxing Li, Zunhui Xia, Juan Zhou, Xiaofei Zhu, Yongmei Li, Yudong Zhang, Xin Luo)</author>
      <guid isPermaLink="false">2506.11674v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
  <item>
      <title>Generative Representational Learning of Foundation Models for Recommendation</title>
      <link>http://arxiv.org/abs/2506.11999v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page is available at https://junkfood436.github.io/RecFound/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为RecFound的推荐基础模型生成表示学习框架，旨在解决推荐系统中的多任务学习问题。&lt;h4&gt;背景&lt;/h4&gt;在人工智能领域，开发能够跨不同任务表现优异的单个基础模型是一个长期目标。通用基础模型的影响已扩展到推荐系统领域。&lt;h4&gt;目的&lt;/h4&gt;针对现有推荐基础模型在嵌入任务和复杂的多任务学习问题上的不足，提出一种新的框架来解决知识共享、冲突解决和收敛速度不一致等问题。&lt;h4&gt;方法&lt;/h4&gt;构建了第一个涵盖生成和嵌入任务的推荐基础模型综合数据集，并提出了一种新颖的多任务训练方案，包括任务特定低秩专家混合（TMoLE）处理知识共享和冲突，逐步收敛导向的样本调度器（S2Sched）解决收敛不一致问题，以及模型合并模块以平衡不同任务的性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，RecFound在多种推荐任务上实现了最先进的性能，优于现有基线。&lt;h4&gt;结论&lt;/h4&gt;RecFound框架能够有效提升推荐系统的多任务学习能力，为推荐系统领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing a single foundation model with the capability to excel acrossdiverse tasks has been a long-standing objective in the field of artificialintelligence. As the wave of general-purpose foundation models sweeps acrossvarious domains, their influence has significantly extended to the field ofrecommendation systems. While recent efforts have explored recommendationfoundation models for various generative tasks, they often overlook crucialembedding tasks and struggle with the complexities of multi-task learning,including knowledge sharing &amp; conflict resolution, and convergence speedinconsistencies. To address these limitations, we introduce RecFound, agenerative representational learning framework for recommendation foundationmodels. We construct the first comprehensive dataset for recommendationfoundation models covering both generative and embedding tasks across diversescenarios. Based on this dataset, we propose a novel multi-task training schemefeaturing a Task-wise Mixture of Low-rank Experts (TMoLE) to handle knowledgesharing &amp; conflict, a Step-wise Convergence-oriented Sample Scheduler (S2Sched)to address inconsistent convergence, and a Model Merge module to balance theperformance across tasks. Experiments demonstrate that RecFound achievesstate-of-the-art performance across various recommendation tasks, outperformingexisting baselines.</description>
      <author>example@mail.com (Zheli Zhou, Chenxu Zhu, Jianghao Lin, Bo Chen, Ruiming Tang, Weinan Zhang, Yong Yu)</author>
      <guid isPermaLink="false">2506.11999v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Robust Filtering -- Novel Statistical Learning and Inference Algorithms with Applications</title>
      <link>http://arxiv.org/abs/2506.11530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD Thesis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了新颖的非线性滤波方法，用于解决实际场景中存在的异常问题，如异常值、偏差、漂移和缺失观测，以提高智能决策在自动驾驶、机器人、医疗监测、智能电网、智能交通和预测维护等领域的应用。&lt;h4&gt;背景&lt;/h4&gt;传统的滤波方法依赖于对噪声统计特性的先验知识，但在实际应用中，这些先验知识往往是未知的或部分已知的，限制了传统方法的应用。&lt;h4&gt;目的&lt;/h4&gt;提出新的鲁棒非线性滤波方法，以解决实际应用中存在的挑战，并扩展到离线估计/学习设置和提出平滑扩展。&lt;h4&gt;方法&lt;/h4&gt;方法基于贝叶斯推理框架，采用确定性近似和随机近似技术，包括变分推理（VI）和粒子滤波/顺序蒙特卡洛（SMC）。同时，使用贝叶斯克拉美罗界（BCRBs）研究测量异常情况下的理论估计极限。&lt;h4&gt;主要发现&lt;/h4&gt;通过仿真和实验验证了所提方法在目标跟踪、室内定位、3D点云配准、网格配准和姿态图优化等场景中的性能提升。&lt;h4&gt;结论&lt;/h4&gt;该研究的基础性质使其在多种应用中具有实用性，并可能在未来扩展到开发异常值鲁棒的机器学习管道、从异常数据中学习系统动力学，以及解决标准扩散模型在存在异常值、不平衡数据集和模式坍塌等挑战中的问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要：状态估计或滤波是使自动驾驶、机器人、医疗监测、智能电网、智能交通和预测维护等应用中的智能决策成为可能的基本任务。标准滤波假设对噪声统计特性的先验知识以从噪声传感器数据中提取潜在的系统状态。然而，现实场景涉及异常值、偏差、漂移和缺失观测等异常情况，具有未知或部分已知的统计特性，限制了传统方法。本文提出了新颖的鲁棒非线性滤波方法来缓解这些挑战。基于我们的滤波方案，我们扩展了离线估计/学习设置，并提出了平滑扩展。我们的方法利用贝叶斯推理框架，采用包括变分推理（VI）和粒子滤波/顺序蒙特卡洛（SMC）在内的确定性近似和随机近似技术。我们还研究了测量异常情况下的贝叶斯克拉美罗界（BCRBs）的理论估计极限。为了验证所提方法性能的提升，我们在包括目标跟踪、室内定位、3D点云配准、网格配准和姿态图优化等场景中进行了仿真和实验。该研究的基础性质使其在多种应用中具有实用性，并可能在未来扩展到开发异常值鲁棒的机器学习管道、从异常数据中学习系统动力学，以及解决标准扩散模型在存在异常值、不平衡数据集和模式坍塌等挑战中的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State estimation or filtering serves as a fundamental task to enableintelligent decision-making in applications such as autonomous vehicles,robotics, healthcare monitoring, smart grids, intelligent transportation, andpredictive maintenance. Standard filtering assumes prior knowledge of noisestatistics to extract latent system states from noisy sensor data. However,real-world scenarios involve abnormalities like outliers, biases, drifts, andmissing observations with unknown or partially known statistics, limitingconventional approaches. This thesis presents novel robust nonlinear filteringmethods to mitigate these challenges. Based on insights from our filteringproposals, we extend the formulations to offline estimation/learning setups andpropose smoothing extensions. Our methods leverage Bayesian inferenceframeworks, employing both deterministic and stochastic approximationtechniques including Variational Inference (VI) and Particle Filters/SequentialMonte Carlo (SMC). We also study theoretical estimation limits using BayesianCram\'er-Rao bounds (BCRBs) in the context of measurement abnormalities. Tovalidate the performance gains of the proposed methods, we perform simulationsand experiments in scenarios including target tracking, indoor localization, 3Dpoint cloud registration, mesh registration, and pose graph optimization. Thefundamental nature of the work makes it useful in diverse applications, withpossible future extensions toward developing outlier-robust machine learningpipelines, learning system dynamics from anomalous data, and addressingchallenges in generative AI where standard diffusion models struggle withoutliers, imbalanced datasets, and mode collapse.</description>
      <author>example@mail.com (Aamir Hussain Chughtai)</author>
      <guid isPermaLink="false">2506.11530v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>GynSurg: A Comprehensive Gynecology Laparoscopic Surgery Dataset</title>
      <link>http://arxiv.org/abs/2506.11356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;深度学习在计算机辅助干预和手术视频分析方面的进步，不仅提升了手术训练、术中决策支持和患者预后，还改善了术后文档记录和手术发现。&lt;h4&gt;背景&lt;/h4&gt;近年来，深度学习在计算机辅助干预和手术视频分析领域取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有数据集规模小、任务范围窄、标注不够详细等问题，我们引入了GynSurg数据集。&lt;h4&gt;方法&lt;/h4&gt;我们创建了GynSurg数据集，这是迄今为止最大、最多样化的多任务妇科腹腔镜手术数据集，涵盖了动作识别、语义分割、手术文档记录和新手术方法发现等多个任务。&lt;h4&gt;主要发现&lt;/h4&gt;GynSurg数据集提供了丰富的标注，支持各种应用，并通过在标准训练协议下测试最先进的模型来证明数据集的质量和多功能性。&lt;h4&gt;结论&lt;/h4&gt;为了加速该领域的发展，我们公开发布了GynSurg数据集及其标注。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in deep learning have transformed computer-assistedintervention and surgical video analysis, driving improvements not only insurgical training, intraoperative decision support, and patient outcomes, butalso in postoperative documentation and surgical discovery. Central to thesedevelopments is the availability of large, high-quality annotated datasets. Ingynecologic laparoscopy, surgical scene understanding and action recognitionare fundamental for building intelligent systems that assist surgeons duringoperations and provide deeper analysis after surgery. However, existingdatasets are often limited by small scale, narrow task focus, or insufficientlydetailed annotations, limiting their utility for comprehensive, end-to-endworkflow analysis. To address these limitations, we introduce GynSurg, thelargest and most diverse multi-task dataset for gynecologic laparoscopicsurgery to date. GynSurg provides rich annotations across multiple tasks,supporting applications in action recognition, semantic segmentation, surgicaldocumentation, and discovery of novel procedural insights. We demonstrate thedataset quality and versatility by benchmarking state-of-the-art models under astandardized training protocol. To accelerate progress in the field, wepublicly release the GynSurg dataset and its annotations</description>
      <author>example@mail.com (Sahar Nasirihaghighi, Negin Ghamsarian, Leonie Peschek, Matteo Munari, Heinrich Husslein, Raphael Sznitman, Klaus Schoeffmann)</author>
      <guid isPermaLink="false">2506.11356v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable representation learning of quantum data enabled by probabilistic variational autoencoders</title>
      <link>http://arxiv.org/abs/2506.11982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Main text 10 pages, total document 16 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;可解释机器学习正在迅速成为科学发现的关键工具。变分自编码器（VAEs）在提取某些输入数据的隐藏物理特征方面显示出潜力，无需对研究系统的监督或先验知识。然而，VAEs创建有意义的可解释表示的能力依赖于其对输入潜在概率分布的准确近似。在处理量子数据时，VAEs必须考虑其固有的随机性和复杂相关性。尽管VAEs先前已被应用于量子数据，但它们通常忽略了其概率性质，阻碍了有意义的物理描述符的提取。本研究通过两个关键修改使VAEs能够学习物理意义上的潜在表示：一个能够忠实重现量子状态的解码器和一个针对此任务的概率损失函数。使用基准量子自旋模型，我们确定了标准方法失败而本方法学习到的表示仍然有意义的范围。应用于Rydberg原子阵列的实验数据，该模型自主发现相结构，无需访问先验标签、哈密顿细节或有关相关序参数的知识，突显了其在量子系统研究中的无监督和可解释工具的潜力。&lt;h4&gt;背景&lt;/h4&gt;可解释机器学习正成为科学发现的关键工具，VAEs在提取输入数据的隐藏物理特征方面显示出潜力。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过修改VAEs来使其能够学习到物理意义上的潜在表示，并应用于量子系统的研究。&lt;h4&gt;方法&lt;/h4&gt;通过两个关键修改，包括一个能够忠实重现量子状态的解码器和针对此任务的概率损失函数，来增强VAEs的学习能力。使用基准量子自旋模型和Rydberg原子阵列的实验数据进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;通过修改VAEs，能够学习到物理意义上的潜在表示，并在量子系统研究中展现出无监督和可解释的潜力。&lt;h4&gt;结论&lt;/h4&gt;VAEs经过适当修改后，可以成为量子系统研究中无监督和可解释的工具。&lt;h4&gt;翻译&lt;/h4&gt;Interpretable machine learning is rapidly becoming a crucial tool for scientific discovery. Among existing approaches, variational autoencoders (VAEs) have shown promise in extracting the hidden physical features of some input data, with no supervision nor prior knowledge of the system at study. Yet, the ability of VAEs to create meaningful, interpretable representations relies on their accurate approximation of the underlying probability distribution of their input. When dealing with quantum data, VAEs must hence account for its intrinsic randomness and complex correlations. While VAEs have been previously applied to quantum data, they have often neglected its probabilistic nature, hindering the extraction of meaningful physical descriptors. Here, we demonstrate that two key modifications enable VAEs to learn physically meaningful latent representations: a decoder capable of faithfully reproduce quantum states and a probabilistic loss tailored to this task. Using benchmark quantum spin models, we identify regimes where standard methods fail while the representations learned by our approach remain meaningful and interpretable. Applied to experimental data from Rydberg atom arrays, the model autonomously uncovers the phase structure without access to prior labels, Hamiltonian details, or knowledge of relevant order parameters, highlighting its potential as an unsupervised and interpretable tool for the study of quantum systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpretable machine learning is rapidly becoming a crucial tool forscientific discovery. Among existing approaches, variational autoencoders(VAEs) have shown promise in extracting the hidden physical features of someinput data, with no supervision nor prior knowledge of the system at study.Yet, the ability of VAEs to create meaningful, interpretable representationsrelies on their accurate approximation of the underlying probabilitydistribution of their input. When dealing with quantum data, VAEs must henceaccount for its intrinsic randomness and complex correlations. While VAEs havebeen previously applied to quantum data, they have often neglected itsprobabilistic nature, hindering the extraction of meaningful physicaldescriptors. Here, we demonstrate that two key modifications enable VAEs tolearn physically meaningful latent representations: a decoder capable offaithfully reproduce quantum states and a probabilistic loss tailored to thistask. Using benchmark quantum spin models, we identify regimes where standardmethods fail while the representations learned by our approach remainmeaningful and interpretable. Applied to experimental data from Rydberg atomarrays, the model autonomously uncovers the phase structure without access toprior labels, Hamiltonian details, or knowledge of relevant order parameters,highlighting its potential as an unsupervised and interpretable tool for thestudy of quantum systems.</description>
      <author>example@mail.com (Paulin de Schoulepnikoff, Gorka Muñoz-Gil, Hendrik Poulsen Nautrup, Hans J. Briegel)</author>
      <guid isPermaLink="false">2506.11982v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>SemanticST: Spatially Informed Semantic Graph Learning for1 Clustering, Integration, and Scalable Analysis of Spatial2 Transcriptomics</title>
      <link>http://arxiv.org/abs/2506.11491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 Figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SemanticST是一种基于生物信息学和图神经网络的深度学习框架，用于空间转录组学分析，它能够提高数据处理的鲁棒性，并支持大规模数据集的分析。&lt;h4&gt;背景&lt;/h4&gt;空间转录组学技术提供了对组织结构和疾病异质性的空间分辨率基因表达分析，但现有方法在处理噪声数据、可扩展性和细胞关系建模方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出SemanticST，旨在通过多语义图构建来建模多样化的细胞环境，并提高空间转录组学分析的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;SemanticST通过构建多个特定于上下文的图来捕捉空间邻近性、基因表达相似性和组织域结构，并学习每个图的解耦嵌入。使用受注意力启发的策略融合这些嵌入，以获得统一的、具有生物学意义的表示。通过社区感知的min-cut损失提高鲁棒性，并支持mini-batch训练。&lt;h4&gt;主要发现&lt;/h4&gt;在四个平台（Visium、Slide-seq、Stereo-seq、Xenium）和多种人类和小鼠组织中，SemanticST在ARI、NMI和轨迹保真度方面比DeepST、GraphST和IRIS提高了20个百分点的增益。在乳腺癌Xenium数据的重新分析中，SemanticST揭示了罕见的、具有临床意义的亚群，包括三阴性受体簇、空间上不同的DCIS到IDC过渡区域和FOXC2肿瘤相关肌上皮细胞，表明存在非典型EMT程序和干细胞样特征。&lt;h4&gt;结论&lt;/h4&gt;SemanticST提供了一个可扩展的、可解释的且基于生物学的空间转录组学分析框架，能够跨组织类型和疾病进行稳健的发现，为空间解析的组织图谱和下一代精准医学铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;Spatial transcriptomics (ST) technologies enable gene expression profiling with spatial resolution, offering unprecedented insights into tissue organization and disease heterogeneity. However, current analysis methods often struggle with noisy data, limited scalability, and inadequate modelling of complex cellular relationships. We present SemanticST, a biologically informed, graph-based deep learning framework that models diverse cellular contexts through multi-semantic graph construction. SemanticST builds multiple context-specific graphs capturing spatial proximity, gene expression similarity, and tissue domain structure, and learns disentangled embeddings for each. These are fused using an attention-inspired strategy to yield a unified, biologically meaningful representation. A community-aware min-cut loss improves robustness over contrastive learning, particularly in sparse ST data. SemanticST supports mini-batch training, making it the first graph neural network scalable to large-scale datasets such as Xenium (500,000 cells). Benchmarking across four platforms (Visium, Slide-seq, Stereo-seq, Xenium) and multiple human and mouse tissues shows consistent 20 percentage gains in ARI, NMI, and trajectory fidelity over DeepST, GraphST, and IRIS. In re-analysis of breast cancer Xenium data, SemanticST revealed rare and clinically significant niches, including triple receptor-positive clusters, spatially distinct DCIS-to-IDC transition zones, and FOXC2 tumour-associated myoepithelial cells, suggesting non-canonical EMT programs with stem-like features. SemanticST thus provides a scalable, interpretable, and biologically grounded framework for spatial transcriptomics analysis, enabling robust discovery across tissue types and diseases, and paving the way for spatially resolved tissue atlases and next-generation precision medicine.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial transcriptomics (ST) technologies enable gene expression profilingwith spatial resolution, offering unprecedented insights into tissueorganization and disease heterogeneity. However, current analysis methods oftenstruggle with noisy data, limited scalability, and inadequate modelling ofcomplex cellular relationships. We present SemanticST, a biologically informed,graph-based deep learning framework that models diverse cellular contextsthrough multi-semantic graph construction. SemanticST builds multiplecontext-specific graphs capturing spatial proximity, gene expressionsimilarity, and tissue domain structure, and learns disentangled embeddings foreach. These are fused using an attention-inspired strategy to yield a unified,biologically meaningful representation. A community-aware min-cut loss improvesrobustness over contrastive learning, particularly in sparse ST data.SemanticST supports mini-batch training, making it the first graph neuralnetwork scalable to large-scale datasets such as Xenium (500,000 cells).Benchmarking across four platforms (Visium, Slide-seq, Stereo-seq, Xenium) andmultiple human and mouse tissues shows consistent 20 percentage gains in ARI,NMI, and trajectory fidelity over DeepST, GraphST, and IRIS. In re-analysis ofbreast cancer Xenium data, SemanticST revealed rare and clinically significantniches, including triple receptor-positive clusters, spatially distinctDCIS-to-IDC transition zones, and FOXC2 tumour-associated myoepithelial cells,suggesting non-canonical EMT programs with stem-like features. SemanticST thusprovides a scalable, interpretable, and biologically grounded framework forspatial transcriptomics analysis, enabling robust discovery across tissue typesand diseases, and paving the way for spatially resolved tissue atlases andnext-generation precision medicine.</description>
      <author>example@mail.com (Roxana Zahedi, Ahmadreza Argha, Nona Farbehi, Ivan Bakhshayeshi, Youqiong Ye, Nigel H. Lovell, Hamid Alinejad-Rokny)</author>
      <guid isPermaLink="false">2506.11491v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction</title>
      <link>http://arxiv.org/abs/2506.12015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review. Project page: https://hsi-che-lin.github.io/EMLoC/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;EMLoC是一种基于仿真的内存高效微调框架，通过LoRA校正，允许在推理所需内存预算内进行模型微调。&lt;h4&gt;背景&lt;/h4&gt;开源基础模型在多个领域得到广泛应用，但针对特定领域或个性化任务的微调因内存开销过大而成本高昂。&lt;h4&gt;目的&lt;/h4&gt;提出EMLoC框架，以降低微调大型基础模型的成本。&lt;h4&gt;方法&lt;/h4&gt;EMLoC使用激活感知奇异值分解（SVD）在小型下游校准集上构建特定任务的轻量级仿真器。通过LoRA在轻量级仿真器上执行微调。为了解决原始模型与压缩仿真器之间的不匹配，提出了一种新的补偿算法来校正微调的LoRA模块。&lt;h4&gt;主要发现&lt;/h4&gt;EMLoC支持灵活的压缩比和标准训练流程，适用于广泛的应用。实验表明，EMLoC在多个数据集和模态上优于其他基线。此外，EMLoC在单个24GB消费级GPU上实现了对38B模型的微调，无需量化，为个人用户提供了高效实用的模型适应性。&lt;h4&gt;结论&lt;/h4&gt;EMLoC是一种高效且实用的模型微调框架，能够降低成本并提高模型适应性，特别适用于个人用户和资源受限的环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-source foundation models have seen rapid adoption and development,enabling powerful general-purpose capabilities across diverse domains. However,fine-tuning large foundation models for domain-specific or personalized tasksremains prohibitively expensive for most users due to the significant memoryoverhead beyond that of inference. We introduce EMLoC, an Emulator-basedMemory-efficient fine-tuning framework with LoRA Correction, which enablesmodel fine-tuning within the same memory budget required for inference. EMLoCconstructs a task-specific light-weight emulator using activation-awaresingular value decomposition (SVD) on a small downstream calibration set.Fine-tuning then is performed on this lightweight emulator via LoRA. To tacklethe misalignment between the original model and the compressed emulator, wepropose a novel compensation algorithm to correct the fine-tuned LoRA module,which thus can be merged into the original model for inference. EMLoC supportsflexible compression ratios and standard training pipelines, making itadaptable to a wide range of applications. Extensive experiments demonstratethat EMLoC outperforms other baselines across multiple datasets and modalities.Moreover, without quantization, EMLoC enables fine-tuning of a 38B model on asingle 24GB consumer GPU-bringing efficient and practical model adaptation toindividual users.</description>
      <author>example@mail.com (Hsi-Che Lin, Yu-Chu Yu, Kai-Po Chang, Yu-Chiang Frank Wang)</author>
      <guid isPermaLink="false">2506.12015v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised Learning of Echocardiographic Video Representations via Online Cluster Distillation</title>
      <link>http://arxiv.org/abs/2506.11777v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DISCOVR的自监督学习框架，用于心脏超声视频表示学习，并在多个超声心动图数据集上取得了优于现有方法的性能。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在自然图像和视频理解方面取得了重大进展，但在超声心动图等领域仍面临挑战，如细微的解剖结构、复杂的时间动态以及缺乏特定领域预训练模型等问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效处理超声心动图视频表示学习的自监督学习框架。&lt;h4&gt;方法&lt;/h4&gt;DISCOVR结合了基于聚类的视频编码器和在线图像编码器，通过语义簇蒸馏损失将解剖知识从图像编码器传递到视频编码器，从而实现具有精细语义理解的时序一致表示。&lt;h4&gt;主要发现&lt;/h4&gt;DISCOVR在零样本和线性探测设置中优于专门的视频异常检测方法和最先进的视频自监督学习基线，并在分割迁移方面取得了优异的性能。&lt;h4&gt;结论&lt;/h4&gt;DISCOVR是一种有效的自监督学习框架，能够提高超声心动图视频表示学习的性能，为该领域的研究提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised learning (SSL) has achieved major advances in natural images and video understanding, but challenges remain in domains like echocardiography (heart ultrasound) due to subtle anatomical structures, complex temporal dynamics, and the current lack of domain-specific pre-trained models. Existing SSL approaches such as contrastive, masked modeling, and clustering-based methods struggle with high intersample similarity, sensitivity to low PSNR inputs common in ultrasound, or aggressive augmentations that distort clinically relevant features. We present DISCOVR (Distilled Image Supervision for Cross Modal Video Representation), a self-supervised dual branch framework for cardiac ultrasound video representation learning. DISCOVR combines a clustering-based video encoder that models temporal dynamics with an online image encoder that extracts fine-grained spatial semantics. These branches are connected through a semantic cluster distillation loss that transfers anatomical knowledge from the evolving image encoder to the video encoder, enabling temporally coherent representations enriched with fine-grained semantic understanding. Evaluated on six echocardiography datasets spanning fetal, pediatric, and adult populations, DISCOVR outperforms both specialized video anomaly detection methods and state-of-the-art video-SSL baselines in zero-shot and linear probing setups, and achieves superior segmentation transfer.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) has achieved major advances in natural imagesand video understanding, but challenges remain in domains like echocardiography(heart ultrasound) due to subtle anatomical structures, complex temporaldynamics, and the current lack of domain-specific pre-trained models. ExistingSSL approaches such as contrastive, masked modeling, and clustering-basedmethods struggle with high intersample similarity, sensitivity to low PSNRinputs common in ultrasound, or aggressive augmentations that distortclinically relevant features. We present DISCOVR (Distilled Image Supervisionfor Cross Modal Video Representation), a self-supervised dual branch frameworkfor cardiac ultrasound video representation learning. DISCOVR combines aclustering-based video encoder that models temporal dynamics with an onlineimage encoder that extracts fine-grained spatial semantics. These branches areconnected through a semantic cluster distillation loss that transfersanatomical knowledge from the evolving image encoder to the video encoder,enabling temporally coherent representations enriched with fine-grainedsemantic understanding. Evaluated on six echocardiography datasets spanningfetal, pediatric, and adult populations, DISCOVR outperforms both specializedvideo anomaly detection methods and state-of-the-art video-SSL baselines inzero-shot and linear probing setups, and achieves superior segmentationtransfer.</description>
      <author>example@mail.com (Divyanshu Mishra, Mohammadreza Salehi, Pramit Saha, Olga Patey, Aris T. Papageorghiou, Yuki M. Asano, J. Alison Noble)</author>
      <guid isPermaLink="false">2506.11777v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Aligned Novel View Image and Geometry Synthesis via Cross-modal Attention Instillation</title>
      <link>http://arxiv.org/abs/2506.11924v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散的框架，通过变形和修复方法进行对齐的新视角图像和几何生成。&lt;h4&gt;背景&lt;/h4&gt;现有的方法需要密集的姿势图像或限于领域视角的姿势嵌入生成模型。&lt;h4&gt;目的&lt;/h4&gt;开发一种不需要密集姿势图像或限制于领域视角的生成模型的新方法。&lt;h4&gt;方法&lt;/h4&gt;该方法利用现成的几何预测器来预测从参考图像中看到的局部几何，并将新视角合成作为图像和几何的修复任务。同时，提出跨模态注意力蒸馏，在训练和推理过程中将图像扩散分支的注意力图注入到平行的几何扩散分支中。此外，引入基于邻近度的网格条件来整合深度和法线线索，在点云之间进行插值，并过滤掉错误预测的几何形状。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在未见过的场景中实现了高保真的预测性视图合成，在插值设置下提供了具有竞争力的重建质量，并产生了几何对齐的彩色点云，用于全面的3D补全。&lt;h4&gt;结论&lt;/h4&gt;该方法在图像和几何上实现了高质量的合成，为3D补全提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;We introduce a diffusion-based framework that performs aligned novel viewimage and geometry generation via a warping-and-inpainting methodology. Unlike prior methods that require dense posed images or pose-embedded generativemodels limited to in-domain views, our method leverages off-the-shelf geometrypredictors to predict partial geometries viewed from reference images, andformulates novel-view synthesis as an inpainting task for both image andgeometry. To ensure accurate alignment between generated images and geometry,we propose cross-modal attention distillation, where attention maps from theimage diffusion branch are injected into a parallel geometry diffusion branchduring both training and inference. This multi-task approach achievessynergistic effects, facilitating geometrically robust image synthesis as wellas well-defined geometry prediction. We further introduce proximity-based meshconditioning to integrate depth and normal cues, interpolating between pointcloud and filtering erroneously predicted geometry from influencing thegeneration process. Empirically, our method achieves high-fidelity extrapolative view synthesis on both image and geometry across a range ofunseen scenes, delivers competitive reconstruction quality under interpolationsettings, and produces geometrically aligned colored point clouds forcomprehensive 3D completion.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a diffusion-based framework that performs aligned novel viewimage and geometry generation via a warping-and-inpainting methodology. Unlikeprior methods that require dense posed images or pose-embedded generativemodels limited to in-domain views, our method leverages off-the-shelf geometrypredictors to predict partial geometries viewed from reference images, andformulates novel-view synthesis as an inpainting task for both image andgeometry. To ensure accurate alignment between generated images and geometry,we propose cross-modal attention distillation, where attention maps from theimage diffusion branch are injected into a parallel geometry diffusion branchduring both training and inference. This multi-task approach achievessynergistic effects, facilitating geometrically robust image synthesis as wellas well-defined geometry prediction. We further introduce proximity-based meshconditioning to integrate depth and normal cues, interpolating between pointcloud and filtering erroneously predicted geometry from influencing thegeneration process. Empirically, our method achieves high-fidelityextrapolative view synthesis on both image and geometry across a range ofunseen scenes, delivers competitive reconstruction quality under interpolationsettings, and produces geometrically aligned colored point clouds forcomprehensive 3D completion. Project page is available athttps://cvlab-kaist.github.io/MoAI.</description>
      <author>example@mail.com (Min-Seop Kwak, Junho Kim, Sangdoo Yun, Dongyoon Han, Taekyoung Kim, Seungryong Kim, Jin-Hwa Kim)</author>
      <guid isPermaLink="false">2506.11924v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>FocalAD: Local Motion Planning for End-to-End Autonomous Driving</title>
      <link>http://arxiv.org/abs/2506.11419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FocalAD的新型端到端自动驾驶框架，该框架专注于关键局部邻居，通过增强局部运动表示来优化规划。&lt;h4&gt;背景&lt;/h4&gt;在端到端自动驾驶中，运动预测对自主车辆规划至关重要。然而，现有方法通常依赖于全局聚合的运动特征，忽略了规划决策主要受少数局部交互代理的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过关注关键局部邻居来改进规划，提高规划可靠性。&lt;h4&gt;方法&lt;/h4&gt;FocalAD包括两个核心模块：Ego-Local-Agents Interactor (ELAI) 和 Focal-Local-Agents Loss (FLA Loss)。ELAI通过图表示进行自我中心交互，以捕获与局部邻居的运动动力学，增强自我规划和代理运动查询。FLA Loss通过增加决策关键邻近代理的权重，引导模型优先考虑与规划更相关的代理。&lt;h4&gt;主要发现&lt;/h4&gt;FocalAD在open-loop nuScenes数据集和closed-loop Bench2Drive基准上优于现有最先进的方法。特别是在注重鲁棒性的Adv-nuScenes数据集上，FocalAD实现了更大的改进，将平均碰撞率降低了41.9%，与DiffusionDrive相比降低了15.6%，与SparseDrive相比降低了15.6%。&lt;h4&gt;结论&lt;/h4&gt;FocalAD框架通过关注局部邻居和优化局部运动表示，提高了自动驾驶的规划可靠性和安全性。&lt;h4&gt;翻译&lt;/h4&gt;In end-to-end autonomous driving, motion prediction plays a pivotal role in ego-vehicle planning. However, existing methods often rely on globally aggregated motion features, ignoring the fact that planning decisions are primarily influenced by a small number of locally interacting agents. Failing to attend to these critical local interactions can obscure potential risks and undermine planning reliability. In this work, we propose FocalAD, a novel end-to-end autonomous driving framework that focuses on critical local neighbors and refines planning by enhancing local motion representations. Specifically, FocalAD comprises two core modules: the Ego-Local-Agents Interactor (ELAI) and the Focal-Local-Agents Loss (FLA Loss). ELAI conducts a graph-based ego-centric interaction representation that captures motion dynamics with local neighbors to enhance both ego planning and agent motion queries. FLA Loss increases the weights of decision-critical neighboring agents, guiding the model to prioritize those more relevant to planning. Extensive experiments show that FocalAD outperforms existing state-of-the-art methods on the open-loop nuScenes datasets and closed-loop Bench2Drive benchmark. Notably, on the robustness-focused Adv-nuScenes dataset, FocalAD achieves even greater improvements, reducing the average collision rate by 41.9% compared to DiffusionDrive and by 15.6% compared to SparseDrive.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In end-to-end autonomous driving,the motion prediction plays a pivotal rolein ego-vehicle planning. However, existing methods often rely on globallyaggregated motion features, ignoring the fact that planning decisions areprimarily influenced by a small number of locally interacting agents. Failingto attend to these critical local interactions can obscure potential risks andundermine planning reliability. In this work, we propose FocalAD, a novelend-to-end autonomous driving framework that focuses on critical localneighbors and refines planning by enhancing local motion representations.Specifically, FocalAD comprises two core modules: the Ego-Local-AgentsInteractor (ELAI) and the Focal-Local-Agents Loss (FLA Loss). ELAI conducts agraph-based ego-centric interaction representation that captures motiondynamics with local neighbors to enhance both ego planning and agent motionqueries. FLA Loss increases the weights of decision-critical neighboringagents, guiding the model to prioritize those more relevant to planning.Extensive experiments show that FocalAD outperforms existing state-of-the-artmethods on the open-loop nuScenes datasets and closed-loop Bench2Drivebenchmark. Notably, on the robustness-focused Adv-nuScenes dataset, FocalADachieves even greater improvements, reducing the average colilision rate by41.9% compared to DiffusionDrive and by 15.6% compared to SparseDrive.</description>
      <author>example@mail.com (Bin Sun, Boao Zhang, Jiayi Lu, Xinjie Feng, Jiachen Shang, Rui Cao, Mengchao Zheng, Chuanye Wang, Shichun Yang, Yaoguang Cao, Ziying Song)</author>
      <guid isPermaLink="false">2506.11419v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Vision-based Lifting of 2D Object Detections for Automated Driving</title>
      <link>http://arxiv.org/abs/2506.11839v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  https://ieeexplore.ieee.org/document/9190325&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图像的3D物体检测方法，旨在为自动驾驶提供一种成本效益高的替代方案，以相机代替LiDAR。&lt;h4&gt;背景&lt;/h4&gt;基于图像的3D物体检测是自动驾驶不可或缺的一部分，因为大多数现代汽车已经配备了廉价的车载摄像头。由于LiDAR能够提供准确的深度信息，目前大多数最先进的3D物体检测器都依赖于LiDAR数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，将现有基于视觉的2D算法的结果提升到3D检测，仅使用相机作为LiDAR的替代品。&lt;h4&gt;方法&lt;/h4&gt;与现有方法不同，本文不仅关注汽车，还关注所有类型的道路使用者。为了尽可能降低计算工作量，本文首次使用2D卷积神经网络（CNN）处理每个2D检测的点云。&lt;h4&gt;主要发现&lt;/h4&gt;在具有挑战性的KITTI 3D物体检测基准上的评估表明，该方法的结果与最先进的基于图像的方法相当，而运行时间仅为后者的三分之一。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在保持计算效率的同时，实现了与最先进方法相当的性能，为自动驾驶中的3D物体检测提供了一种有前景的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于图像的3D物体检测方法，旨在为自动驾驶提供一种成本效益高的替代方案，以相机代替LiDAR。由于LiDAR能够提供准确的深度信息，目前大多数最先进的3D物体检测器都依赖于LiDAR数据。本文提出的方法不仅关注汽车，还关注所有类型的道路使用者。为了尽可能降低计算工作量，本文首次使用2D卷积神经网络（CNN）处理每个2D检测的点云。在具有挑战性的KITTI 3D物体检测基准上的评估表明，该方法的结果与最先进的基于图像的方法相当，而运行时间仅为后者的三分之一。本文提出的方法在保持计算效率的同时，实现了与最先进方法相当的性能，为自动驾驶中的3D物体检测提供了一种有前景的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.23919/FUSION45008.2020.9190325&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-based 3D object detection is an inevitable part of autonomous drivingbecause cheap onboard cameras are already available in most modern cars.Because of the accurate depth information, currently, most state-of-the-art 3Dobject detectors heavily rely on LiDAR data. In this paper, we propose apipeline which lifts the results of existing vision-based 2D algorithms to 3Ddetections using only cameras as a cost-effective alternative to LiDAR. Incontrast to existing approaches, we focus not only on cars but on all types ofroad users. To the best of our knowledge, we are the first using a 2D CNN toprocess the point cloud for each 2D detection to keep the computational effortas low as possible. Our evaluation on the challenging KITTI 3D object detectionbenchmark shows results comparable to state-of-the-art image-based approacheswhile having a runtime of only a third.</description>
      <author>example@mail.com (Hendrik Königshof, Kun Li, Christoph Stiller)</author>
      <guid isPermaLink="false">2506.11839v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>How Visual Representations Map to Language Feature Space in Multimodal LLMs</title>
      <link>http://arxiv.org/abs/2506.11976v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种方法框架，通过冻结大语言模型（LLM）和视觉Transformer（ViT），并仅在视觉指令调整期间训练线性适配器，来实现视觉和语言表示的对齐。实验结果表明，视觉表示与语言特征表示在中间到后层逐渐对齐，但ViT的输出与LLM早期层之间存在基本不匹配，引发关于当前适配器架构是否优化跨模态表示学习的疑问。&lt;h4&gt;背景&lt;/h4&gt;有效的多模态推理依赖于视觉和语言表示的对齐，但视觉语言模型（VLMs）如何实现这种对齐的机制尚不清楚。&lt;h4&gt;目的&lt;/h4&gt;引入一种方法框架，以实现视觉和语言表示的对齐，并探索VLMs中这种对齐的机制。&lt;h4&gt;方法&lt;/h4&gt;冻结LLM和ViT，仅通过训练线性适配器连接它们。使用预训练的稀疏自编码器（SAEs）作为分析工具，通过分析SAE重建误差、稀疏模式和特征SAE描述来揭示视觉表示与语言特征表示的对齐过程。&lt;h4&gt;主要发现&lt;/h4&gt;视觉表示与语言特征表示在中间到后层逐渐对齐，但ViT的输出与LLM早期层之间存在基本不匹配。&lt;h4&gt;结论&lt;/h4&gt;当前基于适配器的架构可能不是优化跨模态表示学习的最佳选择。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种方法框架，通过故意保持冻结的大语言模型（LLM）和冻结的视觉Transformer（ViT），并通过在视觉指令调整期间仅训练线性适配器来连接它们。这种设计是我们方法的基本原则：通过保持语言模型冻结，我们确保它保持其原始的语言表示，而不会对视觉数据进行适应。因此，线性适配器必须直接将视觉特征映射到LLM的现有表示空间，而不是允许语言模型通过微调发展专门的视觉理解。我们的实验设计独特地使得可以使用预训练的LLM稀疏自编码器（SAEs）作为分析工具。这些SAEs与未更改的语言模型保持完美对齐，并作为学习到的语言特征表示的快照。通过系统地分析SAE重建误差、稀疏模式和特征SAE描述，我们揭示了视觉表示逐渐与语言特征表示对齐的层间进展，并在中间到后层收敛。这表明ViT输出与早期LLM层之间存在基本不匹配，引发了关于当前基于适配器的架构是否优化跨模态表示学习的关键问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective multimodal reasoning depends on the alignment of visual andlinguistic representations, yet the mechanisms by which vision-language models(VLMs) achieve this alignment remain poorly understood. We introduce amethodological framework that deliberately maintains a frozen large languagemodel (LLM) and a frozen vision transformer (ViT), connected solely by traininga linear adapter during visual instruction tuning. This design is fundamentalto our approach: by keeping the language model frozen, we ensure it maintainsits original language representations without adaptation to visual data.Consequently, the linear adapter must map visual features directly into theLLM's existing representational space rather than allowing the language modelto develop specialized visual understanding through fine-tuning. Ourexperimental design uniquely enables the use of pre-trained sparse autoencoders(SAEs) of the LLM as analytical probes. These SAEs remain perfectly alignedwith the unchanged language model and serve as a snapshot of the learnedlanguage feature-representations. Through systematic analysis of SAEreconstruction error, sparsity patterns, and feature SAE descriptions, wereveal the layer-wise progression through which visual representationsgradually align with language feature representations, converging inmiddle-to-later layers. This suggests a fundamental misalignment between ViToutputs and early LLM layers, raising important questions about whether currentadapter-based architectures optimally facilitate cross-modal representationlearning.</description>
      <author>example@mail.com (Constantin Venhoff, Ashkan Khakzar, Sonia Joseph, Philip Torr, Neel Nanda)</author>
      <guid isPermaLink="false">2506.11976v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Coefficient Shape Transfer Learning for Functional Linear Regression</title>
      <link>http://arxiv.org/abs/2506.11367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的迁移学习方法，用于解决功能线性模型中数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;在功能线性模型中，数据稀缺是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种迁移学习方法来解决数据稀缺问题。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了目标模型（目标域）和辅助模型（源域）的样本，将源域中的系数形状知识迁移到目标域。&lt;h4&gt;主要发现&lt;/h4&gt;该方法具有两个关键优势：一是对协变量缩放具有鲁棒性；二是系数形状同质性的概念比传统的系数同质性有更深远的意义，使得方法能够利用更广泛的源域，并显著提高模型估计的准确性。&lt;h4&gt;结论&lt;/h4&gt;该方法的有效性通过全面的模拟研究和应用美国国家健康与营养检查调查的体力活动数据进行的职业时间分析得到了证明。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we develop a novel transfer learning methodology to tackle the challenge of data scarcity in functional linear models. The methodology incorporates samples from the target model (target domain) alongside those from auxiliary models (source domains), transferring knowledge of coefficient shape from the source domains to the target domain. This shape-based knowledge transfer offers two key advantages. First, it is robust to covariate scaling, ensuring effectiveness despite variations in data distributions across different source domains. Second, the notion of coefficient shape homogeneity represents a meaningful advance beyond traditional coefficient homogeneity, allowing the method to exploit a wider range of source domains and achieve significantly improved model estimation. We rigorously analyze the convergence rates of the proposed estimator and examine the minimax optimality. Our findings show that the degree of improvement depends not only on the similarity of coefficient shapes between the target and source domains, but also on coefficient magnitudes and the spectral decay rates of the functional covariates covariance operators. To address situations where only a subset of auxiliary models is informative for the target model, we further develop a data-driven procedure for identifying such informative sources. The effectiveness of the proposed methodology is demonstrated through comprehensive simulation studies and an application to occupation time analysis using physical activity data from the U.S. National Health and Nutrition Examination Survey.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we develop a novel transfer learning methodology to tackle thechallenge of data scarcity in functional linear models. The methodologyincorporates samples from the target model (target domain) alongside those fromauxiliary models (source domains), transferring knowledge of coefficient shapefrom the source domains to the target domain. This shape-based knowledgetransfer offers two key advantages. First, it is robust to covariate scaling,ensuring effectiveness despite variations in data distributions acrossdifferent source domains. Second, the notion of coefficient shape homogeneityrepresents a meaningful advance beyond traditional coefficient homogeneity,allowing the method to exploit a wider range of source domains and achievesignificantly improved model estimation. We rigorously analyze the convergencerates of the proposed estimator and examine the minimax optimality. Ourfindings show that the degree of improvement depends not only on the similarityof coefficient shapes between the target and source domains, but also oncoefficient magnitudes and the spectral decay rates of the functionalcovariates covariance operators. To address situations where only a subset ofauxiliary models is informative for the target model, we further develop adata-driven procedure for identifying such informative sources. Theeffectiveness of the proposed methodology is demonstrated through comprehensivesimulation studies and an application to occupation time analysis usingphysical activity data from the U.S. National Health and Nutrition ExaminationSurvey.</description>
      <author>example@mail.com (Shuhao Jiao, Ian W. Mckeague, N. -H. Chan)</author>
      <guid isPermaLink="false">2506.11367v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>AgriPotential: A Novel Multi-Spectral and Multi-Temporal Remote Sensing Dataset for Agricultural Potentials</title>
      <link>http://arxiv.org/abs/2506.11740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了AgriPotential，一个由多个月Sentinel-2卫星影像组成的创新基准数据集，用于农业潜力预测。&lt;h4&gt;背景&lt;/h4&gt;遥感技术已成为大规模地球监测和土地管理的关键工具。&lt;h4&gt;目的&lt;/h4&gt;AgriPotential旨在提高数据驱动的可持续土地利用规划方法。&lt;h4&gt;方法&lt;/h4&gt;数据集包含对三种主要作物类型（葡萄种植、园艺和农田作物）在不同等级上的像素级标注，支持包括序数回归、多标签分类和时空建模在内的多种机器学习任务。&lt;h4&gt;主要发现&lt;/h4&gt;数据集覆盖了法国南部的多个地区，提供了丰富的光谱信息。&lt;h4&gt;结论&lt;/h4&gt;AgriPotential是第一个专门为农业潜力预测设计的公开数据集。&lt;h4&gt;翻译&lt;/h4&gt;摘要：遥感已成为大规模地球监测和土地管理的关键工具。在本文中，我们介绍了AgriPotential，一个由多个月Sentinel-2卫星影像组成的创新基准数据集。该数据集提供了三种主要作物类型（葡萄种植、园艺和农田作物）在不同等级上的像素级农业潜力标注。AgriPotential支持包括序数回归、多标签分类和时空建模在内的多种机器学习任务。数据覆盖了法国南部的多个地区，提供了丰富的光谱信息。AgriPotential是第一个专门为农业潜力预测设计的公开数据集，旨在提高数据驱动的可持续土地利用规划方法。数据集和代码可在https://zenodo.org/records/15556484免费获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Remote sensing has emerged as a critical tool for large-scale Earthmonitoring and land management. In this paper, we introduce AgriPotential, anovel benchmark dataset composed of Sentinel-2 satellite imagery spanningmultiple months. The dataset provides pixel-level annotations of agriculturalpotentials for three major crop types - viticulture, market gardening, andfield crops - across five ordinal classes. AgriPotential supports a broad rangeof machine learning tasks, including ordinal regression, multi-labelclassification, and spatio-temporal modeling. The data covers diverse areas inSouthern France, offering rich spectral information. AgriPotential is the firstpublic dataset designed specifically for agricultural potential prediction,aiming to improve data-driven approaches to sustainable land use planning. Thedataset and the code are freely accessible at:https://zenodo.org/records/15556484</description>
      <author>example@mail.com (Mohammad El Sakka, Caroline De Pourtales, Lotfi Chaari, Josiane Mothe)</author>
      <guid isPermaLink="false">2506.11740v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty Awareness Enables Efficient Labeling for Cancer Subtyping in Digital Pathology</title>
      <link>http://arxiv.org/abs/2506.11439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种将不确定性感知引入自监督对比学习模型的方法，用于辅助癌症亚型分类，在有限的标注数据下实现了癌症亚型分类的最佳性能。&lt;h4&gt;背景&lt;/h4&gt;机器学习辅助的癌症亚型分类在数字病理学中具有前景，但需要使用专家标注进行仔细训练以确保预测的确定性。&lt;h4&gt;目的&lt;/h4&gt;提出不确定性感知的概念，以改善癌症亚型分类模型的性能，特别是在标注数据有限的情况下。&lt;h4&gt;方法&lt;/h4&gt;通过在每个时代计算证据向量来评估模型预测的置信度，并将不确定性分数作为衡量标准，选择性地标记最关键需要进一步标注的图像，从而迭代地优化训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;使用1-10%的策略性选择的标注，在基准数据集上实现了癌症亚型分类的领先性能。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅策略性地指导标注过程以减少对大量标注数据集的需求，而且提高了分类的精确性和效率，对于标注数据有限的环境特别有益，为数字病理学的未来研究和应用提供了有希望的方向。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces the concept of uncertainty awareness into a self-supervised contrastive learning model for the purpose of assisting in cancer subtyping in digital pathology. The background of this study is that cancer subtyping models require careful training with expert annotations to ensure the certainty of their predictions. The aim of this study is to improve the performance of cancer subtyping models, especially in the context of limited labeled data. The method involves calculating an evidence vector at each epoch to assess the model's confidence in its predictions, and using the derived uncertainty score as a metric to selectively label the most crucial images that require further annotation, thus iteratively refining the training process. With just 1-10% of strategically selected annotations, the method achieves state-of-the-art performance in cancer subtyping on benchmark datasets. The conclusion is that this method not only strategically guides the annotation process to minimize the need for extensive labeled datasets but also improves the precision and efficiency of classifications, which is particularly beneficial in settings where the availability of labeled data is limited, offering a promising direction for future research and application in digital pathology.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learning-assisted cancer subtyping is a promising avenue in digitalpathology. Cancer subtyping models, however, require careful training usingexpert annotations so that they can be inferred with a degree of knowncertainty (or uncertainty). To this end, we introduce the concept ofuncertainty awareness into a self-supervised contrastive learning model. Thisis achieved by computing an evidence vector at every epoch, which assesses themodel's confidence in its predictions. The derived uncertainty score is thenutilized as a metric to selectively label the most crucial images that requirefurther annotation, thus iteratively refining the training process. With just1-10% of strategically selected annotations, we attain state-of-the-artperformance in cancer subtyping on benchmark datasets. Our method not onlystrategically guides the annotation process to minimize the need for extensivelabeled datasets, but also improves the precision and efficiency ofclassifications. This development is particularly beneficial in settings wherethe availability of labeled data is limited, offering a promising direction forfuture research and application in digital pathology.</description>
      <author>example@mail.com (Nirhoshan Sivaroopan, Chamuditha Jayanga Galappaththige, Chalani Ekanayake, Hasindri Watawana, Ranga Rodrigo, Chamira U. S. Edussooriya, Dushan N. Wadduwage)</author>
      <guid isPermaLink="false">2506.11439v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>How do Probabilistic Graphical Models and Graph Neural Networks Look at Network Data?</title>
      <link>http://arxiv.org/abs/2506.11869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了概率图模型（PGMs）和图神经网络（GNNs）在处理网络数据方面的比较，通过解决链接预测任务，对合成和真实网络进行了实验。&lt;h4&gt;背景&lt;/h4&gt;图是表示关系数据的强大数据结构，在描述复杂现实世界系统中被广泛使用。PGMs和GNNs都能利用图结构数据，但它们的内在工作方式不同。&lt;h4&gt;目的&lt;/h4&gt;比较PGMs和GNNs在网络数据中捕获信息的能力。&lt;h4&gt;方法&lt;/h4&gt;通过解决链接预测任务，对合成和真实网络进行实验，包括PGMs和GNNs如何处理输入特征，以及它们对噪声特征和图异质性的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;当输入特征低维或噪声时，GNNs的表现不如PGMs，这在许多现实场景中很常见，例如节点属性可能是标量或噪声。当图异质性增加时，PGMs比GNNs更鲁棒。此外，还比较了两个框架的计算复杂性和可解释性。&lt;h4&gt;结论&lt;/h4&gt;PGMs和GNNs在处理网络数据方面有各自的优势和局限性，具体取决于数据的特征和任务的需求。&lt;h4&gt;翻译&lt;/h4&gt;Graphs are a powerful data structure for representing relational data and are widely used to describe complex real-world systems. Probabilistic Graphical Models (PGMs) and Graph Neural Networks (GNNs) can both leverage graph-structured data, but their inherent functioning is different. The question is how do they compare in capturing the information contained in networked datasets? We address this objective by solving a link prediction task and we conduct three main experiments, on both synthetic and real networks: one focuses on how PGMs and GNNs handle input features, while the other two investigate their robustness to noisy features and increasing heterophily of the graph. PGMs do not necessarily require features on nodes, while GNNs cannot exploit the network edges alone, and the choice of input features matters. We find that GNNs are outperformed by PGMs when input features are low-dimensional or noisy, mimicking many real scenarios where node attributes might be scalar or noisy. Then, we find that PGMs are more robust than GNNs when the heterophily of the graph is increased. Finally, to assess performance beyond prediction tasks, we also compare the two frameworks in terms of their computational complexity and interpretability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs are a powerful data structure for representing relational data and arewidely used to describe complex real-world systems. Probabilistic GraphicalModels (PGMs) and Graph Neural Networks (GNNs) can both leveragegraph-structured data, but their inherent functioning is different. Thequestion is how do they compare in capturing the information contained innetworked datasets? We address this objective by solving a link prediction taskand we conduct three main experiments, on both synthetic and real networks: onefocuses on how PGMs and GNNs handle input features, while the other twoinvestigate their robustness to noisy features and increasing heterophily ofthe graph. PGMs do not necessarily require features on nodes, while GNNs cannotexploit the network edges alone, and the choice of input features matters. Wefind that GNNs are outperformed by PGMs when input features are low-dimensionalor noisy, mimicking many real scenarios where node attributes might be scalaror noisy. Then, we find that PGMs are more robust than GNNs when theheterophily of the graph is increased. Finally, to assess performance beyondprediction tasks, we also compare the two frameworks in terms of theircomputational complexity and interpretability.</description>
      <author>example@mail.com (Michela Lapenna, Caterina De Bacco)</author>
      <guid isPermaLink="false">2506.11869v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Methods for evaluating the resolution of 3D data derived from satellite images</title>
      <link>http://arxiv.org/abs/2506.11876v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文讨论了如何评估3D数据的分辨率，并介绍了基于高分辨率参考机载激光雷达的自动化评估工具和工作流程。&lt;h4&gt;背景&lt;/h4&gt;从卫星图像中获得的3D数据对于需要大范围覆盖或涉及无法通过机载激光雷达或相机访问地点的场景建模应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;测量这种数据的分辨率对于确定任务效用和跟踪改进非常重要。&lt;h4&gt;方法&lt;/h4&gt;论文考虑了评估点云、数字表面模型和3D网格模型的分辨率的方法。&lt;h4&gt;主要发现&lt;/h4&gt;论文描述了3D度量评估工具和工作流程，并展示了使用不同质量数据的结果分析。&lt;h4&gt;结论&lt;/h4&gt;论文提出了用于评估3D数据分辨率的工具和方法，并通过实验验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;The paper discusses methods for evaluating the resolution of 3D data and introduces automated evaluation tools and workflows based on high-resolution reference airborne lidar. The background is that 3D data derived from satellite images is essential for scene modeling applications requiring large-scale coverage or involving locations not accessible by airborne lidar or cameras. The purpose is to measure the resolution of this data, which is important for determining mission utility and tracking improvements. The methods considered in the paper are to evaluate the resolution of point clouds, digital surface models, and 3D mesh models. The main findings are that 3D metric evaluation tools and workflows are described, and the results of analyses with data of varying quality are presented. The conclusion is that tools and methods for evaluating the resolution of 3D data have been proposed and verified by experiments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D data derived from satellite images is essential for scene modelingapplications requiring large-scale coverage or involving locations notaccessible by airborne lidar or cameras. Measuring the resolution of this datais important for determining mission utility and tracking improvements. In thiswork, we consider methods to evaluate the resolution of point clouds, digitalsurface models, and 3D mesh models. We describe 3D metric evaluation tools andworkflows that enable automated evaluation based on high-resolution referenceairborne lidar, and we present results of analyses with data of varyingquality.</description>
      <author>example@mail.com (Christina Selby, Holden Bindl, Tyler Feldman, Andrew Skow, Nicolas Norena Acosta, Shea Hagstrom, Myron Brown)</author>
      <guid isPermaLink="false">2506.11876v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs</title>
      <link>http://arxiv.org/abs/2506.11558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为DaMO的数据高效视频语言模型，用于提高视频语言理解中的时间推理能力。&lt;h4&gt;背景&lt;/h4&gt;尽管大语言模型（LLMs）已扩展到视频领域，但现有的视频语言模型（VideoLLMs）在细粒度时间推理方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;设计DaMO模型以实现准确的时间推理和多模态理解。&lt;h4&gt;方法&lt;/h4&gt;DaMO的核心是时间感知的Fuseformer，采用分层双流架构，逐步捕捉每个模态中的时间动态，并有效地融合互补的视觉和音频信息。为了提高计算效率，DaMO集成了全局残差，减少空间冗余的同时保留关键语义细节。通过结构化的四阶段渐进式训练方法训练DaMO，逐步赋予模型多模态对齐、语义接地和时间推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;在时间接地和视频问答基准测试中，DaMO在需要精确时间对齐和推理的任务上优于先前的方法。&lt;h4&gt;结论&lt;/h4&gt;DaMO为数据高效的视频语言建模指出了一个有前景的方向。&lt;h4&gt;翻译&lt;/h4&gt;Large Language Models (LLMs) have recently been extended to the video domain,enabling sophisticated video-language understanding. However, existing VideoLLMs often exhibit limitations in fine-grained temporal reasoning, restrictingtheir ability to precisely attribute responses to specific video moments,especially under constrained supervision. We introduce DaMO, a data-efficientVideo LLM explicitly designed for accurate temporal reasoning and multimodalunderstanding. At its core, the proposed Temporal-aware Fuseformer employs ahierarchical dual-stream architecture that progressively captures temporaldynamics within each modality and effectively fuses complementary visual andaudio information. To further enhance computational efficiency, DaMO integratesa global residual that reduces spatial redundancy while preserving essentialsemantic details. We train DaMO via a structured four-stage progressivetraining paradigm, incrementally equipping the model with multimodal alignment,semantic grounding, and temporal reasoning capabilities. This work alsocontributes multiple datasets augmented from existing ones with GPT-generatedtemporally grounded QA pairs for tasks requiring temporal supervision.Comprehensive experiments on temporal grounding and video QA benchmarksdemonstrate that DaMO consistently surpasses prior methods, particularly intasks demanding precise temporal alignment and reasoning. Our work establishesa promising direction for data-efficient video-language modeling.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have recently been extended to the video domain,enabling sophisticated video-language understanding. However, existing VideoLLMs often exhibit limitations in fine-grained temporal reasoning, restrictingtheir ability to precisely attribute responses to specific video moments,especially under constrained supervision. We introduce DaMO, a data-efficientVideo LLM explicitly designed for accurate temporal reasoning and multimodalunderstanding. At its core, the proposed Temporal-aware Fuseformer employs ahierarchical dual-stream architecture that progressively captures temporaldynamics within each modality and effectively fuses complementary visual andaudio information. To further enhance computational efficiency, DaMO integratesa global residual that reduces spatial redundancy while preserving essentialsemantic details. We train DaMO via a structured four-stage progressivetraining paradigm, incrementally equipping the model with multimodal alignment,semantic grounding, and temporal reasoning capabilities. This work alsocontributes multiple datasets augmented from existing ones with GPT-generatedtemporally grounded QA pairs for tasks requiring temporal supervision.Comprehensive experiments on temporal grounding and video QA benchmarksdemonstrate that DaMO consistently surpasses prior methods, particularly intasks demanding precise temporal alignment and reasoning. Our work establishesa promising direction for data-efficient video-language modeling.</description>
      <author>example@mail.com (Bo-Cheng Chiu, Jen-Jee Chen, Yu-Chee Tseng, Feng-Chi Chen)</author>
      <guid isPermaLink="false">2506.11558v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Improving Large Language Model Safety with Contrastive Representation Learning</title>
      <link>http://arxiv.org/abs/2506.11938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对大型语言模型（LLMs）的防御框架，通过对比表征学习（CRL）方法增强模型对对抗攻击的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型具有深远的社会影响，但它们对多样化且未受控制的输入的响应能力使其容易受到对抗攻击的攻击。&lt;h4&gt;目的&lt;/h4&gt;提出一种防御框架，以增强LLMs对对抗攻击的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;将模型防御问题表述为对比表征学习问题，通过使用基于三元组的损失函数和对抗硬负样本挖掘来微调模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法优于先前的基于表征工程的防御方法，在不影响标准性能的情况下，提高了模型对输入级别和嵌入空间攻击的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的防御框架为提高LLMs对对抗攻击的鲁棒性提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大型语言模型（LLMs）是具有深远社会影响的强大工具，然而它们对多样化且未受控制的输入生成响应的能力使它们容易受到对抗攻击。尽管现有的防御方法在应对不同攻击类型时往往难以泛化，但最近在表征工程方面的进步提供了有希望的替代方案。在这项工作中，我们提出了一种将模型防御问题表述为对比表征学习（CRL）问题的防御框架。我们的方法通过结合基于三元组的损失函数和对抗硬负样本挖掘来微调模型。我们在多个模型上的实验结果表明，我们的方法优于先前的基于表征工程的防御方法，在不损害标准性能的情况下，提高了对输入级别和嵌入空间攻击的鲁棒性。我们的代码可在https://github.com/samuelsimko/crl-llm-defense上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) are powerful tools with profound societalimpacts, yet their ability to generate responses to diverse and uncontrolledinputs leaves them vulnerable to adversarial attacks. While existing defensesoften struggle to generalize across varying attack types, recent advancementsin representation engineering offer promising alternatives. In this work, wepropose a defense framework that formulates model defense as a contrastiverepresentation learning (CRL) problem. Our method finetunes a model using atriplet-based loss combined with adversarial hard negative mining to encourageseparation between benign and harmful representations. Our experimental resultsacross multiple models demonstrate that our approach outperforms priorrepresentation engineering-based defenses, improving robustness against bothinput-level and embedding-space attacks without compromising standardperformance. Our code is available athttps://github.com/samuelsimko/crl-llm-defense</description>
      <author>example@mail.com (Samuel Simko, Mrinmaya Sachan, Bernhard Schölkopf, Zhijing Jin)</author>
      <guid isPermaLink="false">2506.11938v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Many-Body Neural Network Wavefunction for a Non-Hermitian Ising Chain</title>
      <link>http://arxiv.org/abs/2506.11222v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用神经网络方法来研究非厄米量子系统的基态性质，特别是对于具有复杂谱的量子光学材料。&lt;h4&gt;背景&lt;/h4&gt;非厄米量子系统在描述开放量子系统、非平衡动力学和工程量子光学材料方面具有重要意义。然而，由于希尔伯特空间的指数级扩展和异常点的出现，求解非厄米系统的基态性质具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;研究使用不同的神经网络架构来探究具有复杂谱的对称性时间、一维非厄米横向场伊辛模型的基态性质。&lt;h4&gt;方法&lt;/h4&gt;采用循环神经网络（RNN）、受限玻尔兹曼机（RBM）和多层感知器（MLP）等不同的神经网络架构，构建基于神经网络的多体波函数，并通过恢复小系统尺寸下模型的基态性质来验证方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;对于小系统尺寸，神经网络方法与精确对角化（ED）方法的结果吻合良好。对于较大系统尺寸，RNN的表现优于RBM和MLP。通过迁移学习，RBM和MLP的准确性可以显著提高，使得它们在较大系统尺寸下的表现与RNN相当。&lt;h4&gt;结论&lt;/h4&gt;神经网络方法在准确捕捉非厄米量子系统的低能物理方面具有潜力，特别是在研究具有复杂谱的量子光学材料时。&lt;h4&gt;翻译&lt;/h4&gt;摘要：非厄米（NH）量子系统已成为描述开放量子系统、非平衡动力学和工程量子光学材料的有力框架。然而，由于希尔伯特空间的指数级扩展和异常点的出现，求解非厄米系统的基态性质具有挑战性。另一个挑战来自传统方法（如精确对角化）的限制。在过去十年中，神经网络（NN）在近似多体波函数方面显示出希望，但它们在非厄米系统中的应用仍然在很大程度上未被探索。在本文中，我们通过采用循环神经网络（RNN）、受限玻尔兹曼机（RBM）和多层感知器（MLP）等不同的神经网络架构，研究了具有复杂谱的对称性时间、一维非厄米横向场伊辛模型的基态性质。我们构建了基于神经网络的多体波函数，并通过恢复小系统尺寸下模型的基态性质来验证我们的方法，发现与精确对角化方法结果吻合良好。此外，对于较大系统尺寸，我们证明了RNN的表现优于RBM和MLP。然而，我们表明通过迁移学习，RBM和MLP的准确性可以显著提高，使得它们在较大系统尺寸下的表现与RNN相当。这些结果突出了基于神经网络方法——尤其是对于准确捕捉非厄米量子系统的低能物理——的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Non-Hermitian (NH) quantum systems have emerged as a powerful framework fordescribing open quantum systems, non-equilibrium dynamics, and engineeredquantum optical materials. However, solving the ground-state properties of NHsystems is challenging due to the exponential scaling of the Hilbert space, andexotic phenomena such as the emergence of exceptional points. Another challengearises from the limitations of traditional methods like exact diagonalization(ED). For the past decade, neural networks (NN) have shown promise inapproximating many-body wavefunctions, yet their application to NH systemsremains largely unexplored. In this paper, we explore different NNarchitectures to investigate the ground-state properties of aparity-time-symmetric, one-dimensional NH, transverse field Ising model with acomplex spectrum by employing a recurrent neural network (RNN), a restrictedBoltzmann machine (RBM), and a multilayer perceptron (MLP). We construct theNN-based many-body wavefunctions and validate our approach by recovering theground-state properties of the model for small system sizes, finding excellentagreement with ED. Furthermore, for larger system sizes, we demonstrate thatthe RNN outperforms both the RBM and MLP. However, we show that the accuracy ofthe RBM and MLP can be significantly improved through transfer learning,allowing them to perform comparably to the RNN for larger system sizes. Theseresults highlight the potential of neural network-basedapproaches--particularly for accurately capturing the low-energy physics of NHquantum systems.</description>
      <author>example@mail.com (Lavoisier Wah, Remmy Zen, Flore K. Kunst)</author>
      <guid isPermaLink="false">2506.11222v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Teleoperated Driving: a New Challenge for 3D Object Detection in Compressed Point Clouds</title>
      <link>http://arxiv.org/abs/2506.11804v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Transactions on Intelligent Transportation Systems&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，互联设备在多个领域得到发展，从娱乐到教育和工业应用。这种趋势由于传感器数量的增加和访问强大硬件和软件的便利性而加速。其中，远程操控驾驶（TD）领域显著受益。本研究从点云数据中检测车辆和行人的存在，以实现安全的TD操作。&lt;h4&gt;背景&lt;/h4&gt;互联设备的发展在多个领域得到扩展，传感器数量的增加和访问强大硬件和软件的便利性推动了这一趋势。&lt;h4&gt;目的&lt;/h4&gt;检测点云数据中的车辆和行人存在，以支持安全的TD操作。&lt;h4&gt;方法&lt;/h4&gt;本研究使用SELMA数据集，这是一个多模式、开源的自动驾驶合成数据集，我们通过包含3D对象的边界框来扩展该数据集以支持对象检测。分析了最先进压缩算法和对象检测器在不同指标下的性能，包括压缩效率、压缩/解压缩和推理时间，以及检测精度。此外，还测量了压缩和检测对V2X网络的影响，包括数据率和延迟，与3GPP对TD应用的要求相比较。&lt;h4&gt;主要发现&lt;/h4&gt;分析了压缩算法和对象检测器的性能，并测量了压缩和检测对V2X网络的影响。&lt;h4&gt;结论&lt;/h4&gt;通过使用SELMA数据集和先进的算法，实现了对车辆和行人的有效检测，支持了安全的TD操作。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, the development of interconnected devices has expanded in many fields, from infotainment to education and industrial applications. This trend has been accelerated by the increased number of sensors and accessibility to powerful hardware and software. One area that significantly benefits from these advancements is Teleoperated Driving (TD). In this scenario, a controller drives safely a vehicle from remote leveraging sensors data generated onboard the vehicle, and exchanged via Vehicle-to-Everything (V2X) communications. In this work, we tackle the problem of detecting the presence of cars and pedestrians from point cloud data to enable safe TD operations. More specifically, we exploit the SELMA dataset, a multimodal, open-source, synthetic dataset for autonomous driving, that we expanded by including the ground-truth bounding boxes of 3D objects to support object detection. We analyze the performance of state-of-the-art compression algorithms and object detectors under several metrics, including compression efficiency, (de)compression and inference time, and detection accuracy. Moreover, we measure the impact of compression and detection on the V2X network in terms of data rate and latency with respect to 3GPP requirements for TD applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, the development of interconnected devices has expanded inmany fields, from infotainment to education and industrial applications. Thistrend has been accelerated by the increased number of sensors and accessibilityto powerful hardware and software. One area that significantly benefits fromthese advancements is Teleoperated Driving (TD). In this scenario, a controllerdrives safely a vehicle from remote leveraging sensors data generated onboardthe vehicle, and exchanged via Vehicle-to-Everything (V2X) communications. Inthis work, we tackle the problem of detecting the presence of cars andpedestrians from point cloud data to enable safe TD operations. Morespecifically, we exploit the SELMA dataset, a multimodal, open-source,synthetic dataset for autonomous driving, that we expanded by including theground-truth bounding boxes of 3D objects to support object detection. Weanalyze the performance of state-of-the-art compression algorithms and objectdetectors under several metrics, including compression efficiency,(de)compression and inference time, and detection accuracy. Moreover, wemeasure the impact of compression and detection on the V2X network in terms ofdata rate and latency with respect to 3GPP requirements for TD applications.</description>
      <author>example@mail.com (Filippo Bragato, Michael Neri, Paolo Testolina, Marco Giordani, Federica Battisti)</author>
      <guid isPermaLink="false">2506.11804v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Taxonomy of reduction matrices for Graph Coarsening</title>
      <link>http://arxiv.org/abs/2506.11743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了图粗化在图信号处理和机器学习中的应用，提出了一种更通用的降维矩阵概念，并通过修改降维矩阵来减少限制谱近似（RSA）损失。&lt;h4&gt;背景&lt;/h4&gt;图粗化通过降维矩阵和提升矩阵将图信号从原始图投影到粗化图，再返回，但这个过程会损失信息。&lt;h4&gt;目的&lt;/h4&gt;减少图粗化过程中的信息损失，引入更通用的降维矩阵概念，并研究其性质。&lt;h4&gt;方法&lt;/h4&gt;提出了新的降维矩阵概念，并建立了“可接受”的降维矩阵家族分类，讨论了这些矩阵必须满足的性质以及是否具有封闭形式的描述。&lt;h4&gt;主要发现&lt;/h4&gt;发现仅对提升矩阵施加约束可以确保重要的对象如粗化图的邻接矩阵或拉普拉斯矩阵的存在，并通过修改降维矩阵可以进一步减少RSA。&lt;h4&gt;结论&lt;/h4&gt;通过修改降维矩阵，可以在固定提升矩阵的粗化过程中减少RSA损失，并展示了这种选择对粗化图上的节点分类任务的影响。&lt;h4&gt;翻译&lt;/h4&gt;Graph coarsening aims to diminish the size of a graph to lighten its memory footprint, and has numerous applications in graph signal processing and machine learning. It is usually defined using a reduction matrix and a lifting matrix, which, respectively, allows to project a graph signal from the original graph to the coarsened one and back. This results in a loss of information measured by the so-called Restricted Spectral Approximation (RSA). Most coarsening frameworks impose a fixed relationship between the reduction and lifting matrices, generally as pseudo-inverses of each other, and seek to define a coarsening that minimizes the RSA. In this paper, we remark that the roles of these two matrices are not entirely symmetric: indeed, putting constraints on the lifting matrix alone ensures the existence of important objects such as the coarsened graph's adjacency matrix or Laplacian. In light of this, in this paper, we introduce a more general notion of reduction matrix, that is not necessarily the pseudo-inverse of the lifting matrix. We establish a taxonomy of 'admissible' families of reduction matrices, discuss the different properties that they must satisfy and whether they admit a closed-form description or not. We show that, for a fixed coarsening represented by a fixed lifting matrix, the RSA can be further reduced simply by modifying the reduction matrix. We explore different examples, including some based on a constrained optimization process of the RSA. Since this criterion has also been linked to the performance of Graph Neural Networks, we also illustrate the impact of this choice on different node classification tasks on coarsened graphs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph coarsening aims to diminish the size of a graph to lighten its memoryfootprint, and has numerous applications in graph signal processing and machinelearning. It is usually defined using a reduction matrix and a lifting matrix,which, respectively, allows to project a graph signal from the original graphto the coarsened one and back. This results in a loss of information measuredby the so-called Restricted Spectral Approximation (RSA). Most coarseningframeworks impose a fixed relationship between the reduction and liftingmatrices, generally as pseudo-inverses of each other, and seek to define acoarsening that minimizes the RSA. In this paper, we remark that the roles ofthese two matrices are not entirely symmetric: indeed, putting constraints onthe lifting matrix alone ensures the existence of important objects such as thecoarsened graph's adjacency matrix or Laplacian. In light of this, in thispaper, we introduce a more general notion of reduction matrix, that is notnecessarily the pseudo-inverse of the lifting matrix. We establish a taxonomyof ``admissible'' families of reduction matrices, discuss the differentproperties that they must satisfy and whether they admit a closed-formdescription or not. We show that, for a fixed coarsening represented by a fixedlifting matrix, the RSA can be further reduced simply by modifying thereduction matrix. We explore different examples, including some based on aconstrained optimization process of the RSA. Since this criterion has also beenlinked to the performance of Graph Neural Networks, we also illustrate theimpact of this choices on different node classification tasks on coarsenedgraphs.</description>
      <author>example@mail.com (Antonin Joly, Nicolas Keriven, Aline Roumy)</author>
      <guid isPermaLink="false">2506.11743v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Your Ride, Your Rules: Psychology and Cognition Enabled Automated Driving Systems</title>
      <link>http://arxiv.org/abs/2506.11842v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 figures,29 pages, one colummn&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PACE-ADS的自动驾驶系统，旨在提升自动驾驶车辆与乘客的交互，提高舒适度和信任度，以促进自动驾驶技术的普及。&lt;h4&gt;背景&lt;/h4&gt;尽管自动驾驶技术发展迅速，但现有自动驾驶车辆与乘客之间的双向通信效果不佳，这限制了个性化服务和从故障中恢复的能力，从而降低了舒适度和信任度。&lt;h4&gt;目的&lt;/h4&gt;提出PACE-ADS框架，通过感知、解释和响应外部交通和内部乘客状态，实现以人为中心的自动驾驶。&lt;h4&gt;方法&lt;/h4&gt;PACE-ADS包含三个基于基础模型的智能体：驾驶员智能体分析驾驶环境，心理学家智能体解释乘客的心理信号和认知命令，协调者智能体整合这些输入以产生高级行为决策和操作参数。&lt;h4&gt;主要发现&lt;/h4&gt;PACE-ADS在模拟测试中表现良好，能够根据乘客状态调整驾驶风格，提高乘坐舒适度，并通过自主推理或人工引导安全地从故障中恢复。&lt;h4&gt;结论&lt;/h4&gt;PACE-ADS展示了基于语言模型（LLM）的框架在连接机器自主性和以人为本的驾驶之间的潜力。&lt;h4&gt;翻译&lt;/h4&gt;尽管自动驾驶技术取得了快速发展，但当前自动驾驶汽车（AV）与乘客之间的双向通信效果不佳，这限制了个性化服务和从停驶状态中恢复的能力，从而降低了舒适度和信任度。我们提出了PACE-ADS（心理学和认知赋能的自动驾驶系统），这是一个以人为本的自动驾驶框架，它使自动驾驶汽车能够感知、解释和响应外部交通和内部乘客状态。PACE-ADS由三个基于基础模型的智能体组成：驾驶员智能体分析驾驶环境，心理学家智能体解释乘客的心理信号（例如，脑电图、心率、面部表情）和认知命令（例如，语音），协调者智能体整合这些输入以产生高级行为决策和操作参数。PACE-ADS不是取代现有的AV模块，而是在行为级别上与之互补，将低级控制委托给本机AV系统。这种分离实现了闭环适应，并支持跨不同平台的集成。我们在涉及交通信号灯、行人、工作区和跟车等多种场景的模拟中评估了PACE-ADS。结果表明，PACE-ADS能够根据乘客状态调整驾驶风格，提高乘坐舒适度，并通过自主推理或人工引导安全地从停驶状态中恢复。我们的发现突显了基于语言模型（LLM）的框架在连接机器自主性和以人为本的驾驶之间的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite rapid advances in autonomous driving, current autonomous vehicles(AVs) lack effective bidirectional communication with occupants, limitingpersonalization and recovery from immobilization. This reduces comfort andtrust, potentially slowing broader AV adoption. We propose PACE-ADS (Psychologyand Cognition Enabled Automated Driving Systems), a human-centered autonomyframework that enables AVs to sense, interpret, and respond to both externaltraffic and internal occupant states. PACE-ADS comprises three foundationmodel-based agents: a Driver Agent that analyzes the driving context, aPsychologist Agent that interprets occupant psychological signals (e.g., EEG,heart rate, facial expressions) and cognitive commands (e.g., speech), and aCoordinator Agent that integrates these inputs to produce high-level behaviordecisions and operational parameters. Rather than replacing existing AVmodules, PACE-ADS complements them by operating at the behavioral level,delegating low-level control to native AV systems. This separation enablesclosed-loop adaptation and supports integration across diverse platforms. Weevaluate PACE-ADS in simulation across varied scenarios involving trafficlights, pedestrians, work zones, and car following. Results show that PACE-ADSadapts driving styles to occupant states, improves ride comfort, and enablessafe recovery from immobilization via autonomous reasoning or human guidance.Our findings highlight the promise of LLM-based frameworks for bridging the gapbetween machine autonomy and human-centered driving.</description>
      <author>example@mail.com (Zhipeng Bao, Qianwen Li)</author>
      <guid isPermaLink="false">2506.11842v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>PiPViT: Patch-based Visual Interpretable Prototypes for Retinal Image Analysis</title>
      <link>http://arxiv.org/abs/2506.10669v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉可解释原型模型PiPViT，用于图像识别，旨在提高原型方法的可解释性，并在医疗成像中实现生物标志物和病变的精确定位。&lt;h4&gt;背景&lt;/h4&gt;原型方法通过学习细粒度部分原型来提高可解释性，但其输入像素空间的可视化并不总是与人类可理解的生物标志物一致。&lt;h4&gt;目的&lt;/h4&gt;提出PiPViT模型，以解决原型方法在医疗成像中可解释性差的问题，并实现生物标志物和病变的精确定位。&lt;h4&gt;方法&lt;/h4&gt;PiPViT利用视觉Transformer（ViT）捕获图像块之间的长距离依赖关系，学习鲁棒且可解释的原型，仅使用图像级标签来近似病变范围。此外，PiPViT还受益于对比学习和多分辨率输入处理，从而在各个尺度上实现生物标志物的有效定位。&lt;h4&gt;主要发现&lt;/h4&gt;在四个数据集上对PiPViT进行评估，其与现有最先进方法相比，在定量性能上具有竞争力，同时提供了更有意义的解释。在保留测试集上的定量评估确认了学习到的原型在语义和临床上的相关性。&lt;h4&gt;结论&lt;/h4&gt;PiPViT可以透明地解释其决策，并帮助临床医生理解诊断结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：背景和目标：基于原型的学习方法通过学习细粒度部分原型来提高可解释性；然而，它们在输入像素空间中的可视化并不总是与人类可理解的生物标志物一致。此外，众所周知的基于原型的方法通常学习非常细粒度的原型，这在医学成像中可解释性较差，因为生物标志物和病变的存在和范围都至关重要。方法：为了解决这些挑战，我们提出了PiPViT（基于补丁的可视化可解释原型），这是一种本质上可解释的原型模型，用于图像识别。利用视觉Transformer（ViT），PiPViT捕获图像块之间的长距离依赖关系，以学习鲁棒、可解释的原型，仅使用图像级标签来近似病变范围。此外，PiPViT受益于对比学习和多分辨率输入处理，这有助于在各个尺度上实现生物标志物的有效定位。结果：我们在四个数据集上对PiPViT进行了视网膜OCT图像分类的评估，与最先进的方法相比，它在定量性能上具有竞争力，同时提供了更有意义的解释。此外，在保留测试集上的定量评估确认了学习到的原型在语义和临床上的相关性。我们相信PiPViT可以透明地解释其决策，并帮助临床医生理解诊断结果。GitHub页面：https://github.com/marziehoghbaie/PiPViT&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Background and Objective: Prototype-based methods improve interpretability bylearning fine-grained part-prototypes; however, their visualization in theinput pixel space is not always consistent with human-understandablebiomarkers. In addition, well-known prototype-based approaches typically learnextremely granular prototypes that are less interpretable in medical imaging,where both the presence and extent of biomarkers and lesions are critical.  Methods: To address these challenges, we propose PiPViT (Patch-based VisualInterpretable Prototypes), an inherently interpretable prototypical model forimage recognition. Leveraging a vision transformer (ViT), PiPViT captureslong-range dependencies among patches to learn robust, human-interpretableprototypes that approximate lesion extent only using image-level labels.Additionally, PiPViT benefits from contrastive learning and multi-resolutioninput processing, which enables effective localization of biomarkers acrossscales.  Results: We evaluated PiPViT on retinal OCT image classification across fourdatasets, where it achieved competitive quantitative performance compared tostate-of-the-art methods while delivering more meaningful explanations.Moreover, quantitative evaluation on a hold-out test set confirms that thelearned prototypes are semantically and clinically relevant. We believe PiPViTcan transparently explain its decisions and assist clinicians in understandingdiagnostic outcomes. Github page: https://github.com/marziehoghbaie/PiPViT</description>
      <author>example@mail.com (Marzieh Oghbaie, Teresa Araújo, Hrvoje Bogunović)</author>
      <guid isPermaLink="false">2506.10669v2</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>SemanticSplat: Feed-Forward 3D Scene Understanding with Language-Aware Gaussian Fields</title>
      <link>http://arxiv.org/abs/2506.09565v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SemanticSplat的前馈语义感知3D重建方法，用于解决现有3D场景理解方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有的3D场景理解方法如LSM，只能从场景中提取基于语言的语义，无法实现整体场景理解，同时几何重建质量低，存在噪声。&lt;h4&gt;目的&lt;/h4&gt;提出SemanticSplat方法，旨在通过统一3D高斯和潜在语义属性，实现几何、外观和语义的联合建模。&lt;h4&gt;方法&lt;/h4&gt;SemanticSplat融合了多种特征场（如LSeg、SAM）和成本体积表示，用于预测语义各向异性高斯，并通过两阶段蒸馏框架从稀疏视角图像中重建整体多模态语义特征场。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在可提示和开放词汇分割等3D场景理解任务中表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;SemanticSplat方法为3D场景理解提供了新的解决方案，并可通过访问https://semanticsplat.github.io查看视频结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Holistic 3D scene understanding, which jointly models geometry, appearance,and semantics, is crucial for applications like augmented reality and roboticinteraction. Existing feed-forward 3D scene understanding methods (e.g., LSM)are limited to extracting language-based semantics from scenes, failing toachieve holistic scene comprehension. Additionally, they suffer fromlow-quality geometry reconstruction and noisy artifacts. In contrast, per-sceneoptimization methods rely on dense input views, which reduces practicality andincreases complexity during deployment. In this paper, we proposeSemanticSplat, a feed-forward semantic-aware 3D reconstruction method, whichunifies 3D Gaussians with latent semantic attributes for jointgeometry-appearance-semantics modeling. To predict the semantic anisotropicGaussians, SemanticSplat fuses diverse feature fields (e.g., LSeg, SAM) with acost volume representation that stores cross-view feature similarities,enhancing coherent and accurate scene comprehension. Leveraging a two-stagedistillation framework, SemanticSplat reconstructs a holistic multi-modalsemantic feature field from sparse-view images. Experiments demonstrate theeffectiveness of our method for 3D scene understanding tasks like promptableand open-vocabulary segmentation. Video results are available athttps://semanticsplat.github.io.</description>
      <author>example@mail.com (Qijing Li, Jingxiang Sun, Liang An, Zhaoqi Su, Hongwen Zhang, Yebin Liu)</author>
      <guid isPermaLink="false">2506.09565v2</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>PromptTSS: A Prompting-Based Approach for Interactive Multi-Granularity Time Series Segmentation</title>
      <link>http://arxiv.org/abs/2506.11170v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is currently under review. The code will be made available  upon acceptance&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PromptTSS的新框架，用于多粒度时间序列数据的分割，以解决现有方法在处理多粒度状态和适应动态环境时的挑战。&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列数据在制造和可穿戴技术等领域广泛存在，这些数据在不同粒度级别上表现出不同的状态，从粗粒度的系统行为到细粒度的详细事件。有效分割和整合这些不同粒度的状态对于预测维护和性能优化等任务至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有时间序列分割方法面临的挑战，即无法在统一模型中处理多粒度状态以及对新动态环境的适应性有限，提出了PromptTSS框架。&lt;h4&gt;方法&lt;/h4&gt;PromptTSS使用一个具有提示机制的统一模型，该机制利用标签和边界信息来引导分割，同时捕捉粗粒度和细粒度模式，并动态适应未见的模式。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，PromptTSS在多粒度分割中的准确率提高了24.49%，在单粒度分割中提高了17.88%，在迁移学习中提高了高达599.24%，证明了其对分层状态和动态时间序列动态的适应性。&lt;h4&gt;结论&lt;/h4&gt;PromptTSS框架能够有效提高时间序列分割的准确率，并适应不同粒度和动态环境的变化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate time series data, collected across various fields such asmanufacturing and wearable technology, exhibit states at multiple levels ofgranularity, from coarse-grained system behaviors to fine-grained, detailedevents. Effectively segmenting and integrating states across these differentgranularities is crucial for tasks like predictive maintenance and performanceoptimization. However, existing time series segmentation methods face two keychallenges: (1) the inability to handle multiple levels of granularity within aunified model, and (2) limited adaptability to new, evolving patterns indynamic environments. To address these challenges, we propose PromptTSS, anovel framework for time series segmentation with multi-granularity states.PromptTSS uses a unified model with a prompting mechanism that leverages labeland boundary information to guide segmentation, capturing both coarse- andfine-grained patterns while adapting dynamically to unseen patterns.Experiments show PromptTSS improves accuracy by 24.49% in multi-granularitysegmentation, 17.88% in single-granularity segmentation, and up to 599.24% intransfer learning, demonstrating its adaptability to hierarchical states andevolving time series dynamics.</description>
      <author>example@mail.com (Ching Chang, Ming-Chih Lo, Wen-Chih Peng, Tien-Fu Chen)</author>
      <guid isPermaLink="false">2506.11170v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Relational GNNs Cannot Learn $C_2$ Features for Planning</title>
      <link>http://arxiv.org/abs/2506.11721v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;R-GNNs是一种基于GNN的学习值函数的方法，能够在给定的规划领域推广到未见问题。R-GNNs的理论动机源于GNN表达能力与一阶逻辑$C_2$（具有两个变量的计数一阶逻辑）之间的联系。在规划背景下，$C_2$特征指的是由规划域的单元和二元谓词定义的关系的$C_2$公式集。一些规划域具有可分解为$C_2$特征算术表达式的最优值函数。研究显示，与实证结果相反，R-GNNs无法学习由$C_2$特征定义的值函数。此外，还确定了可能更好地学习由$C_2$特征定义的值函数的先前GNN架构。&lt;h4&gt;背景&lt;/h4&gt;R-GNNs是基于GNN的，用于学习能够推广到未见问题的值函数的方法。&lt;h4&gt;目的&lt;/h4&gt;探究R-GNNs是否能够学习由$C_2$特征定义的值函数，并比较其他GNN架构在同样任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;理论分析，实证比较。&lt;h4&gt;主要发现&lt;/h4&gt;R-GNNs不能学习由$C_2$特征定义的值函数，并且存在其他GNN架构可能更适合这项任务。&lt;h4&gt;结论&lt;/h4&gt;R-GNNs在处理某些规划域的值函数学习上存在限制，需要考虑其他可能的GNN架构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Relational Graph Neural Networks (R-GNNs) are a GNN-based approach forlearning value functions that can generalise to unseen problems from a givenplanning domain. R-GNNs were theoretically motivated by the well knownconnection between the expressive power of GNNs and $C_2$, first-order logicwith two variables and counting. In the context of planning, $C_2$ featuresrefer to the set of formulae in $C_2$ with relations defined by the unary andbinary predicates of a planning domain. Some planning domains exhibit optimalvalue functions that can be decomposed as arithmetic expressions of $C_2$features. We show that, contrary to empirical results, R-GNNs cannot learnvalue functions defined by $C_2$ features. We also identify prior GNNarchitectures for planning that may better learn value functions defined by$C_2$ features.</description>
      <author>example@mail.com (Dillon Z. Chen)</author>
      <guid isPermaLink="false">2506.11721v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>CLEAN-MI: A Scalable and Efficient Pipeline for Constructing High-Quality Neurodata in Motor Imagery Paradigm</title>
      <link>http://arxiv.org/abs/2506.11830v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CLEAN-MI的数据构建流程，用于构建大规模、高效、准确的神经数据，以促进基于运动想象（MI）的脑机接口（BCI）中稳健和泛化能力强的基础模型的发展。&lt;h4&gt;背景&lt;/h4&gt;构建大规模、高质量的数据集是开发稳健和泛化能力强的基于运动想象的脑机接口基础模型的基本前提。然而，从不同主体和设备收集的脑电图（EEG）信号通常存在信号噪声比低、电极配置异质性和显著的个体间变异等问题，这给有效的模型训练带来了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出CLEAN-MI数据构建流程，以解决上述问题，提高数据质量和分类性能。&lt;h4&gt;方法&lt;/h4&gt;CLEAN-MI通过频率带滤波、通道模板选择、受试者筛选和边缘分布对齐等步骤，系统地过滤掉无关或低质量数据，并标准化多源EEG数据集。&lt;h4&gt;主要发现&lt;/h4&gt;CLEAN-MI在多个公开的MI数据集上证明了其有效性，实现了数据质量和分类性能的一致性提升。&lt;h4&gt;结论&lt;/h4&gt;CLEAN-MI是一种有效的数据构建流程，有助于提高基于运动想象的脑机接口中数据集的质量和模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The construction of large-scale, high-quality datasets is a fundamentalprerequisite for developing robust and generalizable foundation models in motorimagery (MI)-based brain-computer interfaces (BCIs). However, EEG signalscollected from different subjects and devices are often plagued by lowsignal-to-noise ratio, heterogeneity in electrode configurations, andsubstantial inter-subject variability, posing significant challenges foreffective model training. In this paper, we propose CLEAN-MI, a scalable andsystematic data construction pipeline for constructing large-scale, efficient,and accurate neurodata in the MI paradigm. CLEAN-MI integrates frequency bandfiltering, channel template selection, subject screening, and marginaldistribution alignment to systematically filter out irrelevant or low-qualitydata and standardize multi-source EEG datasets. We demonstrate theeffectiveness of CLEAN-MI on multiple public MI datasets, achieving consistentimprovements in data quality and classification performance.</description>
      <author>example@mail.com (Dingkun Liu, Zhu Chen, Dongrui Wu)</author>
      <guid isPermaLink="false">2506.11830v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Task-Driven Discrete Representation Learning</title>
      <link>http://arxiv.org/abs/2506.11511v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了深度离散表示学习（DRL）在各个领域的成功应用，并从任务驱动的角度提出了一个统一的框架，以探讨离散特征在下游任务中的有用性。&lt;h4&gt;背景&lt;/h4&gt;近年来，深度离散表示学习（DRL）在各种领域取得了显著成功。大多数DRL框架主要关注生成设置，通过生成质量来间接评估表示的质量。&lt;h4&gt;目的&lt;/h4&gt;本文旨在从任务驱动的角度考察DRL，并分析离散表示的特性和对特定任务的益处。&lt;h4&gt;方法&lt;/h4&gt;提出了一个统一的框架，用于探索离散特征在下游任务中的有用性，并提供了关于表示能力与样本复杂度之间权衡的理论分析。&lt;h4&gt;主要发现&lt;/h4&gt;发现了离散表示的特性和它们对特定任务的影响，并揭示了离散表示利用如何影响任务性能。&lt;h4&gt;结论&lt;/h4&gt;展示了框架在多样应用中的灵活性和有效性。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, deep discrete representation learning (DRL) has achieved significant success across various domains. Most DRL frameworks (e.g., the widely used VQ-VAE and its variants) have primarily focused on generative settings, where the quality of a representation is implicitly gauged by the fidelity of its generation. In fact, the goodness of a discrete representation remains ambiguously defined across the literature. In this work, we adopt a practical approach that examines DRL from a task-driven perspective. We propose a unified framework that explores the usefulness of discrete features in relation to downstream tasks, with generation naturally viewed as one possible application. In this context, the properties of discrete representations as well as the way they benefit certain tasks are also relatively understudied. Therefore, we provide an additional theoretical analysis of the trade-off between representational capacity and sample complexity, shedding light on how discrete representation utilization impacts task performance. Finally, we demonstrate the flexibility and effectiveness of our framework across diverse applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, deep discrete representation learning (DRL) has achievedsignificant success across various domains. Most DRL frameworks (e.g., thewidely used VQ-VAE and its variants) have primarily focused on generativesettings, where the quality of a representation is implicitly gauged by thefidelity of its generation. In fact, the goodness of a discrete representationremain ambiguously defined across the literature. In this work, we adopt apractical approach that examines DRL from a task-driven perspective. We proposea unified framework that explores the usefulness of discrete features inrelation to downstream tasks, with generation naturally viewed as one possibleapplication. In this context, the properties of discrete representations aswell as the way they benefit certain tasks are also relatively understudied. Wetherefore provide an additional theoretical analysis of the trade-off betweenrepresentational capacity and sample complexity, shedding light on how discreterepresentation utilization impacts task performance. Finally, we demonstratethe flexibility and effectiveness of our framework across diverse applications.</description>
      <author>example@mail.com (Tung-Long Vuong)</author>
      <guid isPermaLink="false">2506.11511v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>CLIP Meets Diffusion: A Synergistic Approach to Anomaly Detection</title>
      <link>http://arxiv.org/abs/2506.11772v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为CLIPFUSION的异常检测方法，该方法结合了判别性和生成性基础模型，在异常检测中取得了优异的性能。&lt;h4&gt;背景&lt;/h4&gt;异常检测是一个复杂的问题，由于异常定义的模糊性、异常类型的多样性（如局部和全局缺陷）以及训练数据的稀缺性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够捕捉低级和高级特征的综合模型，即使在有限的数据下也能有效工作。&lt;h4&gt;方法&lt;/h4&gt;CLIPFUSION方法利用了基于CLIP的判别模型和基于扩散的生成模型，分别擅长捕捉全局特征和局部细节，形成协同互补的方法。同时，引入了一种利用交叉注意力图和从扩散模型中提取的特征图的方法。&lt;h4&gt;主要发现&lt;/h4&gt;在MVTec-AD和VisA等基准数据集上的实验结果表明，CLIPFUSION在异常分割和分类方面均优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;该方法强调了多模态和多模型融合在解决异常检测多方面挑战中的有效性，为现实世界的应用提供了一种可扩展的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于异常定义的模糊性、异常类型的多样性（例如，局部和全局缺陷）以及训练数据的稀缺性，异常检测是一个复杂的问题。因此，它需要一个能够捕捉低级和高级特征的综合模型，即使在有限的数据下也能有效工作。为了解决这个问题，我们提出了CLIPFUSION方法，该方法利用了判别性和生成性基础模型。具体来说，基于CLIP的判别模型擅长捕捉全局特征，而基于扩散的生成模型有效地捕捉局部细节，形成了一种协同互补的方法。值得注意的是，我们引入了一种利用交叉注意力图和从扩散模型中提取的特征图的方法，专门用于异常检测。在MVTec-AD、VisA等基准数据集上的实验结果表明，CLIPFUSION在异常分割和分类方面均优于基线方法。我们认为，我们的方法强调了多模态和多模型融合在解决异常检测多方面挑战中的有效性，为现实世界的应用提供了一种可扩展的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection is a complex problem due to the ambiguity in defininganomalies, the diversity of anomaly types (e.g., local and global defect), andthe scarcity of training data. As such, it necessitates a comprehensive modelcapable of capturing both low-level and high-level features, even with limiteddata. To address this, we propose CLIPFUSION, a method that leverages bothdiscriminative and generative foundation models. Specifically, the CLIP-baseddiscriminative model excels at capturing global features, while thediffusion-based generative model effectively captures local details, creating asynergistic and complementary approach. Notably, we introduce a methodology forutilizing cross-attention maps and feature maps extracted from diffusion modelsspecifically for anomaly detection. Experimental results on benchmark datasets(MVTec-AD, VisA) demonstrate that CLIPFUSION consistently outperforms baselinemethods, achieving outstanding performance in both anomaly segmentation andclassification. We believe that our method underscores the effectiveness ofmulti-modal and multi-model fusion in tackling the multifaceted challenges ofanomaly detection, providing a scalable solution for real-world applications.</description>
      <author>example@mail.com (Byeongchan Lee, John Won, Seunghyun Lee, Jinwoo Shin)</author>
      <guid isPermaLink="false">2506.11772v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Preserving Clusters in Prompt Learning for Unsupervised Domain Adaptation</title>
      <link>http://arxiv.org/abs/2506.11493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉和文本嵌入几何结构的方法，用于强化无监督领域自适应（UDA）中的伪标签，并促进目标提示学习，以提高领域自适应的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的基于多模态预训练模型（如CLIP）的领域自适应方法在多个基准上取得了最先进的性能，但大部分改进来源于基于伪标签（CLIP零样本预测）和自训练机制，存在视觉嵌入分布偏差的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来强化伪标签并促进目标提示学习，通过利用视觉和文本嵌入的几何结构。&lt;h4&gt;方法&lt;/h4&gt;1. 直接利用基于源和目标视觉嵌入关系的参考预测（来自源提示）。2. 利用预训练的多模态模型中视觉和文本嵌入之间的强聚类行为，基于最优传输理论，将这种洞察转化为一种新的策略，以加强文本嵌入中的聚类属性，进一步增强了目标域中的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过强化伪标签和促进目标提示学习，在领域自适应任务中取得了优越的性能和目标提示的高质量。&lt;h4&gt;结论&lt;/h4&gt;实验和消融研究表明，所提出的方法有效地提高了领域自适应的性能，并改善了目标提示的质量。&lt;h4&gt;翻译&lt;/h4&gt;Recent approaches leveraging multi-modal pre-trained models like CLIP for Unsupervised Domain Adaptation (UDA) have shown significant promise in bridging domain gaps and improving generalization by utilizing rich semantic knowledge and robust visual representations learned through extensive pre-training on diverse image-text datasets. While these methods achieve state-of-the-art performance across benchmarks, much of the improvement stems from base pseudo-labels (CLIP zero-shot predictions) and self-training mechanisms. Thus, the training mechanism exhibits a key limitation wherein the visual embedding distribution in target domains can deviate from the visual embedding distribution in the pre-trained model, leading to misguided signals from class descriptions. This work introduces a fresh solution to reinforce these pseudo-labels and facilitate target-prompt learning, by exploiting the geometry of visual and text embeddings - an aspect that is overlooked by existing methods. We first propose to directly leverage the reference predictions (from source prompts) based on the relationship between source and target visualembeddings. We later show that there is a strong clustering behavior observed between visual and text embeddings in pre-trained multi-modal models. Building on optimal transport theory, we transform this insight into a novel strategy to enforce the clustering property in text embeddings, further enhancing the alignment in the target domain. Our experiments and ablation studies validate the effectiveness of the proposed approach, demonstrating superior performance and improved quality of target prompts in terms of representation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent approaches leveraging multi-modal pre-trained models like CLIP forUnsupervised Domain Adaptation (UDA) have shown significant promise in bridgingdomain gaps and improving generalization by utilizing rich semantic knowledgeand robust visual representations learned through extensive pre-training ondiverse image-text datasets. While these methods achieve state-of-the-artperformance across benchmarks, much of the improvement stems from basepseudo-labels (CLIP zero-shot predictions) and self-training mechanisms. Thus,the training mechanism exhibits a key limitation wherein the visual embeddingdistribution in target domains can deviate from the visual embeddingdistribution in the pre-trained model, leading to misguided signals from classdescriptions. This work introduces a fresh solution to reinforce thesepseudo-labels and facilitate target-prompt learning, by exploiting the geometryof visual and text embeddings - an aspect that is overlooked by existingmethods. We first propose to directly leverage the reference predictions (fromsource prompts) based on the relationship between source and target visualembeddings. We later show that there is a strong clustering behavior observedbetween visual and text embeddings in pre-trained multi-modal models. Buildingon optimal transport theory, we transform this insight into a novel strategy toenforce the clustering property in text embeddings, further enhancing thealignment in the target domain. Our experiments and ablation studies validatethe effectiveness of the proposed approach, demonstrating superior performanceand improved quality of target prompts in terms of representation.</description>
      <author>example@mail.com (Tung-Long Vuong, Hoang Phan, Vy Vo, Anh Bui, Thanh-Toan Do, Trung Le, Dinh Phung)</author>
      <guid isPermaLink="false">2506.11493v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Effectiveness of Deep Features from Domain-Specific Foundation Models in Retinal Image Synthesis</title>
      <link>http://arxiv.org/abs/2506.11753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published and presented at the MIUA 2025 conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;医学影像中神经网络模型的采用受到隐私法规、数据可用性限制、高获取成本和人口结构偏差的制约。&lt;h4&gt;背景&lt;/h4&gt;深度生成模型通过生成合成数据，绕过隐私问题，并通过为代表性不足的群体生成样本来解决公平性问题。&lt;h4&gt;目的&lt;/h4&gt;研究基于大型领域数据集训练的大型基础模型的深度激活层的距离损失函数，是否在感知损失和边缘检测损失函数之上提供优势。&lt;h4&gt;方法&lt;/h4&gt;使用广泛的验证流程，基于无领域和领域特定任务，以评估特定领域深度特征在自动编码器图像生成中的改进。&lt;h4&gt;主要发现&lt;/h4&gt;领域特定深度特征并未提高自动编码器图像生成的质量。相反，研究发现传统的边缘检测滤波器在提高合成样本中血管结构的清晰度方面是有效的。&lt;h4&gt;结论&lt;/h4&gt;在医学影像中，验证不仅需要保证图像的真实性，还需要保证形态和临床准确性，尤其是在彩色眼底视网膜成像方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The adoption of neural network models in medical imaging has been constrainedby strict privacy regulations, limited data availability, high acquisitioncosts, and demographic biases. Deep generative models offer a promisingsolution by generating synthetic data that bypasses privacy concerns andaddresses fairness by producing samples for under-represented groups. However,unlike natural images, medical imaging requires validation not only forfidelity (e.g., Fr\'echet Inception Score) but also for morphological andclinical accuracy. This is particularly true for colour fundus retinal imaging,which requires precise replication of the retinal vascular network, includingvessel topology, continuity, and thickness. In this study, we in-vestigatedwhether a distance-based loss function based on deep activation layers of alarge foundational model trained on large corpus of domain data, colour fundusimaging, offers advantages over a perceptual loss and edge-detection based lossfunctions. Our extensive validation pipeline, based on both domain-free anddomain specific tasks, suggests that domain-specific deep features do notimprove autoen-coder image generation. Conversely, our findings highlight theeffectiveness of con-ventional edge detection filters in improving thesharpness of vascular structures in synthetic samples.</description>
      <author>example@mail.com (Zuzanna Skorniewska, Bartlomiej W. Papiez)</author>
      <guid isPermaLink="false">2506.11753v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Can Time-Series Foundation Models Perform Building Energy Management Tasks?</title>
      <link>http://arxiv.org/abs/2506.11250v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages, 5 tables, 8 figures. Under review for Data-Centric  Engineering journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文评估了时间序列基础模型（TSFMs）在建筑能源管理（BEM）任务中的应用，发现其在泛化能力、性能表现和适应性方面存在局限性。&lt;h4&gt;背景&lt;/h4&gt;BEM任务需要处理和学习多种时间序列数据，现有解决方案依赖于特定任务和数据的定制模型，限制了其更广泛的应用。&lt;h4&gt;目的&lt;/h4&gt;研究TSFMs在BEM任务中的表现，特别是其在零样本单变量预测、热行为建模、分类任务中的零样本表示学习和对性能指标及不同运行条件的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;通过四个维度评估TSFMs：1）零样本单变量预测的泛化能力；2）包含协变量的预测；3）分类任务的零样本表示学习；4）对性能指标和不同运行条件的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;TSFMs在泛化能力上有限，仅在未见数据集和模态上的单变量预测中略优于统计模型。包含协变量并未提升性能，且其表现不如使用协变量的传统模型。TSFMs在生成有效的零样本表示方面表现良好，但在统计模型进行测试时拟合时可能不如统计模型。此外，TSFMs的预测性能对评估指标敏感，在更复杂的建筑环境中表现不如统计模型。&lt;h4&gt;结论&lt;/h4&gt;需要针对TSFM设计进行改进，特别是其处理协变量的能力以及将上下文和时序动态纳入预测机制，以开发更适应性和可扩展的BEM解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Building energy management (BEM) tasks require processing and learning from avariety of time-series data. Existing solutions rely on bespoke task- anddata-specific models to perform these tasks, limiting their broaderapplicability. Inspired by the transformative success of Large Language Models(LLMs), Time-Series Foundation Models (TSFMs), trained on diverse datasets,have the potential to change this. Were TSFMs to achieve a level ofgeneralizability across tasks and contexts akin to LLMs, they couldfundamentally address the scalability challenges pervasive in BEM. Tounderstand where they stand today, we evaluate TSFMs across four dimensions:(1) generalizability in zero-shot univariate forecasting, (2) forecasting withcovariates for thermal behavior modeling, (3) zero-shot representation learningfor classification tasks, and (4) robustness to performance metrics and varyingoperational conditions. Our results reveal that TSFMs exhibit \emph{limited}generalizability, performing only marginally better than statistical models onunseen datasets and modalities for univariate forecasting. Similarly, inclusionof covariates in TSFMs does not yield performance improvements, and theirperformance remains inferior to conventional models that utilize covariates.While TSFMs generate effective zero-shot representations for downstreamclassification tasks, they may remain inferior to statistical models inforecasting when statistical models perform test-time fitting. Moreover, TSFMsforecasting performance is sensitive to evaluation metrics, and they strugglein more complex building environments compared to statistical models. Thesefindings underscore the need for targeted advancements in TSFM design,particularly their handling of covariates and incorporating context andtemporal dynamics into prediction mechanisms, to develop more adaptable andscalable solutions for BEM.</description>
      <author>example@mail.com (Ozan Baris Mulayim, Pengrui Quan, Liying Han, Xiaomin Ouyang, Dezhi Hong, Mario Bergés, Mani Srivastava)</author>
      <guid isPermaLink="false">2506.11250v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Quizzard@INOVA Challenge 2025 -- Track A: Plug-and-Play Technique in Interleaved Multi-Image Model</title>
      <link>http://arxiv.org/abs/2506.11737v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了LLaVA-NeXT-interleave在多图像推理、文档和基于知识的理解以及交互式多模态通信三个任务上的表现，并添加了密集通道集成（DCI）连接器，比较了其与标准模型的性能。&lt;h4&gt;背景&lt;/h4&gt;无具体背景信息。&lt;h4&gt;目的&lt;/h4&gt;1. 展示LLaVA-NeXT-interleave在多个数据集上的出色表现；2. 添加DCI连接器到LLaVA-NeXT-Interleave中，并与标准模型进行性能比较。&lt;h4&gt;方法&lt;/h4&gt;在22个数据集上测试LLaVA-NeXT-interleave在不同任务上的表现，并添加DCI连接器进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;1. 标准模型在整体准确率上表现最佳，尤其在视觉密集型任务上；2. DCI增强版本在需要更深层次语义连贯性或结构变化理解的集上表现突出。&lt;h4&gt;结论&lt;/h4&gt;结合强大的基础模型和即插即用技术对于Interleave任务具有潜力。&lt;h4&gt;翻译&lt;/h4&gt;本文针对两个主要目标进行研究。首先，我们在三个不同任务（多图像推理、文档和基于知识的理解以及交互式多模态通信）的22个数据集上展示了LLaVA-NeXT-interleave的出色性能。其次，我们将密集通道集成（DCI）连接器添加到LLaVA-NeXT-Interleave中，并将其性能与标准模型进行了比较。我们发现，标准模型在整体准确率上达到了最高，在像VISION、NLVR2和Fashion200K这样的视觉密集型任务上表现出色。同时，DCI增强版本在需要更深层次语义连贯性或结构变化理解的集，如MIT-States_PropertyCoherence和SlideVQA上表现出特别的优势。我们的结果突出了结合强大基础模型与即插即用技术进行Interleave任务的潜力。代码可在https://github.com/dinhvietcuong1996/icme25-inova上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses two main objectives. Firstly, we demonstrate theimpressive performance of the LLaVA-NeXT-interleave on 22 datasets across threedifferent tasks: Multi-Image Reasoning, Documents and Knowledge-BasedUnderstanding and Interactive Multi-Modal Communication. Secondly, we add theDense Channel Integration (DCI) connector to the LLaVA-NeXT-Interleave andcompare its performance against the standard model. We find that the standardmodel achieves the highest overall accuracy, excelling in vision-heavy taskslike VISION, NLVR2, and Fashion200K. Meanwhile, the DCI-enhanced version showsparticular strength on datasets requiring deeper semantic coherence orstructured change understanding such as MIT-States_PropertyCoherence andSlideVQA. Our results highlight the potential of combining powerful foundationmodels with plug-and-play techniques for Interleave tasks. The code isavailable at https://github.com/dinhvietcuong1996/icme25-inova.</description>
      <author>example@mail.com (Dinh Viet Cuong, Hoang-Bao Le, An Pham Ngoc Nguyen, Liting Zhou, Cathal Gurrin)</author>
      <guid isPermaLink="false">2506.11737v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Generalised Rate Control Approach For Stream Processing Applications</title>
      <link>http://arxiv.org/abs/2506.11710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络深度强化学习的分布式流处理系统过载控制方法。&lt;h4&gt;背景&lt;/h4&gt;分布式流处理系统广泛应用于处理来自传感器和软件系统的实时数据，其中过载问题是系统稳定性和资源消耗的关键挑战。&lt;h4&gt;目的&lt;/h4&gt;通过控制数据生成速率来避免过载情况，从而提高系统性能。&lt;h4&gt;方法&lt;/h4&gt;使用图神经网络处理流处理引擎收集的系统指标，以避免存储过去状态、减少等待时间，并适应多种场景和流应用。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法能将吞吐量和端到端延迟分别提高13.5%和30%。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提高了分布式流处理系统的性能和稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Distributed stream processing systems are widely deployed to processreal-time data generated by various devices, such as sensors and softwaresystems. A key challenge in the system is overloading, which leads to anunstable system status and consumes additional system resources. In this paper,we use a graph neural network-based deep reinforcement learning tocollaboratively control the data emission rate at which the data is generatedin the stream source to proactively avoid overloading scenarios. Instead ofusing a traditional multi-layer perceptron-styled network to control the rate,the graph neural network is used to process system metrics collected from thestream processing engine. Consequently, the learning agent (i) avoids storingpast states where previous actions may affect the current state, (ii) iswithout waiting a long interval until the current action has been fullyeffective and reflected in the system's specific metrics, and more importantly,(iii) is able to adapt multiple stream applications in multiple scenarios. Wedeploy the rate control approach on three applications, and the experimentalresults demonstrate that the throughput and end-to-end latency are improved byup to 13.5% and 30%, respectively.</description>
      <author>example@mail.com (Ziren Xiao)</author>
      <guid isPermaLink="false">2506.11710v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Brain Network Analysis Based on Fine-tuned Self-supervised Model for Brain Disease Diagnosis</title>
      <link>http://arxiv.org/abs/2506.11671v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 3 figures, International Conference on Neural Computing for  Advanced Applications&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对脑疾病诊断的精细调优脑网络模型，通过多维度扩展脑区表示，提高了模型的可推广性。&lt;h4&gt;背景&lt;/h4&gt;功能脑网络分析对脑疾病分析至关重要，受深度学习方法影响，但现有研究在脑网络基础模型方面有限，限制了其在神经科学中的应用。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效进行脑疾病诊断的精细调优脑网络模型。&lt;h4&gt;方法&lt;/h4&gt;提出模型包含两个关键模块：(1)一个适配器模块，用于在不同维度上扩展脑区特征；(2)一个基于自监督学习和预训练于数千名参与者fMRI数据的精细调优基础脑网络模型。模型中的transformer块能够有效提取脑区特征并计算区域间关联。此外，推导出脑网络的紧凑性潜在表示。&lt;h4&gt;主要发现&lt;/h4&gt;模型在脑疾病诊断中表现出优异的性能，为脑网络分析研究提供了有前景的方法。&lt;h4&gt;结论&lt;/h4&gt;该模型在脑疾病诊断方面具有潜在的应用价值，并可能推动脑网络分析研究的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Functional brain network analysis has become an indispensable tool for braindisease analysis. It is profoundly impacted by deep learning methods, which cancharacterize complex connections between ROIs. However, the research onfoundation models of brain network is limited and constrained to a singledimension, which restricts their extensive application in neuroscience. In thisstudy, we propose a fine-tuned brain network model for brain disease diagnosis.It expands brain region representations across multiple dimensions based on theoriginal brain network model, thereby enhancing its generalizability. Our modelconsists of two key modules: (1)an adapter module that expands brain regionfeatures across different dimensions. (2)a fine-tuned foundation brain networkmodel, based on self-supervised learning and pre-trained on fMRI data fromthousands of participants. Specifically, its transformer block is able toeffectively extract brain region features and compute the inter-regionassociations. Moreover, we derive a compact latent representation of the brainnetwork for brain disease diagnosis. Our downstream experiments in this studydemonstrate that the proposed model achieves superior performance in braindisease diagnosis, which potentially offers a promising approach in brainnetwork analysis research.</description>
      <author>example@mail.com (Yifei Tang, Hongjie Jiang, Changhong Jing, Hieu Pham, Shuqiang Wang)</author>
      <guid isPermaLink="false">2506.11671v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>OV-MAP : Open-Vocabulary Zero-Shot 3D Instance Segmentation Map for Robots</title>
      <link>http://arxiv.org/abs/2506.11585v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IROS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了OV-MAP，这是一种将开放特征集成到3D地图中以增强物体识别能力的移动机器人开放世界3D制图的新方法。&lt;h4&gt;背景&lt;/h4&gt;在相邻体素重叠的特征导致实例级精度降低的情况下，特征溢出体素边界，混合了邻近区域。&lt;h4&gt;目的&lt;/h4&gt;克服上述挑战，实现准确的无监督3D实例分割。&lt;h4&gt;方法&lt;/h4&gt;采用一个类无关的分割模型将2D掩码投影到3D空间，并结合由点云合并原始和合成深度图像生成的补充深度图像。此外，还引入了3D掩码投票机制。&lt;h4&gt;主要发现&lt;/h4&gt;通过在ScanNet200和Replica等公共数据集上的全面实验，证明了该方法在无监督情况下具有优越的性能、鲁棒性和适应性。&lt;h4&gt;结论&lt;/h4&gt;通过真实世界实验，展示了该方法在多样化真实世界环境中的应用适应性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/IROS58592.2024.10801841&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce OV-MAP, a novel approach to open-world 3D mapping for mobilerobots by integrating open-features into 3D maps to enhance object recognitioncapabilities. A significant challenge arises when overlapping features fromadjacent voxels reduce instance-level precision, as features spill over voxelboundaries, blending neighboring regions together. Our method overcomes this byemploying a class-agnostic segmentation model to project 2D masks into 3Dspace, combined with a supplemented depth image created by merging raw andsynthetic depth from point clouds. This approach, along with a 3D mask votingmechanism, enables accurate zero-shot 3D instance segmentation without relyingon 3D supervised segmentation models. We assess the effectiveness of our methodthrough comprehensive experiments on public datasets such as ScanNet200 andReplica, demonstrating superior zero-shot performance, robustness, andadaptability across diverse environments. Additionally, we conducted real-worldexperiments to demonstrate our method's adaptability and robustness whenapplied to diverse real-world environments.</description>
      <author>example@mail.com (Juno Kim, Yesol Park, Hye-Jung Yoon, Byoung-Tak Zhang)</author>
      <guid isPermaLink="false">2506.11585v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Multimodal Large Language Models on Video Captioning via Monte Carlo Tree Search</title>
      <link>http://arxiv.org/abs/2506.11155v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages; ACL 2025(main)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AutoCaption的自动框架，用于评估多模态大型语言模型（MLLMs）的视频理解能力，并通过实验证明了其在视频描述任务中的有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的视频描述基准和评估协议存在关键问题，如关键点的创建不足或不一致、数据创建成本高昂以及评估范围有限。&lt;h4&gt;目的&lt;/h4&gt;提出AutoCaption框架，以解决现有基准和评估协议的问题，并评估MLLMs在视频描述任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;AutoCaption利用蒙特卡洛树搜索（MCTS）构建多个描述性句子（即关键点），以迭代方式全面地表示视频内容。该框架应用于创建MCTS-VCB基准，这是一个细粒度的视频描述基准，涵盖了视频细节，从而能够全面评估MLLMs的视频描述能力。&lt;h4&gt;主要发现&lt;/h4&gt;AutoCaption能够有效地评估视频描述能力，Gemini-1.5-Pro在MCTS-VCB上取得了最高的F1分数（71.2）。使用AutoCaption生成的数据微调InternVL2.5-8B模型，在MCTS-VCB和DREAM-1K上分别提升了25.0%和16.3%，进一步证明了AutoCaption的有效性。&lt;h4&gt;结论&lt;/h4&gt;AutoCaption框架为评估MLLMs的视频描述能力提供了一种有效的方法，并为视频描述任务的研究提供了新的基准。&lt;h4&gt;翻译&lt;/h4&gt;视频描述可以用来评估多模态大型语言模型（MLLMs）的视频理解能力。然而，现有的基准和评估协议存在关键问题，如关键点的创建不足或不一致、数据创建成本高昂以及评估范围有限。为了解决这些问题，我们提出了一种自动框架，名为AutoCaption，它利用蒙特卡洛树搜索（MCTS）以迭代方式构建多个描述性句子（即关键点），以全面地表示视频内容。这种迭代描述策略使得视频细节如动作、物体的属性、环境细节等得以持续提升。我们将AutoCaption应用于创建MCTS-VCB基准，这是一个细粒度的视频描述基准，涵盖了视频细节，从而能够全面评估MLLMs在视频描述任务上的表现。我们在MCTS-VCB上评估了超过20个大小不同的开源和闭源MLLMs。结果表明，MCTS-VCB能够有效地全面评估视频描述能力，其中Gemini-1.5-Pro在MCTS-VCB上取得了最高的F1分数（71.2）。有趣的是，我们使用AutoCaption生成的数据对InternVL2.5-8B模型进行了微调，这有助于模型在MCTS-VCB和DREAM-1K上分别提升了25.0%和16.3%，进一步证明了AutoCaption的有效性。代码和数据可在https://github.com/tjunlp-lab/MCTS-VCB上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video captioning can be used to assess the video understanding capabilitiesof Multimodal Large Language Models (MLLMs). However, existing benchmarks andevaluation protocols suffer from crucial issues, such as inadequate orhomogeneous creation of key points, exorbitant cost of data creation, andlimited evaluation scopes. To address these issues, we propose an automaticframework, named AutoCaption, which leverages Monte Carlo Tree Search (MCTS) toconstruct numerous and diverse descriptive sentences (\textit{i.e.}, keypoints) that thoroughly represent video content in an iterative way. Thisiterative captioning strategy enables the continuous enhancement of videodetails such as actions, objects' attributes, environment details, etc. Weapply AutoCaption to curate MCTS-VCB, a fine-grained video caption benchmarkcovering video details, thereby enabling a comprehensive evaluation of MLLMs onthe video captioning task. We evaluate more than 20 open- and closed-sourceMLLMs of varying sizes on MCTS-VCB. Results show that MCTS-VCB can effectivelyand comprehensively evaluate the video captioning capability, withGemini-1.5-Pro achieving the highest F1 score of 71.2. Interestingly, wefine-tune InternVL2.5-8B with the AutoCaption-generated data, which helps themodel achieve an overall improvement of 25.0% on MCTS-VCB and 16.3% onDREAM-1K, further demonstrating the effectiveness of AutoCaption. The code anddata are available at https://github.com/tjunlp-lab/MCTS-VCB.</description>
      <author>example@mail.com (Linhao Yu, Xinguang Ji, Yahui Liu, Fanheng Kong, Chenxi Sun, Jingyuan Zhang, Hongzhi Zhang, V. W., Fuzheng Zhang, Deyi Xiong)</author>
      <guid isPermaLink="false">2506.11155v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Geometry-Aware Edge Pooling for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.11700v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图池化层，旨在解决现有池化操作在优化学习任务时牺牲基本图结构和可解释性的问题。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在图相关任务中取得了显著成功，但池化层在大型数据集的实时应用中至关重要。&lt;h4&gt;目的&lt;/h4&gt;通过减少输入图的大小，实现更快的训练和可能的更好泛化，同时保持图的度量结构和结构多样性。&lt;h4&gt;方法&lt;/h4&gt;提出的方法通过边缘折叠进行结构感知池化，利用扩散几何，迭代地减小图的大小，同时保留其度量结构和结构多样性。使用等距不变多样性度量（幅度）来引导池化过程，并使用度量空间的传播作为更快速、更稳定的替代方案。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法（1）在各种不同的图分类任务中比其他池化层实现更优的性能；（2）保留了输入图的关键谱属性；（3）在变化不同的池化比率下保持了高精度。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法有效地解决了现有池化操作的局限性，并展示了在图分类任务中的优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have shown significant success for graph-basedtasks. Motivated by the prevalence of large datasets in real-worldapplications, pooling layers are crucial components of GNNs. By reducing thesize of input graphs, pooling enables faster training and potentially bettergeneralisation. However, existing pooling operations often optimise for thelearning task at the expense of fundamental graph structures andinterpretability. This leads to unreliable performance across varying datasettypes, downstream tasks and pooling ratios. Addressing these concerns, wepropose novel graph pooling layers for structure aware pooling via edgecollapses. Our methods leverage diffusion geometry and iteratively reduce agraph's size while preserving both its metric structure and structuraldiversity. We guide pooling using magnitude, an isometry-invariant diversitymeasure, which permits us to control the fidelity of the pooling process.Further, we use the spread of a metric space as a faster and more stablealternative ensuring computational efficiency. Empirical results demonstratethat our methods (i) achieve superior performance compared to alternativepooling layers across a range of diverse graph classification tasks, (ii)preserve key spectral properties of the input graphs, and (iii) retain highaccuracy across varying pooling ratios.</description>
      <author>example@mail.com (Katharina Limbeck, Lydia Mezrag, Guy Wolf, Bastian Rieck)</author>
      <guid isPermaLink="false">2506.11700v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>A$^2$LC: Active and Automated Label Correction for Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2506.11599v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Under review. 22 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为A$^2$LC的语义分割主动和自动标签校正框架，通过集成自动化校正阶段提高了校正效率，并通过自适应平衡获取函数强调了代表性不足的尾部类别，实验结果表明A$^2$LC在Cityscapes和PASCAL VOC 2012数据集上显著优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;手动像素级标注在语义分割中成本高且易出错，而使用基础模型生成伪标签虽然提高了校正效率，但仍有大量低效之处。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且有效的主动标签校正框架，以降低成本并提高语义分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;A$^2$LC框架将自动化校正阶段集成到传统流程中，利用标注者反馈对查询样本以外的数据进行标签校正，并引入自适应平衡获取函数来强调尾部类别。&lt;h4&gt;主要发现&lt;/h4&gt;A$^2$LC在Cityscapes和PASCAL VOC 2012数据集上显著优于现有方法，且使用20%的预算就能超过其他方法的表现，在相同预算下性能提升了27.23%。&lt;h4&gt;结论&lt;/h4&gt;A$^2$LC是一种高效且有效的语义分割标签校正方法，值得进一步研究和应用。&lt;h4&gt;翻译&lt;/h4&gt;Active Label Correction (ALC)已经成为解决语义分割中手动像素级标注高成本和易出错问题的一种有希望的解决方案，通过选择性地识别和纠正误标注的数据。尽管最近的工作通过使用基础模型生成伪标签来提高了校正效率，但仍然存在大量的低效。在本文中，我们提出了针对语义分割的主动和自动标签校正（A$^2$LC），这是一种新颖且高效的ALC框架，它将自动化校正阶段集成到传统流程中。具体来说，自动化校正阶段利用标注者反馈对查询样本以外的数据进行标签校正，从而最大化成本效率。此外，我们还引入了一个自适应平衡获取函数，强调代表性不足的尾部类别，并补充了自动化校正机制。在Cityscapes和PASCAL VOC 2012数据集上的大量实验表明，A$^2$LC显著优于先前最先进的方法。值得注意的是，A$^2$LC通过仅使用20%的预算就优于先前的方法，并在Cityscapes数据集上在等效预算约束下实现了27.23%的性能提升。代码将在接受后发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Active Label Correction (ALC) has emerged as a promising solution to the highcost and error-prone nature of manual pixel-wise annotation in semanticsegmentation, by selectively identifying and correcting mislabeled data.Although recent work has improved correction efficiency by generatingpseudo-labels using foundation models, substantial inefficiencies still remain.In this paper, we propose Active and Automated Label Correction for semanticsegmentation (A$^2$LC), a novel and efficient ALC framework that integrates anautomated correction stage into the conventional pipeline. Specifically, theautomated correction stage leverages annotator feedback to perform labelcorrection beyond the queried samples, thereby maximizing cost efficiency. Inaddition, we further introduce an adaptively balanced acquisition function thatemphasizes underrepresented tail classes and complements the automatedcorrection mechanism. Extensive experiments on Cityscapes and PASCAL VOC 2012demonstrate that A$^2$LC significantly outperforms previous state-of-the-artmethods. Notably, A$^2$LC achieves high efficiency by outperforming previousmethods using only 20% of their budget, and demonstrates strong effectivenessby yielding a 27.23% performance improvement under an equivalent budgetconstraint on the Cityscapes dataset. The code will be released uponacceptance.</description>
      <author>example@mail.com (Youjin Jeon, Kyusik Cho, Suhan Woo, Euntai Kim)</author>
      <guid isPermaLink="false">2506.11599v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>KCES: Training-Free Defense for Robust Graph Neural Networks via Kernel Complexity</title>
      <link>http://arxiv.org/abs/2506.11611v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为KCES的Graph Neural Networks (GNNs)防御框架，用于提高GNNs的鲁棒性，该框架基于图核复杂度（GKC）进行边缘净化，能够有效抵御对抗攻击。&lt;h4&gt;背景&lt;/h4&gt;尽管GNNs在图相关任务中取得了显著成功，但它们对微小的扰动和对抗攻击非常脆弱。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种训练免费、模型无关的防御框架，以提高GNNs的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;KCES利用图核复杂度（GKC）来衡量边缘的潜在风险，通过修剪具有高KC分数的边缘来减轻有害影响。&lt;h4&gt;主要发现&lt;/h4&gt;KCES能够提高GNNs的鲁棒性，优于现有基准，并增强现有防御策略的有效性。&lt;h4&gt;结论&lt;/h4&gt;KCES提供了一个原则性和高效的解决方案，以保护GNNs免受攻击。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have achieved impressive success across a widerange of graph-based tasks, yet they remain highly vulnerable to small,imperceptible perturbations and adversarial attacks. Although numerous defensemethods have been proposed to address these vulnerabilities, many rely onheuristic metrics, overfit to specific attack patterns, and suffer from highcomputational complexity. In this paper, we propose Kernel Complexity-BasedEdge Sanitization (KCES), a training-free, model-agnostic defense framework.KCES leverages Graph Kernel Complexity (GKC), a novel metric derived from thegraph's Gram matrix that characterizes GNN generalization via its test errorbound. Building on GKC, we define a KC score for each edge, measuring thechange in GKC when the edge is removed. Edges with high KC scores, typicallyintroduced by adversarial perturbations, are pruned to mitigate their harmful effects,thereby enhancing GNNs' robustness. KCES can also be seamlessly integrated withexisting defense strategies as a plug-and-play module without requiring training. Theoretical analysis and extensive experiments demonstratethat KCES consistently enhances GNN robustness, outperforms state-of-the-artbaselines, and amplifies the effectiveness of existing defenses, offering aprincipled and efficient solution for securing GNNs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have achieved impressive success across a widerange of graph-based tasks, yet they remain highly vulnerable to small,imperceptible perturbations and adversarial attacks. Although numerous defensemethods have been proposed to address these vulnerabilities, many rely onheuristic metrics, overfit to specific attack patterns, and suffer from highcomputational complexity. In this paper, we propose Kernel Complexity-BasedEdge Sanitization (KCES), a training-free, model-agnostic defense framework.KCES leverages Graph Kernel Complexity (GKC), a novel metric derived from thegraph's Gram matrix that characterizes GNN generalization via its test errorbound. Building on GKC, we define a KC score for each edge, measuring thechange in GKC when the edge is removed. Edges with high KC scores, typicallyintroduced by adversarial perturbations, are pruned to mitigate their harmfuleffects, thereby enhancing GNNs' robustness. KCES can also be seamlesslyintegrated with existing defense strategies as a plug-and-play module withoutrequiring training. Theoretical analysis and extensive experiments demonstratethat KCES consistently enhances GNN robustness, outperforms state-of-the-artbaselines, and amplifies the effectiveness of existing defenses, offering aprincipled and efficient solution for securing GNNs.</description>
      <author>example@mail.com (Yaning Jia, Shenyang Deng, Chiyu Ma, Yaoqing Yang, Soroush Vosoughi)</author>
      <guid isPermaLink="false">2506.11611v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Learn to Preserve Personality: Federated Foundation Models in Recommendations</title>
      <link>http://arxiv.org/abs/2506.11563v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 3 figures, conference, position paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了联邦基础模型（FFM）在推荐系统中的应用，旨在在泛化与个性化之间取得平衡，同时保护用户个性的完整性。&lt;h4&gt;背景&lt;/h4&gt;现有基础模型（FM）面临泛化与个性化之间的平衡挑战，参数高效的适应技术凸显了这一困境。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的学习范式，FFM不仅利用其泛化能力，而且专门设计来保护用户个性的完整性。&lt;h4&gt;方法&lt;/h4&gt;利用联邦学习过程将共享知识与个人特定适应解耦，并在推荐系统中进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;FFM在推荐系统中能够实现用户个性化，同时保持用户个性的完整性。&lt;h4&gt;结论&lt;/h4&gt;预测未来个性化自适应FM将支持个人代理，引导用户在内容上的决策，构建以用户为中心、去中心化的系统。&lt;h4&gt;翻译&lt;/h4&gt;A core learning challenge for existed Foundation Models (FM) is striking the tradeoff between generalization with personalization, which is a dilemma that has been highlighted by various parameter-efficient adaptation techniques. Federated foundation models (FFM) provide a structural means to decouple shared knowledge from individual specific adaptations via decentralized processes. Recommendation systems offer a perfect testbed for FFMs, given their reliance on rich implicit feedback reflecting unique user characteristics. This position paper discusses a novel learning paradigm where FFMs not only harness their generalization capabilities but are specifically designed to preserve the integrity of user personality, illustrated thoroughly within the recommendation contexts. We envision future personal agents, powered by personalized adaptive FMs, guiding user decisions on content. Such an architecture promises a user-centric, decentralized system where individuals maintain control over their personalized agents.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A core learning challenge for existed Foundation Models (FM) is striking thetradeoff between generalization with personalization, which is a dilemma thathas been highlighted by various parameter-efficient adaptation techniques.Federated foundation models (FFM) provide a structural means to decouple sharedknowledge from individual specific adaptations via decentralized processes.Recommendation systems offer a perfect testbed for FFMs, given their relianceon rich implicit feedback reflecting unique user characteristics. This positionpaper discusses a novel learning paradigm where FFMs not only harness theirgeneralization capabilities but are specifically designed to preserve theintegrity of user personality, illustrated thoroughly within the recommendationcontexts. We envision future personal agents, powered by personalized adaptiveFMs, guiding user decisions on content. Such an architecture promises a usercentric, decentralized system where individuals maintain control over theirpersonalized agents.</description>
      <author>example@mail.com (Zhiwei Li, Guodong Long, Chunxu Zhang, Honglei Zhang, Jing Jiang, Chengqi Zhang)</author>
      <guid isPermaLink="false">2506.11563v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models in Autonomous Driving: A Survey on Scenario Generation and Scenario Analysis</title>
      <link>http://arxiv.org/abs/2506.11526v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对自动驾驶场景生成和分析中基础模型的应用进行了综述。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶在复杂环境中的安全导航依赖于处理多样化的驾驶场景。&lt;h4&gt;目的&lt;/h4&gt;本文旨在调查和总结基础模型在自动驾驶场景生成和分析中的应用。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个统一的分类法，包括大语言模型、视觉-语言模型、多模态大语言模型、扩散模型和世界模型。&lt;h4&gt;主要发现&lt;/h4&gt;本文回顾了场景生成和分析的方法、开源数据集、模拟平台和基准挑战，并考察了专门针对场景生成和分析的评价指标。&lt;h4&gt;结论&lt;/h4&gt;本文指出了开放挑战和研究问题，并概述了有希望的未来研究方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：对于自动驾驶汽车，在复杂环境中的安全导航取决于处理广泛的多样化和罕见的驾驶场景。基于模拟和场景的测试已成为自动驾驶系统开发和验证的关键方法。传统的场景生成依赖于基于规则的系统、知识驱动模型和数据驱动合成，通常产生有限的多样性和不切实际的安全关键案例。随着基础模型的兴起，这些代表新一代预训练的通用人工智能模型，开发者可以处理异构输入（例如，自然语言、传感器数据、高清地图和控制动作），从而实现复杂驾驶场景的合成和解释。在本文中，我们对基础模型在自动驾驶场景生成和分析中的应用进行了调查（截至2025年5月）。我们的调查提出了一个统一的分类法，包括大型语言模型、视觉-语言模型、多模态大型语言模型、扩散模型和用于自动驾驶场景生成和分析的世界模型。此外，我们回顾了方法、开源数据集、模拟平台和基准挑战，并检查了专门针对场景生成和分析的评价指标。最后，调查通过突出开放挑战和研究问题，概述了有希望的未来研究方向。所有回顾的论文都列在一个持续维护的存储库中，该存储库包含补充材料，可在https://github.com/TUM-AVS/FM-for-Scenario-Generation-Analysis上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For autonomous vehicles, safe navigation in complex environments depends onhandling a broad range of diverse and rare driving scenarios. Simulation- andscenario-based testing have emerged as key approaches to development andvalidation of autonomous driving systems. Traditional scenario generationrelies on rule-based systems, knowledge-driven models, and data-drivensynthesis, often producing limited diversity and unrealistic safety-criticalcases. With the emergence of foundation models, which represent a newgeneration of pre-trained, general-purpose AI models, developers can processheterogeneous inputs (e.g., natural language, sensor data, HD maps, and controlactions), enabling the synthesis and interpretation of complex drivingscenarios. In this paper, we conduct a survey about the application offoundation models for scenario generation and scenario analysis in autonomousdriving (as of May 2025). Our survey presents a unified taxonomy that includeslarge language models, vision-language models, multimodal large languagemodels, diffusion models, and world models for the generation and analysis ofautonomous driving scenarios. In addition, we review the methodologies,open-source datasets, simulation platforms, and benchmark challenges, and weexamine the evaluation metrics tailored explicitly to scenario generation andanalysis. Finally, the survey concludes by highlighting the open challenges andresearch questions, and outlining promising future research directions. Allreviewed papers are listed in a continuously maintained repository, whichcontains supplementary materials and is available athttps://github.com/TUM-AVS/FM-for-Scenario-Generation-Analysis.</description>
      <author>example@mail.com (Yuan Gao, Mattia Piccinini, Yuchen Zhang, Dingrui Wang, Korbinian Moller, Roberto Brusnicki, Baha Zarrouki, Alessio Gambi, Jan Frederik Totz, Kai Storms, Steven Peters, Andrea Stocco, Bassam Alrifaee, Marco Pavone, Johannes Betz)</author>
      <guid isPermaLink="false">2506.11526v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>FIGNN: Feature-Specific Interpretability for Graph Neural Network Surrogate Models</title>
      <link>http://arxiv.org/abs/2506.11398v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的图神经网络（GNN）架构，即特征特定可解释图神经网络（FIGNN），旨在提高科学应用中在无结构网格上定义的深度学习代理模型的可解释性。&lt;h4&gt;背景&lt;/h4&gt;传统的GNN在多元预测任务中往往掩盖了不同特征在空间上的独特影响。&lt;h4&gt;目的&lt;/h4&gt;增强深度学习代理模型的可解释性。&lt;h4&gt;方法&lt;/h4&gt;引入了特征特定的池化策略，允许对每个预测变量独立分配空间重要性，并在训练目标中加入了基于掩码的正则化项，以显式鼓励可解释性与预测误差之间的对齐，促进模型性能的局部归因。&lt;h4&gt;主要发现&lt;/h4&gt;FIGNN在两个物理上不同的系统（SPEEDY大气环流模型和向后-facing step（BFS）流体动力学基准）的代理建模中表现出竞争力，同时揭示了每个特征独特的物理意义上的空间模式。&lt;h4&gt;结论&lt;/h4&gt;FIGNN被证实是一个适用于复杂物理域中可解释代理建模的通用框架。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的图神经网络（GNN）架构，称为特征特定可解释图神经网络（FIGNN），旨在增强科学应用中在无结构网格上定义的深度学习代理模型的可解释性。传统的GNN在多元预测任务中往往掩盖了不同特征在空间上的独特影响。FIGNN通过引入特征特定的池化策略来解决这一限制，该策略允许对每个预测变量独立分配空间重要性。此外，在训练目标中加入了基于掩码的正则化项，以显式鼓励可解释性与预测误差之间的对齐，促进模型性能的局部归因。该方法在两个物理上不同的系统（SPEEDY大气环流模型和向后-facing step（BFS）流体动力学基准）的代理建模中进行了评估。结果表明，FIGNN在预测性能上具有竞争力，同时揭示了每个特征独特的物理意义上的空间模式。关于 rollout 稳定性、特征误差预算和空间掩码叠加的分析证实了FIGNN作为复杂物理域中可解释代理建模通用框架的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents a novel graph neural network (GNN) architecture, theFeature-specific Interpretable Graph Neural Network (FIGNN), designed toenhance the interpretability of deep learning surrogate models defined onunstructured grids in scientific applications. Traditional GNNs often obscurethe distinct spatial influences of different features in multivariateprediction tasks. FIGNN addresses this limitation by introducing afeature-specific pooling strategy, which enables independent attribution ofspatial importance for each predicted variable. Additionally, a mask-basedregularization term is incorporated into the training objective to explicitlyencourage alignment between interpretability and predictive error, promotinglocalized attribution of model performance. The method is evaluated forsurrogate modeling of two physically distinct systems: the SPEEDY atmosphericcirculation model and the backward-facing step (BFS) fluid dynamics benchmark.Results demonstrate that FIGNN achieves competitive predictive performancewhile revealing physically meaningful spatial patterns unique to each feature.Analysis of rollout stability, feature-wise error budgets, and spatial maskoverlays confirm the utility of FIGNN as a general-purpose framework forinterpretable surrogate modeling in complex physical domains.</description>
      <author>example@mail.com (Riddhiman Raut, Romit Maulik, Shivam Barwey)</author>
      <guid isPermaLink="false">2506.11398v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>TAViS: Text-bridged Audio-Visual Segmentation with Foundation Models</title>
      <link>http://arxiv.org/abs/2506.11436v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TAViS的新框架，用于解决音频-视觉分割（AVS）中的跨模态对齐问题。&lt;h4&gt;背景&lt;/h4&gt;当前音频-视觉分割方法在处理数据稀缺问题时，往往依赖于单一模态的知识或以现成方式结合基础模型，未能有效解决跨模态对齐的挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效结合多模态基础模型知识（ImageBind）和分割基础模型（SAM2）的框架，以实现精确的音频-视觉分割。&lt;h4&gt;方法&lt;/h4&gt;TAViS通过以下方式解决知识转移和监督不足的问题：(1) 引入文本桥接设计，包括一个文本桥接混合提示机制，其中伪文本提供类别原型信息，同时保留音频和视觉输入的模态特定细节；(2) 采用文本作为桥梁的归一化监督策略，以对齐音频-视觉模态中的共享语义概念。&lt;h4&gt;主要发现&lt;/h4&gt;TAViS在单源、多源和语义数据集上实现了优越的性能，并且在零样本设置中表现出色。&lt;h4&gt;结论&lt;/h4&gt;TAViS框架为音频-视觉分割提供了有效的解决方案，尤其是在跨模态对齐和数据稀缺的情况下。&lt;h4&gt;翻译&lt;/h4&gt;摘要：音频-视觉分割（AVS）面临着有效对齐音频和视觉模态的根本挑战。虽然最近的方法利用基础模型来应对数据稀缺问题，但它们通常依赖于单一模态的知识或以现成方式结合基础模型，未能解决跨模态对齐的挑战。在本文中，我们提出了一种名为TAViS的新框架，该框架将多模态基础模型（ImageBind）的知识与用于精确分割的分割基础模型（SAM2）相结合。然而，有效地结合这些模型提出了两个关键挑战：由于它们具有不同的特征空间，因此SAM2和ImageBind之间知识转移的困难，以及仅使用分割损失进行监督的不充分性。为了解决这些挑战，我们引入了一种文本桥接设计，包括两个关键组件：(1) 一个文本桥接混合提示机制，其中伪文本提供类别原型信息，同时保留音频和视觉输入的模态特定细节；(2) 一种利用文本作为桥梁的归一化监督策略，以对齐音频-视觉模态中的共享语义概念。我们的方法在单源、多源和语义数据集上实现了优越的性能，并且在零样本设置中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio-Visual Segmentation (AVS) faces a fundamental challenge of effectivelyaligning audio and visual modalities. While recent approaches leveragefoundation models to address data scarcity, they often rely on single-modalityknowledge or combine foundation models in an off-the-shelf manner, failing toaddress the cross-modal alignment challenge. In this paper, we present TAViS, anovel framework that \textbf{couples} the knowledge of multimodal foundationmodels (ImageBind) for cross-modal alignment and a segmentation foundationmodel (SAM2) for precise segmentation. However, effectively combining thesemodels poses two key challenges: the difficulty in transferring the knowledgebetween SAM2 and ImageBind due to their different feature spaces, and theinsufficiency of using only segmentation loss for supervision. To address thesechallenges, we introduce a text-bridged design with two key components: (1) atext-bridged hybrid prompting mechanism where pseudo text provides classprototype information while retaining modality-specific details from both audioand visual inputs, and (2) an alignment supervision strategy that leveragestext as a bridge to align shared semantic concepts within audio-visualmodalities. Our approach achieves superior performance on single-source,multi-source, semantic datasets, and excels in zero-shot settings.</description>
      <author>example@mail.com (Ziyang Luo, Nian Liu, Xuguang Yang, Salman Khan, Rao Muhammad Anwer, Hisham Cholakkal, Fahad Shahbaz Khan, Junwei Han)</author>
      <guid isPermaLink="false">2506.11436v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>EDN: A Novel Edge-Dependent Noise Model for Graph Data</title>
      <link>http://arxiv.org/abs/2506.11368v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了Edge-Dependent Noise (EDN)模型，该模型关注图数据中节点之间关系的边缘依赖性，并探讨了三种EDN变体，通过实验证明了其在图神经网络和噪声鲁棒算法中的有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的节点标签噪声模型如对称标签噪声（SLN）和类条件噪声（CCN）忽略了图数据中节点之间的重要关系。&lt;h4&gt;目的&lt;/h4&gt;研究边缘依赖噪声（EDN）模型，并探讨其在不同变体下的性能表现。&lt;h4&gt;方法&lt;/h4&gt;在流行的图数据集上使用5种不同的图神经网络（GNN）架构和8种噪声鲁棒算法进行实验，比较了不同EDN变体与传统的节点标签噪声模型在GNN和噪声鲁棒算法中的性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，两种EDN变体相较于传统的节点标签噪声模型，在GNN和噪声鲁棒算法中导致更大的性能下降。&lt;h4&gt;结论&lt;/h4&gt;EDN模型在评估图数据的噪声鲁棒算法时非常重要，可以提高在噪声环境中的图学习可靠性。&lt;h4&gt;翻译&lt;/h4&gt;An important structural feature of a graph is its set of edges, as it captures the relationships among the nodes (the graph's topology). Existing node label noise models like Symmetric Label Noise (SLN) and Class Conditional Noise (CCN) disregard this important node relationship in graph data; and the Edge-Dependent Noise (EDN) model addresses this limitation. EDN posits that in real-world scenarios, label noise may be influenced by the connections between nodes. We explore three variants of EDN. A crucial notion that relates nodes and edges in a graph is the degree of a node; we show that in all three variants, the probability of a node's label corruption is dependent on its degree. Additionally, we compare the dependence of these probabilities on node degree across different variants. We performed experiments on popular graph datasets using 5 different GNN architectures and 8 noise robust algorithms for graph data. The results demonstrate that 2 variants of EDN lead to greater performance degradation in both Graph Neural Networks (GNNs) and existing noise-robust algorithms, as compared to traditional node label noise models. We statistically verify this by posing a suitable hypothesis-testing problem. This emphasizes the importance of incorporating EDN when evaluating noise robust algorithms for graphs, to enhance the reliability of graph-based learning in noisy environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; An important structural feature of a graph is its set of edges, as itcaptures the relationships among the nodes (the graph's topology). Existingnode label noise models like Symmetric Label Noise (SLN) and Class ConditionalNoise (CCN) disregard this important node relationship in graph data; and theEdge-Dependent Noise (EDN) model addresses this limitation. EDN posits that inreal-world scenarios, label noise may be influenced by the connections betweennodes. We explore three variants of EDN. A crucial notion that relates nodesand edges in a graph is the degree of a node; we show that in all threevariants, the probability of a node's label corruption is dependent on itsdegree. Additionally, we compare the dependence of these probabilities on nodedegree across different variants. We performed experiments on popular graphdatasets using 5 different GNN architectures and 8 noise robust algorithms forgraph data. The results demonstrate that 2 variants of EDN lead to greaterperformance degradation in both Graph Neural Networks (GNNs) and existingnoise-robust algorithms, as compared to traditional node label noise models. Westatistically verify this by posing a suitable hypothesis-testing problem. Thisemphasizes the importance of incorporating EDN when evaluating noise robustalgorithms for graphs, to enhance the reliability of graph-based learning innoisy environments.</description>
      <author>example@mail.com (Pintu Kumar, Nandyala Hemachandra)</author>
      <guid isPermaLink="false">2506.11368v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>HyBiomass: Global Hyperspectral Imagery Benchmark Dataset for Evaluating Geospatial Foundation Models in Forest Aboveground Biomass Estimation</title>
      <link>http://arxiv.org/abs/2506.11314v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出一个全球分布的森林地上生物量（AGB）估计数据集，用于评估地理空间基础模型（Geo-FMs）的性能，并探讨了Geo-FMs在HSI应用中的地理偏差和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基准数据集主要限于分割或分类任务，且集中于特定地理区域。&lt;h4&gt;目的&lt;/h4&gt;通过引入全球分布的数据集，旨在促进Geo-FMs在HSI应用中的发展和评估。&lt;h4&gt;方法&lt;/h4&gt;数据集结合了来自EnMAP卫星的共定位高光谱图像（HSI）和来自全球生态系统动态调查激光雷达的AGB密度估计预测，覆盖七个大陆地区。&lt;h4&gt;主要发现&lt;/h4&gt;Geo-FMs的性能可以与基线U-Net相匹配，甚至在某些情况下超越U-Net，尤其是在微调编码器时。U-Net与Geo-FMs之间的性能差异取决于每个地区的数据集大小，并强调了Vision Transformer骨干网络中token patch大小对像素级回归任务准确预测的重要性。&lt;h4&gt;结论&lt;/h4&gt;通过发布这个全球分布的高光谱基准数据集，可以促进Geo-FMs的发展与评估，并有助于研究Geo-FMs的地理偏差和泛化能力。数据集和源代码将公开提供。&lt;h4&gt;翻译&lt;/h4&gt;Comprehensive evaluation of geospatial foundation models (Geo-FMs) requires benchmarking across diverse tasks, sensors, and geographic regions. However, most existing benchmark datasets are limited to segmentation or classification tasks, and focus on specific geographic areas. To address this gap, we introduce a globally distributed dataset for forest aboveground biomass (AGB) estimation, a pixel-wise regression task. This benchmark dataset combines co-located hyperspectral imagery (HSI) from the Environmental Mapping and Analysis Program (EnMAP) satellite and predictions of AGB density estimates derived from the Global Ecosystem Dynamics Investigation lidars, covering seven continental regions. Our experimental results on this dataset demonstrate that the evaluated Geo-FMs can match or, in some cases, surpass the performance of a baseline U-Net, especially when fine-tuning the encoder. We also find that the performance difference between the U-Net and Geo-FMs depends on the dataset size for each region and highlight the importance of the token patch size in the Vision Transformer backbone for accurate predictions in pixel-wise regression tasks. By releasing this globally distributed hyperspectral benchmark dataset, we aim to facilitate the development and evaluation of Geo-FMs for HSI applications. Leveraging this dataset additionally enables research into geographic bias and generalization capacity of Geo-FMs. The dataset and source code will be made publicly available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Comprehensive evaluation of geospatial foundation models (Geo-FMs) requiresbenchmarking across diverse tasks, sensors, and geographic regions. However,most existing benchmark datasets are limited to segmentation or classificationtasks, and focus on specific geographic areas. To address this gap, weintroduce a globally distributed dataset for forest aboveground biomass (AGB)estimation, a pixel-wise regression task. This benchmark dataset combinesco-located hyperspectral imagery (HSI) from the Environmental Mapping andAnalysis Program (EnMAP) satellite and predictions of AGB density estimatesderived from the Global Ecosystem Dynamics Investigation lidars, covering sevencontinental regions. Our experimental results on this dataset demonstrate thatthe evaluated Geo-FMs can match or, in some cases, surpass the performance of abaseline U-Net, especially when fine-tuning the encoder. We also find that theperformance difference between the U-Net and Geo-FMs depends on the datasetsize for each region and highlight the importance of the token patch size inthe Vision Transformer backbone for accurate predictions in pixel-wiseregression tasks. By releasing this globally distributed hyperspectralbenchmark dataset, we aim to facilitate the development and evaluation ofGeo-FMs for HSI applications. Leveraging this dataset additionally enablesresearch into geographic bias and generalization capacity of Geo-FMs. Thedataset and source code will be made publicly available.</description>
      <author>example@mail.com (Aaron Banze, Timothée Stassin, Nassim Ait Ali Braham, Rıdvan Salih Kuzu, Simon Besnard, Michael Schmitt)</author>
      <guid isPermaLink="false">2506.11314v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Lifting Data-Tracing Machine Unlearning to Knowledge-Tracing for Foundation Models</title>
      <link>http://arxiv.org/abs/2506.11253v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将数据追踪机器反学习提升到知识追踪的方法，用于基础模型（FMs）。&lt;h4&gt;背景&lt;/h4&gt;数据所有者可能会撤销允许模型从数据中学习的决定，导致机器反学习需求。目前，数据追踪无法满足对FMs多样化的反学习请求。&lt;h4&gt;目的&lt;/h4&gt;提出基于实际需求和认知研究洞察的方法，使FMs的反学习请求更方便地被提出。&lt;h4&gt;方法&lt;/h4&gt;提出知识追踪的机器反学习范式，并提供了关于视觉语言FMs的具体案例研究。&lt;h4&gt;主要发现&lt;/h4&gt;知识追踪的反学习与人类大脑遗忘过程更为吻合，且对于无权访问FMs大量训练数据的各方（如监管机构、企业用户、产品团队等）更为便利。&lt;h4&gt;结论&lt;/h4&gt;知识追踪机器反学习可以更好地满足FMs的反学习需求，并更贴近人类大脑的遗忘机制。&lt;h4&gt;翻译&lt;/h4&gt;Machine unlearning removes certain training data points and their influence on AI models (e.g., when a data owner revokes their decision to allow models to learn from the data). In this position paper, we propose to lift data-tracing machine unlearning to knowledge-tracing for foundation models (FMs). We support this position based on practical needs and insights from cognitive studies. Practically, tracing data cannot meet the diverse unlearning requests for FMs, which may be from regulators, enterprise users, product teams, etc., having no access to FMs' massive training data. Instead, it is convenient for these parties to issue an unlearning request about the knowledge or capability FMs (should not) possess. Cognitively, knowledge-tracing unlearning aligns with how the human brain forgets more closely than tracing individual training data points. Finally, we provide a concrete case study about a vision-language FM to illustrate how an unlearner might instantiate the knowledge-tracing machine unlearning paradigm.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine unlearning removes certain training data points and their influenceon AI models (e.g., when a data owner revokes their decision to allow models tolearn from the data). In this position paper, we propose to lift data-tracingmachine unlearning to knowledge-tracing for foundation models (FMs). We supportthis position based on practical needs and insights from cognitive studies.Practically, tracing data cannot meet the diverse unlearning requests for FMs,which may be from regulators, enterprise users, product teams, etc., having noaccess to FMs' massive training data. Instead, it is convenient for theseparties to issue an unlearning request about the knowledge or capability FMs(should not) possess. Cognitively, knowledge-tracing unlearning aligns with howthe human brain forgets more closely than tracing individual training datapoints. Finally, we provide a concrete case study about a vision-language FM toillustrate how an unlearner might instantiate the knowledge-tracing machineunlearning paradigm.</description>
      <author>example@mail.com (Yuwen Tan, Boqing Gong)</author>
      <guid isPermaLink="false">2506.11253v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>HEIST: A Graph Foundation Model for Spatial Transcriptomics and Proteomics Data</title>
      <link>http://arxiv.org/abs/2506.11152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;HEIST是一种基于层次图变换器的基础模型，用于处理空间转录组和蛋白质组数据，旨在通过上下文化的细胞和基因表示来理解细胞异质性和转录调控。&lt;h4&gt;背景&lt;/h4&gt;单细胞转录组学已成为生物学数据驱动洞察的重要来源，而空间转录组数据提供了细胞的空间坐标和转录组读数，有助于在组织背景下了解细胞。&lt;h4&gt;目的&lt;/h4&gt;开发一个模型来创建从空间转录组数据中获取的细胞和基因的上下文化表示，以更好地理解细胞异质性和转录调控。&lt;h4&gt;方法&lt;/h4&gt;HEIST模型将组织建模为空间细胞邻域图，每个细胞被建模为基因调控网络图，并使用层次图变换器进行跨层消息传递和层内消息传递。该模型通过空间感知对比学习和掩码自动编码目标进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;HEIST能够有效编码细胞嵌入中的微环境影响，发现先前模型未能区分的空间信息子群。在临床结果预测、细胞类型注释、基因插补和基于空间信息的细胞聚类等下游任务中，HEIST取得了最先进的成果。&lt;h4&gt;结论&lt;/h4&gt;层次建模和基于基因调控网络（GRN）的表示对于理解空间转录组数据中的细胞异质性和转录调控至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single-cell transcriptomics has become a great source for data-driveninsights into biology, enabling the use of advanced deep learning methods tounderstand cellular heterogeneity and transcriptional regulation at thesingle-cell level. With the advent of spatial transcriptomics data we have thepromise of learning about cells within a tissue context as it provides bothspatial coordinates and transcriptomic readouts. However, existing modelseither ignore spatial resolution or the gene regulatory information. Generegulation in cells can change depending on microenvironmental cues fromneighboring cells, but existing models neglect gene regulatory patterns withhierarchical dependencies across levels of abstraction. In order to createcontextualized representations of cells and genes from spatial transcriptomicsdata, we introduce HEIST, a hierarchical graph transformer-based foundationmodel for spatial transcriptomics and proteomics data. HEIST models tissue asspatial cellular neighborhood graphs, and each cell is, in turn, modeled as agene regulatory network graph. The framework includes a hierarchical graphtransformer that performs cross-level message passing and message passingwithin levels. HEIST is pre-trained on 22.3M cells from 124 tissues across 15organs using spatially-aware contrastive learning and masked auto-encodingobjectives. Unsupervised analysis of HEIST representations of cells, shows thatit effectively encodes the microenvironmental influences in cell embeddings,enabling the discovery of spatially-informed subpopulations that prior modelsfail to differentiate. Further, HEIST achieves state-of-the-art results on fourdownstream task such as clinical outcome prediction, cell type annotation, geneimputation, and spatially-informed cell clustering across multipletechnologies, highlighting the importance of hierarchical modeling andGRN-based representations.</description>
      <author>example@mail.com (Hiren Madhu, João Felipe Rocha, Tinglin Huang, Siddharth Viswanath, Smita Krishnaswamy, Rex Ying)</author>
      <guid isPermaLink="false">2506.11152v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Modeling of CRISPR-Cas12 Activity Using Foundation Models and Chromatin Accessibility Data</title>
      <link>http://arxiv.org/abs/2506.11182v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This manuscript has been accepted by ICML workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用预训练的生物基础模型来提高gRNA活性预测的准确性，并探讨了整合染色质可及性数据对预测性能的提升。&lt;h4&gt;背景&lt;/h4&gt;预测gRNA活性对于有效的CRISPR-Cas12基因组编辑至关重要，但由于数据有限、PAMs（Cas结合的短序列要求）的变异以及依赖大规模训练，这一任务仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;研究是否可以通过在转录组数据上预训练的生物基础模型来改善gRNA活性的估计，即使没有特定领域的预训练。&lt;h4&gt;方法&lt;/h4&gt;使用现有RNA基础模型的嵌入作为轻量级回归器的输入，并整合染色质可及性数据以捕获调控环境。&lt;h4&gt;主要发现&lt;/h4&gt;使用预训练的基础模型和染色质可及性数据，在gRNA活性预测方面取得了显著的提升，超过了传统的基线方法。&lt;h4&gt;结论&lt;/h4&gt;预训练的基础模型和染色质可及性数据对于gRNA活性预测是有效的。&lt;h4&gt;翻译&lt;/h4&gt;Predicting guide RNA (gRNA) activity is critical for effective CRISPR-Cas12 genome editing but remains challenging due to limited data, variation across protospacer adjacent motifs (PAMs - short sequence requirements for Cas binding), and reliance on large-scale training. We investigate whether pre-trained biological foundation model originally trained on transcriptomic data can improve gRNA activity estimation even without domain-specific pre-training. Using embeddings from existing RNA foundation model as input to lightweight regressor, we show substantial gains over traditional baselines. We also integrate chromatin accessibility data to capture regulatory context, improving performance further. Our results highlight the effectiveness of pre-trained foundation models and chromatin accessibility data for gRNA activity prediction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting guide RNA (gRNA) activity is critical for effective CRISPR-Cas12genome editing but remains challenging due to limited data, variation acrossprotospacer adjacent motifs (PAMs-short sequence requirements for Cas binding),and reliance on large-scale training. We investigate whether pre-trainedbiological foundation model originally trained on transcriptomic data canimprove gRNA activity estimation even without domain-specific pre-training.Using embeddings from existing RNA foundation model as input to lightweightregressor, we show substantial gains over traditional baselines. We alsointegrate chromatin accessibility data to capture regulatory context, improvingperformance further. Our results highlight the effectiveness of pre-trainedfoundation models and chromatin accessibility data for gRNA activityprediction.</description>
      <author>example@mail.com (Azim Dehghani Amirabad, Yanfei Zhang, Artem Moskalev, Sowmya Rajesh, Tommaso Mansi, Shuwei Li, Mangal Prakash, Rui Liao)</author>
      <guid isPermaLink="false">2506.11182v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Towards a general-purpose foundation model for fMRI analysis</title>
      <link>http://arxiv.org/abs/2506.11167v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了NeuroSTORM，一个从4D fMRI体积直接学习的通用框架，提高了fMRI分析的可重复性和可迁移性。&lt;h4&gt;背景&lt;/h4&gt;fMRI对于研究脑功能和诊断神经系统疾病至关重要，但现有的分析方法由于复杂的预处理和特定任务的模型而面临可重复性和可迁移性问题。&lt;h4&gt;目的&lt;/h4&gt;提出NeuroSTORM框架，以提高fMRI分析的可重复性和可迁移性。&lt;h4&gt;方法&lt;/h4&gt;NeuroSTORM在来自超过50,000名受试者（年龄5至100岁）的28.65百万个fMRI帧（&gt;9,000小时）上预训练，使用Mamba骨干网络和移位扫描策略高效处理4D体积，并提出空间-时间优化预训练方法和特定任务提示调优。&lt;h4&gt;主要发现&lt;/h4&gt;NeuroSTORM在五个任务上优于现有方法，包括年龄/性别预测、表型预测、疾病诊断、fMRI到图像检索和基于任务的fMRI分类。在来自美国、韩国和澳大利亚的医院数据集上表现出强大的临床实用性，在疾病诊断和认知表型预测中取得了最佳性能。&lt;h4&gt;结论&lt;/h4&gt;NeuroSTORM提供了一个标准化、开源的基础模型，以改善基于fMRI的临床研究中的可重复性和可迁移性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Functional Magnetic Resonance Imaging (fMRI) is essential for studying brainfunction and diagnosing neurological disorders, but current analysis methodsface reproducibility and transferability issues due to complex pre-processingand task-specific models. We introduce NeuroSTORM (Neuroimaging FoundationModel with Spatial-Temporal Optimized Representation Modeling), a generalizableframework that directly learns from 4D fMRI volumes and enables efficientknowledge transfer across diverse applications. NeuroSTORM is pre-trained on28.65 million fMRI frames (&gt;9,000 hours) from over 50,000 subjects acrossmultiple centers and ages 5 to 100. Using a Mamba backbone and a shiftedscanning strategy, it efficiently processes full 4D volumes. We also propose aspatial-temporal optimized pre-training approach and task-specific prompttuning to improve transferability. NeuroSTORM outperforms existing methodsacross five tasks: age/gender prediction, phenotype prediction, diseasediagnosis, fMRI-to-image retrieval, and task-based fMRI classification. Itdemonstrates strong clinical utility on datasets from hospitals in the U.S.,South Korea, and Australia, achieving top performance in disease diagnosis andcognitive phenotype prediction. NeuroSTORM provides a standardized, open-sourcefoundation model to improve reproducibility and transferability in fMRI-basedclinical research.</description>
      <author>example@mail.com (Cheng Wang, Yu Jiang, Zhihao Peng, Chenxin Li, Changbae Bang, Lin Zhao, Jinglei Lv, Jorge Sepulcre, Carl Yang, Lifang He, Tianming Liu, Daniel Barron, Quanzheng Li, Randy Hirschtick, Byung-Hoon Kim, Xiang Li, Yixuan Yuan)</author>
      <guid isPermaLink="false">2506.11167v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Evidential Spectrum-Aware Contrastive Learning for OOD Detection in Dynamic Graphs</title>
      <link>http://arxiv.org/abs/2506.07417v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ECML-PKDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了动态图中的分布外检测问题，提出了一种基于证据深度学习的OOD检测器EviSEC，通过证据光谱对比学习提高了检测效果。&lt;h4&gt;背景&lt;/h4&gt;当前OOD检测方法主要针对静态图，存在单点估计导致的偏差和方差高，以及缺乏OOD训练数据导致的分数同质化问题。&lt;h4&gt;目的&lt;/h4&gt;解决动态图中OOD检测的偏差、方差和分数同质化问题。&lt;h4&gt;方法&lt;/h4&gt;提出EviSEC，通过设计证据神经网络和光谱增强模块，利用后验狄利克雷分布来解释输入的随机性，并生成OOD近似以识别高分数模式。&lt;h4&gt;主要发现&lt;/h4&gt;EviSEC在真实世界数据集上有效检测动态图中的OOD样本。&lt;h4&gt;结论&lt;/h4&gt;EviSEC能够有效解决动态图中OOD检测的挑战，为安全敏感领域提供了一种有效的检测方法。&lt;h4&gt;翻译&lt;/h4&gt;Recently, Out-of-distribution (OOD) detection in dynamic graphs, which aims to identify whether incoming data deviates from the distribution of the in-distribution (ID) training set, has garnered considerable attention in security-sensitive fields. Current OOD detection paradigms primarily focus on static graphs and confront two critical challenges: i) high bias and high variance caused by single-point estimation, which makes the predictions sensitive to randomness in the data; ii) score homogenization resulting from the lack of OOD training data, where the model only learns ID-specific patterns, resulting in overall low OOD scores and a narrow score gap between ID and OOD data. To tackle these issues, we first investigate OOD detection in dynamic graphs through the lens of Evidential Deep Learning (EDL). Specifically, we propose EviSEC, an innovative and effective OOD detector via Evidential Spectrum-awarE Contrastive Learning. We design an evidential neural network to redefine the output as the posterior Dirichlet distribution, explaining the randomness of inputs through the uncertainty of distribution, which is overlooked by single-point estimation. Moreover, spectrum-awareaugmentation module generates OOD approximations to identify patterns with high OOD scores, thereby widening the score gap between ID and OOD data and mitigating score homogenization. Extensive experiments on real-world datasets demonstrate that EviSAC effectively detects OOD samples in dynamic graphs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/sunnan191/evisec&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Out-of-distribution (OOD) detection in dynamic graphs, which aimsto identify whether incoming data deviates from the distribution of thein-distribution (ID) training set, has garnered considerable attention insecurity-sensitive fields. Current OOD detection paradigms primarily focus onstatic graphs and confront two critical challenges: i) high bias and highvariance caused by single-point estimation, which makes the predictionssensitive to randomness in the data; ii) score homogenization resulting fromthe lack of OOD training data, where the model only learns ID-specificpatterns, resulting in overall low OOD scores and a narrow score gap between IDand OOD data. To tackle these issues, we first investigate OOD detection indynamic graphs through the lens of Evidential Deep Learning (EDL).Specifically, we propose EviSEC, an innovative and effective OOD detector viaEvidential Spectrum-awarE Contrastive Learning. We design an evidential neuralnetwork to redefine the output as the posterior Dirichlet distribution,explaining the randomness of inputs through the uncertainty of distribution,which is overlooked by single-point estimation. Moreover, spectrum-awareaugmentation module generates OOD approximations to identify patterns with highOOD scores, thereby widening the score gap between ID and OOD data andmitigating score homogenization. Extensive experiments on real-world datasetsdemonstrate that EviSAC effectively detects OOD samples in dynamic graphs.</description>
      <author>example@mail.com (Nan Sun, Xixun Lin, Zhiheng Zhou, Yanmin Shang, Zhenlin Cheng, Yanan Cao)</author>
      <guid isPermaLink="false">2506.07417v2</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Synthetic Geology -- Structural Geology Meets Deep Learning</title>
      <link>http://arxiv.org/abs/2506.11164v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 8 figures, submitted to "Communications Earth &amp;  Environment", geological simulation code at  https://doi.org/10.5281/zenodo.15244035, generative AI code at  https://github.com/chipnbits/flowtrain_stochastic_interpolation/releases/tag/v1.0.0&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;通过深度学习，可视化地球表面以下几公里的地下结构成为可能，该方法通过结合生成式人工智能技术和合成数据生成器，从地表地质数据中生成三维地下区域图像。&lt;h4&gt;背景&lt;/h4&gt;可视化地球表面以下结构对于众多应用至关重要，但目前面临的主要挑战是地下数据的可获得性。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，通过神经网络训练，将地表地质数据与钻孔数据扩展到三维地下区域。&lt;h4&gt;方法&lt;/h4&gt;结合生成式人工智能技术，训练神经网络，并设计合成数据生成器，模拟地质活动，生成大量样本。&lt;h4&gt;主要发现&lt;/h4&gt;基于合成数据的模型能够从未见过的地表地形和地质图生成3D地下图像，随着钻孔数据的增加，图像的准确性提高，并能描绘地层、断层、褶皱、岩墙和岩床等结构。&lt;h4&gt;结论&lt;/h4&gt;这种合成岩壳生成器与训练好的神经网络模型的组合具有早期潜力，最终模型将在特定区域的数据上进行微调，不仅适用于资源勘探、灾害评估和岩土工程，还可以作为人工智能正则化器应用于传统的反问题应用中。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visualizing the first few kilometers of the Earth's subsurface, along-standing challenge gating a virtually inexhaustible list of importantapplications, is coming within reach through deep learning. Building ontechniques of generative artificial intelligence applied to voxelated images,we demonstrate a method that extends surface geological data supplemented byboreholes to a three-dimensional subsurface region by training a neuralnetwork. The Earth's land area having been extensively mapped for geologicalfeatures, the bottleneck of this or any related technique is the availabilityof data below the surface. We close this data gap in the development ofsubsurface deep learning by designing a synthetic data-generator process thatmimics eons of geological activity such as sediment compaction, volcanicintrusion, and tectonic dynamics to produce a virtually limitless number ofsamples of the near lithosphere. A foundation model trained on such syntheticdata is able to generate a 3D image of the subsurface from a previously unseenmap of surface topography and geology, showing increasing fidelity withincreasing access to borehole data, depicting such structures as layers,faults, folds, dikes, and sills. We illustrate the early promise of thecombination of a synthetic lithospheric generator with a trained neural networkmodel using generative flow matching. Ultimately, such models will befine-tuned on data from applicable campaigns, such as mineral prospecting in agiven region. Though useful in itself, a regionally fine-tuned models may beemployed not as an end but as a means: as an AI-based regularizer in a moretraditional inverse problem application, in which the objective functionrepresents the mismatch of additional data with physical models withapplications in resource exploration, hazard assessment, and geotechnicalengineering.</description>
      <author>example@mail.com (Simon Ghyselincks, Valeriia Okhmak, Stefano Zampini, George Turkiyyah, David Keyes, Eldad Haber)</author>
      <guid isPermaLink="false">2506.11164v1</guid>
      <pubDate>Mon, 16 Jun 2025 14:17:31 +0800</pubDate>
    </item>
    <item>
      <title>Joint Beamforming and Resource Allocation for Delay Optimization in RIS-Assisted OFDM Systems: A DRL Approach</title>
      <link>http://arxiv.org/abs/2506.03586v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在下行可重构智能表面（RIS）辅助的正交频分复用（OFDM）系统中，联合相位设计和资源分配问题，以优化平均延迟，其中每个用户的数据包到达基站是随机的。&lt;h4&gt;背景&lt;/h4&gt;该优化问题本质上是马尔可夫决策过程（MDP），属于强化学习的范畴。&lt;h4&gt;目的&lt;/h4&gt;为了有效地处理混合动作空间并降低状态空间维度，提出了一种混合深度强化学习（DRL）方法。&lt;h4&gt;方法&lt;/h4&gt;具体使用近端策略优化（PPO）-θ优化RIS相位偏移设计，而PPO-N负责子载波分配决策。为了进一步减轻子载波分配相关的维度灾难，引入了多智能体策略以更有效地优化子载波分配指标。此外，为了实现更适应的资源分配和准确捕捉网络动态，将与平均延迟密切相关的关键因素，包括缓冲区中积压的数据包数量和当前数据包到达情况，纳入状态空间。还引入了迁移学习框架以提高训练效率和加速收敛。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，所提出的算法显著降低了平均延迟，提高了资源分配效率，与基线方法相比，实现了更优的系统鲁棒性和公平性。&lt;h4&gt;结论&lt;/h4&gt;该算法在优化平均延迟、资源分配效率以及系统性能方面具有显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates a joint phase design and resource allocation problemin downlink reconfigurable intelligent surface (RIS)-assisted orthogonalfrequency division multiplexing (OFDM) systems to optimize average delay, wheredata packets for each user arrive at the base station stochastically. Thesequential optimization problem is inherently a Markov decision process (MDP),making it fall within the scope of reinforcement learning. To effectivelyhandle the mixed action space and reduce the state space dimensionality, ahybrid deep reinforcement learning (DRL) approach is proposed. Specifically,proximal policy optimization (PPO)-$\Theta$ is employed to optimize RIS phaseshift design, while PPO-N is responsible for subcarrier allocation decisions.To further mitigate the curse of dimensionality associated with subcarrierallocation, a multi-agent strategy is introduced to optimize subcarrierallocation indicater more efficiently. Moreover, to achieve more adaptiveresource allocation and accurately capture network dynamics, key factorsclosely related to average delay, including the number of backlogged packets inbuffers and the current packet arrivals, are incorporated into the state space.Furthermore, a transfer learning framework is introduced to enhance trainingefficiency and accelerate convergence. Simulation results demonstrate that theproposed algorithm significantly reduces average delay, enhances resourceallocation efficiency, and achieves superior system robustness and fairnesscompared to baseline methods.</description>
      <author>example@mail.com (Yu Ma, Chongtao Guo, Le Liang, Xiao Li, Shi Jin)</author>
      <guid isPermaLink="false">2506.03586v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
  <item>
      <title>Learnable Spatial-Temporal Positional Encoding for Link Prediction</title>
      <link>http://arxiv.org/abs/2506.08309v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML 2025. 28 pages, 1 figures, 22 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为L-STEP的简单时间链接预测模型，旨在解决现有位置编码方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;当前位置编码在适应复杂属性图、考虑实时拓扑和特征信息、以及在大型结构数据上应用注意力机制方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;开发一种有效且高效的学习性时空位置编码方法。&lt;h4&gt;方法&lt;/h4&gt;L-STEP模型包括以下特点：(1) 证明了所提出的位置学习方案可以从时空谱的角度保持图属性；(2) 验证了MLP可以充分利用表达性并达到在该编码上的Transformer性能；(3) 通过改变不同的初始位置编码输入来展示其鲁棒性；(4) 分析了理论复杂度并获得了比SOTA更少的经验运行时间；(5) 在13个经典数据集上使用10种算法在归纳和归纳设置中展示了其时间链接预测的优势，并使用3种不同的采样策略。&lt;h4&gt;主要发现&lt;/h4&gt;L-STEP在最新的大规模TGB基准测试中取得了领先性能。&lt;h4&gt;结论&lt;/h4&gt;L-STEP模型能够有效解决现有位置编码方法的局限性，并在时间链接预测任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Accurate predictions rely on the expressiveness power of graph deep learning frameworks like graph neural networks and graph transformers, where positional encoding mechanism has become much more indispensable in recent state-of-the-art works to record the canonical position information. However, the current positional encoding is limited in three aspects: (1) most positional encoding methods use pre-defined, and fixed functions, which are inadequate to adapt to the complex attributed graphs; (2) a few pioneering works proposed the learnable positional encoding but are still limited to the structural information, not considering the real-world time-evolving topological and feature information; (3) most positional encoding methods are equipped with transformers' attention mechanism to fully leverage their capabilities, where the dense or relational attention is often unaffordable on large-scale structured data. Hence, we aim to develop Learnable Spatial-Temporal Positional Encoding in an effective and efficient manner and propose a simple temporal link prediction model named L-STEP. Briefly, for L-STEP, we (1) prove the proposed positional learning scheme can preserve the graph property from the spatial-temporal spectral viewpoint, (2) verify that MLPs can fully exploit the expressiveness and reach transformers' performance on that encoding, (3) change different initial positional encoding inputs to show robustness, (4) analyze the theoretical complexity and obtain less empirical running time than SOTA, and (5) demonstrate its temporal link prediction out-performance on 13 classic datasets and with 10 algorithms in both transductive and inductive settings using 3 different sampling strategies. Also, the proposed method obtains the leading performance in the newest large-scale TGB benchmark. Our code is available at https://github.com/kthrn22/L-STEP.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate predictions rely on the expressiveness power of graph deep learningframeworks like graph neural networks and graph transformers, where apositional encoding mechanism has become much more indispensable in recentstate-of-the-art works to record the canonical position information. However,the current positional encoding is limited in three aspects: (1) mostpositional encoding methods use pre-defined, and fixed functions, which areinadequate to adapt to the complex attributed graphs; (2) a few pioneeringworks proposed the learnable positional encoding but are still limited to thestructural information, not considering the real-world time-evolvingtopological and feature information; (3) most positional encoding methods areequipped with transformers' attention mechanism to fully leverage theircapabilities, where the dense or relational attention is often unaffordable onlarge-scale structured data. Hence, we aim to develop LearnableSpatial-Temporal Positional Encoding in an effective and efficient manner andpropose a simple temporal link prediction model named L-STEP. Briefly, forL-STEP, we (1) prove the proposed positional learning scheme can preserve thegraph property from the spatial-temporal spectral viewpoint, (2) verify thatMLPs can fully exploit the expressiveness and reach transformers' performanceon that encoding, (3) change different initial positional encoding inputs toshow robustness, (4) analyze the theoretical complexity and obtain lessempirical running time than SOTA, and (5) demonstrate its temporal linkprediction out-performance on 13 classic datasets and with 10 algorithms inboth transductive and inductive settings using 3 different sampling strategies.Also, \name\ obtains the leading performance in the newest large-scale TGBbenchmark. Our code is available at https://github.com/kthrn22/L-STEP.</description>
      <author>example@mail.com (Katherine Tieu, Dongqi Fu, Zihao Li, Ross Maciejewski, Jingrui He)</author>
      <guid isPermaLink="false">2506.08309v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Instance-Based Transfer Learning with Similarity-Aware Subject Selection for Cross-Subject SSVEP-Based BCIs</title>
      <link>http://arxiv.org/abs/2506.10933v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE Journal of Biomedical and Health Informatics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于实例的与任务相关的成分分析（iTRCA）的迁移学习框架，用于提高SSVEP-BCI的识别准确率，并减少目标受试者的数据需求。&lt;h4&gt;背景&lt;/h4&gt;SSVEP-BCI可以通过足够的训练数据实现高识别准确率，而迁移学习可以通过利用源受试者的数据来减轻目标受试者的数据需求。然而，处理目标和源受试者之间的个体差异仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的迁移学习框架，以减轻目标受试者的数据需求，同时考虑个体差异。&lt;h4&gt;方法&lt;/h4&gt;iTRCA提取两种类型的特征：1）主题通用特征，捕捉源和目标受试者在共同潜在空间中的共享信息；2）主题特定特征，保留目标受试者的独特特征。为了减轻负迁移，设计了基于主题选择的iTRCA（SS-iTRCA），该框架集成了一种基于相似性的主题选择策略，以识别适合迁移的源受试者。&lt;h4&gt;主要发现&lt;/h4&gt;在Benchmark、BETA和自收集数据集上的比较评估表明，所提出的iTRCA和SS-iTRCA框架是有效的。&lt;h4&gt;结论&lt;/h4&gt;本研究为开发高性能的SSVEP-BCI提供了减少目标受试者数据的潜在解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Steady-state visual evoked potential (SSVEP)-based brain-computer interfaces(BCIs) can achieve high recognition accuracy with sufficient training data. Transfer learning presents a promising solution to alleviate data requirements for the target subject by leveraging data from source subjects; however, effectively addressing individual variability among both target and source subjects remains a challenge. This paper proposes a novel transfer learning framework, termed instance-based task-related component analysis (iTRCA), which leverages knowledge from source subjects while considering their individual contributions. iTRCA extracts two types of features: (1) the subject-general feature, capturing shared information between source and target subjects in a common latent space, and (2) the subject-specific feature, preserving the unique characteristics of the target subject. To mitigate negative transfer, we further design an enhanced framework, subject selection-based iTRCA (SS-iTRCA), which integrates a similarity-based subject selection strategy to identify appropriate source subjects for transfer based on their task-related components (TRCs). Comparative evaluations on the Benchmark, BETA, and a self-collected dataset demonstrate the effectiveness of the proposed iTRCA and SS-iTRCA frameworks. This study provides a potential solution for developing high-performance SSVEP-based BCIs with reduced target subject data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/JBHI.2025.3577813&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Steady-state visual evoked potential (SSVEP)-based brain-computer interfaces(BCIs) can achieve high recognition accuracy with sufficient training data.Transfer learning presents a promising solution to alleviate data requirementsfor the target subject by leveraging data from source subjects; however,effectively addressing individual variability among both target and sourcesubjects remains a challenge. This paper proposes a novel transfer learningframework, termed instance-based task-related component analysis (iTRCA), whichleverages knowledge from source subjects while considering their individualcontributions. iTRCA extracts two types of features: (1) the subject-generalfeature, capturing shared information between source and target subjects in acommon latent space, and (2) the subject-specific feature, preserving theunique characteristics of the target subject. To mitigate negative transfer, wefurther design an enhanced framework, subject selection-based iTRCA (SS-iTRCA),which integrates a similarity-based subject selection strategy to identifyappropriate source subjects for transfer based on their task-related components(TRCs). Comparative evaluations on the Benchmark, BETA, and a self-collecteddataset demonstrate the effectiveness of the proposed iTRCA and SS-iTRCAframeworks. This study provides a potential solution for developinghigh-performance SSVEP-based BCIs with reduced target subject data.</description>
      <author>example@mail.com (Ziwen Wang, Yue Zhang, Zhiqiang Zhang, Sheng Quan Xie, Alexander Lanzon, William P. Heath, Zhenhong Li)</author>
      <guid isPermaLink="false">2506.10933v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Spurious Rewards: Rethinking Training Signals in RLVR</title>
      <link>http://arxiv.org/abs/2506.10947v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;强化学习与可验证奖励（RLVR）可以在某些模型中激发强烈的数学推理能力，即使奖励与正确答案的相关性很小、没有或甚至为负。&lt;h4&gt;背景&lt;/h4&gt;研究背景是强化学习与可验证奖励（RLVR）的应用，以及它在数学推理能力提升方面的潜力。&lt;h4&gt;目的&lt;/h4&gt;目的在于验证RLVR在数学推理任务中的效果，并探讨其在不同模型上的表现。&lt;h4&gt;方法&lt;/h4&gt;通过在Qwen2.5-Math-7B模型上应用RLVR，并使用不同类型的奖励（随机奖励、格式奖励、错误标签、1次强化学习、多数投票）进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;主要发现包括：1. RLVR在Qwen2.5-Math-7B模型上显著提升了MATH-500性能；2. RLVR在Qwen模型上提高了代码推理的频率；3. RLVR在Qwen模型上取得的性能提升接近使用真实奖励时的提升，但在其他模型如Llama3或OLMo2上效果不佳。&lt;h4&gt;结论&lt;/h4&gt;结论是，RLVR能够在某些模型中提升数学推理能力，即使在没有有效奖励信号的情况下，它也能揭示预训练期间学习到的有用推理表示。未来研究应考虑在更多样化的模型上验证RLVR的效果。&lt;h4&gt;翻译&lt;/h4&gt;We show that reinforcement learning with verifiable rewards (RLVR) can elicit strong mathematical reasoning in certain models even with spurious rewards that have little, no, or even negative correlation with the correct answer. For example, RLVR improves MATH-500 performance for Qwen2.5-Math-7B in absolute points by 21.4% (random reward), 13.8% (format reward), 24.1% (incorrect label), 26.0% (1-shot RL), and 27.1% (majority voting) -- nearly matching the 29.1% gained with ground truth rewards. However, the spurious rewards that work for Qwen often fail to yield gains with other model families like Llama3 or OLMo2. In particular, we find code reasoning -- thinking in code without actual code execution -- to be a distinctive Qwen2.5-Math behavior that becomes significantly more frequent after RLVR, from 65% to over 90%, even with spurious rewards. Overall, we hypothesize that, given the lack of useful reward signal, RLVR must somehow be surfacing useful reasoning representations learned during pretraining, although the exact mechanism remains a topic for future work. We suggest that future RLVR research should possibly be validated on diverse models rather than a single de facto choice, as we show that it is easy to get significant performance gains on Qwen models even with completely spurious reward signals.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We show that reinforcement learning with verifiable rewards (RLVR) can elicitstrong mathematical reasoning in certain models even with spurious rewards thathave little, no, or even negative correlation with the correct answer. Forexample, RLVR improves MATH-500 performance for Qwen2.5-Math-7B in absolutepoints by 21.4% (random reward), 13.8% (format reward), 24.1% (incorrectlabel), 26.0% (1-shot RL), and 27.1% (majority voting) -- nearly matching the29.1% gained with ground truth rewards. However, the spurious rewards that workfor Qwen often fail to yield gains with other model families like Llama3 orOLMo2. In particular, we find code reasoning -- thinking in code without actualcode execution -- to be a distinctive Qwen2.5-Math behavior that becomessignificantly more frequent after RLVR, from 65% to over 90%, even withspurious rewards. Overall, we hypothesize that, given the lack of useful rewardsignal, RLVR must somehow be surfacing useful reasoning representations learnedduring pretraining, although the exact mechanism remains a topic for futurework. We suggest that future RLVR research should possibly be validated ondiverse models rather than a single de facto choice, as we show that it is easyto get significant performance gains on Qwen models even with completelyspurious reward signals.</description>
      <author>example@mail.com (Rulin Shao, Shuyue Stella Li, Rui Xin, Scott Geng, Yiping Wang, Sewoong Oh, Simon Shaolei Du, Nathan Lambert, Sewon Min, Ranjay Krishna, Yulia Tsvetkov, Hannaneh Hajishirzi, Pang Wei Koh, Luke Zettlemoyer)</author>
      <guid isPermaLink="false">2506.10947v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>GENMANIP: LLM-driven Simulation for Generalizable Instruction-Following Manipulation</title>
      <link>http://arxiv.org/abs/2506.10966v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GenManip，一个针对策略泛化研究的真实桌面模拟平台，用于解决真实世界场景中机器人操作挑战，特别是关于鲁棒泛化的问题。&lt;h4&gt;背景&lt;/h4&gt;在真实世界环境中，机器人操作仍然具有挑战性，特别是关于策略如何适应不同指令和场景的鲁棒泛化方面。现有的模拟平台在探索策略适应多样化指令和场景方面支持不足，因此落后于对遵循指令的基础模型（如LLMs）日益增长的兴趣，这些模型的适应性至关重要，但尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一差距，本文提出GenManip，一个针对策略泛化研究的真实桌面模拟平台。该平台通过LLM驱动的任务导向场景图，利用10K个标注的3D对象资产自动生成大规模、多样化的任务。&lt;h4&gt;方法&lt;/h4&gt;为了系统地评估泛化能力，本文还提出了GenManip-Bench，一个经过人类在环校正的200个场景的基准。评估了两种策略类型：(1) 集成基础模型（用于感知、推理和规划）的模块化操作系统，以及(2) 通过可扩展数据收集训练的端到端策略。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，虽然数据扩展对端到端方法有益，但增强基础模型的模块化系统在多样化的场景中具有更有效的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;我们预计这个平台将促进在现实条件下策略泛化的关键见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在现实世界环境中进行机器人操作仍然具有挑战性，尤其是在鲁棒泛化方面。现有的模拟平台在探索策略如何适应不同指令和场景方面支持不足，因此落后于对遵循指令的基础模型（如LLMs）日益增长的兴趣，这些模型的适应性至关重要，但尚未得到充分探索。为了填补这一差距，我们引入了GenManip，一个针对策略泛化研究的真实桌面模拟平台。该平台通过LLM驱动的任务导向场景图，利用10K个标注的3D对象资产自动生成大规模、多样化的任务。为了系统地评估泛化能力，我们提出了GenManip-Bench，一个经过人类在环校正的200个场景的基准。评估了两种策略类型：(1) 集成基础模型（用于感知、推理和规划）的模块化操作系统，以及(2) 通过可扩展数据收集训练的端到端策略。结果显示，虽然数据扩展对端到端方法有益，但增强基础模型的模块化系统在多样化的场景中具有更有效的泛化能力。我们预计这个平台将促进在现实条件下策略泛化的关键见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic manipulation in real-world settings remains challenging, especiallyregarding robust generalization. Existing simulation platforms lack sufficientsupport for exploring how policies adapt to varied instructions and scenarios.Thus, they lag behind the growing interest in instruction-following foundationmodels like LLMs, whose adaptability is crucial yet remains underexplored infair comparisons. To bridge this gap, we introduce GenManip, a realistictabletop simulation platform tailored for policy generalization studies. Itfeatures an automatic pipeline via LLM-driven task-oriented scene graph tosynthesize large-scale, diverse tasks using 10K annotated 3D object assets. Tosystematically assess generalization, we present GenManip-Bench, a benchmark of200 scenarios refined via human-in-the-loop corrections. We evaluate two policytypes: (1) modular manipulation systems integrating foundation models forperception, reasoning, and planning, and (2) end-to-end policies trainedthrough scalable data collection. Results show that while data scaling benefitsend-to-end methods, modular systems enhanced with foundation models generalizemore effectively across diverse scenarios. We anticipate this platform tofacilitate critical insights for advancing policy generalization in realisticconditions. Project Page: https://genmanip.axi404.top/.</description>
      <author>example@mail.com (Ning Gao, Yilun Chen, Shuai Yang, Xinyi Chen, Yang Tian, Hao Li, Haifeng Huang, Hanqing Wang, Tai Wang, Jiangmiao Pang)</author>
      <guid isPermaLink="false">2506.10966v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Occlusion-Aware 3D Hand-Object Pose Estimation with Masked AutoEncoders</title>
      <link>http://arxiv.org/abs/2506.10816v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于掩码自动编码器的手-物体姿态估计方法，旨在解决单目RGB图像中由于手-物体交互的严重遮挡而导致的挑战。&lt;h4&gt;背景&lt;/h4&gt;手-物体姿态估计是一个重要挑战，主要因为手-物体交互中的遮挡问题。现有方法未能充分探索全局结构感知和推理，限制了它们处理遮挡手-物体交互的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为HOMAE的遮挡感知手-物体姿态估计方法，以解决上述挑战。&lt;h4&gt;方法&lt;/h4&gt;HOMAE采用了一种目标聚焦的掩码策略，对手-物体交互区域施加结构化遮挡，鼓励模型学习上下文感知特征并推理遮挡结构。此外，它还整合了从解码器提取的多尺度特征来预测有符号距离场（SDF），捕捉全局上下文和精细几何。为了增强几何感知，将隐式SDF与从SDF导出的显式点云相结合，利用两种表示的互补优势。这种融合通过结合SDF的全局上下文和点云提供的精确局部几何来更稳健地处理遮挡区域。&lt;h4&gt;主要发现&lt;/h4&gt;在具有挑战性的DexYCB和HO3Dv2基准数据集上进行的广泛实验表明，HOMAE在手-物体姿态估计方面实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;HOMAE方法有效地解决了手-物体姿态估计中的遮挡问题，并将代码和模型公开。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从单目RGB图像中进行手-物体姿态估计仍然是一个重大挑战，主要由于手-物体交互中固有的严重遮挡。现有方法没有充分探索全局结构感知和推理，这限制了它们处理遮挡手-物体交互的有效性。为了应对这一挑战，我们提出了一种基于掩码自动编码器的遮挡感知手-物体姿态估计方法，称为HOMAE。具体而言，我们提出了一种目标聚焦的掩码策略，对手-物体交互区域施加结构化遮挡，鼓励模型学习上下文感知特征并推理遮挡结构。我们进一步整合了从解码器提取的多尺度特征来预测有符号距离场（SDF），捕捉全局上下文和精细几何。为了增强几何感知，我们将隐式SDF与从SDF导出的显式点云相结合，利用两种表示的互补优势。这种融合通过结合SDF的全局上下文和点云提供的精确局部几何来更稳健地处理遮挡区域。在具有挑战性的DexYCB和HO3Dv2基准数据集上进行的广泛实验表明，HOMAE在手-物体姿态估计方面实现了最先进的性能。我们将发布我们的代码和模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hand-object pose estimation from monocular RGB images remains a significantchallenge mainly due to the severe occlusions inherent in hand-objectinteractions. Existing methods do not sufficiently explore global structuralperception and reasoning, which limits their effectiveness in handling occludedhand-object interactions. To address this challenge, we propose anocclusion-aware hand-object pose estimation method based on maskedautoencoders, termed as HOMAE. Specifically, we propose a target-focusedmasking strategy that imposes structured occlusion on regions of hand-objectinteraction, encouraging the model to learn context-aware features and reasonabout the occluded structures. We further integrate multi-scale featuresextracted from the decoder to predict a signed distance field (SDF), capturingboth global context and fine-grained geometry. To enhance geometric perception,we combine the implicit SDF with an explicit point cloud derived from the SDF,leveraging the complementary strengths of both representations. This fusionenables more robust handling of occluded regions by combining the globalcontext from the SDF with the precise local geometry provided by the pointcloud. Extensive experiments on challenging DexYCB and HO3Dv2 benchmarksdemonstrate that HOMAE achieves state-of-the-art performance in hand-objectpose estimation. We will release our code and model.</description>
      <author>example@mail.com (Hui Yang, Wei Sun, Jian Liu, Jin Zheng, Jian Xiao, Ajmal Mian)</author>
      <guid isPermaLink="false">2506.10816v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Matrix Completion with Denoising and Augmented Graph Views for Robust Recommendation</title>
      <link>http://arxiv.org/abs/2506.10658v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Matrix Completion using Contrastive Learning (MCCL)的新方法，用于推荐系统中的矩阵补全，该方法通过对比学习提高了模型的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;矩阵补全在推荐系统中广泛应用，但基于图神经网络的当前方法对噪声或不相关边敏感，容易过拟合，限制了其泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出MCCL方法以克服现有方法的局限性，提高推荐系统的准确性。&lt;h4&gt;方法&lt;/h4&gt;MCCL方法首先为每个交互提取局部邻域子图，然后生成两种不同的图表示。第一种表示通过结合GNN层和注意力机制强调去噪，第二种通过图变分自动编码器对特征分布与标准先验进行对齐。在训练过程中使用互学习损失函数来逐步协调这些表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，MCCL方法不仅提高了预测评分的数值准确性（RMSE改善高达0.8%），而且在排名指标上也有显著提升，排名改善高达36%。&lt;h4&gt;结论&lt;/h4&gt;MCCL方法通过对比学习显著提高了推荐系统的泛化能力和预测准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：矩阵补全是在推荐系统中广泛采用的一种框架，通过预测用户-物品评分矩阵中的缺失项，可以全面理解用户偏好。然而，当前基于图神经网络（GNN）的方法对噪声或不相关边非常敏感——由于它们固有的消息传递机制——并且容易过拟合，这限制了它们的泛化能力。为了克服这些挑战，我们提出了一种名为矩阵补全对比学习（MCCL）的新方法。我们的方法首先为每个交互提取局部邻域子图，然后生成两种不同的图表示。第一种表示通过结合GNN层和注意力机制强调去噪，第二种通过图变分自动编码器将特征分布与标准先验对齐。在训练过程中使用互学习损失函数来逐步协调这些表示，使模型能够捕获共同模式并显著提高其泛化能力。在多个真实世界数据集上的大量实验表明，我们的方法不仅提高了预测评分的数值准确性——RMSE改善高达0.8%——而且还产生了更好的排名，排名指标改善高达36%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Matrix completion is a widely adopted framework in recommender systems, aspredicting the missing entries in the user-item rating matrix enables acomprehensive understanding of user preferences. However, current graph neuralnetwork (GNN)-based approaches are highly sensitive to noisy or irrelevantedges--due to their inherent message-passing mechanisms--and are prone tooverfitting, which limits their generalizability. To overcome these challenges,we propose a novel method called Matrix Completion using Contrastive Learning(MCCL). Our approach begins by extracting local neighborhood subgraphs for eachinteraction and subsequently generates two distinct graph representations. Thefirst representation emphasizes denoising by integrating GNN layers with anattention mechanism, while the second is obtained via a graph variationalautoencoder that aligns the feature distribution with a standard prior. Amutual learning loss function is employed during training to graduallyharmonize these representations, enabling the model to capture common patternsand significantly enhance its generalizability. Extensive experiments onseveral real-world datasets demonstrate that our approach not only improves thenumerical accuracy of the predicted scores--achieving up to a 0.8% improvementin RMSE--but also produces superior rankings with improvements of up to 36% inranking metrics.</description>
      <author>example@mail.com (Narges Nemati, Mostafa Haghir Chehreghani)</author>
      <guid isPermaLink="false">2506.10658v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Automatic Addition of Optimizing Components in Printed Circuit Board Schematics</title>
      <link>http://arxiv.org/abs/2506.10577v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过将组件表示为二分图并利用基于图神经网络（GNN）的节点对预测模型来自动化PCB图优化的方法。&lt;h4&gt;背景&lt;/h4&gt;优化PCB图对于开发高质量的电子设备至关重要，但缺乏熟练工程师和手动优化耗时，导致最佳实践常被忽视，进而增加了后期开发阶段的故障排除成本和产品生命周期缩短，导致难以回收的电子废物增加。&lt;h4&gt;目的&lt;/h4&gt;自动化PCB图优化，提高电路的鲁棒性和可靠性，降低成本和缩短开发时间。&lt;h4&gt;方法&lt;/h4&gt;将组件表示为二分图，利用GNN节点对预测模型自动添加新组件到PCB图中，并将该方法应用于三个相关的PCB设计优化任务，比较了多个流行的GNN架构在标注数据集上的性能。&lt;h4&gt;主要发现&lt;/h4&gt;GNN可以以高精度解决这些问题，并且该方法有望以时间和成本效益的方式自动化PCB设计优化。&lt;h4&gt;结论&lt;/h4&gt;提出的基于GNN的PCB图自动化优化方法有效且具有潜力，可以显著提高PCB设计的效率和产品质量。&lt;h4&gt;翻译&lt;/h4&gt;The design and optimization of Printed Circuit Board (PCB) schematics is crucial for the development of high-quality electronic devices. Thereby, an important task is to optimize drafts by adding components that improve the robustness and reliability of the circuit, e.g., pull-up resistors or decoupling capacitors. Since there is a shortage of skilled engineers and manual optimizations are very time-consuming, these best practices are often neglected. However, this typically leads to higher costs for troubleshooting in later development stages as well as shortened product life cycles, resulting in an increased amount of electronic waste that is difficult to recycle. Here, we present an approach for automating the addition of new components into PCB schematics by representing them as bipartite graphs and utilizing a node pair prediction model based on Graph Neural Networks (GNNs). We apply our approach to three highly relevant PCB design optimization tasks and compare the performance of several popular GNN architectures on real-world datasets labeled by human experts. We show that GNNs can solve these problems with high accuracy and demonstrate that our approach offers the potential to automate PCB design optimizations in a time- and cost-efficient manner.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The design and optimization of Printed Circuit Board (PCB) schematics iscrucial for the development of high-quality electronic devices. Thereby, animportant task is to optimize drafts by adding components that improve therobustness and reliability of the circuit, e.g., pull-up resistors ordecoupling capacitors. Since there is a shortage of skilled engineers andmanual optimizations are very time-consuming, these best practices are oftenneglected. However, this typically leads to higher costs for troubleshooting inlater development stages as well as shortened product life cycles, resulting inan increased amount of electronic waste that is difficult to recycle. Here, wepresent an approach for automating the addition of new components into PCBschematics by representing them as bipartite graphs and utilizing a node pairprediction model based on Graph Neural Networks (GNNs). We apply our approachto three highly relevant PCB design optimization tasks and compare theperformance of several popular GNN architectures on real-world datasets labeledby human experts. We show that GNNs can solve these problems with high accuracyand demonstrate that our approach offers the potential to automate PCB designoptimizations in a time- and cost-efficient manner.</description>
      <author>example@mail.com (Pascal Plettenberg, André Alcalde, Bernhard Sick, Josephine M. Thomas)</author>
      <guid isPermaLink="false">2506.10577v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>FairASR: Fair Audio Contrastive Learning for Automatic Speech Recognition</title>
      <link>http://arxiv.org/abs/2506.10747v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Interspeech2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了FairASR系统，该系统能够通过学习不包含群体成员信息的表征来减少人口统计学偏见，从而实现公平的跨群体泛化。&lt;h4&gt;背景&lt;/h4&gt;大规模语音识别模型在准确性和鲁棒性方面取得了显著进步，但在实际应用中，公平性问题尚未得到充分解决。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一个系统，减少语音识别模型在人口统计学群体间的性能差异。&lt;h4&gt;方法&lt;/h4&gt;FairASR系统利用多人口统计学数据集，通过梯度反转层抑制具有人口统计学歧视性的特征，同时通过无监督对比损失来捕捉可泛化的语音模式。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，FairASR在总体语音识别性能上具有竞争力，同时显著减少了不同人口统计学群体间的性能差异。&lt;h4&gt;结论&lt;/h4&gt;FairASR系统在保持良好语音识别性能的同时，有效地解决了模型在不同群体间的公平性问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale ASR models have achieved remarkable gains in accuracy androbustness. However, fairness issues remain largely unaddressed despite theircritical importance in real-world applications. In this work, we introduceFairASR, a system that mitigates demographic bias by learning representationsthat are uninformative about group membership, enabling fair generalizationacross demographic groups. Leveraging a multi-demographic dataset, our approachemploys a gradient reversal layer to suppress demographic-discriminativefeatures while maintaining the ability to capture generalizable speech patternsthrough an unsupervised contrastive loss. Experimental results show thatFairASR delivers competitive overall ASR performance while significantlyreducing performance disparities across different demographic groups.</description>
      <author>example@mail.com (Jongsuk Kim, Jaemyung Yu, Minchan Kwon, Junmo Kim)</author>
      <guid isPermaLink="false">2506.10747v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>ECAM: A Contrastive Learning Approach to Avoid Environmental Collision in Trajectory Forecasting</title>
      <link>http://arxiv.org/abs/2506.09626v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IJCNN 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于对比学习的环境碰撞避免模块ECAM，用于提升轨迹预测模型的碰撞避免能力。&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶、机器人和监控等应用中，人类轨迹预测至关重要。准确的预测需要模型考虑多种因素，包括社会互动、多模态预测、行人意图和环境背景。&lt;h4&gt;目的&lt;/h4&gt;提高轨迹预测模型在生成无碰撞预测方面的能力。&lt;h4&gt;方法&lt;/h4&gt;ECAM模块通过对比学习增强模型的环境碰撞避免能力，并可以集成到现有的轨迹预测模型中。&lt;h4&gt;主要发现&lt;/h4&gt;在ETH/UCY数据集上评估，ECAM模块显著降低了（-40/50%）碰撞率，证明了其在碰撞避免方面的能力。&lt;h4&gt;结论&lt;/h4&gt;ECAM模块能够有效提高轨迹预测模型的碰撞避免能力，并显著降低碰撞率。&lt;h4&gt;翻译&lt;/h4&gt;Human trajectory forecasting is crucial in applications such as autonomous driving, robotics and surveillance. Accurate forecasting requires models to consider various factors, including social interactions, multi-modal predictions, pedestrian intention and environmental context. While existing methods account for these factors, they often overlook the impact of the environment, which leads to collisions with obstacles. This paper introduces ECAM (Environmental Collision Avoidance Module), a contrastive learning-based module to enhance collision avoidance ability with the environment. The proposed module can be integrated into existing trajectory forecasting models, improving their ability to generate collision-free predictions. We evaluate our method on the ETH/UCY dataset and quantitatively and qualitatively demonstrate its collision avoidance capabilities. Our experiments show that state-of-the-art methods significantly reduce (-40/50%) the collision rate when integrated with the proposed module. The code is available at https://github.com/CVML-CFU/ECAM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human trajectory forecasting is crucial in applications such as autonomousdriving, robotics and surveillance. Accurate forecasting requires models toconsider various factors, including social interactions, multi-modalpredictions, pedestrian intention and environmental context. While existingmethods account for these factors, they often overlook the impact of theenvironment, which leads to collisions with obstacles. This paper introducesECAM (Environmental Collision Avoidance Module), a contrastive learning-basedmodule to enhance collision avoidance ability with the environment. Theproposed module can be integrated into existing trajectory forecasting models,improving their ability to generate collision-free predictions. We evaluate ourmethod on the ETH/UCY dataset and quantitatively and qualitatively demonstrateits collision avoidance capabilities. Our experiments show thatstate-of-the-art methods significantly reduce (-40/50%) the collision rate whenintegrated with the proposed module. The code is available athttps://github.com/CVML-CFU/ECAM.</description>
      <author>example@mail.com (Giacomo Rosin, Muhammad Rameez Ur Rahman, Sebastiano Vascon)</author>
      <guid isPermaLink="false">2506.09626v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>VRBench: A Benchmark for Multi-Step Reasoning in Long Narrative Videos</title>
      <link>http://arxiv.org/abs/2506.10857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了VRBench，这是第一个用于评估大型模型多步推理能力的长篇叙事视频基准，解决了现有评估中忽视时间推理和程序有效性的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的评估方法未能充分考虑时间推理和程序的有效性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够评估大型模型多步推理能力的视频基准。&lt;h4&gt;方法&lt;/h4&gt;VRBench包含1,010个长视频，每个视频平均时长为1.6小时，以及9,468个人工标注的多步问答对和30,292个带时间戳的推理步骤。视频通过多阶段筛选过程进行整理，包括专家互评以优先考虑情节连贯性。开发了一个人类-人工智能协作框架，生成需要多个时间上定位的推理链，涵盖七种类型（例如，事件归因、隐含推理）。VRBench设计了一个多阶段评估流程，评估模型在结果和过程两个层面。&lt;h4&gt;主要发现&lt;/h4&gt;通过在VRBench上对12个大型语言模型和16个视觉语言模型进行广泛评估，进行了详细分析，并提供了有价值见解，推动了多步推理领域的发展。&lt;h4&gt;结论&lt;/h4&gt;VRBench为多步推理能力的评估提供了一个新的基准，有助于推动该领域的研究进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present VRBench, the first long narrative video benchmark crafted forevaluating large models' multi-step reasoning capabilities, addressinglimitations in existing evaluations that overlook temporal reasoning andprocedural validity. It comprises 1,010 long videos (with an average durationof 1.6 hours), along with 9,468 human-labeled multi-step question-answeringpairs and 30,292 reasoning steps with timestamps. These videos are curated viaa multi-stage filtering process including expert inter-rater reviewing toprioritize plot coherence. We develop a human-AI collaborative framework thatgenerates coherent reasoning chains, each requiring multiple temporallygrounded steps, spanning seven types (e.g., event attribution, implicitinference). VRBench designs a multi-phase evaluation pipeline that assessesmodels at both the outcome and process levels. Apart from the MCQs for thefinal results, we propose a progress-level LLM-guided scoring metric toevaluate the quality of the reasoning chain from multiple dimensionscomprehensively. Through extensive evaluations of 12 LLMs and 16 VLMs onVRBench, we undertake a thorough analysis and provide valuable insights thatadvance the field of multi-step reasoning.</description>
      <author>example@mail.com (Jiashuo Yu, Yue Wu, Meng Chu, Zhifei Ren, Zizheng Huang, Pei Chu, Ruijie Zhang, Yinan He, Qirui Li, Songze Li, Zhenxiang Li, Zhongying Tu, Conghui He, Yu Qiao, Yali Wang, Yi Wang, Limin Wang)</author>
      <guid isPermaLink="false">2506.10857v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>SceneCompleter: Dense 3D Scene Completion for Generative Novel View Synthesis</title>
      <link>http://arxiv.org/abs/2506.10981v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SceneCompleter是一个新型框架，通过密集的3D场景补全实现3D一致性的生成新视角合成，有效提高了生成新视角合成的视觉一致性和3D一致性。&lt;h4&gt;背景&lt;/h4&gt;现有的生成模型在新视角合成(NVS)中依赖密集的多视角捕捉，但通常会导致表面过于平滑和几何扭曲，因为生成模型难以从RGB数据中推断3D结构。&lt;h4&gt;目的&lt;/h4&gt;提出SceneCompleter框架，旨在通过3D场景补全实现3D一致性的生成新视角合成。&lt;h4&gt;方法&lt;/h4&gt;SceneCompleter通过两个关键组件实现：(1)一个几何-外观双重流扩散模型，在RGBD空间中联合合成新视角；(2)一个场景嵌入器，从参考图像中编码更全面的场景理解。&lt;h4&gt;主要发现&lt;/h4&gt;通过有效融合结构和纹理信息，该方法在多种数据集上展示了在生成新视角合成中的优越一致性和可信度。&lt;h4&gt;结论&lt;/h4&gt;SceneCompleter框架在生成新视角合成中提供了一种新的方法，能够实现更加真实和一致的3D场景重建。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative models have gained significant attention in novel view synthesis(NVS) by alleviating the reliance on dense multi-view captures. However,existing methods typically fall into a conventional paradigm, where generativemodels first complete missing areas in 2D, followed by 3D recovery techniquesto reconstruct the scene, which often results in overly smooth surfaces anddistorted geometry, as generative models struggle to infer 3D structure solelyfrom RGB data. In this paper, we propose SceneCompleter, a novel framework thatachieves 3D-consistent generative novel view synthesis through dense 3D scenecompletion. SceneCompleter achieves both visual coherence and 3D-consistentgenerative scene completion through two key components: (1) ageometry-appearance dual-stream diffusion model that jointly synthesizes novelviews in RGBD space; (2) a scene embedder that encodes a more holistic sceneunderstanding from the reference image. By effectively fusing structural andtextural information, our method demonstrates superior coherence andplausibility in generative novel view synthesis across diverse datasets.Project Page: https://chen-wl20.github.io/SceneCompleter</description>
      <author>example@mail.com (Weiliang Chen, Jiayi Bi, Yuanhui Huang, Wenzhao Zheng, Yueqi Duan)</author>
      <guid isPermaLink="false">2506.10981v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>VideoDeepResearch: Long Video Understanding With Agentic Tool Using</title>
      <link>http://arxiv.org/abs/2506.10821v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为VideoDeepResearch的新型框架，用于解决长视频理解（LVU）的挑战，并通过实验证明其在多个LVU基准测试中优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;长视频理解对当前的多模态大型语言模型（MLLMs）来说是一个重大挑战，因为它本身具有复杂性以及上下文窗口的限制。&lt;h4&gt;目的&lt;/h4&gt;挑战传统观点，即解决LVU任务需要具有扩展上下文窗口、强大视觉感知能力和专业领域知识的MLLM。&lt;h4&gt;方法&lt;/h4&gt;VideoDeepResearch框架仅使用纯文本的大型推理模型（LRM）和模块化的多模态工具包，包括多模态检索器和视觉感知器。&lt;h4&gt;主要发现&lt;/h4&gt;VideoDeepResearch在多个LVU基准测试中取得了显著改进，分别在MLVU、LVBench和LongVideoBench上超越了之前的最先进水平，提升分别为9.6%、6.6%和3.9%。&lt;h4&gt;结论&lt;/h4&gt;这些发现突显了代理系统在克服LVU问题中的关键挑战方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel framework called VideoDeepResearch for addressing the challenges of Long Video Understanding (LVU), and demonstrates through experiments that it outperforms existing methods in multiple LVU benchmarks. The background is that LVU presents a significant challenge for current multi-modal large language models (MLLMs) due to its inherent complexity and context window constraints. The purpose is to challenge the common belief that solving LVU tasks requires foundation MLLMs with extended context windows, strong visual perception capabilities, and proficient domain expertise. The method is to use a text-only large reasoning model (LRM) and a modular multi-modal toolkit, including multimodal retrievers and visual perceivers, for the VideoDeepResearch framework. The key findings are that VideoDeepResearch achieves substantial improvements over existing MLLM baselines, surpassing the previous state-of-the-art by 9.6%, 6.6%, and 3.9% on MLVU (test), LVBench, and LongVideoBench, respectively. The conclusion is that these findings highlight the promise of agent-based systems in overcoming key challenges in LVU problems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long video understanding (LVU) presents a significant challenge for currentmulti-modal large language models (MLLMs) due to the task's inherent complexityand context window constraint. It is widely assumed that addressing LVU tasksrequires foundation MLLMs with extended context windows, strong visualperception capabilities, and proficient domain expertise. In this work, wechallenge this common belief by introducing VideoDeepResearch, a novel agenticframework for long video understanding. Our approach relies solely on atext-only large reasoning model (LRM) combined with a modular multi-modaltoolkit, including multimodal retrievers and visual perceivers, all of whichare readily available in practice. For each LVU task, the system formulates aproblem-solving strategy through reasoning, while selectively accessing andutilizing essential video content via tool using. We conduct extensiveexperiments on popular LVU benchmarks, including MLVU, Video-MME, and LVBench.Our results demonstrate that VideoDeepResearch achieves substantialimprovements over existing MLLM baselines, surpassing the previousstate-of-the-art by 9.6%, 6.6%, and 3.9% on MLVU (test), LVBench, andLongVideoBench, respectively. These findings highlight the promise of agenticsystems in overcoming key challenges in LVU problems.</description>
      <author>example@mail.com (Huaying Yuan, Zheng Liu, Junjie Zhou, Ji-Rong Wen, Zhicheng Dou)</author>
      <guid isPermaLink="false">2506.10821v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos</title>
      <link>http://arxiv.org/abs/2506.10242v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025 Workshop on Autonomous Driving&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DySS的新方法，用于基于相机视角的3D物体检测，该方法在自动驾驶中具有重要作用。DySS结合了状态空间学习与动态查询技术，在保持检测性能的同时提高了推理效率。&lt;h4&gt;背景&lt;/h4&gt;传统的基于密集BEV特征的3D物体检测方法成本高昂，而基于稀疏查询的方法虽然近期有所研究，但仍然需要大量查询，运行成本较高。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法DySS，以提高3D物体检测的效率和性能。&lt;h4&gt;方法&lt;/h4&gt;DySS利用状态空间模型（SSM）对样本特征进行顺序处理，并通过未来预测和掩码重建等辅助任务来训练SSM，以更好地捕捉运动和对应信息。基于SSM的状态，动态更新查询，通过合并、删除和分割操作来维护一个有用且精简的检测查询集。&lt;h4&gt;主要发现&lt;/h4&gt;DySS在nuScenes测试集上实现了65.31 NDS和57.4 mAP的性能，优于现有最佳方法。在验证集上，DySS达到了56.2 NDS和46.2 mAP，同时保持了33 FPS的实时推理速度。&lt;h4&gt;结论&lt;/h4&gt;DySS是一种高效且性能优异的3D物体检测方法，适用于自动驾驶场景。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于相机视角的Bird's Eye View（BEV）3D物体检测是自动驾驶中最关键的感知任务之一。早期方法依赖于密集的BEV特征，构建成本高昂。近期的研究探索了基于稀疏查询的检测方法。然而，它们仍然需要大量的查询，并且当使用更多的视频帧时，运行成本可能变得高昂。在本文中，我们提出了一种名为DySS的新方法，它采用了状态空间学习和动态查询。具体来说，DySS利用状态空间模型（SSM）按时间步骤顺序处理样本特征。为了鼓励模型更好地捕捉潜在的移动和对应信息，我们引入了未来预测和掩码重建的辅助任务来更好地训练SSM。SSM的状态随后提供了有关场景的有用而高效的总结。基于状态空间学习到的特征，我们通过合并、删除和分割操作动态更新查询，这有助于在整个网络中保持一个有用且精简的检测查询集。我们提出的DySS实现了卓越的检测性能和高效的推理。具体而言，在nuScenes测试集上，DySS实现了65.31 NDS和57.4 mAP，优于现有最佳水平。在验证集上，DySS实现了56.2 NDS和46.2 mAP，以及33 FPS的实时推理速度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Camera-based 3D object detection in Bird's Eye View (BEV) is one of the mostimportant perception tasks in autonomous driving. Earlier methods rely on denseBEV features, which are costly to construct. More recent works explore sparsequery-based detection. However, they still require a large number of queriesand can become expensive to run when more video frames are used. In this paper,we propose DySS, a novel method that employs state-space learning and dynamicqueries. More specifically, DySS leverages a state-space model (SSM) tosequentially process the sampled features over time steps. In order toencourage the model to better capture the underlying motion and correspondenceinformation, we introduce auxiliary tasks of future prediction and maskedreconstruction to better train the SSM. The state of the SSM then provides aninformative yet efficient summarization of the scene. Based on the state-spacelearned features, we dynamically update the queries via merge, remove, andsplit operations, which help maintain a useful, lean set of detection queriesthroughout the network. Our proposed DySS achieves both superior detectionperformance and efficient inference. Specifically, on the nuScenes test split,DySS achieves 65.31 NDS and 57.4 mAP, outperforming the latest state of theart. On the val split, DySS achieves 56.2 NDS and 46.2 mAP, as well as areal-time inference speed of 33 FPS.</description>
      <author>example@mail.com (Rajeev Yasarla, Shizhong Han, Hong Cai, Fatih Porikli)</author>
      <guid isPermaLink="false">2506.10242v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>LightKG: Efficient Knowledge-Aware Recommendations with Simplified GNN Architecture</title>
      <link>http://arxiv.org/abs/2506.10347v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery  and Data Mining&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的知识图谱推荐系统LightKG，旨在解决稀疏性问题，并提高推荐准确率。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）在知识图谱推荐系统（KGRS）中表现出色，但自监督学习（SSL）的引入导致训练时间延长。&lt;h4&gt;目的&lt;/h4&gt;提出LightKG以解决稀疏性问题，同时提高推荐准确率和减少训练时间。&lt;h4&gt;方法&lt;/h4&gt;LightKG使用简化的GNN层，将关系编码为标量对，并采用线性聚合框架。此外，它还包含一个高效的对比层来实现自监督学习。&lt;h4&gt;主要发现&lt;/h4&gt;现有的基于GNN的KGRS在稀疏交互下即使结合SSL也未能保持其优越性能；更复杂的模型在稀疏交互场景中表现更差；注意力机制等复杂机制可能有害，因为它们通常会增加学习难度。&lt;h4&gt;结论&lt;/h4&gt;LightKG在稀疏和密集场景中都优于12个竞争性的KGRS，同时显著减少了训练时间。与带有SSL的KGRS相比，它在推荐准确率上平均提高了5.8%，并节省了84.3%的训练时间。&lt;h4&gt;翻译&lt;/h4&gt;最近，图神经网络（GNN）因其有效性而成为知识图谱感知推荐系统（KGRS）的主流方法。在基于GNN的KGRS的基础上，自监督学习（SSL）已被纳入以解决稀疏性问题，导致训练时间更长。然而，通过广泛的实验，我们发现：（1）与其他KGRS相比，现有的基于GNN的KGRS即使在结合SSL的情况下也无法在稀疏交互下保持其优越性能。（2）更复杂的模型在稀疏交互场景中往往表现更差，并且复杂的机制，如注意力机制，可能是有害的，因为它们通常会增加学习难度。受这些发现的启发，我们提出了一种简单的但功能强大的基于GNN的KGRS，称为LightKG，以解决稀疏性问题。LightKG包含一个简化的GNN层，将有向关系编码为标量对，并采用线性聚合框架，大大降低了GNN的复杂性。此外，LightKG还包含一个高效的对比层来实现自监督学习。它直接最小化原始图中的节点相似度，避免了先前SSL方法中所需的时间消耗较大的子图生成和比较。在四个基准数据集上的实验表明，LightKG在稀疏和密集场景中都优于12个竞争性的KGRS，同时显著减少了训练时间。具体来说，它在推荐准确率上平均超过了最佳基线5.8%，与带有SSL的KGRS相比，节省了84.3%的训练时间。我们的代码可在https://github.com/1371149/LightKG获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737026&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Graph Neural Networks (GNNs) have become the dominant approach forKnowledge Graph-aware Recommender Systems (KGRSs) due to their proveneffectiveness. Building upon GNN-based KGRSs, Self-Supervised Learning (SSL)has been incorporated to address the sparity issue, leading to longer trainingtime. However, through extensive experiments, we reveal that: (1)compared toother KGRSs, the existing GNN-based KGRSs fail to keep their superiorperformance under sparse interactions even with SSL. (2) More complex modelstend to perform worse in sparse interaction scenarios and complex mechanisms,like attention mechanism, can be detrimental as they often increase learningdifficulty. Inspired by these findings, we propose LightKG, a simple yetpowerful GNN-based KGRS to address sparsity issues. LightKG includes asimplified GNN layer that encodes directed relations as scalar pairs ratherthan dense embeddings and employs a linear aggregation framework, greatlyreducing the complexity of GNNs. Additionally, LightKG incorporates anefficient contrastive layer to implement SSL. It directly minimizes the nodesimilarity in original graph, avoiding the time-consuming subgraph generationand comparison required in previous SSL methods. Experiments on four benchmarkdatasets show that LightKG outperforms 12 competitive KGRSs in both sparse anddense scenarios while significantly reducing training time. Specifically, itsurpasses the best baselines by an average of 5.8\% in recommendation accuracyand saves 84.3\% of training time compared to KGRSs with SSL. Our code isavailable at https://github.com/1371149/LightKG.</description>
      <author>example@mail.com (Yanhui Li, Dongxia Wang, Zhu Sun, Haonan Zhang, Huizhong Guo)</author>
      <guid isPermaLink="false">2506.10347v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>PiPViT: Patch-based Visual Interpretable Prototypes for Retinal Image Analysis</title>
      <link>http://arxiv.org/abs/2506.10669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PiPViT是一种基于图像的视觉可解释原型模型，用于图像识别，能够提高原型在医学影像中的可解释性，并有效定位生物标志物。&lt;h4&gt;背景&lt;/h4&gt;原型方法通过学习细粒度部分原型提高可解释性，但其输入像素空间中的可视化不总是与人类可理解的生物标志物一致。&lt;h4&gt;目的&lt;/h4&gt;提出PiPViT模型，以解决原型方法在医学影像中的可解释性问题，并提高生物标志物的定位。&lt;h4&gt;方法&lt;/h4&gt;PiPViT利用视觉变压器(ViT)捕获补丁之间的长距离依赖关系，学习鲁棒且人类可解释的原型，仅使用图像级标签来近似病变范围。此外，PiPViT受益于对比学习和多分辨率输入处理，能够在不同尺度上有效定位生物标志物。&lt;h4&gt;主要发现&lt;/h4&gt;在四个数据集上对PiPViT进行评估，其性能与最先进的方法相当，同时提供了更有意义的解释。对保留测试集的定量评估确认了学习到的原型在语义和临床上是相关的。&lt;h4&gt;结论&lt;/h4&gt;PiPViT能够透明地解释其决策，并帮助临床医生理解诊断结果。&lt;h4&gt;翻译&lt;/h4&gt;PiPViT (Patch-based Visual Interpretable Prototypes) 是一种基于图像的视觉可解释原型模型，用于图像识别。该方法利用视觉变压器（ViT）捕捉补丁之间的长距离依赖关系，学习鲁棒且人类可解释的原型，仅使用图像级标签来近似病变范围。此外，PiPViT受益于对比学习和多分辨率输入处理，能够在不同尺度上有效定位生物标志物。在四个数据集上对PiPViT进行评估，其性能与最先进的方法相当，同时提供了更有意义的解释。对保留测试集的定量评估确认了学习到的原型在语义和临床上是相关的。我们相信PiPViT能够透明地解释其决策，并帮助临床医生理解诊断结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Background and Objective: Prototype-based methods improve interpretability bylearning fine-grained part-prototypes; however, their visualization in theinput pixel space is not always consistent with human-understandablebiomarkers. In addition, well-known prototype-based approaches typically learnextremely granular prototypes that are less interpretable in medical imaging,where both the presence and extent of biomarkers and lesions are critical.  Methods: To address these challenges, we propose PiPViT (Patch-based VisualInterpretable Prototypes), an inherently interpretable prototypical model forimage recognition. Leveraging a vision transformer (ViT), PiPViT captureslong-range dependencies among patches to learn robust, human-interpretableprototypes that approximate lesion extent only using image-level labels.Additionally, PiPViT benefits from contrastive learning and multi-resolutioninput processing, which enables effective localization of biomarkers acrossscales.  Results: We evaluated PiPViT on retinal OCT image classification across fourdatasets, where it achieved competitive quantitative performance compared tostate-of-the-art methods while delivering more meaningful explanations.Moreover, quantitative evaluation on a hold-out test set confirms that thelearned prototypes are semantically and clinically relevant. We believe PiPViTcan transparently explain its decisions and assist clinicians in understandingdiagnostic outcomes. Github page: https://github.com/marziehoghbaie/PiPViT</description>
      <author>example@mail.com (Marzieh Oghbaie, Teresa Araújoa, Hrvoje Bogunović)</author>
      <guid isPermaLink="false">2506.10669v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Tightly-Coupled LiDAR-IMU-Leg Odometry with Online Learned Leg Kinematics Incorporating Foot Tactile Information</title>
      <link>http://arxiv.org/abs/2506.09548v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Robotics and Automation Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种紧密耦合的激光雷达-惯性测量单元-腿部里程计，该方法在无特征环境、可变形地形等恶劣条件下具有鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;针对无特征环境和可变形地形等挑战性条件，提出了基于在线学习的腿部运动学模型。&lt;h4&gt;目的&lt;/h4&gt;提高机器人对重量负载变化和地形条件的适应性，并实现里程计估计的准确性。&lt;h4&gt;方法&lt;/h4&gt;开发了名为神经腿部运动学模型的在线学习模型，该模型结合触觉信息（脚部反作用力）来隐式表达机器人脚与地面之间的非线性动力学。通过联合解决运动学模型的在线训练和里程计估计，以保持两者的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，结合神经腿部运动学模型的里程计估计优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;该方法在两个具有挑战性的场景中得到了验证，包括沙海滩和校园环境，显示了其在不同地形下的有效性。&lt;h4&gt;翻译&lt;/h4&gt;In this letter, we present tightly coupled LiDAR-IMU-leg odometry, which is robust to challenging conditions such as featureless environments and deformable terrains. We developed an online learning-based leg kinematics model named the neural leg kinematics model, which incorporates tactile information (foot reaction force) to implicitly express the nonlinear dynamics between robot feet and the ground. Online training of this model enhances its adaptability to weight load changes of a robot (e.g., assuming delivery or transportation tasks) and terrain conditions. According to the extit{neural adaptive leg odometry factor} and online uncertainty estimation of the leg kinematics model-based motion predictions, we jointly solve online training of this kinematics model and odometry estimation on a unified factor graph to retain the consistency of both. The proposed method was verified through real experiments using a quadruped robot in two challenging situations: 1) a sandy beach, representing an extremely featureless area with a deformable terrain, and 2) a campus, including multiple featureless areas and terrain types of asphalt, gravel (deformable terrain), and grass. Experimental results showed that our odometry estimation incorporating the extit{neural leg kinematics model} outperforms state-of-the-art works. Our project page is available for further details: https://takuokawara.github.io/RAL2025_project_page/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this letter, we present tightly coupled LiDAR-IMU-leg odometry, which isrobust to challenging conditions such as featureless environments anddeformable terrains. We developed an online learning-based leg kinematics modelnamed the neural leg kinematics model, which incorporates tactile information(foot reaction force) to implicitly express the nonlinear dynamics betweenrobot feet and the ground. Online training of this model enhances itsadaptability to weight load changes of a robot (e.g., assuming delivery ortransportation tasks) and terrain conditions. According to the \textit{neuraladaptive leg odometry factor} and online uncertainty estimation of the legkinematics model-based motion predictions, we jointly solve online training ofthis kinematics model and odometry estimation on a unified factor graph toretain the consistency of both. The proposed method was verified through realexperiments using a quadruped robot in two challenging situations: 1) a sandybeach, representing an extremely featureless area with a deformable terrain,and 2) a campus, including multiple featureless areas and terrain types ofasphalt, gravel (deformable terrain), and grass. Experimental results showedthat our odometry estimation incorporating the \textit{neural leg kinematicsmodel} outperforms state-of-the-art works. Our project page is available forfurther details: https://takuokawara.github.io/RAL2025_project_page/</description>
      <author>example@mail.com (Taku Okawara, Kenji Koide, Aoki Takanose, Shuji Oishi, Masashi Yokozuka, Kentaro Uno, Kazuya Yoshida)</author>
      <guid isPermaLink="false">2506.09548v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>General Reference Frame Identification and Transformation in Unbalanced Power Systems</title>
      <link>http://arxiv.org/abs/2506.10835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种基于几何框架的坐标变换新方法，该方法通过使用几何代数中的双矢量分析直接识别不平衡量的轨迹所在平面，显著降低了问题的复杂性。&lt;h4&gt;背景&lt;/h4&gt;坐标变换在电力系统稳定性分析、电机建模和电力电子转换器控制等领域得到了广泛应用，其主要优势在于降维。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的通用变换方法，适用于任何程度的$n$相$(n+1)$线正弦系统的不平衡。&lt;h4&gt;方法&lt;/h4&gt;该方法使用几何代数进行双矢量分析，通过在不同时间瞬间进行两个测量（电压或电流）来实现。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过纯几何推理证明是通用的，并包括其他技术，如经典的Clarke变换。数值模拟和实验验证了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法在多维度系统中的应用以及减少的测量要求，相对于现有的通常限于三相应用或受限于计算方法的现有方法，代表了一个重大的进步。&lt;h4&gt;翻译&lt;/h4&gt;摘要：各个领域，如电力系统稳定性分析、电机建模和电力电子转换器控制，都极大地受益于坐标变换的应用。其中一个主要的好处是降维，这降低了问题的复杂性。本文介绍了一种基于几何框架的新颖通用变换，它通过使用几何代数中的双矢量分析直接识别不平衡量轨迹所在的平面。所提出的方法为任何程度的$n$相$(n+1)$线正弦系统的不平衡提供了一个直接的变换。该变换只需要在不同时间瞬间进行两个测量（电压或电流），这使得它计算效率高。此外，我们通过纯几何推理证明了我们的方法是通用的，并包括其他技术，如经典的Clarke变换。使用实时数字模拟器和物理实验室设置进行的数值模拟和实验验证证明了所提出方法的有效性。将该方法推广到多维度系统，结合减少的测量要求，相对于现有的通常限于三相应用或受限于计算方法的现有方法，代表了一个重大的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Various domains such as power system stability analysis, electric machinemodeling, and control of power electronic converters have significantlybenefited from the application of coordinate transformations. One of the mainbenefits is the dimensional reduction, which reduces the complexity of theproblems. This paper introduces a novel general transformation based on ageometric framework that directly identifies the plane containing the locus forunbalanced quantities through bivector analysis using Geometric Algebra. Theproposed method provides a direct transformation valid for any degree ofunbalance in $n$-phase, $(n+1)$-wire sinusoidal systems. The transformationrequires only two measurements (voltage or current) taken at different timeinstants, making it computationally efficient. Moreover, we demonstrate throughpure geometric reasoning that our approach is general and encompasses othertechniques, such as the classical Clarke transformation. Numerical simulationsand experimental validation using a real-time digital simulator and a physicallaboratory setup demonstrate the effectiveness of the proposed method. Thisgeneralization to multi-dimensional systems, combined with the reducedmeasurement requirements, represents a significant advancement over existingapproaches that are typically restricted to three-phase applications or sufferfrom computational limitations.</description>
      <author>example@mail.com (Francisco G. Montoya, Santiago Sánchez Acevedo)</author>
      <guid isPermaLink="false">2506.10835v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Think before You Simulate: Symbolic Reasoning to Orchestrate Neural Computation for Counterfactual Question Answering</title>
      <link>http://arxiv.org/abs/2506.10753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In Proceedings the IEEE/CVF Winter Conference on Applications of  Computer Vision (WACV 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种增强神经符号模型以进行反事实推理的方法，利用符号推理来处理事件间的因果关系。&lt;h4&gt;背景&lt;/h4&gt;关于视频动态的因果和时序推理是一个挑战性问题。尽管神经符号模型结合了符号推理和基于神经的感知与预测，但它们在回答反事实问题时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;目的是提出一种方法来增强神经符号模型，使其能够更好地处理反事实推理。&lt;h4&gt;方法&lt;/h4&gt;方法包括定义因果图来表示事件间的因果关系，并使用声明式逻辑编程方法Answer Set Programming (ASP)来协调感知和模拟模块。&lt;h4&gt;主要发现&lt;/h4&gt;在两个基准测试CLEVRER和CRAFT上验证了该方法的有效性。该方法在CLEVRER挑战中实现了最先进的性能，显著优于现有模型。在CRAFT基准测试中，通过使用大型的预训练语言模型（如GPT-3.5和GPT-4）作为动态模拟器的代理，进一步提高了反事实问题的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法通过提供由符号因果推理指导的替代提示，可以进一步改善反事实问题的性能。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Causal and temporal reasoning about video dynamics is a challenging problem. While neuro-symbolic models that combine symbolic reasoning with neural-based perception and prediction have shown promise, they exhibit limitations, especially in answering counterfactual questions. This paper introduces a method to enhance a neuro-symbolic model for counterfactual reasoning, leveraging symbolic reasoning about causal relations among events. We define the notion of a causal graph to represent such relations and use Answer Set Programming (ASP), a declarative logic programming method, to find how to coordinate perception and simulation modules. We validate the effectiveness of our approach on two benchmarks, CLEVRER and CRAFT. Our enhancement achieves state-of-the-art performance on the CLEVRER challenge, significantly outperforming existing models. In the case of the CRAFT benchmark, we leverage a large pre-trained language model, such as GPT-3.5 and GPT-4, as a proxy for a dynamics simulator. Our findings show that this method can further improve its performance on counterfactual questions by providing alternative prompts instructed by symbolic causal reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Causal and temporal reasoning about video dynamics is a challenging problem.While neuro-symbolic models that combine symbolic reasoning with neural-basedperception and prediction have shown promise, they exhibit limitations,especially in answering counterfactual questions. This paper introduces amethod to enhance a neuro-symbolic model for counterfactual reasoning,leveraging symbolic reasoning about causal relations among events. We definethe notion of a causal graph to represent such relations and use Answer SetProgramming (ASP), a declarative logic programming method, to find how tocoordinate perception and simulation modules. We validate the effectiveness ofour approach on two benchmarks, CLEVRER and CRAFT. Our enhancement achievesstate-of-the-art performance on the CLEVRER challenge, significantlyoutperforming existing models. In the case of the CRAFT benchmark, we leveragea large pre-trained language model, such as GPT-3.5 and GPT-4, as a proxy for adynamics simulator. Our findings show that this method can further improve itsperformance on counterfactual questions by providing alternative promptsinstructed by symbolic causal reasoning.</description>
      <author>example@mail.com (Adam Ishay, Zhun Yang, Joohyung Lee, Ilgu Kang, Dongjae Lim)</author>
      <guid isPermaLink="false">2506.10753v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>3DGeoDet: General-purpose Geometry-aware Image-based 3D Object Detection</title>
      <link>http://arxiv.org/abs/2506.09541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE Transactions on Multimedia&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为3DGeoDet的新型几何感知3D目标检测方法，该方法能够有效地处理室内和室外环境中的单视角和多视角RGB图像，并展示了其通用适用性。&lt;h4&gt;背景&lt;/h4&gt;基于图像的3D目标检测任务的关键挑战在于缺乏3D几何线索，这导致了图像和3D表示之间对应关系的模糊性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，3DGeoDet通过预测的深度信息，以显式和隐式的方式生成高效的3D几何表示。&lt;h4&gt;方法&lt;/h4&gt;具体来说，利用预测的深度信息学习体素占用情况，并通过提出的体素占用注意力机制显式地优化体素化的3D特征体积。此外，为了进一步增强3D感知，将特征体积与隐式的3D表示（截断符号距离函数）集成。该方法无需3D信号监督，通过利用中间3D表示显著提高了模型对3D几何的理解，并实现了端到端的训练。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在单视角和多视角基准数据集上均超越了最先进的方法，在SUN RGB-D数据集上实现了9.3 mAP@0.5的提升，在ScanNetV2数据集上实现了3.3 mAP@0.5的提升，在KITTI数据集上实现了0.19AP3D@0.7的提升。&lt;h4&gt;结论&lt;/h4&gt;3DGeoDet项目页面：https://cindy0725.github.io/3DGeoDet/&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes 3DGeoDet, a novel geometry-aware 3D object detection approach that effectively handles single- and multi-view RGB images in indoor and outdoor environments, showcasing its general-purpose applicability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes 3DGeoDet, a novel geometry-aware 3D object detectionapproach that effectively handles single- and multi-view RGB images in indoorand outdoor environments, showcasing its general-purpose applicability. The keychallenge for image-based 3D object detection tasks is the lack of 3D geometriccues, which leads to ambiguity in establishing correspondences between imagesand 3D representations. To tackle this problem, 3DGeoDet generates efficient 3Dgeometric representations in both explicit and implicit manners based onpredicted depth information. Specifically, we utilize the predicted depth tolearn voxel occupancy and optimize the voxelized 3D feature volume explicitlythrough the proposed voxel occupancy attention. To further enhance 3Dawareness, the feature volume is integrated with an implicit 3D representation,the truncated signed distance function (TSDF). Without requiring supervisionfrom 3D signals, we significantly improve the model's comprehension of 3Dgeometry by leveraging intermediate 3D representations and achieve end-to-endtraining. Our approach surpasses the performance of state-of-the-artimage-based methods on both single- and multi-view benchmark datasets acrossdiverse environments, achieving a 9.3 mAP@0.5 improvement on the SUN RGB-Ddataset, a 3.3 mAP@0.5 improvement on the ScanNetV2 dataset, and a 0.19AP3D@0.7 improvement on the KITTI dataset. The project page is available at:https://cindy0725.github.io/3DGeoDet/.</description>
      <author>example@mail.com (Yi Zhang, Yi Wang, Yawen Cui, Lap-Pui Chau)</author>
      <guid isPermaLink="false">2506.09541v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Cosmos-Drive-Dreams: Scalable Synthetic Driving Data Generation with World Foundation Models</title>
      <link>http://arxiv.org/abs/2506.09042v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Only the core contributors are listed. The full list of contributors  can be found in Appendix A of this paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Cosmos-Drive-Dreams的合成数据生成管道，用于生成高保真、具有挑战性的场景，以辅助自动驾驶车辆系统的感知和驾驶策略训练。&lt;h4&gt;背景&lt;/h4&gt;收集和注释现实世界数据对于自动驾驶车辆等安全关键物理AI系统来说既耗时又昂贵，尤其难以捕捉罕见的边缘情况。&lt;h4&gt;目的&lt;/h4&gt;提出Cosmos-Drive-Dreams，旨在生成具有挑战性的场景，以促进后续任务如感知和驾驶策略训练。&lt;h4&gt;方法&lt;/h4&gt;Cosmos-Drive-Dreams由Cosmos-Drive模型驱动，该模型是从NVIDIA Cosmos世界基础模型针对驾驶领域专门设计的，能够生成可控、高保真、多视角和时空一致性的驾驶视频。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，生成的数据有助于缓解长尾分布问题，并增强了下游任务（如3D车道检测、3D物体检测和驾驶策略学习）的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文开源了Cosmos-Drive-Dreams的管道工具包、数据集和模型权重，通过NVIDIA的Cosmos平台提供。&lt;h4&gt;翻译&lt;/h4&gt;Collecting and annotating real-world data for safety-critical physical AI systems, such as Autonomous Vehicle (AV), is time-consuming and costly. It is especially challenging to capture rare edge cases, which play a critical role in training and testing of an AV system. To address this challenge, we introduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipeline that aims to generate challenging scenarios to facilitate downstream tasks such as perception and driving policy training. Powering this pipeline is Cosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundation model for the driving domain and are capable of controllable, high-fidelity, multi-view, and spatiotemporally consistent driving video generation. We showcase the utility of these models by applying Cosmos-Drive-Dreams to scale the quantity and diversity of driving datasets with high-fidelity and challenging scenarios. Experimentally, we demonstrate that our generated data helps in mitigating long-tail distribution problems and enhances generalization in downstream tasks such as 3D lane detection, 3D object detection and driving policy learning. We open source our pipeline toolkit, dataset and model weight through the NVIDIA's Cosmos platform.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Collecting and annotating real-world data for safety-critical physical AIsystems, such as Autonomous Vehicle (AV), is time-consuming and costly. It isespecially challenging to capture rare edge cases, which play a critical rolein training and testing of an AV system. To address this challenge, weintroduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipelinethat aims to generate challenging scenarios to facilitate downstream tasks suchas perception and driving policy training. Powering this pipeline isCosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundationmodel for the driving domain and are capable of controllable, high-fidelity,multi-view, and spatiotemporally consistent driving video generation. Weshowcase the utility of these models by applying Cosmos-Drive-Dreams to scalethe quantity and diversity of driving datasets with high-fidelity andchallenging scenarios. Experimentally, we demonstrate that our generated datahelps in mitigating long-tail distribution problems and enhances generalizationin downstream tasks such as 3D lane detection, 3D object detection and drivingpolicy learning. We open source our pipeline toolkit, dataset and model weightsthrough the NVIDIA's Cosmos platform.  Project page: https://research.nvidia.com/labs/toronto-ai/cosmos_drive_dreams</description>
      <author>example@mail.com (Xuanchi Ren, Yifan Lu, Tianshi Cao, Ruiyuan Gao, Shengyu Huang, Amirmojtaba Sabour, Tianchang Shen, Tobias Pfaff, Jay Zhangjie Wu, Runjian Chen, Seung Wook Kim, Jun Gao, Laura Leal-Taixe, Mike Chen, Sanja Fidler, Huan Ling)</author>
      <guid isPermaLink="false">2506.09042v2</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Text to Image for Multi-Label Image Recognition with Joint Prompt-Adapter Learning</title>
      <link>http://arxiv.org/abs/2506.10575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为T2I-PAL的新方法，用于解决仅使用文本描述进行参数高效微调（PEFT）时的模态差距问题，显著提升了图像识别性能。&lt;h4&gt;背景&lt;/h4&gt;预训练视觉语言模型如CLIP能够直接利用文本作为图像进行参数高效微调，但模态差距限制了其性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来减少模态差距，以提升仅使用文本描述进行PEFT时的图像识别性能。&lt;h4&gt;方法&lt;/h4&gt;T2I-PAL利用预训练的文本到图像生成模型从文本描述生成逼真的图像，结合类别级别的热图和可学习原型，以及提示调整和适配器学习来增强分类性能。&lt;h4&gt;主要发现&lt;/h4&gt;T2I-PAL消除了对完全语义标注训练图像的需求，减少了人工标注工作量，并保持了CLIP模型的原生模式，使其能够与任何现有的CLIP框架无缝集成。&lt;h4&gt;结论&lt;/h4&gt;在多个基准数据集上的实验表明，T2I-PAL的平均识别性能比现有最佳方法提高了3.47%。&lt;h4&gt;翻译&lt;/h4&gt;Benefited from image-text contrastive learning, pre-trained vision-language models, e.g., CLIP, allow to direct leverage texts as images (TaI) for parameter-efficient fine-tuning (PEFT). While CLIP is capable of making image features to be similar to the corresponding text features, the modality gap remains a nontrivial issue and limits the image recognition performance of TaI. Using multi-label image recognition (MLR) as an example, we present a novel method, called T2I-PAL to tackle the modality gap issue when using only text captions for PEFT. The core design of T2I-PAL is to leverage pre-trained text-to-image generation models to generate photo-realistic and diverse images from text captions, thereby reducing the modality gap. To further enhance MLR, T2I-PAL incorporates a class-wise heatmap and learnable prototypes. This aggregates local similarities, making the representation of local visual features more robust and informative for multi-label recognition. For better PEFT, we further combine both prompt tuning and adapter learning to enhance classification performance. T2I-PAL offers significant advantages: it eliminates the need for fully semantically annotated training images, thereby reducing the manual annotation workload, and it preserves the intrinsic mode of the CLIP model, allowing for seamless integration with any existing CLIP framework. Extensive experiments on multiple benchmarks, including MS-COCO, VOC2007, and NUS-WIDE, show that our T2I-PAL can boost recognition performance by 3.47% on average above the top-ranked state-of-the-art methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TPAMI.2025.3573852&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Benefited from image-text contrastive learning, pre-trained vision-languagemodels, e.g., CLIP, allow to direct leverage texts as images (TaI) forparameter-efficient fine-tuning (PEFT). While CLIP is capable of making imagefeatures to be similar to the corresponding text features, the modality gapremains a nontrivial issue and limits image recognition performance of TaI.Using multi-label image recognition (MLR) as an example, we present a novelmethod, called T2I-PAL to tackle the modality gap issue when using only textcaptions for PEFT. The core design of T2I-PAL is to leverage pre-trainedtext-to-image generation models to generate photo-realistic and diverse imagesfrom text captions, thereby reducing the modality gap. To further enhance MLR,T2I-PAL incorporates a class-wise heatmap and learnable prototypes. Thisaggregates local similarities, making the representation of local visualfeatures more robust and informative for multi-label recognition. For betterPEFT, we further combine both prompt tuning and adapter learning to enhanceclassification performance. T2I-PAL offers significant advantages: iteliminates the need for fully semantically annotated training images, therebyreducing the manual annotation workload, and it preserves the intrinsic mode ofthe CLIP model, allowing for seamless integration with any existing CLIPframework. Extensive experiments on multiple benchmarks, including MS-COCO,VOC2007, and NUS-WIDE, show that our T2I-PAL can boost recognition performanceby 3.47% in average above the top-ranked state-of-the-art methods.</description>
      <author>example@mail.com (Chun-Mei Feng, Kai Yu, Xinxing Xu, Salman Khan, Rick Siow Mong Goh, Wangmeng Zuo, Yong Liu)</author>
      <guid isPermaLink="false">2506.10575v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Air in Your Neighborhood: Fine-Grained AQI Forecasting Using Mobile Sensor Data</title>
      <link>http://arxiv.org/abs/2506.10332v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 7 figures. Code available at  https://github.com/ASChampOmega/AQI_Forecasting.git&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过预测1平方公里区域内的空气质量指数（AQI），解决了发展中国家空气质量监测数据不足的问题。&lt;h4&gt;背景&lt;/h4&gt;发展中国家空气污染成为重要的健康风险，政府虽然发布AQI数据，但传感器分布稀疏，无法准确反映当地实际情况。&lt;h4&gt;目的&lt;/h4&gt;预测1平方公里区域内的AQI，以解决现有空气质量监测数据的不足。&lt;h4&gt;方法&lt;/h4&gt;采用时空图神经网络（Spatio-temporal GNNs）进行AQI预测，并使用AirDelhi数据集作为案例。&lt;h4&gt;主要发现&lt;/h4&gt;预测结果比现有方法提高了71.654 MSE，减少79%的误差，即使在未标记的坐标上也有显著效果。发现AQI存在强烈的重复短期模式和不断变化的空间关系。&lt;h4&gt;结论&lt;/h4&gt;时空图神经网络在预测空气质量指数方面表现出色，为解决空气质量监测数据不足问题提供了新的方法。&lt;h4&gt;翻译&lt;/h4&gt;Air pollution has become a significant health risk in developing countries. While governments routinely publish air-quality index (AQI) data to track pollution, these values fail to capture the local reality, as sensors are often very sparse. In this paper, we address this gap by predicting AQI in 1 km^2 neighborhoods, using the example of AirDelhi dataset. Using Spatio-temporal GNNs we surpass existing works by 71.654 MSE, a 79% reduction, even on unseen coordinates. New insights about AQI such as the existence of strong repetitive short-term patterns and changing spatial relations are also discovered. The code is available on GitHub.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Air pollution has become a significant health risk in developing countries.While governments routinely publish air-quality index (AQI) data to trackpollution, these values fail to capture the local reality, as sensors are oftenvery sparse. In this paper, we address this gap by predicting AQI in 1 km^2neighborhoods, using the example of AirDelhi dataset. Using Spatio-temporalGNNs we surpass existing works by 71.654 MSE a 79% reduction, even on unseencoordinates. New insights about AQI such as the existence of strong repetitiveshort-term patterns and changing spatial relations are also discovered. Thecode is available on GitHub.</description>
      <author>example@mail.com (Aaryam Sharma)</author>
      <guid isPermaLink="false">2506.10332v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Adv-BMT: Bidirectional Motion Transformer for Safety-Critical Traffic Scenario Generation</title>
      <link>http://arxiv.org/abs/2506.09485v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Adv-BMT的框架，用于解决自动驾驶系统测试中长尾、安全关键场景数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的自动驾驶系统测试数据集中，缺乏长尾、安全关键场景的数据。&lt;h4&gt;目的&lt;/h4&gt;为了解决数据稀缺的问题，提出了一种名为Adv-BMT的框架。&lt;h4&gt;方法&lt;/h4&gt;Adv-BMT框架通过增强现实世界场景中的多样化、真实对抗性交互来扩充数据。其核心组件是双向运动转换器（BMT）模型，用于执行逆交通运动预测，并按逆时间顺序重建交通情况。该框架分为两个阶段：首先进行对抗性初始化，然后进行逆运动预测。&lt;h4&gt;主要发现&lt;/h4&gt;Adv-BMT框架不需要任何碰撞数据进行预训练，能够生成真实且多样化的碰撞交互。实验结果表明，在增强数据集上进行训练，与之前的工作相比，可以降低20%的碰撞率。&lt;h4&gt;结论&lt;/h4&gt;Adv-BMT框架能够有效提高自动驾驶系统测试数据的质量，并减少碰撞率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scenario-based testing is essential for validating the performance ofautonomous driving (AD) systems. However, such testing is limited by thescarcity of long-tailed, safety-critical scenarios in existing datasetscollected in the real world. To tackle the data issue, we propose the Adv-BMTframework, which augments real-world scenarios with diverse and realisticadversarial interactions. The core component of Adv-BMT is a bidirectionalmotion transformer (BMT) model to perform inverse traffic motion predictions,which takes agent information in the last time step of the scenario as input,and reconstruct the traffic in the inverse of chronological order until theinitial time step. The Adv-BMT framework is a two-staged pipeline: it firstconducts adversarial initializations and then inverse motion predictions.Different from previous work, we do not need any collision data forpretraining, and are able to generate realistic and diverse collisioninteractions. Our experimental results validate the quality of generatedcollision scenarios by Adv-BMT: training in our augmented dataset would reduceepisode collision rates by 20\% compared to previous work.</description>
      <author>example@mail.com (Yuxin Liu, Zhenghao Peng, Xuanhao Cui, Bolei Zhou)</author>
      <guid isPermaLink="false">2506.09485v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>In-Hand Object Pose Estimation via Visual-Tactile Fusion</title>
      <link>http://arxiv.org/abs/2506.10787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合视觉和触觉信息进行机器人手部物体姿态估计的方法，以解决视觉遮挡问题。&lt;h4&gt;背景&lt;/h4&gt;精确的手部物体姿态估计对于机器人操作至关重要，但视觉遮挡是视觉方法的一个主要挑战。&lt;h4&gt;目的&lt;/h4&gt;准确确定机器人手部抓取物体的位置和方向。&lt;h4&gt;方法&lt;/h4&gt;该方法通过融合手腕上的RGB-D相机的视觉信息和机器人夹爪指尖上的基于视觉的触觉传感器的触觉信息来解决视觉遮挡问题。它使用一个加权传感器融合模块来结合不同类型传感器的点云数据，并控制每个模态对姿态估计过程的贡献。使用改进的加权点云迭代的最近点（ICP）算法来估计6D物体姿态。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，结合触觉信息显著提高了姿态估计的准确性，尤其是在遮挡较高的情况下。该方法实现了平均姿态估计误差为7.5毫米和16.7度，比仅视觉的基线方法提高了高达20%。&lt;h4&gt;结论&lt;/h4&gt;该方法能够执行精确的物体操作，在现实世界的插入任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Accurate in-hand pose estimation is crucial for robotic object manipulation, but visual occlusion remains a major challenge for vision-based approaches. This paper presents an approach to robotic in-hand object pose estimation, combining visual and tactile information to accurately determine the position and orientation of objects grasped by a robotic hand. We address the challenge of visual occlusion by fusing visual information from a wrist-mounted RGB-D camera with tactile information from vision-based tactile sensors mounted on the fingertips of a robotic gripper. Our approach employs a weighting and sensor fusion module to combine point clouds from heterogeneous sensor types and control each modality's contribution to the pose estimation process. We use an augmented Iterative Closest Point (ICP) algorithm adapted for weighted point clouds to estimate the 6D object pose. Our experiments show that incorporating tactile information significantly improves pose estimation accuracy, particularly when occlusion is high. Our method achieves an average pose estimation error of 7.5 mm and 16.7 degrees, outperforming vision-only baselines by up to 20%. We also demonstrate the ability of our method to perform precise object manipulation in a real-world insertion task.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate in-hand pose estimation is crucial for robotic object manipulation,but visual occlusion remains a major challenge for vision-based approaches.This paper presents an approach to robotic in-hand object pose estimation,combining visual and tactile information to accurately determine the positionand orientation of objects grasped by a robotic hand. We address the challengeof visual occlusion by fusing visual information from a wrist-mounted RGB-Dcamera with tactile information from vision-based tactile sensors mounted onthe fingertips of a robotic gripper. Our approach employs a weighting andsensor fusion module to combine point clouds from heterogeneous sensor typesand control each modality's contribution to the pose estimation process. We usean augmented Iterative Closest Point (ICP) algorithm adapted for weighted pointclouds to estimate the 6D object pose. Our experiments show that incorporatingtactile information significantly improves pose estimation accuracy,particularly when occlusion is high. Our method achieves an average poseestimation error of 7.5 mm and 16.7 degrees, outperforming vision-onlybaselines by up to 20%. We also demonstrate the ability of our method toperform precise object manipulation in a real-world insertion task.</description>
      <author>example@mail.com (Felix Nonnengießer, Alap Kshirsagar, Boris Belousov, Jan Peters)</author>
      <guid isPermaLink="false">2506.10787v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Probabilistic Variational Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.10159v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了基于对比学习的确定性嵌入方法，如SimCLR和SupCon，虽然取得了很好的性能，但缺乏不确定性量化机制。文章提出了变分对比学习（VCL），这是一种无解码器框架，通过将InfoNCE损失视为代理重构项，并在单位超球面上添加KL散度正则化项来最大化证据下界（ELBO）。&lt;h4&gt;背景&lt;/h4&gt;当前对比学习方法如SimCLR和SupCon在性能上达到了最先进的水平，但它们缺乏一个用于不确定性量化的原理性机制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的变分对比学习（VCL）框架，以提供不确定性量化和概率性嵌入。&lt;h4&gt;方法&lt;/h4&gt;VCL框架通过将InfoNCE损失视为代理重构项，并添加KL散度正则化项来最大化证据下界。近似后验分布$q_heta(z|x)$被建模为投影正态分布，从而实现概率性嵌入的采样。VSimCLR和VSupCon是VCL的两个实现，它们用$q_heta(z|x)$的样本替换确定性嵌入，并将归一化KL项纳入损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，VCL减轻了维度塌陷，增强了与类标签的互信息，并且在分类准确率上与确定性基线相匹配或超越，同时通过后验模型提供有意义的不确定性估计。&lt;h4&gt;结论&lt;/h4&gt;VCL为对比学习提供了一个概率基础，成为对比方法的新基准。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes a variational contrastive learning (VCL) framework, which is a decoder-free architecture that maximizes the evidence lower bound (ELBO) by interpreting the InfoNCE loss as a surrogate reconstruction term and adding a KL divergence regularizer to a uniform prior on the unit hypersphere. The approximate posterior $q_heta(z|x)$ is modeled as a projected normal distribution, enabling the sampling of probabilistic embeddings. The two instantiations--VSimCLR and VSupCon--replace deterministic embeddings with samples from $q_heta(z|x)$ and incorporate a normalized KL term into the loss. Experiments on multiple benchmarks demonstrate that VCL mitigates dimension collapse, enhances mutual information with class labels, and matches or outperforms deterministic baselines in classification accuracy, all the while providing meaningful uncertainty estimates through the posterior model. VCL thus equips contrastive learning with a probabilistic foundation, serving as a new basis for contrastive approaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deterministic embeddings learned by contrastive learning (CL) methods such asSimCLR and SupCon achieve state-of-the-art performance but lack a principledmechanism for uncertainty quantification. We propose Variational ContrastiveLearning (VCL), a decoder-free framework that maximizes the evidence lowerbound (ELBO) by interpreting the InfoNCE loss as a surrogate reconstructionterm and adding a KL divergence regularizer to a uniform prior on the unithypersphere. We model the approximate posterior $q_\theta(z|x)$ as a projectednormal distribution, enabling the sampling of probabilistic embeddings. Our twoinstantiations--VSimCLR and VSupCon--replace deterministic embeddings withsamples from $q_\theta(z|x)$ and incorporate a normalized KL term into theloss. Experiments on multiple benchmarks demonstrate that VCL mitigatesdimensional collapse, enhances mutual information with class labels, andmatches or outperforms deterministic baselines in classification accuracy, allthe while providing meaningful uncertainty estimates through the posteriormodel. VCL thus equips contrastive learning with a probabilistic foundation,serving as a new basis for contrastive approaches.</description>
      <author>example@mail.com (Minoh Jeong, Seonho Kim, Alfred Hero)</author>
      <guid isPermaLink="false">2506.10159v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Analyzing the relationships between pretraining language, phonetic, tonal, and speaker information in self-supervised speech models</title>
      <link>http://arxiv.org/abs/2506.10855v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文分析了wav2vec2模型在四种不同语言上的训练情况，探讨了模型如何编码语言匹配和非匹配的语音信息，并分析了音素、词汇音调和说话人信息的表示方式。&lt;h4&gt;背景&lt;/h4&gt;以往的分析主要集中在英语上，而本文旨在扩展这一研究到其他语言。&lt;h4&gt;目的&lt;/h4&gt;研究wav2vec2模型在多种语言上的表现，以及模型如何处理不同类型的语音信息。&lt;h4&gt;方法&lt;/h4&gt;使用探针分类器和几何分析方法，对音素、词汇音调和说话人信息的表示进行了研究。&lt;h4&gt;主要发现&lt;/h4&gt;所有预训练和测试语言中，编码音素、音调和说话人的子空间大部分是正交的，层级的探针准确率模式相似，在后期层中，匹配语言的音素和音调探针（但不是说话人）有相对较小的优势。&lt;h4&gt;结论&lt;/h4&gt;wav2vec2学习到的表示结构在很大程度上独立于预训练期间使用的语音材料。&lt;h4&gt;翻译&lt;/h4&gt;摘要：对自监督语音模型的分析已经开始揭示它们如何表示不同类型的信息。然而，几乎所有分析都集中在英语上。在这里，我们检验了在四种不同语言上训练的wav2vec2模型如何编码匹配和非匹配的语音。我们使用探针分类器和几何分析来检验音素、词汇音调和说话人信息是如何表示的。我们发现，对于所有预训练和测试语言，编码音素、音调和说话人的子空间大部分是正交的，并且层级的探针准确率模式相似，在后期层中，匹配语言的音素和音调探针（但不是说话人）有相对较小的优势。我们的发现表明，wav2vec2学习到的表示结构在很大程度上独立于预训练期间使用的语音材料。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Analyses of self-supervised speech models have begun to reveal where and howthey represent different types of information. However, almost all analyseshave focused on English. Here, we examine how wav2vec2 models trained on fourdifferent languages encode both language-matched and non-matched speech. We useprobing classifiers and geometric analyses to examine how phones, lexicaltones, and speaker information are represented. We show that for allpretraining and test languages, the subspaces encoding phones, tones, andspeakers are largely orthogonal, and that layerwise patterns of probingaccuracy are similar, with a relatively small advantage for matched-languagephone and tone (but not speaker) probes in the later layers. Our findingssuggest that the structure of representations learned by wav2vec2 is largelyindependent of the speech material used during pretraining.</description>
      <author>example@mail.com (Michele Gubian, Ioana Krehan, Oli Liu, James Kirby, Sharon Goldwater)</author>
      <guid isPermaLink="false">2506.10855v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Distillation of atomistic foundation models across architectures and chemical domains</title>
      <link>http://arxiv.org/abs/2506.10956v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文展示了如何通过合成数据的蒸馏方法，将原子基础模型的知识转移到不同架构上，以获得更小、更高效的势场。&lt;h4&gt;背景&lt;/h4&gt;机器学习原子间势场在物理科学研究中发挥了重要作用。最近的原子基础模型虽然应用广泛，但运行速度慢、资源密集。&lt;h4&gt;目的&lt;/h4&gt;通过蒸馏方法，以降低计算成本，提高效率，将原子基础模型的知识应用于不同架构。&lt;h4&gt;方法&lt;/h4&gt;使用合成数据的蒸馏技术，将知识从一种图网络架构转移到另一种架构，并利用原子簇扩展框架。&lt;h4&gt;主要发现&lt;/h4&gt;从一种图网络架构蒸馏到另一种，速度提高超过10倍；利用原子簇扩展框架，速度提高超过100倍。&lt;h4&gt;结论&lt;/h4&gt;该方法支持当前和未来原子基础模型在现实世界科学研究中的常规和计算高效使用。&lt;h4&gt;翻译&lt;/h4&gt;机器学习的原子间势场已经改变了物理科学中的计算研究。最近的原子基础模型再次改变了这个领域：这些势场在许多不同的化学元素和领域上进行了训练，因此应用广泛，但相比之下运行速度较慢，资源密集。在这里，我们展示了如何通过合成数据的蒸馏方法来低成本地将知识从原子基础模型转移到各种不同的架构上，从而解锁更小、更高效的势场。我们通过从一种图网络架构蒸馏到另一种架构，以及利用原子簇扩展框架，展示了超过10倍的速度提升和超过100倍的速度提升。我们在化学和材料领域展示了其适用性：从液态水到极端条件下的氢气；从多孔二氧化硅和混合卤化物钙钛矿太阳能电池材料到有机反应建模。我们的工作展示了蒸馏如何支持当前和未来原子基础模型在现实世界科学研究中的常规和计算高效使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learned interatomic potentials have transformed computationalresearch in the physical sciences. Recent atomistic `foundation' models havechanged the field yet again: trained on many different chemical elements anddomains, these potentials are widely applicable, but comparably slow andresource-intensive to run. Here we show how distillation via synthetic data canbe used to cheaply transfer knowledge from atomistic foundation models to arange of different architectures, unlocking much smaller, more efficientpotentials. We demonstrate speed-ups of $&gt; 10\times$ by distilling from onegraph-network architecture into another, and $&gt; 100\times$ by leveraging theatomic cluster expansion framework. We showcase applicability across chemicaland materials domains: from liquid water to hydrogen under extreme conditions;from porous silica and a hybrid halide perovskite solar-cell material tomodelling organic reactions. Our work shows how distillation can support theroutine and computationally efficient use of current and future atomisticfoundation models in real-world scientific research.</description>
      <author>example@mail.com (John L. A. Gardner, Daniel F. Thomas du Toit, Chiheb Ben Mahmoud, Zoé Faure Beaulieu, Veronika Juraskova, Laura-Bianca Paşca, Louise A. M. Rosset, Fernanda Duarte, Fausto Martelli, Chris J. Pickard, Volker L. Deringer)</author>
      <guid isPermaLink="false">2506.10956v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Gaussian2Scene: 3D Scene Representation Learning via Self-supervised Learning with 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.08777v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Gaussian2Scene的新型场景级自监督学习框架，用于点云预训练，以解决现有方法在场景表示和几何结构捕获方面的限制。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在点云预训练中已成为许多3D视觉任务的基础，它使得从大规模未标注数据中有效学习成为可能。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有自监督学习方法在场景表示和几何结构捕获方面的限制。&lt;h4&gt;方法&lt;/h4&gt;Gaussian2Scene利用3D高斯分层（3DGS）的效率和显式性，采用渐进式的两阶段训练策略：第一阶段使用双分支掩码自动编码器学习2D和3D场景表示；第二阶段以重建的点云初始化训练，并进一步使用高斯原语的几何位置和渲染的RGB图像进行监督学习。&lt;h4&gt;主要发现&lt;/h4&gt;Gaussian2Scene在多个下游3D目标检测任务中展示了有效性，与现有预训练方法相比，表现出了持续的性能提升。&lt;h4&gt;结论&lt;/h4&gt;Gaussian2Scene通过改进的场景级自监督学习框架，提高了3D几何理解，为3D视觉任务提供了更有效的预训练方法。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Self-supervised learning (SSL) for point cloud pre-training has become a cornerstone for many 3D vision tasks, enabling effective learning from large-scale unannotated data. At the scene level, existing SSL methods often incorporate volume rendering into the pre-training framework, using RGB-D images as reconstruction signals to facilitate cross-modal learning. This strategy promotes alignment between 2D and 3D modalities and enables the model to benefit from rich visual cues in the RGB-D inputs. However, these approaches are limited by their reliance on implicit scene representations and high memory demands. Furthermore, since their reconstruction objectives are applied only in 2D space, they often fail to capture underlying 3D geometric structures. To address these challenges, we propose Gaussian2Scene, a novel scene-level SSL framework that leverages the efficiency and explicit nature of 3D Gaussian Splatting (3DGS) for pre-training. The use of 3DGS not only alleviates the computational burden associated with volume rendering but also supports direct 3D scene reconstruction, thereby enhancing the geometric understanding of the backbone network. Our approach follows a progressive two-stage training strategy. In the first stage, a dual-branch masked autoencoder learns both 2D and 3D scene representations. In the second stage, we initialize training with reconstructed point clouds and further supervise learning using the geometric locations of Gaussian primitives and rendered RGB images. This process reinforces both geometric and cross-modal learning. We demonstrate the effectiveness of Gaussian2Scene across several downstream 3D object detection tasks, showing consistent improvements over existing pre-training methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) for point cloud pre-training has become acornerstone for many 3D vision tasks, enabling effective learning fromlarge-scale unannotated data. At the scene level, existing SSL methods oftenincorporate volume rendering into the pre-training framework, using RGB-Dimages as reconstruction signals to facilitate cross-modal learning. Thisstrategy promotes alignment between 2D and 3D modalities and enables the modelto benefit from rich visual cues in the RGB-D inputs. However, these approachesare limited by their reliance on implicit scene representations and high memorydemands. Furthermore, since their reconstruction objectives are applied only in2D space, they often fail to capture underlying 3D geometric structures. Toaddress these challenges, we propose Gaussian2Scene, a novel scene-level SSLframework that leverages the efficiency and explicit nature of 3D GaussianSplatting (3DGS) for pre-training. The use of 3DGS not only alleviates thecomputational burden associated with volume rendering but also supports direct3D scene reconstruction, thereby enhancing the geometric understanding of thebackbone network. Our approach follows a progressive two-stage trainingstrategy. In the first stage, a dual-branch masked autoencoder learns both 2Dand 3D scene representations. In the second stage, we initialize training withreconstructed point clouds and further supervise learning using the geometriclocations of Gaussian primitives and rendered RGB images. This processreinforces both geometric and cross-modal learning. We demonstrate theeffectiveness of Gaussian2Scene across several downstream 3D object detectiontasks, showing consistent improvements over existing pre-training methods.</description>
      <author>example@mail.com (Keyi Liu, Weidong Yang, Ben Fei, Ying He)</author>
      <guid isPermaLink="false">2506.08777v2</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Context-Adaptive Graph Neural Networks for Next POI Recommendation</title>
      <link>http://arxiv.org/abs/2506.10329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CAGNN的上下文自适应图神经网络，用于改进基于位置的服务中的Next Point-of-Interest推荐。&lt;h4&gt;背景&lt;/h4&gt;现有的Next POI推荐方法大多使用图神经网络（GNN）来结合协同信息，但它们通常将不同类型的上下文使用单独的图来建模，忽略了多个上下文因素之间的相互影响。&lt;h4&gt;目的&lt;/h4&gt;提出CAGNN的目的是为了解决上述方法的限制，如次优的注意力权重和推荐性能，以及过分重视序列组件的问题。&lt;h4&gt;方法&lt;/h4&gt;CAGNN通过以下方式实现改进：(1) 引入一个上下文自适应的注意力机制，在图传播过程中联合不同类型的上下文因素进行注意力计算；(2) 引入一个图-序列相互增强模块，通过KL散度对基于图和序列的模块的输出进行对齐。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CAGNN在三个真实世界数据集上始终优于现有方法，并且上下文自适应注意力机制提高了POI表示的表达能力。&lt;h4&gt;结论&lt;/h4&gt;CAGNN通过引入上下文自适应和相互增强机制，显著提升了Next POI推荐的准确性和性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Next POI推荐是位置服务中的一个关键任务，旨在根据用户的签到历史预测他们的下一次访问。虽然许多现有方法利用图神经网络（GNN）来结合协同信息并提高推荐准确性，但其中大多数使用单独的图来建模每种类型的上下文，将不同的因素孤立对待。这限制了它们建模多个上下文因素在消息传播期间对用户过渡的共同影响的能力，导致次优的注意力权重和推荐性能。此外，它们通常将序列组件作为主要预测因素，这可能会损害GNN学习的POI嵌入中的语义和结构信息。为了解决这些限制，我们提出了一个用于Next POI推荐的上下文自适应图神经网络（CAGNN），它通过使用边特定上下文因素动态调整注意力权重，并使基于图和序列的组件之间相互增强。具体来说，CAGNN引入了（1）一个上下文自适应的注意力机制，在图传播过程中联合不同类型的上下文因素进行注意力计算，使模型能够动态捕获协作和上下文依赖的过渡模式；（2）一个图-序列相互增强模块，通过KL散度对基于图和序列的模块的输出进行对齐。在三个真实世界数据集上的实验结果表明，CAGNN始终优于最先进的方法。同时，我们提供了理论保证，我们的上下文自适应注意力机制提高了POI表示的表达能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Next Point-of-Interest (POI) recommendation is a critical task inlocation-based services, aiming to predict users' next visits based on theircheck-in histories. While many existing methods leverage Graph Neural Networks(GNNs) to incorporate collaborative information and improve recommendationaccuracy, most of them model each type of context using separate graphs,treating different factors in isolation. This limits their ability to model theco-influence of multiple contextual factors on user transitions during messagepropagation, resulting in suboptimal attention weights and recommendationperformance. Furthermore, they often prioritize sequential components as theprimary predictor, potentially undermining the semantic and structuralinformation encoded in the POI embeddings learned by GNNs. To address theselimitations, we propose a Context-Adaptive Graph Neural Networks (CAGNN) fornext POI recommendation, which dynamically adjusts attention weights usingedge-specific contextual factors and enables mutual enhancement betweengraph-based and sequential components. Specifically, CAGNN introduces (1) acontext-adaptive attention mechanism that jointly incorporates different typesof contextual factors into the attention computation during graph propagation,enabling the model to dynamically capture collaborative and context-dependenttransition patterns; (2) a graph-sequential mutual enhancement module, whichaligns the outputs of the graph- and sequential-based modules via the KLdivergence, enabling mutual enhancement of both components. Experimentalresults on three real-world datasets demonstrate that CAGNN consistentlyoutperforms state-of-the-art methods. Meanwhile, theoretical guarantees areprovided that our context-adaptive attention mechanism improves theexpressiveness of POI representations.</description>
      <author>example@mail.com (Yu Lei, Limin Shen, Zhu Sun, Tiantian He, Yew-Soon Ong)</author>
      <guid isPermaLink="false">2506.10329v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Improving Medical Visual Representation Learning with Pathological-level Cross-Modal Alignment and Correlation Exploration</title>
      <link>http://arxiv.org/abs/2506.10573v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 10 tables and 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为PLACE的框架，用于从图像报告对中学习医学视觉表示，以解决医学领域数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;医学领域的数据稀缺问题，以及复杂文本关系和语义病理的挑战，促使研究者关注如何通过联合学习来学习医学视觉表示。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高病理观察的一致性，并通过关联探索丰富细节，无需额外的标注。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的病理级别跨模态对齐（PCMA）方法，通过视觉病理观察提取器从局部化标记中提取视觉病理观察表示。设计了一个代理任务，以强制模型识别图像块之间的相关性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该框架在多个下游任务上达到了新的最先进性能，包括分类、图像到文本检索、语义分割、目标检测和报告生成。&lt;h4&gt;结论&lt;/h4&gt;PLACE框架通过PCMA和关联探索，有效地提高了医学视觉表示的学习效果，为下游任务提供了高质量的数据表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning medical visual representations from image-report pairs through jointlearning has garnered increasing research attention due to its potential toalleviate the data scarcity problem in the medical domain. The primarychallenges stem from the lengthy reports that feature complex discourserelations and semantic pathologies. Previous works have predominantly focusedon instance-wise or token-wise cross-modal alignment, often neglecting theimportance of pathological-level consistency. This paper presents a novelframework PLACE that promotes the Pathological-Level Alignment and enriches thefine-grained details via Correlation Exploration without additional humanannotations. Specifically, we propose a novel pathological-level cross-modalalignment (PCMA) approach to maximize the consistency of pathology observationsfrom both images and reports. To facilitate this, a Visual PathologyObservation Extractor is introduced to extract visual pathological observationrepresentations from localized tokens. The PCMA module operates independentlyof any external disease annotations, enhancing the generalizability androbustness of our methods. Furthermore, we design a proxy task that enforcesthe model to identify correlations among image patches, thereby enriching thefine-grained details crucial for various downstream tasks. Experimental resultsdemonstrate that our proposed framework achieves new state-of-the-artperformance on multiple downstream tasks, including classification,image-to-text retrieval, semantic segmentation, object detection and reportgeneration.</description>
      <author>example@mail.com (Jun Wang, Lixing Zhu, Xiaohan Yu, Abhir Bhalerao, Yulan He)</author>
      <guid isPermaLink="false">2506.10573v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Efficient nanophotonic devices optimization using deep neural network trained with physics-based transfer learning (PBTL) methodology</title>
      <link>http://arxiv.org/abs/2506.10418v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于神经网络的代理建模框架，用于光子器件优化，特别是在特征重要性不平衡和高数据生成成本的环境中。&lt;h4&gt;背景&lt;/h4&gt;在特征重要性不平衡和高数据生成成本的环境中，传统优化方法难以应用于光子器件设计。&lt;h4&gt;目的&lt;/h4&gt;提供一种通用的光子设计自动化解决方案，即使在数据资源有限的情况下也能实现。&lt;h4&gt;方法&lt;/h4&gt;该框架包括基于物理的迁移学习（PBTL）增强的代理建模和标量化多目标遗传算法（GAs）。通过将深度神经网络总预测器（DNN-TP）与遗传算法（GA）结合，实现了可扩展和自然启发的优化。引入PBTL，从在活动区域结构上训练的DNN核心预测器（DNN-CP）中转移知识，以提高模型泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;优化了包含活动区和注入区两个区域的中红外量子级联激光器（QCL）结构，这些区域具有不同的特征重要性水平。通过使用DNN-TP代理模型代替计算成本高的数值模拟，优化速度提高了超过80,000倍，允许大规模探索QCL设计空间。PBTL的应用提高了预测准确性，减少了训练数据需求，并提高了优化过程中的器件结构可行性。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地解决了光子器件优化中的挑战，提高了设计自动化水平，并为数据资源有限的情况提供了高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a neural network(NN)-based surrogate modeling framework forphotonic device optimization, especially in domains with imbalanced featureimportance and high data generation costs. Our framework, which comprisesphysics-based transfer learning (PBTL)-enhanced surrogate modeling andscalarized multi-objective genetic algorithms (GAs), offers a generalizablesolution for photonic design automation with minimal data resources.To validatethe framework, we optimize mid-infrared quantum cascade laser (QCL) structuresconsisting of two regions, active and injection, which have different levels offeature importance. The optimization targets include five key QCL performancemetrics such as modal gain, emission wavelength, linewidth, and effectiveinjection, extraction energies. To address the challenge of multiple localoptima in the output latent space, we integrate a deep neural network totalpredictor (DNN-TP) with a GA, enabling scalable and nature-inspiredoptimization. By replacing computationally expensive numerical simulations withthe DNN-TP surrogate model, the optimization achieves a speed-up of over 80,000times, allowing large-scale exploration of the QCL design space.To improvemodel generalization with limited data, we introduce PBTL, which transfersknowledge from a DNN core predictor (DNN-CP) trained on active-regionstructures. This approach yields a 0.69 percentage increase in predictionaccuracy, equivalent to a 50 percentage reduction in training datarequirements, and leads to generate more feasible device structure with 60percentage improvement in evaluation metric during optimization.</description>
      <author>example@mail.com (Gibaek Kim, Jungho Kim)</author>
      <guid isPermaLink="false">2506.10418v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>SpikeSMOKE: Spiking Neural Networks for Monocular 3D Object Detection with Cross-Scale Gated Coding</title>
      <link>http://arxiv.org/abs/2506.07737v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SpikeSMOKE的基于脉冲神经网络（SNNs）的低功耗单目3D物体检测架构，旨在解决自动驾驶等应用场景中3D物体检测的能量消耗问题。&lt;h4&gt;背景&lt;/h4&gt;随着3D物体检测在自动驾驶等领域的广泛应用，其能量消耗问题日益突出。&lt;h4&gt;目的&lt;/h4&gt;通过应用SNNs技术，提出一种低功耗的单目3D物体检测方法。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种名为CSGC的跨尺度门控编码机制，通过结合跨尺度融合的注意力方法和门控滤波机制来增强特征表示能力；2. 设计了一种轻量级的残差块，以保持脉冲计算范式并提高检测性能；3. 在KITTI自动驾驶数据集上进行了实验验证。&lt;h4&gt;主要发现&lt;/h4&gt;1. 与传统的SNNs相比，SpikeSMOKE在保持高检测性能的同时，能够显著降低能量消耗；2. 在困难类别上，能量消耗可以降低72.2%，而检测性能仅降低4%；3. SpikeSMOKE-L（轻量级）相比SMOKE，参数数量减少了3倍，计算量减少了10倍。&lt;h4&gt;结论&lt;/h4&gt;SpikeSMOKE是一种有效的低功耗单目3D物体检测方法，在降低能量消耗的同时，保持了较高的检测性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low energy consumption for 3D object detection is an important research areabecause of the increasing energy consumption with their wide application infields such as autonomous driving. The spiking neural networks (SNNs) withlow-power consumption characteristics can provide a novel solution for thisresearch. Therefore, we apply SNNs to monocular 3D object detection and proposethe SpikeSMOKE architecture in this paper, which is a new attempt for low-powermonocular 3D object detection. As we all know, discrete signals of SNNs willgenerate information loss and limit their feature expression ability comparedwith the artificial neural networks (ANNs).In order to address this issue,inspired by the filtering mechanism of biological neuronal synapses, we proposea cross-scale gated coding mechanism(CSGC), which can enhance featurerepresentation by combining cross-scale fusion of attentional methods and gatedfiltering mechanisms.In addition, to reduce the computation and increase thespeed of training, we present a novel light-weight residual block that canmaintain spiking computing paradigm and the highest possible detectionperformance. Compared to the baseline SpikeSMOKE under the 3D Object Detection,the proposed SpikeSMOKE with CSGC can achieve 11.78 (+2.82, Easy), 10.69 (+3.2,Moderate), and 10.48 (+3.17, Hard) on the KITTI autonomous driving dataset byAP|R11 at 0.7 IoU threshold, respectively. It is important to note that theresults of SpikeSMOKE can significantly reduce energy consumption compared tothe results on SMOKE. For example,the energy consumption can be reduced by72.2% on the hard category, while the detection performance is reduced by only4%. SpikeSMOKE-L (lightweight) can further reduce the amount of parameters by 3times and computation by 10 times compared to SMOKE.</description>
      <author>example@mail.com (Xuemei Chen, Huamin Wang, Hangchi Shen, Shukai Duan, Shiping Wen, Tingwen Huang)</author>
      <guid isPermaLink="false">2506.07737v2</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Graph-MLLM: Harnessing Multimodal Large Language Models for Multimodal Graph Learning</title>
      <link>http://arxiv.org/abs/2506.10282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了多模态大型语言模型（MLLMs）在多模态表示和理解方面的能力，并提出了Graph-MLLM，一个用于多模态图学习的综合基准，以评估不同的学习范式。&lt;h4&gt;背景&lt;/h4&gt;MLLMs在多模态表示和理解方面表现出色，但通常只关注成对模态的对齐，而忽略了数据点之间的结构关系。&lt;h4&gt;目的&lt;/h4&gt;提出Graph-MLLM，旨在为多模态图学习提供一个统一的基准，以公平地评估不同的学习范式。&lt;h4&gt;方法&lt;/h4&gt;Graph-MLLM通过系统地评估三种范式（编码器、对齐器和预测器）在六个不同领域的六个数据集上，来构建一个综合基准。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，联合考虑节点的视觉和文本属性对图学习有益；将视觉属性转换为文本描述比直接使用视觉输入有更好的性能；在特定MMG上微调MLLM可以在大多数情况下实现最先进的成果，即使没有显式的图结构信息。&lt;h4&gt;结论&lt;/h4&gt;Graph-MLLM的提出有助于快速、公平地评估多模态图学习，并激发该领域的进一步创新研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have demonstrated remarkablecapabilities in representing and understanding diverse modalities. However,they typically focus on modality alignment in a pairwise manner whileoverlooking structural relationships across data points. Integratingmultimodality with structured graph information (i.e., multimodal graphs, MMGs)is essential for real-world applications such as social networks, healthcare,and recommendation systems. Existing MMG learning methods fall into threeparadigms based on how they leverage MLLMs: Encoder, Aligner, and Predictor.MLLM-as-Encoder focuses on enhancing graph neural networks (GNNs) viamultimodal feature fusion; MLLM-as-Aligner aligns multimodal attributes inlanguage or hidden space to enable LLM-based graph reasoning; MLLM-as-Predictortreats MLLMs as standalone reasoners with in-context learning or fine-tuning.Despite their advances, the MMG field lacks a unified benchmark to fairlyevaluate across these approaches, making it unclear what progress has beenmade. To bridge this gap, we present Graph-MLLM, a comprehensive benchmark formultimodal graph learning by systematically evaluating these three paradigmsacross six datasets with different domains. Through extensive experiments, weobserve that jointly considering the visual and textual attributes of the nodesbenefits graph learning, even when using pre-trained text-to-image alignmentmodels (e.g., CLIP) as encoders. We also find that converting visual attributesinto textual descriptions further improves performance compared to directlyusing visual inputs. Moreover, we observe that fine-tuning MLLMs on specificMMGs can achieve state-of-the-art results in most scenarios, even withoutexplicit graph structure information. We hope that our open-sourced librarywill facilitate rapid, equitable evaluation and inspire further innovativeresearch in this field.</description>
      <author>example@mail.com (Jiajin Liu, Dongzhe Fan, Jiacheng Shen, Chuanhao Ji, Daochen Zha, Qiaoyu Tan)</author>
      <guid isPermaLink="false">2506.10282v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty-Aware Deep Learning for Automated Skin Cancer Classification: A Comprehensive Evaluation</title>
      <link>http://arxiv.org/abs/2506.10302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究评估了基于深度学习的皮肤病变分类方法，通过迁移学习和不确定性量化技术，在HAM10000数据集上实现了皮肤癌诊断的准确性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;准确可靠的皮肤癌诊断对早期治疗和改善患者预后至关重要。深度学习模型在自动化皮肤癌分类方面显示出潜力，但其性能可能受限于数据稀缺和缺乏不确定性意识。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过迁移学习和不确定性量化技术，提高基于深度学习的皮肤病变分类模型的性能和可靠性。&lt;h4&gt;方法&lt;/h4&gt;研究分为两个阶段：第一阶段，对多种预训练特征提取器（如CLIP、ResNet50、DenseNet121、VGG16、EfficientNet-V2-Large）结合传统分类器（如SVM、XGBoost、逻辑回归）进行基准测试；第二阶段，采用蒙特卡洛dropout、集成和集成蒙特卡洛dropout方法进行不确定性量化。&lt;h4&gt;主要发现&lt;/h4&gt;基于CLIP的视觉变换器，特别是LAION CLIP ViT-H/14结合SVM，在分类性能上表现最佳。集成方法在准确性和不确定性处理之间提供了良好的平衡，而EMCD对不确定预测更为敏感。&lt;h4&gt;结论&lt;/h4&gt;将不确定性量化集成到基于深度学习的医疗诊断中，对于提高性能和现实世界临床应用中的可信度具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and reliable skin cancer diagnosis is critical for early treatmentand improved patient outcomes. Deep learning (DL) models have shown promise inautomating skin cancer classification, but their performance can be limited bydata scarcity and a lack of uncertainty awareness. In this study, we present acomprehensive evaluation of DL-based skin lesion classification using transferlearning and uncertainty quantification (UQ) on the HAM10000 dataset. In thefirst phase, we benchmarked several pre-trained feature extractors-includingContrastive Language-Image Pretraining (CLIP) variants, Residual Network-50(ResNet50), Densely Connected Convolutional Network (DenseNet121), VisualGeometry Group network (VGG16), and EfficientNet-V2-Large-combined with a rangeof traditional classifiers such as Support Vector Machine (SVM), eXtremeGradient Boosting (XGBoost), and logistic regression. Our results show thatCLIP-based vision transformers, particularly LAION CLIP ViT-H/14 with SVM,deliver the highest classification performance. In the second phase, weincorporated UQ using Monte Carlo Dropout (MCD), Ensemble, and Ensemble MonteCarlo Dropout (EMCD) to assess not only prediction accuracy but also thereliability of model outputs. We evaluated these models using uncertainty-awaremetrics such as uncertainty accuracy(UAcc), uncertainty sensitivity(USen),uncertainty specificity(USpe), and uncertainty precision(UPre). The resultsdemonstrate that ensemble methods offer a good trade-off between accuracy anduncertainty handling, while EMCD is more sensitive to uncertain predictions.This study highlights the importance of integrating UQ into DL-based medicaldiagnosis to enhance both performance and trustworthiness in real-worldclinical applications.</description>
      <author>example@mail.com (Hamzeh Asgharnezhad, Pegah Tabarisaadi, Abbas Khosravi, Roohallah Alizadehsani, U. Rajendra Acharya)</author>
      <guid isPermaLink="false">2506.10302v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Error Assessment of CAD Models for Aircraft Manufacturing-and-Measurement</title>
      <link>http://arxiv.org/abs/2506.10594v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HEA-MM的新型分层误差评估框架，用于评估飞机CAD模型在制造和测量平台中的质量。&lt;h4&gt;背景&lt;/h4&gt;航空设备最重要的特征是高质量，包括高性能、高稳定性和高可靠性。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法来评估飞机CAD模型的误差。&lt;h4&gt;方法&lt;/h4&gt;HEA-MM使用结构光扫描仪获取制造工件的综合3D测量，并将测量得到的点云与参考CAD模型进行配准，随后在三个层次上进行误差分析：全局、部件和特征。&lt;h4&gt;主要发现&lt;/h4&gt;在全局层次上评估扫描点云与参考CAD模型的总体偏差；在部件层次上，对点云下的补丁进行误差分析，并提出了一种基于优化的原始补丁细化方法；在特征层次上，对CAD模型中常见的圆形孔进行误差分析，并引入了两阶段算法以检测圆形孔。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，该方法在各种飞机CAD模型上有效。&lt;h4&gt;翻译&lt;/h4&gt;摘要：航空设备最重要的特征是高质量，包括高性能、高稳定性和高可靠性。在本文中，我们提出了一种新的分层误差评估框架，称为HEA-MM，用于制造和测量平台内的飞机CAD模型。HEA-MM采用结构光扫描仪获取制造工件的综合3D测量。测量的点云与参考CAD模型配准，然后在三个层次上进行误差分析：全局、部件和特征。在全局层次上，误差分析评估扫描点云与参考CAD模型的总体偏差。在部件层次上，对点云下的补丁进行误差分析。我们提出了一种基于优化的原始补丁细化方法。引入了两种基本操作，分割和合并，以细化粗糙的原语。在特征层次上，对CAD模型中常见的圆形孔进行误差分析。为此，引入了两阶段算法进行圆形孔的检测。首先，使用张量投票算法识别边缘点。然后，通过假设和聚类框架拟合多个圆，确保准确检测和分析圆形特征。在各种飞机CAD模型上的实验结果表明了所提出方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The most essential feature of aviation equipment is high quality, includinghigh performance, high stability and high reliability. In this paper, wepropose a novel hierarchical error assessment framework for aircraft CAD modelswithin a manufacturing-and-measurement platform, termed HEA-MM. HEA-MM employsstructured light scanners to obtain comprehensive 3D measurements ofmanufactured workpieces. The measured point cloud is registered with thereference CAD model, followed by an error analysis conducted at threehierarchical levels: global, part, and feature. At the global level, the erroranalysis evaluates the overall deviation of the scanned point cloud from thereference CAD model. At the part level, error analysis is performed on thesepatches underlying the point clouds. We propose a novel optimization-basedprimitive refinement method to obtain a set of meaningful patches of pointclouds. Two basic operations, splitting and merging, are introduced to refinethe coarse primitives. At the feature level, error analysis is performed oncircular holes, which are commonly found in CAD models. To facilitate it, atwo-stage algorithm is introduced for the detection of circular holes. First,edge points are identified using a tensor-voting algorithm. Then, multiplecircles are fitted through a hypothesize-and-clusterize framework, ensuringaccurate detection and analysis of the circular features. Experimental resultson various aircraft CAD models demonstrate the effectiveness of our proposedmethod.</description>
      <author>example@mail.com (Jin Huang, Honghua Chen, Mingqiang Wei)</author>
      <guid isPermaLink="false">2506.10594v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Structural-Spectral Graph Convolution with Evidential Edge Learning for Hyperspectral Image Clustering</title>
      <link>http://arxiv.org/abs/2506.09920v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的HSI聚类方法，通过改进超像素分割和图神经网络，提高了大规模HSI数据的聚类准确性。&lt;h4&gt;背景&lt;/h4&gt;HSI聚类是一项重要但具有挑战性的任务，目前大多数方法依赖于超像素分割和图神经网络，但现有方法无法充分利用HSI的谱信息，且超像素拓扑图的不准确性可能导致类语义混淆。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来提高HSI聚类准确性，同时解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;1. 提出一种结构-光谱图卷积算子（SSGCO）来提高超像素表示质量；2. 提出一种证据引导的自适应边缘学习模块（EGAEL）来预测和细化超像素拓扑图中的边缘权重；3. 将提出的方法集成到对比学习框架中，实现表示学习和聚类。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在四个HSI数据集上比最佳比较方法提高了2.61%，6.06%，4.96%和3.15%的聚类准确性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法有效地提高了HSI聚类准确性，并通过开源代码实现了其应用。&lt;h4&gt;翻译&lt;/h4&gt;Hyperspectral image (HSI) clustering assigns similar pixels to the same class without any annotations, which is an important yet challenging task. For large-scale HSIs, most methods rely on superpixel segmentation and perform superpixel-level clustering based on graph neural networks (GNNs). However, existing GNNs cannot fully exploit the spectral information of the input HSI, and the inaccurate superpixel topological graph may lead to the confusion of different class semantics during information aggregation. To address these challenges, we first propose a structural-spectral graph convolutional operator (SSGCO) tailored for graph-structured HSI superpixels to improve their representation quality through the co-extraction of spatial and spectral features. Second, we propose an evidence-guided adaptive edge learning (EGAEL) module that adaptively predicts and refines edge weights in the superpixel topological graph. We integrate the proposed method into a contrastive learning framework to achieve clustering, where representation learning and clustering are simultaneously conducted. Experiments demonstrate that the proposed method improves clustering accuracy by 2.61%, 6.06%, 4.96% and 3.15% over the best compared methods on four HSI datasets. Our code is available at https://github.com/jhqi/SSGCO-EGAEL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperspectral image (HSI) clustering assigns similar pixels to the same classwithout any annotations, which is an important yet challenging task. Forlarge-scale HSIs, most methods rely on superpixel segmentation and performsuperpixel-level clustering based on graph neural networks (GNNs). However,existing GNNs cannot fully exploit the spectral information of the input HSI,and the inaccurate superpixel topological graph may lead to the confusion ofdifferent class semantics during information aggregation. To address thesechallenges, we first propose a structural-spectral graph convolutional operator(SSGCO) tailored for graph-structured HSI superpixels to improve theirrepresentation quality through the co-extraction of spatial and spectralfeatures. Second, we propose an evidence-guided adaptive edge learning (EGAEL)module that adaptively predicts and refines edge weights in the superpixeltopological graph. We integrate the proposed method into a contrastive learningframework to achieve clustering, where representation learning and clusteringare simultaneously conducted. Experiments demonstrate that the proposed methodimproves clustering accuracy by 2.61%, 6.06%, 4.96% and 3.15% over the bestcompared methods on four HSI datasets. Our code is available athttps://github.com/jhqi/SSGCO-EGAEL.</description>
      <author>example@mail.com (Jianhan Qi, Yuheng Jia, Hui Liu, Junhui Hou)</author>
      <guid isPermaLink="false">2506.09920v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>J-DDL: Surface Damage Detection and Localization System for Fighter Aircraft</title>
      <link>http://arxiv.org/abs/2506.10505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种智能表面损伤检测和定位系统J-DDL，用于战斗机，通过激光扫描仪和摄像头获取整个机身的2D图像和3D点云数据，实现精确的损伤检测和定位。&lt;h4&gt;背景&lt;/h4&gt;战斗机需要频繁和彻底的检查以确保安全和延长使用寿命，而传统的手动方法在可扩展性、效率和一致性方面存在限制。&lt;h4&gt;目的&lt;/h4&gt;设计一个系统，以自动化战斗机表面损伤的检测和定位，提高检查效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;J-DDL系统结合2D图像和3D点云数据，使用基于YOLO架构的损伤检测网络，包含轻量级的Fasternet模块、优化的颈架构和新的损失函数Inner-CIOU，并在2D图像上检测损伤后映射到3D点云以实现3D定位。&lt;h4&gt;主要发现&lt;/h4&gt;J-DDL系统不仅简化了检查流程，还确保了对大型复杂战斗机外部的全面和详细的覆盖，并开发了首个针对飞机损伤的公开数据集。&lt;h4&gt;结论&lt;/h4&gt;J-DDL系统在提高自动化飞机检查技术方面具有显著潜力，通过实验评估验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the safety and extended operational life of fighter aircraftnecessitates frequent and exhaustive inspections. While surface defectdetection is feasible for human inspectors, manual methods face criticallimitations in scalability, efficiency, and consistency due to the vast surfacearea, structural complexity, and operational demands of aircraft maintenance.We propose a smart surface damage detection and localization system for fighteraircraft, termed J-DDL. J-DDL integrates 2D images and 3D point clouds of theentire aircraft surface, captured using a combined system of laser scanners andcameras, to achieve precise damage detection and localization. Central to oursystem is a novel damage detection network built on the YOLO architecture,specifically optimized for identifying surface defects in 2D aircraft images.Key innovations include lightweight Fasternet blocks for efficient featureextraction, an optimized neck architecture incorporating Efficient MultiscaleAttention (EMA) modules for superior feature aggregation, and the introductionof a novel loss function, Inner-CIOU, to enhance detection accuracy. Afterdetecting damage in 2D images, the system maps the identified anomalies ontocorresponding 3D point clouds, enabling accurate 3D localization of defectsacross the aircraft surface. Our J-DDL not only streamlines the inspectionprocess but also ensures more comprehensive and detailed coverage of large andcomplex aircraft exteriors. To facilitate further advancements in this domain,we have developed the first publicly available dataset specifically focused onaircraft damage. Experimental evaluations validate the effectiveness of ourframework, underscoring its potential to significantly advance automatedaircraft inspection technologies.</description>
      <author>example@mail.com (Jin Huang, Mingqiang Wei, Zikuan Li, Hangyu Qu, Wei Zhao, Xinyu Bai)</author>
      <guid isPermaLink="false">2506.10505v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Going beyond density functional theory accuracy: Leveraging experimental data to refine pre-trained machine learning interatomic potentials</title>
      <link>http://arxiv.org/abs/2506.10211v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用轨迹重加权技术来改进DFT预训练的机器学习原子间势（MLIPs），以匹配目标实验EXAFS光谱的方法。&lt;h4&gt;背景&lt;/h4&gt;MLIPs的准确性受限于训练数据，这些数据通常来自量子力学计算，如DFT。由于DFT本身基于多个近似，MLIPs可能会继承系统误差，导致与实验数据的偏差。&lt;h4&gt;目的&lt;/h4&gt;提高MLIPs与实验EXAFS光谱的一致性，并改善MLIPs对其他结构性质的预测。&lt;h4&gt;方法&lt;/h4&gt;使用轨迹重加权技术，结合迁移学习和少量训练周期，避免过拟合有限的实验数据。&lt;h4&gt;主要发现&lt;/h4&gt;该方法显著提高了两个MLIPs的性能，一个用于已建立的重核燃料：二氧化铀（UO$_2$），另一个用于核燃料候选者：一氧化铀（UN）。通过比较原始DFT基于的MLIP和EXAFS改进的MLIP在多个性质上的结果，如晶格参数、体积模量、比热容、点缺陷能、弹性常数、声子散射光谱和扩散系数等，验证了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;对于核燃料而言，准确的MLIPs非常有益，因为它能够实现可靠的原子级模拟，大大减少了传统上用于高效和耐用的燃料候选者认证的大量昂贵且危险的实验核积分测试的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning interatomic potentials (MLIPs) are inherently limited by theaccuracy of the training data, usually consisting of energies and forcesobtained from quantum mechanical calculations, such as density functionaltheory (DFT). Since DFT itself is based on several approximations, MLIPs mayinherit systematic errors that lead to discrepancies with experimental data. Inthis paper, we use a trajectory re-weighting technique to refine DFTpre-trained MLIPs to match the target experimental Extended X-ray AbsorptionFine Structure (EXAFS) spectra. EXAFS spectra are sensitive to the localstructural environment around an absorbing atom. Thus, refining an MLIP toimprove agreement with experimental EXAFS spectra also improves the MLIPprediction of other structural properties that are not directly involved in therefinement process. We combine this re-weighting technique with transferlearning and a minimal number of training epochs to avoid overfitting to thelimited experimental data. The refinement approach demonstrates significantimprovement for two MLIPs reported in previous work, one for an establishednuclear fuel: uranium dioxide (UO$_2$) and second one for a nuclear fuelcandidate: uranium mononitride (UN). We validate the effectiveness of ourapproach by comparing the results obtained from the original (unrefined)DFT-based MLIP and the EXAFS-refined MLIP across various properties, such aslattice parameters, bulk modulus, heat capacity, point defect energies, elasticconstants, phonon dispersion spectra, and diffusion coefficients. An accurateMLIP for nuclear fuels is extremely beneficial as it enables reliable atomisticsimulation, which greatly reduces the need for large number of expensive andinherently dangerous experimental nuclear integral tests, traditionallyrequired for the qualification of efficient and resilient fuel candidates.</description>
      <author>example@mail.com (Shriya Gumber, Lorena Alzate-Vargas, Benjamin T. Nebgen, Arjen van Veelen, Smit Kadvani, Tammie Gibson, Richard Messerly)</author>
      <guid isPermaLink="false">2506.10211v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Guided Graph Compression for Quantum Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.09862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Graph Neural Networks（GNNs）在处理图结构数据方面的有效性，但指出其在处理大型图时面临的内存需求和GPU上稀疏矩阵操作效率低下的问题。量子计算（QC）为解决这些问题提供了新的思路，并激发了新的算法方法。特别是，量子图神经网络（QGNNs）在近期文献中被探讨。然而，现有的量子硬件限制了可有效编码的数据维度。现有方法要么手动简化数据集，要么使用人工图数据集。本文提出了Guided Graph Compression（GGC）框架，该框架使用图自动编码器来减少节点数量和节点特征的维度。压缩过程旨在增强下游分类任务的表现，该任务可以使用量子或经典分类器进行。该框架在Jet Tagging任务上进行了评估，这是一个在粒子物理学中区分由夸克和胶子引发的粒子喷注的基本分类问题。GGC与将自动编码器作为独立预处理步骤以及与基线经典GNN分类器进行了比较。数值结果表明，GGC优于这两种替代方案，同时也有助于在现实数据集上测试新的QGNN方法。&lt;h4&gt;背景&lt;/h4&gt;GNNs在处理图结构数据时面临内存需求和稀疏矩阵操作效率低下的问题，量子计算为解决这些问题提供了新的思路。&lt;h4&gt;目的&lt;/h4&gt;提出GGC框架，通过图自动编码器减少节点数量和节点特征的维度，以提高下游分类任务的表现。&lt;h4&gt;方法&lt;/h4&gt;使用图自动编码器进行数据压缩，并将压缩过程指导以增强分类任务的表现。&lt;h4&gt;主要发现&lt;/h4&gt;GGC在Jet Tagging任务上优于其他替代方案，并有助于测试新的QGNN方法。&lt;h4&gt;结论&lt;/h4&gt;GGC框架在提高GNN处理大型图结构数据的能力方面是有效的，并且可以应用于量子或经典分类器。&lt;h4&gt;翻译&lt;/h4&gt;Graph神经网络（GNNs）在处理图结构数据方面非常有效，但由于高内存需求和在GPU上对稀疏矩阵操作的低效，在处理大型图时面临挑战。量子计算（QC）为解决这些问题提供了一个有希望的方法，并激发了一系列新的算法方法。特别是，近期文献中已经探讨了量子图神经网络（QGNNs）。然而，现有的量子硬件限制了可以有效地编码的数据维度。现有的方法要么手动简化数据集，要么使用人工图数据集。本研究引入了引导图压缩（GGC）框架，该框架使用图自动编码器来减少节点数量和节点特征的维度。压缩过程旨在增强下游分类任务的表现，可以使用量子或经典分类器。该框架在Jet Tagging任务上进行了评估，这是一个在粒子物理学中区分由夸克和胶子引发的粒子喷注的基本分类问题。GGC与将自动编码器作为独立预处理步骤以及与基线经典GNN分类器进行了比较。我们的数值结果表明，GGC优于这两种替代方案，同时也有助于在现实数据集上测试新的QGNN方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are effective for processing graph-structureddata but face challenges with large graphs due to high memory requirements andinefficient sparse matrix operations on GPUs. Quantum Computing (QC) offers apromising avenue to address these issues and inspires new algorithmicapproaches. In particular, Quantum Graph Neural Networks (QGNNs) have beenexplored in recent literature. However, current quantum hardware limits thedimension of the data that can be effectively encoded. Existing approacheseither simplify datasets manually or use artificial graph datasets. This workintroduces the Guided Graph Compression (GGC) framework, which uses a graphautoencoder to reduce both the number of nodes and the dimensionality of nodefeatures. The compression is guided to enhance the performance of a downstreamclassification task, which can be applied either with a quantum or a classicalclassifier. The framework is evaluated on the Jet Tagging task, aclassification problem of fundamental importance in high energy physics thatinvolves distinguishing particle jets initiated by quarks from those by gluons.The GGC is compared against using the autoencoder as a standalone preprocessingstep and against a baseline classical GNN classifier. Our numerical resultsdemonstrate that GGC outperforms both alternatives, while also facilitating thetesting of novel QGNN ansatzes on realistic datasets.</description>
      <author>example@mail.com (Mikel Casals, Vasilis Belis, Elias F. Combarro, Eduard Alarcón, Sofia Vallecorsa, Michele Grossi)</author>
      <guid isPermaLink="false">2506.09862v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Causal Inference via Prior-Data Fitted Networks</title>
      <link>http://arxiv.org/abs/2506.10914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CausalFM的综合框架，用于在各种因果推断场景中训练基于PFN的基础模型。&lt;h4&gt;背景&lt;/h4&gt;PFNs是一种Transformer，通过在合成数据上预训练并实现情境学习，使得贝叶斯推断成为可能。&lt;h4&gt;目的&lt;/h4&gt;开发CausalFM框架，使其能够进行贝叶斯因果推断，包括后门、前门和工具变量调整。&lt;h4&gt;方法&lt;/h4&gt;1. 基于结构因果模型（SCM）原则性地构建贝叶斯先验，并推导出此类先验有效性的必要标准。2. 提出一种新的先验分布族，使用因果启发式贝叶斯神经网络。3. 实例化CausalFM，并显式训练一个用于估计条件平均处理效应（CATEs）的基础模型，使用后门调整。&lt;h4&gt;主要发现&lt;/h4&gt;CausalFM在CATE估计方面表现出竞争力，并在多种合成和半合成基准测试中表现出色。&lt;h4&gt;结论&lt;/h4&gt;CausalFM为因果推断提供了一个新的范式，有潜力在医学、经济学和其他学科中改变实践者的因果推断方式。&lt;h4&gt;翻译&lt;/h4&gt;Prior-data fitted networks (PFNs) have recently been proposed as a promising way to train tabular foundation models. PFNs are transformers that are pre-trained on synthetic data generated from a prespecified prior distribution and that enable Bayesian inference through in-context learning. In this paper, we introduce CausalFM, a comprehensive framework for training PFN-based foundation models in various causal inference settings. First, we formalize the construction of Bayesian priors for causal inference based on structural causal models (SCMs) in a principled way and derive necessary criteria for the validity of such priors. Building on this, we propose a novel family of priordistributions using causality-inspired Bayesian neural networks that enable CausalFM to perform Bayesian causal inference in various settings, including back-door, front-door, and instrumental variable adjustment. Finally, we instantiate CausalFM and explicitly train a foundation model for estimating conditional average treatment effects (CATEs) using back-door adjustment. We show that CausalFM performs competitively for CATE estimation using various synthetic and semi-synthetic benchmarks. In sum, our framework can be used as a general recipe to train foundation models for various causal inferencesettings. In contrast to the current state-of-the-art in causal inference, CausalFM offers a novel paradigm with the potential to fundamentally change how practitioners perform causal inference in medicine, economics, and other disciplines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prior-data fitted networks (PFNs) have recently been proposed as a promisingway to train tabular foundation models. PFNs are transformers that arepre-trained on synthetic data generated from a prespecified prior distributionand that enable Bayesian inference through in-context learning. In this paper,we introduce CausalFM, a comprehensive framework for training PFN-basedfoundation models in various causal inference settings. First, we formalize theconstruction of Bayesian priors for causal inference based on structural causalmodels (SCMs) in a principled way and derive necessary criteria for thevalidity of such priors. Building on this, we propose a novel family of priordistributions using causality-inspired Bayesian neural networks that enableCausalFM to perform Bayesian causal inference in various settings, includingback-door, front-door, and instrumental variable adjustment. Finally, weinstantiate CausalFM and explicitly train a foundation model for estimatingconditional average treatment effects (CATEs) using back-door adjustment. Weshow that CausalFM performs competitively for CATE estimation using varioussynthetic and semi-synthetic benchmarks. In sum, our framework can be used as ageneral recipe to train foundation models for various causal inferencesettings. In contrast to the current state-of-the-art in causal inference,CausalFM offers a novel paradigm with the potential to fundamentally change howpractitioners perform causal inference in medicine, economics, and otherdisciplines.</description>
      <author>example@mail.com (Yuchen Ma, Dennis Frauen, Emil Javurek, Stefan Feuerriegel)</author>
      <guid isPermaLink="false">2506.10914v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>PointGS: Point Attention-Aware Sparse View Synthesis with Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.10335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于点特征感知的高斯分层渲染框架，从稀疏训练视图中实现实时、高质量的渲染。&lt;h4&gt;背景&lt;/h4&gt;3D高斯分层渲染（3DGS）技术在渲染速度和视觉质量上优于神经辐射场（NeRF），但现有方法需要大量校准视图来生成一致的场景表示。&lt;h4&gt;目的&lt;/h4&gt;解决3DGS在输入视图有限时，容易过拟合训练视图的问题，导致渲染质量下降。&lt;h4&gt;方法&lt;/h4&gt;采用最新的立体基础模型估计准确的相机姿态并重建密集点云；通过采样和聚合稀疏输入的多尺度二维外观特征来编码每个3D高斯的光谱属性；设计基于自注意力机制的点交互网络以增强点级外观表示；通过两个轻量级多层感知器（MLP）将丰富特征解码为高斯参数。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多样化的基准测试中显著优于基于NeRF的方法，在少样本设置下与最先进的3DGS方法相比也表现出竞争力。&lt;h4&gt;结论&lt;/h4&gt;该方法有效解决了3DGS在稀疏训练视图下的渲染质量问题，实现了实时、高质量的渲染。&lt;h4&gt;翻译&lt;/h4&gt;3D高斯分层渲染（3DGS）是一种创新的渲染技术，通过利用显式的3D场景表示，在渲染速度和视觉质量上超过了神经辐射场（NeRF）。现有的3DGS方法需要大量校准视图来生成一致且完整的场景表示。当输入视图有限时，3DGS往往会过拟合训练视图，导致渲染质量明显下降。为了解决这一限制，我们提出了一种点特征感知的高斯分层框架，可以从稀疏训练视图中实现实时、高质量渲染。具体来说，我们首先采用最新的立体基础模型来估计准确的相机姿态并重建密集点云以进行高斯初始化。然后，通过从稀疏输入中采样和聚合多尺度二维外观特征来编码每个3D高斯的光谱属性。为了增强点级外观表示，我们设计了一个基于自注意力机制的点交互网络，允许每个高斯点与其最近邻点交互。这些增强特征随后通过两个轻量级多层感知器（MLP）解码为高斯参数以进行最终渲染。在多样化的基准测试中的大量实验表明，我们的方法在性能上显著优于基于NeRF的方法，并且在少样本设置下与最先进的3DGS方法相比也取得了具有竞争力的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian splatting (3DGS) is an innovative rendering technique thatsurpasses the neural radiance field (NeRF) in both rendering speed and visualquality by leveraging an explicit 3D scene representation. Existing 3DGSapproaches require a large number of calibrated views to generate a consistentand complete scene representation. When input views are limited, 3DGS tends tooverfit the training views, leading to noticeable degradation in renderingquality. To address this limitation, we propose a Point-wise Feature-AwareGaussian Splatting framework that enables real-time, high-quality renderingfrom sparse training views. Specifically, we first employ the latest stereofoundation model to estimate accurate camera poses and reconstruct a densepoint cloud for Gaussian initialization. We then encode the colour attributesof each 3D Gaussian by sampling and aggregating multiscale 2D appearancefeatures from sparse inputs. To enhance point-wise appearance representation,we design a point interaction network based on a self-attention mechanism,allowing each Gaussian point to interact with its nearest neighbors. Theseenriched features are subsequently decoded into Gaussian parameters through twolightweight multi-layer perceptrons (MLPs) for final rendering. Extensiveexperiments on diverse benchmarks demonstrate that our method significantlyoutperforms NeRF-based approaches and achieves competitive performance underfew-shot settings compared to the state-of-the-art 3DGS methods.</description>
      <author>example@mail.com (Lintao Xiang, Hongpei Zheng, Yating Huang, Qijun Yang, Hujun Yin)</author>
      <guid isPermaLink="false">2506.10335v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Generalizing Supervised Contrastive learning: A Projection Perspective</title>
      <link>http://arxiv.org/abs/2506.09810v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了ProjNCE，这是一种InfoNCE的推广，通过引入投影函数和负样本调整项，将监督和无监督对比学习目标统一，并证明了ProjNCE是一个有效的互信息下界，提高了选择投影策略的灵活性，实验结果表明ProjNCE在多个数据集和设置中优于SupCon和标准交叉熵训练。&lt;h4&gt;背景&lt;/h4&gt;自监督对比学习（SSCL）在表示学习方面表现强大，但监督对比学习（SupCon）在此领域的关注较少，特别是SupCon与互信息（MI）之间的关系尚未探索。&lt;h4&gt;目的&lt;/h4&gt;填补SupCon与MI关系的研究空白，提出ProjNCE来统一监督和无监督对比学习目标，并提高其在选择投影策略方面的灵活性。&lt;h4&gt;方法&lt;/h4&gt;引入ProjNCE，这是一种InfoNCE的推广，包含投影函数和负样本调整项，并在SupCon中探索基于质心的类嵌入和多种投影方法。&lt;h4&gt;主要发现&lt;/h4&gt;ProjNCE是一个有效的MI下界，提供了选择投影策略的灵活性，实验表明ProjNCE在多个数据集和设置中优于SupCon和标准交叉熵训练。&lt;h4&gt;结论&lt;/h4&gt;ProjNCE改进了SupCon，从互信息解释和投影设计两个互补的角度出发，为SupCon作为基础对比学习目标时提供了广泛适用的改进。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised contrastive learning (SSCL) has emerged as a powerful paradigm for representation learning and has been studied from multiple perspectives, including mutual information and geometric viewpoints. However, supervised contrastive (SupCon) approaches have received comparatively little attention in this context: for instance, while InfoNCE used in SSCL is known to form a lower bound on mutual information (MI), the relationship between SupCon and MI remains unexplored. To address this gap, we introduce ProjNCE, a generalization of the InfoNCE loss that unifies supervised and self-supervised contrastive objectives by incorporating projection functions and an adjustment term for negative pairs. We prove that ProjNCE constitutes a valid MI bound and affords greater flexibility in selecting projection strategies for class embeddings. Building on this flexibility, we further explore the centroid-based class embeddings in SupCon by exploring a variety of projection methods. Extensive experiments on multiple datasets and settings demonstrate that ProjNCE consistently outperforms both SupCon and standard cross-entropy training. Our work thus refines SupCon along two complementary perspectives--mutual information interpretation and projection design--and offers broadly applicable improvements whenever SupCon serves as the foundational contrastive objective.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised contrastive learning (SSCL) has emerged as a powerfulparadigm for representation learning and has been studied from multipleperspectives, including mutual information and geometric viewpoints. However,supervised contrastive (SupCon) approaches have received comparatively littleattention in this context: for instance, while InfoNCE used in SSCL is known toform a lower bound on mutual information (MI), the relationship between SupConand MI remains unexplored. To address this gap, we introduce ProjNCE, ageneralization of the InfoNCE loss that unifies supervised and self-supervisedcontrastive objectives by incorporating projection functions and an adjustmentterm for negative pairs. We prove that ProjNCE constitutes a valid MI bound andaffords greater flexibility in selecting projection strategies for classembeddings. Building on this flexibility, we further explore the centroid-basedclass embeddings in SupCon by exploring a variety of projection methods.Extensive experiments on multiple datasets and settings demonstrate thatProjNCE consistently outperforms both SupCon and standard cross-entropytraining. Our work thus refines SupCon along two complementaryperspective--mutual information interpretation and projection design--andoffers broadly applicable improvements whenever SupCon serves as thefoundational contrastive objective.</description>
      <author>example@mail.com (Minoh Jeong, Alfred Hero)</author>
      <guid isPermaLink="false">2506.09810v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Learning-Enhanced MPC for Safe Crowd Navigation with Heterogeneous Constraints</title>
      <link>http://arxiv.org/abs/2506.09859v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于动态环境中具有异构约束的机器人导航的分层框架。&lt;h4&gt;背景&lt;/h4&gt;研究背景为动态环境中的机器人导航问题。&lt;h4&gt;目的&lt;/h4&gt;目的是开发一种能够有效处理动态环境中局部规划的机器人导航方法。&lt;h4&gt;方法&lt;/h4&gt;方法包括利用强化学习训练的图神经网络来估计机器人的成本到目标，以及采用考虑动力学约束的时空路径搜索模块生成参考轨迹。此外，引入了增量动作掩码机制和特权学习策略，以实现所提规划器的端到端训练。&lt;h4&gt;主要发现&lt;/h4&gt;模拟和真实世界实验表明，所提方法在复杂动态环境中的局部规划方面表现出色，达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;与现有的学习优化混合方法相比，该方法消除了对高保真模拟环境的依赖，在计算效率和训练可扩展性方面提供了显著优势。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we propose a novel hierarchical framework for robot navigation in dynamic environments with heterogeneous constraints. Our approach leverages a graph neural network trained via reinforcement learning (RL) to efficiently estimate the robot's cost-to-go, formulated as local goal recommendations. As a spatial-temporal path-searching module, which accounts for kinematic constraints, is then employed to generate a reference trajectory to facilitate solving the non-convex optimization problem used for explicit constraint enforcement. More importantly, we introduce an incremental action-masking mechanism and a privileged learning strategy, enabling end-to-end training of the proposed planner. Both simulation and real-world experiments demonstrate that the proposed method effectively addresses local planning in complex dynamic environments, achieving state-of-the-art (SOTA) performance. Compared with existing learning-optimization hybrid methods, our approach eliminates the dependency on high-fidelity simulation environments, offering significant advantages in computational efficiency and training scalability. The code will be released as open-source upon acceptance of the paper.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel hierarchical framework for robot navigationin dynamic environments with heterogeneous constraints. Our approach leveragesa graph neural network trained via reinforcement learning (RL) to efficientlyestimate the robot's cost-to-go, formulated as local goal recommendations. Aspatio-temporal path-searching module, which accounts for kinematicconstraints, is then employed to generate a reference trajectory to facilitatesolving the non-convex optimization problem used for explicit constraintenforcement. More importantly, we introduce an incremental action-maskingmechanism and a privileged learning strategy, enabling end-to-end training ofthe proposed planner. Both simulation and real-world experiments demonstratethat the proposed method effectively addresses local planning in complexdynamic environments, achieving state-of-the-art (SOTA) performance. Comparedwith existing learning-optimization hybrid methods, our approach eliminates thedependency on high-fidelity simulation environments, offering significantadvantages in computational efficiency and training scalability. The code willbe released as open-source upon acceptance of the paper.</description>
      <author>example@mail.com (Huajian Liu, Yixuan Feng, Wei Dong, Kunpeng Fan, Chao Wang, Yongzhuo Gao)</author>
      <guid isPermaLink="false">2506.09859v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Discovering Hierarchical Latent Capabilities of Language Models via Causal Representation Learning</title>
      <link>http://arxiv.org/abs/2506.10378v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种因果表示学习框架，用于评估语言模型的能力，并通过实际数据验证了该方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;对语言模型能力的忠实评估对于模型发展至关重要，但在这个领域进行严格的因果评估存在方法学挑战，包括复杂的混杂效应和与大量重新训练相关的计算成本。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一种新的因果表示学习框架。&lt;h4&gt;方法&lt;/h4&gt;该方法将观察到的基准性能建模为几个潜在能力因素的线性变换，并通过控制基础模型作为共同混杂因素来识别这些潜在因素之间的因果相关性。&lt;h4&gt;主要发现&lt;/h4&gt;将此方法应用于包含超过1500个模型，这些模型在Open LLM Leaderboard上的六个基准测试中被评估，确定了可靠地解释观察到的性能变化的简洁的三节点线性因果结构。&lt;h4&gt;结论&lt;/h4&gt;研究强调了在评估过程中仔细控制基础模型变化的重要性，这是准确揭示潜在模型能力之间潜在因果关系的关键步骤。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Faithful evaluation of language model capabilities is crucial for deriving actionable insights that can inform model development. However, rigorous causal evaluations in this domain face significant methodological challenges, including complex confounding effects and prohibitive computational costs associated with extensive retraining. To tackle these challenges, we propose a causal representation learning framework wherein observed benchmark performance is modeled as a linear transformation of a few latent capability factors. Crucially, these latent factors are identified as causally interrelated after appropriately controlling for the base model as a common confounder. Applying this approach to a comprehensive dataset encompassing over 1500 models evaluated across six benchmarks from the Open LLM Leaderboard, we identify a concise three-node linear causal structure that reliably explains the observed performance variations. Further interpretation of this causal structure provides substantial scientific insights beyond simple numerical rankings: specifically, we reveal a clear causal direction starting from general problem-solving capabilities, advancing through instruction-following proficiency, and culminating in mathematical reasoning ability. Our results underscore the essential role of carefully controlling base model variations during evaluation, a step critical to accurately uncovering the underlying causal relationships among latent model capabilities.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Faithful evaluation of language model capabilities is crucial for derivingactionable insights that can inform model development. However, rigorous causalevaluations in this domain face significant methodological challenges,including complex confounding effects and prohibitive computational costsassociated with extensive retraining. To tackle these challenges, we propose acausal representation learning framework wherein observed benchmark performanceis modeled as a linear transformation of a few latent capability factors.Crucially, these latent factors are identified as causally interrelated afterappropriately controlling for the base model as a common confounder. Applyingthis approach to a comprehensive dataset encompassing over 1500 modelsevaluated across six benchmarks from the Open LLM Leaderboard, we identify aconcise three-node linear causal structure that reliably explains the observedperformance variations. Further interpretation of this causal structureprovides substantial scientific insights beyond simple numerical rankings:specifically, we reveal a clear causal direction starting from generalproblem-solving capabilities, advancing through instruction-followingproficiency, and culminating in mathematical reasoning ability. Our resultsunderscore the essential role of carefully controlling base model variationsduring evaluation, a step critical to accurately uncovering the underlyingcausal relationships among latent model capabilities.</description>
      <author>example@mail.com (Jikai Jin, Vasilis Syrgkanis, Sham Kakade, Hanlin Zhang)</author>
      <guid isPermaLink="false">2506.10378v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Equations of state and stability condition of mixed p-spin glass model</title>
      <link>http://arxiv.org/abs/2506.10579v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了具有长程相互作用的玻璃模型，特别是混合p自旋玻璃模型，并旨在推导出其方程态，以及在一阶复制品对称破缺框架下，复制品对称解的稳定性条件和属于同一组的复制品在复制品对称破缺第一步中的稳定性。&lt;h4&gt;背景&lt;/h4&gt;Sherrington-Kirkpatrick (SK) 模型是理解自旋玻璃系统的基本模型，它基于完全连接晶格中每对自旋之间的配对相互作用，其长程相互作用简化了系统的研究，消除了波动。&lt;h4&gt;目的&lt;/h4&gt;研究混合p自旋玻璃模型的一般哈密顿量，推导其方程态，并在一阶复制品对称破缺框架下，确定复制品对称解的稳定性和属于同一组的复制品的稳定性。&lt;h4&gt;方法&lt;/h4&gt;通过引入p自旋模型，研究具有长程相互作用的自旋玻璃模型，并应用一阶复制品对称破缺理论。&lt;h4&gt;主要发现&lt;/h4&gt;研究了混合p自旋玻璃模型的方程态，并确定了复制品对称解的稳定性和属于同一组的复制品的稳定性。&lt;h4&gt;结论&lt;/h4&gt;混合p自旋玻璃模型的方程态和稳定性条件得到推导，为理解自旋玻璃系统提供了新的理论框架。&lt;h4&gt;翻译&lt;/h4&gt;The Sherrington-Kirkpatrick (SK) is a foundational model for understanding spin glass systems. It is based on the pairwise interaction between each two spins in a fully connected lattice with quenched disordered interactions. The nature of long-range interaction among spins in the (SK) model simplifies the study of this system by eliminating fluctuations. An advanced (SK) model, known as the p-spin model, introduces higher-order interactions that involve the interaction of P spins. This research focuses on the general Hamiltonian of the spin glass model with long-range interaction, referred to as the mixed p-spin glass model, which consists of adding all p-spin interaction terms. This research aims to derive the equation of states for this Hamiltonian, formulate the equation of state within the framework of the first replica symmetry breaking, and determine both the stability condition of the replica symmetry solution and the stability of the replicas belonging to the same group in the first step of replica symmetry breaking.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Sherrington-Kirkpatrick (SK) is a foundational model for understandingspin glass systems. It is based on the pairwise interaction between each twospins in a fully connected lattice with quenched disordered interactions. Thenature of long-range interaction among spins in the (SK) model simplifies thestudy of this system by eliminating fluctuations. An advanced (SK) model, knownas the p-spin model, introduces higher-order interactions that involve theinteraction of P spins. This research focuses on the general Hamiltonian of thespin glass model with long-range interaction, referred to as the mixed p-spinglass model, which consists of adding all p-spin interaction terms. Thisresearch aims to derive the equation of states for this Hamiltonian, formulatethe equation of state within the framework of the first replica symmetrybreaking, and determine both the stability condition of the replica symmetricsolution and the stability of the replicas belonging to the same group in thefirst step of replica symmetry breaking.</description>
      <author>example@mail.com (Ali Talebi)</author>
      <guid isPermaLink="false">2506.10579v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.09952v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为UniPre3D的统一预训练方法，用于处理不同规模的三维点云数据，并适用于各种架构的3D模型。&lt;h4&gt;背景&lt;/h4&gt;当前缺乏统一的3D模型和针对对象和场景级别点云的预训练方法，3D视觉中的点云数据规模多样性给统一表示学习技术带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够无缝应用于任何规模点云和任何架构3D模型的统一预训练方法。&lt;h4&gt;方法&lt;/h4&gt;方法包括预测高斯原语作为预训练任务，使用可微的高斯撒点技术渲染图像，以及通过集成预训练图像模型中的二维特征来指导模型关注几何结构。&lt;h4&gt;主要发现&lt;/h4&gt;通过在多种对象和场景级别任务上进行的广泛实验，验证了所提出方法在多样化点云模型作为骨干网络时的普适有效性。&lt;h4&gt;结论&lt;/h4&gt;UniPre3D方法在处理三维点云数据方面展现出显著的性能，并且具有广泛的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;The scale diversity of point cloud data presents significant challenges in developing unified representation learning techniques for 3D vision. Currently, there are few unified 3D models, and no existing pre-training method is equally effective for both object- and scene-level point clouds. In this paper, we introduce UniPre3D, the first unified pre-training method that can be seamlessly applied to point clouds of any scale and 3D models of any architecture. Our approach predicts Gaussian primitives as the pre-training task and employs differentiable Gaussian splatting to render images, enabling precise pixel-level supervision and end-to-end optimization. To further regulate the complexity of the pre-training task and direct the model's focus toward geometric structures, we integrate 2D features from pre-trained image models to incorporate well-established texture knowledge. We validate the universal effectiveness of our proposed method through extensive experiments across a variety of object- and scene-level tasks, using diverse point cloud models as backbones. Code is available at https://github.com/wangzy22/UniPre3D.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The scale diversity of point cloud data presents significant challenges indeveloping unified representation learning techniques for 3D vision. Currently,there are few unified 3D models, and no existing pre-training method is equallyeffective for both object- and scene-level point clouds. In this paper, weintroduce UniPre3D, the first unified pre-training method that can beseamlessly applied to point clouds of any scale and 3D models of anyarchitecture. Our approach predicts Gaussian primitives as the pre-trainingtask and employs differentiable Gaussian splatting to render images, enablingprecise pixel-level supervision and end-to-end optimization. To furtherregulate the complexity of the pre-training task and direct the model's focustoward geometric structures, we integrate 2D features from pre-trained imagemodels to incorporate well-established texture knowledge. We validate theuniversal effectiveness of our proposed method through extensive experimentsacross a variety of object- and scene-level tasks, using diverse point cloudmodels as backbones. Code is available at https://github.com/wangzy22/UniPre3D.</description>
      <author>example@mail.com (Ziyi Wang, Yanran Zhang, Jie Zhou, Jiwen Lu)</author>
      <guid isPermaLink="false">2506.09952v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Devil's Hand: Data Poisoning Attacks to Locally Private Graph Learning Protocols</title>
      <link>http://arxiv.org/abs/2506.09803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络在图表示学习中的隐私问题，提出了针对局部隐私图学习协议的数据中毒攻击，并探讨了防御策略。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在图表示学习中取得显著成功，但在处理包含敏感信息的真实世界图时，存在隐私泄露的风险。&lt;h4&gt;目的&lt;/h4&gt;为了解决隐私泄露问题，提出了利用局部差分隐私（LDP）和图神经网络消息传递机制进行局部隐私图学习。&lt;h4&gt;方法&lt;/h4&gt;研究引入了针对局部隐私图学习协议的数据中毒攻击，攻击者通过注入假用户、建立与真实用户的连接和发送精心设计的数据来破坏隐私图学习的效用。&lt;h4&gt;主要发现&lt;/h4&gt;攻击既在理论上也在实证上证明了其有效性，同时指出现有的防御策略效果有限。&lt;h4&gt;结论&lt;/h4&gt;强调了需要开发更强大的防御机制来确保隐私保护图学习框架的鲁棒性和安全性。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates privacy issues in graph neural networks for graph representation learning, proposes a data poisoning attack targeting locally private graph learning protocols, and explores defensive strategies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have achieved significant success in graphrepresentation learning and have been applied to various domains. However, manyreal-world graphs contain sensitive personal information, such as user profilesin social networks, raising serious privacy concerns when graph learning isperformed using GNNs. To address this issue, locally private graph learningprotocols have gained considerable attention. These protocols leverage theprivacy advantages of local differential privacy (LDP) and the effectiveness ofGNN's message-passing in calibrating noisy data, offering strict privacyguarantees for users' local data while maintaining high utility (e.g., nodeclassification accuracy) for graph learning. Despite these advantages, suchprotocols may be vulnerable to data poisoning attacks, a threat that has notbeen considered in previous research. Identifying and addressing these threatsis crucial for ensuring the robustness and security of privacy-preserving graphlearning frameworks. This work introduces the first data poisoning attacktargeting locally private graph learning protocols. The attacker injects fakeusers into the protocol, manipulates these fake users to establish links withgenuine users, and sends carefully crafted data to the server, ultimatelycompromising the utility of private graph learning. The effectiveness of theattack is demonstrated both theoretically and empirically. In addition, severaldefense strategies have also been explored, but their limited effectivenesshighlights the need for more robust defenses.</description>
      <author>example@mail.com (Longzhu He, Chaozhuo Li, Peng Tang, Litian Zhang, Sen Su)</author>
      <guid isPermaLink="false">2506.09803v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>DynaSubVAE: Adaptive Subgrouping for Scalable and Robust OOD Detection</title>
      <link>http://arxiv.org/abs/2506.10200v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为DynaSubVAE的动态子分组变分自动编码器框架，用于处理现实世界中数据中的异质子群体问题，提高模型的预测准确性。&lt;h4&gt;背景&lt;/h4&gt;现实世界的数据中常存在与全局模式不同的子群体，大多数模型往往忽略了这些被低估的群体，导致预测不准确甚至有害。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来适应新出现的模式，而不是将检测到的样本视为域外样本。&lt;h4&gt;方法&lt;/h4&gt;DynaSubVAE通过动态更新其潜在结构来捕捉新趋势，利用基于嵌入相似性的非参数聚类机制发现和建模潜在子群体。&lt;h4&gt;主要发现&lt;/h4&gt;DynaSubVAE在近域外和远域外检测中表现出色，尤其在训练过程中缺失整个类别的类域外场景中表现优异。&lt;h4&gt;结论&lt;/h4&gt;动态子分组机制在域外准确性和后悔精度方面优于独立的聚类方法，如高斯混合模型和KMeans++。&lt;h4&gt;翻译&lt;/h4&gt;Real-world observational data often contain existing or emerging heterogeneous subpopulations that deviate from global patterns. The majority of models tend to overlook these underrepresented groups, leading to inaccurate or even harmful predictions. Existing solutions often rely on detecting these samples as Out-of-domain (OOD) rather than adapting the model to new emerging patterns. We introduce DynaSubVAE, a Dynamic Subgrouping Variational Autoencoder framework that jointly performs representation learning and adaptive OOD detection. Unlike conventional approaches, DynaSubVAE evolves with the data by dynamically updating its latent structure to capture new trends. It leverages a novel non-parametric clustering mechanism, inspired by Gaussian Mixture Models, to discover and model latent subgroups based on embedding similarity. Extensive experiments show that DynaSubVAE achieves competitive performance in both near-OOD and far-OOD detection, and excels in class-OOD scenarios where an entire class is missing during training. We further illustrate that our dynamic subgrouping mechanism outperforms standalone clustering methods such as GMM and KMeans++ in terms of both OOD accuracy and regret precision.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world observational data often contain existing or emergingheterogeneous subpopulations that deviate from global patterns. The majority ofmodels tend to overlook these underrepresented groups, leading to inaccurate oreven harmful predictions. Existing solutions often rely on detecting thesesamples as Out-of-domain (OOD) rather than adapting the model to new emergingpatterns. We introduce DynaSubVAE, a Dynamic Subgrouping VariationalAutoencoder framework that jointly performs representation learning andadaptive OOD detection. Unlike conventional approaches, DynaSubVAE evolves withthe data by dynamically updating its latent structure to capture new trends. Itleverages a novel non-parametric clustering mechanism, inspired by GaussianMixture Models, to discover and model latent subgroups based on embeddingsimilarity. Extensive experiments show that DynaSubVAE achieves competitiveperformance in both near-OOD and far-OOD detection, and excels in class-OODscenarios where an entire class is missing during training. We furtherillustrate that our dynamic subgrouping mechanism outperforms standaloneclustering methods such as GMM and KMeans++ in terms of both OOD accuracy andregret precision.</description>
      <author>example@mail.com (Tina Behrouzi, Sana Tonekaboni, Rahul G. Krishnan, Anna Goldenberg)</author>
      <guid isPermaLink="false">2506.10200v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>VAULT: A Mobile Mapping System for ROS 2-based Autonomous Robots</title>
      <link>http://arxiv.org/abs/2506.09583v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 5 figures, Submitted to WAF 2023: Workshop de Agentes  Fisicos&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了VAULT原型，这是一种基于ROS 2的移动地图系统，用于实现自主机器人在户外和室内的鲁棒定位。&lt;h4&gt;背景&lt;/h4&gt;定位在自主机器人的导航能力中起着关键作用。尽管室内环境可以使用轮式里程计和基于2D激光雷达的地图，但户外环境如农业和林业面临着独特的挑战，需要实时定位和连续地图。&lt;h4&gt;目的&lt;/h4&gt;提出VAULT原型，以解决户外和室内定位的需求。&lt;h4&gt;方法&lt;/h4&gt;VAULT原型结合了多种传感器，包括全球导航卫星系统（GNSS）数据、视觉惯性里程计（VIO）、惯性测量单元（IMU）数据和扩展卡尔曼滤波器（EKF），以生成可靠的3D里程计。此外，还采用了视觉同步定位与映射（VSLAM）技术，以创建全面的3D点云地图。&lt;h4&gt;主要发现&lt;/h4&gt;VAULT原型通过结合这些传感器技术和高级算法，为自主移动机器人的户外定位提供了一种全面解决方案，使机器人能够自信且精确地导航和绘制周围环境。&lt;h4&gt;结论&lt;/h4&gt;VAULT原型为自主机器人在户外环境中的定位提供了有效的方法，提高了导航和地图绘制的准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：定位在自主机器人的导航能力中起着至关重要的作用。虽然室内环境可以依赖轮式里程计和基于2D激光雷达的地图，但户外环境，如农业和林业，面临着独特的挑战，需要实时定位和连续地图。为了满足这一需求，本文提出了一种基于ROS 2的移动地图系统（MMS）的原型——VAULT，它结合了多种传感器以实现户外和室内的鲁棒定位。所提出的解决方案利用全球导航卫星系统（GNSS）数据、视觉惯性里程计（VIO）、惯性测量单元（IMU）数据和扩展卡尔曼滤波器（EKF）来生成可靠的3D里程计。为了进一步提高定位精度，采用了视觉同步定位与映射（VSLAM），从而创建了一个全面的3D点云地图。通过利用这些传感器技术和先进算法，原型为自主移动机器人的户外定位提供了一种全面解决方案，使其能够自信且精确地导航和绘制周围环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Localization plays a crucial role in the navigation capabilities ofautonomous robots, and while indoor environments can rely on wheel odometry and2D LiDAR-based mapping, outdoor settings such as agriculture and forestry,present unique challenges that necessitate real-time localization andconsistent mapping. Addressing this need, this paper introduces the VAULTprototype, a ROS 2-based mobile mapping system (MMS) that combines varioussensors to enable robust outdoor and indoor localization. The proposed solutionharnesses the power of Global Navigation Satellite System (GNSS) data,visual-inertial odometry (VIO), inertial measurement unit (IMU) data, and theExtended Kalman Filter (EKF) to generate reliable 3D odometry. To furtherenhance the localization accuracy, Visual SLAM (VSLAM) is employed, resultingin the creation of a comprehensive 3D point cloud map. By leveraging thesesensor technologies and advanced algorithms, the prototype offers acomprehensive solution for outdoor localization in autonomous mobile robots,enabling them to navigate and map their surroundings with confidence andprecision.</description>
      <author>example@mail.com (Miguel Á. González-Santamarta, Francisco J. Rodríguez-Lera, Vicente Matellán-Olivera)</author>
      <guid isPermaLink="false">2506.09583v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Toward Scalable Quantum Compilation for Modular Architecture: Qubit Mapping and Reuse via Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.09323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了QARMA，一种用于模块化量子架构的基于注意力的深度强化学习Qubit映射方法，及其扩展QARMA-R，它包含了动态Qubit复用能力。该方法结合了注意力机制和图神经网络（GNN）来学习最优的Qubit分配、路由和复用策略，以最小化核心间通信。&lt;h4&gt;背景&lt;/h4&gt;模块化量子架构通过连接多个量子处理单元（QPUs）来实现量子计算系统的扩展，但芯片间的核心操作和量子态传输引入了成本高昂的问题，这些因素导致了噪声和量子退相干。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过改进量子电路编译技术，使资源受限的模块化量子系统能够执行更广泛的量子算法。&lt;h4&gt;方法&lt;/h4&gt;QARMA和QARMA-R结合了注意力机制和图神经网络来学习最优的Qubit分配、路由和复用策略。QARMA使用基于transformer的编码器捕捉全局电路结构和局部Qubit交互，QARMA-R则包含动态Qubit复用编译机制，利用中点测量和重置操作来减少操作和Qubit需求。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与最先进的方法相比，QARMA-R将核心间通信减少了高达100%（平均85%），而QARMA在无复用的大电路中保持了15-40%的改进。与传统模块化Qubit映射相比，该方法将核心间操作减少了96.4-100%。&lt;h4&gt;结论&lt;/h4&gt;提出的QARMA和QARMA-R方法推进了量子电路编译技术，并使资源受限的模块化量子系统能够执行更广泛的量子算法，为可扩展量子计算架构的研究做出了贡献。&lt;h4&gt;翻译&lt;/h4&gt;Modular quantum architectures have emerged as a promising approach for scaling quantum computing systems by connecting multiple Quantum Processing Units (QPUs). However, this approach introduces significant challenges due to costly inter-core operations between chips and quantum state transfers, which contribute to noise and quantum decoherence. This paper presents QARMA, a novel Qubit mapping using Attention-based deep Reinforcement learning (DRL) for Modular quantum Architectures, along with its extension QARMA-R that incorporates dynamic qubit reuse capabilities. Our approach combines an attention-based mechanism with Graph Neural Networks (GNN) to learn optimal qubit allocation, routing, and reuse strategies that minimize inter-core communications. We introduce two key innovations: (1) a transformer-based encoder that captures both the global circuit structure and local qubit interactions and (2) a dynamic qubit reuse compilation mechanism that leverages mid-circuit measurement and reset operations to reduce inter-operation and qubit requirements. Our experimental results show significant improvements over state-of-the-art approaches. Compared to highly-optimized Qiskit with modular architecture configuration, QARMA-R reduces inter-core communications by up to 100% (on average 85%), while QARMA maintains 15-40% improvement for larger circuits without reuse. Against traditional modular qubit mapping, our approach achieves 96.4-100% reduction in inter-core operation. The proposed methods advance quantum circuit compilation techniques and enable the execution of more extensive quantum algorithms on resource-constrained modular quantum systems, contributing to the growing body of research on scalable quantum computing architectures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modular quantum architectures have emerged as a promising approach forscaling quantum computing systems by connecting multiple Quantum ProcessingUnits (QPUs). However, this approach introduces significant challenges due tocostly inter-core operations between chips and quantum state transfers, whichcontribute to noise and quantum decoherence. This paper presents QARMA, a novelQubit mapping using Attention-based deep Reinforcement learning (DRL) forModular quantum Architectures, along with its extension QARMA-R thatincorporates dynamic qubit reuse capabilities. Our approach combines anattention-based mechanism with Graph Neural Networks (GNN) to learn optimalqubit allocation, routing, and reuse strategies that minimize inter-corecommunications. We introduce two key innovations: (1) a transformer-basedencoder that captures both the global circuit structure and local qubitinteractions and (2) a dynamic qubit reuse compilation mechanism that leveragesmid-circuit measurement and reset operations to reduce inter-operation andqubit requirements. Our experimental results show significant improvements overstate-of-the-art approaches. Compared to highly-optimized Qiskit with modulararchitecture configuration, QARMA-R reduces inter-core communications by up to100% (on average 85%), while QARMA maintains 15-40% improvement for largercircuits without reuse. Against traditional modular qubit mapping, our approachachieves 96.4-100% reduction in inter-core operation. The proposed methodsadvance quantum circuit compilation techniques and enable the execution of moreextensive quantum algorithms on resource-constrained modular quantum systems,contributing to the growing body of research on scalable quantum computingarchitectures.</description>
      <author>example@mail.com (Sokea Sang, Leanghok Hour, Youngsun Han)</author>
      <guid isPermaLink="false">2506.09323v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Attention on flow control: transformer-based reinforcement learning for lift regulation in highly disturbed flows</title>
      <link>http://arxiv.org/abs/2506.10153v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于transformer的强化学习框架，用于学习调节阵风序列中气动升力的有效控制策略，并展示了该策略在不同配置下的可推广性。&lt;h4&gt;背景&lt;/h4&gt;线性流控制策略在强扰动序列中可能不再有效，因为存在非线性交互。&lt;h4&gt;目的&lt;/h4&gt;开发一种更有效的控制策略，以调节阵风序列中的气动升力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于transformer的强化学习框架，用于学习控制策略；使用专家策略（线性控制）进行预训练；采用任务级迁移学习，将孤立阵风上的策略扩展到多个阵风；研究四分之一弦俯仰控制与中弦俯仰控制的效果。&lt;h4&gt;主要发现&lt;/h4&gt;训练可以通过预训练和任务级迁移学习加速；学习策略优于最佳比例控制；在小阵风序列环境下学习的策略可以有效地推广到任意长序列的环境；四分之一弦俯仰控制比中弦俯仰控制需要更少的控制努力；这种优势归因于四分之一弦俯仰控制可获得的占优附加质量贡献。&lt;h4&gt;结论&lt;/h4&gt;提出的基于transformer的RL框架和加速技术为解决更复杂的流控制问题提供了有希望的方法。&lt;h4&gt;翻译&lt;/h4&gt;A linear flow control strategy designed for weak disturbances may not remain effective in sequences of strong disturbances due to nonlinear interactions, but it is sensible to leverage it for developing a better strategy. In the present study, we propose a transformer-based reinforcement learning (RL) framework to learn an effective control strategy for regulating aerodynamic lift in gust sequences via pitch control. The transformer addresses the challenge of partial observability from limited surface pressure sensors. We demonstrate that the training can be accelerated with two techniques --pretraining with an expert policy (here, linear control) and task-level transfer learning (here, extending a policy trained on isolated gusts to multiple gusts). We show that the learned strategy outperforms the best proportional control, with the performance gap widening as the number of gusts increases. The control strategy learned in an environment with a small number of successive gusts is shown to effectively generalize to an environment with an arbitrarily long sequence of gusts. We investigate the pivot configuration and show that quarter-chord pitching control can achieve superior lift regulation with substantially less control effort compared to mid-chord pitching control. Through a decomposition of the lift, we attribute this advantage to the dominant added-mass contribution accessible via quarter-chord pitching. The success on multiple configurations shows the generalizability of the proposed transformer-based RL framework, which offers a promising approach to solve more computationally demanding flow control problems when combined with the proposed acceleration techniques.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A linear flow control strategy designed for weak disturbances may not remaineffective in sequences of strong disturbances due to nonlinear interactions,but it is sensible to leverage it for developing a better strategy. In thepresent study, we propose a transformer-based reinforcement learning (RL)framework to learn an effective control strategy for regulating aerodynamiclift in gust sequences via pitch control. The transformer addresses thechallenge of partial observability from limited surface pressure sensors. Wedemonstrate that the training can be accelerated with two techniques --pretraining with an expert policy (here, linear control) and task-leveltransfer learning (here, extending a policy trained on isolated gusts tomultiple gusts). We show that the learned strategy outperforms the bestproportional control, with the performance gap widening as the number of gustsincreases. The control strategy learned in an environment with a small numberof successive gusts is shown to effectively generalize to an environment withan arbitrarily long sequence of gusts. We investigate the pivot configurationand show that quarter-chord pitching control can achieve superior liftregulation with substantially less control effort compared to mid-chordpitching control. Through a decomposition of the lift, we attribute thisadvantage to the dominant added-mass contribution accessible via quarter-chordpitching. The success on multiple configurations shows the generalizability ofthe proposed transformer-based RL framework, which offers a promising approachto solve more computationally demanding flow control problems when combinedwith the proposed acceleration techniques.</description>
      <author>example@mail.com (Zhecheng Liu, Jeff D. Eldredge)</author>
      <guid isPermaLink="false">2506.10153v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Deep Clustering of MNIST with Triplet-Enhanced Convolutional Autoencoders</title>
      <link>http://arxiv.org/abs/2506.10094v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 6 figures, experimental study on deep clustering with  autoencoders&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究通过两阶段深度自动编码器架构实现了一个高级无监督聚类系统，用于处理MNIST手写数字数据，并在多个测试中展现出优异的聚类性能。&lt;h4&gt;背景&lt;/h4&gt;深度神经网络自动编码器在第一阶段通过最小化重建误差来开发图像的极小化但可解释的表示。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过无监督学习方式，实现手写数字的高效聚类，并提高数据重建的准确性和聚类分离的纯净度。&lt;h4&gt;方法&lt;/h4&gt;使用两阶段深度自动编码器架构，第一阶段进行训练，第二阶段通过联合距离目标函数统一重建误差与KMeans聚类损失，实现学习的潜在嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;模型包含批归一化、dropout和权重衰减等三个元素，以实现通用的和稳定的聚类结果。通过Silhouette Score、Davies-Bouldin Index、NMI和ARI等指标验证了模型的聚类性能。&lt;h4&gt;结论&lt;/h4&gt;该研究的方法在数据重建准确性和聚类分离纯净度之间达到了最优组合，为大规模图像聚类应用中的无监督表示学习提供了一个可靠的基准。&lt;h4&gt;翻译&lt;/h4&gt;本研究通过两阶段深度自动编码器架构实现了一个高级无监督聚类系统，用于处理MNIST手写数字数据。通过两阶段架构，第一阶段通过训练深度神经网络自动编码器来开发图像的极小化但可解释的表示。在第二阶段，通过联合距离目标函数，将重建误差与KMeans聚类损失相结合，以实现学习的潜在嵌入。模型包含批归一化、dropout和权重衰减等三个元素，旨在实现通用的和稳定的聚类结果。在广泛的测试中，该框架在Silhouette Score、Davies-Bouldin Index、NMI和ARI等指标上展现了优异的聚类性能。研究还使用了t-SNE可视化来展示学习到的嵌入，显示出数字的明确聚类。该方法在数据重建准确性和聚类分离纯净度之间达到了最优组合，同时具有可理解的结果和可扩展的实现。该研究为不同大规模图像聚类应用中的无监督表示学习提供了一个可靠的基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research implements an advanced unsupervised clustering system for MNISThandwritten digits through two-phase deep autoencoder architecture. A deepneural autoencoder requires a training process during phase one to developminimal yet interpretive representations of images by minimizing reconstructionerrors. During the second phase we unify the reconstruction error with a KMeansclustering loss for learned latent embeddings through a joint distance-basedobjective. Our model contains three elements which include batch normalizationcombined with dropout and weight decay for achieving generalized and stableresults. The framework achieves superior clustering performance duringextensive tests which used intrinsic measurements including Silhouette Scoreand Davies-Bouldin Index coupled with extrinsic metrics NMI and ARI whenprocessing image features. The research uses t-SNE visualization to presentlearned embeddings that show distinct clusters for digits. Our approach reachesan optimal combination between data reconstruction accuracy and clusterseparation purity when adding the benefit of understandable results andscalable implementations. The approach creates a dependable base that helpsdeploy unsupervised representation learning in different large-scale imageclustering applications.</description>
      <author>example@mail.com (Md. Faizul Islam Ansari)</author>
      <guid isPermaLink="false">2506.10094v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Pisces: An Auto-regressive Foundation Model for Image Understanding and Generation</title>
      <link>http://arxiv.org/abs/2506.10395v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Unified image understanding and generation model&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Pisces的自动回归多模态基础模型，该模型通过新颖的解耦视觉编码架构和针对多模态生成的定制化训练技术来解决统一模型开发中的挑战。&lt;h4&gt;背景&lt;/h4&gt;尽管大型语言模型在图像理解和生成方面取得了进展，但统一模型在特定任务上通常不如专用模型表现好。&lt;h4&gt;目的&lt;/h4&gt;开发能够同时高效处理图像理解和生成的统一模型。&lt;h4&gt;方法&lt;/h4&gt;Pisces模型采用了一种新的解耦视觉编码架构和针对多模态生成的优化训练技术，并结合精心 curated 的数据、预训练和微调。&lt;h4&gt;主要发现&lt;/h4&gt;Pisces在超过20个公共图像理解基准测试中表现出色，同时在GenEval图像生成基准上也展示了强大的生成能力。&lt;h4&gt;结论&lt;/h4&gt;Pisces的研究揭示了图像理解和生成之间的协同关系，并证明了使用单独的视觉编码器对统一多模态模型领域的益处。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为Pisces的自动回归多模态基础模型，通过创新的解耦视觉编码架构和针对多模态生成的定制化训练技术解决了统一模型开发中的挑战。尽管大型语言模型在图像理解和生成方面取得了进展，但统一模型在特定任务上通常不如专用模型表现好。本研究旨在开发能够同时高效处理图像理解和生成的统一模型。Pisces模型采用了一种新的解耦视觉编码架构和针对多模态生成的优化训练技术，并结合精心 curated 的数据、预训练和微调。在超过20个公共图像理解基准测试中，Pisces表现出色，同时在GenEval图像生成基准上也展示了强大的生成能力。研究揭示了图像理解和生成之间的协同关系，并证明了使用单独的视觉编码器对统一多模态模型领域的益处。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in large language models (LLMs) have enabled multimodalfoundation models to tackle both image understanding and generation within aunified framework. Despite these gains, unified models often underperformcompared to specialized models in either task. A key challenge in developingunified models lies in the inherent differences between the visual featuresneeded for image understanding versus generation, as well as the distincttraining processes required for each modality. In this work, we introducePisces, an auto-regressive multimodal foundation model that addresses thischallenge through a novel decoupled visual encoding architecture and tailoredtraining techniques optimized for multimodal generation. Combined withmeticulous data curation, pretraining, and finetuning, Pisces achievescompetitive performance in both image understanding and image generation. Weevaluate Pisces on over 20 public benchmarks for image understanding, where itdemonstrates strong performance across a wide range of tasks. Additionally, onGenEval, a widely adopted benchmark for image generation, Pisces exhibitsrobust generative capabilities. Our extensive analysis reveals the synergisticrelationship between image understanding and generation, and the benefits ofusing separate visual encoders, advancing the field of unified multimodalmodels.</description>
      <author>example@mail.com (Zhiyang Xu, Jiuhai Chen, Zhaojiang Lin, Xichen Pan, Lifu Huang, Tianyi Zhou, Madian Khabsa, Qifan Wang, Di Jin, Michihiro Yasunaga, Lili Yu, Xi Victoria Lin, Shaoliang Nie)</author>
      <guid isPermaLink="false">2506.10395v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Canonical Latent Representations in Conditional Diffusion Models</title>
      <link>http://arxiv.org/abs/2506.09955v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  45 pages,41 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;条件扩散模型（CDMs）在生成任务中表现出色，但其建模能力导致类别特征与无关背景信息交织，给提取鲁棒和可解释的表示带来挑战。&lt;h4&gt;背景&lt;/h4&gt;CDMs在分析合成下游判别学习中的应用，但存在类别特征与无关背景信息交织的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提取鲁棒和可解释的表示，并开发一种基于扩散的特征蒸馏范式。&lt;h4&gt;方法&lt;/h4&gt;提出了一种称为CLAReps的潜在代码，用于保留必要的类别信息并丢弃非判别性信号。同时，开发了CaDistill范式，通过CLAReps传递核心类别知识。&lt;h4&gt;主要发现&lt;/h4&gt;CLAReps能够产生每个类别的代表性样本，CaDistill范式在训练后使学生模型具有强大的对抗鲁棒性和泛化能力，专注于类别信号而非虚假背景线索。&lt;h4&gt;结论&lt;/h4&gt;CDMs不仅可以作为图像生成器，还可以作为紧凑、可解释的教师，驱动鲁棒表示学习。&lt;h4&gt;翻译&lt;/h4&gt;Conditional diffusion models (CDMs) have shown impressive performance across a range of generative tasks. Their ability to model the full data distribution has opened new avenues for analysis-by-synthesis in downstream discriminative learning. However, this same modeling capacity causes CDMs to entangle the class-defining features with irrelevant context, posing challenges to extracting robust and interpretable representations. To this end, we identify Canonical LAtent Representations (CLAReps), latent codes whose internal CDM features preserve essential categorical information while discarding non-discriminative signals. When decoded, CLAReps produce representative samples for each class, offering an interpretable and compact summary of the core class semantics with minimal irrelevant details. Exploiting CLAReps, we develop a novel diffusion-based feature-distillation paradigm, CaDistill. While the student has full access to the training set, the CDM as teacher transfers core class knowledge only via CLAReps, which amounts to merely 10 % of the training data in size. After training, the student achieves strong adversarial robustness and generalization ability, focusing more on the class signals instead of spurious background cues. Our findings suggest that CDMs can serve not just as image generators but also as compact, interpretable teachers that can drive robust representation learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conditional diffusion models (CDMs) have shown impressive performance acrossa range of generative tasks. Their ability to model the full data distributionhas opened new avenues for analysis-by-synthesis in downstream discriminativelearning. However, this same modeling capacity causes CDMs to entangle theclass-defining features with irrelevant context, posing challenges toextracting robust and interpretable representations. To this end, we identifyCanonical LAtent Representations (CLAReps), latent codes whose internal CDMfeatures preserve essential categorical information while discardingnon-discriminative signals. When decoded, CLAReps produce representativesamples for each class, offering an interpretable and compact summary of thecore class semantics with minimal irrelevant details. Exploiting CLAReps, wedevelop a novel diffusion-based feature-distillation paradigm, CaDistill. Whilethe student has full access to the training set, the CDM as teacher transferscore class knowledge only via CLAReps, which amounts to merely 10 % of thetraining data in size. After training, the student achieves strong adversarialrobustness and generalization ability, focusing more on the class signalsinstead of spurious background cues. Our findings suggest that CDMs can servenot just as image generators but also as compact, interpretable teachers thatcan drive robust representation learning.</description>
      <author>example@mail.com (Yitao Xu, Tong Zhang, Ehsan Pajouheshgar, Sabine Süsstrunk)</author>
      <guid isPermaLink="false">2506.09955v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>On the Similarities of Embeddings in Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.09781v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  contrastive learning, representation learning, embedding, similarity,  negative pair, positive pair&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出一个统一的框架来理解对比学习（CL），分析了正负对嵌入之间的余弦相似性，并针对小批量训练中对比学习的局限性提出了一种辅助损失项。&lt;h4&gt;背景&lt;/h4&gt;对比学习通过拉近正对嵌入的距离，推开负对嵌入的距离来进行学习。尽管已有多种对比损失函数被提出和分析，但之前的工作缺乏一个全面解释这些目标函数的框架。&lt;h4&gt;目的&lt;/h4&gt;构建一个系统性的框架来理解对比学习，并解决小批量训练中对比学习的局限性。&lt;h4&gt;方法&lt;/h4&gt;通过分析正负对嵌入之间的余弦相似性，提出一个统一的框架。在完整批量设置中，研究了正对完美对齐的不可能性以及如何通过引入视域内负对来缓解这种错位。在迷你批量设置中，展示了较小批量大小导致批量内负对分离更强，从而增加了负对相似性的方差。为了解决这个局限性，引入了一个辅助损失项。&lt;h4&gt;主要发现&lt;/h4&gt;在完整批量设置中，发现当负对相似性低于某个阈值时，正对的完美对齐是不可实现的，且可以通过引入视域内负对来缓解错位。在迷你批量设置中，发现较小的批量大小会导致批量内负对的分离更强，从而增加负对相似性的方差。&lt;h4&gt;结论&lt;/h4&gt;引入的辅助损失项可以有效地提高小批量训练中对比学习方法的性能。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive learning (CL) operates on a simple yet effective principle:embeddings of positive pairs are pulled together, while those of negative pairsare pushed apart. Although various forms of contrastive loss have been proposedand analyzed from different perspectives, prior works lack a comprehensiveframework that systematically explains a broad class of these objectives. Inthis paper, we present a unified framework for understanding CL, which is basedon analyzing the cosine similarity between embeddings of positive and negativepairs. In full-batch settings, we show that perfect alignment of positive pairsis unattainable when similarities of negative pairs fall below a certainthreshold, and that this misalignment can be alleviated by incorporatingwithin-view negative pairs. In mini-batch settings, we demonstrate that smallerbatch sizes incur stronger separation among negative pairs within batches,which leads to higher variance in similarities of negative pairs. To addressthis limitation of mini-batch CL, we introduce an auxiliary loss term thatreduces the variance of similarities of negative pairs in CL. Empirical resultsdemonstrate that incorporating the proposed loss consistently improves theperformance of CL methods in small-batch training.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning (CL) operates on a simple yet effective principle:embeddings of positive pairs are pulled together, while those of negative pairsare pushed apart. Although various forms of contrastive loss have been proposedand analyzed from different perspectives, prior works lack a comprehensiveframework that systematically explains a broad class of these objectives. Inthis paper, we present a unified framework for understanding CL, which is basedon analyzing the cosine similarity between embeddings of positive and negativepairs. In full-batch settings, we show that perfect alignment of positive pairsis unattainable when similarities of negative pairs fall below a certainthreshold, and that this misalignment can be alleviated by incorporatingwithin-view negative pairs. In mini-batch settings, we demonstrate that smallerbatch sizes incur stronger separation among negative pairs within batches,which leads to higher variance in similarities of negative pairs. To addressthis limitation of mini-batch CL, we introduce an auxiliary loss term thatreduces the variance of similarities of negative pairs in CL. Empirical resultsdemonstrate that incorporating the proposed loss consistently improves theperformance of CL methods in small-batch training.</description>
      <author>example@mail.com (Chungpa Lee, Sehee Lim, Kibok Lee, Jy-yong Sohn)</author>
      <guid isPermaLink="false">2506.09781v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging 6DoF Pose Foundation Models For Mapping Marine Sediment Burial</title>
      <link>http://arxiv.org/abs/2506.10386v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究通过结合深度学习模型和立体摄影测量技术，提出了一种名为PoseIDON的计算机视觉流程，用于从ROV视频中估计海底物体的埋藏深度和姿态，为污染评估和恢复策略提供支持。&lt;h4&gt;背景&lt;/h4&gt;海底人类遗物（如弹药）的埋藏状态对于了解沉积动力学、评估生态风险、污染物传输以及危险材料的回收或缓解策略至关重要。&lt;h4&gt;目的&lt;/h4&gt;提高从远程图像中准确估计海底物体埋藏深度的能力。&lt;h4&gt;方法&lt;/h4&gt;PoseIDON结合了深度学习模型和立体摄影测量技术，通过比对物体的CAD模型和观察到的图像来推断埋藏深度，并对海底进行局部平面近似。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在圣地亚哥湾的一个历史海洋倾倒场的54个物体（包括桶和弹药）上进行了验证，平均埋藏深度误差约为10厘米，并能解决反映潜在沉积传输过程的埋藏模式。&lt;h4&gt;结论&lt;/h4&gt;该研究方法可实现海底埋藏的可扩展、非侵入性测绘，并支持污染场所的环境评估。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The burial state of anthropogenic objects on the seafloor provides insightinto localized sedimentation dynamics and is also critical for assessingecological risks, potential pollutant transport, and the viability of recoveryor mitigation strategies for hazardous materials such as munitions. Accurateburial depth estimation from remote imagery remains difficult due to partialocclusion, poor visibility, and object degradation. This work introduces acomputer vision pipeline, called PoseIDON, which combines deep foundation modelfeatures with multiview photogrammetry to estimate six degrees of freedomobject pose and the orientation of the surrounding seafloor from ROV video.Burial depth is inferred by aligning CAD models of the objects with observedimagery and fitting a local planar approximation of the seafloor. The method isvalidated using footage of 54 objects, including barrels and munitions,recorded at a historic ocean dumpsite in the San Pedro Basin. The modelachieves a mean burial depth error of approximately 10 centimeters and resolvesspatial burial patterns that reflect underlying sediment transport processes.This approach enables scalable, non-invasive mapping of seafloor burial andsupports environmental assessment at contaminated sites.</description>
      <author>example@mail.com (Jerry Yan, Chinmay Talegaonkar, Nicholas Antipa, Eric Terrill, Sophia Merrifield)</author>
      <guid isPermaLink="false">2506.10386v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Auto-Compressing Networks</title>
      <link>http://arxiv.org/abs/2506.09714v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究介绍了Auto-Compressing Networks (ACN)这种新型网络结构，通过长距离前馈连接实现信息自动压缩，提高了网络的鲁棒性和迁移学习能力。&lt;h4&gt;背景&lt;/h4&gt;深度神经网络在多个领域取得了显著成功，但随着网络深度的增加，计算冗余问题也随之出现，而表示质量并没有相应提高。&lt;h4&gt;目的&lt;/h4&gt;提出ACN架构，通过改变连接方式，使网络在训练过程中自动压缩信息。&lt;h4&gt;方法&lt;/h4&gt;通过引入长距离前馈连接替换传统的短残差连接，并观察ACN在网络训练过程中的信息压缩行为。&lt;h4&gt;主要发现&lt;/h4&gt;ACN具有自动压缩的特性，能够在训练过程中动态地将信息推入早期层，提高其表示质量，同时揭示深层中的潜在冗余。理论研究表明，这一特性源于ACN中的层间训练模式，根据任务需求动态地利用层。ACN比残差网络表现出更强的噪声鲁棒性、在低数据环境下的优越性能、改进的迁移学习能力以及减少灾难性遗忘，表明它们虽然参数较少，但学习的表示泛化能力更强。在视觉Transformer、MLP-mixers和Bert架构上，ACN实现了高达18%的灾难性遗忘减少和30-80%的架构压缩，同时保持了精度。将ACN与传统剪枝技术相结合，可以在稀疏性-性能权衡方面显著优于传统架构。&lt;h4&gt;结论&lt;/h4&gt;ACN是一种实用的方法，可以开发出能够根据任务复杂度自动调整其计算足迹的高效神经网络架构，同时学习鲁棒的表示。&lt;h4&gt;翻译&lt;/h4&gt;In this study, the novel network architecture called Auto-Compressing Networks (ACN) is proposed, which achieves information automatic compression through long-distance feedforward connections, improving the robustness and transfer learning capabilities of the network.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks with short residual connections have demonstratedremarkable success across domains, but increasing depth often introducescomputational redundancy without corresponding improvements in representationquality. In this work, we introduce Auto-Compressing Networks (ACNs), anarchitectural variant where additive long feedforward connections from eachlayer to the output replace traditional short residual connections. ACNsshowcase a unique property we coin as "auto-compression", the ability of anetwork to organically compress information during training with gradientdescent, through architectural design alone. Through auto-compression,information is dynamically "pushed" into early layers during training,enhancing their representational quality and revealing potential redundancy indeeper ones. We theoretically show that this property emerges from layer-wisetraining patterns present in ACNs, where layers are dynamically utilized duringtraining based on task requirements. We also find that ACNs exhibit enhancednoise robustness compared to residual networks, superior performance inlow-data settings, improved transfer learning capabilities, and mitigatecatastrophic forgetting suggesting that they learn representations thatgeneralize better despite using fewer parameters. Our results demonstrate up to18% reduction in catastrophic forgetting and 30-80% architectural compressionwhile maintaining accuracy across vision transformers, MLP-mixers, and BERTarchitectures. Furthermore, we demonstrate that coupling ACNs with traditionalpruning techniques, enables significantly better sparsity-performancetrade-offs compared to conventional architectures. These findings establishACNs as a practical approach to developing efficient neural architectures thatautomatically adapt their computational footprint to task complexity, whilelearning robust representations.</description>
      <author>example@mail.com (Vaggelis Dorovatas, Georgios Paraskevopoulos, Alexandros Potamianos)</author>
      <guid isPermaLink="false">2506.09714v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing semi-resolved CFD-DEM for dilute to dense particle-fluid systems: A point cloud based, two-step mapping strategy via coarse graining</title>
      <link>http://arxiv.org/abs/2506.09517v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个基于两点映射的CFD-DEM耦合方法，通过点云粗化技术解决传统方法中存在的问题，并验证了其在多种配置下的有效性。&lt;h4&gt;背景&lt;/h4&gt;CFD-DEM耦合是一种高效强大的工具，用于模拟粒子-流体系统，但传统的体积平均CFD-DEM在流体网格分辨率上具有强依赖性，可能导致不稳定并无法捕捉到致密颗粒系统中的孔隙流体压力效应。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的CFD-DEM耦合方法，以克服传统方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;采用点云粗化技术，首先将离散粒子转换为平滑的粗化连续场，然后实现粗化点云场与流体网格变量的精确耦合。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在各种配置下得到验证，包括一维网格上的静态粒子权重分配、二维网格上的下落粒子、粘性流体中的球体沉降、尺寸双分散流化床、Ergun压降测试和浸没颗粒柱倒塌。&lt;h4&gt;结论&lt;/h4&gt;所提出的CFD-DEM方法为准确模拟流体-粒子相互作用提供了一种新的策略，适用于广泛的网格到粒子尺寸比和固体浓度，具有在工业和地球物理应用中的潜在用途。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computational fluid dynamics and discrete element method (CFD-DEM) couplingis an efficient and powerful tool to simulate particle-fluid systems. However,current volume-averaged CFD-DEM relying on direct grid-based mapping betweenthe fluid and particle phases can exhibit a strong dependence on the fluid gridresolution, becoming unstable as particles move across fluid grids, and canfail to capture pore fluid pressure effects in very dense granular systems.Here we propose a two-step mapping CFD-DEM which uses a point-based coarsegraining technique for intermediate smoothing to overcome these limitations.The discrete particles are first converted into smooth, coarse-grainedcontinuum fields via a multi-layer Fibonacci point cloud, independent of thefluid grids. Then, accurate coupling is achieved between the coarse-grained,point cloud fields and the fluid grid-based variables. The algorithm isvalidated in various configurations, including weight allocation of a staticparticle on one-dimensional grids and a falling particle on two-dimensionalgrids, sedimentation of a sphere in a viscous fluid, size-bidisperse fluidizedbeds, Ergun's pressure drop test, and immersed granular column collapse. Theproposed CFD-DEM represents a novel strategy to accurately simulatefluid-particle interactions for a wide range of grid-to-particle size ratiosand solid concentrations, which is of potential use in many industrial andgeophysical applications.</description>
      <author>example@mail.com (Yuxiang Liu, Lu Jing, Xudong Fu, Huabin Shi)</author>
      <guid isPermaLink="false">2506.09517v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Prompt-Guided Latent Diffusion with Predictive Class Conditioning for 3D Prostate MRI Generation</title>
      <link>http://arxiv.org/abs/2506.10230v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MAH and BT are co-senior authors on the work. This work has been  submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的名为CCELLA的模型，旨在解决医学图像学习中数据稀缺的问题，通过结合多种策略提高了LDM的性能和科学可及性。&lt;h4&gt;背景&lt;/h4&gt;医学图像学习受数据稀缺的限制，传统方法依赖短文本编码器、非医学LDM重用或大量数据微调，这些策略限制了性能和科学可及性。&lt;h4&gt;目的&lt;/h4&gt;提出CCELLA模型以解决上述限制，实现高效且高质量的医学图像合成。&lt;h4&gt;方法&lt;/h4&gt;CCELLA使用双重头部条件化方法，通过交叉注意力结合非医学大型语言模型编码的文本特征，通过时间步嵌入结合病理分类。同时，提出联合损失函数和数据高效LDM训练框架。&lt;h4&gt;主要发现&lt;/h4&gt;CCELLA在限制数据量的前列腺MRI数据集上实现了3D FID分数0.025，显著优于FID 0.071的最近基础模型。在前列腺癌预测中，添加合成图像到训练集将分类器准确率从69%提高至74%，仅用合成图像训练的分类器性能与仅用真实图像训练相当。&lt;h4&gt;结论&lt;/h4&gt;CCELLA模型在有限的医学图像数据和高数据标注成本下，能够提高LDM的性能和科学可及性，为医学图像合成和病理预测提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Latent diffusion models (LDM) could alleviate data scarcity challengesaffecting machine learning development for medical imaging. However, medicalLDM training typically relies on performance- or scientificaccessibility-limiting strategies including a reliance on short-prompt textencoders, the reuse of non-medical LDMs, or a requirement for fine-tuning withlarge data volumes. We propose a Class-Conditioned Efficient Large Languagemodel Adapter (CCELLA) to address these limitations. CCELLA is a noveldual-head conditioning approach that simultaneously conditions the LDM U-Netwith non-medical large language model-encoded text features throughcross-attention and with pathology classification through the timestepembedding. We also propose a joint loss function and a data-efficient LDMtraining framework. In combination, these strategies enablepathology-conditioned LDM training for high-quality medical image synthesisgiven limited data volume and human data annotation, improving LDM performanceand scientific accessibility. Our method achieves a 3D FID score of 0.025 on asize-limited prostate MRI dataset, significantly outperforming a recentfoundation model with FID 0.071. When training a classifier for prostate cancerprediction, adding synthetic images generated by our method to the trainingdataset improves classifier accuracy from 69% to 74%. Training a classifiersolely on our method's synthetic images achieved comparable performance totraining on real images alone.</description>
      <author>example@mail.com (Emerson P. Grabke, Masoom A. Haider, Babak Taati)</author>
      <guid isPermaLink="false">2506.10230v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>An Effective End-to-End Solution for Multimodal Action Recognition</title>
      <link>http://arxiv.org/abs/2506.09345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种综合的多模态动作识别解决方案，有效利用多模态信息，解决了三模态数据稀缺的问题，并在动作识别竞赛中取得了优异的成绩。&lt;h4&gt;背景&lt;/h4&gt;多模态任务在动作识别领域取得了显著进展，但由于三模态数据的稀缺，研究三模态动作识别任务面临许多挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种综合的多模态动作识别解决方案，以解决三模态数据稀缺的问题。&lt;h4&gt;方法&lt;/h4&gt;1. 通过优化数据增强技术扩大训练规模，并使用更多RGB数据集预训练骨干网络；2. 利用2D CNN提取多模态空间特征，并结合TSM模块实现多模态时空特征提取；3. 使用SWA、集成和测试时增强（TTA）等预测增强方法，整合不同训练阶段和不同架构的模型知识。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在动作识别竞赛中实现了99%的Top-1准确率和100%的Top-5准确率。&lt;h4&gt;结论&lt;/h4&gt;该解决方案在动作识别领域具有优越性。&lt;h4&gt;翻译&lt;/h4&gt;最近，多模态任务由于它们丰富的多模态信息而极大地推动了动作识别领域的发展。然而，由于三模态数据的稀缺，三模态动作识别任务的研究面临着许多挑战。为此，我们提出了一种全面的多模态动作识别解决方案，该方案有效地利用了多模态信息。首先，通过优化数据增强技术对现有数据进行转换和扩展，以扩大训练规模。同时，使用更多的RGB数据集来预训练骨干网络，通过迁移学习使网络更好地适应新任务。其次，利用2D CNN提取多模态空间特征，并结合时间移位模块（TSM）实现与3D CNN相当的多模态时空特征提取，以提高计算效率。此外，还使用了常见的预测增强方法，如随机权重平均（SWA）、集成和测试时增强（TTA），以整合来自相同架构的不同训练阶段和不同架构的模型知识，从而从不同角度预测动作并充分利用目标信息。最终，我们在竞赛排行榜上实现了99%的Top-1准确率和100%的Top-5准确率，证明了我们解决方案的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, multimodal tasks have strongly advanced the field of actionrecognition with their rich multimodal information. However, due to thescarcity of tri-modal data, research on tri-modal action recognition tasksfaces many challenges. To this end, we have proposed a comprehensive multimodalaction recognition solution that effectively utilizes multimodal information.First, the existing data are transformed and expanded by optimizing dataenhancement techniques to enlarge the training scale. At the same time, moreRGB datasets are used to pre-train the backbone network, which is betteradapted to the new task by means of transfer learning. Secondly, multimodalspatial features are extracted with the help of 2D CNNs and combined with theTemporal Shift Module (TSM) to achieve multimodal spatial-temporal featureextraction comparable to 3D CNNs and improve the computational efficiency. Inaddition, common prediction enhancement methods, such as Stochastic WeightAveraging (SWA), Ensemble and Test-Time augmentation (TTA), are used tointegrate the knowledge of models from different training periods of the samearchitecture and different architectures, so as to predict the actions fromdifferent perspectives and fully exploit the target information. Ultimately, weachieved the Top-1 accuracy of 99% and the Top-5 accuracy of 100% on thecompetition leaderboard, demonstrating the superiority of our solution.</description>
      <author>example@mail.com (Songping Wang, Xiantao Hu, Yueming Lyu, Caifeng Shan)</author>
      <guid isPermaLink="false">2506.09345v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Generalized Gaussian Entropy Model for Point Cloud Attribute Compression with Dynamic Likelihood Intervals</title>
      <link>http://arxiv.org/abs/2506.09510v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于广义高斯熵模型和Mean Error Discriminator (MED)的方法，用于提高点云属性压缩的率失真性能。&lt;h4&gt;背景&lt;/h4&gt;高斯和拉普拉斯熵模型在点云属性压缩中已证明有效，但当前方法中神经网络估计的熵参数中仍存在未利用的信息。&lt;h4&gt;目的&lt;/h4&gt;旨在通过利用这些未利用的信息，提高概率估计的准确性，从而改善点云属性压缩的率失真性能。&lt;h4&gt;方法&lt;/h4&gt;引入了广义高斯熵模型，通过形状参数控制尾部形状以更准确地估计潜变量概率；同时，提出了Mean Error Discriminator (MED)来确定熵参数估计的准确性，并动态调整似然区间。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在基于VAE的三个点云属性压缩模型上显著提高了率失真性能，并且该方法可以应用于其他压缩任务，如图像和视频压缩。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过利用未利用的信息和动态调整似然区间，有效提高了点云属性压缩的率失真性能，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gaussian and Laplacian entropy models are proved effective in learned pointcloud attribute compression, as they assist in arithmetic coding of latents.However, we demonstrate through experiments that there is still unutilizedinformation in entropy parameters estimated by neural networks in currentmethods, which can be used for more accurate probability estimation. Thus weintroduce generalized Gaussian entropy model, which controls the tail shapethrough shape parameter to more accurately estimate the probability of latents.Meanwhile, to the best of our knowledge, existing methods use fixed likelihoodintervals for each integer during arithmetic coding, which limits modelperformance. We propose Mean Error Discriminator (MED) to determine whether theentropy parameter estimation is accurate and then dynamically adjust likelihoodintervals. Experiments show that our method significantly improvesrate-distortion (RD) performance on three VAE-based models for point cloudattribute compression, and our method can be applied to other compressiontasks, such as image and video compression.</description>
      <author>example@mail.com (Changhao Peng, Yuqi Ye, Wei Gao)</author>
      <guid isPermaLink="false">2506.09510v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Causal Climate Emulation with Bayesian Filtering</title>
      <link>http://arxiv.org/abs/2506.09891v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  32 pages, 21 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于因果表示学习的可解释气候模型模拟器，通过引入贝叶斯滤波和长期自回归模拟，实现了对气候动态的准确学习，并在合成数据集以及两个广泛使用的气候模型数据上验证了模型组件的重要性。&lt;h4&gt;背景&lt;/h4&gt;传统气候模型使用复杂的耦合方程模拟地球系统中的物理过程，这些模拟计算成本高，限制了我们对气候变化及其原因和影响的预测和分析。&lt;h4&gt;目的&lt;/h4&gt;开发一种可解释的气候模型模拟器，能够快速模拟气候模型数据，并能够结合物理信息。&lt;h4&gt;方法&lt;/h4&gt;基于因果表示学习，引入贝叶斯滤波和长期自回归模拟方法。&lt;h4&gt;主要发现&lt;/h4&gt;模拟器能够学习准确的气候动态，其各个组件在现实合成数据集和两个广泛使用的气候模型数据上的重要性得到验证。&lt;h4&gt;结论&lt;/h4&gt;提出的气候模型模拟器能够有效地模拟气候动态，并有助于深入理解气候变化的原因和影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional models of climate change use complex systems of coupled equationsto simulate physical processes across the Earth system. These simulations arehighly computationally expensive, limiting our predictions of climate changeand analyses of its causes and effects. Machine learning has the potential toquickly emulate data from climate models, but current approaches are not ableto incorporate physics-informed causal relationships. Here, we develop aninterpretable climate model emulator based on causal representation learning.We derive a physics-informed approach including a Bayesian filter for stablelong-term autoregressive emulation. We demonstrate that our emulator learnsaccurate climate dynamics, and we show the importance of each one of itscomponents on a realistic synthetic dataset and data from two widely deployedclimate models.</description>
      <author>example@mail.com (Sebastian Hickman, Ilija Trajkovic, Julia Kaltenborn, Francis Pelletier, Alex Archibald, Yaniv Gurwicz, Peer Nowack, David Rolnick, Julien Boussard)</author>
      <guid isPermaLink="false">2506.09891v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>An Explainable Deep Learning Framework for Brain Stroke and Tumor Progression via MRI Interpretation</title>
      <link>http://arxiv.org/abs/2506.09161v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in MECON 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于深度学习的系统，能够从MRI图像中识别脑肿瘤和中风，以及它们的相应阶段。&lt;h4&gt;背景&lt;/h4&gt;早期和准确检测脑部异常（如肿瘤和中风）对于及时干预和改善患者预后至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究目的是开发一个能够识别脑肿瘤和中风以及其阶段的深度学习系统。&lt;h4&gt;方法&lt;/h4&gt;研究采用了两种创新的策略，涉及使用MobileNet V2和ResNet-50卷积神经网络，通过迁移学习优化来对MRI扫描进行分类，共分为五个诊断类别。数据集从各种公开的MRI资源中收集和增强，以确保类别平衡和图像多样性。为了提高模型的泛化能力和防止过拟合，使用了dropout层和广泛的数据增强。&lt;h4&gt;主要发现&lt;/h4&gt;模型在训练准确率达到93%，验证准确率达到88%的情况下表现出强大的性能。尽管ResNet-50表现略好，但MobileNet V2由于其轻量级架构，在资源有限的环境中仍是一个有前景的实时诊断选择。&lt;h4&gt;结论&lt;/h4&gt;这项研究提供了一个基于AI的早期脑部异常检测的实际解决方案，具有临床部署的潜力，并可通过更大的数据集和多模态输入进行未来的改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early and accurate detection of brain abnormalities, such as tumors andstrokes, is essential for timely intervention and improved patient outcomes. Inthis study, we present a deep learning-based system capable of identifying bothbrain tumors and strokes from MRI images, along with their respective stages.We have executed two groundbreaking strategies involving convolutional neuralnetworks, MobileNet V2 and ResNet-50-optimized through transfer learning toclassify MRI scans into five diagnostic categories. Our dataset, aggregated andaugmented from various publicly available MRI sources, was carefully curated toensure class balance and image diversity. To enhance model generalization andprevent overfitting, we applied dropout layers and extensive data augmentation.The models achieved strong performance, with training accuracy reaching 93\%and validation accuracy up to 88\%. While ResNet-50 demonstrated slightlybetter results, Mobile Net V2 remains a promising option for real-timediagnosis in low resource settings due to its lightweight architecture. Thisresearch offers a practical AI-driven solution for early brain abnormalitydetection, with potential for clinical deployment and future enhancementthrough larger datasets and multi modal inputs.</description>
      <author>example@mail.com (Rajan Das Gupta, Md Imrul Hasan Showmick, Mushfiqur Rahman Abir, Shanjida Akter, Md. Yeasin Rahat, Md. Jakir Hossen)</author>
      <guid isPermaLink="false">2506.09161v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Do Multiple Instance Learning Models Transfer?</title>
      <link>http://arxiv.org/abs/2506.09022v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 (Spotlight). 20 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在计算病理学中，预训练的多实例学习（MIL）模型在生成临床有意义的切片级嵌入方面的能力，并评估了其在不同任务上的迁移学习能力。&lt;h4&gt;背景&lt;/h4&gt;MIL在计算病理学中用于从高分辨率组织图像中生成临床有意义的切片级嵌入，但在小规模、弱监督的临床数据集上表现不佳。与自然语言处理和传统计算机视觉领域不同，MIL模型的迁移性理解不足。&lt;h4&gt;目的&lt;/h4&gt;系统地评估预训练MIL模型的迁移学习能力。&lt;h4&gt;方法&lt;/h4&gt;评估了11个模型在21个预训练任务上的表现，包括形态学和分子亚型预测。&lt;h4&gt;主要发现&lt;/h4&gt;预训练MIL模型在不同器官上训练后，在目标任务上表现优于从头开始训练的模型。在跨器官和任务上的预训练，尤其是在泛癌症数据集上，能够实现强大的泛化能力，且预训练数据量显著减少。&lt;h4&gt;结论&lt;/h4&gt;MIL模型具有强大的适应能力，迁移学习有助于提高计算病理学中的性能。&lt;h4&gt;翻译&lt;/h4&gt;Multiple Instance Learning (MIL) is a cornerstone approach in computational pathology (CPath) for generating clinically meaningful slide-level embeddings from gigapixel tissue images. However, MIL often struggles with small, weakly supervised clinical datasets. In contrast to fields such as NLP and conventional computer vision, where transfer learning is widely used to address data scarcity, the transferability of MIL models remains poorly understood. In this study, we systematically evaluate the transfer learning capabilities of pretrained MIL models by assessing 11 models across 21 pretraining tasks for morphological and molecular subtype prediction. Our results show that pretrained MIL models, even when trained on different organs than the target task, consistently outperform models trained from scratch. Moreover, pretraining on pancancer datasets enables strong generalization across organs and tasks, outperforming slide foundation models while using substantially less pretraining data. These findings highlight the robust adaptability of MIL models and demonstrate the benefits of leveraging transfer learning to boost performance in CPath. Lastly, we provide a resource which standardizes the implementation of MIL models and collection of pretrained model weights on popular CPath tasks, available at https://github.com/mahmoodlab/MIL-Lab&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multiple Instance Learning (MIL) is a cornerstone approach in computationalpathology (CPath) for generating clinically meaningful slide-level embeddingsfrom gigapixel tissue images. However, MIL often struggles with small, weaklysupervised clinical datasets. In contrast to fields such as NLP andconventional computer vision, where transfer learning is widely used to addressdata scarcity, the transferability of MIL models remains poorly understood. Inthis study, we systematically evaluate the transfer learning capabilities ofpretrained MIL models by assessing 11 models across 21 pretraining tasks formorphological and molecular subtype prediction. Our results show thatpretrained MIL models, even when trained on different organs than the targettask, consistently outperform models trained from scratch. Moreover,pretraining on pancancer datasets enables strong generalization across organsand tasks, outperforming slide foundation models while using substantially lesspretraining data. These findings highlight the robust adaptability of MILmodels and demonstrate the benefits of leveraging transfer learning to boostperformance in CPath. Lastly, we provide a resource which standardizes theimplementation of MIL models and collection of pretrained model weights onpopular CPath tasks, available at https://github.com/mahmoodlab/MIL-Lab</description>
      <author>example@mail.com (Daniel Shao, Richard J. Chen, Andrew H. Song, Joel Runevic, Ming Y. Lu, Tong Ding, Faisal Mahmood)</author>
      <guid isPermaLink="false">2506.09022v2</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Data-Centric Safety and Ethical Measures for Data and AI Governance</title>
      <link>http://arxiv.org/abs/2506.10217v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper accepted and presented at the AAAI 2025 Workshop on Datasets  and Evaluators of AI Safety https://sites.google.com/view/datasafe25/home&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个负责的数据集设计框架，旨在提高人工智能（AI）模型的安全性，减少因低质量、不安全和不道德的数据内容导致的AI滥用风险。&lt;h4&gt;背景&lt;/h4&gt;数据集在赋予AI基础模型高级能力以适应各种下游任务中起着关键作用。这些下游应用可能带来有益和有害的能力，导致双用途AI基础模型，需要各种技术和监管方法来监控和管理这些风险。&lt;h4&gt;目的&lt;/h4&gt;尽管数据集在AI发展中的角色至关重要，但负责的数据集设计和确保数据中心的安仝和道德实践却得到了较少的关注。本研究旨在提出一个负责的数据集设计框架。&lt;h4&gt;方法&lt;/h4&gt;该框架涵盖了AI和数据集生命周期的各个阶段，旨在增强安全措施并减少AI误用的风险。&lt;h4&gt;主要发现&lt;/h4&gt;该框架是领域无关的，适用于各种应用，并可以促进数据集创建、使用和共享中的负责任实践，以促进红队测试、最小化风险并增加对AI模型的信任。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了数据集设计在AI安全中的重要性，并提出了一个全面的框架来提高数据质量和确保AI模型的道德使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Datasets play a key role in imparting advanced capabilities to artificialintelligence (AI) foundation models that can be adapted to various downstreamtasks. These downstream applications can introduce both beneficial and harmfulcapabilities -- resulting in dual use AI foundation models, with varioustechnical and regulatory approaches to monitor and manage these risks. However,despite the crucial role of datasets, responsible dataset design and ensuringdata-centric safety and ethical practices have received less attention. In thisstudy, we pro-pose responsible dataset design framework that encompassesvarious stages in the AI and dataset lifecycle to enhance safety measures andreduce the risk of AI misuse due to low quality, unsafe and unethical datacontent. This framework is domain agnostic, suitable for adoption for variousapplications and can promote responsible practices in dataset creation, use,and sharing to facilitate red teaming, minimize risks, and increase trust in AImodels.</description>
      <author>example@mail.com (Srija Chakraborty)</author>
      <guid isPermaLink="false">2506.10217v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent</title>
      <link>http://arxiv.org/abs/2506.10205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 workshop on Efficient Systems for Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了针对大型语言模型（LLMs）体积庞大问题，提出了基于层状后训练量化和剪枝的方法，并通过理论分析证明了该方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;LLMs由于体积庞大，在边缘设备上应用受限，因此需要模型压缩方法，如量化和剪枝。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的层状后训练量化和剪枝方法，以提高LLMs在边缘设备上的性能。&lt;h4&gt;方法&lt;/h4&gt;该方法基于激活感知权重剪枝和稀疏逼近问题之间的联系，并受到迭代硬阈值法（IHT）成功的启发，通过投影梯度下降（AWP）实现。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AWP在LLMs剪枝和量化方面优于现有方法，并提供了剪枝方法的理论收敛保证。&lt;h4&gt;结论&lt;/h4&gt;AWP是一种有效的LLMs剪枝和量化方法，可以提高LLMs在边缘设备上的性能。&lt;h4&gt;翻译&lt;/h4&gt;To address the enormous size of Large Language Models (LLMs), modelcompression methods, such as quantization and pruning, are often deployed, especially on edge devices. In this work, we focus on layer-wise post-training quantization and pruning. Drawing connections between activation-aware weight pruning and sparse approximation problems, and motivated by the success of Iterative Hard Thresholding (IHT), we propose a unified method for Activation-aware Weight pruning and quantization via Projected gradient descent (AWP). Our experiments demonstrate that AWP outperforms state-of-the-art LLM pruning and quantization methods. Theoretical convergence guarantees of the proposed method for pruning are also provided.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To address the enormous size of Large Language Models (LLMs), modelcompression methods, such as quantization and pruning, are often deployed,especially on edge devices. In this work, we focus on layer-wise post-trainingquantization and pruning. Drawing connections between activation-aware weightpruning and sparse approximation problems, and motivated by the success ofIterative Hard Thresholding (IHT), we propose a unified method forActivation-aware Weight pruning and quantization via Projected gradient descent(AWP). Our experiments demonstrate that AWP outperforms state-of-the-art LLMpruning and quantization methods. Theoretical convergence guarantees of theproposed method for pruning are also provided.</description>
      <author>example@mail.com (Jing Liu, Toshiaki Koike-Akino, Ye Wang, Hassan Mansour, Matthew Brand)</author>
      <guid isPermaLink="false">2506.10205v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Wasserstein Hypergraph Neural Network</title>
      <link>http://arxiv.org/abs/2506.09682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Wasserstein超图神经网络的模型，该模型在处理超图信息时，使用Sliced Wasserstein Pooling方法来聚合信息，并展现出在节点分类任务上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;关系信息建模在机器学习领域的应用推动了多个领域的进步，超图表示学习近年来成为主流，而通过超图表示高阶关系的方法正在迅速发展。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的超图神经网络模型，以改进节点分类任务的性能。&lt;h4&gt;方法&lt;/h4&gt;引入Wasserstein超图神经网络，该模型将节点和超边邻域视为分布，并使用Sliced Wasserstein Pooling来聚合信息。&lt;h4&gt;主要发现&lt;/h4&gt;与传统聚合器（如均值或求和）不同，该模型能够保留分布的几何属性，如形状和分布范围，从而能够反映超边分布之间的转换难度。&lt;h4&gt;结论&lt;/h4&gt;在节点分类任务上，将Wasserstein Pooling应用于超图设置显著提高了性能，在多个真实世界数据集上达到了顶尖水平。&lt;h4&gt;翻译&lt;/h4&gt;The ability to model relational information using machine learning has driven advancements across various domains, from medicine to social science. While graph representation learning has become mainstream over the past decade, representing higher-order relationships through hypergraphs is rapidly gaining momentum. In the last few years, numerous hypergraph neural networks have emerged, most of them falling under a two-stage, set-based framework. The messages are sent from nodes to edges and then from edges to nodes. However, most of the advancement still takes inspiration from the graph counterpart, often simplifying the aggregations to basic pooling operations. In this paper we are introducing Wasserstein Hypergraph Neural Network, a model that treats the nodes and hyperedge neighbourhood as distributions and aggregate the information using Sliced Wasserstein Pooling. Unlike conventional aggregators such as mean or sum, which only capture first-order statistics, our approach has the ability to preserve geometric properties like the shape and spread of distributions. This enables the learned embeddings to reflect how easily one hyperedge distribution can be transformed into another, following principles of optimal transport. Experimental results demonstrate that applying Wasserstein pooling in a hypergraph setting significantly benefits node classification tasks, achieving top performance on several real-world datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to model relational information using machine learning has drivenadvancements across various domains, from medicine to social science. Whilegraph representation learning has become mainstream over the past decade,representing higher-order relationships through hypergraphs is rapidly gainingmomentum. In the last few years, numerous hypergraph neural networks haveemerged, most of them falling under a two-stage, set-based framework. Themessages are sent from nodes to edges and then from edges to nodes. However,most of the advancement still takes inspiration from the graph counterpart,often simplifying the aggregations to basic pooling operations. In this paperwe are introducing Wasserstein Hypergraph Neural Network, a model that treatsthe nodes and hyperedge neighbourhood as distributions and aggregate theinformation using Sliced Wasserstein Pooling. Unlike conventional aggregatorssuch as mean or sum, which only capture first-order statistics, our approachhas the ability to preserve geometric properties like the shape and spread ofdistributions. This enables the learned embeddings to reflect how easily onehyperedge distribution can be transformed into another, following principles ofoptimal transport. Experimental results demonstrate that applying Wassersteinpooling in a hypergraph setting significantly benefits node classificationtasks, achieving top performance on several real-world datasets.</description>
      <author>example@mail.com (Iulia Duta, Pietro Liò)</author>
      <guid isPermaLink="false">2506.09682v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>One Patient, Many Contexts: Scaling Medical AI Through Contextual Intelligence</title>
      <link>http://arxiv.org/abs/2506.10157v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;医学基础模型，包括在临床笔记上训练的语言模型、在医学图像上的视觉-语言模型以及在电子健康记录上的多模态模型，可以总结临床笔记、回答医学问题并协助决策。适应新人群、专业或环境通常需要微调、仔细提示或从知识库中检索，这通常是不切实际的，并限制了它们解释不熟悉的输入和适应训练期间未表示的临床情况的能力。因此，模型容易出现情境错误，即预测看起来合理但未能考虑关键的病人特异性或情境信息。这些错误源于当前模型难以克服的基本限制：在医疗护理不断变化的环境中动态调整其行为。&lt;h4&gt;背景&lt;/h4&gt;医学基础模型在临床笔记、医学图像和电子健康记录上的应用，但需要针对新人群、专业或环境进行微调或检索知识库，限制了模型解释不熟悉输入和适应新情况的能力。&lt;h4&gt;目的&lt;/h4&gt;提出在医疗人工智能中实现情境切换的愿景，即模型能够动态调整推理而不需要针对新专业、人群、工作流程和临床角色进行重新训练。&lt;h4&gt;方法&lt;/h4&gt;概述情境切换在医疗人工智能中的愿景，探讨如何使模型适应不同专业和地区，诊断、管理和治疗各种疾病，并扩大医疗服务的可及性。&lt;h4&gt;主要发现&lt;/h4&gt;当前医学模型在动态调整行为以适应不断变化的医疗护理环境方面存在根本性限制，导致情境错误。&lt;h4&gt;结论&lt;/h4&gt;需要发展能够动态适应新专业、人群、工作流程和临床角色的医疗人工智能模型，以诊断、管理和治疗各种疾病，并扩大医疗服务的可及性。&lt;h4&gt;翻译&lt;/h4&gt;Medical foundation models, including language models trained on clinical notes, vision-language models on medical images, and multimodal models on electronic health records, can summarize clinical notes, answer medical questions, and assist in decision-making. Adapting these models to new populations, specialties, or settings typically requires fine-tuning, careful prompting, or retrieval from knowledge bases. This can be impractical, and limits their ability to interpret unfamiliar inputs and adjust to clinical situations not represented during training. As a result, models are prone to contextual errors, where predictions appear reasonable but fail to account for critical patient-specific or contextual information. These errors stem from a fundamental limitation that current models struggle with: dynamically adjusting their behavior across evolving contexts of medical care. In this Perspective, we outline a vision for context-switching in medical AI: models that dynamically adapt their reasoning without retraining to new specialties, populations, workflows, and clinical roles. We envision context-switching AI to diagnose, manage, and treat a wide range of diseases across specialties and regions, and expand access to medical care.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical foundation models, including language models trained on clinicalnotes, vision-language models on medical images, and multimodal models onelectronic health records, can summarize clinical notes, answer medicalquestions, and assist in decision-making. Adapting these models to newpopulations, specialties, or settings typically requires fine-tuning, carefulprompting, or retrieval from knowledge bases. This can be impractical, andlimits their ability to interpret unfamiliar inputs and adjust to clinicalsituations not represented during training. As a result, models are prone tocontextual errors, where predictions appear reasonable but fail to account forcritical patient-specific or contextual information. These errors stem from afundamental limitation that current models struggle with: dynamically adjustingtheir behavior across evolving contexts of medical care. In this Perspective,we outline a vision for context-switching in medical AI: models thatdynamically adapt their reasoning without retraining to new specialties,populations, workflows, and clinical roles. We envision context-switching AI todiagnose, manage, and treat a wide range of diseases across specialties andregions, and expand access to medical care.</description>
      <author>example@mail.com (Michelle M. Li, Ben Y. Reis, Adam Rodman, Tianxi Cai, Noa Dagan, Ran D. Balicer, Joseph Loscalzo, Isaac S. Kohane, Marinka Zitnik)</author>
      <guid isPermaLink="false">2506.10157v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>DGAE: Diffusion-Guided Autoencoder for Efficient Latent Representation Learning</title>
      <link>http://arxiv.org/abs/2506.09644v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DGAE的模型，通过视觉标记将像素压缩到潜在空间，以解决自动编码器在高压缩比下的性能退化问题，并实现更高效、紧凑的表示。&lt;h4&gt;背景&lt;/h4&gt;尽管近期进展减轻了自动编码器在高压缩比下的性能退化，但由GAN引起的训练不稳定问题仍然是未解决的问题。&lt;h4&gt;目的&lt;/h4&gt;在提高空间压缩的同时，减少潜在空间维度，以实现更高效和紧凑的表示，并解决训练不稳定问题。&lt;h4&gt;方法&lt;/h4&gt;提出DGAE模型，采用扩散模型引导解码器恢复潜在表示中未完全解码的有用信号。&lt;h4&gt;主要发现&lt;/h4&gt;DGAE在高空间压缩率下有效缓解了性能退化，同时实现了比现有方法2倍的更小潜在空间，并展现出在ImageNet-1K图像生成任务上的竞争力。&lt;h4&gt;结论&lt;/h4&gt;DGAE模型通过紧凑的潜在表示促进了扩散模型的快速收敛，实现了高效的图像生成。&lt;h4&gt;翻译&lt;/h4&gt;摘要：自动编码器通过视觉标记将像素压缩到潜在空间，从而增强了最先进的图像和视频生成模型。尽管近期进展减轻了自动编码器在高压缩比下的性能退化，但解决由GAN引起的训练不稳定问题仍然是未解决的问题。在提高空间压缩的同时，我们旨在最小化潜在空间维度，以实现更高效和紧凑的表示。为了应对这些挑战，我们专注于提高解码器的表达能力。具体来说，我们提出了DGAE，该模型采用扩散模型来引导解码器恢复潜在表示中未完全解码的有用信号。通过这种设计，DGAE在高空间压缩率下有效地缓解了性能退化。同时，DGAE实现了比现有方法2倍的更小潜在空间，并展示了在ImageNet-1K图像生成任务上的竞争力。当与扩散模型集成时，DGAEdemonstrates competitive performance on image generation for ImageNet-1K and shows that this compact latent representation facilitates faster convergence of the diffusion model.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autoencoders empower state-of-the-art image and video generative models bycompressing pixels into a latent space through visual tokenization. Althoughrecent advances have alleviated the performance degradation of autoencodersunder high compression ratios, addressing the training instability caused byGAN remains an open challenge. While improving spatial compression, we also aimto minimize the latent space dimensionality, enabling more efficient andcompact representations. To tackle these challenges, we focus on improving thedecoder's expressiveness. Concretely, we propose DGAE, which employs adiffusion model to guide the decoder in recovering informative signals that arenot fully decoded from the latent representation. With this design, DGAEeffectively mitigates the performance degradation under high spatialcompression rates. At the same time, DGAE achieves state-of-the-art performancewith a 2x smaller latent space. When integrated with Diffusion Models, DGAEdemonstrates competitive performance on image generation for ImageNet-1K andshows that this compact latent representation facilitates faster convergence ofthe diffusion model.</description>
      <author>example@mail.com (Dongxu Liu, Yuang Peng, Haomiao Tang, Yuwei Chen, Chunrui Han, Zheng Ge, Daxin Jiang, Mingxue Liao)</author>
      <guid isPermaLink="false">2506.09644v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>TaskCraft: Automated Generation of Agentic Tasks</title>
      <link>http://arxiv.org/abs/2506.10055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为TaskCraft的自动化工作流程，用于生成可调节难度、多工具、可验证的代理任务，以促进NLP和AI的发展。&lt;h4&gt;背景&lt;/h4&gt;代理任务在NLP和AI发展中变得越来越重要，但现有的指令数据缺乏工具交互，且当前代理基准测试依赖昂贵的人工标注，限制了其可扩展性。&lt;h4&gt;目的&lt;/h4&gt;提出TaskCraft旨在解决现有代理任务数据缺乏工具交互和标注成本高的问题，提高代理任务的生成效率和模型调优。&lt;h4&gt;方法&lt;/h4&gt;TaskCraft通过深度和宽度扩展来扩展原子任务，创建结构化和层次化的复杂挑战，以生成难度可调节的代理任务。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，这些任务可以提高生成工作流程中的提示优化，并增强代理基础模型的监督微调。&lt;h4&gt;结论&lt;/h4&gt;TaskCraft提供了一组大约36,000个难度各异的合成数据集，支持未来关于代理调优和评估的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：需要多步骤问题解决、自主性、工具使用和适应性推理的代理任务，正日益成为NLP和AI进步的核心。然而，现有的指令数据缺乏工具交互，当前的代理基准测试依赖于昂贵的人工标注，限制了其可扩展性。我们介绍了TaskCraft，这是一种自动化的工作流程，用于生成难度可调节的、多工具的、可验证的代理任务，具有执行轨迹。TaskCraft通过深度和宽度扩展来扩展原子任务，以创建结构化和层次化的复杂挑战。实证结果表明，这些任务可以提高生成工作流程中的提示优化，并增强代理基础模型的监督微调。我们提出了一组大约36,000个难度各异的合成数据集，以支持未来的代理调优和评估研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Agentic tasks, which require multi-step problem solving with autonomy, tooluse, and adaptive reasoning, are becoming increasingly central to theadvancement of NLP and AI. However, existing instruction data lacks toolinteraction, and current agentic benchmarks rely on costly human annotation,limiting their scalability. We introduce \textsc{TaskCraft}, an automatedworkflow for generating difficulty-scalable, multi-tool, and verifiable agentictasks with execution trajectories. TaskCraft expands atomic tasks usingdepth-based and width-based extensions to create structurally andhierarchically complex challenges. Empirical results show that these tasksimprove prompt optimization in the generation workflow and enhance supervisedfine-tuning of agentic foundation models. We present a large-scale syntheticdataset of approximately 36,000 tasks with varying difficulty to support futureresearch on agent tuning and evaluation.</description>
      <author>example@mail.com (Dingfeng Shi, Jingyi Cao, Qianben Chen, Weichen Sun, Weizhen Li, Hongxuan Lu, Fangchen Dong, Tianrui Qin, King Zhu, Minghao Yang, Jian Yang, Ge Zhang, Jiaheng Liu, Changwang Zhang, Jun Wang, Yuchen Eleanor Jiang, Wangchunshu Zhou)</author>
      <guid isPermaLink="false">2506.10055v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>AnimateAnyMesh: A Feed-Forward 4D Foundation Model for Text-Driven Universal Mesh Animation</title>
      <link>http://arxiv.org/abs/2506.09982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://animateanymesh.github.io/AnimateAnyMesh/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AnimateAnyMesh的前馈框架，该框架能够实现高效的三维网格文本驱动动画。它通过DyMeshVAE架构有效地压缩和重建动态网格序列，同时保持局部拓扑结构。&lt;h4&gt;背景&lt;/h4&gt;尽管4D内容生成领域取得了进步，但创建高质量的动画3D模型仍然具有挑战性，因为建模时空分布的复杂性以及4D训练数据的稀缺性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效进行文本驱动动画的任意三维网格的前馈框架。&lt;h4&gt;方法&lt;/h4&gt;采用了一种新的DyMeshVAE架构，该架构通过分离空间和时间特征来有效地压缩和重建动态网格序列，同时保留局部拓扑结构。此外，采用了基于Rectified Flow的训练策略，以实现高质量的文本条件生成。还贡献了包含超过400万个不同动态网格序列的DyMesh数据集。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法能够在几秒钟内生成语义准确且时间上连贯的网格动画，在质量和效率上显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;这项工作在使4D内容创作更加易于访问和实用方面迈出了重要一步。所有数据、代码和模型都将公开发布。&lt;h4&gt;翻译&lt;/h4&gt;摘要：最近在4D内容生成方面的进步引起了越来越多的关注，然而由于建模时空分布的复杂性以及4D训练数据的稀缺，创建高质量的动画3D模型仍然具有挑战性。在本文中，我们提出了AnimateAnyMesh，这是第一个能够实现任意三维网格高效文本驱动动画的前馈框架。我们的方法利用了新的DyMeshVAE架构，该架构通过分离空间和时间特征，同时保留局部拓扑结构，有效地压缩和重建动态网格序列。为了实现高质量的文本条件生成，我们在压缩的潜在空间中采用了基于Rectified Flow的训练策略。此外，我们贡献了DyMesh数据集，包含超过400万个带有文本注释的多样化动态网格序列。实验结果表明，我们的方法能够在几秒钟内生成语义准确且时间上连贯的网格动画，在质量和效率上显著优于现有方法。我们的工作在使4D内容创作更加易于访问和实用方面迈出了重要一步。所有数据、代码和模型都将公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in 4D content generation have attracted increasing attention,yet creating high-quality animated 3D models remains challenging due to thecomplexity of modeling spatio-temporal distributions and the scarcity of 4Dtraining data. In this paper, we present AnimateAnyMesh, the first feed-forwardframework that enables efficient text-driven animation of arbitrary 3D meshes.Our approach leverages a novel DyMeshVAE architecture that effectivelycompresses and reconstructs dynamic mesh sequences by disentangling spatial andtemporal features while preserving local topological structures. To enablehigh-quality text-conditional generation, we employ a Rectified Flow-basedtraining strategy in the compressed latent space. Additionally, we contributethe DyMesh Dataset, containing over 4M diverse dynamic mesh sequences with textannotations. Experimental results demonstrate that our method generatessemantically accurate and temporally coherent mesh animations in a few seconds,significantly outperforming existing approaches in both quality and efficiency.Our work marks a substantial step forward in making 4D content creation moreaccessible and practical. All the data, code, and models will be open-released.</description>
      <author>example@mail.com (Zijie Wu, Chaohui Yu, Fan Wang, Xiang Bai)</author>
      <guid isPermaLink="false">2506.09982v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>3D-Aware Vision-Language Models Fine-Tuning with Geometric Distillation</title>
      <link>http://arxiv.org/abs/2506.09883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为几何蒸馏的轻量级、无需标注的微调框架，用于增强预训练视觉语言模型对3D空间结构的理解。&lt;h4&gt;背景&lt;/h4&gt;尽管视觉语言模型在视觉和语言任务上表现出色，但在理解3D空间结构方面仍有局限。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，使预训练的视觉语言模型能够更好地理解3D空间结构。&lt;h4&gt;方法&lt;/h4&gt;通过从现成的3D基础模型（如MASt3R、VGGT）中蒸馏出（1）稀疏对应关系、（2）相对深度关系和（3）密集成本体积，将人类启发的几何线索注入预训练的视觉语言模型中，而不改变其架构。&lt;h4&gt;主要发现&lt;/h4&gt;在3D视觉语言推理和3D感知基准测试中，该方法在保持与自然图像-文本输入兼容的同时，显著提高了3D空间推理能力，并降低了计算成本。&lt;h4&gt;结论&lt;/h4&gt;该方法为将2D训练的视觉语言模型与3D理解桥接提供了一个可扩展且高效的方法，为空间基础的多模态任务打开了更广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;Vision-Language Models (VLMs) have shown remarkable performance on diverse visual and linguistic tasks, yet they remain fundamentally limited in their understanding of 3D spatial structures. We propose Geometric Distillation, a lightweight, annotation-free fine-tuning framework that injects human-inspired geometric cues into pretrained VLMs without modifying their architecture. By distilling (1) sparse correspondences, (2) relative depth relations, and (3) dense cost volumes from off-the-shelf 3D foundation models (e.g., MASt3R, VGGT), our method shapes representations to be geometry-aware while remaining compatible with natural image-text inputs. Through extensive evaluations on 3D vision-language reasoning and 3D perception benchmarks, our method consistently outperforms prior approaches, achieving improved 3D spatial reasoning with significantly lower computational cost. Our work demonstrates a scalable and efficient path to bridge 2D-trained VLMs with 3D understanding, opening up wider use in spatially grounded multimodal tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/kaist-cvml/3d-vlm-gd&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Models (VLMs) have shown remarkable performance on diversevisual and linguistic tasks, yet they remain fundamentally limited in theirunderstanding of 3D spatial structures. We propose Geometric Distillation, alightweight, annotation-free fine-tuning framework that injects human-inspiredgeometric cues into pretrained VLMs without modifying their architecture. Bydistilling (1) sparse correspondences, (2) relative depth relations, and (3)dense cost volumes from off-the-shelf 3D foundation models (e.g., MASt3R,VGGT), our method shapes representations to be geometry-aware while remainingcompatible with natural image-text inputs. Through extensive evaluations on 3Dvision-language reasoning and 3D perception benchmarks, our method consistentlyoutperforms prior approaches, achieving improved 3D spatial reasoning withsignificantly lower computational cost. Our work demonstrates a scalable andefficient path to bridge 2D-trained VLMs with 3D understanding, opening upwider use in spatially grounded multimodal tasks.</description>
      <author>example@mail.com (Seonho Lee, Jiho Choi, Inha Kang, Jiwook Kim, Junsung Park, Hyunjung Shim)</author>
      <guid isPermaLink="false">2506.09883v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Learnable Spatial-Temporal Positional Encoding for Link Prediction</title>
      <link>http://arxiv.org/abs/2506.08309v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML 2025. 28 pages, 1 figures, 22 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为L-STEP的简单时间链接预测模型，旨在有效且高效地开发可学习的时空位置编码。&lt;h4&gt;背景&lt;/h4&gt;当前的位置编码在三个方面的局限性：预定义的固定函数、仅限于结构信息、以及在大规模结构数据上的注意力机制。&lt;h4&gt;目的&lt;/h4&gt;开发一种可学习的时空位置编码，并构建一个名为L-STEP的简单时间链接预测模型。&lt;h4&gt;方法&lt;/h4&gt;L-STEP模型通过以下方法实现：1）证明所提出的位置学习方案可以从时空光谱视角保持图属性；2）验证MLPs可以充分利用表达力和达到该编码上的Transformer性能；3）改变不同的初始位置编码输入以展示鲁棒性；4）分析理论复杂度并获得比SOTA更少的经验运行时间；5）在13个经典数据集上以及10种算法在有向和无向设置中使用3种不同的采样策略展示其时间链接预测的优越性。&lt;h4&gt;主要发现&lt;/h4&gt;L-STEP在最新的大规模TGB基准测试中取得了领先性能，并在13个经典数据集上以及10种算法在两种设置中使用三种不同的采样策略展示了其时间链接预测的优越性。&lt;h4&gt;结论&lt;/h4&gt;L-STEP模型通过其有效和高效的时空位置编码方法，在时间链接预测任务中取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;Accurate predictions rely on the expressiveness power of graph deep learning frameworks like graph neural networks and graph transformers, where positional encoding mechanism has become much more indispensable in recent state-of-the-art works to record the canonical position information. However, the current positional encoding is limited in three aspects: (1) most positional encoding methods use pre-defined, and fixed functions, which are inadequate to adapt to the complex attributed graphs; (2) a few pioneering works proposed the learnable positional encoding but are still limited to the structural information, not considering the real-world time-evolving topological and feature information; (3) most positional encoding methods are equipped with transformers' attention mechanism to fully leverage their capabilities, where the dense or relational attention is often unaffordable on large-scale structured data. Hence, we aim to develop Learnable Spatial-Temporal Positional Encoding in an effective and efficient manner and propose a simple temporal link prediction model named L-STEP. Briefly, for L-STEP, we (1) prove the proposed positional learning scheme can preserve the graph property from the spatial-temporal spectral viewpoint, (2) verify that MLPs can fully exploit the expressiveness and reach transformers' performance on that encoding, (3) change different initial positional encoding inputs to show robustness, (4) analyze the theoretical complexity and obtain less empirical running time than SOTA, and (5) demonstrate its temporal link prediction out-performance on 13 classic datasets and with 10 algorithms in both transductive and inductive settings using 3 different sampling strategies. Also, L-STEP obtains the leading performance in the newest large-scale TGB benchmark. Our code is available at https://github.com/kthrn22/L-STEP.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate predictions rely on the expressiveness power of graph deep learningframeworks like graph neural networks and graph transformers, where apositional encoding mechanism has become much more indispensable in recentstate-of-the-art works to record the canonical position information. However,the current positional encoding is limited in three aspects: (1) mostpositional encoding methods use pre-defined, and fixed functions, which areinadequate to adapt to the complex attributed graphs; (2) a few pioneeringworks proposed the learnable positional encoding but are still limited to thestructural information, not considering the real-world time-evolvingtopological and feature information; (3) most positional encoding methods areequipped with transformers' attention mechanism to fully leverage theircapabilities, where the dense or relational attention is often unaffordable onlarge-scale structured data. Hence, we aim to develop LearnableSpatial-Temporal Positional Encoding in an effective and efficient manner andpropose a simple temporal link prediction model named L-STEP. Briefly, forL-STEP, we (1) prove the proposed positional learning scheme can preserve thegraph property from the spatial-temporal spectral viewpoint, (2) verify thatMLPs can fully exploit the expressiveness and reach transformers' performanceon that encoding, (3) change different initial positional encoding inputs toshow robustness, (4) analyze the theoretical complexity and obtain lessempirical running time than SOTA, and (5) demonstrate its temporal linkprediction out-performance on 13 classic datasets and with 10 algorithms inboth transductive and inductive settings using 3 different sampling strategies.Also, L-STEP obtains the leading performance in the newest large-scale TGBbenchmark. Our code is available at https://github.com/kthrn22/L-STEP.</description>
      <author>example@mail.com (Katherine Tieu, Dongqi Fu, Zihao Li, Ross Maciejewski, Jingrui He)</author>
      <guid isPermaLink="false">2506.08309v2</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Depth and Language for Open-Vocabulary Domain-Generalized Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2506.09881v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为Vireo的新型单阶段框架，用于开放词汇域通用语义分割（OV-DGSS），旨在生成未见类别的像素级掩码，同时在未见领域保持鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;Open-Vocabulary semantic segmentation (OVSS)和domain generalization in semantic segmentation (DGSS)之间存在微妙的互补性，这促使研究者提出Open-Vocabulary Domain-Generalized Semantic Segmentation (OV-DGSS)。&lt;h4&gt;目的&lt;/h4&gt;OV-DGSS旨在在保持对未见领域鲁棒性的同时，生成未见类别的像素级掩码，这对于现实世界场景，如恶劣条件下的自动驾驶至关重要。&lt;h4&gt;方法&lt;/h4&gt;Vireo框架基于冻结的视觉基础模型（VFMs），并通过深度VFMs纳入场景几何来提取域不变的结构特征。为了弥合视觉和文本模态在领域变化下的差距，提出了三个关键组件：GeoText Prompts、Coarse Mask Prior Embedding (CMPE)和Domain-Open-Vocabulary Vector EmbeddingHead (DOV-VEH)。&lt;h4&gt;主要发现&lt;/h4&gt;综合评估表明，Vireo在域泛化和开放词汇识别方面均取得了最先进的性能，并显著超越了现有方法。&lt;h4&gt;结论&lt;/h4&gt;Vireo提供了一个统一且可扩展的解决方案，以实现多样化和动态环境中的鲁棒视觉理解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：开放词汇语义分割（OVSS）和领域泛化语义分割（DGSS）之间存在着微妙的互补性，这促使提出开放词汇域通用语义分割（OV-DGSS）。OV-DGSS旨在为未见类别生成像素级掩码，同时在未见领域保持鲁棒性，这对于现实世界场景，如恶劣条件下的自动驾驶等至关重要。我们引入了Vireo，这是一个针对OV-DGSS的全新单阶段框架，首次统一了OVSS和DGSS的优势。Vireo基于冻结的视觉基础模型（VFMs），并利用深度VFMs纳入场景几何来提取域不变的结构特征。为了弥合视觉和文本模态在领域变化下的差距，我们提出了三个关键组件：GeoText提示，将几何特征与语言线索对齐并逐步优化VFM编码器表示；粗掩码先验嵌入（CMPE），用于增强梯度流以实现更快的收敛和更强的文本影响；以及域开放词汇向量嵌入头（DOV-VEH），用于融合优化后的结构和语义特征以实现鲁棒的预测。对这些组件的综合评估表明了我们的设计有效性。我们提出的Vireo在域泛化和开放词汇识别方面均达到了最先进的性能，并显著超越了现有方法，为多样化和动态环境中的鲁棒视觉理解提供了一个统一且可扩展的解决方案。代码可在https://github.com/anonymouse-9c53tp182bvz/Vireo找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-Vocabulary semantic segmentation (OVSS) and domain generalization insemantic segmentation (DGSS) highlight a subtle complementarity that motivatesOpen-Vocabulary Domain-Generalized Semantic Segmentation (OV-DGSS). OV-DGSSaims to generate pixel-level masks for unseen categories while maintainingrobustness across unseen domains, a critical capability for real-worldscenarios such as autonomous driving in adverse conditions. We introduce Vireo,a novel single-stage framework for OV-DGSS that unifies the strengths of OVSSand DGSS for the first time. Vireo builds upon the frozen Visual FoundationModels (VFMs) and incorporates scene geometry via Depth VFMs to extractdomain-invariant structural features. To bridge the gap between visual andtextual modalities under domain shift, we propose three key components: (1)GeoText Prompts, which align geometric features with language cues andprogressively refine VFM encoder representations; (2) Coarse Mask PriorEmbedding (CMPE) for enhancing gradient flow for faster convergence andstronger textual influence; and (3) the Domain-Open-Vocabulary Vector EmbeddingHead (DOV-VEH), which fuses refined structural and semantic features for robustprediction. Comprehensive evaluation on these components demonstrates theeffectiveness of our designs. Our proposed Vireo achieves the state-of-the-artperformance and surpasses existing methods by a large margin in both domaingeneralization and open-vocabulary recognition, offering a unified and scalablesolution for robust visual understanding in diverse and dynamic environments.Code is available at https://github.com/anonymouse-9c53tp182bvz/Vireo.</description>
      <author>example@mail.com (Siyu Chen, Ting Han, Chengzheng Fu, Changshe Zhang, Chaolei Wang, Jinhe Su, Guorong Cai, Meiliu Wu)</author>
      <guid isPermaLink="false">2506.09881v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model-Aided Deep Reinforcement Learning for RIS-Assisted Wireless Communication</title>
      <link>http://arxiv.org/abs/2506.09855v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures, PIMRC conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用预训练开源基础模型LWM处理无线信道并生成多用途和上下文相关信道嵌入的方法，用于联合优化基站波束成形和可重构智能表面配置，以提高无线通信的频谱效率。&lt;h4&gt;背景&lt;/h4&gt;可重构智能表面（RIS）通过动态控制信号传播在环境中，是一种增强无线通信的潜在技术。然而，由于其被动的本质和大量反射元件，其有效部署依赖于准确的信道状态信息（CSI），导致信道估计开销很高。&lt;h4&gt;目的&lt;/h4&gt;解决RIS部署中的信道估计开销问题，提高无线通信的频谱效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的框架，该框架利用预训练的开放源代码基础模型（FM）LWM处理无线信道，生成信道嵌入。设计了一个深度强化学习（DRL）模型，自动选择基站波束成形向量和RIS相移矩阵，以最大化频谱效率（SE）。&lt;h4&gt;主要发现&lt;/h4&gt;预训练FM在无线电信号理解方面可以被微调和集成到DRL中，以在无线网络中进行有效的决策。模态特定FM在现实世界网络优化中具有潜力。与基于DRL的方法和基于波束扫描的方法相比，所提出的方法在频谱效率方面表现更优，分别提高了9.89%和43.66%。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法通过预训练FM和DRL的结合，有效提高了无线通信的频谱效率，证明了模态特定FM在现实世界网络优化中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconfigurable intelligent surfaces (RIS) have emerged as a promisingtechnology for enhancing wireless communication by dynamically controllingsignal propagation in the environment. However, their efficient deploymentrelies on accurate channel state information (CSI), which leads to high channelestimation overhead due to their passive nature and the large number ofreflective elements. In this work, we solve this challenge by proposing a novelframework that leverages a pre-trained open-source foundation model (FM) namedlarge wireless model (LWM) to process wireless channels and generate versatileand contextualized channel embeddings. These embeddings are then used for thejoint optimization of the BS beamforming and RIS configurations. To be morespecific, for joint optimization, we design a deep reinforcement learning (DRL)model to automatically select the BS beamforming vector and RIS phase-shiftmatrix, aiming to maximize the spectral efficiency (SE). This work shows that apre-trained FM for radio signal understanding can be fine-tuned and integratedwith DRL for effective decision-making in wireless networks. It highlights thepotential of modality-specific FMs in real-world network optimization.According to the simulation results, the proposed method outperforms theDRL-based approach and beam sweeping-based approach, achieving 9.89% and 43.66%higher SE, respectively.</description>
      <author>example@mail.com (Mohammad Ghassemi, Sara Farrag Mobarak, Han Zhang, Ali Afana, Akram Bin Sediq, Melike Erol-Kantarci)</author>
      <guid isPermaLink="false">2506.09855v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Accurate and efficient zero-shot 6D pose estimation with frozen foundation models</title>
      <link>http://arxiv.org/abs/2506.09784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FreeZeV2是一种无需训练的方法，通过利用几何和视觉基础模型在无关数据上的预训练，实现了对未见对象的强大泛化能力。&lt;h4&gt;背景&lt;/h4&gt;从RGBD数据估计对象的6D姿态是计算机视觉中的一个基本问题，在机器人和增强现实等领域有应用。&lt;h4&gt;目的&lt;/h4&gt;探究是否需要针对特定任务的训练来实现对未见对象的准确和高效的6D姿态估计。&lt;h4&gt;方法&lt;/h4&gt;FreeZeV2通过三个关键贡献来提升性能：(i)一种稀疏特征提取策略，在不牺牲精度的前提下减少推理时间计算；(ii)一种特征感知的评分机制，改进基于RANSAC的3D注册过程中的姿态选择和姿态候选者的最终排名；(iii)一种模块化设计，支持实例分割模型的集成，增加对分割掩码错误的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;FreeZeV2在BOP基准测试的七个核心数据集上进行了评估，在未见对象的6D姿态估计中建立了新的最先进水平。使用相同的分割掩码时，FreeZeV2比FreeZe快8倍，同时精度提高了5%。使用分割模型集成时，FreeZeV2在速度比FreeZe快2.5倍的同时，精度提高了8%。&lt;h4&gt;结论&lt;/h4&gt;FreeZeV2在BOP挑战2024中被授予最佳整体方法奖。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Estimating the 6D pose of objects from RGBD data is a fundamental problem incomputer vision, with applications in robotics and augmented reality. A keychallenge is achieving generalization to novel objects that were not seenduring training. Most existing approaches address this by scaling up trainingon synthetic data tailored to the task, a process that demands substantialcomputational resources. But is task-specific training really necessary foraccurate and efficient 6D pose estimation of novel objects? To answer No!, weintroduce FreeZeV2, the second generation of FreeZe: a training-free methodthat achieves strong generalization to unseen objects by leveraging geometricand vision foundation models pre-trained on unrelated data. FreeZeV2 improvesboth accuracy and efficiency over FreeZe through three key contributions: (i) asparse feature extraction strategy that reduces inference-time computationwithout sacrificing accuracy; (ii) a feature-aware scoring mechanism thatimproves both pose selection during RANSAC-based 3D registration and the finalranking of pose candidates; and (iii) a modular design that supports ensemblesof instance segmentation models, increasing robustness to segmentation maskserrors. We evaluate FreeZeV2 on the seven core datasets of the BOP Benchmark,where it establishes a new state-of-the-art in 6D pose estimation of unseenobjects. When using the same segmentation masks, FreeZeV2 achieves a remarkable8x speedup over FreeZe while also improving accuracy by 5%. When usingensembles of segmentation models, FreeZeV2 gains an additional 8% in accuracywhile still running 2.5x faster than FreeZe. FreeZeV2 was awarded Best OverallMethod at the BOP Challenge 2024.</description>
      <author>example@mail.com (Andrea Caraffa, Davide Boscaini, Fabio Poiesi)</author>
      <guid isPermaLink="false">2506.09784v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Intelligent Design 4.0: Paradigm Evolution Toward the Agentic AI Era</title>
      <link>http://arxiv.org/abs/2506.09755v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了智能设计（ID）的发展历程及其在工程创新、效率、质量和生产力方面的提升，介绍了基于智能体AI系统的智能设计4.0（ID 4.0）新范式，并探讨了其未来发展方向。&lt;h4&gt;背景&lt;/h4&gt;智能设计（ID）在近年来对工程领域产生了深远影响，而新型的大型语言模型（LLMs）等基础模型（FMs）的兴起为工程设计的进一步变革提供了新的路径。&lt;h4&gt;目的&lt;/h4&gt;提出智能设计4.0（ID 4.0）这一新范式，并探讨其如何通过协调、自主的多智能体系统支持工程设计的端到端自动化。&lt;h4&gt;方法&lt;/h4&gt;回顾了ID的历史演变，分为四个阶段：基于规则的专家系统、特定任务的机器学习模型、大规模基础AI模型以及最近出现的多智能体协作范式。&lt;h4&gt;主要发现&lt;/h4&gt;提出了ID 4.0的概念框架，并讨论了其在支持复杂设计场景、实际设计实现、新型智能体协调机制以及与人类价值观相一致的设计目标设定方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;这些发现为推动智能设计向更高适应性、自主性和有效性发展，以应对日益复杂的设计挑战奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在过去的几十年中，智能设计（ID）的研究与实践显著提升了工程创新、效率、质量和生产力，从根本上改变了工程设计师的思维、行为以及与设计过程互动的方式。近期新兴的基础模型（FMs），特别是大型语言模型（LLMs），展现了基于通用知识的推理能力，为工程设计的进一步变革开辟了新的途径。在此背景下，本文介绍了由智能体AI系统赋能的智能设计4.0（ID 4.0）这一新兴范式。我们回顾了ID在四个不同阶段的演变：基于规则的专家系统、特定任务的机器学习模型、大规模基础AI模型以及最近出现的多智能体协作范式。我们提出了ID 4.0的概念框架，并讨论了其通过协调、自主的多智能体系统支持工程设计端到端自动化的潜力。此外，我们讨论了提升和完全实现ID 4.0潜力的未来展望，包括更复杂的设计场景、更实际的设计实现、新型的智能体协调机制以及与人类价值观更好地对齐的自主设计目标设定。总之，这些见解为推动智能设计向更高适应性、自主性和有效性发展，以应对日益复杂的设计挑战奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Research and practice in Intelligent Design (ID) have significantly enhancedengineering innovation, efficiency, quality, and productivity over recentdecades, fundamentally reshaping how engineering designers think, behave, andinteract with design processes. The recent emergence of Foundation Models(FMs), particularly Large Language Models (LLMs), has demonstrated generalknowledge-based reasoning capabilities, and open new paths and avenues forfurther transformation in engineering design. In this context, this paperintroduces Intelligent Design 4.0 (ID 4.0) as an emerging paradigm empowered byagentic AI systems. We review the historical evolution of ID across fourdistinct stages: rule-based expert systems, task-specific machine learningmodels, large-scale foundation AI models, and the recent emerging paradigm ofmulti-agent collaboration. We propose a conceptual framework for ID 4.0 anddiscuss its potential to support end-to-end automation of engineering designprocesses through coordinated, autonomous multi-agent-based systems.Furthermore, we discuss future perspectives to enhance and fully realize ID4.0's potential, including more complex design scenarios, more practical designimplementations, novel agent coordination mechanisms, and autonomous designgoal-setting with better human value alignment. In sum, these insights lay afoundation for advancing Intelligent Design toward greater adaptivity,autonomy, and effectiveness in addressing increasingly complex designchallenges.</description>
      <author>example@mail.com (Shuo Jiang, Min Xie, Frank Youhua Chen, Jian Ma, Jianxi Luo)</author>
      <guid isPermaLink="false">2506.09755v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Image Matching for UAV Absolute Visual Localization via Semantic and Structural Constraints</title>
      <link>http://arxiv.org/abs/2506.09748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对无人机绝对定位的分层跨源图像匹配方法，旨在解决GNSS信号不可用时的问题。&lt;h4&gt;背景&lt;/h4&gt;绝对定位对于无人机在各种应用中至关重要，但在GNSS信号不可用时变得具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法依赖传统低级图像匹配的局限性，提高无人机在GNSS拒止环境下的绝对定位精度和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出的方法包括语义感知和结构约束的粗匹配模块以及轻量级细粒度匹配模块，并通过图像检索模块构建无人机绝对视觉定位流程。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在各种挑战条件下具有优越的精度和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该方法在GNSS拒止环境下对无人机绝对定位具有有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Absolute localization, aiming to determine an agent's location with respectto a global reference, is crucial for unmanned aerial vehicles (UAVs) invarious applications, but it becomes challenging when global navigationsatellite system (GNSS) signals are unavailable. Vision-based absolutelocalization methods, which locate the current view of the UAV in a referencesatellite map to estimate its position, have become popular in GNSS-deniedscenarios. However, existing methods mostly rely on traditional and low-levelimage matching, suffering from difficulties due to significant differencesintroduced by cross-source discrepancies and temporal variations. To overcomethese limitations, in this paper, we introduce a hierarchical cross-sourceimage matching method designed for UAV absolute localization, which integratesa semantic-aware and structure-constrained coarse matching module with alightweight fine-grained matching module. Specifically, in the coarse matchingmodule, semantic features derived from a vision foundation model firstestablish region-level correspondences under semantic and structuralconstraints. Then, the fine-grained matching module is applied to extract finefeatures and establish pixel-level correspondences. Building upon this, a UAVabsolute visual localization pipeline is constructed without any reliance onrelative localization techniques, mainly by employing an image retrieval modulebefore the proposed hierarchical image matching modules. Experimentalevaluations on public benchmark datasets and a newly introduced CS-UAV datasetdemonstrate superior accuracy and robustness of the proposed method undervarious challenging conditions, confirming its effectiveness.</description>
      <author>example@mail.com (Xiangkai Zhang, Xiang Zhou, Mao Chen, Yuchen Lu, Xu Yang, Zhiyong Liu)</author>
      <guid isPermaLink="false">2506.09748v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>FedVLMBench: Benchmarking Federated Fine-Tuning of Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.09638v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了FedVLMBench，这是第一个用于VLM联邦微调的系统基准。&lt;h4&gt;背景&lt;/h4&gt;VLM在跨模态理解和生成方面表现出色，但现有的联邦学习（FL）方法在隐私敏感领域如医疗保健中面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出FedVLMBench，以评估联邦微调策略、模型架构和任务泛化。&lt;h4&gt;方法&lt;/h4&gt;FedVLMBench集成了两种主流VLM架构、四种微调策略、五种FL算法、六个多模态数据集，覆盖四个跨领域单任务场景和两个跨领域多任务设置，包含四个不同的下游任务类别。&lt;h4&gt;主要发现&lt;/h4&gt;发现2层MLP连接器与并发连接器和LLM调整是编码器基于VLM在FL中的最佳配置；当前FL方法在视觉中心任务中对数据异质性的敏感性显著高于文本中心任务，在无编码器和基于编码器的VLM架构中都如此。&lt;h4&gt;结论&lt;/h4&gt;FedVLMBench为研究社区提供了工具、数据集和经验指导，为多模态基础模型的隐私保护联邦训练提供了一个标准化平台。&lt;h4&gt;翻译&lt;/h4&gt;Vision-Language Models (VLMs) have demonstrated remarkable capabilities in cross-modal understanding and generation by integrating visual and textual information. While instruction tuning and parameter-efficient fine-tuning methods have substantially improved the generalization of VLMs, most existing approaches rely on centralized training, posing challenges for deployment in domains with strict privacy requirements like healthcare. Recent efforts have introduced Federated Learning (FL) into VLM fine-tuning to address these privacy concerns, yet comprehensive benchmarks for evaluating federated fine-tuning strategies, model architectures, and task generalization remain lacking. In this work, we present extbf{FedVLMBench}, the first systematic benchmark for federated fine-tuning of VLMs. FedVLMBench integrates two mainstream VLM architectures (encoder-based and encoder-free), four fine-tuning strategies, five FL algorithms, six multimodal datasets spanning four cross-domain single-task scenarios and two cross-domain multitask settings, covering four distinct downstream task categories. Through extensive experiments, we uncover key insights into the interplay between VLM architectures, fine-tuning strategies, data heterogeneity, and multi-task federated optimization. Notably, we find that a 2-layer multilayer perceptron (MLP) connector with concurrent connector and LLM tuning emerges as the optimal configuration for encoder-based VLMs in FL. Furthermore, current FL methods exhibit significantly higher sensitivity to data heterogeneity in vision-centric tasks than text-centric ones, across both encoder-free and encoder-based VLM architectures. Our benchmark provides essential tools, datasets, and empirical guidance for the research community, offering a standardized platform to advance privacy-preserving, federated training of multimodal foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Models (VLMs) have demonstrated remarkable capabilities incross-modal understanding and generation by integrating visual and textualinformation. While instruction tuning and parameter-efficient fine-tuningmethods have substantially improved the generalization of VLMs, most existingapproaches rely on centralized training, posing challenges for deployment indomains with strict privacy requirements like healthcare. Recent efforts haveintroduced Federated Learning (FL) into VLM fine-tuning to address theseprivacy concerns, yet comprehensive benchmarks for evaluating federatedfine-tuning strategies, model architectures, and task generalization remainlacking. In this work, we present \textbf{FedVLMBench}, the first systematicbenchmark for federated fine-tuning of VLMs. FedVLMBench integrates twomainstream VLM architectures (encoder-based and encoder-free), four fine-tuningstrategies, five FL algorithms, six multimodal datasets spanning fourcross-domain single-task scenarios and two cross-domain multitask settings,covering four distinct downstream task categories. Through extensiveexperiments, we uncover key insights into the interplay between VLMarchitectures, fine-tuning strategies, data heterogeneity, and multi-taskfederated optimization. Notably, we find that a 2-layer multilayer perceptron(MLP) connector with concurrent connector and LLM tuning emerges as the optimalconfiguration for encoder-based VLMs in FL. Furthermore, current FL methodsexhibit significantly higher sensitivity to data heterogeneity invision-centric tasks than text-centric ones, across both encoder-free andencoder-based VLM architectures. Our benchmark provides essential tools,datasets, and empirical guidance for the research community, offering astandardized platform to advance privacy-preserving, federated training ofmultimodal foundation models.</description>
      <author>example@mail.com (Weiying Zheng, Ziyue Lin, Pengxin Guo, Yuyin Zhou, Feifei Wang, Liangqiong Qu)</author>
      <guid isPermaLink="false">2506.09638v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Analytic Task Scheduler: Recursive Least Squares Based Method for Continual Learning in Embodied Foundation Models</title>
      <link>http://arxiv.org/abs/2506.09623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ATS的框架，用于解决具身基础模型在持续学习过程中遇到的重学问题。&lt;h4&gt;背景&lt;/h4&gt;具身基础模型在整合多模态输入理解人类意图和控制机器人方面至关重要，但它们在持续学习新技能时容易忘记之前学到的技能。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，本文旨在提出一种新的框架，以实现具身基础模型的持续学习。&lt;h4&gt;方法&lt;/h4&gt;ATS框架包括一个特定任务的模型库和一个使用递归最小二乘法（RLS）训练的解析调度器。模型库中的每个模型独立地对单个任务进行微调，调度器学习语言指令与特定任务模型之间的映射。&lt;h4&gt;主要发现&lt;/h4&gt;ATS框架能够准确识别任务并动态选择模型，同时避免了任务间的参数干扰。调度器通过仅使用统计数据（自相关矩阵和互相关矩阵）逐步更新其参数，实现了抵抗遗忘的学习，无需回顾历史数据。&lt;h4&gt;结论&lt;/h4&gt;在真实世界机器人平台上的验证表明，ATS具有优异的抵抗遗忘能力和对任务变化的强适应性，是复杂动态环境中具身基础模型持续学习的一个有效、可扩展且可部署的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Embodied foundation models are crucial for Artificial Intelligence (AI) interacting with the physical world by integrating multi-modal inputs, such as proprioception, vision and language, to understand human intentions and generate actions to control robots. While these models demonstrate strong generalization and few-shot learning capabilities, they face significant challenges in continually acquiring new skills without forgetting previously learned skills, a problem known as catastrophic forgetting. To address this issue, we propose the Analytic Task Scheduler (ATS), a novel framework for continual learning in embodied foundation models. ATS consists of a task-specific model library, where each model is fine-tuned independently on a single task, and an analytic scheduler trained using recursive least squares (RLS) to learn the mapping between language instructions and task-specific models. This architecture enables accurate task recognition and dynamic model selection while fundamentally avoiding parameter interference across tasks. The scheduler updates its parameters incrementally using only statistics (autocorrelation and cross-correlation matrices), enabling forgetting-resistant learning without the need to revisit historical data. We validate ATS on a real-world robot platform (RM65B), demonstrating superior resistance to forgetting and strong adaptability to task variations. The results highlight ATS as an effective, scalable, and deployable solution for continual learning in embodied foundation models operating in complex, dynamic environments. Our code will be available at https://github.com/MIAA-Embodied-AI/AnalyticTaskScheduler&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Embodied foundation models are crucial for Artificial Intelligence (AI)interacting with the physical world by integrating multi-modal inputs, such asproprioception, vision and language, to understand human intentions andgenerate actions to control robots. While these models demonstrate stronggeneralization and few-shot learning capabilities, they face significantchallenges in continually acquiring new skills without forgetting previouslylearned skills, a problem known as catastrophic forgetting. To address thisissue, we propose the Analytic Task Scheduler (ATS), a novel framework forcontinual learning in embodied foundation models. ATS consists of atask-specific model library, where each model is fine-tuned independently on asingle task, and an analytic scheduler trained using recursive least squares(RLS) to learn the mapping between language instructions and task-specificmodels. This architecture enables accurate task recognition and dynamic modelselection while fundamentally avoiding parameter interference across tasks. Thescheduler updates its parameters incrementally using only statistics(autocorrelation and cross-correlation matrices), enabling forgetting-resistantlearning without the need to revisit historical data. We validate ATS on areal-world robot platform (RM65B), demonstrating superior resistance toforgetting and strong adaptability to task variations. The results highlightATS as an effective, scalable, and deployable solution for continual learningin embodied foundation models operating in complex, dynamic environments. Ourcode will be available athttps://github.com/MIAA-Embodied-AI/AnalyticTaskScheduler</description>
      <author>example@mail.com (Lipei Xie, Yingxin Li, Huiping Zhuang)</author>
      <guid isPermaLink="false">2506.09623v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Image Transforms derived from Eye Gaze Variables for Progressive Autism Diagnosis</title>
      <link>http://arxiv.org/abs/2506.09065v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 8 figures, and 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于人工智能的辅助技术，用于简化自闭症谱系障碍（ASD）的诊断和管理，旨在提高ASD患者的便利性和照顾者、治疗师的工作效率。&lt;h4&gt;背景&lt;/h4&gt;过去十年中，自闭症谱系障碍的发病率迅速上升，给受影响个体的沟通、行为和注意力带来了重大挑战。现有的诊断技术虽然有效，但耗时较长，导致社会和经济成本高昂。&lt;h4&gt;目的&lt;/h4&gt;该技术旨在提高ASD诊断的便利性，同时提高照顾者和治疗师的工作效率。&lt;h4&gt;方法&lt;/h4&gt;该系统通过结合迁移学习和基于眼动变量的图像转换来诊断ASD，从而实现家庭定期诊断，减少个体和照顾者的压力，并通过图像转换保护用户隐私。&lt;h4&gt;主要发现&lt;/h4&gt;该方法的易用性为监护人和治疗师之间的沟通提供了机会，确保了对进展和不断变化的支持需求的定期更新。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法确保了及时、便捷的诊断，同时保护了受试者的隐私，改善了自闭症患者的治疗效果。&lt;h4&gt;翻译&lt;/h4&gt;The prevalence of Autism Spectrum Disorder (ASD) has surged rapidly over thepast decade, posing significant challenges in communication, behavior, andfocus for affected individuals. Current diagnostic techniques, thougheffective, are time-intensive, leading to high social and economic costs. Thiswork introduces an AI-powered assistive technology designed to streamline ASDdiagnosis and management, enhancing convenience for individuals with ASD andefficiency for caregivers and therapists. The system integrates transferlearning with image transforms derived from eye gaze variables to diagnose ASD.This facilitates and opens opportunities for in-home periodical diagnosis, reducingstress for individuals and caregivers, while also preserving user privacy throughthe use of image transforms. The accessibility of the proposed method also offersopportunities for improved communication between guardians and therapists, ensuringregular updates on progress and evolving support needs. Overall, the approachproposed in this work ensures timely, accessible diagnosis while protecting thesubjects' privacy, improving outcomes for individuals with ASD.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The prevalence of Autism Spectrum Disorder (ASD) has surged rapidly over thepast decade, posing significant challenges in communication, behavior, andfocus for affected individuals. Current diagnostic techniques, thougheffective, are time-intensive, leading to high social and economic costs. Thiswork introduces an AI-powered assistive technology designed to streamline ASDdiagnosis and management, enhancing convenience for individuals with ASD andefficiency for caregivers and therapists. The system integrates transferlearning with image transforms derived from eye gaze variables to diagnose ASD.This facilitates and opens opportunities for in-home periodical diagnosis,reducing stress for individuals and caregivers, while also preserving userprivacy through the use of image transforms. The accessibility of the proposedmethod also offers opportunities for improved communication between guardiansand therapists, ensuring regular updates on progress and evolving supportneeds. Overall, the approach proposed in this work ensures timely, accessiblediagnosis while protecting the subjects' privacy, improving outcomes forindividuals with ASD.</description>
      <author>example@mail.com (Abigail Copiaco, Christian Ritz, Yassine Himeur, Valsamma Eapen, Ammar Albanna, Wathiq Mansoor)</author>
      <guid isPermaLink="false">2506.09065v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Overconfidence: Foundation Models Redefine Calibration in Deep Neural Networks</title>
      <link>http://arxiv.org/abs/2506.09593v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文全面研究了基础模型的校准行为，揭示了挑战传统观念的见解。&lt;h4&gt;背景&lt;/h4&gt;深度神经网络在高度依赖的应用中需要可靠的校准，以避免系统性过度自信，尤其是在分布变化的情况下。&lt;h4&gt;目的&lt;/h4&gt;探索基础模型在预测性能上的校准特性。&lt;h4&gt;方法&lt;/h4&gt;进行了实证分析，研究了模型在分布内部预测中的信心水平，以及它们对后置校准技术的响应。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型在分布内部预测中往往表现出信心不足，导致更高的校准误差，但在分布变化下校准有所改善。后置校准技术能有效地减轻信心不足的偏差，但在严重的分布变化下，这些方法变得不可靠，有时甚至会产生相反的效果。&lt;h4&gt;结论&lt;/h4&gt;基础模型的校准受到架构和训练创新的非单调影响，挑战了持续改进的传统说法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable uncertainty calibration is essential for safely deploying deepneural networks in high-stakes applications. Deep neural networks are known toexhibit systematic overconfidence, especially under distribution shifts.Although foundation models such as ConvNeXt, EVA and BEiT have demonstratedsignificant improvements in predictive performance, their calibrationproperties remain underexplored. This paper presents a comprehensiveinvestigation into the calibration behavior of foundation models, revealinginsights that challenge established paradigms. Our empirical analysis showsthat these models tend to be underconfident in in-distribution predictions,resulting in higher calibration errors, while demonstrating improvedcalibration under distribution shifts. Furthermore, we demonstrate thatfoundation models are highly responsive to post-hoc calibration techniques inthe in-distribution setting, enabling practitioners to effectively mitigateunderconfidence bias. However, these methods become progressively less reliableunder severe distribution shifts and can occasionally produce counterproductiveresults. Our findings highlight the complex, non-monotonic effects ofarchitectural and training innovations on calibration, challenging establishednarratives of continuous improvement.</description>
      <author>example@mail.com (Achim Hekler, Lukas Kuhn, Florian Buettner)</author>
      <guid isPermaLink="false">2506.09593v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>From Partial to Monadic: Combinatory Algebra with Effects</title>
      <link>http://arxiv.org/abs/2506.09453v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了单调组合代数（MCAs）的概念，这是一种比部分组合代数（PCAs）更广泛计算效应的框架，并探讨了其在可计算性理论中的应用。&lt;h4&gt;背景&lt;/h4&gt;部分组合代数（PCAs）是未类型化λ演算的基础模型，也是实现论等可计算性概念的基础。然而，PCAs只通过非终止性作为计算效应，支持的计算概念非常有限。&lt;h4&gt;目的&lt;/h4&gt;为了更好地内化更广泛的计算效应，本文提出了单调组合代数（MCAs），并希望提供一个更强大的框架来推理效应丰富的计算。&lt;h4&gt;方法&lt;/h4&gt;MCAs通过在底层计算效应（由单子表示）上结构化组合代数来推广PCAs的概念。本文展示了MCAs可以通过底层单子支持各种副作用，如非确定性、状态计算和延续。此外，本文在Freyd范畴内对MCAs进行了范畴学描述，并探讨了其在实现论中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;MCAs可以支持通过底层单子实现的多种副作用，如非确定性、状态计算和延续。在Freyd范畴内，MCAs具有范畴学描述，且在实现论中，通过证据框架构建了有效的实现三重积和组装，从而推广了基于PCAs的传统实现语义。&lt;h4&gt;结论&lt;/h4&gt;单调组合代数（MCAs）为内部推理效应丰富的计算提供了一个全面而强大的框架，为更广泛的研究计算及其与实现模型和编程语言的关系铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为单调组合代数（MCAs）的概念，它是一种比部分组合代数（PCAs）更广泛计算效应的框架，并探讨了其在可计算性理论中的应用。部分组合代数（PCAs）是未类型化λ演算的基础模型，也是实现论等可计算性概念的基础。然而，PCAs只通过非终止性作为计算效应，支持的计算概念非常有限。为了更好地内化更广泛的计算效应，本文提出了单调组合代数（MCAs），并希望提供一个更强大的框架来推理效应丰富的计算。单调组合代数（MCAs）通过在底层计算效应（由单子表示）上结构化组合代数来推广部分组合代数（PCAs）的概念。本文展示了单调组合代数（MCAs）可以通过底层单子支持各种副作用，如非确定性、状态计算和延续。此外，本文在Freyd范畴内对单调组合代数（MCAs）进行了范畴学描述，并探讨了其在实现论中的应用。在Freyd范畴内，单调组合代数（MCAs）具有范畴学描述，且在实现论中，通过证据框架构建了有效的实现三重积和组装，从而推广了基于部分组合代数（PCAs）的传统实现语义。单调组合代数（MCAs）为内部推理效应丰富的计算提供了一个全面而强大的框架，为更广泛的研究计算及其与实现模型和编程语言的关系铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Partial Combinatory Algebras (PCAs) provide a foundational model of theuntyped $\lambda$-calculus and serve as the basis for many notions ofcomputability, such as realizability theory. However, PCAs support a verylimited notion of computation by only incorporating non-termination as acomputational effect. To provide a framework that better internalizes a widerange of computational effects, this paper puts forward the notion of MonadicCombinatory Algebras (MCAs). MCAs generalize the notion of PCAs by structuringthe combinatory algebra over an underlying computational effect, embodied by amonad. We show that MCAs can support various side effects through theunderlying monad, such as non-determinism, stateful computation andcontinuations. We further obtain a categorical characterization of MCAs withinFreyd Categories, following a similar connection for PCAs. Moreover, we explorethe application of MCAs in realizability theory, presenting constructions ofeffectful realizability triposes and assemblies derived through evidencedframes, thereby generalizing traditional PCA-based realizability semantics. Themonadic generalization of the foundational notion of PCAs provides acomprehensive and powerful framework for internally reasoning about effectfulcomputations, paving the path to a more encompassing study of computation andits relationship with realizability models and programming languages.</description>
      <author>example@mail.com (Liron Cohen, Ariel Grunfeld, Dominik Kirst, Étienne Miquey)</author>
      <guid isPermaLink="false">2506.09453v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>OWSM-Biasing: Contextualizing Open Whisper-Style Speech Models for Automatic Speech Recognition with Dynamic Vocabulary</title>
      <link>http://arxiv.org/abs/2506.09448v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将现有CB方法与OWSM v3.1结合的方法，通过冻结预训练参数，利用SFMs的知识来有效进行CB，提高了识别准确率。&lt;h4&gt;背景&lt;/h4&gt;尽管SFMs在自动语音识别方面表现出色，但它们在识别罕见和未见词语时仍然存在困难。&lt;h4&gt;目的&lt;/h4&gt;通过结合CB方法和OWSM v3.1，旨在提高对罕见和未见词语的识别准确率。&lt;h4&gt;方法&lt;/h4&gt;在OWSM v3.1的基础上，采用CB方法，同时冻结其预训练参数，以利用SFMs的知识。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法提高了B-WER 11.6个百分点，整体W ER提高了0.9个百分点，同时将实时因素降低了7.5%。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效提高罕见和未见词语的识别准确率，同时保持OWSM v3.1的优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语音基础模型（SFMs），如Open Whisper-Style Speech Models(OWSM)，在大量数据集上进行训练以实现准确的自动语音识别。然而，即使SFMs也难以准确识别罕见和未见词语。尽管上下文偏置（CB）是提高此类词语识别率的有希望的方法，但大多数CB方法都是从头开始训练的，由于缺乏预训练知识，其性能低于SFMs。本文将一个现有的CB方法与OWSM v3.1结合，同时冻结其预训练参数。通过利用SFMs中嵌入的知识，该方法能够有效地进行CB，同时保持SFMs的优势，即使是在小数据集上。实验结果表明，该方法将偏置词语错误率（B-WER）提高了11.6个百分点，相对于非偏置基线，在LibriSpeech 100测试集上使整体W ER提高了0.9个百分点，同时将实时因素降低了7.5%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech foundation models (SFMs), such as Open Whisper-Style Speech Models(OWSM), are trained on massive datasets to achieve accurate automatic speechrecognition. However, even SFMs struggle to accurately recognize rare andunseen words. While contextual biasing (CB) is a promising approach to improverecognition of such words, most CB methods are trained from scratch, resultingin lower performance than SFMs due to the lack of pre-trained knowledge. Thispaper integrates an existing CB method with OWSM v3.1 while freezing itspre-trained parameters. By leveraging the knowledge embedded in SFMs, theproposed method enables effective CB while preserving the advantages of SFMs,even with a small dataset. Experimental results show that the proposed methodimproves the biasing word error rate (B-WER) by 11.6 points, resulting in a 0.9point improvement in the overall WER while reducing the real-time factor by7.5% compared to the non-biasing baseline on the LibriSpeech 100 test-cleanset.</description>
      <author>example@mail.com (Yui Sudo, Yusuke Fujita, Atsushi Kojima, Tomoya Mizumoto, Lianbo Liu)</author>
      <guid isPermaLink="false">2506.09448v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>GigaChat Family: Efficient Russian Language Modeling Through Mixture of Experts Architecture</title>
      <link>http://arxiv.org/abs/2506.09440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACL-2025 System Demo&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GigaChat系列俄罗斯语言大语言模型，包括不同规模的模型和指令微调版本，并详细报告了模型架构、预训练过程和实验设计。此外，评估了这些模型在俄罗斯和英语基准测试中的性能，并与多语言模型进行了比较。文章展示了高性能模型通过API、Telegram机器人以及Web界面可供使用，并发布了三个开源GigaChat模型以促进NLP研究和支持俄罗斯语言的工业解决方案开发。&lt;h4&gt;背景&lt;/h4&gt;现代自然语言处理（NLP）研究和应用中，生成式大语言模型（LLMs）变得至关重要，但针对俄罗斯语言的专用基础模型开发有限，主要由于所需的计算资源巨大。&lt;h4&gt;目的&lt;/h4&gt;介绍GigaChat系列俄罗斯LLMs，评估其性能，并促进NLP研究和俄罗斯语言工业解决方案的开发。&lt;h4&gt;方法&lt;/h4&gt;详细报告了模型架构、预训练过程和实验设计，并进行了性能评估和比较。&lt;h4&gt;主要发现&lt;/h4&gt;GigaChat系列模型在俄罗斯和英语基准测试中表现出色，并通过API、Telegram机器人以及Web界面提供使用。&lt;h4&gt;结论&lt;/h4&gt;GigaChat系列模型为俄罗斯语言的NLP研究和工业应用提供了强大的工具，并通过开源模型促进了这些领域的进一步发展。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一系列针对俄语的生成式大型语言模型（GigaChat），包括不同规模的基础模型和指令微调版本。我们详细介绍了模型架构、预训练过程和实验设计，并对它们在俄语和英语基准上的性能进行了评估，与多语言模型进行了比较。文章展示了性能最优异的模型通过API、Telegram机器人以及Web界面可供使用。此外，我们还发布了三个开源的GigaChat模型，旨在扩展NLP研究机会并支持俄语工业解决方案的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative large language models (LLMs) have become crucial for modern NLPresearch and applications across various languages. However, the development offoundational models specifically tailored to the Russian language has beenlimited, primarily due to the significant computational resources required.This paper introduces the GigaChat family of Russian LLMs, available in varioussizes, including base models and instruction-tuned versions. We provide adetailed report on the model architecture, pre-training process, andexperiments to guide design choices. In addition, we evaluate their performanceon Russian and English benchmarks and compare GigaChat with multilingualanalogs. The paper presents a system demonstration of the top-performing modelsaccessible via an API, a Telegram bot, and a Web interface. Furthermore, wehave released three open GigaChat models in open-source(https://huggingface.co/ai-sage), aiming to expand NLP research opportunitiesand support the development of industrial solutions for the Russian language.</description>
      <author>example@mail.com (GigaChat team, Mamedov Valentin, Evgenii Kosarev, Gregory Leleytner, Ilya Shchuckin, Valeriy Berezovskiy, Daniil Smirnov, Dmitry Kozlov, Sergei Averkiev, Lukyanenko Ivan, Aleksandr Proshunin, Ainur Israfilova, Ivan Baskov, Artem Chervyakov, Emil Shakirov, Mikhail Kolesov, Daria Khomich, Darya Latortseva, Sergei Porkhun, Yury Fedorov, Oleg Kutuzov, Polina Kudriavtseva, Sofiia Soldatova, Kolodin Egor, Stanislav Pyatkin, Dzmitry Menshykh, Grafov Sergei, Eldar Damirov, Karlov Vladimir, Ruslan Gaitukiev, Arkadiy Shatenov, Alena Fenogenova, Nikita Savushkin, Fedor Minkin)</author>
      <guid isPermaLink="false">2506.09440v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Anomaly Detection and Generation with Diffusion Models: A Survey</title>
      <link>http://arxiv.org/abs/2506.09368v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 11 figures, 13 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基于扩散模型（DMs）的异常检测与生成（ADGDM），分析了其理论基础和实际应用，涵盖了图像、视频、时间序列、表格和多模态数据。&lt;h4&gt;背景&lt;/h4&gt;异常检测在网络安全、金融、医疗保健和工业制造等多个领域发挥着关键作用，而深度学习中的扩散模型因其学习复杂数据分布和生成高保真样本的能力，为无监督异常检测提供了一个强大的框架。&lt;h4&gt;目的&lt;/h4&gt;本文旨在全面回顾ADGDM，强调异常检测和生成之间的内在协同关系，并通过分类和比较不同方法来分析其优缺点。&lt;h4&gt;方法&lt;/h4&gt;本文采用了一种教程式分析方法，详细讨论了基于异常评分机制、条件策略和架构设计的ADGDM方法，并分析了它们的优缺点。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，扩散模型能够通过生成技术直接解决异常数据稀缺的根本挑战，同时检测方法提供反馈以改进生成准确性和相关性，从而提升两种技术的潜力。&lt;h4&gt;结论&lt;/h4&gt;本文讨论了可扩展性和计算效率等关键挑战，并概述了未来研究方向，如高效架构、条件策略和与基础模型（如视觉语言模型和大型语言模型）的集成。&lt;h4&gt;翻译&lt;/h4&gt;摘要：异常检测（AD）在网络安全、金融、医疗保健和工业制造等多个领域发挥着关键作用，通过识别现实数据中偏离既定规范的意外模式。近年来，深度学习中的扩散模型（DMs）因其能够学习复杂数据分布和生成高保真样本的能力，引起广泛关注，为无监督异常检测提供了一个强大的框架。在本综述中，我们全面回顾了基于扩散模型的异常检测与生成（ADGDM），以教程式分析的方式探讨了其理论基础和实践应用，涵盖了图像、视频、时间序列、表格和多模态数据。关键的是，与通常将异常检测和生成视为独立问题的现有综述不同，我们强调了它们之间的内在协同关系。我们揭示了扩散模型如何通过生成技术直接解决异常数据稀缺的根本挑战，同时检测方法提供反馈以改进生成准确性和相关性，从而提升两种技术的潜力。一个详细的分类法根据异常评分机制、条件策略和架构设计对ADGDM方法进行分类，分析了它们的优缺点。我们最后讨论了包括可扩展性和计算效率在内的关键挑战，并概述了包括高效架构、条件策略和与基础模型（例如视觉语言模型和大型语言模型）集成在内的有希望的未来方向。通过综合最近的研究进展和概述开放的研究问题，本综述旨在指导研究人员和实践者利用扩散模型在多种应用中实现创新的异常检测解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection (AD) plays a pivotal role across diverse domains, includingcybersecurity, finance, healthcare, and industrial manufacturing, byidentifying unexpected patterns that deviate from established norms inreal-world data. Recent advancements in deep learning, specifically diffusionmodels (DMs), have sparked significant interest due to their ability to learncomplex data distributions and generate high-fidelity samples, offering arobust framework for unsupervised AD. In this survey, we comprehensively reviewanomaly detection and generation with diffusion models (ADGDM), presenting atutorial-style analysis of the theoretical foundations and practicalimplementations and spanning images, videos, time series, tabular, andmultimodal data. Crucially, unlike existing surveys that often treat anomalydetection and generation as separate problems, we highlight their inherentsynergistic relationship. We reveal how DMs enable a reinforcing cycle wheregeneration techniques directly address the fundamental challenge of anomalydata scarcity, while detection methods provide critical feedback to improvegeneration fidelity and relevance, advancing both capabilities beyond theirindividual potential. A detailed taxonomy categorizes ADGDM methods based onanomaly scoring mechanisms, conditioning strategies, and architectural designs,analyzing their strengths and limitations. We final discuss key challengesincluding scalability and computational efficiency, and outline promisingfuture directions such as efficient architectures, conditioning strategies, andintegration with foundation models (e.g., visual-language models and largelanguage models). By synthesizing recent advances and outlining open researchquestions, this survey aims to guide researchers and practitioners inleveraging DMs for innovative AD solutions across diverse applications.</description>
      <author>example@mail.com (Yang Liu, Jing Liu, Chengfang Li, Rui Xi, Wenchao Li, Liang Cao, Jin Wang, Laurence T. Yang, Junsong Yuan, Wei Zhou)</author>
      <guid isPermaLink="false">2506.09368v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>OmniDRCA: Parallel Speech-Text Foundation Model via Dual-Resolution Speech Representations and Contrastive Alignment</title>
      <link>http://arxiv.org/abs/2506.09349v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了OmniDRCA，一种基于联合自回归建模的并行语音-文本基础模型，它具有双重分辨率语音表示和对比跨模态对齐的特点。&lt;h4&gt;背景&lt;/h4&gt;近期关于使用大型语言模型（LLMs）进行端到端语音生成的研究引起了广泛关注，许多研究将基于文本的LLMs扩展到生成离散语音标记。&lt;h4&gt;目的&lt;/h4&gt;提出OmniDRCA模型，旨在通过联合自回归建模实现并行语音-文本生成，并提高语音理解能力。&lt;h4&gt;方法&lt;/h4&gt;OmniDRCA采用双重分辨率语音表示和对比跨模态对齐，并行处理语音和文本表示，并通过对比对齐增强音频理解。&lt;h4&gt;主要发现&lt;/h4&gt;在Spoken Question Answering基准测试中，OmniDRCA在基于并行联合语音-文本建模的基础模型中建立了新的最先进（SOTA）性能，并且与交错模型相比，表现出了具有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;OmniDRCA模型展示了在并行语音-文本生成中的潜力，并探讨了将该框架扩展到全双工对话场景的可能性。&lt;h4&gt;翻译&lt;/h4&gt;Recent studies on end-to-end speech generation with large language models (LLMs) have attracted significant community attention, with multiple works extending text-based LLMs to generate discrete speech tokens. Existing approaches primarily fall into two categories: (1) Methods that generate discrete speech tokens independently without incorporating them into the LLM's autoregressive process, resulting in text generation being unaware of concurrent speech synthesis. (2) Models that generate interleaved or parallel speech-text tokens through joint autoregressive modeling, enabling mutual modality awareness during generation. This paper presents OmniDRCA, a parallel speech-text foundation model based on joint autoregressive modeling, featuring dual-resolution speech representations and contrastive cross-modal alignment. Our approach processes speech and text representations in parallel while enhancing audio comprehension through contrastive alignment. Experimental results on Spoken Question Answering benchmarks demonstrate that OmniDRCA establishes new state-of-the-art (SOTA) performance among parallel joint speech-text modeling based foundation models, and achieves competitive performance compared to interleaved models. Additionally, we explore the potential of extending the framework to full-duplex conversational scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies on end-to-end speech generation with large language models(LLMs) have attracted significant community attention, with multiple worksextending text-based LLMs to generate discrete speech tokens. Existingapproaches primarily fall into two categories: (1) Methods that generatediscrete speech tokens independently without incorporating them into the LLM'sautoregressive process, resulting in text generation being unaware ofconcurrent speech synthesis. (2) Models that generate interleaved or parallelspeech-text tokens through joint autoregressive modeling, enabling mutualmodality awareness during generation. This paper presents OmniDRCA, a parallelspeech-text foundation model based on joint autoregressive modeling, featuringdual-resolution speech representations and contrastive cross-modal alignment.Our approach processes speech and text representations in parallel whileenhancing audio comprehension through contrastive alignment. Experimentalresults on Spoken Question Answering benchmarks demonstrate that OmniDRCAestablishes new state-of-the-art (SOTA) performance among parallel jointspeech-text modeling based foundation models, and achieves competitiveperformance compared to interleaved models. Additionally, we explore thepotential of extending the framework to full-duplex conversational scenarios.</description>
      <author>example@mail.com (Chao-Hong Tan, Qian Chen, Wen Wang, Chong Deng, Qinglin Zhang, Luyao Cheng, Hai Yu, Xin Zhang, Xiang Lv, Tianyu Zhao, Chong Zhang, Yukun Ma, Yafeng Chen, Hui Wang, Jiaqing Liu, Jieping Ye)</author>
      <guid isPermaLink="false">2506.09349v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>UAD: Unsupervised Affordance Distillation for Generalization in Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2506.09284v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了UAD（无监督 affordance蒸馏）方法，用于从基础模型中提取affordance知识，并构建任务条件化的affordance模型，无需手动标注。&lt;h4&gt;背景&lt;/h4&gt;为了使机器人在非结构化环境中执行开放式任务指令，理解细粒度对象affordance至关重要。然而，现有的视觉affordance预测方法通常依赖于手动标注数据或仅在预定义的任务集上运行。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需手动标注数据的方法，从基础模型中提取affordance知识，并构建能够泛化到真实世界场景的任务条件化affordance模型。&lt;h4&gt;方法&lt;/h4&gt;UAD方法结合了大型视觉模型和视觉-语言模型的优势，自动标注包含详细指令和视觉affordance对的庞大数据集。通过在冻结特征之上训练轻量级的任务条件化解码器，UAD展现出在模拟渲染对象训练后，对真实世界场景和不同人类活动的显著泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;UAD使用提供的affordance作为观察空间，展示了一种模仿学习策略，该策略在仅进行10次演示训练后，表现出对未见过的对象实例、对象类别以及任务指令变化的良好泛化能力。&lt;h4&gt;结论&lt;/h4&gt;UAD方法能够有效地从基础模型中提取affordance知识，并构建具有良好泛化能力的任务条件化affordance模型，为机器人操作非结构化环境中的对象提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;理解细粒度对象affordance对于机器人在非结构化环境中根据开放式任务指令操作物体至关重要。然而，现有的视觉affordance预测方法往往依赖于手动标注数据或仅基于预定义的任务集。我们介绍了UAD（无监督affordance蒸馏）方法，该方法从基础模型中提取affordance知识到任务条件化的affordance模型中，无需任何手动标注。通过利用大型视觉模型和视觉-语言模型的互补优势，UAD自动标注了一个包含详细指令和视觉affordance对的大规模数据集。仅训练一个轻量级的任务条件化解码器在冻结特征之上，UAD在仅训练模拟渲染对象的情况下，显示出对真实世界场景和各种人类活动的显著泛化能力。使用UAD提供的affordance作为观察空间，我们展示了一种模仿学习策略，该策略在训练10次演示后表现出对未见过的对象实例、对象类别以及任务指令变化的良好泛化能力。项目网站：https://unsup-affordance.github.io/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding fine-grained object affordances is imperative for robots tomanipulate objects in unstructured environments given open-ended taskinstructions. However, existing methods of visual affordance predictions oftenrely on manually annotated data or conditions only on a predefined set oftasks. We introduce UAD (Unsupervised Affordance Distillation), a method fordistilling affordance knowledge from foundation models into a task-conditionedaffordance model without any manual annotations. By leveraging thecomplementary strengths of large vision models and vision-language models, UADautomatically annotates a large-scale dataset with detailed $&lt;$instruction,visual affordance$&gt;$ pairs. Training only a lightweight task-conditioneddecoder atop frozen features, UAD exhibits notable generalization toin-the-wild robotic scenes and to various human activities, despite only beingtrained on rendered objects in simulation. Using affordance provided by UAD asthe observation space, we show an imitation learning policy that demonstratespromising generalization to unseen object instances, object categories, andeven variations in task instructions after training on as few as 10demonstrations. Project website: https://unsup-affordance.github.io/</description>
      <author>example@mail.com (Yihe Tang, Wenlong Huang, Yingke Wang, Chengshu Li, Roy Yuan, Ruohan Zhang, Jiajun Wu, Li Fei-Fei)</author>
      <guid isPermaLink="false">2506.09284v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Estimating Visceral Adiposity from Wrist-Worn Accelerometry</title>
      <link>http://arxiv.org/abs/2506.09167v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了内脏脂肪组织（VAT）与代谢健康和习惯性体力活动（PA）之间的关系，发现体力活动与VAT之间存在强相关性，并可能影响代谢健康风险。&lt;h4&gt;背景&lt;/h4&gt;内脏脂肪组织是代谢健康和习惯性体力活动的重要标志。过多的VAT与2型糖尿病和胰岛素抵抗高度相关。&lt;h4&gt;目的&lt;/h4&gt;研究通过使用国家健康与营养调查（NHANES）数据，检验体力活动与VAT之间的关系。&lt;h4&gt;方法&lt;/h4&gt;使用两种方法从活动数据中估计VAT：一种方法基于步态和睡眠中的运动特征，使用岭回归将特征统计映射到VAT估计；另一种方法使用深度神经网络，将24小时的连续加速度计数据转换为VAT估计。&lt;h4&gt;主要发现&lt;/h4&gt;两种方法结合使用，并加入关于受试者人口统计学和身体测量信息的协变量，可以获得最准确的VAT估计，相关系数为r=0.86。&lt;h4&gt;结论&lt;/h4&gt;体力活动与VAT之间存在强相关性，进而可能影响代谢健康风险。&lt;h4&gt;翻译&lt;/h4&gt;Visceral adipose tissue (VAT) is a key marker of both metabolic health and habitual physical activity (PA). Excess VAT is highly correlated with type 2 diabetes and insulin resistance. The mechanistic basis for this pathophysiology relates to overloading the liver with fatty acids. VAT is also a highly labile fat depot, with increased turnover stimulated by catecholamines during exercise. VAT can be measured with sophisticated imaging technologies, but can also be inferred directly from PA. We tested this relationship using National Health and Nutrition Examination Survey (NHANES) data from 2011-2014, for individuals aged 20-60 years with 7 days of accelerometry data (n=2,456 men; 2,427 women) [1]. Two approaches were used for estimating VAT from activity. The first used engineered features based on movements during gait and sleep, and then ridge regression to map summary statistics of these features into a VAT estimate. The second approach used deep neural networks trained on 24 hours of continuous accelerometry. A foundation model first mapped each 10s frame into a high-dimensional feature vector. A transformer model then mapped each day's feature vector time series into a VAT estimate, which were averaged over multiple days. For both approaches, the most accurate estimates were obtained with the addition of covariate information about subject demographics and body measurements. The best performance was obtained by combining the two approaches, resulting in VAT estimates with correlations of r=0.86. These findings demonstrate a strong relationship between PA and VAT and, by extension, between PA and metabolic health risks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visceral adipose tissue (VAT) is a key marker of both metabolic health andhabitual physical activity (PA). Excess VAT is highly correlated with type 2diabetes and insulin resistance. The mechanistic basis for this pathophysiologyrelates to overloading the liver with fatty acids. VAT is also a highly labilefat depot, with increased turnover stimulated by catecholamines duringexercise. VAT can be measured with sophisticated imaging technologies, but canalso be inferred directly from PA. We tested this relationship using NationalHealth and Nutrition Examination Survey (NHANES) data from 2011-2014, forindividuals aged 20-60 years with 7 days of accelerometry data (n=2,456 men;2,427 women) [1]. Two approaches were used for estimating VAT from activity.The first used engineered features based on movements during gait and sleep,and then ridge regression to map summary statistics of these features into aVAT estimate. The second approach used deep neural networks trained on 24 hoursof continuous accelerometry. A foundation model first mapped each 10s frameinto a high-dimensional feature vector. A transformer model then mapped eachday's feature vector time series into a VAT estimate, which were averaged overmultiple days. For both approaches, the most accurate estimates were obtainedwith the addition of covariate information about subject demographics and bodymeasurements. The best performance was obtained by combining the twoapproaches, resulting in VAT estimates with correlations of r=0.86. Thesefindings demonstrate a strong relationship between PA and VAT and, byextension, between PA and metabolic health risks.</description>
      <author>example@mail.com (James R. Williamson, Andrew Alini, Brian A. Telfer, Adam W. Potter, Karl E. Friedl)</author>
      <guid isPermaLink="false">2506.09167v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>TRACE: Grounding Time Series in Context for Multimodal Embedding and Retrieval</title>
      <link>http://arxiv.org/abs/2506.09114v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TRACE的多模态检索器，用于有效处理和检索动态数据中的时间序列数据。&lt;h4&gt;背景&lt;/h4&gt;在天气、医疗保健和能源等领域，动态数据的存在强调了有效解释和检索时间序列数据的必要性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够处理多模态数据并提高时间序列模型性能的检索系统。&lt;h4&gt;方法&lt;/h4&gt;TRACE通过将时间序列嵌入与对齐的文本上下文相关联，实现细粒度的通道级对齐，并采用硬负样本挖掘来促进语义上有意义的检索。&lt;h4&gt;主要发现&lt;/h4&gt;TRACE支持灵活的跨模态检索模式，如文本到时间序列和时间序列到文本，有效地将语言描述与复杂的时序模式联系起来。&lt;h4&gt;结论&lt;/h4&gt;TRACE不仅在下游预测和分类任务中实现了最先进的性能，而且还作为一个强大的独立编码器，通过轻量级任务特定调整来优化上下文感知表示。&lt;h4&gt;翻译&lt;/h4&gt;摘要：动态数据在天气、医疗保健和能源等领域的普遍存在，强调了有效解释和检索时间序列数据的必要性。这些数据本质上是与特定领域的上下文相关的，如临床记录或天气叙述，这使得跨模态检索对于下游任务以及通过检索增强的生成（RAG）开发鲁棒的时间序列基础模型至关重要。尽管需求不断增长，但时间序列检索仍然在很大程度上未得到探索。现有方法通常缺乏语义基础，难以对齐异构模态，并且处理多通道信号的能力有限。为了解决这一差距，我们提出了TRACE，一个通用的多模态检索器，它将时间序列嵌入与对齐的文本上下文相关联。TRACE实现了细粒度的通道级对齐，并采用硬负样本挖掘来促进语义上有意义的检索。它支持灵活的跨模态检索模式，包括文本到时间序列和时间序列到文本，有效地将语言描述与复杂的时序模式联系起来。通过检索语义相关的对，TRACE丰富了下游模型的有信息上下文，从而提高了预测准确性和可解释性。除了静态检索引擎之外，TRACE还作为一个强大的独立编码器，通过轻量级任务特定调整来优化上下文感知表示，同时保持强大的跨模态对齐。这些表示在下游预测和分类任务中实现了最先进的性能。在多个领域的广泛实验突出了其双重效用，作为下游应用的有效编码器和通用检索器，以增强时间序列模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ubiquity of dynamic data in domains such as weather, healthcare, andenergy underscores a growing need for effective interpretation and retrieval oftime-series data. These data are inherently tied to domain-specific contexts,such as clinical notes or weather narratives, making cross-modal retrievalessential not only for downstream tasks but also for developing robusttime-series foundation models by retrieval-augmented generation (RAG). Despitethe increasing demand, time-series retrieval remains largely underexplored.Existing methods often lack semantic grounding, struggle to align heterogeneousmodalities, and have limited capacity for handling multi-channel signals. Toaddress this gap, we propose TRACE, a generic multimodal retriever that groundstime-series embeddings in aligned textual context. TRACE enables fine-grainedchannel-level alignment and employs hard negative mining to facilitatesemantically meaningful retrieval. It supports flexible cross-modal retrievalmodes, including Text-to-Timeseries and Timeseries-to-Text, effectively linkinglinguistic descriptions with complex temporal patterns. By retrievingsemantically relevant pairs, TRACE enriches downstream models with informativecontext, leading to improved predictive accuracy and interpretability. Beyond astatic retrieval engine, TRACE also serves as a powerful standalone encoder,with lightweight task-specific tuning that refines context-awarerepresentations while maintaining strong cross-modal alignment. Theserepresentations achieve state-of-the-art performance on downstream forecastingand classification tasks. Extensive experiments across multiple domainshighlight its dual utility, as both an effective encoder for downstreamapplications and a general-purpose retriever to enhance time-series models.</description>
      <author>example@mail.com (Jialin Chen, Ziyu Zhao, Gaukhar Nurbek, Aosong Feng, Ali Maatouk, Leandros Tassiulas, Yifeng Gao, Rex Ying)</author>
      <guid isPermaLink="false">2506.09114v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>The Urban Model Platform: A Public Backbone for Modeling and Simulation in Urban Digital Twins</title>
      <link>http://arxiv.org/abs/2506.10964v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;城市数字孪生被视为整合城市数字资源，实现更可持续和综合的城市规划的一种方式。&lt;h4&gt;背景&lt;/h4&gt;模型和模拟在城市数字孪生中起着核心作用，但将模型整合到城市数字孪生中是一个复杂的任务。&lt;h4&gt;目的&lt;/h4&gt;研究如何表示城市复杂性，如何处理不确定性和建模范式，以及如何捕捉潜在的权力关系。&lt;h4&gt;方法&lt;/h4&gt;采用参与式设计方法，与德国汉堡市合作，研究开放城市模型平台的作用。&lt;h4&gt;主要发现&lt;/h4&gt;开放的Urban Model Platform可以作为城市数字孪生中建模和模拟的公共技术支柱，同时也是城市过程协作和多元表示的社会技术框架。&lt;h4&gt;结论&lt;/h4&gt;该平台基于开放标准，允许模型去中心化集成，支持模型间的通信，并支持多模型方法来表示城市系统。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urban digital twins are increasingly perceived as a way to pool the growingdigital resources of cities for the purpose of a more sustainable andintegrated urban planning. Models and simulations are central to thisundertaking: They enable "what if?" scenarios, create insights and describerelationships between the vast data that is being collected. However, theprocess of integrating and subsequently using models in urban digital twins isan inherently complex undertaking. It raises questions about how to representurban complexity, how to deal with uncertain assUrban Model Platformtions andmodeling paradigms, and how to capture underlying power relations. Existentapproaches in the domain largely focus on monolithic and centralized solutionsin the tradition of neoliberal city-making, oftentimes prohibiting pluralisticand open interoperable models. Using a participatory design for participatorysystems approach together with the City of Hamburg, Germany, we find that anopen Urban Model Platform can function both as a public technological backbonefor modeling and simulation in urban digital twins and as a socio-technicalframework for a collaborative and pluralistic representation of urbanprocesses. Such a platform builds on open standards, allows for a decentralizedintegration of models, enables communication between models and supports amulti-model approach to representing urban systems.</description>
      <author>example@mail.com (Rico H Herzog, Till Degkwitz, Trivik Verma)</author>
      <guid isPermaLink="false">2506.10964v1</guid>
      <pubDate>Fri, 13 Jun 2025 14:28:35 +0800</pubDate>
    </item>
    <item>
      <title>Segment Concealed Objects with Incomplete Supervision</title>
      <link>http://arxiv.org/abs/2506.08955v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE TPAMI&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一的方法来解决不完全监督下隐蔽物体分割（ISCOS）的挑战，通过使用不完全标注的数据进行模型训练，实现了物体与其周围环境的无缝分割。&lt;h4&gt;背景&lt;/h4&gt;ISCOS任务面临两个主要挑战：一是不完全标注数据提供的有限监督，二是区分隐蔽物体和背景的困难，这源于隐蔽场景中的内在相似性。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种统一的方法来克服上述挑战，并实现ISCOS的高效分割。&lt;h4&gt;方法&lt;/h4&gt;提出了一个名为SEE的统一mean-teacher框架，利用视觉基础模型“SegmentAnything Model (SAM)”生成伪标签，并采用一系列策略来生成、存储和监督伪标签，以增强网络训练的鲁棒性。此外，设计了一个混合粒度特征分组模块，通过聚类相似特征来促进分割一致性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在多个ISCOS任务上达到了最先进的性能，并且SEE可以作为即插即用的解决方案，提升现有模型的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法为ISCOS任务提供了一种有效的解决方案，并有望应用于更多相关领域。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种统一的方法来解决不完全监督下隐蔽物体分割（ISCOS）的挑战，通过使用不完全标注的数据进行模型训练，实现了物体与其周围环境的无缝分割。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Incompletely-Supervised Concealed Object Segmentation (ISCOS) involvessegmenting objects that seamlessly blend into their surrounding environments,utilizing incompletely annotated data, such as weak and semi-annotations, formodel training. This task remains highly challenging due to (1) the limitedsupervision provided by the incompletely annotated training data, and (2) thedifficulty of distinguishing concealed objects from the background, whicharises from the intrinsic similarities in concealed scenarios. In this paper,we introduce the first unified method for ISCOS to address these challenges. Totackle the issue of incomplete supervision, we propose a unified mean-teacherframework, SEE, that leverages the vision foundation model, ``\emph{SegmentAnything Model (SAM)}'', to generate pseudo-labels using coarse masks producedby the teacher model as prompts. To mitigate the effect of low-qualitysegmentation masks, we introduce a series of strategies for pseudo-labelgeneration, storage, and supervision. These strategies aim to produceinformative pseudo-labels, store the best pseudo-labels generated, and selectthe most reliable components to guide the student model, thereby ensuringrobust network training. Additionally, to tackle the issue of intrinsicsimilarity, we design a hybrid-granularity feature grouping module that groupsfeatures at different granularities and aggregates these results. By clusteringsimilar features, this module promotes segmentation coherence, facilitatingmore complete segmentation for both single-object and multiple-object images.We validate the effectiveness of our approach across multiple ISCOS tasks, andexperimental results demonstrate that our method achieves state-of-the-artperformance. Furthermore, SEE can serve as a plug-and-play solution, enhancingthe performance of existing models.</description>
      <author>example@mail.com (Chunming He, Kai Li, Yachao Zhang, Ziyun Yang, Youwei Pang, Longxiang Tang, Chengyu Fang, Yulun Zhang, Linghe Kong, Xiu Li, Sina Farsiu)</author>
      <guid isPermaLink="false">2506.08955v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
  <item>
      <title>Enhancing Human-Robot Collaboration: A Sim2Real Domain Adaptation Algorithm for Point Cloud Segmentation in Industrial Environments</title>
      <link>http://arxiv.org/abs/2506.09552v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint, Journal of Intelligent &amp; Robotic Systems&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对人机协作应用的3D环境语义分割的新方法，该方法通过在Sim2Real领域适应中采用双流网络架构（FUSION），提高了语义分割的准确性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;人机协作（HRC）应用中，对3D环境的鲁棒理解至关重要，其中安全性和操作效率是首要考虑因素。语义分割在这一背景下起着关键作用，因为它能够实现对环境的精确和详细理解。&lt;h4&gt;目的&lt;/h4&gt;针对真实世界工业环境中语义分割对标注数据的强烈需求，本文旨在开发一个能够从模拟环境平稳过渡到真实世界应用的语义分割网络，从而增强其实际效用和对安全HRC的影响。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种名为FUSION的双流网络架构，该架构结合了动态图卷积神经网络（DGCNN）和卷积神经网络（CNN），并加入了残差层，作为工业环境的Sim2Real领域适应算法。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型在真实世界的HRC设置和模拟工业点云上进行了评估，显示了比现有方法更高的分割准确率（97.76%）和更好的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在HRC应用中提供了更高的准确性和鲁棒性，为安全的人机协作提供了有效的技术支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The robust interpretation of 3D environments is crucial for human-robotcollaboration (HRC) applications, where safety and operational efficiency areparamount. Semantic segmentation plays a key role in this context by enabling aprecise and detailed understanding of the environment. Considering the intensedata hunger for real-world industrial annotated data essential for effectivesemantic segmentation, this paper introduces a pioneering approach in theSim2Real domain adaptation for semantic segmentation of 3D point cloud data,specifically tailored for HRC. Our focus is on developing a network thatrobustly transitions from simulated environments to real-world applications,thereby enhancing its practical utility and impact on a safe HRC.  In this work, we propose a dual-stream network architecture (FUSION)combining Dynamic Graph Convolutional Neural Networks (DGCNN) and ConvolutionalNeural Networks (CNN) augmented with residual layers as a Sim2Real domainadaptation algorithm for an industrial environment. The proposed model wasevaluated on real-world HRC setups and simulation industrial point clouds, itshowed increased state-of-the-art performance, achieving a segmentationaccuracy of 97.76%, and superior robustness compared to existing methods.</description>
      <author>example@mail.com (Fatemeh Mohammadi Amin, Darwin G. Caldwell, Hans Wernher van de Venn)</author>
      <guid isPermaLink="false">2506.09552v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>MetricHMR: Metric Human Mesh Recovery from Monocular Images</title>
      <link>http://arxiv.org/abs/2506.09919v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了MetricHMR（Metric Human Mesh Recovery），这是一种从单目图像中进行精确全局平移的人体网格恢复方法。&lt;h4&gt;背景&lt;/h4&gt;现有的HMR方法在尺度深度模糊方面存在严重问题，而MetricHMR能够生成几何上合理的身体形状和全局平移。&lt;h4&gt;目的&lt;/h4&gt;分析先前HMR方法在相机模型上的表现，强调标准透视投影模型在实现度量尺度HMR中的关键作用。&lt;h4&gt;方法&lt;/h4&gt;验证了在标准透视投影模型下度量HMR的可接受模糊范围，并提出了一个基于标准透视投影的射线图方法，用于联合编码边界框信息、相机参数和几何线索，以实现端到端度量HMR，无需任何额外的度量正则化模块。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量实验证明，该方法在度量姿态、形状和全局平移估计方面达到了最先进的性能，甚至与顺序HMR方法相比，在室内和室外场景中都表现出色。&lt;h4&gt;结论&lt;/h4&gt;MetricHMR是一种有效的人体网格恢复方法，能够提供准确的全局平移和几何合理的身体形状恢复，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce MetricHMR (Metric Human Mesh Recovery), an approach for metrichuman mesh recovery with accurate global translation from monocular images. Incontrast to existing HMR methods that suffer from severe scale and depthambiguity, MetricHMR is able to produce geometrically reasonable body shape andglobal translation in the reconstruction results. To this end, we firstsystematically analyze previous HMR methods on camera models to emphasize thecritical role of the standard perspective projection model in enablingmetric-scale HMR. We then validate the acceptable ambiguity range of metric HMRunder the standard perspective projection model. Finally, we contribute a novelapproach that introduces a ray map based on the standard perspective projectionto jointly encode bounding-box information, camera parameters, and geometriccues for End2End metric HMR without any additional metric-regularizationmodules. Extensive experiments demonstrate that our method achievesstate-of-the-art performance, even compared with sequential HMR methods, inmetric pose, shape, and global translation estimation across both indoor andin-the-wild scenarios.</description>
      <author>example@mail.com (He Zhang, Chentao Song, Hongwen Zhang, Tao Yu)</author>
      <guid isPermaLink="false">2506.09919v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>CausalVQA: A Physically Grounded Causal Reasoning Benchmark for Video Models</title>
      <link>http://arxiv.org/abs/2506.09943v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  35 pages, 3 figures, Submitted to NeurIPS2025 benchmark track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CausalVQA是一个用于视频问答的基准数据集，旨在测试模型对物理世界中因果关系的理解能力。&lt;h4&gt;背景&lt;/h4&gt;现有的视频问答基准数据集要么侧重于对现实世界视频的表面感知理解，要么侧重于使用模拟环境创建的狭窄物理推理问题。&lt;h4&gt;目的&lt;/h4&gt;CausalVQA通过提供基于现实场景的挑战性问题，同时关注模型通过五种问题类型（反事实、假设、预期、计划和描述）预测不同行动和事件的可能结果的能力，填补了这一重要空白。&lt;h4&gt;方法&lt;/h4&gt;设计了质量控制机制，防止模型利用简单捷径，要求模型基于深度视觉理解而非语言线索来回答问题。&lt;h4&gt;主要发现&lt;/h4&gt;当前前沿的多模态模型在基准测试中的表现远低于人类，尤其是在预期和假设问题上。&lt;h4&gt;结论&lt;/h4&gt;这突显了当前系统在现实世界设置中利用空间时间推理、理解物理原理和识别可能替代方案以做出准确预测的挑战。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了CausalVQA，这是一个由问题-答案对组成的视频问答基准数据集，旨在测试模型对物理世界中因果关系的理解能力。现有的视频问答基准数据集要么倾向于关注现实世界视频的表面感知理解，要么侧重于使用模拟环境创建的狭窄物理推理问题。CausalVQA通过提出基于现实场景的挑战性问题，同时关注模型通过五种问题类型（反事实、假设、预期、计划和描述）预测不同行动和事件的可能结果的能力，填补了这一重要空白。我们设计了质量控制机制，防止模型利用简单捷径，要求模型基于深度视觉理解而非语言线索来回答问题。我们发现，当前前沿的多模态模型在基准测试中的表现远低于人类，尤其是在预期和假设问题上。这突显了当前系统在现实世界设置中利用空间时间推理、理解物理原理和识别可能替代方案以做出准确预测的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce CausalVQA, a benchmark dataset for video question answering(VQA) composed of question-answer pairs that probe models' understanding ofcausality in the physical world. Existing VQA benchmarks either tend to focuson surface perceptual understanding of real-world videos, or on narrow physicalreasoning questions created using simulation environments. CausalVQA fills animportant gap by presenting challenging questions that are grounded inreal-world scenarios, while focusing on models' ability to predict the likelyoutcomes of different actions and events through five question types:counterfactual, hypothetical, anticipation, planning and descriptive. Wedesigned quality control mechanisms that prevent models from exploiting trivialshortcuts, requiring models to base their answers on deep visual understandinginstead of linguistic cues. We find that current frontier multimodal modelsfall substantially below human performance on the benchmark, especially onanticipation and hypothetical questions. This highlights a challenge forcurrent systems to leverage spatial-temporal reasoning, understanding ofphysical principles, and comprehension of possible alternatives to makeaccurate predictions in real-world settings.</description>
      <author>example@mail.com (Aaron Foss, Chloe Evans, Sasha Mitts, Koustuv Sinha, Ammar Rizvi, Justine T. Kao)</author>
      <guid isPermaLink="false">2506.09943v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>SemanticSplat: Feed-Forward 3D Scene Understanding with Language-Aware Gaussian Fields</title>
      <link>http://arxiv.org/abs/2506.09565v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SemanticSplat的前馈语义感知3D重建方法，旨在解决现有3D场景理解方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有的3D场景理解方法主要存在两个问题：一是仅提取基于语言的语义，无法实现全面的场景理解；二是几何重建质量低，存在噪声。&lt;h4&gt;目的&lt;/h4&gt;提出SemanticSplat方法，旨在通过联合建模几何、外观和语义，实现全面的3D场景理解。&lt;h4&gt;方法&lt;/h4&gt;SemanticSplat方法将3D高斯与潜在语义属性统一，用于联合几何-外观-语义建模。通过融合多种特征场（如LSeg、SAM）和存储跨视图特征相似性的成本体积表示，预测语义各向异性高斯，从而提高场景理解的连贯性和准确性。利用两阶段蒸馏框架，从稀疏视图图像中重建全面的多模态语义特征场。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在3D场景理解任务（如提示和开放词汇分割）中表现出色。&lt;h4&gt;结论&lt;/h4&gt;SemanticSplat方法为3D场景理解提供了一种有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：全面的3D场景理解，即同时建模几何、外观和语义，对于增强现实和机器人交互等应用至关重要。现有的前馈3D场景理解方法（例如，LSM）仅限于从场景中提取基于语言的语义，无法实现全面的场景理解。此外，它们在几何重建方面质量低下，存在噪声伪影。相比之下，基于场景优化的方法依赖于密集的输入视图，这降低了其实用性，并在部署期间增加了复杂性。在本文中，我们提出了SemanticSplat，一种前馈语义感知3D重建方法，它将3D高斯与潜在语义属性统一，以实现联合几何-外观-语义建模。为了预测语义各向异性高斯，SemanticSplat融合了多种特征场（例如，LSeg，SAM）与存储跨视图特征相似性的成本体积表示，增强了连贯和准确的场景理解。利用两阶段蒸馏框架，SemanticSplat从稀疏视图图像中重建全面的多模态语义特征场。实验表明，我们提出的方法在3D场景理解任务（如提示和开放词汇分割）中是有效的。视频结果可在https://semanticsplat.github.io上查看。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Holistic 3D scene understanding, which jointly models geometry, appearance,and semantics, is crucial for applications like augmented reality and roboticinteraction. Existing feed-forward 3D scene understanding methods (e.g., LSM)are limited to extracting language-based semantics from scenes, failing toachieve holistic scene comprehension. Additionally, they suffer fromlow-quality geometry reconstruction and noisy artifacts. In contrast, per-sceneoptimization methods rely on dense input views, which reduces practicality andincreases complexity during deployment. In this paper, we proposeSemanticSplat, a feed-forward semantic-aware 3D reconstruction method, whichunifies 3D Gaussians with latent semantic attributes for jointgeometry-appearance-semantics modeling. To predict the semantic anisotropicGaussians, SemanticSplat fuses diverse feature fields (e.g., LSeg, SAM) with acost volume representation that stores cross-view feature similarities,enhancing coherent and accurate scene comprehension. Leveraging a two-stagedistillation framework, SemanticSplat reconstructs a holistic multi-modalsemantic feature field from sparse-view images. Experiments demonstrate theeffectiveness of our method for 3D scene understanding tasks like promptableand open-vocabulary segmentation. Video results are available athttps://semanticsplat.github.io.</description>
      <author>example@mail.com (Qijing Li, Jingxiang Sun, Liang An, Zhaoqi Su, Hongwen Zhang, Yebin Liu)</author>
      <guid isPermaLink="false">2506.09565v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>HopaDIFF: Holistic-Partial Aware Fourier Conditioned Diffusion for Referring Human Action Segmentation in Multi-Person Scenarios</title>
      <link>http://arxiv.org/abs/2506.09650v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code is available at https://github.com/KPeng9510/HopaDIFF.git&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对多个人物场景的文本参考引导的人体动作分割方法，并引入了RHAS133数据集，实现了在RHAS133数据集上最先进的结果。&lt;h4&gt;背景&lt;/h4&gt;动作分割是高级视频理解的核心挑战，主要针对单人活动，忽略了多人物场景。&lt;h4&gt;目的&lt;/h4&gt;提出文本参考引导的人体动作分割方法，解决多人物场景的动作分割问题。&lt;h4&gt;方法&lt;/h4&gt;提出了整体-部分意识傅里叶条件扩散框架（HopaDIFF），利用新的交叉输入门注意力xLSTM增强整体-部分长距离推理，并引入傅里叶条件来提高动作分割生成的细粒度控制。&lt;h4&gt;主要发现&lt;/h4&gt;在RHAS133数据集上，现有的动作识别方法表现有限，视觉线索的聚合对目标人物的效果不佳。&lt;h4&gt;结论&lt;/h4&gt;HopaDIFF在RHAS133数据集上实现了最先进的结果，代码可在GitHub上找到。&lt;h4&gt;翻译&lt;/h4&gt;摘要：动作分割是高级视频理解的核心挑战，旨在将未剪辑的视频分割成片段，并为每个片段分配一个预定义的动作集标签。现有方法主要解决单人活动且动作序列固定的问题，忽略了多人物场景。在本研究中，我们首次提出在多人物场景中的文本参考引导的人体动作分割，其中文本描述指定了分割的目标人物。我们引入了第一个用于指称人体动作分割的数据集，即RHAS133，该数据集由133部电影组成，并标注了137个细粒度动作以及33小时的视频数据，还提供了此新任务的文本描述。在RHAS133数据集上使用基于VLM的特征提取器对现有的动作识别方法进行基准测试，揭示了有限的性能和视觉线索对目标人物聚合的不足。为了解决这个问题，我们提出了整体-部分意识傅里叶条件扩散框架，即HopaDIFF，利用新颖的交叉输入门注意力xLSTM来增强整体-部分长距离推理，并引入傅里叶条件以引入更多细粒度控制来提高动作分割生成。HopaDIFF在RHAS133数据集上的不同评估设置中实现了最先进的结果。代码可在https://github.com/KPeng9510/HopaDIFF.git上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Action segmentation is a core challenge in high-level video understanding,aiming to partition untrimmed videos into segments and assign each a label froma predefined action set. Existing methods primarily address single-personactivities with fixed action sequences, overlooking multi-person scenarios. Inthis work, we pioneer textual reference-guided human action segmentation inmulti-person settings, where a textual description specifies the target personfor segmentation. We introduce the first dataset for Referring Human ActionSegmentation, i.e., RHAS133, built from 133 movies and annotated with 137fine-grained actions with 33h video data, together with textual descriptionsfor this new task. Benchmarking existing action recognition methods on RHAS133using VLM-based feature extractors reveals limited performance and pooraggregation of visual cues for the target person. To address this, we propose aholistic-partial aware Fourier-conditioned diffusion framework, i.e., HopaDIFF,leveraging a novel cross-input gate attentional xLSTM to enhanceholistic-partial long-range reasoning and a novel Fourier condition tointroduce more fine-grained control to improve the action segmentationgeneration. HopaDIFF achieves state-of-the-art results on RHAS133 in diverseevaluation settings. The code is available athttps://github.com/KPeng9510/HopaDIFF.git.</description>
      <author>example@mail.com (Kunyu Peng, Junchao Huang, Xiangsheng Huang, Di Wen, Junwei Zheng, Yufan Chen, Kailun Yang, Jiamin Wu, Chongqing Hao, Rainer Stiefelhagen)</author>
      <guid isPermaLink="false">2506.09650v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>ODG: Occupancy Prediction Using Dual Gaussians</title>
      <link>http://arxiv.org/abs/2506.09417v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的3D占用预测方法ODG，结合了鸟瞰图（BEV）和稀疏点表示，以降低计算成本并解决现有方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;3D占用信息对于场景理解和自动驾驶至关重要，但现有方法计算成本高，需要密集的3D特征体积和交叉注意力来有效聚合信息。&lt;h4&gt;目的&lt;/h4&gt;降低计算成本并解决现有方法的局限性，如BEV在处理小物体时信息损失严重，稀疏点在捕捉平面或大物体时效率低下。&lt;h4&gt;方法&lt;/h4&gt;提出了一种双分支设计：基于查询的稀疏点分支和BEV分支。稀疏点分支学习到的3D信息通过交叉注意力与BEV流共享，丰富BEV平面上困难物体的弱信号。两个分支的输出最终融合以生成预测的3D占用。&lt;h4&gt;主要发现&lt;/h4&gt;在Occ3D-nuScenes和Occ3D-Waymo基准上进行了广泛实验，证明了ODG方法的优势，并且与最新高效方法相比，ODG也提供了具有竞争力的推理速度。&lt;h4&gt;结论&lt;/h4&gt;ODG方法在降低计算成本的同时，提高了3D占用预测的准确性，为自动驾驶等应用提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D occupancy provides fine-grained 3D geometry and semantics for sceneunderstanding which is critical for autonomous driving. Most existing methods,however, carry high compute costs, requiring dense 3D feature volume andcross-attention to effectively aggregate information. More recent works haveadopted Bird's Eye View (BEV) or sparse points as scene representation withmuch reduced cost, but still suffer from their respective shortcomings. Moreconcretely, BEV struggles with small objects that often experience significantinformation loss after being projected to the ground plane. On the other hand,points can flexibly model little objects in 3D, but is inefficient at capturingflat surfaces or large objects. To address these challenges, in this paper, wepresent a novel 3D occupancy prediction approach, ODG, which combines BEV andsparse points based representations. We propose a dual-branch design: aquery-based sparse points branch and a BEV branch. The 3D information learnedin the sparse points branch is shared with the BEV stream via cross-attention,which enriches the weakened signals of difficult objects on the BEV plane. Theoutputs of both branches are finally fused to generate predicted 3D occupancy.We conduct extensive experiments on the Occ3D-nuScenes and Occ3D-Waymobenchmarks that demonstrate the superiority of our proposed ODG. Moreover, ODGalso delivers competitive inference speed when compared to the latest efficientapproaches.</description>
      <author>example@mail.com (Yunxiao Shi, Yinhao Zhu, Shizhong Han, Jisoo Jeong, Amin Ansari, Hong Cai, Fatih Porikli)</author>
      <guid isPermaLink="false">2506.09417v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>Synthetic Human Action Video Data Generation with Pose Transfer</title>
      <link>http://arxiv.org/abs/2506.09411v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用姿态转移（特别是可控3D高斯头像模型）生成合成人类动作视频数据的方法，并在Toyota Smarthome和NTU RGB+D数据集上评估了该方法，证明其在动作识别任务中提高了性能。&lt;h4&gt;背景&lt;/h4&gt;在视频理解任务中，特别是涉及人类运动的任务，合成数据生成常常存在不协调的特征，这降低了其在训练中的有效性。因此，诸如手语翻译、手势识别和自动驾驶中的人类运动理解等任务无法充分利用合成数据的潜力。&lt;h4&gt;目的&lt;/h4&gt;提出一种生成合成人类动作视频数据的方法，以解决合成数据在视频理解任务中的局限性。&lt;h4&gt;方法&lt;/h4&gt;使用姿态转移技术，特别是可控3D高斯头像模型来生成合成人类动作视频数据。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在动作识别任务中提高了性能，并且能够有效地扩展少量样本数据集，弥补了真实训练数据中代表性不足的群体，并增加了多样化的背景。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效提高视频理解任务中动作识别的性能，并且能够扩展少量样本数据集，增强数据多样性。&lt;h4&gt;翻译&lt;/h4&gt;在视频理解任务中，特别是在涉及人类运动的任务中，合成数据生成常常存在不协调的特征，这降低了其在训练中的有效性。因此，诸如手语翻译、手势识别和自动驾驶中的人类运动理解等任务无法充分利用合成数据的潜力。本文提出了一种使用姿态转移（特别是可控3D高斯头像模型）生成合成人类动作视频数据的方法。在Toyota Smarthome和NTU RGB+D数据集上评估该方法时，发现其在动作识别任务中提高了性能。此外，该方法还能有效扩展少量样本数据集，弥补真实训练数据中代表性不足的群体，并增加多样化的背景。本文将该方法及其与互联网上收集的具有新颖人类身份的视频和头像的RANDOM People数据集一起开源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In video understanding tasks, particularly those involving human motion,synthetic data generation often suffers from uncanny features, diminishing itseffectiveness for training. Tasks such as sign language translation, gesturerecognition, and human motion understanding in autonomous driving have thusbeen unable to exploit the full potential of synthetic data. This paperproposes a method for generating synthetic human action video data using posetransfer (specifically, controllable 3D Gaussian avatar models). We evaluatethis method on the Toyota Smarthome and NTU RGB+D datasets and show that itimproves performance in action recognition tasks. Moreover, we demonstrate thatthe method can effectively scale few-shot datasets, making up for groupsunderrepresented in the real training data and adding diverse backgrounds. Weopen-source the method along with RANDOM People, a dataset with videos andavatars of novel human identities for pose transfer crowd-sourced from theinternet.</description>
      <author>example@mail.com (Vaclav Knapp, Matyas Bohacek)</author>
      <guid isPermaLink="false">2506.09411v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>Multivariate Long-term Time Series Forecasting with Fourier Neural Filter</title>
      <link>http://arxiv.org/abs/2506.09174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的多变量长期时间序列预测方法，该方法能够同时捕捉变量内部的时序依赖性和变量间的空间相关性。&lt;h4&gt;背景&lt;/h4&gt;当前时间序列预测方法主要利用自然语言处理或计算机视觉的骨干网络，但这些方法未能充分解决时间序列的独特属性，如周期性。&lt;h4&gt;目的&lt;/h4&gt;提出FNF作为骨干网络和DBD作为架构，以提供优秀的学习能力和最佳学习路径，用于时空建模。&lt;h4&gt;方法&lt;/h4&gt;通过理论分析证明了FNF能够将局部时域和全局频域信息处理统一于单一骨干网络中，而信息瓶颈理论证明了DBD提供了比现有统一或顺序架构更好的梯度流和表示能力。&lt;h4&gt;主要发现&lt;/h4&gt;在11个公共基准数据集上的实证评估表明，该方法在不同领域（能源、气象、交通、环境和自然）中均取得了最先进的性能，且无需任何辅助技术。&lt;h4&gt;结论&lt;/h4&gt;该研究表明，经过适当设计的神经网络架构可以捕捉时间序列的固有属性，有望在科学和工业应用中改变时间序列建模方式。&lt;h4&gt;翻译&lt;/h4&gt;Multivariate long-term time series forecasting has been suffering from the challenge of capturing both temporal dependencies within variables and spatial correlations across variables simultaneously. Current approaches predominantly repurpose backbones from natural language processing or computer vision (e.g., Transformers), which fail to adequately address the unique properties of time series (e.g., periodicity). The research community lacks a dedicated backbonewith temporal-specific inductive biases, instead relying on domain-agnostic backbones supplemented with auxiliary techniques (e.g., signal decomposition). We introduce FNF as the backbone and DBD as the architecture to provide excellent learning capabilities and optimal learning pathways for spatio-temporal modeling, respectively. Our theoretical analysis proves that FNF unifies local time-domain and global frequency-domain information processing within a single backbone that extends naturally to spatial modeling, while information bottleneck theory demonstrates that DBD provides superior gradient flow and representation capacity compared to existing unified or sequential architectures. Our empirical evaluation across 11 public benchmark datasets spanning five domains (energy, meteorology, transportation, environment, and nature) confirms state-of-the-art performance with consistent hyperparameter settings. Notably, our approach achieves these results without any auxiliary techniques, suggesting that properly designed neural architectures can capture the inherent properties of time series, potentially transforming time series modeling in scientific and industrial applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate long-term time series forecasting has been suffering from thechallenge of capturing both temporal dependencies within variables and spatialcorrelations across variables simultaneously. Current approaches predominantlyrepurpose backbones from natural language processing or computer vision (e.g.,Transformers), which fail to adequately address the unique properties of timeseries (e.g., periodicity). The research community lacks a dedicated backbonewith temporal-specific inductive biases, instead relying on domain-agnosticbackbones supplemented with auxiliary techniques (e.g., signal decomposition).We introduce FNF as the backbone and DBD as the architecture to provideexcellent learning capabilities and optimal learning pathways forspatio-temporal modeling, respectively. Our theoretical analysis proves thatFNF unifies local time-domain and global frequency-domain informationprocessing within a single backbone that extends naturally to spatial modeling,while information bottleneck theory demonstrates that DBD provides superiorgradient flow and representation capacity compared to existing unified orsequential architectures. Our empirical evaluation across 11 public benchmarkdatasets spanning five domains (energy, meteorology, transportation,environment, and nature) confirms state-of-the-art performance with consistenthyperparameter settings. Notably, our approach achieves these results withoutany auxiliary techniques, suggesting that properly designed neuralarchitectures can capture the inherent properties of time series, potentiallytransforming time series modeling in scientific and industrial applications.</description>
      <author>example@mail.com (Chenheng Xu, Dan Wu, Yixin Zhu, Ying Nian Wu)</author>
      <guid isPermaLink="false">2506.09174v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>FinHEAR: Human Expertise and Adaptive Risk-Aware Temporal Reasoning for Financial Decision-Making</title>
      <link>http://arxiv.org/abs/2506.09080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FinHEAR的多代理框架，用于处理金融决策中的独特挑战，包括时间推理、适应性风险评估和对动态事件的响应。FinHEAR通过利用专门的大型语言模型（LLM）代理来分析历史趋势、解释当前事件和检索专家意见，以提高金融决策的透明度和稳健性。&lt;h4&gt;背景&lt;/h4&gt;语言模型在处理金融决策时面临挑战，因为它们难以捕捉到人类金融决策中的行为模式，如信息不对称下的专家依赖、损失规避敏感性和反馈驱动的时序调整。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够模拟人类专家知识和适应性风险评估的金融决策支持系统。&lt;h4&gt;方法&lt;/h4&gt;FinHEAR框架通过专家指导的检索、置信度调整的仓位规模和基于结果的细化来增强透明度和稳健性。&lt;h4&gt;主要发现&lt;/h4&gt;在经过精心挑选的金融数据集上的实证结果表明，FinHEAR在趋势预测和交易任务中优于强基线，实现了更高的准确性和更好的风险调整回报。&lt;h4&gt;结论&lt;/h4&gt;FinHEAR是一个有效的工具，可以用于改善金融决策的准确性和风险调整回报。&lt;h4&gt;翻译&lt;/h4&gt;Financial decision-making presents unique challenges for language models, demanding temporal reasoning, adaptive risk assessment, and responsiveness to dynamic events. While large language models (LLMs) show strong general reasoning capabilities, they often fail to capture behavioral patterns central to human financial decisions-such as expert reliance under information asymmetry, loss-averse sensitivity, and feedback-driven temporal adjustment. We propose FinHEAR, a multi-agent framework for Human Expertise and Adaptive Risk-aware reasoning. FinHEAR orchestrates specialized LLM-based agents to analyze historical trends, interpret current events, and retrieve expert-informed precedents within an event-centric pipeline. Grounded in behavioral economics, it incorporates expert-guided retrieval, confidence-adjusted position sizing, and outcome-based refinement to enhance interpretability and robustness. Empirical results on curated financial datasets show that FinHEAR consistently outperforms strong baselines across trend prediction and trading tasks, achieving higher accuracy and better risk-adjusted returns.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Financial decision-making presents unique challenges for language models,demanding temporal reasoning, adaptive risk assessment, and responsiveness todynamic events. While large language models (LLMs) show strong generalreasoning capabilities, they often fail to capture behavioral patterns centralto human financial decisions-such as expert reliance under informationasymmetry, loss-averse sensitivity, and feedback-driven temporal adjustment. Wepropose FinHEAR, a multi-agent framework for Human Expertise and AdaptiveRisk-aware reasoning. FinHEAR orchestrates specialized LLM-based agents toanalyze historical trends, interpret current events, and retrieveexpert-informed precedents within an event-centric pipeline. Grounded inbehavioral economics, it incorporates expert-guided retrieval,confidence-adjusted position sizing, and outcome-based refinement to enhanceinterpretability and robustness. Empirical results on curated financialdatasets show that FinHEAR consistently outperforms strong baselines acrosstrend prediction and trading tasks, achieving higher accuracy and betterrisk-adjusted returns.</description>
      <author>example@mail.com (Jiaxiang Chen, Mingxi Zou, Zhuo Wang, Qifan Wang, Dongning Sun, Chi Zhang, Zenglin Xu)</author>
      <guid isPermaLink="false">2506.09080v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>AVA-Bench: Atomic Visual Ability Benchmark for Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2506.09082v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  First two authors contribute equally&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为AVA-Bench的新基准，用于评估视觉基础模型（VFMs）的性能，解决了现有评估方法中存在的两个关键问题。&lt;h4&gt;背景&lt;/h4&gt;随着视觉基础模型（VFMs）的兴起，对其系统性的评估变得尤为重要。传统的评估方法是将VFMs与大型语言模型（LLMs）配对作为通用头，然后在广泛的视觉问答（VQA）基准上进行评估。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有评估方法中存在的两个关键问题：指令调整数据可能与VQA测试分布不匹配，以及VQA基准通常需要多种视觉能力，难以确定错误是否源于缺乏所有必需的能力或仅仅是单一关键能力。&lt;h4&gt;方法&lt;/h4&gt;提出AVA-Bench，这是第一个明确分离14种原子视觉能力（AVAs）的基准，这些能力是支持复杂视觉推理任务的基石。通过解耦AVAs并在每个AVAs中匹配训练和测试分布，AVA-Bench可以精确地指出VFMs的优缺点。&lt;h4&gt;主要发现&lt;/h4&gt;使用AVA-Bench评估领先的VFMs可以揭示独特的“能力指纹”，将VFMs的选择从经验推测转变为原则性工程。此外，发现一个0.5B的LLM在排名上与一个7B的LLM相似，同时减少了8倍的GPU小时数，使评估更加高效。&lt;h4&gt;结论&lt;/h4&gt;AVA-Bench提供了一个全面和透明的基准，为下一代VFMs的发展奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉基础模型（VFMs）的兴起需要系统性的评估。一种常见的做法是将VFMs与大型语言模型（LLMs）配对作为通用头，然后在广泛的视觉问答（VQA）基准上进行评估。然而，这种协议有两个关键盲点：（i）指令调整数据可能与VQA测试分布不匹配，这意味着错误的预测可能源于此类数据不匹配，而不是VFMs的视觉不足；（ii）VQA基准通常需要多种视觉能力，这使得很难确定错误是否源于缺乏所有必需的能力或仅仅是单一关键能力。为了解决这些差距，我们引入了AVA-Bench，这是第一个明确分离14种原子视觉能力（AVAs）的基准——这些是支持复杂视觉推理任务的基础技能，如定位、深度估计和空间理解。通过解耦AVAs并在每个AVAs中匹配训练和测试分布，AVA-Bench可以精确地指出VFMs的优缺点。将AVA-Bench应用于领先的VFMs因此揭示了独特的“能力指纹”，将VFMs的选择从经验推测转变为原则性工程。值得注意的是，我们发现一个0.5B的LLM在排名上与一个7B的LLM相似，同时减少了8倍的GPU小时数，使评估更加高效。通过提供一个全面和透明的基准，我们希望AVA-Bench为下一代VFMs的发展奠定基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rise of vision foundation models (VFMs) calls for systematic evaluation.A common approach pairs VFMs with large language models (LLMs) asgeneral-purpose heads, followed by evaluation on broad Visual QuestionAnswering (VQA) benchmarks. However, this protocol has two key blind spots: (i)the instruction tuning data may not align with VQA test distributions, meaninga wrong prediction can stem from such data mismatch rather than a VFM' visualshortcomings; (ii) VQA benchmarks often require multiple visual abilities,making it hard to tell whether errors stem from lacking all required abilitiesor just a single critical one. To address these gaps, we introduce AVA-Bench,the first benchmark that explicitly disentangles 14 Atomic Visual Abilities(AVAs) -- foundational skills like localization, depth estimation, and spatialunderstanding that collectively support complex visual reasoning tasks. Bydecoupling AVAs and matching training and test distributions within each,AVA-Bench pinpoints exactly where a VFM excels or falters. Applying AVA-Benchto leading VFMs thus reveals distinctive "ability fingerprints," turning VFMselection from educated guesswork into principled engineering. Notably, we findthat a 0.5B LLM yields similar VFM rankings as a 7B LLM while cutting GPU hoursby 8x, enabling more efficient evaluation. By offering a comprehensive andtransparent benchmark, we hope AVA-Bench lays the foundation for the nextgeneration of VFMs.</description>
      <author>example@mail.com (Zheda Mai, Arpita Chowdhury, Zihe Wang, Sooyoung Jeon, Lemeng Wang, Jiacheng Hou, Jihyung Kil, Wei-Lun Chao)</author>
      <guid isPermaLink="false">2506.09082v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>GIQ: Benchmarking 3D Geometric Reasoning of Vision Foundation Models with Simulated and Real Polyhedra</title>
      <link>http://arxiv.org/abs/2506.08194v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GIQ的基准测试，旨在评估视觉和视觉语言基础模型在几何推理方面的能力，并揭示了当前模型在几何理解上的不足。&lt;h4&gt;背景&lt;/h4&gt;虽然单目3D重建方法和视觉语言模型在标准基准测试中表现出色，但它们对几何特性的真正理解尚不明确。&lt;h4&gt;目的&lt;/h4&gt;设计GIQ基准测试，以评估视觉和视觉语言基础模型的几何推理能力。&lt;h4&gt;方法&lt;/h4&gt;GIQ包含合成和真实世界图像，涵盖224种不同的多面体，包括柏拉图、阿基米德、约翰逊和卡塔兰多面体，以及星形和复合形状，覆盖不同复杂度和对称性级别。通过进行单目3D重建、3D对称性检测、心理旋转测试和零样本形状分类任务等系统性实验。&lt;h4&gt;主要发现&lt;/h4&gt;当前模型在重建基本几何形状时存在显著不足；基础模型在通过线性探测检测特定3D对称元素方面表现良好，但在需要详细几何区分的任务（如心理旋转）上表现不佳；高级视觉语言助手在复杂多面体上的准确率极低，系统性误解了基本属性，如面几何、凸性和复合结构。&lt;h4&gt;结论&lt;/h4&gt;GIQ是一个公开可用的平台，可以突出并解决几何智能中的关键差距，促进稳健、具有几何感知的表示学习方面的未来进步。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a benchmark named GIQ, specifically designed to evaluate the geometric reasoning capabilities of visual and visual language foundation models, and reveals the significant shortcomings of current models in geometric understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular 3D reconstruction methods and vision-language models (VLMs)demonstrate impressive results on standard benchmarks, yet their trueunderstanding of geometric properties remains unclear. We introduce GIQ , acomprehensive benchmark specifically designed to evaluate the geometricreasoning capabilities of vision and vision-language foundation models. GIQcomprises synthetic and real-world images of 224 diverse polyhedra - includingPlatonic, Archimedean, Johnson, and Catalan solids, as well as stellations andcompound shapes - covering varying levels of complexity and symmetry. Throughsystematic experiments involving monocular 3D reconstruction, 3D symmetrydetection, mental rotation tests, and zero-shot shape classification tasks, wereveal significant shortcomings in current models. State-of-the-artreconstruction algorithms trained on extensive 3D datasets struggle toreconstruct even basic geometric forms accurately. While foundation modelseffectively detect specific 3D symmetry elements via linear probing, theyfalter significantly in tasks requiring detailed geometric differentiation,such as mental rotation. Moreover, advanced vision-language assistants exhibitremarkably low accuracy on complex polyhedra, systematically misinterpretingbasic properties like face geometry, convexity, and compound structures. GIQ ispublicly available, providing a structured platform to highlight and addresscritical gaps in geometric intelligence, facilitating future progress inrobust, geometry-aware representation learning.</description>
      <author>example@mail.com (Mateusz Michalkiewicz, Anekha Sokhal, Tadeusz Michalkiewicz, Piotr Pawlikowski, Mahsa Baktashmotlagh, Varun Jampani, Guha Balakrishnan)</author>
      <guid isPermaLink="false">2506.08194v2</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>VersaVid-R1: A Versatile Video Understanding and Reasoning Model from Question Answering to Captioning Tasks</title>
      <link>http://arxiv.org/abs/2506.09079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了DarkEventInfer和MixVidQA两个新型数据集，旨在提升视频推理模型的能力，并提出了VersaVid-R1模型，在视频理解与推理方面取得了显著成果。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型在图像推理方面取得了成功，但视频推理仍处于发展阶段，主要由于高质量推理数据稀缺和训练方法不足。&lt;h4&gt;目的&lt;/h4&gt;弥补视频推理领域的不足，提升模型的高级视频理解和推理能力。&lt;h4&gt;方法&lt;/h4&gt;提出DarkEventInfer和MixVidQA数据集，通过强化学习和多样化的奖励函数训练VersaVid-R1模型。&lt;h4&gt;主要发现&lt;/h4&gt;DarkEventInfer要求模型根据上下文视频线索推断遮挡内容，MixVidQA则挑战模型在处理交错视频序列时忽略一部分内容。&lt;h4&gt;结论&lt;/h4&gt;VersaVid-R1在视频理解、认知推理和视频字幕任务上显著优于现有模型。&lt;h4&gt;翻译&lt;/h4&gt;Recent advancements in multimodal large language models have successfully extended the Reason-Then-Respond paradigm to image-based reasoning, yet video-based reasoning remains an underdeveloped frontier, primarily due to the scarcity of high-quality reasoning-oriented data and effective training methodologies. To bridge this gap, we introduce DarkEventInfer and MixVidQA, two novel datasets specifically designed to stimulate the model's advanced video understanding and reasoning abilities. DarkEventinfer presents videos with masked event segments, requiring models to infer the obscured content based on contextual video cues. MixVidQA, on the other hand, presents interleaved video sequences composed of two distinct clips, challenging models to isolate and reason about one while disregarding the other. Leveraging these carefully curated training samples together with reinforcement learning guided by diverse reward functions, we develop VersaVid-R1, the first versatile video understanding and reasoning model under the Reason-Then-Respond paradigm capable of handling multiple-choice and open-ended question answering, as well as video captioning tasks. Extensive experiments demonstrate that VersaVid-R1 significantly outperforms existing models across a broad spectrum of benchmarks, covering video general understanding, cognitive reasoning, and captioning tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in multimodal large language models have successfullyextended the Reason-Then-Respond paradigm to image-based reasoning, yetvideo-based reasoning remains an underdeveloped frontier, primarily due to thescarcity of high-quality reasoning-oriented data and effective trainingmethodologies. To bridge this gap, we introduce DarkEventInfer and MixVidQA,two novel datasets specifically designed to stimulate the model's advancedvideo understanding and reasoning abilities. DarkEventinfer presents videoswith masked event segments, requiring models to infer the obscured contentbased on contextual video cues. MixVidQA, on the other hand, presentsinterleaved video sequences composed of two distinct clips, challenging modelsto isolate and reason about one while disregarding the other. Leveraging thesecarefully curated training samples together with reinforcement learning guidedby diverse reward functions, we develop VersaVid-R1, the first versatile videounderstanding and reasoning model under the Reason-Then-Respond paradigmcapable of handling multiple-choice and open-ended question answering, as wellas video captioning tasks. Extensive experiments demonstrate that VersaVid-R1significantly outperforms existing models across a broad spectrum ofbenchmarks, covering video general understanding, cognitive reasoning, andcaptioning tasks.</description>
      <author>example@mail.com (Xinlong Chen, Yuanxing Zhang, Yushuo Guan, Bohan Zeng, Yang Shi, Sihan Yang, Pengfei Wan, Qiang Liu, Liang Wang, Tieniu Tan)</author>
      <guid isPermaLink="false">2506.09079v1</guid>
      <pubDate>Thu, 12 Jun 2025 14:09:38 +0800</pubDate>
    </item>
    <item>
      <title>Machine Learning the 6d Supergravity Landscape</title>
      <link>http://arxiv.org/abs/2505.16131v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  49 pages; code and data available at  https://github.com/nait400/ML-6d-sugra-landscape&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文应用监督和未监督的机器学习算法研究了六维弦景观和沼泽地，数据来自几乎无异常的六维N=(1,0)超引力模型，特征为异常系数的Gram矩阵。研究展示了机器学习算法在高效学习景观和沼泽地复杂特征方面的能力。&lt;h4&gt;背景&lt;/h4&gt;研究基于六维超引力理论中的弦景观和沼泽地，使用N=(1,0)超引力模型的Gram矩阵数据。&lt;h4&gt;目的&lt;/h4&gt;探索机器学习算法在理解六维超引力理论的景观和沼泽地方面的应用潜力。&lt;h4&gt;方法&lt;/h4&gt;使用自动编码器进行无监督学习，通过将Gram矩阵数据压缩到二维来进行模型自动分类。同时，使用监督学习建立两个分类器，预测模型在探针弦插入下的一致性和在异常流入下的不一致性。&lt;h4&gt;主要发现&lt;/h4&gt;自动编码器通过压缩数据将相似模型聚类，并识别了这些聚类的显著特征。它还识别了难以重建的异常模型，其中一种模型难以与其他模型结合以消除$ext{tr}R^{4}$异常，表明其在景观中的存在极为罕见。监督学习分类器准确预测了模型的一致性和不一致性。将预测投影到自动编码器的二维潜在层上，显示了一致模型聚类，表明自动编码器学习了模型的有趣且复杂的特征。&lt;h4&gt;结论&lt;/h4&gt;机器学习算法能够有效学习六维超引力理论的景观和沼泽地的复杂特征，为理解和映射这些理论提供了新的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nait400/ml-6d-sugra-landscape&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we apply both supervised and unsupervised machine learningalgorithms to the study of the string landscape and swampland in 6-dimensions.Our data are the (almost) anomaly-free 6-dimensional $\mathcal{N} = (1,0)$supergravity models, characterised by the Gram matrix of anomaly coefficients.Our work demonstrates the ability of machine learning algorithms to efficientlylearn highly complex features of the landscape and swampland. Employing anautoencoder for unsupervised learning, we provide an auto-classification ofthese models by compressing the Gram matrix data to 2-dimensions. Throughcompression, similar models cluster together, and we identify prominentfeatures of these clusters. The autoencoder also identifies outlier modelswhich are difficult to reconstruct. One of these outliers proves to beincredibly difficult to combine with other models such that the$\text{tr}R^{4}$ anomaly vanishes, making its presence in the landscapeextremely rare. Further, we utilise supervised learning to build twoclassifiers predicting (1) model consistency under probe string insertion(precision: 0.78, predicting consistency for 214,837 models with reasonablecertainty) and (2) inconsistency under anomaly inflow (precision: 0.91,predicting inconsistency for 1,909,359 models). Notably, projecting thesepredictions onto the autoencoder's 2-dimensional latent layer shows consistentmodels clustering together, further indicating that the autoencoder has learntinteresting and complex features of the set of models and potentially offers anovel approach to mapping the landscape and swampland of 6-dimensionalsupergravity theories.</description>
      <author>example@mail.com (Nathan Brady, David Tennyson, Thomas Vandermeulen)</author>
      <guid isPermaLink="false">2505.16131v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
  <item>
      <title>Polar Hierarchical Mamba: Towards Streaming LiDAR Object Detection with Point Clouds as Egocentric Sequences</title>
      <link>http://arxiv.org/abs/2506.06944v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Polar Hierarchical Mamba (PHiM)的新颖状态空间模型，旨在提高极坐标下流式处理的LiDAR感知效率。&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶领域，准确且高效的目标检测至关重要，而实时感知需要低延迟和高吞吐量。LiDAR传感器提供鲁棒的深度信息，但传统方法处理360度全扫描需要较长时间。&lt;h4&gt;目的&lt;/h4&gt;提出PHiM以解决传统方法在处理全扫描时的延迟问题，并提高流式处理的性能。&lt;h4&gt;方法&lt;/h4&gt;PHiM使用局部双向Mamba块进行区间内空间编码，全局正向Mamba进行区间间时间建模，并使用扭曲感知的、维分解的操作来替代卷积和位置编码。&lt;h4&gt;主要发现&lt;/h4&gt;PHiM在Waymo Open Dataset上达到了流式检测的最新水平，比之前的最佳方法提高了10%，并且在吞吐量上是全扫描基线的两倍。&lt;h4&gt;结论&lt;/h4&gt;PHiM是一种适用于极坐标流式处理的LiDAR感知的新架构，具有显著性能提升。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Accurate and efficient object detection is essential for autonomous vehicles, where real-time perception requires low latency and high throughput. LiDAR sensors provide robust depth information, but conventional methods process full 360° scans in a single pass, introducing significant delay. Streaming approaches address this by sequentially processing partial scans in the native polar coordinate system, yet they rely on translation-invariant convolutions that are misaligned with polar geometry -- resulting in degraded performance or requiring complex distortion mitigation. Recent Mamba-based state space models (SSMs) have shown promise for LiDAR perception, but only in the full-scan setting, relying on geometric serialization and positional embeddings that are memory-intensive and ill-suited to streaming. We propose Polar Hierarchical Mamba (PHiM), a novel SSM architecture designed for polar-coordinate streaming LiDAR. PHiM uses local bidirectional Mamba blocks for intra-sector spatial encoding and a global forward Mamba for inter-sector temporal modeling, replacing convolutions and positional encodings with distortion-aware, dimensionally-decomposed operations. PHiM sets a new state-of-the-art among streaming detectors on the Waymo Open Dataset, outperforming the previous best by 10% and matching full-scan baselines at twice the throughput. Code will be available at https://github.com/meilongzhang/Polar-Hierarchical-Mamba .&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and efficient object detection is essential for autonomous vehicles,where real-time perception requires low latency and high throughput. LiDARsensors provide robust depth information, but conventional methods process full360{\deg} scans in a single pass, introducing significant delay. Streamingapproaches address this by sequentially processing partial scans in the nativepolar coordinate system, yet they rely on translation-invariant convolutionsthat are misaligned with polar geometry -- resulting in degraded performance orrequiring complex distortion mitigation. Recent Mamba-based state space models(SSMs) have shown promise for LiDAR perception, but only in the full-scansetting, relying on geometric serialization and positional embeddings that arememory-intensive and ill-suited to streaming. We propose Polar HierarchicalMamba (PHiM), a novel SSM architecture designed for polar-coordinate streamingLiDAR. PHiM uses local bidirectional Mamba blocks for intra-sector spatialencoding and a global forward Mamba for inter-sector temporal modeling,replacing convolutions and positional encodings with distortion-aware,dimensionally-decomposed operations. PHiM sets a new state-of-the-art amongstreaming detectors on the Waymo Open Dataset, outperforming the previous bestby 10\% and matching full-scan baselines at twice the throughput. Code will beavailable at https://github.com/meilongzhang/Polar-Hierarchical-Mamba .</description>
      <author>example@mail.com (Mellon M. Zhang, Glen Chou, Saibal Mukhopadhyay)</author>
      <guid isPermaLink="false">2506.06944v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Generative Vehicle Trajectory Models for Traffic Intersection Dynamics</title>
      <link>http://arxiv.org/abs/2506.08963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于交通信号交叉口交通动态的深度生成模型，以帮助交通管理部门更好地理解交通效率和安全性。&lt;h4&gt;背景&lt;/h4&gt;交通交叉口是城市道路网络的重要组成部分，但同时也是事故多发区域。&lt;h4&gt;目的&lt;/h4&gt;开发一个综合分析工具，使用更符合交通工程实际的指标来训练、运行和评估交通模型。&lt;h4&gt;方法&lt;/h4&gt;在大型数据集上训练了先进的车辆轨迹预测模型，并在微观模拟器中对预测模型进行在线评估，以模拟未见过的交通条件。&lt;h4&gt;主要发现&lt;/h4&gt;尽管使用了理想行为的轨迹作为输入并实现了低轨迹重建误差，但生成的轨迹表现出违反交通规则的行为。&lt;h4&gt;结论&lt;/h4&gt;引入了新的指标来评估这些不期望的行为，并展示了相关结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：城市道路网络中的交叉口对于调节人员和货物的流动至关重要。然而，它们是冲突轨迹的区域，容易发生事故。信号交叉口交通动态的深度生成模型可以极大地帮助交通管理部门更好地理解效率和安全性方面。目前，模型主要在计算指标上评估，这些指标主要关注轨迹重建误差。它们没有在实时微观模拟场景中进行在线评估。此外，这些指标没有充分考虑到交通工程特定的关注点，如闯红灯、不允许停车等。在这项工作中，我们提供了一个综合分析工具，用于使用提供更好模型性能洞察的指标来训练、运行和评估模型。我们在收集到的大量数据集上训练了一个最先进的车辆轨迹预测模型，该数据集是通过运行现实世界城市交叉口的校准场景获得的。然后，我们在微观模拟器中在线评估了预测模型在未见过的交通条件下的性能。我们表明，尽管使用了理想行为的轨迹作为输入，并实现了低轨迹重建误差，但生成的轨迹表现出违反交通规则的行为。我们引入了新的指标来评估这种不期望的行为，并展示了我们的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic Intersections are vital to urban road networks as they regulate themovement of people and goods. However, they are regions of conflictingtrajectories and are prone to accidents. Deep Generative models of trafficdynamics at signalized intersections can greatly help traffic authoritiesbetter understand the efficiency and safety aspects. At present, models areevaluated on computational metrics that primarily look at trajectoryreconstruction errors. They are not evaluated online in a `live'microsimulation scenario. Further, these metrics do not adequately considertraffic engineering-specific concerns such as red-light violations, unallowedstoppage, etc. In this work, we provide a comprehensive analytics tool totrain, run, and evaluate models with metrics that give better insights intomodel performance from a traffic engineering point of view. We train astate-of-the-art multi-vehicle trajectory forecasting model on a large datasetcollected by running a calibrated scenario of a real-world urban intersection.We then evaluate the performance of the prediction models, online in amicrosimulator, under unseen traffic conditions. We show that despite usingideally-behaved trajectories as input, and achieving low trajectoryreconstruction errors, the generated trajectories show behaviors that breaktraffic rules. We introduce new metrics to evaluate such undesired behaviorsand present our results.</description>
      <author>example@mail.com (Yash Ranjan, Rahul Sengupta, Anand Rangarajan, Sanjay Ranka)</author>
      <guid isPermaLink="false">2506.08963v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Deploying SICNav in the Field: Safe and Interactive Crowd Navigation using MPC and Bilevel Optimization</title>
      <link>http://arxiv.org/abs/2506.08851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 2025 IEEE ICRA Workshop on Field Robotics  (non-archival)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种安全且高效的拥挤环境导航方法，用于执行如食物配送或自动轮椅移动等服务任务的机器人。&lt;h4&gt;背景&lt;/h4&gt;传统的机器人拥挤环境导航方法将人类运动预测与机器人运动规划分离，忽略了人类与机器人之间的闭环交互。&lt;h4&gt;目的&lt;/h4&gt;提出了一种名为SICNav的安全和交互式拥挤导航方法，它是一个双层模型预测控制框架，将预测和规划合并为一个优化问题，并明确地建模了代理之间的交互。&lt;h4&gt;方法&lt;/h4&gt;介绍了用于部署SICNav的系统概述，该系统在室内和室外环境中部署，并提供了系统在近7公里、两小时自主导航过程中的初步分析。&lt;h4&gt;主要发现&lt;/h4&gt;SICNav方法能够有效处理人类与机器人之间的交互，避免了机器人因人类反应不当而卡住的问题。&lt;h4&gt;结论&lt;/h4&gt;SICNav方法在室内和室外环境中均表现出良好的导航性能，为机器人服务任务在拥挤环境中的导航提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Safe and efficient navigation in crowded environments remains a critical challenge for robots that provide a variety of service tasks such as food delivery or autonomous wheelchair mobility. Classical robot crowd navigation methods decouple human motion prediction from robot motion planning, which neglects the closed-loop interactions between humans and robots. This lack of a model for human reactions to the robot plan (e.g. moving out of the way) can cause the robot to get stuck. Our proposed Safe and Interactive Crowd Navigation (SICNav) method is a bilevel Model Predictive Control (MPC) framework that combines prediction and planning into one optimization problem, explicitly modeling interactions among agents. In this paper, we present a systems overview of the crowd navigation platform we use to deploy SICNav in previously unseen indoor and outdoor environments. We provide a preliminary analysis of the system's operation over the course of nearly 7 km of autonomous navigation over two hours in both indoor and outdoor environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Safe and efficient navigation in crowded environments remains a criticalchallenge for robots that provide a variety of service tasks such as fooddelivery or autonomous wheelchair mobility. Classical robot crowd navigationmethods decouple human motion prediction from robot motion planning, whichneglects the closed-loop interactions between humans and robots. This lack of amodel for human reactions to the robot plan (e.g. moving out of the way) cancause the robot to get stuck. Our proposed Safe and Interactive CrowdNavigation (SICNav) method is a bilevel Model Predictive Control (MPC)framework that combines prediction and planning into one optimization problem,explicitly modeling interactions among agents. In this paper, we present asystems overview of the crowd navigation platform we use to deploy SICNav inpreviously unseen indoor and outdoor environments. We provide a preliminaryanalysis of the system's operation over the course of nearly 7 km of autonomousnavigation over two hours in both indoor and outdoor environments.</description>
      <author>example@mail.com (Sepehr Samavi, Garvish Bhutani, Florian Shkurti, Angela P. Schoellig)</author>
      <guid isPermaLink="false">2506.08851v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Diffuse and Disperse: Image Generation with Representation Regularization</title>
      <link>http://arxiv.org/abs/2506.09027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Dispersive Loss的简单正则化器，用于提升基于扩散的生成模型。该方法通过鼓励内部表示在隐藏空间中分散，类似于对比自监督学习，但无需正样本对，不干扰回归过程中的采样。&lt;h4&gt;背景&lt;/h4&gt;过去十年中，基于扩散的生成模型的发展与表示学习进展独立。这些模型通常依赖于基于回归的目标，并且通常缺乏显式正则化。&lt;h4&gt;目的&lt;/h4&gt;提出Dispersive Loss正则化器，有效提升基于扩散的生成模型。&lt;h4&gt;方法&lt;/h4&gt;Dispersive Loss正则化器，通过鼓励内部表示在隐藏空间中分散，类似于对比自监督学习，但无需正样本对。&lt;h4&gt;主要发现&lt;/h4&gt;Dispersive Loss在ImageNet数据集上对多种模型进行了评估，与广泛使用的强大基线相比，报告了持续改进。&lt;h4&gt;结论&lt;/h4&gt;Dispersive Loss有助于弥合生成建模与表示学习之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of diffusion-based generative models over the past decade haslargely proceeded independently of progress in representation learning. Thesediffusion models typically rely on regression-based objectives and generallylack explicit regularization. In this work, we propose \textit{DispersiveLoss}, a simple plug-and-play regularizer that effectively improvesdiffusion-based generative models. Our loss function encourages internalrepresentations to disperse in the hidden space, analogous to contrastiveself-supervised learning, with the key distinction that it requires no positivesample pairs and therefore does not interfere with the sampling process usedfor regression. Compared to the recent method of representation alignment(REPA), our approach is self-contained and minimalist, requiring nopre-training, no additional parameters, and no external data. We evaluateDispersive Loss on the ImageNet dataset across a range of models and reportconsistent improvements over widely used and strong baselines. We hope our workwill help bridge the gap between generative modeling and representationlearning.</description>
      <author>example@mail.com (Runqian Wang, Kaiming He)</author>
      <guid isPermaLink="false">2506.09027v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Do MIL Models Transfer?</title>
      <link>http://arxiv.org/abs/2506.09022v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 (Spotlight). 20 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究评估了预训练的MIL模型在转移学习方面的能力，结果表明这些模型在处理临床数据时具有很好的适应性和性能提升。&lt;h4&gt;背景&lt;/h4&gt;MIL在计算病理学中用于生成临床有意义的组织图像嵌入，但在小规模、弱监督的数据集上表现不佳。与NLP和传统计算机视觉不同，MIL模型的迁移性理解不足。&lt;h4&gt;目的&lt;/h4&gt;系统评估预训练MIL模型的迁移学习能力，通过比较11个模型在21个预训练任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;评估了11个预训练MIL模型在形态和分子亚型预测任务上的表现，并比较了这些模型与从头开始训练的模型。&lt;h4&gt;主要发现&lt;/h4&gt;预训练MIL模型在不同器官上训练时仍能优于从头开始训练的模型；在跨器官和任务上的预训练可以显著提高泛化能力，并使用更少的数据。&lt;h4&gt;结论&lt;/h4&gt;这些发现突出了MIL模型的鲁棒适应性和利用迁移学习在计算病理学中提升性能的益处。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多实例学习（MIL）是计算病理学中从千兆像素的组织图像中生成临床有意义的切片级嵌入的基础方法。然而，MIL往往在小规模、弱监督的临床数据集上表现不佳。与NLP和传统计算机视觉领域不同，迁移学习被广泛用于解决数据稀缺问题，但MIL模型的迁移性仍然理解不足。在本研究中，我们系统地评估了预训练MIL模型的迁移学习能力，通过评估11个模型在21个预训练任务上的表现。我们的结果表明，即使在这些模型在目标任务不同的器官上进行了训练，预训练MIL模型也始终优于从头开始训练的模型。此外，在泛癌症数据集上进行预训练能够实现跨器官和任务的强大泛化能力，同时使用大量更少的预训练数据。这些发现突出了MIL模型的鲁棒适应能力，并证明了在计算病理学中利用迁移学习来提升性能的益处。最后，我们提供了一种资源，该资源标准化了MIL模型在流行计算病理学任务上的实现和预训练模型权重的收集，可在https://github.com/mahmoodlab/MIL-Lab获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multiple Instance Learning (MIL) is a cornerstone approach in computationalpathology (CPath) for generating clinically meaningful slide-level embeddingsfrom gigapixel tissue images. However, MIL often struggles with small, weaklysupervised clinical datasets. In contrast to fields such as NLP andconventional computer vision, where transfer learning is widely used to addressdata scarcity, the transferability of MIL models remains poorly understood. Inthis study, we systematically evaluate the transfer learning capabilities ofpretrained MIL models by assessing 11 models across 21 pretraining tasks formorphological and molecular subtype prediction. Our results show thatpretrained MIL models, even when trained on different organs than the targettask, consistently outperform models trained from scratch. Moreover,pretraining on pancancer datasets enables strong generalization across organsand tasks, outperforming slide foundation models while using substantially lesspretraining data. These findings highlight the robust adaptability of MILmodels and demonstrate the benefits of leveraging transfer learning to boostperformance in CPath. Lastly, we provide a resource which standardizes theimplementation of MIL models and collection of pretrained model weights onpopular CPath tasks, available at https://github.com/mahmoodlab/MIL-Lab</description>
      <author>example@mail.com (Daniel Shao, Richard J. Chen, Andrew H. Song, Joel Runevic, Ming Y. Lu, Tong Ding, Faisal Mahmood)</author>
      <guid isPermaLink="false">2506.09022v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Gaussian2Scene: 3D Scene Representation Learning via Self-supervised Learning with 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.08777v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Gaussian2Scene的新型场景级自监督学习框架，用于点云预训练，以提高3D视觉任务的效果。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在点云预训练中成为3D视觉任务的基础，通过从大规模未标注数据中学习，提高模型性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种更有效的场景级自监督学习框架，以解决现有方法依赖于隐式场景表示和高内存需求，以及未能捕捉到3D几何结构的局限性。&lt;h4&gt;方法&lt;/h4&gt;Gaussian2Scene利用3D高斯分层（3DGS）的效率和显式性质进行预训练，采用渐进式两阶段训练策略，第一阶段学习2D和3D场景表示，第二阶段使用重建的点云和几何原始体的几何位置以及渲染的RGB图像进行监督学习。&lt;h4&gt;主要发现&lt;/h4&gt;Gaussian2Scene在多个下游3D目标检测任务中表现出色，与现有预训练方法相比，效果一致且有所提升。&lt;h4&gt;结论&lt;/h4&gt;Gaussian2Scene通过改进预训练方法，提高了3D视觉任务的效果，尤其是在几何理解和跨模态学习方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) for point cloud pre-training has become acornerstone for many 3D vision tasks, enabling effective learning fromlarge-scale unannotated data. At the scene level, existing SSL methods oftenincorporate volume rendering into the pre-training framework, using RGB-Dimages as reconstruction signals to facilitate cross-modal learning. Thisstrategy promotes alignment between 2D and 3D modalities and enables the modelto benefit from rich visual cues in the RGB-D inputs. However, these approachesare limited by their reliance on implicit scene representations and high memorydemands. Furthermore, since their reconstruction objectives are applied only in2D space, they often fail to capture underlying 3D geometric structures. Toaddress these challenges, we propose Gaussian2Scene, a novel scene-level SSLframework that leverages the efficiency and explicit nature of 3D GaussianSplatting (3DGS) for pre-training. The use of 3DGS not only alleviates thecomputational burden associated with volume rendering but also supports direct3D scene reconstruction, thereby enhancing the geometric understanding of thebackbone network. Our approach follows a progressive two-stage trainingstrategy. In the first stage, a dual-branch masked autoencoder learns both 2Dand 3D scene representations. In the second stage, we initialize training withreconstructed point clouds and further supervise learning using the geometriclocations of Gaussian primitives and rendered RGB images. This processreinforces both geometric and cross-modal learning. We demonstrate theeffectiveness of Gaussian2Scene across several downstream 3D object detectiontasks, showing consistent improvements over existing pre-training methods.</description>
      <author>example@mail.com (Keyi Liu, Weidong Yang, Ben Fei, Ying He)</author>
      <guid isPermaLink="false">2506.08777v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>TrajFlow: Multi-modal Motion Prediction via Flow Matching</title>
      <link>http://arxiv.org/abs/2506.08541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TrajFlow是一个基于流匹配的运动预测框架，用于解决现有生成轨迹预测方法的可扩展性和效率问题，并在Waymo Open Motion Dataset上表现出色。&lt;h4&gt;背景&lt;/h4&gt;高效准确的运动预测对于自动驾驶安全及决策至关重要，尤其在动态的真实世界条件下需要多模态预测。&lt;h4&gt;目的&lt;/h4&gt;提出TrajFlow，解决现有生成轨迹预测方法的可扩展性和效率挑战。&lt;h4&gt;方法&lt;/h4&gt;1. 采用单次预测多个可能轨迹的方法，减少计算开销。2. 提出基于Plackett-Luce分布的排名损失函数，提高预测轨迹的不确定性估计。3. 设计自条件化训练技术，通过模型自身预测构造噪声输入，提升泛化能力和加速推理。&lt;h4&gt;主要发现&lt;/h4&gt;TrajFlow在Waymo Open Motion Dataset上实现了在多个关键指标上的最先进性能。&lt;h4&gt;结论&lt;/h4&gt;TrajFlow对于安全关键型自动驾驶应用是有效的。&lt;h4&gt;翻译&lt;/h4&gt;Efficient and accurate motion prediction is crucial for ensuring safety and informed decision-making in autonomous driving, particularly under dynamic real-world conditions that necessitate multi-modal forecasts. We introduce TrajFlow, a novel flow matching-based motion prediction framework that addresses the scalability and efficiency challenges of existing generative trajectory prediction methods. Unlike conventional generative approaches that employ i.i.d. sampling and require multiple inference passes to capture diverse outcomes, TrajFlow predicts multiple plausible future trajectories in a single pass, significantly reducing computational overhead while maintaining coherence across predictions. Moreover, we propose a ranking loss based on the Plackett-Luce distribution to improve uncertainty estimation of predicted trajectories. Additionally, we design a self-conditioning training techniquethat reuses the model's own predictions to construct noisy inputs during a second forward pass, thereby improving generalization and accelerating inference. Extensive experiments on the large-scale Waymo Open Motion Dataset (WOMD) demonstrate that TrajFlow achieves state-of-the-art performance across various key metrics, underscoring its effectiveness for safety-critical autonomous driving applications. The code and other details are available on the project website https://traj-flow.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient and accurate motion prediction is crucial for ensuring safety andinformed decision-making in autonomous driving, particularly under dynamicreal-world conditions that necessitate multi-modal forecasts. We introduceTrajFlow, a novel flow matching-based motion prediction framework thataddresses the scalability and efficiency challenges of existing generativetrajectory prediction methods. Unlike conventional generative approaches thatemploy i.i.d. sampling and require multiple inference passes to capture diverseoutcomes, TrajFlow predicts multiple plausible future trajectories in a singlepass, significantly reducing computational overhead while maintaining coherenceacross predictions. Moreover, we propose a ranking loss based on thePlackett-Luce distribution to improve uncertainty estimation of predictedtrajectories. Additionally, we design a self-conditioning training techniquethat reuses the model's own predictions to construct noisy inputs during asecond forward pass, thereby improving generalization and acceleratinginference. Extensive experiments on the large-scale Waymo Open Motion Dataset(WOMD) demonstrate that TrajFlow achieves state-of-the-art performance acrossvarious key metrics, underscoring its effectiveness for safety-criticalautonomous driving applications. The code and other details are available onthe project website https://traj-flow.github.io/.</description>
      <author>example@mail.com (Qi Yan, Brian Zhang, Yutong Zhang, Daniel Yang, Joshua White, Di Chen, Jiachao Liu, Langechuan Liu, Binnan Zhuang, Shaoshuai Shi, Renjie Liao)</author>
      <guid isPermaLink="false">2506.08541v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Cosmos-Drive-Dreams: Scalable Synthetic Driving Data Generation with World Foundation Models</title>
      <link>http://arxiv.org/abs/2506.09042v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Xuanchi Ren, Yifan Lu, Tianshi Cao, Ruiyuan Gao: Equal contribution.  Only the core contributors are listed. The full list of contributors can be  found in Appendix A of this paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Cosmos-Drive-Dreams的合成数据生成（SDG）流程，旨在为自动驾驶（AV）系统等关键物理AI系统生成具有挑战性的场景，以促进感知和驾驶策略训练等下游任务。&lt;h4&gt;背景&lt;/h4&gt;收集和注释用于安全关键物理AI系统（如自动驾驶汽车）的真实世界数据既耗时又昂贵，尤其是捕捉罕见边缘情况，这些情况在AV系统的训练和测试中起着关键作用。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，目的是生成具有挑战性的场景，以促进下游任务，如感知和驾驶策略训练。&lt;h4&gt;方法&lt;/h4&gt;Cosmos-Drive-Dreams流程由Cosmos-Drive支持，这是一个从NVIDIA Cosmos世界基础模型专门针对驾驶领域优化的模型套件，能够生成可控、高保真、多视角和时空一致性的驾驶视频。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，生成的数据有助于缓解长尾分布问题，并增强了下游任务（如3D车道检测、3D物体检测和驾驶策略学习）的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文开源了Cosmos-Drive-Dreams的流程工具包、数据集和模型权重，通过NVIDIA的Cosmos平台提供。&lt;h4&gt;翻译&lt;/h4&gt;Collecting and annotating real-world data for safety-critical physical AI systems, such as Autonomous Vehicle (AV), is time-consuming and costly. It is especially challenging to capture rare edge cases, which play a critical role in training and testing of an AV system. To address this challenge, we introduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipeline that aims to generate challenging scenarios to facilitate downstream tasks such as perception and driving policy training. Powering this pipeline is Cosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundation model for the driving domain and are capable of controllable, high-fidelity, multi-view, and spatiotemporally consistent driving video generation. We showcase the utility of these models by applying Cosmos-Drive-Dreams to scale the quantity and diversity of driving datasets with high-fidelity and challenging scenarios. Experimentally, we demonstrate that our generated data helps in mitigating long-tail distribution problems and enhances generalization in downstream tasks such as 3D lane detection, 3D object detection and driving policy learning. We open source our pipeline toolkit, dataset and model weight through the NVIDIA's Cosmos platform.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Collecting and annotating real-world data for safety-critical physical AIsystems, such as Autonomous Vehicle (AV), is time-consuming and costly. It isespecially challenging to capture rare edge cases, which play a critical rolein training and testing of an AV system. To address this challenge, weintroduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipelinethat aims to generate challenging scenarios to facilitate downstream tasks suchas perception and driving policy training. Powering this pipeline isCosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundationmodel for the driving domain and are capable of controllable, high-fidelity,multi-view, and spatiotemporally consistent driving video generation. Weshowcase the utility of these models by applying Cosmos-Drive-Dreams to scalethe quantity and diversity of driving datasets with high-fidelity andchallenging scenarios. Experimentally, we demonstrate that our generated datahelps in mitigating long-tail distribution problems and enhances generalizationin downstream tasks such as 3D lane detection, 3D object detection and drivingpolicy learning. We open source our pipeline toolkit, dataset and model weightsthrough the NVIDIA's Cosmos platform.  Project page: https://research.nvidia.com/labs/toronto-ai/cosmos_drive_dreams</description>
      <author>example@mail.com (Xuanchi Ren, Yifan Lu, Tianshi Cao, Ruiyuan Gao, Shengyu Huang, Amirmojtaba Sabour, Tianchang Shen, Tobias Pfaff, Jay Zhangjie Wu, Runjian Chen, Seung Wook Kim, Jun Gao, Laura Leal-Taixe, Mike Chen, Sanja Fidler, Huan Ling)</author>
      <guid isPermaLink="false">2506.09042v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Data-Efficient Challenges in Visual Inductive Priors: A Retrospective</title>
      <link>http://arxiv.org/abs/2506.08612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在数据不足的设置中，哪些深度学习方法能够提高模型的训练效果。&lt;h4&gt;背景&lt;/h4&gt;深度学习需要大量数据来训练模型，但在数据不足的情况下，模型的性能可能会下降。&lt;h4&gt;目的&lt;/h4&gt;通过组织“VIPriors：视觉归纳先验用于数据高效深度学习”研讨会系列，旨在刺激新型方法的发展，这些方法通过结合先验知识来提高深度学习模型的数据效率。&lt;h4&gt;方法&lt;/h4&gt;研讨会包括四届数据受损挑战赛，参与者只能使用少量训练样本从头开始训练模型，并且不允许使用任何形式的迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;成功的挑战参赛作品使用了混合Transformer和CNN的大规模模型集成，以及大量的数据增强。基于新先验知识的方法在某些参赛作品中取得了成功。&lt;h4&gt;结论&lt;/h4&gt;数据不足的环境下，深度学习模型可以通过结合先验知识和创新的模型集成方法来提高数据效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep Learning requires large amounts of data to train models that work well.In data-deficient settings, performance can be degraded. We investigate whichDeep Learning methods benefit training models in a data-deficient setting, byorganizing the "VIPriors: Visual Inductive Priors for Data-Efficient DeepLearning" workshop series, featuring four editions of data-impaired challenges.These challenges address the problem of training deep learning models forcomputer vision tasks with limited data. Participants are limited to trainingmodels from scratch using a low number of training samples and are not allowedto use any form of transfer learning. We aim to stimulate the development ofnovel approaches that incorporate prior knowledge to improve the dataefficiency of deep learning models. Successful challenge entries make use oflarge model ensembles that mix Transformers and CNNs, as well as heavy dataaugmentation. Novel prior knowledge-based methods contribute to success in someentries.</description>
      <author>example@mail.com (Robert-Jan Bruintjes, Attila Lengyel, Osman Semih Kayhan, Davide Zambrano, Nergis Tömen, Hadi Jamali-Rad, Jan van Gemert)</author>
      <guid isPermaLink="false">2506.08612v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Effective Data Pruning through Score Extrapolation</title>
      <link>http://arxiv.org/abs/2506.09010v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的数据剪枝技术，通过在小数据集上训练来预测整个数据集的样本重要性，从而在保持模型性能的同时减少计算成本。&lt;h4&gt;背景&lt;/h4&gt;高级机器学习模型训练需要大量数据集，导致计算成本高昂。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，提出了一种新的数据剪枝方法，以减少计算成本。&lt;h4&gt;方法&lt;/h4&gt;该方法通过在少量数据上训练，使用k最近邻和图神经网络来预测样本重要性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在动态不确定性剪枝和TDDS剪枝等两种现有剪枝方法、四个不同数据集（CIFAR-10、CIFAR-100、Places-365和ImageNet）以及三种训练范式（监督学习、无监督学习和对抗学习）中均显示出有效性。&lt;h4&gt;结论&lt;/h4&gt;分数外推是一种有前途的方法，可以扩展像剪枝这样的昂贵计算方法。&lt;h4&gt;翻译&lt;/h4&gt;Training advanced machine learning models requires massive datasets, resulting in prohibitive computational costs. To address this challenge, data pruning techniques identify and remove redundant training samples while preserving model performance. Yet, existing pruning techniques predominantly require a full initial training pass to identify removable samples, negating any efficiency benefits for single training runs. To overcome this limitation, we introduce a novel importance score extrapolation framework that requires training on only a small subset of data. We present two initial approaches in this framework - k-nearest neighbors and graph neural networks - to accurately predict sample importance for the entire dataset using patterns learned from this minimal subset. We demonstrate the effectiveness of our approach for 2 state-of-the-art pruning methods (Dynamic Uncertainty and TDDS), 4 different datasets (CIFAR-10, CIFAR-100, Places-365, and ImageNet), and 3 training paradigms (supervised, unsupervised, and adversarial). Our results indicate that score extrapolation is a promising direction to scale expensive score calculation methods, such as pruning, data attribution, or other tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training advanced machine learning models demands massive datasets, resultingin prohibitive computational costs. To address this challenge, data pruningtechniques identify and remove redundant training samples while preservingmodel performance. Yet, existing pruning techniques predominantly require afull initial training pass to identify removable samples, negating anyefficiency benefits for single training runs. To overcome this limitation, weintroduce a novel importance score extrapolation framework that requirestraining on only a small subset of data. We present two initial approaches inthis framework - k-nearest neighbors and graph neural networks - to accuratelypredict sample importance for the entire dataset using patterns learned fromthis minimal subset. We demonstrate the effectiveness of our approach for 2state-of-the-art pruning methods (Dynamic Uncertainty and TDDS), 4 differentdatasets (CIFAR-10, CIFAR-100, Places-365, and ImageNet), and 3 trainingparadigms (supervised, unsupervised, and adversarial). Our results indicatethat score extrapolation is a promising direction to scale expensive scorecalculation methods, such as pruning, data attribution, or other tasks.</description>
      <author>example@mail.com (Sebastian Schmidt, Prasanga Dhungel, Christoffer Löffler, Björn Nieth, Stephan Günnemann, Leo Schwinn)</author>
      <guid isPermaLink="false">2506.09010v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Rapid cardiac activation prediction for cardiac resynchronization therapy planning using geometric deep learning</title>
      <link>http://arxiv.org/abs/2506.08987v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文开发了一种基于几何深度学习模型的方法，用于预测心脏激动时间图，以优化心脏再同步治疗（CRT）。&lt;h4&gt;背景&lt;/h4&gt;CRT是治疗同步性心脏衰竭的常见干预措施，但由于电极放置不佳，大约三分之一的患者无法响应。&lt;h4&gt;目的&lt;/h4&gt;构建一种在硅中模拟的方法，以帮助解决CRT规划中识别最佳起搏位点的问题。&lt;h4&gt;方法&lt;/h4&gt;开发了两种基于图神经网络（GNN）和几何信息神经网络操作符（GINO）的几何深度学习（DL）模型，用于实时预测CRT规划中的心脏激动时间图。这些模型在由有限元（FE）模拟生成的大型合成数据集上进行了训练，数据集涵盖了广泛的心室（LV）几何形状、起搏位点配置和组织电导率。&lt;h4&gt;主要发现&lt;/h4&gt;GINO模型在预测精度和鲁棒性方面优于GNN模型，且预测误差更低（1.14% vs 3.14%），对噪声和不同网格离散化具有更好的鲁棒性。使用GINO模型，我们还开发了一种从给定的激动时间图和LV几何形状中优化CRT起搏位点的流程。与随机选择起搏位点相比，CRT优化流程可以显著减少最大激动时间（20% vs. 8%）。&lt;h4&gt;结论&lt;/h4&gt;GINO模型在CRT个性化术前优化方面具有作为临床决策支持工具的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Cardiac resynchronization therapy (CRT) is a common intervention for patients with dyssynchronous heart failure, yet approximately one-third of recipients fail to respond due to suboptimal lead placement. Identifying optimal pacing sites remains challenging, largely due to patient-specific anatomical variability and the limitations of current individualized planning strategies. In a step towards constructing an in-silico approach to help address this issue, we develop two geometric deep learning (DL) models, based on graph neural network (GNN) and geometry-informed neural operator (GINO), to predict cardiac activation time map in real-time for CRT planning and optimization. Both models are trained on a large synthetic dataset generated from finite-element (FE) simulations over a wide range of left ventricular (LV) geometries, pacing site configurations, and tissue conductivities. The GINO model significantly outperforms the GNN model, with lower prediction errors (1.14% vs 3.14%) and superior robustness to noise and various mesh discretization. Using the GINO model, we also develop a workflow for optimizing the pacing site in CRT from given activation time map and LV geometry. Compared to randomly selecting a pacing site, the CRT optimization workflow produces a larger reduction in maximum activation time (20% vs. 8%). In conjunction with an interactive web-based graphical user interface (GUI) available at https://dcsim.egr.msu.edu/, the GINO model shows promising potential as a clinical decision-support tool for personalized pre-procedural CRT optimization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ehsanngh/DeepCardioSim&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cardiac resynchronization therapy (CRT) is a common intervention for patientswith dyssynchronous heart failure, yet approximately one-third of recipientsfail to respond due to suboptimal lead placement. Identifying optimal pacingsites remains challenging, largely due to patient-specific anatomicalvariability and the limitations of current individualized planning strategies.In a step towards constructing an in-silico approach to help address thisissue, we develop two geometric deep learning (DL) models, based on graphneural network (GNN) and geometry-informed neural operator (GINO), to predictcardiac activation time map in real-time for CRT planning and optimization.Both models are trained on a large synthetic dataset generated fromfinite-element (FE) simulations over a wide range of left ventricular (LV)geometries, pacing site configurations, and tissue conductivities. The GINOmodel significantly outperforms the GNN model, with lower prediction errors(1.14% vs 3.14%) and superior robustness to noise and various meshdiscretization. Using the GINO model, we also develop a workflow for optimizingthe pacing site in CRT from given activation time map and LV geometry. Comparedto randomly selecting a pacing site, the CRT optimization workflow produces alarger reduction in maximum activation time (20% vs. 8%). In conjunction withan interactive web-based graphical user interface (GUI) available athttps://dcsim.egr.msu.edu/, the GINO model shows promising potential as aclinical decision-support tool for personalized pre-procedural CRToptimization.</description>
      <author>example@mail.com (Ehsan Naghavi, Haifeng Wang, Vahid Ziaei Rad, Julius Guccione, Ghassan Kassab, Vishnu Boddeti, Seungik Baek, Lik-Chuan Lee)</author>
      <guid isPermaLink="false">2506.08987v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>SceneSplat++: A Large Dataset and Comprehensive Benchmark for Language Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.08710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, codes, data and benchmark will be released&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为3D Gaussian Splatting的3D场景编码方法，并建立了一个大规模基准来评估不同方法在3D空间中的性能。&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting是一种高效的场景几何、外观和语义编码方法，将语言与3D场景结合是理解3D场景的有效策略。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法在评估上存在的局限性，提出一个能够全面评估不同方法的基准。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含1060个场景的大规模基准，涵盖室内和室外数据集，评估了基于场景优化、无场景优化和通用方法的三种主要方法。&lt;h4&gt;主要发现&lt;/h4&gt;通用方法在放宽场景特定限制、实现快速前向推理和获得更好的分割性能方面具有明显优势。&lt;h4&gt;结论&lt;/h4&gt;提出了一个名为GaussianWorld-49K的精心策划的3DGS数据集，展示了通用方法可以利用强大的数据先验，并公开了代码、基准和数据集以加速研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D高斯散布（3DGS）是一种高效且有效的场景几何、外观和语义编码。此外，将语言根植于3D场景已被证明是理解3D场景的有效策略。当前的语言高斯散布工作分为三大类：（一）基于场景优化的，（二）无场景优化的，（三）通用方法。然而，大多数工作只评估了少量场景和视角接近训练视图的渲染2D视图，限制了全面3D理解的能力和洞察力。为了解决这一差距，我们提出了第一个直接在3D空间中系统评估这三组方法的基准。在三个室内数据集和一个室外数据集上评估了1060个场景。基准结果表明，通用范式具有明显优势，尤其是在放宽场景特定限制、实现新颖场景的快速前向推理和获得更好的分割性能方面。我们进一步引入了GaussianWorld-49K，这是一个包含约49K个来自多个来源的室内和室外场景的精心策划的3DGS数据集，我们展示了通用方法可以利用强大的数据先验。我们的代码、基准和数据集将公开，以加速通用3DGS场景理解的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) serves as a highly performant and efficientencoding of scene geometry, appearance, and semantics. Moreover, groundinglanguage in 3D scenes has proven to be an effective strategy for 3D sceneunderstanding. Current Language Gaussian Splatting line of work fall into threemain groups: (i) per-scene optimization-based, (ii) per-sceneoptimization-free, and (iii) generalizable approach. However, most of them areevaluated only on rendered 2D views of a handful of scenes and viewpoints closeto the training views, limiting ability and insight into holistic 3Dunderstanding. To address this gap, we propose the first large-scale benchmarkthat systematically assesses these three groups of methods directly in 3Dspace, evaluating on 1060 scenes across three indoor datasets and one outdoordataset. Benchmark results demonstrate a clear advantage of the generalizableparadigm, particularly in relaxing the scene-specific limitation, enabling fastfeed-forward inference on novel scenes, and achieving superior segmentationperformance. We further introduce GaussianWorld-49K a carefully curated 3DGSdataset comprising around 49K diverse indoor and outdoor scenes obtained frommultiple sources, with which we demonstrate the generalizable approach couldharness strong data priors. Our codes, benchmark, and datasets will be madepublic to accelerate research in generalizable 3DGS scene understanding.</description>
      <author>example@mail.com (Mengjiao Ma, Qi Ma, Yue Li, Jiahuan Cheng, Runyi Yang, Bin Ren, Nikola Popovic, Mingqiang Wei, Nicu Sebe, Luc Van Gool, Theo Gevers, Martin R. Oswald, Danda Pani Paudel)</author>
      <guid isPermaLink="false">2506.08710v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Medical Vision-Language Alignment Through Adapting Masked Vision Models</title>
      <link>http://arxiv.org/abs/2506.08990v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  TMI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ALTA的医学视觉-语言对齐方法，该方法在图像-文本匹配任务中表现优异，如检索和零样本分类。ALTA通过优化视觉模型和整合时间多视图影像输入，提高了视觉-语言对齐的效果。&lt;h4&gt;背景&lt;/h4&gt;传统的跨模态对比学习方法在视觉-语言对齐中存在视觉表示能力不足的问题，而多模态掩码模型预训练的模型虽然在视觉表示上表现较好，但在直接跨模态匹配上存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且性能优越的医学视觉-语言对齐方法，以解决传统方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;ALTA方法利用了约8%的可训练参数和少于1/5的掩码记录建模的计算消耗。它通过调整预训练的视觉模型，并结合时间多视图影像输入，来提高视觉-语言对齐的性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ALTA在文本到图像的准确率和图像到文本的检索准确率上分别优于最佳竞争者超过4%和6%。&lt;h4&gt;结论&lt;/h4&gt;ALTA是一种有效的医学视觉-语言对齐方法，通过优化视觉模型和整合影像输入，提高了视觉-语言对齐的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通过跨模态对比学习实现的医学视觉-语言对齐在图像-文本匹配任务中表现出良好的性能，如检索和零样本分类。然而，传统的跨模态对比学习方法（基于CLIP）在视觉表示能力上存在不足，这也限制了它们在视觉-语言对齐中的有效性。相比之下，虽然通过多模态掩码模型预训练的模型在直接跨模态匹配上存在困难，但它们在视觉表示上表现出色。为了解决这一矛盾，我们提出了ALTA（通过调整对齐），一种高效的医学视觉-语言对齐方法，它仅使用了大约8%的可训练参数，以及掩码记录建模所需计算消耗的不到1/5。ALTA通过调整掩码记录建模预训练的视觉模型，在检索和零样本分类等视觉-语言匹配任务中实现了优异的性能。此外，我们还整合了时间多视图影像输入，以增强影像与其对应报告中描述之间的信息一致性，进一步提高了视觉-语言对齐的效果。实验评估表明，ALTA在文本到图像的准确率上优于最佳竞争者超过4%，在图像到文本的检索准确率上约高6%。在有效对齐过程中对视觉-语言模型的调整也促进了更好的视觉和语言理解。代码可在https://github.com/DopamineLcy/ALTA公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TMI.2025.3575853&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical vision-language alignment through cross-modal contrastive learningshows promising performance in image-text matching tasks, such as retrieval andzero-shot classification. However, conventional cross-modal contrastivelearning (CLIP-based) methods suffer from suboptimal visual representationcapabilities, which also limits their effectiveness in vision-languagealignment. In contrast, although the models pretrained via multimodal maskedmodeling struggle with direct cross-modal matching, they excel in visualrepresentation. To address this contradiction, we propose ALTA (ALign ThroughAdapting), an efficient medical vision-language alignment method that utilizesonly about 8% of the trainable parameters and less than 1/5 of thecomputational consumption required for masked record modeling. ALTA achievessuperior performance in vision-language matching tasks like retrieval andzero-shot classification by adapting the pretrained vision model from maskedrecord modeling. Additionally, we integrate temporal-multiview radiographinputs to enhance the information consistency between radiographs and theircorresponding descriptions in reports, further improving the vision-languagealignment. Experimental evaluations show that ALTA outperforms thebest-performing counterpart by over 4% absolute points in text-to-imageaccuracy and approximately 6% absolute points in image-to-text retrievalaccuracy. The adaptation of vision-language models during efficient alignmentalso promotes better vision and language understanding. Code is publiclyavailable at https://github.com/DopamineLcy/ALTA.</description>
      <author>example@mail.com (Chenyu Lian, Hong-Yu Zhou, Dongyun Liang, Jing Qin, Liansheng Wang)</author>
      <guid isPermaLink="false">2506.08990v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>LiftVSR: Lifting Image Diffusion to Video Super-Resolution via Hybrid Temporal Modeling with Only 4$\times$RTX 4090s</title>
      <link>http://arxiv.org/abs/2506.08529v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://kopperx.github.io/projects/liftvsr&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;LiftVSR是一种高效的视频超分辨率框架，通过提升图像扩散先验和引入混合时间建模机制，在保持长期一致性和效率的同时，显著降低了计算成本。&lt;h4&gt;背景&lt;/h4&gt;现有的视频超分辨率方法在保证帧间一致性和降低计算成本方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一个高效的VSR框架，以平衡长期一致性和效率。&lt;h4&gt;方法&lt;/h4&gt;引入了一种混合时间建模机制，包括：(i) 动态时间注意力（DTA）用于短帧段内的细粒度时间建模，和(ii) 注意力内存缓存（AMC）用于跨段的长期时间建模。此外，还引入了不对称采样策略以稳定缓存交互。&lt;h4&gt;主要发现&lt;/h4&gt;LiftVSR在多个VSR基准测试中表现出色，并且计算成本显著低于现有方法。&lt;h4&gt;结论&lt;/h4&gt;LiftVSR通过创新的技术解决了现有VSR方法的局限性，实现了高效的视频超分辨率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion models have significantly advanced video super-resolution (VSR) byenhancing perceptual quality, largely through elaborately designed temporalmodeling to ensure inter-frame consistency. However, existing methods usuallysuffer from limited temporal coherence and prohibitively high computationalcosts (e.g., typically requiring over 8 NVIDIA A100-80G GPUs), especially forlong videos. In this work, we propose LiftVSR, an efficient VSR framework thatleverages and elevates the image-wise diffusion prior from PixArt-$\alpha$,achieving state-of-the-art results using only 4$\times$RTX 4090 GPUs. Tobalance long-term consistency and efficiency, we introduce a hybrid temporalmodeling mechanism that decomposes temporal learning into two complementarycomponents: (i) Dynamic Temporal Attention (DTA) for fine-grained temporalmodeling within short frame segment ($\textit{i.e.}$, low complexity), and (ii)Attention Memory Cache (AMC) for long-term temporal modeling across segments($\textit{i.e.}$, consistency). Specifically, DTA identifies multiple tokenflows across frames within multi-head query and key tokens to warp inter-framecontexts in the value tokens. AMC adaptively aggregates historical segmentinformation via a cache unit, ensuring long-term coherence with minimaloverhead. To further stabilize the cache interaction during inference, weintroduce an asymmetric sampling strategy that mitigates feature mismatchesarising from different diffusion sampling steps. Extensive experiments onseveral typical VSR benchmarks have demonstrated that LiftVSR achievesimpressive performance with significantly lower computational costs.</description>
      <author>example@mail.com (Xijun Wang, Xin Li, Bingchen Li, Zhibo Chen)</author>
      <guid isPermaLink="false">2506.08529v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>InfoDPCCA: Information-Theoretic Dynamic Probabilistic Canonical Correlation Analysis</title>
      <link>http://arxiv.org/abs/2506.08884v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by UAI-25, code is available at  \url{https://github.com/marcusstang/InfoDPCCA}&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;InfoDPCCA是一种动态概率典型相关分析（CCA）框架，用于从高维序列数据中提取有意义的潜在表示。&lt;h4&gt;背景&lt;/h4&gt;提取高维序列数据中的潜在表示是机器学习中的一个关键挑战，其应用范围涵盖自然科学和工程领域。&lt;h4&gt;目的&lt;/h4&gt;InfoDPCCA旨在模型两个相互依赖的观察序列，提取共享的潜在表示，同时学习针对每个序列的特定信息。&lt;h4&gt;方法&lt;/h4&gt;InfoDPCCA利用一种新的信息论目标函数来提取共享的潜在表示，并学习单独的潜在组件，以编码每个序列的特定信息。此外，它引入了一种两步训练方案和残差连接机制来提高训练稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;InfoDPCCA在合成和医学fMRI数据上的实验表明，它是一种出色的表示学习工具。&lt;h4&gt;结论&lt;/h4&gt;InfoDPCCA通过提高可解释性和鲁棒性，有效地解决了动态CCA模型中的互信息编码问题。&lt;h4&gt;翻译&lt;/h4&gt;从高维序列数据中提取有意义的潜在表示是机器学习中的一个关键挑战，其应用范围涵盖自然科学和工程领域。我们引入了InfoDPCCA，这是一种动态概率典型相关分析（CCA）框架，旨在模型两个相互依赖的观察序列。InfoDPCCA利用一种新的信息论目标函数来提取共享的潜在表示，以捕获数据流之间的相互结构，并在表示压缩和预测充分性之间取得平衡，同时学习针对每个序列的特定信息。与DPCCA等先前动态CCA模型不同，我们的方法明确强制共享潜在空间仅编码序列之间的互信息，从而提高了可解释性和鲁棒性。我们还引入了一种两步训练方案，以弥合信息论表示学习和生成建模之间的差距，并采用残差连接机制来增强训练稳定性。通过合成和医学fMRI数据上的实验，我们证明了InfoDPCCA作为表示学习工具的优越性。InfoDPCCA的代码可在https://github.com/marcusstang/InfoDPCCA上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Extracting meaningful latent representations from high-dimensional sequentialdata is a crucial challenge in machine learning, with applications spanningnatural science and engineering. We introduce InfoDPCCA, a dynamicprobabilistic Canonical Correlation Analysis (CCA) framework designed to modeltwo interdependent sequences of observations. InfoDPCCA leverages a novelinformation-theoretic objective to extract a shared latent representation thatcaptures the mutual structure between the data streams and balancesrepresentation compression and predictive sufficiency while also learningseparate latent components that encode information specific to each sequence.Unlike prior dynamic CCA models, such as DPCCA, our approach explicitlyenforces the shared latent space to encode only the mutual information betweenthe sequences, improving interpretability and robustness. We further introducea two-step training scheme to bridge the gap between information-theoreticrepresentation learning and generative modeling, along with a residualconnection mechanism to enhance training stability. Through experiments onsynthetic and medical fMRI data, we demonstrate that InfoDPCCA excels as a toolfor representation learning. Code of InfoDPCCA is available athttps://github.com/marcusstang/InfoDPCCA.</description>
      <author>example@mail.com (Shiqin Tang, Shujian Yu)</author>
      <guid isPermaLink="false">2506.08884v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>ArrowPose: Segmentation, Detection, and 5 DoF Pose Estimation Network for Colorless Point Clouds</title>
      <link>http://arxiv.org/abs/2506.08699v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于无色点云的快速检测和5自由度姿态估计网络。&lt;h4&gt;背景&lt;/h4&gt;该网络通过神经网络预测物体的中心和顶部点来进行姿态估计。&lt;h4&gt;目的&lt;/h4&gt;该网络旨在实现快速且准确的无色点云姿态估计。&lt;h4&gt;方法&lt;/h4&gt;网络在合成数据上训练，并在基准数据集上进行测试，显示出最先进的性能，优于所有无色方法。&lt;h4&gt;主要发现&lt;/h4&gt;该网络能够在仅250毫秒内完成推理，适用于多种场景。&lt;h4&gt;结论&lt;/h4&gt;该网络为无色点云的姿态估计提供了一种快速且有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种针对无色点云的快速检测和5自由度姿态估计网络。该网络通过神经网络预测物体的中心和顶部点来进行姿态估计。网络在合成数据上训练，在基准数据集上测试，表现出最先进的性能，优于所有无色方法。该网络能够在仅250毫秒内完成推理，适用于多种场景。项目页面及代码位于arrowpose.github.io。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a fast detection and 5 DoF (Degrees of Freedom) poseestimation network for colorless point clouds. The pose estimation iscalculated from center and top points of the object, predicted by the neuralnetwork. The network is trained on synthetic data, and tested on a benchmarkdataset, where it demonstrates state-of-the-art performance and outperforms allcolorless methods. The network is able to run inference in only 250milliseconds making it usable in many scenarios. Project page with code atarrowpose.github.io</description>
      <author>example@mail.com (Frederik Hagelskjaer)</author>
      <guid isPermaLink="false">2506.08699v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Adapting to Heterophilic Graph Data with Structure-Guided Neighbor Discovery</title>
      <link>http://arxiv.org/abs/2506.08871v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为结构引导图神经网络（SG-GNN）的架构，用于解决异质数据中的图神经网络（GNNs）性能问题，通过创建新的图结构来提高标签同质性，并通过实验证明其有效性。&lt;h4&gt;背景&lt;/h4&gt;GNNs在处理异质数据时存在困难，因为它们通常假设同质性并依赖于局部消息传递。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来提高GNN在异质数据上的性能。&lt;h4&gt;方法&lt;/h4&gt;通过创建具有相似结构属性的节点链接来构建新的图结构，并证明使用具有较少错误正边（不同类节点之间的连接）的图可以提高GNN性能。引入SG-GNN架构，该架构同时处理原始图和新创建的结构图，自适应地学习权衡它们的贡献。&lt;h4&gt;主要发现&lt;/h4&gt;SG-GNN在具有异质特性的各种基准数据集上实现了最先进或高度竞争的性能，证明了利用结构信息引导GNN的有效性。&lt;h4&gt;结论&lt;/h4&gt;结构引导GNN（SG-GNN）通过利用结构信息提高了GNN在处理异质数据时的性能，为GNN的应用提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) often struggle with heterophilic data, where connected nodes may have dissimilar labels, as they typically assume homophily and rely on local message passing. To address this, we propose creating alternative graph structures by linking nodes with similar structural attributes (e.g., role-based or global), thereby fostering higher label homophily on these new graphs. We theoretically prove that GNN performance can be improved by utilizing graphs with fewer false positive edges (connections between nodes of different classes) and that considering multiple graph views increases the likelihood of finding such beneficial structures. Building on these insights, we introduce Structure-Guided GNN (SG-GNN), an architecture that processes the original graph alongside the newly created structural graphs, adaptively learning to weigh their contributions. Extensive experiments on various benchmark datasets, particularly those with heterophilic characteristics, demonstrate that our SG-GNN achieves state-of-the-art or highly competitive performance, highlighting the efficacy of exploiting structural information to guide GNNs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) often struggle with heterophilic data, whereconnected nodes may have dissimilar labels, as they typically assume homophilyand rely on local message passing. To address this, we propose creatingalternative graph structures by linking nodes with similar structuralattributes (e.g., role-based or global), thereby fostering higher labelhomophily on these new graphs. We theoretically prove that GNN performance canbe improved by utilizing graphs with fewer false positive edges (connectionsbetween nodes of different classes) and that considering multiple graph viewsincreases the likelihood of finding such beneficial structures. Building onthese insights, we introduce Structure-Guided GNN (SG-GNN), an architecturethat processes the original graph alongside the newly created structuralgraphs, adaptively learning to weigh their contributions. Extensive experimentson various benchmark datasets, particularly those with heterophiliccharacteristics, demonstrate that our SG-GNN achieves state-of-the-art orhighly competitive performance, highlighting the efficacy of exploitingstructural information to guide GNNs.</description>
      <author>example@mail.com (Victor M. Tenorio, Madeline Navarro, Samuel Rey, Santiago Segarra, Antonio G. Marques)</author>
      <guid isPermaLink="false">2506.08871v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly</title>
      <link>http://arxiv.org/abs/2506.08708v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PhyBlock是一个渐进式基准，用于评估视觉语言模型（VLMs）在物理理解和规划方面的能力，特别是在结构化的3D环境中。&lt;h4&gt;背景&lt;/h4&gt;尽管视觉语言模型在推理和规划方面表现出有希望的能力，但它们理解物理现象的能力，特别是在结构化的3D环境中，仍然非常有限。&lt;h4&gt;目的&lt;/h4&gt;为了缩小这一差距，PhyBlock通过机器人3D积木组装任务评估VLMs的物理理解和规划能力。&lt;h4&gt;方法&lt;/h4&gt;PhyBlock整合了一个新颖的四级认知层次组装任务和针对性的视觉问答（VQA）样本，旨在评估渐进式空间推理和基本物理理解，包括物体属性、空间关系和整体场景理解。它包括2600个积木任务（400个组装任务，2200个VQA任务），并从部分完成、故障诊断和规划鲁棒性三个关键维度评估模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，VLMs在高级规划和推理能力方面存在明显限制，导致随着任务复杂性的增加，性能显著下降。错误分析揭示了在空间定位和依赖推理方面的持续困难。令人惊讶的是，思维链提示提供的改进最小，表明空间任务严重依赖于直观的模型理解。&lt;h4&gt;结论&lt;/h4&gt;PhyBlock被定位为一个统一的测试平台，以推进具身推理，架起视觉语言理解和现实世界物理问题解决之间的桥梁。&lt;h4&gt;翻译&lt;/h4&gt;While vision-language models (VLMs) have demonstrated promising capabilities in reasoning and planning for embodied agents, their ability to comprehend physical phenomena, particularly within structured 3D environments, remains severely limited. To close this gap, we introduce PhyBlock, a progressive benchmark designed to assess VLMs on physical understanding and planning through robotic 3D block assembly tasks. PhyBlock integrates a novel four-level cognitive hierarchy assembly task alongside targeted Visual Question Answering (VQA) samples, collectively aimed at evaluating progressive spatial reasoning and fundamental physical comprehension, including object properties, spatial relationships, and holistic scene understanding. PhyBlock includes 2600 block tasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three key dimensions: partial completion, failure diagnosis, and planning robustness. We benchmark 21 state-of-the-art VLMs, highlighting their strengths and limitations in physically grounded, multi-step planning. Our empirical findings indicate that the performance of VLMs exhibits pronounced limitations in high-level planning and reasoning capabilities, leading to a notable decline in performance for the growing complexity of the tasks. Error analysis reveals persistent difficulties in spatial orientation and dependency reasoning. Surprisingly, chain-of-thought prompting offers minimal improvements, suggesting spatial tasks heavily rely on intuitive model comprehension. We position PhyBlock as a unified testbed to advance embodied reasoning, bridging vision-language understanding and real-world physical problem-solving.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While vision-language models (VLMs) have demonstrated promising capabilitiesin reasoning and planning for embodied agents, their ability to comprehendphysical phenomena, particularly within structured 3D environments, remainsseverely limited. To close this gap, we introduce PhyBlock, a progressivebenchmark designed to assess VLMs on physical understanding and planningthrough robotic 3D block assembly tasks. PhyBlock integrates a novel four-levelcognitive hierarchy assembly task alongside targeted Visual Question Answering(VQA) samples, collectively aimed at evaluating progressive spatial reasoningand fundamental physical comprehension, including object properties, spatialrelationships, and holistic scene understanding. PhyBlock includes 2600 blocktasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across threekey dimensions: partial completion, failure diagnosis, and planning robustness.We benchmark 21 state-of-the-art VLMs, highlighting their strengths andlimitations in physically grounded, multi-step planning. Our empirical findingsindicate that the performance of VLMs exhibits pronounced limitations inhigh-level planning and reasoning capabilities, leading to a notable decline inperformance for the growing complexity of the tasks. Error analysis revealspersistent difficulties in spatial orientation and dependency reasoning.Surprisingly, chain-of-thought prompting offers minimal improvements,suggesting spatial tasks heavily rely on intuitive model comprehension. Weposition PhyBlock as a unified testbed to advance embodied reasoning, bridgingvision-language understanding and real-world physical problem-solving.</description>
      <author>example@mail.com (Liang Ma, Jiajun Wen, Min Lin, Rongtao Xu, Xiwen Liang, Bingqian Lin, Jun Ma, Yongxin Wang, Ziming Wei, Haokun Lin, Mingfei Han, Meng Cao, Bokui Chen, Ivan Laptev, Xiaodan Liang)</author>
      <guid isPermaLink="false">2506.08708v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Robust Evolutionary Multi-Objective Network Architecture Search for Reinforcement Learning (EMNAS-RL)</title>
      <link>http://arxiv.org/abs/2506.08533v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ESANN 2025 Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文首次提出了一种名为进化多目标网络架构搜索（EMNAS）的方法，用于优化大规模强化学习（RL）在自动驾驶（AD）中的应用中的神经网络架构。&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶领域，神经网络架构的优化是一个关键问题，它涉及到如何通过调整网络结构来提高性能并减少模型大小。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法来优化神经网络架构，以提高自动驾驶中的强化学习性能，同时减少模型尺寸。&lt;h4&gt;方法&lt;/h4&gt;EMNAS利用遗传算法来自动化网络设计，旨在通过增加奖励和减少模型尺寸来提升性能。此外，采用并行化技术来加速搜索过程，并实施师生方法来确保可扩展的优化。该方法强调迁移学习在优化迭代学习过程中的潜力，通过有效利用前一代的知识来提高学习效率和稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，定制的EMNAS在手动设计模型之上，以更少的参数实现了更高的奖励。&lt;h4&gt;结论&lt;/h4&gt;这些策略对自动驾驶中的强化学习领域的EMNAS方法有积极贡献，推动了向性能更优、适用于现实场景的网络架构的发展。&lt;h4&gt;翻译&lt;/h4&gt;本文首次提出了一种名为进化多目标网络架构搜索（EMNAS）的方法，用于优化大规模强化学习（RL）在自动驾驶（AD）中的应用中的神经网络架构。EMNAS利用遗传算法来自动化网络设计，旨在通过增加奖励和减少模型尺寸来提升性能。此外，采用并行化技术来加速搜索过程，并实施师生方法来确保可扩展的优化。该方法强调迁移学习在优化迭代学习过程中的潜力，通过有效利用前一代的知识来提高学习效率和稳定性。实验结果表明，定制的EMNAS在手动设计模型之上，以更少的参数实现了更高的奖励。这些策略对自动驾驶中的强化学习领域的EMNAS方法有积极贡献，推动了向性能更优、适用于现实场景的网络架构的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces Evolutionary Multi-Objective Network ArchitectureSearch (EMNAS) for the first time to optimize neural network architectures inlarge-scale Reinforcement Learning (RL) for Autonomous Driving (AD). EMNAS usesgenetic algorithms to automate network design, tailored to enhance rewards andreduce model size without compromising performance. Additionally,parallelization techniques are employed to accelerate the search, andteacher-student methodologies are implemented to ensure scalable optimization.This research underscores the potential of transfer learning as a robustframework for optimizing performance across iterative learning processes byeffectively leveraging knowledge from earlier generations to enhance learningefficiency and stability in subsequent generations. Experimental resultsdemonstrate that tailored EMNAS outperforms manually designed models, achievinghigher rewards with fewer parameters. The findings of these strategiescontribute positively to EMNAS for RL in autonomous driving, advancing thefield toward better-performing networks suitable for real-world scenarios.</description>
      <author>example@mail.com (Nihal Acharya Adde, Alexandra Gianzina, Hanno Gottschalk, Andreas Ebert)</author>
      <guid isPermaLink="false">2506.08533v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Spatial Transcriptomics Expression Prediction from Histopathology Based on Cross-Modal Mask Reconstruction and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.08854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于对比学习的深度学习方法，用于从全切片图像预测空间分辨率的基因表达，并在六个不同疾病数据集上进行了评估。&lt;h4&gt;背景&lt;/h4&gt;空间转录组学技术广泛用于肿瘤微环境和组织病理学的分子分析，但数据获取成本高，大规模空间转录组数据难以获得。&lt;h4&gt;目的&lt;/h4&gt;开发一种深度学习方法，以降低空间转录组学数据获取成本，并提高基因表达的预测准确性。&lt;h4&gt;方法&lt;/h4&gt;开发了一种基于对比学习的深度学习模型，用于从全切片图像中预测空间分辨率的基因表达，并在六个不同疾病数据集上评估其性能。&lt;h4&gt;主要发现&lt;/h4&gt;与现有研究相比，该方法在预测高度表达基因、高度可变基因和标记基因时，分别提高了6.27%、6.11%和11.26%的Pearson相关系数（PCC）。进一步分析表明，该方法保留了基因间相关性，并适用于样本量有限的数据库。此外，该方法在基于生物标志物表达进行癌症组织定位方面具有潜力。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于对比学习的深度学习方法在预测基因表达和癌症组织定位方面具有显著的优势和应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial transcriptomics is a technology that captures gene expression levelsat different spatial locations, widely used in tumor microenvironment analysisand molecular profiling of histopathology, providing valuable insights intoresolving gene expression and clinical diagnosis of cancer. Due to the highcost of data acquisition, large-scale spatial transcriptomics data remainchallenging to obtain. In this study, we develop a contrastive learning-baseddeep learning method to predict spatially resolved gene expression fromwhole-slide images. Evaluation across six different disease datasetsdemonstrates that, compared to existing studies, our method improves PearsonCorrelation Coefficient (PCC) in the prediction of highly expressed genes,highly variable genes, and marker genes by 6.27%, 6.11%, and 11.26%respectively. Further analysis indicates that our method preserves gene-genecorrelations and applies to datasets with limited samples. Additionally, ourmethod exhibits potential in cancer tissue localization based on biomarkerexpression.</description>
      <author>example@mail.com (Junzhuo Liu, Markus Eckstein, Zhixiang Wang, Friedrich Feuerhake, Dorit Merhof)</author>
      <guid isPermaLink="false">2506.08854v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>On Finetuning Tabular Foundation Models</title>
      <link>http://arxiv.org/abs/2506.08982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了表格深度学习中的基础模型，特别是TabPFNv2在小型数据集上的性能，并探讨了其微调策略和内部机制的变化。&lt;h4&gt;背景&lt;/h4&gt;TabPFNv2使用上下文学习范式在小型数据集上表现优于传统的GBDT方法，但其最佳微调方法和内部机制的改变尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;评估不同的微调策略，并研究微调如何改变TabPFNv2的内部机制。&lt;h4&gt;方法&lt;/h4&gt;对各种数据集进行系统评估，并使用类比检索增强模型的方法来研究微调的影响。&lt;h4&gt;主要发现&lt;/h4&gt;全微调在时间效率和效果方面是TabPFNv2的最实用解决方案。微调通过改进查询表示和关键表示的点积，使得TabPFNv2能够更好地近似目标依赖关系。&lt;h4&gt;结论&lt;/h4&gt;在大型数据集上微调TabPFNv2能够观察到几乎所有任务上的性能提升，特别是在具有I.I.D.拆分的学术数据集上，TabPFNv2可以达到最先进的结果，但在具有时间推移和丰富特征集的数据集上，TabPFNv2的稳定性较差，传统方法仍然更优。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates foundation models in tabular deep learning, particularly the performance of TabPFNv2 on small-scale datasets, and explores its fine-tuning strategy and changes in internal mechanisms.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are an emerging research direction in tabular deeplearning. Notably, TabPFNv2 recently claimed superior performance overtraditional GBDT-based methods on small-scale datasets using an in-contextlearning paradigm, which does not adapt model parameters to target datasets.However, the optimal finetuning approach for adapting tabular foundationalmodels, and how this adaptation reshapes their internal mechanisms, remainsunderexplored. While prior works studied finetuning for earlier foundationalmodels, inconsistent findings and TabPFNv2's unique architecture necessitatefresh investigation. To address these questions, we first systematicallyevaluate various finetuning strategies on diverse datasets. Our findingsestablish full finetuning as the most practical solution for TabPFNv2 in termsof time-efficiency and effectiveness. We then investigate how finetuning altersTabPFNv2's inner mechanisms, drawing an analogy to retrieval-augmented models.We reveal that the success of finetuning stems from the fact that aftergradient-based adaptation, the dot products of the query-representations oftest objects and the key-representations of in-context training objects moreaccurately reflect their target similarity. This improved similarity allowsfinetuned TabPFNv2 to better approximate target dependency by appropriatelyweighting relevant in-context samples, improving the retrieval-based predictionlogic. From the practical perspective, we managed to finetune TabPFNv2 ondatasets with up to 50K objects, observing performance improvements on almostall tasks. More precisely, on academic datasets with I.I.D. splits, finetuningallows TabPFNv2 to achieve state-of-the-art results, while on datasets withgradual temporal shifts and rich feature sets, TabPFNv2 is less stable andprior methods remain better.</description>
      <author>example@mail.com (Ivan Rubachev, Akim Kotelnikov, Nikolay Kartashev)</author>
      <guid isPermaLink="false">2506.08982v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>MLVTG: Mamba-Based Feature Alignment and LLM-Driven Purification for Multi-Modal Video Temporal Grounding</title>
      <link>http://arxiv.org/abs/2506.08512v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MLVTG的新型框架，用于解决视频理解中的视频时间定位问题，通过实验验证了其在多个数据集上优于现有方法的表现。&lt;h4&gt;背景&lt;/h4&gt;视频时间定位（VTG）是视频理解中的一个基本且具有挑战性的任务。现有的基于Transformer的方法往往存在冗余注意力和次优的多模态对齐问题。&lt;h4&gt;目的&lt;/h4&gt;提出MLVTG框架，旨在解决现有Transformer方法中存在的问题，实现更精确的视频时间定位。&lt;h4&gt;方法&lt;/h4&gt;MLVTG框架集成了两个关键模块：MambaAligner和LLMRefiner。MambaAligner使用堆叠的Vision Mamba块作为骨干网络，以建模时间依赖性并提取鲁棒的视频表示。LLMRefiner利用预训练的大型语言模型（LLM）的冻结层来隐式地传递语义先验，增强多模态对齐而不需要微调。&lt;h4&gt;主要发现&lt;/h4&gt;MLVTG通过结构化状态空间动力学进行时间建模，通过文本先验进行语义净化，实现了更精确的定位。在QVHighlights、Charades-STA和TVSum数据集上的实验表明，MLVTG达到了最先进的性能，并显著优于现有基线。&lt;h4&gt;结论&lt;/h4&gt;MLVTG框架在视频时间定位任务上表现出色，为视频理解领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Temporal Grounding (VTG), which aims to localize video clipscorresponding to natural language queries, is a fundamental yet challengingtask in video understanding. Existing Transformer-based methods often sufferfrom redundant attention and suboptimal multi-modal alignment. To address theselimitations, we propose MLVTG, a novel framework that integrates two keymodules: MambaAligner and LLMRefiner. MambaAligner uses stacked Vision Mambablocks as a backbone instead of Transformers to model temporal dependencies andextract robust video representations for multi-modal alignment. LLMRefinerleverages the specific frozen layer of a pre-trained Large Language Model (LLM)to implicitly transfer semantic priors, enhancing multi-modal alignment withoutfine-tuning. This dual alignment strategy, temporal modeling via structuredstate-space dynamics and semantic purification via textual priors, enables moreprecise localization. Extensive experiments on QVHighlights, Charades-STA, andTVSum demonstrate that MLVTG achieves state-of-the-art performance andsignificantly outperforms existing baselines.</description>
      <author>example@mail.com (Zhiyi Zhu, Xiaoyu Wu, Zihao Liu, Linlin Yang)</author>
      <guid isPermaLink="false">2506.08512v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>SurfR: Surface Reconstruction with Multi-scale Attention</title>
      <link>http://arxiv.org/abs/2506.08635v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in 3DV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种快速且准确的无序点云表面重建算法，采用隐式表示。&lt;h4&gt;背景&lt;/h4&gt;现有学习方法要么是针对单个对象的表示，使用小型神经网络模型，允许高表面细节，但需要针对每个对象进行训练；要么是通用表示，需要更大的模型，能够泛化到新的形状，但缺乏细节，推理速度慢。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的隐式表示方法，用于通用3D形状，其在最佳分辨率下比所有基线算法都要快，与最先进技术的性能损失微乎其微。&lt;h4&gt;方法&lt;/h4&gt;通过三个关键贡献实现了最佳精度-速度权衡。首先，为了加快重建速度，展示在早期阶段无需使用查询点进行特征提取（懒查询）。其次，使用并行多尺度网格表示，以开发对不同噪声水平和输入分辨率的鲁棒特征。最后，证明跨尺度的注意力可以提供改进的重建结果。&lt;h4&gt;主要发现&lt;/h4&gt;提出的算法在精度和速度方面取得了最佳平衡，通过懒查询、多尺度网格表示和跨尺度注意力等技术，实现了快速且准确的表面重建。&lt;h4&gt;结论&lt;/h4&gt;该方法在重建无序点云表面方面表现优异，为点云处理领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种针对无序点云的快速且准确的表面重建算法，采用隐式表示。近期学习方法要么是单对象表示，使用小型神经网络模型，允许高表面细节，但需要针对每个对象进行训练，要么是通用表示，需要更大的模型，能够泛化到新的形状，但缺乏细节，推理速度慢。我们提出了一种新的隐式表示方法，用于通用3D形状，其在最佳分辨率下比所有基线算法都要快，与最先进技术的性能损失微乎其微。我们通过三个关键贡献实现了最佳精度-速度权衡。首先，为了加快重建速度，展示在早期阶段无需使用查询点进行特征提取（懒查询）。其次，使用并行多尺度网格表示，以开发对不同噪声水平和输入分辨率的鲁棒特征。最后，证明跨尺度的注意力可以提供改进的重建结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a fast and accurate surface reconstruction algorithm forunorganized point clouds using an implicit representation. Recent learningmethods are either single-object representations with small neural models thatallow for high surface details but require per-object training or generalizedrepresentations that require larger models and generalize to newer shapes butlack details, and inference is slow. We propose a new implicit representationfor general 3D shapes that is faster than all the baselines at their optimumresolution, with only a marginal loss in performance compared to thestate-of-the-art. We achieve the best accuracy-speed trade-off using three keycontributions. Many implicit methods extract features from the point cloud toclassify whether a query point is inside or outside the object. First, to speedup the reconstruction, we show that this feature extraction does not need touse the query point at an early stage (lazy query). Second, we use a parallelmulti-scale grid representation to develop robust features for different noiselevels and input resolutions. Finally, we show that attention across scales canprovide improved reconstruction results.</description>
      <author>example@mail.com (Siddhant Ranade, Gonçalo Dias Pais, Ross Tyler Whitaker, Jacinto C. Nascimento, Pedro Miraldo, Srikumar Ramalingam)</author>
      <guid isPermaLink="false">2506.08635v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Bridging RDF Knowledge Graphs with Graph Neural Networks for Semantically-Rich Recommender Systems</title>
      <link>http://arxiv.org/abs/2506.08743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at DASFAA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将RDF知识图谱与图神经网络（GNNs）综合的方法，以充分利用RDF知识图谱的语义信息，并评估了不同GNN在推荐任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管根据W3C标准RDF创建了超过一千个知识图谱，但它们的丰富语义信息在基于GNN的推荐系统中尚未得到充分利用。&lt;h4&gt;目的&lt;/h4&gt;提出一种综合方法，将RDF知识图谱与GNNs结合，以利用RDF对象属性中的拓扑信息和RDF数据类型属性中的内容信息。&lt;h4&gt;方法&lt;/h4&gt;深入评估了各种GNN，分析了不同的语义特征初始化和图结构异质性对推荐任务性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;通过在涉及数百万节点RDF图的多场景推荐实验中，证明了利用RDF知识图谱的语义丰富性可以显著提高推荐系统。&lt;h4&gt;结论&lt;/h4&gt;为基于GNN的推荐系统在Linked Open Data云上奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have substantially advanced the field of recommender systems. However, despite the creation of more than a thousand knowledge graphs (KGs) under the W3C standard RDF, their rich semantic information has not yet been fully leveraged in GNN-based recommender systems. To address this gap, we propose a comprehensive integration of RDF KGs with GNNs that utilizes both the topological information from RDF object properties and the content information from RDF datatype properties. Our main focus is an in-depth evaluation of various GNNs, analyzing how different semantic feature initializations and types of graph structure heterogeneity influence their performance in recommendation tasks. Through experiments across multiple recommendation scenarios involving multi-million-node RDF graphs, we demonstrate that harnessing the semantic richness of RDF KGs significantly improves recommender systems and lays the groundwork for GNN-based recommenders systems for the Linked Open Data cloud. The code and data are available on our GitHub repository: https://github.com/davidlamprecht/rdf-gnn-recommendation&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have substantially advanced the field ofrecommender systems. However, despite the creation of more than a thousandknowledge graphs (KGs) under the W3C standard RDF, their rich semanticinformation has not yet been fully leveraged in GNN-based recommender systems.To address this gap, we propose a comprehensive integration of RDF KGs withGNNs that utilizes both the topological information from RDF object propertiesand the content information from RDF datatype properties. Our main focus is anin-depth evaluation of various GNNs, analyzing how different semantic featureinitializations and types of graph structure heterogeneity influence theirperformance in recommendation tasks. Through experiments across multiplerecommendation scenarios involving multi-million-node RDF graphs, wedemonstrate that harnessing the semantic richness of RDF KGs significantlyimproves recommender systems and lays the groundwork for GNN-based recommendersystems for the Linked Open Data cloud. The code and data are available on ourGitHub repository: https://github.com/davidlamprecht/rdf-gnn-recommendation</description>
      <author>example@mail.com (Michael Färber, David Lamprecht, Yuni Susanti)</author>
      <guid isPermaLink="false">2506.08743v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Context-aware TFL: A Universal Context-aware Contrastive Learning Framework for Temporal Forgery Localization</title>
      <link>http://arxiv.org/abs/2506.08493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个名为UniCaCLF的通用上下文感知对比学习框架，用于视频伪造定位，并在五个公共数据集上取得了优于现有算法的性能。&lt;h4&gt;背景&lt;/h4&gt;目前多媒体取证领域的研究主要集中于检测伪造的音频-视频内容，并取得了显著成就。然而，这些工作只将深度伪造检测视为分类任务，忽略了视频部分片段被篡改的情况。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种用于视频伪造定位的通用上下文感知对比学习框架UniCaCLF。&lt;h4&gt;方法&lt;/h4&gt;该方法利用监督对比学习通过异常检测来发现和识别伪造瞬间，实现时间伪造片段的精确定位。此外，还提出了一种新颖的上下文感知感知层，利用异构激活操作和自适应上下文更新器构建上下文感知对比目标，通过对比伪造瞬间与真实瞬间的特征距离全局上下文来增强伪造瞬间特征的判别性。还引入了一种高效的上下文感知对比编码，以监督样本的方式进一步推动真实和伪造瞬间特征的可区分性，抑制跨样本影响，提高时间伪造定位性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的UniCaCLF在五个公共数据集上显著优于现有的竞争算法。&lt;h4&gt;结论&lt;/h4&gt;UniCaCLF是一种有效的视频伪造定位方法，能够提高时间伪造定位的性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a universal context-aware contrastive learning framework called UniCaCLF for video forgery localization, which has demonstrated superior performance over existing algorithms on five public datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most research efforts in the multimedia forensics domain have focused ondetecting forgery audio-visual content and reached sound achievements. However,these works only consider deepfake detection as a classification task andignore the case where partial segments of the video are tampered with. Temporalforgery localization (TFL) of small fake audio-visual clips embedded in realvideos is still challenging and more in line with realistic applicationscenarios. To resolve this issue, we propose a universal context-awarecontrastive learning framework (UniCaCLF) for TFL. Our approach leveragessupervised contrastive learning to discover and identify forged instants bymeans of anomaly detection, allowing for the precise localization of temporalforged segments. To this end, we propose a novel context-aware perception layerthat utilizes a heterogeneous activation operation and an adaptive contextupdater to construct a context-aware contrastive objective, which enhances thediscriminability of forged instant features by contrasting them with genuineinstant features in terms of their distances to the global context. Anefficient context-aware contrastive coding is introduced to further push thelimit of instant feature distinguishability between genuine and forged instantsin a supervised sample-by-sample manner, suppressing the cross-sample influenceto improve temporal forgery localization performance. Extensive experimentalresults over five public datasets demonstrate that our proposed UniCaCLFsignificantly outperforms the state-of-the-art competing algorithms.</description>
      <author>example@mail.com (Qilin Yin, Wei Lu, Xiangyang Luo, Xiaochun Cao)</author>
      <guid isPermaLink="false">2506.08493v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Robust Visual Localization via Semantic-Guided Multi-Scale Transformer</title>
      <link>http://arxiv.org/abs/2506.08526v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合多尺度特征学习和语义场景理解的视觉定位框架，以应对动态环境中的挑战。&lt;h4&gt;背景&lt;/h4&gt;在动态环境中，如光照变化、恶劣天气和移动物体等，视觉定位仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，提出了一个框架，该框架结合多尺度特征学习和语义场景理解。&lt;h4&gt;方法&lt;/h4&gt;该方法使用具有跨尺度注意力的分层Transformer，融合几何细节和上下文线索，同时保持空间精度并适应环境变化。通过神经场景表示进行语义监督，引导网络学习视图不变的特征，编码持久性结构信息，同时抑制复杂的环境干扰。&lt;h4&gt;主要发现&lt;/h4&gt;在TartanAir上的实验表明，该方法在具有动态物体、光照变化和遮挡的挑战场景中优于现有的姿态回归方法。&lt;h4&gt;结论&lt;/h4&gt;将多尺度处理与语义引导相结合，为现实世界动态环境中的鲁棒视觉定位提供了一种有前景的策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual localization remains challenging in dynamic environments wherefluctuating lighting, adverse weather, and moving objects disrupt appearancecues. Despite advances in feature representation, current absolute poseregression methods struggle to maintain consistency under varying conditions.To address this challenge, we propose a framework that synergistically combinesmulti-scale feature learning with semantic scene understanding. Our approachemploys a hierarchical Transformer with cross-scale attention to fuse geometricdetails and contextual cues, preserving spatial precision while adapting toenvironmental changes. We improve the performance of this architecture withsemantic supervision via neural scene representation during training, guidingthe network to learn view-invariant features that encode persistent structuralinformation while suppressing complex environmental interference. Experimentson TartanAir demonstrate that our approach outperforms existing pose regressionmethods in challenging scenarios with dynamic objects, illumination changes,and occlusions. Our findings show that integrating multi-scale processing withsemantic guidance offers a promising strategy for robust visual localization inreal-world dynamic environments.</description>
      <author>example@mail.com (Zhongtao Tian, Wenhao Huang, Zhidong Chen, Xiao Wei Sun)</author>
      <guid isPermaLink="false">2506.08526v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Urban Incident Prediction with Graph Neural Networks: Integrating Government Ratings and Crowdsourced Reports</title>
      <link>http://arxiv.org/abs/2506.08740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的多视角、多输出模型，用于预测城市事件的真实状态，并分析了纽约市城市事件的数据集。&lt;h4&gt;背景&lt;/h4&gt;GNN在预测城市基础设施问题等方面被广泛应用。政府官员希望了解哪些社区发生了如路面坑洼或鼠害等问题。政府通过检查评分来观察每个社区的事件真实状态，但这些评分只针对少数社区和事件类型。同时，通过众包报告也可以观察到事件状态，但这些报告可能因不同的报告行为而存在偏差。&lt;h4&gt;目的&lt;/h4&gt;提出一种模型，使用无偏差的评分数据和有偏差的报告数据来预测事件的真实潜在状态。&lt;h4&gt;方法&lt;/h4&gt;设计了一个基于GNN的多视角、多输出模型，并收集、标准化了纽约市3年内的9,615,863条众包报告和1,041,415条政府检查评分数据，涵盖139种事件类型。&lt;h4&gt;主要发现&lt;/h4&gt;模型在真实和半合成数据上表现优于仅使用报告数据或仅使用评分数据的模型，尤其是在评分数据稀疏且报告可预测评分的情况下。此外，还量化了众包报告中的人口统计偏差，例如高收入社区的报告问题率更高。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法对于使用异构、稀疏和有偏差的数据进行潜在状态预测具有广泛的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNNs) are widely used in urban spatiotemporal forecasting, such as predicting infrastructure problems. In this setting, government officials wish to know in which neighborhoods incidents like potholes or rodent issues occur. The true state of incidents (e.g., street conditions) for each neighborhood is observed via government inspection ratings. However, these ratings are only conducted for a sparse set of neighborhoods and incident types. We also observe the state of incidents via crowdsourced reports, which are more densely observed but may be biased due to heterogeneous reporting behavior. First, for such settings, we propose a multiview, multioutput GNN-based model that uses both unbiased rating data and biased reporting data to predict the true latent state of incidents. Second, we investigate a case study of New York City urban incidents and collect, standardize, and make publicly available a dataset of 9,615,863 crowdsourced reports and 1,041,415 government inspection ratings over 3 years and across 139 types of incidents. Finally, we show on both real and semi-synthetic data that our model can better predict the latent state compared to models that use only reporting data or models that use only rating data, especially when rating data is sparse and reports are predictive of ratings. We also quantify demographic biases in crowdsourced reporting, e.g., higher-income neighborhoods report problems at higher rates. Our analysis showcases a widely applicable approach for latent state prediction using heterogeneous, sparse, and biased data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are widely used in urban spatiotemporalforecasting, such as predicting infrastructure problems. In this setting,government officials wish to know in which neighborhoods incidents likepotholes or rodent issues occur. The true state of incidents (e.g., streetconditions) for each neighborhood is observed via government inspectionratings. However, these ratings are only conducted for a sparse set ofneighborhoods and incident types. We also observe the state of incidents viacrowdsourced reports, which are more densely observed but may be biased due toheterogeneous reporting behavior. First, for such settings, we propose amultiview, multioutput GNN-based model that uses both unbiased rating data andbiased reporting data to predict the true latent state of incidents. Second, weinvestigate a case study of New York City urban incidents and collect,standardize, and make publicly available a dataset of 9,615,863 crowdsourcedreports and 1,041,415 government inspection ratings over 3 years and across 139types of incidents. Finally, we show on both real and semi-synthetic data thatour model can better predict the latent state compared to models that use onlyreporting data or models that use only rating data, especially when rating datais sparse and reports are predictive of ratings. We also quantify demographicbiases in crowdsourced reporting, e.g., higher-income neighborhoods reportproblems at higher rates. Our analysis showcases a widely applicable approachfor latent state prediction using heterogeneous, sparse, and biased data.</description>
      <author>example@mail.com (Sidhika Balachandar, Shuvom Sadhuka, Bonnie Berger, Emma Pierson, Nikhil Garg)</author>
      <guid isPermaLink="false">2506.08740v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Zero-Shot Framework for Deepfake Hate Speech Detection in Low-Resource Languages</title>
      <link>http://arxiv.org/abs/2506.08372v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in Interpseech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种用于检测深度伪造音频中仇恨言论的新型多模态框架，即使在零样本情况下也表现出色。&lt;h4&gt;背景&lt;/h4&gt;传统的仇恨言论检测方法在深度伪造音频中效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效检测深度伪造音频中仇恨言论的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法采用对比学习，联合对跨语言的音频和文本表示进行对齐。构建了包含127,290对文本和合成语音样本的基准数据集，涵盖英语和五种印度低资源语言（印地语、孟加拉语、马拉地语、泰米尔语、泰卢固语）。模型学习共享语义嵌入空间，实现鲁棒的跨语言和跨模态分类。&lt;h4&gt;主要发现&lt;/h4&gt;在两个多语言测试集上的实验表明，该方法优于基线，准确率达到0.819和0.701，并且能够很好地推广到未见过的语言。这证明了在低资源设置中，结合模态进行仇恨言论检测的优势，尤其是在单模态模型失效的情况下。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在合成媒体中检测仇恨言论方面具有优势，特别是在低资源环境中。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a novel multimodal framework for hate speech detection in deepfake audio, excelling even in zero-shot scenarios. Unlike previous approaches, our method uses contrastive learning to jointly align audio and text representations across languages. We present the first benchmark dataset with 127,290 paired text and synthesized speech samples in six languages: English and five low-resource Indian languages (Hindi, Bengali, Marathi, Tamil, Telugu). Our model learns a shared semantic embedding space, enabling robust cross-lingual and cross-modal classification. Experiments on two multilingual test sets show our approach outperforms baselines, achieving accuracies of 0.819 and 0.701, and generalizes well to unseen languages. This demonstrates the advantage of combining modalities for hate speech detection in synthetic media, especially in low-resource settings where unimodal models falter. The Dataset is available at https://www.iab-rubric.org/resources.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a novel multimodal framework for hate speech detectionin deepfake audio, excelling even in zero-shot scenarios. Unlike previousapproaches, our method uses contrastive learning to jointly align audio andtext representations across languages. We present the first benchmark datasetwith 127,290 paired text and synthesized speech samples in six languages:English and five low-resource Indian languages (Hindi, Bengali, Marathi, Tamil,Telugu). Our model learns a shared semantic embedding space, enabling robustcross-lingual and cross-modal classification. Experiments on two multilingualtest sets show our approach outperforms baselines, achieving accuracies of0.819 and 0.701, and generalizes well to unseen languages. This demonstratesthe advantage of combining modalities for hate speech detection in syntheticmedia, especially in low-resource settings where unimodal models falter. TheDataset is available at https://www.iab-rubric.org/resources.</description>
      <author>example@mail.com (Rishabh Ranjan, Likhith Ayinala, Mayank Vatsa, Richa Singh)</author>
      <guid isPermaLink="false">2506.08372v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>GIQ: Benchmarking 3D Geometric Reasoning of Vision Foundation Models with Simulated and Real Polyhedra</title>
      <link>http://arxiv.org/abs/2506.08194v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GIQ，一个专门用于评估视觉和视觉-语言基础模型几何推理能力的全面基准。&lt;h4&gt;背景&lt;/h4&gt;虽然单目3D重建方法和视觉-语言模型在标准基准上表现出色，但它们对几何特性的真正理解仍然不清楚。&lt;h4&gt;目的&lt;/h4&gt;GIQ旨在提供一个平台，以评估和解决当前模型在几何智能方面的关键差距。&lt;h4&gt;方法&lt;/h4&gt;GIQ包括合成和真实世界的224个不同多面体的图像，通过单目3D重建、3D对称性检测、心理旋转测试和零样本形状分类任务进行系统性实验。&lt;h4&gt;主要发现&lt;/h4&gt;实验揭示了当前模型在重建基本几何形状、检测3D对称性和心理旋转等任务中的显著不足。&lt;h4&gt;结论&lt;/h4&gt;GIQ公开可用，为突出和解决几何智能的关键差距提供了一个结构化的平台，有助于未来在鲁棒、几何感知的表示学习方面的进步。&lt;h4&gt;翻译&lt;/h4&gt;The abstract discusses the introduction of GIQ, a comprehensive benchmark designed to evaluate the geometric reasoning capabilities of vision and vision-language foundation models. The background states that although impressive results have been achieved on standard benchmarks, the true understanding of geometric properties remains unclear. The purpose of GIQ is to provide a platform for assessing and addressing critical gaps in geometric intelligence. The methods involve systematic experiments with synthetic and real-world images of diverse polyhedra, including various levels of complexity and symmetry, and tasks like monocular 3D reconstruction, 3D symmetry detection, mental rotation tests, and zero-shot shape classification. The main findings reveal significant shortcomings in current models, including struggles in reconstructing basic geometric forms and detecting 3D symmetries, as well as low accuracy in complex polyhedra. The conclusion is that GIQ is publicly available and aims to highlight and address critical gaps in geometric intelligence, facilitating future progress in robust, geometry-aware representation learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular 3D reconstruction methods and vision-language models (VLMs)demonstrate impressive results on standard benchmarks, yet their trueunderstanding of geometric properties remains unclear. We introduce GIQ , acomprehensive benchmark specifically designed to evaluate the geometricreasoning capabilities of vision and vision-language foundation models. GIQcomprises synthetic and real-world images of 224 diverse polyhedra - includingPlatonic, Archimedean, Johnson, and Catalan solids, as well as stellations andcompound shapes - covering varying levels of complexity and symmetry. Throughsystematic experiments involving monocular 3D reconstruction, 3D symmetrydetection, mental rotation tests, and zero-shot shape classification tasks, wereveal significant shortcomings in current models. State-of-the-artreconstruction algorithms trained on extensive 3D datasets struggle toreconstruct even basic geometric forms accurately. While foundation modelseffectively detect specific 3D symmetry elements via linear probing, theyfalter significantly in tasks requiring detailed geometric differentiation,such as mental rotation. Moreover, advanced vision-language assistants exhibitremarkably low accuracy on complex polyhedra, systematically misinterpretingbasic properties like face geometry, convexity, and compound structures. GIQ ispublicly available, providing a structured platform to highlight and addresscritical gaps in geometric intelligence, facilitating future progress inrobust, geometry-aware representation learning.</description>
      <author>example@mail.com (Mateusz Michalkiewicz, Anekha Sokhal, Tadeusz Michalkiewicz, Piotr Pawlikowski, Mahsa Baktashmotlagh, Varun Jampani, Guha Balakrishnan)</author>
      <guid isPermaLink="false">2506.08194v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>SSS: Semi-Supervised SAM-2 with Efficient Prompting for Medical Imaging Segmentation</title>
      <link>http://arxiv.org/abs/2506.08949v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SSS（Semi-Supervised SAM-2）的半监督学习方法，用于医学图像分割，通过利用SAM-2的特征提取能力来提高医学图像分割的性能。&lt;h4&gt;背景&lt;/h4&gt;在信息爆炸的时代，如何有效地利用大规模未标记数据，同时减少对高质量像素级标注的依赖，是医学图像领域的一个关键挑战。&lt;h4&gt;目的&lt;/h4&gt;通过半监督学习（SSL）增强未标记数据的使用，提高完全监督模型的性能，并成为医学图像分析中一个非常有前景的研究方向。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法基于单流“弱到强”一致性正则化框架，引入了判别特征增强（DFE）机制，以进一步探索由多种数据增强策略在多个视角中引入的特征差异。此外，开发了一个提示生成器，该生成器集成了物理约束与滑动窗口（PCSW）机制，为未标记数据生成输入提示。&lt;h4&gt;主要发现&lt;/h4&gt;在ACDC和BHSD两个多标签数据集上进行了广泛的实验，结果表明所提出的方法在半监督医学图像分割方面优于现有方法，SSS在BHSD上的平均Dice分数为53.15，比之前的最先进方法高出+3.65 Dice。&lt;h4&gt;结论&lt;/h4&gt;SSS方法在医学图像分割方面具有优越性，并有望在医学图像分析中得到广泛应用。&lt;h4&gt;翻译&lt;/h4&gt;在信息爆炸的时代，有效地利用大规模未标记数据的同时，减少对高质量像素级标注的依赖，在医学图像领域仍然是一个关键挑战。半监督学习（SSL）通过促进知识迁移，显著提高了完全监督模型的性能，并成为医学图像分析中的一个非常有前景的研究方向。受视觉基础模型（例如SAM-2）提供丰富先验知识能力的影响，本文提出了一种名为SSS（Semi-Supervised SAM-2）的新方法，该方法利用SAM-2的鲁棒特征提取能力来揭示未标记医学图像中的潜在知识，从而有效地增强完全监督医学图像分割的特征支持。具体而言，本文在单流“弱到强”一致性正则化框架的基础上，引入了一种判别特征增强（DFE）机制，以进一步探索由多种数据增强策略在多个视角中引入的特征差异。通过利用多尺度增强技术中的特征相似性和差异性，该方法重建并建模特征，从而有效地优化了显著区域。此外，开发了一个提示生成器，该生成器集成了物理约束与滑动窗口（PCSW）机制，为未标记数据生成输入提示，以满足SAM-2对额外提示的需求。广泛的实验表明，所提出的方法在两个多标签数据集（即ACDC和BHSD）上的半监督医学图像分割方面优于现有方法。值得注意的是，SSS在BHSD上的平均Dice分数为53.15，比之前的最先进方法高出+3.65 Dice。代码可在https://github.com/AIGeeksGroup/SSS上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of information explosion, efficiently leveraging large-scaleunlabeled data while minimizing the reliance on high-quality pixel-levelannotations remains a critical challenge in the field of medical imaging.Semi-supervised learning (SSL) enhances the utilization of unlabeled data byfacilitating knowledge transfer, significantly improving the performance offully supervised models and emerging as a highly promising research directionin medical image analysis. Inspired by the ability of Vision Foundation Models(e.g., SAM-2) to provide rich prior knowledge, we propose SSS (Semi-SupervisedSAM-2), a novel approach that leverages SAM-2's robust feature extractioncapabilities to uncover latent knowledge in unlabeled medical images, thuseffectively enhancing feature support for fully supervised medical imagesegmentation. Specifically, building upon the single-stream "weak-to-strong"consistency regularization framework, this paper introduces a DiscriminativeFeature Enhancement (DFE) mechanism to further explore the featurediscrepancies introduced by various data augmentation strategies acrossmultiple views. By leveraging feature similarity and dissimilarity acrossmulti-scale augmentation techniques, the method reconstructs and models thefeatures, thereby effectively optimizing the salient regions. Furthermore, aprompt generator is developed that integrates Physical Constraints with aSliding Window (PCSW) mechanism to generate input prompts for unlabeled data,fulfilling SAM-2's requirement for additional prompts. Extensive experimentsdemonstrate the superiority of the proposed method for semi-supervised medicalimage segmentation on two multi-label datasets, i.e., ACDC and BHSD. Notably,SSS achieves an average Dice score of 53.15 on BHSD, surpassing the previousstate-of-the-art method by +3.65 Dice. Code will be available athttps://github.com/AIGeeksGroup/SSS.</description>
      <author>example@mail.com (Hongjie Zhu, Xiwei Liu, Rundong Xue, Zeyu Zhang, Yong Xu, Daji Ergu, Ying Cai, Yang Zhao)</author>
      <guid isPermaLink="false">2506.08949v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>The connection between galaxy mergers, star formation and AGN activity in the HSC-SSP</title>
      <link>http://arxiv.org/abs/2506.08469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 12 figures, accepted to ApJ&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了星系合并引发的内部气体流入对星形成率、超大质量黑洞增长和活动星系核（AGN）的影响，通过新的方法对星系分类和属性进行测量。&lt;h4&gt;背景&lt;/h4&gt;内部气体流入被认为是通过星系合并增强星形成率、促进超大质量黑洞增长和刺激活动星系核。然而，由于合并分类和星系及AGN属性量化的困难，这些现象的量化仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;定量研究合并-星形成率-AGN之间的联系，并使用新的方法对星系进行分类和属性测量。&lt;h4&gt;方法&lt;/h4&gt;通过微调预训练的深度表示学习模型Zoobot，利用来自Galaxy Cruise项目的图像和标签在HSC-SSP观测图像中识别合并。使用ProSpect代码拟合GAMA光谱来获取星系和AGN属性，该代码在远紫外到远红外波段的泛色光范围内进行拟合。&lt;h4&gt;主要发现&lt;/h4&gt;在合并和对照组之间，星形成率（SFR）和AGN活动的差异很小。经过进一步可视化纯化合并样本后，发现对星系和后合并星系的影响更大，这些发现表明，长期过程是星形成和AGN活动的重要驱动因素。&lt;h4&gt;结论&lt;/h4&gt;本文的结果对使用长期时间尺度探针提出了一个警示。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由星系合并驱动的内部气体流入被认为可以增强星形成率（SFR），促进超大质量黑洞的增长并刺激活动星系核（AGN）。然而，由于在分类合并和量化星系和AGN属性方面存在困难，这些现象的量化仍然是一个挑战。我们使用Hyper Suprime-Cam Subaru战略计划（HSC-SSP）的星系，通过新的方法对星系分类和属性进行测量，定量检验合并-SFR-AGN联系。在HSC-SSP观测图像中，通过微调预训练的深度表示学习模型Zoobot，利用基于Galaxy Cruise项目的图像和标签识别合并。我们使用ProSpect代码拟合GAMA光谱生成的星系和AGN属性，该代码在泛色光范围内从远紫外到远红外波段进行拟合。在合并和对照组之间，SFR和AGN活动的差异很小，经过进一步可视化纯化合并样本后，发现对星系和后合并星系的影响更大。这些发现表明，长期过程是星形成和AGN活动的重要驱动因素，对使用长期时间尺度探针提出了一个警示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Internal gas inflows driven by galaxy mergers are considered to enhance starformation rates (SFR), fuel supermassive black hole growth and stimulate activegalactic nuclei (AGN). However, quantifying these phenomena remains achallenge, due to difficulties both in classifying mergers and in quantifyinggalaxy and AGN properties. We quantitatively examine the merger-SFR-AGNconnection using Hyper Suprime-Cam Subaru Strategic Program (HSC-SSP) galaxiesusing novel methods for both galaxy classification and property measurements.}{Mergers in HSC-SSP observational images are identified through fine-tuningZoobot, a pretrained deep representation learning model, using images andlabels based on the Galaxy Cruise project. We use galaxy and AGN propertiesthat were produced by fitting Galaxy and Mass Assembly (GAMA) spectra using theSED fitting code ProSpect, which fits panchromatically across the far-UVthrough far-infrared wavelengths and obtains galaxy and AGN propertiessimultaneously.} \textbf{{Little differences are seen in SFR and AGN activitybetween mergers and controls, with $\Delta \mathrm{SFR}=-0.009\pm 0.003$ dex,$\Delta f_{\mathrm{AGN}}=-0.010\pm0.033$ dex and $\DeltaL_{\mathrm{AGN}}=0.002\pm0.025$ dex. After further visual purification of themerger sample, we find $\Delta \mathrm{SFR}=-0.033\pm0.014$ dex, $\Deltaf_{\mathrm{AGN}}=-0.024\pm0.170$ dex, and $\DeltaL_{\mathrm{AGN}}=0.019\pm0.129$ dex for pairs, and $\Delta\mathrm{SFR}=-0.057\pm0.024$ dex, $\Delta f_{\mathrm{AGN}}=0.286\pm0.270$ dex,and $\Delta L_{\mathrm{AGN}}=0.329\pm0.195$ dex for postmergers. These numberssuggest secular processes being an important driver for SF and AGN activity,and present a cautionary tale when using longer timescale tracers.</description>
      <author>example@mail.com (Kiyoaki Christopher Omori, Connor Bottrell, Sabine Bellstedt, Aaron Robotham, Hassen M. Yesuf, Andy D. Goulding, Marcin Sawicki, Tohru Nagao, Tsutomu T. Takeuchi)</author>
      <guid isPermaLink="false">2506.08469v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Large Deviations for Markovian Graphon Processes and Associated Dynamical Systems on Networks</title>
      <link>http://arxiv.org/abs/2506.08333v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  55 pages, no figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究快速变化的马尔可夫网络的时态模型，这些模型由随时间演化的空间相关核调制，这些核定义了边形成和消解的速率。在考虑的区域内，图论值过程的窗口平均值在适当的时间间隔内是系统的自然状态描述符。在适当的跳率核条件下，我们为平均过适当时间窗口的图论过程建立了大数定律和大型偏差原理（LDP），既在弱拓扑下，也在相关图论空间中的割范数下。尽管问题设置和分析比已研究的静态随机网络模型更为复杂，但与速率函数相关的变分问题具有显式解，从而为速率函数提供了一种同样易于处理的、不同的表达式，类似于静态情况。利用这些结果，我们进一步为受底层演化的网络驱动的节点值动态系统建立了LDP。&lt;h4&gt;背景&lt;/h4&gt;本文研究的是快速变化的马尔可夫网络的时态模型，以及由时间演化的空间相关核调制形成的模型。&lt;h4&gt;目的&lt;/h4&gt;本文旨在建立快速变化马尔可夫网络时态模型的大数定律和大型偏差原理。&lt;h4&gt;方法&lt;/h4&gt;本文采用了一种基于窗口平均值的方法来描述系统的状态，并利用适当的条件建立了大数定律和大型偏差原理。&lt;h4&gt;主要发现&lt;/h4&gt;本文在适当条件下为图论过程建立了大数定律和大型偏差原理，并发现与速率函数相关的变分问题具有显式解。&lt;h4&gt;结论&lt;/h4&gt;本文为受底层演化的网络驱动的节点值动态系统建立了大型偏差原理。&lt;h4&gt;翻译&lt;/h4&gt;我们考虑由随时间演化的空间相关核调节的快速变化马尔可夫网络的时态模型，这些核定义了边形成和消解的速率。或者，这些也可以看作是在长时间范围内具有 $O(1)$ 跳转速率的马尔可夫网络。在考虑的区域内，图论值过程在适当时间间隔内的窗口平均值是系统的自然状态描述符。在跳转率核的适当条件下，我们为平均过适当时间窗口的图论过程建立了大数定律和大型偏差原理（LDP），既在弱拓扑下，也在相关图论空间中的割范数下。尽管问题设置和分析比已研究的静态随机网络模型更为复杂，但与速率函数相关的变分问题具有显式解，从而为速率函数提供了一种同样易于处理的、不同的表达式，类似于静态情况。利用这些结果，我们然后为受底层演化的网络驱动的节点值动态系统建立了LDP。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider temporal models of rapidly changing Markovian networks modulatedby time-evolving spatially dependent kernels that define rates for edgeformation and dissolution. Alternatively, these can be viewed as Markoviannetworks with $O(1)$ jump rates viewed over a long time horizon. In the regimeswe consider, the window averages of graphon valued processes over suitable timeintervals are natural state descriptors for the system. Under appropriateconditions on the jump-rate kernels, we establish laws of large numbers andlarge deviation principles(LDP) for the graphon processes averaged over asuitable time window, both in the weak topology and with respect to the cutnorm in the associated graphon space. Although the problem setting and analysisare more involved than for the well-studied static random network model, thevariational problem associated with the rate function admits an explicitsolution, yielding an equally tractable, though different, expression for therate function, similar to the static case. Using these results, we thenestablish the LDP for node-valent dynamical systems driven by the underlyingevolving network.</description>
      <author>example@mail.com (Shankar Bhamidi, Amarjit Budhiraja, Souvik Ray)</author>
      <guid isPermaLink="false">2506.08333v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>BioLangFusion: Multimodal Fusion of DNA, mRNA, and Protein Language Models</title>
      <link>http://arxiv.org/abs/2506.08936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of ICML 2025 Workshop on Multi-modal Foundation  Proceedings of ICML 2025 Workshop on Multi-modal Foundation Proceedings of  ICML 2025 Workshop on Multi-modal Foundation Models and Large Language Models  for Life Sciences&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BioLangFusion的简单方法，用于将预训练的DNA、mRNA和蛋白质语言模型集成到统一的分子表示中。&lt;h4&gt;背景&lt;/h4&gt;该方法受到分子生物学中心法则（从基因到转录再到蛋白质的信息流动）的启发。&lt;h4&gt;目的&lt;/h4&gt;目的是通过在生物学上有意义的密码子级别（编码一个氨基酸的三个核苷酸）对齐每个模态的嵌入，确保直接的跨模态对应关系。&lt;h4&gt;方法&lt;/h4&gt;BioLangFusion研究了三种标准的融合技术：(i) 密码子级别的嵌入连接，(ii) 受多实例学习启发的熵正则化注意力池化，以及(iii) 跨模态多头注意力。每种技术都为结合模态特定的信号提供了不同的归纳偏差。这些方法不需要额外的预训练或修改基础模型，可以方便地与现有的基于序列的基础模型集成。&lt;h4&gt;主要发现&lt;/h4&gt;在五个分子属性预测任务中，BioLangFusion优于强大的单模态基线，表明即使是简单的预训练模型融合也能以最小的开销捕获互补的多组学信息。&lt;h4&gt;结论&lt;/h4&gt;BioLangFusion展示了预训练模型融合的潜力，即使在简单的情况下也能有效地整合多模态信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present BioLangFusion, a simple approach for integrating pre-trained DNA,mRNA, and protein language models into unified molecular representations.Motivated by the central dogma of molecular biology (information flow from geneto transcript to protein), we align per-modality embeddings at the biologicallymeaningful codon level (three nucleotides encoding one amino acid) to ensuredirect cross-modal correspondence. BioLangFusion studies three standard fusiontechniques: (i) codon-level embedding concatenation, (ii) entropy-regularizedattention pooling inspired by multiple-instance learning, and (iii) cross-modalmulti-head attention -- each technique providing a different inductive bias forcombining modality-specific signals. These methods require no additionalpre-training or modification of the base models, allowing straightforwardintegration with existing sequence-based foundation models. Across fivemolecular property prediction tasks, BioLangFusion outperforms strong unimodalbaselines, showing that even simple fusion of pre-trained models can capturecomplementary multi-omic information with minimal overhead.</description>
      <author>example@mail.com (Amina Mollaysa, Artem Moskale, Pushpak Pati, Tommaso Mansi, Mangal Prakash, Rui Liao)</author>
      <guid isPermaLink="false">2506.08936v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>HSG-12M: A Large-Scale Spatial Multigraph Dataset</title>
      <link>http://arxiv.org/abs/2506.08618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  39 pages, 13 figures, 3 tables. Code &amp; pipeline:  [https://github.com/sarinstein-yan/Poly2Graph] Dataset:  [https://github.com/sarinstein-yan/HSG-12M] Dataset released under CC BY 4.0&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了HSG-12M，这是第一个大规模的基于空间多图的数据库，其中包含了在度量空间中嵌入的图，保留了两个节点之间多个几何上不同的轨迹作为单独的边。HSG-12M包含来自1.77TB光谱势数据的11.6百万静态和5.1百万动态哈密顿谱图，涵盖了1401种特征多项式类别。每个图编码了1D晶体能量谱在复平面上的完整几何，产生了超越传统节点坐标数据集的多样化、基于物理学的拓扑结构。&lt;h4&gt;背景&lt;/h4&gt;现有的图基准假设非空间、简单边，将物理上不同的路径合并为单个链接。&lt;h4&gt;目的&lt;/h4&gt;提出HSG-12M，以解决现有图基准的局限性，并促进几何感知图学习和数据驱动科学发现。&lt;h4&gt;方法&lt;/h4&gt;构建了HSG-12M数据集，并开发了Poly2Graph，这是一个高性能的开源管道，将任意的1D晶体哈密顿量映射到谱图。&lt;h4&gt;主要发现&lt;/h4&gt;HSG-12M展示了多边几何在规模学习中的新挑战，并揭示了谱图作为多项式、向量和矩阵的通用拓扑指纹，建立了代数到图的联系。&lt;h4&gt;结论&lt;/h4&gt;HSG-12M为几何感知图学习奠定了基础，并为凝聚态物理学及其他领域的科学发现提供了新的数据驱动机会。&lt;h4&gt;翻译&lt;/h4&gt;Existing graph benchmarks assume non-spatial, simple edges, collapsing physically distinct paths into a single link. We introduce HSG-12M, the first large-scale dataset of spatial multigraphs—graphs embedded in a metric space where multiple geometrically distinct trajectories between two nodes are retained as separate edges. HSG-12M contains 11.6 million static and 5.1 million dynamic Hamiltonian spectral graphs across 1401 characteristic-polynomial classes, derived from 177 TB of spectral potential data. Each graph encodes the full geometry of a 1-D crystal's energy spectrum on the complex plane, producing diverse, physics-grounded topologies that transcend conventional node-coordinate datasets. To enable future extensions, we release Poly2Graph: a high-performance, open-source pipeline that maps arbitrary 1-D crystal Hamiltonians to spectral graphs. Benchmarks with popular GNNs expose new challenges in learning from multi-edge geometry at scale. Beyond its practical utility, we show that spectral graphs serve as universal topological fingerprints of polynomials, vectors, and matrices, forging a new algebra-to-graph link. HSG-12M lays the groundwork for geometry-aware graph learning and new opportunities of data-driven scientific discovery in condensed matter physics and beyond.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing graph benchmarks assume non-spatial, simple edges, collapsingphysically distinct paths into a single link. We introduce HSG-12M, the firstlarge-scale dataset of $\textbf{spatial multigraphs}-$graphs embedded in ametric space where multiple geometrically distinct trajectories between twonodes are retained as separate edges. HSG-12M contains 11.6 million static and5.1 million dynamic $\textit{Hamiltonian spectral graphs}$ across 1401characteristic-polynomial classes, derived from 177 TB of spectral potentialdata. Each graph encodes the full geometry of a 1-D crystal's energy spectrumon the complex plane, producing diverse, physics-grounded topologies thattranscend conventional node-coordinate datasets. To enable future extensions,we release $\texttt{Poly2Graph}$: a high-performance, open-source pipeline thatmaps arbitrary 1-D crystal Hamiltonians to spectral graphs. Benchmarks withpopular GNNs expose new challenges in learning from multi-edge geometry atscale. Beyond its practical utility, we show that spectral graphs serve asuniversal topological fingerprints of polynomials, vectors, and matrices,forging a new algebra-to-graph link. HSG-12M lays the groundwork forgeometry-aware graph learning and new opportunities of data-driven scientificdiscovery in condensed matter physics and beyond.</description>
      <author>example@mail.com (Xianquan Yan, Hakan Akgün, Kenji Kawaguchi, N. Duane Loh, Ching Hua Lee)</author>
      <guid isPermaLink="false">2506.08618v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Intention-Conditioned Flow Occupancy Models</title>
      <link>http://arxiv.org/abs/2506.08902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于流匹配的概率模型，用于预测智能体在长期未来可能访问的状态（即占用度量）。该模型通过包含一个捕获用户意图的潜在变量来增加模型的表达性，并允许通过广义策略改进进行自适应调整。&lt;h4&gt;背景&lt;/h4&gt;大规模预训练在机器学习研究中扮演着重要角色，通过预训练大型基础模型，任何人都可以使用这些模型来适应和微调特定任务。这种方法在强化学习（RL）中也非常有吸引力，因为它提供了解决RL核心挑战（如样本效率和鲁棒性）的有力途径。&lt;h4&gt;目的&lt;/h4&gt;旨在解决RL中预训练大型模型的基本挑战，即动作具有长期依赖性，因此需要训练能够跨时间推理的基础模型。&lt;h4&gt;方法&lt;/h4&gt;使用流匹配构建概率模型来预测智能体在长期未来可能访问的状态，并包含一个捕获用户意图的潜在变量。&lt;h4&gt;主要发现&lt;/h4&gt;在36个基于状态和4个基于图像的基准任务上的实验表明，所提出的方法在回报上实现了1.8倍的中位数改进，成功率提高了36%。&lt;h4&gt;结论&lt;/h4&gt;提出的意图条件流动占用模型（InFOM）在样本效率和鲁棒性方面优于其他预训练方法，能够有效提高强化学习任务的表现。&lt;h4&gt;翻译&lt;/h4&gt;Large-scale pre-training has fundamentally changed how machine learning research is done today: large foundation models are trained once, and then can be used by anyone in the community (including those without data or computeresources to train a model from scratch) to adapt and fine-tune to specific tasks. Applying this same framework to reinforcement learning (RL) is appealing because it offers compelling avenues for addressing core challenges in RL, including sample efficiency and robustness. However, there remains a fundamental challenge to pre-train large models in the context of RL: actions have long-term dependencies, so training a foundation model that reasons across time is important. Recent advances in generative AI have provided new tools for modeling highly complex distributions. In this paper, we build a probabilistic model to predict which states an agent will visit in the temporally distant future (i.e., an occupancy measure) using flow matching. As large datasets are often constructed by many distinct users performing distinct tasks, we include in our model a latent variable capturing the user intention. This intention increases the expressivity of our model, and enables adaptation with generalized policy improvement. We call our proposed method intention-conditioned flow occupancy models (InFOM). Comparing with alternative methods for pre-training, our experiments on 36 state-based and 4 image-based benchmark tasks demonstrate that the proposed method achieves 1.8 times median improvement in returns and increases success rates by 36%. Website: https://chongyi-zheng.github.io/infom Code: https://github.com/chongyi-zheng/infom&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale pre-training has fundamentally changed how machine learningresearch is done today: large foundation models are trained once, and then canbe used by anyone in the community (including those without data or computeresources to train a model from scratch) to adapt and fine-tune to specifictasks. Applying this same framework to reinforcement learning (RL) is appealingbecause it offers compelling avenues for addressing core challenges in RL,including sample efficiency and robustness. However, there remains afundamental challenge to pre-train large models in the context of RL: actionshave long-term dependencies, so training a foundation model that reasons acrosstime is important. Recent advances in generative AI have provided new tools formodeling highly complex distributions. In this paper, we build a probabilisticmodel to predict which states an agent will visit in the temporally distantfuture (i.e., an occupancy measure) using flow matching. As large datasets areoften constructed by many distinct users performing distinct tasks, we includein our model a latent variable capturing the user intention. This intentionincreases the expressivity of our model, and enables adaptation withgeneralized policy improvement. We call our proposed methodintention-conditioned flow occupancy models (InFOM). Comparing with alternativemethods for pre-training, our experiments on $36$ state-based and $4$image-based benchmark tasks demonstrate that the proposed method achieves $1.8\times$ median improvement in returns and increases success rates by $36\%$.Website: https://chongyi-zheng.github.io/infom Code:https://github.com/chongyi-zheng/infom</description>
      <author>example@mail.com (Chongyi Zheng, Seohong Park, Sergey Levine, Benjamin Eysenbach)</author>
      <guid isPermaLink="false">2506.08902v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>MIRAGE: Multimodal foundation model and benchmark for comprehensive retinal OCT image analysis</title>
      <link>http://arxiv.org/abs/2506.08900v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MIRAGE的多模态基础模型，用于分析OCT和SLO图像，并提出了一种新的评估基准，旨在解决现有AI模型在眼科图像分析中的挑战。&lt;h4&gt;背景&lt;/h4&gt;人工智能在分析眼科图像，如OCT图像中起到了重要作用，但开发AI模型通常需要大量标注，且现有模型在独立未见过的数据上表现不佳。现有的基础模型在眼科领域缺乏广泛的验证，且集中于单一成像方式。&lt;h4&gt;目的&lt;/h4&gt;提出MIRAGE模型，并建立一个新的评估基准，以解决上述挑战，并提高眼科图像分析的AI系统的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;开发了一个新的多模态基础模型MIRAGE，并提出了包含OCT/SLO分类和分割任务的新评估基准。&lt;h4&gt;主要发现&lt;/h4&gt;MIRAGE在OCT/SLO分类和分割任务中均优于一般和专业的FMs及分割方法，表明其适用于开发鲁棒的AI系统。&lt;h4&gt;结论&lt;/h4&gt;MIRAGE模型和评估基准已公开发布，有助于推动眼科图像分析的AI系统发展。&lt;h4&gt;翻译&lt;/h4&gt;Artificial intelligence (AI) has become a fundamental tool for assisting clinicians in analyzing ophthalmic images, such as optical coherence tomography (OCT). However, developing AI models often requires extensive annotation, and existing models tend to underperform on independent, unseen data. Foundation models (FMs), large AI models trained on vast unlabeled datasets, have shown promise in overcoming these challenges. Nonetheless, available FMs for ophthalmology lack extensive validation, especially for segmentation tasks, and focus on a single imaging modality. In this context, we propose MIRAGE, a novel multimodal FM for the analysis of OCT and scanning laser ophthalmoscopy (SLO) images. Additionally, we propose a new evaluation benchmark with OCT/SLO classification and segmentation tasks. The comparison with general and specialized FMs and segmentation methods shows the superiority of MIRAGE in both types of tasks, highlighting its suitability as a basis for the development of robust AI systems for retinal OCT image analysis. Both MIRAGE and the evaluation benchmark are publicly available: https://github.com/j-morano/MIRAGE.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence (AI) has become a fundamental tool for assistingclinicians in analyzing ophthalmic images, such as optical coherence tomography(OCT). However, developing AI models often requires extensive annotation, andexisting models tend to underperform on independent, unseen data. Foundationmodels (FMs), large AI models trained on vast unlabeled datasets, have shownpromise in overcoming these challenges. Nonetheless, available FMs forophthalmology lack extensive validation, especially for segmentation tasks, andfocus on a single imaging modality. In this context, we propose MIRAGE, a novelmultimodal FM for the analysis of OCT and scanning laser ophthalmoscopy (SLO)images. Additionally, we propose a new evaluation benchmark with OCT/SLOclassification and segmentation tasks. The comparison with general andspecialized FMs and segmentation methods shows the superiority of MIRAGE inboth types of tasks, highlighting its suitability as a basis for thedevelopment of robust AI systems for retinal OCT image analysis. Both MIRAGEand the evaluation benchmark are publicly available:https://github.com/j-morano/MIRAGE.</description>
      <author>example@mail.com (José Morano, Botond Fazekas, Emese Sükei, Ronald Fecso, Taha Emre, Markus Gumpinger, Georg Faustmann, Marzieh Oghbaie, Ursula Schmidt-Erfurth, Hrvoje Bogunović)</author>
      <guid isPermaLink="false">2506.08900v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Adapting Vision-Language Foundation Model for Next Generation Medical Ultrasound Image Analysis</title>
      <link>http://arxiv.org/abs/2506.08849v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种针对医学超声图像分析的视觉-语言基础模型领域自适应方法，通过调整和优化模型，提高了其在分割和分类任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;医学超声成像是一种重要的影像技术，用于检查浅表器官和组织，如淋巴结、乳腺和甲状腺。手动在图像中标记感兴趣区域是耗时且需要专业知识的工作，容易导致不同的解释。&lt;h4&gt;目的&lt;/h4&gt;旨在克服视觉-语言基础模型在自然和医学成像领域之间的性能差异，提高超声图像分析的准确性。&lt;h4&gt;方法&lt;/h4&gt;研究探索了视觉-语言基础模型的微调流程，使用大型语言模型作为文本细化器，结合特殊设计的自适应策略和任务驱动的头部。&lt;h4&gt;主要发现&lt;/h4&gt;方法在六个超声数据集和两个任务（分割和分类）上进行了广泛评估，实验结果表明该方法能够有效提升视觉-语言基础模型在超声图像分析中的性能，并优于现有的视觉-语言和纯基础模型。&lt;h4&gt;结论&lt;/h4&gt;该方法在超声图像分析中提高了视觉-语言基础模型的表现，具有实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical ultrasonography is an essential imaging technique for examiningsuperficial organs and tissues, including lymph nodes, breast, and thyroid. Itemploys high-frequency ultrasound waves to generate detailed images of theinternal structures of the human body. However, manually contouring regions ofinterest in these images is a labor-intensive task that demands expertise andoften results in inconsistent interpretations among individuals.Vision-language foundation models, which have excelled in various computervision applications, present new opportunities for enhancing ultrasound imageanalysis. Yet, their performance is hindered by the significant differencesbetween natural and medical imaging domains. This research seeks to overcomethese challenges by developing domain adaptation methods for vision-languagefoundation models. In this study, we explore the fine-tuning pipeline forvision-language foundation models by utilizing large language model as textrefiner with special-designed adaptation strategies and task-driven heads. Ourapproach has been extensively evaluated on six ultrasound datasets and twotasks: segmentation and classification. The experimental results show that ourmethod can effectively improve the performance of vision-language foundationmodels for ultrasound image analysis, and outperform the existingstate-of-the-art vision-language and pure foundation models. The source code ofthis study is available at\href{https://github.com/jinggqu/NextGen-UIA}{GitHub}.</description>
      <author>example@mail.com (Jingguo Qu, Xinyang Han, Tonghuan Xiao, Jia Ai, Juan Wu, Tong Zhao, Jing Qin, Ann Dorothy King, Winnie Chiu-Wing Chu, Jing Cai, Michael Tin-Cheung Yingınst)</author>
      <guid isPermaLink="false">2506.08849v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>MOBODY: Model Based Off-Dynamics Offline Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.08460v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了离线强化学习中的离动态问题，提出了一种名为MOBODY的基于模型的离动态离线强化学习算法，该算法通过学习动态来探索目标域，并通过模型扩展来增强数据，从而提高了在目标域中学习策略的能力。&lt;h4&gt;背景&lt;/h4&gt;离动态离线强化学习问题中，目标是从包含不同转换域的离线数据集中学习策略。现有的离动态离线强化学习方法通常受到目标域有限转换的限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够探索目标域并学习策略的离动态离线强化学习算法。&lt;h4&gt;方法&lt;/h4&gt;MOBODY算法通过模型扩展生成新的合成转换，并将其用作离线策略学习中的数据增强。该算法利用源数据和目标数据集来处理不匹配的动态，并通过表示学习发现跨域的状态和转换的共享潜在表示，以学习目标动态。此外，MOBODY还引入了一种Q加权的模仿行为损失来正则化策略。&lt;h4&gt;主要发现&lt;/h4&gt;MOBODY在MuJoCo基准测试中表现优于现有方法，特别是在具有挑战性的场景中表现出显著改进。&lt;h4&gt;结论&lt;/h4&gt;MOBODY算法通过增强数据集和学习动态，显著提高了离动态离线强化学习在目标域中的策略学习性能。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了离动态离线强化学习问题，其目标是学习一个策略，该策略来自从源域和目标域收集的离线数据集，这些数据集具有不匹配的转换。现有的离动态离线强化学习方法通常要么过滤与目标域相似的源转换，要么对源数据进行奖励增强，这两种方法都受到来自目标域的有限转换的限制。因此，学习到的策略无法探索目标域之外的离线数据集。我们提出了MOBODY，这是一种基于模型的离动态离线强化学习算法，通过通过学习动态来启用对目标域的探索来解决这个问题。MOBODY通过模型扩展在目标域中生成新的合成转换，这些转换在离线策略学习期间用作数据增强。与从单个域学习动态的现有基于模型的方法不同，MOBODY通过利用源数据和目标数据集来解决不匹配的动态的挑战。直接合并这些数据集可能会使学习到的模型偏向源动态。相反，MOBODY通过通过表示学习发现跨域的状态和转换的共享潜在表示来学习目标动态。为了稳定训练，MOBODY结合了行为克隆损失来正则化策略。具体来说，我们引入了一种Q加权的模仿行为克隆损失，该损失将策略正则化到具有高目标域Q值的行为，而不是均匀地模仿数据集中的所有行为。这些Q值是从由离线目标数据、增强源数据和从学习到的目标动态的滚动数据组成的增强目标数据集中学习的。我们在MuJoCo基准测试中评估了MOBODY，并表明它显著优于最先进的基线，特别是在具有挑战性的场景中表现出特别显著的改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the off-dynamics offline reinforcement learning problem, where thegoal is to learn a policy from offline datasets collected from source andtarget domains with mismatched transition. Existing off-dynamics offline RLmethods typically either filter source transitions that resemble those of thetarget domain or apply reward augmentation to source data, both constrained bythe limited transitions available from the target domain. As a result, thelearned policy is unable to explore target domain beyond the offline datasets.We propose MOBODY, a Model-Based Off-Dynamics offline RL algorithm thataddresses this limitation by enabling exploration of the target domain vialearned dynamics. MOBODY generates new synthetic transitions in the targetdomain through model rollouts, which are used as data augmentation duringoffline policy learning. Unlike existing model-based methods that learndynamics from a single domain, MOBODY tackles the challenge of mismatcheddynamics by leveraging both source and target datasets. Directly merging thesedatasets can bias the learned model toward source dynamics. Instead, MOBODYlearns target dynamics by discovering a shared latent representation of statesand transitions across domains through representation learning. To stabilizetraining, MOBODY incorporates a behavior cloning loss that regularizes thepolicy. Specifically, we introduce a Q-weighted behavior cloning loss thatregularizes the policy toward actions with high target-domain Q-values, ratherthan uniformly imitating all actions in the dataset. These Q-values are learnedfrom an enhanced target dataset composed of offline target data, augmentedsource data, and rollout data from the learned target dynamics. We evaluateMOBODY on MuJoCo benchmarks and show that it significantly outperformsstate-of-the-art baselines, with especially pronounced improvements inchallenging scenarios.</description>
      <author>example@mail.com (Yihong Guo, Yu Yang, Pan Xu, Anqi Liu)</author>
      <guid isPermaLink="false">2506.08460v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Landsat-Bench: Datasets and Benchmarks for Landsat Foundation Models</title>
      <link>http://arxiv.org/abs/2506.08780v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Landsat-Bench，一套基于Landsat影像的基准测试集，用于促进基于Landsat的地理空间基础模型（GFM）的发展。&lt;h4&gt;背景&lt;/h4&gt;Landsat项目提供了超过50年的全球一致地球影像，但由于缺乏该数据的基准测试，限制了基于Landsat的地理空间基础模型（GFM）的发展。&lt;h4&gt;目的&lt;/h4&gt;通过引入Landsat-Bench，旨在建立基准和标准化的评估方法，以促进基于Landsat的地理空间基础模型（GFM）的发展。&lt;h4&gt;方法&lt;/h4&gt;Landsat-Bench包括三个基准测试集：EuroSAT-L、BigEarthNet-L和LC100-L，这些测试集来自现有的遥感数据集。研究人员在SSL4EO-L数据集上预训练了Landsat基础模型，并使用这些模型进行基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;SSL4EO-L预训练的GFM在下游任务中提取了更好的表示，与ImageNet相比，在EuroSAT-L和BigEarthNet-L上的性能分别提高了+4% OA和+5.1% mAP。&lt;h4&gt;结论&lt;/h4&gt;SSL4EO-L预训练的GFM在基于Landsat的地理空间基础模型（GFM）中具有更高的性能，为后续任务提供了更好的基础。&lt;h4&gt;翻译&lt;/h4&gt;The Landsat program provides over 50 years of globally consistent Earth imagery. However, the lack of benchmarks for this data constrains progress towards Landsat-based Geospatial Foundation Models (GFM). In this paper, we introduce Landsat-Bench, a suite of three benchmarks with Landsat imagery that adapt from existing remote sensing datasets -- EuroSAT-L, BigEarthNet-L, and LC100-L. We establish baseline and standardized evaluation methods across both common architectures and Landsat foundation models pretrained on the SSL4EO-L dataset. Notably, we provide evidence that SSL4EO-L pretrained GFMs extract better representations for downstream tasks in comparison to ImageNet, including performance gains of +4% OA and +5.1% mAP on EuroSAT-L and BigEarthNet-L.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Landsat program offers over 50 years of globally consistent Earthimagery. However, the lack of benchmarks for this data constrains progresstowards Landsat-based Geospatial Foundation Models (GFM). In this paper, weintroduce Landsat-Bench, a suite of three benchmarks with Landsat imagery thatadapt from existing remote sensing datasets -- EuroSAT-L, BigEarthNet-L, andLC100-L. We establish baseline and standardized evaluation methods across bothcommon architectures and Landsat foundation models pretrained on the SSL4EO-Ldataset. Notably, we provide evidence that SSL4EO-L pretrained GFMs extractbetter representations for downstream tasks in comparison to ImageNet,including performance gains of +4% OA and +5.1% mAP on EuroSAT-L andBigEarthNet-L.</description>
      <author>example@mail.com (Isaac Corley, Lakshay Sharma, Ruth Crasto)</author>
      <guid isPermaLink="false">2506.08780v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>FUSE: Measure-Theoretic Compact Fuzzy Set Representation for Taxonomy Expansion</title>
      <link>http://arxiv.org/abs/2506.08409v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于模糊集的集合表示学习方法，用于复杂概念及其关系的建模。&lt;h4&gt;背景&lt;/h4&gt;传统的集合表示学习方法通常将集合建模为向量或几何对象，如箱子，这些方法在集合运算下不是封闭的。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的集合表示学习方法，以模糊集的形式对集合进行体积近似，从而在保持信息的同时提高学习效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Fuzzy Set Embedding (FUSE)的嵌入框架，它基于模糊集的体积近似，满足所有集合运算，并紧凑地近似底层模糊集。&lt;h4&gt;主要发现&lt;/h4&gt;FUSE在分类扩展任务上展示了强大的性能，与现有基线相比，实现了高达23%的改进。&lt;h4&gt;结论&lt;/h4&gt;本文首次尝试理解和高效计算模糊集的嵌入，为概念建模提供了一种新的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：分类扩展，它模拟复杂概念及其关系，可以表述为一种集合表示学习任务。集合的泛化，包括模糊集，包含了不确定性并测量语义概念中的信息，使其适合于概念建模。现有工作通常将集合建模为向量或诸如箱子之类的几何对象，这些方法在集合运算下不是封闭的。在本工作中，我们提出了一种基于集合体积近似为模糊集的集合表示学习的合理和有效公式。由此产生的嵌入框架，模糊集嵌入（FUSE），满足所有集合运算，并紧凑地近似底层模糊集，因此在保持信息的同时，学习效率高，依赖于最小的神经网络架构。我们通过在分类扩展任务上对FUSE的实证演示其力量，其中FUSE与现有基线相比实现了显著的改进，高达23%。我们的工作首次尝试理解和高效计算模糊集的嵌入。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Taxonomy Expansion, which models complex concepts and their relations, can beformulated as a set representation learning task. The generalization of set,fuzzy set, incorporates uncertainty and measures the information within asemantic concept, making it suitable for concept modeling. Existing worksusually model sets as vectors or geometric objects such as boxes, which are notclosed under set operations. In this work, we propose a sound and efficientformulation of set representation learning based on its volume approximation asa fuzzy set. The resulting embedding framework, Fuzzy Set Embedding (FUSE),satisfies all set operations and compactly approximates the underlying fuzzyset, hence preserving information while being efficient to learn, relying onminimum neural architecture. We empirically demonstrate the power of FUSE onthe task of taxonomy expansion, where FUSE achieves remarkable improvements upto 23% compared with existing baselines. Our work marks the first attempt tounderstand and efficiently compute the embeddings of fuzzy sets.</description>
      <author>example@mail.com (Fred Xu, Song Jiang, Zijie Huang, Xiao Luo, Shichang Zhang, Adrian Chen, Yizhou Sun)</author>
      <guid isPermaLink="false">2506.08409v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>WGLE:Backdoor-free and Multi-bit Black-box Watermarking for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.08602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的GNN黑盒水印方法WGLE，用于防止模型盗窃，并实现知识产权保护。&lt;h4&gt;背景&lt;/h4&gt;随着图神经网络（GNNs）在图相关应用中的广泛应用，模型的所有权验证变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的黑盒水印方法，以保护GNN的知识产权，同时避免现有方法的缺点。&lt;h4&gt;方法&lt;/h4&gt;WGLE方法基于层间距离差异（LDDE），通过预定义多个边上的LDDE值，将多比特字符串嵌入到模型中，而不引入错误映射。&lt;h4&gt;主要发现&lt;/h4&gt;WGLE在六个公共数据集和六个主流GNN架构上进行了评估，实现了100%的所有权验证准确率，平均保真度下降为0.85%，具有较好的鲁棒性，且嵌入开销低。&lt;h4&gt;结论&lt;/h4&gt;WGLE是一种有效且高效的GNN黑盒水印方法，能够有效防止模型盗窃，并保护知识产权。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are increasingly deployed in graph-relatedapplications, making ownership verification critical to protect theirintellectual property against model theft. Fingerprinting and black-boxwatermarking are two main methods. However, the former relies on determiningmodel similarity, which is computationally expensive and prone to ownershipcollisions after model post-processing such as model pruning or fine-tuning.The latter embeds backdoors, exposing watermarked models to the risk ofbackdoor attacks. Moreover, both methods enable ownership verification but donot convey additional information. As a result, each distributed model requiresa unique trigger graph, and all trigger graphs must be used to query thesuspect model during verification. Multiple queries increase the financial costand the risk of detection.  To address these challenges, this paper proposes WGLE, a novel black-boxwatermarking paradigm for GNNs that enables embedding the multi-bit string asthe ownership information without using backdoors. WGLE builds on a key insightwe term Layer-wise Distance Difference on an Edge (LDDE), which quantifies thedifference between the feature distance and the prediction distance of twoconnected nodes. By predefining positive or negative LDDE values for multipleselected edges, WGLE embeds the watermark encoding the intended informationwithout introducing incorrect mappings that compromise the primary task. WGLEis evaluated on six public datasets and six mainstream GNN architectures alongwith state-of-the-art methods. The results show that WGLE achieves 100%ownership verification accuracy, an average fidelity degradation of 0.85%,comparable robustness against potential attacks, and low embedding overhead.The code is available in the repository.</description>
      <author>example@mail.com (Tingzhi Li, Xuefeng Liu)</author>
      <guid isPermaLink="false">2506.08602v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion Sequence Models for Enhanced Protein Representation and Generation</title>
      <link>http://arxiv.org/abs/2506.08293v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Diffusion Sequence Model (DSM)，一种新型蛋白质语言模型，通过掩码扩散训练实现高质量表示学习和生成蛋白质设计。&lt;h4&gt;背景&lt;/h4&gt;蛋白质是生物学的基本组成部分，在医学、材料科学和环境应用中具有变革潜力。蛋白质语言模型（pLMs）旨在通过掩码语言模型从未标记的蛋白质序列中学习丰富的语义表示，但它们通常表现出有限的生成能力。&lt;h4&gt;目的&lt;/h4&gt;提高蛋白质语言模型的生成能力，实现高质量表示学习和生成蛋白质设计。&lt;h4&gt;方法&lt;/h4&gt;DSM基于ESM2架构，通过引入掩码前向扩散过程，受到LLaDA框架的启发。DSM(ppi)是DSM的一个变体，针对目标序列进行微调以生成蛋白质结合剂。&lt;h4&gt;主要发现&lt;/h4&gt;DSM能够生成与预期氨基酸组成、二级结构和预测功能一致的多样化、生物模拟序列，即使有90%的标记损坏。DSM的学习表示在下游任务中与类似规模的pLMs相当或更好。DSM和DSM(ppi)在BenchBB基准测试中表现出色，生成的候选结合剂具有比已知结合剂更高的预测结合亲和力。&lt;h4&gt;结论&lt;/h4&gt;掩码扩散被证明是统一蛋白质表示和生成在单一框架中的强大范式。&lt;h4&gt;翻译&lt;/h4&gt;摘要：蛋白质是生物学的基石，通过复杂的物理化学相互作用执行多种功能，并在医学、材料科学和环境应用中具有变革潜力。蛋白质语言模型（pLMs）旨在通过从初级序列中学习丰富的语义表示，通过掩码语言模型从大量未标记的蛋白质序列中揭示见解。然而，这些模型通常表现出有限的生成能力。在这项工作中，我们引入了Diffusion Sequence Model (DSM)，一种新型pLM，通过掩码扩散训练以实现高质量的表示学习和生成蛋白质设计。DSM通过结合LLaDA框架启发的掩码前向扩散过程，在ESM2架构的基础上构建。经过训练，DSM能够生成与预期氨基酸组成、二级结构和预测功能一致的多样化、生物模拟序列，即使有90%的标记损坏。此外，DSM的学习表示在下游任务中与类似规模的pLMs相当或更好。我们还引入了DSM(ppi)，一种针对生成蛋白质结合剂进行微调的变体。我们在具有挑战性的Bench-tested Binder Benchmark (BenchBB)上展示了DSM(ppi)的有效性，其中DSM和DSM(ppi)都产生了比已知结合剂具有更高预测结合亲和力的候选结合剂。我们的结果将掩码扩散确立为统一蛋白质表示和生成在单一框架中的强大范式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Proteins are fundamental to biology, executing diverse functions throughcomplex physicochemical interactions, and they hold transformative potentialacross medicine, materials science, and environmental applications. ProteinLanguage Models (pLMs) aim to unlock insights from the vast space of unlabeledprotein sequences by learning rich, semantic representations from primarysequences via masked language modeling. However, these models typically exhibitlimited generative capacity. In this work, we introduce the Diffusion SequenceModel (DSM), a novel pLM trained with masked diffusion to enable bothhigh-quality representation learning and generative protein design. DSM buildsupon the ESM2 architecture by incorporating a masked forward diffusion processinspired by the LLaDA framework. After training, DSM is capable of generatingdiverse, biomimetic sequences that align with expected amino acid compositions,secondary structures, and predicted functions, even with 90\% token corruption.Furthermore, DSM's learned representations match or exceed those of similarlysized pLMs on downstream tasks. We also introduce DSM(ppi), a variantfine-tuned to generate protein binders by attending to target sequences. Wedemonstrate DSM(ppi)'s effectiveness on the challenging Bench-tested BinderBenchmark (BenchBB), where both DSM and DSM(ppi) produce candidates withsuperior predicted binding affinity compared to known binders. Our resultsestablish masked diffusion as a powerful paradigm for unifying proteinrepresentation and generation in a single framework.</description>
      <author>example@mail.com (Logan Hallee, Nikolaos Rafailidis, David B. Bichara, Jason P. Gleghorn)</author>
      <guid isPermaLink="false">2506.08293v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>HGFormer: A Hierarchical Graph Transformer Framework for Two-Stage Colonel Blotto Games via Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.08580v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HGformer的分层图Transformer框架，用于解决两阶段Colonel Blotto游戏中的资源分配问题，通过实验验证了其在复杂动态游戏场景中的优越性能。&lt;h4&gt;背景&lt;/h4&gt;两阶段Colonel Blotto游戏是一个典型的对抗性资源分配问题，涉及两个代理在两个阶段内按顺序在网络拓扑中分配资源：首先是初始资源部署，然后是多个轮次的动态重新分配调整。&lt;h4&gt;目的&lt;/h4&gt;为了解决游戏阶段之间的顺序依赖性和图拓扑的复杂约束，提出HGformer框架以实现大规模对抗环境中的高效策略生成。&lt;h4&gt;方法&lt;/h4&gt;HGformer通过结合增强的图Transformer编码器（具有结构偏差）和两个代理的分层决策模型来实现策略生成。此外，还设计了一种逐层反馈强化学习算法，将来自低级决策的长期回报反馈到高级策略的优化中。&lt;h4&gt;主要发现&lt;/h4&gt;与现有的分层决策或图神经网络方法相比，HGformer显著提高了资源分配效率和对抗性收益。&lt;h4&gt;结论&lt;/h4&gt;HGformer在复杂动态游戏场景中实现了优于现有方法的整体性能。&lt;h4&gt;翻译&lt;/h4&gt;Two-stage Colonel Blotto game represents a typical adversarial resourceallocation problem, in which two opposing agents sequentially allocate resources in a network topology across two phases: an initial resourcedeployment followed by multiple rounds of dynamic reallocation adjustments. Thesequential dependency between game stages and the complex constraints imposedby the graph topology make it difficult for traditional approaches to attain aglobally optimal strategy. To address these challenges, we propose a hierarchical graph Transformer framework called HGformer. By incorporating an enhanced graph Transformer encoder with structural biases and a two-agent hierarchical decision model, our approach enables efficient policy generation in large-scale adversarial environments. Moreover, we design a layer-by-layer feedback reinforcement learning algorithm that feeds the long-term returns from lower-level decisions back into the optimization of the higher-level strategy, thus bridging the coordination gap between the two decision-making stages. Experimental results demonstrate that, compared to existing hierarchical decision-making or graph neural network methods, HGformer significantly improves resource allocation efficiency and adversarial payoff, achieving superior overall performance in complex dynamic game scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Two-stage Colonel Blotto game represents a typical adversarial resourceallocation problem, in which two opposing agents sequentially allocateresources in a network topology across two phases: an initial resourcedeployment followed by multiple rounds of dynamic reallocation adjustments. Thesequential dependency between game stages and the complex constraints imposedby the graph topology make it difficult for traditional approaches to attain aglobally optimal strategy. To address these challenges, we propose ahierarchical graph Transformer framework called HGformer. By incorporating anenhanced graph Transformer encoder with structural biases and a two-agenthierarchical decision model, our approach enables efficient policy generationin large-scale adversarial environments. Moreover, we design a layer-by-layerfeedback reinforcement learning algorithm that feeds the long-term returns fromlower-level decisions back into the optimization of the higher-level strategy,thus bridging the coordination gap between the two decision-making stages.Experimental results demonstrate that, compared to existing hierarchicaldecision-making or graph neural network methods, HGformer significantlyimproves resource allocation efficiency and adversarial payoff, achievingsuperior overall performance in complex dynamic game scenarios.</description>
      <author>example@mail.com (Yang Lv, Jinlong Lei, Peng Yi)</author>
      <guid isPermaLink="false">2506.08580v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>RS-MTDF: Multi-Teacher Distillation and Fusion for Remote Sensing Semi-Supervised Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2506.08772v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RS-MTDF的半监督语义分割框架，用于遥感图像分割，以解决现有半监督方法中标签数据与未标记数据分布不匹配的问题。&lt;h4&gt;背景&lt;/h4&gt;遥感图像的语义分割对于多种应用至关重要，但其性能高度依赖于大规模、高质量的像素级标注，这些标注获取成本高且耗时。半监督语义分割（SSS）作为一种替代方案，可以有效减轻数据依赖。&lt;h4&gt;目的&lt;/h4&gt;提出RS-MTDF框架，利用视觉基础模型（VFMs）的强大泛化能力，以改善SSS的性能。&lt;h4&gt;方法&lt;/h4&gt;RS-MTDF框架采用多个预训练的VFMs作为专家教师，通过特征级别的蒸馏来对齐学生特征，并融合蒸馏的知识到学生解码器中，从而增强判别能力。&lt;h4&gt;主要发现&lt;/h4&gt;在三个具有挑战性的遥感数据集（ISPRS Potsdam、LoveDA和DeepGlobe）上进行的实验表明，RS-MTDF在各个标签比率上均取得了最先进的性能，尤其是在LoveDA数据集上，在大多数语义类别中获得了最高的IoU值。&lt;h4&gt;结论&lt;/h4&gt;多教师VFMs的指导在显著提高遥感分割的泛化和语义理解方面是有效的。消融实验进一步验证了每个模块的贡献。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Semantic segmentation in remote sensing images is crucial for various applications, yet its performance is heavily reliant on large-scale, high-quality pixel-wise annotations, which are notoriously expensive and time-consuming to acquire. Semi-supervised semantic segmentation (SSS) offers a promising alternative to mitigate this data dependency. However, existing SSS methods often struggle with the inherent distribution mismatch between limited labeled data and abundant unlabeled data, leading to suboptimal generalization. We propose that Vision Foundation Models (VFMs), pre-trained on vast and diverse datasets, possess robust generalization capabilities that can effectively bridge this distribution gap and provide strong semantic priors for SSS. Inspired by this, we introduce RS-MTDF (Multi-Teacher Distillation and Fusion), a novel framework that leverages the powerful semantic knowledge embedded in VFMs to guide semi-supervised learning in remote sensing. Specifically, RS-MTDF employs multiple frozen VFMs (e.g., DINOv2 and CLIP) as expert teachers, utilizing feature-level distillation to align student features with their robust representations. To further enhance discriminative power, the distilled knowledge is seamlessly fused into the student decoder. Extensive experiments on three challenging remote sensing datasets (ISPRS Potsdam, LoveDA, and DeepGlobe) demonstrate that RS-MTDF consistently achieves state-of-the-art performance. Notably, our method outperforms existing approaches across various label ratios on LoveDA and secures the highest IoU in the majority of semantic categories. These results underscore the efficacy of multi-teacher VFM guidance in significantly enhancing both generalization and semantic understanding for remote sensing segmentation. Ablation studies further validate the contribution of each proposed module.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic segmentation in remote sensing images is crucial for variousapplications, yet its performance is heavily reliant on large-scale,high-quality pixel-wise annotations, which are notoriously expensive andtime-consuming to acquire. Semi-supervised semantic segmentation (SSS) offers apromising alternative to mitigate this data dependency. However, existing SSSmethods often struggle with the inherent distribution mismatch between limitedlabeled data and abundant unlabeled data, leading to suboptimal generalization.We propose that Vision Foundation Models (VFMs), pre-trained on vast anddiverse datasets, possess robust generalization capabilities that caneffectively bridge this distribution gap and provide strong semantic priors forSSS. Inspired by this, we introduce RS-MTDF (Multi-Teacher Distillation andFusion), a novel framework that leverages the powerful semantic knowledgeembedded in VFMs to guide semi-supervised learning in remote sensing.Specifically, RS-MTDF employs multiple frozen VFMs (\textit{e.g.}, DINOv2 andCLIP) as expert teachers, utilizing feature-level distillation to align studentfeatures with their robust representations. To further enhance discriminativepower, the distilled knowledge is seamlessly fused into the student decoder.Extensive experiments on three challenging remote sensing datasets (ISPRSPotsdam, LoveDA, and DeepGlobe) demonstrate that RS-MTDF consistently achievesstate-of-the-art performance. Notably, our method outperforms existingapproaches across various label ratios on LoveDA and secures the highest IoU inthe majority of semantic categories. These results underscore the efficacy ofmulti-teacher VFM guidance in significantly enhancing both generalization andsemantic understanding for remote sensing segmentation. Ablation studiesfurther validate the contribution of each proposed module.</description>
      <author>example@mail.com (Jiayi Song, Kaiyu Li, Xiangyong Cao, Deyu Meng)</author>
      <guid isPermaLink="false">2506.08772v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Bayesian Inverse Physics for Neuro-Symbolic Robot Learning</title>
      <link>http://arxiv.org/abs/2506.08756v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合数据驱动学习和结构化推理的概念框架，旨在解决现实世界机器人应用中深度学习架构在未知和动态环境下的局限性。&lt;h4&gt;背景&lt;/h4&gt;现实世界的机器人应用需要适应性、可解释性和数据高效的机器学习方法。&lt;h4&gt;目的&lt;/h4&gt;评估深度学习架构在未知和动态环境下的局限性，并提出一种结合数据驱动学习和结构化推理的方法。&lt;h4&gt;方法&lt;/h4&gt;通过利用可微物理进行高效的世界建模，贝叶斯推理进行不确定性感知的决策，以及元学习进行对新任务的快速适应。&lt;h4&gt;主要发现&lt;/h4&gt;将物理符号推理嵌入到神经网络模型中，机器人可以超越训练数据泛化，推理新情境，并持续扩展其知识。&lt;h4&gt;结论&lt;/h4&gt;这种混合神经符号架构对于下一代自主系统至关重要，并为此提供了一个研究路线图以指导和发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现实世界的机器人应用，从自主探索到辅助技术，需要适应性、可解释性和数据高效的机器学习方法。虽然深度学习架构和基础模型在多样化的机器人应用中推动了显著进步，但它们在未知和动态环境中高效和可靠运行的能力仍然有限。在这篇立场论文中，我们批判性地评估了这些局限性，并介绍了一个结合数据驱动学习与有目的、结构化推理的概念框架。具体来说，我们提出了利用可微物理进行高效世界建模、贝叶斯推理进行不确定性感知决策以及元学习进行对新任务的快速适应。通过在神经网络模型中嵌入物理符号推理，机器人可以超越其训练数据泛化，推理新情境，并持续扩展其知识。我们认为，这样的混合神经符号架构对于下一代自主系统至关重要，为此，我们提供了一个研究路线图以指导和加速其发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world robotic applications, from autonomous exploration to assistivetechnologies, require adaptive, interpretable, and data-efficient learningparadigms. While deep learning architectures and foundation models have drivensignificant advances in diverse robotic applications, they remain limited intheir ability to operate efficiently and reliably in unknown and dynamicenvironments. In this position paper, we critically assess these limitationsand introduce a conceptual framework for combining data-driven learning withdeliberate, structured reasoning. Specifically, we propose leveragingdifferentiable physics for efficient world modeling, Bayesian inference foruncertainty-aware decision-making, and meta-learning for rapid adaptation tonew tasks. By embedding physical symbolic reasoning within neural models,robots could generalize beyond their training data, reason about novelsituations, and continuously expand their knowledge. We argue that such hybridneuro-symbolic architectures are essential for the next generation ofautonomous systems, and to this end, we provide a research roadmap to guide andaccelerate their development.</description>
      <author>example@mail.com (Octavio Arriaga, Rebecca Adam, Melvin Laux, Lisa Gutzeit, Marco Ragni, Jan Peters, Frank Kirchner)</author>
      <guid isPermaLink="false">2506.08756v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Reasoning Capabilities of Small Language Models with Blueprints and Prompt Template Search</title>
      <link>http://arxiv.org/abs/2506.08669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  TTODLer-FM Workshop@ICML'25 (Tiny Titans: The next wave of On-Device  Learning for Foundational Models)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，通过使用大型语言模型生成的蓝图来增强小型语言模型的推理能力，同时减少对提示变化的敏感度，从而提高小型语言模型在各种任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;小型语言模型（SLMs）虽然比大型语言模型（LLMs）更高效，但其有限的容量限制了它们的推理能力，并使它们对提示变化敏感。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，以提高SLMs的推理能力，同时减少对提示变化的敏感性。&lt;h4&gt;方法&lt;/h4&gt;该框架通过以下方式实现：1）利用LLM生成的蓝图提供结构化的推理指南；2）集成提示模板搜索机制来减少SLMs对提示变化的敏感性。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在各种任务（如数学、编码和逻辑推理）上提高了SLMs的表现，且无需增加模型大小或额外训练，为设备或资源受限的环境提供了一种轻量级且易于部署的解决方案。&lt;h4&gt;结论&lt;/h4&gt;该框架为SLMs提供了一个有效的方法来增强推理能力，同时保持了模型的小巧和部署的便捷性。&lt;h4&gt;翻译&lt;/h4&gt;Small language models (SLMs) offer promising and efficient alternatives to large language models (LLMs). However, SLMs' limited capacity restricts their reasoning capabilities and makes them sensitive to prompt variations. To address these challenges, we propose a novel framework that enhances SLM reasoning capabilities through LLM generated blueprints. The blueprints provide structured, high-level reasoning guides that help SLMs systematically tackle related problems. Furthermore, our framework integrates a prompt template search mechanism to mitigate the SLMs' sensitivity to prompt variations. Our framework demonstrates improved SLM performance across various tasks, including math (GSM8K), coding (MBPP), and logic reasoning (BBH). Our approach improves the reasoning capabilities of SLMs without increasing model size or requiring additional training, offering a lightweight and deployment-friendly solution for on-device or resource-constrained environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Small language models (SLMs) offer promising and efficient alternatives tolarge language models (LLMs). However, SLMs' limited capacity restricts theirreasoning capabilities and makes them sensitive to prompt variations. Toaddress these challenges, we propose a novel framework that enhances SLMreasoning capabilities through LLM generated blueprints. The blueprints providestructured, high-level reasoning guides that help SLMs systematically tacklerelated problems. Furthermore, our framework integrates a prompt templatesearch mechanism to mitigate the SLMs' sensitivity to prompt variations. Ourframework demonstrates improved SLM performance across various tasks, includingmath (GSM8K), coding (MBPP), and logic reasoning (BBH). Our approach improvesthe reasoning capabilities of SLMs without increasing model size or requiringadditional training, offering a lightweight and deployment-friendly solutionfor on-device or resource-constrained environments.</description>
      <author>example@mail.com (Dongge Han, Menglin Xia, Daniel Madrigal Diaz, Samuel Kessler, Ankur Mallick, Xuchao Zhang, Mirian Del Carmen Hipolito Garcia, Jin Xu, Victor Rühle, Saravan Rajmohan)</author>
      <guid isPermaLink="false">2506.08669v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>ST-GraphNet: A Spatio-Temporal Graph Neural Network for Understanding and Predicting Automated Vehicle Crash Severity</title>
      <link>http://arxiv.org/abs/2506.08051v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ST-GraphNet，这是一种用于模拟和预测自动驾驶汽车（AV）事故严重程度的时空图神经网络框架。该框架结合了细粒度和区域聚合的时空图来建模。&lt;h4&gt;背景&lt;/h4&gt;理解自动驾驶汽车事故的空间和时间动态对于提高城市移动安全性和基础设施规划至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够模拟和预测AV事故严重程度的时空图神经网络框架。&lt;h4&gt;方法&lt;/h4&gt;使用来自德克萨斯州的真实世界AV相关事故报告数据集，构建了两种互补的图表示：细粒度图和粗粒度图。细粒度图以单个事故事件为节点，通过时空邻近性定义边；粗粒度图将事故聚合到基于H3空间索引的单元格中，通过六边形相邻性连接。每个节点都包含多模态数据，包括使用预训练的Sentence-BERT模型从事故叙述中提取的文本嵌入。评估了不同的图神经网络（GNN）架构，如GCN、GAT和DSTGCN，以分类事故严重程度并预测高风险区域。&lt;h4&gt;主要发现&lt;/h4&gt;ST-GraphNet，在粗粒度H3图上使用DSTGCN作为主干，实现了97.74%的测试准确率，显著优于最佳细粒度模型（64.7%的测试准确率）。&lt;h4&gt;结论&lt;/h4&gt;空间聚合、动态消息传递和多模态特征集成在捕捉AV事故严重程度背后的复杂时空模式方面是有效的。&lt;h4&gt;翻译&lt;/h4&gt;Understanding the spatial and temporal dynamics of automated vehicle (AV) crash severity is critical for advancing urban mobility safety and infrastructure planning. In this work, we introduce ST-GraphNet, a spatio-temporal graph neural network framework designed to model and predict AV crash severity by using both fine-grained and region-aggregated spatial graphs. Using a balanced dataset of 2,352 real-world AV-related crash reports from Texas (2024), including geospatial coordinates, crash timestamps, SAE automation levels, and narrative descriptions, we construct two complementary graph representations: (1) a fine-grained graph with individual crash events as nodes, where edges are defined via spatio-temporal proximity; and (2) a coarse-grained graph where crashes are aggregated into Hexagonal Hierarchical Spatial Indexing (H3)-based spatial cells, connected through hexagonal adjacency. Each node in the graph is enriched with multimodal data, including semantic, spatial, and temporal attributes, including textual embeddings from crash narratives using a pretrained Sentence-BERT model. We evaluate various graph neural network (GNN) architectures, such as Graph Convolutional Networks (GCN), Graph Attention Networks (GAT), and Dynamic Spatio-Temporal GCN (DSTGCN), to classify crash severity and predict high-risk regions. Our proposed ST-GraphNet, which utilizes a DSTGCN backbone on the coarse-grained H3 graph, achieves a test accuracy of 97.74%, substantially outperforming the best fine-grained model (64.7% test accuracy). These findings highlight the effectiveness of spatial aggregation, dynamic message passing, and multi-modal feature integration in capturing the complex spatio-temporal patterns underlying AV crash severity.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the spatial and temporal dynamics of automated vehicle (AV)crash severity is critical for advancing urban mobility safety andinfrastructure planning. In this work, we introduce ST-GraphNet, aspatio-temporal graph neural network framework designed to model and predict AVcrash severity by using both fine-grained and region-aggregated spatial graphs.Using a balanced dataset of 2,352 real-world AV-related crash reports fromTexas (2024), including geospatial coordinates, crash timestamps, SAEautomation levels, and narrative descriptions, we construct two complementarygraph representations: (1) a fine-grained graph with individual crash events asnodes, where edges are defined via spatio-temporal proximity; and (2) acoarse-grained graph where crashes are aggregated into Hexagonal HierarchicalSpatial Indexing (H3)-based spatial cells, connected through hexagonaladjacency. Each node in the graph is enriched with multimodal data, includingsemantic, spatial, and temporal attributes, including textual embeddings fromcrash narratives using a pretrained Sentence-BERT model. We evaluate variousgraph neural network (GNN) architectures, such as Graph Convolutional Networks(GCN), Graph Attention Networks (GAT), and Dynamic Spatio-Temporal GCN(DSTGCN), to classify crash severity and predict high-risk regions. Ourproposed ST-GraphNet, which utilizes a DSTGCN backbone on the coarse-grained H3graph, achieves a test accuracy of 97.74\%, substantially outperforming thebest fine-grained model (64.7\% test accuracy). These findings highlight theeffectiveness of spatial aggregation, dynamic message passing, and multi-modalfeature integration in capturing the complex spatio-temporal patternsunderlying AV crash severity.</description>
      <author>example@mail.com (Mahmuda Sultana Mimi, Md Monzurul Islam, Anannya Ghosh Tusti, Shriyank Somvanshi, Subasish Das)</author>
      <guid isPermaLink="false">2506.08051v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Time Series Representations for Classification Lie Hidden in Pretrained Vision Transformers</title>
      <link>http://arxiv.org/abs/2506.08641v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TiViT的框架，该框架通过将时间序列转换为图像，利用在大型图像数据集上预训练的冻结视觉Transformer（ViTs）的表示能力，以解决时间序列分类问题。&lt;h4&gt;背景&lt;/h4&gt;时间序列分类在医疗和工业领域至关重要，但时间序列基础模型（TSFMs）的发展受到公开可用时间序列数据集稀缺的限制。&lt;h4&gt;目的&lt;/h4&gt;提出TiViT框架，以提高时间序列分类的性能。&lt;h4&gt;方法&lt;/h4&gt;1. 通过分析ViTs的2D补丁化，理论证明了其对于时间序列的增强表示能力。2. 实验表明，TiViT通过使用大型OpenCLIP模型的隐藏表示，在标准时间序列分类基准上达到了最先进的性能。3. 探索了TiViT表示的结构，发现具有高内在维度的中间层对于时间序列分类最为有效。4. 评估了TiViT与TSFM表示空间之间的对齐，并确定了它们之间的强互补性，通过结合其特征实现了进一步的性能提升。&lt;h4&gt;主要发现&lt;/h4&gt;1. ViTs的2D补丁化可以增加与标签相关的标记数量并降低样本复杂度。2. TiViT在标准时间序列分类基准上实现了最先进的性能。3. TiViT的中间层具有高内在维度，对于时间序列分类最为有效。4. TiViT与TSFM表示空间之间存在强互补性。&lt;h4&gt;结论&lt;/h4&gt;TiViT框架为在非视觉领域中重用视觉表示提供了另一个方向。&lt;h4&gt;翻译&lt;/h4&gt;时间序列分类是医疗和工业领域的一项基本任务，然而，由于公开可用的时间序列数据集稀缺，时间序列基础模型（TSFMs）的发展仍然有限。在这项工作中，我们提出了时间视觉Transformer（TiViT），这是一个将时间序列转换为图像的框架，以利用在大型图像数据集上预训练的冻结视觉Transformer（ViTs）的表示能力。首先，我们通过分析ViTs的2D补丁化，从理论上论证了我们的方法，表明它可以增加与标签相关的标记数量并减少样本复杂度。其次，我们通过利用大型OpenCLIP模型的隐藏表示，在标准时间序列分类基准上实证地展示了TiViT实现了最先进的性能。我们探索了TiViT表示的结构，并发现具有高内在维度的中间层对于时间序列分类最为有效。最后，我们评估了TiViT与TSFM表示空间之间的对齐，并确定了它们之间的强互补性，通过结合它们的特征实现了进一步的性能提升。我们的发现揭示了在非视觉领域中重用视觉表示的另一个方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series classification is a fundamental task in healthcare and industry,yet the development of time series foundation models (TSFMs) remains limited bythe scarcity of publicly available time series datasets. In this work, wepropose Time Vision Transformer (TiViT), a framework that converts time seriesinto images to leverage the representational power of frozen VisionTransformers (ViTs) pretrained on large-scale image datasets. First, wetheoretically motivate our approach by analyzing the 2D patching of ViTs fortime series, showing that it can increase the number of label-relevant tokensand reduce the sample complexity. Second, we empirically demonstrate that TiViTachieves state-of-the-art performance on standard time series classificationbenchmarks by utilizing the hidden representations of large OpenCLIP models. Weexplore the structure of TiViT representations and find that intermediatelayers with high intrinsic dimension are the most effective for time seriesclassification. Finally, we assess the alignment between TiViT and TSFMrepresentation spaces and identify a strong complementarity, with furtherperformance gains achieved by combining their features. Our findings reveal yetanother direction for reusing vision representations in a non-visual domain.</description>
      <author>example@mail.com (Simon Roschmann, Quentin Bouniot, Vasilii Feofanov, Ievgen Redko, Zeynep Akata)</author>
      <guid isPermaLink="false">2506.08641v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Hybrid Reasoning for Perception, Explanation, and Autonomous Action in Manufacturing</title>
      <link>http://arxiv.org/abs/2506.08462v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CIPHER的工业控制与解释框架，旨在通过混合专家知识和推理来提高工业过程的鲁棒性和适应性。&lt;h4&gt;背景&lt;/h4&gt;工业过程中的环境和任务往往不可预测，操作错误代价高昂且难以检测。基于AI的控制系统虽然具有潜力，但通常依赖于监督学习和大量标注数据，限制了其在变化和缺乏数据的工业环境中的应用。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够模仿人类推理的工业控制模型，并应用于商业级3D打印机。&lt;h4&gt;方法&lt;/h4&gt;CIPHER框架结合了过程专家、回归模型和检索增强生成技术，以实现外部专家知识的访问和物理信息化的推理。&lt;h4&gt;主要发现&lt;/h4&gt;CIPHER在处理分布外任务时表现出强大的泛化能力，能够解释视觉或文本输入，并自主生成精确的机器指令，无需显式标注。&lt;h4&gt;结论&lt;/h4&gt;CIPHER为自主系统奠定了基础，这些系统能够精确行动、根据上下文进行推理，并透明地传达决策，支持在工业环境中的安全可靠部署。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Industrial processes must be robust and adaptable, as environments and tasks are often unpredictable, while operational errors remain costly and difficult to detect. AI-based control systems offer a path forward, yet typically depend on supervised learning with extensive labelled datasets, which limits their ability to generalize across variable and data-scarce industrial settings. Foundation models could enable broader reasoning and knowledge integration, but rarely deliver the quantitative precision demanded by engineering applications. Here, we introduce Control and Interpretation of Production via Hybrid Expertise and Reasoning (CIPHER): a vision-language-action (VLA) model framework aiming to replicate human-like reasoning for industrial control, instantiated in a commercial-grade 3D printer. It integrates a process expert, a regression model enabling quantitative characterization of system states required for engineering tasks. CIPHER also incorporates retrieval-augmented generation to access external expert knowledge and support physics-informed, chain-of-thought reasoning. This hybrid architecture exhibits strong generalization to out-of-distribution tasks. It interprets visual or textual inputs from process monitoring, explains its decisions, and autonomously generates precise machine instructions, without requiring explicit annotations. CIPHER thus lays the foundations for autonomous systems that act with precision, reason with context, and communicate decisions transparently, supporting safe and trusted deployment in industrial settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Industrial processes must be robust and adaptable, as environments and tasksare often unpredictable, while operational errors remain costly and difficultto detect. AI-based control systems offer a path forward, yet typically dependon supervised learning with extensive labelled datasets, which limits theirability to generalize across variable and data-scarce industrial settings.Foundation models could enable broader reasoning and knowledge integration, butrarely deliver the quantitative precision demanded by engineering applications.Here, we introduceControl and Interpretation of Production via Hybrid Expertiseand Reasoning (CIPHER): a vision-language-action (VLA) model framework aimingto replicate human-like reasoning for industrial control, instantiated in acommercial-grade 3D printer. It integrates a process expert, a regression modelenabling quantitative characterization of system states required forengineering tasks. CIPHER also incorporates retrieval-augmented generation toaccess external expert knowledge and support physics-informed, chain-of-thoughtreasoning. This hybrid architecture exhibits strong generalization toout-of-distribution tasks. It interprets visual or textual inputs from processmonitoring, explains its decisions, and autonomously generates precise machineinstructions, without requiring explicit annotations. CIPHER thus lays thefoundations for autonomous systems that act with precision, reason withcontext, and communicate decisions transparently, supporting safe and trusteddeployment in industrial settings.</description>
      <author>example@mail.com (Christos Margadji, Sebastian W. Pattinson)</author>
      <guid isPermaLink="false">2506.08462v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>SHIELD: Multi-task Multi-distribution Vehicle Routing Solver with Sparsity and Hierarchy</title>
      <link>http://arxiv.org/abs/2506.08424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in the 42nd International Conference of Machine Learning  (ICML)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的多任务多分布车辆路径问题（MTMDVRP）模型SHIELD，该模型结合了稀疏性和层次性原则，并通过混合深度（MoD）技术和基于上下文的聚类层来提高效率和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基于深度学习的路由问题基础模型在处理多种VRP变体时显示出巨大潜力，但往往忽视了复杂真实世界的客户分布。&lt;h4&gt;目的&lt;/h4&gt;提高多任务VRP（MTVRP）设置到更真实、更具挑战性的多任务多分布VRP（MTMDVRP）设置，并开发一个能够有效处理这种复杂性的模型。&lt;h4&gt;方法&lt;/h4&gt;SHIELD模型通过以下方法实现：1. 使用混合深度（MoD）技术强制执行稀疏性，允许模型动态选择使用或跳过每个解码器层，以适应性地分配计算资源；2. 开发基于上下文的聚类层，利用问题中存在的层次结构产生更好的局部表示。&lt;h4&gt;主要发现&lt;/h4&gt;SHIELD模型能够识别出任务和分布之间的关键特征，显著提高了对未见过的任务的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;在9个真实地图上的16种VRP变体上的实证结果表明，该方法优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances toward foundation models for routing problems have shown great potential of a unified deep model for various VRP variants. However, they overlook the complex real-world customer distributions. In this work, we advance the Multi-Task VRP (MTVRP) setting to the more realistic yet challenging Multi-Task Multi-Distribution VRP (MTMDVRP) setting, and introduce SHIELD, a novel model that leverages both sparsity and hierarchy principles. Building on a deeper decoder architecture, we first incorporate the Mixture-of-Depths (MoD) technique to enforce sparsity. This improves both efficiency and generalization by allowing the model to dynamically select nodes to use or skip each decoder layer, providing the needed capacity to adaptively allocate computation for learning the task/distribution specific and shared representations. We also develop a context-based clustering layer that exploits the presence of hierarchical structures in the problems to produce better local representations. These two designs inductively bias the network to identify key features that are common across tasks and distributions, leading to significantly improved generalization on unseen ones. Our empirical results demonstrate the superiority of our approach over existing methods on 9 real-world maps with 16 VRP variants each.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances toward foundation models for routing problems have showngreat potential of a unified deep model for various VRP variants. However, theyoverlook the complex real-world customer distributions. In this work, weadvance the Multi-Task VRP (MTVRP) setting to the more realistic yetchallenging Multi-Task Multi-Distribution VRP (MTMDVRP) setting, and introduceSHIELD, a novel model that leverages both sparsity and hierarchy principles.Building on a deeper decoder architecture, we first incorporate theMixture-of-Depths (MoD) technique to enforce sparsity. This improves bothefficiency and generalization by allowing the model to dynamically select nodesto use or skip each decoder layer, providing the needed capacity to adaptivelyallocate computation for learning the task/distribution specific and sharedrepresentations. We also develop a context-based clustering layer that exploitsthe presence of hierarchical structures in the problems to produce better localrepresentations. These two designs inductively bias the network to identify keyfeatures that are common across tasks and distributions, leading tosignificantly improved generalization on unseen ones. Our empirical resultsdemonstrate the superiority of our approach over existing methods on 9real-world maps with 16 VRP variants each.</description>
      <author>example@mail.com (Yong Liang Goh, Zhiguang Cao, Yining Ma, Jianan Zhou, Mohammad Haroon Dupty, Wee Sun Lee)</author>
      <guid isPermaLink="false">2506.08424v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>H$^2$GFM: Towards unifying Homogeneity and Heterogeneity on Text-Attributed Graphs</title>
      <link>http://arxiv.org/abs/2506.08298v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为H^2GFM的新框架，旨在提高图基础模型（GFM）在处理不同类型图和任务时的泛化能力，特别是针对异构文本属性图（HeTAGs）。&lt;h4&gt;背景&lt;/h4&gt;图学习在多个领域的应用日益增加，推动了统一模型的发展，该模型称为图基础模型（GFM），能够很好地跨不同图和任务泛化。现有研究主要利用文本属性图（TAGs）来处理图之间节点特征的异质性，但主要关注同构文本属性图（HoTAGs），而对异构文本属性图（HeTAGs）的研究不足。&lt;h4&gt;目的&lt;/h4&gt;为了增强GFM的能力和应用，旨在提出一个能够泛化处理HoTAGs和HeTAGs的框架。&lt;h4&gt;方法&lt;/h4&gt;H^2GFM模型通过一个统一文本空间将图之间的各种元关系进行投影，并使用上下文编码来捕捉空间和高级语义关系。为了实现鲁棒的节点表示，提出了一个新颖的上下文自适应图变换器（CGT），有效捕捉上下文邻居及其关系的信息。此外，采用CGT专家混合方法来捕捉不同类型图之间的结构模式异质性。&lt;h4&gt;主要发现&lt;/h4&gt;在广泛的各种HoTAGs和HeTAGs以及学习场景上的综合实验表明，该模型是有效的。&lt;h4&gt;结论&lt;/h4&gt;H^2GFM框架能够有效提升GFM在处理不同类型图和任务时的泛化能力，特别是在处理异构文本属性图方面。&lt;h4&gt;翻译&lt;/h4&gt;The growing interests and applications of graph learning in diverse domains have propelled the development of a unified model generalizing well across different graphs and tasks, known as the Graph Foundation Model (GFM). Existing research has leveraged text-attributed graphs (TAGs) to tackle the heterogeneity in node features among graphs. However, they primarily focus on homogeneous TAGs (HoTAGs), leaving heterogeneous TAGs (HeTAGs), where multiple types of nodes/edges reside, underexplored. To enhance the capabilities and applications of GFM, we introduce H^2GFM, a novel framework designed to generalize across both HoTAGs and HeTAGs. Our model projects diverse meta-relations among graphs under a unified textual space, and employs a context encoding to capture spatial and higher-order semantic relationships. To achieve robust node representations, we propose a novel context-adaptive graph transformer (CGT), effectively capturing information from both context neighbors and their relationships. Furthermore, we employ a mixture of CGT experts to capture the heterogeneity in structural patterns among graph types. Comprehensive experiments on a wide range of HoTAGs and HeTAGs as well as learning scenarios demonstrate the effectiveness of our model.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing interests and applications of graph learning in diverse domainshave propelled the development of a unified model generalizing well acrossdifferent graphs and tasks, known as the Graph Foundation Model (GFM). Existingresearch has leveraged text-attributed graphs (TAGs) to tackle theheterogeneity in node features among graphs. However, they primarily focus onhomogeneous TAGs (HoTAGs), leaving heterogeneous TAGs (HeTAGs), where multipletypes of nodes/edges reside, underexplored. To enhance the capabilities andapplications of GFM, we introduce H$^2$GFM, a novel framework designed togeneralize across both HoTAGs and HeTAGs. Our model projects diversemeta-relations among graphs under a unified textual space, and employs acontext encoding to capture spatial and higher-order semantic relationships. Toachieve robust node representations, we propose a novel context-adaptive graphtransformer (CGT), effectively capturing information from both contextneighbors and their relationships. Furthermore, we employ a mixture of CGTexperts to capture the heterogeneity in structural patterns among graph types.Comprehensive experiments on a wide range of HoTAGs and HeTAGs as well aslearning scenarios demonstrate the effectiveness of our model.</description>
      <author>example@mail.com (Trung-Kien Nguyen, Heng Ping, Shixuan Li, Peiyu Zhang, Nikos Kanakaris, Nicholas Kotov, Paul Bogdan)</author>
      <guid isPermaLink="false">2506.08298v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Seeing Voices: Generating A-Roll Video from Audio with Mirage</title>
      <link>http://arxiv.org/abs/2506.08279v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report website: mirage.app/research/seeing-voices, product  website: mirage.app&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Mirage的音频到视频基础模型，该模型能够根据音频输入生成逼真的视频图像。&lt;h4&gt;背景&lt;/h4&gt;目前视频生成方法要么忽略声音专注于图像序列生成，要么虽然处理视觉和音频元素但仅限于特定应用领域，如配音。&lt;h4&gt;目的&lt;/h4&gt;提出一种音频到视频生成模型，能够从音频输入中生成具有表达性的视频图像。&lt;h4&gt;方法&lt;/h4&gt;Mirage模型结合了语音合成技术和自注意力机制，能够根据包含语音的音频生成视频。&lt;h4&gt;主要发现&lt;/h4&gt;Mirage模型能够生成高质量的视频输出，且在音频到视频生成方面具有通用性。&lt;h4&gt;结论&lt;/h4&gt;Mirage模型为音频到视频生成提供了一种有效的方法，并鼓励读者亲自体验其效果。&lt;h4&gt;翻译&lt;/h4&gt;从专业电影制作到用户生成内容，创作者和消费者长期以来都认识到视频的力量取决于我们听到的（视频的音频轨道）和我们看到的（视频的图像序列）之间的和谐结合。当前的视频生成方法要么忽略声音以专注于通用但无声的图像序列生成，要么处理视觉和音频元素但仅限于配音等特定应用领域。我们介绍了Mirage，这是一种音频到视频的基础模型，能够从零开始根据音频输入生成逼真的、具有表现力的输出图像。当与现有的语音合成方法（如文本到语音或TTS）集成时，Mirage可以生成引人入胜的多模态视频。当在包含语音的音频视频素材（A卷）上训练，并基于包含语音的音频进行条件化时，Mirage可以生成人们根据输入音频中隐含的表现进行可信诠释的视频。我们主要的技术贡献是统一了训练基于自注意力的音频到视频生成模型的方法，无论是从头开始还是基于现有权重。这种方法使得Mirage在音频到视频生成方面保持了通用性，同时产生了比结合特定于音频架构或针对人、语音或图像或音频捕获细节的损失组件的方法具有更高主观质量的输出。我们鼓励读者亲自观看和聆听Mirage的结果（见论文和评论中的链接）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; From professional filmmaking to user-generated content, creators andconsumers have long recognized that the power of video depends on theharmonious integration of what we hear (the video's audio track) with what wesee (the video's image sequence). Current approaches to video generation eitherignore sound to focus on general-purpose but silent image sequence generationor address both visual and audio elements but focus on restricted applicationdomains such as re-dubbing. We introduce Mirage, an audio-to-video foundationmodel that excels at generating realistic, expressive output imagery fromscratch given an audio input. When integrated with existing methods for speechsynthesis (text-to-speech, or TTS), Mirage results in compelling multimodalvideo. When trained on audio-video footage of people talking (A-roll) andconditioned on audio containing speech, Mirage generates video of peopledelivering a believable interpretation of the performance implicit in inputaudio. Our central technical contribution is a unified method for trainingself-attention-based audio-to-video generation models, either from scratch orgiven existing weights. This methodology allows Mirage to retain generality asan approach to audio-to-video generation while producing outputs of superiorsubjective quality to methods that incorporate audio-specific architectures orloss components specific to people, speech, or details of how images or audioare captured. We encourage readers to watch and listen to the results of Miragefor themselves (see paper and comments for links).</description>
      <author>example@mail.com (Aditi Sundararaman, Amogh Adishesha, Andrew Jaegle, Dan Bigioi, Hyoung-Kyu Song, Jon Kyl, Justin Mao, Kevin Lan, Mojtaba Komeili, ShahRukh Athar, Sheila Babayan, Stanislau Beliasau, William Buchwalter)</author>
      <guid isPermaLink="false">2506.08279v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Pre-Trained Time Series Models for Electricity Price Forecasting</title>
      <link>http://arxiv.org/abs/2506.08113v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了电力价格预测（EPF）在现货市场交易决策中的重要性，并比较了多种时间序列基础模型（TSFMs）在EPF中的有效性。&lt;h4&gt;背景&lt;/h4&gt;虽然近年来生成人工智能（GenAI）和预训练的大型语言模型（LLMs）的发展促进了时间序列基础模型（TSFMs）的众多时间序列预测方法，但这些模型在EPF中的有效性尚不确定。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一差距，本文对比了多个最先进的预训练模型（Chronos-Bolt、Chronos-T5、TimesFM、Moirai、Time-MoE和TimeGPT）与已建立的统计和机器学习（ML）方法在EPF中的性能。&lt;h4&gt;方法&lt;/h4&gt;使用来自德国、法国、荷兰、奥地利和比利时2024年的日间拍卖（DAA）电力价格数据，对模型进行了一天的每日预测。&lt;h4&gt;主要发现&lt;/h4&gt;Chronos-Bolt和Time-MoE在TSFMs中表现最强，与传统模型表现相当。然而，双季节性MSTL模型在多个国家和评估指标上表现出色，没有TSFM在统计上优于它。&lt;h4&gt;结论&lt;/h4&gt;本文的研究结果表明，尽管某些TSFMs在EPF中表现出色，但双季节性MSTL模型在多个国家和评估指标上的一致性能表现尤为突出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate electricity price forecasting (EPF) is crucial for effectivedecision-making in power trading on the spot market. While recent advances ingenerative artificial intelligence (GenAI) and pre-trained large languagemodels (LLMs) have inspired the development of numerous time series foundationmodels (TSFMs) for time series forecasting, their effectiveness in EPF remainsuncertain. To address this gap, we benchmark several state-of-the-artpretrained models--Chronos-Bolt, Chronos-T5, TimesFM, Moirai, Time-MoE, andTimeGPT--against established statistical and machine learning (ML) methods forEPF. Using 2024 day-ahead auction (DAA) electricity prices from Germany,France, the Netherlands, Austria, and Belgium, we generate daily forecasts witha one-day horizon. Chronos-Bolt and Time-MoE emerge as the strongest among theTSFMs, performing on par with traditional models. However, the biseasonal MSTLmodel, which captures daily and weekly seasonality, stands out for itsconsistent performance across countries and evaluation metrics, with no TSFMstatistically outperforming it.</description>
      <author>example@mail.com (Timothée Hornek Amir Sartipi, Igor Tchappi, Gilbert Fridgen)</author>
      <guid isPermaLink="false">2506.08113v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>LSM-2: Learning from Incomplete Wearable Sensor Data</title>
      <link>http://arxiv.org/abs/2506.05321v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Xu and Narayanswamy are co-first authors. McDuff and Liu are co-last  authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了第二代大传感器模型（LSM-2）与自适应和继承掩码（AIM）的结合，这是一种新型的自监督学习（SSL）方法，可以直接从数据缺失的情况下学习稳健的表示，而无需显式地进行数据填充。&lt;h4&gt;背景&lt;/h4&gt;基础模型是机器学习近期进展的核心，但可穿戴传感器数据通常存在大量缺失，这对通常假设完整数据输入的自监督学习模型构成了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的SSL方法，能够从缺失数据中学习，以解决可穿戴传感器数据中缺失数据的问题。&lt;h4&gt;方法&lt;/h4&gt;引入了LSM-2与AIM的结合，其中AIM使用可学习的掩码标记来模拟现有的（继承的）和人为引入的缺失数据，从而在推理过程中稳健地处理碎片化的真实世界数据。&lt;h4&gt;主要发现&lt;/h4&gt;LSM-2与AIM在40M小时的日间多模态传感器数据集上进行了预训练，并在包括分类、回归和生成建模在内的各种任务中实现了最佳性能。此外，LSM-2与AIM展现出优异的扩展性能，并且在目标缺失场景下仍能保持高性能，反映了临床一致的模式，如夜间生物信号在高血压预测中的诊断价值。&lt;h4&gt;结论&lt;/h4&gt;AIM为实际的可穿戴数据应用提供了一个更可靠的解决方案，因为它能够处理缺失数据并维持高精度。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型是近期机器学习进步的基石，它们主要依赖于完整且结构良好的数据。可穿戴传感器数据常常存在显著的缺失，这对通常假设完整数据输入的自监督学习（SSL）模型构成了重大挑战。本文介绍了第二代大传感器模型（LSM-2）与自适应和继承掩码（AIM）的结合，这是一种新颖的自监督学习（SSL）方法，可以直接从数据缺失的情况下学习稳健的表示，而无需显式地进行数据填充。AIM的核心创新在于其使用可学习的掩码标记来模拟现有的（继承的）和人为引入的缺失数据，使得它能够在推理过程中稳健地处理碎片化的真实世界数据。在40M小时的日间多模态传感器数据集上预训练后，我们的LSM-2与AIM在包括分类、回归和生成建模在内的各种任务中实现了最佳性能。此外，LSM-2与AIM展现出优异的扩展性能，并且关键的是，即使在目标缺失场景下也能保持高性能，反映了临床一致的模式，如夜间生物信号在高血压预测中的诊断价值。这使得AIM成为实际可穿戴数据应用的一个更可靠的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models, a cornerstone of recent advancements in machine learning,have predominantly thrived on complete and well-structured data. Wearablesensor data frequently suffers from significant missingness, posing asubstantial challenge for self-supervised learning (SSL) models that typicallyassume complete data inputs. This paper introduces the second generation ofLarge Sensor Model (LSM-2) with Adaptive and Inherited Masking (AIM), a novelSSL approach that learns robust representations directly from incomplete datawithout requiring explicit imputation. AIM's core novelty lies in its use oflearnable mask tokens to model both existing ("inherited") and artificiallyintroduced missingness, enabling it to robustly handle fragmented real-worlddata during inference. Pre-trained on an extensive dataset of 40M hours ofday-long multimodal sensor data, our LSM-2 with AIM achieves the bestperformance across a diverse range of tasks, including classification,regression and generative modeling. Furthermore, LSM-2 with AIM exhibitssuperior scaling performance, and critically, maintains high performance evenunder targeted missingness scenarios, reflecting clinically coherent patterns,such as the diagnostic value of nighttime biosignals for hypertensionprediction. This makes AIM a more reliable choice for real-world wearable dataapplications.</description>
      <author>example@mail.com (Maxwell A. Xu, Girish Narayanswamy, Kumar Ayush, Dimitris Spathis, Shun Liao, Shyam A. Tailor, Ahmed Metwally, A. Ali Heydari, Yuwei Zhang, Jake Garrison, Samy Abdel-Ghaffar, Xuhai Xu, Ken Gu, Jacob Sunshine, Ming-Zher Poh, Yun Liu, Tim Althoff, Shrikanth Narayanan, Pushmeet Kohli, Mark Malhotra, Shwetak Patel, Yuzhe Yang, James M. Rehg, Xin Liu, Daniel McDuff)</author>
      <guid isPermaLink="false">2506.05321v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
  <item>
      <title>Diffusion Counterfactual Generation with Semantic Abduction</title>
      <link>http://arxiv.org/abs/2506.07883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of the 42nd International Conference on Machine Learning,  Vancouver, Canada&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散模型的因果机制，用于改进反事实图像生成，旨在解决身份保持、感知质量和因果模型忠实度等挑战。&lt;h4&gt;背景&lt;/h4&gt;反事实图像生成在保持身份、维护感知质量和确保对底层因果模型的忠实度方面存在重大挑战。现有的自动编码框架虽然允许操纵语义潜在空间以进行因果控制，但面临着可扩展性和忠实度的问题。&lt;h4&gt;目的&lt;/h4&gt;通过提出一套基于扩散的因果机制，本文旨在提高反事实图像编辑的质量，并引入空间、语义和动态推理的概念。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种将语义表示整合到扩散模型中的通用框架，通过Pearlian因果性的视角，通过反事实推理过程编辑图像。&lt;h4&gt;主要发现&lt;/h4&gt;这是首次考虑为扩散反事实图像生成提供高级语义身份保持的工作，并展示了语义控制如何实现忠实因果控制和身份保持之间的原则性权衡。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在视觉质量、人类感知和表示学习方面取得了最先进的成果，为反事实图像生成提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Counterfactual image generation presents significant challenges, includingpreserving identity, maintaining perceptual quality, and ensuring faithfulnessto an underlying causal model. While existing auto-encoding frameworks admitsemantic latent spaces which can be manipulated for causal control, theystruggle with scalability and fidelity. Advancements in diffusion modelspresent opportunities for improving counterfactual image editing, havingdemonstrated state-of-the-art visual quality, human-aligned perception andrepresentation learning capabilities. Here, we present a suite ofdiffusion-based causal mechanisms, introducing the notions of spatial, semanticand dynamic abduction. We propose a general framework that integrates semanticrepresentations into diffusion models through the lens of Pearlian causality toedit images via a counterfactual reasoning process. To our knowledge, this isthe first work to consider high-level semantic identity preservation fordiffusion counterfactuals and to demonstrate how semantic control enablesprincipled trade-offs between faithful causal control and identitypreservation.</description>
      <author>example@mail.com (Rajat Rasal, Avinash Kori, Fabio De Sousa Ribeiro, Tian Xia, Ben Glocker)</author>
      <guid isPermaLink="false">2506.07883v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Gradients: When Markets Meet Fine-tuning -- A Distributed Approach to Model Optimisation</title>
      <link>http://arxiv.org/abs/2506.07940v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Gradients，一个将超参数优化转化为竞争市场的去中心化AutoML平台，通过经济激励机制实现个人探索与集体优化目标的统一，从而系统性地发现中心化方法遗漏的更优配置。&lt;h4&gt;背景&lt;/h4&gt;现有的AutoML平台依赖单一优化策略，只探索了一小部分可行的超参数配置，导致优化效果受限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过去中心化的AutoML平台，提高超参数优化的效果。&lt;h4&gt;方法&lt;/h4&gt;Gradients平台将超参数优化转化为竞争市场，独立矿工通过竞争发现最优配置，并利用经济激励机制驱动系统性的探索。&lt;h4&gt;主要发现&lt;/h4&gt;在180个控制实验中，Gradients平台在各种模型架构和任务类型上均取得了显著的效果，平均提升11.8%，在特定任务类型上提升高达30-40%。&lt;h4&gt;结论&lt;/h4&gt;竞争性和经济驱动的AutoML方法可以系统地发现中心化方法遗漏的更优配置，从而提高优化效果。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces Gradients, a decentralized AutoML platform that transforms hyperparameter optimization into a competitive marketplace where independent miners compete to discover optimal configurations. Economic incentives align individual exploration with collective optimization goals, driving systematic investigation of hyperparameter regions that centralized methods miss. We evaluate our approach across 180 controlled experiments spanning diverse model architectures (70M to 70B parameters) and task types. Gradients achieves an 82.8% win rate against HuggingFace AutoTrain and 100% against TogetherAI, Databricks, and Google Cloud, with mean improvements of 11.8% and 42.1% respectively. Complex reasoning and retrieval tasks show particularly strong gains of 30-40%, while diffusion models achieve 23.4% improvements for person-specific generation. These results demonstrate that competitive, economically-driven approaches can systematically discover superior configurations that centralized AutoML consistently miss.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation model fine-tuning faces a fundamental challenge: existing AutoMLplatforms rely on single optimisation strategies that explore only a fractionof viable hyperparameter configurations. In this white paper, We introduceGradients, a decentralised AutoML platform that transforms hyperparameteroptimisation into a competitive marketplace where independent miners compete todiscover optimal configurations. Economic incentives align individualexploration with collective optimisation goals, driving systematicinvestigation of hyperparameter regions that centralised methods miss. Weevaluate our approach across 180 controlled experiments spanning diverse modelarchitectures (70M to 70B parameters) and task types. Gradients achieves an82.8\% win rate against HuggingFace AutoTrain and 100\% against TogetherAI,Databricks, and Google Cloud, with mean improvements of 11.8\% and 42.1\%respectively. Complex reasoning and retrieval tasks show particularly stronggains of 30-40\%, whilst diffusion models achieve 23.4\% improvements forperson-specific generation. These results demonstrate that competitive,economically-driven approaches can systematically discover superiorconfigurations that centralised AutoML consistently miss.</description>
      <author>example@mail.com (Christopher Subia-Waud)</author>
      <guid isPermaLink="false">2506.07940v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence</title>
      <link>http://arxiv.org/abs/2506.07966v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SpaCE-10是一个针对多模态大型语言模型（MLLMs）在空间智能方面进行综合评估的基准。&lt;h4&gt;背景&lt;/h4&gt;MLLMs在多模态任务上取得了显著进步，但现有的基准难以全面评估MLLMs从原子级到组合级的空间智能。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，提出SpaCE-10，一个用于组合空间评估的综合基准。&lt;h4&gt;方法&lt;/h4&gt;定义了10个原子空间能力，组合成8个组合能力，并提出了一个新颖的分层标注流程来生成高质量和多样化的问答对。通过超过150小时的人类专家努力，获得了超过5000个问答对，涵盖811个真实室内场景，包括点云输入和多选题问答。&lt;h4&gt;主要发现&lt;/h4&gt;发现即使是最高级的MLLM，在空间智能方面也远远落后于人类。揭示了计数能力的不足大大限制了现有MLLMs的组合空间能力。&lt;h4&gt;结论&lt;/h4&gt;SpaCE-10为MLLM社区提供了有益的发现和评估工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态大型语言模型（MLLMs）在多种多模态任务上取得了显著的进步。为了在空间中追求更高的智能，MLLMs需要整合多个原子空间能力来处理复杂和动态的任务。然而，现有的基准难以从原子级到组合级全面评估常见MLLMs的空间智能。为了填补这一空白，我们提出了SpaCE-10，一个用于组合空间评估的综合基准。在SpaCE-10中，我们定义了10个原子空间能力，这些能力组合形成了8个组合能力。基于这些定义，我们提出了一种新颖的分层标注流程来生成高质量和多样化的问答对。通过超过150小时的人类专家努力，我们获得了超过5000个问答对，涵盖了811个真实室内场景，包括点云输入和多选题问答。我们在SpaCE-10上对常见MLLMs进行了广泛的评估，发现即使是最高级的MLLM，在空间智能方面也远远落后于人类。通过我们的仔细研究，我们还得出了几个对MLLM社区有益的重要发现。例如，我们揭示了计数能力的不足大大限制了现有MLLMs的组合空间能力。评估代码和基准数据集可在https://github.com/Cuzyoung/SpaCE-10找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have achieved remarkable progress invarious multimodal tasks. To pursue higher intelligence in space, MLLMs requireintegrating multiple atomic spatial capabilities to handle complex and dynamictasks. However, existing benchmarks struggle to comprehensively evaluate thespatial intelligence of common MLLMs from the atomic level to the compositionallevel. To fill this gap, we present SpaCE-10, a comprehensive benchmark forcompositional spatial evaluations. In SpaCE-10, we define 10 atomic spatialcapabilities, which are combined to form 8 compositional capabilities. Based onthese definitions, we propose a novel hierarchical annotation pipeline togenerate high-quality and diverse question-answer (QA) pairs. With over 150+hours of human expert effort, we obtain over 5k QA pairs for 811 real indoorscenes in SpaCE-10, which covers various evaluation settings like point cloudinput and multi-choice QA. We conduct an extensive evaluation of common MLLMson SpaCE-10 and find that even the most advanced MLLM still lags behind humansby large margins. Through our careful study, we also draw several significantfindings that benefit the MLLM community. For example, we reveal that theshortcoming of counting capability greatly limits the compositional spatialcapabilities of existing MLLMs. The evaluation code and benchmark datasets areavailable at https://github.com/Cuzyoung/SpaCE-10.</description>
      <author>example@mail.com (Ziyang Gong, Wenhao Li, Oliver Ma, Songyuan Li, Jiayi Ji, Xue Yang, Gen Luo, Junchi Yan, Rongrong Ji)</author>
      <guid isPermaLink="false">2506.07966v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>CyberV: Cybernetics for Test-time Scaling in Video Understanding</title>
      <link>http://arxiv.org/abs/2506.07971v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于控制论原理的新型框架，旨在解决现有多模态大型语言模型在处理长或复杂视频时的局限性，如计算需求高、鲁棒性差和准确性有限等问题。&lt;h4&gt;背景&lt;/h4&gt;现有多模态大型语言模型在处理长或复杂视频时存在计算需求高、鲁棒性差和准确性有限等问题，这些问题主要源于其前馈处理性质，尤其是在参数较少的模型中更为严重。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了一种名为CyberV的框架，旨在设计能够自我监控、自我纠正和动态资源分配的视频多模态大型语言模型。&lt;h4&gt;方法&lt;/h4&gt;CyberV框架包括一个多模态大型语言模型推理系统、一个传感器和一个控制器。传感器监控多模态大型语言模型的前向过程，收集中间解释，如注意力漂移；控制器决定何时以及如何触发自我纠正并生成反馈以指导下一轮。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CyberV在VideoMMMU上提升了Qwen2.5-VL-7B模型8.3%，在InternVL3-8B上提升了5.5%，超过了竞争性的GPT-4o模型。在Qwen2.5-VL-72B上应用时，提升了10.0%，其性能甚至可与人类专家相媲美。此外，该方法在VideoMME和WorldSense等通用基准测试中也表现出一致的收益，突显了其在使多模态大型语言模型更鲁棒和准确地进行动态视频理解方面的有效性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;CyberV框架能够有效提升多模态大型语言模型在动态视频理解任务中的性能，且无需重新训练或添加额外组件。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current Multimodal Large Language Models (MLLMs) may struggle withunderstanding long or complex videos due to computational demands at test time,lack of robustness, and limited accuracy, primarily stemming from theirfeed-forward processing nature. These limitations could be more severe formodels with fewer parameters. To address these limitations, we propose a novelframework inspired by cybernetic principles, redesigning video MLLMs asadaptive systems capable of self-monitoring, self-correction, and dynamicresource allocation during inference. Our approach, CyberV, introduces acybernetic loop consisting of an MLLM Inference System, a Sensor, and aController. Specifically, the sensor monitors forward processes of the MLLM andcollects intermediate interpretations, such as attention drift, then thecontroller determines when and how to trigger self-correction and generatefeedback to guide the next round. This test-time adaptive scaling frameworkenhances frozen MLLMs without requiring retraining or additional components.Experiments demonstrate significant improvements: CyberV boosts Qwen2.5-VL-7Bby 8.3% and InternVL3-8B by 5.5% on VideoMMMU, surpassing the competitiveproprietary model GPT-4o. When applied to Qwen2.5-VL-72B, it yields a 10.0%improvement, achieving performance even comparable to human experts.Furthermore, our method demonstrates consistent gains on general-purposebenchmarks, such as VideoMME and WorldSense, highlighting its effectiveness andgeneralization capabilities in making MLLMs more robust and accurate fordynamic video understanding. The code is released athttps://github.com/marinero4972/CyberV.</description>
      <author>example@mail.com (Jiahao Meng, Shuyang Sun, Yue Tan, Lu Qi, Yunhai Tong, Xiangtai Li, Longyin Wen)</author>
      <guid isPermaLink="false">2506.07971v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Language Embedding Meets Dynamic Graph: A New Exploration for Neural Architecture Representation Learning</title>
      <link>http://arxiv.org/abs/2506.07735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LeDG-Former的创新框架，通过结合语言语义嵌入和动态图表示学习来克服现有方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;神经网络架构表示学习在部署和设计网络以应用于现实世界方面发挥着关键作用。基于transformers的模型与图神经网络（GNNs）的集成在表示学习方面取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法忽视硬件属性信息以及编码方法依赖静态邻接矩阵的局限性。&lt;h4&gt;方法&lt;/h4&gt;引入LeDG-Former框架，该框架通过结合语言语义嵌入和动态图表示学习，将神经网络架构和硬件平台规范投影到一个统一的语义空间中，实现不同硬件平台间的零样本预测。&lt;h4&gt;主要发现&lt;/h4&gt;LeDG-Former在NNLQP基准测试中超越了之前的方法，建立了新的SOTA，并展示了首次成功实现跨硬件延迟预测的能力。此外，该框架在cell-structured NAS-Bench-101和NAS-Bench-201数据集上也取得了优越的性能。&lt;h4&gt;结论&lt;/h4&gt;LeDG-Former框架有效地解决了现有方法的局限性，为神经网络架构表示学习提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural Architecture Representation Learning aims to transform network modelsinto feature representations for predicting network attributes, playing acrucial role in deploying and designing networks for real-world applications.Recently, inspired by the success of transformers, transformer-based modelsintegrated with Graph Neural Networks (GNNs) have achieved significant progressin representation learning. However, current methods still have somelimitations. First, existing methods overlook hardware attribute information,which conflicts with the current trend of diversified deep learning hardwareand limits the practical applicability of models. Second, current encodingapproaches rely on static adjacency matrices to represent topologicalstructures, failing to capture the structural differences between computationalnodes, which ultimately compromises encoding effectiveness. In this paper, weintroduce LeDG-Former, an innovative framework that addresses these limitationsthrough the synergistic integration of language-based semantic embedding anddynamic graph representation learning. Specifically, inspired by large languagemodels (LLMs), we propose a language embedding framework where both neuralarchitectures and hardware platform specifications are projected into a unifiedsemantic space through tokenization and LLM processing, enabling zero-shotprediction across different hardware platforms for the first time. Then, wepropose a dynamic graph-based transformer for modeling neural architectures,resulting in improved neural architecture modeling performance. On the NNLQPbenchmark, LeDG-Former surpasses previous methods, establishing a new SOTAwhile demonstrating the first successful cross-hardware latency predictioncapability. Furthermore, our framework achieves superior performance on thecell-structured NAS-Bench-101 and NAS-Bench-201 datasets.</description>
      <author>example@mail.com (Haizhao Jing, Haokui Zhang, Zhenhao Shang, Rong Xiao, Peng Wang, Yanning Zhang)</author>
      <guid isPermaLink="false">2506.07735v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Image Reconstruction as a Tool for Feature Analysis</title>
      <link>http://arxiv.org/abs/2506.07803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过图像重建来解释视觉特征的新方法，并分析了不同视觉编码器内部特征表示的差异。&lt;h4&gt;背景&lt;/h4&gt;视觉编码器在现代应用中越来越受欢迎，但它们的内部特征表示方式尚不明确。&lt;h4&gt;目的&lt;/h4&gt;研究视觉编码器内部特征表示的方式，并评估不同模型在图像信息保留方面的表现。&lt;h4&gt;方法&lt;/h4&gt;提出了SigLIP和SigLIP2两种模型，通过比较它们的训练目标，发现基于图像任务的预训练编码器比基于非图像任务的编码器保留了更多的图像信息。此外，通过操纵特征空间来分析重建图像的变化，揭示颜色编码的控制方式。&lt;h4&gt;主要发现&lt;/h4&gt;基于图像任务的预训练编码器比基于非图像任务的编码器保留了更多的图像信息；通过操纵特征空间可以预测性地改变重建图像；正交旋转控制颜色编码。&lt;h4&gt;结论&lt;/h4&gt;该方法可以应用于任何视觉编码器，有助于揭示其特征空间的内部结构。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉编码器在现代应用中越来越受欢迎，从仅视觉模型到多模态系统如视觉-语言模型。尽管它们取得了显著的成功，但它们如何内部表示特征仍然不清楚。在这里，我们提出了一种通过图像重建来解释视觉特征的新方法。我们比较了两个相关的模型家族，SigLIP和SigLIP2，它们在训练目标上有所不同，并表明在基于图像任务的预训练上的编码器比在基于非图像任务（如对比学习）的编码器上保留了更多的图像信息。我们进一步将我们的方法应用于一系列视觉编码器，按照其特征表示的信息量对它们进行排名。最后，我们表明，操纵特征空间会导致重建图像的可预测变化，揭示了正交旋转（而不是空间变换）控制颜色编码。我们的方法可以应用于任何视觉编码器，有助于揭示其特征空间的内部结构。用于重现实验的代码和模型权重可在GitHub上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision encoders are increasingly used in modern applications, fromvision-only models to multimodal systems such as vision-language models.Despite their remarkable success, it remains unclear how these architecturesrepresent features internally. Here, we propose a novel approach forinterpreting vision features via image reconstruction. We compare two relatedmodel families, SigLIP and SigLIP2, which differ only in their trainingobjective, and show that encoders pre-trained on image-based tasks retainsignificantly more image information than those trained on non-image tasks suchas contrastive learning. We further apply our method to a range of visionencoders, ranking them by the informativeness of their feature representations.Finally, we demonstrate that manipulating the feature space yields predictablechanges in reconstructed images, revealing that orthogonal rotations (ratherthan spatial transformations) control color encoding. Our approach can beapplied to any vision encoder, shedding light on the inner structure of itsfeature space. The code and model weights to reproduce the experiments areavailable in GitHub.</description>
      <author>example@mail.com (Eduard Allakhverdov, Dmitrii Tarasov, Elizaveta Goncharova, Andrey Kuznetsov)</author>
      <guid isPermaLink="false">2506.07803v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>CrosswalkNet: An Optimized Deep Learning Framework for Pedestrian Crosswalk Detection in Aerial Images with High-Performance Computing</title>
      <link>http://arxiv.org/abs/2506.07885v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了CrosswalkNet，一个用于从高分辨率航空图像中检测各类人行横道的深度学习框架，旨在提高交通资产管理、安全分析和城市规划的效率。&lt;h4&gt;背景&lt;/h4&gt;随着航空和卫星图像的广泛应用，深度学习在交通资产管理、安全分析和城市规划方面具有巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够准确检测人行横道的深度学习框架。&lt;h4&gt;方法&lt;/h4&gt;CrosswalkNet采用了一种新颖的检测方法，使用定向边界框（OBB）提高检测精度，并通过卷积块注意力、双分支空间金字塔池化快速模块和余弦退火等优化技术来最大化性能和效率。研究使用了包含超过23,000个标注人行横道实例的综合数据集来训练和验证该框架。&lt;h4&gt;主要发现&lt;/h4&gt;最佳模型在马萨诸塞州的航空图像上实现了96.5%的精确率和93.3%的召回率。CrosswalkNet在没有迁移学习或微调的情况下成功应用于新罕布什尔州、弗吉尼亚州和缅因州的数据集。使用高性能计算（HPC）平台处理的人行横道检测结果以多边形形状文件格式提供，加速了数据处理和检测，支持实时分析和安全与移动性应用。&lt;h4&gt;结论&lt;/h4&gt;CrosswalkNet是一个准确且有效的工具，能够增强行人安全并改善城市流动性，为政策制定者、交通工程师和城市规划者提供了有效的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着航空和卫星图像的日益可用，深度学习在交通资产管理、安全分析和城市规划方面具有显著潜力。本研究介绍了CrosswalkNet，这是一个强大且高效的深度学习框架，旨在从15厘米分辨率的航空图像中检测各种类型的人行横道。CrosswalkNet采用了一种新颖的检测方法，通过使用定向边界框（OBB）改进了传统的目标检测策略，无论横道方向如何，都能准确地捕获横道。研究实现了包括卷积块注意力、双分支空间金字塔池化快速模块和余弦退火在内的多种优化技术，以最大化性能和效率。研究使用了包含超过23,000个标注人行横道实例的综合数据集来训练和验证所提出的框架。性能最佳的模型在马萨诸塞州的航空图像上实现了令人印象深刻的96.5%的精确率和93.3%的召回率，证明了其准确性和有效性。CrosswalkNet还成功应用于新罕布什尔州、弗吉尼亚州和缅因州的数据集，无需迁移学习或微调，展示了其鲁棒性和强大的泛化能力。此外，使用高性能计算（HPC）平台处理的人行横道检测结果以多边形形状文件格式提供，已显示出加速数据处理和检测的能力，支持安全性和移动性应用的实时分析。这种集成为政策制定者、交通工程师和城市规划者提供了一个有效的工具，以增强行人安全并改善城市流动性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the increasing availability of aerial and satellite imagery, deeplearning presents significant potential for transportation asset management,safety analysis, and urban planning. This study introduces CrosswalkNet, arobust and efficient deep learning framework designed to detect various typesof pedestrian crosswalks from 15-cm resolution aerial images. CrosswalkNetincorporates a novel detection approach that improves upon traditional objectdetection strategies by utilizing oriented bounding boxes (OBB), enhancingdetection precision by accurately capturing crosswalks regardless of theirorientation. Several optimization techniques, including Convolutional BlockAttention, a dual-branch Spatial Pyramid Pooling-Fast module, and cosineannealing, are implemented to maximize performance and efficiency. Acomprehensive dataset comprising over 23,000 annotated crosswalk instances isutilized to train and validate the proposed framework. The best-performingmodel achieves an impressive precision of 96.5% and a recall of 93.3% on aerialimagery from Massachusetts, demonstrating its accuracy and effectiveness.CrosswalkNet has also been successfully applied to datasets from New Hampshire,Virginia, and Maine without transfer learning or fine-tuning, showcasing itsrobustness and strong generalization capability. Additionally, the crosswalkdetection results, processed using High-Performance Computing (HPC) platformsand provided in polygon shapefile format, have been shown to accelerate dataprocessing and detection, supporting real-time analysis for safety and mobilityapplications. This integration offers policymakers, transportation engineers,and urban planners an effective instrument to enhance pedestrian safety andimprove urban mobility.</description>
      <author>example@mail.com (Zubin Bhuyan, Yuanchang Xie, AngkeaReach Rith, Xintong Yan, Nasko Apostolov, Jimi Oke, Chengbo Ai)</author>
      <guid isPermaLink="false">2506.07885v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>A Temporal FRBR/FRBRoo-Based Model for Component-Level Versioning of Legal Norms</title>
      <link>http://arxiv.org/abs/2506.07853v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结构化时间模型，扩展了FRBRoo框架，以解决法律规范自动处理中的关键挑战，特别是在追踪其层次化组件（如文章、段落）的历时演变。&lt;h4&gt;背景&lt;/h4&gt;目前，虽然FRBR/FRBRoo等基础框架和Akoma Ntoso等标准在宏观层面模型化了法律文件，但它们缺乏原生机制来进行细粒度、组件级别的版本控制，这阻碍了法律文本在特定时间点的确定性重建。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种能够精确、确定地检索和重建法律文本在特定日期状态的模型，为可靠的法律技术和AI应用提供基础。&lt;h4&gt;方法&lt;/h4&gt;提出了一种结构化时间模型，引入了Expressio - Temporal Version (TV)和Language Version (LV)等专门子类来表示法律规范及其语言变体在特定时间点的状态，并应用于层次化结构，引入Component Work (CW)、Component Temporal Version (CTV)和Component Language Version (CLV)来追踪个别文章、段落和条款的生命周期。&lt;h4&gt;主要发现&lt;/h4&gt;以巴西联邦宪法为案例研究，展示了每个修正案如何为受影响的条款创建新的Component Temporal Versions，而未受影响的组件则保留其现有版本。&lt;h4&gt;结论&lt;/h4&gt;该模型为开发高级法律信息系统、知识图谱和能够进行准确历史分析和影响评估的AI工具提供了坚实的基础，克服了当前生成模型的局限性。&lt;h4&gt;翻译&lt;/h4&gt;有效地表示用于自动处理的法律规范是一个关键挑战，尤其是在追踪其层次化组件（例如，文章、段落）的历时演变方面。虽然像FRBR/FRBRoo这样的基础框架和像Akoma Ntoso这样的标准在宏观层面模型化了法律文件，但它们缺乏原生机制来进行细粒度、组件级别的版本控制。这种限制阻碍了法律文本在特定时间点的确定性重建，这是可靠的法律技术和AI应用的基本能力。本文提出了一种结构化时间模型，扩展了FRBRoo框架来填补这一空白。它引入了Expressio - Temporal Version (TV)和Language Version (LV)等专门子类来表示法律规范及其语言变体在特定时间点的状态。该模型以相同的方法进行层次化应用，引入了Component Work (CW)、Component Temporal Version (CTV)和Component Language Version (CLV)来追踪个别文章、段落和条款的生命周期。以巴西联邦宪法为案例研究，本文展示了每个修正案如何为受影响的条款创建新的Component Temporal Versions，而未受影响的组件则保留其现有版本。这种精细粒度、时间感知的架构能够精确、确定地检索和重建任何部分的法律文本，如它在特定日期的状态。该模型为开发高级法律信息系统、知识图谱和能够进行准确历史分析和影响评估的AI工具提供了坚实的基础，克服了当前生成模型的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effectively representing legal norms for automated processing is a criticalchallenge, particularly in tracking the diachronic evolution of theirhierarchical components (e.g., articles, paragraphs). While foundationalframeworks like FRBR/FRBRoo and standards like Akoma Ntoso model legaldocuments at a macro level, they lack native mechanisms for granular,component-level versioning. This limitation hinders the deterministicpoint-in-time reconstruction of legal texts, a fundamental capability forreliable Legal Tech and AI applications. This paper proposes a structured,temporal model that extends the FRBRoo framework to address this gap. Itintroduces specialized subclasses of Expressio - Temporal Version (TV) andLanguage Version (LV - to represent the state of a legal norm and itslinguistic variations at specific points in time. The model applies this sameparadigm hierarchically, introducing Component Work (CW), Component TemporalVersion (CTV), and Component Language Version (CLV) to track the lifecycle ofindividual articles, paragraphs, and clauses. Using the Brazilian FederalConstitution as a case study, the paper demonstrates how each amendment createsnew Component Temporal Versions for affected provisions, while unaffectedcomponents retain their existing versions. This fine-grained, time-awarearchitecture enables the precise, deterministic retrieval and reconstruction ofany part of a legal text as it existed on a specific date. The model provides arobust foundation for developing advanced legal information systems, knowledgegraphs, and AI tools capable of accurate historical analysis and impactassessment, overcoming the limitations of current generative models.</description>
      <author>example@mail.com (Hudson de Martim)</author>
      <guid isPermaLink="false">2506.07853v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Super Encoding Network: Recursive Association of Multi-Modal Encoders for Video Understanding</title>
      <link>http://arxiv.org/abs/2506.07576v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Super Encoding Network (SEN)的统一网络，用于视频理解，该网络通过在基础模型中递归关联多模态编码器来建立深度多模态交互。&lt;h4&gt;背景&lt;/h4&gt;视频理解是迈向世界建模的关键步骤，而多模态基础模型通过大规模预训练显示出巨大潜力。然而，这些模型缺乏深度多模态交互，这对于理解复杂目标运动和多样化的视频场景至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文旨在提出一种新的方法来增强视频理解中的多模态交互。&lt;h4&gt;方法&lt;/h4&gt;本文设计了一种递归关联（RA）块，将多模态信息与输入视频逐步融合，通过超级神经元的递归知识整合、分配和提示来实现。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，SEN在四个代表性的视频任务（跟踪、识别、聊天和编辑）上均显著提升了性能，例如，在像素级跟踪任务中，与CaDeX++方法相比，Jaccard指数提高了2.7%，时间一致性（TC）降低了8.8%。在单次视频编辑任务中，与TuneA-Video方法相比，文本对齐提高了6.4%，帧一致性增加了4.1%。&lt;h4&gt;结论&lt;/h4&gt;SEN能够有效地编码深度多模态交互，从而显著提升视频理解任务的表现。&lt;h4&gt;翻译&lt;/h4&gt;Video understanding has been considered as one critical step towards world modeling, which is an important long-term problem in AI research. Recently, multi-modal foundation models have shown such potential via large-scale pretraining. However, these models simply align encoders of different modalities via contrastive learning, while lacking deeper multi-modal interactions, which is critical for understanding complex target movements with diversified video scenes. To fill this gap, we propose a unified Super Encoding Network (SEN) for video understanding, which builds up such distinct interactions through recursive association of multi-modal encoders in the foundation models. Specifically, we creatively treat those well-trained encoders as 'super neurons' in our SEN. Via designing a Recursive Association (RA) block, we progressively fuse multi-modalities with the input video, based on knowledge integrating, distributing, and prompting of super neurons in a recursive manner. In this way, our SEN can effectively encode deeper multi-modal interactions, for prompting various video understanding tasks in downstream. Extensive experiments show that, our SEN can remarkably boost the four most representative video tasks, including tracking, recognition, chatting, and editing, e.g., for pixel-level tracking, the average jaccard index improves 2.7%, temporal coherence (TC) drops 8.8% compared to the popular CaDeX++ approach. For one-shot video editing, textual alignment improves 6.4%, and frame consistency increases 4.1% compared to the popular TuneA-Video approach.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video understanding has been considered as one critical step towards worldmodeling, which is an important long-term problem in AI research. Recently,multi-modal foundation models have shown such potential via large-scalepretraining. However, these models simply align encoders of differentmodalities via contrastive learning, while lacking deeper multi-modalinteractions, which is critical for understanding complex target movements withdiversified video scenes. To fill this gap, we propose a unified Super EncodingNetwork (SEN) for video understanding, which builds up such distinctinteractions through recursive association of multi-modal encoders in thefoundation models. Specifically, we creatively treat those well-trainedencoders as "super neurons" in our SEN. Via designing a Recursive Association(RA) block, we progressively fuse multi-modalities with the input video, basedon knowledge integrating, distributing, and prompting of super neurons in arecursive manner. In this way, our SEN can effectively encode deepermulti-modal interactions, for prompting various video understanding tasks indownstream. Extensive experiments show that, our SEN can remarkably boost thefour most representative video tasks, including tracking, recognition,chatting, and editing, e.g., for pixel-level tracking, the average jaccardindex improves 2.7%, temporal coherence(TC) drops 8.8% compared to the popularCaDeX++ approach. For one-shot video editing, textual alignment improves 6.4%,and frame consistency increases 4.1% compared to the popular TuneA-Videoapproach.</description>
      <author>example@mail.com (Boyu Chen, Siran Chen, Kunchang Li, Qinglin Xu, Yu Qiao, Yali Wang)</author>
      <guid isPermaLink="false">2506.07576v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>EgoM2P: Egocentric Multimodal Multitask Pretraining</title>
      <link>http://arxiv.org/abs/2506.07886v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究如何理解以自我为中心的多模态信号，如RGB视频、深度、相机姿态和注视信息，这对增强现实、机器人和人机交互等应用至关重要。文章提出了EgoM2P框架，用于处理和合成这些多模态数据，并展示了其在不同任务上的性能优势。&lt;h4&gt;背景&lt;/h4&gt;多模态信号在以自我为中心的视觉应用中至关重要，但构建大规模的以自我为中心的多模态和多任务模型面临挑战，如数据异构性、模态缺失和动态相机运动等。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为EgoM2P的框架，用于解决上述挑战，并提高以自我为中心的多模态理解的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;引入高效的时序标记器，并构建EgoM2P框架，该框架通过从时序感知的多模态标记中学习，来训练一个用于以自我为中心的4D理解的大规模通用模型。&lt;h4&gt;主要发现&lt;/h4&gt;EgoM2P在注视预测、以自我为中心的相机跟踪和从以自我为中心的视频中进行单目深度估计等任务上表现出色，同时速度比专业模型快一个数量级。&lt;h4&gt;结论&lt;/h4&gt;EgoM2P框架有效解决了多模态信号理解中的挑战，提高了以自我为中心的视觉应用的性能，并计划开源以支持社区和推动相关研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：理解以自我为中心的多模态信号，如RGB视频、深度、相机姿态和注视，对于增强现实、机器人和人机交互等应用至关重要。这些能力使系统能够更好地解释相机佩戴者的动作、意图和周围环境。然而，构建大规模的以自我为中心的多模态和多任务模型面临独特的挑战。以自我为中心的数据本质上是异构的，在不同设备和环境中的模态覆盖范围存在很大差异。为缺失的模态，如注视或头戴式相机轨迹生成伪标签通常不可行，使得标准的监督学习方法难以扩展。此外，动态相机运动和第一人称视频的姿态的复杂时空结构为直接应用现有的多模态基础模型增加了额外的挑战。为了解决这些挑战，我们引入了一套高效的时间标记器，并提出了EgoM2P，一个从时序感知的多模态标记中学习的掩码建模框架，用于训练一个用于以自我为中心的4D理解的大规模通用模型。这种统一的设计支持跨各种以自我为中心的感知和合成任务的多任务，包括注视预测、以自我为中心的相机跟踪和从以自我为中心的视频中进行单目深度估计。EgoM2P还作为条件以自我为中心的视频合成的生成模型。在这些任务中，EgoM2P的性能与专业模型相当或更好，同时速度快一个数量级。我们将全面开源EgoM2P以支持社区并推进以自我为中心的视觉研究。项目页面：https://egom2p.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding multimodal signals in egocentric vision, such as RGB video,depth, camera poses, and gaze, is essential for applications in augmentedreality, robotics, and human-computer interaction. These capabilities enablesystems to better interpret the camera wearer's actions, intentions, andsurrounding environment. However, building large-scale egocentric multimodaland multitask models presents unique challenges. Egocentric data are inherentlyheterogeneous, with large variations in modality coverage across devices andsettings. Generating pseudo-labels for missing modalities, such as gaze orhead-mounted camera trajectories, is often infeasible, making standardsupervised learning approaches difficult to scale. Furthermore, dynamic cameramotion and the complex temporal and spatial structure of first-person videopose additional challenges for the direct application of existing multimodalfoundation models.  To address these challenges, we introduce a set of efficient temporaltokenizers and propose EgoM2P, a masked modeling framework that learns fromtemporally aware multimodal tokens to train a large, general-purpose model foregocentric 4D understanding. This unified design supports multitasking acrossdiverse egocentric perception and synthesis tasks, including gaze prediction,egocentric camera tracking, and monocular depth estimation from egocentricvideo. EgoM2P also serves as a generative model for conditional egocentricvideo synthesis. Across these tasks, EgoM2P matches or outperforms specialistmodels while being an order of magnitude faster. We will fully open-sourceEgoM2P to support the community and advance egocentric vision research. Projectpage: https://egom2p.github.io/</description>
      <author>example@mail.com (Gen Li, Yutong Chen, Yiqian Wu, Kaifeng Zhao, Marc Pollefeys, Siyu Tang)</author>
      <guid isPermaLink="false">2506.07886v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Squeeze3D: Your 3D Generation Model is Secretly an Extreme Neural Compressor</title>
      <link>http://arxiv.org/abs/2506.07932v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Squeeze3D是一种新的框架，利用现有预训练的3D生成模型学习到的隐式先验知识，在极高的压缩比下压缩3D数据。&lt;h4&gt;背景&lt;/h4&gt;3D数据的压缩是一个挑战，因为它们通常包含大量的细节。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，能够在不牺牲视觉质量的情况下，以极高的压缩比压缩3D数据。&lt;h4&gt;方法&lt;/h4&gt;Squeeze3D通过可训练的映射网络连接预训练的编码器和生成模型之间的潜在空间。首先，3D模型被预训练的编码器编码，然后转换（即压缩）为高度紧凑的潜在代码。映射网络将压缩的潜在代码转换为强大生成模型的潜在空间，然后条件化以重新创建原始的3D模型（即解压缩）。Squeeze3D完全在生成的合成数据上训练，不需要任何3D数据集。&lt;h4&gt;主要发现&lt;/h4&gt;Squeeze3D在保持视觉质量与许多现有方法相当的同时，实现了高达2187x的纹理网格压缩比，55x的点云压缩比和619x的辐射场压缩比。&lt;h4&gt;结论&lt;/h4&gt;Squeeze3D是一个灵活的框架，可以与现有的预训练3D编码器和生成模型一起使用，支持不同的格式，如网格、点云和辐射场，同时具有较低的压缩和解压缩延迟。&lt;h4&gt;翻译&lt;/h4&gt;我们提出Squeeze3D，一种新颖的框架，它利用现有预训练的3D生成模型学习到的隐式先验知识，在极高的压缩比下压缩3D数据。我们的方法通过可训练的映射网络连接预训练的编码器和预训练的生成模型之间的潜在空间。任何表示为网格、点云或辐射场的3D模型首先由预训练的编码器编码，然后转换为高度紧凑的潜在代码。这个潜在代码可以有效地用作网格或点云的极其压缩的表示。映射网络将压缩的潜在代码转换为强大生成模型的潜在空间，然后条件化以重新创建原始的3D模型（即解压缩）。Squeeze3D完全在生成的合成数据上训练，不需要任何3D数据集。Squeeze3D的架构可以灵活地与现有的预训练3D编码器和现有的生成模型一起使用。它可以灵活地支持不同的格式，包括网格、点云和辐射场。我们的实验表明，Squeeze3D实现了高达2187x的纹理网格压缩比，55x的点云压缩比和619x的辐射场压缩比，同时保持与许多现有方法相当的可视质量。由于Squeeze3D不涉及训练特定于对象的网络来压缩对象，因此它只产生很小的压缩和解压缩延迟。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose Squeeze3D, a novel framework that leverages implicit priorknowledge learnt by existing pre-trained 3D generative models to compress 3Ddata at extremely high compression ratios. Our approach bridges the latentspaces between a pre-trained encoder and a pre-trained generation model throughtrainable mapping networks. Any 3D model represented as a mesh, point cloud, ora radiance field is first encoded by the pre-trained encoder and thentransformed (i.e. compressed) into a highly compact latent code. This latentcode can effectively be used as an extremely compressed representation of themesh or point cloud. A mapping network transforms the compressed latent codeinto the latent space of a powerful generative model, which is then conditionedto recreate the original 3D model (i.e. decompression). Squeeze3D is trainedentirely on generated synthetic data and does not require any 3D datasets. TheSqueeze3D architecture can be flexibly used with existing pre-trained 3Dencoders and existing generative models. It can flexibly support differentformats, including meshes, point clouds, and radiance fields. Our experimentsdemonstrate that Squeeze3D achieves compression ratios of up to 2187x fortextured meshes, 55x for point clouds, and 619x for radiance fields whilemaintaining visual quality comparable to many existing methods. Squeeze3D onlyincurs a small compression and decompression latency since it does not involvetraining object-specific networks to compress an object.</description>
      <author>example@mail.com (Rishit Dagli, Yushi Guan, Sankeerth Durvasula, Mohammadreza Mofayezi, Nandita Vijaykumar)</author>
      <guid isPermaLink="false">2506.07932v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow</title>
      <link>http://arxiv.org/abs/2506.07878v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于事件相机的低延迟运动估计（光流）方法，该方法通过引入时空状态空间模型（STSSM）模块和新型网络架构，实现了高效且性能优异的解决方案。&lt;h4&gt;背景&lt;/h4&gt;传统基于帧的相机在低延迟运动估计方面存在限制，而事件相机可以解锁新的应用领域。尽管深度学习模型如CNN、RNN或ViT在性能上表现出色，但它们通常缺乏所需的计算效率。&lt;h4&gt;目的&lt;/h4&gt;开发一种既高效又具有竞争力的光流估计方法。&lt;h4&gt;方法&lt;/h4&gt;引入了STSSM模块，该模块利用状态空间模型有效地捕捉事件数据中的时空相关性，并提出了一个新的网络架构。&lt;h4&gt;主要发现&lt;/h4&gt;STSSM模块在保持较低复杂性的同时，提供了比ViT和基于CNN的架构更高的性能。该模型在DSEC基准测试中实现了4.5倍的推理速度和8倍的降低计算量，与TMA和EV-FlowNet相比，计算量降低了2倍。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在保持竞争力的同时，显著提高了计算效率。&lt;h4&gt;翻译&lt;/h4&gt;Event cameras unlock new frontiers that were previously unthinkable with standard frame-based cameras. One notable example is low-latency motion estimation (optical flow), which is critical for many real-time applications. In such applications, the computational efficiency of algorithms is paramount. Although recent deep learning paradigms such as CNN, RNN, or ViT have shown remarkable performance, they often lack the desired computational efficiency. Conversely, asynchronous event-based methods including SNNs and GNNs are computationally efficient; however, these approaches fail to capture sufficient spatio-temporal information, a powerful feature required to achieve better performance for optical flow estimation. In this work, we introduce Spatio-Temporal State Space Model (STSSM) module along with a novel network architecture to develop an extremely efficient solution with competitive performance. Our STSSM module leverages state-space models to effectively capture spatio-temporal correlations in event data, offering higher performance with lower complexity compared to ViT, CNN-based architectures in similar settings. Our model achieves 4.5x faster inference and 8x lower computations compared to TMA and 2x lower computations compared to EV-FlowNet with competitive performance on the DSEC benchmark. Our code will be available at https://github.com/AhmedHumais/E-STMFlow&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event cameras unlock new frontiers that were previously unthinkable withstandard frame-based cameras. One notable example is low-latency motionestimation (optical flow), which is critical for many real-time applications.In such applications, the computational efficiency of algorithms is paramount.Although recent deep learning paradigms such as CNN, RNN, or ViT have shownremarkable performance, they often lack the desired computational efficiency.Conversely, asynchronous event-based methods including SNNs and GNNs arecomputationally efficient; however, these approaches fail to capture sufficientspatio-temporal information, a powerful feature required to achieve betterperformance for optical flow estimation. In this work, we introduceSpatio-Temporal State Space Model (STSSM) module along with a novel networkarchitecture to develop an extremely efficient solution with competitiveperformance. Our STSSM module leverages state-space models to effectivelycapture spatio-temporal correlations in event data, offering higher performancewith lower complexity compared to ViT, CNN-based architectures in similarsettings. Our model achieves 4.5x faster inference and 8x lower computationscompared to TMA and 2x lower computations compared to EV-FlowNet withcompetitive performance on the DSEC benchmark. Our code will be available athttps://github.com/AhmedHumais/E-STMFlow</description>
      <author>example@mail.com (Muhammad Ahmed Humais, Xiaoqian Huang, Hussain Sajwani, Sajid Javed, Yahya Zweiri)</author>
      <guid isPermaLink="false">2506.07878v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Design and Evaluation of Deep Learning-Based Dual-Spectrum Image Fusion Methods</title>
      <link>http://arxiv.org/abs/2506.07779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了可见光图像和红外图像融合方法在场景理解，特别是复杂条件下的高级视觉任务中的应用，并提出了一个新的评价框架和数据集。&lt;h4&gt;背景&lt;/h4&gt;可见光图像和红外图像在纹理细节和目标检测上有各自的优势，融合这两种模态可以提高场景理解能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决当前评价方法依赖于通用指标、缺乏标准化基准和下游任务性能的问题，论文提出了一个高质量的校园环境双光谱数据集和一个综合评价框架。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含1369对可见光-红外图像对的校园环境双光谱数据集，提出了一个综合评价框架，该框架结合了融合速度、通用指标和目标检测性能，并在该框架下对比分析了多种融合算法。&lt;h4&gt;主要发现&lt;/h4&gt;融合模型在目标检测任务上表现优异，特别是在低光和遮挡场景下。一些在通用指标上表现良好的算法在下游任务上的表现并不理想，突显了当前评价方法的局限性。&lt;h4&gt;结论&lt;/h4&gt;论文的主要贡献包括：一个面向校园环境且包含多样化、挑战性场景的双光谱数据集；一个任务感知的综合评价框架；以及对多种数据集上领先融合方法的全面比较分析，为未来的发展提供了洞见。&lt;h4&gt;翻译&lt;/h4&gt;The abstract summarizes a study on the application of visible and infrared image fusion methods in scene understanding, especially for advanced vision tasks under challenging conditions, and proposes a new evaluation framework and dataset.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visible images offer rich texture details, while infrared images emphasizesalient targets. Fusing these complementary modalities enhances sceneunderstanding, particularly for advanced vision tasks under challengingconditions. Recently, deep learning-based fusion methods have gained attention,but current evaluations primarily rely on general-purpose metrics withoutstandardized benchmarks or downstream task performance. Additionally, the lackof well-developed dual-spectrum datasets and fair algorithm comparisons hindersprogress.  To address these gaps, we construct a high-quality dual-spectrum datasetcaptured in campus environments, comprising 1,369 well-aligned visible-infraredimage pairs across four representative scenarios: daytime, nighttime, smokeocclusion, and underpasses. We also propose a comprehensive and fair evaluationframework that integrates fusion speed, general metrics, and object detectionperformance using the lang-segment-anything model to ensure fairness indownstream evaluation.  Extensive experiments benchmark several state-of-the-art fusion algorithmsunder this framework. Results demonstrate that fusion models optimized fordownstream tasks achieve superior performance in target detection, especiallyin low-light and occluded scenes. Notably, some algorithms that perform well ongeneral metrics do not translate to strong downstream performance, highlightinglimitations of current evaluation practices and validating the necessity of ourproposed framework.  The main contributions of this work are: (1)a campus-oriented dual-spectrumdataset with diverse and challenging scenes; (2) a task-aware, comprehensiveevaluation framework; and (3) thorough comparative analysis of leading fusionmethods across multiple datasets, offering insights for future development.</description>
      <author>example@mail.com (Beining Xu, Junxian Li)</author>
      <guid isPermaLink="false">2506.07779v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Egocentric Event-Based Vision for Ping Pong Ball Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2506.07860v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE/CVF Conference on Computer Vision and Pattern Recognition  Workshops (CVPRW), Nashville (TN), USA, 2025; 5th International Workshop on  Event-Based Vision&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用事件摄像头进行实时乒乓球轨迹预测的系统。&lt;h4&gt;背景&lt;/h4&gt;与传统摄像头相比，事件摄像头在高速度运动场景中具有更高的时间分辨率，可以提供更频繁的状态更新，更强的鲁棒性以及对异常值的处理能力。&lt;h4&gt;目的&lt;/h4&gt;旨在通过事件摄像头预测乒乓球轨迹，实现3D轨迹预测。&lt;h4&gt;方法&lt;/h4&gt;收集了乒乓球比赛序列数据集，包括球的三维真实轨迹、与Meta Project Aria眼镜传感器数据同步的事件流。系统利用水平视野，利用眼镜的注视数据只处理观察者视野中央的事件，以减少计算延迟。检测管道具有最坏情况下的总延迟为4.5毫秒，包括计算和感知。&lt;h4&gt;主要发现&lt;/h4&gt;系统在收集的轨迹上实现了10.81的降低因子，检测管道的最坏情况总延迟为4.5毫秒，远低于基于帧的30 FPS系统。&lt;h4&gt;结论&lt;/h4&gt;本研究首次提出了一种使用事件摄像头从自视角预测乒乓球轨迹的方法。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we present a real-time egocentric trajectory prediction system for table tennis using event cameras. Unlike standard cameras, which suffer from high latency and motion blur at fast ball speeds, event cameras provide higher temporal resolution, allowing more frequent state updates, greater robustness to outliers, and accurate trajectory predictions using just a short time window after the opponent's impact. We collect a dataset of ping-pong game sequences, including 3D ground-truth trajectories of the ball, synchronized with sensor data from the Meta Project Aria glasses and event streams. Oursystem leverages foveated vision, using eye-gaze data from the glasses to process only events in the viewer's fovea. This biologically inspired approach improves ball detection performance and significantly reduces computational latency, as it efficiently allocates resources to the most perceptually relevant regions, achieving a reduction factor of 10.81 on the collected trajectories. Our detection pipeline has a worst-case total latency of 4.5 ms, including computation and perception - significantly lower than a frame-based 30 FPS system, which, in the worst case, takes 66 ms solely for perception. Finally, we fit a trajectory prediction model to the estimated states of the ball, enabling 3D trajectory forecasting in the future. To the best of our knowledge, this is the first approach to predict table tennis trajectories from an egocentric perspective using event cameras.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present a real-time egocentric trajectory prediction systemfor table tennis using event cameras. Unlike standard cameras, which sufferfrom high latency and motion blur at fast ball speeds, event cameras providehigher temporal resolution, allowing more frequent state updates, greaterrobustness to outliers, and accurate trajectory predictions using just a shorttime window after the opponent's impact. We collect a dataset of ping-pong gamesequences, including 3D ground-truth trajectories of the ball, synchronizedwith sensor data from the Meta Project Aria glasses and event streams. Oursystem leverages foveated vision, using eye-gaze data from the glasses toprocess only events in the viewer's fovea. This biologically inspired approachimproves ball detection performance and significantly reduces computationallatency, as it efficiently allocates resources to the most perceptuallyrelevant regions, achieving a reduction factor of 10.81 on the collectedtrajectories. Our detection pipeline has a worst-case total latency of 4.5 ms,including computation and perception - significantly lower than a frame-based30 FPS system, which, in the worst case, takes 66 ms solely for perception.Finally, we fit a trajectory prediction model to the estimated states of theball, enabling 3D trajectory forecasting in the future. To the best of ourknowledge, this is the first approach to predict table tennis trajectories froman egocentric perspective using event cameras.</description>
      <author>example@mail.com (Ivan Alberico, Marco Cannici, Giovanni Cioffi, Davide Scaramuzza)</author>
      <guid isPermaLink="false">2506.07860v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>OpenSplat3D: Open-Vocabulary 3D Instance Segmentation using Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.07697v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为OpenSplat3D的3D实例分割方法，它扩展了3D Gaussian Splatting在场景表示之外的能力，并通过自然语言描述在3D场景中识别和分割任意对象。&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting（3DGS）已成为神经场景重建的有力表示，它提供了高质量的全新视图合成，同时保持计算效率。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需手动标注的开放词汇3D实例分割方法，以扩展3DGS的应用范围。&lt;h4&gt;方法&lt;/h4&gt;方法利用特征splatting技术将语义信息与单个高斯函数关联，并采用Segment Anything Model实例掩码和对比损失公式作为实例特征的指导，同时利用视觉-语言模型的语言嵌入实现灵活的文本驱动实例识别。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在LERF-mask、LERF-OVS以及完整的ScanNet++验证集上展示了有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够根据自然语言描述识别和分割3D场景中的任意对象，证明了其在3D实例分割方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) has emerged as a powerful representation forneural scene reconstruction, offering high-quality novel view synthesis whilemaintaining computational efficiency. In this paper, we extend the capabilitiesof 3DGS beyond pure scene representation by introducing an approach foropen-vocabulary 3D instance segmentation without requiring manual labeling,termed OpenSplat3D. Our method leverages feature-splatting techniques toassociate semantic information with individual Gaussians, enabling fine-grainedscene understanding. We incorporate Segment Anything Model instance masks witha contrastive loss formulation as guidance for the instance features to achieveaccurate instance-level segmentation. Furthermore, we utilize languageembeddings of a vision-language model, allowing for flexible, text-driveninstance identification. This combination enables our system to identify andsegment arbitrary objects in 3D scenes based on natural language descriptions.We show results on LERF-mask and LERF-OVS as well as the full ScanNet++validation set, demonstrating the effectiveness of our approach.</description>
      <author>example@mail.com (Jens Piekenbrinck, Christian Schmidt, Alexander Hermans, Narunas Vaskevicius, Timm Linder, Bastian Leibe)</author>
      <guid isPermaLink="false">2506.07697v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Ambiguity-Restrained Text-Video Representation Learning for Partially Relevant Video Retrieval</title>
      <link>http://arxiv.org/abs/2506.07471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PRVR的部分相关视频检索方法，旨在从视频库中检索出与给定文本查询相关的特定片段。&lt;h4&gt;背景&lt;/h4&gt;传统的PRVR训练过程假设文本查询与视频之间存在一对一的关系，但作者指出文本和视频内容之间存在固有的模糊性。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，将这种模糊性纳入模型学习过程中。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为ARL的模糊性受限表示学习（Ambiguity-Restrained representation Learning）的方法，用于处理模糊的文本-视频对。ARL首先基于不确定性和相似性两个标准检测模糊对，然后通过多正对比学习和双重三元组损失来分层学习语义关系。此外，ARL还深入研究了视频实例中的细粒度关系，并提出了跨模型模糊性检测来减轻错误传播。&lt;h4&gt;主要发现&lt;/h4&gt;ARL能够有效地处理文本-视频对中的模糊性，并通过多层次的学习增强了文本-帧级别的学习。&lt;h4&gt;结论&lt;/h4&gt;该方法在PRVR中表现出良好的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：部分相关视频检索（PRVR）旨在检索与给定文本查询相关的特定片段的视频。典型的PRVR训练过程假设每个文本查询只与一个视频相关，但作者指出基于概念范围，文本和视频内容之间存在固有的模糊性。基于此，作者提出了一种将这种模糊性纳入模型学习过程的框架。具体来说，作者提出了模糊性受限表示学习（ARL）来解决模糊的文本-视频对。最初，ARL基于不确定性和相似性两个标准检测模糊对。不确定性表示实例是否包含数据集中常见共享的上下文，而相似性表示成对语义重叠。然后，通过检测到的模糊对，ARL通过多正对比学习和双重三元组损失分层学习语义关系。此外，ARL还深入研究了视频实例中的细粒度关系。与典型的在文本-视频级别的训练不同，在提供成对信息时，ARL解决了同一未剪辑视频中帧之间的固有模糊性，这些帧通常包含多个上下文。这使得我们能够在文本-帧级别进一步增强学习。最后，作者提出了跨模型模糊性检测来减轻当使用单个模型检测用于其训练的模糊对时发生的错误传播。结合所有组件，作者提出的方法在PRVR中证明了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Partially Relevant Video Retrieval~(PRVR) aims to retrieve a video where aspecific segment is relevant to a given text query. Typical training processesof PRVR assume a one-to-one relationship where each text query is relevant toonly one video. However, we point out the inherent ambiguity between text andvideo content based on their conceptual scope and propose a framework thatincorporates this ambiguity into the model learning process. Specifically, wepropose Ambiguity-Restrained representation Learning~(ARL) to address ambiguoustext-video pairs. Initially, ARL detects ambiguous pairs based on two criteria:uncertainty and similarity. Uncertainty represents whether instances includecommonly shared context across the dataset, while similarity indicatespair-wise semantic overlap. Then, with the detected ambiguous pairs, our ARLhierarchically learns the semantic relationship via multi-positive contrastivelearning and dual triplet margin loss. Additionally, we delve into fine-grainedrelationships within the video instances. Unlike typical training at thetext-video level, where pairwise information is provided, we address theinherent ambiguity within frames of the same untrimmed video, which oftencontains multiple contexts. This allows us to further enhance learning at thetext-frame level. Lastly, we propose cross-model ambiguity detection tomitigate the error propagation that occurs when a single model is employed todetect ambiguous pairs for its training. With all components combined, ourproposed method demonstrates its effectiveness in PRVR.</description>
      <author>example@mail.com (CH Cho, WJ Moon, W Jun, MS Jung, JP Heo)</author>
      <guid isPermaLink="false">2506.07471v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SpikeSMOKE: Spiking Neural Networks for Monocular 3D Object Detection with Cross-Scale Gated Coding</title>
      <link>http://arxiv.org/abs/2506.07737v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种低功耗的3D物体检测方法，通过使用脉冲神经网络（SNNs）和改进的SpikeSMOKE架构，实现了在减少能耗的同时保持较高的检测性能。&lt;h4&gt;背景&lt;/h4&gt;随着3D物体检测在自动驾驶等领域的广泛应用，其能耗问题日益突出，因此降低能耗成为研究的重要方向。&lt;h4&gt;目的&lt;/h4&gt;设计一种低功耗的3D物体检测方法，以应对自动驾驶等应用场景中的能耗挑战。&lt;h4&gt;方法&lt;/h4&gt;1. 应用SNNs进行单目3D物体检测；2. 提出SpikeSMOKE架构；3. 设计交叉尺度门控编码机制（CSGC）以增强特征表示能力；4. 提出轻量级残差块以减少计算量和提高训练速度。&lt;h4&gt;主要发现&lt;/h4&gt;与基准SpikeSMOKE相比，改进的SpikeSMOKE在KITTI自动驾驶数据集上实现了更高的检测性能，同时在能耗上降低了72.2%，而检测性能仅降低了4%。SpikeSMOKE-L进一步减少了参数量和计算量。&lt;h4&gt;结论&lt;/h4&gt;SNNs在3D物体检测中具有降低能耗的潜力，通过改进的架构和机制可以同时提升检测性能和降低能耗。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low energy consumption for 3D object detection is an important research areabecause of the increasing energy consumption with their wide application infields such as autonomous driving. The spiking neural networks (SNNs) withlow-power consumption characteristics can provide a novel solution for thisresearch. Therefore, we apply SNNs to monocular 3D object detection and proposethe SpikeSMOKE architecture in this paper, which is a new attempt for low-powermonocular 3D object detection. As we all know, discrete signals of SNNs willgenerate information loss and limit their feature expression ability comparedwith the artificial neural networks (ANNs).In order to address this issue,inspired by the filtering mechanism of biological neuronal synapses, we proposea cross-scale gated coding mechanism(CSGC), which can enhance featurerepresentation by combining cross-scale fusion of attentional methods and gatedfiltering mechanisms.In addition, to reduce the computation and increase thespeed of training, we present a novel light-weight residual block that canmaintain spiking computing paradigm and the highest possible detectionperformance. Compared to the baseline SpikeSMOKE under the 3D Object Detection,the proposed SpikeSMOKE with CSGC can achieve 11.78 (+2.82, Easy), 10.69 (+3.2,Moderate), and 10.48 (+3.17, Hard) on the KITTI autonomous driving dataset byAP|R11 at 0.7 IoU threshold, respectively. It is important to note that theresults of SpikeSMOKE can significantly reduce energy consumption compared tothe results on SMOKE. For example,the energy consumption can be reduced by72.2% on the hard category, while the detection performance is reduced by only4%. SpikeSMOKE-L (lightweight) can further reduce the amount of parameters by 3times and computation by 10 times compared to SMOKE.</description>
      <author>example@mail.com (Xuemei Chen, Huamin Wang, Hangchi Shen, Shukai Duan, Shiping Wen, Tingwen Huang)</author>
      <guid isPermaLink="false">2506.07737v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning</title>
      <link>http://arxiv.org/abs/2506.07619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了用于产量预测的全新数据集，这是首个用于机器学习基准测试的瞬态流动数据集，涵盖了1200多种工艺条件。数据集的构建克服了化学数据集通常难以获取的难题，并针对溶剂选择这一理论建模困难的任务，展示了回归算法、迁移学习、特征工程和主动学习在其中的应用。&lt;h4&gt;背景&lt;/h4&gt;机器学习在分子性质预测和反应逆合成中取得了显著成果，但化学数据集往往难以获得，因为它们需要数据清洗、对化学的深入了解，或者根本不可用。&lt;h4&gt;目的&lt;/h4&gt;提出一个用于产量预测的新数据集，为机器学习模型提供基准测试，并探索溶剂选择等任务。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含超过1200种工艺条件的瞬态流动数据集，通过实验设置采样大量连续工艺条件，以应对机器学习模型的新挑战。&lt;h4&gt;主要发现&lt;/h4&gt;数据集涵盖了溶剂选择等难以理论建模的任务，并展示了回归算法、迁移学习、特征工程和主动学习在其中的应用。&lt;h4&gt;结论&lt;/h4&gt;本文提出的数据集和机器学习应用为溶剂替代和可持续制造提供了重要应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：机器学习承诺要改变实验室化学的格局，在分子性质预测和反应逆合成方面取得了令人印象深刻的成果。然而，化学数据集通常难以获得，因为它们往往需要清洗、对化学的深入了解，或者根本不可用。在本文中，我们介绍了一个用于产量预测的新数据集，提供了首个用于机器学习基准测试的瞬态流动数据集，涵盖了1200多种工艺条件。虽然之前的数据库侧重于离散参数，但我们的实验设置使我们能够采样大量连续工艺条件，为机器学习模型带来了新的挑战。我们专注于溶剂选择，这是一个特别难以理论建模的任务，因此非常适合机器学习应用。我们展示了回归算法、迁移学习、特征工程和主动学习的基准测试，这些在溶剂替代和可持续制造方面有重要的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning has promised to change the landscape of laboratorychemistry, with impressive results in molecular property prediction andreaction retro-synthesis. However, chemical datasets are often inaccessible tothe machine learning community as they tend to require cleaning, thoroughunderstanding of the chemistry, or are simply not available. In this paper, weintroduce a novel dataset for yield prediction, providing the first-evertransient flow dataset for machine learning benchmarking, covering over 1200process conditions. While previous datasets focus on discrete parameters, ourexperimental set-up allow us to sample a large number of continuous processconditions, generating new challenges for machine learning models. We focus onsolvent selection, a task that is particularly difficult to model theoreticallyand therefore ripe for machine learning applications. We showcase benchmarkingfor regression algorithms, transfer-learning approaches, feature engineering,and active learning, with important applications towards solvent replacementand sustainable manufacturing.</description>
      <author>example@mail.com (Toby Boyne, Juan S. Campos, Becky D. Langdon, Jixiang Qing, Yilin Xie, Shiqiang Zhang, Calvin Tsay, Ruth Misener, Daniel W. Davies, Kim E. Jelfs, Sarah Boyall, Thomas M. Dixon, Linden Schrecker, Jose Pablo Folch)</author>
      <guid isPermaLink="false">2506.07619v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SurgBench: A Unified Large-Scale Benchmark for Surgical Video Analysis</title>
      <link>http://arxiv.org/abs/2506.07603v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SurgBench，一个统一的手术视频基准框架，包括预训练数据集SurgBench-P和评估基准SurgBench-E，旨在解决手术视频理解领域的数据稀缺问题。&lt;h4&gt;背景&lt;/h4&gt;手术视频理解对于实现自动化手术决策、技能评估和术后质量提升至关重要，但发展手术视频基础模型（FMs）受到大规模、多样化数据集缺乏的阻碍。&lt;h4&gt;目的&lt;/h4&gt;提出SurgBench框架，以解决手术视频理解领域的数据稀缺问题，并提高手术视频分析任务的性能。&lt;h4&gt;方法&lt;/h4&gt;构建了SurgBench-P预训练数据集和SurgBench-E评估基准，其中SurgBench-P包含22种手术程序和11个专业的5300万帧图像，SurgBench-E提供涵盖6个类别、72个细粒度任务的稳健评估。&lt;h4&gt;主要发现&lt;/h4&gt;现有视频FMs难以泛化到不同的手术视频分析任务，而基于SurgBench-P的预训练则显著提高了性能，并实现了对未见过的手术程序和模态的优越跨领域泛化。&lt;h4&gt;结论&lt;/h4&gt;SurgBench框架为手术视频理解领域提供了重要的数据资源和评估基准，有助于推动该领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：手术视频理解对于实现自动化手术决策、技能评估和术后质量提升至关重要。然而，开发手术视频基础模型（FMs）的进展受到大规模、多样化数据集缺乏的阻碍。在本文中，我们引入了SurgBench，这是一个统一的手术视频基准框架，包括预训练数据集SurgBench-P和评估基准SurgBench-E。SurgBench提供了对多样化手术场景的广泛覆盖，其中SurgBench-P包含22种手术程序和11个专业的5300万帧图像，SurgBench-E提供了涵盖6个类别、72个细粒度任务的稳健评估。广泛的实验表明，现有的视频FMs难以泛化到不同的手术视频分析任务，而基于SurgBench-P的预训练则显著提高了性能，并实现了对未见过的手术程序和模态的优越跨领域泛化。我们的数据集和代码可根据请求提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surgical video understanding is pivotal for enabling automated intraoperativedecision-making, skill assessment, and postoperative quality improvement.However, progress in developing surgical video foundation models (FMs) remainshindered by the scarcity of large-scale, diverse datasets for pretraining andsystematic evaluation. In this paper, we introduce \textbf{SurgBench}, aunified surgical video benchmarking framework comprising a pretraining dataset,\textbf{SurgBench-P}, and an evaluation benchmark, \textbf{SurgBench-E}.SurgBench offers extensive coverage of diverse surgical scenarios, withSurgBench-P encompassing 53 million frames across 22 surgical procedures and 11specialties, and SurgBench-E providing robust evaluation across six categories(phase classification, camera motion, tool recognition, disease diagnosis,action classification, and organ detection) spanning 72 fine-grained tasks.Extensive experiments reveal that existing video FMs struggle to generalizeacross varied surgical video analysis tasks, whereas pretraining on SurgBench-Pyields substantial performance improvements and superior cross-domaingeneralization to unseen procedures and modalities. Our dataset and code areavailable upon request.</description>
      <author>example@mail.com (Jianhui Wei, Zikai Xiao, Danyu Sun, Luqi Gong, Zongxin Yang, Zuozhu Liu, Jian Wu)</author>
      <guid isPermaLink="false">2506.07603v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds</title>
      <link>http://arxiv.org/abs/2506.07857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025. Code and data are available at:  https://github.com/vLAR-group/LogoSP&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了无监督3D语义分割问题，通过LogoSP方法从局部和全局点云特征中学习3D语义信息，实现了高度准确的语义伪标签生成，并在室内和室外数据集上取得了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的无监督3D语义分割方法通常通过学习每个点的局部特征和简单的分组策略来解决问题，但缺乏发现超出局部特征的额外语义先验的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为LogoSP的方法，用于从原始点云数据中无监督地学习3D语义信息。&lt;h4&gt;方法&lt;/h4&gt;LogoSP通过根据超点在频域中的全局模式进行分组来发现3D语义信息，从而生成用于训练分割网络的语义伪标签。&lt;h4&gt;主要发现&lt;/h4&gt;LogoSP在室内和室外数据集上超越了所有现有的无监督方法，实现了最先进的无监督3D语义分割性能。研究发现，所学习的全局模式真正代表了在训练过程中没有人类标签时的有意义3D语义。&lt;h4&gt;结论&lt;/h4&gt;LogoSP是一种有效的无监督3D语义分割方法，能够从无标签的原始点云数据中学习到有意义的3D语义信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the problem of unsupervised 3D semantic segmentation on raw pointclouds without needing human labels in training. Existing methods usuallyformulate this problem into learning per-point local features followed by asimple grouping strategy, lacking the ability to discover additional andpossibly richer semantic priors beyond local features. In this paper, weintroduce LogoSP to learn 3D semantics from both local and global pointfeatures. The key to our approach is to discover 3D semantic information bygrouping superpoints according to their global patterns in the frequencydomain, thus generating highly accurate semantic pseudo-labels for training asegmentation network. Extensive experiments on two indoor and an outdoordatasets show that our LogoSP surpasses all existing unsupervised methods bylarge margins, achieving the state-of-the-art performance for unsupervised 3Dsemantic segmentation. Notably, our investigation into the learned globalpatterns reveals that they truly represent meaningful 3D semantics in theabsence of human labels during training.</description>
      <author>example@mail.com (Zihui Zhang, Weisheng Dai, Hongtao Wen, Bo Yang)</author>
      <guid isPermaLink="false">2506.07857v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Residual Reweighted Conformal Prediction for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.07854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Residual Reweighted GNN (RR-GNN)，一种能够生成具有可证明边缘覆盖保证的最小预测集的框架，旨在解决高价值领域中图神经网络（GNNs）的不确定性量化问题。&lt;h4&gt;背景&lt;/h4&gt;尽管GNNs在建模关系数据方面表现出色，但在高价值领域中，由于未量化的不确定性，它们面临重大挑战。现有的符合性预测（CP）方法虽然提供统计覆盖保证，但通常产生过于保守的预测区间，无法考虑图异方差性和结构偏差。现有的残差重加权CP变体虽然解决了一些局限性，但忽略了图拓扑、特定集群的不确定性和通过重用训练集的风险数据泄露。&lt;h4&gt;目的&lt;/h4&gt;提出RR-GNN以解决上述问题，旨在提高预测性能，同时保持统计覆盖。&lt;h4&gt;方法&lt;/h4&gt;RR-GNN引入了三项主要创新：首先，使用图结构莫迪安CP将节点或边根据拓扑特征划分为社区，确保集群条件覆盖反映异质性；其次，使用残差自适应非一致性分数，通过在保留的校准集上训练次级GNN来估计特定任务的残差，动态调整预测区间；第三，采用交叉训练协议，交替优化主GNN和残差预测器，以防止信息泄露同时保持图依赖。&lt;h4&gt;主要发现&lt;/h4&gt;在包括节点分类、回归和边权重预测在内的15个真实世界图上的多样任务中验证了RR-GNN，与CP基线相比，RR-GNN在效率上优于最先进的方法，没有覆盖损失。&lt;h4&gt;结论&lt;/h4&gt;RR-GNN通过提供更精确的预测和避免信息泄露，为高价值领域中的GNNs应用提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) excel at modeling relational data but facesignificant challenges in high-stakes domains due to unquantified uncertainty.Conformal prediction (CP) offers statistical coverage guarantees, but existingmethods often produce overly conservative prediction intervals that fail toaccount for graph heteroscedasticity and structural biases. While residualreweighting CP variants address some of these limitations, they neglect graphtopology, cluster-specific uncertainties, and risk data leakage by reusingtraining sets. To address these issues, we propose Residual Reweighted GNN(RR-GNN), a framework designed to generate minimal prediction sets withprovable marginal coverage guarantees.  RR-GNN introduces three major innovations to enhance prediction performance.First, it employs Graph-Structured Mondrian CP to partition nodes or edges intocommunities based on topological features, ensuring cluster-conditionalcoverage that reflects heterogeneity. Second, it uses Residual-AdaptiveNonconformity Scores by training a secondary GNN on a held-out calibration setto estimate task-specific residuals, dynamically adjusting prediction intervalsaccording to node or edge uncertainty. Third, it adopts a Cross-TrainingProtocol, which alternates the optimization of the primary GNN and the residualpredictor to prevent information leakage while maintaining graph dependencies.We validate RR-GNN on 15 real-world graphs across diverse tasks, including nodeclassification, regression, and edge weight prediction. Compared to CPbaselines, RR-GNN achieves improved efficiency over state-of-the-art methods,with no loss of coverage.</description>
      <author>example@mail.com (Zheng Zhang, Jie Bao, Zhixin Zhou, Nicolo Colombo, Lixin Cheng, Rui Luo)</author>
      <guid isPermaLink="false">2506.07854v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Language-Vision Planner and Executor for Text-to-Visual Reasoning</title>
      <link>http://arxiv.org/abs/2506.07778v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VLAgent是一个AI系统，能够通过自动化过程创建易于理解的视觉推理计划，并实时执行每一步。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型和大型视觉模型的发展推动了多模态视觉-文本推理能力的快速进步，但现有的视觉语言模型（VLMs）存在泛化性能问题。&lt;h4&gt;目的&lt;/h4&gt;提出VLAgent，以提高视觉-文本推理的泛化性能。&lt;h4&gt;方法&lt;/h4&gt;VLAgent通过上下文学习微调LLM生成每项文本-视觉推理任务的逐步计划；在执行计划时，通过神经符号执行模块的逐步优化生成高置信度的推理结果。&lt;h4&gt;主要发现&lt;/h4&gt;VLAgent有三个独特的设计特点：通过上下文学习提高计划生成质量；设计语法-语义解析器来识别和纠正LLM生成的计划脚本中的逻辑错误；使用集成方法提高步执行器的泛化性能。&lt;h4&gt;结论&lt;/h4&gt;在四个视觉推理基准测试（GQA、MME、NLVR2、VQAv2）中，VLAgent相较于现有的VLMs和基于LLM的视觉组合方法（如ViperGPT和VisProg）实现了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;The advancement in large language models (LLMs) and large vision models has fueled the rapid progress in multi-modal visual-text reasoning capabilities. However, existing vision-language models (VLMs) to date suffer from generalization performance. Inspired by recent development in LLMs for visual reasoning, this paper presents VLAgent, an AI system that can create a step-by-step visual reasoning plan with an easy-to-understand script and execute each step of the plan in real time by integrating planning script with execution verifications via an automated process supported by VLAgent. In the task planning phase, VLAgent fine-tunes an LLM through in-context learning to generate a step-by-step planner for each user-submitted text-visual reasoning task. During the plan execution phase, VLAgent progressively refines the composition of neuro-symbolic executable modules to generate high-confidence reasoning results. VLAgent has three unique design characteristics: First, we improve the quality of plan generation through in-context learning, improving logic reasoning by reducing erroneous logic steps, incorrect programs, and LLM hallucinations. Second, we design a syntax-semantics parser to identify and correct additional logic errors of the LLM-generated planning script prior to launching the plan executor. Finally, we employ the ensemble method to improve the generalization performance of our step-executor. Extensive experiments with four visual reasoning benchmarks (GQA, MME, NLVR2, VQAv2) show that VLAgent achieves significant performance enhancement for multimodal text-visual reasoning applications, compared to the existing representative VLMs and LLM-based visual composition approaches like ViperGPT and VisProg, thanks to the novel optimization modules of VLAgent back-engine (SS-Parser, Plan Repairer, Output Verifiers). Code and data will be made available upon paper acceptance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advancement in large language models (LLMs) and large vision models hasfueled the rapid progress in multi-modal visual-text reasoning capabilities.However, existing vision-language models (VLMs) to date suffer fromgeneralization performance. Inspired by recent development in LLMs for visualreasoning, this paper presents VLAgent, an AI system that can create astep-by-step visual reasoning plan with an easy-to-understand script andexecute each step of the plan in real time by integrating planning script withexecution verifications via an automated process supported by VLAgent. In thetask planning phase, VLAgent fine-tunes an LLM through in-context learning togenerate a step-by-step planner for each user-submitted text-visual reasoningtask. During the plan execution phase, VLAgent progressively refines thecomposition of neuro-symbolic executable modules to generate high-confidencereasoning results. VLAgent has three unique design characteristics: First, weimprove the quality of plan generation through in-context learning, improvinglogic reasoning by reducing erroneous logic steps, incorrect programs, and LLMhallucinations. Second, we design a syntax-semantics parser to identify andcorrect additional logic errors of the LLM-generated planning script prior tolaunching the plan executor. Finally, we employ the ensemble method to improvethe generalization performance of our step-executor. Extensive experiments withfour visual reasoning benchmarks (GQA, MME, NLVR2, VQAv2) show that VLAgentachieves significant performance enhancement for multimodal text-visualreasoning applications, compared to the exiting representative VLMs and LLMbased visual composition approaches like ViperGPT and VisProg, thanks to thenovel optimization modules of VLAgent back-engine (SS-Parser, Plan Repairer,Output Verifiers). Code and data will be made available upon paper acceptance.</description>
      <author>example@mail.com (Yichang Xu, Gaowen Liu, Ramana Rao Kompella, Sihao Hu, Tiansheng Huang, Fatih Ilhan, Selim Furkan Tekin, Zachary Yahn, Ling Liu)</author>
      <guid isPermaLink="false">2506.07778v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Evidential Spectrum-Aware Contrastive Learning for OOD Detection in Dynamic Graphs</title>
      <link>http://arxiv.org/abs/2506.07417v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages,5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了动态图中的Out-of-distribution (OOD)检测问题，提出了一种基于证据深度学习（EDL）的OOD检测方法EviSEC，通过证据谱增强对比学习来提高OOD检测的准确性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;在安全敏感领域，动态图中的OOD检测变得尤为重要，但现有的OOD检测方法主要针对静态图，存在单点估计引起的偏差和方差较大，以及缺乏OOD训练数据导致的评分同质化等问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的OOD检测方法，旨在提高动态图中OOD检测的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;首先，通过证据深度学习的视角研究动态图中的OOD检测。具体地，提出EviSEC，通过证据谱增强对比学习来设计一个证据神经网络，并引入谱域增强模块生成OOD近似，以识别具有高OOD评分的模式。&lt;h4&gt;主要发现&lt;/h4&gt;EviSEC通过重新定义输出为后验Dirichlet分布，解释了输入的随机性，并能够生成具有高OOD评分的OOD近似，从而扩大ID和OOD数据之间的评分差距，缓解评分同质化问题。&lt;h4&gt;结论&lt;/h4&gt;在真实世界数据集上的实验表明，EviSEC能够有效地检测动态图中的OOD样本。&lt;h4&gt;翻译&lt;/h4&gt;Recently, Out-of-distribution (OOD) detection in dynamic graphs, which aims to identify whether incoming data deviates from the distribution of the in-distribution (ID) training set, has garnered considerable attention in security-sensitive fields. Current OOD detection paradigms primarily focus on static graphs and confront two critical challenges: i) high bias and high variance caused by single-point estimation, which makes the predictions sensitive to randomness in the data; ii) score homogenization resulting from the lack of OOD training data, where the model only learns ID-specific patterns, resulting in overall low OOD scores and a narrow score gap between ID and OOD data. To tackle these issues, we first investigate OOD detection in dynamic graphs through the lens of Evidential Deep Learning (EDL). Specifically, we propose EviSEC, an innovative and effective OOD detector via Evidential Spectrum-awarE Contrastive Learning. We design an evidential neural network to redefine the output as the posterior Dirichlet distribution, explaining the randomness of inputs through the uncertainty of distribution, which is overlooked by single-point estimation. Moreover, spectrum-areaugmentation module generates OOD approximations to identify patterns with high OOD scores, thereby widening the score gap between ID and OOD data and mitigating score homogenization. Extensive experiments on real-world datasets demonstrate that EviSAC effectively detects OOD samples in dynamic graphs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Out-of-distribution (OOD) detection in dynamic graphs, which aimsto identify whether incoming data deviates from the distribution of thein-distribution (ID) training set, has garnered considerable attention insecurity-sensitive fields. Current OOD detection paradigms primarily focus onstatic graphs and confront two critical challenges: i) high bias and highvariance caused by single-point estimation, which makes the predictionssensitive to randomness in the data; ii) score homogenization resulting fromthe lack of OOD training data, where the model only learns ID-specificpatterns, resulting in overall low OOD scores and a narrow score gap between IDand OOD data. To tackle these issues, we first investigate OOD detection indynamic graphs through the lens of Evidential Deep Learning (EDL).Specifically, we propose EviSEC, an innovative and effective OOD detector viaEvidential Spectrum-awarE Contrastive Learning. We design an evidential neuralnetwork to redefine the output as the posterior Dirichlet distribution,explaining the randomness of inputs through the uncertainty of distribution,which is overlooked by single-point estimation. Moreover, spectrum-awareaugmentation module generates OOD approximations to identify patterns with highOOD scores, thereby widening the score gap between ID and OOD data andmitigating score homogenization. Extensive experiments on real-world datasetsdemonstrate that EviSAC effectively detects OOD samples in dynamic graphs.</description>
      <author>example@mail.com (Nan Sun, Xixun Lin, Zhiheng Zhou, Yanmin Shang, Zhenlin Cheng, Yanan Cao)</author>
      <guid isPermaLink="false">2506.07417v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Flow-Anything: Learning Real-World Optical Flow Estimation from Large-Scale Single-view Images</title>
      <link>http://arxiv.org/abs/2506.07740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Flow-Anything的大规模数据生成框架，用于从现实世界的单视图图像中学习光流估计，旨在解决现实应用中的域差距和数据扩展限制。&lt;h4&gt;背景&lt;/h4&gt;光流估计是计算机视觉的一个关键子领域，但在实际应用中，由动画合成数据集训练的鲁棒性有限。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出Flow-Anything框架，旨在从现实世界的单视图图像中学习光流估计。&lt;h4&gt;方法&lt;/h4&gt;Flow-Anything框架采用两个有效步骤来促进数据扩展：第一步是将单视图图像转换为3D表示，第二步是开发一个对象无关的体积渲染模块和一个深度感知修复模块来模拟3D表示中的动态对象。&lt;h4&gt;主要发现&lt;/h4&gt;首次证明了从大规模现实世界图像生成光流训练数据的优势，在合成数据集上优于最先进的无监督方法和监督方法。&lt;h4&gt;结论&lt;/h4&gt;Flow-Anything模型作为基础模型，增强了各种下游视频任务的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：光流估计是计算机视觉的一个关键子领域，它是视频任务的基础。然而，由于训练数据集的合成动画性质，其实际应用的鲁棒性有限。这引入了当应用于现实世界应用时的域差距，并限制了数据扩展带来的好处。为了解决这些挑战，我们提出了Flow-Anything，这是一个大规模数据生成框架，旨在从现实世界的任何单视图图像中学习光流估计。我们采用两个有效步骤来使数据扩展变得可行。首先，我们使用先进的单目深度估计网络将单视图图像转换为3D表示。这使我们能够在虚拟摄像机下渲染光流和新的视图图像。其次，我们开发了一个对象无关的体积渲染模块和一个深度感知修复模块来模拟3D表示中的动态对象。这两个步骤使我们能够从大规模的单视图图像中生成用于训练的逼真数据集，即FA-Flow数据集。首次，我们证明了从大规模现实世界图像生成光流训练数据的优势，在合成数据集上优于最先进的无监督方法和监督方法。此外，我们的模型作为基础模型，增强了各种下游视频任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optical flow estimation is a crucial subfield of computer vision, serving asa foundation for video tasks. However, the real-world robustness is limited byanimated synthetic datasets for training. This introduces domain gaps whenapplied to real-world applications and limits the benefits of scaling updatasets. To address these challenges, we propose \textbf{Flow-Anything}, alarge-scale data generation framework designed to learn optical flow estimationfrom any single-view images in the real world. We employ two effective steps tomake data scaling-up promising. First, we convert a single-view image into a 3Drepresentation using advanced monocular depth estimation networks. This allowsus to render optical flow and novel view images under a virtual camera. Second,we develop an Object-Independent Volume Rendering module and a Depth-AwareInpainting module to model the dynamic objects in the 3D representation. Thesetwo steps allow us to generate realistic datasets for training from large-scalesingle-view images, namely \textbf{FA-Flow Dataset}. For the first time, wedemonstrate the benefits of generating optical flow training data fromlarge-scale real-world images, outperforming the most advanced unsupervisedmethods and supervised methods on synthetic datasets. Moreover, our modelsserve as a foundation model and enhance the performance of various downstreamvideo tasks.</description>
      <author>example@mail.com (Yingping Liang, Ying Fu, Yutao Hu, Wenqi Shao, Jiaming Liu, Debing Zhang)</author>
      <guid isPermaLink="false">2506.07740v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Taking Flight with Dialogue: Enabling Natural Language Control for PX4-based Drone Agent</title>
      <link>http://arxiv.org/abs/2506.07509v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Source code available at:  https://github.com/limshoonkit/ros2-agent-ws&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种开源的智能框架，用于自然语言控制无人机，并在仿真和定制多旋翼平台上对其性能进行了评估。&lt;h4&gt;背景&lt;/h4&gt;目前，基于地面的人工智能技术主要集中在类人形和轮式机器人上，而空中机器人相对较少被探索。最先进的无人机多模态视觉-语言系统通常依赖于仅限于资源丰富的组织的闭源模型。&lt;h4&gt;目的&lt;/h4&gt;为了民主化无人机的自然语言控制，研究提出了一种开源的智能框架。&lt;h4&gt;方法&lt;/h4&gt;该框架集成了基于PX4的飞行控制、Robot Operating System 2 (ROS 2) 中间件和本地托管模型（使用Ollama）。研究在仿真环境和定制四旋翼平台上对性能进行了评估，比较了四种大型语言模型（LLM）在命令生成方面的表现和三种视觉-语言模型（VLM）在场景理解方面的表现。&lt;h4&gt;主要发现&lt;/h4&gt;在仿真和实际平台上的评估表明，该框架能够有效实现无人机对自然语言指令的理解和执行。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法和框架为无人机自然语言控制提供了新的可能性，有助于推广这项技术。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in agentic and physical artificial intelligence (AI) have largely focused on ground-based platforms such as humanoid and wheeled robots, leaving aerial robots relatively underexplored. Meanwhile, state-of-the-art unmanned aerial vehicle (UAV) multimodal vision-language systems typically rely on closed-source models accessible only to well-resourced organizations. To democratize natural language control of autonomous drones, we present an open-source agentic framework that integrates PX4-based flight control, Robot Operating System 2 (ROS 2) middleware, and locally hosted models using Ollama. We evaluate performance both in simulation and on a custom quadcopter platform, benchmarking four large language model (LLM) families for command generation and three vision-language model (VLM) families for scene understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in agentic and physical artificial intelligence (AI) havelargely focused on ground-based platforms such as humanoid and wheeled robots,leaving aerial robots relatively underexplored. Meanwhile, state-of-the-artunmanned aerial vehicle (UAV) multimodal vision-language systems typically relyon closed-source models accessible only to well-resourced organizations. Todemocratize natural language control of autonomous drones, we present anopen-source agentic framework that integrates PX4-based flight control, RobotOperating System 2 (ROS 2) middleware, and locally hosted models using Ollama.We evaluate performance both in simulation and on a custom quadcopter platform,benchmarking four large language model (LLM) families for command generationand three vision-language model (VLM) families for scene understanding.</description>
      <author>example@mail.com (Shoon Kit Lim, Melissa Jia Ying Chong, Jing Huey Khor, Ting Yang Ling)</author>
      <guid isPermaLink="false">2506.07509v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Multiple Object Stitching for Unsupervised Representation Learning</title>
      <link>http://arxiv.org/abs/2506.07364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MOS的简单而有效的方法，用于改进多对象图像的无监督表示。&lt;h4&gt;背景&lt;/h4&gt;对比学习在单对象中心图像的无监督表示方面取得了显著进展，但在具有多个对象的广泛图像上表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出MOS方法，以改进多对象图像的无监督表示，特别是在对象检测和语义分割等复杂下游任务中。&lt;h4&gt;方法&lt;/h4&gt;通过拼接单对象中心图像来构建多对象图像，从而在不需要人工标注的情况下提供多对象图像之间的额外对象对应关系。&lt;h4&gt;主要发现&lt;/h4&gt;在ImageNet、CIFAR和COCO数据集上的实验结果表明，该方法在单对象中心图像和多对象图像上均取得了领先的无监督表示性能。&lt;h4&gt;结论&lt;/h4&gt;MOS方法能够提供更详细的表示，有助于复杂的下游任务，并且代码可在https://github.com/visresearch/MultipleObjectStitching上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/visresearch/MultipleObjectStitching&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning for single object centric images has achieved remarkableprogress on unsupervised representation, but suffering inferior performance onthe widespread images with multiple objects. In this paper, we propose a simplebut effective method, Multiple Object Stitching (MOS), to refine theunsupervised representation for multi-object images. Specifically, we constructthe multi-object images by stitching the single object centric ones, where theobjects in the synthesized multi-object images are predetermined. Hence,compared to the existing contrastive methods, our method provides additionalobject correspondences between multi-object images without human annotations.In this manner, our method pays more attention to the representations of eachobject in multi-object image, thus providing more detailed representations forcomplicated downstream tasks, such as object detection and semanticsegmentation. Experimental results on ImageNet, CIFAR and COCO datasetsdemonstrate that our proposed method achieves the leading unsupervisedrepresentation performance on both single object centric images andmulti-object ones. The source code is available athttps://github.com/visresearch/MultipleObjectStitching.</description>
      <author>example@mail.com (Chengchao Shen, Dawei Liu, Jianxin Wang)</author>
      <guid isPermaLink="false">2506.07364v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SpatialLM: Training Large Language Models for Structured Indoor Modeling</title>
      <link>http://arxiv.org/abs/2506.07491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SpatialLM是一种处理3D点云数据并生成结构化3D场景理解输出的大型语言模型。&lt;h4&gt;背景&lt;/h4&gt;之前的方法通过特定的网络设计来处理任务，而SpatialLM遵循标准的多模态LLM架构，并直接从开源LLMs进行微调。&lt;h4&gt;目的&lt;/h4&gt;提升现代LLM的空间理解能力，应用于增强现实、实体机器人等领域。&lt;h4&gt;方法&lt;/h4&gt;收集了一个包含12,328个室内场景（54,778个房间）点云的大规模、高质量合成数据集，并对建模和训练决策进行了深入研究。&lt;h4&gt;主要发现&lt;/h4&gt;SpatialLM在布局估计方面表现出色，在3D物体检测方面也有竞争力。&lt;h4&gt;结论&lt;/h4&gt;SpatialLM为提升现代LLM的空间理解能力提供了一条可行的路径。&lt;h4&gt;翻译&lt;/h4&gt;SpatialLM是一种为处理3D点云数据并生成结构化的3D场景理解输出而设计的大型语言模型。与之前依赖特定网络设计的方法不同，我们的模型遵循标准的多模态LLM架构，并直接从开源LLMs进行微调。为了训练SpatialLM，我们收集了一个包含12,328个室内场景（54,778个房间）点云的大规模、高质量合成数据集，并对建模和训练决策进行了深入研究。在公共基准测试中，我们的模型在布局估计方面表现出色，在3D物体检测方面也有竞争力。据此，我们展示了一条增强现代LLM空间理解能力、适用于增强现实、实体机器人等应用的可行路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; SpatialLM is a large language model designed to process 3D point cloud dataand generate structured 3D scene understanding outputs. These outputs includearchitectural elements like walls, doors, windows, and oriented object boxeswith their semantic categories. Unlike previous methods which exploittask-specific network designs, our model adheres to the standard multimodal LLMarchitecture and is fine-tuned directly from open-source LLMs.  To train SpatialLM, we collect a large-scale, high-quality synthetic datasetconsisting of the point clouds of 12,328 indoor scenes (54,778 rooms) withground-truth 3D annotations, and conduct a careful study on various modelingand training decisions. On public benchmarks, our model gives state-of-the-artperformance in layout estimation and competitive results in 3D objectdetection. With that, we show a feasible path for enhancing the spatialunderstanding capabilities of modern LLMs for applications in augmentedreality, embodied robotics, and more.</description>
      <author>example@mail.com (Yongsen Mao, Junhao Zhong, Chuan Fang, Jia Zheng, Rui Tang, Hao Zhu, Ping Tan, Zihan Zhou)</author>
      <guid isPermaLink="false">2506.07491v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Flowing Datasets with Wasserstein over Wasserstein Gradient Flows</title>
      <link>http://arxiv.org/abs/2506.07534v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as an oral at ICML2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种处理机器学习中概率分布数据的创新方法，用于设计在概率分布上的可处理梯度流。&lt;h4&gt;背景&lt;/h4&gt;许多机器学习应用涉及以概率分布形式表示的数据，需要新的技术来设计在无限维对象上的可处理梯度流。&lt;h4&gt;目的&lt;/h4&gt;设计一种方法，能够处理标记数据集，应用于领域自适应、迁移学习或数据集蒸馏等任务。&lt;h4&gt;方法&lt;/h4&gt;提出用特征的条件分布来表示每个类别，并将数据集建模为支持在这些类别上的混合分布，这些类别本身也是概率分布。在空间中引入了最优传输的度量结构——Wasserstein over Wasserstein (WoW) 距离，并导出了空间上的微分结构，定义了WoW梯度流。&lt;h4&gt;主要发现&lt;/h4&gt;通过这种方法，可以设计出在空间上减少给定目标泛函的动力学。&lt;h4&gt;结论&lt;/h4&gt;将该方法应用于迁移学习和数据集蒸馏任务，利用梯度流构造以及基于Sliced-Wasserstein核的最大均值差异等新颖的可处理泛函。&lt;h4&gt;翻译&lt;/h4&gt;Many applications in machine learning involve data represented as probability distributions. The emergence of such data requires radically novel techniques to design tractable gradient flows on probability distributions over this type of (infinite-dimensional) objects. For instance, being able to flow labeled datasets is a core task for applications ranging from domain adaptation to transfer learning or dataset distillation. In this setting, we propose to represent each class by the associated conditional distribution of features, and to model the dataset as a mixture distribution supported on these classes (which are themselves probability distributions), meaning that labeled datasets can be seen as probability distributions over probability distributions. We endow this space with a metric structure from optimal transport, namely the Wasserstein over Wasserstein (WoW) distance, derive a differential structure on this space, and define WoW gradient flows. The latter enables to design dynamics over this space that decrease a given objective functional. We apply our framework to transfer learning and dataset distillation tasks, leveraging our gradient flow construction as well as novel tractable functionals that take the form of Maximum Mean Discrepancies with Sliced-Wasserstein based kernels between probability distributions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many applications in machine learning involve data represented as probabilitydistributions. The emergence of such data requires radically novel techniquesto design tractable gradient flows on probability distributions over this typeof (infinite-dimensional) objects. For instance, being able to flow labeleddatasets is a core task for applications ranging from domain adaptation totransfer learning or dataset distillation. In this setting, we propose torepresent each class by the associated conditional distribution of features,and to model the dataset as a mixture distribution supported on these classes(which are themselves probability distributions), meaning that labeled datasetscan be seen as probability distributions over probability distributions. Weendow this space with a metric structure from optimal transport, namely theWasserstein over Wasserstein (WoW) distance, derive a differential structure onthis space, and define WoW gradient flows. The latter enables to designdynamics over this space that decrease a given objective functional. We applyour framework to transfer learning and dataset distillation tasks, leveragingour gradient flow construction as well as novel tractable functionals that takethe form of Maximum Mean Discrepancies with Sliced-Wasserstein based kernelsbetween probability distributions.</description>
      <author>example@mail.com (Clément Bonet, Christophe Vauthier, Anna Korba)</author>
      <guid isPermaLink="false">2506.07534v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model Empowered Synesthesia of Machines (SoM): AI-native Intelligent Multi-Modal Sensing-Communication Integration</title>
      <link>http://arxiv.org/abs/2506.07647v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为“机器通感”（SoM）的新范式，用于支持未来智能多功能第六代（6G）无线通信网络，并针对现有SoM系统设计中的挑战，提出了基于基础模型（FMs）的系统设计框架。&lt;h4&gt;背景&lt;/h4&gt;现有的SoM系统设计依赖于特定任务的AI模型，面临数据集稀缺、建模能力受限、泛化能力差和通用性有限等问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于FMs的系统设计框架，以解决现有SoM系统设计中的挑战。&lt;h4&gt;方法&lt;/h4&gt;对FMs进行系统分类，包括通用FMs、大型语言模型（LLMs）和SoM领域特定FMs（无线基础模型）。提出了基于LLM和无线基础模型的设计路线图，并提供了设计框架和案例研究。&lt;h4&gt;主要发现&lt;/h4&gt;FMs在解决SoM系统中的现有挑战方面具有关键特性，并展示了相较于特定任务模型的优势。&lt;h4&gt;结论&lt;/h4&gt;本文总结了FMs在SoM系统设计中的应用潜力，并指出了未来研究的潜在方向。&lt;h4&gt;翻译&lt;/h4&gt;To support future intelligent multifunctional sixth-generation (6G) wireless communication networks, Synesthesia of Machines (SoM) is proposed as a new paradigm for artificial intelligence (AI)-native intelligent multi-modal sensing-communication integration. However, existing SoM system designs rely on task-specific AI models and face challenges such as scarcity of massive high-quality datasets, constrained modeling capability, poor generalization, and limited universality. Recently, foundation models (FMs) have emerged as a new deep learning paradigm and have been preliminarily applied to SoM-related tasks, but a systematic design framework is still lacking. In this paper, we for the first time present a systematic categorization of FMs for SoM system design, dividing them into general-purpose FMs, specifically large language models (LLMs), and SoM domain-specific FMs, referred to as wireless foundation models. Furthermore, we derive key characteristics of FMs in addressing existing challenges in SoM systems and propose two corresponding roadmaps, i.e., LLM-based and wireless foundation model-based design. For each roadmap, we provide a framework containing key design steps as a guiding pipeline and several representative case studies of FM-empowered SoM system design. Specifically, we propose LLM-based path loss generation (LLM4PG) and scatterer generation (LLM4SG) schemes, and wireless channel foundation model (WiCo) for SoM mechanism exploration, LLM-based wireless multi-task SoM transceiver (LLM4WM) and wireless foundation model (WiFo) for SoM-enhanced transceiver design, and wireless cooperative perception foundation model (WiPo) for SoM-enhanced cooperative perception, demonstrating the significant superiority of FMs over task-specific models. Finally, we summarize and highlight potential directions for future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To support future intelligent multifunctional sixth-generation (6G) wirelesscommunication networks, Synesthesia of Machines (SoM) is proposed as a novelparadigm for artificial intelligence (AI)-native intelligent multi-modalsensing-communication integration. However, existing SoM system designs rely ontask-specific AI models and face challenges such as scarcity of massivehigh-quality datasets, constrained modeling capability, poor generalization,and limited universality. Recently, foundation models (FMs) have emerged as anew deep learning paradigm and have been preliminarily applied to SoM-relatedtasks, but a systematic design framework is still lacking. In this paper, wefor the first time present a systematic categorization of FMs for SoM systemdesign, dividing them into general-purpose FMs, specifically large languagemodels (LLMs), and SoM domain-specific FMs, referred to as wireless foundationmodels. Furthermore, we derive key characteristics of FMs in addressingexisting challenges in SoM systems and propose two corresponding roadmaps,i.e., LLM-based and wireless foundation model-based design. For each roadmap,we provide a framework containing key design steps as a guiding pipeline andseveral representative case studies of FM-empowered SoM system design.Specifically, we propose LLM-based path loss generation (LLM4PG) and scatterergeneration (LLM4SG) schemes, and wireless channel foundation model (WiCo) forSoM mechanism exploration, LLM-based wireless multi-task SoM transceiver(LLM4WM) and wireless foundation model (WiFo) for SoM-enhanced transceiverdesign, and wireless cooperative perception foundation model (WiPo) forSoM-enhanced cooperative perception, demonstrating the significant superiorityof FMs over task-specific models. Finally, we summarize and highlight potentialdirections for future research.</description>
      <author>example@mail.com (Xiang Cheng, Boxun Liu, Xuanyu Liu, Ensong Liu, Ziwei Huang)</author>
      <guid isPermaLink="false">2506.07647v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding</title>
      <link>http://arxiv.org/abs/2506.07600v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SceneRAG是一种统一的框架，通过结合大型语言模型处理视频中的ASR转写和时序元数据，将视频分割成与叙事一致的场景，从而有效理解长视频内容。&lt;h4&gt;背景&lt;/h4&gt;尽管检索增强生成（RAG）在视频理解方面取得了进展，但长视频内容的有效理解仍因视频数据的规模和复杂性而未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为SceneRAG的框架，以实现长视频内容的有效理解。&lt;h4&gt;方法&lt;/h4&gt;SceneRAG通过处理ASR转写和时序元数据将视频分割成场景，并使用轻量级启发式方法和迭代校正来细化场景边界。每个场景通过融合视觉和文本信息来提取实体关系，并动态构建知识图，实现多跳检索和生成。&lt;h4&gt;主要发现&lt;/h4&gt;在LongerVideos基准测试中，SceneRAG在生成任务上的胜率达到72.5%，显著优于先前基线。&lt;h4&gt;结论&lt;/h4&gt;SceneRAG能够有效地理解长视频内容，并在视频理解任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;尽管最近在视频理解方面检索增强生成（RAG）取得了进展，但由于视频数据的规模和复杂性，有效理解长视频内容仍然未得到充分探索。当前的RAG方法通常将视频分割成固定长度的片段，这往往破坏了上下文信息的连续性，并且无法捕捉到真实的场景边界。受人类将连续经验自然组织成连贯场景的能力的启发，我们提出了一种统一的框架，名为SceneRAG，该框架利用大型语言模型通过处理ASR转录本和时序元数据将视频分割成叙事一致的场景。SceneRAG还通过轻量级启发式方法和迭代校正进一步细化这些初始边界。对于每个场景，该框架融合来自视觉和文本模态的信息来提取实体关系，并动态构建知识图，从而实现考虑长距离依赖关系的稳健的多跳检索和生成。在LongerVideos基准测试中的实验，包含超过134小时的多样化内容，证实SceneRAG在生成任务上的胜率高达72.5%，显著优于先前基线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite recent advances in retrieval-augmented generation (RAG) for videounderstanding, effectively understanding long-form video content remainsunderexplored due to the vast scale and high complexity of video data. CurrentRAG approaches typically segment videos into fixed-length chunks, which oftendisrupts the continuity of contextual information and fails to captureauthentic scene boundaries. Inspired by the human ability to naturally organizecontinuous experiences into coherent scenes, we present SceneRAG, a unifiedframework that leverages large language models to segment videos intonarrative-consistent scenes by processing ASR transcripts alongside temporalmetadata. SceneRAG further sharpens these initial boundaries throughlightweight heuristics and iterative correction. For each scene, the frameworkfuses information from both visual and textual modalities to extract entityrelations and dynamically builds a knowledge graph, enabling robust multi-hopretrieval and generation that account for long-range dependencies. Experimentson the LongerVideos benchmark, featuring over 134 hours of diverse content,confirm that SceneRAG substantially outperforms prior baselines, achieving awin rate of up to 72.5 percent on generation tasks.</description>
      <author>example@mail.com (Nianbo Zeng, Haowen Hou, Fei Richard Yu, Si Shi, Ying Tiffany He)</author>
      <guid isPermaLink="false">2506.07600v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Variational Supervised Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.07413v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;对比学习在塑造不同模态的表示空间方面表现出高效和适应性，但存在两个主要限制。为了解决这些问题，提出了变分监督对比学习（VarCon），该学习通过变分推理和最大化后验加权证据下界（ELBO）来改进对比学习。&lt;h4&gt;背景&lt;/h4&gt;对比学习通过拉近相似样本和推开不同样本来塑造表示空间，但在没有显式调节嵌入分布的情况下，语义相关的实例可能会被无意中推开。此外，过度依赖大批次负样本和定制增强也阻碍了泛化。&lt;h4&gt;目的&lt;/h4&gt;提出VarCon来克服对比学习的限制，包括避免语义相关实例被推开，以及减少对大批次负样本和定制增强的依赖。&lt;h4&gt;方法&lt;/h4&gt;VarCon将监督对比学习重新定义为对潜在类变量的变分推理，并最大化后验加权证据下界（ELBO），以实现高效的类感知匹配和控制嵌入空间中的类内分散。&lt;h4&gt;主要发现&lt;/h4&gt;VarCon在CIFAR-10、CIFAR-100、ImageNet-100和ImageNet-1K上的实验表明，VarCon在对比学习框架中实现了最先进的性能，同时在图像数据上仅用200个epoch就收敛；它产生了更清晰的决策边界和语义组织；在少样本学习中优于监督基线，并且在各种增强策略下表现出更强的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;VarCon是一种有效的对比学习方法，能够显著提高性能，并具有更好的泛化能力和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning has proven to be highly efficient and adaptable inshaping representation spaces across diverse modalities by pulling similarsamples together and pushing dissimilar ones apart. However, two keylimitations persist: (1) Without explicit regulation of the embeddingdistribution, semantically related instances can inadvertently be pushed apartunless complementary signals guide pair selection, and (2) excessive relianceon large in-batch negatives and tailored augmentations hinders generalization.To address these limitations, we propose Variational Supervised ContrastiveLearning (VarCon), which reformulates supervised contrastive learning asvariational inference over latent class variables and maximizes aposterior-weighted evidence lower bound (ELBO) that replaces exhaustivepair-wise comparisons for efficient class-aware matching and grantsfine-grained control over intra-class dispersion in the embedding space.Trained exclusively on image data, our experiments on CIFAR-10, CIFAR-100,ImageNet-100, and ImageNet-1K show that VarCon (1) achieves state-of-the-artperformance for contrastive learning frameworks, reaching 79.36% Top-1 accuracyon ImageNet-1K and 78.29% on CIFAR-100 with a ResNet-50 encoder whileconverging in just 200 epochs; (2) yields substantially clearer decisionboundaries and semantic organization in the embedding space, as evidenced byKNN classification, hierarchical clustering results, and transfer-learningassessments; and (3) demonstrates superior performance in few-shot learningthan supervised baseline and superior robustness across various augmentationstrategies.</description>
      <author>example@mail.com (Ziwen Wang, Jiajun Fan, Thao Nguyen, Heng Ji, Ge Liu)</author>
      <guid isPermaLink="false">2506.07413v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning and Explainable AI for Brain Tumor Classification: A Study Using MRI Data from Bangladesh</title>
      <link>http://arxiv.org/abs/2506.07228v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2024 6th International Conference on Sustainable Technologies for  Industry 5.0 (STI)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究旨在解决脑肿瘤诊断问题，通过创建一个利用孟加拉国多医院MRI数据的自动脑肿瘤分类系统，结合深度学习模型和可解释人工智能方法，提高脑肿瘤检测和识别的准确性。&lt;h4&gt;背景&lt;/h4&gt;脑肿瘤，无论良性还是恶性，都存在很大的健康风险，恶性肿瘤由于其快速和不受控制的增殖而更加危险。在医疗基础设施有限的地区，如孟加拉国，及时诊断至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一个自动化的脑肿瘤分类系统，以提高诊断效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;使用VGG16、VGG19和ResNet50等深度学习模型对脑瘤、脑膜瘤和多种脑癌进行分类。采用Grad-CAM和Grad-CAM++等可解释人工智能方法来增强模型的可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;VGG16模型达到了99.17%的准确率。集成可解释人工智能（XAI）方法提高了系统的透明度和稳定性。&lt;h4&gt;结论&lt;/h4&gt;深度学习模型与可解释人工智能的结合，在资源有限的环境中，如孟加拉国，能够有效提高脑肿瘤的检测和识别。&lt;h4&gt;翻译&lt;/h4&gt;This study aims to address the issue of brain tumor diagnosis by developing an automated brain tumor classification system using MRI data obtained from many hospitals in Bangladesh, combining deep learning models with explainable artificial intelligence (XAI) methods to enhance the accuracy of brain tumor detection and identification.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/STI64222.2024.10951092&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain tumors, regardless of being benign or malignant, pose considerablehealth risks, with malignant tumors being more perilous due to their swift anduncontrolled proliferation, resulting in malignancy. Timely identification iscrucial for enhancing patient outcomes, particularly in nations such asBangladesh, where healthcare infrastructure is constrained. Manual MRI analysisis arduous and susceptible to inaccuracies, rendering it inefficient for promptdiagnosis. This research sought to tackle these problems by creating anautomated brain tumor classification system utilizing MRI data obtained frommany hospitals in Bangladesh. Advanced deep learning models, including VGG16,VGG19, and ResNet50, were utilized to classify glioma, meningioma, and variousbrain cancers. Explainable AI (XAI) methodologies, such as Grad-CAM andGrad-CAM++, were employed to improve model interpretability by emphasizing thecritical areas in MRI scans that influenced the categorization. VGG16 achievedthe most accuracy, attaining 99.17%. The integration of XAI enhanced thesystem's transparency and stability, rendering it more appropriate for clinicalapplication in resource-limited environments such as Bangladesh. This studyhighlights the capability of deep learning models, in conjunction withexplainable artificial intelligence (XAI), to enhance brain tumor detection andidentification in areas with restricted access to advanced medicaltechnologies.</description>
      <author>example@mail.com (Shuvashis Sarker)</author>
      <guid isPermaLink="false">2506.07228v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Return of ChebNet: Understanding and Improving an Overlooked GNN on Long Range Tasks</title>
      <link>http://arxiv.org/abs/2506.07624v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文重新审视了ChebNet，一种早期的光谱图神经网络，并提出了Stable-ChebNet，一种稳定的ChebNet模型，以解决其训练过程中的不稳定性问题。&lt;h4&gt;背景&lt;/h4&gt;ChebNet最初被MPNNs的简单性和有效性所掩盖，MPNNs在捕捉局部图结构方面表现出色，但它们在捕捉节点之间的长距离依赖关系方面有限。&lt;h4&gt;目的&lt;/h4&gt;通过重新审视ChebNet，研究其建模节点间远程交互的能力，并解决其训练过程中的不稳定性问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的稳定模型Stable-ChebNet，该模型允许稳定的信息传播，并具有可控的动态特性，不需要使用特征分解、位置编码或图重连。&lt;h4&gt;主要发现&lt;/h4&gt;Stable-ChebNet在长距离基准测试中相对于经典的MPNNs和GTs表现出竞争力，同时保持了高阶多项式良好的可扩展性。此外，Stable-ChebNet在多个基准测试中实现了接近最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;Stable-ChebNet是一种稳定的图神经网络模型，能够有效地建模节点间的远程交互，并在多个基准测试中表现出优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;ChebNet is one of the earliest spectral GNNs and has been largely overshadowed by Message Passing Neural Networks (MPNNs), which are popular for their simplicity and effectiveness in capturing local graph structure. Despite their success, MPNNs are limited in their ability to capture long-range dependencies between nodes. This has led researchers to adapt MPNNs through rewiring or make use of Graph Transformers, which compromises the computational efficiency that characterized early spatial message-passing architectures and typically disregards the graph structure. Almost a decade after its original introduction, we revisit ChebNet to shed light on its ability to model distant node interactions. We find that out-of-box, ChebNet already shows competitive advantages relative to classical MPNNs and GTs on long-range benchmarks, while maintaining good scalability properties for high-order polynomials. However, we uncover that this polynomial expansion leads ChebNet to an unstable regime during training. To address this limitation, we cast ChebNet as a stable and non-dissipative dynamical system, which we coin Stable-ChebNet. Our Stable-ChebNet model allows for stable information propagation and has controllable dynamics which do not require the use of eigendecompositions, positional encodings, or graph rewiring. Across several benchmarks, Stable-ChebNet achieves near state-of-the-art performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; ChebNet, one of the earliest spectral GNNs, has largely been overshadowed byMessage Passing Neural Networks (MPNNs), which gained popularity for theirsimplicity and effectiveness in capturing local graph structure. Despite theirsuccess, MPNNs are limited in their ability to capture long-range dependenciesbetween nodes. This has led researchers to adapt MPNNs through rewiring or makeuse of Graph Transformers, which compromises the computational efficiency thatcharacterized early spatial message-passing architectures, and typicallydisregards the graph structure. Almost a decade after its originalintroduction, we revisit ChebNet to shed light on its ability to model distantnode interactions. We find that out-of-box, ChebNet already shows competitiveadvantages relative to classical MPNNs and GTs on long-range benchmarks, whilemaintaining good scalability properties for high-order polynomials. However, weuncover that this polynomial expansion leads ChebNet to an unstable regimeduring training. To address this limitation, we cast ChebNet as a stable andnon-dissipative dynamical system, which we coin Stable-ChebNet. OurStable-ChebNet model allows for stable information propagation, and hascontrollable dynamics which do not require the use of eigendecompositions,positional encodings, or graph rewiring. Across several benchmarks,Stable-ChebNet achieves near state-of-the-art performance.</description>
      <author>example@mail.com (Ali Hariri, Álvaro Arroyo, Alessio Gravina, Moshe Eliasof, Carola-Bibiane Schönlieb, Davide Bacciu, Kamyar Azizzadenesheli, Xiaowen Dong, Pierre Vandergheynst)</author>
      <guid isPermaLink="false">2506.07624v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Drive Any Mesh: 4D Latent Diffusion for Mesh Deformation from Video</title>
      <link>http://arxiv.org/abs/2506.07489v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了DriveAnyMesh方法，用于通过单目视频驱动网格。&lt;h4&gt;背景&lt;/h4&gt;当前4D生成技术在现代渲染引擎中面临挑战，隐式方法渲染效率低，不友好于基于光栅化的引擎，而骨骼方法需要大量手动工作且缺乏跨类别泛化能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一种4D扩散模型，用于去噪潜在集合序列，然后从点云轨迹序列解码生成网格动画。&lt;h4&gt;方法&lt;/h4&gt;这些潜在集合利用基于transformer的变分自编码器，同时捕捉3D形状和运动信息。通过使用时空的、基于transformer的扩散模型，信息在多个潜在帧之间交换，增强了生成结果的效率和泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，DriveAnyMesh可以快速生成高质量动画，且与现代渲染引擎兼容。&lt;h4&gt;结论&lt;/h4&gt;该方法在游戏和电影行业中具有潜在应用价值。&lt;h4&gt;翻译&lt;/h4&gt;We propose DriveAnyMesh, a method for driving mesh guided by monocular video. Current 4D generation techniques encounter challenges with modern rendering engines. Implicit methods have low rendering efficiency and are unfriendly torasterization-based engines, while skeletal methods demand significant manualeffort and lack cross-category generalization. Animating existing 3D assets, instead of creating 4D assets from scratch, demands a deep understanding of the input's 3D structure. To tackle these challenges, we present a 4D diffusion model that denoises sequences of latent sets, which are then decoded to producemesh animations from point cloud trajectory sequences. These latent sets leverage a transformer-based variational autoencoder, simultaneously capturing 3D shape and motion information. By employing a spatiotemporal, transformer-based diffusion model, information is exchanged across multiple latent frames, enhancing the efficiency and generalization of the generated results. Our experimental results demonstrate that DriveAnyMesh can rapidly produce high-quality animations for complex motions and is compatible with modern rendering engines. This method holds potential for applications in both the gaming and filming industries.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose DriveAnyMesh, a method for driving mesh guided by monocular video.Current 4D generation techniques encounter challenges with modern renderingengines. Implicit methods have low rendering efficiency and are unfriendly torasterization-based engines, while skeletal methods demand significant manualeffort and lack cross-category generalization. Animating existing 3D assets,instead of creating 4D assets from scratch, demands a deep understanding of theinput's 3D structure. To tackle these challenges, we present a 4D diffusionmodel that denoises sequences of latent sets, which are then decoded to producemesh animations from point cloud trajectory sequences. These latent setsleverage a transformer-based variational autoencoder, simultaneously capturing3D shape and motion information. By employing a spatiotemporal,transformer-based diffusion model, information is exchanged across multiplelatent frames, enhancing the efficiency and generalization of the generatedresults. Our experimental results demonstrate that DriveAnyMesh can rapidlyproduce high-quality animations for complex motions and is compatible withmodern rendering engines. This method holds potential for applications in boththe gaming and filming industries.</description>
      <author>example@mail.com (Yahao Shi, Yang Liu, Yanmin Wu, Xing Liu, Chen Zhao, Jie Luo, Bin Zhou)</author>
      <guid isPermaLink="false">2506.07489v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Text-Attributed Graph Learning through Selective Annotation and Graph Alignment</title>
      <link>http://arxiv.org/abs/2506.07168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GAGA的框架，用于高效学习文本属性图（TAGs）中的节点表示，通过标注代表性节点和边来减少标注时间和成本，同时通过两级行为模块有效整合标注图与TAG，提高分类准确率。&lt;h4&gt;背景&lt;/h4&gt;传统的图神经网络（GNNs）在处理文本属性图（TAGs）时往往表现不佳，因为每个节点都关联着复杂的文本信息。&lt;h4&gt;目的&lt;/h4&gt;克服传统方法在标注时间和成本上的不足，提高节点表示的效率。&lt;h4&gt;方法&lt;/h4&gt;GAGA通过以下方式实现其目的：1. 仅标注代表性节点和边，减少标注时间和成本；2. 构建标注图以捕捉这些标注之间的拓扑关系；3. 采用两级行为模块，将标注图与TAG进行有效整合，对齐其底层结构。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，GAGA在分类准确率上与或超过现有最佳方法，同时仅需标注1%的数据，显示出其高效率。&lt;h4&gt;结论&lt;/h4&gt;GAGA是一种高效且准确的框架，用于学习文本属性图中的节点表示，为处理此类数据提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;在文本属性图（TAGs）领域，传统的图神经网络（GNNs）由于每个节点关联的复杂文本信息而表现不佳。最近的方法通过利用大型语言模型（LLMs）来增强节点文本特征，提高了节点表示，但这些方法通常需要大量的标注或在所有节点上进行微调，这既耗时又昂贵。为了克服这些挑战，我们引入了GAGA，这是一种用于TAG表示学习的有效框架。GAGA通过仅关注标注代表性节点和边来减少标注时间和成本。它构建了一个标注图，捕捉这些标注之间的拓扑关系。此外，GAGA采用一个两级行为模块，有效地将标注图与TAG整合，对齐它们的底层结构。实验表明，GAGA在分类准确率上与或超过现有最佳方法，同时仅需标注1%的数据，证明了其高效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the realm of Text-attributed Graphs (TAGs), traditional graph neuralnetworks (GNNs) often fall short due to the complex textual informationassociated with each node. Recent methods have improved node representations byleveraging large language models (LLMs) to enhance node text features, butthese approaches typically require extensive annotations or fine-tuning acrossall nodes, which is both time-consuming and costly. To overcome thesechallenges, we introduce GAGA, an efficient framework for TAG representationlearning. GAGA reduces annotation time and cost by focusing on annotating onlyrepresentative nodes and edges. It constructs an annotation graph that capturesthe topological relationships among these annotations. Furthermore, GAGAemploys a two-level alignment module to effectively integrate the annotationgraph with the TAG, aligning their underlying structures. Experiments show thatGAGA achieves classification accuracies on par with or surpassingstate-of-the-art methods while requiring only 1% of the data to be annotated,demonstrating its high efficiency.</description>
      <author>example@mail.com (Huanyi Xie, Lijie Hu, Lu Yu, Tianhao Huang, Longfei Li, Meng Li, Jun Zhou, Huan Wang, Di Wang)</author>
      <guid isPermaLink="false">2506.07168v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>HeTa: Relation-wise Heterogeneous Graph Foundation Attack Model</title>
      <link>http://arxiv.org/abs/2506.07428v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的关系感知异构图基础攻击模型HeTa，用于评估异构图神经网络（HGNNs）的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的HGNN攻击方法通常需要复杂的参数重训练来生成特定场景的扰动，且HGNNs容易受到针对的攻击。&lt;h4&gt;目的&lt;/h4&gt;设计一个适用于HGNNs的基础攻击模型，能够实现不同HGNNs之间的泛化扰动，并快速适应新的异构图。&lt;h4&gt;方法&lt;/h4&gt;通过挖掘共享攻击单元设计攻击准则，引入基础代理模型来对齐异质性和识别共享关系感知攻击单元的重要性，并基于此实现关系级别的序列化攻击。&lt;h4&gt;主要发现&lt;/h4&gt;尽管HGNNs在模型设计和参数空间上存在显著差异，但从关系感知的角度来看，它们却共享一些常见的脆弱性模式。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，该方法具有强大的攻击性能和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Heterogeneous Graph Neural Networks (HGNNs) are vulnerable, highlighting the need for tailored attacks to assess their robustness and ensure security. However, existing HGNN attacks often require complex retraining of parameters to generate specific perturbations for new scenarios. Recently, foundation models have opened new horizons for the generalization of graph neural networks by capturing shared semantics across various graph distributions. This leads us to ask: Can we design a foundation attack model for HGNNs that enables generalizable perturbations across different HGNNs, and quickly adapts to new heterogeneous graphs (HGs)? Empirical findings reveal that, despite significant differences in model design and parameter space, different HGNNs surprisingly share common vulnerability patterns from a relation-aware perspective. Therefore, we explore how to design foundation HGNN attack criteria by mining shared attack units. In this paper, we propose a novel relation-wise heterogeneous graph foundation attack model, HeTa. We introduce a foundation surrogate model to align heterogeneity and identify the importance of shared relation-aware attack units. Building on this, we implement a serialized relation-by-relation attack based on the identified relational weights. In this way, the perturbation can be transferred to various target HGNNs and easily fine-tuned for new HGs. Extensive experiments exhibit powerful attack performances and generalizability of our method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterogeneous Graph Neural Networks (HGNNs) are vulnerable, highlighting theneed for tailored attacks to assess their robustness and ensure security.However, existing HGNN attacks often require complex retraining of parametersto generate specific perturbations for new scenarios. Recently, foundationmodels have opened new horizons for the generalization of graph neural networksby capturing shared semantics across various graph distributions. This leads usto ask:Can we design a foundation attack model for HGNNs that enablesgeneralizable perturbations across different HGNNs, and quickly adapts to newheterogeneous graphs (HGs)? Empirical findings reveal that, despite significantdifferences in model design and parameter space, different HGNNs surprisinglyshare common vulnerability patterns from a relation-aware perspective.Therefore, we explore how to design foundation HGNN attack criteria by miningshared attack units. In this paper, we propose a novel relation-wiseheterogeneous graph foundation attack model, HeTa. We introduce a foundationsurrogate model to align heterogeneity and identify the importance of sharedrelation-aware attack units. Building on this, we implement a serializedrelation-by-relation attack based on the identified relational weights. In thisway, the perturbation can be transferred to various target HGNNs and easilyfine-tuned for new HGs. Extensive experiments exhibit powerful attackperformances and generalizability of our method.</description>
      <author>example@mail.com (Yuling Wang, Zihui Chen, Pengfei Jiao, Xiao Wang)</author>
      <guid isPermaLink="false">2506.07428v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>State Entropy Regularization for Robust Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.07085v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了状态熵正则化在强化学习中的应用，分析了其在提高鲁棒性方面的优势，并与策略熵正则化进行了对比。&lt;h4&gt;背景&lt;/h4&gt;状态熵正则化在强化学习中表现出良好的探索和样本复杂度，但其理论保证尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;验证状态熵正则化在提高鲁棒性方面的有效性，并与其他正则化方法进行比较。&lt;h4&gt;方法&lt;/h4&gt;通过分析状态熵正则化在处理结构性和空间相关扰动时的鲁棒性，以及与策略熵正则化的对比，提供了理论保证。&lt;h4&gt;主要发现&lt;/h4&gt;状态熵正则化能够提高对结构性和空间相关扰动的鲁棒性，并且比策略熵正则化在处理这类扰动时更敏感。&lt;h4&gt;结论&lt;/h4&gt;状态熵正则化是一种有效的强化学习方法，特别是在处理转移学习中的结构性扰动时，具有明显的优势。&lt;h4&gt;翻译&lt;/h4&gt;State entropy regularization has empirically shown better exploration and sample complexity in reinforcement learning (RL). However, its theoretical guarantees have not been studied. In this paper, we show that state entropy regularization improves robustness to structured and spatially correlated perturbations. These types of variation are common in transfer learning but often overlooked by standard robust RL methods, which typically focus on small, uncorrelated changes. We provide a comprehensive characterization of these robustness properties, including formal guarantees under reward and transition uncertainty, as well as settings where the method performs poorly. Much of our analysis contrasts state entropy with the widely used policy entropy regularization, highlighting their different benefits. Finally, from a practical standpoint, we illustrate that compared with policy entropy, the robustness advantages of state entropy are more sensitive to the number of rollouts used for policy evaluation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State entropy regularization has empirically shown better exploration andsample complexity in reinforcement learning (RL). However, its theoreticalguarantees have not been studied. In this paper, we show that state entropyregularization improves robustness to structured and spatially correlatedperturbations. These types of variation are common in transfer learning butoften overlooked by standard robust RL methods, which typically focus on small,uncorrelated changes. We provide a comprehensive characterization of theserobustness properties, including formal guarantees under reward and transitionuncertainty, as well as settings where the method performs poorly. Much of ouranalysis contrasts state entropy with the widely used policy entropyregularization, highlighting their different benefits. Finally, from apractical standpoint, we illustrate that compared with policy entropy, therobustness advantages of state entropy are more sensitive to the number ofrollouts used for policy evaluation.</description>
      <author>example@mail.com (Uri Koren, Yonatan Ashlag, Mirco Mutti, Esther Derman, Pierre-Luc Bacon, Shie Mannor)</author>
      <guid isPermaLink="false">2506.07085v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Improving Wildlife Out-of-Distribution Detection: Africas Big Five</title>
      <link>http://arxiv.org/abs/2506.06719v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究旨在解决人类与野生动物冲突，通过计算机视觉技术识别可能引发冲突的个体，如非洲大型动物。&lt;h4&gt;背景&lt;/h4&gt;当前动物分类模型在封闭世界假设下训练，对未知类别的预测往往过于自信。&lt;h4&gt;目的&lt;/h4&gt;研究野生动物（特别是非洲大型动物）的分布外（OOD）检测。&lt;h4&gt;方法&lt;/h4&gt;选择参数化的最近类均值（NCM）和非参数的对比学习方法作为基线，并与其他常见的OOD方法进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;基于特征的方法在不同分类阈值下表现出更强的泛化能力。特别是，使用ImageNet预训练特征的NCM在AUPR-IN、AUPR-OUT和AUTC上分别比最佳OOD方法提高了2%、4%和22%。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，基于特征的方法在OOD检测方面具有更高的准确性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mitigating human-wildlife conflict seeks to resolve unwanted encountersbetween these parties. Computer Vision provides a solution to identifyingindividuals that might escalate into conflict, such as members of the Big FiveAfrican animals. However, environments often contain several varied species.The current state-of-the-art animal classification models are trained under aclosed-world assumption. They almost always remain overconfident in theirpredictions even when presented with unknown classes. This study investigatesout-of-distribution (OOD) detection of wildlife, specifically the Big Five. Tothis end, we select a parametric Nearest Class Mean (NCM) and a non-parametriccontrastive learning approach as baselines to take advantage of pretrained andprojected features from popular classification encoders. Moreover, we compareour baselines to various common OOD methods in the literature. The results showfeature-based methods reflect stronger generalisation capability across varyingclassification thresholds. Specifically, NCM with ImageNet pre-trained featuresachieves a 2%, 4% and 22% improvement on AUPR-IN, AUPR-OUT and AUTC over thebest OOD methods, respectively. The code can be found herehttps://github.com/pxpana/BIG5OOD</description>
      <author>example@mail.com (Mufhumudzi Muthivhi, Jiahao Huo, Fredrik Gustafsson, Terence L. van Zyl)</author>
      <guid isPermaLink="false">2506.06719v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>AugmentGest: Can Random Data Cropping Augmentation Boost Gesture Recognition Performance?</title>
      <link>http://arxiv.org/abs/2506.07216v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种全面的数据增强框架，用于解决深度学习任务中数据集多样性有限的问题，如基于骨骼的数据集。该框架通过几何变换、随机裁剪、旋转、缩放和基于强度的变换来模拟现实世界的变异性，提高了模型在不同数据集和架构上的泛化能力和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;数据增强是深度学习中的关键技术，尤其在数据集多样性有限的任务中，如基于骨骼的数据集，显得尤为重要。&lt;h4&gt;目的&lt;/h4&gt;提高模型在不同数据集和架构上的泛化能力和鲁棒性，丰富手势表示的多样性。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了几何变换、随机裁剪、旋转、缩放和亮度对比度调整等手段，对每个样本生成三个增强版本，从而将数据集规模扩大四倍。&lt;h4&gt;主要发现&lt;/h4&gt;实验在多个基准数据集上进行，包括DHG14/28、SHREC'17和JHMDB，结果表明，该方法在三个评估模型（多流端到端ET、基于FPPR的点云手势识别和DD-Network）上均取得了最先进的成果。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅提高了模型在不同数据集和架构上的泛化能力和鲁棒性，还为现实场景中的手势识别和动作识别应用提供了一个可扩展的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a comprehensive data augmentation framework for tasks with limited dataset diversity, such as skeleton-based datasets. The framework combines geometric transformations, random cropping, rotation, zooming, and intensity-based transformations to simulate real-world variations, thereby enhancing the generalization and robustness of models across diverse datasets and architectures. Experiments on benchmark datasets including DHG14/28, SHREC'17, and JHMDB demonstrate that the proposed method achieves state-of-the-art results on three evaluated models: multi-stream e2eET, FPPR point cloud-based hand gesture recognition (HGR), and DD-Network. The method not only improves model generalization and robustness but also offers a scalable solution for real-world HGR and action recognition applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data augmentation is a crucial technique in deep learning, particularly fortasks with limited dataset diversity, such as skeleton-based datasets. Thispaper proposes a comprehensive data augmentation framework that integratesgeometric transformations, random cropping, rotation, zooming andintensity-based transformations, brightness and contrast adjustments tosimulate real-world variations. Random cropping ensures the preservation ofspatio-temporal integrity while addressing challenges such as viewpoint biasand occlusions. The augmentation pipeline generates three augmented versionsfor each sample in addition to the data set sample, thus quadrupling the dataset size and enriching the diversity of gesture representations. The proposedaugmentation strategy is evaluated on three models: multi-stream e2eET, FPPRpoint cloud-based hand gesture recognition (HGR), and DD-Network. Experimentsare conducted on benchmark datasets including DHG14/28, SHREC'17, and JHMDB.The e2eET model, recognized as the state-of-the-art for hand gesturerecognition on DHG14/28 and SHREC'17. The FPPR-PCD model, the second-bestperforming model on SHREC'17, excels in point cloud-based gesture recognition.DD-Net, a lightweight and efficient architecture for skeleton-based actionrecognition, is evaluated on SHREC'17 and the Human Motion Data Base (JHMDB).The results underline the effectiveness and versatility of the proposedaugmentation strategy, significantly improving model generalization androbustness across diverse datasets and architectures. This framework not onlyestablishes state-of-the-art results on all three evaluated models but alsooffers a scalable solution to advance HGR and action recognition applicationsin real-world scenarios. The framework is available athttps://github.com/NadaAbodeshish/Random-Cropping-augmentation-HGR</description>
      <author>example@mail.com (Nada Aboudeshish, Dmitry Ignatov, Radu Timofte)</author>
      <guid isPermaLink="false">2506.07216v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs</title>
      <link>http://arxiv.org/abs/2506.07454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个多机器人系统，该系统通过3D场景图集成了制图、定位和任务与运动规划（TAMP），以执行用自然语言表达的复杂指令。&lt;h4&gt;背景&lt;/h4&gt;目前多机器人系统需要集成多种功能以执行复杂任务，包括地图构建、定位和规划。&lt;h4&gt;目的&lt;/h4&gt;开发一个多机器人系统，该系统能够理解自然语言指令，并在3D环境中执行复杂任务。&lt;h4&gt;方法&lt;/h4&gt;系统构建了一个共享的3D场景图，其中包含一个基于开放集的对象地图，用于多机器人3D场景图融合。该表示支持实时、视角不变的重定位（通过对象地图）和规划（通过3D场景图）。另外，系统使用大型语言模型（LLM）将操作者的意图转化为规划域定义语言（PDDL）目标，利用共享3D场景图和机器人能力。&lt;h4&gt;主要发现&lt;/h4&gt;该系统能够在大型、室外环境中执行真实世界任务，并对其性能进行了实验评估。&lt;h4&gt;结论&lt;/h4&gt;该多机器人系统能够有效地理解和执行自然语言指令，并在复杂环境中实现任务规划与执行。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce a multi-robot system that integrates mapping,localization, and task and motion planning (TAMP) enabled by 3D scene graphs toexecute complex instructions expressed in natural language. Our system builds ashared 3D scene graph incorporating an open-set object-based map, which isleveraged for multi-robot 3D scene graph fusion. This representation supportsreal-time, view-invariant relocalization (via the object-based map) andplanning (via the 3D scene graph), allowing a team of robots to reason abouttheir surroundings and execute complex tasks. Additionally, we introduce aplanning approach that translates operator intent into Planning DomainDefinition Language (PDDL) goals using a Large Language Model (LLM) byleveraging context from the shared 3D scene graph and robot capabilities. Weprovide an experimental assessment of the performance of our system onreal-world tasks in large-scale, outdoor environments.</description>
      <author>example@mail.com (Jared Strader, Aaron Ray, Jacob Arkin, Mason B. Peterson, Yun Chang, Nathan Hughes, Christopher Bradley, Yi Xuan Jia, Carlos Nieto-Granda, Rajat Talak, Chuchu Fan, Luca Carlone, Jonathan P. How, Nicholas Roy)</author>
      <guid isPermaLink="false">2506.07454v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Visual Prompting: Robustness Inheritance and Beyond</title>
      <link>http://arxiv.org/abs/2506.06823v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2311.10992&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文首次探讨了视觉提示（VP）在鲁棒源模型下的表现，提出了PromptBoundary Loosening（PBL）策略以缓解VP在鲁棒性和泛化能力之间的权衡。&lt;h4&gt;背景&lt;/h4&gt;视觉提示（VP）作为一种有效的迁移学习方法，在视觉任务中显示出其潜力。然而，先前的研究主要集中在从标准源模型中进行VP，而鲁棒源模型下的VP表现尚不明确。&lt;h4&gt;目的&lt;/h4&gt;研究鲁棒源模型对VP表现的影响，探讨VP在鲁棒性和泛化能力之间的权衡，并提出缓解这种权衡的策略。&lt;h4&gt;方法&lt;/h4&gt;本文提出了PromptBoundary Loosening（PBL）策略，这是一种轻量级、即插即用的策略，与VP自然兼容，并有效确保了在源模型为鲁棒模型时鲁棒性的成功继承。&lt;h4&gt;主要发现&lt;/h4&gt;通过在多个数据集上的广泛实验，发现PBL策略能够显著增强VP在下游数据集上的泛化能力，并成功缓解了VP在鲁棒性和泛化能力之间的权衡。&lt;h4&gt;结论&lt;/h4&gt;PBL策略能够有效提高VP在鲁棒源模型下的表现，并具有普遍性，证明了该策略的重要益处。&lt;h4&gt;翻译&lt;/h4&gt;Visual Prompting (VP), an efficient method for transfer learning, has shown its potential in vision tasks. However, previous works focus exclusively on VP from standard source models, it is still unknown how it performs under the scenario of a robust source model: Can the robustness of the source model be successfully inherited? Does VP also encounter the same trade-off between robustness and generalization ability as the source model during this process? If such a trade-off exists, is there a strategy specifically tailored to VP to mitigate this limitation? In this paper, we thoroughly explore these three questions for the first time and provide affirmative answers to them. To mitigate the trade-off faced by VP, we propose a strategy called PromptBoundary Loosening (PBL). As a lightweight, plug-and-play strategy naturally compatible with VP, PBL effectively ensures the successful inheritance of robustness when the source model is a robust model, while significantly enhancing VP's generalization ability across various downstream datasets. Extensive experiments across various datasets show that our findings are universal and demonstrate the significant benefits of the proposed strategy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Prompting (VP), an efficient method for transfer learning, has shownits potential in vision tasks. However, previous works focus exclusively on VPfrom standard source models, it is still unknown how it performs under thescenario of a robust source model: Can the robustness of the source model besuccessfully inherited? Does VP also encounter the same trade-off betweenrobustness and generalization ability as the source model during this process?If such a trade-off exists, is there a strategy specifically tailored to VP tomitigate this limitation? In this paper, we thoroughly explore these threequestions for the first time and provide affirmative answers to them. Tomitigate the trade-off faced by VP, we propose a strategy called PromptBoundary Loosening (PBL). As a lightweight, plug-and-play strategy naturallycompatible with VP, PBL effectively ensures the successful inheritance ofrobustness when the source model is a robust model, while significantlyenhancing VP's generalization ability across various downstream datasets.Extensive experiments across various datasets show that our findings areuniversal and demonstrate the significant benefits of the proposed strategy.</description>
      <author>example@mail.com (Qi Li, Liangzhi Li, Zhouqiang Jiang, Bowen Wang, Keke Tang)</author>
      <guid isPermaLink="false">2506.06823v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>CrossGen: Learning and Generating Cross Fields for Quad Meshing</title>
      <link>http://arxiv.org/abs/2506.07020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://anonymousproject-homepage.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CrossGen是一种新型框架，用于生成高质量的四边形网格，通过在联合潜在空间中统一几何和交叉场表示，支持交叉场的前馈预测和潜在生成建模。&lt;h4&gt;背景&lt;/h4&gt;现有的交叉场生成方法难以在计算效率和生成质量之间取得平衡，通常采用缓慢的针对每个形状的优化。&lt;h4&gt;目的&lt;/h4&gt;提出CrossGen框架，旨在实现快速计算高质量交叉场，同时不需要针对每个形状的优化。&lt;h4&gt;方法&lt;/h4&gt;CrossGen使用自动编码器网络架构，将输入的点云表面编码为稀疏体素网格，具有细粒度的潜在空间，这些空间被解码为基于SDF的表面几何和交叉场。同时，该方法还包含一个用于计算从部分输入（如草图）生成的新形状的交叉场的扩散模型。&lt;h4&gt;主要发现&lt;/h4&gt;CrossGen能够在不到一秒的时间内计算一般输入形状的高质量交叉场，无需针对每个形状的优化，并具有高几何保真度、噪声鲁棒性和快速推理能力。&lt;h4&gt;结论&lt;/h4&gt;CrossGen在四边形网格生成任务中表现出色，适用于各种表面形状，为交叉场生成提供了一种高效且高质量的方法。&lt;h4&gt;翻译&lt;/h4&gt;Cross fields play a critical role in various geometry processing tasks, especially for quad mesh generation. Existing methods for cross field generation often struggle to balance computational efficiency with generation quality, using slow per-shape optimization. We introduce CrossGen, a novel framework that supports both feed-forward prediction and latent generative modeling of cross fields for quad meshing by unifying geometry and cross field representations within a joint latent space. Our method enables extremely fast computation of high-quality cross fields of general input shapes, typically within one second without per-shape optimization. Our method assumes a point-sampled surface, or called a point-cloud surface, as input, so we can accommodate various different surface representations by a straightforward point sampling process. Using an auto-encoder network architecture, we encode input point-cloud surfaces into a sparse voxel grid with fine-grained latent spaces, which are decoded into both SDF-based surface geometry and cross fields. We also contribute a dataset of models with both high-quality signed distance fields (SDFs) representations and their corresponding cross fields, and use it to train our network. Once trained, the network is capable of computing a cross field of an input surface in a feed-forward manner, ensuring high geometric fidelity, noise resilience, and rapid inference. Furthermore, leveraging the same unified latent representation, we incorporate a diffusion model for computing cross fields of new shapes generated from partial input, such as sketches. To demonstrate its practical applications, we validate CrossGen on the quad mesh generation task for a large variety of surface shapes. Experimental results...&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross fields play a critical role in various geometry processing tasks,especially for quad mesh generation. Existing methods for cross fieldgeneration often struggle to balance computational efficiency with generationquality, using slow per-shape optimization. We introduce CrossGen, a novelframework that supports both feed-forward prediction and latent generativemodeling of cross fields for quad meshing by unifying geometry and cross fieldrepresentations within a joint latent space. Our method enables extremely fastcomputation of high-quality cross fields of general input shapes, typicallywithin one second without per-shape optimization. Our method assumes apoint-sampled surface, or called a point-cloud surface, as input, so we canaccommodate various different surface representations by a straightforwardpoint sampling process. Using an auto-encoder network architecture, we encodeinput point-cloud surfaces into a sparse voxel grid with fine-grained latentspaces, which are decoded into both SDF-based surface geometry and crossfields. We also contribute a dataset of models with both high-quality signeddistance fields (SDFs) representations and their corresponding cross fields,and use it to train our network. Once trained, the network is capable ofcomputing a cross field of an input surface in a feed-forward manner, ensuringhigh geometric fidelity, noise resilience, and rapid inference. Furthermore,leveraging the same unified latent representation, we incorporate a diffusionmodel for computing cross fields of new shapes generated from partial input,such as sketches. To demonstrate its practical applications, we validateCrossGen on the quad mesh generation task for a large variety of surfaceshapes. Experimental results...</description>
      <author>example@mail.com (Qiujie Dong, Jiepeng Wang, Rui Xu, Cheng Lin, Yuan Liu, Shiqing Xin, Zichun Zhong, Xin Li, Changhe Tu, Taku Komura, Leif Kobbelt, Scott Schaefer, Wenping Wang)</author>
      <guid isPermaLink="false">2506.07020v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>MIRA: Medical Time Series Foundation Model for Real-World Health Data</title>
      <link>http://arxiv.org/abs/2506.07584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种针对医疗时间序列的统一基础模型MIRA，通过预训练减少标注负担，最小化模型定制，并实现跨临床机构、模态和任务的鲁棒迁移。&lt;h4&gt;背景&lt;/h4&gt;现有通用时间序列基础模型难以处理医疗时间序列数据，因为它们存在不规则的时间间隔、异质采样率和频繁缺失值等问题。&lt;h4&gt;目的&lt;/h4&gt;设计MIRA模型以解决上述挑战，实现医疗时间序列的准确预测。&lt;h4&gt;方法&lt;/h4&gt;MIRA模型包含连续时间旋转位置编码、特定频率的专家混合层以及基于神经网络常微分方程的连续动态外推块。&lt;h4&gt;主要发现&lt;/h4&gt;MIRA在包含超过4540亿时间点的医学语料库上预训练，与零样本和微调的基线相比，在分布外和分布内场景下，预测误差分别减少了10%和7%。&lt;h4&gt;结论&lt;/h4&gt;MIRA为医学时间序列建模的基准研究提供了基础，有助于未来在该领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;A unified foundation model for medical time series -- pretrained on openaccess and ethics board-approved medical corpora -- offers the potential toreduce annotation burdens, minimize model customization, and enable robusttransfer across clinical institutions, modalities, and tasks, particularly indata-scarce or privacy-constrained environments. However, existing generalisttime series foundation models struggle to handle medical time series data dueto their inherent challenges, including irregular intervals, heterogeneoussampling rates, and frequent missing values. To address these challenges, weintroduce MIRA, a unified foundation model specifically designed for medicaltime series forecasting. MIRA incorporates a Continuous-Time Rotary PositionalEncoding that enables fine-grained modeling of variable time intervals, afrequency-specific mixture-of-experts layer that routes computation acrosslatent frequency regimes to further promote temporal specialization, and aContinuous Dynamics Extrapolation Block based on Neural ODE that models thecontinuous trajectory of latent states, enabling accurate forecasting atarbitrary target timestamps. Pretrained on a large-scale and diverse medicalcorpus comprising over 454 billion time points collect from publicly availabledatasets, MIRA achieves reductions in forecasting errors by an average of 10%and 7% in out-of-distribution and in-distribution scenarios, respectively, whencompared to other zero-shot and fine-tuned baselines. We also introduceacomprehensive benchmark spanning multiple downstream clinical tasks,establishing a foundation for future research in medical time series modeling.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A unified foundation model for medical time series -- pretrained on openaccess and ethics board-approved medical corpora -- offers the potential toreduce annotation burdens, minimize model customization, and enable robusttransfer across clinical institutions, modalities, and tasks, particularly indata-scarce or privacy-constrained environments. However, existing generalisttime series foundation models struggle to handle medical time series data dueto their inherent challenges, including irregular intervals, heterogeneoussampling rates, and frequent missing values. To address these challenges, weintroduce MIRA, a unified foundation model specifically designed for medicaltime series forecasting. MIRA incorporates a Continuous-Time Rotary PositionalEncoding that enables fine-grained modeling of variable time intervals, afrequency-specific mixture-of-experts layer that routes computation acrosslatent frequency regimes to further promote temporal specialization, and aContinuous Dynamics Extrapolation Block based on Neural ODE that models thecontinuous trajectory of latent states, enabling accurate forecasting atarbitrary target timestamps. Pretrained on a large-scale and diverse medicalcorpus comprising over 454 billion time points collect from publicly availabledatasets, MIRA achieves reductions in forecasting errors by an average of 10%and 7% in out-of-distribution and in-distribution scenarios, respectively, whencompared to other zero-shot and fine-tuned baselines. We also introduce acomprehensive benchmark spanning multiple downstream clinical tasks,establishing a foundation for future research in medical time series modeling.</description>
      <author>example@mail.com (Hao Li, Bowen Deng, Chang Xu, Zhiyuan Feng, Viktor Schlegel, Yu-Hao Huang, Yizheng Sun, Jingyuan Sun, Kailai Yang, Yiyao Yu, Jiang Bian)</author>
      <guid isPermaLink="false">2506.07584v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>FANVID: A Benchmark for Face and License Plate Recognition in Low-Resolution Videos</title>
      <link>http://arxiv.org/abs/2506.07304v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了FANVID，一个基于视频的基准数据集，旨在提升低分辨率视频中的时间和空间识别能力。&lt;h4&gt;背景&lt;/h4&gt;现实世界的监控视频中，由于低分辨率和干扰因素，人脸和车牌往往难以识别。&lt;h4&gt;目的&lt;/h4&gt;提出FANVID数据集，旨在提高时间和空间识别模型在低分辨率视频中的识别准确率。&lt;h4&gt;方法&lt;/h4&gt;FANVID包含近1,463个低分辨率视频片段，包括来自三个英语国家的人脸和车牌，并包含干扰元素，以提高任务难度和真实性。数据集包含31,096个手动验证的边界框和标签。数据集定义了两个任务：人脸匹配和车牌识别。视频从高分辨率源下采样，以确保单帧中的人脸和文本难以识别，需要模型利用时间信息。引入了适应于IoU &gt; 0.5的平均精度等评估指标。&lt;h4&gt;主要发现&lt;/h4&gt;基线方法在人脸匹配和车牌识别任务中分别取得了0.58和0.42的分数，显示了任务的可行性和挑战。FANVID在人脸和车牌的选择上平衡了多样性和识别难度。&lt;h4&gt;结论&lt;/h4&gt;FANVID旨在促进低分辨率识别的时序建模创新，并在监控、法医学和自动驾驶等领域具有应用前景。&lt;h4&gt;翻译&lt;/h4&gt;Real-world surveillance often renders faces and license plates unrecognizable in individual low-resolution (LR) frames, hindering reliable identification. To advance temporal recognition models, we present FANVID, a novel video-based benchmark comprising nearly 1,463 LR clips (180 x 320, 20--60 FPS) featuring 63 identities and 49 license plates from three English-speaking countries. Each video includes distractor faces and plates, increasing task difficulty and realism. The dataset contains 31,096 manually verified bounding boxes and labels. FANVID defines two tasks: (1) face matching -- detecting LR faces and matching them to high-resolution mugshots, and (2) license plate recognition -- extracting text from LR plates without a predefined database. Videos are downsampled from high-resolution sources to ensure that faces and text are indecipherable in single frames, requiring models to exploit temporal information. We introduce evaluation metrics adapted from mean Average Precision at IoU &gt; 0.5, prioritizing identity correctness for faces and character-level accuracy for text. A baseline method with pre-trained video super-resolution, detection, and recognition achieved performance scores of 0.58 (face matching) and 0.42 (plate recognition), highlighting both the feasibility and challenge of the tasks. FANVID's selection of faces and plates balances diversity with recognition challenge. We release the software for data access, evaluation, baseline, and annotation to support reproducibility and extension. FANVID aims to catalyze innovation in temporal modeling for LR recognition, with applications in surveillance, forensics, and autonomous vehicles.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world surveillance often renders faces and license plates unrecognizablein individual low-resolution (LR) frames, hindering reliable identification. Toadvance temporal recognition models, we present FANVID, a novel video-basedbenchmark comprising nearly 1,463 LR clips (180 x 320, 20--60 FPS) featuring 63identities and 49 license plates from three English-speaking countries. Eachvideo includes distractor faces and plates, increasing task difficulty andrealism. The dataset contains 31,096 manually verified bounding boxes andlabels.  FANVID defines two tasks: (1) face matching -- detecting LR faces andmatching them to high-resolution mugshots, and (2) license plate recognition --extracting text from LR plates without a predefined database. Videos aredownsampled from high-resolution sources to ensure that faces and text areindecipherable in single frames, requiring models to exploit temporalinformation. We introduce evaluation metrics adapted from mean AveragePrecision at IoU &gt; 0.5, prioritizing identity correctness for faces andcharacter-level accuracy for text.  A baseline method with pre-trained video super-resolution, detection, andrecognition achieved performance scores of 0.58 (face matching) and 0.42 (platerecognition), highlighting both the feasibility and challenge of the tasks.FANVID's selection of faces and plates balances diversity with recognitionchallenge. We release the software for data access, evaluation, baseline, andannotation to support reproducibility and extension. FANVID aims to catalyzeinnovation in temporal modeling for LR recognition, with applications insurveillance, forensics, and autonomous vehicles.</description>
      <author>example@mail.com (Kavitha Viswanathan, Vrinda Goel, Shlesh Gholap, Devayan Ghosh, Madhav Gupta, Dhruvi Ganatra, Sanket Potdar, Amit Sethi)</author>
      <guid isPermaLink="false">2506.07304v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Technical Report for ICRA 2025 GOOSE 3D Semantic Segmentation Challenge: Adaptive Point Cloud Understanding for Heterogeneous Robotic Systems</title>
      <link>http://arxiv.org/abs/2506.06995v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Winner of the GOOSE 3D Semantic Segmentation Challenge at the IEEE  ICRA Workshop on Field Robotics 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本技术报告介绍了ICRA 2025 GOOSE 3D语义分割挑战的解决方案实现细节。&lt;h4&gt;背景&lt;/h4&gt;该挑战聚焦于从多个机器人平台收集的多种非结构化室外环境中3D点云的语义分割。&lt;h4&gt;目的&lt;/h4&gt;通过实现点提示调整（Point Prompt Tuning）与点变换器v3（Point Transformer v3，PTv3）骨干网络的集成，解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;采用平台特定的条件化和跨数据集类别对齐策略，使模型能够自适应处理异构的LiDAR数据，且训练过程中无需额外外部数据。&lt;h4&gt;主要发现&lt;/h4&gt;与基线PTv3模型相比，该方法在具有挑战性的平台上实现了显著的性能提升，mIoU提高了高达22.59%，证明了自适应点云理解在场地机器人应用中的有效性。&lt;h4&gt;结论&lt;/h4&gt;自适应点云理解方法在处理非结构化室外环境的3D点云语义分割时，表现出了良好的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report presents the implementation details of the winningsolution for the ICRA 2025 GOOSE 3D Semantic Segmentation Challenge. Thischallenge focuses on semantic segmentation of 3D point clouds from diverseunstructured outdoor environments collected from multiple robotic platforms.This problem was addressed by implementing Point Prompt Tuning (PPT) integratedwith Point Transformer v3 (PTv3) backbone, enabling adaptive processing ofheterogeneous LiDAR data through platform-specific conditioning andcross-dataset class alignment strategies. The model is trained withoutrequiring additional external data. As a result, this approach achievedsubstantial performance improvements with mIoU increases of up to 22.59% onchallenging platforms compared to the baseline PTv3 model, demonstrating theeffectiveness of adaptive point cloud understanding for field roboticsapplications.</description>
      <author>example@mail.com (Xiaoya Zhang)</author>
      <guid isPermaLink="false">2506.06995v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Technical Report: A Practical Guide to Kaldi ASR Optimization</title>
      <link>http://arxiv.org/abs/2506.07149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本技术报告介绍了针对基于Kaldi的自动语音识别（ASR）系统的创新优化，重点关注声学模型增强、超参数调整和语言模型效率。&lt;h4&gt;背景&lt;/h4&gt;报告背景是Kaldi的自动语音识别技术。&lt;h4&gt;目的&lt;/h4&gt;目的是通过优化提高ASR的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;方法包括开发自定义的Conformer块与多流TDNN-F结构集成，采用高级数据增强技术和动态超参数优化，以及使用贝叶斯优化和n-gram剪枝进行语言模型管理。&lt;h4&gt;主要发现&lt;/h4&gt;这些系统性的改进显著提高了ASR的准确性和鲁棒性，优于现有方法，并为多种语音识别场景提供了可扩展的解决方案。&lt;h4&gt;结论&lt;/h4&gt;报告强调了战略优化在保持Kaldi适应性和竞争力中的重要性，特别是在快速发展的技术环境中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report introduces innovative optimizations for Kaldi-basedAutomatic Speech Recognition (ASR) systems, focusing on acoustic modelenhancement, hyperparameter tuning, and language model efficiency. We developeda custom Conformer block integrated with a multistream TDNN-F structure,enabling superior feature extraction and temporal modeling. Our approachincludes advanced data augmentation techniques and dynamic hyperparameteroptimization to boost performance and reduce overfitting. Additionally, wepropose robust strategies for language model management, employing Bayesianoptimization and $n$-gram pruning to ensure relevance and computationalefficiency. These systematic improvements significantly elevate ASR accuracyand robustness, outperforming existing methods and offering a scalable solutionfor diverse speech recognition scenarios. This report underscores theimportance of strategic optimizations in maintaining Kaldi's adaptability andcompetitiveness in rapidly evolving technological landscapes.</description>
      <author>example@mail.com (Mengze Hong, Di Jiang)</author>
      <guid isPermaLink="false">2506.07149v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>AnnoDPO: Protein Functional Annotation Learning with Direct Preference Optimization</title>
      <link>http://arxiv.org/abs/2506.07035v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AnnoDPO的新型多模态框架，用于蛋白质功能预测，通过直接偏好优化（DPO）来增强注释学习，解决了注释稀缺和类别不平衡的双重挑战。&lt;h4&gt;背景&lt;/h4&gt;蛋白质功能解析是蛋白质表示学习中的基本挑战，由于功能注释类别众多且注释实例在生物分类学中的分布高度不平衡，蛋白质语言模型（PLM）面临重大困难。&lt;h4&gt;目的&lt;/h4&gt;提出AnnoDPO框架，旨在通过直接偏好优化（DPO）提高注释学习，以解决蛋白质功能预测中的注释稀缺和类别不平衡问题。&lt;h4&gt;方法&lt;/h4&gt;AnnoDPO框架利用偏好对齐的训练目标，结合强化学习从人类反馈（RLHF）在大型语言模型（LLM）对齐中的成功经验。&lt;h4&gt;主要发现&lt;/h4&gt;AnnoDPO通过偏好对齐的训练目标解决了注释稀缺和类别不平衡的挑战，为蛋白质表示学习中的生物知识整合建立了一种新的范式。&lt;h4&gt;结论&lt;/h4&gt;AnnoDPO框架为蛋白质功能预测提供了一种有效的方法，有助于克服注释稀缺和类别不平衡的问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要：解析蛋白质功能仍然是蛋白质表示学习中的一个基本挑战。这项任务对蛋白质语言模型（PLMs）来说具有重大困难，因为功能注释类别众多，且注释实例在生物分类学中的分布高度不平衡。受大型语言模型（LLM）对齐中强化学习从人类反馈（RLHF）取得的显著成功的启发，我们提出了AnnoDPO，这是一种新颖的多模态蛋白质功能预测框架，它利用直接偏好优化（DPO）来增强注释学习。我们的方法通过偏好对齐的训练目标解决了注释稀缺和类别不平衡的双重挑战，为蛋白质表示学习中的生物知识整合建立了一种新的范式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deciphering protein function remains a fundamental challenge in proteinrepresentation learning. The task presents significant difficulties for proteinlanguage models (PLMs) due to the sheer volume of functional annotationcategories and the highly imbalanced distribution of annotated instances acrossbiological ontologies. Inspired by the remarkable success of reinforcementlearning from human feedback (RLHF) in large language model (LLM) alignment, wepropose AnnoDPO, a novel multi-modal framework for protein function predictionthat leverages Direct Preference Optimization (DPO) to enhance annotationlearning. Our methodology addresses the dual challenges of annotation scarcityand category imbalance through preference-aligned training objectives,establishing a new paradigm for biological knowledge integration in proteinrepresentation learning.</description>
      <author>example@mail.com (Zixuan Jiang, Renjing Xu)</author>
      <guid isPermaLink="false">2506.07035v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Textile Analysis for Recycling Automation using Transfer Learning and Zero-Shot Foundation Models</title>
      <link>http://arxiv.org/abs/2506.06569v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用标准RGB图像进行自动化系统中的关键预处理任务，以提高纺织品回收的效率和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;准确识别材料成分和检测传感器数据中的污染物对于自动化纺织品回收至关重要，但这是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;探索使用RGB图像和现代深度学习技术，包括迁移学习和基础模型，来实现自动化纺织品回收流程的关键分析步骤。&lt;h4&gt;方法&lt;/h4&gt;开发了计算机视觉组件，用于传送带设置，以执行(a)四种常见纺织品类型的分类和(b)按钮和拉链等非纺织品特征的分割。&lt;h4&gt;主要发现&lt;/h4&gt;使用迁移学习和交叉验证评估了几个预训练架构，EfficientNetB0在保留测试集上达到了81.25%的准确率。对于特征分割，结合Grounding DINO开放词汇检测器和Segment Anything Model (SAM)的零样本方法表现出色，生成的掩码与真实值的mIoU达到0.90。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了使用RGB图像与现代深度学习技术相结合的可行性，以实现自动化纺织品回收流程的关键分析步骤。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated sorting is crucial for improving the efficiency and scalability oftextile recycling, but accurately identifying material composition anddetecting contaminants from sensor data remains challenging. This paperinvestigates the use of standard RGB imagery, a cost-effective sensingmodality, for key pre-processing tasks in an automated system. We presentcomputer vision components designed for a conveyor belt setup to perform (a)classification of four common textile types and (b) segmentation of non-textilefeatures such as buttons and zippers. For classification, several pre-trainedarchitectures were evaluated using transfer learning and cross-validation, withEfficientNetB0 achieving the best performance on a held-out test set with81.25\% accuracy. For feature segmentation, a zero-shot approach combining theGrounding DINO open-vocabulary detector with the Segment Anything Model (SAM)was employed, demonstrating excellent performance with a mIoU of 0.90 for thegenerated masks against ground truth. This study demonstrates the feasibilityof using RGB images coupled with modern deep learning techniques, includingtransfer learning for classification and foundation models for zero-shotsegmentation, to enable essential analysis steps for automated textilerecycling pipelines.</description>
      <author>example@mail.com (Yannis Spyridis, Vasileios Argyriou)</author>
      <guid isPermaLink="false">2506.06569v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>GGBall: Graph Generative Model on Poincaré Ball</title>
      <link>http://arxiv.org/abs/2506.07198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GGBall的新型超曲率框架，用于生成具有层次结构的图，以解决欧几里得几何在捕捉指数复杂性方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;生成具有层次结构的图是一个基本挑战，因为欧几里得几何无法有效地捕捉指数复杂性。&lt;h4&gt;目的&lt;/h4&gt;引入GGBall，以解决上述问题，并通过结合几何归纳偏见和现代生成范式来生成具有层次结构的图。&lt;h4&gt;方法&lt;/h4&gt;GGBall结合了超曲率向量量化自动编码器（HVQVAE）和通过闭形式测地线定义的黎曼流匹配先验。此外，还开发了一套在流形上操作的超曲率图神经网络（GNN）和Transformer层。&lt;h4&gt;主要发现&lt;/h4&gt;与最先进的基线相比，GGBall在Community-Small上减少了超过75%的度MMD，在Ego-Small上减少了超过40%，这表明其能够更好地保留拓扑层次结构。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，超曲率几何可以作为复杂、结构化和层次化数据域生成建模的强大基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成具有层次结构的图仍然是一个基本挑战，因为欧几里得几何在捕捉指数复杂性方面存在局限性。在这里，我们引入了GGBall，这是一种用于图生成的新型超曲率框架，它结合了几何归纳偏见与现代生成范式。GGBall结合了超曲率向量量化自动编码器（HVQVAE）和通过闭形式测地线定义的黎曼流匹配先验。这种设计使得基于流的先验能够模拟复杂的潜在分布，而向量量化有助于保留超曲率空间的曲率感知结构。我们进一步开发了一套在流形上操作的超曲率图神经网络（GNN）和Transformer层，确保了稳定性和可扩展性。从经验上看，我们的模型在Community-Small上减少了超过75%的度MMD，在Ego-Small上减少了超过40%，与最先进的基线相比，这表明了其能够更好地保留拓扑层次结构。这些结果突出了超曲率几何作为复杂、结构化和层次化数据域生成建模的强大基础。我们的代码可在https://github.com/AI4Science-WestlakeU/GGBall处获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating graphs with hierarchical structures remains a fundamentalchallenge due to the limitations of Euclidean geometry in capturing exponentialcomplexity. Here we introduce \textbf{GGBall}, a novel hyperbolic framework forgraph generation that integrates geometric inductive biases with moderngenerative paradigms. GGBall combines a Hyperbolic Vector-Quantized Autoencoder(HVQVAE) with a Riemannian flow matching prior defined via closed-formgeodesics. This design enables flow-based priors to model complex latentdistributions, while vector quantization helps preserve the curvature-awarestructure of the hyperbolic space. We further develop a suite of hyperbolic GNNand Transformer layers that operate entirely within the manifold, ensuringstability and scalability. Empirically, our model reduces degree MMD by over75\% on Community-Small and over 40\% on Ego-Small compared to state-of-the-artbaselines, demonstrating an improved ability to preserve topologicalhierarchies. These results highlight the potential of hyperbolic geometry as apowerful foundation for the generative modeling of complex, structured, andhierarchical data domains. Our code is available at\href{https://github.com/AI4Science-WestlakeU/GGBall}{here}.</description>
      <author>example@mail.com (Tianci Bu, Chuanrui Wang, Hao Ma, Haoren Zheng, Xin Lu, Tailin Wu)</author>
      <guid isPermaLink="false">2506.07198v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Learning Robust Heterogeneous Graph Representations via Contrastive-Reconstruction under Sparse Semantics</title>
      <link>http://arxiv.org/abs/2506.06682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HetCRF的新型双通道自监督学习框架，用于异构图的自监督学习。&lt;h4&gt;背景&lt;/h4&gt;图自监督学习中，掩码自编码器（MAE）和对比学习（CL）是两种主要范式。MAE擅长局部特征捕获，而CL擅长全局信息提取。现有的混合框架在共享编码器设计上面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出HetCRF框架，以适应MAE和CL的需求，并解决语义稀疏场景中的问题。&lt;h4&gt;方法&lt;/h4&gt;HetCRF采用两阶段聚合策略来适应嵌入语义，并通过增强编码器输出以提高视图构建的效率。同时，提出了两种正样本增强策略以平衡梯度贡献。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界异构图数据集上的节点分类实验表明，HetCRF优于现有基线。在节点特征缺失的数据集上，如Aminer和Freebase，在40%的标签率下，HetCRF将Macro-F1分数分别提高了2.75%和2.2%，验证了其有效性和优越性。&lt;h4&gt;结论&lt;/h4&gt;HetCRF是一种有效的异构图自监督学习框架，能够提高节点分类的性能，特别是在节点特征缺失的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In graph self-supervised learning, masked autoencoders (MAE) and contrastivelearning (CL) are two prominent paradigms. MAE focuses on reconstructing maskedelements, while CL maximizes similarity between augmented graph views. Recentstudies highlight their complementarity: MAE excels at local feature capture,and CL at global information extraction. Hybrid frameworks for homogeneousgraphs have been proposed, but face challenges in designing shared encoders tomeet the semantic requirements of both tasks. In semantically sparse scenarios,CL struggles with view construction, and gradient imbalance between positiveand negative samples persists. This paper introduces HetCRF, a noveldual-channel self-supervised learning framework for heterogeneous graphs.HetCRF uses a two-stage aggregation strategy to adapt embedding semantics,making it compatible with both MAE and CL. To address semantic sparsity, itenhances encoder output for view construction instead of relying on rawfeatures, improving efficiency. Two positive sample augmentation strategies arealso proposed to balance gradient contributions. Node classificationexperiments on four real-world heterogeneous graph datasets demonstrate thatHetCRF outperforms state-of-the-art baselines. On datasets with missing nodefeatures, such as Aminer and Freebase, at a 40% label rate in nodeclassification, HetCRF improves the Macro-F1 score by 2.75% and 2.2%respectively compared to the second-best baseline, validating its effectivenessand superiority.</description>
      <author>example@mail.com (Di Lin, Wanjing Ren, Xuanbin Li, Rui Zhang)</author>
      <guid isPermaLink="false">2506.06682v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>GeometryZero: Improving Geometry Solving for LLM with Group Contrastive Policy Optimization</title>
      <link>http://arxiv.org/abs/2506.07160v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为GeometryZero的几何推理模型系列，通过改进的强化学习框架GCPO，实现了在几何推理领域的高效性能。&lt;h4&gt;背景&lt;/h4&gt;大语言模型在数学推理方面表现出色，其中几何问题解决是一个具有挑战性的领域，辅助构造在其中起着关键作用。现有的方法要么性能不佳，要么依赖于大规模的LLMs，导致巨大的计算成本。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的强化学习框架，以训练能够有效结合辅助构造和稳健几何推理的小型模型。&lt;h4&gt;方法&lt;/h4&gt;提出了GCPO框架，包含两个关键创新：(1)组对比掩码，根据上下文效用自适应地提供正负奖励信号；(2)长度奖励，促进更长的推理链。基于GCPO，开发了GeometryZero模型系列。&lt;h4&gt;主要发现&lt;/h4&gt;在多个几何基准测试（如Geometry3K、MathVista）中，GeometryZero模型在所有基准测试中都优于基线（如GRPO），平均改进率为4.29%。&lt;h4&gt;结论&lt;/h4&gt;GeometryZero模型通过改进的强化学习框架有效地实现了几何推理，并在实际应用中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，大型语言模型（LLMs）在多个领域展现了显著的能力，特别是在数学推理方面。其中，几何问题解决是一个具有挑战性的领域，辅助构造在其中起着关键作用。现有的方法要么性能不佳，要么依赖于大规模的LLMs（例如GPT-4o），导致巨大的计算成本。我们认为，基于可验证奖励的强化学习（例如GRPO）为训练结合辅助构造与稳健几何推理的小型模型提供了一个有希望的方向。然而，由于对无条件奖励的依赖，直接将GRPO应用于几何推理存在根本性的限制，这会导致无差别且低效的辅助构造。为了解决这些挑战，我们提出了组对比策略优化（GCPO），这是一个具有两个关键创新的强化学习框架：(1)组对比掩码，根据上下文效用自适应地提供正或负奖励信号；(2)长度奖励，促进更长的推理链。在GCPO的基础上，我们开发了GeometryZero，这是一系列可负担规模的几何推理模型，能够明智地决定何时使用辅助构造。我们在流行的几何基准（Geometry3K、MathVista）上进行了广泛的实证评估，结果表明，GeometryZero模型在所有基准测试中均优于基线（例如GRPO），平均改进率为4.29%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in large language models (LLMs) have demonstrated remarkablecapabilities across diverse domains, particularly in mathematical reasoning,amid which geometry problem solving remains a challenging area where auxiliaryconstruction plays a enssential role. Existing approaches either achievesuboptimal performance or rely on massive LLMs (e.g., GPT-4o), incurringmassive computational costs. We posit that reinforcement learning withverifiable reward (e.g., GRPO) offers a promising direction for trainingsmaller models that effectively combine auxiliary construction with robustgeometric reasoning. However, directly applying GRPO to geometric reasoningpresents fundamental limitations due to its dependence on unconditionalrewards, which leads to indiscriminate and counterproductive auxiliaryconstructions. To address these challenges, we propose Group Contrastive PolicyOptimization (GCPO), a novel reinforcement learning framework featuring two keyinnovations: (1) Group Contrastive Masking, which adaptively provides positiveor negative reward signals for auxiliary construction based on contextualutility, and a (2) length reward that promotes longer reasoning chains.Building on GCPO, we develop GeometryZero, a family of affordable-sizegeometric reasoning models that judiciously determine when to employ auxiliaryconstruction. Our extensive empirical evaluation across popular geometricbenchmarks (Geometry3K, MathVista) demonstrates that GeometryZero modelsconsistently outperform baselines (e.g. GRPO), achieving an average improvementof 4.29% across all benchmarks.</description>
      <author>example@mail.com (Yikun Wang, Yibin Wang, Dianyi Wang, Zimian Peng, Qipeng Guo, Dacheng Tao, Jiaqi Wang)</author>
      <guid isPermaLink="false">2506.07160v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Guiding Cross-Modal Representations with MLLM Priors via Preference Alignment</title>
      <link>http://arxiv.org/abs/2506.06970v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MAPLE的新框架，用于跨模态表示学习，通过利用MLLM的内在模态对齐特性来缩小模态差距。&lt;h4&gt;背景&lt;/h4&gt;尽管CLIP在跨模态内容检索方面表现出色，但模态特征空间中仍存在显著的模态差距。&lt;h4&gt;目的&lt;/h4&gt;提出MAPLE框架，旨在通过细粒度对齐先验来指导跨模态表示学习。&lt;h4&gt;方法&lt;/h4&gt;MAPLE框架利用了现成的MLLM来构建自动偏好数据，并引入了一种新的相对偏好对齐（RPA）损失函数，该函数将直接偏好优化（DPO）应用于嵌入学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MAPLE框架在细粒度跨模态检索中取得了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;MAPLE框架在处理细微语义区分方面非常有效。&lt;h4&gt;翻译&lt;/h4&gt;Despite Contrastive Language-Image Pretraining (CLIP)'s remarkable capability to retrieve content across modalities, a substantial modality gap persists in its feature space. Intriguingly, we discover that off-the-shelf MLLMs (Multimodal Large Language Models) demonstrate powerful inherent modality alignment properties. While recent MLLM-based retrievers with unified architectures partially mitigate this gap, their reliance on coarse modality alignment mechanisms fundamentally limits their potential. In this work, We introduce MAPLE (Modality-Aligned Preference Learning for Embeddings), a novel framework that leverages the fine grained alignment priors inherent in MLLM to guide cross modal representation learning. MAPLE formulates the learning process as reinforcement learning with two key components: (1) Automatic preference data construction using off-the-shelf MLLM, and (2) a new Relative Preference Alignment (RPA) loss, which adapts Direct Preference Optimization (DPO) to the embedding learning setting. Experimental results show that our preference-guided alignment achieves substantial gains in fine-grained cross-modal retrieval, underscoring its effectiveness in handling nuanced semantic distinctions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite Contrastive Language-Image Pretraining (CLIP)'s remarkable capabilityto retrieve content across modalities, a substantial modality gap persists inits feature space. Intriguingly, we discover that off-the-shelf MLLMs(Multimodal Large Language Models) demonstrate powerful inherent modalityalignment properties. While recent MLLM-based retrievers with unifiedarchitectures partially mitigate this gap, their reliance on coarse modalityalignment mechanisms fundamentally limits their potential. In this work, Weintroduce MAPLE (Modality-Aligned Preference Learning for Embeddings), a novelframework that leverages the fine grained alignment priors inherent in MLLM toguide cross modal representation learning. MAPLE formulates the learningprocess as reinforcement learning with two key components: (1) Automaticpreference data construction using off-the-shelf MLLM, and (2) a new RelativePreference Alignment (RPA) loss, which adapts Direct Preference Optimization(DPO) to the embedding learning setting. Experimental results show that ourpreference-guided alignment achieves substantial gains in fine-grainedcross-modal retrieval, underscoring its effectiveness in handling nuancedsemantic distinctions.</description>
      <author>example@mail.com (Pengfei Zhao, Rongbo Luan, Wei Zhang, Peng Wu, Sifeng He)</author>
      <guid isPermaLink="false">2506.06970v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Prime the search: Using large language models for guiding geometric task and motion planning by warm-starting tree search</title>
      <link>http://arxiv.org/abs/2506.07062v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The International Journal of Robotics Research (IJRR)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用大型语言模型（LLMs）指导几何任务与运动规划（G-TAMP）问题的方法，通过设计基于谓词的提示来帮助LLMs进行几何推理，并结合蒙特卡洛树搜索（MCTS）进行任务规划。&lt;h4&gt;背景&lt;/h4&gt;G-TAMP问题通常需要大量计算资源或数据来指导搜索，而人类通过常识直觉解决问题。传统方法依赖于领域无关的启发式或从规划经验中学习。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用LLMs的G-TAMP问题解决方法，以减少计算资源需求。&lt;h4&gt;方法&lt;/h4&gt;设计基于谓词的提示帮助LLMs进行几何推理，结合MCTS进行任务规划，并使用LLMs引导搜索过程。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在六个不同的G-TAMP问题上优于之前的LLM规划器和纯搜索算法。&lt;h4&gt;结论&lt;/h4&gt;LLMs可以有效地指导G-TAMP问题的任务规划，结合MCTS可以进一步提高搜索效率。&lt;h4&gt;翻译&lt;/h4&gt;The problem of relocating a set of objects to designated areas amidst movable obstacles can be framed as a Geometric Task and Motion Planning (G-TAMP) problem, a subclass of task and motion planning (TAMP). Traditional approaches to G-TAMP have relied either on domain-independent heuristics or on learning from planning experience to guide the search, both of which typically demand significant computational resources or data. In contrast, humans often use common sense to intuitively decide which objects to manipulate in G-TAMP problems. Inspired by this, we propose leveraging Large Language Models (LLMs), which have common sense knowledge acquired from internet-scale data, to guide task planning in G-TAMP problems. To enable LLMs to perform geometric reasoning, we design a predicate-based prompt that encodes geometric information derived from a motion planning algorithm. We then query the LLM to generate a task plan, which is then used to search for a feasible set of continuous parameters. Since LLMs are prone to mistakes, instead of committing to LLM's outputs, we extend Monte Carlo Tree Search (MCTS) to a hybrid action space and use the LLM to guide the search. Unlike the previous approach that calls an LLM at every node and incurs high computational costs, we use it to warm-start the MCTS with the nodes explored in completing the LLM's task plan. On six different G-TAMP problems, we show our method outperforms previous LLM planners and pure search algorithms. Code can be found at: https://github.com/iMSquared/prime-the-search&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1177/02783649251347307&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The problem of relocating a set of objects to designated areas amidst movableobstacles can be framed as a Geometric Task and Motion Planning (G-TAMP)problem, a subclass of task and motion planning (TAMP). Traditional approachesto G-TAMP have relied either on domain-independent heuristics or on learningfrom planning experience to guide the search, both of which typically demandsignificant computational resources or data. In contrast, humans often usecommon sense to intuitively decide which objects to manipulate in G-TAMPproblems. Inspired by this, we propose leveraging Large Language Models (LLMs),which have common sense knowledge acquired from internet-scale data, to guidetask planning in G-TAMP problems. To enable LLMs to perform geometricreasoning, we design a predicate-based prompt that encodes geometricinformation derived from a motion planning algorithm. We then query the LLM togenerate a task plan, which is then used to search for a feasible set ofcontinuous parameters. Since LLMs are prone to mistakes, instead of committingto LLM's outputs, we extend Monte Carlo Tree Search (MCTS) to a hybrid actionspace and use the LLM to guide the search. Unlike the previous approach thatcalls an LLM at every node and incurs high computational costs, we use it towarm-start the MCTS with the nodes explored in completing the LLM's task plan.On six different G-TAMP problems, we show our method outperforms previous LLMplanners and pure search algorithms. Code can be found at:https://github.com/iMSquared/prime-the-search</description>
      <author>example@mail.com (Dongryung Lee, Sejune Joo, Kimin Lee, Beomjoon Kim)</author>
      <guid isPermaLink="false">2506.07062v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>MAGNet: A Multi-Scale Attention-Guided Graph Fusion Network for DRC Violation Detection</title>
      <link>http://arxiv.org/abs/2506.07126v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 12 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MAGNet的混合深度学习模型，用于集成电路设计的DRC违规预测，通过结合U-Net和图神经网络来提高DRC的热点检测准确性。&lt;h4&gt;背景&lt;/h4&gt;DRC对于集成电路设计的成本降低和设计效率提升具有重要意义，机器学习在计算机辅助设计（CAD）中扮演着重要角色。&lt;h4&gt;目的&lt;/h4&gt;旨在通过MAGNet模型提高DRC违规预测的准确性和减少误报率。&lt;h4&gt;方法&lt;/h4&gt;MAGNet模型通过增强U-Net的动态注意力模块（DAM）和多尺度卷积模块（MSCM）来提取精细和多尺度的空间特征。同时，基于芯片布局的图结构，应用专用图神经网络（GNN）来模拟引脚之间的拓扑关系。在图构建过程中，生成图到网格的映射以对齐GNN特征和布局图像。此外，在训练期间采用标签增强策略以提高模型对稀疏违规模式的敏感性。&lt;h4&gt;主要发现&lt;/h4&gt;MAGNet有效结合了空间、语义和结构信息，在DRC热点检测中实现了更高的预测准确性和更低的误报率。通过增量训练，模型对热点的区分能力进一步增强。&lt;h4&gt;结论&lt;/h4&gt;MAGNet在整体性能上显著优于ibUnet、RouteNet和J-Net等模型，实现了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：设计规则检查（DRC）在集成电路（IC）设计中对于降低成本和提高设计效率具有重大意义。基于机器学习的DRC已成为计算机辅助设计（CAD）中的重要方法。在本文中，我们提出了一种名为MAGNet的混合深度学习模型，它集成了一个改进的U-Net和一个图神经网络，用于DRC违规预测。U-Net主干通过动态注意力模块（DAM）和多尺度卷积模块（MSCM）的增强来加强其提取细粒度和多尺度空间特征的能力。同时，基于芯片布局的图结构，应用专用图神经网络（GNN）来模拟引脚之间的拓扑关系。在图构建过程中，生成图到网格的映射以对齐GNN特征和布局图像。此外，在训练期间采用标签增强策略以提高模型对稀疏违规模式的敏感性。总体而言，MAGNet有效地结合了空间、语义和结构信息，在DRC热点检测中实现了提高的预测准确性和降低的误报率。随后，通过增量训练，实现了对热点更敏感的区分能力。结果表明，与ibUnet、RouteNet和J-Net相比，MAGnet在这些模型中表现显著优于，实现了整体性能的显著提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Design rule checking (DRC) is of great significance for cost reduction anddesign efficiency improvement in integrated circuit (IC) designs.Machine-learning-based DRC has become an important approach in computer-aideddesign (CAD). In this paper, we propose MAGNet, a hybrid deep learning modelthat integrates an improved U-Net with a graph neural network for DRC violationprediction. The U-Net backbone is enhanced with a Dynamic Attention Module(DAM) and a Multi-Scale Convolution Module (MSCM) to strengthen its capabilityin extracting fine-grained and multi-scale spatial features. In parallel, weconstruct a pixel-aligned graph structure based on chip layout tiles, and applya specialized GNN to model the topological relationships among pins. Duringgraph construction, a graph-to-grid mapping is generated to align GNN featureswith the layout image. In addition, a label amplification strategy is adoptedduring training to enhance the model's sensitivity to sparse violationpatterns. Overall, MAGNet effectively combines spatial, semantic, andstructural information, achieving improved prediction accuracy and reducedfalse positive rates in DRC hotspot detection. Subsequently, throughincremental training, we achieve a more sensitive discrimination ability forhotspots. The results demonstrate that, in comparison with ibUnet, RouteNet,and J-Net, MAGnet significantly outperforms these models, achieving substantialimprovements in overall performance.</description>
      <author>example@mail.com (Weihan Lu, Hong Cai Chen)</author>
      <guid isPermaLink="false">2506.07126v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Cross-channel Perception Learning for H&amp;E-to-IHC Virtual Staining</title>
      <link>http://arxiv.org/abs/2506.07559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CCPL的新型跨通道感知学习策略，用于数字病理学中的虚拟染色，以改善病理图像的分析和诊断。&lt;h4&gt;背景&lt;/h4&gt;随着数字病理学的快速发展，虚拟染色成为多媒体医学信息系统中的一项关键技术。然而，现有的H&amp;E到IHC研究往往忽略了细胞核和细胞膜之间的跨通道相关性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，提出了CCPL策略，以改善虚拟染色图像的质量，并支持自动病理诊断。&lt;h4&gt;方法&lt;/h4&gt;CCPL首先将HER2免疫组织化学染色分解为对应细胞核和细胞膜的Hematoxylin和DAB染色通道。利用Gigapath的Tile Encoder提取双通道特征，并测量核和膜之间的跨通道相关性。同时，通过Tile Encoder计算生成和真实染色图像的特征蒸馏损失，增强模型特征提取能力。此外，CCPL对单通道的焦点光学密度图进行统计分析，以确保染色分布和强度的统一。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CCPL有效地保留了病理特征，生成了高质量的虚拟染色图像，并为使用多媒体医学数据进行的自动病理诊断提供了强有力的支持。&lt;h4&gt;结论&lt;/h4&gt;CCPL是一种有效的虚拟染色技术，能够提高病理图像分析的诊断准确性，为病理学领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of digital pathology, virtual staining has becomea key technology in multimedia medical information systems, offering newpossibilities for the analysis and diagnosis of pathological images. However,existing H&amp;E-to-IHC studies often overlook the cross-channel correlationsbetween cell nuclei and cell membranes. To address this issue, we propose anovel Cross-Channel Perception Learning (CCPL) strategy. Specifically, CCPLfirst decomposes HER2 immunohistochemical staining into Hematoxylin and DABstaining channels, corresponding to cell nuclei and cell membranes,respectively. Using the pathology foundation model Gigapath's Tile Encoder,CCPL extracts dual-channel features from both the generated and real images andmeasures cross-channel correlations between nuclei and membranes. The featuresof the generated and real stained images, obtained through the Tile Encoder,are also used to calculate feature distillation loss, enhancing the model'sfeature extraction capabilities without increasing the inference burden.Additionally, CCPL performs statistical analysis on the focal optical densitymaps of both single channels to ensure consistency in staining distribution andintensity. Experimental results, based on quantitative metrics such as PSNR,SSIM, PCC, and FID, along with professional evaluations from pathologists,demonstrate that CCPL effectively preserves pathological features, generateshigh-quality virtual stained images, and provides robust support for automatedpathological diagnosis using multimedia medical data.</description>
      <author>example@mail.com (Hao Yang, JianYu Wu, Run Fang, Xuelian Zhao, Yuan Ji, Zhiyu Chen, Guibin He, Junceng Guo, Yang Liu, Xinhua Zeng)</author>
      <guid isPermaLink="false">2506.07559v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction</title>
      <link>http://arxiv.org/abs/2506.07002v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Two-page abstract version available at CVPR 2025 Embodied AI Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的3D占用预测方法BePo，用于场景理解，以支持自动驾驶。&lt;h4&gt;背景&lt;/h4&gt;现有的3D占用预测方法计算成本高，需要密集的3D特征体积和交叉注意力来有效聚合信息。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法的问题，BePo结合了鸟瞰图（BEV）和稀疏点表示。&lt;h4&gt;方法&lt;/h4&gt;BePo采用双分支设计：一个基于查询的稀疏点分支和一个BEV分支。稀疏点分支中学习的3D信息通过交叉注意力与BEV流共享，丰富了BEV平面上困难物体的弱信号。两个分支的输出最终融合以生成预测的3D占用。&lt;h4&gt;主要发现&lt;/h4&gt;在Occ3D-nuScenes和Occ3D-Waymo基准上进行的大量实验表明，BePo在性能上优于现有方法，并且在推理速度上与最新高效方法具有竞争力。&lt;h4&gt;结论&lt;/h4&gt;BePo是一种有效的3D占用预测方法，适用于自动驾驶和场景理解，同时保持了较高的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D occupancy provides fine-grained 3D geometry and semantics for sceneunderstanding which is critical for autonomous driving. Most existing methods,however, carry high compute costs, requiring dense 3D feature volume andcross-attention to effectively aggregate information. More recent works haveadopted Bird's Eye View (BEV) or sparse points as scene representation withmuch reduced cost, but still suffer from their respective shortcomings. Moreconcretely, BEV struggles with small objects that often experience significantinformation loss after being projected to the ground plane. On the other hand,points can flexibly model little objects in 3D, but is inefficient at capturingflat surfaces or large objects. To address these challenges, in this paper, wepresent a novel 3D occupancy prediction approach, BePo, which combines BEV andsparse points based representations. We propose a dual-branch design: aquery-based sparse points branch and a BEV branch. The 3D information learnedin the sparse points branch is shared with the BEV stream via cross-attention,which enriches the weakened signals of difficult objects on the BEV plane. Theoutputs of both branches are finally fused to generate predicted 3D occupancy.We conduct extensive experiments on the Occ3D-nuScenes and Occ3D-Waymobenchmarks that demonstrate the superiority of our proposed BePo. Moreover,BePo also delivers competitive inference speed when compared to the latestefficient approaches.</description>
      <author>example@mail.com (Yunxiao Shi, Hong Cai, Jisoo Jeong, Yinhao Zhu, Shizhong Han, Amin Ansari, Fatih Porikli)</author>
      <guid isPermaLink="false">2506.07002v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>A Culturally-diverse Multilingual Multimodal Video Benchmark &amp; Model</title>
      <link>http://arxiv.org/abs/2506.07032v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ViMUL-Bench，一个多语言视频多模态模型（LMM）基准，用于评估不同语言环境下的视频LMM性能。&lt;h4&gt;背景&lt;/h4&gt;现有的视频LMM大多使用英语，而多语言视频LMM的研究尚不充分。&lt;h4&gt;目的&lt;/h4&gt;开发一个多语言视频LMM基准，以促进文化语言包容性的视频LMM研究。&lt;h4&gt;方法&lt;/h4&gt;ViMUL-Bench包含14种语言的数据，涵盖15个类别，包括生活方式、节日、食物、仪式、地标和文化名人等。它包含开放式和多项选择题，视频时长从短到长，共有8k个样本，由母语者人工验证。此外，还引入了一个包含120万个样本的机器翻译多语言视频训练集，并开发了一个名为ViMUL的简单多语言视频LMM。&lt;h4&gt;主要发现&lt;/h4&gt;ViMUL-Bench和ViMUL多语言视频LMM有助于在不同资源语言之间提供更好的平衡，以实现视频理解。&lt;h4&gt;结论&lt;/h4&gt;ViMUL-Bench和相关的多语言视频LMM以及大规模多语言视频训练集将为未来研究文化语言包容性的多语言视频LMM提供便利。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译为中文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large multimodal models (LMMs) have recently gained attention due to theireffectiveness to understand and generate descriptions of visual content. Mostexisting LMMs are in English language. While few recent works exploremultilingual image LMMs, to the best of our knowledge, moving beyond theEnglish language for cultural and linguistic inclusivity is yet to beinvestigated in the context of video LMMs. In pursuit of more inclusive videoLMMs, we introduce a multilingual Video LMM benchmark, named ViMUL-Bench, toevaluate Video LMMs across 14 languages, including both low- and high-resourcelanguages: English, Chinese, Spanish, French, German, Hindi, Arabic, Russian,Bengali, Urdu, Sinhala, Tamil, Swedish, and Japanese. Our ViMUL-Bench isdesigned to rigorously test video LMMs across 15 categories including eightculturally diverse categories, ranging from lifestyles and festivals to foodsand rituals and from local landmarks to prominent cultural personalities.ViMUL-Bench comprises both open-ended (short and long-form) and multiple-choicequestions spanning various video durations (short, medium, and long) with 8ksamples that are manually verified by native language speakers. In addition, wealso introduce a machine translated multilingual video training set comprising1.2 million samples and develop a simple multilingual video LMM, named ViMUL,that is shown to provide a better tradeoff between high-and low-resourcelanguages for video understanding. We hope our ViMUL-Bench and multilingualvideo LMM along with a large-scale multilingual video training set will helpease future research in developing cultural and linguistic inclusivemultilingual video LMMs. Our proposed benchmark, video LMM and training datawill be publicly released at https://mbzuai-oryx.github.io/ViMUL/.</description>
      <author>example@mail.com (Bhuiyan Sanjid Shafique, Ashmal Vayani, Muhammad Maaz, Hanoona Abdul Rasheed, Dinura Dissanayake, Mohammed Irfan Kurpath, Yahya Hmaiti, Go Inoue, Jean Lahoud, Md. Safirur Rashid, Shadid Intisar Quasem, Maheen Fatima, Franco Vidal, Mykola Maslych, Ketan Pravin More, Sanoojan Baliah, Hasindri Watawana, Yuhao Li, Fabian Farestam, Leon Schaller, Roman Tymtsiv, Simon Weber, Hisham Cholakkal, Ivan Laptev, Shin'ichi Satoh, Michael Felsberg, Mubarak Shah, Salman Khan, Fahad Shahbaz Khan)</author>
      <guid isPermaLink="false">2506.07032v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Full Conformal Adaptation of Medical Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.06076v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IPMI 2025. Code: https://github.com/jusiro/FCA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了大规模预训练的视觉语言模型（VLMs）在医学图像分析中的应用，特别是在分割对齐预测（SCP）框架下的可靠性。&lt;h4&gt;背景&lt;/h4&gt;大规模预训练的VLMs在医学图像分析中具有广泛的迁移能力，但其可靠性方面尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;探讨VLMs在SCP框架下的行为，并提出解决方案以提高其可靠性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种全新的方法，即全对齐适应，通过少量数据集对预训练模型进行联合适应和对齐。同时，使用SS-Text线性探针求解器减轻计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;该方法需要与SCP相同的数据，在集合效率上提供高达27%的相对改进，同时保持相同的覆盖率保证。&lt;h4&gt;结论&lt;/h4&gt;全对齐适应和SS-Text可以有效提高VLMs在SCP框架下的可靠性和性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the application of large-scale pre-trained vision-language models (VLMs) in medical image analysis, particularly under the split conformal prediction (SCP) framework, and proposes a novel approach to improve their reliability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models (VLMs) pre-trained at large scale have shownunprecedented transferability capabilities and are being progressivelyintegrated into medical image analysis. Although its discriminative potentialhas been widely explored, its reliability aspect remains overlooked. This workinvestigates their behavior under the increasingly popular split conformalprediction (SCP) framework, which theoretically guarantees a given error levelon output sets by leveraging a labeled calibration set. However, the zero-shotperformance of VLMs is inherently limited, and common practice involvesfew-shot transfer learning pipelines, which cannot absorb the rigidexchangeability assumptions of SCP. To alleviate this issue, we propose fullconformal adaptation, a novel setting for jointly adapting and conformalizingpre-trained foundation models, which operates transductively over each testdata point using a few-shot adaptation set. Moreover, we complement thisframework with SS-Text, a novel training-free linear probe solver for VLMs thatalleviates the computational cost of such a transductive approach. We providecomprehensive experiments using 3 different modality-specialized medical VLMsand 9 adaptation tasks. Our framework requires exactly the same data as SCP,and provides consistent relative improvements of up to 27% on set efficiencywhile maintaining the same coverage guarantees.</description>
      <author>example@mail.com (Julio Silva-Rodríguez, Leo Fillioux, Paul-Henry Cournède, Maria Vakalopoulou, Stergios Christodoulidis, Ismail Ben Ayed, Jose Dolz)</author>
      <guid isPermaLink="false">2506.06076v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Graph-Based Physics-Guided Urban PM2.5 Air Quality Imputation with Constrained Monitoring Data</title>
      <link>http://arxiv.org/abs/2506.06917v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACM Transactions on Sensor Networks (TOSN) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GraPhy的基于图和物理指导的学习框架，用于在监测数据有限的城区进行高分辨率和精确的空气质量建模。&lt;h4&gt;背景&lt;/h4&gt;精细的空气质量监测信息对于减少公众接触污染物至关重要，但在社会经济条件较差的地区，监测网络通常较为稀疏，限制了空气质量建模的准确性和分辨率。&lt;h4&gt;目的&lt;/h4&gt;为了解决这个问题，研究者提出了一个名为GraPhy的物理指导图神经网络架构，该架构针对低分辨率监测数据设计了特定层次和边缘特征。&lt;h4&gt;方法&lt;/h4&gt;使用加利福尼亚社会经济条件较差的圣华金谷的数据进行实验，评估了GraPhy的性能，比较了均方误差（MSE）、平均绝对误差（MAE）和R平方值（R2），并与各种基线模型进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，GraPhy在MSE、MAE和R2方面均取得了最佳的整体性能，与基线模型相比，性能提升了9%-56%。此外，GraPhy在不同空间异质性水平上均优于基线模型，证明了模型设计的效果。&lt;h4&gt;结论&lt;/h4&gt;GraPhy框架能够有效提高空气质量建模的准确性和分辨率，尤其是在监测数据稀疏的地区。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3734869&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work introduces GraPhy, a graph-based, physics-guided learning frameworkfor high-resolution and accurate air quality modeling in urban areas withlimited monitoring data. Fine-grained air quality monitoring information isessential for reducing public exposure to pollutants. However, monitoringnetworks are often sparse in socioeconomically disadvantaged regions, limitingthe accuracy and resolution of air quality modeling. To address this, wepropose a physics-guided graph neural network architecture called GraPhy withlayers and edge features designed specifically for low-resolution monitoringdata. Experiments using data from California's socioeconomically disadvantagedSan Joaquin Valley show that GraPhy achieves the overall best performanceevaluated by mean squared error (MSE), mean absolute error (MAE), and R-squarevalue (R2), improving the performance by 9%-56% compared to various baselinemodels. Moreover, GraPhy consistently outperforms baselines across differentspatial heterogeneity levels, demonstrating the effectiveness of our modeldesign.</description>
      <author>example@mail.com (Shangjie Du, Hui Wei, Dong Yoon Lee, Zhizhang Hu, Shijia Pan)</author>
      <guid isPermaLink="false">2506.06917v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>APTOS-2024 challenge report: Generation of synthetic 3D OCT images from fundus photographs</title>
      <link>http://arxiv.org/abs/2506.07542v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了APTOS-2024挑战赛，旨在推动基于人工智能的视网膜图像到3D光学相干断层扫描（OCT）图像的生成技术，以提高眼科诊疗的可及性。&lt;h4&gt;背景&lt;/h4&gt;OCT技术在眼科疾病诊断中至关重要，但其成本较高，限制了其普及。2D彩色眼底摄影虽然成本较低，但无法提供OCT的高分辨率3D图像。&lt;h4&gt;目的&lt;/h4&gt;通过APTOS-2024挑战赛，探索将2D眼底图像转换为3D OCT图像的可行性，以提升眼科诊疗的可及性。&lt;h4&gt;方法&lt;/h4&gt;APTOS-2024挑战赛包括基准数据集、评估方法和顶尖解决方案分析。评估方法包括基于图像的相似度和基于视频的体积一致性。&lt;h4&gt;主要发现&lt;/h4&gt;挑战吸引了342个团队参与，其中9个团队进入决赛。领先的解决方案采用了混合数据预处理、外部眼科成像数据集预训练、视觉基础模型集成和模型架构改进等创新方法。&lt;h4&gt;结论&lt;/h4&gt;APTOS-2024挑战赛证明了眼底图像到3D OCT图像合成的可行性，这可能是提高眼科诊疗在资源匮乏的医疗环境中可及性的潜在解决方案，同时有助于加速医学研究和临床应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optical Coherence Tomography (OCT) provides high-resolution, 3D, andnon-invasive visualization of retinal layers in vivo, serving as a criticaltool for lesion localization and disease diagnosis. However, its widespreadadoption is limited by equipment costs and the need for specialized operators.In comparison, 2D color fundus photography offers faster acquisition andgreater accessibility with less dependence on expensive devices. Althoughgenerative artificial intelligence has demonstrated promising results inmedical image synthesis, translating 2D fundus images into 3D OCT imagespresents unique challenges due to inherent differences in data dimensionalityand biological information between modalities. To advance generative models inthe fundus-to-3D-OCT setting, the Asia Pacific Tele-Ophthalmology Society(APTOS-2024) organized a challenge titled Artificial Intelligence-based OCTGeneration from Fundus Images. This paper details the challenge framework(referred to as APTOS-2024 Challenge), including: the benchmark dataset,evaluation methodology featuring two fidelity metrics-image-based distance(pixel-level OCT B-scan similarity) and video-based distance (semantic-levelvolumetric consistency), and analysis of top-performing solutions. Thechallenge attracted 342 participating teams, with 42 preliminary submissionsand 9 finalists. Leading methodologies incorporated innovations in hybrid datapreprocessing or augmentation (cross-modality collaborative paradigms),pre-training on external ophthalmic imaging datasets, integration of visionfoundation models, and model architecture improvement. The APTOS-2024 Challengeis the first benchmark demonstrating the feasibility of fundus-to-3D-OCTsynthesis as a potential solution for improving ophthalmic care accessibilityin under-resourced healthcare settings, while helping to expedite medicalresearch and clinical applications.</description>
      <author>example@mail.com (Bowen Liu, Weiyi Zhang, Peranut Chotcomwongse, Xiaolan Chen, Ruoyu Chen, Pawin Pakaymaskul, Niracha Arjkongharn, Nattaporn Vongsa, Xuelian Cheng, Zongyuan Ge, Kun Huang, Xiaohui Li, Yiru Duan, Zhenbang Wang, BaoYe Xie, Qiang Chen, Huazhu Fu, Michael A. Mahr, Jiaqi Qu, Wangyiyang Chen, Shiye Wang, Yubo Tan, Yongjie Li, Mingguang He, Danli Shi, Paisan Ruamviboonsuk)</author>
      <guid isPermaLink="false">2506.07542v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>IRS: Instance-Level 3D Scene Graphs via Room Prior Guided LiDAR-Camera Fusion</title>
      <link>http://arxiv.org/abs/2506.06804v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于激光雷达-相机融合的实例级3D场景图构建框架，通过视觉基础模型（VFMs）提高语义提取的准确性和一致性，实现了在开放世界环境中的高效场景理解。&lt;h4&gt;背景&lt;/h4&gt;室内场景理解是机器人领域的基本挑战，对导航和操作等下游任务有直接影响。传统的封闭集识别或闭环检测方法在开放世界环境中的适应性有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种鲁棒且高效的框架，通过LiDAR和相机融合实现实例级3D场景图的构建，提高开放世界环境中的场景理解能力。&lt;h4&gt;方法&lt;/h4&gt;利用LiDAR的广角视野和长距离传感能力快速获取房间级几何先验；采用多级VFMs提高语义提取的准确性和一致性；基于房间分割实现实例融合的并行处理；结合几何和语义线索提高融合的准确性和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，该方法在构建速度上提高了约一个数量级，同时保持了高语义精度。&lt;h4&gt;结论&lt;/h4&gt;通过模拟和真实环境的大量实验验证了该方法的有效性，并通过语言引导的语义导航任务展示了其实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Indoor scene understanding remains a fundamental challenge in robotics, with direct implications for downstream tasks such as navigation and manipulation. Traditional approaches often rely on closed-set recognition or loop closure, limiting their adaptability in open-world environments. With the advent of visual foundation models (VFMs), open-vocabulary recognition and natural language querying have become feasible, unlocking new possibilities for 3D scene graph construction. In this paper, we propose a robust and efficient framework for instance-level 3D scene graph construction via LiDAR-camera fusion. Leveraging LiDAR's widefield of view (FOV) and long-range sensing capabilities, we rapidly acquire room-level geometric priors. Multi-level VFMs are employed to improve the accuracy and consistency of semantic extraction. During instance fusion, room-based segmentation enables parallel processing, while the integration of geometric and semantic cues significantly enhances fusion accuracy and robustness. Compared to state-of-the-art methods, our approach achieves up to an order-of-magnitude improvement in construction speed while maintaining high semantic precision. Extensive experiments in both simulated and real-world environments validate the effectiveness of our approach. We further demonstrate its practical value through a language-guided semantic navigation task, highlighting its potential for real-world robotic applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Indoor scene understanding remains a fundamental challenge in robotics, withdirect implications for downstream tasks such as navigation and manipulation.Traditional approaches often rely on closed-set recognition or loop closure,limiting their adaptability in open-world environments. With the advent ofvisual foundation models (VFMs), open-vocabulary recognition and naturallanguage querying have become feasible, unlocking new possibilities for 3Dscene graph construction.  In this paper, we propose a robust and efficient framework for instance-level3D scene graph construction via LiDAR-camera fusion. Leveraging LiDAR's widefield of view (FOV) and long-range sensing capabilities, we rapidly acquireroom-level geometric priors. Multi-level VFMs are employed to improve theaccuracy and consistency of semantic extraction. During instance fusion,room-based segmentation enables parallel processing, while the integration ofgeometric and semantic cues significantly enhances fusion accuracy androbustness. Compared to state-of-the-art methods, our approach achieves up toan order-of-magnitude improvement in construction speed while maintaining highsemantic precision.  Extensive experiments in both simulated and real-world environments validatethe effectiveness of our approach. We further demonstrate its practical valuethrough a language-guided semantic navigation task, highlighting its potentialfor real-world robotic applications.</description>
      <author>example@mail.com (Hongming Chen, Yiyang Lin, Ziliang Li, Biyu Ye, Yuying Zhang, Ximin Lyu)</author>
      <guid isPermaLink="false">2506.06804v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>TerraFM: A Scalable Foundation Model for Unified Multisensor Earth Observation</title>
      <link>http://arxiv.org/abs/2506.06281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TerraFM是一个可扩展的自监督学习模型，利用全球分布的Sentinel-1和Sentinel-2影像，通过大空间瓦片和土地覆盖意识采样来丰富空间和语义覆盖。该模型在分类和分割任务上表现出强大的泛化能力，在GEO-Bench和Copernicus-Bench上优于先前模型。&lt;h4&gt;背景&lt;/h4&gt;现代地球观测越来越多地利用深度学习来利用卫星影像的规模和多样性。尽管最近的基础模型在地球观测任务中表现出有希望的泛化能力，但许多模型仍受限于其训练数据的规模、地理覆盖和光谱多样性，这些因素对于学习可全球转移的表示至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出TerraFM模型，旨在解决当前深度学习模型在地球观测任务中存在的泛化能力不足的问题。&lt;h4&gt;方法&lt;/h4&gt;TerraFM模型通过以下方法实现其目标：1）利用全球分布的Sentinel-1和Sentinel-2影像；2）采用大空间瓦片和土地覆盖意识采样；3）将雷达和光学输入通过模态特定的补丁嵌入和自适应交叉注意力融合；4）结合局部-全局对比学习，并引入双中心机制，结合类频率感知正则化来解决土地覆盖中的长尾分布。&lt;h4&gt;主要发现&lt;/h4&gt;TerraFM在分类和分割任务上实现了强大的泛化能力，在GEO-Bench和Copernicus-Bench上优于先前模型。&lt;h4&gt;结论&lt;/h4&gt;TerraFM模型是一个有效的工具，可以提高地球观测任务的性能，并在全球范围内具有可转移性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代地球观测（EO）越来越多地利用深度学习来利用卫星影像的规模和多样性。虽然最近的基础模型在EO任务中展示了有希望的泛化能力，但许多模型仍然受限于其训练数据的规模、地理覆盖和光谱多样性，这些因素对于学习可全球转移的表示至关重要。在这项工作中，我们介绍了TerraFM，一个可扩展的自监督学习模型，它利用全球分布的Sentinel-1和Sentinel-2影像，结合大型空间瓦片和土地覆盖意识采样来丰富空间和语义覆盖。通过将传感模式视为自监督方法中的自然增强，我们通过模态特定的补丁嵌入和自适应交叉注意力融合统一了雷达和光学输入。我们的训练策略结合了局部-全局对比学习，并引入了一个双重中心机制，该机制结合了类频率感知正则化来解决土地覆盖中的长尾分布。TerraFM在分类和分割任务上实现了强大的泛化能力，在GEO-Bench和Copernicus-Bench上优于先前模型。我们的代码和预训练模型可在以下链接公开获取：https://github.com/mbzuai-oryx/TerraFM 。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern Earth observation (EO) increasingly leverages deep learning to harnessthe scale and diversity of satellite imagery across sensors and regions. Whilerecent foundation models have demonstrated promising generalization across EOtasks, many remain limited by the scale, geographical coverage, and spectraldiversity of their training data, factors critical for learning globallytransferable representations. In this work, we introduce TerraFM, a scalableself-supervised learning model that leverages globally distributed Sentinel-1and Sentinel-2 imagery, combined with large spatial tiles and land-cover awaresampling to enrich spatial and semantic coverage. By treating sensingmodalities as natural augmentations in our self-supervised approach, we unifyradar and optical inputs via modality-specific patch embeddings and adaptivecross-attention fusion. Our training strategy integrates local-globalcontrastive learning and introduces a dual-centering mechanism thatincorporates class-frequency-aware regularization to address long-taileddistributions in land cover.TerraFM achieves strong generalization on bothclassification and segmentation tasks, outperforming prior models on GEO-Benchand Copernicus-Bench. Our code and pretrained models are publicly available at:https://github.com/mbzuai-oryx/TerraFM .</description>
      <author>example@mail.com (Muhammad Sohail Danish, Muhammad Akhtar Munir, Syed Roshaan Ali Shah, Muhammad Haris Khan, Rao Muhammad Anwer, Jorma Laaksonen, Fahad Shahbaz Khan, Salman Khan)</author>
      <guid isPermaLink="false">2506.06281v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>KNN-Defense: Defense against 3D Adversarial Point Clouds using Nearest-Neighbor Search</title>
      <link>http://arxiv.org/abs/2506.06906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为KNN-Defense的防御策略，用于增强3D点云分类器的对抗鲁棒性，并展示了其在ModelNet40数据集上的有效性。&lt;h4&gt;背景&lt;/h4&gt;深度神经网络在分析3D点云数据方面表现出色，但其易受对抗攻击的影响，这些攻击会损害点云的语义和结构完整性。&lt;h4&gt;目的&lt;/h4&gt;提出KNN-Defense以解决3D视觉系统对抗攻击的脆弱性问题。&lt;h4&gt;方法&lt;/h4&gt;KNN-Defense基于流形假设和特征空间中的最近邻搜索，通过利用训练集中邻近样本的语义相似性来恢复受干扰的输入。&lt;h4&gt;主要发现&lt;/h4&gt;KNN-Defense在多种攻击类型下显著提高了鲁棒性，尤其是在点去除攻击中，与现有方法相比，KNN-Defense在PointNet、PointNet++、DGCNN和PCT上的准确率分别提高了20.1%、3.6%、3.44%和7.74%。&lt;h4&gt;结论&lt;/h4&gt;KNN-Defense提供了一种可扩展且有效的解决方案，用于增强3D点云分类器的对抗鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：深度神经网络（DNNs）在分析3D点云数据方面表现出色。然而，它们容易受到对抗攻击（如点删除、移动和添加）的影响，这给3D视觉系统的可靠性带来了重大挑战。这些攻击会破坏点云的语义和结构完整性，使许多现有防御机制失效。为了解决这个问题，提出了一种名为KNN-Defense的防御策略，其基于流形假设和特征空间中的最近邻搜索。该方法不是通过重建表面几何形状或强制执行均匀的点分布，而是通过利用训练集中邻近样本的语义相似性来恢复受干扰的输入。KNN-Defense轻量级且计算效率高，可以实现快速推理，非常适合实时和实际应用。在ModelNet40数据集上的实证结果表明，KNN-Defense在各种攻击类型下显著提高了鲁棒性。特别是在点删除攻击中——由于关键点的针对性删除，许多现有方法表现不佳——该方法在PointNet、PointNet++、DGCNN和PCT上分别实现了20.1%、3.6%、3.44%和7.74%的准确率提升。这些发现表明，KNN-Defense为增强3D点云分类器的对抗鲁棒性提供了一种可扩展且有效的解决方案。（该方法的开源实现，包括代码和数据，可在https://github.com/nimajam41/3d-knn-defense上获得。)&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks (DNNs) have demonstrated remarkable performance inanalyzing 3D point cloud data. However, their vulnerability to adversarialattacks-such as point dropping, shifting, and adding-poses a critical challengeto the reliability of 3D vision systems. These attacks can compromise thesemantic and structural integrity of point clouds, rendering many existingdefense mechanisms ineffective. To address this issue, a defense strategy namedKNN-Defense is proposed, grounded in the manifold assumption andnearest-neighbor search in feature space. Instead of reconstructing surfacegeometry or enforcing uniform point distributions, the method restoresperturbed inputs by leveraging the semantic similarity of neighboring samplesfrom the training set. KNN-Defense is lightweight and computationallyefficient, enabling fast inference and making it suitable for real-time andpractical applications. Empirical results on the ModelNet40 datasetdemonstrated that KNN-Defense significantly improves robustness across variousattack types. In particular, under point-dropping attacks-where many existingmethods underperform due to the targeted removal of critical points-theproposed method achieves accuracy gains of 20.1%, 3.6%, 3.44%, and 7.74% onPointNet, PointNet++, DGCNN, and PCT, respectively. These findings suggest thatKNN-Defense offers a scalable and effective solution for enhancing theadversarial resilience of 3D point cloud classifiers. (An open-sourceimplementation of the method, including code and data, is available athttps://github.com/nimajam41/3d-knn-defense).</description>
      <author>example@mail.com (Nima Jamali, Matina Mahdizadeh Sani, Hanieh Naderi, Shohreh Kasaei)</author>
      <guid isPermaLink="false">2506.06906v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Multidimensional Analysis of Specific Language Impairment Using Unsupervised Learning Through PCA and Clustering</title>
      <link>http://arxiv.org/abs/2506.05498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 3 figures, 16 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究通过无监督机器学习技术，分析了儿童自然语言发展轨迹，以识别SLI（特定语言障碍）和正常儿童的语言特征，为早期识别和针对性干预提供见解。&lt;h4&gt;背景&lt;/h4&gt;SLI影响大约7%的儿童，表现为孤立的语言缺陷，尽管认知能力、感官系统和环境支持正常。&lt;h4&gt;目的&lt;/h4&gt;研究旨在使用无监督机器学习技术，识别有SLI和无SLI儿童的天然语言发展轨迹。&lt;h4&gt;方法&lt;/h4&gt;研究分析了来自三个语料库（Conti-Ramsden 4、ENNI和Gillam）的1,163名4-16岁儿童的叙事样本，使用主成分分析（PCA）和聚类方法，评估了64个语言特征。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现两个主要聚类：（1）高语言产出且SLI发病率低；（2）产出有限但句法复杂性高且SLI发病率高。边界案例表现出中间特征，支持语言能力的连续模型。SLI主要表现为产出能力降低，而非句法复杂性缺陷。&lt;h4&gt;结论&lt;/h4&gt;研究结果挑战了分类诊断框架，并突出了无监督学习技术在细化诊断标准和干预策略方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;This study aims to identify natural language development trajectories in children with and without SLI using unsupervised machine learning techniques, providing insights for early identification and targeted interventions. Narrative samples from 1,163 children aged 4-16 years across three corpora (Conti-Ramsden 4, ENNI, and Gillam) were analyzed using Principal Component Analysis (PCA) and clustering. A total of 64 linguistic features were evaluated to uncover developmental trajectories and distinguish linguistic profiles. Two primary clusters emerged: (1) high language production with low SLI prevalence, and (2) limited production but higher syntactic complexity with higher SLI prevalence. Additionally, boundary cases exhibited intermediate traits, supporting a continuum model of language abilities. Findings suggest SLI manifests primarily through reduced production capacity rather than syntactic complexity deficits. The results challenge categorical diagnostic frameworks and highlight the potential of unsupervised learning techniques for refining diagnostic criteria and intervention strategies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Specific Language Impairment (SLI) affects approximately 7 percent ofchildren, presenting as isolated language deficits despite normal cognitiveabilities, sensory systems, and supportive environments. Traditional diagnosticapproaches often rely on standardized assessments, which may overlook subtledevelopmental patterns. This study aims to identify natural languagedevelopment trajectories in children with and without SLI using unsupervisedmachine learning techniques, providing insights for early identification andtargeted interventions. Narrative samples from 1,163 children aged 4-16 yearsacross three corpora (Conti-Ramsden 4, ENNI, and Gillam) were analyzed usingPrincipal Component Analysis (PCA) and clustering. A total of 64 linguisticfeatures were evaluated to uncover developmental trajectories and distinguishlinguistic profiles. Two primary clusters emerged: (1) high language productionwith low SLI prevalence, and (2) limited production but higher syntacticcomplexity with higher SLI prevalence. Additionally, boundary cases exhibitedintermediate traits, supporting a continuum model of language abilities.Findings suggest SLI manifests primarily through reduced production capacityrather than syntactic complexity deficits. The results challenge categoricaldiagnostic frameworks and highlight the potential of unsupervised learningtechniques for refining diagnostic criteria and intervention strategies.</description>
      <author>example@mail.com (Niruthiha Selvanayagam)</author>
      <guid isPermaLink="false">2506.05498v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks in Modern AI-aided Drug Discovery</title>
      <link>http://arxiv.org/abs/2506.06915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了图神经网络（GNNs）在人工智能辅助药物发现（AIDD）中的应用，包括其在分子建模中的角色、方法基础、代表性应用和最新进展。&lt;h4&gt;背景&lt;/h4&gt;GNNs是深度学习中的拓扑/结构感知模型，通过直接操作分子图，能够学习药物分子的复杂拓扑和几何特征。&lt;h4&gt;目的&lt;/h4&gt;提供GNNs在药物发现中方法基础和代表性应用的全面概述。&lt;h4&gt;方法&lt;/h4&gt;综述了分子性质预测、虚拟筛选、分子生成、生物医学知识图谱构建和合成规划等任务中的应用，并关注了最近的方法进展，如几何GNNs、可解释模型、不确定性量化、可扩展图架构和图生成框架。&lt;h4&gt;主要发现&lt;/h4&gt;讨论了这些模型如何与现代深度学习方法结合，如自监督学习、多任务学习、元学习和预训练，并强调了在将GNNs应用于现实世界药物发现管线时遇到的实践挑战和方法瓶颈。&lt;h4&gt;结论&lt;/h4&gt;讨论了GNNs在药物发现中的未来发展方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs), as topology/structure-aware models within deeplearning, have emerged as powerful tools for AI-aided drug discovery (AIDD). Bydirectly operating on molecular graphs, GNNs offer an intuitive and expressiveframework for learning the complex topological and geometric features ofdrug-like molecules, cementing their role in modern molecular modeling. Thisreview provides a comprehensive overview of the methodological foundations andrepresentative applications of GNNs in drug discovery, spanning tasks such asmolecular property prediction, virtual screening, molecular generation,biomedical knowledge graph construction, and synthesis planning. Particularattention is given to recent methodological advances, including geometric GNNs,interpretable models, uncertainty quantification, scalable graph architectures,and graph generative frameworks. We also discuss how these models integratewith modern deep learning approaches, such as self-supervised learning,multi-task learning, meta-learning and pre-training. Throughout this review, wehighlight the practical challenges and methodological bottlenecks encounteredwhen applying GNNs to real-world drug discovery pipelines, and conclude with adiscussion on future directions.</description>
      <author>example@mail.com (Odin Zhang, Haitao Lin, Xujun Zhang, Xiaorui Wang, Zhenxing Wu, Qing Ye, Weibo Zhao, Jike Wang, Kejun Ying, Yu Kang, Chang-yu Hsieh, Tingjun Hou)</author>
      <guid isPermaLink="false">2506.06915v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>IMPA-HGAE:Intra-Meta-Path Augmented Heterogeneous Graph Autoencoder</title>
      <link>http://arxiv.org/abs/2506.06809v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为IMPA-HGAE的新型框架，用于提升异构图的自监督学习方法，并通过实验验证了其在异构图数据集上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;自监督学习方法因其优越的泛化能力和低标注成本，在多种下游任务中得到了广泛应用。&lt;h4&gt;目的&lt;/h4&gt;针对现有异构图自监督模型将异构图转换为同构图进行训练的局限性，旨在通过充分利用元路径上的内部节点信息来增强目标节点嵌入。&lt;h4&gt;方法&lt;/h4&gt;IMPA-HGAE框架通过创新掩码策略增强生成式自监督模型在异构图数据上的表示能力，并讨论了方法的可解释性和未来研究方向。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，IMPA-HGAE在异构图数据集上取得了优于现有方法的性能。&lt;h4&gt;结论&lt;/h4&gt;IMPA-HGAE为利用元路径引导的结构语义在复杂图场景中进行鲁棒表示学习提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised learning (SSL) methods have been increasingly applied to diverse downstream tasks due to their superior generalization capabilities and low annotation costs. However, most existing heterogeneous graph SSL models convert heterogeneous graphs into homogeneous ones via meta-paths for training, which only leverage information from nodes at both ends of meta-paths while underutilizing the heterogeneous node information along the meta-paths. To address this limitation, this paper proposes a novel framework named IMPA-HGAE to enhance target node embeddings by fully exploiting internal node information along meta-paths. Experimental results validate that IMPA-HGAE achieves superior performance on heterogeneous datasets. Furthermore, this paper introduces innovative masking strategies to strengthen the representational capacity of generative SSL models on heterogeneous graph data. Additionally, this paper discusses the interpretability of the proposed method and potential future directions for generative self-supervised learning in heterogeneous graphs. This work provides insights into leveraging meta-path-guided structuralsemantics for robust representation learning in complex graph scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) methods have been increasingly applied todiverse downstream tasks due to their superior generalization capabilities andlow annotation costs. However, most existing heterogeneous graph SSL modelsconvert heterogeneous graphs into homogeneous ones via meta-paths for training,which only leverage information from nodes at both ends of meta-paths whileunderutilizing the heterogeneous node information along the meta-paths. Toaddress this limitation, this paper proposes a novel framework named IMPA-HGAEto enhance target node embeddings by fully exploiting internal node informationalong meta-paths. Experimental results validate that IMPA-HGAE achievessuperior performance on heterogeneous datasets. Furthermore, this paperintroduce innovative masking strategies to strengthen the representationalcapacity of generative SSL models on heterogeneous graph data. Additionally,this paper discuss the interpretability of the proposed method and potentialfuture directions for generative self-supervised learning in heterogeneousgraphs. This work provides insights into leveraging meta-path-guided structuralsemantics for robust representation learning in complex graph scenarios.</description>
      <author>example@mail.com (Di Lin, Wanjing Ren, Xuanbin Li, Rui Zhang)</author>
      <guid isPermaLink="false">2506.06809v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>PhysLab: A Benchmark Dataset for Multi-Granularity Visual Parsing of Physics Experiments</title>
      <link>http://arxiv.org/abs/2506.06631v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为PhysLab的视频数据集，用于视觉解析图像和视频，特别针对复杂物理实验的学生行为进行捕捉。&lt;h4&gt;背景&lt;/h4&gt;现有的图像和视频数据集在标注粒度、领域覆盖和过程指导方面存在不足，限制了视觉解析的发展。&lt;h4&gt;目的&lt;/h4&gt;提出PhysLab数据集以解决现有数据集的不足，推动精细视觉解析，促进智能教室系统的发展，以及计算机视觉与教育技术的整合。&lt;h4&gt;方法&lt;/h4&gt;PhysLab数据集包含了620个长视频，涵盖了4个具有多样科学仪器和丰富人机交互模式的代表实验，提供了多层次的标注以支持动作识别、目标检测、人机交互分析等多种视觉任务。&lt;h4&gt;主要发现&lt;/h4&gt;论文通过建立基线和广泛评估，突出了过程教育视频解析的关键挑战。&lt;h4&gt;结论&lt;/h4&gt;PhysLab数据集和评估工具包已公开发布，预期将成为视觉解析研究的重要资源。&lt;h4&gt;翻译&lt;/h4&gt;Visual parsing of images and videos is critical for a wide range of real-world applications. However, progress in this field is constrained by limitations of existing datasets: (1) insufficient annotation granularity, which impedes fine-grained scene understanding and high-level reasoning; (2) limited coverage of domains, particularly a lack of datasets tailored for educational scenarios; and (3) lack of explicit procedural guidance, with minimal logical rules and insufficient representation of structured task process. To address these gaps, we introduce PhysLab, the first video dataset that captures students conducting complex physics experiments. The dataset includes four representative experiments that feature diverse scientific instruments and rich human-object interaction (HOI) patterns. PhysLab comprises 620 long-form videos and provides multilevel annotations that support a variety of vision tasks, including action recognition, object detection, HOI analysis, etc. We establish strong baselines and perform extensive evaluations to highlight key challenges in the parsing of procedural educational videos. We expect PhysLab to serve as a valuable resource for advancing fine-grained visual parsing, facilitating intelligent classroom systems, and fostering closer integration between computer vision and educational technologies. The dataset and the evaluation toolkit are publicly available at https://github.com/ZMH-SDUST/PhysLab.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual parsing of images and videos is critical for a wide range ofreal-world applications. However, progress in this field is constrained bylimitations of existing datasets: (1) insufficient annotation granularity,which impedes fine-grained scene understanding and high-level reasoning; (2)limited coverage of domains, particularly a lack of datasets tailored foreducational scenarios; and (3) lack of explicit procedural guidance, withminimal logical rules and insufficient representation of structured taskprocess. To address these gaps, we introduce PhysLab, the first video datasetthat captures students conducting complex physics experiments. The datasetincludes four representative experiments that feature diverse scientificinstruments and rich human-object interaction (HOI) patterns. PhysLab comprises620 long-form videos and provides multilevel annotations that support a varietyof vision tasks, including action recognition, object detection, HOI analysis,etc. We establish strong baselines and perform extensive evaluations tohighlight key challenges in the parsing of procedural educational videos. Weexpect PhysLab to serve as a valuable resource for advancing fine-grainedvisual parsing, facilitating intelligent classroom systems, and fosteringcloser integration between computer vision and educational technologies. Thedataset and the evaluation toolkit are publicly available athttps://github.com/ZMH-SDUST/PhysLab.</description>
      <author>example@mail.com (Minghao Zou, Qingtian Zeng, Yongping Miao, Shangkun Liu, Zilong Wang, Hantao Liu, Wei Zhou)</author>
      <guid isPermaLink="false">2506.06631v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Model-Driven Graph Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.06212v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MGCL的模型驱动的图对比学习（GCL）框架，该框架利用图论（图的概率生成模型）来指导对比学习，通过考虑数据的潜在生成过程。&lt;h4&gt;背景&lt;/h4&gt;GCL作为一种自监督框架，在无需依赖标注标签的情况下，能够学习具有表达性的节点或图表示，这在现实世界的数据中通常较为稀缺。&lt;h4&gt;目的&lt;/h4&gt;通过对比增强的图数据视图，提高节点和图分类等下游任务的表现。&lt;h4&gt;方法&lt;/h4&gt;MGCL首先估计与观察数据相关的图论，然后定义一个基于图论的增强过程，实现数据自适应和原理性的增强。对于图级任务，MGCL对数据集进行聚类，并为每个组估计一个图论，以便对比对对反映共享的语义和结构。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上的广泛实验表明，MGCL实现了最先进的性能，突出了将生成模型纳入GCL的优势。&lt;h4&gt;结论&lt;/h4&gt;MGCL框架通过利用图论提高了图对比学习的效果，为图级任务提供了更有效的数据增强和表示学习策略。&lt;h4&gt;翻译&lt;/h4&gt;We propose MGCL, a model-driven graph contrastive learning (GCL) framework that leverages graphons (probabilistic generative models for graphs) to guide contrastive learning by accounting for the data's underlying generative process. GCL has emerged as a powerful self-supervised framework for learning expressive node or graph representations without relying on annotated labels, which are often scarce in real-world data. By contrasting augmented views of graph data, GCL has demonstrated strong performance across various downstream tasks, such as node and graph classification. However, existing methods typically rely on manually designed or heuristic augmentation strategies that are not tailored to the underlying data distribution and operate at the individual graph level, ignoring similarities among graphs generated from the same model. Conversely, in our proposed approach, MGCL first estimates the graphon associated with the observed data and then defines a graphon-informed augmentation process, enabling data-adaptive and principled augmentations. Additionally, for graph-level tasks, MGCL clusters the dataset and estimates a graphon per group, enabling contrastive pairs to reflect shared semantics and structure. Extensive experiments on benchmark datasets demonstrate that MGCL achieves state-of-the-art performance, highlighting the advantages of incorporating generative models into GCL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose $\textbf{MGCL}$, a model-driven graph contrastive learning (GCL)framework that leverages graphons (probabilistic generative models for graphs)to guide contrastive learning by accounting for the data's underlyinggenerative process. GCL has emerged as a powerful self-supervised framework forlearning expressive node or graph representations without relying on annotatedlabels, which are often scarce in real-world data. By contrasting augmentedviews of graph data, GCL has demonstrated strong performance across variousdownstream tasks, such as node and graph classification. However, existingmethods typically rely on manually designed or heuristic augmentationstrategies that are not tailored to the underlying data distribution andoperate at the individual graph level, ignoring similarities among graphsgenerated from the same model. Conversely, in our proposed approach, MGCL firstestimates the graphon associated with the observed data and then defines agraphon-informed augmentation process, enabling data-adaptive and principledaugmentations. Additionally, for graph-level tasks, MGCL clusters the datasetand estimates a graphon per group, enabling contrastive pairs to reflect sharedsemantics and structure. Extensive experiments on benchmark datasetsdemonstrate that MGCL achieves state-of-the-art performance, highlighting theadvantages of incorporating generative models into GCL.</description>
      <author>example@mail.com (Ali Azizpour, Nicolas Zilberstein, Santiago Segarra)</author>
      <guid isPermaLink="false">2506.06212v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Face recognition on point cloud with cgan-top for denoising</title>
      <link>http://arxiv.org/abs/2506.06864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in ICASSP 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在噪声点云上进行端到端3D人脸识别的方法，该方法有效地结合了去噪和识别模块。&lt;h4&gt;背景&lt;/h4&gt;使用3D点云进行人脸识别越来越受到关注，但由于传感器不完美，原始点云往往包含大量噪声。&lt;h4&gt;目的&lt;/h4&gt;提出一种在噪声点云上有效进行3D人脸识别的方法。&lt;h4&gt;方法&lt;/h4&gt;设计了一种条件生成对抗网络（cGAN-TOP）来去除点云中的噪声并恢复潜在特征，然后采用链接动态图卷积神经网络（LDGCNN）从处理后的点云中识别人脸。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在Bosphorus数据集上进行了验证，在所有噪声设置下都显著提高了识别准确率，最大增益为14.81%。&lt;h4&gt;结论&lt;/h4&gt;该方法在噪声点云上进行3D人脸识别时具有显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Face recognition using 3D point clouds is gaining growing interest, while rawpoint clouds often contain a significant amount of noise due to imperfectsensors. In this paper, an end-to-end 3D face recognition on a noisy pointcloud is proposed, which synergistically integrates the denoising andrecognition modules. Specifically, a Conditional Generative Adversarial Networkon Three Orthogonal Planes (cGAN-TOP) is designed to effectively remove thenoise in the point cloud, and recover the underlying features for subsequentrecognition. A Linked Dynamic Graph Convolutional Neural Network (LDGCNN) isthen adapted to recognize faces from the processed point cloud, whichhierarchically links both the local point features and neighboring features ofmultiple scales. The proposed method is validated on the Bosphorus dataset. Itsignificantly improves the recognition accuracy under all noise settings, witha maximum gain of 14.81%.</description>
      <author>example@mail.com (Junyu Liu, Jianfeng Ren, Sunhong Liang, Xudong Jiang)</author>
      <guid isPermaLink="false">2506.06864v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>How Important are Videos for Training Video LLMs?</title>
      <link>http://arxiv.org/abs/2506.06928v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page on  https://visualcomputinginstitute.github.io/videollm-pseudovideo-training/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视频大型语言模型（Video LLMs），发现经过图像训练的Video LLMs在时间推理能力上优于预期，而视频特定训练带来的改进很小。&lt;h4&gt;背景&lt;/h4&gt;视频LLMs的研究进展迅速，模型和基准在短短几年内大量涌现，通常这些模型使用预训练的纯文本LLM初始化，并在图像和视频字幕数据集上进行微调。&lt;h4&gt;目的&lt;/h4&gt;探讨Video LLMs在时间推理方面的能力，以及视频特定训练的效率。&lt;h4&gt;方法&lt;/h4&gt;使用LongVU算法训练的LLMs进行图像训练，并在TVBench时间推理基准上进行测试。引入了一个简单的微调方案，涉及一系列标注图像和针对时间能力的问题。&lt;h4&gt;主要发现&lt;/h4&gt;图像训练的LLMs在时间推理基准TVBench上的表现显著高于随机水平，且微调方案的效果接近甚至超过视频训练的LLMs。&lt;h4&gt;结论&lt;/h4&gt;当前模型对视频中丰富的时序特征的利用不足，需要进一步研究图像训练LLMs进行时间推理的机制以及当前视频训练方案的瓶颈。&lt;h4&gt;翻译&lt;/h4&gt;Research into Video Large Language Models (LLMs) has progressed rapidly, with numerous models and benchmarks emerging in just a few years. Typically, these models are initialized with a pretrained text-only LLM and finetuned on both image- and video-caption datasets. In this paper, we present findings indicating that Video LLMs are more capable of temporal reasoning after image-only training than one would assume, and that improvements from video-specific training are surprisingly small. Specifically, we show that image-trained versions of two LLMs trained with the recent LongVU algorithm perform significantly above chance level on TVBench, a temporal reasoning benchmark. Additionally, we introduce a simple finetuning scheme involving sequences of annotated images and questions targeting temporal capabilities. This baseline results in temporal reasoning performance close to, and occasionally higher than, what is achieved by video-trained LLMs. This suggests suboptimal utilization of rich temporal features found in real video by current models. Our analysis motivates further research into the mechanisms that allow image-trained LLMs to perform temporal reasoning, as well as into the bottlenecks that render current video training schemes inefficient.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Research into Video Large Language Models (LLMs) has progressed rapidly, withnumerous models and benchmarks emerging in just a few years. Typically, thesemodels are initialized with a pretrained text-only LLM and finetuned on bothimage- and video-caption datasets. In this paper, we present findingsindicating that Video LLMs are more capable of temporal reasoning afterimage-only training than one would assume, and that improvements fromvideo-specific training are surprisingly small. Specifically, we show thatimage-trained versions of two LLMs trained with the recent LongVU algorithmperform significantly above chance level on TVBench, a temporal reasoningbenchmark. Additionally, we introduce a simple finetuning scheme involvingsequences of annotated images and questions targeting temporal capabilities.This baseline results in temporal reasoning performance close to, andoccasionally higher than, what is achieved by video-trained LLMs. This suggestssuboptimal utilization of rich temporal features found in real video by currentmodels. Our analysis motivates further research into the mechanisms that allowimage-trained LLMs to perform temporal reasoning, as well as into thebottlenecks that render current video training schemes inefficient.</description>
      <author>example@mail.com (George Lydakis, Alexander Hermans, Ali Athar, Daan de Geus, Bastian Leibe)</author>
      <guid isPermaLink="false">2506.06928v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Initial Model Incorporation for Deep Learning FWI: Pretraining or Denormalization?</title>
      <link>http://arxiv.org/abs/2506.05484v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将初始模型知识嵌入神经网络的方法对全波形反演的影响。&lt;h4&gt;背景&lt;/h4&gt;地下属性神经网络重参数化全波形反演是一种有效的无监督学习框架，能够稳定反演，即使起始模型不准确。&lt;h4&gt;目的&lt;/h4&gt;研究两种将初始模型知识嵌入神经网络的方法对神经网络重参数化全波形反演的影响。&lt;h4&gt;方法&lt;/h4&gt;一种是预训练，通过拟合初始速度模型来调节神经网络参数；另一种是去归一化，直接将网络输出添加到初始模型中。&lt;h4&gt;主要发现&lt;/h4&gt;预训练需要基于恒定速度值（均值）进行模型扰动反演，导致工作流程复杂，目标函数在两阶段过程中不一致，导致网络参数失去活性，降低塑性。&lt;h4&gt;结论&lt;/h4&gt;去归一化可以简化工作流程，加速收敛，与预训练相比，可以提高反演精度。&lt;h4&gt;翻译&lt;/h4&gt;Subsurface property neural network reparameterized full waveform inversion (FWI) has emerged as an effective unsupervised learning framework, which can invert stably with an inaccurate starting model. It updates the trainable neural network parameters instead of fine-tuning on the subsurface model directly. There are primarily two ways to embed the prior knowledge of the initial model into neural networks, that is, pretraining and denormalization. Pretraining first regulates the neural networks' parameters by fitting the initial velocity model; Denormalization directly adds the outputs of the network into the initial models without pretraining. In this letter, we systematically investigate the influence of the two ways of initial model incorporation for the neural network reparameterized FWI. We demonstrate that pretraining requires inverting the model perturbation based on a constant velocity value (mean) with a two-stage implementation. It leads to a complex workflow and inconsistency of objective functions in the two-stage process, causing the network parameters to become inactive and lose plasticity. Experimental results demonstrate that denormalization can simplify workflows, accelerate convergence, and enhance inversion accuracy compared with pretraining.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Subsurface property neural network reparameterized full waveform inversion(FWI) has emerged as an effective unsupervised learning framework, which caninvert stably with an inaccurate starting model. It updates the trainableneural network parameters instead of fine-tuning on the subsurface modeldirectly. There are primarily two ways to embed the prior knowledge of theinitial model into neural networks, that is, pretraining and denormalization.Pretraining first regulates the neural networks' parameters by fitting theinitial velocity model; Denormalization directly adds the outputs of thenetwork into the initial models without pretraining. In this letter, wesystematically investigate the influence of the two ways of initial modelincorporation for the neural network reparameterized FWI. We demonstrate thatpretraining requires inverting the model perturbation based on a constantvelocity value (mean) with a two-stage implementation. It leads to a complexworkflow and inconsistency of objective functions in the two-stage process,causing the network parameters to become inactive and lose plasticity.Experimental results demonstrate that denormalization can simplify workflows,accelerate convergence, and enhance inversion accuracy compared withpretraining.</description>
      <author>example@mail.com (Ruihua Chen, Bangyu Wu, Meng Li, Kai Yang)</author>
      <guid isPermaLink="false">2506.05484v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty Estimation on Graphs with Structure Informed Stochastic Partial Differential Equations</title>
      <link>http://arxiv.org/abs/2506.06907v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的不确定性估计方法，该方法能够处理分布偏移问题，并通过引入空间-时间噪声来增强不确定性估计。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在多种网络建模任务中取得了显著成果，但在处理分布偏移时，准确估计不确定性仍然是一个难题。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的消息传递方案，以解决图结构及其标签分布带来的随机性，从而提高不确定性估计的准确性。&lt;h4&gt;方法&lt;/h4&gt;借鉴了由Matern高斯过程驱动的随机偏微分方程（SPDE）的演化与GNN层中消息传递之间的类比，提出了一种新的消息传递方案。&lt;h4&gt;主要发现&lt;/h4&gt;该方法同时捕捉空间和时间上的不确定性，并允许显式控制协方差核的平滑度，从而在标签信息量低和高的情况下都能提高不确定性估计。&lt;h4&gt;结论&lt;/h4&gt;在具有不同标签信息量的图数据集上进行Out-of-Distribution（OOD）检测的广泛实验表明，该方法在现有方法中具有可靠性和优越性。&lt;h4&gt;翻译&lt;/h4&gt;Graph神经网络在多样化的网络建模任务中取得了令人印象深刻的成果，但在图上准确估计不确定性仍然很困难，尤其是在分布偏移的情况下。与传统的不确定性估计不同，基于图的不确定性必须考虑由图的结构及其标签分布产生的随机性，这增加了复杂性。在本文中，我们将由Matern高斯过程驱动的随机偏微分方程（SPDE）的演化与使用GNN层的消息传递之间的类比，提出了一种设计新消息传递方案的原则方法，该方案结合了由SPDE的高斯过程方法启发的空间-时间噪声。我们的方法同时捕捉空间和时间上的不确定性，并允许显式控制协方差核的平滑度，从而增强了在标签信息量低和高的情况下图上的不确定性估计。我们在具有不同标签信息量的图数据集上进行Out-of-Distribution（OOD）检测的广泛实验表明，我们的模型在现有方法中具有可靠性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks have achieved impressive results across diverse networkmodeling tasks, but accurately estimating uncertainty on graphs remainsdifficult, especially under distributional shifts. Unlike traditionaluncertainty estimation, graph-based uncertainty must account for randomnessarising from both the graph's structure and its label distribution, which addscomplexity. In this paper, making an analogy between the evolution of astochastic partial differential equation (SPDE) driven by Matern GaussianProcess and message passing using GNN layers, we present a principled way todesign a novel message passing scheme that incorporates spatial-temporal noisesmotivated by the Gaussian Process approach to SPDE. Our method simultaneouslycaptures uncertainty across space and time and allows explicit control over thecovariance kernel smoothness, thereby enhancing uncertainty estimates on graphswith both low and high label informativeness. Our extensive experiments onOut-of-Distribution (OOD) detection on graph datasets with varying labelinformativeness demonstrate the soundness and superiority of our model toexisting approaches.</description>
      <author>example@mail.com (Fred Xu, Thomas Markovich)</author>
      <guid isPermaLink="false">2506.06907v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Employing Discrete Fourier Transform in Representational Learning</title>
      <link>http://arxiv.org/abs/2506.06765v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过输入重建进行图像表示学习的新方法，使用离散傅里叶变换（DFT）作为学习目标，在CIFAR-10数据集上取得了52.8%的top-1准确率，优于传统的自编码器。&lt;h4&gt;背景&lt;/h4&gt;图像表示学习在机器学习中用于生成可被任意下游任务有效利用的表示，常用的方法是使用自编码器在网络的压缩点提取潜在表示。&lt;h4&gt;目的&lt;/h4&gt;提出一种替代的学习目标，即使用输入的离散傅里叶变换（DFT）作为重建目标。&lt;h4&gt;方法&lt;/h4&gt;使用DFT提供每个频率级别的有意义全局信息，使单个频率分量作为单独的学习目标。对于多维输入数据，DFT通过允许在特定维度上选择性变换，同时保留其他维度的计算，提供了显著的灵活性。此外，某些类型的输入在频率分布中表现出特定的模式，允许我们关注频率子集而不是整个频谱。&lt;h4&gt;主要发现&lt;/h4&gt;DFT作为学习目标适用于表示学习，使用DFT在CIFAR-10上达到了52.8%的top-1准确率，并优于传统的自编码器。仅在低频分量（具有最高幅度的分量）上进行训练，其结果与使用完整频谱相当，准确率仅略有下降。&lt;h4&gt;结论&lt;/h4&gt;DFT是一种有效的学习目标，可以用于图像表示学习，并且这种方法在CIFAR-10数据集上取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通过输入重建进行图像表示学习是机器学习中生成可被任意下游任务有效利用的表示的一种常见技术。一种已建立的方法是使用自编码器在网络压缩点提取潜在表示。这些表示很有价值，因为它们保留了从压缩的潜在空间重建原始输入所需的基本信息。在本文中，我们提出了一种替代的学习目标。我们不是使用原始输入作为重建目标，而是使用输入的离散傅里叶变换（DFT）。DFT在每个频率级别上提供了有意义的全局信息，使单个频率分量作为单独的学习目标变得有用。处理多维输入数据时，DFT通过允许在特定维度上选择性变换，同时保留其他维度的计算，提供了显著的灵活性。此外，某些类型的输入在其频率分布中表现出特定的模式，其中特定的频率分量始终包含大部分幅度，允许我们关注频率的子集而不是整个频谱。这些特性使DFT成为表示学习的一种可行学习目标，我们通过在CIFAR-10上实现52.8%的top-1准确率并优于相同架构配置下的传统自编码器12.8个百分点来验证我们的方法。此外，我们还证明，仅在低频分量（具有最高幅度的分量）上进行训练，其结果与使用完整频谱相当，准确率仅略有下降。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image Representation learning via input reconstruction is a common techniquein machine learning for generating representations that can be effectivelyutilized by arbitrary downstream tasks. A well-established approach is usingautoencoders to extract latent representations at the network's compressionpoint. These representations are valuable because they retain essentialinformation necessary for reconstructing the original input from the compressedlatent space. In this paper, we propose an alternative learning objective.Instead of using the raw input as the reconstruction target, we employ theDiscrete Fourier Transform (DFT) of the input. The DFT provides meaningfulglobal information at each frequency level, making individual frequencycomponents useful as separate learning targets. When dealing withmultidimensional input data, the DFT offers remarkable flexibility by enablingselective transformation across specific dimensions while preserving others inthe computation. Moreover, certain types of input exhibit distinct patterns intheir frequency distributions, where specific frequency components consistentlycontain most of the magnitude, allowing us to focus on a subset of frequenciesrather than the entire spectrum. These characteristics position the DFT as aviable learning objective for representation learning and we validate ourapproach by achieving 52.8% top-1 accuracy on CIFAR-10 with ResNet-50 andoutperforming the traditional autoencoder by 12.8 points under identicalarchitectural configurations. Additionally, we demonstrate that training ononly the lower-frequency components - those with the highest magnitudes yieldsresults comparable to using the full frequency spectrum, with only minimalreductions in accuracy.</description>
      <author>example@mail.com (Raoof HojatJalali, Edmondo Trentin)</author>
      <guid isPermaLink="false">2506.06765v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Towards Terrain-Aware Task-Driven 3D Scene Graph Generation in Outdoor Environments</title>
      <link>http://arxiv.org/abs/2506.06562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 2025 IEEE ICRA Workshop on Field Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了三维场景图（3DSGs）在室外环境中的应用，提出了一种生成适用于大型室外场景的任务无关度量-语义点云的方法，并对现有的室内3DSG生成技术进行了修改以适应室外环境。&lt;h4&gt;背景&lt;/h4&gt;传统的三维场景表示方法如点云和占用网格提供了详细的几何信息，但缺乏结构化和语义组织，不足以支持高级推理。&lt;h4&gt;目的&lt;/h4&gt;研究3DSGs在室外环境中的构建和实用性，并展示其在实际机器人应用中的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种生成适用于大型室外场景的任务无关度量-语义点云的方法，并对室内3DSG生成技术进行了修改。&lt;h4&gt;主要发现&lt;/h4&gt;初步的定性结果表明室外3DSGs的可行性和在现实世界机器人应用中的潜在价值。&lt;h4&gt;结论&lt;/h4&gt;室外3DSGs在提高机器人对环境的结构化推理和决策能力方面具有巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-level autonomous operations depend on a robot's ability to construct asufficiently expressive model of its environment. Traditional three-dimensional(3D) scene representations, such as point clouds and occupancy grids, providedetailed geometric information but lack the structured, semantic organizationneeded for high-level reasoning. 3D scene graphs (3DSGs) address thislimitation by integrating geometric, topological, and semantic relationshipsinto a multi-level graph-based representation. By capturing hierarchicalabstractions of objects and spatial layouts, 3DSGs enable robots to reasonabout environments in a structured manner, improving context-awaredecision-making and adaptive planning. Although most recent work has focused onindoor 3DSGs, this paper investigates their construction and utility in outdoorenvironments. We present a method for generating a task-agnosticmetric-semantic point cloud for large outdoor settings and proposemodifications to existing indoor 3DSG generation techniques for outdoorapplicability. Our preliminary qualitative results demonstrate the feasibilityof outdoor 3DSGs and highlight their potential for future deployment inreal-world field robotic applications.</description>
      <author>example@mail.com (Chad R Samuelson, Timothy W McLain, Joshua G Mangelson)</author>
      <guid isPermaLink="false">2506.06562v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>A Study on the Fine-Tuning Performance of Universal Machine-Learned Interatomic Potentials (U-MLIPs)</title>
      <link>http://arxiv.org/abs/2506.07401v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于MACE的两种基础模型MACE-MP-0及其变体MACE-MP-0b的微调，发现微调可以提高模型在特定任务上的准确性，并且在某些情况下优于从头开始训练的模型。&lt;h4&gt;背景&lt;/h4&gt;U-MLIPs在多样化的原子系统中表现出有效性，但通常需要针对特定任务进行微调以提高准确性。&lt;h4&gt;目的&lt;/h4&gt;探究MACE-MP-0和MACE-MP-0b的微调效果，并识别关键见解。&lt;h4&gt;方法&lt;/h4&gt;在特定任务的数据集上进行微调，并通过过滤或主动学习优化数据集选择。&lt;h4&gt;主要发现&lt;/h4&gt;微调能够提高准确性，并且由于基础模型提供的强大初始预测，微调模型能够更快地收敛。微调的成功也依赖于仔细的数据集选择。&lt;h4&gt;结论&lt;/h4&gt;通过微调可以提升模型在原子模拟中的性能，并且提出了实现更好的微调基础模型的实际策略，探讨了未来发展和应用的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通用的机器学习原子间势能（U-MLIPs）在不同原子系统中证明了其有效性，但通常需要针对特定任务进行微调以提升准确性。我们研究了基于MACE的两种基础模型MACE-MP-0及其变体MACE-MP-0b的微调，并得出了关键见解。针对特定任务的数据集进行微调可以提高准确性，在某些情况下甚至优于从头开始训练的模型。此外，由于基础模型提供的强大初始预测，微调模型能够实现更快的收敛。微调的成功也依赖于数据集选择的精心，这可以通过过滤或主动学习来优化。我们进一步讨论了在原子模拟中实现更好微调基础模型的实际策略，并探索了其发展和应用的未来方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Universal machine-learned interatomic potentials (U-MLIPs) have demonstratedeffectiveness across diverse atomistic systems but often require fine-tuningfor task-specific accuracy. We investigate the fine-tuning of two MACE-basedfoundation models, MACE-MP-0 and its variant MACE-MP-0b, and identify keyinsights. Fine-tuning on task-specific datasets enhances accuracy and, in somecases, outperforms models trained from scratch. Additionally, fine-tuned modelsbenefit from faster convergence due to the strong initial predictions providedby the foundation model. The success of fine-tuning also depends on carefuldataset selection, which can be optimized through filtering or active learning.We further discuss practical strategies for achieving better fine-tuningfoundation models in atomistic simulations and explore future directions fortheir development and applications.</description>
      <author>example@mail.com (Xiaoqing Liu, Kehan Zeng, Yangshuai Wang, Teng Zhao)</author>
      <guid isPermaLink="false">2506.07401v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>GazeNLQ @ Ego4D Natural Language Queries Challenge 2025</title>
      <link>http://arxiv.org/abs/2506.05782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GazeNLQ的解决方案，用于解决CVPR 2025的Ego4D自然语言查询（NLQ）挑战，通过利用注视信息来检索与给定自然语言查询相匹配的视频片段。&lt;h4&gt;背景&lt;/h4&gt;以自拍摄像头捕捉的场景为背景，注视作为非言语交流的关键线索，反映了视觉注意力和人类意图与认知。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用注视信息来检索视频片段的新方法，以匹配自然语言查询。&lt;h4&gt;方法&lt;/h4&gt;引入了一种基于对比学习的预训练策略，用于直接从视频中估计注视，并将估计的注视用于增强模型中的视频表示，从而提高定位精度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，GazeNLQ在R1@IoU0.3和R1@IoU0.5的指标上分别达到了27.82和18.68。&lt;h4&gt;结论&lt;/h4&gt;GazeNLQ是一种有效的视频检索方法，可以显著提高自然语言查询的准确性。&lt;h4&gt;翻译&lt;/h4&gt;本报告介绍了我们在CVPR 2025 Ego4D自然语言查询（NLQ）挑战中的解决方案。以佩戴者视角捕捉的场景为背景，注视作为关键的非言语交流线索，反映了视觉注意力和人类意图与认知。受此启发，我们提出了一种新的方法，称为GazeNLQ，该方法利用注视信息检索与给定自然语言查询匹配的视频片段。具体而言，我们引入了一种基于对比学习的预训练策略，用于直接从视频中估计注视。估计的注视用于增强模型中的视频表示，从而提高定位精度。实验结果表明，GazeNLQ在R1@IoU0.3和R1@IoU0.5的指标上分别达到了27.82和18.68。我们的代码可在https://github.com/stevenlin510/GazeNLQ上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This report presents our solution to the Ego4D Natural Language Queries (NLQ)Challenge at CVPR 2025. Egocentric video captures the scene from the wearer'sperspective, where gaze serves as a key non-verbal communication cue thatreflects visual attention and offer insights into human intention andcognition. Motivated by this, we propose a novel approach, GazeNLQ, whichleverages gaze to retrieve video segments that match given natural languagequeries. Specifically, we introduce a contrastive learning-based pretrainingstrategy for gaze estimation directly from video. The estimated gaze is used toaugment video representations within proposed model, thereby enhancinglocalization accuracy. Experimental results show that GazeNLQ achievesR1@IoU0.3 and R1@IoU0.5 scores of 27.82 and 18.68, respectively. Our code isavailable at https://github.com/stevenlin510/GazeNLQ.</description>
      <author>example@mail.com (Wei-Cheng Lin, Chih-Ming Lien, Chen Lo, Chia-Hung Yeh)</author>
      <guid isPermaLink="false">2506.05782v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>FuncGNN: Learning Functional Semantics of Logic Circuits with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.06787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FuncGNN的方法，用于解决集成电路规模增长和设计复杂性提升带来的AIGs结构异质性和全局逻辑信息损失问题，提高了逻辑电路表示的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;随着集成电路规模的扩大和设计复杂性的增加，有效的电路表示对于逻辑综合、形式验证和其他电子设计自动化流程至关重要。AIGs作为一种紧凑和规范的结构，被广泛应用于布尔逻辑的表示。&lt;h4&gt;目的&lt;/h4&gt;为了解决AIGs中结构异质性和全局逻辑信息损失的问题，提高电路模型的准确性。&lt;h4&gt;方法&lt;/h4&gt;FuncGNN通过集成混合特征聚合来提取多粒度拓扑模式，以减轻结构异质性并增强逻辑电路表示。此外，FuncGNN引入了门感知归一化，以适应电路特定的门分布，提高对结构异质性的鲁棒性。最后，FuncGNN采用多层集成来合并跨层的中间特征，有效地综合局部和全局语义信息，以实现全面的逻辑表示。&lt;h4&gt;主要发现&lt;/h4&gt;在两个逻辑级分析任务（即信号概率预测和真值表距离预测）上，FuncGNN的表现优于现有的最先进方法，分别提高了2.06%和18.71%，同时将训练时间减少了约50.6%，GPU内存使用量减少了约32.8%。&lt;h4&gt;结论&lt;/h4&gt;FuncGNN能够有效提高逻辑电路表示的准确性，并显著减少训练时间和GPU内存使用量，是一种具有潜力的电子设计自动化工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As integrated circuit scale grows and design complexity rises, effectivecircuit representation helps support logic synthesis, formal verification, andother automated processes in electronic design automation. And-Inverter Graphs(AIGs), as a compact and canonical structure, are widely adopted forrepresenting Boolean logic in these workflows. However, the increasingcomplexity and integration density of modern circuits introduce structuralheterogeneity and global logic information loss in AIGs, posing significantchallenges to accurate circuit modeling. To address these issues, we proposeFuncGNN, which integrates hybrid feature aggregation to extractmulti-granularity topological patterns, thereby mitigating structuralheterogeneity and enhancing logic circuit representations. FuncGNN furtherintroduces gate-aware normalization that adapts to circuit-specific gatedistributions, improving robustness to structural heterogeneity. Finally,FuncGNN employs multi-layer integration to merge intermediate features acrosslayers, effectively synthesizing local and global semantic information forcomprehensive logic representations. Experimental results on two logic-levelanalysis tasks (i.e., signal probability prediction and truth-table distanceprediction) demonstrate that FuncGNN outperforms existing state-of-the-artmethods, achieving improvements of 2.06% and 18.71%, respectively, whilereducing training time by approximately 50.6% and GPU memory usage by about32.8%.</description>
      <author>example@mail.com (Qiyun Zhao)</author>
      <guid isPermaLink="false">2506.06787v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>DINO-CoDT: Multi-class Collaborative Detection and Tracking with Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2506.07375v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对多样化道路用户的多类协同检测和跟踪框架，以增强环境理解。&lt;h4&gt;背景&lt;/h4&gt;协同感知在扩展感知范围和增强对传感器故障的鲁棒性方面发挥着关键作用，主要涉及协同3D检测和跟踪任务。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有工作中主要关注车辆类别而缺乏多类协同检测和跟踪有效解决方案的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种包含全局空间注意力融合（GSAF）模块的检测器，用于增强多尺度特征学习；引入了一种基于视觉语义和视觉基础模型的tracklet RE-IDentification（REID）模块，以减少涉及小物体（如行人）的错误匹配；设计了基于速度的适应性tracklet管理（VATM）模块，动态调整跟踪间隔。&lt;h4&gt;主要发现&lt;/h4&gt;在V2X-Real和OPV2V数据集上的大量实验表明，该方法在检测和跟踪精度方面显著优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;该框架在多类协同检测和跟踪方面取得了显著成效，提高了实际场景中的应用能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：协作感知在增强环境理解方面发挥着关键作用，通过扩展感知范围和提高对传感器故障的鲁棒性，这主要涉及协同3D检测和跟踪任务。前者侧重于单个帧中的物体识别，而后者则捕捉随时间变化的连续实例tracklets。然而，现有工作在这两个领域主要关注车辆类别，缺乏有效的多类协同检测和跟踪解决方案。这种局限性阻碍了它们在实际场景中的应用，这些场景涉及具有不同外观和运动模式的各种物体类别。为了克服这些局限性，我们提出了一种针对多样化道路用户的多类协同检测和跟踪框架。我们首先提出了一种包含全局空间注意力融合（GSAF）模块的检测器，用于增强不同大小物体的多尺度特征学习。接下来，我们介绍了一种利用视觉语义和视觉基础模型的tracklet RE-IDentification（REID）模块，以有效减少涉及小物体（如行人）的错误匹配。我们进一步设计了一种基于速度的适应性tracklet管理（VATM）模块，根据物体运动动态调整跟踪间隔。在V2X-Real和OPV2V数据集上的大量实验表明，我们的方法在检测和跟踪精度方面显著优于现有最先进的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Collaborative perception plays a crucial role in enhancing environmentalunderstanding by expanding the perceptual range and improving robustnessagainst sensor failures, which primarily involves collaborative 3D detectionand tracking tasks. The former focuses on object recognition in individualframes, while the latter captures continuous instance tracklets over time.However, existing works in both areas predominantly focus on the vehiclesuperclass, lacking effective solutions for both multi-class collaborativedetection and tracking. This limitation hinders their applicability inreal-world scenarios, which involve diverse object classes with varyingappearances and motion patterns. To overcome these limitations, we propose amulti-class collaborative detection and tracking framework tailored for diverseroad users. We first present a detector with a global spatial attention fusion(GSAF) module, enhancing multi-scale feature learning for objects of varyingsizes. Next, we introduce a tracklet RE-IDentification (REID) module thatleverages visual semantics with a vision foundation model to effectively reduceID SWitch (IDSW) errors, in cases of erroneous mismatches involving smallobjects like pedestrians. We further design a velocity-based adaptive trackletmanagement (VATM) module that adjusts the tracking interval dynamically basedon object motion. Extensive experiments on the V2X-Real and OPV2V datasets showthat our approach significantly outperforms existing state-of-the-art methodsin both detection and tracking accuracy.</description>
      <author>example@mail.com (Xunjie He, Christina Dao Wen Lee, Meiling Wang, Chengran Yuan, Zefan Huang, Yufeng Yue, Marcelo H. Ang Jr)</author>
      <guid isPermaLink="false">2506.07375v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>AANet: Virtual Screening under Structural Uncertainty via Alignment and Aggregation</title>
      <link>http://arxiv.org/abs/2506.05768v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种适用于结构不确定性的虚拟筛选方法，通过对比学习和跨注意力机制，提高了在缺乏口袋信息的apo结构上的虚拟筛选准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的虚拟筛选方法大多基于已知配体结合口袋的全蛋白结构，在缺乏口袋信息的apo结构或AlphaFold2预测结构上表现不佳。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够在结构不确定性的情况下进行准确虚拟筛选的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种包含两个核心组件的方法：(1) 三模态对比学习模块，用于对配体、全蛋白口袋和从结构中检测到的腔体进行表示对齐，增强对口袋定位错误的鲁棒性；(2) 基于跨注意力的适配器，用于动态聚合候选结合位点，使模型能够在没有精确口袋注释的情况下从活性数据中学习。&lt;h4&gt;主要发现&lt;/h4&gt;在apo结构的新颖基准测试中，该方法在盲apo设置下显著优于现有方法，将早期富集因子（EF1%）从11.75提高到37.19。同时，该方法在holo结构上也保持了强大的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在推进一类新药发现方面具有潜力，尤其是在缺乏实验解决的蛋白-配体复合物的情况下。&lt;h4&gt;翻译&lt;/h4&gt;摘要：虚拟筛选（VS）是现代药物发现的关键组成部分，然而，大多数现有方法——无论是基于物理的还是基于深度学习的——都是围绕已知配体结合口袋的全蛋白结构开发的。因此，它们在apo或AlphaFold2等预测结构上的性能显著下降，这些结构更符合现实世界的早期药物发现，其中口袋信息通常缺失。在本文中，我们介绍了一种对齐和聚合框架，以实现结构不确定性下的准确虚拟筛选。我们的方法包含两个核心组件：(1) 三模态对比学习模块，用于对配体、全蛋白口袋和从结构中检测到的腔体进行表示对齐，从而增强对口袋定位错误的鲁棒性；(2) 基于跨注意力的适配器，用于动态聚合候选结合位点，使模型能够在没有精确口袋注释的情况下从活性数据中学习。我们在apo结构的新颖基准测试中评估了我们的方法，在盲apo设置下，它显著优于现有方法，将早期富集因子（EF1%）从11.75提高到37.19。值得注意的是，它也在holo结构上保持了强大的性能。这些结果证明了我们的方法在推进一类新药发现方面的潜力，尤其是在缺乏实验解决的蛋白-配体复合物的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Virtual screening (VS) is a critical component of modern drug discovery, yetmost existing methods--whether physics-based or deep learning-based--aredeveloped around holo protein structures with known ligand-bound pockets.Consequently, their performance degrades significantly on apo or predictedstructures such as those from AlphaFold2, which are more representative ofreal-world early-stage drug discovery, where pocket information is oftenmissing. In this paper, we introduce an alignment-and-aggregation framework toenable accurate virtual screening under structural uncertainty. Our methodcomprises two core components: (1) a tri-modal contrastive learning module thataligns representations of the ligand, the holo pocket, and cavities detectedfrom structures, thereby enhancing robustness to pocket localization error; and(2) a cross-attention based adapter for dynamically aggregating candidatebinding sites, enabling the model to learn from activity data even withoutprecise pocket annotations. We evaluated our method on a newly curatedbenchmark of apo structures, where it significantly outperformsstate-of-the-art methods in blind apo setting, improving the early enrichmentfactor (EF1%) from 11.75 to 37.19. Notably, it also maintains strongperformance on holo structures. These results demonstrate the promise of ourapproach in advancing first-in-class drug discovery, particularly in scenarioslacking experimentally resolved protein-ligand complexes.</description>
      <author>example@mail.com (Wenyu Zhu, Jianhui Wang, Bowen Gao, Yinjun Jia, Haichuan Tan, Ya-Qin Zhang, Wei-Ying Ma, Yanyan Lan)</author>
      <guid isPermaLink="false">2506.05768v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Paged Attention Meets FlexAttention: Unlocking Long-Context Efficiency in Deployed Inference</title>
      <link>http://arxiv.org/abs/2506.07311v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的PagedAttention与PyTorch的FlexAttention集成方法，以解决LLMs在长上下文推理中的内存效率问题，并在IBM的FMS中实现了融合的注意力内核，显著降低了推理延迟。&lt;h4&gt;背景&lt;/h4&gt;LLMs在长上下文推理过程中由于传统的键值缓存处理方式而面临严重的内存效率问题。&lt;h4&gt;目的&lt;/h4&gt;提高LLMs在长上下文推理中的内存效率。&lt;h4&gt;方法&lt;/h4&gt;通过引入PagedAttention与PyTorch的FlexAttention的集成，优化了内部碎片化和与单一键值缓存分配相关的效率问题。&lt;h4&gt;主要发现&lt;/h4&gt;在NVIDIA L4 GPU（24GB）上进行的基准测试表明，使用全局键值缓存时，推理延迟显著降低，与序列长度从128到2048个标记的增长呈线性关系（约2倍），而未使用缓存时，延迟呈指数增长。尽管单步评估的峰值内存使用量基本保持不变（主要由模型权重和激活项决定），但分页注意力引起的增量内存使用量最小，仅在序列长度超过2048个标记时才可观察到，这是由于其2的幂次缓存分配。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法对未来的长上下文模型部署具有重要意义，并且已经开源了完整的实现。&lt;h4&gt;翻译&lt;/h4&gt;Large Language Models (LLMs) encounter severe memory inefficiencies during long-context inference due to conventional handling of key-value (KV) caches. In this work, we introduce a novel integration of PagedAttention with PyTorch's FlexAttention, addressing internal fragmentation and inefficiencies associated with monolithic KV cache allocations. Implemented within IBM's Foundation ModelStack (FMS), our fused attention kernel efficiently gathers scattered KV data. Our benchmarks on an NVIDIA L4 GPU (24GB) demonstrate significantly reduced inference latency, growing only linearly (~2x) with sequence length from 128 to 2048 tokens when utilizing a global KV cache, compared to exponential latency increases without caching. While peak memory usage remains largely unchanged for single-step evaluations (dominated by model weights and activations), paged attention causes minimal incremental memory usage, observable only at sequence lengths exceeding 2048 tokens due to its power-of-two cache allocations. We open-source the full implementation and discuss its implications for future long-context model deployment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) encounter severe memory inefficiencies duringlong-context inference due to conventional handling of key-value (KV) caches.In this work, we introduce a novel integration of PagedAttention with PyTorch'sFlexAttention, addressing internal fragmentation and inefficiencies associatedwith monolithic KV cache allocations. Implemented within IBM's Foundation ModelStack (FMS), our fused attention kernel efficiently gathers scattered KV data.Our benchmarks on an NVIDIA L4 GPU (24GB) demonstrate significantly reducedinference latency, growing only linearly (~2x) with sequence length from 128 to2048 tokens when utilizing a global KV cache, compared to exponential latencyincreases without caching. While peak memory usage remains largely unchangedfor single-step evaluations (dominated by model weights and activations), pagedattention causes minimal incremental memory usage, observable only at sequencelengths exceeding 2048 tokens due to its power-of-two cache allocations. Weopen-source the full implementation and discuss its implications for futurelong-context model deployment.</description>
      <author>example@mail.com (Thomas Joshi, Herman Saini, Neil Dhillon, Antoni Viros i Martin, Kaoutar El Maghraoui)</author>
      <guid isPermaLink="false">2506.07311v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>When Better Features Mean Greater Risks: The Performance-Privacy Trade-Off in Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.05743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted In ACM ASIA Conference on Computer and Communications  Security (ASIA CCS '25), August 25-29, 2025, Ha Noi, Vietnam. For Code, see  https://github.com/SeroneySun/LpLA_code&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了针对编码器模型的成员推理攻击（MIAs）带来的隐私威胁，特别是聚焦于对比学习框架，并提出了一种基于特征向量p-norm的成员推理攻击方法LpLA，旨在揭示模型架构复杂性与隐私泄露风险之间的关系，并提升隐私保护。&lt;h4&gt;背景&lt;/h4&gt;随着深度学习技术的快速发展，预训练编码器模型在特征提取方面表现出色，但在广泛应用中引发了对训练数据隐私泄露风险的担忧。&lt;h4&gt;目的&lt;/h4&gt;系统地调查针对编码器模型的成员推理攻击带来的隐私威胁，并提出一种新的攻击方法。&lt;h4&gt;方法&lt;/h4&gt;通过实验分析模型架构复杂性与隐私泄露风险之间的关系，提出基于特征向量p-norm的LpLA方法，并通过多个数据集和模型架构进行实验验证。&lt;h4&gt;主要发现&lt;/h4&gt;发现更先进的编码器框架在提高特征提取性能的同时，也加剧了隐私泄露风险。LpLA在攻击性能和鲁棒性方面优于现有方法，尤其在有限的攻击知识和查询量下表现突出。&lt;h4&gt;结论&lt;/h4&gt;本研究不仅揭示了对比学习框架中隐私泄露的潜在风险，还为编码器模型的隐私保护研究提供了实践基础，并强调了在模型效用和训练数据隐私之间的平衡重要性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着深度学习技术的快速发展，预训练编码器模型在特征提取方面表现出色，在深度学习的研究和应用中发挥着关键作用。然而，它们的广泛应用引发了关于训练数据隐私泄露风险的重大担忧。本文系统地研究了针对编码器模型的成员推理攻击（MIAs）带来的隐私威胁，重点关注对比学习框架。通过实验分析，我们揭示了模型架构复杂性对成员隐私泄露的显著影响：随着更先进的编码器框架提高特征提取性能，它们同时加剧了隐私泄露风险。此外，本文提出了一种基于特征向量p-norm的新颖成员推理攻击方法，称为嵌入Lp-Norm似然攻击（LpLA）。这种方法通过利用特征向量p-norm的统计分布特性来推断成员状态。多个数据集和模型架构的实验结果表明，LpLA在攻击性能和鲁棒性方面优于现有方法，尤其是在有限的攻击知识和查询量下。本研究不仅揭示了对比学习框架中隐私泄露的潜在风险，还为编码器模型的隐私保护研究提供了实践基础。我们希望这项工作将引起对与自监督学习模型相关的隐私风险的更多关注，并阐明在模型效用和训练数据隐私之间平衡的重要性。我们的代码在https://github.com/SeroneySun/LpLA_code上公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3708821.3733915&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid advancement of deep learning technology, pre-trained encodermodels have demonstrated exceptional feature extraction capabilities, playing apivotal role in the research and application of deep learning. However, theirwidespread use has raised significant concerns about the risk of training dataprivacy leakage. This paper systematically investigates the privacy threatsposed by membership inference attacks (MIAs) targeting encoder models, focusingon contrastive learning frameworks. Through experimental analysis, we revealthe significant impact of model architecture complexity on membership privacyleakage: As more advanced encoder frameworks improve feature-extractionperformance, they simultaneously exacerbate privacy-leakage risks. Furthermore,this paper proposes a novel membership inference attack method based on thep-norm of feature vectors, termed the Embedding Lp-Norm Likelihood Attack(LpLA). This method infers membership status, by leveraging the statisticaldistribution characteristics of the p-norm of feature vectors. Experimentalresults across multiple datasets and model architectures demonstrate that LpLAoutperforms existing methods in attack performance and robustness, particularlyunder limited attack knowledge and query volumes. This study not only uncoversthe potential risks of privacy leakage in contrastive learning frameworks, butalso provides a practical basis for privacy protection research in encodermodels. We hope that this work will draw greater attention to the privacy risksassociated with self-supervised learning models and shed light on theimportance of a balance between model utility and training data privacy. Ourcode is publicly available at: https://github.com/SeroneySun/LpLA_code.</description>
      <author>example@mail.com (Ruining Sun, Hongsheng Hu, Wei Luo, Zhaoxi Zhang, Yanjun Zhang, Haizhuan Yuan, Leo Yu Zhang)</author>
      <guid isPermaLink="false">2506.05743v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Estimation of the curvature from random samples</title>
      <link>http://arxiv.org/abs/2506.06779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过从曲线或曲面上采样得到的有限样本点来估计曲线和曲面曲率的估计器。&lt;h4&gt;背景&lt;/h4&gt;研究者们需要一种方法来估计曲线和曲面的曲率。&lt;h4&gt;目的&lt;/h4&gt;开发一种算法来估计曲线和曲面在特定点的曲率，并将其扩展到估计曲面的高斯曲率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种算法来估计曲线曲率，并将其扩展以估计曲面高斯曲率。该算法利用点云中选定点数与给定点具有足够邻近点的概率之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;算法能够通过控制点云中点的数量来估计曲率。&lt;h4&gt;结论&lt;/h4&gt;该方法为曲率估计提供了一种新的工具，可以应用于曲线和曲面的几何分析。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种通过使用从具有曲线或曲面支撑的概率分布中抽取的有限样本点来估计曲线和曲面曲率的估计器。首先，我们给出了一种估计曲线给定点的曲率的算法。然后，我们将它扩展到估计曲面的高斯曲率。在所提出的算法中，我们使用了点云中选定点数与给定点具有足够邻近点的概率之间的关系。这种关系使我们能够控制点云中所需点的数量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce an estimator for the curvature of curves and surfaces by usingfinite sample points drawn from sampling a probability distribution that hassupport on the curve or surface. First we give an algorithm for estimation ofthe curvature in a given point of a curve. Then, we extend it to estimate theGaussian curvature of the surfaces. In the proposed algorithms, we use arelation between the number of selected points in the point cloud and theprobability that a given point has a suffcient number of nearby points. Thisrelation allows us to control the required number of points in the point cloud.</description>
      <author>example@mail.com (R. Mirzaie)</author>
      <guid isPermaLink="false">2506.06779v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Harnessing Vision-Language Models for Time Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2506.06836v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉语言模型（VLM）的时间序列异常检测（TSAD）方法，旨在提高异常检测的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;时间序列异常检测在医疗、金融和工业监测等领域发挥着重要作用。传统方法主要关注在数值数据上训练特定领域的模型，但缺乏人类专家在识别情境异常方面的视觉-时间推理能力。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文探索了一种基于视觉语言模型（VLM）的解决方案，以增强异常检测的能力。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种两阶段解决方案：(1) ViT4TS，基于轻量级预训练视觉编码器构建的视觉筛选阶段，利用二维时间序列表示来准确定位候选异常；(2) VLM4TS，基于VLM的阶段，整合全局时间上下文和VLM推理能力，对ViT4TS提供的候选异常进行细化检测。&lt;h4&gt;主要发现&lt;/h4&gt;VLM4TS在大多数情况下，无需时间序列训练，在准确性和效率上都优于时间序列预训练和从头开始的基线，F1-max分数提高了24.6%。此外，VLM4TS在token使用效率上也优于现有的基于语言模型的TSAD方法，平均效率提高了36倍。&lt;h4&gt;结论&lt;/h4&gt;VLM4TS是一种有效且高效的时间序列异常检测方法，为该领域的研究提供了新的思路和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time-series anomaly detection (TSAD) has played a vital role in a variety offields, including healthcare, finance, and industrial monitoring. Priormethods, which mainly focus on training domain-specific models on numericaldata, lack the visual-temporal reasoning capacity that human experts have toidentify contextual anomalies. To fill this gap, we explore a solution based onvision language models (VLMs). Recent studies have shown the ability of VLMsfor visual reasoning tasks, yet their direct application to time series hasfallen short on both accuracy and efficiency. To harness the power of VLMs forTSAD, we propose a two-stage solution, with (1) ViT4TS, a vision-screeningstage built on a relatively lightweight pretrained vision encoder, whichleverages 2-D time-series representations to accurately localize candidateanomalies; (2) VLM4TS, a VLM-based stage that integrates global temporalcontext and VLM reasoning capacity to refine the detection upon the candidatesprovided by ViT4TS. We show that without any time-series training, VLM4TSoutperforms time-series pretrained and from-scratch baselines in most cases,yielding a 24.6 percent improvement in F1-max score over the best baseline.Moreover, VLM4TS also consistently outperforms existing language-model-basedTSAD methods and is on average 36 times more efficient in token usage.</description>
      <author>example@mail.com (Zelin He, Sarah Alnegheimish, Matthew Reimherr)</author>
      <guid isPermaLink="false">2506.06836v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>From Generation to Generalization: Emergent Few-Shot Learning in Video Diffusion Models</title>
      <link>http://arxiv.org/abs/2506.07280v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 23 figures, 9 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;视频扩散模型（VDMs）作为强大的生成工具，能够合成高质量的时空内容，其潜力远不止视频生成。VDMs的训练动态，由建模连贯序列的需求驱动，自然促使它们内化结构化的表示和视觉世界的隐含理解。&lt;h4&gt;背景&lt;/h4&gt;VDMs在视频生成领域取得了显著进展，但其潜在能力还未被完全挖掘。&lt;h4&gt;目的&lt;/h4&gt;为了探测VDMs内部知识范围，研究引入了一种小样本微调框架，利用少量示例重新部署VDMs以执行新任务。&lt;h4&gt;方法&lt;/h4&gt;该方法将每个任务转化为视觉过渡，使得模型可以在不改变冻结VDM生成界面的情况下，通过短输入输出序列训练LoRA权重。&lt;h4&gt;主要发现&lt;/h4&gt;尽管只有最小量的监督，该模型在多种任务上表现出强大的泛化能力，从低级视觉任务（如分割和姿态估计）到高级推理任务（如在ARC-AGI上）。&lt;h4&gt;结论&lt;/h4&gt;这些结果将VDMs重新定义为不仅仅是生成引擎，而是适应性视觉学习者，有潜力成为未来视觉领域基础模型的骨干。&lt;h4&gt;翻译&lt;/h4&gt;Video Diffusion Models (VDMs) have emerged as powerful generative tools, capable of synthesizing high-quality spatiotemporal content. Yet, their potential goes far beyond mere video generation. We argue that the training dynamics of VDMs, driven by the need to model coherent sequences, naturally pushes them to internalize structured representations and an implicit understanding of the visual world. To probe the extent of this internal knowledge, we introduce a few-shot fine-tuning framework that repurposes VDMs for new tasks using only a handful of examples. Our method transforms each task into a visual transition, enabling the training of LoRA weights on short input-output sequences without altering the generative interface of a frozen VDM. Despite minimal supervision, the model exhibits strong generalization across diverse tasks, from low-level vision (for example, segmentation and pose estimation) to high-level reasoning (for example, on ARC-AGI). These results reframe VDMs as more than generative engines. They are adaptable visual learners with the potential to serve as the backbone for future foundation models in vision.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Diffusion Models (VDMs) have emerged as powerful generative tools,capable of synthesizing high-quality spatiotemporal content. Yet, theirpotential goes far beyond mere video generation. We argue that the trainingdynamics of VDMs, driven by the need to model coherent sequences, naturallypushes them to internalize structured representations and an implicitunderstanding of the visual world. To probe the extent of this internalknowledge, we introduce a few-shot fine-tuning framework that repurposes VDMsfor new tasks using only a handful of examples. Our method transforms each taskinto a visual transition, enabling the training of LoRA weights on shortinput-output sequences without altering the generative interface of a frozenVDM. Despite minimal supervision, the model exhibits strong generalizationacross diverse tasks, from low-level vision (for example, segmentation and poseestimation) to high-level reasoning (for example, on ARC-AGI). These resultsreframe VDMs as more than generative engines. They are adaptable visuallearners with the potential to serve as the backbone for future foundationmodels in vision.</description>
      <author>example@mail.com (Pablo Acuaviva, Aram Davtyan, Mariam Hassan, Sebastian Stapf, Ahmad Rahimi, Alexandre Alahi, Paolo Favaro)</author>
      <guid isPermaLink="false">2506.07280v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>IQFM A Wireless Foundational Model for I/Q Streams in AI-Native 6G</title>
      <link>http://arxiv.org/abs/2506.06718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为IQFM的I/Q信号基础模型，用于无线通信，支持多种任务，如调制分类、到达角（AoA）、波束预测和射频指纹识别，无需复杂的预处理或手工特征。该模型在对比自监督学习（SSL）框架下，通过任务特定的增强策略，实现了高效的编码和分类，并在多个任务上取得了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;基础模型在自然语言处理和计算机视觉领域显示出巨大的潜力，但在无线通信领域仍处于起步阶段。目前，大多数研究集中在基于图像的模态上，如信道状态信息（CSI）和频率频谱，而直接在原始I/Q数据上操作的基础模型则很少被探索。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够在无线通信领域直接操作原始I/Q数据的基础模型，以支持多种无线通信任务。&lt;h4&gt;方法&lt;/h4&gt;提出IQFM模型，该模型通过任务特定的增强策略和对比自监督学习框架进行训练，并在实际数据上进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;IQFM模型在调制和到达角分类任务上分别达到了99.67%和65.45%的准确率，超过了监督基线模型。此外，该模型还能泛化到分布外的任务，使用少量样本和参数更新即可适应新任务。&lt;h4&gt;结论&lt;/h4&gt;原始I/Q数据基础模型在多任务学习方面具有巨大的潜力，可以作为高效、可重用的编码器，适用于AI原生的6G系统。&lt;h4&gt;翻译&lt;/h4&gt;Foundational models have shown remarkable potential in natural language processing and computer vision, yet remain in their infancy in wireless communications. While a few efforts have explored image-based modalities such as channel state information (CSI) and frequency spectrograms, foundational models that operate directly on raw IQ data remain largely unexplored. This paper presents, IQFM, the first I/Q signal foundational model for wireless communications. IQFM supporting diverse tasks: modulation classification, angle-of-arrival (AoA), beam prediction, and RF fingerprinting, without heavy preprocessing or handcrafted features. We also introduce a task-area augmentation strategy that categorizes transformations into core augmentations, such as cyclic time shifting, and task-specific augmentations. This strategy forms the basis for structured, task-dependent representation learning within a contrastive self-supervised learning (SSL) framework. Using this strategy, the lightweight encoder, pre-trained via SSL on over-the-air multi-antenna IQ data, achieves up to 99.67% and 65.45% accuracy on modulation and AoA classification, respectively, using only one labeled sample per class, outperforming supervised baselines by up to 7x and 145x. The model also generalizes to out-of-distribution tasks; when adapted to new tasks using only 500 samples per class and minimal parameter updates via LoRA, the same frozen encoder achieves 94.15% on beam prediction (vs. 89.53% supervised), 50.00% on RML2016a modulation classification (vs. 49.30%), and 96.05% on RF fingerprinting (vs. 96.64%). These results demonstrate the potential of raw IQ-based foundational models as efficient, reusable encoders for multi-task learning in AI-native 6G systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundational models have shown remarkable potential in natural languageprocessing and computer vision, yet remain in their infancy in wirelesscommunications. While a few efforts have explored image-based modalities suchas channel state information (CSI) and frequency spectrograms, foundationalmodels that operate directly on raw IQ data remain largely unexplored. Thispaper presents, IQFM, the first I/Q signal foundational model for wirelesscommunications. IQFM supporting diverse tasks: modulation classification,angle-of-arrival (AoA), beam prediction, and RF fingerprinting, without heavypreprocessing or handcrafted features. We also introduce a task-awareaugmentation strategy that categorizes transformations into core augmentations,such as cyclic time shifting, and task-specific augmentations. This strategyforms the basis for structured, task-dependent representation learning within acontrastive self-supervised learning (SSL) framework. Using this strategy, thelightweight encoder, pre-trained via SSL on over-the-air multi-antenna IQ data,achieves up to 99.67% and 65.45% accuracy on modulation and AoA classification,respectively, using only one labeled sample per class, outperforming supervisedbaselines by up to 7x and 145x. The model also generalizes toout-of-distribution tasks; when adapted to new tasks using only 500 samples perclass and minimal parameter updates via LoRA, the same frozen encoder achieves94.15% on beam prediction (vs. 89.53% supervised), 50.00% on RML2016amodulation classification (vs. 49.30%), and 96.05% on RF fingerprinting (vs.96.64%). These results demonstrate the potential of raw IQ-based foundationalmodels as efficient, reusable encoders for multi-task learning in AI-native 6Gsystems.</description>
      <author>example@mail.com (Omar Mashaal, Hatem Abou-Zeid)</author>
      <guid isPermaLink="false">2506.06718v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Situational Awareness in Underwater Robotics with Multi-modal Spatial Perception</title>
      <link>http://arxiv.org/abs/2506.06476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多模态传感的SLAM方法，用于提高水下自主和远程操作的能力。&lt;h4&gt;背景&lt;/h4&gt;水下环境中的光线衰减、散射和低对比度等问题常常导致基于视觉的SLAM方法失效，且这些方法通常依赖于单目或立体视觉输入，限制了其在多相机配置中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种融合来自多个传感器（包括相机、惯性测量单元和声学设备）的数据的方法，以增强情境感知并实现鲁棒的实时SLAM。&lt;h4&gt;方法&lt;/h4&gt;通过几何和基于学习的技术以及语义分析来探索解决方案，并在特隆赫姆峡湾的多个现场部署中收集的数据上进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在视觉挑战性的水下环境中，该方法可以实现实时可靠的状态估计和高质量的3D重建。&lt;h4&gt;结论&lt;/h4&gt;系统存在约束，并提出了需要进一步探索的研究问题，如传感器校准和基于学习方法的局限性，以推进大规模水下作业。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a multi-modal sensing-based SLAM method to enhance the capabilities of underwater autonomous and remote operations. The underwater environment often leads to the failure of vision-based SLAM methods due to issues such as light attenuation, scattering, and low contrast, and these methods typically rely on monocular or stereo vision inputs, limiting their application in multi-camera configurations. The proposed method fuses data from multiple sensors, including cameras, inertial measurement units (IMUs), and acoustic devices, to enhance situational awareness and enable robust, real-time SLAM. Solutions are explored using geometric and learning-based techniques along with semantic analysis, and experiments are conducted on data collected from a work-class ROV during several field deployments in the Trondheim Fjord. The experimental results demonstrate the feasibility of real-time reliable state estimation and high-quality 3D reconstructions in visually challenging underwater conditions. System constraints are discussed, and open research questions, such as sensor calibration and limitations with learning-based methods, are identified for further exploration to advance large-scale underwater operations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous Underwater Vehicles (AUVs) and Remotely Operated Vehicles (ROVs)demand robust spatial perception capabilities, including SimultaneousLocalization and Mapping (SLAM), to support both remote and autonomous tasks.Vision-based systems have been integral to these advancements, capturing richcolor and texture at low cost while enabling semantic scene understanding.However, underwater conditions -- such as light attenuation, backscatter, andlow contrast -- often degrade image quality to the point where traditionalvision-based SLAM pipelines fail. Moreover, these pipelines typically rely onmonocular or stereo inputs, limiting their scalability to the multi-cameraconfigurations common on many vehicles. To address these issues, we propose toleverage multi-modal sensing that fuses data from multiple sensors-includingcameras, inertial measurement units (IMUs), and acoustic devices-to enhancesituational awareness and enable robust, real-time SLAM. We explore bothgeometric and learning-based techniques along with semantic analysis, andconduct experiments on the data collected from a work-class ROV during severalfield deployments in the Trondheim Fjord. Through our experimental results, wedemonstrate the feasibility of real-time reliable state estimation andhigh-quality 3D reconstructions in visually challenging underwater conditions.We also discuss system constraints and identify open research questions, suchas sensor calibration, limitations with learning-based methods, that meritfurther exploration to advance large-scale underwater operations.</description>
      <author>example@mail.com (Pushyami Kaveti, Ambjorn Grimsrud Waldum, Hanumant Singh, Martin Ludvigsen)</author>
      <guid isPermaLink="false">2506.06476v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Promoting Ensemble Diversity with Interactive Bayesian Distributional Robustness for Fine-tuning Foundation Models</title>
      <link>http://arxiv.org/abs/2506.07247v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 (Poster)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Interactive Bayesian Distributional Robustness（IBDR）的新颖贝叶斯推理框架，通过增强粒子多样性来提高集成质量。&lt;h4&gt;背景&lt;/h4&gt;IBDR基于一个广义的理论框架，该框架将分布损失与近似的后验概率联系起来。&lt;h4&gt;目的&lt;/h4&gt;通过实现分布鲁棒性和粒子多样性来提升贝叶斯推理的效率。&lt;h4&gt;方法&lt;/h4&gt;采用了一种双重优化过程，在保证分布鲁棒性的同时促进粒子多样性。&lt;h4&gt;主要发现&lt;/h4&gt;使用VTAB-1K基准和常见推理语言任务评估IBDR的性能，结果显示IBDR优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;IBDR在现实世界应用中的有效性得到证实。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为交互式贝叶斯分布鲁棒性（IBDR）的贝叶斯推理新框架，该框架允许建模粒子之间的相互作用，从而通过增加粒子多样性来提高集成质量。IBDR建立在将分布损失与近似后验概率相联系的一般化理论框架之上，从而激发了一种实用的双重优化过程，该过程强制执行分布鲁棒性同时促进粒子多样性。我们使用VTAB-1K基准和常见推理语言任务将IBDR的性能与各种基线方法进行了比较。结果表明，IBDR在这些基线方法中表现优异，强调了其在现实世界应用中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Interactive Bayesian Distributional Robustness (IBDR), a novelBayesian inference framework that allows modeling the interactions betweenparticles, thereby enhancing ensemble quality through increased particlediversity. IBDR is grounded in a generalized theoretical framework thatconnects the distributional population loss with the approximate posterior,motivating a practical dual optimization procedure that enforces distributionalrobustness while fostering particle diversity. We evaluate IBDR's performanceagainst various baseline methods using the VTAB-1K benchmark and the commonreasoning language task. The results consistently show that IBDR outperformsthese baselines, underscoring its effectiveness in real-world applications.</description>
      <author>example@mail.com (Ngoc-Quan Pham, Tuan Truong, Quyen Tran, Tan Nguyen, Dinh Phung, Trung Le)</author>
      <guid isPermaLink="false">2506.07247v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Caterpillar GNN: Replacing Message Passing with Efficient Aggregation</title>
      <link>http://arxiv.org/abs/2506.06784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  40 pages, 9 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种高效聚合机制的消息传递图神经网络（MPGNNs），通过降低表达力来增强聚合能力，并成功应用于图级别任务。&lt;h4&gt;背景&lt;/h4&gt;现代图学习中的MPGNNs注重表达力的最大化，而本文提出了一个不同的方法。&lt;h4&gt;目的&lt;/h4&gt;通过降低表达力，增强MPGNNs的聚合能力，并提高其在图级别任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;引入了一种高效的聚合机制，该机制允许在经典的消息传递和基于着色或普通游走的方法之间无缝扩展。通过同态计数和广义毛毛虫图的层次结构来严格地描述每一步的表达能力，并基于此提出了毛毛虫GNN。&lt;h4&gt;主要发现&lt;/h4&gt;毛毛虫GNN通过其稳健的图级别聚合能力，在特定的合成图级别任务中成功应对了挑战，这些任务对传统的MPGNNs来说很难。此外，在真实世界的数据集上，毛毛虫GNN在保持预测性能的同时，显著减少了计算图中隐藏层中的节点数量。&lt;h4&gt;结论&lt;/h4&gt;毛毛虫GNN是一种有效的MPGNNs，它通过优化聚合机制在图级别任务中表现出色，并在真实世界数据集上实现了可观的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：消息传递图神经网络（MPGNNs）在现代图学习中占据主导地位，通常优先考虑最大的表达能力。相比之下，我们引入了一种高效的聚合机制，故意牺牲一些表达力以获得更强和更有结构的聚合能力。我们的方法允许在经典的消息传递和基于着色或普通游走的方法之间无缝扩展。我们使用广义毛毛虫图的层次结构中的同态计数严格地描述每个中间步骤的表达能力。基于这个基础，我们提出了毛毛虫GNN，它通过其稳健的图级别聚合能力，能够成功地处理专门为挑战经典MPGNNs而设计的合成图级别任务。此外，我们在真实世界的数据集上证明了，毛毛虫GNN在保持预测性能的同时，显著减少了计算图中隐藏层中的节点数量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Message-passing graph neural networks (MPGNNs) dominate modern graphlearning, typically prioritizing maximal expressive power. In contrast, weintroduce an \emph{efficient aggregation} mechanism, deliberately trading offsome expressivity for stronger and more structured aggregation capabilities.Our approach allows seamless scaling between classical message-passing andsimpler methods based on colored or plain walks. We rigorously characterize theexpressive power at each intermediate step using homomorphism counts from ahierarchy of generalized \emph{caterpillar graphs}. Based on this foundation,we propose the \emph{Caterpillar GNN}, whose robust graph-level aggregationenables it to successfully tackle synthetic graph-level task specificallydesigned to be challenging for classical MPGNNs. Moreover, we demonstrate that,on real-world datasets, the Caterpillar GNN achieves comparable predictiveperformance while significantly reducing the number of nodes in the hiddenlayers of the computational graph.</description>
      <author>example@mail.com (Marek Černý)</author>
      <guid isPermaLink="false">2506.06784v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Challenging Vision-Language Models with Surgical Data: A New Dataset and Broad Benchmarking Study</title>
      <link>http://arxiv.org/abs/2506.06232v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视觉语言模型（VLMs）在腔镜手术等内窥镜任务中的应用能力，发现VLMs在基础感知任务上表现良好，但在需要医学知识的高级任务上表现不佳，且专业医疗VLMs在基本和高级手术任务上均不如通用模型，指出需要进一步发展以应对手术的独特挑战。&lt;h4&gt;背景&lt;/h4&gt;传统计算机视觉模型在内窥镜领域泛化能力有限，而基础模型在跨领域性能上展现出潜力。&lt;h4&gt;目的&lt;/h4&gt;评估VLMs在内窥镜任务中的能力，特别是针对腔镜手术。&lt;h4&gt;方法&lt;/h4&gt;使用多种最先进的模型、多个手术数据集和大量的人类参考标注，解决三个关键研究问题：VLMs能否解决基本的感知任务？能否处理基于帧的高级内窥镜场景理解任务？专业医疗VLMs与通用模型相比如何？&lt;h4&gt;主要发现&lt;/h4&gt;VLMs在基本手术感知任务上表现良好，如物体计数和定位，但在需要医学知识的高级任务上表现不佳。专业医疗VLMs在基本和高级手术任务上均不如通用模型，表明它们尚未针对手术环境的复杂性进行优化。&lt;h4&gt;结论&lt;/h4&gt;VLMs在基础感知任务上表现可接受，但在需要医学知识的高级任务上存在不足，需要进一步研究和发展以应对手术的独特挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While traditional computer vision models have historically struggled togeneralize to endoscopic domains, the emergence of foundation models has shownpromising cross-domain performance. In this work, we present the firstlarge-scale study assessing the capabilities of Vision Language Models (VLMs)for endoscopic tasks with a specific focus on laparoscopic surgery. Using adiverse set of state-of-the-art models, multiple surgical datasets, andextensive human reference annotations, we address three key research questions:(1) Can current VLMs solve basic perception tasks on surgical images? (2) Canthey handle advanced frame-based endoscopic scene understanding tasks? and (3)How do specialized medical VLMs compare to generalist models in this context?Our results reveal that VLMs can effectively perform basic surgical perceptiontasks, such as object counting and localization, with performance levelscomparable to general domain tasks. However, their performance deterioratessignificantly when the tasks require medical knowledge. Notably, we find thatspecialized medical VLMs currently underperform compared to generalist modelsacross both basic and advanced surgical tasks, suggesting that they are not yetoptimized for the complexity of surgical environments. These findings highlightthe need for further advancements to enable VLMs to handle the uniquechallenges posed by surgery. Overall, our work provides important insights forthe development of next-generation endoscopic AI systems and identifies keyareas for improvement in medical visual language models.</description>
      <author>example@mail.com (Leon Mayer, Tim Rädsch, Dominik Michael, Lucas Luttner, Amine Yamlahi, Evangelia Christodoulou, Patrick Godau, Marcel Knopp, Annika Reinke, Fiona Kolbinger, Lena Maier-Hein)</author>
      <guid isPermaLink="false">2506.06232v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Robotic Policy Learning via Human-assisted Action Preference Optimization</title>
      <link>http://arxiv.org/abs/2506.07127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为HAPO的人辅助动作偏好优化方法，旨在通过偏好对齐来纠正部署失败并促进VLA模型的有效适应。&lt;h4&gt;背景&lt;/h4&gt;虽然VLA模型是机器人部署的基础模型，但它们依赖于专家演示，这限制了从失败中学习和纠正的能力。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一局限性，提出HAPO方法以实现可靠的部署和从失败中学习。&lt;h4&gt;方法&lt;/h4&gt;HAPO方法包括一个人类-机器人协作框架，用于可靠的失败纠正和通过人类干预收集交互轨迹。这些轨迹随后用于动作偏好优化过程，帮助VLA模型减少失败动作的发生并增强纠正动作的适应性。还提出了一种自适应重新加权算法，以解决在VLA模型中引入偏好优化时不可逆交互和标记概率不匹配的问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明，该方法在各种操作任务中具有优越的泛化能力和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;HAPO方法确保了VLA模型的可靠部署和有效的失败学习。&lt;h4&gt;翻译&lt;/h4&gt;Establishing a reliable and iteratively refined robotic system is essential for deploying real-world applications. While Vision-Language-Action (VLA) models are widely recognized as the foundation model for such robotic deployment, their dependence on expert demonstrations hinders the crucial capabilities of correction and learning from failures. To mitigate this limitation, we introduce a Human-assisted Action Preference Optimization method named HAPO, designed to correct deployment failures and foster effective adaptation through preference alignment for VLA models. This method begins with a human-robot collaboration framework for reliable failure correction and interaction trajectory collection through human intervention. These human-intervention trajectories are further employed within the action preference optimization process, facilitating VLA models to mitigate failure action occurrences while enhancing corrective action adaptation. Specifically, we propose an adaptive reweighting algorithm to address the issues of irreversible interactions and token probability mismatch when introducing preference optimization into VLA models, facilitating model learning from binary desirability signals derived from interactions. Through combining these modules, our human-assisted action preference optimization method ensures reliable deployment and effective learning from failure for VLA models. The experiments conducted in simulation and real-world scenarios prove superior generalization and robustness of our framework across a variety of manipulation tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Establishing a reliable and iteratively refined robotic system is essentialfor deploying real-world applications. While Vision-Language-Action (VLA)models are widely recognized as the foundation model for such roboticdeployment, their dependence on expert demonstrations hinders the crucialcapabilities of correction and learning from failures. To mitigate thislimitation, we introduce a Human-assisted Action Preference Optimization methodnamed HAPO, designed to correct deployment failures and foster effectiveadaptation through preference alignment for VLA models. This method begins witha human-robot collaboration framework for reliable failure correction andinteraction trajectory collection through human intervention. Thesehuman-intervention trajectories are further employed within the actionpreference optimization process, facilitating VLA models to mitigate failureaction occurrences while enhancing corrective action adaptation. Specifically,we propose an adaptive reweighting algorithm to address the issues ofirreversible interactions and token probability mismatch when introducingpreference optimization into VLA models, facilitating model learning frombinary desirability signals derived from interactions. Through combining thesemodules, our human-assisted action preference optimization method ensuresreliable deployment and effective learning from failure for VLA models. Theexperiments conducted in simulation and real-world scenarios prove superiorgeneralization and robustness of our framework across a variety of manipulationtasks.</description>
      <author>example@mail.com (Wenke xia, Yichu Yang, Hongtao Wu, Xiao Ma, Tao Kong, Di Hu)</author>
      <guid isPermaLink="false">2506.07127v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Ai-Driven Vulnerability Analysis in Smart Contracts: Trends, Challenges and Future Directions</title>
      <link>http://arxiv.org/abs/2506.06735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于AI的智能合约漏洞检测技术，分析了机器学习、深度学习、图神经网络和基于Transformer的模型在智能合约安全中的应用。&lt;h4&gt;背景&lt;/h4&gt;智能合约是区块链生态系统的重要组成部分，但存在如数值溢出、重入攻击和不当访问权限等漏洞，导致大量资金损失。&lt;h4&gt;目的&lt;/h4&gt;研究新型AI驱动的智能合约漏洞检测技术，提高安全性和自动化审计。&lt;h4&gt;方法&lt;/h4&gt;本文分析了机器学习、深度学习、图神经网络和基于Transformer的模型在智能合约安全中的应用，比较了这些技术在准确性、可解释性、计算开销和实时适用性方面的优缺点。&lt;h4&gt;主要发现&lt;/h4&gt;AI技术在智能合约漏洞检测方面展现出潜力，但存在一些开放挑战和未来机遇。&lt;h4&gt;结论&lt;/h4&gt;AI技术在智能合约安全领域具有发展潜力，但仍需解决一些开放挑战和未来的发展机遇。&lt;h4&gt;翻译&lt;/h4&gt;The abstract discusses novel AI-driven techniques for vulnerability detection in smart contracts, analyzing the application of machine learning, deep learning, graph neural networks, and transformer-based models in the field of smart contract security.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.5121/ijaia.2025.16305&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Smart contracts, integral to blockchain ecosystems, enable decentralizedapplications to execute predefined operations without intermediaries. Theirability to enforce trustless interactions has made them a core component ofplatforms such as Ethereum. Vulnerabilities such as numerical overflows,reentrancy attacks, and improper access permissions have led to the loss ofmillions of dollars throughout the blockchain and smart contract sector.Traditional smart contract auditing techniques such as manual code reviews andformal verification face limitations in scalability, automation, andadaptability to evolving development patterns. As a result, AI-based solutionshave emerged as a promising alternative, offering the ability to learn complexpatterns, detect subtle flaws, and provide scalable security assurances. Thispaper examines novel AI-driven techniques for vulnerability detection in smartcontracts, focusing on machine learning, deep learning, graph neural networks,and transformer-based models. This paper analyzes how each technique representscode, processes semantic information, and responds to real world vulnerabilityclasses. We also compare their strengths and weaknesses in terms of accuracy,interpretability, computational overhead, and real time applicability. Lastly,it highlights open challenges and future opportunities for advancing thisdomain.</description>
      <author>example@mail.com (Mesut Ozdag)</author>
      <guid isPermaLink="false">2506.06735v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>STSBench: A Spatio-temporal Scenario Benchmark for Multi-modal Large Language Models in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2506.06218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Dataset: https://huggingface.co/datasets/ivc-lrp/STSBench, Code:  https://github.com/LRP-IVC/STSBench&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了STSBench，一个基于场景的框架，用于评估自动驾驶中视觉语言模型（VLMs）的整体理解能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基准测试通常针对单视角的图像或视频，以及针对语义任务如物体识别、密集描述、风险评估或场景理解的VLMs。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够评估VLMs在复杂环境中对基本交通动态推理能力的基准。&lt;h4&gt;方法&lt;/h4&gt;STSBench自动从数据集中挖掘预定义的交通场景，提供直观的用户界面以便高效的人工验证，并为模型评估生成多项选择题。&lt;h4&gt;主要发现&lt;/h4&gt;该基准揭示了现有模型在复杂环境中推理基本交通动态方面的关键不足。&lt;h4&gt;结论&lt;/h4&gt;STSBench通过解决空间时间评估的核心差距，有助于开发更稳健和可解释的VLMs，以用于自动驾驶。&lt;h4&gt;翻译&lt;/h4&gt;We introduce STSBench, a scenario-based framework to benchmark the holistic understanding of vision-language models (VLMs) for autonomous driving. The framework automatically mines pre-defined traffic scenarios from any dataset using ground-truth annotations, provides an intuitive user interface for efficient human verification, and generates multiple-choice questions for model evaluation. Applied to the NuScenes dataset, we present STSnu, the first benchmark that evaluates the spatio-temporal reasoning capabilities of VLMs based on comprehensive 3D perception. Existing benchmarks typically target off-the-shelf or fine-tuned VLMs for images or videos from a single viewpoint and focus on semantic tasks such as object recognition, dense captioning, risk assessment, or scene understanding. In contrast, STSnu evaluates driving expert VLMs for end-to-end driving, operating on videos from multi-view cameras or LiDAR. It specifically assesses their ability to reason about both ego-vehicle actions and complex interactions among traffic participants, a crucial capability for autonomous vehicles. The benchmark features 43 diverse scenarios spanning multiple views and frames, resulting in 971 human-verified multiple-choice questions. A thorough evaluation uncovers critical shortcomings in existing models' ability to reason about fundamental traffic dynamics in complex environments. These findings highlight the urgent need for architectural advances that explicitly model spatio-temporal reasoning. By addressing a core gap in spatio-temporal evaluation, STSBench enables the development of more robust and explainable VLMs for autonomous driving.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce STSBench, a scenario-based framework to benchmark the holisticunderstanding of vision-language models (VLMs) for autonomous driving. Theframework automatically mines pre-defined traffic scenarios from any datasetusing ground-truth annotations, provides an intuitive user interface forefficient human verification, and generates multiple-choice questions for modelevaluation. Applied to the NuScenes dataset, we present STSnu, the firstbenchmark that evaluates the spatio-temporal reasoning capabilities of VLMsbased on comprehensive 3D perception. Existing benchmarks typically targetoff-the-shelf or fine-tuned VLMs for images or videos from a single viewpointand focus on semantic tasks such as object recognition, dense captioning, riskassessment, or scene understanding. In contrast, STSnu evaluates driving expertVLMs for end-to-end driving, operating on videos from multi-view cameras orLiDAR. It specifically assesses their ability to reason about both ego-vehicleactions and complex interactions among traffic participants, a crucialcapability for autonomous vehicles. The benchmark features 43 diverse scenariosspanning multiple views and frames, resulting in 971 human-verifiedmultiple-choice questions. A thorough evaluation uncovers critical shortcomingsin existing models' ability to reason about fundamental traffic dynamics incomplex environments. These findings highlight the urgent need forarchitectural advances that explicitly model spatio-temporal reasoning. Byaddressing a core gap in spatio-temporal evaluation, STSBench enables thedevelopment of more robust and explainable VLMs for autonomous driving.</description>
      <author>example@mail.com (Christian Fruhwirth-Reisinger, Dušan Malić, Wei Lin, David Schinagl, Samuel Schulter, Horst Possegger)</author>
      <guid isPermaLink="false">2506.06218v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>E-BATS: Efficient Backpropagation-Free Test-Time Adaptation for Speech Foundation Models</title>
      <link>http://arxiv.org/abs/2506.07078v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种针对语音基础模型的新型有效无反向传播测试时自适应（TTA）框架E-BATS，旨在解决实际场景中由于声学域偏移导致的性能下降问题。&lt;h4&gt;背景&lt;/h4&gt;语音基础模型在实际应用中面临声学域偏移的挑战，如背景噪声和说话人口音，导致性能下降。传统的TTA方法依赖反向传播，内存消耗大，限制了其在资源受限环境中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出E-BATS框架，旨在实现高效的TTA，同时降低内存消耗，并提高适应效果。&lt;h4&gt;方法&lt;/h4&gt;E-BATS通过三个关键组件实现平衡：轻量级的提示自适应、多尺度损失捕捉全局和局部分布偏移，以及测试时指数移动平均机制实现稳定的跨句子自适应。&lt;h4&gt;主要发现&lt;/h4&gt;在四个噪声语音数据集上进行的实验表明，E-BATS在四个噪声语音数据集上实现了持续的性能提升，与无反向传播基线相比，准确率提高了4.1%-13.5%，同时比基于反向传播的方法节省了2.0-6.4倍的GPU内存。&lt;h4&gt;结论&lt;/h4&gt;E-BATS为在声学变化下实现可扩展和鲁棒的适应提供了途径，为实际环境中的语音处理系统开发更有效的自适应方法铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在涉及声学域偏移的实际场景中，语音基础模型会遇到显著的性能下降，例如背景噪声和说话人口音。测试时自适应（TTA）最近被证明是一种可行的策略，可以在推理时解决这种域偏移，而不需要访问源数据或标签。然而，现有的TTA方法，尤其是那些依赖反向传播的方法，内存密集，限制了它们在语音任务和资源受限环境中的应用。尽管无反向传播的方法提供了改进的效率，但现有的方法在准确性方面表现不佳。这是因为它们主要用于视觉任务，与语音任务的表达式、噪声特征和模型架构根本不同，从而带来了独特的可迁移性挑战。在这篇论文中，我们介绍了E-BATS，这是第一个专为语音基础模型设计的有效无反向传播TTA框架。E-BATS通过三个关键组件在适应性有效性和内存效率之间实现了平衡：（i）基于前向传递的特征对齐的轻量级提示自适应，（ii）多尺度损失以捕捉全局（句子级）和局部分布偏移（标记级），以及（iii）测试时指数移动平均机制以实现跨句子的稳定自适应。在涵盖十六种声学条件的四个噪声语音数据集上进行的实验表明，E-BATS实现了持续的性能提升，与无反向传播基线相比，准确率提高了4.1%-13.5%，与基于反向传播的方法相比，GPU内存节省了2.0-6.4倍。通过在声学变化下实现可扩展和鲁棒的适应，这项工作为开发实际环境中的实用语音处理系统的更有效自适应方法铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech Foundation Models encounter significant performance degradation whendeployed in real-world scenarios involving acoustic domain shifts, such asbackground noise and speaker accents. Test-time adaptation (TTA) has recentlyemerged as a viable strategy to address such domain shifts at inference timewithout requiring access to source data or labels. However, existing TTAapproaches, particularly those relying on backpropagation, arememory-intensive, limiting their applicability in speech tasks andresource-constrained settings. Although backpropagation-free methods offerimproved efficiency, existing ones exhibit poor accuracy. This is because theyare predominantly developed for vision tasks, which fundamentally differ fromspeech task formulations, noise characteristics, and model architecture, posingunique transferability challenges. In this paper, we introduce E-BATS, thefirst Efficient BAckpropagation-free TTA framework designed explicitly forspeech foundation models. E-BATS achieves a balance between adaptationeffectiveness and memory efficiency through three key components: (i)lightweight prompt adaptation for a forward-pass-based feature alignment, (ii)a multi-scale loss to capture both global (utterance-level) and localdistribution shifts (token-level) and (iii) a test-time exponential movingaverage mechanism for stable adaptation across utterances. Experimentsconducted on four noisy speech datasets spanning sixteen acoustic conditionsdemonstrate consistent improvements, with 4.1%-13.5% accuracy gains overbackpropagation-free baselines and 2.0-6.4 times GPU memory savings compared tobackpropagation-based methods. By enabling scalable and robust adaptation underacoustic variability, this work paves the way for developing more efficientadaptation approaches for practical speech processing systems in real-worldenvironments.</description>
      <author>example@mail.com (Jiaheng Dong, Hong Jia, Soumyajit Chatterjee, Abhirup Ghosh, James Bailey, Ting Dang)</author>
      <guid isPermaLink="false">2506.07078v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Neighborhood Overlap-Aware High-Order Graph Neural Network for Dynamic Graph Learning</title>
      <link>http://arxiv.org/abs/2506.06728v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为NO-HGNN的动态图学习新方法，旨在通过考虑邻域重叠来提高节点嵌入的准确性，从而支持下游任务如链接预测。&lt;h4&gt;背景&lt;/h4&gt;动态图学习（DGL）旨在学习具有时间演化的节点嵌入，以支持链接预测等下游任务。在DGL中，有效建模图拓扑的时序动态和结构依赖是一个基本挑战。&lt;h4&gt;目的&lt;/h4&gt;提出NO-HGNN方法，以克服现有方法在捕捉节点交互时忽略复杂结构模式（如邻域重叠）的局限性。&lt;h4&gt;方法&lt;/h4&gt;NO-HGNN基于两个关键创新：（a）计算基于邻域重叠程度的关联分数，以更好地捕捉复杂的节点交互；（b）将这种关联直接嵌入到DGL中高阶图神经网络的消息传递过程中。&lt;h4&gt;主要发现&lt;/h4&gt;在两个真实世界动态图上的实验表明，NO-HGNN在链接预测准确性方面取得了显著的改进，优于几种最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;NO-HGNN通过考虑邻域重叠，在动态图学习领域实现了链接预测性能的提升，为该领域的研究提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic graph learning (DGL) aims to learn informative andtemporally-evolving node embeddings to support downstream tasks such as linkprediction. A fundamental challenge in DGL lies in effectively modeling boththe temporal dynamics and structural dependencies of evolving graph topologies.Recent advances in Dynamic Graph Neural Networks (DGNNs) have obtainedremarkable success by leveraging message-passing mechanisms to capture pairwisenode interactions. However, these approaches often overlook more complexstructural patterns, particularly neighborhood overlap, which can play acritical role in characterizing node interactions. To overcome this limitation,we introduce the Neighborhood Overlap-Aware High-Order Graph Neural Network(NO-HGNN), which is built upon two key innovations: (a) computing a correlationscore based on the extent of neighborhood overlap to better capture complexnode interactions; and (b) embedding this correlation directly into themessage-passing process of high-order graph neural networks in the DGL.Experiments on two real-world dynamic graphs show that NO-HGNN achieves notableimprovements in link prediction accuracy, outperforming severalstate-of-the-art approaches.</description>
      <author>example@mail.com (Ling Wang)</author>
      <guid isPermaLink="false">2506.06728v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Audio and Vision: Zero-Shot Audiovisual Segmentation by Connecting Pretrained Models</title>
      <link>http://arxiv.org/abs/2506.06537v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted on INTERSPEECH2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的零样本视听分割（AVS）框架，旨在通过利用多个预训练模型来识别与声音源相对应的视觉区域，以提高视频理解、监控和人类-计算机交互的效率。&lt;h4&gt;背景&lt;/h4&gt;传统的AVS方法依赖于大规模的像素级标注，这既昂贵又耗时。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在提出一种无需特定任务训练的零样本AVS框架。&lt;h4&gt;方法&lt;/h4&gt;该方法通过整合音频、视觉和文本表示来弥合模态差距，实现精确的声音源分割，同时不需要AVS特定的标注。文章系统地探讨了连接预训练模型的不同策略，并评估了它们在多个数据集上的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，本文提出的框架实现了最先进的零样本AVS性能，突显了多模态模型集成在细粒度视听分割中的有效性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的零样本AVS框架为视频理解、监控和人类-计算机交互等领域提供了有效的解决方案，并证明了多模态模型集成在视听分割中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audiovisual segmentation (AVS) aims to identify visual regions correspondingto sound sources, playing a vital role in video understanding, surveillance,and human-computer interaction. Traditional AVS methods depend on large-scalepixel-level annotations, which are costly and time-consuming to obtain. Toaddress this, we propose a novel zero-shot AVS framework that eliminatestask-specific training by leveraging multiple pretrained models. Our approachintegrates audio, vision, and text representations to bridge modality gaps,enabling precise sound source segmentation without AVS-specific annotations. Wesystematically explore different strategies for connecting pretrained modelsand evaluate their efficacy across multiple datasets. Experimental resultsdemonstrate that our framework achieves state-of-the-art zero-shot AVSperformance, highlighting the effectiveness of multimodal model integration forfinegrained audiovisual segmentation.</description>
      <author>example@mail.com (Seung-jae Lee, Paul Hongsuck Seo)</author>
      <guid isPermaLink="false">2506.06537v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Semi-supervised Segmentation Beyond Accuracy: Reliability and Robustness</title>
      <link>http://arxiv.org/abs/2506.05917v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文讨论了语义分割的重要性及其对场景理解的影响，指出了当前半监督分割评估协议的不足，并提出了一个新的评估指标——可靠分割得分（RSS），以更全面地评估分割模型。&lt;h4&gt;背景&lt;/h4&gt;语义分割对于场景理解至关重要，但其需要昂贵的像素级标注，因此半监督方法吸引了越来越多的关注。然而，现有的评估协议主要关注分割精度，而忽略了可靠性和鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，论文提出了一个名为可靠分割得分（RSS）的新指标，该指标结合了预测精度、校准和不确定性质量度量。&lt;h4&gt;方法&lt;/h4&gt;RSS通过调和平均数结合了这些度量，并对任何组成部分的不足进行惩罚，从而提供了一种简单直观的方法来全面评估分割模型。&lt;h4&gt;主要发现&lt;/h4&gt;对UniMatchV2及其前一代和监督基线的方法进行了综合评估，结果表明半监督方法通常在可靠性和精度之间进行权衡。虽然域外评估显示了UniMatchV2的鲁棒性，但也暴露了持续的可靠性不足。&lt;h4&gt;结论&lt;/h4&gt;论文主张评估协议转向更全面的指标，如RSS，以更好地将半监督学习研究与实际部署需求对齐。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语义分割对于场景理解至关重要，但需要昂贵的像素级标注，这促使人们越来越关注利用大量未标记数据的半监督方法。虽然半监督分割通常被视为通往可扩展、实际部署的途径，但令人惊讶的是，当前的评估协议仅关注分割精度，完全忽略了可靠性和鲁棒性。这些确保在不同条件下保持一致性能（鲁棒性）以及模型置信度良好以及不确定性有意义的（可靠性）质量是自动驾驶等安全关键应用所必需的，在这些应用中，模型必须处理不可预测的环境，并不惜一切代价避免突然故障。为了解决这一差距，我们引入了可靠分割得分（RSS），这是一种新的度量，通过调和平均数结合预测精度、校准和不确定性质量度量。RSS对其任何组成部分的不足进行惩罚，提供了一种简单直观的方式来全面评估分割模型。对UniMatchV2与其前身和监督基线的方法进行的综合评估表明，半监督方法通常在可靠性和精度之间进行权衡。虽然域外评估显示了UniMatchV2的鲁棒性，但它们进一步暴露了持续的可靠性不足。我们主张评估协议转向更全面的指标，如RSS，以更好地将半监督学习研究与实际部署需求对齐。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic segmentation is critical for scene understanding but demands costlypixel-wise annotations, attracting increasing attention to semi-supervisedapproaches to leverage abundant unlabeled data. While semi-supervisedsegmentation is often promoted as a path toward scalable, real-worlddeployment, it is astonishing that current evaluation protocols exclusivelyfocus on segmentation accuracy, entirely overlooking reliability androbustness. These qualities, which ensure consistent performance under diverseconditions (robustness) and well-calibrated model confidences as well asmeaningful uncertainties (reliability), are essential for safety-criticalapplications like autonomous driving, where models must handle unpredictableenvironments and avoid sudden failures at all costs. To address this gap, weintroduce the Reliable Segmentation Score (RSS), a novel metric that combinespredictive accuracy, calibration, and uncertainty quality measures via aharmonic mean. RSS penalizes deficiencies in any of its components, providingan easy and intuitive way of holistically judging segmentation models.Comprehensive evaluations of UniMatchV2 against its predecessor and asupervised baseline show that semi-supervised methods often trade reliabilityfor accuracy. While out-of-domain evaluations demonstrate UniMatchV2'srobustness, they further expose persistent reliability shortcomings. Weadvocate for a shift in evaluation protocols toward more holistic metrics likeRSS to better align semi-supervised learning research with real-worlddeployment needs.</description>
      <author>example@mail.com (Steven Landgraf, Markus Hillemann, Markus Ulrich)</author>
      <guid isPermaLink="false">2506.05917v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Graph Persistence goes Spectral</title>
      <link>http://arxiv.org/abs/2506.06571v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 4 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图拓扑描述符SpectRe，该描述符将谱信息整合到持久同伦图中，并在图表示学习中展现出比现有描述符更高的表达能力。&lt;h4&gt;背景&lt;/h4&gt;在图神经网络（GNNs）中，包括复杂的拓扑信息（如环路）可以证明能够超越Weisfeiler-Leman（WL）层次，从而增强其表达能力。持久同伦（PH）方法越来越多地用于图表示学习，但现有方法由于依赖于特征，仍然无法捕获基本的图结构信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的图拓扑描述符SpectRe，以增强图表示学习的表达能力，并捕获基本的图结构信息。&lt;h4&gt;方法&lt;/h4&gt;SpectRe将谱信息与持久同伦图相结合，并引入全局和局部稳定性的概念来分析现有描述符。&lt;h4&gt;主要发现&lt;/h4&gt;SpectRe在图上具有比现有描述符更高的表达能力，并且在局部上是稳定的。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，SpectRe在合成和真实世界数据集上都是有效的，并且有可能增强图模型在相关学习任务中的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：包括复杂的拓扑信息（例如，环路）可以证明能够超越Weisfeiler-Leman（WL）层次，从而增强信息传递图神经网络（GNNs）的表达能力。因此，持久同伦（PH）方法越来越多地用于图表示学习。在此背景下，最近的工作提出用顶点和边特征装饰经典的PH图以提高表达能力。然而，由于它们依赖于特征，这些方法仍然无法捕获基本的图结构信息。在本文中，我们提出了一种新的图拓扑描述符SpectRe，该描述符将谱信息整合到PH图中。值得注意的是，SpectRe在图上严格优于现有描述符。我们还引入了全局和局部稳定性的概念来分析现有描述符，并证明SpectRe是局部稳定的。最后，在合成和真实世界数据集上的实验表明了SpectRe的有效性及其增强相关学习任务中图模型能力的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Including intricate topological information (e.g., cycles) provably enhancesthe expressivity of message-passing graph neural networks (GNNs) beyond theWeisfeiler-Leman (WL) hierarchy. Consequently, Persistent Homology (PH) methodsare increasingly employed for graph representation learning. In this context,recent works have proposed decorating classical PH diagrams with vertex andedge features for improved expressivity. However, due to their dependence onfeatures, these methods still fail to capture basic graph structuralinformation. In this paper, we propose SpectRe -- a new topological descriptorfor graphs that integrates spectral information into PH diagrams. Notably,SpectRe is strictly more expressive than existing descriptors on graphs. Wealso introduce notions of global and local stability to analyze existingdescriptors and establish that SpectRe is locally stable. Finally, experimentson synthetic and real-world datasets demonstrate the effectiveness of SpectReand its potential to enhance the capabilities of graph models in relevantlearning tasks.</description>
      <author>example@mail.com (Mattie Ji, Amauri H. Souza, Vikas Garg)</author>
      <guid isPermaLink="false">2506.06571v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>FairPFN: A Tabular Foundation Model for Causal Fairness</title>
      <link>http://arxiv.org/abs/2506.07049v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FairPFN的表格基础模型，用于在机器学习系统中识别和减轻受保护属性对预测的因果影响，以提高因果公平性。&lt;h4&gt;背景&lt;/h4&gt;机器学习系统在医疗保健、执法和金融等关键领域得到应用，但这些系统往往基于包含人口统计偏差的历史数据，导致加剧社会不平等。&lt;h4&gt;目的&lt;/h4&gt;提出FairPFN模型，以解决因果公平性问题，减少算法歧视，并使因果公平性更易于应用于复杂场景。&lt;h4&gt;方法&lt;/h4&gt;FairPFN模型通过在合成因果公平数据上预训练，无需对因果模型有先验知识，便能识别和减轻受保护属性的因果影响。&lt;h4&gt;主要发现&lt;/h4&gt;FairPFN模型在多种定制和现实场景中，相对于稳健的基线方法，表现出强大的性能，且无需对因果模型有先验知识。&lt;h4&gt;结论&lt;/h4&gt;FairPFN模型为解决复杂公平性问题铺平了道路，使得因果公平性更容易被广泛应用。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为FairPFN的表格基础模型，用于在机器学习系统中识别和减轻受保护属性对预测的因果影响，以提高因果公平性。机器学习系统在医疗保健、执法和金融等关键领域得到应用，但这些系统往往基于包含人口统计偏差的历史数据，导致加剧社会不平等。提出FairPFN模型，以解决因果公平性问题，减少算法歧视，并使因果公平性更易于应用于复杂场景。FairPFN模型通过在合成因果公平数据上预训练，无需对因果模型有先验知识，便能识别和减轻受保护属性的因果影响。FairPFN模型在多种定制和现实场景中，相对于稳健的基线方法，表现出强大的性能，且无需对因果模型有先验知识。FairPFN模型为解决复杂公平性问题铺平了道路，使得因果公平性更容易被广泛应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning (ML) systems are utilized in critical sectors, such ashealthcare, law enforcement, and finance. However, these systems are oftentrained on historical data that contains demographic biases, leading to MLdecisions that perpetuate or exacerbate existing social inequalities. Causalfairness provides a transparent, human-in-the-loop framework to mitigatealgorithmic discrimination, aligning closely with legal doctrines of direct andindirect discrimination. However, current causal fairness frameworks hold a keylimitation in that they assume prior knowledge of the correct causal model,restricting their applicability in complex fairness scenarios where causalmodels are unknown or difficult to identify. To bridge this gap, we proposeFairPFN, a tabular foundation model pre-trained on synthetic causal fairnessdata to identify and mitigate the causal effects of protected attributes in itspredictions. FairPFN's key contribution is that it requires no knowledge of thecausal model and still demonstrates strong performance in identifying andremoving protected causal effects across a diverse set of hand-crafted andreal-world scenarios relative to robust baseline methods. FairPFN paves the wayfor promising future research, making causal fairness more accessible to awider variety of complex fairness problems.</description>
      <author>example@mail.com (Jake Robertson, Noah Hollmann, Samuel Müller, Noor Awad, Frank Hutter)</author>
      <guid isPermaLink="false">2506.07049v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>You Only Estimate Once: Unified, One-stage, Real-Time Category-level Articulated Object 6D Pose Estimation for Robotic Grasping</title>
      <link>http://arxiv.org/abs/2506.05719v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为YOEO的单阶段方法，用于解决机器人操作任务中关节物体类别级的姿态估计问题，该方法在GAPart数据集上展示了良好的姿态估计能力，并在实际场景中实现了200Hz的实时视觉反馈。&lt;h4&gt;背景&lt;/h4&gt;现有方法在估计类别级的部件姿态和大小时，通常采用复杂的多阶段流程，首先在点云中分割部件实例，然后估计标准化部件坐标空间（NPCS）表示的6D姿态，但这种方法计算成本高且在实时机器人任务中的性能较低。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述方法的局限性，提出YOEO方法，旨在通过单阶段流程同时输出实例分割和NPCS表示，以降低计算成本并提高实时性能。&lt;h4&gt;方法&lt;/h4&gt;YOEO方法使用统一的网络生成点级语义标签和质心偏移，使得来自同一部件实例的点对相同的质心进行投票。进一步，利用聚类算法根据估计的质心距离来区分点。然后，首先分离每个实例的NPCS区域，并将这些区域与真实点云对齐，以恢复最终的姿态和大小。&lt;h4&gt;主要发现&lt;/h4&gt;YOEO方法在GAPart数据集上展示了良好的姿态估计能力，并且在真实世界中部署了该模型，实现了200Hz的实时视觉反馈，使物理Kinova机器人能够与未见过的关节物体交互。&lt;h4&gt;结论&lt;/h4&gt;YOEO方法有效且实用，能够显著提高实时机器人任务中关节物体类别级姿态估计的性能。&lt;h4&gt;翻译&lt;/h4&gt;本文针对机器人操作任务中关节物体类别级姿态估计问题进行了研究。近年来，在估计类别级的部件姿态和大小时，已有工作取得了令人鼓舞的结果。然而，这些方法主要遵循一个复杂的多阶段流程，首先在点云中分割部件实例，然后估计标准化部件坐标空间（NPCS）表示的6D姿态。这些方法在实时机器人任务中存在计算成本高、性能低的问题。为了解决这些局限性，我们提出了YOEO方法，这是一种单阶段方法，能够端到端地同时输出实例分割和NPCS表示。我们使用一个统一的网络来生成点级语义标签和质心偏移，使得来自同一部件实例的点对相同的质心进行投票。我们进一步利用聚类算法根据估计的质心距离来区分点。然后，首先分离每个实例的NPCS区域，并将这些区域与真实点云对齐，以恢复最终的姿态和大小。在GAPart数据集上的实验结果证明了我们提出的单次拍摄方法在姿态估计方面的能力。我们还将在实际场景中部署我们通过合成训练得到的模型，实现200Hz的实时视觉反馈，使物理Kinova机器人能够与未见过的关节物体进行交互。这展示了我们提出的方法的实用性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the problem of category-level pose estimation forarticulated objects in robotic manipulation tasks. Recent works have shownpromising results in estimating part pose and size at the category level.However, these approaches primarily follow a complex multi-stage pipeline thatfirst segments part instances in the point cloud and then estimates theNormalized Part Coordinate Space (NPCS) representation for 6D poses. Theseapproaches suffer from high computational costs and low performance inreal-time robotic tasks. To address these limitations, we propose YOEO, asingle-stage method that simultaneously outputs instance segmentation and NPCSrepresentations in an end-to-end manner. We use a unified network to generatepoint-wise semantic labels and centroid offsets, allowing points from the samepart instance to vote for the same centroid. We further utilize a clusteringalgorithm to distinguish points based on their estimated centroid distances.Finally, we first separate the NPCS region of each instance. Then, we align theseparated regions with the real point cloud to recover the final pose and size.Experimental results on the GAPart dataset demonstrate the pose estimationcapabilities of our proposed single-shot method. We also deploy oursynthetically-trained model in a real-world setting, providing real-time visualfeedback at 200Hz, enabling a physical Kinova robot to interact with unseenarticulated objects. This showcases the utility and effectiveness of ourproposed method.</description>
      <author>example@mail.com (Jingshun Huang, Haitao Lin, Tianyu Wang, Yanwei Fu, Yu-Gang Jiang, Xiangyang Xue)</author>
      <guid isPermaLink="false">2506.05719v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Perspectives: A Survey on Cross-view Collaborative Intelligence with Egocentric-Exocentric Vision</title>
      <link>http://arxiv.org/abs/2506.06253v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了从外心（第三人称）和内心（第一人称）视角的视频理解研究，探讨了两种视角的协同潜力及其在动态环境中的互补理解能力。&lt;h4&gt;背景&lt;/h4&gt;从内外心视角感知世界是人类认知的基础，近年来，让机器利用这两种视角的协同潜力成为视频理解领域的一个引人注目的研究方向。&lt;h4&gt;目的&lt;/h4&gt;本文旨在全面回顾视频理解中的内外心视角，并探讨如何将这两种视角的技术整合，以及实现这些应用的关键研究任务。&lt;h4&gt;方法&lt;/h4&gt;文章系统地组织并回顾了近期的研究进展，分为三个主要研究方向：(1)利用内心数据增强外心理解，(2)利用外心数据改善内心分析，(3)联合学习框架，统一两种视角。并对每个方向的任务和相关工作进行详细分析。&lt;h4&gt;主要发现&lt;/h4&gt;文章讨论了支持内外心视角研究的基准数据集，评估了它们的范围、多样性和适用性，并指出了当前工作的局限性。&lt;h4&gt;结论&lt;/h4&gt;通过综合两种视角的见解，本文旨在激发视频理解和人工智能领域的进步，使机器更接近以人类方式感知世界。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从自我中心（第一人称）和外心（第三人称）的视角感知世界是人类认知的基础，这使人们能够对动态环境有丰富且互补的理解。近年来，让机器利用这两种视角的协同潜力已经成为视频理解领域的一个引人注目的研究方向。在本篇综述中，我们全面回顾了从外心和内心视角的视频理解。我们首先强调了整合内心和外心技术的实际应用，并展望了它们在不同领域中的潜在协作。然后，我们确定了实现这些应用的关键研究任务。接下来，我们系统地组织和回顾了最近的研究进展，主要分为三个研究方向：(1)利用内心数据来增强外心理解，(2)利用外心数据来改进内心分析，(3)联合学习框架，统一两种视角。对于每个方向，我们分析了多样化的任务和相关工作。此外，我们讨论了支持这两种视角研究的基准数据集，评估了它们的范围、多样性和适用性。最后，我们讨论了当前工作的局限性，并提出了有前景的未来研究方向。通过综合两种视角的见解，我们的目标是激发视频理解和人工智能领域的进步，使机器更接近以人类方式感知世界。相关作品的GitHub仓库可以在https://github.com/ayiyayi/Awesome-Egocentric-and-Exocentric-Vision找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Perceiving the world from both egocentric (first-person) and exocentric(third-person) perspectives is fundamental to human cognition, enabling richand complementary understanding of dynamic environments. In recent years,allowing the machines to leverage the synergistic potential of these dualperspectives has emerged as a compelling research direction in videounderstanding. In this survey, we provide a comprehensive review of videounderstanding from both exocentric and egocentric viewpoints. We begin byhighlighting the practical applications of integrating egocentric andexocentric techniques, envisioning their potential collaboration acrossdomains. We then identify key research tasks to realize these applications.Next, we systematically organize and review recent advancements into three mainresearch directions: (1) leveraging egocentric data to enhance exocentricunderstanding, (2) utilizing exocentric data to improve egocentric analysis,and (3) joint learning frameworks that unify both perspectives. For eachdirection, we analyze a diverse set of tasks and relevant works. Additionally,we discuss benchmark datasets that support research in both perspectives,evaluating their scope, diversity, and applicability. Finally, we discusslimitations in current works and propose promising future research directions.By synthesizing insights from both perspectives, our goal is to inspireadvancements in video understanding and artificial intelligence, bringingmachines closer to perceiving the world in a human-like manner. A GitHub repoof related works can be found athttps://github.com/ayiyayi/Awesome-Egocentric-and-Exocentric-Vision.</description>
      <author>example@mail.com (Yuping He, Yifei Huang, Guo Chen, Lidong Lu, Baoqi Pei, Jilan Xu, Tong Lu, Yoichi Sato)</author>
      <guid isPermaLink="false">2506.06253v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>HMVLM: Multistage Reasoning-Enhanced Vision-Language Model for Long-Tailed Driving Scenarios</title>
      <link>http://arxiv.org/abs/2506.05883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WOD Vision-based End-to-End Driving Challenge&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了HaoMo视觉-语言模型（HMVLM），这是一个端到端的驾驶框架，实现了认知启发式快速-慢速架构的慢速分支。&lt;h4&gt;背景&lt;/h4&gt;该模型通过快速控制器输出低级转向、油门和制动命令，同时慢速规划器——一个大型视觉-语言模型——生成高级意图，如“让行行人”或“在卡车后合并”，而不影响延迟。&lt;h4&gt;目的&lt;/h4&gt;HMVLM旨在提高自动驾驶系统的决策效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;HMVLM引入了三项升级：(1) 选择性五视图提示，包含4秒的自身运动学历史；(2) 多阶段思维链（CoT）提示，强制执行场景理解 -&gt; 驾驶决策 -&gt; 轨迹推理的推理流程；(3) 基于样条曲线的轨迹后处理，消除后期抖动和急转弯。&lt;h4&gt;主要发现&lt;/h4&gt;在Waymo开放数据集上训练的HMVLM实现了7.7367的评分，在2025年Waymo基于视觉的端到端（E2E）驾驶挑战中排名第二，比公共基线高出2.77。&lt;h4&gt;结论&lt;/h4&gt;这些升级使得HMVLM在自动驾驶领域取得了显著进展，提高了系统的性能和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present HaoMo Vision-Language Model (HMVLM), an end-to-end drivingframework that implements the slow branch of a cognitively inspired fast-slowarchitecture. A fast controller outputs low-level steering, throttle, and brakecommands, while a slow planner-a large vision-language model-generateshigh-level intents such as "yield to pedestrian" or "merge after the truck"without compromising latency. HMVLM introduces three upgrades: (1) selectivefive-view prompting with an embedded 4s history of ego kinematics, (2)multi-stage chain-of-thought (CoT) prompting that enforces a SceneUnderstanding -&gt; Driving Decision -&gt; Trajectory Inference reasoning flow, and(3) spline-based trajectory post-processing that removes late-stage jitter andsharp turns. Trained on the Waymo Open Dataset, these upgrades enable HMVLM toachieve a Rater Feedback Score (RFS) of 7.7367, securing 2nd place in the 2025Waymo Vision-based End-to-End (E2E) Driving Challenge and surpassing the publicbaseline by 2.77%.</description>
      <author>example@mail.com (Daming Wang, Yuhao Song, Zijian He, Kangliang Chen, Xing Pan, Lu Deng, Weihao Gu)</author>
      <guid isPermaLink="false">2506.05883v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>ICU-TSB: A Benchmark for Temporal Patient Representation Learning for Unsupervised Stratification into Patient Cohorts</title>
      <link>http://arxiv.org/abs/2506.06192v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages 1 table 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究介绍了ICU-TSB（时间分层基准），这是第一个用于评估基于时间患者表示学习的患者分层综合基准。该基准使用三个公开的ICU电子健康记录数据集进行实验，通过比较统计方法和几种循环神经网络（如LSTM和GRU）在生成有效患者表示方面的能力，验证了时间表示学习在重新发现具有临床意义的患者群体方面的潜力。&lt;h4&gt;背景&lt;/h4&gt;患者分层识别对于通过改进诊断和治疗策略推动个性化医学至关重要。ICU的电子健康记录（EHR）包含丰富的时序临床数据，可以用于此目的。&lt;h4&gt;目的&lt;/h4&gt;建立ICU-TSB基准，以评估基于时间患者表示学习的患者分层方法，并比较不同的统计方法和循环神经网络在生成有效患者表示方面的能力。&lt;h4&gt;方法&lt;/h4&gt;使用三个公开的ICU EHR数据集，通过时间表示学习进行患者分层，并引入一种新颖的分层评估框架，利用疾病分类学来衡量发现簇与临床验证的疾病分组之间的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;时间表示学习能够重新发现具有临床意义的患者群体，但这是一个具有挑战性的任务，其v度量从分类学的最高级别0.46下降到最低级别0.40。此外，还评估了为识别的簇分配可解释标签的多种策略。&lt;h4&gt;结论&lt;/h4&gt;ICU-TSB基准有助于评估基于时间患者表示学习的患者分层方法，实验和基准是完全可复制的，并可通过GitHub链接获取。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Identifying clinically meaningful subgroups by patient stratification is essential for advancing personalized medicine through improved diagnostics and treatment strategies. Electronic health records (EHRs), particularly those from intensive care units (ICUs), contain rich temporal clinical data that can be leveraged for this purpose. In this work, we introduce ICU-TSB (Temporal Stratification Benchmark), the first comprehensive benchmark for evaluating patient stratification based on temporal patient representation learning using three publicly available ICU EHR datasets. A key contribution of our benchmark is a novel hierarchical evaluation framework utilizing disease taxonomies to measure the alignment of discovered clusters with clinically validated disease groupings. In our experiments with ICU-TSB, we compared statistical methods and several recurrent neural networks, including LSTM and GRU, for their ability to generate effective patient representations for subsequent clustering of patient trajectories. Our results demonstrate that temporal representation learning can rediscover clinically meaningful patient cohorts; nevertheless, it remains a challenging task, with v-measuring varying from up to 0.46 at the top level of the taxonomy to up to 0.40 at the lowest level. To further enhance the practical utility of our findings, we also evaluate multiple strategies for assigning interpretable labels to the identified clusters. The experiments and benchmark are fully reproducible and available at https://github.com/ds4dh/CBMS2025stratification.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Patient stratification identifying clinically meaningful subgroups isessential for advancing personalized medicine through improved diagnostics andtreatment strategies. Electronic health records (EHRs), particularly those fromintensive care units (ICUs), contain rich temporal clinical data that can beleveraged for this purpose. In this work, we introduce ICU-TSB (TemporalStratification Benchmark), the first comprehensive benchmark for evaluatingpatient stratification based on temporal patient representation learning usingthree publicly available ICU EHR datasets. A key contribution of our benchmarkis a novel hierarchical evaluation framework utilizing disease taxonomies tomeasure the alignment of discovered clusters with clinically validated diseasegroupings. In our experiments with ICU-TSB, we compared statistical methods andseveral recurrent neural networks, including LSTM and GRU, for their ability togenerate effective patient representations for subsequent clustering of patienttrajectories. Our results demonstrate that temporal representation learning canrediscover clinically meaningful patient cohorts; nevertheless, it remains achallenging task, with v-measuring varying from up to 0.46 at the top level ofthe taxonomy to up to 0.40 at the lowest level. To further enhance thepractical utility of our findings, we also evaluate multiple strategies forassigning interpretable labels to the identified clusters. The experiments andbenchmark are fully reproducible and available athttps://github.com/ds4dh/CBMS2025stratification.</description>
      <author>example@mail.com (Dimitrios Proios, Alban Bornet, Anthony Yazdani, Jose F Rodrigues Jr, Douglas Teodoro)</author>
      <guid isPermaLink="false">2506.06192v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Pts3D-LLM: Studying the Impact of Token Structure for 3D Scene Understanding With Large Language Models</title>
      <link>http://arxiv.org/abs/2506.05689v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Main paper and appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了有效表示3D场景的多模态大型语言模型（MLLMs）的重要性与挑战，提出了一种新的方法，通过融合3D点云特征来丰富视觉标记，并在多个3D理解基准测试中实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;当前的方法通常只依赖于2D图像特征和不同的标记化方法。&lt;h4&gt;目的&lt;/h4&gt;为了有效表示3D场景，并提高MLLMs的性能。&lt;h4&gt;方法&lt;/h4&gt;进行了严格的3D标记结构研究，系统性地比较了基于视频和基于点的表示，同时保持了模型骨干和参数的一致性。提出了一个新方法，通过结合来自预训练的Sonata PointTransformer V3编码器的3D点云特征来丰富视觉标记。&lt;h4&gt;主要发现&lt;/h4&gt;将显式的3D特征合并显著提升了性能；基于点的标记结构在点被巧妙采样和排序时可以与基于视频的标记结构相媲美。&lt;h4&gt;结论&lt;/h4&gt;强调了标记结构分析作为一项重要贡献，并强调了在多个种子上平均报告结果的重要性，认为这对于领域中的稳健进步至关重要。&lt;h4&gt;翻译&lt;/h4&gt;有效地表示3D场景对于多模态大型语言模型（MLLMs）至关重要，但也是一个挑战。现有的方法通常仅依赖于2D图像特征和不同的标记化方法。本文对3D标记结构进行了严格的研究，系统地比较了基于视频和基于点的表示，同时保持了一致的模式骨干和参数。我们提出了一种新方法，通过结合来自预训练的Sonata PointTransformer V3编码器的3D点云特征来丰富视觉标记。我们的实验表明，合并显式的3D特征可以显著提高性能。此外，我们还表明，当点被巧妙采样和排序时，基于点的标记结构可以与基于视频的标记结构相媲美。我们从这两种结构中得出的最佳模型在多个3D理解基准测试中实现了最先进的结果。我们强调了标记结构分析作为一项关键贡献，以及跨多个种子平均报告结果的做法，我们认为这对于领域的稳健进步至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effectively representing 3D scenes for Multimodal Large Language Models(MLLMs) is crucial yet challenging. Existing approaches commonly only rely on2D image features and use varied tokenization approaches. This work presents arigorous study of 3D token structures, systematically comparing video-based andpoint-based representations while maintaining consistent model backbones andparameters. We propose a novel approach that enriches visual tokens byincorporating 3D point cloud features from a Sonata pretrained PointTransformer V3 encoder. Our experiments demonstrate that merging explicit 3Dfeatures significantly boosts performance. Furthermore, we show thatpoint-based token structures can rival video-based ones when the points arecleverly sampled and ordered. Our best models from both structures achievestate-of-the-art results on multiple 3D understanding benchmarks. We emphasizeour analysis of token structures as a key contribution, alongside transparentreporting of results averaged over multiple seeds, a practice we believe isvital for robust progress in the field.</description>
      <author>example@mail.com (Hugues Thomas, Chen Chen, Jian Zhang)</author>
      <guid isPermaLink="false">2506.05689v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Rapid training of Hamiltonian graph networks without gradient descent</title>
      <link>http://arxiv.org/abs/2506.06558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 7 figures, 2 tables, and an appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在数据驱动建模中学习遵守物理对称性和约束的动态系统，提出了一种新的方法，通过将物理定律与图神经网络结合，提高了复杂N体动力学模型的建模精度和置换不变性。&lt;h4&gt;背景&lt;/h4&gt;学习遵守物理对称性和约束的动态系统是数据驱动建模中的一个基本挑战。&lt;h4&gt;目的&lt;/h4&gt;提高复杂N体动力学模型的建模精度和置换不变性。&lt;h4&gt;方法&lt;/h4&gt;将物理定律与图神经网络结合，使用Hamiltonian Graph Networks (HGN)进行训练，并通过随机特征参数构造来替代迭代优化算法。&lt;h4&gt;主要发现&lt;/h4&gt;HGN的训练速度比其他15种优化器快600倍，同时保持了可比的精度。模型在多种模拟中表现出鲁棒性能，包括不同几何形状的3维N体质量-弹簧系统，并保留了关于置换、旋转和平移的基本物理不变性。模型即使在训练时只使用8节点系统，也能在零样本方式下泛化到4096节点的系统。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法挑战了迭代梯度下降优化算法在训练物理系统神经网络模型中的主导地位。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在数据驱动建模中学习尊重物理对称性和约束的动态系统仍然是一个基本挑战。将物理定律与图神经网络结合有助于原理性地建模复杂的N体动力学，并产生准确和置换不变的模型。然而，使用迭代、基于梯度的优化算法（例如Adam、RMSProp、LBFGS）来训练图神经网络往往会导致训练缓慢，特别是在大型、复杂的系统中。与15种不同的优化器相比，我们证明Hamiltonian Graph Networks (HGN)可以通过用基于随机特征的参数构造来替代迭代优化，以600倍的速度进行训练，但精度相当。我们在各种模拟中展示了鲁棒的性能，包括最多3维不同几何形状的N体质量-弹簧系统，同时保持了关于置换、旋转和转换的基本物理不变性。我们发现，即使在训练时只使用8节点系统，该模型也能以零样本方式泛化到多达4096节点的系统，而无需重新训练。我们的工作挑战了迭代梯度下降优化算法在训练物理系统神经网络模型中的主导地位。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning dynamical systems that respect physical symmetries and constraintsremains a fundamental challenge in data-driven modeling. Integrating physicallaws with graph neural networks facilitates principled modeling of complexN-body dynamics and yields accurate and permutation-invariant models. However,training graph neural networks with iterative, gradient-based optimizationalgorithms (e.g., Adam, RMSProp, LBFGS) often leads to slow training,especially for large, complex systems. In comparison to 15 differentoptimizers, we demonstrate that Hamiltonian Graph Networks (HGN) can be trainedup to 600x faster--but with comparable accuracy--by replacing iterativeoptimization with random feature-based parameter construction. We show robustperformance in diverse simulations, including N-body mass-spring systems in upto 3 dimensions with different geometries, while retaining essential physicalinvariances with respect to permutation, rotation, and translation. We revealthat even when trained on minimal 8-node systems, the model can generalize in azero-shot manner to systems as large as 4096 nodes without retraining. Our workchallenges the dominance of iterative gradient-descent-based optimizationalgorithms for training neural network models for physical systems.</description>
      <author>example@mail.com (Atamert Rahma, Chinmay Datar, Ana Cukarska, Felix Dietrich)</author>
      <guid isPermaLink="false">2506.06558v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>WhisQ: Cross-Modal Representation Learning for Text-to-Music MOS Prediction</title>
      <link>http://arxiv.org/abs/2506.05899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  3 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为WhisQ的多模态架构，用于评估文本到音乐系统的MOS预测，通过序列级别的共注意力和最优传输正则化来解决双重评估挑战。&lt;h4&gt;背景&lt;/h4&gt;MOS预测需要对整体音乐质量和文本提示对齐进行评估。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效评估文本到音乐系统MOS的模型。&lt;h4&gt;方法&lt;/h4&gt;WhisQ使用Whisper Base模型进行时间音频编码，Qwen 3模型进行文本编码，并通过序列结构保持精细的跨模态建模。该架构具有专门的预测路径，包括从音频嵌入中预测OMQ和利用音频与文本之间的双向序列共注意力的TA。此外，Sinkhorn最优传输损失进一步强化了共享嵌入空间中的语义对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在MusicEval Track-1数据集上，WhisQ在OMQ和TA方面都显著优于基线，分别提高了7%和14%的Spearman相关性。消融研究显示，最优传输正则化提供了最大的性能提升（10%的SRCC改进），证明了显式跨模态对齐对文本到音乐评估的重要性。&lt;h4&gt;结论&lt;/h4&gt;WhisQ通过优化传输正则化和跨模态对齐，提高了文本到音乐系统MOS预测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mean Opinion Score (MOS) prediction for text to music systems requiresevaluating both overall musical quality and text prompt alignment. This paperintroduces WhisQ, a multimodal architecture that addresses this dual-assessmentchallenge through sequence level co-attention and optimal transportregularization. WhisQ employs the Whisper Base pretrained model for temporalaudio encoding and Qwen 3, a 0.6B Small Language Model (SLM), for textencoding, with both maintaining sequence structure for fine grained cross-modalmodeling. The architecture features specialized prediction pathways: OMQ ispredicted from pooled audio embeddings, while TA leverages bidirectionalsequence co-attention between audio and text. Sinkhorn optimal transport lossfurther enforce semantic alignment in the shared embedding space. On theMusicEval Track-1 dataset, WhisQ achieves substantial improvements over thebaseline: 7% improvement in Spearman correlation for OMQ and 14% for TA.Ablation studies reveal that optimal transport regularization provides thelargest performance gain (10% SRCC improvement), demonstrating the importanceof explicit cross-modal alignment for text-to-music evaluation.</description>
      <author>example@mail.com (Jakaria Islam Emon, Kazi Tamanna Alam, Md. Abu Salek)</author>
      <guid isPermaLink="false">2506.05899v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Hallucinate, Ground, Repeat: A Framework for Generalized Visual Relationship Detection</title>
      <link>http://arxiv.org/abs/2506.05651v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 9 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种迭代视觉 grounding 框架，利用大型语言模型（LLMs）作为结构化关系先验，以解决视觉关系检测（VRD）模型在处理未知关系时的泛化问题。&lt;h4&gt;背景&lt;/h4&gt;视觉关系检测在视觉智能、具身 AI、辅助系统和场景理解等领域有广泛应用，但大多数 VRD 模型依赖于固定的谓词集，限制了它们对新交互的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;解决从外部知识中假设的语义上合理但未注释的关系无法视觉化的关键挑战，并实现超越标注数据的关联理解。&lt;h4&gt;方法&lt;/h4&gt;方法交替使用 LLM 从检测到的对象生成候选场景图（期望阶段）和训练视觉模型以将假设与感知证据对齐（最大化阶段）。&lt;h4&gt;主要发现&lt;/h4&gt;模型在三个设置（seen, unseen, mixed）下的谓词分类中分别达到了 15.9, 13.1 和 11.7 的平均召回率（mR@50），优于 LLM-only、few-shot 和 debiased 基准。&lt;h4&gt;结论&lt;/h4&gt;基于 grounded LLM 先验的视觉理解具有可扩展的开放世界视觉理解的前景。&lt;h4&gt;翻译&lt;/h4&gt;Understanding relationships between objects is central to visual intelligence, with applications in embodied AI, assistive systems, and scene understanding. Yet, most visual relationship detection (VRD) models rely on a fixed predicate set, limiting their generalization to novel interactions. A key challenge is the inability to visually ground semantically plausible, but unannotated, relationships hypothesized from external knowledge. This work introduces an iterative visual grounding framework that leverages large language models (LLMs) as structured relational priors. Inspired by expectation-maximization (EM), our method alternates between generating candidate scene graphs from detected objects using an LLM (expectation) and training a visual model to align these hypotheses with perceptual evidence (maximization). This process bootstraps relational understanding beyond annotated data and enables generalization to unseen predicates. Additionally, we introduce a new benchmark for open-world VRD on Visual Genome with 21 held-out predicates and evaluate under three settings: seen, unseen, and mixed. Our model outperforms LLM-only, few-shot, and debiased baselines, achieving mean recall (mR@50) of 15.9, 13.1, and 11.7 on predicate classification on these three sets. These results highlight the promise of grounded LLM priors for scalable open-world visual understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding relationships between objects is central to visualintelligence, with applications in embodied AI, assistive systems, and sceneunderstanding. Yet, most visual relationship detection (VRD) models rely on afixed predicate set, limiting their generalization to novel interactions. A keychallenge is the inability to visually ground semantically plausible, butunannotated, relationships hypothesized from external knowledge. This workintroduces an iterative visual grounding framework that leverages largelanguage models (LLMs) as structured relational priors. Inspired byexpectation-maximization (EM), our method alternates between generatingcandidate scene graphs from detected objects using an LLM (expectation) andtraining a visual model to align these hypotheses with perceptual evidence(maximization). This process bootstraps relational understanding beyondannotated data and enables generalization to unseen predicates. Additionally,we introduce a new benchmark for open-world VRD on Visual Genome with 21held-out predicates and evaluate under three settings: seen, unseen, and mixed.Our model outperforms LLM-only, few-shot, and debiased baselines, achievingmean recall (mR@50) of 15.9, 13.1, and 11.7 on predicate classification onthese three sets. These results highlight the promise of grounded LLM priorsfor scalable open-world visual understanding.</description>
      <author>example@mail.com (Shanmukha Vellamcheti, Sanjoy Kundu, Sathyanarayanan N. Aakur)</author>
      <guid isPermaLink="false">2506.05651v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Learning Along the Arrow of Time: Hyperbolic Geometry for Backward-Compatible Representation Learning</title>
      <link>http://arxiv.org/abs/2506.05826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于双曲几何的向后兼容表示学习方法，通过考虑旧嵌入模型的不确定性，使更新模型能够无缝集成现有模型，避免重新处理存储数据。&lt;h4&gt;背景&lt;/h4&gt;现有的欧几里得空间兼容方法忽略了旧嵌入模型的不确定性，并强制新模型重构过时的表示，无论其质量如何，从而阻碍了新模型的学习过程。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过将嵌入提升到双曲空间，并限制更新嵌入位于旧嵌入的蕴涵锥内，以保持模型之间的代际一致性，同时考虑到表示中的不确定性。&lt;h4&gt;方法&lt;/h4&gt;使用双曲几何来处理时间，将时间视为捕捉模型置信度和演化的自然轴。引入了一种鲁棒的对比对齐损失，根据旧嵌入的不确定性动态调整对齐权重。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了所提出方法在实现兼容性方面的优越性，为构建更具弹性和适应性的机器学习系统铺平了道路。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地解决现有兼容性问题，为机器学习系统的进一步发展提供了新的思路和解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Backward compatible representation learning enables updated models tointegrate seamlessly with existing ones, avoiding to reprocess stored data.Despite recent advances, existing compatibility approaches in Euclidean spaceneglect the uncertainty in the old embedding model and force the new model toreconstruct outdated representations regardless of their quality, therebyhindering the learning process of the new model. In this paper, we propose toswitch perspectives to hyperbolic geometry, where we treat time as a naturalaxis for capturing a model's confidence and evolution. By lifting embeddingsinto hyperbolic space and constraining updated embeddings to lie within theentailment cone of the old ones, we maintain generational consistency acrossmodels while accounting for uncertainties in the representations. To furtherenhance compatibility, we introduce a robust contrastive alignment loss thatdynamically adjusts alignment weights based on the uncertainty of the oldembeddings. Experiments validate the superiority of the proposed method inachieving compatibility, paving the way for more resilient and adaptablemachine learning systems.</description>
      <author>example@mail.com (Ngoc Bui, Menglin Yang, Runjin Chen, Leonardo Neves, Mingxuan Ju, Rex Ying, Neil Shah, Tong Zhao)</author>
      <guid isPermaLink="false">2506.05826v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning</title>
      <link>http://arxiv.org/abs/2506.07044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report, 53 pages, 25 tables, and 16 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Lingshu的医学专用多模态大型语言模型，旨在解决现有医学MLLMs在医学应用中的局限性，并介绍了数据收集、模型训练和评估方法。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型在理解常见视觉元素方面表现出色，但在医学应用中效果有限，因为医学场景的数据和任务与通用领域存在本质差异。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来解决现有医学MLLMs的局限性，包括扩展医学知识覆盖范围、减少幻觉风险和提高推理能力。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种全面的数据收集和整理流程，从医学影像、医学文本和通用领域数据中获取丰富的医学知识数据；2. 合成了准确的医学字幕、视觉问答和推理样本；3. 引入了多阶段训练来嵌入医学专业知识并逐步提高任务解决能力；4. 探索了使用可验证奖励范式结合强化学习来增强医学推理能力；5. 开发了MedEvalKit，一个统一的评估框架，用于标准化、公平和高效地评估模型。&lt;h4&gt;主要发现&lt;/h4&gt;Lingshu在多项基本医学任务中（多模态问答、基于文本的问答和医学报告生成）的表现优于现有开源的多模态模型。&lt;h4&gt;结论&lt;/h4&gt;Lingshu是一个有效的医学专用多模态大型语言模型，能够提高医学应用中的任务解决能力，并为医学MLLMs的发展提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities in understanding common visual elements, largely due to their large-scale datasets and advanced training strategies. However, their effectiveness in medical applications remains limited due to the inherent discrepancies between data and tasks in medical scenarios and those in the general domain. Concretely, existing medical MLLMs face the following critical limitations: (1) limited coverage of medical knowledge beyond imaging, (2) heightened susceptibility to hallucinations due to suboptimal data curation processes, (3) lack of reasoning capabilities tailored for complex medical scenarios. To address these challenges, we first propose a comprehensive data curation procedure that (1) efficiently acquires rich medical knowledge data not only from medical imaging but also from extensive medical texts and general-domain data; and (2) synthesizes accurate medical captions, visual question answering (VQA), and reasoning samples. As a result, we build a multimodal dataset enriched with extensive medical knowledge. Building on the curated data, we introduce our medical-specialized MLLM: Lingshu. Lingshu undergoes multi-stage training to embed medical expertise and enhance its task-solving capabilities progressively. Besides, we preliminarily explore the potential of applying reinforcement learning with verifiable rewards paradigm to enhance Lingshu's medical reasoning ability. Additionally, we develop MedEvalKit, a unified evaluation framework that consolidates leading multimodal and textual medical benchmarks for standardized, fair, and efficient model assessment. We evaluate the performance of Lingshu on three fundamental medical tasks, multimodal QA, text-based QA, and medical report generation. The results show that Lingshu consistently outperforms the existing open-source multimodal models on most tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have demonstrated impressivecapabilities in understanding common visual elements, largely due to theirlarge-scale datasets and advanced training strategies. However, theireffectiveness in medical applications remains limited due to the inherentdiscrepancies between data and tasks in medical scenarios and those in thegeneral domain. Concretely, existing medical MLLMs face the following criticallimitations: (1) limited coverage of medical knowledge beyond imaging, (2)heightened susceptibility to hallucinations due to suboptimal data curationprocesses, (3) lack of reasoning capabilities tailored for complex medicalscenarios. To address these challenges, we first propose a comprehensive datacuration procedure that (1) efficiently acquires rich medical knowledge datanot only from medical imaging but also from extensive medical texts andgeneral-domain data; and (2) synthesizes accurate medical captions, visualquestion answering (VQA), and reasoning samples. As a result, we build amultimodal dataset enriched with extensive medical knowledge. Building on thecurated data, we introduce our medical-specialized MLLM: Lingshu. Lingshuundergoes multi-stage training to embed medical expertise and enhance itstask-solving capabilities progressively. Besides, we preliminarily explore thepotential of applying reinforcement learning with verifiable rewards paradigmto enhance Lingshu's medical reasoning ability. Additionally, we developMedEvalKit, a unified evaluation framework that consolidates leading multimodaland textual medical benchmarks for standardized, fair, and efficient modelassessment. We evaluate the performance of Lingshu on three fundamental medicaltasks, multimodal QA, text-based QA, and medical report generation. The resultsshow that Lingshu consistently outperforms the existing open-source multimodalmodels on most tasks ...</description>
      <author>example@mail.com (LASA Team, Weiwen Xu, Hou Pong Chan, Long Li, Mahani Aljunied, Ruifeng Yuan, Jianyu Wang, Chenghao Xiao, Guizhen Chen, Chaoqun Liu, Zhaodonghui Li, Yu Sun, Junao Shen, Chaojun Wang, Jie Tan, Deli Zhao, Tingyang Xu, Hao Zhang, Yu Rong)</author>
      <guid isPermaLink="false">2506.07044v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Beamforming and Resource Allocation for Delay Optimization in RIS-Assisted OFDM Systems</title>
      <link>http://arxiv.org/abs/2506.03586v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在下行可重构智能表面（RIS）辅助的正交频分复用（OFDM）系统中，联合相位设计和资源分配问题，以优化平均延迟。&lt;h4&gt;背景&lt;/h4&gt;数据包对每个用户的到达是随机的，使得问题本质上成为一个马尔可夫决策过程（MDP），属于强化学习的范畴。&lt;h4&gt;目的&lt;/h4&gt;提出一种混合深度强化学习（DRL）方法，以有效处理混合动作空间并降低状态空间维度。&lt;h4&gt;方法&lt;/h4&gt;使用近端策略优化（PPO）-Θ来优化RIS相移设计，而PPO-N负责子载波分配决策。引入多代理策略以更有效地优化子载波分配指标。将与平均延迟密切相关的关键因素，如缓冲区中积压的数据包数量和当前数据包到达量，纳入状态空间。此外，引入迁移学习框架以提高训练效率和加速收敛。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，所提出的算法显著降低了平均延迟，提高了资源分配效率，与基线方法相比，实现了更优的系统鲁棒性和公平性。&lt;h4&gt;结论&lt;/h4&gt;所提出的算法在优化平均延迟和资源分配效率方面表现出色，同时提高了系统的鲁棒性和公平性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates a joint phase design and resource allocation problemin downlink reconfigurable intelligent surface (RIS)-assisted orthogonalfrequency division multiplexing (OFDM) systems to optimize average delay, wheredata packets for each user arrive at the base station stochastically. Thesequential optimization problem is inherently a Markov decision process (MDP),making it fall within the scope of reinforcement learning. To effectivelyhandle the mixed action space and reduce the state space dimensionality, ahybrid deep reinforcement learning (DRL) approach is proposed. Specifically,proximal policy optimization (PPO)-$\Theta$ is employed to optimize RIS phaseshift design, while PPO-N is responsible for subcarrier allocation decisions.To further mitigate the curse of dimensionality associated with subcarrierallocation, a multi-agent strategy is introduced to optimize subcarrierallocation indicater more efficiently. Moreover, to achieve more adaptiveresource allocation and accurately capture network dynamics, key factorsclosely related to average delay, including the number of backlogged packets inbuffers and the current packet arrivals, are incorporated into the state space.Furthermore, a transfer learning framework is introduced to enhance trainingefficiency and accelerate convergence. Simulation results demonstrate that theproposed algorithm significantly reduces average delay, enhances resourceallocation efficiency, and achieves superior system robustness and fairnesscompared to baseline methods.</description>
      <author>example@mail.com (Yu Ma, Xiao Li, Chongtao Guo, Le Liang, Shi Jin)</author>
      <guid isPermaLink="false">2506.03586v2</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Positional Encoding meets Persistent Homology on Graphs</title>
      <link>http://arxiv.org/abs/2506.05814v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了消息传递图神经网络（GNNs）的局部归纳偏差问题，提出了一种新的可学习方法PiPE（持久性信息位置编码），以解决GNNs在利用关键结构信息方面的不足。&lt;h4&gt;背景&lt;/h4&gt;GNNs的局部归纳偏差阻碍了它们利用诸如连接性和循环等关键结构信息的能力。&lt;h4&gt;目的&lt;/h4&gt;提出新的方法以缓解GNNs的局部归纳偏差问题，并提高其表达能力。&lt;h4&gt;方法&lt;/h4&gt;引入了位置编码（PE）和持久同调（PH）方法，并提出了PiPE方法。&lt;h4&gt;主要发现&lt;/h4&gt;证明了PE和PH方法各有优劣，且无一种方法在所有情况下都优于另一种。PiPE在多种任务（如分子属性预测、图分类和泛化到分布外的情况）中表现良好。&lt;h4&gt;结论&lt;/h4&gt;PiPE是一种比PH和PE都更具表达力的新方法，可以提升图表示学习的前沿水平。&lt;h4&gt;翻译&lt;/h4&gt;摘要：局部归纳偏差阻碍了消息传递图神经网络（GNNs）利用关键结构信息（例如，连接性和循环）的能力。位置编码（PE）和持久同调（PH）是缓解此问题的两种有前途的方法。PE方案赋予GNNs位置感知特征，而PH方法增强了GNNs的多分辨率拓扑特征。然而，PE和PH的相对优缺点缺乏严格的理论描述。我们通过证明两种范式都不比对方更具有表现力，并提供了在一个方法失败而另一个方法成功的新构造，来弥合这一差距。我们的见解为设计了一种新的可学习方法PiPE（持久性信息位置编码）提供了信息，该方法证明比PH和PE都更有表现力。PiPE在各种任务（例如，分子属性预测、图分类和分布外泛化）中表现出强大的性能，从而推动了图表示学习的前沿。代码可在https://github.com/Aalto-QuML/PIPE上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The local inductive bias of message-passing graph neural networks (GNNs)hampers their ability to exploit key structural information (e.g., connectivityand cycles). Positional encoding (PE) and Persistent Homology (PH) have emergedas two promising approaches to mitigate this issue. PE schemes endow GNNs withlocation-aware features, while PH methods enhance GNNs with multiresolutiontopological features. However, a rigorous theoretical characterization of therelative merits and shortcomings of PE and PH has remained elusive. We bridgethis gap by establishing that neither paradigm is more expressive than theother, providing novel constructions where one approach fails but the othersucceeds. Our insights inform the design of a novel learnable method, PiPE(Persistence-informed Positional Encoding), which is provably more expressivethan both PH and PE. PiPE demonstrates strong performance across a variety oftasks (e.g., molecule property prediction, graph classification, andout-of-distribution generalization), thereby advancing the frontiers of graphrepresentation learning. Code is available athttps://github.com/Aalto-QuML/PIPE.</description>
      <author>example@mail.com (Yogesh Verma, Amauri H. Souza, Vikas Garg)</author>
      <guid isPermaLink="false">2506.05814v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Does Your 3D Encoder Really Work? When Pretrain-SFT from 2D VLMs Meets 3D VLMs</title>
      <link>http://arxiv.org/abs/2506.05318v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了二维视觉语言模型（VLMs）在三维场景中的应用，分析了不同模型架构的优缺点，并提出了一种新的数据集以促进三维场景理解。&lt;h4&gt;背景&lt;/h4&gt;随着二维视觉语言模型（VLMs）在二维视觉任务上的显著进步，研究者们开始探索将这些模型扩展到三维场景中，用于三维问答、密集描述和视觉定位等任务。&lt;h4&gt;目的&lt;/h4&gt;研究三维视觉语言模型（3D VLMs）在三维场景中的表现，并寻找提高三维理解的方法。&lt;h4&gt;方法&lt;/h4&gt;将最近的3D VLMs分为三类：以3D对象为中心、基于2D图像和以3D场景为中心的方法。通过深入分析，研究了3D场景中心VLMs的性能差异和原因。&lt;h4&gt;主要发现&lt;/h4&gt;3D场景中心VLMs在性能上低于最新的3D对象中心和基于2D图像的方法，原因在于它们对3D场景编码器的依赖有限，且预训练阶段的效果不如二维VLMs。数据扩展对大型数据集的益处不明显。模型倾向于过度依赖语言线索并过度拟合常见答案分布，从而减少了3D编码器的有效利用。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的3D相关性判别问答数据集，旨在打破捷径学习并提高三维理解。强调了在3D VLMs中需要更先进的评估和改进策略以实现更好的三维理解。&lt;h4&gt;翻译&lt;/h4&gt;With remarkable progress in 2D Vision-Language Models (VLMs) spurring interest in extending them to 3D settings for tasks like 3D Question Answering, DenseCaptioning, and Visual Grounding, this paper discusses the application of 3D VLMs in 3D scenes, analyzes the advantages and disadvantages of different model architectures, and proposes a new dataset to promote 3D scene understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Remarkable progress in 2D Vision-Language Models (VLMs) has spurred interestin extending them to 3D settings for tasks like 3D Question Answering, DenseCaptioning, and Visual Grounding. Unlike 2D VLMs that typically process imagesthrough an image encoder, 3D scenes, with their intricate spatial structures,allow for diverse model architectures. Based on their encoder design, thispaper categorizes recent 3D VLMs into 3D object-centric, 2D image-based, and 3Dscene-centric approaches. Despite the architectural similarity of 3Dscene-centric VLMs to their 2D counterparts, they have exhibited comparativelylower performance compared with the latest 3D object-centric and 2D image-basedapproaches. To understand this gap, we conduct an in-depth analysis, revealingthat 3D scene-centric VLMs show limited reliance on the 3D scene encoder, andthe pre-train stage appears less effective than in 2D VLMs. Furthermore, weobserve that data scaling benefits are less pronounced on larger datasets. Ourinvestigation suggests that while these models possess cross-modal alignmentcapabilities, they tend to over-rely on linguistic cues and overfit to frequentanswer distributions, thereby diminishing the effective utilization of the 3Dencoder. To address these limitations and encourage genuine 3D sceneunderstanding, we introduce a novel 3D Relevance Discrimination QA datasetdesigned to disrupt shortcut learning and improve 3D understanding. Ourfindings highlight the need for advanced evaluation and improved strategies forbetter 3D understanding in 3D VLMs.</description>
      <author>example@mail.com (Haoyuan Li, Yanpeng Zhou, Yufei Gao, Tao Tang, Jianhua Han, Yujie Yuan, Dave Zhenyu Chen, Jiawang Bian, Hang Xu, Xiaodan Liang)</author>
      <guid isPermaLink="false">2506.05318v2</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>LaTtE-Flow: Layerwise Timestep-Expert Flow-based Transformer</title>
      <link>http://arxiv.org/abs/2506.06952v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Unified multimodal model, Flow-matching&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;LaTtE-Flow是一种新型且高效的架构，它统一了图像理解和生成，并提高了性能和生成速度。&lt;h4&gt;背景&lt;/h4&gt;现有统一的多模态模型需要大量预训练，且图像生成速度慢，限制了在实际应用中的部署。&lt;h4&gt;目的&lt;/h4&gt;提出LaTtE-Flow，以实现高效且性能优越的图像理解和生成。&lt;h4&gt;方法&lt;/h4&gt;LaTtE-Flow基于预训练的视觉-语言模型（VLMs），并结合了基于层和时步专家流的新架构。它通过在每个采样时步仅激活一小部分Transformer层来提高采样效率，并采用时步条件残差注意力机制以实现层间高效的信息重用。&lt;h4&gt;主要发现&lt;/h4&gt;LaTtE-Flow在多模态理解任务上取得了良好的性能，同时与最新的统一多模态模型相比，其推理速度提高了约6倍。&lt;h4&gt;结论&lt;/h4&gt;LaTtE-Flow在保持较高图像生成质量的同时，显著提高了性能和生成速度，为多模态任务提供了有效解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in multimodal foundation models unifying image understandingand generation have opened exciting avenues for tackling a wide range ofvision-language tasks within a single framework. Despite progress, existingunified models typically require extensive pretraining and struggle to achievethe same level of performance compared to models dedicated to each task.Additionally, many of these models suffer from slow image generation speeds,limiting their practical deployment in real-time or resource-constrainedsettings. In this work, we propose Layerwise Timestep-Expert Flow-basedTransformer (LaTtE-Flow), a novel and efficient architecture that unifies imageunderstanding and generation within a single multimodal model. LaTtE-Flowbuilds upon powerful pretrained Vision-Language Models (VLMs) to inherit strongmultimodal understanding capabilities, and extends them with a novel LayerwiseTimestep Experts flow-based architecture for efficient image generation.LaTtE-Flow distributes the flow-matching process across specialized groups ofTransformer layers, each responsible for a distinct subset of timesteps. Thisdesign significantly improves sampling efficiency by activating only a smallsubset of layers at each sampling timestep. To further enhance performance, wepropose a Timestep-Conditioned Residual Attention mechanism for efficientinformation reuse across layers. Experiments demonstrate that LaTtE-Flowachieves strong performance on multimodal understanding tasks, while achievingcompetitive image generation quality with around 6x faster inference speedcompared to recent unified multimodal models.</description>
      <author>example@mail.com (Ying Shen, Zhiyang Xu, Jiuhai Chen, Shizhe Diao, Jiaxin Zhang, Yuguang Yao, Joy Rimchala, Ismini Lourentzou, Lifu Huang)</author>
      <guid isPermaLink="false">2506.06952v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>VideoChat-A1: Thinking with Long Videos by Chain-of-Shot Reasoning</title>
      <link>http://arxiv.org/abs/2506.06097v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了视频理解领域的一项新进展，即VideoChat-A1，这是一种新型长视频智能体范式，能够有效地理解长视频内容。&lt;h4&gt;背景&lt;/h4&gt;当前的多模态大型语言模型（MLLMs）在分析短视频方面表现良好，但在理解具有较长上下文的长视频方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;为了解决长视频理解中的困难，论文提出了VideoChat-A1，旨在提高对长视频内容的理解能力。&lt;h4&gt;方法&lt;/h4&gt;VideoChat-A1采用了一种独特的镜头链推理范式，能够逐步选择与用户问题相关的镜头，并从粗到细地分析这些镜头。通过沿着镜头链进行多模态推理，VideoChat-A1可以模拟人类的思考过程，以发现对长视频内容进行深思熟虑理解的有利时间上下文。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，VideoChat-A1在主流长视频问答基准测试中取得了最先进的性能，例如在VideoMME上达到77.0，在EgoSchema上达到70.1，分别比其强基线（如Intern2.5VL-8B和InternVideo2.5-8B）提高了10.8%和6.2%。与GPT-4o和Gemini 1.5 Pro等领先的开源模型相比，VideoChat-A1在准确性方面具有竞争力，但输入帧数减少了7%，推理时间减少了12%。&lt;h4&gt;结论&lt;/h4&gt;VideoChat-A1通过创新的镜头链推理范式，有效地提高了长视频的理解能力，为长视频内容分析提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;最近，视频理解领域的进步是由多模态大型语言模型（MLLMs）驱动的。但是，这些MLLMs擅长分析短视频，而在理解具有较长上下文的长视频方面存在困难。为了解决这一困难，最近提出了几种智能体范式，使用MLLMs作为智能体以检索长视频中的额外上下文知识。然而，大多数现有的智能体忽略了这样一个关键事实，即长视频由多个镜头组成，即要回答来自长视频的用户问题，深入了解其相关镜头对人类来说是至关重要的。没有这样的见解，这些智能体往往会错误地发现冗余甚至噪声的时间上下文，限制了它们在长视频理解方面的能力。为了填补这一空白，我们提出了VideoChat-A1，这是一种新颖的长视频智能体范式。与先前的工作不同，我们的VideoChat-A1可以通过独特的镜头链推理范式深入思考长视频。更具体地说，它可以逐步选择用户问题的相关镜头，并从粗到细地查看这些镜头。通过沿着镜头链进行多模态推理，VideoChat-A1可以有效地模拟逐步的人类思考过程，从而能够交互式地发现对长视频内容进行深思熟虑理解的有利时间上下文。广泛的实验表明，我们的VideoChat-A1在主流长视频问答基准测试中取得了最先进的性能，例如在VideoMME上达到77.0，在EgoSchema上达到70.1，分别比其强基线（例如Intern2.5VL-8B和InternVideo2.5-8B）提高了10.8%和6.2%。与领先的开源GPT-4o和Gemini 1.5 Pro相比，VideoChat-A1提供了具有竞争力的准确性，但平均输入帧数减少了7%，推理时间减少了12%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent advance in video understanding has been driven by multimodal largelanguage models (MLLMs). But these MLLMs are good at analyzing short videos,while suffering from difficulties in understanding videos with a longercontext. To address this difficulty, several agent paradigms have recently beenproposed, using MLLMs as agents for retrieving extra contextual knowledge in along video. However, most existing agents ignore the key fact that a long videois composed with multiple shots, i.e., to answer the user question from a longvideo, it is critical to deeply understand its relevant shots like human.Without such insight, these agents often mistakenly find redundant even noisytemporal context, restricting their capacity for long video understanding. Tofill this gap, we propose VideoChat-A1, a novel long video agent paradigm.Different from the previous works, our VideoChat-A1 can deeply think with longvideos, via a distinct chain-of-shot reasoning paradigm. More specifically, itcan progressively select the relevant shots of user question, and look intothese shots in a coarse-to-fine partition. By multi-modal reasoning along theshot chain, VideoChat-A1 can effectively mimic step-by-step human thinkingprocess, allowing to interactively discover preferable temporal context forthoughtful understanding in long videos. Extensive experiments show that, ourVideoChat-A1 achieves the state-of-the-art performance on the mainstream longvideo QA benchmarks, e.g., it achieves 77.0 on VideoMME and 70.1 on EgoSchema,outperforming its strong baselines (e.g., Intern2.5VL-8B andInternVideo2.5-8B), by up to 10.8\% and 6.2\%. Compared to leading close-sourceGPT-4o and Gemini 1.5 Pro, VideoChat-A1 offers competitive accuracy, but with7\% input frames and 12\% inference time on average.</description>
      <author>example@mail.com (Zikang Wang, Boyu Chen, Zhengrong Yue, Yi Wang, Yu Qiao, Limin Wang, Yali Wang)</author>
      <guid isPermaLink="false">2506.06097v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>GP-MoLFormer-Sim: Test Time Molecular Optimization through Contextual Similarity Guidance</title>
      <link>http://arxiv.org/abs/2506.05628v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages main article, 21 pages total&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于生成化学语言模型（CLM）的、无需训练的分子空间导航和采样方法，该方法利用分子相似性作为指导，并应用于药物发现、化学设计和生物学等领域。&lt;h4&gt;背景&lt;/h4&gt;设计分子时保持与目标分子和/或性质的相似性对于药物发现、化学设计和生物学等领域的应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的无需训练的分子空间导航和采样方法，同时保持与目标分子的相似性。&lt;h4&gt;方法&lt;/h4&gt;该方法利用CLM学习到的上下文表示来估计分子相似性，并据此调整CLM的自回归采样策略。在解码过程的每一步，该方法都会跟踪当前生成与目标之间的距离，并更新logits以鼓励生成保持相似性。该方法使用了一种参数数量约为4700万的基于SMILES的CLM，即GP-MoLFormer，并因此将其称为GP-MoLFormer-Sim。该方法还与遗传算法（GA）集成，并在涉及性质优化、分子重发现和基于结构的药物设计的标准分子优化基准上进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;GP-MoLFormer-Sim结合遗传算法（GP-MoLFormer-Sim+GA）在黑盒情况下优于现有的无需训练的基线方法。&lt;h4&gt;结论&lt;/h4&gt;这项工作的发现是理解并指导CLM生成机制的一步。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种基于生成化学语言模型（CLM）的、无需训练的分子空间导航和采样方法，该方法利用分子相似性作为指导，并应用于药物发现、化学设计和生物学等领域。我们提出的方法利用CLM本身学习到的上下文表示来估计分子相似性，然后使用该相似性来调整CLM的自回归采样策略。在解码过程的每一步，该方法都会跟踪当前生成与目标之间的距离，并更新logits以鼓励生成保持相似性。我们使用了一种参数数量约为4700万的基于SMILES的CLM，即GP-MoLFormer，并因此将其称为GP-MoLFormer-Sim，该模型允许在测试时更新深度生成策略以反映与一组指导分子的上下文相似性。该方法进一步与遗传算法（GA）集成，并在涉及性质优化、分子重发现和基于结构的药物设计的标准分子优化基准上进行了测试。结果表明，GP-MoLFormer-Sim结合遗传算法（GP-MoLFormer-Sim+GA）在黑盒情况下优于现有的无需训练的基线方法。这项工作的发现是理解并指导CLM生成机制的一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to design molecules while preserving similarity to a targetmolecule and/or property is crucial for various applications in drug discovery,chemical design, and biology. We introduce in this paper an efficienttraining-free method for navigating and sampling from the molecular space witha generative Chemical Language Model (CLM), while using the molecularsimilarity to the target as a guide. Our method leverages the contextualrepresentations learned from the CLM itself to estimate the molecularsimilarity, which is then used to adjust the autoregressive sampling strategyof the CLM. At each step of the decoding process, the method tracks thedistance of the current generations from the target and updates the logits toencourage the preservation of similarity in generations. We implement themethod using a recently proposed $\sim$47M parameter SMILES-based CLM,GP-MoLFormer, and therefore refer to the method as GP-MoLFormer-Sim, whichenables a test-time update of the deep generative policy to reflect thecontextual similarity to a set of guide molecules. The method is furtherintegrated into a genetic algorithm (GA) and tested on a set of standardmolecular optimization benchmarks involving property optimization, molecularrediscovery, and structure-based drug design. Results show that,GP-MoLFormer-Sim, combined with GA (GP-MoLFormer-Sim+GA) outperforms existingtraining-free baseline methods, when the oracle remains black-box. The findingsin this work are a step forward in understanding and guiding the generativemechanisms of CLMs.</description>
      <author>example@mail.com (Jiri Navratil, Jarret Ross, Payel Das, Youssef Mroueh, Samuel C Hoffman, Vijil Chenthamarakshan, Brian Belgodere)</author>
      <guid isPermaLink="false">2506.05628v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>PROVSYN: Synthesizing Provenance Graphs for Data Augmentation in Intrusion Detection Systems</title>
      <link>http://arxiv.org/abs/2506.06226v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PROVSYN是一个自动化的框架，通过三个阶段合成来源图，用于入侵检测，特别是在对抗高级持续性威胁（APTs）时，通过展示复杂的攻击模式。&lt;h4&gt;背景&lt;/h4&gt;来源图分析在入侵检测中起着至关重要的作用，特别是在对抗高级持续性威胁（APTs）时，因为它可以揭示复杂的攻击模式。然而，由于现实世界数据中的类别不平衡，结合图神经网络（GNNs）和自然语言处理（NLP）的系统效果有限。&lt;h4&gt;目的&lt;/h4&gt;提出PROVSYN，以解决现实世界数据中类别不平衡的问题，提高入侵检测模型的性能。&lt;h4&gt;方法&lt;/h4&gt;PROVSYN通过以下三个阶段合成来源图：1）使用结构-语义建模进行异构图结构合成；2）基于规则的拓扑优化；3）使用大型语言模型（LLMs）进行上下文感知的文本属性合成。PROVSYN包括一个综合评估框架，该框架整合了结构、文本、时间和基于嵌入的指标，以及语义验证机制，以评估生成的攻击模式和系统行为的正确性。&lt;h4&gt;主要发现&lt;/h4&gt;使用合成图增加下游APT检测模型的训练数据集，实验结果表明PROVSYN能够生成高保真度的图，并通过有效数据增强提高了检测性能。&lt;h4&gt;结论&lt;/h4&gt;PROVSYN框架能够有效地提高入侵检测模型对高级持续性威胁的检测性能，并通过数据增强增强了模型的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Provenance graph analysis plays a vital role in intrusion detection,particularly against Advanced Persistent Threats (APTs), by exposing complexattack patterns. While recent systems combine graph neural networks (GNNs) withnatural language processing (NLP) to capture structural and semantic features,their effectiveness is limited by class imbalance in real-world data. Toaddress this, we introduce PROVSYN, an automated framework that synthesizesprovenance graphs through a three-phase pipeline: (1) heterogeneous graphstructure synthesis with structural-semantic modeling, (2) rule-basedtopological refinement, and (3) context-aware textual attribute synthesis usinglarge language models (LLMs). PROVSYN includes a comprehensive evaluationframework that integrates structural, textual, temporal, and embedding-basedmetrics, along with a semantic validation mechanism to assess the correctnessof generated attack patterns and system behaviors. To demonstrate practicalutility, we use the synthetic graphs to augment training datasets fordownstream APT detection models. Experimental results show that PROVSYNproduces high-fidelity graphs and improves detection performance througheffective data augmentation.</description>
      <author>example@mail.com (Yi Huang, Wajih UI Hassan, Yao Guo, Xiangqun Chen, Ding Li)</author>
      <guid isPermaLink="false">2506.06226v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>ProJo4D: Progressive Joint Optimization for Sparse-View Inverse Physics Estimation</title>
      <link>http://arxiv.org/abs/2506.05317v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ProJo4D的渐进式联合优化框架，用于解决基于物理的神经渲染问题，提高了4D场景理解的效果。&lt;h4&gt;背景&lt;/h4&gt;神经渲染在3D重建和新视角合成方面取得了显著进展，但将物理与神经渲染结合的逆问题（从视觉数据中估计物理参数）仍然具有挑战性，限制了其在机器人学和XR等领域应用的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高基于物理的神经渲染的准确性，特别是在使用稀疏多视角视频数据时。&lt;h4&gt;方法&lt;/h4&gt;ProJo4D通过逐渐增加联合优化参数的集合，并基于它们的敏感性来指导优化过程，从而实现几何、外观、物理状态和材料属性的完全联合优化。&lt;h4&gt;主要发现&lt;/h4&gt;在PAC-NeRF和Spring-Gaus数据集上的评估表明，ProJo4D在4D未来状态预测、未来状态的新视角渲染和材料参数估计方面优于现有工作。&lt;h4&gt;结论&lt;/h4&gt;ProJo4D框架在物理基础上的4D场景理解方面表现出有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：神经渲染在3D重建和新视角合成方面取得了显著进展。与物理的结合开辟了新的应用。然而，从视觉数据中估计物理参数的逆问题仍然具有挑战性，限制了其在机器人学和XR等应用中的有效性。将物理纳入神经渲染框架的现有方法通常需要密集的多视角视频作为输入，这使得它们在实际应用中难以扩展。当面对稀疏的多视角视频时，现有方法使用的顺序优化策略会导致显著的误差累积，例如，不良的初始3D重建会导致后续阶段的材料参数估计不良。与顺序优化不同，由于问题的高度非凸性和通常不可微分的性质，直接同时优化所有参数也失败了。我们提出了ProJo4D，一个渐进式联合优化框架，它根据其敏感性逐步增加联合优化的参数集合，导致对几何、外观、物理状态和材料属性的完全联合优化。在PAC-NeRF和Spring-Gaus数据集上的评估表明，ProJo4D在4D未来状态预测、未来状态的新视角渲染和材料参数估计方面优于先前的工作，证明了它在物理基础上的4D场景理解方面的有效性。有关演示，请访问项目网页：https://daniel03c1.github.io/ProJo4D/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural rendering has made significant strides in 3D reconstruction and novelview synthesis. With the integration with physics, it opens up newapplications. The inverse problem of estimating physics from visual data,however, still remains challenging, limiting its effectiveness for applicationslike physically accurate digital twin creation in robotics and XR. Existingmethods that incorporate physics into neural rendering frameworks typicallyrequire dense multi-view videos as input, making them impractical for scalable,real-world use. When presented with sparse multi-view videos, the sequentialoptimization strategy used by existing approaches introduces significant erroraccumulation, e.g., poor initial 3D reconstruction leads to bad materialparameter estimation in subsequent stages. Instead of sequential optimization,directly optimizing all parameters at the same time also fails due to thehighly non-convex and often non-differentiable nature of the problem. Wepropose ProJo4D, a progressive joint optimization framework that graduallyincreases the set of jointly optimized parameters guided by their sensitivity,leading to fully joint optimization over geometry, appearance, physical state,and material property. Evaluations on PAC-NeRF and Spring-Gaus datasets showthat ProJo4D outperforms prior work in 4D future state prediction, novel viewrendering of future state, and material parameter estimation, demonstrating itseffectiveness in physically grounded 4D scene understanding. For demos, pleasevisit the project webpage: https://daniel03c1.github.io/ProJo4D/</description>
      <author>example@mail.com (Daniel Rho, Jun Myeong Choi, Biswadip Dey, Roni Sengupta)</author>
      <guid isPermaLink="false">2506.05317v2</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Can In-Context Reinforcement Learning Recover From Reward Poisoning Attacks?</title>
      <link>http://arxiv.org/abs/2506.06891v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于上下文的强化学习（ICRL）的抗腐败鲁棒性，重点关注决策预训练的Transformer（DPT）模型，并提出了一种对抗训练框架AT-DPT来应对针对DPT的奖励中毒攻击。&lt;h4&gt;背景&lt;/h4&gt;DPT模型容易受到奖励中毒攻击的影响，这会导致其学习到的策略失效。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种新的对抗训练方法，增强DPT模型对奖励中毒攻击的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种对抗训练框架AT-DPT，该方法同时训练一个攻击者和一个DPT模型。攻击者旨在通过污染环境奖励来最小化DPT的真实奖励，而DPT模型则从污染数据中推断出最优动作。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，AT-DPT在对抗标准bandit算法，包括针对奖励污染设计的鲁棒基线时，显著优于这些基线。在自适应攻击者的评估中，AT-DPT也表现出了类似的结果。此外，将AT-DPT的评估扩展到MDP设置中，结果表明在bandit场景中观察到的鲁棒性在更复杂的环境中也是适用的。&lt;h4&gt;结论&lt;/h4&gt;AT-DPT框架能够有效提高DPT模型对奖励中毒攻击的鲁棒性，并在更复杂的环境中表现出良好的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;We study the corruption-robustness of in-context reinforcement learning (ICRL), focusing on the Decision-Pretrained Transformer (DPT, Lee et al.,2023). To address the challenge of reward poisoning attacks targeting the DPT,we propose a novel adversarial training framework, called Adversarially Trained Decision-Pretrained Transformer (AT-DPT). Our method simultaneously trains an attacker to minimize the true reward of the DPT by poisoning environment rewards, and a DPT model to infer optimal actions from the poisoned data. We evaluate the effectiveness of our approach against standard bandit algorithms, including robust baselines designed to handle reward contamination. Our results show that the proposed method significantly outperforms these baselines in bandit settings, under a learned attacker. We additionally evaluate AT-DPT on an adaptive attacker, and observe similar results. Furthermore, we extend our evaluation to the MDP setting, confirming that the robustness observed in bandit scenarios generalizes to more complex environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the corruption-robustness of in-context reinforcement learning(ICRL), focusing on the Decision-Pretrained Transformer (DPT, Lee et al.,2023). To address the challenge of reward poisoning attacks targeting the DPT,we propose a novel adversarial training framework, called Adversarially TrainedDecision-Pretrained Transformer (AT-DPT). Our method simultaneously trains anattacker to minimize the true reward of the DPT by poisoning environmentrewards, and a DPT model to infer optimal actions from the poisoned data. Weevaluate the effectiveness of our approach against standard bandit algorithms,including robust baselines designed to handle reward contamination. Our resultsshow that the proposed method significantly outperforms these baselines inbandit settings, under a learned attacker. We additionally evaluate AT-DPT onan adaptive attacker, and observe similar results. Furthermore, we extend ourevaluation to the MDP setting, confirming that the robustness observed inbandit scenarios generalizes to more complex environments.</description>
      <author>example@mail.com (Paulius Sasnauskas, Yiğit Yalın, Goran Radanović)</author>
      <guid isPermaLink="false">2506.06891v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Discrete Minds in a Continuous World: Do Language Models Know Time Passes?</title>
      <link>http://arxiv.org/abs/2506.05790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了大型语言模型（LLMs）对时间流逝的感知能力及其在决策中的适应性。&lt;h4&gt;背景&lt;/h4&gt;尽管LLMs在时间推理任务上表现出色，但它们对实际时间流逝的感知能力尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;通过三项实验研究LLMs是否能够感知时间流逝并据此调整决策。&lt;h4&gt;方法&lt;/h4&gt;首先，提出了Token-Time假设，并通过对话时长判断任务验证该假设；其次，展示了LLMs如何利用这种意识来调整回答长度，在用户表达紧迫性时保持准确性；最后，开发了BombRush游戏，以检验LLMs在动态环境中面对渐进时间压力时的行为变化。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs对时间流逝有一定的感知能力，能够将离散的语言符号与连续的物理时间相连接，但这种能力随模型大小和推理能力而异。&lt;h4&gt;结论&lt;/h4&gt;本研究为在时间敏感应用中提高LLMs的时间感知能力奠定了理论基础。&lt;h4&gt;翻译&lt;/h4&gt;While Large Language Models (LLMs) excel at temporal reasoning tasks like event ordering and duration estimation, their ability to perceive the actual passage of time remains unexplored. We investigate whether LLMs perceive the passage of time and adapt their decision-making accordingly through three complementary experiments. First, we introduce the Token-Time Hypothesis, positing that LLMs can map discrete token counts to continuous wall-clock time, and validate this through a dialogue duration judgment task. Second, we demonstrate that LLMs could use this awareness to adapt their response length while maintaining accuracy when users express urgency in question answering tasks. Finally, we develop BombRush, an interactive navigation challenge that examines how LLMs modify behavior under progressive time pressure in dynamic environments. Our findings indicate that LLMs possess certain awareness of time passage, enabling them to bridge discrete linguistic tokens and continuous physical time, though this capability varies with model size and reasoning abilities. This work establishes a theoretical foundation for enhancing temporal awareness in LLMs for time-sensitive applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While Large Language Models (LLMs) excel at temporal reasoning tasks likeevent ordering and duration estimation, their ability to perceive the actualpassage of time remains unexplored. We investigate whether LLMs perceive thepassage of time and adapt their decision-making accordingly through threecomplementary experiments. First, we introduce the Token-Time Hypothesis,positing that LLMs can map discrete token counts to continuous wall-clock time,and validate this through a dialogue duration judgment task. Second, wedemonstrate that LLMs could use this awareness to adapt their response lengthwhile maintaining accuracy when users express urgency in question answeringtasks. Finally, we develop BombRush, an interactive navigation challenge thatexamines how LLMs modify behavior under progressive time pressure in dynamicenvironments. Our findings indicate that LLMs possess certain awareness of timepassage, enabling them to bridge discrete linguistic tokens and continuousphysical time, though this capability varies with model size and reasoningabilities. This work establishes a theoretical foundation for enhancingtemporal awareness in LLMs for time-sensitive applications.</description>
      <author>example@mail.com (Minghan Wang, Ye Bai, Thuy-Trang Vu, Ehsan Shareghi, Gholamreza Haffari)</author>
      <guid isPermaLink="false">2506.05790v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Masked Language Models are Good Heterogeneous Graph Generalizers</title>
      <link>http://arxiv.org/abs/2506.06157v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于掩码语言模型的异构图学习方法MLM4HG，旨在解决现有方法在异构图学习中的泛化问题。&lt;h4&gt;背景&lt;/h4&gt;现有的异构图神经网络（HGNNs）在捕捉异构图（HGs）的结构和语义信息方面表现出色，但在跨领域和任务上的泛化能力有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以增强异构图学习的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;MLM4HG通过基于元路径的文本序列来提取异构图中的结构化和语义信息，并设计定制的文本模板，将不同的图任务统一到一个连贯的完形填空式“掩码”标记预测范式。该方法首先将不同领域的异构图转换为文本，然后结合统一任务文本形成基于异构图的语料库，并使用预训练的语言模型进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界数据集上的跨领域和多任务实验表明，MLM4HG在少样本和零样本场景下均优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;MLM4HG在异构图学习中的泛化性能显著，是一种简单而有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;The abstract of this paper is summarized as follows: This paper proposes a Masked Language Modeling-based method for heterogeneous graph learning, called MLM4HG, aiming to enhance the generalization ability of existing methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterogeneous graph neural networks (HGNNs) excel at capturing structural andsemantic information in heterogeneous graphs (HGs), while struggling togeneralize across domains and tasks. Recently, some researchers have turned tointegrating HGNNs with large language models (LLMs) for more generalizableheterogeneous graph learning. However, these approaches typically extractstructural information via HGNNs as HG tokens, and disparities in embeddingspaces between HGNNs and LLMs have been shown to bias the LLM's comprehensionof HGs. Moreover, as these HG tokens are often derived from node-level tasks,the model's ability to generalize across tasks remains limited. To this end, wepropose a simple yet effective Masked Language Modeling-based method, calledMLM4HG. MLM4HG introduces metapath-based textual sequences instead of HG tokensto extract structural and semantic information inherent in HGs, and designscustomized textual templates to unify different graph tasks into a coherentcloze-style "mask" token prediction paradigm. Specifically, MLM4HG firstconverts HGs from various domains to texts based on metapaths, and subsequentlycombines them with the unified task texts to form a HG-based corpus. Moreover,the corpus is fed into a pretrained LM for fine-tuning with a constrainedtarget vocabulary, enabling the fine-tuned LM to generalize to unseen targetHGs. Extensive cross-domain and multi-task experiments on four real-worlddatasets demonstrate the superior generalization performance of MLM4HG overstate-of-the-art methods in both few-shot and zero-shot scenarios. Our code isavailable at https://github.com/BUPT-GAMMA/MLM4HG.</description>
      <author>example@mail.com (Jinyu Yang, Cheng Yang, Shanyuan Cui, Zeyuan Guo, Liangwei Yang, Muhan Zhang, Chuan Shi)</author>
      <guid isPermaLink="false">2506.06157v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Two-dimensional Taxonomy for N-ary Knowledge Representation Learning Methods</title>
      <link>http://arxiv.org/abs/2506.05626v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了处理n元关系数据的知识超图和超关系知识图谱方法，提出了一个两维分类体系，并讨论了现有数据集、负采样策略和未来研究方向。&lt;h4&gt;背景&lt;/h4&gt;现实世界的知识可以以结构化、半结构化和非结构化数据的形式存在，知识图谱虽然能够整合异构数据源，但通常会将复杂的n元关系简化为简单的三元组，从而丢失了更高阶的关系细节。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了知识超图和超关系知识图谱，结合知识图谱和超图的优势，以更好地捕捉现实世界知识的复杂结构和角色特定的语义。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个两维分类体系，第一维根据方法分类，包括基于翻译的模型、基于张量分解的模型、基于深度神经网络的模型、基于逻辑规则的模型和基于超边扩展的模型。第二维根据模型对实体角色和位置在n元关系中的感知分类，分为无感知、位置感知和角色感知方法。&lt;h4&gt;主要发现&lt;/h4&gt;本文提供了一个全面的综述，包括知识超图和超关系知识图谱的文献，并讨论了现有的数据集、负采样策略。&lt;h4&gt;结论&lt;/h4&gt;本文总结了现有研究，并提出了未来研究的开放挑战，以激发进一步的研究工作。&lt;h4&gt;翻译&lt;/h4&gt;本文综述了处理n元关系数据的知识超图和超关系知识图谱方法，提出了一个两维分类体系：第一个维度根据方法将模型分类，即基于翻译的模型、基于张量分解的模型、基于深度神经网络的模型、基于逻辑规则的模型和基于超边扩展的模型；第二个维度根据模型对实体角色和位置在n元关系中的感知分类，分为无感知、位置感知和角色感知方法。最后，讨论了现有数据集、负采样策略，并概述了开放挑战，以激发未来的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world knowledge can take various forms, including structured,semi-structured, and unstructured data. Among these, knowledge graphs are aform of structured human knowledge that integrate heterogeneous data sourcesinto structured representations but typically reduce complex n-ary relations tosimple triples, thereby losing higher-order relational details. In contrast,hypergraphs naturally represent n-ary relations with hyperedges, which directlyconnect multiple entities together. Yet hypergraph representation learningoften overlooks entity roles in hyperedges, limiting the fine-grained semanticmodelling. To address these issues, knowledge hypergraphs and hyper-relationalknowledge graphs combine the advantages of knowledge graphs and hypergraphs tobetter capture the complex structures and role-specific semantics of real-worldknowledge. This survey provides a comprehensive review of methods handlingn-ary relational data, covering both knowledge hypergraphs and hyper-relationalknowledge graphs literatures. We propose a two-dimensional taxonomy: the firstdimension categorises models based on their methodology, i.e.,translation-based models, tensor factorisation-based models, deep neuralnetwork-based models, logic rules-based models, and hyperedge expansion-basedmodels. The second dimension classifies models according to their awareness ofentity roles and positions in n-ary relations, dividing them into aware-less,position-aware, and role-aware approaches. Finally, we discuss existingdatasets, negative sampling strategies, and outline open challenges to inspirefuture research.</description>
      <author>example@mail.com (Xiaohua Lu, Liubov Tupikina, Mehwish Alam)</author>
      <guid isPermaLink="false">2506.05626v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SIV-Bench: A Video Benchmark for Social Interaction Understanding and Reasoning</title>
      <link>http://arxiv.org/abs/2506.05425v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SIV-Bench，一个用于评估多模态大型语言模型在社交场景理解、社交状态推理和社交动态预测方面的能力的视频基准。&lt;h4&gt;背景&lt;/h4&gt;人类社交互动的丰富性和多层次性，包括多模态线索、不可观察的关系和心智状态以及动态行为，对人工智能提出了巨大挑战。&lt;h4&gt;目的&lt;/h4&gt;为了推进这一领域的研究，本文引入了SIV-Bench，旨在严格评估多模态大型语言模型（MLLMs）的能力。&lt;h4&gt;方法&lt;/h4&gt;SIV-Bench包含2,792个视频片段和8,792个由人机协同生成的问答对，数据来源于TikTok和YouTube，覆盖了广泛的视频类型、呈现风格、语言和文化背景。还包括一个用于分析不同文本线索影响的分析设置。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，模型在社交场景理解（SSU）方面表现良好，但在社交状态推理（SSR）和社交动态预测（SDP）方面存在显著困难，其中关系推理（RI）是一个瓶颈。此外，转录对话在理解复杂社交互动方面发挥了关键作用。&lt;h4&gt;结论&lt;/h4&gt;SIV-Bench通过系统地识别当前MLLMs的优势和局限性，为更智能的AI发展提供了关键见解。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了SIV-Bench，这是一个用于严格评估多模态大型语言模型（MLLMs）在社交场景理解（SSU）、社交状态推理（SSR）和社交动态预测（SDP）方面能力的视频基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rich and multifaceted nature of human social interaction, encompassingmultimodal cues, unobservable relations and mental states, and dynamicalbehavior, presents a formidable challenge for artificial intelligence. Toadvance research in this area, we introduce SIV-Bench, a novel video benchmarkfor rigorously evaluating the capabilities of Multimodal Large Language Models(MLLMs) across Social Scene Understanding (SSU), Social State Reasoning (SSR),and Social Dynamics Prediction (SDP). SIV-Bench features 2,792 video clips and8,792 meticulously generated question-answer pairs derived from a human-LLMcollaborative pipeline. It is originally collected from TikTok and YouTube,covering a wide range of video genres, presentation styles, and linguistic andcultural backgrounds. It also includes a dedicated setup for analyzing theimpact of different textual cues-original on-screen text, added dialogue, or notext. Our comprehensive experiments on leading MLLMs reveal that while modelsadeptly handle SSU, they significantly struggle with SSR and SDP, whereRelation Inference (RI) is an acute bottleneck, as further examined in ouranalysis. Our study also confirms the critical role of transcribed dialogue inaiding comprehension of complex social interactions. By systematicallyidentifying current MLLMs' strengths and limitations, SIV-Bench offers crucialinsights to steer the development of more socially intelligent AI. The datasetand code are available at https://kfq20.github.io/sivbench/.</description>
      <author>example@mail.com (Fanqi Kong, Weiqin Zu, Xinyu Chen, Yaodong Yang, Song-Chun Zhu, Xue Feng)</author>
      <guid isPermaLink="false">2506.05425v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Mixture-of-Experts Meets In-Context Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.05426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为T2MIR的创新框架，用于解决在上下文强化学习（ICRL）中的多模态数据和决策任务异质性挑战，通过引入混合专家（MoE）架构和对比学习方法，显著提升了ICRL的性能。&lt;h4&gt;背景&lt;/h4&gt;在上下文强化学习（ICRL）中，将强化学习代理适应下游任务面临两个主要挑战：状态-动作-奖励数据的内在多模态性和决策任务的多样性和异质性。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为T2MIR的框架，以解决上述挑战，并提升ICRL的性能。&lt;h4&gt;方法&lt;/h4&gt;T2MIR框架引入了MoE架构到基于transformer的决策模型中，包括：1. 替换前馈层为两个并行层：一个token-wise MoE，用于捕捉不同模态输入token的语义；一个task-wise MoE，用于将不同任务路由到专门的专家，以管理广泛的任务分布并减轻梯度冲突。2. 引入对比学习方法，最大化任务与其路由表示之间的互信息，以更精确地捕获任务相关信息。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，T2MIR显著提高了ICRL的学习能力，并优于多种基线方法。&lt;h4&gt;结论&lt;/h4&gt;T2MIR为ICRL带来了MoE的潜力和前景，提供了一种简单且可扩展的架构增强，使ICRL更接近语言和视觉社区的研究成果。&lt;h4&gt;翻译&lt;/h4&gt;In-context reinforcement learning (ICRL) has emerged as a promising paradigm for adapting RL agents to downstream tasks through prompt conditioning. However, two notable challenges remain in fully harnessing in-context learning within RL domains: the intrinsic multi-modality of the state-action-reward data and the diverse, heterogeneous nature of decision tasks. To tackle these challenges, we propose T2MIR (Token- and Task-wise MoE for In-context RL), an innovative framework that introduces architectural advances of mixture-of-experts (MoE) into transformer-based decision models. T2MIR substitutes the feedforward layer with two parallel layers: a token-wise MoE that captures distinct semantics of input tokens across multiple modalities, and a task-wise MoE that routes diverse tasks to specialized experts for managing a broad task distribution with alleviated gradient conflicts. To enhance task-wise routing, we introduce a contrastive learning method that maximizes the mutual information between the task and its router representation, enabling more precise capture of task-relevant information. The outputs of two MoE components are concatenated and fed into the next layer. Comprehensive experiments show that T2MIR significantly facilitates in-context learning capacity and outperforms various types of baselines. We bring the potential and promise of MoE to ICRL, offering a simple and scalable architectural enhancement to advance ICRL one step closer toward achievements in language and vision communities. Our code is available at https://github.com/NJU-RL/T2MIR.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In-context reinforcement learning (ICRL) has emerged as a promising paradigmfor adapting RL agents to downstream tasks through prompt conditioning.However, two notable challenges remain in fully harnessing in-context learningwithin RL domains: the intrinsic multi-modality of the state-action-reward dataand the diverse, heterogeneous nature of decision tasks. To tackle thesechallenges, we propose \textbf{T2MIR} (\textbf{T}oken- and \textbf{T}ask-wise\textbf{M}oE for \textbf{I}n-context \textbf{R}L), an innovative framework thatintroduces architectural advances of mixture-of-experts (MoE) intotransformer-based decision models. T2MIR substitutes the feedforward layer withtwo parallel layers: a token-wise MoE that captures distinct semantics of inputtokens across multiple modalities, and a task-wise MoE that routes diversetasks to specialized experts for managing a broad task distribution withalleviated gradient conflicts. To enhance task-wise routing, we introduce acontrastive learning method that maximizes the mutual information between thetask and its router representation, enabling more precise capture oftask-relevant information. The outputs of two MoE components are concatenatedand fed into the next layer. Comprehensive experiments show that T2MIRsignificantly facilitates in-context learning capacity and outperforms varioustypes of baselines. We bring the potential and promise of MoE to ICRL, offeringa simple and scalable architectural enhancement to advance ICRL one step closertoward achievements in language and vision communities. Our code is availableat https://github.com/NJU-RL/T2MIR.</description>
      <author>example@mail.com (Wenhao Wu, Fuhong Liu, Haoru Li, Zican Hu, Daoyi Dong, Chunlin Chen, Zhi Wang)</author>
      <guid isPermaLink="false">2506.05426v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Spatial Language Maps for Robot Navigation and Manipulation</title>
      <link>http://arxiv.org/abs/2506.06862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted to International Journal of Robotics Research (IJRR). 24  pages, 18 figures. The paper contains texts from VLMaps(arXiv:2210.05714) and  AVLMaps(arXiv:2303.07522). The project page is https://mslmaps.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为多模态空间语言地图的新方法，该方法通过融合预训练的多模态特征与环境的三维重建来提高导航代理的观察与对象或事件描述之间的匹配。&lt;h4&gt;背景&lt;/h4&gt;现有的方法与环境地图脱节，缺乏几何地图的空间精确性，或忽略了除视觉之外的额外模态信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够融合预训练的多模态特征与环境三维重建的空间地图表示，以解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;使用标准探索自主构建这些地图，并创建了两种地图实例：视觉语言地图（VLMaps）和扩展的音频视觉语言地图（AVLMaps），通过添加音频信息获得。&lt;h4&gt;主要发现&lt;/h4&gt;VLMaps可以将自然语言命令直接转换为地图中定位的开放词汇空间目标，并能跨不同机器人实体共享以生成定制的障碍物地图。AVLMaps通过融合来自预训练的多模态基础模型的特征，引入了统一的3D空间表示，集成了音频、视觉和语言线索。这些地图使机器人能够将多模态目标查询（如文本、图像或音频片段）定位到空间位置进行导航，并在模糊环境中显著提高目标区分度。&lt;h4&gt;结论&lt;/h4&gt;在模拟和现实世界的实验中，多模态空间语言地图实现了零样本空间和多模态目标导航，在模糊场景中的召回率提高了50%，这些能力适用于移动机器人和桌面操作器，支持由视觉、音频和空间线索引导的导航和交互。&lt;h4&gt;翻译&lt;/h4&gt;Grounding language to a navigating agent's observations can leverage pretrained multimodal foundation models to match perceptions to object or event descriptions. However, previous approaches remain disconnected from environment mapping, lack the spatial precision of geometric maps, or neglect additional modality information beyond vision. To address this, we propose multimodal spatial language maps as a spatial map representation that fuses pretrained multimodal features with a 3D reconstruction of the environment. We build these maps autonomously using standard exploration. We present two instances of our maps, which are visual-language maps (VLMaps) and their extension to audio-visual-language maps (AVLMaps) obtained by adding audio information. When combined with large language models (LLMs), VLMaps can (i) translate natural language commands into open-vocabulary spatial goals (e.g., 'in between the sofa and TV') directly localized in the map, and (ii) be shared across different robot embodiments to generate tailored obstacle maps on demand. Building upon the capabilities above, AVLMaps extend VLMaps by introducing a unified 3D spatial representation integrating audio, visual, and language cues through the fusion of features from pretrained multimodal foundation models. This enables robots to ground multimodal goal queries (e.g., text, images, or audio snippets) to spatial locations for navigation. Additionally, the incorporation of diverse sensory inputs significantly enhances goal disambiguation in ambiguous environments. Experiments in simulation and real-world settings demonstrate that our multimodal spatial language maps enable zero-shot spatial and multimodal goal navigation and improve recall by 50% in ambiguous scenarios. These capabilities extend to mobile robots and tabletop manipulators, supporting navigation and interaction guided by visual, audio, and spatial cues.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grounding language to a navigating agent's observations can leveragepretrained multimodal foundation models to match perceptions to object or eventdescriptions. However, previous approaches remain disconnected from environmentmapping, lack the spatial precision of geometric maps, or neglect additionalmodality information beyond vision. To address this, we propose multimodalspatial language maps as a spatial map representation that fuses pretrainedmultimodal features with a 3D reconstruction of the environment. We build thesemaps autonomously using standard exploration. We present two instances of ourmaps, which are visual-language maps (VLMaps) and their extension toaudio-visual-language maps (AVLMaps) obtained by adding audio information. Whencombined with large language models (LLMs), VLMaps can (i) translate naturallanguage commands into open-vocabulary spatial goals (e.g., "in between thesofa and TV") directly localized in the map, and (ii) be shared acrossdifferent robot embodiments to generate tailored obstacle maps on demand.Building upon the capabilities above, AVLMaps extend VLMaps by introducing aunified 3D spatial representation integrating audio, visual, and language cuesthrough the fusion of features from pretrained multimodal foundation models.This enables robots to ground multimodal goal queries (e.g., text, images, oraudio snippets) to spatial locations for navigation. Additionally, theincorporation of diverse sensory inputs significantly enhances goaldisambiguation in ambiguous environments. Experiments in simulation andreal-world settings demonstrate that our multimodal spatial language mapsenable zero-shot spatial and multimodal goal navigation and improve recall by50% in ambiguous scenarios. These capabilities extend to mobile robots andtabletop manipulators, supporting navigation and interaction guided by visual,audio, and spatial cues.</description>
      <author>example@mail.com (Chenguang Huang, Oier Mees, Andy Zeng, Wolfram Burgard)</author>
      <guid isPermaLink="false">2506.06862v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>EASG-Bench: Video Q&amp;A Benchmark with Egocentric Action Scene Graphs</title>
      <link>http://arxiv.org/abs/2506.05787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了EASG-Bench，一个用于自摄视频问答的基准，其中的问答对由时空定位的动态场景图生成，该图捕捉了演员、动作和物体之间的复杂关系。&lt;h4&gt;背景&lt;/h4&gt;在自摄视频中，问答系统需要理解场景中的动态关系。&lt;h4&gt;目的&lt;/h4&gt;评估多种语言和视频大型语言模型（video-LLMs）在EASG-Bench上的性能，并识别视频理解领域的研究差距。&lt;h4&gt;方法&lt;/h4&gt;提出了一种系统性的评估框架，并在此基准上评估了多种语言和视频大型语言模型。&lt;h4&gt;主要发现&lt;/h4&gt;观察到了语言和视频大型语言模型之间存在的性能差距，特别是在关注时间顺序的问题上，这表明在长上下文视频理解领域存在研究差距。&lt;h4&gt;结论&lt;/h4&gt;为了促进发现的可重复性和进一步研究的便利，基准和配套代码可在GitHub上获取。&lt;h4&gt;翻译&lt;/h4&gt;We introduce EASG-Bench, a question-answering benchmark for egocentric videos where the question-answering pairs are created from spatio-temporally grounded dynamic scene graphs capturing intricate relationships among actors, actions, and objects. We propose a systematic evaluation framework and evaluate several language-only and video large language models (video-LLMs) on this benchmark. We observe a performance gap in language-only and video-LLMs, especially on questions focusing on temporal ordering, thus identifying a research gap in the area of long-context video understanding. To promote the reproducibility of our findings and facilitate further research, the benchmark and accompanying code are available at the following GitHub page: https://github.com/fpv-iplab/EASG-bench.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce EASG-Bench, a question-answering benchmark for egocentric videoswhere the question-answering pairs are created from spatio-temporally groundeddynamic scene graphs capturing intricate relationships among actors, actions,and objects. We propose a systematic evaluation framework and evaluate severallanguage-only and video large language models (video-LLMs) on this benchmark.We observe a performance gap in language-only and video-LLMs, especially onquestions focusing on temporal ordering, thus identifying a research gap in thearea of long-context video understanding. To promote the reproducibility of ourfindings and facilitate further research, the benchmark and accompanying codeare available at the following GitHub page:https://github.com/fpv-iplab/EASG-bench.</description>
      <author>example@mail.com (Ivan Rodin, Tz-Ying Wu, Kyle Min, Sharath Nittur Sridhar, Antonino Furnari, Subarna Tripathi, Giovanni Maria Farinella)</author>
      <guid isPermaLink="false">2506.05787v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Flow-Attentional Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.06127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为flow attention的新方法，用于改进图神经网络（GNNs）在处理具有物理资源流动（如电力电流或交通流量）的图结构数据时的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的GNNs没有考虑图中与物理资源流动相关的守恒定律，这可能导致模型性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出flow attention以适应现有图注意力机制，以满足基尔霍夫第一定律。&lt;h4&gt;方法&lt;/h4&gt;通过修改图注意力机制，flow attention能够处理具有物理资源流动的图结构数据。&lt;h4&gt;主要发现&lt;/h4&gt;flow attention增强了基于注意力的GNNs在图级分类和回归任务上的性能，并能够区分一些非同构图，这些图在标准注意力机制下无法区分。&lt;h4&gt;结论&lt;/h4&gt;flow attention是一种有效的改进方法，可以提高GNNs在处理具有物理资源流动的图结构数据时的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have become essential for learning from graph-structured data. However, existing GNNs do not consider the conservation law inherent in graphs associated with a flow of physical resources, such as electrical current in power grids or traffic in transportation networks, which can lead to reduced model performance. To address this, we propose flow attention, which adapts existing graph attention mechanisms to satisfy Kirchhoff's first law. Furthermore, we discuss how this modification influences the expressivity and identify sets of non-isomorphic graphs that can be discriminated by flow attention but not by standard attention. Through extensive experiments on two flow graph datasets (electronic circuits and power grids), we demonstrate that flow attention enhances the performance of attention-based GNNs on both graph-level classification and regression tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have become essential for learning fromgraph-structured data. However, existing GNNs do not consider the conservationlaw inherent in graphs associated with a flow of physical resources, such aselectrical current in power grids or traffic in transportation networks, whichcan lead to reduced model performance. To address this, we propose flowattention, which adapts existing graph attention mechanisms to satisfyKirchhoff\'s first law. Furthermore, we discuss how this modificationinfluences the expressivity and identify sets of non-isomorphic graphs that canbe discriminated by flow attention but not by standard attention. Throughextensive experiments on two flow graph datasets (electronic circuits and powergrids), we demonstrate that flow attention enhances the performance ofattention-based GNNs on both graph-level classification and regression tasks.</description>
      <author>example@mail.com (Pascal Plettenberg, Dominik Köhler, Bernhard Sick, Josephine M. Thomas)</author>
      <guid isPermaLink="false">2506.06127v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>EndoARSS: Adapting Spatially-Aware Foundation Model for Efficient Activity Recognition and Semantic Segmentation in Endoscopic Surgery</title>
      <link>http://arxiv.org/abs/2506.06830v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Advanced Intelligent Systems&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EndoARSS的新型多任务学习框架，用于内窥镜手术活动的识别和语义分割，通过提高准确性和鲁棒性来增强内窥镜手术系统的性能。&lt;h4&gt;背景&lt;/h4&gt;内窥镜手术是机器人辅助微创手术的金标准，但在手术场景的复杂性和图像特征混淆的情况下，传统的深度学习模型难以实现理想性能。&lt;h4&gt;目的&lt;/h4&gt;为了解决传统深度学习模型在跨活动干扰问题上的局限性，提出了一种基于多任务学习的框架，以提高整体任务性能。&lt;h4&gt;方法&lt;/h4&gt;EndoARSS框架基于DINOv2基础模型，结合了低秩适应和任务高效共享低秩适配器，引入了空间感知多尺度注意力机制，并创建了三个新的数据集MTLESD、MTLEndovis和MTLEndovis-Gen，用于评估框架的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，EndoARSS在多个基准测试中实现了显著性能提升，与现有模型相比，在准确性和鲁棒性方面均有显著提高。&lt;h4&gt;结论&lt;/h4&gt;EndoARSS有潜力推动AI驱动的内窥镜手术系统的发展，为提高手术安全和效率提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：内镜手术是机器人辅助微创手术的金标准，它为早期疾病检测和精确干预提供了显著优势。然而，手术场景的复杂性，包括不同手术活动场景中的高度可变性和目标与背景之间的混淆图像特征，为手术环境理解带来了挑战。传统的深度学习模型通常难以处理跨活动干扰，导致下游任务性能不佳。为了解决这一局限性，我们探索了多任务学习，它利用任务之间的相关特征来提高整体任务性能。在本文中，我们提出了一种名为EndoARSS的新型多任务学习框架，专门针对内镜手术活动识别和语义分割。基于DINOv2基础模型，我们的方法结合了低秩适应以促进高效的微调，同时引入了任务高效共享低秩适配器以缓解不同任务之间的梯度冲突。此外，我们引入了空间感知多尺度注意力机制，通过实现全局信息的跨空间学习来增强特征表示的区分度。为了评估我们框架的有效性，我们提出了三个新的数据集MTLESD、MTLEndovis和MTLEndovis-Gen，这些数据集针对内镜手术场景定制，并提供了活动识别和语义分割任务的详细注释。大量的实验表明，EndoARSS在多个基准测试中实现了显著的性能，与现有模型相比，在准确性和鲁棒性方面均有显著提高。这些结果强调了EndoARSS在推进AI驱动的内镜手术系统方面的潜力，为提高手术安全和效率提供了有价值的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Endoscopic surgery is the gold standard for robotic-assisted minimallyinvasive surgery, offering significant advantages in early disease detectionand precise interventions. However, the complexity of surgical scenes,characterized by high variability in different surgical activity scenarios andconfused image features between targets and the background, presents challengesfor surgical environment understanding. Traditional deep learning models oftenstruggle with cross-activity interference, leading to suboptimal performance ineach downstream task. To address this limitation, we explore multi-tasklearning, which utilizes the interrelated features between tasks to enhanceoverall task performance. In this paper, we propose EndoARSS, a novelmulti-task learning framework specifically designed for endoscopy surgeryactivity recognition and semantic segmentation. Built upon the DINOv2foundation model, our approach integrates Low-Rank Adaptation to facilitateefficient fine-tuning while incorporating Task Efficient Shared Low-RankAdapters to mitigate gradient conflicts across diverse tasks. Additionally, weintroduce the Spatially-Aware Multi-Scale Attention that enhances featurerepresentation discrimination by enabling cross-spatial learning of globalinformation. In order to evaluate the effectiveness of our framework, wepresent three novel datasets, MTLESD, MTLEndovis and MTLEndovis-Gen, tailoredfor endoscopic surgery scenarios with detailed annotations for both activityrecognition and semantic segmentation tasks. Extensive experiments demonstratethat EndoARSS achieves remarkable performance across multiple benchmarks,significantly improving both accuracy and robustness in comparison to existingmodels. These results underscore the potential of EndoARSS to advance AI-drivenendoscopic surgical systems, offering valuable insights for enhancing surgicalsafety and efficiency.</description>
      <author>example@mail.com (Guankun Wang, Rui Tang, Mengya Xu, Long Bai, Huxin Gao, Hongliang Ren)</author>
      <guid isPermaLink="false">2506.06830v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>LLM-Symbolic Integration for Robust Temporal Tabular Reasoning</title>
      <link>http://arxiv.org/abs/2506.05746v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACL Findings 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了针对时间表问答的挑战，并提出了一种名为TempTabQA-C的数据集和符号中间表示方法，以提高大型语言模型（LLMs）在时间表问答任务中的表现。&lt;h4&gt;背景&lt;/h4&gt;时间表问答对LLMs来说是一个重大挑战，因为需要在对结构化数据的强大推理能力，而传统的提示方法通常不足以应对这种挑战。&lt;h4&gt;目的&lt;/h4&gt;克服传统方法在记忆、对表大小的敏感性和复杂查询性能降低等方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;引入了TempTabQA-C数据集，用于系统性和可控的评估，以及将表格转换为数据库模式的符号中间表示。这种方法允许LLMs生成和执行SQL查询，从而增强泛化能力和减轻偏差。通过结合自适应的少样本提示和上下文定制的示例，该方法实现了更高的鲁棒性、可扩展性和性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在关键挑战方面取得了持续改进，为LLMs进行鲁棒的时间推理设定了新的基准。&lt;h4&gt;结论&lt;/h4&gt;TempTabQA-C数据集和符号中间表示方法能够显著提高LLMs在时间表问答任务中的表现。&lt;h4&gt;翻译&lt;/h4&gt;Temporal tabular question answering presents a significant challenge for Large Language Models (LLMs), requiring robust reasoning over structured data, which is a task where traditional prompting methods often fall short. These methods face challenges such as memorization, sensitivity to table size, and reduced performance on complex queries. To overcome these limitations, we introduce TempTabQA-C, a synthetic dataset designed for systematic and controlled evaluations, alongside a symbolic intermediate representation that transforms tables into database schemas. This structured approach allows LLMs to generate and execute SQL queries, enhancing generalization and mitigating biases. By incorporating adaptive few-shot prompting with contextually tailored examples, our method achieves superior robustness, scalability, and performance. Experimental results consistently highlight improvements across key challenges, setting a new benchmark for robust temporal reasoning with LLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal tabular question answering presents a significant challenge forLarge Language Models (LLMs), requiring robust reasoning over structured data,which is a task where traditional prompting methods often fall short. Thesemethods face challenges such as memorization, sensitivity to table size, andreduced performance on complex queries. To overcome these limitations, weintroduce TempTabQA-C, a synthetic dataset designed for systematic andcontrolled evaluations, alongside a symbolic intermediate representation thattransforms tables into database schemas. This structured approach allows LLMsto generate and execute SQL queries, enhancing generalization and mitigatingbiases. By incorporating adaptive few-shot prompting with contextually tailoredexamples, our method achieves superior robustness, scalability, andperformance. Experimental results consistently highlight improvements acrosskey challenges, setting a new benchmark for robust temporal reasoning withLLMs.</description>
      <author>example@mail.com (Atharv Kulkarni, Kushagra Dixit, Vivek Srikumar, Dan Roth, Vivek Gupta)</author>
      <guid isPermaLink="false">2506.05746v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion-Based Hierarchical Graph Neural Networks for Simulating Nonlinear Solid Mechanics</title>
      <link>http://arxiv.org/abs/2506.06045v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ROBIN的新型学习模拟器，用于在非结构化网格上模拟物理系统，该模拟器通过并行推理方案和分层图神经网络，解决了传统模拟器在捕捉全局现象和长期预测中的局限性。&lt;h4&gt;背景&lt;/h4&gt;基于图的学习模拟器在模拟物理系统方面具有速度和泛化能力的优势，但它们在捕捉全局现象和长期预测方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出ROBIN以解决现有模拟器在模拟物理系统时的局限性，如捕捉全局现象和长期预测中的误差积累。&lt;h4&gt;方法&lt;/h4&gt;ROBIN集成了两个关键创新：(i) 滚动扩散，通过在时间窗口内重叠去噪步骤来分摊基于扩散的细化成本；(ii) 基于代数多重网格粗化的分层图神经网络，实现不同网格分辨率的跨尺度消息传递。&lt;h4&gt;主要发现&lt;/h4&gt;ROBIN在二维和三维固体力学基准测试中表现出色，实现了最先进的精度，并且与标准扩散模拟器相比，推理时间减少了高达一个数量级。&lt;h4&gt;结论&lt;/h4&gt;ROBIN是一种高效且准确的学习模拟器，能够有效地模拟物理系统，特别是在捕捉全局现象和长期预测方面具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;Graph-based learned simulators have emerged as a promising approach for simulating physical systems on unstructured meshes, offering speed and generalization across diverse geometries. However, they often struggle with capturing global phenomena, such as bending or long-range correlations, and suffer from error accumulation over long rollouts due to their reliance on local message passing and direct next-step prediction. We address these limitations by introducing the Rolling Diffusion-Batched Inference Network (ROBIN), a novel learned simulator that integrates two key innovations: (i) Rolling Diffusion, a parallelized inference scheme that amortizes the cost of diffusion-based refinement across physical time steps by overlapping denoising steps across a temporal window. (ii) A Hierarchical Graph Neural Network built on algebraic multigrid coarsening, enabling multiscale message passing across different mesh resolutions. This architecture, implemented via Algebraic-hierarchical Message Passing Networks, captures both fine-scale local dynamics and global structural effects critical for phenomena like beam bending or multi-body contact. We validate ROBIN on challenging 2D and 3D solid mechanics benchmarks involving geometric, material, and contact nonlinearities. ROBIN achieves state-of-the-art accuracy on all tasks, substantially outperforming existing next-step learned simulators while reducing inference time by up to an order of magnitude compared to standard diffusion simulators.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-based learned simulators have emerged as a promising approach forsimulating physical systems on unstructured meshes, offering speed andgeneralization across diverse geometries. However, they often struggle withcapturing global phenomena, such as bending or long-range correlations, andsuffer from error accumulation over long rollouts due to their reliance onlocal message passing and direct next-step prediction. We address theselimitations by introducing the Rolling Diffusion-Batched Inference Network(ROBIN), a novel learned simulator that integrates two key innovations: (i)Rolling Diffusion, a parallelized inference scheme that amortizes the cost ofdiffusion-based refinement across physical time steps by overlapping denoisingsteps across a temporal window. (ii) A Hierarchical Graph Neural Network builton algebraic multigrid coarsening, enabling multiscale message passing acrossdifferent mesh resolutions. This architecture, implemented viaAlgebraic-hierarchical Message Passing Networks, captures both fine-scale localdynamics and global structural effects critical for phenomena like beam bendingor multi-body contact. We validate ROBIN on challenging 2D and 3D solidmechanics benchmarks involving geometric, material, and contact nonlinearities.ROBIN achieves state-of-the-art accuracy on all tasks, substantiallyoutperforming existing next-step learned simulators while reducing inferencetime by up to an order of magnitude compared to standard diffusion simulators.</description>
      <author>example@mail.com (Tobias Würth, Niklas Freymuth, Gerhard Neumann, Luise Kärger)</author>
      <guid isPermaLink="false">2506.06045v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Dream to Generalize: Zero-Shot Model-Based Reinforcement Learning for Unseen Visual Distractions</title>
      <link>http://arxiv.org/abs/2506.05419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AAAI 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Dr. G的新型自监督方法，用于零样本MBRL，以提高模型在视觉干扰下的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;尽管现有的MBRL算法在训练观察中表现良好，但面对观察中的视觉干扰（如云、阴影和光）时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，使模型能够在存在视觉干扰的观察中保持鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;Dr. G使用双重对比学习来训练编码器和世界模型，有效捕捉多视图数据增强中的任务相关特征。此外，还引入了一种当前状态逆动力学模型，帮助世界模型更好地理解时间结构。&lt;h4&gt;主要发现&lt;/h4&gt;Dr. G在简单背景上训练后，在DeepMind Control suite的复杂自然视频背景和Robosuite的随机化环境中测试，性能分别比先前工作提高了117%和14%。&lt;h4&gt;结论&lt;/h4&gt;Dr. G能够提高世界模型对视觉干扰的鲁棒性，并在实际应用中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Model-based reinforcement learning (MBRL) has been used to efficiently solve vision-based control tasks in high-dimensional image observations. Although recent MBRL algorithms perform well in trained observations, they fail when faced with visual distractions in observations. These task-irrelevant distractions (e.g., clouds, shadows, and light) may be constantly present in real-world scenarios. In this study, we propose a novel self-supervised method, Dream to Generalize (Dr. G), for zero-shot MBRL. Dr. G trains its encoder and world model with dual contrastive learning which efficiently captures task-relevant features among multi-view data augmentations. We also introduce a current state inverse dynamics model that helps the world model to better understand the temporal structure. The proposed methods can enhance the robustness of the world model against visual distractions. To evaluate the generalization performance, we first train Dr. G on simple backgrounds and then test it on complex natural video backgrounds in the DeepMind Control suite, and the randomizing environments in Robosuite. Dr. G yields a performance improvement of 117% and 14% over prior works, respectively. Our code is open-sourced and available at https://github.com/JeongsooHa/DrG.git&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model-based reinforcement learning (MBRL) has been used to efficiently solvevision-based control tasks in highdimensional image observations. Althoughrecent MBRL algorithms perform well in trained observations, they fail whenfaced with visual distractions in observations. These task-irrelevantdistractions (e.g., clouds, shadows, and light) may be constantly present inreal-world scenarios. In this study, we propose a novel self-supervised method,Dream to Generalize (Dr. G), for zero-shot MBRL. Dr. G trains its encoder andworld model with dual contrastive learning which efficiently capturestask-relevant features among multi-view data augmentations. We also introduce arecurrent state inverse dynamics model that helps the world model to betterunderstand the temporal structure. The proposed methods can enhance therobustness of the world model against visual distractions. To evaluate thegeneralization performance, we first train Dr. G on simple backgrounds and thentest it on complex natural video backgrounds in the DeepMind Control suite, andthe randomizing environments in Robosuite. Dr. G yields a performanceimprovement of 117% and 14% over prior works, respectively. Our code isopen-sourced and available at https://github.com/JeongsooHa/DrG.git</description>
      <author>example@mail.com (Jeongsoo Ha, Kyungsoo Kim, Yusung Kim)</author>
      <guid isPermaLink="false">2506.05419v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Hi-LSplat: Hierarchical 3D Language Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.06822v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Hi-LSplat的视图一致性的层次语言高斯分层模型，用于3D开放词汇查询，以解决现有3DGS模型中视图不一致性和开放词汇挑战导致的对象和关系描述不一致问题。&lt;h4&gt;背景&lt;/h4&gt;现有的基于3DGS的模型使用视图相关的2D基础模型来细化3D语义，但缺乏统一的3D表示，导致视图不一致。同时，开放词汇挑战导致对象和关系描述的不一致性，阻碍了层次语义理解。&lt;h4&gt;目的&lt;/h4&gt;提出Hi-LSplat模型，以实现视图一致的3D层次语义，并解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;通过构建一个3D层次语义树并使用分层实例聚类将2D特征提升到3D特征，解决由2D语义特征引起的视图不一致问题。此外，引入实例级和部分级的对比损失以捕获全方位的层次语义表示。还构建了两个层次语义数据集以更好地评估模型区分不同语义层级的能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Hi-LSplat在3D开放词汇分割和定位方面具有优越性，其强大的性能在层次语义数据集上突出了其在3D场景中捕捉复杂层次语义的能力。&lt;h4&gt;结论&lt;/h4&gt;Hi-LSplat模型能够有效解决3D开放词汇查询中的视图不一致性和开放词汇挑战，提高了3D语义理解和定位的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling 3D language fields with Gaussian Splatting for open-ended languagequeries has recently garnered increasing attention. However, recent 3DGS-basedmodels leverage view-dependent 2D foundation models to refine 3D semantics butlack a unified 3D representation, leading to view inconsistencies.Additionally, inherent open-vocabulary challenges cause inconsistencies inobject and relational descriptions, impeding hierarchical semanticunderstanding. In this paper, we propose Hi-LSplat, a view-consistentHierarchical Language Gaussian Splatting work for 3D open-vocabulary querying.To achieve view-consistent 3D hierarchical semantics, we first lift 2D featuresto 3D features by constructing a 3D hierarchical semantic tree with layeredinstance clustering, which addresses the view inconsistency issue caused by 2Dsemantic features. Besides, we introduce instance-wise and part-wisecontrastive losses to capture all-sided hierarchical semantic representations.Notably, we construct two hierarchical semantic datasets to better assess themodel's ability to distinguish different semantic levels. Extensive experimentshighlight our method's superiority in 3D open-vocabulary segmentation andlocalization. Its strong performance on hierarchical semantic datasetsunderscores its ability to capture complex hierarchical semantics within 3Dscenes.</description>
      <author>example@mail.com (Chenlu Zhan, Yufei Zhang, Gaoang Wang, Hongwei Wang)</author>
      <guid isPermaLink="false">2506.06822v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>FRAME: Pre-Training Video Feature Representations via Anticipation and Memory</title>
      <link>http://arxiv.org/abs/2506.05543v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为FRAME的视频帧编码器，用于密集视频理解任务，如对象跟踪和语义分割。&lt;h4&gt;背景&lt;/h4&gt;现有的视频编码器在处理密集视频理解任务时存在不足，如缺乏时间感知或性能低于图像编码器。&lt;h4&gt;目的&lt;/h4&gt;提出FRAME以解决现有方法在密集预测任务中的不足，使其能够生成时间一致且空间密集的特征。&lt;h4&gt;方法&lt;/h4&gt;FRAME通过自监督学习，预测当前和未来的DINO补丁特征，从而实现空间精确和时间一致的表现。&lt;h4&gt;主要发现&lt;/h4&gt;FRAME是第一个利用基于图像的模型进行密集预测且在需要精细视觉对应任务上超越它们的视频编码器。&lt;h4&gt;结论&lt;/h4&gt;FRAME在六个密集预测任务上表现优于图像编码器和现有的自监督视频模型，同时保持了紧凑的架构，适用于多种下游应用。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Dense video prediction tasks, such as object tracking and semantic segmentation, require video encoders that generate temporally consistent, spatially dense features for every frame. However, existing approaches fall short: image encoders like DINO or CLIP lack temporal awareness, while video models such as VideoMAE underperform compared to image encoders on dense prediction tasks. We address this gap with FRAME, a self-supervised video frame encoder tailored for dense video understanding. FRAME learns to predict current and future DINO patch features from past and present RGB frames, leading to spatially precise and temporally coherent representations. To our knowledge, FRAME is the first video encoder to leverage image-based models for dense prediction while outperforming them on tasks requiring fine-grained visual correspondence. As an auxiliary capability, FRAME aligns its class token with CLIP's semantic space, supporting language-driven tasks such as video classification. We evaluate FRAME across six dense prediction tasks on seven datasets, where it consistently outperforms image encoders and existing self-supervised video models. Despite its versatility, FRAME maintains a compact architecture suitable for a range of downstream applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dense video prediction tasks, such as object tracking and semanticsegmentation, require video encoders that generate temporally consistent,spatially dense features for every frame. However, existing approaches fallshort: image encoders like DINO or CLIP lack temporal awareness, while videomodels such as VideoMAE underperform compared to image encoders on denseprediction tasks. We address this gap with FRAME, a self-supervised video frameencoder tailored for dense video understanding. FRAME learns to predict currentand future DINO patch features from past and present RGB frames, leading tospatially precise and temporally coherent representations. To our knowledge,FRAME is the first video encoder to leverage image-based models for denseprediction while outperforming them on tasks requiring fine-grained visualcorrespondence. As an auxiliary capability, FRAME aligns its class token withCLIP's semantic space, supporting language-driven tasks such as videoclassification. We evaluate FRAME across six dense prediction tasks on sevendatasets, where it consistently outperforms image encoders and existingself-supervised video models. Despite its versatility, FRAME maintains acompact architecture suitable for a range of downstream applications.</description>
      <author>example@mail.com (Sethuraman TV, Savya Khosla, Vignesh Srinivasakumar, Jiahui Huang, Seoung Wug Oh, Simon Jenni, Derek Hoiem, Joon-Young Lee)</author>
      <guid isPermaLink="false">2506.05543v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>On Measuring Long-Range Interactions in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.05971v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了图神经网络中的长距离图任务问题，提出了一种图操作的范围度量方法，并通过合成实验进行验证。&lt;h4&gt;背景&lt;/h4&gt;长距离图任务，即依赖于远距离节点间交互的任务，是图神经网络研究中的一个开放性问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决长距离图任务问题，论文旨在提出一种更原则性的方法来描述长距离问题。&lt;h4&gt;方法&lt;/h4&gt;论文将长距离交互形式化，引入了图上的操作范围度量，并通过合成实验进行了验证。接着，利用该方法对常用任务和架构进行考察，讨论其长距离能力的实际程度。&lt;h4&gt;主要发现&lt;/h4&gt;论文提出的方法有助于定义和解决图上的长距离问题，并且该范围度量将有助于评估新的数据集和架构。&lt;h4&gt;结论&lt;/h4&gt;论文的研究推进了长距离图任务问题的定义和解决，并为评估新的数据集和架构提供了有价值的工具。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies the long-range graph tasks in graph neural networks, proposes a range measurement method for operators on graphs, and validates it with synthetic experiments. The paper aims to propose a more principled approach to describe the long-range problem. By formalizing long-range interactions in graph tasks, the paper introduces a range measure for operators on graphs and validates it with synthetic experiments. Then, using this measure, the paper examines commonly used tasks and architectures, and discusses the extent to which they are actually long-range. We believe that our work advances efforts to define and address the long-range problem on graphs, and that our range measure will aid the evaluation of new datasets and architectures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-range graph tasks -- those dependent on interactions between distantnodes -- are an open problem in graph neural network research. Real-worldbenchmark tasks, especially the Long Range Graph Benchmark, have become popularfor validating the long-range capability of proposed architectures. However,this is an empirical approach that lacks both robustness and theoreticalunderpinning; a more principled characterization of the long-range problem isrequired. To bridge this gap, we formalize long-range interactions in graphtasks, introduce a range measure for operators on graphs, and validate it withsynthetic experiments. We then leverage our measure to examine commonly usedtasks and architectures, and discuss to what extent they are, in fact,long-range. We believe our work advances efforts to define and address thelong-range problem on graphs, and that our range measure will aid evaluation ofnew datasets and architectures.</description>
      <author>example@mail.com (Jacob Bamberger, Benjamin Gutteridge, Scott le Roux, Michael M. Bronstein, Xiaowen Dong)</author>
      <guid isPermaLink="false">2506.05971v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>StARS DCM: A Sleep Stage-Decoding Forehead EEG Patch for Real-time Modulation of Sleep Physiology</title>
      <link>http://arxiv.org/abs/2506.03442v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;StARS是一个用于实时睡眠监测和干预的模块化软硬件平台。&lt;h4&gt;背景&lt;/h4&gt;睡眠监测和干预技术的研究与应用。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够实时监测和干预睡眠的系统。&lt;h4&gt;方法&lt;/h4&gt;使用DCM生物信号设备和ezmsg实时软件框架同步传感器数据，利用高级神经网络模型和迁移学习进行睡眠阶段解码，支持闭环听觉刺激和动态热调节等干预措施。&lt;h4&gt;主要发现&lt;/h4&gt;StARS可以通过轻量级的脑电图前额贴片或可穿戴设备（如智能戒指）进行配置，提供灵活、低负担的解决方案，同时开源的DCM贴片还允许定制EEG设备开发。&lt;h4&gt;结论&lt;/h4&gt;StARS为脑电图、脑机接口和睡眠增强研究和应用提供了灵活、低负担的解决方案，并促进了EEG设备的定制化开发。&lt;h4&gt;翻译&lt;/h4&gt;The System to Augment Restorative Sleep (StARS) is a modular hardware/software platform designed for real-time sleep monitoring and intervention.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The System to Augment Restorative Sleep (StARS) is a modularhardware/software platform designed for real-time sleep monitoring andintervention. Utilizing the compact DCM biosignal device, StARS captureselectrophysiological signals (EEG, EMG, EOG) and synchronizes sensor data usingthe ezmsg real-time software framework. StARS supports interventions such asclosed-loop auditory stimulation and dynamic thermal modulation guided bysleep-stage decoding via advanced neural network models and transfer learning.Configurable with a lightweight EEG forehead patch or wearable sensors likesmart rings, StARS offers flexible, low-burden solutions for EEG, BCI, andsleep-enhancement research and applications. The open-source DCM patch furtherenables customizable EEG device development.</description>
      <author>example@mail.com (William G. Coon, Preston Peranich, Griffin Milsap)</author>
      <guid isPermaLink="false">2506.03442v2</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Pruning Spurious Subgraphs for Graph Out-of-Distribtuion Generalization</title>
      <link>http://arxiv.org/abs/2506.05957v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submission of ICML2025, with score 4/4/3/3&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于剪枝的图神经网络（GNN）方法PrunE，用于解决训练和测试数据分布偏移下的泛化问题，以改善GNN在现实场景中的应用。&lt;h4&gt;背景&lt;/h4&gt;GNN在训练和测试数据分布偏移的情况下往往会出现性能下降，这限制了其在现实世界中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出PrunE方法，消除虚假边，提高GNN的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;PrunE通过两种正则化项来剪枝虚假边：1）图大小约束排除无信息量的虚假边；2）ε-概率对齐进一步抑制虚假边的出现。&lt;h4&gt;主要发现&lt;/h4&gt;PrunE在理论上分析和大量实验中均显示出比之前最先进方法更优越的泛化性能。&lt;h4&gt;结论&lt;/h4&gt;PrunE通过剪枝虚假边，更全面地保留了不变子图，这对于提高GNN的泛化能力至关重要。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图神经网络（GNNs）在训练和测试数据分布偏移的情况下往往遇到显著的性能下降，这阻碍了它们在现实场景中的应用。最近的研究提出了各种方法来解决分布外泛化挑战，其中许多方法在图领域集中于直接识别一个预测目标标签的不变子图。然而，我们认为直接识别不变子图中的边是具有挑战性和易出错的，特别是在某些虚假边与目标有强相关性时。在本文中，我们提出了PrunE，这是第一个基于剪枝的图OOD方法，旨在消除虚假边以提高OOD泛化能力。通过剪枝虚假边，mine{}更全面地保留了不变子图，这对于OOD泛化至关重要。具体来说，PrunE采用两种正则化项来剪枝虚假边：1）图大小约束排除无信息量的虚假边，2）ε-概率对齐进一步抑制虚假边的出现。通过理论分析和大量实验，我们表明PrunE实现了优于OOD的性能，并且显著优于以前的最先进方法。代码可在https://github.com/tianyao-aka/PrunE-GraphOOD上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) often encounter significant performancedegradation under distribution shifts between training and test data, hinderingtheir applicability in real-world scenarios. Recent studies have proposedvarious methods to address the out-of-distribution generalization challenge,with many methods in the graph domain focusing on directly identifying aninvariant subgraph that is predictive of the target label. However, we arguethat identifying the edges from the invariant subgraph directly is challengingand error-prone, especially when some spurious edges exhibit strongcorrelations with the targets. In this paper, we propose PrunE, the firstpruning-based graph OOD method that eliminates spurious edges to improve OODgeneralizability. By pruning spurious edges, \mine{} retains the invariantsubgraph more comprehensively, which is critical for OOD generalization.Specifically, PrunE employs two regularization terms to prune spurious edges:1) graph size constraint to exclude uninformative spurious edges, and 2)$\epsilon$-probability alignment to further suppress the occurrence of spuriousedges. Through theoretical analysis and extensive experiments, we show thatPrunE achieves superior OOD performance and outperforms previousstate-of-the-art methods significantly. Codes are available at:\href{https://github.com/tianyao-aka/PrunE-GraphOOD}{https://github.com/tianyao-aka/PrunE-GraphOOD}.</description>
      <author>example@mail.com (Tianjun Yao, Haoxuan Li, Yongqiang Chen, Tongliang Liu, Le Song, Eric Xing, Zhiqiang Shen)</author>
      <guid isPermaLink="false">2506.05957v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Research on Personalized Financial Product Recommendation by Integrating Large Language Models and Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.05873v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合大型语言模型（LLM）和图神经网络（GNN）的混合框架，用于个性化金融产品推荐。&lt;h4&gt;背景&lt;/h4&gt;随着金融科技（fintech）的快速发展，个性化金融产品推荐变得越来越重要。传统的协同过滤或基于内容的模型往往无法捕捉用户的潜在偏好和复杂关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的混合框架，以改进个性化金融产品推荐的准确性。&lt;h4&gt;方法&lt;/h4&gt;该框架使用预训练的LLM将文本数据（如用户评论）编码为丰富的特征向量，同时使用异构用户-产品图来建模交互和社会联系。通过定制的信息传递机制，在GNN中融合文本和图信息，共同优化嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;在公共和真实世界金融数据集上的实验表明，该模型在准确度、召回率和NDCG方面优于单独的LLM或GNN，并且具有强的可解释性。&lt;h4&gt;结论&lt;/h4&gt;该研究为个性化金融推荐和更广泛的推荐任务中的跨模态融合提供了新的见解。&lt;h4&gt;翻译&lt;/h4&gt;With the rapid growth of fintech, personalized financial product recommendations have become increasingly important. Traditional methods like collaborative filtering or content-based models often fail to capture users' latent preferences and complex relationships. We propose a hybrid framework integrating large language models (LLMs) and graph neural networks (GNNs). A pre-trained LLM encodes text data (e.g., user reviews) into rich feature vectors, while a heterogeneous user-product graph models interactions and social ties. Through a tailored message-passing mechanism, text and graph information are fused within the GNN to jointly optimize embeddings. Experiments on public and real-world financial datasets show our model outperforms standalone LLM or GNN in accuracy, recall, and NDCG, with strong interpretability. This work offers new insights for personalized financial recommendations and cross-modal fusion in broader recommendation tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid growth of fintech, personalized financial productrecommendations have become increasingly important. Traditional methods likecollaborative filtering or content-based models often fail to capture users'latent preferences and complex relationships. We propose a hybrid frameworkintegrating large language models (LLMs) and graph neural networks (GNNs). Apre-trained LLM encodes text data (e.g., user reviews) into rich featurevectors, while a heterogeneous user-product graph models interactions andsocial ties. Through a tailored message-passing mechanism, text and graphinformation are fused within the GNN to jointly optimize embeddings.Experiments on public and real-world financial datasets show our modeloutperforms standalone LLM or GNN in accuracy, recall, and NDCG, with stronginterpretability. This work offers new insights for personalized financialrecommendations and cross-modal fusion in broader recommendation tasks.</description>
      <author>example@mail.com (Yushang Zhao, Yike Peng, Dannier Li, Yuxin Yang, Chengrui Zhou, Jing Dong)</author>
      <guid isPermaLink="false">2506.05873v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>CR-BLEA: Contrastive Ranking for Adaptive Resource Allocation in Bilevel Evolutionary Algorithms</title>
      <link>http://arxiv.org/abs/2506.06362v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对 bilevel EAs 的新型资源分配框架，旨在提高其效率。&lt;h4&gt;背景&lt;/h4&gt;Bilevel optimization 具有嵌套结构，每个上层候选解都需要解决对应的下层问题，这对计算资源提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;减少资源浪费，提高 bilevel EAs 的效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种对比排名网络，用于在线学习上下层解之间的关系，并据此引导基于引用的排名策略，优先优化任务并自适应控制重采样。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该框架显著降低了计算成本，同时保持了甚至提高了解的准确性。&lt;h4&gt;结论&lt;/h4&gt;该框架为提高 bilevel EAs 的效率提供了一种通用的策略，为更可扩展的 bilevel optimization 开辟了道路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于 bilevel optimization 具有嵌套结构，每个上层候选解都需要解决对应的下层问题，这给计算资源带来了重大挑战。虽然进化算法（EAs）在导航这种复杂景观方面很有效，但它们的高资源需求仍然是一个关键瓶颈——尤其是大量无望的下层任务的冗余评估。尽管在多任务学习和迁移学习方面取得了进展，但资源浪费仍然存在。为了解决这个问题，我们提出了一种新的资源分配框架，用于 bilevel EAs，该框架可以选性地识别和专注于有希望的下层任务。我们的方法的核心是一个对比排名网络，该网络在线学习成对的上层和下层解之间的关系。这种知识指导了基于引用的排名策略，该策略优先优化任务，并根据估计的种群质量自适应控制重采样。在五个最先进的 bilevel 算法上的综合实验表明，我们的框架显著降低了计算成本，同时保持了——甚至提高了——解的准确性。这项工作提供了一种通用的策略来提高 bilevel EAs 的效率，为更可扩展的 bilevel optimization 打开了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bilevel optimization poses a significant computational challenge due to itsnested structure, where each upper-level candidate solution requires solving acorresponding lower-level problem. While evolutionary algorithms (EAs) areeffective at navigating such complex landscapes, their high resource demandsremain a key bottleneck -- particularly the redundant evaluation of numerousunpromising lower-level tasks. Despite recent advances in multitasking andtransfer learning, resource waste persists. To address this issue, we propose anovel resource allocation framework for bilevel EAs that selectively identifiesand focuses on promising lower-level tasks. Central to our approach is acontrastive ranking network that learns relational patterns between pairedupper- and lower-level solutions online. This knowledge guides areference-based ranking strategy that prioritizes tasks for optimization andadaptively controls resampling based on estimated population quality.Comprehensive experiments across five state-of-the-art bilevel algorithms showthat our framework significantly reduces computational cost while preserving --or even enhancing -- solution accuracy. This work offers a generalizablestrategy to improve the efficiency of bilevel EAs, paving the way for morescalable bilevel optimization.</description>
      <author>example@mail.com (Dejun Xu, Jijia Chen, Gary G. Yen, Min Jiang)</author>
      <guid isPermaLink="false">2506.06362v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models via Generative Continual Learning</title>
      <link>http://arxiv.org/abs/2506.06694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MoveGCL的框架，用于训练移动性基础模型，旨在解决移动数据隐私问题和数据孤岛问题。&lt;h4&gt;背景&lt;/h4&gt;移动数据具有隐私敏感性，导致不同机构之间存在数据孤岛，这使得构建类似自然语言处理和计算机视觉领域的通用移动模型具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;开发一个可扩展且保护隐私的框架，通过生成式持续学习训练移动性基础模型。&lt;h4&gt;方法&lt;/h4&gt;MoveGCL通过重新播放从冻结的教师模型生成的合成轨迹，实现去中心化和渐进式模型演变，并通过定制蒸馏策略来减少灾难性遗忘，从而增强知识保留。此外，它还采用了混合专家Transformer和移动感知专家路由机制，以及分层渐进式适应策略来稳定持续更新。&lt;h4&gt;主要发现&lt;/h4&gt;在六个真实世界城市数据集上的实验表明，MoveGCL的性能与联合训练相当，并且显著优于联邦学习基线，同时提供了强大的隐私保护。&lt;h4&gt;结论&lt;/h4&gt;MoveGCL是解锁移动性基础模型的关键步骤，为开放、可扩展且保护隐私的模型开发提供了一个实际蓝图。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为MoveGCL的框架，用于训练移动性基础模型，旨在解决移动数据隐私问题和数据孤岛问题。该框架通过生成式持续学习，实现了去中心化和渐进式模型演变，并通过定制蒸馏策略来减少灾难性遗忘，同时采用了混合专家Transformer和移动感知专家路由机制，以及分层渐进式适应策略来稳定持续更新。在六个真实世界城市数据集上的实验表明，MoveGCL的性能与联合训练相当，并且显著优于联邦学习基线，同时提供了强大的隐私保护。MoveGCL是解锁移动性基础模型的关键步骤，为开放、可扩展且保护隐私的模型开发提供了一个实际蓝图。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have revolutionized fields such as natural languageprocessing and computer vision by enabling general-purpose learning acrossdiverse tasks and datasets. However, building analogous models for humanmobility remains challenging due to the privacy-sensitive nature of mobilitydata and the resulting data silos across institutions. To bridge this gap, wepropose MoveGCL, a scalable and privacy-preserving framework for trainingmobility foundation models via generative continual learning. Without sharingraw data, MoveGCL enables decentralized and progressive model evolution byreplaying synthetic trajectories generated from a frozen teacher model, andreinforces knowledge retention through a tailored distillation strategy thatmitigates catastrophic forgetting. To address the heterogeneity of mobilitypatterns, MoveGCL incorporates a Mixture-of-Experts Transformer with amobility-aware expert routing mechanism, and employs a layer-wise progressiveadaptation strategy to stabilize continual updates. Experiments on sixreal-world urban datasets demonstrate that MoveGCL achieves performancecomparable to joint training and significantly outperforms federated learningbaselines, while offering strong privacy protection. MoveGCL marks a crucialstep toward unlocking foundation models for mobility, offering a practicalblueprint for open, scalable, and privacy-preserving model development in theera of foundation models.</description>
      <author>example@mail.com (Yuan Yuan, Yukun Liu, Chonghua Han, Jie Feng, Yong Li)</author>
      <guid isPermaLink="false">2506.06694v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Transferable Sequential Recommendation with Vanilla Cross-Entropy Loss</title>
      <link>http://arxiv.org/abs/2506.02916v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MMM4Rec的多模态序列推荐框架，用于提高多模态推荐系统的准确性和可迁移性。&lt;h4&gt;背景&lt;/h4&gt;序列推荐系统通过分析用户交互历史来建模用户偏好。尽管多模态序列推荐架构的性能优于传统的基于ID的方法，但现有方法在适应新领域时需要大量微调，导致负迁移效应，成为部署瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多模态序列推荐框架，以降低微调成本并提高推荐准确性。&lt;h4&gt;方法&lt;/h4&gt;MMM4Rec框架结合了状态空间对偶（SSD）的时间衰减特性和时间感知建模设计，动态优先考虑关键模态信息。框架通过共享投影矩阵进行序列级别的跨模态对齐，并使用新设计的交叉SSD模块和双通道傅里叶自适应滤波进行时间融合。&lt;h4&gt;主要发现&lt;/h4&gt;MMM4Rec实现了快速的微调收敛，通过简单的交叉熵损失，显著提高了多模态推荐的准确性，同时保持了强的可迁移性。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的实验，MMM4Rec展现出最先进的性能，相较于现有模型在NDCG@10上提高了31.78%，在迁移到大规模下游数据集时平均收敛速度提高了10倍。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes a novel multi-modal sequential recommendation framework named MMM4Rec to improve the accuracy and transferability of multi-modal recommendation systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential Recommendation (SR) systems model user preferences by analyzinginteraction histories. Although transferable multi-modal SR architecturesdemonstrate superior performance compared to traditional ID-based approaches,current methods incur substantial fine-tuning costs when adapting to newdomains due to complex optimization requirements and negative transfer effects- a significant deployment bottleneck that hinders engineers from efficientlyrepurposing pre-trained models for novel application scenarios with minimaltuning overhead. We propose MMM4Rec (Multi-Modal Mamba for SequentialRecommendation), a novel multi-modal SR framework that incorporates a dedicatedalgebraic constraint mechanism for efficient transfer learning. By combiningState Space Duality (SSD)'s temporal decay properties with a time-awaremodeling design, our model dynamically prioritizes key modality information,overcoming limitations of Transformer-based approaches. The frameworkimplements a constrained two-stage process: (1) sequence-level cross-modalalignment via shared projection matrices, followed by (2) temporal fusion usingour newly designed Cross-SSD module and dual-channel Fourier adaptivefiltering. This architecture maintains semantic consistency while suppressingnoise propagation.MMM4Rec achieves rapid fine-tuning convergence with simplecross-entropy loss, significantly improving multi-modal recommendation accuracywhile maintaining strong transferability. Extensive experiments demonstrateMMM4Rec's state-of-the-art performance, achieving the maximum 31.78% NDCG@10improvement over existing models and exhibiting 10 times faster averageconvergence speed when transferring to large-scale downstream datasets.</description>
      <author>example@mail.com (Hao Fan, Yanrong Hu, Kai Fang, Qingyang Liu, Hongjiu Liu)</author>
      <guid isPermaLink="false">2506.02916v3</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Structured Pruning for Diverse Best-of-N Reasoning Optimization</title>
      <link>http://arxiv.org/abs/2506.03978v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACL Findings 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;模型剪枝在基于transformer的语言模型中，不仅可以实现计算节省，还能增强模型的推理能力。&lt;h4&gt;背景&lt;/h4&gt;模型剪枝传统上被视为一种实现计算节省的手段。&lt;h4&gt;目的&lt;/h4&gt;研究模型剪枝对推理性能的影响，并提出新的对比学习框架。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为SPRINT的新框架，该框架在推理过程中动态选择最优的头和层进行剪枝，并通过对齐问题嵌入和头嵌入来识别剪枝头配置，从而提高推理的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;对某些注意力头的选择性剪枝可以提高推理性能，尤其是在具有挑战性的任务上。&lt;h4&gt;结论&lt;/h4&gt;在MATH500和GSM8K数据集上的实验表明，该方法在推理性能上显著优于传统的best-of-N和随机头选择策略。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we uncover a surprising phenomenon: the selective pruning of certain attention heads leads to improvements in reasoning performance, particularly on challenging tasks. Motivated by this observation, we propose SPRINT, a novel contrastive learning framework that dynamically selects the optimal head and layer to prune during inference. By aligning question embeddings with head embeddings, SPRINT identifies those pruned-head configurations that result in more accurate reasoning. Extensive experiments demonstrate that our method significantly outperforms traditional best-of-$N$ and random head selection strategies on the MATH500 and GSM8K datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model pruning in transformer-based language models, traditionally viewed as ameans of achieving computational savings, can enhance the model's reasoningcapabilities. In this work, we uncover a surprising phenomenon: the selectivepruning of certain attention heads leads to improvements in reasoningperformance, particularly on challenging tasks. Motivated by this observation,we propose SPRINT, a novel contrastive learning framework that dynamicallyselects the optimal head and layer to prune during inference. By aligningquestion embeddings with head embeddings, SPRINT identifies those pruned-headconfigurations that result in more accurate reasoning. Extensive experimentsdemonstrate that our method significantly outperforms traditional best-of-$N$and random head selection strategies on the MATH500 and GSM8K datasets.</description>
      <author>example@mail.com (Hieu Trung Nguyen, Bao Nguyen, Viet Anh Nguyen)</author>
      <guid isPermaLink="false">2506.03978v2</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Models are Good Relational Learners</title>
      <link>http://arxiv.org/abs/2506.05725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Rel-LLM的新架构，用于将大型语言模型（LLMs）应用于关系深度学习（RDL），通过保留数据库中的关系结构来提高LLMs处理和推理复杂实体关系的能力。&lt;h4&gt;背景&lt;/h4&gt;虽然大型语言模型在多个领域表现出色，但它们在关系深度学习领域的应用尚未得到充分探索。现有的方法通过遍历数据库中实体之间的关系，将结构化数据转换为文本文档，但这种基于文本的序列化方法忽略了关键的关系结构，引入了冗余，并且往往超过了标准LLM的上下文长度。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够有效利用LLMs处理结构化数据的方法，同时保留数据库中的关系结构。&lt;h4&gt;方法&lt;/h4&gt;Rel-LLM利用基于图神经网络（GNN）的编码器在检索增强生成（RAG）框架内为LLMs生成结构化关系提示。GNN编码器提取实体周围的局部子图，构建包含相关实体关系和时间依赖性的特征表示。这些表示通过去规范化过程转换为结构化提示，使LLM能够推理关系结构。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量实验，Rel-LLM在关键RDL任务上优于现有方法，提供了一种可扩展且高效的方法来将LLMs与结构化数据源集成。&lt;h4&gt;结论&lt;/h4&gt;Rel-LLM是一种有效的方法，可以整合LLMs和结构化数据源，同时保留数据库中的关系结构，为关系深度学习提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;Large language models (LLMs) have demonstrated remarkable capabilities across various domains, yet their application to relational deep learning (RDL) remains underexplored. Existing approaches adapt LLMs by traversing relational links between entities in a database and converting the structured data into flat text documents. Still, this text-based serialization disregards critical relational structures, introduces redundancy, and often exceeds standard LLM context lengths. We introduce Rel-LLM, a novel architecture that utilizes a graph neural network (GNN)-based encoder to generate structured relational prompts for LLMs within a retrieval-augmented generation (RAG) framework. Unlike traditional text-based serialization approaches, our method preserves the inherent relational structure of databases while enabling LLMs to effectively process and reason over complex entity relationships. Specifically, the GNN encoder extracts a local subgraph around an entity to build feature representations that contain relevant entity relationships and temporal dependencies. These representations are transformed into structured prompts using a denormalization process, effectively allowing the LLM to reason over relational structures. Through extensive experiments, we demonstrate that Rel-LLM outperforms existing methods on key RDL tasks, offering a scalable and efficient approach to integrating LLMs with structured data sources. Code is available at https://github.com/smiles724/Rel-LLM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have demonstrated remarkable capabilities acrossvarious domains, yet their application to relational deep learning (RDL)remains underexplored. Existing approaches adapt LLMs by traversing relationallinks between entities in a database and converting the structured data intoflat text documents. Still, this text-based serialization disregards criticalrelational structures, introduces redundancy, and often exceeds standard LLMcontext lengths. We introduce Rel-LLM, a novel architecture that utilizes agraph neural network (GNN)- based encoder to generate structured relationalprompts for LLMs within a retrieval-augmented generation (RAG) framework.Unlike traditional text-based serialization approaches, our method preservesthe inherent relational structure of databases while enabling LLMs toeffectively process and reason over complex entity relationships. Specifically,the GNN encoder extracts a local subgraph around an entity to build featurerepresentations that contain relevant entity relationships and temporaldependencies. These representations are transformed into structured promptsusing a denormalization process, effectively allowing the LLM to reason overrelational structures. Through extensive experiments, we demonstrate thatRel-LLM outperforms existing methods on key RDL tasks, offering a scalable andefficient approach to integrating LLMs with structured data sources. Code isavailable at https://github.com/smiles724/Rel-LLM.</description>
      <author>example@mail.com (Fang Wu, Vijay Prakash Dwivedi, Jure Leskovec)</author>
      <guid isPermaLink="false">2506.05725v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Topology-aware Neural Flux Prediction Guided by Physics</title>
      <link>http://arxiv.org/abs/2506.05676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于提高图神经网络（GNNs）在处理有向图时对节点信号中高频成分的保留能力。&lt;h4&gt;背景&lt;/h4&gt;GNNs在处理有向图时往往难以保留节点信号中的高频成分，这些成分对于建模流动动态至关重要。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够敏感地捕捉到高频成分的GNN，以捕获详细的拓扑差异。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了1）显式的差异矩阵，用于建模方向梯度，以及2）隐式的物理约束，以确保GNN中的消息传递与自然定律一致。&lt;h4&gt;主要发现&lt;/h4&gt;在两个真实世界有向图数据（水通量网络和城市交通流量网络）上的评估表明，该提议是有效的。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够提高GNN对高频成分的敏感性，从而在建模流动动态方面具有潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) often struggle in preserving high-frequencycomponents of nodal signals when dealing with directed graphs. Such componentsare crucial for modeling flow dynamics, without which a traditional GNN tendsto treat a graph with forward and reverse topologies equal.To make GNNssensitive to those high-frequency components thereby being capable to capturedetailed topological differences, this paper proposes a novel framework thatcombines 1) explicit difference matrices that model directional gradients and2) implicit physical constraints that enforce messages passing within GNNs tobe consistent with natural laws. Evaluations on two real-world directed graphdata, namely, water flux network and urban traffic flow network, demonstratethe effectiveness of our proposal.</description>
      <author>example@mail.com (Haoyang Jiang, Jindong Wang, Xingquan Zhu, Yi He)</author>
      <guid isPermaLink="false">2506.05676v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Sequel-Aware Graph Neural Networks for Sequential Learning</title>
      <link>http://arxiv.org/abs/2506.05625v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于图的方法在推荐系统中的应用，特别是结合时间序列信息，通过实验验证了包含时间序列信息的推荐方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;推荐系统使用用户和物品的高阶嵌入来进行预测，并动态地从邻居中添加协作信号。尽管已经研究了物品间的相关性及其对推荐的影响，但时间序列物品序列在推荐中的有效性研究较少。&lt;h4&gt;目的&lt;/h4&gt;研究时间序列物品序列（继任信息）嵌入结合高阶用户嵌入的效果，并比较其与不考虑继任信息的图推荐系统的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Heterogeneous Sequel-aware Graph Neural Networks（HSAL-GNNs）的方法，并在三个合成数据和三个真实世界数据集上与transformers、图神经网络、自动编码器等算法进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，引入物品序列的序列信息显著提高了推荐的性能。&lt;h4&gt;结论&lt;/h4&gt;时间序列物品序列在推荐系统中具有重要作用，HSAL-GNNs在推荐性能上优于或与不考虑继任信息的图推荐系统相当。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-based recommendation systems use higher-order user and item embeddingsfor next-item predictions. Dynamically adding collaborative signals fromneighbors helps to use similar users' preferences during learning. Whileitem-item correlations and their impact on recommendations have been studied,the efficacy of temporal item sequences for recommendations is much lessexplored. In this paper, we examine temporal item sequence (sequel-aware)embeddings along with higher-order user embeddings and show that sequel-awareGraph Neural Networks have better (or comparable) recommendation performancethan graph-based recommendation systems that do not consider sequelinformation. Extensive empirical results comparing Heterogeneous Sequel-awareGraph Neural Networks (HSAL-GNNs) to other algorithms for sequential learning(such as transformers, graph neural networks, auto-encoders) are presented onthree synthetic and three real-world datasets. Our results indicate that theincorporation of sequence information from items greatly enhancesrecommendations.</description>
      <author>example@mail.com (Anushka Tiwari, Haimonti Dutta, Shahrzad Khanizadeh)</author>
      <guid isPermaLink="false">2506.05625v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Spectral Graph Neural Networks are Incomplete on Graphs with a Simple Spectrum</title>
      <link>http://arxiv.org/abs/2506.05530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages main text&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了如何通过引入光谱特征来增强图神经网络（GNNs）的表达能力，并提出了一种新的方法来提高GNNs在简单光谱图上的表达能力。&lt;h4&gt;背景&lt;/h4&gt;光谱特征被广泛应用于GNNs中以提高其区分非同构图的能力，例如在MPNNs和Graph Transformers中使用图拉普拉斯算子的特征向量进行位置编码。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过引入一个新的表达性层次来评估SGNNs的表达能力，并改进SGNNs在简单光谱图上的表达能力。&lt;h4&gt;方法&lt;/h4&gt;本文采用了一种分类图的方法，通过图的最大特征值多重性来引入SGNNs的表达性层次。此外，本文将旋转等变神经网络应用于图谱设置，提出了一种方法来提高SGNNs的表达能力。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，许多SGNNs在具有不同特征值的图上都是不完整的。通过实验验证了理论上的改进方法，并在MNIST Superpixel数据集上的图像分类实验和ZINC图上的特征向量规范实验中进行了实证验证。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地提高SGNNs在简单光谱图上的表达能力，为GNNs的进一步研究提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spectral features are widely incorporated within Graph Neural Networks (GNNs)to improve their expressive power, or their ability to distinguish amongnon-isomorphic graphs. One popular example is the usage of graph Laplacianeigenvectors for positional encoding in MPNNs and Graph Transformers. Theexpressive power of such Spectrally-enhanced GNNs (SGNNs) is usually evaluatedvia the k-WL graph isomorphism test hierarchy and homomorphism counting. Yet,these frameworks align poorly with the graph spectra, yielding limited insightinto SGNNs' expressive power. We leverage a well-studied paradigm ofclassifying graphs by their largest eigenvalue multiplicity to introduce anexpressivity hierarchy for SGNNs. We then prove that many SGNNs are incompleteeven on graphs with distinct eigenvalues. To mitigate this deficiency, we adaptrotation equivariant neural networks to the graph spectra setting to propose amethod to provably improve SGNNs' expressivity on simple spectrum graphs. Weempirically verify our theoretical claims via an image classificationexperiment on the MNIST Superpixel dataset and eigenvector canonicalization ongraphs from ZINC.</description>
      <author>example@mail.com (Snir Hordan, Maya Bechler-Speicher, Gur Lifshitz, Nadav Dym)</author>
      <guid isPermaLink="false">2506.05530v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Attention-based transformer models for image captioning across languages: An in-depth survey and evaluation</title>
      <link>http://arxiv.org/abs/2506.05399v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 15 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基于注意力的图像字幕生成模型，涵盖了不同语言，并分析了其挑战和局限性。&lt;h4&gt;背景&lt;/h4&gt;图像字幕生成是连接计算机视觉和自然语言处理的一个领域，近年来基于transformer的模型在字幕生成方面取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;全面分析基于注意力的图像字幕生成模型，并探讨其在多语言环境下的应用。&lt;h4&gt;方法&lt;/h4&gt;对基于注意力的图像字幕生成模型进行分类，并探讨基准数据集、评估指标如BLEU、METEOR、CIDEr和ROUGE，以及多语言字幕生成的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;识别出当前模型的关键局限性，包括语义不一致、非英语语言数据稀缺和推理能力限制。&lt;h4&gt;结论&lt;/h4&gt;提出了未来研究方向，如多模态学习、在AI助手、医疗和法医分析中的实时应用。&lt;h4&gt;翻译&lt;/h4&gt;本文综述了基于注意力的图像字幕生成模型，涵盖了不同语言，并分析了其挑战和局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.cosrev.2025.100766&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image captioning involves generating textual descriptions from input images,bridging the gap between computer vision and natural language processing.Recent advancements in transformer-based models have significantly improvedcaption generation by leveraging attention mechanisms for better sceneunderstanding. While various surveys have explored deep learning-basedapproaches for image captioning, few have comprehensively analyzedattention-based transformer models across multiple languages. This surveyreviews attention-based image captioning models, categorizing them intotransformer-based, deep learning-based, and hybrid approaches. It exploresbenchmark datasets, discusses evaluation metrics such as BLEU, METEOR, CIDEr,and ROUGE, and highlights challenges in multilingual captioning. Additionally,this paper identifies key limitations in current models, including semanticinconsistencies, data scarcity in non-English languages, and limitations inreasoning ability. Finally, we outline future research directions, such asmultimodal learning, real-time applications in AI-powered assistants,healthcare, and forensic analysis. This survey serves as a comprehensivereference for researchers aiming to advance the field of attention-based imagecaptioning.</description>
      <author>example@mail.com (Israa A. Albadarneh, Bassam H. Hammo, Omar S. Al-Kadi)</author>
      <guid isPermaLink="false">2506.05399v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Feature-Based Lie Group Transformer for Real-World Applications</title>
      <link>http://arxiv.org/abs/2506.04668v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, the dataset used in this work is  https://drive.google.com/file/d/1RaSWNN2GEyV3zQPeGya4Mr9DDhJ7OMz7/view?usp=sharing&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文主要讨论了表示学习在获取有意义的表示方面的目标，并提出了改进方法以应用于更现实的场景。&lt;h4&gt;背景&lt;/h4&gt;表示学习旨在从无监督的真实世界感官输入中获取有意义的表示，并解释了人类发展的某些方面。&lt;h4&gt;目的&lt;/h4&gt;研究提出了一种新的方法，用于对成对感官输入之间的变化进行分类，并学习满足代数结构约束的转换。&lt;h4&gt;方法&lt;/h4&gt;该方法使用了伽罗瓦代数理论中的群分解，以克服传统表示学习中独立特征轴的假设，并提出了结合特征提取和对象分割的新方法。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，传统的表示学习无法解释条件独立性，且新方法在处理低分辨率图像时存在局限性。&lt;h4&gt;结论&lt;/h4&gt;通过将群分解理论应用于更现实的场景，结合特征提取和对象分割，模型有望更好地理解人类在现实世界中对象识别的发展。&lt;h4&gt;翻译&lt;/h4&gt;The main goal of representation learning is to acquire meaningful representations from real-world sensory inputs without supervision. Representation learning explains some aspects of human development. Various neural network (NN) models have been proposed that acquire empirically good representations. However, the formulation of a good representation has not been established. We recently proposed a method for categorizing changes between a pair of sensory inputs. A unique feature of this approach is that transformations between two sensory inputs are learned to satisfy algebraic structural constraints. Conventional representation learning often assumes that disentangled independent feature axes is a good representation; however, we found that such a representation cannot account for conditional independence. To overcome this problem, we proposed a new method using group decomposition in Galois algebra theory. Although this method is promising for defining a more general representation, it assumes pixel-to-pixel translation without feature extraction, and can only process low-resolution images with no background, which prevents real-world application. In this study, we provide a simple method to apply our group decomposition theory to a more realistic scenario by combining feature extraction and object segmentation. We replace pixel translation with feature translation and formulate object segmentation as grouping features under the same transformation. We validated the proposed method on a practical dataset containing both real-world object and background. We believe that our model will lead to a better understanding of human development of object recognition in the real world.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The main goal of representation learning is to acquire meaningfulrepresentations from real-world sensory inputs without supervision.Representation learning explains some aspects of human development. Variousneural network (NN) models have been proposed that acquire empirically goodrepresentations. However, the formulation of a good representation has not beenestablished. We recently proposed a method for categorizing changes between apair of sensory inputs. A unique feature of this approach is thattransformations between two sensory inputs are learned to satisfy algebraicstructural constraints. Conventional representation learning often assumes thatdisentangled independent feature axes is a good representation; however, wefound that such a representation cannot account for conditional independence.To overcome this problem, we proposed a new method using group decomposition inGalois algebra theory. Although this method is promising for defining a moregeneral representation, it assumes pixel-to-pixel translation without featureextraction, and can only process low-resolution images with no background,which prevents real-world application. In this study, we provide a simplemethod to apply our group decomposition theory to a more realistic scenario bycombining feature extraction and object segmentation. We replace pixeltranslation with feature translation and formulate object segmentation asgrouping features under the same transformation. We validated the proposedmethod on a practical dataset containing both real-world object and background.We believe that our model will lead to a better understanding of humandevelopment of object recognition in the real world.</description>
      <author>example@mail.com (Takayuki Komatsu, Yoshiyuki Ohmura, Kayato Nishitsunoi, Yasuo Kuniyoshi)</author>
      <guid isPermaLink="false">2506.04668v3</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Towards Foundation Model on Temporal Knowledge Graph Reasoning</title>
      <link>http://arxiv.org/abs/2506.06367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种全新的全归纳式时间知识图谱链接预测方法，通过使用正弦位置编码捕捉细粒度时间模式，并利用基于局部和全局时间上下文的消息传递生成自适应实体和关系表示，从而实现模型的无差别时间粒度和时间跨度处理，提高了模型在未见过的知识图谱上的零样本性能。&lt;h4&gt;背景&lt;/h4&gt;现有的时间知识图谱嵌入（TKGE）模型在归纳或半归纳设置中进行链接预测任务，这限制了模型在新领域迁移和泛化到真实世界场景的能力。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有模型在迁移性和泛化能力上的限制，提出了一种全新的全归纳式时间知识图谱链接预测方法。&lt;h4&gt;方法&lt;/h4&gt;模型使用正弦位置编码捕捉细粒度时间模式，并利用消息传递生成自适应实体和关系表示，同时考虑局部和全局时间上下文。&lt;h4&gt;主要发现&lt;/h4&gt;POSTRA模型在未见过的知识图谱上展现出强大的零样本性能，有效推广到新实体、关系和时间戳。&lt;h4&gt;结论&lt;/h4&gt;POSTRA模型为时间知识图谱的基础模型迈出了重要一步，通过单次预训练即可在各种归纳时间推理场景中提高零样本性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel fully-inductive approach for temporal knowledge graph link prediction. The model employs sinusoidal positional encodings to capture fine-grained temporal patterns and generates adaptive entity and relation representations using message passing conditioned on both local and global temporal contexts. The model design is agnostic to temporal granularity and time span, effectively addressing temporal discrepancies across TKGs and facilitating time-aware structural information transfer. As a pretrained, scalable, and transferable model, POSTRA demonstrates strong zero-shot performance on unseen temporal knowledge graphs, effectively generalizing to novel entities, relations, and timestamps. Extensive theoretical analysis and empirical results show that a single pretrained model can improve zero-shot performance on various inductive temporal reasoning scenarios, marking a significant step toward a foundation model for temporal KGs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal Knowledge Graphs (TKGs) store temporal facts with quadruple formats(s, p, o, t). Existing Temporal Knowledge Graph Embedding (TKGE) models performlink prediction tasks in transductive or semi-inductive settings, which meansthe entities, relations, and temporal information in the test graph are fullyor partially observed during training. Such reliance on seen elements duringinference limits the models' ability to transfer to new domains and generalizeto real-world scenarios. A central limitation is the difficulty in learningrepresentations for entities, relations, and timestamps that are transferableand not tied to dataset-specific vocabularies. To overcome these limitations,we introduce the first fully-inductive approach to temporal knowledge graphlink prediction. Our model employs sinusoidal positional encodings to capturefine-grained temporal patterns and generates adaptive entity and relationrepresentations using message passing conditioned on both local and globaltemporal contexts. Our model design is agnostic to temporal granularity andtime span, effectively addressing temporal discrepancies across TKGs andfacilitating time-aware structural information transfer. As a pretrained,scalable, and transferable model, POSTRA demonstrates strong zero-shotperformance on unseen temporal knowledge graphs, effectively generalizing tonovel entities, relations, and timestamps. Extensive theoretical analysis andempirical results show that a single pretrained model can improve zero-shotperformance on various inductive temporal reasoning scenarios, marking asignificant step toward a foundation model for temporal KGs.</description>
      <author>example@mail.com (Jiaxin Pan, Mojtaba Nayyeri, Osama Mohammed, Daniel Hernandez, Rongchuan Zhang, Cheng Cheng, Steffen Staab)</author>
      <guid isPermaLink="false">2506.06367v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>RoPETR: Improving Temporal Camera-Only 3D Detection by Integrating Enhanced Rotary Position Embedding</title>
      <link>http://arxiv.org/abs/2504.12643v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文报告介绍了StreamPETR框架的针对性改进，旨在提高速度估计能力，这对于影响NuScenes检测分数的整体性能是一个关键因素。&lt;h4&gt;背景&lt;/h4&gt;StreamPETR在3D边界框检测方面表现出色，平均精度较高，但分析表明在NuScenes数据集上速度估计是瓶颈。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一限制，提出了一种定制化的位置嵌入策略，以增强时间建模能力。&lt;h4&gt;方法&lt;/h4&gt;在NuScenes测试集上进行了实验评估。&lt;h4&gt;主要发现&lt;/h4&gt;改进的方法使用ViT-L主干网络实现了70.86%的NDS（NuScenes检测分数），达到了相机仅3D物体检测的新基准。&lt;h4&gt;结论&lt;/h4&gt;StreamPETR框架通过改进速度估计能力，在仅使用相机的情况下实现了3D物体检测的新水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report introduces a targeted improvement to the StreamPETRframework, specifically aimed at enhancing velocity estimation, a criticalfactor influencing the overall NuScenes Detection Score. While StreamPETRexhibits strong 3D bounding box detection performance as reflected by its highmean Average Precision our analysis identified velocity estimation as asubstantial bottleneck when evaluated on the NuScenes dataset. To overcome thislimitation, we propose a customized positional embedding strategy tailored toenhance temporal modeling capabilities. Experimental evaluations conducted onthe NuScenes test set demonstrate that our improved approach achieves astate-of-the-art NDS of 70.86% using the ViT-L backbone, setting a newbenchmark for camera-only 3D object detection.</description>
      <author>example@mail.com (Hang Ji, Tao Ni, Xufeng Huang, Zhan Shi, Tao Luo, Xin Zhan, Junbo Chen)</author>
      <guid isPermaLink="false">2504.12643v3</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    </channel>
</rss>