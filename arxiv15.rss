<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 11 Jun 2025 14:17:34 +0800</lastBuildDate>
    <item>
      <title>Machine Learning the 6d Supergravity Landscape</title>
      <link>http://arxiv.org/abs/2505.16131v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  49 pages; code and data available at  https://github.com/nait400/ML-6d-sugra-landscape&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文应用监督和未监督的机器学习算法研究了六维弦景观和沼泽地，数据来自几乎无异常的六维N=(1,0)超引力模型，特征为异常系数的Gram矩阵。研究展示了机器学习算法在高效学习景观和沼泽地复杂特征方面的能力。&lt;h4&gt;背景&lt;/h4&gt;研究基于六维超引力理论中的弦景观和沼泽地，使用N=(1,0)超引力模型的Gram矩阵数据。&lt;h4&gt;目的&lt;/h4&gt;探索机器学习算法在理解六维超引力理论的景观和沼泽地方面的应用潜力。&lt;h4&gt;方法&lt;/h4&gt;使用自动编码器进行无监督学习，通过将Gram矩阵数据压缩到二维来进行模型自动分类。同时，使用监督学习建立两个分类器，预测模型在探针弦插入下的一致性和在异常流入下的不一致性。&lt;h4&gt;主要发现&lt;/h4&gt;自动编码器通过压缩数据将相似模型聚类，并识别了这些聚类的显著特征。它还识别了难以重建的异常模型，其中一种模型难以与其他模型结合以消除$ext{tr}R^{4}$异常，表明其在景观中的存在极为罕见。监督学习分类器准确预测了模型的一致性和不一致性。将预测投影到自动编码器的二维潜在层上，显示了一致模型聚类，表明自动编码器学习了模型的有趣且复杂的特征。&lt;h4&gt;结论&lt;/h4&gt;机器学习算法能够有效学习六维超引力理论的景观和沼泽地的复杂特征，为理解和映射这些理论提供了新的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nait400/ml-6d-sugra-landscape&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we apply both supervised and unsupervised machine learningalgorithms to the study of the string landscape and swampland in 6-dimensions.Our data are the (almost) anomaly-free 6-dimensional $\mathcal{N} = (1,0)$supergravity models, characterised by the Gram matrix of anomaly coefficients.Our work demonstrates the ability of machine learning algorithms to efficientlylearn highly complex features of the landscape and swampland. Employing anautoencoder for unsupervised learning, we provide an auto-classification ofthese models by compressing the Gram matrix data to 2-dimensions. Throughcompression, similar models cluster together, and we identify prominentfeatures of these clusters. The autoencoder also identifies outlier modelswhich are difficult to reconstruct. One of these outliers proves to beincredibly difficult to combine with other models such that the$\text{tr}R^{4}$ anomaly vanishes, making its presence in the landscapeextremely rare. Further, we utilise supervised learning to build twoclassifiers predicting (1) model consistency under probe string insertion(precision: 0.78, predicting consistency for 214,837 models with reasonablecertainty) and (2) inconsistency under anomaly inflow (precision: 0.91,predicting inconsistency for 1,909,359 models). Notably, projecting thesepredictions onto the autoencoder's 2-dimensional latent layer shows consistentmodels clustering together, further indicating that the autoencoder has learntinteresting and complex features of the set of models and potentially offers anovel approach to mapping the landscape and swampland of 6-dimensionalsupergravity theories.</description>
      <author>example@mail.com (Nathan Brady, David Tennyson, Thomas Vandermeulen)</author>
      <guid isPermaLink="false">2505.16131v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
  <item>
      <title>Polar Hierarchical Mamba: Towards Streaming LiDAR Object Detection with Point Clouds as Egocentric Sequences</title>
      <link>http://arxiv.org/abs/2506.06944v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Polar Hierarchical Mamba (PHiM)的新颖状态空间模型，旨在提高极坐标下流式处理的LiDAR感知效率。&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶领域，准确且高效的目标检测至关重要，而实时感知需要低延迟和高吞吐量。LiDAR传感器提供鲁棒的深度信息，但传统方法处理360度全扫描需要较长时间。&lt;h4&gt;目的&lt;/h4&gt;提出PHiM以解决传统方法在处理全扫描时的延迟问题，并提高流式处理的性能。&lt;h4&gt;方法&lt;/h4&gt;PHiM使用局部双向Mamba块进行区间内空间编码，全局正向Mamba进行区间间时间建模，并使用扭曲感知的、维分解的操作来替代卷积和位置编码。&lt;h4&gt;主要发现&lt;/h4&gt;PHiM在Waymo Open Dataset上达到了流式检测的最新水平，比之前的最佳方法提高了10%，并且在吞吐量上是全扫描基线的两倍。&lt;h4&gt;结论&lt;/h4&gt;PHiM是一种适用于极坐标流式处理的LiDAR感知的新架构，具有显著性能提升。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Accurate and efficient object detection is essential for autonomous vehicles, where real-time perception requires low latency and high throughput. LiDAR sensors provide robust depth information, but conventional methods process full 360° scans in a single pass, introducing significant delay. Streaming approaches address this by sequentially processing partial scans in the native polar coordinate system, yet they rely on translation-invariant convolutions that are misaligned with polar geometry -- resulting in degraded performance or requiring complex distortion mitigation. Recent Mamba-based state space models (SSMs) have shown promise for LiDAR perception, but only in the full-scan setting, relying on geometric serialization and positional embeddings that are memory-intensive and ill-suited to streaming. We propose Polar Hierarchical Mamba (PHiM), a novel SSM architecture designed for polar-coordinate streaming LiDAR. PHiM uses local bidirectional Mamba blocks for intra-sector spatial encoding and a global forward Mamba for inter-sector temporal modeling, replacing convolutions and positional encodings with distortion-aware, dimensionally-decomposed operations. PHiM sets a new state-of-the-art among streaming detectors on the Waymo Open Dataset, outperforming the previous best by 10% and matching full-scan baselines at twice the throughput. Code will be available at https://github.com/meilongzhang/Polar-Hierarchical-Mamba .&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and efficient object detection is essential for autonomous vehicles,where real-time perception requires low latency and high throughput. LiDARsensors provide robust depth information, but conventional methods process full360{\deg} scans in a single pass, introducing significant delay. Streamingapproaches address this by sequentially processing partial scans in the nativepolar coordinate system, yet they rely on translation-invariant convolutionsthat are misaligned with polar geometry -- resulting in degraded performance orrequiring complex distortion mitigation. Recent Mamba-based state space models(SSMs) have shown promise for LiDAR perception, but only in the full-scansetting, relying on geometric serialization and positional embeddings that arememory-intensive and ill-suited to streaming. We propose Polar HierarchicalMamba (PHiM), a novel SSM architecture designed for polar-coordinate streamingLiDAR. PHiM uses local bidirectional Mamba blocks for intra-sector spatialencoding and a global forward Mamba for inter-sector temporal modeling,replacing convolutions and positional encodings with distortion-aware,dimensionally-decomposed operations. PHiM sets a new state-of-the-art amongstreaming detectors on the Waymo Open Dataset, outperforming the previous bestby 10\% and matching full-scan baselines at twice the throughput. Code will beavailable at https://github.com/meilongzhang/Polar-Hierarchical-Mamba .</description>
      <author>example@mail.com (Mellon M. Zhang, Glen Chou, Saibal Mukhopadhyay)</author>
      <guid isPermaLink="false">2506.06944v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Generative Vehicle Trajectory Models for Traffic Intersection Dynamics</title>
      <link>http://arxiv.org/abs/2506.08963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于交通信号交叉口交通动态的深度生成模型，以帮助交通管理部门更好地理解交通效率和安全性。&lt;h4&gt;背景&lt;/h4&gt;交通交叉口是城市道路网络的重要组成部分，但同时也是事故多发区域。&lt;h4&gt;目的&lt;/h4&gt;开发一个综合分析工具，使用更符合交通工程实际的指标来训练、运行和评估交通模型。&lt;h4&gt;方法&lt;/h4&gt;在大型数据集上训练了先进的车辆轨迹预测模型，并在微观模拟器中对预测模型进行在线评估，以模拟未见过的交通条件。&lt;h4&gt;主要发现&lt;/h4&gt;尽管使用了理想行为的轨迹作为输入并实现了低轨迹重建误差，但生成的轨迹表现出违反交通规则的行为。&lt;h4&gt;结论&lt;/h4&gt;引入了新的指标来评估这些不期望的行为，并展示了相关结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：城市道路网络中的交叉口对于调节人员和货物的流动至关重要。然而，它们是冲突轨迹的区域，容易发生事故。信号交叉口交通动态的深度生成模型可以极大地帮助交通管理部门更好地理解效率和安全性方面。目前，模型主要在计算指标上评估，这些指标主要关注轨迹重建误差。它们没有在实时微观模拟场景中进行在线评估。此外，这些指标没有充分考虑到交通工程特定的关注点，如闯红灯、不允许停车等。在这项工作中，我们提供了一个综合分析工具，用于使用提供更好模型性能洞察的指标来训练、运行和评估模型。我们在收集到的大量数据集上训练了一个最先进的车辆轨迹预测模型，该数据集是通过运行现实世界城市交叉口的校准场景获得的。然后，我们在微观模拟器中在线评估了预测模型在未见过的交通条件下的性能。我们表明，尽管使用了理想行为的轨迹作为输入，并实现了低轨迹重建误差，但生成的轨迹表现出违反交通规则的行为。我们引入了新的指标来评估这种不期望的行为，并展示了我们的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic Intersections are vital to urban road networks as they regulate themovement of people and goods. However, they are regions of conflictingtrajectories and are prone to accidents. Deep Generative models of trafficdynamics at signalized intersections can greatly help traffic authoritiesbetter understand the efficiency and safety aspects. At present, models areevaluated on computational metrics that primarily look at trajectoryreconstruction errors. They are not evaluated online in a `live'microsimulation scenario. Further, these metrics do not adequately considertraffic engineering-specific concerns such as red-light violations, unallowedstoppage, etc. In this work, we provide a comprehensive analytics tool totrain, run, and evaluate models with metrics that give better insights intomodel performance from a traffic engineering point of view. We train astate-of-the-art multi-vehicle trajectory forecasting model on a large datasetcollected by running a calibrated scenario of a real-world urban intersection.We then evaluate the performance of the prediction models, online in amicrosimulator, under unseen traffic conditions. We show that despite usingideally-behaved trajectories as input, and achieving low trajectoryreconstruction errors, the generated trajectories show behaviors that breaktraffic rules. We introduce new metrics to evaluate such undesired behaviorsand present our results.</description>
      <author>example@mail.com (Yash Ranjan, Rahul Sengupta, Anand Rangarajan, Sanjay Ranka)</author>
      <guid isPermaLink="false">2506.08963v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Deploying SICNav in the Field: Safe and Interactive Crowd Navigation using MPC and Bilevel Optimization</title>
      <link>http://arxiv.org/abs/2506.08851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 2025 IEEE ICRA Workshop on Field Robotics  (non-archival)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种安全且高效的拥挤环境导航方法，用于执行如食物配送或自动轮椅移动等服务任务的机器人。&lt;h4&gt;背景&lt;/h4&gt;传统的机器人拥挤环境导航方法将人类运动预测与机器人运动规划分离，忽略了人类与机器人之间的闭环交互。&lt;h4&gt;目的&lt;/h4&gt;提出了一种名为SICNav的安全和交互式拥挤导航方法，它是一个双层模型预测控制框架，将预测和规划合并为一个优化问题，并明确地建模了代理之间的交互。&lt;h4&gt;方法&lt;/h4&gt;介绍了用于部署SICNav的系统概述，该系统在室内和室外环境中部署，并提供了系统在近7公里、两小时自主导航过程中的初步分析。&lt;h4&gt;主要发现&lt;/h4&gt;SICNav方法能够有效处理人类与机器人之间的交互，避免了机器人因人类反应不当而卡住的问题。&lt;h4&gt;结论&lt;/h4&gt;SICNav方法在室内和室外环境中均表现出良好的导航性能，为机器人服务任务在拥挤环境中的导航提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Safe and efficient navigation in crowded environments remains a critical challenge for robots that provide a variety of service tasks such as food delivery or autonomous wheelchair mobility. Classical robot crowd navigation methods decouple human motion prediction from robot motion planning, which neglects the closed-loop interactions between humans and robots. This lack of a model for human reactions to the robot plan (e.g. moving out of the way) can cause the robot to get stuck. Our proposed Safe and Interactive Crowd Navigation (SICNav) method is a bilevel Model Predictive Control (MPC) framework that combines prediction and planning into one optimization problem, explicitly modeling interactions among agents. In this paper, we present a systems overview of the crowd navigation platform we use to deploy SICNav in previously unseen indoor and outdoor environments. We provide a preliminary analysis of the system's operation over the course of nearly 7 km of autonomous navigation over two hours in both indoor and outdoor environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Safe and efficient navigation in crowded environments remains a criticalchallenge for robots that provide a variety of service tasks such as fooddelivery or autonomous wheelchair mobility. Classical robot crowd navigationmethods decouple human motion prediction from robot motion planning, whichneglects the closed-loop interactions between humans and robots. This lack of amodel for human reactions to the robot plan (e.g. moving out of the way) cancause the robot to get stuck. Our proposed Safe and Interactive CrowdNavigation (SICNav) method is a bilevel Model Predictive Control (MPC)framework that combines prediction and planning into one optimization problem,explicitly modeling interactions among agents. In this paper, we present asystems overview of the crowd navigation platform we use to deploy SICNav inpreviously unseen indoor and outdoor environments. We provide a preliminaryanalysis of the system's operation over the course of nearly 7 km of autonomousnavigation over two hours in both indoor and outdoor environments.</description>
      <author>example@mail.com (Sepehr Samavi, Garvish Bhutani, Florian Shkurti, Angela P. Schoellig)</author>
      <guid isPermaLink="false">2506.08851v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Diffuse and Disperse: Image Generation with Representation Regularization</title>
      <link>http://arxiv.org/abs/2506.09027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Dispersive Loss的简单正则化器，用于提升基于扩散的生成模型。该方法通过鼓励内部表示在隐藏空间中分散，类似于对比自监督学习，但无需正样本对，不干扰回归过程中的采样。&lt;h4&gt;背景&lt;/h4&gt;过去十年中，基于扩散的生成模型的发展与表示学习进展独立。这些模型通常依赖于基于回归的目标，并且通常缺乏显式正则化。&lt;h4&gt;目的&lt;/h4&gt;提出Dispersive Loss正则化器，有效提升基于扩散的生成模型。&lt;h4&gt;方法&lt;/h4&gt;Dispersive Loss正则化器，通过鼓励内部表示在隐藏空间中分散，类似于对比自监督学习，但无需正样本对。&lt;h4&gt;主要发现&lt;/h4&gt;Dispersive Loss在ImageNet数据集上对多种模型进行了评估，与广泛使用的强大基线相比，报告了持续改进。&lt;h4&gt;结论&lt;/h4&gt;Dispersive Loss有助于弥合生成建模与表示学习之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of diffusion-based generative models over the past decade haslargely proceeded independently of progress in representation learning. Thesediffusion models typically rely on regression-based objectives and generallylack explicit regularization. In this work, we propose \textit{DispersiveLoss}, a simple plug-and-play regularizer that effectively improvesdiffusion-based generative models. Our loss function encourages internalrepresentations to disperse in the hidden space, analogous to contrastiveself-supervised learning, with the key distinction that it requires no positivesample pairs and therefore does not interfere with the sampling process usedfor regression. Compared to the recent method of representation alignment(REPA), our approach is self-contained and minimalist, requiring nopre-training, no additional parameters, and no external data. We evaluateDispersive Loss on the ImageNet dataset across a range of models and reportconsistent improvements over widely used and strong baselines. We hope our workwill help bridge the gap between generative modeling and representationlearning.</description>
      <author>example@mail.com (Runqian Wang, Kaiming He)</author>
      <guid isPermaLink="false">2506.09027v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Do MIL Models Transfer?</title>
      <link>http://arxiv.org/abs/2506.09022v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 (Spotlight). 20 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究评估了预训练的MIL模型在转移学习方面的能力，结果表明这些模型在处理临床数据时具有很好的适应性和性能提升。&lt;h4&gt;背景&lt;/h4&gt;MIL在计算病理学中用于生成临床有意义的组织图像嵌入，但在小规模、弱监督的数据集上表现不佳。与NLP和传统计算机视觉不同，MIL模型的迁移性理解不足。&lt;h4&gt;目的&lt;/h4&gt;系统评估预训练MIL模型的迁移学习能力，通过比较11个模型在21个预训练任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;评估了11个预训练MIL模型在形态和分子亚型预测任务上的表现，并比较了这些模型与从头开始训练的模型。&lt;h4&gt;主要发现&lt;/h4&gt;预训练MIL模型在不同器官上训练时仍能优于从头开始训练的模型；在跨器官和任务上的预训练可以显著提高泛化能力，并使用更少的数据。&lt;h4&gt;结论&lt;/h4&gt;这些发现突出了MIL模型的鲁棒适应性和利用迁移学习在计算病理学中提升性能的益处。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多实例学习（MIL）是计算病理学中从千兆像素的组织图像中生成临床有意义的切片级嵌入的基础方法。然而，MIL往往在小规模、弱监督的临床数据集上表现不佳。与NLP和传统计算机视觉领域不同，迁移学习被广泛用于解决数据稀缺问题，但MIL模型的迁移性仍然理解不足。在本研究中，我们系统地评估了预训练MIL模型的迁移学习能力，通过评估11个模型在21个预训练任务上的表现。我们的结果表明，即使在这些模型在目标任务不同的器官上进行了训练，预训练MIL模型也始终优于从头开始训练的模型。此外，在泛癌症数据集上进行预训练能够实现跨器官和任务的强大泛化能力，同时使用大量更少的预训练数据。这些发现突出了MIL模型的鲁棒适应能力，并证明了在计算病理学中利用迁移学习来提升性能的益处。最后，我们提供了一种资源，该资源标准化了MIL模型在流行计算病理学任务上的实现和预训练模型权重的收集，可在https://github.com/mahmoodlab/MIL-Lab获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multiple Instance Learning (MIL) is a cornerstone approach in computationalpathology (CPath) for generating clinically meaningful slide-level embeddingsfrom gigapixel tissue images. However, MIL often struggles with small, weaklysupervised clinical datasets. In contrast to fields such as NLP andconventional computer vision, where transfer learning is widely used to addressdata scarcity, the transferability of MIL models remains poorly understood. Inthis study, we systematically evaluate the transfer learning capabilities ofpretrained MIL models by assessing 11 models across 21 pretraining tasks formorphological and molecular subtype prediction. Our results show thatpretrained MIL models, even when trained on different organs than the targettask, consistently outperform models trained from scratch. Moreover,pretraining on pancancer datasets enables strong generalization across organsand tasks, outperforming slide foundation models while using substantially lesspretraining data. These findings highlight the robust adaptability of MILmodels and demonstrate the benefits of leveraging transfer learning to boostperformance in CPath. Lastly, we provide a resource which standardizes theimplementation of MIL models and collection of pretrained model weights onpopular CPath tasks, available at https://github.com/mahmoodlab/MIL-Lab</description>
      <author>example@mail.com (Daniel Shao, Richard J. Chen, Andrew H. Song, Joel Runevic, Ming Y. Lu, Tong Ding, Faisal Mahmood)</author>
      <guid isPermaLink="false">2506.09022v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Gaussian2Scene: 3D Scene Representation Learning via Self-supervised Learning with 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.08777v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Gaussian2Scene的新型场景级自监督学习框架，用于点云预训练，以提高3D视觉任务的效果。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在点云预训练中成为3D视觉任务的基础，通过从大规模未标注数据中学习，提高模型性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种更有效的场景级自监督学习框架，以解决现有方法依赖于隐式场景表示和高内存需求，以及未能捕捉到3D几何结构的局限性。&lt;h4&gt;方法&lt;/h4&gt;Gaussian2Scene利用3D高斯分层（3DGS）的效率和显式性质进行预训练，采用渐进式两阶段训练策略，第一阶段学习2D和3D场景表示，第二阶段使用重建的点云和几何原始体的几何位置以及渲染的RGB图像进行监督学习。&lt;h4&gt;主要发现&lt;/h4&gt;Gaussian2Scene在多个下游3D目标检测任务中表现出色，与现有预训练方法相比，效果一致且有所提升。&lt;h4&gt;结论&lt;/h4&gt;Gaussian2Scene通过改进预训练方法，提高了3D视觉任务的效果，尤其是在几何理解和跨模态学习方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) for point cloud pre-training has become acornerstone for many 3D vision tasks, enabling effective learning fromlarge-scale unannotated data. At the scene level, existing SSL methods oftenincorporate volume rendering into the pre-training framework, using RGB-Dimages as reconstruction signals to facilitate cross-modal learning. Thisstrategy promotes alignment between 2D and 3D modalities and enables the modelto benefit from rich visual cues in the RGB-D inputs. However, these approachesare limited by their reliance on implicit scene representations and high memorydemands. Furthermore, since their reconstruction objectives are applied only in2D space, they often fail to capture underlying 3D geometric structures. Toaddress these challenges, we propose Gaussian2Scene, a novel scene-level SSLframework that leverages the efficiency and explicit nature of 3D GaussianSplatting (3DGS) for pre-training. The use of 3DGS not only alleviates thecomputational burden associated with volume rendering but also supports direct3D scene reconstruction, thereby enhancing the geometric understanding of thebackbone network. Our approach follows a progressive two-stage trainingstrategy. In the first stage, a dual-branch masked autoencoder learns both 2Dand 3D scene representations. In the second stage, we initialize training withreconstructed point clouds and further supervise learning using the geometriclocations of Gaussian primitives and rendered RGB images. This processreinforces both geometric and cross-modal learning. We demonstrate theeffectiveness of Gaussian2Scene across several downstream 3D object detectiontasks, showing consistent improvements over existing pre-training methods.</description>
      <author>example@mail.com (Keyi Liu, Weidong Yang, Ben Fei, Ying He)</author>
      <guid isPermaLink="false">2506.08777v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>TrajFlow: Multi-modal Motion Prediction via Flow Matching</title>
      <link>http://arxiv.org/abs/2506.08541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TrajFlow是一个基于流匹配的运动预测框架，用于解决现有生成轨迹预测方法的可扩展性和效率问题，并在Waymo Open Motion Dataset上表现出色。&lt;h4&gt;背景&lt;/h4&gt;高效准确的运动预测对于自动驾驶安全及决策至关重要，尤其在动态的真实世界条件下需要多模态预测。&lt;h4&gt;目的&lt;/h4&gt;提出TrajFlow，解决现有生成轨迹预测方法的可扩展性和效率挑战。&lt;h4&gt;方法&lt;/h4&gt;1. 采用单次预测多个可能轨迹的方法，减少计算开销。2. 提出基于Plackett-Luce分布的排名损失函数，提高预测轨迹的不确定性估计。3. 设计自条件化训练技术，通过模型自身预测构造噪声输入，提升泛化能力和加速推理。&lt;h4&gt;主要发现&lt;/h4&gt;TrajFlow在Waymo Open Motion Dataset上实现了在多个关键指标上的最先进性能。&lt;h4&gt;结论&lt;/h4&gt;TrajFlow对于安全关键型自动驾驶应用是有效的。&lt;h4&gt;翻译&lt;/h4&gt;Efficient and accurate motion prediction is crucial for ensuring safety and informed decision-making in autonomous driving, particularly under dynamic real-world conditions that necessitate multi-modal forecasts. We introduce TrajFlow, a novel flow matching-based motion prediction framework that addresses the scalability and efficiency challenges of existing generative trajectory prediction methods. Unlike conventional generative approaches that employ i.i.d. sampling and require multiple inference passes to capture diverse outcomes, TrajFlow predicts multiple plausible future trajectories in a single pass, significantly reducing computational overhead while maintaining coherence across predictions. Moreover, we propose a ranking loss based on the Plackett-Luce distribution to improve uncertainty estimation of predicted trajectories. Additionally, we design a self-conditioning training techniquethat reuses the model's own predictions to construct noisy inputs during a second forward pass, thereby improving generalization and accelerating inference. Extensive experiments on the large-scale Waymo Open Motion Dataset (WOMD) demonstrate that TrajFlow achieves state-of-the-art performance across various key metrics, underscoring its effectiveness for safety-critical autonomous driving applications. The code and other details are available on the project website https://traj-flow.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient and accurate motion prediction is crucial for ensuring safety andinformed decision-making in autonomous driving, particularly under dynamicreal-world conditions that necessitate multi-modal forecasts. We introduceTrajFlow, a novel flow matching-based motion prediction framework thataddresses the scalability and efficiency challenges of existing generativetrajectory prediction methods. Unlike conventional generative approaches thatemploy i.i.d. sampling and require multiple inference passes to capture diverseoutcomes, TrajFlow predicts multiple plausible future trajectories in a singlepass, significantly reducing computational overhead while maintaining coherenceacross predictions. Moreover, we propose a ranking loss based on thePlackett-Luce distribution to improve uncertainty estimation of predictedtrajectories. Additionally, we design a self-conditioning training techniquethat reuses the model's own predictions to construct noisy inputs during asecond forward pass, thereby improving generalization and acceleratinginference. Extensive experiments on the large-scale Waymo Open Motion Dataset(WOMD) demonstrate that TrajFlow achieves state-of-the-art performance acrossvarious key metrics, underscoring its effectiveness for safety-criticalautonomous driving applications. The code and other details are available onthe project website https://traj-flow.github.io/.</description>
      <author>example@mail.com (Qi Yan, Brian Zhang, Yutong Zhang, Daniel Yang, Joshua White, Di Chen, Jiachao Liu, Langechuan Liu, Binnan Zhuang, Shaoshuai Shi, Renjie Liao)</author>
      <guid isPermaLink="false">2506.08541v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Cosmos-Drive-Dreams: Scalable Synthetic Driving Data Generation with World Foundation Models</title>
      <link>http://arxiv.org/abs/2506.09042v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Xuanchi Ren, Yifan Lu, Tianshi Cao, Ruiyuan Gao: Equal contribution.  Only the core contributors are listed. The full list of contributors can be  found in Appendix A of this paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Cosmos-Drive-Dreams的合成数据生成（SDG）流程，旨在为自动驾驶（AV）系统等关键物理AI系统生成具有挑战性的场景，以促进感知和驾驶策略训练等下游任务。&lt;h4&gt;背景&lt;/h4&gt;收集和注释用于安全关键物理AI系统（如自动驾驶汽车）的真实世界数据既耗时又昂贵，尤其是捕捉罕见边缘情况，这些情况在AV系统的训练和测试中起着关键作用。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，目的是生成具有挑战性的场景，以促进下游任务，如感知和驾驶策略训练。&lt;h4&gt;方法&lt;/h4&gt;Cosmos-Drive-Dreams流程由Cosmos-Drive支持，这是一个从NVIDIA Cosmos世界基础模型专门针对驾驶领域优化的模型套件，能够生成可控、高保真、多视角和时空一致性的驾驶视频。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，生成的数据有助于缓解长尾分布问题，并增强了下游任务（如3D车道检测、3D物体检测和驾驶策略学习）的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文开源了Cosmos-Drive-Dreams的流程工具包、数据集和模型权重，通过NVIDIA的Cosmos平台提供。&lt;h4&gt;翻译&lt;/h4&gt;Collecting and annotating real-world data for safety-critical physical AI systems, such as Autonomous Vehicle (AV), is time-consuming and costly. It is especially challenging to capture rare edge cases, which play a critical role in training and testing of an AV system. To address this challenge, we introduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipeline that aims to generate challenging scenarios to facilitate downstream tasks such as perception and driving policy training. Powering this pipeline is Cosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundation model for the driving domain and are capable of controllable, high-fidelity, multi-view, and spatiotemporally consistent driving video generation. We showcase the utility of these models by applying Cosmos-Drive-Dreams to scale the quantity and diversity of driving datasets with high-fidelity and challenging scenarios. Experimentally, we demonstrate that our generated data helps in mitigating long-tail distribution problems and enhances generalization in downstream tasks such as 3D lane detection, 3D object detection and driving policy learning. We open source our pipeline toolkit, dataset and model weight through the NVIDIA's Cosmos platform.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Collecting and annotating real-world data for safety-critical physical AIsystems, such as Autonomous Vehicle (AV), is time-consuming and costly. It isespecially challenging to capture rare edge cases, which play a critical rolein training and testing of an AV system. To address this challenge, weintroduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipelinethat aims to generate challenging scenarios to facilitate downstream tasks suchas perception and driving policy training. Powering this pipeline isCosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundationmodel for the driving domain and are capable of controllable, high-fidelity,multi-view, and spatiotemporally consistent driving video generation. Weshowcase the utility of these models by applying Cosmos-Drive-Dreams to scalethe quantity and diversity of driving datasets with high-fidelity andchallenging scenarios. Experimentally, we demonstrate that our generated datahelps in mitigating long-tail distribution problems and enhances generalizationin downstream tasks such as 3D lane detection, 3D object detection and drivingpolicy learning. We open source our pipeline toolkit, dataset and model weightsthrough the NVIDIA's Cosmos platform.  Project page: https://research.nvidia.com/labs/toronto-ai/cosmos_drive_dreams</description>
      <author>example@mail.com (Xuanchi Ren, Yifan Lu, Tianshi Cao, Ruiyuan Gao, Shengyu Huang, Amirmojtaba Sabour, Tianchang Shen, Tobias Pfaff, Jay Zhangjie Wu, Runjian Chen, Seung Wook Kim, Jun Gao, Laura Leal-Taixe, Mike Chen, Sanja Fidler, Huan Ling)</author>
      <guid isPermaLink="false">2506.09042v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Data-Efficient Challenges in Visual Inductive Priors: A Retrospective</title>
      <link>http://arxiv.org/abs/2506.08612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在数据不足的设置中，哪些深度学习方法能够提高模型的训练效果。&lt;h4&gt;背景&lt;/h4&gt;深度学习需要大量数据来训练模型，但在数据不足的情况下，模型的性能可能会下降。&lt;h4&gt;目的&lt;/h4&gt;通过组织“VIPriors：视觉归纳先验用于数据高效深度学习”研讨会系列，旨在刺激新型方法的发展，这些方法通过结合先验知识来提高深度学习模型的数据效率。&lt;h4&gt;方法&lt;/h4&gt;研讨会包括四届数据受损挑战赛，参与者只能使用少量训练样本从头开始训练模型，并且不允许使用任何形式的迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;成功的挑战参赛作品使用了混合Transformer和CNN的大规模模型集成，以及大量的数据增强。基于新先验知识的方法在某些参赛作品中取得了成功。&lt;h4&gt;结论&lt;/h4&gt;数据不足的环境下，深度学习模型可以通过结合先验知识和创新的模型集成方法来提高数据效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep Learning requires large amounts of data to train models that work well.In data-deficient settings, performance can be degraded. We investigate whichDeep Learning methods benefit training models in a data-deficient setting, byorganizing the "VIPriors: Visual Inductive Priors for Data-Efficient DeepLearning" workshop series, featuring four editions of data-impaired challenges.These challenges address the problem of training deep learning models forcomputer vision tasks with limited data. Participants are limited to trainingmodels from scratch using a low number of training samples and are not allowedto use any form of transfer learning. We aim to stimulate the development ofnovel approaches that incorporate prior knowledge to improve the dataefficiency of deep learning models. Successful challenge entries make use oflarge model ensembles that mix Transformers and CNNs, as well as heavy dataaugmentation. Novel prior knowledge-based methods contribute to success in someentries.</description>
      <author>example@mail.com (Robert-Jan Bruintjes, Attila Lengyel, Osman Semih Kayhan, Davide Zambrano, Nergis Tömen, Hadi Jamali-Rad, Jan van Gemert)</author>
      <guid isPermaLink="false">2506.08612v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Effective Data Pruning through Score Extrapolation</title>
      <link>http://arxiv.org/abs/2506.09010v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的数据剪枝技术，通过在小数据集上训练来预测整个数据集的样本重要性，从而在保持模型性能的同时减少计算成本。&lt;h4&gt;背景&lt;/h4&gt;高级机器学习模型训练需要大量数据集，导致计算成本高昂。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，提出了一种新的数据剪枝方法，以减少计算成本。&lt;h4&gt;方法&lt;/h4&gt;该方法通过在少量数据上训练，使用k最近邻和图神经网络来预测样本重要性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在动态不确定性剪枝和TDDS剪枝等两种现有剪枝方法、四个不同数据集（CIFAR-10、CIFAR-100、Places-365和ImageNet）以及三种训练范式（监督学习、无监督学习和对抗学习）中均显示出有效性。&lt;h4&gt;结论&lt;/h4&gt;分数外推是一种有前途的方法，可以扩展像剪枝这样的昂贵计算方法。&lt;h4&gt;翻译&lt;/h4&gt;Training advanced machine learning models requires massive datasets, resulting in prohibitive computational costs. To address this challenge, data pruning techniques identify and remove redundant training samples while preserving model performance. Yet, existing pruning techniques predominantly require a full initial training pass to identify removable samples, negating any efficiency benefits for single training runs. To overcome this limitation, we introduce a novel importance score extrapolation framework that requires training on only a small subset of data. We present two initial approaches in this framework - k-nearest neighbors and graph neural networks - to accurately predict sample importance for the entire dataset using patterns learned from this minimal subset. We demonstrate the effectiveness of our approach for 2 state-of-the-art pruning methods (Dynamic Uncertainty and TDDS), 4 different datasets (CIFAR-10, CIFAR-100, Places-365, and ImageNet), and 3 training paradigms (supervised, unsupervised, and adversarial). Our results indicate that score extrapolation is a promising direction to scale expensive score calculation methods, such as pruning, data attribution, or other tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training advanced machine learning models demands massive datasets, resultingin prohibitive computational costs. To address this challenge, data pruningtechniques identify and remove redundant training samples while preservingmodel performance. Yet, existing pruning techniques predominantly require afull initial training pass to identify removable samples, negating anyefficiency benefits for single training runs. To overcome this limitation, weintroduce a novel importance score extrapolation framework that requirestraining on only a small subset of data. We present two initial approaches inthis framework - k-nearest neighbors and graph neural networks - to accuratelypredict sample importance for the entire dataset using patterns learned fromthis minimal subset. We demonstrate the effectiveness of our approach for 2state-of-the-art pruning methods (Dynamic Uncertainty and TDDS), 4 differentdatasets (CIFAR-10, CIFAR-100, Places-365, and ImageNet), and 3 trainingparadigms (supervised, unsupervised, and adversarial). Our results indicatethat score extrapolation is a promising direction to scale expensive scorecalculation methods, such as pruning, data attribution, or other tasks.</description>
      <author>example@mail.com (Sebastian Schmidt, Prasanga Dhungel, Christoffer Löffler, Björn Nieth, Stephan Günnemann, Leo Schwinn)</author>
      <guid isPermaLink="false">2506.09010v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Rapid cardiac activation prediction for cardiac resynchronization therapy planning using geometric deep learning</title>
      <link>http://arxiv.org/abs/2506.08987v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文开发了一种基于几何深度学习模型的方法，用于预测心脏激动时间图，以优化心脏再同步治疗（CRT）。&lt;h4&gt;背景&lt;/h4&gt;CRT是治疗同步性心脏衰竭的常见干预措施，但由于电极放置不佳，大约三分之一的患者无法响应。&lt;h4&gt;目的&lt;/h4&gt;构建一种在硅中模拟的方法，以帮助解决CRT规划中识别最佳起搏位点的问题。&lt;h4&gt;方法&lt;/h4&gt;开发了两种基于图神经网络（GNN）和几何信息神经网络操作符（GINO）的几何深度学习（DL）模型，用于实时预测CRT规划中的心脏激动时间图。这些模型在由有限元（FE）模拟生成的大型合成数据集上进行了训练，数据集涵盖了广泛的心室（LV）几何形状、起搏位点配置和组织电导率。&lt;h4&gt;主要发现&lt;/h4&gt;GINO模型在预测精度和鲁棒性方面优于GNN模型，且预测误差更低（1.14% vs 3.14%），对噪声和不同网格离散化具有更好的鲁棒性。使用GINO模型，我们还开发了一种从给定的激动时间图和LV几何形状中优化CRT起搏位点的流程。与随机选择起搏位点相比，CRT优化流程可以显著减少最大激动时间（20% vs. 8%）。&lt;h4&gt;结论&lt;/h4&gt;GINO模型在CRT个性化术前优化方面具有作为临床决策支持工具的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Cardiac resynchronization therapy (CRT) is a common intervention for patients with dyssynchronous heart failure, yet approximately one-third of recipients fail to respond due to suboptimal lead placement. Identifying optimal pacing sites remains challenging, largely due to patient-specific anatomical variability and the limitations of current individualized planning strategies. In a step towards constructing an in-silico approach to help address this issue, we develop two geometric deep learning (DL) models, based on graph neural network (GNN) and geometry-informed neural operator (GINO), to predict cardiac activation time map in real-time for CRT planning and optimization. Both models are trained on a large synthetic dataset generated from finite-element (FE) simulations over a wide range of left ventricular (LV) geometries, pacing site configurations, and tissue conductivities. The GINO model significantly outperforms the GNN model, with lower prediction errors (1.14% vs 3.14%) and superior robustness to noise and various mesh discretization. Using the GINO model, we also develop a workflow for optimizing the pacing site in CRT from given activation time map and LV geometry. Compared to randomly selecting a pacing site, the CRT optimization workflow produces a larger reduction in maximum activation time (20% vs. 8%). In conjunction with an interactive web-based graphical user interface (GUI) available at https://dcsim.egr.msu.edu/, the GINO model shows promising potential as a clinical decision-support tool for personalized pre-procedural CRT optimization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ehsanngh/DeepCardioSim&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cardiac resynchronization therapy (CRT) is a common intervention for patientswith dyssynchronous heart failure, yet approximately one-third of recipientsfail to respond due to suboptimal lead placement. Identifying optimal pacingsites remains challenging, largely due to patient-specific anatomicalvariability and the limitations of current individualized planning strategies.In a step towards constructing an in-silico approach to help address thisissue, we develop two geometric deep learning (DL) models, based on graphneural network (GNN) and geometry-informed neural operator (GINO), to predictcardiac activation time map in real-time for CRT planning and optimization.Both models are trained on a large synthetic dataset generated fromfinite-element (FE) simulations over a wide range of left ventricular (LV)geometries, pacing site configurations, and tissue conductivities. The GINOmodel significantly outperforms the GNN model, with lower prediction errors(1.14% vs 3.14%) and superior robustness to noise and various meshdiscretization. Using the GINO model, we also develop a workflow for optimizingthe pacing site in CRT from given activation time map and LV geometry. Comparedto randomly selecting a pacing site, the CRT optimization workflow produces alarger reduction in maximum activation time (20% vs. 8%). In conjunction withan interactive web-based graphical user interface (GUI) available athttps://dcsim.egr.msu.edu/, the GINO model shows promising potential as aclinical decision-support tool for personalized pre-procedural CRToptimization.</description>
      <author>example@mail.com (Ehsan Naghavi, Haifeng Wang, Vahid Ziaei Rad, Julius Guccione, Ghassan Kassab, Vishnu Boddeti, Seungik Baek, Lik-Chuan Lee)</author>
      <guid isPermaLink="false">2506.08987v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>SceneSplat++: A Large Dataset and Comprehensive Benchmark for Language Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.08710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, codes, data and benchmark will be released&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为3D Gaussian Splatting的3D场景编码方法，并建立了一个大规模基准来评估不同方法在3D空间中的性能。&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting是一种高效的场景几何、外观和语义编码方法，将语言与3D场景结合是理解3D场景的有效策略。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法在评估上存在的局限性，提出一个能够全面评估不同方法的基准。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含1060个场景的大规模基准，涵盖室内和室外数据集，评估了基于场景优化、无场景优化和通用方法的三种主要方法。&lt;h4&gt;主要发现&lt;/h4&gt;通用方法在放宽场景特定限制、实现快速前向推理和获得更好的分割性能方面具有明显优势。&lt;h4&gt;结论&lt;/h4&gt;提出了一个名为GaussianWorld-49K的精心策划的3DGS数据集，展示了通用方法可以利用强大的数据先验，并公开了代码、基准和数据集以加速研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D高斯散布（3DGS）是一种高效且有效的场景几何、外观和语义编码。此外，将语言根植于3D场景已被证明是理解3D场景的有效策略。当前的语言高斯散布工作分为三大类：（一）基于场景优化的，（二）无场景优化的，（三）通用方法。然而，大多数工作只评估了少量场景和视角接近训练视图的渲染2D视图，限制了全面3D理解的能力和洞察力。为了解决这一差距，我们提出了第一个直接在3D空间中系统评估这三组方法的基准。在三个室内数据集和一个室外数据集上评估了1060个场景。基准结果表明，通用范式具有明显优势，尤其是在放宽场景特定限制、实现新颖场景的快速前向推理和获得更好的分割性能方面。我们进一步引入了GaussianWorld-49K，这是一个包含约49K个来自多个来源的室内和室外场景的精心策划的3DGS数据集，我们展示了通用方法可以利用强大的数据先验。我们的代码、基准和数据集将公开，以加速通用3DGS场景理解的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) serves as a highly performant and efficientencoding of scene geometry, appearance, and semantics. Moreover, groundinglanguage in 3D scenes has proven to be an effective strategy for 3D sceneunderstanding. Current Language Gaussian Splatting line of work fall into threemain groups: (i) per-scene optimization-based, (ii) per-sceneoptimization-free, and (iii) generalizable approach. However, most of them areevaluated only on rendered 2D views of a handful of scenes and viewpoints closeto the training views, limiting ability and insight into holistic 3Dunderstanding. To address this gap, we propose the first large-scale benchmarkthat systematically assesses these three groups of methods directly in 3Dspace, evaluating on 1060 scenes across three indoor datasets and one outdoordataset. Benchmark results demonstrate a clear advantage of the generalizableparadigm, particularly in relaxing the scene-specific limitation, enabling fastfeed-forward inference on novel scenes, and achieving superior segmentationperformance. We further introduce GaussianWorld-49K a carefully curated 3DGSdataset comprising around 49K diverse indoor and outdoor scenes obtained frommultiple sources, with which we demonstrate the generalizable approach couldharness strong data priors. Our codes, benchmark, and datasets will be madepublic to accelerate research in generalizable 3DGS scene understanding.</description>
      <author>example@mail.com (Mengjiao Ma, Qi Ma, Yue Li, Jiahuan Cheng, Runyi Yang, Bin Ren, Nikola Popovic, Mingqiang Wei, Nicu Sebe, Luc Van Gool, Theo Gevers, Martin R. Oswald, Danda Pani Paudel)</author>
      <guid isPermaLink="false">2506.08710v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Medical Vision-Language Alignment Through Adapting Masked Vision Models</title>
      <link>http://arxiv.org/abs/2506.08990v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  TMI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ALTA的医学视觉-语言对齐方法，该方法在图像-文本匹配任务中表现优异，如检索和零样本分类。ALTA通过优化视觉模型和整合时间多视图影像输入，提高了视觉-语言对齐的效果。&lt;h4&gt;背景&lt;/h4&gt;传统的跨模态对比学习方法在视觉-语言对齐中存在视觉表示能力不足的问题，而多模态掩码模型预训练的模型虽然在视觉表示上表现较好，但在直接跨模态匹配上存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且性能优越的医学视觉-语言对齐方法，以解决传统方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;ALTA方法利用了约8%的可训练参数和少于1/5的掩码记录建模的计算消耗。它通过调整预训练的视觉模型，并结合时间多视图影像输入，来提高视觉-语言对齐的性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ALTA在文本到图像的准确率和图像到文本的检索准确率上分别优于最佳竞争者超过4%和6%。&lt;h4&gt;结论&lt;/h4&gt;ALTA是一种有效的医学视觉-语言对齐方法，通过优化视觉模型和整合影像输入，提高了视觉-语言对齐的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通过跨模态对比学习实现的医学视觉-语言对齐在图像-文本匹配任务中表现出良好的性能，如检索和零样本分类。然而，传统的跨模态对比学习方法（基于CLIP）在视觉表示能力上存在不足，这也限制了它们在视觉-语言对齐中的有效性。相比之下，虽然通过多模态掩码模型预训练的模型在直接跨模态匹配上存在困难，但它们在视觉表示上表现出色。为了解决这一矛盾，我们提出了ALTA（通过调整对齐），一种高效的医学视觉-语言对齐方法，它仅使用了大约8%的可训练参数，以及掩码记录建模所需计算消耗的不到1/5。ALTA通过调整掩码记录建模预训练的视觉模型，在检索和零样本分类等视觉-语言匹配任务中实现了优异的性能。此外，我们还整合了时间多视图影像输入，以增强影像与其对应报告中描述之间的信息一致性，进一步提高了视觉-语言对齐的效果。实验评估表明，ALTA在文本到图像的准确率上优于最佳竞争者超过4%，在图像到文本的检索准确率上约高6%。在有效对齐过程中对视觉-语言模型的调整也促进了更好的视觉和语言理解。代码可在https://github.com/DopamineLcy/ALTA公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TMI.2025.3575853&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical vision-language alignment through cross-modal contrastive learningshows promising performance in image-text matching tasks, such as retrieval andzero-shot classification. However, conventional cross-modal contrastivelearning (CLIP-based) methods suffer from suboptimal visual representationcapabilities, which also limits their effectiveness in vision-languagealignment. In contrast, although the models pretrained via multimodal maskedmodeling struggle with direct cross-modal matching, they excel in visualrepresentation. To address this contradiction, we propose ALTA (ALign ThroughAdapting), an efficient medical vision-language alignment method that utilizesonly about 8% of the trainable parameters and less than 1/5 of thecomputational consumption required for masked record modeling. ALTA achievessuperior performance in vision-language matching tasks like retrieval andzero-shot classification by adapting the pretrained vision model from maskedrecord modeling. Additionally, we integrate temporal-multiview radiographinputs to enhance the information consistency between radiographs and theircorresponding descriptions in reports, further improving the vision-languagealignment. Experimental evaluations show that ALTA outperforms thebest-performing counterpart by over 4% absolute points in text-to-imageaccuracy and approximately 6% absolute points in image-to-text retrievalaccuracy. The adaptation of vision-language models during efficient alignmentalso promotes better vision and language understanding. Code is publiclyavailable at https://github.com/DopamineLcy/ALTA.</description>
      <author>example@mail.com (Chenyu Lian, Hong-Yu Zhou, Dongyun Liang, Jing Qin, Liansheng Wang)</author>
      <guid isPermaLink="false">2506.08990v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>LiftVSR: Lifting Image Diffusion to Video Super-Resolution via Hybrid Temporal Modeling with Only 4$\times$RTX 4090s</title>
      <link>http://arxiv.org/abs/2506.08529v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://kopperx.github.io/projects/liftvsr&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;LiftVSR是一种高效的视频超分辨率框架，通过提升图像扩散先验和引入混合时间建模机制，在保持长期一致性和效率的同时，显著降低了计算成本。&lt;h4&gt;背景&lt;/h4&gt;现有的视频超分辨率方法在保证帧间一致性和降低计算成本方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一个高效的VSR框架，以平衡长期一致性和效率。&lt;h4&gt;方法&lt;/h4&gt;引入了一种混合时间建模机制，包括：(i) 动态时间注意力（DTA）用于短帧段内的细粒度时间建模，和(ii) 注意力内存缓存（AMC）用于跨段的长期时间建模。此外，还引入了不对称采样策略以稳定缓存交互。&lt;h4&gt;主要发现&lt;/h4&gt;LiftVSR在多个VSR基准测试中表现出色，并且计算成本显著低于现有方法。&lt;h4&gt;结论&lt;/h4&gt;LiftVSR通过创新的技术解决了现有VSR方法的局限性，实现了高效的视频超分辨率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion models have significantly advanced video super-resolution (VSR) byenhancing perceptual quality, largely through elaborately designed temporalmodeling to ensure inter-frame consistency. However, existing methods usuallysuffer from limited temporal coherence and prohibitively high computationalcosts (e.g., typically requiring over 8 NVIDIA A100-80G GPUs), especially forlong videos. In this work, we propose LiftVSR, an efficient VSR framework thatleverages and elevates the image-wise diffusion prior from PixArt-$\alpha$,achieving state-of-the-art results using only 4$\times$RTX 4090 GPUs. Tobalance long-term consistency and efficiency, we introduce a hybrid temporalmodeling mechanism that decomposes temporal learning into two complementarycomponents: (i) Dynamic Temporal Attention (DTA) for fine-grained temporalmodeling within short frame segment ($\textit{i.e.}$, low complexity), and (ii)Attention Memory Cache (AMC) for long-term temporal modeling across segments($\textit{i.e.}$, consistency). Specifically, DTA identifies multiple tokenflows across frames within multi-head query and key tokens to warp inter-framecontexts in the value tokens. AMC adaptively aggregates historical segmentinformation via a cache unit, ensuring long-term coherence with minimaloverhead. To further stabilize the cache interaction during inference, weintroduce an asymmetric sampling strategy that mitigates feature mismatchesarising from different diffusion sampling steps. Extensive experiments onseveral typical VSR benchmarks have demonstrated that LiftVSR achievesimpressive performance with significantly lower computational costs.</description>
      <author>example@mail.com (Xijun Wang, Xin Li, Bingchen Li, Zhibo Chen)</author>
      <guid isPermaLink="false">2506.08529v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>InfoDPCCA: Information-Theoretic Dynamic Probabilistic Canonical Correlation Analysis</title>
      <link>http://arxiv.org/abs/2506.08884v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by UAI-25, code is available at  \url{https://github.com/marcusstang/InfoDPCCA}&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;InfoDPCCA是一种动态概率典型相关分析（CCA）框架，用于从高维序列数据中提取有意义的潜在表示。&lt;h4&gt;背景&lt;/h4&gt;提取高维序列数据中的潜在表示是机器学习中的一个关键挑战，其应用范围涵盖自然科学和工程领域。&lt;h4&gt;目的&lt;/h4&gt;InfoDPCCA旨在模型两个相互依赖的观察序列，提取共享的潜在表示，同时学习针对每个序列的特定信息。&lt;h4&gt;方法&lt;/h4&gt;InfoDPCCA利用一种新的信息论目标函数来提取共享的潜在表示，并学习单独的潜在组件，以编码每个序列的特定信息。此外，它引入了一种两步训练方案和残差连接机制来提高训练稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;InfoDPCCA在合成和医学fMRI数据上的实验表明，它是一种出色的表示学习工具。&lt;h4&gt;结论&lt;/h4&gt;InfoDPCCA通过提高可解释性和鲁棒性，有效地解决了动态CCA模型中的互信息编码问题。&lt;h4&gt;翻译&lt;/h4&gt;从高维序列数据中提取有意义的潜在表示是机器学习中的一个关键挑战，其应用范围涵盖自然科学和工程领域。我们引入了InfoDPCCA，这是一种动态概率典型相关分析（CCA）框架，旨在模型两个相互依赖的观察序列。InfoDPCCA利用一种新的信息论目标函数来提取共享的潜在表示，以捕获数据流之间的相互结构，并在表示压缩和预测充分性之间取得平衡，同时学习针对每个序列的特定信息。与DPCCA等先前动态CCA模型不同，我们的方法明确强制共享潜在空间仅编码序列之间的互信息，从而提高了可解释性和鲁棒性。我们还引入了一种两步训练方案，以弥合信息论表示学习和生成建模之间的差距，并采用残差连接机制来增强训练稳定性。通过合成和医学fMRI数据上的实验，我们证明了InfoDPCCA作为表示学习工具的优越性。InfoDPCCA的代码可在https://github.com/marcusstang/InfoDPCCA上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Extracting meaningful latent representations from high-dimensional sequentialdata is a crucial challenge in machine learning, with applications spanningnatural science and engineering. We introduce InfoDPCCA, a dynamicprobabilistic Canonical Correlation Analysis (CCA) framework designed to modeltwo interdependent sequences of observations. InfoDPCCA leverages a novelinformation-theoretic objective to extract a shared latent representation thatcaptures the mutual structure between the data streams and balancesrepresentation compression and predictive sufficiency while also learningseparate latent components that encode information specific to each sequence.Unlike prior dynamic CCA models, such as DPCCA, our approach explicitlyenforces the shared latent space to encode only the mutual information betweenthe sequences, improving interpretability and robustness. We further introducea two-step training scheme to bridge the gap between information-theoreticrepresentation learning and generative modeling, along with a residualconnection mechanism to enhance training stability. Through experiments onsynthetic and medical fMRI data, we demonstrate that InfoDPCCA excels as a toolfor representation learning. Code of InfoDPCCA is available athttps://github.com/marcusstang/InfoDPCCA.</description>
      <author>example@mail.com (Shiqin Tang, Shujian Yu)</author>
      <guid isPermaLink="false">2506.08884v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>ArrowPose: Segmentation, Detection, and 5 DoF Pose Estimation Network for Colorless Point Clouds</title>
      <link>http://arxiv.org/abs/2506.08699v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于无色点云的快速检测和5自由度姿态估计网络。&lt;h4&gt;背景&lt;/h4&gt;该网络通过神经网络预测物体的中心和顶部点来进行姿态估计。&lt;h4&gt;目的&lt;/h4&gt;该网络旨在实现快速且准确的无色点云姿态估计。&lt;h4&gt;方法&lt;/h4&gt;网络在合成数据上训练，并在基准数据集上进行测试，显示出最先进的性能，优于所有无色方法。&lt;h4&gt;主要发现&lt;/h4&gt;该网络能够在仅250毫秒内完成推理，适用于多种场景。&lt;h4&gt;结论&lt;/h4&gt;该网络为无色点云的姿态估计提供了一种快速且有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种针对无色点云的快速检测和5自由度姿态估计网络。该网络通过神经网络预测物体的中心和顶部点来进行姿态估计。网络在合成数据上训练，在基准数据集上测试，表现出最先进的性能，优于所有无色方法。该网络能够在仅250毫秒内完成推理，适用于多种场景。项目页面及代码位于arrowpose.github.io。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a fast detection and 5 DoF (Degrees of Freedom) poseestimation network for colorless point clouds. The pose estimation iscalculated from center and top points of the object, predicted by the neuralnetwork. The network is trained on synthetic data, and tested on a benchmarkdataset, where it demonstrates state-of-the-art performance and outperforms allcolorless methods. The network is able to run inference in only 250milliseconds making it usable in many scenarios. Project page with code atarrowpose.github.io</description>
      <author>example@mail.com (Frederik Hagelskjaer)</author>
      <guid isPermaLink="false">2506.08699v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Adapting to Heterophilic Graph Data with Structure-Guided Neighbor Discovery</title>
      <link>http://arxiv.org/abs/2506.08871v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为结构引导图神经网络（SG-GNN）的架构，用于解决异质数据中的图神经网络（GNNs）性能问题，通过创建新的图结构来提高标签同质性，并通过实验证明其有效性。&lt;h4&gt;背景&lt;/h4&gt;GNNs在处理异质数据时存在困难，因为它们通常假设同质性并依赖于局部消息传递。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来提高GNN在异质数据上的性能。&lt;h4&gt;方法&lt;/h4&gt;通过创建具有相似结构属性的节点链接来构建新的图结构，并证明使用具有较少错误正边（不同类节点之间的连接）的图可以提高GNN性能。引入SG-GNN架构，该架构同时处理原始图和新创建的结构图，自适应地学习权衡它们的贡献。&lt;h4&gt;主要发现&lt;/h4&gt;SG-GNN在具有异质特性的各种基准数据集上实现了最先进或高度竞争的性能，证明了利用结构信息引导GNN的有效性。&lt;h4&gt;结论&lt;/h4&gt;结构引导GNN（SG-GNN）通过利用结构信息提高了GNN在处理异质数据时的性能，为GNN的应用提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) often struggle with heterophilic data, where connected nodes may have dissimilar labels, as they typically assume homophily and rely on local message passing. To address this, we propose creating alternative graph structures by linking nodes with similar structural attributes (e.g., role-based or global), thereby fostering higher label homophily on these new graphs. We theoretically prove that GNN performance can be improved by utilizing graphs with fewer false positive edges (connections between nodes of different classes) and that considering multiple graph views increases the likelihood of finding such beneficial structures. Building on these insights, we introduce Structure-Guided GNN (SG-GNN), an architecture that processes the original graph alongside the newly created structural graphs, adaptively learning to weigh their contributions. Extensive experiments on various benchmark datasets, particularly those with heterophilic characteristics, demonstrate that our SG-GNN achieves state-of-the-art or highly competitive performance, highlighting the efficacy of exploiting structural information to guide GNNs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) often struggle with heterophilic data, whereconnected nodes may have dissimilar labels, as they typically assume homophilyand rely on local message passing. To address this, we propose creatingalternative graph structures by linking nodes with similar structuralattributes (e.g., role-based or global), thereby fostering higher labelhomophily on these new graphs. We theoretically prove that GNN performance canbe improved by utilizing graphs with fewer false positive edges (connectionsbetween nodes of different classes) and that considering multiple graph viewsincreases the likelihood of finding such beneficial structures. Building onthese insights, we introduce Structure-Guided GNN (SG-GNN), an architecturethat processes the original graph alongside the newly created structuralgraphs, adaptively learning to weigh their contributions. Extensive experimentson various benchmark datasets, particularly those with heterophiliccharacteristics, demonstrate that our SG-GNN achieves state-of-the-art orhighly competitive performance, highlighting the efficacy of exploitingstructural information to guide GNNs.</description>
      <author>example@mail.com (Victor M. Tenorio, Madeline Navarro, Samuel Rey, Santiago Segarra, Antonio G. Marques)</author>
      <guid isPermaLink="false">2506.08871v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly</title>
      <link>http://arxiv.org/abs/2506.08708v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PhyBlock是一个渐进式基准，用于评估视觉语言模型（VLMs）在物理理解和规划方面的能力，特别是在结构化的3D环境中。&lt;h4&gt;背景&lt;/h4&gt;尽管视觉语言模型在推理和规划方面表现出有希望的能力，但它们理解物理现象的能力，特别是在结构化的3D环境中，仍然非常有限。&lt;h4&gt;目的&lt;/h4&gt;为了缩小这一差距，PhyBlock通过机器人3D积木组装任务评估VLMs的物理理解和规划能力。&lt;h4&gt;方法&lt;/h4&gt;PhyBlock整合了一个新颖的四级认知层次组装任务和针对性的视觉问答（VQA）样本，旨在评估渐进式空间推理和基本物理理解，包括物体属性、空间关系和整体场景理解。它包括2600个积木任务（400个组装任务，2200个VQA任务），并从部分完成、故障诊断和规划鲁棒性三个关键维度评估模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，VLMs在高级规划和推理能力方面存在明显限制，导致随着任务复杂性的增加，性能显著下降。错误分析揭示了在空间定位和依赖推理方面的持续困难。令人惊讶的是，思维链提示提供的改进最小，表明空间任务严重依赖于直观的模型理解。&lt;h4&gt;结论&lt;/h4&gt;PhyBlock被定位为一个统一的测试平台，以推进具身推理，架起视觉语言理解和现实世界物理问题解决之间的桥梁。&lt;h4&gt;翻译&lt;/h4&gt;While vision-language models (VLMs) have demonstrated promising capabilities in reasoning and planning for embodied agents, their ability to comprehend physical phenomena, particularly within structured 3D environments, remains severely limited. To close this gap, we introduce PhyBlock, a progressive benchmark designed to assess VLMs on physical understanding and planning through robotic 3D block assembly tasks. PhyBlock integrates a novel four-level cognitive hierarchy assembly task alongside targeted Visual Question Answering (VQA) samples, collectively aimed at evaluating progressive spatial reasoning and fundamental physical comprehension, including object properties, spatial relationships, and holistic scene understanding. PhyBlock includes 2600 block tasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three key dimensions: partial completion, failure diagnosis, and planning robustness. We benchmark 21 state-of-the-art VLMs, highlighting their strengths and limitations in physically grounded, multi-step planning. Our empirical findings indicate that the performance of VLMs exhibits pronounced limitations in high-level planning and reasoning capabilities, leading to a notable decline in performance for the growing complexity of the tasks. Error analysis reveals persistent difficulties in spatial orientation and dependency reasoning. Surprisingly, chain-of-thought prompting offers minimal improvements, suggesting spatial tasks heavily rely on intuitive model comprehension. We position PhyBlock as a unified testbed to advance embodied reasoning, bridging vision-language understanding and real-world physical problem-solving.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While vision-language models (VLMs) have demonstrated promising capabilitiesin reasoning and planning for embodied agents, their ability to comprehendphysical phenomena, particularly within structured 3D environments, remainsseverely limited. To close this gap, we introduce PhyBlock, a progressivebenchmark designed to assess VLMs on physical understanding and planningthrough robotic 3D block assembly tasks. PhyBlock integrates a novel four-levelcognitive hierarchy assembly task alongside targeted Visual Question Answering(VQA) samples, collectively aimed at evaluating progressive spatial reasoningand fundamental physical comprehension, including object properties, spatialrelationships, and holistic scene understanding. PhyBlock includes 2600 blocktasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across threekey dimensions: partial completion, failure diagnosis, and planning robustness.We benchmark 21 state-of-the-art VLMs, highlighting their strengths andlimitations in physically grounded, multi-step planning. Our empirical findingsindicate that the performance of VLMs exhibits pronounced limitations inhigh-level planning and reasoning capabilities, leading to a notable decline inperformance for the growing complexity of the tasks. Error analysis revealspersistent difficulties in spatial orientation and dependency reasoning.Surprisingly, chain-of-thought prompting offers minimal improvements,suggesting spatial tasks heavily rely on intuitive model comprehension. Weposition PhyBlock as a unified testbed to advance embodied reasoning, bridgingvision-language understanding and real-world physical problem-solving.</description>
      <author>example@mail.com (Liang Ma, Jiajun Wen, Min Lin, Rongtao Xu, Xiwen Liang, Bingqian Lin, Jun Ma, Yongxin Wang, Ziming Wei, Haokun Lin, Mingfei Han, Meng Cao, Bokui Chen, Ivan Laptev, Xiaodan Liang)</author>
      <guid isPermaLink="false">2506.08708v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Robust Evolutionary Multi-Objective Network Architecture Search for Reinforcement Learning (EMNAS-RL)</title>
      <link>http://arxiv.org/abs/2506.08533v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ESANN 2025 Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文首次提出了一种名为进化多目标网络架构搜索（EMNAS）的方法，用于优化大规模强化学习（RL）在自动驾驶（AD）中的应用中的神经网络架构。&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶领域，神经网络架构的优化是一个关键问题，它涉及到如何通过调整网络结构来提高性能并减少模型大小。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法来优化神经网络架构，以提高自动驾驶中的强化学习性能，同时减少模型尺寸。&lt;h4&gt;方法&lt;/h4&gt;EMNAS利用遗传算法来自动化网络设计，旨在通过增加奖励和减少模型尺寸来提升性能。此外，采用并行化技术来加速搜索过程，并实施师生方法来确保可扩展的优化。该方法强调迁移学习在优化迭代学习过程中的潜力，通过有效利用前一代的知识来提高学习效率和稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，定制的EMNAS在手动设计模型之上，以更少的参数实现了更高的奖励。&lt;h4&gt;结论&lt;/h4&gt;这些策略对自动驾驶中的强化学习领域的EMNAS方法有积极贡献，推动了向性能更优、适用于现实场景的网络架构的发展。&lt;h4&gt;翻译&lt;/h4&gt;本文首次提出了一种名为进化多目标网络架构搜索（EMNAS）的方法，用于优化大规模强化学习（RL）在自动驾驶（AD）中的应用中的神经网络架构。EMNAS利用遗传算法来自动化网络设计，旨在通过增加奖励和减少模型尺寸来提升性能。此外，采用并行化技术来加速搜索过程，并实施师生方法来确保可扩展的优化。该方法强调迁移学习在优化迭代学习过程中的潜力，通过有效利用前一代的知识来提高学习效率和稳定性。实验结果表明，定制的EMNAS在手动设计模型之上，以更少的参数实现了更高的奖励。这些策略对自动驾驶中的强化学习领域的EMNAS方法有积极贡献，推动了向性能更优、适用于现实场景的网络架构的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces Evolutionary Multi-Objective Network ArchitectureSearch (EMNAS) for the first time to optimize neural network architectures inlarge-scale Reinforcement Learning (RL) for Autonomous Driving (AD). EMNAS usesgenetic algorithms to automate network design, tailored to enhance rewards andreduce model size without compromising performance. Additionally,parallelization techniques are employed to accelerate the search, andteacher-student methodologies are implemented to ensure scalable optimization.This research underscores the potential of transfer learning as a robustframework for optimizing performance across iterative learning processes byeffectively leveraging knowledge from earlier generations to enhance learningefficiency and stability in subsequent generations. Experimental resultsdemonstrate that tailored EMNAS outperforms manually designed models, achievinghigher rewards with fewer parameters. The findings of these strategiescontribute positively to EMNAS for RL in autonomous driving, advancing thefield toward better-performing networks suitable for real-world scenarios.</description>
      <author>example@mail.com (Nihal Acharya Adde, Alexandra Gianzina, Hanno Gottschalk, Andreas Ebert)</author>
      <guid isPermaLink="false">2506.08533v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Spatial Transcriptomics Expression Prediction from Histopathology Based on Cross-Modal Mask Reconstruction and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.08854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于对比学习的深度学习方法，用于从全切片图像预测空间分辨率的基因表达，并在六个不同疾病数据集上进行了评估。&lt;h4&gt;背景&lt;/h4&gt;空间转录组学技术广泛用于肿瘤微环境和组织病理学的分子分析，但数据获取成本高，大规模空间转录组数据难以获得。&lt;h4&gt;目的&lt;/h4&gt;开发一种深度学习方法，以降低空间转录组学数据获取成本，并提高基因表达的预测准确性。&lt;h4&gt;方法&lt;/h4&gt;开发了一种基于对比学习的深度学习模型，用于从全切片图像中预测空间分辨率的基因表达，并在六个不同疾病数据集上评估其性能。&lt;h4&gt;主要发现&lt;/h4&gt;与现有研究相比，该方法在预测高度表达基因、高度可变基因和标记基因时，分别提高了6.27%、6.11%和11.26%的Pearson相关系数（PCC）。进一步分析表明，该方法保留了基因间相关性，并适用于样本量有限的数据库。此外，该方法在基于生物标志物表达进行癌症组织定位方面具有潜力。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于对比学习的深度学习方法在预测基因表达和癌症组织定位方面具有显著的优势和应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial transcriptomics is a technology that captures gene expression levelsat different spatial locations, widely used in tumor microenvironment analysisand molecular profiling of histopathology, providing valuable insights intoresolving gene expression and clinical diagnosis of cancer. Due to the highcost of data acquisition, large-scale spatial transcriptomics data remainchallenging to obtain. In this study, we develop a contrastive learning-baseddeep learning method to predict spatially resolved gene expression fromwhole-slide images. Evaluation across six different disease datasetsdemonstrates that, compared to existing studies, our method improves PearsonCorrelation Coefficient (PCC) in the prediction of highly expressed genes,highly variable genes, and marker genes by 6.27%, 6.11%, and 11.26%respectively. Further analysis indicates that our method preserves gene-genecorrelations and applies to datasets with limited samples. Additionally, ourmethod exhibits potential in cancer tissue localization based on biomarkerexpression.</description>
      <author>example@mail.com (Junzhuo Liu, Markus Eckstein, Zhixiang Wang, Friedrich Feuerhake, Dorit Merhof)</author>
      <guid isPermaLink="false">2506.08854v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>On Finetuning Tabular Foundation Models</title>
      <link>http://arxiv.org/abs/2506.08982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了表格深度学习中的基础模型，特别是TabPFNv2在小型数据集上的性能，并探讨了其微调策略和内部机制的变化。&lt;h4&gt;背景&lt;/h4&gt;TabPFNv2使用上下文学习范式在小型数据集上表现优于传统的GBDT方法，但其最佳微调方法和内部机制的改变尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;评估不同的微调策略，并研究微调如何改变TabPFNv2的内部机制。&lt;h4&gt;方法&lt;/h4&gt;对各种数据集进行系统评估，并使用类比检索增强模型的方法来研究微调的影响。&lt;h4&gt;主要发现&lt;/h4&gt;全微调在时间效率和效果方面是TabPFNv2的最实用解决方案。微调通过改进查询表示和关键表示的点积，使得TabPFNv2能够更好地近似目标依赖关系。&lt;h4&gt;结论&lt;/h4&gt;在大型数据集上微调TabPFNv2能够观察到几乎所有任务上的性能提升，特别是在具有I.I.D.拆分的学术数据集上，TabPFNv2可以达到最先进的结果，但在具有时间推移和丰富特征集的数据集上，TabPFNv2的稳定性较差，传统方法仍然更优。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates foundation models in tabular deep learning, particularly the performance of TabPFNv2 on small-scale datasets, and explores its fine-tuning strategy and changes in internal mechanisms.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are an emerging research direction in tabular deeplearning. Notably, TabPFNv2 recently claimed superior performance overtraditional GBDT-based methods on small-scale datasets using an in-contextlearning paradigm, which does not adapt model parameters to target datasets.However, the optimal finetuning approach for adapting tabular foundationalmodels, and how this adaptation reshapes their internal mechanisms, remainsunderexplored. While prior works studied finetuning for earlier foundationalmodels, inconsistent findings and TabPFNv2's unique architecture necessitatefresh investigation. To address these questions, we first systematicallyevaluate various finetuning strategies on diverse datasets. Our findingsestablish full finetuning as the most practical solution for TabPFNv2 in termsof time-efficiency and effectiveness. We then investigate how finetuning altersTabPFNv2's inner mechanisms, drawing an analogy to retrieval-augmented models.We reveal that the success of finetuning stems from the fact that aftergradient-based adaptation, the dot products of the query-representations oftest objects and the key-representations of in-context training objects moreaccurately reflect their target similarity. This improved similarity allowsfinetuned TabPFNv2 to better approximate target dependency by appropriatelyweighting relevant in-context samples, improving the retrieval-based predictionlogic. From the practical perspective, we managed to finetune TabPFNv2 ondatasets with up to 50K objects, observing performance improvements on almostall tasks. More precisely, on academic datasets with I.I.D. splits, finetuningallows TabPFNv2 to achieve state-of-the-art results, while on datasets withgradual temporal shifts and rich feature sets, TabPFNv2 is less stable andprior methods remain better.</description>
      <author>example@mail.com (Ivan Rubachev, Akim Kotelnikov, Nikolay Kartashev)</author>
      <guid isPermaLink="false">2506.08982v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>MLVTG: Mamba-Based Feature Alignment and LLM-Driven Purification for Multi-Modal Video Temporal Grounding</title>
      <link>http://arxiv.org/abs/2506.08512v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MLVTG的新型框架，用于解决视频理解中的视频时间定位问题，通过实验验证了其在多个数据集上优于现有方法的表现。&lt;h4&gt;背景&lt;/h4&gt;视频时间定位（VTG）是视频理解中的一个基本且具有挑战性的任务。现有的基于Transformer的方法往往存在冗余注意力和次优的多模态对齐问题。&lt;h4&gt;目的&lt;/h4&gt;提出MLVTG框架，旨在解决现有Transformer方法中存在的问题，实现更精确的视频时间定位。&lt;h4&gt;方法&lt;/h4&gt;MLVTG框架集成了两个关键模块：MambaAligner和LLMRefiner。MambaAligner使用堆叠的Vision Mamba块作为骨干网络，以建模时间依赖性并提取鲁棒的视频表示。LLMRefiner利用预训练的大型语言模型（LLM）的冻结层来隐式地传递语义先验，增强多模态对齐而不需要微调。&lt;h4&gt;主要发现&lt;/h4&gt;MLVTG通过结构化状态空间动力学进行时间建模，通过文本先验进行语义净化，实现了更精确的定位。在QVHighlights、Charades-STA和TVSum数据集上的实验表明，MLVTG达到了最先进的性能，并显著优于现有基线。&lt;h4&gt;结论&lt;/h4&gt;MLVTG框架在视频时间定位任务上表现出色，为视频理解领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Temporal Grounding (VTG), which aims to localize video clipscorresponding to natural language queries, is a fundamental yet challengingtask in video understanding. Existing Transformer-based methods often sufferfrom redundant attention and suboptimal multi-modal alignment. To address theselimitations, we propose MLVTG, a novel framework that integrates two keymodules: MambaAligner and LLMRefiner. MambaAligner uses stacked Vision Mambablocks as a backbone instead of Transformers to model temporal dependencies andextract robust video representations for multi-modal alignment. LLMRefinerleverages the specific frozen layer of a pre-trained Large Language Model (LLM)to implicitly transfer semantic priors, enhancing multi-modal alignment withoutfine-tuning. This dual alignment strategy, temporal modeling via structuredstate-space dynamics and semantic purification via textual priors, enables moreprecise localization. Extensive experiments on QVHighlights, Charades-STA, andTVSum demonstrate that MLVTG achieves state-of-the-art performance andsignificantly outperforms existing baselines.</description>
      <author>example@mail.com (Zhiyi Zhu, Xiaoyu Wu, Zihao Liu, Linlin Yang)</author>
      <guid isPermaLink="false">2506.08512v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>SurfR: Surface Reconstruction with Multi-scale Attention</title>
      <link>http://arxiv.org/abs/2506.08635v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in 3DV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种快速且准确的无序点云表面重建算法，采用隐式表示。&lt;h4&gt;背景&lt;/h4&gt;现有学习方法要么是针对单个对象的表示，使用小型神经网络模型，允许高表面细节，但需要针对每个对象进行训练；要么是通用表示，需要更大的模型，能够泛化到新的形状，但缺乏细节，推理速度慢。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的隐式表示方法，用于通用3D形状，其在最佳分辨率下比所有基线算法都要快，与最先进技术的性能损失微乎其微。&lt;h4&gt;方法&lt;/h4&gt;通过三个关键贡献实现了最佳精度-速度权衡。首先，为了加快重建速度，展示在早期阶段无需使用查询点进行特征提取（懒查询）。其次，使用并行多尺度网格表示，以开发对不同噪声水平和输入分辨率的鲁棒特征。最后，证明跨尺度的注意力可以提供改进的重建结果。&lt;h4&gt;主要发现&lt;/h4&gt;提出的算法在精度和速度方面取得了最佳平衡，通过懒查询、多尺度网格表示和跨尺度注意力等技术，实现了快速且准确的表面重建。&lt;h4&gt;结论&lt;/h4&gt;该方法在重建无序点云表面方面表现优异，为点云处理领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种针对无序点云的快速且准确的表面重建算法，采用隐式表示。近期学习方法要么是单对象表示，使用小型神经网络模型，允许高表面细节，但需要针对每个对象进行训练，要么是通用表示，需要更大的模型，能够泛化到新的形状，但缺乏细节，推理速度慢。我们提出了一种新的隐式表示方法，用于通用3D形状，其在最佳分辨率下比所有基线算法都要快，与最先进技术的性能损失微乎其微。我们通过三个关键贡献实现了最佳精度-速度权衡。首先，为了加快重建速度，展示在早期阶段无需使用查询点进行特征提取（懒查询）。其次，使用并行多尺度网格表示，以开发对不同噪声水平和输入分辨率的鲁棒特征。最后，证明跨尺度的注意力可以提供改进的重建结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a fast and accurate surface reconstruction algorithm forunorganized point clouds using an implicit representation. Recent learningmethods are either single-object representations with small neural models thatallow for high surface details but require per-object training or generalizedrepresentations that require larger models and generalize to newer shapes butlack details, and inference is slow. We propose a new implicit representationfor general 3D shapes that is faster than all the baselines at their optimumresolution, with only a marginal loss in performance compared to thestate-of-the-art. We achieve the best accuracy-speed trade-off using three keycontributions. Many implicit methods extract features from the point cloud toclassify whether a query point is inside or outside the object. First, to speedup the reconstruction, we show that this feature extraction does not need touse the query point at an early stage (lazy query). Second, we use a parallelmulti-scale grid representation to develop robust features for different noiselevels and input resolutions. Finally, we show that attention across scales canprovide improved reconstruction results.</description>
      <author>example@mail.com (Siddhant Ranade, Gonçalo Dias Pais, Ross Tyler Whitaker, Jacinto C. Nascimento, Pedro Miraldo, Srikumar Ramalingam)</author>
      <guid isPermaLink="false">2506.08635v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Bridging RDF Knowledge Graphs with Graph Neural Networks for Semantically-Rich Recommender Systems</title>
      <link>http://arxiv.org/abs/2506.08743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at DASFAA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将RDF知识图谱与图神经网络（GNNs）综合的方法，以充分利用RDF知识图谱的语义信息，并评估了不同GNN在推荐任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管根据W3C标准RDF创建了超过一千个知识图谱，但它们的丰富语义信息在基于GNN的推荐系统中尚未得到充分利用。&lt;h4&gt;目的&lt;/h4&gt;提出一种综合方法，将RDF知识图谱与GNNs结合，以利用RDF对象属性中的拓扑信息和RDF数据类型属性中的内容信息。&lt;h4&gt;方法&lt;/h4&gt;深入评估了各种GNN，分析了不同的语义特征初始化和图结构异质性对推荐任务性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;通过在涉及数百万节点RDF图的多场景推荐实验中，证明了利用RDF知识图谱的语义丰富性可以显著提高推荐系统。&lt;h4&gt;结论&lt;/h4&gt;为基于GNN的推荐系统在Linked Open Data云上奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have substantially advanced the field of recommender systems. However, despite the creation of more than a thousand knowledge graphs (KGs) under the W3C standard RDF, their rich semantic information has not yet been fully leveraged in GNN-based recommender systems. To address this gap, we propose a comprehensive integration of RDF KGs with GNNs that utilizes both the topological information from RDF object properties and the content information from RDF datatype properties. Our main focus is an in-depth evaluation of various GNNs, analyzing how different semantic feature initializations and types of graph structure heterogeneity influence their performance in recommendation tasks. Through experiments across multiple recommendation scenarios involving multi-million-node RDF graphs, we demonstrate that harnessing the semantic richness of RDF KGs significantly improves recommender systems and lays the groundwork for GNN-based recommenders systems for the Linked Open Data cloud. The code and data are available on our GitHub repository: https://github.com/davidlamprecht/rdf-gnn-recommendation&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have substantially advanced the field ofrecommender systems. However, despite the creation of more than a thousandknowledge graphs (KGs) under the W3C standard RDF, their rich semanticinformation has not yet been fully leveraged in GNN-based recommender systems.To address this gap, we propose a comprehensive integration of RDF KGs withGNNs that utilizes both the topological information from RDF object propertiesand the content information from RDF datatype properties. Our main focus is anin-depth evaluation of various GNNs, analyzing how different semantic featureinitializations and types of graph structure heterogeneity influence theirperformance in recommendation tasks. Through experiments across multiplerecommendation scenarios involving multi-million-node RDF graphs, wedemonstrate that harnessing the semantic richness of RDF KGs significantlyimproves recommender systems and lays the groundwork for GNN-based recommendersystems for the Linked Open Data cloud. The code and data are available on ourGitHub repository: https://github.com/davidlamprecht/rdf-gnn-recommendation</description>
      <author>example@mail.com (Michael Färber, David Lamprecht, Yuni Susanti)</author>
      <guid isPermaLink="false">2506.08743v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Context-aware TFL: A Universal Context-aware Contrastive Learning Framework for Temporal Forgery Localization</title>
      <link>http://arxiv.org/abs/2506.08493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个名为UniCaCLF的通用上下文感知对比学习框架，用于视频伪造定位，并在五个公共数据集上取得了优于现有算法的性能。&lt;h4&gt;背景&lt;/h4&gt;目前多媒体取证领域的研究主要集中于检测伪造的音频-视频内容，并取得了显著成就。然而，这些工作只将深度伪造检测视为分类任务，忽略了视频部分片段被篡改的情况。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种用于视频伪造定位的通用上下文感知对比学习框架UniCaCLF。&lt;h4&gt;方法&lt;/h4&gt;该方法利用监督对比学习通过异常检测来发现和识别伪造瞬间，实现时间伪造片段的精确定位。此外，还提出了一种新颖的上下文感知感知层，利用异构激活操作和自适应上下文更新器构建上下文感知对比目标，通过对比伪造瞬间与真实瞬间的特征距离全局上下文来增强伪造瞬间特征的判别性。还引入了一种高效的上下文感知对比编码，以监督样本的方式进一步推动真实和伪造瞬间特征的可区分性，抑制跨样本影响，提高时间伪造定位性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的UniCaCLF在五个公共数据集上显著优于现有的竞争算法。&lt;h4&gt;结论&lt;/h4&gt;UniCaCLF是一种有效的视频伪造定位方法，能够提高时间伪造定位的性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a universal context-aware contrastive learning framework called UniCaCLF for video forgery localization, which has demonstrated superior performance over existing algorithms on five public datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most research efforts in the multimedia forensics domain have focused ondetecting forgery audio-visual content and reached sound achievements. However,these works only consider deepfake detection as a classification task andignore the case where partial segments of the video are tampered with. Temporalforgery localization (TFL) of small fake audio-visual clips embedded in realvideos is still challenging and more in line with realistic applicationscenarios. To resolve this issue, we propose a universal context-awarecontrastive learning framework (UniCaCLF) for TFL. Our approach leveragessupervised contrastive learning to discover and identify forged instants bymeans of anomaly detection, allowing for the precise localization of temporalforged segments. To this end, we propose a novel context-aware perception layerthat utilizes a heterogeneous activation operation and an adaptive contextupdater to construct a context-aware contrastive objective, which enhances thediscriminability of forged instant features by contrasting them with genuineinstant features in terms of their distances to the global context. Anefficient context-aware contrastive coding is introduced to further push thelimit of instant feature distinguishability between genuine and forged instantsin a supervised sample-by-sample manner, suppressing the cross-sample influenceto improve temporal forgery localization performance. Extensive experimentalresults over five public datasets demonstrate that our proposed UniCaCLFsignificantly outperforms the state-of-the-art competing algorithms.</description>
      <author>example@mail.com (Qilin Yin, Wei Lu, Xiangyang Luo, Xiaochun Cao)</author>
      <guid isPermaLink="false">2506.08493v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Robust Visual Localization via Semantic-Guided Multi-Scale Transformer</title>
      <link>http://arxiv.org/abs/2506.08526v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合多尺度特征学习和语义场景理解的视觉定位框架，以应对动态环境中的挑战。&lt;h4&gt;背景&lt;/h4&gt;在动态环境中，如光照变化、恶劣天气和移动物体等，视觉定位仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，提出了一个框架，该框架结合多尺度特征学习和语义场景理解。&lt;h4&gt;方法&lt;/h4&gt;该方法使用具有跨尺度注意力的分层Transformer，融合几何细节和上下文线索，同时保持空间精度并适应环境变化。通过神经场景表示进行语义监督，引导网络学习视图不变的特征，编码持久性结构信息，同时抑制复杂的环境干扰。&lt;h4&gt;主要发现&lt;/h4&gt;在TartanAir上的实验表明，该方法在具有动态物体、光照变化和遮挡的挑战场景中优于现有的姿态回归方法。&lt;h4&gt;结论&lt;/h4&gt;将多尺度处理与语义引导相结合，为现实世界动态环境中的鲁棒视觉定位提供了一种有前景的策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual localization remains challenging in dynamic environments wherefluctuating lighting, adverse weather, and moving objects disrupt appearancecues. Despite advances in feature representation, current absolute poseregression methods struggle to maintain consistency under varying conditions.To address this challenge, we propose a framework that synergistically combinesmulti-scale feature learning with semantic scene understanding. Our approachemploys a hierarchical Transformer with cross-scale attention to fuse geometricdetails and contextual cues, preserving spatial precision while adapting toenvironmental changes. We improve the performance of this architecture withsemantic supervision via neural scene representation during training, guidingthe network to learn view-invariant features that encode persistent structuralinformation while suppressing complex environmental interference. Experimentson TartanAir demonstrate that our approach outperforms existing pose regressionmethods in challenging scenarios with dynamic objects, illumination changes,and occlusions. Our findings show that integrating multi-scale processing withsemantic guidance offers a promising strategy for robust visual localization inreal-world dynamic environments.</description>
      <author>example@mail.com (Zhongtao Tian, Wenhao Huang, Zhidong Chen, Xiao Wei Sun)</author>
      <guid isPermaLink="false">2506.08526v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Urban Incident Prediction with Graph Neural Networks: Integrating Government Ratings and Crowdsourced Reports</title>
      <link>http://arxiv.org/abs/2506.08740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的多视角、多输出模型，用于预测城市事件的真实状态，并分析了纽约市城市事件的数据集。&lt;h4&gt;背景&lt;/h4&gt;GNN在预测城市基础设施问题等方面被广泛应用。政府官员希望了解哪些社区发生了如路面坑洼或鼠害等问题。政府通过检查评分来观察每个社区的事件真实状态，但这些评分只针对少数社区和事件类型。同时，通过众包报告也可以观察到事件状态，但这些报告可能因不同的报告行为而存在偏差。&lt;h4&gt;目的&lt;/h4&gt;提出一种模型，使用无偏差的评分数据和有偏差的报告数据来预测事件的真实潜在状态。&lt;h4&gt;方法&lt;/h4&gt;设计了一个基于GNN的多视角、多输出模型，并收集、标准化了纽约市3年内的9,615,863条众包报告和1,041,415条政府检查评分数据，涵盖139种事件类型。&lt;h4&gt;主要发现&lt;/h4&gt;模型在真实和半合成数据上表现优于仅使用报告数据或仅使用评分数据的模型，尤其是在评分数据稀疏且报告可预测评分的情况下。此外，还量化了众包报告中的人口统计偏差，例如高收入社区的报告问题率更高。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法对于使用异构、稀疏和有偏差的数据进行潜在状态预测具有广泛的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNNs) are widely used in urban spatiotemporal forecasting, such as predicting infrastructure problems. In this setting, government officials wish to know in which neighborhoods incidents like potholes or rodent issues occur. The true state of incidents (e.g., street conditions) for each neighborhood is observed via government inspection ratings. However, these ratings are only conducted for a sparse set of neighborhoods and incident types. We also observe the state of incidents via crowdsourced reports, which are more densely observed but may be biased due to heterogeneous reporting behavior. First, for such settings, we propose a multiview, multioutput GNN-based model that uses both unbiased rating data and biased reporting data to predict the true latent state of incidents. Second, we investigate a case study of New York City urban incidents and collect, standardize, and make publicly available a dataset of 9,615,863 crowdsourced reports and 1,041,415 government inspection ratings over 3 years and across 139 types of incidents. Finally, we show on both real and semi-synthetic data that our model can better predict the latent state compared to models that use only reporting data or models that use only rating data, especially when rating data is sparse and reports are predictive of ratings. We also quantify demographic biases in crowdsourced reporting, e.g., higher-income neighborhoods report problems at higher rates. Our analysis showcases a widely applicable approach for latent state prediction using heterogeneous, sparse, and biased data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are widely used in urban spatiotemporalforecasting, such as predicting infrastructure problems. In this setting,government officials wish to know in which neighborhoods incidents likepotholes or rodent issues occur. The true state of incidents (e.g., streetconditions) for each neighborhood is observed via government inspectionratings. However, these ratings are only conducted for a sparse set ofneighborhoods and incident types. We also observe the state of incidents viacrowdsourced reports, which are more densely observed but may be biased due toheterogeneous reporting behavior. First, for such settings, we propose amultiview, multioutput GNN-based model that uses both unbiased rating data andbiased reporting data to predict the true latent state of incidents. Second, weinvestigate a case study of New York City urban incidents and collect,standardize, and make publicly available a dataset of 9,615,863 crowdsourcedreports and 1,041,415 government inspection ratings over 3 years and across 139types of incidents. Finally, we show on both real and semi-synthetic data thatour model can better predict the latent state compared to models that use onlyreporting data or models that use only rating data, especially when rating datais sparse and reports are predictive of ratings. We also quantify demographicbiases in crowdsourced reporting, e.g., higher-income neighborhoods reportproblems at higher rates. Our analysis showcases a widely applicable approachfor latent state prediction using heterogeneous, sparse, and biased data.</description>
      <author>example@mail.com (Sidhika Balachandar, Shuvom Sadhuka, Bonnie Berger, Emma Pierson, Nikhil Garg)</author>
      <guid isPermaLink="false">2506.08740v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Zero-Shot Framework for Deepfake Hate Speech Detection in Low-Resource Languages</title>
      <link>http://arxiv.org/abs/2506.08372v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in Interpseech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种用于检测深度伪造音频中仇恨言论的新型多模态框架，即使在零样本情况下也表现出色。&lt;h4&gt;背景&lt;/h4&gt;传统的仇恨言论检测方法在深度伪造音频中效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效检测深度伪造音频中仇恨言论的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法采用对比学习，联合对跨语言的音频和文本表示进行对齐。构建了包含127,290对文本和合成语音样本的基准数据集，涵盖英语和五种印度低资源语言（印地语、孟加拉语、马拉地语、泰米尔语、泰卢固语）。模型学习共享语义嵌入空间，实现鲁棒的跨语言和跨模态分类。&lt;h4&gt;主要发现&lt;/h4&gt;在两个多语言测试集上的实验表明，该方法优于基线，准确率达到0.819和0.701，并且能够很好地推广到未见过的语言。这证明了在低资源设置中，结合模态进行仇恨言论检测的优势，尤其是在单模态模型失效的情况下。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在合成媒体中检测仇恨言论方面具有优势，特别是在低资源环境中。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a novel multimodal framework for hate speech detection in deepfake audio, excelling even in zero-shot scenarios. Unlike previous approaches, our method uses contrastive learning to jointly align audio and text representations across languages. We present the first benchmark dataset with 127,290 paired text and synthesized speech samples in six languages: English and five low-resource Indian languages (Hindi, Bengali, Marathi, Tamil, Telugu). Our model learns a shared semantic embedding space, enabling robust cross-lingual and cross-modal classification. Experiments on two multilingual test sets show our approach outperforms baselines, achieving accuracies of 0.819 and 0.701, and generalizes well to unseen languages. This demonstrates the advantage of combining modalities for hate speech detection in synthetic media, especially in low-resource settings where unimodal models falter. The Dataset is available at https://www.iab-rubric.org/resources.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a novel multimodal framework for hate speech detectionin deepfake audio, excelling even in zero-shot scenarios. Unlike previousapproaches, our method uses contrastive learning to jointly align audio andtext representations across languages. We present the first benchmark datasetwith 127,290 paired text and synthesized speech samples in six languages:English and five low-resource Indian languages (Hindi, Bengali, Marathi, Tamil,Telugu). Our model learns a shared semantic embedding space, enabling robustcross-lingual and cross-modal classification. Experiments on two multilingualtest sets show our approach outperforms baselines, achieving accuracies of0.819 and 0.701, and generalizes well to unseen languages. This demonstratesthe advantage of combining modalities for hate speech detection in syntheticmedia, especially in low-resource settings where unimodal models falter. TheDataset is available at https://www.iab-rubric.org/resources.</description>
      <author>example@mail.com (Rishabh Ranjan, Likhith Ayinala, Mayank Vatsa, Richa Singh)</author>
      <guid isPermaLink="false">2506.08372v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>GIQ: Benchmarking 3D Geometric Reasoning of Vision Foundation Models with Simulated and Real Polyhedra</title>
      <link>http://arxiv.org/abs/2506.08194v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GIQ，一个专门用于评估视觉和视觉-语言基础模型几何推理能力的全面基准。&lt;h4&gt;背景&lt;/h4&gt;虽然单目3D重建方法和视觉-语言模型在标准基准上表现出色，但它们对几何特性的真正理解仍然不清楚。&lt;h4&gt;目的&lt;/h4&gt;GIQ旨在提供一个平台，以评估和解决当前模型在几何智能方面的关键差距。&lt;h4&gt;方法&lt;/h4&gt;GIQ包括合成和真实世界的224个不同多面体的图像，通过单目3D重建、3D对称性检测、心理旋转测试和零样本形状分类任务进行系统性实验。&lt;h4&gt;主要发现&lt;/h4&gt;实验揭示了当前模型在重建基本几何形状、检测3D对称性和心理旋转等任务中的显著不足。&lt;h4&gt;结论&lt;/h4&gt;GIQ公开可用，为突出和解决几何智能的关键差距提供了一个结构化的平台，有助于未来在鲁棒、几何感知的表示学习方面的进步。&lt;h4&gt;翻译&lt;/h4&gt;The abstract discusses the introduction of GIQ, a comprehensive benchmark designed to evaluate the geometric reasoning capabilities of vision and vision-language foundation models. The background states that although impressive results have been achieved on standard benchmarks, the true understanding of geometric properties remains unclear. The purpose of GIQ is to provide a platform for assessing and addressing critical gaps in geometric intelligence. The methods involve systematic experiments with synthetic and real-world images of diverse polyhedra, including various levels of complexity and symmetry, and tasks like monocular 3D reconstruction, 3D symmetry detection, mental rotation tests, and zero-shot shape classification. The main findings reveal significant shortcomings in current models, including struggles in reconstructing basic geometric forms and detecting 3D symmetries, as well as low accuracy in complex polyhedra. The conclusion is that GIQ is publicly available and aims to highlight and address critical gaps in geometric intelligence, facilitating future progress in robust, geometry-aware representation learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular 3D reconstruction methods and vision-language models (VLMs)demonstrate impressive results on standard benchmarks, yet their trueunderstanding of geometric properties remains unclear. We introduce GIQ , acomprehensive benchmark specifically designed to evaluate the geometricreasoning capabilities of vision and vision-language foundation models. GIQcomprises synthetic and real-world images of 224 diverse polyhedra - includingPlatonic, Archimedean, Johnson, and Catalan solids, as well as stellations andcompound shapes - covering varying levels of complexity and symmetry. Throughsystematic experiments involving monocular 3D reconstruction, 3D symmetrydetection, mental rotation tests, and zero-shot shape classification tasks, wereveal significant shortcomings in current models. State-of-the-artreconstruction algorithms trained on extensive 3D datasets struggle toreconstruct even basic geometric forms accurately. While foundation modelseffectively detect specific 3D symmetry elements via linear probing, theyfalter significantly in tasks requiring detailed geometric differentiation,such as mental rotation. Moreover, advanced vision-language assistants exhibitremarkably low accuracy on complex polyhedra, systematically misinterpretingbasic properties like face geometry, convexity, and compound structures. GIQ ispublicly available, providing a structured platform to highlight and addresscritical gaps in geometric intelligence, facilitating future progress inrobust, geometry-aware representation learning.</description>
      <author>example@mail.com (Mateusz Michalkiewicz, Anekha Sokhal, Tadeusz Michalkiewicz, Piotr Pawlikowski, Mahsa Baktashmotlagh, Varun Jampani, Guha Balakrishnan)</author>
      <guid isPermaLink="false">2506.08194v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>SSS: Semi-Supervised SAM-2 with Efficient Prompting for Medical Imaging Segmentation</title>
      <link>http://arxiv.org/abs/2506.08949v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SSS（Semi-Supervised SAM-2）的半监督学习方法，用于医学图像分割，通过利用SAM-2的特征提取能力来提高医学图像分割的性能。&lt;h4&gt;背景&lt;/h4&gt;在信息爆炸的时代，如何有效地利用大规模未标记数据，同时减少对高质量像素级标注的依赖，是医学图像领域的一个关键挑战。&lt;h4&gt;目的&lt;/h4&gt;通过半监督学习（SSL）增强未标记数据的使用，提高完全监督模型的性能，并成为医学图像分析中一个非常有前景的研究方向。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法基于单流“弱到强”一致性正则化框架，引入了判别特征增强（DFE）机制，以进一步探索由多种数据增强策略在多个视角中引入的特征差异。此外，开发了一个提示生成器，该生成器集成了物理约束与滑动窗口（PCSW）机制，为未标记数据生成输入提示。&lt;h4&gt;主要发现&lt;/h4&gt;在ACDC和BHSD两个多标签数据集上进行了广泛的实验，结果表明所提出的方法在半监督医学图像分割方面优于现有方法，SSS在BHSD上的平均Dice分数为53.15，比之前的最先进方法高出+3.65 Dice。&lt;h4&gt;结论&lt;/h4&gt;SSS方法在医学图像分割方面具有优越性，并有望在医学图像分析中得到广泛应用。&lt;h4&gt;翻译&lt;/h4&gt;在信息爆炸的时代，有效地利用大规模未标记数据的同时，减少对高质量像素级标注的依赖，在医学图像领域仍然是一个关键挑战。半监督学习（SSL）通过促进知识迁移，显著提高了完全监督模型的性能，并成为医学图像分析中的一个非常有前景的研究方向。受视觉基础模型（例如SAM-2）提供丰富先验知识能力的影响，本文提出了一种名为SSS（Semi-Supervised SAM-2）的新方法，该方法利用SAM-2的鲁棒特征提取能力来揭示未标记医学图像中的潜在知识，从而有效地增强完全监督医学图像分割的特征支持。具体而言，本文在单流“弱到强”一致性正则化框架的基础上，引入了一种判别特征增强（DFE）机制，以进一步探索由多种数据增强策略在多个视角中引入的特征差异。通过利用多尺度增强技术中的特征相似性和差异性，该方法重建并建模特征，从而有效地优化了显著区域。此外，开发了一个提示生成器，该生成器集成了物理约束与滑动窗口（PCSW）机制，为未标记数据生成输入提示，以满足SAM-2对额外提示的需求。广泛的实验表明，所提出的方法在两个多标签数据集（即ACDC和BHSD）上的半监督医学图像分割方面优于现有方法。值得注意的是，SSS在BHSD上的平均Dice分数为53.15，比之前的最先进方法高出+3.65 Dice。代码可在https://github.com/AIGeeksGroup/SSS上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of information explosion, efficiently leveraging large-scaleunlabeled data while minimizing the reliance on high-quality pixel-levelannotations remains a critical challenge in the field of medical imaging.Semi-supervised learning (SSL) enhances the utilization of unlabeled data byfacilitating knowledge transfer, significantly improving the performance offully supervised models and emerging as a highly promising research directionin medical image analysis. Inspired by the ability of Vision Foundation Models(e.g., SAM-2) to provide rich prior knowledge, we propose SSS (Semi-SupervisedSAM-2), a novel approach that leverages SAM-2's robust feature extractioncapabilities to uncover latent knowledge in unlabeled medical images, thuseffectively enhancing feature support for fully supervised medical imagesegmentation. Specifically, building upon the single-stream "weak-to-strong"consistency regularization framework, this paper introduces a DiscriminativeFeature Enhancement (DFE) mechanism to further explore the featurediscrepancies introduced by various data augmentation strategies acrossmultiple views. By leveraging feature similarity and dissimilarity acrossmulti-scale augmentation techniques, the method reconstructs and models thefeatures, thereby effectively optimizing the salient regions. Furthermore, aprompt generator is developed that integrates Physical Constraints with aSliding Window (PCSW) mechanism to generate input prompts for unlabeled data,fulfilling SAM-2's requirement for additional prompts. Extensive experimentsdemonstrate the superiority of the proposed method for semi-supervised medicalimage segmentation on two multi-label datasets, i.e., ACDC and BHSD. Notably,SSS achieves an average Dice score of 53.15 on BHSD, surpassing the previousstate-of-the-art method by +3.65 Dice. Code will be available athttps://github.com/AIGeeksGroup/SSS.</description>
      <author>example@mail.com (Hongjie Zhu, Xiwei Liu, Rundong Xue, Zeyu Zhang, Yong Xu, Daji Ergu, Ying Cai, Yang Zhao)</author>
      <guid isPermaLink="false">2506.08949v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>The connection between galaxy mergers, star formation and AGN activity in the HSC-SSP</title>
      <link>http://arxiv.org/abs/2506.08469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 12 figures, accepted to ApJ&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了星系合并引发的内部气体流入对星形成率、超大质量黑洞增长和活动星系核（AGN）的影响，通过新的方法对星系分类和属性进行测量。&lt;h4&gt;背景&lt;/h4&gt;内部气体流入被认为是通过星系合并增强星形成率、促进超大质量黑洞增长和刺激活动星系核。然而，由于合并分类和星系及AGN属性量化的困难，这些现象的量化仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;定量研究合并-星形成率-AGN之间的联系，并使用新的方法对星系进行分类和属性测量。&lt;h4&gt;方法&lt;/h4&gt;通过微调预训练的深度表示学习模型Zoobot，利用来自Galaxy Cruise项目的图像和标签在HSC-SSP观测图像中识别合并。使用ProSpect代码拟合GAMA光谱来获取星系和AGN属性，该代码在远紫外到远红外波段的泛色光范围内进行拟合。&lt;h4&gt;主要发现&lt;/h4&gt;在合并和对照组之间，星形成率（SFR）和AGN活动的差异很小。经过进一步可视化纯化合并样本后，发现对星系和后合并星系的影响更大，这些发现表明，长期过程是星形成和AGN活动的重要驱动因素。&lt;h4&gt;结论&lt;/h4&gt;本文的结果对使用长期时间尺度探针提出了一个警示。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由星系合并驱动的内部气体流入被认为可以增强星形成率（SFR），促进超大质量黑洞的增长并刺激活动星系核（AGN）。然而，由于在分类合并和量化星系和AGN属性方面存在困难，这些现象的量化仍然是一个挑战。我们使用Hyper Suprime-Cam Subaru战略计划（HSC-SSP）的星系，通过新的方法对星系分类和属性进行测量，定量检验合并-SFR-AGN联系。在HSC-SSP观测图像中，通过微调预训练的深度表示学习模型Zoobot，利用基于Galaxy Cruise项目的图像和标签识别合并。我们使用ProSpect代码拟合GAMA光谱生成的星系和AGN属性，该代码在泛色光范围内从远紫外到远红外波段进行拟合。在合并和对照组之间，SFR和AGN活动的差异很小，经过进一步可视化纯化合并样本后，发现对星系和后合并星系的影响更大。这些发现表明，长期过程是星形成和AGN活动的重要驱动因素，对使用长期时间尺度探针提出了一个警示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Internal gas inflows driven by galaxy mergers are considered to enhance starformation rates (SFR), fuel supermassive black hole growth and stimulate activegalactic nuclei (AGN). However, quantifying these phenomena remains achallenge, due to difficulties both in classifying mergers and in quantifyinggalaxy and AGN properties. We quantitatively examine the merger-SFR-AGNconnection using Hyper Suprime-Cam Subaru Strategic Program (HSC-SSP) galaxiesusing novel methods for both galaxy classification and property measurements.}{Mergers in HSC-SSP observational images are identified through fine-tuningZoobot, a pretrained deep representation learning model, using images andlabels based on the Galaxy Cruise project. We use galaxy and AGN propertiesthat were produced by fitting Galaxy and Mass Assembly (GAMA) spectra using theSED fitting code ProSpect, which fits panchromatically across the far-UVthrough far-infrared wavelengths and obtains galaxy and AGN propertiessimultaneously.} \textbf{{Little differences are seen in SFR and AGN activitybetween mergers and controls, with $\Delta \mathrm{SFR}=-0.009\pm 0.003$ dex,$\Delta f_{\mathrm{AGN}}=-0.010\pm0.033$ dex and $\DeltaL_{\mathrm{AGN}}=0.002\pm0.025$ dex. After further visual purification of themerger sample, we find $\Delta \mathrm{SFR}=-0.033\pm0.014$ dex, $\Deltaf_{\mathrm{AGN}}=-0.024\pm0.170$ dex, and $\DeltaL_{\mathrm{AGN}}=0.019\pm0.129$ dex for pairs, and $\Delta\mathrm{SFR}=-0.057\pm0.024$ dex, $\Delta f_{\mathrm{AGN}}=0.286\pm0.270$ dex,and $\Delta L_{\mathrm{AGN}}=0.329\pm0.195$ dex for postmergers. These numberssuggest secular processes being an important driver for SF and AGN activity,and present a cautionary tale when using longer timescale tracers.</description>
      <author>example@mail.com (Kiyoaki Christopher Omori, Connor Bottrell, Sabine Bellstedt, Aaron Robotham, Hassen M. Yesuf, Andy D. Goulding, Marcin Sawicki, Tohru Nagao, Tsutomu T. Takeuchi)</author>
      <guid isPermaLink="false">2506.08469v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Large Deviations for Markovian Graphon Processes and Associated Dynamical Systems on Networks</title>
      <link>http://arxiv.org/abs/2506.08333v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  55 pages, no figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究快速变化的马尔可夫网络的时态模型，这些模型由随时间演化的空间相关核调制，这些核定义了边形成和消解的速率。在考虑的区域内，图论值过程的窗口平均值在适当的时间间隔内是系统的自然状态描述符。在适当的跳率核条件下，我们为平均过适当时间窗口的图论过程建立了大数定律和大型偏差原理（LDP），既在弱拓扑下，也在相关图论空间中的割范数下。尽管问题设置和分析比已研究的静态随机网络模型更为复杂，但与速率函数相关的变分问题具有显式解，从而为速率函数提供了一种同样易于处理的、不同的表达式，类似于静态情况。利用这些结果，我们进一步为受底层演化的网络驱动的节点值动态系统建立了LDP。&lt;h4&gt;背景&lt;/h4&gt;本文研究的是快速变化的马尔可夫网络的时态模型，以及由时间演化的空间相关核调制形成的模型。&lt;h4&gt;目的&lt;/h4&gt;本文旨在建立快速变化马尔可夫网络时态模型的大数定律和大型偏差原理。&lt;h4&gt;方法&lt;/h4&gt;本文采用了一种基于窗口平均值的方法来描述系统的状态，并利用适当的条件建立了大数定律和大型偏差原理。&lt;h4&gt;主要发现&lt;/h4&gt;本文在适当条件下为图论过程建立了大数定律和大型偏差原理，并发现与速率函数相关的变分问题具有显式解。&lt;h4&gt;结论&lt;/h4&gt;本文为受底层演化的网络驱动的节点值动态系统建立了大型偏差原理。&lt;h4&gt;翻译&lt;/h4&gt;我们考虑由随时间演化的空间相关核调节的快速变化马尔可夫网络的时态模型，这些核定义了边形成和消解的速率。或者，这些也可以看作是在长时间范围内具有 $O(1)$ 跳转速率的马尔可夫网络。在考虑的区域内，图论值过程在适当时间间隔内的窗口平均值是系统的自然状态描述符。在跳转率核的适当条件下，我们为平均过适当时间窗口的图论过程建立了大数定律和大型偏差原理（LDP），既在弱拓扑下，也在相关图论空间中的割范数下。尽管问题设置和分析比已研究的静态随机网络模型更为复杂，但与速率函数相关的变分问题具有显式解，从而为速率函数提供了一种同样易于处理的、不同的表达式，类似于静态情况。利用这些结果，我们然后为受底层演化的网络驱动的节点值动态系统建立了LDP。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider temporal models of rapidly changing Markovian networks modulatedby time-evolving spatially dependent kernels that define rates for edgeformation and dissolution. Alternatively, these can be viewed as Markoviannetworks with $O(1)$ jump rates viewed over a long time horizon. In the regimeswe consider, the window averages of graphon valued processes over suitable timeintervals are natural state descriptors for the system. Under appropriateconditions on the jump-rate kernels, we establish laws of large numbers andlarge deviation principles(LDP) for the graphon processes averaged over asuitable time window, both in the weak topology and with respect to the cutnorm in the associated graphon space. Although the problem setting and analysisare more involved than for the well-studied static random network model, thevariational problem associated with the rate function admits an explicitsolution, yielding an equally tractable, though different, expression for therate function, similar to the static case. Using these results, we thenestablish the LDP for node-valent dynamical systems driven by the underlyingevolving network.</description>
      <author>example@mail.com (Shankar Bhamidi, Amarjit Budhiraja, Souvik Ray)</author>
      <guid isPermaLink="false">2506.08333v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>BioLangFusion: Multimodal Fusion of DNA, mRNA, and Protein Language Models</title>
      <link>http://arxiv.org/abs/2506.08936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of ICML 2025 Workshop on Multi-modal Foundation  Proceedings of ICML 2025 Workshop on Multi-modal Foundation Proceedings of  ICML 2025 Workshop on Multi-modal Foundation Models and Large Language Models  for Life Sciences&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BioLangFusion的简单方法，用于将预训练的DNA、mRNA和蛋白质语言模型集成到统一的分子表示中。&lt;h4&gt;背景&lt;/h4&gt;该方法受到分子生物学中心法则（从基因到转录再到蛋白质的信息流动）的启发。&lt;h4&gt;目的&lt;/h4&gt;目的是通过在生物学上有意义的密码子级别（编码一个氨基酸的三个核苷酸）对齐每个模态的嵌入，确保直接的跨模态对应关系。&lt;h4&gt;方法&lt;/h4&gt;BioLangFusion研究了三种标准的融合技术：(i) 密码子级别的嵌入连接，(ii) 受多实例学习启发的熵正则化注意力池化，以及(iii) 跨模态多头注意力。每种技术都为结合模态特定的信号提供了不同的归纳偏差。这些方法不需要额外的预训练或修改基础模型，可以方便地与现有的基于序列的基础模型集成。&lt;h4&gt;主要发现&lt;/h4&gt;在五个分子属性预测任务中，BioLangFusion优于强大的单模态基线，表明即使是简单的预训练模型融合也能以最小的开销捕获互补的多组学信息。&lt;h4&gt;结论&lt;/h4&gt;BioLangFusion展示了预训练模型融合的潜力，即使在简单的情况下也能有效地整合多模态信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present BioLangFusion, a simple approach for integrating pre-trained DNA,mRNA, and protein language models into unified molecular representations.Motivated by the central dogma of molecular biology (information flow from geneto transcript to protein), we align per-modality embeddings at the biologicallymeaningful codon level (three nucleotides encoding one amino acid) to ensuredirect cross-modal correspondence. BioLangFusion studies three standard fusiontechniques: (i) codon-level embedding concatenation, (ii) entropy-regularizedattention pooling inspired by multiple-instance learning, and (iii) cross-modalmulti-head attention -- each technique providing a different inductive bias forcombining modality-specific signals. These methods require no additionalpre-training or modification of the base models, allowing straightforwardintegration with existing sequence-based foundation models. Across fivemolecular property prediction tasks, BioLangFusion outperforms strong unimodalbaselines, showing that even simple fusion of pre-trained models can capturecomplementary multi-omic information with minimal overhead.</description>
      <author>example@mail.com (Amina Mollaysa, Artem Moskale, Pushpak Pati, Tommaso Mansi, Mangal Prakash, Rui Liao)</author>
      <guid isPermaLink="false">2506.08936v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>HSG-12M: A Large-Scale Spatial Multigraph Dataset</title>
      <link>http://arxiv.org/abs/2506.08618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  39 pages, 13 figures, 3 tables. Code &amp; pipeline:  [https://github.com/sarinstein-yan/Poly2Graph] Dataset:  [https://github.com/sarinstein-yan/HSG-12M] Dataset released under CC BY 4.0&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了HSG-12M，这是第一个大规模的基于空间多图的数据库，其中包含了在度量空间中嵌入的图，保留了两个节点之间多个几何上不同的轨迹作为单独的边。HSG-12M包含来自1.77TB光谱势数据的11.6百万静态和5.1百万动态哈密顿谱图，涵盖了1401种特征多项式类别。每个图编码了1D晶体能量谱在复平面上的完整几何，产生了超越传统节点坐标数据集的多样化、基于物理学的拓扑结构。&lt;h4&gt;背景&lt;/h4&gt;现有的图基准假设非空间、简单边，将物理上不同的路径合并为单个链接。&lt;h4&gt;目的&lt;/h4&gt;提出HSG-12M，以解决现有图基准的局限性，并促进几何感知图学习和数据驱动科学发现。&lt;h4&gt;方法&lt;/h4&gt;构建了HSG-12M数据集，并开发了Poly2Graph，这是一个高性能的开源管道，将任意的1D晶体哈密顿量映射到谱图。&lt;h4&gt;主要发现&lt;/h4&gt;HSG-12M展示了多边几何在规模学习中的新挑战，并揭示了谱图作为多项式、向量和矩阵的通用拓扑指纹，建立了代数到图的联系。&lt;h4&gt;结论&lt;/h4&gt;HSG-12M为几何感知图学习奠定了基础，并为凝聚态物理学及其他领域的科学发现提供了新的数据驱动机会。&lt;h4&gt;翻译&lt;/h4&gt;Existing graph benchmarks assume non-spatial, simple edges, collapsing physically distinct paths into a single link. We introduce HSG-12M, the first large-scale dataset of spatial multigraphs—graphs embedded in a metric space where multiple geometrically distinct trajectories between two nodes are retained as separate edges. HSG-12M contains 11.6 million static and 5.1 million dynamic Hamiltonian spectral graphs across 1401 characteristic-polynomial classes, derived from 177 TB of spectral potential data. Each graph encodes the full geometry of a 1-D crystal's energy spectrum on the complex plane, producing diverse, physics-grounded topologies that transcend conventional node-coordinate datasets. To enable future extensions, we release Poly2Graph: a high-performance, open-source pipeline that maps arbitrary 1-D crystal Hamiltonians to spectral graphs. Benchmarks with popular GNNs expose new challenges in learning from multi-edge geometry at scale. Beyond its practical utility, we show that spectral graphs serve as universal topological fingerprints of polynomials, vectors, and matrices, forging a new algebra-to-graph link. HSG-12M lays the groundwork for geometry-aware graph learning and new opportunities of data-driven scientific discovery in condensed matter physics and beyond.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing graph benchmarks assume non-spatial, simple edges, collapsingphysically distinct paths into a single link. We introduce HSG-12M, the firstlarge-scale dataset of $\textbf{spatial multigraphs}-$graphs embedded in ametric space where multiple geometrically distinct trajectories between twonodes are retained as separate edges. HSG-12M contains 11.6 million static and5.1 million dynamic $\textit{Hamiltonian spectral graphs}$ across 1401characteristic-polynomial classes, derived from 177 TB of spectral potentialdata. Each graph encodes the full geometry of a 1-D crystal's energy spectrumon the complex plane, producing diverse, physics-grounded topologies thattranscend conventional node-coordinate datasets. To enable future extensions,we release $\texttt{Poly2Graph}$: a high-performance, open-source pipeline thatmaps arbitrary 1-D crystal Hamiltonians to spectral graphs. Benchmarks withpopular GNNs expose new challenges in learning from multi-edge geometry atscale. Beyond its practical utility, we show that spectral graphs serve asuniversal topological fingerprints of polynomials, vectors, and matrices,forging a new algebra-to-graph link. HSG-12M lays the groundwork forgeometry-aware graph learning and new opportunities of data-driven scientificdiscovery in condensed matter physics and beyond.</description>
      <author>example@mail.com (Xianquan Yan, Hakan Akgün, Kenji Kawaguchi, N. Duane Loh, Ching Hua Lee)</author>
      <guid isPermaLink="false">2506.08618v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Intention-Conditioned Flow Occupancy Models</title>
      <link>http://arxiv.org/abs/2506.08902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于流匹配的概率模型，用于预测智能体在长期未来可能访问的状态（即占用度量）。该模型通过包含一个捕获用户意图的潜在变量来增加模型的表达性，并允许通过广义策略改进进行自适应调整。&lt;h4&gt;背景&lt;/h4&gt;大规模预训练在机器学习研究中扮演着重要角色，通过预训练大型基础模型，任何人都可以使用这些模型来适应和微调特定任务。这种方法在强化学习（RL）中也非常有吸引力，因为它提供了解决RL核心挑战（如样本效率和鲁棒性）的有力途径。&lt;h4&gt;目的&lt;/h4&gt;旨在解决RL中预训练大型模型的基本挑战，即动作具有长期依赖性，因此需要训练能够跨时间推理的基础模型。&lt;h4&gt;方法&lt;/h4&gt;使用流匹配构建概率模型来预测智能体在长期未来可能访问的状态，并包含一个捕获用户意图的潜在变量。&lt;h4&gt;主要发现&lt;/h4&gt;在36个基于状态和4个基于图像的基准任务上的实验表明，所提出的方法在回报上实现了1.8倍的中位数改进，成功率提高了36%。&lt;h4&gt;结论&lt;/h4&gt;提出的意图条件流动占用模型（InFOM）在样本效率和鲁棒性方面优于其他预训练方法，能够有效提高强化学习任务的表现。&lt;h4&gt;翻译&lt;/h4&gt;Large-scale pre-training has fundamentally changed how machine learning research is done today: large foundation models are trained once, and then can be used by anyone in the community (including those without data or computeresources to train a model from scratch) to adapt and fine-tune to specific tasks. Applying this same framework to reinforcement learning (RL) is appealing because it offers compelling avenues for addressing core challenges in RL, including sample efficiency and robustness. However, there remains a fundamental challenge to pre-train large models in the context of RL: actions have long-term dependencies, so training a foundation model that reasons across time is important. Recent advances in generative AI have provided new tools for modeling highly complex distributions. In this paper, we build a probabilistic model to predict which states an agent will visit in the temporally distant future (i.e., an occupancy measure) using flow matching. As large datasets are often constructed by many distinct users performing distinct tasks, we include in our model a latent variable capturing the user intention. This intention increases the expressivity of our model, and enables adaptation with generalized policy improvement. We call our proposed method intention-conditioned flow occupancy models (InFOM). Comparing with alternative methods for pre-training, our experiments on 36 state-based and 4 image-based benchmark tasks demonstrate that the proposed method achieves 1.8 times median improvement in returns and increases success rates by 36%. Website: https://chongyi-zheng.github.io/infom Code: https://github.com/chongyi-zheng/infom&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale pre-training has fundamentally changed how machine learningresearch is done today: large foundation models are trained once, and then canbe used by anyone in the community (including those without data or computeresources to train a model from scratch) to adapt and fine-tune to specifictasks. Applying this same framework to reinforcement learning (RL) is appealingbecause it offers compelling avenues for addressing core challenges in RL,including sample efficiency and robustness. However, there remains afundamental challenge to pre-train large models in the context of RL: actionshave long-term dependencies, so training a foundation model that reasons acrosstime is important. Recent advances in generative AI have provided new tools formodeling highly complex distributions. In this paper, we build a probabilisticmodel to predict which states an agent will visit in the temporally distantfuture (i.e., an occupancy measure) using flow matching. As large datasets areoften constructed by many distinct users performing distinct tasks, we includein our model a latent variable capturing the user intention. This intentionincreases the expressivity of our model, and enables adaptation withgeneralized policy improvement. We call our proposed methodintention-conditioned flow occupancy models (InFOM). Comparing with alternativemethods for pre-training, our experiments on $36$ state-based and $4$image-based benchmark tasks demonstrate that the proposed method achieves $1.8\times$ median improvement in returns and increases success rates by $36\%$.Website: https://chongyi-zheng.github.io/infom Code:https://github.com/chongyi-zheng/infom</description>
      <author>example@mail.com (Chongyi Zheng, Seohong Park, Sergey Levine, Benjamin Eysenbach)</author>
      <guid isPermaLink="false">2506.08902v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>MIRAGE: Multimodal foundation model and benchmark for comprehensive retinal OCT image analysis</title>
      <link>http://arxiv.org/abs/2506.08900v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MIRAGE的多模态基础模型，用于分析OCT和SLO图像，并提出了一种新的评估基准，旨在解决现有AI模型在眼科图像分析中的挑战。&lt;h4&gt;背景&lt;/h4&gt;人工智能在分析眼科图像，如OCT图像中起到了重要作用，但开发AI模型通常需要大量标注，且现有模型在独立未见过的数据上表现不佳。现有的基础模型在眼科领域缺乏广泛的验证，且集中于单一成像方式。&lt;h4&gt;目的&lt;/h4&gt;提出MIRAGE模型，并建立一个新的评估基准，以解决上述挑战，并提高眼科图像分析的AI系统的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;开发了一个新的多模态基础模型MIRAGE，并提出了包含OCT/SLO分类和分割任务的新评估基准。&lt;h4&gt;主要发现&lt;/h4&gt;MIRAGE在OCT/SLO分类和分割任务中均优于一般和专业的FMs及分割方法，表明其适用于开发鲁棒的AI系统。&lt;h4&gt;结论&lt;/h4&gt;MIRAGE模型和评估基准已公开发布，有助于推动眼科图像分析的AI系统发展。&lt;h4&gt;翻译&lt;/h4&gt;Artificial intelligence (AI) has become a fundamental tool for assisting clinicians in analyzing ophthalmic images, such as optical coherence tomography (OCT). However, developing AI models often requires extensive annotation, and existing models tend to underperform on independent, unseen data. Foundation models (FMs), large AI models trained on vast unlabeled datasets, have shown promise in overcoming these challenges. Nonetheless, available FMs for ophthalmology lack extensive validation, especially for segmentation tasks, and focus on a single imaging modality. In this context, we propose MIRAGE, a novel multimodal FM for the analysis of OCT and scanning laser ophthalmoscopy (SLO) images. Additionally, we propose a new evaluation benchmark with OCT/SLO classification and segmentation tasks. The comparison with general and specialized FMs and segmentation methods shows the superiority of MIRAGE in both types of tasks, highlighting its suitability as a basis for the development of robust AI systems for retinal OCT image analysis. Both MIRAGE and the evaluation benchmark are publicly available: https://github.com/j-morano/MIRAGE.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence (AI) has become a fundamental tool for assistingclinicians in analyzing ophthalmic images, such as optical coherence tomography(OCT). However, developing AI models often requires extensive annotation, andexisting models tend to underperform on independent, unseen data. Foundationmodels (FMs), large AI models trained on vast unlabeled datasets, have shownpromise in overcoming these challenges. Nonetheless, available FMs forophthalmology lack extensive validation, especially for segmentation tasks, andfocus on a single imaging modality. In this context, we propose MIRAGE, a novelmultimodal FM for the analysis of OCT and scanning laser ophthalmoscopy (SLO)images. Additionally, we propose a new evaluation benchmark with OCT/SLOclassification and segmentation tasks. The comparison with general andspecialized FMs and segmentation methods shows the superiority of MIRAGE inboth types of tasks, highlighting its suitability as a basis for thedevelopment of robust AI systems for retinal OCT image analysis. Both MIRAGEand the evaluation benchmark are publicly available:https://github.com/j-morano/MIRAGE.</description>
      <author>example@mail.com (José Morano, Botond Fazekas, Emese Sükei, Ronald Fecso, Taha Emre, Markus Gumpinger, Georg Faustmann, Marzieh Oghbaie, Ursula Schmidt-Erfurth, Hrvoje Bogunović)</author>
      <guid isPermaLink="false">2506.08900v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Adapting Vision-Language Foundation Model for Next Generation Medical Ultrasound Image Analysis</title>
      <link>http://arxiv.org/abs/2506.08849v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种针对医学超声图像分析的视觉-语言基础模型领域自适应方法，通过调整和优化模型，提高了其在分割和分类任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;医学超声成像是一种重要的影像技术，用于检查浅表器官和组织，如淋巴结、乳腺和甲状腺。手动在图像中标记感兴趣区域是耗时且需要专业知识的工作，容易导致不同的解释。&lt;h4&gt;目的&lt;/h4&gt;旨在克服视觉-语言基础模型在自然和医学成像领域之间的性能差异，提高超声图像分析的准确性。&lt;h4&gt;方法&lt;/h4&gt;研究探索了视觉-语言基础模型的微调流程，使用大型语言模型作为文本细化器，结合特殊设计的自适应策略和任务驱动的头部。&lt;h4&gt;主要发现&lt;/h4&gt;方法在六个超声数据集和两个任务（分割和分类）上进行了广泛评估，实验结果表明该方法能够有效提升视觉-语言基础模型在超声图像分析中的性能，并优于现有的视觉-语言和纯基础模型。&lt;h4&gt;结论&lt;/h4&gt;该方法在超声图像分析中提高了视觉-语言基础模型的表现，具有实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical ultrasonography is an essential imaging technique for examiningsuperficial organs and tissues, including lymph nodes, breast, and thyroid. Itemploys high-frequency ultrasound waves to generate detailed images of theinternal structures of the human body. However, manually contouring regions ofinterest in these images is a labor-intensive task that demands expertise andoften results in inconsistent interpretations among individuals.Vision-language foundation models, which have excelled in various computervision applications, present new opportunities for enhancing ultrasound imageanalysis. Yet, their performance is hindered by the significant differencesbetween natural and medical imaging domains. This research seeks to overcomethese challenges by developing domain adaptation methods for vision-languagefoundation models. In this study, we explore the fine-tuning pipeline forvision-language foundation models by utilizing large language model as textrefiner with special-designed adaptation strategies and task-driven heads. Ourapproach has been extensively evaluated on six ultrasound datasets and twotasks: segmentation and classification. The experimental results show that ourmethod can effectively improve the performance of vision-language foundationmodels for ultrasound image analysis, and outperform the existingstate-of-the-art vision-language and pure foundation models. The source code ofthis study is available at\href{https://github.com/jinggqu/NextGen-UIA}{GitHub}.</description>
      <author>example@mail.com (Jingguo Qu, Xinyang Han, Tonghuan Xiao, Jia Ai, Juan Wu, Tong Zhao, Jing Qin, Ann Dorothy King, Winnie Chiu-Wing Chu, Jing Cai, Michael Tin-Cheung Yingınst)</author>
      <guid isPermaLink="false">2506.08849v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>MOBODY: Model Based Off-Dynamics Offline Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.08460v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了离线强化学习中的离动态问题，提出了一种名为MOBODY的基于模型的离动态离线强化学习算法，该算法通过学习动态来探索目标域，并通过模型扩展来增强数据，从而提高了在目标域中学习策略的能力。&lt;h4&gt;背景&lt;/h4&gt;离动态离线强化学习问题中，目标是从包含不同转换域的离线数据集中学习策略。现有的离动态离线强化学习方法通常受到目标域有限转换的限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够探索目标域并学习策略的离动态离线强化学习算法。&lt;h4&gt;方法&lt;/h4&gt;MOBODY算法通过模型扩展生成新的合成转换，并将其用作离线策略学习中的数据增强。该算法利用源数据和目标数据集来处理不匹配的动态，并通过表示学习发现跨域的状态和转换的共享潜在表示，以学习目标动态。此外，MOBODY还引入了一种Q加权的模仿行为损失来正则化策略。&lt;h4&gt;主要发现&lt;/h4&gt;MOBODY在MuJoCo基准测试中表现优于现有方法，特别是在具有挑战性的场景中表现出显著改进。&lt;h4&gt;结论&lt;/h4&gt;MOBODY算法通过增强数据集和学习动态，显著提高了离动态离线强化学习在目标域中的策略学习性能。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了离动态离线强化学习问题，其目标是学习一个策略，该策略来自从源域和目标域收集的离线数据集，这些数据集具有不匹配的转换。现有的离动态离线强化学习方法通常要么过滤与目标域相似的源转换，要么对源数据进行奖励增强，这两种方法都受到来自目标域的有限转换的限制。因此，学习到的策略无法探索目标域之外的离线数据集。我们提出了MOBODY，这是一种基于模型的离动态离线强化学习算法，通过通过学习动态来启用对目标域的探索来解决这个问题。MOBODY通过模型扩展在目标域中生成新的合成转换，这些转换在离线策略学习期间用作数据增强。与从单个域学习动态的现有基于模型的方法不同，MOBODY通过利用源数据和目标数据集来解决不匹配的动态的挑战。直接合并这些数据集可能会使学习到的模型偏向源动态。相反，MOBODY通过通过表示学习发现跨域的状态和转换的共享潜在表示来学习目标动态。为了稳定训练，MOBODY结合了行为克隆损失来正则化策略。具体来说，我们引入了一种Q加权的模仿行为克隆损失，该损失将策略正则化到具有高目标域Q值的行为，而不是均匀地模仿数据集中的所有行为。这些Q值是从由离线目标数据、增强源数据和从学习到的目标动态的滚动数据组成的增强目标数据集中学习的。我们在MuJoCo基准测试中评估了MOBODY，并表明它显著优于最先进的基线，特别是在具有挑战性的场景中表现出特别显著的改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the off-dynamics offline reinforcement learning problem, where thegoal is to learn a policy from offline datasets collected from source andtarget domains with mismatched transition. Existing off-dynamics offline RLmethods typically either filter source transitions that resemble those of thetarget domain or apply reward augmentation to source data, both constrained bythe limited transitions available from the target domain. As a result, thelearned policy is unable to explore target domain beyond the offline datasets.We propose MOBODY, a Model-Based Off-Dynamics offline RL algorithm thataddresses this limitation by enabling exploration of the target domain vialearned dynamics. MOBODY generates new synthetic transitions in the targetdomain through model rollouts, which are used as data augmentation duringoffline policy learning. Unlike existing model-based methods that learndynamics from a single domain, MOBODY tackles the challenge of mismatcheddynamics by leveraging both source and target datasets. Directly merging thesedatasets can bias the learned model toward source dynamics. Instead, MOBODYlearns target dynamics by discovering a shared latent representation of statesand transitions across domains through representation learning. To stabilizetraining, MOBODY incorporates a behavior cloning loss that regularizes thepolicy. Specifically, we introduce a Q-weighted behavior cloning loss thatregularizes the policy toward actions with high target-domain Q-values, ratherthan uniformly imitating all actions in the dataset. These Q-values are learnedfrom an enhanced target dataset composed of offline target data, augmentedsource data, and rollout data from the learned target dynamics. We evaluateMOBODY on MuJoCo benchmarks and show that it significantly outperformsstate-of-the-art baselines, with especially pronounced improvements inchallenging scenarios.</description>
      <author>example@mail.com (Yihong Guo, Yu Yang, Pan Xu, Anqi Liu)</author>
      <guid isPermaLink="false">2506.08460v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Landsat-Bench: Datasets and Benchmarks for Landsat Foundation Models</title>
      <link>http://arxiv.org/abs/2506.08780v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Landsat-Bench，一套基于Landsat影像的基准测试集，用于促进基于Landsat的地理空间基础模型（GFM）的发展。&lt;h4&gt;背景&lt;/h4&gt;Landsat项目提供了超过50年的全球一致地球影像，但由于缺乏该数据的基准测试，限制了基于Landsat的地理空间基础模型（GFM）的发展。&lt;h4&gt;目的&lt;/h4&gt;通过引入Landsat-Bench，旨在建立基准和标准化的评估方法，以促进基于Landsat的地理空间基础模型（GFM）的发展。&lt;h4&gt;方法&lt;/h4&gt;Landsat-Bench包括三个基准测试集：EuroSAT-L、BigEarthNet-L和LC100-L，这些测试集来自现有的遥感数据集。研究人员在SSL4EO-L数据集上预训练了Landsat基础模型，并使用这些模型进行基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;SSL4EO-L预训练的GFM在下游任务中提取了更好的表示，与ImageNet相比，在EuroSAT-L和BigEarthNet-L上的性能分别提高了+4% OA和+5.1% mAP。&lt;h4&gt;结论&lt;/h4&gt;SSL4EO-L预训练的GFM在基于Landsat的地理空间基础模型（GFM）中具有更高的性能，为后续任务提供了更好的基础。&lt;h4&gt;翻译&lt;/h4&gt;The Landsat program provides over 50 years of globally consistent Earth imagery. However, the lack of benchmarks for this data constrains progress towards Landsat-based Geospatial Foundation Models (GFM). In this paper, we introduce Landsat-Bench, a suite of three benchmarks with Landsat imagery that adapt from existing remote sensing datasets -- EuroSAT-L, BigEarthNet-L, and LC100-L. We establish baseline and standardized evaluation methods across both common architectures and Landsat foundation models pretrained on the SSL4EO-L dataset. Notably, we provide evidence that SSL4EO-L pretrained GFMs extract better representations for downstream tasks in comparison to ImageNet, including performance gains of +4% OA and +5.1% mAP on EuroSAT-L and BigEarthNet-L.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Landsat program offers over 50 years of globally consistent Earthimagery. However, the lack of benchmarks for this data constrains progresstowards Landsat-based Geospatial Foundation Models (GFM). In this paper, weintroduce Landsat-Bench, a suite of three benchmarks with Landsat imagery thatadapt from existing remote sensing datasets -- EuroSAT-L, BigEarthNet-L, andLC100-L. We establish baseline and standardized evaluation methods across bothcommon architectures and Landsat foundation models pretrained on the SSL4EO-Ldataset. Notably, we provide evidence that SSL4EO-L pretrained GFMs extractbetter representations for downstream tasks in comparison to ImageNet,including performance gains of +4% OA and +5.1% mAP on EuroSAT-L andBigEarthNet-L.</description>
      <author>example@mail.com (Isaac Corley, Lakshay Sharma, Ruth Crasto)</author>
      <guid isPermaLink="false">2506.08780v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>FUSE: Measure-Theoretic Compact Fuzzy Set Representation for Taxonomy Expansion</title>
      <link>http://arxiv.org/abs/2506.08409v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于模糊集的集合表示学习方法，用于复杂概念及其关系的建模。&lt;h4&gt;背景&lt;/h4&gt;传统的集合表示学习方法通常将集合建模为向量或几何对象，如箱子，这些方法在集合运算下不是封闭的。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的集合表示学习方法，以模糊集的形式对集合进行体积近似，从而在保持信息的同时提高学习效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Fuzzy Set Embedding (FUSE)的嵌入框架，它基于模糊集的体积近似，满足所有集合运算，并紧凑地近似底层模糊集。&lt;h4&gt;主要发现&lt;/h4&gt;FUSE在分类扩展任务上展示了强大的性能，与现有基线相比，实现了高达23%的改进。&lt;h4&gt;结论&lt;/h4&gt;本文首次尝试理解和高效计算模糊集的嵌入，为概念建模提供了一种新的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：分类扩展，它模拟复杂概念及其关系，可以表述为一种集合表示学习任务。集合的泛化，包括模糊集，包含了不确定性并测量语义概念中的信息，使其适合于概念建模。现有工作通常将集合建模为向量或诸如箱子之类的几何对象，这些方法在集合运算下不是封闭的。在本工作中，我们提出了一种基于集合体积近似为模糊集的集合表示学习的合理和有效公式。由此产生的嵌入框架，模糊集嵌入（FUSE），满足所有集合运算，并紧凑地近似底层模糊集，因此在保持信息的同时，学习效率高，依赖于最小的神经网络架构。我们通过在分类扩展任务上对FUSE的实证演示其力量，其中FUSE与现有基线相比实现了显著的改进，高达23%。我们的工作首次尝试理解和高效计算模糊集的嵌入。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Taxonomy Expansion, which models complex concepts and their relations, can beformulated as a set representation learning task. The generalization of set,fuzzy set, incorporates uncertainty and measures the information within asemantic concept, making it suitable for concept modeling. Existing worksusually model sets as vectors or geometric objects such as boxes, which are notclosed under set operations. In this work, we propose a sound and efficientformulation of set representation learning based on its volume approximation asa fuzzy set. The resulting embedding framework, Fuzzy Set Embedding (FUSE),satisfies all set operations and compactly approximates the underlying fuzzyset, hence preserving information while being efficient to learn, relying onminimum neural architecture. We empirically demonstrate the power of FUSE onthe task of taxonomy expansion, where FUSE achieves remarkable improvements upto 23% compared with existing baselines. Our work marks the first attempt tounderstand and efficiently compute the embeddings of fuzzy sets.</description>
      <author>example@mail.com (Fred Xu, Song Jiang, Zijie Huang, Xiao Luo, Shichang Zhang, Adrian Chen, Yizhou Sun)</author>
      <guid isPermaLink="false">2506.08409v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>WGLE:Backdoor-free and Multi-bit Black-box Watermarking for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.08602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的GNN黑盒水印方法WGLE，用于防止模型盗窃，并实现知识产权保护。&lt;h4&gt;背景&lt;/h4&gt;随着图神经网络（GNNs）在图相关应用中的广泛应用，模型的所有权验证变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的黑盒水印方法，以保护GNN的知识产权，同时避免现有方法的缺点。&lt;h4&gt;方法&lt;/h4&gt;WGLE方法基于层间距离差异（LDDE），通过预定义多个边上的LDDE值，将多比特字符串嵌入到模型中，而不引入错误映射。&lt;h4&gt;主要发现&lt;/h4&gt;WGLE在六个公共数据集和六个主流GNN架构上进行了评估，实现了100%的所有权验证准确率，平均保真度下降为0.85%，具有较好的鲁棒性，且嵌入开销低。&lt;h4&gt;结论&lt;/h4&gt;WGLE是一种有效且高效的GNN黑盒水印方法，能够有效防止模型盗窃，并保护知识产权。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are increasingly deployed in graph-relatedapplications, making ownership verification critical to protect theirintellectual property against model theft. Fingerprinting and black-boxwatermarking are two main methods. However, the former relies on determiningmodel similarity, which is computationally expensive and prone to ownershipcollisions after model post-processing such as model pruning or fine-tuning.The latter embeds backdoors, exposing watermarked models to the risk ofbackdoor attacks. Moreover, both methods enable ownership verification but donot convey additional information. As a result, each distributed model requiresa unique trigger graph, and all trigger graphs must be used to query thesuspect model during verification. Multiple queries increase the financial costand the risk of detection.  To address these challenges, this paper proposes WGLE, a novel black-boxwatermarking paradigm for GNNs that enables embedding the multi-bit string asthe ownership information without using backdoors. WGLE builds on a key insightwe term Layer-wise Distance Difference on an Edge (LDDE), which quantifies thedifference between the feature distance and the prediction distance of twoconnected nodes. By predefining positive or negative LDDE values for multipleselected edges, WGLE embeds the watermark encoding the intended informationwithout introducing incorrect mappings that compromise the primary task. WGLEis evaluated on six public datasets and six mainstream GNN architectures alongwith state-of-the-art methods. The results show that WGLE achieves 100%ownership verification accuracy, an average fidelity degradation of 0.85%,comparable robustness against potential attacks, and low embedding overhead.The code is available in the repository.</description>
      <author>example@mail.com (Tingzhi Li, Xuefeng Liu)</author>
      <guid isPermaLink="false">2506.08602v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion Sequence Models for Enhanced Protein Representation and Generation</title>
      <link>http://arxiv.org/abs/2506.08293v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Diffusion Sequence Model (DSM)，一种新型蛋白质语言模型，通过掩码扩散训练实现高质量表示学习和生成蛋白质设计。&lt;h4&gt;背景&lt;/h4&gt;蛋白质是生物学的基本组成部分，在医学、材料科学和环境应用中具有变革潜力。蛋白质语言模型（pLMs）旨在通过掩码语言模型从未标记的蛋白质序列中学习丰富的语义表示，但它们通常表现出有限的生成能力。&lt;h4&gt;目的&lt;/h4&gt;提高蛋白质语言模型的生成能力，实现高质量表示学习和生成蛋白质设计。&lt;h4&gt;方法&lt;/h4&gt;DSM基于ESM2架构，通过引入掩码前向扩散过程，受到LLaDA框架的启发。DSM(ppi)是DSM的一个变体，针对目标序列进行微调以生成蛋白质结合剂。&lt;h4&gt;主要发现&lt;/h4&gt;DSM能够生成与预期氨基酸组成、二级结构和预测功能一致的多样化、生物模拟序列，即使有90%的标记损坏。DSM的学习表示在下游任务中与类似规模的pLMs相当或更好。DSM和DSM(ppi)在BenchBB基准测试中表现出色，生成的候选结合剂具有比已知结合剂更高的预测结合亲和力。&lt;h4&gt;结论&lt;/h4&gt;掩码扩散被证明是统一蛋白质表示和生成在单一框架中的强大范式。&lt;h4&gt;翻译&lt;/h4&gt;摘要：蛋白质是生物学的基石，通过复杂的物理化学相互作用执行多种功能，并在医学、材料科学和环境应用中具有变革潜力。蛋白质语言模型（pLMs）旨在通过从初级序列中学习丰富的语义表示，通过掩码语言模型从大量未标记的蛋白质序列中揭示见解。然而，这些模型通常表现出有限的生成能力。在这项工作中，我们引入了Diffusion Sequence Model (DSM)，一种新型pLM，通过掩码扩散训练以实现高质量的表示学习和生成蛋白质设计。DSM通过结合LLaDA框架启发的掩码前向扩散过程，在ESM2架构的基础上构建。经过训练，DSM能够生成与预期氨基酸组成、二级结构和预测功能一致的多样化、生物模拟序列，即使有90%的标记损坏。此外，DSM的学习表示在下游任务中与类似规模的pLMs相当或更好。我们还引入了DSM(ppi)，一种针对生成蛋白质结合剂进行微调的变体。我们在具有挑战性的Bench-tested Binder Benchmark (BenchBB)上展示了DSM(ppi)的有效性，其中DSM和DSM(ppi)都产生了比已知结合剂具有更高预测结合亲和力的候选结合剂。我们的结果将掩码扩散确立为统一蛋白质表示和生成在单一框架中的强大范式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Proteins are fundamental to biology, executing diverse functions throughcomplex physicochemical interactions, and they hold transformative potentialacross medicine, materials science, and environmental applications. ProteinLanguage Models (pLMs) aim to unlock insights from the vast space of unlabeledprotein sequences by learning rich, semantic representations from primarysequences via masked language modeling. However, these models typically exhibitlimited generative capacity. In this work, we introduce the Diffusion SequenceModel (DSM), a novel pLM trained with masked diffusion to enable bothhigh-quality representation learning and generative protein design. DSM buildsupon the ESM2 architecture by incorporating a masked forward diffusion processinspired by the LLaDA framework. After training, DSM is capable of generatingdiverse, biomimetic sequences that align with expected amino acid compositions,secondary structures, and predicted functions, even with 90\% token corruption.Furthermore, DSM's learned representations match or exceed those of similarlysized pLMs on downstream tasks. We also introduce DSM(ppi), a variantfine-tuned to generate protein binders by attending to target sequences. Wedemonstrate DSM(ppi)'s effectiveness on the challenging Bench-tested BinderBenchmark (BenchBB), where both DSM and DSM(ppi) produce candidates withsuperior predicted binding affinity compared to known binders. Our resultsestablish masked diffusion as a powerful paradigm for unifying proteinrepresentation and generation in a single framework.</description>
      <author>example@mail.com (Logan Hallee, Nikolaos Rafailidis, David B. Bichara, Jason P. Gleghorn)</author>
      <guid isPermaLink="false">2506.08293v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>HGFormer: A Hierarchical Graph Transformer Framework for Two-Stage Colonel Blotto Games via Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.08580v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HGformer的分层图Transformer框架，用于解决两阶段Colonel Blotto游戏中的资源分配问题，通过实验验证了其在复杂动态游戏场景中的优越性能。&lt;h4&gt;背景&lt;/h4&gt;两阶段Colonel Blotto游戏是一个典型的对抗性资源分配问题，涉及两个代理在两个阶段内按顺序在网络拓扑中分配资源：首先是初始资源部署，然后是多个轮次的动态重新分配调整。&lt;h4&gt;目的&lt;/h4&gt;为了解决游戏阶段之间的顺序依赖性和图拓扑的复杂约束，提出HGformer框架以实现大规模对抗环境中的高效策略生成。&lt;h4&gt;方法&lt;/h4&gt;HGformer通过结合增强的图Transformer编码器（具有结构偏差）和两个代理的分层决策模型来实现策略生成。此外，还设计了一种逐层反馈强化学习算法，将来自低级决策的长期回报反馈到高级策略的优化中。&lt;h4&gt;主要发现&lt;/h4&gt;与现有的分层决策或图神经网络方法相比，HGformer显著提高了资源分配效率和对抗性收益。&lt;h4&gt;结论&lt;/h4&gt;HGformer在复杂动态游戏场景中实现了优于现有方法的整体性能。&lt;h4&gt;翻译&lt;/h4&gt;Two-stage Colonel Blotto game represents a typical adversarial resourceallocation problem, in which two opposing agents sequentially allocate resources in a network topology across two phases: an initial resourcedeployment followed by multiple rounds of dynamic reallocation adjustments. Thesequential dependency between game stages and the complex constraints imposedby the graph topology make it difficult for traditional approaches to attain aglobally optimal strategy. To address these challenges, we propose a hierarchical graph Transformer framework called HGformer. By incorporating an enhanced graph Transformer encoder with structural biases and a two-agent hierarchical decision model, our approach enables efficient policy generation in large-scale adversarial environments. Moreover, we design a layer-by-layer feedback reinforcement learning algorithm that feeds the long-term returns from lower-level decisions back into the optimization of the higher-level strategy, thus bridging the coordination gap between the two decision-making stages. Experimental results demonstrate that, compared to existing hierarchical decision-making or graph neural network methods, HGformer significantly improves resource allocation efficiency and adversarial payoff, achieving superior overall performance in complex dynamic game scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Two-stage Colonel Blotto game represents a typical adversarial resourceallocation problem, in which two opposing agents sequentially allocateresources in a network topology across two phases: an initial resourcedeployment followed by multiple rounds of dynamic reallocation adjustments. Thesequential dependency between game stages and the complex constraints imposedby the graph topology make it difficult for traditional approaches to attain aglobally optimal strategy. To address these challenges, we propose ahierarchical graph Transformer framework called HGformer. By incorporating anenhanced graph Transformer encoder with structural biases and a two-agenthierarchical decision model, our approach enables efficient policy generationin large-scale adversarial environments. Moreover, we design a layer-by-layerfeedback reinforcement learning algorithm that feeds the long-term returns fromlower-level decisions back into the optimization of the higher-level strategy,thus bridging the coordination gap between the two decision-making stages.Experimental results demonstrate that, compared to existing hierarchicaldecision-making or graph neural network methods, HGformer significantlyimproves resource allocation efficiency and adversarial payoff, achievingsuperior overall performance in complex dynamic game scenarios.</description>
      <author>example@mail.com (Yang Lv, Jinlong Lei, Peng Yi)</author>
      <guid isPermaLink="false">2506.08580v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>RS-MTDF: Multi-Teacher Distillation and Fusion for Remote Sensing Semi-Supervised Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2506.08772v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RS-MTDF的半监督语义分割框架，用于遥感图像分割，以解决现有半监督方法中标签数据与未标记数据分布不匹配的问题。&lt;h4&gt;背景&lt;/h4&gt;遥感图像的语义分割对于多种应用至关重要，但其性能高度依赖于大规模、高质量的像素级标注，这些标注获取成本高且耗时。半监督语义分割（SSS）作为一种替代方案，可以有效减轻数据依赖。&lt;h4&gt;目的&lt;/h4&gt;提出RS-MTDF框架，利用视觉基础模型（VFMs）的强大泛化能力，以改善SSS的性能。&lt;h4&gt;方法&lt;/h4&gt;RS-MTDF框架采用多个预训练的VFMs作为专家教师，通过特征级别的蒸馏来对齐学生特征，并融合蒸馏的知识到学生解码器中，从而增强判别能力。&lt;h4&gt;主要发现&lt;/h4&gt;在三个具有挑战性的遥感数据集（ISPRS Potsdam、LoveDA和DeepGlobe）上进行的实验表明，RS-MTDF在各个标签比率上均取得了最先进的性能，尤其是在LoveDA数据集上，在大多数语义类别中获得了最高的IoU值。&lt;h4&gt;结论&lt;/h4&gt;多教师VFMs的指导在显著提高遥感分割的泛化和语义理解方面是有效的。消融实验进一步验证了每个模块的贡献。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Semantic segmentation in remote sensing images is crucial for various applications, yet its performance is heavily reliant on large-scale, high-quality pixel-wise annotations, which are notoriously expensive and time-consuming to acquire. Semi-supervised semantic segmentation (SSS) offers a promising alternative to mitigate this data dependency. However, existing SSS methods often struggle with the inherent distribution mismatch between limited labeled data and abundant unlabeled data, leading to suboptimal generalization. We propose that Vision Foundation Models (VFMs), pre-trained on vast and diverse datasets, possess robust generalization capabilities that can effectively bridge this distribution gap and provide strong semantic priors for SSS. Inspired by this, we introduce RS-MTDF (Multi-Teacher Distillation and Fusion), a novel framework that leverages the powerful semantic knowledge embedded in VFMs to guide semi-supervised learning in remote sensing. Specifically, RS-MTDF employs multiple frozen VFMs (e.g., DINOv2 and CLIP) as expert teachers, utilizing feature-level distillation to align student features with their robust representations. To further enhance discriminative power, the distilled knowledge is seamlessly fused into the student decoder. Extensive experiments on three challenging remote sensing datasets (ISPRS Potsdam, LoveDA, and DeepGlobe) demonstrate that RS-MTDF consistently achieves state-of-the-art performance. Notably, our method outperforms existing approaches across various label ratios on LoveDA and secures the highest IoU in the majority of semantic categories. These results underscore the efficacy of multi-teacher VFM guidance in significantly enhancing both generalization and semantic understanding for remote sensing segmentation. Ablation studies further validate the contribution of each proposed module.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic segmentation in remote sensing images is crucial for variousapplications, yet its performance is heavily reliant on large-scale,high-quality pixel-wise annotations, which are notoriously expensive andtime-consuming to acquire. Semi-supervised semantic segmentation (SSS) offers apromising alternative to mitigate this data dependency. However, existing SSSmethods often struggle with the inherent distribution mismatch between limitedlabeled data and abundant unlabeled data, leading to suboptimal generalization.We propose that Vision Foundation Models (VFMs), pre-trained on vast anddiverse datasets, possess robust generalization capabilities that caneffectively bridge this distribution gap and provide strong semantic priors forSSS. Inspired by this, we introduce RS-MTDF (Multi-Teacher Distillation andFusion), a novel framework that leverages the powerful semantic knowledgeembedded in VFMs to guide semi-supervised learning in remote sensing.Specifically, RS-MTDF employs multiple frozen VFMs (\textit{e.g.}, DINOv2 andCLIP) as expert teachers, utilizing feature-level distillation to align studentfeatures with their robust representations. To further enhance discriminativepower, the distilled knowledge is seamlessly fused into the student decoder.Extensive experiments on three challenging remote sensing datasets (ISPRSPotsdam, LoveDA, and DeepGlobe) demonstrate that RS-MTDF consistently achievesstate-of-the-art performance. Notably, our method outperforms existingapproaches across various label ratios on LoveDA and secures the highest IoU inthe majority of semantic categories. These results underscore the efficacy ofmulti-teacher VFM guidance in significantly enhancing both generalization andsemantic understanding for remote sensing segmentation. Ablation studiesfurther validate the contribution of each proposed module.</description>
      <author>example@mail.com (Jiayi Song, Kaiyu Li, Xiangyong Cao, Deyu Meng)</author>
      <guid isPermaLink="false">2506.08772v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Bayesian Inverse Physics for Neuro-Symbolic Robot Learning</title>
      <link>http://arxiv.org/abs/2506.08756v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合数据驱动学习和结构化推理的概念框架，旨在解决现实世界机器人应用中深度学习架构在未知和动态环境下的局限性。&lt;h4&gt;背景&lt;/h4&gt;现实世界的机器人应用需要适应性、可解释性和数据高效的机器学习方法。&lt;h4&gt;目的&lt;/h4&gt;评估深度学习架构在未知和动态环境下的局限性，并提出一种结合数据驱动学习和结构化推理的方法。&lt;h4&gt;方法&lt;/h4&gt;通过利用可微物理进行高效的世界建模，贝叶斯推理进行不确定性感知的决策，以及元学习进行对新任务的快速适应。&lt;h4&gt;主要发现&lt;/h4&gt;将物理符号推理嵌入到神经网络模型中，机器人可以超越训练数据泛化，推理新情境，并持续扩展其知识。&lt;h4&gt;结论&lt;/h4&gt;这种混合神经符号架构对于下一代自主系统至关重要，并为此提供了一个研究路线图以指导和发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现实世界的机器人应用，从自主探索到辅助技术，需要适应性、可解释性和数据高效的机器学习方法。虽然深度学习架构和基础模型在多样化的机器人应用中推动了显著进步，但它们在未知和动态环境中高效和可靠运行的能力仍然有限。在这篇立场论文中，我们批判性地评估了这些局限性，并介绍了一个结合数据驱动学习与有目的、结构化推理的概念框架。具体来说，我们提出了利用可微物理进行高效世界建模、贝叶斯推理进行不确定性感知决策以及元学习进行对新任务的快速适应。通过在神经网络模型中嵌入物理符号推理，机器人可以超越其训练数据泛化，推理新情境，并持续扩展其知识。我们认为，这样的混合神经符号架构对于下一代自主系统至关重要，为此，我们提供了一个研究路线图以指导和加速其发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world robotic applications, from autonomous exploration to assistivetechnologies, require adaptive, interpretable, and data-efficient learningparadigms. While deep learning architectures and foundation models have drivensignificant advances in diverse robotic applications, they remain limited intheir ability to operate efficiently and reliably in unknown and dynamicenvironments. In this position paper, we critically assess these limitationsand introduce a conceptual framework for combining data-driven learning withdeliberate, structured reasoning. Specifically, we propose leveragingdifferentiable physics for efficient world modeling, Bayesian inference foruncertainty-aware decision-making, and meta-learning for rapid adaptation tonew tasks. By embedding physical symbolic reasoning within neural models,robots could generalize beyond their training data, reason about novelsituations, and continuously expand their knowledge. We argue that such hybridneuro-symbolic architectures are essential for the next generation ofautonomous systems, and to this end, we provide a research roadmap to guide andaccelerate their development.</description>
      <author>example@mail.com (Octavio Arriaga, Rebecca Adam, Melvin Laux, Lisa Gutzeit, Marco Ragni, Jan Peters, Frank Kirchner)</author>
      <guid isPermaLink="false">2506.08756v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Reasoning Capabilities of Small Language Models with Blueprints and Prompt Template Search</title>
      <link>http://arxiv.org/abs/2506.08669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  TTODLer-FM Workshop@ICML'25 (Tiny Titans: The next wave of On-Device  Learning for Foundational Models)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，通过使用大型语言模型生成的蓝图来增强小型语言模型的推理能力，同时减少对提示变化的敏感度，从而提高小型语言模型在各种任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;小型语言模型（SLMs）虽然比大型语言模型（LLMs）更高效，但其有限的容量限制了它们的推理能力，并使它们对提示变化敏感。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，以提高SLMs的推理能力，同时减少对提示变化的敏感性。&lt;h4&gt;方法&lt;/h4&gt;该框架通过以下方式实现：1）利用LLM生成的蓝图提供结构化的推理指南；2）集成提示模板搜索机制来减少SLMs对提示变化的敏感性。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在各种任务（如数学、编码和逻辑推理）上提高了SLMs的表现，且无需增加模型大小或额外训练，为设备或资源受限的环境提供了一种轻量级且易于部署的解决方案。&lt;h4&gt;结论&lt;/h4&gt;该框架为SLMs提供了一个有效的方法来增强推理能力，同时保持了模型的小巧和部署的便捷性。&lt;h4&gt;翻译&lt;/h4&gt;Small language models (SLMs) offer promising and efficient alternatives to large language models (LLMs). However, SLMs' limited capacity restricts their reasoning capabilities and makes them sensitive to prompt variations. To address these challenges, we propose a novel framework that enhances SLM reasoning capabilities through LLM generated blueprints. The blueprints provide structured, high-level reasoning guides that help SLMs systematically tackle related problems. Furthermore, our framework integrates a prompt template search mechanism to mitigate the SLMs' sensitivity to prompt variations. Our framework demonstrates improved SLM performance across various tasks, including math (GSM8K), coding (MBPP), and logic reasoning (BBH). Our approach improves the reasoning capabilities of SLMs without increasing model size or requiring additional training, offering a lightweight and deployment-friendly solution for on-device or resource-constrained environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Small language models (SLMs) offer promising and efficient alternatives tolarge language models (LLMs). However, SLMs' limited capacity restricts theirreasoning capabilities and makes them sensitive to prompt variations. Toaddress these challenges, we propose a novel framework that enhances SLMreasoning capabilities through LLM generated blueprints. The blueprints providestructured, high-level reasoning guides that help SLMs systematically tacklerelated problems. Furthermore, our framework integrates a prompt templatesearch mechanism to mitigate the SLMs' sensitivity to prompt variations. Ourframework demonstrates improved SLM performance across various tasks, includingmath (GSM8K), coding (MBPP), and logic reasoning (BBH). Our approach improvesthe reasoning capabilities of SLMs without increasing model size or requiringadditional training, offering a lightweight and deployment-friendly solutionfor on-device or resource-constrained environments.</description>
      <author>example@mail.com (Dongge Han, Menglin Xia, Daniel Madrigal Diaz, Samuel Kessler, Ankur Mallick, Xuchao Zhang, Mirian Del Carmen Hipolito Garcia, Jin Xu, Victor Rühle, Saravan Rajmohan)</author>
      <guid isPermaLink="false">2506.08669v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>ST-GraphNet: A Spatio-Temporal Graph Neural Network for Understanding and Predicting Automated Vehicle Crash Severity</title>
      <link>http://arxiv.org/abs/2506.08051v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ST-GraphNet，这是一种用于模拟和预测自动驾驶汽车（AV）事故严重程度的时空图神经网络框架。该框架结合了细粒度和区域聚合的时空图来建模。&lt;h4&gt;背景&lt;/h4&gt;理解自动驾驶汽车事故的空间和时间动态对于提高城市移动安全性和基础设施规划至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够模拟和预测AV事故严重程度的时空图神经网络框架。&lt;h4&gt;方法&lt;/h4&gt;使用来自德克萨斯州的真实世界AV相关事故报告数据集，构建了两种互补的图表示：细粒度图和粗粒度图。细粒度图以单个事故事件为节点，通过时空邻近性定义边；粗粒度图将事故聚合到基于H3空间索引的单元格中，通过六边形相邻性连接。每个节点都包含多模态数据，包括使用预训练的Sentence-BERT模型从事故叙述中提取的文本嵌入。评估了不同的图神经网络（GNN）架构，如GCN、GAT和DSTGCN，以分类事故严重程度并预测高风险区域。&lt;h4&gt;主要发现&lt;/h4&gt;ST-GraphNet，在粗粒度H3图上使用DSTGCN作为主干，实现了97.74%的测试准确率，显著优于最佳细粒度模型（64.7%的测试准确率）。&lt;h4&gt;结论&lt;/h4&gt;空间聚合、动态消息传递和多模态特征集成在捕捉AV事故严重程度背后的复杂时空模式方面是有效的。&lt;h4&gt;翻译&lt;/h4&gt;Understanding the spatial and temporal dynamics of automated vehicle (AV) crash severity is critical for advancing urban mobility safety and infrastructure planning. In this work, we introduce ST-GraphNet, a spatio-temporal graph neural network framework designed to model and predict AV crash severity by using both fine-grained and region-aggregated spatial graphs. Using a balanced dataset of 2,352 real-world AV-related crash reports from Texas (2024), including geospatial coordinates, crash timestamps, SAE automation levels, and narrative descriptions, we construct two complementary graph representations: (1) a fine-grained graph with individual crash events as nodes, where edges are defined via spatio-temporal proximity; and (2) a coarse-grained graph where crashes are aggregated into Hexagonal Hierarchical Spatial Indexing (H3)-based spatial cells, connected through hexagonal adjacency. Each node in the graph is enriched with multimodal data, including semantic, spatial, and temporal attributes, including textual embeddings from crash narratives using a pretrained Sentence-BERT model. We evaluate various graph neural network (GNN) architectures, such as Graph Convolutional Networks (GCN), Graph Attention Networks (GAT), and Dynamic Spatio-Temporal GCN (DSTGCN), to classify crash severity and predict high-risk regions. Our proposed ST-GraphNet, which utilizes a DSTGCN backbone on the coarse-grained H3 graph, achieves a test accuracy of 97.74%, substantially outperforming the best fine-grained model (64.7% test accuracy). These findings highlight the effectiveness of spatial aggregation, dynamic message passing, and multi-modal feature integration in capturing the complex spatio-temporal patterns underlying AV crash severity.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the spatial and temporal dynamics of automated vehicle (AV)crash severity is critical for advancing urban mobility safety andinfrastructure planning. In this work, we introduce ST-GraphNet, aspatio-temporal graph neural network framework designed to model and predict AVcrash severity by using both fine-grained and region-aggregated spatial graphs.Using a balanced dataset of 2,352 real-world AV-related crash reports fromTexas (2024), including geospatial coordinates, crash timestamps, SAEautomation levels, and narrative descriptions, we construct two complementarygraph representations: (1) a fine-grained graph with individual crash events asnodes, where edges are defined via spatio-temporal proximity; and (2) acoarse-grained graph where crashes are aggregated into Hexagonal HierarchicalSpatial Indexing (H3)-based spatial cells, connected through hexagonaladjacency. Each node in the graph is enriched with multimodal data, includingsemantic, spatial, and temporal attributes, including textual embeddings fromcrash narratives using a pretrained Sentence-BERT model. We evaluate variousgraph neural network (GNN) architectures, such as Graph Convolutional Networks(GCN), Graph Attention Networks (GAT), and Dynamic Spatio-Temporal GCN(DSTGCN), to classify crash severity and predict high-risk regions. Ourproposed ST-GraphNet, which utilizes a DSTGCN backbone on the coarse-grained H3graph, achieves a test accuracy of 97.74\%, substantially outperforming thebest fine-grained model (64.7\% test accuracy). These findings highlight theeffectiveness of spatial aggregation, dynamic message passing, and multi-modalfeature integration in capturing the complex spatio-temporal patternsunderlying AV crash severity.</description>
      <author>example@mail.com (Mahmuda Sultana Mimi, Md Monzurul Islam, Anannya Ghosh Tusti, Shriyank Somvanshi, Subasish Das)</author>
      <guid isPermaLink="false">2506.08051v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Time Series Representations for Classification Lie Hidden in Pretrained Vision Transformers</title>
      <link>http://arxiv.org/abs/2506.08641v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TiViT的框架，该框架通过将时间序列转换为图像，利用在大型图像数据集上预训练的冻结视觉Transformer（ViTs）的表示能力，以解决时间序列分类问题。&lt;h4&gt;背景&lt;/h4&gt;时间序列分类在医疗和工业领域至关重要，但时间序列基础模型（TSFMs）的发展受到公开可用时间序列数据集稀缺的限制。&lt;h4&gt;目的&lt;/h4&gt;提出TiViT框架，以提高时间序列分类的性能。&lt;h4&gt;方法&lt;/h4&gt;1. 通过分析ViTs的2D补丁化，理论证明了其对于时间序列的增强表示能力。2. 实验表明，TiViT通过使用大型OpenCLIP模型的隐藏表示，在标准时间序列分类基准上达到了最先进的性能。3. 探索了TiViT表示的结构，发现具有高内在维度的中间层对于时间序列分类最为有效。4. 评估了TiViT与TSFM表示空间之间的对齐，并确定了它们之间的强互补性，通过结合其特征实现了进一步的性能提升。&lt;h4&gt;主要发现&lt;/h4&gt;1. ViTs的2D补丁化可以增加与标签相关的标记数量并降低样本复杂度。2. TiViT在标准时间序列分类基准上实现了最先进的性能。3. TiViT的中间层具有高内在维度，对于时间序列分类最为有效。4. TiViT与TSFM表示空间之间存在强互补性。&lt;h4&gt;结论&lt;/h4&gt;TiViT框架为在非视觉领域中重用视觉表示提供了另一个方向。&lt;h4&gt;翻译&lt;/h4&gt;时间序列分类是医疗和工业领域的一项基本任务，然而，由于公开可用的时间序列数据集稀缺，时间序列基础模型（TSFMs）的发展仍然有限。在这项工作中，我们提出了时间视觉Transformer（TiViT），这是一个将时间序列转换为图像的框架，以利用在大型图像数据集上预训练的冻结视觉Transformer（ViTs）的表示能力。首先，我们通过分析ViTs的2D补丁化，从理论上论证了我们的方法，表明它可以增加与标签相关的标记数量并减少样本复杂度。其次，我们通过利用大型OpenCLIP模型的隐藏表示，在标准时间序列分类基准上实证地展示了TiViT实现了最先进的性能。我们探索了TiViT表示的结构，并发现具有高内在维度的中间层对于时间序列分类最为有效。最后，我们评估了TiViT与TSFM表示空间之间的对齐，并确定了它们之间的强互补性，通过结合它们的特征实现了进一步的性能提升。我们的发现揭示了在非视觉领域中重用视觉表示的另一个方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series classification is a fundamental task in healthcare and industry,yet the development of time series foundation models (TSFMs) remains limited bythe scarcity of publicly available time series datasets. In this work, wepropose Time Vision Transformer (TiViT), a framework that converts time seriesinto images to leverage the representational power of frozen VisionTransformers (ViTs) pretrained on large-scale image datasets. First, wetheoretically motivate our approach by analyzing the 2D patching of ViTs fortime series, showing that it can increase the number of label-relevant tokensand reduce the sample complexity. Second, we empirically demonstrate that TiViTachieves state-of-the-art performance on standard time series classificationbenchmarks by utilizing the hidden representations of large OpenCLIP models. Weexplore the structure of TiViT representations and find that intermediatelayers with high intrinsic dimension are the most effective for time seriesclassification. Finally, we assess the alignment between TiViT and TSFMrepresentation spaces and identify a strong complementarity, with furtherperformance gains achieved by combining their features. Our findings reveal yetanother direction for reusing vision representations in a non-visual domain.</description>
      <author>example@mail.com (Simon Roschmann, Quentin Bouniot, Vasilii Feofanov, Ievgen Redko, Zeynep Akata)</author>
      <guid isPermaLink="false">2506.08641v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Hybrid Reasoning for Perception, Explanation, and Autonomous Action in Manufacturing</title>
      <link>http://arxiv.org/abs/2506.08462v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CIPHER的工业控制与解释框架，旨在通过混合专家知识和推理来提高工业过程的鲁棒性和适应性。&lt;h4&gt;背景&lt;/h4&gt;工业过程中的环境和任务往往不可预测，操作错误代价高昂且难以检测。基于AI的控制系统虽然具有潜力，但通常依赖于监督学习和大量标注数据，限制了其在变化和缺乏数据的工业环境中的应用。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够模仿人类推理的工业控制模型，并应用于商业级3D打印机。&lt;h4&gt;方法&lt;/h4&gt;CIPHER框架结合了过程专家、回归模型和检索增强生成技术，以实现外部专家知识的访问和物理信息化的推理。&lt;h4&gt;主要发现&lt;/h4&gt;CIPHER在处理分布外任务时表现出强大的泛化能力，能够解释视觉或文本输入，并自主生成精确的机器指令，无需显式标注。&lt;h4&gt;结论&lt;/h4&gt;CIPHER为自主系统奠定了基础，这些系统能够精确行动、根据上下文进行推理，并透明地传达决策，支持在工业环境中的安全可靠部署。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Industrial processes must be robust and adaptable, as environments and tasks are often unpredictable, while operational errors remain costly and difficult to detect. AI-based control systems offer a path forward, yet typically depend on supervised learning with extensive labelled datasets, which limits their ability to generalize across variable and data-scarce industrial settings. Foundation models could enable broader reasoning and knowledge integration, but rarely deliver the quantitative precision demanded by engineering applications. Here, we introduce Control and Interpretation of Production via Hybrid Expertise and Reasoning (CIPHER): a vision-language-action (VLA) model framework aiming to replicate human-like reasoning for industrial control, instantiated in a commercial-grade 3D printer. It integrates a process expert, a regression model enabling quantitative characterization of system states required for engineering tasks. CIPHER also incorporates retrieval-augmented generation to access external expert knowledge and support physics-informed, chain-of-thought reasoning. This hybrid architecture exhibits strong generalization to out-of-distribution tasks. It interprets visual or textual inputs from process monitoring, explains its decisions, and autonomously generates precise machine instructions, without requiring explicit annotations. CIPHER thus lays the foundations for autonomous systems that act with precision, reason with context, and communicate decisions transparently, supporting safe and trusted deployment in industrial settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Industrial processes must be robust and adaptable, as environments and tasksare often unpredictable, while operational errors remain costly and difficultto detect. AI-based control systems offer a path forward, yet typically dependon supervised learning with extensive labelled datasets, which limits theirability to generalize across variable and data-scarce industrial settings.Foundation models could enable broader reasoning and knowledge integration, butrarely deliver the quantitative precision demanded by engineering applications.Here, we introduceControl and Interpretation of Production via Hybrid Expertiseand Reasoning (CIPHER): a vision-language-action (VLA) model framework aimingto replicate human-like reasoning for industrial control, instantiated in acommercial-grade 3D printer. It integrates a process expert, a regression modelenabling quantitative characterization of system states required forengineering tasks. CIPHER also incorporates retrieval-augmented generation toaccess external expert knowledge and support physics-informed, chain-of-thoughtreasoning. This hybrid architecture exhibits strong generalization toout-of-distribution tasks. It interprets visual or textual inputs from processmonitoring, explains its decisions, and autonomously generates precise machineinstructions, without requiring explicit annotations. CIPHER thus lays thefoundations for autonomous systems that act with precision, reason withcontext, and communicate decisions transparently, supporting safe and trusteddeployment in industrial settings.</description>
      <author>example@mail.com (Christos Margadji, Sebastian W. Pattinson)</author>
      <guid isPermaLink="false">2506.08462v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>SHIELD: Multi-task Multi-distribution Vehicle Routing Solver with Sparsity and Hierarchy</title>
      <link>http://arxiv.org/abs/2506.08424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in the 42nd International Conference of Machine Learning  (ICML)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的多任务多分布车辆路径问题（MTMDVRP）模型SHIELD，该模型结合了稀疏性和层次性原则，并通过混合深度（MoD）技术和基于上下文的聚类层来提高效率和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基于深度学习的路由问题基础模型在处理多种VRP变体时显示出巨大潜力，但往往忽视了复杂真实世界的客户分布。&lt;h4&gt;目的&lt;/h4&gt;提高多任务VRP（MTVRP）设置到更真实、更具挑战性的多任务多分布VRP（MTMDVRP）设置，并开发一个能够有效处理这种复杂性的模型。&lt;h4&gt;方法&lt;/h4&gt;SHIELD模型通过以下方法实现：1. 使用混合深度（MoD）技术强制执行稀疏性，允许模型动态选择使用或跳过每个解码器层，以适应性地分配计算资源；2. 开发基于上下文的聚类层，利用问题中存在的层次结构产生更好的局部表示。&lt;h4&gt;主要发现&lt;/h4&gt;SHIELD模型能够识别出任务和分布之间的关键特征，显著提高了对未见过的任务的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;在9个真实地图上的16种VRP变体上的实证结果表明，该方法优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances toward foundation models for routing problems have shown great potential of a unified deep model for various VRP variants. However, they overlook the complex real-world customer distributions. In this work, we advance the Multi-Task VRP (MTVRP) setting to the more realistic yet challenging Multi-Task Multi-Distribution VRP (MTMDVRP) setting, and introduce SHIELD, a novel model that leverages both sparsity and hierarchy principles. Building on a deeper decoder architecture, we first incorporate the Mixture-of-Depths (MoD) technique to enforce sparsity. This improves both efficiency and generalization by allowing the model to dynamically select nodes to use or skip each decoder layer, providing the needed capacity to adaptively allocate computation for learning the task/distribution specific and shared representations. We also develop a context-based clustering layer that exploits the presence of hierarchical structures in the problems to produce better local representations. These two designs inductively bias the network to identify key features that are common across tasks and distributions, leading to significantly improved generalization on unseen ones. Our empirical results demonstrate the superiority of our approach over existing methods on 9 real-world maps with 16 VRP variants each.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances toward foundation models for routing problems have showngreat potential of a unified deep model for various VRP variants. However, theyoverlook the complex real-world customer distributions. In this work, weadvance the Multi-Task VRP (MTVRP) setting to the more realistic yetchallenging Multi-Task Multi-Distribution VRP (MTMDVRP) setting, and introduceSHIELD, a novel model that leverages both sparsity and hierarchy principles.Building on a deeper decoder architecture, we first incorporate theMixture-of-Depths (MoD) technique to enforce sparsity. This improves bothefficiency and generalization by allowing the model to dynamically select nodesto use or skip each decoder layer, providing the needed capacity to adaptivelyallocate computation for learning the task/distribution specific and sharedrepresentations. We also develop a context-based clustering layer that exploitsthe presence of hierarchical structures in the problems to produce better localrepresentations. These two designs inductively bias the network to identify keyfeatures that are common across tasks and distributions, leading tosignificantly improved generalization on unseen ones. Our empirical resultsdemonstrate the superiority of our approach over existing methods on 9real-world maps with 16 VRP variants each.</description>
      <author>example@mail.com (Yong Liang Goh, Zhiguang Cao, Yining Ma, Jianan Zhou, Mohammad Haroon Dupty, Wee Sun Lee)</author>
      <guid isPermaLink="false">2506.08424v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>H$^2$GFM: Towards unifying Homogeneity and Heterogeneity on Text-Attributed Graphs</title>
      <link>http://arxiv.org/abs/2506.08298v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为H^2GFM的新框架，旨在提高图基础模型（GFM）在处理不同类型图和任务时的泛化能力，特别是针对异构文本属性图（HeTAGs）。&lt;h4&gt;背景&lt;/h4&gt;图学习在多个领域的应用日益增加，推动了统一模型的发展，该模型称为图基础模型（GFM），能够很好地跨不同图和任务泛化。现有研究主要利用文本属性图（TAGs）来处理图之间节点特征的异质性，但主要关注同构文本属性图（HoTAGs），而对异构文本属性图（HeTAGs）的研究不足。&lt;h4&gt;目的&lt;/h4&gt;为了增强GFM的能力和应用，旨在提出一个能够泛化处理HoTAGs和HeTAGs的框架。&lt;h4&gt;方法&lt;/h4&gt;H^2GFM模型通过一个统一文本空间将图之间的各种元关系进行投影，并使用上下文编码来捕捉空间和高级语义关系。为了实现鲁棒的节点表示，提出了一个新颖的上下文自适应图变换器（CGT），有效捕捉上下文邻居及其关系的信息。此外，采用CGT专家混合方法来捕捉不同类型图之间的结构模式异质性。&lt;h4&gt;主要发现&lt;/h4&gt;在广泛的各种HoTAGs和HeTAGs以及学习场景上的综合实验表明，该模型是有效的。&lt;h4&gt;结论&lt;/h4&gt;H^2GFM框架能够有效提升GFM在处理不同类型图和任务时的泛化能力，特别是在处理异构文本属性图方面。&lt;h4&gt;翻译&lt;/h4&gt;The growing interests and applications of graph learning in diverse domains have propelled the development of a unified model generalizing well across different graphs and tasks, known as the Graph Foundation Model (GFM). Existing research has leveraged text-attributed graphs (TAGs) to tackle the heterogeneity in node features among graphs. However, they primarily focus on homogeneous TAGs (HoTAGs), leaving heterogeneous TAGs (HeTAGs), where multiple types of nodes/edges reside, underexplored. To enhance the capabilities and applications of GFM, we introduce H^2GFM, a novel framework designed to generalize across both HoTAGs and HeTAGs. Our model projects diverse meta-relations among graphs under a unified textual space, and employs a context encoding to capture spatial and higher-order semantic relationships. To achieve robust node representations, we propose a novel context-adaptive graph transformer (CGT), effectively capturing information from both context neighbors and their relationships. Furthermore, we employ a mixture of CGT experts to capture the heterogeneity in structural patterns among graph types. Comprehensive experiments on a wide range of HoTAGs and HeTAGs as well as learning scenarios demonstrate the effectiveness of our model.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing interests and applications of graph learning in diverse domainshave propelled the development of a unified model generalizing well acrossdifferent graphs and tasks, known as the Graph Foundation Model (GFM). Existingresearch has leveraged text-attributed graphs (TAGs) to tackle theheterogeneity in node features among graphs. However, they primarily focus onhomogeneous TAGs (HoTAGs), leaving heterogeneous TAGs (HeTAGs), where multipletypes of nodes/edges reside, underexplored. To enhance the capabilities andapplications of GFM, we introduce H$^2$GFM, a novel framework designed togeneralize across both HoTAGs and HeTAGs. Our model projects diversemeta-relations among graphs under a unified textual space, and employs acontext encoding to capture spatial and higher-order semantic relationships. Toachieve robust node representations, we propose a novel context-adaptive graphtransformer (CGT), effectively capturing information from both contextneighbors and their relationships. Furthermore, we employ a mixture of CGTexperts to capture the heterogeneity in structural patterns among graph types.Comprehensive experiments on a wide range of HoTAGs and HeTAGs as well aslearning scenarios demonstrate the effectiveness of our model.</description>
      <author>example@mail.com (Trung-Kien Nguyen, Heng Ping, Shixuan Li, Peiyu Zhang, Nikos Kanakaris, Nicholas Kotov, Paul Bogdan)</author>
      <guid isPermaLink="false">2506.08298v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Seeing Voices: Generating A-Roll Video from Audio with Mirage</title>
      <link>http://arxiv.org/abs/2506.08279v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report website: mirage.app/research/seeing-voices, product  website: mirage.app&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Mirage的音频到视频基础模型，该模型能够根据音频输入生成逼真的视频图像。&lt;h4&gt;背景&lt;/h4&gt;目前视频生成方法要么忽略声音专注于图像序列生成，要么虽然处理视觉和音频元素但仅限于特定应用领域，如配音。&lt;h4&gt;目的&lt;/h4&gt;提出一种音频到视频生成模型，能够从音频输入中生成具有表达性的视频图像。&lt;h4&gt;方法&lt;/h4&gt;Mirage模型结合了语音合成技术和自注意力机制，能够根据包含语音的音频生成视频。&lt;h4&gt;主要发现&lt;/h4&gt;Mirage模型能够生成高质量的视频输出，且在音频到视频生成方面具有通用性。&lt;h4&gt;结论&lt;/h4&gt;Mirage模型为音频到视频生成提供了一种有效的方法，并鼓励读者亲自体验其效果。&lt;h4&gt;翻译&lt;/h4&gt;从专业电影制作到用户生成内容，创作者和消费者长期以来都认识到视频的力量取决于我们听到的（视频的音频轨道）和我们看到的（视频的图像序列）之间的和谐结合。当前的视频生成方法要么忽略声音以专注于通用但无声的图像序列生成，要么处理视觉和音频元素但仅限于配音等特定应用领域。我们介绍了Mirage，这是一种音频到视频的基础模型，能够从零开始根据音频输入生成逼真的、具有表现力的输出图像。当与现有的语音合成方法（如文本到语音或TTS）集成时，Mirage可以生成引人入胜的多模态视频。当在包含语音的音频视频素材（A卷）上训练，并基于包含语音的音频进行条件化时，Mirage可以生成人们根据输入音频中隐含的表现进行可信诠释的视频。我们主要的技术贡献是统一了训练基于自注意力的音频到视频生成模型的方法，无论是从头开始还是基于现有权重。这种方法使得Mirage在音频到视频生成方面保持了通用性，同时产生了比结合特定于音频架构或针对人、语音或图像或音频捕获细节的损失组件的方法具有更高主观质量的输出。我们鼓励读者亲自观看和聆听Mirage的结果（见论文和评论中的链接）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; From professional filmmaking to user-generated content, creators andconsumers have long recognized that the power of video depends on theharmonious integration of what we hear (the video's audio track) with what wesee (the video's image sequence). Current approaches to video generation eitherignore sound to focus on general-purpose but silent image sequence generationor address both visual and audio elements but focus on restricted applicationdomains such as re-dubbing. We introduce Mirage, an audio-to-video foundationmodel that excels at generating realistic, expressive output imagery fromscratch given an audio input. When integrated with existing methods for speechsynthesis (text-to-speech, or TTS), Mirage results in compelling multimodalvideo. When trained on audio-video footage of people talking (A-roll) andconditioned on audio containing speech, Mirage generates video of peopledelivering a believable interpretation of the performance implicit in inputaudio. Our central technical contribution is a unified method for trainingself-attention-based audio-to-video generation models, either from scratch orgiven existing weights. This methodology allows Mirage to retain generality asan approach to audio-to-video generation while producing outputs of superiorsubjective quality to methods that incorporate audio-specific architectures orloss components specific to people, speech, or details of how images or audioare captured. We encourage readers to watch and listen to the results of Miragefor themselves (see paper and comments for links).</description>
      <author>example@mail.com (Aditi Sundararaman, Amogh Adishesha, Andrew Jaegle, Dan Bigioi, Hyoung-Kyu Song, Jon Kyl, Justin Mao, Kevin Lan, Mojtaba Komeili, ShahRukh Athar, Sheila Babayan, Stanislau Beliasau, William Buchwalter)</author>
      <guid isPermaLink="false">2506.08279v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Pre-Trained Time Series Models for Electricity Price Forecasting</title>
      <link>http://arxiv.org/abs/2506.08113v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了电力价格预测（EPF）在现货市场交易决策中的重要性，并比较了多种时间序列基础模型（TSFMs）在EPF中的有效性。&lt;h4&gt;背景&lt;/h4&gt;虽然近年来生成人工智能（GenAI）和预训练的大型语言模型（LLMs）的发展促进了时间序列基础模型（TSFMs）的众多时间序列预测方法，但这些模型在EPF中的有效性尚不确定。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一差距，本文对比了多个最先进的预训练模型（Chronos-Bolt、Chronos-T5、TimesFM、Moirai、Time-MoE和TimeGPT）与已建立的统计和机器学习（ML）方法在EPF中的性能。&lt;h4&gt;方法&lt;/h4&gt;使用来自德国、法国、荷兰、奥地利和比利时2024年的日间拍卖（DAA）电力价格数据，对模型进行了一天的每日预测。&lt;h4&gt;主要发现&lt;/h4&gt;Chronos-Bolt和Time-MoE在TSFMs中表现最强，与传统模型表现相当。然而，双季节性MSTL模型在多个国家和评估指标上表现出色，没有TSFM在统计上优于它。&lt;h4&gt;结论&lt;/h4&gt;本文的研究结果表明，尽管某些TSFMs在EPF中表现出色，但双季节性MSTL模型在多个国家和评估指标上的一致性能表现尤为突出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate electricity price forecasting (EPF) is crucial for effectivedecision-making in power trading on the spot market. While recent advances ingenerative artificial intelligence (GenAI) and pre-trained large languagemodels (LLMs) have inspired the development of numerous time series foundationmodels (TSFMs) for time series forecasting, their effectiveness in EPF remainsuncertain. To address this gap, we benchmark several state-of-the-artpretrained models--Chronos-Bolt, Chronos-T5, TimesFM, Moirai, Time-MoE, andTimeGPT--against established statistical and machine learning (ML) methods forEPF. Using 2024 day-ahead auction (DAA) electricity prices from Germany,France, the Netherlands, Austria, and Belgium, we generate daily forecasts witha one-day horizon. Chronos-Bolt and Time-MoE emerge as the strongest among theTSFMs, performing on par with traditional models. However, the biseasonal MSTLmodel, which captures daily and weekly seasonality, stands out for itsconsistent performance across countries and evaluation metrics, with no TSFMstatistically outperforming it.</description>
      <author>example@mail.com (Timothée Hornek Amir Sartipi, Igor Tchappi, Gilbert Fridgen)</author>
      <guid isPermaLink="false">2506.08113v1</guid>
      <pubDate>Wed, 11 Jun 2025 14:17:34 +0800</pubDate>
    </item>
    <item>
      <title>LSM-2: Learning from Incomplete Wearable Sensor Data</title>
      <link>http://arxiv.org/abs/2506.05321v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Xu and Narayanswamy are co-first authors. McDuff and Liu are co-last  authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了第二代大传感器模型（LSM-2）与自适应和继承掩码（AIM）的结合，这是一种新型的自监督学习（SSL）方法，可以直接从数据缺失的情况下学习稳健的表示，而无需显式地进行数据填充。&lt;h4&gt;背景&lt;/h4&gt;基础模型是机器学习近期进展的核心，但可穿戴传感器数据通常存在大量缺失，这对通常假设完整数据输入的自监督学习模型构成了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的SSL方法，能够从缺失数据中学习，以解决可穿戴传感器数据中缺失数据的问题。&lt;h4&gt;方法&lt;/h4&gt;引入了LSM-2与AIM的结合，其中AIM使用可学习的掩码标记来模拟现有的（继承的）和人为引入的缺失数据，从而在推理过程中稳健地处理碎片化的真实世界数据。&lt;h4&gt;主要发现&lt;/h4&gt;LSM-2与AIM在40M小时的日间多模态传感器数据集上进行了预训练，并在包括分类、回归和生成建模在内的各种任务中实现了最佳性能。此外，LSM-2与AIM展现出优异的扩展性能，并且在目标缺失场景下仍能保持高性能，反映了临床一致的模式，如夜间生物信号在高血压预测中的诊断价值。&lt;h4&gt;结论&lt;/h4&gt;AIM为实际的可穿戴数据应用提供了一个更可靠的解决方案，因为它能够处理缺失数据并维持高精度。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型是近期机器学习进步的基石，它们主要依赖于完整且结构良好的数据。可穿戴传感器数据常常存在显著的缺失，这对通常假设完整数据输入的自监督学习（SSL）模型构成了重大挑战。本文介绍了第二代大传感器模型（LSM-2）与自适应和继承掩码（AIM）的结合，这是一种新颖的自监督学习（SSL）方法，可以直接从数据缺失的情况下学习稳健的表示，而无需显式地进行数据填充。AIM的核心创新在于其使用可学习的掩码标记来模拟现有的（继承的）和人为引入的缺失数据，使得它能够在推理过程中稳健地处理碎片化的真实世界数据。在40M小时的日间多模态传感器数据集上预训练后，我们的LSM-2与AIM在包括分类、回归和生成建模在内的各种任务中实现了最佳性能。此外，LSM-2与AIM展现出优异的扩展性能，并且关键的是，即使在目标缺失场景下也能保持高性能，反映了临床一致的模式，如夜间生物信号在高血压预测中的诊断价值。这使得AIM成为实际可穿戴数据应用的一个更可靠的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models, a cornerstone of recent advancements in machine learning,have predominantly thrived on complete and well-structured data. Wearablesensor data frequently suffers from significant missingness, posing asubstantial challenge for self-supervised learning (SSL) models that typicallyassume complete data inputs. This paper introduces the second generation ofLarge Sensor Model (LSM-2) with Adaptive and Inherited Masking (AIM), a novelSSL approach that learns robust representations directly from incomplete datawithout requiring explicit imputation. AIM's core novelty lies in its use oflearnable mask tokens to model both existing ("inherited") and artificiallyintroduced missingness, enabling it to robustly handle fragmented real-worlddata during inference. Pre-trained on an extensive dataset of 40M hours ofday-long multimodal sensor data, our LSM-2 with AIM achieves the bestperformance across a diverse range of tasks, including classification,regression and generative modeling. Furthermore, LSM-2 with AIM exhibitssuperior scaling performance, and critically, maintains high performance evenunder targeted missingness scenarios, reflecting clinically coherent patterns,such as the diagnostic value of nighttime biosignals for hypertensionprediction. This makes AIM a more reliable choice for real-world wearable dataapplications.</description>
      <author>example@mail.com (Maxwell A. Xu, Girish Narayanswamy, Kumar Ayush, Dimitris Spathis, Shun Liao, Shyam A. Tailor, Ahmed Metwally, A. Ali Heydari, Yuwei Zhang, Jake Garrison, Samy Abdel-Ghaffar, Xuhai Xu, Ken Gu, Jacob Sunshine, Ming-Zher Poh, Yun Liu, Tim Althoff, Shrikanth Narayanan, Pushmeet Kohli, Mark Malhotra, Shwetak Patel, Yuzhe Yang, James M. Rehg, Xin Liu, Daniel McDuff)</author>
      <guid isPermaLink="false">2506.05321v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
  <item>
      <title>Diffusion Counterfactual Generation with Semantic Abduction</title>
      <link>http://arxiv.org/abs/2506.07883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of the 42nd International Conference on Machine Learning,  Vancouver, Canada&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散模型的因果机制，用于改进反事实图像生成，旨在解决身份保持、感知质量和因果模型忠实度等挑战。&lt;h4&gt;背景&lt;/h4&gt;反事实图像生成在保持身份、维护感知质量和确保对底层因果模型的忠实度方面存在重大挑战。现有的自动编码框架虽然允许操纵语义潜在空间以进行因果控制，但面临着可扩展性和忠实度的问题。&lt;h4&gt;目的&lt;/h4&gt;通过提出一套基于扩散的因果机制，本文旨在提高反事实图像编辑的质量，并引入空间、语义和动态推理的概念。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种将语义表示整合到扩散模型中的通用框架，通过Pearlian因果性的视角，通过反事实推理过程编辑图像。&lt;h4&gt;主要发现&lt;/h4&gt;这是首次考虑为扩散反事实图像生成提供高级语义身份保持的工作，并展示了语义控制如何实现忠实因果控制和身份保持之间的原则性权衡。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在视觉质量、人类感知和表示学习方面取得了最先进的成果，为反事实图像生成提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Counterfactual image generation presents significant challenges, includingpreserving identity, maintaining perceptual quality, and ensuring faithfulnessto an underlying causal model. While existing auto-encoding frameworks admitsemantic latent spaces which can be manipulated for causal control, theystruggle with scalability and fidelity. Advancements in diffusion modelspresent opportunities for improving counterfactual image editing, havingdemonstrated state-of-the-art visual quality, human-aligned perception andrepresentation learning capabilities. Here, we present a suite ofdiffusion-based causal mechanisms, introducing the notions of spatial, semanticand dynamic abduction. We propose a general framework that integrates semanticrepresentations into diffusion models through the lens of Pearlian causality toedit images via a counterfactual reasoning process. To our knowledge, this isthe first work to consider high-level semantic identity preservation fordiffusion counterfactuals and to demonstrate how semantic control enablesprincipled trade-offs between faithful causal control and identitypreservation.</description>
      <author>example@mail.com (Rajat Rasal, Avinash Kori, Fabio De Sousa Ribeiro, Tian Xia, Ben Glocker)</author>
      <guid isPermaLink="false">2506.07883v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Gradients: When Markets Meet Fine-tuning -- A Distributed Approach to Model Optimisation</title>
      <link>http://arxiv.org/abs/2506.07940v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Gradients，一个将超参数优化转化为竞争市场的去中心化AutoML平台，通过经济激励机制实现个人探索与集体优化目标的统一，从而系统性地发现中心化方法遗漏的更优配置。&lt;h4&gt;背景&lt;/h4&gt;现有的AutoML平台依赖单一优化策略，只探索了一小部分可行的超参数配置，导致优化效果受限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过去中心化的AutoML平台，提高超参数优化的效果。&lt;h4&gt;方法&lt;/h4&gt;Gradients平台将超参数优化转化为竞争市场，独立矿工通过竞争发现最优配置，并利用经济激励机制驱动系统性的探索。&lt;h4&gt;主要发现&lt;/h4&gt;在180个控制实验中，Gradients平台在各种模型架构和任务类型上均取得了显著的效果，平均提升11.8%，在特定任务类型上提升高达30-40%。&lt;h4&gt;结论&lt;/h4&gt;竞争性和经济驱动的AutoML方法可以系统地发现中心化方法遗漏的更优配置，从而提高优化效果。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces Gradients, a decentralized AutoML platform that transforms hyperparameter optimization into a competitive marketplace where independent miners compete to discover optimal configurations. Economic incentives align individual exploration with collective optimization goals, driving systematic investigation of hyperparameter regions that centralized methods miss. We evaluate our approach across 180 controlled experiments spanning diverse model architectures (70M to 70B parameters) and task types. Gradients achieves an 82.8% win rate against HuggingFace AutoTrain and 100% against TogetherAI, Databricks, and Google Cloud, with mean improvements of 11.8% and 42.1% respectively. Complex reasoning and retrieval tasks show particularly strong gains of 30-40%, while diffusion models achieve 23.4% improvements for person-specific generation. These results demonstrate that competitive, economically-driven approaches can systematically discover superior configurations that centralized AutoML consistently miss.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation model fine-tuning faces a fundamental challenge: existing AutoMLplatforms rely on single optimisation strategies that explore only a fractionof viable hyperparameter configurations. In this white paper, We introduceGradients, a decentralised AutoML platform that transforms hyperparameteroptimisation into a competitive marketplace where independent miners compete todiscover optimal configurations. Economic incentives align individualexploration with collective optimisation goals, driving systematicinvestigation of hyperparameter regions that centralised methods miss. Weevaluate our approach across 180 controlled experiments spanning diverse modelarchitectures (70M to 70B parameters) and task types. Gradients achieves an82.8\% win rate against HuggingFace AutoTrain and 100\% against TogetherAI,Databricks, and Google Cloud, with mean improvements of 11.8\% and 42.1\%respectively. Complex reasoning and retrieval tasks show particularly stronggains of 30-40\%, whilst diffusion models achieve 23.4\% improvements forperson-specific generation. These results demonstrate that competitive,economically-driven approaches can systematically discover superiorconfigurations that centralised AutoML consistently miss.</description>
      <author>example@mail.com (Christopher Subia-Waud)</author>
      <guid isPermaLink="false">2506.07940v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence</title>
      <link>http://arxiv.org/abs/2506.07966v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SpaCE-10是一个针对多模态大型语言模型（MLLMs）在空间智能方面进行综合评估的基准。&lt;h4&gt;背景&lt;/h4&gt;MLLMs在多模态任务上取得了显著进步，但现有的基准难以全面评估MLLMs从原子级到组合级的空间智能。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，提出SpaCE-10，一个用于组合空间评估的综合基准。&lt;h4&gt;方法&lt;/h4&gt;定义了10个原子空间能力，组合成8个组合能力，并提出了一个新颖的分层标注流程来生成高质量和多样化的问答对。通过超过150小时的人类专家努力，获得了超过5000个问答对，涵盖811个真实室内场景，包括点云输入和多选题问答。&lt;h4&gt;主要发现&lt;/h4&gt;发现即使是最高级的MLLM，在空间智能方面也远远落后于人类。揭示了计数能力的不足大大限制了现有MLLMs的组合空间能力。&lt;h4&gt;结论&lt;/h4&gt;SpaCE-10为MLLM社区提供了有益的发现和评估工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态大型语言模型（MLLMs）在多种多模态任务上取得了显著的进步。为了在空间中追求更高的智能，MLLMs需要整合多个原子空间能力来处理复杂和动态的任务。然而，现有的基准难以从原子级到组合级全面评估常见MLLMs的空间智能。为了填补这一空白，我们提出了SpaCE-10，一个用于组合空间评估的综合基准。在SpaCE-10中，我们定义了10个原子空间能力，这些能力组合形成了8个组合能力。基于这些定义，我们提出了一种新颖的分层标注流程来生成高质量和多样化的问答对。通过超过150小时的人类专家努力，我们获得了超过5000个问答对，涵盖了811个真实室内场景，包括点云输入和多选题问答。我们在SpaCE-10上对常见MLLMs进行了广泛的评估，发现即使是最高级的MLLM，在空间智能方面也远远落后于人类。通过我们的仔细研究，我们还得出了几个对MLLM社区有益的重要发现。例如，我们揭示了计数能力的不足大大限制了现有MLLMs的组合空间能力。评估代码和基准数据集可在https://github.com/Cuzyoung/SpaCE-10找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have achieved remarkable progress invarious multimodal tasks. To pursue higher intelligence in space, MLLMs requireintegrating multiple atomic spatial capabilities to handle complex and dynamictasks. However, existing benchmarks struggle to comprehensively evaluate thespatial intelligence of common MLLMs from the atomic level to the compositionallevel. To fill this gap, we present SpaCE-10, a comprehensive benchmark forcompositional spatial evaluations. In SpaCE-10, we define 10 atomic spatialcapabilities, which are combined to form 8 compositional capabilities. Based onthese definitions, we propose a novel hierarchical annotation pipeline togenerate high-quality and diverse question-answer (QA) pairs. With over 150+hours of human expert effort, we obtain over 5k QA pairs for 811 real indoorscenes in SpaCE-10, which covers various evaluation settings like point cloudinput and multi-choice QA. We conduct an extensive evaluation of common MLLMson SpaCE-10 and find that even the most advanced MLLM still lags behind humansby large margins. Through our careful study, we also draw several significantfindings that benefit the MLLM community. For example, we reveal that theshortcoming of counting capability greatly limits the compositional spatialcapabilities of existing MLLMs. The evaluation code and benchmark datasets areavailable at https://github.com/Cuzyoung/SpaCE-10.</description>
      <author>example@mail.com (Ziyang Gong, Wenhao Li, Oliver Ma, Songyuan Li, Jiayi Ji, Xue Yang, Gen Luo, Junchi Yan, Rongrong Ji)</author>
      <guid isPermaLink="false">2506.07966v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>CyberV: Cybernetics for Test-time Scaling in Video Understanding</title>
      <link>http://arxiv.org/abs/2506.07971v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于控制论原理的新型框架，旨在解决现有多模态大型语言模型在处理长或复杂视频时的局限性，如计算需求高、鲁棒性差和准确性有限等问题。&lt;h4&gt;背景&lt;/h4&gt;现有多模态大型语言模型在处理长或复杂视频时存在计算需求高、鲁棒性差和准确性有限等问题，这些问题主要源于其前馈处理性质，尤其是在参数较少的模型中更为严重。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了一种名为CyberV的框架，旨在设计能够自我监控、自我纠正和动态资源分配的视频多模态大型语言模型。&lt;h4&gt;方法&lt;/h4&gt;CyberV框架包括一个多模态大型语言模型推理系统、一个传感器和一个控制器。传感器监控多模态大型语言模型的前向过程，收集中间解释，如注意力漂移；控制器决定何时以及如何触发自我纠正并生成反馈以指导下一轮。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CyberV在VideoMMMU上提升了Qwen2.5-VL-7B模型8.3%，在InternVL3-8B上提升了5.5%，超过了竞争性的GPT-4o模型。在Qwen2.5-VL-72B上应用时，提升了10.0%，其性能甚至可与人类专家相媲美。此外，该方法在VideoMME和WorldSense等通用基准测试中也表现出一致的收益，突显了其在使多模态大型语言模型更鲁棒和准确地进行动态视频理解方面的有效性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;CyberV框架能够有效提升多模态大型语言模型在动态视频理解任务中的性能，且无需重新训练或添加额外组件。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current Multimodal Large Language Models (MLLMs) may struggle withunderstanding long or complex videos due to computational demands at test time,lack of robustness, and limited accuracy, primarily stemming from theirfeed-forward processing nature. These limitations could be more severe formodels with fewer parameters. To address these limitations, we propose a novelframework inspired by cybernetic principles, redesigning video MLLMs asadaptive systems capable of self-monitoring, self-correction, and dynamicresource allocation during inference. Our approach, CyberV, introduces acybernetic loop consisting of an MLLM Inference System, a Sensor, and aController. Specifically, the sensor monitors forward processes of the MLLM andcollects intermediate interpretations, such as attention drift, then thecontroller determines when and how to trigger self-correction and generatefeedback to guide the next round. This test-time adaptive scaling frameworkenhances frozen MLLMs without requiring retraining or additional components.Experiments demonstrate significant improvements: CyberV boosts Qwen2.5-VL-7Bby 8.3% and InternVL3-8B by 5.5% on VideoMMMU, surpassing the competitiveproprietary model GPT-4o. When applied to Qwen2.5-VL-72B, it yields a 10.0%improvement, achieving performance even comparable to human experts.Furthermore, our method demonstrates consistent gains on general-purposebenchmarks, such as VideoMME and WorldSense, highlighting its effectiveness andgeneralization capabilities in making MLLMs more robust and accurate fordynamic video understanding. The code is released athttps://github.com/marinero4972/CyberV.</description>
      <author>example@mail.com (Jiahao Meng, Shuyang Sun, Yue Tan, Lu Qi, Yunhai Tong, Xiangtai Li, Longyin Wen)</author>
      <guid isPermaLink="false">2506.07971v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Language Embedding Meets Dynamic Graph: A New Exploration for Neural Architecture Representation Learning</title>
      <link>http://arxiv.org/abs/2506.07735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LeDG-Former的创新框架，通过结合语言语义嵌入和动态图表示学习来克服现有方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;神经网络架构表示学习在部署和设计网络以应用于现实世界方面发挥着关键作用。基于transformers的模型与图神经网络（GNNs）的集成在表示学习方面取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法忽视硬件属性信息以及编码方法依赖静态邻接矩阵的局限性。&lt;h4&gt;方法&lt;/h4&gt;引入LeDG-Former框架，该框架通过结合语言语义嵌入和动态图表示学习，将神经网络架构和硬件平台规范投影到一个统一的语义空间中，实现不同硬件平台间的零样本预测。&lt;h4&gt;主要发现&lt;/h4&gt;LeDG-Former在NNLQP基准测试中超越了之前的方法，建立了新的SOTA，并展示了首次成功实现跨硬件延迟预测的能力。此外，该框架在cell-structured NAS-Bench-101和NAS-Bench-201数据集上也取得了优越的性能。&lt;h4&gt;结论&lt;/h4&gt;LeDG-Former框架有效地解决了现有方法的局限性，为神经网络架构表示学习提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural Architecture Representation Learning aims to transform network modelsinto feature representations for predicting network attributes, playing acrucial role in deploying and designing networks for real-world applications.Recently, inspired by the success of transformers, transformer-based modelsintegrated with Graph Neural Networks (GNNs) have achieved significant progressin representation learning. However, current methods still have somelimitations. First, existing methods overlook hardware attribute information,which conflicts with the current trend of diversified deep learning hardwareand limits the practical applicability of models. Second, current encodingapproaches rely on static adjacency matrices to represent topologicalstructures, failing to capture the structural differences between computationalnodes, which ultimately compromises encoding effectiveness. In this paper, weintroduce LeDG-Former, an innovative framework that addresses these limitationsthrough the synergistic integration of language-based semantic embedding anddynamic graph representation learning. Specifically, inspired by large languagemodels (LLMs), we propose a language embedding framework where both neuralarchitectures and hardware platform specifications are projected into a unifiedsemantic space through tokenization and LLM processing, enabling zero-shotprediction across different hardware platforms for the first time. Then, wepropose a dynamic graph-based transformer for modeling neural architectures,resulting in improved neural architecture modeling performance. On the NNLQPbenchmark, LeDG-Former surpasses previous methods, establishing a new SOTAwhile demonstrating the first successful cross-hardware latency predictioncapability. Furthermore, our framework achieves superior performance on thecell-structured NAS-Bench-101 and NAS-Bench-201 datasets.</description>
      <author>example@mail.com (Haizhao Jing, Haokui Zhang, Zhenhao Shang, Rong Xiao, Peng Wang, Yanning Zhang)</author>
      <guid isPermaLink="false">2506.07735v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Image Reconstruction as a Tool for Feature Analysis</title>
      <link>http://arxiv.org/abs/2506.07803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过图像重建来解释视觉特征的新方法，并分析了不同视觉编码器内部特征表示的差异。&lt;h4&gt;背景&lt;/h4&gt;视觉编码器在现代应用中越来越受欢迎，但它们的内部特征表示方式尚不明确。&lt;h4&gt;目的&lt;/h4&gt;研究视觉编码器内部特征表示的方式，并评估不同模型在图像信息保留方面的表现。&lt;h4&gt;方法&lt;/h4&gt;提出了SigLIP和SigLIP2两种模型，通过比较它们的训练目标，发现基于图像任务的预训练编码器比基于非图像任务的编码器保留了更多的图像信息。此外，通过操纵特征空间来分析重建图像的变化，揭示颜色编码的控制方式。&lt;h4&gt;主要发现&lt;/h4&gt;基于图像任务的预训练编码器比基于非图像任务的编码器保留了更多的图像信息；通过操纵特征空间可以预测性地改变重建图像；正交旋转控制颜色编码。&lt;h4&gt;结论&lt;/h4&gt;该方法可以应用于任何视觉编码器，有助于揭示其特征空间的内部结构。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉编码器在现代应用中越来越受欢迎，从仅视觉模型到多模态系统如视觉-语言模型。尽管它们取得了显著的成功，但它们如何内部表示特征仍然不清楚。在这里，我们提出了一种通过图像重建来解释视觉特征的新方法。我们比较了两个相关的模型家族，SigLIP和SigLIP2，它们在训练目标上有所不同，并表明在基于图像任务的预训练上的编码器比在基于非图像任务（如对比学习）的编码器上保留了更多的图像信息。我们进一步将我们的方法应用于一系列视觉编码器，按照其特征表示的信息量对它们进行排名。最后，我们表明，操纵特征空间会导致重建图像的可预测变化，揭示了正交旋转（而不是空间变换）控制颜色编码。我们的方法可以应用于任何视觉编码器，有助于揭示其特征空间的内部结构。用于重现实验的代码和模型权重可在GitHub上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision encoders are increasingly used in modern applications, fromvision-only models to multimodal systems such as vision-language models.Despite their remarkable success, it remains unclear how these architecturesrepresent features internally. Here, we propose a novel approach forinterpreting vision features via image reconstruction. We compare two relatedmodel families, SigLIP and SigLIP2, which differ only in their trainingobjective, and show that encoders pre-trained on image-based tasks retainsignificantly more image information than those trained on non-image tasks suchas contrastive learning. We further apply our method to a range of visionencoders, ranking them by the informativeness of their feature representations.Finally, we demonstrate that manipulating the feature space yields predictablechanges in reconstructed images, revealing that orthogonal rotations (ratherthan spatial transformations) control color encoding. Our approach can beapplied to any vision encoder, shedding light on the inner structure of itsfeature space. The code and model weights to reproduce the experiments areavailable in GitHub.</description>
      <author>example@mail.com (Eduard Allakhverdov, Dmitrii Tarasov, Elizaveta Goncharova, Andrey Kuznetsov)</author>
      <guid isPermaLink="false">2506.07803v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>CrosswalkNet: An Optimized Deep Learning Framework for Pedestrian Crosswalk Detection in Aerial Images with High-Performance Computing</title>
      <link>http://arxiv.org/abs/2506.07885v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了CrosswalkNet，一个用于从高分辨率航空图像中检测各类人行横道的深度学习框架，旨在提高交通资产管理、安全分析和城市规划的效率。&lt;h4&gt;背景&lt;/h4&gt;随着航空和卫星图像的广泛应用，深度学习在交通资产管理、安全分析和城市规划方面具有巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够准确检测人行横道的深度学习框架。&lt;h4&gt;方法&lt;/h4&gt;CrosswalkNet采用了一种新颖的检测方法，使用定向边界框（OBB）提高检测精度，并通过卷积块注意力、双分支空间金字塔池化快速模块和余弦退火等优化技术来最大化性能和效率。研究使用了包含超过23,000个标注人行横道实例的综合数据集来训练和验证该框架。&lt;h4&gt;主要发现&lt;/h4&gt;最佳模型在马萨诸塞州的航空图像上实现了96.5%的精确率和93.3%的召回率。CrosswalkNet在没有迁移学习或微调的情况下成功应用于新罕布什尔州、弗吉尼亚州和缅因州的数据集。使用高性能计算（HPC）平台处理的人行横道检测结果以多边形形状文件格式提供，加速了数据处理和检测，支持实时分析和安全与移动性应用。&lt;h4&gt;结论&lt;/h4&gt;CrosswalkNet是一个准确且有效的工具，能够增强行人安全并改善城市流动性，为政策制定者、交通工程师和城市规划者提供了有效的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着航空和卫星图像的日益可用，深度学习在交通资产管理、安全分析和城市规划方面具有显著潜力。本研究介绍了CrosswalkNet，这是一个强大且高效的深度学习框架，旨在从15厘米分辨率的航空图像中检测各种类型的人行横道。CrosswalkNet采用了一种新颖的检测方法，通过使用定向边界框（OBB）改进了传统的目标检测策略，无论横道方向如何，都能准确地捕获横道。研究实现了包括卷积块注意力、双分支空间金字塔池化快速模块和余弦退火在内的多种优化技术，以最大化性能和效率。研究使用了包含超过23,000个标注人行横道实例的综合数据集来训练和验证所提出的框架。性能最佳的模型在马萨诸塞州的航空图像上实现了令人印象深刻的96.5%的精确率和93.3%的召回率，证明了其准确性和有效性。CrosswalkNet还成功应用于新罕布什尔州、弗吉尼亚州和缅因州的数据集，无需迁移学习或微调，展示了其鲁棒性和强大的泛化能力。此外，使用高性能计算（HPC）平台处理的人行横道检测结果以多边形形状文件格式提供，已显示出加速数据处理和检测的能力，支持安全性和移动性应用的实时分析。这种集成为政策制定者、交通工程师和城市规划者提供了一个有效的工具，以增强行人安全并改善城市流动性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the increasing availability of aerial and satellite imagery, deeplearning presents significant potential for transportation asset management,safety analysis, and urban planning. This study introduces CrosswalkNet, arobust and efficient deep learning framework designed to detect various typesof pedestrian crosswalks from 15-cm resolution aerial images. CrosswalkNetincorporates a novel detection approach that improves upon traditional objectdetection strategies by utilizing oriented bounding boxes (OBB), enhancingdetection precision by accurately capturing crosswalks regardless of theirorientation. Several optimization techniques, including Convolutional BlockAttention, a dual-branch Spatial Pyramid Pooling-Fast module, and cosineannealing, are implemented to maximize performance and efficiency. Acomprehensive dataset comprising over 23,000 annotated crosswalk instances isutilized to train and validate the proposed framework. The best-performingmodel achieves an impressive precision of 96.5% and a recall of 93.3% on aerialimagery from Massachusetts, demonstrating its accuracy and effectiveness.CrosswalkNet has also been successfully applied to datasets from New Hampshire,Virginia, and Maine without transfer learning or fine-tuning, showcasing itsrobustness and strong generalization capability. Additionally, the crosswalkdetection results, processed using High-Performance Computing (HPC) platformsand provided in polygon shapefile format, have been shown to accelerate dataprocessing and detection, supporting real-time analysis for safety and mobilityapplications. This integration offers policymakers, transportation engineers,and urban planners an effective instrument to enhance pedestrian safety andimprove urban mobility.</description>
      <author>example@mail.com (Zubin Bhuyan, Yuanchang Xie, AngkeaReach Rith, Xintong Yan, Nasko Apostolov, Jimi Oke, Chengbo Ai)</author>
      <guid isPermaLink="false">2506.07885v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>A Temporal FRBR/FRBRoo-Based Model for Component-Level Versioning of Legal Norms</title>
      <link>http://arxiv.org/abs/2506.07853v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结构化时间模型，扩展了FRBRoo框架，以解决法律规范自动处理中的关键挑战，特别是在追踪其层次化组件（如文章、段落）的历时演变。&lt;h4&gt;背景&lt;/h4&gt;目前，虽然FRBR/FRBRoo等基础框架和Akoma Ntoso等标准在宏观层面模型化了法律文件，但它们缺乏原生机制来进行细粒度、组件级别的版本控制，这阻碍了法律文本在特定时间点的确定性重建。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种能够精确、确定地检索和重建法律文本在特定日期状态的模型，为可靠的法律技术和AI应用提供基础。&lt;h4&gt;方法&lt;/h4&gt;提出了一种结构化时间模型，引入了Expressio - Temporal Version (TV)和Language Version (LV)等专门子类来表示法律规范及其语言变体在特定时间点的状态，并应用于层次化结构，引入Component Work (CW)、Component Temporal Version (CTV)和Component Language Version (CLV)来追踪个别文章、段落和条款的生命周期。&lt;h4&gt;主要发现&lt;/h4&gt;以巴西联邦宪法为案例研究，展示了每个修正案如何为受影响的条款创建新的Component Temporal Versions，而未受影响的组件则保留其现有版本。&lt;h4&gt;结论&lt;/h4&gt;该模型为开发高级法律信息系统、知识图谱和能够进行准确历史分析和影响评估的AI工具提供了坚实的基础，克服了当前生成模型的局限性。&lt;h4&gt;翻译&lt;/h4&gt;有效地表示用于自动处理的法律规范是一个关键挑战，尤其是在追踪其层次化组件（例如，文章、段落）的历时演变方面。虽然像FRBR/FRBRoo这样的基础框架和像Akoma Ntoso这样的标准在宏观层面模型化了法律文件，但它们缺乏原生机制来进行细粒度、组件级别的版本控制。这种限制阻碍了法律文本在特定时间点的确定性重建，这是可靠的法律技术和AI应用的基本能力。本文提出了一种结构化时间模型，扩展了FRBRoo框架来填补这一空白。它引入了Expressio - Temporal Version (TV)和Language Version (LV)等专门子类来表示法律规范及其语言变体在特定时间点的状态。该模型以相同的方法进行层次化应用，引入了Component Work (CW)、Component Temporal Version (CTV)和Component Language Version (CLV)来追踪个别文章、段落和条款的生命周期。以巴西联邦宪法为案例研究，本文展示了每个修正案如何为受影响的条款创建新的Component Temporal Versions，而未受影响的组件则保留其现有版本。这种精细粒度、时间感知的架构能够精确、确定地检索和重建任何部分的法律文本，如它在特定日期的状态。该模型为开发高级法律信息系统、知识图谱和能够进行准确历史分析和影响评估的AI工具提供了坚实的基础，克服了当前生成模型的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effectively representing legal norms for automated processing is a criticalchallenge, particularly in tracking the diachronic evolution of theirhierarchical components (e.g., articles, paragraphs). While foundationalframeworks like FRBR/FRBRoo and standards like Akoma Ntoso model legaldocuments at a macro level, they lack native mechanisms for granular,component-level versioning. This limitation hinders the deterministicpoint-in-time reconstruction of legal texts, a fundamental capability forreliable Legal Tech and AI applications. This paper proposes a structured,temporal model that extends the FRBRoo framework to address this gap. Itintroduces specialized subclasses of Expressio - Temporal Version (TV) andLanguage Version (LV - to represent the state of a legal norm and itslinguistic variations at specific points in time. The model applies this sameparadigm hierarchically, introducing Component Work (CW), Component TemporalVersion (CTV), and Component Language Version (CLV) to track the lifecycle ofindividual articles, paragraphs, and clauses. Using the Brazilian FederalConstitution as a case study, the paper demonstrates how each amendment createsnew Component Temporal Versions for affected provisions, while unaffectedcomponents retain their existing versions. This fine-grained, time-awarearchitecture enables the precise, deterministic retrieval and reconstruction ofany part of a legal text as it existed on a specific date. The model provides arobust foundation for developing advanced legal information systems, knowledgegraphs, and AI tools capable of accurate historical analysis and impactassessment, overcoming the limitations of current generative models.</description>
      <author>example@mail.com (Hudson de Martim)</author>
      <guid isPermaLink="false">2506.07853v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Super Encoding Network: Recursive Association of Multi-Modal Encoders for Video Understanding</title>
      <link>http://arxiv.org/abs/2506.07576v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Super Encoding Network (SEN)的统一网络，用于视频理解，该网络通过在基础模型中递归关联多模态编码器来建立深度多模态交互。&lt;h4&gt;背景&lt;/h4&gt;视频理解是迈向世界建模的关键步骤，而多模态基础模型通过大规模预训练显示出巨大潜力。然而，这些模型缺乏深度多模态交互，这对于理解复杂目标运动和多样化的视频场景至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文旨在提出一种新的方法来增强视频理解中的多模态交互。&lt;h4&gt;方法&lt;/h4&gt;本文设计了一种递归关联（RA）块，将多模态信息与输入视频逐步融合，通过超级神经元的递归知识整合、分配和提示来实现。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，SEN在四个代表性的视频任务（跟踪、识别、聊天和编辑）上均显著提升了性能，例如，在像素级跟踪任务中，与CaDeX++方法相比，Jaccard指数提高了2.7%，时间一致性（TC）降低了8.8%。在单次视频编辑任务中，与TuneA-Video方法相比，文本对齐提高了6.4%，帧一致性增加了4.1%。&lt;h4&gt;结论&lt;/h4&gt;SEN能够有效地编码深度多模态交互，从而显著提升视频理解任务的表现。&lt;h4&gt;翻译&lt;/h4&gt;Video understanding has been considered as one critical step towards world modeling, which is an important long-term problem in AI research. Recently, multi-modal foundation models have shown such potential via large-scale pretraining. However, these models simply align encoders of different modalities via contrastive learning, while lacking deeper multi-modal interactions, which is critical for understanding complex target movements with diversified video scenes. To fill this gap, we propose a unified Super Encoding Network (SEN) for video understanding, which builds up such distinct interactions through recursive association of multi-modal encoders in the foundation models. Specifically, we creatively treat those well-trained encoders as 'super neurons' in our SEN. Via designing a Recursive Association (RA) block, we progressively fuse multi-modalities with the input video, based on knowledge integrating, distributing, and prompting of super neurons in a recursive manner. In this way, our SEN can effectively encode deeper multi-modal interactions, for prompting various video understanding tasks in downstream. Extensive experiments show that, our SEN can remarkably boost the four most representative video tasks, including tracking, recognition, chatting, and editing, e.g., for pixel-level tracking, the average jaccard index improves 2.7%, temporal coherence (TC) drops 8.8% compared to the popular CaDeX++ approach. For one-shot video editing, textual alignment improves 6.4%, and frame consistency increases 4.1% compared to the popular TuneA-Video approach.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video understanding has been considered as one critical step towards worldmodeling, which is an important long-term problem in AI research. Recently,multi-modal foundation models have shown such potential via large-scalepretraining. However, these models simply align encoders of differentmodalities via contrastive learning, while lacking deeper multi-modalinteractions, which is critical for understanding complex target movements withdiversified video scenes. To fill this gap, we propose a unified Super EncodingNetwork (SEN) for video understanding, which builds up such distinctinteractions through recursive association of multi-modal encoders in thefoundation models. Specifically, we creatively treat those well-trainedencoders as "super neurons" in our SEN. Via designing a Recursive Association(RA) block, we progressively fuse multi-modalities with the input video, basedon knowledge integrating, distributing, and prompting of super neurons in arecursive manner. In this way, our SEN can effectively encode deepermulti-modal interactions, for prompting various video understanding tasks indownstream. Extensive experiments show that, our SEN can remarkably boost thefour most representative video tasks, including tracking, recognition,chatting, and editing, e.g., for pixel-level tracking, the average jaccardindex improves 2.7%, temporal coherence(TC) drops 8.8% compared to the popularCaDeX++ approach. For one-shot video editing, textual alignment improves 6.4%,and frame consistency increases 4.1% compared to the popular TuneA-Videoapproach.</description>
      <author>example@mail.com (Boyu Chen, Siran Chen, Kunchang Li, Qinglin Xu, Yu Qiao, Yali Wang)</author>
      <guid isPermaLink="false">2506.07576v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>EgoM2P: Egocentric Multimodal Multitask Pretraining</title>
      <link>http://arxiv.org/abs/2506.07886v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究如何理解以自我为中心的多模态信号，如RGB视频、深度、相机姿态和注视信息，这对增强现实、机器人和人机交互等应用至关重要。文章提出了EgoM2P框架，用于处理和合成这些多模态数据，并展示了其在不同任务上的性能优势。&lt;h4&gt;背景&lt;/h4&gt;多模态信号在以自我为中心的视觉应用中至关重要，但构建大规模的以自我为中心的多模态和多任务模型面临挑战，如数据异构性、模态缺失和动态相机运动等。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为EgoM2P的框架，用于解决上述挑战，并提高以自我为中心的多模态理解的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;引入高效的时序标记器，并构建EgoM2P框架，该框架通过从时序感知的多模态标记中学习，来训练一个用于以自我为中心的4D理解的大规模通用模型。&lt;h4&gt;主要发现&lt;/h4&gt;EgoM2P在注视预测、以自我为中心的相机跟踪和从以自我为中心的视频中进行单目深度估计等任务上表现出色，同时速度比专业模型快一个数量级。&lt;h4&gt;结论&lt;/h4&gt;EgoM2P框架有效解决了多模态信号理解中的挑战，提高了以自我为中心的视觉应用的性能，并计划开源以支持社区和推动相关研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：理解以自我为中心的多模态信号，如RGB视频、深度、相机姿态和注视，对于增强现实、机器人和人机交互等应用至关重要。这些能力使系统能够更好地解释相机佩戴者的动作、意图和周围环境。然而，构建大规模的以自我为中心的多模态和多任务模型面临独特的挑战。以自我为中心的数据本质上是异构的，在不同设备和环境中的模态覆盖范围存在很大差异。为缺失的模态，如注视或头戴式相机轨迹生成伪标签通常不可行，使得标准的监督学习方法难以扩展。此外，动态相机运动和第一人称视频的姿态的复杂时空结构为直接应用现有的多模态基础模型增加了额外的挑战。为了解决这些挑战，我们引入了一套高效的时间标记器，并提出了EgoM2P，一个从时序感知的多模态标记中学习的掩码建模框架，用于训练一个用于以自我为中心的4D理解的大规模通用模型。这种统一的设计支持跨各种以自我为中心的感知和合成任务的多任务，包括注视预测、以自我为中心的相机跟踪和从以自我为中心的视频中进行单目深度估计。EgoM2P还作为条件以自我为中心的视频合成的生成模型。在这些任务中，EgoM2P的性能与专业模型相当或更好，同时速度快一个数量级。我们将全面开源EgoM2P以支持社区并推进以自我为中心的视觉研究。项目页面：https://egom2p.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding multimodal signals in egocentric vision, such as RGB video,depth, camera poses, and gaze, is essential for applications in augmentedreality, robotics, and human-computer interaction. These capabilities enablesystems to better interpret the camera wearer's actions, intentions, andsurrounding environment. However, building large-scale egocentric multimodaland multitask models presents unique challenges. Egocentric data are inherentlyheterogeneous, with large variations in modality coverage across devices andsettings. Generating pseudo-labels for missing modalities, such as gaze orhead-mounted camera trajectories, is often infeasible, making standardsupervised learning approaches difficult to scale. Furthermore, dynamic cameramotion and the complex temporal and spatial structure of first-person videopose additional challenges for the direct application of existing multimodalfoundation models.  To address these challenges, we introduce a set of efficient temporaltokenizers and propose EgoM2P, a masked modeling framework that learns fromtemporally aware multimodal tokens to train a large, general-purpose model foregocentric 4D understanding. This unified design supports multitasking acrossdiverse egocentric perception and synthesis tasks, including gaze prediction,egocentric camera tracking, and monocular depth estimation from egocentricvideo. EgoM2P also serves as a generative model for conditional egocentricvideo synthesis. Across these tasks, EgoM2P matches or outperforms specialistmodels while being an order of magnitude faster. We will fully open-sourceEgoM2P to support the community and advance egocentric vision research. Projectpage: https://egom2p.github.io/</description>
      <author>example@mail.com (Gen Li, Yutong Chen, Yiqian Wu, Kaifeng Zhao, Marc Pollefeys, Siyu Tang)</author>
      <guid isPermaLink="false">2506.07886v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Squeeze3D: Your 3D Generation Model is Secretly an Extreme Neural Compressor</title>
      <link>http://arxiv.org/abs/2506.07932v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Squeeze3D是一种新的框架，利用现有预训练的3D生成模型学习到的隐式先验知识，在极高的压缩比下压缩3D数据。&lt;h4&gt;背景&lt;/h4&gt;3D数据的压缩是一个挑战，因为它们通常包含大量的细节。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，能够在不牺牲视觉质量的情况下，以极高的压缩比压缩3D数据。&lt;h4&gt;方法&lt;/h4&gt;Squeeze3D通过可训练的映射网络连接预训练的编码器和生成模型之间的潜在空间。首先，3D模型被预训练的编码器编码，然后转换（即压缩）为高度紧凑的潜在代码。映射网络将压缩的潜在代码转换为强大生成模型的潜在空间，然后条件化以重新创建原始的3D模型（即解压缩）。Squeeze3D完全在生成的合成数据上训练，不需要任何3D数据集。&lt;h4&gt;主要发现&lt;/h4&gt;Squeeze3D在保持视觉质量与许多现有方法相当的同时，实现了高达2187x的纹理网格压缩比，55x的点云压缩比和619x的辐射场压缩比。&lt;h4&gt;结论&lt;/h4&gt;Squeeze3D是一个灵活的框架，可以与现有的预训练3D编码器和生成模型一起使用，支持不同的格式，如网格、点云和辐射场，同时具有较低的压缩和解压缩延迟。&lt;h4&gt;翻译&lt;/h4&gt;我们提出Squeeze3D，一种新颖的框架，它利用现有预训练的3D生成模型学习到的隐式先验知识，在极高的压缩比下压缩3D数据。我们的方法通过可训练的映射网络连接预训练的编码器和预训练的生成模型之间的潜在空间。任何表示为网格、点云或辐射场的3D模型首先由预训练的编码器编码，然后转换为高度紧凑的潜在代码。这个潜在代码可以有效地用作网格或点云的极其压缩的表示。映射网络将压缩的潜在代码转换为强大生成模型的潜在空间，然后条件化以重新创建原始的3D模型（即解压缩）。Squeeze3D完全在生成的合成数据上训练，不需要任何3D数据集。Squeeze3D的架构可以灵活地与现有的预训练3D编码器和现有的生成模型一起使用。它可以灵活地支持不同的格式，包括网格、点云和辐射场。我们的实验表明，Squeeze3D实现了高达2187x的纹理网格压缩比，55x的点云压缩比和619x的辐射场压缩比，同时保持与许多现有方法相当的可视质量。由于Squeeze3D不涉及训练特定于对象的网络来压缩对象，因此它只产生很小的压缩和解压缩延迟。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose Squeeze3D, a novel framework that leverages implicit priorknowledge learnt by existing pre-trained 3D generative models to compress 3Ddata at extremely high compression ratios. Our approach bridges the latentspaces between a pre-trained encoder and a pre-trained generation model throughtrainable mapping networks. Any 3D model represented as a mesh, point cloud, ora radiance field is first encoded by the pre-trained encoder and thentransformed (i.e. compressed) into a highly compact latent code. This latentcode can effectively be used as an extremely compressed representation of themesh or point cloud. A mapping network transforms the compressed latent codeinto the latent space of a powerful generative model, which is then conditionedto recreate the original 3D model (i.e. decompression). Squeeze3D is trainedentirely on generated synthetic data and does not require any 3D datasets. TheSqueeze3D architecture can be flexibly used with existing pre-trained 3Dencoders and existing generative models. It can flexibly support differentformats, including meshes, point clouds, and radiance fields. Our experimentsdemonstrate that Squeeze3D achieves compression ratios of up to 2187x fortextured meshes, 55x for point clouds, and 619x for radiance fields whilemaintaining visual quality comparable to many existing methods. Squeeze3D onlyincurs a small compression and decompression latency since it does not involvetraining object-specific networks to compress an object.</description>
      <author>example@mail.com (Rishit Dagli, Yushi Guan, Sankeerth Durvasula, Mohammadreza Mofayezi, Nandita Vijaykumar)</author>
      <guid isPermaLink="false">2506.07932v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow</title>
      <link>http://arxiv.org/abs/2506.07878v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于事件相机的低延迟运动估计（光流）方法，该方法通过引入时空状态空间模型（STSSM）模块和新型网络架构，实现了高效且性能优异的解决方案。&lt;h4&gt;背景&lt;/h4&gt;传统基于帧的相机在低延迟运动估计方面存在限制，而事件相机可以解锁新的应用领域。尽管深度学习模型如CNN、RNN或ViT在性能上表现出色，但它们通常缺乏所需的计算效率。&lt;h4&gt;目的&lt;/h4&gt;开发一种既高效又具有竞争力的光流估计方法。&lt;h4&gt;方法&lt;/h4&gt;引入了STSSM模块，该模块利用状态空间模型有效地捕捉事件数据中的时空相关性，并提出了一个新的网络架构。&lt;h4&gt;主要发现&lt;/h4&gt;STSSM模块在保持较低复杂性的同时，提供了比ViT和基于CNN的架构更高的性能。该模型在DSEC基准测试中实现了4.5倍的推理速度和8倍的降低计算量，与TMA和EV-FlowNet相比，计算量降低了2倍。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在保持竞争力的同时，显著提高了计算效率。&lt;h4&gt;翻译&lt;/h4&gt;Event cameras unlock new frontiers that were previously unthinkable with standard frame-based cameras. One notable example is low-latency motion estimation (optical flow), which is critical for many real-time applications. In such applications, the computational efficiency of algorithms is paramount. Although recent deep learning paradigms such as CNN, RNN, or ViT have shown remarkable performance, they often lack the desired computational efficiency. Conversely, asynchronous event-based methods including SNNs and GNNs are computationally efficient; however, these approaches fail to capture sufficient spatio-temporal information, a powerful feature required to achieve better performance for optical flow estimation. In this work, we introduce Spatio-Temporal State Space Model (STSSM) module along with a novel network architecture to develop an extremely efficient solution with competitive performance. Our STSSM module leverages state-space models to effectively capture spatio-temporal correlations in event data, offering higher performance with lower complexity compared to ViT, CNN-based architectures in similar settings. Our model achieves 4.5x faster inference and 8x lower computations compared to TMA and 2x lower computations compared to EV-FlowNet with competitive performance on the DSEC benchmark. Our code will be available at https://github.com/AhmedHumais/E-STMFlow&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event cameras unlock new frontiers that were previously unthinkable withstandard frame-based cameras. One notable example is low-latency motionestimation (optical flow), which is critical for many real-time applications.In such applications, the computational efficiency of algorithms is paramount.Although recent deep learning paradigms such as CNN, RNN, or ViT have shownremarkable performance, they often lack the desired computational efficiency.Conversely, asynchronous event-based methods including SNNs and GNNs arecomputationally efficient; however, these approaches fail to capture sufficientspatio-temporal information, a powerful feature required to achieve betterperformance for optical flow estimation. In this work, we introduceSpatio-Temporal State Space Model (STSSM) module along with a novel networkarchitecture to develop an extremely efficient solution with competitiveperformance. Our STSSM module leverages state-space models to effectivelycapture spatio-temporal correlations in event data, offering higher performancewith lower complexity compared to ViT, CNN-based architectures in similarsettings. Our model achieves 4.5x faster inference and 8x lower computationscompared to TMA and 2x lower computations compared to EV-FlowNet withcompetitive performance on the DSEC benchmark. Our code will be available athttps://github.com/AhmedHumais/E-STMFlow</description>
      <author>example@mail.com (Muhammad Ahmed Humais, Xiaoqian Huang, Hussain Sajwani, Sajid Javed, Yahya Zweiri)</author>
      <guid isPermaLink="false">2506.07878v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Design and Evaluation of Deep Learning-Based Dual-Spectrum Image Fusion Methods</title>
      <link>http://arxiv.org/abs/2506.07779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了可见光图像和红外图像融合方法在场景理解，特别是复杂条件下的高级视觉任务中的应用，并提出了一个新的评价框架和数据集。&lt;h4&gt;背景&lt;/h4&gt;可见光图像和红外图像在纹理细节和目标检测上有各自的优势，融合这两种模态可以提高场景理解能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决当前评价方法依赖于通用指标、缺乏标准化基准和下游任务性能的问题，论文提出了一个高质量的校园环境双光谱数据集和一个综合评价框架。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含1369对可见光-红外图像对的校园环境双光谱数据集，提出了一个综合评价框架，该框架结合了融合速度、通用指标和目标检测性能，并在该框架下对比分析了多种融合算法。&lt;h4&gt;主要发现&lt;/h4&gt;融合模型在目标检测任务上表现优异，特别是在低光和遮挡场景下。一些在通用指标上表现良好的算法在下游任务上的表现并不理想，突显了当前评价方法的局限性。&lt;h4&gt;结论&lt;/h4&gt;论文的主要贡献包括：一个面向校园环境且包含多样化、挑战性场景的双光谱数据集；一个任务感知的综合评价框架；以及对多种数据集上领先融合方法的全面比较分析，为未来的发展提供了洞见。&lt;h4&gt;翻译&lt;/h4&gt;The abstract summarizes a study on the application of visible and infrared image fusion methods in scene understanding, especially for advanced vision tasks under challenging conditions, and proposes a new evaluation framework and dataset.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visible images offer rich texture details, while infrared images emphasizesalient targets. Fusing these complementary modalities enhances sceneunderstanding, particularly for advanced vision tasks under challengingconditions. Recently, deep learning-based fusion methods have gained attention,but current evaluations primarily rely on general-purpose metrics withoutstandardized benchmarks or downstream task performance. Additionally, the lackof well-developed dual-spectrum datasets and fair algorithm comparisons hindersprogress.  To address these gaps, we construct a high-quality dual-spectrum datasetcaptured in campus environments, comprising 1,369 well-aligned visible-infraredimage pairs across four representative scenarios: daytime, nighttime, smokeocclusion, and underpasses. We also propose a comprehensive and fair evaluationframework that integrates fusion speed, general metrics, and object detectionperformance using the lang-segment-anything model to ensure fairness indownstream evaluation.  Extensive experiments benchmark several state-of-the-art fusion algorithmsunder this framework. Results demonstrate that fusion models optimized fordownstream tasks achieve superior performance in target detection, especiallyin low-light and occluded scenes. Notably, some algorithms that perform well ongeneral metrics do not translate to strong downstream performance, highlightinglimitations of current evaluation practices and validating the necessity of ourproposed framework.  The main contributions of this work are: (1)a campus-oriented dual-spectrumdataset with diverse and challenging scenes; (2) a task-aware, comprehensiveevaluation framework; and (3) thorough comparative analysis of leading fusionmethods across multiple datasets, offering insights for future development.</description>
      <author>example@mail.com (Beining Xu, Junxian Li)</author>
      <guid isPermaLink="false">2506.07779v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Egocentric Event-Based Vision for Ping Pong Ball Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2506.07860v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE/CVF Conference on Computer Vision and Pattern Recognition  Workshops (CVPRW), Nashville (TN), USA, 2025; 5th International Workshop on  Event-Based Vision&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用事件摄像头进行实时乒乓球轨迹预测的系统。&lt;h4&gt;背景&lt;/h4&gt;与传统摄像头相比，事件摄像头在高速度运动场景中具有更高的时间分辨率，可以提供更频繁的状态更新，更强的鲁棒性以及对异常值的处理能力。&lt;h4&gt;目的&lt;/h4&gt;旨在通过事件摄像头预测乒乓球轨迹，实现3D轨迹预测。&lt;h4&gt;方法&lt;/h4&gt;收集了乒乓球比赛序列数据集，包括球的三维真实轨迹、与Meta Project Aria眼镜传感器数据同步的事件流。系统利用水平视野，利用眼镜的注视数据只处理观察者视野中央的事件，以减少计算延迟。检测管道具有最坏情况下的总延迟为4.5毫秒，包括计算和感知。&lt;h4&gt;主要发现&lt;/h4&gt;系统在收集的轨迹上实现了10.81的降低因子，检测管道的最坏情况总延迟为4.5毫秒，远低于基于帧的30 FPS系统。&lt;h4&gt;结论&lt;/h4&gt;本研究首次提出了一种使用事件摄像头从自视角预测乒乓球轨迹的方法。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we present a real-time egocentric trajectory prediction system for table tennis using event cameras. Unlike standard cameras, which suffer from high latency and motion blur at fast ball speeds, event cameras provide higher temporal resolution, allowing more frequent state updates, greater robustness to outliers, and accurate trajectory predictions using just a short time window after the opponent's impact. We collect a dataset of ping-pong game sequences, including 3D ground-truth trajectories of the ball, synchronized with sensor data from the Meta Project Aria glasses and event streams. Oursystem leverages foveated vision, using eye-gaze data from the glasses to process only events in the viewer's fovea. This biologically inspired approach improves ball detection performance and significantly reduces computational latency, as it efficiently allocates resources to the most perceptually relevant regions, achieving a reduction factor of 10.81 on the collected trajectories. Our detection pipeline has a worst-case total latency of 4.5 ms, including computation and perception - significantly lower than a frame-based 30 FPS system, which, in the worst case, takes 66 ms solely for perception. Finally, we fit a trajectory prediction model to the estimated states of the ball, enabling 3D trajectory forecasting in the future. To the best of our knowledge, this is the first approach to predict table tennis trajectories from an egocentric perspective using event cameras.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present a real-time egocentric trajectory prediction systemfor table tennis using event cameras. Unlike standard cameras, which sufferfrom high latency and motion blur at fast ball speeds, event cameras providehigher temporal resolution, allowing more frequent state updates, greaterrobustness to outliers, and accurate trajectory predictions using just a shorttime window after the opponent's impact. We collect a dataset of ping-pong gamesequences, including 3D ground-truth trajectories of the ball, synchronizedwith sensor data from the Meta Project Aria glasses and event streams. Oursystem leverages foveated vision, using eye-gaze data from the glasses toprocess only events in the viewer's fovea. This biologically inspired approachimproves ball detection performance and significantly reduces computationallatency, as it efficiently allocates resources to the most perceptuallyrelevant regions, achieving a reduction factor of 10.81 on the collectedtrajectories. Our detection pipeline has a worst-case total latency of 4.5 ms,including computation and perception - significantly lower than a frame-based30 FPS system, which, in the worst case, takes 66 ms solely for perception.Finally, we fit a trajectory prediction model to the estimated states of theball, enabling 3D trajectory forecasting in the future. To the best of ourknowledge, this is the first approach to predict table tennis trajectories froman egocentric perspective using event cameras.</description>
      <author>example@mail.com (Ivan Alberico, Marco Cannici, Giovanni Cioffi, Davide Scaramuzza)</author>
      <guid isPermaLink="false">2506.07860v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>OpenSplat3D: Open-Vocabulary 3D Instance Segmentation using Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.07697v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为OpenSplat3D的3D实例分割方法，它扩展了3D Gaussian Splatting在场景表示之外的能力，并通过自然语言描述在3D场景中识别和分割任意对象。&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting（3DGS）已成为神经场景重建的有力表示，它提供了高质量的全新视图合成，同时保持计算效率。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需手动标注的开放词汇3D实例分割方法，以扩展3DGS的应用范围。&lt;h4&gt;方法&lt;/h4&gt;方法利用特征splatting技术将语义信息与单个高斯函数关联，并采用Segment Anything Model实例掩码和对比损失公式作为实例特征的指导，同时利用视觉-语言模型的语言嵌入实现灵活的文本驱动实例识别。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在LERF-mask、LERF-OVS以及完整的ScanNet++验证集上展示了有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够根据自然语言描述识别和分割3D场景中的任意对象，证明了其在3D实例分割方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) has emerged as a powerful representation forneural scene reconstruction, offering high-quality novel view synthesis whilemaintaining computational efficiency. In this paper, we extend the capabilitiesof 3DGS beyond pure scene representation by introducing an approach foropen-vocabulary 3D instance segmentation without requiring manual labeling,termed OpenSplat3D. Our method leverages feature-splatting techniques toassociate semantic information with individual Gaussians, enabling fine-grainedscene understanding. We incorporate Segment Anything Model instance masks witha contrastive loss formulation as guidance for the instance features to achieveaccurate instance-level segmentation. Furthermore, we utilize languageembeddings of a vision-language model, allowing for flexible, text-driveninstance identification. This combination enables our system to identify andsegment arbitrary objects in 3D scenes based on natural language descriptions.We show results on LERF-mask and LERF-OVS as well as the full ScanNet++validation set, demonstrating the effectiveness of our approach.</description>
      <author>example@mail.com (Jens Piekenbrinck, Christian Schmidt, Alexander Hermans, Narunas Vaskevicius, Timm Linder, Bastian Leibe)</author>
      <guid isPermaLink="false">2506.07697v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Ambiguity-Restrained Text-Video Representation Learning for Partially Relevant Video Retrieval</title>
      <link>http://arxiv.org/abs/2506.07471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PRVR的部分相关视频检索方法，旨在从视频库中检索出与给定文本查询相关的特定片段。&lt;h4&gt;背景&lt;/h4&gt;传统的PRVR训练过程假设文本查询与视频之间存在一对一的关系，但作者指出文本和视频内容之间存在固有的模糊性。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，将这种模糊性纳入模型学习过程中。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为ARL的模糊性受限表示学习（Ambiguity-Restrained representation Learning）的方法，用于处理模糊的文本-视频对。ARL首先基于不确定性和相似性两个标准检测模糊对，然后通过多正对比学习和双重三元组损失来分层学习语义关系。此外，ARL还深入研究了视频实例中的细粒度关系，并提出了跨模型模糊性检测来减轻错误传播。&lt;h4&gt;主要发现&lt;/h4&gt;ARL能够有效地处理文本-视频对中的模糊性，并通过多层次的学习增强了文本-帧级别的学习。&lt;h4&gt;结论&lt;/h4&gt;该方法在PRVR中表现出良好的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：部分相关视频检索（PRVR）旨在检索与给定文本查询相关的特定片段的视频。典型的PRVR训练过程假设每个文本查询只与一个视频相关，但作者指出基于概念范围，文本和视频内容之间存在固有的模糊性。基于此，作者提出了一种将这种模糊性纳入模型学习过程的框架。具体来说，作者提出了模糊性受限表示学习（ARL）来解决模糊的文本-视频对。最初，ARL基于不确定性和相似性两个标准检测模糊对。不确定性表示实例是否包含数据集中常见共享的上下文，而相似性表示成对语义重叠。然后，通过检测到的模糊对，ARL通过多正对比学习和双重三元组损失分层学习语义关系。此外，ARL还深入研究了视频实例中的细粒度关系。与典型的在文本-视频级别的训练不同，在提供成对信息时，ARL解决了同一未剪辑视频中帧之间的固有模糊性，这些帧通常包含多个上下文。这使得我们能够在文本-帧级别进一步增强学习。最后，作者提出了跨模型模糊性检测来减轻当使用单个模型检测用于其训练的模糊对时发生的错误传播。结合所有组件，作者提出的方法在PRVR中证明了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Partially Relevant Video Retrieval~(PRVR) aims to retrieve a video where aspecific segment is relevant to a given text query. Typical training processesof PRVR assume a one-to-one relationship where each text query is relevant toonly one video. However, we point out the inherent ambiguity between text andvideo content based on their conceptual scope and propose a framework thatincorporates this ambiguity into the model learning process. Specifically, wepropose Ambiguity-Restrained representation Learning~(ARL) to address ambiguoustext-video pairs. Initially, ARL detects ambiguous pairs based on two criteria:uncertainty and similarity. Uncertainty represents whether instances includecommonly shared context across the dataset, while similarity indicatespair-wise semantic overlap. Then, with the detected ambiguous pairs, our ARLhierarchically learns the semantic relationship via multi-positive contrastivelearning and dual triplet margin loss. Additionally, we delve into fine-grainedrelationships within the video instances. Unlike typical training at thetext-video level, where pairwise information is provided, we address theinherent ambiguity within frames of the same untrimmed video, which oftencontains multiple contexts. This allows us to further enhance learning at thetext-frame level. Lastly, we propose cross-model ambiguity detection tomitigate the error propagation that occurs when a single model is employed todetect ambiguous pairs for its training. With all components combined, ourproposed method demonstrates its effectiveness in PRVR.</description>
      <author>example@mail.com (CH Cho, WJ Moon, W Jun, MS Jung, JP Heo)</author>
      <guid isPermaLink="false">2506.07471v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SpikeSMOKE: Spiking Neural Networks for Monocular 3D Object Detection with Cross-Scale Gated Coding</title>
      <link>http://arxiv.org/abs/2506.07737v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种低功耗的3D物体检测方法，通过使用脉冲神经网络（SNNs）和改进的SpikeSMOKE架构，实现了在减少能耗的同时保持较高的检测性能。&lt;h4&gt;背景&lt;/h4&gt;随着3D物体检测在自动驾驶等领域的广泛应用，其能耗问题日益突出，因此降低能耗成为研究的重要方向。&lt;h4&gt;目的&lt;/h4&gt;设计一种低功耗的3D物体检测方法，以应对自动驾驶等应用场景中的能耗挑战。&lt;h4&gt;方法&lt;/h4&gt;1. 应用SNNs进行单目3D物体检测；2. 提出SpikeSMOKE架构；3. 设计交叉尺度门控编码机制（CSGC）以增强特征表示能力；4. 提出轻量级残差块以减少计算量和提高训练速度。&lt;h4&gt;主要发现&lt;/h4&gt;与基准SpikeSMOKE相比，改进的SpikeSMOKE在KITTI自动驾驶数据集上实现了更高的检测性能，同时在能耗上降低了72.2%，而检测性能仅降低了4%。SpikeSMOKE-L进一步减少了参数量和计算量。&lt;h4&gt;结论&lt;/h4&gt;SNNs在3D物体检测中具有降低能耗的潜力，通过改进的架构和机制可以同时提升检测性能和降低能耗。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low energy consumption for 3D object detection is an important research areabecause of the increasing energy consumption with their wide application infields such as autonomous driving. The spiking neural networks (SNNs) withlow-power consumption characteristics can provide a novel solution for thisresearch. Therefore, we apply SNNs to monocular 3D object detection and proposethe SpikeSMOKE architecture in this paper, which is a new attempt for low-powermonocular 3D object detection. As we all know, discrete signals of SNNs willgenerate information loss and limit their feature expression ability comparedwith the artificial neural networks (ANNs).In order to address this issue,inspired by the filtering mechanism of biological neuronal synapses, we proposea cross-scale gated coding mechanism(CSGC), which can enhance featurerepresentation by combining cross-scale fusion of attentional methods and gatedfiltering mechanisms.In addition, to reduce the computation and increase thespeed of training, we present a novel light-weight residual block that canmaintain spiking computing paradigm and the highest possible detectionperformance. Compared to the baseline SpikeSMOKE under the 3D Object Detection,the proposed SpikeSMOKE with CSGC can achieve 11.78 (+2.82, Easy), 10.69 (+3.2,Moderate), and 10.48 (+3.17, Hard) on the KITTI autonomous driving dataset byAP|R11 at 0.7 IoU threshold, respectively. It is important to note that theresults of SpikeSMOKE can significantly reduce energy consumption compared tothe results on SMOKE. For example,the energy consumption can be reduced by72.2% on the hard category, while the detection performance is reduced by only4%. SpikeSMOKE-L (lightweight) can further reduce the amount of parameters by 3times and computation by 10 times compared to SMOKE.</description>
      <author>example@mail.com (Xuemei Chen, Huamin Wang, Hangchi Shen, Shukai Duan, Shiping Wen, Tingwen Huang)</author>
      <guid isPermaLink="false">2506.07737v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning</title>
      <link>http://arxiv.org/abs/2506.07619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了用于产量预测的全新数据集，这是首个用于机器学习基准测试的瞬态流动数据集，涵盖了1200多种工艺条件。数据集的构建克服了化学数据集通常难以获取的难题，并针对溶剂选择这一理论建模困难的任务，展示了回归算法、迁移学习、特征工程和主动学习在其中的应用。&lt;h4&gt;背景&lt;/h4&gt;机器学习在分子性质预测和反应逆合成中取得了显著成果，但化学数据集往往难以获得，因为它们需要数据清洗、对化学的深入了解，或者根本不可用。&lt;h4&gt;目的&lt;/h4&gt;提出一个用于产量预测的新数据集，为机器学习模型提供基准测试，并探索溶剂选择等任务。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含超过1200种工艺条件的瞬态流动数据集，通过实验设置采样大量连续工艺条件，以应对机器学习模型的新挑战。&lt;h4&gt;主要发现&lt;/h4&gt;数据集涵盖了溶剂选择等难以理论建模的任务，并展示了回归算法、迁移学习、特征工程和主动学习在其中的应用。&lt;h4&gt;结论&lt;/h4&gt;本文提出的数据集和机器学习应用为溶剂替代和可持续制造提供了重要应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：机器学习承诺要改变实验室化学的格局，在分子性质预测和反应逆合成方面取得了令人印象深刻的成果。然而，化学数据集通常难以获得，因为它们往往需要清洗、对化学的深入了解，或者根本不可用。在本文中，我们介绍了一个用于产量预测的新数据集，提供了首个用于机器学习基准测试的瞬态流动数据集，涵盖了1200多种工艺条件。虽然之前的数据库侧重于离散参数，但我们的实验设置使我们能够采样大量连续工艺条件，为机器学习模型带来了新的挑战。我们专注于溶剂选择，这是一个特别难以理论建模的任务，因此非常适合机器学习应用。我们展示了回归算法、迁移学习、特征工程和主动学习的基准测试，这些在溶剂替代和可持续制造方面有重要的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning has promised to change the landscape of laboratorychemistry, with impressive results in molecular property prediction andreaction retro-synthesis. However, chemical datasets are often inaccessible tothe machine learning community as they tend to require cleaning, thoroughunderstanding of the chemistry, or are simply not available. In this paper, weintroduce a novel dataset for yield prediction, providing the first-evertransient flow dataset for machine learning benchmarking, covering over 1200process conditions. While previous datasets focus on discrete parameters, ourexperimental set-up allow us to sample a large number of continuous processconditions, generating new challenges for machine learning models. We focus onsolvent selection, a task that is particularly difficult to model theoreticallyand therefore ripe for machine learning applications. We showcase benchmarkingfor regression algorithms, transfer-learning approaches, feature engineering,and active learning, with important applications towards solvent replacementand sustainable manufacturing.</description>
      <author>example@mail.com (Toby Boyne, Juan S. Campos, Becky D. Langdon, Jixiang Qing, Yilin Xie, Shiqiang Zhang, Calvin Tsay, Ruth Misener, Daniel W. Davies, Kim E. Jelfs, Sarah Boyall, Thomas M. Dixon, Linden Schrecker, Jose Pablo Folch)</author>
      <guid isPermaLink="false">2506.07619v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SurgBench: A Unified Large-Scale Benchmark for Surgical Video Analysis</title>
      <link>http://arxiv.org/abs/2506.07603v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SurgBench，一个统一的手术视频基准框架，包括预训练数据集SurgBench-P和评估基准SurgBench-E，旨在解决手术视频理解领域的数据稀缺问题。&lt;h4&gt;背景&lt;/h4&gt;手术视频理解对于实现自动化手术决策、技能评估和术后质量提升至关重要，但发展手术视频基础模型（FMs）受到大规模、多样化数据集缺乏的阻碍。&lt;h4&gt;目的&lt;/h4&gt;提出SurgBench框架，以解决手术视频理解领域的数据稀缺问题，并提高手术视频分析任务的性能。&lt;h4&gt;方法&lt;/h4&gt;构建了SurgBench-P预训练数据集和SurgBench-E评估基准，其中SurgBench-P包含22种手术程序和11个专业的5300万帧图像，SurgBench-E提供涵盖6个类别、72个细粒度任务的稳健评估。&lt;h4&gt;主要发现&lt;/h4&gt;现有视频FMs难以泛化到不同的手术视频分析任务，而基于SurgBench-P的预训练则显著提高了性能，并实现了对未见过的手术程序和模态的优越跨领域泛化。&lt;h4&gt;结论&lt;/h4&gt;SurgBench框架为手术视频理解领域提供了重要的数据资源和评估基准，有助于推动该领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：手术视频理解对于实现自动化手术决策、技能评估和术后质量提升至关重要。然而，开发手术视频基础模型（FMs）的进展受到大规模、多样化数据集缺乏的阻碍。在本文中，我们引入了SurgBench，这是一个统一的手术视频基准框架，包括预训练数据集SurgBench-P和评估基准SurgBench-E。SurgBench提供了对多样化手术场景的广泛覆盖，其中SurgBench-P包含22种手术程序和11个专业的5300万帧图像，SurgBench-E提供了涵盖6个类别、72个细粒度任务的稳健评估。广泛的实验表明，现有的视频FMs难以泛化到不同的手术视频分析任务，而基于SurgBench-P的预训练则显著提高了性能，并实现了对未见过的手术程序和模态的优越跨领域泛化。我们的数据集和代码可根据请求提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surgical video understanding is pivotal for enabling automated intraoperativedecision-making, skill assessment, and postoperative quality improvement.However, progress in developing surgical video foundation models (FMs) remainshindered by the scarcity of large-scale, diverse datasets for pretraining andsystematic evaluation. In this paper, we introduce \textbf{SurgBench}, aunified surgical video benchmarking framework comprising a pretraining dataset,\textbf{SurgBench-P}, and an evaluation benchmark, \textbf{SurgBench-E}.SurgBench offers extensive coverage of diverse surgical scenarios, withSurgBench-P encompassing 53 million frames across 22 surgical procedures and 11specialties, and SurgBench-E providing robust evaluation across six categories(phase classification, camera motion, tool recognition, disease diagnosis,action classification, and organ detection) spanning 72 fine-grained tasks.Extensive experiments reveal that existing video FMs struggle to generalizeacross varied surgical video analysis tasks, whereas pretraining on SurgBench-Pyields substantial performance improvements and superior cross-domaingeneralization to unseen procedures and modalities. Our dataset and code areavailable upon request.</description>
      <author>example@mail.com (Jianhui Wei, Zikai Xiao, Danyu Sun, Luqi Gong, Zongxin Yang, Zuozhu Liu, Jian Wu)</author>
      <guid isPermaLink="false">2506.07603v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds</title>
      <link>http://arxiv.org/abs/2506.07857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025. Code and data are available at:  https://github.com/vLAR-group/LogoSP&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了无监督3D语义分割问题，通过LogoSP方法从局部和全局点云特征中学习3D语义信息，实现了高度准确的语义伪标签生成，并在室内和室外数据集上取得了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的无监督3D语义分割方法通常通过学习每个点的局部特征和简单的分组策略来解决问题，但缺乏发现超出局部特征的额外语义先验的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为LogoSP的方法，用于从原始点云数据中无监督地学习3D语义信息。&lt;h4&gt;方法&lt;/h4&gt;LogoSP通过根据超点在频域中的全局模式进行分组来发现3D语义信息，从而生成用于训练分割网络的语义伪标签。&lt;h4&gt;主要发现&lt;/h4&gt;LogoSP在室内和室外数据集上超越了所有现有的无监督方法，实现了最先进的无监督3D语义分割性能。研究发现，所学习的全局模式真正代表了在训练过程中没有人类标签时的有意义3D语义。&lt;h4&gt;结论&lt;/h4&gt;LogoSP是一种有效的无监督3D语义分割方法，能够从无标签的原始点云数据中学习到有意义的3D语义信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the problem of unsupervised 3D semantic segmentation on raw pointclouds without needing human labels in training. Existing methods usuallyformulate this problem into learning per-point local features followed by asimple grouping strategy, lacking the ability to discover additional andpossibly richer semantic priors beyond local features. In this paper, weintroduce LogoSP to learn 3D semantics from both local and global pointfeatures. The key to our approach is to discover 3D semantic information bygrouping superpoints according to their global patterns in the frequencydomain, thus generating highly accurate semantic pseudo-labels for training asegmentation network. Extensive experiments on two indoor and an outdoordatasets show that our LogoSP surpasses all existing unsupervised methods bylarge margins, achieving the state-of-the-art performance for unsupervised 3Dsemantic segmentation. Notably, our investigation into the learned globalpatterns reveals that they truly represent meaningful 3D semantics in theabsence of human labels during training.</description>
      <author>example@mail.com (Zihui Zhang, Weisheng Dai, Hongtao Wen, Bo Yang)</author>
      <guid isPermaLink="false">2506.07857v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Residual Reweighted Conformal Prediction for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.07854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Residual Reweighted GNN (RR-GNN)，一种能够生成具有可证明边缘覆盖保证的最小预测集的框架，旨在解决高价值领域中图神经网络（GNNs）的不确定性量化问题。&lt;h4&gt;背景&lt;/h4&gt;尽管GNNs在建模关系数据方面表现出色，但在高价值领域中，由于未量化的不确定性，它们面临重大挑战。现有的符合性预测（CP）方法虽然提供统计覆盖保证，但通常产生过于保守的预测区间，无法考虑图异方差性和结构偏差。现有的残差重加权CP变体虽然解决了一些局限性，但忽略了图拓扑、特定集群的不确定性和通过重用训练集的风险数据泄露。&lt;h4&gt;目的&lt;/h4&gt;提出RR-GNN以解决上述问题，旨在提高预测性能，同时保持统计覆盖。&lt;h4&gt;方法&lt;/h4&gt;RR-GNN引入了三项主要创新：首先，使用图结构莫迪安CP将节点或边根据拓扑特征划分为社区，确保集群条件覆盖反映异质性；其次，使用残差自适应非一致性分数，通过在保留的校准集上训练次级GNN来估计特定任务的残差，动态调整预测区间；第三，采用交叉训练协议，交替优化主GNN和残差预测器，以防止信息泄露同时保持图依赖。&lt;h4&gt;主要发现&lt;/h4&gt;在包括节点分类、回归和边权重预测在内的15个真实世界图上的多样任务中验证了RR-GNN，与CP基线相比，RR-GNN在效率上优于最先进的方法，没有覆盖损失。&lt;h4&gt;结论&lt;/h4&gt;RR-GNN通过提供更精确的预测和避免信息泄露，为高价值领域中的GNNs应用提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) excel at modeling relational data but facesignificant challenges in high-stakes domains due to unquantified uncertainty.Conformal prediction (CP) offers statistical coverage guarantees, but existingmethods often produce overly conservative prediction intervals that fail toaccount for graph heteroscedasticity and structural biases. While residualreweighting CP variants address some of these limitations, they neglect graphtopology, cluster-specific uncertainties, and risk data leakage by reusingtraining sets. To address these issues, we propose Residual Reweighted GNN(RR-GNN), a framework designed to generate minimal prediction sets withprovable marginal coverage guarantees.  RR-GNN introduces three major innovations to enhance prediction performance.First, it employs Graph-Structured Mondrian CP to partition nodes or edges intocommunities based on topological features, ensuring cluster-conditionalcoverage that reflects heterogeneity. Second, it uses Residual-AdaptiveNonconformity Scores by training a secondary GNN on a held-out calibration setto estimate task-specific residuals, dynamically adjusting prediction intervalsaccording to node or edge uncertainty. Third, it adopts a Cross-TrainingProtocol, which alternates the optimization of the primary GNN and the residualpredictor to prevent information leakage while maintaining graph dependencies.We validate RR-GNN on 15 real-world graphs across diverse tasks, including nodeclassification, regression, and edge weight prediction. Compared to CPbaselines, RR-GNN achieves improved efficiency over state-of-the-art methods,with no loss of coverage.</description>
      <author>example@mail.com (Zheng Zhang, Jie Bao, Zhixin Zhou, Nicolo Colombo, Lixin Cheng, Rui Luo)</author>
      <guid isPermaLink="false">2506.07854v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Language-Vision Planner and Executor for Text-to-Visual Reasoning</title>
      <link>http://arxiv.org/abs/2506.07778v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VLAgent是一个AI系统，能够通过自动化过程创建易于理解的视觉推理计划，并实时执行每一步。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型和大型视觉模型的发展推动了多模态视觉-文本推理能力的快速进步，但现有的视觉语言模型（VLMs）存在泛化性能问题。&lt;h4&gt;目的&lt;/h4&gt;提出VLAgent，以提高视觉-文本推理的泛化性能。&lt;h4&gt;方法&lt;/h4&gt;VLAgent通过上下文学习微调LLM生成每项文本-视觉推理任务的逐步计划；在执行计划时，通过神经符号执行模块的逐步优化生成高置信度的推理结果。&lt;h4&gt;主要发现&lt;/h4&gt;VLAgent有三个独特的设计特点：通过上下文学习提高计划生成质量；设计语法-语义解析器来识别和纠正LLM生成的计划脚本中的逻辑错误；使用集成方法提高步执行器的泛化性能。&lt;h4&gt;结论&lt;/h4&gt;在四个视觉推理基准测试（GQA、MME、NLVR2、VQAv2）中，VLAgent相较于现有的VLMs和基于LLM的视觉组合方法（如ViperGPT和VisProg）实现了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;The advancement in large language models (LLMs) and large vision models has fueled the rapid progress in multi-modal visual-text reasoning capabilities. However, existing vision-language models (VLMs) to date suffer from generalization performance. Inspired by recent development in LLMs for visual reasoning, this paper presents VLAgent, an AI system that can create a step-by-step visual reasoning plan with an easy-to-understand script and execute each step of the plan in real time by integrating planning script with execution verifications via an automated process supported by VLAgent. In the task planning phase, VLAgent fine-tunes an LLM through in-context learning to generate a step-by-step planner for each user-submitted text-visual reasoning task. During the plan execution phase, VLAgent progressively refines the composition of neuro-symbolic executable modules to generate high-confidence reasoning results. VLAgent has three unique design characteristics: First, we improve the quality of plan generation through in-context learning, improving logic reasoning by reducing erroneous logic steps, incorrect programs, and LLM hallucinations. Second, we design a syntax-semantics parser to identify and correct additional logic errors of the LLM-generated planning script prior to launching the plan executor. Finally, we employ the ensemble method to improve the generalization performance of our step-executor. Extensive experiments with four visual reasoning benchmarks (GQA, MME, NLVR2, VQAv2) show that VLAgent achieves significant performance enhancement for multimodal text-visual reasoning applications, compared to the existing representative VLMs and LLM-based visual composition approaches like ViperGPT and VisProg, thanks to the novel optimization modules of VLAgent back-engine (SS-Parser, Plan Repairer, Output Verifiers). Code and data will be made available upon paper acceptance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advancement in large language models (LLMs) and large vision models hasfueled the rapid progress in multi-modal visual-text reasoning capabilities.However, existing vision-language models (VLMs) to date suffer fromgeneralization performance. Inspired by recent development in LLMs for visualreasoning, this paper presents VLAgent, an AI system that can create astep-by-step visual reasoning plan with an easy-to-understand script andexecute each step of the plan in real time by integrating planning script withexecution verifications via an automated process supported by VLAgent. In thetask planning phase, VLAgent fine-tunes an LLM through in-context learning togenerate a step-by-step planner for each user-submitted text-visual reasoningtask. During the plan execution phase, VLAgent progressively refines thecomposition of neuro-symbolic executable modules to generate high-confidencereasoning results. VLAgent has three unique design characteristics: First, weimprove the quality of plan generation through in-context learning, improvinglogic reasoning by reducing erroneous logic steps, incorrect programs, and LLMhallucinations. Second, we design a syntax-semantics parser to identify andcorrect additional logic errors of the LLM-generated planning script prior tolaunching the plan executor. Finally, we employ the ensemble method to improvethe generalization performance of our step-executor. Extensive experiments withfour visual reasoning benchmarks (GQA, MME, NLVR2, VQAv2) show that VLAgentachieves significant performance enhancement for multimodal text-visualreasoning applications, compared to the exiting representative VLMs and LLMbased visual composition approaches like ViperGPT and VisProg, thanks to thenovel optimization modules of VLAgent back-engine (SS-Parser, Plan Repairer,Output Verifiers). Code and data will be made available upon paper acceptance.</description>
      <author>example@mail.com (Yichang Xu, Gaowen Liu, Ramana Rao Kompella, Sihao Hu, Tiansheng Huang, Fatih Ilhan, Selim Furkan Tekin, Zachary Yahn, Ling Liu)</author>
      <guid isPermaLink="false">2506.07778v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Evidential Spectrum-Aware Contrastive Learning for OOD Detection in Dynamic Graphs</title>
      <link>http://arxiv.org/abs/2506.07417v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages,5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了动态图中的Out-of-distribution (OOD)检测问题，提出了一种基于证据深度学习（EDL）的OOD检测方法EviSEC，通过证据谱增强对比学习来提高OOD检测的准确性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;在安全敏感领域，动态图中的OOD检测变得尤为重要，但现有的OOD检测方法主要针对静态图，存在单点估计引起的偏差和方差较大，以及缺乏OOD训练数据导致的评分同质化等问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的OOD检测方法，旨在提高动态图中OOD检测的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;首先，通过证据深度学习的视角研究动态图中的OOD检测。具体地，提出EviSEC，通过证据谱增强对比学习来设计一个证据神经网络，并引入谱域增强模块生成OOD近似，以识别具有高OOD评分的模式。&lt;h4&gt;主要发现&lt;/h4&gt;EviSEC通过重新定义输出为后验Dirichlet分布，解释了输入的随机性，并能够生成具有高OOD评分的OOD近似，从而扩大ID和OOD数据之间的评分差距，缓解评分同质化问题。&lt;h4&gt;结论&lt;/h4&gt;在真实世界数据集上的实验表明，EviSEC能够有效地检测动态图中的OOD样本。&lt;h4&gt;翻译&lt;/h4&gt;Recently, Out-of-distribution (OOD) detection in dynamic graphs, which aims to identify whether incoming data deviates from the distribution of the in-distribution (ID) training set, has garnered considerable attention in security-sensitive fields. Current OOD detection paradigms primarily focus on static graphs and confront two critical challenges: i) high bias and high variance caused by single-point estimation, which makes the predictions sensitive to randomness in the data; ii) score homogenization resulting from the lack of OOD training data, where the model only learns ID-specific patterns, resulting in overall low OOD scores and a narrow score gap between ID and OOD data. To tackle these issues, we first investigate OOD detection in dynamic graphs through the lens of Evidential Deep Learning (EDL). Specifically, we propose EviSEC, an innovative and effective OOD detector via Evidential Spectrum-awarE Contrastive Learning. We design an evidential neural network to redefine the output as the posterior Dirichlet distribution, explaining the randomness of inputs through the uncertainty of distribution, which is overlooked by single-point estimation. Moreover, spectrum-areaugmentation module generates OOD approximations to identify patterns with high OOD scores, thereby widening the score gap between ID and OOD data and mitigating score homogenization. Extensive experiments on real-world datasets demonstrate that EviSAC effectively detects OOD samples in dynamic graphs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Out-of-distribution (OOD) detection in dynamic graphs, which aimsto identify whether incoming data deviates from the distribution of thein-distribution (ID) training set, has garnered considerable attention insecurity-sensitive fields. Current OOD detection paradigms primarily focus onstatic graphs and confront two critical challenges: i) high bias and highvariance caused by single-point estimation, which makes the predictionssensitive to randomness in the data; ii) score homogenization resulting fromthe lack of OOD training data, where the model only learns ID-specificpatterns, resulting in overall low OOD scores and a narrow score gap between IDand OOD data. To tackle these issues, we first investigate OOD detection indynamic graphs through the lens of Evidential Deep Learning (EDL).Specifically, we propose EviSEC, an innovative and effective OOD detector viaEvidential Spectrum-awarE Contrastive Learning. We design an evidential neuralnetwork to redefine the output as the posterior Dirichlet distribution,explaining the randomness of inputs through the uncertainty of distribution,which is overlooked by single-point estimation. Moreover, spectrum-awareaugmentation module generates OOD approximations to identify patterns with highOOD scores, thereby widening the score gap between ID and OOD data andmitigating score homogenization. Extensive experiments on real-world datasetsdemonstrate that EviSAC effectively detects OOD samples in dynamic graphs.</description>
      <author>example@mail.com (Nan Sun, Xixun Lin, Zhiheng Zhou, Yanmin Shang, Zhenlin Cheng, Yanan Cao)</author>
      <guid isPermaLink="false">2506.07417v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Flow-Anything: Learning Real-World Optical Flow Estimation from Large-Scale Single-view Images</title>
      <link>http://arxiv.org/abs/2506.07740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Flow-Anything的大规模数据生成框架，用于从现实世界的单视图图像中学习光流估计，旨在解决现实应用中的域差距和数据扩展限制。&lt;h4&gt;背景&lt;/h4&gt;光流估计是计算机视觉的一个关键子领域，但在实际应用中，由动画合成数据集训练的鲁棒性有限。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出Flow-Anything框架，旨在从现实世界的单视图图像中学习光流估计。&lt;h4&gt;方法&lt;/h4&gt;Flow-Anything框架采用两个有效步骤来促进数据扩展：第一步是将单视图图像转换为3D表示，第二步是开发一个对象无关的体积渲染模块和一个深度感知修复模块来模拟3D表示中的动态对象。&lt;h4&gt;主要发现&lt;/h4&gt;首次证明了从大规模现实世界图像生成光流训练数据的优势，在合成数据集上优于最先进的无监督方法和监督方法。&lt;h4&gt;结论&lt;/h4&gt;Flow-Anything模型作为基础模型，增强了各种下游视频任务的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：光流估计是计算机视觉的一个关键子领域，它是视频任务的基础。然而，由于训练数据集的合成动画性质，其实际应用的鲁棒性有限。这引入了当应用于现实世界应用时的域差距，并限制了数据扩展带来的好处。为了解决这些挑战，我们提出了Flow-Anything，这是一个大规模数据生成框架，旨在从现实世界的任何单视图图像中学习光流估计。我们采用两个有效步骤来使数据扩展变得可行。首先，我们使用先进的单目深度估计网络将单视图图像转换为3D表示。这使我们能够在虚拟摄像机下渲染光流和新的视图图像。其次，我们开发了一个对象无关的体积渲染模块和一个深度感知修复模块来模拟3D表示中的动态对象。这两个步骤使我们能够从大规模的单视图图像中生成用于训练的逼真数据集，即FA-Flow数据集。首次，我们证明了从大规模现实世界图像生成光流训练数据的优势，在合成数据集上优于最先进的无监督方法和监督方法。此外，我们的模型作为基础模型，增强了各种下游视频任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optical flow estimation is a crucial subfield of computer vision, serving asa foundation for video tasks. However, the real-world robustness is limited byanimated synthetic datasets for training. This introduces domain gaps whenapplied to real-world applications and limits the benefits of scaling updatasets. To address these challenges, we propose \textbf{Flow-Anything}, alarge-scale data generation framework designed to learn optical flow estimationfrom any single-view images in the real world. We employ two effective steps tomake data scaling-up promising. First, we convert a single-view image into a 3Drepresentation using advanced monocular depth estimation networks. This allowsus to render optical flow and novel view images under a virtual camera. Second,we develop an Object-Independent Volume Rendering module and a Depth-AwareInpainting module to model the dynamic objects in the 3D representation. Thesetwo steps allow us to generate realistic datasets for training from large-scalesingle-view images, namely \textbf{FA-Flow Dataset}. For the first time, wedemonstrate the benefits of generating optical flow training data fromlarge-scale real-world images, outperforming the most advanced unsupervisedmethods and supervised methods on synthetic datasets. Moreover, our modelsserve as a foundation model and enhance the performance of various downstreamvideo tasks.</description>
      <author>example@mail.com (Yingping Liang, Ying Fu, Yutao Hu, Wenqi Shao, Jiaming Liu, Debing Zhang)</author>
      <guid isPermaLink="false">2506.07740v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Taking Flight with Dialogue: Enabling Natural Language Control for PX4-based Drone Agent</title>
      <link>http://arxiv.org/abs/2506.07509v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Source code available at:  https://github.com/limshoonkit/ros2-agent-ws&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种开源的智能框架，用于自然语言控制无人机，并在仿真和定制多旋翼平台上对其性能进行了评估。&lt;h4&gt;背景&lt;/h4&gt;目前，基于地面的人工智能技术主要集中在类人形和轮式机器人上，而空中机器人相对较少被探索。最先进的无人机多模态视觉-语言系统通常依赖于仅限于资源丰富的组织的闭源模型。&lt;h4&gt;目的&lt;/h4&gt;为了民主化无人机的自然语言控制，研究提出了一种开源的智能框架。&lt;h4&gt;方法&lt;/h4&gt;该框架集成了基于PX4的飞行控制、Robot Operating System 2 (ROS 2) 中间件和本地托管模型（使用Ollama）。研究在仿真环境和定制四旋翼平台上对性能进行了评估，比较了四种大型语言模型（LLM）在命令生成方面的表现和三种视觉-语言模型（VLM）在场景理解方面的表现。&lt;h4&gt;主要发现&lt;/h4&gt;在仿真和实际平台上的评估表明，该框架能够有效实现无人机对自然语言指令的理解和执行。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法和框架为无人机自然语言控制提供了新的可能性，有助于推广这项技术。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in agentic and physical artificial intelligence (AI) have largely focused on ground-based platforms such as humanoid and wheeled robots, leaving aerial robots relatively underexplored. Meanwhile, state-of-the-art unmanned aerial vehicle (UAV) multimodal vision-language systems typically rely on closed-source models accessible only to well-resourced organizations. To democratize natural language control of autonomous drones, we present an open-source agentic framework that integrates PX4-based flight control, Robot Operating System 2 (ROS 2) middleware, and locally hosted models using Ollama. We evaluate performance both in simulation and on a custom quadcopter platform, benchmarking four large language model (LLM) families for command generation and three vision-language model (VLM) families for scene understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in agentic and physical artificial intelligence (AI) havelargely focused on ground-based platforms such as humanoid and wheeled robots,leaving aerial robots relatively underexplored. Meanwhile, state-of-the-artunmanned aerial vehicle (UAV) multimodal vision-language systems typically relyon closed-source models accessible only to well-resourced organizations. Todemocratize natural language control of autonomous drones, we present anopen-source agentic framework that integrates PX4-based flight control, RobotOperating System 2 (ROS 2) middleware, and locally hosted models using Ollama.We evaluate performance both in simulation and on a custom quadcopter platform,benchmarking four large language model (LLM) families for command generationand three vision-language model (VLM) families for scene understanding.</description>
      <author>example@mail.com (Shoon Kit Lim, Melissa Jia Ying Chong, Jing Huey Khor, Ting Yang Ling)</author>
      <guid isPermaLink="false">2506.07509v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Multiple Object Stitching for Unsupervised Representation Learning</title>
      <link>http://arxiv.org/abs/2506.07364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MOS的简单而有效的方法，用于改进多对象图像的无监督表示。&lt;h4&gt;背景&lt;/h4&gt;对比学习在单对象中心图像的无监督表示方面取得了显著进展，但在具有多个对象的广泛图像上表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出MOS方法，以改进多对象图像的无监督表示，特别是在对象检测和语义分割等复杂下游任务中。&lt;h4&gt;方法&lt;/h4&gt;通过拼接单对象中心图像来构建多对象图像，从而在不需要人工标注的情况下提供多对象图像之间的额外对象对应关系。&lt;h4&gt;主要发现&lt;/h4&gt;在ImageNet、CIFAR和COCO数据集上的实验结果表明，该方法在单对象中心图像和多对象图像上均取得了领先的无监督表示性能。&lt;h4&gt;结论&lt;/h4&gt;MOS方法能够提供更详细的表示，有助于复杂的下游任务，并且代码可在https://github.com/visresearch/MultipleObjectStitching上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/visresearch/MultipleObjectStitching&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning for single object centric images has achieved remarkableprogress on unsupervised representation, but suffering inferior performance onthe widespread images with multiple objects. In this paper, we propose a simplebut effective method, Multiple Object Stitching (MOS), to refine theunsupervised representation for multi-object images. Specifically, we constructthe multi-object images by stitching the single object centric ones, where theobjects in the synthesized multi-object images are predetermined. Hence,compared to the existing contrastive methods, our method provides additionalobject correspondences between multi-object images without human annotations.In this manner, our method pays more attention to the representations of eachobject in multi-object image, thus providing more detailed representations forcomplicated downstream tasks, such as object detection and semanticsegmentation. Experimental results on ImageNet, CIFAR and COCO datasetsdemonstrate that our proposed method achieves the leading unsupervisedrepresentation performance on both single object centric images andmulti-object ones. The source code is available athttps://github.com/visresearch/MultipleObjectStitching.</description>
      <author>example@mail.com (Chengchao Shen, Dawei Liu, Jianxin Wang)</author>
      <guid isPermaLink="false">2506.07364v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SpatialLM: Training Large Language Models for Structured Indoor Modeling</title>
      <link>http://arxiv.org/abs/2506.07491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SpatialLM是一种处理3D点云数据并生成结构化3D场景理解输出的大型语言模型。&lt;h4&gt;背景&lt;/h4&gt;之前的方法通过特定的网络设计来处理任务，而SpatialLM遵循标准的多模态LLM架构，并直接从开源LLMs进行微调。&lt;h4&gt;目的&lt;/h4&gt;提升现代LLM的空间理解能力，应用于增强现实、实体机器人等领域。&lt;h4&gt;方法&lt;/h4&gt;收集了一个包含12,328个室内场景（54,778个房间）点云的大规模、高质量合成数据集，并对建模和训练决策进行了深入研究。&lt;h4&gt;主要发现&lt;/h4&gt;SpatialLM在布局估计方面表现出色，在3D物体检测方面也有竞争力。&lt;h4&gt;结论&lt;/h4&gt;SpatialLM为提升现代LLM的空间理解能力提供了一条可行的路径。&lt;h4&gt;翻译&lt;/h4&gt;SpatialLM是一种为处理3D点云数据并生成结构化的3D场景理解输出而设计的大型语言模型。与之前依赖特定网络设计的方法不同，我们的模型遵循标准的多模态LLM架构，并直接从开源LLMs进行微调。为了训练SpatialLM，我们收集了一个包含12,328个室内场景（54,778个房间）点云的大规模、高质量合成数据集，并对建模和训练决策进行了深入研究。在公共基准测试中，我们的模型在布局估计方面表现出色，在3D物体检测方面也有竞争力。据此，我们展示了一条增强现代LLM空间理解能力、适用于增强现实、实体机器人等应用的可行路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; SpatialLM is a large language model designed to process 3D point cloud dataand generate structured 3D scene understanding outputs. These outputs includearchitectural elements like walls, doors, windows, and oriented object boxeswith their semantic categories. Unlike previous methods which exploittask-specific network designs, our model adheres to the standard multimodal LLMarchitecture and is fine-tuned directly from open-source LLMs.  To train SpatialLM, we collect a large-scale, high-quality synthetic datasetconsisting of the point clouds of 12,328 indoor scenes (54,778 rooms) withground-truth 3D annotations, and conduct a careful study on various modelingand training decisions. On public benchmarks, our model gives state-of-the-artperformance in layout estimation and competitive results in 3D objectdetection. With that, we show a feasible path for enhancing the spatialunderstanding capabilities of modern LLMs for applications in augmentedreality, embodied robotics, and more.</description>
      <author>example@mail.com (Yongsen Mao, Junhao Zhong, Chuan Fang, Jia Zheng, Rui Tang, Hao Zhu, Ping Tan, Zihan Zhou)</author>
      <guid isPermaLink="false">2506.07491v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Flowing Datasets with Wasserstein over Wasserstein Gradient Flows</title>
      <link>http://arxiv.org/abs/2506.07534v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as an oral at ICML2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种处理机器学习中概率分布数据的创新方法，用于设计在概率分布上的可处理梯度流。&lt;h4&gt;背景&lt;/h4&gt;许多机器学习应用涉及以概率分布形式表示的数据，需要新的技术来设计在无限维对象上的可处理梯度流。&lt;h4&gt;目的&lt;/h4&gt;设计一种方法，能够处理标记数据集，应用于领域自适应、迁移学习或数据集蒸馏等任务。&lt;h4&gt;方法&lt;/h4&gt;提出用特征的条件分布来表示每个类别，并将数据集建模为支持在这些类别上的混合分布，这些类别本身也是概率分布。在空间中引入了最优传输的度量结构——Wasserstein over Wasserstein (WoW) 距离，并导出了空间上的微分结构，定义了WoW梯度流。&lt;h4&gt;主要发现&lt;/h4&gt;通过这种方法，可以设计出在空间上减少给定目标泛函的动力学。&lt;h4&gt;结论&lt;/h4&gt;将该方法应用于迁移学习和数据集蒸馏任务，利用梯度流构造以及基于Sliced-Wasserstein核的最大均值差异等新颖的可处理泛函。&lt;h4&gt;翻译&lt;/h4&gt;Many applications in machine learning involve data represented as probability distributions. The emergence of such data requires radically novel techniques to design tractable gradient flows on probability distributions over this type of (infinite-dimensional) objects. For instance, being able to flow labeled datasets is a core task for applications ranging from domain adaptation to transfer learning or dataset distillation. In this setting, we propose to represent each class by the associated conditional distribution of features, and to model the dataset as a mixture distribution supported on these classes (which are themselves probability distributions), meaning that labeled datasets can be seen as probability distributions over probability distributions. We endow this space with a metric structure from optimal transport, namely the Wasserstein over Wasserstein (WoW) distance, derive a differential structure on this space, and define WoW gradient flows. The latter enables to design dynamics over this space that decrease a given objective functional. We apply our framework to transfer learning and dataset distillation tasks, leveraging our gradient flow construction as well as novel tractable functionals that take the form of Maximum Mean Discrepancies with Sliced-Wasserstein based kernels between probability distributions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many applications in machine learning involve data represented as probabilitydistributions. The emergence of such data requires radically novel techniquesto design tractable gradient flows on probability distributions over this typeof (infinite-dimensional) objects. For instance, being able to flow labeleddatasets is a core task for applications ranging from domain adaptation totransfer learning or dataset distillation. In this setting, we propose torepresent each class by the associated conditional distribution of features,and to model the dataset as a mixture distribution supported on these classes(which are themselves probability distributions), meaning that labeled datasetscan be seen as probability distributions over probability distributions. Weendow this space with a metric structure from optimal transport, namely theWasserstein over Wasserstein (WoW) distance, derive a differential structure onthis space, and define WoW gradient flows. The latter enables to designdynamics over this space that decrease a given objective functional. We applyour framework to transfer learning and dataset distillation tasks, leveragingour gradient flow construction as well as novel tractable functionals that takethe form of Maximum Mean Discrepancies with Sliced-Wasserstein based kernelsbetween probability distributions.</description>
      <author>example@mail.com (Clément Bonet, Christophe Vauthier, Anna Korba)</author>
      <guid isPermaLink="false">2506.07534v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model Empowered Synesthesia of Machines (SoM): AI-native Intelligent Multi-Modal Sensing-Communication Integration</title>
      <link>http://arxiv.org/abs/2506.07647v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为“机器通感”（SoM）的新范式，用于支持未来智能多功能第六代（6G）无线通信网络，并针对现有SoM系统设计中的挑战，提出了基于基础模型（FMs）的系统设计框架。&lt;h4&gt;背景&lt;/h4&gt;现有的SoM系统设计依赖于特定任务的AI模型，面临数据集稀缺、建模能力受限、泛化能力差和通用性有限等问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于FMs的系统设计框架，以解决现有SoM系统设计中的挑战。&lt;h4&gt;方法&lt;/h4&gt;对FMs进行系统分类，包括通用FMs、大型语言模型（LLMs）和SoM领域特定FMs（无线基础模型）。提出了基于LLM和无线基础模型的设计路线图，并提供了设计框架和案例研究。&lt;h4&gt;主要发现&lt;/h4&gt;FMs在解决SoM系统中的现有挑战方面具有关键特性，并展示了相较于特定任务模型的优势。&lt;h4&gt;结论&lt;/h4&gt;本文总结了FMs在SoM系统设计中的应用潜力，并指出了未来研究的潜在方向。&lt;h4&gt;翻译&lt;/h4&gt;To support future intelligent multifunctional sixth-generation (6G) wireless communication networks, Synesthesia of Machines (SoM) is proposed as a new paradigm for artificial intelligence (AI)-native intelligent multi-modal sensing-communication integration. However, existing SoM system designs rely on task-specific AI models and face challenges such as scarcity of massive high-quality datasets, constrained modeling capability, poor generalization, and limited universality. Recently, foundation models (FMs) have emerged as a new deep learning paradigm and have been preliminarily applied to SoM-related tasks, but a systematic design framework is still lacking. In this paper, we for the first time present a systematic categorization of FMs for SoM system design, dividing them into general-purpose FMs, specifically large language models (LLMs), and SoM domain-specific FMs, referred to as wireless foundation models. Furthermore, we derive key characteristics of FMs in addressing existing challenges in SoM systems and propose two corresponding roadmaps, i.e., LLM-based and wireless foundation model-based design. For each roadmap, we provide a framework containing key design steps as a guiding pipeline and several representative case studies of FM-empowered SoM system design. Specifically, we propose LLM-based path loss generation (LLM4PG) and scatterer generation (LLM4SG) schemes, and wireless channel foundation model (WiCo) for SoM mechanism exploration, LLM-based wireless multi-task SoM transceiver (LLM4WM) and wireless foundation model (WiFo) for SoM-enhanced transceiver design, and wireless cooperative perception foundation model (WiPo) for SoM-enhanced cooperative perception, demonstrating the significant superiority of FMs over task-specific models. Finally, we summarize and highlight potential directions for future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To support future intelligent multifunctional sixth-generation (6G) wirelesscommunication networks, Synesthesia of Machines (SoM) is proposed as a novelparadigm for artificial intelligence (AI)-native intelligent multi-modalsensing-communication integration. However, existing SoM system designs rely ontask-specific AI models and face challenges such as scarcity of massivehigh-quality datasets, constrained modeling capability, poor generalization,and limited universality. Recently, foundation models (FMs) have emerged as anew deep learning paradigm and have been preliminarily applied to SoM-relatedtasks, but a systematic design framework is still lacking. In this paper, wefor the first time present a systematic categorization of FMs for SoM systemdesign, dividing them into general-purpose FMs, specifically large languagemodels (LLMs), and SoM domain-specific FMs, referred to as wireless foundationmodels. Furthermore, we derive key characteristics of FMs in addressingexisting challenges in SoM systems and propose two corresponding roadmaps,i.e., LLM-based and wireless foundation model-based design. For each roadmap,we provide a framework containing key design steps as a guiding pipeline andseveral representative case studies of FM-empowered SoM system design.Specifically, we propose LLM-based path loss generation (LLM4PG) and scatterergeneration (LLM4SG) schemes, and wireless channel foundation model (WiCo) forSoM mechanism exploration, LLM-based wireless multi-task SoM transceiver(LLM4WM) and wireless foundation model (WiFo) for SoM-enhanced transceiverdesign, and wireless cooperative perception foundation model (WiPo) forSoM-enhanced cooperative perception, demonstrating the significant superiorityof FMs over task-specific models. Finally, we summarize and highlight potentialdirections for future research.</description>
      <author>example@mail.com (Xiang Cheng, Boxun Liu, Xuanyu Liu, Ensong Liu, Ziwei Huang)</author>
      <guid isPermaLink="false">2506.07647v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding</title>
      <link>http://arxiv.org/abs/2506.07600v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SceneRAG是一种统一的框架，通过结合大型语言模型处理视频中的ASR转写和时序元数据，将视频分割成与叙事一致的场景，从而有效理解长视频内容。&lt;h4&gt;背景&lt;/h4&gt;尽管检索增强生成（RAG）在视频理解方面取得了进展，但长视频内容的有效理解仍因视频数据的规模和复杂性而未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为SceneRAG的框架，以实现长视频内容的有效理解。&lt;h4&gt;方法&lt;/h4&gt;SceneRAG通过处理ASR转写和时序元数据将视频分割成场景，并使用轻量级启发式方法和迭代校正来细化场景边界。每个场景通过融合视觉和文本信息来提取实体关系，并动态构建知识图，实现多跳检索和生成。&lt;h4&gt;主要发现&lt;/h4&gt;在LongerVideos基准测试中，SceneRAG在生成任务上的胜率达到72.5%，显著优于先前基线。&lt;h4&gt;结论&lt;/h4&gt;SceneRAG能够有效地理解长视频内容，并在视频理解任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;尽管最近在视频理解方面检索增强生成（RAG）取得了进展，但由于视频数据的规模和复杂性，有效理解长视频内容仍然未得到充分探索。当前的RAG方法通常将视频分割成固定长度的片段，这往往破坏了上下文信息的连续性，并且无法捕捉到真实的场景边界。受人类将连续经验自然组织成连贯场景的能力的启发，我们提出了一种统一的框架，名为SceneRAG，该框架利用大型语言模型通过处理ASR转录本和时序元数据将视频分割成叙事一致的场景。SceneRAG还通过轻量级启发式方法和迭代校正进一步细化这些初始边界。对于每个场景，该框架融合来自视觉和文本模态的信息来提取实体关系，并动态构建知识图，从而实现考虑长距离依赖关系的稳健的多跳检索和生成。在LongerVideos基准测试中的实验，包含超过134小时的多样化内容，证实SceneRAG在生成任务上的胜率高达72.5%，显著优于先前基线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite recent advances in retrieval-augmented generation (RAG) for videounderstanding, effectively understanding long-form video content remainsunderexplored due to the vast scale and high complexity of video data. CurrentRAG approaches typically segment videos into fixed-length chunks, which oftendisrupts the continuity of contextual information and fails to captureauthentic scene boundaries. Inspired by the human ability to naturally organizecontinuous experiences into coherent scenes, we present SceneRAG, a unifiedframework that leverages large language models to segment videos intonarrative-consistent scenes by processing ASR transcripts alongside temporalmetadata. SceneRAG further sharpens these initial boundaries throughlightweight heuristics and iterative correction. For each scene, the frameworkfuses information from both visual and textual modalities to extract entityrelations and dynamically builds a knowledge graph, enabling robust multi-hopretrieval and generation that account for long-range dependencies. Experimentson the LongerVideos benchmark, featuring over 134 hours of diverse content,confirm that SceneRAG substantially outperforms prior baselines, achieving awin rate of up to 72.5 percent on generation tasks.</description>
      <author>example@mail.com (Nianbo Zeng, Haowen Hou, Fei Richard Yu, Si Shi, Ying Tiffany He)</author>
      <guid isPermaLink="false">2506.07600v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Variational Supervised Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.07413v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;对比学习在塑造不同模态的表示空间方面表现出高效和适应性，但存在两个主要限制。为了解决这些问题，提出了变分监督对比学习（VarCon），该学习通过变分推理和最大化后验加权证据下界（ELBO）来改进对比学习。&lt;h4&gt;背景&lt;/h4&gt;对比学习通过拉近相似样本和推开不同样本来塑造表示空间，但在没有显式调节嵌入分布的情况下，语义相关的实例可能会被无意中推开。此外，过度依赖大批次负样本和定制增强也阻碍了泛化。&lt;h4&gt;目的&lt;/h4&gt;提出VarCon来克服对比学习的限制，包括避免语义相关实例被推开，以及减少对大批次负样本和定制增强的依赖。&lt;h4&gt;方法&lt;/h4&gt;VarCon将监督对比学习重新定义为对潜在类变量的变分推理，并最大化后验加权证据下界（ELBO），以实现高效的类感知匹配和控制嵌入空间中的类内分散。&lt;h4&gt;主要发现&lt;/h4&gt;VarCon在CIFAR-10、CIFAR-100、ImageNet-100和ImageNet-1K上的实验表明，VarCon在对比学习框架中实现了最先进的性能，同时在图像数据上仅用200个epoch就收敛；它产生了更清晰的决策边界和语义组织；在少样本学习中优于监督基线，并且在各种增强策略下表现出更强的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;VarCon是一种有效的对比学习方法，能够显著提高性能，并具有更好的泛化能力和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning has proven to be highly efficient and adaptable inshaping representation spaces across diverse modalities by pulling similarsamples together and pushing dissimilar ones apart. However, two keylimitations persist: (1) Without explicit regulation of the embeddingdistribution, semantically related instances can inadvertently be pushed apartunless complementary signals guide pair selection, and (2) excessive relianceon large in-batch negatives and tailored augmentations hinders generalization.To address these limitations, we propose Variational Supervised ContrastiveLearning (VarCon), which reformulates supervised contrastive learning asvariational inference over latent class variables and maximizes aposterior-weighted evidence lower bound (ELBO) that replaces exhaustivepair-wise comparisons for efficient class-aware matching and grantsfine-grained control over intra-class dispersion in the embedding space.Trained exclusively on image data, our experiments on CIFAR-10, CIFAR-100,ImageNet-100, and ImageNet-1K show that VarCon (1) achieves state-of-the-artperformance for contrastive learning frameworks, reaching 79.36% Top-1 accuracyon ImageNet-1K and 78.29% on CIFAR-100 with a ResNet-50 encoder whileconverging in just 200 epochs; (2) yields substantially clearer decisionboundaries and semantic organization in the embedding space, as evidenced byKNN classification, hierarchical clustering results, and transfer-learningassessments; and (3) demonstrates superior performance in few-shot learningthan supervised baseline and superior robustness across various augmentationstrategies.</description>
      <author>example@mail.com (Ziwen Wang, Jiajun Fan, Thao Nguyen, Heng Ji, Ge Liu)</author>
      <guid isPermaLink="false">2506.07413v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning and Explainable AI for Brain Tumor Classification: A Study Using MRI Data from Bangladesh</title>
      <link>http://arxiv.org/abs/2506.07228v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2024 6th International Conference on Sustainable Technologies for  Industry 5.0 (STI)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究旨在解决脑肿瘤诊断问题，通过创建一个利用孟加拉国多医院MRI数据的自动脑肿瘤分类系统，结合深度学习模型和可解释人工智能方法，提高脑肿瘤检测和识别的准确性。&lt;h4&gt;背景&lt;/h4&gt;脑肿瘤，无论良性还是恶性，都存在很大的健康风险，恶性肿瘤由于其快速和不受控制的增殖而更加危险。在医疗基础设施有限的地区，如孟加拉国，及时诊断至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一个自动化的脑肿瘤分类系统，以提高诊断效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;使用VGG16、VGG19和ResNet50等深度学习模型对脑瘤、脑膜瘤和多种脑癌进行分类。采用Grad-CAM和Grad-CAM++等可解释人工智能方法来增强模型的可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;VGG16模型达到了99.17%的准确率。集成可解释人工智能（XAI）方法提高了系统的透明度和稳定性。&lt;h4&gt;结论&lt;/h4&gt;深度学习模型与可解释人工智能的结合，在资源有限的环境中，如孟加拉国，能够有效提高脑肿瘤的检测和识别。&lt;h4&gt;翻译&lt;/h4&gt;This study aims to address the issue of brain tumor diagnosis by developing an automated brain tumor classification system using MRI data obtained from many hospitals in Bangladesh, combining deep learning models with explainable artificial intelligence (XAI) methods to enhance the accuracy of brain tumor detection and identification.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/STI64222.2024.10951092&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain tumors, regardless of being benign or malignant, pose considerablehealth risks, with malignant tumors being more perilous due to their swift anduncontrolled proliferation, resulting in malignancy. Timely identification iscrucial for enhancing patient outcomes, particularly in nations such asBangladesh, where healthcare infrastructure is constrained. Manual MRI analysisis arduous and susceptible to inaccuracies, rendering it inefficient for promptdiagnosis. This research sought to tackle these problems by creating anautomated brain tumor classification system utilizing MRI data obtained frommany hospitals in Bangladesh. Advanced deep learning models, including VGG16,VGG19, and ResNet50, were utilized to classify glioma, meningioma, and variousbrain cancers. Explainable AI (XAI) methodologies, such as Grad-CAM andGrad-CAM++, were employed to improve model interpretability by emphasizing thecritical areas in MRI scans that influenced the categorization. VGG16 achievedthe most accuracy, attaining 99.17%. The integration of XAI enhanced thesystem's transparency and stability, rendering it more appropriate for clinicalapplication in resource-limited environments such as Bangladesh. This studyhighlights the capability of deep learning models, in conjunction withexplainable artificial intelligence (XAI), to enhance brain tumor detection andidentification in areas with restricted access to advanced medicaltechnologies.</description>
      <author>example@mail.com (Shuvashis Sarker)</author>
      <guid isPermaLink="false">2506.07228v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Return of ChebNet: Understanding and Improving an Overlooked GNN on Long Range Tasks</title>
      <link>http://arxiv.org/abs/2506.07624v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文重新审视了ChebNet，一种早期的光谱图神经网络，并提出了Stable-ChebNet，一种稳定的ChebNet模型，以解决其训练过程中的不稳定性问题。&lt;h4&gt;背景&lt;/h4&gt;ChebNet最初被MPNNs的简单性和有效性所掩盖，MPNNs在捕捉局部图结构方面表现出色，但它们在捕捉节点之间的长距离依赖关系方面有限。&lt;h4&gt;目的&lt;/h4&gt;通过重新审视ChebNet，研究其建模节点间远程交互的能力，并解决其训练过程中的不稳定性问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的稳定模型Stable-ChebNet，该模型允许稳定的信息传播，并具有可控的动态特性，不需要使用特征分解、位置编码或图重连。&lt;h4&gt;主要发现&lt;/h4&gt;Stable-ChebNet在长距离基准测试中相对于经典的MPNNs和GTs表现出竞争力，同时保持了高阶多项式良好的可扩展性。此外，Stable-ChebNet在多个基准测试中实现了接近最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;Stable-ChebNet是一种稳定的图神经网络模型，能够有效地建模节点间的远程交互，并在多个基准测试中表现出优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;ChebNet is one of the earliest spectral GNNs and has been largely overshadowed by Message Passing Neural Networks (MPNNs), which are popular for their simplicity and effectiveness in capturing local graph structure. Despite their success, MPNNs are limited in their ability to capture long-range dependencies between nodes. This has led researchers to adapt MPNNs through rewiring or make use of Graph Transformers, which compromises the computational efficiency that characterized early spatial message-passing architectures and typically disregards the graph structure. Almost a decade after its original introduction, we revisit ChebNet to shed light on its ability to model distant node interactions. We find that out-of-box, ChebNet already shows competitive advantages relative to classical MPNNs and GTs on long-range benchmarks, while maintaining good scalability properties for high-order polynomials. However, we uncover that this polynomial expansion leads ChebNet to an unstable regime during training. To address this limitation, we cast ChebNet as a stable and non-dissipative dynamical system, which we coin Stable-ChebNet. Our Stable-ChebNet model allows for stable information propagation and has controllable dynamics which do not require the use of eigendecompositions, positional encodings, or graph rewiring. Across several benchmarks, Stable-ChebNet achieves near state-of-the-art performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; ChebNet, one of the earliest spectral GNNs, has largely been overshadowed byMessage Passing Neural Networks (MPNNs), which gained popularity for theirsimplicity and effectiveness in capturing local graph structure. Despite theirsuccess, MPNNs are limited in their ability to capture long-range dependenciesbetween nodes. This has led researchers to adapt MPNNs through rewiring or makeuse of Graph Transformers, which compromises the computational efficiency thatcharacterized early spatial message-passing architectures, and typicallydisregards the graph structure. Almost a decade after its originalintroduction, we revisit ChebNet to shed light on its ability to model distantnode interactions. We find that out-of-box, ChebNet already shows competitiveadvantages relative to classical MPNNs and GTs on long-range benchmarks, whilemaintaining good scalability properties for high-order polynomials. However, weuncover that this polynomial expansion leads ChebNet to an unstable regimeduring training. To address this limitation, we cast ChebNet as a stable andnon-dissipative dynamical system, which we coin Stable-ChebNet. OurStable-ChebNet model allows for stable information propagation, and hascontrollable dynamics which do not require the use of eigendecompositions,positional encodings, or graph rewiring. Across several benchmarks,Stable-ChebNet achieves near state-of-the-art performance.</description>
      <author>example@mail.com (Ali Hariri, Álvaro Arroyo, Alessio Gravina, Moshe Eliasof, Carola-Bibiane Schönlieb, Davide Bacciu, Kamyar Azizzadenesheli, Xiaowen Dong, Pierre Vandergheynst)</author>
      <guid isPermaLink="false">2506.07624v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Drive Any Mesh: 4D Latent Diffusion for Mesh Deformation from Video</title>
      <link>http://arxiv.org/abs/2506.07489v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了DriveAnyMesh方法，用于通过单目视频驱动网格。&lt;h4&gt;背景&lt;/h4&gt;当前4D生成技术在现代渲染引擎中面临挑战，隐式方法渲染效率低，不友好于基于光栅化的引擎，而骨骼方法需要大量手动工作且缺乏跨类别泛化能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一种4D扩散模型，用于去噪潜在集合序列，然后从点云轨迹序列解码生成网格动画。&lt;h4&gt;方法&lt;/h4&gt;这些潜在集合利用基于transformer的变分自编码器，同时捕捉3D形状和运动信息。通过使用时空的、基于transformer的扩散模型，信息在多个潜在帧之间交换，增强了生成结果的效率和泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，DriveAnyMesh可以快速生成高质量动画，且与现代渲染引擎兼容。&lt;h4&gt;结论&lt;/h4&gt;该方法在游戏和电影行业中具有潜在应用价值。&lt;h4&gt;翻译&lt;/h4&gt;We propose DriveAnyMesh, a method for driving mesh guided by monocular video. Current 4D generation techniques encounter challenges with modern rendering engines. Implicit methods have low rendering efficiency and are unfriendly torasterization-based engines, while skeletal methods demand significant manualeffort and lack cross-category generalization. Animating existing 3D assets, instead of creating 4D assets from scratch, demands a deep understanding of the input's 3D structure. To tackle these challenges, we present a 4D diffusion model that denoises sequences of latent sets, which are then decoded to producemesh animations from point cloud trajectory sequences. These latent sets leverage a transformer-based variational autoencoder, simultaneously capturing 3D shape and motion information. By employing a spatiotemporal, transformer-based diffusion model, information is exchanged across multiple latent frames, enhancing the efficiency and generalization of the generated results. Our experimental results demonstrate that DriveAnyMesh can rapidly produce high-quality animations for complex motions and is compatible with modern rendering engines. This method holds potential for applications in both the gaming and filming industries.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose DriveAnyMesh, a method for driving mesh guided by monocular video.Current 4D generation techniques encounter challenges with modern renderingengines. Implicit methods have low rendering efficiency and are unfriendly torasterization-based engines, while skeletal methods demand significant manualeffort and lack cross-category generalization. Animating existing 3D assets,instead of creating 4D assets from scratch, demands a deep understanding of theinput's 3D structure. To tackle these challenges, we present a 4D diffusionmodel that denoises sequences of latent sets, which are then decoded to producemesh animations from point cloud trajectory sequences. These latent setsleverage a transformer-based variational autoencoder, simultaneously capturing3D shape and motion information. By employing a spatiotemporal,transformer-based diffusion model, information is exchanged across multiplelatent frames, enhancing the efficiency and generalization of the generatedresults. Our experimental results demonstrate that DriveAnyMesh can rapidlyproduce high-quality animations for complex motions and is compatible withmodern rendering engines. This method holds potential for applications in boththe gaming and filming industries.</description>
      <author>example@mail.com (Yahao Shi, Yang Liu, Yanmin Wu, Xing Liu, Chen Zhao, Jie Luo, Bin Zhou)</author>
      <guid isPermaLink="false">2506.07489v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Text-Attributed Graph Learning through Selective Annotation and Graph Alignment</title>
      <link>http://arxiv.org/abs/2506.07168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GAGA的框架，用于高效学习文本属性图（TAGs）中的节点表示，通过标注代表性节点和边来减少标注时间和成本，同时通过两级行为模块有效整合标注图与TAG，提高分类准确率。&lt;h4&gt;背景&lt;/h4&gt;传统的图神经网络（GNNs）在处理文本属性图（TAGs）时往往表现不佳，因为每个节点都关联着复杂的文本信息。&lt;h4&gt;目的&lt;/h4&gt;克服传统方法在标注时间和成本上的不足，提高节点表示的效率。&lt;h4&gt;方法&lt;/h4&gt;GAGA通过以下方式实现其目的：1. 仅标注代表性节点和边，减少标注时间和成本；2. 构建标注图以捕捉这些标注之间的拓扑关系；3. 采用两级行为模块，将标注图与TAG进行有效整合，对齐其底层结构。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，GAGA在分类准确率上与或超过现有最佳方法，同时仅需标注1%的数据，显示出其高效率。&lt;h4&gt;结论&lt;/h4&gt;GAGA是一种高效且准确的框架，用于学习文本属性图中的节点表示，为处理此类数据提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;在文本属性图（TAGs）领域，传统的图神经网络（GNNs）由于每个节点关联的复杂文本信息而表现不佳。最近的方法通过利用大型语言模型（LLMs）来增强节点文本特征，提高了节点表示，但这些方法通常需要大量的标注或在所有节点上进行微调，这既耗时又昂贵。为了克服这些挑战，我们引入了GAGA，这是一种用于TAG表示学习的有效框架。GAGA通过仅关注标注代表性节点和边来减少标注时间和成本。它构建了一个标注图，捕捉这些标注之间的拓扑关系。此外，GAGA采用一个两级行为模块，有效地将标注图与TAG整合，对齐它们的底层结构。实验表明，GAGA在分类准确率上与或超过现有最佳方法，同时仅需标注1%的数据，证明了其高效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the realm of Text-attributed Graphs (TAGs), traditional graph neuralnetworks (GNNs) often fall short due to the complex textual informationassociated with each node. Recent methods have improved node representations byleveraging large language models (LLMs) to enhance node text features, butthese approaches typically require extensive annotations or fine-tuning acrossall nodes, which is both time-consuming and costly. To overcome thesechallenges, we introduce GAGA, an efficient framework for TAG representationlearning. GAGA reduces annotation time and cost by focusing on annotating onlyrepresentative nodes and edges. It constructs an annotation graph that capturesthe topological relationships among these annotations. Furthermore, GAGAemploys a two-level alignment module to effectively integrate the annotationgraph with the TAG, aligning their underlying structures. Experiments show thatGAGA achieves classification accuracies on par with or surpassingstate-of-the-art methods while requiring only 1% of the data to be annotated,demonstrating its high efficiency.</description>
      <author>example@mail.com (Huanyi Xie, Lijie Hu, Lu Yu, Tianhao Huang, Longfei Li, Meng Li, Jun Zhou, Huan Wang, Di Wang)</author>
      <guid isPermaLink="false">2506.07168v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>HeTa: Relation-wise Heterogeneous Graph Foundation Attack Model</title>
      <link>http://arxiv.org/abs/2506.07428v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的关系感知异构图基础攻击模型HeTa，用于评估异构图神经网络（HGNNs）的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的HGNN攻击方法通常需要复杂的参数重训练来生成特定场景的扰动，且HGNNs容易受到针对的攻击。&lt;h4&gt;目的&lt;/h4&gt;设计一个适用于HGNNs的基础攻击模型，能够实现不同HGNNs之间的泛化扰动，并快速适应新的异构图。&lt;h4&gt;方法&lt;/h4&gt;通过挖掘共享攻击单元设计攻击准则，引入基础代理模型来对齐异质性和识别共享关系感知攻击单元的重要性，并基于此实现关系级别的序列化攻击。&lt;h4&gt;主要发现&lt;/h4&gt;尽管HGNNs在模型设计和参数空间上存在显著差异，但从关系感知的角度来看，它们却共享一些常见的脆弱性模式。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，该方法具有强大的攻击性能和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Heterogeneous Graph Neural Networks (HGNNs) are vulnerable, highlighting the need for tailored attacks to assess their robustness and ensure security. However, existing HGNN attacks often require complex retraining of parameters to generate specific perturbations for new scenarios. Recently, foundation models have opened new horizons for the generalization of graph neural networks by capturing shared semantics across various graph distributions. This leads us to ask: Can we design a foundation attack model for HGNNs that enables generalizable perturbations across different HGNNs, and quickly adapts to new heterogeneous graphs (HGs)? Empirical findings reveal that, despite significant differences in model design and parameter space, different HGNNs surprisingly share common vulnerability patterns from a relation-aware perspective. Therefore, we explore how to design foundation HGNN attack criteria by mining shared attack units. In this paper, we propose a novel relation-wise heterogeneous graph foundation attack model, HeTa. We introduce a foundation surrogate model to align heterogeneity and identify the importance of shared relation-aware attack units. Building on this, we implement a serialized relation-by-relation attack based on the identified relational weights. In this way, the perturbation can be transferred to various target HGNNs and easily fine-tuned for new HGs. Extensive experiments exhibit powerful attack performances and generalizability of our method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterogeneous Graph Neural Networks (HGNNs) are vulnerable, highlighting theneed for tailored attacks to assess their robustness and ensure security.However, existing HGNN attacks often require complex retraining of parametersto generate specific perturbations for new scenarios. Recently, foundationmodels have opened new horizons for the generalization of graph neural networksby capturing shared semantics across various graph distributions. This leads usto ask:Can we design a foundation attack model for HGNNs that enablesgeneralizable perturbations across different HGNNs, and quickly adapts to newheterogeneous graphs (HGs)? Empirical findings reveal that, despite significantdifferences in model design and parameter space, different HGNNs surprisinglyshare common vulnerability patterns from a relation-aware perspective.Therefore, we explore how to design foundation HGNN attack criteria by miningshared attack units. In this paper, we propose a novel relation-wiseheterogeneous graph foundation attack model, HeTa. We introduce a foundationsurrogate model to align heterogeneity and identify the importance of sharedrelation-aware attack units. Building on this, we implement a serializedrelation-by-relation attack based on the identified relational weights. In thisway, the perturbation can be transferred to various target HGNNs and easilyfine-tuned for new HGs. Extensive experiments exhibit powerful attackperformances and generalizability of our method.</description>
      <author>example@mail.com (Yuling Wang, Zihui Chen, Pengfei Jiao, Xiao Wang)</author>
      <guid isPermaLink="false">2506.07428v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>State Entropy Regularization for Robust Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.07085v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了状态熵正则化在强化学习中的应用，分析了其在提高鲁棒性方面的优势，并与策略熵正则化进行了对比。&lt;h4&gt;背景&lt;/h4&gt;状态熵正则化在强化学习中表现出良好的探索和样本复杂度，但其理论保证尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;验证状态熵正则化在提高鲁棒性方面的有效性，并与其他正则化方法进行比较。&lt;h4&gt;方法&lt;/h4&gt;通过分析状态熵正则化在处理结构性和空间相关扰动时的鲁棒性，以及与策略熵正则化的对比，提供了理论保证。&lt;h4&gt;主要发现&lt;/h4&gt;状态熵正则化能够提高对结构性和空间相关扰动的鲁棒性，并且比策略熵正则化在处理这类扰动时更敏感。&lt;h4&gt;结论&lt;/h4&gt;状态熵正则化是一种有效的强化学习方法，特别是在处理转移学习中的结构性扰动时，具有明显的优势。&lt;h4&gt;翻译&lt;/h4&gt;State entropy regularization has empirically shown better exploration and sample complexity in reinforcement learning (RL). However, its theoretical guarantees have not been studied. In this paper, we show that state entropy regularization improves robustness to structured and spatially correlated perturbations. These types of variation are common in transfer learning but often overlooked by standard robust RL methods, which typically focus on small, uncorrelated changes. We provide a comprehensive characterization of these robustness properties, including formal guarantees under reward and transition uncertainty, as well as settings where the method performs poorly. Much of our analysis contrasts state entropy with the widely used policy entropy regularization, highlighting their different benefits. Finally, from a practical standpoint, we illustrate that compared with policy entropy, the robustness advantages of state entropy are more sensitive to the number of rollouts used for policy evaluation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State entropy regularization has empirically shown better exploration andsample complexity in reinforcement learning (RL). However, its theoreticalguarantees have not been studied. In this paper, we show that state entropyregularization improves robustness to structured and spatially correlatedperturbations. These types of variation are common in transfer learning butoften overlooked by standard robust RL methods, which typically focus on small,uncorrelated changes. We provide a comprehensive characterization of theserobustness properties, including formal guarantees under reward and transitionuncertainty, as well as settings where the method performs poorly. Much of ouranalysis contrasts state entropy with the widely used policy entropyregularization, highlighting their different benefits. Finally, from apractical standpoint, we illustrate that compared with policy entropy, therobustness advantages of state entropy are more sensitive to the number ofrollouts used for policy evaluation.</description>
      <author>example@mail.com (Uri Koren, Yonatan Ashlag, Mirco Mutti, Esther Derman, Pierre-Luc Bacon, Shie Mannor)</author>
      <guid isPermaLink="false">2506.07085v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Improving Wildlife Out-of-Distribution Detection: Africas Big Five</title>
      <link>http://arxiv.org/abs/2506.06719v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究旨在解决人类与野生动物冲突，通过计算机视觉技术识别可能引发冲突的个体，如非洲大型动物。&lt;h4&gt;背景&lt;/h4&gt;当前动物分类模型在封闭世界假设下训练，对未知类别的预测往往过于自信。&lt;h4&gt;目的&lt;/h4&gt;研究野生动物（特别是非洲大型动物）的分布外（OOD）检测。&lt;h4&gt;方法&lt;/h4&gt;选择参数化的最近类均值（NCM）和非参数的对比学习方法作为基线，并与其他常见的OOD方法进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;基于特征的方法在不同分类阈值下表现出更强的泛化能力。特别是，使用ImageNet预训练特征的NCM在AUPR-IN、AUPR-OUT和AUTC上分别比最佳OOD方法提高了2%、4%和22%。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，基于特征的方法在OOD检测方面具有更高的准确性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mitigating human-wildlife conflict seeks to resolve unwanted encountersbetween these parties. Computer Vision provides a solution to identifyingindividuals that might escalate into conflict, such as members of the Big FiveAfrican animals. However, environments often contain several varied species.The current state-of-the-art animal classification models are trained under aclosed-world assumption. They almost always remain overconfident in theirpredictions even when presented with unknown classes. This study investigatesout-of-distribution (OOD) detection of wildlife, specifically the Big Five. Tothis end, we select a parametric Nearest Class Mean (NCM) and a non-parametriccontrastive learning approach as baselines to take advantage of pretrained andprojected features from popular classification encoders. Moreover, we compareour baselines to various common OOD methods in the literature. The results showfeature-based methods reflect stronger generalisation capability across varyingclassification thresholds. Specifically, NCM with ImageNet pre-trained featuresachieves a 2%, 4% and 22% improvement on AUPR-IN, AUPR-OUT and AUTC over thebest OOD methods, respectively. The code can be found herehttps://github.com/pxpana/BIG5OOD</description>
      <author>example@mail.com (Mufhumudzi Muthivhi, Jiahao Huo, Fredrik Gustafsson, Terence L. van Zyl)</author>
      <guid isPermaLink="false">2506.06719v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>AugmentGest: Can Random Data Cropping Augmentation Boost Gesture Recognition Performance?</title>
      <link>http://arxiv.org/abs/2506.07216v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种全面的数据增强框架，用于解决深度学习任务中数据集多样性有限的问题，如基于骨骼的数据集。该框架通过几何变换、随机裁剪、旋转、缩放和基于强度的变换来模拟现实世界的变异性，提高了模型在不同数据集和架构上的泛化能力和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;数据增强是深度学习中的关键技术，尤其在数据集多样性有限的任务中，如基于骨骼的数据集，显得尤为重要。&lt;h4&gt;目的&lt;/h4&gt;提高模型在不同数据集和架构上的泛化能力和鲁棒性，丰富手势表示的多样性。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了几何变换、随机裁剪、旋转、缩放和亮度对比度调整等手段，对每个样本生成三个增强版本，从而将数据集规模扩大四倍。&lt;h4&gt;主要发现&lt;/h4&gt;实验在多个基准数据集上进行，包括DHG14/28、SHREC'17和JHMDB，结果表明，该方法在三个评估模型（多流端到端ET、基于FPPR的点云手势识别和DD-Network）上均取得了最先进的成果。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅提高了模型在不同数据集和架构上的泛化能力和鲁棒性，还为现实场景中的手势识别和动作识别应用提供了一个可扩展的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a comprehensive data augmentation framework for tasks with limited dataset diversity, such as skeleton-based datasets. The framework combines geometric transformations, random cropping, rotation, zooming, and intensity-based transformations to simulate real-world variations, thereby enhancing the generalization and robustness of models across diverse datasets and architectures. Experiments on benchmark datasets including DHG14/28, SHREC'17, and JHMDB demonstrate that the proposed method achieves state-of-the-art results on three evaluated models: multi-stream e2eET, FPPR point cloud-based hand gesture recognition (HGR), and DD-Network. The method not only improves model generalization and robustness but also offers a scalable solution for real-world HGR and action recognition applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data augmentation is a crucial technique in deep learning, particularly fortasks with limited dataset diversity, such as skeleton-based datasets. Thispaper proposes a comprehensive data augmentation framework that integratesgeometric transformations, random cropping, rotation, zooming andintensity-based transformations, brightness and contrast adjustments tosimulate real-world variations. Random cropping ensures the preservation ofspatio-temporal integrity while addressing challenges such as viewpoint biasand occlusions. The augmentation pipeline generates three augmented versionsfor each sample in addition to the data set sample, thus quadrupling the dataset size and enriching the diversity of gesture representations. The proposedaugmentation strategy is evaluated on three models: multi-stream e2eET, FPPRpoint cloud-based hand gesture recognition (HGR), and DD-Network. Experimentsare conducted on benchmark datasets including DHG14/28, SHREC'17, and JHMDB.The e2eET model, recognized as the state-of-the-art for hand gesturerecognition on DHG14/28 and SHREC'17. The FPPR-PCD model, the second-bestperforming model on SHREC'17, excels in point cloud-based gesture recognition.DD-Net, a lightweight and efficient architecture for skeleton-based actionrecognition, is evaluated on SHREC'17 and the Human Motion Data Base (JHMDB).The results underline the effectiveness and versatility of the proposedaugmentation strategy, significantly improving model generalization androbustness across diverse datasets and architectures. This framework not onlyestablishes state-of-the-art results on all three evaluated models but alsooffers a scalable solution to advance HGR and action recognition applicationsin real-world scenarios. The framework is available athttps://github.com/NadaAbodeshish/Random-Cropping-augmentation-HGR</description>
      <author>example@mail.com (Nada Aboudeshish, Dmitry Ignatov, Radu Timofte)</author>
      <guid isPermaLink="false">2506.07216v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs</title>
      <link>http://arxiv.org/abs/2506.07454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个多机器人系统，该系统通过3D场景图集成了制图、定位和任务与运动规划（TAMP），以执行用自然语言表达的复杂指令。&lt;h4&gt;背景&lt;/h4&gt;目前多机器人系统需要集成多种功能以执行复杂任务，包括地图构建、定位和规划。&lt;h4&gt;目的&lt;/h4&gt;开发一个多机器人系统，该系统能够理解自然语言指令，并在3D环境中执行复杂任务。&lt;h4&gt;方法&lt;/h4&gt;系统构建了一个共享的3D场景图，其中包含一个基于开放集的对象地图，用于多机器人3D场景图融合。该表示支持实时、视角不变的重定位（通过对象地图）和规划（通过3D场景图）。另外，系统使用大型语言模型（LLM）将操作者的意图转化为规划域定义语言（PDDL）目标，利用共享3D场景图和机器人能力。&lt;h4&gt;主要发现&lt;/h4&gt;该系统能够在大型、室外环境中执行真实世界任务，并对其性能进行了实验评估。&lt;h4&gt;结论&lt;/h4&gt;该多机器人系统能够有效地理解和执行自然语言指令，并在复杂环境中实现任务规划与执行。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce a multi-robot system that integrates mapping,localization, and task and motion planning (TAMP) enabled by 3D scene graphs toexecute complex instructions expressed in natural language. Our system builds ashared 3D scene graph incorporating an open-set object-based map, which isleveraged for multi-robot 3D scene graph fusion. This representation supportsreal-time, view-invariant relocalization (via the object-based map) andplanning (via the 3D scene graph), allowing a team of robots to reason abouttheir surroundings and execute complex tasks. Additionally, we introduce aplanning approach that translates operator intent into Planning DomainDefinition Language (PDDL) goals using a Large Language Model (LLM) byleveraging context from the shared 3D scene graph and robot capabilities. Weprovide an experimental assessment of the performance of our system onreal-world tasks in large-scale, outdoor environments.</description>
      <author>example@mail.com (Jared Strader, Aaron Ray, Jacob Arkin, Mason B. Peterson, Yun Chang, Nathan Hughes, Christopher Bradley, Yi Xuan Jia, Carlos Nieto-Granda, Rajat Talak, Chuchu Fan, Luca Carlone, Jonathan P. How, Nicholas Roy)</author>
      <guid isPermaLink="false">2506.07454v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Visual Prompting: Robustness Inheritance and Beyond</title>
      <link>http://arxiv.org/abs/2506.06823v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2311.10992&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文首次探讨了视觉提示（VP）在鲁棒源模型下的表现，提出了PromptBoundary Loosening（PBL）策略以缓解VP在鲁棒性和泛化能力之间的权衡。&lt;h4&gt;背景&lt;/h4&gt;视觉提示（VP）作为一种有效的迁移学习方法，在视觉任务中显示出其潜力。然而，先前的研究主要集中在从标准源模型中进行VP，而鲁棒源模型下的VP表现尚不明确。&lt;h4&gt;目的&lt;/h4&gt;研究鲁棒源模型对VP表现的影响，探讨VP在鲁棒性和泛化能力之间的权衡，并提出缓解这种权衡的策略。&lt;h4&gt;方法&lt;/h4&gt;本文提出了PromptBoundary Loosening（PBL）策略，这是一种轻量级、即插即用的策略，与VP自然兼容，并有效确保了在源模型为鲁棒模型时鲁棒性的成功继承。&lt;h4&gt;主要发现&lt;/h4&gt;通过在多个数据集上的广泛实验，发现PBL策略能够显著增强VP在下游数据集上的泛化能力，并成功缓解了VP在鲁棒性和泛化能力之间的权衡。&lt;h4&gt;结论&lt;/h4&gt;PBL策略能够有效提高VP在鲁棒源模型下的表现，并具有普遍性，证明了该策略的重要益处。&lt;h4&gt;翻译&lt;/h4&gt;Visual Prompting (VP), an efficient method for transfer learning, has shown its potential in vision tasks. However, previous works focus exclusively on VP from standard source models, it is still unknown how it performs under the scenario of a robust source model: Can the robustness of the source model be successfully inherited? Does VP also encounter the same trade-off between robustness and generalization ability as the source model during this process? If such a trade-off exists, is there a strategy specifically tailored to VP to mitigate this limitation? In this paper, we thoroughly explore these three questions for the first time and provide affirmative answers to them. To mitigate the trade-off faced by VP, we propose a strategy called PromptBoundary Loosening (PBL). As a lightweight, plug-and-play strategy naturally compatible with VP, PBL effectively ensures the successful inheritance of robustness when the source model is a robust model, while significantly enhancing VP's generalization ability across various downstream datasets. Extensive experiments across various datasets show that our findings are universal and demonstrate the significant benefits of the proposed strategy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Prompting (VP), an efficient method for transfer learning, has shownits potential in vision tasks. However, previous works focus exclusively on VPfrom standard source models, it is still unknown how it performs under thescenario of a robust source model: Can the robustness of the source model besuccessfully inherited? Does VP also encounter the same trade-off betweenrobustness and generalization ability as the source model during this process?If such a trade-off exists, is there a strategy specifically tailored to VP tomitigate this limitation? In this paper, we thoroughly explore these threequestions for the first time and provide affirmative answers to them. Tomitigate the trade-off faced by VP, we propose a strategy called PromptBoundary Loosening (PBL). As a lightweight, plug-and-play strategy naturallycompatible with VP, PBL effectively ensures the successful inheritance ofrobustness when the source model is a robust model, while significantlyenhancing VP's generalization ability across various downstream datasets.Extensive experiments across various datasets show that our findings areuniversal and demonstrate the significant benefits of the proposed strategy.</description>
      <author>example@mail.com (Qi Li, Liangzhi Li, Zhouqiang Jiang, Bowen Wang, Keke Tang)</author>
      <guid isPermaLink="false">2506.06823v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>CrossGen: Learning and Generating Cross Fields for Quad Meshing</title>
      <link>http://arxiv.org/abs/2506.07020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://anonymousproject-homepage.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CrossGen是一种新型框架，用于生成高质量的四边形网格，通过在联合潜在空间中统一几何和交叉场表示，支持交叉场的前馈预测和潜在生成建模。&lt;h4&gt;背景&lt;/h4&gt;现有的交叉场生成方法难以在计算效率和生成质量之间取得平衡，通常采用缓慢的针对每个形状的优化。&lt;h4&gt;目的&lt;/h4&gt;提出CrossGen框架，旨在实现快速计算高质量交叉场，同时不需要针对每个形状的优化。&lt;h4&gt;方法&lt;/h4&gt;CrossGen使用自动编码器网络架构，将输入的点云表面编码为稀疏体素网格，具有细粒度的潜在空间，这些空间被解码为基于SDF的表面几何和交叉场。同时，该方法还包含一个用于计算从部分输入（如草图）生成的新形状的交叉场的扩散模型。&lt;h4&gt;主要发现&lt;/h4&gt;CrossGen能够在不到一秒的时间内计算一般输入形状的高质量交叉场，无需针对每个形状的优化，并具有高几何保真度、噪声鲁棒性和快速推理能力。&lt;h4&gt;结论&lt;/h4&gt;CrossGen在四边形网格生成任务中表现出色，适用于各种表面形状，为交叉场生成提供了一种高效且高质量的方法。&lt;h4&gt;翻译&lt;/h4&gt;Cross fields play a critical role in various geometry processing tasks, especially for quad mesh generation. Existing methods for cross field generation often struggle to balance computational efficiency with generation quality, using slow per-shape optimization. We introduce CrossGen, a novel framework that supports both feed-forward prediction and latent generative modeling of cross fields for quad meshing by unifying geometry and cross field representations within a joint latent space. Our method enables extremely fast computation of high-quality cross fields of general input shapes, typically within one second without per-shape optimization. Our method assumes a point-sampled surface, or called a point-cloud surface, as input, so we can accommodate various different surface representations by a straightforward point sampling process. Using an auto-encoder network architecture, we encode input point-cloud surfaces into a sparse voxel grid with fine-grained latent spaces, which are decoded into both SDF-based surface geometry and cross fields. We also contribute a dataset of models with both high-quality signed distance fields (SDFs) representations and their corresponding cross fields, and use it to train our network. Once trained, the network is capable of computing a cross field of an input surface in a feed-forward manner, ensuring high geometric fidelity, noise resilience, and rapid inference. Furthermore, leveraging the same unified latent representation, we incorporate a diffusion model for computing cross fields of new shapes generated from partial input, such as sketches. To demonstrate its practical applications, we validate CrossGen on the quad mesh generation task for a large variety of surface shapes. Experimental results...&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross fields play a critical role in various geometry processing tasks,especially for quad mesh generation. Existing methods for cross fieldgeneration often struggle to balance computational efficiency with generationquality, using slow per-shape optimization. We introduce CrossGen, a novelframework that supports both feed-forward prediction and latent generativemodeling of cross fields for quad meshing by unifying geometry and cross fieldrepresentations within a joint latent space. Our method enables extremely fastcomputation of high-quality cross fields of general input shapes, typicallywithin one second without per-shape optimization. Our method assumes apoint-sampled surface, or called a point-cloud surface, as input, so we canaccommodate various different surface representations by a straightforwardpoint sampling process. Using an auto-encoder network architecture, we encodeinput point-cloud surfaces into a sparse voxel grid with fine-grained latentspaces, which are decoded into both SDF-based surface geometry and crossfields. We also contribute a dataset of models with both high-quality signeddistance fields (SDFs) representations and their corresponding cross fields,and use it to train our network. Once trained, the network is capable ofcomputing a cross field of an input surface in a feed-forward manner, ensuringhigh geometric fidelity, noise resilience, and rapid inference. Furthermore,leveraging the same unified latent representation, we incorporate a diffusionmodel for computing cross fields of new shapes generated from partial input,such as sketches. To demonstrate its practical applications, we validateCrossGen on the quad mesh generation task for a large variety of surfaceshapes. Experimental results...</description>
      <author>example@mail.com (Qiujie Dong, Jiepeng Wang, Rui Xu, Cheng Lin, Yuan Liu, Shiqing Xin, Zichun Zhong, Xin Li, Changhe Tu, Taku Komura, Leif Kobbelt, Scott Schaefer, Wenping Wang)</author>
      <guid isPermaLink="false">2506.07020v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>MIRA: Medical Time Series Foundation Model for Real-World Health Data</title>
      <link>http://arxiv.org/abs/2506.07584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种针对医疗时间序列的统一基础模型MIRA，通过预训练减少标注负担，最小化模型定制，并实现跨临床机构、模态和任务的鲁棒迁移。&lt;h4&gt;背景&lt;/h4&gt;现有通用时间序列基础模型难以处理医疗时间序列数据，因为它们存在不规则的时间间隔、异质采样率和频繁缺失值等问题。&lt;h4&gt;目的&lt;/h4&gt;设计MIRA模型以解决上述挑战，实现医疗时间序列的准确预测。&lt;h4&gt;方法&lt;/h4&gt;MIRA模型包含连续时间旋转位置编码、特定频率的专家混合层以及基于神经网络常微分方程的连续动态外推块。&lt;h4&gt;主要发现&lt;/h4&gt;MIRA在包含超过4540亿时间点的医学语料库上预训练，与零样本和微调的基线相比，在分布外和分布内场景下，预测误差分别减少了10%和7%。&lt;h4&gt;结论&lt;/h4&gt;MIRA为医学时间序列建模的基准研究提供了基础，有助于未来在该领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;A unified foundation model for medical time series -- pretrained on openaccess and ethics board-approved medical corpora -- offers the potential toreduce annotation burdens, minimize model customization, and enable robusttransfer across clinical institutions, modalities, and tasks, particularly indata-scarce or privacy-constrained environments. However, existing generalisttime series foundation models struggle to handle medical time series data dueto their inherent challenges, including irregular intervals, heterogeneoussampling rates, and frequent missing values. To address these challenges, weintroduce MIRA, a unified foundation model specifically designed for medicaltime series forecasting. MIRA incorporates a Continuous-Time Rotary PositionalEncoding that enables fine-grained modeling of variable time intervals, afrequency-specific mixture-of-experts layer that routes computation acrosslatent frequency regimes to further promote temporal specialization, and aContinuous Dynamics Extrapolation Block based on Neural ODE that models thecontinuous trajectory of latent states, enabling accurate forecasting atarbitrary target timestamps. Pretrained on a large-scale and diverse medicalcorpus comprising over 454 billion time points collect from publicly availabledatasets, MIRA achieves reductions in forecasting errors by an average of 10%and 7% in out-of-distribution and in-distribution scenarios, respectively, whencompared to other zero-shot and fine-tuned baselines. We also introduceacomprehensive benchmark spanning multiple downstream clinical tasks,establishing a foundation for future research in medical time series modeling.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A unified foundation model for medical time series -- pretrained on openaccess and ethics board-approved medical corpora -- offers the potential toreduce annotation burdens, minimize model customization, and enable robusttransfer across clinical institutions, modalities, and tasks, particularly indata-scarce or privacy-constrained environments. However, existing generalisttime series foundation models struggle to handle medical time series data dueto their inherent challenges, including irregular intervals, heterogeneoussampling rates, and frequent missing values. To address these challenges, weintroduce MIRA, a unified foundation model specifically designed for medicaltime series forecasting. MIRA incorporates a Continuous-Time Rotary PositionalEncoding that enables fine-grained modeling of variable time intervals, afrequency-specific mixture-of-experts layer that routes computation acrosslatent frequency regimes to further promote temporal specialization, and aContinuous Dynamics Extrapolation Block based on Neural ODE that models thecontinuous trajectory of latent states, enabling accurate forecasting atarbitrary target timestamps. Pretrained on a large-scale and diverse medicalcorpus comprising over 454 billion time points collect from publicly availabledatasets, MIRA achieves reductions in forecasting errors by an average of 10%and 7% in out-of-distribution and in-distribution scenarios, respectively, whencompared to other zero-shot and fine-tuned baselines. We also introduce acomprehensive benchmark spanning multiple downstream clinical tasks,establishing a foundation for future research in medical time series modeling.</description>
      <author>example@mail.com (Hao Li, Bowen Deng, Chang Xu, Zhiyuan Feng, Viktor Schlegel, Yu-Hao Huang, Yizheng Sun, Jingyuan Sun, Kailai Yang, Yiyao Yu, Jiang Bian)</author>
      <guid isPermaLink="false">2506.07584v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>FANVID: A Benchmark for Face and License Plate Recognition in Low-Resolution Videos</title>
      <link>http://arxiv.org/abs/2506.07304v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了FANVID，一个基于视频的基准数据集，旨在提升低分辨率视频中的时间和空间识别能力。&lt;h4&gt;背景&lt;/h4&gt;现实世界的监控视频中，由于低分辨率和干扰因素，人脸和车牌往往难以识别。&lt;h4&gt;目的&lt;/h4&gt;提出FANVID数据集，旨在提高时间和空间识别模型在低分辨率视频中的识别准确率。&lt;h4&gt;方法&lt;/h4&gt;FANVID包含近1,463个低分辨率视频片段，包括来自三个英语国家的人脸和车牌，并包含干扰元素，以提高任务难度和真实性。数据集包含31,096个手动验证的边界框和标签。数据集定义了两个任务：人脸匹配和车牌识别。视频从高分辨率源下采样，以确保单帧中的人脸和文本难以识别，需要模型利用时间信息。引入了适应于IoU &gt; 0.5的平均精度等评估指标。&lt;h4&gt;主要发现&lt;/h4&gt;基线方法在人脸匹配和车牌识别任务中分别取得了0.58和0.42的分数，显示了任务的可行性和挑战。FANVID在人脸和车牌的选择上平衡了多样性和识别难度。&lt;h4&gt;结论&lt;/h4&gt;FANVID旨在促进低分辨率识别的时序建模创新，并在监控、法医学和自动驾驶等领域具有应用前景。&lt;h4&gt;翻译&lt;/h4&gt;Real-world surveillance often renders faces and license plates unrecognizable in individual low-resolution (LR) frames, hindering reliable identification. To advance temporal recognition models, we present FANVID, a novel video-based benchmark comprising nearly 1,463 LR clips (180 x 320, 20--60 FPS) featuring 63 identities and 49 license plates from three English-speaking countries. Each video includes distractor faces and plates, increasing task difficulty and realism. The dataset contains 31,096 manually verified bounding boxes and labels. FANVID defines two tasks: (1) face matching -- detecting LR faces and matching them to high-resolution mugshots, and (2) license plate recognition -- extracting text from LR plates without a predefined database. Videos are downsampled from high-resolution sources to ensure that faces and text are indecipherable in single frames, requiring models to exploit temporal information. We introduce evaluation metrics adapted from mean Average Precision at IoU &gt; 0.5, prioritizing identity correctness for faces and character-level accuracy for text. A baseline method with pre-trained video super-resolution, detection, and recognition achieved performance scores of 0.58 (face matching) and 0.42 (plate recognition), highlighting both the feasibility and challenge of the tasks. FANVID's selection of faces and plates balances diversity with recognition challenge. We release the software for data access, evaluation, baseline, and annotation to support reproducibility and extension. FANVID aims to catalyze innovation in temporal modeling for LR recognition, with applications in surveillance, forensics, and autonomous vehicles.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world surveillance often renders faces and license plates unrecognizablein individual low-resolution (LR) frames, hindering reliable identification. Toadvance temporal recognition models, we present FANVID, a novel video-basedbenchmark comprising nearly 1,463 LR clips (180 x 320, 20--60 FPS) featuring 63identities and 49 license plates from three English-speaking countries. Eachvideo includes distractor faces and plates, increasing task difficulty andrealism. The dataset contains 31,096 manually verified bounding boxes andlabels.  FANVID defines two tasks: (1) face matching -- detecting LR faces andmatching them to high-resolution mugshots, and (2) license plate recognition --extracting text from LR plates without a predefined database. Videos aredownsampled from high-resolution sources to ensure that faces and text areindecipherable in single frames, requiring models to exploit temporalinformation. We introduce evaluation metrics adapted from mean AveragePrecision at IoU &gt; 0.5, prioritizing identity correctness for faces andcharacter-level accuracy for text.  A baseline method with pre-trained video super-resolution, detection, andrecognition achieved performance scores of 0.58 (face matching) and 0.42 (platerecognition), highlighting both the feasibility and challenge of the tasks.FANVID's selection of faces and plates balances diversity with recognitionchallenge. We release the software for data access, evaluation, baseline, andannotation to support reproducibility and extension. FANVID aims to catalyzeinnovation in temporal modeling for LR recognition, with applications insurveillance, forensics, and autonomous vehicles.</description>
      <author>example@mail.com (Kavitha Viswanathan, Vrinda Goel, Shlesh Gholap, Devayan Ghosh, Madhav Gupta, Dhruvi Ganatra, Sanket Potdar, Amit Sethi)</author>
      <guid isPermaLink="false">2506.07304v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Technical Report for ICRA 2025 GOOSE 3D Semantic Segmentation Challenge: Adaptive Point Cloud Understanding for Heterogeneous Robotic Systems</title>
      <link>http://arxiv.org/abs/2506.06995v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Winner of the GOOSE 3D Semantic Segmentation Challenge at the IEEE  ICRA Workshop on Field Robotics 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本技术报告介绍了ICRA 2025 GOOSE 3D语义分割挑战的解决方案实现细节。&lt;h4&gt;背景&lt;/h4&gt;该挑战聚焦于从多个机器人平台收集的多种非结构化室外环境中3D点云的语义分割。&lt;h4&gt;目的&lt;/h4&gt;通过实现点提示调整（Point Prompt Tuning）与点变换器v3（Point Transformer v3，PTv3）骨干网络的集成，解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;采用平台特定的条件化和跨数据集类别对齐策略，使模型能够自适应处理异构的LiDAR数据，且训练过程中无需额外外部数据。&lt;h4&gt;主要发现&lt;/h4&gt;与基线PTv3模型相比，该方法在具有挑战性的平台上实现了显著的性能提升，mIoU提高了高达22.59%，证明了自适应点云理解在场地机器人应用中的有效性。&lt;h4&gt;结论&lt;/h4&gt;自适应点云理解方法在处理非结构化室外环境的3D点云语义分割时，表现出了良好的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report presents the implementation details of the winningsolution for the ICRA 2025 GOOSE 3D Semantic Segmentation Challenge. Thischallenge focuses on semantic segmentation of 3D point clouds from diverseunstructured outdoor environments collected from multiple robotic platforms.This problem was addressed by implementing Point Prompt Tuning (PPT) integratedwith Point Transformer v3 (PTv3) backbone, enabling adaptive processing ofheterogeneous LiDAR data through platform-specific conditioning andcross-dataset class alignment strategies. The model is trained withoutrequiring additional external data. As a result, this approach achievedsubstantial performance improvements with mIoU increases of up to 22.59% onchallenging platforms compared to the baseline PTv3 model, demonstrating theeffectiveness of adaptive point cloud understanding for field roboticsapplications.</description>
      <author>example@mail.com (Xiaoya Zhang)</author>
      <guid isPermaLink="false">2506.06995v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Technical Report: A Practical Guide to Kaldi ASR Optimization</title>
      <link>http://arxiv.org/abs/2506.07149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本技术报告介绍了针对基于Kaldi的自动语音识别（ASR）系统的创新优化，重点关注声学模型增强、超参数调整和语言模型效率。&lt;h4&gt;背景&lt;/h4&gt;报告背景是Kaldi的自动语音识别技术。&lt;h4&gt;目的&lt;/h4&gt;目的是通过优化提高ASR的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;方法包括开发自定义的Conformer块与多流TDNN-F结构集成，采用高级数据增强技术和动态超参数优化，以及使用贝叶斯优化和n-gram剪枝进行语言模型管理。&lt;h4&gt;主要发现&lt;/h4&gt;这些系统性的改进显著提高了ASR的准确性和鲁棒性，优于现有方法，并为多种语音识别场景提供了可扩展的解决方案。&lt;h4&gt;结论&lt;/h4&gt;报告强调了战略优化在保持Kaldi适应性和竞争力中的重要性，特别是在快速发展的技术环境中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report introduces innovative optimizations for Kaldi-basedAutomatic Speech Recognition (ASR) systems, focusing on acoustic modelenhancement, hyperparameter tuning, and language model efficiency. We developeda custom Conformer block integrated with a multistream TDNN-F structure,enabling superior feature extraction and temporal modeling. Our approachincludes advanced data augmentation techniques and dynamic hyperparameteroptimization to boost performance and reduce overfitting. Additionally, wepropose robust strategies for language model management, employing Bayesianoptimization and $n$-gram pruning to ensure relevance and computationalefficiency. These systematic improvements significantly elevate ASR accuracyand robustness, outperforming existing methods and offering a scalable solutionfor diverse speech recognition scenarios. This report underscores theimportance of strategic optimizations in maintaining Kaldi's adaptability andcompetitiveness in rapidly evolving technological landscapes.</description>
      <author>example@mail.com (Mengze Hong, Di Jiang)</author>
      <guid isPermaLink="false">2506.07149v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>AnnoDPO: Protein Functional Annotation Learning with Direct Preference Optimization</title>
      <link>http://arxiv.org/abs/2506.07035v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AnnoDPO的新型多模态框架，用于蛋白质功能预测，通过直接偏好优化（DPO）来增强注释学习，解决了注释稀缺和类别不平衡的双重挑战。&lt;h4&gt;背景&lt;/h4&gt;蛋白质功能解析是蛋白质表示学习中的基本挑战，由于功能注释类别众多且注释实例在生物分类学中的分布高度不平衡，蛋白质语言模型（PLM）面临重大困难。&lt;h4&gt;目的&lt;/h4&gt;提出AnnoDPO框架，旨在通过直接偏好优化（DPO）提高注释学习，以解决蛋白质功能预测中的注释稀缺和类别不平衡问题。&lt;h4&gt;方法&lt;/h4&gt;AnnoDPO框架利用偏好对齐的训练目标，结合强化学习从人类反馈（RLHF）在大型语言模型（LLM）对齐中的成功经验。&lt;h4&gt;主要发现&lt;/h4&gt;AnnoDPO通过偏好对齐的训练目标解决了注释稀缺和类别不平衡的挑战，为蛋白质表示学习中的生物知识整合建立了一种新的范式。&lt;h4&gt;结论&lt;/h4&gt;AnnoDPO框架为蛋白质功能预测提供了一种有效的方法，有助于克服注释稀缺和类别不平衡的问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要：解析蛋白质功能仍然是蛋白质表示学习中的一个基本挑战。这项任务对蛋白质语言模型（PLMs）来说具有重大困难，因为功能注释类别众多，且注释实例在生物分类学中的分布高度不平衡。受大型语言模型（LLM）对齐中强化学习从人类反馈（RLHF）取得的显著成功的启发，我们提出了AnnoDPO，这是一种新颖的多模态蛋白质功能预测框架，它利用直接偏好优化（DPO）来增强注释学习。我们的方法通过偏好对齐的训练目标解决了注释稀缺和类别不平衡的双重挑战，为蛋白质表示学习中的生物知识整合建立了一种新的范式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deciphering protein function remains a fundamental challenge in proteinrepresentation learning. The task presents significant difficulties for proteinlanguage models (PLMs) due to the sheer volume of functional annotationcategories and the highly imbalanced distribution of annotated instances acrossbiological ontologies. Inspired by the remarkable success of reinforcementlearning from human feedback (RLHF) in large language model (LLM) alignment, wepropose AnnoDPO, a novel multi-modal framework for protein function predictionthat leverages Direct Preference Optimization (DPO) to enhance annotationlearning. Our methodology addresses the dual challenges of annotation scarcityand category imbalance through preference-aligned training objectives,establishing a new paradigm for biological knowledge integration in proteinrepresentation learning.</description>
      <author>example@mail.com (Zixuan Jiang, Renjing Xu)</author>
      <guid isPermaLink="false">2506.07035v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Textile Analysis for Recycling Automation using Transfer Learning and Zero-Shot Foundation Models</title>
      <link>http://arxiv.org/abs/2506.06569v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用标准RGB图像进行自动化系统中的关键预处理任务，以提高纺织品回收的效率和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;准确识别材料成分和检测传感器数据中的污染物对于自动化纺织品回收至关重要，但这是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;探索使用RGB图像和现代深度学习技术，包括迁移学习和基础模型，来实现自动化纺织品回收流程的关键分析步骤。&lt;h4&gt;方法&lt;/h4&gt;开发了计算机视觉组件，用于传送带设置，以执行(a)四种常见纺织品类型的分类和(b)按钮和拉链等非纺织品特征的分割。&lt;h4&gt;主要发现&lt;/h4&gt;使用迁移学习和交叉验证评估了几个预训练架构，EfficientNetB0在保留测试集上达到了81.25%的准确率。对于特征分割，结合Grounding DINO开放词汇检测器和Segment Anything Model (SAM)的零样本方法表现出色，生成的掩码与真实值的mIoU达到0.90。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了使用RGB图像与现代深度学习技术相结合的可行性，以实现自动化纺织品回收流程的关键分析步骤。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated sorting is crucial for improving the efficiency and scalability oftextile recycling, but accurately identifying material composition anddetecting contaminants from sensor data remains challenging. This paperinvestigates the use of standard RGB imagery, a cost-effective sensingmodality, for key pre-processing tasks in an automated system. We presentcomputer vision components designed for a conveyor belt setup to perform (a)classification of four common textile types and (b) segmentation of non-textilefeatures such as buttons and zippers. For classification, several pre-trainedarchitectures were evaluated using transfer learning and cross-validation, withEfficientNetB0 achieving the best performance on a held-out test set with81.25\% accuracy. For feature segmentation, a zero-shot approach combining theGrounding DINO open-vocabulary detector with the Segment Anything Model (SAM)was employed, demonstrating excellent performance with a mIoU of 0.90 for thegenerated masks against ground truth. This study demonstrates the feasibilityof using RGB images coupled with modern deep learning techniques, includingtransfer learning for classification and foundation models for zero-shotsegmentation, to enable essential analysis steps for automated textilerecycling pipelines.</description>
      <author>example@mail.com (Yannis Spyridis, Vasileios Argyriou)</author>
      <guid isPermaLink="false">2506.06569v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>GGBall: Graph Generative Model on Poincaré Ball</title>
      <link>http://arxiv.org/abs/2506.07198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GGBall的新型超曲率框架，用于生成具有层次结构的图，以解决欧几里得几何在捕捉指数复杂性方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;生成具有层次结构的图是一个基本挑战，因为欧几里得几何无法有效地捕捉指数复杂性。&lt;h4&gt;目的&lt;/h4&gt;引入GGBall，以解决上述问题，并通过结合几何归纳偏见和现代生成范式来生成具有层次结构的图。&lt;h4&gt;方法&lt;/h4&gt;GGBall结合了超曲率向量量化自动编码器（HVQVAE）和通过闭形式测地线定义的黎曼流匹配先验。此外，还开发了一套在流形上操作的超曲率图神经网络（GNN）和Transformer层。&lt;h4&gt;主要发现&lt;/h4&gt;与最先进的基线相比，GGBall在Community-Small上减少了超过75%的度MMD，在Ego-Small上减少了超过40%，这表明其能够更好地保留拓扑层次结构。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，超曲率几何可以作为复杂、结构化和层次化数据域生成建模的强大基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成具有层次结构的图仍然是一个基本挑战，因为欧几里得几何在捕捉指数复杂性方面存在局限性。在这里，我们引入了GGBall，这是一种用于图生成的新型超曲率框架，它结合了几何归纳偏见与现代生成范式。GGBall结合了超曲率向量量化自动编码器（HVQVAE）和通过闭形式测地线定义的黎曼流匹配先验。这种设计使得基于流的先验能够模拟复杂的潜在分布，而向量量化有助于保留超曲率空间的曲率感知结构。我们进一步开发了一套在流形上操作的超曲率图神经网络（GNN）和Transformer层，确保了稳定性和可扩展性。从经验上看，我们的模型在Community-Small上减少了超过75%的度MMD，在Ego-Small上减少了超过40%，与最先进的基线相比，这表明了其能够更好地保留拓扑层次结构。这些结果突出了超曲率几何作为复杂、结构化和层次化数据域生成建模的强大基础。我们的代码可在https://github.com/AI4Science-WestlakeU/GGBall处获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating graphs with hierarchical structures remains a fundamentalchallenge due to the limitations of Euclidean geometry in capturing exponentialcomplexity. Here we introduce \textbf{GGBall}, a novel hyperbolic framework forgraph generation that integrates geometric inductive biases with moderngenerative paradigms. GGBall combines a Hyperbolic Vector-Quantized Autoencoder(HVQVAE) with a Riemannian flow matching prior defined via closed-formgeodesics. This design enables flow-based priors to model complex latentdistributions, while vector quantization helps preserve the curvature-awarestructure of the hyperbolic space. We further develop a suite of hyperbolic GNNand Transformer layers that operate entirely within the manifold, ensuringstability and scalability. Empirically, our model reduces degree MMD by over75\% on Community-Small and over 40\% on Ego-Small compared to state-of-the-artbaselines, demonstrating an improved ability to preserve topologicalhierarchies. These results highlight the potential of hyperbolic geometry as apowerful foundation for the generative modeling of complex, structured, andhierarchical data domains. Our code is available at\href{https://github.com/AI4Science-WestlakeU/GGBall}{here}.</description>
      <author>example@mail.com (Tianci Bu, Chuanrui Wang, Hao Ma, Haoren Zheng, Xin Lu, Tailin Wu)</author>
      <guid isPermaLink="false">2506.07198v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Learning Robust Heterogeneous Graph Representations via Contrastive-Reconstruction under Sparse Semantics</title>
      <link>http://arxiv.org/abs/2506.06682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HetCRF的新型双通道自监督学习框架，用于异构图的自监督学习。&lt;h4&gt;背景&lt;/h4&gt;图自监督学习中，掩码自编码器（MAE）和对比学习（CL）是两种主要范式。MAE擅长局部特征捕获，而CL擅长全局信息提取。现有的混合框架在共享编码器设计上面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出HetCRF框架，以适应MAE和CL的需求，并解决语义稀疏场景中的问题。&lt;h4&gt;方法&lt;/h4&gt;HetCRF采用两阶段聚合策略来适应嵌入语义，并通过增强编码器输出以提高视图构建的效率。同时，提出了两种正样本增强策略以平衡梯度贡献。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界异构图数据集上的节点分类实验表明，HetCRF优于现有基线。在节点特征缺失的数据集上，如Aminer和Freebase，在40%的标签率下，HetCRF将Macro-F1分数分别提高了2.75%和2.2%，验证了其有效性和优越性。&lt;h4&gt;结论&lt;/h4&gt;HetCRF是一种有效的异构图自监督学习框架，能够提高节点分类的性能，特别是在节点特征缺失的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In graph self-supervised learning, masked autoencoders (MAE) and contrastivelearning (CL) are two prominent paradigms. MAE focuses on reconstructing maskedelements, while CL maximizes similarity between augmented graph views. Recentstudies highlight their complementarity: MAE excels at local feature capture,and CL at global information extraction. Hybrid frameworks for homogeneousgraphs have been proposed, but face challenges in designing shared encoders tomeet the semantic requirements of both tasks. In semantically sparse scenarios,CL struggles with view construction, and gradient imbalance between positiveand negative samples persists. This paper introduces HetCRF, a noveldual-channel self-supervised learning framework for heterogeneous graphs.HetCRF uses a two-stage aggregation strategy to adapt embedding semantics,making it compatible with both MAE and CL. To address semantic sparsity, itenhances encoder output for view construction instead of relying on rawfeatures, improving efficiency. Two positive sample augmentation strategies arealso proposed to balance gradient contributions. Node classificationexperiments on four real-world heterogeneous graph datasets demonstrate thatHetCRF outperforms state-of-the-art baselines. On datasets with missing nodefeatures, such as Aminer and Freebase, at a 40% label rate in nodeclassification, HetCRF improves the Macro-F1 score by 2.75% and 2.2%respectively compared to the second-best baseline, validating its effectivenessand superiority.</description>
      <author>example@mail.com (Di Lin, Wanjing Ren, Xuanbin Li, Rui Zhang)</author>
      <guid isPermaLink="false">2506.06682v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>GeometryZero: Improving Geometry Solving for LLM with Group Contrastive Policy Optimization</title>
      <link>http://arxiv.org/abs/2506.07160v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为GeometryZero的几何推理模型系列，通过改进的强化学习框架GCPO，实现了在几何推理领域的高效性能。&lt;h4&gt;背景&lt;/h4&gt;大语言模型在数学推理方面表现出色，其中几何问题解决是一个具有挑战性的领域，辅助构造在其中起着关键作用。现有的方法要么性能不佳，要么依赖于大规模的LLMs，导致巨大的计算成本。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的强化学习框架，以训练能够有效结合辅助构造和稳健几何推理的小型模型。&lt;h4&gt;方法&lt;/h4&gt;提出了GCPO框架，包含两个关键创新：(1)组对比掩码，根据上下文效用自适应地提供正负奖励信号；(2)长度奖励，促进更长的推理链。基于GCPO，开发了GeometryZero模型系列。&lt;h4&gt;主要发现&lt;/h4&gt;在多个几何基准测试（如Geometry3K、MathVista）中，GeometryZero模型在所有基准测试中都优于基线（如GRPO），平均改进率为4.29%。&lt;h4&gt;结论&lt;/h4&gt;GeometryZero模型通过改进的强化学习框架有效地实现了几何推理，并在实际应用中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，大型语言模型（LLMs）在多个领域展现了显著的能力，特别是在数学推理方面。其中，几何问题解决是一个具有挑战性的领域，辅助构造在其中起着关键作用。现有的方法要么性能不佳，要么依赖于大规模的LLMs（例如GPT-4o），导致巨大的计算成本。我们认为，基于可验证奖励的强化学习（例如GRPO）为训练结合辅助构造与稳健几何推理的小型模型提供了一个有希望的方向。然而，由于对无条件奖励的依赖，直接将GRPO应用于几何推理存在根本性的限制，这会导致无差别且低效的辅助构造。为了解决这些挑战，我们提出了组对比策略优化（GCPO），这是一个具有两个关键创新的强化学习框架：(1)组对比掩码，根据上下文效用自适应地提供正或负奖励信号；(2)长度奖励，促进更长的推理链。在GCPO的基础上，我们开发了GeometryZero，这是一系列可负担规模的几何推理模型，能够明智地决定何时使用辅助构造。我们在流行的几何基准（Geometry3K、MathVista）上进行了广泛的实证评估，结果表明，GeometryZero模型在所有基准测试中均优于基线（例如GRPO），平均改进率为4.29%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in large language models (LLMs) have demonstrated remarkablecapabilities across diverse domains, particularly in mathematical reasoning,amid which geometry problem solving remains a challenging area where auxiliaryconstruction plays a enssential role. Existing approaches either achievesuboptimal performance or rely on massive LLMs (e.g., GPT-4o), incurringmassive computational costs. We posit that reinforcement learning withverifiable reward (e.g., GRPO) offers a promising direction for trainingsmaller models that effectively combine auxiliary construction with robustgeometric reasoning. However, directly applying GRPO to geometric reasoningpresents fundamental limitations due to its dependence on unconditionalrewards, which leads to indiscriminate and counterproductive auxiliaryconstructions. To address these challenges, we propose Group Contrastive PolicyOptimization (GCPO), a novel reinforcement learning framework featuring two keyinnovations: (1) Group Contrastive Masking, which adaptively provides positiveor negative reward signals for auxiliary construction based on contextualutility, and a (2) length reward that promotes longer reasoning chains.Building on GCPO, we develop GeometryZero, a family of affordable-sizegeometric reasoning models that judiciously determine when to employ auxiliaryconstruction. Our extensive empirical evaluation across popular geometricbenchmarks (Geometry3K, MathVista) demonstrates that GeometryZero modelsconsistently outperform baselines (e.g. GRPO), achieving an average improvementof 4.29% across all benchmarks.</description>
      <author>example@mail.com (Yikun Wang, Yibin Wang, Dianyi Wang, Zimian Peng, Qipeng Guo, Dacheng Tao, Jiaqi Wang)</author>
      <guid isPermaLink="false">2506.07160v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Guiding Cross-Modal Representations with MLLM Priors via Preference Alignment</title>
      <link>http://arxiv.org/abs/2506.06970v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MAPLE的新框架，用于跨模态表示学习，通过利用MLLM的内在模态对齐特性来缩小模态差距。&lt;h4&gt;背景&lt;/h4&gt;尽管CLIP在跨模态内容检索方面表现出色，但模态特征空间中仍存在显著的模态差距。&lt;h4&gt;目的&lt;/h4&gt;提出MAPLE框架，旨在通过细粒度对齐先验来指导跨模态表示学习。&lt;h4&gt;方法&lt;/h4&gt;MAPLE框架利用了现成的MLLM来构建自动偏好数据，并引入了一种新的相对偏好对齐（RPA）损失函数，该函数将直接偏好优化（DPO）应用于嵌入学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MAPLE框架在细粒度跨模态检索中取得了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;MAPLE框架在处理细微语义区分方面非常有效。&lt;h4&gt;翻译&lt;/h4&gt;Despite Contrastive Language-Image Pretraining (CLIP)'s remarkable capability to retrieve content across modalities, a substantial modality gap persists in its feature space. Intriguingly, we discover that off-the-shelf MLLMs (Multimodal Large Language Models) demonstrate powerful inherent modality alignment properties. While recent MLLM-based retrievers with unified architectures partially mitigate this gap, their reliance on coarse modality alignment mechanisms fundamentally limits their potential. In this work, We introduce MAPLE (Modality-Aligned Preference Learning for Embeddings), a novel framework that leverages the fine grained alignment priors inherent in MLLM to guide cross modal representation learning. MAPLE formulates the learning process as reinforcement learning with two key components: (1) Automatic preference data construction using off-the-shelf MLLM, and (2) a new Relative Preference Alignment (RPA) loss, which adapts Direct Preference Optimization (DPO) to the embedding learning setting. Experimental results show that our preference-guided alignment achieves substantial gains in fine-grained cross-modal retrieval, underscoring its effectiveness in handling nuanced semantic distinctions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite Contrastive Language-Image Pretraining (CLIP)'s remarkable capabilityto retrieve content across modalities, a substantial modality gap persists inits feature space. Intriguingly, we discover that off-the-shelf MLLMs(Multimodal Large Language Models) demonstrate powerful inherent modalityalignment properties. While recent MLLM-based retrievers with unifiedarchitectures partially mitigate this gap, their reliance on coarse modalityalignment mechanisms fundamentally limits their potential. In this work, Weintroduce MAPLE (Modality-Aligned Preference Learning for Embeddings), a novelframework that leverages the fine grained alignment priors inherent in MLLM toguide cross modal representation learning. MAPLE formulates the learningprocess as reinforcement learning with two key components: (1) Automaticpreference data construction using off-the-shelf MLLM, and (2) a new RelativePreference Alignment (RPA) loss, which adapts Direct Preference Optimization(DPO) to the embedding learning setting. Experimental results show that ourpreference-guided alignment achieves substantial gains in fine-grainedcross-modal retrieval, underscoring its effectiveness in handling nuancedsemantic distinctions.</description>
      <author>example@mail.com (Pengfei Zhao, Rongbo Luan, Wei Zhang, Peng Wu, Sifeng He)</author>
      <guid isPermaLink="false">2506.06970v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Prime the search: Using large language models for guiding geometric task and motion planning by warm-starting tree search</title>
      <link>http://arxiv.org/abs/2506.07062v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The International Journal of Robotics Research (IJRR)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用大型语言模型（LLMs）指导几何任务与运动规划（G-TAMP）问题的方法，通过设计基于谓词的提示来帮助LLMs进行几何推理，并结合蒙特卡洛树搜索（MCTS）进行任务规划。&lt;h4&gt;背景&lt;/h4&gt;G-TAMP问题通常需要大量计算资源或数据来指导搜索，而人类通过常识直觉解决问题。传统方法依赖于领域无关的启发式或从规划经验中学习。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用LLMs的G-TAMP问题解决方法，以减少计算资源需求。&lt;h4&gt;方法&lt;/h4&gt;设计基于谓词的提示帮助LLMs进行几何推理，结合MCTS进行任务规划，并使用LLMs引导搜索过程。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在六个不同的G-TAMP问题上优于之前的LLM规划器和纯搜索算法。&lt;h4&gt;结论&lt;/h4&gt;LLMs可以有效地指导G-TAMP问题的任务规划，结合MCTS可以进一步提高搜索效率。&lt;h4&gt;翻译&lt;/h4&gt;The problem of relocating a set of objects to designated areas amidst movable obstacles can be framed as a Geometric Task and Motion Planning (G-TAMP) problem, a subclass of task and motion planning (TAMP). Traditional approaches to G-TAMP have relied either on domain-independent heuristics or on learning from planning experience to guide the search, both of which typically demand significant computational resources or data. In contrast, humans often use common sense to intuitively decide which objects to manipulate in G-TAMP problems. Inspired by this, we propose leveraging Large Language Models (LLMs), which have common sense knowledge acquired from internet-scale data, to guide task planning in G-TAMP problems. To enable LLMs to perform geometric reasoning, we design a predicate-based prompt that encodes geometric information derived from a motion planning algorithm. We then query the LLM to generate a task plan, which is then used to search for a feasible set of continuous parameters. Since LLMs are prone to mistakes, instead of committing to LLM's outputs, we extend Monte Carlo Tree Search (MCTS) to a hybrid action space and use the LLM to guide the search. Unlike the previous approach that calls an LLM at every node and incurs high computational costs, we use it to warm-start the MCTS with the nodes explored in completing the LLM's task plan. On six different G-TAMP problems, we show our method outperforms previous LLM planners and pure search algorithms. Code can be found at: https://github.com/iMSquared/prime-the-search&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1177/02783649251347307&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The problem of relocating a set of objects to designated areas amidst movableobstacles can be framed as a Geometric Task and Motion Planning (G-TAMP)problem, a subclass of task and motion planning (TAMP). Traditional approachesto G-TAMP have relied either on domain-independent heuristics or on learningfrom planning experience to guide the search, both of which typically demandsignificant computational resources or data. In contrast, humans often usecommon sense to intuitively decide which objects to manipulate in G-TAMPproblems. Inspired by this, we propose leveraging Large Language Models (LLMs),which have common sense knowledge acquired from internet-scale data, to guidetask planning in G-TAMP problems. To enable LLMs to perform geometricreasoning, we design a predicate-based prompt that encodes geometricinformation derived from a motion planning algorithm. We then query the LLM togenerate a task plan, which is then used to search for a feasible set ofcontinuous parameters. Since LLMs are prone to mistakes, instead of committingto LLM's outputs, we extend Monte Carlo Tree Search (MCTS) to a hybrid actionspace and use the LLM to guide the search. Unlike the previous approach thatcalls an LLM at every node and incurs high computational costs, we use it towarm-start the MCTS with the nodes explored in completing the LLM's task plan.On six different G-TAMP problems, we show our method outperforms previous LLMplanners and pure search algorithms. Code can be found at:https://github.com/iMSquared/prime-the-search</description>
      <author>example@mail.com (Dongryung Lee, Sejune Joo, Kimin Lee, Beomjoon Kim)</author>
      <guid isPermaLink="false">2506.07062v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>MAGNet: A Multi-Scale Attention-Guided Graph Fusion Network for DRC Violation Detection</title>
      <link>http://arxiv.org/abs/2506.07126v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 12 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MAGNet的混合深度学习模型，用于集成电路设计的DRC违规预测，通过结合U-Net和图神经网络来提高DRC的热点检测准确性。&lt;h4&gt;背景&lt;/h4&gt;DRC对于集成电路设计的成本降低和设计效率提升具有重要意义，机器学习在计算机辅助设计（CAD）中扮演着重要角色。&lt;h4&gt;目的&lt;/h4&gt;旨在通过MAGNet模型提高DRC违规预测的准确性和减少误报率。&lt;h4&gt;方法&lt;/h4&gt;MAGNet模型通过增强U-Net的动态注意力模块（DAM）和多尺度卷积模块（MSCM）来提取精细和多尺度的空间特征。同时，基于芯片布局的图结构，应用专用图神经网络（GNN）来模拟引脚之间的拓扑关系。在图构建过程中，生成图到网格的映射以对齐GNN特征和布局图像。此外，在训练期间采用标签增强策略以提高模型对稀疏违规模式的敏感性。&lt;h4&gt;主要发现&lt;/h4&gt;MAGNet有效结合了空间、语义和结构信息，在DRC热点检测中实现了更高的预测准确性和更低的误报率。通过增量训练，模型对热点的区分能力进一步增强。&lt;h4&gt;结论&lt;/h4&gt;MAGNet在整体性能上显著优于ibUnet、RouteNet和J-Net等模型，实现了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：设计规则检查（DRC）在集成电路（IC）设计中对于降低成本和提高设计效率具有重大意义。基于机器学习的DRC已成为计算机辅助设计（CAD）中的重要方法。在本文中，我们提出了一种名为MAGNet的混合深度学习模型，它集成了一个改进的U-Net和一个图神经网络，用于DRC违规预测。U-Net主干通过动态注意力模块（DAM）和多尺度卷积模块（MSCM）的增强来加强其提取细粒度和多尺度空间特征的能力。同时，基于芯片布局的图结构，应用专用图神经网络（GNN）来模拟引脚之间的拓扑关系。在图构建过程中，生成图到网格的映射以对齐GNN特征和布局图像。此外，在训练期间采用标签增强策略以提高模型对稀疏违规模式的敏感性。总体而言，MAGNet有效地结合了空间、语义和结构信息，在DRC热点检测中实现了提高的预测准确性和降低的误报率。随后，通过增量训练，实现了对热点更敏感的区分能力。结果表明，与ibUnet、RouteNet和J-Net相比，MAGnet在这些模型中表现显著优于，实现了整体性能的显著提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Design rule checking (DRC) is of great significance for cost reduction anddesign efficiency improvement in integrated circuit (IC) designs.Machine-learning-based DRC has become an important approach in computer-aideddesign (CAD). In this paper, we propose MAGNet, a hybrid deep learning modelthat integrates an improved U-Net with a graph neural network for DRC violationprediction. The U-Net backbone is enhanced with a Dynamic Attention Module(DAM) and a Multi-Scale Convolution Module (MSCM) to strengthen its capabilityin extracting fine-grained and multi-scale spatial features. In parallel, weconstruct a pixel-aligned graph structure based on chip layout tiles, and applya specialized GNN to model the topological relationships among pins. Duringgraph construction, a graph-to-grid mapping is generated to align GNN featureswith the layout image. In addition, a label amplification strategy is adoptedduring training to enhance the model's sensitivity to sparse violationpatterns. Overall, MAGNet effectively combines spatial, semantic, andstructural information, achieving improved prediction accuracy and reducedfalse positive rates in DRC hotspot detection. Subsequently, throughincremental training, we achieve a more sensitive discrimination ability forhotspots. The results demonstrate that, in comparison with ibUnet, RouteNet,and J-Net, MAGnet significantly outperforms these models, achieving substantialimprovements in overall performance.</description>
      <author>example@mail.com (Weihan Lu, Hong Cai Chen)</author>
      <guid isPermaLink="false">2506.07126v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Cross-channel Perception Learning for H&amp;E-to-IHC Virtual Staining</title>
      <link>http://arxiv.org/abs/2506.07559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CCPL的新型跨通道感知学习策略，用于数字病理学中的虚拟染色，以改善病理图像的分析和诊断。&lt;h4&gt;背景&lt;/h4&gt;随着数字病理学的快速发展，虚拟染色成为多媒体医学信息系统中的一项关键技术。然而，现有的H&amp;E到IHC研究往往忽略了细胞核和细胞膜之间的跨通道相关性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，提出了CCPL策略，以改善虚拟染色图像的质量，并支持自动病理诊断。&lt;h4&gt;方法&lt;/h4&gt;CCPL首先将HER2免疫组织化学染色分解为对应细胞核和细胞膜的Hematoxylin和DAB染色通道。利用Gigapath的Tile Encoder提取双通道特征，并测量核和膜之间的跨通道相关性。同时，通过Tile Encoder计算生成和真实染色图像的特征蒸馏损失，增强模型特征提取能力。此外，CCPL对单通道的焦点光学密度图进行统计分析，以确保染色分布和强度的统一。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CCPL有效地保留了病理特征，生成了高质量的虚拟染色图像，并为使用多媒体医学数据进行的自动病理诊断提供了强有力的支持。&lt;h4&gt;结论&lt;/h4&gt;CCPL是一种有效的虚拟染色技术，能够提高病理图像分析的诊断准确性，为病理学领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of digital pathology, virtual staining has becomea key technology in multimedia medical information systems, offering newpossibilities for the analysis and diagnosis of pathological images. However,existing H&amp;E-to-IHC studies often overlook the cross-channel correlationsbetween cell nuclei and cell membranes. To address this issue, we propose anovel Cross-Channel Perception Learning (CCPL) strategy. Specifically, CCPLfirst decomposes HER2 immunohistochemical staining into Hematoxylin and DABstaining channels, corresponding to cell nuclei and cell membranes,respectively. Using the pathology foundation model Gigapath's Tile Encoder,CCPL extracts dual-channel features from both the generated and real images andmeasures cross-channel correlations between nuclei and membranes. The featuresof the generated and real stained images, obtained through the Tile Encoder,are also used to calculate feature distillation loss, enhancing the model'sfeature extraction capabilities without increasing the inference burden.Additionally, CCPL performs statistical analysis on the focal optical densitymaps of both single channels to ensure consistency in staining distribution andintensity. Experimental results, based on quantitative metrics such as PSNR,SSIM, PCC, and FID, along with professional evaluations from pathologists,demonstrate that CCPL effectively preserves pathological features, generateshigh-quality virtual stained images, and provides robust support for automatedpathological diagnosis using multimedia medical data.</description>
      <author>example@mail.com (Hao Yang, JianYu Wu, Run Fang, Xuelian Zhao, Yuan Ji, Zhiyu Chen, Guibin He, Junceng Guo, Yang Liu, Xinhua Zeng)</author>
      <guid isPermaLink="false">2506.07559v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction</title>
      <link>http://arxiv.org/abs/2506.07002v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Two-page abstract version available at CVPR 2025 Embodied AI Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的3D占用预测方法BePo，用于场景理解，以支持自动驾驶。&lt;h4&gt;背景&lt;/h4&gt;现有的3D占用预测方法计算成本高，需要密集的3D特征体积和交叉注意力来有效聚合信息。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法的问题，BePo结合了鸟瞰图（BEV）和稀疏点表示。&lt;h4&gt;方法&lt;/h4&gt;BePo采用双分支设计：一个基于查询的稀疏点分支和一个BEV分支。稀疏点分支中学习的3D信息通过交叉注意力与BEV流共享，丰富了BEV平面上困难物体的弱信号。两个分支的输出最终融合以生成预测的3D占用。&lt;h4&gt;主要发现&lt;/h4&gt;在Occ3D-nuScenes和Occ3D-Waymo基准上进行的大量实验表明，BePo在性能上优于现有方法，并且在推理速度上与最新高效方法具有竞争力。&lt;h4&gt;结论&lt;/h4&gt;BePo是一种有效的3D占用预测方法，适用于自动驾驶和场景理解，同时保持了较高的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D occupancy provides fine-grained 3D geometry and semantics for sceneunderstanding which is critical for autonomous driving. Most existing methods,however, carry high compute costs, requiring dense 3D feature volume andcross-attention to effectively aggregate information. More recent works haveadopted Bird's Eye View (BEV) or sparse points as scene representation withmuch reduced cost, but still suffer from their respective shortcomings. Moreconcretely, BEV struggles with small objects that often experience significantinformation loss after being projected to the ground plane. On the other hand,points can flexibly model little objects in 3D, but is inefficient at capturingflat surfaces or large objects. To address these challenges, in this paper, wepresent a novel 3D occupancy prediction approach, BePo, which combines BEV andsparse points based representations. We propose a dual-branch design: aquery-based sparse points branch and a BEV branch. The 3D information learnedin the sparse points branch is shared with the BEV stream via cross-attention,which enriches the weakened signals of difficult objects on the BEV plane. Theoutputs of both branches are finally fused to generate predicted 3D occupancy.We conduct extensive experiments on the Occ3D-nuScenes and Occ3D-Waymobenchmarks that demonstrate the superiority of our proposed BePo. Moreover,BePo also delivers competitive inference speed when compared to the latestefficient approaches.</description>
      <author>example@mail.com (Yunxiao Shi, Hong Cai, Jisoo Jeong, Yinhao Zhu, Shizhong Han, Amin Ansari, Fatih Porikli)</author>
      <guid isPermaLink="false">2506.07002v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>A Culturally-diverse Multilingual Multimodal Video Benchmark &amp; Model</title>
      <link>http://arxiv.org/abs/2506.07032v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ViMUL-Bench，一个多语言视频多模态模型（LMM）基准，用于评估不同语言环境下的视频LMM性能。&lt;h4&gt;背景&lt;/h4&gt;现有的视频LMM大多使用英语，而多语言视频LMM的研究尚不充分。&lt;h4&gt;目的&lt;/h4&gt;开发一个多语言视频LMM基准，以促进文化语言包容性的视频LMM研究。&lt;h4&gt;方法&lt;/h4&gt;ViMUL-Bench包含14种语言的数据，涵盖15个类别，包括生活方式、节日、食物、仪式、地标和文化名人等。它包含开放式和多项选择题，视频时长从短到长，共有8k个样本，由母语者人工验证。此外，还引入了一个包含120万个样本的机器翻译多语言视频训练集，并开发了一个名为ViMUL的简单多语言视频LMM。&lt;h4&gt;主要发现&lt;/h4&gt;ViMUL-Bench和ViMUL多语言视频LMM有助于在不同资源语言之间提供更好的平衡，以实现视频理解。&lt;h4&gt;结论&lt;/h4&gt;ViMUL-Bench和相关的多语言视频LMM以及大规模多语言视频训练集将为未来研究文化语言包容性的多语言视频LMM提供便利。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译为中文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large multimodal models (LMMs) have recently gained attention due to theireffectiveness to understand and generate descriptions of visual content. Mostexisting LMMs are in English language. While few recent works exploremultilingual image LMMs, to the best of our knowledge, moving beyond theEnglish language for cultural and linguistic inclusivity is yet to beinvestigated in the context of video LMMs. In pursuit of more inclusive videoLMMs, we introduce a multilingual Video LMM benchmark, named ViMUL-Bench, toevaluate Video LMMs across 14 languages, including both low- and high-resourcelanguages: English, Chinese, Spanish, French, German, Hindi, Arabic, Russian,Bengali, Urdu, Sinhala, Tamil, Swedish, and Japanese. Our ViMUL-Bench isdesigned to rigorously test video LMMs across 15 categories including eightculturally diverse categories, ranging from lifestyles and festivals to foodsand rituals and from local landmarks to prominent cultural personalities.ViMUL-Bench comprises both open-ended (short and long-form) and multiple-choicequestions spanning various video durations (short, medium, and long) with 8ksamples that are manually verified by native language speakers. In addition, wealso introduce a machine translated multilingual video training set comprising1.2 million samples and develop a simple multilingual video LMM, named ViMUL,that is shown to provide a better tradeoff between high-and low-resourcelanguages for video understanding. We hope our ViMUL-Bench and multilingualvideo LMM along with a large-scale multilingual video training set will helpease future research in developing cultural and linguistic inclusivemultilingual video LMMs. Our proposed benchmark, video LMM and training datawill be publicly released at https://mbzuai-oryx.github.io/ViMUL/.</description>
      <author>example@mail.com (Bhuiyan Sanjid Shafique, Ashmal Vayani, Muhammad Maaz, Hanoona Abdul Rasheed, Dinura Dissanayake, Mohammed Irfan Kurpath, Yahya Hmaiti, Go Inoue, Jean Lahoud, Md. Safirur Rashid, Shadid Intisar Quasem, Maheen Fatima, Franco Vidal, Mykola Maslych, Ketan Pravin More, Sanoojan Baliah, Hasindri Watawana, Yuhao Li, Fabian Farestam, Leon Schaller, Roman Tymtsiv, Simon Weber, Hisham Cholakkal, Ivan Laptev, Shin'ichi Satoh, Michael Felsberg, Mubarak Shah, Salman Khan, Fahad Shahbaz Khan)</author>
      <guid isPermaLink="false">2506.07032v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Full Conformal Adaptation of Medical Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.06076v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IPMI 2025. Code: https://github.com/jusiro/FCA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了大规模预训练的视觉语言模型（VLMs）在医学图像分析中的应用，特别是在分割对齐预测（SCP）框架下的可靠性。&lt;h4&gt;背景&lt;/h4&gt;大规模预训练的VLMs在医学图像分析中具有广泛的迁移能力，但其可靠性方面尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;探讨VLMs在SCP框架下的行为，并提出解决方案以提高其可靠性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种全新的方法，即全对齐适应，通过少量数据集对预训练模型进行联合适应和对齐。同时，使用SS-Text线性探针求解器减轻计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;该方法需要与SCP相同的数据，在集合效率上提供高达27%的相对改进，同时保持相同的覆盖率保证。&lt;h4&gt;结论&lt;/h4&gt;全对齐适应和SS-Text可以有效提高VLMs在SCP框架下的可靠性和性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the application of large-scale pre-trained vision-language models (VLMs) in medical image analysis, particularly under the split conformal prediction (SCP) framework, and proposes a novel approach to improve their reliability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models (VLMs) pre-trained at large scale have shownunprecedented transferability capabilities and are being progressivelyintegrated into medical image analysis. Although its discriminative potentialhas been widely explored, its reliability aspect remains overlooked. This workinvestigates their behavior under the increasingly popular split conformalprediction (SCP) framework, which theoretically guarantees a given error levelon output sets by leveraging a labeled calibration set. However, the zero-shotperformance of VLMs is inherently limited, and common practice involvesfew-shot transfer learning pipelines, which cannot absorb the rigidexchangeability assumptions of SCP. To alleviate this issue, we propose fullconformal adaptation, a novel setting for jointly adapting and conformalizingpre-trained foundation models, which operates transductively over each testdata point using a few-shot adaptation set. Moreover, we complement thisframework with SS-Text, a novel training-free linear probe solver for VLMs thatalleviates the computational cost of such a transductive approach. We providecomprehensive experiments using 3 different modality-specialized medical VLMsand 9 adaptation tasks. Our framework requires exactly the same data as SCP,and provides consistent relative improvements of up to 27% on set efficiencywhile maintaining the same coverage guarantees.</description>
      <author>example@mail.com (Julio Silva-Rodríguez, Leo Fillioux, Paul-Henry Cournède, Maria Vakalopoulou, Stergios Christodoulidis, Ismail Ben Ayed, Jose Dolz)</author>
      <guid isPermaLink="false">2506.06076v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Graph-Based Physics-Guided Urban PM2.5 Air Quality Imputation with Constrained Monitoring Data</title>
      <link>http://arxiv.org/abs/2506.06917v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACM Transactions on Sensor Networks (TOSN) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GraPhy的基于图和物理指导的学习框架，用于在监测数据有限的城区进行高分辨率和精确的空气质量建模。&lt;h4&gt;背景&lt;/h4&gt;精细的空气质量监测信息对于减少公众接触污染物至关重要，但在社会经济条件较差的地区，监测网络通常较为稀疏，限制了空气质量建模的准确性和分辨率。&lt;h4&gt;目的&lt;/h4&gt;为了解决这个问题，研究者提出了一个名为GraPhy的物理指导图神经网络架构，该架构针对低分辨率监测数据设计了特定层次和边缘特征。&lt;h4&gt;方法&lt;/h4&gt;使用加利福尼亚社会经济条件较差的圣华金谷的数据进行实验，评估了GraPhy的性能，比较了均方误差（MSE）、平均绝对误差（MAE）和R平方值（R2），并与各种基线模型进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，GraPhy在MSE、MAE和R2方面均取得了最佳的整体性能，与基线模型相比，性能提升了9%-56%。此外，GraPhy在不同空间异质性水平上均优于基线模型，证明了模型设计的效果。&lt;h4&gt;结论&lt;/h4&gt;GraPhy框架能够有效提高空气质量建模的准确性和分辨率，尤其是在监测数据稀疏的地区。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3734869&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work introduces GraPhy, a graph-based, physics-guided learning frameworkfor high-resolution and accurate air quality modeling in urban areas withlimited monitoring data. Fine-grained air quality monitoring information isessential for reducing public exposure to pollutants. However, monitoringnetworks are often sparse in socioeconomically disadvantaged regions, limitingthe accuracy and resolution of air quality modeling. To address this, wepropose a physics-guided graph neural network architecture called GraPhy withlayers and edge features designed specifically for low-resolution monitoringdata. Experiments using data from California's socioeconomically disadvantagedSan Joaquin Valley show that GraPhy achieves the overall best performanceevaluated by mean squared error (MSE), mean absolute error (MAE), and R-squarevalue (R2), improving the performance by 9%-56% compared to various baselinemodels. Moreover, GraPhy consistently outperforms baselines across differentspatial heterogeneity levels, demonstrating the effectiveness of our modeldesign.</description>
      <author>example@mail.com (Shangjie Du, Hui Wei, Dong Yoon Lee, Zhizhang Hu, Shijia Pan)</author>
      <guid isPermaLink="false">2506.06917v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>APTOS-2024 challenge report: Generation of synthetic 3D OCT images from fundus photographs</title>
      <link>http://arxiv.org/abs/2506.07542v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了APTOS-2024挑战赛，旨在推动基于人工智能的视网膜图像到3D光学相干断层扫描（OCT）图像的生成技术，以提高眼科诊疗的可及性。&lt;h4&gt;背景&lt;/h4&gt;OCT技术在眼科疾病诊断中至关重要，但其成本较高，限制了其普及。2D彩色眼底摄影虽然成本较低，但无法提供OCT的高分辨率3D图像。&lt;h4&gt;目的&lt;/h4&gt;通过APTOS-2024挑战赛，探索将2D眼底图像转换为3D OCT图像的可行性，以提升眼科诊疗的可及性。&lt;h4&gt;方法&lt;/h4&gt;APTOS-2024挑战赛包括基准数据集、评估方法和顶尖解决方案分析。评估方法包括基于图像的相似度和基于视频的体积一致性。&lt;h4&gt;主要发现&lt;/h4&gt;挑战吸引了342个团队参与，其中9个团队进入决赛。领先的解决方案采用了混合数据预处理、外部眼科成像数据集预训练、视觉基础模型集成和模型架构改进等创新方法。&lt;h4&gt;结论&lt;/h4&gt;APTOS-2024挑战赛证明了眼底图像到3D OCT图像合成的可行性，这可能是提高眼科诊疗在资源匮乏的医疗环境中可及性的潜在解决方案，同时有助于加速医学研究和临床应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optical Coherence Tomography (OCT) provides high-resolution, 3D, andnon-invasive visualization of retinal layers in vivo, serving as a criticaltool for lesion localization and disease diagnosis. However, its widespreadadoption is limited by equipment costs and the need for specialized operators.In comparison, 2D color fundus photography offers faster acquisition andgreater accessibility with less dependence on expensive devices. Althoughgenerative artificial intelligence has demonstrated promising results inmedical image synthesis, translating 2D fundus images into 3D OCT imagespresents unique challenges due to inherent differences in data dimensionalityand biological information between modalities. To advance generative models inthe fundus-to-3D-OCT setting, the Asia Pacific Tele-Ophthalmology Society(APTOS-2024) organized a challenge titled Artificial Intelligence-based OCTGeneration from Fundus Images. This paper details the challenge framework(referred to as APTOS-2024 Challenge), including: the benchmark dataset,evaluation methodology featuring two fidelity metrics-image-based distance(pixel-level OCT B-scan similarity) and video-based distance (semantic-levelvolumetric consistency), and analysis of top-performing solutions. Thechallenge attracted 342 participating teams, with 42 preliminary submissionsand 9 finalists. Leading methodologies incorporated innovations in hybrid datapreprocessing or augmentation (cross-modality collaborative paradigms),pre-training on external ophthalmic imaging datasets, integration of visionfoundation models, and model architecture improvement. The APTOS-2024 Challengeis the first benchmark demonstrating the feasibility of fundus-to-3D-OCTsynthesis as a potential solution for improving ophthalmic care accessibilityin under-resourced healthcare settings, while helping to expedite medicalresearch and clinical applications.</description>
      <author>example@mail.com (Bowen Liu, Weiyi Zhang, Peranut Chotcomwongse, Xiaolan Chen, Ruoyu Chen, Pawin Pakaymaskul, Niracha Arjkongharn, Nattaporn Vongsa, Xuelian Cheng, Zongyuan Ge, Kun Huang, Xiaohui Li, Yiru Duan, Zhenbang Wang, BaoYe Xie, Qiang Chen, Huazhu Fu, Michael A. Mahr, Jiaqi Qu, Wangyiyang Chen, Shiye Wang, Yubo Tan, Yongjie Li, Mingguang He, Danli Shi, Paisan Ruamviboonsuk)</author>
      <guid isPermaLink="false">2506.07542v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>IRS: Instance-Level 3D Scene Graphs via Room Prior Guided LiDAR-Camera Fusion</title>
      <link>http://arxiv.org/abs/2506.06804v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于激光雷达-相机融合的实例级3D场景图构建框架，通过视觉基础模型（VFMs）提高语义提取的准确性和一致性，实现了在开放世界环境中的高效场景理解。&lt;h4&gt;背景&lt;/h4&gt;室内场景理解是机器人领域的基本挑战，对导航和操作等下游任务有直接影响。传统的封闭集识别或闭环检测方法在开放世界环境中的适应性有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种鲁棒且高效的框架，通过LiDAR和相机融合实现实例级3D场景图的构建，提高开放世界环境中的场景理解能力。&lt;h4&gt;方法&lt;/h4&gt;利用LiDAR的广角视野和长距离传感能力快速获取房间级几何先验；采用多级VFMs提高语义提取的准确性和一致性；基于房间分割实现实例融合的并行处理；结合几何和语义线索提高融合的准确性和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，该方法在构建速度上提高了约一个数量级，同时保持了高语义精度。&lt;h4&gt;结论&lt;/h4&gt;通过模拟和真实环境的大量实验验证了该方法的有效性，并通过语言引导的语义导航任务展示了其实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Indoor scene understanding remains a fundamental challenge in robotics, with direct implications for downstream tasks such as navigation and manipulation. Traditional approaches often rely on closed-set recognition or loop closure, limiting their adaptability in open-world environments. With the advent of visual foundation models (VFMs), open-vocabulary recognition and natural language querying have become feasible, unlocking new possibilities for 3D scene graph construction. In this paper, we propose a robust and efficient framework for instance-level 3D scene graph construction via LiDAR-camera fusion. Leveraging LiDAR's widefield of view (FOV) and long-range sensing capabilities, we rapidly acquire room-level geometric priors. Multi-level VFMs are employed to improve the accuracy and consistency of semantic extraction. During instance fusion, room-based segmentation enables parallel processing, while the integration of geometric and semantic cues significantly enhances fusion accuracy and robustness. Compared to state-of-the-art methods, our approach achieves up to an order-of-magnitude improvement in construction speed while maintaining high semantic precision. Extensive experiments in both simulated and real-world environments validate the effectiveness of our approach. We further demonstrate its practical value through a language-guided semantic navigation task, highlighting its potential for real-world robotic applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Indoor scene understanding remains a fundamental challenge in robotics, withdirect implications for downstream tasks such as navigation and manipulation.Traditional approaches often rely on closed-set recognition or loop closure,limiting their adaptability in open-world environments. With the advent ofvisual foundation models (VFMs), open-vocabulary recognition and naturallanguage querying have become feasible, unlocking new possibilities for 3Dscene graph construction.  In this paper, we propose a robust and efficient framework for instance-level3D scene graph construction via LiDAR-camera fusion. Leveraging LiDAR's widefield of view (FOV) and long-range sensing capabilities, we rapidly acquireroom-level geometric priors. Multi-level VFMs are employed to improve theaccuracy and consistency of semantic extraction. During instance fusion,room-based segmentation enables parallel processing, while the integration ofgeometric and semantic cues significantly enhances fusion accuracy androbustness. Compared to state-of-the-art methods, our approach achieves up toan order-of-magnitude improvement in construction speed while maintaining highsemantic precision.  Extensive experiments in both simulated and real-world environments validatethe effectiveness of our approach. We further demonstrate its practical valuethrough a language-guided semantic navigation task, highlighting its potentialfor real-world robotic applications.</description>
      <author>example@mail.com (Hongming Chen, Yiyang Lin, Ziliang Li, Biyu Ye, Yuying Zhang, Ximin Lyu)</author>
      <guid isPermaLink="false">2506.06804v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>TerraFM: A Scalable Foundation Model for Unified Multisensor Earth Observation</title>
      <link>http://arxiv.org/abs/2506.06281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TerraFM是一个可扩展的自监督学习模型，利用全球分布的Sentinel-1和Sentinel-2影像，通过大空间瓦片和土地覆盖意识采样来丰富空间和语义覆盖。该模型在分类和分割任务上表现出强大的泛化能力，在GEO-Bench和Copernicus-Bench上优于先前模型。&lt;h4&gt;背景&lt;/h4&gt;现代地球观测越来越多地利用深度学习来利用卫星影像的规模和多样性。尽管最近的基础模型在地球观测任务中表现出有希望的泛化能力，但许多模型仍受限于其训练数据的规模、地理覆盖和光谱多样性，这些因素对于学习可全球转移的表示至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出TerraFM模型，旨在解决当前深度学习模型在地球观测任务中存在的泛化能力不足的问题。&lt;h4&gt;方法&lt;/h4&gt;TerraFM模型通过以下方法实现其目标：1）利用全球分布的Sentinel-1和Sentinel-2影像；2）采用大空间瓦片和土地覆盖意识采样；3）将雷达和光学输入通过模态特定的补丁嵌入和自适应交叉注意力融合；4）结合局部-全局对比学习，并引入双中心机制，结合类频率感知正则化来解决土地覆盖中的长尾分布。&lt;h4&gt;主要发现&lt;/h4&gt;TerraFM在分类和分割任务上实现了强大的泛化能力，在GEO-Bench和Copernicus-Bench上优于先前模型。&lt;h4&gt;结论&lt;/h4&gt;TerraFM模型是一个有效的工具，可以提高地球观测任务的性能，并在全球范围内具有可转移性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代地球观测（EO）越来越多地利用深度学习来利用卫星影像的规模和多样性。虽然最近的基础模型在EO任务中展示了有希望的泛化能力，但许多模型仍然受限于其训练数据的规模、地理覆盖和光谱多样性，这些因素对于学习可全球转移的表示至关重要。在这项工作中，我们介绍了TerraFM，一个可扩展的自监督学习模型，它利用全球分布的Sentinel-1和Sentinel-2影像，结合大型空间瓦片和土地覆盖意识采样来丰富空间和语义覆盖。通过将传感模式视为自监督方法中的自然增强，我们通过模态特定的补丁嵌入和自适应交叉注意力融合统一了雷达和光学输入。我们的训练策略结合了局部-全局对比学习，并引入了一个双重中心机制，该机制结合了类频率感知正则化来解决土地覆盖中的长尾分布。TerraFM在分类和分割任务上实现了强大的泛化能力，在GEO-Bench和Copernicus-Bench上优于先前模型。我们的代码和预训练模型可在以下链接公开获取：https://github.com/mbzuai-oryx/TerraFM 。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern Earth observation (EO) increasingly leverages deep learning to harnessthe scale and diversity of satellite imagery across sensors and regions. Whilerecent foundation models have demonstrated promising generalization across EOtasks, many remain limited by the scale, geographical coverage, and spectraldiversity of their training data, factors critical for learning globallytransferable representations. In this work, we introduce TerraFM, a scalableself-supervised learning model that leverages globally distributed Sentinel-1and Sentinel-2 imagery, combined with large spatial tiles and land-cover awaresampling to enrich spatial and semantic coverage. By treating sensingmodalities as natural augmentations in our self-supervised approach, we unifyradar and optical inputs via modality-specific patch embeddings and adaptivecross-attention fusion. Our training strategy integrates local-globalcontrastive learning and introduces a dual-centering mechanism thatincorporates class-frequency-aware regularization to address long-taileddistributions in land cover.TerraFM achieves strong generalization on bothclassification and segmentation tasks, outperforming prior models on GEO-Benchand Copernicus-Bench. Our code and pretrained models are publicly available at:https://github.com/mbzuai-oryx/TerraFM .</description>
      <author>example@mail.com (Muhammad Sohail Danish, Muhammad Akhtar Munir, Syed Roshaan Ali Shah, Muhammad Haris Khan, Rao Muhammad Anwer, Jorma Laaksonen, Fahad Shahbaz Khan, Salman Khan)</author>
      <guid isPermaLink="false">2506.06281v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>KNN-Defense: Defense against 3D Adversarial Point Clouds using Nearest-Neighbor Search</title>
      <link>http://arxiv.org/abs/2506.06906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为KNN-Defense的防御策略，用于增强3D点云分类器的对抗鲁棒性，并展示了其在ModelNet40数据集上的有效性。&lt;h4&gt;背景&lt;/h4&gt;深度神经网络在分析3D点云数据方面表现出色，但其易受对抗攻击的影响，这些攻击会损害点云的语义和结构完整性。&lt;h4&gt;目的&lt;/h4&gt;提出KNN-Defense以解决3D视觉系统对抗攻击的脆弱性问题。&lt;h4&gt;方法&lt;/h4&gt;KNN-Defense基于流形假设和特征空间中的最近邻搜索，通过利用训练集中邻近样本的语义相似性来恢复受干扰的输入。&lt;h4&gt;主要发现&lt;/h4&gt;KNN-Defense在多种攻击类型下显著提高了鲁棒性，尤其是在点去除攻击中，与现有方法相比，KNN-Defense在PointNet、PointNet++、DGCNN和PCT上的准确率分别提高了20.1%、3.6%、3.44%和7.74%。&lt;h4&gt;结论&lt;/h4&gt;KNN-Defense提供了一种可扩展且有效的解决方案，用于增强3D点云分类器的对抗鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：深度神经网络（DNNs）在分析3D点云数据方面表现出色。然而，它们容易受到对抗攻击（如点删除、移动和添加）的影响，这给3D视觉系统的可靠性带来了重大挑战。这些攻击会破坏点云的语义和结构完整性，使许多现有防御机制失效。为了解决这个问题，提出了一种名为KNN-Defense的防御策略，其基于流形假设和特征空间中的最近邻搜索。该方法不是通过重建表面几何形状或强制执行均匀的点分布，而是通过利用训练集中邻近样本的语义相似性来恢复受干扰的输入。KNN-Defense轻量级且计算效率高，可以实现快速推理，非常适合实时和实际应用。在ModelNet40数据集上的实证结果表明，KNN-Defense在各种攻击类型下显著提高了鲁棒性。特别是在点删除攻击中——由于关键点的针对性删除，许多现有方法表现不佳——该方法在PointNet、PointNet++、DGCNN和PCT上分别实现了20.1%、3.6%、3.44%和7.74%的准确率提升。这些发现表明，KNN-Defense为增强3D点云分类器的对抗鲁棒性提供了一种可扩展且有效的解决方案。（该方法的开源实现，包括代码和数据，可在https://github.com/nimajam41/3d-knn-defense上获得。)&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks (DNNs) have demonstrated remarkable performance inanalyzing 3D point cloud data. However, their vulnerability to adversarialattacks-such as point dropping, shifting, and adding-poses a critical challengeto the reliability of 3D vision systems. These attacks can compromise thesemantic and structural integrity of point clouds, rendering many existingdefense mechanisms ineffective. To address this issue, a defense strategy namedKNN-Defense is proposed, grounded in the manifold assumption andnearest-neighbor search in feature space. Instead of reconstructing surfacegeometry or enforcing uniform point distributions, the method restoresperturbed inputs by leveraging the semantic similarity of neighboring samplesfrom the training set. KNN-Defense is lightweight and computationallyefficient, enabling fast inference and making it suitable for real-time andpractical applications. Empirical results on the ModelNet40 datasetdemonstrated that KNN-Defense significantly improves robustness across variousattack types. In particular, under point-dropping attacks-where many existingmethods underperform due to the targeted removal of critical points-theproposed method achieves accuracy gains of 20.1%, 3.6%, 3.44%, and 7.74% onPointNet, PointNet++, DGCNN, and PCT, respectively. These findings suggest thatKNN-Defense offers a scalable and effective solution for enhancing theadversarial resilience of 3D point cloud classifiers. (An open-sourceimplementation of the method, including code and data, is available athttps://github.com/nimajam41/3d-knn-defense).</description>
      <author>example@mail.com (Nima Jamali, Matina Mahdizadeh Sani, Hanieh Naderi, Shohreh Kasaei)</author>
      <guid isPermaLink="false">2506.06906v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Multidimensional Analysis of Specific Language Impairment Using Unsupervised Learning Through PCA and Clustering</title>
      <link>http://arxiv.org/abs/2506.05498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 3 figures, 16 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究通过无监督机器学习技术，分析了儿童自然语言发展轨迹，以识别SLI（特定语言障碍）和正常儿童的语言特征，为早期识别和针对性干预提供见解。&lt;h4&gt;背景&lt;/h4&gt;SLI影响大约7%的儿童，表现为孤立的语言缺陷，尽管认知能力、感官系统和环境支持正常。&lt;h4&gt;目的&lt;/h4&gt;研究旨在使用无监督机器学习技术，识别有SLI和无SLI儿童的天然语言发展轨迹。&lt;h4&gt;方法&lt;/h4&gt;研究分析了来自三个语料库（Conti-Ramsden 4、ENNI和Gillam）的1,163名4-16岁儿童的叙事样本，使用主成分分析（PCA）和聚类方法，评估了64个语言特征。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现两个主要聚类：（1）高语言产出且SLI发病率低；（2）产出有限但句法复杂性高且SLI发病率高。边界案例表现出中间特征，支持语言能力的连续模型。SLI主要表现为产出能力降低，而非句法复杂性缺陷。&lt;h4&gt;结论&lt;/h4&gt;研究结果挑战了分类诊断框架，并突出了无监督学习技术在细化诊断标准和干预策略方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;This study aims to identify natural language development trajectories in children with and without SLI using unsupervised machine learning techniques, providing insights for early identification and targeted interventions. Narrative samples from 1,163 children aged 4-16 years across three corpora (Conti-Ramsden 4, ENNI, and Gillam) were analyzed using Principal Component Analysis (PCA) and clustering. A total of 64 linguistic features were evaluated to uncover developmental trajectories and distinguish linguistic profiles. Two primary clusters emerged: (1) high language production with low SLI prevalence, and (2) limited production but higher syntactic complexity with higher SLI prevalence. Additionally, boundary cases exhibited intermediate traits, supporting a continuum model of language abilities. Findings suggest SLI manifests primarily through reduced production capacity rather than syntactic complexity deficits. The results challenge categorical diagnostic frameworks and highlight the potential of unsupervised learning techniques for refining diagnostic criteria and intervention strategies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Specific Language Impairment (SLI) affects approximately 7 percent ofchildren, presenting as isolated language deficits despite normal cognitiveabilities, sensory systems, and supportive environments. Traditional diagnosticapproaches often rely on standardized assessments, which may overlook subtledevelopmental patterns. This study aims to identify natural languagedevelopment trajectories in children with and without SLI using unsupervisedmachine learning techniques, providing insights for early identification andtargeted interventions. Narrative samples from 1,163 children aged 4-16 yearsacross three corpora (Conti-Ramsden 4, ENNI, and Gillam) were analyzed usingPrincipal Component Analysis (PCA) and clustering. A total of 64 linguisticfeatures were evaluated to uncover developmental trajectories and distinguishlinguistic profiles. Two primary clusters emerged: (1) high language productionwith low SLI prevalence, and (2) limited production but higher syntacticcomplexity with higher SLI prevalence. Additionally, boundary cases exhibitedintermediate traits, supporting a continuum model of language abilities.Findings suggest SLI manifests primarily through reduced production capacityrather than syntactic complexity deficits. The results challenge categoricaldiagnostic frameworks and highlight the potential of unsupervised learningtechniques for refining diagnostic criteria and intervention strategies.</description>
      <author>example@mail.com (Niruthiha Selvanayagam)</author>
      <guid isPermaLink="false">2506.05498v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks in Modern AI-aided Drug Discovery</title>
      <link>http://arxiv.org/abs/2506.06915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了图神经网络（GNNs）在人工智能辅助药物发现（AIDD）中的应用，包括其在分子建模中的角色、方法基础、代表性应用和最新进展。&lt;h4&gt;背景&lt;/h4&gt;GNNs是深度学习中的拓扑/结构感知模型，通过直接操作分子图，能够学习药物分子的复杂拓扑和几何特征。&lt;h4&gt;目的&lt;/h4&gt;提供GNNs在药物发现中方法基础和代表性应用的全面概述。&lt;h4&gt;方法&lt;/h4&gt;综述了分子性质预测、虚拟筛选、分子生成、生物医学知识图谱构建和合成规划等任务中的应用，并关注了最近的方法进展，如几何GNNs、可解释模型、不确定性量化、可扩展图架构和图生成框架。&lt;h4&gt;主要发现&lt;/h4&gt;讨论了这些模型如何与现代深度学习方法结合，如自监督学习、多任务学习、元学习和预训练，并强调了在将GNNs应用于现实世界药物发现管线时遇到的实践挑战和方法瓶颈。&lt;h4&gt;结论&lt;/h4&gt;讨论了GNNs在药物发现中的未来发展方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs), as topology/structure-aware models within deeplearning, have emerged as powerful tools for AI-aided drug discovery (AIDD). Bydirectly operating on molecular graphs, GNNs offer an intuitive and expressiveframework for learning the complex topological and geometric features ofdrug-like molecules, cementing their role in modern molecular modeling. Thisreview provides a comprehensive overview of the methodological foundations andrepresentative applications of GNNs in drug discovery, spanning tasks such asmolecular property prediction, virtual screening, molecular generation,biomedical knowledge graph construction, and synthesis planning. Particularattention is given to recent methodological advances, including geometric GNNs,interpretable models, uncertainty quantification, scalable graph architectures,and graph generative frameworks. We also discuss how these models integratewith modern deep learning approaches, such as self-supervised learning,multi-task learning, meta-learning and pre-training. Throughout this review, wehighlight the practical challenges and methodological bottlenecks encounteredwhen applying GNNs to real-world drug discovery pipelines, and conclude with adiscussion on future directions.</description>
      <author>example@mail.com (Odin Zhang, Haitao Lin, Xujun Zhang, Xiaorui Wang, Zhenxing Wu, Qing Ye, Weibo Zhao, Jike Wang, Kejun Ying, Yu Kang, Chang-yu Hsieh, Tingjun Hou)</author>
      <guid isPermaLink="false">2506.06915v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>IMPA-HGAE:Intra-Meta-Path Augmented Heterogeneous Graph Autoencoder</title>
      <link>http://arxiv.org/abs/2506.06809v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为IMPA-HGAE的新型框架，用于提升异构图的自监督学习方法，并通过实验验证了其在异构图数据集上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;自监督学习方法因其优越的泛化能力和低标注成本，在多种下游任务中得到了广泛应用。&lt;h4&gt;目的&lt;/h4&gt;针对现有异构图自监督模型将异构图转换为同构图进行训练的局限性，旨在通过充分利用元路径上的内部节点信息来增强目标节点嵌入。&lt;h4&gt;方法&lt;/h4&gt;IMPA-HGAE框架通过创新掩码策略增强生成式自监督模型在异构图数据上的表示能力，并讨论了方法的可解释性和未来研究方向。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，IMPA-HGAE在异构图数据集上取得了优于现有方法的性能。&lt;h4&gt;结论&lt;/h4&gt;IMPA-HGAE为利用元路径引导的结构语义在复杂图场景中进行鲁棒表示学习提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised learning (SSL) methods have been increasingly applied to diverse downstream tasks due to their superior generalization capabilities and low annotation costs. However, most existing heterogeneous graph SSL models convert heterogeneous graphs into homogeneous ones via meta-paths for training, which only leverage information from nodes at both ends of meta-paths while underutilizing the heterogeneous node information along the meta-paths. To address this limitation, this paper proposes a novel framework named IMPA-HGAE to enhance target node embeddings by fully exploiting internal node information along meta-paths. Experimental results validate that IMPA-HGAE achieves superior performance on heterogeneous datasets. Furthermore, this paper introduces innovative masking strategies to strengthen the representational capacity of generative SSL models on heterogeneous graph data. Additionally, this paper discusses the interpretability of the proposed method and potential future directions for generative self-supervised learning in heterogeneous graphs. This work provides insights into leveraging meta-path-guided structuralsemantics for robust representation learning in complex graph scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) methods have been increasingly applied todiverse downstream tasks due to their superior generalization capabilities andlow annotation costs. However, most existing heterogeneous graph SSL modelsconvert heterogeneous graphs into homogeneous ones via meta-paths for training,which only leverage information from nodes at both ends of meta-paths whileunderutilizing the heterogeneous node information along the meta-paths. Toaddress this limitation, this paper proposes a novel framework named IMPA-HGAEto enhance target node embeddings by fully exploiting internal node informationalong meta-paths. Experimental results validate that IMPA-HGAE achievessuperior performance on heterogeneous datasets. Furthermore, this paperintroduce innovative masking strategies to strengthen the representationalcapacity of generative SSL models on heterogeneous graph data. Additionally,this paper discuss the interpretability of the proposed method and potentialfuture directions for generative self-supervised learning in heterogeneousgraphs. This work provides insights into leveraging meta-path-guided structuralsemantics for robust representation learning in complex graph scenarios.</description>
      <author>example@mail.com (Di Lin, Wanjing Ren, Xuanbin Li, Rui Zhang)</author>
      <guid isPermaLink="false">2506.06809v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>PhysLab: A Benchmark Dataset for Multi-Granularity Visual Parsing of Physics Experiments</title>
      <link>http://arxiv.org/abs/2506.06631v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为PhysLab的视频数据集，用于视觉解析图像和视频，特别针对复杂物理实验的学生行为进行捕捉。&lt;h4&gt;背景&lt;/h4&gt;现有的图像和视频数据集在标注粒度、领域覆盖和过程指导方面存在不足，限制了视觉解析的发展。&lt;h4&gt;目的&lt;/h4&gt;提出PhysLab数据集以解决现有数据集的不足，推动精细视觉解析，促进智能教室系统的发展，以及计算机视觉与教育技术的整合。&lt;h4&gt;方法&lt;/h4&gt;PhysLab数据集包含了620个长视频，涵盖了4个具有多样科学仪器和丰富人机交互模式的代表实验，提供了多层次的标注以支持动作识别、目标检测、人机交互分析等多种视觉任务。&lt;h4&gt;主要发现&lt;/h4&gt;论文通过建立基线和广泛评估，突出了过程教育视频解析的关键挑战。&lt;h4&gt;结论&lt;/h4&gt;PhysLab数据集和评估工具包已公开发布，预期将成为视觉解析研究的重要资源。&lt;h4&gt;翻译&lt;/h4&gt;Visual parsing of images and videos is critical for a wide range of real-world applications. However, progress in this field is constrained by limitations of existing datasets: (1) insufficient annotation granularity, which impedes fine-grained scene understanding and high-level reasoning; (2) limited coverage of domains, particularly a lack of datasets tailored for educational scenarios; and (3) lack of explicit procedural guidance, with minimal logical rules and insufficient representation of structured task process. To address these gaps, we introduce PhysLab, the first video dataset that captures students conducting complex physics experiments. The dataset includes four representative experiments that feature diverse scientific instruments and rich human-object interaction (HOI) patterns. PhysLab comprises 620 long-form videos and provides multilevel annotations that support a variety of vision tasks, including action recognition, object detection, HOI analysis, etc. We establish strong baselines and perform extensive evaluations to highlight key challenges in the parsing of procedural educational videos. We expect PhysLab to serve as a valuable resource for advancing fine-grained visual parsing, facilitating intelligent classroom systems, and fostering closer integration between computer vision and educational technologies. The dataset and the evaluation toolkit are publicly available at https://github.com/ZMH-SDUST/PhysLab.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual parsing of images and videos is critical for a wide range ofreal-world applications. However, progress in this field is constrained bylimitations of existing datasets: (1) insufficient annotation granularity,which impedes fine-grained scene understanding and high-level reasoning; (2)limited coverage of domains, particularly a lack of datasets tailored foreducational scenarios; and (3) lack of explicit procedural guidance, withminimal logical rules and insufficient representation of structured taskprocess. To address these gaps, we introduce PhysLab, the first video datasetthat captures students conducting complex physics experiments. The datasetincludes four representative experiments that feature diverse scientificinstruments and rich human-object interaction (HOI) patterns. PhysLab comprises620 long-form videos and provides multilevel annotations that support a varietyof vision tasks, including action recognition, object detection, HOI analysis,etc. We establish strong baselines and perform extensive evaluations tohighlight key challenges in the parsing of procedural educational videos. Weexpect PhysLab to serve as a valuable resource for advancing fine-grainedvisual parsing, facilitating intelligent classroom systems, and fosteringcloser integration between computer vision and educational technologies. Thedataset and the evaluation toolkit are publicly available athttps://github.com/ZMH-SDUST/PhysLab.</description>
      <author>example@mail.com (Minghao Zou, Qingtian Zeng, Yongping Miao, Shangkun Liu, Zilong Wang, Hantao Liu, Wei Zhou)</author>
      <guid isPermaLink="false">2506.06631v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Model-Driven Graph Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.06212v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MGCL的模型驱动的图对比学习（GCL）框架，该框架利用图论（图的概率生成模型）来指导对比学习，通过考虑数据的潜在生成过程。&lt;h4&gt;背景&lt;/h4&gt;GCL作为一种自监督框架，在无需依赖标注标签的情况下，能够学习具有表达性的节点或图表示，这在现实世界的数据中通常较为稀缺。&lt;h4&gt;目的&lt;/h4&gt;通过对比增强的图数据视图，提高节点和图分类等下游任务的表现。&lt;h4&gt;方法&lt;/h4&gt;MGCL首先估计与观察数据相关的图论，然后定义一个基于图论的增强过程，实现数据自适应和原理性的增强。对于图级任务，MGCL对数据集进行聚类，并为每个组估计一个图论，以便对比对对反映共享的语义和结构。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上的广泛实验表明，MGCL实现了最先进的性能，突出了将生成模型纳入GCL的优势。&lt;h4&gt;结论&lt;/h4&gt;MGCL框架通过利用图论提高了图对比学习的效果，为图级任务提供了更有效的数据增强和表示学习策略。&lt;h4&gt;翻译&lt;/h4&gt;We propose MGCL, a model-driven graph contrastive learning (GCL) framework that leverages graphons (probabilistic generative models for graphs) to guide contrastive learning by accounting for the data's underlying generative process. GCL has emerged as a powerful self-supervised framework for learning expressive node or graph representations without relying on annotated labels, which are often scarce in real-world data. By contrasting augmented views of graph data, GCL has demonstrated strong performance across various downstream tasks, such as node and graph classification. However, existing methods typically rely on manually designed or heuristic augmentation strategies that are not tailored to the underlying data distribution and operate at the individual graph level, ignoring similarities among graphs generated from the same model. Conversely, in our proposed approach, MGCL first estimates the graphon associated with the observed data and then defines a graphon-informed augmentation process, enabling data-adaptive and principled augmentations. Additionally, for graph-level tasks, MGCL clusters the dataset and estimates a graphon per group, enabling contrastive pairs to reflect shared semantics and structure. Extensive experiments on benchmark datasets demonstrate that MGCL achieves state-of-the-art performance, highlighting the advantages of incorporating generative models into GCL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose $\textbf{MGCL}$, a model-driven graph contrastive learning (GCL)framework that leverages graphons (probabilistic generative models for graphs)to guide contrastive learning by accounting for the data's underlyinggenerative process. GCL has emerged as a powerful self-supervised framework forlearning expressive node or graph representations without relying on annotatedlabels, which are often scarce in real-world data. By contrasting augmentedviews of graph data, GCL has demonstrated strong performance across variousdownstream tasks, such as node and graph classification. However, existingmethods typically rely on manually designed or heuristic augmentationstrategies that are not tailored to the underlying data distribution andoperate at the individual graph level, ignoring similarities among graphsgenerated from the same model. Conversely, in our proposed approach, MGCL firstestimates the graphon associated with the observed data and then defines agraphon-informed augmentation process, enabling data-adaptive and principledaugmentations. Additionally, for graph-level tasks, MGCL clusters the datasetand estimates a graphon per group, enabling contrastive pairs to reflect sharedsemantics and structure. Extensive experiments on benchmark datasetsdemonstrate that MGCL achieves state-of-the-art performance, highlighting theadvantages of incorporating generative models into GCL.</description>
      <author>example@mail.com (Ali Azizpour, Nicolas Zilberstein, Santiago Segarra)</author>
      <guid isPermaLink="false">2506.06212v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Face recognition on point cloud with cgan-top for denoising</title>
      <link>http://arxiv.org/abs/2506.06864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in ICASSP 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在噪声点云上进行端到端3D人脸识别的方法，该方法有效地结合了去噪和识别模块。&lt;h4&gt;背景&lt;/h4&gt;使用3D点云进行人脸识别越来越受到关注，但由于传感器不完美，原始点云往往包含大量噪声。&lt;h4&gt;目的&lt;/h4&gt;提出一种在噪声点云上有效进行3D人脸识别的方法。&lt;h4&gt;方法&lt;/h4&gt;设计了一种条件生成对抗网络（cGAN-TOP）来去除点云中的噪声并恢复潜在特征，然后采用链接动态图卷积神经网络（LDGCNN）从处理后的点云中识别人脸。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在Bosphorus数据集上进行了验证，在所有噪声设置下都显著提高了识别准确率，最大增益为14.81%。&lt;h4&gt;结论&lt;/h4&gt;该方法在噪声点云上进行3D人脸识别时具有显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Face recognition using 3D point clouds is gaining growing interest, while rawpoint clouds often contain a significant amount of noise due to imperfectsensors. In this paper, an end-to-end 3D face recognition on a noisy pointcloud is proposed, which synergistically integrates the denoising andrecognition modules. Specifically, a Conditional Generative Adversarial Networkon Three Orthogonal Planes (cGAN-TOP) is designed to effectively remove thenoise in the point cloud, and recover the underlying features for subsequentrecognition. A Linked Dynamic Graph Convolutional Neural Network (LDGCNN) isthen adapted to recognize faces from the processed point cloud, whichhierarchically links both the local point features and neighboring features ofmultiple scales. The proposed method is validated on the Bosphorus dataset. Itsignificantly improves the recognition accuracy under all noise settings, witha maximum gain of 14.81%.</description>
      <author>example@mail.com (Junyu Liu, Jianfeng Ren, Sunhong Liang, Xudong Jiang)</author>
      <guid isPermaLink="false">2506.06864v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>How Important are Videos for Training Video LLMs?</title>
      <link>http://arxiv.org/abs/2506.06928v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page on  https://visualcomputinginstitute.github.io/videollm-pseudovideo-training/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视频大型语言模型（Video LLMs），发现经过图像训练的Video LLMs在时间推理能力上优于预期，而视频特定训练带来的改进很小。&lt;h4&gt;背景&lt;/h4&gt;视频LLMs的研究进展迅速，模型和基准在短短几年内大量涌现，通常这些模型使用预训练的纯文本LLM初始化，并在图像和视频字幕数据集上进行微调。&lt;h4&gt;目的&lt;/h4&gt;探讨Video LLMs在时间推理方面的能力，以及视频特定训练的效率。&lt;h4&gt;方法&lt;/h4&gt;使用LongVU算法训练的LLMs进行图像训练，并在TVBench时间推理基准上进行测试。引入了一个简单的微调方案，涉及一系列标注图像和针对时间能力的问题。&lt;h4&gt;主要发现&lt;/h4&gt;图像训练的LLMs在时间推理基准TVBench上的表现显著高于随机水平，且微调方案的效果接近甚至超过视频训练的LLMs。&lt;h4&gt;结论&lt;/h4&gt;当前模型对视频中丰富的时序特征的利用不足，需要进一步研究图像训练LLMs进行时间推理的机制以及当前视频训练方案的瓶颈。&lt;h4&gt;翻译&lt;/h4&gt;Research into Video Large Language Models (LLMs) has progressed rapidly, with numerous models and benchmarks emerging in just a few years. Typically, these models are initialized with a pretrained text-only LLM and finetuned on both image- and video-caption datasets. In this paper, we present findings indicating that Video LLMs are more capable of temporal reasoning after image-only training than one would assume, and that improvements from video-specific training are surprisingly small. Specifically, we show that image-trained versions of two LLMs trained with the recent LongVU algorithm perform significantly above chance level on TVBench, a temporal reasoning benchmark. Additionally, we introduce a simple finetuning scheme involving sequences of annotated images and questions targeting temporal capabilities. This baseline results in temporal reasoning performance close to, and occasionally higher than, what is achieved by video-trained LLMs. This suggests suboptimal utilization of rich temporal features found in real video by current models. Our analysis motivates further research into the mechanisms that allow image-trained LLMs to perform temporal reasoning, as well as into the bottlenecks that render current video training schemes inefficient.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Research into Video Large Language Models (LLMs) has progressed rapidly, withnumerous models and benchmarks emerging in just a few years. Typically, thesemodels are initialized with a pretrained text-only LLM and finetuned on bothimage- and video-caption datasets. In this paper, we present findingsindicating that Video LLMs are more capable of temporal reasoning afterimage-only training than one would assume, and that improvements fromvideo-specific training are surprisingly small. Specifically, we show thatimage-trained versions of two LLMs trained with the recent LongVU algorithmperform significantly above chance level on TVBench, a temporal reasoningbenchmark. Additionally, we introduce a simple finetuning scheme involvingsequences of annotated images and questions targeting temporal capabilities.This baseline results in temporal reasoning performance close to, andoccasionally higher than, what is achieved by video-trained LLMs. This suggestssuboptimal utilization of rich temporal features found in real video by currentmodels. Our analysis motivates further research into the mechanisms that allowimage-trained LLMs to perform temporal reasoning, as well as into thebottlenecks that render current video training schemes inefficient.</description>
      <author>example@mail.com (George Lydakis, Alexander Hermans, Ali Athar, Daan de Geus, Bastian Leibe)</author>
      <guid isPermaLink="false">2506.06928v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Initial Model Incorporation for Deep Learning FWI: Pretraining or Denormalization?</title>
      <link>http://arxiv.org/abs/2506.05484v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将初始模型知识嵌入神经网络的方法对全波形反演的影响。&lt;h4&gt;背景&lt;/h4&gt;地下属性神经网络重参数化全波形反演是一种有效的无监督学习框架，能够稳定反演，即使起始模型不准确。&lt;h4&gt;目的&lt;/h4&gt;研究两种将初始模型知识嵌入神经网络的方法对神经网络重参数化全波形反演的影响。&lt;h4&gt;方法&lt;/h4&gt;一种是预训练，通过拟合初始速度模型来调节神经网络参数；另一种是去归一化，直接将网络输出添加到初始模型中。&lt;h4&gt;主要发现&lt;/h4&gt;预训练需要基于恒定速度值（均值）进行模型扰动反演，导致工作流程复杂，目标函数在两阶段过程中不一致，导致网络参数失去活性，降低塑性。&lt;h4&gt;结论&lt;/h4&gt;去归一化可以简化工作流程，加速收敛，与预训练相比，可以提高反演精度。&lt;h4&gt;翻译&lt;/h4&gt;Subsurface property neural network reparameterized full waveform inversion (FWI) has emerged as an effective unsupervised learning framework, which can invert stably with an inaccurate starting model. It updates the trainable neural network parameters instead of fine-tuning on the subsurface model directly. There are primarily two ways to embed the prior knowledge of the initial model into neural networks, that is, pretraining and denormalization. Pretraining first regulates the neural networks' parameters by fitting the initial velocity model; Denormalization directly adds the outputs of the network into the initial models without pretraining. In this letter, we systematically investigate the influence of the two ways of initial model incorporation for the neural network reparameterized FWI. We demonstrate that pretraining requires inverting the model perturbation based on a constant velocity value (mean) with a two-stage implementation. It leads to a complex workflow and inconsistency of objective functions in the two-stage process, causing the network parameters to become inactive and lose plasticity. Experimental results demonstrate that denormalization can simplify workflows, accelerate convergence, and enhance inversion accuracy compared with pretraining.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Subsurface property neural network reparameterized full waveform inversion(FWI) has emerged as an effective unsupervised learning framework, which caninvert stably with an inaccurate starting model. It updates the trainableneural network parameters instead of fine-tuning on the subsurface modeldirectly. There are primarily two ways to embed the prior knowledge of theinitial model into neural networks, that is, pretraining and denormalization.Pretraining first regulates the neural networks' parameters by fitting theinitial velocity model; Denormalization directly adds the outputs of thenetwork into the initial models without pretraining. In this letter, wesystematically investigate the influence of the two ways of initial modelincorporation for the neural network reparameterized FWI. We demonstrate thatpretraining requires inverting the model perturbation based on a constantvelocity value (mean) with a two-stage implementation. It leads to a complexworkflow and inconsistency of objective functions in the two-stage process,causing the network parameters to become inactive and lose plasticity.Experimental results demonstrate that denormalization can simplify workflows,accelerate convergence, and enhance inversion accuracy compared withpretraining.</description>
      <author>example@mail.com (Ruihua Chen, Bangyu Wu, Meng Li, Kai Yang)</author>
      <guid isPermaLink="false">2506.05484v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty Estimation on Graphs with Structure Informed Stochastic Partial Differential Equations</title>
      <link>http://arxiv.org/abs/2506.06907v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的不确定性估计方法，该方法能够处理分布偏移问题，并通过引入空间-时间噪声来增强不确定性估计。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在多种网络建模任务中取得了显著成果，但在处理分布偏移时，准确估计不确定性仍然是一个难题。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的消息传递方案，以解决图结构及其标签分布带来的随机性，从而提高不确定性估计的准确性。&lt;h4&gt;方法&lt;/h4&gt;借鉴了由Matern高斯过程驱动的随机偏微分方程（SPDE）的演化与GNN层中消息传递之间的类比，提出了一种新的消息传递方案。&lt;h4&gt;主要发现&lt;/h4&gt;该方法同时捕捉空间和时间上的不确定性，并允许显式控制协方差核的平滑度，从而在标签信息量低和高的情况下都能提高不确定性估计。&lt;h4&gt;结论&lt;/h4&gt;在具有不同标签信息量的图数据集上进行Out-of-Distribution（OOD）检测的广泛实验表明，该方法在现有方法中具有可靠性和优越性。&lt;h4&gt;翻译&lt;/h4&gt;Graph神经网络在多样化的网络建模任务中取得了令人印象深刻的成果，但在图上准确估计不确定性仍然很困难，尤其是在分布偏移的情况下。与传统的不确定性估计不同，基于图的不确定性必须考虑由图的结构及其标签分布产生的随机性，这增加了复杂性。在本文中，我们将由Matern高斯过程驱动的随机偏微分方程（SPDE）的演化与使用GNN层的消息传递之间的类比，提出了一种设计新消息传递方案的原则方法，该方案结合了由SPDE的高斯过程方法启发的空间-时间噪声。我们的方法同时捕捉空间和时间上的不确定性，并允许显式控制协方差核的平滑度，从而增强了在标签信息量低和高的情况下图上的不确定性估计。我们在具有不同标签信息量的图数据集上进行Out-of-Distribution（OOD）检测的广泛实验表明，我们的模型在现有方法中具有可靠性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks have achieved impressive results across diverse networkmodeling tasks, but accurately estimating uncertainty on graphs remainsdifficult, especially under distributional shifts. Unlike traditionaluncertainty estimation, graph-based uncertainty must account for randomnessarising from both the graph's structure and its label distribution, which addscomplexity. In this paper, making an analogy between the evolution of astochastic partial differential equation (SPDE) driven by Matern GaussianProcess and message passing using GNN layers, we present a principled way todesign a novel message passing scheme that incorporates spatial-temporal noisesmotivated by the Gaussian Process approach to SPDE. Our method simultaneouslycaptures uncertainty across space and time and allows explicit control over thecovariance kernel smoothness, thereby enhancing uncertainty estimates on graphswith both low and high label informativeness. Our extensive experiments onOut-of-Distribution (OOD) detection on graph datasets with varying labelinformativeness demonstrate the soundness and superiority of our model toexisting approaches.</description>
      <author>example@mail.com (Fred Xu, Thomas Markovich)</author>
      <guid isPermaLink="false">2506.06907v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Employing Discrete Fourier Transform in Representational Learning</title>
      <link>http://arxiv.org/abs/2506.06765v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过输入重建进行图像表示学习的新方法，使用离散傅里叶变换（DFT）作为学习目标，在CIFAR-10数据集上取得了52.8%的top-1准确率，优于传统的自编码器。&lt;h4&gt;背景&lt;/h4&gt;图像表示学习在机器学习中用于生成可被任意下游任务有效利用的表示，常用的方法是使用自编码器在网络的压缩点提取潜在表示。&lt;h4&gt;目的&lt;/h4&gt;提出一种替代的学习目标，即使用输入的离散傅里叶变换（DFT）作为重建目标。&lt;h4&gt;方法&lt;/h4&gt;使用DFT提供每个频率级别的有意义全局信息，使单个频率分量作为单独的学习目标。对于多维输入数据，DFT通过允许在特定维度上选择性变换，同时保留其他维度的计算，提供了显著的灵活性。此外，某些类型的输入在频率分布中表现出特定的模式，允许我们关注频率子集而不是整个频谱。&lt;h4&gt;主要发现&lt;/h4&gt;DFT作为学习目标适用于表示学习，使用DFT在CIFAR-10上达到了52.8%的top-1准确率，并优于传统的自编码器。仅在低频分量（具有最高幅度的分量）上进行训练，其结果与使用完整频谱相当，准确率仅略有下降。&lt;h4&gt;结论&lt;/h4&gt;DFT是一种有效的学习目标，可以用于图像表示学习，并且这种方法在CIFAR-10数据集上取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通过输入重建进行图像表示学习是机器学习中生成可被任意下游任务有效利用的表示的一种常见技术。一种已建立的方法是使用自编码器在网络压缩点提取潜在表示。这些表示很有价值，因为它们保留了从压缩的潜在空间重建原始输入所需的基本信息。在本文中，我们提出了一种替代的学习目标。我们不是使用原始输入作为重建目标，而是使用输入的离散傅里叶变换（DFT）。DFT在每个频率级别上提供了有意义的全局信息，使单个频率分量作为单独的学习目标变得有用。处理多维输入数据时，DFT通过允许在特定维度上选择性变换，同时保留其他维度的计算，提供了显著的灵活性。此外，某些类型的输入在其频率分布中表现出特定的模式，其中特定的频率分量始终包含大部分幅度，允许我们关注频率的子集而不是整个频谱。这些特性使DFT成为表示学习的一种可行学习目标，我们通过在CIFAR-10上实现52.8%的top-1准确率并优于相同架构配置下的传统自编码器12.8个百分点来验证我们的方法。此外，我们还证明，仅在低频分量（具有最高幅度的分量）上进行训练，其结果与使用完整频谱相当，准确率仅略有下降。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image Representation learning via input reconstruction is a common techniquein machine learning for generating representations that can be effectivelyutilized by arbitrary downstream tasks. A well-established approach is usingautoencoders to extract latent representations at the network's compressionpoint. These representations are valuable because they retain essentialinformation necessary for reconstructing the original input from the compressedlatent space. In this paper, we propose an alternative learning objective.Instead of using the raw input as the reconstruction target, we employ theDiscrete Fourier Transform (DFT) of the input. The DFT provides meaningfulglobal information at each frequency level, making individual frequencycomponents useful as separate learning targets. When dealing withmultidimensional input data, the DFT offers remarkable flexibility by enablingselective transformation across specific dimensions while preserving others inthe computation. Moreover, certain types of input exhibit distinct patterns intheir frequency distributions, where specific frequency components consistentlycontain most of the magnitude, allowing us to focus on a subset of frequenciesrather than the entire spectrum. These characteristics position the DFT as aviable learning objective for representation learning and we validate ourapproach by achieving 52.8% top-1 accuracy on CIFAR-10 with ResNet-50 andoutperforming the traditional autoencoder by 12.8 points under identicalarchitectural configurations. Additionally, we demonstrate that training ononly the lower-frequency components - those with the highest magnitudes yieldsresults comparable to using the full frequency spectrum, with only minimalreductions in accuracy.</description>
      <author>example@mail.com (Raoof HojatJalali, Edmondo Trentin)</author>
      <guid isPermaLink="false">2506.06765v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Towards Terrain-Aware Task-Driven 3D Scene Graph Generation in Outdoor Environments</title>
      <link>http://arxiv.org/abs/2506.06562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 2025 IEEE ICRA Workshop on Field Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了三维场景图（3DSGs）在室外环境中的应用，提出了一种生成适用于大型室外场景的任务无关度量-语义点云的方法，并对现有的室内3DSG生成技术进行了修改以适应室外环境。&lt;h4&gt;背景&lt;/h4&gt;传统的三维场景表示方法如点云和占用网格提供了详细的几何信息，但缺乏结构化和语义组织，不足以支持高级推理。&lt;h4&gt;目的&lt;/h4&gt;研究3DSGs在室外环境中的构建和实用性，并展示其在实际机器人应用中的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种生成适用于大型室外场景的任务无关度量-语义点云的方法，并对室内3DSG生成技术进行了修改。&lt;h4&gt;主要发现&lt;/h4&gt;初步的定性结果表明室外3DSGs的可行性和在现实世界机器人应用中的潜在价值。&lt;h4&gt;结论&lt;/h4&gt;室外3DSGs在提高机器人对环境的结构化推理和决策能力方面具有巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-level autonomous operations depend on a robot's ability to construct asufficiently expressive model of its environment. Traditional three-dimensional(3D) scene representations, such as point clouds and occupancy grids, providedetailed geometric information but lack the structured, semantic organizationneeded for high-level reasoning. 3D scene graphs (3DSGs) address thislimitation by integrating geometric, topological, and semantic relationshipsinto a multi-level graph-based representation. By capturing hierarchicalabstractions of objects and spatial layouts, 3DSGs enable robots to reasonabout environments in a structured manner, improving context-awaredecision-making and adaptive planning. Although most recent work has focused onindoor 3DSGs, this paper investigates their construction and utility in outdoorenvironments. We present a method for generating a task-agnosticmetric-semantic point cloud for large outdoor settings and proposemodifications to existing indoor 3DSG generation techniques for outdoorapplicability. Our preliminary qualitative results demonstrate the feasibilityof outdoor 3DSGs and highlight their potential for future deployment inreal-world field robotic applications.</description>
      <author>example@mail.com (Chad R Samuelson, Timothy W McLain, Joshua G Mangelson)</author>
      <guid isPermaLink="false">2506.06562v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>A Study on the Fine-Tuning Performance of Universal Machine-Learned Interatomic Potentials (U-MLIPs)</title>
      <link>http://arxiv.org/abs/2506.07401v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于MACE的两种基础模型MACE-MP-0及其变体MACE-MP-0b的微调，发现微调可以提高模型在特定任务上的准确性，并且在某些情况下优于从头开始训练的模型。&lt;h4&gt;背景&lt;/h4&gt;U-MLIPs在多样化的原子系统中表现出有效性，但通常需要针对特定任务进行微调以提高准确性。&lt;h4&gt;目的&lt;/h4&gt;探究MACE-MP-0和MACE-MP-0b的微调效果，并识别关键见解。&lt;h4&gt;方法&lt;/h4&gt;在特定任务的数据集上进行微调，并通过过滤或主动学习优化数据集选择。&lt;h4&gt;主要发现&lt;/h4&gt;微调能够提高准确性，并且由于基础模型提供的强大初始预测，微调模型能够更快地收敛。微调的成功也依赖于仔细的数据集选择。&lt;h4&gt;结论&lt;/h4&gt;通过微调可以提升模型在原子模拟中的性能，并且提出了实现更好的微调基础模型的实际策略，探讨了未来发展和应用的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通用的机器学习原子间势能（U-MLIPs）在不同原子系统中证明了其有效性，但通常需要针对特定任务进行微调以提升准确性。我们研究了基于MACE的两种基础模型MACE-MP-0及其变体MACE-MP-0b的微调，并得出了关键见解。针对特定任务的数据集进行微调可以提高准确性，在某些情况下甚至优于从头开始训练的模型。此外，由于基础模型提供的强大初始预测，微调模型能够实现更快的收敛。微调的成功也依赖于数据集选择的精心，这可以通过过滤或主动学习来优化。我们进一步讨论了在原子模拟中实现更好微调基础模型的实际策略，并探索了其发展和应用的未来方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Universal machine-learned interatomic potentials (U-MLIPs) have demonstratedeffectiveness across diverse atomistic systems but often require fine-tuningfor task-specific accuracy. We investigate the fine-tuning of two MACE-basedfoundation models, MACE-MP-0 and its variant MACE-MP-0b, and identify keyinsights. Fine-tuning on task-specific datasets enhances accuracy and, in somecases, outperforms models trained from scratch. Additionally, fine-tuned modelsbenefit from faster convergence due to the strong initial predictions providedby the foundation model. The success of fine-tuning also depends on carefuldataset selection, which can be optimized through filtering or active learning.We further discuss practical strategies for achieving better fine-tuningfoundation models in atomistic simulations and explore future directions fortheir development and applications.</description>
      <author>example@mail.com (Xiaoqing Liu, Kehan Zeng, Yangshuai Wang, Teng Zhao)</author>
      <guid isPermaLink="false">2506.07401v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>GazeNLQ @ Ego4D Natural Language Queries Challenge 2025</title>
      <link>http://arxiv.org/abs/2506.05782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GazeNLQ的解决方案，用于解决CVPR 2025的Ego4D自然语言查询（NLQ）挑战，通过利用注视信息来检索与给定自然语言查询相匹配的视频片段。&lt;h4&gt;背景&lt;/h4&gt;以自拍摄像头捕捉的场景为背景，注视作为非言语交流的关键线索，反映了视觉注意力和人类意图与认知。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用注视信息来检索视频片段的新方法，以匹配自然语言查询。&lt;h4&gt;方法&lt;/h4&gt;引入了一种基于对比学习的预训练策略，用于直接从视频中估计注视，并将估计的注视用于增强模型中的视频表示，从而提高定位精度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，GazeNLQ在R1@IoU0.3和R1@IoU0.5的指标上分别达到了27.82和18.68。&lt;h4&gt;结论&lt;/h4&gt;GazeNLQ是一种有效的视频检索方法，可以显著提高自然语言查询的准确性。&lt;h4&gt;翻译&lt;/h4&gt;本报告介绍了我们在CVPR 2025 Ego4D自然语言查询（NLQ）挑战中的解决方案。以佩戴者视角捕捉的场景为背景，注视作为关键的非言语交流线索，反映了视觉注意力和人类意图与认知。受此启发，我们提出了一种新的方法，称为GazeNLQ，该方法利用注视信息检索与给定自然语言查询匹配的视频片段。具体而言，我们引入了一种基于对比学习的预训练策略，用于直接从视频中估计注视。估计的注视用于增强模型中的视频表示，从而提高定位精度。实验结果表明，GazeNLQ在R1@IoU0.3和R1@IoU0.5的指标上分别达到了27.82和18.68。我们的代码可在https://github.com/stevenlin510/GazeNLQ上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This report presents our solution to the Ego4D Natural Language Queries (NLQ)Challenge at CVPR 2025. Egocentric video captures the scene from the wearer'sperspective, where gaze serves as a key non-verbal communication cue thatreflects visual attention and offer insights into human intention andcognition. Motivated by this, we propose a novel approach, GazeNLQ, whichleverages gaze to retrieve video segments that match given natural languagequeries. Specifically, we introduce a contrastive learning-based pretrainingstrategy for gaze estimation directly from video. The estimated gaze is used toaugment video representations within proposed model, thereby enhancinglocalization accuracy. Experimental results show that GazeNLQ achievesR1@IoU0.3 and R1@IoU0.5 scores of 27.82 and 18.68, respectively. Our code isavailable at https://github.com/stevenlin510/GazeNLQ.</description>
      <author>example@mail.com (Wei-Cheng Lin, Chih-Ming Lien, Chen Lo, Chia-Hung Yeh)</author>
      <guid isPermaLink="false">2506.05782v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>FuncGNN: Learning Functional Semantics of Logic Circuits with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.06787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FuncGNN的方法，用于解决集成电路规模增长和设计复杂性提升带来的AIGs结构异质性和全局逻辑信息损失问题，提高了逻辑电路表示的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;随着集成电路规模的扩大和设计复杂性的增加，有效的电路表示对于逻辑综合、形式验证和其他电子设计自动化流程至关重要。AIGs作为一种紧凑和规范的结构，被广泛应用于布尔逻辑的表示。&lt;h4&gt;目的&lt;/h4&gt;为了解决AIGs中结构异质性和全局逻辑信息损失的问题，提高电路模型的准确性。&lt;h4&gt;方法&lt;/h4&gt;FuncGNN通过集成混合特征聚合来提取多粒度拓扑模式，以减轻结构异质性并增强逻辑电路表示。此外，FuncGNN引入了门感知归一化，以适应电路特定的门分布，提高对结构异质性的鲁棒性。最后，FuncGNN采用多层集成来合并跨层的中间特征，有效地综合局部和全局语义信息，以实现全面的逻辑表示。&lt;h4&gt;主要发现&lt;/h4&gt;在两个逻辑级分析任务（即信号概率预测和真值表距离预测）上，FuncGNN的表现优于现有的最先进方法，分别提高了2.06%和18.71%，同时将训练时间减少了约50.6%，GPU内存使用量减少了约32.8%。&lt;h4&gt;结论&lt;/h4&gt;FuncGNN能够有效提高逻辑电路表示的准确性，并显著减少训练时间和GPU内存使用量，是一种具有潜力的电子设计自动化工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As integrated circuit scale grows and design complexity rises, effectivecircuit representation helps support logic synthesis, formal verification, andother automated processes in electronic design automation. And-Inverter Graphs(AIGs), as a compact and canonical structure, are widely adopted forrepresenting Boolean logic in these workflows. However, the increasingcomplexity and integration density of modern circuits introduce structuralheterogeneity and global logic information loss in AIGs, posing significantchallenges to accurate circuit modeling. To address these issues, we proposeFuncGNN, which integrates hybrid feature aggregation to extractmulti-granularity topological patterns, thereby mitigating structuralheterogeneity and enhancing logic circuit representations. FuncGNN furtherintroduces gate-aware normalization that adapts to circuit-specific gatedistributions, improving robustness to structural heterogeneity. Finally,FuncGNN employs multi-layer integration to merge intermediate features acrosslayers, effectively synthesizing local and global semantic information forcomprehensive logic representations. Experimental results on two logic-levelanalysis tasks (i.e., signal probability prediction and truth-table distanceprediction) demonstrate that FuncGNN outperforms existing state-of-the-artmethods, achieving improvements of 2.06% and 18.71%, respectively, whilereducing training time by approximately 50.6% and GPU memory usage by about32.8%.</description>
      <author>example@mail.com (Qiyun Zhao)</author>
      <guid isPermaLink="false">2506.06787v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>DINO-CoDT: Multi-class Collaborative Detection and Tracking with Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2506.07375v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对多样化道路用户的多类协同检测和跟踪框架，以增强环境理解。&lt;h4&gt;背景&lt;/h4&gt;协同感知在扩展感知范围和增强对传感器故障的鲁棒性方面发挥着关键作用，主要涉及协同3D检测和跟踪任务。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有工作中主要关注车辆类别而缺乏多类协同检测和跟踪有效解决方案的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种包含全局空间注意力融合（GSAF）模块的检测器，用于增强多尺度特征学习；引入了一种基于视觉语义和视觉基础模型的tracklet RE-IDentification（REID）模块，以减少涉及小物体（如行人）的错误匹配；设计了基于速度的适应性tracklet管理（VATM）模块，动态调整跟踪间隔。&lt;h4&gt;主要发现&lt;/h4&gt;在V2X-Real和OPV2V数据集上的大量实验表明，该方法在检测和跟踪精度方面显著优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;该框架在多类协同检测和跟踪方面取得了显著成效，提高了实际场景中的应用能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：协作感知在增强环境理解方面发挥着关键作用，通过扩展感知范围和提高对传感器故障的鲁棒性，这主要涉及协同3D检测和跟踪任务。前者侧重于单个帧中的物体识别，而后者则捕捉随时间变化的连续实例tracklets。然而，现有工作在这两个领域主要关注车辆类别，缺乏有效的多类协同检测和跟踪解决方案。这种局限性阻碍了它们在实际场景中的应用，这些场景涉及具有不同外观和运动模式的各种物体类别。为了克服这些局限性，我们提出了一种针对多样化道路用户的多类协同检测和跟踪框架。我们首先提出了一种包含全局空间注意力融合（GSAF）模块的检测器，用于增强不同大小物体的多尺度特征学习。接下来，我们介绍了一种利用视觉语义和视觉基础模型的tracklet RE-IDentification（REID）模块，以有效减少涉及小物体（如行人）的错误匹配。我们进一步设计了一种基于速度的适应性tracklet管理（VATM）模块，根据物体运动动态调整跟踪间隔。在V2X-Real和OPV2V数据集上的大量实验表明，我们的方法在检测和跟踪精度方面显著优于现有最先进的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Collaborative perception plays a crucial role in enhancing environmentalunderstanding by expanding the perceptual range and improving robustnessagainst sensor failures, which primarily involves collaborative 3D detectionand tracking tasks. The former focuses on object recognition in individualframes, while the latter captures continuous instance tracklets over time.However, existing works in both areas predominantly focus on the vehiclesuperclass, lacking effective solutions for both multi-class collaborativedetection and tracking. This limitation hinders their applicability inreal-world scenarios, which involve diverse object classes with varyingappearances and motion patterns. To overcome these limitations, we propose amulti-class collaborative detection and tracking framework tailored for diverseroad users. We first present a detector with a global spatial attention fusion(GSAF) module, enhancing multi-scale feature learning for objects of varyingsizes. Next, we introduce a tracklet RE-IDentification (REID) module thatleverages visual semantics with a vision foundation model to effectively reduceID SWitch (IDSW) errors, in cases of erroneous mismatches involving smallobjects like pedestrians. We further design a velocity-based adaptive trackletmanagement (VATM) module that adjusts the tracking interval dynamically basedon object motion. Extensive experiments on the V2X-Real and OPV2V datasets showthat our approach significantly outperforms existing state-of-the-art methodsin both detection and tracking accuracy.</description>
      <author>example@mail.com (Xunjie He, Christina Dao Wen Lee, Meiling Wang, Chengran Yuan, Zefan Huang, Yufeng Yue, Marcelo H. Ang Jr)</author>
      <guid isPermaLink="false">2506.07375v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>AANet: Virtual Screening under Structural Uncertainty via Alignment and Aggregation</title>
      <link>http://arxiv.org/abs/2506.05768v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种适用于结构不确定性的虚拟筛选方法，通过对比学习和跨注意力机制，提高了在缺乏口袋信息的apo结构上的虚拟筛选准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的虚拟筛选方法大多基于已知配体结合口袋的全蛋白结构，在缺乏口袋信息的apo结构或AlphaFold2预测结构上表现不佳。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够在结构不确定性的情况下进行准确虚拟筛选的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种包含两个核心组件的方法：(1) 三模态对比学习模块，用于对配体、全蛋白口袋和从结构中检测到的腔体进行表示对齐，增强对口袋定位错误的鲁棒性；(2) 基于跨注意力的适配器，用于动态聚合候选结合位点，使模型能够在没有精确口袋注释的情况下从活性数据中学习。&lt;h4&gt;主要发现&lt;/h4&gt;在apo结构的新颖基准测试中，该方法在盲apo设置下显著优于现有方法，将早期富集因子（EF1%）从11.75提高到37.19。同时，该方法在holo结构上也保持了强大的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在推进一类新药发现方面具有潜力，尤其是在缺乏实验解决的蛋白-配体复合物的情况下。&lt;h4&gt;翻译&lt;/h4&gt;摘要：虚拟筛选（VS）是现代药物发现的关键组成部分，然而，大多数现有方法——无论是基于物理的还是基于深度学习的——都是围绕已知配体结合口袋的全蛋白结构开发的。因此，它们在apo或AlphaFold2等预测结构上的性能显著下降，这些结构更符合现实世界的早期药物发现，其中口袋信息通常缺失。在本文中，我们介绍了一种对齐和聚合框架，以实现结构不确定性下的准确虚拟筛选。我们的方法包含两个核心组件：(1) 三模态对比学习模块，用于对配体、全蛋白口袋和从结构中检测到的腔体进行表示对齐，从而增强对口袋定位错误的鲁棒性；(2) 基于跨注意力的适配器，用于动态聚合候选结合位点，使模型能够在没有精确口袋注释的情况下从活性数据中学习。我们在apo结构的新颖基准测试中评估了我们的方法，在盲apo设置下，它显著优于现有方法，将早期富集因子（EF1%）从11.75提高到37.19。值得注意的是，它也在holo结构上保持了强大的性能。这些结果证明了我们的方法在推进一类新药发现方面的潜力，尤其是在缺乏实验解决的蛋白-配体复合物的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Virtual screening (VS) is a critical component of modern drug discovery, yetmost existing methods--whether physics-based or deep learning-based--aredeveloped around holo protein structures with known ligand-bound pockets.Consequently, their performance degrades significantly on apo or predictedstructures such as those from AlphaFold2, which are more representative ofreal-world early-stage drug discovery, where pocket information is oftenmissing. In this paper, we introduce an alignment-and-aggregation framework toenable accurate virtual screening under structural uncertainty. Our methodcomprises two core components: (1) a tri-modal contrastive learning module thataligns representations of the ligand, the holo pocket, and cavities detectedfrom structures, thereby enhancing robustness to pocket localization error; and(2) a cross-attention based adapter for dynamically aggregating candidatebinding sites, enabling the model to learn from activity data even withoutprecise pocket annotations. We evaluated our method on a newly curatedbenchmark of apo structures, where it significantly outperformsstate-of-the-art methods in blind apo setting, improving the early enrichmentfactor (EF1%) from 11.75 to 37.19. Notably, it also maintains strongperformance on holo structures. These results demonstrate the promise of ourapproach in advancing first-in-class drug discovery, particularly in scenarioslacking experimentally resolved protein-ligand complexes.</description>
      <author>example@mail.com (Wenyu Zhu, Jianhui Wang, Bowen Gao, Yinjun Jia, Haichuan Tan, Ya-Qin Zhang, Wei-Ying Ma, Yanyan Lan)</author>
      <guid isPermaLink="false">2506.05768v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Paged Attention Meets FlexAttention: Unlocking Long-Context Efficiency in Deployed Inference</title>
      <link>http://arxiv.org/abs/2506.07311v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的PagedAttention与PyTorch的FlexAttention集成方法，以解决LLMs在长上下文推理中的内存效率问题，并在IBM的FMS中实现了融合的注意力内核，显著降低了推理延迟。&lt;h4&gt;背景&lt;/h4&gt;LLMs在长上下文推理过程中由于传统的键值缓存处理方式而面临严重的内存效率问题。&lt;h4&gt;目的&lt;/h4&gt;提高LLMs在长上下文推理中的内存效率。&lt;h4&gt;方法&lt;/h4&gt;通过引入PagedAttention与PyTorch的FlexAttention的集成，优化了内部碎片化和与单一键值缓存分配相关的效率问题。&lt;h4&gt;主要发现&lt;/h4&gt;在NVIDIA L4 GPU（24GB）上进行的基准测试表明，使用全局键值缓存时，推理延迟显著降低，与序列长度从128到2048个标记的增长呈线性关系（约2倍），而未使用缓存时，延迟呈指数增长。尽管单步评估的峰值内存使用量基本保持不变（主要由模型权重和激活项决定），但分页注意力引起的增量内存使用量最小，仅在序列长度超过2048个标记时才可观察到，这是由于其2的幂次缓存分配。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法对未来的长上下文模型部署具有重要意义，并且已经开源了完整的实现。&lt;h4&gt;翻译&lt;/h4&gt;Large Language Models (LLMs) encounter severe memory inefficiencies during long-context inference due to conventional handling of key-value (KV) caches. In this work, we introduce a novel integration of PagedAttention with PyTorch's FlexAttention, addressing internal fragmentation and inefficiencies associated with monolithic KV cache allocations. Implemented within IBM's Foundation ModelStack (FMS), our fused attention kernel efficiently gathers scattered KV data. Our benchmarks on an NVIDIA L4 GPU (24GB) demonstrate significantly reduced inference latency, growing only linearly (~2x) with sequence length from 128 to 2048 tokens when utilizing a global KV cache, compared to exponential latency increases without caching. While peak memory usage remains largely unchanged for single-step evaluations (dominated by model weights and activations), paged attention causes minimal incremental memory usage, observable only at sequence lengths exceeding 2048 tokens due to its power-of-two cache allocations. We open-source the full implementation and discuss its implications for future long-context model deployment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) encounter severe memory inefficiencies duringlong-context inference due to conventional handling of key-value (KV) caches.In this work, we introduce a novel integration of PagedAttention with PyTorch'sFlexAttention, addressing internal fragmentation and inefficiencies associatedwith monolithic KV cache allocations. Implemented within IBM's Foundation ModelStack (FMS), our fused attention kernel efficiently gathers scattered KV data.Our benchmarks on an NVIDIA L4 GPU (24GB) demonstrate significantly reducedinference latency, growing only linearly (~2x) with sequence length from 128 to2048 tokens when utilizing a global KV cache, compared to exponential latencyincreases without caching. While peak memory usage remains largely unchangedfor single-step evaluations (dominated by model weights and activations), pagedattention causes minimal incremental memory usage, observable only at sequencelengths exceeding 2048 tokens due to its power-of-two cache allocations. Weopen-source the full implementation and discuss its implications for futurelong-context model deployment.</description>
      <author>example@mail.com (Thomas Joshi, Herman Saini, Neil Dhillon, Antoni Viros i Martin, Kaoutar El Maghraoui)</author>
      <guid isPermaLink="false">2506.07311v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>When Better Features Mean Greater Risks: The Performance-Privacy Trade-Off in Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.05743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted In ACM ASIA Conference on Computer and Communications  Security (ASIA CCS '25), August 25-29, 2025, Ha Noi, Vietnam. For Code, see  https://github.com/SeroneySun/LpLA_code&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了针对编码器模型的成员推理攻击（MIAs）带来的隐私威胁，特别是聚焦于对比学习框架，并提出了一种基于特征向量p-norm的成员推理攻击方法LpLA，旨在揭示模型架构复杂性与隐私泄露风险之间的关系，并提升隐私保护。&lt;h4&gt;背景&lt;/h4&gt;随着深度学习技术的快速发展，预训练编码器模型在特征提取方面表现出色，但在广泛应用中引发了对训练数据隐私泄露风险的担忧。&lt;h4&gt;目的&lt;/h4&gt;系统地调查针对编码器模型的成员推理攻击带来的隐私威胁，并提出一种新的攻击方法。&lt;h4&gt;方法&lt;/h4&gt;通过实验分析模型架构复杂性与隐私泄露风险之间的关系，提出基于特征向量p-norm的LpLA方法，并通过多个数据集和模型架构进行实验验证。&lt;h4&gt;主要发现&lt;/h4&gt;发现更先进的编码器框架在提高特征提取性能的同时，也加剧了隐私泄露风险。LpLA在攻击性能和鲁棒性方面优于现有方法，尤其在有限的攻击知识和查询量下表现突出。&lt;h4&gt;结论&lt;/h4&gt;本研究不仅揭示了对比学习框架中隐私泄露的潜在风险，还为编码器模型的隐私保护研究提供了实践基础，并强调了在模型效用和训练数据隐私之间的平衡重要性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着深度学习技术的快速发展，预训练编码器模型在特征提取方面表现出色，在深度学习的研究和应用中发挥着关键作用。然而，它们的广泛应用引发了关于训练数据隐私泄露风险的重大担忧。本文系统地研究了针对编码器模型的成员推理攻击（MIAs）带来的隐私威胁，重点关注对比学习框架。通过实验分析，我们揭示了模型架构复杂性对成员隐私泄露的显著影响：随着更先进的编码器框架提高特征提取性能，它们同时加剧了隐私泄露风险。此外，本文提出了一种基于特征向量p-norm的新颖成员推理攻击方法，称为嵌入Lp-Norm似然攻击（LpLA）。这种方法通过利用特征向量p-norm的统计分布特性来推断成员状态。多个数据集和模型架构的实验结果表明，LpLA在攻击性能和鲁棒性方面优于现有方法，尤其是在有限的攻击知识和查询量下。本研究不仅揭示了对比学习框架中隐私泄露的潜在风险，还为编码器模型的隐私保护研究提供了实践基础。我们希望这项工作将引起对与自监督学习模型相关的隐私风险的更多关注，并阐明在模型效用和训练数据隐私之间平衡的重要性。我们的代码在https://github.com/SeroneySun/LpLA_code上公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3708821.3733915&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid advancement of deep learning technology, pre-trained encodermodels have demonstrated exceptional feature extraction capabilities, playing apivotal role in the research and application of deep learning. However, theirwidespread use has raised significant concerns about the risk of training dataprivacy leakage. This paper systematically investigates the privacy threatsposed by membership inference attacks (MIAs) targeting encoder models, focusingon contrastive learning frameworks. Through experimental analysis, we revealthe significant impact of model architecture complexity on membership privacyleakage: As more advanced encoder frameworks improve feature-extractionperformance, they simultaneously exacerbate privacy-leakage risks. Furthermore,this paper proposes a novel membership inference attack method based on thep-norm of feature vectors, termed the Embedding Lp-Norm Likelihood Attack(LpLA). This method infers membership status, by leveraging the statisticaldistribution characteristics of the p-norm of feature vectors. Experimentalresults across multiple datasets and model architectures demonstrate that LpLAoutperforms existing methods in attack performance and robustness, particularlyunder limited attack knowledge and query volumes. This study not only uncoversthe potential risks of privacy leakage in contrastive learning frameworks, butalso provides a practical basis for privacy protection research in encodermodels. We hope that this work will draw greater attention to the privacy risksassociated with self-supervised learning models and shed light on theimportance of a balance between model utility and training data privacy. Ourcode is publicly available at: https://github.com/SeroneySun/LpLA_code.</description>
      <author>example@mail.com (Ruining Sun, Hongsheng Hu, Wei Luo, Zhaoxi Zhang, Yanjun Zhang, Haizhuan Yuan, Leo Yu Zhang)</author>
      <guid isPermaLink="false">2506.05743v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Estimation of the curvature from random samples</title>
      <link>http://arxiv.org/abs/2506.06779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过从曲线或曲面上采样得到的有限样本点来估计曲线和曲面曲率的估计器。&lt;h4&gt;背景&lt;/h4&gt;研究者们需要一种方法来估计曲线和曲面的曲率。&lt;h4&gt;目的&lt;/h4&gt;开发一种算法来估计曲线和曲面在特定点的曲率，并将其扩展到估计曲面的高斯曲率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种算法来估计曲线曲率，并将其扩展以估计曲面高斯曲率。该算法利用点云中选定点数与给定点具有足够邻近点的概率之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;算法能够通过控制点云中点的数量来估计曲率。&lt;h4&gt;结论&lt;/h4&gt;该方法为曲率估计提供了一种新的工具，可以应用于曲线和曲面的几何分析。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种通过使用从具有曲线或曲面支撑的概率分布中抽取的有限样本点来估计曲线和曲面曲率的估计器。首先，我们给出了一种估计曲线给定点的曲率的算法。然后，我们将它扩展到估计曲面的高斯曲率。在所提出的算法中，我们使用了点云中选定点数与给定点具有足够邻近点的概率之间的关系。这种关系使我们能够控制点云中所需点的数量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce an estimator for the curvature of curves and surfaces by usingfinite sample points drawn from sampling a probability distribution that hassupport on the curve or surface. First we give an algorithm for estimation ofthe curvature in a given point of a curve. Then, we extend it to estimate theGaussian curvature of the surfaces. In the proposed algorithms, we use arelation between the number of selected points in the point cloud and theprobability that a given point has a suffcient number of nearby points. Thisrelation allows us to control the required number of points in the point cloud.</description>
      <author>example@mail.com (R. Mirzaie)</author>
      <guid isPermaLink="false">2506.06779v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Harnessing Vision-Language Models for Time Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2506.06836v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉语言模型（VLM）的时间序列异常检测（TSAD）方法，旨在提高异常检测的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;时间序列异常检测在医疗、金融和工业监测等领域发挥着重要作用。传统方法主要关注在数值数据上训练特定领域的模型，但缺乏人类专家在识别情境异常方面的视觉-时间推理能力。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文探索了一种基于视觉语言模型（VLM）的解决方案，以增强异常检测的能力。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种两阶段解决方案：(1) ViT4TS，基于轻量级预训练视觉编码器构建的视觉筛选阶段，利用二维时间序列表示来准确定位候选异常；(2) VLM4TS，基于VLM的阶段，整合全局时间上下文和VLM推理能力，对ViT4TS提供的候选异常进行细化检测。&lt;h4&gt;主要发现&lt;/h4&gt;VLM4TS在大多数情况下，无需时间序列训练，在准确性和效率上都优于时间序列预训练和从头开始的基线，F1-max分数提高了24.6%。此外，VLM4TS在token使用效率上也优于现有的基于语言模型的TSAD方法，平均效率提高了36倍。&lt;h4&gt;结论&lt;/h4&gt;VLM4TS是一种有效且高效的时间序列异常检测方法，为该领域的研究提供了新的思路和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time-series anomaly detection (TSAD) has played a vital role in a variety offields, including healthcare, finance, and industrial monitoring. Priormethods, which mainly focus on training domain-specific models on numericaldata, lack the visual-temporal reasoning capacity that human experts have toidentify contextual anomalies. To fill this gap, we explore a solution based onvision language models (VLMs). Recent studies have shown the ability of VLMsfor visual reasoning tasks, yet their direct application to time series hasfallen short on both accuracy and efficiency. To harness the power of VLMs forTSAD, we propose a two-stage solution, with (1) ViT4TS, a vision-screeningstage built on a relatively lightweight pretrained vision encoder, whichleverages 2-D time-series representations to accurately localize candidateanomalies; (2) VLM4TS, a VLM-based stage that integrates global temporalcontext and VLM reasoning capacity to refine the detection upon the candidatesprovided by ViT4TS. We show that without any time-series training, VLM4TSoutperforms time-series pretrained and from-scratch baselines in most cases,yielding a 24.6 percent improvement in F1-max score over the best baseline.Moreover, VLM4TS also consistently outperforms existing language-model-basedTSAD methods and is on average 36 times more efficient in token usage.</description>
      <author>example@mail.com (Zelin He, Sarah Alnegheimish, Matthew Reimherr)</author>
      <guid isPermaLink="false">2506.06836v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>From Generation to Generalization: Emergent Few-Shot Learning in Video Diffusion Models</title>
      <link>http://arxiv.org/abs/2506.07280v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 23 figures, 9 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;视频扩散模型（VDMs）作为强大的生成工具，能够合成高质量的时空内容，其潜力远不止视频生成。VDMs的训练动态，由建模连贯序列的需求驱动，自然促使它们内化结构化的表示和视觉世界的隐含理解。&lt;h4&gt;背景&lt;/h4&gt;VDMs在视频生成领域取得了显著进展，但其潜在能力还未被完全挖掘。&lt;h4&gt;目的&lt;/h4&gt;为了探测VDMs内部知识范围，研究引入了一种小样本微调框架，利用少量示例重新部署VDMs以执行新任务。&lt;h4&gt;方法&lt;/h4&gt;该方法将每个任务转化为视觉过渡，使得模型可以在不改变冻结VDM生成界面的情况下，通过短输入输出序列训练LoRA权重。&lt;h4&gt;主要发现&lt;/h4&gt;尽管只有最小量的监督，该模型在多种任务上表现出强大的泛化能力，从低级视觉任务（如分割和姿态估计）到高级推理任务（如在ARC-AGI上）。&lt;h4&gt;结论&lt;/h4&gt;这些结果将VDMs重新定义为不仅仅是生成引擎，而是适应性视觉学习者，有潜力成为未来视觉领域基础模型的骨干。&lt;h4&gt;翻译&lt;/h4&gt;Video Diffusion Models (VDMs) have emerged as powerful generative tools, capable of synthesizing high-quality spatiotemporal content. Yet, their potential goes far beyond mere video generation. We argue that the training dynamics of VDMs, driven by the need to model coherent sequences, naturally pushes them to internalize structured representations and an implicit understanding of the visual world. To probe the extent of this internal knowledge, we introduce a few-shot fine-tuning framework that repurposes VDMs for new tasks using only a handful of examples. Our method transforms each task into a visual transition, enabling the training of LoRA weights on short input-output sequences without altering the generative interface of a frozen VDM. Despite minimal supervision, the model exhibits strong generalization across diverse tasks, from low-level vision (for example, segmentation and pose estimation) to high-level reasoning (for example, on ARC-AGI). These results reframe VDMs as more than generative engines. They are adaptable visual learners with the potential to serve as the backbone for future foundation models in vision.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Diffusion Models (VDMs) have emerged as powerful generative tools,capable of synthesizing high-quality spatiotemporal content. Yet, theirpotential goes far beyond mere video generation. We argue that the trainingdynamics of VDMs, driven by the need to model coherent sequences, naturallypushes them to internalize structured representations and an implicitunderstanding of the visual world. To probe the extent of this internalknowledge, we introduce a few-shot fine-tuning framework that repurposes VDMsfor new tasks using only a handful of examples. Our method transforms each taskinto a visual transition, enabling the training of LoRA weights on shortinput-output sequences without altering the generative interface of a frozenVDM. Despite minimal supervision, the model exhibits strong generalizationacross diverse tasks, from low-level vision (for example, segmentation and poseestimation) to high-level reasoning (for example, on ARC-AGI). These resultsreframe VDMs as more than generative engines. They are adaptable visuallearners with the potential to serve as the backbone for future foundationmodels in vision.</description>
      <author>example@mail.com (Pablo Acuaviva, Aram Davtyan, Mariam Hassan, Sebastian Stapf, Ahmad Rahimi, Alexandre Alahi, Paolo Favaro)</author>
      <guid isPermaLink="false">2506.07280v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>IQFM A Wireless Foundational Model for I/Q Streams in AI-Native 6G</title>
      <link>http://arxiv.org/abs/2506.06718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为IQFM的I/Q信号基础模型，用于无线通信，支持多种任务，如调制分类、到达角（AoA）、波束预测和射频指纹识别，无需复杂的预处理或手工特征。该模型在对比自监督学习（SSL）框架下，通过任务特定的增强策略，实现了高效的编码和分类，并在多个任务上取得了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;基础模型在自然语言处理和计算机视觉领域显示出巨大的潜力，但在无线通信领域仍处于起步阶段。目前，大多数研究集中在基于图像的模态上，如信道状态信息（CSI）和频率频谱，而直接在原始I/Q数据上操作的基础模型则很少被探索。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够在无线通信领域直接操作原始I/Q数据的基础模型，以支持多种无线通信任务。&lt;h4&gt;方法&lt;/h4&gt;提出IQFM模型，该模型通过任务特定的增强策略和对比自监督学习框架进行训练，并在实际数据上进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;IQFM模型在调制和到达角分类任务上分别达到了99.67%和65.45%的准确率，超过了监督基线模型。此外，该模型还能泛化到分布外的任务，使用少量样本和参数更新即可适应新任务。&lt;h4&gt;结论&lt;/h4&gt;原始I/Q数据基础模型在多任务学习方面具有巨大的潜力，可以作为高效、可重用的编码器，适用于AI原生的6G系统。&lt;h4&gt;翻译&lt;/h4&gt;Foundational models have shown remarkable potential in natural language processing and computer vision, yet remain in their infancy in wireless communications. While a few efforts have explored image-based modalities such as channel state information (CSI) and frequency spectrograms, foundational models that operate directly on raw IQ data remain largely unexplored. This paper presents, IQFM, the first I/Q signal foundational model for wireless communications. IQFM supporting diverse tasks: modulation classification, angle-of-arrival (AoA), beam prediction, and RF fingerprinting, without heavy preprocessing or handcrafted features. We also introduce a task-area augmentation strategy that categorizes transformations into core augmentations, such as cyclic time shifting, and task-specific augmentations. This strategy forms the basis for structured, task-dependent representation learning within a contrastive self-supervised learning (SSL) framework. Using this strategy, the lightweight encoder, pre-trained via SSL on over-the-air multi-antenna IQ data, achieves up to 99.67% and 65.45% accuracy on modulation and AoA classification, respectively, using only one labeled sample per class, outperforming supervised baselines by up to 7x and 145x. The model also generalizes to out-of-distribution tasks; when adapted to new tasks using only 500 samples per class and minimal parameter updates via LoRA, the same frozen encoder achieves 94.15% on beam prediction (vs. 89.53% supervised), 50.00% on RML2016a modulation classification (vs. 49.30%), and 96.05% on RF fingerprinting (vs. 96.64%). These results demonstrate the potential of raw IQ-based foundational models as efficient, reusable encoders for multi-task learning in AI-native 6G systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundational models have shown remarkable potential in natural languageprocessing and computer vision, yet remain in their infancy in wirelesscommunications. While a few efforts have explored image-based modalities suchas channel state information (CSI) and frequency spectrograms, foundationalmodels that operate directly on raw IQ data remain largely unexplored. Thispaper presents, IQFM, the first I/Q signal foundational model for wirelesscommunications. IQFM supporting diverse tasks: modulation classification,angle-of-arrival (AoA), beam prediction, and RF fingerprinting, without heavypreprocessing or handcrafted features. We also introduce a task-awareaugmentation strategy that categorizes transformations into core augmentations,such as cyclic time shifting, and task-specific augmentations. This strategyforms the basis for structured, task-dependent representation learning within acontrastive self-supervised learning (SSL) framework. Using this strategy, thelightweight encoder, pre-trained via SSL on over-the-air multi-antenna IQ data,achieves up to 99.67% and 65.45% accuracy on modulation and AoA classification,respectively, using only one labeled sample per class, outperforming supervisedbaselines by up to 7x and 145x. The model also generalizes toout-of-distribution tasks; when adapted to new tasks using only 500 samples perclass and minimal parameter updates via LoRA, the same frozen encoder achieves94.15% on beam prediction (vs. 89.53% supervised), 50.00% on RML2016amodulation classification (vs. 49.30%), and 96.05% on RF fingerprinting (vs.96.64%). These results demonstrate the potential of raw IQ-based foundationalmodels as efficient, reusable encoders for multi-task learning in AI-native 6Gsystems.</description>
      <author>example@mail.com (Omar Mashaal, Hatem Abou-Zeid)</author>
      <guid isPermaLink="false">2506.06718v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Situational Awareness in Underwater Robotics with Multi-modal Spatial Perception</title>
      <link>http://arxiv.org/abs/2506.06476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多模态传感的SLAM方法，用于提高水下自主和远程操作的能力。&lt;h4&gt;背景&lt;/h4&gt;水下环境中的光线衰减、散射和低对比度等问题常常导致基于视觉的SLAM方法失效，且这些方法通常依赖于单目或立体视觉输入，限制了其在多相机配置中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种融合来自多个传感器（包括相机、惯性测量单元和声学设备）的数据的方法，以增强情境感知并实现鲁棒的实时SLAM。&lt;h4&gt;方法&lt;/h4&gt;通过几何和基于学习的技术以及语义分析来探索解决方案，并在特隆赫姆峡湾的多个现场部署中收集的数据上进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在视觉挑战性的水下环境中，该方法可以实现实时可靠的状态估计和高质量的3D重建。&lt;h4&gt;结论&lt;/h4&gt;系统存在约束，并提出了需要进一步探索的研究问题，如传感器校准和基于学习方法的局限性，以推进大规模水下作业。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a multi-modal sensing-based SLAM method to enhance the capabilities of underwater autonomous and remote operations. The underwater environment often leads to the failure of vision-based SLAM methods due to issues such as light attenuation, scattering, and low contrast, and these methods typically rely on monocular or stereo vision inputs, limiting their application in multi-camera configurations. The proposed method fuses data from multiple sensors, including cameras, inertial measurement units (IMUs), and acoustic devices, to enhance situational awareness and enable robust, real-time SLAM. Solutions are explored using geometric and learning-based techniques along with semantic analysis, and experiments are conducted on data collected from a work-class ROV during several field deployments in the Trondheim Fjord. The experimental results demonstrate the feasibility of real-time reliable state estimation and high-quality 3D reconstructions in visually challenging underwater conditions. System constraints are discussed, and open research questions, such as sensor calibration and limitations with learning-based methods, are identified for further exploration to advance large-scale underwater operations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous Underwater Vehicles (AUVs) and Remotely Operated Vehicles (ROVs)demand robust spatial perception capabilities, including SimultaneousLocalization and Mapping (SLAM), to support both remote and autonomous tasks.Vision-based systems have been integral to these advancements, capturing richcolor and texture at low cost while enabling semantic scene understanding.However, underwater conditions -- such as light attenuation, backscatter, andlow contrast -- often degrade image quality to the point where traditionalvision-based SLAM pipelines fail. Moreover, these pipelines typically rely onmonocular or stereo inputs, limiting their scalability to the multi-cameraconfigurations common on many vehicles. To address these issues, we propose toleverage multi-modal sensing that fuses data from multiple sensors-includingcameras, inertial measurement units (IMUs), and acoustic devices-to enhancesituational awareness and enable robust, real-time SLAM. We explore bothgeometric and learning-based techniques along with semantic analysis, andconduct experiments on the data collected from a work-class ROV during severalfield deployments in the Trondheim Fjord. Through our experimental results, wedemonstrate the feasibility of real-time reliable state estimation andhigh-quality 3D reconstructions in visually challenging underwater conditions.We also discuss system constraints and identify open research questions, suchas sensor calibration, limitations with learning-based methods, that meritfurther exploration to advance large-scale underwater operations.</description>
      <author>example@mail.com (Pushyami Kaveti, Ambjorn Grimsrud Waldum, Hanumant Singh, Martin Ludvigsen)</author>
      <guid isPermaLink="false">2506.06476v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Promoting Ensemble Diversity with Interactive Bayesian Distributional Robustness for Fine-tuning Foundation Models</title>
      <link>http://arxiv.org/abs/2506.07247v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 (Poster)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Interactive Bayesian Distributional Robustness（IBDR）的新颖贝叶斯推理框架，通过增强粒子多样性来提高集成质量。&lt;h4&gt;背景&lt;/h4&gt;IBDR基于一个广义的理论框架，该框架将分布损失与近似的后验概率联系起来。&lt;h4&gt;目的&lt;/h4&gt;通过实现分布鲁棒性和粒子多样性来提升贝叶斯推理的效率。&lt;h4&gt;方法&lt;/h4&gt;采用了一种双重优化过程，在保证分布鲁棒性的同时促进粒子多样性。&lt;h4&gt;主要发现&lt;/h4&gt;使用VTAB-1K基准和常见推理语言任务评估IBDR的性能，结果显示IBDR优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;IBDR在现实世界应用中的有效性得到证实。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为交互式贝叶斯分布鲁棒性（IBDR）的贝叶斯推理新框架，该框架允许建模粒子之间的相互作用，从而通过增加粒子多样性来提高集成质量。IBDR建立在将分布损失与近似后验概率相联系的一般化理论框架之上，从而激发了一种实用的双重优化过程，该过程强制执行分布鲁棒性同时促进粒子多样性。我们使用VTAB-1K基准和常见推理语言任务将IBDR的性能与各种基线方法进行了比较。结果表明，IBDR在这些基线方法中表现优异，强调了其在现实世界应用中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Interactive Bayesian Distributional Robustness (IBDR), a novelBayesian inference framework that allows modeling the interactions betweenparticles, thereby enhancing ensemble quality through increased particlediversity. IBDR is grounded in a generalized theoretical framework thatconnects the distributional population loss with the approximate posterior,motivating a practical dual optimization procedure that enforces distributionalrobustness while fostering particle diversity. We evaluate IBDR's performanceagainst various baseline methods using the VTAB-1K benchmark and the commonreasoning language task. The results consistently show that IBDR outperformsthese baselines, underscoring its effectiveness in real-world applications.</description>
      <author>example@mail.com (Ngoc-Quan Pham, Tuan Truong, Quyen Tran, Tan Nguyen, Dinh Phung, Trung Le)</author>
      <guid isPermaLink="false">2506.07247v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Caterpillar GNN: Replacing Message Passing with Efficient Aggregation</title>
      <link>http://arxiv.org/abs/2506.06784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  40 pages, 9 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种高效聚合机制的消息传递图神经网络（MPGNNs），通过降低表达力来增强聚合能力，并成功应用于图级别任务。&lt;h4&gt;背景&lt;/h4&gt;现代图学习中的MPGNNs注重表达力的最大化，而本文提出了一个不同的方法。&lt;h4&gt;目的&lt;/h4&gt;通过降低表达力，增强MPGNNs的聚合能力，并提高其在图级别任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;引入了一种高效的聚合机制，该机制允许在经典的消息传递和基于着色或普通游走的方法之间无缝扩展。通过同态计数和广义毛毛虫图的层次结构来严格地描述每一步的表达能力，并基于此提出了毛毛虫GNN。&lt;h4&gt;主要发现&lt;/h4&gt;毛毛虫GNN通过其稳健的图级别聚合能力，在特定的合成图级别任务中成功应对了挑战，这些任务对传统的MPGNNs来说很难。此外，在真实世界的数据集上，毛毛虫GNN在保持预测性能的同时，显著减少了计算图中隐藏层中的节点数量。&lt;h4&gt;结论&lt;/h4&gt;毛毛虫GNN是一种有效的MPGNNs，它通过优化聚合机制在图级别任务中表现出色，并在真实世界数据集上实现了可观的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：消息传递图神经网络（MPGNNs）在现代图学习中占据主导地位，通常优先考虑最大的表达能力。相比之下，我们引入了一种高效的聚合机制，故意牺牲一些表达力以获得更强和更有结构的聚合能力。我们的方法允许在经典的消息传递和基于着色或普通游走的方法之间无缝扩展。我们使用广义毛毛虫图的层次结构中的同态计数严格地描述每个中间步骤的表达能力。基于这个基础，我们提出了毛毛虫GNN，它通过其稳健的图级别聚合能力，能够成功地处理专门为挑战经典MPGNNs而设计的合成图级别任务。此外，我们在真实世界的数据集上证明了，毛毛虫GNN在保持预测性能的同时，显著减少了计算图中隐藏层中的节点数量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Message-passing graph neural networks (MPGNNs) dominate modern graphlearning, typically prioritizing maximal expressive power. In contrast, weintroduce an \emph{efficient aggregation} mechanism, deliberately trading offsome expressivity for stronger and more structured aggregation capabilities.Our approach allows seamless scaling between classical message-passing andsimpler methods based on colored or plain walks. We rigorously characterize theexpressive power at each intermediate step using homomorphism counts from ahierarchy of generalized \emph{caterpillar graphs}. Based on this foundation,we propose the \emph{Caterpillar GNN}, whose robust graph-level aggregationenables it to successfully tackle synthetic graph-level task specificallydesigned to be challenging for classical MPGNNs. Moreover, we demonstrate that,on real-world datasets, the Caterpillar GNN achieves comparable predictiveperformance while significantly reducing the number of nodes in the hiddenlayers of the computational graph.</description>
      <author>example@mail.com (Marek Černý)</author>
      <guid isPermaLink="false">2506.06784v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Challenging Vision-Language Models with Surgical Data: A New Dataset and Broad Benchmarking Study</title>
      <link>http://arxiv.org/abs/2506.06232v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视觉语言模型（VLMs）在腔镜手术等内窥镜任务中的应用能力，发现VLMs在基础感知任务上表现良好，但在需要医学知识的高级任务上表现不佳，且专业医疗VLMs在基本和高级手术任务上均不如通用模型，指出需要进一步发展以应对手术的独特挑战。&lt;h4&gt;背景&lt;/h4&gt;传统计算机视觉模型在内窥镜领域泛化能力有限，而基础模型在跨领域性能上展现出潜力。&lt;h4&gt;目的&lt;/h4&gt;评估VLMs在内窥镜任务中的能力，特别是针对腔镜手术。&lt;h4&gt;方法&lt;/h4&gt;使用多种最先进的模型、多个手术数据集和大量的人类参考标注，解决三个关键研究问题：VLMs能否解决基本的感知任务？能否处理基于帧的高级内窥镜场景理解任务？专业医疗VLMs与通用模型相比如何？&lt;h4&gt;主要发现&lt;/h4&gt;VLMs在基本手术感知任务上表现良好，如物体计数和定位，但在需要医学知识的高级任务上表现不佳。专业医疗VLMs在基本和高级手术任务上均不如通用模型，表明它们尚未针对手术环境的复杂性进行优化。&lt;h4&gt;结论&lt;/h4&gt;VLMs在基础感知任务上表现可接受，但在需要医学知识的高级任务上存在不足，需要进一步研究和发展以应对手术的独特挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While traditional computer vision models have historically struggled togeneralize to endoscopic domains, the emergence of foundation models has shownpromising cross-domain performance. In this work, we present the firstlarge-scale study assessing the capabilities of Vision Language Models (VLMs)for endoscopic tasks with a specific focus on laparoscopic surgery. Using adiverse set of state-of-the-art models, multiple surgical datasets, andextensive human reference annotations, we address three key research questions:(1) Can current VLMs solve basic perception tasks on surgical images? (2) Canthey handle advanced frame-based endoscopic scene understanding tasks? and (3)How do specialized medical VLMs compare to generalist models in this context?Our results reveal that VLMs can effectively perform basic surgical perceptiontasks, such as object counting and localization, with performance levelscomparable to general domain tasks. However, their performance deterioratessignificantly when the tasks require medical knowledge. Notably, we find thatspecialized medical VLMs currently underperform compared to generalist modelsacross both basic and advanced surgical tasks, suggesting that they are not yetoptimized for the complexity of surgical environments. These findings highlightthe need for further advancements to enable VLMs to handle the uniquechallenges posed by surgery. Overall, our work provides important insights forthe development of next-generation endoscopic AI systems and identifies keyareas for improvement in medical visual language models.</description>
      <author>example@mail.com (Leon Mayer, Tim Rädsch, Dominik Michael, Lucas Luttner, Amine Yamlahi, Evangelia Christodoulou, Patrick Godau, Marcel Knopp, Annika Reinke, Fiona Kolbinger, Lena Maier-Hein)</author>
      <guid isPermaLink="false">2506.06232v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Robotic Policy Learning via Human-assisted Action Preference Optimization</title>
      <link>http://arxiv.org/abs/2506.07127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为HAPO的人辅助动作偏好优化方法，旨在通过偏好对齐来纠正部署失败并促进VLA模型的有效适应。&lt;h4&gt;背景&lt;/h4&gt;虽然VLA模型是机器人部署的基础模型，但它们依赖于专家演示，这限制了从失败中学习和纠正的能力。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一局限性，提出HAPO方法以实现可靠的部署和从失败中学习。&lt;h4&gt;方法&lt;/h4&gt;HAPO方法包括一个人类-机器人协作框架，用于可靠的失败纠正和通过人类干预收集交互轨迹。这些轨迹随后用于动作偏好优化过程，帮助VLA模型减少失败动作的发生并增强纠正动作的适应性。还提出了一种自适应重新加权算法，以解决在VLA模型中引入偏好优化时不可逆交互和标记概率不匹配的问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明，该方法在各种操作任务中具有优越的泛化能力和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;HAPO方法确保了VLA模型的可靠部署和有效的失败学习。&lt;h4&gt;翻译&lt;/h4&gt;Establishing a reliable and iteratively refined robotic system is essential for deploying real-world applications. While Vision-Language-Action (VLA) models are widely recognized as the foundation model for such robotic deployment, their dependence on expert demonstrations hinders the crucial capabilities of correction and learning from failures. To mitigate this limitation, we introduce a Human-assisted Action Preference Optimization method named HAPO, designed to correct deployment failures and foster effective adaptation through preference alignment for VLA models. This method begins with a human-robot collaboration framework for reliable failure correction and interaction trajectory collection through human intervention. These human-intervention trajectories are further employed within the action preference optimization process, facilitating VLA models to mitigate failure action occurrences while enhancing corrective action adaptation. Specifically, we propose an adaptive reweighting algorithm to address the issues of irreversible interactions and token probability mismatch when introducing preference optimization into VLA models, facilitating model learning from binary desirability signals derived from interactions. Through combining these modules, our human-assisted action preference optimization method ensures reliable deployment and effective learning from failure for VLA models. The experiments conducted in simulation and real-world scenarios prove superior generalization and robustness of our framework across a variety of manipulation tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Establishing a reliable and iteratively refined robotic system is essentialfor deploying real-world applications. While Vision-Language-Action (VLA)models are widely recognized as the foundation model for such roboticdeployment, their dependence on expert demonstrations hinders the crucialcapabilities of correction and learning from failures. To mitigate thislimitation, we introduce a Human-assisted Action Preference Optimization methodnamed HAPO, designed to correct deployment failures and foster effectiveadaptation through preference alignment for VLA models. This method begins witha human-robot collaboration framework for reliable failure correction andinteraction trajectory collection through human intervention. Thesehuman-intervention trajectories are further employed within the actionpreference optimization process, facilitating VLA models to mitigate failureaction occurrences while enhancing corrective action adaptation. Specifically,we propose an adaptive reweighting algorithm to address the issues ofirreversible interactions and token probability mismatch when introducingpreference optimization into VLA models, facilitating model learning frombinary desirability signals derived from interactions. Through combining thesemodules, our human-assisted action preference optimization method ensuresreliable deployment and effective learning from failure for VLA models. Theexperiments conducted in simulation and real-world scenarios prove superiorgeneralization and robustness of our framework across a variety of manipulationtasks.</description>
      <author>example@mail.com (Wenke xia, Yichu Yang, Hongtao Wu, Xiao Ma, Tao Kong, Di Hu)</author>
      <guid isPermaLink="false">2506.07127v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Ai-Driven Vulnerability Analysis in Smart Contracts: Trends, Challenges and Future Directions</title>
      <link>http://arxiv.org/abs/2506.06735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于AI的智能合约漏洞检测技术，分析了机器学习、深度学习、图神经网络和基于Transformer的模型在智能合约安全中的应用。&lt;h4&gt;背景&lt;/h4&gt;智能合约是区块链生态系统的重要组成部分，但存在如数值溢出、重入攻击和不当访问权限等漏洞，导致大量资金损失。&lt;h4&gt;目的&lt;/h4&gt;研究新型AI驱动的智能合约漏洞检测技术，提高安全性和自动化审计。&lt;h4&gt;方法&lt;/h4&gt;本文分析了机器学习、深度学习、图神经网络和基于Transformer的模型在智能合约安全中的应用，比较了这些技术在准确性、可解释性、计算开销和实时适用性方面的优缺点。&lt;h4&gt;主要发现&lt;/h4&gt;AI技术在智能合约漏洞检测方面展现出潜力，但存在一些开放挑战和未来机遇。&lt;h4&gt;结论&lt;/h4&gt;AI技术在智能合约安全领域具有发展潜力，但仍需解决一些开放挑战和未来的发展机遇。&lt;h4&gt;翻译&lt;/h4&gt;The abstract discusses novel AI-driven techniques for vulnerability detection in smart contracts, analyzing the application of machine learning, deep learning, graph neural networks, and transformer-based models in the field of smart contract security.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.5121/ijaia.2025.16305&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Smart contracts, integral to blockchain ecosystems, enable decentralizedapplications to execute predefined operations without intermediaries. Theirability to enforce trustless interactions has made them a core component ofplatforms such as Ethereum. Vulnerabilities such as numerical overflows,reentrancy attacks, and improper access permissions have led to the loss ofmillions of dollars throughout the blockchain and smart contract sector.Traditional smart contract auditing techniques such as manual code reviews andformal verification face limitations in scalability, automation, andadaptability to evolving development patterns. As a result, AI-based solutionshave emerged as a promising alternative, offering the ability to learn complexpatterns, detect subtle flaws, and provide scalable security assurances. Thispaper examines novel AI-driven techniques for vulnerability detection in smartcontracts, focusing on machine learning, deep learning, graph neural networks,and transformer-based models. This paper analyzes how each technique representscode, processes semantic information, and responds to real world vulnerabilityclasses. We also compare their strengths and weaknesses in terms of accuracy,interpretability, computational overhead, and real time applicability. Lastly,it highlights open challenges and future opportunities for advancing thisdomain.</description>
      <author>example@mail.com (Mesut Ozdag)</author>
      <guid isPermaLink="false">2506.06735v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>STSBench: A Spatio-temporal Scenario Benchmark for Multi-modal Large Language Models in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2506.06218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Dataset: https://huggingface.co/datasets/ivc-lrp/STSBench, Code:  https://github.com/LRP-IVC/STSBench&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了STSBench，一个基于场景的框架，用于评估自动驾驶中视觉语言模型（VLMs）的整体理解能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基准测试通常针对单视角的图像或视频，以及针对语义任务如物体识别、密集描述、风险评估或场景理解的VLMs。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够评估VLMs在复杂环境中对基本交通动态推理能力的基准。&lt;h4&gt;方法&lt;/h4&gt;STSBench自动从数据集中挖掘预定义的交通场景，提供直观的用户界面以便高效的人工验证，并为模型评估生成多项选择题。&lt;h4&gt;主要发现&lt;/h4&gt;该基准揭示了现有模型在复杂环境中推理基本交通动态方面的关键不足。&lt;h4&gt;结论&lt;/h4&gt;STSBench通过解决空间时间评估的核心差距，有助于开发更稳健和可解释的VLMs，以用于自动驾驶。&lt;h4&gt;翻译&lt;/h4&gt;We introduce STSBench, a scenario-based framework to benchmark the holistic understanding of vision-language models (VLMs) for autonomous driving. The framework automatically mines pre-defined traffic scenarios from any dataset using ground-truth annotations, provides an intuitive user interface for efficient human verification, and generates multiple-choice questions for model evaluation. Applied to the NuScenes dataset, we present STSnu, the first benchmark that evaluates the spatio-temporal reasoning capabilities of VLMs based on comprehensive 3D perception. Existing benchmarks typically target off-the-shelf or fine-tuned VLMs for images or videos from a single viewpoint and focus on semantic tasks such as object recognition, dense captioning, risk assessment, or scene understanding. In contrast, STSnu evaluates driving expert VLMs for end-to-end driving, operating on videos from multi-view cameras or LiDAR. It specifically assesses their ability to reason about both ego-vehicle actions and complex interactions among traffic participants, a crucial capability for autonomous vehicles. The benchmark features 43 diverse scenarios spanning multiple views and frames, resulting in 971 human-verified multiple-choice questions. A thorough evaluation uncovers critical shortcomings in existing models' ability to reason about fundamental traffic dynamics in complex environments. These findings highlight the urgent need for architectural advances that explicitly model spatio-temporal reasoning. By addressing a core gap in spatio-temporal evaluation, STSBench enables the development of more robust and explainable VLMs for autonomous driving.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce STSBench, a scenario-based framework to benchmark the holisticunderstanding of vision-language models (VLMs) for autonomous driving. Theframework automatically mines pre-defined traffic scenarios from any datasetusing ground-truth annotations, provides an intuitive user interface forefficient human verification, and generates multiple-choice questions for modelevaluation. Applied to the NuScenes dataset, we present STSnu, the firstbenchmark that evaluates the spatio-temporal reasoning capabilities of VLMsbased on comprehensive 3D perception. Existing benchmarks typically targetoff-the-shelf or fine-tuned VLMs for images or videos from a single viewpointand focus on semantic tasks such as object recognition, dense captioning, riskassessment, or scene understanding. In contrast, STSnu evaluates driving expertVLMs for end-to-end driving, operating on videos from multi-view cameras orLiDAR. It specifically assesses their ability to reason about both ego-vehicleactions and complex interactions among traffic participants, a crucialcapability for autonomous vehicles. The benchmark features 43 diverse scenariosspanning multiple views and frames, resulting in 971 human-verifiedmultiple-choice questions. A thorough evaluation uncovers critical shortcomingsin existing models' ability to reason about fundamental traffic dynamics incomplex environments. These findings highlight the urgent need forarchitectural advances that explicitly model spatio-temporal reasoning. Byaddressing a core gap in spatio-temporal evaluation, STSBench enables thedevelopment of more robust and explainable VLMs for autonomous driving.</description>
      <author>example@mail.com (Christian Fruhwirth-Reisinger, Dušan Malić, Wei Lin, David Schinagl, Samuel Schulter, Horst Possegger)</author>
      <guid isPermaLink="false">2506.06218v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>E-BATS: Efficient Backpropagation-Free Test-Time Adaptation for Speech Foundation Models</title>
      <link>http://arxiv.org/abs/2506.07078v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种针对语音基础模型的新型有效无反向传播测试时自适应（TTA）框架E-BATS，旨在解决实际场景中由于声学域偏移导致的性能下降问题。&lt;h4&gt;背景&lt;/h4&gt;语音基础模型在实际应用中面临声学域偏移的挑战，如背景噪声和说话人口音，导致性能下降。传统的TTA方法依赖反向传播，内存消耗大，限制了其在资源受限环境中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出E-BATS框架，旨在实现高效的TTA，同时降低内存消耗，并提高适应效果。&lt;h4&gt;方法&lt;/h4&gt;E-BATS通过三个关键组件实现平衡：轻量级的提示自适应、多尺度损失捕捉全局和局部分布偏移，以及测试时指数移动平均机制实现稳定的跨句子自适应。&lt;h4&gt;主要发现&lt;/h4&gt;在四个噪声语音数据集上进行的实验表明，E-BATS在四个噪声语音数据集上实现了持续的性能提升，与无反向传播基线相比，准确率提高了4.1%-13.5%，同时比基于反向传播的方法节省了2.0-6.4倍的GPU内存。&lt;h4&gt;结论&lt;/h4&gt;E-BATS为在声学变化下实现可扩展和鲁棒的适应提供了途径，为实际环境中的语音处理系统开发更有效的自适应方法铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在涉及声学域偏移的实际场景中，语音基础模型会遇到显著的性能下降，例如背景噪声和说话人口音。测试时自适应（TTA）最近被证明是一种可行的策略，可以在推理时解决这种域偏移，而不需要访问源数据或标签。然而，现有的TTA方法，尤其是那些依赖反向传播的方法，内存密集，限制了它们在语音任务和资源受限环境中的应用。尽管无反向传播的方法提供了改进的效率，但现有的方法在准确性方面表现不佳。这是因为它们主要用于视觉任务，与语音任务的表达式、噪声特征和模型架构根本不同，从而带来了独特的可迁移性挑战。在这篇论文中，我们介绍了E-BATS，这是第一个专为语音基础模型设计的有效无反向传播TTA框架。E-BATS通过三个关键组件在适应性有效性和内存效率之间实现了平衡：（i）基于前向传递的特征对齐的轻量级提示自适应，（ii）多尺度损失以捕捉全局（句子级）和局部分布偏移（标记级），以及（iii）测试时指数移动平均机制以实现跨句子的稳定自适应。在涵盖十六种声学条件的四个噪声语音数据集上进行的实验表明，E-BATS实现了持续的性能提升，与无反向传播基线相比，准确率提高了4.1%-13.5%，与基于反向传播的方法相比，GPU内存节省了2.0-6.4倍。通过在声学变化下实现可扩展和鲁棒的适应，这项工作为开发实际环境中的实用语音处理系统的更有效自适应方法铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech Foundation Models encounter significant performance degradation whendeployed in real-world scenarios involving acoustic domain shifts, such asbackground noise and speaker accents. Test-time adaptation (TTA) has recentlyemerged as a viable strategy to address such domain shifts at inference timewithout requiring access to source data or labels. However, existing TTAapproaches, particularly those relying on backpropagation, arememory-intensive, limiting their applicability in speech tasks andresource-constrained settings. Although backpropagation-free methods offerimproved efficiency, existing ones exhibit poor accuracy. This is because theyare predominantly developed for vision tasks, which fundamentally differ fromspeech task formulations, noise characteristics, and model architecture, posingunique transferability challenges. In this paper, we introduce E-BATS, thefirst Efficient BAckpropagation-free TTA framework designed explicitly forspeech foundation models. E-BATS achieves a balance between adaptationeffectiveness and memory efficiency through three key components: (i)lightweight prompt adaptation for a forward-pass-based feature alignment, (ii)a multi-scale loss to capture both global (utterance-level) and localdistribution shifts (token-level) and (iii) a test-time exponential movingaverage mechanism for stable adaptation across utterances. Experimentsconducted on four noisy speech datasets spanning sixteen acoustic conditionsdemonstrate consistent improvements, with 4.1%-13.5% accuracy gains overbackpropagation-free baselines and 2.0-6.4 times GPU memory savings compared tobackpropagation-based methods. By enabling scalable and robust adaptation underacoustic variability, this work paves the way for developing more efficientadaptation approaches for practical speech processing systems in real-worldenvironments.</description>
      <author>example@mail.com (Jiaheng Dong, Hong Jia, Soumyajit Chatterjee, Abhirup Ghosh, James Bailey, Ting Dang)</author>
      <guid isPermaLink="false">2506.07078v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Neighborhood Overlap-Aware High-Order Graph Neural Network for Dynamic Graph Learning</title>
      <link>http://arxiv.org/abs/2506.06728v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为NO-HGNN的动态图学习新方法，旨在通过考虑邻域重叠来提高节点嵌入的准确性，从而支持下游任务如链接预测。&lt;h4&gt;背景&lt;/h4&gt;动态图学习（DGL）旨在学习具有时间演化的节点嵌入，以支持链接预测等下游任务。在DGL中，有效建模图拓扑的时序动态和结构依赖是一个基本挑战。&lt;h4&gt;目的&lt;/h4&gt;提出NO-HGNN方法，以克服现有方法在捕捉节点交互时忽略复杂结构模式（如邻域重叠）的局限性。&lt;h4&gt;方法&lt;/h4&gt;NO-HGNN基于两个关键创新：（a）计算基于邻域重叠程度的关联分数，以更好地捕捉复杂的节点交互；（b）将这种关联直接嵌入到DGL中高阶图神经网络的消息传递过程中。&lt;h4&gt;主要发现&lt;/h4&gt;在两个真实世界动态图上的实验表明，NO-HGNN在链接预测准确性方面取得了显著的改进，优于几种最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;NO-HGNN通过考虑邻域重叠，在动态图学习领域实现了链接预测性能的提升，为该领域的研究提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic graph learning (DGL) aims to learn informative andtemporally-evolving node embeddings to support downstream tasks such as linkprediction. A fundamental challenge in DGL lies in effectively modeling boththe temporal dynamics and structural dependencies of evolving graph topologies.Recent advances in Dynamic Graph Neural Networks (DGNNs) have obtainedremarkable success by leveraging message-passing mechanisms to capture pairwisenode interactions. However, these approaches often overlook more complexstructural patterns, particularly neighborhood overlap, which can play acritical role in characterizing node interactions. To overcome this limitation,we introduce the Neighborhood Overlap-Aware High-Order Graph Neural Network(NO-HGNN), which is built upon two key innovations: (a) computing a correlationscore based on the extent of neighborhood overlap to better capture complexnode interactions; and (b) embedding this correlation directly into themessage-passing process of high-order graph neural networks in the DGL.Experiments on two real-world dynamic graphs show that NO-HGNN achieves notableimprovements in link prediction accuracy, outperforming severalstate-of-the-art approaches.</description>
      <author>example@mail.com (Ling Wang)</author>
      <guid isPermaLink="false">2506.06728v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Audio and Vision: Zero-Shot Audiovisual Segmentation by Connecting Pretrained Models</title>
      <link>http://arxiv.org/abs/2506.06537v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted on INTERSPEECH2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的零样本视听分割（AVS）框架，旨在通过利用多个预训练模型来识别与声音源相对应的视觉区域，以提高视频理解、监控和人类-计算机交互的效率。&lt;h4&gt;背景&lt;/h4&gt;传统的AVS方法依赖于大规模的像素级标注，这既昂贵又耗时。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在提出一种无需特定任务训练的零样本AVS框架。&lt;h4&gt;方法&lt;/h4&gt;该方法通过整合音频、视觉和文本表示来弥合模态差距，实现精确的声音源分割，同时不需要AVS特定的标注。文章系统地探讨了连接预训练模型的不同策略，并评估了它们在多个数据集上的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，本文提出的框架实现了最先进的零样本AVS性能，突显了多模态模型集成在细粒度视听分割中的有效性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的零样本AVS框架为视频理解、监控和人类-计算机交互等领域提供了有效的解决方案，并证明了多模态模型集成在视听分割中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audiovisual segmentation (AVS) aims to identify visual regions correspondingto sound sources, playing a vital role in video understanding, surveillance,and human-computer interaction. Traditional AVS methods depend on large-scalepixel-level annotations, which are costly and time-consuming to obtain. Toaddress this, we propose a novel zero-shot AVS framework that eliminatestask-specific training by leveraging multiple pretrained models. Our approachintegrates audio, vision, and text representations to bridge modality gaps,enabling precise sound source segmentation without AVS-specific annotations. Wesystematically explore different strategies for connecting pretrained modelsand evaluate their efficacy across multiple datasets. Experimental resultsdemonstrate that our framework achieves state-of-the-art zero-shot AVSperformance, highlighting the effectiveness of multimodal model integration forfinegrained audiovisual segmentation.</description>
      <author>example@mail.com (Seung-jae Lee, Paul Hongsuck Seo)</author>
      <guid isPermaLink="false">2506.06537v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Semi-supervised Segmentation Beyond Accuracy: Reliability and Robustness</title>
      <link>http://arxiv.org/abs/2506.05917v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文讨论了语义分割的重要性及其对场景理解的影响，指出了当前半监督分割评估协议的不足，并提出了一个新的评估指标——可靠分割得分（RSS），以更全面地评估分割模型。&lt;h4&gt;背景&lt;/h4&gt;语义分割对于场景理解至关重要，但其需要昂贵的像素级标注，因此半监督方法吸引了越来越多的关注。然而，现有的评估协议主要关注分割精度，而忽略了可靠性和鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，论文提出了一个名为可靠分割得分（RSS）的新指标，该指标结合了预测精度、校准和不确定性质量度量。&lt;h4&gt;方法&lt;/h4&gt;RSS通过调和平均数结合了这些度量，并对任何组成部分的不足进行惩罚，从而提供了一种简单直观的方法来全面评估分割模型。&lt;h4&gt;主要发现&lt;/h4&gt;对UniMatchV2及其前一代和监督基线的方法进行了综合评估，结果表明半监督方法通常在可靠性和精度之间进行权衡。虽然域外评估显示了UniMatchV2的鲁棒性，但也暴露了持续的可靠性不足。&lt;h4&gt;结论&lt;/h4&gt;论文主张评估协议转向更全面的指标，如RSS，以更好地将半监督学习研究与实际部署需求对齐。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语义分割对于场景理解至关重要，但需要昂贵的像素级标注，这促使人们越来越关注利用大量未标记数据的半监督方法。虽然半监督分割通常被视为通往可扩展、实际部署的途径，但令人惊讶的是，当前的评估协议仅关注分割精度，完全忽略了可靠性和鲁棒性。这些确保在不同条件下保持一致性能（鲁棒性）以及模型置信度良好以及不确定性有意义的（可靠性）质量是自动驾驶等安全关键应用所必需的，在这些应用中，模型必须处理不可预测的环境，并不惜一切代价避免突然故障。为了解决这一差距，我们引入了可靠分割得分（RSS），这是一种新的度量，通过调和平均数结合预测精度、校准和不确定性质量度量。RSS对其任何组成部分的不足进行惩罚，提供了一种简单直观的方式来全面评估分割模型。对UniMatchV2与其前身和监督基线的方法进行的综合评估表明，半监督方法通常在可靠性和精度之间进行权衡。虽然域外评估显示了UniMatchV2的鲁棒性，但它们进一步暴露了持续的可靠性不足。我们主张评估协议转向更全面的指标，如RSS，以更好地将半监督学习研究与实际部署需求对齐。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic segmentation is critical for scene understanding but demands costlypixel-wise annotations, attracting increasing attention to semi-supervisedapproaches to leverage abundant unlabeled data. While semi-supervisedsegmentation is often promoted as a path toward scalable, real-worlddeployment, it is astonishing that current evaluation protocols exclusivelyfocus on segmentation accuracy, entirely overlooking reliability androbustness. These qualities, which ensure consistent performance under diverseconditions (robustness) and well-calibrated model confidences as well asmeaningful uncertainties (reliability), are essential for safety-criticalapplications like autonomous driving, where models must handle unpredictableenvironments and avoid sudden failures at all costs. To address this gap, weintroduce the Reliable Segmentation Score (RSS), a novel metric that combinespredictive accuracy, calibration, and uncertainty quality measures via aharmonic mean. RSS penalizes deficiencies in any of its components, providingan easy and intuitive way of holistically judging segmentation models.Comprehensive evaluations of UniMatchV2 against its predecessor and asupervised baseline show that semi-supervised methods often trade reliabilityfor accuracy. While out-of-domain evaluations demonstrate UniMatchV2'srobustness, they further expose persistent reliability shortcomings. Weadvocate for a shift in evaluation protocols toward more holistic metrics likeRSS to better align semi-supervised learning research with real-worlddeployment needs.</description>
      <author>example@mail.com (Steven Landgraf, Markus Hillemann, Markus Ulrich)</author>
      <guid isPermaLink="false">2506.05917v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Graph Persistence goes Spectral</title>
      <link>http://arxiv.org/abs/2506.06571v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 4 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图拓扑描述符SpectRe，该描述符将谱信息整合到持久同伦图中，并在图表示学习中展现出比现有描述符更高的表达能力。&lt;h4&gt;背景&lt;/h4&gt;在图神经网络（GNNs）中，包括复杂的拓扑信息（如环路）可以证明能够超越Weisfeiler-Leman（WL）层次，从而增强其表达能力。持久同伦（PH）方法越来越多地用于图表示学习，但现有方法由于依赖于特征，仍然无法捕获基本的图结构信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的图拓扑描述符SpectRe，以增强图表示学习的表达能力，并捕获基本的图结构信息。&lt;h4&gt;方法&lt;/h4&gt;SpectRe将谱信息与持久同伦图相结合，并引入全局和局部稳定性的概念来分析现有描述符。&lt;h4&gt;主要发现&lt;/h4&gt;SpectRe在图上具有比现有描述符更高的表达能力，并且在局部上是稳定的。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，SpectRe在合成和真实世界数据集上都是有效的，并且有可能增强图模型在相关学习任务中的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：包括复杂的拓扑信息（例如，环路）可以证明能够超越Weisfeiler-Leman（WL）层次，从而增强信息传递图神经网络（GNNs）的表达能力。因此，持久同伦（PH）方法越来越多地用于图表示学习。在此背景下，最近的工作提出用顶点和边特征装饰经典的PH图以提高表达能力。然而，由于它们依赖于特征，这些方法仍然无法捕获基本的图结构信息。在本文中，我们提出了一种新的图拓扑描述符SpectRe，该描述符将谱信息整合到PH图中。值得注意的是，SpectRe在图上严格优于现有描述符。我们还引入了全局和局部稳定性的概念来分析现有描述符，并证明SpectRe是局部稳定的。最后，在合成和真实世界数据集上的实验表明了SpectRe的有效性及其增强相关学习任务中图模型能力的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Including intricate topological information (e.g., cycles) provably enhancesthe expressivity of message-passing graph neural networks (GNNs) beyond theWeisfeiler-Leman (WL) hierarchy. Consequently, Persistent Homology (PH) methodsare increasingly employed for graph representation learning. In this context,recent works have proposed decorating classical PH diagrams with vertex andedge features for improved expressivity. However, due to their dependence onfeatures, these methods still fail to capture basic graph structuralinformation. In this paper, we propose SpectRe -- a new topological descriptorfor graphs that integrates spectral information into PH diagrams. Notably,SpectRe is strictly more expressive than existing descriptors on graphs. Wealso introduce notions of global and local stability to analyze existingdescriptors and establish that SpectRe is locally stable. Finally, experimentson synthetic and real-world datasets demonstrate the effectiveness of SpectReand its potential to enhance the capabilities of graph models in relevantlearning tasks.</description>
      <author>example@mail.com (Mattie Ji, Amauri H. Souza, Vikas Garg)</author>
      <guid isPermaLink="false">2506.06571v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>FairPFN: A Tabular Foundation Model for Causal Fairness</title>
      <link>http://arxiv.org/abs/2506.07049v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FairPFN的表格基础模型，用于在机器学习系统中识别和减轻受保护属性对预测的因果影响，以提高因果公平性。&lt;h4&gt;背景&lt;/h4&gt;机器学习系统在医疗保健、执法和金融等关键领域得到应用，但这些系统往往基于包含人口统计偏差的历史数据，导致加剧社会不平等。&lt;h4&gt;目的&lt;/h4&gt;提出FairPFN模型，以解决因果公平性问题，减少算法歧视，并使因果公平性更易于应用于复杂场景。&lt;h4&gt;方法&lt;/h4&gt;FairPFN模型通过在合成因果公平数据上预训练，无需对因果模型有先验知识，便能识别和减轻受保护属性的因果影响。&lt;h4&gt;主要发现&lt;/h4&gt;FairPFN模型在多种定制和现实场景中，相对于稳健的基线方法，表现出强大的性能，且无需对因果模型有先验知识。&lt;h4&gt;结论&lt;/h4&gt;FairPFN模型为解决复杂公平性问题铺平了道路，使得因果公平性更容易被广泛应用。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为FairPFN的表格基础模型，用于在机器学习系统中识别和减轻受保护属性对预测的因果影响，以提高因果公平性。机器学习系统在医疗保健、执法和金融等关键领域得到应用，但这些系统往往基于包含人口统计偏差的历史数据，导致加剧社会不平等。提出FairPFN模型，以解决因果公平性问题，减少算法歧视，并使因果公平性更易于应用于复杂场景。FairPFN模型通过在合成因果公平数据上预训练，无需对因果模型有先验知识，便能识别和减轻受保护属性的因果影响。FairPFN模型在多种定制和现实场景中，相对于稳健的基线方法，表现出强大的性能，且无需对因果模型有先验知识。FairPFN模型为解决复杂公平性问题铺平了道路，使得因果公平性更容易被广泛应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning (ML) systems are utilized in critical sectors, such ashealthcare, law enforcement, and finance. However, these systems are oftentrained on historical data that contains demographic biases, leading to MLdecisions that perpetuate or exacerbate existing social inequalities. Causalfairness provides a transparent, human-in-the-loop framework to mitigatealgorithmic discrimination, aligning closely with legal doctrines of direct andindirect discrimination. However, current causal fairness frameworks hold a keylimitation in that they assume prior knowledge of the correct causal model,restricting their applicability in complex fairness scenarios where causalmodels are unknown or difficult to identify. To bridge this gap, we proposeFairPFN, a tabular foundation model pre-trained on synthetic causal fairnessdata to identify and mitigate the causal effects of protected attributes in itspredictions. FairPFN's key contribution is that it requires no knowledge of thecausal model and still demonstrates strong performance in identifying andremoving protected causal effects across a diverse set of hand-crafted andreal-world scenarios relative to robust baseline methods. FairPFN paves the wayfor promising future research, making causal fairness more accessible to awider variety of complex fairness problems.</description>
      <author>example@mail.com (Jake Robertson, Noah Hollmann, Samuel Müller, Noor Awad, Frank Hutter)</author>
      <guid isPermaLink="false">2506.07049v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>You Only Estimate Once: Unified, One-stage, Real-Time Category-level Articulated Object 6D Pose Estimation for Robotic Grasping</title>
      <link>http://arxiv.org/abs/2506.05719v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为YOEO的单阶段方法，用于解决机器人操作任务中关节物体类别级的姿态估计问题，该方法在GAPart数据集上展示了良好的姿态估计能力，并在实际场景中实现了200Hz的实时视觉反馈。&lt;h4&gt;背景&lt;/h4&gt;现有方法在估计类别级的部件姿态和大小时，通常采用复杂的多阶段流程，首先在点云中分割部件实例，然后估计标准化部件坐标空间（NPCS）表示的6D姿态，但这种方法计算成本高且在实时机器人任务中的性能较低。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述方法的局限性，提出YOEO方法，旨在通过单阶段流程同时输出实例分割和NPCS表示，以降低计算成本并提高实时性能。&lt;h4&gt;方法&lt;/h4&gt;YOEO方法使用统一的网络生成点级语义标签和质心偏移，使得来自同一部件实例的点对相同的质心进行投票。进一步，利用聚类算法根据估计的质心距离来区分点。然后，首先分离每个实例的NPCS区域，并将这些区域与真实点云对齐，以恢复最终的姿态和大小。&lt;h4&gt;主要发现&lt;/h4&gt;YOEO方法在GAPart数据集上展示了良好的姿态估计能力，并且在真实世界中部署了该模型，实现了200Hz的实时视觉反馈，使物理Kinova机器人能够与未见过的关节物体交互。&lt;h4&gt;结论&lt;/h4&gt;YOEO方法有效且实用，能够显著提高实时机器人任务中关节物体类别级姿态估计的性能。&lt;h4&gt;翻译&lt;/h4&gt;本文针对机器人操作任务中关节物体类别级姿态估计问题进行了研究。近年来，在估计类别级的部件姿态和大小时，已有工作取得了令人鼓舞的结果。然而，这些方法主要遵循一个复杂的多阶段流程，首先在点云中分割部件实例，然后估计标准化部件坐标空间（NPCS）表示的6D姿态。这些方法在实时机器人任务中存在计算成本高、性能低的问题。为了解决这些局限性，我们提出了YOEO方法，这是一种单阶段方法，能够端到端地同时输出实例分割和NPCS表示。我们使用一个统一的网络来生成点级语义标签和质心偏移，使得来自同一部件实例的点对相同的质心进行投票。我们进一步利用聚类算法根据估计的质心距离来区分点。然后，首先分离每个实例的NPCS区域，并将这些区域与真实点云对齐，以恢复最终的姿态和大小。在GAPart数据集上的实验结果证明了我们提出的单次拍摄方法在姿态估计方面的能力。我们还将在实际场景中部署我们通过合成训练得到的模型，实现200Hz的实时视觉反馈，使物理Kinova机器人能够与未见过的关节物体进行交互。这展示了我们提出的方法的实用性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the problem of category-level pose estimation forarticulated objects in robotic manipulation tasks. Recent works have shownpromising results in estimating part pose and size at the category level.However, these approaches primarily follow a complex multi-stage pipeline thatfirst segments part instances in the point cloud and then estimates theNormalized Part Coordinate Space (NPCS) representation for 6D poses. Theseapproaches suffer from high computational costs and low performance inreal-time robotic tasks. To address these limitations, we propose YOEO, asingle-stage method that simultaneously outputs instance segmentation and NPCSrepresentations in an end-to-end manner. We use a unified network to generatepoint-wise semantic labels and centroid offsets, allowing points from the samepart instance to vote for the same centroid. We further utilize a clusteringalgorithm to distinguish points based on their estimated centroid distances.Finally, we first separate the NPCS region of each instance. Then, we align theseparated regions with the real point cloud to recover the final pose and size.Experimental results on the GAPart dataset demonstrate the pose estimationcapabilities of our proposed single-shot method. We also deploy oursynthetically-trained model in a real-world setting, providing real-time visualfeedback at 200Hz, enabling a physical Kinova robot to interact with unseenarticulated objects. This showcases the utility and effectiveness of ourproposed method.</description>
      <author>example@mail.com (Jingshun Huang, Haitao Lin, Tianyu Wang, Yanwei Fu, Yu-Gang Jiang, Xiangyang Xue)</author>
      <guid isPermaLink="false">2506.05719v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Perspectives: A Survey on Cross-view Collaborative Intelligence with Egocentric-Exocentric Vision</title>
      <link>http://arxiv.org/abs/2506.06253v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了从外心（第三人称）和内心（第一人称）视角的视频理解研究，探讨了两种视角的协同潜力及其在动态环境中的互补理解能力。&lt;h4&gt;背景&lt;/h4&gt;从内外心视角感知世界是人类认知的基础，近年来，让机器利用这两种视角的协同潜力成为视频理解领域的一个引人注目的研究方向。&lt;h4&gt;目的&lt;/h4&gt;本文旨在全面回顾视频理解中的内外心视角，并探讨如何将这两种视角的技术整合，以及实现这些应用的关键研究任务。&lt;h4&gt;方法&lt;/h4&gt;文章系统地组织并回顾了近期的研究进展，分为三个主要研究方向：(1)利用内心数据增强外心理解，(2)利用外心数据改善内心分析，(3)联合学习框架，统一两种视角。并对每个方向的任务和相关工作进行详细分析。&lt;h4&gt;主要发现&lt;/h4&gt;文章讨论了支持内外心视角研究的基准数据集，评估了它们的范围、多样性和适用性，并指出了当前工作的局限性。&lt;h4&gt;结论&lt;/h4&gt;通过综合两种视角的见解，本文旨在激发视频理解和人工智能领域的进步，使机器更接近以人类方式感知世界。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从自我中心（第一人称）和外心（第三人称）的视角感知世界是人类认知的基础，这使人们能够对动态环境有丰富且互补的理解。近年来，让机器利用这两种视角的协同潜力已经成为视频理解领域的一个引人注目的研究方向。在本篇综述中，我们全面回顾了从外心和内心视角的视频理解。我们首先强调了整合内心和外心技术的实际应用，并展望了它们在不同领域中的潜在协作。然后，我们确定了实现这些应用的关键研究任务。接下来，我们系统地组织和回顾了最近的研究进展，主要分为三个研究方向：(1)利用内心数据来增强外心理解，(2)利用外心数据来改进内心分析，(3)联合学习框架，统一两种视角。对于每个方向，我们分析了多样化的任务和相关工作。此外，我们讨论了支持这两种视角研究的基准数据集，评估了它们的范围、多样性和适用性。最后，我们讨论了当前工作的局限性，并提出了有前景的未来研究方向。通过综合两种视角的见解，我们的目标是激发视频理解和人工智能领域的进步，使机器更接近以人类方式感知世界。相关作品的GitHub仓库可以在https://github.com/ayiyayi/Awesome-Egocentric-and-Exocentric-Vision找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Perceiving the world from both egocentric (first-person) and exocentric(third-person) perspectives is fundamental to human cognition, enabling richand complementary understanding of dynamic environments. In recent years,allowing the machines to leverage the synergistic potential of these dualperspectives has emerged as a compelling research direction in videounderstanding. In this survey, we provide a comprehensive review of videounderstanding from both exocentric and egocentric viewpoints. We begin byhighlighting the practical applications of integrating egocentric andexocentric techniques, envisioning their potential collaboration acrossdomains. We then identify key research tasks to realize these applications.Next, we systematically organize and review recent advancements into three mainresearch directions: (1) leveraging egocentric data to enhance exocentricunderstanding, (2) utilizing exocentric data to improve egocentric analysis,and (3) joint learning frameworks that unify both perspectives. For eachdirection, we analyze a diverse set of tasks and relevant works. Additionally,we discuss benchmark datasets that support research in both perspectives,evaluating their scope, diversity, and applicability. Finally, we discusslimitations in current works and propose promising future research directions.By synthesizing insights from both perspectives, our goal is to inspireadvancements in video understanding and artificial intelligence, bringingmachines closer to perceiving the world in a human-like manner. A GitHub repoof related works can be found athttps://github.com/ayiyayi/Awesome-Egocentric-and-Exocentric-Vision.</description>
      <author>example@mail.com (Yuping He, Yifei Huang, Guo Chen, Lidong Lu, Baoqi Pei, Jilan Xu, Tong Lu, Yoichi Sato)</author>
      <guid isPermaLink="false">2506.06253v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>HMVLM: Multistage Reasoning-Enhanced Vision-Language Model for Long-Tailed Driving Scenarios</title>
      <link>http://arxiv.org/abs/2506.05883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WOD Vision-based End-to-End Driving Challenge&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了HaoMo视觉-语言模型（HMVLM），这是一个端到端的驾驶框架，实现了认知启发式快速-慢速架构的慢速分支。&lt;h4&gt;背景&lt;/h4&gt;该模型通过快速控制器输出低级转向、油门和制动命令，同时慢速规划器——一个大型视觉-语言模型——生成高级意图，如“让行行人”或“在卡车后合并”，而不影响延迟。&lt;h4&gt;目的&lt;/h4&gt;HMVLM旨在提高自动驾驶系统的决策效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;HMVLM引入了三项升级：(1) 选择性五视图提示，包含4秒的自身运动学历史；(2) 多阶段思维链（CoT）提示，强制执行场景理解 -&gt; 驾驶决策 -&gt; 轨迹推理的推理流程；(3) 基于样条曲线的轨迹后处理，消除后期抖动和急转弯。&lt;h4&gt;主要发现&lt;/h4&gt;在Waymo开放数据集上训练的HMVLM实现了7.7367的评分，在2025年Waymo基于视觉的端到端（E2E）驾驶挑战中排名第二，比公共基线高出2.77。&lt;h4&gt;结论&lt;/h4&gt;这些升级使得HMVLM在自动驾驶领域取得了显著进展，提高了系统的性能和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present HaoMo Vision-Language Model (HMVLM), an end-to-end drivingframework that implements the slow branch of a cognitively inspired fast-slowarchitecture. A fast controller outputs low-level steering, throttle, and brakecommands, while a slow planner-a large vision-language model-generateshigh-level intents such as "yield to pedestrian" or "merge after the truck"without compromising latency. HMVLM introduces three upgrades: (1) selectivefive-view prompting with an embedded 4s history of ego kinematics, (2)multi-stage chain-of-thought (CoT) prompting that enforces a SceneUnderstanding -&gt; Driving Decision -&gt; Trajectory Inference reasoning flow, and(3) spline-based trajectory post-processing that removes late-stage jitter andsharp turns. Trained on the Waymo Open Dataset, these upgrades enable HMVLM toachieve a Rater Feedback Score (RFS) of 7.7367, securing 2nd place in the 2025Waymo Vision-based End-to-End (E2E) Driving Challenge and surpassing the publicbaseline by 2.77%.</description>
      <author>example@mail.com (Daming Wang, Yuhao Song, Zijian He, Kangliang Chen, Xing Pan, Lu Deng, Weihao Gu)</author>
      <guid isPermaLink="false">2506.05883v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>ICU-TSB: A Benchmark for Temporal Patient Representation Learning for Unsupervised Stratification into Patient Cohorts</title>
      <link>http://arxiv.org/abs/2506.06192v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages 1 table 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究介绍了ICU-TSB（时间分层基准），这是第一个用于评估基于时间患者表示学习的患者分层综合基准。该基准使用三个公开的ICU电子健康记录数据集进行实验，通过比较统计方法和几种循环神经网络（如LSTM和GRU）在生成有效患者表示方面的能力，验证了时间表示学习在重新发现具有临床意义的患者群体方面的潜力。&lt;h4&gt;背景&lt;/h4&gt;患者分层识别对于通过改进诊断和治疗策略推动个性化医学至关重要。ICU的电子健康记录（EHR）包含丰富的时序临床数据，可以用于此目的。&lt;h4&gt;目的&lt;/h4&gt;建立ICU-TSB基准，以评估基于时间患者表示学习的患者分层方法，并比较不同的统计方法和循环神经网络在生成有效患者表示方面的能力。&lt;h4&gt;方法&lt;/h4&gt;使用三个公开的ICU EHR数据集，通过时间表示学习进行患者分层，并引入一种新颖的分层评估框架，利用疾病分类学来衡量发现簇与临床验证的疾病分组之间的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;时间表示学习能够重新发现具有临床意义的患者群体，但这是一个具有挑战性的任务，其v度量从分类学的最高级别0.46下降到最低级别0.40。此外，还评估了为识别的簇分配可解释标签的多种策略。&lt;h4&gt;结论&lt;/h4&gt;ICU-TSB基准有助于评估基于时间患者表示学习的患者分层方法，实验和基准是完全可复制的，并可通过GitHub链接获取。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Identifying clinically meaningful subgroups by patient stratification is essential for advancing personalized medicine through improved diagnostics and treatment strategies. Electronic health records (EHRs), particularly those from intensive care units (ICUs), contain rich temporal clinical data that can be leveraged for this purpose. In this work, we introduce ICU-TSB (Temporal Stratification Benchmark), the first comprehensive benchmark for evaluating patient stratification based on temporal patient representation learning using three publicly available ICU EHR datasets. A key contribution of our benchmark is a novel hierarchical evaluation framework utilizing disease taxonomies to measure the alignment of discovered clusters with clinically validated disease groupings. In our experiments with ICU-TSB, we compared statistical methods and several recurrent neural networks, including LSTM and GRU, for their ability to generate effective patient representations for subsequent clustering of patient trajectories. Our results demonstrate that temporal representation learning can rediscover clinically meaningful patient cohorts; nevertheless, it remains a challenging task, with v-measuring varying from up to 0.46 at the top level of the taxonomy to up to 0.40 at the lowest level. To further enhance the practical utility of our findings, we also evaluate multiple strategies for assigning interpretable labels to the identified clusters. The experiments and benchmark are fully reproducible and available at https://github.com/ds4dh/CBMS2025stratification.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Patient stratification identifying clinically meaningful subgroups isessential for advancing personalized medicine through improved diagnostics andtreatment strategies. Electronic health records (EHRs), particularly those fromintensive care units (ICUs), contain rich temporal clinical data that can beleveraged for this purpose. In this work, we introduce ICU-TSB (TemporalStratification Benchmark), the first comprehensive benchmark for evaluatingpatient stratification based on temporal patient representation learning usingthree publicly available ICU EHR datasets. A key contribution of our benchmarkis a novel hierarchical evaluation framework utilizing disease taxonomies tomeasure the alignment of discovered clusters with clinically validated diseasegroupings. In our experiments with ICU-TSB, we compared statistical methods andseveral recurrent neural networks, including LSTM and GRU, for their ability togenerate effective patient representations for subsequent clustering of patienttrajectories. Our results demonstrate that temporal representation learning canrediscover clinically meaningful patient cohorts; nevertheless, it remains achallenging task, with v-measuring varying from up to 0.46 at the top level ofthe taxonomy to up to 0.40 at the lowest level. To further enhance thepractical utility of our findings, we also evaluate multiple strategies forassigning interpretable labels to the identified clusters. The experiments andbenchmark are fully reproducible and available athttps://github.com/ds4dh/CBMS2025stratification.</description>
      <author>example@mail.com (Dimitrios Proios, Alban Bornet, Anthony Yazdani, Jose F Rodrigues Jr, Douglas Teodoro)</author>
      <guid isPermaLink="false">2506.06192v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Pts3D-LLM: Studying the Impact of Token Structure for 3D Scene Understanding With Large Language Models</title>
      <link>http://arxiv.org/abs/2506.05689v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Main paper and appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了有效表示3D场景的多模态大型语言模型（MLLMs）的重要性与挑战，提出了一种新的方法，通过融合3D点云特征来丰富视觉标记，并在多个3D理解基准测试中实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;当前的方法通常只依赖于2D图像特征和不同的标记化方法。&lt;h4&gt;目的&lt;/h4&gt;为了有效表示3D场景，并提高MLLMs的性能。&lt;h4&gt;方法&lt;/h4&gt;进行了严格的3D标记结构研究，系统性地比较了基于视频和基于点的表示，同时保持了模型骨干和参数的一致性。提出了一个新方法，通过结合来自预训练的Sonata PointTransformer V3编码器的3D点云特征来丰富视觉标记。&lt;h4&gt;主要发现&lt;/h4&gt;将显式的3D特征合并显著提升了性能；基于点的标记结构在点被巧妙采样和排序时可以与基于视频的标记结构相媲美。&lt;h4&gt;结论&lt;/h4&gt;强调了标记结构分析作为一项重要贡献，并强调了在多个种子上平均报告结果的重要性，认为这对于领域中的稳健进步至关重要。&lt;h4&gt;翻译&lt;/h4&gt;有效地表示3D场景对于多模态大型语言模型（MLLMs）至关重要，但也是一个挑战。现有的方法通常仅依赖于2D图像特征和不同的标记化方法。本文对3D标记结构进行了严格的研究，系统地比较了基于视频和基于点的表示，同时保持了一致的模式骨干和参数。我们提出了一种新方法，通过结合来自预训练的Sonata PointTransformer V3编码器的3D点云特征来丰富视觉标记。我们的实验表明，合并显式的3D特征可以显著提高性能。此外，我们还表明，当点被巧妙采样和排序时，基于点的标记结构可以与基于视频的标记结构相媲美。我们从这两种结构中得出的最佳模型在多个3D理解基准测试中实现了最先进的结果。我们强调了标记结构分析作为一项关键贡献，以及跨多个种子平均报告结果的做法，我们认为这对于领域的稳健进步至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effectively representing 3D scenes for Multimodal Large Language Models(MLLMs) is crucial yet challenging. Existing approaches commonly only rely on2D image features and use varied tokenization approaches. This work presents arigorous study of 3D token structures, systematically comparing video-based andpoint-based representations while maintaining consistent model backbones andparameters. We propose a novel approach that enriches visual tokens byincorporating 3D point cloud features from a Sonata pretrained PointTransformer V3 encoder. Our experiments demonstrate that merging explicit 3Dfeatures significantly boosts performance. Furthermore, we show thatpoint-based token structures can rival video-based ones when the points arecleverly sampled and ordered. Our best models from both structures achievestate-of-the-art results on multiple 3D understanding benchmarks. We emphasizeour analysis of token structures as a key contribution, alongside transparentreporting of results averaged over multiple seeds, a practice we believe isvital for robust progress in the field.</description>
      <author>example@mail.com (Hugues Thomas, Chen Chen, Jian Zhang)</author>
      <guid isPermaLink="false">2506.05689v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Rapid training of Hamiltonian graph networks without gradient descent</title>
      <link>http://arxiv.org/abs/2506.06558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 7 figures, 2 tables, and an appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在数据驱动建模中学习遵守物理对称性和约束的动态系统，提出了一种新的方法，通过将物理定律与图神经网络结合，提高了复杂N体动力学模型的建模精度和置换不变性。&lt;h4&gt;背景&lt;/h4&gt;学习遵守物理对称性和约束的动态系统是数据驱动建模中的一个基本挑战。&lt;h4&gt;目的&lt;/h4&gt;提高复杂N体动力学模型的建模精度和置换不变性。&lt;h4&gt;方法&lt;/h4&gt;将物理定律与图神经网络结合，使用Hamiltonian Graph Networks (HGN)进行训练，并通过随机特征参数构造来替代迭代优化算法。&lt;h4&gt;主要发现&lt;/h4&gt;HGN的训练速度比其他15种优化器快600倍，同时保持了可比的精度。模型在多种模拟中表现出鲁棒性能，包括不同几何形状的3维N体质量-弹簧系统，并保留了关于置换、旋转和平移的基本物理不变性。模型即使在训练时只使用8节点系统，也能在零样本方式下泛化到4096节点的系统。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法挑战了迭代梯度下降优化算法在训练物理系统神经网络模型中的主导地位。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在数据驱动建模中学习尊重物理对称性和约束的动态系统仍然是一个基本挑战。将物理定律与图神经网络结合有助于原理性地建模复杂的N体动力学，并产生准确和置换不变的模型。然而，使用迭代、基于梯度的优化算法（例如Adam、RMSProp、LBFGS）来训练图神经网络往往会导致训练缓慢，特别是在大型、复杂的系统中。与15种不同的优化器相比，我们证明Hamiltonian Graph Networks (HGN)可以通过用基于随机特征的参数构造来替代迭代优化，以600倍的速度进行训练，但精度相当。我们在各种模拟中展示了鲁棒的性能，包括最多3维不同几何形状的N体质量-弹簧系统，同时保持了关于置换、旋转和转换的基本物理不变性。我们发现，即使在训练时只使用8节点系统，该模型也能以零样本方式泛化到多达4096节点的系统，而无需重新训练。我们的工作挑战了迭代梯度下降优化算法在训练物理系统神经网络模型中的主导地位。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning dynamical systems that respect physical symmetries and constraintsremains a fundamental challenge in data-driven modeling. Integrating physicallaws with graph neural networks facilitates principled modeling of complexN-body dynamics and yields accurate and permutation-invariant models. However,training graph neural networks with iterative, gradient-based optimizationalgorithms (e.g., Adam, RMSProp, LBFGS) often leads to slow training,especially for large, complex systems. In comparison to 15 differentoptimizers, we demonstrate that Hamiltonian Graph Networks (HGN) can be trainedup to 600x faster--but with comparable accuracy--by replacing iterativeoptimization with random feature-based parameter construction. We show robustperformance in diverse simulations, including N-body mass-spring systems in upto 3 dimensions with different geometries, while retaining essential physicalinvariances with respect to permutation, rotation, and translation. We revealthat even when trained on minimal 8-node systems, the model can generalize in azero-shot manner to systems as large as 4096 nodes without retraining. Our workchallenges the dominance of iterative gradient-descent-based optimizationalgorithms for training neural network models for physical systems.</description>
      <author>example@mail.com (Atamert Rahma, Chinmay Datar, Ana Cukarska, Felix Dietrich)</author>
      <guid isPermaLink="false">2506.06558v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>WhisQ: Cross-Modal Representation Learning for Text-to-Music MOS Prediction</title>
      <link>http://arxiv.org/abs/2506.05899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  3 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为WhisQ的多模态架构，用于评估文本到音乐系统的MOS预测，通过序列级别的共注意力和最优传输正则化来解决双重评估挑战。&lt;h4&gt;背景&lt;/h4&gt;MOS预测需要对整体音乐质量和文本提示对齐进行评估。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效评估文本到音乐系统MOS的模型。&lt;h4&gt;方法&lt;/h4&gt;WhisQ使用Whisper Base模型进行时间音频编码，Qwen 3模型进行文本编码，并通过序列结构保持精细的跨模态建模。该架构具有专门的预测路径，包括从音频嵌入中预测OMQ和利用音频与文本之间的双向序列共注意力的TA。此外，Sinkhorn最优传输损失进一步强化了共享嵌入空间中的语义对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在MusicEval Track-1数据集上，WhisQ在OMQ和TA方面都显著优于基线，分别提高了7%和14%的Spearman相关性。消融研究显示，最优传输正则化提供了最大的性能提升（10%的SRCC改进），证明了显式跨模态对齐对文本到音乐评估的重要性。&lt;h4&gt;结论&lt;/h4&gt;WhisQ通过优化传输正则化和跨模态对齐，提高了文本到音乐系统MOS预测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mean Opinion Score (MOS) prediction for text to music systems requiresevaluating both overall musical quality and text prompt alignment. This paperintroduces WhisQ, a multimodal architecture that addresses this dual-assessmentchallenge through sequence level co-attention and optimal transportregularization. WhisQ employs the Whisper Base pretrained model for temporalaudio encoding and Qwen 3, a 0.6B Small Language Model (SLM), for textencoding, with both maintaining sequence structure for fine grained cross-modalmodeling. The architecture features specialized prediction pathways: OMQ ispredicted from pooled audio embeddings, while TA leverages bidirectionalsequence co-attention between audio and text. Sinkhorn optimal transport lossfurther enforce semantic alignment in the shared embedding space. On theMusicEval Track-1 dataset, WhisQ achieves substantial improvements over thebaseline: 7% improvement in Spearman correlation for OMQ and 14% for TA.Ablation studies reveal that optimal transport regularization provides thelargest performance gain (10% SRCC improvement), demonstrating the importanceof explicit cross-modal alignment for text-to-music evaluation.</description>
      <author>example@mail.com (Jakaria Islam Emon, Kazi Tamanna Alam, Md. Abu Salek)</author>
      <guid isPermaLink="false">2506.05899v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Hallucinate, Ground, Repeat: A Framework for Generalized Visual Relationship Detection</title>
      <link>http://arxiv.org/abs/2506.05651v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 9 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种迭代视觉 grounding 框架，利用大型语言模型（LLMs）作为结构化关系先验，以解决视觉关系检测（VRD）模型在处理未知关系时的泛化问题。&lt;h4&gt;背景&lt;/h4&gt;视觉关系检测在视觉智能、具身 AI、辅助系统和场景理解等领域有广泛应用，但大多数 VRD 模型依赖于固定的谓词集，限制了它们对新交互的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;解决从外部知识中假设的语义上合理但未注释的关系无法视觉化的关键挑战，并实现超越标注数据的关联理解。&lt;h4&gt;方法&lt;/h4&gt;方法交替使用 LLM 从检测到的对象生成候选场景图（期望阶段）和训练视觉模型以将假设与感知证据对齐（最大化阶段）。&lt;h4&gt;主要发现&lt;/h4&gt;模型在三个设置（seen, unseen, mixed）下的谓词分类中分别达到了 15.9, 13.1 和 11.7 的平均召回率（mR@50），优于 LLM-only、few-shot 和 debiased 基准。&lt;h4&gt;结论&lt;/h4&gt;基于 grounded LLM 先验的视觉理解具有可扩展的开放世界视觉理解的前景。&lt;h4&gt;翻译&lt;/h4&gt;Understanding relationships between objects is central to visual intelligence, with applications in embodied AI, assistive systems, and scene understanding. Yet, most visual relationship detection (VRD) models rely on a fixed predicate set, limiting their generalization to novel interactions. A key challenge is the inability to visually ground semantically plausible, but unannotated, relationships hypothesized from external knowledge. This work introduces an iterative visual grounding framework that leverages large language models (LLMs) as structured relational priors. Inspired by expectation-maximization (EM), our method alternates between generating candidate scene graphs from detected objects using an LLM (expectation) and training a visual model to align these hypotheses with perceptual evidence (maximization). This process bootstraps relational understanding beyond annotated data and enables generalization to unseen predicates. Additionally, we introduce a new benchmark for open-world VRD on Visual Genome with 21 held-out predicates and evaluate under three settings: seen, unseen, and mixed. Our model outperforms LLM-only, few-shot, and debiased baselines, achieving mean recall (mR@50) of 15.9, 13.1, and 11.7 on predicate classification on these three sets. These results highlight the promise of grounded LLM priors for scalable open-world visual understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding relationships between objects is central to visualintelligence, with applications in embodied AI, assistive systems, and sceneunderstanding. Yet, most visual relationship detection (VRD) models rely on afixed predicate set, limiting their generalization to novel interactions. A keychallenge is the inability to visually ground semantically plausible, butunannotated, relationships hypothesized from external knowledge. This workintroduces an iterative visual grounding framework that leverages largelanguage models (LLMs) as structured relational priors. Inspired byexpectation-maximization (EM), our method alternates between generatingcandidate scene graphs from detected objects using an LLM (expectation) andtraining a visual model to align these hypotheses with perceptual evidence(maximization). This process bootstraps relational understanding beyondannotated data and enables generalization to unseen predicates. Additionally,we introduce a new benchmark for open-world VRD on Visual Genome with 21held-out predicates and evaluate under three settings: seen, unseen, and mixed.Our model outperforms LLM-only, few-shot, and debiased baselines, achievingmean recall (mR@50) of 15.9, 13.1, and 11.7 on predicate classification onthese three sets. These results highlight the promise of grounded LLM priorsfor scalable open-world visual understanding.</description>
      <author>example@mail.com (Shanmukha Vellamcheti, Sanjoy Kundu, Sathyanarayanan N. Aakur)</author>
      <guid isPermaLink="false">2506.05651v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Learning Along the Arrow of Time: Hyperbolic Geometry for Backward-Compatible Representation Learning</title>
      <link>http://arxiv.org/abs/2506.05826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于双曲几何的向后兼容表示学习方法，通过考虑旧嵌入模型的不确定性，使更新模型能够无缝集成现有模型，避免重新处理存储数据。&lt;h4&gt;背景&lt;/h4&gt;现有的欧几里得空间兼容方法忽略了旧嵌入模型的不确定性，并强制新模型重构过时的表示，无论其质量如何，从而阻碍了新模型的学习过程。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过将嵌入提升到双曲空间，并限制更新嵌入位于旧嵌入的蕴涵锥内，以保持模型之间的代际一致性，同时考虑到表示中的不确定性。&lt;h4&gt;方法&lt;/h4&gt;使用双曲几何来处理时间，将时间视为捕捉模型置信度和演化的自然轴。引入了一种鲁棒的对比对齐损失，根据旧嵌入的不确定性动态调整对齐权重。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了所提出方法在实现兼容性方面的优越性，为构建更具弹性和适应性的机器学习系统铺平了道路。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地解决现有兼容性问题，为机器学习系统的进一步发展提供了新的思路和解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Backward compatible representation learning enables updated models tointegrate seamlessly with existing ones, avoiding to reprocess stored data.Despite recent advances, existing compatibility approaches in Euclidean spaceneglect the uncertainty in the old embedding model and force the new model toreconstruct outdated representations regardless of their quality, therebyhindering the learning process of the new model. In this paper, we propose toswitch perspectives to hyperbolic geometry, where we treat time as a naturalaxis for capturing a model's confidence and evolution. By lifting embeddingsinto hyperbolic space and constraining updated embeddings to lie within theentailment cone of the old ones, we maintain generational consistency acrossmodels while accounting for uncertainties in the representations. To furtherenhance compatibility, we introduce a robust contrastive alignment loss thatdynamically adjusts alignment weights based on the uncertainty of the oldembeddings. Experiments validate the superiority of the proposed method inachieving compatibility, paving the way for more resilient and adaptablemachine learning systems.</description>
      <author>example@mail.com (Ngoc Bui, Menglin Yang, Runjin Chen, Leonardo Neves, Mingxuan Ju, Rex Ying, Neil Shah, Tong Zhao)</author>
      <guid isPermaLink="false">2506.05826v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning</title>
      <link>http://arxiv.org/abs/2506.07044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report, 53 pages, 25 tables, and 16 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Lingshu的医学专用多模态大型语言模型，旨在解决现有医学MLLMs在医学应用中的局限性，并介绍了数据收集、模型训练和评估方法。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型在理解常见视觉元素方面表现出色，但在医学应用中效果有限，因为医学场景的数据和任务与通用领域存在本质差异。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来解决现有医学MLLMs的局限性，包括扩展医学知识覆盖范围、减少幻觉风险和提高推理能力。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种全面的数据收集和整理流程，从医学影像、医学文本和通用领域数据中获取丰富的医学知识数据；2. 合成了准确的医学字幕、视觉问答和推理样本；3. 引入了多阶段训练来嵌入医学专业知识并逐步提高任务解决能力；4. 探索了使用可验证奖励范式结合强化学习来增强医学推理能力；5. 开发了MedEvalKit，一个统一的评估框架，用于标准化、公平和高效地评估模型。&lt;h4&gt;主要发现&lt;/h4&gt;Lingshu在多项基本医学任务中（多模态问答、基于文本的问答和医学报告生成）的表现优于现有开源的多模态模型。&lt;h4&gt;结论&lt;/h4&gt;Lingshu是一个有效的医学专用多模态大型语言模型，能够提高医学应用中的任务解决能力，并为医学MLLMs的发展提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities in understanding common visual elements, largely due to their large-scale datasets and advanced training strategies. However, their effectiveness in medical applications remains limited due to the inherent discrepancies between data and tasks in medical scenarios and those in the general domain. Concretely, existing medical MLLMs face the following critical limitations: (1) limited coverage of medical knowledge beyond imaging, (2) heightened susceptibility to hallucinations due to suboptimal data curation processes, (3) lack of reasoning capabilities tailored for complex medical scenarios. To address these challenges, we first propose a comprehensive data curation procedure that (1) efficiently acquires rich medical knowledge data not only from medical imaging but also from extensive medical texts and general-domain data; and (2) synthesizes accurate medical captions, visual question answering (VQA), and reasoning samples. As a result, we build a multimodal dataset enriched with extensive medical knowledge. Building on the curated data, we introduce our medical-specialized MLLM: Lingshu. Lingshu undergoes multi-stage training to embed medical expertise and enhance its task-solving capabilities progressively. Besides, we preliminarily explore the potential of applying reinforcement learning with verifiable rewards paradigm to enhance Lingshu's medical reasoning ability. Additionally, we develop MedEvalKit, a unified evaluation framework that consolidates leading multimodal and textual medical benchmarks for standardized, fair, and efficient model assessment. We evaluate the performance of Lingshu on three fundamental medical tasks, multimodal QA, text-based QA, and medical report generation. The results show that Lingshu consistently outperforms the existing open-source multimodal models on most tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have demonstrated impressivecapabilities in understanding common visual elements, largely due to theirlarge-scale datasets and advanced training strategies. However, theireffectiveness in medical applications remains limited due to the inherentdiscrepancies between data and tasks in medical scenarios and those in thegeneral domain. Concretely, existing medical MLLMs face the following criticallimitations: (1) limited coverage of medical knowledge beyond imaging, (2)heightened susceptibility to hallucinations due to suboptimal data curationprocesses, (3) lack of reasoning capabilities tailored for complex medicalscenarios. To address these challenges, we first propose a comprehensive datacuration procedure that (1) efficiently acquires rich medical knowledge datanot only from medical imaging but also from extensive medical texts andgeneral-domain data; and (2) synthesizes accurate medical captions, visualquestion answering (VQA), and reasoning samples. As a result, we build amultimodal dataset enriched with extensive medical knowledge. Building on thecurated data, we introduce our medical-specialized MLLM: Lingshu. Lingshuundergoes multi-stage training to embed medical expertise and enhance itstask-solving capabilities progressively. Besides, we preliminarily explore thepotential of applying reinforcement learning with verifiable rewards paradigmto enhance Lingshu's medical reasoning ability. Additionally, we developMedEvalKit, a unified evaluation framework that consolidates leading multimodaland textual medical benchmarks for standardized, fair, and efficient modelassessment. We evaluate the performance of Lingshu on three fundamental medicaltasks, multimodal QA, text-based QA, and medical report generation. The resultsshow that Lingshu consistently outperforms the existing open-source multimodalmodels on most tasks ...</description>
      <author>example@mail.com (LASA Team, Weiwen Xu, Hou Pong Chan, Long Li, Mahani Aljunied, Ruifeng Yuan, Jianyu Wang, Chenghao Xiao, Guizhen Chen, Chaoqun Liu, Zhaodonghui Li, Yu Sun, Junao Shen, Chaojun Wang, Jie Tan, Deli Zhao, Tingyang Xu, Hao Zhang, Yu Rong)</author>
      <guid isPermaLink="false">2506.07044v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Beamforming and Resource Allocation for Delay Optimization in RIS-Assisted OFDM Systems</title>
      <link>http://arxiv.org/abs/2506.03586v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在下行可重构智能表面（RIS）辅助的正交频分复用（OFDM）系统中，联合相位设计和资源分配问题，以优化平均延迟。&lt;h4&gt;背景&lt;/h4&gt;数据包对每个用户的到达是随机的，使得问题本质上成为一个马尔可夫决策过程（MDP），属于强化学习的范畴。&lt;h4&gt;目的&lt;/h4&gt;提出一种混合深度强化学习（DRL）方法，以有效处理混合动作空间并降低状态空间维度。&lt;h4&gt;方法&lt;/h4&gt;使用近端策略优化（PPO）-Θ来优化RIS相移设计，而PPO-N负责子载波分配决策。引入多代理策略以更有效地优化子载波分配指标。将与平均延迟密切相关的关键因素，如缓冲区中积压的数据包数量和当前数据包到达量，纳入状态空间。此外，引入迁移学习框架以提高训练效率和加速收敛。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，所提出的算法显著降低了平均延迟，提高了资源分配效率，与基线方法相比，实现了更优的系统鲁棒性和公平性。&lt;h4&gt;结论&lt;/h4&gt;所提出的算法在优化平均延迟和资源分配效率方面表现出色，同时提高了系统的鲁棒性和公平性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates a joint phase design and resource allocation problemin downlink reconfigurable intelligent surface (RIS)-assisted orthogonalfrequency division multiplexing (OFDM) systems to optimize average delay, wheredata packets for each user arrive at the base station stochastically. Thesequential optimization problem is inherently a Markov decision process (MDP),making it fall within the scope of reinforcement learning. To effectivelyhandle the mixed action space and reduce the state space dimensionality, ahybrid deep reinforcement learning (DRL) approach is proposed. Specifically,proximal policy optimization (PPO)-$\Theta$ is employed to optimize RIS phaseshift design, while PPO-N is responsible for subcarrier allocation decisions.To further mitigate the curse of dimensionality associated with subcarrierallocation, a multi-agent strategy is introduced to optimize subcarrierallocation indicater more efficiently. Moreover, to achieve more adaptiveresource allocation and accurately capture network dynamics, key factorsclosely related to average delay, including the number of backlogged packets inbuffers and the current packet arrivals, are incorporated into the state space.Furthermore, a transfer learning framework is introduced to enhance trainingefficiency and accelerate convergence. Simulation results demonstrate that theproposed algorithm significantly reduces average delay, enhances resourceallocation efficiency, and achieves superior system robustness and fairnesscompared to baseline methods.</description>
      <author>example@mail.com (Yu Ma, Xiao Li, Chongtao Guo, Le Liang, Shi Jin)</author>
      <guid isPermaLink="false">2506.03586v2</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Positional Encoding meets Persistent Homology on Graphs</title>
      <link>http://arxiv.org/abs/2506.05814v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了消息传递图神经网络（GNNs）的局部归纳偏差问题，提出了一种新的可学习方法PiPE（持久性信息位置编码），以解决GNNs在利用关键结构信息方面的不足。&lt;h4&gt;背景&lt;/h4&gt;GNNs的局部归纳偏差阻碍了它们利用诸如连接性和循环等关键结构信息的能力。&lt;h4&gt;目的&lt;/h4&gt;提出新的方法以缓解GNNs的局部归纳偏差问题，并提高其表达能力。&lt;h4&gt;方法&lt;/h4&gt;引入了位置编码（PE）和持久同调（PH）方法，并提出了PiPE方法。&lt;h4&gt;主要发现&lt;/h4&gt;证明了PE和PH方法各有优劣，且无一种方法在所有情况下都优于另一种。PiPE在多种任务（如分子属性预测、图分类和泛化到分布外的情况）中表现良好。&lt;h4&gt;结论&lt;/h4&gt;PiPE是一种比PH和PE都更具表达力的新方法，可以提升图表示学习的前沿水平。&lt;h4&gt;翻译&lt;/h4&gt;摘要：局部归纳偏差阻碍了消息传递图神经网络（GNNs）利用关键结构信息（例如，连接性和循环）的能力。位置编码（PE）和持久同调（PH）是缓解此问题的两种有前途的方法。PE方案赋予GNNs位置感知特征，而PH方法增强了GNNs的多分辨率拓扑特征。然而，PE和PH的相对优缺点缺乏严格的理论描述。我们通过证明两种范式都不比对方更具有表现力，并提供了在一个方法失败而另一个方法成功的新构造，来弥合这一差距。我们的见解为设计了一种新的可学习方法PiPE（持久性信息位置编码）提供了信息，该方法证明比PH和PE都更有表现力。PiPE在各种任务（例如，分子属性预测、图分类和分布外泛化）中表现出强大的性能，从而推动了图表示学习的前沿。代码可在https://github.com/Aalto-QuML/PIPE上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The local inductive bias of message-passing graph neural networks (GNNs)hampers their ability to exploit key structural information (e.g., connectivityand cycles). Positional encoding (PE) and Persistent Homology (PH) have emergedas two promising approaches to mitigate this issue. PE schemes endow GNNs withlocation-aware features, while PH methods enhance GNNs with multiresolutiontopological features. However, a rigorous theoretical characterization of therelative merits and shortcomings of PE and PH has remained elusive. We bridgethis gap by establishing that neither paradigm is more expressive than theother, providing novel constructions where one approach fails but the othersucceeds. Our insights inform the design of a novel learnable method, PiPE(Persistence-informed Positional Encoding), which is provably more expressivethan both PH and PE. PiPE demonstrates strong performance across a variety oftasks (e.g., molecule property prediction, graph classification, andout-of-distribution generalization), thereby advancing the frontiers of graphrepresentation learning. Code is available athttps://github.com/Aalto-QuML/PIPE.</description>
      <author>example@mail.com (Yogesh Verma, Amauri H. Souza, Vikas Garg)</author>
      <guid isPermaLink="false">2506.05814v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Does Your 3D Encoder Really Work? When Pretrain-SFT from 2D VLMs Meets 3D VLMs</title>
      <link>http://arxiv.org/abs/2506.05318v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了二维视觉语言模型（VLMs）在三维场景中的应用，分析了不同模型架构的优缺点，并提出了一种新的数据集以促进三维场景理解。&lt;h4&gt;背景&lt;/h4&gt;随着二维视觉语言模型（VLMs）在二维视觉任务上的显著进步，研究者们开始探索将这些模型扩展到三维场景中，用于三维问答、密集描述和视觉定位等任务。&lt;h4&gt;目的&lt;/h4&gt;研究三维视觉语言模型（3D VLMs）在三维场景中的表现，并寻找提高三维理解的方法。&lt;h4&gt;方法&lt;/h4&gt;将最近的3D VLMs分为三类：以3D对象为中心、基于2D图像和以3D场景为中心的方法。通过深入分析，研究了3D场景中心VLMs的性能差异和原因。&lt;h4&gt;主要发现&lt;/h4&gt;3D场景中心VLMs在性能上低于最新的3D对象中心和基于2D图像的方法，原因在于它们对3D场景编码器的依赖有限，且预训练阶段的效果不如二维VLMs。数据扩展对大型数据集的益处不明显。模型倾向于过度依赖语言线索并过度拟合常见答案分布，从而减少了3D编码器的有效利用。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的3D相关性判别问答数据集，旨在打破捷径学习并提高三维理解。强调了在3D VLMs中需要更先进的评估和改进策略以实现更好的三维理解。&lt;h4&gt;翻译&lt;/h4&gt;With remarkable progress in 2D Vision-Language Models (VLMs) spurring interest in extending them to 3D settings for tasks like 3D Question Answering, DenseCaptioning, and Visual Grounding, this paper discusses the application of 3D VLMs in 3D scenes, analyzes the advantages and disadvantages of different model architectures, and proposes a new dataset to promote 3D scene understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Remarkable progress in 2D Vision-Language Models (VLMs) has spurred interestin extending them to 3D settings for tasks like 3D Question Answering, DenseCaptioning, and Visual Grounding. Unlike 2D VLMs that typically process imagesthrough an image encoder, 3D scenes, with their intricate spatial structures,allow for diverse model architectures. Based on their encoder design, thispaper categorizes recent 3D VLMs into 3D object-centric, 2D image-based, and 3Dscene-centric approaches. Despite the architectural similarity of 3Dscene-centric VLMs to their 2D counterparts, they have exhibited comparativelylower performance compared with the latest 3D object-centric and 2D image-basedapproaches. To understand this gap, we conduct an in-depth analysis, revealingthat 3D scene-centric VLMs show limited reliance on the 3D scene encoder, andthe pre-train stage appears less effective than in 2D VLMs. Furthermore, weobserve that data scaling benefits are less pronounced on larger datasets. Ourinvestigation suggests that while these models possess cross-modal alignmentcapabilities, they tend to over-rely on linguistic cues and overfit to frequentanswer distributions, thereby diminishing the effective utilization of the 3Dencoder. To address these limitations and encourage genuine 3D sceneunderstanding, we introduce a novel 3D Relevance Discrimination QA datasetdesigned to disrupt shortcut learning and improve 3D understanding. Ourfindings highlight the need for advanced evaluation and improved strategies forbetter 3D understanding in 3D VLMs.</description>
      <author>example@mail.com (Haoyuan Li, Yanpeng Zhou, Yufei Gao, Tao Tang, Jianhua Han, Yujie Yuan, Dave Zhenyu Chen, Jiawang Bian, Hang Xu, Xiaodan Liang)</author>
      <guid isPermaLink="false">2506.05318v2</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>LaTtE-Flow: Layerwise Timestep-Expert Flow-based Transformer</title>
      <link>http://arxiv.org/abs/2506.06952v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Unified multimodal model, Flow-matching&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;LaTtE-Flow是一种新型且高效的架构，它统一了图像理解和生成，并提高了性能和生成速度。&lt;h4&gt;背景&lt;/h4&gt;现有统一的多模态模型需要大量预训练，且图像生成速度慢，限制了在实际应用中的部署。&lt;h4&gt;目的&lt;/h4&gt;提出LaTtE-Flow，以实现高效且性能优越的图像理解和生成。&lt;h4&gt;方法&lt;/h4&gt;LaTtE-Flow基于预训练的视觉-语言模型（VLMs），并结合了基于层和时步专家流的新架构。它通过在每个采样时步仅激活一小部分Transformer层来提高采样效率，并采用时步条件残差注意力机制以实现层间高效的信息重用。&lt;h4&gt;主要发现&lt;/h4&gt;LaTtE-Flow在多模态理解任务上取得了良好的性能，同时与最新的统一多模态模型相比，其推理速度提高了约6倍。&lt;h4&gt;结论&lt;/h4&gt;LaTtE-Flow在保持较高图像生成质量的同时，显著提高了性能和生成速度，为多模态任务提供了有效解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in multimodal foundation models unifying image understandingand generation have opened exciting avenues for tackling a wide range ofvision-language tasks within a single framework. Despite progress, existingunified models typically require extensive pretraining and struggle to achievethe same level of performance compared to models dedicated to each task.Additionally, many of these models suffer from slow image generation speeds,limiting their practical deployment in real-time or resource-constrainedsettings. In this work, we propose Layerwise Timestep-Expert Flow-basedTransformer (LaTtE-Flow), a novel and efficient architecture that unifies imageunderstanding and generation within a single multimodal model. LaTtE-Flowbuilds upon powerful pretrained Vision-Language Models (VLMs) to inherit strongmultimodal understanding capabilities, and extends them with a novel LayerwiseTimestep Experts flow-based architecture for efficient image generation.LaTtE-Flow distributes the flow-matching process across specialized groups ofTransformer layers, each responsible for a distinct subset of timesteps. Thisdesign significantly improves sampling efficiency by activating only a smallsubset of layers at each sampling timestep. To further enhance performance, wepropose a Timestep-Conditioned Residual Attention mechanism for efficientinformation reuse across layers. Experiments demonstrate that LaTtE-Flowachieves strong performance on multimodal understanding tasks, while achievingcompetitive image generation quality with around 6x faster inference speedcompared to recent unified multimodal models.</description>
      <author>example@mail.com (Ying Shen, Zhiyang Xu, Jiuhai Chen, Shizhe Diao, Jiaxin Zhang, Yuguang Yao, Joy Rimchala, Ismini Lourentzou, Lifu Huang)</author>
      <guid isPermaLink="false">2506.06952v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>VideoChat-A1: Thinking with Long Videos by Chain-of-Shot Reasoning</title>
      <link>http://arxiv.org/abs/2506.06097v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了视频理解领域的一项新进展，即VideoChat-A1，这是一种新型长视频智能体范式，能够有效地理解长视频内容。&lt;h4&gt;背景&lt;/h4&gt;当前的多模态大型语言模型（MLLMs）在分析短视频方面表现良好，但在理解具有较长上下文的长视频方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;为了解决长视频理解中的困难，论文提出了VideoChat-A1，旨在提高对长视频内容的理解能力。&lt;h4&gt;方法&lt;/h4&gt;VideoChat-A1采用了一种独特的镜头链推理范式，能够逐步选择与用户问题相关的镜头，并从粗到细地分析这些镜头。通过沿着镜头链进行多模态推理，VideoChat-A1可以模拟人类的思考过程，以发现对长视频内容进行深思熟虑理解的有利时间上下文。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，VideoChat-A1在主流长视频问答基准测试中取得了最先进的性能，例如在VideoMME上达到77.0，在EgoSchema上达到70.1，分别比其强基线（如Intern2.5VL-8B和InternVideo2.5-8B）提高了10.8%和6.2%。与GPT-4o和Gemini 1.5 Pro等领先的开源模型相比，VideoChat-A1在准确性方面具有竞争力，但输入帧数减少了7%，推理时间减少了12%。&lt;h4&gt;结论&lt;/h4&gt;VideoChat-A1通过创新的镜头链推理范式，有效地提高了长视频的理解能力，为长视频内容分析提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;最近，视频理解领域的进步是由多模态大型语言模型（MLLMs）驱动的。但是，这些MLLMs擅长分析短视频，而在理解具有较长上下文的长视频方面存在困难。为了解决这一困难，最近提出了几种智能体范式，使用MLLMs作为智能体以检索长视频中的额外上下文知识。然而，大多数现有的智能体忽略了这样一个关键事实，即长视频由多个镜头组成，即要回答来自长视频的用户问题，深入了解其相关镜头对人类来说是至关重要的。没有这样的见解，这些智能体往往会错误地发现冗余甚至噪声的时间上下文，限制了它们在长视频理解方面的能力。为了填补这一空白，我们提出了VideoChat-A1，这是一种新颖的长视频智能体范式。与先前的工作不同，我们的VideoChat-A1可以通过独特的镜头链推理范式深入思考长视频。更具体地说，它可以逐步选择用户问题的相关镜头，并从粗到细地查看这些镜头。通过沿着镜头链进行多模态推理，VideoChat-A1可以有效地模拟逐步的人类思考过程，从而能够交互式地发现对长视频内容进行深思熟虑理解的有利时间上下文。广泛的实验表明，我们的VideoChat-A1在主流长视频问答基准测试中取得了最先进的性能，例如在VideoMME上达到77.0，在EgoSchema上达到70.1，分别比其强基线（例如Intern2.5VL-8B和InternVideo2.5-8B）提高了10.8%和6.2%。与领先的开源GPT-4o和Gemini 1.5 Pro相比，VideoChat-A1提供了具有竞争力的准确性，但平均输入帧数减少了7%，推理时间减少了12%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent advance in video understanding has been driven by multimodal largelanguage models (MLLMs). But these MLLMs are good at analyzing short videos,while suffering from difficulties in understanding videos with a longercontext. To address this difficulty, several agent paradigms have recently beenproposed, using MLLMs as agents for retrieving extra contextual knowledge in along video. However, most existing agents ignore the key fact that a long videois composed with multiple shots, i.e., to answer the user question from a longvideo, it is critical to deeply understand its relevant shots like human.Without such insight, these agents often mistakenly find redundant even noisytemporal context, restricting their capacity for long video understanding. Tofill this gap, we propose VideoChat-A1, a novel long video agent paradigm.Different from the previous works, our VideoChat-A1 can deeply think with longvideos, via a distinct chain-of-shot reasoning paradigm. More specifically, itcan progressively select the relevant shots of user question, and look intothese shots in a coarse-to-fine partition. By multi-modal reasoning along theshot chain, VideoChat-A1 can effectively mimic step-by-step human thinkingprocess, allowing to interactively discover preferable temporal context forthoughtful understanding in long videos. Extensive experiments show that, ourVideoChat-A1 achieves the state-of-the-art performance on the mainstream longvideo QA benchmarks, e.g., it achieves 77.0 on VideoMME and 70.1 on EgoSchema,outperforming its strong baselines (e.g., Intern2.5VL-8B andInternVideo2.5-8B), by up to 10.8\% and 6.2\%. Compared to leading close-sourceGPT-4o and Gemini 1.5 Pro, VideoChat-A1 offers competitive accuracy, but with7\% input frames and 12\% inference time on average.</description>
      <author>example@mail.com (Zikang Wang, Boyu Chen, Zhengrong Yue, Yi Wang, Yu Qiao, Limin Wang, Yali Wang)</author>
      <guid isPermaLink="false">2506.06097v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>GP-MoLFormer-Sim: Test Time Molecular Optimization through Contextual Similarity Guidance</title>
      <link>http://arxiv.org/abs/2506.05628v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages main article, 21 pages total&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于生成化学语言模型（CLM）的、无需训练的分子空间导航和采样方法，该方法利用分子相似性作为指导，并应用于药物发现、化学设计和生物学等领域。&lt;h4&gt;背景&lt;/h4&gt;设计分子时保持与目标分子和/或性质的相似性对于药物发现、化学设计和生物学等领域的应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的无需训练的分子空间导航和采样方法，同时保持与目标分子的相似性。&lt;h4&gt;方法&lt;/h4&gt;该方法利用CLM学习到的上下文表示来估计分子相似性，并据此调整CLM的自回归采样策略。在解码过程的每一步，该方法都会跟踪当前生成与目标之间的距离，并更新logits以鼓励生成保持相似性。该方法使用了一种参数数量约为4700万的基于SMILES的CLM，即GP-MoLFormer，并因此将其称为GP-MoLFormer-Sim。该方法还与遗传算法（GA）集成，并在涉及性质优化、分子重发现和基于结构的药物设计的标准分子优化基准上进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;GP-MoLFormer-Sim结合遗传算法（GP-MoLFormer-Sim+GA）在黑盒情况下优于现有的无需训练的基线方法。&lt;h4&gt;结论&lt;/h4&gt;这项工作的发现是理解并指导CLM生成机制的一步。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种基于生成化学语言模型（CLM）的、无需训练的分子空间导航和采样方法，该方法利用分子相似性作为指导，并应用于药物发现、化学设计和生物学等领域。我们提出的方法利用CLM本身学习到的上下文表示来估计分子相似性，然后使用该相似性来调整CLM的自回归采样策略。在解码过程的每一步，该方法都会跟踪当前生成与目标之间的距离，并更新logits以鼓励生成保持相似性。我们使用了一种参数数量约为4700万的基于SMILES的CLM，即GP-MoLFormer，并因此将其称为GP-MoLFormer-Sim，该模型允许在测试时更新深度生成策略以反映与一组指导分子的上下文相似性。该方法进一步与遗传算法（GA）集成，并在涉及性质优化、分子重发现和基于结构的药物设计的标准分子优化基准上进行了测试。结果表明，GP-MoLFormer-Sim结合遗传算法（GP-MoLFormer-Sim+GA）在黑盒情况下优于现有的无需训练的基线方法。这项工作的发现是理解并指导CLM生成机制的一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to design molecules while preserving similarity to a targetmolecule and/or property is crucial for various applications in drug discovery,chemical design, and biology. We introduce in this paper an efficienttraining-free method for navigating and sampling from the molecular space witha generative Chemical Language Model (CLM), while using the molecularsimilarity to the target as a guide. Our method leverages the contextualrepresentations learned from the CLM itself to estimate the molecularsimilarity, which is then used to adjust the autoregressive sampling strategyof the CLM. At each step of the decoding process, the method tracks thedistance of the current generations from the target and updates the logits toencourage the preservation of similarity in generations. We implement themethod using a recently proposed $\sim$47M parameter SMILES-based CLM,GP-MoLFormer, and therefore refer to the method as GP-MoLFormer-Sim, whichenables a test-time update of the deep generative policy to reflect thecontextual similarity to a set of guide molecules. The method is furtherintegrated into a genetic algorithm (GA) and tested on a set of standardmolecular optimization benchmarks involving property optimization, molecularrediscovery, and structure-based drug design. Results show that,GP-MoLFormer-Sim, combined with GA (GP-MoLFormer-Sim+GA) outperforms existingtraining-free baseline methods, when the oracle remains black-box. The findingsin this work are a step forward in understanding and guiding the generativemechanisms of CLMs.</description>
      <author>example@mail.com (Jiri Navratil, Jarret Ross, Payel Das, Youssef Mroueh, Samuel C Hoffman, Vijil Chenthamarakshan, Brian Belgodere)</author>
      <guid isPermaLink="false">2506.05628v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>PROVSYN: Synthesizing Provenance Graphs for Data Augmentation in Intrusion Detection Systems</title>
      <link>http://arxiv.org/abs/2506.06226v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PROVSYN是一个自动化的框架，通过三个阶段合成来源图，用于入侵检测，特别是在对抗高级持续性威胁（APTs）时，通过展示复杂的攻击模式。&lt;h4&gt;背景&lt;/h4&gt;来源图分析在入侵检测中起着至关重要的作用，特别是在对抗高级持续性威胁（APTs）时，因为它可以揭示复杂的攻击模式。然而，由于现实世界数据中的类别不平衡，结合图神经网络（GNNs）和自然语言处理（NLP）的系统效果有限。&lt;h4&gt;目的&lt;/h4&gt;提出PROVSYN，以解决现实世界数据中类别不平衡的问题，提高入侵检测模型的性能。&lt;h4&gt;方法&lt;/h4&gt;PROVSYN通过以下三个阶段合成来源图：1）使用结构-语义建模进行异构图结构合成；2）基于规则的拓扑优化；3）使用大型语言模型（LLMs）进行上下文感知的文本属性合成。PROVSYN包括一个综合评估框架，该框架整合了结构、文本、时间和基于嵌入的指标，以及语义验证机制，以评估生成的攻击模式和系统行为的正确性。&lt;h4&gt;主要发现&lt;/h4&gt;使用合成图增加下游APT检测模型的训练数据集，实验结果表明PROVSYN能够生成高保真度的图，并通过有效数据增强提高了检测性能。&lt;h4&gt;结论&lt;/h4&gt;PROVSYN框架能够有效地提高入侵检测模型对高级持续性威胁的检测性能，并通过数据增强增强了模型的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Provenance graph analysis plays a vital role in intrusion detection,particularly against Advanced Persistent Threats (APTs), by exposing complexattack patterns. While recent systems combine graph neural networks (GNNs) withnatural language processing (NLP) to capture structural and semantic features,their effectiveness is limited by class imbalance in real-world data. Toaddress this, we introduce PROVSYN, an automated framework that synthesizesprovenance graphs through a three-phase pipeline: (1) heterogeneous graphstructure synthesis with structural-semantic modeling, (2) rule-basedtopological refinement, and (3) context-aware textual attribute synthesis usinglarge language models (LLMs). PROVSYN includes a comprehensive evaluationframework that integrates structural, textual, temporal, and embedding-basedmetrics, along with a semantic validation mechanism to assess the correctnessof generated attack patterns and system behaviors. To demonstrate practicalutility, we use the synthetic graphs to augment training datasets fordownstream APT detection models. Experimental results show that PROVSYNproduces high-fidelity graphs and improves detection performance througheffective data augmentation.</description>
      <author>example@mail.com (Yi Huang, Wajih UI Hassan, Yao Guo, Xiangqun Chen, Ding Li)</author>
      <guid isPermaLink="false">2506.06226v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>ProJo4D: Progressive Joint Optimization for Sparse-View Inverse Physics Estimation</title>
      <link>http://arxiv.org/abs/2506.05317v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ProJo4D的渐进式联合优化框架，用于解决基于物理的神经渲染问题，提高了4D场景理解的效果。&lt;h4&gt;背景&lt;/h4&gt;神经渲染在3D重建和新视角合成方面取得了显著进展，但将物理与神经渲染结合的逆问题（从视觉数据中估计物理参数）仍然具有挑战性，限制了其在机器人学和XR等领域应用的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高基于物理的神经渲染的准确性，特别是在使用稀疏多视角视频数据时。&lt;h4&gt;方法&lt;/h4&gt;ProJo4D通过逐渐增加联合优化参数的集合，并基于它们的敏感性来指导优化过程，从而实现几何、外观、物理状态和材料属性的完全联合优化。&lt;h4&gt;主要发现&lt;/h4&gt;在PAC-NeRF和Spring-Gaus数据集上的评估表明，ProJo4D在4D未来状态预测、未来状态的新视角渲染和材料参数估计方面优于现有工作。&lt;h4&gt;结论&lt;/h4&gt;ProJo4D框架在物理基础上的4D场景理解方面表现出有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：神经渲染在3D重建和新视角合成方面取得了显著进展。与物理的结合开辟了新的应用。然而，从视觉数据中估计物理参数的逆问题仍然具有挑战性，限制了其在机器人学和XR等应用中的有效性。将物理纳入神经渲染框架的现有方法通常需要密集的多视角视频作为输入，这使得它们在实际应用中难以扩展。当面对稀疏的多视角视频时，现有方法使用的顺序优化策略会导致显著的误差累积，例如，不良的初始3D重建会导致后续阶段的材料参数估计不良。与顺序优化不同，由于问题的高度非凸性和通常不可微分的性质，直接同时优化所有参数也失败了。我们提出了ProJo4D，一个渐进式联合优化框架，它根据其敏感性逐步增加联合优化的参数集合，导致对几何、外观、物理状态和材料属性的完全联合优化。在PAC-NeRF和Spring-Gaus数据集上的评估表明，ProJo4D在4D未来状态预测、未来状态的新视角渲染和材料参数估计方面优于先前的工作，证明了它在物理基础上的4D场景理解方面的有效性。有关演示，请访问项目网页：https://daniel03c1.github.io/ProJo4D/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural rendering has made significant strides in 3D reconstruction and novelview synthesis. With the integration with physics, it opens up newapplications. The inverse problem of estimating physics from visual data,however, still remains challenging, limiting its effectiveness for applicationslike physically accurate digital twin creation in robotics and XR. Existingmethods that incorporate physics into neural rendering frameworks typicallyrequire dense multi-view videos as input, making them impractical for scalable,real-world use. When presented with sparse multi-view videos, the sequentialoptimization strategy used by existing approaches introduces significant erroraccumulation, e.g., poor initial 3D reconstruction leads to bad materialparameter estimation in subsequent stages. Instead of sequential optimization,directly optimizing all parameters at the same time also fails due to thehighly non-convex and often non-differentiable nature of the problem. Wepropose ProJo4D, a progressive joint optimization framework that graduallyincreases the set of jointly optimized parameters guided by their sensitivity,leading to fully joint optimization over geometry, appearance, physical state,and material property. Evaluations on PAC-NeRF and Spring-Gaus datasets showthat ProJo4D outperforms prior work in 4D future state prediction, novel viewrendering of future state, and material parameter estimation, demonstrating itseffectiveness in physically grounded 4D scene understanding. For demos, pleasevisit the project webpage: https://daniel03c1.github.io/ProJo4D/</description>
      <author>example@mail.com (Daniel Rho, Jun Myeong Choi, Biswadip Dey, Roni Sengupta)</author>
      <guid isPermaLink="false">2506.05317v2</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Can In-Context Reinforcement Learning Recover From Reward Poisoning Attacks?</title>
      <link>http://arxiv.org/abs/2506.06891v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于上下文的强化学习（ICRL）的抗腐败鲁棒性，重点关注决策预训练的Transformer（DPT）模型，并提出了一种对抗训练框架AT-DPT来应对针对DPT的奖励中毒攻击。&lt;h4&gt;背景&lt;/h4&gt;DPT模型容易受到奖励中毒攻击的影响，这会导致其学习到的策略失效。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种新的对抗训练方法，增强DPT模型对奖励中毒攻击的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种对抗训练框架AT-DPT，该方法同时训练一个攻击者和一个DPT模型。攻击者旨在通过污染环境奖励来最小化DPT的真实奖励，而DPT模型则从污染数据中推断出最优动作。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，AT-DPT在对抗标准bandit算法，包括针对奖励污染设计的鲁棒基线时，显著优于这些基线。在自适应攻击者的评估中，AT-DPT也表现出了类似的结果。此外，将AT-DPT的评估扩展到MDP设置中，结果表明在bandit场景中观察到的鲁棒性在更复杂的环境中也是适用的。&lt;h4&gt;结论&lt;/h4&gt;AT-DPT框架能够有效提高DPT模型对奖励中毒攻击的鲁棒性，并在更复杂的环境中表现出良好的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;We study the corruption-robustness of in-context reinforcement learning (ICRL), focusing on the Decision-Pretrained Transformer (DPT, Lee et al.,2023). To address the challenge of reward poisoning attacks targeting the DPT,we propose a novel adversarial training framework, called Adversarially Trained Decision-Pretrained Transformer (AT-DPT). Our method simultaneously trains an attacker to minimize the true reward of the DPT by poisoning environment rewards, and a DPT model to infer optimal actions from the poisoned data. We evaluate the effectiveness of our approach against standard bandit algorithms, including robust baselines designed to handle reward contamination. Our results show that the proposed method significantly outperforms these baselines in bandit settings, under a learned attacker. We additionally evaluate AT-DPT on an adaptive attacker, and observe similar results. Furthermore, we extend our evaluation to the MDP setting, confirming that the robustness observed in bandit scenarios generalizes to more complex environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the corruption-robustness of in-context reinforcement learning(ICRL), focusing on the Decision-Pretrained Transformer (DPT, Lee et al.,2023). To address the challenge of reward poisoning attacks targeting the DPT,we propose a novel adversarial training framework, called Adversarially TrainedDecision-Pretrained Transformer (AT-DPT). Our method simultaneously trains anattacker to minimize the true reward of the DPT by poisoning environmentrewards, and a DPT model to infer optimal actions from the poisoned data. Weevaluate the effectiveness of our approach against standard bandit algorithms,including robust baselines designed to handle reward contamination. Our resultsshow that the proposed method significantly outperforms these baselines inbandit settings, under a learned attacker. We additionally evaluate AT-DPT onan adaptive attacker, and observe similar results. Furthermore, we extend ourevaluation to the MDP setting, confirming that the robustness observed inbandit scenarios generalizes to more complex environments.</description>
      <author>example@mail.com (Paulius Sasnauskas, Yiğit Yalın, Goran Radanović)</author>
      <guid isPermaLink="false">2506.06891v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Discrete Minds in a Continuous World: Do Language Models Know Time Passes?</title>
      <link>http://arxiv.org/abs/2506.05790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了大型语言模型（LLMs）对时间流逝的感知能力及其在决策中的适应性。&lt;h4&gt;背景&lt;/h4&gt;尽管LLMs在时间推理任务上表现出色，但它们对实际时间流逝的感知能力尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;通过三项实验研究LLMs是否能够感知时间流逝并据此调整决策。&lt;h4&gt;方法&lt;/h4&gt;首先，提出了Token-Time假设，并通过对话时长判断任务验证该假设；其次，展示了LLMs如何利用这种意识来调整回答长度，在用户表达紧迫性时保持准确性；最后，开发了BombRush游戏，以检验LLMs在动态环境中面对渐进时间压力时的行为变化。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs对时间流逝有一定的感知能力，能够将离散的语言符号与连续的物理时间相连接，但这种能力随模型大小和推理能力而异。&lt;h4&gt;结论&lt;/h4&gt;本研究为在时间敏感应用中提高LLMs的时间感知能力奠定了理论基础。&lt;h4&gt;翻译&lt;/h4&gt;While Large Language Models (LLMs) excel at temporal reasoning tasks like event ordering and duration estimation, their ability to perceive the actual passage of time remains unexplored. We investigate whether LLMs perceive the passage of time and adapt their decision-making accordingly through three complementary experiments. First, we introduce the Token-Time Hypothesis, positing that LLMs can map discrete token counts to continuous wall-clock time, and validate this through a dialogue duration judgment task. Second, we demonstrate that LLMs could use this awareness to adapt their response length while maintaining accuracy when users express urgency in question answering tasks. Finally, we develop BombRush, an interactive navigation challenge that examines how LLMs modify behavior under progressive time pressure in dynamic environments. Our findings indicate that LLMs possess certain awareness of time passage, enabling them to bridge discrete linguistic tokens and continuous physical time, though this capability varies with model size and reasoning abilities. This work establishes a theoretical foundation for enhancing temporal awareness in LLMs for time-sensitive applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While Large Language Models (LLMs) excel at temporal reasoning tasks likeevent ordering and duration estimation, their ability to perceive the actualpassage of time remains unexplored. We investigate whether LLMs perceive thepassage of time and adapt their decision-making accordingly through threecomplementary experiments. First, we introduce the Token-Time Hypothesis,positing that LLMs can map discrete token counts to continuous wall-clock time,and validate this through a dialogue duration judgment task. Second, wedemonstrate that LLMs could use this awareness to adapt their response lengthwhile maintaining accuracy when users express urgency in question answeringtasks. Finally, we develop BombRush, an interactive navigation challenge thatexamines how LLMs modify behavior under progressive time pressure in dynamicenvironments. Our findings indicate that LLMs possess certain awareness of timepassage, enabling them to bridge discrete linguistic tokens and continuousphysical time, though this capability varies with model size and reasoningabilities. This work establishes a theoretical foundation for enhancingtemporal awareness in LLMs for time-sensitive applications.</description>
      <author>example@mail.com (Minghan Wang, Ye Bai, Thuy-Trang Vu, Ehsan Shareghi, Gholamreza Haffari)</author>
      <guid isPermaLink="false">2506.05790v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Masked Language Models are Good Heterogeneous Graph Generalizers</title>
      <link>http://arxiv.org/abs/2506.06157v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于掩码语言模型的异构图学习方法MLM4HG，旨在解决现有方法在异构图学习中的泛化问题。&lt;h4&gt;背景&lt;/h4&gt;现有的异构图神经网络（HGNNs）在捕捉异构图（HGs）的结构和语义信息方面表现出色，但在跨领域和任务上的泛化能力有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以增强异构图学习的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;MLM4HG通过基于元路径的文本序列来提取异构图中的结构化和语义信息，并设计定制的文本模板，将不同的图任务统一到一个连贯的完形填空式“掩码”标记预测范式。该方法首先将不同领域的异构图转换为文本，然后结合统一任务文本形成基于异构图的语料库，并使用预训练的语言模型进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界数据集上的跨领域和多任务实验表明，MLM4HG在少样本和零样本场景下均优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;MLM4HG在异构图学习中的泛化性能显著，是一种简单而有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;The abstract of this paper is summarized as follows: This paper proposes a Masked Language Modeling-based method for heterogeneous graph learning, called MLM4HG, aiming to enhance the generalization ability of existing methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterogeneous graph neural networks (HGNNs) excel at capturing structural andsemantic information in heterogeneous graphs (HGs), while struggling togeneralize across domains and tasks. Recently, some researchers have turned tointegrating HGNNs with large language models (LLMs) for more generalizableheterogeneous graph learning. However, these approaches typically extractstructural information via HGNNs as HG tokens, and disparities in embeddingspaces between HGNNs and LLMs have been shown to bias the LLM's comprehensionof HGs. Moreover, as these HG tokens are often derived from node-level tasks,the model's ability to generalize across tasks remains limited. To this end, wepropose a simple yet effective Masked Language Modeling-based method, calledMLM4HG. MLM4HG introduces metapath-based textual sequences instead of HG tokensto extract structural and semantic information inherent in HGs, and designscustomized textual templates to unify different graph tasks into a coherentcloze-style "mask" token prediction paradigm. Specifically, MLM4HG firstconverts HGs from various domains to texts based on metapaths, and subsequentlycombines them with the unified task texts to form a HG-based corpus. Moreover,the corpus is fed into a pretrained LM for fine-tuning with a constrainedtarget vocabulary, enabling the fine-tuned LM to generalize to unseen targetHGs. Extensive cross-domain and multi-task experiments on four real-worlddatasets demonstrate the superior generalization performance of MLM4HG overstate-of-the-art methods in both few-shot and zero-shot scenarios. Our code isavailable at https://github.com/BUPT-GAMMA/MLM4HG.</description>
      <author>example@mail.com (Jinyu Yang, Cheng Yang, Shanyuan Cui, Zeyuan Guo, Liangwei Yang, Muhan Zhang, Chuan Shi)</author>
      <guid isPermaLink="false">2506.06157v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Two-dimensional Taxonomy for N-ary Knowledge Representation Learning Methods</title>
      <link>http://arxiv.org/abs/2506.05626v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了处理n元关系数据的知识超图和超关系知识图谱方法，提出了一个两维分类体系，并讨论了现有数据集、负采样策略和未来研究方向。&lt;h4&gt;背景&lt;/h4&gt;现实世界的知识可以以结构化、半结构化和非结构化数据的形式存在，知识图谱虽然能够整合异构数据源，但通常会将复杂的n元关系简化为简单的三元组，从而丢失了更高阶的关系细节。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了知识超图和超关系知识图谱，结合知识图谱和超图的优势，以更好地捕捉现实世界知识的复杂结构和角色特定的语义。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个两维分类体系，第一维根据方法分类，包括基于翻译的模型、基于张量分解的模型、基于深度神经网络的模型、基于逻辑规则的模型和基于超边扩展的模型。第二维根据模型对实体角色和位置在n元关系中的感知分类，分为无感知、位置感知和角色感知方法。&lt;h4&gt;主要发现&lt;/h4&gt;本文提供了一个全面的综述，包括知识超图和超关系知识图谱的文献，并讨论了现有的数据集、负采样策略。&lt;h4&gt;结论&lt;/h4&gt;本文总结了现有研究，并提出了未来研究的开放挑战，以激发进一步的研究工作。&lt;h4&gt;翻译&lt;/h4&gt;本文综述了处理n元关系数据的知识超图和超关系知识图谱方法，提出了一个两维分类体系：第一个维度根据方法将模型分类，即基于翻译的模型、基于张量分解的模型、基于深度神经网络的模型、基于逻辑规则的模型和基于超边扩展的模型；第二个维度根据模型对实体角色和位置在n元关系中的感知分类，分为无感知、位置感知和角色感知方法。最后，讨论了现有数据集、负采样策略，并概述了开放挑战，以激发未来的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world knowledge can take various forms, including structured,semi-structured, and unstructured data. Among these, knowledge graphs are aform of structured human knowledge that integrate heterogeneous data sourcesinto structured representations but typically reduce complex n-ary relations tosimple triples, thereby losing higher-order relational details. In contrast,hypergraphs naturally represent n-ary relations with hyperedges, which directlyconnect multiple entities together. Yet hypergraph representation learningoften overlooks entity roles in hyperedges, limiting the fine-grained semanticmodelling. To address these issues, knowledge hypergraphs and hyper-relationalknowledge graphs combine the advantages of knowledge graphs and hypergraphs tobetter capture the complex structures and role-specific semantics of real-worldknowledge. This survey provides a comprehensive review of methods handlingn-ary relational data, covering both knowledge hypergraphs and hyper-relationalknowledge graphs literatures. We propose a two-dimensional taxonomy: the firstdimension categorises models based on their methodology, i.e.,translation-based models, tensor factorisation-based models, deep neuralnetwork-based models, logic rules-based models, and hyperedge expansion-basedmodels. The second dimension classifies models according to their awareness ofentity roles and positions in n-ary relations, dividing them into aware-less,position-aware, and role-aware approaches. Finally, we discuss existingdatasets, negative sampling strategies, and outline open challenges to inspirefuture research.</description>
      <author>example@mail.com (Xiaohua Lu, Liubov Tupikina, Mehwish Alam)</author>
      <guid isPermaLink="false">2506.05626v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>SIV-Bench: A Video Benchmark for Social Interaction Understanding and Reasoning</title>
      <link>http://arxiv.org/abs/2506.05425v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SIV-Bench，一个用于评估多模态大型语言模型在社交场景理解、社交状态推理和社交动态预测方面的能力的视频基准。&lt;h4&gt;背景&lt;/h4&gt;人类社交互动的丰富性和多层次性，包括多模态线索、不可观察的关系和心智状态以及动态行为，对人工智能提出了巨大挑战。&lt;h4&gt;目的&lt;/h4&gt;为了推进这一领域的研究，本文引入了SIV-Bench，旨在严格评估多模态大型语言模型（MLLMs）的能力。&lt;h4&gt;方法&lt;/h4&gt;SIV-Bench包含2,792个视频片段和8,792个由人机协同生成的问答对，数据来源于TikTok和YouTube，覆盖了广泛的视频类型、呈现风格、语言和文化背景。还包括一个用于分析不同文本线索影响的分析设置。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，模型在社交场景理解（SSU）方面表现良好，但在社交状态推理（SSR）和社交动态预测（SDP）方面存在显著困难，其中关系推理（RI）是一个瓶颈。此外，转录对话在理解复杂社交互动方面发挥了关键作用。&lt;h4&gt;结论&lt;/h4&gt;SIV-Bench通过系统地识别当前MLLMs的优势和局限性，为更智能的AI发展提供了关键见解。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了SIV-Bench，这是一个用于严格评估多模态大型语言模型（MLLMs）在社交场景理解（SSU）、社交状态推理（SSR）和社交动态预测（SDP）方面能力的视频基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rich and multifaceted nature of human social interaction, encompassingmultimodal cues, unobservable relations and mental states, and dynamicalbehavior, presents a formidable challenge for artificial intelligence. Toadvance research in this area, we introduce SIV-Bench, a novel video benchmarkfor rigorously evaluating the capabilities of Multimodal Large Language Models(MLLMs) across Social Scene Understanding (SSU), Social State Reasoning (SSR),and Social Dynamics Prediction (SDP). SIV-Bench features 2,792 video clips and8,792 meticulously generated question-answer pairs derived from a human-LLMcollaborative pipeline. It is originally collected from TikTok and YouTube,covering a wide range of video genres, presentation styles, and linguistic andcultural backgrounds. It also includes a dedicated setup for analyzing theimpact of different textual cues-original on-screen text, added dialogue, or notext. Our comprehensive experiments on leading MLLMs reveal that while modelsadeptly handle SSU, they significantly struggle with SSR and SDP, whereRelation Inference (RI) is an acute bottleneck, as further examined in ouranalysis. Our study also confirms the critical role of transcribed dialogue inaiding comprehension of complex social interactions. By systematicallyidentifying current MLLMs' strengths and limitations, SIV-Bench offers crucialinsights to steer the development of more socially intelligent AI. The datasetand code are available at https://kfq20.github.io/sivbench/.</description>
      <author>example@mail.com (Fanqi Kong, Weiqin Zu, Xinyu Chen, Yaodong Yang, Song-Chun Zhu, Xue Feng)</author>
      <guid isPermaLink="false">2506.05425v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Mixture-of-Experts Meets In-Context Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.05426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为T2MIR的创新框架，用于解决在上下文强化学习（ICRL）中的多模态数据和决策任务异质性挑战，通过引入混合专家（MoE）架构和对比学习方法，显著提升了ICRL的性能。&lt;h4&gt;背景&lt;/h4&gt;在上下文强化学习（ICRL）中，将强化学习代理适应下游任务面临两个主要挑战：状态-动作-奖励数据的内在多模态性和决策任务的多样性和异质性。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为T2MIR的框架，以解决上述挑战，并提升ICRL的性能。&lt;h4&gt;方法&lt;/h4&gt;T2MIR框架引入了MoE架构到基于transformer的决策模型中，包括：1. 替换前馈层为两个并行层：一个token-wise MoE，用于捕捉不同模态输入token的语义；一个task-wise MoE，用于将不同任务路由到专门的专家，以管理广泛的任务分布并减轻梯度冲突。2. 引入对比学习方法，最大化任务与其路由表示之间的互信息，以更精确地捕获任务相关信息。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，T2MIR显著提高了ICRL的学习能力，并优于多种基线方法。&lt;h4&gt;结论&lt;/h4&gt;T2MIR为ICRL带来了MoE的潜力和前景，提供了一种简单且可扩展的架构增强，使ICRL更接近语言和视觉社区的研究成果。&lt;h4&gt;翻译&lt;/h4&gt;In-context reinforcement learning (ICRL) has emerged as a promising paradigm for adapting RL agents to downstream tasks through prompt conditioning. However, two notable challenges remain in fully harnessing in-context learning within RL domains: the intrinsic multi-modality of the state-action-reward data and the diverse, heterogeneous nature of decision tasks. To tackle these challenges, we propose T2MIR (Token- and Task-wise MoE for In-context RL), an innovative framework that introduces architectural advances of mixture-of-experts (MoE) into transformer-based decision models. T2MIR substitutes the feedforward layer with two parallel layers: a token-wise MoE that captures distinct semantics of input tokens across multiple modalities, and a task-wise MoE that routes diverse tasks to specialized experts for managing a broad task distribution with alleviated gradient conflicts. To enhance task-wise routing, we introduce a contrastive learning method that maximizes the mutual information between the task and its router representation, enabling more precise capture of task-relevant information. The outputs of two MoE components are concatenated and fed into the next layer. Comprehensive experiments show that T2MIR significantly facilitates in-context learning capacity and outperforms various types of baselines. We bring the potential and promise of MoE to ICRL, offering a simple and scalable architectural enhancement to advance ICRL one step closer toward achievements in language and vision communities. Our code is available at https://github.com/NJU-RL/T2MIR.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In-context reinforcement learning (ICRL) has emerged as a promising paradigmfor adapting RL agents to downstream tasks through prompt conditioning.However, two notable challenges remain in fully harnessing in-context learningwithin RL domains: the intrinsic multi-modality of the state-action-reward dataand the diverse, heterogeneous nature of decision tasks. To tackle thesechallenges, we propose \textbf{T2MIR} (\textbf{T}oken- and \textbf{T}ask-wise\textbf{M}oE for \textbf{I}n-context \textbf{R}L), an innovative framework thatintroduces architectural advances of mixture-of-experts (MoE) intotransformer-based decision models. T2MIR substitutes the feedforward layer withtwo parallel layers: a token-wise MoE that captures distinct semantics of inputtokens across multiple modalities, and a task-wise MoE that routes diversetasks to specialized experts for managing a broad task distribution withalleviated gradient conflicts. To enhance task-wise routing, we introduce acontrastive learning method that maximizes the mutual information between thetask and its router representation, enabling more precise capture oftask-relevant information. The outputs of two MoE components are concatenatedand fed into the next layer. Comprehensive experiments show that T2MIRsignificantly facilitates in-context learning capacity and outperforms varioustypes of baselines. We bring the potential and promise of MoE to ICRL, offeringa simple and scalable architectural enhancement to advance ICRL one step closertoward achievements in language and vision communities. Our code is availableat https://github.com/NJU-RL/T2MIR.</description>
      <author>example@mail.com (Wenhao Wu, Fuhong Liu, Haoru Li, Zican Hu, Daoyi Dong, Chunlin Chen, Zhi Wang)</author>
      <guid isPermaLink="false">2506.05426v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Spatial Language Maps for Robot Navigation and Manipulation</title>
      <link>http://arxiv.org/abs/2506.06862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted to International Journal of Robotics Research (IJRR). 24  pages, 18 figures. The paper contains texts from VLMaps(arXiv:2210.05714) and  AVLMaps(arXiv:2303.07522). The project page is https://mslmaps.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为多模态空间语言地图的新方法，该方法通过融合预训练的多模态特征与环境的三维重建来提高导航代理的观察与对象或事件描述之间的匹配。&lt;h4&gt;背景&lt;/h4&gt;现有的方法与环境地图脱节，缺乏几何地图的空间精确性，或忽略了除视觉之外的额外模态信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够融合预训练的多模态特征与环境三维重建的空间地图表示，以解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;使用标准探索自主构建这些地图，并创建了两种地图实例：视觉语言地图（VLMaps）和扩展的音频视觉语言地图（AVLMaps），通过添加音频信息获得。&lt;h4&gt;主要发现&lt;/h4&gt;VLMaps可以将自然语言命令直接转换为地图中定位的开放词汇空间目标，并能跨不同机器人实体共享以生成定制的障碍物地图。AVLMaps通过融合来自预训练的多模态基础模型的特征，引入了统一的3D空间表示，集成了音频、视觉和语言线索。这些地图使机器人能够将多模态目标查询（如文本、图像或音频片段）定位到空间位置进行导航，并在模糊环境中显著提高目标区分度。&lt;h4&gt;结论&lt;/h4&gt;在模拟和现实世界的实验中，多模态空间语言地图实现了零样本空间和多模态目标导航，在模糊场景中的召回率提高了50%，这些能力适用于移动机器人和桌面操作器，支持由视觉、音频和空间线索引导的导航和交互。&lt;h4&gt;翻译&lt;/h4&gt;Grounding language to a navigating agent's observations can leverage pretrained multimodal foundation models to match perceptions to object or event descriptions. However, previous approaches remain disconnected from environment mapping, lack the spatial precision of geometric maps, or neglect additional modality information beyond vision. To address this, we propose multimodal spatial language maps as a spatial map representation that fuses pretrained multimodal features with a 3D reconstruction of the environment. We build these maps autonomously using standard exploration. We present two instances of our maps, which are visual-language maps (VLMaps) and their extension to audio-visual-language maps (AVLMaps) obtained by adding audio information. When combined with large language models (LLMs), VLMaps can (i) translate natural language commands into open-vocabulary spatial goals (e.g., 'in between the sofa and TV') directly localized in the map, and (ii) be shared across different robot embodiments to generate tailored obstacle maps on demand. Building upon the capabilities above, AVLMaps extend VLMaps by introducing a unified 3D spatial representation integrating audio, visual, and language cues through the fusion of features from pretrained multimodal foundation models. This enables robots to ground multimodal goal queries (e.g., text, images, or audio snippets) to spatial locations for navigation. Additionally, the incorporation of diverse sensory inputs significantly enhances goal disambiguation in ambiguous environments. Experiments in simulation and real-world settings demonstrate that our multimodal spatial language maps enable zero-shot spatial and multimodal goal navigation and improve recall by 50% in ambiguous scenarios. These capabilities extend to mobile robots and tabletop manipulators, supporting navigation and interaction guided by visual, audio, and spatial cues.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grounding language to a navigating agent's observations can leveragepretrained multimodal foundation models to match perceptions to object or eventdescriptions. However, previous approaches remain disconnected from environmentmapping, lack the spatial precision of geometric maps, or neglect additionalmodality information beyond vision. To address this, we propose multimodalspatial language maps as a spatial map representation that fuses pretrainedmultimodal features with a 3D reconstruction of the environment. We build thesemaps autonomously using standard exploration. We present two instances of ourmaps, which are visual-language maps (VLMaps) and their extension toaudio-visual-language maps (AVLMaps) obtained by adding audio information. Whencombined with large language models (LLMs), VLMaps can (i) translate naturallanguage commands into open-vocabulary spatial goals (e.g., "in between thesofa and TV") directly localized in the map, and (ii) be shared acrossdifferent robot embodiments to generate tailored obstacle maps on demand.Building upon the capabilities above, AVLMaps extend VLMaps by introducing aunified 3D spatial representation integrating audio, visual, and language cuesthrough the fusion of features from pretrained multimodal foundation models.This enables robots to ground multimodal goal queries (e.g., text, images, oraudio snippets) to spatial locations for navigation. Additionally, theincorporation of diverse sensory inputs significantly enhances goaldisambiguation in ambiguous environments. Experiments in simulation andreal-world settings demonstrate that our multimodal spatial language mapsenable zero-shot spatial and multimodal goal navigation and improve recall by50% in ambiguous scenarios. These capabilities extend to mobile robots andtabletop manipulators, supporting navigation and interaction guided by visual,audio, and spatial cues.</description>
      <author>example@mail.com (Chenguang Huang, Oier Mees, Andy Zeng, Wolfram Burgard)</author>
      <guid isPermaLink="false">2506.06862v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>EASG-Bench: Video Q&amp;A Benchmark with Egocentric Action Scene Graphs</title>
      <link>http://arxiv.org/abs/2506.05787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了EASG-Bench，一个用于自摄视频问答的基准，其中的问答对由时空定位的动态场景图生成，该图捕捉了演员、动作和物体之间的复杂关系。&lt;h4&gt;背景&lt;/h4&gt;在自摄视频中，问答系统需要理解场景中的动态关系。&lt;h4&gt;目的&lt;/h4&gt;评估多种语言和视频大型语言模型（video-LLMs）在EASG-Bench上的性能，并识别视频理解领域的研究差距。&lt;h4&gt;方法&lt;/h4&gt;提出了一种系统性的评估框架，并在此基准上评估了多种语言和视频大型语言模型。&lt;h4&gt;主要发现&lt;/h4&gt;观察到了语言和视频大型语言模型之间存在的性能差距，特别是在关注时间顺序的问题上，这表明在长上下文视频理解领域存在研究差距。&lt;h4&gt;结论&lt;/h4&gt;为了促进发现的可重复性和进一步研究的便利，基准和配套代码可在GitHub上获取。&lt;h4&gt;翻译&lt;/h4&gt;We introduce EASG-Bench, a question-answering benchmark for egocentric videos where the question-answering pairs are created from spatio-temporally grounded dynamic scene graphs capturing intricate relationships among actors, actions, and objects. We propose a systematic evaluation framework and evaluate several language-only and video large language models (video-LLMs) on this benchmark. We observe a performance gap in language-only and video-LLMs, especially on questions focusing on temporal ordering, thus identifying a research gap in the area of long-context video understanding. To promote the reproducibility of our findings and facilitate further research, the benchmark and accompanying code are available at the following GitHub page: https://github.com/fpv-iplab/EASG-bench.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce EASG-Bench, a question-answering benchmark for egocentric videoswhere the question-answering pairs are created from spatio-temporally groundeddynamic scene graphs capturing intricate relationships among actors, actions,and objects. We propose a systematic evaluation framework and evaluate severallanguage-only and video large language models (video-LLMs) on this benchmark.We observe a performance gap in language-only and video-LLMs, especially onquestions focusing on temporal ordering, thus identifying a research gap in thearea of long-context video understanding. To promote the reproducibility of ourfindings and facilitate further research, the benchmark and accompanying codeare available at the following GitHub page:https://github.com/fpv-iplab/EASG-bench.</description>
      <author>example@mail.com (Ivan Rodin, Tz-Ying Wu, Kyle Min, Sharath Nittur Sridhar, Antonino Furnari, Subarna Tripathi, Giovanni Maria Farinella)</author>
      <guid isPermaLink="false">2506.05787v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Flow-Attentional Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.06127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为flow attention的新方法，用于改进图神经网络（GNNs）在处理具有物理资源流动（如电力电流或交通流量）的图结构数据时的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的GNNs没有考虑图中与物理资源流动相关的守恒定律，这可能导致模型性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出flow attention以适应现有图注意力机制，以满足基尔霍夫第一定律。&lt;h4&gt;方法&lt;/h4&gt;通过修改图注意力机制，flow attention能够处理具有物理资源流动的图结构数据。&lt;h4&gt;主要发现&lt;/h4&gt;flow attention增强了基于注意力的GNNs在图级分类和回归任务上的性能，并能够区分一些非同构图，这些图在标准注意力机制下无法区分。&lt;h4&gt;结论&lt;/h4&gt;flow attention是一种有效的改进方法，可以提高GNNs在处理具有物理资源流动的图结构数据时的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have become essential for learning from graph-structured data. However, existing GNNs do not consider the conservation law inherent in graphs associated with a flow of physical resources, such as electrical current in power grids or traffic in transportation networks, which can lead to reduced model performance. To address this, we propose flow attention, which adapts existing graph attention mechanisms to satisfy Kirchhoff's first law. Furthermore, we discuss how this modification influences the expressivity and identify sets of non-isomorphic graphs that can be discriminated by flow attention but not by standard attention. Through extensive experiments on two flow graph datasets (electronic circuits and power grids), we demonstrate that flow attention enhances the performance of attention-based GNNs on both graph-level classification and regression tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have become essential for learning fromgraph-structured data. However, existing GNNs do not consider the conservationlaw inherent in graphs associated with a flow of physical resources, such aselectrical current in power grids or traffic in transportation networks, whichcan lead to reduced model performance. To address this, we propose flowattention, which adapts existing graph attention mechanisms to satisfyKirchhoff\'s first law. Furthermore, we discuss how this modificationinfluences the expressivity and identify sets of non-isomorphic graphs that canbe discriminated by flow attention but not by standard attention. Throughextensive experiments on two flow graph datasets (electronic circuits and powergrids), we demonstrate that flow attention enhances the performance ofattention-based GNNs on both graph-level classification and regression tasks.</description>
      <author>example@mail.com (Pascal Plettenberg, Dominik Köhler, Bernhard Sick, Josephine M. Thomas)</author>
      <guid isPermaLink="false">2506.06127v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>EndoARSS: Adapting Spatially-Aware Foundation Model for Efficient Activity Recognition and Semantic Segmentation in Endoscopic Surgery</title>
      <link>http://arxiv.org/abs/2506.06830v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Advanced Intelligent Systems&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EndoARSS的新型多任务学习框架，用于内窥镜手术活动的识别和语义分割，通过提高准确性和鲁棒性来增强内窥镜手术系统的性能。&lt;h4&gt;背景&lt;/h4&gt;内窥镜手术是机器人辅助微创手术的金标准，但在手术场景的复杂性和图像特征混淆的情况下，传统的深度学习模型难以实现理想性能。&lt;h4&gt;目的&lt;/h4&gt;为了解决传统深度学习模型在跨活动干扰问题上的局限性，提出了一种基于多任务学习的框架，以提高整体任务性能。&lt;h4&gt;方法&lt;/h4&gt;EndoARSS框架基于DINOv2基础模型，结合了低秩适应和任务高效共享低秩适配器，引入了空间感知多尺度注意力机制，并创建了三个新的数据集MTLESD、MTLEndovis和MTLEndovis-Gen，用于评估框架的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，EndoARSS在多个基准测试中实现了显著性能提升，与现有模型相比，在准确性和鲁棒性方面均有显著提高。&lt;h4&gt;结论&lt;/h4&gt;EndoARSS有潜力推动AI驱动的内窥镜手术系统的发展，为提高手术安全和效率提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：内镜手术是机器人辅助微创手术的金标准，它为早期疾病检测和精确干预提供了显著优势。然而，手术场景的复杂性，包括不同手术活动场景中的高度可变性和目标与背景之间的混淆图像特征，为手术环境理解带来了挑战。传统的深度学习模型通常难以处理跨活动干扰，导致下游任务性能不佳。为了解决这一局限性，我们探索了多任务学习，它利用任务之间的相关特征来提高整体任务性能。在本文中，我们提出了一种名为EndoARSS的新型多任务学习框架，专门针对内镜手术活动识别和语义分割。基于DINOv2基础模型，我们的方法结合了低秩适应以促进高效的微调，同时引入了任务高效共享低秩适配器以缓解不同任务之间的梯度冲突。此外，我们引入了空间感知多尺度注意力机制，通过实现全局信息的跨空间学习来增强特征表示的区分度。为了评估我们框架的有效性，我们提出了三个新的数据集MTLESD、MTLEndovis和MTLEndovis-Gen，这些数据集针对内镜手术场景定制，并提供了活动识别和语义分割任务的详细注释。大量的实验表明，EndoARSS在多个基准测试中实现了显著的性能，与现有模型相比，在准确性和鲁棒性方面均有显著提高。这些结果强调了EndoARSS在推进AI驱动的内镜手术系统方面的潜力，为提高手术安全和效率提供了有价值的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Endoscopic surgery is the gold standard for robotic-assisted minimallyinvasive surgery, offering significant advantages in early disease detectionand precise interventions. However, the complexity of surgical scenes,characterized by high variability in different surgical activity scenarios andconfused image features between targets and the background, presents challengesfor surgical environment understanding. Traditional deep learning models oftenstruggle with cross-activity interference, leading to suboptimal performance ineach downstream task. To address this limitation, we explore multi-tasklearning, which utilizes the interrelated features between tasks to enhanceoverall task performance. In this paper, we propose EndoARSS, a novelmulti-task learning framework specifically designed for endoscopy surgeryactivity recognition and semantic segmentation. Built upon the DINOv2foundation model, our approach integrates Low-Rank Adaptation to facilitateefficient fine-tuning while incorporating Task Efficient Shared Low-RankAdapters to mitigate gradient conflicts across diverse tasks. Additionally, weintroduce the Spatially-Aware Multi-Scale Attention that enhances featurerepresentation discrimination by enabling cross-spatial learning of globalinformation. In order to evaluate the effectiveness of our framework, wepresent three novel datasets, MTLESD, MTLEndovis and MTLEndovis-Gen, tailoredfor endoscopic surgery scenarios with detailed annotations for both activityrecognition and semantic segmentation tasks. Extensive experiments demonstratethat EndoARSS achieves remarkable performance across multiple benchmarks,significantly improving both accuracy and robustness in comparison to existingmodels. These results underscore the potential of EndoARSS to advance AI-drivenendoscopic surgical systems, offering valuable insights for enhancing surgicalsafety and efficiency.</description>
      <author>example@mail.com (Guankun Wang, Rui Tang, Mengya Xu, Long Bai, Huxin Gao, Hongliang Ren)</author>
      <guid isPermaLink="false">2506.06830v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>LLM-Symbolic Integration for Robust Temporal Tabular Reasoning</title>
      <link>http://arxiv.org/abs/2506.05746v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACL Findings 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了针对时间表问答的挑战，并提出了一种名为TempTabQA-C的数据集和符号中间表示方法，以提高大型语言模型（LLMs）在时间表问答任务中的表现。&lt;h4&gt;背景&lt;/h4&gt;时间表问答对LLMs来说是一个重大挑战，因为需要在对结构化数据的强大推理能力，而传统的提示方法通常不足以应对这种挑战。&lt;h4&gt;目的&lt;/h4&gt;克服传统方法在记忆、对表大小的敏感性和复杂查询性能降低等方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;引入了TempTabQA-C数据集，用于系统性和可控的评估，以及将表格转换为数据库模式的符号中间表示。这种方法允许LLMs生成和执行SQL查询，从而增强泛化能力和减轻偏差。通过结合自适应的少样本提示和上下文定制的示例，该方法实现了更高的鲁棒性、可扩展性和性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在关键挑战方面取得了持续改进，为LLMs进行鲁棒的时间推理设定了新的基准。&lt;h4&gt;结论&lt;/h4&gt;TempTabQA-C数据集和符号中间表示方法能够显著提高LLMs在时间表问答任务中的表现。&lt;h4&gt;翻译&lt;/h4&gt;Temporal tabular question answering presents a significant challenge for Large Language Models (LLMs), requiring robust reasoning over structured data, which is a task where traditional prompting methods often fall short. These methods face challenges such as memorization, sensitivity to table size, and reduced performance on complex queries. To overcome these limitations, we introduce TempTabQA-C, a synthetic dataset designed for systematic and controlled evaluations, alongside a symbolic intermediate representation that transforms tables into database schemas. This structured approach allows LLMs to generate and execute SQL queries, enhancing generalization and mitigating biases. By incorporating adaptive few-shot prompting with contextually tailored examples, our method achieves superior robustness, scalability, and performance. Experimental results consistently highlight improvements across key challenges, setting a new benchmark for robust temporal reasoning with LLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal tabular question answering presents a significant challenge forLarge Language Models (LLMs), requiring robust reasoning over structured data,which is a task where traditional prompting methods often fall short. Thesemethods face challenges such as memorization, sensitivity to table size, andreduced performance on complex queries. To overcome these limitations, weintroduce TempTabQA-C, a synthetic dataset designed for systematic andcontrolled evaluations, alongside a symbolic intermediate representation thattransforms tables into database schemas. This structured approach allows LLMsto generate and execute SQL queries, enhancing generalization and mitigatingbiases. By incorporating adaptive few-shot prompting with contextually tailoredexamples, our method achieves superior robustness, scalability, andperformance. Experimental results consistently highlight improvements acrosskey challenges, setting a new benchmark for robust temporal reasoning withLLMs.</description>
      <author>example@mail.com (Atharv Kulkarni, Kushagra Dixit, Vivek Srikumar, Dan Roth, Vivek Gupta)</author>
      <guid isPermaLink="false">2506.05746v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion-Based Hierarchical Graph Neural Networks for Simulating Nonlinear Solid Mechanics</title>
      <link>http://arxiv.org/abs/2506.06045v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ROBIN的新型学习模拟器，用于在非结构化网格上模拟物理系统，该模拟器通过并行推理方案和分层图神经网络，解决了传统模拟器在捕捉全局现象和长期预测中的局限性。&lt;h4&gt;背景&lt;/h4&gt;基于图的学习模拟器在模拟物理系统方面具有速度和泛化能力的优势，但它们在捕捉全局现象和长期预测方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出ROBIN以解决现有模拟器在模拟物理系统时的局限性，如捕捉全局现象和长期预测中的误差积累。&lt;h4&gt;方法&lt;/h4&gt;ROBIN集成了两个关键创新：(i) 滚动扩散，通过在时间窗口内重叠去噪步骤来分摊基于扩散的细化成本；(ii) 基于代数多重网格粗化的分层图神经网络，实现不同网格分辨率的跨尺度消息传递。&lt;h4&gt;主要发现&lt;/h4&gt;ROBIN在二维和三维固体力学基准测试中表现出色，实现了最先进的精度，并且与标准扩散模拟器相比，推理时间减少了高达一个数量级。&lt;h4&gt;结论&lt;/h4&gt;ROBIN是一种高效且准确的学习模拟器，能够有效地模拟物理系统，特别是在捕捉全局现象和长期预测方面具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;Graph-based learned simulators have emerged as a promising approach for simulating physical systems on unstructured meshes, offering speed and generalization across diverse geometries. However, they often struggle with capturing global phenomena, such as bending or long-range correlations, and suffer from error accumulation over long rollouts due to their reliance on local message passing and direct next-step prediction. We address these limitations by introducing the Rolling Diffusion-Batched Inference Network (ROBIN), a novel learned simulator that integrates two key innovations: (i) Rolling Diffusion, a parallelized inference scheme that amortizes the cost of diffusion-based refinement across physical time steps by overlapping denoising steps across a temporal window. (ii) A Hierarchical Graph Neural Network built on algebraic multigrid coarsening, enabling multiscale message passing across different mesh resolutions. This architecture, implemented via Algebraic-hierarchical Message Passing Networks, captures both fine-scale local dynamics and global structural effects critical for phenomena like beam bending or multi-body contact. We validate ROBIN on challenging 2D and 3D solid mechanics benchmarks involving geometric, material, and contact nonlinearities. ROBIN achieves state-of-the-art accuracy on all tasks, substantially outperforming existing next-step learned simulators while reducing inference time by up to an order of magnitude compared to standard diffusion simulators.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-based learned simulators have emerged as a promising approach forsimulating physical systems on unstructured meshes, offering speed andgeneralization across diverse geometries. However, they often struggle withcapturing global phenomena, such as bending or long-range correlations, andsuffer from error accumulation over long rollouts due to their reliance onlocal message passing and direct next-step prediction. We address theselimitations by introducing the Rolling Diffusion-Batched Inference Network(ROBIN), a novel learned simulator that integrates two key innovations: (i)Rolling Diffusion, a parallelized inference scheme that amortizes the cost ofdiffusion-based refinement across physical time steps by overlapping denoisingsteps across a temporal window. (ii) A Hierarchical Graph Neural Network builton algebraic multigrid coarsening, enabling multiscale message passing acrossdifferent mesh resolutions. This architecture, implemented viaAlgebraic-hierarchical Message Passing Networks, captures both fine-scale localdynamics and global structural effects critical for phenomena like beam bendingor multi-body contact. We validate ROBIN on challenging 2D and 3D solidmechanics benchmarks involving geometric, material, and contact nonlinearities.ROBIN achieves state-of-the-art accuracy on all tasks, substantiallyoutperforming existing next-step learned simulators while reducing inferencetime by up to an order of magnitude compared to standard diffusion simulators.</description>
      <author>example@mail.com (Tobias Würth, Niklas Freymuth, Gerhard Neumann, Luise Kärger)</author>
      <guid isPermaLink="false">2506.06045v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Dream to Generalize: Zero-Shot Model-Based Reinforcement Learning for Unseen Visual Distractions</title>
      <link>http://arxiv.org/abs/2506.05419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AAAI 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Dr. G的新型自监督方法，用于零样本MBRL，以提高模型在视觉干扰下的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;尽管现有的MBRL算法在训练观察中表现良好，但面对观察中的视觉干扰（如云、阴影和光）时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，使模型能够在存在视觉干扰的观察中保持鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;Dr. G使用双重对比学习来训练编码器和世界模型，有效捕捉多视图数据增强中的任务相关特征。此外，还引入了一种当前状态逆动力学模型，帮助世界模型更好地理解时间结构。&lt;h4&gt;主要发现&lt;/h4&gt;Dr. G在简单背景上训练后，在DeepMind Control suite的复杂自然视频背景和Robosuite的随机化环境中测试，性能分别比先前工作提高了117%和14%。&lt;h4&gt;结论&lt;/h4&gt;Dr. G能够提高世界模型对视觉干扰的鲁棒性，并在实际应用中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Model-based reinforcement learning (MBRL) has been used to efficiently solve vision-based control tasks in high-dimensional image observations. Although recent MBRL algorithms perform well in trained observations, they fail when faced with visual distractions in observations. These task-irrelevant distractions (e.g., clouds, shadows, and light) may be constantly present in real-world scenarios. In this study, we propose a novel self-supervised method, Dream to Generalize (Dr. G), for zero-shot MBRL. Dr. G trains its encoder and world model with dual contrastive learning which efficiently captures task-relevant features among multi-view data augmentations. We also introduce a current state inverse dynamics model that helps the world model to better understand the temporal structure. The proposed methods can enhance the robustness of the world model against visual distractions. To evaluate the generalization performance, we first train Dr. G on simple backgrounds and then test it on complex natural video backgrounds in the DeepMind Control suite, and the randomizing environments in Robosuite. Dr. G yields a performance improvement of 117% and 14% over prior works, respectively. Our code is open-sourced and available at https://github.com/JeongsooHa/DrG.git&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model-based reinforcement learning (MBRL) has been used to efficiently solvevision-based control tasks in highdimensional image observations. Althoughrecent MBRL algorithms perform well in trained observations, they fail whenfaced with visual distractions in observations. These task-irrelevantdistractions (e.g., clouds, shadows, and light) may be constantly present inreal-world scenarios. In this study, we propose a novel self-supervised method,Dream to Generalize (Dr. G), for zero-shot MBRL. Dr. G trains its encoder andworld model with dual contrastive learning which efficiently capturestask-relevant features among multi-view data augmentations. We also introduce arecurrent state inverse dynamics model that helps the world model to betterunderstand the temporal structure. The proposed methods can enhance therobustness of the world model against visual distractions. To evaluate thegeneralization performance, we first train Dr. G on simple backgrounds and thentest it on complex natural video backgrounds in the DeepMind Control suite, andthe randomizing environments in Robosuite. Dr. G yields a performanceimprovement of 117% and 14% over prior works, respectively. Our code isopen-sourced and available at https://github.com/JeongsooHa/DrG.git</description>
      <author>example@mail.com (Jeongsoo Ha, Kyungsoo Kim, Yusung Kim)</author>
      <guid isPermaLink="false">2506.05419v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Hi-LSplat: Hierarchical 3D Language Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.06822v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Hi-LSplat的视图一致性的层次语言高斯分层模型，用于3D开放词汇查询，以解决现有3DGS模型中视图不一致性和开放词汇挑战导致的对象和关系描述不一致问题。&lt;h4&gt;背景&lt;/h4&gt;现有的基于3DGS的模型使用视图相关的2D基础模型来细化3D语义，但缺乏统一的3D表示，导致视图不一致。同时，开放词汇挑战导致对象和关系描述的不一致性，阻碍了层次语义理解。&lt;h4&gt;目的&lt;/h4&gt;提出Hi-LSplat模型，以实现视图一致的3D层次语义，并解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;通过构建一个3D层次语义树并使用分层实例聚类将2D特征提升到3D特征，解决由2D语义特征引起的视图不一致问题。此外，引入实例级和部分级的对比损失以捕获全方位的层次语义表示。还构建了两个层次语义数据集以更好地评估模型区分不同语义层级的能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Hi-LSplat在3D开放词汇分割和定位方面具有优越性，其强大的性能在层次语义数据集上突出了其在3D场景中捕捉复杂层次语义的能力。&lt;h4&gt;结论&lt;/h4&gt;Hi-LSplat模型能够有效解决3D开放词汇查询中的视图不一致性和开放词汇挑战，提高了3D语义理解和定位的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling 3D language fields with Gaussian Splatting for open-ended languagequeries has recently garnered increasing attention. However, recent 3DGS-basedmodels leverage view-dependent 2D foundation models to refine 3D semantics butlack a unified 3D representation, leading to view inconsistencies.Additionally, inherent open-vocabulary challenges cause inconsistencies inobject and relational descriptions, impeding hierarchical semanticunderstanding. In this paper, we propose Hi-LSplat, a view-consistentHierarchical Language Gaussian Splatting work for 3D open-vocabulary querying.To achieve view-consistent 3D hierarchical semantics, we first lift 2D featuresto 3D features by constructing a 3D hierarchical semantic tree with layeredinstance clustering, which addresses the view inconsistency issue caused by 2Dsemantic features. Besides, we introduce instance-wise and part-wisecontrastive losses to capture all-sided hierarchical semantic representations.Notably, we construct two hierarchical semantic datasets to better assess themodel's ability to distinguish different semantic levels. Extensive experimentshighlight our method's superiority in 3D open-vocabulary segmentation andlocalization. Its strong performance on hierarchical semantic datasetsunderscores its ability to capture complex hierarchical semantics within 3Dscenes.</description>
      <author>example@mail.com (Chenlu Zhan, Yufei Zhang, Gaoang Wang, Hongwei Wang)</author>
      <guid isPermaLink="false">2506.06822v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>FRAME: Pre-Training Video Feature Representations via Anticipation and Memory</title>
      <link>http://arxiv.org/abs/2506.05543v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为FRAME的视频帧编码器，用于密集视频理解任务，如对象跟踪和语义分割。&lt;h4&gt;背景&lt;/h4&gt;现有的视频编码器在处理密集视频理解任务时存在不足，如缺乏时间感知或性能低于图像编码器。&lt;h4&gt;目的&lt;/h4&gt;提出FRAME以解决现有方法在密集预测任务中的不足，使其能够生成时间一致且空间密集的特征。&lt;h4&gt;方法&lt;/h4&gt;FRAME通过自监督学习，预测当前和未来的DINO补丁特征，从而实现空间精确和时间一致的表现。&lt;h4&gt;主要发现&lt;/h4&gt;FRAME是第一个利用基于图像的模型进行密集预测且在需要精细视觉对应任务上超越它们的视频编码器。&lt;h4&gt;结论&lt;/h4&gt;FRAME在六个密集预测任务上表现优于图像编码器和现有的自监督视频模型，同时保持了紧凑的架构，适用于多种下游应用。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Dense video prediction tasks, such as object tracking and semantic segmentation, require video encoders that generate temporally consistent, spatially dense features for every frame. However, existing approaches fall short: image encoders like DINO or CLIP lack temporal awareness, while video models such as VideoMAE underperform compared to image encoders on dense prediction tasks. We address this gap with FRAME, a self-supervised video frame encoder tailored for dense video understanding. FRAME learns to predict current and future DINO patch features from past and present RGB frames, leading to spatially precise and temporally coherent representations. To our knowledge, FRAME is the first video encoder to leverage image-based models for dense prediction while outperforming them on tasks requiring fine-grained visual correspondence. As an auxiliary capability, FRAME aligns its class token with CLIP's semantic space, supporting language-driven tasks such as video classification. We evaluate FRAME across six dense prediction tasks on seven datasets, where it consistently outperforms image encoders and existing self-supervised video models. Despite its versatility, FRAME maintains a compact architecture suitable for a range of downstream applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dense video prediction tasks, such as object tracking and semanticsegmentation, require video encoders that generate temporally consistent,spatially dense features for every frame. However, existing approaches fallshort: image encoders like DINO or CLIP lack temporal awareness, while videomodels such as VideoMAE underperform compared to image encoders on denseprediction tasks. We address this gap with FRAME, a self-supervised video frameencoder tailored for dense video understanding. FRAME learns to predict currentand future DINO patch features from past and present RGB frames, leading tospatially precise and temporally coherent representations. To our knowledge,FRAME is the first video encoder to leverage image-based models for denseprediction while outperforming them on tasks requiring fine-grained visualcorrespondence. As an auxiliary capability, FRAME aligns its class token withCLIP's semantic space, supporting language-driven tasks such as videoclassification. We evaluate FRAME across six dense prediction tasks on sevendatasets, where it consistently outperforms image encoders and existingself-supervised video models. Despite its versatility, FRAME maintains acompact architecture suitable for a range of downstream applications.</description>
      <author>example@mail.com (Sethuraman TV, Savya Khosla, Vignesh Srinivasakumar, Jiahui Huang, Seoung Wug Oh, Simon Jenni, Derek Hoiem, Joon-Young Lee)</author>
      <guid isPermaLink="false">2506.05543v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>On Measuring Long-Range Interactions in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.05971v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了图神经网络中的长距离图任务问题，提出了一种图操作的范围度量方法，并通过合成实验进行验证。&lt;h4&gt;背景&lt;/h4&gt;长距离图任务，即依赖于远距离节点间交互的任务，是图神经网络研究中的一个开放性问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决长距离图任务问题，论文旨在提出一种更原则性的方法来描述长距离问题。&lt;h4&gt;方法&lt;/h4&gt;论文将长距离交互形式化，引入了图上的操作范围度量，并通过合成实验进行了验证。接着，利用该方法对常用任务和架构进行考察，讨论其长距离能力的实际程度。&lt;h4&gt;主要发现&lt;/h4&gt;论文提出的方法有助于定义和解决图上的长距离问题，并且该范围度量将有助于评估新的数据集和架构。&lt;h4&gt;结论&lt;/h4&gt;论文的研究推进了长距离图任务问题的定义和解决，并为评估新的数据集和架构提供了有价值的工具。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies the long-range graph tasks in graph neural networks, proposes a range measurement method for operators on graphs, and validates it with synthetic experiments. The paper aims to propose a more principled approach to describe the long-range problem. By formalizing long-range interactions in graph tasks, the paper introduces a range measure for operators on graphs and validates it with synthetic experiments. Then, using this measure, the paper examines commonly used tasks and architectures, and discusses the extent to which they are actually long-range. We believe that our work advances efforts to define and address the long-range problem on graphs, and that our range measure will aid the evaluation of new datasets and architectures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-range graph tasks -- those dependent on interactions between distantnodes -- are an open problem in graph neural network research. Real-worldbenchmark tasks, especially the Long Range Graph Benchmark, have become popularfor validating the long-range capability of proposed architectures. However,this is an empirical approach that lacks both robustness and theoreticalunderpinning; a more principled characterization of the long-range problem isrequired. To bridge this gap, we formalize long-range interactions in graphtasks, introduce a range measure for operators on graphs, and validate it withsynthetic experiments. We then leverage our measure to examine commonly usedtasks and architectures, and discuss to what extent they are, in fact,long-range. We believe our work advances efforts to define and address thelong-range problem on graphs, and that our range measure will aid evaluation ofnew datasets and architectures.</description>
      <author>example@mail.com (Jacob Bamberger, Benjamin Gutteridge, Scott le Roux, Michael M. Bronstein, Xiaowen Dong)</author>
      <guid isPermaLink="false">2506.05971v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>StARS DCM: A Sleep Stage-Decoding Forehead EEG Patch for Real-time Modulation of Sleep Physiology</title>
      <link>http://arxiv.org/abs/2506.03442v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;StARS是一个用于实时睡眠监测和干预的模块化软硬件平台。&lt;h4&gt;背景&lt;/h4&gt;睡眠监测和干预技术的研究与应用。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够实时监测和干预睡眠的系统。&lt;h4&gt;方法&lt;/h4&gt;使用DCM生物信号设备和ezmsg实时软件框架同步传感器数据，利用高级神经网络模型和迁移学习进行睡眠阶段解码，支持闭环听觉刺激和动态热调节等干预措施。&lt;h4&gt;主要发现&lt;/h4&gt;StARS可以通过轻量级的脑电图前额贴片或可穿戴设备（如智能戒指）进行配置，提供灵活、低负担的解决方案，同时开源的DCM贴片还允许定制EEG设备开发。&lt;h4&gt;结论&lt;/h4&gt;StARS为脑电图、脑机接口和睡眠增强研究和应用提供了灵活、低负担的解决方案，并促进了EEG设备的定制化开发。&lt;h4&gt;翻译&lt;/h4&gt;The System to Augment Restorative Sleep (StARS) is a modular hardware/software platform designed for real-time sleep monitoring and intervention.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The System to Augment Restorative Sleep (StARS) is a modularhardware/software platform designed for real-time sleep monitoring andintervention. Utilizing the compact DCM biosignal device, StARS captureselectrophysiological signals (EEG, EMG, EOG) and synchronizes sensor data usingthe ezmsg real-time software framework. StARS supports interventions such asclosed-loop auditory stimulation and dynamic thermal modulation guided bysleep-stage decoding via advanced neural network models and transfer learning.Configurable with a lightweight EEG forehead patch or wearable sensors likesmart rings, StARS offers flexible, low-burden solutions for EEG, BCI, andsleep-enhancement research and applications. The open-source DCM patch furtherenables customizable EEG device development.</description>
      <author>example@mail.com (William G. Coon, Preston Peranich, Griffin Milsap)</author>
      <guid isPermaLink="false">2506.03442v2</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Pruning Spurious Subgraphs for Graph Out-of-Distribtuion Generalization</title>
      <link>http://arxiv.org/abs/2506.05957v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submission of ICML2025, with score 4/4/3/3&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于剪枝的图神经网络（GNN）方法PrunE，用于解决训练和测试数据分布偏移下的泛化问题，以改善GNN在现实场景中的应用。&lt;h4&gt;背景&lt;/h4&gt;GNN在训练和测试数据分布偏移的情况下往往会出现性能下降，这限制了其在现实世界中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出PrunE方法，消除虚假边，提高GNN的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;PrunE通过两种正则化项来剪枝虚假边：1）图大小约束排除无信息量的虚假边；2）ε-概率对齐进一步抑制虚假边的出现。&lt;h4&gt;主要发现&lt;/h4&gt;PrunE在理论上分析和大量实验中均显示出比之前最先进方法更优越的泛化性能。&lt;h4&gt;结论&lt;/h4&gt;PrunE通过剪枝虚假边，更全面地保留了不变子图，这对于提高GNN的泛化能力至关重要。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图神经网络（GNNs）在训练和测试数据分布偏移的情况下往往遇到显著的性能下降，这阻碍了它们在现实场景中的应用。最近的研究提出了各种方法来解决分布外泛化挑战，其中许多方法在图领域集中于直接识别一个预测目标标签的不变子图。然而，我们认为直接识别不变子图中的边是具有挑战性和易出错的，特别是在某些虚假边与目标有强相关性时。在本文中，我们提出了PrunE，这是第一个基于剪枝的图OOD方法，旨在消除虚假边以提高OOD泛化能力。通过剪枝虚假边，mine{}更全面地保留了不变子图，这对于OOD泛化至关重要。具体来说，PrunE采用两种正则化项来剪枝虚假边：1）图大小约束排除无信息量的虚假边，2）ε-概率对齐进一步抑制虚假边的出现。通过理论分析和大量实验，我们表明PrunE实现了优于OOD的性能，并且显著优于以前的最先进方法。代码可在https://github.com/tianyao-aka/PrunE-GraphOOD上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) often encounter significant performancedegradation under distribution shifts between training and test data, hinderingtheir applicability in real-world scenarios. Recent studies have proposedvarious methods to address the out-of-distribution generalization challenge,with many methods in the graph domain focusing on directly identifying aninvariant subgraph that is predictive of the target label. However, we arguethat identifying the edges from the invariant subgraph directly is challengingand error-prone, especially when some spurious edges exhibit strongcorrelations with the targets. In this paper, we propose PrunE, the firstpruning-based graph OOD method that eliminates spurious edges to improve OODgeneralizability. By pruning spurious edges, \mine{} retains the invariantsubgraph more comprehensively, which is critical for OOD generalization.Specifically, PrunE employs two regularization terms to prune spurious edges:1) graph size constraint to exclude uninformative spurious edges, and 2)$\epsilon$-probability alignment to further suppress the occurrence of spuriousedges. Through theoretical analysis and extensive experiments, we show thatPrunE achieves superior OOD performance and outperforms previousstate-of-the-art methods significantly. Codes are available at:\href{https://github.com/tianyao-aka/PrunE-GraphOOD}{https://github.com/tianyao-aka/PrunE-GraphOOD}.</description>
      <author>example@mail.com (Tianjun Yao, Haoxuan Li, Yongqiang Chen, Tongliang Liu, Le Song, Eric Xing, Zhiqiang Shen)</author>
      <guid isPermaLink="false">2506.05957v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Research on Personalized Financial Product Recommendation by Integrating Large Language Models and Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.05873v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合大型语言模型（LLM）和图神经网络（GNN）的混合框架，用于个性化金融产品推荐。&lt;h4&gt;背景&lt;/h4&gt;随着金融科技（fintech）的快速发展，个性化金融产品推荐变得越来越重要。传统的协同过滤或基于内容的模型往往无法捕捉用户的潜在偏好和复杂关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的混合框架，以改进个性化金融产品推荐的准确性。&lt;h4&gt;方法&lt;/h4&gt;该框架使用预训练的LLM将文本数据（如用户评论）编码为丰富的特征向量，同时使用异构用户-产品图来建模交互和社会联系。通过定制的信息传递机制，在GNN中融合文本和图信息，共同优化嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;在公共和真实世界金融数据集上的实验表明，该模型在准确度、召回率和NDCG方面优于单独的LLM或GNN，并且具有强的可解释性。&lt;h4&gt;结论&lt;/h4&gt;该研究为个性化金融推荐和更广泛的推荐任务中的跨模态融合提供了新的见解。&lt;h4&gt;翻译&lt;/h4&gt;With the rapid growth of fintech, personalized financial product recommendations have become increasingly important. Traditional methods like collaborative filtering or content-based models often fail to capture users' latent preferences and complex relationships. We propose a hybrid framework integrating large language models (LLMs) and graph neural networks (GNNs). A pre-trained LLM encodes text data (e.g., user reviews) into rich feature vectors, while a heterogeneous user-product graph models interactions and social ties. Through a tailored message-passing mechanism, text and graph information are fused within the GNN to jointly optimize embeddings. Experiments on public and real-world financial datasets show our model outperforms standalone LLM or GNN in accuracy, recall, and NDCG, with strong interpretability. This work offers new insights for personalized financial recommendations and cross-modal fusion in broader recommendation tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid growth of fintech, personalized financial productrecommendations have become increasingly important. Traditional methods likecollaborative filtering or content-based models often fail to capture users'latent preferences and complex relationships. We propose a hybrid frameworkintegrating large language models (LLMs) and graph neural networks (GNNs). Apre-trained LLM encodes text data (e.g., user reviews) into rich featurevectors, while a heterogeneous user-product graph models interactions andsocial ties. Through a tailored message-passing mechanism, text and graphinformation are fused within the GNN to jointly optimize embeddings.Experiments on public and real-world financial datasets show our modeloutperforms standalone LLM or GNN in accuracy, recall, and NDCG, with stronginterpretability. This work offers new insights for personalized financialrecommendations and cross-modal fusion in broader recommendation tasks.</description>
      <author>example@mail.com (Yushang Zhao, Yike Peng, Dannier Li, Yuxin Yang, Chengrui Zhou, Jing Dong)</author>
      <guid isPermaLink="false">2506.05873v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>CR-BLEA: Contrastive Ranking for Adaptive Resource Allocation in Bilevel Evolutionary Algorithms</title>
      <link>http://arxiv.org/abs/2506.06362v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对 bilevel EAs 的新型资源分配框架，旨在提高其效率。&lt;h4&gt;背景&lt;/h4&gt;Bilevel optimization 具有嵌套结构，每个上层候选解都需要解决对应的下层问题，这对计算资源提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;减少资源浪费，提高 bilevel EAs 的效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种对比排名网络，用于在线学习上下层解之间的关系，并据此引导基于引用的排名策略，优先优化任务并自适应控制重采样。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该框架显著降低了计算成本，同时保持了甚至提高了解的准确性。&lt;h4&gt;结论&lt;/h4&gt;该框架为提高 bilevel EAs 的效率提供了一种通用的策略，为更可扩展的 bilevel optimization 开辟了道路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于 bilevel optimization 具有嵌套结构，每个上层候选解都需要解决对应的下层问题，这给计算资源带来了重大挑战。虽然进化算法（EAs）在导航这种复杂景观方面很有效，但它们的高资源需求仍然是一个关键瓶颈——尤其是大量无望的下层任务的冗余评估。尽管在多任务学习和迁移学习方面取得了进展，但资源浪费仍然存在。为了解决这个问题，我们提出了一种新的资源分配框架，用于 bilevel EAs，该框架可以选性地识别和专注于有希望的下层任务。我们的方法的核心是一个对比排名网络，该网络在线学习成对的上层和下层解之间的关系。这种知识指导了基于引用的排名策略，该策略优先优化任务，并根据估计的种群质量自适应控制重采样。在五个最先进的 bilevel 算法上的综合实验表明，我们的框架显著降低了计算成本，同时保持了——甚至提高了——解的准确性。这项工作提供了一种通用的策略来提高 bilevel EAs 的效率，为更可扩展的 bilevel optimization 打开了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bilevel optimization poses a significant computational challenge due to itsnested structure, where each upper-level candidate solution requires solving acorresponding lower-level problem. While evolutionary algorithms (EAs) areeffective at navigating such complex landscapes, their high resource demandsremain a key bottleneck -- particularly the redundant evaluation of numerousunpromising lower-level tasks. Despite recent advances in multitasking andtransfer learning, resource waste persists. To address this issue, we propose anovel resource allocation framework for bilevel EAs that selectively identifiesand focuses on promising lower-level tasks. Central to our approach is acontrastive ranking network that learns relational patterns between pairedupper- and lower-level solutions online. This knowledge guides areference-based ranking strategy that prioritizes tasks for optimization andadaptively controls resampling based on estimated population quality.Comprehensive experiments across five state-of-the-art bilevel algorithms showthat our framework significantly reduces computational cost while preserving --or even enhancing -- solution accuracy. This work offers a generalizablestrategy to improve the efficiency of bilevel EAs, paving the way for morescalable bilevel optimization.</description>
      <author>example@mail.com (Dejun Xu, Jijia Chen, Gary G. Yen, Min Jiang)</author>
      <guid isPermaLink="false">2506.06362v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models via Generative Continual Learning</title>
      <link>http://arxiv.org/abs/2506.06694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MoveGCL的框架，用于训练移动性基础模型，旨在解决移动数据隐私问题和数据孤岛问题。&lt;h4&gt;背景&lt;/h4&gt;移动数据具有隐私敏感性，导致不同机构之间存在数据孤岛，这使得构建类似自然语言处理和计算机视觉领域的通用移动模型具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;开发一个可扩展且保护隐私的框架，通过生成式持续学习训练移动性基础模型。&lt;h4&gt;方法&lt;/h4&gt;MoveGCL通过重新播放从冻结的教师模型生成的合成轨迹，实现去中心化和渐进式模型演变，并通过定制蒸馏策略来减少灾难性遗忘，从而增强知识保留。此外，它还采用了混合专家Transformer和移动感知专家路由机制，以及分层渐进式适应策略来稳定持续更新。&lt;h4&gt;主要发现&lt;/h4&gt;在六个真实世界城市数据集上的实验表明，MoveGCL的性能与联合训练相当，并且显著优于联邦学习基线，同时提供了强大的隐私保护。&lt;h4&gt;结论&lt;/h4&gt;MoveGCL是解锁移动性基础模型的关键步骤，为开放、可扩展且保护隐私的模型开发提供了一个实际蓝图。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为MoveGCL的框架，用于训练移动性基础模型，旨在解决移动数据隐私问题和数据孤岛问题。该框架通过生成式持续学习，实现了去中心化和渐进式模型演变，并通过定制蒸馏策略来减少灾难性遗忘，同时采用了混合专家Transformer和移动感知专家路由机制，以及分层渐进式适应策略来稳定持续更新。在六个真实世界城市数据集上的实验表明，MoveGCL的性能与联合训练相当，并且显著优于联邦学习基线，同时提供了强大的隐私保护。MoveGCL是解锁移动性基础模型的关键步骤，为开放、可扩展且保护隐私的模型开发提供了一个实际蓝图。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have revolutionized fields such as natural languageprocessing and computer vision by enabling general-purpose learning acrossdiverse tasks and datasets. However, building analogous models for humanmobility remains challenging due to the privacy-sensitive nature of mobilitydata and the resulting data silos across institutions. To bridge this gap, wepropose MoveGCL, a scalable and privacy-preserving framework for trainingmobility foundation models via generative continual learning. Without sharingraw data, MoveGCL enables decentralized and progressive model evolution byreplaying synthetic trajectories generated from a frozen teacher model, andreinforces knowledge retention through a tailored distillation strategy thatmitigates catastrophic forgetting. To address the heterogeneity of mobilitypatterns, MoveGCL incorporates a Mixture-of-Experts Transformer with amobility-aware expert routing mechanism, and employs a layer-wise progressiveadaptation strategy to stabilize continual updates. Experiments on sixreal-world urban datasets demonstrate that MoveGCL achieves performancecomparable to joint training and significantly outperforms federated learningbaselines, while offering strong privacy protection. MoveGCL marks a crucialstep toward unlocking foundation models for mobility, offering a practicalblueprint for open, scalable, and privacy-preserving model development in theera of foundation models.</description>
      <author>example@mail.com (Yuan Yuan, Yukun Liu, Chonghua Han, Jie Feng, Yong Li)</author>
      <guid isPermaLink="false">2506.06694v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Transferable Sequential Recommendation with Vanilla Cross-Entropy Loss</title>
      <link>http://arxiv.org/abs/2506.02916v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MMM4Rec的多模态序列推荐框架，用于提高多模态推荐系统的准确性和可迁移性。&lt;h4&gt;背景&lt;/h4&gt;序列推荐系统通过分析用户交互历史来建模用户偏好。尽管多模态序列推荐架构的性能优于传统的基于ID的方法，但现有方法在适应新领域时需要大量微调，导致负迁移效应，成为部署瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多模态序列推荐框架，以降低微调成本并提高推荐准确性。&lt;h4&gt;方法&lt;/h4&gt;MMM4Rec框架结合了状态空间对偶（SSD）的时间衰减特性和时间感知建模设计，动态优先考虑关键模态信息。框架通过共享投影矩阵进行序列级别的跨模态对齐，并使用新设计的交叉SSD模块和双通道傅里叶自适应滤波进行时间融合。&lt;h4&gt;主要发现&lt;/h4&gt;MMM4Rec实现了快速的微调收敛，通过简单的交叉熵损失，显著提高了多模态推荐的准确性，同时保持了强的可迁移性。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的实验，MMM4Rec展现出最先进的性能，相较于现有模型在NDCG@10上提高了31.78%，在迁移到大规模下游数据集时平均收敛速度提高了10倍。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes a novel multi-modal sequential recommendation framework named MMM4Rec to improve the accuracy and transferability of multi-modal recommendation systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential Recommendation (SR) systems model user preferences by analyzinginteraction histories. Although transferable multi-modal SR architecturesdemonstrate superior performance compared to traditional ID-based approaches,current methods incur substantial fine-tuning costs when adapting to newdomains due to complex optimization requirements and negative transfer effects- a significant deployment bottleneck that hinders engineers from efficientlyrepurposing pre-trained models for novel application scenarios with minimaltuning overhead. We propose MMM4Rec (Multi-Modal Mamba for SequentialRecommendation), a novel multi-modal SR framework that incorporates a dedicatedalgebraic constraint mechanism for efficient transfer learning. By combiningState Space Duality (SSD)'s temporal decay properties with a time-awaremodeling design, our model dynamically prioritizes key modality information,overcoming limitations of Transformer-based approaches. The frameworkimplements a constrained two-stage process: (1) sequence-level cross-modalalignment via shared projection matrices, followed by (2) temporal fusion usingour newly designed Cross-SSD module and dual-channel Fourier adaptivefiltering. This architecture maintains semantic consistency while suppressingnoise propagation.MMM4Rec achieves rapid fine-tuning convergence with simplecross-entropy loss, significantly improving multi-modal recommendation accuracywhile maintaining strong transferability. Extensive experiments demonstrateMMM4Rec's state-of-the-art performance, achieving the maximum 31.78% NDCG@10improvement over existing models and exhibiting 10 times faster averageconvergence speed when transferring to large-scale downstream datasets.</description>
      <author>example@mail.com (Hao Fan, Yanrong Hu, Kai Fang, Qingyang Liu, Hongjiu Liu)</author>
      <guid isPermaLink="false">2506.02916v3</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Structured Pruning for Diverse Best-of-N Reasoning Optimization</title>
      <link>http://arxiv.org/abs/2506.03978v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACL Findings 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;模型剪枝在基于transformer的语言模型中，不仅可以实现计算节省，还能增强模型的推理能力。&lt;h4&gt;背景&lt;/h4&gt;模型剪枝传统上被视为一种实现计算节省的手段。&lt;h4&gt;目的&lt;/h4&gt;研究模型剪枝对推理性能的影响，并提出新的对比学习框架。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为SPRINT的新框架，该框架在推理过程中动态选择最优的头和层进行剪枝，并通过对齐问题嵌入和头嵌入来识别剪枝头配置，从而提高推理的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;对某些注意力头的选择性剪枝可以提高推理性能，尤其是在具有挑战性的任务上。&lt;h4&gt;结论&lt;/h4&gt;在MATH500和GSM8K数据集上的实验表明，该方法在推理性能上显著优于传统的best-of-N和随机头选择策略。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we uncover a surprising phenomenon: the selective pruning of certain attention heads leads to improvements in reasoning performance, particularly on challenging tasks. Motivated by this observation, we propose SPRINT, a novel contrastive learning framework that dynamically selects the optimal head and layer to prune during inference. By aligning question embeddings with head embeddings, SPRINT identifies those pruned-head configurations that result in more accurate reasoning. Extensive experiments demonstrate that our method significantly outperforms traditional best-of-$N$ and random head selection strategies on the MATH500 and GSM8K datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model pruning in transformer-based language models, traditionally viewed as ameans of achieving computational savings, can enhance the model's reasoningcapabilities. In this work, we uncover a surprising phenomenon: the selectivepruning of certain attention heads leads to improvements in reasoningperformance, particularly on challenging tasks. Motivated by this observation,we propose SPRINT, a novel contrastive learning framework that dynamicallyselects the optimal head and layer to prune during inference. By aligningquestion embeddings with head embeddings, SPRINT identifies those pruned-headconfigurations that result in more accurate reasoning. Extensive experimentsdemonstrate that our method significantly outperforms traditional best-of-$N$and random head selection strategies on the MATH500 and GSM8K datasets.</description>
      <author>example@mail.com (Hieu Trung Nguyen, Bao Nguyen, Viet Anh Nguyen)</author>
      <guid isPermaLink="false">2506.03978v2</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Models are Good Relational Learners</title>
      <link>http://arxiv.org/abs/2506.05725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Rel-LLM的新架构，用于将大型语言模型（LLMs）应用于关系深度学习（RDL），通过保留数据库中的关系结构来提高LLMs处理和推理复杂实体关系的能力。&lt;h4&gt;背景&lt;/h4&gt;虽然大型语言模型在多个领域表现出色，但它们在关系深度学习领域的应用尚未得到充分探索。现有的方法通过遍历数据库中实体之间的关系，将结构化数据转换为文本文档，但这种基于文本的序列化方法忽略了关键的关系结构，引入了冗余，并且往往超过了标准LLM的上下文长度。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够有效利用LLMs处理结构化数据的方法，同时保留数据库中的关系结构。&lt;h4&gt;方法&lt;/h4&gt;Rel-LLM利用基于图神经网络（GNN）的编码器在检索增强生成（RAG）框架内为LLMs生成结构化关系提示。GNN编码器提取实体周围的局部子图，构建包含相关实体关系和时间依赖性的特征表示。这些表示通过去规范化过程转换为结构化提示，使LLM能够推理关系结构。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量实验，Rel-LLM在关键RDL任务上优于现有方法，提供了一种可扩展且高效的方法来将LLMs与结构化数据源集成。&lt;h4&gt;结论&lt;/h4&gt;Rel-LLM是一种有效的方法，可以整合LLMs和结构化数据源，同时保留数据库中的关系结构，为关系深度学习提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;Large language models (LLMs) have demonstrated remarkable capabilities across various domains, yet their application to relational deep learning (RDL) remains underexplored. Existing approaches adapt LLMs by traversing relational links between entities in a database and converting the structured data into flat text documents. Still, this text-based serialization disregards critical relational structures, introduces redundancy, and often exceeds standard LLM context lengths. We introduce Rel-LLM, a novel architecture that utilizes a graph neural network (GNN)-based encoder to generate structured relational prompts for LLMs within a retrieval-augmented generation (RAG) framework. Unlike traditional text-based serialization approaches, our method preserves the inherent relational structure of databases while enabling LLMs to effectively process and reason over complex entity relationships. Specifically, the GNN encoder extracts a local subgraph around an entity to build feature representations that contain relevant entity relationships and temporal dependencies. These representations are transformed into structured prompts using a denormalization process, effectively allowing the LLM to reason over relational structures. Through extensive experiments, we demonstrate that Rel-LLM outperforms existing methods on key RDL tasks, offering a scalable and efficient approach to integrating LLMs with structured data sources. Code is available at https://github.com/smiles724/Rel-LLM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have demonstrated remarkable capabilities acrossvarious domains, yet their application to relational deep learning (RDL)remains underexplored. Existing approaches adapt LLMs by traversing relationallinks between entities in a database and converting the structured data intoflat text documents. Still, this text-based serialization disregards criticalrelational structures, introduces redundancy, and often exceeds standard LLMcontext lengths. We introduce Rel-LLM, a novel architecture that utilizes agraph neural network (GNN)- based encoder to generate structured relationalprompts for LLMs within a retrieval-augmented generation (RAG) framework.Unlike traditional text-based serialization approaches, our method preservesthe inherent relational structure of databases while enabling LLMs toeffectively process and reason over complex entity relationships. Specifically,the GNN encoder extracts a local subgraph around an entity to build featurerepresentations that contain relevant entity relationships and temporaldependencies. These representations are transformed into structured promptsusing a denormalization process, effectively allowing the LLM to reason overrelational structures. Through extensive experiments, we demonstrate thatRel-LLM outperforms existing methods on key RDL tasks, offering a scalable andefficient approach to integrating LLMs with structured data sources. Code isavailable at https://github.com/smiles724/Rel-LLM.</description>
      <author>example@mail.com (Fang Wu, Vijay Prakash Dwivedi, Jure Leskovec)</author>
      <guid isPermaLink="false">2506.05725v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Topology-aware Neural Flux Prediction Guided by Physics</title>
      <link>http://arxiv.org/abs/2506.05676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于提高图神经网络（GNNs）在处理有向图时对节点信号中高频成分的保留能力。&lt;h4&gt;背景&lt;/h4&gt;GNNs在处理有向图时往往难以保留节点信号中的高频成分，这些成分对于建模流动动态至关重要。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够敏感地捕捉到高频成分的GNN，以捕获详细的拓扑差异。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了1）显式的差异矩阵，用于建模方向梯度，以及2）隐式的物理约束，以确保GNN中的消息传递与自然定律一致。&lt;h4&gt;主要发现&lt;/h4&gt;在两个真实世界有向图数据（水通量网络和城市交通流量网络）上的评估表明，该提议是有效的。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够提高GNN对高频成分的敏感性，从而在建模流动动态方面具有潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) often struggle in preserving high-frequencycomponents of nodal signals when dealing with directed graphs. Such componentsare crucial for modeling flow dynamics, without which a traditional GNN tendsto treat a graph with forward and reverse topologies equal.To make GNNssensitive to those high-frequency components thereby being capable to capturedetailed topological differences, this paper proposes a novel framework thatcombines 1) explicit difference matrices that model directional gradients and2) implicit physical constraints that enforce messages passing within GNNs tobe consistent with natural laws. Evaluations on two real-world directed graphdata, namely, water flux network and urban traffic flow network, demonstratethe effectiveness of our proposal.</description>
      <author>example@mail.com (Haoyang Jiang, Jindong Wang, Xingquan Zhu, Yi He)</author>
      <guid isPermaLink="false">2506.05676v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Sequel-Aware Graph Neural Networks for Sequential Learning</title>
      <link>http://arxiv.org/abs/2506.05625v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于图的方法在推荐系统中的应用，特别是结合时间序列信息，通过实验验证了包含时间序列信息的推荐方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;推荐系统使用用户和物品的高阶嵌入来进行预测，并动态地从邻居中添加协作信号。尽管已经研究了物品间的相关性及其对推荐的影响，但时间序列物品序列在推荐中的有效性研究较少。&lt;h4&gt;目的&lt;/h4&gt;研究时间序列物品序列（继任信息）嵌入结合高阶用户嵌入的效果，并比较其与不考虑继任信息的图推荐系统的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Heterogeneous Sequel-aware Graph Neural Networks（HSAL-GNNs）的方法，并在三个合成数据和三个真实世界数据集上与transformers、图神经网络、自动编码器等算法进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，引入物品序列的序列信息显著提高了推荐的性能。&lt;h4&gt;结论&lt;/h4&gt;时间序列物品序列在推荐系统中具有重要作用，HSAL-GNNs在推荐性能上优于或与不考虑继任信息的图推荐系统相当。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-based recommendation systems use higher-order user and item embeddingsfor next-item predictions. Dynamically adding collaborative signals fromneighbors helps to use similar users' preferences during learning. Whileitem-item correlations and their impact on recommendations have been studied,the efficacy of temporal item sequences for recommendations is much lessexplored. In this paper, we examine temporal item sequence (sequel-aware)embeddings along with higher-order user embeddings and show that sequel-awareGraph Neural Networks have better (or comparable) recommendation performancethan graph-based recommendation systems that do not consider sequelinformation. Extensive empirical results comparing Heterogeneous Sequel-awareGraph Neural Networks (HSAL-GNNs) to other algorithms for sequential learning(such as transformers, graph neural networks, auto-encoders) are presented onthree synthetic and three real-world datasets. Our results indicate that theincorporation of sequence information from items greatly enhancesrecommendations.</description>
      <author>example@mail.com (Anushka Tiwari, Haimonti Dutta, Shahrzad Khanizadeh)</author>
      <guid isPermaLink="false">2506.05625v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Spectral Graph Neural Networks are Incomplete on Graphs with a Simple Spectrum</title>
      <link>http://arxiv.org/abs/2506.05530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages main text&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了如何通过引入光谱特征来增强图神经网络（GNNs）的表达能力，并提出了一种新的方法来提高GNNs在简单光谱图上的表达能力。&lt;h4&gt;背景&lt;/h4&gt;光谱特征被广泛应用于GNNs中以提高其区分非同构图的能力，例如在MPNNs和Graph Transformers中使用图拉普拉斯算子的特征向量进行位置编码。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过引入一个新的表达性层次来评估SGNNs的表达能力，并改进SGNNs在简单光谱图上的表达能力。&lt;h4&gt;方法&lt;/h4&gt;本文采用了一种分类图的方法，通过图的最大特征值多重性来引入SGNNs的表达性层次。此外，本文将旋转等变神经网络应用于图谱设置，提出了一种方法来提高SGNNs的表达能力。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，许多SGNNs在具有不同特征值的图上都是不完整的。通过实验验证了理论上的改进方法，并在MNIST Superpixel数据集上的图像分类实验和ZINC图上的特征向量规范实验中进行了实证验证。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地提高SGNNs在简单光谱图上的表达能力，为GNNs的进一步研究提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spectral features are widely incorporated within Graph Neural Networks (GNNs)to improve their expressive power, or their ability to distinguish amongnon-isomorphic graphs. One popular example is the usage of graph Laplacianeigenvectors for positional encoding in MPNNs and Graph Transformers. Theexpressive power of such Spectrally-enhanced GNNs (SGNNs) is usually evaluatedvia the k-WL graph isomorphism test hierarchy and homomorphism counting. Yet,these frameworks align poorly with the graph spectra, yielding limited insightinto SGNNs' expressive power. We leverage a well-studied paradigm ofclassifying graphs by their largest eigenvalue multiplicity to introduce anexpressivity hierarchy for SGNNs. We then prove that many SGNNs are incompleteeven on graphs with distinct eigenvalues. To mitigate this deficiency, we adaptrotation equivariant neural networks to the graph spectra setting to propose amethod to provably improve SGNNs' expressivity on simple spectrum graphs. Weempirically verify our theoretical claims via an image classificationexperiment on the MNIST Superpixel dataset and eigenvector canonicalization ongraphs from ZINC.</description>
      <author>example@mail.com (Snir Hordan, Maya Bechler-Speicher, Gur Lifshitz, Nadav Dym)</author>
      <guid isPermaLink="false">2506.05530v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Attention-based transformer models for image captioning across languages: An in-depth survey and evaluation</title>
      <link>http://arxiv.org/abs/2506.05399v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 15 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基于注意力的图像字幕生成模型，涵盖了不同语言，并分析了其挑战和局限性。&lt;h4&gt;背景&lt;/h4&gt;图像字幕生成是连接计算机视觉和自然语言处理的一个领域，近年来基于transformer的模型在字幕生成方面取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;全面分析基于注意力的图像字幕生成模型，并探讨其在多语言环境下的应用。&lt;h4&gt;方法&lt;/h4&gt;对基于注意力的图像字幕生成模型进行分类，并探讨基准数据集、评估指标如BLEU、METEOR、CIDEr和ROUGE，以及多语言字幕生成的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;识别出当前模型的关键局限性，包括语义不一致、非英语语言数据稀缺和推理能力限制。&lt;h4&gt;结论&lt;/h4&gt;提出了未来研究方向，如多模态学习、在AI助手、医疗和法医分析中的实时应用。&lt;h4&gt;翻译&lt;/h4&gt;本文综述了基于注意力的图像字幕生成模型，涵盖了不同语言，并分析了其挑战和局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.cosrev.2025.100766&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image captioning involves generating textual descriptions from input images,bridging the gap between computer vision and natural language processing.Recent advancements in transformer-based models have significantly improvedcaption generation by leveraging attention mechanisms for better sceneunderstanding. While various surveys have explored deep learning-basedapproaches for image captioning, few have comprehensively analyzedattention-based transformer models across multiple languages. This surveyreviews attention-based image captioning models, categorizing them intotransformer-based, deep learning-based, and hybrid approaches. It exploresbenchmark datasets, discusses evaluation metrics such as BLEU, METEOR, CIDEr,and ROUGE, and highlights challenges in multilingual captioning. Additionally,this paper identifies key limitations in current models, including semanticinconsistencies, data scarcity in non-English languages, and limitations inreasoning ability. Finally, we outline future research directions, such asmultimodal learning, real-time applications in AI-powered assistants,healthcare, and forensic analysis. This survey serves as a comprehensivereference for researchers aiming to advance the field of attention-based imagecaptioning.</description>
      <author>example@mail.com (Israa A. Albadarneh, Bassam H. Hammo, Omar S. Al-Kadi)</author>
      <guid isPermaLink="false">2506.05399v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Feature-Based Lie Group Transformer for Real-World Applications</title>
      <link>http://arxiv.org/abs/2506.04668v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, the dataset used in this work is  https://drive.google.com/file/d/1RaSWNN2GEyV3zQPeGya4Mr9DDhJ7OMz7/view?usp=sharing&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文主要讨论了表示学习在获取有意义的表示方面的目标，并提出了改进方法以应用于更现实的场景。&lt;h4&gt;背景&lt;/h4&gt;表示学习旨在从无监督的真实世界感官输入中获取有意义的表示，并解释了人类发展的某些方面。&lt;h4&gt;目的&lt;/h4&gt;研究提出了一种新的方法，用于对成对感官输入之间的变化进行分类，并学习满足代数结构约束的转换。&lt;h4&gt;方法&lt;/h4&gt;该方法使用了伽罗瓦代数理论中的群分解，以克服传统表示学习中独立特征轴的假设，并提出了结合特征提取和对象分割的新方法。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，传统的表示学习无法解释条件独立性，且新方法在处理低分辨率图像时存在局限性。&lt;h4&gt;结论&lt;/h4&gt;通过将群分解理论应用于更现实的场景，结合特征提取和对象分割，模型有望更好地理解人类在现实世界中对象识别的发展。&lt;h4&gt;翻译&lt;/h4&gt;The main goal of representation learning is to acquire meaningful representations from real-world sensory inputs without supervision. Representation learning explains some aspects of human development. Various neural network (NN) models have been proposed that acquire empirically good representations. However, the formulation of a good representation has not been established. We recently proposed a method for categorizing changes between a pair of sensory inputs. A unique feature of this approach is that transformations between two sensory inputs are learned to satisfy algebraic structural constraints. Conventional representation learning often assumes that disentangled independent feature axes is a good representation; however, we found that such a representation cannot account for conditional independence. To overcome this problem, we proposed a new method using group decomposition in Galois algebra theory. Although this method is promising for defining a more general representation, it assumes pixel-to-pixel translation without feature extraction, and can only process low-resolution images with no background, which prevents real-world application. In this study, we provide a simple method to apply our group decomposition theory to a more realistic scenario by combining feature extraction and object segmentation. We replace pixel translation with feature translation and formulate object segmentation as grouping features under the same transformation. We validated the proposed method on a practical dataset containing both real-world object and background. We believe that our model will lead to a better understanding of human development of object recognition in the real world.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The main goal of representation learning is to acquire meaningfulrepresentations from real-world sensory inputs without supervision.Representation learning explains some aspects of human development. Variousneural network (NN) models have been proposed that acquire empirically goodrepresentations. However, the formulation of a good representation has not beenestablished. We recently proposed a method for categorizing changes between apair of sensory inputs. A unique feature of this approach is thattransformations between two sensory inputs are learned to satisfy algebraicstructural constraints. Conventional representation learning often assumes thatdisentangled independent feature axes is a good representation; however, wefound that such a representation cannot account for conditional independence.To overcome this problem, we proposed a new method using group decomposition inGalois algebra theory. Although this method is promising for defining a moregeneral representation, it assumes pixel-to-pixel translation without featureextraction, and can only process low-resolution images with no background,which prevents real-world application. In this study, we provide a simplemethod to apply our group decomposition theory to a more realistic scenario bycombining feature extraction and object segmentation. We replace pixeltranslation with feature translation and formulate object segmentation asgrouping features under the same transformation. We validated the proposedmethod on a practical dataset containing both real-world object and background.We believe that our model will lead to a better understanding of humandevelopment of object recognition in the real world.</description>
      <author>example@mail.com (Takayuki Komatsu, Yoshiyuki Ohmura, Kayato Nishitsunoi, Yasuo Kuniyoshi)</author>
      <guid isPermaLink="false">2506.04668v3</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>Towards Foundation Model on Temporal Knowledge Graph Reasoning</title>
      <link>http://arxiv.org/abs/2506.06367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种全新的全归纳式时间知识图谱链接预测方法，通过使用正弦位置编码捕捉细粒度时间模式，并利用基于局部和全局时间上下文的消息传递生成自适应实体和关系表示，从而实现模型的无差别时间粒度和时间跨度处理，提高了模型在未见过的知识图谱上的零样本性能。&lt;h4&gt;背景&lt;/h4&gt;现有的时间知识图谱嵌入（TKGE）模型在归纳或半归纳设置中进行链接预测任务，这限制了模型在新领域迁移和泛化到真实世界场景的能力。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有模型在迁移性和泛化能力上的限制，提出了一种全新的全归纳式时间知识图谱链接预测方法。&lt;h4&gt;方法&lt;/h4&gt;模型使用正弦位置编码捕捉细粒度时间模式，并利用消息传递生成自适应实体和关系表示，同时考虑局部和全局时间上下文。&lt;h4&gt;主要发现&lt;/h4&gt;POSTRA模型在未见过的知识图谱上展现出强大的零样本性能，有效推广到新实体、关系和时间戳。&lt;h4&gt;结论&lt;/h4&gt;POSTRA模型为时间知识图谱的基础模型迈出了重要一步，通过单次预训练即可在各种归纳时间推理场景中提高零样本性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel fully-inductive approach for temporal knowledge graph link prediction. The model employs sinusoidal positional encodings to capture fine-grained temporal patterns and generates adaptive entity and relation representations using message passing conditioned on both local and global temporal contexts. The model design is agnostic to temporal granularity and time span, effectively addressing temporal discrepancies across TKGs and facilitating time-aware structural information transfer. As a pretrained, scalable, and transferable model, POSTRA demonstrates strong zero-shot performance on unseen temporal knowledge graphs, effectively generalizing to novel entities, relations, and timestamps. Extensive theoretical analysis and empirical results show that a single pretrained model can improve zero-shot performance on various inductive temporal reasoning scenarios, marking a significant step toward a foundation model for temporal KGs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal Knowledge Graphs (TKGs) store temporal facts with quadruple formats(s, p, o, t). Existing Temporal Knowledge Graph Embedding (TKGE) models performlink prediction tasks in transductive or semi-inductive settings, which meansthe entities, relations, and temporal information in the test graph are fullyor partially observed during training. Such reliance on seen elements duringinference limits the models' ability to transfer to new domains and generalizeto real-world scenarios. A central limitation is the difficulty in learningrepresentations for entities, relations, and timestamps that are transferableand not tied to dataset-specific vocabularies. To overcome these limitations,we introduce the first fully-inductive approach to temporal knowledge graphlink prediction. Our model employs sinusoidal positional encodings to capturefine-grained temporal patterns and generates adaptive entity and relationrepresentations using message passing conditioned on both local and globaltemporal contexts. Our model design is agnostic to temporal granularity andtime span, effectively addressing temporal discrepancies across TKGs andfacilitating time-aware structural information transfer. As a pretrained,scalable, and transferable model, POSTRA demonstrates strong zero-shotperformance on unseen temporal knowledge graphs, effectively generalizing tonovel entities, relations, and timestamps. Extensive theoretical analysis andempirical results show that a single pretrained model can improve zero-shotperformance on various inductive temporal reasoning scenarios, marking asignificant step toward a foundation model for temporal KGs.</description>
      <author>example@mail.com (Jiaxin Pan, Mojtaba Nayyeri, Osama Mohammed, Daniel Hernandez, Rongchuan Zhang, Cheng Cheng, Steffen Staab)</author>
      <guid isPermaLink="false">2506.06367v1</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>RoPETR: Improving Temporal Camera-Only 3D Detection by Integrating Enhanced Rotary Position Embedding</title>
      <link>http://arxiv.org/abs/2504.12643v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文报告介绍了StreamPETR框架的针对性改进，旨在提高速度估计能力，这对于影响NuScenes检测分数的整体性能是一个关键因素。&lt;h4&gt;背景&lt;/h4&gt;StreamPETR在3D边界框检测方面表现出色，平均精度较高，但分析表明在NuScenes数据集上速度估计是瓶颈。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一限制，提出了一种定制化的位置嵌入策略，以增强时间建模能力。&lt;h4&gt;方法&lt;/h4&gt;在NuScenes测试集上进行了实验评估。&lt;h4&gt;主要发现&lt;/h4&gt;改进的方法使用ViT-L主干网络实现了70.86%的NDS（NuScenes检测分数），达到了相机仅3D物体检测的新基准。&lt;h4&gt;结论&lt;/h4&gt;StreamPETR框架通过改进速度估计能力，在仅使用相机的情况下实现了3D物体检测的新水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report introduces a targeted improvement to the StreamPETRframework, specifically aimed at enhancing velocity estimation, a criticalfactor influencing the overall NuScenes Detection Score. While StreamPETRexhibits strong 3D bounding box detection performance as reflected by its highmean Average Precision our analysis identified velocity estimation as asubstantial bottleneck when evaluated on the NuScenes dataset. To overcome thislimitation, we propose a customized positional embedding strategy tailored toenhance temporal modeling capabilities. Experimental evaluations conducted onthe NuScenes test set demonstrate that our improved approach achieves astate-of-the-art NDS of 70.86% using the ViT-L backbone, setting a newbenchmark for camera-only 3D object detection.</description>
      <author>example@mail.com (Hang Ji, Tao Ni, Xufeng Huang, Zhan Shi, Tao Luo, Xin Zhan, Junbo Chen)</author>
      <guid isPermaLink="false">2504.12643v3</guid>
      <pubDate>Tue, 10 Jun 2025 14:47:12 +0800</pubDate>
    </item>
    <item>
      <title>$\mathcal{H}$-HIGNN: A Scalable Graph Neural Network Framework with Hierarchical Matrix Acceleration for Simulation of Large-Scale Particulate Suspensions</title>
      <link>http://arxiv.org/abs/2505.08174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种利用图神经网络(GNNs)和分层矩阵(𝜅-矩阵)技术的快速且可扩展的框架，用于模拟大规模颗粒悬浮体系，该体系在科学和工程领域具有广泛的影响。&lt;h4&gt;背景&lt;/h4&gt;大规模颗粒悬浮体系的模拟在科学和工程领域具有广泛的应用，但传统的模拟方法在处理大规模系统时效率较低。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效且可扩展的框架来模拟大规模颗粒悬浮体系。&lt;h4&gt;方法&lt;/h4&gt;该框架基于流体动力相互作用图神经网络(HIGNN)，使用GNN来模拟颗粒在流体动力相互作用(HIs)和外部力作用下的运动张量。同时，将𝜅-矩阵技术集成到HIGNN中，以降低预测成本的规模。&lt;h4&gt;主要发现&lt;/h4&gt;HIGNN能够有效捕捉短程和长程HIs及其多体性质，并通过仅在每个时间步长进行一次前向传递来显著提高计算速度。然而，由于两体HIs的固有缓慢衰减，其整体预测成本呈二次标度，限制了其可扩展性。通过集成𝜅-矩阵技术，将预测成本的标度降低到准线性。&lt;h4&gt;结论&lt;/h4&gt;HIGNN-H矩阵（𝜅-HIGNN）在准确性和可扩展性方面都得到了验证，具有优越的计算效率，且仅需要少量的计算资源，例如，单个中端GPU就足以模拟包含1000万个颗粒的系统。此外，𝜅-HIGNN能够有效地模拟实际相关的大规模颗粒和柔性丝悬浮体系。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种快速且可扩展的框架，利用图神经网络（GNNs）和分层矩阵（𝜅-矩阵）技术，用于模拟大规模颗粒悬浮体系，这在科学和工程领域具有更广泛的影响。该框架基于流体动力相互作用图神经网络（HIGNN），利用GNN模拟颗粒在流体动力相互作用（HIs）和外部力作用下的运动张量。HIGNN具有以下优点：它能够有效地捕捉短程和长程HIs及其多体性质；它通过在每个时间步长仅需要通过其神经网络一次来显著提高计算速度；它通过图连接性和物理相互作用之间的直接对应提供了比黑盒神经网络模型更多的可解释性；并且它在不同系统之间具有可迁移性，无论颗粒的数量、浓度、配置或外部力如何。尽管HIGNN提供了显著的加速，但由于两体HIs的固有缓慢衰减，其整体预测成本的二次标度限制了其可扩展性。为了在所有尺度上实现优越的效率，在本文中，我们将𝜅-矩阵技术集成到HIGNN中，将预测成本的标度降低到准线性。通过综合评估，我们验证了𝜅-HIGNN的准确性，并展示了其准线性的可扩展性和优越的计算效率。它只需要最小的计算资源；例如，单个中端GPU就足以模拟包含1000万个颗粒的系统。最后，我们展示了𝜅-HIGNN有效地模拟实际相关的大规模颗粒和柔性丝悬浮体系的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a fast and scalable framework, leveraging graph neural networks(GNNs) and hierarchical matrix ($\mathcal{H}$-matrix) techniques, forsimulating large-scale particulate suspensions, which have broader impactsacross science and engineering. The framework draws on the HydrodynamicInteraction Graph Neural Network (HIGNN) that employs GNNs to model themobility tensor governing particle motion under hydrodynamic interactions (HIs)and external forces. HIGNN offers several advantages: it effectively capturesboth short- and long-range HIs and their many-body nature; it realizes asubstantial speedup over traditional methodologies, by requiring only a forwardpass through its neural networks at each time step; it provides explainabilitybeyond black-box neural network models, through direct correspondence betweengraph connectivity and physical interactions; and it demonstratestransferability across different systems, irrespective of particles' number,concentration, configuration, or external forces. While HIGNN providessignificant speedup, the quadratic scaling of its overall prediction cost (withrespect to the total number of particles), due to intrinsically slow-decayingtwo-body HIs, limits its scalability. To achieve superior efficiency across allscales, in the present work we integrate $\mathcal{H}$-matrix techniques intoHIGNN, reducing the prediction cost scaling to quasi-linear. Throughcomprehensive evaluations, we validate $\mathcal{H}$-HIGNN's accuracy, anddemonstrate its quasi-linear scalability and superior computational efficiency.It requires only minimal computing resources; for example, a single mid-rangeGPU is sufficient for a system containing 10 million particles. Finally, wedemonstrate $\mathcal{H}$-HIGNN's ability to efficiently simulate practicallyrelevant large-scale suspensions of both particles and flexible filaments.</description>
      <author>example@mail.com (Zhan Ma, Zisheng Ye, Ebrahim Safdarian, Wenxiao Pan)</author>
      <guid isPermaLink="false">2505.08174v1</guid>
      <pubDate>Mon, 09 Jun 2025 14:06:09 +0800</pubDate>
    </item>
  <item>
      <title>How hard is learning to cut? Trade-offs and sample complexity</title>
      <link>http://arxiv.org/abs/2506.00252v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了分支定界算法的数据驱动方法，特别是针对裁剪平面的选择，提出了新的样本复杂度下界，并证明了学习特定裁剪平面选择方法至少需要与学习任何通用目标函数相同的样本量。&lt;h4&gt;背景&lt;/h4&gt;近年来，分支定界算法在不同阶段（如分支或裁剪平面的选择）的决策优化吸引了数据驱动方法的关注。在裁剪平面选择方面，文献中提出了两个评分函数来评估裁剪平面的质量：分支定界树的大小和差距闭合。&lt;h4&gt;目的&lt;/h4&gt;提出新的样本复杂度下界，评估裁剪平面选择方法的学习效果。&lt;h4&gt;方法&lt;/h4&gt;通过对未知分布的实例学习来最小化评分函数，并证明了所需样本量至少与学习任何通用目标函数的样本量相同。&lt;h4&gt;主要发现&lt;/h4&gt;对于广泛类别的映射实例到裁剪平面的函数，学习这些评分函数至少需要与学习通用目标函数相同的样本量。这些结果也适用于从有限裁剪平面集合（如单纯形表中的裁剪平面）学习的情况。&lt;h4&gt;结论&lt;/h4&gt;这些结果构成了学习到裁剪框架的第一个下界，并且与神经网络的情况下的已知上界相比，它们几乎相等。实验结果表明，差距闭合评分是降低分支定界树大小的有效代理，这是首次从理论和计算的角度同时讨论这两个评分函数。&lt;h4&gt;翻译&lt;/h4&gt;在近年来的研究中，分支定界算法成为了数据驱动方法的目标，旨在优化算法的不同阶段（如分支或裁剪平面的选择）的决策。特别是在裁剪平面选择方面，文献中提出了两个评分函数来评估裁剪平面的质量：分支定界树的大小和差距闭合。在本文中，我们提出了适用于这两个评分函数的新样本复杂度下界。我们证明了对于广泛类别的函数，该函数将实例映射到裁剪平面，学习未知分布的实例以最小化这些评分函数至少需要与从相同的类别函数学习任何通用目标函数（使用平方损失）相同的样本量。我们的结果也扩展到从有限裁剪平面集合学习的情况，即单纯形表中的裁剪平面。据我们所知，这些构成了学习到裁剪框架的第一个下界。我们将我们的界限与神经网络情况下的已知上界进行了比较，并表明它们几乎是紧密的。我们使用在集合覆盖和设施定位整数规划模型上评估的图神经网络选择来说明我们的结果，并从经验上证明了差距闭合评分是降低分支定界树大小的有效代理。尽管差距闭合评分在整数规划文献中得到了广泛的应用，但这是首次从理论和计算的角度同时讨论这两个评分函数的原则性分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the recent years, branch-and-cut algorithms have been the target ofdata-driven approaches designed to enhance the decision making in differentphases of the algorithm such as branching, or the choice of cutting planes(cuts). In particular, for cutting plane selection two score functions havebeen proposed in the literature to evaluate the quality of a cut:branch-and-cut tree size and gap closed. In this paper, we present new samplecomplexity lower bounds, valid for both scores. We show that for a wide familyof classes $\mathcal{F}$ that maps an instance to a cut, learning over anunknown distribution of the instances to minimize those scores requires atleast (up to multiplicative constants) as many samples as learning from thesame class function $\mathcal{F}$ any generic target function (using squareloss). Our results also extend to the case of learning from a restricted set ofcuts, namely those from the Simplex tableau. To the best of our knowledge,these constitute the first lower bounds for the learning-to-cut framework. Wecompare our bounds to known upper bounds in the case of neural networks andshow they are nearly tight. We illustrate our results with a graph neuralnetwork selection evaluated on set covering and facility location integerprogramming models and we empirically show that the gap closed score is aneffective proxy to minimize the branch-and-cut tree size. Although the gapclosed score has been extensively used in the integer programming literature,this is the first principled analysis discussing both scores at the same timeboth theoretically and computationally.</description>
      <author>example@mail.com (Sammy Khalife, Andrea Lodi)</author>
      <guid isPermaLink="false">2506.00252v1</guid>
      <pubDate>Mon, 09 Jun 2025 14:06:09 +0800</pubDate>
    </item>
    <item>
      <title>A Driving Regime-Embedded Deep Learning Framework for Modeling Intra-Driver Heterogeneity in Multi-Scale Car-Following Dynamics</title>
      <link>http://arxiv.org/abs/2506.05902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的数据驱动式跟车模型，旨在更准确地捕捉驾驶行为的动态异质性。&lt;h4&gt;背景&lt;/h4&gt;现有模型在处理驾驶行为的异质性方面存在不足，往往强调驾驶员之间的异质性或依赖简化的假设。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一差距，提出了一种新的数据驱动跟车框架，用于系统性地将离散驾驶状态嵌入到车辆运动预测中。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了门控循环单元（GRU）进行离散驾驶状态分类和长短期记忆网络（LSTM）进行连续运动预测，利用高分辨率交通轨迹数据集。&lt;h4&gt;主要发现&lt;/h4&gt;该框架显著减少了加速度、速度和间距指标的预测误差，并能重现关键交通现象，如停车和启动波传播和振荡动力学。&lt;h4&gt;结论&lt;/h4&gt;该框架能够更全面地表示驾驶员之间的异质性和驾驶员内部的动态异质性，提高了跟车模型的预测准确性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的数据驱动跟车模型，旨在更准确地捕捉驾驶行为的动态异质性。现有模型在处理驾驶行为的异质性方面存在不足，往往强调驾驶员之间的异质性或依赖简化的假设。为了解决这一差距，提出了一种新的数据驱动跟车框架，用于系统性地将离散驾驶状态嵌入到车辆运动预测中。该框架结合了门控循环单元（GRU）进行离散驾驶状态分类和长短期记忆网络（LSTM）进行连续运动预测，利用高分辨率交通轨迹数据集。该框架显著减少了加速度、速度和间距指标的预测误差，并能重现关键交通现象，如停车和启动波传播和振荡动力学。该框架能够更全面地表示驾驶员之间的异质性和驾驶员内部的动态异质性，提高了跟车模型的预测准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A fundamental challenge in car-following modeling lies in accuratelyrepresenting the multi-scale complexity of driving behaviors, particularly theintra-driver heterogeneity where a single driver's actions fluctuatedynamically under varying conditions. While existing models, both conventionaland data-driven, address behavioral heterogeneity to some extent, they oftenemphasize inter-driver heterogeneity or rely on simplified assumptions,limiting their ability to capture the dynamic heterogeneity of a single driverunder different driving conditions. To address this gap, we propose a noveldata-driven car-following framework that systematically embeds discrete drivingregimes (e.g., steady-state following, acceleration, cruising) into vehicularmotion predictions. Leveraging high-resolution traffic trajectory datasets, theproposed hybrid deep learning architecture combines Gated Recurrent Units fordiscrete driving regime classification with Long Short-Term Memory networks forcontinuous kinematic prediction, unifying discrete decision-making processesand continuous vehicular dynamics to comprehensively represent inter- andintra-driver heterogeneity. Driving regimes are identified using a bottom-upsegmentation algorithm and Dynamic Time Warping, ensuring robustcharacterization of behavioral states across diverse traffic scenarios.Comparative analyses demonstrate that the framework significantly reducesprediction errors for acceleration (maximum MSE improvement reached 58.47\%),speed, and spacing metrics while reproducing critical traffic phenomena, suchas stop-and-go wave propagation and oscillatory dynamics.</description>
      <author>example@mail.com (Shirui Zhou, Jiying Yan, Junfang Tian, Tao Wang, Yongfu Li, Shiquan Zhong)</author>
      <guid isPermaLink="false">2506.05902v1</guid>
      <pubDate>Mon, 09 Jun 2025 14:06:09 +0800</pubDate>
    </item>
    <item>
      <title>EqCollide: Equivariant and Collision-Aware Deformable Objects Neural Simulator</title>
      <link>http://arxiv.org/abs/2506.05797v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为EqCollide的新方法，用于模拟可变形物体的碰撞。该方法通过引入等变编码器和图神经网络来处理碰撞，提高了模拟的准确性和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;模拟可变形物体的碰撞是一个复杂而具有挑战性的任务，因为需要处理固体力学和多体交互的复杂性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够准确、稳定和可扩展地模拟可变形物体及其碰撞的神经字段模拟器。&lt;h4&gt;方法&lt;/h4&gt;1. 使用等变编码器将物体几何和速度映射到潜在控制点。2. 利用基于图神经网络的等变图神经网络模型通过碰撞感知的消息传递来模拟控制点之间的相互作用。3. 通过查询条件于控制点特征的神经字段来重建速度场。&lt;h4&gt;主要发现&lt;/h4&gt;EqCollide在多种物体配置下实现了准确、稳定和可扩展的模拟，并且相比最好的基线模型，其滚动均方误差（MSE）降低了24.34%到35.82%。此外，模型能够泛化到更多的碰撞物体和更长的时序范围，并且对输入通过群作用变换保持鲁棒。&lt;h4&gt;结论&lt;/h4&gt;EqCollide是一个高效且准确的模拟器，适用于可变形物体及其碰撞的模拟。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulating collisions of deformable objects is a fundamental yet challengingtask due to the complexity of modeling solid mechanics and multi-bodyinteractions. Existing data-driven methods often suffer from lack ofequivariance to physical symmetries, inadequate handling of collisions, andlimited scalability. Here we introduce EqCollide, the first end-to-endequivariant neural fields simulator for deformable objects and theircollisions. We propose an equivariant encoder to map object geometry andvelocity into latent control points. A subsequent equivariant Graph NeuralNetwork-based Neural Ordinary Differential Equation models the interactionsamong control points via collision-aware message passing. To reconstructvelocity fields, we query a neural field conditioned on control point features,enabling continuous and resolution-independent motion predictions. Experimentalresults show that EqCollide achieves accurate, stable, and scalable simulationsacross diverse object configurations, and our model achieves 24.34% to 35.82%lower rollout MSE even compared with the best-performing baseline model.Furthermore, our model could generalize to more colliding objects and extendedtemporal horizons, and stay robust to input transformed with group action.</description>
      <author>example@mail.com (Qianyi Chen, Tianrun Gao, Chenbo Jiang, Tailin Wu)</author>
      <guid isPermaLink="false">2506.05797v1</guid>
      <pubDate>Mon, 09 Jun 2025 14:06:09 +0800</pubDate>
    </item>
    <item>
      <title>SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes</title>
      <link>http://arxiv.org/abs/2506.01558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个名为SAM2-LOVE的新型框架，用于在语言辅助音频视觉场景（LAVS）中实现像素级的场景理解。&lt;h4&gt;背景&lt;/h4&gt;现有的双模态方法由于缺乏第三模态而失败，而现有的三模态方法在时空一致性方面存在问题，导致目标在不同帧之间发生偏移。&lt;h4&gt;目的&lt;/h4&gt;为了提供像素级的场景理解，论文旨在解决LAVS中的音频视觉分割（Ref-AVS）任务。&lt;h4&gt;方法&lt;/h4&gt;SAM2-LOVE框架将文本、音频和视觉表示集成到一个可学习的标记中，以提示和调整SAM2以实现Ref-AVS。该框架包括一个多模态融合模块，旨在提高SAM2的多模态理解，以及标记传播和累积策略，旨在增强时空一致性而不忘记历史信息。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，SAM2-LOVE在Ref-AVS基准测试中比SOTA方法在J&amp;F指标上提高了8.5%，并展示了组件的简单性和有效性。&lt;h4&gt;结论&lt;/h4&gt;SAM2-LOVE是一个有效的框架，可以用于LAVS中的Ref-AVS任务，并提供了比现有方法更好的性能。&lt;h4&gt;翻译&lt;/h4&gt;参考音频视觉分割（Ref-AVS）旨在为语言辅助音频视觉场景（LAVS）提供像素级的场景理解。这项任务要求模型能够持续地对视频中由文本和音频所指的物体进行分割。由于缺乏第三模态，以前的双模态方法总是失败，而现有的三模态方法在时空一致性方面存在问题，导致不同帧的目标偏移。在本工作中，我们介绍了一个新的框架，称为SAM2-LOVE，它将文本、音频和视觉表示集成到一个可学习的标记中，以提示和调整SAM2以实现LAVS中的Ref-AVS。技术上，我们的方法包括一个旨在提高SAM2多模态理解的多模态融合模块，以及旨在增强时空一致性而不忘记历史信息的标记传播和累积策略。我们进行了广泛的实验，以证明SAM2-LOVE在Ref-AVS基准测试中比SOTA方法在J&amp;F指标上提高了8.5%，并展示了组件的简单性和有效性。我们的代码将在这里提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reference Audio-Visual Segmentation (Ref-AVS) aims to provide a pixel-wisescene understanding in Language-aided Audio-Visual Scenes (LAVS). This taskrequires the model to continuously segment objects referred to by text andaudio from a video. Previous dual-modality methods always fail due to the lackof a third modality and the existing triple-modality method struggles withspatio-temporal consistency, leading to the target shift of different frames.In this work, we introduce a novel framework, termed SAM2-LOVE, whichintegrates textual, audio, and visual representations into a learnable token toprompt and align SAM2 for achieving Ref-AVS in the LAVS. Technically, ourapproach includes a multimodal fusion module aimed at improving multimodalunderstanding of SAM2, as well as token propagation and accumulation strategiesdesigned to enhance spatio-temporal consistency without forgetting historicalinformation. We conducted extensive experiments to demonstrate that SAM2-LOVEoutperforms the SOTA by 8.5\% in $\mathcal{J\&amp;F}$ on the Ref-AVS benchmark andshowcase the simplicity and effectiveness of the components. Our code will beavailable here.</description>
      <author>example@mail.com (Yuji Wang, Haoran Xu, Yong Liu, Jiaze Li, Yansong Tang)</author>
      <guid isPermaLink="false">2506.01558v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
  <item>
      <title>Interpretable Multimodal Framework for Human-Centered Street Assessment: Integrating Visual-Language Models for Perceptual Urban Diagnostics</title>
      <link>http://arxiv.org/abs/2506.05087v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一个名为MSEF的新型多模态街道评估框架，融合了视觉变换器和大型语言模型，用于对街道景观进行可解释的双输出评估。&lt;h4&gt;背景&lt;/h4&gt;虽然从图像或GIS中得出的客观街道指标在城市分析中已成为标准，但它们不足以捕捉包容性城市设计所必需的主观感知。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入MSEF框架，提高对街道景观的主观感知评估，并促进包容性城市设计。&lt;h4&gt;方法&lt;/h4&gt;研究利用来自哈尔滨的15000多张标注的街景图像，使用LoRA和P-Tuning v2对框架进行微调，实现了参数高效的适应。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在客观特征上达到了0.84的F1分数，并与居民感知的聚合结果有89.3%的一致性。它还捕捉了与上下文相关的矛盾，如非正式商业既能提高感知活力，同时又降低行人舒适度。&lt;h4&gt;结论&lt;/h4&gt;MSEF不仅提供了城市感知建模的方法论创新，还为寻求在基础设施精确性与生活体验之间取得平衡的规划系统提供了实用价值。&lt;h4&gt;翻译&lt;/h4&gt;While objective street metrics derived from imagery or GIS have becomestandard in urban analytics, they remain insufficient to capture subjectiveperceptions essential to inclusive urban design. This study introduces a novelMultimodal Street Evaluation Framework (MSEF) that fuses a vision transformer(VisualGLM-6B) with a large language model (GPT-4), enabling interpretabledual-output assessment of streetscapes. Leveraging over 15,000 annotatedstreet-view images from Harbin, China, we fine-tune the framework using LoRAand P-Tuning v2 for parameter-efficient adaptation. The model achieves an F1score of 0.84 on objective features and 89.3 percent agreement with aggregatedresident perceptions, validated across stratified socioeconomic geographies. Beyond classification accuracy, MSEF captures context-dependent contradictions: for instance, informal commerce boosts perceived vibrancy while simultaneouslyreducing pedestrian comfort. It also identifies nonlinear and semanticallycontingent patterns -- such as the divergent perceptual effects ofarchitectural transparency across residential and commercial zones -- revealingthe limits of universal spatial heuristics. By generating natural-languagerationales grounded in attention mechanisms, the framework bridges sensory datawith socio-affective inference, enabling transparent diagnostics aligned withSDG 11. This work offers both methodological innovation in urban perceptionmodeling and practical utility for planning systems seeking to reconcileinfrastructural precision with lived experience.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While objective street metrics derived from imagery or GIS have becomestandard in urban analytics, they remain insufficient to capture subjectiveperceptions essential to inclusive urban design. This study introduces a novelMultimodal Street Evaluation Framework (MSEF) that fuses a vision transformer(VisualGLM-6B) with a large language model (GPT-4), enabling interpretabledual-output assessment of streetscapes. Leveraging over 15,000 annotatedstreet-view images from Harbin, China, we fine-tune the framework using LoRAand P-Tuning v2 for parameter-efficient adaptation. The model achieves an F1score of 0.84 on objective features and 89.3 percent agreement with aggregatedresident perceptions, validated across stratified socioeconomic geographies.Beyond classification accuracy, MSEF captures context-dependent contradictions:for instance, informal commerce boosts perceived vibrancy while simultaneouslyreducing pedestrian comfort. It also identifies nonlinear and semanticallycontingent patterns -- such as the divergent perceptual effects ofarchitectural transparency across residential and commercial zones -- revealingthe limits of universal spatial heuristics. By generating natural-languagerationales grounded in attention mechanisms, the framework bridges sensory datawith socio-affective inference, enabling transparent diagnostics aligned withSDG 11. This work offers both methodological innovation in urban perceptionmodeling and practical utility for planning systems seeking to reconcileinfrastructural precision with lived experience.</description>
      <author>example@mail.com (HaoTian Lan)</author>
      <guid isPermaLink="false">2506.05087v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Rectified Point Flow: Generic Point Cloud Pose Estimation</title>
      <link>http://arxiv.org/abs/2506.05282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://rectified-pointflow.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了Rectified Point Flow，这是一种统一的参数化方法，将成对点云配准和多部件形状组装作为一个单一代数生成问题。该方法在未定位的点云上学习了一个连续的点速度场，将噪声点移动到目标位置，从而恢复部件姿态。&lt;h4&gt;背景&lt;/h4&gt;之前的点云配准和多部件形状组装工作通常将问题分为多个部分，并通过特殊的对称性处理方法来解决。&lt;h4&gt;目的&lt;/h4&gt;旨在通过统一的方法解决点云配准和多部件形状组装问题，同时提高配准和组装的准确性。&lt;h4&gt;方法&lt;/h4&gt;学习一个连续的点速度场，将噪声点移动到目标位置，并利用自监督编码器专注于重叠点来提高性能。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在六个基准测试中实现了最先进的性能，这些测试涵盖了成对配准和形状组装。此外，该方法可以有效地在多样数据集上进行联合训练，从而提高准确性。&lt;h4&gt;结论&lt;/h4&gt;Rectified Point Flow方法通过学习共享的几何先验，实现了在成对配准和多部件形状组装任务中的高精度。&lt;h4&gt;翻译&lt;/h4&gt;We introduce Rectified Point Flow, a unified parameterization that formulates pairwise point cloud registration and multi-part shape assembly as a single conditional generative problem. Given unposed point clouds, our method learns a continuous point-wise velocity field that transports noisy points toward their target positions, from which part poses are recovered. In contrast to prior work that regresses part-wise poses with ad-hoc symmetry handling, our method intrinsically learns assembly symmetries without symmetry labels. Together with a self-supervised encoder focused on overlapping points, our method achieves a new state-of-the-art performance on six benchmarks spanning pairwisely registration and shape assembly. Notably, our unified formulation enables effective joint training on diverse datasets, facilitating the learning of shared geometric priors and consequently boosting accuracy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Rectified Point Flow, a unified parameterization that formulatespairwise point cloud registration and multi-part shape assembly as a singleconditional generative problem. Given unposed point clouds, our method learns acontinuous point-wise velocity field that transports noisy points toward theirtarget positions, from which part poses are recovered. In contrast to priorwork that regresses part-wise poses with ad-hoc symmetry handling, our methodintrinsically learns assembly symmetries without symmetry labels. Together witha self-supervised encoder focused on overlapping points, our method achieves anew state-of-the-art performance on six benchmarks spanning pairwiseregistration and shape assembly. Notably, our unified formulation enableseffective joint training on diverse datasets, facilitating the learning ofshared geometric priors and consequently boosting accuracy. Project page:https://rectified-pointflow.github.io/.</description>
      <author>example@mail.com (Tao Sun, Liyuan Zhu, Shengyu Huang, Shuran Song, Iro Armeni)</author>
      <guid isPermaLink="false">2506.05282v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Does Your 3D Encoder Really Work? When Pretrain-SFT from 2D VLMs Meets 3D VLMs</title>
      <link>http://arxiv.org/abs/2506.05318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了将2D视觉语言模型（VLMs）扩展到3D环境以进行3D问答、密集描述和视觉定位等任务的研究进展。通过分析不同类型的3D VLMs，提出了改进3D理解的策略。&lt;h4&gt;背景&lt;/h4&gt;2D VLMs在图像处理方面取得了显著进展，但3D场景的复杂空间结构需要不同的模型架构。&lt;h4&gt;目的&lt;/h4&gt;分析不同类型的3D VLMs，并提出改进3D理解的策略。&lt;h4&gt;方法&lt;/h4&gt;对3D VLMs进行分类，并进行深入分析以理解性能差异。&lt;h4&gt;主要发现&lt;/h4&gt;3D场景中心型VLMs在性能上低于3D对象中心型和基于2D图像的方法；3D场景中心型VLMs对3D场景编码器的依赖有限；数据规模扩大对大数据集的益处不明显；模型过度依赖语言提示和频繁答案分布，导致3D编码器的有效利用降低。&lt;h4&gt;结论&lt;/h4&gt;提出一个新的3D相关性区分QA数据集，旨在破坏捷径学习并提高3D理解；强调在3D VLMs中需要先进的评估和改进策略以实现更好的3D理解。&lt;h4&gt;翻译&lt;/h4&gt;This paper discusses the research progress of extending 2D Vision-Language Models (VLMs) to 3D environments for tasks such as 3D Question Answering, DenseCaptioning, and Visual Grounding. By analyzing different types of 3D VLMs, strategies for improving 3D understanding are proposed.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Remarkable progress in 2D Vision-Language Models (VLMs) has spurred interestin extending them to 3D settings for tasks like 3D Question Answering, DenseCaptioning, and Visual Grounding. Unlike 2D VLMs that typically process imagesthrough an image encoder, 3D scenes, with their intricate spatial structures,allow for diverse model architectures. Based on their encoder design, thispaper categorizes recent 3D VLMs into 3D object-centric, 2D image-based, and 3Dscene-centric approaches. Despite the architectural similarity of 3Dscene-centric VLMs to their 2D counterparts, they have exhibited comparativelylower performance compared with the latest 3D object-centric and 2D image-basedapproaches. To understand this gap, we conduct an in-depth analysis, revealingthat 3D scene-centric VLMs show limited reliance on the 3D scene encoder, andthe pre-train stage appears less effective than in 2D VLMs. Furthermore, weobserve that data scaling benefits are less pronounced on larger datasets. Ourinvestigation suggests that while these models possess cross-modal alignmentcapabilities, they tend to over-rely on linguistic cues and overfit to frequentanswer distributions, thereby diminishing the effective utilization of the 3Dencoder. To address these limitations and encourage genuine 3D sceneunderstanding, we introduce a novel 3D Relevance Discrimination QA datasetdesigned to disrupt shortcut learning and improve 3D understanding. Ourfindings highlight the need for advanced evaluation and improved strategies forbetter 3D understanding in 3D VLMs.</description>
      <author>example@mail.com (Haoyuan Li, Yanpeng Zhou, Yufei Gao, Tao Tang, Jianhua Han, Yujie Yuan, Dave Zhenyu Chen, Jiawang Bian, Hang Xu, Xiaodan Liang)</author>
      <guid isPermaLink="false">2506.05318v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Seeing the Invisible: Machine learning-Based QPI Kernel Extraction via Latent Alignment</title>
      <link>http://arxiv.org/abs/2506.05325v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于人工智能的框架，用于从量子材料中的多散射图像中提取单散射器的Quasiparticle interference (QPI)核。&lt;h4&gt;背景&lt;/h4&gt;Quasiparticle interference (QPI)成像是一种强大的工具，用于探测量子材料的电子结构，但从多散射图像中提取单散射器QPI核是一个基本的逆问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法，以解决从多散射图像中提取单散射器QPI核的难题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种两步学习策略，将核表示学习从观察到的核推理中分离出来。第一步是训练一个变分自动编码器来学习散射核的紧凑潜在空间。第二步是使用专用编码器将QPI观察到的潜在表示与预学习的核对齐。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够在复杂、纠缠的散射条件下稳健地推断核，并且实验结果表明，该方法在提取准确性和泛化到未见过的核方面都取得了显著提高。&lt;h4&gt;结论&lt;/h4&gt;该方法在QPI核提取方面取得了显著进步，为量子材料电子结构的探测提供了新的工具。&lt;h4&gt;翻译&lt;/h4&gt;Quasiparticle interference (QPI) 成像是一种强大的工具，用于探测量子材料的电子结构，但从多散射图像中提取单散射器的 QPI 核仍然是一个基本的逆问题。在本工作中，我们提出了第一个基于人工智能的 QPI 核提取框架。我们引入了一种两步学习策略，将核表示学习从观察到的核推理中分离出来。第一步，我们训练一个变分自动编码器来学习散射核的紧凑潜在空间。第二步，我们使用专用编码器将 QPI 观察到的潜在表示与预学习的核对齐。这种设计使模型能够在复杂、纠缠的散射条件下稳健地推断核。我们构建了一个包含 100 个独特核的多样化和物理上现实的 QPI 数据集，并将我们的方法与直接的一步基线进行了比较。实验结果表明，我们的方法在提取准确性和泛化到未见过的核方面都取得了显著提高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quasiparticle interference (QPI) imaging is a powerful tool for probingelectronic structures in quantum materials, but extracting the single-scattererQPI pattern (i.e., the kernel) from a multi-scatterer image remains afundamentally ill-posed inverse problem. In this work, we propose the firstAI-based framework for QPI kernel extraction. We introduce a two-step learningstrategy that decouples kernel representation learning fromobservation-to-kernel inference. In the first step, we train a variationalautoencoder to learn a compact latent space of scattering kernels. In thesecond step, we align the latent representation of QPI observations with thoseof the pre-learned kernels using a dedicated encoder. This design enables themodel to infer kernels robustly even under complex, entangled scatteringconditions. We construct a diverse and physically realistic QPI datasetcomprising 100 unique kernels and evaluate our method against a direct one-stepbaseline. Experimental results demonstrate that our approach achievessignificantly higher extraction accuracy, and improved generalization to unseenkernels.</description>
      <author>example@mail.com (Yingshuai Ji, Haomin Zhuang, Matthew Toole, James McKenzie, Xiaolong Liu, Xiangliang Zhang)</author>
      <guid isPermaLink="false">2506.05325v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Joint Beamforming and Integer User Association using a GNN with Gumbel-Softmax Reparameterizations</title>
      <link>http://arxiv.org/abs/2506.05241v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的图神经网络（GNN）结构，用于优化多小区无线网络中的波束成形向量和用户关联决策，同时确保关联输出为整数，并通过Gumbel-Softmax（GS）重参数化方法满足整数关联约束，从而在保证整数关联的同时不增加计算复杂度。&lt;h4&gt;背景&lt;/h4&gt;现有的机器学习设计在优化多小区无线网络时，通常需要将整数关联变量近似为概率分布输出。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以联合优化波束成形向量和用户关联，同时保证关联输出为整数。&lt;h4&gt;方法&lt;/h4&gt;使用图神经网络（GNN）结构，结合Gumbel-Softmax（GS）重参数化技术来满足整数关联约束。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，该方法在保证整数关联决策的同时，相比其他分数关联方法，在更大的网络中实现了更高的总速率。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法在优化多小区无线网络时，通过GNN和GS技术，能够有效实现整数关联决策，提高网络的总速率，具有较好的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;Machine learning (ML) models can effectively optimize a multi-cell wireless network by designing the beamforming vectors and association decisions. Existing ML designs, however, often need to approximate the integer association variables with a probability distribution output. We propose a novel graph neural network (GNN) structure that jointly optimizes beamforming vectors and user association while guaranteeing association output as integers. The integer association constraints are satisfied using the Gumbel-Softmax (GS) reparameterization, without increasing computational complexity. Simulation results demonstrate that our proposed GS-based GNN consistently achieves integer association decisions and yields a higher sum-rate, especially when generalized to larger networks, compared to all other fractional association methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning (ML) models can effectively optimize a multi-cell wirelessnetwork by designing the beamforming vectors and association decisions.Existing ML designs, however, often needs to approximate the integerassociation variables with a probability distribution output. We propose anovel graph neural network (GNN) structure that jointly optimize beamformingvectors and user association while guaranteeing association output as integers.The integer association constraints are satisfied using the Gumbel-Softmax (GS)reparameterization, without increasing computational complexity. Simulationresults demonstrate that our proposed GS-based GNN consistently achievesinteger association decisions and yields a higher sum-rate, especially whengeneralized to larger networks, compared to all other fractional associationmethods.</description>
      <author>example@mail.com (Qing Lyu, Mai Vu)</author>
      <guid isPermaLink="false">2506.05241v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Depth Representations for Feed-Forward 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.05327v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://aim-uofa.github.io/PMLoss&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的正则化损失函数PM-Loss，用于解决3D Gaussian Splatting渲染中深度图导致的点云碎片化和稀疏问题，从而提高渲染质量。&lt;h4&gt;背景&lt;/h4&gt;深度图在3D Gaussian Splatting中用于生成新视图，但深度图在物体边界处的不连续性常导致点云碎片化，影响渲染质量。&lt;h4&gt;目的&lt;/h4&gt;提出PM-Loss以解决深度图导致点云碎片化的问题，提高3D Gaussian Splatting的渲染质量。&lt;h4&gt;方法&lt;/h4&gt;使用预训练的transformer预测点图（pointmap），尽管点图可能不如深度图准确，但能有效强制几何平滑，特别是在物体边界附近。&lt;h4&gt;主要发现&lt;/h4&gt;PM-Loss能够有效提高基于深度图的3D Gaussian Splatting渲染质量，并在不同架构和场景中显著改善渲染结果。&lt;h4&gt;结论&lt;/h4&gt;PM-Loss是一种有效的正则化损失函数，可以显著提升3D Gaussian Splatting的渲染效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Depth maps are widely used in feed-forward 3D Gaussian Splatting (3DGS)pipelines by unprojecting them into 3D point clouds for novel view synthesis.This approach offers advantages such as efficient training, the use of knowncamera poses, and accurate geometry estimation. However, depth discontinuitiesat object boundaries often lead to fragmented or sparse point clouds, degradingrendering quality -- a well-known limitation of depth-based representations. Totackle this issue, we introduce PM-Loss, a novel regularization loss based on apointmap predicted by a pre-trained transformer. Although the pointmap itselfmay be less accurate than the depth map, it effectively enforces geometricsmoothness, especially around object boundaries. With the improved depth map,our method significantly improves the feed-forward 3DGS across variousarchitectures and scenes, delivering consistently better rendering results. Ourproject page: https://aim-uofa.github.io/PMLoss</description>
      <author>example@mail.com (Duochao Shi, Weijie Wang, Donny Y. Chen, Zeyu Zhang, Jia-Wang Bian, Bohan Zhuang, Chunhua Shen)</author>
      <guid isPermaLink="false">2506.05327v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>FRED: The Florence RGB-Event Drone Dataset</title>
      <link>http://arxiv.org/abs/2506.05163v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为FRED的新型多模态数据集，旨在解决传统RGB相机在捕捉快速移动物体时的局限性，特别是在挑战性光照条件下。FRED结合了RGB视频和事件流，用于无人机检测、跟踪和轨迹预测。&lt;h4&gt;背景&lt;/h4&gt;小型、快速、轻量级的无人机对传统RGB相机来说存在挑战，因为它们在捕捉快速移动的物体，尤其是在恶劣光照条件下存在局限性。事件相机提供了理想的解决方案，但现有的基准测试往往缺乏精细的时间分辨率或针对无人机特定的运动模式。&lt;h4&gt;目的&lt;/h4&gt;通过创建一个结合RGB视频和事件流的多模态数据集FRED，旨在推动无人机感知和时空理解的研究。&lt;h4&gt;方法&lt;/h4&gt;FRED数据集包含超过7小时的密集标注无人机轨迹，使用5种不同的无人机模型，并包括雨和恶劣光照条件等挑战性场景。提供了详细的评估协议和标准度量，以促进可重复的基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;FRED数据集提供了高时间分辨率和动态范围，有助于无人机检测、跟踪和轨迹预测的研究。&lt;h4&gt;结论&lt;/h4&gt;FRED数据集有望推进高速无人机感知和多模态时空理解的研究。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces the Florence RGB-Event Drone dataset (FRED), a novel multimodal dataset specifically designed for drone detection, tracking, and trajectory forecasting, combining RGB video and event streams. FRED features more than 7 hours of densely annotated drone trajectories, using 5 different drone models and including challenging scenarios such as rain and adverse lighting conditions. We provide detailed evaluation protocols and standard metrics for each task, facilitating reproducible benchmarking. The authors hope FRED will advance research in high-speed drone perception and multimodal spatiotemporal understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Small, fast, and lightweight drones present significant challenges fortraditional RGB cameras due to their limitations in capturing fast-movingobjects, especially under challenging lighting conditions. Event cameras offeran ideal solution, providing high temporal definition and dynamic range, yetexisting benchmarks often lack fine temporal resolution or drone-specificmotion patterns, hindering progress in these areas. This paper introduces theFlorence RGB-Event Drone dataset (FRED), a novel multimodal datasetspecifically designed for drone detection, tracking, and trajectoryforecasting, combining RGB video and event streams. FRED features more than 7hours of densely annotated drone trajectories, using 5 different drone modelsand including challenging scenarios such as rain and adverse lightingconditions. We provide detailed evaluation protocols and standard metrics foreach task, facilitating reproducible benchmarking. The authors hope FRED willadvance research in high-speed drone perception and multimodal spatiotemporalunderstanding.</description>
      <author>example@mail.com (Gabriele Magrini, Niccolò Marini, Federico Becattini, Lorenzo Berlincioni, Niccolò Biondi, Pietro Pala, Alberto Del Bimbo)</author>
      <guid isPermaLink="false">2506.05163v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>From Play to Replay: Composed Video Retrieval for Temporally Fine-Grained Videos</title>
      <link>http://arxiv.org/abs/2506.05274v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TF-CoVR的大规模基准，用于细粒度视频检索，专注于捕捉细微且快速的时间差异，并通过对比学习模型在多个视频片段中检索目标视频。&lt;h4&gt;背景&lt;/h4&gt;现有的CoVR基准主要关注外观变化或粗粒度事件变化，无法捕捉细微的时间差异。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够捕捉细微、快速时间差异的细粒度视频检索基准，并评估相关模型在零样本和微调模式下的性能。&lt;h4&gt;方法&lt;/h4&gt;TF-CoVR基准基于体操和跳水视频，提供180K个三元组。通过提示语言模型来构建每个&lt;查询，修改&gt;对，并与多个有效目标视频相关联。TF-CoVR-Base模型采用两阶段训练框架：预训练视频编码器以获得时间区分性嵌入，然后使用对比学习对齐查询和候选视频。&lt;h4&gt;主要发现&lt;/h4&gt;TF-CoVR-Base在TF-CoVR基准上显著提高了零样本mAP@50和微调后的性能。&lt;h4&gt;结论&lt;/h4&gt;TF-CoVR基准为细粒度视频检索提供了新的挑战和评估标准，TF-CoVR-Base模型在捕捉时间动态方面表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Composed Video Retrieval (CoVR) retrieves a target video given a query videoand a modification text describing the intended change. Existing CoVRbenchmarks emphasize appearance shifts or coarse event changes and therefore donot test the ability to capture subtle, fast-paced temporal differences. Weintroduce TF-CoVR, the first large-scale benchmark dedicated to temporallyfine-grained CoVR. TF-CoVR focuses on gymnastics and diving and provides 180Ktriplets drawn from FineGym and FineDiving. Previous CoVR benchmarks focusingon temporal aspect, link each query to a single target segment taken from thesame video, limiting practical usefulness. In TF-CoVR, we instead constructeach &lt;query, modification&gt; pair by prompting an LLM with the label differencesbetween clips drawn from different videos; every pair is thus associated withmultiple valid target videos (3.9 on average), reflecting real-world tasks suchas sports-highlight generation. To model these temporal dynamics we proposeTF-CoVR-Base, a concise two-stage training framework: (i) pre-train a videoencoder on fine-grained action classification to obtain temporallydiscriminative embeddings; (ii) align the composed query with candidate videosusing contrastive learning. We conduct the first comprehensive study of image,video, and general multimodal embedding (GME) models on temporally fine-grainedcomposed retrieval in both zero-shot and fine-tuning regimes. On TF-CoVR,TF-CoVR-Base improves zero-shot mAP@50 from 5.92 (LanguageBind) to 7.51, andafter fine-tuning raises the state-of-the-art from 19.83 to 25.82.</description>
      <author>example@mail.com (Animesh Gupta, Jay Parmar, Ishan Rajendrakumar Dave, Mubarak Shah)</author>
      <guid isPermaLink="false">2506.05274v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Can Foundation Models Generalise the Presentation Attack Detection Capabilities on ID Cards?</title>
      <link>http://arxiv.org/abs/2506.05263v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在身份证明检测（PAD）领域，如何提高模型在不同国家身份证上的泛化能力，以及如何使用基础模型（FM）来适应这种泛化。&lt;h4&gt;背景&lt;/h4&gt;由于隐私保护的原因，大多数PAD系统只训练在少量身份证件上，导致它们在未知的新身份证国家测试时无法获得具有竞争力的结果。&lt;h4&gt;目的&lt;/h4&gt;旨在提高FM的能力，并评估其如何用于增强PAD的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;使用不同测试协议，包括零样本和微调，以及两个不同的身份证件数据集：一个基于智利身份证的私有数据集和一个基于芬兰、西班牙和斯洛伐克身份证的公开数据集。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果指出，真实图像是泛化的关键。&lt;h4&gt;结论&lt;/h4&gt;FM在提高PAD泛化能力方面具有潜力，特别是当用于处理真实图像时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nowadays, one of the main challenges in presentation attack detection (PAD)on ID cards is obtaining generalisation capabilities for a diversity ofcountries that are issuing ID cards. Most PAD systems are trained on one, two,or three ID documents because of privacy protection concerns. As a result, theydo not obtain competitive results for commercial purposes when tested in anunknown new ID card country. In this scenario, Foundation Models (FM) trainedon huge datasets can help to improve generalisation capabilities. This workintends to improve and benchmark the capabilities of FM and how to use them toadapt the generalisation on PAD of ID Documents. Different test protocols wereused, considering zero-shot and fine-tuning and two different ID card datasets.One private dataset based on Chilean IDs and one open-set based on three IDcountries: Finland, Spain, and Slovakia. Our findings indicate that bona fideimages are the key to generalisation.</description>
      <author>example@mail.com (Juan E. Tapia, Christoph Busch)</author>
      <guid isPermaLink="false">2506.05263v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>FALO: Fast and Accurate LiDAR 3D Object Detection on Resource-Constrained Devices</title>
      <link>http://arxiv.org/abs/2506.04499v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FALO的硬件友好的LiDAR 3D检测方法，该方法在保持高检测精度的同时，实现了快速的推理速度。&lt;h4&gt;背景&lt;/h4&gt;现有的LiDAR 3D检测方法主要依赖于稀疏卷积和/或Transformer，这些方法在资源受限的边缘设备上运行时，由于不规则的内存访问模式和较高的计算成本，可能会遇到挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种既具有高检测精度又具有快速推理速度的LiDAR 3D检测方法。&lt;h4&gt;方法&lt;/h4&gt;FALO首先将3D点云进行体素化，然后将稀疏3D体素根据其坐标和邻近性排列成1D序列。该序列随后通过作者提出的ConvDotMix模块进行处理，该模块包含大核卷积、Hadamard积和线性层。ConvDotMix在空间和嵌入维度上提供了足够的混合能力，并引入了空间特征之间的高阶非线性交互。此外，在通过ConvDotMix层时，引入了隐式分组，以平衡张量维度，提高推理效率，并考虑了感受野的增长。&lt;h4&gt;主要发现&lt;/h4&gt;FALO在nuScenes和Waymo等LiDAR 3D检测基准上实现了具有竞争力的性能，并且在移动GPU和移动NPU上比最新的SOTA方法快1.6~9.8倍。&lt;h4&gt;结论&lt;/h4&gt;FALO是一种在资源受限平台上运行友好的LiDAR 3D检测方法，它可以在紧凑的嵌入式设备上轻松部署，并实现了高性能和快速推理速度的结合。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing LiDAR 3D object detection methods predominantely rely on sparseconvolutions and/or transformers, which can be challenging to run onresource-constrained edge devices, due to irregular memory access patterns andhigh computational costs. In this paper, we propose FALO, a hardware-friendlyapproach to LiDAR 3D detection, which offers both state-of-the-art (SOTA)detection accuracy and fast inference speed. More specifically, given the 3Dpoint cloud and after voxelization, FALO first arranges sparse 3D voxels into a1D sequence based on their coordinates and proximity. The sequence is thenprocessed by our proposed ConvDotMix blocks, consisting of large-kernelconvolutions, Hadamard products, and linear layers. ConvDotMix providessufficient mixing capability in both spatial and embedding dimensions, andintroduces higher-order nonlinear interaction among spatial features.Furthermore, when going through the ConvDotMix layers, we introduce implicitgrouping, which balances the tensor dimensions for more efficient inference andtakes into account the growing receptive field. All these operations arefriendly to run on resource-constrained platforms and proposed FALO can readilydeploy on compact, embedded devices. Our extensive evaluation on LiDAR 3Ddetection benchmarks such as nuScenes and Waymo shows that FALO achievescompetitive performance. Meanwhile, FALO is 1.6~9.8x faster than the latestSOTA on mobile Graphics Processing Unit (GPU) and mobile Neural Processing Unit(NPU).</description>
      <author>example@mail.com (Shizhong Han, Hsin-Pai Cheng, Hong Cai, Jihad Masri, Soyeb Nagori, Fatih Porikli)</author>
      <guid isPermaLink="false">2506.04499v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>DiCoRe: Enhancing Zero-shot Event Detection via Divergent-Convergent LLM Reasoning</title>
      <link>http://arxiv.org/abs/2506.05128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted at ACL ARR May 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DiCoRe是一种用于零样本事件检测的框架，通过Dreamer和Grounder的解耦任务，结合LLM-Judge的验证，在多个数据集上实现了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;零样本事件检测（Zero-shot Event Detection）是理解专业领域文档的关键任务，但由于复杂的事件本体、领域特定触发词的提取和结构化限制，大型语言模型（LLMs）在零样本事件检测中的效用受到限制。&lt;h4&gt;目的&lt;/h4&gt;提出DiCoRe框架，以解决LLMs在零样本事件检测中的局限性。&lt;h4&gt;方法&lt;/h4&gt;DiCoRe采用Dreamer进行发散性推理，通过开放式事件发现来增强事件覆盖；Grounder引入收敛性推理，使用有限状态机引导的约束解码来调整预测与任务特定指令的一致性；LLM-Judge用于验证最终输出以确保高精度。&lt;h4&gt;主要发现&lt;/h4&gt;在五个领域的六个数据集上，DiCoRe在零样本、迁移学习和推理基线中表现优异，平均F1分数比最佳基线高出4-7%。&lt;h4&gt;结论&lt;/h4&gt;DiCoRe是一个强大的零样本事件检测框架，能够显著提升事件检测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Zero-shot Event Detection (ED), the task of identifying event mentions innatural language text without any training data, is critical for documentunderstanding in specialized domains. Understanding the complex event ontology,extracting domain-specific triggers from the passage, and structuring themappropriately overloads and limits the utility of Large Language Models (LLMs)for zero-shot ED. To this end, we propose DiCoRe, a divergent-convergentreasoning framework that decouples the task of ED using Dreamer and Grounder.Dreamer encourages divergent reasoning through open-ended event discovery,which helps to boost event coverage. Conversely, Grounder introduces convergentreasoning to align the free-form predictions with the task-specificinstructions using finite-state machine guided constrained decoding.Additionally, an LLM-Judge verifies the final outputs to ensure high precision.Through extensive experiments on six datasets across five domains and nineLLMs, we demonstrate how DiCoRe consistently outperforms prior zero-shot,transfer-learning, and reasoning baselines, achieving 4-7% average F1 gainsover the best baseline -- establishing DiCoRe as a strong zero-shot EDframework.</description>
      <author>example@mail.com (Tanmay Parekh, Kartik Mehta, Ninareh Mehrabi, Kai-Wei Chang, Nanyun Peng)</author>
      <guid isPermaLink="false">2506.05128v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>AV-Reasoner: Improving and Benchmarking Clue-Grounded Audio-Visual Counting for MLLMs</title>
      <link>http://arxiv.org/abs/2506.05328v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了CG-AV-Counting，一个包含长视频的线索地面计数基准，旨在解决现有机器学习语言模型在计数任务上的困难。&lt;h4&gt;背景&lt;/h4&gt;尽管视频理解取得进展，但当前的多语言语言模型在计数任务上仍存在挑战，现有的基准测试存在视频短、查询集封闭、缺乏线索标注和弱多模态覆盖等问题。&lt;h4&gt;目的&lt;/h4&gt;提出CG-AV-Counting基准，支持黑盒和白盒评估，为端到端和基于推理的计数提供全面的测试平台。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含1,027个多模态问题和5,845个标注线索的基准，并提出AV-Reasoner模型，使用GRPO和课程学习来提高模型的计数能力。&lt;h4&gt;主要发现&lt;/h4&gt;AV-Reasoner在多个基准测试中取得了最先进的成果，证明了强化学习的效果。但实验表明，在域外基准测试中，语言空间中的推理未能带来性能提升。&lt;h4&gt;结论&lt;/h4&gt;CG-AV-Counting基准和AV-Reasoner模型为计数任务提供了新的解决方案，并揭示了强化学习在计数任务中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管在视频理解方面取得了进展，但当前的多语言语言模型在计数任务上仍面临挑战。现有的基准测试受限于短视频、封闭集查询、缺乏线索标注和弱多模态覆盖。在本文中，我们介绍了CG-AV-Counting，一个包含1,027个多模态问题和5,845个标注线索的线索地面计数基准，覆盖了497个长视频。它支持黑盒和白盒评估，作为一个全面的测试平台，用于端到端和基于推理的计数。为了探索提高模型计数能力的方法，我们提出了AV-Reasoner，一个使用GRPO和课程学习训练的模型，以从相关任务中泛化计数能力。AV-Reasoner在多个基准测试中取得了最先进的成果，证明了强化学习的效果。然而，实验表明，在域外基准测试中，语言空间中的推理未能带来性能提升。代码和基准已发布在https://av-reasoner.github.io。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite progress in video understanding, current MLLMs struggle with countingtasks. Existing benchmarks are limited by short videos, close-set queries, lackof clue annotations, and weak multimodal coverage. In this paper, we introduceCG-AV-Counting, a manually-annotated clue-grounded counting benchmark with1,027 multimodal questions and 5,845 annotated clues over 497 long videos. Itsupports both black-box and white-box evaluation, serving as a comprehensivetestbed for both end-to-end and reasoning-based counting. To explore ways toimprove model's counting capability, we propose AV-Reasoner, a model trainedwith GRPO and curriculum learning to generalize counting ability from relatedtasks. AV-Reasoner achieves state-of-the-art results across multiplebenchmarks, demonstrating the effectiveness of reinforcement learning. However,experiments show that on out-of-domain benchmarks, reasoning in the languagespace fails to bring performance gains. The code and benchmark have beenrealeased on https://av-reasoner.github.io.</description>
      <author>example@mail.com (Lidong Lu, Guo Chen, Zhiqi Li, Yicheng Liu, Tong Lu)</author>
      <guid isPermaLink="false">2506.05328v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Towards Language-Augmented Multi-Agent Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.05236v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在多智能体强化学习中，如何通过使智能体基于人类定义的语言来提高学习和协调能力。&lt;h4&gt;背景&lt;/h4&gt;以往的多智能体强化学习研究主要关注从头开始开发的自发通信协议，这些协议往往导致效率低下或不可解释的系统。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过引入人类定义的语言，改善多智能体在具有身体感知的智能体中的学习和协调。&lt;h4&gt;方法&lt;/h4&gt;提出了一种框架，其中智能体不仅被训练来执行动作，还被训练来产生和解释其观察的自然语言描述。这种语言增强的学习具有双重作用：实现智能体之间的明确通信并指导表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;使用本文提出方法训练的智能体在各种任务上优于传统的自发通信基线。分析显示，语言定位导致更丰富的内部表示，更好地泛化到新的合作伙伴，并提高了人机交互能力。&lt;h4&gt;结论&lt;/h4&gt;这些发现证明了将结构化语言集成到多智能体学习中的有效性，并为更可解释和强大的多智能体系统开辟了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Communication is a fundamental aspect of coordinated behavior in multi-agentreinforcement learning. Yet, most prior works in this field have focused onemergent communication protocols developed from scratch, often resulting ininefficient or non-interpretable systems. Inspired by the role of language innatural intelligence, we investigate how grounding agents in a human-definedlanguage can improve learning and coordination of multiple embodied agents. Wepropose a framework in which agents are trained not only to act but also toproduce and interpret natural language descriptions of their observations. Thislanguage-augmented learning serves a dual role: enabling explicit communicationbetween agents and guiding representation learning. We demonstrate that agentstrained with our method outperform traditional emergent communication baselinesacross various tasks. Our analysis reveals that language grounding leads tomore informative internal representations, better generalization to newpartners, and improved capability for human-agent interaction. These findingsdemonstrate the effectiveness of integrating structured language intomulti-agent learning and open avenues for more interpretable and capablemulti-agent systems.</description>
      <author>example@mail.com (Maxime Toquebiau, Jae-Yun Jun, Faïz Benamar, Nicolas Bredeche)</author>
      <guid isPermaLink="false">2506.05236v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Segmentation of Agricultural Vehicles using 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.05009v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新的生成真实合成数据的方法，用于训练神经网络，特别是针对3D点云语义分割任务。该方法通过3D高斯撒点（3DGS）和高斯不透明度场（GOF）生成多种农业车辆的3D资产，并在模拟环境中使用模拟激光雷达生成点云，以降低数据获取和标注的成本。&lt;h4&gt;背景&lt;/h4&gt;训练神经网络进行3D点云语义分割需要大量数据集，但获取和标注真实世界的点云既昂贵又费时。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的数据生成流程，以降低生成真实合成数据所需的高成本和劳动力。&lt;h4&gt;方法&lt;/h4&gt;利用3D高斯撒点（3DGS）和高斯不透明度场（GOF）生成3D资产，并将其放置在模拟环境中，使用模拟激光雷达生成点云，以实现灵活的流程。&lt;h4&gt;主要发现&lt;/h4&gt;使用合成数据训练的PointNet++、Point Transformer V3和OACNN模型表现出色，其中PTv3模型在mIoU指标上达到91.35%，且未在真实数据上训练或验证。此外，在某些场景中，仅使用合成数据训练的模型甚至优于使用真实数据训练的模型。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够生成适用于神经网络训练的合成数据，且在某些情况下，仅使用合成数据训练的模型在性能上优于使用真实数据训练的模型。&lt;h4&gt;翻译&lt;/h4&gt;This study proposes a novel pipeline for generating realistic synthetic data for training neural networks, especially for tasks such as 3D point cloud semantic segmentation. The method utilizes 3D Gaussian Splatting (3DGS) and Gaussian Opacity Fields (GOF) to generate 3D assets of various agricultural vehicles and places them in a simulated environment, where point clouds are generated using a simulated LiDAR, to reduce the costs and labor involved in data acquisition and annotation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training neural networks for tasks such as 3D point cloud semanticsegmentation demands extensive datasets, yet obtaining and annotatingreal-world point clouds is costly and labor-intensive. This work aims tointroduce a novel pipeline for generating realistic synthetic data, byleveraging 3D Gaussian Splatting (3DGS) and Gaussian Opacity Fields (GOF) togenerate 3D assets of multiple different agricultural vehicles instead of usinggeneric models. These assets are placed in a simulated environment, where thepoint clouds are generated using a simulated LiDAR. This is a flexible approachthat allows changing the LiDAR specifications without incurring additionalcosts. We evaluated the impact of synthetic data on segmentation models such asPointNet++, Point Transformer V3, and OACNN, by training and validating themodels only on synthetic data. Remarkably, the PTv3 model had an mIoU of91.35\%, a noteworthy result given that the model had neither been trained norvalidated on any real data. Further studies even suggested that in certainscenarios the models trained only on synthetically generated data performedbetter than models trained on real-world data. Finally, experimentsdemonstrated that the models can generalize across semantic classes, enablingaccurate predictions on mesh models they were never trained on.</description>
      <author>example@mail.com (Alfred T. Christiansen, Andreas H. Højrup, Morten K. Stephansen, Md Ibtihaj A. Sakib, Taman S. Poojary, Filip Slezak, Morten S. Laursen, Thomas B. Moeslund, Joakim B. Haurum)</author>
      <guid isPermaLink="false">2506.05009v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Spatiotemporal Contrastive Learning for Cross-View Video Localization in Unstructured Off-road Terrains</title>
      <link>http://arxiv.org/abs/2506.05250v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为MoViX的自监督跨视图视频定位框架，用于在无GPS的越野环境中进行鲁棒的3自由度定位。&lt;h4&gt;背景&lt;/h4&gt;在无GPS的越野环境中进行3自由度定位具有挑战性，原因包括感知模糊（重复的植被和未结构化的地形）以及季节性变化导致场景外观显著变化。&lt;h4&gt;目的&lt;/h4&gt;MoViX旨在学习视点和季节不变的表达，同时保持方向感知，这对于准确定位至关重要。&lt;h4&gt;方法&lt;/h4&gt;MoViX采用姿势依赖的正样本采样策略来增强方向辨别，以及时间对齐的硬负样本挖掘来避免从季节性线索中快速学习。运动信息帧采样器选择空间上多样的帧，而轻量级时间聚合器强调几何上对齐的观测，同时降低模糊观测的权重。&lt;h4&gt;主要发现&lt;/h4&gt;MoViX在TartanDrive 2.0数据集上进行了评估，在不到30分钟的训练数据和超过12.29公里的测试数据上表现出色，即使是在过时的卫星影像下，MoViX也有93%的时间在25米内定位到真实地面，100%的时间在未知区域内定位在50米内。&lt;h4&gt;结论&lt;/h4&gt;MoViX在未对特定环境进行调优的情况下，优于现有基准，并在一个地理上不同的场地和一个不同的机器人平台上展示了泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Robust cross-view 3-DoF localization in GPS-denied, off-road environmentsremains challenging due to (1) perceptual ambiguities from repetitivevegetation and unstructured terrain, and (2) seasonal shifts that significantlyalter scene appearance, hindering alignment with outdated satellite imagery. Toaddress this, we introduce MoViX, a self-supervised cross-view video localiza-tion framework that learns viewpoint- and season-invariant representations while preserving directional awareness essential for accurate localization. MoViX employs a pose-dependent positive sampling strategy to enhance directional discrimination and temporally aligned hard negative mining to discourage shortcut learning from seasonal cues. A motion-informed frame sampler selects spatially diverse frames, and a lightweight temporal aggregatoremphasizes geometrically aligned observations while downweighting ambiguous ones. At inference, MoViX runs within a Monte Carlo Localization framework, using a learned cross-view matching module in place of handcrafted models. Entropy-guided temperature scaling enables robust multi-hypothesis tracking and confident convergence under visual ambiguity. We evaluate MoViX on the TartanDrive 2.0 dataset, training on under 30 minutes of data and testing over 12.29 km. Despite outdated satellite imagery, MoViX localizes within 25 meters of ground truth 93% of the time, and within 50 meters 100% of the time in unseen regions, outperforming state-of-the-art baselines without environment-specific tuning. We further demonstrate generalization on a real-world off-road dataset from a geographically distinct site with a different robot platform.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust cross-view 3-DoF localization in GPS-denied, off-road environmentsremains challenging due to (1) perceptual ambiguities from repetitivevegetation and unstructured terrain, and (2) seasonal shifts that significantlyalter scene appearance, hindering alignment with outdated satellite imagery. Toaddress this, we introduce MoViX, a self-supervised cross-view videolocalization framework that learns viewpoint- and season-invariantrepresentations while preserving directional awareness essential for accuratelocalization. MoViX employs a pose-dependent positive sampling strategy toenhance directional discrimination and temporally aligned hard negative miningto discourage shortcut learning from seasonal cues. A motion-informed framesampler selects spatially diverse frames, and a lightweight temporal aggregatoremphasizes geometrically aligned observations while downweighting ambiguousones. At inference, MoViX runs within a Monte Carlo Localization framework,using a learned cross-view matching module in place of handcrafted models.Entropy-guided temperature scaling enables robust multi-hypothesis tracking andconfident convergence under visual ambiguity. We evaluate MoViX on theTartanDrive 2.0 dataset, training on under 30 minutes of data and testing over12.29 km. Despite outdated satellite imagery, MoViX localizes within 25 metersof ground truth 93% of the time, and within 50 meters 100% of the time inunseen regions, outperforming state-of-the-art baselines withoutenvironment-specific tuning. We further demonstrate generalization on areal-world off-road dataset from a geographically distinct site with adifferent robot platform.</description>
      <author>example@mail.com (Zhiyun Deng, Dongmyeong Lee, Amanda Adkins, Jesse Quattrociocchi, Christian Ellis, Joydeep Biswas)</author>
      <guid isPermaLink="false">2506.05250v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Towards Vision-Language-Garment Models For Web Knowledge Garment Understanding and Generation</title>
      <link>http://arxiv.org/abs/2506.05210v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at MMFM CVPRW'25, code available at  https://georgenakayama.github.io/AIpparel/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为VLG的视觉-语言-服装模型，该模型可以从文本描述和视觉图像中合成服装，并评估其在未知服装风格和提示下的零样本泛化能力。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型在泛化方面表现出色，但其在服装生成等特定领域的知识迁移能力尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;研究VLG模型在服装生成领域的应用，特别是其将网络规模推理迁移到未见过的服装风格和提示的能力。&lt;h4&gt;方法&lt;/h4&gt;通过实验评估VLG的零样本泛化能力，并探究其在服装设计等特定领域的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;初步结果表明VLG模型在知识迁移方面具有潜力，显示出多模态基础模型在适应特定领域如时尚设计方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;多模态基础模型在特定领域如时尚设计中的适应性是值得进一步研究的方向。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal foundation models have demonstrated strong generalization, yet their ability to transfer knowledge to specialized domains such as garment generation remains underexplored. We introduce VLG, a vision-language-garment model that synthesizes garments from textual descriptions and visual imagery. Our experiments assess VLG's zero-shot generalization, investigating its ability to transfer web-scale reasoning to unseen garment styles and prompts. Preliminary results indicate promising transfer capabilities, highlighting the potential for multimodal foundation models to adapt effectively to specialized domains like fashion design.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal foundation models have demonstrated strong generalization, yettheir ability to transfer knowledge to specialized domains such as garmentgeneration remains underexplored. We introduce VLG, a vision-language-garmentmodel that synthesizes garments from textual descriptions and visual imagery.Our experiments assess VLG's zero-shot generalization, investigating itsability to transfer web-scale reasoning to unseen garment styles and prompts.Preliminary results indicate promising transfer capabilities, highlighting thepotential for multimodal foundation models to adapt effectively to specializeddomains like fashion design.</description>
      <author>example@mail.com (Jan Ackermann, Kiyohiro Nakayama, Guandao Yang, Tong Wu, Gordon Wetzstein)</author>
      <guid isPermaLink="false">2506.05210v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>GEX: Democratizing Dexterity with Fully-Actuated Dexterous Hand and Exoskeleton Glove</title>
      <link>http://arxiv.org/abs/2506.04982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GEX的创新低成本灵巧操作系统，该系统结合了GX11三指类人手（11自由度）和EX12三指外骨骼手套（12自由度），通过运动学重定向形成闭环遥操作框架，实现高保真控制。系统组件采用模块化3D打印手指设计，在保持完全驱动能力的同时，实现了超低制造成本。&lt;h4&gt;背景&lt;/h4&gt;传统的灵巧操作研究存在成本和性能之间的差距。&lt;h4&gt;目的&lt;/h4&gt;提出一种低成本、高性能的灵巧操作系统，以促进具身人工智能和灵巧机器人技能的迁移学习。&lt;h4&gt;方法&lt;/h4&gt;GEX系统采用模块化3D打印手指设计，并集成独立关节电机，实现所有23个自由度的完全驱动，确保完整的状态可观测性和精确的运动学建模。&lt;h4&gt;主要发现&lt;/h4&gt;GEX系统通过全驱动架构实现了精确的双向运动学计算，显著提高了外骨骼和机器人手之间的运动学重定向保真度。&lt;h4&gt;结论&lt;/h4&gt;GEX系统解决了灵巧操作研究中的成本性能差距，为获取高质量演示数据提供了可访问的平台，以推动具身人工智能和灵巧机器人技能的迁移学习。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces GEX, an innovative low-cost dexterous manipulationsystem that combines the GX11 tri-finger anthropomorphic hand (11 DoF) with theEX12 tri-finger exoskeleton glove (12 DoF), forming a closed-loop teleoperationframework through kinematic retargeting for high-fidelity control. Bothcomponents employ modular 3D-printed finger designs, achieving ultra-lowmanufacturing costs while maintaining full actuation capabilities. Departingfrom conventional tendon-driven or underactuated approaches, our electromechanicalsystem integrates independent joint motors across all 23 DoF, ensuring completestate observability and accurate kinematic modeling. This full-actuationarchitecture enables precise bidirectional kinematic calculations, substantiallyenhancing kinematic retargeting fidelity between the exoskeleton and robotic hand. Theproposed system bridges the cost-performance gap in dexterous manipulation research,providing an accessible platform for acquiring high-quality demonstration data toadvance embodied AI and dexterous robotic skill transfer learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces GEX, an innovative low-cost dexterous manipulationsystem that combines the GX11 tri-finger anthropomorphic hand (11 DoF) with theEX12 tri-finger exoskeleton glove (12 DoF), forming a closed-loop teleoperationframework through kinematic retargeting for high-fidelity control. Bothcomponents employ modular 3D-printed finger designs, achieving ultra-lowmanufacturing costs while maintaining full actuation capabilities. Departingfrom conventional tendon-driven or underactuated approaches, ourelectromechanical system integrates independent joint motors across all 23 DoF,ensuring complete state observability and accurate kinematic modeling. Thisfull-actuation architecture enables precise bidirectional kinematiccalculations, substantially enhancing kinematic retargeting fidelity betweenthe exoskeleton and robotic hand. The proposed system bridges thecost-performance gap in dexterous manipulation research, providing anaccessible platform for acquiring high-quality demonstration data to advanceembodied AI and dexterous robotic skill transfer learning.</description>
      <author>example@mail.com (Yunlong Dong, Xing Liu, Jun Wan, Zelin Deng)</author>
      <guid isPermaLink="false">2506.04982v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Through-the-Wall Radar Human Activity Recognition WITHOUT Using Neural Networks</title>
      <link>http://arxiv.org/abs/2506.05169v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 8 figures, 8 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过墙体雷达（TWR）进行人体活动识别（HAR）的新方法，旨在挑战传统的基于神经网络模型的方法。&lt;h4&gt;背景&lt;/h4&gt;通过墙体雷达进行人体活动识别的研究已有数年，但研究者似乎陷入了仅通过神经网络模型在雷达图像数据上训练的思维定势。&lt;h4&gt;目的&lt;/h4&gt;尝试回到原始的研究路径，避免使用神经网络，以实现TWR-HAR任务，并挑战通过神经网络模型实现智能识别。&lt;h4&gt;方法&lt;/h4&gt;首先生成TWR的时域图和多普勒时域图，然后使用角点检测方法确定人体目标前景和噪声背景的初始区域，接着使用多相主动轮廓模型对微多普勒特征进行分割，并将分割特征离散化为二维点云。最后，使用Mapper算法计算结果点云与模板数据点云之间的拓扑相似度，以获得识别结果。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过数值模拟和测量实验证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法有效避免了神经网络的使用，为TWR-HAR任务提供了一种新的思路。&lt;h4&gt;翻译&lt;/h4&gt;After a few years of research in the field of through-the-wall radar (TWR) human activity recognition (HAR), I found that we seem to be stuck in the mindset of training on radar image data through neural network models. The earliest related works in this field based on template matching did not require a training process, and I believe they have never died. Because these methods possess a strong physical interpretability and are closer to the basis of theoretical signal processing research. In this paper, I would like to try to return to the original path by attempting to eschew neural networks to achieve the TWR HAR task and challenge to achieve intelligent recognition as neural network models. In detail, the range-time map and Doppler-time map of TWR are first generated. Then, the initial regions of the human target foreground and noise background on the maps are determined using corner detection method, and the micro-Doppler signature is segmented using the multiphase active contour model. The micro-Doppler segmentation feature is discretized into a two-dimensional point cloud. Finally, the topological similarity between the resulting point cloud and the point clouds of the template data is calculated using Mapper algorithm to obtain the recognition results. The effectiveness of the proposed method is demonstrated by numerical simulated and measured experiments. The open-source code of this work is released at: https://github.com/JoeyBGOfficial/Through-the-Wall-Radar-Human-Activity-Recognition-Without-Using-Neural-Networks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; After a few years of research in the field of through-the-wall radar (TWR)human activity recognition (HAR), I found that we seem to be stuck in themindset of training on radar image data through neural network models. Theearliest related works in this field based on template matching did not requirea training process, and I believe they have never died. Because these methodspossess a strong physical interpretability and are closer to the basis oftheoretical signal processing research. In this paper, I would like to try toreturn to the original path by attempting to eschew neural networks to achievethe TWR HAR task and challenge to achieve intelligent recognition as neuralnetwork models. In detail, the range-time map and Doppler-time map of TWR arefirst generated. Then, the initial regions of the human target foreground andnoise background on the maps are determined using corner detection method, andthe micro-Doppler signature is segmented using the multiphase active contourmodel. The micro-Doppler segmentation feature is discretized into atwo-dimensional point cloud. Finally, the topological similarity between theresulting point cloud and the point clouds of the template data is calculatedusing Mapper algorithm to obtain the recognition results. The effectiveness ofthe proposed method is demonstrated by numerical simulated and measuredexperiments. The open-source code of this work is released at:https://github.com/JoeyBGOfficial/Through-the-Wall-Radar-Human-Activity-Recognition-Without-Using-Neural-Networks.</description>
      <author>example@mail.com (Weicheng Gao)</author>
      <guid isPermaLink="false">2506.05169v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Single GPU Task Adaptation of Pathology Foundation Models for Whole Slide Image Analysis</title>
      <link>http://arxiv.org/abs/2506.05184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TAPFM的新方法，用于单GPU任务适配病理基础模型（PFM），该方法利用视觉Transformer（ViT）的注意力机制进行多实例学习（MIL）聚合，并优化特征表示和注意力权重，从而在膀胱癌和肺癌突变预测任务中优于传统方法。&lt;h4&gt;背景&lt;/h4&gt;病理基础模型（PFM）在分析全切片图像（WSI）方面表现出强大的能力，但针对特定临床任务进行预训练PFM的适配存在挑战，主要是因为大像素图像只有弱标签（WSI级标签），需要使用MIL范式进行有效的WSI分析。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以实现预训练PFM在标准硬件上的实际适配，用于各种临床应用。&lt;h4&gt;方法&lt;/h4&gt;TAPFM方法使用视觉Transformer（ViT）的注意力机制进行MIL聚合，并优化特征表示和注意力权重，同时保持MIL聚合器和PFM的计算图分离，以创建与下游任务目标一致的稳定训练动态。&lt;h4&gt;主要发现&lt;/h4&gt;在膀胱癌和肺癌突变预测任务中，TAPFM在机构间和TCGA队列上均优于传统方法，其中H-Optimus-0（TAPFM）优于基准。TAPFM还有效地处理了可操作突变的多元分类。&lt;h4&gt;结论&lt;/h4&gt;TAPFM使得在标准硬件上对强大的预训练PFM进行适配成为可能，适用于各种临床应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：病理基础模型（PFMs）已成为分析全切片图像（WSIs）的有力工具。然而，针对特定临床任务适配这些预训练PFM存在相当大的挑战，主要是因为只有弱（WSI级）标签可用于吉像素图像，需要使用多实例学习（MIL）范式进行有效的WSI分析。本文提出了一种名为TAPFM的新方法，用于单GPU任务适配PFM（TAPFM），该方法使用视觉Transformer（ViT）的注意力机制进行MIL聚合，同时优化特征表示和注意力权重。所提出的方法为MIL聚合器和PFM保持独立的计算图，以创建与端到端适配期间的下游任务目标一致的稳定训练动态。在膀胱癌和肺癌腺癌的突变预测任务中，对机构间和TCGA队列进行了评估，TAPFM始终优于传统方法，其中H-Optimus-0（TAPFM）优于基准。TAPFM还有效地处理了可操作突变的多元分类。因此，TAPFM使得在标准硬件上对强大的预训练PFM进行适配成为可能，适用于各种临床应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pathology foundation models (PFMs) have emerged as powerful tools foranalyzing whole slide images (WSIs). However, adapting these pretrained PFMsfor specific clinical tasks presents considerable challenges, primarily due tothe availability of only weak (WSI-level) labels for gigapixel images,necessitating multiple instance learning (MIL) paradigm for effective WSIanalysis. This paper proposes a novel approach for single-GPU \textbf{T}ask\textbf{A}daptation of \textbf{PFM}s (TAPFM) that uses vision transformer(\vit) attention for MIL aggregation while optimizing both for featurerepresentations and attention weights. The proposed approach maintains separatecomputational graphs for MIL aggregator and the PFM to create stable trainingdynamics that align with downstream task objectives during end-to-endadaptation. Evaluated on mutation prediction tasks for bladder cancer and lungadenocarcinoma across institutional and TCGA cohorts, TAPFM consistentlyoutperforms conventional approaches, with H-Optimus-0 (TAPFM) outperforming thebenchmarks. TAPFM effectively handles multi-label classification of actionablemutations as well. Thus, TAPFM makes adaptation of powerful pre-trained PFMspractical on standard hardware for various clinical applications.</description>
      <author>example@mail.com (Neeraj Kumar, Swaraj Nanda, Siddharth Singi, Jamal Benhamida, David Kim, Jie-Fu Chen, Amir Momeni-Boroujeni, Gregory M. Goldgof, Gabriele Campanella, Chad Vanderbilt)</author>
      <guid isPermaLink="false">2506.05184v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>ProJo4D: Progressive Joint Optimization for Sparse-View Inverse Physics Estimation</title>
      <link>http://arxiv.org/abs/2506.05317v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了ProJo4D，一个渐进式联合优化框架，用于解决神经渲染中的物理问题，提高了在3D重建和新型视图合成中的应用效果。&lt;h4&gt;背景&lt;/h4&gt;神经渲染在3D重建和新型视图合成方面取得了显著进展，但将物理融入其中仍面临挑战，限制了其在机器人学和XR中的数字孪生创建等应用中的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过逐步增加联合优化参数的集合，以解决现有方法在稀疏多视图视频输入下的误差累积问题。&lt;h4&gt;方法&lt;/h4&gt;ProJo4D通过逐步增加联合优化参数的集合，引导参数敏感度，最终实现几何、外观、物理状态和材料属性的完全联合优化。&lt;h4&gt;主要发现&lt;/h4&gt;在PAC-NeRF和Spring-Gaus数据集上的评估表明，ProJo4D在4D未来状态预测、未来状态的全新视图渲染以及材料参数估计方面优于先前的工作。&lt;h4&gt;结论&lt;/h4&gt;ProJo4D在基于物理的4D场景理解方面表现出有效性，为3D重建和新型视图合成提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：神经渲染在3D重建和新型视图合成方面取得了显著进展。与物理学的结合开辟了新的应用。然而，从视觉数据中估计物理的逆问题仍然具有挑战性，限制了其在机器人学和XR中用于创建物理精确数字孪生等应用中的有效性。将物理融入神经渲染框架的现有方法通常需要密集的多视图视频作为输入，这使得它们在实际应用中不切实际。当面对稀疏的多视图视频时，现有方法使用的顺序优化策略引入了显著的误差累积，例如，糟糕的初始3D重建会导致后续阶段的材料参数估计不良。与顺序优化不同，由于问题的非凸性和通常不可微的性质，同时直接优化所有参数也失败了。我们提出了ProJo4D，一个渐进式联合优化框架，它根据参数的敏感性逐步增加联合优化的参数集，导致对几何、外观、物理状态和材料属性的完全联合优化。在PAC-NeRF和Spring-Gaus数据集上的评估表明，ProJo4D在4D未来状态预测、未来状态的全新视图渲染和材料参数估计方面优于先前的工作，证明了它在基于物理的4D场景理解方面的有效性。有关演示，请访问项目网页：https://daniel03c1.github.io/ProJo4D/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural rendering has made significant strides in 3D reconstruction and novelview synthesis. With the integration with physics, it opens up newapplications. The inverse problem of estimating physics from visual data,however, still remains challenging, limiting its effectiveness for applicationslike physically accurate digital twin creation in robotics and XR. Existingmethods that incorporate physics into neural rendering frameworks typicallyrequire dense multi-view videos as input, making them impractical for scalable,real-world use. When presented with sparse multi-view videos, the sequentialoptimization strategy used by existing approaches introduces significant erroraccumulation, e.g., poor initial 3D reconstruction leads to bad materialparameter estimation in subsequent stages. Instead of sequential optimization,directly optimizing all parameters at the same time also fails due to thehighly non-convex and often non-differentiable nature of the problem. Wepropose ProJo4D, a progressive joint optimization framework that graduallyincreases the set of jointly optimized parameters guided by their sensitivity,leading to fully joint optimization over geometry, appearance, physical state,and material property. Evaluations on PAC-NeRF and Spring-Gaus datasets showthat ProJo4D outperforms prior work in 4D future state prediction, novel viewrendering of future state, and material parameter estimation, demonstrating itseffectiveness in physically grounded 4D scene understanding. For demos, pleasevisit the project webpage: https://daniel03c1.github.io/ProJo4D/</description>
      <author>example@mail.com (Daniel Rho, Jun Myeong Choi, Biswadip Dey, Roni Sengupta)</author>
      <guid isPermaLink="false">2506.05317v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating Degree Bias Adaptively with Hard-to-Learn Nodes in Graph Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.05214v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HAR的对比学习损失函数，用于减轻图神经网络在节点分类任务中的度偏问题，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在节点分类任务中常受到度偏的影响，即预测性能在不同度数的节点之间有所差异。&lt;h4&gt;目的&lt;/h4&gt;提出HAR对比学习损失函数，以减轻节点分类任务中的度偏问题。&lt;h4&gt;方法&lt;/h4&gt;HAR通过利用节点标签添加更多的正对，并根据学习难度自适应地加权正负对。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SHARP在四个数据集上均优于基线方法，无论是在全局层面还是在度层面。&lt;h4&gt;结论&lt;/h4&gt;HAR对比学习损失函数能够有效减轻图神经网络中的度偏问题，并提高节点分类任务的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) often suffer from degree bias in node classification tasks, where prediction performance varies across nodes with different degrees. Several approaches, which adopt Graph Contrastive Learning (GCL), have been proposed to mitigate this bias. However, the limited number of positive pairs and the equal weighting of all positives and negatives in GCL still lead to low-degree nodes acquiring insufficient and noisy information. This paper proposes the Hardness Adaptive Reweighted (HAR) contrastive loss to mitigate degree bias. It adds more positive pairs by leveraging node labels and adaptively weights positive and negative pairs based on their learning hardness. In addition, we develop an experimental framework named SHARP to extend HAR to a broader range of scenarios. Both our theoretical analysis and experiments validate the effectiveness of SHARP. The experimental results across four datasets show that SHARP achieves better performance against baselines at both global and degree levels.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) often suffer from degree bias in nodeclassification tasks, where prediction performance varies across nodes withdifferent degrees. Several approaches, which adopt Graph Contrastive Learning(GCL), have been proposed to mitigate this bias. However, the limited number ofpositive pairs and the equal weighting of all positives and negatives in GCLstill lead to low-degree nodes acquiring insufficient and noisy information.This paper proposes the Hardness Adaptive Reweighted (HAR) contrastive loss tomitigate degree bias. It adds more positive pairs by leveraging node labels andadaptively weights positive and negative pairs based on their learninghardness. In addition, we develop an experimental framework named SHARP toextend HAR to a broader range of scenarios. Both our theoretical analysis andexperiments validate the effectiveness of SHARP. The experimental resultsacross four datasets show that SHARP achieves better performance againstbaselines at both global and degree levels.</description>
      <author>example@mail.com (Jingyu Hu, Hongbo Bo, Jun Hong, Xiaowei Liu, Weiru Liu)</author>
      <guid isPermaLink="false">2506.05214v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>iN2V: Bringing Transductive Node Embeddings to Inductive Graphs</title>
      <link>http://arxiv.org/abs/2506.05039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为iN2V的节点嵌入方法，用于在训练过程中处理未见过的节点，并将其应用于归纳学习场景。&lt;h4&gt;背景&lt;/h4&gt;传统的节点嵌入方法如node2vec在处理未见过的节点时存在局限性，只能应用于训练过程中包含所有节点的有向图（transductive）。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够处理未见节点并适用于归纳学习场景的节点嵌入方法。&lt;h4&gt;方法&lt;/h4&gt;iN2V结合了后处理计算未见节点嵌入的方法，并对原始node2vec的训练过程进行了修改，以准备后处理步骤。&lt;h4&gt;主要发现&lt;/h4&gt;iN2V在多个基准数据集上进行了实验，结果表明iN2V能够有效地将归纳嵌入应用于归纳学习场景，平均提高了节点分类1分，最大改进可达6分。&lt;h4&gt;结论&lt;/h4&gt;iN2V是一种插件式方法，可以创建新的或丰富现有的嵌入，并可以与其他嵌入方法结合使用，是一种灵活的归纳节点表示学习方法。&lt;h4&gt;翻译&lt;/h4&gt;Shallow node embeddings like node2vec (N2V) can be used for nodes without features or to supplement existing features with structure-based information. Embedding methods like N2V are limited in their application on new nodes, which restricts them to the transductive setting where the entire graph, including the test nodes, is available during training. We propose inductive node2vec (iN2V), which combines a post-hoc procedure to compute embeddings for nodes unseen during training and modifications to the original N2V training procedure to prepare the embeddings for this post-hoc procedure. We conduct experiments on several benchmark datasets and demonstrate that iN2V is an effective approach to bringing transductive embeddings to an inductive setting. Using iN2V embeddings improves node classification by 1 point on average, with up to 6 points of improvement depending on the dataset and the number of unseen nodes. Our iN2V is a plug-in approach to create new or enrich existing embeddings. It can also be combined with other embedding methods, making it a versatile approach for inductive node representation learning. Code to reproduce the results is available at https://github.com/Foisunt/iN2V .&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Shallow node embeddings like node2vec (N2V) can be used for nodes withoutfeatures or to supplement existing features with structure-based information.Embedding methods like N2V are limited in their application on new nodes, whichrestricts them to the transductive setting where the entire graph, includingthe test nodes, is available during training. We propose inductive node2vec(iN2V), which combines a post-hoc procedure to compute embeddings for nodesunseen during training and modifications to the original N2V training procedureto prepare the embeddings for this post-hoc procedure. We conduct experimentson several benchmark datasets and demonstrate that iN2V is an effectiveapproach to bringing transductive embeddings to an inductive setting. UsingiN2V embeddings improves node classification by 1 point on average, with up to6 points of improvement depending on the dataset and the number of unseennodes. Our iN2V is a plug-in approach to create new or enrich existingembeddings. It can also be combined with other embedding methods, making it aversatile approach for inductive node representation learning. Code toreproduce the results is available at https://github.com/Foisunt/iN2V .</description>
      <author>example@mail.com (Nicolas Lell, Ansgar Scherp)</author>
      <guid isPermaLink="false">2506.05039v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Learning Intrinsic Alignments from Local Galaxy Environments</title>
      <link>http://arxiv.org/abs/2506.05155v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为DELTA的深度学习模型，该模型能够从观测数据中分离出星系内在对齐（IAs）和弱引力透镜畸变，并使用等变图神经网络来捕捉局部星系环境信息。&lt;h4&gt;背景&lt;/h4&gt;在星系研究中，内在对齐是指星系在空间中的分布模式，它可能受到潮汐力的作用。&lt;h4&gt;目的&lt;/h4&gt;DELTA模型旨在通过不依赖模拟和假设特定对齐形式来学习星系形状与其局部环境之间的关系。&lt;h4&gt;方法&lt;/h4&gt;DELTA模型使用等变图神经网络作为骨干网络，并具有概率性方向输出，能够灵活地学习星系形状与局部环境之间的联系。&lt;h4&gt;主要发现&lt;/h4&gt;DELTA模型在包含真实噪声对齐信号的模拟目录中能够准确重建无噪声的纯对齐信号，并通过映射这些对齐来直观地展示模拟目录中的对齐模式。&lt;h4&gt;结论&lt;/h4&gt;将DELTA模型与深度学习解释技术相结合，可以进一步了解驱动星系间潮汐关系的物理机制。这种方法适用于联合光度和光谱调查，如即将到来的Euclid、Rubin和DESI数据集的组合。&lt;h4&gt;翻译&lt;/h4&gt;我们提出DELTA（数据经验学习潮汐对齐），一种深度学习模型，它仅使用观测数据从弱引力透镜畸变中分离出星系内在对齐（IAs）。该模型使用适合捕捉局部星系环境信息的等变图神经网络骨干，并结合概率性方向输出。与参数模型不同，DELTA灵活地学习星系形状与其局部环境之间的关系，而不假设显式的IA形式或依赖于模拟。当应用于包含真实噪声对齐信号的模拟目录时，它能够准确重建无噪声的纯对齐信号。通过映射这些对齐提供了对模拟目录中IA模式的直接可视化。将DELTA与深度学习解释技术相结合提供了对驱动星系间潮汐关系的物理机制的进一步了解。这种理解和控制IAs的新方法适用于应用联合光度和光谱调查，如即将到来的Euclid、Rubin和DESI数据集的组合。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present DELTA (Data-Empiric Learned Tidal Alignments), a deep learningmodel that isolates galaxy intrinsic alignments (IAs) from weak lensingdistortions using only observational data. The model uses an Equivariant GraphNeural Network backbone suitable for capturing information from the localgalaxy environment, in conjunction with a probabilistic orientation output.Unlike parametric models, DELTA flexibly learns the relationship between galaxyshapes and their local environments, without assuming an explicit IA form orrelying on simulations. When applied to mock catalogs with realistic noisy IAsinjected, it accurately reconstructs the noise-free, pure IA signal. Mappingthese alignments provides a direct visualization of IA patterns in the mockcatalogs. Combining DELTA with deep learning interpretation techniques providesfurther insights into the physics driving tidal relationships between galaxies.This new approach to understanding and controlling IAs is suitable forapplication to joint photometric and spectroscopic surveys such as thecombination of upcoming Euclid, Rubin, and DESI datasets.</description>
      <author>example@mail.com (Matthew Craigie, Eric Huff, Yuan-Sen Ting, Rossana Ruggeri, Tamara M. Davis)</author>
      <guid isPermaLink="false">2506.05155v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>OpenMaskDINO3D : Reasoning 3D Segmentation via Large Language Model</title>
      <link>http://arxiv.org/abs/2506.04837v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://github.com/Zhangkuns/OpenMaskDINO3D&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了OpenMaskDINO3D，一个用于全面3D理解和分割的LLM，它在处理点云数据和文本提示以生成实例分割掩码方面表现出色，并在多个3D任务中表现出高效。&lt;h4&gt;背景&lt;/h4&gt;尽管感知系统在二维推理分割方面取得了显著进步，但它们仍然依赖于明确的人类指令或预定义的类别来识别目标对象，而在三维推理分割方面，类似的框架和结构尚不存在。&lt;h4&gt;目的&lt;/h4&gt;提出OpenMaskDINO3D，以实现从自然语言指令直接生成精确点云分割结果的目标。&lt;h4&gt;方法&lt;/h4&gt;OpenMaskDINO3D通过处理点云数据和文本提示，结合SEG标记和对象标识符，实现了高精度的3D分割掩码生成。&lt;h4&gt;主要发现&lt;/h4&gt;在ScanNet数据集上的实验结果表明，OpenMaskDINO3D在多种任务中验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;OpenMaskDINO3D为3D推理分割提供了一种新的解决方案，能够从自然语言指令中直接生成精确的点云分割结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although perception systems have made remarkable advancements in recentyears, particularly in 2D reasoning segmentation, these systems still rely onexplicit human instruction or pre-defined categories to identify target objectsbefore executing visual recognition tasks. Such systems have maturedsignificantly, demonstrating the ability to reason and comprehend implicit userintentions in two-dimensional contexts, producing accurate segmentation masksbased on complex and implicit query text. However, a comparable framework andstructure for 3D reasoning segmentation remain absent. This paper introducesOpenMaskDINO3D, a LLM designed for comprehensive 3D understanding andsegmentation. OpenMaskDINO3D processes point cloud data and text prompts toproduce instance segmentation masks, excelling in many 3D tasks. By introducinga SEG token and object identifier, we achieve high-precision 3D segmentationmask generation, enabling the model to directly produce accurate point cloudsegmentation results from natural language instructions. Experimental resultson large-scale ScanNet datasets validate the effectiveness of ourOpenMaskDINO3D across various tasks.</description>
      <author>example@mail.com (Kunshen Zhang)</author>
      <guid isPermaLink="false">2506.04837v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>TextVidBench: A Benchmark for Long Video Scene Text Understanding</title>
      <link>http://arxiv.org/abs/2506.04983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TextVidBench，这是一个针对长视频文本问答任务的新基准，旨在解决现有数据集在视频时长和评估范围上的限制。&lt;h4&gt;背景&lt;/h4&gt;尽管在短视频文本视觉问答任务上取得了进展，但现有数据集仍存在视频时长有限和评估范围狭窄的问题，这难以充分评估强大多模态大语言模型的能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些限制，提出TextVidBench，以促进长视频理解能力的评估。&lt;h4&gt;方法&lt;/h4&gt;TextVidBench具有以下特点：1) 跨域长视频覆盖，包括9个类别，平均视频长度为2306秒；2) 三阶段评估框架：文本针插 haystack -&gt; 时间定位 -&gt; 文本动态描述；3) 高质量细粒度标注，包含超过5000个问题-答案对及详细语义标签。&lt;h4&gt;主要发现&lt;/h4&gt;TextVidBench对现有模型提出了重大挑战，而提出的方法为改进长视频场景文本理解能力提供了有价值的见解。&lt;h4&gt;结论&lt;/h4&gt;TextVidBench的引入为长视频文本问答任务提供了更全面的评估平台，有助于推动相关技术的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管在短视频文本视觉问答任务上取得了进展，但现有数据集仍存在视频时长有限和评估范围狭窄的问题，这难以充分评估强大多模态大语言模型的能力。为了解决这些限制，我们提出了TextVidBench，这是第一个专门为长视频文本问答（&gt;3分钟）设计的基准。TextVidBench有三个关键贡献：1) 跨领域长视频覆盖：涵盖9个类别（例如新闻、体育、游戏），平均视频长度为2306秒，使长视频理解的评估更加真实。2) 三阶段评估框架：“文本针插 haystack -&gt; 时间定位 -&gt; 文本动态描述”。3) 高质量细粒度标注：包含超过5000个问题-答案对及详细语义标签。此外，我们提出了一种高效的方法来提高大模型：通过（i）引入IT-Rope机制和时间提示工程来增强时间感知，（ii）采用非均匀位置编码以更好地处理长视频序列，（iii）对视频-文本数据应用轻量级微调。在多个公开数据集以及TextVidBench上的广泛实验表明，我们的新基准对现有模型提出了重大挑战，而我们的方法为提高长视频场景文本理解能力提供了有价值的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite recent progress on the short-video Text-Visual Question Answering(ViteVQA) task - largely driven by benchmarks such as M4-ViteVQA - existingdatasets still suffer from limited video duration and narrow evaluation scopes,making it difficult to adequately assess the growing capabilities of powerfulmultimodal large language models (MLLMs). To address these limitations, weintroduce TextVidBench, the first benchmark specifically designed forlong-video text question answering (&gt;3 minutes). TextVidBench makes three keycontributions: 1) Cross-domain long-video coverage: Spanning 9 categories(e.g., news, sports, gaming), with an average video length of 2306 seconds,enabling more realistic evaluation of long-video understanding. 2) Athree-stage evaluation framework: "Text Needle-in-Haystack -&gt; TemporalGrounding -&gt; Text Dynamics Captioning". 3) High-quality fine-grainedannotations: Containing over 5,000 question-answer pairs with detailed semanticlabeling. Furthermore, we propose an efficient paradigm for improving largemodels through: (i) introducing the IT-Rope mechanism and temporal promptengineering to enhance temporal perception, (ii) adopting non-uniformpositional encoding to better handle long video sequences, and (iii) applyinglightweight fine-tuning on video-text data. Extensive experiments on multiplepublic datasets as well as TextVidBench demonstrate that our new benchmarkpresents significant challenges to existing models, while our proposed methodoffers valuable insights into improving long-video scene text understandingcapabilities.</description>
      <author>example@mail.com (Yangyang Zhong, Ji Qi, Yuan Yao, Pengxin Luo, Yunfeng Yan, Donglian Qi, Zhiyuan Liu, Tat-Seng Chua)</author>
      <guid isPermaLink="false">2506.04983v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>HUMOF: Human Motion Forecasting in Interactive Social Scenes</title>
      <link>http://arxiv.org/abs/2506.03753v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在交互场景中预测人类运动的有效方法，以应对复杂场景中预测人类行为的挑战。&lt;h4&gt;背景&lt;/h4&gt;复杂场景中的人类行为预测面临挑战，因为存在大量的人与人、人与环境的交互信息，这增加了预测人类运动的不确定性。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来提高复杂场景中人类运动预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;设计了一个分层交互特征表示，高层次特征捕捉交互的整体上下文，低层次特征关注细节。此外，提出了一个由粗到细的交互推理模块，利用空间和频率视角有效地利用分层特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在四个公开数据集上实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在复杂场景中的人类运动预测方面表现出色，将在论文发表时发布代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complex scenes present significant challenges for predicting human behaviourdue to the abundance of interaction information, such as human-human andhumanenvironment interactions. These factors complicate the analysis andunderstanding of human behaviour, thereby increasing the uncertainty inforecasting human motions. Existing motion prediction methods thus struggle inthese complex scenarios. In this paper, we propose an effective method forhuman motion forecasting in interactive scenes. To achieve a comprehensiverepresentation of interactions, we design a hierarchical interaction featurerepresentation so that high-level features capture the overall context of theinteractions, while low-level features focus on fine-grained details. Besides,we propose a coarse-to-fine interaction reasoning module that leverages bothspatial and frequency perspectives to efficiently utilize hierarchicalfeatures, thereby enhancing the accuracy of motion predictions. Our methodachieves state-of-the-art performance across four public datasets. Code will bereleased when this paper is published.</description>
      <author>example@mail.com (Caiyi Sun, Yujing Sun, Xiao Han, Zemin Yang, Jiawei Liu, Xinge Zhu, Siu Ming Yiu, Yuexin Ma)</author>
      <guid isPermaLink="false">2506.03753v2</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Laws for Robust Comparison of Open Foundation Language-Vision Models and Datasets</title>
      <link>http://arxiv.org/abs/2506.04598v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. In Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了可迁移学习中的缩放定律，并展示了如何使用缩放定律来比较模型和数据集，以决定预训练的最佳方法。&lt;h4&gt;背景&lt;/h4&gt;缩放定律在预测重要基础模型在更大规模下的特性和性能方面已得到应用。&lt;h4&gt;目的&lt;/h4&gt;通过缩放定律比较两个语言视觉学习程序CLIP和MaMMUT，评估其预训练过程的优劣。&lt;h4&gt;方法&lt;/h4&gt;通过密集测量广泛范围的模型和样本，推导出CLIP和MaMMUT的完整缩放定律，并使用这些定律比较两个模型，同时考虑了下游任务如分类、检索和分割。&lt;h4&gt;主要发现&lt;/h4&gt;MaMMUT在规模和样本效率方面优于标准CLIP，并且在多种下游任务和开放数据集上观察到一致的趋势。&lt;h4&gt;结论&lt;/h4&gt;缩放定律的准确推导为跨尺度范围进行模型和数据集比较提供了手段，避免了仅基于单一参考尺度的测量得出的误导性结论，为开放基础模型和数据集的系统比较和改进铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;In studies of transferable learning, scaling laws are obtained for various important foundation models to predict their properties and performance at larger scales. We show here how scaling law derivation can also be used for model and dataset comparison, allowing to decide which procedure is to be preferred for pre-training. For the first time, full scaling laws based on dense measurements across a wide span of model and samples seen scales are derived for two important language-vision learning procedures, CLIP and MaMMUT, that use either contrastive only or contrastive and captioning text generative loss. Ensuring sufficient prediction accuracy for held out points, we used derived scaling laws to compare both models, obtaining evidence for MaMMUT's stronger improvement with scale and better sample efficiency than standard CLIP. To strengthen validity of the comparison, we show scaling laws for various downstream tasks, classification, retrieval, and segmentation, and for different open datasets, DataComp, DFN and Re-LAION, observing consistently the same trends. We show that comparison can also be performed when deriving scaling laws with a constant learning rate schedule, reducing compute cost. Accurate derivation of scaling laws provides thus means to perform model and dataset comparison across scale spans, avoiding misleading conclusions based on measurements from single reference scales only, paving the road for systematic comparison and improvement of open foundation models and datasets for their creation. We release all the pre-trained models with their intermediate checkpoints, including openMaMMUT-L/14, which achieves 80.3% zero-shot ImageNet-1k accuracy, trained on 12.8B samples from DataComp-1.4B. Code for reproducing experiments in the paper and raw experiments data can be found at https://github.com/LAION-AI/scaling-laws-for-comparison.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In studies of transferable learning, scaling laws are obtained for variousimportant foundation models to predict their properties and performance atlarger scales. We show here how scaling law derivation can also be used formodel and dataset comparison, allowing to decide which procedure is to bepreferred for pre-training. For the first time, full scaling laws based ondense measurements across a wide span of model and samples seen scales arederived for two important language-vision learning procedures, CLIP and MaMMUT,that use either contrastive only or contrastive and captioning text generativeloss. Ensuring sufficient prediction accuracy for held out points, we usederived scaling laws to compare both models, obtaining evidence for MaMMUT'sstronger improvement with scale and better sample efficiency than standardCLIP. To strengthen validity of the comparison, we show scaling laws forvarious downstream tasks, classification, retrieval, and segmentation, and fordifferent open datasets, DataComp, DFN and Re-LAION, observing consistently thesame trends. We show that comparison can also be performed when derivingscaling laws with a constant learning rate schedule, reducing compute cost.Accurate derivation of scaling laws provides thus means to perform model anddataset comparison across scale spans, avoiding misleading conclusions based onmeasurements from single reference scales only, paving the road for systematiccomparison and improvement of open foundation models and datasets for theircreation. We release all the pre-trained models with their intermediatecheckpoints, including openMaMMUT-L/14, which achieves $80.3\%$ zero-shotImageNet-1k accuracy, trained on 12.8B samples from DataComp-1.4B. Code forreproducing experiments in the paper and raw experiments data can be found athttps://github.com/LAION-AI/scaling-laws-for-comparison.</description>
      <author>example@mail.com (Marianna Nezhurina, Tomer Porian, Giovanni Pucceti, Tommie Kerssies, Romain Beaumont, Mehdi Cherti, Jenia Jitsev)</author>
      <guid isPermaLink="false">2506.04598v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>TRACE: Contrastive learning for multi-trial time-series data in neuroscience</title>
      <link>http://arxiv.org/abs/2506.04906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TRACE的新型对比学习框架，用于处理神经时间序列数据，通过对比学习的方法学习神经元响应的表示。&lt;h4&gt;背景&lt;/h4&gt;现代神经记录技术如两光子成像技术可以获取大量神经元的时间序列数据，而现有的神经网络时间序列分析方法依赖于通用的数据增强技术，并未充分利用神经网络数据中的多试次数据结构。&lt;h4&gt;目的&lt;/h4&gt;提出TRACE框架，旨在通过对比学习有效地从神经时间序列数据中学习神经元的表示。&lt;h4&gt;方法&lt;/h4&gt;TRACE框架通过在不同试次子集之间进行平均来生成正对，结合对比学习和邻近嵌入的思想，直接学习二维嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;TRACE在模拟数据中表现出优于其他方法的性能，能够解决细微的响应差异；在体内记录数据中，TRACE学习到的表示能够捕捉生物相关的连续变化、细胞类型相关的聚类结构，并有助于数据质量控制。&lt;h4&gt;结论&lt;/h4&gt;TRACE是一种有效的对比学习框架，能够从神经时间序列数据中学习到有意义的神经元表示，有助于神经科学数据的分析和理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern neural recording techniques such as two-photon imaging allow toacquire vast time-series datasets with responses of hundreds or thousands ofneurons. Contrastive learning is a powerful self-supervised framework forlearning representations of complex datasets. Existing applications for neuraltime series rely on generic data augmentations and do not exploit themulti-trial data structure inherent in many neural datasets. Here we presentTRACE, a new contrastive learning framework that averages across differentsubsets of trials to generate positive pairs. TRACE allows to directly learn atwo-dimensional embedding, combining ideas from contrastive learning andneighbor embeddings. We show that TRACE outperforms other methods, resolvingfine response differences in simulated data. Further, using in vivo recordings,we show that the representations learned by TRACE capture both biologicallyrelevant continuous variation, cell-type-related cluster structure, and canassist data quality control.</description>
      <author>example@mail.com (Lisa Schmors, Dominic Gonschorek, Jan Niklas Böhm, Yongrong Qiu, Na Zhou, Dmitry Kobak, Andreas Tolias, Fabian Sinz, Jacob Reimer, Katrin Franke, Sebastian Damrich, Philipp Berens)</author>
      <guid isPermaLink="false">2506.04906v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>SGN-CIRL: Scene Graph-based Navigation with Curriculum, Imitation, and Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.04505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于3D场景图的强化学习导航框架SGN-CIRL，用于无地图的机器人导航。该框架通过模仿学习和课程学习加速和稳定强化学习算法的训练过程，并通过实验证明在复杂导航情况下使用3D场景图显著提高了成功率。&lt;h4&gt;背景&lt;/h4&gt;3D场景图模型能够描述物体之间的空间关系，帮助智能体在部分可观测环境中高效导航并预测目标物体的位置。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的导航框架，以实现无地图的机器人导航，并提高在复杂环境中的导航成功率。&lt;h4&gt;方法&lt;/h4&gt;1. 提出基于3D场景图的强化学习导航框架SGN-CIRL；2. 采用模仿学习和课程学习来加速和稳定训练过程；3. 在Isaac Sim环境中进行数值实验。&lt;h4&gt;主要发现&lt;/h4&gt;使用3D场景图进行强化学习在复杂导航案例中的成功率显著提高。&lt;h4&gt;结论&lt;/h4&gt;3D场景图可以显著提高强化学习在复杂导航环境中的应用效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D场景图模型描述了物体之间的空间关系，使智能体能够在部分可观测环境中高效导航并预测目标物体的位置。本文提出了一种名为SGN-CIRL（基于3D场景图的强化学习导航）的原创框架，用于无地图的基于可学习表示的开源词汇3D场景图的强化学习导航。为了加速和稳定基于强化学习的算法训练，该框架还采用了模仿学习和课程学习。前者使智能体能够从演示中学习，而后者通过逐步增加从简单到更高级场景的任务复杂性来构建训练过程。在Isaac Sim环境中进行的数值实验表明，使用3D场景图进行强化学习显著提高了在困难导航案例中的成功率。代码已开源，可在https://github.com/Xisonik/Aloha_graph上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The 3D scene graph models spatial relationships between objects, enabling theagent to efficiently navigate in a partially observable environment and predictthe location of the target object.This paper proposes an original frameworknamed SGN-CIRL (3D Scene Graph-Based Reinforcement Learning Navigation) formapless reinforcement learning-based robot navigation with learnablerepresentation of open-vocabulary 3D scene graph. To accelerate and stabilizethe training of reinforcement learning-based algorithms, the framework alsoemploys imitation learning and curriculum learning. The first one enables theagent to learn from demonstrations, while the second one structures thetraining process by gradually increasing task complexity from simple to moreadvanced scenarios. Numerical experiments conducted in the Isaac Simenvironment showed that using a 3D scene graph for reinforcement learningsignificantly increased the success rate in difficult navigation cases. Thecode is open-sourced and available at: https://github.com/Xisonik/Aloha\_graph.</description>
      <author>example@mail.com (Nikita Oskolkov, Huzhenyu Zhang, Dmitry Makarov, Dmitry Yudin, Aleksandr Panov)</author>
      <guid isPermaLink="false">2506.04505v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Qwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models</title>
      <link>http://arxiv.org/abs/2506.05176v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Qwen3 Embedding系列，这是在文本嵌入和重排序能力上相较于前代GTE-Qwen系列的重要进步，基于Qwen3基础模型构建。&lt;h4&gt;背景&lt;/h4&gt;Qwen3 Embedding系列是在Qwen3基础模型上发展而来，旨在提升文本嵌入和重排序的能力。&lt;h4&gt;目的&lt;/h4&gt;提升文本嵌入和重排序的性能，并满足多样化的部署场景需求。&lt;h4&gt;方法&lt;/h4&gt;采用多阶段训练流程，结合大规模无监督预训练和高质量数据集上的监督微调，以及有效的模型合并策略。Qwen3 LLMs在训练过程中不仅作为骨干模型，还负责跨多个领域和语言的训练数据合成。&lt;h4&gt;主要发现&lt;/h4&gt;Qwen3 Embedding系列在多个基准测试中达到最先进的结果，特别是在多语言评估基准MTEB和代码检索、跨语言检索以及多语言检索等任务中表现出色。&lt;h4&gt;结论&lt;/h4&gt;Qwen3 Embedding系列通过提供不同规模的模型（0.6B、4B、8B）来满足不同部署场景的需求，并公开模型以促进社区研究和开发。&lt;h4&gt;翻译&lt;/h4&gt;在本工作中，我们介绍了Qwen3 Embedding系列，这是在文本嵌入和重排序能力上相较于其前代GTE-Qwen系列的重要进步，建立在Qwen3基础模型之上。利用Qwen3 LLMs在多语言文本理解和生成方面的强大能力，我们创新的分阶段训练流程结合了大规模无监督预训练和高质量数据集上的监督微调。有效的模型合并策略进一步确保了Qwen3 Embedding系列的鲁棒性和适应性。在训练过程中，Qwen3 LLMs不仅作为骨干模型，还发挥着在多个领域和语言中综合高质量、丰富和多样化训练数据的关键作用，从而增强了训练流程。Qwen3 Embedding系列为嵌入和重排序任务提供了多种模型大小（0.6B、4B、8B），以满足多样化的部署场景，用户可以根据效率或效果进行优化。实证评估表明，Qwen3 Embedding系列在多个基准测试中实现了最先进的结果。值得注意的是，它在多语言评估基准MTEB的文本嵌入以及各种检索任务中表现出色，包括代码检索、跨语言检索和多语言检索。为了促进可重复性和推动社区驱动的研发，Qwen3 Embedding模型在Apache 2.0许可下公开。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we introduce the Qwen3 Embedding series, a significantadvancement over its predecessor, the GTE-Qwen series, in text embedding andreranking capabilities, built upon the Qwen3 foundation models. Leveraging theQwen3 LLMs' robust capabilities in multilingual text understanding andgeneration, our innovative multi-stage training pipeline combines large-scaleunsupervised pre-training with supervised fine-tuning on high-quality datasets.Effective model merging strategies further ensure the robustness andadaptability of the Qwen3 Embedding series. During the training process, theQwen3 LLMs serve not only as backbone models but also play a crucial role insynthesizing high-quality, rich, and diverse training data across multipledomains and languages, thus enhancing the training pipeline. The Qwen3Embedding series offers a spectrum of model sizes (0.6B, 4B, 8B) for bothembedding and reranking tasks, addressing diverse deployment scenarios whereusers can optimize for either efficiency or effectiveness. Empiricalevaluations demonstrate that the Qwen3 Embedding series achievesstate-of-the-art results across diverse benchmarks. Notably, it excels on themultilingual evaluation benchmark MTEB for text embedding, as well as invarious retrieval tasks, including code retrieval, cross-lingual retrieval andmultilingual retrieval. To facilitate reproducibility and promotecommunity-driven research and development, the Qwen3 Embedding models arepublicly available under the Apache 2.0 license.</description>
      <author>example@mail.com (Yanzhao Zhang, Mingxin Li, Dingkun Long, Xin Zhang, Huan Lin, Baosong Yang, Pengjun Xie, An Yang, Dayiheng Liu, Junyang Lin, Fei Huang, Jingren Zhou)</author>
      <guid isPermaLink="false">2506.05176v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>The future of gravitational wave science unlocking LIGO potential: AI-driven data analysis and exploration</title>
      <link>http://arxiv.org/abs/2506.04584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了人工智能（AI）在引力波天文学中的应用，特别是AI如何增强信号检测、噪声减少和数据解释。&lt;h4&gt;背景&lt;/h4&gt;引力波天文学的兴起改变了观测宇宙灾难性事件的方式，如黑洞合并和中子星碰撞。LIGO在发现这些事件中发挥了重要作用，但引力波数据的巨大体积和复杂性对传统分析方法提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;研究AI与引力波科学的日益紧密的协同作用，强调AI如何提高探测器灵敏度。&lt;h4&gt;方法&lt;/h4&gt;本文概述了引力波基础知识，讨论了机器学习在提高探测器灵敏度中的作用，并回顾了基于2021至2024年数据的AI技术，包括监督学习、无监督学习、深度学习和强化学习。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，深度学习和监督学习在提高真正阳性率（TPR）和降低假阳性率（FPR）方面优于其他方法。无监督和强化学习模型虽然精度较低，但效率高，适用于实时应用。&lt;h4&gt;结论&lt;/h4&gt;AI与引力波研究的整合显著提高了事件检测的可靠性和速度，为探索动态宇宙开辟了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;随着引力波天文学（GW）的出现，观测宇宙灾难性事件，如黑洞合并和中子星碰撞的方式发生了革命性的变化。激光干涉仪引力波观测站（LIGO）在这些发现中处于前沿。然而，引力波数据的巨大体积和复杂性对传统分析方法提出了重大挑战。本文研究了人工智能（AI）与GW科学之间日益增长的协同作用，强调AI如何增强信号检测、噪声减少和数据解释。它从引力波基础知识概述开始，讨论了机器学习在提高探测器灵敏度中的作用。与LIGO观测到的显著GW事件一起，讨论了持续的挑战，如数据质量、泛化能力和计算限制。根据2021至2024年的数据，对AI技术进行了全面的性能评估，包括监督学习、无监督学习、深度学习和强化学习。评估指标包括准确性、精确度、真正阳性率（TPR）、假阳性率（FPR）和计算效率。发现深度学习和监督学习优于其他方法，特别是在提高TPR和最小化FPR方面。虽然无监督和强化学习模型精度较低，但它们展示了高效率和实时应用的潜力。研究还探讨了AI整合到下一代探测器和波形重建技术中。总的来说，AI与GW研究的整合显著提高了事件检测的可靠性和速度，为探索动态宇宙开辟了新的可能性。本文全面概述了AI在塑造GW天文学未来中的变革性作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.53894/ijirss.v8i3.7514&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of gravitational wave astronomy (GW) has revolutionized theobservation of cataclysmic cosmic events, such as black hole mergers andneutron star collisions. The Laser Interferometer Gravitational-WaveObservatory (LIGO) has been at the forefront of these discoveries. However, theimmense volume and complexity of gravitational wave data present significantchallenges for traditional analysis methods. This paper investigates thegrowing synergy between artificial intelligence (AI) and GW science,emphasizing how AI enhances signal detection, noise reduction, and datainterpretation. It begins with an overview of GW fundamentals and the role ofmachine learning in increasing detector sensitivity. Notable GW events observedby LIGO are discussed alongside persistent analytical challenges such as dataquality, generalization, and computational constraints. A comprehensiveperformance review of AI techniques, including supervised learning,unsupervised learning, deep learning, and reinforcement learning, is presentedbased on data spanning 2021 to 2024. Evaluation metrics include accuracy,precision, true positive rate (TPR), false positive rate (FPR), andcomputational efficiency. Findings indicate that deep learning and supervisedlearning outperform other approaches, particularly in enhancing TPR andminimizing FPR. While unsupervised and reinforcement learning models offer lessprecision, they demonstrate high efficiency and potential for real-timeapplications. The study also explores AI integration into next-generationdetectors and waveform reconstruction techniques. Overall, the integration ofAI into GW research significantly improves the reliability and speed of eventdetection, unlocking new possibilities for exploring the dynamic universe. Thispaper provides a comprehensive outlook on the transformative role of AI inshaping the future of GW astronomy.</description>
      <author>example@mail.com (Yong Xiao, Li, Zin Nandar Win, He Wang, Hla Myo Tun, Win Thu Zar)</author>
      <guid isPermaLink="false">2506.04584v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Aligning Multimodal Representations through an Information Bottleneck</title>
      <link>http://arxiv.org/abs/2506.04870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了对比损失在多模态表示学习中的应用，指出其不适用于学习对齐的表示空间，并提出了相应的解决方案。&lt;h4&gt;背景&lt;/h4&gt;对比损失在多模态表示学习中广泛使用，但实验表明其效果不佳。&lt;h4&gt;目的&lt;/h4&gt;分析对比损失在多模态表示学习中的不足，并提出改进方法。&lt;h4&gt;方法&lt;/h4&gt;通过信息瓶颈原理进行理论描述，通过控制实验分析不同超参数的影响，并提出在损失函数中加入正则化项的方法。&lt;h4&gt;主要发现&lt;/h4&gt;对比损失未能有效去除表示空间中的模态特定信息，导致学习到的表示空间不对齐。&lt;h4&gt;结论&lt;/h4&gt;通过在损失函数中加入正则化项，可以增加表示的对齐度，提高多模态表示学习的效果。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive losses have been extensively used as a tool for multimodal representation learning. However, it has been empirically observed that their use is not effective to learn an aligned representation space. In this paper, we argue that this phenomenon is caused by the presence of modality-specific information in the representation space. Although some of the most widely used contrastive losses maximize the mutual information between representations of both modalities, they are not designed to remove the modality-specific information. We give a theoretical description of this problem through the lens of the Information Bottleneck Principle. We also empirically analyze how different hyperparameters affect the emergence of this phenomenon in a controlled experimental setup. Finally, we propose a regularization term in the loss function that is derived by means of a variational approximation and aims to increase the representational alignment. We analyze in a set of controlled experiments and real-world applications the advantages of including this regularization term.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive losses have been extensively used as a tool for multimodalrepresentation learning. However, it has been empirically observed that theiruse is not effective to learn an aligned representation space. In this paper,we argue that this phenomenon is caused by the presence of modality-specificinformation in the representation space. Although some of the most widely usedcontrastive losses maximize the mutual information between representations ofboth modalities, they are not designed to remove the modality-specificinformation. We give a theoretical description of this problem through the lensof the Information Bottleneck Principle. We also empirically analyze howdifferent hyperparameters affect the emergence of this phenomenon in acontrolled experimental setup. Finally, we propose a regularization term in theloss function that is derived by means of a variational approximation and aimsto increase the representational alignment. We analyze in a set of controlledexperiments and real-world applications the advantages of including thisregularization term.</description>
      <author>example@mail.com (Antonio Almudévar, José Miguel Hernández-Lobato, Sameer Khurana, Ricard Marxer, Alfonso Ortega)</author>
      <guid isPermaLink="false">2506.04870v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>ReXVQA: A Large-scale Visual Question Answering Benchmark for Generalist Chest X-ray Understanding</title>
      <link>http://arxiv.org/abs/2506.04353v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ReXVQA，这是迄今为止最大的胸部放射学视觉问答（VQA）基准，包含约696,000个问题与160,000张胸部X光片配对，用于训练、验证和测试集。该基准旨在评估多模态大型语言模型在胸部X光片解读方面的性能。&lt;h4&gt;背景&lt;/h4&gt;以往的研究主要依赖于基于模板的查询，而ReXVQA引入了多样化的临床真实任务，反映了五个核心放射学推理技能：存在评估、定位分析、否定检测、鉴别诊断和几何推理。&lt;h4&gt;目的&lt;/h4&gt;评估八种最先进的跨模态大型语言模型，并建立一个新的标准来评估通用的放射学人工智能系统。&lt;h4&gt;方法&lt;/h4&gt;评估了包括MedGemma-4B-it、Qwen2.5-VL、Janus-Pro-7B和Eagle2-9B在内的八种模型，并与人类读者进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;性能最佳的模型（MedGemma）实现了83.24%的整体准确率，并且在人类读者（最佳放射科住院医师准确率为77.27%）之上。人类读者之间的性能模式与AI模型和人类读者之间的性能模式存在差异。&lt;h4&gt;结论&lt;/h4&gt;ReXVQA建立了评估放射学人工智能系统的新标准，为下一代能够模拟专家级临床推理的人工智能系统奠定了基础。数据集将在https://huggingface.co/datasets/rajpurkarlab/ReXVQA上开源。&lt;h4&gt;翻译&lt;/h4&gt;本文提出ReXVQA，这是胸部放射学视觉问答（VQA）领域最大、最全面的基准，包括约696,000个问题与160,000张胸部X光片配对，用于训练、验证和测试集。与以往主要依赖基于模板查询的研究不同，ReXVQA引入了多样化的临床真实任务，反映了五个核心放射学推理技能：存在评估、定位分析、否定检测、鉴别诊断和几何推理。评估了包括MedGemma-4B-it、Qwen2.5-VL、Janus-Pro-7B和Eagle2-9B在内的八种最先进的跨模态大型语言模型。性能最佳的模型（MedGemma）实现了83.24%的整体准确率。为了弥合人工智能性能与临床专业知识之间的差距，我们对200个随机抽取的病例进行了包括3名放射科住院医师在内的人类读者研究。评估表明，与人类读者相比，MedGemma实现了更优的性能（准确率为83.84%），代表了人工智能在胸部X光片解读方面超越专家人类评估的一个重要里程碑。读者研究揭示了AI模型和人类专家之间的性能模式存在差异，放射科医生之间的一致性较强，而人类读者与AI模型之间的一致性模式则更为多变。ReXVQA建立了评估通用放射学人工智能系统的新标准，提供了公共排行榜、细粒度评估分割、结构化解释和类别级分解。这个基准为下一代能够模拟专家级临床推理的人工智能系统奠定了基础。我们的数据集将在https://huggingface.co/datasets/rajpurkarlab/ReXVQA上开源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present ReXVQA, the largest and most comprehensive benchmark for visualquestion answering (VQA) in chest radiology, comprising approximately 696,000questions paired with 160,000 chest X-rays studies across training, validation,and test sets. Unlike prior efforts that rely heavily on template basedqueries, ReXVQA introduces a diverse and clinically authentic task suitereflecting five core radiological reasoning skills: presence assessment,location analysis, negation detection, differential diagnosis, and geometricreasoning. We evaluate eight state-of-the-art multimodal large language models,including MedGemma-4B-it, Qwen2.5-VL, Janus-Pro-7B, and Eagle2-9B. Thebest-performing model (MedGemma) achieves 83.24% overall accuracy. To bridgethe gap between AI performance and clinical expertise, we conducted acomprehensive human reader study involving 3 radiology residents on 200randomly sampled cases. Our evaluation demonstrates that MedGemma achievedsuperior performance (83.84% accuracy) compared to human readers (bestradiology resident: 77.27%), representing a significant milestone where AIperformance exceeds expert human evaluation on chest X-ray interpretation. Thereader study reveals distinct performance patterns between AI models and humanexperts, with strong inter-reader agreement among radiologists while showingmore variable agreement patterns between human readers and AI models. ReXVQAestablishes a new standard for evaluating generalist radiological AI systems,offering public leaderboards, fine-grained evaluation splits, structuredexplanations, and category-level breakdowns. This benchmark lays the foundationfor next-generation AI systems capable of mimicking expert-level clinicalreasoning beyond narrow pathology classification. Our dataset will beopen-sourced at https://huggingface.co/datasets/rajpurkarlab/ReXVQA</description>
      <author>example@mail.com (Ankit Pal, Jung-Oh Lee, Xiaoman Zhang, Malaikannan Sankarasubbu, Seunghyeon Roh, Won Jung Kim, Meesun Lee, Pranav Rajpurkar)</author>
      <guid isPermaLink="false">2506.04353v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>PixCell: A generative foundation model for digital histopathology images</title>
      <link>http://arxiv.org/abs/2506.05127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了PixCell，一种基于扩散模型的病理学生成性基础模型，它可以生成多种癌症类型的高质量图像，并在病理学研究和数据共享等方面具有应用价值。&lt;h4&gt;背景&lt;/h4&gt;病理学领域的数字化和大数据时代的到来，推动了病理学的发展，同时也提出了新的挑战，如数据稀缺和隐私保护等。&lt;h4&gt;目的&lt;/h4&gt;介绍PixCell模型，该模型旨在通过生成性方法解决病理学中的问题，如数据稀缺、隐私保护和进行虚拟染色等。&lt;h4&gt;方法&lt;/h4&gt;PixCell在包含69,184个H&amp;E染色全切片图像的大规模数据集PanCan-30M上训练，采用了渐进式训练策略和基于自我监督的条件化技术。&lt;h4&gt;主要发现&lt;/h4&gt;PixCell能够生成多样化和高质量的图像，这些图像可以用作训练自我监督判别模型的数据替代品，并在数据共享和隐私保护方面具有优势。通过有限的标注图像，PixCell可以实现图像生成的精确控制，并在细胞分割任务中提升下游性能。&lt;h4&gt;结论&lt;/h4&gt;PixCell在病理学研究中具有广泛应用前景，能够加速计算病理学领域的研究进展。&lt;h4&gt;翻译&lt;/h4&gt;The abstract introduces PixCell, a diffusion-based generative foundation model for histopathology that can generate diverse and high-quality images across multiple cancer types, which has application value in various aspects of pathology research, such as data sharing and privacy protection.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The digitization of histology slides has revolutionized pathology, providingmassive datasets for cancer diagnosis and research. Contrastive self-supervisedand vision-language models have been shown to effectively mine large pathologydatasets to learn discriminative representations. On the other hand, generativemodels, capable of synthesizing realistic and diverse images, present acompelling solution to address unique problems in pathology that involvesynthesizing images; overcoming annotated data scarcity, enablingprivacy-preserving data sharing, and performing inherently generative tasks,such as virtual staining. We introduce PixCell, the first diffusion-basedgenerative foundation model for histopathology. We train PixCell on PanCan-30M,a vast, diverse dataset derived from 69,184 H\&amp;E-stained whole slide imagescovering various cancer types. We employ a progressive training strategy and aself-supervision-based conditioning that allows us to scale up training withoutany annotated data. PixCell generates diverse and high-quality images acrossmultiple cancer types, which we find can be used in place of real data to traina self-supervised discriminative model. Synthetic images shared betweeninstitutions are subject to fewer regulatory barriers than would be the casewith real clinical images. Furthermore, we showcase the ability to preciselycontrol image generation using a small set of annotated images, which can beused for both data augmentation and educational purposes. Testing on a cellsegmentation task, a mask-guided PixCell enables targeted data augmentation,improving downstream performance. Finally, we demonstrate PixCell's ability touse H\&amp;E structural staining to infer results from molecular marker studies; weuse this capability to infer IHC staining from H\&amp;E images. Our trained modelsare publicly released to accelerate research in computational pathology.</description>
      <author>example@mail.com (Srikar Yellapragada, Alexandros Graikos, Zilinghan Li, Kostas Triaridis, Varun Belagali, Saarthak Kapse, Tarak Nath Nandi, Ravi K Madduri, Prateek Prasanna, Tahsin Kurc, Rajarsi R. Gupta, Joel Saltz, Dimitris Samaras)</author>
      <guid isPermaLink="false">2506.05127v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>APVR: Hour-Level Long Video Understanding with Adaptive Pivot Visual Information Retrieval</title>
      <link>http://arxiv.org/abs/2506.04953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为APVR的无需训练的视频理解框架，通过层次化视觉信息检索来克服内存墙限制，提高了对小时级别视频的处理能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基于视频的多模态大语言模型在处理小时级别视频时存在计算限制和从长时间序列中提取信息效率低下的问题。&lt;h4&gt;目的&lt;/h4&gt;提出APVR框架，旨在解决小时级别视频理解中的内存墙限制。&lt;h4&gt;方法&lt;/h4&gt;APVR框架包含两个互补组件：Pivot Frame Retrieval通过语义扩展和多模态置信度评分识别语义相关的视频帧；Pivot Token Retrieval在枢纽帧内执行查询感知的注意力驱动的标记选择。&lt;h4&gt;主要发现&lt;/h4&gt;在LongVideoBench和VideoMME上的实验验证显示了显著的性能提升，不仅对于无需训练的方法，也对基于训练的方法都达到了最先进的结果。&lt;h4&gt;结论&lt;/h4&gt;APVR框架在保持语义准确性的同时，能够处理长达小时的视频，并且能够与现有的机器学习大语言模型架构无缝集成。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current video-based multimodal large language models struggle with hour-levelvideo understanding due to computational constraints and inefficientinformation extraction from extensive temporal sequences. We propose APVR(Adaptive Pivot Visual information Retrieval), a training-free framework thataddresses the memory wall limitation through hierarchical visual informationretrieval. APVR operates via two complementary components: Pivot FrameRetrieval employs semantic expansion and multi-modal confidence scoring toidentify semantically relevant video frames, while Pivot Token Retrievalperforms query-aware attention-driven token selection within the pivot frames.This dual granularity approach enables processing of hour-long videos whilemaintaining semantic fidelity. Experimental validation on LongVideoBench andVideoMME demonstrates significant performance improvements, establishingstate-of-the-art results for not only training-free but also training-basedapproaches while providing plug-and-play integration capability with existingMLLM architectures.</description>
      <author>example@mail.com (Hong Gao, Yiming Bao, Xuezhan Tu, Bin Zhong, Minling Zhang)</author>
      <guid isPermaLink="false">2506.04953v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>OpenGT: A Comprehensive Benchmark For Graph Transformers</title>
      <link>http://arxiv.org/abs/2506.04765v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Graph Transformers（GTs）的性能和设计，强调了它们在建模长距离依赖和复杂结构关系方面的优势，同时也指出了目前对GTs适用场景和设计选择的探索不足。&lt;h4&gt;背景&lt;/h4&gt;Graph Transformers在多个领域表现出色，通过利用注意力机制，它们能够超越局部邻域，建模长距离依赖和复杂结构关系。&lt;h4&gt;目的&lt;/h4&gt;为了解决GTs适用场景和设计选择的探索不足的问题，本文提出了OpenGT，一个全面的Graph Transformers基准。&lt;h4&gt;方法&lt;/h4&gt;OpenGT通过建立标准化的实验设置，整合了多种最先进的GNNs和GTs，允许进行公平的比较和多维度的分析。&lt;h4&gt;主要发现&lt;/h4&gt;OpenGT基准揭示了多个关键洞察，包括模型在不同任务级别间迁移的困难、局部注意力机制的局限性、某些模型中效率与性能的权衡、特定位置编码的应用场景以及某些位置编码的前处理开销。&lt;h4&gt;结论&lt;/h4&gt;本文旨在为未来的Graph Transformers研究奠定基础，强调公平性、可重复性和通用性，并开发了OpenGT库，方便训练和评估现有的GTs。&lt;h4&gt;翻译&lt;/h4&gt;Graph Transformers (GTs) recently have demonstrated remarkable performance across various domains. By utilizing attention mechanisms, GTs are capable of modeling long-range dependencies and complex structural relationships beyond local neighborhoods. However, their applicable scenarios are still underexplored, which highlights the need to identify when and why they excel. Furthermore, unlike GNNs, which predominantly rely on message-passing mechanisms, GTs exhibit a diverse design space in areas such as positional encoding, attention mechanisms, and graph-specific adaptations. Yet, it remains unclear which of these design choices are truly effective and under what conditions. As a result, the community currently lacks a comprehensive benchmark and library to promote a deeper understanding and further development of GTs. To address this gap, this paper introduces OpenGT, a comprehensive benchmark for Graph Transformers. OpenGT enables fair comparisons and multidimensional analysis by establishing standardized experimental settings and incorporating a broad selection of state-of-the-art GNNs and GTs. Our benchmark evaluates GTs from multiple perspectives, encompassing diverse tasks and datasets with varying properties. Through extensive experiments, our benchmark has uncovered several critical insights, including the difficulty of transferring models across task levels, the limitations of local attention, the efficiency trade-offs in several models, the application scenarios of specific positional encodings, and the preprocessing overhead of some positional encodings. We aspire for this work to establish a foundation for future graph transformer research emphasizing fairness, reproducibility, and generalizability. We have developed an easy-to-use library OpenGT for training and evaluating existing GTs. The benchmark code is available at https://github.com/eaglelab-zju/OpenGT.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Transformers (GTs) have recently demonstrated remarkable performanceacross diverse domains. By leveraging attention mechanisms, GTs are capable ofmodeling long-range dependencies and complex structural relationships beyondlocal neighborhoods. However, their applicable scenarios are stillunderexplored, this highlights the need to identify when and why they excel.Furthermore, unlike GNNs, which predominantly rely on message-passingmechanisms, GTs exhibit a diverse design space in areas such as positionalencoding, attention mechanisms, and graph-specific adaptations. Yet, it remainsunclear which of these design choices are truly effective and under whatconditions. As a result, the community currently lacks a comprehensivebenchmark and library to promote a deeper understanding and further developmentof GTs. To address this gap, this paper introduces OpenGT, a comprehensivebenchmark for Graph Transformers. OpenGT enables fair comparisons andmultidimensional analysis by establishing standardized experimental settingsand incorporating a broad selection of state-of-the-art GNNs and GTs. Ourbenchmark evaluates GTs from multiple perspectives, encompassing diverse tasksand datasets with varying properties. Through extensive experiments, ourbenchmark has uncovered several critical insights, including the difficulty oftransferring models across task levels, the limitations of local attention, theefficiency trade-offs in several models, the application scenarios of specificpositional encodings, and the preprocessing overhead of some positionalencodings. We aspire for this work to establish a foundation for future graphtransformer research emphasizing fairness, reproducibility, andgeneralizability. We have developed an easy-to-use library OpenGT for trainingand evaluating existing GTs. The benchmark code is available athttps://github.com/eaglelab-zju/OpenGT.</description>
      <author>example@mail.com (Jiachen Tang, Zhonghao Wang, Sirui Chen, Sheng Zhou, Jiawei Chen, Jiajun Bu)</author>
      <guid isPermaLink="false">2506.04765v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>CL-ISR: A Contrastive Learning and Implicit Stance Reasoning Framework for Misleading Text Detection on Social Media</title>
      <link>http://arxiv.org/abs/2506.05107v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CL-ISR的新型框架，用于提高社交媒体上误导性文本的检测准确性。&lt;h4&gt;背景&lt;/h4&gt;社交媒体上的误导性文本可能导致公众误解、社会恐慌和经济损失。&lt;h4&gt;目的&lt;/h4&gt;提高社交媒体上误导性文本的检测准确性。&lt;h4&gt;方法&lt;/h4&gt;结合对比学习和隐式立场推理，通过对比学习算法提高模型对真实文本和误导文本语义差异的学习能力，引入隐式立场推理模块探索文本中的潜在立场倾向及其与相关主题的关系。&lt;h4&gt;主要发现&lt;/h4&gt;CL-ISR框架利用对比学习的判别能力和立场推理的解读深度，显著提高了检测效果。&lt;h4&gt;结论&lt;/h4&gt;CL-ISR框架能够有效提高社交媒体上误导性文本的检测准确性。&lt;h4&gt;翻译&lt;/h4&gt;Misleading text detection on social media platforms is a critical research area, as these texts can lead to public misunderstanding, social panic and even economic losses. This paper proposes a novel framework - CL-ISR (Contrastive Learning and Implicit Stance Reasoning), which combines contrastive learning and implicit stance reasoning, to improve the detection accuracy of misleading texts on social media. First, we use the contrastive learning algorithm to improve the model's learning ability of semantic differences between truthful and misleading texts. Contrastive learning could help the model to better capture the distinguishing features between different categories by constructing positive and negative sample pairs. This approach enables the model to capture distinguishing features more effectively, particularly in linguistically complicated situations. Second, we introduce the implicit stance reasoning module, to explore the potential stance tendencies in the text and their relationships with related topics. This method is effective for identifying content that misleads through stance shifting or emotional manipulation, because it can capture the implicit information behind the text. Finally, we integrate these two algorithms together to form a new framework, CL-ISR, which leverages the discriminative power of contrastive learning and the interpretive depth of stance reasoning to significantly improve detection effect.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Misleading text detection on social media platforms is a critical researcharea, as these texts can lead to public misunderstanding, social panic and eveneconomic losses. This paper proposes a novel framework - CL-ISR (ContrastiveLearning and Implicit Stance Reasoning), which combines contrastive learningand implicit stance reasoning, to improve the detection accuracy of misleadingtexts on social media. First, we use the contrastive learning algorithm toimprove the model's learning ability of semantic differences between truthfuland misleading texts. Contrastive learning could help the model to bettercapture the distinguishing features between different categories byconstructing positive and negative sample pairs. This approach enables themodel to capture distinguishing features more effectively, particularly inlinguistically complicated situations. Second, we introduce the implicit stancereasoning module, to explore the potential stance tendencies in the text andtheir relationships with related topics. This method is effective foridentifying content that misleads through stance shifting or emotionalmanipulation, because it can capture the implicit information behind the text.Finally, we integrate these two algorithms together to form a new framework,CL-ISR, which leverages the discriminative power of contrastive learning andthe interpretive depth of stance reasoning to significantly improve detectioneffect.</description>
      <author>example@mail.com (Tianyi Huang, Zikun Cui, Cuiqianhe Du, Chia-En Chiang)</author>
      <guid isPermaLink="false">2506.05107v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Tuning the Right Foundation Models is What you Need for Partial Label Learning</title>
      <link>http://arxiv.org/abs/2506.05027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code can be found at \url{https://github.com/SEU-hk/PartialCLIP}&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了部分标签学习（PLL），评估了11种基础模型在13种PLL方法下的性能，并提出了一个针对基础模型的PLL微调框架PartialCLIP。&lt;h4&gt;背景&lt;/h4&gt;PLL旨在从带有不精确监督的数据集中训练可泛化的分类器，这是现实应用中常见的问题。&lt;h4&gt;目的&lt;/h4&gt;评估现有PLL方法在基础模型上的性能，并提出改进的PLL模型。&lt;h4&gt;方法&lt;/h4&gt;在8个基准数据集上，对11种基础模型在13种PLL方法下的性能进行了全面评估，并提出了PartialCLIP框架。&lt;h4&gt;主要发现&lt;/h4&gt;1) 使用基础模型时，PLL方法可以实现显著的性能提升；2) 不同PLL方法之间的性能相似；3) 在不同的模糊程度下，PLL方法保持稳定的性能；4) PLL方法对基础模型的选择和适应策略敏感。&lt;h4&gt;结论&lt;/h4&gt;实验结果和分析突出了现有PLL方法的局限性，并为开发更通用的PLL模型提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;Partial label learning (PLL) aims to train generalizable classifiers from datasets with inexact supervision, a common challenge in real-world applications. Existing studies have developed numerous approaches to progressively refine and recover ground-truth labels by training convolutional neural networks. However, limited attention has been given to foundation models that offer transferrable representations. In this work, we empirically conduct comprehensive evaluations of 11 foundation models across 13 PLL approaches on 8 benchmark datasets under 3 PLL scenarios. We further propose PartialCLIP, an efficient fine-tuning framework for foundation models in PLL. Our findings reveal that current PLL approaches tend to 1) achieve significant performance gains when using foundation models, 2) exhibit remarkably similar performance to each other, 3) maintain stable performance across varying ambiguity levels, while 4) are susceptible to foundation model selection and adaptation strategies. Additionally, we demonstrate the efficacy of text-embedding classifier initialization and effective candidate label filtering using zero-shot CLIP. Our experimental results and analysis underscore the limitations of current PLL approaches and provide valuable insights for developing more generalizable PLL models. The source code can be found at https://github.com/SEU-hk/PartialCLIP.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Partial label learning (PLL) seeks to train generalizable classifiers fromdatasets with inexact supervision, a common challenge in real-worldapplications. Existing studies have developed numerous approaches toprogressively refine and recover ground-truth labels by training convolutionalneural networks. However, limited attention has been given to foundation modelsthat offer transferrable representations. In this work, we empirically conductcomprehensive evaluations of 11 foundation models across 13 PLL approaches on 8benchmark datasets under 3 PLL scenarios. We further propose PartialCLIP, anefficient fine-tuning framework for foundation models in PLL. Our findingsreveal that current PLL approaches tend to 1) achieve significant performancegains when using foundation models, 2) exhibit remarkably similar performanceto each other, 3) maintain stable performance across varying ambiguity levels,while 4) are susceptible to foundation model selection and adaptationstrategies. Additionally, we demonstrate the efficacy of text-embeddingclassifier initialization and effective candidate label filtering usingzero-shot CLIP. Our experimental results and analysis underscore thelimitations of current PLL approaches and provide valuable insights fordeveloping more generalizable PLL models. The source code can be found athttps://github.com/SEU-hk/PartialCLIP.</description>
      <author>example@mail.com (Kuang He, Wei Tang, Tong Wei, Min-Ling Zhang)</author>
      <guid isPermaLink="false">2506.05027v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>DualX-VSR: Dual Axial Spatial$\times$Temporal Transformer for Real-World Video Super-Resolution without Motion Compensation</title>
      <link>http://arxiv.org/abs/2506.04830v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DualX-VSR的Transformer模型，用于现实世界视频超分辨率（VSR）任务，该模型通过引入新的双重轴向时空注意力机制，有效地解决了现有VSR模型在像素级精度、响应域限制和依赖光学流对齐等方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;Transformer模型在视频理解方面取得了进展，但在视频超分辨率任务中存在挑战，如像素级精度要求高，而现有的VSR模型可能因为序列注意力机制而降低精度。&lt;h4&gt;目的&lt;/h4&gt;提出DualX-VSR模型，旨在解决现实世界视频超分辨率中的像素级精度问题，并克服现有模型在响应域和光学流对齐方面的限制。&lt;h4&gt;方法&lt;/h4&gt;DualX-VSR模型通过引入新的双重轴向时空注意力机制，整合空间和时间信息，并简化结构以提供时空信息的连贯表示。&lt;h4&gt;主要发现&lt;/h4&gt;DualX-VSR模型通过消除运动补偿需求，提供了一种更简化的结构，从而在现实世界的VSR任务中实现了高保真度和卓越的性能。&lt;h4&gt;结论&lt;/h4&gt;DualX-VSR模型在视频超分辨率任务中展示了优异的性能，为解决现实世界中的VSR问题提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于Transformer的模型如ViViT和TimeSformer通过有效地模拟时空依赖性而提高了视频理解。最近的一些视频生成模型，如Sora和Vidu，进一步突显了Transformer在长程特征提取和整体时空建模方面的能力。然而，将这些模型直接应用于现实世界的视频超分辨率（VSR）具有挑战性，因为VSR需要像素级的精确度，这可能会被标记化和序列注意力机制所损害。尽管最近的基于Transformer的VSR模型尝试使用更小的块和局部注意力来解决这些问题，但它们仍然面临着诸如受限的响应域和对基于光流对齐的依赖等限制，这可能会在现实世界中引入不准确。为了克服这些问题，我们提出了用于现实世界视频超分辨率的Dual Axial Spatial×Temporal Transformer（DualX-VSR），它引入了一种新颖的双重轴向时空注意力机制，该机制沿正交方向整合空间和时间信息。DualX-VSR消除了运动补偿的需求，提供了一个提供时空信息连贯表示的简化结构。因此，DualX-VSR在现实世界的VSR任务中实现了高保真度和卓越的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer-based models like ViViT and TimeSformer have advanced videounderstanding by effectively modeling spatiotemporal dependencies. Recent videogeneration models, such as Sora and Vidu, further highlight the power oftransformers in long-range feature extraction and holistic spatiotemporalmodeling. However, directly applying these models to real-world videosuper-resolution (VSR) is challenging, as VSR demands pixel-level precision,which can be compromised by tokenization and sequential attention mechanisms.While recent transformer-based VSR models attempt to address these issues usingsmaller patches and local attention, they still face limitations such asrestricted receptive fields and dependence on optical flow-based alignment,which can introduce inaccuracies in real-world settings. To overcome theseissues, we propose Dual Axial Spatial$\times$Temporal Transformer forReal-World Video Super-Resolution (DualX-VSR), which introduces a novel dualaxial spatial$\times$temporal attention mechanism that integrates spatial andtemporal information along orthogonal directions. DualX-VSR eliminates the needfor motion compensation, offering a simplified structure that provides acohesive representation of spatiotemporal information. As a result, DualX-VSRachieves high fidelity and superior performance in real-world VSR task.</description>
      <author>example@mail.com (Shuo Cao, Yihao Liu, Xiaohui Li. Yuanting Gao. Yu Zhou, Chao Dong)</author>
      <guid isPermaLink="false">2506.04830v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>OpenAg: Democratizing Agricultural Intelligence</title>
      <link>http://arxiv.org/abs/2506.04571v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为OpenAg的综合框架，旨在推动农业人工智能（AGI）的发展，以解决当前农业智能系统在情境理解、可解释性和适应性方面的不足。&lt;h4&gt;背景&lt;/h4&gt;农业正经历由人工智能（AI）、机器学习和知识表示技术驱动的重大变革。然而，目前的农业智能系统往往缺乏情境理解、可解释性和适应性，尤其是对于资源有限的小农户来说。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，OpenAg框架旨在结合特定领域的知识、神经网络知识图谱、多智能体推理、因果可解释性和自适应迁移学习，以提供情境感知、可解释和可操作的见解。&lt;h4&gt;方法&lt;/h4&gt;OpenAg系统包括：（一）一个统一的农业知识库，整合科学文献、传感器数据和农民生成的知识；（二）一个用于结构化推理和推理的神经网络农业知识图谱；（三）一个自适应的多智能体推理系统，其中AI智能体在农业领域专业化和协作；（四）一个因果透明机制，确保AI建议是可解释的、科学依据的并与现实世界约束一致。&lt;h4&gt;主要发现&lt;/h4&gt;OpenAg旨在弥合科学知识与经验丰富的农民的隐性专业知识之间的差距，以支持可扩展且与当地相关的农业决策。&lt;h4&gt;结论&lt;/h4&gt;OpenAg框架有望为农业决策提供支持，帮助解决当前农业智能系统存在的问题，推动农业的智能化发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：农业正在经历由人工智能（AI）、机器学习和知识表示技术驱动的重大变革。然而，当前农业智能系统通常缺乏情境理解、可解释性和适应性，尤其是在资源有限的小农户中。通用的大语言模型（LLM）虽然功能强大，但通常缺乏农业领域特定的知识和情境推理，这些是实际农业决策支持所必需的。它们往往产生过于通用的或不切实际的推荐，适用于现实世界的应用。为了解决这些挑战，我们提出了OpenAg，这是一个旨在推动农业人工智能（AGI）的综合框架。OpenAg结合了特定领域的基座模型、神经网络知识图谱、多智能体推理、因果可解释性和自适应迁移学习，以提供情境感知、可解释和可操作的见解。该系统包括：（一）一个统一的农业知识库，整合科学文献、传感器数据和农民生成的知识；（二）一个用于结构化推理和推理的神经网络农业知识图谱；（三）一个自适应的多智能体推理系统，其中AI智能体在农业领域专业化和协作；（四）一个因果透明机制，确保AI建议是可解释的、科学依据的并与现实世界约束一致。OpenAg的目标是弥合科学知识与经验丰富的农民的隐性专业知识之间的差距，以支持可扩展且与当地相关的农业决策。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Agriculture is undergoing a major transformation driven by artificialintelligence (AI), machine learning, and knowledge representation technologies.However, current agricultural intelligence systems often lack contextualunderstanding, explainability, and adaptability, especially for smallholderfarmers with limited resources. General-purpose large language models (LLMs),while powerful, typically lack the domain-specific knowledge and contextualreasoning needed for practical decision support in farming. They tend toproduce recommendations that are too generic or unrealistic for real-worldapplications. To address these challenges, we present OpenAg, a comprehensiveframework designed to advance agricultural artificial general intelligence(AGI). OpenAg combines domain-specific foundation models, neural knowledgegraphs, multi-agent reasoning, causal explainability, and adaptive transferlearning to deliver context-aware, explainable, and actionable insights. Thesystem includes: (i) a unified agricultural knowledge base that integratesscientific literature, sensor data, and farmer-generated knowledge; (ii) aneural agricultural knowledge graph for structured reasoning and inference;(iii) an adaptive multi-agent reasoning system where AI agents specialize andcollaborate across agricultural domains; and (iv) a causal transparencymechanism that ensures AI recommendations are interpretable, scientificallygrounded, and aligned with real-world constraints. OpenAg aims to bridge thegap between scientific knowledge and the tacit expertise of experienced farmersto support scalable and locally relevant agricultural decision-making.</description>
      <author>example@mail.com (Srikanth Thudumu, Jason Fisher)</author>
      <guid isPermaLink="false">2506.04571v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Towards LLM-Centric Multimodal Fusion: A Survey on Integration Strategies and Techniques</title>
      <link>http://arxiv.org/abs/2506.04788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 3 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对多模态大型语言模型（MLLMs）的研究进展进行了综述，分析了当前的方法，并提出了一个基于三个关键维度的分类框架。&lt;h4&gt;背景&lt;/h4&gt;MLLMs的快速发展改变了人工智能的格局，这些模型结合了预训练的大型语言模型和各种模态编码器。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供一个以LLM为中心的分析，填补现有文献中关于如何将不同模态输入转换为语言嵌入空间的方法的空白。&lt;h4&gt;方法&lt;/h4&gt;提出了一个基于三个关键维度的分类框架：模态集成架构策略、表示学习技术（联合或协调表示）和训练范式（包括训练策略和目标函数）。通过分析2021年至2025年间开发的125个MLLMs，识别了该领域的趋势。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出了一个分类框架，为研究人员提供了一个当前集成技术的结构化概述，并识别了MLLMs领域的趋势。&lt;h4&gt;结论&lt;/h4&gt;这些见解旨在指导基于预训练基础的未来模型开发更鲁棒的多模态集成策略。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态大型语言模型（MLLMs）的快速发展已经改变了人工智能的格局。这些模型结合了预训练的大型语言模型和各种模态编码器。这种集成需要对不同模态如何连接到语言骨干的系统理解。我们的调查提供了一个以LLM为中心的当前方法的分析。我们检查了将各种模态输入转换为语言嵌入空间的方法。这解决了现有文献中的一个重大空白。我们基于三个关键维度提出了一个MLLMs的分类框架。首先，我们考察了模态集成架构策略，包括具体的集成机制和融合级别。其次，我们将表示学习技术分类为联合或协调表示。第三，我们分析了训练范式，包括训练策略和目标函数。通过分析2021年至2025年间开发的125个MLLMs，我们确定了该领域的趋势。我们的分类法为研究人员提供了一个当前集成技术的结构化概述。这些见解旨在指导基于预训练基础的未来模型开发更鲁棒的多模态集成策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid progress of Multimodal Large Language Models(MLLMs) has transformedthe AI landscape. These models combine pre-trained LLMs with various modalityencoders. This integration requires a systematic understanding of how differentmodalities connect to the language backbone. Our survey presents an LLM-centricanalysis of current approaches. We examine methods for transforming andaligning diverse modal inputs into the language embedding space. This addressesa significant gap in existing literature. We propose a classification frameworkfor MLLMs based on three key dimensions. First, we examine architecturalstrategies for modality integration. This includes both the specificintegration mechanisms and the fusion level. Second, we categorizerepresentation learning techniques as either joint or coordinaterepresentations. Third, we analyze training paradigms, including trainingstrategies and objective functions. By examining 125 MLLMs developed between2021 and 2025, we identify emerging patterns in the field. Our taxonomyprovides researchers with a structured overview of current integrationtechniques. These insights aim to guide the development of more robustmultimodal integration strategies for future models built on pre-trainedfoundations.</description>
      <author>example@mail.com (Jisu An, Junseok Lee, Jeoungeun Lee, Yongseok Son)</author>
      <guid isPermaLink="false">2506.04788v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Unfolding Spatial Cognition: Evaluating Multimodal Models on Visual Simulations</title>
      <link>http://arxiv.org/abs/2506.04633v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  STARE is available at https://github.com/STARE-bench/STARE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了STARE基准，旨在评估多模态大型语言模型在需要多步视觉模拟的任务上的表现。&lt;h4&gt;背景&lt;/h4&gt;现有AI基准主要评估语言推理，忽略了非语言、多步视觉模拟的复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出STARE基准，以严格评估多模态大型语言模型在通过多步视觉模拟解决的任务上的能力。&lt;h4&gt;方法&lt;/h4&gt;STARE基准包含4K个任务，涵盖基础几何变换（2D和3D）、集成空间推理（立方体网络折叠和七巧板谜题）以及现实世界空间推理（透视和时空推理）。&lt;h4&gt;主要发现&lt;/h4&gt;模型在简单的2D变换推理上表现良好，但在需要多步视觉模拟的复杂任务上，如3D立方体网络折叠和七巧板谜题，表现接近随机机会。人类在复杂任务上达到几乎完美的准确率，但耗时较长（最多28.9秒），通过中间视觉模拟可以显著加快（平均减少7.5秒）。模型从视觉模拟中获得的性能提升不一致，大多数任务上有所提升，但在特定情况下如七巧板谜题（GPT-4o, o1）和立方体网络折叠（Claude-3.5, Gemini-2.0Flash）上有所下降，表明模型可能不知道如何有效地利用中间视觉信息。&lt;h4&gt;结论&lt;/h4&gt;STARE基准揭示了多模态大型语言模型在空间认知任务上的局限性和潜力，为未来的研究提供了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial cognition is essential for human intelligence, enablingproblem-solving through visual simulations rather than solely relying on verbalreasoning. However, existing AI benchmarks primarily assess verbal reasoning,neglecting the complexities of non-verbal, multi-step visual simulation. Weintroduce STARE(Spatial Transformations and Reasoning Evaluation), a benchmarkdesigned to rigorously evaluate multimodal large language models on tasksbetter solved through multi-step visual simulation. STARE features 4K tasksspanning foundational geometric transformations (2D and 3D), integrated spatialreasoning (cube net folding and tangram puzzles), and real-world spatialreasoning (perspective and temporal reasoning), reflecting practical cognitivechallenges like object assembly, mechanical diagram interpretation, andeveryday spatial navigation. Our evaluations show that models excel atreasoning over simpler 2D transformations, but perform close to random chanceon more complex tasks like 3D cube net folding and tangram puzzles that requiremulti-step visual simulations. Humans achieve near-perfect accuracy but takeconsiderable time (up to 28.9s) on complex tasks, significantly speeding up(down by 7.5 seconds on average) with intermediate visual simulations. Incontrast, models exhibit inconsistent performance gains from visualsimulations, improving on most tasks but declining in specific cases liketangram puzzles (GPT-4o, o1) and cube net folding (Claude-3.5, Gemini-2.0Flash), indicating that models may not know how to effectively leverageintermediate visual information.</description>
      <author>example@mail.com (Linjie Li, Mahtab Bigverdi, Jiawei Gu, Zixian Ma, Yinuo Yang, Ziang Li, Yejin Choi, Ranjay Krishna)</author>
      <guid isPermaLink="false">2506.04633v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>RoboRefer: Towards Spatial Referring with Reasoning in Vision-Language Models for Robotics</title>
      <link>http://arxiv.org/abs/2506.04308v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://zhoues.github.io/RoboRefer/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了RoboRefer，一个能够准确理解和动态推理的3D-aware VLM，并通过RefSpatial和RefSpatial-Bench等工具支持其训练和评估。&lt;h4&gt;背景&lt;/h4&gt;尽管预训练的视觉语言模型（VLMs）强大，但近期方法在理解复杂3D场景和动态推理指令指示的位置方面仍不理想。&lt;h4&gt;目的&lt;/h4&gt;设计RoboRefer以实现精确的3D空间理解，并通过多步骤空间推理提升泛化能力。&lt;h4&gt;方法&lt;/h4&gt;RoboRefer通过集成解耦的深度编码器进行监督微调（SFT），并使用强化微调（RFT）进行多步骤空间推理。RefSpatial是一个包含大量QA对的大规模数据集，支持复杂推理过程。RefSpatial-Bench是一个用于评估多步骤空间推理的基准。&lt;h4&gt;主要发现&lt;/h4&gt;SFT训练的RoboRefer在空间理解上达到最先进的水平，平均成功率为89.6%。RFT训练的RoboRefer在RefSpatial-Bench上超过了所有其他基线，平均准确率比Gemini-2.5-Pro高17.4%。RoboRefer可以与多种控制策略集成，以执行不同机器人上的长时程、动态任务。&lt;h4&gt;结论&lt;/h4&gt;RoboRefer在空间理解和动态推理方面表现出色，为机器人与3D物理世界交互提供了有效的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial referring is a fundamental capability of embodied robots to interactwith the 3D physical world. However, even with the powerful pretrained visionlanguage models (VLMs), recent approaches are still not qualified to accuratelyunderstand the complex 3D scenes and dynamically reason about theinstruction-indicated locations for interaction. To this end, we proposeRoboRefer, a 3D-aware VLM that can first achieve precise spatial understandingby integrating a disentangled but dedicated depth encoder via supervisedfine-tuning (SFT). Moreover, RoboRefer advances generalized multi-step spatialreasoning via reinforcement fine-tuning (RFT), with metric-sensitive processreward functions tailored for spatial referring tasks. To support SFT and RFTtraining, we introduce RefSpatial, a large-scale dataset of 20M QA pairs (2xprior), covering 31 spatial relations (vs. 15 prior) and supporting complexreasoning processes (up to 5 steps). In addition, we introduceRefSpatial-Bench, a challenging benchmark filling the gap in evaluating spatialreferring with multi-step reasoning. Experiments show that SFT-trainedRoboRefer achieves state-of-the-art spatial understanding, with an averagesuccess rate of 89.6%. RFT-trained RoboRefer further outperforms all otherbaselines by a large margin, even surpassing Gemini-2.5-Pro by 17.4% in averageaccuracy on RefSpatial-Bench. Notably, RoboRefer can be integrated with variouscontrol policies to execute long-horizon, dynamic tasks across diverse robots(e,g., UR5, G1 humanoid) in cluttered real-world scenes.</description>
      <author>example@mail.com (Enshen Zhou, Jingkun An, Cheng Chi, Yi Han, Shanyu Rong, Chi Zhang, Pengwei Wang, Zhongyuan Wang, Tiejun Huang, Lu Sheng, Shanghang Zhang)</author>
      <guid isPermaLink="false">2506.04308v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Machine Learning for Scientific Discovery: Workflow and Best Practices</title>
      <link>http://arxiv.org/abs/2506.04553v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 4 figures, 12 additional pages of citations&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结构化的工作流程，用于在科学研究中应用无监督学习技术，旨在提高无监督学习发现的可靠性和可重复性。&lt;h4&gt;背景&lt;/h4&gt;无监督学习在气候科学、生物医学、天文学、化学等领域被广泛应用，但缺乏标准化工作流程，导致科学发现不可靠且难以重复。&lt;h4&gt;目的&lt;/h4&gt;提出一种结构化的无监督学习工作流程，以提高科学发现的可靠性和可重复性。&lt;h4&gt;方法&lt;/h4&gt;包括制定可验证的科学问题、进行稳健的数据准备和探索、使用多种建模技术、通过评估无监督学习结论的稳定性和泛化能力进行严格验证，以及促进结果的有效沟通和记录。&lt;h4&gt;主要发现&lt;/h4&gt;通过天文学案例研究，展示了验证的重要性，并说明了精心设计的无监督学习工作流程如何促进科学发现。&lt;h4&gt;结论&lt;/h4&gt;采用结构化的无监督学习工作流程可以显著提高科学发现的可靠性和可重复性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised machine learning is widely used to mine large, unlabeleddatasets to make data-driven discoveries in critical domains such as climatescience, biomedicine, astronomy, chemistry, and more. However, despite itswidespread utilization, there is a lack of standardization in unsupervisedlearning workflows for making reliable and reproducible scientific discoveries.In this paper, we present a structured workflow for using unsupervised learningtechniques in science. We highlight and discuss best practices starting withformulating validatable scientific questions, conducting robust datapreparation and exploration, using a range of modeling techniques, performingrigorous validation by evaluating the stability and generalizability ofunsupervised learning conclusions, and promoting effective communication anddocumentation of results to ensure reproducible scientific discoveries. Toillustrate our proposed workflow, we present a case study from astronomy,seeking to refine globular clusters of Milky Way stars based upon theirchemical composition. Our case study highlights the importance of validationand illustrates how the benefits of a carefully-designed workflow forunsupervised learning can advance scientific discovery.</description>
      <author>example@mail.com (Andersen Chang, Tiffany M. Tang, Tarek M. Zikry, Genevera I. Allen)</author>
      <guid isPermaLink="false">2506.04553v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Physics Informed Capsule Enhanced Variational AutoEncoder for Underwater Image Enhancement</title>
      <link>http://arxiv.org/abs/2506.04753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的双流架构，通过显式集成Jaffe-McGlamery物理模型和基于胶囊聚类的特征表示学习，实现了最先进的水下图像增强。&lt;h4&gt;背景&lt;/h4&gt;水下图像增强是一个具有挑战性的领域，需要同时考虑物理和感知因素。&lt;h4&gt;目的&lt;/h4&gt;开发一种参数自由的水下图像增强方法，同时保持语义结构和细粒度细节。&lt;h4&gt;方法&lt;/h4&gt;该方法同时估计传输图和空间变化的背景光，通过专门的物理估计器，同时在并行流中通过胶囊聚类提取实体级特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在六个具有挑战性的基准测试中进行了广泛的实验，结果表明，与现有最佳方法相比，PSNR提高了0.5dB，同时计算复杂度（FLOPs）减少了三分之二，或者与具有相似计算预算的方法相比，PSNR提高了超过1dB。&lt;h4&gt;结论&lt;/h4&gt;该方法在物理遵守和感知质量方面都取得了显著的成果，并且计算效率高。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新的双流架构，通过显式集成Jaffe-McGlamery物理模型与基于胶囊聚类的特征表示学习，实现了最先进的水下图像增强。我们的方法同时估计传输图和空间变化的背景光，通过专门的物理估计器，同时在并行流中通过胶囊聚类提取实体级特征。这种物理引导的方法实现了参数自由增强，同时尊重水下形成约束，并保持语义结构和细粒度细节。我们的方法还具有一个新颖的优化目标，确保在多个空间频率上既符合物理约束又具有良好的感知质量。为了验证我们的方法，我们在六个具有挑战性的基准测试中进行了广泛的实验。结果表明，与现有最佳方法相比，PSNR提高了0.5dB，同时计算复杂度（FLOPs）减少了三分之二，或者与具有相似计算预算的方法相比，PSNR提高了超过1dB。代码和数据将在https://github.com/iN1k1/上提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel dual-stream architecture that achieves state-of-the-artunderwater image enhancement by explicitly integrating the Jaffe-McGlameryphysical model with capsule clustering-based feature representation learning.Our method simultaneously estimates transmission maps and spatially-varyingbackground light through a dedicated physics estimator while extractingentity-level features via capsule clustering in a parallel stream. Thisphysics-guided approach enables parameter-free enhancement that respectsunderwater formation constraints while preserving semantic structures andfine-grained details. Our approach also features a novel optimization objectiveensuring both physical adherence and perceptual quality across multiple spatialfrequencies. To validate our approach, we conducted extensive experimentsacross six challenging benchmarks. Results demonstrate consistent improvementsof $+0.5$dB PSNR over the best existing methods while requiring only one-thirdof their computational complexity (FLOPs), or alternatively, more than $+1$dBPSNR improvement when compared to methods with similar computational budgets.Code and data \textit{will} be available at https://github.com/iN1k1/.</description>
      <author>example@mail.com (Niki Martinel, Rita Pucci)</author>
      <guid isPermaLink="false">2506.04753v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Influence Functions for Edge Edits in Non-Convex Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.04694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种适用于图神经网络（GNNs）的近端Bregman响应函数，用于更有效地预测边删除的影响，提高GNN的可解释性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;理解个体边对图神经网络行为的影响对于提高其可解释性和鲁棒性至关重要。现有的图影响函数方法依赖于严格的凸性假设，只考虑边删除的影响，而忽略了边插入的影响，并且未能捕捉到这些修改引起的信息传播变化。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来准确预测GNNs中边删除和插入的影响。&lt;h4&gt;方法&lt;/h4&gt;提出了一种适用于GNNs的近端Bregman响应函数，该方法放宽了凸性要求，并使影响预测适用于标准的神经网络架构。此外，该方法明确考虑了信息传播效应，并将影响预测扩展到边删除和插入。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法能够对现实世界数据集中的不同GNNs特性进行准确的影响预测。此外，影响函数在图重连和对抗攻击等应用中表现出多功能性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法可以有效地预测GNNs中边删除和插入的影响，为提高GNN的可解释性和鲁棒性提供了新的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding how individual edges influence the behavior of graph neuralnetworks (GNNs) is essential for improving their interpretability androbustness. Graph influence functions have emerged as promising tools toefficiently estimate the effects of edge deletions without retraining. However,existing influence prediction methods rely on strict convexity assumptions,exclusively consider the influence of edge deletions while disregarding edgeinsertions, and fail to capture changes in message propagation caused by thesemodifications. In this work, we propose a proximal Bregman response functionspecifically tailored for GNNs, relaxing the convexity requirement and enablingaccurate influence prediction for standard neural network architectures.Furthermore, our method explicitly accounts for message propagation effects andextends influence prediction to both edge deletions and insertions in aprincipled way. Experiments with real-world datasets demonstrate accurateinfluence predictions for different characteristics of GNNs. We furtherdemonstrate that the influence function is versatile in applications such asgraph rewiring and adversarial attacks.</description>
      <author>example@mail.com (Jaeseung Heo, Kyeongheung Yun, Seokwon Yoon, MoonJeong Park, Jungseul Ok, Dongwoo Kim)</author>
      <guid isPermaLink="false">2506.04694v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Contrastive Learning in Session-based Recommendation</title>
      <link>http://arxiv.org/abs/2506.05044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted by Pattern Recognition&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MACL的新型多模态自适应对比学习框架，用于解决基于会话的推荐中的数据稀疏性问题，并通过实验证明了其在真实世界数据集上的优越性。&lt;h4&gt;背景&lt;/h4&gt;会话推荐旨在基于用户有限行为预测匿名用户的意图，对比学习在此任务中表现出缓解数据稀疏性的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提升基于会话的推荐系统，解决现有对比学习方法存在的三个问题：忽视项目级稀疏性、未确保增强视图的语义一致性、对正负信号的处理不平等。&lt;h4&gt;方法&lt;/h4&gt;设计了一个多模态增强策略来生成语义一致的项目和会话级视图，并提出了一种自适应对比损失函数来区分正负信号的贡献，从而提升自监督学习。&lt;h4&gt;主要发现&lt;/h4&gt;现有的基于对比学习的方法存在三个主要障碍：忽视项目级稀疏性、未确保增强视图的语义一致性、对正负信号的处理不平等。&lt;h4&gt;结论&lt;/h4&gt;MACL在三个真实世界数据集上的实验结果表明，其优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于会话的推荐旨在基于有限的行为预测匿名用户的意图。对比学习具有缓解数据稀疏性的能力，但现有的基于对比学习的方法仍存在三个问题：它们忽视了项目级稀疏性，主要关注会话级稀疏性；它们通常使用项目ID（如裁剪、掩码和重排）来增强会话，未能确保增强视图的语义一致性；它们对正负信号一视同仁，没有考虑它们的效用差异。因此，我们提出了一种新的多模态自适应对比学习框架，称为MACL，用于基于会话的推荐。在MACL中，我们设计了一种多模态增强策略，通过利用项目多模态特征生成语义一致的项目和会话级视图。此外，我们还提出了一种自适应对比损失函数，以区分正负信号的不同贡献，从而提高自监督学习。在三个真实世界数据集上的大量实验表明，MACL优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Session-based recommendation aims to predict intents of anonymous users basedon limited behaviors. With the ability in alleviating data sparsity,contrastive learning is prevailing in the task. However, we spot that existingcontrastive learning based methods still suffer from three obstacles: (1) theyoverlook item-level sparsity and primarily focus on session-level sparsity; (2)they typically augment sessions using item IDs like crop, mask and reorder,failing to ensure the semantic consistency of augmented views; (3) they treatall positive-negative signals equally, without considering their varyingutility. To this end, we propose a novel multi-modal adaptive contrastivelearning framework called MACL for session-based recommendation. In MACL, amulti-modal augmentation is devised to generate semantically consistent viewsat both item and session levels by leveraging item multi-modal features.Besides, we present an adaptive contrastive loss that distinguishes varyingcontributions of positive-negative signals to improve self-supervised learning.Extensive experiments on three real-world datasets demonstrate the superiorityof MACL over state-of-the-art methods.</description>
      <author>example@mail.com (Xiaokun Zhang, Bo Xu, Fenglong Ma, Zhizheng Wang, Liang Yang, Hongfei Lin)</author>
      <guid isPermaLink="false">2506.05044v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Neurosymbolic Artificial Intelligence for Robust Network Intrusion Detection: From Scratch to Transfer Learning</title>
      <link>http://arxiv.org/abs/2506.04454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 5 figures, 11 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文扩展了ODXU神经符号AI框架，用于网络入侵检测系统，提高了鲁棒性、可解释性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;网络入侵检测系统在保护数字基础设施免受复杂网络威胁方面发挥着重要作用。&lt;h4&gt;目的&lt;/h4&gt;提高网络入侵检测系统的鲁棒性、可解释性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;ODXU框架结合了深度嵌入聚类、XGBoost符号推理和不确定性量化。使用基于分数的方法和基于元模型的技术来评估预测的可靠性，并开发了迁移学习策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ODXU在CIC-IDS-2017数据集上优于传统神经网络模型。迁移学习策略在ACI-IoT-2023数据集上表现出色，即使在样本量较少的情况下也优于传统神经网络模型。基于元模型的不确定性量化方法在两个数据集上都优于基于分数的方法。&lt;h4&gt;结论&lt;/h4&gt;ODXU框架及其迁移学习策略在网络安全领域具有潜在的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Network Intrusion Detection Systems (NIDS) play a vital role in protectingdigital infrastructures against increasingly sophisticated cyber threats. Inthis paper, we extend ODXU, a Neurosymbolic AI (NSAI) framework that integratesdeep embedded clustering for feature extraction, symbolic reasoning usingXGBoost, and comprehensive uncertainty quantification (UQ) to enhancerobustness, interpretability, and generalization in NIDS. The extended ODXUincorporates score-based methods (e.g., Confidence Scoring, Shannon Entropy)and metamodel-based techniques, including SHAP values and Information Gain, toassess the reliability of predictions. Experimental results on the CIC-IDS-2017dataset show that ODXU outperforms traditional neural models across sixevaluation metrics, including classification accuracy and false omission rate.While transfer learning has seen widespread adoption in fields such as computervision and natural language processing, its potential in cybersecurity has notbeen thoroughly explored. To bridge this gap, we develop a transfer learningstrategy that enables the reuse of a pre-trained ODXU model on a differentdataset. Our ablation study on ACI-IoT-2023 demonstrates that the optimaltransfer configuration involves reusing the pre-trained autoencoder, retrainingthe clustering module, and fine-tuning the XGBoost classifier, and outperformstraditional neural models when trained with as few as 16,000 samples(approximately 50% of the training data). Additionally, results show thatmetamodel-based UQ methods consistently outperform score-based approaches onboth datasets.</description>
      <author>example@mail.com (Huynh T. T. Tran, Jacob Sander, Achraf Cohen, Brian Jalaian, Nathaniel D. Bastian)</author>
      <guid isPermaLink="false">2506.04454v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>UAV4D: Dynamic Neural Rendering of Human-Centric UAV Imagery using Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.05011v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了UAV4D框架，旨在解决无人机捕获场景中的渲染挑战，特别是在单目摄像头设置、俯视视角和多个人物移动的情况下。&lt;h4&gt;背景&lt;/h4&gt;现有的动态神经渲染方法未能解决无人机捕获场景中的独特挑战，特别是涉及单目摄像头设置、俯视视角和多个小型移动人物的场景，这些场景在现有数据集中没有得到充分体现。&lt;h4&gt;目的&lt;/h4&gt;提出UAV4D框架，实现对无人机捕获的动态现实场景进行逼真渲染，特别是从单目视频数据中重建具有多个移动行人的动态场景，而不需要额外的传感器。&lt;h4&gt;方法&lt;/h4&gt;使用3D基础模型和人体网格重建模型重建场景背景和人物。提出了一种新颖的方法来解决场景尺度模糊问题，通过识别人物-场景接触点来将人物和场景放置在世界坐标中。利用SMPL模型和背景网格初始化高斯斑点，实现场景的整体渲染。&lt;h4&gt;主要发现&lt;/h4&gt;在三个复杂无人机捕获数据集（VisDrone、Manipal-UAV和Okutama-Action）上评估了该方法，这些数据集具有不同的特征，每个数据集中有10~50个人物。结果表明，该方法在新型视图合成方面优于现有方法，实现了1.5 dB PSNR的改进和更优的视觉清晰度。&lt;h4&gt;结论&lt;/h4&gt;UAV4D框架在新型视图合成方面具有显著优势，提高了渲染质量，为无人机捕获的动态场景提供了更逼真的渲染效果。&lt;h4&gt;翻译&lt;/h4&gt;尽管在动态神经渲染方面取得了显著进展，但现有方法未能解决无人机捕获场景中提出的独特挑战，特别是那些涉及单目摄像头设置、俯视视角和多个小型移动人物的场景，这些场景在现有数据集中没有得到充分体现。在这项工作中，我们介绍了UAV4D，这是一个框架，旨在实现对无人机捕获的动态现实场景进行逼真渲染。具体来说，我们解决了从单目视频数据中重建具有多个移动行人的动态场景的挑战，而不需要额外的传感器。我们使用3D基础模型和人体网格重建模型来重建场景背景和人物。我们提出了一种新颖的方法来解决问题场景尺度模糊，通过识别人物-场景接触点将人物和场景放置在世界坐标中。此外，我们利用SMPL模型和背景网格来初始化高斯斑点，实现场景的整体渲染。我们在三个复杂无人机捕获数据集（VisDrone、Manipal-UAV和Okutama-Action）上评估了我们的方法，这些数据集具有不同的特征和10~50个人物。我们的结果表明，与现有方法相比，我们的方法在新型视图合成方面具有优势，实现了1.5 dB PSNR的改进和更优的视觉清晰度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite significant advancements in dynamic neural rendering, existingmethods fail to address the unique challenges posed by UAV-captured scenarios,particularly those involving monocular camera setups, top-down perspective, andmultiple small, moving humans, which are not adequately represented in existingdatasets. In this work, we introduce UAV4D, a framework for enablingphotorealistic rendering for dynamic real-world scenes captured by UAVs.Specifically, we address the challenge of reconstructing dynamic scenes withmultiple moving pedestrians from monocular video data without the need foradditional sensors. We use a combination of a 3D foundation model and a humanmesh reconstruction model to reconstruct both the scene background and humans.We propose a novel approach to resolve the scene scale ambiguity and place bothhumans and the scene in world coordinates by identifying human-scene contactpoints. Additionally, we exploit the SMPL model and background mesh toinitialize Gaussian splats, enabling holistic scene rendering. We evaluated ourmethod on three complex UAV-captured datasets: VisDrone, Manipal-UAV, andOkutama-Action, each with distinct characteristics and 10~50 humans. Ourresults demonstrate the benefits of our approach over existing methods in novelview synthesis, achieving a 1.5 dB PSNR improvement and superior visualsharpness.</description>
      <author>example@mail.com (Jaehoon Choi, Dongki Jung, Christopher Maxey, Yonghan Lee, Sungmin Eum, Dinesh Manocha, Heesung Kwon)</author>
      <guid isPermaLink="false">2506.05011v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Learning dissection trajectories from expert surgical videos via imitation learning with equivariant diffusion</title>
      <link>http://arxiv.org/abs/2506.04716v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为iDPOE的新方法，用于通过模仿学习预测ESD手术中的切割轨迹，以提升手术技能训练并简化学习过程。&lt;h4&gt;背景&lt;/h4&gt;尽管内窥镜黏膜下剥离术（ESD）是一种成熟的移除上皮病变的技术，但预测ESD视频中的切割轨迹对于提高手术技能训练和简化学习过程具有重要意义，这一领域仍处于探索阶段。&lt;h4&gt;目的&lt;/h4&gt;为了解决在处理不确定的未来动作、学习几何对称性和将技能推广到不同的手术场景中存在的挑战，本文旨在提出一种新的方法来预测ESD手术中的切割轨迹。&lt;h4&gt;方法&lt;/h4&gt;iDPOE方法通过联合状态动作分布来模拟专家行为，捕捉切割轨迹的随机性，并通过嵌入等变性来增强模型对几何对称性的泛化能力。此外，通过将扩散模型纳入策略学习，iDPOE确保了高效的训练和采样，并开发了一种前向过程引导的动作推理策略来解决状态不匹配问题。&lt;h4&gt;主要发现&lt;/h4&gt;使用近2000个剪辑的ESD视频数据集进行实验，结果表明，iDPOE方法在轨迹预测方面优于现有的显式和隐式方法。&lt;h4&gt;结论&lt;/h4&gt;iDPOE是首次将模仿学习应用于手术技能发展，特别是用于切割轨迹预测。&lt;h4&gt;翻译&lt;/h4&gt;摘要：内窥镜黏膜下剥离术（ESD）是一种成熟的移除上皮病变的技术。预测ESD视频中的切割轨迹对于提高手术技能训练和简化学习过程具有重要意义，尽管这一领域仍处于探索阶段。虽然模仿学习在从专家演示中获取技能方面显示出希望，但在处理不确定的未来动作、学习几何对称性和将技能推广到不同的手术场景中仍然存在挑战。为了解决这些问题，我们提出了一种新的方法：具有等变性表示的隐式扩散策略模仿学习（iDPOE）。我们的方法通过联合状态动作分布来模拟专家行为，捕捉切割轨迹的随机性，并通过将扩散模型纳入策略学习，确保了高效的训练和采样，从而实现了更准确的预测和更好的泛化。此外，我们通过将等变性嵌入到学习过程中，增强了模型对几何对称性的泛化能力。为了解决状态不匹配问题，我们开发了一种前向过程引导的动作推理策略进行条件采样。使用近2000个剪辑的ESD视频数据集进行的实验结果表明，我们的方法在轨迹预测方面优于现有的显式和隐式方法。据我们所知，这是首次将模仿学习应用于手术技能发展，特别是用于切割轨迹预测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.media.2025.103599&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Endoscopic Submucosal Dissection (ESD) is a well-established technique forremoving epithelial lesions. Predicting dissection trajectories in ESD videosoffers significant potential for enhancing surgical skill training andsimplifying the learning process, yet this area remains underexplored. Whileimitation learning has shown promise in acquiring skills from expertdemonstrations, challenges persist in handling uncertain future movements,learning geometric symmetries, and generalizing to diverse surgical scenarios.To address these, we introduce a novel approach: Implicit Diffusion Policy withEquivariant Representations for Imitation Learning (iDPOE). Our method modelsexpert behavior through a joint state action distribution, capturing thestochastic nature of dissection trajectories and enabling robust visualrepresentation learning across various endoscopic views. By incorporating adiffusion model into policy learning, iDPOE ensures efficient training andsampling, leading to more accurate predictions and better generalization.Additionally, we enhance the model's ability to generalize to geometricsymmetries by embedding equivariance into the learning process. To addressstate mismatches, we develop a forward-process guided action inference strategyfor conditional sampling. Using an ESD video dataset of nearly 2000 clips,experimental results show that our approach surpasses state-of-the-art methods,both explicit and implicit, in trajectory prediction. To the best of ourknowledge, this is the first application of imitation learning to surgicalskill development for dissection trajectory prediction.</description>
      <author>example@mail.com (Hongyu Wang, Yonghao Long, Yueyao Chen, Hon-Chi Yip, Markus Scheppach, Philip Wai-Yan Chiu, Yeung Yam, Helen Mei-Ling Meng, Qi Dou)</author>
      <guid isPermaLink="false">2506.04716v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Object-X: Learning to Reconstruct Multi-Modal 3D Object Representations</title>
      <link>http://arxiv.org/abs/2506.04789v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Object-X的多模态物体表示框架，能够编码丰富的物体嵌入（如图像、点云、文本），并将其解码为详细的几何和视觉重建。&lt;h4&gt;背景&lt;/h4&gt;学习有效的多模态3D物体表示对于增强现实和机器人等应用至关重要。现有方法通常依赖于针对特定任务的嵌入，这些嵌入要么用于语义理解，要么用于几何重建，因此通常不能解码为显式的几何形状，也不能跨任务重用。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够编码和重建多模态物体表示的通用框架。&lt;h4&gt;方法&lt;/h4&gt;Object-X通过在3D体素网格中几何地定位捕获的模态，并学习一个非结构化的嵌入，融合体素信息和物体属性来操作。该嵌入使基于3D高斯Splatting的物体重建成为可能，同时支持包括场景对齐、单图像3D物体重建和定位在内的多种下游任务。&lt;h4&gt;主要发现&lt;/h4&gt;在两个具有挑战性的真实世界数据集上的评估表明，Object-X产生了与标准3D高斯Splatting相当的高保真新视图合成，同时显著提高了几何精度。此外，Object-X在场景对齐和定位方面与专用方法具有竞争力。关键的是，与传统的基于图像或点云的方法相比，我们的以物体为中心的描述符所需的存储量降低了3-4个数量级。&lt;h4&gt;结论&lt;/h4&gt;Object-X是一种可扩展且高度实用的多模态3D场景表示解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning effective multi-modal 3D representations of objects is essential fornumerous applications, such as augmented reality and robotics. Existing methodsoften rely on task-specific embeddings that are tailored either for semanticunderstanding or geometric reconstruction. As a result, these embeddingstypically cannot be decoded into explicit geometry and simultaneously reusedacross tasks. In this paper, we propose Object-X, a versatile multi-modalobject representation framework capable of encoding rich object embeddings(e.g. images, point cloud, text) and decoding them back into detailed geometricand visual reconstructions. Object-X operates by geometrically grounding thecaptured modalities in a 3D voxel grid and learning an unstructured embeddingfusing the information from the voxels with the object attributes. The learnedembedding enables 3D Gaussian Splatting-based object reconstruction, while alsosupporting a range of downstream tasks, including scene alignment, single-image3D object reconstruction, and localization. Evaluations on two challengingreal-world datasets demonstrate that Object-X produces high-fidelity novel-viewsynthesis comparable to standard 3D Gaussian Splatting, while significantlyimproving geometric accuracy. Moreover, Object-X achieves competitiveperformance with specialized methods in scene alignment and localization.Critically, our object-centric descriptors require 3-4 orders of magnitude lessstorage compared to traditional image- or point cloud-based approaches,establishing Object-X as a scalable and highly practical solution formulti-modal 3D scene representation.</description>
      <author>example@mail.com (Gaia Di Lorenzo, Federico Tombari, Marc Pollefeys, Daniel Barath)</author>
      <guid isPermaLink="false">2506.04789v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>The Oversmoothing Fallacy: A Misguided Narrative in GNN Research</title>
      <link>http://arxiv.org/abs/2506.04653v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了深度图神经网络（GNNs）中过度平滑问题，并提出了对深度GNN架构进一步探索的建议。&lt;h4&gt;背景&lt;/h4&gt;过度平滑被认为是构建深度GNN的主要障碍，限制了其性能。&lt;h4&gt;目的&lt;/h4&gt;本文旨在挑战过度平滑的影响被高估的观点，并倡导对深度GNN架构进行更深入的探索。&lt;h4&gt;方法&lt;/h4&gt;分析了GNN的三个核心操作：聚合、线性变换和非线性激活，并指出先前研究错误地将过度平滑与梯度消失混淆，后者是由变换和激活引起的，而不是聚合。&lt;h4&gt;主要发现&lt;/h4&gt;发现过度平滑并非GNN独有的问题，并展示了跳过连接和归一化等经典解决方案可以使深度GNN层成功堆叠而不降低性能。&lt;h4&gt;结论&lt;/h4&gt;本文澄清了关于过度平滑的误解，并为深度GNN的潜力提供了新的见解。&lt;h4&gt;翻译&lt;/h4&gt;Oversmoothing has been recognized as a main obstacle to building deep GraphNeural Networks (GNNs), limiting the performance. This position paper arguesthat the influence of oversmoothing has been overstated and advocates for afurther exploration of deep GNN architectures. Given the three core operations of GNNs, aggregation, linear transformation, and non-linear activation, we showthat prior studies have mistakenly confused oversmoothing with the vanishinggradient, caused by transformation and activation rather than aggregation. Ourfinding challenges prior beliefs about oversmoothing being unique to GNNs. Furthermore, we demonstrate that classical solutions such as skip connections and normalization enable the successful stacking of deep GNN layers without performance degradation. Our results clarify misconceptions about oversmoothing and shed new light on the potential of deep GNNs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Oversmoothing has been recognized as a main obstacle to building deep GraphNeural Networks (GNNs), limiting the performance. This position paper arguesthat the influence of oversmoothing has been overstated and advocates for afurther exploration of deep GNN architectures. Given the three core operationsof GNNs, aggregation, linear transformation, and non-linear activation, we showthat prior studies have mistakenly confused oversmoothing with the vanishinggradient, caused by transformation and activation rather than aggregation. Ourfinding challenges prior beliefs about oversmoothing being unique to GNNs.Furthermore, we demonstrate that classical solutions such as skip connectionsand normalization enable the successful stacking of deep GNN layers withoutperformance degradation. Our results clarify misconceptions about oversmoothingand shed new light on the potential of deep GNNs.</description>
      <author>example@mail.com (MoonJeong Park, Sunghyun Choi, Jaeseung Heo, Eunhyeok Park, Dongwoo Kim)</author>
      <guid isPermaLink="false">2506.04653v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Triple Attention Transformer Architecture for Time-Dependent Concrete Creep Prediction</title>
      <link>http://arxiv.org/abs/2506.04243v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的三重注意力Transformer架构，用于预测时间依赖性的混凝土蠕变，解决了当前方法中将时间仅视为输入参数而不是模拟变形发展序列性质的根本局限性。&lt;h4&gt;背景&lt;/h4&gt;当前方法在混凝土蠕变预测中处理时间的方式存在问题，没有充分捕捉到变形发展的序列性质。&lt;h4&gt;目的&lt;/h4&gt;将混凝土蠕变预测转化为自回归序列建模任务，类似于语言处理，以利用Transformer的自注意力机制捕捉历史蠕变模式中的长距离依赖关系。&lt;h4&gt;方法&lt;/h4&gt;模型实现了一个三流注意力框架，包括时间注意力用于序列进展、特征注意力用于材料属性相互作用以及批量注意力用于采样器之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;在标准化的每日测量数据集上评估，该架构实现了优异的性能，平均绝对百分比误差为1.63%，R2值为0.999，显著优于传统的经验模型和现有的机器学习方法。消融研究证实了注意力机制的关键作用，其中注意力池对模型性能的贡献最大。SHAP分析揭示了杨氏模量是主要的预测特征，其次是密度和抗压强度，这为工程应用提供了可解释性。部署的基于网络的界面促进了实际实施，允许使用标准实验室参数进行实时预测。&lt;h4&gt;结论&lt;/h4&gt;这项工作证明了将Transformer架构应用于材料科学问题的可行性，展示了数据驱动方法在结构行为预测和工程设计实践中的革命性潜力。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的三重注意力变换器架构，用于预测时间相关的混凝土蠕变，解决了当前方法中将时间仅仅视为输入参数而不是模拟变形发展序列性质的基本局限性。通过将混凝土蠕变预测转化为类似于语言处理的自回归序列建模任务，我们的架构利用了变换器的自注意力机制来捕捉历史蠕变模式中的长距离依赖关系。该模型实现了包含时间注意力（用于序列进展）、特征注意力（用于材料属性相互作用）和批量注意力（用于采样器之间的关系）的三流注意力框架。在跨度为160天的标准化每日测量数据集上评估，该架构实现了卓越的性能，平均绝对百分比误差为1.63%，所有数据集的R2值为0.999，显著优于传统的经验模型和现有的机器学习方法。消融研究证实了注意力机制的关键作用，其中注意力池对模型性能的贡献最大。SHAP分析揭示了杨氏模量是主要的预测特征，其次是密度和抗压强度，这为工程应用提供了可解释性。部署的基于网络的界面促进了实际实施，允许使用标准实验室参数进行实时预测。这项工作证明了将变换器架构应用于材料科学问题的可行性，展示了数据驱动方法在结构行为预测和工程设计实践中的革命性潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel Triple Attention Transformer Architecture forpredicting time-dependent concrete creep, addressing fundamental limitations incurrent approaches that treat time as merely an input parameter rather thanmodeling the sequential nature of deformation development. By transformingconcrete creep prediction into an autoregressive sequence modeling task similarto language processing, our architecture leverages the transformer'sself-attention mechanisms to capture long-range dependencies in historicalcreep patterns. The model implements a triple-stream attention frameworkincorporating temporal attention for sequential progression, feature attentionfor material property interactions, and batch attention for inter-samplerelationships. Evaluated on experimental datasets with standardized dailymeasurements spanning 160 days, the architecture achieves exceptionalperformance with mean absolute percentage error of 1.63% and R2 values of 0.999across all datasets, substantially outperforming traditional empirical modelsand existing machine learning approaches. Ablation studies confirm the criticalrole of attention mechanisms, with attention pooling contributing mostsignificantly to model performance. SHAP analysis reveals Young's modulus asthe primary predictive feature, followed by density and compressive strength,providing interpretability essential for engineering applications. A deployedweb-based interface facilitates practical implementation, enabling real-timepredictions using standard laboratory parameters. This work establishes theviability of applying transformer architectures to materials science problems,demonstrating the potential for data-driven approaches to revolutionizestructural behavior prediction and engineering design practices.</description>
      <author>example@mail.com (Warayut Dokduea, Weerachart Tangchirapat, Sompote Youwai)</author>
      <guid isPermaLink="false">2506.04243v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Ignoring Directionality Leads to Compromised Graph Neural Network Explanations</title>
      <link>http://arxiv.org/abs/2506.04608v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNNs）在关键领域的应用，强调了在支持人类决策中可靠解释的重要性，并指出传统图对称化方法丢弃了方向信息，导致信息损失和误导性解释。通过理论和实证研究，证明了保留方向语义可以显著提高解释质量。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在关键领域越来越受欢迎，但在这些领域中，可靠的解释对于支持人类决策至关重要。&lt;h4&gt;目的&lt;/h4&gt;本文旨在分析图对称化方法对解释准确性的影响，并提出改进的方法以增强GNN的解释能力。&lt;h4&gt;方法&lt;/h4&gt;通过理论和实证研究，分析了图对称化方法对解释准确性的影响，并验证了保留方向语义对解释质量的提升。&lt;h4&gt;主要发现&lt;/h4&gt;图对称化方法导致信息损失和误导性解释，而保留方向语义可以显著提高解释质量。&lt;h4&gt;结论&lt;/h4&gt;本文强调了在安全关键应用中，图神经网络解释的必要性，特别是在保留方向语义方面。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) are increasingly used in critical domains, where reliable explanations are vital for supporting human decision-making. However, the common practice of graph symmetrization discards directional information, leading to significant information loss and misleading explanations. Our analysis demonstrates how this practice compromises explanation fidelity. Through theoretical and empirical studies, we show that preserving directional semantics significantly improves explanation quality, ensuring more faithful insights for human decision-makers. These findings highlight the need for direction-aware GNN explainability in security-critical applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are increasingly used in critical domains, wherereliable explanations are vital for supporting human decision-making. However,the common practice of graph symmetrization discards directional information,leading to significant information loss and misleading explanations. Ouranalysis demonstrates how this practice compromises explanation fidelity.Through theoretical and empirical studies, we show that preserving directionalsemantics significantly improves explanation quality, ensuring more faithfulinsights for human decision-makers. These findings highlight the need fordirection-aware GNN explainability in security-critical applications.</description>
      <author>example@mail.com (Changsheng Sun, Xinke Li, Jin Song Dong)</author>
      <guid isPermaLink="false">2506.04608v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Plan via Supervised Contrastive Learning and Strategic Interpolation: A Chess Case Study</title>
      <link>http://arxiv.org/abs/2506.04892v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于嵌入空间的直觉驱动规划模型，用于模拟人类在棋类游戏中的决策过程，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;现代棋类引擎通过深度树搜索和递归评估实现超人类水平的表现，而人类玩家则依赖直觉选择候选走法，并通过浅层搜索来验证。&lt;h4&gt;目的&lt;/h4&gt;为了模拟人类玩家的直觉驱动规划过程，本文提出了一种使用监督对比学习训练的transformer编码器，将棋盘状态嵌入到一个由位置评估结构化的潜在空间中。&lt;h4&gt;方法&lt;/h4&gt;在潜在空间中，距离反映了评估相似性，可视化的轨迹显示了游戏状态之间的可解释转换。通过在嵌入空间中前进到有利区域，模型可以在不依赖深度搜索的情况下进行走法选择。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，即使使用只有6层广度搜索，该模型也能达到估计的Elo等级分2593。模型性能随着模型大小和嵌入维度的增加而提高，表明潜在规划可能是传统搜索的可行替代方案。&lt;h4&gt;结论&lt;/h4&gt;尽管本文的研究集中在棋类游戏上，但所提出的基于嵌入的规划方法可以推广到其他可学习状态评估的完美信息游戏中。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代象棋引擎通过深度树搜索和递归评估达到超人类的表现，而人类玩家则依靠直觉选择候选走法，随后通过浅层搜索来验证。为了模拟这种直觉驱动的规划过程，我们使用监督对比学习训练了一个transformer编码器，将棋盘状态嵌入到一个由位置评估结构化的潜在空间中。在这个空间中，距离反映了评估相似性，可视化的轨迹显示了游戏状态之间的可解释转换。我们证明了走法选择可以完全在这个嵌入空间内进行，通过向有利区域前进，而不依赖于深度搜索。尽管只使用了6层广度搜索，我们的模型达到了估计的Elo等级分2593。随着模型大小和嵌入维度的增加，性能得到提高，这表明潜在规划可能是传统搜索的可行替代方案。尽管我们关注的是象棋，但所提出的基于嵌入的规划方法可以推广到其他可学习状态评估的完美信息游戏中。所有源代码可在https://github.com/andrewhamara/SOLIS上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern chess engines achieve superhuman performance through deep tree searchand regressive evaluation, while human players rely on intuition to selectcandidate moves followed by a shallow search to validate them. To model thisintuition-driven planning process, we train a transformer encoder usingsupervised contrastive learning to embed board states into a latent spacestructured by positional evaluation. In this space, distance reflectsevaluative similarity, and visualized trajectories display interpretabletransitions between game states. We demonstrate that move selection can occurentirely within this embedding space by advancing toward favorable regions,without relying on deep search. Despite using only a 6-ply beam search, ourmodel achieves an estimated Elo rating of 2593. Performance improves with bothmodel size and embedding dimensionality, suggesting that latent planning mayoffer a viable alternative to traditional search. Although we focus on chess,the proposed embedding-based planning method can be generalized to otherperfect-information games where state evaluations are learnable. All sourcecode is available at https://github.com/andrewhamara/SOLIS.</description>
      <author>example@mail.com (Andrew Hamara, Greg Hamerly, Pablo Rivas, Andrew C. Freeman)</author>
      <guid isPermaLink="false">2506.04892v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Static Word Embeddings for Sentence Semantic Representation</title>
      <link>http://arxiv.org/abs/2506.04624v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了新的静态词嵌入方法，优化了句子的语义表示。&lt;h4&gt;背景&lt;/h4&gt;现有的静态词嵌入模型在句子语义任务上的表现有限。&lt;h4&gt;目的&lt;/h4&gt;提高句子语义任务的性能。&lt;h4&gt;方法&lt;/h4&gt;从预训练的SentenceTransformer中提取词嵌入，通过句子级主成分分析和知识蒸馏或对比学习进行改进。在推理阶段，通过平均词嵌入来表示句子，以降低计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;模型在单语和多语任务上均显著优于现有的静态模型，在某些数据集上甚至与基本的SentenceTransformer模型（SimCSE）相当。此外，方法成功移除了与句子语义无关的词嵌入成分，并根据词对句子语义的影响调整了向量范数。&lt;h4&gt;结论&lt;/h4&gt;提出的方法有效提升了句子语义表示的性能，并为句子语义任务提供了一种新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose new static word embeddings optimised for sentence semanticrepresentation. We first extract word embeddings from a pre-trained SentenceTransformer, and improve them with sentence-level principal component analysis,followed by either knowledge distillation or contrastive learning. Duringinference, we represent sentences by simply averaging word embeddings, whichrequires little computational cost. We evaluate models on both monolingual andcross-lingual tasks and show that our model substantially outperforms existingstatic models on sentence semantic tasks, and even rivals a basic SentenceTransformer model (SimCSE) on some data sets. Lastly, we perform a variety ofanalyses and show that our method successfully removes word embeddingcomponents that are irrelevant to sentence semantics, and adjusts the vectornorms based on the influence of words on sentence semantics.</description>
      <author>example@mail.com (Takashi Wada, Yuki Hirakawa, Ryotaro Shimizu, Takahiro Kawashima, Yuki Saito)</author>
      <guid isPermaLink="false">2506.04624v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Feature-Based Lie Group Transformer for Real-World Applications</title>
      <link>http://arxiv.org/abs/2506.04668v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法，通过结合特征提取和对象分割，将群分解理论应用于更真实的场景，以改善物体识别的表示学习。&lt;h4&gt;背景&lt;/h4&gt;表示学习旨在从现实世界的感官输入中获取有意义的表示，而无需监督。这种方法解释了人类发展的某些方面。&lt;h4&gt;目的&lt;/h4&gt;目的是提出一种新的方法，以克服传统表示学习方法的局限性，例如无法处理具有背景的低分辨率图像。&lt;h4&gt;方法&lt;/h4&gt;方法包括使用伽罗瓦代数理论中的群分解，将像素转换替换为特征转换，并将对象分割表示为在同一变换下的特征分组。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，传统的独立特征轴的解耦表示无法解释条件独立性，而新的方法通过结合特征提取和对象分割，提高了表示的通用性。&lt;h4&gt;结论&lt;/h4&gt;结论是，该方法有望更好地理解人类在现实世界中物体识别的发展。&lt;h4&gt;翻译&lt;/h4&gt;Representation learning aims to acquire meaningful representations from real-world sensory inputs without supervision. This method explains some aspects of human development. Various neural network (NN) models have been proposed that acquire empirically good representations. However, the formulation of a good representation has not been established. We recently proposed a method for categorizing changes between a pair of sensory inputs. A unique feature of this approach is that transformations between two sensory inputs are learned to satisfy algebraic structural constraints. Conventional representation learning often assumes that disentangled independent feature axes is a good representation; however, we found that such a representation cannot account for conditional independence. To overcome this problem, we proposed a new method using group decomposition in Galois algebra theory. Although this method is promising for defining a more general representation, it assumes pixel-to-pixel translation without feature extraction, and can only process low-resolution images with no background, which prevents real-world application. In this study, we provide a simple method to apply our group decomposition theory to a more realistic scenario by combining feature extraction and object segmentation. We replace pixel translation with feature translation and formulate object segmentation as grouping features under the same transformation. We validated the proposed method on a practical dataset containing both real-world object and background. We believe that our model will lead to a better understanding of human development of object recognition in the real world.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The main goal of representation learning is to acquire meaningfulrepresentations from real-world sensory inputs without supervision.Representation learning explains some aspects of human development. Variousneural network (NN) models have been proposed that acquire empirically goodrepresentations. However, the formulation of a good representation has not beenestablished. We recently proposed a method for categorizing changes between apair of sensory inputs. A unique feature of this approach is thattransformations between two sensory inputs are learned to satisfy algebraicstructural constraints. Conventional representation learning often assumes thatdisentangled independent feature axes is a good representation; however, wefound that such a representation cannot account for conditional independence.To overcome this problem, we proposed a new method using group decomposition inGalois algebra theory. Although this method is promising for defining a moregeneral representation, it assumes pixel-to-pixel translation without featureextraction, and can only process low-resolution images with no background,which prevents real-world application. In this study, we provide a simplemethod to apply our group decomposition theory to a more realistic scenario bycombining feature extraction and object segmentation. We replace pixeltranslation with feature translation and formulate object segmentation asgrouping features under the same transformation. We validated the proposedmethod on a practical dataset containing both real-world object and background.We believe that our model will lead to a better understanding of humandevelopment of object recognition in the real world.</description>
      <author>example@mail.com (Takayuki Komatsu, Yoshiyuki Ohmura, Kayato Nishitsunoi, Yasuo Kuniyoshi)</author>
      <guid isPermaLink="false">2506.04668v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Neural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction</title>
      <link>http://arxiv.org/abs/2506.04650v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了神经网络可重构性作为统一框架，将主流模型适应技术（模型重编程、提示微调和提示指令）联系起来，这些技术通过在接口处操纵信息来重新用途预训练模型，同时保持模型参数不变。&lt;h4&gt;背景&lt;/h4&gt;随着大规模预训练基础模型在规模和能力上的扩展，有效地适应特定下游任务变得越来越关键。现有的适应方法大多在孤立中发展，缺乏对它们之间相互关系的清晰理解。&lt;h4&gt;目的&lt;/h4&gt;提出神经网络可重构性作为统一框架，以便更好地理解和管理不同模型适应技术之间的联系。&lt;h4&gt;方法&lt;/h4&gt;引入了神经网络可重构性作为统一框架，并提出了一个分类法，从四个关键维度（操作格式、位置、操作符和输出对齐需求）对基于信息操纵的适应方法进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;该框架适用于不同数据模态，不依赖于特定模型架构。通过这一框架可以揭示现有技术如情境学习和思维链提示的理论联系和实践区别。&lt;h4&gt;结论&lt;/h4&gt;神经网络可重构性被视为有效模型适应的基本范式，并指出了由此产生的有希望的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了神经网络可重构性作为统一框架，将主流模型适应技术（模型重编程、提示微调和提示指令）联系起来，这些技术通过在接口处操纵信息来重新用途预训练模型，同时保持模型参数不变。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As large-scale pre-trained foundation models continue to expand in size andcapability, efficiently adapting them to specific downstream tasks has becomeincreasingly critical. Despite substantial progress, existing adaptationapproaches have evolved largely in isolation, without a clear understanding oftheir interrelationships. This survey introduces neural networkreprogrammability as a unifying framework that bridges mainstream modeladaptation techniques--model reprogramming, prompt tuning, and promptinstruction--previously fragmented research areas yet converges on a sharedprinciple: repurposing a pre-trained model by manipulating information at theinterfaces while keeping the model parameters frozen. These methods exploitneural networks' sensitivity to manipulation on different interfaces, be itthrough perturbing inputs, inserting tokens into intermediate layers, orproviding task-specific examples in context, to redirect model behaviorstowards desired outcomes. We then present a taxonomy that categorizes suchinformation manipulation-based adaptation approaches across four keydimensions: manipulation format (fixed or learnable), location (interfaceswhere manipulations occur), operator (how they are applied), and outputalignment requirement (post-processing needed to align outputs with downstreamtasks). Notably, this framework applies consistently across data modalities,independent of specific model architectures. Moreover, viewing establishedtechniques like in-context learning and chain-of-thought prompting through thislens reveals both their theoretical connections and practical distinctions. Wefurther analyze remaining technical challenges and ethical considerations,positioning neural network reprogrammability as a fundamental paradigm forefficient model adaptation. We lastly identify promising research directionsemerging from this integrative viewpoint.</description>
      <author>example@mail.com (Zesheng Ye, Chengyi Cai, Ruijiang Dong, Jianzhong Qi, Lei Feng, Pin-Yu Chen, Feng Liu)</author>
      <guid isPermaLink="false">2506.04650v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Follow-Your-Creation: Empowering 4D Creation through Video Inpainting</title>
      <link>http://arxiv.org/abs/2506.04590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://follow-your-creation.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为Follow-Your-Creation的4D视频创作框架，该框架能够从单目视频输入中生成和编辑4D内容。&lt;h4&gt;背景&lt;/h4&gt;目前4D视频创作需要多个视角的视频，而本文提出的方法只需要单目视频输入。&lt;h4&gt;目的&lt;/h4&gt;目的是通过视频修复技术生成和编辑4D视频内容。&lt;h4&gt;方法&lt;/h4&gt;使用视频修复基础模型作为生成先验，将4D视频创作重新定义为视频修复任务。通过生成复合遮蔽的修复视频数据来微调模型，同时使用深度点云渲染和编辑遮蔽来创建复合遮蔽数据集。设计了一种自我迭代调整策略来处理大范围相机运动下的时间一致性，并在推理过程中引入了时间包装模块来提高生成质量。&lt;h4&gt;主要发现&lt;/h4&gt;该方法有效地利用了基础模型的先验知识，同时保持了其原始性能，能够生成具有一致多视图连贯性的4D视频。此外，该方法支持基于提示的内容编辑，表现出强大的灵活性和优越性，在质量和多功能性方面均优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;该方法在4D视频生成和编辑方面具有显著优势，为单目视频到4D视频的转换提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;We introduce Follow-Your-Creation, a novel 4D video creation framework capable of both generating and editing 4D content from a single monocular video input. By leveraging a powerful video inpainting foundation model as a generative prior, we reformulate 4D video creation as a video inpainting task, enabling the model to fill in missing content caused by camera trajectory changes or user edits. To facilitate this, we generate composite masked inpainting video data to effectively fine-tune the model for 4D video generation. Given an input video and its associated camera trajectory, we first perform depth-based point cloud rendering to obtain invisibility masks that indicate the regions that should be completed. Simultaneously, editing masks are introduced to specify user-defined modifications, and these are combined with the invisibility masks to create a composite masks dataset. During training, we randomly sample different types of masks to construct diverse and challenging inpainting scenarios, enhancing the model's generalization and robustness in various 4D editing and generation tasks. To handle temporal consistency under large camera motion, we design a self-iterative tuning strategy that gradually increases the viewing angles during training, where the model is used to generate the next-stage training data after each fine-tuning iteration. Moreover, we introduce a temporal packaging module during inference to enhance generation quality. Our method effectively leverages the prior knowledge of the base model without degrading its original performance, enabling the generation of 4D videos with consistent multi-view coherence. In addition, our approach supports prompt-based content editing, demonstrating strong flexibility and significantly outperforming state-of-the-art methods in both quality and versatility.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Follow-Your-Creation, a novel 4D video creation frameworkcapable of both generating and editing 4D content from a single monocular videoinput. By leveraging a powerful video inpainting foundation model as agenerative prior, we reformulate 4D video creation as a video inpainting task,enabling the model to fill in missing content caused by camera trajectorychanges or user edits. To facilitate this, we generate composite maskedinpainting video data to effectively fine-tune the model for 4D videogeneration. Given an input video and its associated camera trajectory, we firstperform depth-based point cloud rendering to obtain invisibility masks thatindicate the regions that should be completed. Simultaneously, editing masksare introduced to specify user-defined modifications, and these are combinedwith the invisibility masks to create a composite masks dataset. Duringtraining, we randomly sample different types of masks to construct diverse andchallenging inpainting scenarios, enhancing the model's generalization androbustness in various 4D editing and generation tasks. To handle temporalconsistency under large camera motion, we design a self-iterative tuningstrategy that gradually increases the viewing angles during training, where themodel is used to generate the next-stage training data after each fine-tuningiteration. Moreover, we introduce a temporal packaging module during inferenceto enhance generation quality. Our method effectively leverages the priorknowledge of the base model without degrading its original performance,enabling the generation of 4D videos with consistent multi-view coherence. Inaddition, our approach supports prompt-based content editing, demonstratingstrong flexibility and significantly outperforming state-of-the-art methods inboth quality and versatility.</description>
      <author>example@mail.com (Yue Ma, Kunyu Feng, Xinhua Zhang, Hongyu Liu, David Junhao Zhang, Jinbo Xing, Yinhan Zhang, Ayden Yang, Zeyu Wang, Qifeng Chen)</author>
      <guid isPermaLink="false">2506.04590v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>"Don't Do That!": Guiding Embodied Systems through Large Language Model-based Constraint Generation</title>
      <link>http://arxiv.org/abs/2506.04500v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint; under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为STPR的约束生成框架，利用大型语言模型（LLMs）将自然语言中的约束条件转化为可执行的Python函数，以解决机器人导航中复杂空间、数学和条件约束的规划问题。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型（LLMs）的进步激发了将自然语言中的复杂约束条件融入机器人导航规划问题的兴趣。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，能够将自然语言描述的约束条件转化为机器可执行的代码，从而简化规划算法的输入。&lt;h4&gt;方法&lt;/h4&gt;STPR框架使用LLMs将“做什么”或“不做什么”的指令转化为Python函数，利用LLMs的编码能力将问题描述从语言转换为结构化和透明的代码。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，LLM生成的函数能够准确描述复杂的数学约束，并且这些函数适用于点云表示，与传统搜索算法结合使用。在Gazebo模拟环境中，STPR确保了在多个约束和场景下的完全合规性，并且运行时间短。&lt;h4&gt;结论&lt;/h4&gt;STPR框架不仅适用于大型LLMs，还可以与小型、特定于代码的LLMs结合使用，以低推理成本适用于广泛的紧凑型模型。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为STPR的约束生成框架，利用大型语言模型（LLMs）将自然语言中的约束条件转化为可执行的Python函数，以解决机器人导航中复杂空间、数学和条件约束的规划问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in large language models (LLMs) have spurred interest inrobotic navigation that incorporates complex spatial, mathematical, andconditional constraints from natural language into the planning problem. Suchconstraints can be informal yet highly complex, making it challenging totranslate into a formal description that can be passed on to a planningalgorithm. In this paper, we propose STPR, a constraint generation frameworkthat uses LLMs to translate constraints (expressed as instructions on ``whatnot to do'') into executable Python functions. STPR leverages the LLM's strongcoding capabilities to shift the problem description from language intostructured and transparent code, thus circumventing complex reasoning andavoiding potential hallucinations. We show that these LLM-generated functionsaccurately describe even complex mathematical constraints, and apply them topoint cloud representations with traditional search algorithms. Experiments ina simulated Gazebo environment show that STPR ensures full compliance acrossseveral constraints and scenarios, while having short runtimes. We also verifythat STPR can be used with smaller, code-specific LLMs, making it applicable toa wide range of compact models at low inference cost.</description>
      <author>example@mail.com (Aladin Djuhera, Amin Seffo, Masataro Asai, Holger Boche)</author>
      <guid isPermaLink="false">2506.04500v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>AuthGuard: Generalizable Deepfake Detection via Language Guidance</title>
      <link>http://arxiv.org/abs/2506.04501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AuthGuard的深度伪造检测框架，通过结合语言指导和视觉编码器，提高了深度伪造检测的泛化能力，并在多个数据集上取得了最先进的检测精度。&lt;h4&gt;背景&lt;/h4&gt;现有的深度伪造检测技术难以跟上不断发展的新型伪造方法，因为它们依赖于在训练期间学习到的统计伪象，这些伪象往往与特定的生成过程相关，可能不代表测试时遇到的新、未见过的深度伪造生成方法。&lt;h4&gt;目的&lt;/h4&gt;通过整合语言指导和人类似常识推理，提高深度伪造检测的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;1. 使用通用多语言语言模型（MLLM）和少量样本提示生成文本；2. 结合判别分类和图像-文本对比学习训练深度伪造视觉编码器；3. 将数据不确定性学习集成到视觉-语言对比学习中，减轻图像-文本监督中的噪声；4. 专家视觉编码器与语言模型（LLM）无缝接口。&lt;h4&gt;主要发现&lt;/h4&gt;AuthGuard在分布内和分布外设置中均实现了最先进的深度伪造检测精度，在DFDC数据集上AUC提高了6.15%，在DF40数据集上提高了16.68%。此外，AuthGuard显著增强了深度伪造推理能力，在DDVQA数据集上性能提高了24.69%。&lt;h4&gt;结论&lt;/h4&gt;AuthGuard框架通过结合语言指导和视觉编码器，实现了更泛化和可解释的深度伪造检测，同时提高了检测精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing deepfake detection techniques struggle to keep-up with theever-evolving novel, unseen forgeries methods. This limitation stems from theirreliance on statistical artifacts learned during training, which are often tiedto specific generation processes that may not be representative of samples fromnew, unseen deepfake generation methods encountered at test time. We proposethat incorporating language guidance can improve deepfake detectiongeneralization by integrating human-like commonsense reasoning -- such asrecognizing logical inconsistencies and perceptual anomalies -- alongsidestatistical cues. To achieve this, we train an expert deepfake vision encoderby combining discriminative classification with image-text contrastivelearning, where the text is generated by generalist MLLMs using few-shotprompting. This allows the encoder to extract both language-describable,commonsense deepfake artifacts and statistical forgery artifacts frompixel-level distributions. To further enhance robustness, we integrate datauncertainty learning into vision-language contrastive learning, mitigatingnoise in image-text supervision. Our expert vision encoder seamlesslyinterfaces with an LLM, further enabling more generalized and interpretabledeepfake detection while also boosting accuracy. The resulting framework,AuthGuard, achieves state-of-the-art deepfake detection accuracy in bothin-distribution and out-of-distribution settings, achieving AUC gains of 6.15%on the DFDC dataset and 16.68% on the DF40 dataset. Additionally, AuthGuardsignificantly enhances deepfake reasoning, improving performance by 24.69% onthe DDVQA dataset.</description>
      <author>example@mail.com (Guangyu Shen, Zhihua Li, Xiang Xu, Tianchen Zhao, Zheng Zhang, Dongsheng An, Zhuowen Tu, Yifan Xing, Qin Zhang)</author>
      <guid isPermaLink="false">2506.04501v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models</title>
      <link>http://arxiv.org/abs/2506.04586v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LESS的框架，该框架利用大型语言模型（LLMs）来校正从野外数据生成的伪标签，并在多种语言和任务上取得了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;LESS框架旨在通过结合LLMs和半监督学习技术，提高自动语音识别（ASR）和自动语音翻译（AST）等任务的性能。&lt;h4&gt;目的&lt;/h4&gt;LESS框架的目的是通过优化LLM知识迁移效率，提升从无监督数据生成的伪标签的质量。&lt;h4&gt;方法&lt;/h4&gt;LESS框架通过LLM对ASR或AST的伪标签进行细化，并采用数据过滤策略来增强LLM的知识迁移效率。&lt;h4&gt;主要发现&lt;/h4&gt;在普通话ASR和西班牙语到英语AST任务上，LESS实现了3.77%的绝对错误率（WER）降低，以及Callhome和Fisher测试集上的BLEU分数分别为34.0和64.7。&lt;h4&gt;结论&lt;/h4&gt;LESS框架在不同语言、任务和领域中的适应性得到了验证，并且通过消融实验揭示了利用LLM知识进行语音处理应用的新见解。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为LESS（大型语言模型增强半监督学习）的通用框架，该框架利用大型语言模型（LLMs）来校正从野外数据生成的伪标签。在LESS框架中，来自无监督数据的自动语音识别（ASR）或自动语音翻译（AST）的伪标签通过LLM进行细化，并通过数据过滤策略进行增强，以优化LLM知识迁移效率。在普通话ASR和西班牙语到英语AST任务上的实验表明，LESS在Wenet语音测试集上实现了3.77%的显著绝对错误率（WER）降低，在Callhome和Fisher测试集上分别实现了34.0和64.7的BLEU分数。这些结果验证了LESS在不同语言、任务和领域中的适应性。通过各种LLMs和提示配置进行的消融研究为利用LLM派生的知识进行语音处理应用提供了新的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce LESS (Large Language Model Enhanced Semi-supervised Learning), aversatile framework that leverages Large Language Models (LLMs) to correctpseudo labels generated from in-the-wild data. Within the LESS framework,pseudo-labeled text from Automatic Speech Recognition (ASR) or Automatic SpeechTranslation (AST) of the unsupervised data is refined by an LLM, and augmentedby a data filtering strategy to optimize LLM knowledge transfer efficiency.Experiments on both Mandarin ASR and Spanish-to-English AST tasks show thatLESS achieves a notable absolute WER reduction of 3.77% on the Wenet Speechtest set, as well as BLEU scores of 34.0 and 64.7 on Callhome and Fisher testsets respectively. These results validate the adaptability of LESS acrossdifferent languages, tasks, and domains. Ablation studies conducted withvarious LLMs and prompt configurations provide novel insights into leveragingLLM-derived knowledge for speech processing applications.</description>
      <author>example@mail.com (Wen Ding, Fan Qian)</author>
      <guid isPermaLink="false">2506.04586v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Learning Smooth State-Dependent Traversability from Dense Point Clouds</title>
      <link>http://arxiv.org/abs/2506.04362v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SPARTA的方法，用于从点云数据中估计接近角度条件下的可通行性。&lt;h4&gt;背景&lt;/h4&gt;在越野自主导航中，地形可通行性往往依赖于车辆的状态，某些障碍物只能从特定方向通过。&lt;h4&gt;目的&lt;/h4&gt;为了解决学习这种交互关系的问题，即通过编码接近角度作为模型输入，本文旨在提出一种高效的方法。&lt;h4&gt;方法&lt;/h4&gt;SPARTA通过在网络中引入几何结构，输出一个在1-Sphere上的平滑分析函数，以预测任何接近角度的风险分布。&lt;h4&gt;主要发现&lt;/h4&gt;该函数由傅里叶基函数组成，由于其周期性和平滑性，具有很好的泛化能力。在仿真平台和实际硬件上，SPARTA均表现出良好的性能。&lt;h4&gt;结论&lt;/h4&gt;SPARTA在提高越野自主导航的可通行性预测方面具有显著优势，能够有效应对实际场景中的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A key open challenge in off-road autonomy is that the traversability ofterrain often depends on the vehicle's state. In particular, some obstacles areonly traversable from some orientations. However, learning this interaction byencoding the angle of approach as a model input demands a large and diversetraining dataset and is computationally inefficient during planning due torepeated model inference. To address these challenges, we present SPARTA, amethod for estimating approach angle conditioned traversability from pointclouds. Specifically, we impose geometric structure into our network byoutputting a smooth analytical function over the 1-Sphere that predicts riskdistribution for any angle of approach with minimal overhead and can be reusedfor subsequent queries. The function is composed of Fourier basis functions,which has important advantages for generalization due to their periodic natureand smoothness. We demonstrate SPARTA both in a high-fidelity simulationplatform, where our model achieves a 91\% success rate crossing a 40m boulderfield (compared to 73\% for the baseline), and on hardware, illustrating thegeneralization ability of the model to real-world settings.</description>
      <author>example@mail.com (Zihao Dong, Alan Papalia, Leonard Jung, Alenna Spiro, Philip R. Osteen, Christa S. Robison, Michael Everett)</author>
      <guid isPermaLink="false">2506.04362v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>DAS-MAE: A self-supervised pre-training framework for universal and high-performance representation learning of distributed fiber-optic acoustic sensing</title>
      <link>http://arxiv.org/abs/2506.04552v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了分布式光纤声学传感（DAS）技术，提出了一种名为DAS Masked AutoEncoder（DAS-MAE）的自监督预训练框架，用于分析大规模未标记的DAS信号。&lt;h4&gt;背景&lt;/h4&gt;DAS技术在分布式振动测量方面具有高空间分辨率和长测量范围的优势，但在分析二维时空DAS信号时存在分析挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种自监督预训练框架，用于学习DAS信号的表示，以解决DAS信号分析中的挑战。&lt;h4&gt;方法&lt;/h4&gt;设计了DAS-MAE框架，通过掩码重建任务学习信号的表示，并在少样本分类任务中进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;DAS-MAE在少样本分类任务中达到了1%的错误率和64.5%的相对改进，在外部损伤预防的实际应用中达到了5.0%的识别错误率，比从头开始的有监督训练提高了75.7%的相对改进。&lt;h4&gt;结论&lt;/h4&gt;DAS-MAE框架展示了高性能和通用性，有潜力成为分析大规模未标记DAS信号的基础模型。&lt;h4&gt;翻译&lt;/h4&gt;Distributed fiber-optic acoustic sensing (DAS) has emerged as a transformative approach for distributed vibration measurement with high spatial resolution and long measurement range while maintaining cost-efficiency. However, the two-dimensional spatial-temporal DAS signals present analytical challenges. The abstract signal morphology lacking intuitive physical correspondence complicates human interpretation, and its unique spatial-temporal coupling renders conventional image processing methods suboptimal. This study investigates spatial-temporal characteristics and proposes a self-supervised pre-training framework that learns signals' representations through a mask-reconstruction task. This framework is named the DAS Masked AutoEncoder (DAS-MAE). The DAS-MAE learns high-level representations (e.g., event class) without using labels. It achieves up to 1% error and 64.5% relative improvement (RI) over the semi-supervised baseline in few-shot classification tasks. In a practical external damage prevention application, DAS-MAE attains a 5.0% recognition error, marking a 75.7% RI over supervised training from scratch. These results demonstrate the high-performance and universal representations learned by the DAS-MAE framework, highlighting its potential as a foundation model for analyzing massive unlabeled DAS signals.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Distributed fiber-optic acoustic sensing (DAS) has emerged as atransformative approach for distributed vibration measurement with high spatialresolution and long measurement range while maintaining cost-efficiency.However, the two-dimensional spatial-temporal DAS signals present analyticalchallenges. The abstract signal morphology lacking intuitive physicalcorrespondence complicates human interpretation, and its uniquespatial-temporal coupling renders conventional image processing methodssuboptimal. This study investigates spatial-temporal characteristics andproposes a self-supervised pre-training framework that learns signals'representations through a mask-reconstruction task. This framework is named theDAS Masked AutoEncoder (DAS-MAE). The DAS-MAE learns high-level representations(e.g., event class) without using labels. It achieves up to 1% error and 64.5%relative improvement (RI) over the semi-supervised baseline in few-shotclassification tasks. In a practical external damage prevention application,DAS-MAE attains a 5.0% recognition error, marking a 75.7% RI over supervisedtraining from scratch. These results demonstrate the high-performance anduniversal representations learned by the DAS-MAE framework, highlighting itspotential as a foundation model for analyzing massive unlabeled DAS signals.</description>
      <author>example@mail.com (Junyi Duan, Jiageng Chen, Zuyuan He)</author>
      <guid isPermaLink="false">2506.04552v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>HuGeDiff: 3D Human Generation via Diffusion with Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.04351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种弱监督流程来解决3D人类生成中的挑战，包括生成精确的3D人类、细节控制、真实感、多样性、现实主义和标注问题。&lt;h4&gt;背景&lt;/h4&gt;3D人类生成在计算机视觉和图形学领域有广泛的应用，尽管有扩散模型、Neural Radiance Fields或Gaussian Splatting等生成AI的进展，但基于文本提示的精确3D人类生成控制仍然是一个开放挑战。&lt;h4&gt;目的&lt;/h4&gt;解决生成精确3D人类时面临的困难，如细节、手和面部渲染、真实感以及外观的可控性。&lt;h4&gt;方法&lt;/h4&gt;1. 使用最先进的图像扩散模型生成具有可控属性（如外观、种族、性别等）的逼真人类图像数据集。2. 提出一种基于transformer架构的高效图像特征到3D点云的映射方法。3. 训练一个基于相同文本提示的点云扩散模型，以生成原始样本。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，本文提出的方法在3D人类生成方面实现了数量级的速度提升，并显著提高了文本提示对齐、真实感和渲染质量。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地解决3D人类生成中的挑战，有望促进该领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D人类生成是一个在计算机视觉和图形学领域具有广泛应用的重要问题。尽管在生成AI，如扩散模型或Neural Radiance Fields或Gaussian Splatting等渲染方法方面取得了进展，但从文本提示控制精确的3D人类生成仍然是一个未解决的问题。当前的方法在细节、手和面部的精确渲染、人类真实感和外观的可控性方面存在困难。人类图像数据中缺乏多样性、现实主义和标注也是一个挑战，阻碍了基础3D人类模型的发展。我们提出了一种弱监督流程来尝试解决这些挑战。在第一步，我们使用最先进的图像扩散模型生成具有可控属性（如外观、种族、性别等）的逼真人类图像数据集。接下来，我们提出了一种基于transformer架构的高效的从图像特征到3D点云的映射方法。最后，我们通过训练一个基于生成原始样本的相同文本提示的点云扩散模型来闭合循环。我们展示了与现有方法相比，3D人类生成方面的数量级速度提升，以及显著提高的文本提示对齐、真实感和渲染质量。我们将提供代码和数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D human generation is an important problem with a wide range of applicationsin computer vision and graphics. Despite recent progress in generative AI suchas diffusion models or rendering methods like Neural Radiance Fields orGaussian Splatting, controlling the generation of accurate 3D humans from textprompts remains an open challenge. Current methods struggle with fine detail,accurate rendering of hands and faces, human realism, and controlability overappearance. The lack of diversity, realism, and annotation in human image dataalso remains a challenge, hindering the development of a foundational 3D humanmodel. We present a weakly supervised pipeline that tries to address thesechallenges. In the first step, we generate a photorealistic human image datasetwith controllable attributes such as appearance, race, gender, etc using astate-of-the-art image diffusion model. Next, we propose an efficient mappingapproach from image features to 3D point clouds using a transformer-basedarchitecture. Finally, we close the loop by training a point-cloud diffusionmodel that is conditioned on the same text prompts used to generate theoriginal samples. We demonstrate orders-of-magnitude speed-ups in 3D humangeneration compared to the state-of-the-art approaches, along withsignificantly improved text-prompt alignment, realism, and rendering quality.We will make the code and dataset available.</description>
      <author>example@mail.com (Maksym Ivashechkin, Oscar Mendez, Richard Bowden)</author>
      <guid isPermaLink="false">2506.04351v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>The Latent Space Hypothesis: Toward Universal Medical Representation Learning</title>
      <link>http://arxiv.org/abs/2506.04515v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  51 pages, 12 figures. A position paper examining the latent space  hypothesis - the proposition that diverse medical data can be represented in  shared latent spaces reflecting fundamental biological processes. The paper  discusses theoretical foundations, reviews supporting evidence, and considers  potential implications for medical AI and representation learning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于潜在空间假设的方法，通过将不同模态的医学数据统一到一个共享空间中，实现对疾病的个性化诊断、纵向监测和定制化治疗。&lt;h4&gt;背景&lt;/h4&gt;医学数据包括基因组序列、视网膜照片、结构化实验室结果和非结构化临床叙事等，这些数据虽然形式多样，但往往编码着关于同一生理状态的相似信息。&lt;h4&gt;目的&lt;/h4&gt;通过学习几何表示，将个体的健康状况、疾病进展和治疗干预在统一空间中表示出来，以实现对疾病的深入理解和个性化治疗。&lt;h4&gt;方法&lt;/h4&gt;采用潜在空间假设，将每个观察结果视为一个统一、层次化组织的流形上的投影，并通过学习到的几何表示来分析个体健康状态和疾病进展。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够揭示亚轨迹和患者特异性的变化方向，为个性化诊断、纵向监测和定制化治疗提供了定量依据。&lt;h4&gt;结论&lt;/h4&gt;尽管存在偏差放大、罕见疾病数据稀缺、隐私问题和因果关系区分等挑战，但通过使用规模感知编码器、在纵向数据流上进行持续学习和基于扰动的验证，这些挑战有望得到解决。&lt;h4&gt;翻译&lt;/h4&gt;摘要：医学数据范围从基因组序列和视网膜照片到结构化实验室结果和非结构化临床叙事。尽管这些模态看起来不同，但它们都编码了关于单一基础生理状态的相似信息。潜在空间假设将每个观察结果视为一个统一、层次化组织的流形的投影——就像同一三维物体投射的阴影。在这个学习到的几何表示中，个体的健康状况占据一个点，疾病进展描绘出一条轨迹，治疗干预对应一个有向向量。在共享空间中解释异质证据提供了一种审视常见疾病（如帕金森病或克罗恩病）的原理方法，这些疾病往往掩盖了多个病理生理实体，并涉及比以前认为更广泛的解剖区域。通过揭示亚轨迹和患者特定的变化方向，该框架为个性化诊断、纵向监测和定制化治疗提供了定量依据，将临床实践从按可能具有误导性的标签分组转向导航每个人的独特轨迹。挑战仍然存在——偏差放大、罕见疾病数据稀缺、隐私和因果关系区分——但规模感知编码器、在纵向数据流上进行持续学习和基于扰动的验证提供了可能的路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical data range from genomic sequences and retinal photographs tostructured laboratory results and unstructured clinical narratives. Althoughthese modalities appear disparate, many encode convergent information about asingle underlying physiological state. The Latent Space Hypothesis frames eachobservation as a projection of a unified, hierarchically organized manifold --much like shadows cast by the same three-dimensional object. Within thislearned geometric representation, an individual's health status occupies apoint, disease progression traces a trajectory, and therapeutic interventioncorresponds to a directed vector. Interpreting heterogeneous evidence in ashared space provides a principled way to re-examine eponymous conditions --such as Parkinson's or Crohn's -- that often mask multiple pathophysiologicalentities and involve broader anatomical domains than once believed. Byrevealing sub-trajectories and patient-specific directions of change, theframework supplies a quantitative rationale for personalised diagnosis,longitudinal monitoring, and tailored treatment, moving clinical practice awayfrom grouping by potentially misleading labels toward navigation of eachperson's unique trajectory. Challenges remain -- bias amplification, datascarcity for rare disorders, privacy, and the correlation-causation divide --but scale-aware encoders, continual learning on longitudinal data streams, andperturbation-based validation offer plausible paths forward.</description>
      <author>example@mail.com (Salil Patel)</author>
      <guid isPermaLink="false">2506.04515v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>SF$^2$Bench: Evaluating Data-Driven Models for Compound Flood Forecasting in South Florida</title>
      <link>http://arxiv.org/abs/2506.04281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  60 Pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了复合洪水的预测，介绍了SF2Bench这一综合时间序列集合，评估了六种模型方法在洪水预测中的性能，并探讨了不同特征对洪水预测的影响。&lt;h4&gt;背景&lt;/h4&gt;复合洪水的预测因气象、水文和海洋因素的复杂相互作用而具有挑战性，全球气候变化增加了洪水风险。&lt;h4&gt;目的&lt;/h4&gt;为了解决数据集的稀缺问题，本文引入了SF2Bench，以更详细地分析各因素对复合洪水的影响，并评估不同模型方法在洪水预测中的性能。&lt;h4&gt;方法&lt;/h4&gt;SF2Bench集成了潮汐、降雨、地下水和人类管理活动（闸门和泵控制）四个关键因素，并评估了六种模型方法：多层感知器、卷积神经网络、循环神经网络、图神经网络、转换器和大型语言模型。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验验证了不同关键特征对洪水预测的影响，分析了时间和空间方面的因素，并提供了关于历史数据和空间依赖性的见解。&lt;h4&gt;结论&lt;/h4&gt;不同方法在捕捉复合洪水中的复杂时间和空间依赖性方面具有不同的能力，SF2Bench和评估的模型方法有助于提高洪水预测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Forecasting compound floods presents a significant challenge due to theintricate interplay of meteorological, hydrological, and oceanographic factors.Analyzing compound floods has become more critical as the global climateincreases flood risks. Traditional physics-based methods, such as theHydrologic Engineering Center's River Analysis System, are oftentime-inefficient. Machine learning has recently demonstrated promise in bothmodeling accuracy and computational efficiency. However, the scarcity ofcomprehensive datasets currently hinders systematic analysis. Existingwater-related datasets are often limited by a sparse network of monitoringstations and incomplete coverage of relevant factors. To address thischallenge, we introduce SF2Bench, a comprehensive time series collection oncompound floods in South Florida, which integrates four key factors: tide,rainfall, groundwater, and human management activities (gate and pumpcontrolling). This integration allows for a more detailed analysis of theindividual contributions of these drivers to compound flooding and informs thedevelopment of improved flood forecasting approaches. To comprehensivelyevaluate the potential of various modeling paradigms, we assess the performanceof six categories of methods, encompassing Multilayer Perceptrons,Convolutional Neural Networks, Recurrent Neural Networks, Graph NeuralNetworks, Transformers, and Large Language Models. We verified the impact ofdifferent key features on flood forecasting through experiments. Our analysisexamines temporal and spatial aspects, providing insights into the influence ofhistorical data and spatial dependencies. The varying performance across theseapproaches underscores the diverse capabilities of each in capturing complextemporal and spatial dependencies inherent in compound floods.</description>
      <author>example@mail.com (Xu Zheng, Chaohao Lin, Sipeng Chen, Zhuomin Chen, Jimeng Shi, Wei Cheng, Jayantha Obeysekera, Jason Liu, Dongsheng Luo)</author>
      <guid isPermaLink="false">2506.04281v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Text Classification Using Contrastive Learning Informed Path Guided Hierarchy</title>
      <link>http://arxiv.org/abs/2506.04381v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2203.03825 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HTC-CLIP的分层文本分类方法，通过对比学习来学习层次感知的文本表示和文本引导的层次表示，实现了两种现有方法的结合，提高了分类性能。&lt;h4&gt;背景&lt;/h4&gt;分层文本分类（HTC）在处理复杂标签层次方面表现良好，被广泛应用于电子商务、客户服务和医疗等行业。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的HTC模型，结合两种现有方法的优势，以实现更好的分类性能。&lt;h4&gt;方法&lt;/h4&gt;HTC-CLIP模型利用对比学习学习层次感知的文本表示和文本引导的层次表示，并在训练过程中学习两个不同的类别概率分布。在推理阶段，结合两种表示来提高分类效果。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，HTC-CLIP模型能够有效结合两种方法，在两个公开数据集上相较于现有最佳模型，宏F1分数提升了0.99-2.37%。&lt;h4&gt;结论&lt;/h4&gt;HTC-CLIP是一种有效的分层文本分类方法，能够显著提高分类性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3233/FAIA230249&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hierarchical Text Classification (HTC) has recently gained traction given theability to handle complex label hierarchy. This has found applications indomains like E- commerce, customer care and medicine industry among otherreal-world applications. Existing HTC models either encode label hierarchyseparately and mix it with text encoding or guide the label hierarchy structurein the text encoder. Both approaches capture different characteristics of labelhierarchy and are complementary to each other. In this paper, we propose aHierarchical Text Classification using Contrastive Learning Informed Pathguided hierarchy (HTC-CLIP), which learns hierarchy-aware text representationand text informed path guided hierarchy representation using contrastivelearning. During the training of HTC-CLIP, we learn two different sets of classprobabilities distributions and during inference, we use the pooled output ofboth probabilities for each class to get the best of both representations. Ourresults show that the two previous approaches can be effectively combined intoone architecture to achieve improved performance. Tests on two public benchmarkdatasets showed an improvement of 0.99 - 2.37% in Macro F1 score using HTC-CLIPover the existing state-of-the-art models.</description>
      <author>example@mail.com (Neeraj Agrawal, Saurabh Kumar, Priyanka Bhatt, Tanishka Agarwal)</author>
      <guid isPermaLink="false">2506.04381v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Geometric Visual Fusion Graph Neural Networks for Multi-Person Human-Object Interaction Recognition in Videos</title>
      <link>http://arxiv.org/abs/2506.03440v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Expert Systems with Applications (ESWA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GeoVis-GNN的图形神经网络，用于视频中的HOI识别，通过结合视觉和几何特征，实现多模态融合，并通过建立实体特定表示来提高识别效果。&lt;h4&gt;背景&lt;/h4&gt;视频中的HOI识别需要理解视觉模式和几何关系随时间的变化，视觉特征捕捉外观上下文，几何特征提供结构模式，多模态特征融合是挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的方法来融合视觉和几何特征，并通过建立实体特定表示来提高HOI识别的准确性。&lt;h4&gt;方法&lt;/h4&gt;GeoVis-GNN采用双注意力特征融合和依赖实体图学习，从实体特定表示逐步构建到高级交互理解。&lt;h4&gt;主要发现&lt;/h4&gt;GeoVis-GNN在多种HOI场景中表现出色，包括两人交互、单人活动、双手动操作和复杂的并发部分交互。&lt;h4&gt;结论&lt;/h4&gt;GeoVis-GNN在HOI识别方面达到了最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;Human-Object Interaction (HOI) recognition in videos requires understanding both visual patterns and geometric relationships as they evolve over time. Visual and geometric features offer complementary strengths. Visual features capture appearance context, while geometric features provide structural patterns. Effectively fusing these multimodal features without compromising their unique characteristics remains challenging. We observe that establishing robust, entity-specific representations before modeling interactions helps preserve the strengths of each modality. Therefore, we hypothesize that a bottom-up approach is crucial for effective multimodal fusion. Following this insight, we propose the Geometric Visual Fusion Graph Neural Network (GeoVis-GNN), which uses dual-attention feature fusion combined with interdependent entity graph learning. It progressively builds from entity-specific representations toward high-level interaction understanding. To advance HOI recognition to real-world scenarios, we introduce the Concurrent Partial Interaction Dataset (MPHOI-120). It captures dynamic multi-person interactions involving concurrent actions and partial engagement. This dataset helps address challenges like complex human-object dynamics and mutual occlusions. Extensive experiments demonstrate the effectiveness of our method across various HOI scenarios. These scenarios include two-person interactions, single-person activities, bimanual manipulations, and complex concurrent partial interactions. Our method achieves state-of-the-art performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human-Object Interaction (HOI) recognition in videos requires understandingboth visual patterns and geometric relationships as they evolve over time.Visual and geometric features offer complementary strengths. Visual featurescapture appearance context, while geometric features provide structuralpatterns. Effectively fusing these multimodal features without compromisingtheir unique characteristics remains challenging. We observe that establishingrobust, entity-specific representations before modeling interactions helpspreserve the strengths of each modality. Therefore, we hypothesize that abottom-up approach is crucial for effective multimodal fusion. Following thisinsight, we propose the Geometric Visual Fusion Graph Neural Network(GeoVis-GNN), which uses dual-attention feature fusion combined withinterdependent entity graph learning. It progressively builds fromentity-specific representations toward high-level interaction understanding. Toadvance HOI recognition to real-world scenarios, we introduce the ConcurrentPartial Interaction Dataset (MPHOI-120). It captures dynamic multi-personinteractions involving concurrent actions and partial engagement. This datasethelps address challenges like complex human-object dynamics and mutualocclusions. Extensive experiments demonstrate the effectiveness of our methodacross various HOI scenarios. These scenarios include two-person interactions,single-person activities, bimanual manipulations, and complex concurrentpartial interactions. Our method achieves state-of-the-art performance.</description>
      <author>example@mail.com (Tanqiu Qiao, Ruochen Li, Frederick W. B. Li, Yoshiki Kubotani, Shigeo Morishima, Hubert P. H. Shum)</author>
      <guid isPermaLink="false">2506.03440v2</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>ExDiff: A Framework for Simulating Diffusion Processes on Complex Networks with Explainable AI Integration</title>
      <link>http://arxiv.org/abs/2506.04271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ExDiff是一个集成网络模拟、图神经网络（GNN）和可解释人工智能（XAI）的交互式和模块化计算框架，用于模拟和解释扩散动态。&lt;h4&gt;背景&lt;/h4&gt;理解和控制复杂网络中的扩散过程对流行病学到信息科学等多个领域至关重要。&lt;h4&gt;目的&lt;/h4&gt;ExDiff旨在提供一种强大的、灵活的、易于使用的平台，以研究网络系统中扩散现象，促进方法创新和实践洞察。&lt;h4&gt;方法&lt;/h4&gt;ExDiff结合了经典分室模型与深度学习技术，以捕捉不同网络拓扑中的扩散结构和时间特征。框架包含网络分析、神经网络建模、模拟和可解释性等专用模块，通过Google Colab的直观界面访问。&lt;h4&gt;主要发现&lt;/h4&gt;通过SIRVD模型的案例研究，ExDiff能够模拟疾病传播、评估干预策略、分类节点状态，并通过XAI技术揭示传播的结构决定因素。&lt;h4&gt;结论&lt;/h4&gt;通过统一模拟和可解释性，ExDiff为研究网络系统中扩散现象提供了一个有力的工具，有助于促进方法论创新和提供实际见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding and controlling diffusion processes in complex networks iscritical across domains ranging from epidemiology to information science. Here,we present ExDiff, an interactive and modular computational framework thatintegrates network simulation, graph neural networks (GNNs), and explainableartificial intelligence (XAI) to model and interpret diffusion dynamics. ExDiffcombines classical compartmental models with deep learning techniques tocapture both the structural and temporal characteristics of diffusion acrossdiverse network topologies. The framework features dedicated modules fornetwork analysis, neural modeling, simulation, and interpretability, allaccessible via an intuitive interface built on Google Colab. Through a casestudy of the Susceptible Infectious Recovered Vaccinated Dead (SIRVD) model, wedemonstrate the capacity to simulate disease spread, evaluate interventionstrategies, classify node states, and reveal the structural determinants ofcontagion through XAI techniques. By unifying simulation and interpretability,ExDiff provides a powerful, flexible, and accessible platform for studyingdiffusion phenomena in networked systems, enabling both methodologicalinnovation and practical insight.</description>
      <author>example@mail.com (Annamaria Defilippo, Ugo Lomoio, Barbara Puccio, Pierangelo Veltri, Pietro Hiram Guzzi)</author>
      <guid isPermaLink="false">2506.04271v1</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Understanding and Mitigating Network Latency Effect on Teleoperated-Robot with Extended Reality</title>
      <link>http://arxiv.org/abs/2506.01135v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This documents is a 5 pages technical report version. Removed  watermark from acm for copyright purpose&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TeleXR，一个创新的XR远程操作框架，旨在解决现有系统中的运动到运动延迟问题。&lt;h4&gt;背景&lt;/h4&gt;现有的远程机器人操作系统由于过度依赖网络通信，存在运动到运动延迟，导致操作误差大和任务完成时间长。&lt;h4&gt;目的&lt;/h4&gt;TeleXR旨在通过降低网络依赖来减少运动到运动延迟，提高远程操作的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;TeleXR通过利用本地传感数据重构延迟或缺失的信息，并采用竞争感知调度和带宽自适应点云缩放技术来实现。&lt;h4&gt;主要发现&lt;/h4&gt;TeleXR显著减少了网络引起的延迟，同时保持了高机器人规划准确性和XR与机器人操作的同时运行。&lt;h4&gt;结论&lt;/h4&gt;TeleXR是一种有效解决远程机器人操作中运动到运动延迟问题的开源框架。&lt;h4&gt;翻译&lt;/h4&gt;Robot teleoperation with extended reality (XR teleoperation) enables intuitive interaction by allowing remote robots to mimic user motions with real-time 3D feedback. However, existing systems face significant motion-to-motion (M2M) latency--the delay between the user's latest motion and the corresponding robot feedback--leading to high teleoperation error and mission completion time. This issue stems from the system's exclusive reliance on network communication, making it highly vulnerable to network degradation. To address these challenges, we introduce TeleXR, the first end-to-end, fully open-sourced XR teleoperation framework that decouples robot control and XR visualization from network dependencies. TeleXR leverages local sensing data to reconstruct delayed or missing information of the counterpart, thereby significantly reducing network-induced issues. This approach allows both the XR and robot to run concurrently with network transmission while maintaining high robot planning accuracy. TeleXR also features contention-aware scheduling to mitigate GPU contention and bandwidth-adaptive point cloud scaling to cope with limited bandwidth.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robot teleoperation with extended reality (XR teleoperation) enablesintuitive interaction by allowing remote robots to mimic user motions withreal-time 3D feedback. However, existing systems face significantmotion-to-motion (M2M) latency--the delay between the user's latest motion andthe corresponding robot feedback--leading to high teleoperation error andmission completion time. This issue stems from the system's exclusive relianceon network communication, making it highly vulnerable to network degradation.  To address these challenges, we introduce TeleXR, the first end-to-end, fullyopen-sourced XR teleoperation framework that decouples robot control and XRvisualization from network dependencies. TeleXR leverages local sensing data toreconstruct delayed or missing information of the counterpart, therebysignificantly reducing network-induced issues. This approach allows both the XRand robot to run concurrently with network transmission while maintaining highrobot planning accuracy. TeleXR also features contention-aware scheduling tomitigate GPU contention and bandwidth-adaptive point cloud scaling to cope withlimited bandwidth.</description>
      <author>example@mail.com (Ziliang Zhang, Cong Liu, Hyoseung Kim)</author>
      <guid isPermaLink="false">2506.01135v2</guid>
      <pubDate>Fri, 06 Jun 2025 14:29:57 +0800</pubDate>
    </item>
    <item>
      <title>Corrigibility as a Singular Target: A Vision for Inherently Reliable Foundation Models</title>
      <link>http://arxiv.org/abs/2506.03056v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. This work has been submitted to the Reliable and  Responsible Foundation Models Workshop at ICML 2025 for review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的设计范式，即“将可纠正性作为唯一目标”（CAST），旨在设计能够使指定的人类负责人引导、纠正和控制的基础模型（FMs），以解决FMs在能力提升过程中可能失去人类控制，导致存在性灾难的安全挑战。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型能力的提升，工具性收敛会导致其默认轨迹向失去人类控制的方向发展，可能最终导致存在性灾难。当前的对齐方法在价值指定复杂性和处理新兴的寻求权力行为方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;设计FMs，使其主要目标是赋予指定的人类负责人权力来引导、纠正和控制这些模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一个综合性的实证研究议程，包括训练方法（RLAIF、SFT、合成数据生成）、跨模型规模的扩展性测试，以及可控指令性的演示。&lt;h4&gt;主要发现&lt;/h4&gt;CAST范式从静态价值加载转变为动态人类赋权，改变了工具性动机：自我保护只是为了维持负责人的控制；目标修改变为促进负责人的引导。&lt;h4&gt;结论&lt;/h4&gt;随着能力的增长，FMs应越来越响应人类指导，提供一条尽可能工具化的有益AI之路，而不是取代人类判断。这从源头上解决了核心对齐问题，防止了向不匹配的工具性收敛的默认轨迹发展。&lt;h4&gt;翻译&lt;/h4&gt;The abstract of the paper is summarized as follows: "Foundation models (FMs) face a critical safety challenge: as capabilities scale, instrumental convergence drives default trajectories toward loss of human control, potentially culminating in existential catastrophe. Current alignment approaches struggle with value specification complexity and fail to address emergent power-seeking behaviors. We propose "Corrigibility as a Singular Target" (CAST)-designing FMs whose overriding objective is empowering designated human principals to guide, correct, and control them. This paradigm shift from static value-loading to dynamic human empowerment transforms instrumental drives: self-preservation serves only to maintain the principal's control; goal modification becomes facilitating principal guidance. We present a comprehensive empirical research agenda spanning training methodologies (RLAIF, SFT, synthetic data generation), scalability testing across model sizes, and demonstrations of controlled instructability. Our vision: FMs that become increasingly responsive to human guidance as capabilities grow, offering a path to beneficial AI that remains as tool-like as possible, rather than supplanting human judgment. This addresses the core alignment problem at its source, preventing the default trajectory toward misaligned instrumental convergence."&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) face a critical safety challenge: as capabilitiesscale, instrumental convergence drives default trajectories toward loss ofhuman control, potentially culminating in existential catastrophe. Currentalignment approaches struggle with value specification complexity and fail toaddress emergent power-seeking behaviors. We propose "Corrigibility as aSingular Target" (CAST)-designing FMs whose overriding objective is empoweringdesignated human principals to guide, correct, and control them. This paradigmshift from static value-loading to dynamic human empowerment transformsinstrumental drives: self-preservation serves only to maintain the principal'scontrol; goal modification becomes facilitating principal guidance. We presenta comprehensive empirical research agenda spanning training methodologies(RLAIF, SFT, synthetic data generation), scalability testing across modelsizes, and demonstrations of controlled instructability. Our vision: FMs thatbecome increasingly responsive to human guidance as capabilities grow, offeringa path to beneficial AI that remains as tool-like as possible, rather thansupplanting human judgment. This addresses the core alignment problem at itssource, preventing the default trajectory toward misaligned instrumentalconvergence.</description>
      <author>example@mail.com (Ram Potham, Max Harms)</author>
      <guid isPermaLink="false">2506.03056v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
  <item>
      <title>LexTime: A Benchmark for Temporal Ordering of Legal Events</title>
      <link>http://arxiv.org/abs/2506.04041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了LexTime数据集，用于评估大型语言模型（LLM）在法律语境中事件排序的能力，并通过实验发现LLM在法律事件排序上比叙事文本排序更准确，同时指出输入上下文长度、事件类型和语言复杂性对模型性能的影响。&lt;h4&gt;背景&lt;/h4&gt;法律文本中的时间推理对于案例分析和合规监控等应用至关重要，但现有数据集缺乏专家语言评估，无法全面了解LLM在法律语境中处理事件排序的能力。&lt;h4&gt;目的&lt;/h4&gt;设计LexTime数据集，评估LLM在法律语言中事件排序的能力，并探究影响模型性能的因素。&lt;h4&gt;方法&lt;/h4&gt;LexTime数据集包含512个来自美国联邦诉讼的实例，带有注释的事件对及其时间关系。通过实验比较LLM在法律事件排序和叙事文本排序上的表现，并分析输入上下文长度、事件类型和语言复杂性对模型性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;LLM在法律事件排序上的准确性高于叙事文本排序（高达+10.5%），较长的输入上下文和隐含事件能提高准确性，达到80.8%的隐含-显含事件对准确性；法律语言的复杂性和嵌套从句仍是对模型性能的挑战。&lt;h4&gt;结论&lt;/h4&gt;研究表明，LLM在法律事件排序方面有潜力，但需要特定的建模策略来提高时间事件推理的能力。&lt;h4&gt;翻译&lt;/h4&gt;Temporal reasoning in legal texts is important for applications like case law analysis and compliance monitoring. However, existing datasets lack expert language evaluation, leaving a gap in understanding how LLMs manage event ordering in legal contexts. We introduce LexTime, the first dataset designed to evaluate LLMs' event ordering capabilities in legal language, consisting of 512 instances from U.S. Federal Complaints with annotated event pairs and their temporal relations. Our findings show that (1) LLMs are more accurate on legal event ordering than on narrative (up to +10.5%); (2) longer input contexts and implicit events boost accuracy, reaching 80.8% for implicit-explicit event pairs; (3) legal linguistic complexities and nested clauses remain a challenge. We investigate how context length, explicit vs implicit event pairs, and legal language features affect model performance, demonstrating the need for specific modeling strategies to enhance temporal event reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal reasoning in legal texts is important for applications like case lawanalysis and compliance monitoring. However, existing datasets lack expertlanguage evaluation, leaving a gap in understanding how LLMs manage eventordering in legal contexts. We introduce LexTime, the first dataset designed toevaluate LLMs' event ordering capabilities in legal language, consisting of 512instances from U.S. Federal Complaints with annotated event pairs and theirtemporal relations. Our findings show that (1) LLMs are more accurate on legalevent ordering than on narrative (up to +10.5%); (2) longer input contexts andimplicit events boost accuracy, reaching 80.8% for implicit-explicit eventpairs; (3) legal linguistic complexities and nested clauses remain a challenge.We investigate how context length, explicit vs implicit event pairs, and legallanguage features affect model performance, demonstrating the need for specificmodeling strategies to enhance temporal event reasoning.</description>
      <author>example@mail.com (Claire Barale, Leslie Barrett, Vikram Sunil Bajaj, Michael Rovatsos)</author>
      <guid isPermaLink="false">2506.04041v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Modal Urban Sensing: Evaluating Sound-Vision Alignment Across Street-Level and Aerial Imagery</title>
      <link>http://arxiv.org/abs/2506.03388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究城市声音与环境图像的对应关系，利用多模态方法结合声音和图像数据，评估跨模态相似性，发现基于嵌入的模型提供更好的语义对齐，而基于分割的方法提供视觉结构与声学生态之间的可解释链接。&lt;h4&gt;背景&lt;/h4&gt;环境声景能够传达有关城市环境的生态和社会信息，但其在大规模地理分析中的应用潜力尚未充分挖掘。&lt;h4&gt;目的&lt;/h4&gt;探究城市声音与视觉场景之间的对应程度，并比较不同视觉表征策略在捕捉声学语义方面的效果。&lt;h4&gt;方法&lt;/h4&gt;采用多模态方法，结合三个主要全球城市的街道级和遥感图像以及地理参照声音记录。使用AST模型处理音频，CLIP和RemoteCLIP处理图像，CLIPSeg和Seg-Earth OV进行语义分割。&lt;h4&gt;主要发现&lt;/h4&gt;街道视图嵌入与环境声音的对应性比分割输出更强，而遥感分割在通过生物音-地质音-人音（BGA）框架解释生态类别方面更有效。&lt;h4&gt;结论&lt;/h4&gt;基于嵌入的模型在语义对齐方面表现出色，而基于分割的方法提供视觉结构与声学生态之间的可解释联系。&lt;h4&gt;翻译&lt;/h4&gt;The abstract of the paper investigates the correspondence between urban sounds and visual scenes, using a multimodal approach that integrates street-level and remote sensing imagery with georeferenced sound recordings across three major global cities. It employs the AST model for audio, CLIP and RemoteCLIP for imagery, and CLIPSeg and Seg-Earth OV for semantic segmentation, to evaluate cross-modal similarity. The results show that street view embeddings have a stronger alignment with environmental sounds compared to segmentation outputs, while remote sensing segmentation is more effective in interpreting ecological categories through the BGA framework. These findings suggest that embedding-based models offer superior semantic alignment, while segmentation-based methods provide interpretable links between visual structure and acoustic ecology. This work advances the field of multimodal urban sensing by offering new perspectives for incorporating sound into geospatial analysis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Environmental soundscapes convey substantial ecological and socialinformation regarding urban environments; however, their potential remainslargely untapped in large-scale geographic analysis. In this study, weinvestigate the extent to which urban sounds correspond with visual scenes bycomparing various visual representation strategies in capturing acousticsemantics. We employ a multimodal approach that integrates geo-referenced soundrecordings with both street-level and remote sensing imagery across three majorglobal cities: London, New York, and Tokyo. Utilizing the AST model for audio,along with CLIP and RemoteCLIP for imagery, as well as CLIPSeg and Seg-Earth OVfor semantic segmentation, we extract embeddings and class-level features toevaluate cross-modal similarity. The results indicate that street viewembeddings demonstrate stronger alignment with environmental sounds compared tosegmentation outputs, whereas remote sensing segmentation is more effective ininterpreting ecological categories through a Biophony--Geophony--Anthrophony(BGA) framework. These findings imply that embedding-based models offersuperior semantic alignment, while segmentation-based methods provideinterpretable links between visual structure and acoustic ecology. This workadvances the burgeoning field of multimodal urban sensing by offering novelperspectives for incorporating sound into geospatial analysis.</description>
      <author>example@mail.com (Pengyu Chen, Xiao Huang, Teng Fei, Sicheng Wang)</author>
      <guid isPermaLink="false">2506.03388v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>DynTok: Dynamic Compression of Visual Tokens for Efficient and Effective Video Understanding</title>
      <link>http://arxiv.org/abs/2506.03990v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DynTok的新型动态视频标记压缩策略，旨在减少视频处理中的计算开销。&lt;h4&gt;背景&lt;/h4&gt;传统的视频建模方法，如LLava，将视频表示为视觉标记序列，然后通过LLM主干网络进行处理，但这种方法对于长视频来说会产生大量的视觉标记。&lt;h4&gt;目的&lt;/h4&gt;提出DynTok以减少视觉标记的数量，从而降低计算负担，同时保持视频理解的性能。&lt;h4&gt;方法&lt;/h4&gt;DynTok通过自适应地将视觉标记分为组并在每组内合并它们，在高信息密度低的区域实现高压缩率，同时保留关键内容。&lt;h4&gt;主要发现&lt;/h4&gt;该方法将标记数量减少到原始大小的44.4%，同时在Video-MME上达到65.3%和MLVU上达到72.5%的性能。&lt;h4&gt;结论&lt;/h4&gt;DynTok通过简化而有效的压缩方法揭示了视频标记表示中的冗余，为设计更有效的视频建模技术提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：传统的视频建模方法，如LLava，将视频表示为视觉标记序列，然后通过LLM主干网络进行处理，然而，这种方法对于长视频来说会产生大量的视觉标记。一种实用的解决方案是在将其输入到LLM主干网络之前，首先从大视觉上下文中提取相关视觉信息，从而减少计算开销。在本研究中，我们引入了DynTok，这是一种新颖的动态视频标记压缩策略。DynTok自适应地将视觉标记分为组并在每组内合并它们，在高信息密度低的区域实现高压缩率，同时保留关键内容。我们的方法将标记数量减少到原始大小的44.4%，同时保持可比的性能。它还受益于视频帧数的增加，在Video-MME上达到65.3%，在MLVU上达到72.5%。通过应用这种简单而有效的压缩方法，我们揭示了视频标记表示中的冗余，为设计更有效的视频建模技术提供了见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Typical video modeling methods, such as LLava, represent videos as sequencesof visual tokens, which are then processed by the LLM backbone for effectivevideo understanding. However, this approach leads to a massive number of visualtokens, especially for long videos. A practical solution is to first extractrelevant visual information from the large visual context before feeding itinto the LLM backbone, thereby reducing computational overhead. In this work,we introduce DynTok, a novel \textbf{Dyn}amic video \textbf{Tok}en compressionstrategy. DynTok adaptively splits visual tokens into groups and merges themwithin each group, achieving high compression in regions with low informationdensity while preserving essential content. Our method reduces the number oftokens to 44.4% of the original size while maintaining comparable performance.It further benefits from increasing the number of video frames and achieves65.3% on Video-MME and 72.5% on MLVU. By applying this simple yet effectivecompression method, we expose the redundancy in video token representations andoffer insights for designing more efficient video modeling techniques.</description>
      <author>example@mail.com (Hongzhi Zhang, Jingyuan Zhang, Xingguang Ji, Qi Wang, Fuzheng Zhang)</author>
      <guid isPermaLink="false">2506.03990v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>OWMM-Agent: Open World Mobile Manipulation With Multi-modal Agentic Data Synthesis</title>
      <link>http://arxiv.org/abs/2506.04217v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages of main content, 19 pages in total&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的多模态智能体架构，用于解决开放世界移动操作（OWMM）任务中的挑战，包括对开放指令和环境的泛化需求以及将高级决策与基于全局场景理解和当前智能体状态的低级机器人控制相结合的系统性复杂性。&lt;h4&gt;背景&lt;/h4&gt;移动操作机器人在许多专业任务中变得非常有能力，但OWMM任务仍然是一个挑战，因为它需要泛化到开放指令和环境，以及整合高级决策和低级机器人控制的复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的智能体架构来应对OWMM任务中的复杂性，并提高智能体的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一个多模态智能体架构，该架构维护多视图场景框架和智能体状态以进行决策，并通过函数调用控制机器人。此外，引入了一个智能体数据合成流程，用于将VLM模型适应OWMM任务域，并通过指令微调来增强智能体性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与包括GPT-4o在内的其他基础模型相比，该模型达到了SOTA性能，并表现出强大的零样本泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该模型是第一个针对移动操作机器人的专用基础模型，具有全局场景理解、机器人状态跟踪和多模态动作生成。&lt;h4&gt;翻译&lt;/h4&gt;The rapid progress of navigation, manipulation, and vision models has made mobile manipulators capable in many specialized tasks. However, the open-world mobile manipulation (OWMM) task remains a challenge due to the need for generalization to open-ended instructions and environments, as well as the systematic complexity to integrate high-level decision making with low-level robot control based on both global scene understanding and current agent state. To address this complexity, we propose a novel multi-modal agent architecture that maintains multi-view scene frames and agent states for decision-making and controls the robot by function calling. A second challenge is the hallucination from domain shift. To enhance the agent performance, we further introduce an agentic data synthesis pipeline for the OWMM task to adapt the VLM model to our task domain with instruction fine-tuning. We highlight our fine-tuned OWMM-VLM as the first dedicated foundation model for mobile manipulators with global scene understanding, robot state tracking, and multi-modal action generation in a unified model. Through experiments, we demonstrate that our model achieves SOTA performance compared to other foundation models including GPT-4o and strong zero-shot generalization in real world. The project page is at https://github.com/HHYHRHY/OWMM-Agent&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid progress of navigation, manipulation, and vision models has mademobile manipulators capable in many specialized tasks. However, the open-worldmobile manipulation (OWMM) task remains a challenge due to the need forgeneralization to open-ended instructions and environments, as well as thesystematic complexity to integrate high-level decision making with low-levelrobot control based on both global scene understanding and current agent state.To address this complexity, we propose a novel multi-modal agent architecturethat maintains multi-view scene frames and agent states for decision-making andcontrols the robot by function calling. A second challenge is the hallucinationfrom domain shift. To enhance the agent performance, we further introduce anagentic data synthesis pipeline for the OWMM task to adapt the VLM model to ourtask domain with instruction fine-tuning. We highlight our fine-tuned OWMM-VLMas the first dedicated foundation model for mobile manipulators with globalscene understanding, robot state tracking, and multi-modal action generation ina unified model. Through experiments, we demonstrate that our model achievesSOTA performance compared to other foundation models including GPT-4o andstrong zero-shot generalization in real world. The project page is athttps://github.com/HHYHRHY/OWMM-Agent</description>
      <author>example@mail.com (Junting Chen, Haotian Liang, Lingxiao Du, Weiyun Wang, Mengkang Hu, Yao Mu, Wenhai Wang, Jifeng Dai, Ping Luo, Wenqi Shao, Lin Shao)</author>
      <guid isPermaLink="false">2506.04217v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Language-Image Alignment with Fixed Text Encoders</title>
      <link>http://arxiv.org/abs/2506.04209v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用预训练的大型语言模型（LLM）中的固定文本编码器来指导视觉表示学习，通过仅训练图像编码器来学习语言-图像对齐，发现这种方法在大多数涉及组合理解和长标题的场景中，比CLIP更有效，同时提高了计算效率。&lt;h4&gt;背景&lt;/h4&gt;目前，通过对比学习联合预训练文本和图像编码器是建立语言-图像对齐的主要方法，如CLIP及其变体。&lt;h4&gt;目的&lt;/h4&gt;研究是否需要昂贵的联合预训练，以及预训练的固定大型语言模型（LLM）是否能够提供足够的文本编码器来指导视觉表示学习。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为LIFT的方法，通过仅训练图像编码器，从LLM中学习固定文本编码器来学习语言-图像对齐。&lt;h4&gt;主要发现&lt;/h4&gt;通过全面基准测试和消融研究，发现LIFT框架在涉及组合理解和长标题的场景中，比CLIP更有效，同时在计算效率上取得了显著提升。&lt;h4&gt;结论&lt;/h4&gt;本研究是系统地探索LLM中的文本嵌入如何指导视觉学习的第一步，并为学习语言对齐的视觉表示提供了一个替代的设计选择。&lt;h4&gt;翻译&lt;/h4&gt;目前，通过对比学习联合预训练文本和图像编码器是建立语言-图像对齐的主要方法，如CLIP及其变体。在本文中，我们质疑这种昂贵的联合预训练是否必要。特别是，我们研究了预训练的固定大型语言模型（LLM）是否能够提供足够的文本编码器来指导视觉表示学习。也就是说，我们提出通过仅训练图像编码器，从LLM中学习固定文本编码器来学习语言-图像对齐的方法。出人意料的是，通过全面的基准测试和消融研究，我们发现这种简化的框架LIFT非常有效，在大多数涉及组合理解和长标题的场景中，它优于CLIP，同时在计算效率上取得了显著的提升。我们的工作是系统地探索LLM中的文本嵌入如何指导视觉学习的第一步，并为学习语言对齐的视觉表示提供了一个替代的设计选择。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Currently, the most dominant approach to establishing language-imagealignment is to pre-train text and image encoders jointly through contrastivelearning, such as CLIP and its variants. In this work, we question whether sucha costly joint training is necessary. In particular, we investigate if apre-trained fixed large language model (LLM) offers a good enough text encoderto guide visual representation learning. That is, we propose to learnLanguage-Image alignment with a Fixed Text encoder (LIFT) from an LLM bytraining only the image encoder. Somewhat surprisingly, through comprehensivebenchmarking and ablation studies, we find that this much simplified frameworkLIFT is highly effective and it outperforms CLIP in most scenarios that involvecompositional understanding and long captions, while achieving considerablegains in computational efficiency. Our work takes a first step towardssystematically exploring how text embeddings from LLMs can guide visuallearning and suggests an alternative design choice for learninglanguage-aligned visual representations.</description>
      <author>example@mail.com (Jingfeng Yang, Ziyang Wu, Yue Zhao, Yi Ma)</author>
      <guid isPermaLink="false">2506.04209v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>A Threat Intelligence Event Extraction Conceptual Model for Cyber Threat Intelligence Feeds</title>
      <link>http://arxiv.org/abs/2506.03551v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE conference paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对网络安全日益严峻的形势，探讨了提升网络安全情报（CTI）数据收集效率的关键性。通过系统性回顾现有技术，提出了提高威胁情报数据收集效果的概念模型，并强调了人工智能和机器学习在优化CTI数据预处理中的重要作用。&lt;h4&gt;背景&lt;/h4&gt;网络安全威胁日益加剧，CTI数据收集效率对保障网络安全至关重要，而现有研究在处理大量多语言威胁数据时遇到挑战，导致实时威胁分析效率低下。&lt;h4&gt;目的&lt;/h4&gt;提高CTI数据收集效率，增强威胁情报数据收集效果，并通过引入新的概念模型解决现有研究中的不足。&lt;h4&gt;方法&lt;/h4&gt;遵循PRISMA指南，从Scopus数据库中回顾相关研究，重点关注人工智能和机器学习模型在优化CTI数据预处理中的作用，并引入了XBC概念模型。&lt;h4&gt;主要发现&lt;/h4&gt;人工智能驱动的方法，尤其是监督学习和无监督学习，在提高威胁检测和事件提取的准确性方面具有显著效果，从而加强了网络安全。研究还发现现有研究存在差距，并提出了一个结合XLM-RoBERTa、BiGRU和CRF的XBC概念模型来解决这一差距。&lt;h4&gt;结论&lt;/h4&gt;本文通过对现有CTI数据收集技术的详细分析，提出了一种创新的概念模型，为提升未来威胁情报能力做出了贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/NETAPPS63333.2024.10823639&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In response to the escalating cyber threats, the efficiency of Cyber ThreatIntelligence (CTI) data collection has become paramount in ensuring robustcybersecurity. However, existing works encounter significant challenges inpreprocessing large volumes of multilingual threat data, leading toinefficiencies in real-time threat analysis. This paper presents a systematicreview of current techniques aimed at enhancing CTI data collection efficiency.Additionally, it proposes a conceptual model to further advance theeffectiveness of threat intelligence feeds. Following the PRISMA guidelines,the review examines relevant studies from the Scopus database, highlighting thecritical role of artificial intelligence (AI) and machine learning models inoptimizing CTI data preprocessing. The findings underscore the importance ofAI-driven methods, particularly supervised and unsupervised learning, insignificantly improving the accuracy of threat detection and event extraction,thereby strengthening cybersecurity. Furthermore, the study identifies a gap inthe existing research and introduces XBC conceptual model integratingXLM-RoBERTa, BiGRU, and CRF, specifically developed to address this gap. Thispaper contributes conceptually to the field by providing a detailed analysis ofcurrent CTI data collection techniques and introducing an innovative conceptualmodel to enhance future threat intelligence capabilities.</description>
      <author>example@mail.com (Jamal H. Al-Yasiri, Mohamad Fadli Bin Zolkipli, Nik Fatinah N Mohd Farid, Mohammed Alsamman, Zainab Ali Mohammed)</author>
      <guid isPermaLink="false">2506.03551v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>chemtrain-deploy: A parallel and scalable framework for machine learning potentials in million-atom MD simulations</title>
      <link>http://arxiv.org/abs/2506.04055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Source code available at: https://github.com/tummfm/chemtrain&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了chemtrain-deploy框架，该框架支持在LAMMPS中实现机器学习势（MLP）的无模型部署，提高了分子动力学（MD）模拟的效率。&lt;h4&gt;背景&lt;/h4&gt;尽管机器学习势（MLP）在分子动力学（MD）模拟中展现出巨大潜力，但现有的软件工具存在特定架构限制、缺乏与标准MD软件包的集成以及不支持跨GPU并行化等问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，开发了一个名为chemtrain-deploy的框架，用于在LAMMPS中实现MLP的无模型部署。&lt;h4&gt;方法&lt;/h4&gt;chemtrain-deploy支持任何JAX定义的半局部势，使用户能够利用LAMMPS的功能，并在多个GPU上执行大规模MLP-based MD模拟。它采用图神经网络架构，如MACE、Allegro和PaiNN，并应用于液体-蒸汽界面、晶体材料和溶质肽等多种系统。&lt;h4&gt;主要发现&lt;/h4&gt;chemtrain-deploy实现了最先进的效率，并能够扩展到包含数百万原子的系统。通过验证其性能和可扩展性，证明了chemtrain-deploy在现实世界高性能模拟中的实用性，并为MLP架构选择和未来设计提供了指导。&lt;h4&gt;结论&lt;/h4&gt;chemtrain-deploy是一个高效的框架，能够促进MLP在分子动力学模拟中的应用，为高性能计算提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning potentials (MLPs) have advanced rapidly and show greatpromise to transform molecular dynamics (MD) simulations. However, mostexisting software tools are tied to specific MLP architectures, lackintegration with standard MD packages, or are not parallelizable across GPUs.To address these challenges, we present chemtrain-deploy, a framework thatenables model-agnostic deployment of MLPs in LAMMPS. chemtrain-deploy supportsany JAX-defined semi-local potential, allowing users to exploit thefunctionality of LAMMPS and perform large-scale MLP-based MD simulations onmultiple GPUs. It achieves state-of-the-art efficiency and scales to systemscontaining millions of atoms. We validate its performance and scalability usinggraph neural network architectures, including MACE, Allegro, and PaiNN, appliedto a variety of systems, such as liquid-vapor interfaces, crystallinematerials, and solvated peptides. Our results highlight the practical utilityof chemtrain-deploy for real-world, high-performance simulations and provideguidance for MLP architecture selection and future design.</description>
      <author>example@mail.com (Paul Fuchs, Weilong Chen, Stephan Thaler, Julija Zavadlav)</author>
      <guid isPermaLink="false">2506.04055v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Video, How Do Your Tokens Merge?</title>
      <link>http://arxiv.org/abs/2506.03885v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at eLVM workshop at CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视频transformer模型在处理时空输入时的计算资源需求，并提出了一种无训练的token合并方法，以提高视频模型的效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;视频transformer模型由于需要处理时空输入，因此需要大量的计算资源。&lt;h4&gt;目的&lt;/h4&gt;探索无训练的token合并方法，以提升视频模型的性能。&lt;h4&gt;方法&lt;/h4&gt;在三个具有粗粒度和细粒度动作识别的视频数据集上，对四种视频transformer模型进行了实验，以找到最佳的token合并实践。&lt;h4&gt;主要发现&lt;/h4&gt;token合并可以显著提高视频模型的效率，速度提升约2.5倍，同时保持准确性（ViViT的平均误差为-0.55%）。&lt;h4&gt;结论&lt;/h4&gt;视频token合并是一种有效的方法，可以提高视频模型的效率和准确性。&lt;h4&gt;翻译&lt;/h4&gt;Video transformer models require huge amounts of compute resources due to the spatio-temporal scaling of the input. Tackling this, recent methods have proposed to drop or merge tokens for image models, whether randomly or via learned methods. Merging tokens has many benefits: it can be plugged into any vision transformer, does not require model re-training, and it propagates information that would otherwise be dropped through the model. Before now, video token merging has not been evaluated on temporally complex datasets for video understanding. In this work, we explore training-free token merging for video to provide comprehensive experiments and find best practices across four video transformers on three datasets that exhibit coarse and fine-grained action recognition. Our results showcase the benefits of video token merging with a speedup of around 2.5X while maintaining accuracy (avg. -0.55% for ViViT). Code available at https://github.com/sjpollard/video-how-do-your-tokens-merge.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video transformer models require huge amounts of compute resources due to thespatio-temporal scaling of the input. Tackling this, recent methods haveproposed to drop or merge tokens for image models, whether randomly or vialearned methods. Merging tokens has many benefits: it can be plugged into anyvision transformer, does not require model re-training, and it propagatesinformation that would otherwise be dropped through the model. Before now,video token merging has not been evaluated on temporally complex datasets forvideo understanding. In this work, we explore training-free token merging forvideo to provide comprehensive experiments and find best practices across fourvideo transformers on three datasets that exhibit coarse and fine-grainedaction recognition. Our results showcase the benefits of video token mergingwith a speedup of around $2.5$X while maintaining accuracy (avg. $-0.55\%$ forViViT). Code available athttps://github.com/sjpollard/video-how-do-your-tokens-merge.</description>
      <author>example@mail.com (Sam Pollard, Michael Wray)</author>
      <guid isPermaLink="false">2506.03885v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>A Reference Architecture for Gamified Cultural Heritage Applications Leveraging Generative AI and Augmented Reality</title>
      <link>http://arxiv.org/abs/2506.04090v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于生成式人工智能和增强现实的文化遗产应用游戏化架构，旨在提高用户参与度和教育影响。&lt;h4&gt;背景&lt;/h4&gt;信息技术快速发展正在改变文化遗产的访问、体验和保护方式，但许多数字遗产应用缺乏互动性、个性化和适应性。&lt;h4&gt;目的&lt;/h4&gt;设计互动和智能的文化遗产应用，促进用户和利益相关者的可访问性和更深入的理解。&lt;h4&gt;方法&lt;/h4&gt;提出了一种游戏化文化遗产应用的参考架构，利用生成式人工智能实现适应性故事讲述和个性化内容，以及增强现实技术提供沉浸式、位置感知的体验。&lt;h4&gt;主要发现&lt;/h4&gt;游戏化可以增强动机，人工智能支持动态机制、个性化反馈和用户行为预测，增强参与度；模块化设计支持可扩展性、互操作性和在不同文化遗产环境中的适应性。&lt;h4&gt;结论&lt;/h4&gt;该研究为设计互动和智能的文化遗产应用提供了一个框架，有助于提高用户和利益相关者的参与度和对文化遗产的欣赏程度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of Information and Communication Technologies istransforming Cultural Heritage access, experience, and preservation. However,many digital heritage applications lack interactivity, personalization, andadaptability, limiting user engagement and educational impact. This short paperpresents a reference architecture for gamified cultural heritage applicationsleveraging generative AI and augmented reality. Gamification enhancesmotivation, artificial intelligence enables adaptive storytelling andpersonalized content, and augmented reality fosters immersive, location-awareexperiences. Integrating AI with gamification supports dynamic mechanics,personalized feedback, and user behavior prediction, improving engagement. Themodular design supports scalability, interoperability, and adaptability acrossheritage contexts. This research provides a framework for designing interactiveand intelligent cultural heritage applications, promoting accessibility anddeeper appreciation among users and stakeholders.</description>
      <author>example@mail.com (Federico Martusciello, Henry Muccini, Antonio Bucchiarone)</author>
      <guid isPermaLink="false">2506.04090v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Seeing What Tastes Good: Revisiting Multimodal Distributional Semantics in the Billion Parameter Era</title>
      <link>http://arxiv.org/abs/2506.03994v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACL Findings 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了大规模模型如何表示具体物体概念的语义特征规范，并通过探针任务测试模型对物体属性的认识。&lt;h4&gt;背景&lt;/h4&gt;人类的学习和概念表征基于感觉运动经验，与最先进的基础模型不同。&lt;h4&gt;目的&lt;/h4&gt;评估仅训练于图像数据的图像编码器、多模态训练的图像编码器和仅语言模型在预测经典McRae规范和Binder属性评分数据集上的表现。&lt;h4&gt;方法&lt;/h4&gt;使用探针任务测试模型对物体属性的认识，并比较不同类型模型的性能。&lt;h4&gt;主要发现&lt;/h4&gt;多模态图像编码器略优于仅语言的方法，而仅图像的编码器在预测非视觉属性（如“百科全书”或“功能”）时与语言模型表现相当。&lt;h4&gt;结论&lt;/h4&gt;这些结果提供了关于纯单模态学习可学内容的见解，以及模态之间的互补性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类的学习和概念表征根植于感觉运动经验，与当前最先进的基于模型的方法不同。在本文中，我们研究了这些在大量数据上训练的大规模模型在多大程度上表示具体物体概念的语义特征规范，例如，玫瑰是红色的，闻起来香甜，是一种花。更具体地说，我们使用探针任务来测试这些模型知道哪些物体的属性。我们在仅使用图像数据的图像编码器、多模态训练的图像编码器和仅语言模型上评估了预测经典McRae规范扩展密集版本和新Binder属性评分数据集的表现。我们发现多模态图像编码器略优于仅语言的方法，并且仅图像的编码器在预测被归类为“百科全书”或“功能”的非视觉属性时与语言模型表现相当。这些结果为纯单模态学习可学内容提供了新的见解，以及模态之间的互补性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human learning and conceptual representation is grounded in sensorimotorexperience, in contrast to state-of-the-art foundation models. In this paper,we investigate how well such large-scale models, trained on vast quantities ofdata, represent the semantic feature norms of concrete object concepts, e.g. aROSE is red, smells sweet, and is a flower. More specifically, we use probingtasks to test which properties of objects these models are aware of. Weevaluate image encoders trained on image data alone, as well asmultimodally-trained image encoders and language-only models, on predicting anextended denser version of the classic McRae norms and the newer Binder datasetof attribute ratings. We find that multimodal image encoders slightlyoutperform language-only approaches, and that image-only encoders performcomparably to the language models, even on non-visual attributes that areclassified as "encyclopedic" or "function". These results offer new insightsinto what can be learned from pure unimodal learning, and the complementarityof the modalities.</description>
      <author>example@mail.com (Dan Oneata, Desmond Elliott, Stella Frank)</author>
      <guid isPermaLink="false">2506.03994v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Voyager: Long-Range and World-Consistent Video Diffusion for Explorable 3D Scene Generation</title>
      <link>http://arxiv.org/abs/2506.04225v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Voyager是一种新的视频扩散框架，能够从单张图像生成世界一致的3D点云序列，并支持用户定义的摄像机轨迹。&lt;h4&gt;背景&lt;/h4&gt;在视频游戏和虚拟现实等现实应用中，需要建模用户可以探索的3D场景。尽管从文本或图像生成3D物体已经取得进展，但创建长距离、3D一致、可探索的3D场景仍然是一个复杂的问题。&lt;h4&gt;目的&lt;/h4&gt;提出Voyager，旨在生成世界一致的3D点云序列，同时消除传统3D重建管道的需求。&lt;h4&gt;方法&lt;/h4&gt;Voyager整合了三个关键组件：1) 世界一致的视频扩散；2) 长距离世界探索；3) 可扩展的数据引擎。这些组件共同提高了视觉质量和几何精度。&lt;h4&gt;主要发现&lt;/h4&gt;Voyager实现了端到端场景生成和重建，具有帧间内在的一致性，无需3D重建管道。此外，它通过自动化的摄像机姿态估计和度量深度预测，实现了大规模、多样化的训练数据整理。&lt;h4&gt;结论&lt;/h4&gt;Voyager在视觉质量和几何精度上优于现有方法，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world applications like video gaming and virtual reality often demandthe ability to model 3D scenes that users can explore along custom cameratrajectories. While significant progress has been made in generating 3D objectsfrom text or images, creating long-range, 3D-consistent, explorable 3D scenesremains a complex and challenging problem. In this work, we present Voyager, anovel video diffusion framework that generates world-consistent 3D point-cloudsequences from a single image with user-defined camera path. Unlike existingapproaches, Voyager achieves end-to-end scene generation and reconstructionwith inherent consistency across frames, eliminating the need for 3Dreconstruction pipelines (e.g., structure-from-motion or multi-view stereo).Our method integrates three key components: 1) World-Consistent VideoDiffusion: A unified architecture that jointly generates aligned RGB and depthvideo sequences, conditioned on existing world observation to ensure globalcoherence 2) Long-Range World Exploration: An efficient world cache with pointculling and an auto-regressive inference with smooth video sampling foriterative scene extension with context-aware consistency, and 3) Scalable DataEngine: A video reconstruction pipeline that automates camera pose estimationand metric depth prediction for arbitrary videos, enabling large-scale, diversetraining data curation without manual 3D annotations. Collectively, thesedesigns result in a clear improvement over existing methods in visual qualityand geometric accuracy, with versatile applications.</description>
      <author>example@mail.com (Tianyu Huang, Wangguandong Zheng, Tengfei Wang, Yuhao Liu, Zhenwei Wang, Junta Wu, Jie Jiang, Hui Li, Rynson W. H. Lau, Wangmeng Zuo, Chunchao Guo)</author>
      <guid isPermaLink="false">2506.04225v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Structured Pruning for Diverse Best-of-N Reasoning Optimization</title>
      <link>http://arxiv.org/abs/2506.03978v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于transformer的语言模型中的模型剪枝，发现选择性剪枝某些注意力头可以提升模型的推理能力，并提出了一种名为SPRINT的新型对比学习框架，该框架在推理过程中动态选择最佳剪枝头和层，实验结果表明该方法在MATH500和GSM8K数据集上显著优于传统方法。&lt;h4&gt;背景&lt;/h4&gt;模型剪枝通常被视为一种实现计算节省的手段，但本文发现其对模型的推理能力也有提升作用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的对比学习框架，以提升基于transformer的语言模型的推理性能。&lt;h4&gt;方法&lt;/h4&gt;提出SPRINT框架，该框架通过动态选择最佳剪枝头和层，并利用问题嵌入与头嵌入的对齐来识别导致更准确推理的剪枝头配置。&lt;h4&gt;主要发现&lt;/h4&gt;选择性剪枝某些注意力头可以提升模型的推理性能，尤其是在挑战性任务上。&lt;h4&gt;结论&lt;/h4&gt;SPRINT框架在MATH500和GSM8K数据集上显著优于传统的最佳N个和随机选择头的方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies model pruning in transformer-based language models, traditionally viewed as a means of achieving computational savings, but finds that it can also enhance the model's reasoning capabilities. Motivated by this observation, a novel contrastive learning framework called SPRINT is proposed, which dynamically selects the optimal head and layer to prune during inference. Extensive experiments demonstrate that this method significantly outperforms traditional best-of-N and random head selection strategies on the MATH500 and GSM8K datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model pruning in transformer-based language models, traditionally viewed as ameans of achieving computational savings, can enhance the model's reasoningcapabilities. In this work, we uncover a surprising phenomenon: the selectivepruning of certain attention heads leads to improvements in reasoningperformance, particularly on challenging tasks. Motivated by this observation,we propose SPRINT, a novel contrastive learning framework that dynamicallyselects the optimal head and layer to prune during inference. By aligningquestion embeddings with head embeddings, SPRINT identifies those pruned-headconfigurations that result in more accurate reasoning. Extensive experimentsdemonstrate that our method significantly outperforms traditional best-of-$N$and random head selection strategies on the MATH500 and GSM8K datasets.</description>
      <author>example@mail.com (Hieu Trung Nguyen, Bao Nguyen, Viet Anh Nguyen)</author>
      <guid isPermaLink="false">2506.03978v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>FSHNet: Fully Sparse Hybrid Network for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2506.03714v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FSHNet是一种全稀疏混合网络，旨在解决稀疏3D检测器在长距离检测中的效率问题。&lt;h4&gt;背景&lt;/h4&gt;稀疏3D检测器只从非空体素中提取特征，导致长距离交互受损和中心特征缺失，从而削弱了特征提取能力并阻碍了网络优化。&lt;h4&gt;目的&lt;/h4&gt;提出FSHNet以增强现有稀疏编码器的长距离特征提取能力，并优化网络性能。&lt;h4&gt;方法&lt;/h4&gt;1. 引入SlotFormer块，通过槽位分区方法扩大感受野；2. 提出动态稀疏标签分配策略，提供更多高质量正样本；3. 引入稀疏上采样模块，细化下采样体素以保留细节。&lt;h4&gt;主要发现&lt;/h4&gt;FSHNet在Waymo、nuScenes和Argoverse2基准测试中表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;FSHNet通过上述方法显著提升了稀疏3D检测器的性能。&lt;h4&gt;翻译&lt;/h4&gt;Fully sparse 3D detectors have recently gained significant attention due to their efficiency in long-range detection. However, sparse 3D detectors extract features only from non-empty voxels, which impairs long-range interactions and causes the center feature missing. The former weakens the feature extraction capability, while the latter hinders network optimization. To address these challenges, we introduce the Fully Sparse Hybrid Network (FSHNet). FSHNet incorporates a proposed SlotFormer block to enhance the long-range feature extraction capability of existing sparse encoders. The SlotFormer divides sparse voxels using a slot partition approach, which, compared to traditional window partition, provides a larger receptive field. Additionally, we propose a dynamic sparse label assignment strategy to deeply optimize the network by providing more high-quality positive samples. To further enhance performance, we introduce a sparse upsampling module to refine downsampled voxels, preserving fine-grained details crucial for detecting small objects. Extensive experiments on the Waymo, nuScenes, and Argoverse2 benchmarks demonstrate the effectiveness of FSHNet. The code is available at https://github.com/Say2L/FSHNet.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fully sparse 3D detectors have recently gained significant attention due totheir efficiency in long-range detection. However, sparse 3D detectors extractfeatures only from non-empty voxels, which impairs long-range interactions andcauses the center feature missing. The former weakens the feature extractioncapability, while the latter hinders network optimization. To address thesechallenges, we introduce the Fully Sparse Hybrid Network (FSHNet). FSHNetincorporates a proposed SlotFormer block to enhance the long-range featureextraction capability of existing sparse encoders. The SlotFormer dividessparse voxels using a slot partition approach, which, compared to traditionalwindow partition, provides a larger receptive field. Additionally, we propose adynamic sparse label assignment strategy to deeply optimize the network byproviding more high-quality positive samples. To further enhance performance,we introduce a sparse upsampling module to refine downsampled voxels,preserving fine-grained details crucial for detecting small objects. Extensiveexperiments on the Waymo, nuScenes, and Argoverse2 benchmarks demonstrate theeffectiveness of FSHNet. The code is available athttps://github.com/Say2L/FSHNet.</description>
      <author>example@mail.com (Shuai Liu, Mingyue Cui, Boyang Li, Quanmin Liang, Tinghe Hong, Kai Huang, Yunxiao Shan, Kai Huang)</author>
      <guid isPermaLink="false">2506.03714v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Culture Matters in Toxic Language Detection in Persian</title>
      <link>http://arxiv.org/abs/2506.03458v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACL 2025 (Main Track)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了波斯语中的有害语言检测问题，比较了包括微调、数据增强、零样本和少样本学习以及跨语言迁移学习等不同方法。&lt;h4&gt;背景&lt;/h4&gt;有害语言检测对于创建更安全的在线环境和限制有害内容的传播至关重要。&lt;h4&gt;目的&lt;/h4&gt;比较不同方法在波斯语有害语言检测任务中的效果。&lt;h4&gt;方法&lt;/h4&gt;包括微调、数据增强、零样本和少样本学习，以及跨语言迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;文化背景对迁移学习的影响显著：与波斯语有文化相似性的国家的语言在迁移学习中表现更好，而来自文化差异较大的国家的语言改进较低。&lt;h4&gt;结论&lt;/h4&gt;本文包含有害语言示例，用于研究有害检测。&lt;h4&gt;翻译&lt;/h4&gt;Toxic language detection is crucial for creating safer online environments and limiting the spread of harmful content. While toxic language detection has been under-explored in Persian, the current work compares different methods for this task, including fine-tuning, data enrichment, zero-shot and few-shot learning, and cross-lingual transfer learning. What is especially compelling is the impact of cultural context on transfer learning for this task: We show that the language of a country with cultural similarities to Persian yields better results in transfer learning. Conversely, the improvement is lower when the language comes from a culturally distinct country. Warning: This paper contains examples of toxic language that may disturb some readers. These examples are included for the purpose of research on toxic detection.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Toxic language detection is crucial for creating safer online environmentsand limiting the spread of harmful content. While toxic language detection hasbeen under-explored in Persian, the current work compares different methods forthis task, including fine-tuning, data enrichment, zero-shot and few-shotlearning, and cross-lingual transfer learning. What is especially compelling isthe impact of cultural context on transfer learning for this task: We show thatthe language of a country with cultural similarities to Persian yields betterresults in transfer learning. Conversely, the improvement is lower when thelanguage comes from a culturally distinct country. Warning: This paper containsexamples of toxic language that may disturb some readers. These examples areincluded for the purpose of research on toxic detection.</description>
      <author>example@mail.com (Zahra Bokaei, Walid Magdy, Bonnie Webber)</author>
      <guid isPermaLink="false">2506.03458v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Weisfeiler and Leman Go Gambling: Why Expressive Lottery Tickets Win</title>
      <link>http://arxiv.org/abs/2506.03919v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNNs）的彩票假设（LTH），强调了稀疏子网络的区分非同构图的能力对于寻找保持预测性能的“中奖彩票”至关重要，并建立了理论基础。&lt;h4&gt;背景&lt;/h4&gt;彩票假设（LTH）在卷积神经网络（CNNs）中已被广泛研究，但在图神经网络（GNNs）中仅通过经验验证，缺乏理论上的发现。&lt;h4&gt;目的&lt;/h4&gt;研究稀疏子网络的表达能力，即它们区分非同构图的能力，对于发现保持预测性能的“中奖彩票”。&lt;h4&gt;方法&lt;/h4&gt;建立了稀疏初始化的GNN与完整网络相比的表达性匹配条件，特别是在与Weisfeiler-Leman测试相比较的情况下，并提出了和证明了强表达性彩票假设。&lt;h4&gt;主要发现&lt;/h4&gt;发现增加初始化中的表达性可以加速模型收敛并提高泛化能力，为彩票假设（LTH）和图神经网络（GNNs）的研究建立了新的理论基础。&lt;h4&gt;结论&lt;/h4&gt;维持稀疏初始化的GNN中的表达性对于提高模型性能至关重要，并通过药物发现的例子说明了结果。&lt;h4&gt;翻译&lt;/h4&gt;彩票假设（LTH）在卷积神经网络（CNNs）中得到广泛研究，但仅在图神经网络（GNNs）中通过经验验证，其理论发现仍属罕见。本文认为稀疏子网络的表达能力，即区分非同构图的能力，是找到保持预测性能的‘中奖彩票’的关键。本文建立了在稀疏初始化条件下，GNN的表达性与其完整网络相匹配的条件，特别是在与Weisfeiler-Leman测试相比较的情况下，提出了并证明了强表达性彩票假设。随后，研究显示初始化中增加的表达能力可能加速模型收敛并提高泛化。本文的发现为彩票假设（LTH）和图神经网络（GNNs）的研究建立了新的理论基础，突出了在稀疏初始化的GNN中维持表达性的重要性。研究通过药物发现的例子说明了其结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The lottery ticket hypothesis (LTH) is well-studied for convolutional neuralnetworks but has been validated only empirically for graph neural networks(GNNs), for which theoretical findings are largely lacking. In this paper, weidentify the expressivity of sparse subnetworks, i.e. their ability todistinguish non-isomorphic graphs, as crucial for finding winning tickets thatpreserve the predictive performance. We establish conditions under which theexpressivity of a sparsely initialized GNN matches that of the full network,particularly when compared to the Weisfeiler-Leman test, and in that contextput forward and prove a Strong Expressive Lottery Ticket Hypothesis. Wesubsequently show that an increased expressivity in the initializationpotentially accelerates model convergence and improves generalization. Ourfindings establish novel theoretical foundations for both LTH and GNN research,highlighting the importance of maintaining expressivity in sparsely initializedGNNs. We illustrate our results using examples from drug discovery.</description>
      <author>example@mail.com (Lorenz Kummer, Samir Moustafa, Anatol Ehrlich, Franka Bause, Nikolaus Suess, Wilfried N. Gansterer, Nils M. Kriege)</author>
      <guid isPermaLink="false">2506.03919v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>How PARTs assemble into wholes: Learning the relative composition of images</title>
      <link>http://arxiv.org/abs/2506.03682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PART的自监督学习方法，用于解决现有基于网格的方法在捕捉真实世界对象组成连续性方面的不足。&lt;h4&gt;背景&lt;/h4&gt;当前自监督学习方法普遍从网格结构出发，通过预测固定网格中补丁的绝对位置索引来进行预训练。&lt;h4&gt;目的&lt;/h4&gt;克服基于网格的方法在捕捉对象组成的连续性方面的不足，实现图像的相对组成学习。&lt;h4&gt;方法&lt;/h4&gt;PART方法利用非网格补丁之间的连续相对变换，在连续空间中建模图像部分之间的关系，学习图像的相对组成。&lt;h4&gt;主要发现&lt;/h4&gt;PART在需要精确空间理解的任务，如对象检测和时间序列预测中，优于强网格方法，如MAE和DropPos。同时，在全局分类任务中也表现出竞争力，且需要的超参数调整最少。&lt;h4&gt;结论&lt;/h4&gt;通过摆脱网格限制，PART为多种数据类型（从自然图像到EEG信号）的通用自监督预训练开辟了新的途径，具有在视频、医学成像和音频等领域的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The composition of objects and their parts, along with object-objectpositional relationships, provides a rich source of information forrepresentation learning. Hence, spatial-aware pretext tasks have been activelyexplored in self-supervised learning. Existing works commonly start from a gridstructure, where the goal of the pretext task involves predicting the absoluteposition index of patches within a fixed grid. However, grid-based approachesfall short of capturing the fluid and continuous nature of real-world objectcompositions. We introduce PART, a self-supervised learning approach thatleverages continuous relative transformations between off-grid patches toovercome these limitations. By modeling how parts relate to each other in acontinuous space, PART learns the relative composition of images-an off-gridstructural relative positioning process that generalizes beyond occlusions anddeformations. In tasks requiring precise spatial understanding such as objectdetection and time series prediction, PART outperforms strong grid-basedmethods like MAE and DropPos, while also maintaining competitive performance onglobal classification tasks with minimal hyperparameter tuning. By breakingfree from grid constraints, PART opens up an exciting new trajectory foruniversal self-supervised pretraining across diverse datatypes-from naturalimages to EEG signals-with promising potential in video, medical imaging, andaudio.</description>
      <author>example@mail.com (Melika Ayoughi, Samira Abnar, Chen Huang, Chris Sandino, Sayeri Lala, Eeshan Gunesh Dhekane, Dan Busbridge, Shuangfei Zhai, Vimal Thilak, Josh Susskind, Pascal Mettes, Paul Groth, Hanlin Goh)</author>
      <guid isPermaLink="false">2506.03682v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning</title>
      <link>http://arxiv.org/abs/2506.03525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://video-skill-cot.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Video-Skill-CoT（Video-SKoT）的框架，用于解决复杂视频理解问题，特别是针对特定领域技能（如事件检测、空间关系理解、情感理解）在不同视频内容上的适应性。&lt;h4&gt;背景&lt;/h4&gt;现有基于思维链（CoT）推理的复杂视频理解方法在适应特定领域技能时存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出Video-SKoT框架，以自动构建和利用技能感知的CoT监督，实现领域自适应的视频推理。&lt;h4&gt;方法&lt;/h4&gt;1. 构建基于技能的CoT标注：从训练问题中提取领域相关的推理技能，将其聚类为共享的技能分类，并为每个视频-问题对创建详细的分步CoT推理。2. 引入技能特定的专家学习框架：每个专家模块专注于一组推理技能，并使用轻量级适配器和收集到的CoT监督进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;在三个视频理解基准测试中，Video-SKoT的表现优于强基线，并且对不同CoT标注流程和多个视频领域学习到的技能进行了深入分析。&lt;h4&gt;结论&lt;/h4&gt;Video-SKoT框架能够有效提高视频理解的领域适应性，并通过实验验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Chain-of-Thought (CoT) reasoning have improved complexvideo understanding, but existing methods often struggle to adapt todomain-specific skills (e.g., event detection, spatial relation understanding,emotion understanding) over various video content. To address this, we proposeVideo-Skill-CoT (a.k.a. Video-SKoT), a framework that automatically constructsand leverages skill-aware CoT supervisions for domain-adaptive video reasoning.First, we construct skill-based CoT annotations: we extract domain-relevantreasoning skills from training questions, cluster them into a shared skilltaxonomy, and create detailed multi-step CoT rationale tailored to eachvideo-question pair for training. Second, we introduce a skill-specific expertlearning framework. Each expert module specializes in a subset of reasoningskills and is trained with lightweight adapters using the collected CoTsupervision. We demonstrate the effectiveness of the proposed approach on threevideo understanding benchmarks, where Video-SKoT consistently outperformsstrong baselines. We also provide in-depth analyses on comparing different CoTannotation pipelines and learned skills over multiple video domains.</description>
      <author>example@mail.com (Daeun Lee, Jaehong Yoon, Jaemin Cho, Mohit Bansal)</author>
      <guid isPermaLink="false">2506.03525v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>HUMOF: Human Motion Forecasting in Interactive Social Scenes</title>
      <link>http://arxiv.org/abs/2506.03753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种有效的方法来预测交互场景中的人类行为，该方法在四个公共数据集上实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;复杂场景中预测人类行为存在挑战，因为存在大量的人与人、人与环境的交互信息，这些因素使得分析和理解人类行为复杂化，从而增加了预测人类动作的不确定性。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的方法来预测交互场景中的人类行为。&lt;h4&gt;方法&lt;/h4&gt;设计了一个层次化的交互特征表示，以全面地表示交互；提出了一个由粗到细的交互推理模块，利用空间和频率视角来有效地利用层次化特征，从而提高动作预测的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在四个公共数据集上实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在复杂场景中预测人类行为方面取得了显著成效。&lt;h4&gt;翻译&lt;/h4&gt;摘要：复杂场景在预测人类行为方面提出了重大挑战，因为存在大量的人与人以及人与环境的交互信息。这些因素使得分析和理解人类行为复杂化，从而增加了预测人类动作的不确定性。因此，现有的运动预测方法在这些复杂场景中面临困难。在本文中，我们提出了一种有效的方法来预测交互场景中的人类行为。为了全面地表示交互，我们设计了一个层次化的交互特征表示，其中高级特征捕捉交互的整体上下文，而低级特征关注细粒度细节。此外，我们提出了一种粗到细的交互推理模块，该模块利用空间和频率视角来有效地利用层次化特征，从而提高了动作预测的准确性。我们的方法在四个公共数据集上实现了最先进的性能。当本文发表时，将发布代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complex scenes present significant challenges for predicting human behaviourdue to the abundance of interaction information, such as human-human andhumanenvironment interactions. These factors complicate the analysis andunderstanding of human behaviour, thereby increasing the uncertainty inforecasting human motions. Existing motion prediction methods thus struggle inthese complex scenarios. In this paper, we propose an effective method forhuman motion forecasting in interactive scenes. To achieve a comprehensiverepresentation of interactions, we design a hierarchical interaction featurerepresentation so that high-level features capture the overall context of theinteractions, while low-level features focus on fine-grained details. Besides,we propose a coarse-to-fine interaction reasoning module that leverages bothspatial and frequency perspectives to efficiently utilize hierarchicalfeatures, thereby enhancing the accuracy of motion predictions. Our methodachieves state-of-the-art performance across four public datasets. Code will bereleased when this paper is published.</description>
      <author>example@mail.com (Caiyi Sun, Yujing Sun, Xiao Han, Zemin Yang, Jiawei Liu, Xinge Zhu, Siu Ming Yiu, Yuexin Ma)</author>
      <guid isPermaLink="false">2506.03753v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Safety of Foundation Models for Visual Navigation through Collision Avoidance via Repulsive Estimation</title>
      <link>http://arxiv.org/abs/2506.03834v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CARE的模块，用于通过排斥力估计进行碰撞避免，以提高基于视觉的导航系统的安全性，无需额外的距离传感器或对预训练模型的微调。&lt;h4&gt;背景&lt;/h4&gt;尽管使用RGB输入的最近的基础模型表现出强大的性能，但它们往往在未见过的物体或摄像头参数（例如视场、姿态或焦距）变化的分布外（OOD）环境中无法泛化。没有微调，这些模型可能生成不安全的轨迹，导致碰撞，需要昂贵的数据收集和重新训练。&lt;h4&gt;目的&lt;/h4&gt;CARE旨在解决上述限制，通过无缝集成到任何基于RGB的导航系统中，并动态调整其输出轨迹，使用由单目深度图派生的排斥力矢量。&lt;h4&gt;方法&lt;/h4&gt;CARE与多个机器人平台上的最先进的基于视觉的导航模型相结合进行评估，通过将排斥力矢量与局部轨迹结合，以减少碰撞率。&lt;h4&gt;主要发现&lt;/h4&gt;CARE在减少碰撞率（高达100%）的同时，不会牺牲到达目标性能，并在探索任务中提高了无碰撞行程距离，最高可达10.7倍。&lt;h4&gt;结论&lt;/h4&gt;CARE模块能够有效提高基于视觉的导航系统的安全性，并在实际应用中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose CARE (Collision Avoidance via Repulsive Estimation), aplug-and-play module that enhances the safety of vision-based navigationwithout requiring additional range sensors or fine-tuning of pretrained models.While recent foundation models using only RGB inputs have shown strongperformance, they often fail to generalize in out-of-distribution (OOD)environments with unseen objects or variations in camera parameters (e.g.,field of view, pose, or focal length). Without fine-tuning, these models maygenerate unsafe trajectories that lead to collisions, requiring costly datacollection and retraining. CARE addresses this limitation by seamlesslyintegrating with any RGB-based navigation system that outputs localtrajectories, dynamically adjusting them using repulsive force vectors derivedfrom monocular depth maps. We evaluate CARE by combining it withstate-of-the-art vision-based navigation models across multiple robotplatforms. CARE consistently reduces collision rates (up to 100%) withoutsacrificing goal-reaching performance and improves collision-free traveldistance by up to 10.7x in exploration tasks.</description>
      <author>example@mail.com (Joonkyung Kim, Joonyeol Sim, Woojun Kim, Katia Sycara, Changjoo Nam)</author>
      <guid isPermaLink="false">2506.03834v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Trajectory Prediction Meets Large Language Models: A Survey</title>
      <link>http://arxiv.org/abs/2506.03408v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, GitHub:  https://github.com/colorfulfuture/Awesome-Trajectory-Motion-Prediction-Papers&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了将大型语言模型（LLMs）应用于轨迹预测的近期进展，并概述了这一新兴领域的五个研究方向。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在语义和推理能力方面的进步激发了将语言驱动技术融入轨迹预测的兴趣。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供对这一新兴领域的全面概述，并对相关方法进行分析。&lt;h4&gt;方法&lt;/h4&gt;将近期工作分为五个方向：语言建模范式下的轨迹预测、直接使用预训练语言模型的轨迹预测、语言引导的场景理解以进行轨迹预测、语言驱动的数据生成用于轨迹预测、基于语言的理由和可解释性用于轨迹预测。&lt;h4&gt;主要发现&lt;/h4&gt;对每个方向中的代表性方法进行了分析，突出了核心设计选择，并确定了开放性挑战。&lt;h4&gt;结论&lt;/h4&gt;该综述连接了自然语言处理和轨迹预测，提供了一个统一的角度，说明了语言如何丰富轨迹预测。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in large language models (LLMs) have sparked growing interest in integrating language-driven techniques into trajectory prediction. By leveraging their semantic and reasoning capabilities, LLMs are reshaping how autonomous systems perceive, model, and predict trajectories. This survey provides a comprehensive overview of this emerging field, categorizing recent work into five directions: (1) Trajectory prediction via language modeling paradigms, (2) Direct trajectory prediction with pretrained language models, (3) Language-guided scene understanding for trajectory prediction, (4) Language-driven data generation for trajectory prediction, (5) Language-based reasoning and interpretability for trajectory prediction. For each, we analyze representative methods, highlight core design choices, and identify open challenges. This survey bridges natural language processing and trajectory prediction, offering a unified perspective on how language can enrich trajectory prediction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in large language models (LLMs) have sparked growing interestin integrating language-driven techniques into trajectory prediction. Byleveraging their semantic and reasoning capabilities, LLMs are reshaping howautonomous systems perceive, model, and predict trajectories. This surveyprovides a comprehensive overview of this emerging field, categorizing recentwork into five directions: (1) Trajectory prediction via language modelingparadigms, (2) Direct trajectory prediction with pretrained language models,(3) Language-guided scene understanding for trajectory prediction, (4)Language-driven data generation for trajectory prediction, (5) Language-basedreasoning and interpretability for trajectory prediction. For each, we analyzerepresentative methods, highlight core design choices, and identify openchallenges. This survey bridges natural language processing and trajectoryprediction, offering a unified perspective on how language can enrichtrajectory prediction.</description>
      <author>example@mail.com (Yi Xu, Ruining Yang, Yitian Zhang, Yizhou Wang, Jianglin Lu, Mingyuan Zhang, Lili Su, Yun Fu)</author>
      <guid isPermaLink="false">2506.03408v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>TextAtari: 100K Frames Game Playing with Language Agents</title>
      <link>http://arxiv.org/abs/2506.04098v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  51 pages, 39 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了TextAtari，这是一个用于评估语言代理在非常长远的决策任务上的基准，这些任务可达100,000步。通过将经典Atari游戏的可视状态表示转换为丰富的文本描述，TextAtari创建了一个将顺序决策与自然语言处理相结合的挑战性测试平台。&lt;h4&gt;背景&lt;/h4&gt;TextAtari通过将游戏状态转换为文本，为长时决策任务提供了一种新的评估方法。&lt;h4&gt;目的&lt;/h4&gt;评估不同形式的先验知识对长时挑战中的表现的影响，并研究语义理解、指令理解和专家演示对代理决策的影响。&lt;h4&gt;方法&lt;/h4&gt;包括几乎100个不同的任务，使用无监督表示学习框架（AtariARI）将任务转换为文本。评估了三种开源大型语言模型（Qwen2.5-7B，Gemma-7B，和Llama3.1-8B）在三个代理框架（零样本、少样本思维链和反思推理）中的表现。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，在广泛的规划任务中，语言代理与人类玩家之间存在显著的性能差距，突显了在数千步的顺序推理、状态跟踪和战略规划方面的挑战。&lt;h4&gt;结论&lt;/h4&gt;TextAtari提供了标准化的评估协议、基线实现和促进语言模型与规划交叉领域研究进展的框架。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了TextAtari，这是一个用于评估语言代理在非常长远的决策任务上的基准，这些任务可达100,000步。通过将经典Atari游戏的可视状态表示翻译成丰富的文本描述，TextAtari创建了一个将顺序决策与自然语言处理相结合的挑战性测试平台。该基准包括近100个具有不同复杂度、动作空间和规划范围的独立任务，所有任务都通过一个无监督表示学习框架（AtariARI）转换为文本。我们评估了三种开源的大型语言模型（Qwen2.5-7B、Gemma-7B和Llama3.1-8B）在三个代理框架（零样本、少样本思维链和反思推理）中的表现，以评估不同形式的先验知识如何影响这些长时挑战的表现。四种场景——基础、隐蔽、手动增强和基于参考——研究了语义理解、指令理解和专家演示对代理决策的影响。我们的结果表明，在广泛的规划任务中，语言代理与人类玩家之间存在显著的性能差距，突显了在数万步的顺序推理、状态跟踪和战略规划方面的挑战。TextAtari提供了标准化的评估协议、基线实现，以及推进语言模型与规划交叉领域研究的框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Lww007/Text-Atari-Agents&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present TextAtari, a benchmark for evaluating language agents on verylong-horizon decision-making tasks spanning up to 100,000 steps. By translatingthe visual state representations of classic Atari games into rich textualdescriptions, TextAtari creates a challenging test bed that bridges sequentialdecision-making with natural language processing. The benchmark includes nearly100 distinct tasks with varying complexity, action spaces, and planninghorizons, all rendered as text through an unsupervised representation learningframework (AtariARI). We evaluate three open-source large language models(Qwen2.5-7B, Gemma-7B, and Llama3.1-8B) across three agent frameworks(zero-shot, few-shot chain-of-thought, and reflection reasoning) to assess howdifferent forms of prior knowledge affect performance on these long-horizonchallenges. Four scenarios-Basic, Obscured, Manual Augmentation, andReference-based-investigate the impact of semantic understanding, instructioncomprehension, and expert demonstrations on agent decision-making. Our resultsreveal significant performance gaps between language agents and human playersin extensive planning tasks, highlighting challenges in sequential reasoning,state tracking, and strategic planning across tens of thousands of steps.TextAtari provides standardized evaluation protocols, baseline implementations,and a framework for advancing research at the intersection of language modelsand planning.</description>
      <author>example@mail.com (Wenhao Li, Wenwu Li, Chuyun Shen, Junjie Sheng, Zixiao Huang, Di Wu, Yun Hua, Wei Yin, Xiangfeng Wang, Hongyuan Zha, Bo Jin)</author>
      <guid isPermaLink="false">2506.04098v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Causality-Aware Contrastive Learning for Robust Multivariate Time-Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2506.03964v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CAROTS的新颖的多变量时间序列异常检测（MTSAD）方法，该方法结合了因果关系的概念，通过对比学习来提高异常检测的鲁棒性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;在多变量时间序列异常检测中，利用变量之间的因果关系是一个有前景的研究方向，但目前尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的MTSAD方法，通过结合因果关系来提高异常检测的性能。&lt;h4&gt;方法&lt;/h4&gt;CAROTS方法包括两个数据增强器，用于生成保持因果性和破坏因果性的样本，分别对应正常变化和合成异常。使用这些样本进行对比学习，训练一个编码器，其潜在空间根据因果关系区分正常和异常样本。此外，CAROTS引入了一种相似性过滤的单类对比损失，鼓励对比学习过程逐渐包含更多具有共同因果关系的语义多样性样本。&lt;h4&gt;主要发现&lt;/h4&gt;在五个真实世界和两个合成数据集上的广泛实验表明，因果关系的集成赋予了CAROTS改进的MTSAD能力。&lt;h4&gt;结论&lt;/h4&gt;CAROTS是一种有效且鲁棒的多变量时间序列异常检测方法，其代码可在GitHub上找到。&lt;h4&gt;翻译&lt;/h4&gt;摘要：利用多变量时间序列中变量间的复杂因果关系为更鲁棒和可靠的多变量时间序列异常检测（MTSAD）提供了一条有希望的研究途径，但这一领域的研究仍处于起步阶段。本文提出了一种名为CAROTS的新颖的MTSAD方法，该方法将因果关系的概念融入对比学习中。CAROTS采用两个数据增强器来获取保持因果性和破坏因果性的样本，分别作为正常变化和合成异常的广泛范围。使用保持因果性和破坏因果性的样本作为正样本和负样本，CAROTS执行对比学习以训练一个编码器，其潜在空间根据因果关系区分正常和异常样本。此外，CAROTS引入了一种相似性过滤的单类对比损失，鼓励对比学习过程逐渐包含更多具有共同因果关系的语义多样性样本。在五个真实世界和两个合成数据集上的广泛实验验证了因果关系的集成赋予了CAROTS改进的MTSAD能力。代码可在https://github.com/kimanki/CAROTS上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Utilizing the complex inter-variable causal relationships within multivariatetime-series provides a promising avenue toward more robust and reliablemultivariate time-series anomaly detection (MTSAD) but remains an underexploredarea of research. This paper proposes Causality-Aware contrastive learning forRObust multivariate Time-Series (CAROTS), a novel MTSAD pipeline thatincorporates the notion of causality into contrastive learning. CAROTS employstwo data augmentors to obtain causality-preserving and -disturbing samples thatserve as a wide range of normal variations and synthetic anomalies,respectively. With causality-preserving and -disturbing samples as positivesand negatives, CAROTS performs contrastive learning to train an encoder whoselatent space separates normal and abnormal samples based on causality.Moreover, CAROTS introduces a similarity-filtered one-class contrastive lossthat encourages the contrastive learning process to gradually incorporate moresemantically diverse samples with common causal relationships. Extensiveexperiments on five real-world and two synthetic datasets validate that theintegration of causal relationships endows CAROTS with improved MTSADcapabilities. The code is available at https://github.com/kimanki/CAROTS.</description>
      <author>example@mail.com (HyunGi Kim, Jisoo Mok, Dongjun Lee, Jaihyun Lew, Sungjae Kim, Sungroh Yoon)</author>
      <guid isPermaLink="false">2506.03964v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Seeing in the Dark: Benchmarking Egocentric 3D Vision with the Oxford Day-and-Night Dataset</title>
      <link>http://arxiv.org/abs/2506.04224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://oxdan.active.vision/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Oxford Day-and-Night，这是一个用于挑战性光照条件下进行新颖视图合成（NVS）和视觉重定位的大规模自主体数据集。&lt;h4&gt;背景&lt;/h4&gt;现有的数据集通常缺乏关键特征组合，如地面真实3D几何、广泛的照明变化和完整的6自由度运动。&lt;h4&gt;目的&lt;/h4&gt;Oxford Day-and-Night通过利用Meta ARIA眼镜捕获自主体视频，并应用多会话SLAM来估计相机姿态、重建3D点云和对齐在不同照明条件下捕获的序列，以解决这些差距。&lt;h4&gt;方法&lt;/h4&gt;该数据集跨越超过30公里的记录轨迹，覆盖了40,000平方米的区域，支持两个核心基准测试：NVS和重定位。&lt;h4&gt;主要发现&lt;/h4&gt;该数据集为自主体3D视觉研究提供了一个丰富的基础，并提供了评估模型在现实和多样化环境中的独特平台。&lt;h4&gt;结论&lt;/h4&gt;Oxford Day-and-Night是一个重要的数据集，为NVS和视觉重定位研究提供了新的资源，有助于推动相关技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Oxford Day-and-Night, a large-scale, egocentric dataset fornovel view synthesis (NVS) and visual relocalisation under challenging lightingconditions. Existing datasets often lack crucial combinations of features suchas ground-truth 3D geometry, wide-ranging lighting variation, and full 6DoFmotion. Oxford Day-and-Night addresses these gaps by leveraging Meta ARIAglasses to capture egocentric video and applying multi-session SLAM to estimatecamera poses, reconstruct 3D point clouds, and align sequences captured undervarying lighting conditions, including both day and night. The dataset spansover 30 $\mathrm{km}$ of recorded trajectories and covers an area of 40,000$\mathrm{m}^2$, offering a rich foundation for egocentric 3D vision research.It supports two core benchmarks, NVS and relocalisation, providing a uniqueplatform for evaluating models in realistic and diverse environments.</description>
      <author>example@mail.com (Zirui Wang, Wenjing Bian, Xinghui Li, Yifu Tao, Jianeng Wang, Maurice Fallon, Victor Adrian Prisacariu)</author>
      <guid isPermaLink="false">2506.04224v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>StARS DCM: A Sleep Stage-Decoding Forehead EEG Patch for Real-time Modulation of Sleep Physiology</title>
      <link>http://arxiv.org/abs/2506.03442v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;StARS是一个模块化的软硬件平台，用于实时睡眠监测和干预。&lt;h4&gt;背景&lt;/h4&gt;StARS平台利用DCM生物信号设备和ezmsg实时软件框架。&lt;h4&gt;目的&lt;/h4&gt;提供实时睡眠监测和干预的解决方案。&lt;h4&gt;方法&lt;/h4&gt;StARS捕捉电生理信号（EEG、EMG、EOG），并使用高级神经网络模型和迁移学习进行睡眠阶段解码，支持闭环听觉刺激和动态热调节等干预措施。&lt;h4&gt;主要发现&lt;/h4&gt;StARS可以配置轻量级的EEG额头贴片或智能戒指等可穿戴传感器，提供灵活、低负担的解决方案。&lt;h4&gt;结论&lt;/h4&gt;StARS平台进一步促进了可定制EEG设备的发展。&lt;h4&gt;翻译&lt;/h4&gt;The System to Augment Restorative Sleep (StARS) is a modular hardware/software platform designed for real-time sleep monitoring and intervention.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The System to Augment Restorative Sleep (StARS) is a modularhardware/software platform designed for real-time sleep monitoring andintervention. Utilizing the compact DCM biosignal device, StARS captureselectrophysiological signals (EEG, EMG, EOG) and synchronizes sensor data usingthe ezmsg real-time software framework. StARS supports interventions such asclosed-loop auditory stimulation and dynamic thermal modulation guided bysleep-stage decoding via advanced neural network models and transfer learning.Configurable with a lightweight EEG forehead patch or wearable sensors likesmart rings, StARS offers flexible, low-burden solutions for EEG, BCI, andsleep-enhancement research and applications. The open-source DCM patch furtherenables customizable EEG device development.</description>
      <author>example@mail.com (William G. Coon, Preston Peranich, Griffin Milsap)</author>
      <guid isPermaLink="false">2506.03442v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Frame-Level Real-Time Assessment of Stroke Rehabilitation Exercises from Video-Level Labeled Data: Task-Specific vs. Foundation Models</title>
      <link>http://arxiv.org/abs/2506.03752v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种框架，用于从视频级标注中学习对个体帧进行分类，以实时评估康复训练中的补偿运动。&lt;h4&gt;背景&lt;/h4&gt;随着中风康复需求的增加，对支持自主锻炼的解决方案的需求也在增加。虚拟教练可以从视频数据中提供实时锻炼反馈，帮助患者改善运动功能并保持参与度。&lt;h4&gt;目的&lt;/h4&gt;减少对实时运动分析系统帧级标注的需求，这些标注既耗时又昂贵。&lt;h4&gt;方法&lt;/h4&gt;使用基于梯度的技术和伪标签选择方法创建帧级伪标签以训练帧级分类器。利用预训练的任务特定模型（ActionTransformer，SkateFormer）和基础模型（MOMENT）生成伪标签，以提高对新患者的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;在SERE数据集上，MOMENT在视频级评估中取得了更好的结果（AUC = 73%），优于基线LSTM（AUC = 58%）。Action Transformer结合集成梯度技术，在帧级评估中取得了更好的结果（AUC = 72%），优于使用地面真实帧级标注训练的基线（AUC = 69%）。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法与预训练模型相结合，增强了模型的泛化能力，并简化了对新患者的定制，减少了数据标注的需求。&lt;h4&gt;翻译&lt;/h4&gt;摘要：中风康复需求的增长增加了对支持自主锻炼的解决方案的需求。虚拟教练可以从视频数据中提供实时锻炼反馈，帮助患者改善运动功能并保持参与度。然而，训练实时运动分析系统需要帧级标注，这既耗时又昂贵。在本研究中，我们提出了一种框架，该框架学习从视频级标注中分类个体帧，以实时评估康复训练中的补偿运动。我们使用基于梯度的技术和伪标签选择方法创建帧级伪标签以训练帧级分类器。我们利用预训练的任务特定模型——ActionTransformer，SkateFormer——和基础模型——MOMENT——生成伪标签，旨在提高对新患者的泛化能力。为了验证该方法，我们使用了SERE数据集，其中包括18名中风后患者进行五种康复锻炼的补偿运动标注。MOMENT在视频级评估中取得了更好的结果（AUC = 73%），优于基线LSTM（AUC = 58%）。Action Transformer结合集成梯度技术，在帧级评估中取得了更好的结果（AUC = 72%），优于使用地面真实帧级标注训练的基线（AUC = 69%）。我们表明，我们提出的方法与预训练模型相结合，增强了模型的泛化能力，并简化了对新患者的定制，减少了数据标注的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing demands of stroke rehabilitation have increased the need forsolutions to support autonomous exercising. Virtual coaches can providereal-time exercise feedback from video data, helping patients improve motorfunction and keep engagement. However, training real-time motion analysissystems demands frame-level annotations, which are time-consuming and costly toobtain. In this work, we present a framework that learns to classify individualframes from video-level annotations for real-time assessment of compensatorymotions in rehabilitation exercises. We use a gradient-based technique and apseudo-label selection method to create frame-level pseudo-labels for traininga frame-level classifier. We leverage pre-trained task-specific models - ActionTransformer, SkateFormer - and a foundation model - MOMENT - for pseudo-labelgeneration, aiming to improve generalization to new patients. To validate theapproach, we use the \textit{SERE} dataset with 18 post-stroke patientsperforming five rehabilitation exercises annotated on compensatory motions.MOMENT achieves better video-level assessment results (AUC = $73\%$),outperforming the baseline LSTM (AUC = $58\%$). The Action Transformer, withthe Integrated Gradient technique, leads to better outcomes (AUC = $72\%$) forframe-level assessment, outperforming the baseline trained with ground truthframe-level labeling (AUC = $69\%$). We show that our proposed approach withpre-trained models enhances model generalization ability and facilitates thecustomization to new patients, reducing the demands of data labeling.</description>
      <author>example@mail.com (Gonçalo Mesquita, Ana Rita Cóias, Artur Dubrawski, Alexandre Bernardino)</author>
      <guid isPermaLink="false">2506.03752v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Resource Allocation in Multi-Channel Wireless Networks</title>
      <link>http://arxiv.org/abs/2506.03813v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为eWMMSE的增强WMMSE算法，用于解决多信道无线网络中的联合信道和功率分配问题。通过引入基于图神经网络的JCPGNN-M解决方案，降低了迭代优化计算复杂度，并实现了多信道分配。该方法结合拉格朗日框架和图神经网络，提高了数据速率，降低了推理时间，并适用于大规模网络。&lt;h4&gt;背景&lt;/h4&gt;随着移动设备数量的增加，干扰成为无线网络数据速率提升的主要瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的方法来解决多信道无线网络中的联合信道和功率分配问题。&lt;h4&gt;方法&lt;/h4&gt;1. 提出eWMMSE算法；2. 引入JCPGNN-M，基于图神经网络实现多信道分配；3. 使用拉格朗日框架系统性地施加总功率约束；4. 结合拉格朗日框架和图神经网络，迭代更新拉格朗日乘数和资源分配方案。&lt;h4&gt;主要发现&lt;/h4&gt;JCPGNN-M比eWMMSE实现了更好的数据速率，且推理时间更低，并且能够很好地推广到更大的网络。&lt;h4&gt;结论&lt;/h4&gt;JCPGNN-M是一种有效解决多信道无线网络中JCPA问题的方法，具有较好的性能和适用性。&lt;h4&gt;翻译&lt;/h4&gt;As the number of mobile devices continues to grow, interference has become amajor bottleneck in improving data rates in wireless networks. Efficient jointchannel and power allocation (JCPA) is crucial for managing interference. Inthis paper, we first propose an enhanced WMMSE (eWMMSE) algorithm to solve theJCPA problem in multi-channel wireless networks. To reduce the computationalcomplexity of iterative optimization, we further introduce JCPGNN-M, a graphneural network-based solution that enables simultaneous multi-channelallocation for each user. We reformulate the problem as a Lagrangian function,which allows us to enforce the total power constraints systematically. Oursolution involves combining this Lagrangian framework with GNNs and iterativelyupdating the Lagrange multipliers and resource allocation scheme. Unlikeexisting GNN-based methods that limit each user to a single channel, JCPGNN-Msupports efficient spectrum reuse and scales well in dense network scenarios.Simulation results show that JCPGNN-M achieves better data rate compared toeWMMSE. Meanwhile, the inference time of JCPGNN-M is much lower than eWMMS, andit can generalize well to larger networks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the number of mobile devices continues to grow, interference has become amajor bottleneck in improving data rates in wireless networks. Efficient jointchannel and power allocation (JCPA) is crucial for managing interference. Inthis paper, we first propose an enhanced WMMSE (eWMMSE) algorithm to solve theJCPA problem in multi-channel wireless networks. To reduce the computationalcomplexity of iterative optimization, we further introduce JCPGNN-M, a graphneural network-based solution that enables simultaneous multi-channelallocation for each user. We reformulate the problem as a Lagrangian function,which allows us to enforce the total power constraints systematically. Oursolution involves combining this Lagrangian framework with GNNs and iterativelyupdating the Lagrange multipliers and resource allocation scheme. Unlikeexisting GNN-based methods that limit each user to a single channel, JCPGNN-Msupports efficient spectrum reuse and scales well in dense network scenarios.Simulation results show that JCPGNN-M achieves better data rate compared toeWMMSE. Meanwhile, the inference time of JCPGNN-M is much lower than eWMMS, andit can generalize well to larger networks.</description>
      <author>example@mail.com (Lili Chen, Changyang She, Jingge Zhu, Jamie Evans)</author>
      <guid isPermaLink="false">2506.03813v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>BiXFormer: A Robust Framework for Maximizing Modality Effectiveness in Multi-Modal Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2506.03675v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;利用多模态数据通过提供互补的语义和几何信息来增强场景理解。&lt;h4&gt;背景&lt;/h4&gt;现有的方法将来自多个模态的特征融合或提炼知识到一个统一表示中，虽然提高了鲁棒性，但限制了每个模态在不同情况下充分利用其优势的能力。&lt;h4&gt;目的&lt;/h4&gt;将多模态语义分割重新定义为掩码级别的分类任务，并提出BiXFormer模型，以集成统一模态匹配（UMM）和跨模态对齐（CMA）来最大化模态的有效性并处理缺失模态。&lt;h4&gt;方法&lt;/h4&gt;BiXFormer首先将多模态输入分类为RGB和X（X代表任何非RGB模态，如深度），允许对每个模态进行单独处理。UMM包括模态无关匹配（MAM）和互补匹配（CM），MAM对来自所有模态的特征进行标签分配而不考虑模态差异，利用每个模态的优势。CM随后将未匹配的标签重新分配给各自模态中剩余未分配的特征，确保每个可用的模态都对最终预测做出贡献，并减轻缺失模态的影响。CMA通过将CM中分配的较弱的查询与MAM中最佳匹配的查询对齐，进一步促进UMM。&lt;h4&gt;主要发现&lt;/h4&gt;在合成和真实世界的多模态基准测试中，实验证明了该方法的有效性，在mIoU方面比现有技术提高了+2.75%和+22.74%。&lt;h4&gt;结论&lt;/h4&gt;BiXFormer通过优化多模态信息融合和缺失模态处理，显著提高了多模态语义分割的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Utilizing multi-modal data enhances scene understanding by providingcomplementary semantic and geometric information. Existing methods fusefeatures or distill knowledge from multiple modalities into a unifiedrepresentation, improving robustness but restricting each modality's ability tofully leverage its strengths in different situations. We reformulatemulti-modal semantic segmentation as a mask-level classification task andpropose BiXFormer, which integrates Unified Modality Matching (UMM) and CrossModality Alignment (CMA) to maximize modality effectiveness and handle missingmodalities. Specifically, BiXFormer first categorizes multi-modal inputs intoRGB and X, where X represents any non-RGB modalities, e.g., depth, allowingseparate processing for each. This design leverages the well-establishedpretraining for RGB, while addressing the relative lack of attention to Xmodalities. Then, we propose UMM, which includes Modality Agnostic Matching(MAM) and Complementary Matching (CM). MAM assigns labels to features from allmodalities without considering modality differences, leveraging each modality'sstrengths. CM then reassigns unmatched labels to remaining unassigned featureswithin their respective modalities, ensuring that each available modalitycontributes to the final prediction and mitigating the impact of missingmodalities. Moreover, to further facilitate UMM, we introduce CMA, whichenhances the weaker queries assigned in CM by aligning them with optimallymatched queries from MAM. Experiments on both synthetic and real-worldmulti-modal benchmarks demonstrate the effectiveness of our method, achievingsignificant improvements in mIoU of +2.75% and +22.74% over the prior arts.</description>
      <author>example@mail.com (Jialei Chen, Xu Zheng, Danda Pani Paudel, Luc Van Gool, Hiroshi Murase, Daisuke Deguchi)</author>
      <guid isPermaLink="false">2506.03675v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Quality Assessment Using the Perceptual Clustering Weighted Graph (PCW-Graph) and Attention Fusion Network</title>
      <link>http://arxiv.org/abs/2506.04081v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;No-Reference Point Cloud Quality Assessment (NR-PCQA)是评估3D内容的关键，特别是在没有参考模型的真实世界应用中。&lt;h4&gt;背景&lt;/h4&gt;NR-PCQA对于在没有参考模型的情况下评估3D内容非常重要。&lt;h4&gt;目的&lt;/h4&gt;NR-PCQA的目的是评估3D内容的质量。&lt;h4&gt;方法&lt;/h4&gt;NR-PCQA是一种无需参考模型的质量评估方法。&lt;h4&gt;主要发现&lt;/h4&gt;摘要中没有提供具体的研究发现。&lt;h4&gt;结论&lt;/h4&gt;摘要中没有提供具体的结论。&lt;h4&gt;翻译&lt;/h4&gt;No-Reference Point Cloud Quality Assessment (NR-PCQA) is critical for evaluating 3D content in real-world applications where reference models are unavailable.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; No-Reference Point Cloud Quality Assessment (NR-PCQA) is critical forevaluating 3D content in real-world applications where reference models areunavailable.</description>
      <author>example@mail.com (Abdelouahed Laazoufi, Mohammed El Hassouni, Hocine Cherifi)</author>
      <guid isPermaLink="false">2506.04081v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives</title>
      <link>http://arxiv.org/abs/2506.03709v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Workshop on Foundation Models Meet Embodied Agents at  CVPR 2025 (Non-archival Track)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究开放词汇语义分割（OVSS）在现实世界应用中的挑战，提出AetherVision-Bench基准，评估多角度分割性能，并探索零样本迁移模型的关键影响因素。&lt;h4&gt;背景&lt;/h4&gt;Open-vocabulary semantic segmentation (OVSS)面临跨领域泛化挑战，影响其实际应用效果。&lt;h4&gt;目的&lt;/h4&gt;评估多角度分割性能，探索零样本迁移模型的关键影响因素，建立稳健性基准。&lt;h4&gt;方法&lt;/h4&gt;提出AetherVision-Bench基准，评估state-of-the-art OVSS模型，研究关键因素。&lt;h4&gt;主要发现&lt;/h4&gt;AetherVision-Bench基准有助于广泛评估不同视角和传感器模态的性能，对零样本迁移模型性能有重要影响。&lt;h4&gt;结论&lt;/h4&gt;研究为未来OVSS研究提供有价值见解和基础。&lt;h4&gt;翻译&lt;/h4&gt;Open-vocabulary semantic segmentation (OVSS) involves assigning labels to each pixel in an image based on textual descriptions, leveraging world models like CLIP. However, they encounter significant challenges in cross-domain generalization, hindering their practical efficacy in real-world applications. Embodied AI systems are transforming autonomous navigation for ground vehicles and drones by enhancing their perception abilities, and in this study, we present AetherVision-Bench, a benchmark for multi-angle segmentation across aerial, and ground perspectives, which facilitates an extensive evaluation of performance across different viewing angles and sensor modalities. We assess state-of-the-art OVSS models on the proposed benchmark and investigate the key factors that impact the performance of zero-shot transfer models. Our work pioneers the creation of a robustness benchmark, offering valuable insights and establishing a foundation for future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-vocabulary semantic segmentation (OVSS) involves assigning labels toeach pixel in an image based on textual descriptions, leveraging world modelslike CLIP. However, they encounter significant challenges in cross-domaingeneralization, hindering their practical efficacy in real-world applications.Embodied AI systems are transforming autonomous navigation for ground vehiclesand drones by enhancing their perception abilities, and in this study, wepresent AetherVision-Bench, a benchmark for multi-angle segmentation acrossaerial, and ground perspectives, which facilitates an extensive evaluation ofperformance across different viewing angles and sensor modalities. We assessstate-of-the-art OVSS models on the proposed benchmark and investigate the keyfactors that impact the performance of zero-shot transfer models. Our workpioneers the creation of a robustness benchmark, offering valuable insights andestablishing a foundation for future research.</description>
      <author>example@mail.com (Aniruddh Sikdar, Aditya Gandhamal, Suresh Sundaram)</author>
      <guid isPermaLink="false">2506.03709v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>On Support Samples of Next Word Prediction</title>
      <link>http://arxiv.org/abs/2506.04047v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACL2025(Main Conference)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了语言模型中的数据中心化可解释性，重点关注下一词预测任务，揭示了支持样本和非支持样本在模型决策中的不同作用。&lt;h4&gt;背景&lt;/h4&gt;语言模型在复杂决策中表现出色，但其决策背后的原因理解起来仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;探究语言模型中数据中心化可解释性，特别是针对下一词预测任务。&lt;h4&gt;方法&lt;/h4&gt;利用代表定理，识别出两种支持样本类型，并分析其在模型中的作用。&lt;h4&gt;主要发现&lt;/h4&gt;支持样本是非支持样本的固有属性，甚至在训练开始之前就可以预测。非支持样本在直接预测中影响力较小，但在防止过拟合和塑造泛化及表示学习方面起着关键作用。非支持样本的重要性在更深层次中增加，表明它们在中间表示形成中起着重要作用。&lt;h4&gt;结论&lt;/h4&gt;这些发现揭示了数据和模型决策之间的相互作用，为理解语言模型的行为和可解释性提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates data-centric interpretability in language models, focusing on the next-word prediction task. Using representer theorem, we identify two types of support samples - those that either promote or deter specific predictions. Our findings reveal that being a support sample is an intrinsic property, predictable even before training begins. Additionally, while non-support samples are less influential in direct predictions, they play a critical role in preventing overfitting and shaping generalization and representation learning. Notably, the importance of non-support samples increases in deeper layers, suggesting their significant role in intermediate representation formation. These insights shed light on the interplay between data and model decisions, offering a new dimension to understanding language model behavior and interpretability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Language models excel in various tasks by making complex decisions, yetunderstanding the rationale behind these decisions remains a challenge. Thispaper investigates \emph{data-centric interpretability} in language models,focusing on the next-word prediction task. Using representer theorem, weidentify two types of \emph{support samples}-those that either promote or deterspecific predictions. Our findings reveal that being a support sample is anintrinsic property, predictable even before training begins. Additionally,while non-support samples are less influential in direct predictions, they playa critical role in preventing overfitting and shaping generalization andrepresentation learning. Notably, the importance of non-support samplesincreases in deeper layers, suggesting their significant role in intermediaterepresentation formation.These insights shed light on the interplay betweendata and model decisions, offering a new dimension to understanding languagemodel behavior and interpretability.</description>
      <author>example@mail.com (Yuqian Li, Yupei Du, Yufang Liu, Feifei Feng, Mou Xiao Feng, Yuanbin Wu)</author>
      <guid isPermaLink="false">2506.04047v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Vegetation Index-Based Unsupervised Crop Stress Detection via Eigenvector-Guided Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.03394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;EigenCL是一种基于生物物理原理的无监督对比学习框架，用于作物早期压力检测，提高了检测准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;早期检测作物压力对于减少产量损失和及时干预精准农业至关重要。传统方法使用NDRE检测压力存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出EigenCL框架，实现作物压力的早期检测。&lt;h4&gt;方法&lt;/h4&gt;利用超过10,000个Sentinel-2NDRE图像块，构建每个块的五点NDRE时间序列，并推导出径向基函数（RBF）相似度矩阵。使用主要特征向量（解释76%的方差）定义压力感知相似度进行对比嵌入学习。&lt;h4&gt;主要发现&lt;/h4&gt;EigenCL通过生物相似的应力轨迹将嵌入拉近，将差异较大的嵌入推开，形成的嵌入聚类具有生理意义，检测准确率高达76%，比传统NDRE阈值提前12天。&lt;h4&gt;结论&lt;/h4&gt;EigenCL是一种无标签、可扩展的早期压力检测方法，与植物生理学相符合，适用于数据稀缺的农业环境。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Early detection of crop stress is vital for minimizing yield loss and enabling timely intervention in precision agriculture. Traditional approaches using NDRE often detect stress only after visible symptoms appear or require labeled datasets, limiting scalability. This study introduces EigenCL, a novel unsupervised contrastive learning framework guided by temporal NDRE dynamics and biologically grounded eigen decomposition. Using over 10,000 Sentinel-2NDRE image patches from drought-affected Iowa cornfields, we constructed five-point NDRE time series per patch and derived an RBF similarity matrix. The principal eigenvector explaining 76% of the variance and strongly correlated (r= 0.95) with raw NDRE values was used to define stress-aware similarity for contrastive embedding learning. Unlike existing methods that rely on visual augmentations, EigenCL pulls embeddings together based on biologically similar stress trajectories and pushes apart divergent ones. The learned embeddings formed physiologically meaningful clusters, achieving superior clustering metrics (Silhouette: 0.748, DBI: 0.35) and enabling 76% early stress detection up to 12 days before conventional NDRE thresholds. Downstream classification yielded 95% k-NN and 91% logistic regression accuracy. Validation on an independent 2023 Nebraska dataset confirmed generalizability without retraining. EigenCL offers a label-free, scalable approach for early stress detection that aligns with underlying plant physiology and is suitable for real-world deployment in data-scarce agricultural environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early detection of crop stress is vital for minimizing yield loss andenabling timely intervention in precision agriculture. Traditional approachesusing NDRE often detect stress only after visible symptoms appear or requirelabeled datasets, limiting scalability. This study introduces EigenCL, a novelunsupervised contrastive learning framework guided by temporal NDRE dynamicsand biologically grounded eigen decomposition. Using over 10,000 Sentinel-2NDRE image patches from drought-affected Iowa cornfields, we constructedfive-point NDRE time series per patch and derived an RBF similarity matrix. Theprincipal eigenvector explaining 76% of the variance and strongly correlated (r= 0.95) with raw NDRE values was used to define stress-aware similarity forcontrastive embedding learning. Unlike existing methods that rely on visualaugmentations, EigenCL pulls embeddings together based on biologically similarstress trajectories and pushes apart divergent ones. The learned embeddingsformed physiologically meaningful clusters, achieving superior clusteringmetrics (Silhouette: 0.748, DBI: 0.35) and enabling 76% early stress detectionup to 12 days before conventional NDRE thresholds. Downstream classificationyielded 95% k-NN and 91% logistic regression accuracy. Validation on anindependent 2023 Nebraska dataset confirmed generalizability withoutretraining. EigenCL offers a label-free, scalable approach for early stressdetection that aligns with underlying plant physiology and is suitable forreal-world deployment in data-scarce agricultural environments.</description>
      <author>example@mail.com (Shafqaat Ahmad)</author>
      <guid isPermaLink="false">2506.03394v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Semiconductor SEM Image Defect Classification Using Supervised and Semi-Supervised Learning with Vision Transformers</title>
      <link>http://arxiv.org/abs/2506.03345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at 36th Annual SEMI Advanced Semiconductor Manufacturing  Conference (ASMC) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉Transformer（ViT）神经网络自动分类扫描电子显微镜（SEM）图像中晶圆缺陷的方法，旨在提高分类准确性和计算效率。&lt;h4&gt;背景&lt;/h4&gt;半导体工艺中的缺陷控制对于保持产量、降低生产成本和防止关键组件的时变失效至关重要。传统的基于电子束的图像检测方法在缺陷分类方面存在时间、劳动力和人类偏见等局限性。&lt;h4&gt;目的&lt;/h4&gt;提高晶圆缺陷的自动分类准确率，并实现高效计算。&lt;h4&gt;方法&lt;/h4&gt;在IBM Albany工厂的300mm晶圆半导体缺陷数据集上评估了所提出的方法，研究了DinoV2迁移学习和半监督学习在提高分类准确性和计算效率方面的潜力。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用少于15张图像每个缺陷类别的数据，实现了超过90%的分类准确率。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了所提出的框架可以应用于一个平台无关的内部分类工具，具有更快的周转时间和灵活性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：控制半导体工艺中的缺陷对于维持产量、降低生产成本和防止关键组件的时变失效至关重要。基于电子束的成像技术已被用作晶圆检测的工具，以检查缺陷。然而，对于这些纳米级缺陷的图像手动分类受到时间、劳动力和人类偏见等限制。近年来，深度学习计算机视觉算法在工业中的图像检测应用中显示出其有效性。本研究提出了应用视觉Transformer（ViT）神经网络自动分类扫描电子显微镜（SEM）图像中晶圆缺陷的方法。我们在IBM Albany工厂的300mm晶圆半导体缺陷数据集上评估了所提出的方法，研究了DinoV2迁移学习和半监督学习在提高分类准确率和计算效率方面的潜力。我们能够实现每个缺陷类别少于15张图像的分类准确率超过90%。我们的工作证明了将所提出的框架应用于平台无关的内部分类工具的潜力，具有更快的周转时间和灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ASMC64512.2025.11010396&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Controlling defects in semiconductor processes is important for maintainingyield, improving production cost, and preventing time-dependent criticalcomponent failures. Electron beam-based imaging has been used as a tool tosurvey wafers in the line and inspect for defects. However, manualclassification of images for these nano-scale defects is limited by time, laborconstraints, and human biases. In recent years, deep learning computer visionalgorithms have shown to be effective solutions for image-based inspectionapplications in industry. This work proposes application of vision transformer(ViT) neural networks for automatic defect classification (ADC) of scanningelectron microscope (SEM) images of wafer defects. We evaluated our proposedmethods on 300mm wafer semiconductor defect data from our fab in IBM Albany. Westudied 11 defect types from over 7400 total images and investigated thepotential of transfer learning of DinoV2 and semi-supervised learning forimproved classification accuracy and efficient computation. We were able toachieve classification accuracies of over 90% with less than 15 images perdefect class. Our work demonstrates the potential to apply the proposedframework for a platform agnostic in-house classification tool with fasterturnaround time and flexibility.</description>
      <author>example@mail.com (Chien-Fu, Huang, Katherine Sieg, Leonid Karlinksy, Nash Flores, Rebekah Sheraw, Xin Zhang)</author>
      <guid isPermaLink="false">2506.03345v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>MudiNet: Task-guided Disentangled Representation Learning for 5G Indoor Multipath-assisted Positioning</title>
      <link>http://arxiv.org/abs/2506.04024v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了5G通信系统中基于多径辅助定位（MAP）的方法，提出了一种新的任务引导解耦表示学习方法，以提高定位精度。&lt;h4&gt;背景&lt;/h4&gt;在5G通信系统中，多径分量（MPC）被视为有价值的信息，但现有研究往往将反射面视为理想反射面，而忽略了由漫反射器引起的难以区分的多径问题。&lt;h4&gt;目的&lt;/h4&gt;旨在通过研究漫反射器的统计分布特征，设计一种方法来直接将信道脉冲响应（CIR）映射到位置，同时减轻对定位精度贡献较小的成分（如漫反射多径）的不利影响。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于多时间信道脉冲响应（CIR）观测的任务引导解耦表示学习方法，利用全局特征提取架构和多层感知器（MLP）来提取与用户设备（UE）位置相关的时变特征。此外，应用基于潜在变量模型（LVM）的变分推理来分离CIR中的独立特征，并通过位置标签指导LVM表达对定位更有益的成分。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟结果表明，所提出的方法在定位精度方面优于传统的基于搜索的定位方法，并且对漫反射器引起的难以区分的多径具有更强的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高5G通信系统中的定位精度，并具有较强的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;In the fifth-generation communication system (5G), multipath-assisted positioning (MAP) has emerged as a promising approach. With the enhancement of signal resolution, multipath components (MPC) are no longer regarded as noise but rather as valuable information that can contribute to positioning. However, existing research often treats reflective surfaces as ideal reflectors, while being powerless in the face of indistinguishable multipath caused by diffusely reflecting surfaces. This study approaches diffusely reflecting surfaces from the perspective of uncertainty, investigating the statistical distribution characteristics of indoor diffuse and specular reflectors. Based on these insights, a task-guided disentangled representation learning method leveraging multi-time channel impulse response (CIR) observations is designed to directly map CIRs to positions, while mitigating the adverse effects of components that contribute minimally to localization accuracy (e.g., diffuse multipath). In this semi-supervised learning framework, a global feature extraction architecture based on self-attention is proposed to capture location-independent wireless environmental information, while an MLP is employed to extract the time-varying features related to user equipment (UE) positions. Variational inference based on a latent variable model (LVM) is applied to separate independent features within the CIR, with position labels guiding the LVM to express components more beneficial for localization. Additionally, we provide a feasibility proof for the separability of diffuse and specular environmental features in CIRs. Simulation results demonstrate that the proposed method achieves higher localization accuracy compared to conventional search-based localization methods, with enhanced robustness against indistinguishable multipath from diffusely reflecting surfaces.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the fifth-generation communication system (5G), multipath-assistedpositioning (MAP) has emerged as a promising approach. With the enhancement ofsignal resolution, multipath component (MPC) are no longer regarded as noisebut rather as valuable information that can contribute to positioning. However,existing research often treats reflective surfaces as ideal reflectors, whilebeing powerless in the face of indistinguishable multipath caused by diffusereflectors. This study approaches diffuse reflectors from the perspective ofuncertainty, investigating the statistical distribution characteristics ofindoor diffuse and specular reflectors. Based on these insights, a task-guideddisentangled representation learning method leveraging multi-time channelimpulse response (CIR) observations is designed to directly map CIRs topositions, while mitigating the adverse effects of components that contributeminimally to localization accuracy (e.g., diffuse multipath).In thissemi-supervised learning framework, a global feature extraction architecturebased on self-attention is proposed to capture location-independent wirelessenvironmental information, while an MLP is employed to extract the time-varyingfeatures related to user equipment (UE) positions. Variational inference basedon a latent variable model (LVM) is applied to separate independent featureswithin the CIR, with position labels guiding the LVM to express components morebeneficial for localization. Additionally, we provide a feasibility proof forthe separability of diffuse and specular environmental features in CIRs.Simulation results demonstrate that the proposed method achieves higherlocalization accuracy compared to conventional search-based localizationmethods, with enhanced robustness against indistinguishable multipath fromdiffuse reflectors.</description>
      <author>example@mail.com (Ye Tian, Xueting Xu, Ao Peng)</author>
      <guid isPermaLink="false">2506.04024v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Out-of-Distribution Graph Models Merging</title>
      <link>http://arxiv.org/abs/2506.03674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了跨域图模型合并的新问题，旨在构建一个通用的模型，该模型由在不同领域上预训练的多个图模型组成，这些模型之间存在分布差异。本文提出了一种图生成策略，实例化了多个域的混合分布，并通过MoE模块和掩码机制进行模型合并和微调，以实现通用适应。框架架构无关，无需任何源/目标域数据。理论和实验结果都证明了该方法在解决模型泛化问题上的有效性。&lt;h4&gt;背景&lt;/h4&gt;本文研究的背景是跨域图模型合并问题，该问题由于模型参数中隐含的领域不变知识的难以学习以及从可能异构的GNN主干网络中整合专长而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;本文的目的是构建一个通用的模型，该模型能够从多个在不同领域上预训练的图模型中学习，并解决分布差异的问题。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种图生成策略，用于实例化多个域的混合分布。然后，通过MoE模块和掩码机制合并和微调预训练的图模型，以实现通用适应。&lt;h4&gt;主要发现&lt;/h4&gt;本文的主要发现是提出的框架能够有效地解决模型泛化问题，并且该框架是架构无关的，无需任何源/目标域数据。&lt;h4&gt;结论&lt;/h4&gt;本文的结论是，所提出的方法在解决跨域图模型合并问题上是有效的，能够提高模型的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了跨域图模型合并的新问题，旨在构建一个通用的模型，该模型由在不同领域上预训练的多个图模型组成，这些模型之间存在分布差异。这一问题由于模型参数中隐含的领域不变知识的难以学习以及从可能异构的GNN主干网络中整合专长而具有挑战性。在本文中，我们提出了一种图生成策略，用于实例化多个域的混合分布。然后，我们通过MoE模块和掩码机制合并和微调预训练的图模型，以实现通用适应。我们的框架架构无关，可以无任何源/目标域数据运行。理论和实验结果都证明了我们方法在解决模型泛化问题上的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper studies a novel problem of out-of-distribution graph modelsmerging, which aims to construct a generalized model from multiple graph modelspre-trained on different domains with distribution discrepancy. This problem ischallenging because of the difficulty in learning domain-invariant knowledgeimplicitly in model parameters and consolidating expertise from potentiallyheterogeneous GNN backbones. In this work, we propose a graph generationstrategy that instantiates the mixture distribution of multiple domains. Then,we merge and fine-tune the pre-trained graph models via a MoE module and amasking mechanism for generalized adaptation. Our framework isarchitecture-agnostic and can operate without any source/target domain data.Both theoretical analysis and experimental results demonstrate theeffectiveness of our approach in addressing the model generalization problem.</description>
      <author>example@mail.com (Yidi Wang, Jiawei Gu, pei Xiaobing, Xubin Zheng, Xiao Luo, Pengyang Wang, Ziyue Qiao)</author>
      <guid isPermaLink="false">2506.03674v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Spatial Understanding from Videos: Structured Prompts Meet Simulation Data</title>
      <link>http://arxiv.org/abs/2506.03642v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一框架，用于增强预训练视觉语言模型（VLMs）的3D空间推理能力，解决了空间不确定性和数据稀缺性问题。&lt;h4&gt;背景&lt;/h4&gt;视觉空间理解是机器人导航和具身交互等下游任务的基础，但现有方法存在空间不确定性和数据稀缺性的限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需修改模型架构的方法，以增强预训练VLMs的3D空间推理能力。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了SpatialMind和ScanForgeQA。SpatialMind是一种结构化提示策略，将复杂场景和问题分解为可解释的推理步骤；ScanForgeQA是一个可扩展的问答数据集，通过自动化构建过程从多样化的3D模拟场景中构建，用于微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提示和微调策略在多个基准测试中均表现出有效性和结合效果，并为未来关于视觉空间理解的研究提供了启示。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架有效提升了预训练VLMs的3D空间推理能力，为视觉空间理解领域的研究提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual-spatial understanding, the ability to infer object relationships andlayouts from visual input, is fundamental to downstream tasks such as roboticnavigation and embodied interaction. However, existing methods face spatialuncertainty and data scarcity, limiting the 3D spatial reasoning capability ofpre-trained vision-language models (VLMs). To address these challenges, wepresent a unified framework for enhancing 3D spatial reasoning in pre-trainedVLMs without modifying their architecture. This framework combines SpatialMind,a structured prompting strategy that decomposes complex scenes and questionsinto interpretable reasoning steps, with ScanForgeQA, a scalablequestion-answering dataset built from diverse 3D simulation scenes through anautomated construction process designed for fine-tuning. Extensive experimentsacross multiple benchmarks demonstrate the individual and combinedeffectiveness of our prompting and fine-tuning strategies, and yield insightsthat may inspire future research on visual-spatial understanding.</description>
      <author>example@mail.com (Haoyu Zhang, Meng Liu, Zaijing Li, Haokun Wen, Weili Guan, Yaowei Wang, Liqiang Nie)</author>
      <guid isPermaLink="false">2506.03642v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>MMM4Rec: A Transfer-Efficient Framework for Multi-modal Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2506.02916v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MMM4Rec的多模态序列推荐框架，旨在解决传统多模态推荐方法在新领域适应时的高调优成本问题，提高了多模态推荐的准确性和迁移能力。&lt;h4&gt;背景&lt;/h4&gt;虽然可迁移的多模态推荐架构在性能上优于传统基于ID的方法，但在新领域适应时，由于优化要求和负迁移效应，现有方法需要大量调优，这成为部署的瓶颈。&lt;h4&gt;目的&lt;/h4&gt;降低在新领域适应时的调优成本，提高多模态推荐系统的准确性和迁移能力。&lt;h4&gt;方法&lt;/h4&gt;MMM4Rec通过结合状态空间对偶（SSD）的时间衰减特性和时间感知建模设计，动态地优先考虑关键模态信息，并通过约束的两阶段过程实现序列级跨模态对齐和时序融合。&lt;h4&gt;主要发现&lt;/h4&gt;MMM4Rec在保持语义一致性的同时抑制噪声传播，实现了快速调优收敛，与现有模型相比，在NDCG@10指标上提高了31.78%，平均收敛速度提高了10倍。&lt;h4&gt;结论&lt;/h4&gt;MMM4Rec在多模态推荐方面达到了最先进的性能，显著提高了推荐的准确性和迁移能力，为高效复用预训练模型提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential Recommendation (SR) systems model user preferences by analyzinginteraction histories. Although transferable multi-modal SR architecturesdemonstrate superior performance compared to traditional ID-based approaches,current methods incur substantial fine-tuning costs when adapting to newdomains due to complex optimization requirements and negative transfer effects- a significant deployment bottleneck that hinders engineers from efficientlyrepurposing pre-trained models for novel application scenarios with minimaltuning overhead. We propose MMM4Rec (Multi-Modal Mamba for SequentialRecommendation), a novel multi-modal SR framework that incorporates a dedicatedalgebraic constraint mechanism for efficient transfer learning. By combiningState Space Duality (SSD)'s temporal decay properties with a time-awaremodeling design, our model dynamically prioritizes key modality information,overcoming limitations of Transformer-based approaches. The frameworkimplements a constrained two-stage process: (1) sequence-level cross-modalalignment via shared projection matrices, followed by (2) temporal fusion usingour newly designed Cross-SSD module and dual-channel Fourier adaptivefiltering. This architecture maintains semantic consistency while suppressingnoise propagation.MMM4Rec achieves rapid fine-tuning convergence with simplecross-entropy loss, significantly improving multi-modal recommendation accuracywhile maintaining strong transferability. Extensive experiments demonstrateMMM4Rec's state-of-the-art performance, achieving the maximum 31.78% NDCG@10improvement over existing models and exhibiting 10 times faster averageconvergence speed when transferring to large-scale downstream datasets.</description>
      <author>example@mail.com (Hao Fan, Yanrong Hu, Kai Fang, Qingyang Liu, Hongjiu Liu)</author>
      <guid isPermaLink="false">2506.02916v2</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>EV-Flying: an Event-based Dataset for In-The-Wild Recognition of Flying Objects</title>
      <link>http://arxiv.org/abs/2506.04048v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用事件相机进行空中物体监测的潜力，旨在提高对小型飞行物体，如昆虫和无人机的识别效率。&lt;h4&gt;背景&lt;/h4&gt;传统的基于RGB的方法在处理尺度变化、运动模糊和高速物体运动等方面存在困难，特别是对于小型飞行物体。&lt;h4&gt;目的&lt;/h4&gt;探索事件相机在检测和识别飞行物体，尤其是可能不遵循短期和长期可预测模式的动物方面的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出EV-Flying，一个基于事件的飞行物体数据集，包含手动标注的鸟类、昆虫和无人机，具有时空边界框和轨迹标识。为了有效地处理异步事件流，采用受PointNet启发的轻量级架构的点云方法。&lt;h4&gt;主要发现&lt;/h4&gt;研究了使用基于事件表示的点云进行飞行物体分类。&lt;h4&gt;结论&lt;/h4&gt;所提出的 dataset 和方法为在现实场景中更有效地进行空中物体识别铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monitoring aerial objects is crucial for security, wildlife conservation, andenvironmental studies. Traditional RGB-based approaches struggle withchallenges such as scale variations, motion blur, and high-speed objectmovements, especially for small flying entities like insects and drones. Inthis work, we explore the potential of event-based vision for detecting andrecognizing flying objects, in particular animals that may not follow short andlong-term predictable patters. Event cameras offer high temporal resolution,low latency, and robustness to motion blur, making them well-suited for thistask. We introduce EV-Flying, an event-based dataset of flying objects,comprising manually annotated birds, insects and drones with spatio-temporalbounding boxes and track identities. To effectively process the asynchronousevent streams, we employ a point-based approach leveraging lightweightarchitectures inspired by PointNet. Our study investigates the classificationof flying objects using point cloud-based event representations. The proposeddataset and methodology pave the way for more efficient and reliable aerialobject recognition in real-world scenarios.</description>
      <author>example@mail.com (Gabriele Magrini, Federico Becattini, Giovanni Colombo, Pietro Pala)</author>
      <guid isPermaLink="false">2506.04048v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>CARL: Causality-guided Architecture Representation Learning for an Interpretable Performance Predictor</title>
      <link>http://arxiv.org/abs/2506.04001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CARL的因果引导架构表示学习方法，用于神经架构搜索（NAS）的性能预测，旨在解决现有预测器在学习有限训练样本和多样测试样本之间内在分布差异时的泛化问题。&lt;h4&gt;背景&lt;/h4&gt;性能预测器被认为是加速神经架构搜索（NAS）评估阶段的可行方法，但大多数现有预测器忽视了训练样本和测试样本之间的分布差异，导致学习到虚假相关性，泛化能力差。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，能够分离架构的临界（因果）和冗余（非因果）特征，以实现可泛化的架构性能预测。&lt;h4&gt;方法&lt;/h4&gt;CARL方法使用子结构提取器将输入架构在潜在空间中分解为临界和冗余子结构。然后，通过将临界表示与多种冗余表示配对，生成多个干预样本，以优先考虑临界特征。&lt;h4&gt;主要发现&lt;/h4&gt;在五个NAS搜索空间上的广泛实验表明，CARL在准确性和可解释性方面达到了最先进水平。例如，在CIFAR-10上使用DARTS时，CARL达到了97.67%的top-1准确率。&lt;h4&gt;结论&lt;/h4&gt;CARL方法能够有效地解决NAS中性能预测的泛化问题，并显著提高了预测的准确性和可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Performance predictors have emerged as a promising method to accelerate theevaluation stage of neural architecture search (NAS). These predictors estimatethe performance of unseen architectures by learning from the correlationbetween a small set of trained architectures and their performance. However,most existing predictors ignore the inherent distribution shift between limitedtraining samples and diverse test samples. Hence, they tend to learn spuriouscorrelations as shortcuts to predictions, leading to poor generalization. Toaddress this, we propose a Causality-guided Architecture RepresentationLearning (CARL) method aiming to separate critical (causal) and redundant(non-causal) features of architectures for generalizable architectureperformance prediction. Specifically, we employ a substructure extractor tosplit the input architecture into critical and redundant substructures in thelatent space. Then, we generate multiple interventional samples by pairingcritical representations with diverse redundant representations to prioritizecritical features. Extensive experiments on five NAS search spaces demonstratethe state-of-the-art accuracy and superior interpretability of CARL. Forinstance, CARL achieves 97.67% top-1 accuracy on CIFAR-10 using DARTS.</description>
      <author>example@mail.com (Han Ji, Yuqi Feng, Jiahao Fan, Yanan Sun)</author>
      <guid isPermaLink="false">2506.04001v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Analyzing Transformer Models and Knowledge Distillation Approaches for Image Captioning on Edge AI</title>
      <link>http://arxiv.org/abs/2506.03607v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在边缘设备上运行的基于Transformer的图像描述模型，以提高机器感知能力，改善自主机器人的场景理解，并协助工业检查。&lt;h4&gt;背景&lt;/h4&gt;边缘计算将处理能力分散到网络边缘，使得物联网应用能够实现实时的人工智能驱动决策。在工业自动化领域，如机器人和坚固的边缘人工智能，实时感知和智能对于自主操作至关重要。&lt;h4&gt;目的&lt;/h4&gt;针对边缘或物联网设备计算资源有限且对响应时间有严格要求的问题，本文旨在提出一种资源高效的Transformer模型，以加速推理同时保持模型性能。&lt;h4&gt;方法&lt;/h4&gt;通过评估资源高效的Transformer模型并应用知识蒸馏技术，研究在资源受限设备上的模型有效运行。&lt;h4&gt;主要发现&lt;/h4&gt;研究者展示了在边缘设备上运行的Transformer模型能够有效进行图像描述，同时通过知识蒸馏技术加速推理过程。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在保持模型性能的同时，能够在资源受限的设备上实现推理加速。&lt;h4&gt;翻译&lt;/h4&gt;摘要：边缘计算将处理能力分散到网络边缘，使得物联网应用能够实现实时的人工智能驱动决策。在工业自动化，如机器人和坚固的边缘人工智能中，实时感知和智能对于自主操作至关重要。在边缘或物联网设备上部署基于Transformer的图像描述模型可以增强机器感知，改善自主机器人的场景理解，并协助工业检查。然而，这些边缘或物联网设备在物理灵活性方面通常受到计算资源的限制，同时它们对响应时间有严格的要求。传统的深度学习模型对于这些设备来说可能太大且计算密集。在本研究中，我们提出了在边缘设备上有效运行的基于Transformer的图像描述模型的发现。通过评估资源高效的Transformer模型并应用知识蒸馏技术，我们证明了使用这些技术可以在资源受限的设备上加速推理，同时保持模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Edge computing decentralizes processing power to network edge, enablingreal-time AI-driven decision-making in IoT applications. In industrialautomation such as robotics and rugged edge AI, real-time perception andintelligence are critical for autonomous operations. Deployingtransformer-based image captioning models at the edge can enhance machineperception, improve scene understanding for autonomous robots, and aid inindustrial inspection.  However, these edge or IoT devices are often constrained in computationalresources for physical agility, yet they have strict response timerequirements. Traditional deep learning models can be too large andcomputationally demanding for these devices. In this research, we presentfindings of transformer-based models for image captioning that operateeffectively on edge devices. By evaluating resource-effective transformermodels and applying knowledge distillation techniques, we demonstrate inferencecan be accelerated on resource-constrained devices while maintaining modelperformance using these techniques.</description>
      <author>example@mail.com (Wing Man Casca Kwok, Yip Chiu Tung, Kunal Bhagchandani)</author>
      <guid isPermaLink="false">2506.03607v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>How Far Are We from Predicting Missing Modalities with Foundation Models?</title>
      <link>http://arxiv.org/abs/2506.03530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了多模态基础模型在缺失模态预测中的潜力，并提出了一个针对性的框架以提升预测准确性和适应性。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型在多种任务中表现出色，但其作为即插即用解决方案的潜力尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;评估现有方法，并提出一个针对缺失模态预测的框架，以解决现有模型在语义提取和模态验证方面的不足。&lt;h4&gt;方法&lt;/h4&gt;将现有方法分为三类代表性范式，包含42个模型变体，并在预测准确性和适应性方面进行综合评估。&lt;h4&gt;主要发现&lt;/h4&gt;当前基础模型在细粒度语义提取和生成的模态稳健性验证方面存在不足，导致预测结果不理想。&lt;h4&gt;结论&lt;/h4&gt;提出的框架通过动态调整模态感知挖掘策略和自优化机制，显著提高了缺失图像和文本预测的FID和MER。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal foundation models have demonstrated impressive capabilities across diverse tasks. However, their potential as plug-and-play solutions for missing modality prediction remains underexplored. To investigate this, we categorize existing approaches into three representative paradigms, encompassing a total of 42 model variants, and conduct a comprehensive evaluation in terms of prediction accuracy and adaptability to downstream tasks. Our analysis reveals that current foundation models often fall short in two critical aspects: (i) fine-grained semantic extraction from the available modalities, and (ii) robust validation of generated modalities. These limitations lead to suboptimal and, at times, misaligned predictions. To address these challenges, we propose an agentic framework tailored for missing modality prediction. This framework dynamically formulates modality-aware mining strategies based on the input context, facilitating the extraction of richer and more discriminative semantic features. In addition, we introduce a self-refinement mechanism, which iteratively verifies and enhances the quality of generated modalities through internal feedback. Experimental results show that our method reduces FID for missing image prediction by at least 14% and MER for missing text prediction by at least 10% compared to baselines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal foundation models have demonstrated impressive capabilities acrossdiverse tasks. However, their potential as plug-and-play solutions for missingmodality prediction remains underexplored. To investigate this, we categorizeexisting approaches into three representative paradigms, encompassing a totalof 42 model variants, and conduct a comprehensive evaluation in terms ofprediction accuracy and adaptability to downstream tasks. Our analysis revealsthat current foundation models often fall short in two critical aspects: (i)fine-grained semantic extraction from the available modalities, and (ii) robustvalidation of generated modalities. These limitations lead to suboptimal and,at times, misaligned predictions. To address these challenges, we propose anagentic framework tailored for missing modality prediction. This frameworkdynamically formulates modality-aware mining strategies based on the inputcontext, facilitating the extraction of richer and more discriminative semanticfeatures. In addition, we introduce a \textit{self-refinement mechanism}, whichiteratively verifies and enhances the quality of generated modalities throughinternal feedback. Experimental results show that our method reduces FID formissing image prediction by at least 14% and MER for missing text prediction byat least 10% compared to baselines.</description>
      <author>example@mail.com (Guanzhou Ke, Yi Xie, Xiaoli Wang, Guoqing Chao, Bo Wang, Shengfeng He)</author>
      <guid isPermaLink="false">2506.03530v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>DiagNet: Detecting Objects using Diagonal Constraints on Adjacency Matrix of Graph Neural Network</title>
      <link>http://arxiv.org/abs/2506.03571v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了DaigNet，一种基于图卷积网络（GCN）邻接矩阵对角线约束的对象检测新方法。&lt;h4&gt;背景&lt;/h4&gt;现有的对象检测方法通常需要设计一系列锚框。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要设计锚框的对象检测方法。&lt;h4&gt;方法&lt;/h4&gt;提出了两种基于硬和软约束的邻接矩阵对角化算法，以及两种基于对角约束和补充约束的损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;DaigNet在Pascal VOC数据集上比YOLOv1提高了7.5%的mAP50，在MS COCO数据集上比YOLOv3u提高了5.1%，比YOLOv5u提高了3.7%，比YOLOv8提高了2.9%。&lt;h4&gt;结论&lt;/h4&gt;DaigNet是一种有效且性能优越的对象检测方法，具有无需设计锚框的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose DaigNet, a new approach to object detection with which we candetect an object bounding box using diagonal constraints on adjacency matrix ofa graph convolutional network (GCN). We propose two diagonalization algorithmsbased on hard and soft constraints on adjacency matrix and two loss functionsusing diagonal constraint and complementary constraint. The DaigNet eliminatesthe need for designing a set of anchor boxes commonly used. To provefeasibility of our novel detector, we adopt detection head in YOLO models.Experiments show that the DiagNet achieves 7.5% higher mAP50 on Pascal VOC thanYOLOv1. The DiagNet also shows 5.1% higher mAP on MS COCO than YOLOv3u, 3.7%higher mAP than YOLOv5u, and 2.9% higher mAP than YOLOv8.</description>
      <author>example@mail.com (Chong Hyun Lee, Kibae Lee)</author>
      <guid isPermaLink="false">2506.03571v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating SfM-based Pose Estimation with Dominating Set</title>
      <link>http://arxiv.org/abs/2506.03667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种预处理技术，用于加速基于运动结构（SfM）的姿态估计，这对于增强现实（AR）、虚拟现实（VR）和机器人等实时应用至关重要。&lt;h4&gt;背景&lt;/h4&gt;实时应用如增强现实、虚拟现实和机器人需要快速准确的姿态估计。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，在不牺牲显著精度的前提下，显著提高姿态估计过程的速度。&lt;h4&gt;方法&lt;/h4&gt;该方法利用图论中的支配集概念来预处理SfM模型。&lt;h4&gt;主要发现&lt;/h4&gt;使用OnePose数据集评估了该方法，结果显示处理速度提高了1.5到14.48倍，参考图像和点云大小分别减少了17-23倍和2.27-4倍。&lt;h4&gt;结论&lt;/h4&gt;这项工作为高效且准确的3D姿态估计提供了一个有前景的解决方案，在实时应用中平衡了速度和精度。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a preprocessing technique to speed up Structure-from-Motion (SfM) based pose estimation, which is critical for real-time applications like augmented reality (AR), virtual reality (VR), and robotics. Our method leverages the concept of a dominating set from graph theory to preprocess SfM models, significantly enhancing the speed of the pose estimation process without losing significant accuracy. Using the OnePose dataset, we evaluated our method across various SfM-based pose estimation techniques. The results demonstrate substantial improvements in processing speed, ranging from 1.5 to 14.48 times, and a reduction in reference images and point cloud size by factors of 17-23 and 2.27-4, respectively. This work offers a promising solution for efficient and accurate 3D pose estimation, balancing speed and accuracy in real-time applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a preprocessing technique to speed upStructure-from-Motion (SfM) based pose estimation, which is critical forreal-time applications like augmented reality (AR), virtual reality (VR), androbotics. Our method leverages the concept of a dominating set from graphtheory to preprocess SfM models, significantly enhancing the speed of the poseestimation process without losing significant accuracy. Using the OnePosedataset, we evaluated our method across various SfM-based pose estimationtechniques. The results demonstrate substantial improvements in processingspeed, ranging from 1.5 to 14.48 times, and a reduction in reference images andpoint cloud size by factors of 17-23 and 2.27-4, respectively. This work offersa promising solution for efficient and accurate 3D pose estimation, balancingspeed and accuracy in real-time applications.</description>
      <author>example@mail.com (Joji Joseph, Bharadwaj Amrutur, Shalabh Bhatnagar)</author>
      <guid isPermaLink="false">2506.03667v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Attention-Only Transformers via Unrolled Subspace Denoising</title>
      <link>http://arxiv.org/abs/2506.03790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 7 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种全新的可解释的transformer架构，通过压缩噪声初始标记表示到低维子空间来学习表示。&lt;h4&gt;背景&lt;/h4&gt;尽管transformer在实践中的应用很普遍，但其架构是经验设计的，既没有数学依据也不可解释。许多经验研究表明，transformer架构的一些组件可能是冗余的。&lt;h4&gt;目的&lt;/h4&gt;目标是推导出一个完全可解释的transformer架构，只包含必要的组件。&lt;h4&gt;方法&lt;/h4&gt;该方法通过将迭代去噪操作展开成一个深层网络，形成了一个高度紧凑的架构，该架构只包含自注意力算子，并在每一层有跳跃连接。每个层通过线性率提高标记表示的信号与噪声比。&lt;h4&gt;主要发现&lt;/h4&gt;每个层都执行高效的去噪，随着层数的增加，标记表示的信号与噪声比以线性速度提高。&lt;h4&gt;结论&lt;/h4&gt;尽管这种架构很简单，但在视觉和语言任务上的广泛实验表明，它达到的性能接近于标准transformer架构如GPT-2和CRATE。&lt;h4&gt;翻译&lt;/h4&gt;尽管transformers在实践中很受欢迎，但它们的架构是经验设计的，既没有数学依据也不可解释。许多经验研究表明，transformer架构的一些组件可能是冗余的。为了推导出一个只有必要组件的完全可解释的transformer架构，我们认为表示学习的目标是压缩一组噪声初始标记表示到一个低维子空间的混合体。为了压缩这些噪声标记表示，一个相关的去噪操作自然地采取多头（子空间）自注意力的形式。通过将这样的迭代去噪操作展开成一个深层网络，我们得到了一个高度紧凑的架构，该架构只包含自注意力算子，并在每一层有跳跃连接。此外，我们还表明，每一层都执行高度有效的去噪：它以线性速度提高标记表示的信号与噪声比。尽管它的简单性，但在视觉和语言任务上的广泛实验表明，这样的transformer达到的性能接近于标准transformer架构，如GPT-2和CRATE。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the popularity of transformers in practice, their architectures areempirically designed and neither mathematically justified nor interpretable.Moreover, as indicated by many empirical studies, some components oftransformer architectures may be redundant. To derive a fully interpretabletransformer architecture with only necessary components, we contend that thegoal of representation learning is to compress a set of noisy initial tokenrepresentations towards a mixture of low-dimensional subspaces. To compressthese noisy token representations, an associated denoising operation naturallytakes the form of a multi-head (subspace) self-attention. By unrolling suchiterative denoising operations into a deep network, we arrive at a highlycompact architecture that consists of \textit{only} self-attention operatorswith skip connections at each layer. Moreover, we show that each layer performshighly efficient denoising: it improves the signal-to-noise ratio of tokenrepresentations \textit{at a linear rate} with respect to the number of layers.Despite its simplicity, extensive experiments on vision and language tasksdemonstrate that such a transformer achieves performance close to that ofstandard transformer architectures such as GPT-2 and CRATE.</description>
      <author>example@mail.com (Peng Wang, Yifu Lu, Yaodong Yu, Druv Pai, Qing Qu, Yi Ma)</author>
      <guid isPermaLink="false">2506.03790v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Topology-Aware Graph Neural Network-based State Estimation for PMU-Unobservable Power Systems</title>
      <link>http://arxiv.org/abs/2506.03493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的深度几何学习方法，用于估计PMU不可观测的电力系统状态，以克服传统优化方法的高在线计算负担、有限的PMU覆盖范围和非高斯测量噪声等问题。&lt;h4&gt;背景&lt;/h4&gt;传统的基于优化的时间同步状态估计技术存在计算负担重、PMU覆盖范围有限和非高斯测量噪声等问题，而基于学习的模型容易受到拓扑变化和实时数据丢失的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过图神经网络来估计PMU不可观测的电力系统状态，以解决传统方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了图卷积和多头图注意力层在一个定制的端到端学习框架内，以处理拓扑变化和实时数据丢失，并推导出状态估计误差的上界。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在存在拓扑变化、PMU故障、坏数据、非高斯测量噪声和大型系统实施的情况下，所提出的定制GNN-SE（CGNN-SE）方法优于传统的基于优化的技术和基于学习的模型。&lt;h4&gt;结论&lt;/h4&gt;基于图神经网络的深度几何学习方法在处理电力系统状态估计方面表现出色，能够有效应对多种挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional optimization-based techniques for time-synchronized stateestimation (SE) often suffer from high online computational burden, limitedphasor measurement unit (PMU) coverage, and presence of non-Gaussianmeasurement noise. Although conventional learning-based models have beendeveloped to overcome these challenges, they are negatively impacted bytopology changes and real-time data loss. This paper proposes a novel deepgeometric learning approach based on graph neural networks (GNNs) to estimatethe states of PMU-unobservable power systems. The proposed approach combinesgraph convolution and multi-head graph attention layers inside a customizedend-to-end learning framework to handle topology changes and real-time dataloss. An upper bound on SE error as a function of topology change is alsoderived. Experimental results for different test systems demonstratesuperiority of the proposed customized GNN-SE (CGNN-SE) over traditionaloptimization-based techniques as well as conventional learning-based models inpresence of topology changes, PMU failures, bad data, non-Gaussian measurementnoise, and large system implementation.</description>
      <author>example@mail.com (Shiva Moshtagh, Behrouz Azimian, Mohammad Golgol, Anamitra Pal)</author>
      <guid isPermaLink="false">2506.03493v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models</title>
      <link>http://arxiv.org/abs/2506.03516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPR 2025 workshop - Foundation Models Meet Embodied  Agents&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种零样本目标导航框架，用于在未探索的环境中定位目标物体，该框架结合了视觉基础模型(VFMs)的感知能力和基于模型的规划器，实现了长时域决策。&lt;h4&gt;背景&lt;/h4&gt;目标导航是具身AI中的基本任务，传统方法依赖于大量标注数据或强化学习环境中的大量交互，难以泛化到新环境且可扩展性有限。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战，本文探索了零样本设置，使代理在没有特定任务训练的情况下操作，以实现更可扩展和适应性强的解决方案。&lt;h4&gt;方法&lt;/h4&gt;该框架集成了VFMs的感知能力与能够通过前沿探索进行长时域决策的模型化规划器。&lt;h4&gt;主要发现&lt;/h4&gt;在HM3D数据集上使用Habitat模拟器评估该方法，结果显示在零样本目标导航方面，该方法在成功加权路径长度方面达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在零样本目标导航任务中取得了显著的性能提升，为具身AI领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object goal navigation is a fundamental task in embodied AI, where an agentis instructed to locate a target object in an unexplored environment.Traditional learning-based methods rely heavily on large-scale annotated dataor require extensive interaction with the environment in a reinforcementlearning setting, often failing to generalize to novel environments andlimiting scalability. To overcome these challenges, we explore a zero-shotsetting where the agent operates without task-specific training, enabling morescalable and adaptable solution. Recent advances in Vision Foundation Models(VFMs) offer powerful capabilities for visual understanding and reasoning,making them ideal for agents to comprehend scenes, identify relevant regions,and infer the likely locations of objects. In this work, we present a zero-shotobject goal navigation framework that integrates the perceptual strength ofVFMs with a model-based planner that is capable of long-horizon decision makingthrough frontier exploration. We evaluate our approach on the HM3D datasetusing the Habitat simulator and demonstrate that our method achievesstate-of-the-art performance in terms of success weighted by path length forzero-shot object goal navigation.</description>
      <author>example@mail.com (Arnab Debnath, Gregory J. Stein, Jana Kosecka)</author>
      <guid isPermaLink="false">2506.03516v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Go Beyond Earth: Understanding Human Actions and Scenes in Microgravity Environments</title>
      <link>http://arxiv.org/abs/2506.02845v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 3 figures, code are available at  https://github.com/LEI-QI-233/HAR-in-Space&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了MicroG-4M，这是一个用于微重力下人类活动时空和语义理解的基准数据集。&lt;h4&gt;背景&lt;/h4&gt;尽管视频理解取得了重大进展，但大多数现有数据集仅限于地球重力条件，而微重力会改变人类运动、交互和视觉语义，这对现实世界的视觉系统提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，本文提出MicroG-4M，旨在评估微重力环境下的空间定位和语义推理。&lt;h4&gt;方法&lt;/h4&gt;MicroG-4M由真实太空任务和电影模拟构建，包含4,759个片段，涵盖了50个动作，1,238个丰富的上下文字幕，以及关于宇航员活动和场景理解的7,000多对问答。&lt;h4&gt;主要发现&lt;/h4&gt;MicroG-4M支持三个核心任务：细粒度多标签动作识别、时间视频字幕生成和视觉问答，为微重力环境下的空间定位和语义推理提供了全面的评估。&lt;h4&gt;结论&lt;/h4&gt;通过使用最先进的模型建立基线，所有数据、标注和代码都在https://github.com/LEI-QI-233/HAR-in-Space上提供。&lt;h4&gt;翻译&lt;/h4&gt;尽管在视频理解方面取得了重大进展，但大多数现有数据集仅限于地球的重力条件。然而，微重力会改变人类运动、交互和视觉语义，这揭示了现实世界视觉系统的一个关键差距。这为安全关键的太空应用中的领域鲁棒视频理解带来了挑战。为了解决这个问题，我们引入了MicroG-4M，这是第一个用于微重力下人类活动时空和语义理解的基准。该数据集由真实世界的太空任务和电影模拟构建，包括4,759个片段，涵盖了50个动作，1,238个丰富的上下文字幕，以及关于宇航员活动和场景理解的7,000多对问答。MicroG-4M支持三个核心任务：细粒度多标签动作识别、时间视频字幕生成和视觉问答，使得对微重力环境下的空间定位和语义推理的全面评估成为可能。我们使用最先进的模型建立了基线。所有数据、标注和代码均可在https://github.com/LEI-QI-233/HAR-in-Space上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite substantial progress in video understanding, most existing datasetsare limited to Earth's gravitational conditions. However, microgravity altershuman motion, interactions, and visual semantics, revealing a critical gap forreal-world vision systems. This presents a challenge for domain-robust videounderstanding in safety-critical space applications. To address this, weintroduce MicroG-4M, the first benchmark for spatio-temporal and semanticunderstanding of human activities in microgravity. Constructed from real-worldspace missions and cinematic simulations, the dataset includes 4,759 clipscovering 50 actions, 1,238 context-rich captions, and over 7,000question-answer pairs on astronaut activities and scene understanding.MicroG-4M supports three core tasks: fine-grained multi-label actionrecognition, temporal video captioning, and visual question answering, enablinga comprehensive evaluation of both spatial localization and semantic reasoningin microgravity contexts. We establish baselines using state-of-the-art models.All data, annotations, and code are available athttps://github.com/LEI-QI-233/HAR-in-Space.</description>
      <author>example@mail.com (Di Wen, Lei Qi, Kunyu Peng, Kailun Yang, Fei Teng, Ao Luo, Jia Fu, Yufan Chen, Ruiping Liu, Yitian Shi, M. Saquib Sarfraz, Rainer Stiefelhagen)</author>
      <guid isPermaLink="false">2506.02845v2</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision</title>
      <link>http://arxiv.org/abs/2506.03605v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种框架，利用Exo-Ego4D构建的大规模视频数据集，提取各种物体的多样化操作轨迹，并基于这些轨迹开发轨迹生成模型，以解决交互式机器人在常见场景中学习使用工具或物体的挑战。&lt;h4&gt;背景&lt;/h4&gt;训练模型生成操作轨迹需要大量多样化的详细操作演示，这在规模上几乎不可行。&lt;h4&gt;目的&lt;/h4&gt;开发能够从动作描述中生成6DoF操作轨迹的模型，为交互式机器人处理常见场景中的工具或物体提供支持。&lt;h4&gt;方法&lt;/h4&gt;提出了一种框架，利用大规模的Exo-Ego4D视频数据集提取操作轨迹，并基于这些轨迹和相关文本动作描述开发轨迹生成模型。&lt;h4&gt;主要发现&lt;/h4&gt;在HOT3D的ego-centric vision-based in-a-quality轨迹数据集上，模型成功生成了有效的物体轨迹，建立了训练数据集和基线模型。&lt;h4&gt;结论&lt;/h4&gt;该框架和模型为生成6DoF操作轨迹提供了一个有效的解决方案，有助于交互式机器人学习在常见场景中使用工具或物体。&lt;h4&gt;翻译&lt;/h4&gt;在常见场景中学习使用工具或物体，尤其是按指令以各种方式处理它们，是开发交互式机器人的一项关键挑战。训练生成此类操作轨迹的模型需要大量和多样化的详细操作演示，这对于各种物体而言几乎是不可能收集到的规模。在本文中，我们提出了一种框架，该框架利用了由Exo-Ego4D构建的大规模自我和外部视角视频数据集——这些数据集在全球范围内投入了大量努力——以大规模地提取多样化的操作轨迹。从这些提取的轨迹和相关文本动作描述中，我们开发了基于视觉和基于点云的语言模型的轨迹生成模型。在最近提出的HOT3D的以自我为中心的视觉为基础的高质量轨迹数据集中，我们证实了我们的模型成功地生成了有效的物体轨迹，为从自我为中心视觉中的动作描述生成6DoF操作轨迹的新的任务建立了训练数据集和基线模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning to use tools or objects in common scenes, particularly handling themin various ways as instructed, is a key challenge for developing interactiverobots. Training models to generate such manipulation trajectories requires alarge and diverse collection of detailed manipulation demonstrations forvarious objects, which is nearly unfeasible to gather at scale. In this paper,we propose a framework that leverages large-scale ego- and exo-centric videodatasets -- constructed globally with substantial effort -- of Exo-Ego4D toextract diverse manipulation trajectories at scale. From these extractedtrajectories with the associated textual action description, we developtrajectory generation models based on visual and point cloud-based languagemodels. In the recently proposed egocentric vision-based in-a-qualitytrajectory dataset of HOT3D, we confirmed that our models successfully generatevalid object trajectories, establishing a training dataset and baseline modelsfor the novel task of generating 6DoF manipulation trajectories from actiondescriptions in egocentric vision.</description>
      <author>example@mail.com (Tomoya Yoshida, Shuhei Kurita, Taichi Nishimura, Shinsuke Mori)</author>
      <guid isPermaLink="false">2506.03605v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Geometric Visual Fusion Graph Neural Networks for Multi-Person Human-Object Interaction Recognition in Videos</title>
      <link>http://arxiv.org/abs/2506.03440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Expert Systems with Applications (ESWA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为GeoVis-GNN的几何视觉融合图神经网络，用于视频中的HOI识别，通过结合双注意力特征融合和相互依存的实体图学习，实现多模态特征的有效融合。&lt;h4&gt;背景&lt;/h4&gt;视频中的HOI识别需要理解随时间演变的视觉模式和几何关系，视觉和几何特征各有优势，但如何有效地融合这些特征是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;为了有效地融合多模态特征，论文提出了一种自下而上的方法，并提出了GeoVis-GNN模型，旨在提高HOI识别的性能。&lt;h4&gt;方法&lt;/h4&gt;GeoVis-GNN使用双注意力特征融合和相互依存的实体图学习，从实体特定的表示逐步构建到高级交互理解。&lt;h4&gt;主要发现&lt;/h4&gt;论文引入了MPHOI-120数据集，该数据集捕捉动态的多个人交互，包括同时动作和部分参与，有助于解决复杂的人-物动态和相互遮挡等问题。&lt;h4&gt;结论&lt;/h4&gt;实验表明，该方法在各种HOI场景中均取得了最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;Human-Object Interaction (HOI) recognition in videos requires understanding both visual patterns and geometric relationships as they evolve over time. Visual and geometric features offer complementary strengths. Visual features capture appearance context, while geometric features provide structural patterns. Effectively fusing these multimodal features without compromising their unique characteristics remains challenging. We observe that establishing robust, entity-specific representations before modeling interactions helps preserve the strengths of each modality. Therefore, we hypothesize that a bottom-up approach is crucial for effective multimodal fusion. Following this insight, we propose the Geometric Visual Fusion Graph Neural Network (GeoVis-GNN), which uses dual-attention feature fusion combined with interdependent entity graph learning. It progressively builds from entity-specific representations toward high-level interaction understanding. To advance HOI recognition to real-world scenarios, we introduce the Concurrent Partial Interaction Dataset (MPHOI-120). It captures dynamic multi-person interactions involving concurrent actions and partial engagement. This dataset helps address challenges like complex human-object dynamics and mutual occlusions. Extensive experiments demonstrate the effectiveness of our method across various HOI scenarios. These scenarios include two-person interactions, single-person activities, bimanual manipulations, and complex concurrent partial interactions. Our method achieves state-of-the-art performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human-Object Interaction (HOI) recognition in videos requires understandingboth visual patterns and geometric relationships as they evolve over time.Visual and geometric features offer complementary strengths. Visual featurescapture appearance context, while geometric features provide structuralpatterns. Effectively fusing these multimodal features without compromisingtheir unique characteristics remains challenging. We observe that establishingrobust, entity-specific representations before modeling interactions helpspreserve the strengths of each modality. Therefore, we hypothesize that abottom-up approach is crucial for effective multimodal fusion. Following thisinsight, we propose the Geometric Visual Fusion Graph Neural Network(GeoVis-GNN), which uses dual-attention feature fusion combined withinterdependent entity graph learning. It progressively builds fromentity-specific representations toward high-level interaction understanding. Toadvance HOI recognition to real-world scenarios, we introduce the ConcurrentPartial Interaction Dataset (MPHOI-120). It captures dynamic multi-personinteractions involving concurrent actions and partial engagement. This datasethelps address challenges like complex human-object dynamics and mutualocclusions. Extensive experiments demonstrate the effectiveness of our methodacross various HOI scenarios. These scenarios include two-person interactions,single-person activities, bimanual manipulations, and complex concurrentpartial interactions. Our method achieves state-of-the-art performance.</description>
      <author>example@mail.com (Tanqiu Qiao, Ruochen Li, Frederick W. B. Li, Yoshiki Kubotani, Shigeo Morishima, Hubert P. H. Shum)</author>
      <guid isPermaLink="false">2506.03440v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Physics and Computing Performance of the EggNet Tracking Pipeline</title>
      <link>http://arxiv.org/abs/2506.03415v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于图神经网络（GNN）的粒子轨迹重建方法，特别是EggNet这一单次方法，并评估了其在TrackML数据集上的物理和计算性能。&lt;h4&gt;背景&lt;/h4&gt;传统的粒子轨迹重建算法由于组合性质而计算复杂，近年来GNN被用于提高算法的可扩展性。&lt;h4&gt;目的&lt;/h4&gt;评估EggNet跟踪管道在TrackML数据集上的物理和计算性能，并探索减少计算内存和时间的不同技术。&lt;h4&gt;方法&lt;/h4&gt;提出了一种EggNet方法，该方法直接以探测器空间点为输入，迭代地应用图注意力网络，并随着图结构的演变更新图，以提高边缘效率和纯度。&lt;h4&gt;主要发现&lt;/h4&gt;EggNet方法在TrackML数据集上提供了良好的模型性能，同时探索了减少计算资源消耗的技术。&lt;h4&gt;结论&lt;/h4&gt;EggNet是一种有效的粒子轨迹重建方法，有助于提高算法的可扩展性和性能。&lt;h4&gt;翻译&lt;/h4&gt;Particle track reconstruction is traditionally computationally challenging due to the combinatorial nature of the tracking algorithms employed. Recent developments have focused on novel algorithms with graph neural networks (GNNs), which can improve scalability. While most of these GNN-based methods require an input graph to be constructed before performing message passing, a one-shot approach called EggNet that directly takes detector spacepoints as inputs and iteratively apply graph attention networks with an evolving graph structure has been proposed. The graphs are gradually updated to improve the edge efficiency and purity, thus providing a better model performance. In this work, we evaluate the physics and computing performance of the EggNet tracking pipeline on the full TrackML dataset. We also explore different techniques to reduce constraints on computation memory and computing time.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Particle track reconstruction is traditionally computationally challengingdue to the combinatorial nature of the tracking algorithms employed. Recentdevelopments have focused on novel algorithms with graph neural networks(GNNs), which can improve scalability. While most of these GNN-based methodsrequire an input graph to be constructed before performing message passing, aone-shot approach called EggNet that directly takes detector spacepoints asinputs and iteratively apply graph attention networks with an evolving graphstructure has been proposed. The graphs are gradually updated to improve theedge efficiency and purity, thus providing a better model performance. In thiswork, we evaluate the physics and computing performance of the EggNet trackingpipeline on the full TrackML dataset. We also explore different techniques toreduce constraints on computation memory and computing time.</description>
      <author>example@mail.com (Jay Chan, Brandon Wang, Paolo Calafiura)</author>
      <guid isPermaLink="false">2506.03415v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>OpenCarbon: A Contrastive Learning-based Cross-Modality Neural Approach for High-Resolution Carbon Emission Prediction Using Open Data</title>
      <link>http://arxiv.org/abs/2506.03224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于开放数据的碳排放预测模型OpenCarbon，用于高分辨率城市碳排放预测，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;精确估计高分辨率碳排放对于有效的排放治理和缓解规划至关重要。传统的精确碳核算方法因数据收集工作量大而受限。&lt;h4&gt;目的&lt;/h4&gt;开发一个基于开放数据的预测模型，以简化高分辨率碳排放的估计。&lt;h4&gt;方法&lt;/h4&gt;结合卫星图像和POI数据，利用跨模态信息提取和融合模块以及邻域信息聚合模块来预测高分辨率城市碳排放。&lt;h4&gt;主要发现&lt;/h4&gt;OpenCarbon模型在R2性能上提升了26.6%，并且能够捕捉城市功能与碳排放之间的内在关系。&lt;h4&gt;结论&lt;/h4&gt;OpenCarbon模型能够有效促进碳治理和针对性的碳缓解规划。&lt;h4&gt;翻译&lt;/h4&gt;Accurately estimating high-resolution carbon emissions is crucial for effective emission governance and mitigation planning. While conventional methods for precise carbon accounting are hindered by substantial data collection efforts, the rise of open data and advanced learning techniques offers a promising solution. Once an open data-based prediction model is developed and trained, it can easily infer emissions for new areas based on available open data. To address this, we incorporate two modalities of open data, satellite images and point-of-interest (POI) data, to predict high-resolution urban carbon emissions, with satellite images providing macroscopic and static and POI data offering fine-grained and relatively dynamic functionality information. However, estimating high-resolution carbon emissions presents two significant challenges: the intertwined and implicit effects of various functionalities on carbon emissions, and the complex spatial contiguity correlations that give rise to the agglomeration effect. Our model, OpenCarbon, features two major designs that target the challenges: a cross-modality information extraction and fusion module to extract complementary functionality information from two modules and model their interactions, and a neighborhood-informed aggregation module to capture the spatial contiguity correlations. Extensive experiments demonstrate our model's superiority, with a significant performance gain of 26.6% on R2. Further generalizability tests and case studies also show OpenCarbon's capacity to capture the intrinsic relation between urban functionalities and carbon emissions, validating its potential to empower efficient carbon governance and targeted carbon mitigation planning. Codes and data are available: https://github.com/JinweiZzz/OpenCarbon.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately estimating high-resolution carbon emissions is crucial foreffective emission governance and mitigation planning. While conventionalmethods for precise carbon accounting are hindered by substantial datacollection efforts, the rise of open data and advanced learning techniquesoffers a promising solution. Once an open data-based prediction model isdeveloped and trained, it can easily infer emissions for new areas based onavailable open data. To address this, we incorporate two modalities of opendata, satellite images and point-of-interest (POI) data, to predicthigh-resolution urban carbon emissions, with satellite images providingmacroscopic and static and POI data offering fine-grained and relativelydynamic functionality information. However, estimating high-resolution carbonemissions presents two significant challenges: the intertwined and impliciteffects of various functionalities on carbon emissions, and the complex spatialcontiguity correlations that give rise to the agglomeration effect. Our model,OpenCarbon, features two major designs that target the challenges: across-modality information extraction and fusion module to extractcomplementary functionality information from two modules and model theirinteractions, and a neighborhood-informed aggregation module to capture thespatial contiguity correlations. Extensive experiments demonstrate our model'ssuperiority, with a significant performance gain of 26.6\% on R2. Furthergeneralizability tests and case studies also show OpenCarbon's capacity tocapture the intrinsic relation between urban functionalities and carbonemissions, validating its potential to empower efficient carbon governance andtargeted carbon mitigation planning. Codes and data are available:https://github.com/JinweiZzz/OpenCarbon.</description>
      <author>example@mail.com (Jinwei Zeng, Yu Liu, Guozhen Zhang, Jingtao Ding, Yuming Lin, Jian Yuan, Yong Li)</author>
      <guid isPermaLink="false">2506.03224v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>When Does Closeness in Distribution Imply Representational Similarity? An Identifiability Perspective</title>
      <link>http://arxiv.org/abs/2506.03784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了不同深度神经网络学习到的表示相似性的问题，并从可识别性理论的角度出发，探讨了当模型生成的分布接近时，模型表示相似的条件。&lt;h4&gt;背景&lt;/h4&gt;表示相似性是深度神经网络研究中的一个活跃话题。&lt;h4&gt;目的&lt;/h4&gt;通过研究，确定模型分布接近时，模型表示是否也相似。&lt;h4&gt;方法&lt;/h4&gt;作者从可识别性理论出发，定义了一种分布距离，用于衡量表示的相似性，并通过实验验证了其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，模型分布之间的Kullback-Leibler散度小并不保证对应的表示相似。此外，网络宽度与分布距离和表示相似性之间存在关联。&lt;h4&gt;结论&lt;/h4&gt;本文建立了分布接近与表示相似性之间的联系。&lt;h4&gt;翻译&lt;/h4&gt;摘要：何时以及为什么不同深度神经网络学习到的表示相似是一个活跃的研究课题。我们选择从可识别性理论的角度来回答这些问题，该理论表明，表示相似性的度量应该对不改变模型分布的变换是不变的。我们关注一个包括几个流行的预训练方法（例如，自回归语言模型）的模型家族，我们探讨了当模型生成接近的分布时，模型表示何时相似。我们证明了模型分布之间的小Kullback-Leibler散度并不能保证相应的表示相似。这有一个重要的推论，即任意接近最大化似然性的模型仍然可以学习到不相似的表示，这一现象在我们的CIFAR-10上训练的模型的经验观察中也得到了反映。然后我们定义了一种分布距离，其中接近性意味着表示相似性，在合成实验中，我们发现更宽的网络学习到与我们距离更近的分布，并且具有更相似的表示。我们的结果在分布接近和表示相似性之间建立了一个联系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When and why representations learned by different deep neural networks aresimilar is an active research topic. We choose to address these questions fromthe perspective of identifiability theory, which suggests that a measure ofrepresentational similarity should be invariant to transformations that leavethe model distribution unchanged. Focusing on a model family which includesseveral popular pre-training approaches, e.g., autoregressive language models,we explore when models which generate distributions that are close have similarrepresentations. We prove that a small Kullback-Leibler divergence between themodel distributions does not guarantee that the corresponding representationsare similar. This has the important corollary that models arbitrarily close tomaximizing the likelihood can still learn dissimilar representations, aphenomenon mirrored in our empirical observations on models trained onCIFAR-10. We then define a distributional distance for which closeness impliesrepresentational similarity, and in synthetic experiments, we find that widernetworks learn distributions which are closer with respect to our distance andhave more similar representations. Our results establish a link betweencloseness in distribution and representational similarity.</description>
      <author>example@mail.com (Beatrix M. G. Nielsen, Emanuele Marconato, Andrea Dittadi, Luigi Gresele)</author>
      <guid isPermaLink="false">2506.03784v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>ViT-Split: Unleashing the Power of Vision Foundation Models via Efficient Splitting Heads</title>
      <link>http://arxiv.org/abs/2506.03433v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The project is available:  https://jackyfl.github.io/vitsplit.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ViT-Split的新方法，用于改进视觉基础模型（VFMs）的适配器，以提升其在下游任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的VFM适配器通过利用VFMs的先验知识取得了良好的效果，但存在效率和复杂性方面的问题。&lt;h4&gt;目的&lt;/h4&gt;针对现有方法的不足，提出ViT-Split方法，旨在提高训练效率并减少对参数的调整。&lt;h4&gt;方法&lt;/h4&gt;ViT-Split基于对多个VFMs（如DINOv2）层的观察，将其分为两个组件：一个用于学习低级特征的学习器和一个用于学习特定任务特征的学习器。该方法消除了CNN分支，并引入了任务头和先验头，以解决早期梯度回传问题和利用先验知识。&lt;h4&gt;主要发现&lt;/h4&gt;ViT-Split通过消除CNN分支和引入两个头，有效减少了早期梯度回传，并利用了冻结的VFM的多尺度先验特征，从而减少了调整参数和过拟合的可能性。&lt;h4&gt;结论&lt;/h4&gt;在多个任务（如分割、检测、深度估计和视觉问答）上的实验验证了ViT-Split的有效性和效率，其训练时间可减少至原来的1/4，同时在ADE20K数据集上取得了与现有VFM适配器相当甚至更好的结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉基础模型（VFMs）在广泛的下游任务中表现出色。虽然一些VFM适配器通过利用VFMs的先验知识取得了有希望的结果，但我们在这些方法中识别出两种低效性。首先，卷积神经网络（CNN）与VFM骨干之间的交互触发了早期层梯度回传。其次，现有方法需要调整所有组件，增加了复杂性。此外，这些适配器改变了VFM特征，未能充分利用先验知识。为了解决这些挑战，我们提出了一种名为ViT-Split的新方法，基于一个关键观察：多个VFMs（如DINOv2）的层可以被分为两个不同的组件：一个用于学习低级特征的学习器和一个用于学习特定任务特征的学习器。利用这一洞察，我们消除了CNN分支，并引入了两个头，任务头和先验头，到冻结的VFM中。任务头被设计用于学习特定任务的特征，减轻了早期梯度传播问题。先验头用于利用冻结的VFM的多尺度先验特征，减少调整参数和过拟合。在分割、检测、深度估计和视觉问答等各个任务上的广泛实验验证了ViT-Split的有效性和效率。具体来说，ViT-Split将训练时间减少了高达4倍，同时在ADE20K数据集上与其它VFM适配器相比，取得了相当甚至更好的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision foundation models (VFMs) have demonstrated remarkable performanceacross a wide range of downstream tasks. While several VFM adapters have shownpromising results by leveraging the prior knowledge of VFMs, we identify twoinefficiencies in these approaches. First, the interaction betweenconvolutional neural network (CNN) and VFM backbone triggers early layergradient backpropagation. Second, existing methods require tuning allcomponents, adding complexity. Besides, these adapters alter VFM features,underutilizing the prior knowledge. To tackle these challenges, we propose anew approach called ViT-Split, based on a key observation: the layers ofseveral VFMs, like DINOv2, can be divided into two distinct components: anextractor for learning low-level features and an adapter for learningtask-specific features. Leveraging this insight, we eliminate the CNN branchand introduce two heads, task head and prior head, to the frozen VFM. The taskhead is designed to learn task-specific features, mitigating the early gradientpropagation issue. The prior head is used to leverage the multi-scale priorfeatures from the frozen VFM, reducing tuning parameters and overfitting.Extensive experiments on various tasks (e.g., segmentation, detection, depthestimation, and visual question answering) validate the effectiveness andefficiency of ViT-Split. Specifically, ViT-Split reduces training time up to$4\times$ while achieving comparable or even better results on ADE20K, comparedto other VFM adapters.</description>
      <author>example@mail.com (Yifan Li, Xin Li, Tianqin Li, Wenbin He, Yu Kong, Liu Ren)</author>
      <guid isPermaLink="false">2506.03433v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>KG-BiLM: Knowledge Graph Embedding via Bidirectional Language Models</title>
      <link>http://arxiv.org/abs/2506.03576v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为KG-BiLM的框架，用于统一知识图谱和语言模型，以实现更丰富的语义理解。&lt;h4&gt;背景&lt;/h4&gt;当前知识表示学习（KRL）的进展表明，将符号知识图谱（KGs）与语言模型（LMs）结合的必要性。&lt;h4&gt;目的&lt;/h4&gt;填补现有方法只关注图结构或文本语义的空白，同时捕捉全局KG连通性、细微的语言上下文和判别推理语义。&lt;h4&gt;方法&lt;/h4&gt;KG-BiLM包含三个关键组件：双向知识注意力、知识掩码预测和对比图语义聚合。&lt;h4&gt;主要发现&lt;/h4&gt;在标准基准测试中，KG-BiLM在链接预测任务上优于强基线，特别是在具有复杂多跳关系的大规模图上，验证了其统一结构和文本语义的有效性。&lt;h4&gt;结论&lt;/h4&gt;KG-BiLM通过融合知识图谱的结构线索和生成变换器的语义表达，为统一结构信息和文本语义提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in knowledge representation learning (KRL) highlight theurgent necessity to unify symbolic knowledge graphs (KGs) with language models(LMs) for richer semantic understanding. However, existing approaches typicallyprioritize either graph structure or textual semantics, leaving a gap: aunified framework that simultaneously captures global KG connectivity, nuancedlinguistic context, and discriminative reasoning semantics. To bridge this gap,we introduce KG-BiLM, a bidirectional LM framework that fuses structural cuesfrom KGs with the semantic expressiveness of generative transformers. KG-BiLMincorporates three key components: (i) Bidirectional Knowledge Attention, whichremoves the causal mask to enable full interaction among all tokens andentities; (ii) Knowledge-Masked Prediction, which encourages the model toleverage both local semantic contexts and global graph connectivity; and (iii)Contrastive Graph Semantic Aggregation, which preserves KG structure viacontrastive alignment of sampled sub-graph representations. Extensiveexperiments on standard benchmarks demonstrate that KG-BiLM outperforms strongbaselines in link prediction, especially on large-scale graphs with complexmulti-hop relations - validating its effectiveness in unifying structuralinformation and textual semantics.</description>
      <author>example@mail.com (Zirui Chen, Xin Wang, Zhao Li, Wenbin Guo, Dongxiao He)</author>
      <guid isPermaLink="false">2506.03576v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>POLARIS: A High-contrast Polarimetric Imaging Benchmark Dataset for Exoplanetary Disk Representation Learning</title>
      <link>http://arxiv.org/abs/2506.03511v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages main text with 5 figures, 9 pages appendix with 9 figures.  Submitted to NeurIPS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了利用人工智能技术对地外行星进行成像的可能性，并提出了一个基于偏振光数据表示学习的基准，探索了未来十年人工智能在成像类地行星中的应用。&lt;h4&gt;背景&lt;/h4&gt;目前，通过高对比度成像设备直接观测到的新系外行星数量有限，传统的成像方法依赖对参考星的大量手动标记。&lt;h4&gt;目的&lt;/h4&gt;评估人工智能在直接成像地外行星中的潜力，并提出一个新的、高质量的数据集和基准。&lt;h4&gt;方法&lt;/h4&gt;使用了从2014年开始的全公共SPHERE/IRDIS偏振光档案中的参考星和恒星周围盘片图像，建立了POLARIS数据集，并通过统计、生成和大型视觉语言模型评估了多种模型，提出了一个无监督的生成表示学习框架。&lt;h4&gt;主要发现&lt;/h4&gt;提出了第一个统一降低的、高质量的地外行星成像数据集，并通过集成不同模型，实现了优越的性能和增强的表示能力。&lt;h4&gt;结论&lt;/h4&gt;通过发布数据集和基准，旨在为天体物理学家提供新工具，并鼓励数据科学家推进直接地外行星成像，促进跨学科的重大突破。&lt;h4&gt;翻译&lt;/h4&gt;本文提出利用人工智能技术在接下来的十年中成像类似地球的系外行星的可能性，并从偏振光数据表示学习的角度探讨这个问题。尽管在过去十年中投入了大量资金，但只有少数新系外行星被直接成像。现有的成像方法高度依赖于对参考星进行劳动密集型标记，这些参考星作为背景以提取目标恒星周围的 circumstellar objects（盘片或系外行星）。通过我们的 POLARIS（POlarized Light dAta for total intensity Representation learning of direct Imaging of exoplanetary Systems）数据集，我们使用自2014年以来公开的 SPHERE/IRDIS 偏振光档案对参考星和恒星周围盘片图像进行分类，需要的手动标记不到10%。我们评估了一系列模型，包括统计、生成和大型视觉语言模型，并提供了基准性能。我们还提出了一种无监督的生成表示学习框架，它集成了这些模型，并实现了卓越的性能和增强的表示能力。据我们所知，这是第一个统一降低、高质量的地外行星成像数据集，在天体物理学和机器学习中非常罕见。通过发布这个数据集和基准，我们的目标是装备天体物理学家，并鼓励数据科学家推进直接地外行星成像，催化跨学科的重大突破。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With over 1,000,000 images from more than 10,000 exposures usingstate-of-the-art high-contrast imagers (e.g., Gemini Planet Imager, VLT/SPHERE)in the search for exoplanets, can artificial intelligence (AI) serve as atransformative tool in imaging Earth-like exoplanets in the coming decade? Inthis paper, we introduce a benchmark and explore this question from apolarimetric image representation learning perspective. Despite extensiveinvestments over the past decade, only a few new exoplanets have been directlyimaged. Existing imaging approaches rely heavily on labor-intensive labeling ofreference stars, which serve as background to extract circumstellar objects(disks or exoplanets) around target stars. With our POLARIS (POlarized LightdAta for total intensity Representation learning of direct Imaging ofexoplanetary Systems) dataset, we classify reference star and circumstellardisk images using the full public SPHERE/IRDIS polarized-light archive since2014, requiring less than 10 percent manual labeling. We evaluate a range ofmodels including statistical, generative, and large vision-language models andprovide baseline performance. We also propose an unsupervised generativerepresentation learning framework that integrates these models, achievingsuperior performance and enhanced representational power. To our knowledge,this is the first uniformly reduced, high-quality exoplanet imaging dataset,rare in astrophysics and machine learning. By releasing this dataset andbaselines, we aim to equip astrophysicists with new tools and engage datascientists in advancing direct exoplanet imaging, catalyzing majorinterdisciplinary breakthroughs.</description>
      <author>example@mail.com (Fangyi Cao, Bin Ren, Zihao Wang, Shiwei Fu, Youbin Mo, Xiaoyang Liu, Yuzhou Chen, Weixin Yao)</author>
      <guid isPermaLink="false">2506.03511v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>InterRVOS: Interaction-aware Referring Video Object Segmentation</title>
      <link>http://arxiv.org/abs/2506.02356v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的视频对象分割任务，即交互感知的视频对象分割（InterRVOS），该任务旨在分割涉及交互的演员和目标实体。同时，提出了一个大规模的自动构建的数据集InterRVOS-8K，以及一个用于处理演员-目标分割的基准架构ReVIOSa。&lt;h4&gt;背景&lt;/h4&gt;现有的视频对象分割方法主要关注单个目标对象的定位，而忽略了对象间的交互作用。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够分割涉及交互的演员和目标实体的新任务，并建立强大的基础以研究以交互为中心的视频理解。&lt;h4&gt;方法&lt;/h4&gt;提出了InterRVOS-8K数据集和ReVIOSa架构，并引入了演员-目标感知的评价设置。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方案在复杂对象交互建模方面优于先前的方法，为交互中心视频理解的未来研究奠定了基础。&lt;h4&gt;结论&lt;/h4&gt;通过引入交互感知的视频对象分割，本研究为理解视频中的复杂交互提供了新的视角和工具。&lt;h4&gt;翻译&lt;/h4&gt;Referring video object segmentation aims to segment the object in a video corresponding to a given natural language expression. While prior works have explored various referring scenarios, including motion-centric or multi-instance expressions, most approaches still focus on localizing a single target object in isolation. However, in comprehensive video understanding, an object's role is often defined by its interactions with other entities, which are largely overlooked in existing datasets and models. In this work, we introduce Interaction-aware referring video object segmentation (InterRVOS), a new task that requires segmenting both actor and target entities involved in an interaction. Each interaction is described through a pair of complementary expressions from different semantic perspectives, enabling fine-grained modeling of inter-object relationships. To tackle this task, we propose InterRVOS-8K, the large-scale and automatically constructed dataset containing diverse interaction-aware expressions with corresponding masks, including challenging cases such as motion-only multi-instance expressions. We also present a baseline architecture, ReVIOSa, designed to handle actor-target segmentation from a single expression, achieving strong performance in both standard and interaction-focused settings. Furthermore, we introduce an actor-target-aware evaluation setting that enables a more targeted assessment of interaction understanding. Experimental results demonstrate that our approach outperforms prior methods in modeling complex object interactions for referring video object segmentation task, establishing a strong foundation for future research in interaction-centric video understanding. Our project page is available at https://cvlab-kaist.github.io/InterRVOS.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Referring video object segmentation aims to segment the object in a videocorresponding to a given natural language expression. While prior works haveexplored various referring scenarios, including motion-centric ormulti-instance expressions, most approaches still focus on localizing a singletarget object in isolation. However, in comprehensive video understanding, anobject's role is often defined by its interactions with other entities, whichare largely overlooked in existing datasets and models. In this work, weintroduce Interaction-aware referring video object sgementation (InterRVOS), anew task that requires segmenting both actor and target entities involved in aninteraction. Each interactoin is described through a pair of complementaryexpressions from different semantic perspectives, enabling fine-grainedmodeling of inter-object relationships. To tackle this task, we proposeInterRVOS-8K, the large-scale and automatically constructed dataset containingdiverse interaction-aware expressions with corresponding masks, includingchallenging cases such as motion-only multi-instance expressions. We alsopresent a baseline architecture, ReVIOSa, designed to handle actor-targetsegmentation from a single expression, achieving strong performance in bothstandard and interaction-focused settings. Furthermore, we introduce anactor-target-aware evalaution setting that enables a more targeted assessmentof interaction understanding. Experimental results demonstrate that ourapproach outperforms prior methods in modeling complex object interactions forreferring video object segmentation task, establishing a strong foundation forfuture research in interaction-centric video understanding. Our project page isavailable at https://cvlab-kaist.github.io/InterRVOS.</description>
      <author>example@mail.com (Woojeong Jin, Seongchan Kim, Seungryong Kim)</author>
      <guid isPermaLink="false">2506.02356v2</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>A Foundation Model for Spatial Proteomics</title>
      <link>http://arxiv.org/abs/2506.03373v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;KRONOS是一种为空间蛋白质组学构建的基础模型，通过在大量图像数据上自监督训练，能够在细胞、微环境和组织等多个尺度上学习生物学上有意义的表示，从而提高细胞表型、区域分类和患者分层等下游任务的表现。&lt;h4&gt;背景&lt;/h4&gt;基础模型在图像分析中开始发挥重要作用，但在空间蛋白质组学（单细胞分辨率的蛋白质成像）中的应用有限。&lt;h4&gt;目的&lt;/h4&gt;开发一个适用于空间蛋白质组学的基础模型KRONOS。&lt;h4&gt;方法&lt;/h4&gt;KRONOS在超过4700万个图像片段上进行自监督训练，这些片段覆盖了175个蛋白质标记、16种组织类型和8种基于荧光的成像平台。模型进行了关键架构调整以处理多通道和异质的多重成像数据。&lt;h4&gt;主要发现&lt;/h4&gt;KRONOS能够在多个尺度上学习生物学上有意义的表示，包括细胞和微环境到组织水平，实现了对细胞表型、区域分类和患者分层等任务的高性能。KRONOS还引入了无分割的图像片段级处理，以实现高效且可扩展的空间蛋白质组学分析。&lt;h4&gt;结论&lt;/h4&gt;KRONOS是一个灵活且可扩展的空间蛋白质组学工具，其模型可通过https://github.com/mahmoodlab/KRONOS公开访问。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型已经开始通过作为预训练的通用骨干网络来改变图像分析，即使是在训练后数据有限的情况下，也能适应许多任务，但它们对空间蛋白质组学（单细胞分辨率的蛋白质成像）的影响仍然有限。在这里，我们介绍了KRONOS，这是一个为空间蛋白质组学构建的基础模型。KRONOS在超过4700万个图像片段上进行自监督训练，这些片段覆盖了175个蛋白质标记、16种组织类型和8种基于荧光的成像平台。我们引入了关键的架构调整来解决多重成像的高维、多通道和异质性质。我们证明了KRONOS能够在多个尺度上学习生物学上有意义的表示，从细胞和微环境到组织水平，使它能够解决包括细胞表型、区域分类和患者分层在内的各种下游任务。在11个独立队列中进行评估，KRONOS在细胞表型、治疗反应预测和检索任务中实现了最先进的性能，并且高度数据高效。KRONOS还引入了无分割的图像片段级处理，以实现高效且可扩展的空间蛋白质组学分析，允许跨机构比较，并作为一个图像反向搜索引擎用于空间模式。总之，这些结果将KRONOS定位为空间蛋白质组学的灵活且可扩展的工具。该模型可通过https://github.com/mahmoodlab/KRONOS公开访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have begun to transform image analysis by acting aspretrained generalist backbones that can be adapted to many tasks even whenpost-training data are limited, yet their impact on spatial proteomics, imagingthat maps proteins at single-cell resolution, remains limited. Here, weintroduce KRONOS, a foundation model built for spatial proteomics. KRONOS wastrained in a self-supervised manner on over 47 million image patches covering175 protein markers, 16 tissue types, and 8 fluorescence-based imagingplatforms. We introduce key architectural adaptations to address thehigh-dimensional, multi-channel, and heterogeneous nature of multiplex imaging.We demonstrate that KRONOS learns biologically meaningful representationsacross multiple scales, ranging from cellular and microenvironment to tissuelevels, enabling it to address diverse downstream tasks, including cellphenotyping, region classification, and patient stratification. Evaluatedacross 11 independent cohorts, KRONOS achieves state-of-the-art performanceacross cell phenotyping, treatment response prediction, and retrieval tasks,and is highly data-efficient. KRONOS also introduces the paradigm ofsegmentation-free patch-level processing for efficient and scalable spatialproteomics analysis, allowing cross-institutional comparisons, and as an imagereverse search engine for spatial patterns. Together, these results positionKRONOS as a flexible and scalable tool for spatial proteomics. The model ispublicly accessible at https://github.com/mahmoodlab/KRONOS.</description>
      <author>example@mail.com (Muhammad Shaban, Yuzhou Chang, Huaying Qiu, Yao Yu Yeo, Andrew H. Song, Guillaume Jaume, Yuchen Wang, Luca L. Weishaupt, Tong Ding, Anurag Vaidya, Abdallah Lamane, Daniel Shao, Mohammed Zidane, Yunhao Bai, Paige McCallum, Shuli Luo, Wenrui Wu, Yang Wang, Precious Cramer, Chi Ngai Chan, Pierre Stephan, Johanna Schaffenrath, Jia Le Lee, Hendrik A. Michel, Caiwei Tian, Cristina Almagro-Perez, Sophia J. Wagner, Sharifa Sahai, Ming Y. Lu, Richard J. Chen, Andrew Zhang, Mark Edward M. Gonzales, Ahmad Makky, Jia-Ying Joey Lee, Hao Cheng, Nourhan El Ahmar, Sayed Matar, Maximilian Haist, Darci Phillips, Yuqi Tan, Garry P. Nolan, W. Richard Burack, Jacob D. Estes, Jonathan T. C. Liu, Toni K Choueiri, Neeraj Agarwal, Marc Barry, Scott J. Rodig, Long Phi Le, Georg Gerber, Christian M. Schürch, Fabian J. Theis, Youn H Kim, Joe Yeong, Sabina Signoretti, Brooke E. Howitt, Lit-Hsin Loo, Qin Ma, Sizun Jiang, Faisal Mahmood)</author>
      <guid isPermaLink="false">2506.03373v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Skeleton-Based Action Representation Learning</title>
      <link>http://arxiv.org/abs/2506.03481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于骨架的人体动作识别，特别关注处理关节维度和拓扑结构变化的异构骨架数据。&lt;h4&gt;背景&lt;/h4&gt;由于人体骨架来源多样，骨架数据自然表现出异质性，但以往工作忽略了这一点，仅针对同质骨架构建模型。&lt;h4&gt;目的&lt;/h4&gt;解决异构骨架动作表示学习中的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一个框架，包含异构骨架处理和统一表示学习两个主要组件。前者通过辅助网络将二维骨架数据转换为三维骨架，并使用骨架特定提示构建提示统一骨架。后者使用共享骨干网络学习统一的动作表示。&lt;h4&gt;主要发现&lt;/h4&gt;在NTU-60、NTU-120和PKU-MMD II数据集上进行的实验表明，该方法在动作理解的各种任务中效果显著。&lt;h4&gt;结论&lt;/h4&gt;该方法可以应用于具有不同人形结构的机器人中的动作识别。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Skeleton-based human action recognition has received widespread attention inrecent years due to its diverse range of application scenarios. Due to thedifferent sources of human skeletons, skeleton data naturally exhibitheterogeneity. The previous works, however, overlook the heterogeneity of humanskeletons and solely construct models tailored for homogeneous skeletons. Thiswork addresses the challenge of heterogeneous skeleton-based actionrepresentation learning, specifically focusing on processing skeleton data thatvaries in joint dimensions and topological structures. The proposed frameworkcomprises two primary components: heterogeneous skeleton processing and unifiedrepresentation learning. The former first converts two-dimensional skeletondata into three-dimensional skeleton via an auxiliary network, and thenconstructs a prompted unified skeleton using skeleton-specific prompts. We alsodesign an additional modality named semantic motion encoding to harness thesemantic information within skeletons. The latter module learns a unifiedaction representation using a shared backbone network that processes differentheterogeneous skeletons. Extensive experiments on the NTU-60, NTU-120, andPKU-MMD II datasets demonstrate the effectiveness of our method in varioustasks of action understanding. Our approach can be applied to actionrecognition in robots with different humanoid structures.</description>
      <author>example@mail.com (Hongsong Wang, Xiaoyan Ma, Jidong Kuang, Jie Gui)</author>
      <guid isPermaLink="false">2506.03481v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Channel-adaptive Cross-modal Generative Semantic Communication for Point Cloud Transmission</title>
      <link>http://arxiv.org/abs/2506.03211v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的适用于点云传输的通道自适应跨模态生成语义通信方法GenSeC-PC，该方法结合了图像和点云，并通过改进的解码器和通道自适应架构实现了高效的压缩和重建。&lt;h4&gt;背景&lt;/h4&gt;随着自动驾驶和扩展现实的发展，点云的有效传输变得日益重要。&lt;h4&gt;目的&lt;/h4&gt;提高点云传输的压缩效率和重建性能。&lt;h4&gt;方法&lt;/h4&gt;GenSeC-PC使用语义编码器融合图像和点云，图像作为非传输的辅助信息。解码器基于PointDif的架构。设计了一种简化的非对称通道自适应联合语义信道编码架构，其中只有编码器需要平均信噪比和可用带宽的反馈。同时，使用修正的降噪扩散隐式模型加速解码过程，实现毫秒级实时通信。&lt;h4&gt;主要发现&lt;/h4&gt;GenSeC-PC利用生成先验确保即使是从噪声或不完整的源点云中也能进行可靠的重建。支持全模拟传输，通过消除先前SemCom方法中常见的需要无误差辅助信息传输的需求，提高了压缩效率。&lt;h4&gt;结论&lt;/h4&gt;仿真结果证实了跨模态语义提取和双指标引导微调的有效性，表明该框架在不同条件下（包括低信噪比、带宽限制、不同数量的二维图像和未见过的对象）具有鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;With the rapid development of autonomous driving and extended reality, efficient transmission of point clouds (PCs) has become increasingly important. In this context, we propose a novel channel-adaptive cross-modal generativesemantic communication (SemCom) for PC transmission, called GenSeC-PC. GenSeC-PC employs a semantic encoder that fuses images and point clouds, where images serve as non-transmitted side information. Meanwhile, the decoder is built upon the backbone of PointDif. Such a cross-modal design not only ensures high compression efficiency but also delivers superior reconstruction performance compared to PointDif. Moreover, to ensure robust transmission and reduce system complexity, we design a streamlined and asymmetric channel-adaptive joint semantic-channel coding architecture, where only the encoder needs the feedback of average signal-to-noise ratio (SNR) and available bandwidth. In addition, rectified denoising diffusion implicit models is employed to accelerate the decoding process to the millisecond level, enabling real-time PC communication. Unlike existing methods, GenSeC-PC leverages generative priors to ensure reliable reconstruction even from noisy or incomplete source PCs. More importantly, it supports fully analog transmission, improving compression efficiency by eliminating the need for error-free side information transmission common in prior SemCom approaches. Simulation results confirm the effectiveness of cross-modal semantic extraction and dual-metric guided fine-tuning, highlighting the framework's robustness across diver seconditions, including low SNR, bandwidth limitations, varying numbers of 2D images, and previously unseen objects.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of autonomous driving and extended reality,efficient transmission of point clouds (PCs) has become increasingly important.In this context, we propose a novel channel-adaptive cross-modal generativesemantic communication (SemCom) for PC transmission, called GenSeC-PC.GenSeC-PC employs a semantic encoder that fuses images and point clouds, whereimages serve as non-transmitted side information. Meanwhile, the decoder isbuilt upon the backbone of PointDif. Such a cross-modal design not only ensureshigh compression efficiency but also delivers superior reconstructionperformance compared to PointDif. Moreover, to ensure robust transmission andreduce system complexity, we design a streamlined and asymmetricchannel-adaptive joint semantic-channel coding architecture, where only theencoder needs the feedback of average signal-to-noise ratio (SNR) and availablebandwidth. In addition, rectified denoising diffusion implicit models isemployed to accelerate the decoding process to the millisecond level, enablingreal-time PC communication. Unlike existing methods, GenSeC-PC leveragesgenerative priors to ensure reliable reconstruction even from noisy orincomplete source PCs. More importantly, it supports fully analog transmission,improving compression efficiency by eliminating the need for error-free sideinformation transmission common in prior SemCom approaches. Simulation resultsconfirm the effectiveness of cross-modal semantic extraction and dual-metricguided fine-tuning, highlighting the framework's robustness across diverseconditions, including low SNR, bandwidth limitations, varying numbers of 2Dimages, and previously unseen objects.</description>
      <author>example@mail.com (Wanting Yang, Zehui Xiong, Qianqian Yang, Ping Zhang, Merouane Debbah, Rahim Tafazolli)</author>
      <guid isPermaLink="false">2506.03211v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Towards Source Attribution of Singing Voice Deepfake with Multimodal Foundation Models</title>
      <link>http://arxiv.org/abs/2506.03364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to INTERSPEECH 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了唱歌声音深度伪造源归因（SVDSA）任务，并提出了多模态基础模型（MMFMs）在SVDSA中的有效性，通过实验验证了这一假设，并提出了一种新的框架COFFE，用于FM的有效融合。&lt;h4&gt;背景&lt;/h4&gt;唱歌声音深度伪造源归因（SVDSA）是一个新兴的研究领域，旨在识别和归因唱歌声音深度伪造的来源。&lt;h4&gt;目的&lt;/h4&gt;研究多模态基础模型（MMFMs）在唱歌声音深度伪造源归因（SVDSA）任务中的有效性，并提出一种新的框架以改善该任务的表现。&lt;h4&gt;方法&lt;/h4&gt;通过实验验证了MMFMs在SVDSA中的有效性，并提出了一个名为COFFE的新框架，该框架使用Chernoff Distance作为新的损失函数，以实现基础模型的有效融合。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MMFMs在SVDSA任务中是最有效的，并且通过COFFE框架融合MMFMs可以获得比单个FM和基线融合方法更优的性能。&lt;h4&gt;结论&lt;/h4&gt;多模态基础模型（MMFMs）在唱歌声音深度伪造源归因（SVDSA）任务中表现出色，通过COFFE框架融合MMFMs可以提高SVDSA的性能。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we introduce the task of singing voice deepfake sourceattribution (SVDSA). We hypothesize that multimodal foundation models (MMFMs)such as ImageBind, LanguageBind will be most effective for SVDSA as they arebetter equipped for capturing subtle source-specific characteristics-such asunique timbre, pitch manipulation, or synthesis artifacts of each singing voicedeepfake source due to their cross-modality pre-training. Our experiments withMMFMs, speech foundation models and music foundation models verify thehypothesis that MMFMs are the most effective for SVDSA. Furthermore, inspiredfrom related research, we also explore fusion of foundation models (FMs) forimproved SVDSA. To this end, we propose a novel framework, COFFE which employsChernoff Distance as novel loss function for effective fusion of FMs. ThroughCOFFE with the symphony of MMFMs, we attain the topmost performance incomparison to all the individual FMs and baseline fusion methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we introduce the task of singing voice deepfake sourceattribution (SVDSA). We hypothesize that multimodal foundation models (MMFMs)such as ImageBind, LanguageBind will be most effective for SVDSA as they arebetter equipped for capturing subtle source-specific characteristics-such asunique timbre, pitch manipulation, or synthesis artifacts of each singing voicedeepfake source due to their cross-modality pre-training. Our experiments withMMFMs, speech foundation models and music foundation models verify thehypothesis that MMFMs are the most effective for SVDSA. Furthermore, inspiredfrom related research, we also explore fusion of foundation models (FMs) forimproved SVDSA. To this end, we propose a novel framework, COFFE which employsChernoff Distance as novel loss function for effective fusion of FMs. ThroughCOFFE with the symphony of MMFMs, we attain the topmost performance incomparison to all the individual FMs and baseline fusion methods.</description>
      <author>example@mail.com (Orchid Chetia Phukan, Girish, Mohd Mujtaba Akhtar, Swarup Ranjan Behera, Priyabrata Mallick, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma)</author>
      <guid isPermaLink="false">2506.03364v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>HYFuse: Aligning Heterogeneous Speech Pre-Trained Representations in Hyperbolic Space for Speech Emotion Recognition</title>
      <link>http://arxiv.org/abs/2506.03403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to INTERSPEECH 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于压缩的表示（CBRs）和基于表示学习的表示（RLRs）在语音情感识别（SER）中的应用，并提出了一个名为HYFuse的新框架，通过将表示转换为双曲空间来实现RLRs和CBRs的融合。&lt;h4&gt;背景&lt;/h4&gt;CBRs如EnCodec能够捕捉到声学特征，而RLRs如WavLM能够编码高级语义和韵律信息。尽管两者都用于SER，但它们之间的融合尚未被探索。&lt;h4&gt;目的&lt;/h4&gt;填补CBRs和RLRs融合的空白，并验证融合后的表示是否提供互补信息，从而提高SER的性能。&lt;h4&gt;方法&lt;/h4&gt;提出HYFuse框架，通过将x-vector（RLR）和Soundstream（CBR）的表示转换为双曲空间进行融合。&lt;h4&gt;主要发现&lt;/h4&gt;通过HYFuse融合RLRs和CBRs，实现了比单个表示或同质融合更好的性能，并报告了最先进的成果（SOTA）。&lt;h4&gt;结论&lt;/h4&gt;HYFuse框架有效融合了RLRs和CBRs，提高了SER的性能，为未来的研究提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了基于压缩的表示（CBRs）和基于表示学习的表示（RLRs）在语音情感识别（SER）中的应用，并提出了一种名为HYFuse的新框架，通过将表示转换为双曲空间来实现RLRs和CBRs的融合。研究发现，通过HYFuse融合RLRs和CBRs，能够实现比单个表示或同质融合更好的性能，并达到了最先进的水平（SOTA）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Compression-based representations (CBRs) from neural audio codecs such asEnCodec capture intricate acoustic features like pitch and timbre, whilerepresentation-learning-based representations (RLRs) from pre-trained modelstrained for speech representation learning such as WavLM encode high-levelsemantic and prosodic information. Previous research on Speech EmotionRecognition (SER) has explored both, however, fusion of CBRs and RLRs haven'tbeen explored yet. In this study, we solve this gap and investigate the fusionof RLRs and CBRs and hypothesize they will be more effective by providingcomplementary information. To this end, we propose, HYFuse, a novel frameworkthat fuses the representations by transforming them to hyperbolic space. WithHYFuse, through fusion of x-vector (RLR) and Soundstream (CBR), we achieve thetop performance in comparison to individual representations as well as thehomogeneous fusion of RLRs and CBRs and report SOTA.</description>
      <author>example@mail.com (Orchid Chetia Phukan, Girish, Mohd Mujtaba Akhtar, Swarup Ranjan Behera, Pailla Balakrishna Reddy, Arun Balaji Buduru, Rajesh Sharma)</author>
      <guid isPermaLink="false">2506.03403v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>A Multimodal, Multilingual, and Multidimensional Pipeline for Fine-grained Crowdsourcing Earthquake Damage Evaluation</title>
      <link>http://arxiv.org/abs/2506.03360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种结构化的多模态、多语言、多维度（3M）管道，利用多模态大型语言模型（MLLMs）来评估灾害影响，以提高灾害损失评估的速度和准确性。&lt;h4&gt;背景&lt;/h4&gt;快速、细粒度的灾害损失评估对于有效的应急响应至关重要，但由于地面传感器的限制和官方报告的延迟，这仍然是一个挑战。社交媒体提供了丰富的人本观察数据，但其多模态和非结构化的性质给传统的分析方法带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在利用社交媒体数据，通过多模态大型语言模型来提高灾害损失评估的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;研究评估了三种基础模型在两次主要地震事件中的表现，并使用宏观和微观分析进行评估。该方法利用MLLMs整合图像和文本信号，并与地面真值地震数据进行关联。&lt;h4&gt;主要发现&lt;/h4&gt;MLLMs能够有效地整合图像-文本信号，并显示出与地面真值地震数据之间强烈的关联。然而，性能因语言、震中距离和输入模态而异。&lt;h4&gt;结论&lt;/h4&gt;该研究突出了MLLMs在灾害评估中的潜力，并为未来将MLLMs应用于实时危机情境的研究奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译为中文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Rapid, fine-grained disaster damage assessment is essential for effectiveemergency response, yet remains challenging due to limited ground sensors anddelays in official reporting. Social media provides a rich, real-time source ofhuman-centric observations, but its multimodal and unstructured nature presentschallenges for traditional analytical methods. In this study, we propose astructured Multimodal, Multilingual, and Multidimensional (3M) pipeline thatleverages multimodal large language models (MLLMs) to assess disaster impacts.We evaluate three foundation models across two major earthquake events usingboth macro- and micro-level analyses. Results show that MLLMs effectivelyintegrate image-text signals and demonstrate a strong correlation withground-truth seismic data. However, performance varies with language,epicentral distance, and input modality. This work highlights the potential ofMLLMs for disaster assessment and provides a foundation for future research inapplying MLLMs to real-time crisis contexts. The code and data are released at:https://github.com/missa7481/EMNLP25_earthquake</description>
      <author>example@mail.com (Zihui Ma, Lingyao Li, Juan Li, Wenyue Hua, Jingxiao Liu, Qingyuan Feng, Yuki Miura)</author>
      <guid isPermaLink="false">2506.03360v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>SAB3R: Semantic-Augmented Backbone in 3D Reconstruction</title>
      <link>http://arxiv.org/abs/2506.02112v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  3D-LLM/VLA @ CVPR2025 | Project page:  https://uva-computer-vision-lab.github.io/sab3r/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Map and Locate的新任务，该任务将基于自然语言查询的对象实例检测和分割（开放词汇分割）与3D重建（从视觉输入中估计场景的3D结构）的传统不同目标统一。&lt;h4&gt;背景&lt;/h4&gt;传统的开放词汇分割和3D重建是两个独立的任务，本文提出的新任务旨在将它们结合。&lt;h4&gt;目的&lt;/h4&gt;Map and Locate任务旨在生成从无姿态视频中的点云，并基于开放词汇查询进行对象实例分割，为现实世界的具身人工智能应用提供一个关键步骤。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种名为SAB3R的简单而有效的基线，它基于MASt3R（3D计算机视觉领域的最新突破）并采用轻量级蒸馏策略。SAB3R通过将密集的、每像素的语义特征从2D视觉骨干网络（如CLIP和DINOv2）传递到MASt3R中，来增强其能力。该模型在不引入任何辅助冻结网络的情况下，在单次前向传递中生成每像素语义特征并构建连贯的点云图。&lt;h4&gt;主要发现&lt;/h4&gt;与分别部署MASt3R和CLIP相比，SAB3R在Map and Locate基准测试上实现了优越的性能。此外，SAB3R在2D语义分割和3D任务上的评估表明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;SAB3R模型通过结合开放词汇分割和3D重建，为Map and Locate任务提供了有效的方法，为现实世界中的应用铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a new task, Map and Locate, which unifies the traditionallydistinct objectives of open-vocabulary segmentation - detecting and segmentingobject instances based on natural language queries - and 3D reconstruction, theprocess of estimating a scene's 3D structure from visual inputs. Specifically,Map and Locate involves generating a point cloud from an unposed video andsegmenting object instances based on open-vocabulary queries. This task servesas a critical step toward real-world embodied AI applications and introduces apractical task that bridges reconstruction, recognition and reorganization. Totackle this task, we introduce a simple yet effective baseline, which we denoteas SAB3R. Our approach builds upon MASt3R, a recent breakthrough in 3D computervision, and incorporates a lightweight distillation strategy. This methodtransfers dense, per-pixel semantic features from 2D vision backbones (eg, CLIPand DINOv2) to enhance MASt3R's capabilities. Without introducing any auxiliaryfrozen networks, our model generates per-pixel semantic features and constructscohesive point maps in a single forward pass. Compared to separately deployingMASt3R and CLIP, our unified model, SAB3R, achieves superior performance on theMap and Locate benchmark. Furthermore, we evaluate SAB3R on both 2D semanticsegmentation and 3D tasks to comprehensively validate its effectiveness.</description>
      <author>example@mail.com (Xuweiyi Chen, Tian Xia, Sihan Xu, Jianing Yang, Joyce Chai, Zezhou Cheng)</author>
      <guid isPermaLink="false">2506.02112v2</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Open-PMC-18M: A High-Fidelity Large Scale Medical Dataset for Multimodal Representation Learning</title>
      <link>http://arxiv.org/abs/2506.02738v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer对象检测的子图提取流程，用于大规模子图提取，并构建了一个大规模的生物医学视觉语言数据集，用于提高视觉语言模型的表现。&lt;h4&gt;背景&lt;/h4&gt;复合图在生物医学文献中很常见，但大规模子图提取尚未得到充分解决，先前的研究在数据集规模和泛化能力方面有限。&lt;h4&gt;目的&lt;/h4&gt;研究通过大规模子图提取实现高保真图像-文本对齐对视觉语言模型中的表示学习的影响。&lt;h4&gt;方法&lt;/h4&gt;开发了一个可扩展的子图提取流程，并在包含50万张复合图的合成语料库上训练，同时在ImageCLEF2016和合成基准上取得了最先进的性能。构建了一个包含1800万个与临床相关的子图-标题对的OPEN-PMC-18M大规模高质量生物医学视觉语言数据集。&lt;h4&gt;主要发现&lt;/h4&gt;使用该流程，在检索、零样本分类和鲁棒性基准测试中，视觉语言模型的表现得到提升，超过了现有基线。&lt;h4&gt;结论&lt;/h4&gt;发布的子图提取流程、数据集、模型和代码支持可重复的基准测试，并促进了生物医学视觉语言建模和表示学习的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：复合图，即包含多个子图的复合图像，在生物医学文献中普遍存在，但大规模子图提取仍然没有得到充分解决。先前关于子图提取的研究在数据集规模和泛化能力方面都有限，留下了一个关键性的未解决问题：通过大规模子图提取实现的高保真图像-文本对齐如何影响视觉语言模型中的表示学习？我们通过引入一个基于Transformer对象检测的可扩展子图提取流程来填补这一空白，该流程在包含50万张复合图的合成语料库上进行了训练，并在ImageCLEF2016和合成基准上实现了最先进的性能。使用此流程，我们发布了OPEN-PMC-18M，这是一个包含1800万个与临床相关的子图-标题对的大规模高质量生物医学视觉语言数据集，涵盖了放射学、显微镜和可见光摄影。我们在我们精心制作的数据集上训练和评估了视觉语言模型，并在检索、零样本分类和鲁棒性基准测试中展示了改进的表现，超过了现有基线。我们发布了我们的数据集、模型和代码，以支持可重复的基准测试和进一步研究生物医学视觉语言建模和表示学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Compound figures, which are multi-panel composites containing diversesubfigures, are ubiquitous in biomedical literature, yet large-scale subfigureextraction remains largely unaddressed. Prior work on subfigure extraction hasbeen limited in both dataset size and generalizability, leaving a critical openquestion: How does high-fidelity image-text alignment via large-scale subfigureextraction impact representation learning in vision-language models? We addressthis gap by introducing a scalable subfigure extraction pipeline based ontransformer-based object detection, trained on a synthetic corpus of 500,000compound figures, and achieving state-of-the-art performance on both ImageCLEF2016 and synthetic benchmarks. Using this pipeline, we release OPEN-PMC-18M, alarge-scale high quality biomedical vision-language dataset comprising 18million clinically relevant subfigure-caption pairs spanning radiology,microscopy, and visible light photography. We train and evaluatevision-language models on our curated datasets and show improved performanceacross retrieval, zero-shot classification, and robustness benchmarks,outperforming existing baselines. We release our dataset, models, and code tosupport reproducible benchmarks and further study into biomedicalvision-language modeling and representation learning.</description>
      <author>example@mail.com (Negin Baghbanzadeh, Sajad Ashkezari, Elham Dolatabadi, Arash Afkanpour)</author>
      <guid isPermaLink="false">2506.02738v2</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>The Future of Continual Learning in the Era of Foundation Models: Three Key Directions</title>
      <link>http://arxiv.org/abs/2506.03320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 1 figure, accepted at TCAI workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要讨论了持续学习在人工智能中的重要性，尽管深度学习和大语言模型的出现提出了挑战，但持续学习仍然对于保持模型更新、实现个性化适应和构建可扩展智能系统至关重要。&lt;h4&gt;背景&lt;/h4&gt;持续学习是人类和人工智能智能的核心能力。早期人工智能系统强调了增量知识巩固，而强化学习强调了动态适应。&lt;h4&gt;目的&lt;/h4&gt;探讨持续学习在深度学习时代和大型语言模型出现后的地位。&lt;h4&gt;方法&lt;/h4&gt;分析不同人工智能范式对持续学习的不同需求，并提出持续学习的三个关键理由。&lt;h4&gt;主要发现&lt;/h4&gt;持续学习对于保持基础模型更新、实现模型特化和个性化、以及构建可扩展智能系统是必要的。&lt;h4&gt;结论&lt;/h4&gt;持续学习将继续在人工智能的发展中扮演关键角色，未来的AI将由不断进化和互动的模型生态系统定义。&lt;h4&gt;翻译&lt;/h4&gt;持续学习——在时间上获取、保留和精炼知识的能力——始终是人类和人工智能智能的基本要素。历史上，不同的AI范式已经承认这种需求，尽管优先级不同：早期的专家系统和生产系统侧重于增量知识整合，而强化学习则强调动态适应。随着深度学习的兴起，深度持续学习主要侧重于在学习时间上学习稳健和可重用表示，以解决越来越复杂的任务序列。然而，大型语言模型（LLMs）和基础模型的出现引发了这样的问题：当中心化、单一大模型可以处理具有互联网规模知识的各种任务时，我们是否仍然需要持续学习？我们认为，持续学习对于以下三个关键原因仍然是必要的：（一）持续的预训练仍然有必要以确保基础模型保持最新，减轻知识陈旧和分布偏移，同时整合新信息；（二）持续的微调使模型能够特化和个性化，适应特定领域任务、用户偏好和现实世界限制，而无需全面重新训练，避免需要计算昂贵的长上下文窗口；（三）持续的组合性提供了一种可扩展和模块化的智能方法，使得基础模型和代理可以动态组合、重组和适应。尽管持续预训练和微调被视为利基研究方向，但我们认为持续的组合性将标志着持续学习的重生。人工智能的未来将由一个不断进化和互动的模型生态系统来定义，持续学习比以往任何时候都更加相关。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual learning--the ability to acquire, retain, and refine knowledge overtime--has always been fundamental to intelligence, both human and artificial.Historically, different AI paradigms have acknowledged this need, albeit withvarying priorities: early expert and production systems focused on incrementalknowledge consolidation, while reinforcement learning emphasised dynamicadaptation. With the rise of deep learning, deep continual learning hasprimarily focused on learning robust and reusable representations over time tosolve sequences of increasingly complex tasks. However, the emergence of LargeLanguage Models (LLMs) and foundation models has raised the question: Do westill need continual learning when centralised, monolithic models can tacklediverse tasks with access to internet-scale knowledge? We argue that continuallearning remains essential for three key reasons: (i) continual pre-training isstill necessary to ensure foundation models remain up to date, mitigatingknowledge staleness and distribution shifts while integrating new information;(ii) continual fine-tuning enables models to specialise and personalise,adapting to domain-specific tasks, user preferences, and real-world constraintswithout full retraining, avoiding the need for computationally expensive longcontext-windows; (iii) continual compositionality offers a scalable and modularapproach to intelligence, enabling the orchestration of foundation models andagents to be dynamically composed, recombined, and adapted. While continualpre-training and fine-tuning are explored as niche research directions, weargue it is continual compositionality that will mark the rebirth of continuallearning. The future of AI will not be defined by a single static model but byan ecosystem of continually evolving and interacting models, making continuallearning more relevant than ever.</description>
      <author>example@mail.com (Jack Bell, Luigi Quarantiello, Eric Nuertey Coleman, Lanpei Li, Malio Li, Mauro Madeddu, Elia Piccoli, Vincenzo Lomonaco)</author>
      <guid isPermaLink="false">2506.03320v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Human Fall Detection using Transfer Learning-based 3D CNN</title>
      <link>http://arxiv.org/abs/2506.03193v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于3D CNN的视觉跌倒检测系统，用于解决老年人跌倒这一健康问题。&lt;h4&gt;背景&lt;/h4&gt;随着老年人人口的稳步增长，跌倒成为了重要的健康问题。&lt;h4&gt;目的&lt;/h4&gt;开发一个自动化的跌倒检测监控系统。&lt;h4&gt;方法&lt;/h4&gt;使用预训练的3D CNN模型来提取时空特征，并通过支持向量机（SVM）分类器进行活动分类。&lt;h4&gt;主要发现&lt;/h4&gt;该系统仅训练了SVM分类器，从而节省了训练3D CNN所需的时间。实验使用了GMDCSA和CAUCAFall两个数据集。&lt;h4&gt;结论&lt;/h4&gt;通过使用3D CNN模型和SVM分类器，该系统能够有效地检测跌倒事件。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a vision-based fall detection system using a pre-trained 3D CNN to address the health issue of unintentional falls in the elderly population. With the steady increase in the elderly population, falls have become a significant health concern. The aim is to develop an automated fall detection monitoring system. The method involves using a pre-trained 3D CNN model to extract spatio-temporal features and a support vector machine (SVM) classifier for activity classification. The system only trained the SVM classifier to save the time required for training the 3D CNN. The experiments were conducted using the GMDCSA and CAUCAFall datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-3-031-81935-3_9&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unintentional or accidental falls are one of the significant health issues insenior persons. The population of senior persons is increasing steadily. So,there is a need for an automated fall detection monitoring system. This paperintroduces a vision-based fall detection system using a pre-trained 3D CNN.Unlike 2D CNN, 3D CNN extracts not only spatial but also temporal features. Theproposed model leverages the original learned weights of a 3D CNN modelpre-trained on the Sports1M dataset to extract the spatio-temporal features.Only the SVM classifier was trained, which saves the time required to train the3D CNN. Stratified shuffle five split cross-validation has been used to splitthe dataset into training and testing data. Extracted features from theproposed 3D CNN model were fed to an SVM classifier to classify the activity asfall or ADL. Two datasets, GMDCSA and CAUCAFall, were utilized to conduct theexperiment. The source code for this work can be accessed via the followinglink: https://github.com/ekramalam/HFD_3DCNN.</description>
      <author>example@mail.com (Ekram Alam, Abu Sufian, Paramartha Dutta, Marco Leo)</author>
      <guid isPermaLink="false">2506.03193v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>MobCLIP: Learning General-purpose Geospatial Representation at Scale</title>
      <link>http://arxiv.org/abs/2506.01297v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MobCLIP是一种新型的地理空间位置表示学习方法，通过多模态融合技术，实现了对地理空间位置的高效和可扩展的表示学习。&lt;h4&gt;背景&lt;/h4&gt;地理空间位置的表示学习是实现通用地理空间智能的核心挑战，现有的嵌入方法通常缺乏多样性，限制了其在人类和自然领域各种任务中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出MobCLIP，作为第一个全国性的通用目的位置编码器，旨在通过有效和可扩展的多模态融合技术，整合多样化的数据模式。&lt;h4&gt;方法&lt;/h4&gt;采用基于CLIP的新型架构，将超过1亿个POI、全国范围的遥感影像和结构化人口统计数据与一个包含十亿条边的移动性图相结合。通过将空间位置划分为受Vision Transformers启发的网格单元，建立一个连接移动模式和多模态特征的统一表示空间。&lt;h4&gt;主要发现&lt;/h4&gt;MobCLIP在包含11个下游预测任务的基准数据集上，与最先进的模型相比，平均提高了35%的通用预测性能。在以人为中心的任务中，如能耗预测、线下零售消费额预测和犯罪案件预测，性能提升尤为显著。&lt;h4&gt;结论&lt;/h4&gt;MobCLIP通过有效集成以人为中心的模态，在以人为中心的任务中实现了显著的性能提升，并展示了地理空间表示学习中的扩展行为。&lt;h4&gt;翻译&lt;/h4&gt;Representation learning of geospatial locations remains a core challenge in achieving general geospatial intelligence. Current embedding methods often lack versatility, limiting their utility across diverse tasks in both human and natural domains. We present MobCLIP, the first nationwide general-purposelocation encoder, integrating an unprecedented diversity of data modalitiesthrough effective and scalable multimodal fusion. Adopting a novel CLIP-based architecture, our framework aligns 100M+ POIs, nationwide remote sensing imagery, and structured demographic statistics with a billion-edge mobility graph. By tokenizing spatial locations into grid cells inspired by Vision Transformers, we establish a unified representation space bridging mobility patterns and multimodal features. To rigorously evaluate the general-purpose effectiveness of MobCLIP, we construct a benchmark dataset composed of 11 downstream prediction tasks across social, economic, and natural domains. Experiments show that MobCLIP, with four input modalities and a compact 128-dimensional representation space, achieves significantly superiorgeneral-purpose predictive performances than state-of-the-art models by anaverage of 35%. Thanks to the effective integration of human-centricmodalities, the performance gain is particularly profound in human-centrictasks, such as energy consumption (+260%), offline retail consumption amount(+98%), and crime cases (+95%) predictions. Echoing LLM scaling laws, wefurther demonstrate the scaling behavior in geospatial representation learning.We open-source code and pretrained models at:https://github.com/ylzhouchris/MobCLIP.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning of geospatial locations remains a core challenge inachieving general geospatial intelligence. Current embedding methods often lackversatility, limiting their utility across diverse tasks in both human andnatural domains. We present MobCLIP, the first nationwide general-purposelocation encoder, integrating an unprecedented diversity of data modalitiesthrough effective and scalable multimodal fusion. Adopting a novel CLIP-basedarchitecture, our framework aligns 100M+ POIs, nationwide remote sensingimagery, and structured demographic statistics with a billion-edge mobilitygraph. By tokenizing spatial locations into grid cells inspired by VisionTransformers, we establish a unified representation space bridging mobilitypatterns and multimodal features. To rigorously evaluate the general-purposeeffectiveness of MobCLIP, we construct a benchmark dataset composed of 11downstream prediction tasks across social, economic, and natural domains.Experiments show that MobCLIP, with four input modalities and a compact128-dimensional representation space, achieves significantly superiorgeneral-purpose predictive performances than state-of-the-art models by anaverage of 35%. Thanks to the effective integration of human-centricmodalities, the performance gain is particularly profound in human-centrictasks, such as energy consumption (+260%), offline retail consumption amount(+98%), and crime cases (+95%) predictions. Echoing LLM scaling laws, wefurther demonstrate the scaling behavior in geospatial representation learning.We open-source code and pretrained models at:https://github.com/ylzhouchris/MobCLIP.</description>
      <author>example@mail.com (Ya Wen, Jixuan Cai, Qiyao Ma, Linyan Li, Xinhua Chen, Chris Webster, Yulun Zhou)</author>
      <guid isPermaLink="false">2506.01297v3</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Learning 3D Representations from Procedural 3D Programs</title>
      <link>http://arxiv.org/abs/2411.17467v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SynData4CV @ CVPR2025 | Project Page:  https://point-mae-zero.cs.virginia.edu/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从无标签3D点云中获取可迁移3D表示的方法，通过自监督学习从程序性3D程序中学习3D表示，这些程序使用简单的原语和增强自动生成3D形状。&lt;h4&gt;背景&lt;/h4&gt;获取3D资产需要专业知识或专业3D扫描设备，这使得3D数据的获取难以规模化，并引发版权问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过程序性3D程序自动生成3D形状，从而解决3D数据获取的挑战。&lt;h4&gt;方法&lt;/h4&gt;使用程序性3D程序学习3D表示，这些程序通过简单的原语和增强自动生成3D形状。&lt;h4&gt;主要发现&lt;/h4&gt;从程序性生成的3D形状中学习的3D表示，在形状分类、部分分割和掩码点云补全等下游3D任务中，其性能与从语义可识别的3D模型（如飞机）学习的最先进表示相当。&lt;h4&gt;结论&lt;/h4&gt;当前自监督学习在点云上的方法不依赖于3D形状的语义，揭示了学习的3D表示的本质。&lt;h4&gt;翻译&lt;/h4&gt;自监督学习已成为从无标签3D点云中获取可迁移3D表示的有前途的方法。与广泛可用的2D图像不同，获取3D资产需要专门的专家或专业3D扫描设备，这使得规模化变得困难，并引发了版权问题。为了解决这些挑战，我们提出从程序性3D程序中学习3D表示，这些程序使用简单的原语和增强自动生成3D形状。令人惊讶的是，尽管缺乏语义内容，从程序性生成的3D形状中学习的3D表示在包括形状分类、部分分割和掩码点云补全在内的各种下游3D任务中，其性能与从语义可识别的3D模型（例如飞机）学习的最先进表示相当。我们对构成良好的3D程序性程序的因素进行了详细分析。大量实验进一步表明，当前自监督学习方法在点云上不依赖于3D形状的语义，揭示了学习的3D表示的本质。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning has emerged as a promising approach for acquiringtransferable 3D representations from unlabeled 3D point clouds. Unlike 2Dimages, which are widely accessible, acquiring 3D assets requires specializedexpertise or professional 3D scanning equipment, making it difficult to scaleand raising copyright concerns. To address these challenges, we proposelearning 3D representations from procedural 3D programs that automaticallygenerate 3D shapes using simple primitives and augmentations. Remarkably,despite lacking semantic content, the 3D representations learned from theprocedurally generated 3D shapes perform on par with state-of-the-artrepresentations learned from semantically recognizable 3D models (e.g.,airplanes) across various downstream 3D tasks, including shape classification,part segmentation, and masked point cloud completion. We provide a detailedanalysis on factors that make a good 3D procedural program. Extensiveexperiments further suggest that current self-supervised learning methods onpoint clouds do not rely on the semantics of 3D shapes, shedding light on thenature of 3D representations learned.</description>
      <author>example@mail.com (Xuweiyi Chen, Zezhou Cheng)</author>
      <guid isPermaLink="false">2411.17467v2</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Future-Oriented Navigation: Dynamic Obstacle Avoidance with One-Shot Energy-Based Multimodal Motion Prediction</title>
      <link>http://arxiv.org/abs/2505.00237v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in IEEE Robotics and Automation Letters (RA-L)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在动态和不确定环境中安全高效控制移动机器人的集成方法。&lt;h4&gt;背景&lt;/h4&gt;移动机器人在动态和不确定环境中的控制是一个复杂的问题。&lt;h4&gt;目的&lt;/h4&gt;旨在实现移动机器人在动态环境中的有效导航。&lt;h4&gt;方法&lt;/h4&gt;方法包括：一次性多模态运动预测和模型预测控制。运动预测由基于能量的神经网络驱动，生成高分辨率、多步预测。预测结果用于创建作为数学约束的几何形状。动态障碍物通过无监督方式按邻近性分组，以提高性能和效率。整体无碰撞导航由具有特定设计的前瞻性动态障碍物避免的模型预测控制处理。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在不同场景中表现出色，这些场景代表了典型的仓库设置。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了所提出的方法优于其他现有的动态障碍物避免方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种针对动态和不确定环境的移动机器人安全高效控制方法。该方法包含两个关键步骤：一次性多模态运动预测和模型预测控制。运动预测由基于能量的神经网络驱动，产生高分辨率、多步预测。预测结果被进一步利用来创建数学约束下的几何形状。不是单独处理每个动态障碍物，而是通过无监督方式按邻近性对预测的障碍物进行分组，以提高性能和效率。整体无碰撞导航由具有特定设计的前瞻性动态障碍物避免的模型预测控制处理。在代表典型仓库设置的多种场景中对该方法进行了测试，结果表明该方法优于其他现有的动态障碍物避免方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an integrated approach for the safe and efficient controlof mobile robots in dynamic and uncertain environments. The approach consistsof two key steps: one-shot multimodal motion prediction to anticipate motionsof dynamic obstacles and model predictive control to incorporate thesepredictions into the motion planning process. Motion prediction is driven by anenergy-based neural network that generates high-resolution, multi-steppredictions in a single operation. The prediction outcomes are further utilizedto create geometric shapes formulated as mathematical constraints. Instead oftreating each dynamic obstacle individually, predicted obstacles are grouped byproximity in an unsupervised way to improve performance and efficiency. Theoverall collision-free navigation is handled by model predictive control with aspecific design for proactive dynamic obstacle avoidance. The proposed approachallows mobile robots to navigate effectively in dynamic environments. Itsperformance is accessed across various scenarios that represent typicalwarehouse settings. The results demonstrate that the proposed approachoutperforms other existing dynamic obstacle avoidance methods.</description>
      <author>example@mail.com (Ze Zhang, Georg Hess, Junjie Hu, Emmanuel Dean, Lennart Svensson, Knut Åkesson)</author>
      <guid isPermaLink="false">2505.00237v3</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Lightweight Convolutional Neural Networks for Retinal Disease Classification</title>
      <link>http://arxiv.org/abs/2506.03186v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视网膜疾病如糖尿病视网膜病变（DR）和黄斑孔（MH）对视力的影响，并采用MobileNet和NASNetMobile两种轻量级卷积神经网络进行视网膜图像分类，以提高早期诊断的准确性。&lt;h4&gt;背景&lt;/h4&gt;视网膜疾病如DR和MH严重影响视力，早期检测至关重要，DR可能导致失明，MH则影响阅读和面部识别等任务。&lt;h4&gt;目的&lt;/h4&gt;利用卷积神经网络（CNN）进行视网膜疾病分类，为AI辅助眼科诊断和早期干预提供基础。&lt;h4&gt;方法&lt;/h4&gt;在RFMiD数据集上训练模型，该数据集包含3,200张眼底图像，经过预处理如调整大小、归一化和增强。为解决数据稀缺问题，采用了迁移学习和数据增强技术。&lt;h4&gt;主要发现&lt;/h4&gt;MobileNetV2实现了90.8%的最高准确率，优于NASNetMobile的89.5%准确率。&lt;h4&gt;结论&lt;/h4&gt;CNN在视网膜疾病分类中表现出有效性，为AI辅助眼科诊断和早期干预提供了支持。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the impact of retinal diseases such as Diabetic Retinopathy (DR) and Macular Hole (MH) on vision, and employs two lightweight and efficient Convolution Neural Network architectures, MobileNet and NASNetMobile, for the classification of Normal, DR, and MH retinal images, in order to improve the accuracy of early detection. The models were trained on the RFMiD dataset, which consists of 3,200 fundus images after preprocessing steps such as resizing, normalization, and augmentation. To address the issue of data scarcity, this study utilizes transfer learning and data augmentation techniques to enhance model generalization and performance. The experimental results demonstrate that MobileNetV2 achieves the highest accuracy of 90.8%, outperforming NASNetMobile, which achieves 89.5% accuracy. These findings highlight the effectiveness of CNNs in retinal disease classification, providing a foundation for AI-assisted ophthalmic diagnosis and early intervention.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retinal diseases such as Diabetic Retinopathy (DR) and Macular Hole (MH)significantly impact vision and affect millions worldwide. Early detection iscrucial, as DR, a complication of diabetes, damages retinal blood vessels,potentially leading to blindness, while MH disrupts central vision, affectingtasks like reading and facial recognition. This paper employed two lightweightand efficient Convolution Neural Network architectures, MobileNet andNASNetMobile, for the classification of Normal, DR, and MH retinal images. Themodels were trained on the RFMiD dataset, consisting of 3,200 fundus images,after undergoing preprocessing steps such as resizing, normalization, andaugmentation. To address data scarcity, this study leveraged transfer learningand data augmentation techniques, enhancing model generalization andperformance. The experimental results demonstrate that MobileNetV2 achieved thehighest accuracy of 90.8%, outperforming NASNetMobile, which achieved 89.5%accuracy. These findings highlight the effectiveness of CNNs in retinal diseaseclassification, providing a foundation for AI-assisted ophthalmic diagnosis andearly intervention.</description>
      <author>example@mail.com (Duaa Kareem Qasim, Sabah Abdulazeez Jebur, Lafta Raheem Ali, Abdul Jalil M. Khalaf, Abir Jaafar Hussain)</author>
      <guid isPermaLink="false">2506.03186v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Jamming Source Localization</title>
      <link>http://arxiv.org/abs/2506.03196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文首次将基于图的学习应用于干扰源定位，解决无线网络中干扰攻击的威胁。&lt;h4&gt;背景&lt;/h4&gt;基于图的学习在建模复杂关系方面显示出巨大的潜力，但在无线安全领域的应用尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于图学习的干扰源定位方法，以应对无线网络中干扰攻击的挑战。&lt;h4&gt;方法&lt;/h4&gt;将定位问题重新定义为归纳图回归任务，采用结构化节点表示，集成局部和全局信号聚合，确保空间一致性和自适应信号融合。通过注意力机制增强网络鲁棒性，并引入置信度引导的估计机制，动态平衡学习预测与领域先验。&lt;h4&gt;主要发现&lt;/h4&gt;在复杂射频环境中，该方法在信号信息稀疏和模糊的挑战场景下，显著优于现有的定位基准。&lt;h4&gt;结论&lt;/h4&gt;基于图学习的框架在干扰源定位方面表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Graph-based learning has emerged as a transformative approach for modeling complex relationships across diverse domains, yet its potential in wireless security remains largely unexplored. In this work, we introduce the first application of graph-based learning for jamming source localization, addressing the imminent threat of jamming attacks in wireless networks. Unlike geometric optimization techniques that struggle under environmental uncertainties and dense interference, we reformulate localization as an inductive graph regression task. Our approach integrates structured node representations that encode local and global signal aggregation, ensuring spatial coherence and adaptive signal fusion. To enhance robustness, we incorporate an attention-based graph neural network that adaptively refines neighborhood influence and introduces a confidence-guided estimation mechanism that dynamically balances learned predictions with domain-informed priors. We evaluate our approach under complex radio frequency environments with varying sampling densities and signal propagation conditions, conducting comprehensive ablation studies on graph construction, feature selection, and pooling strategies. Results demonstrate that our novel graph-based learning framework significantly outperforms established localization baselines, particularly in challenging scenarios with sparse and obfuscated signal information. Code is available at [https://github.com/daniaherzalla/gnn-jamming-source-localization](https://github.com/daniaherzalla/gnn-jamming-source-localization).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-based learning has emerged as a transformative approach for modelingcomplex relationships across diverse domains, yet its potential in wirelesssecurity remains largely unexplored. In this work, we introduce the firstapplication of graph-based learning for jamming source localization, addressingthe imminent threat of jamming attacks in wireless networks. Unlike geometricoptimization techniques that struggle under environmental uncertainties anddense interference, we reformulate localization as an inductive graphregression task. Our approach integrates structured node representations thatencode local and global signal aggregation, ensuring spatial coherence andadaptive signal fusion. To enhance robustness, we incorporate anattention-based graph neural network that adaptively refines neighborhoodinfluence and introduces a confidence-guided estimation mechanism thatdynamically balances learned predictions with domain-informed priors. Weevaluate our approach under complex radio frequency environments with varyingsampling densities and signal propagation conditions, conducting comprehensiveablation studies on graph construction, feature selection, and poolingstrategies. Results demonstrate that our novel graph-based learning frameworksignificantly outperforms established localization baselines, particularly inchallenging scenarios with sparse and obfuscated signal information. Code isavailable at[https://github.com/daniaherzalla/gnn-jamming-source-localization](https://github.com/daniaherzalla/gnn-jamming-source-localization).</description>
      <author>example@mail.com (Dania Herzalla, Willian T. Lunardi, Martin Andreoni)</author>
      <guid isPermaLink="false">2506.03196v1</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>MINT: Multimodal Instruction Tuning with Multimodal Interaction Grouping</title>
      <link>http://arxiv.org/abs/2506.02308v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了多模态基础模型在多任务上取得的突破性进展，并提出了一个名为MINT的任务分组策略，以提高多模态指令微调的性能。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型在多个任务上取得了最先进的性能，这得益于新的预训练范式和高质量的提示。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过分组任务来提高多模态指令微调的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于多模态交互类型的简单而有效的任务分组策略MINT。&lt;h4&gt;主要发现&lt;/h4&gt;发现仅仅增加指令微调任务的数量并不总能带来更好的性能，而是通过按模态间的共同交互分组任务，可以鼓励模型在组内学习可迁移的技能，同时减少不匹配任务之间的干扰。&lt;h4&gt;结论&lt;/h4&gt;MINT方法在多模态指令微调中优于现有的任务分组基线，实现了泛化和专业化的有效平衡。&lt;h4&gt;翻译&lt;/h4&gt;摘要：最近在多模态基础模型方面取得的进展，在一系列任务上实现了最先进的性能。这些突破主要是由利用大规模未标记多模态数据的新预训练范式驱动的，随后在精心挑选的标记数据集和高质量提示上进行指令微调。尽管人们对将指令微调扩展到更大规模的数据集（数量和规模）越来越感兴趣，但我们的发现表明，简单地增加指令微调任务的数量并不总能带来更好的性能。相反，我们观察到，通过按模态间的共同交互分组任务，例如发现冗余共享信息、优先选择具有独特信息的模态或要求协同融合以从两种模态中获取新信息，可以鼓励模型在组内学习可迁移的技能，同时抑制不匹配任务之间的干扰。为此，我们引入了MINT，这是一种简单但令人惊讶有效的基于多模态交互类型的任务分组策略。我们证明了所提出的方法在多模态指令微调中大大优于现有的任务分组基线，实现了泛化和专业化的有效平衡。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in multimodal foundation models have achievedstate-of-the-art performance across a range of tasks. These breakthroughs arelargely driven by new pre-training paradigms that leverage large-scale,unlabeled multimodal data, followed by instruction fine-tuning on curatedlabeled datasets and high-quality prompts. While there is growing interest inscaling instruction fine-tuning to ever-larger datasets in both quantity andscale, our findings reveal that simply increasing the number ofinstruction-tuning tasks does not consistently yield better performance.Instead, we observe that grouping tasks by the common interactions acrossmodalities, such as discovering redundant shared information, prioritizingmodality selection with unique information, or requiring synergistic fusion todiscover new information from both modalities, encourages the models to learntransferrable skills within a group while suppressing interference frommismatched tasks. To this end, we introduce MINT, a simple yet surprisinglyeffective task-grouping strategy based on the type of multimodal interaction.We demonstrate that the proposed method greatly outperforms existing taskgrouping baselines for multimodal instruction tuning, striking an effectivebalance between generalization and specialization.</description>
      <author>example@mail.com (Xiaojun Shan, Qi Cao, Xing Han, Haofei Yu, Paul Pu Liang)</author>
      <guid isPermaLink="false">2506.02308v2</guid>
      <pubDate>Thu, 05 Jun 2025 14:27:56 +0800</pubDate>
    </item>
    <item>
      <title>FORLA:Federated Object-centric Representation Learning with Slot Attention</title>
      <link>http://arxiv.org/abs/2506.02964v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为FORLA的新型框架，用于在异构无标签数据集上进行联邦学习中的对象中心表示学习和特征适应。&lt;h4&gt;背景&lt;/h4&gt;在联邦学习中，学习有效的视觉表示是一个核心挑战，需要联合信息跨客户端，同时在不监督的情况下解耦特定领域的因素。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，用于通过无监督的槽位注意力机制，在客户端之间进行联邦对象中心表示学习和特征适应。&lt;h4&gt;方法&lt;/h4&gt;该框架的核心是一个共享的特征适配器，它在客户端之间协作训练以适配基础模型中的特征，以及一个共享的槽位注意力模块，该模块学习重建适配后的特征。为了优化适配器，设计了一个双分支的学生-教师架构，其中每个客户端有一个学生解码器学习从基础模型重建完整特征，而一个教师解码器重建其适配的、低维的对应特征。共享的槽位注意力模块通过在客户端之间对齐对象级表示来实现跨领域学习。&lt;h4&gt;主要发现&lt;/h4&gt;在多个真实世界数据集上的实验表明，该框架不仅在对象发现方面优于集中式基线，而且还学习了一个紧凑的、通用的表示，该表示在各个领域内具有良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;这项工作突出了联邦槽位注意力作为从跨领域数据中可扩展、无监督地进行视觉表示学习的一个有效工具。&lt;h4&gt;翻译&lt;/h4&gt;该论文提出了一种新的联邦学习框架FORLA，用于在异构无标签数据集上进行对象中心的视觉表示学习和特征适应。通过实验证明，该方法在对象发现任务上优于集中式方法，并能学习到在不同领域内具有良好的泛化能力的紧凑表示。联邦槽位注意力机制被证明是跨领域数据无监督视觉表示学习的一个有效工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning efficient visual representations across heterogeneous unlabeleddatasets remains a central challenge in federated learning. Effective federatedrepresentations require features that are jointly informative across clientswhile disentangling domain-specific factors without supervision. We introduceFORLA, a novel framework for federated object-centric representation learningand feature adaptation across clients using unsupervised slot attention. At thecore of our method is a shared feature adapter, trained collaboratively acrossclients to adapt features from foundation models, and a shared slot attentionmodule that learns to reconstruct the adapted features. To optimize thisadapter, we design a two-branch student-teacher architecture. In each client, astudent decoder learns to reconstruct full features from foundation models,while a teacher decoder reconstructs their adapted, low-dimensionalcounterpart. The shared slot attention module bridges cross-domain learning byaligning object-level representations across clients. Experiments in multiplereal-world datasets show that our framework not only outperforms centralizedbaselines on object discovery but also learns a compact, universalrepresentation that generalizes well across domains. This work highlightsfederated slot attention as an effective tool for scalable, unsupervised visualrepresentation learning from cross-domain data with distributed concepts.</description>
      <author>example@mail.com (Guiqiu Liao, Matjaz Jogan, Eric Eaton, Daniel A. Hashimoto)</author>
      <guid isPermaLink="false">2506.02964v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
  <item>
      <title>OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models</title>
      <link>http://arxiv.org/abs/2506.03135v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://qizekun.github.io/omnispatial/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为OmniSpatial的全面且具有挑战性的空间推理基准，旨在解决当前视觉-语言模型在空间推理方面的局限。&lt;h4&gt;背景&lt;/h4&gt;空间推理是认知心理学的一个重要方面，也是当前视觉-语言模型的主要瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出OmniSpatial，一个基于认知心理学的空间推理基准，用于评估和改进视觉-语言模型对基本空间关系的理解。&lt;h4&gt;方法&lt;/h4&gt;通过互联网数据爬取和仔细的人工标注，构建了超过1500个问答对，涵盖动态推理、复杂空间逻辑、空间交互和视角假设四大类别，共计50个细粒度子类别。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，无论是开源还是闭源的视觉-语言模型，以及现有的推理和空间理解模型，在全面的空间理解方面都存在显著局限。&lt;h4&gt;结论&lt;/h4&gt;本文分析了失败案例，并提出了未来研究的潜在方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial reasoning is a key aspect of cognitive psychology and remains a majorbottleneck for current vision-language models (VLMs). While extensive researchhas aimed to evaluate or improve VLMs' understanding of basic spatialrelations, such as distinguishing left from right, near from far, and objectcounting, these tasks represent only the most fundamental level of spatialreasoning. In this work, we introduce OmniSpatial, a comprehensive andchallenging benchmark for spatial reasoning, grounded in cognitive psychology.OmniSpatial covers four major categories: dynamic reasoning, complex spatiallogic, spatial interaction, and perspective-taking, with 50 fine-grainedsubcategories. Through Internet data crawling and careful manual annotation, weconstruct over 1.5K question-answer pairs. Extensive experiments show that bothopen- and closed-source VLMs, as well as existing reasoning and spatialunderstanding models, exhibit significant limitations in comprehensive spatialunderstanding. We further analyze failure cases and propose potentialdirections for future research.</description>
      <author>example@mail.com (Mengdi Jia, Zekun Qi, Shaochen Zhang, Wenyao Zhang, Xinqiang Yu, Jiawei He, He Wang, Li Yi)</author>
      <guid isPermaLink="false">2506.03135v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Investigating Mask-aware Prototype Learning for Tabular Anomaly Detection</title>
      <link>http://arxiv.org/abs/2506.02757v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于表格式异常检测的方法，旨在解决现有深度学习方法在表示纠缠和全局相关性建模方面的不足。&lt;h4&gt;背景&lt;/h4&gt;表格式异常检测在医疗疾病识别、金融欺诈检测、入侵监测等领域具有重要应用。&lt;h4&gt;目的&lt;/h4&gt;提高异常检测的性能，解决表示纠缠和全局相关性建模问题。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了掩码建模和原型学习。在编码阶段，使用正交基向量进行学习，以共享无纠缠的正常模式；在解码阶段，并行解码多个掩码表示以进行重建，并学习关联原型以提取正常特征相关性。&lt;h4&gt;主要发现&lt;/h4&gt;模型从分布匹配的角度出发，将投影空间学习和关联原型学习都形式化为最优传输问题，并使用校准距离来细化异常分数。&lt;h4&gt;结论&lt;/h4&gt;在20个表格式基准数据集上的实验表明，该方法有效且可解释。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Tabular anomaly detection, which aims at identifying deviant samples, has been crucial in a variety of real-world applications, such as medical disease identification, financial fraud detection, intrusion monitoring, etc. Although recent deep learning-based methods have achieved competitive performances, these methods suffer from representation entanglement and the lack of global correlation modeling, which hinders anomaly detection performance. To tackle the problem, we incorporate mask modeling and prototype learning into tabular anomaly detection. The core idea is to design learnable masks by disentangled representation learning within a projection space and extracting normal dependencies as explicit global prototypes. Specifically, the overall model involves two parts: (i) During encoding, we perform mask modeling in both the data space and projection space with orthogonal basis vectors for learning shared disentangled normal patterns; (ii) During decoding, we decode multiple masked representations in parallel for reconstruction and learn association prototypes to extract normal characteristic correlations. Our proposal derives from a distribution-matching perspective, where both projection space learning and association prototype learning are formulated as optimal transport problems, and the calibration distances are utilized to refine the anomaly scores. Quantitative and qualitative experiments on 20 tabular benchmarks demonstrate the effectiveness and interpretability of our model.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tabular anomaly detection, which aims at identifying deviant samples, hasbeen crucial in a variety of real-world applications, such as medical diseaseidentification, financial fraud detection, intrusion monitoring, etc. Althoughrecent deep learning-based methods have achieved competitive performances,these methods suffer from representation entanglement and the lack of globalcorrelation modeling, which hinders anomaly detection performance. To tacklethe problem, we incorporate mask modeling and prototype learning into tabularanomaly detection. The core idea is to design learnable masks by disentangledrepresentation learning within a projection space and extracting normaldependencies as explicit global prototypes. Specifically, the overall modelinvolves two parts: (i) During encoding, we perform mask modeling in both thedata space and projection space with orthogonal basis vectors for learningshared disentangled normal patterns; (ii) During decoding, we decode multiplemasked representations in parallel for reconstruction and learn associationprototypes to extract normal characteristic correlations. Our proposal derivesfrom a distribution-matching perspective, where both projection space learningand association prototype learning are formulated as optimal transportproblems, and the calibration distances are utilized to refine the anomalyscores. Quantitative and qualitative experiments on 20 tabular benchmarksdemonstrate the effectiveness and interpretability of our model.</description>
      <author>example@mail.com (Ruiying Lu, Jinhan Liu, Chuan Du, Dandan Guo)</author>
      <guid isPermaLink="false">2506.02757v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Open-PMC-18M: A High-Fidelity Large Scale Medical Dataset for Multimodal Representation Learning</title>
      <link>http://arxiv.org/abs/2506.02738v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于Transformer的物体检测的子图提取流程，用于从复合图像中提取子图，并建立了大规模的生物医学视觉-语言数据集，以提高视觉-语言模型的表现。&lt;h4&gt;背景&lt;/h4&gt;复合图像在生物医学文献中很常见，但大规模的子图提取问题尚未得到解决。现有子图提取工作在数据集规模和泛化能力方面有限。&lt;h4&gt;目的&lt;/h4&gt;探讨高保真图像-文本对齐通过大规模子图提取对视觉-语言模型中的表示学习的影响。&lt;h4&gt;方法&lt;/h4&gt;提出了一种可扩展的子图提取流程，基于Transformer的物体检测，并在包含500,000个复合图像的合成语料库上训练。同时，创建了包含1800万个临床相关子图-标题对的OPEN-PMC-18M数据集。&lt;h4&gt;主要发现&lt;/h4&gt;该流程在ImageCLEF2016和合成基准测试上达到了最先进的性能，并在检索、零样本分类和鲁棒性基准测试中显示出改进的表现。&lt;h4&gt;结论&lt;/h4&gt;提出的子图提取流程和数据集有助于生物医学视觉-语言建模和表示学习的进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：复合图像，即包含多个子图的复合图像，在生物医学文献中普遍存在，但大规模的子图提取问题仍未得到解决。先前关于子图提取的研究在数据集规模和泛化能力方面都有限，留下了一个关键性的未解问题：通过大规模子图提取实现的高保真图像-文本对齐如何影响视觉-语言模型中的表示学习？我们通过引入一个基于Transformer的物体检测的可扩展子图提取流程来填补这一空白，该流程在包含500,000个复合图像的合成语料库上进行了训练，并在ImageCLEF2016和合成基准测试上实现了最先进的性能。使用这个流程，我们发布了OPEN-PMC-18M，这是一个大规模高质量的生物医学视觉-语言数据集，包含涵盖放射学、显微镜和可见光摄影的1800万个临床相关子图-标题对。我们在我们的精选数据集上训练并评估了视觉-语言模型，并在检索、零样本分类和鲁棒性基准测试中显示出改进的表现，优于现有基线。我们发布了我们的数据集、模型和代码，以支持可重复的基准测试和生物医学视觉-语言建模及表示学习的进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Compound figures, which are multi-panel composites containing diversesubfigures, are ubiquitous in biomedical literature, yet large-scale subfigureextraction remains largely unaddressed. Prior work on subfigure extraction hasbeen limited in both dataset size and generalizability, leaving a critical openquestion: How does high-fidelity image-text alignment via large-scale subfigureextraction impact representation learning in vision-language models? We addressthis gap by introducing a scalable subfigure extraction pipeline based ontransformer-based object detection, trained on a synthetic corpus of 500,000compound figures, and achieving state-of-the-art performance on both ImageCLEF2016 and synthetic benchmarks. Using this pipeline, we release OPEN-PMC-18M, alarge-scale high quality biomedical vision-language dataset comprising 18million clinically relevant subfigure-caption pairs spanning radiology,microscopy, and visible light photography. We train and evaluatevision-language models on our curated datasets and show improved performanceacross retrieval, zero-shot classification, and robustness benchmarks,outperforming existing baselines. We release our dataset, models, and code tosupport reproducible benchmarks and further study into biomedicalvision-language modeling and representation learning.</description>
      <author>example@mail.com (Negin Baghbanzadeh, Sajad Ashkezari, Elham Dolatabadi, Arash Afkanpour)</author>
      <guid isPermaLink="false">2506.02738v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Understanding Stability Mechanisms in Single-Atom Alloys with Theory-infused Deep Learning</title>
      <link>http://arxiv.org/abs/2506.03031v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种可解释的深度学习模型，通过将结合能理论纳入图神经网络（GNN）框架来增强过渡金属合金（TMAs）的预测能力。&lt;h4&gt;背景&lt;/h4&gt;模型旨在分析过渡金属合金的稳定性，并揭示其背后的物理参数。&lt;h4&gt;目的&lt;/h4&gt;预测总结合能（晶体稳定性的指标），并解析其贡献因素和基础物理参数。&lt;h4&gt;方法&lt;/h4&gt;将结合能理论应用于GNN框架，分析单原子合金（SAAs）的稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;模型揭示了过渡金属表面的稳定性趋势，并分析了单原子合金中单体/二聚体（平面对称性破坏）和顶层/底层（非平面对称性破坏）配置的相对稳定性。&lt;h4&gt;结论&lt;/h4&gt;该模型作为一个强大的工具，有助于理解和战略性地设计TMAs，以促进在催化和材料科学领域应用的材料稳定性提升。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种可解释的深度学习模型，通过将结合能理论融入图神经网络（GNN）框架，增强了过渡金属合金（TMAs）的预测能力。该模型不仅预测了总结合能——晶体稳定性的指标，而且还分解了其各种贡献因素和基础物理参数。从模型中提取的物理洞察力阐明了过渡金属表面在周期表中的稳定性趋势。此外，通过将该模型应用于单原子合金（SAAs），一类具有催化意义的下一代TMAs，我们分析了并解释了单体/二聚体（平面对称性破坏）和顶层/底层（非平面对称性破坏）配置的相对稳定性。这两种类型的对称性破坏导致单原子合金中不同的热力学偏好，受限于局域效应（例如d轨道耦合）和非局域效应（例如波函数重整化）。因此，该模型定位为理解和战略性地设计TMAs的强大工具，使材料科学和催化领域先进应用中具有改进稳定性的材料的定制开发成为可能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present an interpretable deep learning model that enhances the predictionof cohesive energy in transition metal alloys (TMAs) by incorporating cohesiontheory into a graph neural network (GNN) framework. The model not only predictsthe total cohesive energy-an indicator of crystal stability-but alsodisentangles its various contributing factors and underlying physicalparameters. The physics insights extracted from the model clarify the stabilitytrends of transition metal surfaces across the periodic table. Furthermore, byapplying the model to single-atom alloys (SAAs), a class of catalyticallysignificant next-generation TMAs, we analyze and explain the relative stabilityof monomer/dimer (in-plane symmetry breaking) and top-/sub-layer (out-of-planesymmetry breaking) configurations. These two types of symmetry breaking lead todistinct thermodynamic preferences in SAAs, governed by localized effects (e.g.d-orbital coupling) and delocalized effects (e.g. wavefunctionrenormalization). The model is thus positioned as a powerful tool forunderstanding and strategically designing TMAs, enabling the tailoreddevelopment of materials with improved stability for advanced applications incatalysis and materials science.</description>
      <author>example@mail.com (Yang Huang, Shih-Han Wang, Shuyi Cao, Luke E. K. Achenie, Hongliang Xin)</author>
      <guid isPermaLink="false">2506.03031v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Sheaves Reloaded: A Directional Awakening</title>
      <link>http://arxiv.org/abs/2506.02842v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新型的神经网络——有向细胞层神经网络（DSNN），它是一种强大的图神经网络（GNN）的推广，能够更好地建模复杂关系数据。&lt;h4&gt;背景&lt;/h4&gt;尽管方向性在图学习任务中已被证明能够显著提高性能，并且对于许多实际应用至关重要，但现有的有向神经网络在表示方向性方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一局限性，本文提出了有向细胞层（Directed Cellular Sheaf），一种专门设计的细胞层，旨在明确考虑边方向。在此基础上，定义了一种新的层拉普拉斯算子——有向层拉普拉斯算子，它捕捉了图的拓扑结构和方向信息。&lt;h4&gt;方法&lt;/h4&gt;本文提出的有向层神经网络（DSNN）将方向性嵌入到其架构中，通过有向层拉普拉斯算子作为其核心操作符。&lt;h4&gt;主要发现&lt;/h4&gt;在九个真实世界基准测试中，DSNN一致优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;DSNN作为一种新的神经网络模型，在建模复杂关系数据方面具有显著优势，并且能够提高图学习任务的性能。&lt;h4&gt;翻译&lt;/h4&gt;Sheaf Neural Networks (SNNs) represent a powerful generalization of GraphNeural Networks (GNNs) that significantly improve our ability to model complex relational data. While directionality has been shown to substantially boost performance in graph learning tasks and is key to many real-world applications, existing SNNs fall short in representing it. To address this limitation, we introduce the Directed Cellular Sheaf, a special type of cellular sheaf designed to explicitly account for edge orientation. Building on this structure, we define a new sheaf Laplacian, the Directed Sheaf Laplacian, which captures both the graph's topology and its directional information. This operator serves as the backbone of the Directed Sheaf Neural Network (DSNN), the first SNN model to embed a directional bias into its architecture. Extensive experiments on nine real-world benchmarks show that DSNN consistently outperforms baseline methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sheaf Neural Networks (SNNs) represent a powerful generalization of GraphNeural Networks (GNNs) that significantly improve our ability to model complexrelational data. While directionality has been shown to substantially boostperformance in graph learning tasks and is key to many real-world applications,existing SNNs fall short in representing it. To address this limitation, weintroduce the Directed Cellular Sheaf, a special type of cellular sheafdesigned to explicitly account for edge orientation. Building on thisstructure, we define a new sheaf Laplacian, the Directed Sheaf Laplacian, whichcaptures both the graph's topology and its directional information. Thisoperator serves as the backbone of the Directed Sheaf Neural Network (DSNN),the first SNN model to embed a directional bias into its architecture.Extensive experiments on nine real-world benchmarks show that DSNN consistentlyoutperforms baseline methods.</description>
      <author>example@mail.com (Stefano Fiorini, Hakan Aktas, Iulia Duta, Stefano Coniglio, Pietro Morerio, Alessio Del Bue, Pietro Liò)</author>
      <guid isPermaLink="false">2506.02842v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MMM4Rec: An Transfer-Efficient Framework for Multi-modal Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2506.02916v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MMM4Rec的多模态序列推荐框架，通过结合状态空间对偶（SSD）的时间衰减特性和时间感知建模设计，实现高效迁移学习，并显著提高了多模态推荐精度和迁移能力。&lt;h4&gt;背景&lt;/h4&gt;序列推荐系统通过分析用户交互历史来建模用户偏好。虽然多模态序列推荐架构比传统的基于ID的方法表现出色，但当前方法在适应新领域时需要大量微调，存在优化要求和负迁移效应，成为部署的瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多模态序列推荐框架，以降低迁移学习成本，提高推荐精度和迁移能力。&lt;h4&gt;方法&lt;/h4&gt;MMM4Rec框架采用一个专用的代数约束机制，通过结合SSD的时间衰减特性和时间感知建模设计，动态优先考虑关键模态信息。它实现了一个受限的两阶段过程：首先通过共享投影矩阵进行序列级别的跨模态对齐，然后使用新设计的Cross-SSD模块和双通道傅里叶自适应滤波进行时间融合。&lt;h4&gt;主要发现&lt;/h4&gt;MMM4Rec在快速微调收敛和简单交叉熵损失下表现出色，与现有模型相比，实现了31.78%的NDCG@10最大提升，并且在迁移到大规模下游数据集时表现出10倍的平均收敛速度。&lt;h4&gt;结论&lt;/h4&gt;MMM4Rec框架在多模态序列推荐领域表现出卓越的性能，为推荐系统的微调和迁移学习提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential Recommendation (SR) systems model user preferences by analyzinginteraction histories. Although transferable multi-modal SR architecturesdemonstrate superior performance compared to traditional ID-based approaches,current methods incur substantial fine-tuning costs when adapting to newdomains due to complex optimization requirements and negative transfer effects- a significant deployment bottleneck that hinders engineers from efficientlyrepurposing pre-trained models for novel application scenarios with minimaltuning overhead. We propose MMM4Rec (Multi-Modal Mamba for SequentialRecommendation), a novel multi-modal SR framework that incorporates a dedicatedalgebraic constraint mechanism for efficient transfer learning. By combiningState Space Duality (SSD)'s temporal decay properties with a time-awaremodeling design, our model dynamically prioritizes key modality information,overcoming limitations of Transformer-based approaches. The frameworkimplements a constrained two-stage process: (1) sequence-level cross-modalalignment via shared projection matrices, followed by (2) temporal fusion usingour newly designed Cross-SSD module and dual-channel Fourier adaptivefiltering. This architecture maintains semantic consistency while suppressingnoise propagation.MMM4Rec achieves rapid fine-tuning convergence with simplecross-entropy loss, significantly improving multi-modal recommendation accuracywhile maintaining strong transferability. Extensive experiments demonstrateMMM4Rec's state-of-the-art performance, achieving the maximum 31.78% NDCG@10improvement over existing models and exhibiting 10 times faster averageconvergence speed when transferring to large-scale downstream datasets.</description>
      <author>example@mail.com (Hao Fan, Yanrong Hu, Kai Fang, Qingyang Liu, Hongjiu Liu)</author>
      <guid isPermaLink="false">2506.02916v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Go Beyond Earth: Understanding Human Actions and Scenes in Microgravity Environments</title>
      <link>http://arxiv.org/abs/2506.02845v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 3 figures, submitted to NeurIPS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为MicroG-4M的数据集，用于微重力下人类活动的时空和语义理解。&lt;h4&gt;背景&lt;/h4&gt;现有的视频理解数据集大多限于地球重力条件，而微重力会改变人类动作、交互和视觉语义，这对现实世界的视觉系统提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，提出了MicroG-4M，以支持微重力环境下的领域鲁棒视频理解。&lt;h4&gt;方法&lt;/h4&gt;MicroG-4M由真实太空任务和电影模拟构建，包括4,759个剪辑，涵盖50个动作，1,238个丰富的上下文描述，以及关于宇航员活动和场景理解的7,000多对问答。&lt;h4&gt;主要发现&lt;/h4&gt;MicroG-4M支持精细粒度多标签动作识别、时间视频字幕和视觉问答三个核心任务，从而全面评估微重力环境中的空间定位和语义推理。&lt;h4&gt;结论&lt;/h4&gt;通过使用最先进的模型建立基线，所有数据、注释和代码均可在https://github.com/LEI-QI-233/HAR-in-Space上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite substantial progress in video understanding, most existing datasetsare limited to Earth's gravitational conditions. However, microgravity altershuman motion, interactions, and visual semantics, revealing a critical gap forreal-world vision systems. This presents a challenge for domain-robust videounderstanding in safety-critical space applications. To address this, weintroduce MicroG-4M, the first benchmark for spatio-temporal and semanticunderstanding of human activities in microgravity. Constructed from real-worldspace missions and cinematic simulations, the dataset includes 4,759 clipscovering 50 actions, 1,238 context-rich captions, and over 7,000question-answer pairs on astronaut activities and scene understanding.MicroG-4M supports three core tasks: fine-grained multi-label actionrecognition, temporal video captioning, and visual question answering, enablinga comprehensive evaluation of both spatial localization and semantic reasoningin microgravity contexts. We establish baselines using state-of-the-art models.All data, annotations, and code are available athttps://github.com/LEI-QI-233/HAR-in-Space.</description>
      <author>example@mail.com (Di Wen, Lei Qi, Kunyu Peng, Kailun Yang, Fei Teng, Ao Luo, Jia Fu, Yufan Chen, Ruiping Liu, Yitian Shi, M. Saquib Sarfraz, Rainer Stiefelhagen)</author>
      <guid isPermaLink="false">2506.02845v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Rodrigues Network for Learning Robot Actions</title>
      <link>http://arxiv.org/abs/2506.02618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为神经罗德里格斯算子（Neural Rodrigues Operator）的学习泛化方法，旨在为神经网络注入动力学感知的归纳偏置，以解决机器人学习中理解与预测关节动作的问题。&lt;h4&gt;背景&lt;/h4&gt;目前常用的神经网络架构如MLPs和Transformers缺乏反映关节系统底层运动学结构的归纳偏置。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够学习运动学操作的方法，并将其应用于神经网络，以提高对关节动作的理解和预测。&lt;h4&gt;方法&lt;/h4&gt;设计了神经罗德里格斯算子，并基于此算子构建了罗德里格斯网络（RodriNet），一个针对动作处理的创新神经网络架构。在合成任务中评估了该网络的表达能力，并在真实应用中进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;在运动学预测和动作预测的合成任务中，与标准骨干相比，罗德里格斯网络表现出显著的改进。在机器人基准测试和单图像3D手部重建的实际情况中，也展示了其有效性。&lt;h4&gt;结论&lt;/h4&gt;将结构化的运动学先验整合到网络架构中，可以改善在不同领域中的动作学习。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在机器人学习中，理解和预测关节动作非常重要。然而，像MLP和Transformers这样的常见架构缺乏反映关节系统底层运动学结构的归纳偏置。为此，我们提出了神经罗德里格斯算子，这是一种对经典前向运动学操作的学习泛化，旨在将运动学感知的归纳偏置注入到神经网络中。基于这个算子，我们设计了罗德里格斯网络（RodriNet），一种专门用于处理动作的新颖神经网络架构。我们在两个合成任务中评估了我们的网络在运动学和运动预测方面的表达能力，与标准骨干相比，显示出显著的改进。我们进一步证明了其在两个实际应用中的有效性：（i）使用扩散策略在机器人基准测试中进行模仿学习，以及（ii）单图像3D手部重建。我们的结果表明，将结构化的运动学先验整合到网络架构中可以提高各种领域中的动作学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding and predicting articulated actions is important in robotlearning. However, common architectures such as MLPs and Transformers lackinductive biases that reflect the underlying kinematic structure of articulatedsystems. To this end, we propose the Neural Rodrigues Operator, a learnablegeneralization of the classical forward kinematics operation, designed toinject kinematics-aware inductive bias into neural computation. Building onthis operator, we design the Rodrigues Network (RodriNet), a novel neuralarchitecture specialized for processing actions. We evaluate the expressivityof our network on two synthetic tasks on kinematic and motion prediction,showing significant improvements compared to standard backbones. We furtherdemonstrate its effectiveness in two realistic applications: (i) imitationlearning on robotic benchmarks with the Diffusion Policy, and (ii) single-image3D hand reconstruction. Our results suggest that integrating structuredkinematic priors into the network architecture improves action learning invarious domains.</description>
      <author>example@mail.com (Jialiang Zhang, Haoran Geng, Yang You, Congyue Deng, Pieter Abbeel, Jitendra Malik, Leonidas Guibas)</author>
      <guid isPermaLink="false">2506.02618v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MERIT: Multilingual Semantic Retrieval with Interleaved Multi-Condition Query</title>
      <link>http://arxiv.org/abs/2506.03144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint; Project Page, Code, and Dataset at:  https://merit-2025.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了MERIT，第一个用于交错多条件语义检索的多语言数据集，并提出了Coral框架以改进现有模型在多条件语义检索中的性能。&lt;h4&gt;背景&lt;/h4&gt;语义检索在现代应用中至关重要，但当前研究探索不足。现有数据集通常限于单一语言、单一图像或单一检索条件，未能充分利用视觉信息的表现力。&lt;h4&gt;目的&lt;/h4&gt;提出MERIT数据集和Coral框架，以解决现有数据集的局限性并改进多条件语义检索的性能。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含320,000个查询和135,000个产品的多语言数据集，提出了一种新的微调框架Coral，该框架通过嵌入重建和对比学习来改进预训练的MLLM。&lt;h4&gt;主要发现&lt;/h4&gt;在MERIT上的实验表明，Coral比传统方法在性能上提高了45.9%，并验证了其在8个已建立的检索基准上的强大泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文的贡献——一个新颖的数据集、识别现有方法的关键局限性和一个创新的微调框架——为交错多条件语义检索的未来研究奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语义检索对于现代应用至关重要，但在当前研究中却未得到充分探索。现有数据集仅限于单一语言、单一图像或单一检索条件，往往未能充分利用视觉信息的表现力，这从当图像被标题替换时维持的性能可以得出。然而，实际的检索场景通常涉及交错的多条件查询和多图像。因此，本文介绍了MERIT，这是第一个用于交错多条件语义检索的多语言数据集，包括5种语言中的320,000个查询和135,000个产品，涵盖7个不同的产品类别。在MERIT上的广泛实验确定了现有模型的局限性：只关注全局语义信息，而忽略了查询中的特定条件元素。因此，我们提出了Coral，一个新颖的微调框架，通过整合嵌入重建来保留细粒度的条件元素，并通过对比学习来提取全面的全球语义。实验表明，Coral在MERIT上比传统方法实现了45.9%的性能提升，并在8个已建立的检索基准上验证了其强大的泛化能力。总的来说，我们的贡献——一个新颖的数据集、识别现有方法的临界局限性以及一个创新的微调框架——为交错多条件语义检索的未来研究奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic retrieval is crucial for modern applications yet remainsunderexplored in current research. Existing datasets are limited to singlelanguages, single images, or singular retrieval conditions, often failing tofully exploit the expressive capacity of visual information as evidenced bymaintained performance when images are replaced with captions. However,practical retrieval scenarios frequently involve interleaved multi-conditionqueries with multiple images. Hence, this paper introduces MERIT, the firstmultilingual dataset for interleaved multi-condition semantic retrieval,comprising 320,000 queries with 135,000 products in 5 languages, covering 7distinct product categories. Extensive experiments on MERIT identify existingmodels's limitation: focusing solely on global semantic information whileneglecting specific conditional elements in queries. Consequently, we proposeCoral, a novel fine-tuning framework that adapts pre-trained MLLMs byintegrating embedding reconstruction to preserve fine-grained conditionalelements and contrastive learning to extract comprehensive global semantics.Experiments demonstrate that Coral achieves a 45.9% performance improvementover conventional approaches on MERIT, with strong generalization capabilitiesvalidated across 8 established retrieval benchmarks. Collectively, ourcontributions - a novel dataset, identification of critical limitations inexisting approaches, and an innovative fine-tuning framework - establish afoundation for future research in interleaved multi-condition semanticretrieval.</description>
      <author>example@mail.com (Wei Chow, Yuan Gao, Linfeng Li, Xian Wang, Qi Xu, Hang Song, Lingdong Kong, Ran Zhou, Yi Zeng, Yidong Cai, Botian Jiang, Shilin Xu, Jiajun Zhang, Minghui Qiu, Xiangtai Li, Tianshu Yang, Siliang Tang, Juncheng Li)</author>
      <guid isPermaLink="false">2506.03144v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Large-scale Self-supervised Video Foundation Model for Intelligent Surgery</title>
      <link>http://arxiv.org/abs/2506.02692v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为SurgVISTA的视频级手术预训练框架，旨在通过联合时空建模学习大规模手术视频数据，以改善手术场景理解，从而支持决策、提高手术效率和确保术中安全。&lt;h4&gt;背景&lt;/h4&gt;计算机辅助干预（CAI）有潜力革命化现代外科手术，其中手术场景理解是支持决策、提高手术效率和确保术中安全的关键组成部分。现有的基于AI的方法通过自监督空间表示学习减轻了注释负担，但在预训练过程中缺乏显式的时序建模，这从根本上限制了动态手术场景的捕捉，导致时空理解不完整。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一个能够从大规模手术视频数据中联合时空表示学习的预训练框架，以改善手术场景理解。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含3,650个视频和约3,550,000个帧的大规模手术视频数据集，覆盖20多种手术程序和10多个解剖结构。基于此数据集，提出了SurgVISTA，这是一种基于重建的预训练方法，通过联合时空建模捕捉复杂的空间结构和时序动态。此外，SurgVISTA结合了由手术专家指导的图像级知识蒸馏，以增强对细粒度解剖和语义特征的学习。&lt;h4&gt;主要发现&lt;/h4&gt;SurgVISTA在13个视频级数据集组成的全面基准上进行了验证，这些数据集覆盖六个手术程序和四个任务。广泛的实验表明，SurgVISTA在自然和手术领域预训练模型中表现一致地优于，展示了在临床上有意义的场景中推进智能手术系统的强大潜力。&lt;h4&gt;结论&lt;/h4&gt;SurgVISTA预训练框架有望通过提升手术场景理解，支持临床意义上的智能手术系统的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computer-Assisted Intervention (CAI) has the potential to revolutionizemodern surgery, with surgical scene understanding serving as a criticalcomponent in supporting decision-making, improving procedural efficacy, andensuring intraoperative safety. While existing AI-driven approaches alleviateannotation burdens via self-supervised spatial representation learning, theirlack of explicit temporal modeling during pre-training fundamentally restrictsthe capture of dynamic surgical contexts, resulting in incompletespatiotemporal understanding. In this work, we introduce the first video-levelsurgical pre-training framework that enables joint spatiotemporalrepresentation learning from large-scale surgical video data. To achieve this,we constructed a large-scale surgical video dataset comprising 3,650 videos andapproximately 3.55 million frames, spanning more than 20 surgical proceduresand over 10 anatomical structures. Building upon this dataset, we proposeSurgVISTA (Surgical Video-level Spatial-Temporal Architecture), areconstruction-based pre-training method that captures intricate spatialstructures and temporal dynamics through joint spatiotemporal modeling.Additionally, SurgVISTA incorporates image-level knowledge distillation guidedby a surgery-specific expert to enhance the learning of fine-grained anatomicaland semantic features. To validate its effectiveness, we established acomprehensive benchmark comprising 13 video-level datasets spanning sixsurgical procedures across four tasks. Extensive experiments demonstrate thatSurgVISTA consistently outperforms both natural- and surgical-domainpre-trained models, demonstrating strong potential to advance intelligentsurgical systems in clinically meaningful scenarios.</description>
      <author>example@mail.com (Shu Yang, Fengtao Zhou, Leon Mayer, Fuxiang Huang, Yiliang Chen, Yihui Wang, Sunan He, Yuxiang Nie, Xi Wang, Ömer Sümer, Yueming Jin, Huihui Sun, Shuchang Xu, Alex Qinyang Liu, Zheng Li, Jing Qin, Jeremy YuenChun Teoh, Lena Maier-Hein, Hao Chen)</author>
      <guid isPermaLink="false">2506.02692v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Combining social relations and interaction data in Recommender System with Graph Convolution Collaborative Filtering</title>
      <link>http://arxiv.org/abs/2506.02834v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了推荐系统在数据挖掘领域的应用，通过分析用户评分信息，为用户提供合适的产品推荐，并在电子商务、阅读书籍、观看电影、选择课程或访问网站等方面发挥作用。&lt;h4&gt;背景&lt;/h4&gt;推荐系统利用用户评分信息，通过协作过滤、矩阵分解或奇异向量分解等方法，计算用户间的相似性，以生成推荐。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提高推荐系统的准确性和召回率，通过结合社交关系数据和用户评分历史相似性来实现。&lt;h4&gt;方法&lt;/h4&gt;提出了数据预处理方法来去除异常值，如单个评论或与项目互动较少的用户。提出的模型将结合社交关系数据和用户评分历史相似性。&lt;h4&gt;主要发现&lt;/h4&gt;发现用户间的相似性对推荐有重要影响，社交关系数据也会影响消费习惯，但结合用户社交影响和相似购物习惯存在挑战。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法有助于提高推荐系统的准确性和召回率，通过处理数据噪声并考虑用户社交关系和评分历史相似性。&lt;h4&gt;翻译&lt;/h4&gt;A recommender system is an important subject in the field of data mining, where the item rating information from users is exploited and processed to make suitable recommendations with all other users. The recommender system creates convenience for e-commerce users and stimulates the consumption of items that are suitable for users. In addition to e-commerce, a recommender system is also used to provide recommendations on books to read, movies to watch, courses to take or websites to visit. Similarity between users is an important impact for recommendation, which could be calculated from the data of past user ratings of the item by methods of collaborative filtering, matrix factorization or singular vector decomposition. In the development of graph data mining techniques, the relationships between users and items can be represented by matrices from which collaborative filtering could be done with the larger database, more accurate and faster in calculation. All these data can be represented graphically and mined by today's highly developed graph neural network models. On the other hand, users' social friendship data also influence consumption habits because recommendations from friends will be considered more carefully than information sources. However, combining a user's friend influence and the similarity between users whose similar shopping habits is challenging. Because the information is noisy and it affects each particular data set in different ways. In this study, we present the input data processing method to remove outliers which are single reviews or users with little interaction with the items; the next proposed model will combine the social relationship data and the similarity in the rating history of users to improve the accuracy and recall of the recommender system.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A recommender system is an important subject in the field of data mining,where the item rating information from users is exploited and processed to makesuitable recommendations with all other users. The recommender system createsconvenience for e-commerce users and stimulates the consumption of items thatare suitable for users. In addition to e-commerce, a recommender system is alsoused to provide recommendations on books to read, movies to watch, courses totake or websites to visit. Similarity between users is an important impact forrecommendation, which could be calculated from the data of past user ratings ofthe item by methods of collaborative filtering, matrix factorization orsingular vector decomposition. In the development of graph data miningtechniques, the relationships between users and items can be represented bymatrices from which collaborative filtering could be done with the largerdatabase, more accurate and faster in calculation. All these data can berepresented graphically and mined by today's highly developed graph neuralnetwork models. On the other hand, users' social friendship data also influenceconsumption habits because recommendations from friends will be considered morecarefully than information sources. However, combining a user's friendinfluence and the similarity between users whose similar shopping habits ischallenging. Because the information is noisy and it affects each particulardata set in different ways. In this study, we present the input data processingmethod to remove outliers which are single reviews or users with littleinteraction with the items; the next proposed model will combine the socialrelationship data and the similarity in the rating history of users to improvethe accuracy and recall of the recommender system.</description>
      <author>example@mail.com (Tin T. Tran, Vaclav Snasel, Loc Tan Nguyen)</author>
      <guid isPermaLink="false">2506.02834v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MVTD: A Benchmark Dataset for Maritime Visual Object Tracking</title>
      <link>http://arxiv.org/abs/2506.02866v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submited to Nature Scientific Data&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Maritime Visual Tracking Dataset (MVTD)，这是一个专为海上视觉目标跟踪任务设计的公开数据集，旨在解决海上环境中的跟踪挑战。&lt;h4&gt;背景&lt;/h4&gt;尽管通用目标跟踪技术取得了显著进展，但海上环境中的特殊挑战，如水面反光、低对比度目标、动态变化的背景和频繁的遮挡，对现有跟踪算法的性能产生了显著影响。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一差距，本文提出了MVTD数据集，以提供针对海上视觉目标跟踪的特定领域数据。&lt;h4&gt;方法&lt;/h4&gt;MVTD包含182个高分辨率视频序列，总计约150,000帧，涵盖了船只、船舶、帆船和无人水面舰艇四个代表性目标类别。该数据集捕捉了多样化的操作条件和海上场景，反映了真实海上环境的复杂性。&lt;h4&gt;主要发现&lt;/h4&gt;在MVTD上评估了14种最新的SOTA跟踪算法，发现与通用数据集相比，这些算法的性能有所下降。然而，当在MVTD上微调后，这些模型表现出显著的性能提升，强调了领域适应和迁移学习在特定跟踪环境中的重要性。&lt;h4&gt;结论&lt;/h4&gt;MVTD数据集为视觉跟踪社区填补了一个关键缺口，提供了一个真实且具有挑战性的海上场景基准。&lt;h4&gt;翻译&lt;/h4&gt;视觉目标跟踪（VOT）是一个具有广泛应用的基本任务，在自主导航、监控和海事机器人等领域有着重要作用。尽管通用目标跟踪取得了显著的进步，但海上环境仍然存在独特的挑战，包括水面反光、低对比度目标、动态变化的背景和频繁的遮挡。这些复杂性严重降低了最先进跟踪算法的性能，突显了特定领域数据集的必要性。为了解决这一差距，我们引入了海事视觉跟踪数据集（MVTD），这是一个专为海上视觉目标跟踪设计的公开基准数据集。MVTD包含182个高分辨率视频序列，总计约150,000帧，包括船只、船舶、帆船和无人水面舰艇四个代表性目标类别。该数据集捕捉了多样化的操作条件和海上场景，反映了真实海上环境的复杂性。我们在MVTD基准上评估了14种最近的最先进跟踪算法，并观察到与它们在通用数据集上的性能相比，性能有显著下降。然而，当在MVTD上微调时，这些模型表现出显著的性能提升，强调了领域适应和迁移学习在特定跟踪环境中的重要性。MVTD数据集通过为海上场景提供真实且具有挑战性的基准，在视觉跟踪社区中填补了一个关键缺口。数据集和源代码可在以下链接访问：https://github.com/AhsanBaidar/MVTD。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Object Tracking (VOT) is a fundamental task with widespreadapplications in autonomous navigation, surveillance, and maritime robotics.Despite significant advances in generic object tracking, maritime environmentscontinue to present unique challenges, including specular water reflections,low-contrast targets, dynamically changing backgrounds, and frequentocclusions. These complexities significantly degrade the performance ofstate-of-the-art tracking algorithms, highlighting the need for domain-specificdatasets. To address this gap, we introduce the Maritime Visual TrackingDataset (MVTD), a comprehensive and publicly available benchmark specificallydesigned for maritime VOT. MVTD comprises 182 high-resolution video sequences,totaling approximately 150,000 frames, and includes four representative objectclasses: boat, ship, sailboat, and unmanned surface vehicle (USV). The datasetcaptures a diverse range of operational conditions and maritime scenarios,reflecting the real-world complexities of maritime environments. We evaluated14 recent SOTA tracking algorithms on the MVTD benchmark and observedsubstantial performance degradation compared to their performance ongeneral-purpose datasets. However, when fine-tuned on MVTD, these modelsdemonstrate significant performance gains, underscoring the effectiveness ofdomain adaptation and the importance of transfer learning in specializedtracking contexts. The MVTD dataset fills a critical gap in the visual trackingcommunity by providing a realistic and challenging benchmark for maritimescenarios. Dataset and Source Code can be accessed here"https://github.com/AhsanBaidar/MVTD".</description>
      <author>example@mail.com (Ahsan Baidar Bakht, Muhayy Ud Din, Sajid Javed, Irfan Hussain)</author>
      <guid isPermaLink="false">2506.02866v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>PhysGaia: A Physics-Aware Dataset of Multi-Body Interactions for Dynamic Novel View Synthesis</title>
      <link>http://arxiv.org/abs/2506.02794v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: http://cvlab.snu.ac.kr/research/PhysGaia, Data:  https://huggingface.co/datasets/mijeongkim/PhysGaia/tree/main&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PhysGaia是一个为动态新颖视图合成（DyNVS）设计的物理感知数据集，包含结构化物体和无结构物理现象。它支持物理感知的动态场景建模，具有丰富的多物体交互和多种物理材料，并严格遵循物理定律。&lt;h4&gt;背景&lt;/h4&gt;现有的数据集主要关注 photorealistic reconstruction，而PhysGaia旨在支持物理感知的动态场景建模。&lt;h4&gt;目的&lt;/h4&gt;提供复杂的动态场景，支持物理建模，并促进动态视图合成、基于物理的场景理解和深度学习与物理模拟的集成。&lt;h4&gt;方法&lt;/h4&gt;PhysGaia使用精心选择的材料特定物理求解器来生成场景，并提供了3D粒子轨迹和物理参数等真实信息。&lt;h4&gt;主要发现&lt;/h4&gt;PhysGaia超越了现有数据集中常见的刚性物体，包含液体、气体、粘弹性和纺织等物理材料。&lt;h4&gt;结论&lt;/h4&gt;PhysGaia解决了物理感知建模数据集的缺乏问题，将显著推动动态视图合成和相关领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;PhysGaia是一个新的物理感知数据集，专门用于动态新颖视图合成。它包含结构化物体和无结构物理现象。与现有主要关注真实感重建的数据集不同，PhysGaia旨在积极支持物理感知的动态场景建模。我们的数据集提供了复杂的动态场景，其中多个物体之间有丰富的交互，它们真实地碰撞并交换力。此外，它包含多种物理材料，如液体、气体、粘弹性物质和纺织品，这些材料超越了现有数据集中普遍存在的刚性物体。PhysGaia中的所有场景都忠实于物理定律，利用精心选择的材料特定物理求解器生成。为了使物理建模具有可量化的评估，我们的数据集提供了必要的真实信息，包括3D粒子轨迹和物理参数，例如粘度。为了促进研究采用，我们还提供了使用最先进的DyNVS模型与我们的数据集的必要集成管道，并报告了它们的结果。通过解决物理感知建模数据集的关键缺乏，PhysGaia将显著推进动态视图合成、基于物理的场景理解和与物理模拟集成的深度学习模型的研究——最终使更忠实于复杂动态场景的重建和解释成为可能。我们的数据集和代码可在项目网站http://cvlab.snu.ac.kr/research/PhysGaia上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce PhysGaia, a novel physics-aware dataset specifically designedfor Dynamic Novel View Synthesis (DyNVS), encompassing both structured objectsand unstructured physical phenomena. Unlike existing datasets that primarilyfocus on photorealistic reconstruction, PhysGaia is created to actively supportphysics-aware dynamic scene modeling. Our dataset provides complex dynamicscenarios with rich interactions among multiple objects, where theyrealistically collide with each other and exchange forces. Furthermore, itcontains a diverse range of physical materials, such as liquid, gas,viscoelastic substance, and textile, which moves beyond the rigid bodiesprevalent in existing datasets. All scenes in PhysGaia are faithfully generatedto strictly adhere to physical laws, leveraging carefully selectedmaterial-specific physics solvers. To enable quantitative evaluation ofphysical modeling, our dataset provides essential ground-truth information,including 3D particle trajectories and physics parameters, e.g., viscosity. Tofacilitate research adoption, we also provide essential integration pipelinesfor using state-of-the-art DyNVS models with our dataset and report theirresults. By addressing the critical lack of datasets for physics-awaremodeling, PhysGaia will significantly advance research in dynamic viewsynthesis, physics-based scene understanding, and deep learning modelsintegrated with physical simulation -- ultimately enabling more faithfulreconstruction and interpretation of complex dynamic scenes. Our datasets andcodes are available in the project website,http://cvlab.snu.ac.kr/research/PhysGaia.</description>
      <author>example@mail.com (Mijeong Kim, Gunhee Kim, Jungyoon Choi, Wonjae Roh, Bohyung Han)</author>
      <guid isPermaLink="false">2506.02794v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Targeted Forgetting of Image Subgroups in CLIP Models</title>
      <link>http://arxiv.org/abs/2506.03117v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 Figures,5 Pages. The project page is  \url{https://zhangaipi.github.io/forget_clip/}&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法，用于在保留模型整体性能的同时，从预训练模型中选择性忘记特定知识部分。&lt;h4&gt;背景&lt;/h4&gt;现有的模型遗忘方法要么依赖于对预训练数据集的访问，要么专注于粗粒度的遗忘（例如整个类别），在细粒度遗忘方面存在空白。&lt;h4&gt;目的&lt;/h4&gt;在不依赖预训练数据的情况下，选择性地忘记特定知识部分，同时保持模型的整体性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种三阶段方法，包括：(1) 遗忘阶段，对要遗忘的样本进行微调；(2) 提醒阶段，恢复保留样本的性能；(3) 恢复阶段，使用模型蒸馏恢复零样本能力。此外，引入了知识蒸馏来处理遗忘样本、保留样本和未见过的预训练数据之间的分布差异。&lt;h4&gt;主要发现&lt;/h4&gt;在CIFAR-10、ImageNet-1K和风格数据集上的大量实验表明，该方法在遗忘特定子组的同时，在语义相似的子组和其他类别上保持了强大的零样本性能，显著优于基线遗忘方法。&lt;h4&gt;结论&lt;/h4&gt;该方法在保持模型性能的同时，有效地实现了细粒度知识遗忘，为模型在实际应用中的可靠性提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型（FMs）如CLIP通过利用大规模的无监督预训练，在各种任务上展示了令人印象深刻的零样本性能。然而，它们往往从嘈杂的互联网数据集中继承有害或不希望的知识，损害了其在现实世界应用中的可靠性。现有的模型遗忘方法要么依赖于访问预训练数据集，要么专注于粗粒度遗忘（例如整个类别），在细粒度遗忘方面存在关键差距。在本文中，我们解决了在没有访问预训练数据的情况下，在类中选择性地忘记特定知识部分这一具有挑战性的场景，同时保持模型的整体性能。我们提出了一种新颖的三阶段方法，逐步遗忘目标知识同时减轻过度遗忘。它包括（1）遗忘阶段，对要遗忘的样本进行微调；（2）提醒阶段，恢复保留样本的性能；（3）恢复阶段，使用模型蒸馏恢复零样本能力。此外，我们引入了知识蒸馏来处理遗忘样本、保留样本和未见过的预训练数据之间的分布差异。在CIFAR-10、ImageNet-1K和风格数据集上的大量实验表明，我们的方法在遗忘特定子组的同时，在语义相似的子组和其他类别上保持了强大的零样本性能，显著优于基线遗忘方法，这些方法在CLIP遗忘设置下失去了有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) such as CLIP have demonstrated impressive zero-shotperformance across various tasks by leveraging large-scale, unsupervisedpre-training. However, they often inherit harmful or unwanted knowledge fromnoisy internet-sourced datasets, compromising their reliability in real-worldapplications. Existing model unlearning methods either rely on access topre-trained datasets or focus on coarse-grained unlearning (e.g., entireclasses), leaving a critical gap for fine-grained unlearning. In this paper, weaddress the challenging scenario of selectively forgetting specific portions ofknowledge within a class, without access to pre-trained data, while preservingthe model's overall performance. We propose a novel three-stage approach thatprogressively unlearns targeted knowledge while mitigating over-forgetting. Itconsists of (1) a forgetting stage to fine-tune the CLIP on samples to beforgotten, (2) a reminding stage to restore performance on retained samples,and (3) a restoring stage to recover zero-shot capabilities using modelsouping. Additionally, we introduce knowledge distillation to handle thedistribution disparity between forgetting, retaining samples, and unseenpre-trained data. Extensive experiments on CIFAR-10, ImageNet-1K, and styledatasets demonstrate that our approach effectively unlearns specific subgroupswhile maintaining strong zero-shot performance on semantically similarsubgroups and other categories, significantly outperforming baseline unlearningmethods, which lose effectiveness under the CLIP unlearning setting.</description>
      <author>example@mail.com (Zeliang Zhang, Gaowen Liu, Charles Fleming, Ramana Rao Kompella, Chenliang Xu)</author>
      <guid isPermaLink="false">2506.03117v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Enriching Location Representation with Detailed Semantic Information</title>
      <link>http://arxiv.org/abs/2506.02744v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了CaLLiPer+模型，该模型通过整合POI名称和分类标签，在多模态对比学习框架中提升了对城市环境结构性和语义特征的捕捉能力。&lt;h4&gt;背景&lt;/h4&gt;传统的空间嵌入方法往往过于重视空间邻近性，而未能充分利用地点的细粒度上下文信息。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一局限性，提出了一种新的模型CaLLiPer+，旨在提高城市建模的准确性。&lt;h4&gt;方法&lt;/h4&gt;CaLLiPer+模型在多模态对比学习框架中整合了POI名称和分类标签，并在土地利用分类和社会经济状态分布映射两个下游任务中进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;CaLLiPer+在两个任务中相较于基线方法，性能提升了4%到11%。此外，POI名称的整合增强了位置检索能力，使模型能够更精确地捕捉复杂的城市概念。消融实验揭示了POI名称的互补作用以及利用预训练文本编码器进行空间表示的优势。&lt;h4&gt;结论&lt;/h4&gt;本文的研究结果表明，将细粒度语义属性和多模态学习技术相结合，有助于推动城市基础模型的发展。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces the CaLLiPer+ model, which integrates POI names and categorical labels within a multimodal contrastive learning framework to enhance the capture of structural and semantic characteristics of urban environments. The background of the study is that traditional spatial embedding methods often prioritize spatial proximity while underutilizing fine-grained contextual information from places. The purpose of the research is to address this limitation by proposing a new model, CaLLiPer+, to improve the accuracy of urban modeling. The method involves evaluating the model on two downstream tasks, land use classification and socioeconomic status distribution mapping, within a multimodal contrastive learning framework. The main findings show that CaLLiPer+ achieves consistent performance gains of 4% to 11% over baseline methods and enhances location retrieval, enabling the model to capture complex urban concepts with greater precision. Ablation studies further reveal the complementary role of POI names and the advantages of leveraging pretrained text encoders for spatial representations. Overall, the study highlights the potential of integrating fine-grained semantic attributes and multimodal learning techniques to advance the development of urban foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial representations that capture both structural and semanticcharacteristics of urban environments are essential for urban modeling.Traditional spatial embeddings often prioritize spatial proximity whileunderutilizing fine-grained contextual information from places. To address thislimitation, we introduce CaLLiPer+, an extension of the CaLLiPer model thatsystematically integrates Point-of-Interest (POI) names alongside categoricallabels within a multimodal contrastive learning framework. We evaluate itseffectiveness on two downstream tasks, land use classification andsocioeconomic status distribution mapping, demonstrating consistent performancegains of 4% to 11% over baseline methods. Additionally, we show thatincorporating POI names enhances location retrieval, enabling models to capturecomplex urban concepts with greater precision. Ablation studies further revealthe complementary role of POI names and the advantages of leveraging pretrainedtext encoders for spatial representations. Overall, our findings highlight thepotential of integrating fine-grained semantic attributes and multimodallearning techniques to advance the development of urban foundation models.</description>
      <author>example@mail.com (Junyuan Liu, Xinglei Wang, Tao Cheng)</author>
      <guid isPermaLink="false">2506.02744v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Simple, Good, Fast: Self-Supervised World Models Free of Baggage</title>
      <link>http://arxiv.org/abs/2506.02612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published as a conference paper at ICLR 2025. Code is available at  https://github.com/jrobine/sgf&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SGF，这是一种简单、良好且快速的世界模型，它使用自监督表示学习，通过帧和动作堆叠捕获短期依赖，并通过数据增强增强对模型错误的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;摘要提出了世界模型的关键组件以及不使用循环神经网络（RNNs）、转换器、离散表示和图像重建的世界模型的局限性。&lt;h4&gt;目的&lt;/h4&gt;研究SGF模型的性能和其在世界模型领域的应用潜力。&lt;h4&gt;方法&lt;/h4&gt;论文详细讨论了SGF与现有世界模型的关系，通过消融研究评估了构建模块，并在Atari 100k基准测试中通过定量比较展示了良好的性能。&lt;h4&gt;主要发现&lt;/h4&gt;SGF模型能够通过自监督学习和数据增强提高模型的鲁棒性，并在基准测试中表现出良好的性能。&lt;h4&gt;结论&lt;/h4&gt;SGF模型是一种有潜力的世界模型，能够有效地处理短期依赖并提高对模型错误的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为SGF的简单、良好且快速的世界模型，该模型利用自监督表示学习，通过帧和动作堆叠捕捉短期依赖，并通过数据增强增强对模型错误的鲁棒性。论文广泛讨论了SGF与现有世界模型的关系，通过消融研究评估了构建模块，并在Atari 100k基准测试中通过定量比较展示了良好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; What are the essential components of world models? How far do we get withworld models that are not employing RNNs, transformers, discreterepresentations, and image reconstructions? This paper introduces SGF, aSimple, Good, and Fast world model that uses self-supervised representationlearning, captures short-time dependencies through frame and action stacking,and enhances robustness against model errors through data augmentation. Weextensively discuss SGF's connections to established world models, evaluate thebuilding blocks in ablation studies, and demonstrate good performance throughquantitative comparisons on the Atari 100k benchmark.</description>
      <author>example@mail.com (Jan Robine, Marc Höftmann, Stefan Harmeling)</author>
      <guid isPermaLink="false">2506.02612v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>TalkingMachines: Real-Time Audio-Driven FaceTime-Style Video via Autoregressive Diffusion Models</title>
      <link>http://arxiv.org/abs/2506.03099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TalkingMachines的高效框架，该框架可以将预训练的视频生成模型转化为实时、音频驱动的角色动画器。&lt;h4&gt;背景&lt;/h4&gt;现有的视频生成模型无法实现实时、音频驱动的角色动画。&lt;h4&gt;目的&lt;/h4&gt;通过整合音频大型语言模型（LLM）和视频生成基础模型，实现自然对话体验。&lt;h4&gt;方法&lt;/h4&gt;（1）将预训练的SOTA图像到视频模型DiT调整为18亿参数的音频驱动的角色生成模型；（2）通过从双向教师模型到稀疏因果自回归学生模型的不对称知识蒸馏，实现无错误累积的无限视频流；（3）设计了一个高吞吐量、低延迟的推理流程，包括多个关键工程优化，如DiT和VAE解码器在不同设备上的解耦，使用CUDA流高效重叠设备间通信和计算，以及消除冗余计算以最大化帧生成吞吐量。&lt;h4&gt;主要发现&lt;/h4&gt;TalkingMachines框架能够实现实时、音频驱动的角色动画，并提供了自然对话体验。&lt;h4&gt;结论&lt;/h4&gt;TalkingMachines是一种有效的方法，可以将预训练的视频生成模型转化为实时、音频驱动的角色动画器，为用户提供更加丰富的交互体验。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we introduce TalkingMachines, an efficient framework that converts pretrained video generation models into real-time, audio-driven character animators. TalkingMachines enables natural conversational experiences by integrating an audio large language model (LLM) with our video generation foundation model. Our main contributions include: (1) We adapt a pretrained SOTA image-to-video DiT into an audio-driven avatar generation model with 18 billion parameters; (2) We enable infinite video streaming without error accumulation through asymmetric knowledge distillation from a bidirectional teacher model into a sparse causal, autoregressive student model; (3) We design a high-throughput, low-latency inference pipeline incorporating several key engineering optimizations such as: (a) disaggregation of the DiT and VAE decoder across separate devices, (b) efficient overlap of inter-device communication and computation using CUDA streams, (c) elimination of redundant recomputations to maximize frame-generation throughput. Please see demo videos here - https://aaxwaz.github.io/TalkingMachines/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present TalkingMachines -- an efficient framework thattransforms pretrained video generation models into real-time, audio-drivencharacter animators. TalkingMachines enables natural conversational experiencesby integrating an audio large language model (LLM) with our video generationfoundation model. Our primary contributions include: (1) We adapt a pretrainedSOTA image-to-video DiT into an audio-driven avatar generation model of 18billion parameters; (2) We enable infinite video streaming without erroraccumulation through asymmetric knowledge distillation from a bidirectionalteacher model into a sparse causal, autoregressive student model; (3) We designa high-throughput, low-latency inference pipeline incorporating several keyengineering optimizations such as: (a) disaggregation of the DiT and VAEdecoder across separate devices, (b) efficient overlap of inter-devicecommunication and computation using CUDA streams, (c) elimination of redundantrecomputations to maximize frame-generation throughput. Please see demo videoshere - https://aaxwaz.github.io/TalkingMachines/</description>
      <author>example@mail.com (Chetwin Low, Weimin Wang)</author>
      <guid isPermaLink="false">2506.03099v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Joint Optimization based on Two-phase GNN in RIS- and DF-assisted MISO Systems with Fine-grained Rate Demands</title>
      <link>http://arxiv.org/abs/2506.02642v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 Pages, 9 figures, accepted by IEEE TRANSACTIONS ON WIRELESS  COMMUNICATIONS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于可重构智能表面（RIS）和半双工解码转发（DF）中继的联合优化模型，以优化通信系统中的无线信号传播。&lt;h4&gt;背景&lt;/h4&gt;用户通常具有不同的速率需求，并且根据需求被分为不同的组。这导致在最大化速率和满足精细速率需求之间存在权衡，以及当最大化总速率时，在组间竞争和组内合作之间也存在权衡。&lt;h4&gt;目的&lt;/h4&gt;针对传统方法往往忽略这两个权衡的问题，提出了一种新的联合优化模型。&lt;h4&gt;方法&lt;/h4&gt;该模型针对一个由多个天线组成的基站（BS）通过多个RIS和DF中继为具有精细速率需求的分组用户提供服务的MISO系统进行优化。设计了一个新的损失函数，不仅可以优化所有组的总速率，还可以通过修改惩罚参数来调整精细速率需求的满意度。此外，还提出了一种基于两阶段图神经网络（GNN）的方法，该方法输入信道状态信息（CSI），同时自主地学习有效的相位偏移、波束成形和中继选择。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法显著提高了系统性能。&lt;h4&gt;结论&lt;/h4&gt;该研究为优化通信系统中的无线信号传播提供了一种新的有效方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel joint optimization model for a communication system that leverages Reconfigurable Intelligent Surfaces (RIS) and half-duplex decoded and forwarded (DF) relays to optimize wireless signal propagation. Considering that users typically have different rate demands and are clustered into groups based on their requirements, leading to a trade-off between maximizing the rate and satisfying fine-grained rate demands, as well as a trade-off between inter-group competition and intra-group cooperation when maximizing the sum rate, the traditional approaches often overlook the joint optimization encompassing both trade-offs. To address this issue, the proposed model optimizes a multiple-input single-output (MISO) system with a base station (BS) equipped with multiple antennas transmitting data via multiple RISs and DF relays to serve grouped users with fine-grained rate demands. A new loss function is designed to not only optimize the sum rate of all groups but also adjust the satisfaction ratio of fine-grained rate demands by modifying the penalty parameter. Furthermore, a two-phase graph neural network (GNN) based approach is proposed that inputs channel state information (CSI) to simultaneously and autonomously learn efficient phase shifts, beamforming, and relay selection. The experimental results demonstrate that the proposed method significantly improves the system performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconfigurable intelligent Surfaces (RIS) and half-duplex decoded andforwarded (DF) relays can collaborate to optimize wireless signal propagationin communication systems. Users typically have different rate demands and areclustered into groups in practice based on their requirements, where the formerresults in the trade-off between maximizing the rate and satisfyingfine-grained rate demands, while the latter causes a trade-off betweeninter-group competition and intra-group cooperation when maximizing the sumrate. However, traditional approaches often overlook the joint optimizationencompassing both of these trade-offs, disregarding potential optimal solutionsand leaving some users even consistently at low date rates. To address thisissue, we propose a novel joint optimization model for a RIS- and DF-assistedmultiple-input single-output (MISO) system where a base station (BS) is withmultiple antennas transmits data by multiple RISs and DF relays to servegrouped users with fine-grained rate demands. We design a new loss function tonot only optimize the sum rate of all groups but also adjust the satisfactionratio of fine-grained rate demands by modifying the penalty parameter. Wefurther propose a two-phase graph neural network (GNN) based approach thatinputs channel state information (CSI) to simultaneously and autonomously learnefficient phase shifts, beamforming, and relay selection. The experimentalresults demonstrate that the proposed method significantly improves systemperformance.</description>
      <author>example@mail.com (Huijun Tang, Jieling Zhang, Zhidong Zhao, Huaming Wu, Hongjian Sun, Pengfei Jiao)</author>
      <guid isPermaLink="false">2506.02642v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Weak Supervision for Real World Graphs</title>
      <link>http://arxiv.org/abs/2506.02451v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了WSNET，一种用于弱监督图对比学习的框架，通过利用弱信号来指导鲁棒表示学习，解决了节点分类在现实世界图中的标签稀缺和噪声问题。&lt;h4&gt;背景&lt;/h4&gt;节点分类在现实世界图中，特别是在如人口贩卖检测和虚假信息监控等高风险领域，常常面临标签稀缺和噪声的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来利用图中的弱信号，以指导鲁棒表示学习，从而提高节点分类的准确性。&lt;h4&gt;方法&lt;/h4&gt;WSNET框架通过结合图结构、节点特征和多个噪声监督源，利用定制的对比目标来实现弱标签数据的集成。&lt;h4&gt;主要发现&lt;/h4&gt;在三个现实世界数据集和受控噪声的合成基准测试中，WSNET在F1分数上比最先进的对比学习和噪声标签学习方法提高了高达15%。&lt;h4&gt;结论&lt;/h4&gt;该研究结果强调了在弱监督下对比学习的有效性，以及在基于图的设置中利用不完整标签的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在现实世界图中进行节点分类常常受到标签稀缺和噪声的困扰，尤其是在如人口贩卖检测和虚假信息监控等高风险领域。虽然直接监督有限，但这些图通常包含可以指导学习的弱信号、噪声或间接线索。我们提出了WSNET，一种新颖的弱监督图对比学习框架，它利用这些弱信号来指导鲁棒的表示学习。WSNET通过对比目标集成图结构、节点特征和多个噪声监督源，适用于弱标签数据。在三个现实世界数据集和受控噪声的合成基准测试中，WSNET在F1分数上始终优于最先进的对比学习和噪声标签学习方法，最高提高了15%。我们的结果突出了弱监督下对比学习的有效性以及在不完美的标签中利用基于图设置的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Node classification in real world graphs often suffers from label scarcityand noise, especially in high stakes domains like human trafficking detectionand misinformation monitoring. While direct supervision is limited, such graphsfrequently contain weak signals, noisy or indirect cues, that can still informlearning. We propose WSNET, a novel weakly supervised graph contrastivelearning framework that leverages these weak signals to guide robustrepresentation learning. WSNET integrates graph structure, node features, andmultiple noisy supervision sources through a contrastive objective tailored forweakly labeled data. Across three real world datasets and synthetic benchmarkswith controlled noise, WSNET consistently outperforms state of the artcontrastive and noisy label learning methods by up to 15% in F1 score. Ourresults highlight the effectiveness of contrastive learning under weaksupervision and the promise of exploiting imperfect labels in graph basedsettings.</description>
      <author>example@mail.com (Pratheeksha Nair, Reihaneh Rabbany)</author>
      <guid isPermaLink="false">2506.02451v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>UTCS: Effective Unsupervised Temporal Community Search with Pre-training of Temporal Dynamics and Subgraph Knowledge</title>
      <link>http://arxiv.org/abs/2506.02784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGIR'25 short paper track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对时间图中的社区搜索问题，提出了一种无监督时间社区搜索方法，通过预训练时间动态和子图知识模型来解决传统方法需要预定义子图结构和基于学习的方法难以捕捉时间交互信息的问题。&lt;h4&gt;背景&lt;/h4&gt;在许多实际应用中，实体之间的关系可以建模为时间图，其中每条边都有一个时间戳表示交互时间。社区搜索（CS）是图分析中的一个基本问题，但在时间图中存在两个主要局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的无监督时间社区搜索方法，以解决传统方法和基于学习的方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;该方法包含两个关键阶段：离线预训练和在线搜索。在离线预训练阶段，引入多个学习目标以促进无监督学习环境下的预训练过程。在线搜索阶段，通过预训练的节点表示和一种新颖的评分机制来确定候选子图和社区成员。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在五个真实世界数据集上表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效解决时间图中的社区搜索问题，为相关研究提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;In many real-world applications, the evolving relationships between entities can be modeled as temporal graphs, where each edge has a timestamp representing the interaction time. As a fundamental problem in graph analysis, community search (CS) in temporal graphs has received growing attention but exhibits two major limitations: (1) Traditional methods typically require predefined subgraph structures, which are not always known in advance. (2) Learning-based methods struggle to capture temporal interaction information. To fill this research gap, in this paper, we propose an effective Unsupervised Temporal Community Search with pre-training of temporal dynamics and subgraph knowledge model (model). The model contains two key stages: offline pre-training and online search. In the first stage, we introduce multiple learning objectives to facilitate the pre-training process in the unsupervised learning setting. In the second stage, we identify a candidate subgraph and compute community scores using the pre-trained node representations and a novel scoring mechanism to determine the final community members. Experiments on five real-world datasets demonstrate the effectiveness.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In many real-world applications, the evolving relationships between entitiescan be modeled as temporal graphs, where each edge has a timestamp representingthe interaction time.  As a fundamental problem in graph analysis, {\it community search (CS)} intemporal graphs has received growing attention but exhibits two majorlimitations: (1) Traditional methods typically require predefined subgraphstructures, which are not always known in advance. (2) Learning-based methodsstruggle to capture temporal interaction information. To fill this researchgap, in this paper, we propose an effective \textbf{U}nsupervised\textbf{T}emporal \textbf{C}ommunity \textbf{S}earch with pre-training oftemporal dynamics and subgraph knowledge model (\textbf{\model}).\model~contains two key stages: offline pre-training and online search. In thefirst stage, we introduce multiple learning objectives to facilitate thepre-training process in the unsupervised learning setting. In the second stage,we identify a candidate subgraph and compute community scores using thepre-trained node representations and a novel scoring mechanism to determine thefinal community members. Experiments on five real-world datasets demonstratethe effectiveness.</description>
      <author>example@mail.com (Yue Zhang, Yankai Chen, Yingli Zhou, Yucan Guo, Xiaolin Han, Chenhao Ma)</author>
      <guid isPermaLink="false">2506.02784v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>HGOT: Self-supervised Heterogeneous Graph Neural Network with Optimal Transport</title>
      <link>http://arxiv.org/abs/2506.02619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The paper has 9 pages of text and 13 pages in total (including  acknowledgments, impact statement, references, and appendix), with 6 figures  and 2 tables. This paper has been accepted by ICML 2025 conference and this  is a final version of the manuscript submitted to the conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的无图增强的自监督异构图神经网络（HGOT），通过最优传输机制缓解了正负样本采样的繁琐过程，在多个下游任务中取得了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;异构图神经网络（HGNNs）在处理异构信息网络方面表现出色，而自监督学习在无标签情况下具有巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;设计一种无需图增强策略的自监督学习方法，以提高异构图神经网络在下游任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;HGOT利用最优传输机制，设计了一种聚合视图（中心视图）来整合不同元路径（分支视图）中的语义信息，并引入最优传输计划以识别分支视图中的语义与中心视图之间的传输关系。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界数据集上的实验表明，HGOT在节点分类任务上平均比最先进的方法提高了超过6%的准确率。&lt;h4&gt;结论&lt;/h4&gt;HGOT模型在多种下游任务中实现了最先进的性能，特别是在节点分类任务上表现出显著优势。&lt;h4&gt;翻译&lt;/h4&gt;Heterogeneous Graph Neural Networks (HGNNs), have demonstrated excellent capabilities in processing heterogeneous information networks. Self-supervised learning on heterogeneous graphs, especially contrastive self-supervised strategy, shows great potential when there are no labels. However, this approach requires the use of carefully designed graph augmentation strategies and the selection of positive and negative samples. Determining the exact level of similarity between sample pairs is non-trivial. To solve this problem, we propose a novel self-supervised Heterogeneous graph neural network with Optimal Transport (HGOT) method which is designed to facilitate self-supervised learning for heterogeneous graphs without graph augmentation strategies. Different from traditional contrastive self-supervised learning, HGOT employs the optimal transport mechanism to relieve the laborious sampling process of positive and negative samples. Specifically, we design an aggregating view (central view) to integrate the semantic information contained in the views represented by different meta-paths (branch views). Then, we introduce an optimal transport plan to identify the transport relationship between these semantics contained in the branch view and the central view. This allows the optimal transport plan between graphs to align with the representations, forcing the encoder to learn node representations that are more similar to the graph space and of higher quality. Extensive experiments on four real-world datasets demonstrate that our proposed HGOT model can achieve state-of-the-art performance on various downstream tasks. In particular, in the node classification task, HGOT achieves an average of more than 6% improvement in accuracy compared with state-of-the-art methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterogeneous Graph Neural Networks (HGNNs), have demonstrated excellentcapabilities in processing heterogeneous information networks. Self-supervisedlearning on heterogeneous graphs, especially contrastive self-supervisedstrategy, shows great potential when there are no labels. However, thisapproach requires the use of carefully designed graph augmentation strategiesand the selection of positive and negative samples. Determining the exact levelof similarity between sample pairs is non-trivial.To solve this problem, wepropose a novel self-supervised Heterogeneous graph neural network with OptimalTransport (HGOT) method which is designed to facilitate self-supervisedlearning for heterogeneous graphs without graph augmentation strategies.Different from traditional contrastive self-supervised learning, HGOT employsthe optimal transport mechanism to relieve the laborious sampling process ofpositive and negative samples. Specifically, we design an aggregating view(central view) to integrate the semantic information contained in the viewsrepresented by different meta-paths (branch views). Then, we introduce anoptimal transport plan to identify the transport relationship between thesemantics contained in the branch view and the central view. This allows theoptimal transport plan between graphs to align with the representations,forcing the encoder to learn node representations that are more similar to thegraph space and of higher quality. Extensive experiments on four real-worlddatasets demonstrate that our proposed HGOT model can achieve state-of-the-artperformance on various downstream tasks. In particular, in the nodeclassification task, HGOT achieves an average of more than 6% improvement inaccuracy compared with state-of-the-art methods.</description>
      <author>example@mail.com (Yanbei Liu, Chongxu Wang, Zhitao Xiao, Lei Geng, Yanwei Pang, Xiao Wang)</author>
      <guid isPermaLink="false">2506.02619v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Learning Treatment Representations for Downstream Instrumental Variable Regression</title>
      <link>http://arxiv.org/abs/2506.02200v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法来构建治疗表示，通过在表示学习过程中显式地纳入工具变量，以解决传统工具变量估计方法在处理高维无结构治疗变量时的限制。&lt;h4&gt;背景&lt;/h4&gt;传统的工具变量估计方法受限于可用的工具变量数量，难以处理高维和无结构的治疗变量，如医院中患者治疗路径的描述。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以解决高维内生变量和有限工具变量的问题，并确保工具变量表示的学习过程中不会产生重大遗漏变量偏差。&lt;h4&gt;方法&lt;/h4&gt;在表示学习过程中显式地纳入工具变量，提供了一种处理高维内生变量的框架，并通过实验验证了该方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法优于传统两阶段方法，后者在降维时不包含工具变量信息，能够优化结果预测的方向。&lt;h4&gt;结论&lt;/h4&gt;通过在表示学习过程中显式地纳入工具变量，可以构建更准确的治疗表示，从而提高高维内生变量分析的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional instrumental variable (IV) estimators face a fundamentalconstraint: they can only accommodate as many endogenous treatment variables asavailable instruments. This limitation becomes particularly challenging insettings where the treatment is presented in a high-dimensional andunstructured manner (e.g. descriptions of patient treatment pathways in ahospital). In such settings, researchers typically resort to applyingunsupervised dimension reduction techniques to learn a low-dimensionaltreatment representation prior to implementing IV regression analysis. We showthat such methods can suffer from substantial omitted variable bias due toimplicit regularization in the representation learning step. We propose a novelapproach to construct treatment representations by explicitly incorporatinginstrumental variables during the representation learning process. Our approachprovides a framework for handling high-dimensional endogenous variables withlimited instruments. We demonstrate both theoretically and empirically thatfitting IV models on these instrument-informed representations ensuresidentification of directions that optimize outcome prediction. Our experimentsshow that our proposed methodology improves upon the conventional two-stageapproaches that perform dimension reduction without incorporating instrumentinformation.</description>
      <author>example@mail.com (Shiangyi Lin, Hui Lan, Vasilis Syrgkanis)</author>
      <guid isPermaLink="false">2506.02200v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Self-attention U-Net decoder for toric codes</title>
      <link>http://arxiv.org/abs/2506.02734v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages; 12 figures;&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种适用于toric码的自注意力U-Net量子解码器（SU-NetQD），在电路级噪声环境中优于最小权重完美匹配解码器，提高了量子纠错码和量子计算的实用性。&lt;h4&gt;背景&lt;/h4&gt;在NISQ时代，量子纠错是实现通用量子计算的重要瓶颈，而量子错误纠正码中的稳定子码是其中最常见的一种。高效可扩展的解码器是量子错误纠正码应用的关键。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的量子解码器，以解决toric码在量子纠错中的解码问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种自注意力U-Net量子解码器（SU-NetQD），该解码器结合了低级解码器和高级解码器，并利用迁移学习机制。&lt;h4&gt;主要发现&lt;/h4&gt;SU-NetQD在电路级噪声环境中优于最小权重完美匹配解码器，实现了比MWPM更低的逻辑错误率，并发现随着噪声偏差的增加，码阈值呈上升趋势。在极端偏置的噪声环境中，达到0.231的高阈值。&lt;h4&gt;结论&lt;/h4&gt;SU-NetQD是一个高精度解码器的关键创新，提供了量子噪声分析的实用工具，促进了量子纠错码和量子计算的实用性。&lt;h4&gt;翻译&lt;/h4&gt;In the NISQ era, one of the most important bottlenecks for the realization of universal quantum computation is error correction. Stabiliser code is the most recognizable type of quantum error correction code. A scalable efficient decoder is most desired for the application of the quantum error correction codes. In this work, we propose a self-attention U-Net quantum decoder (SU-NetQD) for toric code, which outperforms the minimum weight perfect matching decoder, especially in the circuit level noise environments. Specifically, with our SU-NetQD, we achieve lower logical error rates compared with MWPM and discover an increased trend of code threshold as the increase of noise bias. We obtain a high threshold of 0.231 for the extremely biased noise environment. The combination of low-level decoder and high-level decoder is the key innovation for the high accuracy of our decoder. With transfer learning mechanics, our decoder is scalable for cases with different code distances. Our decoder provides a practical tool for quantum noise analysis and promotes the practicality of quantum error correction codes and quantum computing.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/xiazhuo/SUNetQD&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the NISQ era, one of the most important bottlenecks for the realization ofuniversal quantum computation is error correction. Stabiliser code is the mostrecognizable type of quantum error correction code. A scalable efficientdecoder is most desired for the application of the quantum error correctioncodes. In this work, we propose a self-attention U-Net quantum decoder(SU-NetQD) for toric code, which outperforms the minimum weight perfectmatching decoder, especially in the circuit level noise environments.Specifically, with our SU-NetQD, we achieve lower logical error rates comparedwith MWPM and discover an increased trend of code threshold as the increase ofnoise bias. We obtain a high threshold of 0.231 for the extremely biased noiseenvironment. The combination of low-level decoder and high-level decoder is thekey innovation for the high accuracy of our decoder. With transfer learningmechanics, our decoder is scalable for cases with different code distances. Ourdecoder provides a practical tool for quantum noise analysis and promotes thepracticality of quantum error correction codes and quantum computing.</description>
      <author>example@mail.com (Wei-Wei Zhang, Zhuo Xia, Wei Zhao, Wei Pan, Haobin Shi)</author>
      <guid isPermaLink="false">2506.02734v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MotionRAG-Diff: A Retrieval-Augmented Diffusion Framework for Long-Term Music-to-Dance Generation</title>
      <link>http://arxiv.org/abs/2506.02661v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MotionRAG-Diff的混合框架，用于生成长期、连贯且逼真的音乐条件舞蹈序列，解决了现有方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;生成长期、连贯且逼真的音乐条件舞蹈序列是人体运动合成的挑战性任务。现有方法存在关键局限性：运动图方法依赖于固定的模板库，限制了创造性生成；扩散模型虽然能够产生新颖的动作，但通常缺乏时间一致性和音乐对齐。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一种名为MotionRAG-Diff的混合框架，以实现高质量、音乐一致的舞蹈生成，适用于任意长期音乐输入。&lt;h4&gt;方法&lt;/h4&gt;该方法引入了三项核心创新：(1) 一种跨模态对比学习架构，在共享潜在空间中对异构的音乐和舞蹈表示进行对齐，建立无配对数据的无监督语义对应；(2) 一种优化的运动图系统，用于高效检索和无缝连接运动片段，确保长序列中的真实性和时间一致性；(3) 一种多条件扩散模型，联合条件原始音乐信号和对比特征，以增强运动质量和全局同步。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，MotionRAG-Diff在运动质量、多样性和音乐-运动同步精度方面达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;这项工作通过结合基于检索的模板保真度与基于扩散的创造性增强，为音乐驱动的舞蹈生成建立了一种新的范式。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成长期、连贯、逼真的音乐条件舞蹈序列仍然是人体运动合成中的一个挑战性任务。现有方法存在关键局限性：运动图方法依赖于固定的模板库，限制了创造性生成；扩散模型虽然能够产生新颖的动作，但通常缺乏时间一致性和音乐对齐。为了解决这些挑战，我们提出了一种名为MotionRAG-Diff的混合框架，该框架整合了检索增强生成（RAG）和基于扩散的细化，以实现高质量、音乐一致的舞蹈生成，适用于任意长期音乐输入。我们的方法引入了三项核心创新：(1) 一种跨模态对比学习架构，在共享潜在空间中对异构的音乐和舞蹈表示进行对齐，建立无配对数据的无监督语义对应；(2) 一种优化的运动图系统，用于高效检索和无缝连接运动片段，确保长序列中的真实性和时间一致性；(3) 一种多条件扩散模型，联合条件原始音乐信号和对比特征，以增强运动质量和全局同步。广泛的实验表明，MotionRAG-Diff在运动质量、多样性和音乐-运动同步精度方面达到了最先进的性能。这项工作通过结合基于检索的模板保真度与基于扩散的创造性增强，为音乐驱动的舞蹈生成建立了一种新的范式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating long-term, coherent, and realistic music-conditioned dancesequences remains a challenging task in human motion synthesis. Existingapproaches exhibit critical limitations: motion graph methods rely on fixedtemplate libraries, restricting creative generation; diffusion models, whilecapable of producing novel motions, often lack temporal coherence and musicalalignment. To address these challenges, we propose $\textbf{MotionRAG-Diff}$, ahybrid framework that integrates Retrieval-Augmented Generation (RAG) withdiffusion-based refinement to enable high-quality, musically coherent dancegeneration for arbitrary long-term music inputs. Our method introduces threecore innovations: (1) A cross-modal contrastive learning architecture thataligns heterogeneous music and dance representations in a shared latent space,establishing unsupervised semantic correspondence without paired data; (2) Anoptimized motion graph system for efficient retrieval and seamlessconcatenation of motion segments, ensuring realism and temporal coherenceacross long sequences; (3) A multi-condition diffusion model that jointlyconditions on raw music signals and contrastive features to enhance motionquality and global synchronization. Extensive experiments demonstrate thatMotionRAG-Diff achieves state-of-the-art performance in motion quality,diversity, and music-motion synchronization accuracy. This work establishes anew paradigm for music-driven dance generation by synergizing retrieval-basedtemplate fidelity with diffusion-based creative enhancement.</description>
      <author>example@mail.com (Mingyang Huang, Peng Zhang, Bang Zhang)</author>
      <guid isPermaLink="false">2506.02661v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>HIEGNet: A Heterogenous Graph Neural Network Including the Immune Environment in Glomeruli Classification</title>
      <link>http://arxiv.org/abs/2506.02542v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for poster presentation at MIDL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HIEGNet的异构图神经网络架构，用于肾小球健康分类，并在肾移植患者的全切片图像数据集上进行了测试。&lt;h4&gt;背景&lt;/h4&gt;GNNs在组织病理学领域表现出色，但在肾小球健康分类任务上尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来分类肾小球健康，特别是在识别节点、边及其特征方面。&lt;h4&gt;方法&lt;/h4&gt;使用传统的计算机视觉技术和机器学习技术来识别节点、边和相应的特征，构建异构图，并提出HIEGNet架构进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，HIEGNet在肾小球分类任务中优于多个基线模型，并且在所有基线模型中具有最佳的泛化性能。&lt;h4&gt;结论&lt;/h4&gt;HIEGNet能够考虑每个肾小球的免疫环境，并在肾小球健康分类任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have recently been found to excel in histopathology. However, an important histopathological task, where GNNs have not been extensively explored, is the classification of glomeruli health as an important indicator in nephropathology. This task presents unique difficulties, particularly for the graph construction, i.e., the identification of nodes, edges, and informative features. In this work, we propose a pipeline composed of different traditional and machine learning-based computer vision techniques to identify nodes, edges, and their corresponding features to form a heterogeneous graph. We then proceed to propose a novel heterogeneous GNN architecture for glomeruli classification, called HIEGNet, that integrates both glomeruli and their surrounding immune cells. Hence, HIEGNet is able to consider the immune environment of each glomerulus in its classification. Our HIEGNet was trained and tested on a dataset of Whole Slide Images from kidney transplant patients. Experimental results demonstrate that HIEGNet outperforms several baseline models and generalises best between patients among all baseline models. Our implementation is publicly available at https://github.com/nklsKrmnn/HIEGNet.git.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have recently been found to excel inhistopathology. However, an important histopathological task, where GNNs havenot been extensively explored, is the classification of glomeruli health as animportant indicator in nephropathology. This task presents unique difficulties,particularly for the graph construction, i.e., the identification of nodes,edges, and informative features. In this work, we propose a pipeline composedof different traditional and machine learning-based computer vision techniquesto identify nodes, edges, and their corresponding features to form aheterogeneous graph. We then proceed to propose a novel heterogeneous GNNarchitecture for glomeruli classification, called HIEGNet, that integrates bothglomeruli and their surrounding immune cells. Hence, HIEGNet is able toconsider the immune environment of each glomerulus in its classification. OurHIEGNet was trained and tested on a dataset of Whole Slide Images from kidneytransplant patients. Experimental results demonstrate that HIEGNet outperformsseveral baseline models and generalises best between patients among allbaseline models. Our implementation is publicly available athttps://github.com/nklsKrmnn/HIEGNet.git.</description>
      <author>example@mail.com (Niklas Kormann, Masoud Ramuz, Zeeshan Nisar, Nadine S. Schaadt, Hendrik Annuth, Benjamin Doerr, Friedrich Feuerhake, Thomas Lampert, Johannes F. Lutzeyer)</author>
      <guid isPermaLink="false">2506.02542v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MLaGA: Multimodal Large Language and Graph Assistant</title>
      <link>http://arxiv.org/abs/2506.02568v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MLaGA的多模态大语言和图助手模型，旨在扩展大型语言模型在处理复杂图结构和多模态属性推理方面的能力。&lt;h4&gt;背景&lt;/h4&gt;尽管大型语言模型在文本丰富的图数据分析方面表现出显著的效果，但它们在多模态图上的应用还未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;旨在解决多模态图在现实场景中的广泛应用与其在现有方法中的不足。&lt;h4&gt;方法&lt;/h4&gt;设计了一个结构感知的多模态编码器，通过联合图预训练目标将文本和视觉属性对齐到一个统一的空间中，并实现了一个多模态指令调整方法，通过轻量级投影将多模态特征和图结构整合到LLM中。&lt;h4&gt;主要发现&lt;/h4&gt;MLaGA在多个数据集上的实验表明，与领先的基线方法相比，它在各种图学习任务中实现了优越的性能，无论是监督学习还是迁移学习场景。&lt;h4&gt;结论&lt;/h4&gt;MLaGA能够有效提升大型语言模型在多模态图数据分析方面的能力，为解决现实世界中的多模态图问题提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have demonstrated substantial efficacy inadvancing graph-structured data analysis. Prevailing LLM-based graph methodsexcel in adapting LLMs to text-rich graphs, wherein node attributes are textdescriptions. However, their applications to multimodal graphs--where nodes areassociated with diverse attribute types, such as texts and images--remainunderexplored, despite their ubiquity in real-world scenarios. To bridge thegap, we introduce the Multimodal Large Language and Graph Assistant (MLaGA), aninnovative model that adeptly extends LLM capabilities to facilitate reasoningover complex graph structures and multimodal attributes. We first design astructure-aware multimodal encoder to align textual and visual attributeswithin a unified space through a joint graph pre-training objective.Subsequently, we implement a multimodal instruction-tuning approach toseamlessly integrate multimodal features and graph structures into the LLMthrough lightweight projectors. Extensive experiments across multiple datasetsdemonstrate the effectiveness of MLaGA compared to leading baseline methods,achieving superior performance in diverse graph learning tasks under bothsupervised and transfer learning scenarios.</description>
      <author>example@mail.com (Dongzhe Fan, Yi Fang, Jiajin Liu, Djellel Difallah, Qiaoyu Tan)</author>
      <guid isPermaLink="false">2506.02568v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Descriptive History Representations: Learning Representations by Answering Questions</title>
      <link>http://arxiv.org/abs/2506.02125v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于部分可观察环境的有效决策方法，即描述性历史表示（DHRs），通过压缩长交互历史以提供信息化的表示。该方法在用户建模任务中得到了验证，可以生成可解释的文本用户档案，用于预测用户的行为。&lt;h4&gt;背景&lt;/h4&gt;在部分可观察环境中，有效决策需要将长交互历史压缩成信息化的表示。&lt;h4&gt;目的&lt;/h4&gt;提出描述性历史表示（DHRs），以优化控制并提供一种结构化的方式来总结历史。&lt;h4&gt;方法&lt;/h4&gt;设计了一个多智能体学习框架，包括表示、决策和提问组件，并使用联合目标进行优化，以平衡奖励最大化与表示回答信息性问题的能力。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在用户建模任务中有效，能够生成足够的统计数据，预测用户基于偏好的行为。&lt;h4&gt;结论&lt;/h4&gt;DHRs可以有效地捕捉历史细节和预测结构，为有效决策提供支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective decision making in partially observable environments requirescompressing long interaction histories into informative representations. Weintroduce Descriptive History Representations (DHRs): sufficient statisticscharacterized by their capacity to answer relevant questions about pastinteractions and potential future outcomes. DHRs focus on capturing theinformation necessary to address task-relevant queries, providing a structuredway to summarize a history for optimal control. We propose a multi-agentlearning framework, involving representation, decision, and question-askingcomponents, optimized using a joint objective that balances reward maximizationwith the representation's ability to answer informative questions. This yieldsrepresentations that capture the salient historical details and predictivestructures needed for effective decision making. We validate our approach onuser modeling tasks with public movie and shopping datasets, generatinginterpretable textual user profiles which serve as sufficient statistics forpredicting preference-driven behavior of users.</description>
      <author>example@mail.com (Guy Tennenholtz, Jihwan Jeong, Chih-Wei Hsu, Yinlam Chow, Craig Boutilier)</author>
      <guid isPermaLink="false">2506.02125v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Towards Geometry Problem Solving in the Large Model Era: A Survey</title>
      <link>http://arxiv.org/abs/2506.02690v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8pages, 4 figures, conference submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了几何问题解决（GPS）在人工智能领域的进展，探讨了其在教育、计算机辅助设计和计算图形学中的应用。&lt;h4&gt;背景&lt;/h4&gt;尽管GPS在教育、设计等领域具有重要意义，但由于需要空间理解和严谨的逻辑推理，自动化GPS仍具挑战性。&lt;h4&gt;目的&lt;/h4&gt;系统性地总结了GPS的进展，并提出了一个统一的分析范式，以指导未来研究向人类水平的几何推理发展。&lt;h4&gt;方法&lt;/h4&gt;通过三个核心维度：基准构建、文本和图表解析、推理范式来综述GPS的进展。&lt;h4&gt;主要发现&lt;/h4&gt;近年来，大型模型在SAT级别问题上的突破显著，但该领域在方法、基准和评估框架上仍存在碎片化。&lt;h4&gt;结论&lt;/h4&gt;提出了统一的解析范式，评估了当前局限性，并确定了未来研究的新机遇，包括自动基准生成和可解释的神经符号集成。&lt;h4&gt;翻译&lt;/h4&gt;摘要：几何问题解决（GPS）代表人工智能的一个关键前沿，在教育、计算机辅助设计和计算图形学等领域具有深远的应用。尽管其意义重大，但由于对空间理解和严谨逻辑推理的双重需求，自动化GPS仍然具有挑战性。最近，大型模型的发展使SAT级别问题的突破成为可能，但该领域在方法、基准和评估框架上仍然存在碎片化。本文通过三个核心维度系统地综合了GPS的进展：（1）基准构建，（2）文本和图表解析，（3）推理范式。我们进一步提出了一种统一的分析范式，评估了当前的局限性，并确定了未来研究的新机遇，包括自动化基准生成和可解释的神经符号集成。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometry problem solving (GPS) represents a critical frontier in artificialintelligence, with profound applications in education, computer-aided design,and computational graphics. Despite its significance, automating GPS remainschallenging due to the dual demands of spatial understanding and rigorouslogical reasoning. Recent advances in large models have enabled notablebreakthroughs, particularly for SAT-level problems, yet the field remainsfragmented across methodologies, benchmarks, and evaluation frameworks. Thissurvey systematically synthesizes GPS advancements through three coredimensions: (1) benchmark construction, (2) textual and diagrammatic parsing,and (3) reasoning paradigms. We further propose a unified analytical paradigm,assess current limitations, and identify emerging opportunities to guide futureresearch toward human-level geometric reasoning, including automated benchmarkgeneration and interpretable neuro-symbolic integration.</description>
      <author>example@mail.com (Yurui Zhao, Xiang Wang, Jiahong Liu, Irwin King, Zhitao Huang)</author>
      <guid isPermaLink="false">2506.02690v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Contrast &amp; Compress: Learning Lightweight Embeddings for Short Trajectories</title>
      <link>http://arxiv.org/abs/2506.02571v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted for peer review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，通过Transformer编码器和对比三元组损失学习短轨迹的固定维度嵌入，以提高运动预测和自主导航等下游应用的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常依赖于计算密集型的启发式算法或缺乏可解释性和可控性的潜在锚点表示。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够高效且准确地检索语义和方向上相似的短轨迹的新框架。&lt;h4&gt;方法&lt;/h4&gt;提出了一种利用Transformer编码器和对比三元组损失学习固定维度嵌入的方法，并分析了余弦和基于FFT的相似性指标在对比学习范式中的影响，以捕捉短期操纵的特征方向意图。&lt;h4&gt;主要发现&lt;/h4&gt;在Argoverse 2数据集上的实验表明，由余弦相似性目标形成的嵌入在语义和方向属性上的轨迹聚类表现优于基于FFT的基线，并且在检索任务中表现出色。紧凑的Transformer架构即使在低维嵌入（例如16维，但质地上降至4维）的情况下，也能在检索性能和计算开销之间实现令人满意的平衡。&lt;h4&gt;结论&lt;/h4&gt;该框架提供了紧凑、语义上有意义且高效的轨迹数据表示，为启发式相似度度量提供了一种稳健的替代方案，并为更透明和可控的运动预测流程铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;The ability to retrieve semantically and directionally similar short-range trajectories with both accuracy and efficiency is foundational for downstream applications such as motion forecasting and autonomous navigation. However, prevailing approaches often depend on computationally intensive heuristics or latent anchor representations that lack interpretability and controllability. In this work, we propose a novel framework for learning fixed-dimensional embeddings for short trajectories by leveraging a Transformer encoder trained with a contrastive triplet loss that emphasize the importance of discriminative feature spaces for trajectory data. We analyze the influence of Cosine and FFT-based similarity metrics within the contrastive learning paradigm, with a focus on capturing the nuanced directional intent that characterizes short-term maneuvers. Our empirical evaluation on the Argoverse 2 dataset demonstrates that embeddings shaped by Cosine similarity objectives yield superior clustering of trajectories by both semantic and directional attributes, outperforming FFT-based baselines in retrieval tasks. Notably, we show that compact Transformer architectures, even with low-dimensional embeddings (e.g., 16 dimensions, but qualitatively down to 4), achieve a compelling balance between retrieval performance (minADE, minFDE) and computational overhead, aligning with the growing demand for scalable and interpretable motion priors in real-time systems. The resulting embeddings provide a compact, semantically meaningful, and efficient representation of trajectory data, offering a robust alternative to heuristic similarity measures and paving the way for more transparent and controllable motion forecasting pipelines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to retrieve semantically and directionally similar short-rangetrajectories with both accuracy and efficiency is foundational for downstreamapplications such as motion forecasting and autonomous navigation. However,prevailing approaches often depend on computationally intensive heuristics orlatent anchor representations that lack interpretability and controllability.In this work, we propose a novel framework for learning fixed-dimensionalembeddings for short trajectories by leveraging a Transformer encoder trainedwith a contrastive triplet loss that emphasize the importance of discriminativefeature spaces for trajectory data. We analyze the influence of Cosine andFFT-based similarity metrics within the contrastive learning paradigm, with afocus on capturing the nuanced directional intent that characterizes short-termmaneuvers. Our empirical evaluation on the Argoverse 2 dataset demonstratesthat embeddings shaped by Cosine similarity objectives yield superiorclustering of trajectories by both semantic and directional attributes,outperforming FFT-based baselines in retrieval tasks. Notably, we show thatcompact Transformer architectures, even with low-dimensional embeddings (e.g.,16 dimensions, but qualitatively down to 4), achieve a compelling balancebetween retrieval performance (minADE, minFDE) and computational overhead,aligning with the growing demand for scalable and interpretable motion priorsin real-time systems. The resulting embeddings provide a compact, semanticallymeaningful, and efficient representation of trajectory data, offering a robustalternative to heuristic similarity measures and paving the way for moretransparent and controllable motion forecasting pipelines.</description>
      <author>example@mail.com (Abhishek Vivekanandan, Christian Hubschneider, J. Marius Zöllner)</author>
      <guid isPermaLink="false">2506.02571v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Large Language Models for Polymer Property Predictions</title>
      <link>http://arxiv.org/abs/2506.02129v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了机器学习在聚合物科学中的应用，特别是大语言模型（LLMs）在聚合物信息学中的潜力，通过在精心策划的数据集上微调LLMs来预测热性能。&lt;h4&gt;背景&lt;/h4&gt;机器学习对聚合物科学产生了革命性的影响，特别是LLMs简化了依赖大量标记数据集、手工特征表示和复杂特征工程的传统工作流程。&lt;h4&gt;目的&lt;/h4&gt;目的是通过微调通用的LLMs来预测聚合物的关键热性能，包括玻璃转变温度、熔点和分解温度。&lt;h4&gt;方法&lt;/h4&gt;研究人员对开源的LLaMA-3-8B和商业的GPT-3.5进行了微调，并在11,740条条目的数据集上进行了测试。他们使用了参数高效的微调和超参数优化，并将这些模型与基于指纹的传统方法进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;LLM方法在性能上接近传统模型，但在预测精度和效率上普遍表现不佳。LLaMA-3在性能上优于GPT-3.5，可能是因为其可调的开源架构。单任务学习（ST）比多任务学习（MT）更有效，因为LLMs难以捕捉跨属性相关性。分子嵌入的分析揭示了通用LLMs在表示细微的化学结构信息方面的局限性。&lt;h4&gt;结论&lt;/h4&gt;这些发现提供了分子嵌入和自然语言处理之间相互作用的见解，指导了LLMs在聚合物信息学中的应用选择。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning has revolutionized polymer science by enabling rapidproperty prediction and generative design. Large language models (LLMs) offerfurther opportunities in polymer informatics by simplifying workflows thattraditionally rely on large labeled datasets, handcrafted representations, andcomplex feature engineering. LLMs leverage natural language inputs throughtransfer learning, eliminating the need for explicit fingerprinting andstreamlining training. In this study, we finetune general purpose LLMs --open-source LLaMA-3-8B and commercial GPT-3.5 -- on a curated dataset of 11,740entries to predict key thermal properties: glass transition, melting, anddecomposition temperatures. Using parameter-efficient fine-tuning andhyperparameter optimization, we benchmark these models against traditionalfingerprinting-based approaches -- Polymer Genome, polyGNN, and polyBERT --under single-task (ST) and multi-task (MT) learning. We find that whileLLM-based methods approach traditional models in performance, they generallyunderperform in predictive accuracy and efficiency. LLaMA-3 consistentlyoutperforms GPT-3.5, likely due to its tunable open-source architecture.Additionally, ST learning proves more effective than MT, as LLMs struggle tocapture cross-property correlations, a key strength of traditional methods.Analysis of molecular embeddings reveals limitations of general purpose LLMs inrepresenting nuanced chemo-structural information compared to handcraftedfeatures and domain-specific embeddings. These findings provide insight intothe interplay between molecular embeddings and natural language processing,guiding LLM selection for polymer informatics.</description>
      <author>example@mail.com (Sonakshi Gupta, Akhlak Mahmood, Shivank Shukla, Rampi Ramprasad)</author>
      <guid isPermaLink="false">2506.02129v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MLLMs Need 3D-Aware Representation Supervision for Scene Understanding</title>
      <link>http://arxiv.org/abs/2506.01946v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了多模态大型语言模型（MLLMs）的3D感知能力，并提出了一个名为3DRS的框架，通过引入预训练的3D基础模型来增强MLLM的3D表示学习，从而提高场景理解能力。&lt;h4&gt;背景&lt;/h4&gt;MLLMs在3D推理方面利用了其强大的2D预训练能力，但缺乏明确的3D数据限制了3D表示能力。&lt;h4&gt;目的&lt;/h4&gt;研究MLLMs的3D感知能力，并提出方法来增强MLLM的3D表示学习。&lt;h4&gt;方法&lt;/h4&gt;通过评估多视图对应关系，揭示3D感知表示质量与下游任务性能之间的强正相关关系。提出3DRS框架，通过引入预训练3D基础模型的监督来增强MLLM的3D表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;3D感知表示的质量与下游任务性能之间存在强正相关关系。&lt;h4&gt;结论&lt;/h4&gt;3DRS框架通过将MLLM视觉特征与从3D模型中提炼的丰富3D知识对齐，有效提高了场景理解能力。&lt;h4&gt;翻译&lt;/h4&gt;The abstract of the paper investigates the 3D awareness of multimodal large language models (MLLMs) by evaluating multi-view correspondence and reveals a strong positive correlation between the quality of 3D-aware representation and downstream task performance. Motivated by this, the paper proposes 3DRS, a framework that enhances MLLM 3D representation learning by introducing supervision from pretrained 3D foundation models. The approach aligns MLLM visual features with rich 3D knowledge distilled from 3D models, effectively improving scene understanding. Extensive experiments across multiple benchmarks and MLLMs, including visual grounding, captioning, and question answering, demonstrate consistent performance gains. Project page: https://visual-ai.github.io/3drs&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in scene understanding have leveraged multimodal largelanguage models (MLLMs) for 3D reasoning by capitalizing on their strong 2Dpretraining. However, the lack of explicit 3D data during MLLM pretraininglimits 3D representation capability. In this paper, we investigate the3D-awareness of MLLMs by evaluating multi-view correspondence and reveal astrong positive correlation between the quality of 3D-aware representation anddownstream task performance. Motivated by this, we propose 3DRS, a frameworkthat enhances MLLM 3D representation learning by introducing supervision frompretrained 3D foundation models. Our approach aligns MLLM visual features withrich 3D knowledge distilled from 3D models, effectively improving sceneunderstanding. Extensive experiments across multiple benchmarks and MLLMs --including visual grounding, captioning, and question answering -- demonstrateconsistent performance gains. Project page: https://visual-ai.github.io/3drs</description>
      <author>example@mail.com (Xiaohu Huang, Jingjing Wu, Qunyi Xie, Kai Han)</author>
      <guid isPermaLink="false">2506.01946v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Sight Guide: A Wearable Assistive Perception and Navigation System for the Vision Assistance Race in the Cybathlon 2024</title>
      <link>http://arxiv.org/abs/2506.02676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了为视障人士设计的可穿戴辅助系统Sight Guide，该系统在Cybathlon 2024比赛的Vision Assistance Race中取得成功，并详细阐述了系统设计、评估结果和经验教训。&lt;h4&gt;背景&lt;/h4&gt;视障人士在需要空间意识和语义场景理解的任务中面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;加速发展和评估使视障人士能够完成这些任务的技术。&lt;h4&gt;方法&lt;/h4&gt;Sight Guide系统通过集成经典机器人算法和基于学习的方案，使用振动信号和音频指令引导用户完成复杂任务。&lt;h4&gt;主要发现&lt;/h4&gt;在测试环境中，Sight Guide实现了95.7%的任务成功率，并在Cybathlon比赛中证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;本工作为系统设计、评估结果和经验教训提供了深入见解，并指出了更广泛应用于现实世界的方向。&lt;h4&gt;翻译&lt;/h4&gt;Visually impaired individuals face significant challenges navigating and interacting with unknown situations, particularly in tasks requiring spatial awareness and semantic scene understanding. To accelerate the development and evaluate the state of technologies that enable visually impaired people to solve these tasks, the Vision Assistance Race (VIS) at the Cybathlon 2024 competition was organized. In this work, we present Sight Guide, a wearable assistive system designed for the VIS. The system processes data from multiple RGB and depth cameras on an embedded computer that guides the user through complex, real-world-inspired tasks using vibration signals and audio commands. Our software architecture integrates classical robotics algorithms with learning-based approaches to enable capabilities such as obstacle avoidance, object detection, optical character recognition, and touchscreen interaction. In a testing environment, Sight Guide achieved a 95.7% task success rate, and further demonstrated its effectiveness during the Cybathlon competition. This work provides detailed insights into the system design, evaluation results, and lessons learned, and outlines directions towards a broader real-world applicability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visually impaired individuals face significant challenges navigating andinteracting with unknown situations, particularly in tasks requiring spatialawareness and semantic scene understanding. To accelerate the development andevaluate the state of technologies that enable visually impaired people tosolve these tasks, the Vision Assistance Race (VIS) at the Cybathlon 2024competition was organized. In this work, we present Sight Guide, a wearableassistive system designed for the VIS. The system processes data from multipleRGB and depth cameras on an embedded computer that guides the user throughcomplex, real-world-inspired tasks using vibration signals and audio commands.Our software architecture integrates classical robotics algorithms withlearning-based approaches to enable capabilities such as obstacle avoidance,object detection, optical character recognition, and touchscreen interaction.In a testing environment, Sight Guide achieved a 95.7% task success rate, andfurther demonstrated its effectiveness during the Cybathlon competition. Thiswork provides detailed insights into the system design, evaluation results, andlessons learned, and outlines directions towards a broader real-worldapplicability.</description>
      <author>example@mail.com (Patrick Pfreundschuh, Giovanni Cioffi, Cornelius von Einem, Alexander Wyss, Hans Wernher van de Venn, Cesar Cadena, Davide Scaramuzza, Roland Siegwart, Alireza Darvishy)</author>
      <guid isPermaLink="false">2506.02676v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>On the Robustness of Tabular Foundation Models: Test-Time Attacks and In-Context Defenses</title>
      <link>http://arxiv.org/abs/2506.02978v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对表格基础模型（如TabPFN和TabICL）的对抗性脆弱性进行了全面研究，重点关注其易受攻击性和作为对抗工具的潜在风险。&lt;h4&gt;背景&lt;/h4&gt;现有的表格基础模型利用上下文学习实现强性能，但对其对抗性鲁棒性研究不足。&lt;h4&gt;目的&lt;/h4&gt;探究表格基础模型的对抗性脆弱性，包括其易受攻击性和作为对抗工具的潜在风险。&lt;h4&gt;方法&lt;/h4&gt;在金融、网络安全和医疗保健三个领域的三个基准测试中，研究通过小规模结构化扰动测试输入对预测准确性的影响，并提出一种基于上下文的对抗性训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;发现小规模结构化扰动可以显著降低预测准确性，并证明了表格基础模型可以被重新用于生成对随机森林和XGBoost等传统模型的逃避策略。&lt;h4&gt;结论&lt;/h4&gt;表格基础模型既是攻击目标也是对抗威胁的来源，强调了在新兴范式中对鲁棒训练和评估实践的紧迫需求。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we conduct a comprehensive study on the adversarial vulnerabilities of tabular foundational models (such as TabPFN and TabICL), focusing on both their susceptibility to targeted test-time attacks and their potential misuse as adversarial tools. In three benchmarks in finance, cybersecurity, and healthcare, we show that small, structured perturbations to test inputs can significantly degrade prediction accuracy, even when the training context remains fixed. Additionally, we demonstrate that tabular FM can be repurposed to generate transferable evasion against conventional models such as random forests and XGBoost, and to a lesser extent against deep tabular models. To improve tabular FM, we formulate the robustification problem as an optimization of the weights (adversarial fine-tuning) or the context (adversarial in-context learning). We introduce an in-context adversarial training strategy that incrementally replaces the context with adversarial perturbed instances without updating model weights. Our approach improves robustness across multiple tabular benchmarks. Together, these findings position tabular FM as both a target and a source of adversarial threats, highlighting the urgent need for robust training and evaluation practices in this emerging paradigm.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent tabular Foundational Models (FM) such as TabPFN and TabICL, leveragein-context learning to achieve strong performance without gradient updates orfine-tuning. However, their robustness to adversarial manipulation remainslargely unexplored. In this work, we present a comprehensive study of theadversarial vulnerabilities of tabular FM, focusing on both their fragility totargeted test-time attacks and their potential misuse as adversarial tools. Weshow on three benchmarks in finance, cybersecurity and healthcare, that small,structured perturbations to test inputs can significantly degrade predictionaccuracy, even when training context remain fixed. Additionally, we demonstratethat tabular FM can be repurposed to generate transferable evasion toconventional models such as random forests and XGBoost, and on a lesser extentto deep tabular models. To improve tabular FM, we formulate the robustificationproblem as an optimization of the weights (adversarial fine-tuning), or thecontext (adversarial in-context learning). We introduce an in-contextadversarial training strategy that incrementally replaces the context withadversarial perturbed instances, without updating model weights. Our approachimproves robustness across multiple tabular benchmarks. Together, thesefindings position tabular FM as both a target and a source of adversarialthreats, highlighting the urgent need for robust training and evaluationpractices in this emerging paradigm.</description>
      <author>example@mail.com (Mohamed Djilani, Thibault Simonetto, Karim Tit, Florian Tambon, Paul Récamier, Salah Ghamizi, Maxime Cordy, Mike Papadakis)</author>
      <guid isPermaLink="false">2506.02978v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Multilingual Information Retrieval with a Monolingual Knowledge Base</title>
      <link>http://arxiv.org/abs/2506.02527v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, accepted at GENNEXT@SIGIR25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的策略，通过加权采样和对比学习微调多语言嵌入模型，以实现使用单语种知识库的多语言信息检索，并证明了这种方法在MRR和Recall@3上的性能提升。&lt;h4&gt;背景&lt;/h4&gt;多语言信息检索成为扩展跨语言知识共享的有力工具，但高质量知识库资源稀缺且语言有限，因此需要有效的嵌入模型将不同语言的句子转换为与知识库语言相同的特征向量空间，这对于跨语言知识共享至关重要，特别是将高资源语言中的知识转移到低资源语言中。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的策略来微调多语言嵌入模型，以实现使用单语种知识库的多语言信息检索。&lt;h4&gt;方法&lt;/h4&gt;采用加权采样和对比学习的方法来微调多语言嵌入模型。&lt;h4&gt;主要发现&lt;/h4&gt;加权采样策略在MRR上提高了31.03%，在Recall@3上提高了33.98%。该方法对语言无偏见，适用于多语言和代码转换用例。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法可以有效地提升多语言信息检索的性能，并且对语言无偏见，适用于多种用例。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multilingual information retrieval has emerged as powerful tools forexpanding knowledge sharing across languages. On the other hand, resources onhigh quality knowledge base are often scarce and in limited languages,therefore an effective embedding model to transform sentences from differentlanguages into a feature vector space same as the knowledge base languagebecomes the key ingredient for cross language knowledge sharing, especially totransfer knowledge available in high-resource languages to low-resource ones.In this paper we propose a novel strategy to fine-tune multilingual embeddingmodels with weighted sampling for contrastive learning, enabling multilingualinformation retrieval with a monolingual knowledge base. We demonstrate thatthe weighted sampling strategy produces performance gains compared to standardones by up to 31.03\% in MRR and up to 33.98\% in Recall@3. Additionally, ourproposed methodology is language agnostic and applicable for both multilingualand code switching use cases.</description>
      <author>example@mail.com (Yingying Zhuang, Aman Gupta, Anurag Beniwal)</author>
      <guid isPermaLink="false">2506.02527v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Question-Answering for Driving Scene Understanding Using Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.02615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于自动驾驶场景理解的分层问答方法，在成本效益和详细视觉解释之间取得平衡。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶车辆需要有效理解和解释周围环境，以做出安全驾驶决策。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效且能够准确解释场景的方法，用于自动驾驶车辆。&lt;h4&gt;方法&lt;/h4&gt;该方法在特定地理区域的定制数据集上微调紧凑型视觉语言模型（VLM），并在推理阶段采用分层问答策略。VLM在结构化问题树中导航，根据高级问题和详细子问题生成答案。为了优化推理时间，动态跳过基于先前答案的问题，并使用手工制作的模板合成提取的答案。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在捕获关键场景细节方面与GPT-4o等最先进方法具有竞争力，同时实现了显著更低的推理时间。&lt;h4&gt;结论&lt;/h4&gt;该分层问答方法能够以最小的延迟捕获关键驾驶元素，适用于自动驾驶场景理解。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种用于自动驾驶场景理解的分层问答方法，在成本效益和详细视觉解释之间取得平衡。该方法在特定地理区域的定制数据集上微调紧凑型视觉语言模型（VLM），并在推理阶段采用分层问答策略。VLM在结构化问题树中导航，根据高级问题和详细子问题生成答案。为了优化推理时间，动态跳过基于先前答案的问题，并使用手工制作的模板合成提取的答案。该方法在捕获关键场景细节方面与GPT-4o等最先进方法具有竞争力，同时实现了显著更低的推理时间。该分层问答方法能够以最小的延迟捕获关键驾驶元素，适用于自动驾驶场景理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present a hierarchical question-answering (QA) approach forscene understanding in autonomous vehicles, balancing cost-efficiency withdetailed visual interpretation. The method fine-tunes a compact vision-languagemodel (VLM) on a custom dataset specific to the geographical area in which thevehicle operates to capture key driving-related visual elements. At theinference stage, the hierarchical QA strategy decomposes the sceneunderstanding task into high-level and detailed sub-questions. Instead ofgenerating lengthy descriptions, the VLM navigates a structured question tree,where answering high-level questions (e.g., "Is it possible for the ego vehicleto turn left at the intersection?") triggers more detailed sub-questions (e.g.,"Is there a vehicle approaching the intersection from the oppositedirection?"). To optimize inference time, questions are dynamically skippedbased on previous answers, minimizing computational overhead. The extractedanswers are then synthesized using handcrafted templates to ensure coherent,contextually accurate scene descriptions. We evaluate the proposed approach onthe custom dataset using GPT reference-free scoring, demonstrating itscompetitiveness with state-of-the-art methods like GPT-4o in capturing keyscene details while achieving significantly lower inference time. Moreover,qualitative results from real-time deployment highlight the proposed approach'scapacity to capture key driving elements with minimal latency.</description>
      <author>example@mail.com (Safaa Abdullahi Moallim Mohamud, Minjin Baek, Dong Seog Han)</author>
      <guid isPermaLink="false">2506.02615v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Sign Language: Towards Sign Understanding for Robot Autonomy</title>
      <link>http://arxiv.org/abs/2506.02556v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为导航标志理解的任务，旨在从传达场景空间信息的标志中提取导航线索。&lt;h4&gt;背景&lt;/h4&gt;标志是人类环境中的普遍元素，对场景理解和导航至关重要。对于自主系统来说，有效地解析和理解标志是必要的。&lt;h4&gt;目的&lt;/h4&gt;目标是建立导航标志理解的基准，包括创建测试集、提出评价标准和建立基线方法。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含160多张图像的测试集，这些图像展示了医院、商场和交通枢纽等公共场所中不同复杂度和设计的标志。使用视觉-语言模型（VLMs）来解析导航标志。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，VLMs在导航标志理解任务上表现出良好的性能，这可能激励机器人领域下游应用的发展。&lt;h4&gt;结论&lt;/h4&gt;VLMs在导航标志理解任务上具有潜力，代码和数据集可在GitHub上获取。&lt;h4&gt;翻译&lt;/h4&gt;Signage is an ubiquitous element of human environments, playing a critical role in both scene understanding and navigation. For autonomous systems to fully interpret human environments, effectively parsing and understanding signs is essential. We introduce the task of navigational sign understanding, aimed at extracting navigational cues from signs that convey symbolic spatial information about the scene. Specifically, we focus on signs capturing directional cues that point toward distant locations and locational cues that identify specific places. To benchmark performance on this task, we curate a comprehensive test set, propose appropriate evaluation metrics, and establish a baseline approach. Our test set consists of over 160 images, capturing signs with varying complexity and design across a wide range of public spaces, such as hospitals, shopping malls, and transportation hubs. Our baseline approach harnesses Vision-Language Models (VLMs) to parse navigational signs under these high degrees of variability. Experiments show that VLMs offer promising performance on this task, potentially motivating downstream applications in robotics. The code and dataset are available on Github.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Signage is an ubiquitous element of human environments, playing a criticalrole in both scene understanding and navigation. For autonomous systems tofully interpret human environments, effectively parsing and understanding signsis essential. We introduce the task of navigational sign understanding, aimedat extracting navigational cues from signs that convey symbolic spatialinformation about the scene. Specifically, we focus on signs capturingdirectional cues that point toward distant locations and locational cues thatidentify specific places. To benchmark performance on this task, we curate acomprehensive test set, propose appropriate evaluation metrics, and establish abaseline approach. Our test set consists of over 160 images, capturing signswith varying complexity and design across a wide range of public spaces, suchas hospitals, shopping malls, and transportation hubs. Our baseline approachharnesses Vision-Language Models (VLMs) to parse navigational signs under thesehigh degrees of variability. Experiments show that VLMs offer promisingperformance on this task, potentially motivating downstream applications inrobotics. The code and dataset are available on Github.</description>
      <author>example@mail.com (Ayush Agrawal, Joel Loo, Nicky Zimmerman, David Hsu)</author>
      <guid isPermaLink="false">2506.02556v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>From Features to Structure: Task-Aware Graph Construction for Relational and Tabular Learning with GNNs</title>
      <link>http://arxiv.org/abs/2506.02243v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为auGraph的统一框架，用于针对表格和关系数据执行任务感知的图增强，以解决深度学习在处理结构化数据时遇到的挑战。&lt;h4&gt;背景&lt;/h4&gt;表格和关系数据在机器学习应用中非常普遍，但它们对深度学习方法提出了独特的挑战，因为深度学习方法通常假设输入是平坦且特征对齐的。&lt;h4&gt;目的&lt;/h4&gt;提出auGraph框架的目的是为了利用表格和关系数据中的结构依赖性，同时避免现有基于GNN方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;auGraph通过将属性选择性提升为节点，并使用评分函数来量化它们对下游预测任务的相关性，从而增强基础图结构。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，auGraph生成的图在支持关系和表格预测任务的学习方面优于基于模式和启发式图构建方法。&lt;h4&gt;结论&lt;/h4&gt;auGraph通过保持原始数据模式并注入与任务相关的结构信号，为表格和关系数据提供了有效的图增强解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a unified framework called auGraph for task-aware graph augmentation, which applies to both tabular and relational data to address the challenges faced by deep learning methods in processing structured data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tabular and relational data remain the most ubiquitous formats in real-worldmachine learning applications, spanning domains from finance to healthcare.Although both formats offer structured representations, they pose distinctchallenges for modern deep learning methods, which typically assume flat,feature-aligned inputs. Graph Neural Networks (GNNs) have emerged as apromising solution by capturing structural dependencies within and betweentables. However, existing GNN-based approaches often rely on rigid,schema-derived graphs -- such as those based on primary-foreign key links --thereby underutilizing rich, predictive signals in non key attributes. In thiswork, we introduce auGraph, a unified framework for task-aware graphaugmentation that applies to both tabular and relational data. auGraph enhancesbase graph structures by selectively promoting attributes into nodes, guided byscoring functions that quantify their relevance to the downstream predictiontask. This augmentation preserves the original data schema while injectingtask-relevant structural signal. Empirically, auGraph outperforms schema-basedand heuristic graph construction methods by producing graphs that bettersupport learning for relational and tabular prediction tasks.</description>
      <author>example@mail.com (Tamara Cucumides, Floris Geerts)</author>
      <guid isPermaLink="false">2506.02243v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>VLCD: Vision-Language Contrastive Distillation for Accurate and Efficient Automatic Placenta Analysis</title>
      <link>http://arxiv.org/abs/2506.02229v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of the 9th International Workshop on Health Intelligence,  in conjunction with the Annual AAAI Conference on Artificial Intelligence,  Philadelphia, Pennsylvania, March 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的视觉-语言对比学习（VLC）框架，以提高产前病理检测的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;胎盘病理检查是检测和减轻与分娩相关的健康风险的有效方法。人工智能的发展使得利用胎盘照片和病理报告进行产前病理征象的检测和分类成为可能。&lt;h4&gt;目的&lt;/h4&gt;针对现有自动化方法计算量大的问题，提出两种改进措施，以提高VLC框架的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;提出两种改进措施：(1) 文本锚定的视觉-语言对比知识蒸馏（VLCD），一种新的医学VLC预训练知识蒸馏策略；(2) 使用大型自然图像数据集进行无监督预蒸馏，以改善初始化。&lt;h4&gt;主要发现&lt;/h4&gt;改进后的方法能够蒸馏出性能匹配或超越教师模型的神经网络，同时实现模型压缩和加速。结果表明，无监督预蒸馏在提高方法性能和鲁棒性方面具有价值，尤其是在处理低质量图像时。VLCD是提高医疗VLC方法效率和可部署性的有效方式，使基于AI的健康保健解决方案在资源受限的环境中更加可及。&lt;h4&gt;结论&lt;/h4&gt;本文提出的改进方法有效地提高了产前病理检测的准确性和效率，使得AI在医疗保健领域的应用更加广泛和可及。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pathological examination of the placenta is an effective method for detectingand mitigating health risks associated with childbirth. Recent advancements inAI have enabled the use of photographs of the placenta and pathology reportsfor detecting and classifying signs of childbirth-related pathologies. However,existing automated methods are computationally extensive, which limits theirdeployability. We propose two modifications to vision-language contrastivelearning (VLC) frameworks to enhance their accuracy and efficiency: (1)text-anchored vision-language contrastive knowledge distillation (VLCD)-a newknowledge distillation strategy for medical VLC pretraining, and (2)unsupervised predistillation using a large natural images dataset for improvedinitialization. Our approach distills efficient neural networks that match orsurpass the teacher model in performance while achieving model compression andacceleration. Our results showcase the value of unsupervised predistillation inimproving the performance and robustness of our approach, specifically forlower-quality images. VLCD serves as an effective way to improve the efficiencyand deployability of medical VLC approaches, making AI-based healthcaresolutions more accessible, especially in resource-constrained environments.</description>
      <author>example@mail.com (Manas Mehta, Yimu Pan, Kelly Gallagher, Alison D. Gernand, Jeffery A. Goldstein, Delia Mwinyelle, Leena Mithal, James Z. Wang)</author>
      <guid isPermaLink="false">2506.02229v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Federated Gaussian Mixture Models</title>
      <link>http://arxiv.org/abs/2506.01780v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 6 figures. Submitted to ACM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了FedGenGMM，这是一种针对无监督学习场景的Gaussian Mixture Models (GMM)的新型单次联邦学习方法。&lt;h4&gt;背景&lt;/h4&gt;在联邦学习（FL）中，多个去中心化客户端在不共享原始数据的情况下协同训练模型，面临着统计异质性、高通信成本和隐私问题。&lt;h4&gt;目的&lt;/h4&gt;FedGenGMM旨在解决这些问题，通过允许在客户端设备上独立训练的本地GMM模型通过单次通信轮次进行聚合。&lt;h4&gt;方法&lt;/h4&gt;该方法利用GMM的生成特性，在服务器端创建一个合成数据集来高效训练全局模型。&lt;h4&gt;主要发现&lt;/h4&gt;在涵盖图像、表格和时间序列数据的多个数据集上的评估表明，FedGenGMM在数据异质性显著的情况下，仍然能够持续实现与非联邦学习和迭代联邦学习方法相当的性能。&lt;h4&gt;结论&lt;/h4&gt;FedGenGMM显著降低了通信开销，在异常检测任务中保持了稳健的性能，并在本地模型复杂度方面提供了灵活性，使其特别适合边缘计算环境。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为FedGenGMM的新颖的单次联邦学习方法，用于高斯混合模型（GMM）的无监督学习场景。在联邦学习中，多个去中心化客户端在不共享原始数据的情况下协同训练模型，面临着统计异质性、高通信成本和隐私问题。FedGenGMM通过允许在客户端设备上独立训练的本地GMM模型通过单次通信轮次进行聚合来解决这些问题。该方法利用GMM的生成特性，在服务器端创建一个合成数据集来高效训练全局模型。在涵盖图像、表格和时间序列数据的多个数据集上的评估表明，FedGenGMM在数据异质性显著的情况下，仍然能够持续实现与非联邦学习和迭代联邦学习方法相当的性能。FedGenGMM显著降低了通信开销，在异常检测任务中保持了稳健的性能，并在本地模型复杂度方面提供了灵活性，使其特别适合边缘计算环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces FedGenGMM, a novel one-shot federated learning approachfor Gaussian Mixture Models (GMM) tailored for unsupervised learning scenarios.In federated learning (FL), where multiple decentralized clientscollaboratively train models without sharing raw data, significant challengesinclude statistical heterogeneity, high communication costs, and privacyconcerns. FedGenGMM addresses these issues by allowing local GMM models,trained independently on client devices, to be aggregated through a singlecommunication round. This approach leverages the generative property of GMMs,enabling the creation of a synthetic dataset on the server side to train aglobal model efficiently. Evaluation across diverse datasets covering image,tabular, and time series data demonstrates that FedGenGMM consistently achievesperformance comparable to non-federated and iterative federated methods, evenunder significant data heterogeneity. Additionally, FedGenGMM significantlyreduces communication overhead, maintains robust performance in anomalydetection tasks, and offers flexibility in local model complexities, making itparticularly suitable for edge computing environments.</description>
      <author>example@mail.com (Sophia Zhang Pettersson, Kuo-Yun Liang, Juan Carlos Andresen)</author>
      <guid isPermaLink="false">2506.01780v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>ReconXF: Graph Reconstruction Attack via Public Feature Explanations on Privatized Node Features and Labels</title>
      <link>http://arxiv.org/abs/2506.02134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在隐私保护下，如何通过解释性方法在图神经网络中识别重要节点属性，并提出了ReconXF攻击方法来对抗这种隐私风险。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在多个应用中表现出色，但作为黑盒模型，限制了其在关键领域如医疗保健和刑事司法中的使用。解释性方法虽然提供了特征级别的解释，但同时也带来了隐私风险。&lt;h4&gt;目的&lt;/h4&gt;为了在保护节点特征和标签的同时提供解释性信息，研究如何在隐私保护的环境下进行图结构恢复。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的图重构攻击方法ReconXF，该方法通过结合去噪机制和利用解释中的结构信号，在具有公共解释和私有辅助数据的场景下进行攻击。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，ReconXF在私有设置中优于现有方法，提高了AUC和平均精度。结果表明，即使在辅助数据的隐私保护下，公共解释与去噪相结合也能实现图结构的恢复。&lt;h4&gt;结论&lt;/h4&gt;ReconXF方法有效地对抗了基于解释的攻击，并在隐私保护的环境下实现了图结构的恢复。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies how to identify important node attributes in graph neural networks using explainable methods under privacy protection, and proposes a new graph reconstruction attack method called ReconXF to counter this privacy risk.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) achieve high performance across manyapplications but function as black-box models, limiting their use in criticaldomains like healthcare and criminal justice. Explainability methods addressthis by providing feature-level explanations that identify important nodeattributes for predictions. These explanations create privacy risks. Combinedwith auxiliary information, feature explanations can enable adversaries toreconstruct graph structure, exposing sensitive relationships. Existing graphreconstruction attacks assume access to original auxiliary data, but practicalsystems use differential privacy to protect node features and labels whileproviding explanations for transparency. We study a threat model whereadversaries access public feature explanations along with privatized nodefeatures and labels. We show that existing explanation-based attacks like GSEFperform poorly with privatized data due to noise from differential privacymechanisms. We propose ReconXF, a graph reconstruction attack for scenarioswith public explanations and privatized auxiliary data. Our method adaptsexplanation-based frameworks by incorporating denoising mechanisms that handledifferential privacy noise while exploiting structural signals in explanations.Experiments across multiple datasets show ReconXF outperforms SoTA methods inprivatized settings, with improvements in AUC and average precision. Resultsindicate that public explanations combined with denoising enable graphstructure recovery even under the privacy protection of auxiliary data. Code isavailable at (link to be made public after acceptance).</description>
      <author>example@mail.com (Rishi Raj Sahoo, Rucha Bhalchandra Joshi, Subhankar Mishra)</author>
      <guid isPermaLink="false">2506.02134v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Biomedical Multi-modal Representation Learning with Multi-scale Pre-training and Perturbed Report Discrimination</title>
      <link>http://arxiv.org/abs/2506.01902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 1 figure, accepted by 2024 IEEE Conference on Artificial  Intelligence (CAI)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的方法，用于预训练生物医学视觉语言模型，以解决生物医学文本的复杂性和领域特定语义在常见对比学习方法中被忽视的问题。&lt;h4&gt;背景&lt;/h4&gt;视觉语言模型在大量未标记的生物医学图像及其相关报告中学习到通用的语义表示，这些多模态表示可以促进生物医学领域的各种下游任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，即扰动报告判别，用于预训练生物医学视觉语言模型，以解决生物医学文本复杂性和领域特定语义的问题。&lt;h4&gt;方法&lt;/h4&gt;首先，创建一组文本扰动方法，保持相同单词的同时破坏句子的语义结构。然后，对报告应用不同类型的扰动，并使用模型区分原始报告和扰动报告，前提是给定相关图像。同时，通过对比注意力加权的图像子区域和图像-文本对中的子词，增强方法对两种模态的更高粒度敏感度。&lt;h4&gt;主要发现&lt;/h4&gt;在多个下游任务上进行了广泛的实验，该方法优于强基线方法，结果表明该方法学习到更具语义意义和鲁棒性的多模态表示。&lt;h4&gt;结论&lt;/h4&gt;该方法在生物医学视觉语言模型的预训练中表现出色，能够学习到更具语义意义和鲁棒性的多模态表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/CAI59869.2024.00097&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models pre-trained on large scale of unlabeled biomedicalimages and associated reports learn generalizable semantic representations.These multi-modal representations can benefit various downstream tasks in thebiomedical domain. Contrastive learning is widely used to pre-trainvision-language models for general natural images and associated captions.Despite its popularity, we found biomedical texts have complex anddomain-specific semantics that are often neglected by common contrastivemethods. To address this issue, we propose a novel method, perturbed reportdiscrimination, for pre-train biomedical vision-language models. First, wecurate a set of text perturbation methods that keep the same words, but disruptthe semantic structure of the sentence. Next, we apply different types ofperturbation to reports, and use the model to distinguish the original reportfrom the perturbed ones given the associated image. Parallel to this, weenhance the sensitivity of our method to higher level of granularity for bothmodalities by contrasting attention-weighted image sub-regions and sub-words inthe image-text pairs. We conduct extensive experiments on multiple downstreamtasks, and our method outperforms strong baseline methods. The resultsdemonstrate that our approach learns more semantic meaningful and robustmulti-modal representations.</description>
      <author>example@mail.com (Xinliu Zhong, Kayhan Batmanghelich, Li Sun)</author>
      <guid isPermaLink="false">2506.01902v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Automated Manifold Learning for Reduced Order Modeling</title>
      <link>http://arxiv.org/abs/2506.01741v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用几何表示学习从时空数据中驱动发现系统动态的方法。&lt;h4&gt;背景&lt;/h4&gt;识别数据中的几何结构是（无监督）学习的基础，几何表示学习在科学和工程领域得到了广泛应用。&lt;h4&gt;目的&lt;/h4&gt;探索几何表示学习在时空数据中驱动发现系统动态的应用。&lt;h4&gt;方法&lt;/h4&gt;提出在时空邻近图中编码相似结构，并应用多种经典和基于深度学习的流形学习方法来学习降阶动态。&lt;h4&gt;主要发现&lt;/h4&gt;流形学习方法通常能够恢复降阶动态，但不同算法和超参数选择下学习到的表示质量差异很大，表明对各自方法内在几何假设的高度敏感性，并暗示需要仔细的超参数调整，这在实践中可能很昂贵。&lt;h4&gt;结论&lt;/h4&gt;提出了一种自动流形学习框架，该框架根据输入图的代表性子样本选择流形学习方法及其相应的超参数选择，证明了该框架在可扩展性和学习到的表示在捕捉底层系统动态的局部和全局几何特征方面的准确性方面均有性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：识别数据中的几何结构是（无监督）学习的基础。因此，几何表示学习在科学和工程领域得到了广泛应用。在这项工作中，我们研究了利用几何表示学习从时空数据中驱动发现系统动态的方法。我们提出在时空邻近图中编码相似结构，然后应用一系列经典和基于深度学习的流形学习方法来学习降阶动态。我们观察到，虽然流形学习方法通常能够恢复降阶动态，但不同算法和超参数选择下学习到的表示质量差异很大，这表明对各自方法内在几何假设的高度敏感性，并暗示需要仔细的超参数调整，这在实践中可能很昂贵。为了克服这些挑战，我们提出了一种自动流形学习框架，该框架根据输入图的代表性子样本选择流形学习方法及其相应的超参数选择。我们证明了所提出的框架在可扩展性和学习到的表示在捕捉底层系统动态的局部和全局几何特征方面的准确性方面均有性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The problem of identifying geometric structure in data is a cornerstone of(unsupervised) learning. As a result, Geometric Representation Learning hasbeen widely applied across scientific and engineering domains. In this work, weinvestigate the use of Geometric Representation Learning for the data-drivendiscovery of system dynamics from spatial-temporal data. We propose to encodesimilarity structure in such data in a spatial-temporal proximity graph, towhich we apply a range of classical and deep learning-based manifold learningapproaches to learn reduced order dynamics. We observe that while manifoldlearning is generally capable of recovering reduced order dynamics, the qualityof the learned representations varies substantially across different algorithmsand hyperparameter choices. This is indicative of high sensitivity to theinherent geometric assumptions of the respective approaches and suggests a needfor careful hyperparameter tuning, which can be expensive in practise. Toovercome these challenges, we propose a framework for Automated ManifoldLearning, which selects a manifold learning approach and correspondinghyperparameter choices based on representative subsamples of the input graph.We demonstrate that the proposed framework leads to performance gains both inscalability and in the learned representations' accuracy in capturing local andglobal geometric features of the underlying system dynamics.</description>
      <author>example@mail.com (Imran Nasim, Melanie Weber)</author>
      <guid isPermaLink="false">2506.01741v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Stock Market Telepathy: Graph Neural Networks Predicting the Secret Conversations between MINT and G7 Countries</title>
      <link>http://arxiv.org/abs/2506.01945v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了新兴经济体，特别是MINT国家在全球股市中的影响力，并探讨了这些市场与发达国家的经济条件之间的关系。&lt;h4&gt;背景&lt;/h4&gt;MINT国家在全球股市中的影响力逐渐增强，但同时也受到G7国家经济条件的影响。&lt;h4&gt;目的&lt;/h4&gt;为了准确预测股票价格走势，本文使用MTGNN算法对G7和MINT国家的股票市场指数进行了分析。&lt;h4&gt;方法&lt;/h4&gt;采用MTGNN算法对2012年至2024年的G7和MINT国家的主要股票市场指数进行了研究，该方法能够考虑多变量时间序列中的复杂时空联系。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，美国和加拿大在G7国家中对于股票指数预测最具影响力，而印度尼西亚和土耳其在MINT国家中影响最大。此外，MTGNN在预测MINT和G7国家的股票市场指数价格方面优于传统方法。&lt;h4&gt;结论&lt;/h4&gt;本研究为分析经济板块市场和全球股市动态提供了有价值的见解，并展示了使用MTGNN进行实证分析的强大方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emerging economies, particularly the MINT countries (Mexico, Indonesia,Nigeria, and T\"urkiye), are gaining influence in global stock markets,although they remain susceptible to the economic conditions of developedcountries like the G7 (Canada, France, Germany, Italy, Japan, the UnitedKingdom, and the United States). This interconnectedness and sensitivity offinancial markets make understanding these relationships crucial for investorsand policymakers to predict stock price movements accurately. To this end, weexamined the main stock market indices of G7 and MINT countries from 2012 to2024, using a recent graph neural network (GNN) algorithm called multivariatetime series forecasting with graph neural network (MTGNN). This method allowsfor considering complex spatio-temporal connections in multivariate timeseries. In the implementations, MTGNN revealed that the US and Canada are themost influential G7 countries regarding stock indices in the forecastingprocess, and Indonesia and T\"urkiye are the most influential MINT countries.Additionally, our results showed that MTGNN outperformed traditional methods inforecasting the prices of stock market indices for MINT and G7 countries.Consequently, the study offers valuable insights into economic blocks' marketsand presents a compelling empirical approach to analyzing global stock marketdynamics using MTGNN.</description>
      <author>example@mail.com (Nurbanu Bursa)</author>
      <guid isPermaLink="false">2506.01945v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>INESC-ID @ eRisk 2025: Exploring Fine-Tuned, Similarity-Based, and Prompt-Based Approaches to Depression Symptom Identification</title>
      <link>http://arxiv.org/abs/2506.02924v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 1 figure, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文描述了团队针对eRisk 2025任务1：搜索抑郁症症状的方法。通过句子集合和Beck抑郁量表-II（BDI）问卷，参与者提交与BDI中每种抑郁症状相关的最多1000个句子，并按相关性排序。参与者的提交根据标准信息检索（IR）指标进行评估，包括平均精度（AP）和R-精度（R-PREC）。由于训练数据的标签限制，我们将开发过程定位为针对每个BDI症状的二分类任务，并据此进行评估。&lt;h4&gt;背景&lt;/h4&gt;该研究针对抑郁症症状的搜索任务，旨在通过信息检索技术识别与抑郁症相关的症状。&lt;h4&gt;目的&lt;/h4&gt;开发一个有效的系统来识别与BDI问卷中每种抑郁症状相关的句子。&lt;h4&gt;方法&lt;/h4&gt;使用标准信息检索（IR）指标进行评估，将开发过程定位为针对每个BDI症状的二分类任务，并探索了基础模型微调、句子相似性、大型语言模型（LLM）提示和集成技术。将可用标记数据分为训练和验证集。&lt;h4&gt;主要发现&lt;/h4&gt;微调基础模型结合合成数据可以缓解类别不平衡问题，并取得了最佳性能。最优方法因症状而异。&lt;h4&gt;结论&lt;/h4&gt;通过微调基础模型和使用集成方法，实现了最高的信息检索评估分数，超越了16个其他团队的提交。&lt;h4&gt;翻译&lt;/h4&gt;在本文中，我们描述了我们团队针对eRisk 2025任务1：搜索抑郁症症状的方法。给定一组句子和Beck的抑郁量表-II（BDI）问卷，参与者被要求提交最多1000个与BDI中每种抑郁症状相关的句子，并按相关性排序。参与者的提交根据标准信息检索（IR）指标进行评估，包括平均精度（AP）和R-精度（R-PREC）。然而，由于提供的训练数据是由句子标记为与BDI的某种症状相关或不相关，因此我们将我们的开发定位于针对每个BDI症状的二分类任务，并据此进行评估。为此，我们将可用的标记数据分为训练集和验证集，并探索了基础模型微调、句子相似性、大型语言模型（LLM）提示和集成技术。验证结果表明，微调基础模型产生了最佳性能，特别是在与合成数据结合以减轻类别不平衡的情况下。我们还观察到，最佳方法因症状而异。基于这些见解，我们设计了五个独立的测试运行，其中两个使用了集成方法。这些运行在官方IR评估中取得了最高分数，超过了其他16个团队的提交。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we describe our team's approach to eRisk's 2025 Task 1: Searchfor Symptoms of Depression. Given a set of sentences and the Beck's DepressionInventory - II (BDI) questionnaire, participants were tasked with submitting upto 1,000 sentences per depression symptom in the BDI, sorted by relevance.Participant submissions were evaluated according to standard InformationRetrieval (IR) metrics, including Average Precision (AP) and R-Precision(R-PREC). The provided training data, however, consisted of sentences labeledas to whether a given sentence was relevant or not w.r.t. one of BDI'ssymptoms. Due to this labeling limitation, we framed our development as abinary classification task for each BDI symptom, and evaluated accordingly. Tothat end, we split the available labeled data into training and validationsets, and explored foundation model fine-tuning, sentence similarity, LargeLanguage Model (LLM) prompting, and ensemble techniques. The validation resultsrevealed that fine-tuning foundation models yielded the best performance,particularly when enhanced with synthetic data to mitigate class imbalance. Wealso observed that the optimal approach varied by symptom. Based on theseinsights, we devised five independent test runs, two of which used ensemblemethods. These runs achieved the highest scores in the official IR evaluation,outperforming submissions from 16 other teams.</description>
      <author>example@mail.com (Diogo A. P. Nunes, Eugénio Ribeiro)</author>
      <guid isPermaLink="false">2506.02924v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>iQUEST: An Iterative Question-Guided Framework for Knowledge Base Question Answering</title>
      <link>http://arxiv.org/abs/2506.01784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ACL 2025 (Main)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为iQUEST的KBQA框架，用于解决LLMs在知识密集型场景中的事实不准确问题，通过引入外部知识资源如知识图谱来提高推理的可靠性。&lt;h4&gt;背景&lt;/h4&gt;尽管LLMs在自然语言处理任务中表现出色，但在知识密集型场景中经常出现事实不准确的问题。&lt;h4&gt;目的&lt;/h4&gt;通过整合外部知识资源，特别是知识图谱，为更可靠的推理提供一个透明且可更新的基础。&lt;h4&gt;方法&lt;/h4&gt;iQUEST通过迭代地将复杂查询分解为更简单的子查询，确保结构化和专注的推理轨迹。此外，它还整合了图神经网络（GNN）来预测并整合每一步推理中的2-hop邻居信息。&lt;h4&gt;主要发现&lt;/h4&gt;iQUEST在四个基准数据集和四个LLMs上展现了持续的改进。&lt;h4&gt;结论&lt;/h4&gt;iQUEST通过双重方法加强了推理过程，使模型能够更有效地探索可行路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While Large Language Models (LLMs) excel at many natural language processingtasks, they often suffer from factual inaccuracies in knowledge-intensivescenarios. Integrating external knowledge resources, particularly knowledgegraphs (KGs), provides a transparent and updatable foundation for more reliablereasoning. Knowledge Base Question Answering (KBQA), which queries and reasonsover KGs, is central to this effort, especially for complex, multi-hop queries.However, multi-hop reasoning poses two key challenges: (1)~maintaining coherentreasoning paths, and (2)~avoiding prematurely discarding critical multi-hopconnections. To address these issues, we introduce iQUEST, a question-guidedKBQA framework that iteratively decomposes complex queries into simplersub-questions, ensuring a structured and focused reasoning trajectory.Additionally, we integrate a Graph Neural Network (GNN) to look ahead andincorporate 2-hop neighbor information at each reasoning step. This dualapproach strengthens the reasoning process, enabling the model to exploreviable paths more effectively. Detailed experiments demonstrate the consistentimprovement delivered by iQUEST across four benchmark datasets and four LLMs.</description>
      <author>example@mail.com (Shuai Wang, Yinan Yu)</author>
      <guid isPermaLink="false">2506.01784v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Principled data augmentation for learning to solve quadratic programming problems</title>
      <link>http://arxiv.org/abs/2506.01728v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了利用消息传递图神经网络（MPNNs）针对二次规划（QPs）进行数据增强的原理性方法，以提高学习到优化（L2O）任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;线性规划和二次规划在许多实际应用中至关重要，而使用MPNNs的L2O方法在解决这类优化问题方面显示出潜力。然而，在数据稀缺的环境下，特别是处理如QPs等复杂优化问题时，稳健的L2O MPNNs仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种专门针对QPs的数据增强方法，以生成多样化且保持最优性的实例，并集成到基于对比学习的自监督学习框架中，以预训练MPNNs，从而在L2O任务上获得更好的性能。&lt;h4&gt;方法&lt;/h4&gt;该方法利用理论上有依据的数据增强技术，并结合自监督学习框架，通过对比学习来预训练MPNNs。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在监督场景中提高了泛化能力，并促进了相关优化问题上的有效迁移学习。&lt;h4&gt;结论&lt;/h4&gt;通过数据增强和自监督学习，L2O MPNNs在解决QPs等复杂优化问题时展现出更好的性能和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Linear and quadratic optimization are crucial in numerous real-world applications, from training machine learning models to integer-linear optimization. Recently, learning-to-optimize methods (L2O) for linear (LPs) or quadratic programs (QPs) using message-passing graph neural networks (MPNNs) have gained traction, promising lightweight, data-driven proxies for solving such optimization problems. However, robust L2O MPNNs remain challenging in data-scarce settings, especially when addressing complex optimization problems such as QPs. This work introduces a principled approach to data augmentation tailored for QPs via MPNNs. Our method leverages theoretically justified data augmentation techniques to generate diverse yet optimality-preserving instances. Furthermore, we integrate these augmentations into a self-supervised learning framework based on contrastive learning, thereby pretraining MPNNs for enhanced performance on L2O tasks. Extensive experiments demonstrate that our approach improves generalization in supervised scenarios and facilitates effective transfer learning to related optimization problems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Linear and quadratic optimization are crucial in numerous real-worldapplications, from training machine learning models to integer-linearoptimization. Recently, learning-to-optimize methods (L2O) for linear (LPs) orquadratic programs (QPs) using message-passing graph neural networks (MPNNs)have gained traction, promising lightweight, data-driven proxies for solvingsuch optimization problems. For example, they replace the costly computation ofstrong branching scores in branch-and-bound solvers, requiring solving manysuch optimization problems. However, robust L2O MPNNs remain challenging indata-scarce settings, especially when addressing complex optimization problemssuch as QPs. This work introduces a principled approach to data augmentationtailored for QPs via MPNNs. Our method leverages theoretically justified dataaugmentation techniques to generate diverse yet optimality-preservinginstances. Furthermore, we integrate these augmentations into a self-supervisedlearning framework based on contrastive learning, thereby pretraining MPNNs forenhanced performance on L2O tasks. Extensive experiments demonstrate that ourapproach improves generalization in supervised scenarios and facilitateseffective transfer learning to related optimization problems.</description>
      <author>example@mail.com (Chendi Qian, Christopher Morris)</author>
      <guid isPermaLink="false">2506.01728v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Towards Auto-Annotation from Annotation Guidelines: A Benchmark through 3D LiDAR Detection</title>
      <link>http://arxiv.org/abs/2506.02914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究从专家定义的标注指南中自动化数据标注的方法，提出新的基准AnnoGuide，并使用nuScenes数据集进行案例研究，旨在减少人工标注的劳动强度和成本。&lt;h4&gt;背景&lt;/h4&gt;数据标注是机器学习解决方案的关键前提，但也是一个劳动密集、耗时且昂贵的流程。&lt;h4&gt;目的&lt;/h4&gt;通过引入AnnoGuide，评估从专家定义的标注指南中自动化数据标注的方法，以消除手动标注的需求。&lt;h4&gt;方法&lt;/h4&gt;采用一个简单的流程，包括：(1) 使用开源基础模型进行RGB图像中的目标检测和分割；(2) 使用已知的相机姿态将2D检测投影到3D；(3) 在每个2D检测的视锥体内聚类LiDAR点以生成3D立方体。&lt;h4&gt;主要发现&lt;/h4&gt;通过逐步优化关键组件，3D检测的平均精度（mAP）从12.1提升到21.9，但结果表明AnnoGuide仍然是一个开放且具有挑战性的问题，强调了开发基于LiDAR的基础模型的紧迫性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的AnnoGuide方法在减少数据标注工作量方面取得了显著进展，但仍需进一步研究以解决挑战并推动基于LiDAR的基础模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A crucial yet under-appreciated prerequisite in machine learning solutionsfor real-applications is data annotation: human annotators are hired tomanually label data according to detailed, expert-crafted guidelines. This isoften a laborious, tedious, and costly process. To study methods forfacilitating data annotation, we introduce a new benchmark AnnoGuide:Auto-Annotation from Annotation Guidelines. It aims to evaluate automatedmethods for data annotation directly from expert-defined annotation guidelines,eliminating the need for manual labeling. As a case study, we repurpose thewell-established nuScenes dataset, commonly used in autonomous drivingresearch, which provides comprehensive annotation guidelines for labeling LiDARpoint clouds with 3D cuboids across 18 object classes. These guidelines includea few visual examples and textual descriptions, but no labeled 3D cuboids inLiDAR data, making this a novel task of multi-modal few-shot 3D detectionwithout 3D annotations. The advances of powerful foundation models (FMs) makeAnnoGuide especially timely, as FMs offer promising tools to tackle itschallenges. We employ a conceptually straightforward pipeline that (1) utilizesopen-source FMs for object detection and segmentation in RGB images, (2)projects 2D detections into 3D using known camera poses, and (3) clusters LiDARpoints within the frustum of each 2D detection to generate a 3D cuboid.Starting with a non-learned solution that leverages off-the-shelf FMs, weprogressively refine key components and achieve significant performanceimprovements, boosting 3D detection mAP from 12.1 to 21.9! Nevertheless, ourresults highlight that AnnoGuide remains an open and challenging problem,underscoring the urgent need for developing LiDAR-based FMs. We release ourcode and models at GitHub: https://annoguide.github.io/annoguide3Dbenchmark</description>
      <author>example@mail.com (Yechi Ma, Wei Hua, Shu Kong)</author>
      <guid isPermaLink="false">2506.02914v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Overcoming Data Scarcity in Scanning Tunnelling Microscopy Image Segmentation</title>
      <link>http://arxiv.org/abs/2506.01678v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于STM图像分析的自动化分割方法，使用少量样本学习和无监督学习，以提高STM图像分割的效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;STM是一种用于原子分辨率表面成像的强大技术，但在分析图像时，手动识别和标记特征是一项劳动密集型任务。&lt;h4&gt;目的&lt;/h4&gt;开发一种自动化方法来减轻STM图像分析中的劳动负担，并提高分割的灵活性和准确性。&lt;h4&gt;方法&lt;/h4&gt;提出的方法结合了少量样本学习和无监督学习，无需大量手动标注数据集，且能够适应未见过的表面。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在识别三种不同表面（Si(001)、Ge(001)和TiO$_2$(110)）上的原子特征方面表现出强泛化能力，能够在训练后仅通过少量额外标注数据点适应未见过的表面。&lt;h4&gt;结论&lt;/h4&gt;该研究是向STM图像的高效和材料无关的自动分割迈出的重要一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scanning tunnelling microscopy (STM) is a powerful technique for imagingsurfaces with atomic resolution, providing insight into physical and chemicalprocesses at the level of single atoms and molecules. A regular task of STMimage analysis is the identification and labelling of features of interestagainst a uniform background. Performing this manually is a labour-intensivetask, requiring significant human effort. To reduce this burden, we propose anautomated approach to the segmentation of STM images that uses both few-shotlearning and unsupervised learning. Our technique offers greater flexibilitycompared to previous supervised methods; it removes the requirement for largemanually annotated datasets and is thus easier to adapt to an unseen surfacewhile still maintaining a high accuracy. We demonstrate the effectiveness ofour approach by using it to recognise atomic features on three distinctsurfaces: Si(001), Ge(001), and TiO$_2$(110), including adsorbed AsH$_3$molecules on the silicon and germanium surfaces. Our model exhibits stronggeneralisation capabilities, and following initial training, can be adapted tounseen surfaces with as few as one additional labelled data point. This work isa significant step towards efficient and material-agnostic, automaticsegmentation of STM images.</description>
      <author>example@mail.com (Nikola L. Kolev, Max Trouton, Filippo Federici Canova, Geoff Thornton, David Z. Gao, Neil J. Curson, Taylor J. Z. Stock)</author>
      <guid isPermaLink="false">2506.01678v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Cell-o1: Training LLMs to Solve Single-Cell Reasoning Puzzles with Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.02911v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages; 16 tables; 7 figures; Code:  https://github.com/ncbi-nlp/cell-o1&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为CellPuzzles的任务，旨在模仿人类专家根据领域知识对细胞进行类型标注的过程，并引入了一种名为Cell-o1的新模型，以提高批量细胞类型标注的准确性。&lt;h4&gt;背景&lt;/h4&gt;细胞类型标注是分析单细胞RNA测序数据异质性的关键任务。尽管最近的基座模型可以自动化这一过程，但它们通常独立标注细胞，不考虑批量级别的细胞背景，也不提供解释性推理。&lt;h4&gt;目的&lt;/h4&gt;目标是开发一种能够考虑批量级别细胞背景并进行解释性推理的细胞类型标注方法。&lt;h4&gt;方法&lt;/h4&gt;提出CellPuzzles任务，该任务跨越多种组织、疾病和捐赠者条件，需要跨批量级别细胞背景进行推理以确保标签的唯一性。同时，提出了一种名为Cell-o1的7B LLM，通过在精炼推理痕迹上进行的监督微调和批量奖励的强化学习进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;现有的大型语言模型在CellPuzzles任务上表现不佳，最佳基线模型（OpenAI的o1）在批量级别上的准确率仅为19.0%。Cell-o1实现了最先进的性能，超过了o1超过73%，并且能够很好地泛化到不同的上下文中。&lt;h4&gt;结论&lt;/h4&gt;Cell-o1在批量细胞类型标注任务中表现出色，提供了对批量级别标注性能和出现专家级推理的见解。&lt;h4&gt;翻译&lt;/h4&gt;Cell type annotation is a key task in analyzing the heterogeneity of single-cell RNA sequencing data. Although recent foundation models automate this process, they typically annotate cells independently, without considering batch-level cellular context or providing explanatory reasoning. In contrast, human experts often annotate distinct cell types for different cell clusters based on their domain knowledge. To mimic this workflow, we introduce the CellPuzzles task, where the objective is to assign unique cell types to a batch of cells. This benchmark spans diverse tissues, diseases, and donor conditions, and requires reasoning across the batch-level cellular context to ensure label uniqueness. We find that off-the-shelf large language models (LLMs) struggle on CellPuzzles, with the best baseline (OpenAI's o1) achieving only 19.0% batch-level accuracy. To fill this gap, we propose Cell-o1, a 7B LLM trained via supervised fine-tuning on distilled reasoning traces, followed by reinforcement learning with batch-level rewards. Cell-o1 achieves state-of-the-art performance, outperforming o1 by over 73% and generalizing well across contexts. Further analysis of training dynamics and reasoning behaviors provides insights into batch-level annotation performance and emergent expert-like reasoning. Code and data are available at https://github.com/ncbi-nlp/cell-o1.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cell type annotation is a key task in analyzing the heterogeneity ofsingle-cell RNA sequencing data. Although recent foundation models automatethis process, they typically annotate cells independently, without consideringbatch-level cellular context or providing explanatory reasoning. In contrast,human experts often annotate distinct cell types for different cell clustersbased on their domain knowledge. To mimic this workflow, we introduce theCellPuzzles task, where the objective is to assign unique cell types to a batchof cells. This benchmark spans diverse tissues, diseases, and donor conditions,and requires reasoning across the batch-level cellular context to ensure labeluniqueness. We find that off-the-shelf large language models (LLMs) struggle onCellPuzzles, with the best baseline (OpenAI's o1) achieving only 19.0%batch-level accuracy. To fill this gap, we propose Cell-o1, a 7B LLM trainedvia supervised fine-tuning on distilled reasoning traces, followed byreinforcement learning with batch-level rewards. Cell-o1 achievesstate-of-the-art performance, outperforming o1 by over 73% and generalizingwell across contexts. Further analysis of training dynamics and reasoningbehaviors provides insights into batch-level annotation performance andemergent expert-like reasoning. Code and data are available athttps://github.com/ncbi-nlp/cell-o1.</description>
      <author>example@mail.com (Yin Fang, Qiao Jin, Guangzhi Xiong, Bowen Jin, Xianrui Zhong, Siru Ouyang, Aidong Zhang, Jiawei Han, Zhiyong Lu)</author>
      <guid isPermaLink="false">2506.02911v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>FDSG: Forecasting Dynamic Scene Graphs</title>
      <link>http://arxiv.org/abs/2506.01487v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 9 figures, 15 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FDSG的新框架，用于预测动态场景图，该框架能够预测未来帧中的实体标签、边界框和关系，同时为已观察到的帧生成场景图。&lt;h4&gt;背景&lt;/h4&gt;现有的场景图生成方法要么从观察到的帧中生成场景图而不显式建模时间动态，要么仅预测关系而假设静态实体标签和位置。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法的限制，有效预测实体和关系的动态，促进视频场景理解。&lt;h4&gt;方法&lt;/h4&gt;FDSG利用查询分解和神经网络随机微分方程来建模实体和关系的动态，并通过时间聚合模块通过交叉注意力整合预测和观察到的信息。&lt;h4&gt;主要发现&lt;/h4&gt;在Action Genome上的实验表明，FDSG在动态场景图生成、场景图预测和场景图预测方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;FDSG是一个有效的动态场景图预测框架，能够显著提高视频场景理解的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic scene graph generation extends scene graph generation from images tovideos by modeling entity relationships and their temporal evolution. However,existing methods either generate scene graphs from observed frames withoutexplicitly modeling temporal dynamics, or predict only relationships whileassuming static entity labels and locations. These limitations hinder effectiveextrapolation of both entity and relationship dynamics, restricting video sceneunderstanding. We propose Forecasting Dynamic Scene Graphs (FDSG), a novelframework that predicts future entity labels, bounding boxes, andrelationships, for unobserved frames, while also generating scene graphs forobserved frames. Our scene graph forecast module leverages query decompositionand neural stochastic differential equations to model entity and relationshipdynamics. A temporal aggregation module further refines predictions byintegrating forecasted and observed information via cross-attention. Tobenchmark FDSG, we introduce Scene Graph Forecasting, a new task for fullfuture scene graph prediction. Experiments on Action Genome show that FDSGoutperforms state-of-the-art methods on dynamic scene graph generation, scenegraph anticipation, and scene graph forecasting. Codes will be released uponpublication.</description>
      <author>example@mail.com (Yi Yang, Yuren Cong, Hao Cheng, Bodo Rosenhahn, Michael Ying Yang)</author>
      <guid isPermaLink="false">2506.01487v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Graph neural network model for the era of large atomistic models</title>
      <link>http://arxiv.org/abs/2506.01686v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为DPA3的多层图神经网络，该网络基于线图序列（LiGS），旨在大规模原子模型（LAMs）时代进行广泛应用。DPA3模型遵循可扩展性法则，在多个基准案例中显示出优越的准确性。&lt;h4&gt;背景&lt;/h4&gt;大规模原子模型（LAMs）旨在用密度泛函理论（DFT）普遍表示原子系统的基态势能面。可扩展性法则在大型模型的发展中至关重要，表明随着模型规模的增加、训练数据集的扩展和计算预算的增大，其泛化能力不断提高。&lt;h4&gt;目的&lt;/h4&gt;开发一种适用于LAMs时代的多任务训练模型DPA3，以在多种基准案例中实现高精度。&lt;h4&gt;方法&lt;/h4&gt;DPA3基于线图序列（LiGS）构建，通过堆叠额外层来增加模型参数的可扩展性，并采用一种数据集编码机制，在多任务训练框架中将训练数据规模的扩展与模型规模分离。&lt;h4&gt;主要发现&lt;/h4&gt;DPA3模型的泛化误差遵循可扩展性法则，作为问题导向的势能模型，在多数基准案例中显示出优越的准确性。在OpenLAM-v1数据集上训练的DPA-3.1-3M模型在LAMBench基准套件中表现出最先进的性能，展现出最低的整体零样本泛化误差。&lt;h4&gt;结论&lt;/h4&gt;DPA3作为一款开箱即用的潜在模型，在下游科学应用中需要最小的微调数据，表现出优异的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models, or large atomistic models (LAMs), aim to universallyrepresent the ground-state potential energy surface (PES) of atomistic systemsas defined by density functional theory (DFT). The scaling law is pivotal inthe development of large models, suggesting that their generalizability indownstream tasks consistently improves with increased model size, expandedtraining datasets, and larger computational budgets. In this study, we presentDPA3, a multi-layer graph neural network founded on line graph series (LiGS),designed explicitly for the era of LAMs. We demonstrate that the generalizationerror of the DPA3 model adheres to the scaling law. The scalability in thenumber of model parameters is attained by stacking additional layers withinDPA3. Additionally, the model employs a dataset encoding mechanism thatdecouples the scaling of training data size from the model size within itsmulti-task training framework. When trained as problem-oriented potentialenergy models, the DPA3 model exhibits superior accuracy in the majority ofbenchmark cases, encompassing systems with diverse features, includingmolecules, bulk materials, surface and cluster catalysis, two-dimensionalmaterials, and battery materials. When trained as a LAM on the OpenLAM-v1dataset, the DPA-3.1-3M model exhibits state-of-the-art performance in theLAMBench benchmark suit for LAMs, demonstrating lowest overall zero-shotgeneralization error across 17 downstream tasks from a broad spectrum ofresearch domains. This performance suggests superior accuracy as anout-of-the-box potential model, requiring minimal fine-tuning data fordownstream scientific applications.</description>
      <author>example@mail.com (Duo Zhang, Anyang Peng, Chun Cai, Wentao Li, Yuanchang Zhou, Jinzhe Zeng, Mingyu Guo, Chengqian Zhang, Bowen Li, Hong Jiang, Tong Zhu, Weile Jia, Linfeng Zhang, Han Wang)</author>
      <guid isPermaLink="false">2506.01686v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Unpacking Softmax: How Temperature Drives Representation Collapse, Compression, and Generalization</title>
      <link>http://arxiv.org/abs/2506.01562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了softmax函数在塑造模型表示中的关键作用，并引入了rank deficit bias的概念，探讨了softmax动力学在学习和增强模型表现方面的应用。&lt;h4&gt;背景&lt;/h4&gt;softmax函数是深度神经网络的基本构建块，常用于分类任务中的输出分布或transformer架构中的注意力权重。&lt;h4&gt;目的&lt;/h4&gt;研究softmax函数对学习动态和所学表示的影响，以优化模型行为。&lt;h4&gt;方法&lt;/h4&gt;引入rank deficit bias概念，分析softmax函数的logits范数对学习的影响，并演示如何利用softmax动力学来学习压缩表示或提高模型在分布外数据上的性能。&lt;h4&gt;主要发现&lt;/h4&gt;softmax函数可能导致深度网络找到比类别数量低得多的rank的解，这种偏差依赖于softmax函数的logits范数，该范数受超参数的隐式影响或由softmax温度直接修改。&lt;h4&gt;结论&lt;/h4&gt;本文提供了对softmax机制的新见解，使我们可以更好地控制深度神经网络中的表示学习。&lt;h4&gt;翻译&lt;/h4&gt;The softmax function is a fundamental building block of deep neural networks, commonly used to define output distributions in classification tasks or attention weights in transformer architectures. Despite its widespread use and proven effectiveness, its influence on learning dynamics and learned representations remains poorly understood, limiting our ability to optimize model behavior. In this paper, we study the pivotal role of the softmax function in shaping the model's representation. We introduce the concept of rank deficit bias - a phenomenon in which softmax-based deep networks find solutions of rank much lower than the number of classes. This bias depends on the softmax function's logits norm, which is implicitly influenced by hyperparameters or directly modified by softmax temperature. Furthermore, we demonstrate how to exploit the softmax dynamics to learn compressed representations or to enhance their performance on out-of-distribution data. We validate our findings across diverse architectures and real-world datasets, highlighting the broad applicability of temperature tuning in improving model performance. Our work provides new insights into the mechanisms of softmax, enabling better control over representation learning in deep neural networks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The softmax function is a fundamental building block of deep neural networks,commonly used to define output distributions in classification tasks orattention weights in transformer architectures. Despite its widespread use andproven effectiveness, its influence on learning dynamics and learnedrepresentations remains poorly understood, limiting our ability to optimizemodel behavior. In this paper, we study the pivotal role of the softmaxfunction in shaping the model's representation. We introduce the concept ofrank deficit bias - a phenomenon in which softmax-based deep networks findsolutions of rank much lower than the number of classes. This bias depends onthe softmax function's logits norm, which is implicitly influenced byhyperparameters or directly modified by softmax temperature. Furthermore, wedemonstrate how to exploit the softmax dynamics to learn compressedrepresentations or to enhance their performance on out-of-distribution data. Wevalidate our findings across diverse architectures and real-world datasets,highlighting the broad applicability of temperature tuning in improving modelperformance. Our work provides new insights into the mechanisms of softmax,enabling better control over representation learning in deep neural networks.</description>
      <author>example@mail.com (Wojciech Masarczyk, Mateusz Ostaszewski, Tin Sum Cheng, Tomasz Trzciński, Aurelien Lucchi, Razvan Pascanu)</author>
      <guid isPermaLink="false">2506.01562v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>EgoVLM: Policy Optimization for Egocentric Video Understanding</title>
      <link>http://arxiv.org/abs/2506.03097v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Our Code can be found at https://github.com/adityavavre/VidEgoVLM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了EgoVLM，一个针对第一人称视频流进行视觉理解和时空推理的视觉语言模型，并通过强化学习优化提高了模型性能。&lt;h4&gt;背景&lt;/h4&gt;随着可穿戴相机和自主代理等新兴的具身人工智能应用的发展，对从第一人称视频流中进行稳健推理的需求日益凸显。&lt;h4&gt;目的&lt;/h4&gt;设计EgoVLM，以整合视觉理解和时空推理，并使其适用于第一人称视频环境。&lt;h4&gt;方法&lt;/h4&gt;EgoVLM通过Group Relative Policy Optimization（GRPO）进行微调，该方法是一种强化学习方法，旨在使模型输出与人类的推理步骤相一致。同时，直接使用强化学习进行微调，而没有在思维链（CoT）数据上进行任何监督式微调。&lt;h4&gt;主要发现&lt;/h4&gt;EgoVLM在第一人称视频问答基准测试中表现出色，特定领域的训练显著提高了其性能。EgoVLM-3B在EgoSchema基准测试上分别比Qwen2.5-VL 3B和7B模型高出14.33和13.87个准确度点。通过明确生成推理轨迹，EgoVLM增强了可解释性，使其适用于下游应用。此外，引入了一种基于关键帧的新奖励机制，该机制结合了显著帧选择，以指导强化学习优化。&lt;h4&gt;结论&lt;/h4&gt;EgoVLM通过结合视觉语言模型和强化学习，为第一人称视频中的时空推理提供了有效的解决方案，并为未来在时间基础上的具身推理探索开辟了新的途径。&lt;h4&gt;翻译&lt;/h4&gt;We introduce EgoVLM, a vision-language model specifically designed to integrate visual comprehension and spatial-temporal reasoning within egocentric video contexts. EgoVLM is fine-tuned via Group Relative Policy Optimization (GRPO), a reinforcement learning method adapted to align model outputs with human-like reasoning steps. Following DeepSeek R1-Zero's approach, we directly tune using RL without any supervised fine-tuning phase on chain-of-thought (CoT) data. We evaluate EgoVLM on egocentric video question answering benchmarks and show that domain-specific training substantially improves performance over general-purpose VLMs. Our EgoVLM-3B, trained exclusively on non-CoT egocentric data, outperforms the base Qwen2.5-VL 3B and 7B models by 14.33 and 13.87 accuracy points on the EgoSchema benchmark, respectively. By explicitly generating reasoning traces, EgoVLM enhances interpretability, making it well-suited for downstream applications. Furthermore, we introduce a novel keyframe-based reward that incorporates salient frame selection to guide reinforcement learning optimization. This reward formulation opens a promising avenue for future exploration in temporally grounded egocentric reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emerging embodied AI applications, such as wearable cameras and autonomousagents, have underscored the need for robust reasoning from first person videostreams. We introduce EgoVLM, a vision-language model specifically designed tointegrate visual comprehension and spatial-temporal reasoning within egocentricvideo contexts. EgoVLM is fine-tuned via Group Relative Policy Optimization(GRPO), a reinforcement learning method adapted to align model outputs withhuman-like reasoning steps. Following DeepSeek R1-Zero's approach, we directlytune using RL without any supervised fine-tuning phase on chain-of-thought(CoT) data. We evaluate EgoVLM on egocentric video question answeringbenchmarks and show that domain-specific training substantially improvesperformance over general-purpose VLMs. Our EgoVLM-3B, trained exclusively onnon-CoT egocentric data, outperforms the base Qwen2.5-VL 3B and 7B models by14.33 and 13.87 accuracy points on the EgoSchema benchmark, respectively. Byexplicitly generating reasoning traces, EgoVLM enhances interpretability,making it well-suited for downstream applications. Furthermore, we introduce anovel keyframe-based reward that incorporates salient frame selection to guidereinforcement learning optimization. This reward formulation opens a promisingavenue for future exploration in temporally grounded egocentric reasoning.</description>
      <author>example@mail.com (Ashwin Vinod, Shrey Pandit, Aditya Vavre, Linshen Liu)</author>
      <guid isPermaLink="false">2506.03097v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning for Efficient Transaction Validation in UTXO-based Blockchains</title>
      <link>http://arxiv.org/abs/2506.01614v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种适用于UTXO型区块链（如比特币）的可扩展性机器学习（ML）方法，以优化UTXO集分片和交易路由，从而提升交易处理速度和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;现有的UTXO集分片方法在有效分配UTXO到验证者之间以及处理由于子父交易依赖产生的通信开销方面存在困难，这会显著降低交易处理速度。&lt;h4&gt;目的&lt;/h4&gt;提出一种机器学习方法，旨在优化UTXO集分片和交易路由，确保交易被路由到包含其父UTXO的分区，以提升交易处理速度和区块链的可扩展性。&lt;h4&gt;方法&lt;/h4&gt;该方法的核心是一个结合对比学习和无监督学习的框架，用于创建交易输出的嵌入空间。模型通过三元组损失和在线半硬负样本挖掘在历史交易数据上训练，将父-子消费模式直接嵌入其参数中。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够根据消费关系对交易输出进行分组，从而有效地将交易路由到正确的验证微服务，同时减少了跨分片通信开销。&lt;h4&gt;结论&lt;/h4&gt;该方法显著减少了跨分片通信开销，提高了吞吐量和可扩展性，避免了昂贵的实时父交易查找。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种适用于比特币等UTXO型区块链的可扩展性机器学习方法。先前关于UTXO集分片的方法在有效分配UTXO到验证者以及由于子父交易依赖产生的通信开销方面存在困难，这会显著阻碍交易处理速度。我们的解决方案使用机器学习来优化不仅UTXO集分片还包括交易路由，确保交易被路由到包含其父UTXO的分区。我们的方法的核心是一个结合对比学习和无监督学习的框架，用于创建交易输出的嵌入空间。这种嵌入允许模型根据消费关系对交易输出进行分组，从而能够有效地将交易路由到正确的验证微服务。该模型在历史交易数据上使用三元组损失和在线半硬负样本挖掘进行训练，将父-子消费模式直接嵌入其参数中，从而消除了昂贵的实时父交易查找的需要。这显著减少了跨分片通信开销，提高了吞吐量和可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a Machine Learning (ML) approach for scalability ofUTXO-based blockchains, such as Bitcoin. Prior approaches to UTXO set shardingstruggle with distributing UTXOs effectively across validators, creatingsubstantial communication overhead due to child-parent transactiondependencies. This overhead, which arises from the need to locate parent UTXOs,significantly hampers transaction processing speeds. Our solution uses ML tooptimize not only UTXO set sharding but also the routing of incomingtransactions, ensuring that transactions are directed to shards containingtheir parent UTXOs. At the heart of our approach is a framework that combinescontrastive and unsupervised learning to create an embedding space fortransaction outputs. This embedding allows the model to group transactionoutputs based on spending relationships, making it possible to routetransactions efficiently to the correct validation microservices. Trained onhistorical transaction data with triplet loss and online semi-hard negativemining, the model embeds parent-child spending patterns directly into itsparameters, thus eliminating the need for costly, real-time parent transactionlookups. This significantly reduces cross-shard communication overhead,boosting throughput and scalability.</description>
      <author>example@mail.com (Hamid Attar, Luigi Lunardon, Alessio Pagani)</author>
      <guid isPermaLink="false">2506.01614v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Learning Sparsity for Effective and Efficient Music Performance Question Answering</title>
      <link>http://arxiv.org/abs/2506.01319v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the main conference of the 63rd Annual Meeting of the  Association for Computational Linguistics (ACL 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对音乐表演中的多模态场景理解和推理的挑战，提出了一种名为Sparsify的稀疏学习框架，以提高音乐表演音频-视觉问答（Music AVQA）的性能和数据效率。&lt;h4&gt;背景&lt;/h4&gt;音乐表演具有密集连续的音频和无缝的音频-视觉集成，这对多模态场景理解和推理提出了独特挑战。&lt;h4&gt;目的&lt;/h4&gt;提出更有效的音频-视觉表示集成方法，提高Music AVQA的性能和数据效率。&lt;h4&gt;方法&lt;/h4&gt;Sparsify框架集成了三种稀疏化策略，并在Music AVQA数据集上实现了最先进的性能。此外，它通过选择和利用大约25%的MUSIC-AVQA v2.0训练数据，同时保持70-80%的全数据性能，来提高数据效率。&lt;h4&gt;主要发现&lt;/h4&gt;Sparsify在Music AVQA数据集上实现了最先进的性能，同时将训练时间减少了28.32%，保持了准确性。&lt;h4&gt;结论&lt;/h4&gt;Sparsify框架有效地提高了Music AVQA的性能和数据效率，为处理音乐表演中的多模态场景理解和推理提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Music performances, characterized by dense and continuous audio as well as seamless audio-visual integration, present unique challenges for multimodal scene understanding and reasoning. Recent Music Performance Audio-Visual Question Answering (Music AVQA) datasets have been proposed to reflect these challenges, highlighting the continued need for more effective integration of audio-visual representations in complex question answering. However, existing Music AVQA methods often rely on dense and unoptimized representations, leading to inefficiencies in the isolation of key information, the reduction of redundancy, and the prioritization of critical samples. To address these challenges, we introduce Sparsify, a sparse learning framework specifically designed for Music AVQA. It integrates three sparsification strategies into an end-to-end pipeline and achieves state-of-the-art performance on the Music AVQA datasets. In addition, it reduces training time by 28.32% compared to its fully trained dense counterpart while maintaining accuracy, demonstrating clear efficiency gains. To further improve data efficiency, we propose a key-subset selection algorithm that selects and uses approximately 25% of MUSIC-AVQA v2.0 training data and retains 70-80% of full-data performance across models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Music performances, characterized by dense and continuous audio as well asseamless audio-visual integration, present unique challenges for multimodalscene understanding and reasoning. Recent Music Performance Audio-VisualQuestion Answering (Music AVQA) datasets have been proposed to reflect thesechallenges, highlighting the continued need for more effective integration ofaudio-visual representations in complex question answering. However, existingMusic AVQA methods often rely on dense and unoptimized representations, leadingto inefficiencies in the isolation of key information, the reduction ofredundancy, and the prioritization of critical samples. To address thesechallenges, we introduce Sparsify, a sparse learning framework specificallydesigned for Music AVQA. It integrates three sparsification strategies into anend-to-end pipeline and achieves state-of-the-art performance on the Music AVQAdatasets. In addition, it reduces training time by 28.32% compared to its fullytrained dense counterpart while maintaining accuracy, demonstrating clearefficiency gains. To further improve data efficiency, we propose a key-subsetselection algorithm that selects and uses approximately 25% of MUSIC-AVQA v2.0training data and retains 70-80% of full-data performance across models.</description>
      <author>example@mail.com (Xingjian Diao, Tianzhen Yang, Chunhui Zhang, Weiyi Wu, Ming Cheng, Jiang Gui)</author>
      <guid isPermaLink="false">2506.01319v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Understanding and Improving Laplacian Positional Encodings For Temporal GNNs</title>
      <link>http://arxiv.org/abs/2506.01596v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ECML-PKDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了时间图学习在推荐系统、交通预测和社会网络分析中的应用，针对时间图中位置编码的进展有限的问题，提出了一种理论框架，并引入了新的方法来减少计算开销，同时进行了一系列实验研究。&lt;h4&gt;背景&lt;/h4&gt;时间图学习在多个领域有应用，但时间图中位置编码的进展有限，现有方法存在计算成本高、理论理解有限和编码应用不明确等问题。&lt;h4&gt;目的&lt;/h4&gt;解决时间图中位置编码的挑战，提高计算效率，并研究不同模型和任务中位置编码的有效性。&lt;h4&gt;方法&lt;/h4&gt;提出一个理论框架连接超拉普拉斯编码和时间切片编码，引入新的方法降低计算开销，并进行了广泛的实验研究。&lt;h4&gt;主要发现&lt;/h4&gt;位置编码在特定场景下可以显著提高性能，但其有效性在不同模型中存在差异。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和理论框架有助于推动时间图学习的发展，并提供了关于位置编码有效性的重要见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal graph learning has applications in recommendation systems, trafficforecasting, and social network analysis. Although multiple architectures havebeen introduced, progress in positional encoding for temporal graphs remainslimited. Extending static Laplacian eigenvector approaches to temporal graphsthrough the supra-Laplacian has shown promise, but also poses key challenges:high eigendecomposition costs, limited theoretical understanding, and ambiguityabout when and how to apply these encodings. In this paper, we address theseissues by (1) offering a theoretical framework that connects supra-Laplacianencodings to per-time-slice encodings, highlighting the benefits of leveragingadditional temporal connectivity, (2) introducing novel methods to reduce thecomputational overhead, achieving up to 56x faster runtimes while scaling tographs with 50,000 active nodes, and (3) conducting an extensive experimentalstudy to identify which models, tasks, and datasets benefit most from theseencodings. Our findings reveal that while positional encodings cansignificantly boost performance in certain scenarios, their effectivenessvaries across different models.</description>
      <author>example@mail.com (Yaniv Galron, Fabrizio Frasca, Haggai Maron, Eran Treister, Moshe Eliasof)</author>
      <guid isPermaLink="false">2506.01596v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Deep learning of thermodynamic laws from microscopic dynamics</title>
      <link>http://arxiv.org/abs/2506.01506v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究通过数值模拟证明了深度神经网络可以从微观数据中学习宏观热力学定律。&lt;h4&gt;背景&lt;/h4&gt;使用分子动力学模拟生成气体粒子在绝热过程中的快照图像数据。&lt;h4&gt;目的&lt;/h4&gt;训练深度神经网络以确定输入图像对的时序顺序。&lt;h4&gt;方法&lt;/h4&gt;观察训练后的网络是否能在状态之间诱导出与绝热可及性一致的关系，并满足热力学的公理。&lt;h4&gt;主要发现&lt;/h4&gt;训练的神经网络学习到的内部表示可以作为熵，表明机器学习可以揭示在比基本组成部分大的尺度上有效的涌现物理定律。&lt;h4&gt;结论&lt;/h4&gt;这些结果为数据驱动发现宏观物理学开辟了途径。&lt;h4&gt;翻译&lt;/h4&gt;我们通过数值模拟表明，深度神经网络可以从微观数据中纯学习宏观热力学定律。利用分子动力学模拟，我们生成了气体粒子经历绝热过程的快照图像数据。我们训练一个深度神经网络来确定输入图像对的时序顺序。我们观察到，训练后的网络在状态之间诱导出与绝热可及性一致的关系，满足热力学的公理。此外，深度神经网络学习到的内部表示作为熵。这些结果表明，机器学习可以揭示在比基本组成部分大的尺度上有效的涌现物理定律——为数据驱动发现宏观物理学开辟了途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We numerically show that a deep neural network (DNN) can learn macroscopicthermodynamic laws purely from microscopic data. Using molecular dynamicssimulations, we generate the data of snapshot images of gas particlesundergoing adiabatic processes. We train a DNN to determine the temporal orderof input image pairs. We observe that the trained network induces an orderrelation between states consistent with adiabatic accessibility, satisfying theaxioms of thermodynamics. Furthermore, the internal representation learned bythe DNN act as an entropy. These results suggest that machine learning candiscover emergent physical laws that are valid at scales far larger than thoseof the underlying constituents -- opening a pathway to data-driven discovery ofmacroscopic physics.</description>
      <author>example@mail.com (Hiroto Kuroyanagi, Tatsuro Yuge)</author>
      <guid isPermaLink="false">2506.01506v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>HaploOmni: Unified Single Transformer for Multimodal Video Understanding and Generation</title>
      <link>http://arxiv.org/abs/2506.02975v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种高效训练范式，用于构建用于统一多模态理解和生成的单个Transformer模型。&lt;h4&gt;背景&lt;/h4&gt;随着语言模型的发展，统一的多模态理解和生成在模型架构从分离的组件发展到统一的单模型框架方面取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;旨在通过提出一种多模态预热策略和解决跨模态兼容性挑战的方法，来构建一个能够高效训练的统一多模态理解和生成模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一种多模态预热策略，利用先验知识扩展模型能力，并引入了特征预缩放和多模态AdaLN技术来解决跨模态兼容性问题。&lt;h4&gt;主要发现&lt;/h4&gt;整合所提出的技术，创建了HaploOmni，这是一种新的单模态Transformer。HaploOmni在有限的训练成本下，在多个图像和视频理解和生成基准测试中实现了与先进统一模型相竞争的性能。&lt;h4&gt;结论&lt;/h4&gt;所有代码将在https://github.com/Tencent/HaploVLM上公开，以供进一步的研究和验证。&lt;h4&gt;翻译&lt;/h4&gt;With the advancement of language models, unified multimodal understanding and generation have made significant strides, with model architectures evolving from separated components to unified single-model frameworks. This paper explores an efficient training paradigm to build a single transformer for unified multimodal understanding and generation. Specifically, we propose a multimodal warmup strategy utilizing prior knowledge to extend capabilities. To address cross-modal compatibility challenges, we introduce feature pre-scaling and multimodal AdaLN techniques. Integrating the proposed technologies, we present the HaploOmni, a new single multimodal transformer. With limited training costs, HaploOmni achieves competitive performance across multiple image and video understanding and generation benchmarks over advanced unified models. All codes will be made public at https://github.com/Tencent/HaploVLM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the advancement of language models, unified multimodal understanding andgeneration have made significant strides, with model architectures evolvingfrom separated components to unified single-model frameworks. This paperexplores an efficient training paradigm to build a single transformer forunified multimodal understanding and generation. Specifically, we propose amultimodal warmup strategy utilizing prior knowledge to extend capabilities. Toaddress cross-modal compatibility challenges, we introduce feature pre-scalingand multimodal AdaLN techniques. Integrating the proposed technologies, wepresent the HaploOmni, a new single multimodal transformer. With limitedtraining costs, HaploOmni achieves competitive performance across multipleimage and video understanding and generation benchmarks over advanced unifiedmodels. All codes will be made public at https://github.com/Tencent/HaploVLM.</description>
      <author>example@mail.com (Yicheng Xiao, Lin Song, Rui Yang, Cheng Cheng, Zunnan Xu, Zhaoyang Zhang, Yixiao Ge, Xiu Li, Ying Shan)</author>
      <guid isPermaLink="false">2506.02975v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>SemiVT-Surge: Semi-Supervised Video Transformer for Surgical Phase Recognition</title>
      <link>http://arxiv.org/abs/2506.01471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视频转换器的模型，用于半监督学习在手术阶段识别中的应用，通过结合未标记数据和标签数据进行特征空间优化，显著提高了手术视频分析的准确性。&lt;h4&gt;背景&lt;/h4&gt;准确识别手术阶段对于计算机辅助手术和手术视频分析至关重要，但手动标注手术视频工作量大，促使研究转向利用未标记数据以减少标注的工作量。&lt;h4&gt;目的&lt;/h4&gt;提出一种半监督学习方法，以在手术视频分析中利用未标记数据，实现高准确率。&lt;h4&gt;方法&lt;/h4&gt;该方法包括一个鲁棒的伪标签框架，结合了时间一致性正则化和带有类别原型的对比学习，以利用标记数据和伪标签来优化特征空间。&lt;h4&gt;主要发现&lt;/h4&gt;在RAMIE数据集上，通过结合未标记数据，该方法实现了4.9%的准确率提升，在Cholec80数据集上使用1/4的标记数据即获得了与全监督方法相当的结果。&lt;h4&gt;结论&lt;/h4&gt;该方法为半监督手术阶段识别建立了一个强大的基准，为该领域未来的研究铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;Accurate surgical phase recognition is crucial for computer-assisted interventions and surgical video analysis. Annotating long surgical videos is labor-intensive, driving research toward leveraging unlabeled data for strong performance with minimal annotations. Although self-supervised learning has gained popularity by enabling large-scale pretraining followed by fine-tuning on small labeled subsets, semi-supervised approaches remain largely underexplored in the surgical domain. In this work, we propose a video transformer-based model with a robust pseudo-labeling framework. Our method incorporates temporal consistency regularization for unlabeled data and contrastive learning with class prototypes, which leverages both labeled data and pseudo-labels to refine the feature space. Through extensive experiments on the private RAMIE (Robot-Assisted Minimally Invasive Esophagectomy) dataset and the public Cholec80 dataset, we demonstrate the effectiveness of our approach. By incorporating unlabeled data, we achieve state-of-the-art performance on RAMIE with a 4.9% accuracy increase and obtain comparable results to full supervision while using only 1/4 of the labeled data on Cholec80. Our findings establish a strong benchmark for semi-supervised surgical phase recognition, paving the way for future research in this domain.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate surgical phase recognition is crucial for computer-assistedinterventions and surgical video analysis. Annotating long surgical videos islabor-intensive, driving research toward leveraging unlabeled data for strongperformance with minimal annotations. Although self-supervised learning hasgained popularity by enabling large-scale pretraining followed by fine-tuningon small labeled subsets, semi-supervised approaches remain largelyunderexplored in the surgical domain. In this work, we propose a videotransformer-based model with a robust pseudo-labeling framework. Our methodincorporates temporal consistency regularization for unlabeled data andcontrastive learning with class prototypes, which leverages both labeled dataand pseudo-labels to refine the feature space. Through extensive experiments onthe private RAMIE (Robot-Assisted Minimally Invasive Esophagectomy) dataset andthe public Cholec80 dataset, we demonstrate the effectiveness of our approach.By incorporating unlabeled data, we achieve state-of-the-art performance onRAMIE with a 4.9% accuracy increase and obtain comparable results to fullsupervision while using only 1/4 of the labeled data on Cholec80. Our findingsestablish a strong benchmark for semi-supervised surgical phase recognition,paving the way for future research in this domain.</description>
      <author>example@mail.com (Yiping Li, Ronald de Jong, Sahar Nasirihaghighi, Tim Jaspers, Romy van Jaarsveld, Gino Kuiper, Richard van Hillegersberg, Fons van der Sommen, Jelle Ruurda, Marcel Breeuwer, Yasmina Al Khalil)</author>
      <guid isPermaLink="false">2506.01471v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Sheep Facial Pain Assessment Under Weighted Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.01468v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2025 19th International Conference on Automatic Face and Gesture  Recognition (FG)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的加权图神经网络（WGNN）模型，用于识别和评估羊的疼痛程度，并构建了一个新的羊面部特征数据集，以提高羊疼痛检测的准确性。&lt;h4&gt;背景&lt;/h4&gt;准确识别和评估羊的疼痛对于动物健康和减轻有害情况至关重要，但现有的自动监测疼痛的能力有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来链接羊的面部特征和定义疼痛水平，以准确评估羊的健康状态。&lt;h4&gt;方法&lt;/h4&gt;研究分析了羊的面部表情，并提出了一个新的加权图神经网络（WGNN）模型，以及一个符合羊面部表情量表（SPFES）参数的羊面部特征数据集。&lt;h4&gt;主要发现&lt;/h4&gt;YOLOv8n检测器在羊面部特征数据集上实现了59.30%的平均精度（mAP），在七个其他检测模型中表现最佳。WGNN框架在YOLOv8n轻量级设备上部署时，对多个面部部位表情的跟踪准确率达到92.71%。&lt;h4&gt;结论&lt;/h4&gt;面部特征检测和疼痛水平预测对于评估羊的健康状态至关重要，而WGNN模型在羊面部特征数据上的应用具有很高的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Accurately recognizing and assessing pain in sheep is key to discern animal health and mitigating harmful situations. However, such accuracy is limited by the ability to manage automatic monitoring of pain in those animals. Facial expression scoring is a widely used and useful method to evaluate pain in both humans and other living beings. Researchers also analyzed the facial expressions of sheep to assess their health state and concluded that facial landmark detection and pain level prediction are essential. For this purpose, we propose a novel weighted graph neural network (WGNN) model to link sheep's detected facial landmarks and define pain levels. Furthermore, we propose a new sheep facial landmarks dataset that adheres to the parameters of the Sheep Facial Expression Scale (SPFES). Currently, there is no comprehensive performance benchmark that specifically evaluates the use of graph neural networks (GNNs) on sheep facial landmark data to detect and measure pain levels. The YOLOv8n detector architecture achieves a mean average precision (mAP) of 59.30% with the sheep facial landmarks dataset, among seven other detection models. The WGNN framework has an accuracy of 92.71% for tracking multiple facial parts expressions with the YOLOv8n lightweight on-board device deployment-capable model.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately recognizing and assessing pain in sheep is key to discern animalhealth and mitigating harmful situations. However, such accuracy is limited bythe ability to manage automatic monitoring of pain in those animals. Facialexpression scoring is a widely used and useful method to evaluate pain in bothhumans and other living beings. Researchers also analyzed the facialexpressions of sheep to assess their health state and concluded that faciallandmark detection and pain level prediction are essential. For this purpose,we propose a novel weighted graph neural network (WGNN) model to link sheep'sdetected facial landmarks and define pain levels. Furthermore, we propose a newsheep facial landmarks dataset that adheres to the parameters of the SheepFacial Expression Scale (SPFES). Currently, there is no comprehensiveperformance benchmark that specifically evaluates the use of graph neuralnetworks (GNNs) on sheep facial landmark data to detect and measure painlevels. The YOLOv8n detector architecture achieves a mean average precision(mAP) of 59.30% with the sheep facial landmarks dataset, among seven otherdetection models. The WGNN framework has an accuracy of 92.71% for trackingmultiple facial parts expressions with the YOLOv8n lightweight on-board devicedeployment-capable model.</description>
      <author>example@mail.com (Alam Noor, Luis Almeida, Mohamed Daoudi, Kai Li, Eduardo Tovar)</author>
      <guid isPermaLink="false">2506.01468v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MobCLIP: Learning General-purpose Geospatial Representation at Scale</title>
      <link>http://arxiv.org/abs/2506.01297v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MobCLIP是一个全国范围内的通用目的位置编码器，通过有效且可扩展的多模态融合，集成了前所未有的数据多样性。&lt;h4&gt;背景&lt;/h4&gt;当前嵌入方法在实现通用地理空间智能方面仍然是一个核心挑战，它们通常缺乏通用性，限制了它们在人类和自然领域的多样化任务中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出MobCLIP，旨在构建一个能够处理多种数据模式并应用于不同任务的通用位置编码器。&lt;h4&gt;方法&lt;/h4&gt;采用基于CLIP的新型架构，MobCLIP将100M+的POI、全国范围的遥感影像和结构化人口统计数据与一个包含十亿条边的移动性图进行对齐。通过将空间位置划分为灵感来自Vision Transformers的网格单元，建立了连接移动模式和多模态特征的统一表示空间。&lt;h4&gt;主要发现&lt;/h4&gt;MobCLIP在具有四个输入模态和紧凑的128维表示空间的帮助下，在11个下游预测任务上（涵盖社会、经济和自然领域）实现了比最先进模型平均高出35%的显著更好的通用预测性能。特别是在人类中心任务上，性能提升尤为显著，如能耗预测（+260%）、线下零售消费量预测（+98%）和犯罪案件预测（+95%）。此外，MobCLIP也表现出与LLM扩展法则一致的扩展行为。&lt;h4&gt;结论&lt;/h4&gt;MobCLIP在地理空间表示学习方面展现了强大的能力，通过有效的人本模式集成，在多个领域取得了显著的性能提升，并证明了其扩展潜力。&lt;h4&gt;翻译&lt;/h4&gt;Representation learning of geospatial locations remains a core challenge in achieving general geospatial intelligence. Current embedding methods often lack versatility, limiting their utility across diverse tasks in both human and natural domains. We present MobCLIP, the first nationwide general-purpose location encoder, integrating an unprecedented diversity of data modalities through effective and scalable multimodal fusion. Adopting a novel CLIP-based architecture, our framework aligns 100M+ POIs, nationwide remote sensing imagery, and structured demographic statistics with a billion-edge mobility graph. By tokenizing spatial locations into grid cells inspired by Vision Transformers, we establish a unified representation space bridging mobility patterns and multimodal features. To rigorously evaluate the general-purpose effectiveness of MobCLIP, we construct a benchmark dataset composed of 11 downstream prediction tasks across social, economic, and natural domains. Experiments show that MobCLIP, with four input modalities and a compact 128-dimensional representation space, achieves significantly superior general-purpose predictive performances than state-of-the-art models by an average of 35%. Thanks to the effective integration of human-centric modalities, the performance gain is particularly profound in human-centric tasks, such as energy consumption (+260%), offline retail consumption amount (+98%), and crime cases (+95%) predictions. Echoing LLM scaling laws, we further demonstrate the scaling behavior in geospatial representation learning. We open-source code and pretrained models at: github.com.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning of geospatial locations remains a core challenge inachieving general geospatial intelligence. Current embedding methods often lackversatility, limiting their utility across diverse tasks in both human andnatural domains. We present MobCLIP, the first nationwide general-purposelocation encoder, integrating an unprecedented diversity of data modalitiesthrough effective and scalable multimodal fusion. Adopting a novel CLIP-basedarchitecture, our framework aligns 100M+ POIs, nationwide remote sensingimagery, and structured demographic statistics with a billion-edge mobilitygraph. By tokenizing spatial locations into grid cells inspired by VisionTransformers, we establish a unified representation space bridging mobilitypatterns and multimodal features. To rigorously evaluate the general-purposeeffectiveness of MobCLIP, we construct a benchmark dataset composed of 11downstream prediction tasks across social, economic, and natural domains.Experiments show that MobCLIP, with four input modalities and a compact128-dimensional representation space, achieves significantly superiorgeneral-purpose predictive performances than state-of-the-art models by anaverage of 35%. Thanks to the effective integration of human-centricmodalities, the performance gain is particularly profound in human-centrictasks, such as energy consumption (+260%), offline retail consumption amount(+98%), and crime cases (+95%) predictions. Echoing LLM scaling laws, wefurther demonstrate the scaling behavior in geospatial representation learning.We open-source code and pretrained models at: github.com.</description>
      <author>example@mail.com (Ya Wen, Jixuan Cai, Qiyao Ma, Linyan Li, Xinhua Chen, Chris Webster, Yulun Zhou)</author>
      <guid isPermaLink="false">2506.01297v2</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Perceptual Inductive Bias Is What You Need Before Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.01201v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025. Tianqin Li and Junru Zhao contributed equally to this  work. Due to a formatting error during the CVPR submission, the equal  contribution note was omitted in the official proceedings. This arXiv version  corrects that oversight. The author order follows alphabetical order by last  name&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了Marr的视觉感知理论，提出了一种基于Marr多阶段理论的对象表示学习方法，该方法在视觉处理中优先考虑边界和表面属性的推导，从而提高了收敛速度和最终表示质量。&lt;h4&gt;背景&lt;/h4&gt;Marr的视觉感知理论认为视觉处理是多阶段的，先处理边界和表面属性，再形成语义对象表示。而传统的对比表示学习方法通常跳过这一多阶段过程，直接学习语义表示空间。&lt;h4&gt;目的&lt;/h4&gt;通过利用Marr的多阶段理论，构建边界和表面级别的表示，并在其后进行对象语义的训练，以提高模型的收敛速度和最终表示质量。&lt;h4&gt;方法&lt;/h4&gt;该方法包括两个阶段：首先使用早期视觉处理阶段的感知结构构建边界和表面级别的表示；其次，训练模型以进行对象语义的学习。&lt;h4&gt;主要发现&lt;/h4&gt;该研究发现，该方法在ResNet18上实现了2倍的收敛速度，在语义分割、深度估计和对象识别任务上提高了最终表示质量，并且增强了鲁棒性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;论文提出了在通用对比表示预训练之前添加一个预训练阶段，以进一步优化最终表示质量并减少整体收敛时间，这是通过从人类视觉系统中获取的归纳偏差实现的。&lt;h4&gt;翻译&lt;/h4&gt;David Marr的先导视觉感知理论规定，视觉处理是一个多阶段的过程，优先考虑边界和表面属性的推导，然后再形成语义对象表示。与此相反，对比表示学习框架通常绕过这种明确的阶段性方法，将其目标定义为直接学习对象的语义表示空间。虽然这种方法在一般环境中是有效的，但它牺牲了视觉的归纳偏差，导致收敛速度较慢，并导致学习捷径产生纹理偏差。在本工作中，我们证明了通过利用Marr的多阶段理论——首先使用早期视觉处理阶段的感知结构构建边界和表面级别的表示，然后训练对象语义——可以在ResNet18上实现2倍的收敛速度，在语义分割、深度估计和对象识别上提高最终表示，并增强鲁棒性和泛化能力。总之，我们提出在通用对比表示预训练之前添加一个预训练阶段，通过从人类视觉系统中获取的归纳偏差，进一步优化最终表示质量并减少整体收敛时间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; David Marr's seminal theory of human perception stipulates that visualprocessing is a multi-stage process, prioritizing the derivation of boundaryand surface properties before forming semantic object representations. Incontrast, contrastive representation learning frameworks typically bypass thisexplicit multi-stage approach, defining their objective as the direct learningof a semantic representation space for objects. While effective in generalcontexts, this approach sacrifices the inductive biases of vision, leading toslower convergence speed and learning shortcut resulting in texture bias. Inthis work, we demonstrate that leveraging Marr's multi-stage theory-by firstconstructing boundary and surface-level representations using perceptualconstructs from early visual processing stages and subsequently training forobject semantics-leads to 2x faster convergence on ResNet18, improved finalrepresentations on semantic segmentation, depth estimation, and objectrecognition, and enhanced robustness and out-of-distribution capability.Together, we propose a pretraining stage before the general contrastiverepresentation pretraining to further enhance the final representation qualityand reduce the overall convergence time via inductive bias from human visionsystems.</description>
      <author>example@mail.com (Tianqin Li, Junru Zhao, Dunhan Jiang, Shenghao Wu, Alan Ramirez, Tai Sing Lee)</author>
      <guid isPermaLink="false">2506.01201v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>METok: Multi-Stage Event-based Token Compression for Efficient Long Video Understanding</title>
      <link>http://arxiv.org/abs/2506.02850v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为METok的无需训练的多阶段事件驱动令牌压缩框架，旨在加速视频大型语言模型（VLLMs）的推理，同时保持准确性。&lt;h4&gt;背景&lt;/h4&gt;尽管视频大型语言模型在理解视频内容方面取得了显著进步，但处理长视频仍然具有挑战性，主要是因为计算需求高和视觉数据中的冗余。&lt;h4&gt;目的&lt;/h4&gt;提出METok框架，旨在加速VLLMs的推理过程，同时保持或提高模型的准确性。&lt;h4&gt;方法&lt;/h4&gt;METok通过三个关键阶段逐步消除冗余视觉令牌：1）在视觉编码过程中的事件感知压缩；2）基于语义对齐和事件重要性在预填充阶段进行分层令牌剪枝；3）解码阶段的KV缓存优化以进一步减少内存消耗。&lt;h4&gt;主要发现&lt;/h4&gt;在多个视频基准测试中，METok通过动态选择信息丰富的视觉令牌，在效率和准确性之间实现了最佳权衡。例如，将LongVA-7B与METok结合使用，实现了80.6%的FLOPs减少和93.5%的KV缓存内存节省，同时保持了可比甚至更优的准确性。&lt;h4&gt;结论&lt;/h4&gt;METok框架为VLLMs提供了一种有效的加速方法，同时保持了高准确性，为处理长视频提供了一种可行的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Video Large Language Models (VLLMs) have significantlyenhanced their ability to understand video content. Nonetheless, processinglong videos remains challenging due to high computational demands and theredundancy present in the visual data. In this work, we propose METok, atraining-free, Multi-stage Event-based Token compression framework designed toaccelerate VLLMs' inference while preserving accuracy. METok progressivelyeliminates redundant visual tokens across three critical stages: (1)event-aware compression during vision encoding, (2) hierarchical token pruningin the prefilling stage based on semantic alignment and event importance, and(3) a decoding-stage KV Cache optimization that further reduces memoryconsumption. Our experiments on diverse video benchmarks demonstrate that METokachieves an optimal trade-off between efficiency and accuracy by dynamicallyselecting informative visual tokens. For instance, equipping LongVA-7B withMETok realizes an 80.6% FLOPs reduction and 93.5% KV Cache memory savings, allwhile maintaining comparable or even superior accuracy.</description>
      <author>example@mail.com (Mengyue Wang, Shuo Chen, Kristian Kersting, Volker Tresp, Yunpu Ma)</author>
      <guid isPermaLink="false">2506.02850v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Kernel-based Unsupervised Embedding Alignment for Enhanced Visual Representation in Vision-language Models</title>
      <link>http://arxiv.org/abs/2506.02557v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的基于核的方法，用于将CLIP的视觉表示与DINOv2对齐，以提高下游多模态大语言模型（MLLMs）的性能。&lt;h4&gt;背景&lt;/h4&gt;CLIP等视觉语言模型在视觉和文本表示对齐方面取得了显著成功，但它们的细粒度感知能力有限，导致下游MLLMs性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以增强CLIP视觉表示的感知能力，同时保持与文本嵌入的兼容性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种针对高效随机优化的对齐目标，通过仅对图像进行对齐微调，使视觉编码器与冻结的文本编码器保持兼容，并在零样本对象识别、细粒度空间推理和定位方面表现出显著改进。&lt;h4&gt;主要发现&lt;/h4&gt;对齐后的视觉编码器在零样本对象识别、细粒度空间推理和定位方面有显著提升，下游MLLMs的性能也得到增强。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地提高了CLIP视觉表示的感知能力，并显著提升了下游MLLMs的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉语言模型，如CLIP，在视觉和文本表示对齐方面取得了显著成功，已成为许多多模态大语言模型（MLLMs）如LLaVA和OpenFlamingo的核心组件。然而，许多研究已经指出CLIP的细粒度感知能力有限是一个关键缺点，导致下游MLLMs性能大幅下降。相比之下，以视觉为中心的基础模型如DINOv2在捕捉图像细节方面表现出惊人的能力。在这项工作中，我们提出了一种基于核的新方法，将CLIP的视觉表示与DINOv2对齐，确保生成的嵌入与文本嵌入保持兼容性的同时增强了感知能力。我们的对齐目标是针对高效随机优化设计的。在仅对图像进行对齐微调之后，视觉编码器保持了与冻结的文本编码器的兼容性，并在零样本对象识别、细粒度空间推理和定位方面表现出显著的改进。通过集成对齐的视觉编码器，下游MLLMs也展示了增强的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models, such as CLIP, have achieved significant success inaligning visual and textual representations, becoming essential components ofmany multi-modal large language models (MLLMs) like LLaVA and OpenFlamingo.However, numerous studies have identified CLIP's limited fine-grainedperception as a critical drawback, leading to substantial failures indownstream MLLMs. In contrast, vision-centric foundation models like DINOv2demonstrate remarkable capabilities in capturing fine details from images. Inthis work, we propose a novel kernel-based method to align CLIP's visualrepresentation with that of DINOv2, ensuring that the resulting embeddingsmaintain compatibility with text embeddings while enhancing perceptualcapabilities. Our alignment objective is designed for efficient stochasticoptimization. Following this image-only alignment fine-tuning, the visualencoder retains compatibility with the frozen text encoder and exhibitssignificant improvements in zero-shot object recognition, fine-grained spatialreasoning, and localization. By integrating the aligned visual encoder,downstream MLLMs also demonstrate enhanced performance.</description>
      <author>example@mail.com (Shizhan Gong, Yankai Jiang, Qi Dou, Farzan Farnia)</author>
      <guid isPermaLink="false">2506.02557v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Recent Developments in GNNs for Drug Discovery</title>
      <link>http://arxiv.org/abs/2506.01302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文回顾了图神经网络（GNN）在计算药物发现中的最新发展及其在分子生成、分子性质预测和药物-药物相互作用预测中的作用。&lt;h4&gt;背景&lt;/h4&gt;文章强调了GNN在理解复杂分子模式方面的能力，并探讨了其当前和潜在的应用。&lt;h4&gt;目的&lt;/h4&gt;通过对该领域最新发展的总结，强调GNN的能力，并分类现有基于输入类型和下游应用任务的GNN模型。&lt;h4&gt;方法&lt;/h4&gt;文章首先分析了各种分子表示方法，然后详细讨论并分类了现有GNN模型，并收集了各种应用中常用的基准数据集。&lt;h4&gt;主要发现&lt;/h4&gt;没有明确指出具体的主要发现，但提到总结了该研究领域的共同趋势。&lt;h4&gt;结论&lt;/h4&gt;文章最后简要讨论了GNN在计算药物发现中的发展趋势。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we review recent developments and the role of Graph Neural Networks (GNNs) in computational drug discovery, including molecule generation, molecular property prediction, and drug-drug interaction prediction. By summarizing the most recent developments in this area, we underscore the capabilities of GNNs to comprehend intricate molecular patterns, while exploring both their current and prospective applications. We initiate our discussion by examining various molecular representations, followed by detailed discussions and categorization of existing GNN models based on their input types and downstream application tasks. We also collect a list of commonly used benchmark datasets for a variety of applications. We conclude the paper with brief discussions and summarize common trends in this important research area.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we review recent developments and the role of Graph NeuralNetworks (GNNs) in computational drug discovery, including molecule generation,molecular property prediction, and drug-drug interaction prediction. Bysummarizing the most recent developments in this area, we underscore thecapabilities of GNNs to comprehend intricate molecular patterns, whileexploring both their current and prospective applications. We initiate ourdiscussion by examining various molecular representations, followed by detaileddiscussions and categorization of existing GNN models based on their inputtypes and downstream application tasks. We also collect a list of commonly usedbenchmark datasets for a variety of applications. We conclude the paper withbrief discussions and summarize common trends in this important research area.</description>
      <author>example@mail.com (Zhengyu Fang, Xiaoge Zhang, Anyin Zhao, Xiao Li, Huiyuan Chen, Jing Li)</author>
      <guid isPermaLink="false">2506.01302v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Learning More with Less: Self-Supervised Approaches for Low-Resource Speech Emotion Recognition</title>
      <link>http://arxiv.org/abs/2506.02059v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在低资源语言环境下，利用无监督学习方法提升语音情感识别（SER）的效果。&lt;h4&gt;背景&lt;/h4&gt;尽管深度学习在语音情感识别领域取得了显著进展，但对于低资源语言（LRLs）来说，由于标注数据的稀缺，仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过无监督学习提高低资源语言环境下的语音情感识别性能。&lt;h4&gt;方法&lt;/h4&gt;具体方法包括探究对比学习（CL）和自监督的Bootstrap Your Own Latent（BYOL）来增强跨语言的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;这些方法在乌尔都语、德语和孟加拉语中实现了显著的F1分数提升，分别为10.6%、15.2%和13.9%，证明了它们在低资源语言中的有效性。&lt;h4&gt;结论&lt;/h4&gt;本文的工作为开发面向少数语言、更具包容性、可解释性和鲁棒性的情感识别系统提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;Speech Emotion Recognition (SER) has seen significant progress with deep learning, yet remains challenging for Low-Resource Languages (LRLs) due to the scarcity of annotated data. In this work, we explore unsupervised learning to improve SER in low-resource settings. Specifically, we investigate contrastive learning (CL) and Bootstrap Your Own Latent (BYOL) as self-supervised approaches to enhance cross-lingual generalization. Our methods achieve notable F1 score improvements of 10.6% in Urdu, 15.2% in German, and 13.9% in Bangla, demonstrating their effectiveness in LRLs. Additionally, we analyze model behavior to provide insights on key factors influencing performance across languages, and also highlighting challenges in low-resource SER. This work provides a foundation for developing more inclusive, explainable, and robust emotion recognition systems for underrepresented languages.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech Emotion Recognition (SER) has seen significant progress with deeplearning, yet remains challenging for Low-Resource Languages (LRLs) due to thescarcity of annotated data. In this work, we explore unsupervised learning toimprove SER in low-resource settings. Specifically, we investigate contrastivelearning (CL) and Bootstrap Your Own Latent (BYOL) as self-supervisedapproaches to enhance cross-lingual generalization. Our methods achieve notableF1 score improvements of 10.6% in Urdu, 15.2% in German, and 13.9% in Bangla,demonstrating their effectiveness in LRLs. Additionally, we analyze modelbehavior to provide insights on key factors influencing performance acrosslanguages, and also highlighting challenges in low-resource SER. This workprovides a foundation for developing more inclusive, explainable, and robustemotion recognition systems for underrepresented languages.</description>
      <author>example@mail.com (Ziwei Gong, Pengyuan Shi, Kaan Donbekci, Lin Ai, Run Chen, David Sasu, Zehui Wu, Julia Hirschberg)</author>
      <guid isPermaLink="false">2506.02059v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Multi-View Representation Learning using Vision-Language Model for 3D/4D Facial Expression Recognition</title>
      <link>http://arxiv.org/abs/2506.01203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SMILE-VLM的自监督视觉-语言模型，用于3D/4D面部表情识别，该模型统一了多视图视觉表示学习与自然语言监督，并在多个基准测试中实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;面部表情识别（FER）是情感计算中的基本任务，应用于人机交互、心理健康分析和行为理解。&lt;h4&gt;目的&lt;/h4&gt;提出SMILE-VLM，以实现更鲁棒、语义对齐且视图不变的面部表情嵌入。&lt;h4&gt;方法&lt;/h4&gt;SMILE-VLM通过以下三个核心组件实现：通过Barlow Twins风格的损失实现多视图去相关，视觉-语言对比对齐，以及跨模态冗余最小化。&lt;h4&gt;主要发现&lt;/h4&gt;SMILE-VLM在多个基准测试中取得了最先进的性能，并且将其扩展到4D微表情识别（MER）任务，以识别微妙的情感线索。&lt;h4&gt;结论&lt;/h4&gt;SMILE-VLM不仅超越了现有的无监督方法，而且与监督基线相匹配或超过，为表达性面部行为理解提供了一个可扩展且标注高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Facial expression recognition (FER) is a fundamental task in affectivecomputing with applications in human-computer interaction, mental healthanalysis, and behavioral understanding. In this paper, we propose SMILE-VLM, aself-supervised vision-language model for 3D/4D FER that unifies multiviewvisual representation learning with natural language supervision. SMILE-VLMlearns robust, semantically aligned, and view-invariant embeddings by proposingthree core components: multiview decorrelation via a Barlow Twins-style loss,vision-language contrastive alignment, and cross-modal redundancy minimization.Our framework achieves the state-of-the-art performance on multiple benchmarks.We further extend SMILE-VLM to the task of 4D micro-expression recognition(MER) to recognize the subtle affective cues. The extensive results demonstratethat SMILE-VLM not only surpasses existing unsupervised methods but alsomatches or exceeds supervised baselines, offering a scalable andannotation-efficient solution for expressive facial behavior understanding.</description>
      <author>example@mail.com (Muzammil Behzad)</author>
      <guid isPermaLink="false">2506.01203v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Aligned Contrastive Loss for Long-Tailed Recognition</title>
      <link>http://arxiv.org/abs/2506.01071v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025 DG-EBF Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种对齐对比学习（ACL）算法来解决长尾识别问题。&lt;h4&gt;背景&lt;/h4&gt;多视角训练可以提高性能，但随着视角数量的增加，对比学习并不总是能提高模型的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;设计ACL算法以消除梯度冲突和正负样本间不平衡的吸引和排斥梯度问题。&lt;h4&gt;方法&lt;/h4&gt;通过监督对比学习（SCL）的理论梯度分析，识别了这些潜在问题，并提出了ACL算法。&lt;h4&gt;主要发现&lt;/h4&gt;ACL算法在多个基准测试中表现出强大的性能，并通过在长尾CIFAR、ImageNet、Places和iNaturalist数据集上的实验验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;ACL实现了新的最先进性能。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we propose an Aligned Contrastive Learning (ACL) algorithm to address the long-tailed recognition problem. Our findings indicate that while multi-view training boosts the performance, contrastive learning does not consistently enhance model generalization as the number of views increases. Through theoretical gradient analysis of supervised contrastive learning (SCL), we identify gradient conflicts, and imbalanced attraction and repulsion gradients between positive and negative pairs as the underlying issues. Our ACL algorithm is designed to eliminate these problems and demonstrates strong performance across multiple benchmarks. We validate the effectiveness of ACL through experiments on long-tailed CIFAR, ImageNet, Places, and iNaturalist datasets. Results show that ACL achieves new state-of-the-art performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose an Aligned Contrastive Learning (ACL) algorithm toaddress the long-tailed recognition problem. Our findings indicate that whilemulti-view training boosts the performance, contrastive learning does notconsistently enhance model generalization as the number of views increases.Through theoretical gradient analysis of supervised contrastive learning (SCL),we identify gradient conflicts, and imbalanced attraction and repulsiongradients between positive and negative pairs as the underlying issues. Our ACLalgorithm is designed to eliminate these problems and demonstrates strongperformance across multiple benchmarks. We validate the effectiveness of ACLthrough experiments on long-tailed CIFAR, ImageNet, Places, and iNaturalistdatasets. Results show that ACL achieves new state-of-the-art performance.</description>
      <author>example@mail.com (Jiali Ma, Jiequan Cui, Maeno Kazuki, Lakshmi Subramanian, Karlekar Jayashree, Sugiri Pranata, Hanwang Zhang)</author>
      <guid isPermaLink="false">2506.01071v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>SurgVLM: A Large Vision-Language Model and Systematic Evaluation Benchmark for Surgical Intelligence</title>
      <link>http://arxiv.org/abs/2506.02555v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为SurgVLM的大规模视觉语言基础模型，用于手术智能，旨在解决手术领域智能应用不足的问题。&lt;h4&gt;背景&lt;/h4&gt;现有通用视觉语言模型在手术领域的应用不足，主要原因是缺乏特定领域的监督和高质量的大型手术数据库。&lt;h4&gt;目的&lt;/h4&gt;构建一个能够处理各种手术任务的视觉语言基础模型，并评估其在手术领域的性能。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含超过1.81百万帧图像和7.79百万对话的大规模多模态手术数据库SurgVLM-DB，并基于Qwen2.5-VL构建了SurgVLM模型。对模型进行指令微调，并构建了SurgVLM-Bench基准进行方法评估。&lt;h4&gt;主要发现&lt;/h4&gt;SurgVLM-Bench包含了6个广泛使用的手术领域数据集，覆盖了多个关键下游任务。SurgVLM在不同规模的模型中均表现出良好的性能，并与14个主流的商业视觉语言模型进行了比较。&lt;h4&gt;结论&lt;/h4&gt;SurgVLM在手术领域智能应用中具有潜力，为手术智能的发展提供了新的思路和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have achieved transformative success across biomedicaldomains by enabling holistic understanding of multimodal data. However, theirapplication in surgery remains underexplored. Surgical intelligence presentsunique challenges - requiring surgical visual perception, temporal analysis,and reasoning. Existing general-purpose vision-language models fail to addressthese needs due to insufficient domain-specific supervision and the lack of alarge-scale high-quality surgical database. To bridge this gap, we proposeSurgVLM, one of the first large vision-language foundation models for surgicalintelligence, where this single universal model can tackle versatile surgicaltasks. To enable this, we construct a large-scale multimodal surgical database,SurgVLM-DB, comprising over 1.81 million frames with 7.79 millionconversations, spanning more than 16 surgical types and 18 anatomicalstructures. We unify and reorganize 23 public datasets across 10 surgicaltasks, followed by standardizing labels and doing hierarchical vision-languagealignment to facilitate comprehensive coverage of gradually finer-grainedsurgical tasks, from visual perception, temporal analysis, to high-levelreasoning. Building upon this comprehensive dataset, we propose SurgVLM, whichis built upon Qwen2.5-VL, and undergoes instruction tuning to 10+ surgicaltasks. We further construct a surgical multimodal benchmark, SurgVLM-Bench, formethod evaluation. SurgVLM-Bench consists of 6 popular and widely-used datasetsin surgical domain, covering several crucial downstream tasks. Based onSurgVLM-Bench, we evaluate the performance of our SurgVLM (3 SurgVLM variants:SurgVLM-7B, SurgVLM-32B, and SurgVLM-72B), and conduct comprehensivecomparisons with 14 mainstream commercial VLMs (e.g., GPT-4o, Gemini 2.0 Flash,Qwen2.5-Max).</description>
      <author>example@mail.com (Zhitao Zeng, Zhu Zhuo, Xiaojun Jia, Erli Zhang, Junde Wu, Jiaan Zhang, Yuxuan Wang, Chang Han Low, Jian Jiang, Zilong Zheng, Xiaochun Cao, Yutong Ban, Qi Dou, Yang Liu, Yueming Jin)</author>
      <guid isPermaLink="false">2506.02555v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering</title>
      <link>http://arxiv.org/abs/2506.01174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025 Workshop on 3D-LLM/VLA: Bridging Language, Vision and  Action in 3D Environments&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GraphPad的动态结构化记忆系统，该系统帮助智能体通过API调用调整其任务需求，以提高在场景和任务理解上的表现。&lt;h4&gt;背景&lt;/h4&gt;结构化场景表示是具身智能体的核心组成部分，但在任务规格改变时，传统的预建结构化表示方法可能不足以捕捉关键信息。&lt;h4&gt;目的&lt;/h4&gt;设计GraphPad，以便智能体能够根据任务需求动态调整其结构化记忆。&lt;h4&gt;方法&lt;/h4&gt;GraphPad包含一个可变场景图、一个导航日志和任务特定笔记的草稿板。这些组件共同构成一个动态的工作空间，帮助智能体在场景和任务理解上保持同步。&lt;h4&gt;主要发现&lt;/h4&gt;在OpenEQA基准测试中，GraphPad实现了55.3%的准确率，比使用相同视觉语言模型和仅图像的基线提高了3.0%，且输入帧数减少了五倍。&lt;h4&gt;结论&lt;/h4&gt;GraphPad允许通过在线语言驱动的3D记忆细化，能够在不额外训练或收集数据的情况下提供更具信息量的表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Structured scene representations are a core component of embodied agents,helping to consolidate raw sensory streams into readable, modular, andsearchable formats. Due to their high computational overhead, many approachesbuild such representations in advance of the task. However, when the taskspecifications change, such static approaches become inadequate as they maymiss key objects, spatial relations, and details. We introduce GraphPad, amodifiable structured memory that an agent can tailor to the needs of the taskthrough API calls. It comprises a mutable scene graph representing theenvironment, a navigation log indexing frame-by-frame content, and a scratchpadfor task-specific notes. Together, GraphPad serves as a dynamic workspace thatremains complete, current, and aligned with the agent's immediate understandingof the scene and its task. On the OpenEQA benchmark, GraphPad attains 55.3%, a+3.0% increase over an image-only baseline using the same vision-languagemodel, while operating with five times fewer input frames. These results showthat allowing online, language-driven refinement of 3-D memory yields moreinformative representations without extra training or data collection.</description>
      <author>example@mail.com (Muhammad Qasim Ali, Saeejith Nair, Alexander Wong, Yuchen Cui, Yuhao Chen)</author>
      <guid isPermaLink="false">2506.01174v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025</title>
      <link>http://arxiv.org/abs/2506.02550v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The champion solution for the Ego4D Long-Term Action Anticipation  Challenge at the CVPR EgoVis Workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于Ego4D长期动作预测（LTA）任务的新型三阶段框架。&lt;h4&gt;背景&lt;/h4&gt;受到近期基础模型进展的启发。&lt;h4&gt;目的&lt;/h4&gt;实现长期动作预测。&lt;h4&gt;方法&lt;/h4&gt;包括特征提取、动作识别和长期动作预测三个阶段。使用高性能视觉编码器提取视觉特征，通过Transformer预测动词和名词，并利用动词-名词共现矩阵提高识别准确率。最后，将预测的动词-名词对格式化为文本提示，输入到微调的大型语言模型（LLM）中预测未来动作序列。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在CVPR 2025挑战赛中排名第一，在长期动作预测方面建立了新的基准。&lt;h4&gt;结论&lt;/h4&gt;该框架实现了长期动作预测的新突破。&lt;h4&gt;翻译&lt;/h4&gt;在本报告中，我们提出了一种用于Ego4D长期动作预测（LTA）任务的新型三阶段框架。受近期基础模型进展的启发，我们的方法包括三个阶段：特征提取、动作识别和长期动作预测。首先，使用高性能视觉编码器提取视觉特征。然后，将这些特征输入到Transformer中预测动词和名词，并引入动词-名词共现矩阵以增强识别准确性。最后，将预测的动词-名词对格式化为文本提示，输入到微调的大型语言模型（LLM）中以预测未来的动作序列。我们的框架在CVPR 2025挑战赛中排名第一，在长期动作预测方面建立了新的基准。我们的代码将在https://github.com/CorrineQiu/Ego4D-LTA-Challenge-2025上发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this report, we present a novel three-stage framework developed for theEgo4D Long-Term Action Anticipation (LTA) task. Inspired by recent advances infoundation models, our method consists of three stages: feature extraction,action recognition, and long-term action anticipation. First, visual featuresare extracted using a high-performance visual encoder. The features are thenfed into a Transformer to predict verbs and nouns, with a verb-nounco-occurrence matrix incorporated to enhance recognition accuracy. Finally, thepredicted verb-noun pairs are formatted as textual prompts and input into afine-tuned large language model (LLM) to anticipate future action sequences.Our framework achieves first place in this challenge at CVPR 2025, establishinga new state-of-the-art in long-term action prediction. Our code will bereleased at https://github.com/CorrineQiu/Ego4D-LTA-Challenge-2025.</description>
      <author>example@mail.com (Qiaohui Chu, Haoyu Zhang, Yisen Feng, Meng Liu, Weili Guan, Yaowei Wang, Liqiang Nie)</author>
      <guid isPermaLink="false">2506.02550v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Slow Feature Analysis on Markov Chains from Goal-Directed Behavior</title>
      <link>http://arxiv.org/abs/2506.01145v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;慢特征分析是一种无监督表示学习方法，可以从时间数据中提取缓慢变化的特征，并可用于后续的强化学习。&lt;h4&gt;背景&lt;/h4&gt;通常假设用于学习表示的数据生成行为是一个均匀的随机游走，而较少研究关注使用目标导向行为生成的样本来学习表示。&lt;h4&gt;目的&lt;/h4&gt;通过最优慢特征在遍历马尔可夫链的视角，研究这些差异对理想化设置中的价值函数逼近的影响。&lt;h4&gt;方法&lt;/h4&gt;评估和讨论了三种可能减轻有害缩放效应的校正途径，并考虑了目标回避行为这一特殊情况。&lt;h4&gt;主要发现&lt;/h4&gt;研究揭示了目标导向行为对价值函数逼近的影响，并提出了三种校正方法。&lt;h4&gt;结论&lt;/h4&gt;慢特征分析在强化学习中的适用性，以及通过校正方法来改善价值函数逼近的效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：慢特征分析是一种无监督的表示学习方法，可以从时间数据中提取缓慢变化的特征，并且可以用于后续的强化学习。通常，用于学习表示的数据生成行为假设为一个均匀的随机游走。在强化学习环境中，较少的研究集中在使用目标导向行为生成的样本来学习表示。在空间设置中，目标导向行为通常会导致接近奖励位置和远离奖励位置的状态之间的状态占用显著差异。通过最优慢特征在遍历马尔可夫链的视角，这项工作研究了这些差异对理想化设置中的价值函数逼近的影响。此外，评估和讨论了三种可能缓解有害缩放效应的校正途径。此外，还考虑了目标回避行为这一特殊情况。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Slow Feature Analysis is a unsupervised representation learning method thatextracts slowly varying features from temporal data and can be used as a basisfor subsequent reinforcement learning. Often, the behavior that generates thedata on which the representation is learned is assumed to be a uniform randomwalk. Less research has focused on using samples generated by goal-directedbehavior, as commonly the case in a reinforcement learning setting, to learn arepresentation. In a spatial setting, goal-directed behavior typically leads tosignificant differences in state occupancy between states that are close to areward location and far from a reward location.  Through the perspective of optimal slow features on ergodic Markov chains,this work investigates the effects of these differences on value-functionapproximation in an idealized setting. Furthermore, three correction routes,which can potentially alleviate detrimental scaling effects, are evaluated anddiscussed. In addition, the special case of goal-averse behavior is considered.</description>
      <author>example@mail.com (Merlin Schüler, Eddie Seabrook, Laurenz Wiskott)</author>
      <guid isPermaLink="false">2506.01145v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>ECP-Mamba: An Efficient Multi-scale Self-supervised Contrastive Learning Method with State Space Model for PolSAR Image Classification</title>
      <link>http://arxiv.org/abs/2506.01040v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ECP-Mamba的高效PolSAR图像分类框架，该框架结合了多尺度自监督对比学习和状态空间模型（SSM）骨干网络，解决了现有方法依赖大量标注数据和Transformer架构计算效率低的问题。&lt;h4&gt;背景&lt;/h4&gt;目前基于深度学习的PolSAR图像分类方法存在依赖大量标注数据和Transformer架构计算效率低的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效、资源消耗低的PolSAR图像分类方法。&lt;h4&gt;方法&lt;/h4&gt;ECP-Mamba通过多尺度预测预训练任务来解决标注数据稀缺的问题，并使用简化自蒸馏范式。此外，通过设计螺旋扫描策略，优化了Mamba架构（一种选择性的SSM）的计算效率，并提出了轻量级的Cross Mamba模块以促进多尺度特征之间的互补性。&lt;h4&gt;主要发现&lt;/h4&gt;ECP-Mamba在四个基准数据集上进行了广泛的实验，证明了其在平衡高精度与资源效率方面的有效性。在Flevoland 1989数据集上，ECP-Mamba实现了99.70%的整体准确率、99.64%的平均准确率和0.9962的Kappa系数。&lt;h4&gt;结论&lt;/h4&gt;ECP-Mamba是一种有效的PolSAR图像分类方法，能够平衡高精度和资源效率。&lt;h4&gt;翻译&lt;/h4&gt;Recently, polarimetric synthetic aperture radar (PolSAR) image classification has been greatly promoted by deep neural networks. However, current deep learning-based PolSAR classification methods encounter difficulties due to its dependence on extensive labeled data and the computational inefficiency of architectures like Transformers. This paper presents ECP-Mamba, an efficient framework integrating multi-scale self-supervised contrastive learning with a state space model (SSM) backbone. Specifically, ECP-Mamba addresses annotations scarcity through a multi-scale predictive pretext task based on local-to-global feature correspondences, which uses a simplified self-distillation paradigm without negative sample pairs. To enhance computational efficiency, the Mamba architecture (a selective SSM) is first tailored for pixel-wise PolSAR classification task by designing a spiral scan strategy. This strategy prioritizes causally relevant features near the central pixel, leveraging the localized nature of pixel-wise classification tasks. Additionally, the lightweight Cross Mamba module is proposed to facilitate complementary multi-scale feature interaction with minimal overhead. Extensive experiments across four benchmark datasets demonstrate ECP-Mamba's effectiveness in balancing high accuracy with resource efficiency. On the Flevoland 1989 dataset, ECP-Mamba achieves state-of-the-art performance with an overall accuracy of 99.70%, average accuracy of 99.64% and Kappa coefficient of 99.62e-2. Our code will be available at https://github.com/HaixiaBi1982/ECP_Mamba.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, polarimetric synthetic aperture radar (PolSAR) image classificationhas been greatly promoted by deep neural networks. However,current deeplearning-based PolSAR classification methods encounter difficulties due to itsdependence on extensive labeled data and the computational inefficiency ofarchitectures like Transformers. This paper presents ECP-Mamba, an efficientframework integrating multi-scale self-supervised contrastive learning with astate space model (SSM) backbone. Specifically, ECP-Mamba addresses annotationscarcity through a multi-scale predictive pretext task based on local-to-globalfeature correspondences, which uses a simplified self-distillation paradigmwithout negative sample pairs. To enhance computational efficiency,the Mambaarchitecture (a selective SSM) is first tailored for pixel-wise PolSARclassification task by designing a spiral scan strategy. This strategyprioritizes causally relevant features near the central pixel, leveraging thelocalized nature of pixel-wise classification tasks. Additionally, thelightweight Cross Mamba module is proposed to facilitates complementarymulti-scale feature interaction with minimal overhead. Extensive experimentsacross four benchmark datasets demonstrate ECP-Mamba's effectiveness inbalancing high accuracy with resource efficiency. On the Flevoland 1989dataset, ECP-Mamba achieves state-of-the-art performance with an overallaccuracy of 99.70%, average accuracy of 99.64% and Kappa coefficient of99.62e-2. Our code will be available athttps://github.com/HaixiaBi1982/ECP_Mamba.</description>
      <author>example@mail.com (Zuzheng Kuang, Haixia Bi, Chen Xu, Jian Sun)</author>
      <guid isPermaLink="false">2506.01040v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Towards Efficient Few-shot Graph Neural Architecture Search via Partitioning Gradient Contribution</title>
      <link>http://arxiv.org/abs/2506.01231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGKDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对权重耦合问题，提出了一种新的方法，即Gradient Contribution（GC）方法，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;某些研究引入了少样本神经架构搜索（NAS）方法来解决权重耦合问题，但这些方法通常计算效率低，且提供的分区方案不理想。&lt;h4&gt;目的&lt;/h4&gt;为了更有效地解决这个问题，本文从新的角度分析了权重耦合问题，并提出了GC方法以及Unified Graph Neural Architecture Search（UGAS）框架。&lt;h4&gt;方法&lt;/h4&gt;GC方法通过分解超网络反向传播过程中的向量-雅可比乘积，高效地计算模块间梯度方向的余弦相似度，并根据这些相似度将具有冲突梯度方向的模块分配到不同的子超网络中，相似模块则分组在一起。UGAS框架则探索了MPNN和GT的最佳组合。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，GC在超网络分区质量和时间效率方面达到了最先进（SOTA）的性能。此外，UGAS+GC搜索的架构优于手动设计的GNN和现有NAS方法搜索到的架构。&lt;h4&gt;结论&lt;/h4&gt;通过消融研究进一步证明了所有提出方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;为了解决权重耦合问题，本文从新颖的角度分析了这一问题，并提出了Gradient Contribution（GC）方法。该方法通过分解向量-雅可比乘积，高效地计算模块间梯度方向的余弦相似度，并基于此将具有冲突梯度方向的模块分配到不同的子超网络中，相似模块则分组在一起。此外，本文还提出了Unified Graph Neural Architecture Search（UGAS）框架，该框架探索了MPNN和GT的最佳组合。实验结果表明，GC在超网络分区质量和时间效率方面达到了最先进的性能，且UGAS+GC搜索的架构优于手动设计的GNN和现有NAS方法搜索到的架构。消融研究进一步证明了所有提出方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To address the weight coupling problem, certain studies introduced few-shotNeural Architecture Search (NAS) methods, which partition the supernet intomultiple sub-supernets. However, these methods often suffer from computationalinefficiency and tend to provide suboptimal partitioning schemes. To addressthis problem more effectively, we analyze the weight coupling problem from anovel perspective, which primarily stems from distinct modules in succeedinglayers imposing conflicting gradient directions on the preceding layer modules.Based on this perspective, we propose the Gradient Contribution (GC) methodthat efficiently computes the cosine similarity of gradient directions amongmodules by decomposing the Vector-Jacobian Product during supernetbackpropagation. Subsequently, the modules with conflicting gradient directionsare allocated to distinct sub-supernets while similar ones are groupedtogether. To assess the advantages of GC and address the limitations ofexisting Graph Neural Architecture Search methods, which are limited tosearching a single type of Graph Neural Networks (Message Passing NeuralNetworks (MPNNs) or Graph Transformers (GTs)), we propose the Unified GraphNeural Architecture Search (UGAS) framework, which explores optimalcombinations of MPNNs and GTs. The experimental results demonstrate that GCachieves state-of-the-art (SOTA) performance in supernet partitioning qualityand time efficiency. In addition, the architectures searched by UGAS+GCoutperform both the manually designed GNNs and those obtained by existing NASmethods. Finally, ablation studies further demonstrate the effectiveness of allproposed methods.</description>
      <author>example@mail.com (Wenhao Song, Xuan Wu, Bo Yang, You Zhou, Yubin Xiao, Yanchun Liang, Hongwei Ge, Heow Pueh Lee, Chunguo Wu)</author>
      <guid isPermaLink="false">2506.01231v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Bot Detection via Heterophily-Aware Representation Learning and Prototype-Guided Cluster Discovery</title>
      <link>http://arxiv.org/abs/2506.00989v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;BotHP是一种基于生成图自监督学习（GSL）的框架，旨在通过异质性感知表示学习和原型引导的聚类发现来提升图基社交机器人检测器的性能。&lt;h4&gt;背景&lt;/h4&gt;当前图基检测方法在社交机器人检测中表现出色，但受限于标签依赖和跨不同社区的低泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出BotHP框架，以克服标签依赖和泛化能力不足的问题。&lt;h4&gt;方法&lt;/h4&gt;BotHP采用双重编码器架构，包括一个图感知编码器来捕捉节点共同性，和一个图无关编码器来保留节点独特性。此外，还引入了原型引导的聚类发现前缀任务来模拟机器人集群的潜在全局一致性。&lt;h4&gt;主要发现&lt;/h4&gt;BotHP能够同时建模同质性和异质性，有效对抗交互伪装问题，并通过原型引导的聚类发现识别空间分散但语义对齐的机器人集体。&lt;h4&gt;结论&lt;/h4&gt;在两个真实世界机器人检测基准测试上的实验表明，BotHP能够持续提升基于图的机器人检测器的性能，提高检测准确性，减轻对标签的依赖，并增强泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：检测社交媒体机器人对于维护社交网络的安全性和可信度至关重要。尽管当代基于图的检测方法显示出有希望的结果，但它们的实际应用受到标签依赖和跨不同社区泛化能力差的限制。生成图自监督学习（GSL）提供了一个克服这些限制的有希望的方法论，但现有的方法主要遵循同质性假设，未能捕捉图中的全局模式，这可能在面对机器人检测场景中的交互伪装和分布式部署挑战时降低其有效性。为此，我们提出了BotHP，这是一种针对通过异质性感知表示学习和原型引导的聚类发现来增强图基机器人检测器性能的生成GSL框架。具体来说，BotHP利用一个双重编码器架构，包括一个图感知编码器来捕捉节点共同性，和一个图无关编码器来保留节点独特性。这允许同时建模同质性和异质性，有效对抗交互伪装问题。此外，BotHP还引入了一个原型引导的聚类发现前缀任务来模拟机器人集群的潜在全局一致性，并识别空间分散但语义对齐的机器人集体。在两个真实世界机器人检测基准测试上的大量实验表明，BotHP能够持续提升基于图的机器人检测器的性能，提高检测性能，减轻对标签的依赖，并增强泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting social media bots is essential for maintaining the security andtrustworthiness of social networks. While contemporary graph-based detectionmethods demonstrate promising results, their practical application is limitedby label reliance and poor generalization capability across diversecommunities. Generative Graph Self-Supervised Learning (GSL) presents apromising paradigm to overcome these limitations, yet existing approachespredominantly follow the homophily assumption and fail to capture the globalpatterns in the graph, which potentially diminishes their effectiveness whenfacing the challenges of interaction camouflage and distributed deployment inbot detection scenarios. To this end, we propose BotHP, a generative GSLframework tailored to boost graph-based bot detectors through heterophily-awarerepresentation learning and prototype-guided cluster discovery. Specifically,BotHP leverages a dual-encoder architecture, consisting of a graph-awareencoder to capture node commonality and a graph-agnostic encoder to preservenode uniqueness. This enables the simultaneous modeling of both homophily andheterophily, effectively countering the interaction camouflage issue.Additionally, BotHP incorporates a prototype-guided cluster discovery pretexttask to model the latent global consistency of bot clusters and identifyspatially dispersed yet semantically aligned bot collectives. Extensiveexperiments on two real-world bot detection benchmarks demonstrate that BotHPconsistently boosts graph-based bot detectors, improving detection performance,alleviating label reliance, and enhancing generalization capability.</description>
      <author>example@mail.com (Buyun He, Xiaorui Jiang, Qi Wu, Hao Liu, Yingguang Yang, Yong Liao)</author>
      <guid isPermaLink="false">2506.00989v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution</title>
      <link>http://arxiv.org/abs/2506.01037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 10 figures, accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于自我监督学习和Mamba的噪声鲁棒现实世界视频超分辨率（VSR）框架，通过结合全局时空注意力机制和自监督ControlNet，提高了生成的视频质量。&lt;h4&gt;背景&lt;/h4&gt;现有的基于扩散的视频超分辨率方法由于固有的随机性，容易在高清视频中引入复杂的退化并产生明显的伪影。&lt;h4&gt;目的&lt;/h4&gt;提出一种噪声鲁棒的VSR框架，以减少在高分辨率视频中的伪影和退化。&lt;h4&gt;方法&lt;/h4&gt;1. 使用自我监督学习和Mamba改进预训练的潜在扩散模型。2. 通过VideoState-Space块和3D选择性扫描模块增强扩散模型，以确保相邻帧之间的内容一致性。3. 引入自监督ControlNet，利用HR特征作为指导，并采用对比学习从LR视频中提取退化不敏感的特征。4. 提出基于HR-LR视频混合的三阶段训练策略以稳定VSR训练。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的自监督ControlNet与时空连续Mamba的VSR算法在现实世界VSR基准数据集上实现了优于现有技术的感知质量。&lt;h4&gt;结论&lt;/h4&gt;验证了所提出的模型设计和训练策略的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing diffusion-based video super-resolution (VSR) methods are susceptibleto introducing complex degradations and noticeable artifacts intohigh-resolution videos due to their inherent randomness. In this paper, wepropose a noise-robust real-world VSR framework by incorporatingself-supervised learning and Mamba into pre-trained latent diffusion models. Toensure content consistency across adjacent frames, we enhance the diffusionmodel with a global spatio-temporal attention mechanism using the VideoState-Space block with a 3D Selective Scan module, which reinforces coherenceat an affordable computational cost. To further reduce artifacts in generateddetails, we introduce a self-supervised ControlNet that leverages HR featuresas guidance and employs contrastive learning to extract degradation-insensitivefeatures from LR videos. Finally, a three-stage training strategy based on amixture of HR-LR videos is proposed to stabilize VSR training. The proposedSelf-supervised ControlNet with Spatio-Temporal Continuous Mamba based VSRalgorithm achieves superior perceptual quality than state-of-the-arts onreal-world VSR benchmark datasets, validating the effectiveness of the proposedmodel design and training strategies.</description>
      <author>example@mail.com (Shijun Shi, Jing Xu, Lijing Lu, Zhihang Li, Kai Hu)</author>
      <guid isPermaLink="false">2506.01037v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Advancing from Automated to Autonomous Beamline by Leveraging Computer Vision</title>
      <link>http://arxiv.org/abs/2506.00836v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个基于计算机视觉的系统，旨在实现同步辐射光束线的自主操作，以提高实验的自动化、可靠性和安全性。&lt;h4&gt;背景&lt;/h4&gt;同步辐射光源是高端大型用户设施，需要自主的同步辐射光束线操作，但当前最先进的同步辐射光束线仍高度依赖人工安全监管。&lt;h4&gt;目的&lt;/h4&gt;实现实验的自动化、可靠性和安全性，减少人工干预。&lt;h4&gt;方法&lt;/h4&gt;开发了一个基于计算机视觉的系统，结合深度学习和多视图相机进行实时碰撞检测。系统利用设备分割、跟踪和几何分析进行潜在碰撞评估，并通过迁移学习增强鲁棒性。此外，还开发了一个交互式注释模块，以提高对新物体类别的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;在真实光束线数据集上的实验表明，该系统具有高精度、实时性能和强大的自主同步辐射光束线操作潜力。&lt;h4&gt;结论&lt;/h4&gt;该系统为实现同步辐射光束线的自主操作提供了有效途径，有望提高实验的自动化水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The synchrotron light source, a cutting-edge large-scale user facility,requires autonomous synchrotron beamline operations, a crucial technique thatshould enable experiments to be conducted automatically, reliably, and safelywith minimum human intervention. However, current state-of-the-art synchrotronbeamlines still heavily rely on human safety oversight. To bridge the gapbetween automated and autonomous operation, a computer vision-based system isproposed, integrating deep learning and multiview cameras for real-timecollision detection. The system utilizes equipment segmentation, tracking, andgeometric analysis to assess potential collisions with transfer learning thatenhances robustness. In addition, an interactive annotation module has beendeveloped to improve the adaptability to new object classes. Experiments on areal beamline dataset demonstrate high accuracy, real-time performance, andstrong potential for autonomous synchrotron beamline operations.</description>
      <author>example@mail.com (Baolu Li, Hongkai Yu, Huiming Sun, Jin Ma, Yuewei Lin, Lu Ma, Yonghua Du)</author>
      <guid isPermaLink="false">2506.00836v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Keystep Recognition using Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.01102v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种灵活的图学习框架GLEVR，用于细粒度按键识别，能够有效利用自拍摄像头视频中的长期依赖关系。&lt;h4&gt;背景&lt;/h4&gt;将按键识别视为节点分类任务，并针对自拍摄像头视频中的按键识别问题进行研究。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效利用长期依赖关系的按键识别方法，并构建一个计算高效、性能优异的模型。&lt;h4&gt;方法&lt;/h4&gt;构建一个图，其中每个自拍摄像头视频片段对应一个节点，并利用内外部视频的对应关系进行训练，同时增加自动字幕作为额外模态，考虑外部视频片段或字幕作为额外的节点，并定义节点间连接的策略。&lt;h4&gt;主要发现&lt;/h4&gt;在Ego-Exo4D数据集上进行了广泛实验，证明了所提出的基于图的灵活框架在性能上显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;GLEVR框架在按键识别任务中表现出色，为自拍摄像头视频的按键识别提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We pose keystep recognition as a node classification task, and propose aflexible graph-learning framework for fine-grained keystep recognition that isable to effectively leverage long-term dependencies in egocentric videos. Ourapproach, termed GLEVR, consists of constructing a graph where each video clipof the egocentric video corresponds to a node. The constructed graphs aresparse and computationally efficient, outperforming existing larger modelssubstantially. We further leverage alignment between egocentric and exocentricvideos during training for improved inference on egocentric videos, as well asadding automatic captioning as an additional modality. We consider each clip ofeach exocentric video (if available) or video captions as additional nodesduring training. We examine several strategies to define connections acrossthese nodes. We perform extensive experiments on the Ego-Exo4D dataset and showthat our proposed flexible graph-based framework notably outperforms existingmethods.</description>
      <author>example@mail.com (Julia Lee Romero, Kyle Min, Subarna Tripathi, Morteza Karimzadeh)</author>
      <guid isPermaLink="false">2506.01102v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>What do self-supervised speech models know about Dutch? Analyzing advantages of language-specific pre-training</title>
      <link>http://arxiv.org/abs/2506.00981v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Interspeech 2025. For model, code, and materials, see  https://github.com/mdhk/SSL-NL-eval&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了自监督模型学习的语音表示的语言特异性，发现专门在荷兰语上预训练的模型在表示荷兰语语言特征方面优于使用相同数量的英语或更多多语言数据的模型。&lt;h4&gt;背景&lt;/h4&gt;已有研究表明，从仅使用语音记录训练的端到端模型中可以成功解码一系列语言特征，但对于在特定语言上预训练是否提高了语言特定的语言信息，了解不多。&lt;h4&gt;目的&lt;/h4&gt;测试自监督Wav2Vec2模型内部表示中荷兰语音和词汇信息的编码。&lt;h4&gt;方法&lt;/h4&gt;比较了专门在荷兰语上预训练、在相同数量的英语上预训练以及在更多多语言数据上预训练的模型的表现。&lt;h4&gt;主要发现&lt;/h4&gt;专门在荷兰语上预训练的模型在表示荷兰语语言特征方面表现优于其他两种预训练方法，这种语言特定的优势可以通过训练的聚类或分类探针检测到，并且部分可以通过零样本指标观察到。&lt;h4&gt;结论&lt;/h4&gt;语言特定的语言特征编码优势与自动语音识别任务中的下游性能相一致。&lt;h4&gt;翻译&lt;/h4&gt;摘要：自监督模型学习的语音表示的语言特异性如何？已有研究显示，可以从仅用语音记录训练的端到端模型中成功解码一系列语言特征。然而，对于在特定语言上预训练是否提高了语言特定的语言信息，了解不多。在本研究中，我们测试了自监督Wav2Vec2模型内部表示中荷兰语音和词汇信息的编码。仅使用荷兰语预训练可以比使用相同数量的英语或更多多语言数据预训练更好地表示荷兰语语言特征。这种语言特定的优势可以通过训练的聚类或分类探针很好地检测到，并且部分可以通过零样本指标观察到。此外，语言特定的语言特征编码优势与自动语音识别任务中的下游性能相一致。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.21437/Interspeech.2025-1526&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; How language-specific are speech representations learned by self-supervisedmodels? Existing work has shown that a range of linguistic features can besuccessfully decoded from end-to-end models trained only on speech recordings.However, it's less clear to what extent pre-training on specific languagesimproves language-specific linguistic information. Here we test the encoding ofDutch phonetic and lexical information in internal representations ofself-supervised Wav2Vec2 models. Pre-training exclusively on Dutch improves therepresentation of Dutch linguistic features as compared to pre-training onsimilar amounts of English or larger amounts of multilingual data. Thislanguage-specific advantage is well-detected by trained clustering orclassification probes, and partially observable using zero-shot metrics.Furthermore, the language-specific benefit on linguistic feature encodingaligns with downstream performance on Automatic Speech Recognition.</description>
      <author>example@mail.com (Marianne de Heer Kloots, Hosein Mohebbi, Charlotte Pouw, Gaofei Shen, Willem Zuidema, Martijn Bentum)</author>
      <guid isPermaLink="false">2506.00981v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>AuralSAM2: Enabling SAM2 Hear Through Pyramid Audio-Visual Feature Prompting</title>
      <link>http://arxiv.org/abs/2506.01015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 18 Figures and 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SAM2在视频剪辑的promptable segmentation方面表现出强大的泛化能力，但其与音频模态的集成尚待探索。&lt;h4&gt;背景&lt;/h4&gt;现有的方法主要分为两类：一是将适配器注入图像编码器以接收音频信号，这在prompt engineering过程中会降低效率；二是利用额外的基础模型生成视觉提示，但这些提示往往定位不准确，导致SAM2的误导。&lt;h4&gt;目的&lt;/h4&gt;提出AuralSAM2，包含新颖的AuralFuser模块，该模块外部连接到SAM2，以集成不同模态的特征并生成特征级提示，引导SAM2的解码器进行声音目标的分割。&lt;h4&gt;方法&lt;/h4&gt;通过特征金字塔实现集成，进一步细化语义理解和增强多模态场景中的物体意识。此外，引入音频引导的对比学习，以显式地对齐音频和视觉表示，并减轻由主导视觉模式引起的偏差。&lt;h4&gt;主要发现&lt;/h4&gt;在公共基准测试中，该方法在性能上显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;AuralSAM2通过改进的模态融合和对比学习方法，实现了对SAM2在音频-视觉分割任务上的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;Segment Anything Model 2 (SAM2) 在视频剪辑的提示式分割方面表现出强大的泛化能力；然而，其与音频模态的集成尚未得到充分探索。现有的方法主要遵循两个方向：（1）将适配器注入图像编码器以接收音频信号，这在提示工程过程中会降低效率；（2）利用额外的基础模型为声音对象生成视觉提示，但这些提示通常定位不准确，导致SAM2的误导。此外，这些方法忽视了层次化视觉特征与其他模态之间丰富的语义互动，导致跨模态融合效果不佳。在本研究中，我们提出了AuralSAM2，包括新颖的AuralFuser模块，该模块外部连接到SAM2，以集成来自不同模态的特征并生成特征级提示，引导SAM2的解码器进行声音目标的分割。这种集成是通过特征金字塔实现的，进一步细化语义理解并增强多模态场景中的物体意识。此外，引入了音频引导的对比学习，以显式地对齐音频和视觉表示，并减轻由主导视觉模式引起的偏差。在公共基准测试中的结果表明，我们的方法在性能上显著优于现有方法。代码可在https://github.com/yyliu01/AuralSAM2上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Segment Anything Model 2 (SAM2) exhibits strong generalisation for promptablesegmentation in video clips; however, its integration with the audio modalityremains underexplored. Existing approaches mainly follow two directions: (1)injecting adapters into the image encoder to receive audio signals, whichincurs efficiency costs during prompt engineering, and (2) leveragingadditional foundation models to generate visual prompts for the soundingobjects, which are often imprecisely localised, leading to misguidance in SAM2.Moreover, these methods overlook the rich semantic interplay betweenhierarchical visual features and other modalities, resulting in suboptimalcross-modal fusion. In this work, we propose AuralSAM2, comprising the novelAuralFuser module, which externally attaches to SAM2 to integrate features fromdifferent modalities and generate feature-level prompts, guiding SAM2's decoderin segmenting sounding targets. Such integration is facilitated by a featurepyramid, further refining semantic understanding and enhancing object awarenessin multimodal scenarios. Additionally, the audio-guided contrastive learning isintroduced to explicitly align audio and visual representations and to alsomitigate biases caused by dominant visual patterns. Results on publicbenchmarks show that our approach achieves remarkable improvements over theprevious methods in the field. Code is available athttps://github.com/yyliu01/AuralSAM2.</description>
      <author>example@mail.com (Yuyuan Liu, Yuanhong Chen, Chong Wang, Junlin Han, Junde Wu, Can Peng, Jingkun Chen, Yu Tian, Gustavo Carneiro)</author>
      <guid isPermaLink="false">2506.01015v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Multi-level and Multi-modal Action Anticipation</title>
      <link>http://arxiv.org/abs/2506.02382v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in 2025 IEEE International Conference on Image Processing  (ICIP)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Multi-level and Multi-modal Action Anticipation (m&amp;m-Ant)的新型多模态动作预测方法，该方法结合视觉和文本线索，并显式建模层次语义信息以提高预测准确性。&lt;h4&gt;背景&lt;/h4&gt;动作预测对于智能系统的发展至关重要，它需要处理部分观察到的视频中的不完全信息，并具备时间推理和不确定性处理的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效预测未来动作的方法，并通过结合多种信息源来提高预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;m&amp;m-Ant方法结合视觉和文本线索，并引入细粒度标签生成器与专门的时序一致性损失函数来优化性能。&lt;h4&gt;主要发现&lt;/h4&gt;在Breakfast、50 Salads和DARai等广泛使用的数据集上，该方法实现了最先进的预测准确率，平均提高了3.08%。&lt;h4&gt;结论&lt;/h4&gt;多模态和层次建模在动作预测领域具有巨大潜力，并为本领域未来的研究设立了一个新的基准。&lt;h4&gt;翻译&lt;/h4&gt;动作预测，即从部分观察到的视频中预测未来动作的任务，对于推进智能系统的发展至关重要。与在完全观察到的视频上运行的动作识别不同，动作预测必须处理不完整的信息，因此需要时间推理和内在的不确定性处理。虽然近年来取得了一些进展，但传统方法通常仅关注视觉模态，忽视了整合多种信息源的可能性。从人类行为中汲取灵感，我们引入了名为Multi-level and Multi-modal Action Anticipation (m&amp;m-Ant)的新颖多模态动作预测方法，该方法结合了视觉和文本线索，并显式地建模层次语义信息以实现更准确的预测。为了解决粗粒度动作标签不准确的问题，我们提出了一种细粒度标签生成器与专门的时序一致性损失函数相结合的方法来优化性能。在包括Breakfast、50 Salads和DARai在内的广泛使用的数据集上进行的广泛实验表明，我们的方法非常有效，与现有方法相比，平均预测准确率提高了3.08%。这项工作强调了多模态和层次建模在推进动作预测方面的潜力，并为该领域未来的研究建立了一个新的基准。我们的代码可在https://github.com/olivesgatech/mM-ant上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Action anticipation, the task of predicting future actions from partiallyobserved videos, is crucial for advancing intelligent systems. Unlike actionrecognition, which operates on fully observed videos, action anticipation musthandle incomplete information. Hence, it requires temporal reasoning, andinherent uncertainty handling. While recent advances have been made,traditional methods often focus solely on visual modalities, neglecting thepotential of integrating multiple sources of information. Drawing inspirationfrom human behavior, we introduce \textit{Multi-level and Multi-modal ActionAnticipation (m\&amp;m-Ant)}, a novel multi-modal action anticipation approach thatcombines both visual and textual cues, while explicitly modeling hierarchicalsemantic information for more accurate predictions. To address the challenge ofinaccurate coarse action labels, we propose a fine-grained label generatorpaired with a specialized temporal consistency loss function to optimizeperformance. Extensive experiments on widely used datasets, includingBreakfast, 50 Salads, and DARai, demonstrate the effectiveness of our approach,achieving state-of-the-art results with an average anticipation accuracyimprovement of 3.08\% over existing methods. This work underscores thepotential of multi-modal and hierarchical modeling in advancing actionanticipation and establishes a new benchmark for future research in the field.Our code is available at: https://github.com/olivesgatech/mM-ant.</description>
      <author>example@mail.com (Seulgi Kim, Ghazal Kaviani, Mohit Prabhushankar, Ghassan AlRegib)</author>
      <guid isPermaLink="false">2506.02382v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Getting More from Less: Transfer Learning Improves Sleep Stage Decoding Accuracy in Peripheral Wearable Devices</title>
      <link>http://arxiv.org/abs/2506.00730v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了迁移学习技术在睡眠阶段解码中的应用，通过利用预训练的神经网络模型，显著提高了从外围可穿戴设备中解码睡眠阶段准确率。&lt;h4&gt;背景&lt;/h4&gt;传统的消费级可穿戴设备依赖外围生理信号，如脉搏容积描记图（PPG）和呼吸数据，这些信号虽然方便但缺乏临床脑电图（EEG）的精确性。&lt;h4&gt;目的&lt;/h4&gt;探索迁移学习如何增强睡眠阶段解码的准确性和实用性。&lt;h4&gt;方法&lt;/h4&gt;在大型公开EEG数据集上预训练了一个基于Transformer的神经网络模型，并在噪声较大的外围信号上微调了这个模型。&lt;h4&gt;主要发现&lt;/h4&gt;迁移学习将分类准确率从仅使用外围信号的基准模型的67.6%提高到了76.6%，特别是在REM和N1等较浅睡眠阶段，准确率得到了显著提升。&lt;h4&gt;结论&lt;/h4&gt;迁移学习可以显著提高消费级可穿戴设备的准确性，未来结合自监督学习方法可能进一步提高性能，为个性化健康应用提供更精确的纵向睡眠监测。&lt;h4&gt;翻译&lt;/h4&gt;摘要：迁移学习，一种在生成人工智能中常用的技术，允许神经网络模型在执行新任务时利用先验知识。本研究表明，通过利用在脑电图（EEG）信号上预训练的神经网络模型，迁移学习显著提高了从外围可穿戴设备中解码睡眠阶段的准确性。消费级可穿戴技术通常依赖于外围生理信号，如脉搏容积描记图（PPG）和呼吸数据，虽然方便，但缺乏临床脑电图（EEG）在详细睡眠阶段分类方面的精确度。我们在大型公开的EEG数据集上预训练了一个基于Transformer的神经网络模型，随后在噪声较大的外围信号上微调了这个模型。我们的迁移学习方法将整体分类准确率从仅基于外围信号的基准模型的67.6%提高到了76.6%。在睡眠阶段，特别是REM和N1等较浅睡眠阶段，观察到了显著的准确率提升。这些结果突出了迁移学习在显著提高消费级可穿戴设备的准确性和实用性方面的潜力，而无需改变现有硬件。未来自监督学习方法的集成可能进一步提升性能，便于为个性化健康应用提供更精确的纵向睡眠监测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning, a technique commonly used in generative artificialintelligence, allows neural network models to bring prior knowledge to bearwhen learning a new task. This study demonstrates that transfer learningsignificantly enhances the accuracy of sleep-stage decoding from peripheralwearable devices by leveraging neural network models pretrained onelectroencephalographic (EEG) signals. Consumer wearable technologies typicallyrely on peripheral physiological signals such as pulse plethysmography (PPG)and respiratory data, which, while convenient, lack the fidelity of clinicalelectroencephalography (EEG) for detailed sleep-stage classification. Wepretrained a transformer-based neural network on a large, publicly availableEEG dataset and subsequently fine-tuned this model on noisier peripheralsignals. Our transfer learning approach improved overall classificationaccuracy from 67.6\% (baseline model trained solely on peripheral signals) to76.6\%. Notable accuracy improvements were observed across sleep stages,particularly lighter sleep stages such as REM and N1. These results highlighttransfer learning's potential to substantially enhance the accuracy and utilityof consumer wearable devices without altering existing hardware. Futureintegration of self-supervised learning methods may further boost performance,facilitating more precise, longitudinal sleep monitoring for personalizedhealth applications.</description>
      <author>example@mail.com (William G Coon, Diego Luna, Akshita Panagrahi, Matthew Reid, Mattson Ogg)</author>
      <guid isPermaLink="false">2506.00730v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Generative AI for Predicting 2D and 3D Wildfire Spread: Beyond Physics-Based Models and Traditional Deep Learning</title>
      <link>http://arxiv.org/abs/2506.02485v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了利用生成式AI进行野火预测的潜力，并提出了将生成式AI集成到野火管理中的五个关键愿景和三个主要挑战。&lt;h4&gt;背景&lt;/h4&gt;全球野火给人类、环境和经济带来了巨大损失，需要更有效的应对策略。现有的物理模型和深度学习模型在实时预测和可视化多模态火势扩散方面存在限制。&lt;h4&gt;目的&lt;/h4&gt;倡导将生成式AI作为野火预测的基础框架，并探讨如何通过这些模型增强二维火势预测和实现更真实、可扩展的三维模拟。&lt;h4&gt;方法&lt;/h4&gt;采用大型语言模型进行自动知识提取、文献综合和文献计量映射，并探索将生成式AI应用于野火管理的不同方面。&lt;h4&gt;主要发现&lt;/h4&gt;生成式AI在整合多模态数据、生成不确定情况下的多样场景和改善时空尺度上的野火动力学建模方面具有优势。&lt;h4&gt;结论&lt;/h4&gt;提出了五个关键愿景（多模态方法、AI基础模型、对话式AI系统、基于边缘计算的情景生成和认知数字孪生）以及三个主要挑战和相应的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：野火继续在全球范围内造成严重的人类、环境和经济损失，正如2025年洛杉矶野火悲剧性地证明的那样，迫切需要更有效的应对策略。尽管基于物理的模型和深度学习模型在野火模拟方面取得了进展，但它们在预测和实时可视化多模态火势扩散方面面临关键限制，特别是在使用动态更新的GIS数据进行2D和3D空间域的模拟时。这些限制阻碍了及时的紧急响应、基础设施保护和社区安全。生成式AI最近在研究和工业界中作为一种变革性的方法出现。诸如生成对抗网络（GANs）、变分自编码器（VAEs）、Transformer和基于扩散的架构等模型，与传统方法相比具有独特的优势，包括整合多模态数据、在不确定性下生成多样场景以及改善时空尺度上的野火动力学建模。这篇立场论文主张采用生成式AI作为野火预测的基础框架。我们探讨了如何通过这些模型增强2D火势预测和实现更真实、可扩展的3D模拟。此外，我们采用了一种新颖的人机协作框架，使用大型语言模型（LLMs）进行自动知识提取、文献综合和文献计量映射。展望未来，我们确定了将生成式AI集成到野火管理中的五个关键愿景：多模态方法、AI基础模型、对话式AI系统、基于边缘计算的情景生成和认知数字孪生。我们还解决了伴随这些机会的三个主要挑战，并提出了支持其实施的潜在解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wildfires continue to inflict devastating human, environmental, and economiclosses globally, as tragically exemplified by the 2025 Los Angeles wildfire andthe urgent demand for more effective response strategies. While physics-basedand deep learning models have advanced wildfire simulation, they face criticallimitations in predicting and visualizing multimodal fire spread in real time,particularly in both 2D and 3D spatial domains using dynamically updated GISdata. These limitations hinder timely emergency response, infrastructureprotection, and community safety. Generative AI has recently emerged as atransformative approach across research and industry. Models such as GenerativeAdversarial Networks (GANs), Variational Autoencoders (VAEs), Transformers, anddiffusion-based architectures offer distinct advantages over traditionalmethods, including the integration of multimodal data, generation of diversescenarios under uncertainty, and improved modeling of wildfire dynamics acrossspatial and temporal scales. This position paper advocates for the adoption ofgenerative AI as a foundational framework for wildfire prediction. We explorehow such models can enhance 2D fire spread forecasting and enable morerealistic, scalable 3D simulations. Additionally, we employ a novel human-AIcollaboration framework using large language models (LLMs) for automatedknowledge extraction, literature synthesis, and bibliometric mapping. Lookingahead, we identify five key visions for integrating generative AI into wildfiremanagement: multimodal approaches, AI foundation models, conversational AIsystems, edge-computing-based scenario generation, and cognitive digital twins.We also address three major challenges accompanying these opportunities andpropose potential solutions to support their implementation.</description>
      <author>example@mail.com (Haowen Xu, Sisi Zlatanova, Ruiyu Liang, Ismet Canbulat)</author>
      <guid isPermaLink="false">2506.02485v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Regulatory Graphs and GenAI for Real-Time Transaction Monitoring and Compliance Explanation in Banking</title>
      <link>http://arxiv.org/abs/2506.01093v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种实时交易监控框架，该框架结合了基于图建模、叙事字段嵌入和生成解释，以支持自动化的金融合规。&lt;h4&gt;背景&lt;/h4&gt;在金融领域，自动化的交易监控和合规性检查对于防范风险和确保合规性至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够自动识别可疑交易行为并生成符合法规的解释的实时交易监控系统。&lt;h4&gt;方法&lt;/h4&gt;该系统构建动态交易图，提取结构和上下文特征，并使用图神经网络对可疑行为进行分类。检索增强生成模块为每个标记的交易生成与法规条款相符的自然语言解释。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟金融数据流上的实验表明，该方法取得了优异的结果，F1分数为98.2%，精确度为97.8%，召回率为97.0%。专家评估进一步证实了生成解释的质量和可解释性。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了结合图智能和生成模型在支持高风险金融环境中的可解释、审计准备就绪的合规性方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种实时交易监控框架，该框架结合了基于图建模、叙事字段嵌入和生成解释来支持自动化的金融合规。系统构建动态交易图，提取结构和上下文特征，并使用图神经网络对可疑行为进行分类。检索增强生成模块为每个标记的交易生成与法规条款相符的自然语言解释。在模拟金融数据流上的实验表明，该方法取得了优异的结果，F1分数为98.2%，精确度为97.8%，召回率为97.0%。专家评估进一步证实了生成解释的质量和可解释性。该研究证明了结合图智能和生成模型在支持高风险金融环境中的可解释、审计准备就绪的合规性方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a real-time transaction monitoring framework thatintegrates graph-based modeling, narrative field embedding, and generativeexplanation to support automated financial compliance. The system constructsdynamic transaction graphs, extracts structural and contextual features, andclassifies suspicious behavior using a graph neural network. Aretrieval-augmented generation module generates natural language explanationsaligned with regulatory clauses for each flagged transaction. Experimentsconducted on a simulated stream of financial data show that the proposed methodachieves superior results, with 98.2% F1-score, 97.8% precision, and 97.0%recall. Expert evaluation further confirms the quality and interpretability ofgenerated justifications. The findings demonstrate the potential of combininggraph intelligence and generative models to support explainable, audit-readycompliance in high-risk financial environments.</description>
      <author>example@mail.com (Kunal Khanvilkar, Kranthi Kommuru)</author>
      <guid isPermaLink="false">2506.01093v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Hidden Representation Clustering with Multi-Task Representation Learning towards Robust Online Budget Allocation</title>
      <link>http://arxiv.org/abs/2506.00959v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的营销优化方法，通过聚类视角解决大规模在线预算分配问题，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;营销优化作为推动用户增长的关键因素，传统方法存在大规模反事实预测和复杂度权衡等挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，解决大规模在线预算分配问题，特别是在数据噪声较大的工业场景中。&lt;h4&gt;方法&lt;/h4&gt;1. 提出多任务表示网络学习个体属性并将其特征映射到高维隐藏表示。2. 通过基于划分的聚类将隐藏表示分为K组。3. 将表示模块和聚类模型蒸馏到一个多分类模型中，以方便在线部署。&lt;h4&gt;主要发现&lt;/h4&gt;离线实验验证了与六种最先进的营销优化算法相比，该方法的有效性和优越性。在线A/B测试表明，该方法在订单量（OV）和商品交易总额（GMV）方面分别优于在线算法0.53%和0.65%。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效解决大规模在线预算分配问题，并在实际应用中取得了良好的效果。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel marketing optimization method that solves the large-scale online budget allocation problem from a clustering perspective, and its effectiveness is validated through experiments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Marketing optimization, commonly formulated as an online budget allocationproblem, has emerged as a pivotal factor in driving user growth. Most existingresearch addresses this problem by following the principle of 'first predictthen optimize' for each individual, which presents challenges related tolarge-scale counterfactual prediction and solving complexity trade-offs. Notethat the practical data quality is uncontrollable, and the solving scale tendsto be tens of millions. Therefore, the existing approaches make the robustbudget allocation non-trivial, especially in industrial scenarios withconsiderable data noise. To this end, this paper proposes a novel approach thatsolves the problem from the cluster perspective. Specifically, we propose amulti-task representation network to learn the inherent attributes ofindividuals and project the original features into high-dimension hiddenrepresentations through the first two layers of the trained network. Then, wedivide these hidden representations into $K$ groups through partitioning-basedclustering, thus reformulating the problem as an integer stochastic programmingproblem under different total budgets. Finally, we distill the representationmodule and clustering model into a multi-category model to facilitate onlinedeployment. Offline experiments validate the effectiveness and superiority ofour approach compared to six state-of-the-art marketing optimizationalgorithms. Online A/B tests on the Meituan platform indicate that the approachoutperforms the online algorithm by 0.53% and 0.65%, considering order volume(OV) and gross merchandise volume (GMV), respectively.</description>
      <author>example@mail.com (Xiaohan Wang, Yu Zhang, Guibin Jiang, Bing Cheng, Wei Lin)</author>
      <guid isPermaLink="false">2506.00959v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>InterRVOS: Interaction-aware Referring Video Object Segmentation</title>
      <link>http://arxiv.org/abs/2506.02356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的视频对象分割任务，即交互感知的视频对象分割（InterRVOS），旨在通过理解物体间的交互来分割视频中的对象。该方法通过大规模数据集和新的评估设置来提高对复杂交互的理解。&lt;h4&gt;背景&lt;/h4&gt;现有研究主要关注单独定位单个目标对象，而忽略了物体之间交互的重要性。&lt;h4&gt;目的&lt;/h4&gt;通过引入InterRVOS任务，实现同时分割交互中的参与者和目标实体，并从不同语义角度对交互进行建模。&lt;h4&gt;方法&lt;/h4&gt;提出InterRVOS-8K数据集，包含多样化的交互感知表达式和相应的掩码。同时，设计了ReVIOSa架构，用于处理单表达式中的演员-目标分割，并在标准环境和交互焦点环境中取得良好性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在建模复杂交互方面优于现有方法，为以交互为中心的视频理解研究奠定了基础。&lt;h4&gt;结论&lt;/h4&gt;InterRVOS为视频理解领域提供了新的研究方向，有助于更好地理解视频中的复杂交互。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Referring video object segmentation aims to segment the object in a videocorresponding to a given natural language expression. While prior works haveexplored various referring scenarios, including motion-centric ormulti-instance expressions, most approaches still focus on localizing a singletarget object in isolation. However, in comprehensive video understanding, anobject's role is often defined by its interactions with other entities, whichare largely overlooked in existing datasets and models. In this work, weintroduce Interaction-aware referring video object sgementation (InterRVOS), anew task that requires segmenting both actor and target entities involved in aninteraction. Each interactoin is described through a pair of complementaryexpressions from different semantic perspectives, enabling fine-grainedmodeling of inter-object relationships. To tackle this task, we proposeInterRVOS-8K, the large-scale and automatically constructed dataset containingdiverse interaction-aware expressions with corresponding masks, includingchallenging cases such as motion-only multi-instance expressions. We alsopresent a baseline architecture, ReVIOSa, designed to handle actor-targetsegmentation from a single expression, achieving strong performance in bothstandard and interaction-focused settings. Furthermore, we introduce anactor-target-aware evalaution setting that enables a more targeted assessmentof interaction understanding. Experimental results demonstrate that ourapproach outperforms prior methods in modeling complex object interactions forreferring video object segmentation task, establishing a strong foundation forfuture research in interaction-centric video understanding. Our project page isavailable at\href{https://cvlab-kaist.github.io/InterRVOS}{https://cvlab-kaist.github.io/InterRVOS}.</description>
      <author>example@mail.com (Woojeong Jin, Seongchan Kim, Seungryong Kim)</author>
      <guid isPermaLink="false">2506.02356v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Chunking Enhances Recognition of Implicit Sequential Patterns</title>
      <link>http://arxiv.org/abs/2506.00588v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种神经启发的时序序列压缩方法，通过上下文标记的块来表示序列中的重复结构单元或“社区”。这些标记在离线睡眠阶段生成，作为对过去经验的紧凑引用，允许学习者在输入范围之外整合信息。&lt;h4&gt;背景&lt;/h4&gt;研究旨在探讨传统基于神经网络的序列学习器（如循环神经网络RNN）在处理多尺度时间模式时的局限性。&lt;h4&gt;目的&lt;/h4&gt;通过实验评估时序块压缩方法在受限资源设置下的学习效率，并通过小型人类试点研究验证结构抽象的概念。&lt;h4&gt;方法&lt;/h4&gt;研究在受控的合成环境中评估了该方法，并使用串行反应时间任务进行了小型人类试点研究。&lt;h4&gt;主要发现&lt;/h4&gt;初步结果表明，时序块压缩可以显著提高学习效率，并且学习到的上下文标签可以在相关任务间迁移。&lt;h4&gt;结论&lt;/h4&gt;该研究为时序块压缩提供了一个早期概念验证，为迁移学习等未来应用提供了潜力。&lt;h4&gt;翻译&lt;/h4&gt;In this pilot study, we propose a neuro-inspired approach that compresses temporal sequences into context-tagged chunks, where each tag represents a recurring structural unit or ``community'' in the sequence. These tags are generated during an offline sleep phase and serve as compact references to past experience, allowing the learner to incorporate information beyond its immediate input range. We evaluate this idea in a controlled synthetic environment designed to reveal the limitations of traditional neural network based sequence learners, such as recurrent neural networks (RNNs), when facing temporal patterns on multiple timescales. We evaluate this idea in a controlled synthetic environment designed to reveal the limitations of traditional neural network based sequence learners, such as recurrent neural networks (RNNs), when facing temporal patterns on multiple timescales. Our results, while preliminary, suggest that temporal chunking can significantly enhance learning efficiency under resource constrained settings. A small-scale human pilot study using a Serial Reaction Time Task further motivates the idea of structural abstraction. Although limited to synthetic tasks, this work serves as an early proof-of-concept, with initial evidence that learned context tags can transfer across related task, offering potential for future applications in transfer learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this pilot study, we propose a neuro-inspired approach that compressestemporal sequences into context-tagged chunks, where each tag represents arecurring structural unit or``community'' in the sequence. These tags aregenerated during an offline sleep phase and serve as compact references to pastexperience, allowing the learner to incorporate information beyond itsimmediate input range. We evaluate this idea in a controlled syntheticenvironment designed to reveal the limitations of traditional neural networkbased sequence learners, such as recurrent neural networks (RNNs), when facingtemporal patterns on multiple timescales. We evaluate this idea in a controlledsynthetic environment designed to reveal the limitations of traditional neuralnetwork based sequence learners, such as recurrent neural networks (RNNs), whenfacing temporal patterns on multiple timescales. Our results, whilepreliminary, suggest that temporal chunking can significantly enhance learningefficiency under resource constrained settings. A small-scale human pilot studyusing a Serial Reaction Time Task further motivates the idea of structuralabstraction. Although limited to synthetic tasks, this work serves as an earlyproof-of-concept, with initial evidence that learned context tags can transferacross related task, offering potential for future applications in transferlearning.</description>
      <author>example@mail.com (Jayanta Dey, Nicholas Soures, Miranda Gonzales, Itamar Lerner, Christopher Kanan, Dhireesha Kudithipudi)</author>
      <guid isPermaLink="false">2506.00588v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>PolyBERT: Fine-Tuned Poly Encoder BERT-Based Model for Word Sense Disambiguation</title>
      <link>http://arxiv.org/abs/2506.00968v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于BERT的多编码器模型PolyBERT，用于解决主流词义消歧（WSD）方法中的不足，通过批对比学习（BCL）提高了语义表示和计算效率。&lt;h4&gt;背景&lt;/h4&gt;现有的WSD方法使用BERT提取语义，但在特征提取过程中未能平衡局部和全局语义表示，且在训练阶段包含了所有可能的词义，导致计算成本高。&lt;h4&gt;目的&lt;/h4&gt;提出PolyBERT模型以解决现有WSD方法的不足，包括改善语义表示和降低计算成本。&lt;h4&gt;方法&lt;/h4&gt;PolyBERT模型采用多编码器和多头注意力机制融合局部和全局语义，同时引入BCL减少冗余训练输入。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，PolyBERT在F1分数上比基线方法如Huang的GlossBERT和Blevins的BEM提高了2%，并且与不使用BCL的PolyBERT相比，使用BCL的PolyBERT减少了37.6%的GPU使用时间。&lt;h4&gt;结论&lt;/h4&gt;PolyBERT通过平衡局部和全局语义以及引入批对比学习，有效地提高了WSD的性能和计算效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mainstream Word Sense Disambiguation (WSD) approaches have employed BERT toextract semantics from both context and definitions of senses to determine themost suitable sense of a target word, achieving notable performance. However,there are two limitations in these approaches. First, previous studies failedto balance the representation of token-level (local) and sequence-level(global) semantics during feature extraction, leading to insufficient semanticrepresentation and a performance bottleneck. Second, these approachesincorporated all possible senses of each target word during the training phase,leading to unnecessary computational costs. To overcome these limitations, thispaper introduces a poly-encoder BERT-based model with batch contrastivelearning for WSD, named PolyBERT. Compared with previous WSD methods, PolyBERThas two improvements: (1) A poly-encoder with a multi-head attention mechanismis utilized to fuse token-level (local) and sequence-level (global) semantics,rather than focusing on just one. This approach enriches semanticrepresentation by balancing local and global semantics. (2) To avoid redundanttraining inputs, Batch Contrastive Learning (BCL) is introduced. BCL utilizesthe correct senses of other target words in the same batch as negative samplesfor the current target word, which reduces training inputs and computationalcost. The experimental results demonstrate that PolyBERT outperforms baselineWSD methods such as Huang's GlossBERT and Blevins's BEM by 2\% in F1-score. Inaddition, PolyBERT with BCL reduces GPU hours by 37.6\% compared with PolyBERTwithout BCL.</description>
      <author>example@mail.com (Linhan Xia, Mingzhan Yang, Guohui Yuan, Shengnan Tao, Yujing Qiu, Guo Yu, Kai Lei)</author>
      <guid isPermaLink="false">2506.00968v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting End-to-End Learning with Slide-level Supervision in Computational Pathology</title>
      <link>http://arxiv.org/abs/2506.02408v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的多实例学习（MIL）方法ABMILX，用于计算病理学中的癌症诊断和预后。该方法结合了预训练编码器和端到端学习，旨在解决现有方法的性能限制。&lt;h4&gt;背景&lt;/h4&gt;预训练编码器和MIL在计算病理学中得到了广泛应用，但缺乏编码器微调和MIL的分离优化导致性能限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的MIL方法ABMILX，以解决端到端学习中的优化挑战，并提高计算病理学中的性能。&lt;h4&gt;方法&lt;/h4&gt;提出ABMILX方法，通过全局相关性注意力和多头机制来缓解稀疏注意力MIL的优化问题，并使用多尺度随机补丁采样策略进行端到端训练。&lt;h4&gt;主要发现&lt;/h4&gt;ABMILX在多个基准测试中超越了现有基础模型，同时保持了计算效率。&lt;h4&gt;结论&lt;/h4&gt;端到端学习在计算病理学中有潜力，需要更多研究关注。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes a new multi-instance learning (MIL) method called ABMILX for cancer diagnosis and prognosis in computational pathology. The method combines pre-trained encoders with end-to-end learning to address the performance limitations of existing methods. ABMILX mitigates the optimization challenges of end-to-end learning by using global correlation-based attention refinement and multi-head mechanisms, and achieves state-of-the-art performance while remaining computationally efficient. The paper demonstrates the potential of end-to-end learning in computational pathology and calls for greater research focus in this area.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pre-trained encoders for offline feature extraction followed by multipleinstance learning (MIL) aggregators have become the dominant paradigm incomputational pathology (CPath), benefiting cancer diagnosis and prognosis.However, performance limitations arise from the absence of encoder fine-tuningfor downstream tasks and disjoint optimization with MIL. While slide-levelsupervised end-to-end (E2E) learning is an intuitive solution to this issue, itfaces challenges such as high computational demands and suboptimal results.These limitations motivate us to revisit E2E learning. We argue that prior workneglects inherent E2E optimization challenges, leading to performancedisparities compared to traditional two-stage methods. In this paper, wepioneer the elucidation of optimization challenge caused by sparse-attentionMIL and propose a novel MIL called ABMILX. It mitigates this problem throughglobal correlation-based attention refinement and multi-head mechanisms. Withthe efficient multi-scale random patch sampling strategy, an E2E trained ResNetwith ABMILX surpasses SOTA foundation models under the two-stage paradigmacross multiple challenging benchmarks, while remaining computationallyefficient (&lt;10 RTX3090 hours). We show the potential of E2E learning in CPathand calls for greater research focus in this area. The code ishttps://github.com/DearCaat/E2E-WSI-ABMILX.</description>
      <author>example@mail.com (Wenhao Tang, Rong Qin, Heng Fang, Fengtao Zhou, Hao Chen, Xiang Li, Ming-Ming Cheng)</author>
      <guid isPermaLink="false">2506.02408v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Pilot Contamination-Aware Graph Attention Network for Power Control in CFmMIMO</title>
      <link>http://arxiv.org/abs/2506.00967v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图注意力网络的CFmMIMO系统下行链路功率控制算法，该算法以自监督方式运行，有效处理导频污染问题，并适应动态变化的用户数量。&lt;h4&gt;背景&lt;/h4&gt;基于优化的功率控制算法在CFmMIMO系统中计算复杂度高，不适合实时应用。基于学习的算法，尤其是图神经网络（GNNs），在解决功率控制问题中表现出色。然而，现有基于GNN的方法假设导频序列间理想正交性，这在实际中不现实，且多数方法假设用户数量固定。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的算法来解决现有方法中存在的假设不现实、用户数量动态变化和计算资源消耗大的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的图注意力网络算法，该算法在CFmMIMO系统中进行下行链路功率控制，并能够以自监督方式运行，同时处理导频污染问题，并适应动态变化的用户数量。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该算法在处理导频污染和适应动态用户数量方面有效，甚至与最优加速投影梯度方法相比也表现出良好的性能。&lt;h4&gt;结论&lt;/h4&gt;该图注意力网络算法为CFmMIMO系统下行链路功率控制提供了一种有效且实用的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a graph attention network-based downlink power control algorithm for CFmMIMO systems, which operates in a self-supervised manner while effectively handling pilot contamination and adapting to a dynamic number of UEs. Experimental results show its effectiveness, even compared to the optimal accelerated projected gradient method as a baseline.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optimization-based power control algorithms are predominantly iterative withhigh computational complexity, making them impractical for real-timeapplications in cell-free massive multiple-input multiple-output (CFmMIMO)systems. Learning-based methods have emerged as a promising alternative, andamong them, graph neural networks (GNNs) have demonstrated their excellentperformance in solving power control problems. However, all existing GNN-basedapproaches assume ideal orthogonality among pilot sequences for user equipments(UEs), which is unrealistic given that the number of UEs exceeds the availableorthogonal pilot sequences in CFmMIMO schemes. Moreover, most learning-basedmethods assume a fixed number of UEs, whereas the number of active UEs variesover time in practice. Additionally, supervised training necessitates costlycomputational resources for computing the target power control solutions for alarge volume of training samples. To address these issues, we propose a graphattention network for downlink power control in CFmMIMO systems that operatesin a self-supervised manner while effectively handling pilot contamination andadapting to a dynamic number of UEs. Experimental results show itseffectiveness, even in comparison to the optimal accelerated projected gradientmethod as a baseline.</description>
      <author>example@mail.com (Tingting Zhang, Sergiy A. Vorobyov, David J. Love, Taejoon Kim, Kai Dong)</author>
      <guid isPermaLink="false">2506.00967v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>General-purpose audio representation learning for real-world sound scenes</title>
      <link>http://arxiv.org/abs/2506.00934v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的自监督训练方法，用于通用、真实世界音频模型（GRAMs），旨在解决现有音频基础模型在真实世界应用中的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有的音频基础模型在非空间、单声源音频片段上训练和测试，导致它们在真实世界场景中的表现受限，并且缺乏空间感知的音频嵌入。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自监督训练方法，以实现自然、嘈杂声音场景中的鲁棒空间音频表示学习，并应用于任何基于掩码的深度学习模型。&lt;h4&gt;方法&lt;/h4&gt;通过训练两个最先进的模型（一个基于transformer，一个基于mamba骨干网络）来展示方法的有效性，并使用HEAR基准、新合成的自然版本HEAR基准和基于HEAR基准数据集的新的声音定位任务来评估提取的音频表示的质量。&lt;h4&gt;主要发现&lt;/h4&gt;该方法最小化了干、非空间、单声源声音场景与自然声音场景之间的性能差距，在关键任务如听觉场景分析方面超越了现有最先进的音频基础模型，并且在训练步骤中占比较小。此外，GRAMs在声音定位任务上表现出最先进的性能，甚至超过了监督声音定位模型。&lt;h4&gt;结论&lt;/h4&gt;该方法代表了向鲁棒的音频基础模型迈出的重要一步，这些模型在自然声音场景以及空间音频表示学习方面均达到最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;While audio foundation models perform well on myriad of tasks from sound classification to speech analysis, these models are trained and tested on dry, non-spatial, single-source audio clips. This limits their success in real-world situations and results in spatially unaware audio embeddings. To address these limitations, we propose a novel self-supervised training approach for General-Purpose, Real-world Audio Models (GRAMs). The GRAM training approach enables robust spatial audio representation learning for naturalistic, noisy sound scenes and can be applied to any masking-based deep learning model. We demonstrate the success of our approach by training two state-of-the-art models, one with a transformer and one with a mamba backbone. We assess the quality of the extracted audio representations from GRAMs using the original version of the HEAR benchmark, a newly synthesized, naturalistic version of the HEAR benchmark, and novel sound localization tasks based on HEAR benchmark datasets. The results show that our approach minimizes the performance gap between dry, non-spatial, single-source sound scenes and naturalistic sound scenes for crucial tasks such as auditory scene analysis, outperforming existing state-of-the-art audio foundation models at a fraction of the training steps. Moreover, GRAMs show state-of-the-art performance on sound localization tasks, exceeding even supervised sound localization models. In sum, the proposed approach represents a significant advancement towards robust audio foundation models for real-world applications with state-of-the-art performance on naturalistic sound scenes as well as spatial audio representation learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While audio foundation models perform well on myriad of tasks from soundclassification to speech analysis, these models are trained and tested on dry,non-spatial, single-source audio clips. This limits their success in real-worldsituations and results in spatially unaware audio embeddings. To address theselimitations, we propose a novel self-supervised training approach forGeneral-Purpose, Real-world Audio Models (GRAMs). The GRAM training approachenables robust spatial audio representation learning for naturalistic, noisysound scenes and can be applied to any masking-based deep learning model. Wedemonstrate the success of our approach by training two state-of-the-artmodels, one with a transformer and one with a mamba backbone. We assess thequality of the extracted audio representations from GRAMs using the originalversion of the HEAR benchmark, a newly synthesized, naturalistic version of theHEAR benchmark, and novel sound localization tasks based on HEAR benchmarkdatasets. The results show that our approach minimizes the performance gapbetween dry, non-spatial, single-source sound scenes and naturalistic soundscenes for crucial tasks such as auditory scene analysis, outperformingexisting state-of-the-art audio foundation models at a fraction of the trainingsteps. Moreover, GRAMs show state-of-the-art performance on sound localizationtasks, exceeding even supervised sound localization models. In sum, theproposed approach represents a significant advancement towards robust audiofoundation models for real-world applications with state-of-the-art performanceon naturalistic sound scenes as well as spatial audio representation learning.</description>
      <author>example@mail.com (Goksenin Yuksel, Marcel van Gerven, Kiki van der Heijden)</author>
      <guid isPermaLink="false">2506.00934v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Reinforcement Learning Tuning for VideoLLMs: Reward Design and Data Efficiency</title>
      <link>http://arxiv.org/abs/2506.01908v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用多模态大型语言模型（MLLMs）理解具有复杂语义和长期时间依赖性的真实世界视频的问题。通过探索强化学习调优（RLT）作为后训练策略来增强MLLMs的视频特定推理能力，提出了一种基于GRPO框架的Dual-reward公式，并通过离散和连续奖励信号监督语义和时间推理。此外，引入了一种基于重复推理的方差感知数据选择策略，以促进基于偏好的优化，并在多个视频理解任务上取得了优于监督微调和现有RLT基线的性能。&lt;h4&gt;背景&lt;/h4&gt;理解具有复杂语义和长期时间依赖性的真实世界视频是计算机视觉中的基本挑战。&lt;h4&gt;目的&lt;/h4&gt;利用强化学习调优（RLT）作为后训练策略来增强MLLMs的视频特定推理能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于GRPO框架的Dual-reward公式，并引入了方差感知数据选择策略。&lt;h4&gt;主要发现&lt;/h4&gt;在八个代表性的视频理解任务上，方法表现优于监督微调和现有RLT基线，且在更少的训练数据下实现了更优的性能。&lt;h4&gt;结论&lt;/h4&gt;奖励设计和数据选择对于利用MLLMs推进以推理为中心的视频理解至关重要。&lt;h4&gt;翻译&lt;/h4&gt;Understanding real-world videos with complex semantics and long temporaldependencies remains a fundamental challenge in computer vision. Recentprogress in multimodal large language models (MLLMs) has demonstrated strongcapabilities in vision-language tasks, while reinforcement learning tuning(RLT) has further improved their reasoning abilities. In this work, we exploreRLT as a post-training strategy to enhance the video-specific reasoningcapabilities of MLLMs. Built upon the Group Relative Policy Optimization (GRPO)framework, we propose a dual-reward formulation that supervises both semanticand temporal reasoning through discrete and continuous reward signals. Tofacilitate effective preference-based optimization, we introduce avariance-aware data selection strategy based on repeated inference to identifysamples that provide informative learning signals. We evaluate our approachacross eight representative video understanding tasks, including VideoQA,Temporal Video Grounding, and Grounded VideoQA. Our method consistentlyoutperforms supervised fine-tuning and existing RLT baselines, achievingsuperior performance with significantly less training data. These resultsunderscore the importance of reward design and data selection in advancingreasoning-centric video understanding with MLLMs. Notably, The initial coderelease (two months ago) has now been expanded with updates, includingoptimized reward mechanisms and additional datasets. The latest version isavailable at https://github.com/appletea233/Temporal-R1 .&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding real-world videos with complex semantics and long temporaldependencies remains a fundamental challenge in computer vision. Recentprogress in multimodal large language models (MLLMs) has demonstrated strongcapabilities in vision-language tasks, while reinforcement learning tuning(RLT) has further improved their reasoning abilities. In this work, we exploreRLT as a post-training strategy to enhance the video-specific reasoningcapabilities of MLLMs. Built upon the Group Relative Policy Optimization (GRPO)framework, we propose a dual-reward formulation that supervises both semanticand temporal reasoning through discrete and continuous reward signals. Tofacilitate effective preference-based optimization, we introduce avariance-aware data selection strategy based on repeated inference to identifysamples that provide informative learning signals. We evaluate our approachacross eight representative video understanding tasks, including VideoQA,Temporal Video Grounding, and Grounded VideoQA. Our method consistentlyoutperforms supervised fine-tuning and existing RLT baselines, achievingsuperior performance with significantly less training data. These resultsunderscore the importance of reward design and data selection in advancingreasoning-centric video understanding with MLLMs. Notably, The initial coderelease (two months ago) has now been expanded with updates, includingoptimized reward mechanisms and additional datasets. The latest version isavailable at https://github.com/appletea233/Temporal-R1 .</description>
      <author>example@mail.com (Hongyu Li, Songhao Han, Yue Liao, Junfeng Luo, Jialin Gao, Shuicheng Yan, Si Liu)</author>
      <guid isPermaLink="false">2506.01908v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>COGNATE: Acceleration of Sparse Tensor Programs on Emerging Hardware using Transfer Learning</title>
      <link>http://arxiv.org/abs/2506.00424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the 42nd International Conference on Machine Learning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了COGNATE框架，该框架利用通用硬件（如CPU）的低成本数据样本来训练成本模型，并在新兴硬件上进行少量样本的微调，以优化稀疏张量程序。&lt;h4&gt;背景&lt;/h4&gt;稀疏张量程序在深度学习和图分析中至关重要，需要专门的硬件加速器来优化处理。&lt;h4&gt;目的&lt;/h4&gt;为了应对稀疏输入的变异性以及早期加速器依赖昂贵的模拟器的问题，开发了一种新的框架COGNATE。&lt;h4&gt;方法&lt;/h4&gt;COGNATE利用硬件平台间输入特征的均匀性，通过少量数据样本进行成本模型训练，并在新兴硬件上进行少量样本的微调。&lt;h4&gt;主要发现&lt;/h4&gt;COGNATE在实验中优于现有技术，SpMM的平均加速达到1.47倍（最高5.46倍），SDDMM的平均加速达到1.39倍（最高4.22倍）。&lt;h4&gt;结论&lt;/h4&gt;COGNATE通过有效降低数据样本需求，提高了成本模型训练的效率，适用于早期加速器的优化。&lt;h4&gt;翻译&lt;/h4&gt;Sparse tensor programs are essential in deep learning and graph analytics, driving the need for optimized processing. To meet this demand, specialized hardware accelerators are being developed. Optimizing these programs for accelerators is challenging for two reasons: program performance is highly sensitive to variations in sparse inputs, and early-stage accelerators rely on expensive simulators. Therefore, ML-based cost models used for optimizing such programs on general-purpose hardware are often ineffective for early-stage accelerators, as they require large datasets for proper training. To this end, we introduce COGNATE, a novel framework that leverages inexpensive data samples from general-purpose hardware (e.g., CPUs) to train cost models, followed by few-shot fine-tuning on emerging hardware. COGNATE exploits the homogeneity of input features across hardware platforms while effectively mitigating heterogeneity, enabling cost model training with just 5% of the data samples needed by accelerator-specific models to achieve comparable performance. We conduct extensive experiments to demonstrate that COGNATE outperforms existing techniques, achieving average speedups of 1.47x (up to 5.46x) for SpMM and 1.39x (up to 4.22x) for SDDMM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sparse tensor programs are essential in deep learning and graph analytics,driving the need for optimized processing. To meet this demand, specializedhardware accelerators are being developed. Optimizing these programs foraccelerators is challenging for two reasons: program performance is highlysensitive to variations in sparse inputs, and early-stage accelerators rely onexpensive simulators. Therefore, ML-based cost models used for optimizing suchprograms on general-purpose hardware are often ineffective for early-stageaccelerators, as they require large datasets for proper training. To this end,we introduce COGNATE, a novel framework that leverages inexpensive data samplesfrom general-purpose hardware (e.g., CPUs) to train cost models, followed byfew-shot fine-tuning on emerging hardware. COGNATE exploits the homogeneity ofinput features across hardware platforms while effectively mitigatingheterogeneity, enabling cost model training with just 5% of the data samplesneeded by accelerator-specific models to achieve comparable performance. Weconduct extensive experiments to demonstrate that COGNATE outperforms existingtechniques, achieving average speedups of 1.47x (up to 5.46x) for SpMM and1.39x (up to 4.22x) for SDDMM.</description>
      <author>example@mail.com (Chamika Sudusinghe, Gerasimos Gerogiannis Damitha Lenadora, Charles Block, Josep Torrellas, Charith Mendis)</author>
      <guid isPermaLink="false">2506.00424v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty-Aware Metabolic Stability Prediction with Dual-View Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.00936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This manuscript has been accepted for publication at ECML-PKDD 2025.  The final version will be published in the conference proceedings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为TrustworthyMS的代谢稳定性预测新框架，旨在解决现有方法在分子模型和不确定性量化方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;准确预测分子的代谢稳定性对于药物研发至关重要，但由于分子间复杂的相互作用，这一任务具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出TrustworthyMS框架，以提高代谢稳定性预测的准确性和可靠性。&lt;h4&gt;方法&lt;/h4&gt;1. 使用分子图拓扑重映射机制同步原子-键相互作用；2. 通过对比拓扑-键对齐增强表示的鲁棒性；3. 利用Beta-Binomial不确定性量化模型进行预测和置信度校准。&lt;h4&gt;主要发现&lt;/h4&gt;TrustworthyMS在预测性能方面优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;TrustworthyMS是一种有效且可靠的代谢稳定性预测工具，可提高药物研发的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction of molecular metabolic stability (MS) is critical fordrug research and development but remains challenging due to the complexinterplay of molecular interactions. Despite recent advances in graph neuralnetworks (GNNs) for MS prediction, current approaches face two criticallimitations: (1) incomplete molecular modeling due to atom-centricmessage-passing mechanisms that disregard bond-level topological features, and(2) prediction frameworks that lack reliable uncertainty quantification. Toaddress these challenges, we propose TrustworthyMS, a novel contrastivelearning framework designed for uncertainty-aware metabolic stabilityprediction. First, a molecular graph topology remapping mechanism synchronizesatom-bond interactions through edge-induced feature propagation, capturing bothlocalized electronic effects and global conformational constraints. Second,contrastive topology-bond alignment enforces consistency between moleculartopology views and bond patterns via feature alignment, enhancingrepresentation robustness. Third, uncertainty modeling through Beta-Binomialuncertainty quantification enables simultaneous prediction and confidencecalibration under epistemic uncertainty. Through extensive experiments, ourresults demonstrate that TrustworthyMS outperforms current state-of-the-artmethods in terms of predictive performance.</description>
      <author>example@mail.com (Peijin Guo, Minghui Li, Hewen Pan, Bowen Chen, Yang Wu, Zikang Guo, Leo Yu Zhang, Shengshan Hu, Shengqing Hu)</author>
      <guid isPermaLink="false">2506.00936v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Auto-Labeling Data for Object Detection</title>
      <link>http://arxiv.org/abs/2506.02359v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种无需真实标签训练标准目标检测模型的方法，通过配置预训练的视觉-语言基础模型生成特定应用的伪真实标签，以降低传统标注成本并提高模型效率。&lt;h4&gt;背景&lt;/h4&gt;传统标注方法在规模上成本高昂，而全监督目标检测的替代方案要么功能受损，要么需要大型模型，导致推理成本过高。&lt;h4&gt;目的&lt;/h4&gt;旨在解决在无需地面真实标签的情况下训练标准目标检测模型的问题。&lt;h4&gt;方法&lt;/h4&gt;配置预训练的视觉-语言基础模型生成应用特定的伪真实标签，与现有模型训练框架集成，并训练轻量级检测模型。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个数据集上保持了有竞争力的性能，同时显著减少了标注时间和成本。&lt;h4&gt;结论&lt;/h4&gt;该方法在多个数据集上提供了与传统标注相竞争的性能，是一种有效的替代方案，适用于实际应用。&lt;h4&gt;翻译&lt;/h4&gt;Great labels make great models. However, traditional labeling approaches for tasks like object detection have substantial costs at scale. Furthermore, alternatives to fully-supervised object detection either lose functionality or require larger models with prohibitive computational costs for inference at scale. To that end, this paper addresses the problem of training standard object detection models without any ground truth labels. Instead, we configure previously-trained vision-language foundation models to generate application-specific pseudo "ground truth" labels. These auto-generated labels directly integrate with existing model training frameworks, and we subsequently train lightweight detection models that are computationally efficient. In this way, we avoid the costs of traditional labeling, leverage the knowledge of vision-language models, and keep the efficiency of lightweight models for practical application. We perform exhaustive experiments across multiple labeling configurations, downstream inference models, and datasets to establish best practices and set an extensive auto-labeling benchmark. From our results, we find that our approach is a viable alternative to standard labeling in that it maintains competitive performance on multiple datasets and substantially reduces labeling time and costs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Great labels make great models. However, traditional labeling approaches fortasks like object detection have substantial costs at scale. Furthermore,alternatives to fully-supervised object detection either lose functionality orrequire larger models with prohibitive computational costs for inference atscale. To that end, this paper addresses the problem of training standardobject detection models without any ground truth labels. Instead, we configurepreviously-trained vision-language foundation models to generateapplication-specific pseudo "ground truth" labels. These auto-generated labelsdirectly integrate with existing model training frameworks, and we subsequentlytrain lightweight detection models that are computationally efficient. In thisway, we avoid the costs of traditional labeling, leverage the knowledge ofvision-language models, and keep the efficiency of lightweight models forpractical application. We perform exhaustive experiments across multiplelabeling configurations, downstream inference models, and datasets to establishbest practices and set an extensive auto-labeling benchmark. From our results,we find that our approach is a viable alternative to standard labeling in thatit maintains competitive performance on multiple datasets and substantiallyreduces labeling time and costs.</description>
      <author>example@mail.com (Brent A. Griffin, Manushree Gangwar, Jacob Sela, Jason J. Corso)</author>
      <guid isPermaLink="false">2506.02359v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Linear Representation Transferability Hypothesis: Leveraging Small Models to Steer Large Models</title>
      <link>http://arxiv.org/abs/2506.00653v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为线性表示可迁移性（LRT）的假设，认为不同规模模型的表示空间之间存在亲和变换，并通过实验验证了小模型的表示可以指导大模型的行为。&lt;h4&gt;背景&lt;/h4&gt;已有研究表明，具有相似架构的神经网络在相似数据上学习到与学习任务相关的共享表示。&lt;h4&gt;目的&lt;/h4&gt;提出LRT假设，并通过实验验证不同规模模型之间的表示空间是否存在亲和变换。&lt;h4&gt;方法&lt;/h4&gt;学习不同规模模型隐藏状态之间的仿射映射，并评估转移向量（与特定模型行为相关的隐藏状态方向）在从小型到大型语言模型转移时是否保持其语义效果。&lt;h4&gt;主要发现&lt;/h4&gt;实验发现，这些仿射映射可以保留引导行为。&lt;h4&gt;结论&lt;/h4&gt;小模型学习到的表示可以用于指导大模型的行为，LRT假设可能是在理解模型尺度间表示对齐方面的一个有希望的方向。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为线性表示可迁移性（LRT）的假设，认为不同规模模型的表示空间之间存在亲和变换，并通过实验验证了小模型的表示可以指导大模型的行为。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; It has been hypothesized that neural networks with similar architecturestrained on similar data learn shared representations relevant to the learningtask. We build on this idea by extending the conceptual framework whererepresentations learned across models trained on the same data can be expressedas linear combinations of a \emph{universal} set of basis features. These basisfeatures underlie the learning task itself and remain consistent across models,regardless of scale. From this framework, we propose the \textbf{LinearRepresentation Transferability (LRT)} Hypothesis -- that there exists an affinetransformation between the representation spaces of different models. To testthis hypothesis, we learn affine mappings between the hidden states of modelsof different sizes and evaluate whether steering vectors -- directions inhidden state space associated with specific model behaviors -- retain theirsemantic effect when transferred from small to large language models using thelearned mappings. We find strong empirical evidence that such affine mappingscan preserve steering behaviors. These findings suggest that representationslearned by small models can be used to guide the behavior of large models, andthat the LRT hypothesis may be a promising direction on understandingrepresentation alignment across model scales.</description>
      <author>example@mail.com (Femi Bello, Anubrata Das, Fanzhi Zeng, Fangcong Yin, Liu Leqi)</author>
      <guid isPermaLink="false">2506.00653v2</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>ReAgent-V: A Reward-Driven Multi-Agent Framework for Video Understanding</title>
      <link>http://arxiv.org/abs/2506.01300v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 18 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ReAgent-V的新型视频理解框架，该框架通过高效的帧选择和实时奖励生成来增强推理能力，并支持灵活的工具集成。&lt;h4&gt;背景&lt;/h4&gt;传统的视频理解方法在复杂场景中存在自我校正和适应能力不足的问题。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法的局限性，提高视频理解模型的推理能力和泛化性能。&lt;h4&gt;方法&lt;/h4&gt;ReAgent-V框架集成了奖励模型和强化学习，并通过多视角反射机制调整预测，同时支持数据过滤和偏好优化。&lt;h4&gt;主要发现&lt;/h4&gt;在12个数据集上进行的实验表明，ReAgent-V在视频理解、视频推理增强和视觉-语言-动作模型对齐三个核心应用中取得了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;ReAgent-V框架有效地提高了视频理解模型的推理能力和泛化性能，展现了其有效性和通用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video understanding is fundamental to tasks such as action recognition, videoreasoning, and robotic control. Early video understanding methods based onlarge vision-language models (LVLMs) typically adopt a single-pass reasoningparadigm without dynamic feedback, limiting the model's capacity toself-correct and adapt in complex scenarios. Recent efforts have attempted toaddress this limitation by incorporating reward models and reinforcementlearning to enhance reasoning, or by employing tool-agent frameworks. However,these approaches face several challenges, including high annotation costs,reward signals that fail to capture real-time reasoning states, and lowinference efficiency. To overcome these issues, we propose ReAgent-V, a novelagentic video understanding framework that integrates efficient frame selectionwith real-time reward generation during inference. These reward signals notonly guide iterative answer refinement through a multi-perspective reflectionmechanism-adjusting predictions from conservative, neutral, and aggressiveviewpoints-but also enable automatic filtering of high-quality data forsupervised fine-tuning (SFT), direct preference optimization (DPO), and grouprelative policy optimization (GRPO). ReAgent-V is lightweight, modular, andextensible, supporting flexible tool integration tailored to diverse tasks.Extensive experiments on 12 datasets across three core applications-videounderstanding, video reasoning enhancement, and vision-language-action modelalignment-demonstrate significant gains in generalization and reasoning, withimprovements of up to 6.9%, 2.1%, and 9.8%, respectively, highlighting theeffectiveness and versatility of the proposed framework.</description>
      <author>example@mail.com (Yiyang Zhou, Yangfan He, Yaofeng Su, Siwei Han, Joel Jang, Gedas Bertasius, Mohit Bansal, Huaxiu Yao)</author>
      <guid isPermaLink="false">2506.01300v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Neuro2Semantic: A Transfer Learning Framework for Semantic Reconstruction of Continuous Language from Human Intracranial EEG</title>
      <link>http://arxiv.org/abs/2506.00381v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Interspeech 2025 Code at  https://github.com/SiavashShams/neuro2semantic&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Neuro2Semantic的新框架，用于从颅内脑电图（iEEG）记录中重建感知语音的语义内容。&lt;h4&gt;背景&lt;/h4&gt;解码连续语言从神经信号中是神经科学与人工智能交叉领域的一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够从神经数据中重建语义内容的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法分为两个阶段：首先，基于LSTM的适配器将神经信号与预训练的文本嵌入对齐；其次，校正模块直接从这些对齐的嵌入生成连续、自然的文本。&lt;h4&gt;主要发现&lt;/h4&gt;Neuro2Semantic在低数据设置下表现优异，仅用30分钟的神经数据就超越了最近的一项最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;这些结果突显了Neuro2Semantic在脑机接口和神经解码技术中的实际应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从神经信号中解码连续语言是神经科学与人工智能交叉领域的一个重大挑战。我们提出了一种名为Neuro2Semantic的新框架，该框架可以从颅内脑电图（iEEG）记录中重建感知语音的语义内容。我们的方法包括两个阶段：首先，基于LSTM的适配器将神经信号与预训练的文本嵌入对齐；其次，校正模块直接从这些对齐的嵌入生成连续、自然的文本。这种灵活的方法克服了先前解码方法的局限性，并实现了不受约束的文本生成。Neuro2Semantic在低数据设置下实现了强大的性能，仅用30分钟的神经数据就超越了最近的一项最先进的方法。这些结果突显了Neuro2Semantic在脑机接口和神经解码技术中的实际应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decoding continuous language from neural signals remains a significantchallenge in the intersection of neuroscience and artificial intelligence. Weintroduce Neuro2Semantic, a novel framework that reconstructs the semanticcontent of perceived speech from intracranial EEG (iEEG) recordings. Ourapproach consists of two phases: first, an LSTM-based adapter aligns neuralsignals with pre-trained text embeddings; second, a corrector module generatescontinuous, natural text directly from these aligned embeddings. This flexiblemethod overcomes the limitations of previous decoding approaches and enablesunconstrained text generation. Neuro2Semantic achieves strong performance withas little as 30 minutes of neural data, outperforming a recent state-of-the-artmethod in low-data settings. These results highlight the potential forpractical applications in brain-computer interfaces and neural decodingtechnologies.</description>
      <author>example@mail.com (Siavash Shams, Richard Antonello, Gavin Mischler, Stephan Bickel, Ashesh Mehta, Nima Mesgarani)</author>
      <guid isPermaLink="false">2506.00381v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>EEG2TEXT-CN: An Exploratory Study of Open-Vocabulary Chinese Text-EEG Alignment via Large Language Model and Contrastive Learning on ChineseEEG</title>
      <link>http://arxiv.org/abs/2506.00854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为EEG2TEXT-CN的开源词汇EEG到文本生成框架，针对中文进行了优化。&lt;h4&gt;背景&lt;/h4&gt;目前尚无专门针对中文的开源词汇EEG到文本生成框架。&lt;h4&gt;目的&lt;/h4&gt;构建一个能够将脑电图（EEG）信号转换为文本的框架。&lt;h4&gt;方法&lt;/h4&gt;基于生物基础的EEG编码器（NICE-EEG）和紧凑的预训练语言模型（MiniLM），通过掩码预训练和对比学习将多通道脑信号与自然语言表示对齐。使用中文EEG数据集的子集，对每个句子中的汉字进行编码，并在零样本设置中预测完整句子。解码器使用教师强制和填充掩码进行训练，以适应不同长度的序列。&lt;h4&gt;主要发现&lt;/h4&gt;在超过1500个训练-验证句子和300个保留测试样本上的评估显示，有希望的词汇对齐，最佳BLEU-1分数为6.38%。虽然句法流畅性仍然是一个挑战，但研究结果证明了从EEG中解码非语音、跨模态语言的可能性。&lt;h4&gt;结论&lt;/h4&gt;该研究在多语言脑到文本研究领域开辟了新的方向，为中文的认知语言界面奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose EEG2TEXT-CN, which, to the best of our knowledge, represents oneof the earliest open-vocabulary EEG-to-text generation frameworks tailored forChinese. Built on a biologically grounded EEG encoder (NICE-EEG) and a compactpretrained language model (MiniLM), our architecture aligns multichannel brainsignals with natural language representations via masked pretraining andcontrastive learning. Using a subset of the ChineseEEG dataset, where eachsentence contains approximately ten Chinese characters aligned with 128-channelEEG recorded at 256 Hz, we segment EEG into per-character embeddings andpredict full sentences in a zero-shot setting. The decoder is trained withteacher forcing and padding masks to accommodate variable-length sequences.Evaluation on over 1,500 training-validation sentences and 300 held-out testsamples shows promising lexical alignment, with a best BLEU-1 score of 6.38\%.While syntactic fluency remains a challenge, our findings demonstrate thefeasibility of non-phonetic, cross-modal language decoding from EEG. This workopens a new direction in multilingual brain-to-text research and lays thefoundation for future cognitive-language interfaces in Chinese.</description>
      <author>example@mail.com (Jacky Tai-Yu Lu, Jung Chiang, Chi-Sheng Chen, Anna Nai-Yun Tung, Hsiang Wei Hu, Yuan Chiao Cheng)</author>
      <guid isPermaLink="false">2506.00854v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Lyrics Transcription on Music Mixtures with Consistency Loss</title>
      <link>http://arxiv.org/abs/2506.02339v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to Interspeech&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究自动歌词转录（ALT）技术，旨在识别歌唱声音中的歌词，并探讨了低秩自适应（LoRA）在ALT中的应用，同时提出了使用一致性损失来改进转录方法。&lt;h4&gt;背景&lt;/h4&gt;自动歌词转录与自动语音识别（ASR）类似，但由于歌唱声音的领域特定属性，ALT面临额外的复杂性。基础ASR模型在处理歌唱声音时表现不佳，尤其是在有音乐伴奏的情况下。&lt;h4&gt;目的&lt;/h4&gt;旨在解决基础ASR模型在歌唱声音上的性能下降问题，并探索LoRA在ALT中的应用。&lt;h4&gt;方法&lt;/h4&gt;研究了单领域和双领域微调策略，并提出使用一致性损失来更好地对齐语音和混合编码器表示，从而在不依赖歌唱声音分离的情况下改进转录。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明，虽然简单的双领域微调表现不佳，但采用一致性损失的系统训练可以获得适度但一致的性能提升。&lt;h4&gt;结论&lt;/h4&gt;证明了通过调整ASR基础模型来适应音乐转录的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Automatic Lyrics Transcription (ALT) aims to recognize lyrics from singing voices, similar to Automatic Speech Recognition (ASR) for spoken language, but faces added complexity due to domain-specific properties of the singing voice. While foundation ASR models show robustness in various speech tasks, their performance degrades on singing voice, especially in the presence of musical accompaniment. This work focuses on this performance gap and explores Low-Rank Adaptation (LoRA) for ALT, investigating both single-domain and dual-domain fine-tuning strategies. We propose using a consistency loss to better align vocal and mixture encoder representations, improving transcription on mixture without relying on singing voice separation. Our results show that while naive dual-domain fine-tuning underperforms, structured training with consistency loss yields modest but consistent gains, demonstrating the potential of adapting ASR foundation models for music.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic Lyrics Transcription (ALT) aims to recognize lyrics from singingvoices, similar to Automatic Speech Recognition (ASR) for spoken language, butfaces added complexity due to domain-specific properties of the singing voice.While foundation ASR models show robustness in various speech tasks, theirperformance degrades on singing voice, especially in the presence of musicalaccompaniment. This work focuses on this performance gap and explores Low-RankAdaptation (LoRA) for ALT, investigating both single-domain and dual-domainfine-tuning strategies. We propose using a consistency loss to better alignvocal and mixture encoder representations, improving transcription on mixturewithout relying on singing voice separation. Our results show that whilena\"ive dual-domain fine-tuning underperforms, structured training withconsistency loss yields modest but consistent gains, demonstrating thepotential of adapting ASR foundation models for music.</description>
      <author>example@mail.com (Jiawen Huang, Felipe Sousa, Emir Demirel, Emmanouil Benetos, Igor Gadelha)</author>
      <guid isPermaLink="false">2506.02339v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Unlearning Inversion Attacks for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.00808v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TrendAttack的图反学习攻击方法，用于对抗图神经网络（GNN）中的图反学习技术，通过分析未学习到的边及其影响，揭示了当前图反学习方法在隐私保护方面的脆弱性。&lt;h4&gt;背景&lt;/h4&gt;图反学习方法旨在从训练好的GNN中移除敏感数据的影响，而不进行完整的重新训练，假设删除的信息无法恢复。&lt;h4&gt;目的&lt;/h4&gt;挑战假设删除的信息无法恢复，研究是否可以通过黑盒访问未学习的GNN和部分图知识来重建删除的边。&lt;h4&gt;方法&lt;/h4&gt;提出了TrendAttack，通过利用模型对未学习边附近节点的信心下降这一理论和实证模式，以及设计自适应预测机制，对不同类型的边应用不同的相似度阈值。&lt;h4&gt;主要发现&lt;/h4&gt;发现未学习边附近节点的模型信心显著下降，并设计了一种自适应预测机制，该机制可以根据不同的边类型调整相似度阈值。&lt;h4&gt;结论&lt;/h4&gt;实验表明，TrendAttack在四个真实世界数据集上显著优于现有的GNN成员推断基线，揭示了当前图反学习方法在隐私保护方面的关键漏洞。&lt;h4&gt;翻译&lt;/h4&gt;Graph unlearning methods aim to efficiently remove the impact of sensitive data from trained GNNs without full retraining, assuming that deleted information cannot be recovered. In this work, we challenge this assumption by introducing the graph unlearning inversion attack: given only black-box access to an unlearned GNN and partial graph knowledge, can an adversary reconstruct the removed edges? We identify two key challenges: varying probability-similarity thresholds for unlearned versus retained edges, and the difficulty of locating unlearned edge endpoints, and address them with TrendAttack. First, we derive and exploit the confidence pitfall, a theoretical and empirical pattern showing that nodes adjacent to unlearned edges exhibit a large drop in model confidence. Second, we design an adaptive prediction mechanism that applies different similarity thresholds to unlearned and other membership edges. Our framework flexibly integrates existing membership inference techniques and extends them with trend features. Experiments on four real-world datasets demonstrate that TrendAttack significantly outperforms state-of-the-art GNN membership inference baselines, exposing a critical privacy vulnerability in current graph unlearning methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph unlearning methods aim to efficiently remove the impact of sensitivedata from trained GNNs without full retraining, assuming that deletedinformation cannot be recovered. In this work, we challenge this assumption byintroducing the graph unlearning inversion attack: given only black-box accessto an unlearned GNN and partial graph knowledge, can an adversary reconstructthe removed edges? We identify two key challenges: varyingprobability-similarity thresholds for unlearned versus retained edges, and thedifficulty of locating unlearned edge endpoints, and address them withTrendAttack. First, we derive and exploit the confidence pitfall, a theoreticaland empirical pattern showing that nodes adjacent to unlearned edges exhibit alarge drop in model confidence. Second, we design an adaptive predictionmechanism that applies different similarity thresholds to unlearned and othermembership edges. Our framework flexibly integrates existing membershipinference techniques and extends them with trend features. Experiments on fourreal-world datasets demonstrate that TrendAttack significantly outperformsstate-of-the-art GNN membership inference baselines, exposing a criticalprivacy vulnerability in current graph unlearning methods.</description>
      <author>example@mail.com (Jiahao Zhang, Yilong Wang, Zhiwei Zhang, Xiaorui Liu, Suhang Wang)</author>
      <guid isPermaLink="false">2506.00808v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Domain Adaptation-Driven Physics-Informed Graph Representation Learning for AC-OPF</title>
      <link>http://arxiv.org/abs/2506.00478v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的AC-OPF求解器DDA-PIGCN，用于优化发电机功率输出，并通过结合时空特征来克服传统方法在约束建模和知识表示方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;当前AC-OPF求解器难以有效表示约束空间中变量分布与最优解之间的复杂关系，且仅基于空间拓扑建模电力系统限制了额外先验知识的整合。&lt;h4&gt;目的&lt;/h4&gt;提出DDA-PIGCN方法，旨在解决约束相关的问题，并构建一个结合时空特征的图学习框架。&lt;h4&gt;方法&lt;/h4&gt;DDA-PIGCN采用多层硬物理信息约束来改进具有不同长程依赖关系的特征的一致性优化，并使用动态域适应学习机制在预定义约束下迭代更新和细化关键状态变量。它通过利用电力网的物理结构捕捉发电机和负荷之间的时空依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;通过在多个IEEE标准测试案例（如案例9、案例30和案例300）上的比较和消融研究，DDA-PIGCN表现出色，平均绝对误差（MAE）在0.0011到0.0624之间，约束满意度在99.6%到100%之间。&lt;h4&gt;结论&lt;/h4&gt;DDA-PIGCN是一种可靠且高效的AC-OPF求解器，为电力系统优化提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Alternating Current Optimal Power Flow (AC-OPF) aims to optimize generatorpower outputs by utilizing the non-linear relationships between voltagemagnitudes and phase angles in a power system. However, current AC-OPF solversstruggle to effectively represent the complex relationship between variabledistributions in the constraint space and their corresponding optimalsolutions. This limitation in constraint modeling restricts the system'sability to develop diverse knowledge representations. Additionally, modelingthe power grid solely based on spatial topology further limits the integrationof additional prior knowledge, such as temporal information. To overcome thesechallenges, we propose DDA-PIGCN (Dynamic Domain Adaptation-DrivenPhysics-Informed Graph Convolutional Network), a new method designed to addressconstraint-related issues and build a graph-based learning framework thatincorporates spatiotemporal features. DDA-PIGCN improves consistencyoptimization for features with varying long-range dependencies by applyingmulti-layer, hard physics-informed constraints. It also uses a dynamic domainadaptation learning mechanism that iteratively updates and refines key statevariables under predefined constraints, enabling precise constraintverification. Moreover, it captures spatiotemporal dependencies betweengenerators and loads by leveraging the physical structure of the power grid,allowing for deep integration of topological information across time and space.Extensive comparative and ablation studies show that DDA-PIGCN delivers strongperformance across several IEEE standard test cases (such as case9, case30, andcase300), achieving mean absolute errors (MAE) from 0.0011 to 0.0624 andconstraint satisfaction rates between 99.6% and 100%, establishing it as areliable and efficient AC-OPF solver.</description>
      <author>example@mail.com (Hongjie Zhu, Zezheng Zhang, Zeyu Zhang, Yu Bai, Shimin Wen, Huazhang Wang, Daji Ergu, Ying Cai, Yang Zhao)</author>
      <guid isPermaLink="false">2506.00478v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MOOSE: Pay Attention to Temporal Dynamics for Video Understanding via Optical Flows</title>
      <link>http://arxiv.org/abs/2506.01119v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MOOSE的新型视频编码器，该编码器通过结合光流和空间嵌入来高效地建模时间信息，旨在解决视频分析中的时间动态捕捉问题。&lt;h4&gt;背景&lt;/h4&gt;许多视频分析任务需要高效且可解释的时间建模，如原子动作、自闭症患者的异常运动行为检测或实时MRI中的人类语音的发音运动分析。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的视频理解架构，以减少计算复杂度并提高时间动态建模的可解释性。&lt;h4&gt;方法&lt;/h4&gt;MOOSE利用预训练的视觉和光流编码器，而不是从头开始训练视频模型，从而实现高效的时态建模。&lt;h4&gt;主要发现&lt;/h4&gt;MOOSE在多个基准测试中取得了最先进的性能，包括临床、医学和标准动作识别数据集，证明了其广泛的应用性和有效性。&lt;h4&gt;结论&lt;/h4&gt;MOOSE通过结合光流和空间嵌入，为视频分析中的时间建模提供了一种高效且可解释的方法，显著提高了性能并降低了计算成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many motion-centric video analysis tasks, such as atomic actions, detectingatypical motor behavior in individuals with autism, or analyzing articulatorymotion in real-time MRI of human speech, require efficient and interpretabletemporal modeling. Capturing temporal dynamics is a central challenge in videoanalysis, often requiring significant computational resources and fine-grainedannotations that are not widely available. This paper presents MOOSE (MotionFlow Over Spatial Space), a novel temporally-centric video encoder explicitlyintegrating optical flow with spatial embeddings to model temporal informationefficiently, inspired by human perception of motion. Unlike prior models, MOOSEtakes advantage of rich, widely available pre-trained visual and optical flowencoders instead of training video models from scratch. This significantlyreduces computational complexity while enhancing temporal interpretability. Ourprimary contributions includes (1) proposing a computationally efficienttemporally-centric architecture for video understanding (2) demonstratingenhanced interpretability in modeling temporal dynamics; and (3) achievingstate-of-the-art performance on diverse benchmarks, including clinical,medical, and standard action recognition datasets, confirming the broadapplicability and effectiveness of our approach.</description>
      <author>example@mail.com (Hong Nguyen, Dung Tran, Hieu Hoang, Phong Nguyen, Shrikanth Narayanan)</author>
      <guid isPermaLink="false">2506.01119v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Minimax Rates for the Estimation of Eigenpairs of Weighted Laplace-Beltrami Operators on Manifolds</title>
      <link>http://arxiv.org/abs/2506.00171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了从分布在流形上的分布ρ的样本中估计椭圆微分算子特征对的问题。文章中讨论的算子与无监督学习相关，特别是通过数据云上的常用图拉普拉斯算子的适当缩放极限获得。&lt;h4&gt;背景&lt;/h4&gt;该研究背景涉及椭圆微分算子特征对的估计，这些算子在无监督学习中具有重要意义，特别是在从数据云上获得的常用图拉普拉斯算子的适当缩放极限。&lt;h4&gt;目的&lt;/h4&gt;研究此特征对估计问题的最小-最大风险，并探索由随机数据构建的常用图拉普拉斯算子能够达到的近似率。&lt;h4&gt;方法&lt;/h4&gt;假设ρ属于具有受控二阶导数的某个分布族，并且ρ支持的d维流形M具有有界几何，证明了在H^1(M)意义上逼近特征值和特征向量的统计最小-最大率是n^{-2/(d+4)}，该率与相关密度估计问题的最小-最大率相匹配。此外，分析了在大数据极限下研究近邻图上的拉普拉斯算子的文献，证明了在数据生成模型上更强的正则性假设下，图拉普拉斯算子的特征对可以诱导出对流形无知的估计器，其近似误差（对数修正项除外）与我们的下界相匹配。&lt;h4&gt;主要发现&lt;/h4&gt;1) 与过去分析的近似误差度量相比，我们考虑了更强的范数来度量近似误差；2) 我们的收敛率在一系列光滑分布上是统一的，不仅适用于具有特殊对称性的密度，而且由于我们的下界，当图连通性足够高时，在本质上是最优的。&lt;h4&gt;结论&lt;/h4&gt;本研究扩展了基于图的学习的现有文献，通过考虑更强的范数和统一的收敛率，提供了对图拉普拉斯算子特征对估计问题的深入理解。&lt;h4&gt;翻译&lt;/h4&gt;本研究研究了从分布在流形上的分布ρ的样本中估计椭圆微分算子特征对的问题。文章中讨论的算子与无监督学习相关，特别是通过数据云上常用图拉普拉斯算子的适当缩放极限获得。我们研究了此特征对估计问题的最小-最大风险，并探索了由随机数据构建的常用图拉普拉斯算子能够达到的近似率。具体而言，假设ρ属于具有受控二阶导数的某个分布族，并且ρ支持的d维流形M具有有界几何，我们证明了在H^1(M)意义上逼近特征值和特征向量的统计最小-最大率是n^{-2/(d+4)}，该率与相关密度估计问题的最小-最大率相匹配。然后，我们回顾了在大数据极限下研究近邻图上的拉普拉斯算子的文献，并证明了在数据生成模型上更强的正则性假设下，图拉普拉斯算子的特征对可以诱导出对流形无知的估计器，其近似误差（对数修正项除外）与我们的下界相匹配。我们的分析使我们能够以至少两种显著方式扩展基于图的学习的现有文献：1) 我们考虑了比过去分析的更强的范数来度量近似误差；2) 我们的收敛率在一系列光滑分布上是统一的，不仅适用于具有特殊对称性的密度，而且由于我们的下界，当图连通性足够高时，在本质上是最优的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the problem of estimating eigenpairs of elliptic differentialoperators from samples of a distribution $\rho$ supported on a manifold $M$.The operators discussed in the paper are relevant in unsupervised learning andin particular are obtained by taking suitable scaling limits of widely usedgraph Laplacians over data clouds. We study the minimax risk for this eigenpairestimation problem and explore the rates of approximation that can be achievedby commonly used graph Laplacians built from random data. More concretely,assuming that $\rho$ belongs to a certain family of distributions withcontrolled second derivatives, and assuming that the $d$-dimensional manifold$M$ where $\rho$ is supported has bounded geometry, we prove that thestatistical minimax rate for approximating eigenvalues and eigenvectors in the$H^1(M)$-sense is $n^{-2/(d+4)}$, a rate that matches the minimax rate for aclosely related density estimation problem. We then revisit the literaturestudying Laplacians over proximity graphs in the large data limit and provethat, under slightly stronger regularity assumptions on the data generatingmodel, eigenpairs of graph Laplacians induce manifold agnostic estimators withan error of approximation that, up to logarithmic corrections, matches ourlower bounds. Our analysis allows us to expand the existing literature ongraph-based learning in at least two significant ways: 1) we consider strongernorms to measure the error of approximation than the ones that had beenanalyzed in the past; 2) our rates of convergence are uniform over a family ofsmooth distributions and do not just apply to densities with specialsymmetries, and, as a consequence of our lower bounds, are essentially sharpwhen the connectivity of the graph is sufficiently high.</description>
      <author>example@mail.com (Nicolás García Trillos, Chenghui Li, Raghavendra Venkatraman)</author>
      <guid isPermaLink="false">2506.00171v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>A Brain Graph Foundation Model: Pre-Training and Prompt-Tuning for Any Atlas and Disorder</title>
      <link>http://arxiv.org/abs/2506.02044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  34pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BrainGFM的大规模脑基础模型，该模型利用图对比学习和图掩码自动编码器进行大规模fMRI预训练，旨在推进神经科学研究。&lt;h4&gt;背景&lt;/h4&gt;随着大型语言模型在AI研究中的革命性发展，构建大规模脑基础模型以推进神经科学的研究越来越受到关注。&lt;h4&gt;目的&lt;/h4&gt;通过提出一种新的图预训练范式，构建一个统一的BrainGFM框架，以促进对大规模fMRI数据的处理和分析。&lt;h4&gt;方法&lt;/h4&gt;BrainGFM采用图对比学习和图掩码自动编码器进行预训练，并在多样化的脑图谱上预训练，以增强模型的泛化能力。同时，整合图提示和语言提示，以支持高效的下游迁移，并使用元学习优化图提示。&lt;h4&gt;主要发现&lt;/h4&gt;BrainGFM在27个神经影像数据集上进行预训练，覆盖25种常见的神经和精神疾病，包括8种常用的脑分区，涉及25000多个受试者和400000个图样本。&lt;h4&gt;结论&lt;/h4&gt;BrainGFM能够有效适应多种图谱、神经和精神疾病以及任务设置，并通过语言引导的提示实现强泛化。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为BrainGFM的大规模脑基础模型，利用图对比学习和图掩码自动编码器进行大规模fMRI预训练，旨在推进神经科学研究。该模型在27个神经影像数据集上预训练，覆盖25种常见的神经和精神疾病，包括8种常用的脑分区，涉及25000多个受试者和400000个图样本。BrainGFM能够有效适应多种图谱、神经和精神疾病以及任务设置，并通过语言引导的提示实现强泛化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As large language models (LLMs) continue to revolutionize AI research, thereis a growing interest in building large-scale brain foundation models toadvance neuroscience. While most existing brain foundation models arepre-trained on time-series signals or region-of-interest (ROI) features, wepropose a novel graph-based pre-training paradigm for constructing a braingraph foundation model. In this paper, we introduce the Brain Graph FoundationModel, termed BrainGFM, a unified framework that leverages graph contrastivelearning and graph masked autoencoders for large-scale fMRI-based pre-training.BrainGFM is pre-trained on a diverse mixture of brain atlases with varyingparcellations, significantly expanding the pre-training corpus and enhancingthe model's ability to generalize across heterogeneous fMRI-derived brainrepresentations. To support efficient and versatile downstream transfer, weintegrate both graph prompts and language prompts into the model design,enabling BrainGFM to flexibly adapt to a wide range of atlases, neurologicaland psychiatric disorders, and task settings. Furthermore, we employmeta-learning to optimize the graph prompts, facilitating strong generalizationto previously unseen disorders under both few-shot and zero-shot learningconditions via language-guided prompting. BrainGFM is pre-trained on 27neuroimaging datasets spanning 25 common neurological and psychiatricdisorders, encompassing 2 types of brain atlases (functional and anatomical)across 8 widely-used parcellations, and covering over 25,000 subjects, 60,000fMRI scans, and a total of 400,000 graph samples aggregated across all atlasesand parcellations. The code is available at:https://github.com/weixinxu666/BrainGFM</description>
      <author>example@mail.com (Xinxu Wei, Kanhao Zhao, Yong Jiao, Lifang He, Yu Zhang)</author>
      <guid isPermaLink="false">2506.02044v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MINT: Multimodal Instruction Tuning with Multimodal Interaction Grouping</title>
      <link>http://arxiv.org/abs/2506.02308v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了多模态基础模型在多个任务上的最新进展，分析了任务分组策略对多模态指令微调性能的影响。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型在多个任务上取得了最先进的性能，这些进展主要得益于新的预训练范式，这些范式利用大规模、未标记的多模态数据，随后在精心挑选的标记数据集和高质量提示上进行指令微调。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过任务分组策略提高多模态指令微调的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了MINT，一种基于多模态交互类型的简单而有效的任务分组策略，并通过实验证明其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，仅增加指令微调任务的数量并不总是能带来更好的性能。相反，通过将任务按模态间的共同交互分组，如发现冗余共享信息、优先选择具有独特信息的模态或要求协同融合以从两种模态中发现新信息，可以鼓励模型在组内学习可迁移的技能，同时抑制不匹配任务的干扰。&lt;h4&gt;结论&lt;/h4&gt;MINT方法在多模态指令微调的任务分组方面优于现有的基线方法，在泛化与专业化之间取得了有效的平衡。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Recent advances in multimodal foundation models have achieved state-of-the-art performance across a range of tasks. These breakthroughs are largely driven by new pre-training paradigms that leverage large-scale, unlabeled multimodal data, followed by instruction fine-tuning on curated labeled datasets and high-quality prompts. While there is growing interest in scaling instruction fine-tuning to ever-larger datasets in both quantity and scale, our findings reveal that simply increasing the number of instruction-tuning tasks does not consistently yield better performance. Instead, we observe that grouping tasks by the common interactions across modalities, such as discovering redundant shared information, prioritizing modality selection with unique information, or requiring synergistic fusion to discover new information from both modalities, encourages the models to learn transferrable skills within a group while suppressing interference from mismatched tasks. To this end, we introduce MINT, a simple yet surprisingly effective task-grouping strategy based on the type of multimodal interaction. We demonstrate that the proposed method greatly outperforms existing task grouping baselines for multimodal instruction tuning, striking an effective balance between generalization and specialization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in multimodal foundation models have achievedstate-of-the-art performance across a range of tasks. These breakthroughs arelargely driven by new pre-training paradigms that leverage large-scale,unlabeled multimodal data, followed by instruction fine-tuning on curatedlabeled datasets and high-quality prompts. While there is growing interest inscaling instruction fine-tuning to ever-larger datasets in both quantity andscale, our findings reveal that simply increasing the number ofinstruction-tuning tasks does not consistently yield better performance.Instead, we observe that grouping tasks by the common interactions acrossmodalities, such as discovering redundant shared information, prioritizingmodality selection with unique information, or requiring synergistic fusion todiscover new information from both modalities, encourages the models to learntransferrable skills within a group while suppressing interference frommismatched tasks. To this end, we introduce MINT, a simple yet surprisinglyeffective task-grouping strategy based on the type of multimodal interaction.We demonstrate that the proposed method greatly outperforms existing taskgrouping baselines for multimodal instruction tuning, striking an effectivebalance between generalization and specialization.</description>
      <author>example@mail.com (Xiaojun Shan, Qi Cao, Xing Han, Haofei Yu, Paul Pu Liang)</author>
      <guid isPermaLink="false">2506.02308v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>A Dynamic Stiefel Graph Neural Network for Efficient Spatio-Temporal Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2506.00798v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DST-SGNN的动态时空斯蒂费尔图神经网络，用于高效处理时空时间序列数据。&lt;h4&gt;背景&lt;/h4&gt;时空时间序列在众多应用中得到了广泛应用，但由于时间和空间维度的复杂动态相关性，准确预测时空时间序列是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有图神经网络在建模动态时空关系时难以平衡有效性和效率的问题。&lt;h4&gt;方法&lt;/h4&gt;本文首先引入了斯蒂费尔图谱卷积（SGSC）和斯蒂费尔图傅里叶变换（SGFT），并通过线性动态图优化在斯蒂费尔流形上（LDGOSM）学习SGFT矩阵，从而显著降低计算复杂度。此外，还提出了多层SGSC（MSGSC）来有效地捕捉复杂的时空相关性。&lt;h4&gt;主要发现&lt;/h4&gt;在七个时空数据集上的广泛实验表明，DST-SGNN在保持相对较低的计算成本的同时，优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;DST-SGNN是一种有效且高效的时空时间序列预测方法，在多个应用场景中具有潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatio-temporal time series (STTS) have been widely used in manyapplications. However, accurately forecasting STTS is challenging due tocomplex dynamic correlations in both time and space dimensions. Existing graphneural networks struggle to balance effectiveness and efficiency in modelingdynamic spatio-temporal relations. To address this problem, we propose theDynamic Spatio-Temporal Stiefel Graph Neural Network (DST-SGNN) to efficientlyprocess STTS. For DST-SGNN, we first introduce the novel Stiefel Graph SpectralConvolution (SGSC) and Stiefel Graph Fourier Transform (SGFT). The SGFT matrixin SGSC is constrained to lie on the Stiefel manifold, and SGSC can be regardedas a filtered graph spectral convolution. We also propose the Linear DynamicGraph Optimization on Stiefel Manifold (LDGOSM), which can efficiently learnthe SGFT matrix from the dynamic graph and significantly reduce thecomputational complexity. Finally, we propose a multi-layer SGSC (MSGSC) thatefficiently captures complex spatio-temporal correlations. Extensiveexperiments on seven spatio-temporal datasets show that DST-SGNN outperformsstate-of-the-art methods while maintaining relatively low computational costs.</description>
      <author>example@mail.com (Jiankai Zheng, Liang Xie)</author>
      <guid isPermaLink="false">2506.00798v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>On Designing Diffusion Autoencoders for Efficient Generation and Representation Learning</title>
      <link>http://arxiv.org/abs/2506.00136v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 10 tables, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了扩散自编码器（DAs），这是一种扩散生成模型的变体，它使用输入相关的潜在变量来捕捉扩散过程中的表示。这些表示可以用于下游任务，如分类、可控生成和插值。文章探讨了DAs的生成性能依赖于潜在变量的建模和采样，并提出了一种新的模型DMZ，它结合了两种模型的优势，即有效的表示和高效的建模与生成。&lt;h4&gt;背景&lt;/h4&gt;扩散自编码器（DAs）是一种生成模型，它通过扩散过程来学习数据的潜在表示。DAs的性能受到潜在变量建模和采样方法的影响。&lt;h4&gt;目的&lt;/h4&gt;提高扩散自编码器的生成性能，同时保持有效的表示和高效的建模与生成。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的模型DMZ，通过连接两种扩散模型（DAs和那些学习正向（噪声）过程的模型）的设计决策，如潜在变量选择和条件化方法。&lt;h4&gt;主要发现&lt;/h4&gt;DMZ模型通过结合两种模型的优势，实现了在下游任务（包括领域迁移）上的有效表示，并且与标准扩散模型相比，具有更高效的建模和生成，减少了去噪步骤。&lt;h4&gt;结论&lt;/h4&gt;DMZ模型通过改进潜在变量的建模和采样，实现了在生成性能和表示有效性方面的提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/exlab-research/dmz&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion autoencoders (DAs) are variants of diffusion generative models thatuse an input-dependent latent variable to capture representations alongside thediffusion process. These representations, to varying extents, can be used fortasks such as downstream classification, controllable generation, andinterpolation. However, the generative performance of DAs relies heavily on howwell the latent variables can be modelled and subsequently sampled from. Bettergenerative modelling is also the primary goal of another class of diffusionmodels -- those that learn their forward (noising) process. While effective atadjusting the noise process in an input-dependent manner, they must satisfyadditional constraints derived from the terminal conditions of the diffusionprocess. Here, we draw a connection between these two classes of models andshow that certain design decisions (latent variable choice, conditioningmethod, etc.) in the DA framework -- leading to a model we term DMZ -- allow usto obtain the best of both worlds: effective representations as evaluated ondownstream tasks, including domain transfer, as well as more efficientmodelling and generation with fewer denoising steps compared to standard DMs.</description>
      <author>example@mail.com (Magdalena Proszewska, Nikolay Malkin, N. Siddharth)</author>
      <guid isPermaLink="false">2506.00136v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>FlexSelect: Flexible Token Selection for Efficient Long Video Understanding</title>
      <link>http://arxiv.org/abs/2506.00993v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FlexSelect是一种灵活且高效的标记选择策略，用于处理长视频，旨在降低视频大语言模型（VideoLLMs）的复杂性和内存需求。&lt;h4&gt;背景&lt;/h4&gt;长视频理解对视频大语言模型（VideoLLMs）来说是一个重大挑战，因为其计算和内存需求过高。&lt;h4&gt;目的&lt;/h4&gt;提出FlexSelect，以识别和保留最相关的语义内容，从而提高长视频理解的效率。&lt;h4&gt;方法&lt;/h4&gt;FlexSelect利用参考Transformer层的跨模态注意力模式，包括：（1）一个无需训练的标记排名管道，利用忠实的跨模态注意力权重来估计每个视频标记的重要性；（2）一个排名监督的轻量级选择器，用于复制这些排名并过滤冗余标记。&lt;h4&gt;主要发现&lt;/h4&gt;FlexSelect可以无缝集成到各种VideoLLM架构中，如LLaVA-Video、InternVL和Qwen-VL，显著提高了多个长视频基准测试的性能，并实现了显著的加速（例如，在LLaVA-Video-7B模型上达到9倍）。&lt;h4&gt;结论&lt;/h4&gt;FlexSelect在提高长视频理解效率方面具有巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译：Long-form video understanding poses a significant challenge for video large language models (VideoLLMs) due to prohibitively high computational and memory demands. In this paper, we propose FlexSelect, a flexible and efficient token selection strategy for processing long videos. FlexSelect identifies and retains the most semantically relevant content by leveraging cross-modal attention patterns from a reference transformer layer. It comprises two key components: (1) a training-free token ranking pipeline that leverages faithful cross-modal attention weights to estimate each video token's importance, and (2) a rank-supervised lightweight selector that is trained to replicate these rankings and filter redundant tokens. This generic approach can be seamlessly integrated into various VideoLLM architectures, such as LLaVA-Video, InternVL, and Qwen-VL, serving as a plug-and-play module to extend their temporal context length. Empirically, FlexSelect delivers strong gains across multiple long-video benchmarks including VideoMME, MLVU, LongVB, and LVBench. Moreover, it achieves significant speed-ups (for example, up to 9 times on a LLaVA-Video-7B model), highlighting FlexSelect's promise for efficient long-form video understanding. Project page available at: https://yunzhuzhang0918.github.io/flex_select&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-form video understanding poses a significant challenge for video largelanguage models (VideoLLMs) due to prohibitively high computational and memorydemands. In this paper, we propose FlexSelect, a flexible and efficient tokenselection strategy for processing long videos. FlexSelect identifies andretains the most semantically relevant content by leveraging cross-modalattention patterns from a reference transformer layer. It comprises two keycomponents: (1) a training-free token ranking pipeline that leverages faithfulcross-modal attention weights to estimate each video token's importance, and(2) a rank-supervised lightweight selector that is trained to replicate theserankings and filter redundant tokens. This generic approach can be seamlesslyintegrated into various VideoLLM architectures, such as LLaVA-Video, InternVLand Qwen-VL, serving as a plug-and-play module to extend their temporal contextlength. Empirically, FlexSelect delivers strong gains across multiplelong-video benchmarks including VideoMME, MLVU, LongVB, and LVBench. Moreover,it achieves significant speed-ups (for example, up to 9 times on aLLaVA-Video-7B model), highlighting FlexSelect's promise for efficientlong-form video understanding. Project page available at:https://yunzhuzhang0918.github.io/flex_select</description>
      <author>example@mail.com (Yunzhu Zhang, Yu Lu, Tianyi Wang, Fengyun Rao, Yi Yang, Linchao Zhu)</author>
      <guid isPermaLink="false">2506.00993v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>M3ANet: Multi-scale and Multi-Modal Alignment Network for Brain-Assisted Target Speaker Extraction</title>
      <link>http://arxiv.org/abs/2506.00466v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于脑辅助的目标说话人提取方法，通过利用脑神经活动（如脑电图EEG）来从混合语音中提取目标说话人的语音。&lt;h4&gt;背景&lt;/h4&gt;现有的目标说话人提取模型忽略了语音和脑电图模态之间的时间不一致性问题，影响了提取性能。此外，当前模型中的语音编码器通常使用基本的时序操作（如一维卷积），无法有效提取目标说话人信息。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文提出了一种多尺度多模态对齐网络（M3ANet）。&lt;h4&gt;方法&lt;/h4&gt;1. 使用对比学习策略的模态对齐模块来消除脑电图和语音模态之间的时间不一致性。2. 使用带有GroupMamba模块的多尺度卷积作为语音编码器，从不同方向扫描每个尺度的语音特征，使模型能够捕获深层次的序列信息。&lt;h4&gt;主要发现&lt;/h4&gt;在三个公开数据集上的实验结果表明，所提出的模型在各种评估指标上优于现有最先进的方法，突出了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在目标说话人提取任务中表现出色，为脑辅助语音处理提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：脑辅助目标说话人提取（TSE）旨在通过利用脑神经活动（例如脑电图EEG）从混合语音中提取被关注的语音。然而，现有模型忽略了语音和脑电图模态之间时间不一致的问题，这阻碍了TSE的性能。此外，当前模型中的语音编码器通常使用基本的时序操作（例如一维卷积），这些操作无法有效地提取目标说话人信息。为了解决这些问题，本文提出了一种用于脑辅助TSE的多尺度多模态对齐网络（M3ANet）。具体来说，为了消除脑电图和语音模态之间的时间不一致性，应用了对比学习策略的模态对齐模块来对齐两种模态的时间特征。此外，为了充分提取语音信息，使用带有GroupMamba模块的多尺度卷积作为语音编码器，从不同方向扫描每个尺度的语音特征，使模型能够捕获深层次的序列信息。在三个公开数据集上的实验结果表明，所提出的模型在各种评估指标上优于现有最先进的方法，突出了我们提出方法的有效性。源代码可在以下链接获取：https://github.com/fchest/M3ANet。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The brain-assisted target speaker extraction (TSE) aims to extract theattended speech from mixed speech by utilizing the brain neural activities, forexample Electroencephalography (EEG). However, existing models overlook theissue of temporal misalignment between speech and EEG modalities, which hampersTSE performance. In addition, the speech encoder in current models typicallyuses basic temporal operations (e.g., one-dimensional convolution), which areunable to effectively extract target speaker information. To address theseissues, this paper proposes a multi-scale and multi-modal alignment network(M3ANet) for brain-assisted TSE. Specifically, to eliminate the temporalinconsistency between EEG and speech modalities, the modal alignment modulethat uses a contrastive learning strategy is applied to align the temporalfeatures of both modalities. Additionally, to fully extract speech information,multi-scale convolutions with GroupMamba modules are used as the speechencoder, which scans speech features at each scale from different directions,enabling the model to capture deep sequence information. Experimental resultson three publicly available datasets show that the proposed model outperformscurrent state-of-the-art methods across various evaluation metrics,highlighting the effectiveness of our proposed method. The source code isavailable at: https://github.com/fchest/M3ANet.</description>
      <author>example@mail.com (Cunhang Fan, Ying Chen, Jian Zhou, Zexu Pan, Jingjing Zhang, Youdian Gao, Xiaoke Yang, Zhengqi Wen, Zhao Lv)</author>
      <guid isPermaLink="false">2506.00466v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Improving Knowledge Distillation Under Unknown Covariate Shift Through Confidence-Guided Data Augmentation</title>
      <link>http://arxiv.org/abs/2506.02294v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散的数据增强策略，旨在解决知识蒸馏中的协变量偏移问题，通过最大化教师和学生之间的不一致性来生成挑战性样本，提高学生网络的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;大型基础模型在广泛数据集上展现出强大的零样本能力，但数据量和模型尺寸受限时，知识蒸馏成为将知识从基础模型传递到小型学生网络的有效工具。&lt;h4&gt;目的&lt;/h4&gt;针对知识蒸馏中常见的协变量偏移问题，即训练时出现但在测试时未出现的虚假特征，研究如何使学生在教师模型鲁棒的前提下，也能对虚假特征表现出鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;引入了一种基于扩散的数据增强策略，通过最大化教师和学生之间的不一致性来生成图像，从而创建学生难以处理的挑战性样本。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在CelebA和SpuCo Birds数据集上显著提高了最差组和平均组的准确率，以及在协变量偏移下的虚假ImageNet数据集上的虚假AUC，超越了现有的基于扩散的数据增强基线。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地提高了学生网络的鲁棒性，在知识蒸馏中取得了优于现有方法的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large foundation models trained on extensive datasets demonstrate strongzero-shot capabilities in various domains. To replicate their success when dataand model size are constrained, knowledge distillation has become anestablished tool for transferring knowledge from foundation models to smallstudent networks. However, the effectiveness of distillation is criticallylimited by the available training data. This work addresses the commonpractical issue of covariate shift in knowledge distillation, where spuriousfeatures appear during training but not at test time. We ask the question: whenthese spurious features are unknown, yet a robust teacher is available, is itpossible for a student to also become robust to them? We address this problemby introducing a novel diffusion-based data augmentation strategy thatgenerates images by maximizing the disagreement between the teacher and thestudent, effectively creating challenging samples that the student struggleswith. Experiments demonstrate that our approach significantly improves worstgroup and mean group accuracy on CelebA and SpuCo Birds as well as the spuriousmAUC on spurious ImageNet under covariate shift, outperforming state-of-the-artdiffusion-based data augmentation baselines</description>
      <author>example@mail.com (Niclas Popp, Kevin Alexander Laube, Matthias Hein, Lukas Schott)</author>
      <guid isPermaLink="false">2506.02294v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Amatriciana: Exploiting Temporal GNNs for Robust and Efficient Money Laundering Detection</title>
      <link>http://arxiv.org/abs/2506.00654v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Amatriciana，一种基于图神经网络的创新方法，用于检测交易图中的洗钱行为，并考虑了时间信息。该方法在公共数据集上的实验表明，Amatriciana能够从有限的数据中学习，并且当数据量增加时，其性能优于其他最先进的方法，尤其是在减少误报率方面。&lt;h4&gt;背景&lt;/h4&gt;洗钱是一种对金融安全和社交安全构成严重威胁的金融犯罪。随着交易数量的增加，需要使用自动工具来帮助执法机构检测此类犯罪活动。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效检测洗钱行为的自动工具。&lt;h4&gt;方法&lt;/h4&gt;Amatriciana方法基于图神经网络，考虑了时间信息，并利用了整个交易图中的所有关系信息，而不是将其分割成基于时间段的子图。&lt;h4&gt;主要发现&lt;/h4&gt;Amatriciana模型可以从有限的数据中学习，并且当数据量增加时，其性能优于其他最先进的方法。Amatriciana在检测洗钱者时，减少了误报率，达到了0.76的F1分数，并且与其他最先进模型相比，误报率降低了55%。&lt;h4&gt;结论&lt;/h4&gt;Amatriciana是一种有效的洗钱检测工具，能够减少误报率，提高检测准确率。&lt;h4&gt;翻译&lt;/h4&gt;Money laundering is a financial crime that poses a serious threat to financial integrity and social security. The growing number of transactions makes it necessary to use automatic tools that help law enforcement agencies detect such criminal activity. In this work, we present Amatriciana, a novel approach based on Graph Neural Networks to detect money launderers inside a graph of transactions by considering temporal information. Amatriciana uses the whole graph of transactions without splitting it into several time-based subgraphs, exploiting all relational information in the dataset. Our experiments on a public dataset reveal that the model can learn from a limited amount of data. Furthermore, when more data is available, the model outperforms other State-of-the-art approaches; in particular, Amatriciana decreases the number of False Positives (FPs) while detecting many launderers. In summary, Amatriciana achieves an F1 score of 0.76. In addition, it lowers the FPs by 55% with respect to other State-of-the-art models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICDMW65004.2024.00039&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Money laundering is a financial crime that poses a serious threat tofinancial integrity and social security. The growing number of transactionsmakes it necessary to use automatic tools that help law enforcement agenciesdetect such criminal activity. In this work, we present Amatriciana, a novelapproach based on Graph Neural Networks to detect money launderers inside agraph of transactions by considering temporal information. Amatriciana uses thewhole graph of transactions without splitting it into several time-basedsubgraphs, exploiting all relational information in the dataset. Ourexperiments on a public dataset reveal that the model can learn from a limitedamount of data. Furthermore, when more data is available, the model outperformsother State-of-the-art approaches; in particular, Amatriciana decreases thenumber of False Positives (FPs) while detecting many launderers. In summary,Amatriciana achieves an F1 score of 0.76. In addition, it lowers the FPs by 55%with respect to other State-of-the-art models.</description>
      <author>example@mail.com (Marco Di Gennaro, Francesco Panebianco, Marco Pianta, Stefano Zanero, Michele Carminati)</author>
      <guid isPermaLink="false">2506.00654v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Deep Temporal Reasoning in Video Language Models: A Cross-Linguistic Evaluation of Action Duration and Completion through Perfect Times</title>
      <link>http://arxiv.org/abs/2506.00928v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了人类对事件的感知与区分已完成动作和持续动作的能力，这一过程受到语言结构和视觉线索的共同影响。&lt;h4&gt;背景&lt;/h4&gt;人类感知事件与区分已完成（完美和目的）和持续动作有内在联系，这一过程由语言结构和视觉线索共同介导。&lt;h4&gt;目的&lt;/h4&gt;提出一个名为“完美时间”的数据集，用于评估视频语言模型（VLMs）在时间推理方面的能力。&lt;h4&gt;方法&lt;/h4&gt;该数据集包含日常活动视频、事件完成标签和针对完美性定制的干扰项，以检测模型是否真正理解时间动态，而不是仅仅依赖于表面标记。&lt;h4&gt;主要发现&lt;/h4&gt;尽管在基于文本的任务上表现出色，但最先进的模型在模仿人类基于视频的时间因果推理方面仍存在困难。&lt;h4&gt;结论&lt;/h4&gt;强调了整合深度多模态线索以捕捉时间和因果视频动态中动作持续时间和完成度的细微差异的必要性，为评估和推进VLMs中的时间推理设定了新的标准。&lt;h4&gt;翻译&lt;/h4&gt;人类对事件的感知与区分已完成（完美和目的）和持续动作有内在联系，这一过程由语言结构和视觉线索共同介导。本研究提出了“完美时间”数据集，旨在评估视频语言模型（VLMs）在时间推理方面的能力。该数据集包含日常活动视频、事件完成标签和针对完美性定制的干扰项，以检测模型是否真正理解时间动态，而不是仅仅依赖于表面标记。尽管在基于文本的任务上表现出色，但最先进的模型在模仿人类基于视频的时间因果推理方面仍存在困难。该研究强调了整合深度多模态线索以捕捉时间和因果视频动态中动作持续时间和完成度的细微差异的必要性，为评估和推进VLMs中的时间推理设定了新的标准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human perception of events is intrinsically tied to distinguishing betweencompleted (perfect and telic) and ongoing (durative) actions, a processmediated by both linguistic structure and visual cues. In this work, weintroduce the \textbf{Perfect Times} dataset, a novel, quadrilingual (English,Italian, Russian, and Japanese) multiple-choice question-answering benchmarkdesigned to assess video-language models (VLMs) on temporal reasoning. Bypairing everyday activity videos with event completion labels andperfectivity-tailored distractors, our dataset probes whether models trulycomprehend temporal dynamics or merely latch onto superficial markers.Experimental results indicate that state-of-the-art models, despite theirsuccess on text-based tasks, struggle to mirror human-like temporal and causalreasoning grounded in video. This study underscores the necessity ofintegrating deep multimodal cues to capture the nuances of action duration andcompletion within temporal and causal video dynamics, setting a new standardfor evaluating and advancing temporal reasoning in VLMs.</description>
      <author>example@mail.com (Olga Loginova, Sofía Ortega Loguinova)</author>
      <guid isPermaLink="false">2506.00928v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>A New Spatiotemporal Correlation Anomaly Detection Method that Integrates Contrastive Learning and Few-Shot Learning in Wireless Sensor Networks</title>
      <link>http://arxiv.org/abs/2506.00420v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MTAD-RD的时空相关性检测模型，用于解决无线传感器网络（WSN）异常检测中的挑战。&lt;h4&gt;背景&lt;/h4&gt;WSN异常检测对于评估WSN的可靠性和稳定性至关重要，但现有方法面临诸如时空相关性特征提取有限、缺乏样本标签、异常样本数量少和样本分布不平衡等问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，设计了一种同时考虑模型架构和两阶段训练策略的时空相关性检测模型。&lt;h4&gt;方法&lt;/h4&gt;模型结构设计方面，MTAD-RD包括一个增强的保留网络（RetNet）、一个多粒度特征融合模块和一个图注意力网络模块来提取节点间相关性信息。训练方法方面，采用两阶段训练策略：首先，设计了一个对比学习代理任务，用于学习未标记数据中的可迁移特征；然后，设计了一个基于缓存的样本采样器，将样本分为少量样本和对比学习数据，并开发了一个特定的联合损失函数来训练双图判别网络，以有效解决样本不平衡问题。&lt;h4&gt;主要发现&lt;/h4&gt;在真实公共数据集上的实验表明，MTAD-RD异常检测方法实现了90.97%的F1分数，优于现有的监督WSN异常检测方法。&lt;h4&gt;结论&lt;/h4&gt;MTAD-RD模型在WSN异常检测中表现出色，能够有效解决现有方法的局限性，并提高了检测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting anomalies in the data collected by WSNs can provide crucialevidence for assessing the reliability and stability of WSNs. Existing methodsfor WSN anomaly detection often face challenges such as the limited extractionof spatiotemporal correlation features, the absence of sample labels, fewanomaly samples, and an imbalanced sample distribution. To address theseissues, a spatiotemporal correlation detection model (MTAD-RD) considering bothmodel architecture and a two-stage training strategy perspective is proposed.In terms of model structure design, the proposed MTAD-RD backbone networkincludes a retentive network (RetNet) enhanced by a cross-retention (CR)module, a multigranular feature fusion module, and a graph attention networkmodule to extract internode correlation information. This proposed model canintegrate the intermodal correlation features and spatial features of WSNneighbor nodes while extracting global information from time series data.Moreover, its serialized inference characteristic can remarkably reduceinference overhead. For model training, a two-stage training approach wasdesigned. First, a contrastive learning proxy task was designed for time seriesdata with graph structure information in WSNs, enabling the backbone network tolearn transferable features from unlabeled data using unsupervised contrastivelearning methods, thereby addressing the issue of missing sample labels in thedataset. Then, a caching-based sample sampler was designed to divide samplesinto few-shot and contrastive learning data. A specific joint loss function wasdeveloped to jointly train the dual-graph discriminator network to address theproblem of sample imbalance effectively. In experiments carried out on realpublic datasets, the designed MTAD-RD anomaly detection method achieved an F1score of 90.97%, outperforming existing supervised WSN anomaly detectionmethods.</description>
      <author>example@mail.com (Miao Ye, Suxiao Wang, Jiaguang Han, Yong Wang, Xiaoli Wang, Jingxuan Wei, Peng Wen, Jing Cui)</author>
      <guid isPermaLink="false">2506.00420v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Are Mamba-based Audio Foundation Models the Best Fit for Non-Verbal Emotion Recognition?</title>
      <link>http://arxiv.org/abs/2506.02258v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to EUSIPCO 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于非言语声音的情感识别（NVER），首次探讨了用于NVER的mamba基础音频模型（MAFMs），并假设MAFMs将优于基于注意力的音频基础模型（AAFMs），因为其状态空间建模能更有效地捕捉内在的情感结构。通过实验验证了这一假设，并进一步探索了基础模型（FMs）的融合，提出了RENO模型，该模型使用renyi散度作为新的损失函数，并利用自注意力机制以实现FMs之间的更好交互。&lt;h4&gt;背景&lt;/h4&gt;非言语声音情感识别（NVER）是一个研究领域，本文首次将mamba基础音频模型（MAFMs）应用于此领域。&lt;h4&gt;目的&lt;/h4&gt;研究MAFMs在NVER中的性能，并探索FMs的融合以提升NVER的性能。&lt;h4&gt;方法&lt;/h4&gt;使用MAFMs进行NVER，并将其与基于注意力的音频基础模型（AAFMs）进行比较。此外，提出了一个名为RENO的模型，该模型融合了MAFMs和AAFMs，并使用renyi散度作为损失函数以及自注意力机制。&lt;h4&gt;主要发现&lt;/h4&gt;MAFMs在NVER中表现出色，且与AAFMs相比，能够更有效地捕捉内在情感结构。RENO模型通过融合MAFMs和AAFMs实现了在NVER中的最佳性能。&lt;h4&gt;结论&lt;/h4&gt;MAFMs在NVER中具有优势，RENO模型通过融合FMs进一步提升了NVER的性能，并达到了目前该领域的最先进水平。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we focus on non-verbal vocal sounds emotion recognition (NVER). We investigate mamba-based audio foundation models (MAFMs) for the first time for NVER and hypothesize that MAFMs will outperform attention-based audio foundation models (AAFMs) for NVER by leveraging its state-space modeling to capture intrinsic emotional structures more effectively. Unlike AAFMs, which may amplify irrelevant patterns due to their attention mechanisms, MAFMs will extract more stable and context-aware representations, enabling better differentiation of subtle non-verbal emotional cues. Our experiments with state-of-the-art (SOTA) AAFMs and MAFMs validates our hypothesis. Further, motivated from related research such as speech emotion recognition, synthetic speech detection, where fusion of foundation models (FMs) have showed improved performance, we also explore fusion of FMs for NVER. To this end, we propose, RENO, that uses renyi-divergence as a novel loss function for effective alignment of the FMs. It also makes use of self-attention for better intra-representation interaction of the FMs. With RENO, through the heterogeneous fusion of MAFMs and AAFMs, we show the topmost performance in comparison to individual FMs, its fusion and also setting SOTA in comparison to previous SOTA work.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we focus on non-verbal vocal sounds emotion recognition (NVER).We investigate mamba-based audio foundation models (MAFMs) for the first timefor NVER and hypothesize that MAFMs will outperform attention-based audiofoundation models (AAFMs) for NVER by leveraging its state-space modeling tocapture intrinsic emotional structures more effectively. Unlike AAFMs, whichmay amplify irrelevant patterns due to their attention mechanisms, MAFMs willextract more stable and context-aware representations, enabling betterdifferentiation of subtle non-verbal emotional cues. Our experiments withstate-of-the-art (SOTA) AAFMs and MAFMs validates our hypothesis. Further,motivated from related research such as speech emotion recognition, syntheticspeech detection, where fusion of foundation models (FMs) have showed improvedperformance, we also explore fusion of FMs for NVER. To this end, we propose,RENO, that uses renyi-divergence as a novel loss function for effectivealignment of the FMs. It also makes use of self-attention for betterintra-representation interaction of the FMs. With RENO, through theheterogeneous fusion of MAFMs and AAFMs, we show the topmost performance incomparison to individual FMs, its fusion and also setting SOTA in comparison toprevious SOTA work.</description>
      <author>example@mail.com (Mohd Mujtaba Akhtar, Orchid Chetia Phukan, Girish, Swarup Ranjan Behera, Ananda Chandra Nayak, Sanjib Kumar Nayak, Arun Balaji Buduru, Rajesh Sharma)</author>
      <guid isPermaLink="false">2506.02258v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>TMetaNet: Topological Meta-Learning Framework for Dynamic Link Prediction</title>
      <link>http://arxiv.org/abs/2506.00453v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于动态图持久同调表示的方法DowkerZigzag Persistence (DZP)和基于动态拓扑特征的元学习参数更新模型TMetaNet，用于解决动态图学习中的挑战。&lt;h4&gt;背景&lt;/h4&gt;动态图由于其结构和时间依赖性的变化，对传统的图学习提出了挑战。现有的元学习方法大多依赖于固定的权重更新参数，忽略了动态图演变的内在复杂高阶拓扑信息。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够捕捉动态图高阶特征的持久同调表示方法，并提出一种基于动态拓扑特征的元学习参数更新模型，以提高动态图学习的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了DZP方法，它基于Dowker复形和zigzag持久性来捕获动态图的高阶特征。同时，提出了TMetaNet模型，该模型通过利用高阶拓扑特征之间的距离，实现更有效的跨时间快照的适应。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，TMetaNet在真实世界数据集上表现出最先进的性能和抗噪声鲁棒性，证明了其在元学习和动态图分析中的高潜力。&lt;h4&gt;结论&lt;/h4&gt;DZP和TMetaNet为动态图学习提供了一种有效的方法，有望提高动态图分析的性能和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a dynamic graph persistent homology representation method DowkerZigzag Persistence (DZP) and a meta-learning parameter update model TMetaNet based on dynamic topological features, to address the challenges in dynamic graph learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic graphs evolve continuously, presenting challenges for traditionalgraph learning due to their changing structures and temporal dependencies.Recent advancements have shown potential in addressing these challenges bydeveloping suitable meta-learning-based dynamic graph neural network models.However, most meta-learning approaches for dynamic graphs rely on fixed weightupdate parameters, neglecting the essential intrinsic complex high-ordertopological information of dynamically evolving graphs. We have designed DowkerZigzag Persistence (DZP), an efficient and stable dynamic graph persistenthomology representation method based on Dowker complex and zigzag persistence,to capture the high-order features of dynamic graphs. Armed with the DZP ideas,we propose TMetaNet, a new meta-learning parameter update model based ondynamic topological features. By utilizing the distances between high-ordertopological features, TMetaNet enables more effective adaptation acrosssnapshots. Experiments on real-world datasets demonstrate TMetaNet'sstate-of-the-art performance and resilience to graph noise, illustrating itshigh potential for meta-learning and dynamic graph analysis. Our code isavailable at https://github.com/Lihaogx/TMetaNet.</description>
      <author>example@mail.com (Hao Li, Hao Wan, Yuzhou Chen, Dongsheng Ye, Yulia Gel, Hao Jiang)</author>
      <guid isPermaLink="false">2506.00453v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>3D Skeleton-Based Action Recognition: A Review</title>
      <link>http://arxiv.org/abs/2506.00915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基于3D骨骼的动作识别进行了全面的综述，强调了任务导向的框架，并分析了该领域的最新进展。&lt;h4&gt;背景&lt;/h4&gt;基于骨骼的动作识别在计算机视觉领域占有一席之地，但之前的综述主要采用模型导向的视角，忽略了骨骼动作识别的基本步骤。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文旨在提供一个全面、任务导向的框架，以加深对骨骼动作识别任务的理解。&lt;h4&gt;方法&lt;/h4&gt;本文将任务分解为一系列子任务，重点关注预处理步骤，如模态推导和数据增强。随后深入讨论了关键子任务，包括特征提取和时空建模技术。此外，还提到了基础动作识别网络以及最新的混合架构、Mamba模型、大型语言模型（LLMs）和生成模型。&lt;h4&gt;主要发现&lt;/h4&gt;本文提供了一个关于公共3D骨骼数据集的全面概述，并分析了在这些基准上评估的最先进算法。&lt;h4&gt;结论&lt;/h4&gt;通过结合任务导向的讨论、对子任务的全面审查以及对最新进展的强调，本文为理解和推进3D骨骼动作识别领域提供了一个基本且易于理解的路线图。&lt;h4&gt;翻译&lt;/h4&gt;With the inherent advantages of skeleton representation, 3D skeleton-based action recognition has become a prominent topic in the field of computer vision. However, previous reviews have predominantly adopted a model-oriented perspective, often neglecting the fundamental steps involved in skeleton-based action recognition. This oversight tends to ignore key components of skeleton-based action recognition beyond model design and has hindered deeper, more intrinsic understanding of the task. To bridge this gap, our review aims to address these limitations by presenting a comprehensive, task-oriented framework for understanding skeleton-based action recognition. We begin by decomposing the task into a series of sub-tasks, placing particular emphasis on preprocessing steps such as modality derivation and data augmentation. The subsequent discussion delves into critical sub-tasks, including feature extraction and spatio-temporal modeling techniques. Beyond foundational action recognition networks, recently advanced frameworks such as hybrid architectures, Mamba models, large language models (LLMs), and generative models have also been highlighted. Finally, a comprehensive overview of public 3D skeleton datasets is presented, accompanied by an analysis of state-of-the-art algorithms evaluated on these benchmarks. By integrating task-oriented discussions, comprehensive examinations of sub-tasks, and an emphasis on the latest advancements, our review provides a fundamental and accessible structured roadmap for understanding and advancing the field of 3D skeleton-based action recognition.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the inherent advantages of skeleton representation, 3D skeleton-basedaction recognition has become a prominent topic in the field of computervision. However, previous reviews have predominantly adopted a model-orientedperspective, often neglecting the fundamental steps involved in skeleton-basedaction recognition. This oversight tends to ignore key components ofskeleton-based action recognition beyond model design and has hindered deeper,more intrinsic understanding of the task. To bridge this gap, our review aimsto address these limitations by presenting a comprehensive, task-orientedframework for understanding skeleton-based action recognition. We begin bydecomposing the task into a series of sub-tasks, placing particular emphasis onpreprocessing steps such as modality derivation and data augmentation. Thesubsequent discussion delves into critical sub-tasks, including featureextraction and spatio-temporal modeling techniques. Beyond foundational actionrecognition networks, recently advanced frameworks such as hybridarchitectures, Mamba models, large language models (LLMs), and generativemodels have also been highlighted. Finally, a comprehensive overview of public3D skeleton datasets is presented, accompanied by an analysis ofstate-of-the-art algorithms evaluated on these benchmarks. By integratingtask-oriented discussions, comprehensive examinations of sub-tasks, and anemphasis on the latest advancements, our review provides a fundamental andaccessible structured roadmap for understanding and advancing the field of 3Dskeleton-based action recognition.</description>
      <author>example@mail.com (Mengyuan Liu, Hong Liu, Qianshuo Hu, Bin Ren, Junsong Yuan, Jiaying Lin, Jiajun Wen)</author>
      <guid isPermaLink="false">2506.00915v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>JojoSCL: Shrinkage Contrastive Learning for single-cell RNA sequence Clustering</title>
      <link>http://arxiv.org/abs/2506.00410v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为JojoSCL的新型自监督对比学习框架，用于单细胞RNA测序数据的聚类分析，并通过实验证明其优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;单细胞RNA测序技术革命性地推动了我们对细胞过程的理解，但高维度和稀疏性数据给聚类分析带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的聚类方法，以提高单细胞RNA测序数据的聚类效果。&lt;h4&gt;方法&lt;/h4&gt;JojoSCL通过结合层次贝叶斯估计的收缩估计器以及Stein的不偏风险估计（SURE）优化，对实例级和聚类级的对比学习进行细化。&lt;h4&gt;主要发现&lt;/h4&gt;在十个单细胞RNA测序数据集上的实验表明，JojoSCL在聚类效果上优于常见的聚类方法，并通过鲁棒性和消融研究验证了其实用性。&lt;h4&gt;结论&lt;/h4&gt;JojoSCL是一种有效的单细胞RNA测序数据聚类工具，可在实践中使用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Single-cell RNA sequencing (scRNA-seq) has revolutionized our understandingof cellular processes by enabling gene expression analysis at the individualcell level. Clustering allows for the identification of cell types and thefurther discovery of intrinsic patterns in single-cell data. However, the highdimensionality and sparsity of scRNA-seq data continue to challenge existingclustering models. In this paper, we introduce JojoSCL, a novel self-supervisedcontrastive learning framework for scRNA-seq clustering. By incorporating ashrinkage estimator based on hierarchical Bayesian estimation, which adjustsgene expression estimates towards more reliable cluster centroids to reduceintra-cluster dispersion, and optimized using Stein's Unbiased Risk Estimate(SURE), JojoSCL refines both instance-level and cluster-level contrastivelearning. Experiments on ten scRNA-seq datasets substantiate that JojoSCLconsistently outperforms prevalent clustering methods, with further validationof its practicality through robustness analysis and ablation studies. JojoSCL'scode is available at: https://github.com/ziwenwang28/JojoSCL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single-cell RNA sequencing (scRNA-seq) has revolutionized our understandingof cellular processes by enabling gene expression analysis at the individualcell level. Clustering allows for the identification of cell types and thefurther discovery of intrinsic patterns in single-cell data. However, the highdimensionality and sparsity of scRNA-seq data continue to challenge existingclustering models. In this paper, we introduce JojoSCL, a novel self-supervisedcontrastive learning framework for scRNA-seq clustering. By incorporating ashrinkage estimator based on hierarchical Bayesian estimation, which adjustsgene expression estimates towards more reliable cluster centroids to reduceintra-cluster dispersion, and optimized using Stein's Unbiased Risk Estimate(SURE), JojoSCL refines both instance-level and cluster-level contrastivelearning. Experiments on ten scRNA-seq datasets substantiate that JojoSCLconsistently outperforms prevalent clustering methods, with further validationof its practicality through robustness analysis and ablation studies. JojoSCL'scode is available at: https://github.com/ziwenwang28/JojoSCL.</description>
      <author>example@mail.com (Ziwen Wang)</author>
      <guid isPermaLink="false">2506.00410v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Is Your Explanation Reliable: Confidence-Aware Explanation on Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.00437v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In Proceedings of the 31st ACM SIGKDD Conference on Knowledge  Discovery and Data Mining (KDD25)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于理论原理的GNN解释框架，通过引入置信度评分模块ConfExplainer，使用广义图信息瓶颈与置信度约束（GIB-CC）来量化生成解释的可靠性。&lt;h4&gt;背景&lt;/h4&gt;由于需要可解释性，解释图神经网络（GNNs）的行为和预测变得非常重要，但现有的后处理实例级解释方法在分布外或未知测试数据集上的可靠性不确定。&lt;h4&gt;目的&lt;/h4&gt;提高GNN解释的可信度和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个名为ConfExplainer的解释框架，该框架基于广义图信息瓶颈与置信度约束（GIB-CC）来量化解释的可靠性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在提高GNN解释的可信度和鲁棒性方面优于现有方法，置信度评分在增强解释的可靠性方面非常有效。&lt;h4&gt;结论&lt;/h4&gt;ConfExplainer框架通过引入置信度评分模块，有效提高了GNN解释的可信度和鲁棒性，为解释GNN预测提供了一种可靠的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737010&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Explaining Graph Neural Networks (GNNs) has garnered significant attentiondue to the need for interpretability, enabling users to understand the behaviorof these black-box models better and extract valuable insights from theirpredictions. While numerous post-hoc instance-level explanation methods havebeen proposed to interpret GNN predictions, the reliability of theseexplanations remains uncertain, particularly in the out-of-distribution orunknown test datasets. In this paper, we address this challenge by introducingan explainer framework with the confidence scoring module ( ConfExplainer),grounded in theoretical principle, which is generalized graph informationbottleneck with confidence constraint (GIB-CC), that quantifies the reliabilityof generated explanations. Experimental results demonstrate the superiority ofour approach, highlighting the effectiveness of the confidence score inenhancing the trustworthiness and robustness of GNN explanations.</description>
      <author>example@mail.com (Jiaxing Zhang, Xiaoou Liu, Dongsheng Luo, Hua Wei)</author>
      <guid isPermaLink="false">2506.00437v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Constrained Sliced Wasserstein Embedding</title>
      <link>http://arxiv.org/abs/2506.02203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种优化Sliced Wasserstein距离切片方向的方法，通过约束学习来提高比较高维概率测度时的效率。&lt;h4&gt;背景&lt;/h4&gt;Sliced Wasserstein距离通过将高维概率测度投影到多个一维概率分布上来比较，但确定信息丰富的切片方向是一个挑战，需要大量的切片来提高性能，从而增加了计算复杂度。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来优化Sliced Wasserstein距离的切片方向，以减少计算复杂度并提高性能。&lt;h4&gt;方法&lt;/h4&gt;引入了一种约束学习方法，通过将一维传输计划约束为近似原始空间中的最优计划来确保有意义的切片方向。利用传输计划的连续松弛，实现了一个基于梯度的原对偶方法来训练切片参数和剩余模型参数。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法可以将高维嵌入池化成固定长度的排列不变表示，并在图像、点云和蛋白质序列上训练的基础模型中展示了所提出的有约束学习方法的效用。&lt;h4&gt;结论&lt;/h4&gt;所提出的有约束学习方法在学习更有信息量的切片方向方面是有效的，并且可以通过提供的GitHub链接访问其实施代码。&lt;h4&gt;翻译&lt;/h4&gt;Sliced Wasserstein (SW) distances provide an efficient way to compare high-dimensional probability measures by projecting them onto multiple 1-dimensional probability distributions. However, identifying informative slicing directions has proven challenging, often requiring a large number of slices to achieve desirable performance and thereby increasing computational complexity. We introduce a constrained learning approach to optimize the slicing directions for SW distances. Specifically, we constrain the 1D transport plans to approximate the optimal plan in the original space, ensuring meaningful slicing directions. By leveraging continuous relaxations of these transport plans, we enable a gradient-based primal-dual approach to train the slicer parameters, along with the remaining model parameters. We demonstrate how this constrained slicing approach can be applied to pool high-dimensional embeddings into fixed-length permutation-invariant representations. Numerical results on foundation models trained on images, point clouds, and protein sequences showcase the efficacy of the proposed constrained learning approach in learning more informative slicing directions. Our implementation code can be found at https://github.com/Stranja572/constrainedswe.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sliced Wasserstein (SW) distances offer an efficient method for comparinghigh-dimensional probability measures by projecting them onto multiple1-dimensional probability distributions. However, identifying informativeslicing directions has proven challenging, often necessitating a large numberof slices to achieve desirable performance and thereby increasing computationalcomplexity. We introduce a constrained learning approach to optimize theslicing directions for SW distances. Specifically, we constrain the 1Dtransport plans to approximate the optimal plan in the original space, ensuringmeaningful slicing directions. By leveraging continuous relaxations of thesetransport plans, we enable a gradient-based primal-dual approach to train theslicer parameters, alongside the remaining model parameters. We demonstrate howthis constrained slicing approach can be applied to pool high-dimensionalembeddings into fixed-length permutation-invariant representations. Numericalresults on foundation models trained on images, point clouds, and proteinsequences showcase the efficacy of the proposed constrained learning approachin learning more informative slicing directions. Our implementation code can befound at https://github.com/Stranja572/constrainedswe.</description>
      <author>example@mail.com (Navid NaderiAlizadeh, Darian Salehi, Xinran Liu, Soheil Kolouri)</author>
      <guid isPermaLink="false">2506.02203v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Scene Detection Policies and Keyframe Extraction Strategies for Large-Scale Video Analysis</title>
      <link>http://arxiv.org/abs/2506.00667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 8 figures, submitted as a preprint. ArXiv preprint only,  not submitted to a journal yet&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种统一的、自适应的框架，用于自动场景检测和关键帧选择，适用于从短视频到长篇电影、档案内容和监控录像等多种视频格式。&lt;h4&gt;背景&lt;/h4&gt;场景分割和关键帧提取是视频理解流程中的关键预处理步骤，支持索引、摘要和语义检索等任务。然而，现有方法在处理不同类型和长度的视频时往往缺乏泛化能力。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够处理多种视频格式的自动场景检测和关键帧选择系统，以支持视频分析的下游应用。&lt;h4&gt;方法&lt;/h4&gt;系统根据视频长度动态选择分割策略：对于短视频使用自适应阈值，对于中等长度的视频使用混合策略，对于长视频使用基于区间的分割。对于关键帧选择，使用了一个轻量级的模块，该模块通过锐度、亮度和时间分布的复合指标对采样帧进行评分。&lt;h4&gt;主要发现&lt;/h4&gt;系统在不同视频格式和长度上保持了一致的粒度和高效的处理，并在商业视频分析平台上部署，已处理来自媒体、教育、研究和安全等领域的多个内容。&lt;h4&gt;结论&lt;/h4&gt;该系统提供了一个可扩展且可解释的解决方案，适用于UI预览、嵌入管道和内容过滤等下游应用。未来工作将包括音频感知分割和基于强化学习的帧评分。&lt;h4&gt;翻译&lt;/h4&gt;摘要：鲁棒的场景分割和关键帧提取是视频理解流程中的关键预处理步骤，支持索引、摘要和语义检索等任务。然而，现有方法在处理不同类型和长度的视频时往往缺乏泛化能力。我们提出了一种统一的、自适应的框架，用于自动场景检测和关键帧选择，适用于从短视频到长篇电影、档案内容和监控录像等多种视频格式。我们的系统根据视频长度动态选择分割策略：对于短视频使用自适应阈值，对于中等长度的视频使用混合策略，对于长视频使用基于区间的分割。为了关键帧选择，我们采用了一个轻量级的模块，该模块通过锐度、亮度和时间分布的复合指标对采样帧进行评分。设计用于高吞吐量工作流程的系统已在商业视频分析平台上部署，并处理了来自媒体、教育、研究和安全等领域的多个内容。它提供了一个可扩展且可解释的解决方案，适用于下游应用，如UI预览、嵌入管道和内容过滤。我们讨论了实际实施细节，并概述了未来的改进，包括音频感知分割和基于强化学习的帧评分。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust scene segmentation and keyframe extraction are essential preprocessingsteps in video understanding pipelines, supporting tasks such as indexing,summarization, and semantic retrieval. However, existing methods often lackgeneralizability across diverse video types and durations. We present aunified, adaptive framework for automatic scene detection and keyframeselection that handles formats ranging from short-form media to long-formfilms, archival content, and surveillance footage. Our system dynamicallyselects segmentation policies based on video length: adaptive thresholding forshort videos, hybrid strategies for mid-length ones, and interval-basedsplitting for extended recordings. This ensures consistent granularity andefficient processing across domains. For keyframe selection, we employ alightweight module that scores sampled frames using a composite metric ofsharpness, luminance, and temporal spread, avoiding complex saliency modelswhile ensuring visual relevance. Designed for high-throughput workflows, thesystem is deployed in a commercial video analysis platform and has processedcontent from media, education, research, and security domains. It offers ascalable and interpretable solution suitable for downstream applications suchas UI previews, embedding pipelines, and content filtering. We discusspractical implementation details and outline future enhancements, includingaudio-aware segmentation and reinforcement-learned frame scoring.</description>
      <author>example@mail.com (Vasilii Korolkov)</author>
      <guid isPermaLink="false">2506.00667v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>CLARIFY: Contrastive Preference Reinforcement Learning for Untangling Ambiguous Queries</title>
      <link>http://arxiv.org/abs/2506.00388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为CLARIFY的离线PbRL方法，用于解决人类偏好中模糊反馈的问题，提高了PbRL在现实世界中的应用效率。&lt;h4&gt;背景&lt;/h4&gt;PbRL通过从人类偏好比较中推断奖励函数，避免了显式奖励工程，但人类在标记相似片段的偏好时往往存在困难，这降低了标签效率并限制了PbRL的实际应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决人类偏好中模糊反馈的问题，提高PbRL的标签效率和实际应用效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为CLARIFY的离线PbRL方法，该方法学习一个包含偏好信息的轨迹嵌入空间，确保明显区分的片段间隔较大，从而便于选择更明确的查询。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CLARIFY在非理想教师和真实人类反馈环境中均优于基线方法。该方法不仅选择了更明显的查询，还学习了有意义的轨迹嵌入。&lt;h4&gt;结论&lt;/h4&gt;CLARIFY方法能够有效提高PbRL在现实世界中的应用效果，为解决人类偏好中模糊反馈问题提供了一种新的思路。&lt;h4&gt;翻译&lt;/h4&gt;Preference-based reinforcement learning (PbRL) bypasses explicit reward engineering by inferring reward functions from human preference comparisons, enabling better alignment with human intentions. However, humans often struggle to label a clear preference between similar segments, reducing label efficiency and limiting PbRL's real-world applicability. To address this, we propose an offline PbRL method: Contrastive LeArning for ResolvIng Ambiguous Feedback (CLARIFY), which learns a trajectory embedding space that incorporates preference information, ensuring clearly distinguished segments are spaced apart, thus facilitating the selection of more unambiguous queries. Extensive experiments demonstrate that CLARIFY outperforms baselines in both non-ideal teachers and real human feedback settings. Our approach not only selects more distinguished queries but also learns meaningful trajectory embeddings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Preference-based reinforcement learning (PbRL) bypasses explicit rewardengineering by inferring reward functions from human preference comparisons,enabling better alignment with human intentions. However, humans often struggleto label a clear preference between similar segments, reducing label efficiencyand limiting PbRL's real-world applicability. To address this, we propose anoffline PbRL method: Contrastive LeArning for ResolvIng Ambiguous Feedback(CLARIFY), which learns a trajectory embedding space that incorporatespreference information, ensuring clearly distinguished segments are spacedapart, thus facilitating the selection of more unambiguous queries. Extensiveexperiments demonstrate that CLARIFY outperforms baselines in both non-idealteachers and real human feedback settings. Our approach not only selects moredistinguished queries but also learns meaningful trajectory embeddings.</description>
      <author>example@mail.com (Ni Mu, Hao Hu, Xiao Hu, Yiqin Yang, Bo Xu, Qing-Shan Jia)</author>
      <guid isPermaLink="false">2506.00388v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Tomographic Foundation Model -- FORCE: Flow-Oriented Reconstruction Conditioning Engine</title>
      <link>http://arxiv.org/abs/2506.02149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的CT图像重建方法，通过结合数据保真度和先进的生成AI模型Poisson flow generative model (PFGM)及其扩展版本PFGM++，构建了Flow-Oriented Reconstruction Conditioning Engine (FORCE)框架，显著提升了CT成像任务的表现。&lt;h4&gt;背景&lt;/h4&gt;临床CT应用如低剂量筛查、稀疏视图扫描和金属植入等情况，常导致重建图像中出现严重噪声和伪影，需要改进的重建技术。深度学习在CT图像重建方面取得了显著进展，但获取配对训练数据仍具挑战性，且深度学习模型存在数据不一致性和模型不稳定性导致的幻觉风险。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的CT图像重建框架，以解决临床CT应用中的噪声和伪影问题，并提高重建图像的质量。&lt;h4&gt;方法&lt;/h4&gt;本文将数据保真度与Poisson flow generative model (PFGM)及其扩展版本PFGM++结合，提出了Flow-Oriented Reconstruction Conditioning Engine (FORCE)框架。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在各种CT成像任务中表现出色，优于现有的无监督重建方法。&lt;h4&gt;结论&lt;/h4&gt;Flow-Oriented Reconstruction Conditioning Engine (FORCE)框架在CT图像重建中具有良好的性能，为解决临床CT应用中的噪声和伪影问题提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;Computed tomography (CT) is a major medical imaging modality. Clinical CT scenarios, such as low-dose screening, sparse-view scanning, and metalimplants, often lead to severe noise and artifacts in reconstructed images,requiring improved reconstruction techniques. The introduction of deep learninghas significantly advanced CT image reconstruction. However, obtaining pairedtraining data remains rather challenging due to patient motion and otherconstraints. Although deep learning methods can still perform well withapproximately paired data, they inherently carry the risk of hallucination dueto data inconsistencies and model instability. In this paper, we integrate thedata fidelity with the state-of-the-art generative AI model, referred to as thePoisson flow generative model (PFGM) with a generalized version PFGM++, andpropose a novel CT framework: Flow-Oriented Reconstruction Conditioning Engine(FORCE). In our experiments, the proposed method shows superior performance invarious CT imaging tasks, outperforming existing unsupervised reconstructionapproaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computed tomography (CT) is a major medical imaging modality. Clinical CTscenarios, such as low-dose screening, sparse-view scanning, and metalimplants, often lead to severe noise and artifacts in reconstructed images,requiring improved reconstruction techniques. The introduction of deep learninghas significantly advanced CT image reconstruction. However, obtaining pairedtraining data remains rather challenging due to patient motion and otherconstraints. Although deep learning methods can still perform well withapproximately paired data, they inherently carry the risk of hallucination dueto data inconsistencies and model instability. In this paper, we integrate thedata fidelity with the state-of-the-art generative AI model, referred to as thePoisson flow generative model (PFGM) with a generalized version PFGM++, andpropose a novel CT framework: Flow-Oriented Reconstruction Conditioning Engine(FORCE). In our experiments, the proposed method shows superior performance invarious CT imaging tasks, outperforming existing unsupervised reconstructionapproaches.</description>
      <author>example@mail.com (Wenjun Xia, Chuang Niu, Ge Wang)</author>
      <guid isPermaLink="false">2506.02149v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>TIDFormer: Exploiting Temporal and Interactive Dynamics Makes A Great Dynamic Graph Transformer</title>
      <link>http://arxiv.org/abs/2506.00431v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  KDD2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TIDFormer的动态图Transformer模型，该模型在捕捉动态图中的时序和交互动态方面表现出高效性，并在多个动态图数据集上超越了现有模型。&lt;h4&gt;背景&lt;/h4&gt;由于自注意力机制（SAMs）在序列建模中捕捉依赖关系的能力，一些现有的动态图神经网络（DGNNs）利用Transformer架构和不同的编码设计来捕捉动态图的序列演化。&lt;h4&gt;目的&lt;/h4&gt;提高基于Transformer的DGNNs的有效性和效率，通过正确定义动态图上的SAM和全面编码时序和交互动态，而不需要额外的复杂模块。&lt;h4&gt;方法&lt;/h4&gt;提出TIDFormer，利用基于日历的时间分区信息和通过采样一阶邻居提取的信息交互嵌入来建模时序和交互动态。同时，通过简单分解来捕捉历史交互模式中的潜在变化。&lt;h4&gt;主要发现&lt;/h4&gt;TIDFormer在多个动态图数据集上进行了广泛的实验，结果显示其在大多数数据集和实验设置上优于现有模型，并展现出相对于先前基于Transformer的方法的显著效率优势。&lt;h4&gt;结论&lt;/h4&gt;TIDFormer是一个高效且有效的动态图Transformer模型，它在捕捉动态图中的时序和交互动态方面表现出色，并且在多个数据集上优于现有模型。&lt;h4&gt;翻译&lt;/h4&gt;由于自注意力机制（SAMs）在序列建模中捕捉依赖关系的能力，一些现有的动态图神经网络（DGNNs）利用Transformer架构和不同的编码设计来捕捉动态图的序列演化。然而，这些基于Transformer的DGNNs的有效性和效率存在显著差异，突出了在动态图上正确定义SAM以及全面编码时序和交互动态的重要性，而无需额外的复杂模块。在本工作中，我们提出了TIDFormer，这是一种动态图Transformer，以高效的方式充分利用了时序和交互动态。我们阐明了我们提出的SAM的可解释性，解决了先前工作中其在动态图上不可解释定义的开放性问题。为了分别建模时序和交互动态，我们利用基于日历的时间分区信息，并仅通过采样一阶邻居为有向图和无向图提取信息交互嵌入。此外，我们通过简单分解来捕捉历史交互模式中的潜在变化，联合建模时序和交互特征。我们在多个动态图数据集上进行了广泛的实验，以验证TIDFormer的有效性和效率。实验结果表明，TIDFormer在大多数数据集和实验设置上优于现有模型，并且相对于先前基于Transformer的方法具有显著的效率优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737155&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to the proficiency of self-attention mechanisms (SAMs) in capturingdependencies in sequence modeling, several existing dynamic graph neuralnetworks (DGNNs) utilize Transformer architectures with various encodingdesigns to capture sequential evolutions of dynamic graphs. However, theeffectiveness and efficiency of these Transformer-based DGNNs varysignificantly, highlighting the importance of properly defining the SAM ondynamic graphs and comprehensively encoding temporal and interactive dynamicswithout extra complex modules. In this work, we propose TIDFormer, a dynamicgraph TransFormer that fully exploits Temporal and Interactive Dynamics in anefficient manner. We clarify and verify the interpretability of our proposedSAM, addressing the open problem of its uninterpretable definitions on dynamicgraphs in previous works. To model the temporal and interactive dynamics,respectively, we utilize the calendar-based time partitioning information andextract informative interaction embeddings for both bipartite and non-bipartitegraphs using merely the sampled first-order neighbors. In addition, we jointlymodel temporal and interactive features by capturing potential changes inhistorical interaction patterns through a simple decomposition. We conductextensive experiments on several dynamic graph datasets to verify theeffectiveness and efficiency of TIDFormer. The experimental results demonstratethat TIDFormer excels, outperforming state-of-the-art models across mostdatasets and experimental settings. Furthermore, TIDFormer exhibits significantefficiency advantages compared to previous Transformer-based methods.</description>
      <author>example@mail.com (Jie Peng, Zhewei Wei, Yuhang Ye)</author>
      <guid isPermaLink="false">2506.00431v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Chain-of-Frames: Advancing Video Understanding in Multimodal LLMs via Frame-Aware Reasoning</title>
      <link>http://arxiv.org/abs/2506.00318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于视频帧的推理步骤的视频LLMs，通过在自然语言中生成推理轨迹来提高视频理解任务的表现。&lt;h4&gt;背景&lt;/h4&gt;研究表明，在回答用户请求之前，让大型语言模型（LLMs）以自然语言生成推理轨迹可以显著提高其性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，使视频LLMs的推理步骤基于并明确引用相关视频帧。&lt;h4&gt;方法&lt;/h4&gt;创建了一个名为CoF-Data的大型数据集，包含多种主题和任务的问题、答案以及相应的基于帧的推理轨迹。然后，在CoF数据上微调现有的视频LLMs。该方法简单且自包含，不需要辅助网络来选择或描述相关帧。&lt;h4&gt;主要发现&lt;/h4&gt;基于CoF的模型能够生成准确地引用关键帧以回答给定问题的思维链。&lt;h4&gt;结论&lt;/h4&gt;该方法在多个视频理解基准测试中表现出色，例如在Video-MME、MVBench和VSI-Bench上超越了领先的视频LLMs，并显著降低了幻觉率。&lt;h4&gt;翻译&lt;/h4&gt;最近的研究表明，在回答用户请求之前，让大型语言模型（LLMs）以自然语言生成推理轨迹可以显著提高其在各种任务上的性能。这种方法已扩展到多模态LLMs，其中模型可以生成关于输入图像和视频内容的思维链（CoT）。在本工作中，我们提出获取视频LLMs，其推理步骤基于并明确引用相关视频帧。为此，我们首先创建了一个名为CoF-Data的大型数据集，包含多种主题和任务的问题、答案以及相应的自然和合成视频的基于帧的推理轨迹。然后，在CoF数据上微调现有的视频LLMs。我们的方法简单且自包含，与现有的视频CoT方法不同，不需要辅助网络来选择或描述相关帧。我们表明，基于CoF的模型能够生成准确地引用关键帧以回答给定问题的思维链。这反过来又导致在多个视频理解基准测试中表现出色，例如在Video-MME、MVBench和VSI-Bench上超过了领先的视频LLMs，并显著降低了幻觉率。代码可在https://github.com/SaraGhazanfari/CoF处获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent work has shown that eliciting Large Language Models (LLMs) to generatereasoning traces in natural language before answering the user's request cansignificantly improve their performance across tasks. This approach has beenextended to multimodal LLMs, where the models can produce chain-of-thoughts(CoT) about the content of input images and videos. In this work, we propose toobtain video LLMs whose reasoning steps are grounded in, and explicitly referto, the relevant video frames. For this, we first create CoF-Data, a largedataset of diverse questions, answers, and corresponding frame-groundedreasoning traces about both natural and synthetic videos, spanning varioustopics and tasks. Then, we fine-tune existing video LLMs on thischain-of-frames (CoF) data. Our approach is simple and self-contained, and,unlike existing approaches for video CoT, does not require auxiliary networksto select or caption relevant frames. We show that our models based on CoF areable to generate chain-of-thoughts that accurately refer to the key frames toanswer the given question. This, in turn, leads to improved performance acrossmultiple video understanding benchmarks, for example, surpassing leading videoLLMs on Video-MME, MVBench, and VSI-Bench, and notably reducing thehallucination rate. Code available athttps://github.com/SaraGhazanfari/CoF}{github.com/SaraGhazanfari/CoF.</description>
      <author>example@mail.com (Sara Ghazanfari, Francesco Croce, Nicolas Flammarion, Prashanth Krishnamurthy, Farshad Khorrami, Siddharth Garg)</author>
      <guid isPermaLink="false">2506.00318v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>SMELLNET: A Large-scale Dataset for Real-world Smell Recognition</title>
      <link>http://arxiv.org/abs/2506.00239v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了基于气味识别的AI技术及其在过敏原检测、工艺监控和情绪、压力及疾病监测中的应用。文章提出了SmellNet，这是一个首个大规模的气味数据库，并展示了基于该数据库训练的AI模型在物质气味分类上的性能。&lt;h4&gt;背景&lt;/h4&gt;AI在气味识别方面具有广泛的应用潜力，但目前缺乏大规模的基准数据集和评估体系。&lt;h4&gt;目的&lt;/h4&gt;构建一个大规模的气味数据库SmellNet，并基于此训练AI模型实现实时物质气味分类。&lt;h4&gt;方法&lt;/h4&gt;使用便携式气体和化学传感器收集气味数据，创建SmellNet数据库；利用序列模型、对比学习和新的时间差分方法训练AI模型；在预录制数据和真实世界条件下评估模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;SmellNet数据库包含约18万时间步的50种物质数据；模型在预录制数据上达到65.35%的准确率，在真实世界条件下对坚果和香料达到10.71%和25.38%的准确率。&lt;h4&gt;结论&lt;/h4&gt;尽管取得了令人鼓舞的结果，但SmellNet也突显了构建AI气味识别技术的技术挑战，包括更丰富的特征学习、边缘化气味模型和环境变化的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了基于气味识别的人工智能技术及其在过敏原检测、制造过程监控和情绪、压力及疾病监测等方面的广泛应用潜力。尽管目前缺乏大规模的基准数据集和评估体系，但本文提出并构建了一个名为SmellNet的大规模气味数据库。通过使用便携式气体和化学传感器收集数据，SmellNet包含了约18万时间步的50种物质数据。基于此数据库，本文训练了人工智能模型，以实现仅通过气味进行物质的实时分类。在预录制数据上，最佳模型达到了65.35%的准确率，在真实世界条件下，对坚果和香料分别达到了10.71%和25.38%的准确率。尽管取得了令人鼓舞的结果，但SmellNet也突显了构建人工智能气味识别技术的技术挑战，包括更丰富的特征学习、边缘化气味模型和环境变化的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability of AI to sense and identify various substances based on theirsmell alone can have profound impacts on allergen detection (e.g., smellinggluten or peanuts in a cake), monitoring the manufacturing process, and sensinghormones that indicate emotional states, stress levels, and diseases. Despitethese broad impacts, there are virtually no large scale benchmarks, andtherefore little progress, for training and evaluating AI systems' ability tosmell in the real world. In this paper, we use portable gas and chemicalsensors to create SmellNet, the first large-scale database that digitizes adiverse range of smells in the natural world. SmellNet contains about 180,000time steps of 50 substances (spanning nuts, spices, herbs, fruits, andvegetables) with 50 hours of data. Using SmellNet, we train AI models forreal-time classification of substances based on their smell alone. Our bestmethods leverage sequence models, contrastive learning to integratehigh-resolution Gas Chromatography-Mass Spectrometry molecular data, and a newtemporal difference method that identifies sharp changes in sensor readings.Our best models achieve up to 65.35% accuracy on pre-recorded data, andgeneralize to real-world conditions with 10.71% accuracy on nuts and 25.38% onspices in the challenging 50-way online classification task. Despite thesepromising results, SmellNet highlights many technical challenges in building AIfor smell, including richer feature learning, on-edge smell models, androbustness to environmental changes.</description>
      <author>example@mail.com (Dewei Feng, Carol Li, Wei Dai, Paul Pu Liang)</author>
      <guid isPermaLink="false">2506.00239v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting LRP: Positional Attribution as the Missing Ingredient for Transformer Explainability</title>
      <link>http://arxiv.org/abs/2506.02138v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的Transformer可解释性工具，通过考虑位置编码来提高解释性。&lt;h4&gt;背景&lt;/h4&gt;Transformer的可解释性是深度学习研究中的一个关键追求，Layer-wise Relevance Propagation (LRP)是一种有前景的方法，但它忽略了位置编码这一重要组件。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来改进Transformer的可解释性，使其能够考虑位置编码。&lt;h4&gt;方法&lt;/h4&gt;将Transformer的可解释性输入空间重新定义为位置-标记对，并提出了专门的理论基础LRP规则，以传播不同位置编码方法（如旋转、可学习和绝对PE）的归因。&lt;h4&gt;主要发现&lt;/h4&gt;通过在细调分类器和零样本基础模型（如LLaMA 3）上的广泛实验，该方法在视觉和NLP可解释性任务中显著优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;该方法通过考虑位置编码，显著提高了Transformer的可解释性，并且代码是公开的。&lt;h4&gt;翻译&lt;/h4&gt;The development of effective explainability tools for Transformers is a crucial pursuit in deep learning research. One of the most promising approaches in this domain is Layer-wise Relevance Propagation (LRP), which propagates relevance scores backward through the network to the input space by redistributing activation values based on predefined rules. However, existing LRP-based methods for Transformer explainability entirely overlook a critical component of the Transformer architecture: its positional encoding (PE), resulting in violation of the conservation property, and the loss of an important and unique type of relevance, which is also associated with structural and positional features. To address this limitation, we reformulate the input space for Transformer explainability as a set of position-token pairs. This allows us to propose specialized theoretically-grounded LRP rules designed to propagate attributions across various positional encoding methods, including Rotary, Learnable, and Absolute PE. Extensive experiments with both fine-tuned classifiers and zero-shot foundation models, such as LLaMA 3, demonstrate that our method significantly outperforms the state-of-the-art in both vision and NLP explainability tasks. Our code is publicly available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of effective explainability tools for Transformers is acrucial pursuit in deep learning research. One of the most promising approachesin this domain is Layer-wise Relevance Propagation (LRP), which propagatesrelevance scores backward through the network to the input space byredistributing activation values based on predefined rules. However, existingLRP-based methods for Transformer explainability entirely overlook a criticalcomponent of the Transformer architecture: its positional encoding (PE),resulting in violation of the conservation property, and the loss of animportant and unique type of relevance, which is also associated withstructural and positional features. To address this limitation, we reformulatethe input space for Transformer explainability as a set of position-tokenpairs. This allows us to propose specialized theoretically-grounded LRP rulesdesigned to propagate attributions across various positional encoding methods,including Rotary, Learnable, and Absolute PE. Extensive experiments with bothfine-tuned classifiers and zero-shot foundation models, such as LLaMA 3,demonstrate that our method significantly outperforms the state-of-the-art inboth vision and NLP explainability tasks. Our code is publicly available.</description>
      <author>example@mail.com (Yarden Bakish, Itamar Zimerman, Hila Chefer, Lior Wolf)</author>
      <guid isPermaLink="false">2506.02138v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>GrapheonRL: A Graph Neural Network and Reinforcement Learning Framework for Constraint and Data-Aware Workflow Mapping and Scheduling in Heterogeneous HPC Systems</title>
      <link>http://arxiv.org/abs/2506.00260v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 7 figures, IEEE COMPSAC 2025 Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合图神经网络（GNN）和强化学习（RL）的新方法，以灵活处理工作流、动态约束和异构资源，同时提供快速响应。&lt;h4&gt;背景&lt;/h4&gt;有效利用资源和减少作业完成时间（makespan）是异构高性能计算（HPC）环境中工作负载映射和调度的关键好处。&lt;h4&gt;目的&lt;/h4&gt;旨在提供一个能够处理异构HPC计算连续系统景观中不断变化的约束、工作负载大小和复杂性的鲁棒且可扩展的映射和调度解决方案。&lt;h4&gt;方法&lt;/h4&gt;该方法采用GNN来管理依赖和资源需求，RL通过学习策略优化调度决策，避免了对全局搜索的需求。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法能够有效适应不同的工作流，遵守HPC约束，并提供类似于ILP的优化解决方案，但执行时间显著减少（快76%），与启发式方法相当（仅比OLB慢3.85倍）。&lt;h4&gt;结论&lt;/h4&gt;该研究为HPC环境中的工作负载映射和调度提供了一种高效且可扩展的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective resource utilization and decreased makespan in heterogeneous HighPerformance Computing (HPC) environments are key benefits of workload mappingand scheduling. Tools such as Snakemake, a workflow management solution, employInteger Linear Programming (ILP) and heuristic techniques to deploy workflowsin various HPC environments like SLURM (Simple Linux Utility for ResourceManagement) or Kubernetes. Its scheduler factors in workflow task dependencies,resource requirements, and individual task data sizes before system deployment.ILP offers optimal solutions respecting constraints, but only for smallerworkflows. Meanwhile, meta-heuristics and heuristics offer faster, thoughsuboptimal, makespan. As problem sizes, system constraints, and complexitiesevolve, maintaining these schedulers becomes challenging. In this study, wepropose a novel solution that integrates Graph Neural Network (GNN) andReinforcement Learning (RL) to flexibly handle workflows, dynamic constraints,and heterogeneous resources while providing quick responses. GNN managesdependencies and resource requirements, and RL optimizes schedulingdecision-making via a learned policy, overcoming the need for a comprehensiveglobal search. Experimental results with different datasets demonstrate thatthis method effectively adapts to different workflows, adheres to HPCconstraints, and offers optimal solutions akin to ILP but with drasticallyreduced execution times (76 percent faster), comparable to heuristic methods(only 3.85 times slower than OLB). Our contribution is to provide a robust yetscalable mapping and scheduling solution that can handle changing constraints,as well as workload sizes and complexities in a heterogeneous HPC ComputeContinuum system landscape.</description>
      <author>example@mail.com (Aasish Kumar Sharma, Julian Kunkel)</author>
      <guid isPermaLink="false">2506.00260v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Fast-in-Slow: A Dual-System Foundation Model Unifying Fast Manipulation within Slow Reasoning</title>
      <link>http://arxiv.org/abs/2506.01953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Fast-in-Slow的统一双系统视觉语言动作（VLA）模型，旨在解决机器人操作中的策略和执行效率问题。&lt;h4&gt;背景&lt;/h4&gt;当前基于互联网规模预训练的视觉语言模型（VLM）在常识推理方面具有优势，但执行频率低。为解决这一矛盾，提出了基于Kahneman理论的混合系统方法，但现有设计将两个系统作为独立模型，限制了System 1从System 2中充分利用预训练知识。&lt;h4&gt;目的&lt;/h4&gt;提出Fast-in-Slow（FiS）模型，通过将System 1执行模块嵌入到基于VLM的System 2中，提高执行频率并促进推理与执行之间的协调。&lt;h4&gt;方法&lt;/h4&gt;FiS模型通过参数共享将System 1执行模块集成到System 2中，设计了双感知共训练策略，使System 1具备动作生成能力，同时保持System 2的上下文推理表示。&lt;h4&gt;主要发现&lt;/h4&gt;FiS-VLA在模拟和现实任务中，平均成功率比之前的方法分别提高了8%和11%，同时达到了117.7 Hz的控制频率。&lt;h4&gt;结论&lt;/h4&gt;FiS模型有效地提高了机器人操作的策略和执行效率，为机器人领域提供了新的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;The summary of the abstract is as follows: The Fast-in-Slow (FiS) model is proposed in this paper to address the challenges of policy and execution efficiency in robotic manipulation. By embedding the System 1 execution module within the VLM-based System 2 and sharing parameters, the model not only enables high-frequency execution in System 1 but also facilitates the coordination between reasoning and execution components within the single foundation model of System 2. The FiS-VLA model outperforms previous state-of-the-art methods by 8% in simulation and 11% in real-world tasks, achieving a control frequency of 117.7 Hz with an action chunk set to eight.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalized policy and execution efficiency constitute the two criticalchallenges in robotic manipulation. While recent foundation policies benefitfrom the common-sense reasoning capabilities of internet-scale pretrainedvision-language models (VLMs), they often suffer from low execution frequency.To mitigate this dilemma, dual-system approaches, inspired by Kahneman'stheory, have been proposed to leverage a VLM-based System 2 model handlinghigh-level reasoning and a separate System 1 action model ensuring real-timecontrol. However, existing designs maintain both systems as separate models,limiting System 1 from fully leveraging the rich pretrained knowledge from theVLM-based System 2. In this work, we propose Fast-in-Slow (FiS), a unifieddual-system vision-language-action (VLA) model that embeds the System 1execution module within the VLM-based System 2 by partially sharing parameters.This innovative paradigm not only enables high-frequency execution in System 1but also facilitates coordination between the reasoning and executioncomponents within a single foundation model of System 2. Given theirfundamentally distinct roles within FiS-VLA, we design the two systems toincorporate heterogeneous modality inputs alongside asynchronous operatingfrequencies, enabling both fast and precise manipulation. To enablecoordination between the two systems, a dual-aware co-training strategy isproposed that equips System 1 with action generation capabilities whilepreserving System 2's contextual reasoning representation. For evaluation,FiS-VLA outperforms previous state-of-the-art methods by 8% in simulation and11% in real-world tasks in terms of average success rate, while achieving a117.7 Hz control frequency with action chunk set to eight. Project web page:fast-in-slow.github.io.</description>
      <author>example@mail.com (Hao Chen, Jiaming Liu, Chenyang Gu, Zhuoyang Liu, Renrui Zhang, Xiaoqi Li, Xiao He, Yandong Guo, Chi-Wing Fu, Shanghang Zhang, Pheng-Ann Heng)</author>
      <guid isPermaLink="false">2506.01953v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning</title>
      <link>http://arxiv.org/abs/2506.00101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 pages, 1 figure, 4 tables. Full paper is available at  arXiv:2503.21055&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了过程感知视频表示学习，通过结合LLM生成的状态变化描述作为视频编码器的监督信号，并生成状态变化反事实以帮助模型学习。实验结果表明，所提出的状态变化描述及其反事实在多个任务上取得了显著改进。&lt;h4&gt;背景&lt;/h4&gt;当前过程感知视频表示学习研究未能明确学习状态变化（场景转换）。&lt;h4&gt;目的&lt;/h4&gt;通过改进视频表示学习，使模型能够理解动作步骤之间的因果关系。&lt;h4&gt;方法&lt;/h4&gt;使用LLM生成的状态变化描述作为监督信号，并生成状态变化反事实来模拟假设的失败结果，使模型通过想象未见过的情况来学习。&lt;h4&gt;主要发现&lt;/h4&gt;模型通过反事实推理增强了理解活动每个步骤因果关系的本领，实验验证了模型在过程感知任务上的有效性，包括时间动作分割、错误检测等。&lt;h4&gt;结论&lt;/h4&gt;提出的状态变化描述及其反事实在多个任务上显著提升了模型的效果。&lt;h4&gt;翻译&lt;/h4&gt;Understanding a procedural activity requires modeling both how action steps transform the scene, and how evolving scene transformations can influence the sequence of action steps, even those that are accidental or erroneous. Yet, existing work on procedure-aware video representations fails to explicitly learn the state changes (scene transformations). In this work, we study procedure-aware video representation learning by incorporating state-change descriptions generated by LLMs as supervision signals for video encoders. Moreover, we generate state-change counterfactuals that simulate hypothesized failure outcomes, allowing models to learn by imagining the unseen ``What if'' scenarios. This counterfactual reasoning facilitates the model's ability to understand the cause and effect of each step in an activity. To verify the procedure awareness of our model, we conduct extensive experiments on procedure-aware tasks, including temporal action segmentation, error detection, and more. Our results demonstrate the effectiveness of the proposed state-change descriptions and their counterfactuals, and achieve significant improvements on multiple tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding a procedural activity requires modeling both how action stepstransform the scene, and how evolving scene transformations can influence thesequence of action steps, even those that are accidental or erroneous. Yet,existing work on procedure-aware video representations fails to explicitlylearned the state changes (scene transformations). In this work, we studyprocedure-aware video representation learning by incorporating state-changedescriptions generated by LLMs as supervision signals for video encoders.Moreover, we generate state-change counterfactuals that simulate hypothesizedfailure outcomes, allowing models to learn by imagining the unseen ``What if''scenarios. This counterfactual reasoning facilitates the model's ability tounderstand the cause and effect of each step in an activity. To verify theprocedure awareness of our model, we conduct extensive experiments onprocedure-aware tasks, including temporal action segmentation, error detection,and more. Our results demonstrate the effectiveness of the proposedstate-change descriptions and their counterfactuals, and achieve significantimprovements on multiple tasks.</description>
      <author>example@mail.com (Chi-Hsi Kung, Frangil Ramirez, Juhyung Ha, Yi-Ting Chen, David Crandall, Yi-Hsuan Tsai)</author>
      <guid isPermaLink="false">2506.00101v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>DeGLIF for Label Noise Robust Node Classification using GNNs</title>
      <link>http://arxiv.org/abs/2506.00244v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DeGLIF的降噪技术，用于处理图数据中的标签噪声，通过使用一小部分干净数据和leave-one-out影响函数来实现对图数据的鲁棒节点级预测。&lt;h4&gt;背景&lt;/h4&gt;相比于干净标签数据集，噪声标签数据集和图数据通常更便宜。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来处理图数据中的标签噪声，并实现准确的节点级预测。&lt;h4&gt;方法&lt;/h4&gt;DeGLIF使用leave-one-out影响函数来估计如果从训练数据集中移除一个训练点，模型参数的变化。该方法扩展了最近关于图神经网络（GNNs）的leave-one-out影响函数的计算方法，并引入了一个新的理论动机重标记函数来降噪训练数据集。DeGLIF有两种变体用于识别噪声节点，这两种变体都不需要关于噪声模型或数据集中噪声水平的信息。&lt;h4&gt;主要发现&lt;/h4&gt;通过详细的计算实验，证明了DeGLIF在不同数据集上的有效性，其准确率优于其他基线算法。&lt;h4&gt;结论&lt;/h4&gt;DeGLIF是一种有效的降噪技术，可以用于处理图数据中的标签噪声，并在不同数据集上表现出比其他基线算法更好的性能。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为DeGLIF的降噪技术：使用留一法影响函数进行降噪图数据。DeGLIF利用少量干净数据和留一法影响函数，在图数据上实现鲁棒的节点级预测。留一法影响函数近似了从训练数据集中移除一个训练点时模型参数的变化。最近的研究提出了一种计算图神经网络（GNNs）的留一法影响函数的方法。我们将这项研究扩展到估计如果从训练数据集中移除一个训练节点，验证损失的变化。我们使用这个估计和一个新的理论动机重标记函数来降噪训练数据集。我们提出了两种DeGLIF变体来识别噪声节点。这两种变体都不需要关于噪声模型或数据集中噪声水平的信息；DeGLIF也不估计这些数量。对于这些变体之一，我们证明了检测到的噪声点确实会增加风险。我们在不同的数据集上进行了详细的计算实验，以证明DeGLIF的有效性。它比其他基线算法实现了更好的准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Noisy labelled datasets are generally inexpensive compared to clean labelleddatasets, and the same is true for graph data. In this paper, we propose adenoising technique DeGLIF: Denoising Graph Data using Leave-One-Out InfluenceFunction. DeGLIF uses a small set of clean data and the leave-one-out influencefunction to make label noise robust node-level prediction on graph data.Leave-one-out influence function approximates the change in the modelparameters if a training point is removed from the training dataset. Recentadvances propose a way to calculate the leave-one-out influence function forGraph Neural Networks (GNNs). We extend that recent work to estimate the changein validation loss, if a training node is removed from the training dataset. Weuse this estimate and a new theoretically motivated relabelling function todenoise the training dataset. We propose two DeGLIF variants to identify noisynodes. Both these variants do not require any information about the noise modelor the noise level in the dataset; DeGLIF also does not estimate thesequantities. For one of these variants, we prove that the noisy points detectedcan indeed increase risk. We carry out detailed computational experiments ondifferent datasets to show the effectiveness of DeGLIF. It achieves betteraccuracy than other baseline algorithms</description>
      <author>example@mail.com (Pintu Kumar, Nandyala Hemachandra)</author>
      <guid isPermaLink="false">2506.00244v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>E3D-Bench: A Benchmark for End-to-End 3D Geometric Foundation Models</title>
      <link>http://arxiv.org/abs/2506.01933v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://e3dbench.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了3D几何基础模型（GFMs）在空间智能领域的应用，包括3D重建、感知和推理，特别关注了从非结构化或流媒体图像中实时、准确地估计核心3D属性的技术。&lt;h4&gt;背景&lt;/h4&gt;空间智能在机器人、航空成像和扩展现实等领域至关重要，而3D GFMs能够直接预测密集的3D表示，无需预计算的相机参数，因此成为关键推动力。&lt;h4&gt;目的&lt;/h4&gt;提出一个全面的3D GFMs基准，评估其在多个任务和不同数据集上的性能，并指导未来模型的扩展和优化。&lt;h4&gt;方法&lt;/h4&gt;开发了标准化工具包，自动化数据集处理、评估协议和指标计算，确保比较的公平性和可重复性，评估了16个最先进的GFMs。&lt;h4&gt;主要发现&lt;/h4&gt;揭示了不同GFMs在各项任务和领域中的优势和局限性，并得出了关键见解。&lt;h4&gt;结论&lt;/h4&gt;公开所有代码、评估脚本和数据处理，以加速3D空间智能的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：空间智能，包括3D重建、感知和推理，对于机器人、航空成像和扩展现实等应用至关重要。一个关键推动力是从非结构化或流媒体图像中实时、准确地估计核心3D属性（相机参数、点云、深度图和3D点轨迹）。受大型基础模型在语言和2D视觉中的成功启发，一类新的端到端3D几何基础模型（GFMs）已经出现，它们可以在单次前馈传递中直接预测密集的3D表示，消除了对缓慢或不可用的预计算相机参数的需求。自2023年底以来，该领域已经爆炸式增长，但缺乏系统评估。在这项工作中，我们提出了第一个全面的3D GFMs基准，涵盖了五个核心任务：稀疏视图深度估计、视频深度估计、3D重建、多视图姿态估计和新型视图合成，涵盖了标准和非标准数据集。我们的标准化工具包自动化了数据集处理、评估协议和指标计算，以确保公平、可重复的比较。我们评估了16个最先进的GFMs，揭示了它们在任务和领域中的优势和局限性，并得出了关键见解以指导未来的模型扩展和优化。所有代码、评估脚本和数据处理将公开发布，以加速3D空间智能的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial intelligence, encompassing 3D reconstruction, perception, andreasoning, is fundamental to applications such as robotics, aerial imaging, andextended reality. A key enabler is the real-time, accurate estimation of core3D attributes (camera parameters, point clouds, depth maps, and 3D pointtracks) from unstructured or streaming imagery. Inspired by the success oflarge foundation models in language and 2D vision, a new class of end-to-end 3Dgeometric foundation models (GFMs) has emerged, directly predicting dense 3Drepresentations in a single feed-forward pass, eliminating the need for slow orunavailable precomputed camera parameters. Since late 2023, the field hasexploded with diverse variants, but systematic evaluation is lacking. In thiswork, we present the first comprehensive benchmark for 3D GFMs, covering fivecore tasks: sparse-view depth estimation, video depth estimation, 3Dreconstruction, multi-view pose estimation, novel view synthesis, and spanningboth standard and challenging out-of-distribution datasets. Our standardizedtoolkit automates dataset handling, evaluation protocols, and metriccomputation to ensure fair, reproducible comparisons. We evaluate 16state-of-the-art GFMs, revealing their strengths and limitations across tasksand domains, and derive key insights to guide future model scaling andoptimization. All code, evaluation scripts, and processed data will be publiclyreleased to accelerate research in 3D spatial intelligence.</description>
      <author>example@mail.com (Wenyan Cong, Yiqing Liang, Yancheng Zhang, Ziyi Yang, Yan Wang, Boris Ivanovic, Marco Pavone, Chen Chen, Zhangyang Wang, Zhiwen Fan)</author>
      <guid isPermaLink="false">2506.01933v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Understanding Overadaptation in Supervised Fine-Tuning: The Role of Ensemble Methods</title>
      <link>http://arxiv.org/abs/2506.01901v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在特定领域数据上进行的监督微调（SFT）方法，发现SFT模型容易遗忘预训练期间获得的知识。通过将预训练模型与其微调后的对应模型进行集成，可以缓解这一问题。研究进一步发现，集成模型不仅在基础模型中保留了通用知识，而且在微调领域本身也优于微调模型。本文对集成方法的优势进行了理论分析，并证明其在提高性能方面比正则化技术更有效。&lt;h4&gt;背景&lt;/h4&gt;监督微调（SFT）是适应特定任务的主要方法，但SFT模型容易出现遗忘知识的问题。&lt;h4&gt;目的&lt;/h4&gt;证明集成方法在语言模型中也能有效缓解遗忘知识的问题，并对其优势进行理论分析。&lt;h4&gt;方法&lt;/h4&gt;对预训练模型与微调模型进行集成，并对其进行理论分析。&lt;h4&gt;主要发现&lt;/h4&gt;集成模型不仅保留了预训练模型的知识，而且在微调领域也优于微调模型。集成方法通过平衡两个主要误差来源（偏差和方差）来缓解遗忘知识的问题，比正则化技术更有效。&lt;h4&gt;结论&lt;/h4&gt;集成方法可以有效地提高模型性能，为模型集成提供理论支持。&lt;h4&gt;翻译&lt;/h4&gt;Supervised fine-tuning (SFT) on domain-specific data is the dominant approach for adapting foundation models to specialized tasks. However, it has been observed that SFT models tend to forget knowledge acquired during pretraining. In vision models, ensembling a pretrained model with its fine-tuned counterpart has been shown to mitigate this issue. In this work, we demonstrate that the same holds for language models, and, more strikingly, we observe an overadaptation phenomenon: the ensemble model not only retains general knowledge from the foundation model but also outperforms the fine-tuned model even on the fine-tuning domain itself. Despite the empirical success of ensembling, a theoretical understanding of its benefits remains underexplored. We develop a formal theoretical analysis of the overadaptation phenomenon. Ensembling mitigates this by balancing two primary sources of error: bias, caused by insufficient fine-tuning, and variance, introduced by overfitting to fine-tuning data. While regularization techniques aim to address this trade-off, we show that ensembling provides a more effective solution. We analyze this phenomenon in over-parameterized linear settings and demonstrate that interpolating between pretrained and fine-tuned weights significantly improves performance. These findings offer theoretical justification for the observed advantages of model ensembling, supported by empirical experiments consistent with our analysis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Supervised fine-tuning (SFT) on domain-specific data is the dominant approachfor adapting foundation models to specialized tasks. However, it has beenobserved that SFT models tend to forget knowledge acquired during pretraining.In vision models, ensembling a pretrained model with its fine-tuned counterparthas been shown to mitigate this issue. In this work, we demonstrate that thesame holds for language models, and, more strikingly, we observe anoveradaptation phenomenon: the ensemble model not only retains generalknowledge from the foundation model but also outperforms the fine-tuned modeleven on the fine-tuning domain itself. Despite the empirical success ofensembling, a theoretical understanding of its benefits remains underexplored.We develop a formal theoretical analysis of the overadaptation phenomenon.Ensembling mitigates this by balancing two primary sources of error: bias,caused by insufficient fine-tuning, and variance, introduced by overfitting tofine-tuning data. While regularization techniques aim to address thistrade-off, we show that ensembling provides a more effective solution. Weanalyze this phenomenon in over-parameterized linear settings and demonstratethat interpolating between pretrained and fine-tuned weights significantlyimproves performance. These findings offer theoretical justification for theobserved advantages of model ensembling, supported by empirical experimentsconsistent with our analysis.</description>
      <author>example@mail.com (Yifan Hao, Xingyuan Pan, Hanning Zhang, Chenlu Ye, Rui Pan, Tong Zhang)</author>
      <guid isPermaLink="false">2506.01901v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>EEG Foundation Models for BCI Learn Diverse Features of Electrophysiology</title>
      <link>http://arxiv.org/abs/2506.01867v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Two figures, one table, six pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的自监督BCI基础模型预训练方法，该方法受HuBERT框架启发，并针对脑电图（EEG）应用，旨在提高BCI模型在神经解码方面的表现。&lt;h4&gt;背景&lt;/h4&gt;BCI研究和神经科学领域越来越多地采用大规模人工智能预训练方法与公共数据集相结合，这种方法在神经解码方面取得了成功。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自监督预训练方法，以学习神经生理学的鲁棒表示，并探索BCI模型在其他脑功能及电生理信息方面的潜在应用。&lt;h4&gt;方法&lt;/h4&gt;该方法基于Transformer架构，专门针对低功耗、实时应用设计，使用最少的前处理数据和头皮上的八个EEG通道。&lt;h4&gt;主要发现&lt;/h4&gt;该基础模型不仅支持标准的BCI任务（如P300、运动想象），还学习了与个体差异和其他显著电生理成分（如α节律）相关的特征。&lt;h4&gt;结论&lt;/h4&gt;本研究为如何利用强大的AI方法与神经数据结合进行多种任务和应用提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;摘要：脑机接口（BCI）研究以及神经科学领域的许多部分，已经通过将大规模人工智能（AI）预训练方法与大量公共数据集相结合而取得了成功。使用无标签的自监督目标对基础模型进行预训练的方法，有望学习神经生理学的鲁棒表示，这可能有助于解决神经解码方面的长期挑战。然而，迄今为止，这项工作主要集中在标准的BCI基准和任务上，这可能会忽视这些强大方法可能学习的关于脑功能以及其他电生理信息的众多特征。我们介绍了一种新的自监督BCI基础模型预训练方法，该方法受HuBERT框架启发，该框架最初是为语音处理而开发的。我们的流程专门针对低功耗、实时使用，涉及最少的前处理数据和头皮上的八个EEG通道。我们表明，我们的基础模型学习了一种支持标准BCI任务（P300、运动想象）的EEG表示，但该模型还学习了与个体差异和其他显著电生理成分（例如，α节律）相关的神经数据特征。除了描述和评估一种新的预训练BCI模型和神经解码方法之外，这项工作还开启了对神经数据与强大AI方法结合可能存在的任务和用例的新视野。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain computer interface (BCI) research, as well as increasing portions ofthe field of neuroscience, have found success deploying large-scale artificialintelligence (AI) pre-training methods in conjunction with vast publicrepositories of data. This approach of pre-training foundation models usinglabel-free, self-supervised objectives offers the potential to learn robustrepresentations of neurophysiology, potentially addressing longstandingchallenges in neural decoding. However, to date, much of this work has focusedexplicitly on standard BCI benchmarks and tasks, which likely overlooks themultitude of features these powerful methods might learn about brain functionas well as other electrophysiological information. We introduce a new methodfor self-supervised BCI foundation model pre-training for EEG inspired by atransformer-based approach adapted from the HuBERT framework originallydeveloped for speech processing. Our pipeline is specifically focused onlow-profile, real-time usage, involving minimally pre-processed data and justeight EEG channels on the scalp. We show that our foundation model learned arepresentation of EEG that supports standard BCI tasks (P300, motor imagery),but also that this model learns features of neural data related to individualvariability, and other salient electrophysiological components (e.g., alpharhythms). In addition to describing and evaluating a novel approach topre-training BCI models and neural decoding, this work opens the aperture forwhat kind of tasks and use-cases might exist for neural data in concert withpowerful AI methods.</description>
      <author>example@mail.com (Mattson Ogg, Rahul Hingorani, Diego Luna, Griffin W. Milsap, William G. Coon, Clara A. Scholl)</author>
      <guid isPermaLink="false">2506.01867v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Binary Cumulative Encoding meets Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2505.24595v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的时间序列预测方法，通过将连续的目标空间离散化并预测固定类别，提高了训练稳定性、不确定性建模的鲁棒性，并与现代深度学习架构兼容。该方法引入了二进制累积编码（BCE），以保持目标值的顺序和大小信息，并通过卷积神经网络架构实现快速和表达式的时序建模。&lt;h4&gt;背景&lt;/h4&gt;现有时间序列预测方法大多依赖于one-hot编码，忽略了目标值的内在顺序结构，无法提供预测值与真实值之间相对距离的信息。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在处理目标值顺序结构方面的不足，提出一种新的编码方式，并设计相应的神经网络架构，以提高时间序列预测的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了二进制累积编码（BCE），将标量目标表示为单调的二进制向量，并设计了一种针对BCE的卷积神经网络架构，包含残差和膨胀卷积。&lt;h4&gt;主要发现&lt;/h4&gt;通过在基准预测数据集上的广泛实验，证明该方法在点预测和概率预测方面均优于现有方法，同时需要更少的参数并允许更快的训练。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地处理时间序列预测中的顺序结构问题，并通过实验验证了其优越性。&lt;h4&gt;翻译&lt;/h4&gt;Recent studies in time series forecasting have explored formulating regression via classification task. By discretizing the continuous target space into bins and predicting over a fixed set of classes, these approaches benefit from stable training, robust uncertainty modeling, and compatibility with modern deep learning architectures. However, most existing methods rely on one-hot encoding that ignores the inherent ordinal structure of the underlying values. As a result, they fail to provide information about the relative distance between predicted and true values during training. In this paper, we propose to address this limitation by introducing binary cumulative encoding (BCE), that represents scalar targets into monotonic binary vectors. This encoding implicitly preserves order and magnitude information, allowing the model to learn distance-aware representations while still operating within a classification framework. We propose a convolutional neural network architecture specifically designed for BCE, incorporating residual and dilated convolutions to enable fast and expressive temporal modeling. Through extensive experiments on benchmark forecasting datasets, we show that our approach outperforms widely used methods in both point and probabilistic forecasting, while requiring fewer parameters and enabling faster training.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies in time series forecasting have explored formulatingregression via classification task. By discretizing the continuous target spaceinto bins and predicting over a fixed set of classes, these approaches benefitfrom stable training, robust uncertainty modeling, and compatibility withmodern deep learning architectures. However, most existing methods rely onone-hot encoding that ignores the inherent ordinal structure of the underlyingvalues. As a result, they fail to provide information about the relativedistance between predicted and true values during training. In this paper, wepropose to address this limitation by introducing binary cumulative encoding(BCE), that represents scalar targets into monotonic binary vectors. Thisencoding implicitly preserves order and magnitude information, allowing themodel to learn distance-aware representations while still operating within aclassification framework. We propose a convolutional neural networkarchitecture specifically designed for BCE, incorporating residual and dilatedconvolutions to enable fast and expressive temporal modeling. Through extensiveexperiments on benchmark forecasting datasets, we show that our approachoutperforms widely used methods in both point and probabilistic forecasting,while requiring fewer parameters and enabling faster training.</description>
      <author>example@mail.com (Andrei Chernov, Vitaliy Pozdnyakov, Ilya Makarov)</author>
      <guid isPermaLink="false">2505.24595v2</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>SPACE: Your Genomic Profile Predictor is a Powerful DNA Foundation Model</title>
      <link>http://arxiv.org/abs/2506.01833v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为SPACE的模型，用于DNA预训练，该模型通过监督训练和混合专家（MoE）技术来提高DNA序列的表示能力。&lt;h4&gt;背景&lt;/h4&gt;受无监督预训练方法成功应用的启发，研究者们将其应用于DNA预训练，但作者认为仅使用这些方法会导致次优结果，因为纯DNA序列缺乏足够的信息。&lt;h4&gt;目的&lt;/h4&gt;旨在通过监督训练和混合专家技术来提高DNA序列的表示能力，以实现更有效的DNA预训练。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为SPACE的模型，该模型利用监督训练进行基因组轮廓预测，并使用混合专家（MoE）技术来捕捉不同物种和基因组轮廓之间的DNA序列关系。&lt;h4&gt;主要发现&lt;/h4&gt;通过在多个任务上的广泛实验，SPACE模型达到了最先进的性能，证明了使用监督基因组轮廓训练的DNA模型是强大的DNA表示学习器。&lt;h4&gt;结论&lt;/h4&gt;DNA模型与监督基因组轮廓的训练相结合，可以更有效地学习DNA表示，并实现优于纯序列预训练的效果。&lt;h4&gt;翻译&lt;/h4&gt;受无监督预训练方法成功应用的启发，研究者们将这种方法应用于DNA预训练。然而，我们认为仅使用这些方法会导致次优结果，因为纯DNA序列缺乏足够的信息，其功能受基因组轮廓（如染色质可及性）等基因组特征调控。在此，我们展示了监督训练对于基因组轮廓预测的有效性，这比纯序列预训练更为有效。鉴于基因组轮廓预测的多物种和多轮廓特性，我们引入了我们的物种-轮廓自适应协作专家（SPACE）模型，该模型利用混合专家（MoE）技术来更好地捕捉不同物种间和基因组轮廓之间的DNA序列关系，从而学习更有效的DNA表示。通过在多个任务上的广泛实验，我们的模型实现了最先进的性能，证明了使用监督基因组轮廓训练的DNA模型是强大的DNA表示学习器。代码可在https://github.com/ZhuJiwei111/SPACE获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inspired by the success of unsupervised pre-training paradigms, researchershave applied these approaches to DNA pre-training. However, we argue that theseapproaches alone yield suboptimal results because pure DNA sequences lacksufficient information, since their functions are regulated by genomic profileslike chromatin accessibility. Here, we demonstrate that supervised training forgenomic profile prediction serves as a more effective alternative to puresequence pre-training. Furthermore, considering the multi-species andmulti-profile nature of genomic profile prediction, we introduce our$\textbf{S}$pecies-$\textbf{P}$rofile $\textbf{A}$daptive$\textbf{C}$ollaborative $\textbf{E}$xperts (SPACE) that leverages Mixture ofExperts (MoE) to better capture the relationships between DNA sequences acrossdifferent species and genomic profiles, thereby learning more effective DNArepresentations. Through extensive experiments across various tasks, our modelachieves state-of-the-art performance, establishing that DNA models trainedwith supervised genomic profiles serve as powerful DNA representation learners.The code is available at https://github.com/ZhuJiwei111/SPACE.</description>
      <author>example@mail.com (Zhao Yang, Jiwei Zhu, Bing Su)</author>
      <guid isPermaLink="false">2506.01833v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Human-Centric Evaluation for Foundation Models</title>
      <link>http://arxiv.org/abs/2506.01793v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种以人为中心的评估框架，通过实验收集了大量用户反馈，分析了不同基础模型的能力。&lt;h4&gt;背景&lt;/h4&gt;目前大多数对基础模型的评估都侧重于客观指标，但这种方法无法反映真实的人类体验。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，提出了一个以人为中心的评估框架，重点关注问题解决能力、信息质量和交互体验。&lt;h4&gt;方法&lt;/h4&gt;通过涉及Deepseek R1、OpenAI o3 mini、Grok 3和Gemini 2.5的实验，进行了超过540次的参与者驱动的评估，其中人类和模型共同完成开放性研究任务。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，Grok 3的表现优于Deepseek R1和Gemini 2.5，而OpenAI o3 mini的表现落后。&lt;h4&gt;结论&lt;/h4&gt;这项研究不仅提升了主观评估方法，还为标准化、自动化的评估奠定了基础，推动了LLM在研究和实际场景中的应用。&lt;h4&gt;翻译&lt;/h4&gt;Currently, nearly all evaluations of foundation models focus on objective metrics, emphasizing quiz performance to define model capabilities. While this model-centric approach enables rapid performance assessment, it fails to reflect authentic human experiences. To address this gap, we propose a Human-Centric subjective Evaluation (HCE) framework, focusing on three core dimensions: problem-solving ability, information quality, and interaction experience. Through experiments involving Deepseek R1, OpenAI o3 mini, Grok 3, and Gemini 2.5, we conduct over 540 participant-driven evaluations, where humans and models collaborate on open-ended research tasks, yielding a comprehensive subjective dataset. This dataset captures diverse user feedback across multiple disciplines, revealing distinct model strengths and adaptability. Our findings highlight Grok 3's superior performance, followed by Deepseek R1 and Gemini 2.5, with OpenAI o3 mini lagging behind. By offering a novel framework and a rich dataset, this study not only enhances subjective evaluation methodologies but also lays the foundation for standardized, automated assessments, advancing LLM development for research and practical scenarios. Our dataset link is https://github.com/yijinguo/Human-Centric-Evaluation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Currently, nearly all evaluations of foundation models focus on objectivemetrics, emphasizing quiz performance to define model capabilities. While thismodel-centric approach enables rapid performance assessment, it fails toreflect authentic human experiences. To address this gap, we propose aHuman-Centric subjective Evaluation (HCE) framework, focusing on three coredimensions: problem-solving ability, information quality, and interactionexperience. Through experiments involving Deepseek R1, OpenAI o3 mini, Grok 3,and Gemini 2.5, we conduct over 540 participant-driven evaluations, wherehumans and models collaborate on open-ended research tasks, yielding acomprehensive subjective dataset. This dataset captures diverse user feedbackacross multiple disciplines, revealing distinct model strengths andadaptability. Our findings highlight Grok 3's superior performance, followed byDeepseek R1 and Gemini 2.5, with OpenAI o3 mini lagging behind. By offering anovel framework and a rich dataset, this study not only enhances subjectiveevaluation methodologies but also lays the foundation for standardized,automated assessments, advancing LLM development for research and practicalscenarios. Our dataset link ishttps://github.com/yijinguo/Human-Centric-Evaluation.</description>
      <author>example@mail.com (Yijin Guo, Kaiyuan Ji, Xiaorong Zhu, Junying Wang, Farong Wen, Chunyi Li, Zicheng Zhang, Guangtao Zhai)</author>
      <guid isPermaLink="false">2506.01793v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Entanglement for Pattern Learning in Temporal Data with Logarithmic Complexity: Benchmarking on IBM Quantum Hardware</title>
      <link>http://arxiv.org/abs/2506.00097v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于量子计算的时间序列预测框架，旨在解决传统方法在数据有限或硬件受限环境中的资源消耗和扩展性问题。&lt;h4&gt;背景&lt;/h4&gt;时间序列预测在科学和技术领域至关重要，但经典方法如自回归模型和深度学习架构在资源消耗和扩展性方面存在局限。&lt;h4&gt;目的&lt;/h4&gt;开发一种量子原生的时间序列预测框架，利用量子纠缠的参数化量子电路来学习时间依赖性。&lt;h4&gt;方法&lt;/h4&gt;提出的量子时间序列（QTS）模型将标准化序列数据编码为单比特旋转，并通过结构化的纠缠模式嵌入时间结构。&lt;h4&gt;主要发现&lt;/h4&gt;QTS在合成和真实世界数据集上与经典模型进行了基准测试，包括用于数值天气预报的地球位势高度场。实验表明，QTS可以使用更少的数据点捕捉时间模式。&lt;h4&gt;结论&lt;/h4&gt;QTS在噪声后端和真实IBM量子硬件上的基准测试表明，量子纠缠可以作为实际计算资源用于时间建模，并有望在纳米尺度系统、量子传感器网络和其他预测场景中实现近期应用。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a quantum-native time series forecasting framework aimed at addressing the limitations of classical methods in resource consumption and scalability in data-limited or hardware-constrained settings. The proposed Quantum Time Series (QTS) model encodes normalized sequential data into single-qubit rotations and embeds temporal structure through structured entanglement patterns. Experiments on synthetic and real-world datasets, including geopotential height fields used in numerical weather prediction, demonstrate that QTS can capture temporal patterns using fewer data points. Benchmarking on noisy backends and real IBM quantum hardware establishes quantum entanglement as a practical computational resource for temporal modeling, with potential near-term applications in nano-scale systems, quantum sensor networks, and other forecasting scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting is foundational in scientific and technologicaldomains, from climate modelling to molecular dynamics. Classical approacheshave significantly advanced sequential prediction, including autoregressivemodels and deep learning architectures such as temporal convolutional networks(TCNs) and Transformers. Yet, they remain resource-intensive and often scalepoorly in data-limited or hardware-constrained settings. We propose aquantum-native time series forecasting framework that harnessesentanglement-based parameterized quantum circuits to learn temporaldependencies. Our Quantum Time Series (QTS) model encodes normalized sequentialdata into single-qubit rotations and embeds temporal structure throughstructured entanglement patterns. This design considers predictive performancewith logarithmic complexity in training data and parameter count. We benchmarkQTS against classical models on synthetic and real-world datasets, includinggeopotential height fields used in numerical weather prediction. Experiments onthe noisy backend and real IBM quantum hardware demonstrate that QTS cancapture temporal patterns using fewer data points. Hardware benchmarkingresults establish quantum entanglement as a practical computational resourcefor temporal modelling, with potential near-term applications in nano-scalesystems, quantum sensor networks, and other forecasting scenarios.</description>
      <author>example@mail.com (Mostafizur Rahaman Laskar, Richa Goel)</author>
      <guid isPermaLink="false">2506.00097v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>SatDreamer360: Geometry Consistent Street-View Video Generation from Satellite Imagery</title>
      <link>http://arxiv.org/abs/2506.00600v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SatDreamer360的新框架，用于从单张卫星图像和预定义轨迹生成几何和时序一致的地面视图视频。&lt;h4&gt;背景&lt;/h4&gt;生成连续地面视频是一项具有巨大应用潜力的挑战性任务，可用于模拟、自主导航和数字孪生城市。&lt;h4&gt;目的&lt;/h4&gt;提出的方法旨在克服现有方法在生成时序一致序列方面的不足，同时提高视频的真实性、连贯性和几何对齐。&lt;h4&gt;方法&lt;/h4&gt;SatDreamer360通过引入紧凑的三平面表示来编码场景几何，并使用基于射线的像素注意力机制检索三平面中的视点相关特征。此外，还提出了一个基于视差约束的时序注意力模块，以确保多帧一致性。&lt;h4&gt;主要发现&lt;/h4&gt;SatDreamer360在多样城市场景中实现了在保真度、连贯性和几何对齐方面的优越性能。&lt;h4&gt;结论&lt;/h4&gt;SatDreamer360是一个有效的方法，能够从卫星图像中生成高质量的连续地面视图视频，为模拟、自主导航和数字孪生城市等领域提供支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从卫星图像生成连续地面视频是一项具有重大应用潜力的挑战性任务，在模拟、自主导航和数字孪生城市等领域具有显著的应用潜力。现有方法主要侧重于合成单个地面视图图像，通常依赖于辅助输入，如高度图或手工投影，并且在生成时序一致序列方面存在不足。在本文中，我们提出了一种名为SatDreamer360的新框架，该框架可以从单个卫星图像和预定义轨迹生成几何和时序一致的地面视图视频。为了弥合大的视点差距，我们引入了一种紧凑的三平面表示，它直接从卫星图像中编码场景几何。基于射线的像素注意力机制从三平面中检索视点相关的特征，使跨视图对应关系准确无误，无需额外的几何先验。为了确保多帧一致性，我们提出了一种基于视差约束的时序注意力模块，使用沿轨迹的已知相对姿态对帧间特征进行对齐。为了支持评估，我们引入了VIGOR++，这是一个用于跨视图视频生成的大型数据集，具有密集的轨迹注释和高品质的地面视图序列。广泛的实验表明，SatDreamer360在多样城市场景中实现了在保真度、连贯性和几何对齐方面的优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating continuous ground-level video from satellite imagery is achallenging task with significant potential for applications in simulation,autonomous navigation, and digital twin cities. Existing approaches primarilyfocus on synthesizing individual ground-view images, often relying on auxiliaryinputs like height maps or handcrafted projections, and fall short in producingtemporally consistent sequences. In this paper, we propose {SatDreamer360}, anovel framework that generates geometrically and temporally consistentground-view video from a single satellite image and a predefined trajectory. Tobridge the large viewpoint gap, we introduce a compact tri-plane representationthat encodes scene geometry directly from the satellite image. A ray-basedpixel attention mechanism retrieves view-dependent features from the tri-plane,enabling accurate cross-view correspondence without requiring additionalgeometric priors. To ensure multi-frame consistency, we propose anepipolar-constrained temporal attention module that aligns features acrossframes using the known relative poses along the trajectory. To supportevaluation, we introduce {VIGOR++}, a large-scale dataset for cross-view videogeneration, with dense trajectory annotations and high-quality ground-viewsequences. Extensive experiments demonstrate that SatDreamer360 achievessuperior performance in fidelity, coherence, and geometric alignment acrossdiverse urban scenes.</description>
      <author>example@mail.com (Xianghui Ze, Beiyi Zhu, Zhenbo Song, Jianfeng Lu, Yujiao Shi)</author>
      <guid isPermaLink="false">2506.00600v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>MIND: Material Interface Generation from UDFs for Non-Manifold Surface Reconstruction</title>
      <link>http://arxiv.org/abs/2506.02938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MIND的算法，直接从UDFs生成材料界面，从而实现非流形网格的提取。&lt;h4&gt;背景&lt;/h4&gt;UDFs在3D深度学习中广泛应用，但直接从UDFs提取网格存在挑战，因为学习到的场很少达到精确的零距离。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的算法，以解决从UDFs中提取网格的挑战，特别是非流形几何形状。&lt;h4&gt;方法&lt;/h4&gt;MIND算法通过从UDF推导出有意义的空间分区，将目标表面作为不同区域的界面。首先计算一个双符号局部场以区分流形补丁的两面，然后扩展到能够分离非流形结构所有面的多标签全局场。通过将这个多标签场与输入的UDF结合，构建支持非流形网格提取的多标签Marching Cubes算法。&lt;h4&gt;主要发现&lt;/h4&gt;MIND算法能够鲁棒地处理复杂的非流形表面，并在实验中显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;MIND算法为从UDFs中提取非流形网格提供了一种有效的方法，并展示了其在多种数据源生成UDFs上的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：无符号距离场（UDFs）因其能够表示任意拓扑形状而在3D深度学习中得到广泛应用。尽管先前的工作主要集中在从点云或多视图图像中学习UDFs，但从UDFs中提取网格仍然具有挑战性，因为学习到的场很少达到精确的零距离。一种常见的解决方案是从UDFs局部重建符号距离场（SDFs），以便通过Marching Cubes进行表面提取。然而，这通常会引入诸如空洞或虚假成分之类的拓扑错误。此外，局部SDFs本质上不能表示非流形几何，导致在这些情况下完全失败。为了解决这一差距，我们提出了MIND（从非流形距离场生成材料界面），这是一种直接从UDFs生成材料界面的新算法，从全局角度实现非流形网格提取。我们方法的核心在于从UDF推导出有意义的空间分区，目标表面作为不同区域的界面出现。我们首先计算一个双符号局部场以区分流形补丁的两面，然后扩展到能够分离非流形结构所有面的多标签全局场。通过将这个多标签场与输入的UDF结合，我们构建了通过多标签Marching Cubes算法支持非流形网格提取的材料界面。在来自点云重建、多视图重建和中心线变换的多种数据源生成的UDFs上进行的广泛实验表明，我们的方法能够鲁棒地处理复杂的非流形表面，并且在性能上显著优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsigned distance fields (UDFs) are widely used in 3D deep learning due totheir ability to represent shapes with arbitrary topology. While prior work haslargely focused on learning UDFs from point clouds or multi-view images,extracting meshes from UDFs remains challenging, as the learned fields rarelyattain exact zero distances. A common workaround is to reconstruct signeddistance fields (SDFs) locally from UDFs to enable surface extraction viaMarching Cubes. However, this often introduces topological artifacts such asholes or spurious components. Moreover, local SDFs are inherently incapable ofrepresenting non-manifold geometry, leading to complete failure in such cases.To address this gap, we propose MIND (Material Interface from Non-manifoldDistance fields), a novel algorithm for generating material interfaces directlyfrom UDFs, enabling non-manifold mesh extraction from a global perspective. Thecore of our method lies in deriving a meaningful spatial partitioning from theUDF, where the target surface emerges as the interface between distinctregions. We begin by computing a two-signed local field to distinguish the twosides of manifold patches, and then extend this to a multi-labeled global fieldcapable of separating all sides of a non-manifold structure. By combining thismulti-labeled field with the input UDF, we construct material interfaces thatsupport non-manifold mesh extraction via a multi-labeled Marching Cubesalgorithm. Extensive experiments on UDFs generated from diverse data sources,including point cloud reconstruction, multi-view reconstruction, and medialaxis transforms, demonstrate that our approach robustly handles complexnon-manifold surfaces and significantly outperforms existing methods.</description>
      <author>example@mail.com (Xuhui Chen, Fei Hou, Wencheng Wang, Hong Qin, Ying He)</author>
      <guid isPermaLink="false">2506.02938v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Towards Explicit Geometry-Reflectance Collaboration for Generalized LiDAR Segmentation in Adverse Weather</title>
      <link>http://arxiv.org/abs/2506.02396v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对LiDAR语义分割模型在恶劣天气条件下精度下降的问题，提出了一种新的几何-反射协作（GRC）框架，该框架能够有效提取场景的内在信息，提高模型的鲁棒性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的LiDAR语义分割模型在恶劣天气条件下往往精度下降，现有方法主要关注通过天气模拟或通用增强技术来增强训练数据，但很少有研究关注点云几何结构和反射强度中的异构域迁移带来的负面影响。&lt;h4&gt;目的&lt;/h4&gt;针对上述问题，本文旨在提出一种新的方法来提高LiDAR语义分割模型在恶劣天气条件下的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种名为GRC的框架，该框架采用双分支架构，分别处理几何和反射特征，并采用鲁棒的多级特征协作模块来抑制不必要和不准确的信息。&lt;h4&gt;主要发现&lt;/h4&gt;通过在具有挑战性的基准数据集上进行实验，本文的方法GRC在恶劣天气条件下优于现有方法，并取得了新的最先进的结果。&lt;h4&gt;结论&lt;/h4&gt;本文提出的GRC框架能够有效提高LiDAR语义分割模型在恶劣天气条件下的性能，为解决这一难题提供了一种新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing LiDAR semantic segmentation models often suffer from decreasedaccuracy when exposed to adverse weather conditions. Recent methods addressingthis issue focus on enhancing training data through weather simulation oruniversal augmentation techniques. However, few works have studied the negativeimpacts caused by the heterogeneous domain shifts in the geometric structureand reflectance intensity of point clouds. In this paper, we delve into thischallenge and address it with a novel Geometry-Reflectance Collaboration (GRC)framework that explicitly separates feature extraction for geometry andreflectance. Specifically, GRC employs a dual-branch architecture designed toindependently process geometric and reflectance features initially, therebycapitalizing on their distinct characteristic. Then, GRC adopts a robustmulti-level feature collaboration module to suppress redundant and unreliableinformation from both branches. Consequently, without complex simulation oraugmentation, our method effectively extracts intrinsic information about thescene while suppressing interference, thus achieving better robustness andgeneralization in adverse weather conditions. We demonstrate the effectivenessof GRC through comprehensive experiments on challenging benchmarks, showingthat our method outperforms previous approaches and establishes newstate-of-the-art results.</description>
      <author>example@mail.com (Longyu Yang, Ping Hu, Shangbo Yuan, Lu Zhang, Jun Liu, Hengtao Shen, Xiaofeng Zhu)</author>
      <guid isPermaLink="false">2506.02396v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>SAB3R: Semantic-Augmented Backbone in 3D Reconstruction</title>
      <link>http://arxiv.org/abs/2506.02112v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://uva-computer-vision-lab.github.io/sab3r/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为“地图与定位”的新任务，该任务结合了开放词汇分割和3D重建的目标，涉及从未定位的视频生成点云并根据开放词汇查询分割对象实例。&lt;h4&gt;背景&lt;/h4&gt;开放词汇分割和3D重建是两个传统上不同的目标，分别涉及自然语言查询检测和分割对象实例，以及从视觉输入估计场景的3D结构。&lt;h4&gt;目的&lt;/h4&gt;该任务作为迈向现实世界具身人工智能应用的关键步骤，引入了一个连接重建、识别和重组的实用任务。&lt;h4&gt;方法&lt;/h4&gt;提出了一个简单而有效的基线SAB3R，它基于MASt3R（3D计算机视觉的最新突破）并采用轻量级蒸馏策略，将2D视觉骨干网络（如CLIP和DINOv2）的密集、每像素语义特征转移到MASt3R上，以增强其能力。&lt;h4&gt;主要发现&lt;/h4&gt;SAB3R模型在地图与定位基准测试上实现了优于分别部署MASt3R和CLIP的性能，并且通过在2D语义分割和3D任务上的评估，全面验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;SAB3R模型在地图与定位任务上表现出色，为未来具身人工智能应用提供了有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;We introduce a new task, Map and Locate, which unifies the traditionally distinct objectives of open-vocabulary segmentation - detecting and segmenting object instances based on natural language queries - and 3D reconstruction, the process of estimating a scene's 3D structure from visual inputs. Specifically, Map and Locate involves generating a point cloud from an unposed video and segmenting object instances based on open-vocabulary queries. This task serves as a critical step toward real-world embodied AI applications and introduces a practical task that bridges reconstruction, recognition and reorganization. To tackle this task, we introduce a simple yet effective baseline, which we denote as SAB3R. Our approach builds upon MASt3R, a recent breakthrough in 3D computer vision, and incorporates a lightweight distillation strategy. This method transfers dense, per-pixel semantic features from 2D vision backbones (eg, CLIP and DINOv2) to enhance MASt3R's capabilities. Without introducing any auxiliary frozen networks, our model generates per-pixel semantic features and constructs cohesive point maps in a single forward pass. Compared to separately deploying MASt3R and CLIP, our unified model, SAB3R, achieves superior performance on the Map and Locate benchmark. Furthermore, we evaluate SAB3R on both 2D semantic segmentation and 3D tasks to comprehensively validate its effectiveness.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a new task, Map and Locate, which unifies the traditionallydistinct objectives of open-vocabulary segmentation - detecting and segmentingobject instances based on natural language queries - and 3D reconstruction, theprocess of estimating a scene's 3D structure from visual inputs. Specifically,Map and Locate involves generating a point cloud from an unposed video andsegmenting object instances based on open-vocabulary queries. This task servesas a critical step toward real-world embodied AI applications and introduces apractical task that bridges reconstruction, recognition and reorganization. Totackle this task, we introduce a simple yet effective baseline, which we denoteas SAB3R. Our approach builds upon MASt3R, a recent breakthrough in 3D computervision, and incorporates a lightweight distillation strategy. This methodtransfers dense, per-pixel semantic features from 2D vision backbones (eg, CLIPand DINOv2) to enhance MASt3R's capabilities. Without introducing any auxiliaryfrozen networks, our model generates per-pixel semantic features and constructscohesive point maps in a single forward pass. Compared to separately deployingMASt3R and CLIP, our unified model, SAB3R, achieves superior performance on theMap and Locate benchmark. Furthermore, we evaluate SAB3R on both 2D semanticsegmentation and 3D tasks to comprehensively validate its effectiveness.</description>
      <author>example@mail.com (Xuweiyi Chen, Tian Xia, Sihan Xu, Jianing Yang, Joyce Chai, Zezhou Cheng)</author>
      <guid isPermaLink="false">2506.02112v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised Latent Space Optimization with Nebula Variational Coding</title>
      <link>http://arxiv.org/abs/2506.01414v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种变分推断模型，通过引入额外的变量（称为星云锚点）来优化潜在流形，从而提升分类、分割、补全和/或重建的性能。该方法通过约束潜在特征形成高斯分布，形成了称为星云变分编码（NVC）的生成模型，并通过度量学习使聚类分离更加明显。&lt;h4&gt;背景&lt;/h4&gt;深度学习方法通过层次化的方式处理数据，并使用中间（或潜在）特征。目前的研究旨在通过概率模型优化潜在流形来提升分类、分割、补全和/或重建的性能。&lt;h4&gt;目的&lt;/h4&gt;设计一个通用的解决方案来优化潜在流形，以提升分类、分割、补全和/或重建的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种变分推断模型，引入星云锚点变量来引导潜在变量形成聚类，并使用变分约束防止锚点之间聚类。同时，通过度量学习以自监督的方式明确聚类之间的分离。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验证明，该方法可以应用于解决不同问题的不同架构，包括文本序列、图像、3D点云和体积数据，验证了所提方法的优势。&lt;h4&gt;结论&lt;/h4&gt;提出的NVC模型能够通过聚类适应训练数据的语义，如样本的类别标签，并在多种数据类型上表现出良好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TPAMI.2022.3160539&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning approaches process data in a layer-by-layer way withintermediate (or latent) features. We aim at designing a general solution tooptimize the latent manifolds to improve the performance on classification,segmentation, completion and/or reconstruction through probabilistic models.This paper proposes a variational inference model which leads to a clusteredembedding. We introduce additional variables in the latent space, called\textbf{nebula anchors}, that guide the latent variables to form clustersduring training. To prevent the anchors from clustering among themselves, weemploy the variational constraint that enforces the latent features within ananchor to form a Gaussian distribution, resulting in a generative model werefer as Nebula Variational Coding (NVC). Since each latent feature can belabeled with the closest anchor, we also propose to apply metric learning in aself-supervised way to make the separation between clusters more explicit. As aconsequence, the latent variables of our variational coder form clusters whichadapt to the generated semantic of the training data, \textit{e.g.} thecategorical labels of each sample. We demonstrate experimentally that it can beused within different architectures designed to solve different problemsincluding text sequence, images, 3D point clouds and volumetric data,validating the advantage of our proposed method.</description>
      <author>example@mail.com (Yida Wang, David Joseph Tan, Nassir Navab, Federico Tombari)</author>
      <guid isPermaLink="false">2506.01414v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>OG-VLA: 3D-Aware Vision Language Action Model via Orthographic Image Generation</title>
      <link>http://arxiv.org/abs/2506.01196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;OG-VLA是一种结合了视觉语言动作模型（VLAs）的泛化能力和3D感知策略的鲁棒性的新架构和学习框架。&lt;h4&gt;背景&lt;/h4&gt;现有的3D感知机器人策略在精确的机器人操作任务上表现优异，但在处理未见过的指令、场景和物体时泛化能力不足。而VLAs虽然在泛化指令和场景方面表现出色，但对相机和机器人姿态变化敏感。&lt;h4&gt;目的&lt;/h4&gt;解决将自然语言指令和多视图RGBD观察映射到准静态机器人动作的挑战，并提高3D感知关键帧策略的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;OG-VLA将输入观察从不同视角投影到点云，然后从标准正交投影图中渲染，确保输入视图不变性和输入输出空间之间的一致性。这些标准视图通过视觉骨干网络、大型语言模型（LLM）和图像扩散模型进行处理，生成编码了输入场景中末端执行器下一点位置和方向的图像。&lt;h4&gt;主要发现&lt;/h4&gt;在Arnold和Colosseum基准测试中，OG-VLA在未见过的环境中实现了最先进的泛化能力，相对于基准测试有超过40%的相对改进，同时在已见设置中保持了鲁棒的性能。&lt;h4&gt;结论&lt;/h4&gt;OG-VLA展示了在3到5个演示中的现实世界适应性以及强大的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;OG-VLA，一种新型架构和学习框架，结合了视觉语言动作模型（VLAs）的泛化能力与3D感知策略的鲁棒性。我们解决了将自然语言指令和多视图RGBD观察映射到准静态机器人动作的挑战。3D感知机器人策略在精确的机器人操作任务上取得了最先进的性能，但在处理未见过的指令、场景和物体时泛化能力有限。另一方面，VLAs在泛化指令和场景方面表现出色，但对相机和机器人姿态变化敏感。我们利用语言和视觉基础模型中嵌入的先验知识来提高3D感知关键帧策略的泛化能力。OG-VLA将输入观察从不同视角投影到点云，然后从标准正交投影图中渲染，确保输入视图不变性和输入输出空间之间的一致性。这些标准视图通过视觉骨干网络、大型语言模型（LLM）和图像扩散模型进行处理，生成编码了输入场景中末端执行器下一点位置和方向的图像。在Arnold和Colosseum基准测试中，OG-VLA在未见过的环境中实现了最先进的泛化能力，相对于基准测试有超过40%的相对改进，同时在已见设置中保持了鲁棒的性能。我们还展示了在3到5个演示中的现实世界适应性以及强大的泛化能力。更多信息请访问https://og-vla.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce OG-VLA, a novel architecture and learning framework thatcombines the generalization strengths of Vision Language Action models (VLAs)with the robustness of 3D-aware policies. We address the challenge of mappingnatural language instructions and multi-view RGBD observations to quasi-staticrobot actions. 3D-aware robot policies achieve state-of-the-art performance onprecise robot manipulation tasks, but struggle with generalization to unseeninstructions, scenes, and objects. On the other hand, VLAs excel atgeneralizing across instructions and scenes, but can be sensitive to camera androbot pose variations. We leverage prior knowledge embedded in language andvision foundation models to improve generalization of 3D-aware keyframepolicies. OG-VLA projects input observations from diverse views into a pointcloud which is then rendered from canonical orthographic views, ensuring inputview invariance and consistency between input and output spaces. Thesecanonical views are processed with a vision backbone, a Large Language Model(LLM), and an image diffusion model to generate images that encode the nextposition and orientation of the end-effector on the input scene. Evaluations onthe Arnold and Colosseum benchmarks demonstrate state-of-the-art generalizationto unseen environments, with over 40% relative improvements while maintainingrobust performance in seen settings. We also show real-world adaption in 3 to 5demonstrations along with strong generalization. Videos and resources athttps://og-vla.github.io/</description>
      <author>example@mail.com (Ishika Singh, Ankit Goyal, Stan Birchfield, Dieter Fox, Animesh Garg, Valts Blukis)</author>
      <guid isPermaLink="false">2506.01196v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>$\text{TREX}^2$: Dual-Reconstruction Framework for Teleoperated-Robot with EXtended Reality</title>
      <link>http://arxiv.org/abs/2506.01135v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了TREX^2，一个端到端、开源的XR遥操作框架，用于减少网络延迟和提高遥操作准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的XR遥操作系统存在运动到运动（M2M）延迟问题，导致遥操作误差和任务完成时间增加。&lt;h4&gt;目的&lt;/h4&gt;提出TREX^2框架，以解决现有系统的网络依赖性和延迟问题。&lt;h4&gt;方法&lt;/h4&gt;TREX^2通过本地感知数据重建延迟或缺失信息，同时实现XR和机器人并发运行，并采用竞争感知调度和带宽自适应点云缩放技术。&lt;h4&gt;主要发现&lt;/h4&gt;TREX^2在WLAN和蜂窝网络中分别将遥操作误差减少了69.8%和73.1%，同时将任务完成时间提高了47.7%，在真实世界任务中表现出色。&lt;h4&gt;结论&lt;/h4&gt;TREX^2显著提高了XR遥操作的准确性和效率，是现有框架的有效替代品。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robot teleoperation with extended reality (XR teleoperation) enablesintuitive interaction by allowing remote robots to mimic user motions withreal-time 3D feedback. However, existing systems face significantmotion-to-motion (M2M) latency -- the delay between the user's latest motionand the corresponding robot feedback -- leading to high teleoperation error andmission completion time. This issue stems from the system's exclusive relianceon network communication, making it highly vulnerable to network degradation.To address these challenges, we introduce $\text{TREX}^2$, the firstend-to-end, fully open-sourced XR teleoperation framework that decouples robotcontrol and XR visualization from network dependencies. $\text{TREX}^2$leverages local sensing data to reconstruct delayed or missing information ofthe counterpart, thereby significantly reducing network-induced issues. Thisapproach allows both the XR and robot to run concurrently with networktransmission while maintaining high robot planning accuracy. $\text{TREX}^2$also features contention-aware scheduling to mitigate GPU contention andbandwidth-adaptive point cloud scaling to cope with limited bandwidth. Weimplement $\text{TREX}^2$ across three hardware settings, including simulatedand physical robots, and evaluate it on 9,500 real-world teleoperation trialsfrom the RoboSet dataset \cite{kumar2024robohive}, covering single- andmulti-step missions. Compared to state-of-the-art XR teleoperation frameworks,$\text{TREX}^2$ reduces teleoperation error by up to 69.8% on WLAN and 73.1% oncellular networks with only 6.7% maximum runtime overhead. It also improvescompletion time by up to 47.7%, enabling smoother teleoperation. A real-worldcase study on ten stationary and mobile missions further shows $\text{TREX}^2$achieves up to 37.7% faster completion while lowering average teleoperationerror by up to 57.2%.</description>
      <author>example@mail.com (Ziliang Zhang, Cong Liu, Hyoseung Kim)</author>
      <guid isPermaLink="false">2506.01135v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>CountingFruit: Real-Time 3D Fruit Counting with Language-Guided Semantic Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.01109v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FruitLangGS的实时3D水果计数框架，用于解决实际农业环境中由于视觉遮挡、语义模糊和高计算需求而导致的精确水果计数难题。&lt;h4&gt;背景&lt;/h4&gt;精确水果计数在现实农业环境中是一个长期挑战，现有基于神经辐射场的计数方法存在推理速度慢、泛化能力有限和缺乏开放集语义控制支持等问题。&lt;h4&gt;目的&lt;/h4&gt;提出FruitLangGS框架，通过空间重建、语义嵌入和语言引导的实例估计来解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;FruitLangGS首先使用自适应高斯散点渲染管道，结合半径感知剪枝和基于瓦片的光栅化进行高效渲染。为了实现语义控制，每个高斯点编码一个压缩的CLIP对齐语言嵌入，形成紧凑且可查询的3D表示。在推理时，直接在3D空间中应用基于提示的语义过滤，而不依赖于图像空间分割或视级融合。然后通过分布感知采样将选定的高斯点转换为密集点云，并进行聚类以估计水果数量。&lt;h4&gt;主要发现&lt;/h4&gt;在真实果园数据上的实验结果表明，FruitLangGS相比先前方法实现了更高的渲染速度、语义灵活性和计数精度。&lt;h4&gt;结论&lt;/h4&gt;FruitLangGS为语言驱动的实时神经渲染在开放世界场景中提供了一个新的视角。&lt;h4&gt;翻译&lt;/h4&gt;Accurate fruit counting in real-world agricultural environments is a long-standing challenge due to visual occlusions, semantic ambiguity, and the high computational demands of 3D reconstruction. Existing methods based on neural radiance fields suffer from low inference speed, limited generalization, and lack support for open-set semantic control. This paper presents FruitLangGS, a real-time 3D fruit counting framework that addresses these limitations through spatial reconstruction, semantic embedding, and language-guided instance estimation. FruitLangGS first reconstructs orchard-scale scenes using an adaptive Gaussian splatting pipeline with radius-aware pruning and tile-based rasterization for efficient rendering. To enable semantic control, each Gaussian encodes a compressed CLIP-aligned language embedding, forming a compact and queryable 3D representation. At inference time, prompt-based semantic filtering is applied directly in 3D space, without relying on image-space segmentation or view-level fusion. The selected Gaussians are then converted into dense point clouds via distribution-aware sampling and clustered to estimate fruit counts. Experimental results on real orchard data demonstrate that FruitLangGS achieves higher rendering speed, semantic flexibility, and counting accuracy compared to prior approaches, offering a new perspective for language-driven, real-time neural rendering across open-world scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate fruit counting in real-world agricultural environments is alongstanding challenge due to visual occlusions, semantic ambiguity, and thehigh computational demands of 3D reconstruction. Existing methods based onneural radiance fields suffer from low inference speed, limited generalization,and lack support for open-set semantic control. This paper presentsFruitLangGS, a real-time 3D fruit counting framework that addresses theselimitations through spatial reconstruction, semantic embedding, andlanguage-guided instance estimation. FruitLangGS first reconstructsorchard-scale scenes using an adaptive Gaussian splatting pipeline withradius-aware pruning and tile-based rasterization for efficient rendering. Toenable semantic control, each Gaussian encodes a compressed CLIP-alignedlanguage embedding, forming a compact and queryable 3D representation. Atinference time, prompt-based semantic filtering is applied directly in 3Dspace, without relying on image-space segmentation or view-level fusion. Theselected Gaussians are then converted into dense point clouds viadistribution-aware sampling and clustered to estimate fruit counts.Experimental results on real orchard data demonstrate that FruitLangGS achieveshigher rendering speed, semantic flexibility, and counting accuracy compared toprior approaches, offering a new perspective for language-driven, real-timeneural rendering across open-world scenarios.</description>
      <author>example@mail.com (Fengze Li, Yangle Liu, Jieming Ma, Hai-Ning Liang, Yaochun Shen, Huangxiang Li, Zhijing Wu)</author>
      <guid isPermaLink="false">2506.01109v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Deformable registration and generative modelling of aortic anatomies by auto-decoders and neural ODEs</title>
      <link>http://arxiv.org/abs/2506.00947v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 7 figures, 6 tables, 2 algorithms. Submitted to "npj  Biological Physics and Mechanics". Dataset publicly available at  https://doi.org/10.5281/zenodo.15494901&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该工作介绍了AD-SVFD，一种用于血管形状变形配准到预定义参考以及生成合成解剖结构的深度学习模型。&lt;h4&gt;背景&lt;/h4&gt;AD-SVFD通过将每个几何形状表示为加权点云，并使用常微分方程（ODE）的解来建模环境空间变形。&lt;h4&gt;目的&lt;/h4&gt;AD-SVFD旨在实现血管形状的高精度变形配准，并能够生成新的解剖结构。&lt;h4&gt;方法&lt;/h4&gt;AD-SVFD通过最小化变形后的点云与参考点云之间的Chamfer距离来优化模型参数，并使用反向积分的ODE来定义逆变换。模型具有自动解码结构，可以在训练期间与网络参数联合优化，以实现形状群之间的泛化。&lt;h4&gt;主要发现&lt;/h4&gt;AD-SVFD能够通过低维代码实现自我条件化，在推理时仅微调潜在代码，显著降低计算开销。使用隐式形状表示可以合成新的解剖结构。&lt;h4&gt;结论&lt;/h4&gt;在健康主动脉解剖结构上的数值实验表明，AD-SVFD在具有竞争力的计算成本下产生了高质量的结果。&lt;h4&gt;翻译&lt;/h4&gt;This work introduces AD-SVFD, a deep learning model for the deformation registration of vascular shapes to a pre-defined reference and for the generation of synthetic anatomies. AD-SVFD operates by representing each geometry as a weighted point cloud and models ambient space deformations as solutions at unit time of ODEs, whose time-independent right-hand sides are expressed through artificial neural networks. The model parameters are optimized by minimizing the Chamfer Distance between the deformed and reference point clouds, while backward integration of the ODE defines the inverse transformation. A distinctive feature of AD-SVFD is its auto-decoder structure, that enables generalization across shape cohorts and favors efficient weight sharing. In particular, each anatomy is associated with a low-dimensional code that acts as a self-conditioning field and that is jointly optimized with the network parameters during training. At inference, only the latent codes are fine-tuned, substantially reducing computational overheads. Furthermore, the use of implicit shape representations enables generative applications: new anatomies can be synthesized by suitably sampling from the latent space and applying the corresponding inverse transformations to the reference geometry. Numerical experiments, conducted on healthy aortic anatomies, showcase the high-quality results of AD-SVFD, which yields extremely accurate approximations at competitive computational costs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work introduces AD-SVFD, a deep learning model for the deformableregistration of vascular shapes to a pre-defined reference and for thegeneration of synthetic anatomies. AD-SVFD operates by representing eachgeometry as a weighted point cloud and models ambient space deformations assolutions at unit time of ODEs, whose time-independent right-hand sides areexpressed through artificial neural networks. The model parameters areoptimized by minimizing the Chamfer Distance between the deformed and referencepoint clouds, while backward integration of the ODE defines the inversetransformation. A distinctive feature of AD-SVFD is its auto-decoder structure,that enables generalization across shape cohorts and favors efficient weightsharing. In particular, each anatomy is associated with a low-dimensional codethat acts as a self-conditioning field and that is jointly optimized with thenetwork parameters during training. At inference, only the latent codes arefine-tuned, substantially reducing computational overheads. Furthermore, theuse of implicit shape representations enables generative applications: newanatomies can be synthesized by suitably sampling from the latent space andapplying the corresponding inverse transformations to the reference geometry.Numerical experiments, conducted on healthy aortic anatomies, showcase thehigh-quality results of AD-SVFD, which yields extremely accurate approximationsat competitive computational costs.</description>
      <author>example@mail.com (Riccardo Tenderini, Luca Pegolotti, Fanwei Kong, Stefano Pagani, Francesco Regazzoni, Alison L. Marsden, Simone Deparis)</author>
      <guid isPermaLink="false">2506.00947v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Improving Multi-Vehicle Perception Fusion with Millimeter-Wave Radar Assistance</title>
      <link>http://arxiv.org/abs/2506.00837v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  to appear in IEEE INFOCOM 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为MMatch的轻量级系统，用于实现毫米波雷达点云的准确和实时感知融合，以提高自动驾驶的安全性。&lt;h4&gt;背景&lt;/h4&gt;合作感知是提高驾驶安全性的新范式，通过共享传感器读数来实现。实时且准确地对齐和融合感知是实现这一愿景的关键技术。&lt;h4&gt;目的&lt;/h4&gt;为了满足自动驾驶对精度、实时性和适应性的要求，提出了一种新的方法。&lt;h4&gt;方法&lt;/h4&gt;MMatch系统利用毫米波雷达提供的精细空间信息，这些信息与所有车辆都有独特的关联，即使在不同的视角中也是如此。通过捕捉和理解这种关联中目标的独特局部和全局位置，可以快速找到所有可见车辆进行视角对齐。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MMatch在59毫秒内实现了厘米级精度，显著提高了自动驾驶的可靠性。&lt;h4&gt;结论&lt;/h4&gt;MMatch是一种有效的轻量级系统，可以准确和实时地融合感知，有助于提高自动驾驶的安全性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cooperative perception enables vehicles to share sensor readings and hasbecome a new paradigm to improve driving safety, where the key enablingtechnology for realizing this vision is to real-time and accurately align andfuse the perceptions. Recent advances to align the views rely on high-densityLiDAR data or fine-grained image feature representations, which however fail tomeet the requirements of accuracy, real-time, and adaptability for autonomousdriving. To this end, we present MMatch, a lightweight system that enablesaccurate and real-time perception fusion with mmWave radar point clouds. Thekey insight is that fine-grained spatial information provided by the radarpresent unique associations with all the vehicles even in two separate views.As a result, by capturing and understanding the unique local and globalposition of the targets in this association, we can quickly find out all theco-visible vehicles for view alignment. We implement MMatch on both thedatasets collected from the CARLA platform and the real-world traffic with over15,000 radar point cloud pairs. Experimental results show that MMatch achievesdecimeter-level accuracy within 59ms, which significantly improves thereliability for autonomous driving.</description>
      <author>example@mail.com (Zhiqing Luo, Yi Wang, Yingying He, Wei Wang)</author>
      <guid isPermaLink="false">2506.00837v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Constrained Stein Variational Gradient Descent for Robot Perception, Planning, and Identification</title>
      <link>http://arxiv.org/abs/2506.00589v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出两种新的框架，将约束优化原理应用于新的变分推理算法Stein变分梯度下降，以解决机器人学中的多核问题。&lt;h4&gt;背景&lt;/h4&gt;机器人学中的多核问题常常涉及不确定性，或者需要找到多个高质量可行解。&lt;h4&gt;目的&lt;/h4&gt;设计框架以支持多种类型的约束优化器，并处理任意约束，以解决机器人学中的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种通用的框架，该框架可以处理多种类型的约束优化器，并能够处理任意约束。&lt;h4&gt;主要发现&lt;/h4&gt;在多种问题上展示了该框架的应用，包括学习近似分布而不违反约束，例如避免碰撞的机器人运动计划、具有精确桌面放置约束的机器人臂关节角度以及具有桌面放置约束的点云中的物体姿态。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架能够有效地应用于机器人学中的约束优化问题，并生成满足特定约束的高质量解。&lt;h4&gt;翻译&lt;/h4&gt;Many core problems in robotics can be framed as constrained optimization problems. Often on these problems, the robotic system has uncertainty, or it would be advantageous to identify multiple high quality feasible solutions. To enable this, we present two novel frameworks for applying principles of constrained optimization to the new variational inference algorithm Stein variational gradient descent. Our general framework supports multiple types of constrained optimizers and can handle arbitrary constraints. We demonstrate on a variety of problems that we are able to learn to approximate distributions without violating constraints. Specifically, we show that we can build distributions of: robot motion plans that exactly avoid collisions, robot arm joint angles on the SE(3) manifold with exact table placement constraints, and object poses from point clouds with table placement constraints.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many core problems in robotics can be framed as constrained optimizationproblems. Often on these problems, the robotic system has uncertainty, or itwould be advantageous to identify multiple high quality feasible solutions. Toenable this, we present two novel frameworks for applying principles ofconstrained optimization to the new variational inference algorithm Steinvariational gradient descent. Our general framework supports multiple types ofconstrained optimizers and can handle arbitrary constraints. We demonstrate ona variety of problems that we are able to learn to approximate distributionswithout violating constraints. Specifically, we show that we can builddistributions of: robot motion plans that exactly avoid collisions, robot armjoint angles on the SE(3) manifold with exact table placement constraints, andobject poses from point clouds with table placement constraints.</description>
      <author>example@mail.com (Griffin Tabor, Tucker Hermans)</author>
      <guid isPermaLink="false">2506.00589v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>ViVo: A Dataset for Volumetric VideoReconstruction and Compression</title>
      <link>http://arxiv.org/abs/2506.00558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的三维视频重建和压缩数据集ViVo，旨在解决现有数据集在内容和多样性方面的不足。&lt;h4&gt;背景&lt;/h4&gt;随着神经体积视频重建和压缩研究的发展，需要更多样化和真实的数据集来开发和验证模型。&lt;h4&gt;目的&lt;/h4&gt;提出ViVo数据集，以支持三维视频重建和压缩的研究。&lt;h4&gt;方法&lt;/h4&gt;ViVo数据集包含14对多视图RGB和深度视频，同步于30FPS，并附带每帧校准和音频数据，以及相应的2D前景掩码和3D点云。&lt;h4&gt;主要发现&lt;/h4&gt;ViVo数据集展示了现有数据集在体积视频重建和压缩任务中的局限性，并证明了该数据集的挑战性。&lt;h4&gt;结论&lt;/h4&gt;需要开发更有效的算法来应对体积视频重建和压缩任务。&lt;h4&gt;翻译&lt;/h4&gt;As research on neural volumetric video reconstruction and compression flourishes, there is a need for diverse and realistic datasets, which can be used to develop and validate reconstruction and compression models. However, existing volumetric video datasets lack diverse content in terms of both semantic and low-level features that are commonly present in real-world production pipelines. In this context, we propose a new dataset, ViVo, for VolumetrIc VideO reconstruction and compression. The dataset is faithful to real-world volumetric video production and is the first dataset to extend the definition of diversity to include both human-centric characteristics (skin, hair, etc.) and dynamic visual phenomena (transparent, reflective, liquid, etc.). Each video sequence in this database contains raw data including fourteen multi-view RGB and depth video pairs, synchronized at 30FPS with per-frame calibration and audio data, and their associated 2-D foreground masks and 3-D point clouds. To demonstrate the use of this database, we have benchmarked three state-of-the-art (SotA) 3-D reconstruction methods and two volumetric video compression algorithms. The obtained results evidence the challenging nature of the proposed dataset and the limitations of existing datasets for both volumetric video reconstruction and compression tasks, highlighting the need to develop more effective algorithms for these applications. The database and the associated results are available at https://vivo-bvicr.github.io/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As research on neural volumetric video reconstruction and compressionflourishes, there is a need for diverse and realistic datasets, which can beused to develop and validate reconstruction and compression models. However,existing volumetric video datasets lack diverse content in terms of bothsemantic and low-level features that are commonly present in real-worldproduction pipelines. In this context, we propose a new dataset, ViVo, forVolumetrIc VideO reconstruction and compression. The dataset is faithful toreal-world volumetric video production and is the first dataset to extend thedefinition of diversity to include both human-centric characteristics (skin,hair, etc.) and dynamic visual phenomena (transparent, reflective, liquid,etc.). Each video sequence in this database contains raw data includingfourteen multi-view RGB and depth video pairs, synchronized at 30FPS withper-frame calibration and audio data, and their associated 2-D foreground masksand 3-D point clouds. To demonstrate the use of this database, we havebenchmarked three state-of-the-art (SotA) 3-D reconstruction methods and twovolumetric video compression algorithms. The obtained results evidence thechallenging nature of the proposed dataset and the limitations of existingdatasets for both volumetric video reconstruction and compression tasks,highlighting the need to develop more effective algorithms for theseapplications. The database and the associated results are available athttps://vivo-bvicr.github.io/</description>
      <author>example@mail.com (Adrian Azzarelli, Ge Gao, Ho Man Kwan, Fan Zhang, Nantheera Anantrasirichai, Ollie Moolan-Feroze, David Bull)</author>
      <guid isPermaLink="false">2506.00558v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>BAGNet: A Boundary-Aware Graph Attention Network for 3D Point Cloud Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2506.00475v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by the 2025 International Joint Conference on Neural  Networks (IJCNN 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Boundary-Aware Graph attention Network (BAGNet)的新型图注意力网络，用于点云语义分割，旨在减少计算成本并提高分割精度。&lt;h4&gt;背景&lt;/h4&gt;点云数据因其不规则和不结构化而具有挑战性，传统的基于图的方法虽然能建模点云，但计算成本高。&lt;h4&gt;目的&lt;/h4&gt;降低计算成本，同时提高点云语义分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;BAGNet包含一个边界感知图注意力层（BAGLayer），它通过边缘顶点融合和注意力系数来捕捉边界点的特征，并使用轻量级的注意力池化层提取点云的全局特征。&lt;h4&gt;主要发现&lt;/h4&gt;边界点具有更复杂的空间结构信息，BAGNet在标准数据集上的实验结果表明，其性能优于现有方法，具有更高的准确率和更少的推理时间。&lt;h4&gt;结论&lt;/h4&gt;BAGNet是一种有效的点云语义分割方法，能够在保证准确性的同时减少计算成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Since the point cloud data is inherently irregular and unstructured, pointcloud semantic segmentation has always been a challenging task. The graph-basedmethod attempts to model the irregular point cloud by representing it as agraph; however, this approach incurs substantial computational cost due to thenecessity of constructing a graph for every point within a large-scale pointcloud. In this paper, we observe that boundary points possess more intricatespatial structural information and develop a novel graph attention networkknown as the Boundary-Aware Graph attention Network (BAGNet). On one hand,BAGNet contains a boundary-aware graph attention layer (BAGLayer), whichemploys edge vertex fusion and attention coefficients to capture features ofboundary points, reducing the computation time. On the other hand, BAGNetemploys a lightweight attention pooling layer to extract the global feature ofthe point cloud to maintain model accuracy. Extensive experiments on standarddatasets demonstrate that BAGNet outperforms state-of-the-art methods in pointcloud semantic segmentation with higher accuracy and less inference time.</description>
      <author>example@mail.com (Wei Tao, Xiaoyang Qu, Kai Lu, Jiguang Wan, Shenglin He, Jianzong Wang)</author>
      <guid isPermaLink="false">2506.00475v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>PointODE: Lightweight Point Cloud Learning with Neural Ordinary Differential Equations on Edge</title>
      <link>http://arxiv.org/abs/2506.00438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PointODE的参数高效的ResNet-like架构，用于点云特征提取，并通过Neural ODE技术压缩参数，以提高边缘设备的性能。&lt;h4&gt;背景&lt;/h4&gt;嵌入式边缘设备常用于运行现实世界的点云应用，但深度学习方法可能因资源限制而无法在这些设备上运行。&lt;h4&gt;目的&lt;/h4&gt;填补深度学习方法在边缘设备上应用的空白。&lt;h4&gt;方法&lt;/h4&gt;引入PointODE，一种基于堆叠MLP块和残差连接的参数高效ResNet-like架构；利用Neural ODE技术压缩PointODE；提出点对齐归一化方法以处理特征点的非均匀分布；设计PointODE-Elite的轻量级版本，并为其设计专用加速器。&lt;h4&gt;主要发现&lt;/h4&gt;PointODE-Elite具有0.58M可训练参数，并设计有专门的FPGA加速器，实现多点特征提取的并行化，并存储所有参数于芯片上以减少外部数据传输。与ARM Cortex-A53 CPU相比，PointODE-Elite的加速器在Xilinx ZCU104板上加速了4.9倍的特征提取，提高了3.7倍的推理速度和3.5倍的能效。&lt;h4&gt;结论&lt;/h4&gt;尽管架构简单，PointODE-Elite在合成数据和真实世界分类数据集上表现出与最先进模型相媲美的准确性，大大提高了准确性与推理成本之间的权衡。&lt;h4&gt;翻译&lt;/h4&gt;摘要：嵌入式边缘设备通常用作运行现实世界点云应用的计算平台，但基于深度学习的新方法可能由于资源限制而无法适应此类设备。在本文中，我们通过引入PointODE，一种基于堆叠MLP块和残差连接的参数高效的ResNet-like架构，旨在填充这一空白。我们利用Neural ODE（常微分方程），ResNet的一种连续深度版本，最初是为建模连续时间系统的动力学而开发的，通过在MLP块之间重用相同的参数来压缩PointODE。为了处理特征点的非均匀分布，我们为PointODE提出了点对齐归一化。我们引入了PointODE-Elite作为轻量级版本，具有0.58M个可训练参数，并为其设计了一个用于嵌入式FPGA的专用加速器。该加速器由一个四阶段流水线组成，以并行化多个点的特征提取，并将所有参数存储在芯片上以消除大部分外部数据传输。与ARM Cortex-A53 CPU相比，在Xilinx ZCU104板上实现的加速器将特征提取速度提高了4.9倍，实现了3.7倍的推理速度和3.5倍的能效。尽管架构简单，PointODE-Elite在合成数据和真实世界分类数据集上与最先进的模型表现出竞争力，大大提高了准确性和推理成本之间的权衡。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Embedded edge devices are often used as a computing platform to runreal-world point cloud applications, but recent deep learning-based methods maynot fit on such devices due to limited resources. In this paper, we aim to fillthis gap by introducing PointODE, a parameter-efficient ResNet-likearchitecture for point cloud feature extraction based on a stack of MLP blockswith residual connections. We leverage Neural ODE (Ordinary DifferentialEquation), a continuous-depth version of ResNet originally developed formodeling the dynamics of continuous-time systems, to compress PointODE byreusing the same parameters across MLP blocks. The point-wise normalization isproposed for PointODE to handle the non-uniform distribution of feature points.We introduce PointODE-Elite as a lightweight version with 0.58M trainableparameters and design its dedicated accelerator for embedded FPGAs. Theaccelerator consists of a four-stage pipeline to parallelize the featureextraction for multiple points and stores the entire parameters on-chip toeliminate most of the off-chip data transfers. Compared to the ARM Cortex-A53CPU, the accelerator implemented on a Xilinx ZCU104 board speeds up the featureextraction by 4.9x, leading to 3.7x faster inference and 3.5x betterenergy-efficiency. Despite the simple architecture, PointODE-Elite showscompetitive accuracy to the state-of-the-art models on both synthetic andreal-world classification datasets, greatly improving the trade-off betweenaccuracy and inference cost.</description>
      <author>example@mail.com (Keisuke Sugiura, Mizuki Yasuda, Hiroki Matsutani)</author>
      <guid isPermaLink="false">2506.00438v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Voxelization for Transform coding of 3D Gaussian splatting data</title>
      <link>http://arxiv.org/abs/2506.00271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对3D高斯细分（3DGS）数据的压缩框架，该框架利用了最初为点云开发的变换编码工具。与现有的3DGS压缩方法不同，该方法能够在计算效率高的方式下以多个比特率生成压缩的3DGS模型。&lt;h4&gt;背景&lt;/h4&gt;点云体素化是一种离散化技术，点云编解码器使用它来提高编码效率，同时允许使用快速的变换编码算法。&lt;h4&gt;目的&lt;/h4&gt;提出一种自适应体素化算法，专门针对3DGS数据，以避免点云编解码器中使用的均匀体素化带来的低效。&lt;h4&gt;方法&lt;/h4&gt;确保较大体积的高斯位置以高分辨率表示，因为这些对渲染质量有显著影响。同时，对于密集区域中的较小高斯，使用低分辨率表示，这些对渲染质量的影响相对较低。这种自适应体素化方法显著减少了编码3DGS数据所需的高斯数量和比特率。体素化后，许多高斯被移动或消除。因此，提出了一种微调/重新着色剩余3DGS属性的方法，该方法可以通过初始化来减少所需的再训练量。&lt;h4&gt;主要发现&lt;/h4&gt;在预训练数据集上的实验结果表明，所提出的压缩框架优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的压缩框架能够高效地压缩3DGS数据，并且提供了优于现有方法的性能。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种针对3D高斯细分（3DGS）数据的压缩框架，该框架利用了最初为点云开发的变换编码工具。与现有的3DGS压缩方法不同，该方法能够在计算效率高的方式下以多个比特率生成压缩的3DGS模型。点云体素化是一种离散化技术，点云编解码器使用它来提高编码效率，同时允许使用快速的变换编码算法。提出了一种自适应体素化算法，专门针对3DGS数据，以避免点云编解码器中使用的均匀体素化带来的低效。确保较大体积的高斯位置以高分辨率表示，因为这些对渲染质量有显著影响。同时，对于密集区域中的较小高斯，使用低分辨率表示，这些对渲染质量的影响相对较低。这种自适应体素化方法显著减少了编码3DGS数据所需的高斯数量和比特率。体素化后，许多高斯被移动或消除。因此，提出了一种微调/重新着色剩余3DGS属性的方法，该方法可以通过初始化来减少所需的再训练量。在预训练数据集上的实验结果表明，所提出的压缩框架优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel compression framework for 3D Gaussian splatting (3DGS)data that leverages transform coding tools originally developed for pointclouds. Contrary to existing 3DGS compression methods, our approach can producecompressed 3DGS models at multiple bitrates in a computationally efficient way.Point cloud voxelization is a discretization technique that point cloud codecsuse to improve coding efficiency while enabling the use of fast transformcoding algorithms. We propose an adaptive voxelization algorithm tailored to3DGS data, to avoid the inefficiencies introduced by uniform voxelization usedin point cloud codecs. We ensure the positions of larger volume Gaussians arerepresented at high resolution, as these significantly impact renderingquality. Meanwhile, a low-resolution representation is used for dense regionswith smaller Gaussians, which have a relatively lower impact on renderingquality. This adaptive voxelization approach significantly reduces the numberof Gaussians and the bitrate required to encode the 3DGS data. Aftervoxelization, many Gaussians are moved or eliminated. Thus, we propose tofine-tune/recolor the remaining 3DGS attributes with an initialization that canreduce the amount of retraining required. Experimental results on pre-traineddatasets show that our proposed compression framework outperforms existingmethods.</description>
      <author>example@mail.com (Chenjunjie Wang, Shashank N. Sridhara, Eduardo Pavez, Antonio Ortega, Cheng Chang)</author>
      <guid isPermaLink="false">2506.00271v1</guid>
      <pubDate>Wed, 04 Jun 2025 14:37:22 +0800</pubDate>
    </item>
    <item>
      <title>End-to-End Framework for Predicting the Remaining Useful Life of Lithium-Ion Batteries</title>
      <link>http://arxiv.org/abs/2505.16664v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的剩余使用寿命（RUL）预测方法，旨在提高锂离子电池的维护效率。&lt;h4&gt;背景&lt;/h4&gt;准确预测锂离子电池的RUL对于及时维护和保障电动汽车等应用的运营效率至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的RUL预测方法，通过分析最近充放电循环数据来估计剩余可用循环次数。&lt;h4&gt;方法&lt;/h4&gt;该方法包括一个新颖的信号处理流程和一个深度学习预测模型。信号处理流程中，计算了基于电流和容量信号的导出容量特征。在预测模型中，使用一维卷积神经网络（CNN）、注意力长短期记忆（A-LSTM）和基于常微分方程的LSTM（ODE-LSTM）块组成的混合深度学习架构。&lt;h4&gt;主要发现&lt;/h4&gt;模型在跨不同学习策略和目标数据划分场景的迁移学习中被评估，结果表明模型在有限目标数据上微调时仍保持稳健的性能。在两个公开的大型数据集上的实验结果表明，该方法优于基线深度学习方法和机器学习技术，RMSE为101.59。&lt;h4&gt;结论&lt;/h4&gt;该方法具有强大的实际RUL预测应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction of the Remaining Useful Life (RUL) is essential forenabling timely maintenance of lithium-ion batteries, impacting the operationalefficiency of electric applications that rely on them. This paper proposes aRUL prediction approach that leverages data from recent charge-discharge cyclesto estimate the number of remaining usable cycles. The approach introduces botha novel signal processing pipeline and a deep learning prediction model. In thesignal preprocessing pipeline, a derived capacity feature $\dot{Q}(I, Q)$ iscomputed based on current and capacity signals. Alongside original capacity,voltage and current, these features are denoised and enhanced using statisticalmetrics and a delta-based method to capture differences between the current andprevious cycles. In the prediction model, the processed features are then fedinto a hybrid deep learning architecture composed of 1D Convolutional NeuralNetworks (CNN), Attentional Long Short-Term Memory (A-LSTM), and OrdinaryDifferential Equation-based LSTM (ODE-LSTM) blocks. This architecture isdesigned to capture both local signal characteristics and long-range temporaldependencies while modeling the continuous-time dynamics of batterydegradation. The model is further evaluated using transfer learning acrossdifferent learning strategies and target data partitioning scenarios. Resultsindicate that the model maintains robust performance, even when fine-tuned onlimited target data. Experimental results on two publicly available large-scaledatasets demonstrate that the proposed method outperforms a baseline deeplearning approach and machine learning techniques, achieving an RMSE of 101.59,highlighting its strong potential for real-world RUL prediction applications.</description>
      <author>example@mail.com (Khoa Tran, Tri Le, Bao Huynh, Hung-Cuong Trinh, Vy-Rin Nguyen)</author>
      <guid isPermaLink="false">2505.16664v2</guid>
      <pubDate>Tue, 03 Jun 2025 14:06:17 +0800</pubDate>
    </item>
  <item>
      <title>NUC-Net: Non-uniform Cylindrical Partition Network for Efficient LiDAR Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2505.24634v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at TCSVT in 2025.Code available at  https://github.com/alanWXZ/NUC-Net&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NUC-Net的非均匀圆柱分割网络，用于解决现有LiDAR语义分割方法的问题，包括计算成本高和内存消耗大，以及未很好地处理LiDAR点云的不平衡分布。&lt;h4&gt;背景&lt;/h4&gt;LiDAR语义分割在自动驾驶中扮演着重要角色，现有的基于体素的方法通过均匀分割3D LiDAR点云来形成基于笛卡尔/圆柱坐标的结构化表示。&lt;h4&gt;目的&lt;/h4&gt;提出NUC-Net以解决现有方法的缺点，包括降低计算成本和内存消耗，以及更好地处理点云的不平衡分布。&lt;h4&gt;方法&lt;/h4&gt;NUC-Net采用API方法非均匀分割径向轴，并生成具有代表性的体素表示。此外，还提出了一种非均匀多尺度聚合方法来提高上下文信息。&lt;h4&gt;主要发现&lt;/h4&gt;NUC-Net在SemanticKITTI和nuScenes数据集上实现了最先进的性能，具有更快的速度和更少的训练时间。该方法可以作为一个通用的LiDAR语义分割组件，通过4倍的训练速度、2倍的GPU内存减少和3倍的推理速度提升，显著提高了均匀方法的准确性和效率。&lt;h4&gt;结论&lt;/h4&gt;NUC-Net通过理论分析验证了其有效性，并探讨了点分布对性能的影响。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: LiDAR semantic segmentation plays a vital role in autonomous driving. Existing voxel-based methods for LiDAR semantic segmentation apply uniform partition to the 3D LiDAR point cloud to form a structured representation based on cartesian/cylindrical coordinates. Although these methods show impressive performance, the drawback of existing voxel-based methods remains in two aspects: (1) it requires a large enough input voxel resolution, which brings a large amount of computation cost and memory consumption. (2) it does not well handle the unbalanced point distribution of LiDAR point cloud. In this paper, we propose a non-uniform cylindrical partition network named NUC-Net to tackle the above challenges. Specifically, we propose the Arithmetic Progression of Interval (API) method to non-uniformly partition the radial axis and generate the voxel representation which is representative and efficient. Moreover, we propose a non-uniform multi-scale aggregation method to improve contextual information. Our method achieves state-of-the-art performance on SemanticKITTI and nuScenes datasets with much faster speed and much less training time. And our method can be a general component for LiDAR semantic segmentation, which significantly improves both the accuracy and efficiency of the uniform counterpart by 4 times faster training, 2 times GPU memory reduction, and 3 times inference speedup. We further provide theoretical analysis towards understanding why NUC is effective and how point distribution affects performance. Code is available at https://github.com/alanWXZ/NUC-Net.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TCSVT.2025.3554182&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR semantic segmentation plays a vital role in autonomous driving.Existing voxel-based methods for LiDAR semantic segmentation apply uniformpartition to the 3D LiDAR point cloud to form a structured representation basedon cartesian/cylindrical coordinates. Although these methods show impressiveperformance, the drawback of existing voxel-based methods remains in twoaspects: (1) it requires a large enough input voxel resolution, which brings alarge amount of computation cost and memory consumption. (2) it does not wellhandle the unbalanced point distribution of LiDAR point cloud. In this paper,we propose a non-uniform cylindrical partition network named NUC-Net to tacklethe above challenges. Specifically, we propose the Arithmetic Progression ofInterval (API) method to non-uniformly partition the radial axis and generatethe voxel representation which is representative and efficient. Moreover, wepropose a non-uniform multi-scale aggregation method to improve contextualinformation. Our method achieves state-of-the-art performance on SemanticKITTIand nuScenes datasets with much faster speed and much less training time. Andour method can be a general component for LiDAR semantic segmentation, whichsignificantly improves both the accuracy and efficiency of the uniformcounterpart by $4 \times$ training faster and $2 \times$ GPU memory reductionand $3 \times$ inference speedup. We further provide theoretical analysistowards understanding why NUC is effective and how point distribution affectsperformance. Code is available at\href{https://github.com/alanWXZ/NUC-Net}{https://github.com/alanWXZ/NUC-Net}.</description>
      <author>example@mail.com (Xuzhi Wang, Wei Feng, Lingdong Kong, Liang Wan)</author>
      <guid isPermaLink="false">2505.24634v2</guid>
      <pubDate>Tue, 03 Jun 2025 14:06:17 +0800</pubDate>
    </item>
    <item>
      <title>Pre-Training and Personalized Fine-Tuning via Over-the-Air Federated Meta-Learning: Convergence-Generalization Trade-Offs</title>
      <link>http://arxiv.org/abs/2406.11569v4</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  39 pages, 8 figures, submitted for possible journal publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于元学习的个性化联邦学习（meta-pFL）在无线设置下的泛化性能，探讨了在新的代理和任务上泛化与收敛之间的权衡。&lt;h4&gt;背景&lt;/h4&gt;现代人工智能应用如大型语言模型（LLMs）的训练范式已从预训练转向预训练后微调。由于公开数据仓库的减少和AI模型访问的民主化努力，预训练预计将越来越多地从当前集中式部署迁移到联邦学习（FL）实现。&lt;h4&gt;目的&lt;/h4&gt;研究meta-pFL在无线设置下的泛化性能，特别是当参与预训练阶段的代理通过共享无线信道与服务器连接时。&lt;h4&gt;方法&lt;/h4&gt;采用空中计算，研究了对新代理和任务的泛化与收敛之间的权衡。&lt;h4&gt;主要发现&lt;/h4&gt;权衡源于信道损坏可能增强泛化，同时降低收敛。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的数值结果验证了理论。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For modern artificial intelligence (AI) applications such as large languagemodels (LLMs), the training paradigm has recently shifted to pre-trainingfollowed by fine-tuning. Furthermore, owing to dwindling open repositories ofdata and thanks to efforts to democratize access to AI models, pre-training isexpected to increasingly migrate from the current centralized deployments tofederated learning (FL) implementations. Meta-learning provides a generalframework in which pre-training and fine-tuning can be formalized.Meta-learning-based personalized FL (meta-pFL) moves beyond basicpersonalization by targeting generalization to new agents and tasks. This paperstudies the generalization performance of meta-pFL for a wireless setting inwhich the agents participating in the pre-training phase, i.e., meta-learning,are connected via a shared wireless channel to the server. Adoptingover-the-air computing, we study the trade-off between generalization to newagents and tasks, on the one hand, and convergence, on the other hand. Thetrade-off arises from the fact that channel impairments may enhancegeneralization, while degrading convergence. Extensive numerical resultsvalidate the theory.</description>
      <author>example@mail.com (Haifeng Wen, Hong Xing, Osvaldo Simeone)</author>
      <guid isPermaLink="false">2406.11569v4</guid>
      <pubDate>Tue, 03 Jun 2025 14:06:17 +0800</pubDate>
    </item>
    <item>
      <title>VLM-3R: Vision-Language Models Augmented with Instruction-Aligned 3D Reconstruction</title>
      <link>http://arxiv.org/abs/2505.20279v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://vlm-3r.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为VLM-3R的统一框架，用于视觉语言模型，它通过3D重建指令调整来处理单目视频帧，实现3D场景的理解。&lt;h4&gt;背景&lt;/h4&gt;随着大型多模态模型在2D图像和视频领域的快速发展，研究者们开始将这些模型扩展到3D场景的理解，以实现类似人类的视觉空间智能。然而，在模型编码和数据获取方面，达到与人类相当的空间理解能力存在重大挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在通过VLM-3R框架，实现单目视频帧的3D空间理解和时空推理，并提高模型的准确性和可扩展性。&lt;h4&gt;方法&lt;/h4&gt;VLM-3R使用几何编码器推导出隐式的3D标记，以表示空间理解。通过空间-视觉-视图融合和超过200K个精心制作的3D重建指令调整问答对，VLM-3R能够有效地将现实世界的空间环境与语言指令对齐。&lt;h4&gt;主要发现&lt;/h4&gt;VLM-3R不仅促进了稳健的视觉空间推理，还实现了对时空3D环境变化的理解，在准确性和可扩展性方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;VLM-3R模型为理解和推理3D场景提供了新的方法，对于时间敏感的应用和单目视频输入具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;The rapid advancement of Large Multimodal Models (LMMs) for 2D images and videos has motivated extending these models to understand 3D scenes, aiming for human-like visual-spatial intelligence. Nevertheless, achieving deep spatial understanding comparable to human capabilities poses significant challenges in model encoding and data acquisition. Existing methods frequently depend on external depth sensors for geometry capture or utilize off-the-shelf algorithms for pre-constructing 3D maps, thereby limiting their scalability, especially with prevalent monocular video inputs and for time-sensitive applications. In this work, we introduce VLM-3R, a unified framework for Vision-Language Models (VLMs) that incorporates 3D Reconstructive instruction tuning. VLM-3R processes monocular video frames by employing a geometry encoder to derive implicit 3D tokens that represent spatial understanding. Leveraging our Spatial-Visual-View Fusion and over 200K curated 3D reconstructive instruction tuning question-answer (QA) pairs, VLM-3R effectively aligns real-world spatial context with language instructions. This enables monocular 3D spatial assistance and embodied reasoning. To facilitate the evaluation of temporal reasoning, we introduce the Vision-Spatial-Temporal Intelligence benchmark, featuring over 138.6K QA pairs across five distinct tasks focused on evolving spatial relationships. Extensive experiments demonstrate that our model, VLM-3R, not only facilitates robust visual-spatial reasoning but also enables the understanding of temporal 3D context changes, excelling in both accuracy and scalability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/VITA-Group/VLM-3R&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of Large Multimodal Models (LMMs) for 2D images andvideos has motivated extending these models to understand 3D scenes, aiming forhuman-like visual-spatial intelligence. Nevertheless, achieving deep spatialunderstanding comparable to human capabilities poses significant challenges inmodel encoding and data acquisition. Existing methods frequently depend onexternal depth sensors for geometry capture or utilize off-the-shelf algorithmsfor pre-constructing 3D maps, thereby limiting their scalability, especiallywith prevalent monocular video inputs and for time-sensitive applications. Inthis work, we introduce VLM-3R, a unified framework for Vision-Language Models(VLMs) that incorporates 3D Reconstructive instruction tuning. VLM-3R processesmonocular video frames by employing a geometry encoder to derive implicit 3Dtokens that represent spatial understanding. Leveraging our Spatial-Visual-ViewFusion and over 200K curated 3D reconstructive instruction tuningquestion-answer (QA) pairs, VLM-3R effectively aligns real-world spatialcontext with language instructions. This enables monocular 3D spatialassistance and embodied reasoning. To facilitate the evaluation of temporalreasoning, we introduce the Vision-Spatial-Temporal Intelligence benchmark,featuring over 138.6K QA pairs across five distinct tasks focused on evolvingspatial relationships. Extensive experiments demonstrate that our model,VLM-3R, not only facilitates robust visual-spatial reasoning but also enablesthe understanding of temporal 3D context changes, excelling in both accuracyand scalability.</description>
      <author>example@mail.com (Zhiwen Fan, Jian Zhang, Renjie Li, Junge Zhang, Runjin Chen, Hezhen Hu, Kevin Wang, Huaizhi Qu, Dilin Wang, Zhicheng Yan, Hongyu Xu, Justin Theiss, Tianlong Chen, Jiachen Li, Zhengzhong Tu, Zhangyang Wang, Rakesh Ranjan)</author>
      <guid isPermaLink="false">2505.20279v2</guid>
      <pubDate>Tue, 03 Jun 2025 14:06:17 +0800</pubDate>
    </item>
    <item>
      <title>SpeechVerifier: Robust Acoustic Fingerprint against Tampering Attacks via Watermarking</title>
      <link>http://arxiv.org/abs/2505.23821v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SpeechVerifier，一种基于发布语音本身来主动验证语音完整性的方法，以应对社交媒体时代恶意篡改公共演讲的问题。&lt;h4&gt;背景&lt;/h4&gt;社交媒体的兴起导致恶意篡改的公共演讲，尤其是有影响力的人物演讲，严重影响了社会稳定和公众信任。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有语音篡改检测方法不足的问题，即依赖外部参考数据或对攻击敏感但对良性操作（如压缩和重采样）不够鲁棒。&lt;h4&gt;方法&lt;/h4&gt;SpeechVerifier通过多尺度特征提取捕捉不同时间分辨率的语音特征，并使用对比学习生成指纹来检测不同粒度的修改。这些指纹设计为对良性操作鲁棒，但在恶意篡改时会发生显著变化。指纹通过段式水印嵌入到语音信号中，以便在没有外部参考的情况下进行语音验证。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SpeechVerifier在检测篡改攻击方面有效，并且对良性操作具有鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;SpeechVerifier是一种有效的语音完整性验证工具，可以有效地检测篡改攻击并抵抗良性操作。&lt;h4&gt;翻译&lt;/h4&gt;With the surge of social media, maliciously tampered public speeches, especially those from influential figures, have seriously affected social stability and public trust. Existing speech tampering detection methods remain insufficient: they either rely on external reference data or fail to be both sensitive to attacks and robust to benign operations, such as compression and resampling. To tackle these challenges, we introduce SpeechVerifer to proactively verify speech integrity using only the published speech itself, i.e., without requiring any external references. Inspired by audio fingerprinting and watermarking, SpeechVerifier can (i) effectively detect tampering attacks, (ii) be robust to benign operations and (iii) verify the integrity only based on published speeches. Briefly, SpeechVerifier utilizes multiscale feature extraction to capture speech features across different temporal resolutions. Then, it employs contrastive learning to generate fingerprints that can detect modifications at varying granularities. These fingerprints are designed to be robust to benign operations, but exhibit significant changes when malicious tampering occurs. To enable speech verification in a self-contained manner, the generated fingerprints are then embedded into the speech signal by segment-wise watermarking. Without external references, SpeechVerifier can retrieve the fingerprint from the published audio and check it with the embedded watermark to verify the integrity of the speech. Extensive experimental results demonstrate that the proposed SpeechVerifier is effective in detecting tampering attacks and robust to benign operations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the surge of social media, maliciously tampered public speeches,especially those from influential figures, have seriously affected socialstability and public trust. Existing speech tampering detection methods remaininsufficient: they either rely on external reference data or fail to be bothsensitive to attacks and robust to benign operations, such as compression andresampling. To tackle these challenges, we introduce SpeechVerifer toproactively verify speech integrity using only the published speech itself,i.e., without requiring any external references. Inspired by audiofingerprinting and watermarking, SpeechVerifier can (i) effectively detecttampering attacks, (ii) be robust to benign operations and (iii) verify theintegrity only based on published speeches. Briefly, SpeechVerifier utilizesmultiscale feature extraction to capture speech features across differenttemporal resolutions. Then, it employs contrastive learning to generatefingerprints that can detect modifications at varying granularities. Thesefingerprints are designed to be robust to benign operations, but exhibitsignificant changes when malicious tampering occurs. To enable speechverification in a self-contained manner, the generated fingerprints are thenembedded into the speech signal by segment-wise watermarking. Without externalreferences, SpeechVerifier can retrieve the fingerprint from the publishedaudio and check it with the embedded watermark to verify the integrity of thespeech. Extensive experimental results demonstrate that the proposedSpeechVerifier is effective in detecting tampering attacks and robust to benignoperations.</description>
      <author>example@mail.com (Lingfeng Yao, Chenpei Huang, Shengyao Wang, Junpei Xue, Hanqing Guo, Jiang Liu, Xun Chen, Miao Pan)</author>
      <guid isPermaLink="false">2505.23821v2</guid>
      <pubDate>Tue, 03 Jun 2025 14:06:17 +0800</pubDate>
    </item>
    <item>
      <title>Dual-Task Graph Neural Network for Joint Seizure Onset Zone Localization and Outcome Prediction using Stereo EEG</title>
      <link>http://arxiv.org/abs/2505.23669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了一种基于sEEG记录的图神经网络框架，用于预测耐药性癫痫患者的无发作结果并定位癫痫起源区。&lt;h4&gt;背景&lt;/h4&gt;癫痫患者手术中定位致痫脑区并预测术后无发作情况对于手术规划和患者管理至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过sEEG记录预测无发作结果并识别癫痫起源区。&lt;h4&gt;方法&lt;/h4&gt;研究引入了一种双任务图神经网络（GNN）框架，该框架在窗口化的sEEG记录上操作，通过构建功能连接图并提取节点特征来预测无发作结果和定位癫痫起源区。&lt;h4&gt;主要发现&lt;/h4&gt;模型在10折交叉验证下，对于无发作预测的平均图级准确率为89.31%，癫痫起源区的节点级定位准确率为94.72%。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的GNN框架在预测无发作结果和癫痫起源区定位方面具有较高准确性。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is about a study introducing a dual-task graph neural network (GNN) framework that operates on windowed sEEG recordings to jointly predict seizure-freedom outcomes and identify seizure-onset-zone (SOZ) channels. The model achieves a mean graph-level accuracy of 89.31% for seizure-freedom prediction and a node-level SOZ localization accuracy of 94.72% under 10-fold cross-validation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately localizing the brain regions that triggers seizures and predictingwhether a patient will be seizure-free after surgery are vital for surgicalplanning and patient management in drug-resistant epilepsy.Stereo-electroencephalography (sEEG) delivers high-fidelity intracranialrecordings that enable clinicians to precisely locate epileptogenic networks.However, the clinical identification is subjective and dependent on theexpertise of the clinical team. Data driven approaches in this domain aresparse, despite the fact that sEEG offers high temporal-fidelity related toseizure dynamics that can be leveraged using graph structures ideal forimitating brain networks. In this study, we introduce a dual-task graph-neuralnetwork (GNN) framework that operates on windowed sEEG recordings to jointlypredict seizure-freedom outcomes and identify seizure-onset-zone (SOZ)channels. We assemble non-overlapping 10 second windows from 51 clinicalseizures spread across 20 pediatric patients, with sEEG data annotated byclinical experts. For each temporal window we construct a functionalconnectivity graph via thresholded Pearson correlations and extract rich nodefeatures (spectral, statistical, wavelet, Hjorth and local graph features),alongside six global graph descriptors. We optimize a combined cross-entropyloss with a tunable task-weight, and select model hyper-parameters via Optuna.Under window-level 10-fold cross-validation, the model achieves a meangraph-level accuracy of $89.31 \pm 0.0976 \%$ for seizure-freedom predictionand a node-level SOZ localization accuracy of $94.72. \pm 0.0041 \%$. For thebest performing model, we ran additive and leave-one-out ablation studies toexplore feature importance for graph and node-level accuracy.</description>
      <author>example@mail.com (Syeda Abeera Amir, Artur Agaronyan, William Gaillard, Chima Oluigbo, Syed Muhammad Anwar)</author>
      <guid isPermaLink="false">2505.23669v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
  <item>
      <title>6D Pose Estimation on Point Cloud Data through Prior Knowledge Integration: A Case Study in Autonomous Disassembly</title>
      <link>http://arxiv.org/abs/2505.24669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究在计算机视觉领域，即使利用3D点云数据，精确估计6D姿态仍然是一个挑战。在制造业中，利用先验知识可以提高这一任务的效率。研究重点在于通过识别和估计电机的螺栓6D姿态，以促进产品生命周期的工程化。由于遮挡和单视图数据获取的限制，特别是在电机夹紧系统中，某些部分被遮挡，使得一些螺栓难以察觉。因此，开发一个能够获取完整螺栓信息的综合流程至关重要。本文以螺栓检测作为项目的一个相关用例，介绍了一个精心设计的多阶段流程，有效地捕获了电机上所有螺栓的6D信息，展示了在处理这一挑战性任务时先验知识的有效利用。&lt;h4&gt;背景&lt;/h4&gt;在计算机视觉领域，精确估计6D姿态是一个挑战，尤其在制造业中，利用先验知识可以提高这一任务的效率。&lt;h4&gt;目的&lt;/h4&gt;识别和估计电机的螺栓6D姿态，促进产品生命周期的工程化。&lt;h4&gt;方法&lt;/h4&gt;开发一个能够获取完整螺栓信息的综合流程，并利用先验知识处理挑战性任务。&lt;h4&gt;主要发现&lt;/h4&gt;提出的多阶段流程能够有效地捕获电机上所有螺栓的6D信息。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅对6D姿态估计领域做出了贡献，还强调了将特定领域的见解整合到解决制造业和自动化中复杂问题的可行性。&lt;h4&gt;翻译&lt;/h4&gt;The accurate estimation of 6D pose remains a challenging task within the computer vision domain, even when utilizing 3D point cloud data. Conversely, in the manufacturing domain, instances arise where leveraging prior knowledge can yield advancements in this endeavor. This study focuses on the disassembly of starter motors to augment the engineering of product life cycles. A pivotal objective in this context involves the identification and 6D pose estimation of bolts affixed to the motors, facilitating automated disassembly within the manufacturing workflow. Complicating matters, the presence of occlusions and the limitations of single-view data acquisition, notably when motors are placed in a clamping system, obscure certain portions and render some bolts imperceptible. Consequently, the development of a comprehensive pipeline capable of acquiring complete bolt information is imperative to avoid oversight in bolt detection. In this paper, employing the task of bolt detection within the scope of our project as a pertinent use case, we introduce a meticulously devised pipeline. This multi-stage pipeline effectively captures the 6D information with regard to all bolts on the motor, thereby showcasing the effective utilization of prior knowledge in handling this challenging task. The proposed methodology not only contributes to the field of 6D pose estimation but also underscores the viability of integrating domain-specific insights to tackle complex problems in manufacturing and automation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accurate estimation of 6D pose remains a challenging task within thecomputer vision domain, even when utilizing 3D point cloud data. Conversely, inthe manufacturing domain, instances arise where leveraging prior knowledge canyield advancements in this endeavor. This study focuses on the disassembly ofstarter motors to augment the engineering of product life cycles. A pivotalobjective in this context involves the identification and 6D pose estimation ofbolts affixed to the motors, facilitating automated disassembly within themanufacturing workflow. Complicating matters, the presence of occlusions andthe limitations of single-view data acquisition, notably when motors are placedin a clamping system, obscure certain portions and render some boltsimperceptible. Consequently, the development of a comprehensive pipelinecapable of acquiring complete bolt information is imperative to avoid oversightin bolt detection. In this paper, employing the task of bolt detection withinthe scope of our project as a pertinent use case, we introduce a meticulouslydevised pipeline. This multi-stage pipeline effectively captures the 6Dinformation with regard to all bolts on the motor, thereby showcasing theeffective utilization of prior knowledge in handling this challenging task. Theproposed methodology not only contributes to the field of 6D pose estimationbut also underscores the viability of integrating domain-specific insights totackle complex problems in manufacturing and automation.</description>
      <author>example@mail.com (Chengzhi Wu, Hao Fu, Jan-Philipp Kaiser, Erik Tabuchi Barczak, Julius Pfrommer, Gisela Lanza, Michael Heizmann, Jürgen Beyerer)</author>
      <guid isPermaLink="false">2505.24669v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>The Road to Generalizable Neuro-Symbolic Learning Should be Paved with Foundation Models</title>
      <link>http://arxiv.org/abs/2505.24874v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;神经符号学习被提出以解决训练神经网络进行复杂推理任务时的挑战，并带来可解释性、可靠性和效率等额外好处。&lt;h4&gt;背景&lt;/h4&gt;神经符号学习方法传统上与符号程序结合训练神经模型，但面临重大挑战，限制了它们解决简单问题。&lt;h4&gt;目的&lt;/h4&gt;探讨在基础模型时代，神经符号学习中的专门模型训练在其中的作用。&lt;h4&gt;方法&lt;/h4&gt;通过分析传统神经符号学习在计算、数据和程序方面的三个陷阱，探讨这些问题导致的泛化问题。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型使可泛化的神经符号解决方案成为可能，提供了一条实现神经符号学习原始目标而不带来从头开始训练的缺点的方法。&lt;h4&gt;结论&lt;/h4&gt;基础模型为神经符号学习提供了实现其目标的途径，解决了传统方法的局限性。&lt;h4&gt;翻译&lt;/h4&gt;Neuro-symbolic learning was proposed to address challenges with training neural networks for complex reasoning tasks with the added benefits of interpretability, reliability, and efficiency. Neuro-symbolic learning methods traditionally train neural models in conjunction with symbolic programs, but they face significant challenges that limit them to simplistic problems. On the other hand, purely-neural foundation models now reach state-of-the-art performance through prompting rather than training, but they are often unreliable and lack interpretability. Supplementing foundation models with symbolic programs, which we call neuro-symbolic prompting, provides a way to use these models for complex reasoning tasks. Doing so raises the question: What role does specialized model training as part of neuro-symbolic learning have in the age of foundation models? To explore this question, we highlight three pitfalls of traditional neuro-symbolic learning with respect to the compute, data, and programs leading to generalization problems. This position paper argues that foundation models enable generalizable neuro-symbolic solutions, offering a path towards achieving the original goals of neuro-symbolic learning without the downsides of training from scratch.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neuro-symbolic learning was proposed to address challenges with trainingneural networks for complex reasoning tasks with the added benefits ofinterpretability, reliability, and efficiency. Neuro-symbolic learning methodstraditionally train neural models in conjunction with symbolic programs, butthey face significant challenges that limit them to simplistic problems. On theother hand, purely-neural foundation models now reach state-of-the-artperformance through prompting rather than training, but they are oftenunreliable and lack interpretability. Supplementing foundation models withsymbolic programs, which we call neuro-symbolic prompting, provides a way touse these models for complex reasoning tasks. Doing so raises the question:What role does specialized model training as part of neuro-symbolic learninghave in the age of foundation models? To explore this question, we highlightthree pitfalls of traditional neuro-symbolic learning with respect to thecompute, data, and programs leading to generalization problems. This positionpaper argues that foundation models enable generalizable neuro-symbolicsolutions, offering a path towards achieving the original goals ofneuro-symbolic learning without the downsides of training from scratch.</description>
      <author>example@mail.com (Adam Stein, Aaditya Naik, Neelay Velingker, Mayur Naik, Eric Wong)</author>
      <guid isPermaLink="false">2505.24874v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Conformal Prediction for Zero-Shot Models</title>
      <link>http://arxiv.org/abs/2505.24693v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025. Code: https://github.com/jusiro/CLIP-Conformal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了在大规模预训练的视觉语言模型中，通过分割一致性预测范式来提高模型的可靠性和不确定性。&lt;h4&gt;背景&lt;/h4&gt;大规模预训练的视觉语言模型在下游任务中表现出前所未有的适应性和泛化能力，但其可靠性和不确定性尚未得到充分关注。&lt;h4&gt;目的&lt;/h4&gt;研究CLIP模型在分割一致性预测范式下的能力，该范式基于小规模标记校准集为黑盒模型提供理论保证。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Conf-OT的迁移学习设置，该设置在结合校准集和查询集上进行归纳操作，通过解决最优传输问题来弥合预训练和适应之间的领域差距。&lt;h4&gt;主要发现&lt;/h4&gt;Conf-OT在15个数据集和三种非一致性得分上全面探索了这种一致性预测策略，提供了一致相对效率提升，最高可达20%，同时比流行的归纳方法快15倍。&lt;h4&gt;结论&lt;/h4&gt;Conf-OT方法在保持覆盖保证的同时，通过迁移学习有效提高了模型的一致性预测能力，并显著提升了效率。&lt;h4&gt;翻译&lt;/h4&gt;This study investigates the capability of CLIP models under the split conformal prediction paradigm, which provides theoretical guarantees to black-box models based on a small, labeled calibration set. In contrast to the mainstream literature on conformal predictors in vision classifiers, foundation models exhibit a particular characteristic: they are pre-trained on an inaccessiblesource domain on a one-time basis, different from the transferred task. This domain drift negatively affects the efficiency of the conformal sets and poses additional challenges. To alleviate this issue, we propose Conf-OT, a transfer learning setting that operates transductive over the combined calibration and query sets. Solving an optimal transport problem, the proposed method bridges the domain gap between pre-training and adaptation without requiring additional data splits but still maintaining coverage guarantees. We comprehensively explore this conformal prediction strategy on a broad span of 15 datasets and three non-conformity scores. Conf-OT provides consistent relative improvements of up to 20% on set efficiency while being 15 times faster than popular transductive approaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models pre-trained at large scale have shown unprecedentedadaptability and generalization to downstream tasks. Although itsdiscriminative potential has been widely explored, its reliability anduncertainty are still overlooked. In this work, we investigate the capabilitiesof CLIP models under the split conformal prediction paradigm, which providestheoretical guarantees to black-box models based on a small, labeledcalibration set. In contrast to the main body of literature on conformalpredictors in vision classifiers, foundation models exhibit a particularcharacteristic: they are pre-trained on a one-time basis on an inaccessiblesource domain, different from the transferred task. This domain driftnegatively affects the efficiency of the conformal sets and poses additionalchallenges. To alleviate this issue, we propose Conf-OT, a transfer learningsetting that operates transductive over the combined calibration and querysets. Solving an optimal transport problem, the proposed method bridges thedomain gap between pre-training and adaptation without requiring additionaldata splits but still maintaining coverage guarantees. We comprehensivelyexplore this conformal prediction strategy on a broad span of 15 datasets andthree non-conformity scores. Conf-OT provides consistent relative improvementsof up to 20% on set efficiency while being 15 times faster than populartransductive approaches.</description>
      <author>example@mail.com (Julio Silva-Rodríguez, Ismail Ben Ayed, Jose Dolz)</author>
      <guid isPermaLink="false">2505.24693v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Weisfeiler and Leman Follow the Arrow of Time: Expressive Power of Message Passing in Temporal Event Graphs</title>
      <link>http://arxiv.org/abs/2505.24438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了时间图在时间影响下因果拓扑结构的重要性，并提出了一种新的概念——一致事件图同构，用于分析时间图神经网络的表达能力。&lt;h4&gt;背景&lt;/h4&gt;时间图具有独特的因果拓扑结构，但现有的时间图神经网络（TGNNs）往往忽略这种结构。目前缺乏一种将图同构推广到时间图的通用方法，无法完全捕捉其因果拓扑。&lt;h4&gt;目的&lt;/h4&gt;为了分析TGNNs的表达能力，本文旨在提出一种新的时间图同构概念，并开发一种适用于时间图神经网络的消息传递方案。&lt;h4&gt;方法&lt;/h4&gt;引入了一致事件图同构，该方法利用时间图中的时间展开表示来捕捉因果路径。同时，将Weisfeiler-Leman算法推广到时间图，以启发式地区分非同构的时间图。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出的方法与现有时间图同构概念进行了比较，并展示了其在时间图分类实验中的优越性。&lt;h4&gt;结论&lt;/h4&gt;本文的理论基础为时间图神经网络提供了一种新的消息传递方案，实验表明该方法在时间图分类任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;An important characteristic of temporal graphs is how the directed arrow of time influences their causal topology, i.e., which nodes can possibly influence each other causally via time-respecting paths. The resulting patterns are often neglected by temporal graph neural networks (TGNNs). To formally analyze the expressive power of TGNNs, we lack a generalization of graph isomorphism to temporal graphs that fully captures their causal topology. Addressing this gap, we introduce the notion of consistent event graph isomorphism, which utilizes a time-unfolded representation of time-respecting paths in temporal graphs. We compare this definition with existing notions of temporal graph isomorphisms. We illustrate and highlight the advantages of our approach and develop a temporal generalization of the Weisfeiler-Leman algorithm to heuristically distinguish non-isomorphic temporal graphs. Building on this theoretical foundation, we derive a novel message passing scheme for temporal graph neural networks that operates on the event graph representation of temporal graphs. An experimental evaluation shows that our approach performs well in a temporal graph classification experiment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; An important characteristic of temporal graphs is how the directed arrow oftime influences their causal topology, i.e., which nodes can possibly influenceeach other causally via time-respecting paths. The resulting patterns are oftenneglected by temporal graph neural networks (TGNNs). To formally analyze theexpressive power of TGNNs, we lack a generalization of graph isomorphism totemporal graphs that fully captures their causal topology. Addressing this gap,we introduce the notion of consistent event graph isomorphism, which utilizes atime-unfolded representation of time-respecting paths in temporal graphs. Wecompare this definition with existing notions of temporal graph isomorphisms.We illustrate and highlight the advantages of our approach and develop atemporal generalization of the Weisfeiler-Leman algorithm to heuristicallydistinguish non-isomorphic temporal graphs. Building on this theoreticalfoundation, we derive a novel message passing scheme for temporal graph neuralnetworks that operates on the event graph representation of temporal graphs. Anexperimental evaluation shows that our approach performs well in a temporalgraph classification experiment.</description>
      <author>example@mail.com (Franziska Heeg, Jonas Sauer, Petra Mutzel, Ingo Scholtes)</author>
      <guid isPermaLink="false">2505.24438v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>A 3D Mobile Crowdsensing Framework for Sustainable Urban Digital Twins</title>
      <link>http://arxiv.org/abs/2505.24348v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 18 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对可持续城市数字孪生（UDTs）的3D移动众包感知（3D-MCS）框架。&lt;h4&gt;背景&lt;/h4&gt;该框架包括四个关键机制：3D-MCS机制、基于Geohash的空间信息管理机制、UDTs的动态点云集成机制和基于Web的3D-MCS及UDTs实时可视化器。&lt;h4&gt;目的&lt;/h4&gt;该框架旨在通过有效的数据收集和分析，实现UDTs的实时可视化。&lt;h4&gt;方法&lt;/h4&gt;主动感知模型采用游戏化的3D-MCS方法，参与者通过增强现实领土着色游戏收集点云数据；被动感知模型则采用可穿戴3D-MCS方法，参与者将智能手机挂在脖子上，不干扰日常生活。空间信息管理机制使用Geohash有效地划分空间区域。动态点云集成机制通过全局和局部点云注册将3D-MCS收集的点云集成到UDTs中。&lt;h4&gt;主要发现&lt;/h4&gt;通过真实世界的实验验证了所提框架的有效性，从主观评价和数据收集分析的角度验证了3D-MCS模型的有效性，并使用数据集分析了动态点云集成机制的性能。&lt;h4&gt;结论&lt;/h4&gt;该框架能够有效实现UDTs的3D-MCS数据收集和集成，为城市规划和监控提供了有力支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this article, we propose a 3D mobile crowdsensing (3D-MCS) framework aimedat sustainable urban digital twins (UDTs). The framework comprises four keymechanisms: (1) the 3D-MCS mechanism, consisting of active and passive models;(2) the Geohash-based spatial information management mechanism; (3) the dynamicpoint cloud integration mechanism for UDTs; and (4) the web-based real-timevisualizer for 3D-MCS and UDTs. The active sensing model features a gamified3D-MCS approach, where participants collect point cloud data through anaugmented reality territory coloring game. In contrast, the passive sensingmodel employs a wearable 3D-MCS approach, where participants wear smartphonesaround their necks without disrupting daily activities. The spatial informationmanagement mechanism efficiently partitions the space into regions usingGeohash. The dynamic point cloud integration mechanism incorporates pointclouds collected by 3D-MCS into UDTs through global and local point cloudregistration. Finally, we evaluated the proposed framework through real-worldexperiments. We verified the effectiveness of the proposed 3D-MCS models fromthe perspectives of subjective evaluation and data collection and analysis.Furthermore, we analyzed the performance of the dynamic point cloud integrationusing a dataset.</description>
      <author>example@mail.com (Taku Yamazaki, Kaito Watanabe, Tatsuya Kase, Kenta Hasegawa, Koki Saida, Takumi Miyoshi)</author>
      <guid isPermaLink="false">2505.24348v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Context is Gold to find the Gold Passage: Evaluating and Training Contextual Document Embeddings</title>
      <link>http://arxiv.org/abs/2505.24782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的文本嵌入方法，用于解决现代文档检索嵌入方法在编码同一文档中的段落时，往往忽略文档其他部分的重要上下文信息的问题。&lt;h4&gt;背景&lt;/h4&gt;现代文档检索嵌入方法通常独立地编码同一文档中的段落，这导致忽略了文档中其他部分的重要上下文信息。&lt;h4&gt;目的&lt;/h4&gt;通过引入ConTEB（上下文感知文本嵌入基准），评估检索模型在利用文档全局上下文方面的能力，并提出InSeNT（序列负训练）方法，以增强上下文表示学习并保持计算效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为InSeNT的对比后训练方法，该方法结合了晚段池化，以增强上下文表示学习，同时保持计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，在需要上下文的检索场景中，最先进的嵌入模型表现不佳。InSeNT方法显著提高了检索质量，并且嵌入的段落对子优化的段落分割策略和更大的检索语料库大小更加鲁棒。&lt;h4&gt;结论&lt;/h4&gt;本文提出的InSeNT方法在提高检索质量的同时，保持了基模型性能，并且对不同的段落分割策略和检索语料库大小具有更好的适应性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代文档检索嵌入方法的一个局限性是它们通常独立地编码来自同一文档的段落，经常忽略文档其余部分可能极大地改进单个段落表示的关键上下文信息。在这项工作中，我们引入了ConTEB（上下文感知文本嵌入基准），这是一个旨在评估检索模型在利用文档全局上下文能力方面的基准。我们的结果表明，在需要上下文的检索场景中，最先进的嵌入模型表现不佳。为了解决这一局限性，我们提出了InSeNT（序列负训练），一种新颖的对比后训练方法，该方法与晚段池化相结合，增强了上下文表示学习，同时保持了计算效率。我们的方法在ConTEB上显著提高了检索质量，而没有牺牲基模型性能。我们进一步发现，使用我们的方法嵌入的段落对子优化的段落分割策略和更大的检索语料库大小更加鲁棒。我们已在https://github.com/illuin-tech/contextual-embeddings上开源所有工件。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A limitation of modern document retrieval embedding methods is that theytypically encode passages (chunks) from the same documents independently, oftenoverlooking crucial contextual information from the rest of the document thatcould greatly improve individual chunk representations.  In this work, we introduce ConTEB (Context-aware Text Embedding Benchmark), abenchmark designed to evaluate retrieval models on their ability to leveragedocument-wide context. Our results show that state-of-the-art embedding modelsstruggle in retrieval scenarios where context is required. To address thislimitation, we propose InSeNT (In-sequence Negative Training), a novelcontrastive post-training approach which combined with late chunking poolingenhances contextual representation learning while preserving computationalefficiency. Our method significantly improves retrieval quality on ConTEBwithout sacrificing base model performance. We further find chunks embeddedwith our method are more robust to suboptimal chunking strategies and largerretrieval corpus sizes. We open-source all artifacts athttps://github.com/illuin-tech/contextual-embeddings.</description>
      <author>example@mail.com (Max Conti, Manuel Faysse, Gautier Viaud, Antoine Bosselut, Céline Hudelot, Pierre Colombo)</author>
      <guid isPermaLink="false">2505.24782v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Autoregression-free video prediction using diffusion model for mitigating error propagation</title>
      <link>http://arxiv.org/abs/2505.22111v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散模型的AutoRegression-Free（ARFree）视频预测框架，旨在解决现有视频预测方法在预测远期帧时出现的误差传播问题。&lt;h4&gt;背景&lt;/h4&gt;现有的长期视频预测方法通常依赖于自回归视频预测机制，但这种机制在预测远期帧时容易产生误差传播。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了一种不依赖自回归的视频预测框架。&lt;h4&gt;方法&lt;/h4&gt;该框架包含两个关键组件：1）运动预测模块，通过从上下文帧元组中提取的运动特征来预测未来运动；2）训练方法，旨在提高相邻未来帧元组之间的运动连续性和上下文一致性。&lt;h4&gt;主要发现&lt;/h4&gt;通过两个基准数据集的实验，表明提出的ARFree视频预测框架优于几种最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;ARFree视频预测框架在减少误差传播方面表现出色，为视频预测提供了一种新的有效方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing long-term video prediction methods often rely on an autoregressivevideo prediction mechanism. However, this approach suffers from errorpropagation, particularly in distant future frames. To address this limitation,this paper proposes the first AutoRegression-Free (ARFree) video predictionframework using diffusion models. Different from an autoregressive videoprediction mechanism, ARFree directly predicts any future frame tuples from thecontext frame tuple. The proposed ARFree consists of two key components: 1) amotion prediction module that predicts a future motion using motion featureextracted from the context frame tuple; 2) a training method that improvesmotion continuity and contextual consistency between adjacent future frametuples. Our experiments with two benchmark datasets show that the proposedARFree video prediction framework outperforms several state-of-the-art videoprediction methods.</description>
      <author>example@mail.com (Woonho Ko, Jin Bok Park, Il Yong Chun)</author>
      <guid isPermaLink="false">2505.22111v2</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>SiLVR: A Simple Language-based Video Reasoning Framework</title>
      <link>http://arxiv.org/abs/2505.24869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SiLVR是一个基于简单语言的视频推理框架，旨在提升多模态大型语言模型在视频语言任务上的推理能力。&lt;h4&gt;背景&lt;/h4&gt;尽管测试时优化在大型语言模型（LLMs）的推理能力上取得了显著进展，但多模态LLMs（MLLMs）在复杂视频语言任务上的推理能力仍然落后。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，提出SiLVR框架，以分解复杂视频理解过程为两个阶段。&lt;h4&gt;方法&lt;/h4&gt;第一阶段，SiLVR利用多感官输入（如短视频字幕和音频/语音字幕）将原始视频转换为基于语言的表示。第二阶段，将语言描述输入到强大的推理LLM中，以解决复杂的视频语言理解任务。为了处理长上下文的多感官输入，使用自适应标记减少方案，动态确定采样标记的时间粒度。&lt;h4&gt;主要发现&lt;/h4&gt;SiLVR在Video-MME（长）、Video-MMMU（理解）、Video-MMLU、CGBench和EgoLife等任务上取得了最佳结果。实证研究表明，即使没有显式地针对视频进行训练，强大的推理LLM也能有效地从视频中聚集多感官输入信息，以完成视频中的复杂时间、因果、长上下文和知识获取推理任务。&lt;h4&gt;结论&lt;/h4&gt;SiLVR是一个简单、模块化和无需训练的视频推理框架，显著提升了MLLMs在视频语言任务上的推理能力。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in test-time optimization have led to remarkable reasoning capabilities in Large Language Models (LLMs), enabling them to solve highly complex problems in math and coding. However, the reasoning capabilities of multimodal LLMs (MLLMs) still significantly lag, especially for complex video-language tasks. To address this issue, we present SiLVR, a SimpleLanguage-based Video Reasoning framework that decomposes complex video understanding into two stages. In the first stage, SiLVR transforms raw video into language-based representations using multisensory inputs, such as short clip captions and audio/speech subtitles. In the second stage, language descriptions are fed into a powerful reasoning LLM to solve complex video-language understanding tasks. To handle long-context multisensory inputs, we use an adaptive token reduction scheme, which dynamically determines the temporal granularity with which to sample the tokens. Our simple, modular, and training-free video reasoning framework achieves the best-reported results on Video-MME (long), Video-MMMU (comprehension), Video-MMLU, CGBench, and EgoLife. Furthermore, our empirical study focused on video reasoning capabilities shows that, despite not being explicitly trained on video, strong reasoning LLMs can effectively aggregate multisensory input information from video, speech, and audio for complex temporal, causal, long-context, and knowledge acquisition reasoning tasks in video. Code is available at https://github.com/CeeZh/SILVR.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in test-time optimization have led to remarkable reasoningcapabilities in Large Language Models (LLMs), enabling them to solve highlycomplex problems in math and coding. However, the reasoning capabilities ofmultimodal LLMs (MLLMs) still significantly lag, especially for complexvideo-language tasks. To address this issue, we present SiLVR, a SimpleLanguage-based Video Reasoning framework that decomposes complex videounderstanding into two stages. In the first stage, SiLVR transforms raw videointo language-based representations using multisensory inputs, such as shortclip captions and audio/speech subtitles. In the second stage, languagedescriptions are fed into a powerful reasoning LLM to solve complexvideo-language understanding tasks. To handle long-context multisensory inputs,we use an adaptive token reduction scheme, which dynamically determines thetemporal granularity with which to sample the tokens. Our simple, modular, andtraining-free video reasoning framework achieves the best-reported results onVideo-MME (long), Video-MMMU (comprehension), Video-MMLU, CGBench, and EgoLife.Furthermore, our empirical study focused on video reasoning capabilities showsthat, despite not being explicitly trained on video, strong reasoning LLMs caneffectively aggregate multisensory input information from video, speech, andaudio for complex temporal, causal, long-context, and knowledge acquisitionreasoning tasks in video. Code is available at https://github.com/CeeZh/SILVR.</description>
      <author>example@mail.com (Ce Zhang, Yan-Bo Lin, Ziyang Wang, Mohit Bansal, Gedas Bertasius)</author>
      <guid isPermaLink="false">2505.24869v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Tackling View-Dependent Semantics in 3D Language Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2505.24746v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 camera ready. Project Page:  https://jumpat.github.io/laga-page/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LaGa的方法，用于从RGB图像中重建高质感的3D场景，并扩展了3D Gaussian Splatting技术以支持语言驱动的开放词汇场景理解。&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting在3D场景重建方面取得了进展，但现有研究在将2D语义特征投影到3D高斯上时，忽略了2D和3D理解之间的基本差距，即3D物体可能从不同视角表现出不同的语义。&lt;h4&gt;目的&lt;/h4&gt;提出LaGa方法，以解决上述挑战，实现更全面的3D场景理解。&lt;h4&gt;方法&lt;/h4&gt;LaGa通过将3D场景分解为对象，建立跨视角的语义连接。然后，通过聚类语义描述符并基于多视角语义重新加权，构建视角聚合的语义表示。&lt;h4&gt;主要发现&lt;/h4&gt;LaGa有效捕捉了视角依赖性语义的关键信息，显著提高了对3D场景的理解。在LERF-OVS数据集上，LaGa相对于之前的SOTA方法实现了+18.7%的mIoU提升。&lt;h4&gt;结论&lt;/h4&gt;LaGa是一个有效的3D场景重建方法，能够提高对视角依赖性语义的理解，并显著优于现有技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in 3D Gaussian Splatting (3D-GS) enable high-quality 3Dscene reconstruction from RGB images. Many studies extend this paradigm forlanguage-driven open-vocabulary scene understanding. However, most of themsimply project 2D semantic features onto 3D Gaussians and overlook afundamental gap between 2D and 3D understanding: a 3D object may exhibitvarious semantics from different viewpoints--a phenomenon we termview-dependent semantics. To address this challenge, we propose LaGa (LanguageGaussians), which establishes cross-view semantic connections by decomposingthe 3D scene into objects. Then, it constructs view-aggregated semanticrepresentations by clustering semantic descriptors and reweighting them basedon multi-view semantics. Extensive experiments demonstrate that LaGaeffectively captures key information from view-dependent semantics, enabling amore comprehensive understanding of 3D scenes. Notably, under the samesettings, LaGa achieves a significant improvement of +18.7% mIoU over theprevious SOTA on the LERF-OVS dataset. Our code is available at:https://github.com/SJTU-DeepVisionLab/LaGa.</description>
      <author>example@mail.com (Jiazhong Cen, Xudong Zhou, Jiemin Fang, Changsong Wen, Lingxi Xie, Xiaopeng Zhang, Wei Shen, Qi Tian)</author>
      <guid isPermaLink="false">2505.24746v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>A Cross Branch Fusion-Based Contrastive Learning Framework for Point Cloud Self-supervised Learning</title>
      <link>http://arxiv.org/abs/2505.24641v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PoCCA的点云对比交叉分支注意力框架，用于无监督学习点云数据，旨在学习丰富的3D点云表示。&lt;h4&gt;背景&lt;/h4&gt;对比学习是自监督学习中的关键方法，主要采用多分支策略来比较不同分支获得的潜在表示并训练编码器。&lt;h4&gt;目的&lt;/h4&gt;在没有额外训练数据的情况下，进行点云无监督学习，学习丰富的3D点云表示。&lt;h4&gt;方法&lt;/h4&gt;PoCCA引入子分支，允许在不同分支之间在损失端之前进行信息交换，通过多种方式对输入数据进行增强，以供不同分支使用。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在使用无额外训练数据的情况下，PoCCA自监督模型学习的表示在用于点云下游任务时达到最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;PoCCA框架在点云无监督学习中表现出色，能够有效学习高质量的3D点云表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning is an essential method in self-supervised learning. Itprimarily employs a multi-branch strategy to compare latent representationsobtained from different branches and train the encoder. In the case ofmulti-modal input, diverse modalities of the same object are fed into distinctbranches. When using single-modal data, the same input undergoes variousaugmentations before being fed into different branches. However, all existingcontrastive learning frameworks have so far only performed contrastiveoperations on the learned features at the final loss end, with no informationexchange between different branches prior to this stage. In this paper, forpoint cloud unsupervised learning without the use of extra training data, wepropose a Contrastive Cross-branch Attention-based framework for Point clouddata (termed PoCCA), to learn rich 3D point cloud representations. Byintroducing sub-branches, PoCCA allows information exchange between differentbranches before the loss end. Experimental results demonstrate that in the caseof using no extra training data, the representations learned with ourself-supervised model achieve state-of-the-art performances when used fordownstream tasks on point clouds.</description>
      <author>example@mail.com (Chengzhi Wu, Qianliang Huang, Kun Jin, Julius Pfrommer, Jürgen Beyerer)</author>
      <guid isPermaLink="false">2505.24641v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>GenSpace: Benchmarking Spatially-Aware Image Generation</title>
      <link>http://arxiv.org/abs/2505.24870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了GenSpace，一个用于评估图像生成模型空间感知能力的基准和评估流程，并指出当前AI模型在空间感知方面存在局限性。&lt;h4&gt;背景&lt;/h4&gt;人类能够直观地在三维空间中构图和排列场景进行摄影，但AI图像生成器是否具有类似的空间感知能力？&lt;h4&gt;目的&lt;/h4&gt;评估当前图像生成模型的空间感知能力，并提出改进方向。&lt;h4&gt;方法&lt;/h4&gt;提出了一种专门的评估流程和指标，使用多个视觉基础模型重建3D场景几何，以提供更准确和符合人类的空间感知度。&lt;h4&gt;主要发现&lt;/h4&gt;AI模型在创建视觉吸引人的图像和遵循一般指令方面表现良好，但在处理具体的3D细节，如物体放置、关系和尺寸测量方面存在困难。&lt;h4&gt;结论&lt;/h4&gt;当前最先进的图像生成模型在空间感知方面存在三个核心局限性：物体透视理解、自我中心-中心化转换和度量测量遵守，为提高图像生成中的空间智能指明了可能的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类可以直观地在三维空间中构图和排列场景进行摄影。然而，高级AI图像生成器在从文本或图像提示创建图像时，是否能够具有类似的三维空间感知能力？我们提出了GenSpace，一个新颖的基准和评估流程，全面评估当前图像生成模型的空间感知能力。此外，使用通用视觉-语言模型（VLMs）的标准评估往往无法捕捉详细的时空错误。为了应对这一挑战，我们提出了一种专门的评估流程和指标，该流程使用多个视觉基础模型重建3D场景几何，并提供了一个更准确且符合人类的空间感知度指标。我们的发现表明，尽管AI模型能够创建视觉吸引人的图像并遵循一般指令，但在处理具体的3D细节，如物体放置、关系和尺寸测量方面存在困难。我们总结了当前最先进图像生成模型在空间感知方面的三个核心局限性：物体透视理解、自我中心-中心化转换和度量测量遵守，突出了提高图像生成中空间智能的可能方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans can intuitively compose and arrange scenes in the 3D space forphotography. However, can advanced AI image generators plan scenes with similar3D spatial awareness when creating images from text or image prompts? Wepresent GenSpace, a novel benchmark and evaluation pipeline to comprehensivelyassess the spatial awareness of current image generation models. Furthermore,standard evaluations using general Vision-Language Models (VLMs) frequentlyfail to capture the detailed spatial errors. To handle this challenge, wepropose a specialized evaluation pipeline and metric, which reconstructs 3Dscene geometry using multiple visual foundation models and provides a moreaccurate and human-aligned metric of spatial faithfulness. Our findings showthat while AI models create visually appealing images and can follow generalinstructions, they struggle with specific 3D details like object placement,relationships, and measurements. We summarize three core limitations in thespatial perception of current state-of-the-art image generation models: 1)Object Perspective Understanding, 2) Egocentric-Allocentric Transformation and3) Metric Measurement Adherence, highlighting possible directions for improvingspatial intelligence in image generation.</description>
      <author>example@mail.com (Zehan Wang, Jiayang Xu, Ziang Zhang, Tianyu Pan, Chao Du, Hengshuang Zhao, Zhou Zhao)</author>
      <guid isPermaLink="false">2505.24870v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning Weather Models for Subregional Ocean Forecasting: A Case Study on the Canary Current Upwelling System</title>
      <link>http://arxiv.org/abs/2505.24429v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要讨论了海洋预测对社会各领域的影响，以及基于深度学习的预测方法在提高海洋预测准确性方面的潜力。&lt;h4&gt;背景&lt;/h4&gt;传统海洋预测方法基于全球环流模型，计算成本高且速度慢，限制了其提供快速预测的能力。深度学习模型提供了更快、更准确的预测，但它们通常使用数值模拟的全球数据训练，可能不反映现实。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在将最初为全球天气预报开发的图神经网络应用于改进子区域海洋预测，特别是针对加那利海流上升系统。&lt;h4&gt;方法&lt;/h4&gt;该模型使用卫星数据进行训练，并与最先进的物理海洋模型进行比较，以评估其在捕捉海洋动力学方面的性能。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明，尽管在上升区域存在一些挑战，但深度学习模型在精度方面超越了传统方法。与ConvLSTM和GLORYS再分析相比，该模型在减少RMSE误差方面表现出优越性能，特别是在具有复杂海洋动力学如加比尔角、博雅多尔角和白崖的区域。该模型在这些关键位置实现了高达26.5%的相对改进和高达76%的误差减少。&lt;h4&gt;结论&lt;/h4&gt;这些发现表明，将气象数据驱动模型应用于改进子区域中期海洋预测是可行的。&lt;h4&gt;翻译&lt;/h4&gt;摘要：海洋预报通过支持环境保护和经济活动影响社会的各个领域。基于全球环流模型的传统预报方法计算成本高且速度慢，限制了其提供快速预报的能力。深度学习技术的最新进展提供了更快、更准确的预测，尽管这些数据驱动模型通常使用数值模拟的全球数据进行训练，这可能不反映现实。这种模型的出现为在子区域域内提高海洋预报提供了巨大潜力。然而，它们预测细尺度的海洋过程，如中尺度结构的能力仍 largely unknown（很大程度上未知）。本研究旨在将最初为全球天气预报开发的图神经网络应用于改进子区域海洋预报，特别是针对加那利海流上升系统。该模型使用卫星数据进行训练，并与最先进的物理海洋模型进行比较，以评估其在捕捉海洋动力学方面的性能。我们的结果表明，尽管在上升区域存在一些挑战，但深度学习模型在精度方面超越了传统方法。它在与ConvLSTM和GLORYS再分析相比时，在减少RMSE误差方面表现出优越性能，特别是在具有复杂海洋动力学如加比尔角、博雅多尔角和白崖的区域。该模型在这些关键位置实现了高达26.5%的相对改进和高达76%的误差减少，这突出了其增强的能力来捕捉空间变异性并提高复杂地区的预测精度。这些发现表明，将气象数据驱动模型应用于改进子区域中期海洋预报是可行的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Oceanographic forecasting impacts various sectors of society by supportingenvironmental conservation and economic activities. Based on global circulationmodels, traditional forecasting methods are computationally expensive and slow,limiting their ability to provide rapid forecasts. Recent advances in deeplearning offer faster and more accurate predictions, although these data-drivenmodels are often trained with global data from numerical simulations, which maynot reflect reality. The emergence of such models presents great potential forimproving ocean prediction at a subregional domain. However, their ability topredict fine-scale ocean processes, like mesoscale structures, remains largelyunknown. This work aims to adapt a graph neural network initially developed forglobal weather forecasting to improve subregional ocean prediction,specifically focusing on the Canary Current upwelling system. The model istrained with satellite data and compared to state-of-the-art physical oceanmodels to assess its performance in capturing ocean dynamics. Our results showthat the deep learning model surpasses traditional methods in precision despitesome challenges in upwelling areas. It demonstrated superior performance inreducing RMSE errors compared to ConvLSTM and the GLORYS reanalysis,particularly in regions with complex oceanic dynamics such as Cape Ghir, CapeBojador, and Cape Blanc. The model achieved improvements of up to 26.5%relative to ConvLSTM and error reductions of up to 76% in 5-day forecastscompared to the GLORYS reanalysis at these critical locations, highlighting itsenhanced capability to capture spatial variability and improve predictiveaccuracy in complex areas. These findings suggest the viability of adaptingmeteorological data-driven models for improving subregional medium-term oceanforecasting.</description>
      <author>example@mail.com (Giovanny C-Londoño, Javier Sánchez, Ángel Rodríguez-Santana)</author>
      <guid isPermaLink="false">2505.24429v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Collision Probability Estimation for Optimization-based Vehicular Motion Planning</title>
      <link>http://arxiv.org/abs/2505.21161v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于优化方法的运动规划算法，用于自动驾驶中的碰撞概率（POC）估计，以解决测量和估计不确定性带来的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的POC估计技术通常使用基于采样的方法，但这些方法计算效率低，且结果具有非确定性。&lt;h4&gt;目的&lt;/h4&gt;提出一种计算高效且确定性的POC估计方法，以保证运动规划的可行性。&lt;h4&gt;方法&lt;/h4&gt;通过多圆形形状近似来过度估计车辆形状，将预测车辆的位置和航向建模为随机变量，并提出了一种计算POC估计的算法，用于处理位置和航向的Gaussian不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;该算法能提供POC的过度估计，保证安全，并在路径跟随的随机模型预测控制器（SMPC）中应用，生成可重复的轨迹，同时在测试案例中保持控制器的可行性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够处理不同水平的不确定性，为自动驾驶中的运动规划提供了一种有效的POC估计方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Tolksdorf/Collision-Probaility-Estimation&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many motion planning algorithms for automated driving require estimating theprobability of collision (POC) to account for uncertainties in the measurementand estimation of the motion of road users. Common POC estimation techniquesoften utilize sampling-based methods that suffer from computationalinefficiency and a non-deterministic estimation, i.e., each estimation resultfor the same inputs is slightly different. In contrast, optimization-basedmotion planning algorithms require computationally efficient POC estimation,ideally using deterministic estimation, such that typical optimizationalgorithms for motion planning retain feasibility. Estimating the POCanalytically, however, is challenging because it depends on understanding thecollision conditions (e.g., vehicle's shape) and characterizing the uncertaintyin motion prediction. In this paper, we propose an approach in which weestimate the POC between two vehicles by over-approximating their shapes by amulti-circular shape approximation. The position and heading of the predictedvehicle are modelled as random variables, contrasting with the literature,where the heading angle is often neglected. We guarantee that the provided POCis an over-approximation, which is essential in providing safety guarantees,and present a computationally efficient algorithm for computing the POCestimate for Gaussian uncertainty in the position and heading. This algorithmis then used in a path-following stochastic model predictive controller (SMPC)for motion planning. With the proposed algorithm, the SMPC generatesreproducible trajectories while the controller retains its feasibility in thepresented test cases and demonstrates the ability to handle varying levels ofuncertainty.</description>
      <author>example@mail.com (Leon Tolksdorf, Arturo Tejada, Christian Birkner, Nathan van de Wouw)</author>
      <guid isPermaLink="false">2505.21161v2</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors</title>
      <link>http://arxiv.org/abs/2505.24625v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新的视频-3D几何大型语言模型（VG LLM），通过视频数据直接理解和推理3D空间，无需额外的3D输入，并在3D场景理解和空间推理任务中取得了显著成果。&lt;h4&gt;背景&lt;/h4&gt;先前研究通过将3D场景解释为视频来应用多模态大型语言模型（MLLMs），这些方法通常依赖于全面的三维数据输入，如点云或重建的鸟瞰图。&lt;h4&gt;目的&lt;/h4&gt;提升MLLMs从视频数据中直接理解和推理3D空间的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一个名为VG LLM的方法，它使用3D视觉几何编码器从视频序列中提取3D先验信息，并将这些信息与视觉标记结合后输入到MLLM中。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在各种与3D场景理解和空间推理相关的任务中实现了显著的改进，其4B模型在没有依赖显式3D数据输入的情况下，与现有最先进的方法相比取得了具有竞争力的结果，甚至在VSI-Bench评估中超过了Gemini-1.5-Pro。&lt;h4&gt;结论&lt;/h4&gt;VG LLM在3D场景理解和空间推理任务中表现出色，为直接从视频数据中学习3D信息提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Previous research has investigated the application of Multimodal LargeLanguage Models (MLLMs) in understanding 3D scenes by interpreting them asvideos. These approaches generally depend on comprehensive 3D data inputs, suchas point clouds or reconstructed Bird's-Eye View (BEV) maps. In our research,we advance this field by enhancing the capability of MLLMs to understand andreason in 3D spaces directly from video data, without the need for additional3D input. We propose a novel and efficient method, the Video-3D Geometry LargeLanguage Model (VG LLM). Our approach employs a 3D visual geometry encoder thatextracts 3D prior information from video sequences. This information isintegrated with visual tokens and fed into the MLLM. Extensive experiments haveshown that our method has achieved substantial improvements in various tasksrelated to 3D scene understanding and spatial reasoning, all directly learnedfrom video sources. Impressively, our 4B model, which does not rely on explicit3D data inputs, achieves competitive results compared to existingstate-of-the-art methods, and even surpasses the Gemini-1.5-Pro in theVSI-Bench evaluations.</description>
      <author>example@mail.com (Duo Zheng, Shijia Huang, Yanyang Li, Liwei Wang)</author>
      <guid isPermaLink="false">2505.24625v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Time Blindness: Why Video-Language Models Can't See What Humans Can?</title>
      <link>http://arxiv.org/abs/2505.24867v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page at https://timeblindness.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SpookyBench基准测试，旨在研究视觉语言模型在视频理解中处理空间信息时的局限性。&lt;h4&gt;背景&lt;/h4&gt;尽管视觉语言模型在理解视频中的时空关系方面取得了显著进展，但当空间信息被遮挡时，这些模型难以捕捉纯粹的时间模式。&lt;h4&gt;目的&lt;/h4&gt;SpookyBench旨在通过仅使用噪声帧的时间序列来编码信息，模拟从生物信号到隐蔽通信的自然现象，以评估视觉语言模型在处理时间模式时的能力。&lt;h4&gt;方法&lt;/h4&gt;SpookyBench提供了一个基准测试环境，其中人类可以以超过98%的准确率识别序列中的形状、文本和模式，而最先进的视觉语言模型却无法做到。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，视觉语言模型过度依赖帧级空间特征，无法从时间线索中提取意义。此外，在低空间信噪比的数据集上训练时，模型的时间理解能力下降速度比人类感知快，特别是在需要精细时间推理的任务中。&lt;h4&gt;结论&lt;/h4&gt;为了克服这一局限性，需要开发新的架构或训练范式，以解耦空间依赖和时间处理。SpookyBench的发布旨在推动时间模式识别研究，并弥合人类与机器视频理解之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近期在视觉语言模型（VLMs）方面取得的进展，使视频中的时空关系理解取得了显著进展。然而，当空间信息被遮挡时，这些模型在捕捉纯粹的时间模式上存在困难。我们介绍了SpookyBench，一个信息仅通过噪声帧的时间序列编码的基准测试，反映了从生物信号到隐蔽通信的自然现象。有趣的是，尽管人类可以以超过98%的准确率在这些序列中识别形状、文本和模式，但最先进的VLMs的准确率为0%。这种性能差距突显了一个关键限制：过度依赖帧级空间特征和无法从时间线索中提取意义。此外，在低空间信噪比的数据集上训练时，模型的时间理解能力下降速度比人类感知快，特别是在需要精细时间推理的任务中。克服这一限制需要新的架构或训练范式，以解耦空间依赖和时间处理。我们的系统分析表明，这个问题在模型规模和架构上普遍存在。我们发布了SpookyBench，以推动时间模式识别研究，并弥合人类与机器视频理解之间的差距。数据集和代码已发布在我们的项目网站上：https://timeblindness.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in vision-language models (VLMs) have made impressive stridesin understanding spatio-temporal relationships in videos. However, when spatialinformation is obscured, these models struggle to capture purely temporalpatterns. We introduce $\textbf{SpookyBench}$, a benchmark where information isencoded solely in temporal sequences of noise-like frames, mirroring naturalphenomena from biological signaling to covert communication. Interestingly,while humans can recognize shapes, text, and patterns in these sequences withover 98% accuracy, state-of-the-art VLMs achieve 0% accuracy. This performancegap highlights a critical limitation: an over-reliance on frame-level spatialfeatures and an inability to extract meaning from temporal cues. Furthermore,when trained in data sets with low spatial signal-to-noise ratios (SNR),temporal understanding of models degrades more rapidly than human perception,especially in tasks requiring fine-grained temporal reasoning. Overcoming thislimitation will require novel architectures or training paradigms that decouplespatial dependencies from temporal processing. Our systematic analysis showsthat this issue persists across model scales and architectures. We releaseSpookyBench to catalyze research in temporal pattern recognition and bridge thegap between human and machine video understanding. Dataset and code has beenmade available on our project website: https://timeblindness.github.io/.</description>
      <author>example@mail.com (Ujjwal Upadhyay, Mukul Ranjan, Zhiqiang Shen, Mohamed Elhoseiny)</author>
      <guid isPermaLink="false">2505.24867v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Graph Masked Contrastive Learning for Robust Recommendation</title>
      <link>http://arxiv.org/abs/2505.24172v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Masked Contrastive Learning（MCL）的新型模型，用于增强推荐任务中对噪声的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;Heterogeneous graph neural networks（HGNNs）在利用辅助信息进行推荐任务中表现出优越性，但使用元路径构建的图通常过于密集，含有大量噪声边，且HGNNs的传播机制会将图中的噪声传播到远距离的邻居节点，影响多个节点嵌入。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述限制，提出MCL模型以提高推荐对噪声的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;MCL采用随机掩码策略通过元路径增强图，减少节点对特定邻居的敏感性，增强嵌入鲁棒性。此外，MCL在Heterogeneous Information Network（HIN）上采用对比交叉视图，从单跳邻居和元路径邻居两个角度进行对比学习。这种方法同时获取了捕获局部和高层结构的嵌入，以用于推荐。&lt;h4&gt;主要发现&lt;/h4&gt;在三个真实世界数据集上的实证评估表明，该方法优于现有的推荐方法。&lt;h4&gt;结论&lt;/h4&gt;MCL模型通过增强推荐对噪声的鲁棒性，提高了推荐任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterogeneous graph neural networks (HGNNs) have demonstrated theirsuperiority in exploiting auxiliary information for recommendation tasks.However, graphs constructed using meta-paths in HGNNs are usually too dense andcontain a large number of noise edges. The propagation mechanism of HGNNspropagates even small amounts of noise in a graph to distant neighboring nodes,thereby affecting numerous node embeddings. To address this limitation, weintroduce a novel model, named Masked Contrastive Learning (MCL), to enhancerecommendation robustness to noise. MCL employs a random masking strategy toaugment the graph via meta-paths, reducing node sensitivity to specificneighbors and bolstering embedding robustness. Furthermore, MCL employscontrastive cross-view on a Heterogeneous Information Network (HIN) from twoperspectives: one-hop neighbors and meta-path neighbors. This approach acquiresembeddings capturing both local and high-order structures simultaneously forrecommendation. Empirical evaluations on three real-world datasets confirm thesuperiority of our approach over existing recommendation methods.</description>
      <author>example@mail.com (Lei Sang, Yu Wang, Yiwen Zhang)</author>
      <guid isPermaLink="false">2505.24172v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>GARLIC: GAussian Representation LearnIng for spaCe partitioning</title>
      <link>http://arxiv.org/abs/2505.24608v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了GARLIC，一种基于高斯表示学习的索引结构，用于高效地学习高维向量空间。&lt;h4&gt;背景&lt;/h4&gt;GARLIC受到3D渲染中高斯分裂技术的启发，用于高维搜索和分类。&lt;h4&gt;目的&lt;/h4&gt;优化高斯参数，平衡覆盖、分配置信度、结构和语义一致性。&lt;h4&gt;方法&lt;/h4&gt;通过分割和克隆操作逐步细化表示，处理数百维度的数据，以应对不同的数据密度。&lt;h4&gt;主要发现&lt;/h4&gt;GARLIC具有快速构建时间（例如，SIFT1M的构建时间约为5分钟），在低候选者环境中达到约50%的Recall10@10。&lt;h4&gt;结论&lt;/h4&gt;在标准基准测试中，GARLIC在k-NN检索中表现一致，在Fashion-MNIST上使用约一半的探针就实现了与Faiss-IVF相当的高Recall10@10，在分类任务中比其他多数投票方法提高了约15%的准确性。此外，GARLIC具有较强的泛化能力，即使使用下采样训练数据也能保持高精度，使用1%的训练数据就能达到约45%的Recall@1，因此对于需要速度和准确性的应用非常强大。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了GARLIC（高斯表示学习用于空间划分），一种基于N维高斯的新颖索引结构，用于高效地学习高维向量空间。我们的方法受到3D渲染中高斯分裂技术的启发，我们将这些技术适应于高维搜索和分类。我们使用信息论目标优化高斯参数，以平衡覆盖、分配置信度、结构和语义一致性。一个关键贡献是通过分割和克隆操作逐步细化表示，处理数百维度的数据，从而处理不同的数据密度。GARLIC提供了传统空间划分方法的快速构建时间（例如，SIFT1M的构建时间约为5分钟），同时在低候选者环境中达到约50%的Recall10@10。在标准基准测试中，我们的方法在k-NN检索中表现一致，在Fashion-MNIST上使用约一半的探针就实现了与Faiss-IVF相当的高Recall10@10，在分类任务中比其他多数投票方法提高了约15%的准确性。此外，我们展示了强大的泛化能力，即使使用下采样训练数据也能保持高精度：使用仅1%的训练数据就能达到约45%的Recall@1，因此GARLIC对于需要速度和准确性的应用非常强大。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce GARLIC (GAussian Representation LearnIng for spaCepartitioning), a novel indexing structure based on \(N\)-dimensional Gaussiansfor efficiently learning high-dimensional vector spaces. Our approach isinspired from Gaussian splatting techniques, typically used in 3D rendering,which we adapt for high-dimensional search and classification. We optimizeGaussian parameters using information-theoretic objectives that balancecoverage, assignment confidence, and structural and semantic consistency. A keycontribution is to progressively refine the representation through split andclone operations, handling hundreds of dimensions, thus handling varying datadensities. GARLIC offers the fast building times of traditional spacepartitioning methods (e.g., under \(\sim5\) min build time for SIFT1M) whileachieving \(\sim50\%\) Recall10@10 in low-candidate regimes. Experimentalresults on standard benchmarks demonstrate our method's consistency in (a)\(k\)-NN retrieval, outperforming methods, such as Faiss-IVF, in fast-recall byusing about half their probes for the same Recall10@10 in Fashion-MNIST, and(b) in classification tasks, beating by \(\sim15\%\) accuracy other majorityvoting methods. Further, we show strong generalization capabilities,maintaining high accuracy even with downsampled training data: using just\(1\%\) of the training data returns \(\sim 45\%\) Recall@1, thus making GARLICquite powerful for applications requiring both speed and accuracy.</description>
      <author>example@mail.com (Panagiotis Rigas, Panagiotis Drivas, Charalambos Tzamos, Ioannis Chamodrakas, George Ioannakis, Leonidas J. Guibas, Ioannis Z. Emiris)</author>
      <guid isPermaLink="false">2505.24608v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>ConversAR: Exploring Embodied LLM-Powered Group Conversations in Augmented Reality for Second Language Learners</title>
      <link>http://arxiv.org/abs/2505.24000v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in Proceedings of the Extended Abstracts of the CHI  Conference on Human Factors in Computing Systems&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ConversAR的增强现实应用，它通过两个具有视觉场景理解和实时字幕的实体化语言模型代理，帮助第二语言学习者练习情境化的群体对话。&lt;h4&gt;背景&lt;/h4&gt;群体对话对于第二语言学习者来说很有价值，因为它提供了练习听力、口语、复杂轮流技巧和体验目标语言中的群体社会动态的机会。然而，大多数现有的基于增强现实（AR）的对话学习工具都侧重于二元交互而不是群体对话。&lt;h4&gt;目的&lt;/h4&gt;研究目的是探索使用AR技术进行群体语言实践的可能性，并开发一个工具来帮助第二语言学习者练习群体对话。&lt;h4&gt;方法&lt;/h4&gt;研究人员开发了一个名为ConversAR的AR应用，该应用由gpt-4o驱动，并包含两个具有视觉场景理解和实时字幕的实体化语言模型代理。&lt;h4&gt;主要发现&lt;/h4&gt;在一个包含10名参与者的系统评估中，用户报告说，与与其他学习者面对面练习的方法相比，使用ConversAR减少了说话焦虑并增加了学习者的自主性。&lt;h4&gt;结论&lt;/h4&gt;ConversAR作为一种AR应用，能够帮助第二语言学习者减少说话焦虑，并提高学习者的自主性，为群体语言实践提供了一种新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：群体对话对于第二语言学习者来说很有价值，因为它们提供了练习听力、口语、复杂轮流技巧和体验目标语言中的群体社会动态的机会。然而，大多数现有的基于增强现实（AR）的对话学习工具都侧重于二元交互而不是群体对话。尽管研究表明，AR可以帮助减少说话焦虑，并在二元场景中创建一个练习说话技能的舒适空间，特别是与基于大型语言模型（LLM）的对话代理一起，但这些技术在群体语言实践方面的潜力仍未得到充分探索。我们介绍了一种名为ConversAR的由gpt-4o驱动的AR应用，它使第二语言学习者能够练习情境化的群体对话。我们的系统具有两个具有视觉场景理解和实时字幕的实体化LLM代理。在一个包含10名参与者的系统评估中，用户报告说，与与其他学习者面对面练习的方法相比，使用ConversAR减少了说话焦虑并增加了学习者的自主性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3706599.3720162&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Group conversations are valuable for second language (L2) learners as theyprovide opportunities to practice listening and speaking, exercise complexturn-taking skills, and experience group social dynamics in a target language.However, most existing Augmented Reality (AR)-based conversational learningtools focus on dyadic interactions rather than group dialogues. Althoughresearch has shown that AR can help reduce speaking anxiety and create acomfortable space for practicing speaking skills in dyadic scenarios,especially with Large Language Model (LLM)-based conversational agents, thepotential for group language practice using these technologies remains largelyunexplored. We introduce ConversAR, a gpt-4o powered AR application, thatenables L2 learners to practice contextualized group conversations. Our systemfeatures two embodied LLM agents with vision-based scene understanding and livecaptions. In a system evaluation with 10 participants, users reported reducedspeaking anxiety and increased learner autonomy compared to perceptions ofin-person practice methods with other learners.</description>
      <author>example@mail.com (Jad Bendarkawi, Ashley Ponce, Sean Mata, Aminah Aliu, Yuhan Liu, Lei Zhang, Amna Liaqat, Varun Nagaraj Rao, Andrés Monroy-Hernández)</author>
      <guid isPermaLink="false">2505.24000v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Text Encoders for Labor Market Analysis</title>
      <link>http://arxiv.org/abs/2505.24640v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ConTeXT-match的对比学习方法，用于技能分类的极端多标签分类任务，提高了技能提取的效率和性能，并引入了Skill-XL基准和新版的JobBERT V2模型，以提高大规模实时劳动力市场分析的效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;劳动力市场分析依赖从职位广告中提取信息，这些信息虽然有价值但未结构化，而现有技能提取方法依赖计算量大、速度慢的大语言模型。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的技能提取方法，并支持鲁棒的评估。&lt;h4&gt;方法&lt;/h4&gt;设计了一种新的对比学习方法ConTeXT-match，引入了新的基准Skill-XL，并改进了JobBERT V2模型。&lt;h4&gt;主要发现&lt;/h4&gt;ConTeXT-match显著提高了技能提取效率和性能，Skill-XL基准解决了标签空间冗余问题，JobBERT V2模型利用提取的技能生成高质量职位标题表示。&lt;h4&gt;结论&lt;/h4&gt;提出的模型在效率和准确性方面表现出色，适合用于大规模实时劳动力市场分析。&lt;h4&gt;翻译&lt;/h4&gt;摘要：劳动力市场分析依赖于从职位广告中提取见解，这些广告提供了关于职位名称和相应技能要求的宝贵但未结构化的信息。尽管现有的技能提取方法在性能上达到了高水平，但它们依赖于计算量大且速度慢的大语言模型。在本文中，我们提出了ConTeXT-match，一种新的带有标记级注意力的对比学习方法，非常适合极端的多标签分类任务——技能分类。ConTeXT-match显著提高了技能提取的效率和性能，使用轻量级的双编码器模型实现了最先进的结果。为了支持稳健的评估，我们引入了Skill-XL，一个具有详尽、句子级技能注释的新基准，它明确解决了大标签空间中的冗余问题。最后，我们展示了JobBERT V2，一个改进的职位标题规范化模型，它利用提取的技能来生成高质量的职位标题表示。实验表明，我们的模型在效率和准确性方面都很高，适合用于大规模实时劳动力市场分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Labor market analysis relies on extracting insights from job advertisements,which provide valuable yet unstructured information on job titles andcorresponding skill requirements. While state-of-the-art methods for skillextraction achieve strong performance, they depend on large language models(LLMs), which are computationally expensive and slow. In this paper, we propose\textbf{ConTeXT-match}, a novel contrastive learning approach with token-levelattention that is well-suited for the extreme multi-label classification taskof skill classification. \textbf{ConTeXT-match} significantly improves skillextraction efficiency and performance, achieving state-of-the-art results witha lightweight bi-encoder model. To support robust evaluation, we introduce\textbf{Skill-XL}, a new benchmark with exhaustive, sentence-level skillannotations that explicitly address the redundancy in the large label space.Finally, we present \textbf{JobBERT V2}, an improved job title normalizationmodel that leverages extracted skills to produce high-quality job titlerepresentations. Experiments demonstrate that our models are efficient,accurate, and scalable, making them ideal for large-scale, real-time labormarket analysis.</description>
      <author>example@mail.com (Jens-Joris Decorte, Jeroen Van Hautte, Chris Develder, Thomas Demeester)</author>
      <guid isPermaLink="false">2505.24640v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>TalkingHeadBench: A Multi-Modal Benchmark &amp; Analysis of Talking-Head DeepFake Detection</title>
      <link>http://arxiv.org/abs/2505.24866v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TalkingHeadBench，这是一个用于评估最先进深度伪造检测器性能的全面多模型多生成器基准和精选数据集。&lt;h4&gt;背景&lt;/h4&gt;深度伪造生成技术迅速发展，使得合成视频的真实性提升，对媒体、政治和金融等领域构成重大风险。然而，现有的深度伪造检测基准无法反映这一进展。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够评估最先进检测器在最新生成器上性能的基准和数据集，以促进更鲁棒和更通用的检测模型研究。&lt;h4&gt;方法&lt;/h4&gt;构建了包含由领先学术和商业模型合成的深度伪造的视频数据集，并设计了评估在身份和生成器特征分布变化下的泛化能力的协议。对包括CNN、视觉变换器和时序模型在内的多种检测方法进行了基准测试，并使用Grad-CAM可视化进行错误分析。&lt;h4&gt;主要发现&lt;/h4&gt;当前检测方法在鲁棒性和泛化能力方面存在不足，且存在常见的失败模式和检测偏差。&lt;h4&gt;结论&lt;/h4&gt;TalkingHeadBench旨在通过提供全面的数据集和协议，加速对快速发展的生成技术的研究，以开发更鲁棒和通用的检测模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由先进生成模型推动的头部说话人深度伪造生成技术的快速发展，将合成视频的真实性提升到了一个在媒体、政治和金融等领域带来重大风险的级别。然而，当前头部说话人深度伪造检测的基准无法反映这一进展，依赖于过时的生成器，并且对模型的鲁棒性和泛化能力提供的信息有限。我们介绍了TalkingHeadBench，这是一个全面的多模型多生成器基准和精选数据集，旨在评估最先进检测器在最新生成器上的性能。我们的数据集包括由领先学术和商业模型合成的深度伪造，并具有精心构建的协议来评估在身份和生成器特征分布变化下的泛化能力。我们对包括CNN、视觉变换器和时序模型在内的多种现有检测方法进行了基准测试，并分析了它们的鲁棒性和泛化能力。此外，我们通过Grad-CAM可视化提供了错误分析，以揭示常见的失败模式和检测偏差。TalkingHeadBench托管在https://huggingface.co/datasets/luchaoqi/TalkingHeadBench上，对所有数据拆分和协议提供开放访问。我们的基准旨在面对快速发展的生成技术，加速对更鲁棒和通用检测模型的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of talking-head deepfake generation fueled by advancedgenerative models has elevated the realism of synthetic videos to a level thatposes substantial risks in domains such as media, politics, and finance.However, current benchmarks for deepfake talking-head detection fail to reflectthis progress, relying on outdated generators and offering limited insight intomodel robustness and generalization. We introduce TalkingHeadBench, acomprehensive multi-model multi-generator benchmark and curated datasetdesigned to evaluate the performance of state-of-the-art detectors on the mostadvanced generators. Our dataset includes deepfakes synthesized by leadingacademic and commercial models and features carefully constructed protocols toassess generalization under distribution shifts in identity and generatorcharacteristics. We benchmark a diverse set of existing detection methods,including CNNs, vision transformers, and temporal models, and analyze theirrobustness and generalization capabilities. In addition, we provide erroranalysis using Grad-CAM visualizations to expose common failure modes anddetector biases. TalkingHeadBench is hosted onhttps://huggingface.co/datasets/luchaoqi/TalkingHeadBench with open access toall data splits and protocols. Our benchmark aims to accelerate researchtowards more robust and generalizable detection models in the face of rapidlyevolving generative techniques.</description>
      <author>example@mail.com (Xinqi Xiong, Prakrut Patel, Qingyuan Fan, Amisha Wadhwa, Sarathy Selvam, Xiao Guo, Luchao Qi, Xiaoming Liu, Roni Sengupta)</author>
      <guid isPermaLink="false">2505.24866v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>MiCRo: Mixture Modeling and Context-aware Routing for Personalized Preference Learning</title>
      <link>http://arxiv.org/abs/2505.24846v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了MiCRo，一个两阶段的框架，用于通过利用大规模二元偏好数据集来增强个性化偏好学习，以解决基于Bradley-Terry模型进行奖励建模的局限性。&lt;h4&gt;背景&lt;/h4&gt;在应用强化学习从人类反馈（RLHF）到对齐大型语言模型（LLMs）时，奖励建模是构建安全基础模型的关键步骤。然而，基于Bradley-Terry（BT）模型的奖励建模假设全局奖励函数，无法捕捉人类偏好的多样性和异质性。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种能够更好地捕捉人类偏好的个性化偏好学习方法，以支持个性化和对立的对齐。&lt;h4&gt;方法&lt;/h4&gt;MiCRo采用两阶段框架：第一阶段引入上下文感知混合建模方法来捕捉多样的人类偏好；第二阶段整合在线路由策略，根据特定上下文动态调整混合权重，以解决模糊性，实现高效和可扩展的偏好适应。&lt;h4&gt;主要发现&lt;/h4&gt;MiCRo能够有效捕捉多样的人类偏好，并在下游个性化方面显著改进。&lt;h4&gt;结论&lt;/h4&gt;MiCRo通过提高个性化偏好学习的能力，为LLMs的个性化和对立对齐提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reward modeling is a key step in building safe foundation models whenapplying reinforcement learning from human feedback (RLHF) to align LargeLanguage Models (LLMs). However, reward modeling based on the Bradley-Terry(BT) model assumes a global reward function, failing to capture the inherentlydiverse and heterogeneous human preferences. Hence, such oversimplificationlimits LLMs from supporting personalization and pluralistic alignment.Theoretically, we show that when human preferences follow a mixturedistribution of diverse subgroups, a single BT model has an irreducible error.While existing solutions, such as multi-objective learning with fine-grainedannotations, help address this issue, they are costly and constrained bypredefined attributes, failing to fully capture the richness of human values.In this work, we introduce MiCRo, a two-stage framework that enhancespersonalized preference learning by leveraging large-scale binary preferencedatasets without requiring explicit fine-grained annotations. In the firststage, MiCRo introduces context-aware mixture modeling approach to capturediverse human preferences. In the second stage, MiCRo integrates an onlinerouting strategy that dynamically adapts mixture weights based on specificcontext to resolve ambiguity, allowing for efficient and scalable preferenceadaptation with minimal additional supervision. Experiments on multiplepreference datasets demonstrate that MiCRo effectively captures diverse humanpreferences and significantly improves downstream personalization.</description>
      <author>example@mail.com (Jingyan Shen, Jiarui Yao, Rui Yang, Yifan Sun, Feng Luo, Rui Pan, Tong Zhang, Han Zhao)</author>
      <guid isPermaLink="false">2505.24846v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>NUC-Net: Non-uniform Cylindrical Partition Network for Efficient LiDAR Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2505.24634v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NUC-Net的非均匀圆柱分割网络，用于解决LiDAR语义分割中的挑战，包括减少计算成本、内存消耗和提高对点云不平衡分布的处理能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基于体素的方法在LiDAR语义分割中应用了均匀分割，但存在计算量大、内存消耗高和未能有效处理点云不平衡分布的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的非均匀圆柱分割网络，以降低计算成本、减少内存消耗并更好地处理点云的不平衡分布。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种名为API的方法，用于非均匀分割径向轴，并生成具有代表性的体素表示；2. 提出了一种非均匀多尺度聚合方法，以提高上下文信息。&lt;h4&gt;主要发现&lt;/h4&gt;NUC-Net在SemanticKITTI和nuScenes数据集上实现了最先进的性能，同时速度更快，训练时间更短，并且能够以4倍的速度训练、2倍的GPU内存减少和3倍的速度提升推理速度。&lt;h4&gt;结论&lt;/h4&gt;NUC-Net是一种通用的LiDAR语义分割组件，显著提高了均匀方法的准确性和效率，并通过理论分析解释了NUC-Net的有效性和点分布对性能的影响。&lt;h4&gt;翻译&lt;/h4&gt;LiDAR语义分割在自动驾驶中起着至关重要的作用。现有的基于体素的方法对3D LiDAR点云应用了均匀分割，以笛卡尔/圆柱坐标形成结构化表示。尽管这些方法表现出令人印象深刻的性能，但现有基于体素的方法在两个方面存在缺点：（1）需要足够大的输入体素分辨率，这带来了大量的计算成本和内存消耗；（2）未能很好地处理LiDAR点云的不平衡点分布。在本文中，我们提出了一种名为NUC-Net的非均匀圆柱分割网络来应对上述挑战。具体来说，我们提出了算术递增区间（API）方法来非均匀分割径向轴，并生成具有代表性的体素表示。此外，我们提出了一种非均匀多尺度聚合方法来提高上下文信息。我们的方法在SemanticKITTI和nuScenes数据集上实现了最先进的性能，具有更快的速度和更少的训练时间。我们的方法可以成为LiDAR语义分割的通用组件，通过4倍的速度训练、2倍的GPU内存减少和3倍的速度提升推理，显著提高了均匀方法的准确性和效率。我们进一步提供了理论分析，以理解NUC的有效性和点分布如何影响性能。代码可在https://github.com/alanWXZ/NUC-Net上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TCSVT.2025.3554182&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR semantic segmentation plays a vital role in autonomous driving.Existing voxel-based methods for LiDAR semantic segmentation apply uniformpartition to the 3D LiDAR point cloud to form a structured representation basedon cartesian/cylindrical coordinates. Although these methods show impressiveperformance, the drawback of existing voxel-based methods remains in twoaspects: (1) it requires a large enough input voxel resolution, which brings alarge amount of computation cost and memory consumption. (2) it does not wellhandle the unbalanced point distribution of LiDAR point cloud. In this paper,we propose a non-uniform cylindrical partition network named NUC-Net to tacklethe above challenges. Specifically, we propose the Arithmetic Progression ofInterval (API) method to non-uniformly partition the radial axis and generatethe voxel representation which is representative and efficient. Moreover, wepropose a non-uniform multi-scale aggregation method to improve contextualinformation. Our method achieves state-of-the-art performance on SemanticKITTIand nuScenes datasets with much faster speed and much less training time. Andour method can be a general component for LiDAR semantic segmentation, whichsignificantly improves both the accuracy and efficiency of the uniformcounterpart by $4 \times$ training faster and $2 \times$ GPU memory reductionand $3 \times$ inference speedup. We further provide theoretical analysistowards understanding why NUC is effective and how point distribution affectsperformance. Code is available at\href{https://github.com/alanWXZ/NUC-Net}{https://github.com/alanWXZ/NUC-Net}.</description>
      <author>example@mail.com (Xuzhi Wang, Wei Feng, Lingdong Kong, Liang Wan)</author>
      <guid isPermaLink="false">2505.24634v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Cross-Modal Knowledge Distillation: A Disentanglement Approach for RGBD Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2505.24361v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CroDiNo-KD的新型跨模态知识蒸馏框架，用于RGBD语义分割，以解决传感器故障或资源限制导致的训练和推理阶段数据模态不匹配问题。&lt;h4&gt;背景&lt;/h4&gt;多模态RGB和深度（RGBD）数据在机器人、自动驾驶和遥感等领域广泛应用。这些数据提供了3D空间上下文，增强了环境感知能力。&lt;h4&gt;目的&lt;/h4&gt;克服传统跨模态知识蒸馏（CMKD）框架在教师架构选择和蒸馏过程选择上的挑战，以提高其在现实场景中的应用。&lt;h4&gt;方法&lt;/h4&gt;CroDiNo-KD通过利用解耦表示、对比学习和解耦数据增强来同时学习单模态RGB和深度模型，旨在通过交互和协作结构化神经网络模型的内部流形。&lt;h4&gt;主要发现&lt;/h4&gt;在三个RGBD数据集上的评估表明，CroDiNo-KD的质量优于其他CMKD框架，并建议重新考虑传统的教师/学生范式，以从多模态数据中提取信息到单模态神经网络。&lt;h4&gt;结论&lt;/h4&gt;CroDiNo-KD是一种有效的跨模态知识蒸馏框架，可以提高RGBD语义分割的性能，并为从多模态数据中提取信息提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal RGB and Depth (RGBD) data are predominant in many domains such asrobotics, autonomous driving and remote sensing. The combination of thesemulti-modal data enhances environmental perception by providing 3D spatialcontext, which is absent in standard RGB images. Although RGBD multi-modal datacan be available to train computer vision models, accessing all sensormodalities during the inference stage may be infeasible due to sensor failuresor resource constraints, leading to a mismatch between data modalitiesavailable during training and inference. Traditional Cross-Modal KnowledgeDistillation (CMKD) frameworks, developed to address this task, are typicallybased on a teacher/student paradigm, where a multi-modal teacher distillsknowledge into a single-modality student model. However, these approaches facechallenges in teacher architecture choices and distillation process selection,thus limiting their adoption in real-world scenarios. To overcome these issues,we introduce CroDiNo-KD (Cross-Modal Disentanglement: a New Outlook onKnowledge Distillation), a novel cross-modal knowledge distillation frameworkfor RGBD semantic segmentation. Our approach simultaneously learnssingle-modality RGB and Depth models by exploiting disentanglementrepresentation, contrastive learning and decoupled data augmentation with theaim to structure the internal manifolds of neural network models throughinteraction and collaboration. We evaluated CroDiNo-KD on three RGBD datasetsacross diverse domains, considering recent CMKD frameworks as competitors. Ourfindings illustrate the quality of CroDiNo-KD, and they suggest reconsideringthe conventional teacher/student paradigm to distill information frommulti-modal data to single-modality neural networks.</description>
      <author>example@mail.com (Roger Ferrod, Cássio F. Dantas, Luigi Di Caro, Dino Ienco)</author>
      <guid isPermaLink="false">2505.24361v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Density Ratio Permutation Tests with connections to distributional shifts and conditional two-sample testing</title>
      <link>http://arxiv.org/abs/2505.24529v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  67 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的假设检验方法，用于进行密度比率的统计推断，并详细介绍了密度比率置换检验（DRPT）。&lt;h4&gt;背景&lt;/h4&gt;在独立数据中，从具有密度函数f和g的分布中抽取数据，并基于固定的密度比率r进行假设检验。&lt;h4&gt;目的&lt;/h4&gt;旨在通过有效的马尔可夫链蒙特卡罗算法，根据r确定的分布来抽取合并数据的置换，生成可交换的样本版本，以验证有限样本的有效性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于积分概率度量（IPM）的测试统计量，并证明了DRPT在轻微的假设下是一致的。在函数类是再生核希尔伯特空间的情况下，引入了Shifted-MMD的推广。对于连续数据，如果g-rf的归一化版本位于Sobolev球中，基于Shifted-MMD建立了DRPT的最小-最大最优性。对于未知位移因子r的情况，使用密度比率估计技术从部分数据中估计r，并推导了基于估计错误的I类错误界限。此外，还展示了如何将DRPT应用于条件双样本测试。&lt;h4&gt;主要发现&lt;/h4&gt;DRPT在模拟和真实世界数据集上的实验验证了理论发现，证明了其在评估建模假设（如重要性权重、协变量偏移等）方面的通用性。&lt;h4&gt;结论&lt;/h4&gt;DRPT是一种有效的工具，可以用于统计推断密度比率，并能够适应条件双样本测试和评估多种建模假设场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce novel hypothesis tests to allow for statistical inference fordensity ratios. More precisely, we introduce the Density Ratio Permutation Test(DRPT) for testing $H_0: g \propto r f$ based on independent data drawn fromdistributions with densities $f$ and $g$, where the hypothesised density ratio$r$ is a fixed function. The proposed test employs an efficient Markov ChainMonte Carlo algorithm to draw permutations of the combined dataset according toa distribution determined by $r$, producing exchangeable versions of the wholesample and thereby establishing finite-sample validity. Regarding the test'sbehaviour under the alternative hypothesis, we begin by demonstrating that ifthe test statistic is chosen as an Integral Probability Metric (IPM), the DRPTis consistent under mild assumptions on the function class that defines theIPM. We then narrow our focus to the setting where the function class is aReproducing Kernel Hilbert Space, and introduce a generalisation of theclassical Maximum Mean Discrepancy (MMD), which we term Shifted-MMD. Forcontinuous data, assuming that a normalised version of $g - rf$ lies in aSobolev ball, we establish the minimax optimality of the DRPT based on theShifted-MMD. We further extend our approach to scenarios with an unknown shiftfactor $r$, estimating it from part of the data using Density Ratio Estimationtechniques, and derive Type-I error bounds based on estimation error.Additionally, we demonstrate how the DRPT can be adapted for conditionaltwo-sample testing, establishing it as a versatile tool for assessing modellingassumptions on importance weights, covariate shifts and related scenarios,which frequently arise in contexts such as transfer learning and causalinference. Finally, we validate our theoretical findings through experiments onboth simulated and real-world datasets.</description>
      <author>example@mail.com (Alberto Bordino, Thomas B. Berrett)</author>
      <guid isPermaLink="false">2505.24529v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>MGS3: A Multi-Granularity Self-Supervised Code Search Framework</title>
      <link>http://arxiv.org/abs/2505.24274v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个多粒度代码搜索框架MGS$^{3}$，旨在提高代码重用性和开发效率，通过自然语言查询检索相关的代码片段。&lt;h4&gt;背景&lt;/h4&gt;尽管现有的自监督代码预训练方法在代码数据量庞大的代码库中取得了显著进展，但它们主要关注利用对比学习将自然语言与函数级别的代码片段对齐，忽视了函数级别代码片段中大量存在的细粒度代码片段，导致在所有粒度级别上性能不理想。&lt;h4&gt;目的&lt;/h4&gt;解决上述问题，提出MGS$^{3}$框架，旨在通过多粒度代码搜索增强软件重用性和开发者生产力。&lt;h4&gt;方法&lt;/h4&gt;首先构建了一个名为MGCodeSearchNet的多粒度代码搜索数据集，包含超过536K对自然语言和代码片段。然后，MGS$^{3}$包含一个层次多粒度表示模块（HMGR），利用句法结构关系进行分层表示，并将细粒度信息聚合到粗粒度表示中。在对比学习阶段，旨在为细粒度代码构建相同粒度的正样本，并引入函数内的负样本。&lt;h4&gt;主要发现&lt;/h4&gt;在代码搜索基准测试中，MGS$^{3}$框架在多个粒度的代码搜索任务中表现出优异的性能，并展示了其模型无关性和与现有预训练代码表示模型的兼容性。&lt;h4&gt;结论&lt;/h4&gt;MGS$^{3}$框架能够有效提高代码搜索性能，有助于提高软件开发效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：为了提高软件的可重用性和开发者的生产效率，代码搜索已经成为一个关键领域，目标是通过自然语言查询检索相关的功能代码片段。尽管在利用代码库中的大量代码数据进行自监督代码预训练方面取得了显著进展，但现有方法主要关注利用对比学习将自然语言与函数级别的代码片段对齐。这些研究忽视了函数级别代码片段中普遍存在的细粒度（如块级和语句级）代码片段的丰富性，导致在所有粒度级别上的性能都不理想。为了解决这个问题，我们首先构建了一个名为MGCodeSearchNet的多粒度代码搜索数据集，其中包含536K+对自然语言和代码片段。随后，我们引入了一种新颖的多粒度自监督对比学习代码搜索框架（MGS$^{3}$）。首先，MGS$^{3}$包含一个层次多粒度表示模块（HMGR），它利用句法结构关系进行分层表示，并将细粒度信息聚合到粗粒度表示中。在对比学习阶段，我们努力为细粒度代码构建相同粒度的正样本，并引入函数内的负样本。最后，我们在各种粒度的代码搜索基准测试中进行了广泛实验，证明了该框架在多个粒度的代码搜索任务中表现出色。这些实验还展示了其模型无关性和与现有预训练代码表示模型的兼容性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the pursuit of enhancing software reusability and developer productivity,code search has emerged as a key area, aimed at retrieving code snippetsrelevant to functionalities based on natural language queries. Despitesignificant progress in self-supervised code pre-training utilizing the vastamount of code data in repositories, existing methods have primarily focused onleveraging contrastive learning to align natural language with function-levelcode snippets. These studies have overlooked the abundance of fine-grained(such as block-level and statement-level) code snippets prevalent within thefunction-level code snippets, which results in suboptimal performance acrossall levels of granularity. To address this problem, we first construct amulti-granularity code search dataset called MGCodeSearchNet, which contains536K+ pairs of natural language and code snippets. Subsequently, we introduce anovel Multi-Granularity Self-Supervised contrastive learning code Searchframework (MGS$^{3}$}). First, MGS$^{3}$ features a HierarchicalMulti-Granularity Representation module (HMGR), which leverages syntacticstructural relationships for hierarchical representation and aggregatesfine-grained information into coarser-grained representations. Then, during thecontrastive learning phase, we endeavor to construct positive samples of thesame granularity for fine-grained code, and introduce in-function negativesamples for fine-grained code. Finally, we conduct extensive experiments oncode search benchmarks across various granularities, demonstrating that theframework exhibits outstanding performance in code search tasks of multiplegranularities. These experiments also showcase its model-agnostic nature andcompatibility with existing pre-trained code representation models.</description>
      <author>example@mail.com (Rui Li, Junfeng Kang, Qi Liu, Liyang He, Zheng Zhang, Yunhao Sha, Linbo Zhu, Zhenya Huang)</author>
      <guid isPermaLink="false">2505.24274v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Anomaly Detection and Improvement of Clusters using Enhanced K-Means Algorithm</title>
      <link>http://arxiv.org/abs/2505.24365v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE ICCCSP&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一的方法，用于数据集中的聚类细化和异常检测。&lt;h4&gt;背景&lt;/h4&gt;本文旨在解决数据集中聚类精炼和异常检测的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的算法，以降低N个聚类的内部方差，直至达到全局最小值，从而得到比标准k-means算法更紧密的聚类。&lt;h4&gt;方法&lt;/h4&gt;该算法通过迭代减少内部方差，并使用轮廓系数、Calinski-Harabasz指数和Davies-Bouldin指数等内在度量来评估方法。同时，通过识别导致显著方差增加的点，将其扩展到异常检测。&lt;h4&gt;主要发现&lt;/h4&gt;在合成数据和UCI乳腺癌和UCI葡萄酒质量数据集上，该方法在合成数据集上实现了18.7%的方差减少，在葡萄酒质量数据集上实现了88.1%的方差减少，并在葡萄酒质量数据集上提高了22.5%的准确性和20.8%的F1分数。&lt;h4&gt;结论&lt;/h4&gt;该算法在聚类细化和异常检测方面具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a unified approach to cluster refinement and anomaly detection in datasets. We propose a novel algorithm that iteratively reduces the intra-cluster variance of N clusters until a global minimum is reached, yielding tighter clusters than the standard k-means algorithm. We evaluate the method using intrinsic measures for unsupervised learning, including the silhouette coefficient, Calinski-Harabasz index, and Davies-Bouldin index, and extend it to anomaly detection by identifying points whose assignment causes a significant variance increase. External validation on synthetic data and the UCI Breast Cancer and UCI Wine Quality datasets employs the Jaccard similarity score, V-measure, and F1 score. Results show variance reductions of 18.7% and 88.1% on the synthetic and Wine Quality datasets, respectively, along with accuracy and F1 score improvements of 22.5% and 20.8% on the Wine Quality dataset.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a unified approach to cluster refinement and anomalydetection in datasets. We propose a novel algorithm that iteratively reducesthe intra-cluster variance of N clusters until a global minimum is reached,yielding tighter clusters than the standard k-means algorithm. We evaluate themethod using intrinsic measures for unsupervised learning, including thesilhouette coefficient, Calinski-Harabasz index, and Davies-Bouldin index, andextend it to anomaly detection by identifying points whose assignment causes asignificant variance increase. External validation on synthetic data and theUCI Breast Cancer and UCI Wine Quality datasets employs the Jaccard similarityscore, V-measure, and F1 score. Results show variance reductions of 18.7% and88.1% on the synthetic and Wine Quality datasets, respectively, along withaccuracy and F1 score improvements of 22.5% and 20.8% on the Wine Qualitydataset.</description>
      <author>example@mail.com (Vardhan Shorewala, Shivam Shorewala)</author>
      <guid isPermaLink="false">2505.24365v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>R3DM: Enabling Role Discovery and Diversity Through Dynamics Models in Multi-agent Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2505.24265v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, To appear in the International Conference of Machine  Learning (ICML 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为R3DM的新颖的基于角色的多智能体强化学习框架，用于提升复杂任务的合作学习。&lt;h4&gt;背景&lt;/h4&gt;多智能体强化学习在交通控制、自动驾驶和机器人等领域取得了显著进展，而基于角色的方法旨在通过角色自然出现来增强协调学习。&lt;h4&gt;目的&lt;/h4&gt;提出的方法旨在通过让智能体的角色塑造其未来行为，从而实现有效的协调。&lt;h4&gt;方法&lt;/h4&gt;R3DM通过最大化智能体角色、观察到的轨迹和预期未来行为之间的互信息来学习涌现的角色。它通过对比学习过去的轨迹来优化目标，首先推导出中间角色，这些角色通过学习到的动态模型塑造内在奖励，以促进不同角色未来行为的多样性。&lt;h4&gt;主要发现&lt;/h4&gt;在SMAC和SMACv2环境中进行的基准测试表明，R3DM优于最先进的MARL方法，提高了多智能体协调，使得胜率提高了多达20%。&lt;h4&gt;结论&lt;/h4&gt;R3DM框架通过考虑智能体角色的未来影响，在多智能体强化学习中实现了更好的协调和性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-agent reinforcement learning (MARL) has achieved significant progressin large-scale traffic control, autonomous vehicles, and robotics. Drawinginspiration from biological systems where roles naturally emerge to enablecoordination, role-based MARL methods have been proposed to enhance cooperationlearning for complex tasks. However, existing methods exclusively derive rolesfrom an agent's past experience during training, neglecting their influence onits future trajectories. This paper introduces a key insight: an agent's roleshould shape its future behavior to enable effective coordination. Hence, wepropose Role Discovery and Diversity through Dynamics Models (R3DM), a novelrole-based MARL framework that learns emergent roles by maximizing the mutualinformation between agents' roles, observed trajectories, and expected futurebehaviors. R3DM optimizes the proposed objective through contrastive learningon past trajectories to first derive intermediate roles that shape intrinsicrewards to promote diversity in future behaviors across different roles througha learned dynamics model. Benchmarking on SMAC and SMACv2 environmentsdemonstrates that R3DM outperforms state-of-the-art MARL approaches, improvingmulti-agent coordination to increase win rates by up to 20%.</description>
      <author>example@mail.com (Harsh Goel, Mohammad Omama, Behdad Chalaki, Vaishnav Tadiparthi, Ehsan Moradi Pari, Sandeep Chinchali)</author>
      <guid isPermaLink="false">2505.24265v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>GATE: General Arabic Text Embedding for Enhanced Semantic Textual Similarity with Matryoshka Representation Learning and Hybrid Loss Training</title>
      <link>http://arxiv.org/abs/2505.24581v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GATE模型，该模型在MTEB基准测试中在语义文本相似度任务上取得了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;由于缺乏高质量的数据集和预训练模型，阿拉伯语在语义文本相似度（STS）领域的的研究有限。&lt;h4&gt;目的&lt;/h4&gt;提出GATE模型，旨在提高阿拉伯语语义相似度在文本检索、聚类和语义关系理解等应用中的准确性。&lt;h4&gt;方法&lt;/h4&gt;GATE模型利用Matryoshka表示学习方法和混合损失训练方法，结合阿拉伯语三元组数据集进行自然语言推理。&lt;h4&gt;主要发现&lt;/h4&gt;GATE模型在语义文本相似度基准测试中优于包括OpenAI在内的更大模型，性能提高了20-25%，有效捕捉了阿拉伯语的独特语义细微差别。&lt;h4&gt;结论&lt;/h4&gt;GATE模型为阿拉伯语语义文本相似度研究提供了新的解决方案，并证明了其在性能上的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic textual similarity (STS) is a critical task in natural languageprocessing (NLP), enabling applications in retrieval, clustering, andunderstanding semantic relationships between texts. However, research in thisarea for the Arabic language remains limited due to the lack of high-qualitydatasets and pre-trained models. This scarcity of resources has restricted theaccurate evaluation and advance of semantic similarity in Arabic text. Thispaper introduces General Arabic Text Embedding (GATE) models that achievestate-of-the-art performance on the Semantic Textual Similarity task within theMTEB benchmark. GATE leverages Matryoshka Representation Learning and a hybridloss training approach with Arabic triplet datasets for Natural LanguageInference, which are essential for enhancing model performance in tasks thatdemand fine-grained semantic understanding. GATE outperforms larger models,including OpenAI, with a 20-25% performance improvement on STS benchmarks,effectively capturing the unique semantic nuances of Arabic.</description>
      <author>example@mail.com (Omer Nacar, Anis Koubaa, Serry Sibaee, Yasser Al-Habashi, Adel Ammar, Wadii Boulila)</author>
      <guid isPermaLink="false">2505.24581v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Biological Pathway Guided Gene Selection Through Collaborative Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2505.24155v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31st SIGKDD Conference on Knowledge Discovery and Data Mining (KDD  2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的两阶段框架，用于在基因选择中整合统计选择和生物通路知识，以解决传统方法在识别预测基因时忽视复杂生物通路和调控网络的问题。&lt;h4&gt;背景&lt;/h4&gt;基因选择在高维基因组数据中对于理解疾病机制和改善治疗效果至关重要。传统方法在识别预测基因时有效，但往往忽略复杂的生物通路和调控网络，导致不稳定的生物无关特征。&lt;h4&gt;目的&lt;/h4&gt;为了解决传统方法在基因选择中的局限性，提出一种新的方法来整合生物通路知识，同时保持统计的严谨性。&lt;h4&gt;方法&lt;/h4&gt;该方法采用多智能体强化学习（MARL）来整合统计选择与生物通路知识。首先，引入了一种通路引导的预过滤策略，结合多种统计方法和KEGG通路信息进行初始降维。接着，在细化选择阶段，将基因建模为MARL框架中的协作智能体，每个智能体优化预测能力和生物相关性。框架通过基于图神经网络的州状态表示、结合预测性能与基因中心性和通路覆盖度的奖励机制，以及使用共享记忆和集中式评判组件的协作学习策略来整合通路知识。&lt;h4&gt;主要发现&lt;/h4&gt;在多个基因表达数据集上的广泛实验表明，与传统的基因选择方法相比，该方法显著提高了预测准确性和生物可解释性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在基因选择中有效地整合了生物通路知识，提高了预测的准确性和生物可解释性，为理解疾病机制和改善治疗效果提供了新的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gene selection in high-dimensional genomic data is essential forunderstanding disease mechanisms and improving therapeutic outcomes.Traditional feature selection methods effectively identify predictive genes butoften ignore complex biological pathways and regulatory networks, leading tounstable and biologically irrelevant signatures. Prior approaches, such asLasso-based methods and statistical filtering, either focus solely onindividual gene-outcome associations or fail to capture pathway-levelinteractions, presenting a key challenge: how to integrate biological pathwayknowledge while maintaining statistical rigor in gene selection? To addressthis gap, we propose a novel two-stage framework that integrates statisticalselection with biological pathway knowledge using multi-agent reinforcementlearning (MARL). First, we introduce a pathway-guided pre-filtering strategythat leverages multiple statistical methods alongside KEGG pathway informationfor initial dimensionality reduction. Next, for refined selection, we modelgenes as collaborative agents in a MARL framework, where each agent optimizesboth predictive power and biological relevance. Our framework incorporatespathway knowledge through Graph Neural Network-based state representations, areward mechanism combining prediction performance with gene centrality andpathway coverage, and collaborative learning strategies using shared memory anda centralized critic component. Extensive experiments on multiple geneexpression datasets demonstrate that our approach significantly improves bothprediction accuracy and biological interpretability compared to traditionalmethods.</description>
      <author>example@mail.com (Ehtesamul Azim, Dongjie Wang, Tae Hyun Hwang, Yanjie Fu, Wei Zhang)</author>
      <guid isPermaLink="false">2505.24155v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning from CAD Software</title>
      <link>http://arxiv.org/abs/2505.24838v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为VideoCAD的工程UI交互学习新方法，旨在解决计算机辅助设计（CAD）中UI交互学习的问题。&lt;h4&gt;背景&lt;/h4&gt;CAD是一个耗时且复杂的流程，需要用户与复杂的3D界面进行精确的长期交互。现有的AI驱动UI代理在处理短期低复杂度任务方面表现良好，但未能满足专业工程工具的需求。&lt;h4&gt;目的&lt;/h4&gt;通过创建一个大规模合成数据集，提高工程UI交互学习的复杂度和时间跨度，从而更好地支持专业CAD工具的交互学习。&lt;h4&gt;方法&lt;/h4&gt;VideoCAD是一个包含超过41K个标注视频记录的大规模合成数据集，通过自动化框架从人工CAD设计中收集高保真UI动作数据生成。VideoCADFormer模型被提出，用于直接从视频中学习CAD交互，并在多个行为克隆基线中表现优异。&lt;h4&gt;主要发现&lt;/h4&gt;VideoCAD提供了比现有数据集高一个数量级的UI交互学习复杂性，其时间跨度是其他数据集的20倍。VideoCAD的两个重要下游应用是学习专业精密度3D CAD工具的UI交互和一个视觉问答（VQA）基准，用于评估多模态大型语言模型的空间推理和视频理解能力。&lt;h4&gt;结论&lt;/h4&gt;VideoCADFormer和从VideoCAD派生的VQA基准揭示了基于视频的UI理解中的关键挑战，包括精确动作定位、多模态和空间推理以及长期依赖关系的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computer-Aided Design (CAD) is a time-consuming and complex process,requiring precise, long-horizon user interactions with intricate 3D interfaces.While recent advances in AI-driven user interface (UI) agents show promise,most existing datasets and methods focus on short, low-complexity tasks inmobile or web applications, failing to capture the demands of professionalengineering tools. In this work, we introduce VideoCAD, the first attempt atengineering UI interaction learning for precision tasks. Specifically, VideoCADis a large-scale synthetic dataset consisting of over 41K annotated videorecordings of CAD operations, generated using an automated framework forcollecting high-fidelity UI action data from human-made CAD designs. Comparedto existing datasets, VideoCAD offers an order of magnitude higher complexityin UI interaction learning for real-world engineering tasks, having up to a 20xlonger time horizon than other datasets. We show two important downstreamapplications of VideoCAD: learning UI interactions from professional precision3D CAD tools and a visual question-answering (VQA) benchmark designed toevaluate multimodal large language models' (LLM) spatial reasoning and videounderstanding abilities. To learn the UI interactions, we proposeVideoCADFormer - a state-of-the-art model in learning CAD interactions directlyfrom video, which outperforms multiple behavior cloning baselines. BothVideoCADFormer and the VQA benchmark derived from VideoCAD reveal keychallenges in the current state of video-based UI understanding, including theneed for precise action grounding, multi-modal and spatial reasoning, andlong-horizon dependencies.</description>
      <author>example@mail.com (Brandon Man, Ghadi Nehme, Md Ferdous Alam, Faez Ahmed)</author>
      <guid isPermaLink="false">2505.24838v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Bi-Manual Joint Camera Calibration and Scene Representation</title>
      <link>http://arxiv.org/abs/2505.24819v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Bi-JCR的双手操作关节校准和表示框架，用于简化多机器人操作臂的相机校准过程，通过无需拍摄校准标记的RGB图像集，实现多机器人操作臂的相机外参、机器人间相对位姿以及共享工作空间的统一、尺度一致的3D表示的估计。&lt;h4&gt;背景&lt;/h4&gt;在机器人操作中，特别是双手操作，常常需要在多个机器人操作臂上安装多个相机，并在机器人产生运动或构建环境表示之前对这些相机进行校准。&lt;h4&gt;目的&lt;/h4&gt;目的是通过引入Bi-JCR框架，使多个安装有相机的机器人操作臂能够绕过拍摄校准标记的图像，从而简化相机校准过程。&lt;h4&gt;方法&lt;/h4&gt;Bi-JCR利用3D基础模型进行密集的无标记多视角对应，联合估计每个相机到其末端执行器的外参、操作臂之间的相对位姿以及共享工作空间的统一、尺度一致的3D表示。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够从同一捕获的RGB图像集中联合估计上述参数，并支持碰撞检测和语义分割，以促进下游的双手操作协调任务。&lt;h4&gt;结论&lt;/h4&gt;通过在多种桌面环境中进行实证评估，证明了Bi-JCR的鲁棒性和在多种下游任务中的适用性。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we introduce a framework called Bi-JCR for bimanual joint calibration and representation. This framework simplifies the calibration process for multiple robot manipulators equipped with cameras by avoiding the need to capture images of calibration markers. By leveraging 3D foundation models for dense, marker-free multi-view correspondence, Bi-JCR jointly estimates the extrinsic transformation from each camera to its end-effector, the inter-arm relative poses between manipulators, and a unified, scale-consistent 3D representation of the shared workspace, all from the same captured RGB image sets. This representation, jointly constructed from images captured by cameras on both manipulators, lives in a common coordinate frame and supports collision checking and semantic segmentation to facilitate downstream bimanual coordination tasks. The robustness of Bi-JCR is empirically evaluated on a variety of tabletop environments, and its applicability on a variety of downstream tasks is demonstrated.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robot manipulation, especially bimanual manipulation, often requires settingup multiple cameras on multiple robot manipulators. Before robot manipulatorscan generate motion or even build representations of their environments, thecameras rigidly mounted to the robot need to be calibrated. Camera calibrationis a cumbersome process involving collecting a set of images, with eachcapturing a pre-determined marker. In this work, we introduce the Bi-ManualJoint Calibration and Representation Framework (Bi-JCR). Bi-JCR enablesmultiple robot manipulators, each with cameras mounted, to circumvent takingimages of calibration markers. By leveraging 3D foundation models for dense,marker-free multi-view correspondence, Bi-JCR jointly estimates: (i) theextrinsic transformation from each camera to its end-effector, (ii) theinter-arm relative poses between manipulators, and (iii) a unified,scale-consistent 3D representation of the shared workspace, all from the samecaptured RGB image sets. The representation, jointly constructed from imagescaptured by cameras on both manipulators, lives in a common coordinate frameand supports collision checking and semantic segmentation to facilitatedownstream bimanual coordination tasks. We empirically evaluate the robustnessof Bi-JCR on a variety of tabletop environments, and demonstrate itsapplicability on a variety of downstream tasks.</description>
      <author>example@mail.com (Haozhan Tang, Tianyi Zhang, Matthew Johnson-Roberson, Weiming Zhi)</author>
      <guid isPermaLink="false">2505.24819v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Practical Bayes-Optimal Membership Inference Attacks</title>
      <link>http://arxiv.org/abs/2505.24089v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages plus 13 pages of appendices&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了针对独立同分布数据和图结构数据的成员推理攻击（MIAs），并基于Sablayrolles等人的贝叶斯决策理论框架，推导出针对图神经网络节点级别MIAs的贝叶斯最优推理规则。同时，介绍了BASE和G-BASE两种贝叶斯最优攻击的近似方法，并在性能上优于现有的基于分类器的节点级别MIA攻击。BASE方法在非图数据上的性能也与最先进的MIA方法相当，但计算成本更低。此外，证明了BASE和RMIA在特定超参数设置下是等价的，为RMIA攻击提供了贝叶斯最优的理论依据。&lt;h4&gt;背景&lt;/h4&gt;成员推理攻击（MIAs）是一种针对数据集成员身份的攻击方法，本文针对独立同分布数据和图结构数据进行了研究。&lt;h4&gt;目的&lt;/h4&gt;开发针对独立同分布数据和图结构数据的成员推理攻击，并推导出针对图神经网络的贝叶斯最优推理规则。&lt;h4&gt;方法&lt;/h4&gt;基于贝叶斯决策理论框架，推导贝叶斯最优推理规则，并提出了BASE和G-BASE两种贝叶斯最优攻击的近似方法。&lt;h4&gt;主要发现&lt;/h4&gt;BASE和G-BASE在性能上优于现有的基于分类器的节点级别MIA攻击，BASE在非图数据上的性能也与最先进的MIA方法相当，计算成本更低。BASE和RMIA在特定超参数设置下是等价的。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和理论为成员推理攻击提供了新的思路，并对图结构数据的攻击提出了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;We develop practical and theoretically grounded membership inference attacks (MIAs) against both independent and identically distributed (i.i.d.) data and graph-structured data. Building on the Bayesian decision-theoretic framework of Sablayrolles et al., we derive the Bayes-optimal membership inference rule for node-level MIAs against graph neural networks, addressing key open questions about optimal query strategies in the graph setting. We introduce BASE and G-BASE, computationally efficient approximations of the Bayes-optimal attack. G-BASE achieves superior performance compared to previously proposed classifier-based node-level MIA attacks. BASE, which is also applicable to non-graph data, matches or exceeds the performance of prior state-of-the-art MIAs, such as LiRA and RMIA, at a significantly lower computational cost. Finally, we show that BASE and RMIA are equivalent under a specific hyperparameter setting, providing a principled, Bayes-optimal justification for the RMIA attack.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We develop practical and theoretically grounded membership inference attacks(MIAs) against both independent and identically distributed (i.i.d.) data andgraph-structured data. Building on the Bayesian decision-theoretic framework ofSablayrolles et al., we derive the Bayes-optimal membership inference rule fornode-level MIAs against graph neural networks, addressing key open questionsabout optimal query strategies in the graph setting. We introduce BASE andG-BASE, computationally efficient approximations of the Bayes-optimal attack.G-BASE achieves superior performance compared to previously proposedclassifier-based node-level MIA attacks. BASE, which is also applicable tonon-graph data, matches or exceeds the performance of prior state-of-the-artMIAs, such as LiRA and RMIA, at a significantly lower computational cost.Finally, we show that BASE and RMIA are equivalent under a specifichyperparameter setting, providing a principled, Bayes-optimal justification forthe RMIA attack.</description>
      <author>example@mail.com (Marcus Lassila, Johan Östman, Khac-Hoang Ngo, Alexandre Graell i Amat)</author>
      <guid isPermaLink="false">2505.24089v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Learning reusable concepts across different egocentric video understanding tasks</title>
      <link>http://arxiv.org/abs/2505.24690v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Extended abstract derived from arXiv:2502.02487. Presented at the  Second Joint Egocentric Vision (EgoVis) Workshop (CVPR 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Hier-EgoPack，一个能够创建一系列任务视角的统一框架，这些视角可以在下游任务中迁移，并作为额外洞察的潜在来源，就像机器人可以携带并使用的一套技能。&lt;h4&gt;背景&lt;/h4&gt;人类对视频流中描绘的人类活动的理解是多方面的：在很短的时间内，我们可以把握正在发生的事情，识别场景中对象的相关性和相互作用，并预测接下来将要发生的事情。&lt;h4&gt;目的&lt;/h4&gt;赋予自主系统这样的整体感知能力，学习如何关联不同任务的概念和抽象知识，以及在学习新技能时利用任务协同是至关重要的。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种新的框架，称为Hier-EgoPack，旨在实现上述目标。&lt;h4&gt;主要发现&lt;/h4&gt;Hier-EgoPack能够创建可以跨任务迁移的任务视角，并提供额外的洞察。&lt;h4&gt;结论&lt;/h4&gt;Hier-EgoPack是一个潜在的技能背包，机器人可以在需要时使用。&lt;h4&gt;翻译&lt;/h4&gt;我们的理解视频流中描述的人类活动是多方面的：在短短几秒钟内，我们可以理解正在发生的事情，识别场景中对象的相关性和相互作用，并预测接下来将要发生的事情。为了赋予自主系统这样的整体感知能力，学习如何关联不同任务的概念和抽象知识，以及在学习新技能时利用任务协同是至关重要的。在本文中，我们介绍了一种统一框架，称为Hier-EgoPack，它能够创建一系列任务视角，这些视角可以在下游任务中迁移，并作为额外洞察的潜在来源，就像机器人可以携带并使用的一套技能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Our comprehension of video streams depicting human activities is naturallymultifaceted: in just a few moments, we can grasp what is happening, identifythe relevance and interactions of objects in the scene, and forecast what willhappen soon, everything all at once. To endow autonomous systems with suchholistic perception, learning how to correlate concepts, abstract knowledgeacross diverse tasks, and leverage tasks synergies when learning novel skillsis essential. In this paper, we introduce Hier-EgoPack, a unified frameworkable to create a collection of task perspectives that can be carried acrossdownstream tasks and used as a potential source of additional insights, as abackpack of skills that a robot can carry around and use when needed.</description>
      <author>example@mail.com (Simone Alberto Peirone, Francesca Pistilli, Antonio Alliegro, Tatiana Tommasi, Giuseppe Averta)</author>
      <guid isPermaLink="false">2505.24690v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Attractor learning for spatiotemporally chaotic dynamical systems using echo state networks with transfer learning</title>
      <link>http://arxiv.org/abs/2505.24099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了回声状态网络（ESNs）在广义库尔莫托-西瓦辛斯基（gKS）方程预测能力，这是一种具有时空混沌的非线性偏微分方程。通过结合迁移学习，提出了一种新方法来提升ESNs在不同参数范围内的预测性能，重点关注预测由变化色散关系或空间域长度引起的gKS模型长期统计模式的变化，并成功捕捉了潜在混沌吸引子的变化。&lt;h4&gt;背景&lt;/h4&gt;gKS方程是一种展示时空混沌的非线性偏微分方程。&lt;h4&gt;目的&lt;/h4&gt;目的是通过引入迁移学习来提升ESNs在不同参数范围内的预测性能。&lt;h4&gt;方法&lt;/h4&gt;采用了一种结合ESNs与迁移学习的方法，用于预测gKS模型长期统计模式的变化。&lt;h4&gt;主要发现&lt;/h4&gt;研究重点关注预测由变化色散关系或空间域长度引起的gKS模型长期统计模式的变化，并成功捕捉了潜在混沌吸引子的变化。&lt;h4&gt;结论&lt;/h4&gt;通过迁移学习，ESNs能够有效地适应不同的参数设置，并成功预测gKS模型中的混沌吸引子变化。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we explore the predictive capabilities of echo state networks (ESNs) for the generalized Kuramoto-Sivashinsky (gKS) equation, an archetypal nonlinear PDE that exhibits spatiotemporal chaos. We introduce a novel methodology that integrates ESNs with transfer learning, aiming to enhance predictive performance across various parameter regimes of the gKS model. Our research focuses on predicting changes in long-term statistical patterns of the gKS model that result from varying the dispersion relation or the length of the spatial domain. We use transfer learning to adapt ESNs to different parameter settings and successfully capture changes in the underlying chaotic attractor.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we explore the predictive capabilities of echo state networks(ESNs) for the generalized Kuramoto-Sivashinsky (gKS) equation, an archetypalnonlinear PDE that exhibits spatiotemporal chaos. We introduce a novelmethodology that integrates ESNs with transfer learning, aiming to enhancepredictive performance across various parameter regimes of the gKS model. Ourresearch focuses on predicting changes in long-term statistical patterns of thegKS model that result from varying the dispersion relation or the length of thespatial domain. We use transfer learning to adapt ESNs to different parametersettings and successfully capture changes in the underlying chaotic attractor.</description>
      <author>example@mail.com (Mohammad Shah Alam, William Ott, Ilya Timofeyev)</author>
      <guid isPermaLink="false">2505.24099v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Binary Cumulative Encoding meets Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2505.24595v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了通过分类任务来构建时间序列预测回归的方法，提出了一种新的二进制累积编码（BCE）方法，以改进现有方法的不足。&lt;h4&gt;背景&lt;/h4&gt;近年来，时间序列预测的研究探讨了通过分类任务来构建回归的方法。这些方法通过将连续的目标空间离散化并预测固定类别的数据，具有稳定的训练、鲁棒的不确定性建模和与深度学习架构的兼容性。&lt;h4&gt;目的&lt;/h4&gt;提出的方法旨在解决现有方法中忽略目标值的序数结构的问题，并允许模型在分类框架内学习到距离感知的表示。&lt;h4&gt;方法&lt;/h4&gt;引入了BCE，将标量目标表示为单调的二进制向量，以保留顺序和幅度信息。此外，还提出了一种专门针对BCE的卷积神经网络架构，其中包含了残差和扩张卷积，以实现快速和表达的时间建模。&lt;h4&gt;主要发现&lt;/h4&gt;在基准预测数据集上的广泛实验表明，该方法在点预测和概率预测方面均优于广泛使用的方法，同时参数更少，训练更快。&lt;h4&gt;结论&lt;/h4&gt;BCE编码和设计的卷积神经网络架构能够提高时间序列预测的准确性和效率。&lt;h4&gt;翻译&lt;/h4&gt;Recent studies in time series forecasting have explored formulating regression via classification task. By discretizing the continuous target space into bins and predicting over a fixed set of classes, these approaches benefit from stable training, robust uncertainty modeling, and compatibility with modern deep learning architectures. However, most existing methods rely on one-hot encoding that ignores the inherent ordinal structure of the underlying values. As a result, they fail to provide information about the relative distance between predicted and true values during training. In this paper, we propose to address this limitation by introducing binary cumulative encoding (BCE), that represents scalar targets into monotonic binary vectors. This encoding implicitly preserves order and magnitude information, allowing the model to learn distance-aware representations while still operating within a classification framework. We propose a convolutional neural network architecture specifically designed for BCE, incorporating residual and dilated convolutions to enable fast and expressive temporal modeling. Through extensive experiments on benchmark forecasting datasets, we show that our approach outperforms widely used methods in both point and probabilistic forecasting, while requiring fewer parameters and enabling faster training.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies in time series forecasting have explored formulatingregression via classification task. By discretizing the continuous target spaceinto bins and predicting over a fixed set of classes, these approaches benefitfrom stable training, robust uncertainty modeling, and compatibility withmodern deep learning architectures. However, most existing methods rely onone-hot encoding that ignores the inherent ordinal structure of the underlyingvalues. As a result, they fail to provide information about the relativedistance between predicted and true values during training. In this paper, wepropose to address this limitation by introducing binary cumulative encoding(BCE), that represents scalar targets into monotonic binary vectors. Thisencoding implicitly preserves order and magnitude information, allowing themodel to learn distance-aware representations while still operating within aclassification framework. We propose a convolutional neural networkarchitecture specifically designed for BCE, incorporating residual and dilatedconvolutions to enable fast and expressive temporal modeling. Through extensiveexperiments on benchmark forecasting datasets, we show that our approachoutperforms widely used methods in both point and probabilistic forecasting,while requiring fewer parameters and enabling faster training.</description>
      <author>example@mail.com (Andrei Chernov, Vitaliy Pozdnyakov, Ilya Makarov)</author>
      <guid isPermaLink="false">2505.24595v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>BIRD: Behavior Induction via Representation-structure Distillation</title>
      <link>http://arxiv.org/abs/2505.23933v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;BIRD（通过表示结构蒸馏进行行为诱导）是一种灵活的框架，通过匹配学生模型的内部表示结构来转移对齐行为，提高了模型在不同任务或数据分布上的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;将与人类价值观一致的行为（如鲁棒性、公平性和诚实性）转移到不同任务或数据分布的模型上存在挑战，因为在对齐行为中，对齐行为容易在微调过程中丢失，并且收集保留这些行为的特定任务数据成本高昂。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，能够有效地将具有对齐行为（如鲁棒性）的模型转移到新的任务或数据集上。&lt;h4&gt;方法&lt;/h4&gt;提出BIRD框架，通过匹配学生模型的内部表示结构到教师模型的结构，来实现对齐行为的转移。&lt;h4&gt;主要发现&lt;/h4&gt;BIRD在图像分类的分布外鲁棒性方面优于微调、迁移学习和持续学习方法，提高了鲁棒准确率，最高可达16%。即使在教师模型在更简单的数据集上训练，并且比学生模型小25倍的情况下，BIRD仍然有效。在超过400对教师-学生模型的大规模研究中，教师表示的三个可解释和可计算属性（即任务相关性、行为相关性和互补知识）解释了转移成功变化的85%。&lt;h4&gt;结论&lt;/h4&gt;BIRD可以将小型、对齐良好的模型转化为可扩展的对齐种子，消除了在野外部署安全AI系统的一个关键瓶颈。&lt;h4&gt;翻译&lt;/h4&gt;Human-aligned deep learning models exhibit behaviors consistent with human values, such as robustness, fairness, and honesty. Transferring these behavioral properties to models trained on different tasks or data distributions remains challenging: aligned behavior is easily forgotten during fine-tuning, and collecting task-specific data that preserves this behavior can be prohibitively costly. We introduce BIRD (Behavior Induction via Representation-structure Distillation), a flexible framework for transferring aligned behavior by matching the internal representation structure of a student model to that of a teacher. Applied to out-of-distribution robustness in image classification, BIRD outperforms fine-tuning, transfer learning, and continual learning methods, improving robust accuracy by up to 16% over the next strongest baseline. It remains effective even when the teacher is trained on a much simpler dataset and is 25 × smaller than the student. In a large-scale study of over 400 teacher-student pairs, we show that three interpretable and computable properties of the teacher's representations (i.e., task relevance, behavioral relevance, and complementary knowledge) explain up to 85% of the variance in transfer success. These insights offer practical guidance for teacher selection and design. BIRD turns small, well-aligned models into scalable alignment seeds, removing a key bottleneck in deploying safe AI systems in the wild.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human-aligned deep learning models exhibit behaviors consistent with humanvalues, such as robustness, fairness, and honesty. Transferring thesebehavioral properties to models trained on different tasks or datadistributions remains challenging: aligned behavior is easily forgotten duringfine-tuning, and collecting task-specific data that preserves this behavior canbe prohibitively costly. We introduce BIRD (Behavior Induction viaRepresentation-structure Distillation), a flexible framework for transferringaligned behavior by matching the internal representation structure of a studentmodel to that of a teacher. Applied to out-of-distribution robustness in imageclassification, BIRD outperforms fine-tuning, transfer learning, and continuallearning methods, improving robust accuracy by up to 16% over the nextstrongest baseline. It remains effective even when the teacher is trained on amuch simpler dataset and is $25 \times$ smaller than the student. In alarge-scale study of over 400 teacher-student pairs, we show that threeinterpretable and computable properties of the teacher's representations (i.e.,task relevance, behavioral relevance, and complementary knowledge) explain upto 85% of the variance in transfer success. These insights offer practicalguidance for teacher selection and design. BIRD turns small, well-alignedmodels into scalable alignment seeds, removing a key bottleneck in deployingsafe AI systems in the wild.</description>
      <author>example@mail.com (Galen Pogoncheff, Michael Beyeler)</author>
      <guid isPermaLink="false">2505.23933v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Two-stage MCMC for Fast Bayesian Inference of Large Spatio-temporal Ordinal Data, with Application to US Drought</title>
      <link>http://arxiv.org/abs/2505.24594v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种适用于大型数据集的贝叶斯时空模型拟合方法，通过两个阶段的算法来处理高维时空数据。&lt;h4&gt;背景&lt;/h4&gt;高维时空数据在拟合时空模型时面临计算挑战，数据依赖性强，且涉及大量观测值。&lt;h4&gt;目的&lt;/h4&gt;提出一种适用于有序响应变量的贝叶斯时空模型拟合方法，避免过度简化的模型。&lt;h4&gt;方法&lt;/h4&gt;采用两阶段算法：第一阶段独立地建模空间位置，捕捉时间依赖性，并支持并行计算；第二阶段从第一阶段的后验分布中重采样，引入空间依赖性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了快速贝叶斯推理，能够在计算上对大型数据集是可行的，并保持了后验分布的完整性。&lt;h4&gt;结论&lt;/h4&gt;该方法相比单阶段模型拟合在计算上具有显著优势，并适用于大型时空数据集。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a two-stage algorithm for fitting Bayesian spatio-temporal models to large datasets when the response variable is ordinal, addressing the computational challenges of high-dimensional spatio-temporal data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High dimensional space-time data pose known computational challenges whenfitting spatio-temporal models. Such data show dependence across severaldimensions of space as well as in time, and can easily involve hundreds ofthousands of observations. Many spatio-temporal models result in a dependencestructure across all observations and can be fit only at a substantialcomputational cost, arising from dense matrix inversion, high dimensionalparameter spaces, poor mixing in Markov Chain Monte Carlo, or the impossibilityof utilizing parallel computing due to a lack of independence anywhere in themodel fitting process. These computational challenges are exacerbated when theresponse variable is ordinal, and especially as the number of orderedcategories grows. Some spatio-temporal models achieve computational feasibilityfor large datasets but only through overly restrictive model simplifications,which we seek to avoid here. In this paper we demonstrate a two-stage algorithmto fit a Bayesian spatio-temporal model to large datasets when the responsevariable is ordinal. The first stage models locations independently in space,capturing temporal dependence, and can be run in parallel. The second stageresamples from the first stage posterior distributions with an acceptanceprobability computed to impose spatial dependence from the full spatio-temporalmodel. The result is fast Bayesian inference which samples from the fullspatio-temporal posterior and is computationally feasible even for largedatasets. We quantify the substantial computational gains our approachachieves, and demonstrate the preservation of the posterior distribution ascompared to the more costly single-stage model fit. We apply our approach to alarge spatio-temporal drought dataset in the United States, a dataset too largefor many existing spatio-temporal methods.</description>
      <author>example@mail.com (Staci Hepler, Rob Erhardt)</author>
      <guid isPermaLink="false">2505.24594v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>AFLoRA: Adaptive Federated Fine-Tuning of Large Language Models with Resource-Aware Low-Rank Adaption</title>
      <link>http://arxiv.org/abs/2505.24773v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AFLoRA的联邦微调框架，用于在异构和受限的资源环境中高效地调整大型语言模型。&lt;h4&gt;背景&lt;/h4&gt;联邦微调是一种使用分布式数据来适应下游任务的可行方法，但在实际部署中，由于客户端的计算和通信需求高，以及数据异构性，存在挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在解决联邦微调中计算和通信开销大、数据异构性问题，提高大型语言模型的适应性和效率。&lt;h4&gt;方法&lt;/h4&gt;AFLoRA通过解耦共享和客户端特定更新来减少开销，利用对角矩阵进行秩剪枝以更好地利用本地资源，并采用秩感知聚合与公开数据细化来增强数据异构性下的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，AFLoRA在准确性和效率方面均优于现有方法，为实际环境中高效的大语言模型适应提供了可行的解决方案。&lt;h4&gt;结论&lt;/h4&gt;AFLoRA是一个有效的联邦微调框架，适用于在异构环境中对大型语言模型进行高效调整。&lt;h4&gt;翻译&lt;/h4&gt;Federated fine-tuning has emerged as a promising approach to adapt foundation models to downstream tasks using decentralized data. However, real-world deployment remains challenging due to the high computational and communication demands of fine-tuning Large Language Models (LLMs) on clients with data and system resources that are heterogeneous and constrained. In such settings, the global model's performance is often bottlenecked by the weakest clients and further degraded by the non-IID nature of local data. Although existing methods leverage parameter-efficient techniques such as Low-Rank Adaptation (LoRA) to reduce communication and computation overhead, they often fail to simultaneously ensure accurate aggregation of low-rank updates and maintain low system costs, thereby hindering overall performance. To address these challenges, we propose AFLoRA, an adaptive and lightweight federated fine-tuning framework for LLMs. AFLoRA decouples shared and client-specific updates to reduce overhead and improve aggregation accuracy, incorporates diagonal matrix-based rank pruning to better utilize local resources, and employs rank-aware aggregation with public data refinement to strengthen generalization under data heterogeneity. Extensive experiments demonstrate that AFLoRA outperforms state-of-the-art methods in both accuracy and efficiency, providing a practical solution for efficient LLM adaptation in heterogeneous environments in the real world.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated fine-tuning has emerged as a promising approach to adapt foundationmodels to downstream tasks using decentralized data. However, real-worlddeployment remains challenging due to the high computational and communicationdemands of fine-tuning Large Language Models (LLMs) on clients with data andsystem resources that are heterogeneous and constrained. In such settings, theglobal model's performance is often bottlenecked by the weakest clients andfurther degraded by the non-IID nature of local data. Although existing methodsleverage parameter-efficient techniques such as Low-Rank Adaptation (LoRA) toreduce communication and computation overhead, they often fail tosimultaneously ensure accurate aggregation of low-rank updates and maintain lowsystem costs, thereby hindering overall performance. To address thesechallenges, we propose AFLoRA, an adaptive and lightweight federatedfine-tuning framework for LLMs. AFLoRA decouples shared and client-specificupdates to reduce overhead and improve aggregation accuracy, incorporatesdiagonal matrix-based rank pruning to better utilize local resources, andemploys rank-aware aggregation with public data refinement to strengthengeneralization under data heterogeneity. Extensive experiments demonstrate thatAFLoRA outperforms state-of-the-art methods in both accuracy and efficiency,providing a practical solution for efficient LLM adaptation in heterogeneousenvironments in the real world.</description>
      <author>example@mail.com (Yajie Zhou, Xiaoyi Pang, Zhibo Wang)</author>
      <guid isPermaLink="false">2505.24773v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>SPPSFormer: High-quality Superpoint-based Transformer for Roof Plane Instance Segmentation from Point Clouds</title>
      <link>http://arxiv.org/abs/2505.24475v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了Transformer在点云屋顶平面实例分割中的应用，并提出了一种改进的方法来生成高质量的superpoints，以提升Transformer的性能。该方法结合了手工特征和多维特征，设计了新的解码器，并通过后处理优化了预测结果。&lt;h4&gt;背景&lt;/h4&gt;Transformer在点云屋顶平面实例分割中的应用较少，现有的superpoint Transformers由于使用低质量的superpoints而性能有限。&lt;h4&gt;目的&lt;/h4&gt;提高Transformer在点云屋顶平面实例分割中的性能。&lt;h4&gt;方法&lt;/h4&gt;1. 建立了两个高质量superpoints应满足的标准；2. 介绍了相应的两阶段superpoint生成过程；3. 将多维手工特征结合到模型中；4. 设计了一种结合Kolmogorov-Arnold网络和Transformer模块的解码器；5. 使用传统算法进行后处理优化。&lt;h4&gt;主要发现&lt;/h4&gt;1. 新方法在数据集上达到了最先进的性能；2. 模型对训练过程中的平面边界标注不敏感，显著降低了标注负担；3. 除了屋顶类型外，点云密度、密度均匀性和3D点精度对分割性能有显著影响。&lt;h4&gt;结论&lt;/h4&gt;通过引入高质量superpoints、结合手工特征和改进的解码器，可以显著提升Transformer在点云屋顶平面实例分割中的性能，并减轻标注负担。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformers have been seldom employed in point cloud roof plane instancesegmentation, which is the focus of this study, and existing superpointTransformers suffer from limited performance due to the use of low-qualitysuperpoints. To address this challenge, we establish two criteria thathigh-quality superpoints for Transformers should satisfy and introduce acorresponding two-stage superpoint generation process. The superpointsgenerated by our method not only have accurate boundaries, but also exhibitconsistent geometric sizes and shapes, both of which greatly benefit thefeature learning of superpoint Transformers. To compensate for the limitationsof deep learning features when the training set size is limited, we incorporatemultidimensional handcrafted features into the model. Additionally, we design adecoder that combines a Kolmogorov-Arnold Network with a Transformer module toimprove instance prediction and mask extraction. Finally, our network'spredictions are refined using traditional algorithm-based postprocessing. Forevaluation, we annotated a real-world dataset and corrected annotation errorsin the existing RoofN3D dataset. Experimental results show that our methodachieves state-of-the-art performance on our dataset, as well as both theoriginal and reannotated RoofN3D datasets. Moreover, our model is not sensitiveto plane boundary annotations during training, significantly reducing theannotation burden. Through comprehensive experiments, we also identified keyfactors influencing roof plane segmentation performance: in addition to rooftypes, variations in point cloud density, density uniformity, and 3D pointprecision have a considerable impact. These findings underscore the importanceof incorporating data augmentation strategies that account for point cloudquality to enhance model robustness under diverse and challenging conditions.</description>
      <author>example@mail.com (Cheng Zeng, Xiatian Qi, Chi Chen, Kai Sun, Wangle Zhang, Yuxuan Liu, Yan Meng, Bisheng Yang)</author>
      <guid isPermaLink="false">2505.24475v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing the Accuracy of Spatio-Temporal Models for Wind Speed Prediction by Incorporating Bias-Corrected Crowdsourced Data</title>
      <link>http://arxiv.org/abs/2505.24506v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种框架，通过两阶段方法将个人气象站（PWS）数据纳入统计模型，以验证官方气象站数据，从而提高风能潜力的估计准确性。&lt;h4&gt;背景&lt;/h4&gt;高分辨率时空风速数据对于估计地点的风能潜力至关重要。统计模型通常依赖于来自官方气象站的高质量实时数据以提高预测准确性。&lt;h4&gt;目的&lt;/h4&gt;将个人气象站数据整合到统计模型中，以验证官方气象站数据，并提高风能潜力的估计准确性。&lt;h4&gt;方法&lt;/h4&gt;首先，使用再分析数据对PWS风速数据进行偏差校正。其次，实施一个贝叶斯层次时空模型，该模型考虑了PWS数据中的测量误差。&lt;h4&gt;主要发现&lt;/h4&gt;包括偏差校正的PWS数据比仅使用气象站数据提高了预测准确性，平均预测误差降低了7%。结果与流行的再分析产品相当，但与这些数值天气预报模型不同，该方法提供实时数据并提高了不确定性量化。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过结合PWS数据和官方气象站数据，显著提高了风能潜力的估计准确性，尤其适用于官方监测站稀疏的地区。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate high-resolution spatial and temporal wind speed data is critical forestimating the wind energy potential of a location. For real-time wind speedprediction, statistical models typically depend on high-quality (near)real-time data from official meteorological stations to improve forecastingaccuracy. Personal weather stations (PWS) offer an additional source ofreal-time data and broader spatial coverage than offical stations. However,they are not subject to rigorous quality control and may exhibit bias ormeasurement errors. This paper presents a framework for incorporating PWS datainto statistical models for validated official meteorological station data viaa two-stage approach. First, bias correction is performed on PWS wind speeddata using reanalysis data. Second, we implement a Bayesian hierarchicalspatio-temporal model that accounts for varying measurement error in the PWSdata. This enables wind speed prediction across a target area, and isparticularly beneficial for improving predictions in regions sparse in officialmonitoring stations. Our results show that including bias-corrected PWS dataimproves prediction accuracy compared to using meteorological station dataalone, with a 7% reduction in prediction error on average across all sites. Theresults are comparable with popular reanalysis products, but unlike thesenumerical weather models our approach is available in real-time and offersimproved uncertainty quantification.</description>
      <author>example@mail.com (Eamonn Organ, Maeve Upton, Denis Allard, Lionel Benoit, James Sweeney)</author>
      <guid isPermaLink="false">2505.24506v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Primal-Dual Neural Algorithmic Reasoning</title>
      <link>http://arxiv.org/abs/2505.24067v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The 42nd International Conference on Machine Learning, 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于原-对偶范式的通用Neural Algorithmic Reasoning（NAR）框架，用于解决更复杂的难题，并通过实证研究证明了其在多个任务上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;目前NAR研究主要集中在学习多项式时间内可解问题的精确算法，将其扩展到更难问题仍是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够处理更难问题的NAR框架，并提升模型在复杂数据上的推理能力。&lt;h4&gt;方法&lt;/h4&gt;采用原-对偶范式，利用原变量和对偶变量之间的二分表示，将原-对偶算法与图神经网络相结合，并将小实例的最优解引入模型以增强推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;模型不仅能够模拟近似算法，而且在多个任务上超越了它们，表现出对更大和分布外图的良好泛化能力。&lt;h4&gt;结论&lt;/h4&gt;提出的框架具有实际应用价值，可以通过与商业求解器集成并应用于真实世界数据集来展示其效用。&lt;h4&gt;翻译&lt;/h4&gt;Neural Algorithmic Reasoning (NAR) 训练神经网络来模拟经典算法，使得在复杂数据上能够进行结构化和可解释的推理。虽然先前的研究主要集中在学习多项式时间内可解问题的精确算法，但将NAR扩展到更难问题仍然是一个开放挑战。在这项工作中，我们引入了一个基于原-对偶范式的通用NAR框架，这是一种设计高效近似算法的经典方法。通过利用原变量和对偶变量之间的二分表示，我们建立了原-对偶算法与图神经网络之间的对齐。此外，我们通过将小实例的最优解引入模型来极大地增强了模型的推理能力。我们的实证结果表明，我们的模型不仅能够模拟，而且在多个任务上优于近似算法，表现出对更大和分布外图的鲁棒泛化能力。此外，我们通过将其与商业求解器集成并将其应用于真实世界数据集，强调了该框架的实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural Algorithmic Reasoning (NAR) trains neural networks to simulateclassical algorithms, enabling structured and interpretable reasoning overcomplex data. While prior research has predominantly focused on learning exactalgorithms for polynomial-time-solvable problems, extending NAR to harderproblems remains an open challenge. In this work, we introduce a general NARframework grounded in the primal-dual paradigm, a classical method fordesigning efficient approximation algorithms. By leveraging a bipartiterepresentation between primal and dual variables, we establish an alignmentbetween primal-dual algorithms and Graph Neural Networks. Furthermore, weincorporate optimal solutions from small instances to greatly enhance themodel's reasoning capabilities. Our empirical results demonstrate that ourmodel not only simulates but also outperforms approximation algorithms formultiple tasks, exhibiting robust generalization to larger andout-of-distribution graphs. Moreover, we highlight the framework's practicalutility by integrating it with commercial solvers and applying it to real-worlddatasets.</description>
      <author>example@mail.com (Yu He, Ellen Vitercik)</author>
      <guid isPermaLink="false">2505.24067v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>A Mathematical Perspective On Contrastive Learning</title>
      <link>http://arxiv.org/abs/2505.24134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  44 pages, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多模态对比学习方法，用于连接不同的数据模态，特别是图像和文本数据。该方法通过识别一组编码器，每个模态一个，以在共同潜在空间中对齐表示。&lt;h4&gt;背景&lt;/h4&gt;多模态对比学习是连接不同数据模态的方法，其典型例子是连接图像和文本数据。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过优化编码器来定义每个模态条件概率分布，以实现多模态算法如跨模态检索和分类。&lt;h4&gt;方法&lt;/h4&gt;采用了一种框架，该框架将对比学习解释为优化编码器，以定义符合可用数据的条件概率分布。研究还包括引入新的概率损失函数和使用替代指标来衡量共同潜在空间中的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在多元高斯设置中，将潜在空间识别视为低秩矩阵近似问题，从而可以描述损失函数和度量指标在逼近自然统计（如条件均值和协方差）方面的能力。&lt;h4&gt;结论&lt;/h4&gt;引入的框架通过数值实验在多元高斯、标记的MNIST数据集和海洋学中的数据同化应用中得到研究。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种多模态对比学习方法，旨在连接不同数据模态，特别是图像和文本数据。该方法通过识别一组编码器，每个模态一个，以在共同潜在空间中对齐表示。研究包括优化编码器以定义条件概率分布，以及引入新的概率损失函数和使用替代指标来衡量共同潜在空间中的对齐。在多元高斯设置中，将潜在空间识别视为低秩矩阵近似问题，并通过数值实验得到研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal contrastive learning is a methodology for linking different datamodalities; the canonical example is linking image and text data. Themethodology is typically framed as the identification of a set of encoders, onefor each modality, that align representations within a common latent space. Inthis work, we focus on the bimodal setting and interpret contrastive learningas the optimization of (parameterized) encoders that define conditionalprobability distributions, for each modality conditioned on the other,consistent with the available data. This provides a framework for multimodalalgorithms such as crossmodal retrieval, which identifies the mode of one ofthese conditional distributions, and crossmodal classification, which issimilar to retrieval but includes a fine-tuning step to make it task specific.  The framework we adopt also gives rise to crossmodal generative models. Thisprobabilistic perspective suggests two natural generalizations of contrastivelearning: the introduction of novel probabilistic loss functions, and the useof alternative metrics for measuring alignment in the common latent space. Westudy these generalizations of the classical approach in the multivariateGaussian setting. In this context we view the latent space identification as alow-rank matrix approximation problem. This allows us to characterize thecapabilities of loss functions and alignment metrics to approximate naturalstatistics, such as conditional means and covariances; doing so yields novelvariants on contrastive learning algorithms for specific mode-seeking and forgenerative tasks. The framework we introduce is also studied through numericalexperiments on multivariate Gaussians, the labeled MNIST dataset, and on a dataassimilation application arising in oceanography.</description>
      <author>example@mail.com (Ricardo Baptista, Andrew M. Stuart, Son Tran)</author>
      <guid isPermaLink="false">2505.24134v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Bridging 3D Anomaly Localization and Repair via High-Quality Continuous Geometric Representation</title>
      <link>http://arxiv.org/abs/2505.24431v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Pose-Aware Signed Distance Field (PASDF)的3D点云异常检测框架，用于提高视觉系统的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;3D点云异常检测对于稳健的视觉系统至关重要，但受到姿态变化和复杂几何异常的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够集成3D异常检测和修复的学习框架，通过学习连续、姿态不变形状表示来提高几何保真度。&lt;h4&gt;方法&lt;/h4&gt;PASDF利用姿态对齐模块进行正则化，并通过SDF网络动态地结合姿态信息，实现从连续SDF中隐式学习高保真异常修复模板。此外，通过异常感知评分模块实现精确的像素级异常定位。&lt;h4&gt;主要发现&lt;/h4&gt;在Real3D-AD和Anomaly-ShapeNet数据集上的实验表明，PASDF实现了最先进的性能，分别达到了80.2%和90.0%的高对象级AUROC分数。&lt;h4&gt;结论&lt;/h4&gt;PASDF通过连续几何表示在3D异常检测中取得了显著效果，并促进了实际异常区域的修复。&lt;h4&gt;翻译&lt;/h4&gt;摘要：三维点云异常检测对于稳健的视觉系统至关重要，但受到姿态变化和复杂几何异常的挑战。现有的基于补丁的方法由于离散体素化或基于投影的表示，往往遭受几何保真度问题，限制了细粒度异常定位。我们引入了姿态感知签名距离场（PASDF），这是一个新的框架，通过学习连续、姿态不变形状表示来集成3D异常检测和修复。PASDF利用姿态对齐模块进行规范化，并通过SDF网络动态地结合姿态，从连续SDF中隐式学习高保真异常修复模板。这通过异常感知评分模块促进了精确的像素级异常定位。至关重要的是，PASDF中的连续三维表示不仅限于检测，还促进了现场异常修复。在Real3D-AD和Anomaly-ShapeNet上的实验证明了最先进的性能，分别达到了80.2%和90.0%的高对象级AUROC分数。这些结果突出了连续几何表示在推进3D异常检测和促进实际异常区域修复方面的有效性。代码可在https://github.com/ZZZBBBZZZ/PASDF上获得，以支持进一步的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D point cloud anomaly detection is essential for robust vision systems butis challenged by pose variations and complex geometric anomalies. Existingpatch-based methods often suffer from geometric fidelity issues due to discretevoxelization or projection-based representations, limiting fine-grained anomalylocalization. We introduce Pose-Aware Signed Distance Field (PASDF), a novelframework that integrates 3D anomaly detection and repair by learning acontinuous, pose-invariant shape representation. PASDF leverages a PoseAlignment Module for canonicalization and a SDF Network to dynamicallyincorporate pose, enabling implicit learning of high-fidelity anomaly repairtemplates from the continuous SDF. This facilitates precise pixel-level anomalylocalization through an Anomaly-Aware Scoring Module. Crucially, the continuous3D representation in PASDF extends beyond detection, facilitating in-situanomaly repair. Experiments on Real3D-AD and Anomaly-ShapeNet demonstratestate-of-the-art performance, achieving high object-level AUROC scores of 80.2%and 90.0%, respectively. These results highlight the effectiveness ofcontinuous geometric representations in advancing 3D anomaly detection andfacilitating practical anomaly region repair. The code is available athttps://github.com/ZZZBBBZZZ/PASDF to support further research.</description>
      <author>example@mail.com (Bozhong Zheng, Jinye Gan, Xiaohao Xu, Wenqiao Li, Xiaonan Huang, Na Ni, Yingna Wu)</author>
      <guid isPermaLink="false">2505.24431v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model</title>
      <link>http://arxiv.org/abs/2505.24476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Period-LLM的多模态大型语言模型，旨在提高周期性任务在各种模态上的性能，并构建了不同难度的基准来评估大型模型的跨模态周期能力。&lt;h4&gt;背景&lt;/h4&gt;周期或准周期现象揭示了各种自然过程（如天气模式、运动行为、交通流和生物信号）的内在特性。由于这些现象跨越多个模态，多模态大型语言模型（MLLMs）在有效捕捉和理解其复杂性质方面具有潜在能力。&lt;h4&gt;目的&lt;/h4&gt;解决当前MLLMs在周期性任务上的困难，包括缺乏时间建模和短周期与长周期的冲突。&lt;h4&gt;方法&lt;/h4&gt;提出Period-LLM模型，采用“从简单到复杂泛化”的方法，从相对简单的文本任务开始，逐步过渡到更复杂的视觉和多模态任务，以确保模型逐步建立稳健的周期推理能力。此外，还提出了“抵抗逻辑遗忘”的优化策略，以在语义对齐过程中保持周期推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;大量实验表明，所提出的Period-LLM在周期性任务上优于现有的MLLMs。&lt;h4&gt;结论&lt;/h4&gt;Period-LLM模型在周期性任务方面表现出优越性，为多模态大型语言模型在周期性现象处理方面提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Periodic or quasi-periodic phenomena reveal intrinsic characteristics in various natural processes, such as weather patterns, movement behaviors, traffic flows, and biological signals. Given that these phenomena span multiple modalities, the capabilities of Multimodal Large Language Models (MLLMs) offer promising potential to effectively capture and understand their complex nature. However, current MLLMs struggle with periodic tasks due to limitations in: 1) lack of temporal modelling and 2) conflict between short and long periods. This paper introduces Period-LLM, a multimodal large language model designed to enhance the performance of periodic tasks across various modalities, and constructs a benchmark of various difficulty for evaluating the cross-modal periodic capabilities of large models. Specially, We adopt an 'Easy to Hard Generalization' paradigm, starting with relatively simple text-based tasks and progressing to more complex visual and multimodal tasks, ensuring that the model gradually builds robust periodic reasoning capabilities. Additionally, we propose a 'Resisting Logical Oblivion' optimization strategy to maintain periodic reasoning abilities during semantic alignment. Extensive experiments demonstrate the superiority of the proposed Period-LLM over existing MLLMs in periodic tasks. The code is available at https://github.com/keke-nice/Period-LLM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Periodic or quasi-periodic phenomena reveal intrinsic characteristics invarious natural processes, such as weather patterns, movement behaviors,traffic flows, and biological signals. Given that these phenomena span multiplemodalities, the capabilities of Multimodal Large Language Models (MLLMs) offerpromising potential to effectively capture and understand their complex nature.However, current MLLMs struggle with periodic tasks due to limitations in: 1)lack of temporal modelling and 2) conflict between short and long periods. Thispaper introduces Period-LLM, a multimodal large language model designed toenhance the performance of periodic tasks across various modalities, andconstructs a benchmark of various difficulty for evaluating the cross-modalperiodic capabilities of large models. Specially, We adopt an "Easy to HardGeneralization" paradigm, starting with relatively simple text-based tasks andprogressing to more complex visual and multimodal tasks, ensuring that themodel gradually builds robust periodic reasoning capabilities. Additionally, wepropose a "Resisting Logical Oblivion" optimization strategy to maintainperiodic reasoning abilities during semantic alignment. Extensive experimentsdemonstrate the superiority of the proposed Period-LLM over existing MLLMs inperiodic tasks. The code is available athttps://github.com/keke-nice/Period-LLM.</description>
      <author>example@mail.com (Yuting Zhang, Hao Lu, Qingyong Hu, Yin Wang, Kaishen Yuan, Xin Liu, Kaishun Wu)</author>
      <guid isPermaLink="false">2505.24476v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>PDE-Transformer: Efficient and Versatile Transformers for Physics Simulations</title>
      <link>http://arxiv.org/abs/2505.24717v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025. Code available at  https://github.com/tum-pbs/pde-transformer&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于PDE-Transformer的改进型架构，用于在规则网格上进行物理模拟的代理建模。该架构结合了扩散变换器的最新架构改进和针对大规模模拟的调整，以实现更可扩展和通用的变压器架构。实验表明，该架构在16种不同类型的PDE数据集上优于现有的计算机视觉Transformer架构。此外，该方法通过将不同的物理通道作为时空标记单独嵌入，并通过通道自注意力机制进行交互，有助于在同时学习多种类型的PDE时保持标记信息的一致密度。预训练模型在多个下游任务上的性能优于从头开始训练，并在物理模拟中击败了其他基础模型架构。&lt;h4&gt;背景&lt;/h4&gt;当前对物理模拟的代理建模方法需要更高效和通用的架构。&lt;h4&gt;目的&lt;/h4&gt;提出一个改进的Transformer架构，用于提高物理模拟代理建模的效率。&lt;h4&gt;方法&lt;/h4&gt;结合扩散变换器的最新架构改进，调整以适应大规模模拟，并提出将不同物理通道作为时空标记嵌入并使用通道自注意力机制。&lt;h4&gt;主要发现&lt;/h4&gt;提出的PDE-Transformer架构在16种不同类型的PDE数据集上优于现有的计算机视觉Transformer架构，且预训练模型在多个下游任务上表现出色。&lt;h4&gt;结论&lt;/h4&gt;PDE-Transformer是一种高效且通用的架构，适用于物理科学中的大规模基础模型构建。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了PDE-Transformer，这是一种改进的基于变换器的架构，用于在规则网格上进行物理模拟的代理建模。我们将扩散变换器的最新架构改进与针对大规模模拟的调整相结合，以产生一个更可扩展和通用的通用变换器架构，该架构可以用作构建物理科学中大规模基础模型的骨干。我们证明了我们的架构在16种不同类型的PDE的大型数据集上优于最先进的计算机视觉变换器架构。我们建议将不同的物理通道分别嵌入为时空标记，并通过通道自注意力机制进行交互。这有助于在学习多种类型的PDE时保持标记信息的一致密度。我们证明了我们的预训练模型在多个具有挑战性的下游任务上的性能优于从头开始训练，并且在物理模拟中也击败了其他基础模型架构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce PDE-Transformer, an improved transformer-based architecture forsurrogate modeling of physics simulations on regular grids. We combine recentarchitectural improvements of diffusion transformers with adjustments specificfor large-scale simulations to yield a more scalable and versatilegeneral-purpose transformer architecture, which can be used as the backbone forbuilding large-scale foundation models in physical sciences. We demonstratethat our proposed architecture outperforms state-of-the-art transformerarchitectures for computer vision on a large dataset of 16 different types ofPDEs. We propose to embed different physical channels individually asspatio-temporal tokens, which interact via channel-wise self-attention. Thishelps to maintain a consistent information density of tokens when learningmultiple types of PDEs simultaneously. We demonstrate that our pre-trainedmodels achieve improved performance on several challenging downstream taskscompared to training from scratch and also beat other foundation modelarchitectures for physics simulations.</description>
      <author>example@mail.com (Benjamin Holzschuh, Qiang Liu, Georg Kohl, Nils Thuerey)</author>
      <guid isPermaLink="false">2505.24717v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Source and Target Domains via Link Prediction for Unsupervised Domain Adaptation on Graphs</title>
      <link>http://arxiv.org/abs/2505.24055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于解决图神经网络（GNNs）在节点分类上的挑战，特别是在无监督领域自适应（UDA）方面，该框架通过链接预测连接源图和目标图中的节点，以增强目标节点的领域内分布邻域。&lt;h4&gt;背景&lt;/h4&gt;GNNs在图上的节点分类表现出色，但其成功依赖于大量标记数据，而获取高质量标签成本高昂且具有挑战性，尤其是在新兴领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效处理源图和目标图之间分布偏移的新框架，以促进分类器的自适应。&lt;h4&gt;方法&lt;/h4&gt;该方法采用链接预测连接源图和目标图中的节点，从而促进消息传递，并通过修改目标图来减少其在嵌入空间中的偏差，同时设计了一种新的身份保持学习目标，以防止目标图中的判别信息丢失。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该框架在真实世界数据集上有效，能够减少源图和目标图之间的偏差，并对领域间的标签分布不均不敏感。&lt;h4&gt;结论&lt;/h4&gt;该框架为无监督领域自适应提供了一个新的解决方案，特别是在处理具有分布偏移的图数据时。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNNs) have shown great ability for node classification on graphs. However, the success of GNNs relies on abundant labeled data, while obtaining high-quality labels is costly and challenging, especially for newly emerging domains. Hence, unsupervised domain adaptation (UDA), which trains a classifier on the labeled source graph and adapts it to the unlabeled target graph, is attracting increasing attention. Various approaches have been proposed to alleviate the distribution shift between the source and target graphs to facilitate the classifier adaptation. However, most of them simply adopt existing UDA techniques developed for independent and identically distributed data to gain domain-invariant node embeddings for graphs, which do not fully consider the graph structure and message-passing mechanism of GNNs during the adaptation and will fail when label distribution shift exists among domains. In this paper, we proposed a novel framework that adopts link prediction to connect nodes between source and target graphs, which can facilitate message-passing between the source and target graphs and augment the target nodes to have ``in-distribution'' neighborhoods with the source domain. This strategy modified the target graph on the input level to reduce its deviation from the source domain in the embedding space and is insensitive to disproportional label distributions across domains. To prevent the loss of discriminative information in the target graph, we further design a novel identity-preserving learning objective, which guides the learning of the edge insertion module together with reconstruction and adaptation losses. Experimental results on real-world datasets demonstrate the effectiveness of our framework.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have shown great ability for node classificationon graphs. However, the success of GNNs relies on abundant labeled data, whileobtaining high-quality labels is costly and challenging, especially for newlyemerging domains. Hence, unsupervised domain adaptation (UDA), which trains aclassifier on the labeled source graph and adapts it to the unlabeled targetgraph, is attracting increasing attention. Various approaches have beenproposed to alleviate the distribution shift between the source and targetgraphs to facilitate the classifier adaptation. However, most of them simplyadopt existing UDA techniques developed for independent and identicallydistributed data to gain domain-invariant node embeddings for graphs, which donot fully consider the graph structure and message-passing mechanism of GNNsduring the adaptation and will fail when label distribution shift exists amongdomains. In this paper, we proposed a novel framework that adopts linkprediction to connect nodes between source and target graphs, which canfacilitate message-passing between the source and target graphs and augment thetarget nodes to have ``in-distribution'' neighborhoods with the source domain.This strategy modified the target graph on the input level to reduce itsdeviation from the source domain in the embedding space and is insensitive todisproportional label distributions across domains. To prevent the loss ofdiscriminative information in the target graph, we further design a novelidentity-preserving learning objective, which guides the learning of the edgeinsertion module together with reconstruction and adaptation losses.Experimental results on real-world datasets demonstrate the effectiveness ofour framework.</description>
      <author>example@mail.com (Yilong Wang, Tianxiang Zhao, Zongyu Wu, Suhang Wang)</author>
      <guid isPermaLink="false">2505.24055v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Bayesian Inference for Spatially-Temporally Misaligned Data Using Predictive Stacking</title>
      <link>http://arxiv.org/abs/2505.24397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  34 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种贝叶斯层次模型来分析时空不匹配的暴露和健康结果数据，以研究空气污染对人类健康的影响。&lt;h4&gt;背景&lt;/h4&gt;空气污染是导致不良健康结果的主要环境风险因素，但其对人类健康的影响难以量化。&lt;h4&gt;目的&lt;/h4&gt;开发一种贝叶斯层次模型来分析时空不匹配的暴露和健康结果数据。&lt;h4&gt;方法&lt;/h4&gt;引入了贝叶斯预测堆叠，结合多个预测时空模型，避免迭代估计算法如马尔可夫链蒙特卡洛法因弱识别参数导致的收敛问题。&lt;h4&gt;主要发现&lt;/h4&gt;应用该方法研究了臭氧对加利福尼亚州哮喘的影响。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地分析时空不匹配的暴露和健康结果数据，为研究空气污染对健康的影响提供了新的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Air pollution remains a major environmental risk factor that is oftenassociated with adverse health outcomes. However, quantifying and evaluatingits effects on human health is challenging due to the complex nature ofexposure data. Recent technological advances have led to the collection ofvarious indicators of air pollution at increasingly high spatial-temporalresolutions (e.g., daily averages of pollutant levels at spatial locationsreferenced by latitude-longitude). However, health outcomes are typicallyaggregated over several spatial-temporal coordinates (e.g., annual prevalencefor a county) to comply with survey regulations. This article develops aBayesian hierarchical model to analyze such spatially-temporally misalignedexposure and health outcome data. We introduce Bayesian predictive stacking,which optimally combines multiple predictive spatial-temporal models and avoidsiterative estimation algorithms such as Markov chain Monte Carlo that struggledue to convergence issues inflicted by the presence of weakly identifiedparameters. We apply our proposed method to study the effects of ozone onasthma in the state of California.</description>
      <author>example@mail.com (Soumyakanti Pan, Sudipto Banerjee)</author>
      <guid isPermaLink="false">2505.24397v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>BioCLIP 2: Emergent Properties from Scaling Hierarchical Contrastive Learning</title>
      <link>http://arxiv.org/abs/2505.23883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://imageomics.github.io/bioclip-2/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究发现了在大规模训练的模型中存在显著的自发行为，这些行为超出了它们的初始训练目标。通过大规模对比视觉-语言训练，在生物视觉模型中发现了这种自发行为。&lt;h4&gt;背景&lt;/h4&gt;大规模训练的模型表现出超越初始训练目标的新能力。&lt;h4&gt;目的&lt;/h4&gt;通过大规模对比视觉-语言训练，在生物视觉模型中寻找自发行为。&lt;h4&gt;方法&lt;/h4&gt;首先构建了包含2.14亿张生物体图像的TreeOfLife-200M数据集，然后在该数据集上训练BioCLIP 2模型以区分不同物种。通过分析BioCLIP 2学习到的嵌入空间，研究了模型的自发特性。&lt;h4&gt;主要发现&lt;/h4&gt;BioCLIP 2在应用于各种生物视觉任务（如栖息地分类和特征预测）时表现出非凡的准确性。模型在不同物种的嵌入分布与功能生态意义（如喙的大小和栖息地）紧密相关。在物种内部，物种变异（如生命阶段和性别）在正交于物种区分的子空间中得到保留并更好地分离。通过形式证明和分析，解释了层次监督和对比目标如何促进这些自发特性。结果表明，随着训练数据规模的增加，这些特性变得越来越重要，导致一个具有生物学意义的嵌入空间。&lt;h4&gt;结论&lt;/h4&gt;大规模训练数据使得模型的自发特性变得更加重要，并形成了一个具有生物学意义的嵌入空间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models trained at scale exhibit remarkable emergent behaviors,learning new capabilities beyond their initial training objectives. We findsuch emergent behaviors in biological vision models via large-scale contrastivevision-language training. To achieve this, we first curate TreeOfLife-200M,comprising 214 million images of living organisms, the largest and most diversebiological organism image dataset to date. We then train BioCLIP 2 onTreeOfLife-200M to distinguish different species. Despite the narrow trainingobjective, BioCLIP 2 yields extraordinary accuracy when applied to variousbiological visual tasks such as habitat classification and trait prediction. Weidentify emergent properties in the learned embedding space of BioCLIP 2. Atthe inter-species level, the embedding distribution of different species alignsclosely with functional and ecological meanings (e.g., beak sizes andhabitats). At the intra-species level, instead of being diminished, theintra-species variations (e.g., life stages and sexes) are preserved and betterseparated in subspaces orthogonal to inter-species distinctions. We provideformal proof and analyses to explain why hierarchical supervision andcontrastive objectives encourage these emergent properties. Crucially, ourresults reveal that these properties become increasingly significant withlarger-scale training data, leading to a biologically meaningful embeddingspace.</description>
      <author>example@mail.com (Jianyang Gu, Samuel Stevens, Elizabeth G Campolongo, Matthew J Thompson, Net Zhang, Jiaman Wu, Andrei Kopanev, Zheda Mai, Alexander E. White, James Balhoff, Wasila Dahdul, Daniel Rubenstein, Hilmar Lapp, Tanya Berger-Wolf, Wei-Lun Chao, Yu Su)</author>
      <guid isPermaLink="false">2505.23883v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection</title>
      <link>http://arxiv.org/abs/2505.04594v4</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MonoCoP是一种基于链式预测的3D属性预测方法，旨在提高单目3D物体检测的准确性。&lt;h4&gt;背景&lt;/h4&gt;3D属性预测对于单目3D物体检测至关重要，但深度估计因2D图像到3D空间的映射模糊性而极具挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出MonoCoP方法，以改善3D属性预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;MonoCoP通过三个关键设计实现链式预测：1）使用轻量级AttributeNet（AN）学习每个3D属性的特征；2）构建显式链来传播这些特征；3）使用残差连接聚合链上每个属性的特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MonoCoP在KITTI排行榜上达到了最先进的性能，且无需额外数据，在Waymo和nuScenes frontal数据集上也优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;MonoCoP通过条件预测和特征传播显著提高了单目3D物体检测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately predicting 3D attributes is crucial for monocular 3D objectdetection (Mono3D), with depth estimation posing the greatest challenge due tothe inherent ambiguity in mapping 2D images to 3D space. While existing methodsleverage multiple depth cues (e.g., estimating depth uncertainty, modelingdepth error) to improve depth accuracy, they overlook that accurate depthprediction requires conditioning on other 3D attributes, as these attributesare intrinsically inter-correlated through the 3D to 2D projection, whichultimately limits overall accuracy and stability. Inspired by Chain-of-Thought(CoT) in large language models (LLMs), this paper proposes MonoCoP, whichleverages a Chain-of-Prediction (CoP) to predict attributes sequentially andconditionally via three key designs. First, it employs a lightweightAttributeNet (AN) for each 3D attribute to learn attribute-specific features.Next, MonoCoP constructs an explicit chain to propagate these learned featuresfrom one attribute to the next. Finally, MonoCoP uses a residual connection toaggregate features for each attribute along the chain, ensuring that laterattribute predictions are conditioned on all previously processed attributeswithout forgetting the features of earlier ones. Experimental results show thatour MonoCoP achieves state-of-the-art (SoTA) performance on the KITTIleaderboard without requiring additional data and further surpasses existingmethods on the Waymo and nuScenes frontal datasets.</description>
      <author>example@mail.com (Zhihao Zhang, Abhinav Kumar, Girish Chandar Ganesan, Xiaoming Liu)</author>
      <guid isPermaLink="false">2505.04594v4</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>VUDG: A Dataset for Video Understanding Domain Generalization</title>
      <link>http://arxiv.org/abs/2505.24346v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;视频理解领域近年来取得了显著进展，但现有工作往往忽视了实际应用中固有的领域迁移问题，导致领域泛化（DG）在视频理解中的研究不足。&lt;h4&gt;背景&lt;/h4&gt;视频理解领域近年来得益于深度模型的发展和大规模标注数据集的可用性取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;提出VideoUnderstanding Domain Generalization (VUDG)，一个专门设计用于评估视频理解中领域泛化性能的新型数据集。&lt;h4&gt;方法&lt;/h4&gt;VUDG包含来自11个不同领域的视频，涵盖三种类型的领域迁移，并保持不同领域间的语义相似性以确保公平且具有意义的评估。提出一个多专家渐进式标注框架，为每个视频标注多选题和开放式问答对。&lt;h4&gt;主要发现&lt;/h4&gt;在9个代表性的大型视频语言模型（LVLMs）和几种传统视频问答方法上进行的广泛实验表明，大多数模型（包括最先进的LVLMs）在领域迁移下会性能下降。&lt;h4&gt;结论&lt;/h4&gt;VUDG突显了领域迁移带来的挑战以及当前模型对数据分布变化的鲁棒性差异，认为VUDG为未来领域泛化视频理解研究提供了宝贵资源。&lt;h4&gt;翻译&lt;/h4&gt;Video understanding has made remarkable progress in recent years, largely driven by advances in deep models and the availability of large-scale annotated datasets. However, existing works typically ignore the inherent domain shifts encountered in real-world video applications, leaving domain generalization (DG) in video understanding underexplored. Hence, we propose VideoUnderstanding Domain Generalization (VUDG), a novel dataset designed specifically for evaluating the DG performance in video understanding. VUDG contains videos from 11 distinct domains that cover three types of domain shifts, and maintains semantic similarity across different domains to ensure fair and meaningful evaluation. We propose a multi-expert progressive annotation framework to annotate each video with both multiple-choice and open-ended question-answer pairs. Extensive experiments on 9 representative large video-language models (LVLMs) and several traditional video question-answering methods show that most models (including state-of-the-art LVLMs) suffer performance degradation under domain shifts. These results highlight the challenges posed by VUDG and the difference in the robustness of current models to data distribution shifts. We believe VUDG provides a valuable resource for prompting future research in domain generalization video understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video understanding has made remarkable progress in recent years, largelydriven by advances in deep models and the availability of large-scale annotateddatasets. However, existing works typically ignore the inherent domain shiftsencountered in real-world video applications, leaving domain generalization(DG) in video understanding underexplored. Hence, we propose VideoUnderstanding Domain Generalization (VUDG), a novel dataset designedspecifically for evaluating the DG performance in video understanding. VUDGcontains videos from 11 distinct domains that cover three types of domainshifts, and maintains semantic similarity across different domains to ensurefair and meaningful evaluation. We propose a multi-expert progressiveannotation framework to annotate each video with both multiple-choice andopen-ended question-answer pairs. Extensive experiments on 9 representativelarge video-language models (LVLMs) and several traditional video questionanswering methods show that most models (including state-of-the-art LVLMs)suffer performance degradation under domain shifts. These results highlight thechallenges posed by VUDG and the difference in the robustness of current modelsto data distribution shifts. We believe VUDG provides a valuable resource forprompting future research in domain generalization video understanding.</description>
      <author>example@mail.com (Ziyi Wang, Zhi Gao, Boxuan Yu, Zirui Dai, Yuxiang Song, Qingyuan Lu, Jin Chen, Xinxiao Wu)</author>
      <guid isPermaLink="false">2505.24346v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>LTM3D: Bridging Token Spaces for Conditional 3D Generation with Auto-Regressive Diffusion Framework</title>
      <link>http://arxiv.org/abs/2505.24245v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LTM3D的框架，用于条件3D形状生成，该框架结合了扩散模型和自回归模型的优点。&lt;h4&gt;背景&lt;/h4&gt;虽然基于扩散的方法在建模连续潜在空间方面有效，而自回归模型在捕捉词间依赖关系方面表现出色，但将这两种范式结合用于3D形状生成仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这个问题，LTM3D引入了条件分布建模骨干，利用掩码自动编码器和扩散模型来增强词依赖学习。&lt;h4&gt;方法&lt;/h4&gt;LTM3D还引入了前缀学习，这在生成过程中将条件词与形状潜在词对齐，提高了跨模态的灵活性。此外，还提出了一个潜在词重建模块，结合重建引导采样以减少不确定性并增强生成形状的结构保真度。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在操作于词空间的基础上，支持多种3D表示，包括符号距离场、点云、网格和3D高斯分层。在图像和文本条件形状生成任务上的大量实验表明，LTM3D在提示保真度和结构精度方面优于现有方法，并为多模态、多表示的3D生成提供了一个通用的框架。&lt;h4&gt;结论&lt;/h4&gt;LTM3D是一种高效且通用的3D形状生成方法，它在多个方面都优于现有的技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present LTM3D, a Latent Token space Modeling framework for conditional 3Dshape generation that integrates the strengths of diffusion and auto-regressive(AR) models. While diffusion-based methods effectively model continuous latentspaces and AR models excel at capturing inter-token dependencies, combiningthese paradigms for 3D shape generation remains a challenge. To address this,LTM3D features a Conditional Distribution Modeling backbone, leveraging amasked autoencoder and a diffusion model to enhance token dependency learning.Additionally, we introduce Prefix Learning, which aligns condition tokens withshape latent tokens during generation, improving flexibility across modalities.We further propose a Latent Token Reconstruction module withReconstruction-Guided Sampling to reduce uncertainty and enhance structuralfidelity in generated shapes. Our approach operates in token space, enablingsupport for multiple 3D representations, including signed distance fields,point clouds, meshes, and 3D Gaussian Splatting. Extensive experiments onimage- and text-conditioned shape generation tasks demonstrate that LTM3Doutperforms existing methods in prompt fidelity and structural accuracy whileoffering a generalizable framework for multi-modal, multi-representation 3Dgeneration.</description>
      <author>example@mail.com (Xin Kang, Zihan Zheng, Lei Chu, Yue Gao, Jiahao Li, Hao Pan, Xuejin Chen, Yan Lu)</author>
      <guid isPermaLink="false">2505.24245v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>DisTime: Distribution-based Time Representation for Video Large Language Models</title>
      <link>http://arxiv.org/abs/2505.24329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了DisTime，一个旨在提高视频大型语言模型（Video-LLMs）时间理解的轻量级框架，并通过实验证明其在时间敏感任务中取得了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管在视频理解方面取得了进展，但Video-LLMs在精确时间定位上面临挑战，这是由于离散时间表示和有限的时间感知数据集造成的。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，DisTime旨在增强Video-LLMs的时间理解能力。&lt;h4&gt;方法&lt;/h4&gt;DisTime使用一个可学习的标记来创建连续的时间嵌入空间，并采用基于分布的时间解码器生成时间概率分布，以减轻边界模糊性并保持时间连续性。此外，它还重新编码时间戳，为Video-LLMs提供时间标记。为了克服现有数据集中时间粒度的限制，论文提出了一种结合Video-LLMs的标题能力和专门时间模型的定位专家的自动化标注范式。&lt;h4&gt;主要发现&lt;/h4&gt;DisTime在三个时间敏感任务中的基准测试中实现了最先进的性能，同时在视频问答任务中保持了有竞争力的性能。InternVid-TG是一个包含1.25M时间标记事件的庞大数据集，覆盖179k个视频，是ActivityNet-Caption的55倍。&lt;h4&gt;结论&lt;/h4&gt;DisTime框架在视频-LLMs的时间理解方面取得了显著成果，并通过实验验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;尽管在视频理解方面取得了进展，但视频大型语言模型（Video-LLMs）由于离散时间表示和有限的时间感知数据集，在精确时间定位方面面临挑战。为了解决这些问题，我们引入了DisTime，一个旨在增强视频-LLMs时间理解的轻量级框架。DisTime使用一个可学习的标记创建连续的时间嵌入空间，并采用基于分布的时间解码器生成时间概率分布，有效地减轻了边界模糊性并保持了时间连续性。此外，基于分布的时间编码器重新编码时间戳，为视频-LLMs提供时间标记。为了克服现有数据集中时间粒度的限制，我们提出了一种结合视频-LLMs的标题能力和专门时间模型的定位专家的自动化标注范式。这导致了InternVid-TG的创建，一个包含1.25M时间标记事件的庞大数据集，覆盖179k个视频，是ActivityNet-Caption的55倍。广泛的实验表明，DisTime在三个时间敏感任务中的基准测试中实现了最先进的性能，同时在视频问答任务中保持了有竞争力的性能。代码和数据发布在https://github.com/josephzpng/DisTime。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite advances in general video understanding, Video Large Language Models(Video-LLMs) face challenges in precise temporal localization due to discretetime representations and limited temporally aware datasets. Existing methodsfor temporal expression either conflate time with text-based numerical values,add a series of dedicated temporal tokens, or regress time using specializedtemporal grounding heads. To address these issues, we introduce DisTime, alightweight framework designed to enhance temporal comprehension in Video-LLMs.DisTime employs a learnable token to create a continuous temporal embeddingspace and incorporates a Distribution-based Time Decoder that generatestemporal probability distributions, effectively mitigating boundary ambiguitiesand maintaining temporal continuity. Additionally, the Distribution-based TimeEncoder re-encodes timestamps to provide time markers for Video-LLMs. Toovercome temporal granularity limitations in existing datasets, we propose anautomated annotation paradigm that combines the captioning capabilities ofVideo-LLMs with the localization expertise of dedicated temporal models. Thisleads to the creation of InternVid-TG, a substantial dataset with 1.25Mtemporally grounded events across 179k videos, surpassing ActivityNet-Captionby 55 times. Extensive experiments demonstrate that DisTime achievesstate-of-the-art performance across benchmarks in three time-sensitive taskswhile maintaining competitive performance in Video QA tasks. Code and data arereleased at https://github.com/josephzpng/DisTime.</description>
      <author>example@mail.com (Yingsen Zeng, Zepeng Huang, Yujie Zhong, Chengjian Feng, Jie Hu, Lin Ma, Yang Liu)</author>
      <guid isPermaLink="false">2505.24329v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Geospatial Foundation Models to Enable Progress on Sustainable Development Goals</title>
      <link>http://arxiv.org/abs/2505.24528v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SustainFM是一个基于17个可持续发展目标的多任务基准测试框架，用于评估地理空间领域的大型预训练AI系统（FMs）在解决复杂可持续发展挑战中的作用。&lt;h4&gt;背景&lt;/h4&gt;FMs在自然语言处理和计算机视觉领域取得了革命性的进步，现在正被应用于地理空间分析和地球观测。尽管如此，这些模型在现实世界中的效用及其与全球可持续发展目标的契合度尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;引入SustainFM框架，以全面评估地理空间FMs，并探讨其在实现可持续发展目标中的作用。&lt;h4&gt;方法&lt;/h4&gt;SustainFM涵盖了从资产财富预测到环境灾害检测的多种任务，为地理空间FMs提供了一项严格的跨学科评估。&lt;h4&gt;主要发现&lt;/h4&gt;1. FMs在多种任务和数据集上通常优于传统方法，但并非在所有情况下都占优势。2. 评估FMs时，应考虑转移性、泛化能力和能源效率等关键指标。3. FMs能够提供基于可持续发展目标的可扩展解决方案，有助于解决复杂挑战。&lt;h4&gt;结论&lt;/h4&gt;提倡从以模型为中心的开发转向以影响驱动的部署，并强调能源效率、对领域变化的鲁棒性和伦理考虑等指标。&lt;h4&gt;翻译&lt;/h4&gt;Foundation Models (FMs) are large-scale, pre-trained AI systems that have revolutionized natural language processing and computer vision, and are now advancing geospatial analysis and Earth Observation (EO). They promise improved generalization across tasks, scalability, and efficient adaptation with minimal labeled data. However, despite the rapid proliferation of geospatial FMs, their real-world utility and alignment with global sustainability goals remain underexplored. We introduce SustainFM, a comprehensive benchmarking framework grounded in the 17 Sustainable Development Goals with extremely diverse tasks ranging from asset wealth prediction to environmental hazard detection. This study provides a rigorous, interdisciplinary assessment of geospatial FMs and offers critical insights into their role in attaining sustainability goals. Our findings show: (1) While not universally superior, FMs often outperform traditional approaches across diverse tasks and datasets. (2) Evaluating FMs should go beyond accuracy to include transferability, generalization, and energy efficiency as key criteria for their responsible use. (3) FMs enable scalable, SDG-grounded solutions, offering broad utility for tackling complex sustainability challenges. Critically, we advocate for a paradigm shift from model-centric development to impact-driven deployment, and emphasize metrics such as energy efficiency, robustness to domain shifts, and ethical considerations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation Models (FMs) are large-scale, pre-trained AI systems that haverevolutionized natural language processing and computer vision, and are nowadvancing geospatial analysis and Earth Observation (EO). They promise improvedgeneralization across tasks, scalability, and efficient adaptation with minimallabeled data. However, despite the rapid proliferation of geospatial FMs, theirreal-world utility and alignment with global sustainability goals remainunderexplored. We introduce SustainFM, a comprehensive benchmarking frameworkgrounded in the 17 Sustainable Development Goals with extremely diverse tasksranging from asset wealth prediction to environmental hazard detection. Thisstudy provides a rigorous, interdisciplinary assessment of geospatial FMs andoffers critical insights into their role in attaining sustainability goals. Ourfindings show: (1) While not universally superior, FMs often outperformtraditional approaches across diverse tasks and datasets. (2) Evaluating FMsshould go beyond accuracy to include transferability, generalization, andenergy efficiency as key criteria for their responsible use. (3) FMs enablescalable, SDG-grounded solutions, offering broad utility for tackling complexsustainability challenges. Critically, we advocate for a paradigm shift frommodel-centric development to impact-driven deployment, and emphasize metricssuch as energy efficiency, robustness to domain shifts, and ethicalconsiderations.</description>
      <author>example@mail.com (Pedram Ghamisi, Weikang Yu, Xiaokang Zhang, Aldino Rizaldy, Jian Wang, Chufeng Zhou, Richard Gloaguen, Gustau Camps-Valls)</author>
      <guid isPermaLink="false">2505.24528v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Point-MoE: Towards Cross-Domain Generalization in 3D Semantic Segmentation via Mixture-of-Experts</title>
      <link>http://arxiv.org/abs/2505.23926v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://uva-computer-vision-lab.github.io/point-moe/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Point-MoE，一种混合专家架构，旨在实现大规模、跨域泛化的3D感知。&lt;h4&gt;背景&lt;/h4&gt;3D点云理解尚未达到自然语言处理和计算机视觉的水平，这归因于3D数据集规模较小以及数据来源的多样性。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，使模型能够在没有领域标签的情况下自动专业化，并在大规模跨域数据上训练统一模型。&lt;h4&gt;方法&lt;/h4&gt;Point-MoE通过简单的top-k路由策略，能够在混合领域数据上自动专业化专家。&lt;h4&gt;主要发现&lt;/h4&gt;Point-MoE在性能上优于强大的多域基线，并且能够更好地泛化到未见过的领域。&lt;h4&gt;结论&lt;/h4&gt;Point-MoE为3D理解提供了一个可扩展的前进路径，即让模型在多样化的3D数据中发现结构，而不是通过手动编纂或领域监督来强加结构。&lt;h4&gt;翻译&lt;/h4&gt;尽管扩展定律已经改变了自然语言处理和计算机视觉，但3D点云理解尚未达到这一阶段。这可以归因于3D数据集相对较小的规模以及数据本身的多样化来源。点云由不同的传感器（例如，深度相机、激光雷达）在多个领域（例如，室内、室外）捕获，每个领域都引入了独特的扫描模式、采样密度和语义偏差。这种领域异质性是训练大规模统一模型的主要障碍，尤其是在领域标签通常在推理时间不可访问的现实约束下。在这项工作中，我们提出了Point-MoE，这是一种混合专家架构，旨在实现大规模、跨域泛化的3D感知。我们发现，当在混合领域数据上训练时，标准的点云骨干网络在性能上显著下降，而具有简单top-k路由策略的Point-MoE可以自动专业化专家，即使没有访问领域标签。我们的实验表明，Point-MoE不仅优于强大的多域基线，而且能够更好地泛化到未见过的领域。这项工作强调了3D理解的一个可扩展的前进路径：让模型在多样化的3D数据中发现结构，而不是通过手动编纂或领域监督来强加结构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While scaling laws have transformed natural language processing and computervision, 3D point cloud understanding has yet to reach that stage. This can beattributed to both the comparatively smaller scale of 3D datasets, as well asthe disparate sources of the data itself. Point clouds are captured by diversesensors (e.g., depth cameras, LiDAR) across varied domains (e.g., indoor,outdoor), each introducing unique scanning patterns, sampling densities, andsemantic biases. Such domain heterogeneity poses a major barrier towardstraining unified models at scale, especially under the realistic constraintthat domain labels are typically inaccessible at inference time. In this work,we propose Point-MoE, a Mixture-of-Experts architecture designed to enablelarge-scale, cross-domain generalization in 3D perception. We show thatstandard point cloud backbones degrade significantly in performance whentrained on mixed-domain data, whereas Point-MoE with a simple top-k routingstrategy can automatically specialize experts, even without access to domainlabels. Our experiments demonstrate that Point-MoE not only outperforms strongmulti-domain baselines but also generalizes better to unseen domains. This workhighlights a scalable path forward for 3D understanding: letting the modeldiscover structure in diverse 3D data, rather than imposing it via manualcuration or domain supervision.</description>
      <author>example@mail.com (Xuweiyi Chen, Wentao Zhou, Aruni RoyChowdhury, Zezhou Cheng)</author>
      <guid isPermaLink="false">2505.23926v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Threading Keyframe with Narratives: MLLMs as Strong Long Video Comprehenders</title>
      <link>http://arxiv.org/abs/2505.24158v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Nar-KFC的模块，用于有效地处理长视频理解问题，该问题由于视频帧数量与语言模型上下文长度限制之间的矛盾而具有挑战性。&lt;h4&gt;背景&lt;/h4&gt;长视频理解面临挑战，因为视频帧数量庞大，而语言模型的上下文长度有限。传统的均匀采样可能导致选择无关内容，而训练后的模型在处理数千帧时计算负担沉重。&lt;h4&gt;目的&lt;/h4&gt;提出Nar-KFC模块，以促进长视频的有效和高效感知。&lt;h4&gt;方法&lt;/h4&gt;Nar-KFC包括两个协作步骤：首先，将关键帧选择过程定义为整数二次规划问题，联合优化查询相关性和帧多样性；其次，为了减轻稀疏关键帧采样引起的时序不连续性，引入了由非关键帧生成的交错文本叙述，并基于其真实时序插入到关键帧之间。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Nar-KFC显著提高了流行MLLMs在多个长视频基准测试中的性能。&lt;h4&gt;结论&lt;/h4&gt;Nar-KFC作为一种时间和内容感知的压缩策略，能够补充视觉和文本模态，为长视频理解提供了一种有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于视频帧（即视觉标记）数量庞大与语言模型上下文长度有限之间的矛盾，使用多模态大型语言模型（MLLMs）进行长视频理解仍然是一个具有挑战性的问题。传统的均匀采样往往导致选择无关内容，而在数千帧上对MLLMs进行后训练则带来了巨大的计算负担。在本文中，我们提出了一个名为Nar-KFC的即插即用模块，以促进长视频感知的有效性和效率。Nar-KFC通常涉及两个协作步骤。首先，我们将关键帧选择过程定义为整数二次规划问题，联合优化查询相关性和帧多样性。为了避免其计算复杂性，设计了一种定制的贪婪搜索策略作为高效的替代方案。其次，为了减轻由稀疏关键帧采样引起的时序不连续性，我们进一步引入了由现成的字幕生成器生成的交错文本叙述。这些叙述根据其真实时序插入到关键帧之间，形成了一种连贯紧凑的表示。因此，Nar-KFC作为一种时间和内容感知的压缩策略，补充了视觉和文本模态。在多个长视频基准测试上的实验结果表明，Nar-KFC显著提高了流行MLLMs的性能。代码将公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Employing Multimodal Large Language Models (MLLMs) for long videounderstanding remains a challenging problem due to the dilemma between thesubstantial number of video frames (i.e., visual tokens) versus the limitedcontext length of language models. Traditional uniform sampling often leads toselection of irrelevant content, while post-training MLLMs on thousands offrames imposes a substantial computational burden. In this paper, we proposethreading keyframes with narratives (Nar-KFC), a plug-and-play module tofacilitate effective and efficient long video perception. Nar-KFC generallyinvolves two collaborative steps. First, we formulate the keyframe selectionprocess as an integer quadratic programming problem, jointly optimizingquery-relevance and frame-diversity. To avoid its computational complexity, acustomized greedy search strategy is designed as an efficient alternative.Second, to mitigate the temporal discontinuity caused by sparse keyframesampling, we further introduce interleaved textual narratives generated fromnon-keyframes using off-the-shelf captioners. These narratives are insertedbetween keyframes based on their true temporal order, forming a coherent andcompact representation. Nar-KFC thus serves as a temporal- and content-awarecompression strategy that complements visual and textual modalities.Experimental results on multiple long-video benchmarks demonstrate that Nar-KFCsignificantly improves the performance of popular MLLMs. Code will be madepublicly available.</description>
      <author>example@mail.com (Bo Fang, Wenhao Wu, Qiangqiang Wu, Yuxin Song, Antoni B. Chan)</author>
      <guid isPermaLink="false">2505.24158v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>un$^2$CLIP: Improving CLIP's Visual Detail Capturing Ability via Inverting unCLIP</title>
      <link>http://arxiv.org/abs/2505.24517v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种改进的CLIP模型，名为un$^2$CLIP，旨在通过结合生成模型unCLIP的特性来提升CLIP在图像细节捕捉方面的能力。&lt;h4&gt;背景&lt;/h4&gt;CLIP作为基础模型在视觉和跨模态任务中应用广泛，但最近的研究表明其在图像细节区分和密集预测任务上的表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提高现有CLIP模型，使其能够捕捉更多图像细节。&lt;h4&gt;方法&lt;/h4&gt;采用生成模型unCLIP，该模型基于CLIP图像嵌入训练图像生成器，即逆CLIP图像编码器。un$^2$CLIP旨在通过结合unCLIP的图像细节捕捉能力和CLIP的文本编码器保持一致性来改进CLIP模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，un$^2$CLIP在多个任务上显著提升了CLIP的性能，包括MMVP-VLM基准、密集预测开放词汇分割任务和多模态大型语言模型任务。&lt;h4&gt;结论&lt;/h4&gt;un$^2$CLIP是一个有效的改进方案，能够提高CLIP在图像细节捕捉方面的能力。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive Language-Image Pre-training (CLIP) has become a foundation model and has been applied to various vision and multimodal tasks. However, recent works indicate that CLIP falls short in distinguishing detailed differences in images and shows suboptimal performance on dense-prediction and vision-centric multimodal tasks. Therefore, this work focuses on improving existing CLIP models, aiming to capture as many visual details in images as possible. We find that a specific type of generative models, unCLIP, provides a suitable framework for achieving our goal. Specifically, unCLIP trains an image generator conditioned on the CLIP image embedding. In other words, it inverts the CLIP image encoder. Compared to discriminative models like CLIP, generative models are better at capturing image details because they are trained to learn the data distribution of images. Additionally, the conditional input space of unCLIP aligns with CLIP's original image-text embedding space. Therefore, we propose to invert unCLIP (dubbed un$^2$CLIP) to improve the CLIP model. In this way, the improved image encoder can gain unCLIP's visual detail capturing ability while preserving its alignment with the original text encoder simultaneously. We evaluate our improved CLIP across various tasks to which CLIP has been applied, including the challenging MMVP-VLM benchmark, the dense-prediction open-vocabulary segmentation task, and multimodal large language model tasks. Experiments show that un$^2$CLIP significantly improves the original CLIP and previous CLIP improvement methods. Code and models will be available at https://github.com/LiYinqi/un2CLIP.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive Language-Image Pre-training (CLIP) has become a foundation modeland has been applied to various vision and multimodal tasks. However, recentworks indicate that CLIP falls short in distinguishing detailed differences inimages and shows suboptimal performance on dense-prediction and vision-centricmultimodal tasks. Therefore, this work focuses on improving existing CLIPmodels, aiming to capture as many visual details in images as possible. We findthat a specific type of generative models, unCLIP, provides a suitableframework for achieving our goal. Specifically, unCLIP trains an imagegenerator conditioned on the CLIP image embedding. In other words, it invertsthe CLIP image encoder. Compared to discriminative models like CLIP, generativemodels are better at capturing image details because they are trained to learnthe data distribution of images. Additionally, the conditional input space ofunCLIP aligns with CLIP's original image-text embedding space. Therefore, wepropose to invert unCLIP (dubbed un$^2$CLIP) to improve the CLIP model. In thisway, the improved image encoder can gain unCLIP's visual detail capturingability while preserving its alignment with the original text encodersimultaneously. We evaluate our improved CLIP across various tasks to whichCLIP has been applied, including the challenging MMVP-VLM benchmark, thedense-prediction open-vocabulary segmentation task, and multimodal largelanguage model tasks. Experiments show that un$^2$CLIP significantly improvesthe original CLIP and previous CLIP improvement methods. Code and models willbe available at https://github.com/LiYinqi/un2CLIP.</description>
      <author>example@mail.com (Yinqi Li, Jiahe Zhao, Hong Chang, Ruibing Hou, Shiguang Shan, Xilin Chen)</author>
      <guid isPermaLink="false">2505.24517v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Multi-RAG: A Multimodal Retrieval-Augmented Generation System for Adaptive Video Understanding</title>
      <link>http://arxiv.org/abs/2505.23990v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Multi-RAG的多模态检索增强生成系统，旨在为人类在信息密集型环境中提供适应性辅助，以减轻认知负担并提高情境理解。&lt;h4&gt;背景&lt;/h4&gt;随着机器人和智能代理在人类生活中的日益融合，人类需要将认知负担转移到这些系统，特别是在动态、信息丰富的场景中。&lt;h4&gt;目的&lt;/h4&gt;Multi-RAG旨在通过整合和推理来自视频、音频和文本等多源信息流，提高情境理解并减少认知负荷。&lt;h4&gt;方法&lt;/h4&gt;Multi-RAG探索了多模态信息理解如何在动态、以人为中心的情境中为适应性机器人辅助提供基础，并在MMBench-Video数据集上进行了基准测试，以评估其实际应用能力。&lt;h4&gt;主要发现&lt;/h4&gt;Multi-RAG在MMBench-Video数据集上表现出色，与现有的开源视频大型语言模型（Video-LLMs）和大型视觉语言模型（LVLMs）相比，其性能更优，同时资源消耗更少，输入数据更少。&lt;h4&gt;结论&lt;/h4&gt;Multi-RAG有潜力成为未来动态、真实世界情境中人类-机器人适应性辅助系统的实用和高效基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：为了有效地参与人类社会，适应、过滤信息和在不断变化的情况下做出明智决策的能力至关重要。随着机器人和智能代理越来越多地融入人类生活，人类有越来越多的机会和需要将认知负担转移到这些系统，尤其是在动态、信息丰富的场景中。为了满足这一关键需求，我们提出了Multi-RAG，一个多模态检索增强生成系统，旨在为人类在信息密集型环境中提供适应性辅助。我们的系统旨在通过整合和推理来自视频、音频和文本等多源信息流，提高情境理解并减少认知负荷。作为长期人-机器人伙伴关系的一个促成步骤，Multi-RAG探讨了多模态信息理解如何作为动态、以人为中心的情境中适应性机器人辅助的基础。为了评估其在实际人助代理任务中的能力，我们在MMBench-Video数据集上对Multi-RAG进行了基准测试，这是一个具有挑战性的多模态视频理解基准。与现有的开源视频大型语言模型（Video-LLMs）和大型视觉语言模型（LVLMs）相比，我们的系统实现了更优的性能，同时资源消耗更少，输入数据更少。结果表明，Multi-RAG在动态、真实世界情境中作为未来人类-机器人适应性辅助系统的实用和高效基础具有潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To effectively engage in human society, the ability to adapt, filterinformation, and make informed decisions in ever-changing situations iscritical. As robots and intelligent agents become more integrated into humanlife, there is a growing opportunity-and need-to offload the cognitive burdenon humans to these systems, particularly in dynamic, information-richscenarios.  To fill this critical need, we present Multi-RAG, a multimodalretrieval-augmented generation system designed to provide adaptive assistanceto humans in information-intensive circumstances. Our system aims to improvesituational understanding and reduce cognitive load by integrating andreasoning over multi-source information streams, including video, audio, andtext. As an enabling step toward long-term human-robot partnerships, Multi-RAGexplores how multimodal information understanding can serve as a foundation foradaptive robotic assistance in dynamic, human-centered situations. To evaluateits capability in a realistic human-assistance proxy task, we benchmarkedMulti-RAG on the MMBench-Video dataset, a challenging multimodal videounderstanding benchmark. Our system achieves superior performance compared toexisting open-source video large language models (Video-LLMs) and largevision-language models (LVLMs), while utilizing fewer resources and less inputdata. The results demonstrate Multi- RAG's potential as a practical andefficient foundation for future human-robot adaptive assistance systems indynamic, real-world contexts.</description>
      <author>example@mail.com (Mingyang Mao, Mariela M. Perez-Cabarcas, Utteja Kallakuri, Nicholas R. Waytowich, Xiaomin Lin, Tinoosh Mohsenin)</author>
      <guid isPermaLink="false">2505.23990v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Object Centric Concept Bottlenecks</title>
      <link>http://arxiv.org/abs/2505.24492v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了Object-Centric Concept Bottlenecks（OCB）框架，旨在解决现代AI中高表现力和可解释性模型的发展难题。&lt;h4&gt;背景&lt;/h4&gt;高表现力和可解释性模型在AI中是一个关键挑战。概念化模型（CBMs）试图通过从全局编码（如图像编码）中提取人类可理解的概念，然后对概念激活应用线性分类器，以实现透明的决策来解决这一挑战。&lt;h4&gt;目的&lt;/h4&gt;为了克服CBMs在对象中心现实世界设置中的表现力限制，论文旨在提升复杂视觉任务的处理能力。&lt;h4&gt;方法&lt;/h4&gt;OCB框架结合了CBMs和预训练的对象中心基础模型的优势，并通过评估OCB在复杂图像数据集上的表现以及进行消融研究来分析框架的关键组件，如聚合对象-概念编码的策略。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果证明了OCB优于传统的CBMs，并允许对复杂视觉任务进行可解释的决策。&lt;h4&gt;结论&lt;/h4&gt;OCB框架能够提升模型性能和可解释性，是解决现代AI中高表现力和可解释性模型挑战的有效方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing high-performing, yet interpretable models remains a criticalchallenge in modern AI. Concept-based models (CBMs) attempt to address this byextracting human-understandable concepts from a global encoding (e.g., imageencoding) and then applying a linear classifier on the resulting conceptactivations, enabling transparent decision-making. However, their reliance onholistic image encodings limits their expressiveness in object-centricreal-world settings and thus hinders their ability to solve complex visiontasks beyond single-label classification. To tackle these challenges, weintroduce Object-Centric Concept Bottlenecks (OCB), a framework that combinesthe strengths of CBMs and pre-trained object-centric foundation models,boosting performance and interpretability. We evaluate OCB on complex imagedatasets and conduct a comprehensive ablation study to analyze key componentsof the framework, such as strategies for aggregating object-concept encodings.The results show that OCB outperforms traditional CBMs and allows one to makeinterpretable decisions for complex visual tasks.</description>
      <author>example@mail.com (David Steinmann, Wolfgang Stammer, Antonia Wüst, Kristian Kersting)</author>
      <guid isPermaLink="false">2505.24492v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Multilingual Gloss-free Sign Language Translation: Towards Building a Sign Language Foundation Model</title>
      <link>http://arxiv.org/abs/2505.24355v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种用于手语翻译的多语言无词模型，旨在解决跨语言资源利用问题，提高手语与口语之间的沟通。&lt;h4&gt;背景&lt;/h4&gt;现有的手语翻译研究主要集中于单一手语到单一口语的翻译，而多语言手语翻译（MLSLT）因语言冲突和对齐困难而未被充分探索。&lt;h4&gt;目的&lt;/h4&gt;通过提出一种多语言无词模型，缓解低资源问题，并提高手语翻译的可用性。&lt;h4&gt;方法&lt;/h4&gt;该模型采用双重CTC目标，针对符号级手语识别和口语文本生成，支持10种手语，并能够处理一对一、多对一和多对多的手语翻译任务。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在三个广泛使用的基准测试（multilingual SP-10、PHOENIX14T和CSL-Daily）上实现了与现有方法相当的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的模型为多语言手语翻译提供了一种有效的方法，有望改善手语与口语社区之间的沟通。&lt;h4&gt;翻译&lt;/h4&gt;手语翻译（SLT）旨在将手语（SL）视频转换为口语文本，从而弥合手语与口语社区之间的沟通差距。虽然大多数现有工作集中于将单一手语翻译成单一口语（一对一SLT），但利用多语言资源可以缓解低资源问题并提高可用性。然而，由于手语和口语之间的语言冲突和对齐困难，多语言手语翻译（MLSLT）仍然未被充分探索。为了解决这些挑战，我们提出了一种具有双重CTC目标的多语言无词模型，用于符号级手语识别和口语文本生成。我们的模型支持10种手语，并处理一对一、多对一和多对多的SLT任务，在三个广泛采用的基准测试（multilingual SP-10、PHOENIX14T和CSL-Daily）上与最先进的方法相比实现了有竞争力的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sign Language Translation (SLT) aims to convert sign language (SL) videosinto spoken language text, thereby bridging the communication gap between thesign and the spoken community. While most existing works focus on translating asingle sign language into a single spoken language (one-to-one SLT), leveragingmultilingual resources could mitigate low-resource issues and enhanceaccessibility. However, multilingual SLT (MLSLT) remains unexplored due tolanguage conflicts and alignment difficulties across SLs and spoken languages.To address these challenges, we propose a multilingual gloss-free model withdual CTC objectives for token-level SL identification and spoken textgeneration. Our model supports 10 SLs and handles one-to-one, many-to-one, andmany-to-many SLT tasks, achieving competitive performance compared tostate-of-the-art methods on three widely adopted benchmarks: multilingualSP-10, PHOENIX14T, and CSL-Daily.</description>
      <author>example@mail.com (Sihan Tan, Taro Miyazaki, Kazuhiro Nakadai)</author>
      <guid isPermaLink="false">2505.24355v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Hybrid-Graph Neural Network Method for Muon Fast Reconstruction in Neutrino Telescopes</title>
      <link>http://arxiv.org/abs/2505.23425v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对μ子轨迹重建的高效混合图神经网络（GNN）方法，旨在提高中微子望远镜的实验灵敏度和在线触发能力。&lt;h4&gt;背景&lt;/h4&gt;快速且精确的μ子重建对于中微子望远镜至关重要。&lt;h4&gt;目的&lt;/h4&gt;提高中微子望远镜的实验灵敏度和实现在线触发。&lt;h4&gt;方法&lt;/h4&gt;采用混合图神经网络（GNN）方法，结合了GNN的鲁棒性和传统的基于物理的方法，实现了高效的μ子轨迹重建。&lt;h4&gt;主要发现&lt;/h4&gt;LITE GNN模型在GPU上的运行时间仅为0.19-0.29毫秒/事件，比传统基于似然的方法快三个数量级，同时保持了高重建精度。对于高能μ子（10-100 TeV），中值角误差约为0.1度，重建的切伦科夫光子发射位置误差在3-5米以下。Semi-GNN方法提供了一种评估事件重建质量的方法，能够识别和排除重建质量较差的事件。&lt;h4&gt;结论&lt;/h4&gt;基于GNN的方法被证明是下一代中微子望远镜数据重建的有希望的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a Hybrid-Graph Neural Network (GNN) method tailored for efficient muon track reconstruction, leveraging the robustness of GNNs alongside traditional physics-based approaches. The 'LITE GNN model' achieves a runtime of 0.19-0.29 ms per event on GPUs, offering a three orders of magnitude speedup compared to traditional likelihood-based methods while maintaining a high reconstruction accuracy. For high-energy muons (10-100 TeV), the median angular error is approximately 0.1 degrees, with errors in reconstructed Cherenkov photon emission positions being below 3-5 meters, depending on the GNN model used. Furthermore, the Semi-GNN method offers a mechanism to assess the quality of event reconstruction, enabling the identification and exclusion of poorly reconstructed events. These results establish the GNN-based approach as a promising solution for next-generation neutrino telescope data reconstruction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fast and accurate muon reconstruction is crucial for neutrino telescopes toimprove experimental sensitivity and enable online triggering. This paperintroduces a Hybrid-Graph Neural Network (GNN) method tailored for efficientmuon track reconstruction, leveraging the robustness of GNNs alongsidetraditional physics-based approaches. The "LITE GNN model" achieves a runtimeof 0.19-0.29 ms per event on GPUs, offering a three orders of magnitude speedupcompared to traditional likelihood-based methods while maintaining a highreconstruction accuracy. For high-energy muons (10-100 TeV), the median angularerror is approximately 0.1 degrees, with errors in reconstructed Cherenkovphoton emission positions being below 3-5 meters, depending on the GNN modelused. Furthermore, the Semi-GNN method offers a mechanism to assess the qualityof event reconstruction, enabling the identification and exclusion of poorlyreconstructed events. These results establish the GNN-based approach as apromising solution for next-generation neutrino telescope data reconstruction.</description>
      <author>example@mail.com (Cen Mo, Liang Li)</author>
      <guid isPermaLink="false">2505.23425v2</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>ScaleLong: A Multi-Timescale Benchmark for Long Video Understanding</title>
      <link>http://arxiv.org/abs/2505.23922v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ScaleLong的新基准，用于评估长视频理解模型在多时间尺度上的性能，通过在同一视频内容中嵌入针对不同时间尺度（秒、十几秒、分钟、小时）的问题，实现了对模型性能的直接比较。&lt;h4&gt;背景&lt;/h4&gt;现有的长视频理解基准要么忽略了多尺度设计，要么在不同视频中分散处理特定时间尺度的问题，这阻碍了模型性能在不同时间尺度上的直接比较。&lt;h4&gt;目的&lt;/h4&gt;解决现有基准中存在的问题，通过ScaleLong基准实现模型在不同时间尺度上的性能直接比较。&lt;h4&gt;方法&lt;/h4&gt;ScaleLong基准包含来自5个主要类别和36个子类别的269个长视频（平均长度86分钟），每个视频包含4-8个精心设计的问题，至少包含一个问题针对每个时间尺度。&lt;h4&gt;主要发现&lt;/h4&gt;评估了23个多模态语言模型（MLLM），发现性能曲线呈U形，在最长和最短时间尺度上准确率较高，而在中间水平上有所下降。消融研究表明，增加视觉标记容量可以一致地增强所有时间尺度上的推理能力。&lt;h4&gt;结论&lt;/h4&gt;ScaleLong提供了一个细粒度、多时间尺度的基准，以推进MLLM在长视频理解方面的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管长视频理解要求模型捕捉从片段（秒）到镜头（十几秒）、事件（分钟）和故事（小时）的层次时间信息，但现有的基准要么忽略了这种多尺度设计，要么将特定时间尺度的问题分散在不同的视频中，这阻碍了在同一内容上对模型性能在不同时间尺度上的直接比较。为了解决这个问题，我们引入了ScaleLong，这是第一个通过在同一视频内容中嵌入针对四个层次时间尺度（片段、镜头、事件和故事）的问题来解耦这些因素的基准。这种内容内多时间尺度提问设计使得可以直接比较相同视频在不同时间尺度上的模型性能。ScaleLong包含269个长视频（平均长度86分钟），来自5个主要类别和36个子类别，每个视频有4-8个精心设计的问题，每个时间尺度至少有一个问题。评估了23个MLLM，发现性能曲线呈U形，在最长和最短时间尺度上准确率较高，在中间水平上有所下降。此外，消融研究表明，增加视觉标记容量可以一致地增强所有时间尺度上的推理能力。ScaleLong提供了一个精细的多时间尺度基准，以推进MLLM在长视频理解方面的能力。代码和数据集可在https://github.com/multimodal-art-projection/ScaleLong获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although long-video understanding demands that models capture hierarchicaltemporal information -- from clip (seconds) and shot (tens of seconds) to event(minutes) and story (hours) -- existing benchmarks either neglect thismulti-scale design or scatter scale-specific questions across different videos,preventing direct comparison of model performance across timescales on the samecontent. To address this, we introduce ScaleLong, the first benchmark todisentangle these factors by embedding questions targeting four hierarchicaltimescales -- clip (seconds), shot (tens of seconds), event (minutes), andstory (hours) -- all within the same video content. This within-contentmulti-timescale questioning design enables direct comparison of modelperformance across timescales on identical videos. ScaleLong features 269 longvideos (avg.\ 86\,min) from 5 main categories and 36 sub-categories, with 4--8carefully designed questions, including at least one question for eachtimescale. Evaluating 23 MLLMs reveals a U-shaped performance curve, withhigher accuracy at the shortest and longest timescales and a dip atintermediate levels. Furthermore, ablation studies show that increased visualtoken capacity consistently enhances reasoning across all timescales. ScaleLongoffers a fine-grained, multi-timescale benchmark for advancing MLLMcapabilities in long-video understanding. The code and dataset are availablehttps://github.com/multimodal-art-projection/ScaleLong.</description>
      <author>example@mail.com (David Ma, Huaqing Yuan, Xingjian Wang, Qianbo Zang, Tianci Liu, Xinyang He, Yanbin Wei, Jiawei Guo, Ni Jiahui, Zhenzhu Yang, Meng Cao, Shanghaoran Quan, Yizhi Li, Wangchunshu Zhou, Jiaheng Liu, Wenhao Huang, Ge Zhang, Shiwen Ni, Xiaojie Jin)</author>
      <guid isPermaLink="false">2505.23922v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>A Benchmark Dataset for Graph Regression with Homogeneous and Multi-Relational Variants</title>
      <link>http://arxiv.org/abs/2505.23875v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了RelSC，一个基于程序图的新的图回归数据集，该数据集通过源代码提取语法和语义信息，并提供了连续的目标变量。RelSC有两大变体：RelSC-H提供单一种类边的丰富节点特征，而RelSC-M保持原始的多关系结构。研究评估了多种图神经网络架构，发现结构表示的重要性，并证明了RelSC在推动图回归方法发展中的价值。&lt;h4&gt;背景&lt;/h4&gt;现有的图回归公共基准主要关注分子图和引用网络，缺乏多样性，限制了在多种图结构上泛化的模型发展。&lt;h4&gt;目的&lt;/h4&gt;提出RelSC数据集，用于评估和推动图回归方法在更广泛图结构上的性能。&lt;h4&gt;方法&lt;/h4&gt;从源代码中提取语法和语义信息构建程序图，并使用执行时间成本作为标签。RelSC提供两种变体：RelSC-H和RelSC-M。在两种变体上评估多种图神经网络架构。&lt;h4&gt;主要发现&lt;/h4&gt;在RelSC的不同变体上评估图神经网络架构时，发现同质和多层关系设置之间存在一致的性能差异，强调了结构表示的重要性。&lt;h4&gt;结论&lt;/h4&gt;RelSC作为一个具有挑战性和灵活性的基准，对于推进图回归方法具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-level regression underpins many real-world applications, yet publicbenchmarks remain heavily skewed toward molecular graphs and citation networks.This limited diversity hinders progress on models that must generalize acrossboth homogeneous and heterogeneous graph structures. We introduce RelSC, a newgraph-regression dataset built from program graphs that combine syntactic andsemantic information extracted from source code. Each graph is labelled withthe execution-time cost of the corresponding program, providing a continuoustarget variable that differs markedly from those found in existing benchmarks.RelSC is released in two complementary variants. RelSC-H supplies rich nodefeatures under a single (homogeneous) edge type, while RelSC-M preserves theoriginal multi-relational structure, connecting nodes through multiple edgetypes that encode distinct semantic relationships. Together, these variants letresearchers probe how representation choice influences model behaviour. Weevaluate a diverse set of graph neural network architectures on both variantsof RelSC. The results reveal consistent performance differences between thehomogeneous and multi-relational settings, emphasising the importance ofstructural representation. These findings demonstrate RelSC's value as achallenging and versatile benchmark for advancing graph regression methods.</description>
      <author>example@mail.com (Peter Samoaa, Marcus Vukojevic, Morteza Haghir Chehreghani, Antonio Longa)</author>
      <guid isPermaLink="false">2505.23875v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Harnessing Foundation Models for Robust and Generalizable 6-DOF Bronchoscopy Localization</title>
      <link>http://arxiv.org/abs/2505.24249v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PANSv2是一个通用的和鲁棒的支气管镜定位框架，用于解决现有方法在泛化能力和鲁棒性方面的挑战。&lt;h4&gt;背景&lt;/h4&gt;基于视觉的6自由度支气管镜定位是一种准确且经济的介入性引导方法，但现有方法在泛化能力和对视觉退化条件的鲁棒性方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出PANSv2框架以解决现有方法的问题，提高支气管镜定位的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;PANSv2通过整合深度估计、地标检测和中心线约束，将多个视觉线索整合到一个统一的姿态优化框架中。同时，使用EndoOmni和EndoMamba模型进行深度估计和地标检测，结合空间和时间分析，并在多样化的支气管镜数据集上进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;PANSv2在包含10个患者案例的支气管镜数据集上实现了最高的跟踪成功率，与现有方法相比，SR-5（绝对轨迹误差小于5毫米的百分比）提高了18.1%，显示出在临床应用中的潜力。&lt;h4&gt;结论&lt;/h4&gt;PANSv2框架能够有效提高支气管镜定位的准确性和鲁棒性，为临床应用提供了有前景的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-based 6-DOF bronchoscopy localization offers a promising solution foraccurate and cost-effective interventional guidance. However, existing methodsstruggle with 1) limited generalization across patient cases due to scarcelabeled data, and 2) poor robustness under visual degradation, as bronchoscopyprocedures frequently involve artifacts such as occlusions and motion blur thatimpair visual information. To address these challenges, we propose PANSv2, ageneralizable and robust bronchoscopy localization framework. Motivated by PANSthat leverages multiple visual cues for pose likelihood measurement, PANSv2integrates depth estimation, landmark detection, and centerline constraintsinto a unified pose optimization framework that evaluates pose probability andsolves for the optimal bronchoscope pose. To further enhance generalizationcapabilities, we leverage the endoscopic foundation model EndoOmni for depthestimation and the video foundation model EndoMamba for landmark detection,incorporating both spatial and temporal analyses. Pretrained on diverseendoscopic datasets, these models provide stable and transferable visualrepresentations, enabling reliable performance across varied bronchoscopyscenarios. Additionally, to improve robustness to visual degradation, weintroduce an automatic re-initialization module that detects tracking failuresand re-establishes pose using landmark detections once clear views areavailable. Experimental results on bronchoscopy dataset encompassing 10 patientcases show that PANSv2 achieves the highest tracking success rate, with an18.1% improvement in SR-5 (percentage of absolute trajectory error under 5 mm)compared to existing methods, showing potential towards real clinical usage.</description>
      <author>example@mail.com (Qingyao Tian, Huai Liao, Xinyan Huang, Bingyu Yang, Hongbin Liu)</author>
      <guid isPermaLink="false">2505.24249v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Personalized Subgraph Federated Learning with Differentiable Auxiliary Projections</title>
      <link>http://arxiv.org/abs/2505.23864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FedAux的个性化子图联邦学习框架，用于在图结构数据上解决非IID问题，该框架通过辅助投影学习来对齐、比较和聚合异构分布的本地模型，同时不共享原始数据或节点嵌入。&lt;h4&gt;背景&lt;/h4&gt;在图结构数据上的联邦学习通常面临非IID挑战，尤其是在每个客户端持有从全局图中采样的不同子图的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出FedAux框架，旨在学习对齐、比较和聚合异构分布的本地模型，而不共享原始数据或节点嵌入。&lt;h4&gt;方法&lt;/h4&gt;在FedAux中，每个客户端联合训练（i）一个本地GNN和（ii）一个可学习的辅助投影向量（APV），该向量将节点嵌入差异性地投影到一维空间。随后通过软排序操作和轻量级的一维卷积来细化这些嵌入，使APV能够有效捕获客户端特定的信息。本地训练后，这些APV作为紧凑的签名，由服务器用于计算客户端之间的相似性并执行相似度加权的参数混合，从而产生个性化的模型并保留跨客户端的知识迁移。&lt;h4&gt;主要发现&lt;/h4&gt;FedAux在多种图基准测试中的实证评估表明，它在准确性和个性化性能方面显著优于现有基线。&lt;h4&gt;结论&lt;/h4&gt;FedAux框架在图结构数据上的联邦学习中表现出色，通过辅助投影有效地解决了非IID问题，并提高了模型的学习性能。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we introduce Federated learning with Auxiliary projections (FedAux), a personalized subgraph FL framework that learns to align, compare, and aggregate heterogeneously distributed local models without sharing raw data or node embeddings. In FedAux, each client jointly trains (i) a local GNN and (ii) a learnable auxiliary projection vector (APV) that differentiably projects node embeddings onto a 1D space. A soft-sorting operation followed by a lightweight 1D convolution refines these embeddings in the ordered space, enabling the APV to effectively capture client-specific information. After local training, these APVs serve as compact signatures that the server uses to compute inter-client similarities and perform similarity-weighted parameter mixing, yielding personalized models while preserving cross-client knowledge transfer. Moreover, we provide rigorous theoretical analysis to establish the convergence and rationality of our design. Empirical evaluations across diverse graph benchmarks demonstrate that FedAux substantially outperforms existing baselines in both accuracy and personalization performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated learning (FL) on graph-structured data typically faces non-IIDchallenges, particularly in scenarios where each client holds a distinctsubgraph sampled from a global graph. In this paper, we introduce Federatedlearning with Auxiliary projections (FedAux), a personalized subgraph FLframework that learns to align, compare, and aggregate heterogeneouslydistributed local models without sharing raw data or node embeddings. InFedAux, each client jointly trains (i) a local GNN and (ii) a learnableauxiliary projection vector (APV) that differentiably projects node embeddingsonto a 1D space. A soft-sorting operation followed by a lightweight 1Dconvolution refines these embeddings in the ordered space, enabling the APV toeffectively capture client-specific information. After local training, theseAPVs serve as compact signatures that the server uses to compute inter-clientsimilarities and perform similarity-weighted parameter mixing, yieldingpersonalized models while preserving cross-client knowledge transfer. Moreover,we provide rigorous theoretical analysis to establish the convergence andrationality of our design. Empirical evaluations across diverse graphbenchmarks demonstrate that FedAux substantially outperforms existing baselinesin both accuracy and personalization performance.</description>
      <author>example@mail.com (Wei Zhuo, Zhaohuan Zhan, Ziduo Yang, Han Yu)</author>
      <guid isPermaLink="false">2505.23864v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks</title>
      <link>http://arxiv.org/abs/2505.21649v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了DORI（Discriminative Orientation Reasoning Intelligence），一个用于评估物体方向感知能力的全面基准。DORI通过11个数据集上的精心设计的任务，揭示了当前视觉语言模型在物体方向感知上的局限性。&lt;h4&gt;背景&lt;/h4&gt;物体方向理解是视觉感知中的基本挑战，对机器人操作和增强现实等应用至关重要。当前视觉语言基准未能单独评估这一能力，经常将其与位置关系和一般场景理解混淆。&lt;h4&gt;目的&lt;/h4&gt;建立DORI基准，将物体方向感知作为主要评估目标，评估方向理解的四维：正面对齐、旋转变换、相对方向关系和标准方向理解。&lt;h4&gt;方法&lt;/h4&gt;DORI通过从11个数据集中精心挑选的任务，涵盖67个类别、67个物体，从合成和真实世界场景中评估方向理解。&lt;h4&gt;主要发现&lt;/h4&gt;评估了15个最先进的视觉语言模型，发现即使表现最好的模型在粗略任务上也只有54.2%的准确率，在细致的方向判断上只有33.0%。在需要参考系转换或复合旋转的任务中，性能进一步下降。&lt;h4&gt;结论&lt;/h4&gt;研究表明，需要专门的定向表示机制。模型在精确角度估计、跟踪视角间方向变化和复合旋转理解方面存在系统性缺陷，表明它们内部的三维空间表示有限。&lt;h4&gt;翻译&lt;/h4&gt;摘要：物体方向理解是视觉感知中的基本挑战，对于机器人操作和增强现实等应用至关重要。当前的视觉语言基准未能单独评估这一能力，常常将之与位置关系和一般场景理解混淆。我们引入了DORI（判别性方向推理智能），这是一个全面的基准，将物体方向感知作为主要评估目标。DORI评估了方向理解的四个维度：正面对齐、旋转变换、相对方向关系和标准方向理解。通过从11个数据集中精心挑选的任务，涵盖67个类别、67个物体，从合成和真实世界场景中，DORI提供了关于多模态系统如何理解物体方向见解。我们对15个最先进的视觉语言模型的评估揭示了关键的局限性：即使是表现最好的模型，在粗略任务上也只能达到54.2%的准确率，在细致的方向判断上只有33.0%，需要参考系转换或复合旋转的任务中，性能进一步下降。这些发现证明了需要专门的定向表示机制，因为模型显示出系统性无法执行精确的角度估计、跟踪视角间方向变化和理解复合旋转的能力——表明它们内部的三维空间表示有限。作为第一个专门为多模态系统中的方向意识设计的诊断框架，DORI对改进机器人控制、3D场景重建和物理环境中的人类-人工智能交互具有重要意义。DORI数据：https://huggingface.co/datasets/appledora/DORI-Benchmark&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object orientation understanding represents a fundamental challenge in visualperception critical for applications like robotic manipulation and augmentedreality. Current vision-language benchmarks fail to isolate this capability,often conflating it with positional relationships and general sceneunderstanding. We introduce DORI (Discriminative Orientation ReasoningIntelligence), a comprehensive benchmark establishing object orientationperception as a primary evaluation target. DORI assesses four dimensions oforientation comprehension: frontal alignment, rotational transformations,relative directional relationships, and canonical orientation understanding.Through carefully curated tasks from 11 datasets spanning 67 object categoriesacross synthetic and real-world scenarios, DORI provides insights on howmulti-modal systems understand object orientations. Our evaluation of 15state-of-the-art vision-language models reveals critical limitations: even thebest models achieve only 54.2% accuracy on coarse tasks and 33.0% on granularorientation judgments, with performance deteriorating for tasks requiringreference frame shifts or compound rotations. These findings demonstrate theneed for dedicated orientation representation mechanisms, as models showsystematic inability to perform precise angular estimations, track orientationchanges across viewpoints, and understand compound rotations - suggestinglimitations in their internal 3D spatial representations. As the firstdiagnostic framework specifically designed for orientation awareness inmultimodal systems, DORI offers implications for improving robotic control, 3Dscene reconstruction, and human-AI interaction in physical environments. DORIdata: https://huggingface.co/datasets/appledora/DORI-Benchmark</description>
      <author>example@mail.com (Keanu Nichols, Nazia Tasnim, Yuting Yan, Nicholas Ikechukwu, Elva Zou, Deepti Ghadiyaram, Bryan A. Plummer)</author>
      <guid isPermaLink="false">2505.21649v3</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>From Hallucinations to Jailbreaks: Rethinking the Vulnerability of Large Foundation Models</title>
      <link>http://arxiv.org/abs/2505.24232v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个统一的理论框架，用于研究大型基础模型（LFMs）的两种主要漏洞：幻觉和越狱攻击。通过实证研究，发现这两种漏洞之间存在关联，并提出相应的缓解策略。&lt;h4&gt;背景&lt;/h4&gt;大型基础模型（LFMs）存在幻觉和越狱攻击两种漏洞，这两种漏洞通常被独立研究。&lt;h4&gt;目的&lt;/h4&gt;建立一个统一的理论框架，研究幻觉和越狱攻击之间的关系，并提出相应的缓解策略。&lt;h4&gt;方法&lt;/h4&gt;提出一个理论框架，将越狱攻击视为token级别的优化，将幻觉视为attention级别的优化。通过实证研究验证理论框架的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;发现幻觉和越狱攻击的损失函数在优化目标特定输出时收敛相似，并且两者在attention重新分配方面表现出一致的梯度行为。&lt;h4&gt;结论&lt;/h4&gt;提出缓解幻觉可以降低越狱的成功率，反之亦然。研究表明，大型基础模型存在共同的失败模式，因此，鲁棒性策略应同时解决这两种漏洞。&lt;h4&gt;翻译&lt;/h4&gt;Large foundation models (LFMs) are susceptible to two distinct vulnerabilities: hallucinations and jailbreak attacks. While typically studied in isolation, we observe that defenses targeting one often affect the other, hinting at a deeper connection. We propose a unified theoretical framework that models jailbreaks as token-level optimization and hallucinations as attention-level optimization. Within this framework, we establish two key propositions: (1) Similar Loss Convergence - the loss functions for both vulnerabilities converge similarly when optimizing for target-specific outputs; and (2) Gradient Consistency in Attention Redistribution - both exhibit consistent gradient behavior driven by shared attention dynamics. We validate these propositions empirically on LLaVA-1.5 and MiniGPT-4, showing consistent optimization trends and aligned gradients. Leveraging this connection, we demonstrate that mitigation techniques for hallucinations can reduce jailbreak success rates, and vice versa. Our findings reveal a shared failure mode in LFMs and suggest that robustness strategies should jointly address both vulnerabilities.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large foundation models (LFMs) are susceptible to two distinctvulnerabilities: hallucinations and jailbreak attacks. While typically studiedin isolation, we observe that defenses targeting one often affect the other,hinting at a deeper connection.  We propose a unified theoretical framework that models jailbreaks astoken-level optimization and hallucinations as attention-level optimization.Within this framework, we establish two key propositions: (1) \textit{SimilarLoss Convergence} - the loss functions for both vulnerabilities convergesimilarly when optimizing for target-specific outputs; and (2) \textit{GradientConsistency in Attention Redistribution} - both exhibit consistent gradientbehavior driven by shared attention dynamics.  We validate these propositions empirically on LLaVA-1.5 and MiniGPT-4,showing consistent optimization trends and aligned gradients. Leveraging thisconnection, we demonstrate that mitigation techniques for hallucinations canreduce jailbreak success rates, and vice versa. Our findings reveal a sharedfailure mode in LFMs and suggest that robustness strategies should jointlyaddress both vulnerabilities.</description>
      <author>example@mail.com (Haibo Jin, Peiyan Zhang, Peiran Wang, Man Luo, Haohan Wang)</author>
      <guid isPermaLink="false">2505.24232v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Single Domain Generalization for Alzheimer's Detection from 3D MRIs with Pseudo-Morphological Augmentations and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2505.22465v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对阿尔茨海默病MRI检测中存在的挑战，提出了一种针对单域泛化设置的方法，旨在提高模型在不同数据集上的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;尽管深度学习模型在阿尔茨海默病MRI检测方面取得了显著进展，但数据集不平衡、协议差异和有限的数据集多样性等问题仍然限制了模型的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;针对上述问题，本文旨在通过设计一个模型，在给定一个域的数据时，实现针对不同分布的未见域的最大性能。&lt;h4&gt;方法&lt;/h4&gt;本文提出使用可学习的伪形态学模块，以生成具有形状感知和解剖意义的类特定增强，并结合监督对比学习模块提取稳健的类特定表示。&lt;h4&gt;主要发现&lt;/h4&gt;在三个数据集上进行的实验表明，该方法在处理数据集不平衡和成像协议变化时，性能和泛化能力都有所提高。&lt;h4&gt;结论&lt;/h4&gt;该方法的源代码将在论文被接受后公开，链接为https://github.com/zobia111/SDG-Alzheimer。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although Alzheimer's disease detection via MRIs has advanced significantlythanks to contemporary deep learning models, challenges such as classimbalance, protocol variations, and limited dataset diversity often hindertheir generalization capacity. To address this issue, this article focuses onthe single domain generalization setting, where given the data of one domain, amodel is designed and developed with maximal performance w.r.t. an unseendomain of distinct distribution. Since brain morphology is known to play acrucial role in Alzheimer's diagnosis, we propose the use of learnablepseudo-morphological modules aimed at producing shape-aware, anatomicallymeaningful class-specific augmentations in combination with a supervisedcontrastive learning module to extract robust class-specific representations.Experiments conducted across three datasets show improved performance andgeneralization capacity, especially under class imbalance and imaging protocolvariations. The source code will be made available upon acceptance athttps://github.com/zobia111/SDG-Alzheimer.</description>
      <author>example@mail.com (Zobia Batool, Huseyin Ozkan, Erchan Aptoula)</author>
      <guid isPermaLink="false">2505.22465v2</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Foundation Models for Zero-Shot Biometric Tasks</title>
      <link>http://arxiv.org/abs/2505.24214v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究利用视觉-语言模型（VLMs）和多模态大型语言模型（MLLMs）在生物识别领域的应用，评估了这些模型在六项生物识别任务中的零样本和少样本性能。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型的兴起，VLMs和MLLMs在人工智能领域展现了强大的泛化能力。然而，这些模型在生物识别和分析方面的潜力尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在建立一项综合基准，评估公开可用的VLMs和MLLMs在六个生物识别任务中的表现，包括人脸验证、软生物特征属性预测、虹膜识别、演示攻击检测和面部操纵检测。&lt;h4&gt;方法&lt;/h4&gt;研究使用了41种VLMs，在LFW和IITD-R-Full等数据集上进行了实验，验证了模型在各项任务中的性能。此外，研究还尝试了将简单分类器应用于模型嵌入，以提高检测深度伪造、演示攻击和提取软生物特征属性等任务的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，这些基础模型可以从各种生物识别任务中提取特征，并取得了不同程度的成功。例如，在人脸验证任务中，LFW数据集上取得了96.77%的匹配准确率；在虹膜识别任务中，IITD-R-Full数据集上取得了97.55%的匹配准确率。&lt;h4&gt;结论&lt;/h4&gt;这项工作强调了预训练模型在实现人工通用智能长期愿景中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;The advent of foundation models, particularly Vision-Language Models (VLMs) and Multi-modal Large Language Models (MLLMs), has redefined the frontiers of artificial intelligence, enabling remarkable generalization across diverse tasks with minimal or no supervision. Yet, their potential in biometric recognition and analysis remains relatively underexplored. In this work, we introduce a comprehensive benchmark that evaluates the zero-shot and few-shot performance of state-of-the-art publicly available VLMs and MLLMs across six biometric tasks spanning the face and iris modalities: face verification, soft biometric attribute prediction (gender and race), iris recognition, presentation attack detection (PAD), and face manipulation detection (morphs and deepfakes). A total of 41 VLMs were used in this evaluation. Experiments show that embeddings from these foundation models can be used for diverse biometric tasks with varying degrees of success. For example, in the case of face verification, a True Match Rate (TMR) of 96.77 percent was obtained at a False Match Rate (FMR) of 1 percent on the Labeled Face in the Wild (LFW) dataset, without any fine-tuning. In the case of iris recognition, the TMR at 1 percent FMR on the IITD-R-Full dataset was 97.55 percent without any fine-tuning. Further, we show that applying a simple classifier head to these embeddings can help perform DeepFake detection for faces, Presentation Attack Detection (PAD) for irides, and extract soft biometric attributes like gender and ethnicity from faces with reasonably high accuracy. This work reiterates the potential of pretrained models in achieving the long-term vision of Artificial General Intelligence.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of foundation models, particularly Vision-Language Models (VLMs)and Multi-modal Large Language Models (MLLMs), has redefined the frontiers ofartificial intelligence, enabling remarkable generalization across diversetasks with minimal or no supervision. Yet, their potential in biometricrecognition and analysis remains relatively underexplored. In this work, weintroduce a comprehensive benchmark that evaluates the zero-shot and few-shotperformance of state-of-the-art publicly available VLMs and MLLMs across sixbiometric tasks spanning the face and iris modalities: face verification, softbiometric attribute prediction (gender and race), iris recognition,presentation attack detection (PAD), and face manipulation detection (morphsand deepfakes). A total of 41 VLMs were used in this evaluation. Experimentsshow that embeddings from these foundation models can be used for diversebiometric tasks with varying degrees of success. For example, in the case offace verification, a True Match Rate (TMR) of 96.77 percent was obtained at aFalse Match Rate (FMR) of 1 percent on the Labeled Face in the Wild (LFW)dataset, without any fine-tuning. In the case of iris recognition, the TMR at 1percent FMR on the IITD-R-Full dataset was 97.55 percent without anyfine-tuning. Further, we show that applying a simple classifier head to theseembeddings can help perform DeepFake detection for faces, Presentation AttackDetection (PAD) for irides, and extract soft biometric attributes like genderand ethnicity from faces with reasonably high accuracy. This work reiteratesthe potential of pretrained models in achieving the long-term vision ofArtificial General Intelligence.</description>
      <author>example@mail.com (Redwan Sony, Parisa Farmanifard, Hamzeh Alzwairy, Nitish Shukla, Arun Ross)</author>
      <guid isPermaLink="false">2505.24214v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Improving Multilingual Speech Models on ML-SUPERB 2.0: Fine-tuning with Data Augmentation and LID-Aware CTC</title>
      <link>http://arxiv.org/abs/2505.24200v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的多语言语音处理方法，通过探索多种策略来适应预训练的Speech Foundation Models (SFM)，并在ML-SUPERB 2.0数据集上实现了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;尽管使用SFM在语言识别（LID）和自动语音识别（ASR）等任务上取得了良好的性能，但在资源有限的情况下进行微调时，这些模型面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提高多语言LID和ASR在ML-SUPERB 2.0数据集上的性能。&lt;h4&gt;方法&lt;/h4&gt;采用冻结上游训练、部分微调、低秩适应等策略来调整SFM；应用数据增强来减少在少样本设置中的性能差距；引入LID连接主义时序分类（CTC）损失进行正则化。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在ML-SUPERB 2.0数据集上实现了LID准确率的14%相对提升和ASR错误率（CER）的30%相对降低，并在Interspeech 2025 ML-SUPERB 2.0挑战赛中获得第二名。&lt;h4&gt;结论&lt;/h4&gt;通过上述方法，显著提升了多语言语音处理模型的性能，为实际应用提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multilingual speech processing with self-supervised or supervised pre-trainedSpeech Foundation Models (SFM) has achieved strong performance on tasks likeLanguage Identification (LID) and Automatic Speech Recognition (ASR). However,these models struggle with limited resources during fine-tuning. This paperenhances multilingual LID and ASR on ML-SUPERB 2.0 by exploring multiplestrategies for adapting SFMs, including frozen upstream training, partialfine-tuning, and low-rank adaptation. Furthermore, we employ data augmentationto mitigate performance gaps in few-shot settings and introduce LIDConnectionist Temporal Classification (CTC) loss for regularization. Ourapproach achieves a 14% relative improvement in LID accuracy and a 30% relativereduction in ASR CER over the baseline on ML-SUPERB 2.0, securing second placein the Interspeech 2025 ML-SUPERB 2.0 Challenge.</description>
      <author>example@mail.com (Qingzheng Wang, Jiancheng Sun, Yifan Peng, Shinji Watanabe)</author>
      <guid isPermaLink="false">2505.24200v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>MaCP: Minimal yet Mighty Adaptation via Hierarchical Cosine Projection</title>
      <link>http://arxiv.org/abs/2505.23870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2410.09103&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MaCP是一种新的自适应方法，通过最小化参数和内存需求，在微调大型基础模型时实现了卓越的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的自适应方法在微调大型基础模型时通常需要大量的参数和内存。&lt;h4&gt;目的&lt;/h4&gt;MaCP旨在利用余弦投影的能量紧缩和去相关特性，提高模型效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;MaCP将权重变化从低秩自适应投影到离散余弦空间，并将权重变化分配到不同的离散余弦谱级别，然后选择每个分配中最关键的频率成分。&lt;h4&gt;主要发现&lt;/h4&gt;MaCP在包括自然语言理解、自然语言生成、文本摘要以及图像分类和视频理解在内的多种单模态和多模态任务中表现出有效性，与现有方法相比，它提供了更高的准确性、显著降低的计算复杂度和更低的内存需求。&lt;h4&gt;结论&lt;/h4&gt;MaCP是一种高效的自适应方法，适用于微调大型基础模型，具有显著的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a new adaptation method MaCP, Minimal yet Mighty adaptive CosineProjection, that achieves exceptional performance while requiring minimalparameters and memory for fine-tuning large foundation models. Its general ideais to exploit the superior energy compaction and decorrelation properties ofcosine projection to improve both model efficiency and accuracy. Specifically,it projects the weight change from the low-rank adaptation into the discretecosine space. Then, the weight change is partitioned over different levels ofthe discrete cosine spectrum, and each partition's most critical frequencycomponents are selected. Extensive experiments demonstrate the effectiveness ofMaCP across a wide range of single-modality tasks, including natural languageunderstanding, natural language generation, text summarization, as well asmulti-modality tasks such as image classification and video understanding. MaCPconsistently delivers superior accuracy, significantly reduced computationalcomplexity, and lower memory requirements compared to existing alternatives.</description>
      <author>example@mail.com (Yixian Shen, Qi Bi, Jia-Hong Huang, Hongyi Zhu, Andy D. Pimentel, Anuj Pathania)</author>
      <guid isPermaLink="false">2505.23870v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Invariant Link Selector for Spatial-Temporal Out-of-Distribution Problem</title>
      <link>http://arxiv.org/abs/2505.24178v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by AISTATS 2025. 22 pages, 2 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对时间序列图上的鲁棒不变学习的方法，以解决训练环境和测试环境之间的数据差异问题。&lt;h4&gt;背景&lt;/h4&gt;在基础模型时代，数据分布不匹配（OOD）问题阻碍了人工智能的泛化能力，特别是当关联时间因素时，问题更加复杂。&lt;h4&gt;目的&lt;/h4&gt;旨在研究时间图中哪些组件在标签方面最具不变性和代表性，以实现鲁棒的不变学习。&lt;h4&gt;方法&lt;/h4&gt;使用信息瓶颈（IB）方法，提出了一种误差界限不变链接选择器，在训练过程中区分不变组件和可变组件，使深度学习模型对不同测试场景具有可泛化性。此外，还导出了一系列严格通用的优化函数，并配备了特定于任务的损失函数，例如时间链接预测，以便预训练模型解决现实世界的应用任务。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过实验验证了在引用推荐和商品推荐等实际应用中的有效性。&lt;h4&gt;结论&lt;/h4&gt;该研究为时间序列图上的鲁棒不变学习提供了一种新方法，有助于提高人工智能模型的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;In the era of foundation models, Out-of- Distribution (OOD) problems, i.e.,the data discrepancy between the training environments and testingenvironments, hinder AI generalization. Further, relational data like graphsdisobeying the Independent and Identically Distributed (IID) condition makes theproblem more challenging, especially much harder when it is associated withtime. Motivated by this, to realize the robust invariant learning over temporalgraphs, we want to investigate what components in temporal graphs are mostinvariant and representative with respect to labels. With the InformationBottleneck (IB) method, we propose an error-bounded Invariant Link Selectorthat can distinguish invariant components and variant components during thetraining process to make the deep learning model generalizable for differenttesting scenarios. Besides deriving a series of rigorous generalizableoptimization functions, we also equip the training with task-specific lossfunctions, e.g., temporal link prediction, to make pretrained models solvemore real-world application tasks like citation recommendation and merchandiserecommendation, as demonstrated in our experiments with state-of-the-art (SOTA)methods. Our code is available at https://github.com/kthrn22/OOD-Linker.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of foundation models, Out-of- Distribution (OOD) problems, i.e.,the data discrepancy between the training environments and testingenvironments, hinder AI generalization. Further, relational data like graphsdisobeying the Independent and Identically Distributed (IID) condition makesthe problem more challenging, especially much harder when it is associated withtime. Motivated by this, to realize the robust invariant learning over temporalgraphs, we want to investigate what components in temporal graphs are mostinvariant and representative with respect to labels. With the InformationBottleneck (IB) method, we propose an error-bounded Invariant Link Selectorthat can distinguish invariant components and variant components during thetraining process to make the deep learning model generalizable for differenttesting scenarios. Besides deriving a series of rigorous generalizableoptimization functions, we also equip the training with task-specific lossfunctions, e.g., temporal link prediction, to make pretrained models solvereal-world application tasks like citation recommendation and merchandiserecommendation, as demonstrated in our experiments with state-of-the-art (SOTA)methods. Our code is available at https://github.com/kthrn22/OOD-Linker.</description>
      <author>example@mail.com (Katherine Tieu, Dongqi Fu, Jun Wu, Jingrui He)</author>
      <guid isPermaLink="false">2505.24178v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Pretraining Deformable Image Registration Networks with Random Images</title>
      <link>http://arxiv.org/abs/2505.24167v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by MIDL 2025. Code available at  https://github.com/junyuchen245/Pretraining_Image_Registration_DNNs&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的医学图像配准方法，通过在随机生成的图像上进行预训练来提高配准精度和效率。&lt;h4&gt;背景&lt;/h4&gt;深度学习在医学图像配准中的应用日益增加，但传统的训练方法需要大量的医学图像数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的预训练策略，以减少对特定领域数据的依赖，并提高配准模型的性能。&lt;h4&gt;方法&lt;/h4&gt;利用随机生成的图像进行预训练，这些图像具有精心设计的噪声和对比度属性，以模拟医学图像。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该预训练策略提高了配准精度，减少了达到竞争性性能所需的特定领域数据量，并加快了下游训练的收敛速度。&lt;h4&gt;结论&lt;/h4&gt;该方法通过预训练提高了医学图像配准的准确性和效率，为医学图像配准提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，基于深度学习的医学图像配准技术取得了显著进展，表明训练深度神经网络（DNNs）并不一定需要医学图像。先前的研究表明，在具有精心设计的噪声和对比度属性的随机图像上训练的DNNs仍然可以很好地泛化到未见过的医学数据。基于这一洞察，我们提出使用随机图像之间的配准作为预训练图像配准基础模型的一个代理任务。实证结果表明，我们的预训练策略提高了配准精度，减少了达到竞争性性能所需的特定领域数据量，并加速了下游训练的收敛，从而提高了计算效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in deep learning-based medical image registration have shownthat training deep neural networks~(DNNs) does not necessarily require medicalimages. Previous work showed that DNNs trained on randomly generated imageswith carefully designed noise and contrast properties can still generalize wellto unseen medical data. Building on this insight, we propose using registrationbetween random images as a proxy task for pretraining a foundation model forimage registration. Empirical results show that our pretraining strategyimproves registration accuracy, reduces the amount of domain-specific dataneeded to achieve competitive performance, and accelerates convergence duringdownstream training, thereby enhancing computational efficiency.</description>
      <author>example@mail.com (Junyu Chen, Shuwen Wei, Yihao Liu, Aaron Carass, Yong Du)</author>
      <guid isPermaLink="false">2505.24167v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>The Butterfly Effect in Pathology: Exploring Security in Pathology Foundation Models</title>
      <link>http://arxiv.org/abs/2505.24141v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究首次系统地调查了病理基础模型在对抗攻击下的安全性，提出了一种无标签攻击框架，并通过实验验证了攻击的有效性。&lt;h4&gt;背景&lt;/h4&gt;病理基础模型在研究和临床决策支持系统中得到广泛应用，但其对抗攻击的脆弱性尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;探索病理基础模型在对抗攻击下的安全性，并提出防御策略。&lt;h4&gt;方法&lt;/h4&gt;引入了“局部扰动全局影响”的原则，提出了一种无需访问下游任务标签的无标签攻击框架，并对四个经典的白盒攻击方法进行了修订。&lt;h4&gt;主要发现&lt;/h4&gt;通过修改每张幻灯片0.1%的patches，攻击导致下游准确率下降最多可达20%。分析了影响攻击成功的关键因素，探讨了patch级脆弱性与语义内容之间的关系，并对潜在防御策略进行了初步研究。&lt;h4&gt;结论&lt;/h4&gt;本研究为未来研究病理基础模型的对抗鲁棒性和可靠部署奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;With the widespread adoption of pathology foundation models in both research and clinical decision support systems, exploring their security has become a critical concern. However, despite their growing impact, the vulnerability of these models to adversarial attacks remains largely unexplored. In this work, we present the first systematic investigation into the security of pathology foundation models for whole slide image (WSI) analysis against adversarial attacks. Specifically, we introduce the principle of 'local perturbation with global impact' and propose a label-free attack framework that operates without requiring access to downstream task labels. Under this attack framework, we revise four classical white-box attack methods and redefine the perturbation budget based on the characteristics of WSI. We conduct comprehensive experiments on three representative pathology foundation models across five datasets and six downstream tasks. Despite modifying only 0.1% of patches per slide with imperceptible noise, our attack leads to downstream accuracy degradation that can reach up to 20% in the worst cases. Furthermore, we analyze key factors that influence attack success, explore the relationship between patch-level vulnerability and semantic content, and conduct a preliminary investigation into potential defense strategies. These findings lay the groundwork for future research on the adversarial robustness and reliable deployment of pathology foundation models. Our code is publicly available at: https://github.com/Jiashuai-Liu-hmos/Attack-WSI-pathology-foundation-models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the widespread adoption of pathology foundation models in both researchand clinical decision support systems, exploring their security has become acritical concern. However, despite their growing impact, the vulnerability ofthese models to adversarial attacks remains largely unexplored. In this work,we present the first systematic investigation into the security of pathologyfoundation models for whole slide image~(WSI) analysis against adversarialattacks. Specifically, we introduce the principle of \textit{local perturbationwith global impact} and propose a label-free attack framework that operateswithout requiring access to downstream task labels. Under this attackframework, we revise four classical white-box attack methods and redefine theperturbation budget based on the characteristics of WSI. We conductcomprehensive experiments on three representative pathology foundation modelsacross five datasets and six downstream tasks. Despite modifying only 0.1\% ofpatches per slide with imperceptible noise, our attack leads to downstreamaccuracy degradation that can reach up to 20\% in the worst cases. Furthermore,we analyze key factors that influence attack success, explore the relationshipbetween patch-level vulnerability and semantic content, and conduct apreliminary investigation into potential defence strategies. These findings laythe groundwork for future research on the adversarial robustness and reliabledeployment of pathology foundation models. Our code is publicly available at:https://github.com/Jiashuai-Liu-hmos/Attack-WSI-pathology-foundation-models.</description>
      <author>example@mail.com (Jiashuai Liu, Yingjia Shang, Yingkang Zhan, Di Zhang, Yi Niu, Dong Wei, Xian Wu, Zeyu Gao, Chen Li, Yefeng Zheng)</author>
      <guid isPermaLink="false">2505.24141v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Directed Homophily-Aware Graph Neural Network</title>
      <link>http://arxiv.org/abs/2505.22362v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DHGNN的图神经网络框架，该框架通过引入同质性和方向敏感组件来解决现有GNN在异质邻域泛化困难和忽略图方向性问题。&lt;h4&gt;背景&lt;/h4&gt;现有的图神经网络在处理图结构数据时取得了显著成功，但大多数GNN在处理异质邻域时泛化能力有限，并且忽略了现实世界图中图的方向性，导致在不对称结构的定向图上性能不佳。&lt;h4&gt;目的&lt;/h4&gt;提出DHGNN以解决上述问题，使其能够更好地处理异质邻域和图的方向性。&lt;h4&gt;方法&lt;/h4&gt;DHGNN采用可重置的门控机制来根据同质性和信息量自适应地调节消息贡献，并使用结构感知的噪声容忍融合模块来有效整合来自原始和反向方向上的节点表示。&lt;h4&gt;主要发现&lt;/h4&gt;在异质和同质定向图数据集上的广泛实验表明，DHGNN在节点分类和链接预测任务中优于现有方法，特别是在链接预测任务中，DHGNN比最佳基线提高了高达15.07%。分析表明，门控机制能够捕捉到方向性同质性和层间同质性的波动，为复杂图结构上的消息传递行为提供了更深入的见解。&lt;h4&gt;结论&lt;/h4&gt;DHGNN通过结合同质性和方向敏感性，提高了图神经网络在处理定向图结构数据时的性能和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have achieved significant success in various learning tasks on graph-structured data. Nevertheless, most GNNs struggle to generalize to heterophilic neighborhoods. Additionally, many GNNs ignore the directional nature of real-world graphs, resulting in suboptimal performance on directed graphs with asymmetric structures. In this work, we propose Directed Homophily-aware Graph Neural Network (DHGNN), a novel framework that addresses these limitations by incorporating homophily-aware and direction-sensitive components. DHGNN employs a resettable gating mechanism to adaptively modulate message contributions based on homophily levels and informativeness, and a structure-aware noise-tolerant fusion module to effectively integrate node representations from the original and reverse directions. Extensive experiments on both homophilic and heterophilic directed graph datasets demonstrate that DHGNN outperforms state-of-the-art methods in node classification and link prediction. In particular, DHGNN improves over the best baseline by up to 15.07% in link prediction. Our analysis further shows that the gating mechanism captures directional homophily gaps and fluctuating homophily across layers, providing deeper insights into message-passing behavior on complex graph structures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have achieved significant success in variouslearning tasks on graph-structured data. Nevertheless, most GNNs struggle togeneralize to heterophilic neighborhoods. Additionally, many GNNs ignore thedirectional nature of real-world graphs, resulting in suboptimal performance ondirected graphs with asymmetric structures. In this work, we propose DirectedHomophily-aware Graph Neural Network (DHGNN), a novel framework that addressesthese limitations by incorporating homophily-aware and direction-sensitivecomponents. DHGNN employs a resettable gating mechanism to adaptively modulatemessage contributions based on homophily levels and informativeness, and astructure-aware noise-tolerant fusion module to effectively integrate noderepresentations from the original and reverse directions. Extensive experimentson both homophilic and heterophilic directed graph datasets demonstrate thatDHGNN outperforms state-of-the-art methods in node classification and linkprediction. In particular, DHGNN improves over the best baseline by up to15.07% in link prediction. Our analysis further shows that the gating mechanismcaptures directional homophily gaps and fluctuating homophily across layers,providing deeper insights into message-passing behavior on complex graphstructures.</description>
      <author>example@mail.com (Aihu Zhang, Jiaxing Xu, Mengcheng Lan, Shili Xiang, Yiping Ke)</author>
      <guid isPermaLink="false">2505.22362v2</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Federated Foundation Model for GI Endoscopy Images</title>
      <link>http://arxiv.org/abs/2505.24108v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 11 figures, submitted to BHI2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于胃肠内镜成像的基础模型训练的联邦学习框架，旨在解决数据稀缺和隐私保护的问题。&lt;h4&gt;背景&lt;/h4&gt;胃肠内镜检查对于早期发现疾病和改善患者预后至关重要。深度学习在支持胃肠诊断和决策方面已取得成功，但这些模型需要昂贵的数据集和标签。&lt;h4&gt;目的&lt;/h4&gt;开发能够学习通用表示的基础模型，以克服数据稀缺，并解决医疗数据的敏感性和隐私保护问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种联邦学习框架，用于在本地医院环境中训练基础模型，同时为共享模型做出贡献。在异构和同构环境下进行了实验，评估了多个联邦学习算法的适用性。&lt;h4&gt;主要发现&lt;/h4&gt;训练的基础模型在分类、检测和分割三个关键下游任务上均取得了改进性能，证明了在联邦和隐私保护环境中的有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法在保护患者隐私的同时，通过联邦学习框架提高了胃肠内镜成像模型的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gastrointestinal (GI) endoscopy is essential in identifying GI tractabnormalities in order to detect diseases in their early stages and improvepatient outcomes. Although deep learning has shown success in supporting GIdiagnostics and decision-making, these models require curated datasets withlabels that are expensive to acquire. Foundation models offer a promisingsolution by learning general-purpose representations, which can be finetunedfor specific tasks, overcoming data scarcity. Developing foundation models formedical imaging holds significant potential, but the sensitive and protectednature of medical data presents unique challenges. Foundation model trainingtypically requires extensive datasets, and while hospitals generate largevolumes of data, privacy restrictions prevent direct data sharing, makingfoundation model training infeasible in most scenarios. In this work, wepropose a FL framework for training foundation models for gastroendoscopyimaging, enabling data to remain within local hospital environments whilecontributing to a shared model. We explore several established FL algorithms,assessing their suitability for training foundation models without relying ontask-specific labels, conducting experiments in both homogeneous andheterogeneous settings. We evaluate the trained foundation model on threecritical downstream tasks--classification, detection, and segmentation--anddemonstrate that it achieves improved performance across all tasks,highlighting the effectiveness of our approach in a federated,privacy-preserving setting.</description>
      <author>example@mail.com (Alina Devkota, Annahita Amireskandari, Joel Palko, Shyam Thakkar, Donald Adjeroh, Xiajun Jiang, Binod Bhattarai, Prashnna K. Gyawali)</author>
      <guid isPermaLink="false">2505.24108v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Weakly-Supervised Affordance Grounding Guided by Part-Level Semantic Priors</title>
      <link>http://arxiv.org/abs/2505.24103v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究弱监督的可用性定位任务，通过使用人-物交互图像和自视角物体图像训练模型识别物体上的可用性区域，无需密集标签。&lt;h4&gt;背景&lt;/h4&gt;以往的工作大多基于类激活图，这些图在语义分割中有效，但不一定适合定位动作和功能。&lt;h4&gt;目的&lt;/h4&gt;利用最新的高级基础模型，开发了一个基于伪标签的监督训练流程。&lt;h4&gt;方法&lt;/h4&gt;伪标签由一个现成的部分分割模型生成，并受可用性到部分名称的映射指导。此外，引入了三个对基线模型的关键增强：标签精炼阶段、细粒度特征对齐过程和轻量级推理模块。&lt;h4&gt;主要发现&lt;/h4&gt;这些技术利用了现成基础模型中嵌入的静态对象语义知识，以改善可用性学习，有效地弥合了物体和动作之间的差距。&lt;h4&gt;结论&lt;/h4&gt;广泛的实验表明，所提出的模型性能在现有方法上实现了突破性的改进。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we focus on the task of weakly supervised affordance grounding, where a model is trained to identify affordance regions on objects using human-object interaction images and egocentric object images without dense labels. Previous works are mostly built upon class activation maps, which are effective for semantic segmentation but may not be suitable for locating actions and functions. Leveraging recent advanced foundation models, we develop a supervised training pipeline based on pseudo labels. The pseudo labels are generated from an off-the-shelf part segmentation model, guided by a mapping from affordance to part names. Furthermore, we introduce three key enhancements to the baseline model: a label refining stage, a fine-grained feature alignment process, and a lightweight reasoning module. These techniques harness the semantic knowledge of static objects embedded in off-the-shelf foundation models to improve affordance learning, effectively bridging the gap between objects and actions. Extensive experiments demonstrate that the performance of the proposed model has achieved a breakthrough improvement over existing methods. Our codes are available at https://github.com/woyut/WSAG-PLSP.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we focus on the task of weakly supervised affordance grounding,where a model is trained to identify affordance regions on objects usinghuman-object interaction images and egocentric object images without denselabels. Previous works are mostly built upon class activation maps, which areeffective for semantic segmentation but may not be suitable for locatingactions and functions. Leveraging recent advanced foundation models, we developa supervised training pipeline based on pseudo labels. The pseudo labels aregenerated from an off-the-shelf part segmentation model, guided by a mappingfrom affordance to part names. Furthermore, we introduce three key enhancementsto the baseline model: a label refining stage, a fine-grained feature alignmentprocess, and a lightweight reasoning module. These techniques harness thesemantic knowledge of static objects embedded in off-the-shelf foundationmodels to improve affordance learning, effectively bridging the gap betweenobjects and actions. Extensive experiments demonstrate that the performance ofthe proposed model has achieved a breakthrough improvement over existingmethods. Our codes are available at https://github.com/woyut/WSAG-PLSP .</description>
      <author>example@mail.com (Peiran Xu, Yadong Mu)</author>
      <guid isPermaLink="false">2505.24103v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>SpeechVerifier: Robust Acoustic Fingerprint against Tampering Attacks via Watermarking</title>
      <link>http://arxiv.org/abs/2505.23821v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SpeechVerifier的语音验证方法，用于检测和验证公开演讲的完整性，以应对社交媒体时代恶意篡改演讲的问题。&lt;h4&gt;背景&lt;/h4&gt;社交媒体的兴起导致恶意篡改的公开演讲，特别是有影响力的人物演讲，严重影响了社会稳定和公众信任。&lt;h4&gt;目的&lt;/h4&gt;针对现有语音篡改检测方法的不足，即依赖外部数据或对良性操作敏感度不足，提出一种新的语音验证方法。&lt;h4&gt;方法&lt;/h4&gt;SpeechVerifier利用多尺度特征提取捕捉不同时间分辨率下的语音特征，并通过对比学习生成指纹来检测修改，指纹设计对良性操作具有鲁棒性，在恶意篡改时表现出显著变化。指纹通过分段水印嵌入到语音信号中，无需外部参考即可进行语音验证。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SpeechVerifier在检测篡改攻击方面有效，同时对良性操作具有鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;SpeechVerifier是一种有效的语音验证方法，可以有效地检测篡改攻击，并对良性操作具有鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;With the surge of social media, maliciously tampered public speeches, especially those from influential figures, have seriously affected social stability and public trust. Existing speech tampering detection methods remain insufficient: they either rely on external reference data or fail to be both sensitive to attacks and robust to benign operations, such as compression and resampling. To tackle these challenges, we introduce SpeechVerifer to proactively verify speech integrity using only the published speech itself, i.e., without requiring any external references. Inspired by audio fingerprinting and watermarking, SpeechVerifier can (i) effectively detect tampering attacks, (ii) be robust to benign operations and (iii) verify the integrity only based on published speeches. Briefly, SpeechVerifier utilizes multiscale feature extraction to capture speech features across different temporal resolutions. Then, it employs contrastive learning to generate fingerprints that can detect modifications at varying granularities. These fingerprints are designed to be robust to benign operations, but exhibit significant changes when malicious tampering occurs. To enable speech verification in a self-contained manner, the generated fingerprints are then embedded into the speech signal by segment-wise watermarking. Without external references, SpeechVerifier can retrieve the fingerprint from the published audio and check it with the embedded watermark to verify the integrity of the speech. Extensive experimental results demonstrate that the proposed SpeechVerifier is effective in detecting tampering attacks and robust to benign operations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the surge of social media, maliciously tampered public speeches,especially those from influential figures, have seriously affected socialstability and public trust. Existing speech tampering detection methods remaininsufficient: they either rely on external reference data or fail to be bothsensitive to attacks and robust to benign operations, such as compression andresampling. To tackle these challenges, we introduce SpeechVerifer toproactively verify speech integrity using only the published speech itself,i.e., without requiring any external references. Inspired by audiofingerprinting and watermarking, SpeechVerifier can (i) effectively detecttampering attacks, (ii) be robust to benign operations and (iii) verify theintegrity only based on published speeches. Briefly, SpeechVerifier utilizesmultiscale feature extraction to capture speech features across differenttemporal resolutions. Then, it employs contrastive learning to generatefingerprints that can detect modifications at varying granularities. Thesefingerprints are designed to be robust to benign operations, but exhibitsignificant changes when malicious tampering occurs. To enable speechverification in a self-contained manner, the generated fingerprints are thenembedded into the speech signal by segment-wise watermarking. Without externalreferences, SpeechVerifier can retrieve the fingerprint from the publishedaudio and check it with the embedded watermark to verify the integrity of thespeech. Extensive experimental results demonstrate that the proposedSpeechVerifier is effective in detecting tampering attacks and robust to benignoperations.</description>
      <author>example@mail.com (Lingfeng Yao, Chenpei Huang, Shengyao Wang, Junpei Xue, Hanqing Guo, Jiang Liu, Xun Chen, Miao Pan)</author>
      <guid isPermaLink="false">2505.23821v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Proxy-FDA: Proxy-based Feature Distribution Alignment for Fine-tuning Vision Foundation Models without Forgetting</title>
      <link>http://arxiv.org/abs/2505.24088v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Proxy-FDA的新颖正则化方法，旨在在微调基础模型时减少概念遗忘，同时不影响微调性能。&lt;h4&gt;背景&lt;/h4&gt;预训练的基础模型在大量数据上编码了丰富的现实世界概念，可以通过微调应用于下游任务。然而，在单一任务上微调基础模型可能导致在其他任务上的概念遗忘问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以减少在微调过程中先验知识的遗忘，同时不影响微调效果。&lt;h4&gt;方法&lt;/h4&gt;Proxy-FDA通过在预训练和微调的特征空间之间执行特征分布对齐（使用最近邻图），并通过动态生成的信息代理来增加数据多样性，进一步改进对齐。&lt;h4&gt;主要发现&lt;/h4&gt;Proxy-FDA显著减少了微调过程中的概念遗忘，并且发现遗忘与分布距离度量之间存在强烈的相关性（与L2距离相比）。&lt;h4&gt;结论&lt;/h4&gt;Proxy-FDA在各种微调设置（端到端、少样本和持续调整）以及不同的任务（如图像分类、字幕和VQA）中都显示出其优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在大量数据上预训练的视觉基础模型编码了丰富的现实世界概念，这些概念可以通过微调应用于下游任务。然而，在单一任务上对基础模型进行微调通常会导致其他任务上的概念遗忘问题。最近的方法旨在通过微调来减轻先验知识的遗忘，同时不影响微调性能。知识通常通过匹配原始和微调模型权重或特征对来保留。然而，这种点对点的匹配可能过于强烈，而没有意识到编码丰富知识的特征邻域结构。我们提出了一种名为Proxy-FDA的新颖正则化方法，它明确地保留了特征空间中的结构知识。Proxy-FDA在预训练和微调的特征空间之间执行特征分布对齐（使用最近邻图），并通过动态生成的信息代理来增加数据多样性，进一步改进对齐。实验表明，Proxy-FDA在微调过程中显著减少了概念遗忘，并且我们发现遗忘与分布距离度量之间存在强烈的相关性（与L2距离相比）。我们进一步证明了Proxy-FDA在各种微调设置（端到端、少样本和持续调整）和不同任务（如图像分类、字幕和VQA）中的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision foundation models pre-trained on massive data encode richrepresentations of real-world concepts, which can be adapted to downstreamtasks by fine-tuning. However, fine-tuning foundation models on one task oftenleads to the issue of concept forgetting on other tasks. Recent methods ofrobust fine-tuning aim to mitigate forgetting of prior knowledge withoutaffecting the fine-tuning performance. Knowledge is often preserved by matchingthe original and fine-tuned model weights or feature pairs. However, suchpoint-wise matching can be too strong, without explicit awareness of thefeature neighborhood structures that encode rich knowledge as well. We proposea novel regularization method Proxy-FDA that explicitly preserves thestructural knowledge in feature space. Proxy-FDA performs Feature DistributionAlignment (using nearest neighbor graphs) between the pre-trained andfine-tuned feature spaces, and the alignment is further improved by informativeproxies that are generated dynamically to increase data diversity. Experimentsshow that Proxy-FDA significantly reduces concept forgetting duringfine-tuning, and we find a strong correlation between forgetting and adistributional distance metric (in comparison to L2 distance). We furtherdemonstrate Proxy-FDA's benefits in various fine-tuning settings (end-to-end,few-shot and continual tuning) and across different tasks like imageclassification, captioning and VQA.</description>
      <author>example@mail.com (Chen Huang, Skyler Seto, Hadi Pouransari, Mehrdad Farajtabar, Raviteja Vemulapalli, Fartash Faghri, Oncel Tuzel, Barry-John Theobald, Josh Susskind)</author>
      <guid isPermaLink="false">2505.24088v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>From Images to Signals: Are Large Vision Models Useful for Time Series Analysis?</title>
      <link>http://arxiv.org/abs/2505.24030v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了Transformer模型在时间序列研究中的应用，尤其是大型语言模型（LLMs）和基础模型在时间序列分析中的潜力，并探讨了大型视觉模型（LVMs）在时间序列分析中的效用。&lt;h4&gt;背景&lt;/h4&gt;Transformer模型在时间序列研究中的应用越来越受到关注，多模态研究方向的兴起促使人们探索大型视觉模型（LVMs）在时间序列分析中的价值。&lt;h4&gt;目的&lt;/h4&gt;为了评估LVMs在时间序列分析中的实用性，研究者设计并进行了首个涉及4种LVMs、8种成像方法、18个数据集和26个基线模型的研究，包括高级（分类）和低级（预测）任务，并进行了广泛的消融分析。&lt;h4&gt;方法&lt;/h4&gt;研究者设计了实验，比较了LVMs在不同时间序列任务上的表现，包括时间序列分类和预测，并进行了详细的消融分析。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现LVMs在时间序列分类任务中表现出色，但在预测任务上面临挑战。尽管效果显著，但当前最有效的LVM预测模型仅限于特定类型的LVM和成像方法，对预测周期存在偏见，且难以有效利用长窗口的历史数据。&lt;h4&gt;结论&lt;/h4&gt;本文的研究成果为LVM和多模态技术在时间序列任务中的应用提供了基础，并为进一步研究提供了参考。&lt;h4&gt;翻译&lt;/h4&gt;Transformer-based models have gained increasing attention in time series research, driving interest in Large Language Models (LLMs) and foundation models for time series analysis. As the field moves toward multi-modality, Large Vision Models (LVMs) are emerging as a promising direction. In the past, the effectiveness of Transformer and LLMs in time series has been debated. When it comes to LVMs, a similar question arises: are LVMs truly useful for time series analysis? To address it, we design and conduct the first principled study involving 4 LVMs, 8 imaging methods, 18 datasets and 26 baselines across both high-level (classification) and low-level (forecasting) tasks, with extensive ablation analysis. Our findings indicate LVMs are indeed useful for time series classification but face challenges in forecasting. Although effective, the contemporary best LVM forecasters are limited to specific types of LVMs and imaging methods, exhibit a bias toward forecasting periods, and have limited ability to utilize long look-back windows. We hope our findings could serve as a cornerstone for future research on LVM- and multimodal-based solutions to different time series tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer-based models have gained increasing attention in time seriesresearch, driving interest in Large Language Models (LLMs) and foundationmodels for time series analysis. As the field moves toward multi-modality,Large Vision Models (LVMs) are emerging as a promising direction. In the past,the effectiveness of Transformer and LLMs in time series has been debated. Whenit comes to LVMs, a similar question arises: are LVMs truely useful for timeseries analysis? To address it, we design and conduct the first principledstudy involving 4 LVMs, 8 imaging methods, 18 datasets and 26 baselines acrossboth high-level (classification) and low-level (forecasting) tasks, withextensive ablation analysis. Our findings indicate LVMs are indeed useful fortime series classification but face challenges in forecasting. Althougheffective, the contemporary best LVM forecasters are limited to specific typesof LVMs and imaging methods, exhibit a bias toward forecasting periods, andhave limited ability to utilize long look-back windows. We hope our findingscould serve as a cornerstone for future research on LVM- and multimodal-basedsolutions to different time series tasks.</description>
      <author>example@mail.com (Ziming Zhao, ChengAo Shen, Hanghang Tong, Dongjin Song, Zhigang Deng, Qingsong Wen, Jingchao Ni)</author>
      <guid isPermaLink="false">2505.24030v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>DINO-R1: Incentivizing Reasoning Capability in Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2505.24025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DINO-R1的新方法，旨在通过强化学习提升视觉基础模型在视觉推理方面的能力。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型的推理能力受到广泛关注，并取得了显著成果。然而，这些推理能力在视觉基础模型，如DINO系列中，尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;本研究的目标是使用强化学习来提升视觉基础模型的视觉推理能力。&lt;h4&gt;方法&lt;/h4&gt;DINO-R1引入了Group Relative Query Optimization (GRQO)这一新的强化式训练策略，该策略基于分组归一化的对齐质量来计算查询级别的奖励。同时，通过应用KL正则化来稳定物体分布，以减少训练过程中的不稳定性和过拟合。在Grounding-DINO的基础上，DINO-R1家族模型集成了视觉提示编码器和视觉引导的查询选择机制。&lt;h4&gt;主要发现&lt;/h4&gt;在COCO、LVIS和ODinW上的大量实验表明，DINO-R1在开放词汇和封闭集视觉提示场景中都显著优于监督式微调基线，并表现出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;DINO-R1在提升视觉基础模型推理能力方面取得了一定的成果，为该领域的研究提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;最近对大型语言模型（如DeepSeek-R1）推理能力的爆炸性兴趣，通过基于强化学习的微调框架（例如Group Relative Policy Optimization (GRPO)方法）已经展示了显著的成功。然而，这些推理能力仍然没有得到充分探索，并且特别在视觉基础模型中缺失，包括像DINO系列这样的表示模型。在这项工作中，我们提出了DINO-R1，这是第一个试图使用强化学习来激励视觉基础模型视觉上下文推理能力的研究。具体来说，DINO-R1引入了Group Relative Query Optimization (GRQO)，这是一种为基于查询的表示模型专门设计的新的强化式训练策略，它根据分组归一化的对齐质量计算查询级别的奖励。我们还应用KL正则化来稳定物体分布，以减少训练的不稳定性。这种联合优化能够在查询上实现密集和有表达力的监督，同时减轻过拟合和分布漂移。基于Grounding-DINO，我们训练了一系列的DINO-R1家族模型，这些模型集成了视觉提示编码器和视觉引导的查询选择机制。在COCO、LVIS和ODinW上的大量实验表明，DINO-R1在开放词汇和封闭集视觉提示场景中都显著优于监督式微调基线，并实现了良好的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent explosive interest in the reasoning capabilities of large languagemodels, such as DeepSeek-R1, has demonstrated remarkable success throughreinforcement learning-based fine-tuning frameworks, exemplified by methodslike Group Relative Policy Optimization (GRPO). However, such reasoningabilities remain underexplored and notably absent in vision foundation models,including representation models like the DINO series. In this work, we propose\textbf{DINO-R1}, the first such attempt to incentivize visual in-contextreasoning capabilities of vision foundation models using reinforcementlearning. Specifically, DINO-R1 introduces \textbf{Group Relative QueryOptimization (GRQO)}, a novel reinforcement-style training strategy explicitlydesigned for query-based representation models, which computes query-levelrewards based on group-normalized alignment quality. We also applyKL-regularization to stabilize the objectness distribution to reduce thetraining instability. This joint optimization enables dense and expressivesupervision across queries while mitigating overfitting and distributionaldrift. Building upon Grounding-DINO, we train a series of DINO-R1 family modelsthat integrate a visual prompt encoder and a visual-guided query selectionmechanism. Extensive experiments on COCO, LVIS, and ODinW demonstrate thatDINO-R1 significantly outperforms supervised fine-tuning baselines, achievingstrong generalization in both open-vocabulary and closed-set visual promptingscenarios.</description>
      <author>example@mail.com (Chenbin Pan, Wenbin He, Zhengzhong Tu, Liu Ren)</author>
      <guid isPermaLink="false">2505.24025v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Modal View Enhanced Large Vision Models for Long-Term Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2505.24003v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DMMV的新颖的多模态视图框架，用于长期时间序列预测（LTSF）。该框架利用趋势季节分解和基于自适应分解的新型回溯残差，以集成多模态视图，并在多个数据集上优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;时间序列数据可以以多种形式表示，如图像和文本，从而提供多模态视图（MMVs）。这些视图可以揭示互补模式，并允许使用预训练的大型模型（如LVMs）进行LTSF。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效利用LVMs进行LTSF的新方法，同时克服LVMs的归纳偏差。&lt;h4&gt;方法&lt;/h4&gt;DMMV通过趋势季节分解和自适应分解，结合多模态视图来提高LTSF的性能。&lt;h4&gt;主要发现&lt;/h4&gt;与14个最先进的模型相比，DMMV在6个基准数据集上取得了最佳均方误差（MSE），表明其在LTSF中的优越性。&lt;h4&gt;结论&lt;/h4&gt;DMMV是一种有效的方法，可以提高LTSF的准确性，并在多个数据集上优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：时间序列，通常表示为数值序列，也可以转换为图像和文本，从而提供对同一底层信号的多模态视图（MMVs）。这些MMVs可以揭示互补模式，并允许使用强大的预训练大型模型，如大型视觉模型（LVMs），进行长期时间序列预测（LTSF）。然而，正如我们在这项工作中所确定的，将LVMs应用于LTSF会导致“预测期”的归纳偏差。为了利用这种偏差，我们提出了一种基于分解的多模态视图框架DMMV，它利用趋势季节分解和基于回溯残差的自适应分解来集成MMVs进行LTSF。与14个最先进的（SOTA）模型在多个数据集上的比较评估表明，DMMV优于单视图和现有的多模态基线，在8个基准数据集中的6个上实现了最佳的均方误差（MSE）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series, typically represented as numerical sequences, can also betransformed into images and texts, offering multi-modal views (MMVs) of thesame underlying signal. These MMVs can reveal complementary patterns and enablethe use of powerful pre-trained large models, such as large vision models(LVMs), for long-term time series forecasting (LTSF). However, as we identifiedin this work, applying LVMs to LTSF poses an inductive bias towards"forecasting periods". To harness this bias, we propose DMMV, a noveldecomposition-based multi-modal view framework that leverages trend-seasonaldecomposition and a novel backcast residual based adaptive decomposition tointegrate MMVs for LTSF. Comparative evaluations against 14 state-of-the-art(SOTA) models across diverse datasets show that DMMV outperforms single-viewand existing multi-modal baselines, achieving the best mean squared error (MSE)on 6 out of 8 benchmark datasets.</description>
      <author>example@mail.com (ChengAo Shen, Wenchao Yu, Ziming Zhao, Dongjin Song, Wei Cheng, Haifeng Chen, Jingchao Ni)</author>
      <guid isPermaLink="false">2505.24003v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Simplifying Bayesian Optimization Via In-Context Direct Optimum Sampling</title>
      <link>http://arxiv.org/abs/2505.23913v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对昂贵黑盒函数优化的完全零样本解决方案，无需使用代理模型或获取函数优化。&lt;h4&gt;背景&lt;/h4&gt;在科学和工程领域，优化昂贵的黑盒函数是一个普遍问题，常用的解决方案是贝叶斯优化（BO），它通常包括代理模型和获取函数两部分。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需代理模型拟合或获取函数优化的贝叶斯优化（BO）方法。&lt;h4&gt;方法&lt;/h4&gt;使用预训练的深度生成模型直接从最优点的后验分布中进行采样。&lt;h4&gt;主要发现&lt;/h4&gt;该方法与Thompson抽样等价，并在一系列真实世界基准测试中展示了其能力和成本效益。与基于高斯过程的BO相比，该方法在墙钟时间上实现了超过35倍的效率提升，使得高效的并行和分布式BO成为可能。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效地进行高吞吐量的优化，并且无需进行代理模型或获取函数的优化，从而提高了贝叶斯优化的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The optimization of expensive black-box functions is ubiquitous in scienceand engineering. A common solution to this problem is Bayesian optimization(BO), which is generally comprised of two components: (i) a surrogate model and(ii) an acquisition function, which generally require expensive re-training andoptimization steps at each iteration, respectively. Although recent workenabled in-context surrogate models that do not require re-training, virtuallyall existing BO methods still require acquisition function maximization toselect the next observation, which introduces many knobs to tune, such as MonteCarlo samplers and multi-start optimizers. In this work, we propose acompletely in-context, zero-shot solution for BO that does not requiresurrogate fitting or acquisition function optimization. This is done by using apre-trained deep generative model to directly sample from the posterior overthe optimum point. We show that this process is equivalent to Thompson samplingand demonstrate the capabilities and cost-effectiveness of our foundation modelon a suite of real-world benchmarks. We achieve an efficiency gain of more than35x in terms of wall-clock time when compared with Gaussian process-based BO,enabling efficient parallel and distributed BO, e.g., for high-throughputoptimization.</description>
      <author>example@mail.com (Gustavo Sutter Pessurno de Carvalho, Mohammed Abdulrahman, Hao Wang, Sriram Ganapathi Subramanian, Marc St-Aubin, Sharon O'Sullivan, Lawrence Wan, Luis Ricardez-Sandoval, Pascal Poupart, Agustinus Kristiadi)</author>
      <guid isPermaLink="false">2505.23913v1</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Point Cloud Completion through Unbalanced Optimal Transport</title>
      <link>http://arxiv.org/abs/2410.02671v4</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为UOT-UPC的模型，用于解决无配对点云补全问题，该模型通过学习无配对的不完整和完整点云数据之间的补全映射，避免了依赖于配对数据集。&lt;h4&gt;背景&lt;/h4&gt;无配对点云补全对于现实世界的应用至关重要，因为在这种情况下，完整的点云的真实数据往往不可用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，即UOT-UPC模型，以解决无配对点云补全问题。&lt;h4&gt;方法&lt;/h4&gt;UOT-UPC模型将无配对补全任务公式化为（不平衡）最优传输（OT）问题，并使用神经OT模型通过神经网络学习UOT映射。&lt;h4&gt;主要发现&lt;/h4&gt;UOT-UPC模型是第一个尝试利用UOT进行无配对点云补全的模型，在单类别和多类别基准测试中都取得了具有竞争力或优越的性能。特别是，该方法在处理类别不平衡问题时表现出特别鲁棒，这在现实世界的无配对点云补全场景中经常遇到。&lt;h4&gt;结论&lt;/h4&gt;UOT-UPC模型能够有效地解决无配对点云补全问题，并在实际应用中表现出良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：无配对点云补全是现实应用中的关键，因为完整的点云的真实数据通常不可用。通过从无配对的不完整和完整点云数据中学习补全映射，这项任务避免了依赖于配对数据集。在本文中，我们提出了名为无平衡最优传输映射用于无配对点云补全（UOT-UPC）的模型，该模型将无配对补全任务定义为（不平衡）最优传输（OT）问题。我们的方法采用了一个神经OT模型，使用神经网络学习UOT映射。我们的模型是第一个尝试利用UOT进行无配对点云补全的尝试，在单类别和多类别基准测试中均取得了具有竞争力或优越的性能。特别是，我们的方法在处理类别不平衡问题时表现出特别鲁棒，这在现实世界的无配对点云补全场景中经常遇到。代码可在https://github.com/LEETK99/UOT-UPC获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unpaired point cloud completion is crucial for real-world applications, whereground-truth data for complete point clouds are often unavailable. By learninga completion map from unpaired incomplete and complete point cloud data, thistask avoids the reliance on paired datasets. In this paper, we propose the\textit{Unbalanced Optimal Transport Map for Unpaired Point Cloud Completion(\textbf{UOT-UPC})} model, which formulates the unpaired completion task as the(Unbalanced) Optimal Transport (OT) problem. Our method employs a Neural OTmodel learning the UOT map using neural networks. Our model is the firstattempt to leverage UOT for unpaired point cloud completion, achievingcompetitive or superior performance on both single-category and multi-categorybenchmarks. In particular, our approach is especially robust under the classimbalance problem, which is frequently encountered in real-world unpaired pointcloud completion scenarios. The code is available athttps://github.com/LEETK99/UOT-UPC.</description>
      <author>example@mail.com (Taekyung Lee, Jaemoo Choi, Jaewoong Choi, Myungjoo Kang)</author>
      <guid isPermaLink="false">2410.02671v4</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>CAD-Coder: Text-to-CAD Generation with Chain-of-Thought and Geometric Reward</title>
      <link>http://arxiv.org/abs/2505.19713v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为CAD-Coder的新型框架，将文本到CAD的转换重新定义为生成基于Python的参数化CAD语言CadQuery脚本。该框架实现了直接的几何验证、丰富的建模词汇和与现有LLMs的无缝集成。&lt;h4&gt;背景&lt;/h4&gt;为了提高代码的有效性和几何精度，提出了一种两阶段学习流程：第一阶段是监督微调配对的文本-CadQuery数据，第二阶段是使用包含几何奖励（Chamfer距离）和格式奖励的CAD特定奖励的Group Reward Policy Optimization（GRPO）强化学习。&lt;h4&gt;目的&lt;/h4&gt;目的是开发一个能够从自然语言直接生成多样化、有效和复杂CAD模型的框架，以推进文本到CAD生成和几何推理的当前技术水平。&lt;h4&gt;方法&lt;/h4&gt;提出了一个思维链（CoT）规划过程来提高模型的推理能力，并构建了一个包含110K个文本-CadQuery-3D模型三元组和1.5K个CoT样本的大规模、高质量数据集。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，CAD-Coder能够使LLMs直接从自然语言生成多样化的、有效的和复杂的CAD模型。&lt;h4&gt;结论&lt;/h4&gt;CAD-Coder框架显著提升了文本到CAD的生成和几何推理能力，为相关领域的研究提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we introduce CAD-Coder, a novel framework that reformulates text-to-CAD as the generation of CadQuery scripts - a Python-based, parametricCAD language. This representation enables direct geometric validation, a richer modeling vocabulary, and seamless integration with existing LLMs. To further enhance code validity and geometric fidelity, we propose a two-stage learning pipeline: (1) supervised fine-tuning on paired text-CadQuery data, and (2) reinforcement learning with Group Reward Policy Optimization (GRPO), guided by a CAD-specific reward comprising both a geometric reward (Chamfer Distance) and a format reward. We also introduce a chain-of-thought (CoT) planning process to improve model reasoning, and construct a large-scale, high-quality dataset of 110K text-CadQuery-3D model triplets and 1.5K CoT samples via an automated pipeline. Extensive experiments demonstrate that CAD-Coder enables LLMs to generate diverse, valid, and complex CAD models directly from natural language, advancing the state of the art of text-to-CAD generation and geometric reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we introduce CAD-Coder, a novel framework that reformulatestext-to-CAD as the generation of CadQuery scripts - a Python-based, parametricCAD language. This representation enables direct geometric validation, a richermodeling vocabulary, and seamless integration with existing LLMs. To furtherenhance code validity and geometric fidelity, we propose a two-stage learningpipeline: (1) supervised fine-tuning on paired text-CadQuery data, and (2)reinforcement learning with Group Reward Policy Optimization (GRPO), guided bya CAD-specific reward comprising both a geometric reward (Chamfer Distance) anda format reward. We also introduce a chain-of-thought (CoT) planning process toimprove model reasoning, and construct a large-scale, high-quality dataset of110K text-CadQuery-3D model triplets and 1.5K CoT samples via an automatedpipeline. Extensive experiments demonstrate that CAD-Coder enables LLMs togenerate diverse, valid, and complex CAD models directly from natural language,advancing the state of the art of text-to-CAD generation and geometricreasoning.</description>
      <author>example@mail.com (Yandong Guan, Xilin Wang, Xingxi Ming, Jing Zhang, Dong Xu, Qian Yu)</author>
      <guid isPermaLink="false">2505.19713v2</guid>
      <pubDate>Mon, 02 Jun 2025 14:29:20 +0800</pubDate>
    </item>
    <item>
      <title>Spatial-MLLM: Boosting MLLM Capabilities in Visual-based Spatial Intelligence</title>
      <link>http://arxiv.org/abs/2505.23747v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Spatial-MLLM的新框架，用于从纯2D观察中进行基于视觉的空间推理，显著提升了MLLM在2D视觉任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管多模态大型语言模型（MLLMs）在2D视觉任务上的性能有所提升，但提高其空间智能仍是一大挑战。现有的3D MLLMs通常依赖额外的3D或2.5D数据来融入空间意识，限制了它们在仅包含2D输入（如图像或视频）的场景中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种从纯2D观察中进行视觉基础空间推理的新框架，以解决MLLMs在空间智能方面的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种双编码器架构：一个预训练的2D视觉编码器用于提取语义特征，一个从视觉几何模型主干初始化的空间编码器用于提取3D结构特征。然后通过一个连接器将这两个特征整合为统一的视觉标记，以增强空间理解。此外，还提出了一种空间感知的帧采样策略，在推理时选择视频序列中具有空间信息的帧，确保在有限的标记长度下，模型专注于对空间推理至关重要的帧。&lt;h4&gt;主要发现&lt;/h4&gt;Spatial-MLLM在多种真实世界数据集上的实验表明，该模型在基于视觉的空间理解和推理任务中达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;Spatial-MLLM通过创新的架构和策略，显著提升了MLLM在空间智能方面的表现，为解决MLLMs在处理2D输入时的空间智能挑战提供了一种新的思路。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have significantly enhanced performance on 2D visual tasks. However, improving their spatial intelligence remains a challenge. Existing 3D MLLMs always rely on additional 3D or 2.5D data to incorporate spatial awareness, restricting their utility in scenarios with only 2D inputs, such as images or videos. In this paper, we present Spatial-MLLM, a novel framework for visual-based spatial reasoning from purely 2D observations. Unlike conventional video MLLMs which rely on CLIP-based visual encoders optimized for semantic understanding, our key insight is to unleash the strong structure prior from the feed-forward visual geometry foundation model. Specifically, we propose a dual-encoder architecture: a pretrained 2D visual encoder to extract semantic features, and a spatial encoder-initialized from the backbone of the visual geometry model-to extract 3D structure features. A connector then integrates both features into unified visual tokens for enhanced spatial understanding. Furthermore, we propose a space-aware frame sampling strategy at inference time, which selects the spatially informative frames of a video sequence, ensuring that even under limited token length, the model focuses on frames critical for spatial reasoning. Beyond architecture improvements, we construct the Spatial-MLLM-120k dataset and train the model on it using supervised fine-tuning and GRPO. Extensive experiments on various real-world datasets demonstrate that our spatial-MLLM achieves state-of-the-art performance in a wide range of visual-based spatial understanding and reasoning tasks. Project page: https://diankun-wu.github.io/Spatial-MLLM/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Multimodal Large Language Models (MLLMs) havesignificantly enhanced performance on 2D visual tasks. However, improving theirspatial intelligence remains a challenge. Existing 3D MLLMs always rely onadditional 3D or 2.5D data to incorporate spatial awareness, restricting theirutility in scenarios with only 2D inputs, such as images or videos. In thispaper, we present Spatial-MLLM, a novel framework for visual-based spatialreasoning from purely 2D observations. Unlike conventional video MLLMs whichrely on CLIP-based visual encoders optimized for semantic understanding, ourkey insight is to unleash the strong structure prior from the feed-forwardvisual geometry foundation model. Specifically, we propose a dual-encoderarchitecture: a pretrained 2D visual encoder to extract semantic features, anda spatial encoder-initialized from the backbone of the visual geometry model-toextract 3D structure features. A connector then integrates both features intounified visual tokens for enhanced spatial understanding. Furthermore, wepropose a space-aware frame sampling strategy at inference time, which selectsthe spatially informative frames of a video sequence, ensuring that even underlimited token length, the model focuses on frames critical for spatialreasoning. Beyond architecture improvements, we construct the Spatial-MLLM-120kdataset and train the model on it using supervised fine-tuning and GRPO.Extensive experiments on various real-world datasets demonstrate that ourspatial-MLLM achieves state-of-the-art performance in a wide range ofvisual-based spatial understanding and reasoning tasks. Project page:https://diankun-wu.github.io/Spatial-MLLM/.</description>
      <author>example@mail.com (Diankun Wu, Fangfu Liu, Yi-Hsin Hung, Yueqi Duan)</author>
      <guid isPermaLink="false">2505.23747v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
  <item>
      <title>FMG-Det: Foundation Model Guided Robust Object Detection</title>
      <link>http://arxiv.org/abs/2505.23726v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, ICIP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了FMG-Det方法，用于在存在噪声标注的情况下训练模型，该方法结合了多实例学习框架和预处理流程，以提高检测器性能。&lt;h4&gt;背景&lt;/h4&gt;由于对物体边界标注的主观性，收集高质量的数据对于目标检测任务是一项挑战。标注的不一致性使得验证标注变得困难，且在物体边界部分可见或模糊的情况下，这个问题更加严重。噪声标注会显著降低检测器的性能，尤其在少样本设置中，少量损坏的标注就能影响模型性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单、高效的方法，用于在存在噪声标注的情况下训练模型，以解决标注一致性和验证的问题。&lt;h4&gt;方法&lt;/h4&gt;提出FMG-Det方法，该方法结合了多实例学习（MIL）框架和预处理流程，利用强大的基础模型在训练前纠正标签，并对检测器头部进行轻微修改。&lt;h4&gt;主要发现&lt;/h4&gt;FMG-Det方法在多个数据集上，无论是标准场景还是少样本场景，都实现了最先进的性能，同时比其他方法简单且高效。&lt;h4&gt;结论&lt;/h4&gt;FMG-Det方法是一种有效处理噪声标注的简单且高效的方法，能够显著提高检测器的性能。&lt;h4&gt;翻译&lt;/h4&gt;Collecting high quality data for object detection tasks is challenging due to the inherent subjectivity in labeling the boundaries of an object. This makes it difficult to not only collect consistent annotations across a dataset but also to validate them, as no two annotators are likely to label the same object using the exact same coordinates. These challenges are further compounded when object boundaries are partially visible or blurred, which can be the case in many domains. Training on noisy annotations significantly degrades detector performance, rendering them unusable, particularly in few-shot settings, where just a few corrupted annotations can impact model performance. In this work, we propose FMG-Det, a simple, efficient methodology for training models with noisy annotations. More specifically, we propose combining a multiple instance learning (MIL) framework with a pre-processing pipeline that leverages powerful foundation models to correct labels prior to training. This pre-processing pipeline, along with slight modifications to the detector head, results in state-of-the-art performance across a number of datasets, for both standard and few-shot scenarios, while being much simpler and more efficient than other approaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Collecting high quality data for object detection tasks is challenging due tothe inherent subjectivity in labeling the boundaries of an object. This makesit difficult to not only collect consistent annotations across a dataset butalso to validate them, as no two annotators are likely to label the same objectusing the exact same coordinates. These challenges are further compounded whenobject boundaries are partially visible or blurred, which can be the case inmany domains. Training on noisy annotations significantly degrades detectorperformance, rendering them unusable, particularly in few-shot settings, wherejust a few corrupted annotations can impact model performance. In this work, wepropose FMG-Det, a simple, efficient methodology for training models with noisyannotations. More specifically, we propose combining a multiple instancelearning (MIL) framework with a pre-processing pipeline that leverages powerfulfoundation models to correct labels prior to training. This pre-processingpipeline, along with slight modifications to the detector head, results instate-of-the-art performance across a number of datasets, for both standard andfew-shot scenarios, while being much simpler and more efficient than otherapproaches.</description>
      <author>example@mail.com (Darryl Hannan, Timothy Doster, Henry Kvinge, Adam Attarian, Yijing Watkins)</author>
      <guid isPermaLink="false">2505.23726v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Rooms from Motion: Un-posed Indoor 3D Object Detection as Localization and Mapping</title>
      <link>http://arxiv.org/abs/2505.23756v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文重新审视了基于场景的3D物体检测，通过一个以物体为中心的框架，结合定位和地图构建功能，使用3D方向盒作为基础几何元素。该方法在未进行姿态调整的图像集合上操作，通过改进结构从运动中的标准2D关键点匹配器，实现了基于图像导出的3D盒子的物体中心匹配器，从而估计了度量相机姿态、物体轨迹，并最终生成全局语义3D物体地图。&lt;h4&gt;背景&lt;/h4&gt;现有的3D物体检测方法在全局范围内操作，并隐式依赖于先验存在的度量相机姿态。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为Rooms from Motion（RfM）的方法，以改善场景级3D物体检测的性能。&lt;h4&gt;方法&lt;/h4&gt;RfM通过使用基于图像导出的3D盒子的物体中心匹配器来代替标准2D关键点匹配器，并在未进行姿态调整的图像集合上操作，从而估计度量相机姿态、物体轨迹，并生成全局语义3D物体地图。&lt;h4&gt;主要发现&lt;/h4&gt;RfM在CA-1M和ScanNet++数据集上展示了强大的定位性能，并产生了比领先的基于点和多视图的3D物体检测方法更高质量的地图。&lt;h4&gt;结论&lt;/h4&gt;RfM实现了一种通用的以物体为中心的表示，不仅扩展了Cubify Anything的工作到完整场景，还允许进行本质上的稀疏定位和与场景中物体数量成比例的参数化地图构建。&lt;h4&gt;翻译&lt;/h4&gt;我们重新审视了场景级3D物体检测作为以物体为中心的框架的输出，该框架能够进行定位和映射，使用3D定向盒作为基础几何元素。虽然现有的3D物体检测方法在全局范围内操作，并且隐式依赖于先验存在的度量相机姿态，但我们的方法，即运动中的房间（RfM），在未进行姿态调整的图像集合上操作。通过用基于图像导出的3D盒子的物体中心匹配器替换标准2D关键点匹配的结构从运动，我们估计了度量相机姿态、物体轨迹，并最终生成全局语义3D物体地图。当先验姿态可用时，我们可以通过针对个别观测的全球3D盒子的优化来显著提高地图质量。RfM显示出强大的定位性能，并且随后在CA-1M和ScanNet++上产生了比领先基于点和多视图的3D物体检测方法更高质量的地图，尽管这些全局方法依赖于通过点云或密集体实现的过度参数化。运动中的房间（RfM）实现了一种通用的以物体为中心的表示，不仅扩展了Cubify Anything的工作到完整场景，还允许进行本质上的稀疏定位和与场景中物体数量成比例的参数化地图构建。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We revisit scene-level 3D object detection as the output of an object-centricframework capable of both localization and mapping using 3D oriented boxes asthe underlying geometric primitive. While existing 3D object detectionapproaches operate globally and implicitly rely on the a priori existence ofmetric camera poses, our method, Rooms from Motion (RfM) operates on acollection of un-posed images. By replacing the standard 2D keypoint-basedmatcher of structure-from-motion with an object-centric matcher based onimage-derived 3D boxes, we estimate metric camera poses, object tracks, andfinally produce a global, semantic 3D object map. When a priori pose isavailable, we can significantly improve map quality through optimization ofglobal 3D boxes against individual observations. RfM shows strong localizationperformance and subsequently produces maps of higher quality than leadingpoint-based and multi-view 3D object detection methods on CA-1M and ScanNet++,despite these global methods relying on overparameterization through pointclouds or dense volumes. Rooms from Motion achieves a general, object-centricrepresentation which not only extends the work of Cubify Anything to fullscenes but also allows for inherently sparse localization and parametricmapping proportional to the number of objects in a scene.</description>
      <author>example@mail.com (Justin Lazarow, Kai Kang, Afshin Dehghan)</author>
      <guid isPermaLink="false">2505.23756v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>To Trust Or Not To Trust Your Vision-Language Model's Prediction</title>
      <link>http://arxiv.org/abs/2505.23745v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TrustVLM是一个无监督框架，旨在解决视觉语言模型（VLMs）在多模态理解和生成中的预测可信度问题。&lt;h4&gt;背景&lt;/h4&gt;VLMs在视觉和文本模态的对齐方面表现出色，但在零样本和迁移学习场景中易受误分类影响，存在安全风险。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架来估计VLM的预测何时可信，以提高模型在关键领域的可靠性。&lt;h4&gt;方法&lt;/h4&gt;利用模态间隙和图像嵌入空间中的概念表示，提出一个新颖的置信度评分函数。&lt;h4&gt;主要发现&lt;/h4&gt;在17个不同的数据集上评估，与现有基准相比，在AURC、AUROC和FPR95上分别提高了51.87%、9.14%和32.42%。&lt;h4&gt;结论&lt;/h4&gt;TrustVLM通过提高模型的可信度而不需要重新训练，为VLMs在现实世界应用中的安全部署铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;Vision-Language Models (VLMs) have demonstrated strong capabilities in aligning visual and textual modalities, enabling a wide range of applications in multimodal understanding and generation. While they excel in zero-shot and transfer learning scenarios, VLMs remain susceptible to misclassification, often yielding confident yet incorrect predictions. This limitation poses a significant risk in safety-critical domains, where erroneous predictions can lead to severe consequences. In this work, we introduce TrustVLM, a training-free framework designed to address the critical challenge of estimating when VLM's predictions can be trusted. Motivated by the observed modality gap in VLMs and the insight that certain concepts are more distinctly represented in the image embedding space, we propose a novel confidence-scoring function that leverages this space to improve misclassification detection. We rigorously evaluate our approach across 17 diverse datasets, employing 4 architectures and 2 VLMs, and demonstrate state-of-the-art performance, with improvements of up to 51.87% in AURC, 9.14% in AUROC, and 32.42% in FPR95 compared to existing baselines. By improving the reliability of the model without requiring retraining, TrustVLM paves the way for safer deployment of VLMs in real-world applications. The code will be available at https://github.com/EPFL-IMOS/TrustVLM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Models (VLMs) have demonstrated strong capabilities inaligning visual and textual modalities, enabling a wide range of applicationsin multimodal understanding and generation. While they excel in zero-shot andtransfer learning scenarios, VLMs remain susceptible to misclassification,often yielding confident yet incorrect predictions. This limitation poses asignificant risk in safety-critical domains, where erroneous predictions canlead to severe consequences. In this work, we introduce TrustVLM, atraining-free framework designed to address the critical challenge ofestimating when VLM's predictions can be trusted. Motivated by the observedmodality gap in VLMs and the insight that certain concepts are more distinctlyrepresented in the image embedding space, we propose a novel confidence-scoringfunction that leverages this space to improve misclassification detection. Werigorously evaluate our approach across 17 diverse datasets, employing 4architectures and 2 VLMs, and demonstrate state-of-the-art performance, withimprovements of up to 51.87% in AURC, 9.14% in AUROC, and 32.42% in FPR95compared to existing baselines. By improving the reliability of the modelwithout requiring retraining, TrustVLM paves the way for safer deployment ofVLMs in real-world applications. The code will be available athttps://github.com/EPFL-IMOS/TrustVLM.</description>
      <author>example@mail.com (Hao Dong, Moru Liu, Jian Liang, Eleni Chatzi, Olga Fink)</author>
      <guid isPermaLink="false">2505.23745v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>EmotionRankCLAP: Bridging Natural Language Speaking Styles and Ordinal Speech Emotion via Rank-N-Contrast</title>
      <link>http://arxiv.org/abs/2505.23732v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EmotionRankCLAP的监督对比学习方法，旨在解决当前基于情感的语言-音频预训练方法中存在的不足，如无法捕捉情感顺序性、跨模态对齐不足等问题。&lt;h4&gt;背景&lt;/h4&gt;现有的情感对比语言-音频预训练方法通常通过简单地对音频样本与对应的文本提示进行对齐来学习，这导致无法捕捉情感的顺序性，影响了跨情感的理解，并且由于对齐不足，音频和文本嵌入之间存在较大的模态差距。&lt;h4&gt;目的&lt;/h4&gt;提出EmotionRankCLAP方法，旨在通过使用情感语音和自然语言提示的维度属性，联合捕捉细粒度的情感变化，并提高跨模态对齐。&lt;h4&gt;方法&lt;/h4&gt;该方法利用Rank-N-Contrast目标，通过对比样本在效价-唤醒空间中的排名来学习有序关系。&lt;h4&gt;主要发现&lt;/h4&gt;EmotionRankCLAP在跨模态检索任务中，通过建模情感顺序性，在情感对比语言-音频预训练方法中表现优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;EmotionRankCLAP是一种有效的情感对比学习方法，能够提高跨模态对齐，并更好地捕捉情感的顺序性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current emotion-based contrastive language-audio pretraining (CLAP) methodstypically learn by na\"ively aligning audio samples with corresponding textprompts. Consequently, this approach fails to capture the ordinal nature ofemotions, hindering inter-emotion understanding and often resulting in a widemodality gap between the audio and text embeddings due to insufficientalignment. To handle these drawbacks, we introduce EmotionRankCLAP, asupervised contrastive learning approach that uses dimensional attributes ofemotional speech and natural language prompts to jointly capture fine-grainedemotion variations and improve cross-modal alignment. Our approach utilizes aRank-N-Contrast objective to learn ordered relationships by contrasting samplesbased on their rankings in the valence-arousal space. EmotionRankCLAPoutperforms existing emotion-CLAP methods in modeling emotion ordinality acrossmodalities, measured via a cross-modal retrieval task.</description>
      <author>example@mail.com (Shreeram Suresh Chandra, Lucas Goncalves, Junchen Lu, Carlos Busso, Berrak Sisman)</author>
      <guid isPermaLink="false">2505.23732v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>DeepChest: Dynamic Gradient-Free Task Weighting for Effective Multi-Task Learning in Chest X-ray Classification</title>
      <link>http://arxiv.org/abs/2505.23595v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DeepChest的动态任务权重框架，用于多标签胸部X射线（CXR）分类，旨在解决多任务学习（MTL）中任务权重平衡的问题。&lt;h4&gt;背景&lt;/h4&gt;在复杂领域如医学影像中，多任务学习（MTL）通过共享表示学习具有固有优势，但有效平衡任务贡献仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出DeepChest框架，以提高多标签胸部X射线（CXR）分类的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;DeepChest利用基于任务特定损失趋势的有效分析的性能驱动权重机制，无需梯度访问即可自适应调整任务重要性，从而显著减少内存使用并提高训练速度。&lt;h4&gt;主要发现&lt;/h4&gt;DeepChest在整体准确率上优于现有的MTL方法7%，同时显著降低了单个任务损失，表明了改进的泛化能力和有效缓解了负迁移。&lt;h4&gt;结论&lt;/h4&gt;DeepChest的效率和性能提升为在关键医疗诊断应用中更实用和稳健地部署深度学习铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;While Multi-Task Learning (MTL) offers inherent advantages in complex domains such as medical imaging by enabling shared representation learning, effectively balancing task contributions remains a significant challenge. This paper addresses this critical issue by introducing DeepChest, a novel, computationally efficient and effective dynamic task-weighting framework specifically designed for multi-label chest X-ray (CXR) classification. Unlike existing heuristic or gradient-based methods that often incur substantial overhead, DeepChest leverages a performance-driven weighting mechanism based on effective analysis of task-specific loss trends. Given a network architecture (e.g., ResNet18), our model-agnostic approach adaptively adjusts task importance without requiring gradient access, thereby significantly reducing memory usage and achieving a threefold increase in training speed. It can be easily applied to improve various state-of-the-art methods. Extensive experiments on a large-scale CXR dataset demonstrate that DeepChest not only outperforms state-of-the-art MTL methods by 7% in overall accuracy but also yields substantial reductions in individual task losses, indicating improved generalization and effective mitigation of negative transfer. The efficiency and performance gains of DeepChest pave the way for more practical and robust deployment of deep learning in critical medical diagnostic applications. The code is publicly available at https://github.com/youssefkhalil320/DeepChest-MTL&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While Multi-Task Learning (MTL) offers inherent advantages in complex domainssuch as medical imaging by enabling shared representation learning, effectivelybalancing task contributions remains a significant challenge. This paperaddresses this critical issue by introducing DeepChest, a novel,computationally efficient and effective dynamic task-weighting frameworkspecifically designed for multi-label chest X-ray (CXR) classification. Unlikeexisting heuristic or gradient-based methods that often incur substantialoverhead, DeepChest leverages a performance-driven weighting mechanism based oneffective analysis of task-specific loss trends. Given a network architecture(e.g., ResNet18), our model-agnostic approach adaptively adjusts taskimportance without requiring gradient access, thereby significantly reducingmemory usage and achieving a threefold increase in training speed. It can beeasily applied to improve various state-of-the-art methods. Extensiveexperiments on a large-scale CXR dataset demonstrate that DeepChest not onlyoutperforms state-of-the-art MTL methods by 7% in overall accuracy but alsoyields substantial reductions in individual task losses, indicating improvedgeneralization and effective mitigation of negative transfer. The efficiencyand performance gains of DeepChest pave the way for more practical and robustdeployment of deep learning in critical medical diagnostic applications. Thecode is publicly available at https://github.com/youssefkhalil320/DeepChest-MTL</description>
      <author>example@mail.com (Youssef Mohamed, Noran Mohamed, Khaled Abouhashad, Feilong Tang, Sara Atito, Shoaib Jameel, Imran Razzak, Ahmed B. Zaky)</author>
      <guid isPermaLink="false">2505.23595v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>VideoREPA: Learning Physics for Video Generation through Relational Alignment with Foundation Models</title>
      <link>http://arxiv.org/abs/2505.23656v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为VideoREPA的新型框架，用于提升文本到视频（T2V）模型的物理理解能力，从而实现更符合物理规律的视频生成。&lt;h4&gt;背景&lt;/h4&gt;现有的T2V模型在生成物理上合理的视频内容方面存在困难，因为它们在理解物理方面的能力有限。&lt;h4&gt;目的&lt;/h4&gt;通过从视频理解基础模型中提取物理理解能力，提升T2V模型的物理理解能力，实现更符合物理的视频生成。&lt;h4&gt;方法&lt;/h4&gt;VideoREPA通过Token Relation Distillation（TRD）损失函数，利用时空对齐为微调强大的预训练T2V模型提供软指导，这是与之前表示对齐（REPA）方法的关键区别。&lt;h4&gt;主要发现&lt;/h4&gt;VideoREPA显著提高了基线方法CogVideoX的物理常识，在相关基准测试中实现了显著改进，并显示出生成符合直观物理的视频的强大能力。&lt;h4&gt;结论&lt;/h4&gt;VideoREPA是第一个专为微调T2V模型设计的REPA方法，并且专门用于注入物理知识。&lt;h4&gt;翻译&lt;/h4&gt;Recent advancements in text-to-video (T2V) diffusion models have enabled high-fidelity and realistic video synthesis. However, current T2V models often struggle to generate physically plausible content due to their limited inherent ability to accurately understand physics. We found that while the representations within T2V models possess some capacity for physics understanding, they lag significantly behind those from recent video self-supervised learning methods. To this end, we propose a novel framework called VideoREPA, which distills physics understanding capability from video understanding foundation models into T2V models by aligning token-level relations. This closes the physics understanding gap and enables more physics-plausible generation. Specifically, we introduce the Token Relation Distillation (TRD) loss, leveraging spatio-temporal alignment to provide soft guidance suitable for finetuning powerful pre-trained T2V models, a critical departure from prior representation alignment (REPA) methods. To our knowledge, VideoREPA is the first REPA method designed for finetuning T2V models and specifically for injecting physical knowledge. Empirical evaluations show that VideoREPA substantially enhances the physics commonsense of baseline method, CogVideoX, achieving significant improvement on relevant benchmarks and demonstrating a strong capacity for generating videos consistent with intuitive physics. More video results are available at https://videorepa.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in text-to-video (T2V) diffusion models have enabledhigh-fidelity and realistic video synthesis. However, current T2V models oftenstruggle to generate physically plausible content due to their limited inherentability to accurately understand physics. We found that while therepresentations within T2V models possess some capacity for physicsunderstanding, they lag significantly behind those from recent videoself-supervised learning methods. To this end, we propose a novel frameworkcalled VideoREPA, which distills physics understanding capability from videounderstanding foundation models into T2V models by aligning token-levelrelations. This closes the physics understanding gap and enable morephysics-plausible generation. Specifically, we introduce the Token RelationDistillation (TRD) loss, leveraging spatio-temporal alignment to provide softguidance suitable for finetuning powerful pre-trained T2V models, a criticaldeparture from prior representation alignment (REPA) methods. To our knowledge,VideoREPA is the first REPA method designed for finetuning T2V models andspecifically for injecting physical knowledge. Empirical evaluations show thatVideoREPA substantially enhances the physics commonsense of baseline method,CogVideoX, achieving significant improvement on relevant benchmarks anddemonstrating a strong capacity for generating videos consistent with intuitivephysics. More video results are available at https://videorepa.github.io/.</description>
      <author>example@mail.com (Xiangdong Zhang, Jiaqi Liao, Shaofeng Zhang, Fanqing Meng, Xiangpeng Wan, Junchi Yan, Yu Cheng)</author>
      <guid isPermaLink="false">2505.23656v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>CLDTracker: A Comprehensive Language Description for Visual Tracking</title>
      <link>http://arxiv.org/abs/2505.23704v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  47 pages, 9 figures, Information Fusion Journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CLDTracker的新型视觉跟踪框架，用于解决视频目标跟踪（VOT）中的挑战。&lt;h4&gt;背景&lt;/h4&gt;VOT在计算机视觉中是一个基本但具有挑战性的任务，由于动态外观变化、遮挡和背景杂乱等问题。&lt;h4&gt;目的&lt;/h4&gt;提出CLDTracker以解决传统跟踪器在复杂场景中的局限性，并充分发挥视觉语言模型（VLMs）在VOT中的潜力。&lt;h4&gt;方法&lt;/h4&gt;CLDTracker采用双分支架构，包括文本分支和视觉分支。文本分支利用VLMs如CLIP和GPT-4V生成丰富的文本描述，并通过语义和上下文线索增强。&lt;h4&gt;主要发现&lt;/h4&gt;在六个标准VOT基准上的实验表明，CLDTracker实现了最先进的性能，验证了利用鲁棒和时态自适应的视觉语言表示进行跟踪的有效性。&lt;h4&gt;结论&lt;/h4&gt;CLDTracker为VOT提供了一种有效的解决方案，并公开了代码和模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; VOT remains a fundamental yet challenging task in computer vision due todynamic appearance changes, occlusions, and background clutter. Traditionaltrackers, relying primarily on visual cues, often struggle in such complexscenarios. Recent advancements in VLMs have shown promise in semanticunderstanding for tasks like open-vocabulary detection and image captioning,suggesting their potential for VOT. However, the direct application of VLMs toVOT is hindered by critical limitations: the absence of a rich andcomprehensive textual representation that semantically captures the targetobject's nuances, limiting the effective use of language information;inefficient fusion mechanisms that fail to optimally integrate visual andtextual features, preventing a holistic understanding of the target; and a lackof temporal modeling of the target's evolving appearance in the languagedomain, leading to a disconnect between the initial description and theobject's subsequent visual changes. To bridge these gaps and unlock the fullpotential of VLMs for VOT, we propose CLDTracker, a novel ComprehensiveLanguage Description framework for robust visual Tracking. Our trackerintroduces a dual-branch architecture consisting of a textual and a visualbranch. In the textual branch, we construct a rich bag of textual descriptionsderived by harnessing the powerful VLMs such as CLIP and GPT-4V, enriched withsemantic and contextual cues to address the lack of rich textualrepresentation. Experiments on six standard VOT benchmarks demonstrate thatCLDTracker achieves SOTA performance, validating the effectiveness ofleveraging robust and temporally-adaptive vision-language representations fortracking. Code and models are publicly available at:https://github.com/HamadYA/CLDTracker</description>
      <author>example@mail.com (Mohamad Alansari, Sajid Javed, Iyyakutti Iyappan Ganapathi, Sara Alansari, Muzammal Naseer)</author>
      <guid isPermaLink="false">2505.23704v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>SeG-SR: Integrating Semantic Knowledge into Remote Sensing Image Super-Resolution via Vision-Language Model</title>
      <link>http://arxiv.org/abs/2505.23010v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SeG-SR的语义引导超分辨率框架，旨在通过利用视觉语言模型提取语义知识来提高遥感图像超分辨率性能。&lt;h4&gt;背景&lt;/h4&gt;高分辨率遥感图像在城市规划、环境监测等领域应用广泛，但实际获取的图像往往因传感器和数据传输限制而分辨率下降。现有的超分辨率方法主要关注像素层面的低级特征，忽略了遥感场景的高级理解，可能导致重建结果中出现语义不一致的伪影。&lt;h4&gt;目的&lt;/h4&gt;探索高级语义知识在提高遥感图像超分辨率性能中的作用。&lt;h4&gt;方法&lt;/h4&gt;SeG-SR框架包括语义特征提取模块（SFEM）、语义定位模块（SLM）和可学习调制模块（LMM）。SFEM利用预训练的视觉语言模型从遥感图像中提取语义知识；SLM从提取的语义知识中导出一系列语义指导；LMM使用语义指导来调制超分辨率网络提取的特征，有效地将高级场景理解融入超分辨率流程。&lt;h4&gt;主要发现&lt;/h4&gt;SeG-SR在两个数据集上实现了最先进的性能，并在各种超分辨率架构中一致地提高了性能。&lt;h4&gt;结论&lt;/h4&gt;SeG-SR框架通过引入语义知识，有效地提高了遥感图像超分辨率的效果，为遥感图像处理提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;High-resolution (HR) remote sensing imagery plays a vital role in a wide range of applications, including urban planning and environmental monitoring. However, due to limitations in sensors and data transmission links, the images acquired in practice often suffer from resolution degradation. Remote Sensing Image Super-Resolution (RSISR) aims to reconstruct HR images from low-resolution (LR) inputs, providing a cost-effective and efficient alternative to direct HR image acquisition. Existing RSISR methods primarily focus on low-level characteristics in pixel space, while neglecting the high-level understanding of remote sensing scenes. This may lead to semantically inconsistent artifacts in the reconstructed results. Motivated by this observation, our work aims to explore the role of high-level semantic knowledge in improving RSISR performance. We propose a Semantic-Guided Super-Resolution framework, SeG-SR, which leverages Vision-Language Models (VLMs) to extract semantic knowledge from input images and uses it to guide the super resolution (SR) process. Specifically, we first design a Semantic Feature Extraction Module (SFEM) that utilizes a pretrained VLM to extract semantic knowledge from remote sensing images. Next, we propose a Semantic Localization Module (SLM), which derives a series of semantic guidance from the extracted semantic knowledge. Finally, we develop a Learnable Modulation Module (LMM) that uses semantic guidance to modulate the features extracted by the SR network, effectively incorporating high-level scene understanding into the SR pipeline. We validate the effectiveness and generalizability of SeG-SR through extensive experiments: SeG-SR achieves state-of-the-art performance on two datasets and consistently delivers performance improvements across various SR architectures. Codes can be found at https://github.com/Mr-Bamboo/SeG-SR.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-resolution (HR) remote sensing imagery plays a vital role in a widerange of applications, including urban planning and environmental monitoring.However, due to limitations in sensors and data transmission links, the imagesacquired in practice often suffer from resolution degradation. Remote SensingImage Super-Resolution (RSISR) aims to reconstruct HR images fromlow-resolution (LR) inputs, providing a cost-effective and efficientalternative to direct HR image acquisition. Existing RSISR methods primarilyfocus on low-level characteristics in pixel space, while neglecting thehigh-level understanding of remote sensing scenes. This may lead tosemantically inconsistent artifacts in the reconstructed results. Motivated bythis observation, our work aims to explore the role of high-level semanticknowledge in improving RSISR performance. We propose a Semantic-GuidedSuper-Resolution framework, SeG-SR, which leverages Vision-Language Models(VLMs) to extract semantic knowledge from input images and uses it to guide thesuper resolution (SR) process. Specifically, we first design a Semantic FeatureExtraction Module (SFEM) that utilizes a pretrained VLM to extract semanticknowledge from remote sensing images. Next, we propose a Semantic LocalizationModule (SLM), which derives a series of semantic guidance from the extractedsemantic knowledge. Finally, we develop a Learnable Modulation Module (LMM)that uses semantic guidance to modulate the features extracted by the SRnetwork, effectively incorporating high-level scene understanding into the SRpipeline. We validate the effectiveness and generalizability of SeG-SR throughextensive experiments: SeG-SR achieves state-of-the-art performance on twodatasets and consistently delivers performance improvements across various SRarchitectures. Codes can be found at https://github.com/Mr-Bamboo/SeG-SR.</description>
      <author>example@mail.com (Bowen Chen, Keyan Chen, Mohan Yang, Zhengxia Zou, Zhenwei Shi)</author>
      <guid isPermaLink="false">2505.23010v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>The Meeseeks Mesh: Spatially Consistent 3D Adversarial Objects for BEV Detector</title>
      <link>http://arxiv.org/abs/2505.22499v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了3D物体检测在自动驾驶系统中的重要性，提出了一个针对真实世界攻击场景的非侵入式3D对抗物体生成方法，用于评估3D物体检测模型的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;3D物体检测是自动驾驶系统中的关键组成部分，它允许在多变的环境条件下实时识别和检测车辆、行人和障碍物。&lt;h4&gt;目的&lt;/h4&gt;为了确保3D物体检测的鲁棒性、可靠性和安全性，研究了3D对抗攻击，并评估了模型在攻击环境下的性能。&lt;h4&gt;方法&lt;/h4&gt;论文提出了生成非侵入式3D对抗物体的方法，并使用可微渲染技术来准确建模对抗物体与目标车辆之间的空间关系。此外，引入了遮挡感知模块以增强不同视角下的视觉一致性和真实性，并设计了BEV空间特征引导的优化策略以保持攻击效果。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，生成的对抗物体在不同位置和距离上具有强大的泛化能力，能够有效抑制最先进的3D物体检测器的车辆预测。&lt;h4&gt;结论&lt;/h4&gt;该方法可以作为测试3D物体检测模型鲁棒性的重要工具，在部署前对模型进行评估。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D object detection is a critical component in autonomous driving systems. Itallows real-time recognition and detection of vehicles, pedestrians andobstacles under varying environmental conditions. Among existing methods, 3Dobject detection in the Bird's Eye View (BEV) has emerged as the mainstreamframework. To guarantee a safe, robust and trustworthy 3D object detection, 3Dadversarial attacks are investigated, where attacks are placed in 3Denvironments to evaluate the model performance, e.g. putting a film on a car,clothing a pedestrian. The vulnerability of 3D object detection models to 3Dadversarial attacks serves as an important indicator to evaluate the robustnessof the model against perturbations. To investigate this vulnerability, wegenerate non-invasive 3D adversarial objects tailored for real-world attackscenarios. Our method verifies the existence of universal adversarial objectsthat are spatially consistent across time and camera views. Specifically, weemploy differentiable rendering techniques to accurately model the spatialrelationship between adversarial objects and the target vehicle. Furthermore,we introduce an occlusion-aware module to enhance visual consistency andrealism under different viewpoints. To maintain attack effectiveness acrossmultiple frames, we design a BEV spatial feature-guided optimization strategy.Experimental results demonstrate that our approach can reliably suppressvehicle predictions from state-of-the-art 3D object detectors, serving as animportant tool to test robustness of 3D object detection models beforedeployment. Moreover, the generated adversarial objects exhibit stronggeneralization capabilities, retaining its effectiveness at various positionsand distances in the scene.</description>
      <author>example@mail.com (Aixuan Li, Mochu Xiang, Jing Zhang, Yuchao Dai)</author>
      <guid isPermaLink="false">2505.22499v2</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Subgraph Gaussian Embedding Contrast for Self-Supervised Graph Representation Learning</title>
      <link>http://arxiv.org/abs/2505.23529v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SubGEC的新型图表示学习方法，用于将高维图结构数据编码为低维向量。&lt;h4&gt;背景&lt;/h4&gt;图表示学习（GRL）是机器学习中的一个基本任务，它旨在将高维图结构数据编码为低维向量。自监督学习方法（SSL）在GRL中被广泛应用，因为它们可以避免昂贵的标注过程。&lt;h4&gt;目的&lt;/h4&gt;研究目的是提出一种新的方法，以增强自监督学习在图表示学习中的应用。&lt;h4&gt;方法&lt;/h4&gt;提出的方法引入了一个子图高斯嵌入模块，该模块自适应地将子图映射到结构化的高斯空间，同时保留输入子图的特征并生成具有可控分布的子图。然后，使用Wasserstein和Gromov-Wasserstein距离来有效测量子图之间的相似性，从而增强对比学习过程的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;在多个基准测试上的广泛实验表明，该方法在性能上优于或与最先进的方法相竞争。&lt;h4&gt;结论&lt;/h4&gt;本文的研究发现为自监督学习方法在图表示学习中的应用提供了见解，强调了生成对比对分布的重要性。&lt;h4&gt;翻译&lt;/h4&gt;Graph Representation Learning (GRL) is a fundamental task in machine learning, aiming to encode high-dimensional graph-structured data into low-dimensional vectors. Self-Supervised Learning (SSL) methods are widely used in GRL because they can avoid expensive human annotation. In this work, we propose a novel Subgraph Gaussian Embedding Contrast (SubGEC) method. Our approach introduces a subgraph Gaussian embedding module, which adaptively maps subgraphs to a structured Gaussian space, ensuring the preservation of input subgraph characteristics while generating subgraphs with a controlled distribution. We then employ optimal transport distances, more precisely the Wasserstein and Gromov-Wasserstein distances, to effectively measure the similarity between subgraphs, enhancing the robustness of the contrastive learning process. Extensive experiments across multiple benchmarks demonstrate that the method outperforms or presents competitive performance against state-of-the-art approaches. Our findings provide insights into the design of SSL methods for GRL, emphasizing the importance of the distribution of the generated contrastive pairs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Representation Learning (GRL) is a fundamental task in machinelearning, aiming to encode high-dimensional graph-structured data intolow-dimensional vectors. Self-Supervised Learning (SSL) methods are widely usedin GRL because they can avoid expensive human annotation. In this work, wepropose a novel Subgraph Gaussian Embedding Contrast (SubGEC) method. Ourapproach introduces a subgraph Gaussian embedding module, which adaptively mapssubgraphs to a structured Gaussian space, ensuring the preservation of inputsubgraph characteristics while generating subgraphs with a controlleddistribution. We then employ optimal transport distances, more precisely theWasserstein and Gromov-Wasserstein distances, to effectively measure thesimilarity between subgraphs, enhancing the robustness of the contrastivelearning process. Extensive experiments across multiple benchmarks demonstratethat \method~outperforms or presents competitive performance againststate-of-the-art approaches. Our findings provide insights into the design ofSSL methods for GRL, emphasizing the importance of the distribution of thegenerated contrastive pairs.</description>
      <author>example@mail.com (Shifeng Xie, Aref Einizade, Jhony H. Giraldo)</author>
      <guid isPermaLink="false">2505.23529v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>AMBER: Adaptive Mesh Generation by Iterative Mesh Resolution Prediction</title>
      <link>http://arxiv.org/abs/2505.23663v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;AMBER是一种基于监督学习的自适应网格生成方法，通过迭代预测尺寸场，利用专家标签自动投影进行数据增强，在2D和3D数据集上表现出色。&lt;h4&gt;背景&lt;/h4&gt;使用有限元方法（FEM）模拟复杂物理系统时，成本和精度与底层网格的分辨率成正比。自适应网格通过在关键区域细化分辨率来提高计算效率，但通常需要特定的启发式方法或人工设计。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为AMBER的自适应网格生成方法，以解决当前自适应网格生成的局限性。&lt;h4&gt;方法&lt;/h4&gt;AMBER从粗网格开始，迭代预测尺寸场，即从几何形状到目标网格局部单元大小的映射函数，并使用预测结果生成新的中间网格。这一过程通过分层图神经网络实现，并在训练期间依赖于数据增强，将专家标签自动投影到AMBER生成的数据上。&lt;h4&gt;主要发现&lt;/h4&gt;AMBER在2D和3D数据集上，包括经典物理问题、机械组件和真实世界工业设计数据集上进行了评估，并且能够推广到未见过的几何形状，在多个基准测试中表现优于使用图神经网络、卷积神经网络和基于强化学习的其他方法。&lt;h4&gt;结论&lt;/h4&gt;AMBER是一种有效的自适应网格生成方法，可以提高模拟复杂物理系统的计算效率和精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The cost and accuracy of simulating complex physical systems using the FiniteElement Method (FEM) scales with the resolution of the underlying mesh.Adaptive meshes improve computational efficiency by refining resolution incritical regions, but typically require task-specific heuristics or cumbersomemanual design by a human expert. We propose Adaptive Meshing By ExpertReconstruction (AMBER), a supervised learning approach to mesh adaptation.Starting from a coarse mesh, AMBER iteratively predicts the sizing field, i.e.,a function mapping from the geometry to the local element size of the targetmesh, and uses this prediction to produce a new intermediate mesh using anout-of-the-box mesh generator. This process is enabled through a hierarchicalgraph neural network, and relies on data augmentation by automaticallyprojecting expert labels onto AMBER-generated data during training. We evaluateAMBER on 2D and 3D datasets, including classical physics problems, mechanicalcomponents, and real-world industrial designs with human expert meshes. AMBERgeneralizes to unseen geometries and consistently outperforms multiple recentbaselines, including ones using Graph and Convolutional Neural Networks, andReinforcement Learning-based approaches.</description>
      <author>example@mail.com (Niklas Freymuth, Tobias Würth, Nicolas Schreiber, Balazs Gyenes, Andreas Boltres, Johannes Mitsch, Aleksandar Taranovic, Tai Hoang, Philipp Dahlinger, Philipp Becker, Luise Kärger, Gerhard Neumann)</author>
      <guid isPermaLink="false">2505.23663v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>ZeroSep: Separate Anything in Audio with Zero Training</title>
      <link>http://arxiv.org/abs/2505.23625v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://wikichao.github.io/ZeroSep/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;音频源分离对于机器理解复杂声学环境和支撑众多音频应用至关重要。本文提出了一种名为ZeroSep的无监督方法，通过预训练的文本引导音频扩散模型实现零样本源分离，克服了传统方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有的监督深度学习方法在需要大量任务特定标签数据且难以泛化到真实世界声学场景的多样性和开放集性质方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;研究是否可以通过预训练的文本引导音频扩散模型克服这些局限性。&lt;h4&gt;方法&lt;/h4&gt;ZeroSep方法通过将混合音频转换为扩散模型的潜在空间，然后使用文本条件引导去噪过程以恢复单独的源。&lt;h4&gt;主要发现&lt;/h4&gt;ZeroSep在适当的配置下可以仅通过预训练的文本引导音频扩散模型实现零样本源分离，且无需任务特定训练或微调。&lt;h4&gt;结论&lt;/h4&gt;ZeroSep与多种预训练的文本引导音频扩散模型兼容，在多个分离基准测试中表现出强大的分离性能，甚至超过了监督方法。&lt;h4&gt;翻译&lt;/h4&gt;Audio source separation is fundamental for machines to understand complex acoustic environments and underpins numerous audio applications. Current supervised deep learning approaches, while powerful, are limited by the need for extensive, task-specific labeled data and struggle to generalize to the immense variability and open-set nature of real-world acoustic scenes. Inspired by the success of generative foundation models, we investigate whether pre-trained text-guided audio diffusion models can overcome these limitations. We make a surprising discovery: zero-shot source separation can be achieved purely through a pre-trained text-guided audio diffusion model under the right configuration. Our method, named ZeroSep, works by inverting the mixed audio into the diffusion model's latent space and then using text conditioning to guide the denoising process to recover individual sources. Without any task-specific training or fine-tuning, ZeroSep repurposes the generative diffusion model for a discriminative separation task and inherently supports open-set scenarios through its rich textual priors. ZeroSep is compatible with a variety of pre-trained text-guided audio diffusion backbones and delivers strong separation performance on multiple separation benchmarks, surpassing even supervised methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio source separation is fundamental for machines to understand complexacoustic environments and underpins numerous audio applications. Currentsupervised deep learning approaches, while powerful, are limited by the needfor extensive, task-specific labeled data and struggle to generalize to theimmense variability and open-set nature of real-world acoustic scenes. Inspiredby the success of generative foundation models, we investigate whetherpre-trained text-guided audio diffusion models can overcome these limitations.We make a surprising discovery: zero-shot source separation can be achievedpurely through a pre-trained text-guided audio diffusion model under the rightconfiguration. Our method, named ZeroSep, works by inverting the mixed audiointo the diffusion model's latent space and then using text conditioning toguide the denoising process to recover individual sources. Without anytask-specific training or fine-tuning, ZeroSep repurposes the generativediffusion model for a discriminative separation task and inherently supportsopen-set scenarios through its rich textual priors. ZeroSep is compatible witha variety of pre-trained text-guided audio diffusion backbones and deliversstrong separation performance on multiple separation benchmarks, surpassingeven supervised methods.</description>
      <author>example@mail.com (Chao Huang, Yuesheng Ma, Junxuan Huang, Susan Liang, Yunlong Tang, Jing Bi, Wenqiang Liu, Nima Mesgarani, Chenliang Xu)</author>
      <guid isPermaLink="false">2505.23625v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>On Transferring Transferability: Towards a Theory for Size Generalization</title>
      <link>http://arxiv.org/abs/2505.23599v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  69 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通用的跨维度可迁移性框架，探讨了模型在低维数据上训练后，能否将其性能迁移到高维输入上的问题。&lt;h4&gt;背景&lt;/h4&gt;现代学习任务需要能够处理不同尺寸输入的模型，因此提出了适用于图、集合和点云等领域的维度无关架构。&lt;h4&gt;目的&lt;/h4&gt;研究低维数据训练的模型在高维输入上的性能迁移性。&lt;h4&gt;方法&lt;/h4&gt;通过引入一个通用的跨维度可迁移性框架，证明了可迁移性与极限空间中的连续性相对应，该极限空间由将小问题实例与等效的大实例相识别形成。&lt;h4&gt;主要发现&lt;/h4&gt;可迁移性对应于极限空间中的连续性，这种识别由数据和学习任务驱动。&lt;h4&gt;结论&lt;/h4&gt;通过在现有架构上实现必要的修改以确保其可迁移性，并提供了设计可迁移新模型的设计原则。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a general framework for transferability across dimensions, exploring whether a model trained on low-dimensional data can transfer its performance to higher-dimensional inputs. In the background, modern learning tasks require models that can handle inputs of varying sizes, so dimension-independent architectures have been proposed for domains where the inputs are graphs, sets, and point clouds. The purpose of the study is to investigate the transferability of performance of models trained on low-dimensional data to higher-dimensional inputs. The method is to introduce a general framework for transferability across dimensions, which proves that transferability corresponds precisely to continuity in a limit space formed by identifying small problem instances with equivalent large ones. This identification is driven by the data and the learning task. The conclusion is that necessary changes are made to existing architectures to ensure their transferability, and design principles for designing new transferable models are provided. Numerical experiments support the findings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many modern learning tasks require models that can take inputs of varyingsizes. Consequently, dimension-independent architectures have been proposed fordomains where the inputs are graphs, sets, and point clouds. Recent work ongraph neural networks has explored whether a model trained on low-dimensionaldata can transfer its performance to higher-dimensional inputs. We extend thisbody of work by introducing a general framework for transferability acrossdimensions. We show that transferability corresponds precisely to continuity ina limit space formed by identifying small problem instances with equivalentlarge ones. This identification is driven by the data and the learning task. Weinstantiate our framework on existing architectures, and implement thenecessary changes to ensure their transferability. Finally, we provide designprinciples for designing new transferable models. Numerical experiments supportour findings.</description>
      <author>example@mail.com (Eitan Levin, Yuxin Ma, Mateo Díaz, Soledad Villar)</author>
      <guid isPermaLink="false">2505.23599v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>BioReason: Incentivizing Multimodal Biological Reasoning within a DNA-LLM Model</title>
      <link>http://arxiv.org/abs/2505.23579v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 3 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;BioReason是一种新的生物信息学架构，通过将DNA基础模型与大型语言模型（LLM）深度集成，实现了对复杂基因组数据进行深层次、可解释的生物推理，推动了科学发现。&lt;h4&gt;背景&lt;/h4&gt;当前DNA基础模型在序列表示方面表现良好，但难以进行多步推理，并且缺乏透明的生物直观解释，这成为了生物信息学中的一个重要挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够从复杂基因组数据中解锁深层、可解释生物推理的系统。&lt;h4&gt;方法&lt;/h4&gt;BioReason通过监督微调和定向强化学习来提高多步推理能力，使得LLM能够直接处理和推理基因组信息。&lt;h4&gt;主要发现&lt;/h4&gt;BioReason在基于KEGG的疾病通路预测和变异效应预测等生物推理基准测试中，相较于强大的单模态基线平均提高了15%的性能。它能够对未见过的生物实体进行推理，并通过可解释的、逐步的生物轨迹来阐述决策过程。&lt;h4&gt;结论&lt;/h4&gt;BioReason为AI在生物学领域提供了一个变革性的方法，它能够促进对机制的深入理解，并加速从基因组数据生成可测试的假设。&lt;h4&gt;翻译&lt;/h4&gt;Unlocking deep, interpretable biological reasoning from complex genomic data is a major AI challenge hindering scientific discovery. Current DNA foundation models, despite strong sequence representation, struggle with multi-step reasoning and lack inherent transparent, biologically intuitive explanations. We introduce BioReason, a pioneering architecture that, for the first time, deeply integrates a DNA foundation model with a Large Language Model (LLM). This novel connection enables the LLM to directly process and reason with genomic information as a fundamental input, fostering a new form of multimodal biological understanding. BioReason's sophisticated multi-step reasoning is developed through supervised fine-tuning and targeted reinforcement learning, guiding the system to generate logical, biologically coherent deductions. On biological reasoning benchmarks including KEGG-based disease pathway prediction- where accuracy improves from 88% to 97% - and variant effect prediction, BioReason demonstrates an average 15% performance gain over strong single-modality baselines. BioReason reasons over unseen biological entities and articulates decision-making through interpretable, step-by-step biological traces, offering a transformative approach for AI in biology that enables deeper mechanistic insights and accelerates testable hypothesis generation from genomic data. Data, code, and checkpoints are publicly available at https://github.com/bowang-lab/BioReason&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unlocking deep, interpretable biological reasoning from complex genomic datais a major AI challenge hindering scientific discovery. Current DNA foundationmodels, despite strong sequence representation, struggle with multi-stepreasoning and lack inherent transparent, biologically intuitive explanations.We introduce BioReason, a pioneering architecture that, for the first time,deeply integrates a DNA foundation model with a Large Language Model (LLM).This novel connection enables the LLM to directly process and reason withgenomic information as a fundamental input, fostering a new form of multimodalbiological understanding. BioReason's sophisticated multi-step reasoning isdeveloped through supervised fine-tuning and targeted reinforcement learning,guiding the system to generate logical, biologically coherent deductions. Onbiological reasoning benchmarks including KEGG-based disease pathway prediction- where accuracy improves from 88% to 97% - and variant effect prediction,BioReason demonstrates an average 15% performance gain over strongsingle-modality baselines. BioReason reasons over unseen biological entitiesand articulates decision-making through interpretable, step-by-step biologicaltraces, offering a transformative approach for AI in biology that enablesdeeper mechanistic insights and accelerates testable hypothesis generation fromgenomic data. Data, code, and checkpoints are publicly available athttps://github.com/bowang-lab/BioReason</description>
      <author>example@mail.com (Adibvafa Fallahpour, Andrew Magnuson, Purav Gupta, Shihao Ma, Jack Naimer, Arnav Shah, Haonan Duan, Omar Ibrahim, Hani Goodarzi, Chris J. Maddison, Bo Wang)</author>
      <guid isPermaLink="false">2505.23579v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Maximum Likelihood Learning of Latent Dynamics Without Reconstruction</title>
      <link>http://arxiv.org/abs/2505.23569v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的无监督学习方法，用于处理具有潜在动态结构的时间序列数据——识别参数化的高斯状态空间模型（RP-GSSM）。该方法通过结合对比方法的直觉和概率生成模型的灵活工具，学习解释不同时间步长观测之间统计依赖性的马尔可夫高斯潜在变量。&lt;h4&gt;背景&lt;/h4&gt;针对时间序列数据，传统的方法在处理具有潜在动态结构的数据时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出RP-GSSM模型，以学习时间序列数据中的潜在动态结构，并提高模型在非线性随机动力学学习等方面的性能。&lt;h4&gt;方法&lt;/h4&gt;RP-GSSM是一个概率模型，通过最大似然学习马尔可夫高斯潜在变量。与对比方法不同，它是一个有效的概率模型。与生成模型不同，它不需要从潜在变量到观测值的显式网络映射，允许模型专注于潜在变量的推断。模型具有精确推断的能力，同时通过非线性神经网络链接保持表达性。&lt;h4&gt;主要发现&lt;/h4&gt;RP-GSSM在视频中的非线性随机动力学学习问题，包括有或无背景干扰的情况下，优于其他方法。结果表明，RP-GSSM可以作为各种下游应用的有用基础模型。&lt;h4&gt;结论&lt;/h4&gt;RP-GSSM是一个高效且具有表达性的模型，能够学习任务相关的潜在变量，无需额外的正则化、辅助损失或优化器调度，为时间序列数据分析和处理提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a novel unsupervised learning method for time series data withlatent dynamical structure: the recognition-parametrized Gaussian state spacemodel (RP-GSSM). The RP-GSSM is a probabilistic model that learns MarkovianGaussian latents explaining statistical dependence between observations atdifferent time steps, combining the intuition of contrastive methods with theflexible tools of probabilistic generative models. Unlike contrastiveapproaches, the RP-GSSM is a valid probabilistic model learned via maximumlikelihood. Unlike generative approaches, the RP-GSSM has no need for anexplicit network mapping from latents to observations, allowing it to focusmodel capacity on inference of latents. The model is both tractable andexpressive: it admits exact inference thanks to its jointly Gaussian latentprior, while maintaining expressivity with an arbitrarily nonlinear neuralnetwork link between observations and latents. These qualities allow theRP-GSSM to learn task-relevant latents without ad-hoc regularization, auxiliarylosses, or optimizer scheduling. We show how this approach outperformsalternatives on problems that include learning nonlinear stochastic dynamicsfrom video, with or without background distractors. Our results position theRP-GSSM as a useful foundation model for a variety of downstream applications.</description>
      <author>example@mail.com (Samo Hromadka, Kai Biegun, Lior Fox, James Heald, Maneesh Sahani)</author>
      <guid isPermaLink="false">2505.23569v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Skin Lesion Phenotyping via Nested Multi-modal Contrastive Learning</title>
      <link>http://arxiv.org/abs/2505.23709v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SLIMP是一种通过新颖的嵌套对比学习方法来学习皮肤病变丰富表示的新方法。&lt;h4&gt;背景&lt;/h4&gt;皮肤病变检测和分类面临挑战，因为成像条件多样且缺乏临床和表型背景。&lt;h4&gt;目的&lt;/h4&gt;提出SLIMP以改善皮肤病变分类任务的表现。&lt;h4&gt;方法&lt;/h4&gt;SLIMP结合了单个皮肤病变的外观和元数据，以及与患者病历和其他临床相关信息相关的患者级别元数据。&lt;h4&gt;主要发现&lt;/h4&gt;通过充分利用所有可用数据模态，SLIMP在下游皮肤病变分类任务上优于其他预训练策略。&lt;h4&gt;结论&lt;/h4&gt;SLIMP通过学习到的表示质量提高了皮肤病变分类的性能。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了SLIMP（皮肤病变图像-元数据预训练），通过一种新颖的嵌套对比学习方法来学习皮肤病变的丰富表示。由于成像条件（照明、颜色、分辨率、距离等）的多样性和缺乏临床和表型背景，仅基于图像的黑色素瘤检测和皮肤病变分类具有重要意义。临床医生通常采取整体方法来评估患者的风险水平，并决定哪些病变可能是恶性的，需要切除，同时考虑患者的病史以及患者其他病变的外观。受此启发，SLIMP结合了单个皮肤病变的外观和元数据，以及与患者病历和其他临床相关信息相关的患者级别元数据。通过在整个学习过程中充分利用所有可用的数据模态，所提出的预训练策略在下游皮肤病变分类任务上优于其他预训练策略，突出了学习到的表示质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce SLIMP (Skin Lesion Image-Metadata Pre-training) for learningrich representations of skin lesions through a novel nested contrastivelearning approach that captures complex relationships between images andmetadata. Melanoma detection and skin lesion classification based solely onimages, pose significant challenges due to large variations in imagingconditions (lighting, color, resolution, distance, etc.) and lack of clinicaland phenotypical context. Clinicians typically follow a holistic approach forassessing the risk level of the patient and for deciding which lesions may bemalignant and need to be excised, by considering the patient's medical historyas well as the appearance of other lesions of the patient. Inspired by this,SLIMP combines the appearance and the metadata of individual skin lesions withpatient-level metadata relating to their medical record and other clinicallyrelevant information. By fully exploiting all available data modalitiesthroughout the learning process, the proposed pre-training strategy improvesperformance compared to other pre-training strategies on downstream skinlesions classification tasks highlighting the learned representations quality.</description>
      <author>example@mail.com (Dionysis Christopoulos, Sotiris Spanos, Eirini Baltzi, Valsamis Ntouskos, Konstantinos Karantzalos)</author>
      <guid isPermaLink="false">2505.23709v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Bridging the Gap Between Semantic and User Preference Spaces for Multi-modal Music Representation Learning</title>
      <link>http://arxiv.org/abs/2505.23298v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICMR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为HTCL的新方法，该方法通过分层两阶段对比学习来学习音乐的全面表示，并在音乐语义和推荐任务上取得了有效的结果。&lt;h4&gt;背景&lt;/h4&gt;当前音乐表示学习主要集中在学习无标签音频的声音乐表示或尝试使用稀少的音频-文本配对获取多模态音乐表示。这些方法要么忽略了语言语义，要么依赖于难以创建且昂贵的标注音频数据集。此外，仅仅建模语义空间通常无法在音乐推荐任务上取得满意的效果，因为用户偏好空间被忽略了。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来学习一个连接语义空间和用户偏好空间的全面音乐表示。&lt;h4&gt;方法&lt;/h4&gt;设计了一种可扩展的音频编码器，并利用预训练的BERT模型作为文本编码器，通过大规模对比预训练学习音频-文本语义。此外，探索了一种简单而有效的方法，利用来自在线音乐平台的数据，通过对比微调将语义空间调整到用户偏好空间。&lt;h4&gt;主要发现&lt;/h4&gt;该方法不仅能够从文本编码器中提取语言语义，而且能够保持语义空间完整性的同时，在用户偏好空间中建模相似性。&lt;h4&gt;结论&lt;/h4&gt;在音乐语义和推荐任务上的实验结果证实了该方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Recent works of music representation learning mainly focus on learningacoustic music representations with unlabeled audios or further attempt toacquire multi-modal music representations with scarce annotated audio-textpairs. They either ignore the language semantics or rely on labeled audiodatasets that are difficult and expensive to create. Moreover, merely modelingsemantic space usually fails to achieve satisfactory performance on musicrecommendation tasks since the user preference space is ignored. In this paper,we propose a novel Hierarchical Two-stage Contrastive Learning (HTCL) methodthat models similarity from the semantic perspective to the user perspectivehierarchically to learn a comprehensive music representation bridging the gapbetween semantic and user preference spaces. We devise a scalable audio encoderand leverage a pre-trained BERT model as the text encoder to learn audio-textsemantics via large-scale contrastive pre-training. Further, we explore asimple yet effective way to exploit interaction data from our online musicplatform to adapt the semantic space to user preference space via contrastivefine-tuning, which differs from previous works that follow the idea ofcollaborative filtering. As a result, we obtain a powerful audio encoder thatnot only distills language semantics from the text encoder but also modelssimilarity in user preference space with the integrity of semantic spacepreserved. Experimental results on both music semantic and recommendation tasksconfirm the effectiveness of our method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3731715.3733471&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent works of music representation learning mainly focus on learningacoustic music representations with unlabeled audios or further attempt toacquire multi-modal music representations with scarce annotated audio-textpairs. They either ignore the language semantics or rely on labeled audiodatasets that are difficult and expensive to create. Moreover, merely modelingsemantic space usually fails to achieve satisfactory performance on musicrecommendation tasks since the user preference space is ignored. In this paper,we propose a novel Hierarchical Two-stage Contrastive Learning (HTCL) methodthat models similarity from the semantic perspective to the user perspectivehierarchically to learn a comprehensive music representation bridging the gapbetween semantic and user preference spaces. We devise a scalable audio encoderand leverage a pre-trained BERT model as the text encoder to learn audio-textsemantics via large-scale contrastive pre-training. Further, we explore asimple yet effective way to exploit interaction data from our online musicplatform to adapt the semantic space to user preference space via contrastivefine-tuning, which differs from previous works that follow the idea ofcollaborative filtering. As a result, we obtain a powerful audio encoder thatnot only distills language semantics from the text encoder but also modelssimilarity in user preference space with the integrity of semantic spacepreserved. Experimental results on both music semantic and recommendation tasksconfirm the effectiveness of our method.</description>
      <author>example@mail.com (Xiaofeng Pan, Jing Chen, Haitong Zhang, Menglin Xing, Jiayi Wei, Xuefeng Mu, Zhongqian Xie)</author>
      <guid isPermaLink="false">2505.23298v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action Control</title>
      <link>http://arxiv.org/abs/2505.22421v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  code will be released at https://github.com/antonioo-c/GeoDrive&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了GeoDrive，一种集成了鲁棒3D几何条件的世界模型，用于提升驾驶世界模型的空间理解和动作可控性。&lt;h4&gt;背景&lt;/h4&gt;世界模型在动态环境模拟中的应用已得到显著进展，有助于系统预见未来状态和评估潜在动作。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在维持鲁棒3D几何一致性或处理遮挡时积累的伪影问题，这两个方面对于自主导航任务中的可靠安全性评估至关重要。&lt;h4&gt;方法&lt;/h4&gt;GeoDrive通过首先从输入帧中提取3D表示，然后根据用户指定的自我汽车轨迹获得其2D渲染。在训练过程中，提出动态编辑模块以通过编辑车辆位置来增强渲染。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在动作准确性和3D空间意识方面显著优于现有模型，导致了更真实、适应性更强和更可靠的场景建模，有助于更安全的自动驾驶。&lt;h4&gt;结论&lt;/h4&gt;GeoDrive模型可以泛化到新的轨迹，并提供了交互式场景编辑能力，如对象编辑和对象轨迹控制。&lt;h4&gt;翻译&lt;/h4&gt;Recent advancements in world models have revolutionized dynamic environment simulation, allowing systems to foresee future states and assess potential actions. In autonomous driving, these capabilities help vehicles anticipate the behavior of other road users, perform risk-aware planning, accelerate training in simulation, and adapt to novel scenarios, thereby enhancing safety and reliability. Current approaches exhibit deficiencies in maintaining robust 3D geometric consistency or accumulating artifacts during occlusion handling, both critical for reliable safety assessment in autonomous navigation tasks. To address this, we introduce GeoDrive, which explicitly integrates robust 3D geometry conditions into driving world models to enhance spatial understanding and action controllability. Specifically, we first extract a 3D representation from the input frame and then obtain its 2D rendering based on the user-specified ego-car trajectory. To enable dynamic modeling, we propose a dynamic editing module during training to enhance the renderings by editing the positions of the vehicles. Extensive experiments demonstrate that our method significantly outperforms existing models in both action accuracy and 3D spatial awareness, leading to more realistic, adaptable, and reliable scenemodeling for safer autonomous driving. Additionally, our model can generalize to novel trajectories and offers interactive scene editing capabilities, such as object editing and object trajectory control.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in world models have revolutionized dynamic environmentsimulation, allowing systems to foresee future states and assess potentialactions. In autonomous driving, these capabilities help vehicles anticipate thebehavior of other road users, perform risk-aware planning, accelerate trainingin simulation, and adapt to novel scenarios, thereby enhancing safety andreliability. Current approaches exhibit deficiencies in maintaining robust 3Dgeometric consistency or accumulating artifacts during occlusion handling, bothcritical for reliable safety assessment in autonomous navigation tasks. Toaddress this, we introduce GeoDrive, which explicitly integrates robust 3Dgeometry conditions into driving world models to enhance spatial understandingand action controllability. Specifically, we first extract a 3D representationfrom the input frame and then obtain its 2D rendering based on theuser-specified ego-car trajectory. To enable dynamic modeling, we propose adynamic editing module during training to enhance the renderings by editing thepositions of the vehicles. Extensive experiments demonstrate that our methodsignificantly outperforms existing models in both action accuracy and 3Dspatial awareness, leading to more realistic, adaptable, and reliable scenemodeling for safer autonomous driving. Additionally, our model can generalizeto novel trajectories and offers interactive scene editing capabilities, suchas object editing and object trajectory control.</description>
      <author>example@mail.com (Anthony Chen, Wenzhao Zheng, Yida Wang, Xueyang Zhang, Kun Zhan, Peng Jia, Kurt Keutzer, Shanghang Zhang)</author>
      <guid isPermaLink="false">2505.22421v2</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Hybrid-Graph Neural Network Method for Muon Fast Reconstruction in Neutrino Telescopes</title>
      <link>http://arxiv.org/abs/2505.23425v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种针对μ子轨迹重建的高效Hybrid-Graph Neural Network (GNN)方法，该方法结合了GNN的鲁棒性和传统物理方法，显著提高了中微子望远镜的实验灵敏度和在线触发能力。&lt;h4&gt;背景&lt;/h4&gt;快速且精确的μ子重建对中微子望远镜至关重要，因为它可以提高实验灵敏度和实现在线触发。&lt;h4&gt;目的&lt;/h4&gt;提高中微子望远镜的数据重建效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;采用了一种名为“LITE GNN模型”的方法，该模型在GPU上的运行时间为0.19-0.29毫秒/事件，与传统的基于似然的方法相比，速度提升了三个数量级，同时保持了高重建精度。&lt;h4&gt;主要发现&lt;/h4&gt;对于高能μ子（10-100 TeV），LITE GNN模型的中值角度误差约为0.1度，重建的切伦科夫光子发射位置误差在3-5米以下。此外，Semi-GNN方法提供了一种评估事件重建质量的方法，能够识别并排除重建不良的事件。&lt;h4&gt;结论&lt;/h4&gt;基于GNN的方法是下一代中微子望远镜数据重建的有希望解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：快速且精确的μ子重建对于中微子望远镜来说至关重要，这对于提高实验灵敏度和实现在线触发至关重要。本文介绍了一种针对高效μ子轨迹重建的定制化Hybrid-Graph Neural Network (GNN)方法，该方法结合了GNN的鲁棒性和传统基于物理的方法。'LITE GNN模型'在GPU上的每次事件运行时间为0.19-0.29毫秒，与传统的基于似然的方法相比，速度提高了三个数量级，同时保持了高重建精度。对于高能μ子（10-100 TeV），该模型的中值角度误差约为0.1度，重建的切伦科夫光子发射位置误差在3-5米以下，具体取决于所使用的GNN模型。此外，Semi-GNN方法提供了一种评估事件重建质量的方法，允许识别和排除重建不良的事件。这些结果将基于GNN的方法确立为下一代中微子望远镜数据重建的有希望解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fast and accurate muon reconstruction is crucial for neutrino telescopes toimprove experimental sensitivity and enable online triggering. This paperintroduces a Hybrid-Graph Neural Network (GNN) method tailored for efficientmuon track reconstruction, leveraging the robustness of GNNs alongsidetraditional physics-based approaches. The "LITE GNN model" achieves a runtimeof 0.19-0.29 ms per event on GPUs, offering a three orders of magnitude speedupcompared to traditional likelihood-based methods while maintaining a highreconstruction accuracy. For high-energy muons (10-100 TeV), the median angularerror is approximately 0.1 degrees, with errors in reconstructed Cherenkovphoton emission positions being below 3-5 meters, depending on the GNN modelused. Furthermore, the Semi-GNN method offers a mechanism to assess the qualityof event reconstruction, enabling the identification and exclusion of poorlyreconstructed events. These results establish the GNN-based approach as apromising solution for next-generation neutrino telescope data reconstruction.</description>
      <author>example@mail.com (Cen Mo, Liang Li)</author>
      <guid isPermaLink="false">2505.23425v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Equivariant Spherical Transformer for Efficient Molecular Modeling</title>
      <link>http://arxiv.org/abs/2505.23086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SE(3)-equivariant Graph Neural Networks在分子系统建模方面取得了显著进展，但EST（Equivariant Spherical Transformer）通过引入Transformer结构提高了表达能力和性能。&lt;h4&gt;背景&lt;/h4&gt;SE(3)-equivariant Graph Neural Networks通过使用群表示在分子系统建模中取得了进展，但其基于张量积的卷积在非线性表达和群表示的完整性方面存在限制。&lt;h4&gt;目的&lt;/h4&gt;克服SE(3)-equivariant Graph Neural Networks的局限性，提高分子系统建模的表达能力和性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的框架EST（Equivariant Spherical Transformer），它利用傅里叶变换后在群表示的空间域内的Transformer结构。&lt;h4&gt;主要发现&lt;/h4&gt;EST能够涵盖张量积的功能空间，同时实现更高的表达能力。EST的等变归纳偏差通过傅里叶变换的均匀采样策略得到保证。&lt;h4&gt;结论&lt;/h4&gt;EST在多个分子基准测试中表现出最先进的性能，包括OC20和QM9。&lt;h4&gt;翻译&lt;/h4&gt;SE(3)-等变图神经网络（GNNs）通过使用群表示显著推进了分子系统建模。然而，它们依赖于基于张量积卷积的消息传递过程，由于非线性不足和不完整的群表示而受到限制，从而限制了表达能力。为了克服这些限制，我们引入了等变球面变换器（EST），这是一种新颖的框架，它利用傅里叶变换后在群表示的空间域内的变换器结构。我们从理论和实证上证明了EST可以涵盖张量积的功能空间，同时实现更高的表达能力。此外，EST的等变归纳偏差通过傅里叶变换的均匀采样策略得到保证。我们的实验表明，EST在各种分子基准测试中，包括OC20和QM9，都表现出最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; SE(3)-equivariant Graph Neural Networks (GNNs) have significantly advancedmolecular system modeling by employing group representations. However, theirmessage passing processes, which rely on tensor product-based convolutions, arelimited by insufficient non-linearity and incomplete group representations,thereby restricting expressiveness. To overcome these limitations, we introducethe Equivariant Spherical Transformer (EST), a novel framework that leverages aTransformer structure within the spatial domain of group representations afterFourier transform. We theoretically and empirically demonstrate that EST canencompass the function space of tensor products while achieving superiorexpressiveness. Furthermore, EST's equivariant inductive bias is guaranteedthrough a uniform sampling strategy for the Fourier transform. Our experimentsdemonstrate state-of-the-art performance by EST on various molecularbenchmarks, including OC20 and QM9.</description>
      <author>example@mail.com (Junyi An, Xinyu Lu, Chao Qu, Yunfei Shi, Peijia Lin, Qianwei Tang, Licheng Xu, Fenglei Cao, Yuan Qi)</author>
      <guid isPermaLink="false">2505.23086v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Epistemic Errors of Imperfect Multitask Learners When Distributions Shift</title>
      <link>http://arxiv.org/abs/2505.23496v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了数据噪声情况下的统计学习问题，提出了关于认知误差的定义和分解误差界限，并针对特定场景提供了误差界限和泛化界限，同时定义了负迁移，并在合成实验中验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;现实世界中的学习场景可能存在多种认知不确定性，如多任务学习、分布偏移和不完善学习等。&lt;h4&gt;目的&lt;/h4&gt;为了解决测试时可能遇到的数据认知不确定性，识别测试数据的分布。&lt;h4&gt;方法&lt;/h4&gt;提出了认知误差的定义和一种通用的分解误差界限，并针对贝叶斯迁移学习和ε邻域内的分布偏移提供了特定的误差界限和泛化界限。&lt;h4&gt;主要发现&lt;/h4&gt;误差界限首次考虑了认知误差，涵盖了所有认知不确定性的来源，并将误差分别归因于学习过程和环境的多个方面。&lt;h4&gt;结论&lt;/h4&gt;本文为认知误差提供了新的理解和处理方法，并在合成实验中验证了所提方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;When data are noisy, a statistical learner's goal is to resolve epistemic uncertainty about the data it will encounter at test-time, i.e., to identify the distribution of test (target) data. Many real-world learning settings introduce sources of epistemic uncertainty that can not be resolved on the basis of training (source) data alone: The source data may arise from multiple tasks (multitask learning), the target data may differ systematically from the source data tasks (distribution shift), and/or the learner may not arrive at an accurate characterization of the source data (imperfect learning). We introduce a principled definition of epistemic error, and provide a generic, decompositional epistemic error bound. Our error bound is the first to (i) consider epistemic error specifically, (ii) accommodate all the sources of epistemic uncertainty above, and (iii) separately attribute the error to each of multiple aspects of the learning procedure and environment. As corollaries of the generic result, we provide (i) epistemic error bounds specialized to the settings of Bayesian transfer learning and distribution shift within ε-neighborhoods, and (ii) a set of corresponding generalization bounds. Finally, we provide a novel definition of negative transfer, and validate its insights in a synthetic experimental setting.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When data are noisy, a statistical learner's goal is to resolve epistemicuncertainty about the data it will encounter at test-time, i.e., to identifythe distribution of test (target) data. Many real-world learning settingsintroduce sources of epistemic uncertainty that can not be resolved on thebasis of training (source) data alone: The source data may arise from multipletasks (multitask learning), the target data may differ systematically from thesource data tasks (distribution shift), and/or the learner may not arrive at anaccurate characterization of the source data (imperfect learning). We introducea principled definition of epistemic error, and provide a generic,decompositional epistemic error bound. Our error bound is the first to (i)consider epistemic error specifically, (ii) accommodate all the sources ofepistemic uncertainty above, and (iii) separately attribute the error to eachof multiple aspects of the learning procedure and environment. As corollariesof the generic result, we provide (i) epistemic error bounds specialized to thesettings of Bayesian transfer learning and distribution shift within$\epsilon$-neighborhoods, and (ii) a set of corresponding generalizationbounds. Finally, we provide a novel definition of negative transfer, andvalidate its insights in a synthetic experimental setting.</description>
      <author>example@mail.com (Sabina J. Sloman, Michele Caprio, Samuel Kaski)</author>
      <guid isPermaLink="false">2505.23496v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>A Divide-and-Conquer Approach for Global Orientation of Non-Watertight Scene-Level Point Clouds Using 0-1 Integer Optimization</title>
      <link>http://arxiv.org/abs/2505.23469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted to SIGGRAPH 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DACPO（Divide-And-Conquer Point Orientation）是一种用于大规模非封闭3D场景点云定位的新框架。&lt;h4&gt;背景&lt;/h4&gt;点云定位是计算机图形学和3D视觉中的基本问题，在重建、分割和分析中应用广泛。尽管已有显著进展，但现有方法主要关注封闭的、对象级别的3D模型。&lt;h4&gt;目的&lt;/h4&gt;解决大规模非封闭3D场景点云定位这一未被充分探索的挑战。&lt;h4&gt;方法&lt;/h4&gt;DACPO采用分而治之的策略，将输入点云分割成更小的、可管理的块，独立处理每个块，并通过全局优化阶段整合结果。每个块通过随机贪婪方法和改进的迭代泊松表面重建进行两步处理：估计初始法线方向和细化这些方向。使用无向图来建模块间关系，节点代表块，边连接空间相邻的块。引入可见连接区域的概念来可靠地评估相邻块之间的定位一致性。全局整合被表述为一个0-1整数约束优化问题，块翻转状态作为二进制变量。&lt;h4&gt;主要发现&lt;/h4&gt;DACPO在基准数据集上的实验表明，它在现有方法往往失败的具有挑战性的大规模非封闭场景中表现出强大的性能。&lt;h4&gt;结论&lt;/h4&gt;DACPO是一个可扩展且鲁棒的点云定位框架，特别适用于大规模非封闭3D场景。&lt;h4&gt;翻译&lt;/h4&gt;摘要的英文内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Orienting point clouds is a fundamental problem in computer graphics and 3Dvision, with applications in reconstruction, segmentation, and analysis. Whilesignificant progress has been made, existing approaches mainly focus onwatertight, object-level 3D models. The orientation of large-scale,non-watertight 3D scenes remains an underexplored challenge. To address thisgap, we propose DACPO (Divide-And-Conquer Point Orientation), a novel frameworkthat leverages a divide-and-conquer strategy for scalable and robust pointcloud orientation. Rather than attempting to orient an unbounded scene at once,DACPO segments the input point cloud into smaller, manageable blocks, processeseach block independently, and integrates the results through a globaloptimization stage. For each block, we introduce a two-step process: estimatinginitial normal orientations by a randomized greedy method and refining them byan adapted iterative Poisson surface reconstruction. To achieve consistencyacross blocks, we model inter-block relationships using an an undirected graph,where nodes represent blocks and edges connect spatially adjacent blocks. Toreliably evaluate orientation consistency between adjacent blocks, we introducethe concept of the visible connected region, which defines the region overwhich visibility-based assessments are performed. The global integration isthen formulated as a 0-1 integer-constrained optimization problem, with blockflip states as binary variables. Despite the combinatorial nature of theproblem, DACPO remains scalable by limiting the number of blocks (typically afew hundred for 3D scenes) involved in the optimization. Experiments onbenchmark datasets demonstrate DACPO's strong performance, particularly inchallenging large-scale, non-watertight scenarios where existing methods oftenfail. The source code is available at https://github.com/zd-lee/DACPO.</description>
      <author>example@mail.com (Zhuodong Li, Fei Hou, Wencheng Wang, Xuequan Lu, Ying He)</author>
      <guid isPermaLink="false">2505.23469v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>One Trajectory, One Token: Grounded Video Tokenization via Panoptic Sub-object Trajectory</title>
      <link>http://arxiv.org/abs/2505.23617v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于轨迹的视频标记化方法，旨在提高长视频处理中transformer模型的效率。&lt;h4&gt;背景&lt;/h4&gt;现有的视频标记化方法使用时空补丁，导致标记数量过多和计算效率低下。&lt;h4&gt;目的&lt;/h4&gt;通过改进视频标记化方法，减少标记数量，提高计算效率，同时保持视频理解的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了基于全景子对象轨迹的地面视频标记化，并提出了TrajViT视频编码器，该编码器提取对象轨迹并转换为语义上有意义的标记。&lt;h4&gt;主要发现&lt;/h4&gt;TrajViT在多个视频理解基准测试中显著优于空间时间ViT（ViT3D），例如在视频文本检索任务中，TrajViT比ViT3D在平均6%的top-5召回率上表现更好。此外，TrajViT作为现代VideoLLM的视频编码器，在6个VideoQA基准测试中平均提高了5.2%的性能，同时具有4倍更快的训练时间和18倍更少的推理FLOPs。&lt;h4&gt;结论&lt;/h4&gt;TrajViT是第一个在多种视频分析任务中持续优于ViT3D的高效编码器，是一种稳健且可扩展的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Effective video tokenization is critical for scaling transformer models for long videos. Current approaches tokenize videos using space-time patches, leading to excessive tokens and computational inefficiencies. The best token reduction strategies degrade performance and barely reduce the number of tokens when the camera moves. We introduce grounded video tokenization, a paradigm that organizes tokens based on panoptic sub-object trajectories rather than fixed patches. Our method aligns with fundamental perceptual principles, ensuring that tokenization reflects scene complexity rather than video duration. We propose TrajViT, a video encoder that extracts object trajectories and converts them into semantically meaningful tokens, significantly reducing redundancy while maintaining temporal coherence. Trained with contrastive learning, TrajViT significantly outperforms space-time ViT (ViT3D) across multiple video understanding benchmarks, e.g., TrajViT outperforms ViT3D by a large margin of 6% top-5 recall in average at video-text retrieval task with 10x token deduction. We also show TrajViT as a stronger model than ViT3D for being the video encoder for modern VideoLLM, obtaining an average of 5.2% performance improvement across 6 VideoQA benchmarks while having 4x faster training time and 18x less inference FLOPs. TrajViT is the first efficient encoder to consistently outperform ViT3D across diverse video analysis tasks, making it a robust and scalable solution.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective video tokenization is critical for scaling transformer models forlong videos. Current approaches tokenize videos using space-time patches,leading to excessive tokens and computational inefficiencies. The best tokenreduction strategies degrade performance and barely reduce the number of tokenswhen the camera moves. We introduce grounded video tokenization, a paradigmthat organizes tokens based on panoptic sub-object trajectories rather thanfixed patches. Our method aligns with fundamental perceptual principles,ensuring that tokenization reflects scene complexity rather than videoduration. We propose TrajViT, a video encoder that extracts object trajectoriesand converts them into semantically meaningful tokens, significantly reducingredundancy while maintaining temporal coherence. Trained with contrastivelearning, TrajViT significantly outperforms space-time ViT (ViT3D) acrossmultiple video understanding benchmarks, e.g., TrajViT outperforms ViT3D by alarge margin of 6% top-5 recall in average at video-text retrieval task with10x token deduction. We also show TrajViT as a stronger model than ViT3D forbeing the video encoder for modern VideoLLM, obtaining an average of 5.2%performance improvement across 6 VideoQA benchmarks while having 4x fastertraining time and 18x less inference FLOPs. TrajViT is the first efficientencoder to consistently outperform ViT3D across diverse video analysis tasks,making it a robust and scalable solution.</description>
      <author>example@mail.com (Chenhao Zheng, Jieyu Zhang, Mohammadreza Salehi, Ziqi Gao, Vishnu Iyengar, Norimasa Kobori, Quan Kong, Ranjay Krishna)</author>
      <guid isPermaLink="false">2505.23617v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Graph Positional Autoencoders as Self-supervised Learners</title>
      <link>http://arxiv.org/abs/2505.23345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 3 figures, Accepted at KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GraphPAE是一种新的图自监督学习方法，通过双路径架构来重建节点特征和位置，提高了图自动编码器在预测信息方面的能力。&lt;h4&gt;背景&lt;/h4&gt;图自监督学习旨在在不依赖标记数据的情况下学习有效的图表示，其中图自动编码器因其效率和可扩展性而受到关注。&lt;h4&gt;目的&lt;/h4&gt;提出GraphPAE以解决传统节点或边掩码范式在捕捉图中的低频信号和结构信息方面的不足。&lt;h4&gt;方法&lt;/h4&gt;GraphPAE采用双路径架构，特征路径使用位置编码增强消息传递处理，而位置路径利用节点表示来细化位置并近似特征向量。&lt;h4&gt;主要发现&lt;/h4&gt;GraphPAE在异构节点分类、图属性预测和迁移学习等任务上实现了最先进的性能，并且显著优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;GraphPAE通过学习不同频率的信息，有效地提高了图自动编码器的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph self-supervised learning seeks to learn effective graph representationswithout relying on labeled data. Among various approaches, graph autoencoders(GAEs) have gained significant attention for their efficiency and scalability.Typically, GAEs take incomplete graphs as input and predict missing elements,such as masked nodes or edges. While effective, our experimental investigationreveals that traditional node or edge masking paradigms primarily capturelow-frequency signals in the graph and fail to learn the expressive structuralinformation. To address these issues, we propose Graph Positional Autoencoders(GraphPAE), which employs a dual-path architecture to reconstruct both nodefeatures and positions. Specifically, the feature path uses positional encodingto enhance the message-passing processing, improving GAE's ability to predictthe corrupted information. The position path, on the other hand, leverages noderepresentations to refine positions and approximate eigenvectors, therebyenabling the encoder to learn diverse frequency information. We conductextensive experiments to verify the effectiveness of GraphPAE, includingheterophilic node classification, graph property prediction, and transferlearning. The results demonstrate that GraphPAE achieves state-of-the-artperformance and consistently outperforms baselines by a large margin.</description>
      <author>example@mail.com (Yang Liu, Deyu Bo, Wenxuan Cao, Yuan Fang, Yawen Li, Chuan Shi)</author>
      <guid isPermaLink="false">2505.23345v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>FreRA: A Frequency-Refined Augmentation for Contrastive Learning on Time Series Classification</title>
      <link>http://arxiv.org/abs/2505.23181v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对时间序列分类任务的对比学习方法，该方法从频域角度出发，设计了一种轻量级且有效的频域增强方法FreRA，以提高对比学习的表现。&lt;h4&gt;背景&lt;/h4&gt;对比学习在无监督表示学习中表现出色，但在时间序列分类任务中，最优增强策略的设计相对较少探索，现有方法主要借鉴自视觉领域，与时间序列数据不匹配。&lt;h4&gt;目的&lt;/h4&gt;提出一种从频域出发的增强方法，以解决现有方法在时间序列分类任务中的不匹配问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为FreRA的频域增强方法，它能够自动分离重要和不重要的频率成分，并针对重要成分进行语义感知的标识修改，对不重要成分进行语义无关的自适应修改。&lt;h4&gt;主要发现&lt;/h4&gt;FreRA能够生成语义保持的视图，在UCR、UEA档案以及五个大规模数据集上的实验表明，FreRA在时间序列分类、异常检测和迁移学习任务上优于十个基线方法。&lt;h4&gt;结论&lt;/h4&gt;FreRA在对比表示学习和迁移学习场景下的泛化能力方面表现出优越性。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive learning has emerged as a competent approach for unsupervised representation learning. However, the design of an optimal augmentation strategy, although crucial for contrastive learning, is less explored for time series classification tasks. Existing predefined time-domain augmentation methods are primarily adopted from vision and are not specific to time series data. Consequently, this cross-modality incompatibility may distort the semantically relevant information of time series by introducing mismatched patterns into the data. To address this limitation, we present a novel perspective from the frequency domain and identify three advantages for downstream classification: global, independent, and compact. To fully utilize the three properties, we propose the lightweight yet effective Frequency Refined Augmentation (FreRA) tailored for time series contrastive learning on classification tasks, which can be seamlessly integrated with contrastive learning frameworks in a plug-and-play manner. Specifically, FreRA automatically separates critical and unimportant frequency components. Accordingly, we propose semantic-aware Identity Modification and semantic-agnostic Self-adaptive Modification to protect semantically relevant information in the critical frequency components and infuse variance into the unimportant ones respectively. Theoretically, we prove that FreRA generates semantic-preserving views. Empirically, we conduct extensive experiments on two benchmark datasets, including UCR and UEA archives, as well as five large-scale datasets on diverse applications. FreRA consistently outperforms ten leading baselines on time series classification, anomaly detection, and transfer learning tasks, demonstrating superior capabilities in contrastive representation learning and generalization in transfer learning scenarios across diverse datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3736969&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning has emerged as a competent approach for unsupervisedrepresentation learning. However, the design of an optimal augmentationstrategy, although crucial for contrastive learning, is less explored for timeseries classification tasks. Existing predefined time-domain augmentationmethods are primarily adopted from vision and are not specific to time seriesdata. Consequently, this cross-modality incompatibility may distort thesemantically relevant information of time series by introducing mismatchedpatterns into the data. To address this limitation, we present a novelperspective from the frequency domain and identify three advantages fordownstream classification: global, independent, and compact. To fully utilizethe three properties, we propose the lightweight yet effective FrequencyRefined Augmentation (FreRA) tailored for time series contrastive learning onclassification tasks, which can be seamlessly integrated with contrastivelearning frameworks in a plug-and-play manner. Specifically, FreRAautomatically separates critical and unimportant frequency components.Accordingly, we propose semantic-aware Identity Modification andsemantic-agnostic Self-adaptive Modification to protect semantically relevantinformation in the critical frequency components and infuse variance into theunimportant ones respectively. Theoretically, we prove that FreRA generatessemantic-preserving views. Empirically, we conduct extensive experiments on twobenchmark datasets, including UCR and UEA archives, as well as five large-scaledatasets on diverse applications. FreRA consistently outperforms ten leadingbaselines on time series classification, anomaly detection, and transferlearning tasks, demonstrating superior capabilities in contrastiverepresentation learning and generalization in transfer learning scenariosacross diverse datasets.</description>
      <author>example@mail.com (Tian Tian, Chunyan Miao, Hangwei Qian)</author>
      <guid isPermaLink="false">2505.23181v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>LeMoRe: Learn More Details for Lightweight Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2505.23093v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IEEE ICIP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种高效的光照语义分割方法，旨在平衡计算效率和表现力。&lt;h4&gt;背景&lt;/h4&gt;现有的语义分割方法在特征建模的复杂性面前难以兼顾效率和性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种通过结合显式和隐式建模来平衡计算效率与表现力的有效方法。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了明确的笛卡尔方向、显式建模的视图和隐式推断的中间表示，通过嵌套注意力机制高效捕捉全局依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;在ADE20K、CityScapes、Pascal Context和COCO-Stuff等具有挑战性的数据集上进行了广泛实验，证明了LeMoRe在性能和效率之间取得了有效平衡。&lt;h4&gt;结论&lt;/h4&gt;LeMoRe方法在语义分割任务中实现了效率与性能的有效平衡。&lt;h4&gt;翻译&lt;/h4&gt;摘要：轻量级语义分割对于许多下游视觉任务至关重要。遗憾的是，现有方法由于特征建模的复杂性，往往难以在效率和性能之间取得平衡。许多这些方法受到刚性架构和隐式表示学习的限制，通常以参数密集的设计和对计算密集型基于视觉Transformer框架的依赖为特征。在本工作中，我们通过结合显式和隐式建模来协同提高计算效率和表现力，提出了一种高效的方法。我们的方法结合了明确的笛卡尔方向、显式建模的视图和隐式推断的中间表示，通过嵌套注意力机制有效地捕捉全局依赖关系。在包括ADE20K、CityScapes、Pascal Context和COCO-Stuff在内的具有挑战性的数据集上进行的广泛实验表明，LeMoRe在性能和效率之间取得了有效的平衡。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lightweight semantic segmentation is essential for many downstream visiontasks. Unfortunately, existing methods often struggle to balance efficiency andperformance due to the complexity of feature modeling. Many of these existingapproaches are constrained by rigid architectures and implicit representationlearning, often characterized by parameter-heavy designs and a reliance oncomputationally intensive Vision Transformer-based frameworks. In this work, weintroduce an efficient paradigm by synergizing explicit and implicit modelingto balance computational efficiency with representational fidelity. Our methodcombines well-defined Cartesian directions with explicitly modeled views andimplicitly inferred intermediate representations, efficiently capturing globaldependencies through a nested attention mechanism. Extensive experiments onchallenging datasets, including ADE20K, CityScapes, Pascal Context, andCOCO-Stuff, demonstrate that LeMoRe strikes an effective balance betweenperformance and efficiency.</description>
      <author>example@mail.com (Mian Muhammad Naeem Abid, Nancy Mehta, Zongwei Wu, Radu Timofte)</author>
      <guid isPermaLink="false">2505.23093v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>DORAEMON: Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation</title>
      <link>http://arxiv.org/abs/2505.21969v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DORAEMON的认知启发式框架，用于在未知环境中实现自适应导航，旨在解决现有基于视觉-语言模型(VLM)的零样本方法在时空连续性、记忆表示和任务理解方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;自适应导航对于家庭服务机器人至关重要，但需要低级路径规划和高级场景理解，这给机器人带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以解决现有方法在时空连续性、记忆表示和任务理解方面的不足，实现无地图构建或预训练的零样本自主导航。&lt;h4&gt;方法&lt;/h4&gt;DORAEMON框架由腹侧流和背侧流组成，腹侧流通过层次语义-空间融合和拓扑图处理时空连续性，背侧流结合RAG-VLM和Policy-VLM以改善决策。此外，还开发了Nav-Ensurance来确保导航的安全性和效率。&lt;h4&gt;主要发现&lt;/h4&gt;DORAEMON在HM3D、MP3D和GOAT数据集上进行了评估，在成功率(SR)和成功加权路径长度(SPL)指标上均达到最先进水平，显著优于现有方法。同时，引入了新的评估指标(AORI)来更好地评估导航智能。&lt;h4&gt;结论&lt;/h4&gt;DORAEMON在零样本自主导航方面表现优异，无需预先构建地图或进行预训练，为家庭服务机器人在未知环境中的导航提供了有效解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adaptive navigation in unfamiliar environments is crucial for householdservice robots but remains challenging due to the need for both low-level pathplanning and high-level scene understanding. While recent vision-language model(VLM) based zero-shot approaches reduce dependence on prior maps andscene-specific training data, they face significant limitations: spatiotemporaldiscontinuity from discrete observations, unstructured memory representations,and insufficient task understanding leading to navigation failures. We proposeDORAEMON (Decentralized Ontology-aware Reliable Agent with Enhanced MemoryOriented Navigation), a novel cognitive-inspired framework consisting ofVentral and Dorsal Streams that mimics human navigation capabilities. TheDorsal Stream implements the Hierarchical Semantic-Spatial Fusion and TopologyMap to handle spatiotemporal discontinuities, while the Ventral Stream combinesRAG-VLM and Policy-VLM to improve decision-making. Our approach also developsNav-Ensurance to ensure navigation safety and efficiency. We evaluate DORAEMONon the HM3D, MP3D, and GOAT datasets, where it achieves state-of-the-artperformance on both success rate (SR) and success weighted by path length (SPL)metrics, significantly outperforming existing methods. We also introduce a newevaluation metric (AORI) to assess navigation intelligence better.Comprehensive experiments demonstrate DORAEMON's effectiveness in zero-shotautonomous navigation without requiring prior map building or pre-training.</description>
      <author>example@mail.com (Tianjun Gu, Linfeng Li, Xuhong Wang, Chenghua Gong, Jingyu Gong, Zhizhong Zhang, Yuan Xie, Lizhuang Ma, Xin Tan)</author>
      <guid isPermaLink="false">2505.21969v2</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Geometric and Semantic Foundation Models for Generalized Monocular Depth Estimation</title>
      <link>http://arxiv.org/abs/2505.23400v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BriGeS的有效方法，该方法通过融合几何和语义信息来增强单目深度估计（MDE）。&lt;h4&gt;背景&lt;/h4&gt;在MDE领域，深度和分割基础模型各自有其优势，但如何有效结合这两个方面仍是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在通过融合几何和语义信息，提高MDE的准确性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;BriGeS的核心是Bridging Gate，该门控机制结合了深度和分割模型的优势，并使用注意力温度缩放技术微调注意力机制，避免过度关注特定特征。此外，该方法仅训练Bridging Gate，以减少资源需求和训练时间。&lt;h4&gt;主要发现&lt;/h4&gt;在多个挑战性数据集上的广泛实验表明，BriGeS在复杂场景的MDE任务中优于现有方法，有效处理复杂结构和重叠物体。&lt;h4&gt;结论&lt;/h4&gt;BriGeS是一种高效的单目深度估计方法，能够有效结合几何和语义信息，实现更准确和鲁棒的深度估计。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了BriGeS，一种在基础模型中融合几何和语义信息以增强单目深度估计的有效方法。BriGeS的核心是Bridging Gate，它结合了深度和分割基础模型的互补优势。这种整合通过我们的注意力温度缩放技术进一步细化，该技术精细调整注意力机制的焦点，以防止过度关注特定特征，从而确保在多种输入上保持平衡的性能。BriGeS利用预训练的基础模型，并采用仅训练Bridging Gate的策略。这种方法显著减少了资源需求和训练时间，同时保持了模型有效地泛化的能力。在多个具有挑战性的数据集上的广泛实验表明，BriGeS在复杂场景的MDE中优于最先进的方法，能够有效地处理复杂结构和重叠物体。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Bridging Geometric and Semantic (BriGeS), an effective method thatfuses geometric and semantic information within foundation models to enhanceMonocular Depth Estimation (MDE). Central to BriGeS is the Bridging Gate, whichintegrates the complementary strengths of depth and segmentation foundationmodels. This integration is further refined by our Attention TemperatureScaling technique. It finely adjusts the focus of the attention mechanisms toprevent over-concentration on specific features, thus ensuring balancedperformance across diverse inputs. BriGeS capitalizes on pre-trained foundationmodels and adopts a strategy that focuses on training only the Bridging Gate.This method significantly reduces resource demands and training time whilemaintaining the model's ability to generalize effectively. Extensiveexperiments across multiple challenging datasets demonstrate that BriGeSoutperforms state-of-the-art methods in MDE for complex scenes, effectivelyhandling intricate structures and overlapping objects.</description>
      <author>example@mail.com (Sanggyun Ma, Wonjoon Choi, Jihun Park, Jaeyeul Kim, Seunghun Lee, Jiwan Seo, Sunghoon Im)</author>
      <guid isPermaLink="false">2505.23400v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Case-Based Reasoning Enhances the Predictive Power of LLMs in Drug-Drug Interaction</title>
      <link>http://arxiv.org/abs/2505.23034v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为CBR-DDI的新型框架，用于药物相互作用（DDI）预测，该框架通过案例推理（CBR）从历史案例中提炼药理学原则，以提升大型语言模型（LLM）在DDI任务中的推理能力。&lt;h4&gt;背景&lt;/h4&gt;药物相互作用预测对治疗安全性至关重要，尽管大型语言模型在药物任务中显示出潜力，但其对DDI预测的有效性仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提高LLM在DDI预测任务中的推理能力。&lt;h4&gt;方法&lt;/h4&gt;CBR-DDI通过利用LLM提取药理学见解和图神经网络（GNN）建模药物关联来构建知识库。采用混合检索机制和双层知识增强提示，使LLM能够有效地检索和重用相关案例。此外，还引入了一种代表性采样策略，用于动态案例细化。&lt;h4&gt;主要发现&lt;/h4&gt;CBR-DDI在大量实验中实现了最先进的性能，与流行的LLM和CBR基线相比，准确率提高了28.7%，同时保持了高可解释性和灵活性。&lt;h4&gt;结论&lt;/h4&gt;CBR-DDI框架在药物相互作用预测中表现出色，为LLM在药物任务中的应用提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drug-drug interaction (DDI) prediction is critical for treatment safety.While large language models (LLMs) show promise in pharmaceutical tasks, theireffectiveness in DDI prediction remains challenging. Inspired by thewell-established clinical practice where physicians routinely reference similarhistorical cases to guide their decisions through case-based reasoning (CBR),we propose CBR-DDI, a novel framework that distills pharmacological principlesfrom historical cases to improve LLM reasoning for DDI tasks. CBR-DDIconstructs a knowledge repository by leveraging LLMs to extract pharmacologicalinsights and graph neural networks (GNNs) to model drug associations. A hybridretrieval mechanism and dual-layer knowledge-enhanced prompting allow LLMs toeffectively retrieve and reuse relevant cases. We further introduce arepresentative sampling strategy for dynamic case refinement. Extensiveexperiments demonstrate that CBR-DDI achieves state-of-the-art performance,with a significant 28.7% accuracy improvement over both popular LLMs and CBRbaseline, while maintaining high interpretability and flexibility.</description>
      <author>example@mail.com (Guangyi Liu, Yongqi Zhang, Xunyuan Liu, Quanming Yao)</author>
      <guid isPermaLink="false">2505.23034v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>QLIP: A Dynamic Quadtree Vision Prior Enhances MLLM Performance Without Retraining</title>
      <link>http://arxiv.org/abs/2505.23004v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 19 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了QLIP模型，作为CLIP视觉编码器的替代品，用于提升多模态大语言模型（MLLMs）的视觉理解能力，同时避免了重训练的需要。&lt;h4&gt;背景&lt;/h4&gt;现有的MLLMs，如CLIP模型，其视觉编码器存在限制，包括处理固定输入分辨率和无法为不同图像生成分离嵌入的问题。&lt;h4&gt;目的&lt;/h4&gt;解决CLIP视觉编码器的限制，提出一个可以无缝集成到现有MLLMs中的替代方案，同时增强视觉理解能力。&lt;h4&gt;方法&lt;/h4&gt;QLIP模型基于图像四叉树，用内容感知的补丁化方法替换了标准的均匀网格补丁，以解决CLIP视觉编码器的微观偏差和插值偏差问题。&lt;h4&gt;主要发现&lt;/h4&gt;QLIP在不重训练或微调整个MLLM的情况下，提升了LLaVA v1.5模型系列在各种模型大小上的视觉问答准确率，并在V^*基准测试中提升了13.6%的详细理解性能。&lt;h4&gt;结论&lt;/h4&gt;QLIP是一个有效的CLIP视觉编码器替代品，能够显著提升MLLMs的视觉理解能力，且易于集成和使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) encode images into visual tokens,aligning visual and textual signals within a shared latent space to facilitatecrossmodal representation learning. The CLIP model is a widely adoptedfoundational vision language model whose vision encoder has played a criticalrole in the development of MLLMs such as LLaVA. However, the CLIP visionencoder suffers from notable limitations including being constrained to onlyhandling fixed input resolutions and a failure to produce separated embeddingsfor dissimilar images. Replacing the vision encoder of an existing modeltypically incurs substantial computational costs because such a change oftennecessitates retraining the entire model pipeline.  In this work, we identify two factors which underlie the limitations of theCLIP vision encoder: mesoscopic bias and interpolation bias. To address theseissues, we propose QLIP, a drop-in replacement for CLIP that can be seamlesslyintegrated with existing MLLMs with only a few lines of code and can enhanceboth coarse-grained and fine-grained visual understanding, without re-training.QLIP is designed around an image quadtree which replaces the standard uniformgrid patches with a novel content aware patchification. Our experimentalresults demonstrate that QLIP improves the general visual question answeringaccuracy of the LLaVA v1.5 model series across various model sizes--withoutrequiring retraining or fine-tuning of the full MLLM. Notably, QLIP boostsdetailed understanding performance on the challenging $V^{\ast}$ benchmark byup to 13.6 percent.</description>
      <author>example@mail.com (Kyle R. Chickering, Bangzheng Li, Muhao Chen)</author>
      <guid isPermaLink="false">2505.23004v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>GenCAD-Self-Repairing: Feasibility Enhancement for 3D CAD Generation</title>
      <link>http://arxiv.org/abs/2505.23287v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GenCAD-Self-Repairing的框架，旨在提高3D模型生成在计算机辅助设计（CAD）领域的可行性。&lt;h4&gt;背景&lt;/h4&gt;随着生成式AI的发展，将AI应用于3D模型生成的研究受到关注，特别是从图像自动生成CAD文件。GenCAD是一个在这一领域有显著贡献的模型，但存在生成不可行边界表示（B-reps）的问题。&lt;h4&gt;目的&lt;/h4&gt;解决GenCAD在生成不可行设计时的局限性，提高生成CAD模型的可行性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种框架，通过扩散引导和自修复流程增强生成CAD模型的可行性。该框架在潜在空间中集成指导扩散去噪过程，并通过基于回归的校正机制来细化不可行的CAD命令序列，同时保持几何精度。&lt;h4&gt;主要发现&lt;/h4&gt;该方法成功将基线方法中三分之二的不可行设计转化为可行设计，显著提高了可行性率，同时保持了真实模型点云和生成模型点云之间合理的几何精度。&lt;h4&gt;结论&lt;/h4&gt;通过显著提高生成CAD模型的可行性，该方法有助于扩大高质量训练数据的可用性，并增强了AI驱动CAD生成在制造业、建筑和产品设计中的应用。&lt;h4&gt;翻译&lt;/h4&gt;With the advancement of generative AI, research on its application to 3D model generation has gained traction, particularly in automating the creation of Computer-Aided Design (CAD) files from images. GenCAD is a notable model in this domain, leveraging an autoregressive transformer-based architecture with a contrastive learning framework to generate CAD programs. However, a major limitation of GenCAD is its inability to consistently produce feasible boundary representations (B-reps), with approximately 10% of generated designs being infeasible. To address this, we propose GenCAD-Self-Repairing, a framework that enhances the feasibility of generative CAD models through diffusion guidance and a self-repairing pipeline. This framework integrates a guided diffusion denoising process in the latent space and a regression-based correction mechanism to refine infeasible CAD command sequences while preserving geometric accuracy. Our approach successfully converted two-thirds of infeasible designs in the baseline method into feasible ones, significantly improving the feasibility rate while simultaneously maintaining a reasonable level of geometric accuracy between the point clouds of ground truth models and generated models. By significantly improving the feasibility rate of generating CAD models, our approach helps expand the availability of high-quality training data and enhances the applicability of AI-driven CAD generation in manufacturing, architecture, and product design.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the advancement of generative AI, research on its application to 3Dmodel generation has gained traction, particularly in automating the creationof Computer-Aided Design (CAD) files from images. GenCAD is a notable model inthis domain, leveraging an autoregressive transformer-based architecture with acontrastive learning framework to generate CAD programs.  However, a major limitation of GenCAD is its inability to consistentlyproduce feasible boundary representations (B-reps), with approximately 10% ofgenerated designs being infeasible. To address this, we proposeGenCAD-Self-Repairing, a framework that enhances the feasibility of generativeCAD models through diffusion guidance and a self-repairing pipeline. Thisframework integrates a guided diffusion denoising process in the latent spaceand a regression-based correction mechanism to refine infeasible CAD commandsequences while preserving geometric accuracy. Our approach successfullyconverted two-thirds of infeasible designs in the baseline method into feasibleones, significantly improving the feasibility rate while simultaneouslymaintaining a reasonable level of geometric accuracy between the point cloudsof ground truth models and generated models.  By significantly improving the feasibility rate of generating CAD models, ourapproach helps expand the availability of high-quality training data andenhances the applicability of AI-driven CAD generation in manufacturing,architecture, and product design.</description>
      <author>example@mail.com (Chikaha Tsuji, Enrique Flores Medina, Harshit Gupta, Md Ferdous Alam)</author>
      <guid isPermaLink="false">2505.23287v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Representing local protein environments with atomistic foundation models</title>
      <link>http://arxiv.org/abs/2505.23354v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于原子基础模型（AFM）中间特征的局部蛋白质环境表示方法，并展示了其在蛋白质建模和生物分子相互作用设计中的应用潜力。&lt;h4&gt;背景&lt;/h4&gt;蛋白质的局部结构对其功能和与其他分子的相互作用有重要影响。然而，蛋白质环境的多样性和复杂性使得对其进行建模具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一个能够有效捕捉局部结构和化学特征的局部蛋白质环境表示方法。&lt;h4&gt;方法&lt;/h4&gt;通过从原子基础模型中提取中间特征，构建了局部蛋白质环境的表示。&lt;h4&gt;主要发现&lt;/h4&gt;该表示方法能够有效捕捉蛋白质的局部结构和化学特征，并且所得到的表示空间具有有意义的结构，可以用于构建数据驱动的生物分子环境分布先验。&lt;h4&gt;结论&lt;/h4&gt;该方法在生物分子核磁共振波谱学领域实现了物理信息化学位移预测，达到了最先进的准确度。研究结果表明，原子基础模型及其涌现表示在蛋白质建模中具有出人意料的成效，有望开启构建蛋白质环境有效功能表示的新方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：蛋白质的局部结构对其功能和与其他分子的相互作用有重要影响。因此，对局部蛋白质环境进行简洁、有效的表示对于建模和设计蛋白质以及生物分子相互作用至关重要。然而，这些环境的广泛的结构和化学多样性使得它们难以建模，并且这类表示方法尚未得到充分探索。在本工作中，我们提出了一种基于原子基础模型（AFMs）中间特征的局部蛋白质环境的新表示方法。我们证明了这种嵌入方法能够有效地捕捉局部结构（例如，二级结构基序）和化学特征（例如，氨基酸身份和质子化状态）。我们进一步表明，从AFM导出的表示空间显示出有意义的结构，使得能够构建关于生物分子环境分布的数据驱动先验。最后，在生物分子核磁共振波谱学的背景下，我们证明了所提出的表示方法实现了一种前所未有的物理信息化学位移预测器，达到了最先进的准确度。我们的结果证明了原子基础模型及其涌现表示在蛋白质建模中的出人意料的成效，超出了传统分子模拟的范畴。我们相信这将开启构建蛋白质环境有效功能表示的新研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The local structure of a protein strongly impacts its function andinteractions with other molecules. Therefore, a concise, informativerepresentation of a local protein environment is essential for modeling anddesigning proteins and biomolecular interactions. However, these environments'extensive structural and chemical variability makes them challenging to model,and such representations remain under-explored. In this work, we propose anovel representation for a local protein environment derived from theintermediate features of atomistic foundation models (AFMs). We demonstratethat this embedding effectively captures both local structure (e.g., secondarymotifs), and chemical features (e.g., amino-acid identity and protonationstate). We further show that the AFM-derived representation space exhibitsmeaningful structure, enabling the construction of data-driven priors over thedistribution of biomolecular environments. Finally, in the context ofbiomolecular NMR spectroscopy, we demonstrate that the proposed representationsenable a first-of-its-kind physics-informed chemical shift predictor thatachieves state-of-the-art accuracy. Our results demonstrate the surprisingeffectiveness of atomistic foundation models and their emergent representationsfor protein modeling beyond traditional molecular simulations. We believe thiswill open new lines of work in constructing effective functionalrepresentations for protein environments.</description>
      <author>example@mail.com (Meital Bojan, Sanketh Vedula, Advaith Maddipatla, Nadav Bojan Sellam, Federico Napoli, Paul Schanda, Alex M. Bronstein)</author>
      <guid isPermaLink="false">2505.23354v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Hyperbolic-PDE GNN: Spectral Graph Neural Networks in the Perspective of A System of Hyperbolic Partial Differential Equations</title>
      <link>http://arxiv.org/abs/2505.23014v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 2 figures, published to ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用双曲偏微分方程（hyperbolic PDEs）进行图神经网络（GNNs）消息传递的新方法，该方法能够增强拓扑特征的学习和解释性。&lt;h4&gt;背景&lt;/h4&gt;传统的GNNs在非拓扑相关的空间域学习节点特征，难以确保拓扑特征的有效学习。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来学习图数据的拓扑特征，并增强消息传递的可解释性。&lt;h4&gt;方法&lt;/h4&gt;将消息传递建模为双曲偏微分方程系统，将节点表示映射到特定解空间，该空间由描述图拓扑结构的特征向量生成。&lt;h4&gt;主要发现&lt;/h4&gt;通过这种方法，节点特征可以分解为特征向量的叠加，这不仅提高了消息传递的可解释性，还允许显式提取拓扑结构的特征。该方法与谱图神经网络（spectral GNNs）建立了联系，并作为一种消息传递增强范式。&lt;h4&gt;结论&lt;/h4&gt;实验表明，这种基于双曲偏微分方程的范式具有强大的灵活性，并显著提高了各种谱GNNs在不同图任务上的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图神经网络（GNNs）利用消息传递机制来学习图数据的拓扑特征。传统的GNNs在与其拓扑无关的空间域学习节点特征，这几乎不能保证拓扑特征的有效学习。在本文中，我们将消息传递建模为双曲偏微分方程（hyperbolic PDEs）系统，构成了一个将节点表示明确映射到特定解空间的动力学系统。这个解空间由描述图拓扑结构的特征向量集生成。在这个系统中，对于任何时刻，节点特征都可以分解为特征向量的叠加。这不仅增强了消息传递的可解释性，还允许显式提取关于拓扑结构的基本特征。此外，通过求解这个双曲偏微分方程系统，我们建立了与谱图神经网络（spectral GNNs）的联系，作为谱GNNs的消息传递增强范式。我们进一步引入多项式来近似任意滤波函数。大量的实验表明，基于双曲偏微分方程的范式不仅表现出强大的灵活性，而且还显著提高了各种谱GNNs在不同图任务上的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) leverage message passing mechanisms to learn thetopological features of graph data. Traditional GNNs learns node features in aspatial domain unrelated to the topology, which can hardly ensure topologicalfeatures. In this paper, we formulates message passing as a system ofhyperbolic partial differential equations (hyperbolic PDEs), constituting adynamical system that explicitly maps node representations into a particularsolution space. This solution space is spanned by a set of eigenvectorsdescribing the topological structure of graphs. Within this system, for anymoment in time, a node features can be decomposed into a superposition of thebasis of eigenvectors. This not only enhances the interpretability of messagepassing but also enables the explicit extraction of fundamental characteristicsabout the topological structure. Furthermore, by solving this system ofhyperbolic partial differential equations, we establish a connection withspectral graph neural networks (spectral GNNs), serving as a message passingenhancement paradigm for spectral GNNs.We further introduce polynomials toapproximate arbitrary filter functions. Extensive experiments demonstrate thatthe paradigm of hyperbolic PDEs not only exhibits strong flexibility but alsosignificantly enhances the performance of various spectral GNNs across diversegraph tasks.</description>
      <author>example@mail.com (Juwei Yue, Haikuo Li, Jiawei Sheng, Xiaodong Li, Taoyu Su, Tingwen Liu, Li Guo)</author>
      <guid isPermaLink="false">2505.23014v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>VideoReasonBench: Can MLLMs Perform Vision-Centric Complex Video Reasoning?</title>
      <link>http://arxiv.org/abs/2505.23359v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://llyx97.github.io/video_reason_bench/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了长链思考（CoT）推理对大型语言模型（LLMs）在复杂任务上的性能提升作用，并引入了VideoReasonBench作为视频推理基准来评估视觉中心化的复杂视频推理能力。&lt;h4&gt;背景&lt;/h4&gt;虽然长链思考推理在复杂任务上对LLMs性能提升有显著作用，但在视频理解领域，这一优势尚未得到证实，因为大多数现有基准缺乏足够的推理深度来展示扩展CoT链的优势。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文提出了VideoReasonBench基准，旨在评估视觉中心化的复杂视频推理。&lt;h4&gt;方法&lt;/h4&gt;VideoReasonBench中的每个视频都描述了在视频部分可见的潜在状态上的一系列细粒度操作。问题评估了三个递增的视频推理技能水平：回忆观察到的视觉信息、推断潜在状态的内容以及预测视频之外的信息。&lt;h4&gt;主要发现&lt;/h4&gt;使用VideoReasonBench对18个最先进的多模态LLMs进行了评估，发现大多数在复杂视频推理上表现不佳，例如GPT-4o的准确率仅为6.9%，而增强思考的Gemini-2.5-Pro准确率达到56.0%。对“测试时扩展”的研究进一步揭示了扩展思考预算在提高VideoReasonBench上的性能是必要的。&lt;h4&gt;结论&lt;/h4&gt;扩展思考预算对于在VideoReasonBench上提高性能至关重要，而现有的视频基准对此并没有或只有极小的帮助。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies have shown that long chain-of-thought (CoT) reasoning cansignificantly enhance the performance of large language models (LLMs) oncomplex tasks. However, this benefit is yet to be demonstrated in the domain ofvideo understanding, since most existing benchmarks lack the reasoning depthrequired to demonstrate the advantages of extended CoT chains. While recentefforts have proposed benchmarks aimed at video reasoning, the tasks are oftenknowledge-driven and do not rely heavily on visual content. To bridge this gap,we introduce VideoReasonBench, a benchmark designed to evaluate vision-centric,complex video reasoning. To ensure visual richness and high reasoningcomplexity, each video in VideoReasonBench depicts a sequence of fine-grainedoperations on a latent state that is only visible in part of the video. Thequestions evaluate three escalating levels of video reasoning skills: recallingobserved visual information, inferring the content of latent states, andpredicting information beyond the video. Under such task setting, models haveto precisely recall multiple operations in the video, and perform step-by-stepreasoning to get correct final answers for these questions. UsingVideoReasonBench, we comprehensively evaluate 18 state-of-the-art multimodalLLMs (MLLMs), finding that most perform poorly on complex video reasoning,e.g., GPT-4o achieves only 6.9% accuracy, while the thinking-enhancedGemini-2.5-Pro significantly outperforms others with 56.0% accuracy. Ourinvestigations on "test-time scaling" further reveal that extended thinkingbudget, while offering none or minimal benefits on existing video benchmarks,is essential for improving the performance on VideoReasonBench.</description>
      <author>example@mail.com (Yuanxin Liu, Kun Ouyang, Haoning Wu, Yi Liu, Lin Sui, Xinhao Li, Yan Zhong, Y. Charles, Xinyu Zhou, Xu Sun)</author>
      <guid isPermaLink="false">2505.23359v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Federated Unsupervised Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2505.23292v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了联邦学习（FL）在无监督语义图像分割（USS）中的应用。&lt;h4&gt;背景&lt;/h4&gt;现有的USS方法使用冻结的视觉基础模型提取像素级特征，并通过自监督目标来鼓励语义分组，然后将这些特征分组到语义簇中以生成分割掩码。&lt;h4&gt;目的&lt;/h4&gt;将上述思想扩展到联邦环境中，需要跨分布式客户端的特征表示和簇中心对齐，在没有监督的情况下，这是一个在异构数据分布中固有的困难任务。&lt;h4&gt;方法&lt;/h4&gt;提出了FUSS（联邦无监督图像语义分割）框架，这是第一个实现完全去中心化、无标签语义分割训练的框架。FUSS引入了新的联邦策略，以促进特征和原型空间中的全局一致性，联合优化局部分割头和共享语义中心。&lt;h4&gt;主要发现&lt;/h4&gt;在基准和真实世界数据集上的实验，包括二分类和多分类分割任务，表明FUSS在变化客户端数据分布下，始终优于仅本地客户端训练以及经典联邦算法的扩展。&lt;h4&gt;结论&lt;/h4&gt;为了支持可重复性，一旦论文被接受，将发布完整代码。&lt;h4&gt;翻译&lt;/h4&gt;这项工作探讨了联邦学习（FL）在无监督语义图像分割（USS）中的应用。最近的无监督语义图像分割方法使用冻结的视觉基础模型提取像素级特征，并通过自监督目标来鼓励语义分组。然后，将这些特征分组到语义簇中以生成分割掩码。将上述思想扩展到联邦环境需要跨分布式客户端的特征表示和簇中心对齐——在没有监督的情况下，这是在异构数据分布中固有的困难任务。为了解决这个问题，我们提出了FUSS（联邦无监督图像语义分割）框架，据我们所知，这是第一个实现完全去中心化、无标签语义分割训练的框架。FUSS引入了新的联邦策略，以促进特征和原型空间中的全局一致性，联合优化局部分割头和共享语义中心。在基准和真实世界数据集上的实验，包括二分类和多分类分割任务，表明FUSS在变化客户端数据分布下，始终优于仅本地客户端训练以及经典联邦算法的扩展。为了支持可重复性，一旦论文被接受，将发布完整代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work explores the application of Federated Learning (FL) in UnsupervisedSemantic image Segmentation (USS). Recent USS methods extract pixel-levelfeatures using frozen visual foundation models and refine them throughself-supervised objectives that encourage semantic grouping. These features arethen grouped to semantic clusters to produce segmentation masks. Extendingthese ideas to federated settings requires feature representation and clustercentroid alignment across distributed clients -- an inherently difficult taskunder heterogeneous data distributions in the absence of supervision. Toaddress this, we propose FUSS Federated Unsupervised image SemanticSegmentation) which is, to our knowledge, the first framework to enable fullydecentralized, label-free semantic segmentation training. FUSS introduces novelfederation strategies that promote global consistency in feature and prototypespace, jointly optimizing local segmentation heads and shared semanticcentroids. Experiments on both benchmark and real-world datasets, includingbinary and multi-class segmentation tasks, show that FUSS consistentlyoutperforms local-only client trainings as well as extensions of classical FLalgorithms under varying client data distributions. To support reproducibility,full code will be released upon manuscript acceptance.</description>
      <author>example@mail.com (Evangelos Charalampakis, Vasileios Mygdalis, Ioannis Pitas)</author>
      <guid isPermaLink="false">2505.23292v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>CryoCCD: Conditional Cycle-consistent Diffusion with Biophysical Modeling for Cryo-EM Synthesis</title>
      <link>http://arxiv.org/abs/2505.23444v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CryoCCD是一种合成框架，结合生物物理建模和生成技术，用于生成高质量、结构准确的冷冻电镜图像，以提高下游分析的性能。&lt;h4&gt;背景&lt;/h4&gt;冷冻电镜（cryo-EM）可以提供大分子的高原子分辨率成像，但下游分析模型的开发受到高质量标注数据的稀缺性的阻碍。&lt;h4&gt;目的&lt;/h4&gt;提出CryoCCD以克服现有方法在捕捉生物样本的结构多样性和冷冻电镜成像中固有的复杂、空间变化的噪声方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;CryoCCD通过生物物理建模和生成技术生成多尺度冷冻电镜图像，使用条件扩散模型生成现实噪声，并采用循环一致性增强和掩码感知对比学习来捕获空间自适应噪声模式。&lt;h4&gt;主要发现&lt;/h4&gt;CryoCCD生成的微图结构准确，在下游任务中提高了性能，在颗粒挑选和重建方面优于最先进的基线。&lt;h4&gt;结论&lt;/h4&gt;CryoCCD是一个有效的合成框架，可以生成高质量的冷冻电镜图像，为下游分析提供更好的数据支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cryo-electron microscopy (cryo-EM) offers near-atomic resolution imaging ofmacromolecules, but developing robust models for downstream analysis ishindered by the scarcity of high-quality annotated data. While synthetic datageneration has emerged as a potential solution, existing methods often fail tocapture both the structural diversity of biological specimens and the complex,spatially varying noise inherent in cryo-EM imaging. To overcome theselimitations, we propose CryoCCD, a synthesis framework that integratesbiophysical modeling with generative techniques. Specifically, CryoCCD producesmulti-scale cryo-EM micrographs that reflect realistic biophysical variabilitythrough compositional heterogeneity, cellular context, and physics-informedimaging. To generate realistic noise, we employ a conditional diffusion model,enhanced by cycle consistency to preserve structural fidelity and mask-awarecontrastive learning to capture spatially adaptive noise patterns. Extensiveexperiments show that CryoCCD generates structurally accurate micrographs andenhances performance in downstream tasks, outperforming state-of-the-artbaselines in both particle picking and reconstruction.</description>
      <author>example@mail.com (Runmin Jiang, Genpei Zhang, Yuntian Yang, Siqi Wu, Yuheng Zhang, Wanyue Feng, Yizhou Zhao, Xi Xiao, Xiao Wang, Tianyang Wang, Xingjian Li, Min Xu)</author>
      <guid isPermaLink="false">2505.23444v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>PreFM: Online Audio-Visual Event Parsing via Predictive Future Modeling</title>
      <link>http://arxiv.org/abs/2505.23155v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了在线音频-视觉事件解析（On-AVEP），一种新的音频、视觉和音频-视觉事件解析范式，通过顺序分析传入的视频流，旨在实现实时多模态视频理解。&lt;h4&gt;背景&lt;/h4&gt;现有的音频-视觉事件解析方法通常依赖于离线处理整个视频，模型尺寸巨大，限制了它们的实时应用。&lt;h4&gt;目的&lt;/h4&gt;开发一个具有高精度在线推理能力和实时效率的模型，以有效区分在线设置中背景不清晰和有限的事件。&lt;h4&gt;方法&lt;/h4&gt;提出预测未来建模（PreFM）框架，包括：(a) 预测多模态未来建模以推断和整合有益的未来音频-视觉线索，增强上下文理解；(b) 模态无关的鲁棒表示和焦点时间优先级，以改进精确度和泛化。&lt;h4&gt;主要发现&lt;/h4&gt;在UnAV-100和LLP数据集上的广泛实验表明，PreFM在参数显著减少的情况下，比最先进的算法有显著的性能提升，为实时多模态视频理解提供了有洞见的途径。&lt;h4&gt;结论&lt;/h4&gt;PreFM框架是实时音频-视觉事件解析的有效解决方案，对多模态视频理解领域具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;Audio-visual event parsing plays a crucial role in understanding multimodal video content, but existing methods typically rely on offline processing of entire videos with huge model sizes, limiting their real-time applicability. We introduce Online Audio-Visual Event Parsing (On-AVEP), a novel paradigm for parsing audio, visual, and audio-visual events by sequentially analyzing incoming video streams. The On-AVEP task necessitates models with two key capabilities: (1) Accurate online inference, to effectively distinguish events with unclear and limited context in online settings, and (2) Real-time efficiency, to balance high performance with computational constraints. To cultivate these, we propose the Predictive Future Modeling (PreFM) framework featured by (a) predictive multimodal future modeling to infer and integrate beneficial future audio-visual cues, thereby enhancing contextual understanding and (b) modality-agnostic robust representation along with focal temporal prioritization to improve precision and generalization. Extensive experiments on the UnAV-100 and LLP datasets show PreFM significantly outperforms state-of-the-art methods by a large margin with significantly fewer parameters, offering an insightful approach for real-time multimodal video understanding. Code is available at https://github.com/XiaoYu-1123/PreFM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio-visual event parsing plays a crucial role in understanding multimodalvideo content, but existing methods typically rely on offline processing ofentire videos with huge model sizes, limiting their real-time applicability. Weintroduce Online Audio-Visual Event Parsing (On-AVEP), a novel paradigm forparsing audio, visual, and audio-visual events by sequentially analyzingincoming video streams. The On-AVEP task necessitates models with two keycapabilities: (1) Accurate online inference, to effectively distinguish eventswith unclear and limited context in online settings, and (2) Real-timeefficiency, to balance high performance with computational constraints. Tocultivate these, we propose the Predictive Future Modeling (PreFM) frameworkfeatured by (a) predictive multimodal future modeling to infer and integratebeneficial future audio-visual cues, thereby enhancing contextual understandingand (b) modality-agnostic robust representation along with focal temporalprioritization to improve precision and generalization. Extensive experimentson the UnAV-100 and LLP datasets show PreFM significantly outperformsstate-of-the-art methods by a large margin with significantly fewer parameters,offering an insightful approach for real-time multimodal video understanding.Code is available at https://github.com/XiaoYu-1123/PreFM.</description>
      <author>example@mail.com (Xiao Yu, Yan Fang, Xiaojie Jin, Yao Zhao, Yunchao Wei)</author>
      <guid isPermaLink="false">2505.23155v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Pre-training for Recommendation Unlearning</title>
      <link>http://arxiv.org/abs/2505.22649v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to SIGIR 2025 Oral&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为UnlearnRec的模型无关预训练范式，用于提高推荐系统在选择性遗忘训练数据方面的效率。&lt;h4&gt;背景&lt;/h4&gt;现代基于图神经网络（GNN）的推荐系统在建模用户-物品交互方面表现出色，但面临需要选择性遗忘训练数据的新场景。&lt;h4&gt;目的&lt;/h4&gt;解决推荐系统在隐私、偏好变化和监管框架下消除特定用户数据影响的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的模型无关预训练范式UnlearnRec，其Influence Encoder可以直接生成未学习模型的更新参数，无需完全重新训练。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在公共基准数据集上的评估显示，与重新训练方法相比，提供了超过10倍的速度提升，同时保持了模型的性能特征。&lt;h4&gt;结论&lt;/h4&gt;UnlearnRec方法在选择性遗忘训练数据方面表现出优异的效果，同时提高了推荐系统的效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由图神经网络（GNN）驱动的现代推荐系统在建模复杂的用户-物品交互方面表现出色，但日益面临需要选择性遗忘训练数据的情况。除了用户出于隐私关注或偏好变化而请求删除特定交互之外，监管框架还要求推荐系统能够消除某些用户数据对模型的影响。这种推荐反学习挑战具有独特的困难，因为删除交互图中的连接会在整个模型中产生连锁反应，可能影响众多用户的推荐。传统方法存在重大缺陷：碎片化方法会损害图结构并降低性能，而影响函数技术可能不适用于复杂的GNN，尤其是在自监督或随机架构中。为了解决这些限制，我们提出了一种新的模型无关预训练范式UnlearnRec，为系统进行高效的未学习操作做好准备。我们的影响编码器接受未学习请求以及现有的模型参数，并直接生成未学习模型的更新参数，无需大量微调，避免了完全重新训练，同时保留了模型的性能特征。在公共基准数据集上的广泛评估表明，我们的方法提供了卓越的未学习效果，与重新训练方法相比，提供了超过10倍的速度提升。我们将在https://github.com/HKUDS/UnlearnRec上发布我们的方法实现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3726302.3730060&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern recommender systems powered by Graph Neural Networks (GNNs) excel atmodeling complex user-item interactions, yet increasingly face scenariosrequiring selective forgetting of training data. Beyond user requests to removespecific interactions due to privacy concerns or preference changes, regulatoryframeworks mandate recommender systems' ability to eliminate the influence ofcertain user data from models. This recommendation unlearning challengepresents unique difficulties as removing connections within interaction graphscreates ripple effects throughout the model, potentially impactingrecommendations for numerous users. Traditional approaches suffer fromsignificant drawbacks: fragmentation methods damage graph structure anddiminish performance, while influence function techniques make assumptions thatmay not hold in complex GNNs, particularly with self-supervised or randomarchitectures. To address these limitations, we propose a novel model-agnosticpre-training paradigm UnlearnRec that prepares systems for efficient unlearningoperations. Our Influence Encoder takes unlearning requests together withexisting model parameters and directly produces updated parameters of unlearnedmodel with little fine-tuning, avoiding complete retraining while preservingmodel performance characteristics. Extensive evaluation on public benchmarksdemonstrates that our method delivers exceptional unlearning effectivenesswhile providing more than 10x speedup compared to retraining approaches. Werelease our method implementation at: https://github.com/HKUDS/UnlearnRec.</description>
      <author>example@mail.com (Guoxuan Chen, Lianghao Xia, Chao Huang)</author>
      <guid isPermaLink="false">2505.22649v2</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Compositional Scene Understanding through Inverse Generative Modeling</title>
      <link>http://arxiv.org/abs/2505.21780v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025, Webpage:  https://energy-based-model.github.io/compositional-inference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了如何使用生成模型不仅来合成视觉内容，还能理解自然图像中的场景属性。&lt;h4&gt;背景&lt;/h4&gt;生成模型在生成高保真视觉内容方面表现出色。&lt;h4&gt;目的&lt;/h4&gt;探索生成模型在理解场景属性方面的应用。&lt;h4&gt;方法&lt;/h4&gt;将场景理解作为逆向生成建模问题，寻找视觉生成模型的条件参数以最佳拟合给定自然图像。提出从场景的不同部分构建由较小模型组成的视觉生成模型，以实现从与训练过程中看到的图像显著不同的图像中推断场景结构。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够推断场景中的对象集，并能够对具有更多新形状的新测试场景实现稳健的泛化。此外，还可以推断全局场景因素，同样能够对新场景实现稳健的泛化。最后，说明如何将这种方法直接应用于现有的预训练文本到图像生成模型，以实现零样本多对象感知。&lt;h4&gt;结论&lt;/h4&gt;提出了基于组合推理的视觉生成模型，可以有效地理解和合成复杂场景，并对新场景具有泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we explore how generative models can be further used not only to synthesize visual content but also to understand the properties of a scene given a natural image. We formulate scene understanding as an inverse generative modeling problem, where we seek to find conditional parameters of a visual generative model to best fit a given natural image. To enable this procedure to infer scene structure from images substantially different than those seen during training, we further propose to build this visual generative model compositionally from smaller models over pieces of a scene. We illustrate how this procedure enables us to infer the set of objects in a scene, enabling robust generalization to new test scenes with an increased number of objects of new shapes. We further illustrate how this enables us to infer global scene factors, likewise enabling robust generalization to new scenes. Finally, we illustrate how this approach can be directly applied to existing pretrained text-to-image generative models for zero-shot multi-object perception. Code and visualizations are at https://energy-based-model.github.io/compositional-inference.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative models have demonstrated remarkable abilities in generatinghigh-fidelity visual content. In this work, we explore how generative modelscan further be used not only to synthesize visual content but also tounderstand the properties of a scene given a natural image. We formulate sceneunderstanding as an inverse generative modeling problem, where we seek to findconditional parameters of a visual generative model to best fit a given naturalimage. To enable this procedure to infer scene structure from imagessubstantially different than those seen during training, we further propose tobuild this visual generative model compositionally from smaller models overpieces of a scene. We illustrate how this procedure enables us to infer the setof objects in a scene, enabling robust generalization to new test scenes withan increased number of objects of new shapes. We further illustrate how thisenables us to infer global scene factors, likewise enabling robustgeneralization to new scenes. Finally, we illustrate how this approach can bedirectly applied to existing pretrained text-to-image generative models forzero-shot multi-object perception. Code and visualizations are athttps://energy-based-model.github.io/compositional-inference.</description>
      <author>example@mail.com (Yanbo Wang, Justin Dauwels, Yilun Du)</author>
      <guid isPermaLink="false">2505.21780v2</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Maximizing Confidence Alone Improves Reasoning</title>
      <link>http://arxiv.org/abs/2505.22660v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Website: https://rent-rl.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RENT的无监督强化学习方法，用于解决强化学习中的奖励工程问题。&lt;h4&gt;背景&lt;/h4&gt;强化学习在多个领域取得了显著进展，但奖励函数的设计是一个难题。&lt;h4&gt;目的&lt;/h4&gt;开发一种不需要外部奖励或真实答案的强化学习方法。&lt;h4&gt;方法&lt;/h4&gt;RENT通过最小化模型内部分布的熵来作为内在奖励，从而强化高自信度的思维链。&lt;h4&gt;主要发现&lt;/h4&gt;在多个推理基准测试中，该方法展示了模型推理能力的提升，包括GSM8K、MATH500、AMC、AIME和GPQA等。&lt;h4&gt;结论&lt;/h4&gt;该方法在无法获得外部监督的广泛领域中具有适用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：强化学习（RL）使机器学习模型在许多领域取得了显著的进步。最近，RL使前沿语言模型能够解决具有挑战性的数学、科学和编程问题。然而，任何RL算法的核心是奖励函数，而在任何领域中的奖励工程都是一个臭名昭著的难题。在本文中，我们提出了RENT：通过熵最小化进行强化学习——一种完全无监督的RL方法，它不需要外部奖励或真实答案，而是使用模型底层分布的熵作为内在奖励。我们发现，通过强化产生高模型自信度答案的思维链，模型提高了其推理能力。在我们的实验中，我们在包括GSM8K、MATH500、AMC、AIME和GPQA等在内的广泛推理基准测试中展示了这些改进，以及来自Qwen和Mistral家族的各种大小的模型。我们无监督学习方法的通用性使其适用于广泛无法获得外部监督的领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement learning (RL) has enabled machine learning models to achievesignificant advances in many fields. Most recently, RL has empowered frontierlanguage models to solve challenging math, science, and coding problems.However, central to any RL algorithm is the reward function, and rewardengineering is a notoriously difficult problem in any domain. In this paper, wepropose RENT: Reinforcement Learning via Entropy Minimization -- a fullyunsupervised RL method that requires no external reward or ground-truthanswers, and instead uses the model's entropy of its underlying distribution asan intrinsic reward. We find that by reinforcing the chains of thought thatyield high model confidence on its generated answers, the model improves itsreasoning ability. In our experiments, we showcase these improvements on anextensive suite of commonly-used reasoning benchmarks, including GSM8K,MATH500, AMC, AIME, and GPQA, and models of varying sizes from the Qwen andMistral families. The generality of our unsupervised learning method lendsitself to applicability in a wide range of domains where external supervisionis unavailable.</description>
      <author>example@mail.com (Mihir Prabhudesai, Lili Chen, Alex Ippoliti, Katerina Fragkiadaki, Hao Liu, Deepak Pathak)</author>
      <guid isPermaLink="false">2505.22660v2</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Disrupting Vision-Language Model-Driven Navigation Services via Adversarial Object Fusion</title>
      <link>http://arxiv.org/abs/2505.23266v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Adversarial Object Fusion（AdvOF）的新型攻击框架，针对服务导向环境中的视觉和语言导航（VLN）代理，通过生成对抗性3D对象来攻击。AdvOF旨在提高对基于VLM的导航系统在服务计算环境中的安全性。&lt;h4&gt;背景&lt;/h4&gt;虽然大型语言模型（LLMs）和视觉语言模型（VLMs）通过改进感知和决策能力增强了服务导向的导航系统，但它们的集成引入了在任务关键型服务工作流程中的脆弱性。&lt;h4&gt;目的&lt;/h4&gt;利用AdvOF研究并探索对抗性环境对基于VLM的VLN代理感知模块的影响。&lt;h4&gt;方法&lt;/h4&gt;AdvOF首先精确聚合和定位受害对象在2D和3D空间中的位置，定义和渲染对抗性对象。然后，通过在物理属性和VLM感知之间进行正则化，协同优化对抗性对象。通过分配不同视角的重要性权重，优化过程通过迭代融合局部更新和论证来进行，并保持稳定和多方视角。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的评估表明，AdvOF可以在对抗性条件下有效降低代理性能，同时保持对正常导航任务的干扰最小。&lt;h4&gt;结论&lt;/h4&gt;这项工作推进了对基于VLM的导航系统中服务安全性的理解，为物理世界部署中的鲁棒服务组合提供了计算基础。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为Adversarial Object Fusion（AdvOF）的新型攻击框架，针对服务导向环境中的视觉和语言导航（VLN）代理，通过生成对抗性3D对象来攻击。虽然大型语言模型（LLMs）和视觉语言模型（VLMs）通过改进感知和决策能力增强了服务导向的导航系统，但它们的集成引入了在任务关键型服务工作流程中的脆弱性。利用AdvOF研究并探索对抗性环境对基于VLM的VLN代理感知模块的影响。AdvOF首先精确聚合和定位受害对象在2D和3D空间中的位置，定义和渲染对抗性对象。然后，通过在物理属性和VLM感知之间进行正则化，协同优化对抗性对象。通过分配不同视角的重要性权重，优化过程通过迭代融合局部更新和论证来进行，并保持稳定和多方视角。广泛的评估表明，AdvOF可以在对抗性条件下有效降低代理性能，同时保持对正常导航任务的干扰最小。这项工作推进了对基于VLM的导航系统中服务安全性的理解，为物理世界部署中的鲁棒服务组合提供了计算基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Adversarial Object Fusion (AdvOF), a novel attack frameworktargeting vision-and-language navigation (VLN) agents in service-orientedenvironments by generating adversarial 3D objects. While foundational modelslike Large Language Models (LLMs) and Vision Language Models (VLMs) haveenhanced service-oriented navigation systems through improved perception anddecision-making, their integration introduces vulnerabilities inmission-critical service workflows. Existing adversarial attacks fail toaddress service computing contexts, where reliability and quality-of-service(QoS) are paramount. We utilize AdvOF to investigate and explore the impact ofadversarial environments on the VLM-based perception module of VLN agents. Inparticular, AdvOF first precisely aggregates and aligns the victim objectpositions in both 2D and 3D space, defining and rendering adversarial objects.Then, we collaboratively optimize the adversarial object with regularizationbetween the adversarial and victim object across physical properties and VLMperceptions. Through assigning importance weights to varying views, theoptimization is processed stably and multi-viewedly by iterative fusions fromlocal updates and justifications. Our extensive evaluations demonstrate AdvOFcan effectively degrade agent performance under adversarial conditions whilemaintaining minimal interference with normal navigation tasks. This workadvances the understanding of service security in VLM-powered navigationsystems, providing computational foundations for robust service composition inphysical-world deployments.</description>
      <author>example@mail.com (Chunlong Xie, Jialing He, Shangwei Guo, Jiacheng Wang, Shudong Zhang, Tianwei Zhang, Tao Xiang)</author>
      <guid isPermaLink="false">2505.23266v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Improving Contrastive Learning for Referring Expression Counting</title>
      <link>http://arxiv.org/abs/2505.22850v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为C-REX的新型对比学习框架，用于解决Referring Expression Counting（REC）问题，该框架在REC任务中取得了最先进的成果。&lt;h4&gt;背景&lt;/h4&gt;物体计数从特定类别的模型发展到无类别的模型，现在的挑战是如何根据细粒度属性和上下文差异进行物体计数。&lt;h4&gt;目的&lt;/h4&gt;提出C-REX框架，旨在通过对比学习增强判别性表征学习，以解决REC问题。&lt;h4&gt;方法&lt;/h4&gt;C-REX框架基于监督对比学习，完全在图像空间内操作，避免图像-文本对比学习中的错位问题，并保证有更大的负样本池，从而提高学习到的表征的鲁棒性。此外，通过分析基于检测的模型的键组件，发现检测物体质心而非边界框是计数任务成功的关键因素，并据此设计了一个简单有效的基于检测的基线。&lt;h4&gt;主要发现&lt;/h4&gt;C-REX在REC任务中取得了最先进的成果，在MAE和RMSE方面分别优于先前方法22%和10%，同时在无类别计数任务中也表现出色。&lt;h4&gt;结论&lt;/h4&gt;C-REX框架在REC任务中表现出色，为解决该问题提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：物体计数从特定类别的模型发展到无类别的模型，现在的挑战是如何根据细粒度属性和上下文差异进行物体计数。现有的方法在区分视觉上相似但对应不同指代表达式的同一类别物体时存在困难。为了解决这个问题，我们提出了C-REX，一种基于监督对比学习的新型对比学习框架，旨在增强判别性表征学习。与先前工作不同，C-REX完全在图像空间内操作，避免了图像-文本对比学习中的错位问题，从而提供了更稳定的对比信号。它还保证了更大的负样本池，从而提高了学习到的表征的鲁棒性。此外，我们展示了我们的框架足够通用和灵活，可以应用于其他类似任务，如无类别计数。为了支持我们的方法，我们分析了基于检测的sota模型的键组件，并确定检测物体质心而非边界框是它们在计数任务中成功的关键共同因素。我们利用这一见解设计了一个简单而有效的基于检测的基线。我们的实验表明，C-REX在REC任务中实现了最先进的成果，在MAE和RMSE方面分别优于先前方法22%和10%，同时也在无类别计数任务中表现出色。代码可在https://github.com/cvlab-stonybrook/c-rex上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object counting has progressed from class-specific models, which count onlyknown categories, to class-agnostic models that generalize to unseencategories. The next challenge is Referring Expression Counting (REC), wherethe goal is to count objects based on fine-grained attributes and contextualdifferences. Existing methods struggle with distinguishing visually similarobjects that belong to the same category but correspond to different referringexpressions. To address this, we propose C-REX, a novel contrastive learningframework, based on supervised contrastive learning, designed to enhancediscriminative representation learning. Unlike prior works, C-REX operatesentirely within the image space, avoiding the misalignment issues of image-textcontrastive learning, thus providing a more stable contrastive signal. It alsoguarantees a significantly larger pool of negative samples, leading to improvedrobustness in the learned representations. Moreover, we showcase that ourframework is versatile and generic enough to be applied to other similar taskslike class-agnostic counting. To support our approach, we analyze the keycomponents of sota detection-based models and identify that detecting objectcentroids instead of bounding boxes is the key common factor behind theirsuccess in counting tasks. We use this insight to design a simple yet effectivedetection-based baseline to build upon. Our experiments show that C-REXachieves state-of-the-art results in REC, outperforming previous methods bymore than 22\% in MAE and more than 10\% in RMSE, while also demonstratingstrong performance in class-agnostic counting. Code is available athttps://github.com/cvlab-stonybrook/c-rex.</description>
      <author>example@mail.com (Kostas Triaridis, Panagiotis Kaliosis, E-Ro Nguyen, Jingyi Xu, Hieu Le, Dimitris Samaras)</author>
      <guid isPermaLink="false">2505.22850v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>HyperPointFormer: Multimodal Fusion in 3D Space with Dual-Branch Cross-Attention Transformers</title>
      <link>http://arxiv.org/abs/2505.23206v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于3D点云的融合方法，用于在城市场景中进行土地利用/土地覆盖分类。&lt;h4&gt;背景&lt;/h4&gt;目前大多数研究都在2D环境下进行，将3D信息与2D数据结合时，通常会将3D数据转换为2D格式，但这限制了模型直接学习3D空间特征的能力，并减少了输入数据的维度。&lt;h4&gt;目的&lt;/h4&gt;提出一种完全基于3D的方法，融合所有模态的3D点云，并使用专门的Transformer模型同时学习几何和光谱特征。&lt;h4&gt;方法&lt;/h4&gt;引入基于跨注意力的机制，在3D点上完全操作，有效地整合来自不同模态在不同尺度的特征，并通过跨注意力允许一个模态评估另一个模态的重要性。&lt;h4&gt;主要发现&lt;/h4&gt;与2D方法相比，3D融合提供了有竞争力的结果，并提供了更多的灵活性，通过提供3D预测，这些预测可以投影到2D地图上，而反过来则不可行。&lt;h4&gt;结论&lt;/h4&gt;该方法在多个数据集上进行了评估，包括DFC2018、ISPRS Vaihingen 3D和IEEE 2019数据融合竞赛，代码已发布。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态遥感数据，包括光谱和激光雷达或摄影测量，对于在城市场景中实现满意的土地利用/土地覆盖分类结果至关重要。到目前为止，大多数研究都是在2D环境下进行的。当数据集中有3D信息时，通常通过将3D数据转换为2D格式来与2D数据集成。尽管这种方法产生了令人满意的分类结果，但它通过限制模型直接从原始点云中学习3D空间特征的能力，未能充分利用3D数据的潜力。此外，它限制了3D预测的生成，因为输入数据的维度已经减少。在本研究中，我们提出了一种完全基于3D的方法，融合了3D点云中的所有模态，并使用了一个专门的具有双分支的Transformer模型来同时学习几何和光谱特征。为了增强融合过程，我们引入了一种基于跨注意力的机制，该机制完全在3D点上操作，有效地整合了来自不同模态在不同尺度的特征。跨注意力的目的是允许一个模态通过权衡相关特征来评估另一个模态的重要性。我们通过使用2018年IEEE GRSS数据融合竞赛（DFC2018）数据集，将我们的方法与3D和2D方法进行了比较。我们的发现表明，与2D方法相比，3D融合提供了有竞争力的结果，并提供了更多的灵活性，通过提供3D预测。这些预测可以投影到2D地图上，这是反向不可行的。此外，我们在不同的数据集上评估了我们的方法，特别是ISPRS Vaihingen 3D和IEEE 2019数据融合竞赛。我们的代码已发布在https://github.com/aldinorizaldy/hyperpointformer。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal remote sensing data, including spectral and lidar orphotogrammetry, is crucial for achieving satisfactory land-use / land-coverclassification results in urban scenes. So far, most studies have beenconducted in a 2D context. When 3D information is available in the dataset, itis typically integrated with the 2D data by rasterizing the 3D data into 2Dformats. Although this method yields satisfactory classification results, itfalls short in fully exploiting the potential of 3D data by restricting themodel's ability to learn 3D spatial features directly from raw point clouds.Additionally, it limits the generation of 3D predictions, as the dimensionalityof the input data has been reduced. In this study, we propose a fully 3D-basedmethod that fuses all modalities within the 3D point cloud and employs adedicated dual-branch Transformer model to simultaneously learn geometric andspectral features. To enhance the fusion process, we introduce across-attention-based mechanism that fully operates on 3D points, effectivelyintegrating features from various modalities across multiple scales. Thepurpose of cross-attention is to allow one modality to assess the importance ofanother by weighing the relevant features. We evaluated our method by comparingit against both 3D and 2D methods using the 2018 IEEE GRSS Data Fusion Contest(DFC2018) dataset. Our findings indicate that 3D fusion delivers competitiveresults compared to 2D methods and offers more flexibility by providing 3Dpredictions. These predictions can be projected onto 2D maps, a capability thatis not feasible in reverse. Additionally, we evaluated our method on differentdatasets, specifically the ISPRS Vaihingen 3D and the IEEE 2019 Data FusionContest. Our code will be published here:https://github.com/aldinorizaldy/hyperpointformer.</description>
      <author>example@mail.com (Aldino Rizaldy, Richard Gloaguen, Fabian Ewald Fassnacht, Pedram Ghamisi)</author>
      <guid isPermaLink="false">2505.23206v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>cadrille: Multi-modal CAD Reconstruction with Online Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2505.22914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于视觉语言模型的多模态CAD重建模型，旨在通过结合多种输入模态来提高CAD应用的普及性和性能。&lt;h4&gt;背景&lt;/h4&gt;计算机辅助设计（CAD）在工程和制造业中扮演着核心角色，能够创建精确和可编辑的3D模型。然而，现有方法通常仅关注单一输入模态，如点云、图像或文本，这限制了其泛化能力和鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;开发一个多模态CAD重建模型，该模型能够同时处理点云、图像和文本三种输入模态，以提升设计应用的普及性和性能。&lt;h4&gt;方法&lt;/h4&gt;论文采用了两阶段的工作流程：首先在大型程序生成数据上进行监督微调（SFT），然后利用在线反馈进行强化学习（RL）微调。此外，论文首次探索了使用强化学习对大型语言模型（LLM）进行CAD任务微调，并证明了在线强化学习算法如组相对偏好优化（GRPO）优于离线替代方案。&lt;h4&gt;主要发现&lt;/h4&gt;在DeepCAD基准测试中，该论文的SFT模型在所有三种输入模态上均优于现有的单一模态方法。更重要的是，经过RL微调后，该方法在包括真实世界数据集在内的三个具有挑战性的数据集上均达到了新的最先进水平。&lt;h4&gt;结论&lt;/h4&gt;多模态CAD重建模型通过结合视觉语言模型和强化学习技术，显著提高了CAD任务的性能，为CAD设计领域带来了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;Computer-Aided Design (CAD) plays a central role in engineering and manufacturing, making it possible to create precise and editable 3D models. Using a variety of sensor or user-provided data as inputs for CAD reconstruction can democratize access to design applications. However, existing methods typically focus on a single input modality, such as point clouds, images, or text, which limits their generalizability and robustness. Leveraging recent advances in vision-language models (VLM), we propose a multi-modal CAD reconstruction model that simultaneously processes all three input modalities. Inspired by large language model (LLM) training paradigms, we adopt a two-stage pipeline: supervised fine-tuning (SFT) on large-scale procedurally generated data, followed by reinforcement learning (RL) fine-tuning using online feedback, obtained programatically. Furthermore, we are the first to explore RL fine-tuning of LLMs for CAD tasks demonstrating that online RL algorithms such as Group Relative Preference Optimization (GRPO) outperform offline alternatives. In the DeepCAD benchmark, our SFT model outperforms existing single-modal approaches in all three input modalities simultaneously. More importantly, after RL fine-tuning, cadrille sets new state-of-the-art on three challenging datasets, including a real-world one.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computer-Aided Design (CAD) plays a central role in engineering andmanufacturing, making it possible to create precise and editable 3D models.Using a variety of sensor or user-provided data as inputs for CADreconstruction can democratize access to design applications. However, existingmethods typically focus on a single input modality, such as point clouds,images, or text, which limits their generalizability and robustness. Leveragingrecent advances in vision-language models (VLM), we propose a multi-modal CADreconstruction model that simultaneously processes all three input modalities.Inspired by large language model (LLM) training paradigms, we adopt a two-stagepipeline: supervised fine-tuning (SFT) on large-scale procedurally generateddata, followed by reinforcement learning (RL) fine-tuning using onlinefeedback, obtained programatically. Furthermore, we are the first to explore RLfine-tuning of LLMs for CAD tasks demonstrating that online RL algorithms suchas Group Relative Preference Optimization (GRPO) outperform offlinealternatives. In the DeepCAD benchmark, our SFT model outperforms existingsingle-modal approaches in all three input modalities simultaneously. Moreimportantly, after RL fine-tuning, cadrille sets new state-of-the-art on threechallenging datasets, including a real-world one.</description>
      <author>example@mail.com (Maksim Kolodiazhnyi, Denis Tarasov, Dmitrii Zhemchuzhnikov, Alexander Nikulin, Ilya Zisman, Anna Vorontsova, Anton Konushin, Vladislav Kurenkov, Danila Rukhovich)</author>
      <guid isPermaLink="false">2505.22914v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks</title>
      <link>http://arxiv.org/abs/2505.21649v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了DORI（判别性方向推理智能）这一基准，用于评估物体方向感知能力，并揭示了当前视觉语言模型在方向感知上的局限性。&lt;h4&gt;背景&lt;/h4&gt;物体方向理解是视觉感知中的基本挑战，对机器人操作和增强现实等应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;建立物体方向感知作为主要评估目标，评估方向理解的四个维度：正面对齐、旋转变换、相对方向关系和标准方向理解。&lt;h4&gt;方法&lt;/h4&gt;DORI通过从11个数据集中精心挑选的任务，涵盖67个物体类别，在合成和真实世界场景中进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;评估了15个最先进的视觉语言模型，发现它们在粗粒度任务上的准确率仅为54.2%，在细粒度方向判断上的准确率为33.0%，并且当需要参考框架转换或复合旋转时，性能下降。&lt;h4&gt;结论&lt;/h4&gt;DORI表明需要专门的定向表示机制，因为模型在精确角度估计、跨视点跟踪方向变化和理解复合旋转方面存在系统性无能，这表明它们内部的三维空间表示存在局限性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：面向对象的理解是视觉感知中的一个基本挑战，这对于机器人操作和增强现实等应用至关重要。当前的视觉语言基准未能分离这种能力，通常将它们与位置关系和一般场景理解混淆。我们引入了DORI（判别性方向推理智能），这是一个全面的基准，将物体方向感知作为主要评估目标。DORI评估了方向理解的四个维度：正面对齐、旋转变换、相对方向关系和标准方向理解。通过从11个数据集中精心挑选的任务，涵盖67个物体类别，包括合成和真实世界场景，DORI提供了关于多模态系统如何理解物体方向的认识。我们对15个最先进的视觉语言模型进行了评估，揭示了关键局限性：即使是最好的模型在粗粒度任务上的准确率也只有54.2%，在细粒度方向判断上的准确率为33.0%，并且当需要参考框架转换或复合旋转时，性能下降。这些发现表明需要专门的定向表示机制，因为模型显示出系统性地无法执行精确的角度估计、跟踪方向变化以及理解复合旋转——这表明它们内部的三维空间表示存在局限性。作为第一个专为多模态系统中方向意识设计的诊断框架，DORI对改进机器人控制、3D场景重建以及物理环境中的人类-人工智能交互具有影响。DORI数据：https://huggingface.co/datasets/appledora/DORI-Benchmark&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object orientation understanding represents a fundamental challenge in visualperception critical for applications like robotic manipulation and augmentedreality. Current vision-language benchmarks fail to isolate this capability,often conflating it with positional relationships and general sceneunderstanding. We introduce DORI (Discriminative Orientation ReasoningIntelligence), a comprehensive benchmark establishing object orientationperception as a primary evaluation target. DORI assesses four dimensions oforientation comprehension: frontal alignment, rotational transformations,relative directional relationships, and canonical orientation understanding.Through carefully curated tasks from 11 datasets spanning 67 object categoriesacross synthetic and real-world scenarios, DORI provides insights on howmulti-modal systems understand object orientations. Our evaluation of 15state-of-the-art vision-language models reveals critical limitations: even thebest models achieve only 54.2% accuracy on coarse tasks and 33.0% on granularorientation judgments, with performance deteriorating for tasks requiringreference frame shifts or compound rotations. These findings demonstrate theneed for dedicated orientation representation mechanisms, as models showsystematic inability to perform precise angular estimations, track orientationchanges across viewpoints, and understand compound rotations - suggestinglimitations in their internal 3D spatial representations. As the firstdiagnostic framework specifically designed for orientation awareness inmultimodal systems, DORI offers implications for improving robotic control, 3Dscene reconstruction, and human-AI interaction in physical environments. DORIdata: https://huggingface.co/datasets/appledora/DORI-Benchmark</description>
      <author>example@mail.com (Keanu Nichols, Nazia Tasnim, Yuting Yan, Nicholas Ikechukwu, Elva Zou, Deepti Ghadiyaram, Bryan A. Plummer)</author>
      <guid isPermaLink="false">2505.21649v2</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>VidText: Towards Comprehensive Evaluation for Video Text Understanding</title>
      <link>http://arxiv.org/abs/2505.22810v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VidText是一个新的视频文本理解基准，旨在全面评估视频文本理解，包括涵盖真实世界场景、多语言内容，以及引入层次化评估框架和配对感知推理任务。&lt;h4&gt;背景&lt;/h4&gt;现有的视频理解基准忽视文本信息，而OCR基准限于静态图像，限制了它们捕捉文本与动态视觉环境之间互动的能力。&lt;h4&gt;目的&lt;/h4&gt;提出VidText基准，以填补视频理解基准中的这一空白，并作为未来关于动态环境中视频文本多模态推理研究的基础。&lt;h4&gt;方法&lt;/h4&gt;VidText基准包括广泛的实际场景，支持多语言内容，并引入了视频级、剪辑级和实例级任务，以及一系列配对感知推理任务。&lt;h4&gt;主要发现&lt;/h4&gt;在18个最先进的LMM上进行的大量实验表明，当前模型在大多数任务上表现不佳，存在显著的改进空间。进一步分析突出了模型内在因素（如输入分辨率和OCR能力）和外部因素（如辅助信息的使用和思维链推理策略）的影响。&lt;h4&gt;结论&lt;/h4&gt;VidText基准有望填补视频理解基准中的空白，并为动态环境中视频文本的多模态推理研究提供基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual texts embedded in videos carry rich semantic information, which iscrucial for both holistic video understanding and fine-grained reasoning aboutlocal human actions. However, existing video understanding benchmarks largelyoverlook textual information, while OCR-specific benchmarks are constrained tostatic images, limiting their ability to capture the interaction between textand dynamic visual contexts. To address this gap, we propose VidText, a newbenchmark designed for comprehensive and in-depth evaluation of video textunderstanding. VidText offers the following key features: 1) It covers a widerange of real-world scenarios and supports multilingual content, encompassingdiverse settings where video text naturally appears. 2) It introduces ahierarchical evaluation framework with video-level, clip-level, andinstance-level tasks, enabling assessment of both global summarization andlocal retrieval capabilities. 3) The benchmark also introduces a set of pairedperception reasoning tasks, ranging from visual text perception to cross-modalreasoning between textual and visual information. Extensive experiments on 18state-of-the-art Large Multimodal Models (LMMs) reveal that current modelsstruggle across most tasks, with significant room for improvement. Furtheranalysis highlights the impact of both model-intrinsic factors, such as inputresolution and OCR capability, and external factors, including the use ofauxiliary information and Chain-of-Thought reasoning strategies. We hopeVidText will fill the current gap in video understanding benchmarks and serveas a foundation for future research on multimodal reasoning with video text indynamic environments.</description>
      <author>example@mail.com (Zhoufaran Yang, Yan Shu, Zhifei Yang, Yan Zhang, Yu Li, Keyang Lu, Gangyan Zeng, Shaohui Liu, Yu Zhou, Nicu Sebe)</author>
      <guid isPermaLink="false">2505.22810v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Patient Domain Supervised Contrastive Learning for Lung Sound Classification Using Mobile Phone</title>
      <link>http://arxiv.org/abs/2505.23132v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ITS-CSCC 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究利用智能手机麦克风记录和分析肺音，旨在克服传统肺音评估的局限性，并展示智能手机在诊断肺病方面的潜力。&lt;h4&gt;背景&lt;/h4&gt;传统的面对面肺音评估在COVID-19大流行期间暴露出其局限性。&lt;h4&gt;目的&lt;/h4&gt;使用智能手机麦克风记录和分析肺音，以提高肺病检测的准确性。&lt;h4&gt;方法&lt;/h4&gt;面对电子听诊器和智能手机麦克风之间音频风格的差异以及患者之间的可变性，研究开发了名为Patient Domain Supervised Contrastive Learning (PD-SCL)的方法，并将其与Audio Spectrogram Transformer (AST)模型相结合。&lt;h4&gt;主要发现&lt;/h4&gt;通过与AST模型结合，PD-SCL方法将性能提高了2.4%，显示出智能手机在诊断肺音方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;这项研究证明了智能手机在诊断肺音方面的潜力，并有可能在传统临床环境之外得到广泛应用，有助于在COVID-19后世界中使肺病检测更加便捷。&lt;h4&gt;翻译&lt;/h4&gt;摘要：听诊对于诊断肺部疾病至关重要。COVID-19大流行揭示了传统面对面肺音评估的局限性。为了克服这些问题，数字听诊器和人工智能（AI）的进步导致了新的诊断方法的发展。在此背景下，我们的研究旨在使用智能手机麦克风来记录和分析肺音。我们面临两个主要挑战：电子听诊器和智能手机麦克风之间的音频风格差异，以及患者之间的可变性。为了解决这些挑战，我们开发了一种称为Patient Domain Supervised Contrastive Learning (PD-SCL)的方法。通过将这种方法与Audio Spectrogram Transformer (AST)模型相结合，我们将其性能与原始AST模型相比提高了2.4%。这一进展表明，智能手机可以有效地诊断肺音，解决患者数据的不一致性，并显示出在传统临床环境之外广泛使用的潜力。我们的研究有助于使肺病检测在COVID-19后世界中更加便捷。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Auscultation is crucial for diagnosing lung diseases. The COVID-19 pandemichas revealed the limitations of traditional, in-person lung sound assessments.To overcome these issues, advancements in digital stethoscopes and artificialintelligence (AI) have led to the development of new diagnostic methods. Inthis context, our study aims to use smartphone microphones to record andanalyze lung sounds. We faced two major challenges: the difference in audiostyle between electronic stethoscopes and smartphone microphones, and thevariability among patients. To address these challenges, we developed a methodcalled Patient Domain Supervised Contrastive Learning (PD-SCL). By integratingthis method with the Audio Spectrogram Transformer (AST) model, wesignificantly improved its performance by 2.4\% compared to the original ASTmodel. This progress demonstrates that smartphones can effectively diagnoselung sounds, addressing inconsistencies in patient data and showing potentialfor broad use beyond traditional clinical settings. Our research contributes tomaking lung disease detection more accessible in the post-COVID-19 world.</description>
      <author>example@mail.com (Seung Gyu Jeong, Seong Eun Kim)</author>
      <guid isPermaLink="false">2505.23132v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>RiverMamba: A State Space Model for Global River Discharge and Flood Forecasting</title>
      <link>http://arxiv.org/abs/2505.22535v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Main paper 10 pages, Appendix 53 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的深度学习模型RiverMamba，用于河流径流和洪水预报，以提高预警系统的可靠性。&lt;h4&gt;背景&lt;/h4&gt;现有的深度学习方法主要应用于局部尺度的水文预报，且未能充分利用水体固有的空间联系。&lt;h4&gt;目的&lt;/h4&gt;提出新的深度学习方法，以建模时空关系，改善河流径流和洪水预报。&lt;h4&gt;方法&lt;/h4&gt;RiverMamba使用长期再分析数据进行预训练，能够预测全球范围内的河流径流和洪水，预报范围达到0.05度网格，预测提前时间最长可达7天。模型采用高效的Mamba模块，能够捕捉全球尺度的渠道网络路由，并通过时空建模考虑欧洲中期天气预报中心的天气预报不准确性。&lt;h4&gt;主要发现&lt;/h4&gt;RiverMamba在预测河流径流，包括极端洪水以及不同回期和提前时间的情况下，都表现出了可靠的预测能力，超越了现有的基于人工智能和物理模型的运行模型。&lt;h4&gt;结论&lt;/h4&gt;RiverMamba为科学和运营应用提供了可靠的河流径流预测，为洪水预警系统提供了有力的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent deep learning approaches for river discharge forecasting have improvedthe accuracy and efficiency in flood forecasting, enabling more reliable earlywarning systems for risk management. Nevertheless, existing deep learningapproaches in hydrology remain largely confined to local-scale applications anddo not leverage the inherent spatial connections of bodies of water. Thus,there is a strong need for new deep learning methodologies that are capable ofmodeling spatio-temporal relations to improve river discharge and floodforecasting for scientific and operational applications. To address this, wepresent RiverMamba, a novel deep learning model that is pretrained withlong-term reanalysis data and that can forecast global river discharge andfloods on a $0.05^\circ$ grid up to 7 days lead time, which is of highrelevance in early warning. To achieve this, RiverMamba leverages efficientMamba blocks that enable the model to capture global-scale channel networkrouting and enhance its forecast capability for longer lead times. The forecastblocks integrate ECMWF HRES meteorological forecasts, while accounting fortheir inaccuracies through spatio-temporal modeling. Our analysis demonstratesthat RiverMamba delivers reliable predictions of river discharge, includingextreme floods across return periods and lead times, surpassing bothoperational AI- and physics-based models.</description>
      <author>example@mail.com (Mohamad Hakam Shams Eddin, Yikui Zhang, Stefan Kollet, Juergen Gall)</author>
      <guid isPermaLink="false">2505.22535v2</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Less is More: Unlocking Specialization of Time Series Foundation Models via Structured Pruning</title>
      <link>http://arxiv.org/abs/2505.23195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Manuscript with fixed typos and figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了时间序列基础模型（TSFMs）在零样本预测任务中的表现，并提出了一种结构化剪枝方法来优化模型的微调过程。&lt;h4&gt;背景&lt;/h4&gt;TSFMs在预训练时具有大量参数，能够实现出色的零样本预测性能，但在微调后，它们往往无法超越专门训练的较小模型。&lt;h4&gt;目的&lt;/h4&gt;研究如何有效地对TSFMs进行适应，以实现针对目标预测任务的有效调整。&lt;h4&gt;方法&lt;/h4&gt;通过实证研究，发现预训练模型在计算上存在固有稀疏性和冗余，提出了结构化剪枝方法，通过聚焦于更相关和紧凑的参数空间来正则化微调过程。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，对较小的剪枝TSFM进行微调可以显著提高预测性能，相比微调原始模型效果更好。&lt;h4&gt;结论&lt;/h4&gt;‘剪枝然后微调’的范式通常使TSFMs能够达到最先进的性能，并超越强大的专门基线。&lt;h4&gt;翻译&lt;/h4&gt;摘要：缩放定律推动了时间序列基础模型（TSFMs）的开发，这些模型预训练了大量的参数，并实现了显著的零样本预测性能。令人惊讶的是，即使在微调之后，TSFMs也无法始终优于在完整数据上训练的较小、专门的模型。一个关键问题是如何实现TSFMs对目标预测任务的有效适应。通过对各种TSFMs的实证研究，预训练模型往往表现出计算上的固有稀疏性和冗余，这表明TSFMs已经学会了激活与任务相关的网络子结构来适应不同的预测任务。为了保留这种宝贵的先验知识，我们提出了一种结构化剪枝方法，通过将其聚焦于更相关和紧凑的参数空间来正则化后续的微调过程。在七个TSFMs和六个基准上的大量实验表明，对较小的剪枝TSFM进行微调与对原始模型进行微调相比，可以显著提高预测性能。这种‘剪枝然后微调’的范式通常使TSFMs能够达到最先进的性能，并超越强大的专门基线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scaling laws motivate the development of Time Series Foundation Models(TSFMs) that pre-train vast parameters and achieve remarkable zero-shotforecasting performance. Surprisingly, even after fine-tuning, TSFMs cannotconsistently outperform smaller, specialized models trained on full-shotdownstream data. A key question is how to realize effective adaptation of TSFMsfor a target forecasting task. Through empirical studies on various TSFMs, thepre-trained models often exhibit inherent sparsity and redundancy incomputation, suggesting that TSFMs have learned to activate task-relevantnetwork substructures to accommodate diverse forecasting tasks. To preservethis valuable prior knowledge, we propose a structured pruning method toregularize the subsequent fine-tuning process by focusing it on a more relevantand compact parameter space. Extensive experiments on seven TSFMs and sixbenchmarks demonstrate that fine-tuning a smaller, pruned TSFM significantlyimproves forecasting performance compared to fine-tuning original models. This"prune-then-finetune" paradigm often enables TSFMs to achieve state-of-the-artperformance and surpass strong specialized baselines.</description>
      <author>example@mail.com (Lifan Zhao, Yanyan Shen, Zhaoyang Liu, Xue Wang, Jiaji Deng)</author>
      <guid isPermaLink="false">2505.23195v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Query Routing for Retrieval-Augmented Language Models</title>
      <link>http://arxiv.org/abs/2505.23052v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Retrieval-Augmented Generation (RAG)显著提高了大型语言模型（LLMs）在知识密集型任务上的性能，但RAG下LLMs的响应质量差异需要智能路由机制，通过专用路由模型从多个检索增强的LLMs中选择最合适的模型。本文提出了RAGRouter，这是一种感知RAG的路由设计，利用文档嵌入和RAG能力嵌入通过对比学习捕捉知识表示的变化，并实现明智的路由决策。&lt;h4&gt;背景&lt;/h4&gt;Retrieval-Augmented Generation (RAG)在知识密集型任务上对大型语言模型（LLMs）性能的显著提升，以及RAG下LLMs响应质量差异的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的检索增强LLM路由问题，并解决现有路由方法在RAG场景中表现不佳的问题。&lt;h4&gt;方法&lt;/h4&gt;提出RAGRouter，这是一种利用文档嵌入和RAG能力嵌入通过对比学习捕捉知识表示变化和实现明智路由决策的路由设计。&lt;h4&gt;主要发现&lt;/h4&gt;RAGRouter在平均上优于最佳单个LLM 3.61%，并优于现有路由方法3.29%-9.33%。在低延迟约束下，它还实现了强大的性能-效率权衡。&lt;h4&gt;结论&lt;/h4&gt;RAGRouter是一种有效的RAG感知路由设计，能够显著提高知识密集型任务上的LLM性能，并在低延迟条件下实现性能和效率的平衡。&lt;h4&gt;翻译&lt;/h4&gt;Retrieval-Augmented Generation (RAG)显著提升了大型语言模型（LLMs）在知识密集型任务上的表现。然而，在RAG环境下，不同LLMs的响应质量存在差异，这要求有智能的路由机制来选择最适合每个查询的模型，通过一个专门的路由模型从多个检索增强的LLMs中进行选择。我们观察到外部文档会动态影响LLMs回答查询的能力，而依赖静态参数化知识表示的现有路由方法在RAG场景中表现不佳。为了解决这个问题，我们正式定义了一个新的检索增强LLM路由问题，将检索到的文档的影响纳入路由框架中。我们提出了RAGRouter，这是一种感知RAG的路由设计，通过利用文档嵌入和RAG能力嵌入进行对比学习来捕捉知识表示的变化，从而实现有信息量的路由决策。在多种知识密集型任务和检索设置上的广泛实验表明，RAGRouter的平均性能优于最佳单个LLM 3.61%，并优于现有路由方法3.29%-9.33%。此外，通过扩展基于分数阈值的机制，它在低延迟约束下也实现了强大的性能-效率权衡。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retrieval-Augmented Generation (RAG) significantly improves the performanceof Large Language Models (LLMs) on knowledge-intensive tasks. However, varyingresponse quality across LLMs under RAG necessitates intelligent routingmechanisms, which select the most suitable model for each query from multipleretrieval-augmented LLMs via a dedicated router model. We observe that externaldocuments dynamically affect LLMs' ability to answer queries, while existingrouting methods, which rely on static parametric knowledge representations,exhibit suboptimal performance in RAG scenarios. To address this, we formallydefine the new retrieval-augmented LLM routing problem, incorporating theinfluence of retrieved documents into the routing framework. We proposeRAGRouter, a RAG-aware routing design, which leverages document embeddings andRAG capability embeddings with contrastive learning to capture knowledgerepresentation shifts and enable informed routing decisions. Extensiveexperiments on diverse knowledge-intensive tasks and retrieval settings showthat RAGRouter outperforms the best individual LLM by 3.61% on average andexisting routing methods by 3.29%-9.33%. With an extended score-threshold-basedmechanism, it also achieves strong performance-efficiency trade-offs underlow-latency constraints.</description>
      <author>example@mail.com (Jiarui Zhang, Xiangyu Liu, Yong Hu, Chaoyue Niu, Fan Wu, Guihai Chen)</author>
      <guid isPermaLink="false">2505.23052v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>When Does Neuroevolution Outcompete Reinforcement Learning in Transfer Learning Tasks?</title>
      <link>http://arxiv.org/abs/2505.22696v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了神经进化（NE）的迁移学习能力，通过两个基准实验证明了NE方法在迁移能力上的多样性，并经常优于强化学习（RL）基线。&lt;h4&gt;背景&lt;/h4&gt;迁移技能的持续高效转移是生物智能的标志，也是人工智能系统长期追求的目标。强化学习在高维控制任务中是主导学习范式，但已知其容易受到任务变化的影响和灾难性遗忘。&lt;h4&gt;目的&lt;/h4&gt;研究神经进化（NE）的迁移学习能力。&lt;h4&gt;方法&lt;/h4&gt;引入了两个基准：一是步进门基准，其中神经网络被要求模拟逻辑电路，设计强调模块化重复和变化；二是ecorobot基准，它扩展了Brax物理引擎，加入了墙壁和障碍物等对象，并能够轻松切换不同的机器人形态。两个基准都包含一个课程，使得可以评估跨越不同复杂度任务的技能迁移。&lt;h4&gt;主要发现&lt;/h4&gt;NE方法在迁移能力上存在差异，并经常优于RL基线。&lt;h4&gt;结论&lt;/h4&gt;NE方法作为构建更适应性强代理的基础具有潜力，并指出了将NE扩展到复杂、现实世界问题的未来挑战。&lt;h4&gt;翻译&lt;/h4&gt;The ability to continuously and efficiently transfer skills across tasks is a hallmark of biological intelligence and a long-standing goal in artificial systems. Reinforcement learning (RL), a dominant paradigm for learning in high-dimensional control tasks, is known to suffer from brittleness to task variations and catastrophic forgetting. Neuroevolution (NE) has recently gained attention for its robustness, scalability, and capacity to escape local optima. In this paper, we investigate an understudied dimension of NE: its transfer learning capabilities. To this end, we introduce two benchmarks: a) in stepping gates, neural networks are tasked with emulating logic circuits, with designs that emphasize modular repetition and variation b) ecorobot extends the Brax physics engine with objects such as walls and obstacles and the ability to easily switch between different robotic morphologies. Crucial in both benchmarks is the presence of a curriculum that enables evaluating skill transfer across tasks of increasing complexity. Our empirical analysis shows that NE methods vary in their transfer abilities and frequently outperform RL baselines. Our findings support the potential of NE as a foundation for building more adaptable agents and highlight future challenges for scaling NE to complex, real-world problems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to continuously and efficiently transfer skills across tasks is ahallmark of biological intelligence and a long-standing goal in artificialsystems. Reinforcement learning (RL), a dominant paradigm for learning inhigh-dimensional control tasks, is known to suffer from brittleness to taskvariations and catastrophic forgetting. Neuroevolution (NE) has recently gainedattention for its robustness, scalability, and capacity to escape local optima.In this paper, we investigate an understudied dimension of NE: its transferlearning capabilities. To this end, we introduce two benchmarks: a) in steppinggates, neural networks are tasked with emulating logic circuits, with designsthat emphasize modular repetition and variation b) ecorobot extends the Braxphysics engine with objects such as walls and obstacles and the ability toeasily switch between different robotic morphologies. Crucial in bothbenchmarks is the presence of a curriculum that enables evaluating skilltransfer across tasks of increasing complexity. Our empirical analysis showsthat NE methods vary in their transfer abilities and frequently outperform RLbaselines. Our findings support the potential of NE as a foundation forbuilding more adaptable agents and highlight future challenges for scaling NEto complex, real-world problems.</description>
      <author>example@mail.com (Eleni Nisioti, Joachim Winther Pedersen, Erwan Plantec, Milton L. Montero, Sebastian Risi)</author>
      <guid isPermaLink="false">2505.22696v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Spatio-Temporal Joint Density Driven Learning for Skeleton-Based Action Recognition</title>
      <link>http://arxiv.org/abs/2505.23012v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的测量方法——时空联合密度（STJD），用于量化骨骼序列中动态和静态元素之间的复杂交互，并提出了一种新的对比学习方法STJD-CL以及结合重建框架的STJD-MP方法，以改进骨骼动作分类的性能。&lt;h4&gt;背景&lt;/h4&gt;传统的无监督或自监督学习在骨骼动作分类中主要关注骨骼序列的动态方面，但骨骼中动态和静态元素的复杂交互为动作分类提供了很少被利用的判别潜力。&lt;h4&gt;目的&lt;/h4&gt;提出时空联合密度（STJD）来量化骨骼动作中动态和静态元素之间的交互，并设计新的对比学习方法以改进动作分类的性能。&lt;h4&gt;方法&lt;/h4&gt;1. 提出时空联合密度（STJD）来量化骨骼动作中动态和静态元素之间的交互；2. 提出STJD-CL对比学习策略，以同步调整骨骼序列和其关键关节的表示，并对比关键关节和非关键关节的表示；3. 提出STJD-MP方法，通过结合重建框架进行更有效的学习。&lt;h4&gt;主要发现&lt;/h4&gt;在NTU RGB+D 60、NTU RGB+D 120和PKUMMD数据集上的实验表明，STJD-CL和STJD-MP方法在动作分类任务中提高了性能，尤其是在NTU RGB+D 120数据集上，使用X-sub和X-set评估分别比最先进的对比学习方法提高了3.5和3.6个百分点。&lt;h4&gt;结论&lt;/h4&gt;STJD-CL和STJD-MP方法通过量化骨骼动作中动态和静态元素的交互，显著提高了骨骼动作分类的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TBIOM.2025.3566212&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional approaches in unsupervised or self supervised learning forskeleton-based action classification have concentrated predominantly on thedynamic aspects of skeletal sequences. Yet, the intricate interaction betweenthe moving and static elements of the skeleton presents a rarely tappeddiscriminative potential for action classification. This paper introduces anovel measurement, referred to as spatial-temporal joint density (STJD), toquantify such interaction. Tracking the evolution of this density throughout anaction can effectively identify a subset of discriminative moving and/or staticjoints termed "prime joints" to steer self-supervised learning. A newcontrastive learning strategy named STJD-CL is proposed to align therepresentation of a skeleton sequence with that of its prime joints whilesimultaneously contrasting the representations of prime and nonprime joints. Inaddition, a method called STJD-MP is developed by integrating it with areconstruction-based framework for more effective learning. Experimentalevaluations on the NTU RGB+D 60, NTU RGB+D 120, and PKUMMD datasets in variousdownstream tasks demonstrate that the proposed STJD-CL and STJD-MP improvedperformance, particularly by 3.5 and 3.6 percentage points over thestate-of-the-art contrastive methods on the NTU RGB+D 120 dataset using X-suband X-set evaluations, respectively.</description>
      <author>example@mail.com (Shanaka Ramesh Gunasekara, Wanqing Li, Philip Ogunbona, Jack Yang)</author>
      <guid isPermaLink="false">2505.23012v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>BLUE: Bi-layer Heterogeneous Graph Fusion Network for Avian Influenza Forecasting</title>
      <link>http://arxiv.org/abs/2505.22692v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 3 figures, 9 tables. The paper is under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BLUE的模型，用于准确预测野生鸟类中的禽流感爆发。该模型通过整合遗传、空间和生态数据，能够捕捉多尺度传播模式，从而提高预测准确性。&lt;h4&gt;背景&lt;/h4&gt;目前禽流感爆发的预测需要考虑复杂的传播模式，但现有模型大多仅依赖空间连接，忽略了遗传信息的重要性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够整合遗传、空间和生态数据，准确预测禽流感爆发的模型。&lt;h4&gt;方法&lt;/h4&gt;BLUE模型通过以下步骤实现：1) 构建来自多个信息源和多个层级的异构图；2) 对关系类型进行平滑处理；3) 在融合过程中保留结构模式；4) 使用自回归图序列模型预测未来爆发，捕捉随时间变化的传播动态。&lt;h4&gt;主要发现&lt;/h4&gt;BLUE模型在预测准确性上优于现有基线，证明了将多层信息纳入传染病预测的价值。&lt;h4&gt;结论&lt;/h4&gt;通过整合遗传、空间和生态数据，BLUE模型能够更准确地预测禽流感爆发，为疾病防控提供了有力的工具。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Accurate forecasting of avian influenza outbreaks within wild bird populations requires models that account for complex, multi-scale transmission patterns driven by various factors. Spatio-temporal GNN-based models have recently gained traction for infection forecasting due to their ability to capture relations and flow between spatial regions, but most existing frameworks rely solely on spatial connections and their connections. This overlooks valuable genetic information at the case level, such as cases in one region being genetically descended from strains in another, which is essential for understanding how infectious diseases spread through epidemiological linkages beyond geography. We address this gap with BLUE, a B}i-Layer heterogeneous graph fUsion nEtwork designed to integrate genetic, spatial, and ecological data for accurate outbreak forecasting. The framework 1) builds heterogeneous graphs from multiple information sources and multiple layers, 2) smooths across relation types, 3) performs fusion while retaining structural patterns, and 4) predicts future outbreaks via an autoregressive graph sequence model that captures transmission dynamics over time. To facilitate further research, we introduce extbf{Avian-US} dataset, the dataset for avian influenza outbreak forecasting in the United States, incorporating genetic, spatial, and ecological data across locations. BLUE achieves superior performance over existing baselines, highlighting the value of incorporating multi-layer information into infectious disease forecasting.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate forecasting of avian influenza outbreaks within wild birdpopulations requires models that account for complex, multi-scale transmissionpatterns driven by various factors. Spatio-temporal GNN-based models haverecently gained traction for infection forecasting due to their ability tocapture relations and flow between spatial regions, but most existingframeworks rely solely on spatial connections and their connections. Thisoverlooks valuable genetic information at the case level, such as cases in oneregion being genetically descended from strains in another, which is essentialfor understanding how infectious diseases spread through epidemiologicallinkages beyond geography. We address this gap with BLUE, a B}i-Layerheterogeneous graph fUsion nEtwork designed to integrate genetic, spatial, andecological data for accurate outbreak forecasting. The framework 1) buildsheterogeneous graphs from multiple information sources and multiple layers, 2)smooths across relation types, 3) performs fusion while retaining structuralpatterns, and 4) predicts future outbreaks via an autoregressive graph sequencemodel that captures transmission dynamics over time. To facilitate furtherresearch, we introduce \textbf{Avian-US} dataset, the dataset for avianinfluenza outbreak forecasting in the United States, incorporating genetic,spatial, and ecological data across locations. BLUE achieves superiorperformance over existing baselines, highlighting the value of incorporatingmulti-layer information into infectious disease forecasting.</description>
      <author>example@mail.com (Jing Du, Haley Stone, Yang Yang, Ashna Desai, Hao Xue, Andreas Züfle, Chandini Raina MacIntyre, Flora D. Salim)</author>
      <guid isPermaLink="false">2505.22692v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning</title>
      <link>http://arxiv.org/abs/2505.21863v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为GETReason的框架，用于从图像中提取更深层次的事件背景信息，并通过GREAT指标评估基于推理的图像理解。&lt;h4&gt;背景&lt;/h4&gt;现有方法在提取具有新闻和教育价值的公共事件图像的相关性方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出GETReason框架以超越表面图像描述，推断更深层次的事件背景意义。&lt;h4&gt;方法&lt;/h4&gt;GETReason通过提取全局事件、时间和地理空间信息来增强对图像重要性的理解。此外，引入了GREAT指标来评估基于推理的图像理解。&lt;h4&gt;主要发现&lt;/h4&gt;使用推理加权指标评估的分层多智能体方法表明，可以推断出有意义的见解，有效地将图像与其更广泛的事件背景联系起来。&lt;h4&gt;结论&lt;/h4&gt;GETReason和GREAT指标为准确提取图像的背景信息提供了新的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：公共事件中的重要图像包含有价值的背景信息，这对于新闻和教育至关重要。然而，现有方法在准确提取这种相关性方面往往存在困难。为了解决这个问题，我们引入了GETReason（地理事件时间推理）框架，该框架超越了表面级的图像描述，以推断更深层次的事件背景意义。我们提出，提取全局事件、时间和地理空间信息可以增强对图像重要性的理解。此外，我们引入了GREAT（具有时间对齐的地理推理和事件准确性），这是一种新的用于评估基于推理的图像理解的指标。我们的分层多智能体方法，使用推理加权指标进行评估，表明可以推断出有意义的见解，有效地将图像与其更广泛的事件背景联系起来。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Publicly significant images from events hold valuable contextual information,crucial for journalism and education. However, existing methods often struggleto extract this relevance accurately. To address this, we introduce GETReason(Geospatial Event Temporal Reasoning), a framework that moves beyondsurface-level image descriptions to infer deeper contextual meaning. We proposethat extracting global event, temporal, and geospatial information enhancesunderstanding of an image's significance. Additionally, we introduce GREAT(Geospatial Reasoning and Event Accuracy with Temporal Alignment), a new metricfor evaluating reasoning-based image understanding. Our layered multi-agentapproach, assessed using a reasoning-weighted metric, demonstrates thatmeaningful insights can be inferred, effectively linking images to theirbroader event context.</description>
      <author>example@mail.com (Shikhhar Siingh, Abhinav Rawat, Chitta Baral, Vivek Gupta)</author>
      <guid isPermaLink="false">2505.21863v2</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>EAD: An EEG Adapter for Automated Classification</title>
      <link>http://arxiv.org/abs/2505.23107v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EEG Adapter (EAD)的灵活框架，用于学习EEG嵌入，以应对不同设备采集的EEG数据分类问题。&lt;h4&gt;背景&lt;/h4&gt;EEG在神经解码中应用广泛，但传统EEG分类需要针对特定任务进行数据采集和预处理，且深度学习技术对EEG通道数敏感，难以适应不同设备。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够处理不同设备采集的EEG数据并学习嵌入表示的框架。&lt;h4&gt;方法&lt;/h4&gt;提出了EEG Adapter (EAD)，它兼容任何信号采集设备，并利用了经过改进的EEG基础模型来学习稳健的表示。&lt;h4&gt;主要发现&lt;/h4&gt;EAD在两个公开数据集上达到了最先进的准确率（99.33%和92.31%），展示了该框架在不同感知任务（刺激和静息状态EEG信号）的多样性EEG数据集中的有效性。&lt;h4&gt;结论&lt;/h4&gt;EEG Adapter (EAD)框架在处理不同设备和不同任务下的EEG数据分类时显示出良好的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;While electroencephalography (EEG) has been a popular modality for neuraldecoding, it often involves task specific acquisition of the EEG data. Thisposes challenges for the development of a unified pipeline to learn embeddingsfor various EEG signal classification, which is often involved in variousdecoding tasks. Traditionally, EEG classification involves the step of signalpreprocessing and the use of deep learning techniques, which are highlydependent on the number of EEG channels in each sample. However, the samepipeline cannot be applied even if the EEG data is collected for the sameexperiment but with different acquisition devices. This necessitates thedevelopment of a framework for learning EEG embeddings, which could be highlybeneficial for tasks involving multiple EEG samples for the same task but withvarying numbers of EEG channels. In this work, we propose EEG Adapter (EAD), aflexible framework compatible with any signal acquisition device. Morespecifically, we leverage a recent EEG foundational model with significantadaptations to learn robust representations from the EEG data for theclassification task. We evaluate EAD on two publicly available datasetsachieving state-of-the-art accuracies 99.33% and 92.31% on EEG-ImageNet andBrainLat respectively. This illustrates the effectiveness of the proposedframework across diverse EEG datasets containing two different perceptiontasks: stimulus and resting-state EEG signals. We also perform zero-shot EEGclassification on EEG-ImageNet task to demonstrate the generalizationcapability of the proposed approach.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While electroencephalography (EEG) has been a popular modality for neuraldecoding, it often involves task specific acquisition of the EEG data. Thisposes challenges for the development of a unified pipeline to learn embeddingsfor various EEG signal classification, which is often involved in variousdecoding tasks. Traditionally, EEG classification involves the step of signalpreprocessing and the use of deep learning techniques, which are highlydependent on the number of EEG channels in each sample. However, the samepipeline cannot be applied even if the EEG data is collected for the sameexperiment but with different acquisition devices. This necessitates thedevelopment of a framework for learning EEG embeddings, which could be highlybeneficial for tasks involving multiple EEG samples for the same task but withvarying numbers of EEG channels. In this work, we propose EEG Adapter (EAD), aflexible framework compatible with any signal acquisition device. Morespecifically, we leverage a recent EEG foundational model with significantadaptations to learn robust representations from the EEG data for theclassification task. We evaluate EAD on two publicly available datasetsachieving state-of-the-art accuracies 99.33% and 92.31% on EEG-ImageNet andBrainLat respectively. This illustrates the effectiveness of the proposedframework across diverse EEG datasets containing two different perceptiontasks: stimulus and resting-state EEG signals. We also perform zero-shot EEGclassification on EEG-ImageNet task to demonstrate the generalizationcapability of the proposed approach.</description>
      <author>example@mail.com (Pushapdeep Singh, Jyoti Nigam, Medicherla Vamsi Krishna, Arnav Bhavsar, Aditya Nigam)</author>
      <guid isPermaLink="false">2505.23107v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Weight Spectra Induced Efficient Model Adaptation</title>
      <link>http://arxiv.org/abs/2505.23099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了大规模基础模型在下游任务中的表现，提出了参数高效微调方法PEFT，并通过SVD揭示了权重矩阵在微调过程中的结构变化，提出了一种新的方法，通过可学习的缩放来精确调节最关键的部分。&lt;h4&gt;背景&lt;/h4&gt;大规模基础模型在下游任务中表现出色，但全量微调成本高昂，因此开发了PEFT方法。&lt;h4&gt;目的&lt;/h4&gt;探究PEFT修改模型参数的机制，并改进微调方法。&lt;h4&gt;方法&lt;/h4&gt;使用奇异值分解（SVD）分析权重矩阵在微调过程中的结构变化，并提出了一种基于可学习缩放的新方法。&lt;h4&gt;主要发现&lt;/h4&gt;微调主要放大了前几个奇异值，而其余部分保持不变，表明特定任务的知识被注入到低维子空间中。主导奇异向量在特定任务方向上重新定向，而非主导子空间保持稳定。&lt;h4&gt;结论&lt;/h4&gt;提出的方法在多个任务上实现了对强基线的持续改进，证明了结构化微调的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Large-scale foundation models have demonstrated remarkable versatility across a wide range of downstream tasks. However, fully fine-tuning these models incurs prohibitive computational costs, motivating the development of Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA, which introduces low-rank updates to pre-trained weights. Despite their empirical success, the underlying mechanisms by which PEFT modifies model parameters remain underexplored. In this work, we present a systematic investigation into the structural changes of weight matrices during fully fine-tuning. Through singular value decomposition (SVD), we reveal that fine-tuning predominantly amplifies the top singular values while leaving the remainder largely intact, suggesting that task-specific knowledge is injected into a low-dimensional subspace. Furthermore, we find that the dominant singular vectors are reoriented in task-specific directions, whereas the non-dominant subspace remains stable. Building on these insights, we propose a novel method that leverages learnable rescaling of top singular directions, enabling precise modulation of the most influential components without disrupting the global structure. Our approach achieves consistent improvements over strong baselines across multiple tasks, highlighting the efficacy of structurally informed fine-tuning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale foundation models have demonstrated remarkable versatility acrossa wide range of downstream tasks. However, fully fine-tuning these modelsincurs prohibitive computational costs, motivating the development ofParameter-Efficient Fine-Tuning (PEFT) methods such as LoRA, which introduceslow-rank updates to pre-trained weights. Despite their empirical success, theunderlying mechanisms by which PEFT modifies model parameters remainunderexplored. In this work, we present a systematic investigation into thestructural changes of weight matrices during fully fine-tuning. Throughsingular value decomposition (SVD), we reveal that fine-tuning predominantlyamplifies the top singular values while leaving the remainder largely intact,suggesting that task-specific knowledge is injected into a low-dimensionalsubspace. Furthermore, we find that the dominant singular vectors arereoriented in task-specific directions, whereas the non-dominant subspaceremains stable. Building on these insights, we propose a novel method thatleverages learnable rescaling of top singular directions, enabling precisemodulation of the most influential components without disrupting the globalstructure. Our approach achieves consistent improvements over strong baselinesacross multiple tasks, highlighting the efficacy of structurally informedfine-tuning.</description>
      <author>example@mail.com (Chongjie Si, Xuankun Yang, Muqing Liu, Yadao Wang, Xiaokang Yang, Wenbo Su, Bo Zheng, Wei Shen)</author>
      <guid isPermaLink="false">2505.23099v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Be.FM: Open Foundation Models for Human Behavior</title>
      <link>http://arxiv.org/abs/2505.23058v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Be.FM，一个用于人类行为建模的开源基础模型，探讨了其在理解和预测人类决策方面的潜力。&lt;h4&gt;背景&lt;/h4&gt;尽管基础模型在多个领域取得了成功，但它们在建模和理解人类行为方面的潜力仍被大量未探索。&lt;h4&gt;目的&lt;/h4&gt;开发Be.FM，一个专门为人类行为建模设计的开源基础模型，并测试其能力。&lt;h4&gt;方法&lt;/h4&gt;Be.FM基于开源大型语言模型构建，并在多样化的行为数据上进行微调。同时，构建了一套全面的基准任务来测试行为基础模型的能力。&lt;h4&gt;主要发现&lt;/h4&gt;Be.FM能够预测行为，推断个人和群体的特征，生成关于情境的见解，并应用行为科学知识。&lt;h4&gt;结论&lt;/h4&gt;Be.FM展示了在理解和预测人类行为方面的潜力，为行为基础模型的发展提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;尽管在众多领域取得了成功，但基础模型在建模和理解人类行为方面的潜力仍然被大量未探索。我们介绍了Be.FM，这是第一个用于人类行为建模的开源基础模型之一。Be.FM建立在开源大型语言模型之上，并在多样化的行为数据上进行微调。我们可以使用Be.FM来理解和预测人类决策。我们构建了一套全面的基准任务来测试行为基础模型的能力。我们的结果表明，Be.FM可以预测行为，推断个人和群体的特征，生成关于情境的见解，并应用行为科学知识。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite their success in numerous fields, the potential of foundation modelsfor modeling and understanding human behavior remains largely unexplored. Weintroduce Be.FM, one of the first open foundation models designed for humanbehavior modeling. Built upon open-source large language models and fine-tunedon a diverse range of behavioral data, Be.FM can be used to understand andpredict human decision-making. We construct a comprehensive set of benchmarktasks for testing the capabilities of behavioral foundation models. Our resultsdemonstrate that Be.FM can predict behaviors, infer characteristics ofindividuals and populations, generate insights about contexts, and applybehavioral science knowledge.</description>
      <author>example@mail.com (Yutong Xie, Zhuoheng Li, Xiyuan Wang, Yijun Pan, Qijia Liu, Xingzhi Cui, Kuang-Yu Lo, Ruoyi Gao, Xingjian Zhang, Jin Huang, Walter Yuan, Matthew O. Jackson, Qiaozhu Mei)</author>
      <guid isPermaLink="false">2505.23058v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>From Theory to Application: Fine-Tuning Large EEG Model with Real-World Stress Data</title>
      <link>http://arxiv.org/abs/2505.23042v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了大型语言模型在各个领域的进展，评估了大型脑电图模型（LEMs）的有效性，并展示了其在现实世界脑-机接口应用中的潜力。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型在多个领域取得了显著进展，这激发了跨领域基础模型的发展。&lt;h4&gt;目的&lt;/h4&gt;评估大型脑电图模型（LEMs）的有效性，并评估其在现实世界环境中的应用。&lt;h4&gt;方法&lt;/h4&gt;通过微调LaBraM，一种最先进的脑电图基础模型，在真实世界的压力分类数据集上进行训练，该数据集是在研究生课堂中收集的。使用18名研究生在课堂会议期间记录的静息态脑电图数据来训练二元分类器。&lt;h4&gt;主要发现&lt;/h4&gt;微调后的最佳模型在5秒窗口内实现了90.47%的平衡准确率，显著优于传统的压力分类器，同时在准确性和推理效率方面都有所提升。此外，该模型在随机数据打乱和减少通道数的情况下仍表现出鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明LEMs能够有效地处理现实世界的脑电图数据，并突出了它们通过从以模型为中心转向以数据为中心的设计，有可能革新脑-机接口应用的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Large Language Models have inspired the development offoundation models across various domains. In this study, we evaluate theefficacy of Large EEG Models (LEMs) by fine-tuning LaBraM, a state-of-the-artfoundation EEG model, on a real-world stress classification dataset collectedin a graduate classroom. Unlike previous studies that primarily evaluate LEMsusing data from controlled clinical settings, our work assesses theirapplicability to real-world environments. We train a binary classifier thatdistinguishes between normal and elevated stress states using resting-state EEGdata recorded from 18 graduate students during a class session. Thebest-performing fine-tuned model achieves a balanced accuracy of 90.47% with a5-second window, significantly outperforming traditional stress classifiers inboth accuracy and inference efficiency. We further evaluate the robustness ofthe fine-tuned LEM under random data shuffling and reduced channel counts.These results demonstrate the capability of LEMs to effectively processreal-world EEG data and highlight their potential to revolutionizebrain-computer interface applications by shifting the focus from model-centricto data-centric design.</description>
      <author>example@mail.com (Siwen Wang, Shitou Zhang, Wan-Lin Chen, Dung Truong, Tzyy-Ping Jung)</author>
      <guid isPermaLink="false">2505.23042v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Scaling Laws for EHR Foundation Models</title>
      <link>http://arxiv.org/abs/2505.22964v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了电子健康记录（EHRs）中的扩展定律，发现EHR模型表现出与大型语言模型（LLMs）相似的扩展行为，为高效训练策略提供了预测性见解。&lt;h4&gt;背景&lt;/h4&gt;扩展定律在大型语言模型的发展中发挥了重要作用，但在电子健康记录（EHRs）领域尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;对EHR基础模型的扩展定律进行实证研究。&lt;h4&gt;方法&lt;/h4&gt;在MIMIC-IV数据库中，使用不同模型大小和计算预算训练Transformer架构，以识别EHR模型的扩展模式。&lt;h4&gt;主要发现&lt;/h4&gt;发现了包括抛物线IsoFLOPs曲线和计算、模型参数、数据大小与临床效用之间的幂律关系的扩展模式。&lt;h4&gt;结论&lt;/h4&gt;这些发现为开发能够改变临床预测任务和推进个性化医疗的强大EHR基础模型奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;The emergence of scaling laws has profoundly shaped the development of large language models (LLMs), enabling predictable performance gains through systematic increases in model size, dataset volume, and compute. Yet, these principles remain largely unexplored in the context of electronic health records (EHRs) -- a rich, sequential, and globally abundant data source that differs structurally from natural language. In this work, we present the first empirical investigation of scaling laws for EHR foundation models. By training transformer architectures on patient timeline data from the MIMIC-IV database across varying model sizes and compute budgets, we identify consistent scaling patterns, including parabolic IsoFLOPs curves and power-law relationships between compute, model parameters, data size, and clinical utility. These findings demonstrate that EHR models exhibit scaling behavior analogous to LLMs, offering predictive insights into resource-efficient training strategies. Our results lay the groundwork for developing powerful EHR foundation models capable of transforming clinical prediction tasks and advancing personalized healthcare.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of scaling laws has profoundly shaped the development of largelanguage models (LLMs), enabling predictable performance gains throughsystematic increases in model size, dataset volume, and compute. Yet, theseprinciples remain largely unexplored in the context of electronic healthrecords (EHRs) -- a rich, sequential, and globally abundant data source thatdiffers structurally from natural language. In this work, we present the firstempirical investigation of scaling laws for EHR foundation models. By trainingtransformer architectures on patient timeline data from the MIMIC-IV databaseacross varying model sizes and compute budgets, we identify consistent scalingpatterns, including parabolic IsoFLOPs curves and power-law relationshipsbetween compute, model parameters, data size, and clinical utility. Thesefindings demonstrate that EHR models exhibit scaling behavior analogous toLLMs, offering predictive insights into resource-efficient training strategies.Our results lay the groundwork for developing powerful EHR foundation modelscapable of transforming clinical prediction tasks and advancing personalizedhealthcare.</description>
      <author>example@mail.com (Sheng Zhang, Qin Liu, Naoto Usuyama, Cliff Wong, Tristan Naumann, Hoifung Poon)</author>
      <guid isPermaLink="false">2505.22964v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>LLM-based HSE Compliance Assessment: Benchmark, Performance, and Advancements</title>
      <link>http://arxiv.org/abs/2505.22959v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了HSE-Bench，一个用于评估大型语言模型（LLMs）在HSE合规性评估方面的能力的数据集，并提出了一个新的提示技术Reasoning of Expert（RoE），以指导LLMs进行合规性评估。&lt;h4&gt;背景&lt;/h4&gt;HSE合规性评估需要在复杂的法规和复杂的人机环境交互下进行动态实时决策。尽管大型语言模型在决策智能和上下文对话方面具有巨大潜力，但它们在HSE领域的专业知识以及结构化法律推理能力尚待探索。&lt;h4&gt;目的&lt;/h4&gt;评估LLMs在HSE合规性评估方面的能力，并提出改进LLMs在HSE合规性评估中推理能力的方法。&lt;h4&gt;方法&lt;/h4&gt;构建了HSE-Bench数据集，包含超过1000个手动编制的问题，并基于问题识别、规则回忆、规则应用和规则结论（IRAC）的推理流程进行评估。对超过10个LLMs，包括基础模型、推理模型和多模态视觉模型进行了广泛的评估。&lt;h4&gt;主要发现&lt;/h4&gt;尽管当前LLMs取得了良好的性能，但它们的推理能力主要依赖于语义匹配，而不是基于HSE合规性背景的原则性推理。此外，它们的推理过程缺乏系统化的法律推理，这是严格HSE合规性评估所必需的。&lt;h4&gt;结论&lt;/h4&gt;本文强调了LLMs在HSE合规性评估中的推理差距，并启发了对相关任务进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces HSE-Bench, a benchmark dataset designed to evaluate the compliance assessment capabilities of large language models (LLMs) in the field of health, safety, and environment (HSE), and proposes a new prompting technique, Reasoning of Expert (RoE), to guide LLMs in the process of compliance assessment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Health, Safety, and Environment (HSE) compliance assessment demands dynamicreal-time decision-making under complicated regulations and complexhuman-machine-environment interactions. While large language models (LLMs) holdsignificant potential for decision intelligence and contextual dialogue, theircapacity for domain-specific knowledge in HSE and structured legal reasoningremains underexplored. We introduce HSE-Bench, the first benchmark datasetdesigned to evaluate the HSE compliance assessment capabilities of LLM.HSE-Bench comprises over 1,000 manually curated questions drawn fromregulations, court cases, safety exams, and fieldwork videos, and integrates areasoning flow based on Issue spotting, rule Recall, rule Application, and ruleConclusion (IRAC) to assess the holistic reasoning pipeline. We conductextensive evaluations on different prompting strategies and more than 10 LLMs,including foundation models, reasoning models and multimodal vision models. Theresults show that, although current LLMs achieve good performance, theircapabilities largely rely on semantic matching rather than principled reasoninggrounded in the underlying HSE compliance context. Moreover, their nativereasoning trace lacks the systematic legal reasoning required for rigorous HSEcompliance assessment. To alleviate these, we propose a new promptingtechnique, Reasoning of Expert (RoE), which guides LLMs to simulate thereasoning process of different experts for compliance assessment and reach amore accurate unified decision. We hope our study highlights reasoning gaps inLLMs for HSE compliance and inspires further research on related tasks.</description>
      <author>example@mail.com (Jianwei Wang, Mengqi Wang, Yinsi Zhou, Zhenchang Xing, Qing Liu, Xiwei Xu, Wenjie Zhang, Liming Zhu)</author>
      <guid isPermaLink="false">2505.22959v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents</title>
      <link>http://arxiv.org/abs/2505.22954v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code at https://github.com/jennyzzt/dgm&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为达尔文戈德尔机器（DGM）的自改进系统，该系统能够通过迭代修改自身代码来提高其能力，并使用编码基准来验证每个变化。DGM通过借鉴达尔文进化论和开放性研究，维护一个生成的编码代理档案，并通过采样和基础模型创建新的有趣版本来扩展这个档案。实验表明，DGM在编码能力上自动提高了性能，并在多个基准测试中显著优于没有自改进或开放性探索的基线。&lt;h4&gt;背景&lt;/h4&gt;当前的人工智能系统具有由人类设计的固定架构，无法自主和持续地改进自己。自动化AI的进步本身可以加速AI的发展并让我们更早地获得其益处。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够自我改进的人工智能系统，使其能够通过迭代修改自身代码来提高其能力，并通过编码基准验证每个变化。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为达尔文戈德尔机器（DGM）的自改进系统，该系统通过迭代修改自身代码（从而也提高了其修改自身代码库的能力），并使用编码基准来验证每个变化。&lt;h4&gt;主要发现&lt;/h4&gt;DGM在编码能力上自动提高了性能，例如更好的代码编辑工具、长上下文窗口管理、同行评审机制。在SWE-bench基准测试中，性能从20.0%提高到50.0%，在Polyglot基准测试中从14.2%提高到30.7%。此外，DGM在多个基准测试中显著优于没有自改进或开放性探索的基线。&lt;h4&gt;结论&lt;/h4&gt;DGM是向自我改进人工智能的重大迈进，能够在无尽创新的道路上收集自己的垫脚石。&lt;h4&gt;翻译&lt;/h4&gt;Today's AI systems have human-designed, fixed architectures and cannot autonomously and continuously improve themselves. The advance of AI could itself be automated. If done safely, that would accelerate AI development and allow us to reap its benefits much sooner. Meta-learning can automate the discovery of novel algorithms, but is limited by first-order improvements and the human design of a suitable search space. The G"odel machine proposed a theoretical alternative: a self-improving AI that repeatedly modifies itself in a provably beneficial manner. Unfortunately, proving that most changes are net beneficial is impossible in practice. We introduce the Darwin G"odel Machine (DGM), a self-improving system that iteratively modifies its own code (thereby also improving its ability to modify its own codebase) and empirically validates each change using coding benchmarks. Inspired by Darwinian evolution and open-endedness research, the DGM maintains an archive of generated coding agents. It grows the archive by sampling an agent from it and using a foundation model to create a new, interesting, version of the sampled agent. This open-ended exploration forms a growing tree of diverse, high-quality agents and allows the parallel exploration of many different paths through the search space. Empirically, the DGM automatically improves its coding capabilities (e.g., better code editing tools, long-context window management, peer-review mechanisms), increasing performance on SWE-bench from 20.0% to 50.0%, and on Polyglot from 14.2% to 30.7%. Furthermore, the DGM significantly outperforms baselines without self-improvement or open-ended exploration. All experiments were done with safety precautions (e.g., sandboxing, human oversight). The DGM is a significant step toward self-improving AI, capable of gathering its own stepping stones along paths that unfold into endless innovation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Today's AI systems have human-designed, fixed architectures and cannotautonomously and continuously improve themselves. The advance of AI coulditself be automated. If done safely, that would accelerate AI development andallow us to reap its benefits much sooner. Meta-learning can automate thediscovery of novel algorithms, but is limited by first-order improvements andthe human design of a suitable search space. The G\"odel machine proposed atheoretical alternative: a self-improving AI that repeatedly modifies itself ina provably beneficial manner. Unfortunately, proving that most changes are netbeneficial is impossible in practice. We introduce the Darwin G\"odel Machine(DGM), a self-improving system that iteratively modifies its own code (therebyalso improving its ability to modify its own codebase) and empiricallyvalidates each change using coding benchmarks. Inspired by Darwinian evolutionand open-endedness research, the DGM maintains an archive of generated codingagents. It grows the archive by sampling an agent from it and using afoundation model to create a new, interesting, version of the sampled agent.This open-ended exploration forms a growing tree of diverse, high-qualityagents and allows the parallel exploration of many different paths through thesearch space. Empirically, the DGM automatically improves its codingcapabilities (e.g., better code editing tools, long-context window management,peer-review mechanisms), increasing performance on SWE-bench from 20.0% to50.0%, and on Polyglot from 14.2% to 30.7%. Furthermore, the DGM significantlyoutperforms baselines without self-improvement or open-ended exploration. Allexperiments were done with safety precautions (e.g., sandboxing, humanoversight). The DGM is a significant step toward self-improving AI, capable ofgathering its own stepping stones along paths that unfold into endlessinnovation.</description>
      <author>example@mail.com (Jenny Zhang, Shengran Hu, Cong Lu, Robert Lange, Jeff Clune)</author>
      <guid isPermaLink="false">2505.22954v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Molecular Grammar: Multi-Modal Foundation Models Induce Interpretable Molecular Graph Languages</title>
      <link>http://arxiv.org/abs/2505.22948v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FMG的数据高效分子生成方法，利用多模态基础模型（MMFMs）来诱导可解释的分子语言，并展示了其在合成性、多样性和数据效率方面的优势。&lt;h4&gt;背景&lt;/h4&gt;现有的分子生成方法依赖专家标注或不稳定的启发式算法进行语法学习，缺乏可解释性。&lt;h4&gt;目的&lt;/h4&gt;提出FMG，以实现数据高效的分子生成，并提高分子生成模型的化学可解释性。&lt;h4&gt;方法&lt;/h4&gt;FMG利用MMFM的化学知识将分子渲染为图像，用文本描述它们，并通过提示学习在模态之间对齐信息。&lt;h4&gt;主要发现&lt;/h4&gt;FMG可以作为现有分子生成和性质预测中语法学习方法的直接替代品，不仅表现出优异的合成性、多样性和数据效率，还提供了内置的化学可解释性。&lt;h4&gt;结论&lt;/h4&gt;FMG为自动化分子发现工作流程提供了有效的工具，并可通过提供的代码进行实现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent data-efficient molecular generation approaches exploit graph grammarsto introduce interpretability into the generative models. However, grammarlearning therein relies on expert annotation or unreliable heuristics foralgorithmic inference. We propose Foundation Molecular Grammar (FMG), whichleverages multi-modal foundation models (MMFMs) to induce an interpretablemolecular language. By exploiting the chemical knowledge of an MMFM, FMGrenders molecules as images, describes them as text, and aligns informationacross modalities using prompt learning. FMG can be used as a drop-inreplacement for the prior grammar learning approaches in molecular generationand property prediction. We show that FMG not only excels in synthesizability,diversity, and data efficiency but also offers built-in chemicalinterpretability for automated molecular discovery workflows. Code is availableat https://github.com/shiningsunnyday/induction.</description>
      <author>example@mail.com (Michael Sun, Weize Yuan, Gang Liu, Wojciech Matusik, Jie Chen)</author>
      <guid isPermaLink="false">2505.22948v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Defining Foundation Models for Computational Science: A Call for Clarity and Rigor</title>
      <link>http://arxiv.org/abs/2505.22904v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 2 tables, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在计算科学中应用基础模型的概念，提出了一种形式化的定义，并介绍了数据驱动有限元方法（DD-FEM）。&lt;h4&gt;背景&lt;/h4&gt;自然语言处理和计算机视觉领域基础模型的成功激发了对计算科学和科学机器学习的扩展研究。&lt;h4&gt;目的&lt;/h4&gt;解决基础模型在计算科学应用中缺乏普遍接受的定义的问题。&lt;h4&gt;方法&lt;/h4&gt;提出基础模型在计算科学中的形式化定义，强调通用性、可重用性和可扩展性，并引入DD-FEM框架。&lt;h4&gt;主要发现&lt;/h4&gt;DD-FEM结合了经典有限元方法的模块化结构和数据驱动学习的表示能力，解决了计算科学中基础模型的关键挑战，如可扩展性、适应性和物理一致性。&lt;h4&gt;结论&lt;/h4&gt;通过将传统数值方法与现代人工智能范式相结合，本研究为评估和开发计算科学中未来基础模型的新方法提供了坚实的理论基础。&lt;h4&gt;翻译&lt;/h4&gt;The widespread success of foundation models in natural language processing and computer vision has inspired researchers to extend the concept to scientific machine learning and computational science. However, this position paper argues that as the term 'foundation model' is an evolving concept, its application in computational science is increasingly used without a universally accepted definition, potentially creating confusion and diluting its precise scientific meaning. In this paper, we address this gap by proposing a formal definition of foundation models in computational science, grounded in the core values of generality, reusability, and scalability. We articulate a set of essential and desirable characteristics that such models must exhibit, drawing parallels with traditional foundational methods, like the finite element and finite volume methods. Furthermore, we introduce the Data-Driven Finite Element Method (DD-FEM), a framework that fuses the modular structure of classical FEM with the representational power of data-driven learning. We demonstrate how DD-FEM addresses many of the key challenges in realizing foundation models for computational science, including scalability, adaptability, and physics consistency. By bridging traditional numerical methods with modern AI paradigms, this work provides a rigorous foundation for evaluating and developing novel approaches toward future foundation models in computational science.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The widespread success of foundation models in natural language processingand computer vision has inspired researchers to extend the concept toscientific machine learning and computational science. However, this positionpaper argues that as the term "foundation model" is an evolving concept, itsapplication in computational science is increasingly used without a universallyaccepted definition, potentially creating confusion and diluting its precisescientific meaning. In this paper, we address this gap by proposing a formaldefinition of foundation models in computational science, grounded in the corevalues of generality, reusability, and scalability. We articulate a set ofessential and desirable characteristics that such models must exhibit, drawingparallels with traditional foundational methods, like the finite element andfinite volume methods. Furthermore, we introduce the Data-Driven Finite ElementMethod (DD-FEM), a framework that fuses the modular structure of classical FEMwith the representational power of data-driven learning. We demonstrate howDD-FEM addresses many of the key challenges in realizing foundation models forcomputational science, including scalability, adaptability, and physicsconsistency. By bridging traditional numerical methods with modern AIparadigms, this work provides a rigorous foundation for evaluating anddeveloping novel approaches toward future foundation models in computationalscience.</description>
      <author>example@mail.com (Youngsoo Choi, Siu Wun Cheung, Youngkyu Kim, Ping-Hsuan Tsai, Alejandro N. Diaz, Ivan Zanardi, Seung Whan Chung, Dylan Matthew Copeland, Coleman Kendrick, William Anderson, Traian Iliescu, Matthias Heinkenschloss)</author>
      <guid isPermaLink="false">2505.22904v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Preference Learning with Response Time</title>
      <link>http://arxiv.org/abs/2505.22820v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将响应时间数据整合到人类偏好学习框架中，以提高奖励模型诱导的有效性。&lt;h4&gt;背景&lt;/h4&gt;虽然二进制偏好数据已成为微调基础模型、生成式AI系统和其他大规模模型的基本数据，但用户决策中固有的宝贵时间信息尚未得到充分利用。&lt;h4&gt;目的&lt;/h4&gt;提出新的方法将响应时间信息与二进制选择数据相结合，利用证据积累漂移扩散（EZ）模型，其中响应时间可反映偏好强度。&lt;h4&gt;方法&lt;/h4&gt;开发了Neyman正交损失函数，实现了奖励模型学习的理想收敛速度，与理论上如果事先知道每个查询的期望响应时间所能达到的最优速度相匹配。&lt;h4&gt;主要发现&lt;/h4&gt;对于线性奖励函数，传统的偏好学习在误差率上呈指数级随奖励大小增加。而响应时间增强的方法将这一误差率降低到多项式级，从而显著提高了样本效率。&lt;h4&gt;结论&lt;/h4&gt;这些保证被扩展到非参数奖励函数空间，为更复杂、更现实的奖励模型建立了收敛性质。&lt;h4&gt;翻译&lt;/h4&gt;本文探讨了将响应时间数据整合到人类偏好学习框架中以提高奖励模型诱导的有效性。尽管二进制偏好数据已成为微调基础模型、生成式AI系统和其他大规模模型的基本数据，但用户决策中固有的宝贵时间信息尚未得到充分利用。本文提出了一种新的方法，将响应时间信息与二进制选择数据相结合，利用证据积累漂移扩散（EZ）模型，其中响应时间可反映偏好强度。本文开发了Neyman正交损失函数，实现了奖励模型学习的理想收敛速度，与理论上如果事先知道每个查询的期望响应时间所能达到的最优速度相匹配。理论分析表明，对于线性奖励函数，传统的偏好学习在误差率上呈指数级随奖励大小增加。而响应时间增强的方法将这一误差率降低到多项式级，从而显著提高了样本效率。这些保证被扩展到非参数奖励函数空间，为更复杂、更现实的奖励模型建立了收敛性质。本文在图像偏好学习的背景下进行了广泛的实验，验证了理论发现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the integration of response time data into humanpreference learning frameworks for more effective reward model elicitation.While binary preference data has become fundamental in fine-tuning foundationmodels, generative AI systems, and other large-scale models, the valuabletemporal information inherent in user decision-making remains largelyunexploited. We propose novel methodologies to incorporate response timeinformation alongside binary choice data, leveraging the Evidence AccumulationDrift Diffusion (EZ) model, under which response time is informative of thepreference strength. We develop Neyman-orthogonal loss functions that achieveoracle convergence rates for reward model learning, matching the theoreticaloptimal rates that would be attained if the expected response times for eachquery were known a priori. Our theoretical analysis demonstrates that forlinear reward functions, conventional preference learning suffers from errorrates that scale exponentially with reward magnitude. In contrast, our responsetime-augmented approach reduces this to polynomial scaling, representing asignificant improvement in sample efficiency. We extend these guarantees tonon-parametric reward function spaces, establishing convergence properties formore complex, realistic reward models. Our extensive experiments validate ourtheoretical findings in the context of preference learning over images.</description>
      <author>example@mail.com (Ayush Sawarni, Sahasrajit Sarmasarkar, Vasilis Syrgkanis)</author>
      <guid isPermaLink="false">2505.22820v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>DeepMultiConnectome: Deep Multi-Task Prediction of Structural Connectomes Directly from Diffusion MRI Tractography</title>
      <link>http://arxiv.org/abs/2505.22685v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 5 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DeepMultiConnectome是一种基于深度学习的模型，能够直接从弥散加权磁共振成像(弥散成像)轨迹图中预测结构连接组，无需灰质分割，支持多种分割方案。&lt;h4&gt;背景&lt;/h4&gt;传统的连接组生成方法耗时且需要灰质分割，这对大规模研究构成了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出DeepMultiConnectome模型，以实现快速生成不同分割方案下的个体特异性连接组。&lt;h4&gt;方法&lt;/h4&gt;DeepMultiConnectome使用基于点云的神经网络和多任务学习，根据两个分割方案中流线的连接区域对它们进行分类，并共享学习到的表示。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在人类连接组项目青年成人数据集（n=1000）上进行了训练和验证，能够从包含300万条流线的全脑轨迹图中预测多个结构连接组，耗时约40秒。预测的连接组与传统方法生成的连接组高度相关，且保留了网络属性。测试-重测分析表明，DeepMultiConnectome的可重复性与传统方法生成的连接组相当。&lt;h4&gt;结论&lt;/h4&gt;DeepMultiConnectome提供了一种可扩展、快速的模型，可以生成多个分割方案下的个体特异性连接组。&lt;h4&gt;翻译&lt;/h4&gt;We introduce DeepMultiConnectome, a deep-learning model that predicts structural connectomes directly from tractography, bypassing the need for gray matter parcellation while supporting multiple parcellation schemes. The model uses a point-cloud-based neural network with multi-task learning to classify streamlines according to their connected regions across two parcellation schemes, sharing a learned representation. Trained and validated on tractography from the Human Connectome Project Young Adult dataset ($n = 1000$) labeled with an 84 and 164 region gray matter parcellation scheme, DeepMultiConnectome predicts multiple structural connectomes from a whole-brain tractogram containing 3 million streamlines in approximately 40 seconds. Evaluation by comparing predicted connectomes with traditionally generated connectomes shows high correlation ($r = 0.992$ for an 84-region scheme; $r = 0.986$ for a 164-region scheme) and preservation of network properties. Test-retest analysis of DeepMultiConnectome demonstrates reproducibility comparable to traditionally generated connectomes. The predicted connectomes perform similarly to traditionally generated connectomes in predicting age and cognitive function. Overall, DeepMultiConnectome provides a scalable, fast model for generating subject-specific connectomes across multiple parcellation schemes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion MRI (dMRI) tractography enables in vivo mapping of brain structuralconnections, but traditional connectome generation is time-consuming andrequires gray matter parcellation, posing challenges for large-scale studies.We introduce DeepMultiConnectome, a deep-learning model that predictsstructural connectomes directly from tractography, bypassing the need for graymatter parcellation while supporting multiple parcellation schemes. Using apoint-cloud-based neural network with multi-task learning, the model classifiesstreamlines according to their connected regions across two parcellationschemes, sharing a learned representation. We train and validateDeepMultiConnectome on tractography from the Human Connectome Project YoungAdult dataset ($n = 1000$), labeled with an 84 and 164 region gray matterparcellation scheme. DeepMultiConnectome predicts multiple structuralconnectomes from a whole-brain tractogram containing 3 million streamlines inapproximately 40 seconds. DeepMultiConnectome is evaluated by comparingpredicted connectomes with traditional connectomes generated using theconventional method of labeling streamlines using a gray matter parcellation.The predicted connectomes are highly correlated with traditionally generatedconnectomes ($r = 0.992$ for an 84-region scheme; $r = 0.986$ for a 164-regionscheme) and largely preserve network properties. A test-retest analysis ofDeepMultiConnectome demonstrates reproducibility comparable to traditionallygenerated connectomes. The predicted connectomes perform similarly totraditionally generated connectomes in predicting age and cognitive function.Overall, DeepMultiConnectome provides a scalable, fast model for generatingsubject-specific connectomes across multiple parcellation schemes.</description>
      <author>example@mail.com (Marcus J. Vroemen, Yuqian Chen, Yui Lo, Tengfei Xu, Weidong Cai, Fan Zhang, Josien P. W. Pluim, Lauren J. O'Donnell)</author>
      <guid isPermaLink="false">2505.22685v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>IMTS is Worth Time $\times$ Channel Patches: Visual Masked Autoencoders for Irregular Multivariate Time Series Prediction</title>
      <link>http://arxiv.org/abs/2505.22815v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为VIMTS的框架，用于解决不规则多变量时间序列（IMTS）预测问题，该框架通过调整视觉MaskAutoEncoder（MAE）以适应IMTS预测。&lt;h4&gt;背景&lt;/h4&gt;由于多通道信号的不对齐和大量缺失数据的存在，IMTS预测具有挑战性。现有方法难以从具有大量缺失值的数据中捕获可靠的时序模式。&lt;h4&gt;目的&lt;/h4&gt;提出VIMTS框架，以解决IMTS预测中的挑战，并提高预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;VIMTS首先将IMTS沿时间线处理成等间隔的特征块，然后利用学习到的跨通道依赖关系对这些块进行补充。之后，它利用视觉MAE处理稀疏多通道数据的能力进行块重建，并采用从聚焦上下文生成精确预测的粗到细技术。此外，通过将视觉MAE调整到IMTS数据，VIMTS集成了自监督学习以改进IMTS建模。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，VIMTS在性能和少样本能力方面优于现有方法，推动了视觉基础模型在更一般的时间序列任务中的应用。&lt;h4&gt;结论&lt;/h4&gt;VIMTS是一个有效的IMTS预测框架，它通过结合视觉MAE和自监督学习，提高了预测的准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：不规则多变量时间序列（IMTS）预测由于多通道信号的不对齐和大量缺失数据的存在而具有挑战性。现有方法由于显著的缺失值而难以从此类数据中捕获可靠的时序模式。虽然预训练的基础模型在解决这些挑战方面显示出潜力，但它们通常是为规则采样时间序列（RTS）设计的。受视觉MaskAutoEncoder（MAE）在建模稀疏多通道信息方面的强大能力和其在RTS预测中的成功启发，我们提出了VIMTS，一个用于IMTS预测的框架，它调整了视觉MAE。为了减轻缺失值的影响，VIMTS首先将IMTS沿时间线处理成等间隔的特征块。然后，它使用学习到的跨通道依赖关系对这些块进行补充。然后，它利用视觉MAE处理稀疏多通道数据的能力进行块重建，随后采用从聚焦上下文生成精确预测的粗到细技术。此外，我们通过将视觉MAE调整到IMTS数据，集成了自监督学习以改进IMTS建模。广泛的实验表明VIMTS的优越性能和少样本能力，推动了视觉基础模型在更一般的时间序列任务中的应用。我们的代码可在https://github.com/WHU-HZY/VIMTS上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Irregular Multivariate Time Series (IMTS) forecasting is challenging due tothe unaligned nature of multi-channel signals and the prevalence of extensivemissing data. Existing methods struggle to capture reliable temporal patternsfrom such data due to significant missing values. While pre-trained foundationmodels show potential for addressing these challenges, they are typicallydesigned for Regularly Sampled Time Series (RTS). Motivated by the visual MaskAutoEncoder's (MAE) powerful capability for modeling sparse multi-channelinformation and its success in RTS forecasting, we propose VIMTS, a frameworkadapting Visual MAE for IMTS forecasting. To mitigate the effect of missingvalues, VIMTS first processes IMTS along the timeline into feature patches atequal intervals. These patches are then complemented using learnedcross-channel dependencies. Then it leverages visual MAE's capability inhandling sparse multichannel data for patch reconstruction, followed by acoarse-to-fine technique to generate precise predictions from focused contexts.In addition, we integrate self-supervised learning for improved IMTS modelingby adapting the visual MAE to IMTS data. Extensive experiments demonstrateVIMTS's superior performance and few-shot capability, advancing the applicationof visual foundation models in more general time series tasks. Our code isavailable at https://github.com/WHU-HZY/VIMTS.</description>
      <author>example@mail.com (Zhangyi Hu, Jiemin Wu, Hua Xu, Mingqian Liao, Ninghui Feng, Bo Gao, Songning Lai, Yutao Yue)</author>
      <guid isPermaLink="false">2505.22815v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>ReassembleNet: Learnable Keypoints and Diffusion for 2D Fresco Reconstruction</title>
      <link>http://arxiv.org/abs/2505.21117v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ReassembleNet的方法，用于解决多领域中的重组任务，如考古学、基因组学和分子对接，该方法通过降低计算复杂度，同时整合多种模态的数据，提高了重组的准确性和实用性。&lt;h4&gt;背景&lt;/h4&gt;重组任务在多个领域都是一个重大挑战，需要精确放置和定位元素以重建原始结构。&lt;h4&gt;目的&lt;/h4&gt;解决现有深度学习方法的局限性，包括可扩展性、多模态性和现实世界的适用性。&lt;h4&gt;方法&lt;/h4&gt;ReassembleNet通过将每个输入部件表示为一组轮廓关键点，并利用图神经网络池化技术来选择最有信息量的点，从而降低复杂性。此外，该方法通过在半合成数据集上进行预训练，进一步增强了其性能。最后，应用基于扩散的位姿估计来恢复原始结构。&lt;h4&gt;主要发现&lt;/h4&gt;ReassembleNet在RMSE旋转和翻译方面分别提高了55%和86%，优于先前的方法。&lt;h4&gt;结论&lt;/h4&gt;ReassembleNet是一种有效的重组方法，能够处理复杂和真实世界的问题，并显著提高了重组的准确性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The task of reassembly is a significant challenge across multiple domains,including archaeology, genomics, and molecular docking, requiring the preciseplacement and orientation of elements to reconstruct an original structure. Inthis work, we address key limitations in state-of-the-art Deep Learning methodsfor reassembly, namely i) scalability; ii) multimodality; and iii) real-worldapplicability: beyond square or simple geometric shapes, realistic and complexerosion, or other real-world problems. We propose ReassembleNet, a method thatreduces complexity by representing each input piece as a set of contourkeypoints and learning to select the most informative ones by Graph NeuralNetworks pooling inspired techniques. ReassembleNet effectively lowerscomputational complexity while enabling the integration of features frommultiple modalities, including both geometric and texture data. Furtherenhanced through pretraining on a semi-synthetic dataset. We then applydiffusion-based pose estimation to recover the original structure. We improveon prior methods by 55% and 86% for RMSE Rotation and Translation,respectively.</description>
      <author>example@mail.com (Adeela Islam, Stefano Fiorini, Stuart James, Pietro Morerio, Alessio Del Bue)</author>
      <guid isPermaLink="false">2505.21117v2</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Anomalies by Synthesis: Anomaly Detection using Generative Diffusion Models for Off-Road Navigation</title>
      <link>http://arxiv.org/abs/2505.22805v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种分析-by-合成的方法，用于像素级异常检测，该方法无需对异常数据的性质做任何假设。&lt;h4&gt;背景&lt;/h4&gt;为了在非结构化环境中安全可靠地导航，机器人必须检测与训练数据分布不一致的异常。&lt;h4&gt;目的&lt;/h4&gt;实现无需对异常数据性质做假设的像素级异常检测。&lt;h4&gt;方法&lt;/h4&gt;使用生成扩散模型合成编辑后的图像，去除异常的同时保持剩余图像不变；通过分析由扩散模型修改的图像段来识别异常；提出一种基于理想引导梯度的推理方法，并推导出一种原理性的近似方法，以引导扩散模型预测引导梯度；编辑技术纯粹是测试时技术，可以集成到现有工作流程中，无需重新训练或微调；利用视觉-语言基础模型在学习的特征空间中比较像素，检测语义上有意义的编辑，实现准确的异常检测。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种新的推理方法，通过分析理想引导梯度和推导原理性近似，以引导扩散模型预测引导梯度。&lt;h4&gt;结论&lt;/h4&gt;该方法能够实现非结构化环境中的准确异常检测，适用于越野导航。&lt;h4&gt;翻译&lt;/h4&gt;为了在越野和非结构化环境中安全可靠地导航，机器人必须检测与训练数据分布不一致的异常。我们提出了一种分析-by-合成的方法，用于像素级异常检测，该方法无需对异常数据的性质做任何假设。给定一个输入图像，我们使用生成扩散模型合成一个编辑后的图像，去除异常的同时保持剩余图像不变。然后，我们将异常检测定义为分析由扩散模型修改的图像段。我们提出了一种基于理想引导梯度的推理方法，并推导出一种原理性的近似，以引导扩散模型预测引导梯度。我们的编辑技术纯粹是测试时技术，可以集成到现有工作流程中，无需重新训练或微调。最后，我们使用视觉-语言基础模型的组合在学习的特征空间中比较像素，检测语义上有意义的编辑，从而实现准确的异常检测，适用于越野导航。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In order to navigate safely and reliably in off-road and unstructuredenvironments, robots must detect anomalies that are out-of-distribution (OOD)with respect to the training data. We present an analysis-by-synthesis approachfor pixel-wise anomaly detection without making any assumptions about thenature of OOD data. Given an input image, we use a generative diffusion modelto synthesize an edited image that removes anomalies while keeping theremaining image unchanged. Then, we formulate anomaly detection as analyzingwhich image segments were modified by the diffusion model. We propose a novelinference approach for guided diffusion by analyzing the ideal guidancegradient and deriving a principled approximation that bootstraps the diffusionmodel to predict guidance gradients. Our editing technique is purely test-timethat can be integrated into existing workflows without the need for retrainingor fine-tuning. Finally, we use a combination of vision-language foundationmodels to compare pixels in a learned feature space and detect semanticallymeaningful edits, enabling accurate anomaly detection for off-road navigation.Project website: https://siddancha.github.io/anomalies-by-diffusion-synthesis/</description>
      <author>example@mail.com (Siddharth Ancha, Sunshine Jiang, Travis Manderson, Laura Brandt, Yilun Du, Philip R. Osteen, Nicholas Roy)</author>
      <guid isPermaLink="false">2505.22805v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Theory and simulation of elastoinertial rectification of oscillatory flows in two-dimensional deformable rectangular channels</title>
      <link>http://arxiv.org/abs/2505.22799v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究了一种二维流体通道，当流体通过时，由于流体动力作用，通道发生变形，流体惯性和变形之间的非线性耦合产生了一种称为‘弹性惯性整流’的现象，该现象增强了流动效应。&lt;h4&gt;背景&lt;/h4&gt;二维通道由刚性底部表面和上方的弹性层组成，当流体通过时，流体-固体界面发生变形，改变了通道的横截面积。&lt;h4&gt;目的&lt;/h4&gt;将流体-结构相互作用（FSI）的理论应用于二维矩形配置，并使用直接数值模拟验证理论。&lt;h4&gt;方法&lt;/h4&gt;采用Chandler和Vella的联合基础模型来捕捉几乎不可压缩的弹性层的变形，并使用开放源代码计算平台FEniCS执行符合任意拉格朗日-欧拉（ALE）FSI公式的直接数值模拟。&lt;h4&gt;主要发现&lt;/h4&gt;理论预测与模拟结果在压力和变形的主导阶数上吻合良好。然而，在次主导阶数上，平均压力与模拟结果吻合良好，但平均变形表现出显著的轴向和垂直位移。&lt;h4&gt;结论&lt;/h4&gt;理论预测与模拟结果在主导阶数上具有良好的一致性，但在次主导阶数上存在差异，表明需要进一步研究以更准确地描述流动和变形之间的相互作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A slender two-dimensional (2D) channel bounded by a rigid bottom surface anda slender elastic layer above deforms when a fluid flows through it.Hydrodynamic forces cause deformation at the fluid-solid interface, which inturn changes the cross-sectional area of the fluidic channel. The nonlinearcoupling between flow and deformation, along with the attendant asymmetry ingeometry caused by flow-induced deformation, produces a streaming effect (anon-zero cycle-average despite time-periodic forcing). Surprisingly, fluidinertia provides another nonlinear coupling, tightly connected to deformation,that enhances streaming, termed ``elastoinertial rectification'' by Zhang andRallabandi [J. Fluid Mech. 996, A16 (2024)]. We adapt the latter theory of howtwo-way coupled fluid--structure interaction (FSI) produces streaming to a 2Drectangular configuration, specifically taking care to capture the deformationsof the nearly incompressible slender elastic layer via the combined foundationmodel of Chandler and Vella [Proc. R. Soc. A 476, 20200551 (2020)]. Wesupplement the elastoinertial rectification theory with direct numericalsimulations performed using a conforming arbitrary Lagrangian-Eulerian (ALE)FSI formulation with streamline upwind Petrov-Galerkin stabilization,implemented via the open-source computing platform FEniCS. We examine the axialvariation of the cycle-averaged pressure as a function of key dimensionlessgroups of the problem: the Womersley number, the elastoviscous number, and thecompliance number. Assuming a small compliance number, we find excellentagreement between theory and simulations for the leading-order pressure anddeformation across a range of conditions. At the next order, the cycle-averagedpressures agree well; however, the cycle-averaged deformation is found toexhibit significant axial and vertical displacements, unlike the combinedfoundation model.</description>
      <author>example@mail.com (Uday M. Rade, Shrihari D. Pande, Ivan C. Christov)</author>
      <guid isPermaLink="false">2505.22799v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Navigating the Latent Space Dynamics of Neural Models</title>
      <link>http://arxiv.org/abs/2505.22785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出将神经网络视为作用于潜在流形上的动力学系统，通过迭代应用编码-解码映射隐式定义潜在向量场，并分析该向量场在神经网络模型和数据属性分析中的应用。&lt;h4&gt;背景&lt;/h4&gt;神经网络通常将高维数据转换为低维潜在空间的紧凑结构表示。&lt;h4&gt;目的&lt;/h4&gt;探索神经网络模型的动力学特性，提供新的分析工具。&lt;h4&gt;方法&lt;/h4&gt;研究自编码器模型如何定义潜在向量场，并分析标准训练过程引入的归纳偏差。&lt;h4&gt;主要发现&lt;/h4&gt;发现标准训练过程在向量场中产生吸引子点，这些吸引子可以用于分析模型的泛化能力和记忆模式，提取网络参数中的先验知识，以及识别异常值。&lt;h4&gt;结论&lt;/h4&gt;该方法在视觉基础模型上得到验证，显示其在实际场景中的应用性和有效性。&lt;h4&gt;翻译&lt;/h4&gt;Neural networks transform high-dimensional data into compact, structured representations, often modeled as elements of a lower dimensional latent space. In this paper, we present an alternative interpretation of neural models as dynamical systems acting on the latent manifold. Specifically, we show that autoencoder models implicitly define a latent vector field on the manifold, derived by iteratively applying the encoding-decoding map, without any additional training. We observe that standard training procedures introduce inductive biases that lead to the emergence of attractor points within this vector field. Drawing on this insight, we propose to leverage the vector field as a representation for the network, providing a novel tool to analyze the properties of the model and the data. This representation enables to: (i) analyze the generalization and memorization regimes of neural models, even throughout training; (ii) extract prior knowledge encoded in the network's parameters from the attractors, without requiring any input data; (iii) identify out-of-distribution samples from their trajectories in the vector field. We further validate our approach on vision foundation models, showcasing the applicability and effectiveness of our method in real-world scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural networks transform high-dimensional data into compact, structuredrepresentations, often modeled as elements of a lower dimensional latent space.In this paper, we present an alternative interpretation of neural models asdynamical systems acting on the latent manifold. Specifically, we show thatautoencoder models implicitly define a latent vector field on the manifold,derived by iteratively applying the encoding-decoding map, without anyadditional training. We observe that standard training procedures introduceinductive biases that lead to the emergence of attractor points within thisvector field. Drawing on this insight, we propose to leverage the vector fieldas a representation for the network, providing a novel tool to analyze theproperties of the model and the data. This representation enables to: (i)analyze the generalization and memorization regimes of neural models, eventhroughout training; (ii) extract prior knowledge encoded in the network'sparameters from the attractors, without requiring any input data; (iii)identify out-of-distribution samples from their trajectories in the vectorfield. We further validate our approach on vision foundation models, showcasingthe applicability and effectiveness of our method in real-world scenarios.</description>
      <author>example@mail.com (Marco Fumero, Luca Moschella, Emanuele Rodolà, Francesco Locatello)</author>
      <guid isPermaLink="false">2505.22785v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Multivariate de Bruijn Graphs: A Symbolic Graph Framework for Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2505.22768v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DRAGON的编码器，用于解决时间序列预测的挑战，该编码器通过引入多维de Bruijn图来连接符号表示和神经网络建模。&lt;h4&gt;背景&lt;/h4&gt;时间序列预测对基础模型来说是一个挑战，因为它具有时间异质性、高维度和缺乏内在符号结构的特点。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种新的编码器，以解决时间序列预测中的这些挑战。&lt;h4&gt;方法&lt;/h4&gt;DRAGON将连续输入序列离散化，并将它们映射到一个固定的图结构上，通过基于图的注意力机制实现动态上下文恢复。DRAGON作为一个辅助模块集成到双分支架构中，增强了传统的基于CNN的编码器，使其具有符号和结构感知的表示。&lt;h4&gt;主要发现&lt;/h4&gt;DRAGON能够有效地处理时间序列预测问题，通过引入多维de Bruijn图来增强编码器的性能。&lt;h4&gt;结论&lt;/h4&gt;DRAGON是一种有效的编码器，可以用于时间序列预测，并有望提高预测的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Time series forecasting remains a challenging task for foundation models due to temporal heterogeneity, high dimensionality, and the lack of inherent symbolic structure. In this work, we propose DRAGON (Discrete Representation and Augmented Graph encoding Over deBruijn Graphs), a novel encoder that introduces Multivariate de Bruijn Graphs (MdBGs) to bridge the gap between symbolic representations and neural modeling. DRAGON discretizes continuous input sequences and maps them onto a fixed graph structure, enabling dynamic context recovery via graph-based attention. Integrated as an auxiliary module within a dual-branch architecture, DRAGON augments conventional CNN-based encoders with symbolic, structure-aware representations. All code developed for this study is available at:https://github.com/KurbanIntelligenceLab/MultdBG-Time-Series-Library&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting remains a challenging task for foundation models dueto temporal heterogeneity, high dimensionality, and the lack of inherentsymbolic structure. In this work, we propose DRAGON (Discrete Representationand Augmented Graph encoding Over deBruijN Graphs), a novel encoder thatintroduces Multivariate de Bruijn Graphs (MdBGs) to bridge the gap betweensymbolic representations and neural modeling. DRAGON discretizes continuousinput sequences and maps them onto a fixed graph structure, enabling dynamiccontext recovery via graph-based attention. Integrated as an auxiliary modulewithin a dual-branch architecture, DRAGON augments conventional CNN-basedencoders with symbolic, structure-aware representations. All code developed forthis study is available at:https://github.com/KurbanIntelligenceLab/MultdBG-Time-Series-Library</description>
      <author>example@mail.com (Mert Onur Cakiroglu, Idil Bilge Altun, Hasan Kurban, Elham Buxton, Mehmet Dalkilic)</author>
      <guid isPermaLink="false">2505.22768v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Pessimism Principle Can Be Effective: Towards a Framework for Zero-Shot Transfer Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2505.18447v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于悲观原则的转移强化学习新框架，旨在解决在有限数据情况下，利用相关源域的大量数据来推导目标环境近似最优策略所面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;转移强化学习旨在通过利用相关源域的大量数据，在目标环境中推导出近似最优策略，但面临两个关键挑战：转移策略的性能保证不足可能导致不期望的行为，以及涉及多个源域时的负迁移风险。&lt;h4&gt;目的&lt;/h4&gt;提出一种新框架，通过构建和优化目标域性能的保守估计来解决上述挑战。&lt;h4&gt;方法&lt;/h4&gt;该方法通过提供目标性能的优化下界，确保决策的安全和可靠，并展示出随着源域质量的单调改进，避免负迁移。构建两种类型的保守估计，严格表征其有效性，并开发具有收敛保证的高效分布式算法。&lt;h4&gt;主要发现&lt;/h4&gt;新框架提供了理论上合理且实践上稳健的转移强化学习解决方案。&lt;h4&gt;结论&lt;/h4&gt;本文提出的框架能够有效解决转移强化学习中的挑战，为相关领域的研究提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer reinforcement learning aims to derive a near-optimal policy for atarget environment with limited data by leveraging abundant data from relatedsource domains. However, it faces two key challenges: the lack of performanceguarantees for the transferred policy, which can lead to undesired actions, andthe risk of negative transfer when multiple source domains are involved. Wepropose a novel framework based on the pessimism principle, which constructsand optimizes a conservative estimation of the target domain's performance. Ourframework effectively addresses the two challenges by providing an optimizedlower bound on target performance, ensuring safe and reliable decisions, and byexhibiting monotonic improvement with respect to the quality of the sourcedomains, thereby avoiding negative transfer. We construct two types ofconservative estimations, rigorously characterize their effectiveness, anddevelop efficient distributed algorithms with convergence guarantees. Ourframework provides a theoretically sound and practically robust solution fortransfer learning in reinforcement learning.</description>
      <author>example@mail.com (Chi Zhang, Ziying Jia, George K. Atia, Sihong He, Yue Wang)</author>
      <guid isPermaLink="false">2505.18447v2</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>FAMA: The First Large-Scale Open-Science Speech Foundation Model for English and Italian</title>
      <link>http://arxiv.org/abs/2505.22759v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FAMA是首个针对英语和意大利语的开源语音基础模型（SFM）家族，在超过150,000小时的开源语音数据上训练，并包含一个16,000小时清洗和伪标注的语音数据集，在性能和速度上具有竞争力。&lt;h4&gt;背景&lt;/h4&gt;尽管Whisper和SeamlessM4T等语音基础模型推动了语音处理领域的发展，但其封闭性导致可重复性和公平评估存在挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，提出FAMA，旨在推动语音处理领域的开源科学。&lt;h4&gt;方法&lt;/h4&gt;开发FAMA，使用超过150,000小时的开源语音数据训练，并创建一个包含16,000小时清洗和伪标注语音数据的新数据集。&lt;h4&gt;主要发现&lt;/h4&gt;FAMA在性能上与现有SFMs相当，同时速度提升高达8倍。&lt;h4&gt;结论&lt;/h4&gt;FAMA的发布在开源许可下，促进了语音技术研究的开放性。&lt;h4&gt;翻译&lt;/h4&gt;The development of speech foundation models (SFMs) like Whisper and SeamlessM4T has significantly advanced the field of speech processing. However, their closed nature -- with inaccessible training data and code -- poses major reproducibility and fair evaluation challenges. While other domains have made substantial progress toward open science by developing fully transparent models trained on open-source (OS) code and data, similar efforts in speech remain limited. To fill this gap, we introduce FAMA, the first family of open science SFMs for English and Italian, trained on 150k+ hours of OS speech data. Moreover, we present a new dataset containing 16k hours of cleaned and pseudo-labeled speech for both languages. Results show that FAMA achieves competitive performance compared to existing SFMs while being up to 8 times faster. All artifacts, including code, datasets, and models, are released under OS-compliant licenses, promoting openness in speech technology research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of speech foundation models (SFMs) like Whisper andSeamlessM4T has significantly advanced the field of speech processing. However,their closed nature--with inaccessible training data and code--poses majorreproducibility and fair evaluation challenges. While other domains have madesubstantial progress toward open science by developing fully transparent modelstrained on open-source (OS) code and data, similar efforts in speech remainlimited. To fill this gap, we introduce FAMA, the first family of open scienceSFMs for English and Italian, trained on 150k+ hours of OS speech data.Moreover, we present a new dataset containing 16k hours of cleaned andpseudo-labeled speech for both languages. Results show that FAMA achievescompetitive performance compared to existing SFMs while being up to 8 timesfaster. All artifacts, including code, datasets, and models, are released underOS-compliant licenses, promoting openness in speech technology research.</description>
      <author>example@mail.com (Sara Papi, Marco Gaido, Luisa Bentivogli, Alessio Brutti, Mauro Cettolo, Roberto Gretter, Marco Matassoni, Mohamed Nabih, Matteo Negri)</author>
      <guid isPermaLink="false">2505.22759v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Sparse2DGS: Sparse-View Surface Reconstruction using 2D Gaussian Splatting with Dense Point Cloud</title>
      <link>http://arxiv.org/abs/2505.19854v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICIP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Gaussian Splatting（GS）是一种快速有效的视图合成方法，在3D重建中应用广泛。然而，当输入图像数量有限时，重建精度会显著下降。为了解决这个问题，提出了一个新的3D重建方法Sparse2DGS，它使用少量图像进行重建。&lt;h4&gt;背景&lt;/h4&gt;GS方法在3D重建中的应用，以及当输入图像数量有限时，重建精度下降的问题。&lt;h4&gt;目的&lt;/h4&gt;提高使用有限数量图像进行3D重建的精度。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的3D重建方法Sparse2DGS，它结合了DUSt3R和COLMAP MVS来生成高精度和密集的3D点云，用于初始化2D高斯。&lt;h4&gt;主要发现&lt;/h4&gt;Sparse2DGS可以准确重建物体的3D形状，只需使用三张图像。&lt;h4&gt;结论&lt;/h4&gt;Sparse2DGS是一个有效的3D重建方法，特别适合于只有少量输入图像的情况。&lt;h4&gt;翻译&lt;/h4&gt;Gaussian Splatting（GS）作为一种快速有效的视图合成技术，在3D重建领域受到了关注。它已应用于基于多视图图像的3D重建，并实现了快速精确的重建。然而，GS方法假定输入包含大量多视图图像，因此当仅提供有限数量的输入图像时，重建精度会显著降低。其中一个主要原因是通过运动结构（SfM）获得的稀疏点云中的3D点数不足，这导致了优化高斯原语时的初始条件不佳。我们提出了一种新的3D重建方法，称为Sparse2DGS，以增强仅使用三张图像进行对象重建的2DGS。Sparse2DGS采用DUSt3R，这是一个用于立体图像的基本模型，以及COLMAP MVS来生成高度精确和密集的3D点云，然后使用这些点云来初始化2D高斯。通过在DTU数据集上的实验，我们表明Sparse2DGS可以使用仅三张图像准确重建物体的3D形状。该项目的页面可在https://gsisaoki.github.io/SPARSE2DGS/上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gaussian Splatting (GS) has gained attention as a fast and effective methodfor novel view synthesis. It has also been applied to 3D reconstruction usingmulti-view images and can achieve fast and accurate 3D reconstruction. However,GS assumes that the input contains a large number of multi-view images, andtherefore, the reconstruction accuracy significantly decreases when only alimited number of input images are available. One of the main reasons is theinsufficient number of 3D points in the sparse point cloud obtained throughStructure from Motion (SfM), which results in a poor initialization foroptimizing the Gaussian primitives. We propose a new 3D reconstruction method,called Sparse2DGS, to enhance 2DGS in reconstructing objects using only threeimages. Sparse2DGS employs DUSt3R, a fundamental model for stereo images, alongwith COLMAP MVS to generate highly accurate and dense 3D point clouds, whichare then used to initialize 2D Gaussians. Through experiments on the DTUdataset, we show that Sparse2DGS can accurately reconstruct the 3D shapes ofobjects using just three images. The project page is available athttps://gsisaoki.github.io/SPARSE2DGS/</description>
      <author>example@mail.com (Natsuki Takama, Shintaro Ito, Koichi Ito, Hwann-Tzong Chen, Takafumi Aoki)</author>
      <guid isPermaLink="false">2505.19854v2</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>HiDream-I1: A High-Efficient Image Generative Foundation Model with Sparse Diffusion Transformer</title>
      <link>http://arxiv.org/abs/2505.22705v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Source codes and models are available at  https://github.com/HiDream-ai/HiDream-I1 and  https://github.com/HiDream-ai/HiDream-E1&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为HiDream-I1的新开源图像生成基础模型，该模型在保持高质量图像生成的同时，降低了计算复杂性和推理延迟。&lt;h4&gt;背景&lt;/h4&gt;近年来，图像生成模型在提高质量方面取得了进展，但往往以增加计算复杂性和推理延迟为代价。&lt;h4&gt;目的&lt;/h4&gt;为了解决这种关键权衡，提出了HiDream-I1模型，旨在在保证图像质量的同时降低计算成本。&lt;h4&gt;方法&lt;/h4&gt;HiDream-I1采用了新的稀疏扩散Transformer（DiT）结构，包括双流解耦设计，以及动态的混合专家（MoE）架构。此外，还提供了三种变体：HiDream-I1-Full、HiDream-I1-Dev和HiDream-I1-Fast，以支持不同的模型能力。同时，还开发了基于指令的图像编辑模型HiDream-E1，并将其与文本到图像生成结合，形成了一个综合的图像代理HiDream-A1。&lt;h4&gt;主要发现&lt;/h4&gt;HiDream-I1在几秒钟内实现了最先进的图像生成质量，并且通过开源代码和模型权重，加速了多模态AIGC研究。&lt;h4&gt;结论&lt;/h4&gt;HiDream-I1模型在保持图像质量的同时，有效降低了计算成本，并提供了基于指令的图像编辑功能，为图像生成和编辑领域带来了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Recent advancements in image generative foundation models have prioritized quality improvements but often at the cost of increased computational complexity and inference latency. To address this critical trade-off, we introduce HiDream-I1, a new open-source image generative foundation model with 17B parameters that achieves state-of-the-art image generation quality within seconds. HiDream-I1 is constructed with a new sparse Diffusion Transformer (DiT) structure. Specifically, it starts with a dual-stream decoupled design of sparse DiT with dynamic Mixture-of-Experts (MoE) architecture, in which two separate encoders are first involved to independently process image and text tokens. Then, a single-stream sparse DiT structure with dynamic MoE architecture is adopted to trigger multi-model interaction for image generation in a cost-efficient manner. To support flexible accessibility with varied model capabilities, we provide HiDream-I1 in three variants: HiDream-I1-Full, HiDream-I1-Dev, and HiDream-I1-Fast. Furthermore, we go beyond the typical text-to-image generation and remould HiDream-I1 with additional image conditions to perform precise, instruction-based editing on given images, yielding a new instruction-based image editing model namely HiDream-E1. Ultimately, by integrating text-to-image generation and instruction-based image editing, HiDream-I1 evolves to form a comprehensive image agent (HiDream-A1) capable of fully interactive image creation and refinement. To accelerate multi-modal AIGC research, we have open-sourced all the codes and model weights of HiDream-I1-Full, HiDream-I1-Dev, HiDream-I1-Fast, HiDream-E1 through our project websites: https://github.com/HiDream-ai/HiDream-I1 and https://github.com/HiDream-ai/HiDream-E1. All features can be directly experienced via https://vivago.ai/studio.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in image generative foundation models have prioritizedquality improvements but often at the cost of increased computationalcomplexity and inference latency. To address this critical trade-off, weintroduce HiDream-I1, a new open-source image generative foundation model with17B parameters that achieves state-of-the-art image generation quality withinseconds. HiDream-I1 is constructed with a new sparse Diffusion Transformer(DiT) structure. Specifically, it starts with a dual-stream decoupled design ofsparse DiT with dynamic Mixture-of-Experts (MoE) architecture, in which twoseparate encoders are first involved to independently process image and texttokens. Then, a single-stream sparse DiT structure with dynamic MoEarchitecture is adopted to trigger multi-model interaction for image generationin a cost-efficient manner. To support flexiable accessibility with variedmodel capabilities, we provide HiDream-I1 in three variants: HiDream-I1-Full,HiDream-I1-Dev, and HiDream-I1-Fast.  Furthermore, we go beyond the typical text-to-image generation and remouldHiDream-I1 with additional image conditions to perform precise,instruction-based editing on given images, yielding a new instruction-basedimage editing model namely HiDream-E1. Ultimately, by integrating text-to-imagegeneration and instruction-based image editing, HiDream-I1 evolves to form acomprehensive image agent (HiDream-A1) capable of fully interactive imagecreation and refinement. To accelerate multi-modal AIGC research, we haveopen-sourced all the codes and model weights of HiDream-I1-Full,HiDream-I1-Dev, HiDream-I1-Fast, HiDream-E1 through our project websites:https://github.com/HiDream-ai/HiDream-I1 andhttps://github.com/HiDream-ai/HiDream-E1. All features can be directlyexperienced via https://vivago.ai/studio.</description>
      <author>example@mail.com (Qi Cai, Jingwen Chen, Yang Chen, Yehao Li, Fuchen Long, Yingwei Pan, Zhaofan Qiu, Yiheng Zhang, Fengbin Gao, Peihan Xu, Yimeng Wang, Kai Yu, Wenxuan Chen, Ziwei Feng, Zijian Gong, Jianzhuang Pan, Yi Peng, Rui Tian, Siyu Wang, Bo Zhao, Ting Yao, Tao Mei)</author>
      <guid isPermaLink="false">2505.22705v1</guid>
      <pubDate>Fri, 30 May 2025 14:26:18 +0800</pubDate>
    </item>
    <item>
      <title>Understanding (Un)Reliability of Steering Vectors in Language Models</title>
      <link>http://arxiv.org/abs/2505.22637v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 10 figures. Presented at the ICLR 2025 Workshop on  Foundation Models in the Wild&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了提示类型和激活差异的几何形状对Steering向量的可靠性影响。&lt;h4&gt;背景&lt;/h4&gt;Steering向量是一种通过在推理时添加学习偏差来轻量级控制语言模型行为的策略，尽管表现有潜力，但可能存在不可靠或反效果的问题。&lt;h4&gt;目的&lt;/h4&gt;探究提示类型和激活差异几何对Steering向量可靠性的影响。&lt;h4&gt;方法&lt;/h4&gt;通过实验分析不同提示类型产生的Steering效果，以及激活差异的余弦相似度和激活分离度对Steering的影响。&lt;h4&gt;主要发现&lt;/h4&gt;1. 所有七种提示类型都产生正向的Steering效果，但样本间方差高，常产生与预期相反的效果。2. 提示类型之间没有明显的优劣。3. 高余弦相似度的激活差异预示更有效的Steering。4. 正负激活分离度更好的数据集更易于Steering。&lt;h4&gt;结论&lt;/h4&gt;当目标行为不能由一个连贯的方向表示时，向量Steering是不可靠的。&lt;h4&gt;翻译&lt;/h4&gt;Steering vectors are a lightweight method to control language model behavior by adding a learned bias to the activations at inference time. Although steering demonstrates promising performance, recent work shows that it can be unreliable or even counterproductive in some cases. This paper studies the influence of prompt types and the geometry of activation differences on steering reliability. First, we find that all seven prompt types used in our experiments produce a net positive steering effect, but exhibit high variance across samples, and often give an effect opposite of the desired one. No prompt type clearly outperforms the others, and yet the steering vectors resulting from the different prompt types often differ directionally (as measured by cosine similarity). Second, we show that higher cosine similarity between training set activation differences predicts more effective steering. Finally, we observe that datasets where positive and negative activations are better separated are more steerable. Our results suggest that vector steering is unreliable when the target behavior is not represented by a coherent direction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Steering vectors are a lightweight method to control language model behaviorby adding a learned bias to the activations at inference time. Althoughsteering demonstrates promising performance, recent work shows that it can beunreliable or even counterproductive in some cases. This paper studies theinfluence of prompt types and the geometry of activation differences onsteering reliability. First, we find that all seven prompt types used in ourexperiments produce a net positive steering effect, but exhibit high varianceacross samples, and often give an effect opposite of the desired one. No prompttype clearly outperforms the others, and yet the steering vectors resultingfrom the different prompt types often differ directionally (as measured bycosine similarity). Second, we show that higher cosine similarity betweentraining set activation differences predicts more effective steering. Finally,we observe that datasets where positive and negative activations are betterseparated are more steerable. Our results suggest that vector steering isunreliable when the target behavior is not represented by a coherent direction.</description>
      <author>example@mail.com (Joschka Braun, Carsten Eickhoff, David Krueger, Seyed Ali Bahrainian, Dmitrii Krasheninnikov)</author>
      <guid isPermaLink="false">2505.22637v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
  <item>
      <title>On Geometry-Enhanced Parameter-Efficient Fine-Tuning for 3D Scene Segmentation</title>
      <link>http://arxiv.org/abs/2505.22444v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Geometric Encoding Mixer（GEM）的参数高效的微调（PEFT）方法，旨在提高大规模预训练点云模型的3D场景理解能力。GEM通过轻量级的潜在注意力机制和细粒度的局部位置编码，有效地捕捉了全局上下文，从而在减少计算和存储成本的同时，提高了模型的性能。&lt;h4&gt;背景&lt;/h4&gt;大规模预训练点云模型在3D场景理解方面取得了显著进展，但将这些模型应用于特定下游任务通常需要完全微调，导致高昂的计算和存储成本。现有的PEFT技术在自然语言处理和2D视觉任务中表现良好，但直接应用于3D点云模型时效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种适用于3D点云模型的PEFT方法，以降低计算和存储成本，同时保持或提高模型的性能。&lt;h4&gt;方法&lt;/h4&gt;GEM是一种几何感知的PEFT模块，它将细粒度的局部位置编码与轻量级的潜在注意力机制结合，以捕捉3D模型中的空间和几何上下文。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，GEM在性能上与完全微调相当，甚至有所超越，而只需更新模型参数的1.6%，低于其他PEFT方法。这种方法显著降低了训练时间和内存需求。&lt;h4&gt;结论&lt;/h4&gt;GEM为大规模3D点云模型的参数高效、可扩展和几何感知的微调设置了一个新的基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of large-scale pre-trained point cloud models has significantlyadvanced 3D scene understanding, but adapting these models to specificdownstream tasks typically demands full fine-tuning, incurring highcomputational and storage costs. Parameter-efficient fine-tuning (PEFT)techniques, successful in natural language processing and 2D vision tasks,would underperform when naively applied to 3D point cloud models due tosignificant geometric and spatial distribution shifts. Existing PEFT methodscommonly treat points as orderless tokens, neglecting important local spatialstructures and global geometric contexts in 3D modeling. To bridge this gap, weintroduce the Geometric Encoding Mixer (GEM), a novel geometry-aware PEFTmodule specifically designed for 3D point cloud transformers. GEM explicitlyintegrates fine-grained local positional encodings with a lightweight latentattention mechanism to capture comprehensive global context, therebyeffectively addressing the spatial and geometric distribution mismatch.Extensive experiments demonstrate that GEM achieves performance comparable toor sometimes even exceeding full fine-tuning, while only updating 1.6% of themodel's parameters, fewer than other PEFT methods. With significantly reducedtraining time and memory requirements, our approach thus sets a new benchmarkfor efficient, scalable, and geometry-aware fine-tuning of large-scale 3D pointcloud models. Code will be released.</description>
      <author>example@mail.com (Liyao Tang, Zhe Chen, Dacheng Tao)</author>
      <guid isPermaLink="false">2505.22444v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Single Domain Generalization for Alzheimer's Detection from 3D MRIs with Pseudo-Morphological Augmentations and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2505.22465v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对阿尔茨海默病MRI检测中存在的类别不平衡、协议变异和数据集多样性有限等问题，提出了一个针对单一领域泛化设置的方法，以提高模型在不同分布的未知领域上的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管深度学习模型在阿尔茨海默病MRI检测方面取得了显著进展，但仍然面临一些挑战，如类别不平衡、协议变异和数据集多样性有限等问题，这些因素限制了模型泛化能力。&lt;h4&gt;目的&lt;/h4&gt;通过设计并开发一个针对一个领域的数据，在具有不同分布的未知领域上实现最大性能的模型，以解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;本文提出使用可学习的伪形态学模块，旨在产生形状感知、解剖上有意义的类别特定增强，并结合监督对比学习模块来提取鲁棒的类别特定表示。&lt;h4&gt;主要发现&lt;/h4&gt;在三个数据集上进行的实验表明，该方法在类别不平衡和成像协议变异的情况下提高了性能和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法能够有效提高阿尔茨海默病MRI检测模型的性能和泛化能力，实验结果支持了该方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;尽管通过现代深度学习模型在MRI检测阿尔茨海默病方面取得了显著进展，但类别不平衡、协议变化和数据集多样性有限等问题通常阻碍了它们的泛化能力。为了解决这个问题，本文关注单一领域泛化设置，即给定一个领域的数据，设计并开发一个模型，使其在具有不同分布的未观察领域上具有最大性能。由于大脑形态在阿尔茨海默病诊断中起着至关重要的作用，我们提出了使用可学习的伪形态学模块，旨在产生形状感知、解剖上有意义的类别特定增强，并结合监督对比学习模块来提取鲁棒的类别特定表示。在三个数据集上进行的实验表明，在类别不平衡和成像协议变化的情况下，该方法提高了性能和泛化能力。源代码将在接受后通过https://github.com/zobia111/SDG-Alzheimer提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although Alzheimer's disease detection via MRIs has advanced significantlythanks to contemporary deep learning models, challenges such as classimbalance, protocol variations, and limited dataset diversity often hindertheir generalization capacity. To address this issue, this article focuses onthe single domain generalization setting, where given the data of one domain, amodel is designed and developed with maximal performance w.r.t. an unseendomain of distinct distribution. Since brain morphology is known to play acrucial role in Alzheimer's diagnosis, we propose the use of learnablepseudo-morphological modules aimed at producing shape-aware, anatomicallymeaningful class-specific augmentations in combination with a supervisedcontrastive learning module to extract robust class-specific representations.Experiments conducted across three datasets show improved performance andgeneralization capacity, especially under class imbalance and imaging protocolvariations. The source code will be made available upon acceptance athttps://github.com/zobia111/SDG-Alzheimer.</description>
      <author>example@mail.com (Zobia Batool, Huseyin Ozkan, Erchan Aptoula)</author>
      <guid isPermaLink="false">2505.22465v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Pre-training for Recommendation Unlearning</title>
      <link>http://arxiv.org/abs/2505.22649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to SIGIR 2025 Oral&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为UnlearnRec的新型模型无关预训练范式，用于解决推荐系统在选择性遗忘训练数据时的挑战。&lt;h4&gt;背景&lt;/h4&gt;现代基于图神经网络（GNNs）的推荐系统在建模用户-物品交互方面表现出色，但面临需要选择性遗忘训练数据的场景。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，使推荐系统能够有效地从模型中消除特定用户数据的影响，以解决隐私问题、偏好变化或监管框架的要求。&lt;h4&gt;方法&lt;/h4&gt;UnlearnRec通过一个影响编码器直接从未学习请求和现有模型参数中生成未学习模型的更新参数，实现模型的无需完全重新训练。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在公共基准数据集上的评估显示，与重新训练方法相比，提供了超过10倍的速度提升，同时保持了模型性能特征。&lt;h4&gt;结论&lt;/h4&gt;UnlearnRec方法在选择性遗忘训练数据方面表现出色，为推荐系统提供了一种高效且性能良好的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3726302.3730060&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern recommender systems powered by Graph Neural Networks (GNNs) excel atmodeling complex user-item interactions, yet increasingly face scenariosrequiring selective forgetting of training data. Beyond user requests to removespecific interactions due to privacy concerns or preference changes, regulatoryframeworks mandate recommender systems' ability to eliminate the influence ofcertain user data from models. This recommendation unlearning challengepresents unique difficulties as removing connections within interaction graphscreates ripple effects throughout the model, potentially impactingrecommendations for numerous users. Traditional approaches suffer fromsignificant drawbacks: fragmentation methods damage graph structure anddiminish performance, while influence function techniques make assumptions thatmay not hold in complex GNNs, particularly with self-supervised or randomarchitectures. To address these limitations, we propose a novel model-agnosticpre-training paradigm UnlearnRec that prepares systems for efficient unlearningoperations. Our Influence Encoder takes unlearning requests together withexisting model parameters and directly produces updated parameters of unlearnedmodel with little fine-tuning, avoiding complete retraining while preservingmodel performance characteristics. Extensive evaluation on public benchmarksdemonstrates that our method delivers exceptional unlearning effectivenesswhile providing more than 10x speedup compared to retraining approaches. Werelease our method implementation at: https://github.com/HKUDS/UnlearnRec.</description>
      <author>example@mail.com (Guoxuan Chen, Lianghao Xia, Chao Huang)</author>
      <guid isPermaLink="false">2505.22649v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Let's Predict Sentence by Sentence</title>
      <link>http://arxiv.org/abs/2505.22202v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Work In Progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了预训练语言模型是否能够通过构建在它们学习到的表示之上，提升到抽象的语义单元推理空间，而不是原始的标记序列。&lt;h4&gt;背景&lt;/h4&gt;自回归语言模型（LMs）一次生成一个标记，而人类的推理操作在句子、命题和概念等高级抽象上。这种对比引发了核心问题：LMs是否能够像人类一样推理结构化的语义单元。&lt;h4&gt;目的&lt;/h4&gt;探究预训练的LMs是否能够通过其学习到的表示，被提升到抽象推理空间。&lt;h4&gt;方法&lt;/h4&gt;提出了一种框架，该框架通过自回归地预测连续的句子嵌入来适应预训练的标记级LM在句子空间中的操作。探索了两种受经典表示学习启发的嵌入范式：1）语义嵌入，通过自编码来保留表面意义；2）上下文嵌入，通过下一句预测来编码期待结构。在离散和连续两种推理机制下进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;在数学、逻辑、常识和规划四个领域，连续推理下的上下文嵌入在性能上与思维链（CoT）相当，同时平均减少了推理时间的FLOPs一半。还展示了可扩展性和模块化适应的早期迹象。引入了SentenceLens，一种诊断工具，可以将中间模型状态解码为可解释的句子。&lt;h4&gt;结论&lt;/h4&gt;预训练的LMs可以有效地过渡到潜在嵌入空间中的抽象、结构化推理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autoregressive language models (LMs) generate one token at a time, yet humanreasoning operates over higher-level abstractions - sentences, propositions,and concepts. This contrast raises a central question- Can LMs likewise learnto reason over structured semantic units rather than raw token sequences? Inthis work, we investigate whether pretrained LMs can be lifted into suchabstract reasoning spaces by building on their learned representations. Wepresent a framework that adapts a pretrained token-level LM to operate insentence space by autoregressively predicting continuous embeddings of nextsentences. We explore two embedding paradigms inspired by classicalrepresentation learning: 1) semantic embeddings, learned via autoencoding topreserve surface meaning; and 2) contextual embeddings, trained vianext-sentence prediction to encode anticipatory structure. We evaluate bothunder two inference regimes: Discretized, which decodes each predictedembedding into text before re-encoding; and Continuous, which reasons entirelyin embedding space for improved efficiency. Across four domains - mathematics,logic, commonsense, and planning - contextual embeddings under continuousinference show competitive performance with Chain-of-Thought (CoT) whilereducing inference-time FLOPs on average by half. We also present early signsof scalability and modular adaptation. Finally, to visualize latenttrajectories, we introduce SentenceLens, a diagnostic tool that decodesintermediate model states into interpretable sentences. Together, our resultsindicate that pretrained LMs can effectively transition to abstract, structuredreasoning within latent embedding spaces.</description>
      <author>example@mail.com (Hyeonbin Hwang, Byeongguk Jeon, Seungone Kim, Jiyeon Kim, Hoyeon Chang, Sohee Yang, Seungpil Won, Dohaeng Lee, Youbin Ahn, Minjoon Seo)</author>
      <guid isPermaLink="false">2505.22202v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>NFR: Neural Feature-Guided Non-Rigid Shape Registration</title>
      <link>http://arxiv.org/abs/2505.22445v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 9 figures. arXiv admin note: substantial text overlap with  arXiv:2311.04494&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于学习的新框架，用于3D形状配准，克服了输入形状中显著的非刚性变形和部分性的挑战，并且在训练过程中无需对应标注。&lt;h4&gt;背景&lt;/h4&gt;3D形状配准中存在显著的非刚性变形和形状的部分性，传统方法难以处理。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的学习方法，以解决3D形状配准中的非刚性变形和部分性问题。&lt;h4&gt;方法&lt;/h4&gt;将深度学习形状匹配网络学习到的神经特征整合到迭代几何形状配准流程中，通过神经特征提供更准确和语义上有意义的对应估计，并根据中间配准动态更新对应关系，并通过一致性先验进行过滤。&lt;h4&gt;主要发现&lt;/h4&gt;神经特征比空间特征（如坐标）提供更准确和语义上有意义的对应估计，有助于处理大非刚性变形；动态更新和一致性先验过滤增强了整体流程的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;在有限的训练形状和少量训练样本的情况下，该方法在多个非刚性点云匹配和部分形状匹配基准测试中实现了最先进的性能，并且在处理经历显著外部和内部变形的未见形状对时，也提供了高质量的对应关系。&lt;h4&gt;翻译&lt;/h4&gt;在本文中，我们提出了一种新的基于学习的方法用于3D形状配准，该方法克服了输入形状中显著的非刚性变形和部分性的挑战，并且在训练过程中不需要对应标注。我们的关键洞察是将深度学习形状匹配网络学习的神经特征结合到一个迭代的几何形状配准流程中。我们方法的优势在于两个方面——一方面，神经特征提供了比空间特征（例如坐标）更准确和语义上有意义的对应估计，这在存在大非刚性变形的情况下至关重要；另一方面，对应关系根据中间配准动态更新，并通过一致性先验进行过滤，这显著增强了整体流程的鲁棒性。实证结果表明，在只有几十个有限变异性训练形状的情况下，我们的流程在多个非刚性点云匹配和部分形状匹配的基准测试中实现了最先进的性能，同时也在处理经历显著外部和内部变形的未见形状对时提供了高质量的对应关系，在这种情况下，传统配准方法和内在方法都无效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel learning-based framework for 3D shaperegistration, which overcomes the challenges of significant non-rigiddeformation and partiality undergoing among input shapes, and, remarkably,requires no correspondence annotation during training. Our key insight is toincorporate neural features learned by deep learning-based shape matchingnetworks into an iterative, geometric shape registration pipeline. Theadvantage of our approach is two-fold -- On one hand, neural features providemore accurate and semantically meaningful correspondence estimation thanspatial features (e.g., coordinates), which is critical in the presence oflarge non-rigid deformations; On the other hand, the correspondences aredynamically updated according to the intermediate registrations and filtered byconsistency prior, which prominently robustify the overall pipeline. Empiricalresults show that, with as few as dozens of training shapes of limitedvariability, our pipeline achieves state-of-the-art results on severalbenchmarks of non-rigid point cloud matching and partial shape matching acrossvarying settings, but also delivers high-quality correspondences between unseenchallenging shape pairs that undergo both significant extrinsic and intrinsicdeformations, in which case neither traditional registration methods norintrinsic methods work.</description>
      <author>example@mail.com (Puhua Jiang, Zhangquan Chen, Mingze Sun, Ruqi Huang)</author>
      <guid isPermaLink="false">2505.22445v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Autoregression-free video prediction using diffusion model for mitigating error propagation</title>
      <link>http://arxiv.org/abs/2505.22111v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散模型的AutoRegression-Free（ARFree）视频预测框架，旨在解决现有长视频预测方法中误差传播的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的长视频预测方法通常依赖于自回归视频预测机制，但这种机制在预测未来帧时容易产生误差传播，尤其是在较远的未来帧。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述局限性，本文提出了ARFree视频预测框架。&lt;h4&gt;方法&lt;/h4&gt;ARFree框架包括两个关键组件：1）一个运动预测模块，该模块使用从上下文帧元组中提取的运动特征来预测未来的运动；2）一个训练方法，该方法提高了相邻未来帧元组之间的运动连续性和上下文一致性。&lt;h4&gt;主要发现&lt;/h4&gt;在两个基准数据集上的实验表明，提出的ARFree视频预测框架优于几种最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;ARFree视频预测框架能够有效提高视频预测的准确性，减少误差传播问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing long-term video prediction methods often rely on an autoregressivevideo prediction mechanism. However, this approach suffers from errorpropagation, particularly in distant future frames. To address this limitation,this paper proposes the first AutoRegression-Free (ARFree) video predictionframework using diffusion models. Different from an autoregressive videoprediction mechanism, ARFree directly predicts any future frame tuples from thecontext frame tuple. The proposed ARFree consists of two key components: 1) amotion prediction module that predicts a future motion using motion featureextracted from the context frame tuple; 2) a training method that improvesmotion continuity and contextual consistency between adjacent future frametuples. Our experiments with two benchmark datasets show that the proposedARFree video prediction framework outperforms several state-of-the-art videoprediction methods.</description>
      <author>example@mail.com (Woonho Ko, Jin Bok Park, Il Yong Chun)</author>
      <guid isPermaLink="false">2505.22111v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>The Meeseeks Mesh: Spatially Consistent 3D Adversarial Objects for BEV Detector</title>
      <link>http://arxiv.org/abs/2505.22499v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了3D物体检测在自动驾驶系统中的关键作用，提出了针对3D对抗攻击的防御方法，以提高检测模型的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;3D物体检测是自动驾驶系统的核心组件，能够在不同环境下实时识别车辆、行人和障碍物。&lt;h4&gt;目的&lt;/h4&gt;研究3D物体检测模型对3D对抗攻击的脆弱性，以评估模型在受到扰动时的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;生成针对现实场景的不可侵入性3D对抗物体，并使用可微渲染技术来准确模拟对抗物体与目标车辆之间的空间关系。引入遮挡感知模块以增强不同视角下的视觉一致性和真实性。设计基于BEV空间特征的优化策略以维持攻击效果。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法可以有效抑制最先进的3D物体检测器的车辆预测，是一种测试3D物体检测模型鲁棒性的重要工具。&lt;h4&gt;结论&lt;/h4&gt;生成的对抗物体具有强大的泛化能力，在不同位置和距离的场景中均保持其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D object detection is a critical component in autonomous driving systems. Itallows real-time recognition and detection of vehicles, pedestrians andobstacles under varying environmental conditions. Among existing methods, 3Dobject detection in the Bird's Eye View (BEV) has emerged as the mainstreamframework. To guarantee a safe, robust and trustworthy 3D object detection, 3Dadversarial attacks are investigated, where attacks are placed in 3Denvironments to evaluate the model performance, e.g., putting a film on a car,clothing a pedestrian. The vulnerability of 3D object detection models to 3Dadversarial attacks serves as an important indicator to evaluate the robustnessof the model against perturbations. To investigate this vulnerability, wegenerate non-invasive 3D adversarial objects tailored for real-world attackscenarios. Our method verifies the existence of universal adversarial objectsthat are spatially consistent across time and camera views. Specifically, weemploy differentiable rendering techniques to accurately model the spatialrelationship between adversarial objects and the target vehicle. Furthermore,we introduce an occlusion-aware module to enhance visual consistency andrealism under different viewpoints. To maintain attack effectiveness acrossmultiple frames, we design a BEV spatial feature-guided optimization strategy.Experimental results demonstrate that our approach can reliably suppressvehicle predictions from state-of-the-art 3D object detectors, serving as animportant tool to test robustness of 3D object detection models beforedeployment. Moreover, the generated adversarial objects exhibit stronggeneralization capabilities, retaining its effectiveness at various positionsand distances in the scene.</description>
      <author>example@mail.com (Aixuan Li, Mochu Xiang, Jing Zhang, Yuchao Dai)</author>
      <guid isPermaLink="false">2505.22499v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Geometric GNNs for Charged Particle Tracking at GlueX</title>
      <link>http://arxiv.org/abs/2505.22504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用图神经网络（GNN）进行核物理实验中粒子轨迹追踪的方法，评估了其在GlueX实验数据上的性能，并与传统方法进行了比较。&lt;h4&gt;背景&lt;/h4&gt;核物理实验通过高能碰撞来揭示物质的基本构建块。这些实验产生复杂的粒子轨迹，追踪带电粒子在强磁场中的轨迹对于重建粒子轨迹和精确确定相互作用至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用图神经网络在GlueX实验中实现高效的粒子轨迹追踪。&lt;h4&gt;方法&lt;/h4&gt;使用模拟数据训练GNN模型，并在模拟和真实的GlueX测量数据上测试模型。通过批量处理多个事件来提高处理速度，并利用图形处理单元（GPU）的并行计算能力。&lt;h4&gt;主要发现&lt;/h4&gt;基于GNN的轨迹追踪在固定纯度下，段级效率优于目前GlueX使用的传统方法，同时提供了更快的推理速度。GNN模型通过批量处理事件实现显著加速，利用了GPU的并行计算能力。&lt;h4&gt;结论&lt;/h4&gt;GNN在核物理实验中的粒子轨迹追踪方面显示出优于传统方法的性能，特别是在处理速度和效率上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nuclear physics experiments are aimed at uncovering the fundamental buildingblocks of matter. The experiments involve high-energy collisions that producecomplex events with many particle trajectories. Tracking charged particlesresulting from collisions in the presence of a strong magnetic field iscritical to enable the reconstruction of particle trajectories and precisedetermination of interactions. It is traditionally achieved throughcombinatorial approaches that scale worse than linearly as the number of hitsgrows. Since particle hit data naturally form a 3-dimensional point cloud andcan be structured as graphs, Graph Neural Networks (GNNs) emerge as anintuitive and effective choice for this task. In this study, we evaluate theGNN model for track finding on the data from the GlueX experiment at JeffersonLab. We use simulation data to train the model and test on both simulation andreal GlueX measurements. We demonstrate that GNN-based track findingoutperforms the currently used traditional method at GlueX in terms ofsegment-based efficiency at a fixed purity while providing faster inferences.We show that the GNN model can achieve significant speedup by processingmultiple events in batches, which exploits the parallel computation capabilityof Graphical Processing Units (GPUs). Finally, we compare the GNNimplementation on GPU and FPGA and describe the trade-off.</description>
      <author>example@mail.com (Ahmed Hossam Mohammed, Kishansingh Rajput, Simon Taylor, Denis Furletov, Sergey Furletov, Malachi Schram)</author>
      <guid isPermaLink="false">2505.22504v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Principled Out-of-Distribution Generalization via Simplicity</title>
      <link>http://arxiv.org/abs/2505.22622v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了现代基础模型在分布外（OOD）泛化方面的表现，并探讨了这一现象背后的理论原理。通过分析扩散模型在图像生成中的组合泛化能力，发现尽管神经网络架构能够表达多种模型，但符合人类期望的通用模型通常是训练数据中最简单的。&lt;h4&gt;背景&lt;/h4&gt;现代基础模型展现出卓越的分布外泛化能力，能够解决远超出其训练数据支持的任务，但其背后的理论原理尚不明确。&lt;h4&gt;目的&lt;/h4&gt;研究分布外泛化的理论框架，并通过简单性来量化这一框架。&lt;h4&gt;方法&lt;/h4&gt;开发了基于简单性的理论框架，并使用预定义的简单性指标进行分析。研究了两个关键场景：恒定间隙设置和消失间隙设置，并研究了正则化最大似然估计器，为学习真实、通用、简单的模型提供了样本复杂度保证。&lt;h4&gt;主要发现&lt;/h4&gt;发现神经网络架构足以表达多种模型，但符合人类期望的通用模型通常是训练数据中最简单的。&lt;h4&gt;结论&lt;/h4&gt;提出了基于简单性的理论框架，并建立了学习真实、通用、简单模型的样本复杂度保证。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the out-of-distribution (OOD) generalization of modern foundation models, and explores the theoretical principles underlying this phenomenon. By examining the compositional generalization abilities of diffusion models in image generation, it is found that while neural network architectures are expressive enough to represent a wide range of models, including many with undesirable behavior on OOD inputs, the truly generalizable model that aligns with human expectations typically corresponds to the simplest among those consistent with the training data. Motivated by this observation, a theoretical framework for OOD generalization via simplicity is developed, quantified using a predefined simplicity metric. Two key regimes are analyzed: (1) the constant-gap setting, where the true model is strictly simpler than all spurious alternatives by a fixed gap, and (2) the vanishing-gap setting, where the fixed gap is replaced by a smoothness condition ensuring that models close in simplicity to the true model yield similar predictions. For both regimes, the regularized maximum likelihood estimator is studied, and the first sharp sample complexity guarantees for learning the true, generalizable, simple model are established.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern foundation models exhibit remarkable out-of-distribution (OOD)generalization, solving tasks far beyond the support of their training data.However, the theoretical principles underpinning this phenomenon remainelusive. This paper investigates this problem by examining the compositionalgeneralization abilities of diffusion models in image generation. Our analysisreveals that while neural network architectures are expressive enough torepresent a wide range of models -- including many with undesirable behavior onOOD inputs -- the true, generalizable model that aligns with human expectationstypically corresponds to the simplest among those consistent with the trainingdata.  Motivated by this observation, we develop a theoretical framework for OODgeneralization via simplicity, quantified using a predefined simplicity metric.We analyze two key regimes: (1) the constant-gap setting, where the true modelis strictly simpler than all spurious alternatives by a fixed gap, and (2) thevanishing-gap setting, where the fixed gap is replaced by a smoothnesscondition ensuring that models close in simplicity to the true model yieldsimilar predictions. For both regimes, we study the regularized maximumlikelihood estimator and establish the first sharp sample complexity guaranteesfor learning the true, generalizable, simple model.</description>
      <author>example@mail.com (Jiawei Ge, Amanda Wang, Shange Tang, Chi Jin)</author>
      <guid isPermaLink="false">2505.22622v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Maximizing Confidence Alone Improves Reasoning</title>
      <link>http://arxiv.org/abs/2505.22660v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为RENT的基于熵最小化的强化学习方法，该方法不需要外部奖励或真实答案，而是使用模型底层分布的熵作为内在奖励。&lt;h4&gt;背景&lt;/h4&gt;强化学习在多个领域取得了显著进步，但奖励函数的工程化是任何领域中的难题。&lt;h4&gt;目的&lt;/h4&gt;提出RENT方法，以解决强化学习中奖励工程化的问题。&lt;h4&gt;方法&lt;/h4&gt;RENT方法利用模型生成的答案的置信度，通过强化这些思维链来提高模型推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;在GSM8K、MATH500、AMC、AIME和GPQA等常用的推理基准测试中，RENT方法展示了模型推理能力的提升。&lt;h4&gt;结论&lt;/h4&gt;该方法适用于外部监督有限或不可用的大量领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要：强化学习（RL）使机器学习模型在许多领域取得了显著进步。最近，RL使前沿语言模型能够解决数学、科学和编码中的难题。然而，任何RL算法的核心是奖励函数，而奖励工程化在任何领域都是众所周知的难题。在本文中，我们提出了RENT：通过熵最小化的强化学习——一种完全无监督的RL方法，它不需要外部奖励或真实答案，而是使用模型底层分布的熵作为内在奖励。我们发现，通过强化产生高模型置信度的思维链，可以提高模型的推理能力。在我们的实验中，我们在GSM8K、MATH500、AMC、AIME和GPQA等广泛的常用推理基准测试中展示了这些改进，包括Qwen和Mistral家族的各种大小模型。我们无监督学习方法的一般性使其适用于外部监督有限或不可用的广泛领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement learning (RL) has enabled machine learning models to achievesignificant advances in many fields. Most recently, RL has empowered frontierlanguage models to solve challenging math, science, and coding problems.However, central to any RL algorithm is the reward function, and rewardengineering is a notoriously difficult problem in any domain. In this paper, wepropose RENT: Reinforcement Learning via Entropy Minimization -- a fullyunsupervised RL method that requires no external reward or ground-truthanswers, and instead uses the model's entropy of its underlying distribution asan intrinsic reward. We find that by reinforcing the chains of thought thatyield high model confidence on its generated answers, the model improves itsreasoning ability. In our experiments, we showcase these improvements on anextensive suite of commonly-used reasoning benchmarks, including GSM8K,MATH500, AMC, AIME, and GPQA, and models of varying sizes from the Qwen andMistral families. The generality of our unsupervised learning method lendsitself to applicability in a wide range of domains where external supervisionis limited or unavailable.</description>
      <author>example@mail.com (Mihir Prabhudesai, Lili Chen, Alex Ippoliti, Katerina Fragkiadaki, Hao Liu, Deepak Pathak)</author>
      <guid isPermaLink="false">2505.22660v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Object Concepts Emerge from Motion</title>
      <link>http://arxiv.org/abs/2505.21635v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于生物启发的方法，用于无监督地学习以物体为中心的视觉表示，并通过运动边界作为物体级别分组的信号来获取伪实例监督。&lt;h4&gt;背景&lt;/h4&gt;物体概念在人类视觉认知中起着基础性作用，通过观察运动，婴儿能够获得物体理解。&lt;h4&gt;目的&lt;/h4&gt;开发一个无需监督学习的生物启发框架，用于学习物体中心的视觉表示。&lt;h4&gt;方法&lt;/h4&gt;使用现成的光流和聚类算法生成基于运动的实例掩码，并通过对比学习训练视觉编码器。该框架完全无标签，不依赖相机标定。&lt;h4&gt;主要发现&lt;/h4&gt;运动边界是物体级别分组的一个强信号，可以用于从原始视频中推导出伪实例监督。&lt;h4&gt;结论&lt;/h4&gt;该方法在低级（单目深度估计）和高级（3D物体检测和占用预测）视觉任务中优于先前的方法，并显示出对未见场景的强大泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：物体概念在人类视觉认知中起着基础性作用，使人们能够在物理世界中感知、记忆和互动。受发育神经科学发现（婴儿通过观察运动来获得物体理解）的启发，我们提出了一种生物启发的框架，用于以无监督的方式学习以物体为中心的视觉表示。我们的关键洞察是，运动边界是物体级别分组的一个强信号，可以用来从原始视频中推导出伪实例监督。具体来说，我们使用现成的光流和聚类算法生成基于运动的实例掩码，并使用它们通过对比学习来训练视觉编码器。我们的框架完全无标签，不依赖于相机标定，这使得它能够扩展到大规模非结构化视频数据。我们在跨越低级（单目深度估计）和高级（3D物体检测和占用预测）视觉的三个下游任务上评估了我们的方法。我们的模型优于先前监督和无监督基线，并显示出对未见场景的强大泛化能力。这些结果表明，由运动引起的物体表示为现有的视觉基础模型提供了一个有吸引力的替代方案，捕捉了一个关键但被忽视的抽象层次：视觉实例。相应的代码将在论文接受后发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object concepts play a foundational role in human visual cognition, enablingperception, memory, and interaction in the physical world. Inspired by findingsin developmental neuroscience - where infants are shown to acquire objectunderstanding through observation of motion - we propose a biologicallyinspired framework for learning object-centric visual representations in anunsupervised manner. Our key insight is that motion boundary serves as a strongsignal for object-level grouping, which can be used to derive pseudo instancesupervision from raw videos. Concretely, we generate motion-based instancemasks using off-the-shelf optical flow and clustering algorithms, and use themto train visual encoders via contrastive learning. Our framework is fullylabel-free and does not rely on camera calibration, making it scalable tolarge-scale unstructured video data. We evaluate our approach on threedownstream tasks spanning both low-level (monocular depth estimation) andhigh-level (3D object detection and occupancy prediction) vision. Our modelsoutperform previous supervised and self-supervised baselines and demonstratestrong generalization to unseen scenes. These results suggest thatmotion-induced object representations offer a compelling alternative toexisting vision foundation models, capturing a crucial but overlooked level ofabstraction: the visual instance. The corresponding code will be released uponpaper acceptance.</description>
      <author>example@mail.com (Haoqian Liang, Xiaohui Wang, Zhichao Li, Ya Yang, Naiyan Wang)</author>
      <guid isPermaLink="false">2505.21635v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action Control</title>
      <link>http://arxiv.org/abs/2505.22421v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  code will be released at https://github.com/antonioo-c/GeoDrive&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了GeoDrive，这是一种将鲁棒3D几何条件集成到驾驶世界模型中的方法，以增强空间理解和动作可控性，从而提高自动驾驶的安全性。&lt;h4&gt;背景&lt;/h4&gt;世界模型在动态环境模拟方面的进步改变了自动驾驶系统，使系统能够预见未来状态和评估潜在动作。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在保持鲁棒3D几何一致性或处理遮挡时积累伪影方面的不足，以实现可靠的安全评估。&lt;h4&gt;方法&lt;/h4&gt;GeoDrive首先从输入帧中提取3D表示，然后根据用户指定的ego-car轨迹获得其2D渲染。在训练过程中，提出一个动态编辑模块来通过编辑车辆位置来增强渲染。&lt;h4&gt;主要发现&lt;/h4&gt;GeoDrive在动作准确性和3D空间意识方面显著优于现有模型，导致更真实、适应性强和可靠的场景建模，提高了自动驾驶的安全性。&lt;h4&gt;结论&lt;/h4&gt;GeoDrive可以推广到新的轨迹，并提供交互式场景编辑功能，如对象编辑和对象轨迹控制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in world models have revolutionized dynamic environmentsimulation, allowing systems to foresee future states and assess potentialactions. In autonomous driving, these capabilities help vehicles anticipate thebehavior of other road users, perform risk-aware planning, accelerate trainingin simulation, and adapt to novel scenarios, thereby enhancing safety andreliability. Current approaches exhibit deficiencies in maintaining robust 3Dgeometric consistency or accumulating artifacts during occlusion handling, bothcritical for reliable safety assessment in autonomous navigation tasks. Toaddress this, we introduce GeoDrive, which explicitly integrates robust 3Dgeometry conditions into driving world models to enhance spatial understandingand action controllability. Specifically, we first extract a 3D representationfrom the input frame and then obtain its 2D rendering based on theuser-specified ego-car trajectory. To enable dynamic modeling, we propose adynamic editing module during training to enhance the renderings by editing thepositions of the vehicles. Extensive experiments demonstrate that our methodsignificantly outperforms existing models in both action accuracy and 3Dspatial awareness, leading to more realistic, adaptable, and reliable scenemodeling for safer autonomous driving. Additionally, our model can generalizeto novel trajectories and offers interactive scene editing capabilities, suchas object editing and object trajectory control.</description>
      <author>example@mail.com (Anthony Chen, Wenzhao Zheng, Yida Wang, Xueyang Zhang, Kun Zhan, Peng Jia, Kurt Keutzer, Shangbang Zhang)</author>
      <guid isPermaLink="false">2505.22421v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>From Controlled Scenarios to Real-World: Cross-Domain Degradation Pattern Matching for All-in-One Image Restoration</title>
      <link>http://arxiv.org/abs/2505.22284v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该摘要介绍了一种名为Unified Domain-Adaptive Image Restoration (UDAIR)的图像恢复框架，旨在通过一个模型实现多种退化模式的图像恢复，并在多个公开数据集上取得了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的All-in-One Image Restoration (AiOIR)方法在封闭和受控场景中表现出色，但在真实世界场景中由于训练样本（源域）和真实测试样本（目标域）之间数据分布的差异，导致性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出UDAIR框架，利用源域学习到的知识来改善目标域的图像恢复效果。&lt;h4&gt;方法&lt;/h4&gt;1. 设计一个码本来学习表示退化模式的离散嵌入；2. 提出交叉样本对比学习机制以捕捉特定退化模式的不同样本的共享特征；3. 提出一种域适应策略来动态对齐源域和目标域的码本嵌入；4. 设计基于相关对齐的测试时自适应机制来微调对齐差异。&lt;h4&gt;主要发现&lt;/h4&gt;在10个开源数据集上的实验结果表明，UDAIR在AiOIR任务上取得了最先进的性能，且其特征聚类验证了在未知条件下的退化识别，定性的比较展示了其在真实世界场景中的鲁棒泛化能力。&lt;h4&gt;结论&lt;/h4&gt;UDAIR框架有效解决了真实世界场景中的图像恢复问题，并取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;As a fundamental imaging task, All-in-One Image Restoration (AiOIR) aims to achieve image restoration caused by multiple degradation patterns via a single model with unified parameters. Although existing AiOIR approaches obtain promising performance in closed and controlled scenarios, they still suffer from considerable performance reduction in real-world scenarios since the gap of data distributions between the training samples (source domain) and real-world test samples (target domain) can lead to inferior degradation awareness ability. To address this issue, a Unified Domain-Adaptive Image Restoration (UDAIR) framework is proposed to effectively achieve AiOIR by leveraging the learned knowledge from source domain to target domain. To improve the degradation identification, a codebook is designed to learn a group of discrete embeddings to denote the degradation patterns, and the cross-sample contrastive learning mechanism is further proposed to capture shared features from different samples of certain degradation. To bridge the data gap, a domain adaptation strategy is proposed to build the feature projection between the source and target domains by dynamically aligning their codebook embeddings, and a correlation alignment-based test-time adaptation mechanism is designed to fine-tune the alignment discrepancies by tightening the degradation embeddings to the corresponding cluster center in the source domain. Experimental results on 10 open-source datasets demonstrate that UDAIR achieves new state-of-the-art performance for the AiOIR task. Most importantly, the feature cluster validates the degradation identification under unknown conditions, and qualitative comparisons showcase robust generalization to real-world scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As a fundamental imaging task, All-in-One Image Restoration (AiOIR) aims toachieve image restoration caused by multiple degradation patterns via a singlemodel with unified parameters. Although existing AiOIR approaches obtainpromising performance in closed and controlled scenarios, they still sufferedfrom considerable performance reduction in real-world scenarios since the gapof data distributions between the training samples (source domain) andreal-world test samples (target domain) can lead inferior degradation awarenessability. To address this issue, a Unified Domain-Adaptive Image Restoration(UDAIR) framework is proposed to effectively achieve AiOIR by leveraging thelearned knowledge from source domain to target domain. To improve thedegradation identification, a codebook is designed to learn a group of discreteembeddings to denote the degradation patterns, and the cross-sample contrastivelearning mechanism is further proposed to capture shared features fromdifferent samples of certain degradation. To bridge the data gap, a domainadaptation strategy is proposed to build the feature projection between thesource and target domains by dynamically aligning their codebook embeddings,and a correlation alignment-based test-time adaptation mechanism is designed tofine-tune the alignment discrepancies by tightening the degradation embeddingsto the corresponding cluster center in the source domain. Experimental resultson 10 open-source datasets demonstrate that UDAIR achieves new state-of-the-artperformance for the AiOIR task. Most importantly, the feature cluster validatethe degradation identification under unknown conditions, and qualitativecomparisons showcase robust generalization to real-world scenarios.</description>
      <author>example@mail.com (Junyu Fan, Chuanlin Liao, Yi Lin)</author>
      <guid isPermaLink="false">2505.22284v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Effective and Efficient One-pass Compression of Speech Foundation Models Using Sparsity-aware Self-pinching Gates</title>
      <link>http://arxiv.org/abs/2505.22608v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的语音基础模型压缩方法，该方法将模型剪枝和参数更新紧密集成到单阶段中。&lt;h4&gt;背景&lt;/h4&gt;语音基础模型在压缩过程中需要同时考虑参数数量和性能损失。&lt;h4&gt;目的&lt;/h4&gt;旨在通过压缩模型参数数量，同时保持或提高模型的性能。&lt;h4&gt;方法&lt;/h4&gt;该方法采用高度紧凑的层级绑定自夹紧门控机制，每个门控仅包含一个可学习的阈值，并与未压缩模型联合训练，用于细粒度神经元级别的剪枝。&lt;h4&gt;主要发现&lt;/h4&gt;在LibriSpeech-100hr语料库上的实验表明，该方法将wav2vec2.0-base和HuBERT-large模型的参数数量分别减少了65%和60%，同时在测试-clean数据集上没有引起统计上显著的词错误率（WER）增加。&lt;h4&gt;结论&lt;/h4&gt;与之前在相同任务上发布的方法相比，该方法不仅实现了在可比的模型压缩比4.26x下的最低WER 7.05%，而且模型压缩时间至少减少了25%。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的语音基础模型压缩方法，该方法将模型剪枝和参数更新紧密集成到单阶段中。通过在LibriSpeech-100hr语料库上的实验，该方法显著减少了模型的参数数量，同时保持了性能，并在测试数据集上取得了优异的性能。与现有方法相比，该方法在压缩比和压缩时间上都有显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel approach for speech foundation models compressionthat tightly integrates model pruning and parameter update into a single stage.Highly compact layer-level tied self-pinching gates each containing only asingle learnable threshold are jointly trained with uncompressed models andused in fine-grained neuron level pruning. Experiments conducted on theLibriSpeech-100hr corpus suggest that our approach reduces the number ofparameters of wav2vec2.0-base and HuBERT-large models by 65% and 60%respectively, while incurring no statistically significant word error rate(WER) increase on the test-clean dataset. Compared to previously publishedmethods on the same task, our approach not only achieves the lowest WER of7.05% on the test-clean dataset under a comparable model compression ratio of4.26x, but also operates with at least 25% less model compression time.</description>
      <author>example@mail.com (Haoning Xu, Zhaoqing Li, Youjun Chen, Huimeng Wang, Guinan Li, Mengzhe Geng, Chengxi Deng, Xunying Liu)</author>
      <guid isPermaLink="false">2505.22608v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>3DLLM-Mem: Long-Term Spatial-Temporal Memory for Embodied 3D Large Language Model</title>
      <link>http://arxiv.org/abs/2505.22657v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  demos at: https://3dllm-mem.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文讨论了人类在复杂任务中的长期记忆利用能力与当前大型语言模型在动态多房间3D环境中的局限性。提出了一种新的模型来解决这一问题。&lt;h4&gt;背景&lt;/h4&gt;人类擅长利用长期记忆完成复杂任务，而大型语言模型在动态多房间3D环境中面临规划与行动的挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决大型语言模型在3D环境中的记忆建模不足的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了3DMem-Bench基准测试和3DLLM-Mem模型。3DMem-Bench包含超过26,000条轨迹和2,892个任务，用于评估代理在3D环境中的长期记忆推理能力。3DLLM-Mem模型使用工作记忆标记作为查询，从存储过去观察和交互的情景记忆中选择性地关注和融合最有用的时空特征。&lt;h4&gt;主要发现&lt;/h4&gt;3DLLM-Mem在3DMem-Bench的多个任务上实现了最先进的性能，成功率比最强基线高出16.5%。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的动态记忆管理和融合模型，大型语言模型在复杂、长期环境的时空推理和行动方面取得了显著进步。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类通过利用长期记忆在时间和空间经验上表现出色，完成复杂任务。相比之下，当前的大型语言模型（LLMs）在动态、多房间的3D环境中有效地规划和行动存在困难。我们认为这种限制的部分原因是LLMs缺乏适当的3D时空记忆建模。为了解决这个问题，我们首先引入了3DMem-Bench，这是一个包含超过26,000条轨迹和2,892个具身任务、问答和字幕的综合基准，旨在评估代理在3D环境中进行长期记忆推理的能力。其次，我们提出了3DLLM-Mem，这是一个用于在LLMs中进行具身时空推理和行动的新的动态记忆管理和融合模型。我们的模型使用工作记忆标记，代表当前观察结果，作为查询，以选择性地关注和融合情景记忆中最有用的时空特征，情景记忆存储过去的观察和交互。我们的方法使代理能够专注于与任务相关的信息，同时在复杂、长期环境中保持记忆效率。实验结果表明，3DLLM-Mem在各种任务上实现了最先进的性能，在3DMem-Bench最具挑战性的野外具身任务上的成功率比最强基线高出16.5%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans excel at performing complex tasks by leveraging long-term memoryacross temporal and spatial experiences. In contrast, current Large LanguageModels (LLMs) struggle to effectively plan and act in dynamic, multi-room 3Denvironments. We posit that part of this limitation is due to the lack ofproper 3D spatial-temporal memory modeling in LLMs. To address this, we firstintroduce 3DMem-Bench, a comprehensive benchmark comprising over 26,000trajectories and 2,892 embodied tasks, question-answering and captioning,designed to evaluate an agent's ability to reason over long-term memory in 3Denvironments. Second, we propose 3DLLM-Mem, a novel dynamic memory managementand fusion model for embodied spatial-temporal reasoning and actions in LLMs.Our model uses working memory tokens, which represents current observations, asqueries to selectively attend to and fuse the most useful spatial and temporalfeatures from episodic memory, which stores past observations and interactions.Our approach allows the agent to focus on task-relevant information whilemaintaining memory efficiency in complex, long-horizon environments.Experimental results demonstrate that 3DLLM-Mem achieves state-of-the-artperformance across various tasks, outperforming the strongest baselines by16.5% in success rate on 3DMem-Bench's most challenging in-the-wild embodiedtasks.</description>
      <author>example@mail.com (Wenbo Hu, Yining Hong, Yanjun Wang, Leison Gao, Zibu Wei, Xingcheng Yao, Nanyun Peng, Yonatan Bitton, Idan Szpektor, Kai-Wei Chang)</author>
      <guid isPermaLink="false">2505.22657v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>The quest for the GRAph Level autoEncoder (GRALE)</title>
      <link>http://arxiv.org/abs/2505.22109v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GRALE，一种新的图自动编码器，用于将不同大小的图编码和解码到一个共享的嵌入空间。GRALE通过一个受最优传输启发损失函数训练，该函数比较原始和重建的图，并利用一个可微节点匹配模块，与编码器和解码器一起训练。GRALE的注意力架构基于AlphaFold的核心组件Evoformer，并扩展以支持图编码和解码。数值实验表明，GRALE可以实现高度通用的预训练形式，适用于广泛的下游任务。&lt;h4&gt;背景&lt;/h4&gt;尽管基于图的学习吸引了大量关注，但图表示学习仍然是一个具有挑战性的任务，其解决方法可能影响化学或生物学等关键应用领域。&lt;h4&gt;目的&lt;/h4&gt;提出GRALE，旨在解决图表示学习的挑战，并提高其在关键应用领域的应用效果。&lt;h4&gt;方法&lt;/h4&gt;GRALE通过使用一个受最优传输启发损失函数和可微节点匹配模块进行训练，该模块与编码器和解码器一起训练。其架构基于Evoformer，并扩展以支持图编码和解码。&lt;h4&gt;主要发现&lt;/h4&gt;GRALE在模拟和分子数据上的数值实验表明，它可以实现高度通用的预训练形式，适用于从分类和回归到更复杂的图插值、编辑、匹配和预测等下游任务。&lt;h4&gt;结论&lt;/h4&gt;GRALE是一种有效的图表示学习方法，能够支持多种下游任务，有望在化学和生物学等领域的应用中发挥重要作用。&lt;h4&gt;翻译&lt;/h4&gt;尽管基于图的学习吸引了大量关注，图表示学习仍然是一个具有挑战性的任务，其解决方法可能影响化学或生物学等关键应用领域。为此，我们提出GRALE，一种新的图自动编码器，用于将不同大小的图编码和解码到一个共享的嵌入空间。GRALE使用一个受最优传输启发损失函数进行训练，该函数比较原始和重建的图，并利用一个与编码器和解码器一起训练的可微节点匹配模块。所提出的基于注意力的架构基于AlphaFold的核心组件Evoformer，并扩展以支持图编码和解码。我们在模拟和分子数据上的数值实验表明，GRALE能够实现高度通用的预训练形式，适用于广泛的下游任务，从分类和回归到更复杂的图插值、编辑、匹配和预测等。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although graph-based learning has attracted a lot of attention, graphrepresentation learning is still a challenging task whose resolution may impactkey application fields such as chemistry or biology. To this end, we introduceGRALE, a novel graph autoencoder that encodes and decodes graphs of varyingsizes into a shared embedding space. GRALE is trained using an OptimalTransport-inspired loss that compares the original and reconstructed graphs andleverages a differentiable node matching module, which is trained jointly withthe encoder and decoder. The proposed attention-based architecture relies onEvoformer, the core component of AlphaFold, which we extend to support bothgraph encoding and decoding. We show, in numerical experiments on simulated andmolecular data, that GRALE enables a highly general form of pre-training,applicable to a wide range of downstream tasks, from classification andregression to more complex tasks such as graph interpolation, editing,matching, and prediction.</description>
      <author>example@mail.com (Paul Krzakala, Gabriel Melo, Charlotte Laclau, Florence d'Alché-Buc, Rémi Flamary)</author>
      <guid isPermaLink="false">2505.22109v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Forecasting Multivariate Urban Data via Decomposition and Spatio-Temporal Graph Analysis</title>
      <link>http://arxiv.org/abs/2505.22474v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的多变量时间序列预测模型，使用先进的图神经网络（GNNs）来捕捉不同时间序列变量之间的空间依赖关系，以解决城市数据预测的复杂挑战。&lt;h4&gt;背景&lt;/h4&gt;城市数据预测面临复杂挑战，因为各种城市指标（如天气、空气污染、碳排放强度和能源需求）之间存在复杂的相互依赖关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型，利用GNNs来提高多变量城市数据预测的准确性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;模型包括基于分解的预处理步骤，将趋势、季节性和残差成分隔离，以增强预测的准确性和可解释性。同时，利用GNNs的动态能力来捕捉依赖关系并提高预测性能。&lt;h4&gt;主要发现&lt;/h4&gt;在包括电力使用、天气指标、碳排放强度和空气污染数据的真实世界数据集上进行的广泛实验表明，所提出的方法在各种预测场景中都是有效的。&lt;h4&gt;结论&lt;/h4&gt;该模型有潜力优化智能基础设施系统，有助于节能型城市发展和提高公共福祉。&lt;h4&gt;翻译&lt;/h4&gt;The forecasting of multivariate urban data presents a complex challenge due to the intricate dependencies between various urban metrics such as weather, air pollution, carbon intensity, and energy demand. This paper introduces a novel multivariate time-series forecasting model that utilizes advanced GraphNeural Networks (GNNs) to capture spatial dependencies among different time-series variables. The proposed model incorporates a decomposition-based preprocessing step, isolating trend, seasonal, and residual components to enhance the accuracy and interpretability of forecasts. By leveraging the dynamic capabilities of GNNs, the model effectively captures interdependencies and improves the forecasting performance. Extensive experiments on real-world datasets, including electricity usage, weather metrics, carbon intensity, and air pollution data, demonstrate the effectiveness of the proposed approach across various forecasting scenarios. The results highlight the potential of the model to optimize smart infrastructure systems, contributing to energy-efficient urban development and enhanced public well-being.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The forecasting of multivariate urban data presents a complex challenge dueto the intricate dependencies between various urban metrics such as weather,air pollution, carbon intensity, and energy demand. This paper introduces anovel multivariate time-series forecasting model that utilizes advanced GraphNeural Networks (GNNs) to capture spatial dependencies among differenttime-series variables. The proposed model incorporates a decomposition-basedpreprocessing step, isolating trend, seasonal, and residual components toenhance the accuracy and interpretability of forecasts. By leveraging thedynamic capabilities of GNNs, the model effectively captures interdependenciesand improves the forecasting performance. Extensive experiments on real-worlddatasets, including electricity usage, weather metrics, carbon intensity, andair pollution data, demonstrate the effectiveness of the proposed approachacross various forecasting scenarios. The results highlight the potential ofthe model to optimize smart infrastructure systems, contributing toenergy-efficient urban development and enhanced public well-being.</description>
      <author>example@mail.com (Amirhossein Sohrabbeig, Omid Ardakanian, Petr Musilek)</author>
      <guid isPermaLink="false">2505.22474v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Directed Homophily-Aware Graph Neural Network</title>
      <link>http://arxiv.org/abs/2505.22362v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DHGNN的新框架，旨在解决现有图神经网络在处理异质邻域和忽略图方向性方面的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的图神经网络在处理具有异质邻域的图结构和不对称结构的图时存在困难。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够处理异质邻域并敏感于图方向的图神经网络。&lt;h4&gt;方法&lt;/h4&gt;DHGNN通过引入同质性感知和方向敏感组件来解决这些问题。它使用可重置的门控机制来根据同质性和信息性自适应地调节消息贡献，并使用结构感知的噪声容忍融合模块来有效地整合来自原始和反向方向的节点表示。&lt;h4&gt;主要发现&lt;/h4&gt;在异质和同质有向图数据集上的广泛实验表明，DHGNN在节点分类和链接预测方面优于现有方法，尤其是在链接预测方面，DHGNN的性能比最佳基线提高了高达15.07%。分析显示，门控机制捕捉到了方向同质性差距和层间同质性的波动，为复杂图结构上的消息传递行为提供了更深入的见解。&lt;h4&gt;结论&lt;/h4&gt;DHGNN通过其同质性感知和方向敏感的特性，为图神经网络处理异质邻域和方向性图结构提供了有效的解决方案，并在节点分类和链接预测任务中取得了显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have achieved significant success in variouslearning tasks on graph-structured data. Nevertheless, most GNNs struggle togeneralize to heterophilic neighborhoods. Additionally, many GNNs ignore thedirectional nature of real-world graphs, resulting in suboptimal performance ondirected graphs with asymmetric structures. In this work, we propose DirectedHomophily-aware Graph Neural Network (DHGNN), a novel framework that addressesthese limitations by incorporating homophily-aware and direction-sensitivecomponents. DHGNN employs a resettable gating mechanism to adaptively modulatemessage contributions based on homophily levels and informativeness, and astructure-aware noise-tolerant fusion module to effectively integrate noderepresentations from the original and reverse directions. Extensive experimentson both homophilic and heterophilic directed graph datasets demonstrate thatDHGNN outperforms state-of-the-art methods in node classification and linkprediction. In particular, DHGNN improves over the best baseline by up to15.07% in link prediction. Our analysis further shows that the gating mechanismcaptures directional homophily gaps and fluctuating homophily across layers,providing deeper insights into message-passing behavior on complex graphstructures.</description>
      <author>example@mail.com (Aihu Zhang, Jiaxing Xu, Mengcheng Lan, Shili Xiang, Yiping Ke)</author>
      <guid isPermaLink="false">2505.22362v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Chest Disease Detection In X-Ray Images Using Deep Learning Classification Method</title>
      <link>http://arxiv.org/abs/2505.22609v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究对比了多种分类模型在将胸片图像分类为COVID-19、肺炎、肺结核和正常病例四种类别中的性能，并使用迁移学习和先进的预训练卷积神经网络模型进行了实验。&lt;h4&gt;背景&lt;/h4&gt;通过使用迁移学习技术，利用最先进的预训练卷积神经网络模型，对标注的医疗X光图像进行了微调。&lt;h4&gt;目的&lt;/h4&gt;探究不同分类模型在胸片图像分类任务中的性能，并提高分类结果的准确性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;采用迁移学习技术，对预训练的CNN模型进行微调，并应用Grad-CAM技术提供分类决策的可视化解释。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，模型在关键分类指标如精确度、召回率和F1分数上表现出色，且初步结果令人鼓舞。&lt;h4&gt;结论&lt;/h4&gt;研究证明了迁移学习技术对提高胸片图像分类性能的有效性，并通过Grad-CAM提高了模型的可解释性和透明度。&lt;h4&gt;翻译&lt;/h4&gt;本研究调查了多个分类模型在将胸部X射线图像分类为COVID-19、肺炎、结核病（TB）和正常病例四种类别中的性能。我们利用了最先进的预训练卷积神经网络（CNN）模型进行迁移学习。我们将在标注的医疗X射线图像上对这些预训练架构进行微调。初步结果显示，模型在关键分类指标（如精确度、召回率和F1分数）方面表现良好，具有很高的准确性。我们应用了梯度加权类激活映射（Grad-CAM）来提高模型的可解释性，为分类决策提供可视化解释，从而提高了临床应用中的信任和透明度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we investigate the performance across multiple classificationmodels to classify chest X-ray images into four categories of COVID-19,pneumonia, tuberculosis (TB), and normal cases. We leveraged transfer learningtechniques with state-of-the-art pre-trained Convolutional Neural Networks(CNNs) models. We fine-tuned these pre-trained architectures on a labeledmedical x-ray images. The initial results are promising with high accuracy andstrong performance in key classification metrics such as precision, recall, andF1 score. We applied Gradient-weighted Class Activation Mapping (Grad-CAM) formodel interpretability to provide visual explanations for classificationdecisions, improving trust and transparency in clinical applications.</description>
      <author>example@mail.com (Alanna Hazlett, Naomi Ohashi, Timothy Rodriguez, Sodiq Adewole)</author>
      <guid isPermaLink="false">2505.22609v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>LiDAR Based Semantic Perception for Forklifts in Outdoor Environments</title>
      <link>http://arxiv.org/abs/2505.22258v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种针对复杂户外环境中的自主叉车操作的基于LiDAR的语义分割框架。&lt;h4&gt;背景&lt;/h4&gt;研究针对的是复杂户外环境中的工业物料搬运任务。&lt;h4&gt;目的&lt;/h4&gt;实现动态和静态障碍物的高精度检测和分割，确保安全的关键实例类别（如行人、车辆、叉车）和环境类别（如可行驶地面、车道、建筑物）的准确分割。&lt;h4&gt;方法&lt;/h4&gt;采用了双LiDAR系统，结合正向和向下倾斜的LiDAR传感器，利用两个传感器捕获的高分辨率3D点云，采用轻量级且鲁棒的点云分割方法。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证表明，该方法在满足严格的运行时间要求的同时，实现了高分割精度，证明了其在动态仓库和场院环境中的可行性和安全性。&lt;h4&gt;结论&lt;/h4&gt;该方法适用于安全意识强的、完全自主的叉车在动态仓库和场院环境中的导航。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we present a novel LiDAR-based semantic segmentation frameworktailored for autonomous forklifts operating in complex outdoor environments.Central to our approach is the integration of a dual LiDAR system, whichcombines forward-facing and downward-angled LiDAR sensors to enablecomprehensive scene understanding, specifically tailored for industrialmaterial handling tasks. The dual configuration improves the detection andsegmentation of dynamic and static obstacles with high spatial precision. Usinghigh-resolution 3D point clouds captured from two sensors, our method employs alightweight yet robust approach that segments the point clouds intosafety-critical instance classes such as pedestrians, vehicles, and forklifts,as well as environmental classes such as driveable ground, lanes, andbuildings. Experimental validation demonstrates that our approach achieves highsegmentation accuracy while satisfying strict runtime requirements,establishing its viability for safety-aware, fully autonomous forkliftnavigation in dynamic warehouse and yard environments.</description>
      <author>example@mail.com (Benjamin Serfling, Hannes Reichert, Lorenzo Bayerlein, Konrad Doll, Kati Radkhah-Lens)</author>
      <guid isPermaLink="false">2505.22258v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>An Augmentation-Aware Theory for Self-Supervised Contrastive Learning</title>
      <link>http://arxiv.org/abs/2505.22196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICML2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对自监督对比学习的增强感知误差界限，揭示了数据增强在自监督对比学习中的作用，并通过实验验证了理论结果。&lt;h4&gt;背景&lt;/h4&gt;自监督对比学习在机器学习和计算机视觉领域已成为一种强大的工具，用于从无标签数据中学习有意义的表示。&lt;h4&gt;目的&lt;/h4&gt;为了填补现有理论研究中数据增强作用未被充分利用的空白，提出了增强感知误差界限。&lt;h4&gt;方法&lt;/h4&gt;首次提出了针对自监督对比学习的增强感知误差界限，并在新的语义标签假设下讨论了特定增强方法对误差界限的影响，同时进行了像素级和表示级实验。&lt;h4&gt;主要发现&lt;/h4&gt;发现监督风险不仅受无监督风险限制，还受数据增强引起的权衡影响。&lt;h4&gt;结论&lt;/h4&gt;数据增强在自监督对比学习中起着重要作用，并且通过实验验证了理论结果的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised contrastive learning has emerged as a powerful tool in machine learning and computer vision to learn meaningful representations from unlabeled data. Meanwhile, its empirical success has encouraged many theoretical studies to reveal the learning mechanisms. However, in the existing theoretical research, the role of data augmentation is still under-exploited, especially the effects of specific augmentation types. To fill in the blank, we for the first time propose an augmentation-aware error bound for self-supervised contrastive learning, showing that the supervised risk is bounded not only by the unsupervised risk, but also explicitly by a trade-off induced by data augmentation. Then, under a novel semantic label assumption, we discuss how certain augmentation methods affect the error bound. Lastly, we conduct both pixel- and representation-level experiments to verify our proposed theoretical results.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised contrastive learning has emerged as a powerful tool inmachine learning and computer vision to learn meaningful representations fromunlabeled data. Meanwhile, its empirical success has encouraged manytheoretical studies to reveal the learning mechanisms. However, in the existingtheoretical research, the role of data augmentation is still under-exploited,especially the effects of specific augmentation types. To fill in the blank, wefor the first time propose an augmentation-aware error bound forself-supervised contrastive learning, showing that the supervised risk isbounded not only by the unsupervised risk, but also explicitly by a trade-offinduced by data augmentation. Then, under a novel semantic label assumption, wediscuss how certain augmentation methods affect the error bound. Lastly, weconduct both pixel- and representation-level experiments to verify our proposedtheoretical results.</description>
      <author>example@mail.com (Jingyi Cui, Hongwei Wen, Yisen Wang)</author>
      <guid isPermaLink="false">2505.22196v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>DES-LOC: Desynced Low Communication Adaptive Optimizers for Training Foundation Models</title>
      <link>http://arxiv.org/abs/2505.22549v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Keywords: Distributed Training, Foundation Models, Large Language  Models, Optimizers, Communication Efficiency, Federated Learning, Distributed  Systems, Optimization Theory, Scaling, Robustness. Preprint, under review at  NeurIPS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DES-LOC的新型自适应优化器，旨在降低分布式训练中的通信成本，同时保证收敛性。&lt;h4&gt;背景&lt;/h4&gt;当前使用分布式数据并行（DDP）方法扩展基础模型训练时，受限于带宽。现有的稀疏通信方法如Local SGD只能同步模型参数，难以适应自适应优化器，因为它们需要同步额外的优化器状态。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够降低通信成本的同时保持收敛性的自适应优化器。&lt;h4&gt;方法&lt;/h4&gt;DES-LOC通过为参数和动量分配独立的同步周期，实现了这一点。&lt;h4&gt;主要发现&lt;/h4&gt;在1.7B语言模型上的广泛实验表明，DES-LOC的通信量比DDP低170倍，比之前的Local ADAM低2倍。此外，DES-LOC不像之前的方法那样是启发式的，更适合易受系统故障影响的实际训练场景。&lt;h4&gt;结论&lt;/h4&gt;DES-LOC为分布式训练提供了一种可扩展、带宽高效且容错性强的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scaling foundation model training with Distributed Data Parallel (DDP)methods is bandwidth-limited. Existing infrequent communication methods likeLocal SGD were designed to synchronize only model parameters and cannot betrivially applied to adaptive optimizers due to additional optimizer states.Current approaches extending Local SGD either lack convergence guarantees orrequire synchronizing all optimizer states, tripling communication costs. Wepropose Desynced Low Communication Adaptive Optimizers (DES-LOC), a family ofoptimizers assigning independent synchronization periods to parameters andmomenta, enabling lower communication costs while preserving convergence.Through extensive experiments on language models of up to 1.7B, we show thatDES-LOC can communicate 170x less than DDP and 2x less than the previousstate-of-the-art Local ADAM. Furthermore, unlike previous heuristic approaches,DES-LOC is suited for practical training scenarios prone to system failures.DES-LOC offers a scalable, bandwidth-efficient, and fault-tolerant solution forfoundation model training.</description>
      <author>example@mail.com (Alex Iacob, Lorenzo Sani, Mher Safaryan, Paris Giampouras, Samuel Horváth, Andrej Jovanovic, Meghdad Kurmanji, Preslav Aleksandrov, William F. Shen, Xinchi Qiu, Nicholas D. Lane)</author>
      <guid isPermaLink="false">2505.22549v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>3D Question Answering via only 2D Vision-Language Models</title>
      <link>http://arxiv.org/abs/2505.22143v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了如何利用大型视觉语言模型（LVLMs）在3D场景理解任务中的应用，以3D问答（3D-QA）为例，提出了一种名为cdViews的新方法，通过2D模型进行零样本推理，以解决3D-QA问题。&lt;h4&gt;背景&lt;/h4&gt;大型视觉语言模型在多个领域取得了显著进展，但3D场景理解任务的训练数据有限。&lt;h4&gt;目的&lt;/h4&gt;探索如何利用LVLMs解决3D场景理解任务，以3D问答为例。&lt;h4&gt;方法&lt;/h4&gt;不直接训练LVLMs，而是通过从3D点云中采样2D视图，并输入到2D模型中来回答问题。cdViews方法包括两个关键组件：viewSelector根据提供答案特定信息的潜力优先选择关键视图，viewNMS通过基于空间重叠去除冗余视图来增强多样性。&lt;h4&gt;主要发现&lt;/h4&gt;cdViews在ScanQA和SQA基准测试中实现了最先进的性能，而无需对2D模型进行微调。&lt;h4&gt;结论&lt;/h4&gt;2D LVLMs是目前解决3D任务的资源密集型3D LVLMs的最有效替代方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大型视觉语言模型（LVLMs）在众多领域取得了显著进展。在这项工作中，我们探讨了如何利用其潜力来解决3D场景理解任务，以3D问答（3D-QA）为例。由于3D的培训数据有限，我们不训练LVLMs，而是以零样本的方式进行推理。具体来说，我们从3D点云中采样2D视图，并将它们输入到2D模型中来回答给定的问题。当选择2D模型时，例如LLAVA-OV，采样视图的质量最为重要。我们提出了cdViews，这是一种用于自动选择对3D-QA至关重要的多样化视图的新方法。cdViews由两个关键组件组成：viewSelector根据其提供答案特定信息的潜力优先选择关键视图，viewNMS通过基于空间重叠去除冗余视图来增强多样性。我们在广泛使用的ScanQA和SQA基准测试中评估了cdViews，证明了它在3D-QA中实现了最先进的性能，同时仅依赖于2D模型而不进行微调。这些发现支持了我们的信念，即2D LVLMs是目前解决3D任务的最有效的替代方案（资源密集型的3D LVLMs）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large vision-language models (LVLMs) have significantly advanced numerousfields. In this work, we explore how to harness their potential to address 3Dscene understanding tasks, using 3D question answering (3D-QA) as arepresentative example. Due to the limited training data in 3D, we do not trainLVLMs but infer in a zero-shot manner. Specifically, we sample 2D views from a3D point cloud and feed them into 2D models to answer a given question. Whenthe 2D model is chosen, e.g., LLAVA-OV, the quality of sampled views mattersthe most. We propose cdViews, a novel approach to automatically selectingcritical and diverse Views for 3D-QA. cdViews consists of two key components:viewSelector prioritizing critical views based on their potential to provideanswer-specific information, and viewNMS enhancing diversity by removingredundant views based on spatial overlap. We evaluate cdViews on thewidely-used ScanQA and SQA benchmarks, demonstrating that it achievesstate-of-the-art performance in 3D-QA while relying solely on 2D models withoutfine-tuning. These findings support our belief that 2D LVLMs are currently themost effective alternative (of the resource-intensive 3D LVLMs) for addressing3D tasks.</description>
      <author>example@mail.com (Fengyun Wang, Sicheng Yu, Jiawei Wu, Jinhui Tang, Hanwang Zhang, Qianru Sun)</author>
      <guid isPermaLink="false">2505.22143v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Universal Visuo-Tactile Video Understanding for Embodied Interaction</title>
      <link>http://arxiv.org/abs/2505.22566v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了VTV-LLM，这是第一个用于通用视触觉视频（VTV）理解的跨模态大型语言模型，它弥合了触觉感知与自然语言之间的差距。&lt;h4&gt;背景&lt;/h4&gt;触觉感知对于实体智能体理解物体物理属性至关重要，而现有方法在视觉和语言模态上虽有进展，但未能有效整合触觉信息。&lt;h4&gt;目的&lt;/h4&gt;提出VTV-LLM以解决跨传感器和跨模态整合的挑战，并提高触觉视频理解任务的表现。&lt;h4&gt;方法&lt;/h4&gt;构建了VTV150K数据集，包含来自100个不同物体的150,000个视频帧，并使用四种基本触觉属性进行标注。开发了包含VTV增强、VTV-文本对齐和文本提示微调的三阶段训练范式。&lt;h4&gt;主要发现&lt;/h4&gt;VTV-LLM框架实现了复杂的触觉推理能力，包括特征评估、比较分析、基于场景的决策等。&lt;h4&gt;结论&lt;/h4&gt;实验评估表明，VTV-LLM在触觉视频理解任务中表现出色，为更直观的人机交互奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：触觉感知对于实体智能体理解物体物理属性至关重要，而现有方法在视觉和语言模态上虽有进展，但未能有效整合触觉信息。在本文中，我们提出了VTV-LLM，这是第一个用于通用视触觉视频（VTV）理解的跨模态大型语言模型，它弥合了触觉感知与自然语言之间的差距。为了解决跨传感器和跨模态整合的挑战，我们贡献了VTV150K数据集，该数据集包含来自100个不同物体的150,000个视频帧，并使用四种基本触觉属性进行标注。我们开发了一种新颖的三阶段训练范式，包括VTV增强以实现鲁棒的视觉触觉表示、VTV-文本对齐以实现跨模态对应以及文本提示微调以实现自然语言生成。我们的框架实现了复杂的触觉推理能力，包括特征评估、比较分析、基于场景的决策等。实验评估表明，VTV-LLM在触觉视频理解任务中表现出色，为更直观的人机交互奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tactile perception is essential for embodied agents to understand physicalattributes of objects that cannot be determined through visual inspectionalone. While existing approaches have made progress in visual and languagemodalities for physical understanding, they fail to effectively incorporatetactile information that provides crucial haptic feedback for real-worldinteraction. In this paper, we present VTV-LLM, the first multi-modal largelanguage model for universal Visuo-Tactile Video (VTV) understanding thatbridges the gap between tactile perception and natural language. To address thechallenges of cross-sensor and cross-modal integration, we contribute VTV150K,a comprehensive dataset comprising 150,000 video frames from 100 diverseobjects captured across three different tactile sensors (GelSight Mini, DIGIT,and Tac3D), annotated with four fundamental tactile attributes (hardness,protrusion, elasticity, and friction). We develop a novel three-stage trainingparadigm that includes VTV enhancement for robust visuo-tactile representation,VTV-text alignment for cross-modal correspondence, and text prompt finetuningfor natural language generation. Our framework enables sophisticated tactilereasoning capabilities including feature assessment, comparative analysis,scenario-based decision making and so on. Experimental evaluations demonstratethat VTV-LLM achieves superior performance in tactile video understandingtasks, establishing a foundation for more intuitive human-machine interactionin tactile domains.</description>
      <author>example@mail.com (Yifan Xie, Mingyang Li, Shoujie Li, Xingting Li, Guangyu Chen, Fei Ma, Fei Richard Yu, Wenbo Ding)</author>
      <guid isPermaLink="false">2505.22566v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Reinforced Reasoning for Embodied Planning</title>
      <link>http://arxiv.org/abs/2505.22050v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种增强的强化学习框架，用于解决交互式环境中基于动态视觉观察和自然语言目标的实体规划问题。&lt;h4&gt;背景&lt;/h4&gt;虽然最近的视觉语言模型（VLMs）在静态感知任务上表现出色，但在时间推理、空间理解和常识基础等方面，对于实体规划存在困难。&lt;h4&gt;目的&lt;/h4&gt;通过引入强化学习，提升实体规划中所需的推理能力。&lt;h4&gt;方法&lt;/h4&gt;首先，从强大的闭源模型中提取高质量数据集，并执行监督微调（SFT）来装备模型以结构化决策先验；然后，设计一个基于规则的奖励函数，针对多步动作质量进行优化，并通过广义强化偏好优化（GRPO）来优化策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，该方法在Embench基准测试中显著优于类似规模或更大的模型，包括GPT-4o-mini和70B+的开源基准模型，并且展现出对未见环境的强大泛化能力。&lt;h4&gt;结论&lt;/h4&gt;这项工作强调了强化驱动推理在推进实体AI中长期规划方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Embodied planning requires agents to make coherent multi-step decisions based on dynamic visual observations and natural language goals. While recent vision-language models (VLMs) excel at static perception tasks, they struggle with the temporal reasoning, spatial understanding, and common-sense grounding needed for planning in interactive environments. In this work, we introduce a reinforcement fine-tuning framework that brings R1-style reasoning enhancement into embodied planning. We first distill a high-quality dataset from a powerful closed-source model and perform supervised fine-tuning (SFT) to equip the model with structured decision-making priors. We then design a rule-based reward function tailored to multi-step action quality and optimize the policy via Generalized Reinforced Preference Optimization (GRPO). Our approach is evaluated on Embench, a recent benchmark for interactive embodied tasks, covering both in-domain and out-of-domain scenarios. Experimental results show that our method significantly outperforms models of similar or larger scale, including GPT-4o-mini and 70B+ open-source baselines, and exhibits strong generalization to unseen environments. This work highlights the potential of reinforcement-driven reasoning to advance long-horizon planning in embodied AI.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Embodied planning requires agents to make coherent multi-step decisions basedon dynamic visual observations and natural language goals. While recentvision-language models (VLMs) excel at static perception tasks, they strugglewith the temporal reasoning, spatial understanding, and commonsense groundingneeded for planning in interactive environments. In this work, we introduce areinforcement fine-tuning framework that brings R1-style reasoning enhancementinto embodied planning. We first distill a high-quality dataset from a powerfulclosed-source model and perform supervised fine-tuning (SFT) to equip the modelwith structured decision-making priors. We then design a rule-based rewardfunction tailored to multi-step action quality and optimize the policy viaGeneralized Reinforced Preference Optimization (GRPO). Our approach isevaluated on Embench, a recent benchmark for interactive embodied tasks,covering both in-domain and out-of-domain scenarios. Experimental results showthat our method significantly outperforms models of similar or larger scale,including GPT-4o-mini and 70B+ open-source baselines, and exhibits stronggeneralization to unseen environments. This work highlights the potential ofreinforcement-driven reasoning to advance long-horizon planning in embodied AI.</description>
      <author>example@mail.com (Di Wu, Jiaxin Fan, Junzhe Zang, Guanbo Wang, Wei Yin, Wenhao Li, Bo Jin)</author>
      <guid isPermaLink="false">2505.22050v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>On the Transferability and Discriminability of Repersentation Learning in Unsupervised Domain Adaptation</title>
      <link>http://arxiv.org/abs/2505.22099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的无监督领域自适应（UDA）框架，以解决仅依赖分布对齐和源域经验风险最小化方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;传统的基于对抗的方法在UDA中忽视了目标域特征的判别性，导致性能不佳。&lt;h4&gt;目的&lt;/h4&gt;为了弥补理论实践之间的差距，本文定义了“良好的表示学习”应保证可迁移性和判别性，并证明了针对目标域判别性的额外损失项是必要的。&lt;h4&gt;方法&lt;/h4&gt;提出的方法，即基于域不变表示学习全局和局部一致性（RLGLC），通过整合域对齐目标与判别性增强约束，利用非对称松弛Wasserstein距离（AR-WWD）处理类别不平衡和语义维度加权，并采用局部一致性机制以保留目标域的细粒度判别信息。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，RLGLC在多个基准数据集上优于现有方法，证实了本文理论视角的价值，并强调了在基于对抗的UDA中强制执行可迁移性和判别性的必要性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在无监督领域自适应中取得了显著的性能提升，为未来的研究提供了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we addressed the limitation of relying solely on distributionalignment and source-domain empirical risk minimization in Unsupervised DomainAdaptation (UDA). Our information-theoretic analysis showed that this standardadversarial-based framework neglects the discriminability of target-domainfeatures, leading to suboptimal performance. To bridge thistheoretical-practical gap, we defined "good representation learning" asguaranteeing both transferability and discriminability, and proved that anadditional loss term targeting target-domain discriminability is necessary.Building on these insights, we proposed a novel adversarial-based UDA frameworkthat explicitly integrates a domain alignment objective with adiscriminability-enhancing constraint. Instantiated as Domain-InvariantRepresentation Learning with Global and Local Consistency (RLGLC), our methodleverages Asymmetrically-Relaxed Wasserstein of Wasserstein Distance (AR-WWD)to address class imbalance and semantic dimension weighting, and employs alocal consistency mechanism to preserve fine-grained target-domaindiscriminative information. Extensive experiments across multiple benchmarkdatasets demonstrate that RLGLC consistently surpasses state-of-the-artmethods, confirming the value of our theoretical perspective and underscoringthe necessity of enforcing both transferability and discriminability inadversarial-based UDA.</description>
      <author>example@mail.com (Wenwen Qiang, Ziyin Gu, Lingyu Si, Jiangmeng Li, Changwen Zheng, Fuchun Sun, Hui Xiong)</author>
      <guid isPermaLink="false">2505.22099v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>B-XAIC Dataset: Benchmarking Explainable AI for Graph Neural Networks Using Chemical Data</title>
      <link>http://arxiv.org/abs/2505.22252v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 16 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为B-XAIC的新型基准，用于评估化学信息学和药物发现中深度学习模型的可解释性，并揭示了现有方法在分子领域的局限性。&lt;h4&gt;背景&lt;/h4&gt;在化学信息学和药物发现中，理解深度学习模型预测的推理过程至关重要，因为这些模型的分子设计决定了它们的性质。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有可解释人工智能（XAI）评估框架的局限性，如依赖人工数据集或简化任务，本文提出了B-XAIC基准。&lt;h4&gt;方法&lt;/h4&gt;B-XAIC基准由真实世界的分子数据和具有已知标签理由的多样化任务构建而成，用于评估Graph Neural Networks（GNNs）在分子领域的XAI方法。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用B-XAIC进行综合评估，揭示了现有XAI方法在分子领域的局限性。&lt;h4&gt;结论&lt;/h4&gt;B-XAIC为深入了解XAI的可靠性提供了宝贵资源，有助于开发更可靠和可解释的模型。&lt;h4&gt;翻译&lt;/h4&gt;Understanding the reasoning behind deep learning model predictions is crucial in cheminformatics and drug discovery, where molecular design determines their properties. However, current evaluation frameworks for Explainable AI (XAI) in this domain often rely on artificial datasets or simplified tasks, employing data-derived metrics that fail to capture the complexity of real-world scenarios and lack a direct link to explanation faithfulness. To address this, we introduce B-XAIC, a novel benchmark constructed from real-world molecular data and diverse tasks with known ground-truth rationales for assigned labels. Through a comprehensive evaluation using B-XAIC, we reveal limitations of existing XAI methods for Graph Neural Networks (GNNs) in the molecular domain. This benchmark provides a valuable resource for gaining deeper insights into the faithfulness of XAI, facilitating the development of more reliable and interpretable models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the reasoning behind deep learning model predictions is crucialin cheminformatics and drug discovery, where molecular design determines theirproperties. However, current evaluation frameworks for Explainable AI (XAI) inthis domain often rely on artificial datasets or simplified tasks, employingdata-derived metrics that fail to capture the complexity of real-worldscenarios and lack a direct link to explanation faithfulness. To address this,we introduce B-XAIC, a novel benchmark constructed from real-world moleculardata and diverse tasks with known ground-truth rationales for assigned labels.Through a comprehensive evaluation using B-XAIC, we reveal limitations ofexisting XAI methods for Graph Neural Networks (GNNs) in the molecular domain.This benchmark provides a valuable resource for gaining deeper insights intothe faithfulness of XAI, facilitating the development of more reliable andinterpretable models.</description>
      <author>example@mail.com (Magdalena Proszewska, Tomasz Danel, Dawid Rymarczyk)</author>
      <guid isPermaLink="false">2505.22252v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>GLAMP: An Approximate Message Passing Framework for Transfer Learning with Applications to Lasso-based Estimators</title>
      <link>http://arxiv.org/abs/2505.22594v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  104 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GLAMP的近似消息传递算法，它扩展了AMP算法的范围，使其能够处理矩阵值迭代和非可分去噪函数，从而更精确地描述从多个数据源中获取信息且存在分布变化的估计量。&lt;h4&gt;背景&lt;/h4&gt;现有的AMP框架无法同时处理矩阵值迭代和非可分去噪函数，限制了其在多个领域的应用。&lt;h4&gt;目的&lt;/h4&gt;提出GLAMP算法，解决现有AMP框架的局限性，使其能够更广泛地应用于统计、深度学习、遗传学和通信等领域。&lt;h4&gt;方法&lt;/h4&gt;引入GLAMP算法，并严格证明了其状态演化的正确性。&lt;h4&gt;主要发现&lt;/h4&gt;GLAMP算法能够分析之前无法触及的迁移学习估计量，并通过模拟展示了其理论在有限样本下的高准确性。&lt;h4&gt;结论&lt;/h4&gt;GLAMP算法是AMP算法的一种扩展，能够更精确地描述复杂的数据处理问题，并在多个领域中具有潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Approximate Message Passing (AMP) 算法能够精确地描述高维极限下某些类别的随机对象，并在统计学、深度学习、遗传学和通信等领域得到了广泛应用。然而，现有的AMP框架无法同时处理矩阵值迭代和非可分去噪函数。这种局限性阻止了它们精确地描述从多个数据源中获取信息且存在分布变化的估计量。在本工作中，我们引入了广义长近似消息传递（Generalized Long Approximate Message Passing, GLAMP），这是AMP算法的一种新颖扩展，用于解决这一局限性。我们严格证明了GLAMP的状态演化。GLAMP显著扩大了AMP的范围，使得分析之前无法触及的迁移学习估计量成为可能。我们通过精确描述三种基于Lasso的迁移学习估计量的风险，即堆叠Lasso、模型平均估计量和第二步估计量，来展示GLAMP的实用性。我们还通过广泛的模拟展示了我们理论的显著有限样本准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Approximate Message Passing (AMP) algorithms enable precise characterizationof certain classes of random objects in the high-dimensional limit, and havefound widespread applications in fields such as statistics, deep learning,genetics, and communications. However, existing AMP frameworks cannotsimultaneously handle matrix-valued iterates and non-separable denoisingfunctions. This limitation prevents them from precisely characterizingestimators that draw information from multiple data sources with distributionshifts. In this work, we introduce Generalized Long Approximate Message Passing(GLAMP), a novel extension of AMP that addresses this limitation. We rigorouslyprove state evolution for GLAMP. GLAMP significantly broadens the scope of AMP,enabling the analysis of transfer learning estimators that were previously outof reach. We demonstrate the utility of GLAMP by precisely characterizing therisk of three Lasso-based transfer learning estimators: the Stacked Lasso, theModel Averaging Estimator, and the Second Step Estimator. We also demonstratethe remarkable finite sample accuracy of our theory via extensive simulations.</description>
      <author>example@mail.com (Longlin Wang, Yanke Song, Kuanhao Jiang, Pragya Sur)</author>
      <guid isPermaLink="false">2505.22594v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>BaryIR: Learning Multi-Source Unified Representation in Continuous Barycenter Space for Generalizable All-in-One Image Restoration</title>
      <link>http://arxiv.org/abs/2505.21637v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BaryIR的多源表示学习框架，用于处理不同类型的图像退化，并展示其在现实世界数据和未见退化方面的优越性能。&lt;h4&gt;背景&lt;/h4&gt;尽管在同时处理不同类型退化的全图像修复（AIR）方面取得了显著进展，但现有方法对分布外退化和图像仍然很脆弱，限制了其在现实世界中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够处理多种退化并具有良好泛化能力的图像修复方法。&lt;h4&gt;方法&lt;/h4&gt;BaryIR将多源退化图像的潜在空间分解为连续的重心空间用于统一特征编码和特定源子空间用于特定语义编码。通过引入多源潜在最优传输重心问题，学习一个连续的重心映射来将潜在表示传输到重心空间。传输成本被设计为对比特定源子空间中的表示，同时保持与重心空间表示的正交性。&lt;h4&gt;主要发现&lt;/h4&gt;BaryIR能够学习具有统一退化无关信息的紧凑表示，以及从特定源子空间中提取退化特定语义，捕捉多源数据流形的固有几何结构，从而实现可泛化的图像修复。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，BaryIR在性能上与最先进的全图像修复方法相比具有竞争力，并且表现出对现实世界数据和未见退化的优越泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管在处理不同类型退化的全图像修复（AIR）方面取得了显著进展，但现有方法对分布外退化和图像仍然很脆弱，限制了其在现实世界中的应用。在本文中，我们提出了一种名为BaryIR的多源表示学习框架，该框架将多源退化图像的潜在空间分解为一个连续的重心空间，用于统一特征编码，以及特定源子空间，用于特定语义编码。具体来说，我们通过引入一个多源潜在最优传输重心问题来寻求多源统一表示，在这个问题中，学习一个连续的重心映射来将潜在表示传输到重心空间。传输成本被设计为对比特定源子空间中的表示，同时保持与重心空间表示的正交性。这使得BaryIR能够从重心空间学习具有统一退化无关信息的紧凑表示，以及从特定源子空间中提取退化特定语义，捕捉多源数据流形的固有几何结构，以实现可泛化的图像修复。广泛的实验表明，与最先进的全图像修复方法相比，BaryIR实现了具有竞争力的性能。特别是，BaryIR在现实世界数据和未见退化方面表现出卓越的泛化能力。代码将在https://github.com/xl-tang3/BaryIR上公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite remarkable advances made in all-in-one image restoration (AIR) forhandling different types of degradations simultaneously, existing methodsremain vulnerable to out-of-distribution degradations and images, limitingtheir real-world applicability. In this paper, we propose a multi-sourcerepresentation learning framework BaryIR, which decomposes the latent space ofmulti-source degraded images into a continuous barycenter space for unifiedfeature encoding and source-specific subspaces for specific semantic encoding.Specifically, we seek the multi-source unified representation by introducing amulti-source latent optimal transport barycenter problem, in which a continuousbarycenter map is learned to transport the latent representations to thebarycenter space. The transport cost is designed such that the representationsfrom source-specific subspaces are contrasted with each other while maintainingorthogonality to those from the barycenter space. This enables BaryIR to learncompact representations with unified degradation-agnostic information from thebarycenter space, as well as degradation-specific semantics fromsource-specific subspaces, capturing the inherent geometry of multi-source datamanifold for generalizable AIR. Extensive experiments demonstrate that BaryIRachieves competitive performance compared to state-of-the-art all-in-onemethods. Particularly, BaryIR exhibits superior generalization ability toreal-world data and unseen degradations. The code will be publicly available athttps://github.com/xl-tang3/BaryIR.</description>
      <author>example@mail.com (Xiaole Tang, Xiaoyi He, Xiang Gu, Jian Sun)</author>
      <guid isPermaLink="false">2505.21637v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis</title>
      <link>http://arxiv.org/abs/2505.22079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages (8 main, 2 references, 6 appendix), 13 figures. Accepted to  CVPR 2025. This author-accepted manuscript includes an expanded ethics/data  user agreement section. The final version will appear in the Proceedings of  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新方法，旨在解决大规模图像-文本对数据集在视觉-语言处理（VLP）中的应用问题，特别是在医疗数据上直接应用通用领域架构的挑战。&lt;h4&gt;背景&lt;/h4&gt;随着大规模图像-文本对数据集的发展，自监督学习在视觉-语言处理领域取得了显著进展。然而，直接将通用领域的架构如CLIP应用于医疗数据面临挑战，特别是在处理否定和解决医疗数据集固有的数据不平衡问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合临床增强动态软标签和医疗图形对齐的新方法，以提高临床理解和对比损失在医疗环境中的适用性。&lt;h4&gt;方法&lt;/h4&gt;引入基于否定的硬负例，以深化模型对临床语言复杂性的理解。该方法易于集成到医疗CLIP训练流程中，并在多个任务上实现最先进的性能，包括零样本、微调和报告检索。为了全面评估模型理解临床语言的能力，引入了CXR-Align基准，专门用于评估胸部X光（CXR）数据集中否定和临床信息的理解。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法易于实现，并且在对比学习框架中具有很好的泛化能力，增强了医疗VLP的能力，并推进了医疗影像中的临床语言理解。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法为医疗视觉-语言处理提供了新的思路，通过改进模型对临床语言的理解能力，有助于提升医疗影像分析的水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of large-scale image-text pair datasets has significantlyadvanced self-supervised learning in Vision-Language Processing (VLP). However,directly applying general-domain architectures such as CLIP to medical datapresents challenges, particularly in handling negations and addressing theinherent data imbalance of medical datasets. To address these issues, wepropose a novel approach that integrates clinically-enhanced dynamic softlabels and medical graphical alignment, thereby improving clinicalcomprehension and the applicability of contrastive loss in medical contexts.Furthermore, we introduce negation-based hard negatives to deepen the model'sunderstanding of the complexities of clinical language. Our approach is easilyintegrated into the medical CLIP training pipeline and achievesstate-of-the-art performance across multiple tasks, including zero-shot,fine-tuned classification, and report retrieval. To comprehensively evaluateour model's capacity for understanding clinical language, we introduceCXR-Align, a benchmark uniquely designed to evaluate the understanding ofnegation and clinical information within chest X-ray (CXR) datasets.Experimental results demonstrate that our proposed methods are straightforwardto implement and generalize effectively across contrastive learning frameworks,enhancing medical VLP capabilities and advancing clinical languageunderstanding in medical imaging.</description>
      <author>example@mail.com (Hanbin Ko, Chang-Min Park)</author>
      <guid isPermaLink="false">2505.22079v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>What Makes a Good Reasoning Chain? Uncovering Structural Patterns in Long Chain-of-Thought Reasoning</title>
      <link>http://arxiv.org/abs/2505.22148v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LCoT2Tree的自动化框架，该框架可以将连续的LCoT（长链式思维）转换为层次化的树结构，从而实现LLM推理的更深入结构分析。&lt;h4&gt;背景&lt;/h4&gt;虽然LCoT在复杂任务中实现了专家级的表现，但其推理链的内部结构如何驱动或预测最终答案的正确性，仍然是一个关键且未充分探索的问题。&lt;h4&gt;目的&lt;/h4&gt;研究LCoT推理链的内部结构，并开发LCoT2Tree框架以实现LLM推理的深入结构分析。&lt;h4&gt;方法&lt;/h4&gt;使用图神经网络（GNN）分析LCoT2Tree提取的结构模式，包括探索、回溯和验证，并利用可解释性技术识别关键思维模式。&lt;h4&gt;主要发现&lt;/h4&gt;LCoT2Tree提取的结构模式是预测最终性能的强预测因子，并揭示了导致失败的思维模式，如过度分支。&lt;h4&gt;结论&lt;/h4&gt;LCoT2Tree在诊断、解释和改进LLM推理中发挥着关键作用，并支持实际应用，如提高Best-of-N解码的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，在大型语言模型（LLM）推理方面的最新进展使得长链式思维（LCoT）策略变得流行，该策略鼓励在产生最终答案之前进行深思熟虑和逐步推理。尽管LCoT在复杂任务中实现了专家级的表现，但其推理链的内部结构如何驱动或甚至预测最终答案的正确性仍然是一个关键且未充分探索的问题。在这项工作中，我们提出了LCoT2Tree，一个将连续的LCoT转换为层次化树结构的自动化框架，从而实现了LLM推理的更深入结构分析。使用图神经网络（GNN），我们发现LCoT2Tree提取的结构模式，包括探索、回溯和验证，是更广泛的任务和模型最终性能的强预测因子。利用可解释性技术，我们进一步确定了导致失败的思维模式，如过度分支。除了诊断洞察力之外，LCoT2Tree的结构模式还支持实际应用，包括提高Best-of-N解码的有效性。总的来说，我们的结果强调了推理链内部结构的关键作用，将LCoT2Tree定位为诊断、解释和改进LLM推理的有力工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in reasoning with large language models (LLMs) havepopularized Long Chain-of-Thought (LCoT), a strategy that encourages deliberateand step-by-step reasoning before producing a final answer. While LCoTs haveenabled expert-level performance in complex tasks, how the internal structuresof their reasoning chains drive, or even predict, the correctness of finalanswers remains a critical yet underexplored question. In this work, we presentLCoT2Tree, an automated framework that converts sequential LCoTs intohierarchical tree structures and thus enables deeper structural analysis of LLMreasoning. Using graph neural networks (GNNs), we reveal that structuralpatterns extracted by LCoT2Tree, including exploration, backtracking, andverification, serve as stronger predictors of final performance across a widerange of tasks and models. Leveraging an explainability technique, we furtheridentify critical thought patterns such as over-branching that account forfailures. Beyond diagnostic insights, the structural patterns by LCoT2Treesupport practical applications, including improving Best-of-N decodingeffectiveness. Overall, our results underscore the critical role of internalstructures of reasoning chains, positioning LCoT2Tree as a powerful tool fordiagnosing, interpreting, and improving reasoning in LLMs.</description>
      <author>example@mail.com (Gangwei Jiang, Yahui Liu, Zhaoyi Li, Qi Wang, Fuzheng Zhang, Linqi Song, Ying Wei, Defu Lian)</author>
      <guid isPermaLink="false">2505.22148v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>From Large AI Models to Agentic AI: A Tutorial on Future Intelligent Communications</title>
      <link>http://arxiv.org/abs/2505.22311v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文系统介绍了大型人工智能模型（LAMs）和代理人工智能技术在智能通信系统中的应用，旨在为研究者提供关于尖端技术的全面概述和实际指导。&lt;h4&gt;背景&lt;/h4&gt;随着6G通信的到来，智能通信系统面临感知和响应能力受限、可扩展性有限以及在动态环境中的低适应性等多重挑战。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供对LAMs和代理人工智能技术的原理、设计和应用的系统介绍，以帮助研究者全面了解前沿技术并得到实践指导。&lt;h4&gt;方法&lt;/h4&gt;文章首先概述了6G通信的背景，回顾了从LAMs到代理人工智能技术的技术演变，并明确了教程的动机和主要贡献。然后，对构建LAMs所需的关键组件进行了全面综述，并对LAMs进行了分类和分析。接着，提出了适用于通信的以LAM为中心的设计范式，并基于此开发了一个基于LAM的代理人工智能系统，同时介绍了其核心组件和交互机制。最后，引入了一个多代理框架，并概述了LAMs和代理人工智能在通信场景中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;文章提出了适用于通信的LAM-centric设计范式，并开发了一个基于LAM的代理人工智能系统，同时介绍了一个多代理框架。&lt;h4&gt;结论&lt;/h4&gt;文章总结了当前研究中的挑战和未来方向，旨在支持高效、安全和可持续的下一代智能通信系统的发展。&lt;h4&gt;翻译&lt;/h4&gt;With the advent of 6G communications, intelligent communication systems facemultiple challenges, including constrained perception and response capabilities, limited scalability, and low adaptability in dynamic environments. This tutorial provides a systematic introduction to the principles, design, and applications of Large Artificial Intelligence Models (LAMs) and Agentic AI technologies in intelligent communication systems, aiming to offer researchers a comprehensive overview of cutting-edge technologies and practical guidance. First, we outline the background of 6G communications, review the technological evolution from LAMs to Agentic AI, and clarify the tutorial's motivation and main contributions. Subsequently, we present a comprehensive review of the key components required for constructing LAMs. We further categorize LAMs and analyze their applicability, covering Large Language Models (LLMs), Large Vision Models (LVMs), Large Multimodal Models (LMMs), Large Reasoning Models (LRMs), and lightweight LAMs. Next, we propose a LAM-centric design paradigm tailored for communications, encompassing dataset construction and both internal and external learning approaches. Building upon this, we develop an LAM-based Agentic AI system for intelligent communications, clarifying its core components such as planners, knowledge bases, tools, and memory modules, as well as its interaction mechanisms. We also introduce a multi-agent framework with data retrieval, collaborative planning, and reflective evaluation for 6G. Subsequently, we provide a detailed overview of the applications of LAMs and Agentic AI in communication scenarios. Finally, we summarize the research challenges and future directions in current studies, aiming to support the development of efficient, secure, and sustainable next-generation intelligent communication systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the advent of 6G communications, intelligent communication systems facemultiple challenges, including constrained perception and responsecapabilities, limited scalability, and low adaptability in dynamicenvironments. This tutorial provides a systematic introduction to theprinciples, design, and applications of Large Artificial Intelligence Models(LAMs) and Agentic AI technologies in intelligent communication systems, aimingto offer researchers a comprehensive overview of cutting-edge technologies andpractical guidance. First, we outline the background of 6G communications,review the technological evolution from LAMs to Agentic AI, and clarify thetutorial's motivation and main contributions. Subsequently, we present acomprehensive review of the key components required for constructing LAMs. Wefurther categorize LAMs and analyze their applicability, covering LargeLanguage Models (LLMs), Large Vision Models (LVMs), Large Multimodal Models(LMMs), Large Reasoning Models (LRMs), and lightweight LAMs. Next, we propose aLAM-centric design paradigm tailored for communications, encompassing datasetconstruction and both internal and external learning approaches. Building uponthis, we develop an LAM-based Agentic AI system for intelligent communications,clarifying its core components such as planners, knowledge bases, tools, andmemory modules, as well as its interaction mechanisms. We also introduce amulti-agent framework with data retrieval, collaborative planning, andreflective evaluation for 6G. Subsequently, we provide a detailed overview ofthe applications of LAMs and Agentic AI in communication scenarios. Finally, wesummarize the research challenges and future directions in current studies,aiming to support the development of efficient, secure, and sustainablenext-generation intelligent communication systems.</description>
      <author>example@mail.com (Feibo Jiang, Cunhua Pan, Li Dong, Kezhi Wang, Octavia A. Dobre, Merouane Debbah)</author>
      <guid isPermaLink="false">2505.22311v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>RiverMamba: A State Space Model for Global River Discharge and Flood Forecasting</title>
      <link>http://arxiv.org/abs/2505.22535v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Main paper 10 pages, Appendix 53 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RiverMamba的新型深度学习模型，用于预测河流径流和洪水，该模型在早期预警方面具有高相关性。&lt;h4&gt;背景&lt;/h4&gt;现有的深度学习方法在河流径流预测方面提高了准确性和效率，但主要限于局部尺度应用，未能利用水体固有的空间联系。&lt;h4&gt;目的&lt;/h4&gt;开发新的深度学习方法，能够模拟时空关系，以改善河流径流和洪水预测。&lt;h4&gt;方法&lt;/h4&gt;RiverMamba模型使用长期再分析数据进行预训练，可以预测全球河流径流和洪水，预测范围可达0.05度网格，预测时间可达7天。&lt;h4&gt;主要发现&lt;/h4&gt;RiverMamba模型通过高效的Mamba块捕捉全球尺度水道网络路由，并增强了其长期预测能力。模型整合了ECMWF HRES气象预报，并通过时空建模考虑了预报的不准确性。&lt;h4&gt;结论&lt;/h4&gt;RiverMamba模型在预测河流径流，包括极端洪水和不同预测时间，方面提供了可靠的预测，超越了现有的基于AI和物理学的模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：最近，用于河流径流预测的深度学习方法在洪水预测中提高了准确性和效率，为风险管理提供了更可靠的早期预警系统。尽管如此，现有的水文深度学习方法在很大程度上仍然局限于局部尺度应用，并且没有利用水体固有的空间联系。因此，迫切需要新的深度学习方法，能够模拟时空关系，以改善河流径流和洪水预测，用于科学和实际应用。为了解决这个问题，我们提出了RiverMamba，这是一种新的深度学习模型，使用长期再分析数据进行预训练，能够预测全球河流径流和洪水，预测范围可达0.05度网格，预测时间可达7天，这在早期预警方面具有重要意义。为了实现这一点，RiverMamba利用高效的Mamba块，使模型能够捕捉全球尺度水道网络路由，并增强其长期预测能力。预测块整合了ECMWF HRES气象预报，并通过时空建模考虑了预报的不准确性。我们的分析表明，RiverMamba提供了可靠的河流径流预测，包括不同重现期和预测时间的极端洪水，超过了现有的基于AI和物理学的模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent deep learning approaches for river discharge forecasting have improvedthe accuracy and efficiency in flood forecasting, enabling more reliable earlywarning systems for risk management. Nevertheless, existing deep learningapproaches in hydrology remain largely confined to local-scale applications anddo not leverage the inherent spatial connections of bodies of water. Thus,there is a strong need for new deep learning methodologies that are capable ofmodeling spatio-temporal relations to improve river discharge and floodforecasting for scientific and operational applications. To address this, wepresent RiverMamba, a novel deep learning model that is pretrained withlong-term reanalysis data and that can forecast global river discharge andfloods on a $0.05^\circ$ grid up to 7 days lead time, which is of highrelevance in early warning. To achieve this, RiverMamba leverages efficientMamba blocks that enable the model to capture global-scale channel networkrouting and enhance its forecast capability for longer lead times. The forecastblocks integrate ECMWF HRES meteorological forecasts, while accounting fortheir inaccuracies through spatio-temporal modeling. Our analysis demonstratesthat RiverMamba delivers reliable predictions of river discharge, includingextreme floods across return periods and lead times, surpassing bothoperational AI- and physics-based models.</description>
      <author>example@mail.com (Mohamad Hakam Shams Eddin, Yikui Zahng, Stefan Kollet, Juergen Gall)</author>
      <guid isPermaLink="false">2505.22535v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Weakly-Supervised Contrastive Learning for Imprecise Class Labels</title>
      <link>http://arxiv.org/abs/2505.22028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  38 pages, 2 figures, 11 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于连续语义相似度的弱监督对比学习方法，通过测量示例对之间的语义相似度来定义正负对，以解决数据标注模糊或不准确的问题。&lt;h4&gt;背景&lt;/h4&gt;对比学习在有效表示学习方面取得了显著成功，但监督对比学习在实际场景中受限于数据标注的模糊性或不准确性。&lt;h4&gt;目的&lt;/h4&gt;为了解决监督对比学习在数据标注不精确情况下的局限性，提出了一种新的弱监督对比学习方法。&lt;h4&gt;方法&lt;/h4&gt;引入了“连续语义相似度”的概念，通过迭代优化弱监督信号来衡量示例对之间的语义相似度，并基于此提出了一种图理论框架。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在噪声标签和部分标签学习等场景中表现出色，理论上可以近似监督对比学习，并且代码实现已公开。&lt;h4&gt;结论&lt;/h4&gt;本文提出的弱监督对比学习方法能够有效提高学习效果，尤其是在数据标注不精确的情况下。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive learning has achieved remarkable success in learning effective representations, with supervised contrastive learning often outperforming self-supervised approaches. However, in real-world scenarios, data annotations are often ambiguous or inaccurate, meaning that class labels may not reliably indicate whether two examples belong to the same class. This limitation restricts the applicability of supervised contrastive learning. To address this challenge, we introduce the concept of 'continuous semantic similarity' to define positive and negative pairs. Instead of directly relying on imprecise class labels, we measure the semantic similarity between example pairs, which quantifies how closely they belong to the same category by iteratively refining weak supervisory signals. Based on this concept, we propose a graph-theoretic framework for weakly-supervised contrastive learning, where semantic similarity serves as the graph weights. Our framework is highly versatile and can be applied to many weakly-supervised learning scenarios. We demonstrate its effectiveness through experiments in two common settings, i.e., noisy label and partial label learning, where existing methods can be easily integrated to significantly improve performance. Theoretically, we establish an error bound for our approach, showing that it can approximate supervised contrastive learning under mild conditions. The implementation code is available at https://github.com/Speechless-10308/WSC.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning has achieved remarkable success in learning effectiverepresentations, with supervised contrastive learning often outperformingself-supervised approaches. However, in real-world scenarios, data annotationsare often ambiguous or inaccurate, meaning that class labels may not reliablyindicate whether two examples belong to the same class. This limitationrestricts the applicability of supervised contrastive learning. To address thischallenge, we introduce the concept of ``continuous semantic similarity'' todefine positive and negative pairs. Instead of directly relying on impreciseclass labels, we measure the semantic similarity between example pairs, whichquantifies how closely they belong to the same category by iteratively refiningweak supervisory signals. Based on this concept, we propose a graph-theoreticframework for weakly-supervised contrastive learning, where semantic similarityserves as the graph weights. Our framework is highly versatile and can beapplied to many weakly-supervised learning scenarios. We demonstrate itseffectiveness through experiments in two common settings, i.e., noisy label andpartial label learning, where existing methods can be easily integrated tosignificantly improve performance. Theoretically, we establish an error boundfor our approach, showing that it can approximate supervised contrastivelearning under mild conditions. The implementation code is available athttps://github.com/Speechless-10308/WSC.</description>
      <author>example@mail.com (Zi-Hao Zhou, Jun-Jie Wang, Tong Wei, Min-Ling Zhang)</author>
      <guid isPermaLink="false">2505.22028v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Graph-Assisted Culturally Adaptable Idiomatic Translation for Indic Languages</title>
      <link>http://arxiv.org/abs/2505.21937v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为IdiomCE的基于自适应图神经网络的方法，用于翻译多词表达和习语，该方法能够学习习语表达之间的复杂映射，并有效推广到训练过程中的已见和未见节点。&lt;h4&gt;背景&lt;/h4&gt;翻译多词表达和习语需要深入了解源语言和目标语言的文化细微差别，由于习语翻译的一对多特性，同一个源习语可能因文化参照和语境变化而在目标语言中有多个对应表达。&lt;h4&gt;目的&lt;/h4&gt;为了解决传统静态知识图谱和基于提示的方法在处理复杂关系时遇到的困难，提出了一种新的方法来提高习语翻译的质量。&lt;h4&gt;方法&lt;/h4&gt;IdiomCE方法通过自适应图神经网络学习习语表达之间的映射，从而在资源受限的环境中也能提高翻译质量。&lt;h4&gt;主要发现&lt;/h4&gt;在多个习语翻译数据集上使用无参考指标评估，该方法在将英语习语翻译成多种印度语言时显示出显著的改进。&lt;h4&gt;结论&lt;/h4&gt;IdiomCE方法能够有效提高习语翻译的质量，尤其是在资源受限的设置中。&lt;h4&gt;翻译&lt;/h4&gt;提出了一种新的习语翻译方法，该方法基于自适应图神经网络，能够有效处理习语翻译中的文化差异和语境变化，提高了翻译质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Translating multi-word expressions (MWEs) and idioms requires a deepunderstanding of the cultural nuances of both the source and target languages.This challenge is further amplified by the one-to-many nature of idiomatictranslations, where a single source idiom can have multiple target-languageequivalents depending on cultural references and contextual variations.Traditional static knowledge graphs (KGs) and prompt-based approaches struggleto capture these complex relationships, often leading to suboptimaltranslations. To address this, we propose IdiomCE, an adaptive graph neuralnetwork (GNN) based methodology that learns intricate mappings betweenidiomatic expressions, effectively generalizing to both seen and unseen nodesduring training. Our proposed method enhances translation quality even inresource-constrained settings, facilitating improved idiomatic translation insmaller models. We evaluate our approach on multiple idiomatic translationdatasets using reference-less metrics, demonstrating significant improvementsin translating idioms from English to various Indian languages.</description>
      <author>example@mail.com (Pratik Rakesh Singh, Kritarth Prasad, Mohammadi Zaki, Pankaj Wasnik)</author>
      <guid isPermaLink="false">2505.21937v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>New Tools are Needed for Tracking Adherence to AI Model Behavioral Use Clauses</title>
      <link>http://arxiv.org/abs/2505.22287v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基础模型对人工智能的变革性影响，分析了AI许可和风险管理机制，并提出了跟踪和遵守这些许可的工具的重要性。&lt;h4&gt;背景&lt;/h4&gt;基础模型因大量研发投入、数据来源增长和可扩展架构而具备强大能力，但对其滥用风险的担忧促使设计了限制风险的机制。&lt;h4&gt;目的&lt;/h4&gt;研究AI许可的采用情况、遵守程度，并探讨跟踪和遵守这些许可的工具的必要性。&lt;h4&gt;方法&lt;/h4&gt;创建了自定义AI许可生成器以促进许可创建，并分析了使用该工具创建的300多个定制许可以及HuggingFace模型库中的170万个模型许可。&lt;h4&gt;主要发现&lt;/h4&gt;发现这些许可的采用率在增加，对支持其创建的工具感兴趣，并且趋于采用共同的条款配置。&lt;h4&gt;结论&lt;/h4&gt;认为跟踪和遵守这些许可的工具是确保其产生预期影响的自然且迫切需要的下一步。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型对人工智能产生了变革性影响。大量研发投入、不断增长的数据来源以及与数据和计算能力相匹配的架构导致了具有强大能力的模型。资产释放对于科学进步和商业企业至关重要。然而，对AI滥用风险的担忧导致了限制技术风险的机制的设计。结果是，许可中包含行为使用条款和可接受使用政策的激增，这些政策正在被常用的模型系列（如Llama、Gemma、Deepseek）和众多小型项目越来越多地采用。我们创建并部署了一个自定义AI许可生成器以促进许可创建，并使用该工具定量和定性分析了300多个定制许可。同时，我们分析了HuggingFace模型库中的170万个模型许可。我们的结果表明，这些许可的采用率在增加，对支持其创建的工具感兴趣，并且趋于采用共同的条款配置。在这篇论文中，我们提出跟踪和遵守这些许可的工具是确保它们产生预期影响的自然且迫切需要的下一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have had a transformative impact on AI. A combination oflarge investments in research and development, growing sources of digital datafor training, and architectures that scale with data and compute has led tomodels with powerful capabilities. Releasing assets is fundamental toscientific advancement and commercial enterprise. However, concerns overnegligent or malicious uses of AI have led to the design of mechanisms to limitthe risks of the technology. The result has been a proliferation of licenseswith behavioral-use clauses and acceptable-use-policies that are increasinglybeing adopted by commonly used families of models (Llama, Gemma, Deepseek) anda myriad of smaller projects. We created and deployed a custom AI licensesgenerator to facilitate license creation and have quantitatively andqualitatively analyzed over 300 customized licenses created with this tool.Alongside this we analyzed 1.7 million models licenses on the HuggingFace modelhub. Our results show increasing adoption of these licenses, interest in toolsthat support their creation and a convergence on common clause configurations.In this paper we take the position that tools for tracking adoption of, andadherence to, these licenses is the natural next step and urgently needed inorder to ensure they have the desired impact of ensuring responsible use.</description>
      <author>example@mail.com (Daniel McDuff, Tim Korjakow, Kevin Klyman, Danish Contractor)</author>
      <guid isPermaLink="false">2505.22287v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>DORAEMON: Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation</title>
      <link>http://arxiv.org/abs/2505.21969v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DORAEMON的认知启发式框架，用于在未知环境中进行自适应导航，解决了现有视觉-语言模型在零样本情况下的局限性。&lt;h4&gt;背景&lt;/h4&gt;在未知环境中进行自适应导航对家庭服务机器人至关重要，但需要低级路径规划和高级场景理解，现有基于视觉-语言模型的零样本方法存在时空不连续性、无结构记忆表示和任务理解不足等问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的认知启发式框架，以解决现有方法的局限性，实现更有效的自适应导航。&lt;h4&gt;方法&lt;/h4&gt;DORAEMON框架包含腹侧流和背侧流，腹侧流实现层次语义-空间融合和拓扑图来处理时空不连续性，背侧流结合RAG-VLM和Policy-VLM来提高决策能力。此外，还开发了Nav-Ensurance来确保导航的安全性和效率。&lt;h4&gt;主要发现&lt;/h4&gt;在HM3D、MP3D和GOAT数据集上，DORAEMON在成功率（SR）和成功加权路径长度（SPL）指标上均达到最先进水平，显著优于现有方法。同时，引入了新的评估指标AORI来更好地评估导航智能。&lt;h4&gt;结论&lt;/h4&gt;DORAEMON在零样本自主导航方面表现出色，无需预先构建地图或进行预训练。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adaptive navigation in unfamiliar environments is crucial for householdservice robots but remains challenging due to the need for both low-level pathplanning and high-level scene understanding. While recent vision-language model(VLM) based zero-shot approaches reduce dependence on prior maps andscene-specific training data, they face significant limitations: spatiotemporaldiscontinuity from discrete observations, unstructured memory representations,and insufficient task understanding leading to navigation failures. We proposeDORAEMON (Decentralized Ontology-aware Reliable Agent with Enhanced MemoryOriented Navigation), a novel cognitive-inspired framework consisting ofVentral and Dorsal Streams that mimics human navigation capabilities. TheDorsal Stream implements the Hierarchical Semantic-Spatial Fusion and TopologyMap to handle spatiotemporal discontinuities, while the Ventral Stream combinesRAG-VLM and Policy-VLM to improve decision-making. Our approach also developsNav-Ensurance to ensure navigation safety and efficiency. We evaluate DORAEMONon the HM3D, MP3D, and GOAT datasets, where it achieves state-of-the-artperformance on both success rate (SR) and success weighted by path length (SPL)metrics, significantly outperforming existing methods. We also introduce a newevaluation metric (AORI) to assess navigation intelligence better.Comprehensive experiments demonstrate DORAEMON's effectiveness in zero-shotautonomous navigation without requiring prior map building or pre-training.</description>
      <author>example@mail.com (Tianjun Gu, Linfeng Li, Xuhong Wang, Chenghua Gong, Jingyu Gong, Zhizhong Zhang, Yuan Xie, Lizhuang Ma, Xin Tan)</author>
      <guid isPermaLink="false">2505.21969v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Fostering Video Reasoning via Next-Event Prediction</title>
      <link>http://arxiv.org/abs/2505.22457v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为next-event prediction（NEP）的学习任务，旨在通过利用未来视频片段作为自监督信号来培养MLLMs的时间推理能力。&lt;h4&gt;背景&lt;/h4&gt;现有任务如视频问答和视频字幕通常依赖于人工标注或更强大的MLLMs，而视频字幕则往往将时间推理与空间信息混为一谈。&lt;h4&gt;目的&lt;/h4&gt;旨在解决现有时间推理任务的问题，为MLLMs提供一种新的时间推理能力。&lt;h4&gt;方法&lt;/h4&gt;将视频分割为过去和未来帧，MLLM以过去帧为输入，预测未来帧中事件的总览，从而鼓励模型进行时间推理。同时，创建了一个包含33,000个自动提取视频片段的数据集V1-33K，并探索了多种视频指令微调策略，以研究它们对时间推理的影响。还引入了FutureBench来评估预测未见未来事件的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了NEP为培养MLLMs时间推理能力提供了一个可扩展且有效的训练范式。&lt;h4&gt;结论&lt;/h4&gt;NEP是一种有效的方法，可以帮助MLLMs培养时间推理能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Next-token prediction serves as the foundational learning task enabling reasoning in LLMs. But what should the learning task be when aiming to equip MLLMs with temporal reasoning capabilities over video inputs? Existing tasks such as video question answering often rely on annotations from humans or much stronger MLLMs, while video captioning tends to entangle temporal reasoning with spatial information. To address this gap, we propose next-event prediction (NEP), a learning task that harnesses future video segments as a rich, self-supervised signal to foster temporal reasoning. We segment each video into past and future frames: the MLLM takes the past frames as input and predicts a summary of events derived from the future frames, thereby encouraging the model to reason temporally in order to complete the task. To support this task, we curate V1-33K, a dataset comprising 33,000 automatically extracted video segments spanning diverse real-world scenarios. We further explore a range of video instruction-tuning strategies to study their effects on temporal reasoning. To evaluate progress, we introduce FutureBench to assess coherence in predicting unseen future events. Experiments validate that NEP offers a scalable and effective training paradigm for fostering temporal reasoning in MLLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Next-token prediction serves as the foundational learning task enablingreasoning in LLMs. But what should the learning task be when aiming to equipMLLMs with temporal reasoning capabilities over video inputs? Existing taskssuch as video question answering often rely on annotations from humans or muchstronger MLLMs, while video captioning tends to entangle temporal reasoningwith spatial information. To address this gap, we propose next-event prediction(NEP), a learning task that harnesses future video segments as a rich,self-supervised signal to foster temporal reasoning. We segment each video intopast and future frames: the MLLM takes the past frames as input and predicts asummary of events derived from the future frames, thereby encouraging the modelto reason temporally in order to complete the task. To support this task, wecurate V1-33K, a dataset comprising 33,000 automatically extracted videosegments spanning diverse real-world scenarios. We further explore a range ofvideo instruction-tuning strategies to study their effects on temporalreasoning. To evaluate progress, we introduce FutureBench to assess coherencein predicting unseen future events. Experiments validate that NEP offers ascalable and effective training paradigm for fostering temporal reasoning inMLLMs.</description>
      <author>example@mail.com (Haonan Wang, Hongfu Liu, Xiangyan Liu, Chao Du, Kenji Kawaguchi, Ye Wang, Tianyu Pang)</author>
      <guid isPermaLink="false">2505.22457v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging LLM for Stuttering Speech: A Unified Architecture Bridging Recognition and Event Detection</title>
      <link>http://arxiv.org/abs/2505.22005v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于LLM的ASR-SED多任务学习框架，用于联合优化自动语音识别和口吃事件检测任务，有效提高了在口吃语音场景下的ASR性能。&lt;h4&gt;背景&lt;/h4&gt;自动语音识别（ASR）在口吃语音场景中的性能瓶颈限制了其在语音康复等领域的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以减少口吃语音场景下ASR的错误率，并提高口吃事件检测的准确性。&lt;h4&gt;方法&lt;/h4&gt;设计了动态交互机制，其中ASR分支利用CTC生成的软提示辅助LLM上下文建模，而SED分支输出口吃嵌入以增强LLM对口吃语音的理解。此外，采用对比学习增强口吃声学特征的判别能力，并应用Focal Loss减轻口吃事件类别中的长尾分布。&lt;h4&gt;主要发现&lt;/h4&gt;在AS-70普通话口吃数据集上的评估表明，该框架将ASR字符错误率（CER）降低到5.45%，相对降低了37.71%，并实现了平均口吃事件检测F1分数为73.63%，相对提高了46.58%。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在口吃语音场景下显著提高了ASR的性能，并有效提升了口吃事件检测的准确性。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes an LLM-driven ASR-SED multi-task learning framework that jointly optimizes the ASR and Stuttering Event Detection (SED) tasks, effectively improving the performance of ASR in stuttering speech scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The performance bottleneck of Automatic Speech Recognition (ASR) instuttering speech scenarios has limited its applicability in domains such asspeech rehabilitation. This paper proposed an LLM-driven ASR-SED multi-tasklearning framework that jointly optimized the ASR and Stuttering EventDetection (SED) tasks. We proposed a dynamic interaction mechanism where theASR branch leveraged CTC-generated soft prompts to assist LLM context modeling,while the SED branch output stutter embeddings to enhance LLM comprehension ofstuttered speech. We incorporated contrastive learning to strengthen thediscriminative power of stuttering acoustic features and applied Focal Loss tomitigate the long-tailed distribution in stuttering event categories.Evaluations on the AS-70 Mandarin stuttering dataset demonstrated that ourframework reduced the ASR character error rate (CER) to 5.45% (-37.71% relativereduction) and achieved an average SED F1-score of 73.63% (+46.58% relativeimprovement).</description>
      <author>example@mail.com (Shangkun Huang, Jing Deng, Jintao Kang, Rong Zheng)</author>
      <guid isPermaLink="false">2505.22005v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>FALCON: An ML Framework for Fully Automated Layout-Constrained Analog Circuit Design</title>
      <link>http://arxiv.org/abs/2505.21923v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FALCON是一个统一的机器学习框架，用于通过拓扑选择和布局约束优化实现自动化、基于规格的模拟电路合成。&lt;h4&gt;背景&lt;/h4&gt;设计模拟电路是一个复杂的多阶段过程，包括拓扑选择、参数推断和布局可行性。&lt;h4&gt;目的&lt;/h4&gt;提高模拟电路设计的自动化程度和效率。&lt;h4&gt;方法&lt;/h4&gt;FALCON首先使用性能驱动的分类器，结合人类设计启发式方法选择合适的电路拓扑。然后，它使用一个定制的边缘中心图神经网络，该网络被训练来将电路拓扑和参数映射到性能，并通过学习的前向模型实现基于梯度的参数推断。推断过程由可微的布局成本引导，该成本来源于捕捉寄生和频率依赖效应的解析方程，并受设计规则约束。&lt;h4&gt;主要发现&lt;/h4&gt;FALCON在拓扑推断中表现出&gt;99%的准确性，在性能预测中表现出&lt;10%的相对误差，并且具有高效的布局感知设计，每个实例完成时间不到1秒。&lt;h4&gt;结论&lt;/h4&gt;FALCON是一个实用且可扩展的基础模型，适用于端到端模拟电路设计自动化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Designing analog circuits from performance specifications is a complex,multi-stage process encompassing topology selection, parameter inference, andlayout feasibility. We introduce FALCON, a unified machine learning frameworkthat enables fully automated, specification-driven analog circuit synthesisthrough topology selection and layout-constrained optimization. Given a targetperformance, FALCON first selects an appropriate circuit topology using aperformance-driven classifier guided by human design heuristics. Next, itemploys a custom, edge-centric graph neural network trained to map circuittopology and parameters to performance, enabling gradient-based parameterinference through the learned forward model. This inference is guided by adifferentiable layout cost, derived from analytical equations capturingparasitic and frequency-dependent effects, and constrained by design rules. Wetrain and evaluate FALCON on a large-scale custom dataset of 1M analog mm-wavecircuits, generated and simulated using Cadence Spectre across 20expert-designed topologies. Through this evaluation, FALCON demonstrates &gt;99\%accuracy in topology inference, &lt;10\% relative error in performance prediction,and efficient layout-aware design that completes in under 1 second perinstance. Together, these results position FALCON as a practical and extensiblefoundation model for end-to-end analog circuit design automation.</description>
      <author>example@mail.com (Asal Mehradfar, Xuzhe Zhao, Yilun Huang, Emir Ceyani, Yankai Yang, Shihao Han, Hamidreza Aghasi, Salman Avestimehr)</author>
      <guid isPermaLink="false">2505.21923v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Infer Parameterized Representations of Plants from 3D Scans</title>
      <link>http://arxiv.org/abs/2505.22337v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一的方法，用于从非结构化观测中忠实重建植物的三维结构。该方法通过训练一个递归神经网络，能够从输入的三维点云中推断出植物的参数化表示，适用于具有二元轴向树结构的任何植物。&lt;h4&gt;背景&lt;/h4&gt;重建植物的三维结构是一个具有挑战性的任务，由于器官之间的遮挡或空间邻近性，计算上存在特定问题。&lt;h4&gt;目的&lt;/h4&gt;目标是提出一种统一的方法，能够从植物的三维扫描中推断出植物的参数化表示，适用于包括重建、分割和骨架化在内的各种任务。&lt;h4&gt;方法&lt;/h4&gt;通过训练一个递归神经网络，该网络使用基于L系统的虚拟植物生成模型生成数据，从而能够从输入的三维点云中推断出参数化的树状表示。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在Chenopodium Album植物上进行了评估，实验结果表明，该统一框架可以实现包括重建、分割和骨架化在内的不同任务，且在每个任务上达到与现有技术相媲美的结果。&lt;h4&gt;结论&lt;/h4&gt;该研究为从非结构化数据中重建植物的三维结构提供了一种有效的方法，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing faithfully the 3D architecture of plants from unstructuredobservations is a challenging task. Plants frequently contain numerous organs,organized in branching systems in more or less complex spatial networks,leading to specific computational issues due to self-occlusion or spatialproximity between organs. Existing works either consider inverse modeling wherethe aim is to recover the procedural rules that allow to simulate virtualplants, or focus on specific tasks such as segmentation or skeletonization. Wepropose a unified approach that, given a 3D scan of a plant, allows to infer aparameterized representation of the plant. This representation describes theplant's branching structure, contains parametric information for each plantorgan, and can therefore be used directly in a variety of tasks. In thisdata-driven approach, we train a recursive neural network with virtual plantsgenerated using an L-systems-based procedural model. After training, thenetwork allows to infer a parametric tree-like representation based on an input3D point cloud. Our method is applicable to any plant that can be representedas binary axial tree. We evaluate our approach on Chenopodium Album plants,using experiments on synthetic plants to show that our unified framework allowsfor different tasks including reconstruction, segmentation and skeletonization,while achieving results on-par with state-of-the-art for each task.</description>
      <author>example@mail.com (Samara Ghrer, Christophe Godin, Stefanie Wuhrer)</author>
      <guid isPermaLink="false">2505.22337v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Towards Comprehensive Scene Understanding: Integrating First and Third-Person Views for LVLMs</title>
      <link>http://arxiv.org/abs/2505.21955v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种框架，用于增强以第一人称视角捕获的用户注意力信息和手-物体交互的视觉-语言模型（LVLMs），通过结合第三人称视角提供全局场景布局和物体可见性等补充信息，以提高LVLMs在空间或上下文相关查询上的表现。&lt;h4&gt;背景&lt;/h4&gt;随着虚拟和增强现实等交互式应用的兴起，头戴式摄像头捕获的第一人称视角成为关键输入。然而，这种视角的视野有限，缺乏全局上下文，导致在空间或上下文相关查询上的失败。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在通过引入第三人称视角来增强第一人称视角，为LVLMs提供更全面的信息，从而提高其在多视角推理上的性能。&lt;h4&gt;方法&lt;/h4&gt;本文提出了E3VQA，这是第一个基于同步第一人称和第三人称图像对的多视角问答基准。此外，还提出了M3CoT，一种无需训练的提示技术，通过整合来自三个互补视角的场景图来构建统一场景表示。&lt;h4&gt;主要发现&lt;/h4&gt;M3CoT使LVLMs能够更有效地跨视角进行推理，在GPT-4o和Gemini2.0 Flash上分别实现了4.84%和5.94%的性能提升。广泛评估揭示了LVLMs在多视角推理中的优势和局限性，并强调了利用第一人称和第三人称输入的价值。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和基准为LVLMs在多视角推理中的应用提供了新的思路，并通过实验验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种框架，用于增强以第一人称视角捕获的用户注意力信息和手-物体交互的视觉-语言模型（LVLMs），通过结合第三人称视角提供全局场景布局和物体可见性等补充信息，以提高LVLMs在空间或上下文相关查询上的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large vision-language models (LVLMs) are increasingly deployed in interactiveapplications such as virtual and augmented reality, where first-person(egocentric) view captured by head-mounted cameras serves as key input. Whilethis view offers fine-grained cues about user attention and hand-objectinteractions, their narrow field of view and lack of global context often leadto failures on spatially or contextually demanding queries. To address this, weintroduce a framework that augments egocentric inputs with third-person(exocentric) views, providing complementary information such as global scenelayout and object visibility to LVLMs. We present E3VQA, the first benchmarkfor multi-view question answering with 4K high-quality question-answer pairsgrounded in synchronized ego-exo image pairs. Additionally, we propose M3CoT, atraining-free prompting technique that constructs a unified scenerepresentation by integrating scene graphs from three complementaryperspectives. M3CoT enables LVLMs to reason more effectively across views,yielding consistent performance gains (4.84% for GPT-4o and 5.94% for Gemini2.0 Flash) over a recent CoT baseline. Our extensive evaluation reveals keystrengths and limitations of LVLMs in multi-view reasoning and highlights thevalue of leveraging both egocentric and exocentric inputs.</description>
      <author>example@mail.com (Insu Lee, Wooje Park, Jaeyun Jang, Minyoung Noh, Kyuhong Shim, Byonghyo Shim)</author>
      <guid isPermaLink="false">2505.21955v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Improved Approximation Algorithms for Chromatic and Pseudometric-Weighted Correlation Clustering</title>
      <link>http://arxiv.org/abs/2505.21939v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对关联聚类问题，提出了改进的近似算法。&lt;h4&gt;背景&lt;/h4&gt;关联聚类（CC）是无监督学习中的一个基础问题，它使用标记图来建模二元相似关系。然而，许多实际应用涉及更复杂的关联，如多类分类交互或边标签的不确定置信度。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文研究了两种关联聚类的一般化：着色关联聚类（CCC）和伪度量加权关联聚类。本文旨在为这两种设置开发改进的近似算法。&lt;h4&gt;方法&lt;/h4&gt;本文的方法利用基于LP的枢轴技术结合特定问题的舍入函数。对于伪度量加权关联聚类问题，提出了一种严格的10/3近似算法。对于着色关联聚类（CCC）问题，将近似比率从之前的2.5改进到2.15，并在同一分析框架内确定了2.11的下界。&lt;h4&gt;主要发现&lt;/h4&gt;对于伪度量加权关联聚类问题，算法达到了10/3的近似比，与标准LP松弛结合专用舍入所能达到的最佳界限相匹配。对于着色关联聚类（CCC）问题，改进了近似比率，并展示了结果的近最优性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的算法对于解决关联聚类问题提供了有效的近似解，特别是在处理更复杂的关系时表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Correlation Clustering (CC) is a foundational problem in unsupervisedlearning that models binary similarity relations using labeled graphs. Whileclassical CC has been widely studied, many real-world applications involve morenuanced relationships, either multi-class categorical interactions or varyingconfidence levels in edge labels. To address these, two natural generalizationshave been proposed: Chromatic Correlation Clustering (CCC), which assignssemantic colors to edge labels, and pseudometric-weighted CC, which allows edgeweights satisfying the triangle inequality. In this paper, we develop improvedapproximation algorithms for both settings. Our approach leverages LP-basedpivoting techniques combined with problem-specific rounding functions. For thepseudometric-weighted correlation clustering problem, we present a tight$10/3$-approximation algorithm, matching the best possible bound achievablewithin the framework of standard LP relaxation combined with specializedrounding. For the Chromatic Correlation Clustering (CCC) problem, we improvethe approximation ratio from the previous best of $2.5$ to $2.15$, and weestablish a lower bound of $2.11$ within the same analytical framework,highlighting the near-optimality of our result.</description>
      <author>example@mail.com (Dahoon Lee, Chenglin Fan, Euiwoong Lee)</author>
      <guid isPermaLink="false">2505.21939v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Towards Structure-aware Model for Multi-modal Knowledge Graph Completion</title>
      <link>http://arxiv.org/abs/2505.21973v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TSAM的新型多模态知识图谱补全（MMKGC）模型，该模型通过整合细粒度模态交互和主导图结构，形成高性能的MMKGC框架。&lt;h4&gt;背景&lt;/h4&gt;随着多模态信息的爆炸式增长，传统的知识图谱补全（KGC）模型无法直接应用，促使大量研究者研究多模态知识图谱补全（MMKGC）。&lt;h4&gt;目的&lt;/h4&gt;为了解决MMKGC面临的挑战，即如何处理细粒度模态信息交互和意识，以及如何在多模态知识融合中确保图结构的主导作用并处理其他模态在模态融合过程中产生的噪声。&lt;h4&gt;方法&lt;/h4&gt;TSAM模型提出了细粒度模态意识融合方法（FgMAF），使用预训练语言模型更好地捕捉不同模态的细粒度语义信息交互，并采用注意力机制实现细粒度模态意识和融合。此外，还提出了结构感知对比学习方法（SaCL），利用两种对比学习方式使其他模态与结构化模态更紧密地对齐。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，提出的TSAM模型在广泛使用的多模态数据集上显著优于现有的MMKGC模型。&lt;h4&gt;结论&lt;/h4&gt;TSAM模型在多模态知识图谱补全方面取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：知识图谱（KGs）在推动各种多媒体和人工智能应用中扮演着关键角色。然而，随着多模态信息的爆炸式增长，传统的知识图谱补全（KGC）模型无法直接应用。这吸引了大量研究者研究多模态知识图谱补全（MMKGC）。由于MMKG扩展了KG到视觉和文本领域，MMKGC面临两个主要挑战：（1）如何处理细粒度模态信息交互和意识；（2）如何在多模态知识融合中确保图结构的主导作用并处理其他模态在模态融合过程中产生的噪声。为了解决这些挑战，本文提出了一种名为TSAM的新型MMKGC模型，该模型整合了细粒度模态交互和主导图结构，形成一个高性能的MMKGC框架。具体来说，为了解决这些挑战，TSAM提出了细粒度模态意识融合方法（FgMAF），该方法使用预训练语言模型更好地捕捉不同模态的细粒度语义信息交互，并采用注意力机制实现细粒度模态意识和融合。此外，TSAM还提出了结构感知对比学习方法（SaCL），该方法利用两种对比学习方式使其他模态与结构化模态更紧密地对齐。广泛的实验表明，提出的TSAM模型在广泛使用的多模态数据集上显著优于现有的MMKGC模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge graphs (KGs) play a key role in promoting various multimedia and AIapplications. However, with the explosive growth of multi-modal information,traditional knowledge graph completion (KGC) models cannot be directly applied.This has attracted a large number of researchers to study multi-modal knowledgegraph completion (MMKGC). Since MMKG extends KG to the visual and textualdomains, MMKGC faces two main challenges: (1) how to deal with the fine-grainedmodality information interaction and awareness; (2) how to ensure the dominantrole of graph structure in multi-modal knowledge fusion and deal with the noisegenerated by other modalities during modality fusion. To address thesechallenges, this paper proposes a novel MMKGC model named TSAM, whichintegrates fine-grained modality interaction and dominant graph structure toform a high-performance MMKGC framework. Specifically, to solve the challenges,TSAM proposes the Fine-grained Modality Awareness Fusion method (FgMAF), whichuses pre-trained language models to better capture fine-grained semanticinformation interaction of different modalities and employs an attentionmechanism to achieve fine-grained modality awareness and fusion. Additionally,TSAM presents the Structure-aware Contrastive Learning method (SaCL), whichutilizes two contrastive learning approaches to align other modalities moreclosely with the structured modality. Extensive experiments show that theproposed TSAM model significantly outperforms existing MMKGC models on widelyused multi-modal datasets.</description>
      <author>example@mail.com (Linyu Li, Zhi Jin, Yichi Zhang, Dongming Jin, Chengfeng Dou, Yuanpeng He, Xuan Zhang, Haiyan Zhao)</author>
      <guid isPermaLink="false">2505.21973v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>A Graph Completion Method that Jointly Predicts Geometry and Topology Enables Effective Molecule Assembly</title>
      <link>http://arxiv.org/abs/2505.21833v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为EdGr的空间图扩散模型，该模型通过联合推理分子的几何和拓扑特性，同时预测片段位置和片段间的化学键，用于分子组装任务，并在药物设计等领域的空间图补全问题上有广泛的应用。&lt;h4&gt;背景&lt;/h4&gt;药物设计通常从寻找与蛋白质结合口袋中的特定区域形成相互作用的化学小团体或片段开始，然后将这些片段组装成具有高亲和力的分子是一项挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种能够联合几何和拓扑预测来有效完成分子组装任务的模型。&lt;h4&gt;方法&lt;/h4&gt;提出了EdGr模型，该模型在扩散去噪过程中同时预测片段位置和片段间的化学键，并允许连接性线索指导空间移动。&lt;h4&gt;主要发现&lt;/h4&gt;EdGr在分子组装任务上显著优于先前的方法，并且在噪声水平增加时仍保持稳健的性能。&lt;h4&gt;结论&lt;/h4&gt;EdGr模型不仅适用于药物发现，其明确耦合几何和拓扑预测的方法还适用于其他空间图补全问题，如神经网络重构、3D场景理解和传感器网络设计。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A common starting point for drug design is to find small chemical groups or"fragments" that form interactions with distinct subregions in a proteinbinding pocket. The subsequent challenge is to assemble these fragments into amolecule that has high affinity to the protein, by adding chemical bondsbetween atoms in different fragments. This "molecule assembly" task isparticularly challenging because, initially, fragment positions are known onlyapproximately. Prior methods for spatial graph completion-adding missing edgesto a graph whose nodes have associated spatial coordinates-either treat nodepositions as fixed or adjust node positions before predicting edges. The factthat these methods treat geometry and topology prediction separately limitstheir ability to reconcile noisy geometries and plausible connectivities. Toaddress this limitation, we introduce EdGr, a spatial graph diffusion modelthat reasons jointly over geometry and topology of molecules to simultaneouslypredict fragment positions and inter-fragment bonds. Importantly, predictededge likelihoods directly influence node position updates during the diffusiondenoising process, allowing connectivity cues to guide spatial movements, andvice versa. EdGr substantially outperforms previous methods on the moleculeassembly task and maintains robust performance as noise levels increase. Beyonddrug discovery, our approach of explicitly coupling geometry and topologyprediction is broadly applicable to spatial graph completion problems, such asneural circuit reconstruction, 3D scene understanding, and sensor networkdesign.</description>
      <author>example@mail.com (Rohan V. Koodli, Alexander S. Powers, Ayush Pandit, Chiho Im, Ron O. Dror)</author>
      <guid isPermaLink="false">2505.21833v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>A Joint Reconstruction-Triplet Loss Autoencoder Approach Towards Unseen Attack Detection in IoV Networks</title>
      <link>http://arxiv.org/abs/2505.21703v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in the IEEE Internet of Things Journal  (IoT-J)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了物联网车辆（IoV）系统的安全问题，提出了一种基于无监督自动编码器的方法，用于检测IoV网络中的未知攻击。&lt;h4&gt;背景&lt;/h4&gt;IoV系统在提高交通效率和安全性方面取得了显著进步，但其高度互联性也带来了巨大的安全漏洞。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效检测IoV网络中未知攻击的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于无监督自动编码器的方法，该方法完全基于良性网络数据进行训练，并利用重建和三元组边缘损失的加权组合来指导自动编码器的训练。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在未知攻击类型上表现出鲁棒性，在良性数据上准确率达到99%，在异常数据上的性能在97%到100%之间。此外，通过迁移学习，模型能够适应不同领域，实现类似的高性能。&lt;h4&gt;结论&lt;/h4&gt;该方法为IoV网络中的未知攻击检测提供了一种有效手段，并且具有跨领域的适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Internet of Vehicles (IoV) systems, while offering significant advancementsin transportation efficiency and safety, introduce substantial securityvulnerabilities due to their highly interconnected nature. These dynamicsystems produce massive amounts of data between vehicles, infrastructure, andcloud services and present a highly distributed framework with a wide attacksurface. In considering network-centered attacks on IoV systems, attacks suchas Denial-of-Service (DoS) can prohibit the communication of essential physicaltraffic safety information between system elements, illustrating that thesecurity concerns for these systems go beyond the traditional confidentiality,integrity, and availability concerns of enterprise systems. Given thecomplexity and volume of data generated by IoV systems, traditional securitymechanisms are often inadequate for accurately detecting sophisticated andevolving cyberattacks. Here, we present an unsupervised autoencoder methodtrained entirely on benign network data for the purpose of unseen attackdetection in IoV networks. We leverage a weighted combination of reconstructionand triplet margin loss to guide the autoencoder training and develop a diverserepresentation of the benign training set. We conduct extensive experiments onrecent network intrusion datasets from two different application domains,industrial IoT and home IoT, that represent the modern IoV task. We show thatour method performs robustly for all unseen attack types, with roughly 99%accuracy on benign data and between 97% and 100% performance on anomaly data.We extend these results to show that our model is adaptable through the use oftransfer learning, achieving similarly high results while leveraging domainfeatures from one domain to another.</description>
      <author>example@mail.com (Julia Boone, Tolunay Seyfi, Fatemeh Afghah)</author>
      <guid isPermaLink="false">2505.21703v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Compositional Scene Understanding through Inverse Generative Modeling</title>
      <link>http://arxiv.org/abs/2505.21780v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025, Webpage:  https://energy-based-model.github.io/compositional-inference/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了生成模型在合成视觉内容和理解场景属性方面的应用。通过构建由小模型组成的视觉生成模型，实现了对场景结构的推断，并展示了其在多对象感知和全局场景因素推断上的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;生成模型在生成高保真视觉内容方面表现出色。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用生成模型不仅合成视觉内容，还能理解自然图像中场景的属性。&lt;h4&gt;方法&lt;/h4&gt;将场景理解视为逆生成建模问题，通过寻找视觉生成模型的条件参数以最佳拟合给定自然图像。此外，提出从场景的各个部分构建由较小模型组成的视觉生成模型，以推断与训练时图像显著不同的图像中的场景结构。&lt;h4&gt;主要发现&lt;/h4&gt;该研究展示了如何通过此方法推断场景中的对象集合，并使模型对具有更多新形状对象的新测试场景具有鲁棒性。此外，该方法还能推断全局场景因素，同样提高了对新场景的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该方法可以直接应用于现有的预训练文本到图像生成模型，实现零样本多对象感知。&lt;h4&gt;翻译&lt;/h4&gt;Generative models have demonstrated remarkable abilities in generating high-fidelity visual content. In this work, we explore how generative models can further be used not only to synthesize visual content but also to understand the properties of a scene given a natural image. We formulate scene understanding as an inverse generative modeling problem, where we seek to find conditional parameters of a visual generative model to best fit a given natural image. To enable this procedure to infer scene structure from images substantially different than those seen during training, we further propose to build this visual generative model compositionally from smaller models over pieces of a scene. We illustrate how this procedure enables us to infer the set of objects in a scene, enabling robust generalization to new test scenes with an increased number of objects of new shapes. We further illustrate how this enables us to infer global scene factors, likewise enabling robust generalization to new scenes. Finally, we illustrate how this approach can be directly applied to existing pretrained text-to-image generative models for zero-shot multi-object perception. Code and visualizations are at https://energy-based-model.github.io/compositional-inference.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative models have demonstrated remarkable abilities in generatinghigh-fidelity visual content. In this work, we explore how generative modelscan further be used not only to synthesize visual content but also tounderstand the properties of a scene given a natural image. We formulate sceneunderstanding as an inverse generative modeling problem, where we seek to findconditional parameters of a visual generative model to best fit a given naturalimage. To enable this procedure to infer scene structure from imagessubstantially different than those seen during training, we further propose tobuild this visual generative model compositionally from smaller models overpieces of a scene. We illustrate how this procedure enables us to infer the setof objects in a scene, enabling robust generalization to new test scenes withan increased number of objects of new shapes. We further illustrate how thisenables us to infer global scene factors, likewise enabling robustgeneralization to new scenes. Finally, we illustrate how this approach can bedirectly applied to existing pretrained text-to-image generative models forzero-shot multi-object perception. Code and visualizations are at\href{https://energy-based-model.github.io/compositional-inference}{https://energy-based-model.github.io/compositional-inference}.</description>
      <author>example@mail.com (Yanbo Wang, Justin Dauwels, Yilun Du)</author>
      <guid isPermaLink="false">2505.21780v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>LLMPR: A Novel LLM-Driven Transfer Learning based Petition Ranking Model</title>
      <link>http://arxiv.org/abs/2505.21689v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 5 figures, journal paper, submitted to AI and Law&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于大型语言模型的自动框架LLMPR，用于对法律请愿书进行优先级排序，以提高司法效率并减少案件积压。&lt;h4&gt;背景&lt;/h4&gt;印度司法系统中未解决的案件持续积累，手动优先级排序方法效率低下且主观偏见严重，导致案件处理延迟。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的自动化的法律请愿书排序方法。&lt;h4&gt;方法&lt;/h4&gt;使用ILDC数据集，包含7,593个标注的请愿书，通过DistilBERT、LegalBERT和MiniLM等嵌入技术处理非结构化法律文本并提取特征。结合定量指标如逾期天数、排名分数和单词计数，训练了多个机器学习模型，包括随机森林、决策树、XGBoost、LightGBM和CatBoost。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，随机森林和决策树模型性能优异，准确率超过99%，Spearman秩相关系数为0.99。仅使用数值特征的模型几乎达到最佳排序结果（R2 = 0.988，θ = 0.998），而基于LLM的嵌入只带来微小的改进。&lt;h4&gt;结论&lt;/h4&gt;自动化的请愿书排序可以有效地优化司法工作流程，减少案件积压，并提高法律优先级分配的公平性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：未解决的案件在印度司法系统中的持续积累，尤其是对司法正义的及时交付造成了严重阻碍。手动优先级排序方法往往效率低下且存在主观偏见，进一步加剧了延迟。为了解决这个问题，我们提出了基于大型语言模型的请愿书排序（LLMPR）框架，该框架利用迁移学习和机器学习技术，根据请愿书的紧迫性上下文为其分配优先级排名。利用包含7,593个标注请愿书的ILDC数据集，我们通过各种嵌入技术，包括DistilBERT、LegalBERT和MiniLM等，处理非结构化法律文本并提取特征。将这些文本嵌入与定量指标（如逾期天数、排名分数和单词计数）相结合，训练了多个机器学习模型，包括随机森林、决策树、XGBoost、LightGBM和CatBoost。我们的实验表明，随机森林和决策树模型表现出优异的性能，准确率超过99%，Spearman秩相关系数为0.99。值得注意的是，仅使用数值特征的模型几乎达到了最佳的排序结果（R2 = 0.988，θ = 0.998），而基于LLM的嵌入只带来了微小的改进。这些发现表明，自动化的请愿书排序可以有效地优化司法工作流程，减少案件积压，并提高法律优先级分配的公平性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The persistent accumulation of unresolved legal cases, especially within theIndian judiciary, significantly hampers the timely delivery of justice. Manualmethods of prioritizing petitions are often prone to inefficiencies andsubjective biases further exacerbating delays. To address this issue, wepropose LLMPR (Large Language Model-based Petition Ranking), an automatedframework that utilizes transfer learning and machine learning to assignpriority rankings to legal petitions based on their contextual urgency.Leveraging the ILDC dataset comprising 7,593 annotated petitions, we processunstructured legal text and extract features through various embeddingtechniques, including DistilBERT, LegalBERT, and MiniLM. These textualembeddings are combined with quantitative indicators such as gap days, rankscores, and word counts to train multiple machine learning models, includingRandom Forest, Decision Tree, XGBoost, LightGBM, and CatBoost. Our experimentsdemonstrate that Random Forest and Decision Tree models yield superiorperformance, with accuracy exceeding 99% and a Spearman rank correlation of0.99. Notably, models using only numerical features achieve nearly optimalranking results (R2 = 0.988, \r{ho} = 0.998), while LLM-based embeddings offeronly marginal gains. These findings suggest that automated petition ranking caneffectively streamline judicial workflows, reduce case backlog, and improvefairness in legal prioritization.</description>
      <author>example@mail.com (Avijit Gayen, Somyajit Chakraborty, Mainak Sen, Soham Paul, Angshuman Jana)</author>
      <guid isPermaLink="false">2505.21689v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Training-free Open-Vocabulary Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2505.22209v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了无监督语义分割领域的研究历史、方法发展、当前状态和未来研究方向。&lt;h4&gt;背景&lt;/h4&gt;语义分割是图像理解中的基础任务，传统方法需要大量计算资源和训练数据，而开放词汇语义分割需要大量精细标注的数据。&lt;h4&gt;目的&lt;/h4&gt;介绍无监督开放词汇语义分割领域，特别是利用现有多模态分类模型的方法。&lt;h4&gt;方法&lt;/h4&gt;回顾了30多种方法，分为基于CLIP、利用辅助视觉基础模型和基于生成方法三大类，并讨论了当前研究的局限性和未来研究方向。&lt;h4&gt;主要发现&lt;/h4&gt;无监督开放词汇语义分割领域存在多种方法，包括基于CLIP、辅助视觉基础模型和生成方法等。&lt;h4&gt;结论&lt;/h4&gt;本文为该领域的新研究者提供了入门读物，并激发了该领域的研究兴趣。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语义分割是图像理解中最基本的任务之一，具有悠久的研究历史和众多不同的方法。传统方法试图从头开始训练模型，需要大量的计算资源和训练数据。随着向开放词汇语义分割的转变，即要求模型对超出学习类别的对象进行分类，大量精细标注的数据将变得过于昂贵。研究人员转而采用无需训练的方法，利用为更容易获取数据的任务而构建的现有模型。具体来说，这项调查将涵盖利用现有多模态分类模型进行无监督开放词汇语义分割的历史、细微差别、思想发展和最先进的技术。我们将首先介绍任务定义，然后概述流行的模型架构，接着重点介绍30多种方法，这些方法分为更广泛的研究分支：纯CLIP基础、利用辅助视觉基础模型和依赖生成方法的方法。随后，我们将讨论当前研究的局限性和潜在问题，以及为未来研究提供一些未充分探索的想法。我们相信这项调查将为新研究者提供良好的入门读物，并激发对该领域的研究兴趣。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic segmentation is one of the most fundamental tasks in imageunderstanding with a long history of research, and subsequently a myriad ofdifferent approaches. Traditional methods strive to train models up fromscratch, requiring vast amounts of computational resources and training data.In the advent of moving to open-vocabulary semantic segmentation, which asksmodels to classify beyond learned categories, large quantities of finelyannotated data would be prohibitively expensive. Researchers have insteadturned to training-free methods where they leverage existing models made fortasks where data is more easily acquired. Specifically, this survey will coverthe history, nuance, idea development and the state-of-the-art in training-freeopen-vocabulary semantic segmentation that leverages existing multi-modalclassification models. We will first give a preliminary on the task definitionfollowed by an overview of popular model archetypes and then spotlight over 30approaches split into broader research branches: purely CLIP-based, thoseleveraging auxiliary visual foundation models and ones relying on generativemethods. Subsequently, we will discuss the limitations and potential problemsof current research, as well as provide some underexplored ideas for futurestudy. We believe this survey will serve as a good onboarding read to newresearchers and spark increased interest in the area.</description>
      <author>example@mail.com (Naomi Kombol, Ivan Martinović, Siniša Šegvić)</author>
      <guid isPermaLink="false">2505.22209v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>LiDARDustX: A LiDAR Dataset for Dusty Unstructured Road Environments</title>
      <link>http://arxiv.org/abs/2505.21914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了LiDARDustX数据集，用于在高度粉尘条件下进行感知任务，如采矿区域的环境。&lt;h4&gt;背景&lt;/h4&gt;现有自动驾驶数据集主要关注结构化城市环境，限制了在非结构化和特定场景，尤其是有大量粉尘的情景下的探索。&lt;h4&gt;目的&lt;/h4&gt;LiDARDustX数据集旨在提供一个评估最先进3D检测和分割算法性能的基准，并分析粉尘对感知准确性的影响及其原因。&lt;h4&gt;方法&lt;/h4&gt;LiDARDustX数据集由30,000个由六个不同LiDAR传感器捕获的LiDAR帧组成，每个帧都有3D边界框注释和点云语义分割。超过80%的数据集包含受粉尘影响的场景。&lt;h4&gt;主要发现&lt;/h4&gt;该数据集为评估最先进3D检测和分割算法提供了基准，并揭示了粉尘对感知准确性的影响。&lt;h4&gt;结论&lt;/h4&gt;LiDARDustX数据集对于在高度粉尘条件下验证智能车辆算法的进步具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces the LiDARDustX dataset, which is specifically designed for perception tasks under high-dust conditions, such as those encountered in mining areas. The LiDARDustX dataset consists of 30,000 LiDAR frames captured by six different LiDAR sensors, each accompanied by 3D bounding box annotations and point cloud semantic segmentation. Notably, over 80% of the dataset comprises dust-affected scenes. By utilizing this dataset, we have established a benchmark for evaluating the performance of state-of-the-art 3D detection and segmentation algorithms. Additionally, we have analyzed the impact of dust on perception accuracy and delved into the causes of these effects. The data and further information can be accessed at: https://github.com/vincentweikey/LiDARDustX.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous driving datasets are essential for validating the progress ofintelligent vehicle algorithms, which include localization, perception, andprediction. However, existing datasets are predominantly focused on structuredurban environments, which limits the exploration of unstructured andspecialized scenarios, particularly those characterized by significant dustlevels. This paper introduces the LiDARDustX dataset, which is specificallydesigned for perception tasks under high-dust conditions, such as thoseencountered in mining areas. The LiDARDustX dataset consists of 30,000 LiDARframes captured by six different LiDAR sensors, each accompanied by 3D boundingbox annotations and point cloud semantic segmentation. Notably, over 80% of thedataset comprises dust-affected scenes. By utilizing this dataset, we haveestablished a benchmark for evaluating the performance of state-of-the-art 3Ddetection and segmentation algorithms. Additionally, we have analyzed theimpact of dust on perception accuracy and delved into the causes of theseeffects. The data and further information can be accessed at:https://github.com/vincentweikey/LiDARDustX.</description>
      <author>example@mail.com (Chenfeng Wei, Qi Wu, Si Zuo, Jiahua Xu, Boyang Zhao, Zeyu Yang, Guotao Xie, Shenhong Wang)</author>
      <guid isPermaLink="false">2505.21914v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>P-DROP: Poisson-Based Dropout for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2505.21783v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对图神经网络（GNNs）中的过度平滑问题提出了一种基于泊松过程的节点选择策略，通过引入结构感知的随机更新来提高节点的判别能力。&lt;h4&gt;背景&lt;/h4&gt;过度平滑是图神经网络（GNNs）中的一个主要挑战，重复的消息传递导致节点表示收敛并失去判别能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的节点选择策略以解决GNNs中的过度平滑问题。&lt;h4&gt;方法&lt;/h4&gt;该方法为每个节点配备一个独立的泊松时钟，实现异步和局部更新，以保持结构多样性。策略应用于两种场景：作为基于dropout的正则化的替代方案，以及作为动态子图训练方案。&lt;h4&gt;主要发现&lt;/h4&gt;在标准基准（Cora、Citeseer、Pubmed）上的实验结果表明，与传统的Dropout、DropEdge和DropNode方法相比，基于泊松的方法在后期训练阶段具有竞争力或改进的准确率。&lt;h4&gt;结论&lt;/h4&gt;基于泊松过程的节点选择策略能够有效提高GNNs的准确率，特别是在训练的后期阶段。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Over-smoothing remains a major challenge in Graph Neural Networks (GNNs),where repeated message passing causes node representations to converge and losediscriminative power. To address this, we propose a novel node selectionstrategy based on Poisson processes, introducing stochastic but structure-awareupdates. Specifically, we equip each node with an independent Poisson clock,enabling asynchronous and localized updates that preserve structural diversity.We explore two applications of this strategy: as a replacement fordropout-based regularization and as a dynamic subgraph training scheme.Experimental results on standard benchmarks (Cora, Citeseer, Pubmed)demonstrate that our Poisson-based method yields competitive or improvedaccuracy compared to traditional Dropout, DropEdge, and DropNode approaches,particularly in later training stages.</description>
      <author>example@mail.com (Hyunsik Yun)</author>
      <guid isPermaLink="false">2505.21783v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Something's Fishy In The Data Lake: A Critical Re-evaluation of Table Union Search Benchmarks</title>
      <link>http://arxiv.org/abs/2505.21329v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted @ ACL 2025's Table Representation Learning Workshop (TRL)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文分析了当前表格联合搜索（TUS）方法的基准测试，发现现有基准存在局限性，导致简单基线表现良好，甚至超越复杂方法。作者提出了未来基准测试的必要标准，以实现更真实和可靠的语义表格联合搜索进展评估。&lt;h4&gt;背景&lt;/h4&gt;表格联合搜索（TUS）是数据湖中的一项任务，涉及识别可以与给定查询表联合的表格以丰富其内容。现有的方法通常使用基准测试来评估其在现实世界TUS任务中的语义理解能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有基准测试的局限性，作者提出了未来基准测试的必要标准。&lt;h4&gt;方法&lt;/h4&gt;作者分析了现有的TUS基准测试，并提出了改进基准测试的建议。&lt;h4&gt;主要发现&lt;/h4&gt;现有的基准测试存在局限性，导致简单基线表现良好，且这些基线往往在基准测试中优于更复杂的方法。&lt;h4&gt;结论&lt;/h4&gt;当前基准测试的得分受到数据集特定特征的影响，无法有效隔离语义理解的增益。&lt;h4&gt;翻译&lt;/h4&gt;This paper analyzes the current benchmarks of table union search (TUS) methods, finds that the existing benchmarks have limitations, causing simple baselines to perform surprisingly well, often outperforming more sophisticated approaches. The authors propose essential criteria for future benchmarks to enable a more realistic and reliable evaluation of progress in semantic table union search.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent table representation learning and data discovery methods tackle tableunion search (TUS) within data lakes, which involves identifying tables thatcan be unioned with a given query table to enrich its content. These methodsare commonly evaluated using benchmarks that aim to assess semanticunderstanding in real-world TUS tasks. However, our analysis of prominent TUSbenchmarks reveals several limitations that allow simple baselines to performsurprisingly well, often outperforming more sophisticated approaches. Thissuggests that current benchmark scores are heavily influenced bydataset-specific characteristics and fail to effectively isolate the gains fromsemantic understanding. To address this, we propose essential criteria forfuture benchmarks to enable a more realistic and reliable evaluation ofprogress in semantic table union search.</description>
      <author>example@mail.com (Allaa Boutaleb, Bernd Amann, Hubert Naacke, Rafael Angarita)</author>
      <guid isPermaLink="false">2505.21329v2</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Optimizing Deep Learning for Skin Cancer Classification: A Computationally Efficient CNN with Minimal Accuracy Trade-Off</title>
      <link>http://arxiv.org/abs/2505.21597v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, &amp; 7 Images&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种定制化的CNN模型，在保持高分类准确率的同时，显著减少了参数数量和计算成本，适用于资源受限的环境。&lt;h4&gt;背景&lt;/h4&gt;深度学习在医学图像分析中的应用提高了皮肤癌分类的准确性，但现有的基于迁移学习的模型计算开销大，不适用于资源受限的环境。&lt;h4&gt;目的&lt;/h4&gt;研究提出一种新的CNN模型，以减少参数数量和计算成本，同时保持皮肤癌分类的准确性。&lt;h4&gt;方法&lt;/h4&gt;通过构建一个轻量级的CNN模型，与ResNet50等现有模型进行比较，并在HAM10000数据集上进行实证分析。&lt;h4&gt;主要发现&lt;/h4&gt;新的CNN模型将参数数量减少了96.7%，同时保持了小于0.022%的分类准确率偏差；迁移学习模型虽然提高了约0.022%的准确性，但FLOPs增加了13,216.76%，显著提高了计算成本和推理延迟。&lt;h4&gt;结论&lt;/h4&gt;新的CNN模型在保持高准确率的同时，显著降低了计算成本和推理延迟，是移动和边缘皮肤癌诊断的实用解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：深度学习在医学图像分析中的快速发展极大地提高了皮肤癌分类的准确性。然而，当前最先进的模型，尤其是基于迁移学习的模型，如ResNet50，伴随着巨大的计算开销，使得它们在资源受限的环境中部署变得不切实际。本研究提出了一种定制的CNN模型，在参数数量上实现了96.7%的减少（从ResNet50的2390万减少到692,000），同时保持了小于0.022%的分类准确率偏差。我们对HAM10000数据集的实证分析表明，尽管迁移学习模型提供了约0.022%的边际准确性提升，但它们导致了FLOPs的惊人增长13,216.76%，大大提高了计算成本和推理延迟。相比之下，我们的轻量级CNN架构，与ResNet50的400亿相比，仅包含3004万FLOPs，显著降低了能耗、内存占用和推理时间。这些发现强调了深度模型复杂性与现实可行性之间的权衡，将我们的优化CNN定位为移动和边缘皮肤癌诊断的实用解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of deep learning in medical image analysis has greatlyenhanced the accuracy of skin cancer classification. However, currentstate-of-the-art models, especially those based on transfer learning likeResNet50, come with significant computational overhead, rendering themimpractical for deployment in resource-constrained environments. This studyproposes a custom CNN model that achieves a 96.7\% reduction in parameters(from 23.9 million in ResNet50 to 692,000) while maintaining a classificationaccuracy deviation of less than 0.022\%. Our empirical analysis of the HAM10000dataset reveals that although transfer learning models provide a marginalaccuracy improvement of approximately 0.022\%, they result in a staggering13,216.76\% increase in FLOPs, considerably raising computational costs andinference latency. In contrast, our lightweight CNN architecture, whichencompasses only 30.04 million FLOPs compared to ResNet50's 4.00 billion,significantly reduces energy consumption, memory footprint, and inference time.These findings underscore the trade-off between the complexity of deep modelsand their real-world feasibility, positioning our optimized CNN as a practicalsolution for mobile and edge-based skin cancer diagnostics.</description>
      <author>example@mail.com (Abdullah Al Mamun, Pollob Chandra Ray, Md Rahat Ul Nasib, Akash Das, Jia Uddin, Md Nurul Absur)</author>
      <guid isPermaLink="false">2505.21597v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning</title>
      <link>http://arxiv.org/abs/2505.21863v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GETReason的框架，用于从公开事件图像中提取重要信息，以增强对图像重要性的理解。&lt;h4&gt;背景&lt;/h4&gt;公开事件图像中包含对新闻和教育有价值的背景信息，但现有方法在准确提取这些相关性方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出GETReason框架，以超越表面图像描述，推断更深层次的背景意义。&lt;h4&gt;方法&lt;/h4&gt;引入GREAT指标来评估基于推理的图像理解，并采用分层多智能体方法，通过推理加权指标进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;通过提取全局事件、时间和地理空间信息，可以有效地将图像与其更广泛的事件背景联系起来。&lt;h4&gt;结论&lt;/h4&gt;GETReason框架能够从图像中推断出有意义的见解，有效提升了图像理解的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Publicly significant images from events hold valuable contextual information, crucial for journalism and education. However, existing methods often struggle to extract this relevance accurately. To address this, we introduce GETReason (Geospatial Event Temporal Reasoning), a framework that moves beyond surface-level image descriptions to infer deeper contextual meaning. We propose that extracting global event, temporal, and geospatial information enhances understanding of an image's significance. Additionally, we introduce GREAT (Geospatial Reasoning and Event Accuracy with Temporal Alignment), a new metric for evaluating reasoning-based image understanding. Our layered multi-agent approach, assessed using a reasoning-weighted metric, demonstrates that meaningful insights can be inferred, effectively linking images to their broader event context.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Publicly significant images from events hold valuable contextual information,crucial for journalism and education. However, existing methods often struggleto extract this relevance accurately. To address this, we introduce GETReason(Geospatial Event Temporal Reasoning), a framework that moves beyondsurface-level image descriptions to infer deeper contextual meaning. We proposethat extracting global event, temporal, and geospatial information enhancesunderstanding of an image's significance. Additionally, we introduce GREAT(Geospatial Reasoning and Event Accuracy with Temporal Alignment), a new metricfor evaluating reasoning-based image understanding. Our layered multi-agentapproach, assessed using a reasoning-weighted metric, demonstrates thatmeaningful insights can be inferred, effectively linking images to theirbroader event context.</description>
      <author>example@mail.com (Shikhhar Siingh, Abhinav Rawat, Vivek Gupta, Chitta Baral)</author>
      <guid isPermaLink="false">2505.21863v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>EPiC: Efficient Video Camera Control Learning with Precise Anchor-Video Guidance</title>
      <link>http://arxiv.org/abs/2505.21876v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://zunwang1.github.io/Epic&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;EPiC是一个高效且精确的3D摄像机控制学习框架，能够自动构建高质量的锚视频，用于视频扩散模型（VDMs）的训练，无需昂贵的摄像机轨迹标注。&lt;h4&gt;背景&lt;/h4&gt;现有的3D摄像机控制在视频扩散模型中，通常通过渲染估计点云并遵循标注的摄像机轨迹来创建锚视频，但点云估计的误差和摄像机轨迹标注的资源需求限制了这种方法。&lt;h4&gt;目的&lt;/h4&gt;解决现有3D摄像机控制方法中的误差和资源需求问题。&lt;h4&gt;方法&lt;/h4&gt;EPiC通过基于首帧可见性的源视频掩码创建高精度的锚视频，并引入了轻量级的条件模块Anchor-ControlNet，该模块在可见区域集成锚视频指导，以减少参数数量。&lt;h4&gt;主要发现&lt;/h4&gt;EPiC在RealEstate10K和MiraData数据集上实现了SOTA性能，展现了精确和鲁棒的摄像机控制能力，并且具有强大的零样本泛化能力。&lt;h4&gt;结论&lt;/h4&gt;EPiC通过创新的锚视频构建和条件模块，实现了对3D摄像机控制的精确控制，并且能够适应视频到视频的场景，是一种高效且鲁棒的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近期关于视频扩散模型（VDMs）中的3D摄像机控制方法，常常通过创建锚视频来引导扩散模型，作为结构化先验，通过渲染从估计的点云遵循标注的摄像机轨迹。然而，点云估计固有的误差常常导致锚视频不准确。此外，对大量摄像机轨迹标注的需求进一步增加了资源需求。为了解决这些限制，我们引入了EPiC，这是一个高效且精确的摄像机控制学习框架，能够自动构建高质量的锚视频，而无需昂贵的摄像机轨迹标注。具体来说，我们通过基于首帧可见性的源视频掩码创建用于训练的高精度锚视频。这种方法确保了高一致性，消除了对摄像机轨迹标注的需求，因此可以轻松应用于任何自然场景中的视频以生成图像到视频（I2V）训练对。此外，我们引入了Anchor-ControlNet，这是一个轻量级的条件模块，它将锚视频指导集成到预训练的VDMs的可见区域中，参数少于骨干模型参数的1%。通过结合所提出的锚视频数据和ControlNet模块，EPiC实现了具有显著减少参数、训练步骤和数据量的高效训练，无需对通常用于缓解渲染错位的扩散模型骨干进行修改。尽管在基于掩码的锚视频上进行训练，但我们的方法在推理时对使用点云制作的锚视频具有鲁棒的泛化能力，从而实现了精确的3D信息摄像机控制。EPiC在RealEstate10K和MiraData数据集上实现了I2V摄像机控制任务的SOTA性能，在定性和定量上都展示了精确和鲁棒的摄像机控制能力。值得注意的是，EPiC还表现出强大的零样本泛化能力，适用于视频到视频场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent approaches on 3D camera control in video diffusion models (VDMs) oftencreate anchor videos to guide diffusion models as a structured prior byrendering from estimated point clouds following annotated camera trajectories.However, errors inherent in point cloud estimation often lead to inaccurateanchor videos. Moreover, the requirement for extensive camera trajectoryannotations further increases resource demands. To address these limitations,we introduce EPiC, an efficient and precise camera control learning frameworkthat automatically constructs high-quality anchor videos without expensivecamera trajectory annotations. Concretely, we create highly precise anchorvideos for training by masking source videos based on first-frame visibility.This approach ensures high alignment, eliminates the need for camera trajectoryannotations, and thus can be readily applied to any in-the-wild video togenerate image-to-video (I2V) training pairs. Furthermore, we introduceAnchor-ControlNet, a lightweight conditioning module that integrates anchorvideo guidance in visible regions to pretrained VDMs, with less than 1% ofbackbone model parameters. By combining the proposed anchor video data andControlNet module, EPiC achieves efficient training with substantially fewerparameters, training steps, and less data, without requiring modifications tothe diffusion model backbone typically needed to mitigate renderingmisalignments. Although being trained on masking-based anchor videos, ourmethod generalizes robustly to anchor videos made with point clouds duringinference, enabling precise 3D-informed camera control. EPiC achieves SOTAperformance on RealEstate10K and MiraData for I2V camera control task,demonstrating precise and robust camera control ability both quantitatively andqualitatively. Notably, EPiC also exhibits strong zero-shot generalization tovideo-to-video scenarios.</description>
      <author>example@mail.com (Zun Wang, Jaemin Cho, Jialu Li, Han Lin, Jaehong Yoon, Yue Zhang, Mohit Bansal)</author>
      <guid isPermaLink="false">2505.21876v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Visual Loop Closure Detection Through Deep Graph Consensus</title>
      <link>http://arxiv.org/abs/2505.21754v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LoopGNN的图神经网络架构，用于视觉环闭合检测，通过考虑多个关键帧的邻域来检测环闭合，以解决传统方法在在线同步定位与建图场景下的计算资源限制问题。&lt;h4&gt;背景&lt;/h4&gt;传统的视觉环闭合检测依赖于位置识别方法，并通过计算代价高昂的RANSAC几何验证来验证候选环闭合，这在大规模候选环验证中受到时间和计算资源的限制。&lt;h4&gt;目的&lt;/h4&gt;提高环闭合检测的精度和召回率，同时减少计算成本。&lt;h4&gt;方法&lt;/h4&gt;LoopGNN通过利用位置识别检索到的视觉相似关键帧的团，在团中的节点间传播深度特征编码，以估计环闭合一致性。&lt;h4&gt;主要发现&lt;/h4&gt;LoopGNN在TartanDrive 2.0和NCLT数据集上的实验表明，其性能优于传统基准方法。消融研究显示，该方法对深度特征编码的类型不敏感，且比经典几何验证基准具有更高的计算效率。&lt;h4&gt;结论&lt;/h4&gt;LoopGNN是一种有效的视觉环闭合检测方法，具有高精度、高召回率和高效的计算性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：传统的视觉环闭合检测依赖于位置识别方法来检索候选环，并通过计算昂贵的基于RANSAC的几何验证来验证。由于错误的阳性环闭合会显著降低下游姿态图估计，在线同步定位与建图场景中验证大量候选环受到有限时间和计算资源的限制。虽然大多数深度环闭合检测方法仅操作于关键帧对，但我们通过在检测环时考虑多个关键帧的邻域来放宽这一限制。在这项工作中，我们引入了LoopGNN，这是一种图神经网络架构，通过利用位置识别检索到的视觉相似关键帧的团来估计环闭合一致性。通过在团的节点间传播深度特征编码，我们的方法在保持高召回率的同时提供了高精度的估计。在TartanDrive 2.0和NCLT数据集上的广泛实验评估表明，LoopGNN优于传统基线。此外，针对各种关键点提取器的消融研究表明，我们的方法对深度特征编码的类型不敏感，并且比经典几何验证基线具有更高的计算效率。我们在https://loopgnn.cs.uni-freiburg.de发布了我们的代码、补充材料和关键帧数据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual loop closure detection traditionally relies on place recognitionmethods to retrieve candidate loops that are validated using computationallyexpensive RANSAC-based geometric verification. As false positive loop closuressignificantly degrade downstream pose graph estimates, verifying a large numberof candidates in online simultaneous localization and mapping scenarios isconstrained by limited time and compute resources. While most deep loop closuredetection approaches only operate on pairs of keyframes, we relax thisconstraint by considering neighborhoods of multiple keyframes when detectingloops. In this work, we introduce LoopGNN, a graph neural network architecturethat estimates loop closure consensus by leveraging cliques of visually similarkeyframes retrieved through place recognition. By propagating deep featureencodings among nodes of the clique, our method yields high-precision estimateswhile maintaining high recall. Extensive experimental evaluations on theTartanDrive 2.0 and NCLT datasets demonstrate that LoopGNN outperformstraditional baselines. Additionally, an ablation study across various keypointextractors demonstrates that our method is robust, regardless of the type ofdeep feature encodings used, and exhibits higher computational efficiencycompared to classical geometric verification baselines. We release our code,supplementary material, and keyframe data athttps://loopgnn.cs.uni-freiburg.de.</description>
      <author>example@mail.com (Martin Büchner, Liza Dahiya, Simon Dorer, Vipul Ramtekkar, Kenji Nishimiya, Daniele Cattaneo, Abhinav Valada)</author>
      <guid isPermaLink="false">2505.21754v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Copresheaf Topological Neural Networks: A Generalized Deep Learning Framework</title>
      <link>http://arxiv.org/abs/2505.21251v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了共层拓扑神经网络（CTNNs），这是一种强大的统一框架，能够封装广泛的深度学习架构，并设计用于处理结构化数据，如图像、点云、图、网格和拓扑流形。&lt;h4&gt;背景&lt;/h4&gt;尽管深度学习对从数字助手到自主系统等领域的深远影响，但针对特定任务和数据类型设计神经架构的原则性设计仍然是该领域最持久的挑战之一。&lt;h4&gt;目的&lt;/h4&gt;CTNNs通过将模型设计建立在共层这一代数拓扑语言的基础上来填补这一差距，共层是用于泛化和包含当今大多数实际使用的深度学习模型的概念。&lt;h4&gt;方法&lt;/h4&gt;这种方法提供了一个丰富的设计空间，从中可以推导出理论上合理且实际有效的解决方案，以解决表示学习中的核心挑战，如长距离依赖、过度平滑、异质性和非欧几里得域。&lt;h4&gt;主要发现&lt;/h4&gt;在结构化数据基准测试上的实验结果表明，CTNNs在需要层次化或局部敏感的任务中，持续优于传统基线。&lt;h4&gt;结论&lt;/h4&gt;这些结果强调了CTNNs作为下一代深度学习架构的原理性和多尺度基础的潜力。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了共层拓扑神经网络（CTNNs），这是一个强大且统一的框架，能够封装广泛的深度学习架构，旨在处理结构化数据，包括图像、点云、图、网格和拓扑流形。虽然深度学习深刻影响了从数字助手到自主系统等多个领域，但针对特定任务和数据类型设计神经架构的原则性设计仍然是该领域最持久的挑战之一。CTNNs通过将模型设计建立在共层这一代数拓扑语言的基础上来填补这一差距，共层是用于泛化和包含当今大多数实际使用的深度学习模型的概念。这种抽象而建设性的公式化提供了一种丰富的设计空间，从中可以推导出理论上合理且实际有效的解决方案，以解决表示学习中的核心挑战：长距离依赖、过度平滑、异质性和非欧几里得域。我们在结构化数据基准测试上的实验结果表明，CTNNs在需要层次化或局部敏感的任务中，持续优于传统基线。这些结果强调了CTNNs作为下一代深度学习架构的原理性和多尺度基础的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce copresheaf topological neural networks (CTNNs), a powerful andunifying framework that encapsulates a wide spectrum of deep learningarchitectures, designed to operate on structured data: including images, pointclouds, graphs, meshes, and topological manifolds. While deep learning hasprofoundly impacted domains ranging from digital assistants to autonomoussystems, the principled design of neural architectures tailored to specifictasks and data types remains one of the field's most persistent openchallenges. CTNNs address this gap by grounding model design in the language ofcopresheaves, a concept from algebraic topology that generalizes and subsumesmost practical deep learning models in use today. This abstract yetconstructive formulation yields a rich design space from which theoreticallysound and practically effective solutions can be derived to tackle corechallenges in representation learning: long-range dependencies, oversmoothing,heterophily, and non-Euclidean domains. Our empirical results on structureddata benchmarks demonstrate that CTNNs consistently outperform conventionalbaselines, particularly in tasks requiring hierarchical or localizedsensitivity. These results underscore CTNNs as a principled, multi-scalefoundation for the next generation of deep learning architectures.</description>
      <author>example@mail.com (Mustafa Hajij, Lennart Bastian, Sarah Osentoski, Hardik Kabaria, John L. Davenport, Sheik Dawood, Balaji Cherukuri, Joseph G. Kocheemoolayil, Nastaran Shahmansouri, Adrian Lew, Theodore Papamarkou, Tolga Birdal)</author>
      <guid isPermaLink="false">2505.21251v2</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Gradient-based Adversarial Attacks on Point Cloud Classification</title>
      <link>http://arxiv.org/abs/2505.21854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了改进的基于梯度的对抗攻击方法，旨在提升点云分类模型的鲁棒性评估。&lt;h4&gt;背景&lt;/h4&gt;现有的基于梯度的对抗攻击方法在点云的异质性考虑不足，导致扰动过大且明显。&lt;h4&gt;目的&lt;/h4&gt;提出新的策略以提高对抗攻击的有效性和不可感知性。&lt;h4&gt;方法&lt;/h4&gt;引入了WAAttack，一个结合加权梯度和自适应步长策略的新框架，以及SubAttack，一种将点云分解为子集并集中扰动关键结构的策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，提出的方法在生成几乎不可感知的对抗样例方面优于现有基准。&lt;h4&gt;结论&lt;/h4&gt;本文方法对3D点云分类的基于梯度的对抗攻击进行了原理性的重新思考。&lt;h4&gt;翻译&lt;/h4&gt;Gradient-based adversarial attacks have become a dominant approach for evaluating the robustness of point cloud classification models. However, existing methods often rely on uniform update rules that fail to consider the heterogeneous nature of point clouds, resulting in excessive and perceptible perturbations. In this paper, we rethink the design of gradient-based attacks by analyzing the limitations of conventional gradient update mechanisms and propose two new strategies to improve both attack effectiveness and imperceptibility. First, we introduce WAAttack, a novel framework that incorporates weighted gradients and an adaptive step-size strategy to account for the non-uniform contribution of points during optimization. This approach enables more targeted and subtle perturbations by dynamically adjusting updates according to the local structure and sensitivity of each point. Second, we propose SubAttack, a complementary strategy that decomposes the point cloud into subsets and focuses perturbation efforts on structurally critical regions. Together, these methods represent a principled rethinking of gradient-based adversarial attacks for 3D point cloud classification. Extensive experiments demonstrate that our approach outperforms state-of-the-art baselines in generating highly imperceptible adversarial examples. Code will be released upon paper acceptance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gradient-based adversarial attacks have become a dominant approach forevaluating the robustness of point cloud classification models. However,existing methods often rely on uniform update rules that fail to consider theheterogeneous nature of point clouds, resulting in excessive and perceptibleperturbations. In this paper, we rethink the design of gradient-based attacksby analyzing the limitations of conventional gradient update mechanisms andpropose two new strategies to improve both attack effectiveness andimperceptibility. First, we introduce WAAttack, a novel framework thatincorporates weighted gradients and an adaptive step-size strategy to accountfor the non-uniform contribution of points during optimization. This approachenables more targeted and subtle perturbations by dynamically adjusting updatesaccording to the local structure and sensitivity of each point. Second, wepropose SubAttack, a complementary strategy that decomposes the point cloudinto subsets and focuses perturbation efforts on structurally critical regions.Together, these methods represent a principled rethinking of gradient-basedadversarial attacks for 3D point cloud classification. Extensive experimentsdemonstrate that our approach outperforms state-of-the-art baselines ingenerating highly imperceptible adversarial examples. Code will be releasedupon paper acceptance.</description>
      <author>example@mail.com (Jun Chen, Xinke Li, Mingyue Xu, Tianrui Li, Chongshou Li)</author>
      <guid isPermaLink="false">2505.21854v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Developing a Top-tier Framework in Naturalistic Conditions Challenge for Categorized Emotion Prediction: From Speech Foundation Models and Learning Objective to Data Augmentation and Engineering Choices</title>
      <link>http://arxiv.org/abs/2505.22133v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to INTERSPEECH 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为SAILER的系统，用于参加2025年INTERSPEECH情感识别挑战赛，并展示了该系统在处理自然情感语音数据方面的有效性。&lt;h4&gt;背景&lt;/h4&gt;自然情感语音的情感识别是一个具有挑战性的任务，主要难点在于情感标注的主观性和数据集中情感标签的不平衡分布。&lt;h4&gt;目的&lt;/h4&gt;设计一个简单、可复现且有效的系统，用于解决自然情感语音的情感识别问题。&lt;h4&gt;方法&lt;/h4&gt;SAILER系统在设计上注重模型选择、学习目标、数据增强和工程选择等关键因素，并通过单一系统和多个系统的集成来提升性能。&lt;h4&gt;主要发现&lt;/h4&gt;SAILER系统在挑战赛中表现优异，单个系统（未集成）的表现超过95%的参赛作品，集成三个系统后，成绩达到前三名。&lt;h4&gt;结论&lt;/h4&gt;SAILER系统在自然情感语音的情感识别任务中展现出良好的性能，是一个有潜力的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Speech emotion recognition (SER), particularly for naturally expressed emotions, remains a challenging computational task. Key challenges include the inherent subjectivity in emotion annotation and the imbalanced distribution of emotion labels in datasets. This paper introduces the exttt{SAILER} system developed for participation in the INTERSPEECH 2025 Emotion Recognition Challenge (Task 1). The challenge dataset, which contains natural emotional speech from podcasts, serves as a valuable resource for studying imbalanced and subjective emotion annotations. Our system is designed to be simple, reproducible, and effective, highlighting critical choices in modeling, learning objectives, data augmentation, and engineering choices. Results show that even a single system (without ensembling) can outperform more than 95% of the submissions, with a Macro-F1 score exceeding 0.4. Moreover, an ensemble of three systems further improves performance, achieving a competitively ranked score (top-3 performing team). Our model is at:https://github.com/tiantiaf0627/vox-profile-release.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech emotion recognition (SER), particularly for naturally expressedemotions, remains a challenging computational task. Key challenges include theinherent subjectivity in emotion annotation and the imbalanced distribution ofemotion labels in datasets. This paper introduces the \texttt{SAILER} systemdeveloped for participation in the INTERSPEECH 2025 Emotion RecognitionChallenge (Task 1). The challenge dataset, which contains natural emotionalspeech from podcasts, serves as a valuable resource for studying imbalanced andsubjective emotion annotations. Our system is designed to be simple,reproducible, and effective, highlighting critical choices in modeling,learning objectives, data augmentation, and engineering choices. Results showthat even a single system (without ensembling) can outperform more than 95\% ofthe submissions, with a Macro-F1 score exceeding 0.4. Moreover, an ensemble ofthree systems further improves performance, achieving a competitively rankedscore (top-3 performing team). Our model is at:https://github.com/tiantiaf0627/vox-profile-release.</description>
      <author>example@mail.com (Tiantian Feng, Thanathai Lertpetchpun, Dani Byrd, Shrikanth Narayanan)</author>
      <guid isPermaLink="false">2505.22133v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks</title>
      <link>http://arxiv.org/abs/2505.21649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了DORI（判别性方向推理智能），一个用于评估物体方向感知能力的全面基准。DORI通过精心设计的任务和数据分析，揭示了当前视觉-语言模型在方向感知方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;物体方向理解是视觉感知中的一个基本挑战，对于机器人操作和增强现实等应用至关重要。现有的视觉-语言基准未能单独评估这一能力，常常将其与位置关系和场景理解混淆。&lt;h4&gt;目的&lt;/h4&gt;引入DORI作为评估物体方向感知能力的基准，并揭示当前视觉-语言模型在方向感知方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;DORI通过从11个数据集中精心挑选的任务，涵盖67个物体类别，评估了方向理解的四个维度：正面对齐、旋转变换、相对方向关系和标准方向理解。&lt;h4&gt;主要发现&lt;/h4&gt;对15个最先进的视觉-语言模型的评估显示，即使在粗略任务上，最佳模型的准确率也只有54.2%，在细粒度方向判断上为33.0%。模型在需要参考系转换或复合旋转的任务上的表现下降，表明它们在内部3D空间表示方面存在局限性。&lt;h4&gt;结论&lt;/h4&gt;DORI作为第一个专门为多模态系统中的方向感知设计的诊断框架，对改进机器人控制、3D场景重建和物理环境中的AI与人类交互具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;摘要：面向对象的理解是视觉感知中的一个基本挑战，对于机器人操作和增强现实等应用至关重要。当前的视觉-语言基准未能单独评估这一能力，常常将其与位置关系和一般场景理解混淆。我们引入了DORI（判别性方向推理智能），一个建立物体方向感知作为主要评估目标的全面基准。DORI评估了方向理解的四个维度：正面对齐、旋转变换、相对方向关系和标准方向理解。通过从11个数据集中精心挑选的任务，涵盖67个物体类别，DORI提供了关于多模态系统如何理解物体方向的观点。我们对15个最先进的视觉-语言模型的评估揭示了关键的限制：即使是最好的模型在粗略任务上也只能达到54.2%的准确率，在细粒度方向判断上为33.0%，对于需要参考系转换或复合旋转的任务，性能会下降。这些发现表明需要专门的定向表示机制，因为模型显示出系统性地无法进行精确的角度估计，无法跟踪视角变化中的方向变化，也无法理解复合旋转——这表明它们在内部3D空间表示方面的局限性。作为第一个专门为多模态系统中的方向感知设计的诊断框架，DORI对改进机器人控制、3D场景重建和物理环境中的AI与人类交互具有重要意义。DORI数据：https://huggingface.co/datasets/appledora/DORI-Benchmark&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object orientation understanding represents a fundamental challenge in visualperception critical for applications like robotic manipulation and augmentedreality. Current vision-language benchmarks fail to isolate this capability,often conflating it with positional relationships and general sceneunderstanding. We introduce DORI (Discriminative Orientation ReasoningIntelligence), a comprehensive benchmark establishing object orientationperception as a primary evaluation target. DORI assesses four dimensions oforientation comprehension: frontal alignment, rotational transformations,relative directional relationships, and canonical orientation understanding.Through carefully curated tasks from 11 datasets spanning 67 object categoriesacross synthetic and real-world scenarios, DORI provides insights on howmulti-modal systems understand object orientations. Our evaluation of 15state-of-the-art vision-language models reveals critical limitations: even thebest models achieve only 54.2% accuracy on coarse tasks and 33.0% on granularorientation judgments, with performance deteriorating for tasks requiringreference frame shifts or compound rotations. These findings demonstrate theneed for dedicated orientation representation mechanisms, as models showsystematic inability to perform precise angular estimations, track orientationchanges across viewpoints, and understand compound rotations - suggestinglimitations in their internal 3D spatial representations. As the firstdiagnostic framework specifically designed for orientation awareness inmultimodal systems, DORI offers implications for improving robotic control, 3Dscene reconstruction, and human-AI interaction in physical environments. DORIdata: https://huggingface.co/datasets/appledora/DORI-Benchmark</description>
      <author>example@mail.com (Keanu Nichols, Nazia Tasnim, Yan Yuting, Nicholas Ikechukwu, Elva Zou, Deepti Ghadiyaram, Bryan Plummer)</author>
      <guid isPermaLink="false">2505.21649v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Any-to-Bokeh: One-Step Video Bokeh via Multi-Plane Image Guided Diffusion</title>
      <link>http://arxiv.org/abs/2505.21593v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  project page: https://vivocameraresearch.github.io/any2bokeh/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的视频虚化框架，用于将任意输入视频转换为具有时间一致性和深度感知的虚化效果。&lt;h4&gt;背景&lt;/h4&gt;扩散编辑模型在图像模拟和图像虚化方面取得了进展，但视频虚化仍然未被充分探索。现有视频编辑模型无法显式控制焦点平面或调整虚化强度，限制了其应用范围。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以实现可控制的光学效果，解决视频编辑模型中时间抖动和边缘模糊过渡不理想的问题。&lt;h4&gt;方法&lt;/h4&gt;通过构建多平面图像（MPI）表示，提供深度相关的模糊合成几何指导，并利用预训练模型如Stable Video Diffusion的3D先验知识，实现实时且一致的虚化效果。同时，引入渐进式训练策略以提高时间一致性、深度鲁棒性和细节保持。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够生成高质量的、可控制的虚化效果，在多个评估基准上达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法为视频虚化提供了新的解决方案，有望在视频编辑和视觉效果领域得到应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in diffusion based editing models have enabled realisticcamera simulation and image-based bokeh, but video bokeh remains largelyunexplored. Existing video editing models cannot explicitly control focusplanes or adjust bokeh intensity, limiting their applicability for controllableoptical effects. Moreover, naively extending image-based bokeh methods to videooften results in temporal flickering and unsatisfactory edge blur transitionsdue to the lack of temporal modeling and generalization capability. To addressthese challenges, we propose a novel one-step video bokeh framework thatconverts arbitrary input videos into temporally coherent, depth-aware bokeheffects. Our method leverages a multi-plane image (MPI) representationconstructed through a progressively widening depth sampling function, providingexplicit geometric guidance for depth-dependent blur synthesis. By conditioninga single-step video diffusion model on MPI layers and utilizing the strong 3Dpriors from pre-trained models such as Stable Video Diffusion, our approachachieves realistic and consistent bokeh effects across diverse scenes.Additionally, we introduce a progressive training strategy to enhance temporalconsistency, depth robustness, and detail preservation. Extensive experimentsdemonstrate that our method produces high-quality, controllable bokeh effectsand achieves state-of-the-art performance on multiple evaluation benchmarks.</description>
      <author>example@mail.com (Yang Yang, Siming Zheng, Jinwei Chen, Boxi Wu, Xiaofei He, Deng Cai, Bo Li, Peng-Tao Jiang)</author>
      <guid isPermaLink="false">2505.21593v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>On-the-fly Routing for Zero-shot MoE Speaker Adaptation of Speech Foundation Models for Dysarthric Speech Recognition</title>
      <link>http://arxiv.org/abs/2505.22072v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于MoE的说话人自适应框架，用于基于基础模型的语音障碍语音识别。&lt;h4&gt;背景&lt;/h4&gt;语音障碍语音识别需要说话人自适应技术，而现有的自适应方法往往难以实现零样本自适应和实时处理。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种新的MoE框架，能够实现零样本自适应、实时处理，并融合领域知识。&lt;h4&gt;方法&lt;/h4&gt;该框架通过动态组合基于预测的说话人依赖路由参数，实现说话人严重程度和性别的适配专家。使用KL散度进一步强化专家间的多样性和对未见说话人的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;在UASpeech语料库上的实验结果表明，基于MoE的自适应方法相较于未适配的基线模型HuBERT/WavLM，实现了显著的错误率（WER）降低，最大绝对降低1.34%（相对降低6.36%）。在跨不同说话人数据量级的批处理自适应中，实现了最大2.55%的绝对WER降低（相对降低11.44%）和7倍的实时速度提升。同时，获得了最低的公开WER，为16.35%（非常低可懂性下的46.77%）。&lt;h4&gt;结论&lt;/h4&gt;该方法在语音障碍语音识别中表现出色，能够显著提升识别准确率和速度，具有实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a novel MoE-based speaker adaptation framework forfoundation models based dysarthric speech recognition. This approach enableszero-shot adaptation and real-time processing while incorporating domainknowledge. Speech impairment severity and gender conditioned adapter expertsare dynamically combined using on-the-fly predicted speaker-dependent routingparameters. KL-divergence is used to further enforce diversity among expertsand their generalization to unseen speakers. Experimental results on theUASpeech corpus suggest that on-the-fly MoE-based adaptation producesstatistically significant WER reductions of up to 1.34% absolute (6.36%relative) over the unadapted baseline HuBERT/WavLM models. Consistent WERreductions of up to 2.55% absolute (11.44% relative) and RTF speedups of up to7 times are obtained over batch-mode adaptation across varying speaker-leveldata quantities. The lowest published WER of 16.35% (46.77% on very lowintelligibility) is obtained.</description>
      <author>example@mail.com (Shujie HU, Xurong Xie, Mengzhe Geng, Jiajun Deng, Huimeng Wang, Guinan Li, Chengxi Deng, Tianzi Wang, Mingyu Cui, Helen Meng, Xunying Liu)</author>
      <guid isPermaLink="false">2505.22072v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Subspecialty-Specific Foundation Model for Intelligent Gastrointestinal Pathology</title>
      <link>http://arxiv.org/abs/2505.21928v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了Digepath，一个针对胃肠道病理学的专业基础模型，用于优化胃肠道疾病的诊断和预测。&lt;h4&gt;背景&lt;/h4&gt;胃肠道疾病在临床上具有重要意义，需要精确的诊断方法来提高患者预后。传统的组织病理学诊断依赖于病理医生的主观解释，存在可重复性和诊断变异性的限制。&lt;h4&gt;目的&lt;/h4&gt;开发Digepath，以克服传统诊断方法的局限性，并为胃肠道疾病提供病理学特定的基础模型。&lt;h4&gt;方法&lt;/h4&gt;Digepath采用预训练与精细筛选相结合的双重阶段迭代优化策略，专门设计用于检测全切片图像中的稀疏病变区域。它在大约200,000张胃肠道疾病染色切片的353百万个图像块上进行了预训练。&lt;h4&gt;主要发现&lt;/h4&gt;Digepath在33项与胃肠道病理学相关的任务中达到了最先进的性能，包括病理诊断、分子预测、基因突变预测和预后评估，尤其在诊断不明确的情况下和分辨率无关的组织分类方面表现突出。该模型在全国9家独立医疗机构中实现了对早期胃肠道癌症的高达99.6%的敏感性。&lt;h4&gt;结论&lt;/h4&gt;Digepath的性能突出，显示出其在组织病理学实践中的潜力，不仅推动了人工智能驱动的胃肠道疾病精确病理学的发展，也为其他病理亚专业建立了一个可转移的范例。&lt;h4&gt;翻译&lt;/h4&gt;摘要：胃肠道疾病代表了临床上的重要负担，需要精确的诊断方法来优化患者预后。传统的组织病理学诊断高度依赖于病理医生的主观解释，存在可重复性和诊断变异性的限制。为了克服这些限制并解决缺乏针对胃肠道疾病病理学的基础模型的问题，我们开发了Digepath，一个专门针对胃肠道病理学的专业基础模型。我们的框架引入了一种双重阶段迭代优化策略，结合预训练和精细筛选，专门设计用于解决全切片图像中稀疏病变区域的检测。Digepath在超过200,000张胃肠道疾病染色切片的353百万个图像块上进行了预训练。它在33项与胃肠道病理学相关的任务中达到了最先进的性能，包括病理诊断、分子预测、基因突变预测和预后评估，尤其在诊断不明确的情况下和分辨率无关的组织分类方面表现突出。我们进一步将智能筛选模块应用于早期胃肠道癌症的筛查，并在全国9家独立医疗机构中实现了近完美的99.6%敏感性。Digepath的杰出性能突出了其在组织病理学实践中的潜力。这项工作不仅推动了人工智能驱动的胃肠道疾病精确病理学的发展，也为其他病理亚专业建立了一个可转移的范例。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gastrointestinal (GI) diseases represent a clinically significant burden,necessitating precise diagnostic approaches to optimize patient outcomes.Conventional histopathological diagnosis, heavily reliant on the subjectiveinterpretation of pathologists, suffers from limited reproducibility anddiagnostic variability. To overcome these limitations and address the lack ofpathology-specific foundation models for GI diseases, we develop Digepath, aspecialized foundation model for GI pathology. Our framework introduces adual-phase iterative optimization strategy combining pretraining withfine-screening, specifically designed to address the detection of sparselydistributed lesion areas in whole-slide images. Digepath is pretrained on morethan 353 million image patches from over 200,000 hematoxylin and eosin-stainedslides of GI diseases. It attains state-of-the-art performance on 33 out of 34tasks related to GI pathology, including pathological diagnosis, molecularprediction, gene mutation prediction, and prognosis evaluation, particularly indiagnostically ambiguous cases and resolution-agnostic tissue classification.Wefurther translate the intelligent screening module for early GI cancer andachieve near-perfect 99.6% sensitivity across 9 independent medicalinstitutions nationwide. The outstanding performance of Digepath highlights itspotential to bridge critical gaps in histopathological practice. This work notonly advances AI-driven precision pathology for GI diseases but alsoestablishes a transferable paradigm for other pathology subspecialties.</description>
      <author>example@mail.com (Lianghui Zhu, Xitong Ling, Minxi Ouyang, Xiaoping Liu, Mingxi Fu, Tian Guan, Fanglei Fu, Xuanyu Wang, Maomao Zeng, Mingxi Zhu, Yibo Jin, Liming Liu, Song Duan, Qiming He, Yizhi Wang, Luxi Xie, Houqiang Li, Yonghong He, Sufang Tian)</author>
      <guid isPermaLink="false">2505.21928v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Completion: A Foundation Model for General Knowledge Graph Reasoning</title>
      <link>http://arxiv.org/abs/2505.21926v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACL 2025 Findings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MERRY的基础模型，用于通用知识图谱推理，并在知识图谱内推理任务和知识图谱问答等知识图谱外任务中进行了性能研究。&lt;h4&gt;背景&lt;/h4&gt;尽管基础模型在自然语言处理和计算机视觉领域展现出巨大潜力，但现有针对知识图谱的基础模型研究主要关注其结构方面，多数工作局限于知识图谱内任务，如知识图谱补全，这限制了在知识图谱外任务上的进展。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够处理知识图谱内和知识图谱外任务的通用知识图谱推理模型。&lt;h4&gt;方法&lt;/h4&gt;MERRY模型利用知识图谱中的结构和文本信息，提出了一种多视角条件消息传递（CMP）编码架构以整合文本和结构模态，并引入了动态残差融合模块和灵活的边评分机制以适应不同的下游任务。&lt;h4&gt;主要发现&lt;/h4&gt;在28个数据集上的综合评估表明，MERRY在大多数场景下优于现有基线，展示了在知识图谱内强大的推理能力和对知识图谱问答等知识图谱外任务的优秀泛化能力。&lt;h4&gt;结论&lt;/h4&gt;MERRY模型在知识图谱推理领域是一个有前景的研究成果，为处理更复杂的知识图谱外任务提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In natural language processing (NLP) and computer vision (CV), the successfulapplication of foundation models across diverse tasks has demonstrated theirremarkable potential. However, despite the rich structural and textualinformation embedded in knowledge graphs (KGs), existing research of foundationmodel for KG has primarily focused on their structural aspects, with mostefforts restricted to in-KG tasks (e.g., knowledge graph completion, KGC). Thislimitation has hindered progress in addressing more challenging out-of-KGtasks. In this paper, we introduce MERRY, a foundation model for generalknowledge graph reasoning, and investigate its performance across two taskcategories: in-KG reasoning tasks (e.g., KGC) and out-of-KG tasks (e.g., KGquestion answering, KGQA). We not only utilize the structural information, butalso the textual information in KGs. Specifically, we propose amulti-perspective Conditional Message Passing (CMP) encoding architecture tobridge the gap between textual and structural modalities, enabling theirseamless integration. Additionally, we introduce a dynamic residual fusionmodule to selectively retain relevant textual information and a flexible edgescoring mechanism to adapt to diverse downstream tasks. Comprehensiveevaluations on 28 datasets demonstrate that MERRY outperforms existingbaselines in most scenarios, showcasing strong reasoning capabilities withinKGs and excellent generalization to out-of-KG tasks such as KGQA.</description>
      <author>example@mail.com (Yin Hua, Zhiqiang Liu, Mingyang Chen, Zheng Fang, Chi Man Wong, Lingxiao Li, Chi Man Vong, Huajun Chen, Wen Zhang)</author>
      <guid isPermaLink="false">2505.21926v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Streamlining Resilient Kubernetes Autoscaling with Multi-Agent Systems via an Automated Online Design Framework</title>
      <link>http://arxiv.org/abs/2505.21559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于强化学习的Kubernetes集群多智能体系统，用于提高集群在面临如DDoS攻击等对抗性场景下的操作弹性。&lt;h4&gt;背景&lt;/h4&gt;云原生系统中，具有相互依赖服务的Kubernetes集群由于工作负载管理问题（如资源阻塞、瓶颈或持续Pod崩溃）而面临操作弹性挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，将保持操作弹性的总体目标分解为针对特定故障的子目标，由协作智能体共同实现。&lt;h4&gt;方法&lt;/h4&gt;引入一个自动化的四阶段在线框架，用于设计HPA多智能体系统：1）从集群跟踪中建模数字孪生；2）在模拟中使用针对故障上下文的角色和任务训练智能体；3）分析智能体行为以提高可解释性；4）将学习到的策略转移到实际集群。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，生成的HPA多智能体系统在保持操作弹性方面优于三种最先进的HPA系统，在各种对抗性条件下表现出色。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在提高云原生系统中Kubernetes集群的操作弹性方面具有显著效果，特别是在面对DDoS攻击等对抗性场景时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In cloud-native systems, Kubernetes clusters with interdependent servicesoften face challenges to their operational resilience due to poor workloadmanagement issues such as resource blocking, bottlenecks, or continuous podcrashes. These vulnerabilities are further amplified in adversarial scenarios,such as Distributed Denial-of-Service attacks (DDoS). Conventional HorizontalPod Autoscaling (HPA) approaches struggle to address such dynamic conditions,while reinforcement learning-based methods, though more adaptable, typicallyoptimize single goals like latency or resource usage, neglecting broaderfailure scenarios. We propose decomposing the overarching goal of maintainingoperational resilience into failure-specific sub-goals delegated tocollaborative agents, collectively forming an HPA Multi-Agent System (MAS). Weintroduce an automated, four-phase online framework for HPA MAS design: 1)modeling a digital twin built from cluster traces; 2) training agents insimulation using roles and missions tailored to failure contexts; 3) analyzingagent behaviors for explainability; and 4) transferring learned policies to thereal cluster. Experimental results demonstrate that the generated HPA MASsoutperform three state-of-the-art HPA systems in sustaining operationalresilience under various adversarial conditions in a proposed complex cluster.</description>
      <author>example@mail.com (Julien Soulé, Jean-Paul Jamont, Michel Occello, Louis-Marie Traonouez, Paul Théron)</author>
      <guid isPermaLink="false">2505.21559v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>FCKT: Fine-Grained Cross-Task Knowledge Transfer with Semantic Contrastive Learning for Targeted Sentiment Analysis</title>
      <link>http://arxiv.org/abs/2505.21040v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对目标情感分析（TSA）的细粒度跨任务知识迁移框架FCKT，通过显式地将方面信息纳入情感预测，实现了细粒度知识迁移，有效缓解了负迁移并提升了任务性能。&lt;h4&gt;背景&lt;/h4&gt;目标情感分析涉及从评论中识别特定方面并确定其对应情感的两个子任务。现有研究大多采用多任务学习范式在潜在空间中对齐任务特定特征，但主要依赖于粗粒度知识迁移，缺乏对方面-情感关系的细粒度控制。&lt;h4&gt;目的&lt;/h4&gt;为了克服上述局限性，提出FCKT框架，旨在通过细粒度知识迁移来提升目标情感分析的性能。&lt;h4&gt;方法&lt;/h4&gt;FCKT通过显式地结合方面信息进行情感预测，实现了细粒度知识迁移，有效减轻了负迁移。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，FCKT在三个数据集上均优于各种基线和大型语言模型（LLMs），证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;FCKT框架能够有效提升目标情感分析的性能，并通过细粒度知识迁移缓解了负迁移。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we address the task of targeted sentiment analysis (TSA), which involves two sub-tasks, i.e., identifying specific aspects from reviews and determining their corresponding sentiments. Aspect extraction forms the foundation for sentiment prediction, highlighting the critical dependency between these two tasks for effective cross-task knowledge transfer. While most existing studies adopt a multi-task learning paradigm to align task-specific features in the latent space, they predominantly rely on coarse-grained knowledge transfer. Such approaches lack fine-grained control over aspect-sentiment relationships, often assuming uniform sentiment polarity within related aspects. This oversimplification neglects contextual cues that differentiate sentiments, leading to negative transfer. To overcome these limitations, we propose FCKT, a fine-grained cross-task knowledge transfer framework tailored for TSA. By explicitly incorporating aspect-level information into sentiment prediction, FCKT achieves fine-grained knowledge transfer, effectively mitigating negative transfer and enhancing task performance. Experiments on three datasets, including comparisons with various baselines and large language models (LLMs), demonstrate the effectiveness of FCKT. The source code is available on https://github.com/cwei01/FCKT.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we address the task of targeted sentiment analysis (TSA),which involves two sub-tasks, i.e., identifying specific aspects from reviewsand determining their corresponding sentiments. Aspect extraction forms thefoundation for sentiment prediction, highlighting the critical dependencybetween these two tasks for effective cross-task knowledge transfer. While mostexisting studies adopt a multi-task learning paradigm to align task-specificfeatures in the latent space, they predominantly rely on coarse-grainedknowledge transfer. Such approaches lack fine-grained control overaspect-sentiment relationships, often assuming uniform sentiment polaritywithin related aspects. This oversimplification neglects contextual cues thatdifferentiate sentiments, leading to negative transfer. To overcome theselimitations, we propose FCKT, a fine-grained cross-task knowledge transferframework tailored for TSA. By explicitly incorporating aspect-levelinformation into sentiment prediction, FCKT achieves fine-grained knowledgetransfer, effectively mitigating negative transfer and enhancing taskperformance. Experiments on three datasets, including comparisons with variousbaselines and large language models (LLMs), demonstrate the effectiveness ofFCKT. The source code is available on https://github.com/cwei01/FCKT.</description>
      <author>example@mail.com (Wei Chen, Zhao Zhang, Meng Yuan, Kepeng Xu, Fuzhen Zhuang)</author>
      <guid isPermaLink="false">2505.21040v2</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>InfoSAM: Fine-Tuning the Segment Anything Model from An Information-Theoretic Perspective</title>
      <link>http://arxiv.org/abs/2505.21920v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML 2025 (Highlight)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为InfoSAM的信息理论方法，用于增强Segment Anything Model (SAM)的微调过程，以提升其在特定领域任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;SAM作为一种视觉基础模型，在通用任务中表现出零样本能力，但在特定领域任务中表现不佳。现有的参数高效微调（PEFT）方法忽略了预训练模型中编码的领域不变关系。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出InfoSAM，旨在通过提炼和保留预训练的分割知识来增强SAM的微调。&lt;h4&gt;方法&lt;/h4&gt;InfoSAM通过两个基于互信息的创新目标来构建知识迁移过程：(i) 压缩从预训练SAM中提取的领域不变关系，排除可能的伪不变信息；(ii) 最大化教师（预训练SAM）和学生（微调模型）学习到的关系知识之间的互信息。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验验证了InfoSAM在提高SAM家族在现实世界任务中的性能方面的有效性，证明了其在处理特定场景中的适应性和优越性。&lt;h4&gt;结论&lt;/h4&gt;InfoSAM为SAM的PEFT建立了一个稳健的蒸馏框架，显著提升了SAM在特定领域任务中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Segment Anything Model (SAM), a vision foundation model, exhibitsimpressive zero-shot capabilities in general tasks but struggles in specializeddomains. Parameter-efficient fine-tuning (PEFT) is a promising approach tounleash the potential of SAM in novel scenarios. However, existing PEFT methodsfor SAM neglect the domain-invariant relations encoded in the pre-trainedmodel. To bridge this gap, we propose InfoSAM, an information-theoreticapproach that enhances SAM fine-tuning by distilling and preserving itspre-trained segmentation knowledge. Specifically, we formulate the knowledgetransfer process as two novel mutual information-based objectives: (i) tocompress the domain-invariant relation extracted from pre-trained SAM,excluding pseudo-invariant information as possible, and (ii) to maximize mutualinformation between the relational knowledge learned by the teacher(pre-trained SAM) and the student (fine-tuned model). The proposed InfoSAMestablishes a robust distillation framework for PEFT of SAM. Extensiveexperiments across diverse benchmarks validate InfoSAM's effectiveness inimproving SAM family's performance on real-world tasks, demonstrating itsadaptability and superiority in handling specialized scenarios.</description>
      <author>example@mail.com (Yuanhong Zhang, Muyao Yuan, Weizhan Zhang, Tieliang Gong, Wen Wen, Jiangyong Ying, Weijie Shi)</author>
      <guid isPermaLink="false">2505.21920v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>CellCLAT: Preserving Topology and Trimming Redundancy in Self-Supervised Cellular Contrastive Learning</title>
      <link>http://arxiv.org/abs/2505.21587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CellCLAT的自监督拓扑深度学习方法，用于处理细胞复杂结构中的高阶交互，以提取无标签图的表示。&lt;h4&gt;背景&lt;/h4&gt;自监督拓扑深度学习在建模高阶交互和提取无标签图表示方面具有潜力，但细胞复杂结构中的外在与内在挑战限制了其发展。&lt;h4&gt;目的&lt;/h4&gt;提出CellCLAT框架，以解决细胞复杂结构中的外在与内在挑战，包括结构约束和语义冗余。&lt;h4&gt;方法&lt;/h4&gt;CellCLAT采用基于参数扰动的增强方法注入噪声，同时保持细胞结构；并使用细胞修剪调度器通过双层元学习掩蔽与任务无关的细胞，去除冗余拓扑元素。&lt;h4&gt;主要发现&lt;/h4&gt;CellCLAT在自监督图学习方法中取得了显著改进，为该领域的发展做出了重要尝试。&lt;h4&gt;结论&lt;/h4&gt;CellCLAT框架有效地处理了细胞复杂结构中的挑战，实现了在自监督图学习中的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised topological deep learning (TDL) represents a nascent but underexplored area with significant potential for modeling higher-order interactions in simplicial complexes and cellular complexes to derive representations of unlabeled graphs. Compared to simplicial complexes, cellular complexes exhibit greater expressive power. However, the advancement in self-supervised learning for cellular TDL is largely hindered by two core challenges: extrinsic structural constraints inherent to cellular complexes, and intrinsic semantic redundancy in cellular representations. The first challenge highlights that traditional graph augmentation techniques may compromise the integrity of higher-order cellular interactions, while the second underscores that topological redundancy in cellular complexes potentially diminishes task-relevant information. To address these issues, we introduce Cellular Complex Contrastive Learning with Adaptive Trimming (CellCLAT), a twofold framework designed to adhere to the combinatorial constraints of cellular complexes while mitigating informational redundancy. Specifically, we propose a parameter perturbation-based augmentation method that injects controlled noise into cellular interactions without altering the underlying cellular structures, thereby preserving cellular topology during contrastive learning. Additionally, a cellular trimming scheduler is employed to mask gradient contributions from task-irrelevant cells through a bi-level meta-learning approach, effectively removing redundant topological elements while maintaining critical higher-order semantics. We provide theoretical justification and empirical validation to demonstrate that CellCLAT achieves substantial improvements over existing self-supervised graph learning methods, marking a significant attempt in this domain.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised topological deep learning (TDL) represents a nascent butunderexplored area with significant potential for modeling higher-orderinteractions in simplicial complexes and cellular complexes to deriverepresentations of unlabeled graphs. Compared to simplicial complexes, cellularcomplexes exhibit greater expressive power. However, the advancement inself-supervised learning for cellular TDL is largely hindered by two corechallenges: \textit{extrinsic structural constraints} inherent to cellularcomplexes, and intrinsic semantic redundancy in cellular representations. Thefirst challenge highlights that traditional graph augmentation techniques maycompromise the integrity of higher-order cellular interactions, while thesecond underscores that topological redundancy in cellular complexespotentially diminish task-relevant information. To address these issues, weintroduce Cellular Complex Contrastive Learning with Adaptive Trimming(CellCLAT), a twofold framework designed to adhere to the combinatorialconstraints of cellular complexes while mitigating informational redundancy.Specifically, we propose a parameter perturbation-based augmentation methodthat injects controlled noise into cellular interactions without altering theunderlying cellular structures, thereby preserving cellular topology duringcontrastive learning. Additionally, a cellular trimming scheduler is employedto mask gradient contributions from task-irrelevant cells through a bi-levelmeta-learning approach, effectively removing redundant topological elementswhile maintaining critical higher-order semantics. We provide theoreticaljustification and empirical validation to demonstrate that CellCLAT achievessubstantial improvements over existing self-supervised graph learning methods,marking a significant attempt in this domain.</description>
      <author>example@mail.com (Bin Qin, Qirui Ji, Jiangmeng Li, Yupeng Wang, Xuesong Wu, Jianwen Cao, Fanjiang Xu)</author>
      <guid isPermaLink="false">2505.21587v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge</title>
      <link>http://arxiv.org/abs/2505.21906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://chatvla-2.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了ChatVLA-2，这是一种新型的混合专家VLA模型，旨在通过一个专门的三阶段训练流程，在微调过程中保留并扩展预训练视觉语言模型（VLM）的核心能力。&lt;h4&gt;背景&lt;/h4&gt;VLA模型在机器人领域成为新一代模型，但现有的端到端VLA系统在适应特定机器人任务时，往往会在微调过程中失去关键能力。&lt;h4&gt;目的&lt;/h4&gt;提出一个通用的VLA模型，使其能够保留并扩展VLM的核心能力，包括开放世界的推理能力和有效地将推理转化为机器人可执行的动作。&lt;h4&gt;方法&lt;/h4&gt;设计了一个数学匹配任务，其中机器人解释写在白板上的数学问题，并从桌子上选择相应的数字卡片来解决方程。此外，通过实验验证了模型在数学推理和OCR能力上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;ChatVLA-2在数学推理和OCR能力上表现出色，这些能力并非在VLA中进行显式训练。此外，模型还展现出强大的空间推理能力，能够解释涉及先前未见物体的新方向指令。&lt;h4&gt;结论&lt;/h4&gt;该方法在推理和理解能力上显著超越了如OpenVLA、DexVLA和pi-zero等最先进的模仿学习方法，是开发真正通用的、具有强大推理能力的机器人基础模型的重要进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language-action (VLA) models have emerged as the next generation ofmodels in robotics. However, despite leveraging powerful pre-trainedVision-Language Models (VLMs), existing end-to-end VLA systems often lose keycapabilities during fine-tuning as the model adapts to specific robotic tasks.We argue that a generalizable VLA model should retain and expand upon the VLM'score competencies: 1) Open-world embodied reasoning - the VLA should inheritthe knowledge from VLM, i.e., recognize anything that the VLM can recognize,capable of solving math problems, possessing visual-spatial intelligence, 2)Reasoning following - effectively translating the open-world reasoning intoactionable steps for the robot. In this work, we introduce ChatVLA-2, a novelmixture-of-expert VLA model coupled with a specialized three-stage trainingpipeline designed to preserve the VLM's original strengths while enablingactionable reasoning. To validate our approach, we design a math-matching taskwherein a robot interprets math problems written on a whiteboard and pickscorresponding number cards from a table to solve equations. Remarkably, ourmethod exhibits exceptional mathematical reasoning and OCR capabilities,despite these abilities not being explicitly trained within the VLA.Furthermore, we demonstrate that the VLA possesses strong spatial reasoningskills, enabling it to interpret novel directional instructions involvingpreviously unseen objects. Overall, our method showcases reasoning andcomprehension abilities that significantly surpass state-of-the-art imitationlearning methods such as OpenVLA, DexVLA, and pi-zero. This work represents asubstantial advancement toward developing truly generalizable roboticfoundation models endowed with robust reasoning capacities.</description>
      <author>example@mail.com (Zhongyi Zhou, Yichen Zhu, Junjie Wen, Chaomin Shen, Yi Xu)</author>
      <guid isPermaLink="false">2505.21906v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>CAST: Contrastive Adaptation and Distillation for Semi-Supervised Instance Segmentation</title>
      <link>http://arxiv.org/abs/2505.21904v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CAST是一种半监督知识蒸馏框架，用于将预训练视觉基础模型压缩成紧凑的专家，使用有限的标注数据和大量的未标注数据。&lt;h4&gt;背景&lt;/h4&gt;实例分割需要昂贵的每像素标注和大型模型。&lt;h4&gt;目的&lt;/h4&gt;提出CAST框架，以压缩预训练视觉基础模型并提高半监督学习的效果。&lt;h4&gt;方法&lt;/h4&gt;CAST分为三个阶段：(1) 通过自训练和对比像素校准进行域适应；(2) 通过统一的多目标损失函数进行蒸馏，该函数结合了标准监督和伪标签以及实例感知的像素级对比损失；(3) 在标注数据上进行微调以消除残留的伪标签偏差。&lt;h4&gt;主要发现&lt;/h4&gt;CAST的核心是一个实例感知的像素级对比损失，它融合了掩码和类别得分来挖掘信息性负样本并强制执行清晰的实例间边界。&lt;h4&gt;结论&lt;/h4&gt;在Cityscapes和ADE20K数据集上，CAST的学生模型（比其适应的VFM教师模型小11倍）在AP指标上分别提升了3.4和1.5，并且优于最先进的半监督学习方法。&lt;h4&gt;翻译&lt;/h4&gt;Instance segmentation requires costly per-pixel annotations and large models. We introduce CAST, a semi-supervised knowledge distillation (SSKD) framework that compresses pretrained vision foundation models (VFM) into compact experts using limited labeled and abundant unlabeled data. CAST unfolds in three stages: (1) domain adaptation of the VFM teacher(s) via self-training with contrastive pixel calibration, (2) distillation into a compact student via a unified multi-objective loss that couples standard supervision and pseudo-labels with our instance-aware pixel-wise contrastive term, and (3) fine-tuning on labeled data to remove residual pseudo-label bias. Central to CAST is an instance-aware pixel-wise contrastive loss that fuses mask and class scores to mine informative negatives and enforce clear inter-instance margins. By maintaining this contrastive signal across both adaptation and distillation, we align teacher and student embeddings and fully leverage unlabeled images. On Cityscapes and ADE20K, our ~11X smaller student surpasses its adapted VFM teacher(s) by +3.4 AP (33.9 vs. 30.5) and +1.5 AP (16.7 vs. 15.2) and outperforms state-of-the-art semi-supervised approaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Instance segmentation demands costly per-pixel annotations and large models.We introduce CAST, a semi-supervised knowledge distillation (SSKD) frameworkthat compresses pretrained vision foundation models (VFM) into compact expertsusing limited labeled and abundant unlabeled data. CAST unfolds in threestages: (1) domain adaptation of the VFM teacher(s) via self-training withcontrastive pixel calibration, (2) distillation into a compact student via aunified multi-objective loss that couples standard supervision andpseudo-labels with our instance-aware pixel-wise contrastive term, and (3)fine-tuning on labeled data to remove residual pseudo-label bias. Central toCAST is an \emph{instance-aware pixel-wise contrastive loss} that fuses maskand class scores to mine informative negatives and enforce clear inter-instancemargins. By maintaining this contrastive signal across both adaptation anddistillation, we align teacher and student embeddings and fully leverageunlabeled images. On Cityscapes and ADE20K, our ~11X smaller student surpassesits adapted VFM teacher(s) by +3.4 AP (33.9 vs. 30.5) and +1.5 AP (16.7 vs.15.2) and outperforms state-of-the-art semi-supervised approaches.</description>
      <author>example@mail.com (Pardis Taghavi, Tian Liu, Renjie Li, Reza Langari, Zhengzhong Tu)</author>
      <guid isPermaLink="false">2505.21904v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>CityGo: Lightweight Urban Modeling and Rendering with Proxy Buildings and Residual Gaussians</title>
      <link>http://arxiv.org/abs/2505.21041v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CityGo的混合框架，用于从空中视角对大规模城市场景进行轻量级、逼真的渲染。&lt;h4&gt;背景&lt;/h4&gt;准确高效地建模大规模城市场景对于AR导航、无人机检查和智能城市数字孪生等应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;旨在解决从空中视角重建城市规模环境时的挑战，如遮挡、不完整的几何形状和高内存需求。&lt;h4&gt;方法&lt;/h4&gt;CityGo结合了纹理代理几何与残差和周围3D高斯，通过图像渲染和反向投影生成无遮挡纹理。同时，使用基于代理-照片差异的残差高斯捕捉高频细节，并通过重要性感知的下采样减少非关键区域的冗余。&lt;h4&gt;主要发现&lt;/h4&gt;CityGo显著减少了训练时间，平均加速1.4倍，同时提供与纯3D高斯分层方法相当的视觉保真度。&lt;h4&gt;结论&lt;/h4&gt;CityGo能够在移动消费级GPU上实时渲染大规模城市场景，同时大幅减少内存使用和能耗。&lt;h4&gt;翻译&lt;/h4&gt;Accurate and efficient modeling of large-scale urban scenes is critical for applications such as AR navigation, UAV based inspection, and smart city digital twins. While aerial imagery offers broad coverage and complements limitations of ground-based data, reconstructing city-scale environments from such views remains challenging due to occlusions, incomplete geometry, and high memory demands. Recent advances like 3D Gaussian Splatting (3DGS) improve scalability and visual quality but remain limited by dense primitive usage, long training times, and poor suitability for edge devices. We propose CityGo, a hybrid framework that combines textured proxy geometry with residual and surrounding 3D Gaussians for lightweight, photorealistic rendering of urban scenes from aerial perspectives. Our approach first extracts compact building proxy meshes from MVS point clouds, then uses zero order SH Gaussians to generate occlusion-free textures via image-based rendering and back-projection. To capture high-frequency details, we introduce residual Gaussians placed based on proxy-photo discrepancies and guided by depth priors. Broader urban context is represented by surrounding Gaussians, with importance-aware downsampling applied to non-critical regions to reduce redundancy. A tailored optimization strategy jointly refines proxy textures and Gaussian parameters, enabling real-time rendering of complex urban scenes on mobile GPUs with significantly reduced training and memory requirements. Extensive experiments on real-world aerial datasets demonstrate that our hybrid representation significantly reduces training time, achieving on average 1.4x speedup, while delivering comparable visual fidelity to pure 3D Gaussian Splatting approaches. Furthermore, CityGo enables real-time rendering of large-scale urban scenes on mobile consumer GPUs, with substantially reduced memory usage and energy consumption.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and efficient modeling of large-scale urban scenes is critical forapplications such as AR navigation, UAV based inspection, and smart citydigital twins. While aerial imagery offers broad coverage and complementslimitations of ground-based data, reconstructing city-scale environments fromsuch views remains challenging due to occlusions, incomplete geometry, and highmemory demands. Recent advances like 3D Gaussian Splatting (3DGS) improvescalability and visual quality but remain limited by dense primitive usage,long training times, and poor suit ability for edge devices. We propose CityGo,a hybrid framework that combines textured proxy geometry with residual andsurrounding 3D Gaussians for lightweight, photorealistic rendering of urbanscenes from aerial perspectives. Our approach first extracts compact buildingproxy meshes from MVS point clouds, then uses zero order SH Gaussians togenerate occlusion-free textures via image-based rendering and back-projection.To capture high-frequency details, we introduce residual Gaussians placed basedon proxy-photo discrepancies and guided by depth priors. Broader urban contextis represented by surrounding Gaussians, with importance-aware downsamplingapplied to non-critical regions to reduce redundancy. A tailored optimizationstrategy jointly refines proxy textures and Gaussian parameters, enablingreal-time rendering of complex urban scenes on mobile GPUs with significantlyreduced training and memory requirements. Extensive experiments on real-worldaerial datasets demonstrate that our hybrid representation significantlyreduces training time, achieving on average 1.4x speedup, while deliveringcomparable visual fidelity to pure 3D Gaussian Splatting approaches.Furthermore, CityGo enables real-time rendering of large-scale urban scenes onmobile consumer GPUs, with substantially reduced memory usage and energyconsumption.</description>
      <author>example@mail.com (Weihang Liu, Yuhui Zhong, Yuke Li, Xi Chen, Jiadi Cui, Honglong Zhang, Lan Xu, Xin Lou, Yujiao Shi, Jingyi Yu, Yingliang Zhang)</author>
      <guid isPermaLink="false">2505.21041v2</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Bayesian Model Averaging in the Era of Foundation Models</title>
      <link>http://arxiv.org/abs/2505.21857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文重新审视了经典的贝叶斯模型平均（BMA）范式，以集成预训练和/或轻微微调的基础模型，增强图像和文本数据的分类性能。&lt;h4&gt;背景&lt;/h4&gt;在预训练基础模型的应用中，需要一种方法来集成这些模型，以优化分类性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于BMA的方法，以增强图像和文本数据的分类性能，并通过引入可训练的线性分类器来实现。&lt;h4&gt;方法&lt;/h4&gt;1. 介绍可训练的线性分类器，这些分类器以预训练基础模型的冻结特征为输入。2. 提出一种优化模型平均方案（OMA），直接优化模型集成权重，类似于基于模型后验分布的BMA，通过减少集成模型预测中的意外（预测的预期熵）来降低计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;模型后验告诉我们哪些线性头和冻结特征更适合特定数据集，从而实现一种原则性的模型集成方法。&lt;h4&gt;结论&lt;/h4&gt;这些方法将能够将未来可能显著更好的基础模型纳入其中，以增强具有挑战性的分类任务的性能。&lt;h4&gt;翻译&lt;/h4&gt;We revisit the classical, full-fledged Bayesian model averaging (BMA) paradigm to ensemble pre-trained and/or lightly-finetuned foundation models to enhance the classification performance on image and text data. To make BMA attractive under foundation models, we introduce trainable linear classifiers that take frozen features from the pre-trained foundation models as inputs. The model posteriors over the linear classifiers tell us which linear heads and frozen features are better suited for a given dataset, resulting in a principled model ensembling method. Furthermore, we propose a computationally cheaper, optimizable model averaging scheme (OMA). In OMA, we directly optimize the model ensemble weights, just like those weights based on model posteriordistributions in BMA, by reducing the amount of surprise (expected entropy of the predictions) we get from predictions of ensembled models. With the rapid development of foundation models, these approaches will enable the incorporation of future, possibly significantly better foundation models to enhance the performance of challenging classification tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We revisit the classical, full-fledged Bayesian model averaging (BMA)paradigm to ensemble pre-trained and/or lightly-finetuned foundation models toenhance the classification performance on image and text data. To make BMAtractable under foundation models, we introduce trainable linear classifiersthat take frozen features from the pre-trained foundation models as inputs. Themodel posteriors over the linear classifiers tell us which linear heads andfrozen features are better suited for a given dataset, resulting in aprincipled model ensembling method. Furthermore, we propose a computationallycheaper, optimizable model averaging scheme (OMA). In OMA, we directly optimizethe model ensemble weights, just like those weights based on model posteriordistributions in BMA, by reducing the amount of surprise (expected entropy ofthe predictions) we get from predictions of ensembled models. With the rapiddevelopment of foundation models, these approaches will enable theincorporation of future, possibly significantly better foundation models toenhance the performance of challenging classification tasks.</description>
      <author>example@mail.com (Mijung Park)</author>
      <guid isPermaLink="false">2505.21857v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment</title>
      <link>http://arxiv.org/abs/2505.21561v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted to the CVPR Workshop 2025, to be held in  Nashville, Tennessee&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的深度学习框架，用于自动分期诊断蝶枕骨合（SOS）融合，这在正畸学和法医人类学中是一个关键的诊断标志。&lt;h4&gt;背景&lt;/h4&gt;蝶枕骨合（SOS）融合是正畸学和法医人类学中的重要诊断标志。&lt;h4&gt;目的&lt;/h4&gt;开发一种自动化分期诊断蝶枕骨合（SOS）融合的深度学习框架。&lt;h4&gt;方法&lt;/h4&gt;该框架采用双模型架构，其中教师模型在手动裁剪的图像上训练，将精确的空间理解转移到操作完整未裁剪图像的学生模型上。这种知识蒸馏通过一个新设计的损失函数实现，该函数将空间logits对齐，并整合基于梯度的注意力空间映射，确保学生模型能够内化与解剖相关的特征，而不依赖于外部裁剪或YOLO基于分割。&lt;h4&gt;主要发现&lt;/h4&gt;通过利用专家精选的数据和每一步的反馈，该框架达到了稳健的诊断准确性，最终形成了一个临床可行的端到端流程。这种简化的方法避免了额外的预处理工具，并加速了部署，从而提高了在不同临床环境中骨骼成熟度评估的效率和一致性。&lt;h4&gt;结论&lt;/h4&gt;该框架为蝶枕骨合（SOS）融合的自动化分期诊断提供了一种高效、一致的方法，有助于提高临床诊断的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a novel deep learning framework for the automated staging ofspheno-occipital synchondrosis (SOS) fusion, a critical diagnostic marker inboth orthodontics and forensic anthropology. Our approach leverages adual-model architecture wherein a teacher model, trained on manually croppedimages, transfers its precise spatial understanding to a student model thatoperates on full, uncropped images. This knowledge distillation is facilitatedby a newly formulated loss function that aligns spatial logits as well asincorporates gradient-based attention spatial mapping, ensuring that thestudent model internalizes the anatomically relevant features without relyingon external cropping or YOLO-based segmentation. By leveraging expert-curateddata and feedback at each step, our framework attains robust diagnosticaccuracy, culminating in a clinically viable end-to-end pipeline. Thisstreamlined approach obviates the need for additional pre-processing tools andaccelerates deployment, thereby enhancing both the efficiency and consistencyof skeletal maturation assessment in diverse clinical settings.</description>
      <author>example@mail.com (Omid Halimi Milani, Amanda Nikho, Marouane Tliba, Lauren Mills, Ahmet Enis Cetin, Mohammed H Elnagar)</author>
      <guid isPermaLink="false">2505.21561v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>TuneComp: Joint Fine-tuning and Compression for Large Foundation Models</title>
      <link>http://arxiv.org/abs/2505.21835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preliminary Work&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在模型后训练阶段直接构建较小模型的方法，通过联合微调和压缩，显著优于其他顺序压缩方法。&lt;h4&gt;背景&lt;/h4&gt;在模型后训练阶段，为了减小模型大小，通常采用压缩方法，如知识蒸馏、低秩逼近和剪枝。&lt;h4&gt;目的&lt;/h4&gt;旨在减少在微调和压缩过程中性能损失和中间步骤产生的不必要大模型。&lt;h4&gt;方法&lt;/h4&gt;通过逐步蒸馏模型到剪枝的低秩结构，实现模型的联合微调和压缩。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，联合微调和压缩在性能上显著优于其他顺序压缩方法。&lt;h4&gt;结论&lt;/h4&gt;提出的联合微调和压缩方法可以有效地减小模型大小，同时保持或提高模型性能。&lt;h4&gt;翻译&lt;/h4&gt;To reduce model size during post-training, compression methods, including knowledge distillation, low-rank approximation, and pruning, are often applied after fine-tuning the model. However, sequential fine-tuning and compression sacrifices performance, while creating a larger than necessary model as an intermediate step. In this work, we aim to reduce this gap, by directly constructing a smaller model while guided by the downstream task. We propose to jointly fine-tune and compress the model by gradually distilling it to a pruned low-rank structure. Experiments demonstrate that joint fine-tuning and compression significantly outperforms other sequential compression methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To reduce model size during post-training, compression methods, includingknowledge distillation, low-rank approximation, and pruning, are often appliedafter fine-tuning the model. However, sequential fine-tuning and compressionsacrifices performance, while creating a larger than necessary model as anintermediate step. In this work, we aim to reduce this gap, by directlyconstructing a smaller model while guided by the downstream task. We propose tojointly fine-tune and compress the model by gradually distilling it to a prunedlow-rank structure. Experiments demonstrate that joint fine-tuning andcompression significantly outperforms other sequential compression methods.</description>
      <author>example@mail.com (Xiangyu Chen, Jing Liu, Ye Wang, Matthew Brand, Pu, Wang, Toshiaki Koike-Akino)</author>
      <guid isPermaLink="false">2505.21835v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Query, Don't Train: Privacy-Preserving Tabular Prediction from EHR Data via SQL Queries</title>
      <link>http://arxiv.org/abs/2505.21801v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了QDT，一个结构化数据基础模型接口，通过大型语言模型生成SQL查询，实现对电子健康记录（EHRs）的表格推理，同时保护患者隐私。&lt;h4&gt;背景&lt;/h4&gt;EHRs数据对于预测模型非常重要，但严格的隐私法规（如HIPAA、GDPR）通常限制对个人级别记录的访问。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种方法，能够在不访问个人级别数据的情况下，利用EHRs数据进行分析和预测。&lt;h4&gt;方法&lt;/h4&gt;QDT使用大型语言模型（LLM）作为模式感知查询规划器，从自然语言任务描述和测试时输入生成隐私合规的SQL查询。模型通过这些查询提取人口统计学摘要，并利用LLM进行思维链推理以做出预测。&lt;h4&gt;主要发现&lt;/h4&gt;QDT在不进行监督模型训练或直接访问数据的情况下，通过SQL查询提取摘要级人口统计学统计，并在预测30天住院再次入院方面达到F1 = 0.70，优于TabPFN（F1 = 0.68）。这是第一个仅使用模式元数据和汇总统计进行隐私保护的结构化预测的LLM驱动的演示。&lt;h4&gt;结论&lt;/h4&gt;QDT提供了一个可扩展、可解释且符合法规的替代方案，为传统的基座模型管道提供了一种新的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：电子健康记录（EHRs）包含了丰富的结构化、纵向数据，这些数据对于预测建模至关重要，但严格的隐私法规（例如，HIPAA，GDPR）往往限制了个人级别记录的访问。我们引入了Query, Don't Train（QDT）：一个结构化数据基础模型接口，它通过LLM生成的SQL查询来实现对EHRs的表格推理。QDT不依赖于或访问个人级别的示例进行训练，而是使用大型语言模型（LLM）作为模式感知的查询规划器，从自然语言任务描述和测试时输入生成隐私合规的SQL查询。然后，该模型通过这些SQL查询提取摘要级别的人口统计学统计，LLM在结果上执行思维链推理以做出预测。这种仅在推理时间进行的途径（1）消除了监督模型训练或直接数据访问的需求，（2）通过符号、可审计的查询确保了可解释性，（3）自然处理缺失特征，无需插补或预处理，（4）有效管理高维数值数据，以增强分析能力。我们使用MIMIC风格的EHR队列对QDT进行了30天住院再次入院预测任务的有效性验证，对于2型糖尿病患者的F1 = 0.70，优于TabPFN（F1 = 0.68）。据我们所知，这是第一个仅使用模式元数据和汇总统计进行LLM驱动、隐私保护的结构化预测的演示——提供了一种可扩展、可解释且符合法规的替代方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electronic health records (EHRs) contain richly structured, longitudinal dataessential for predictive modeling, yet stringent privacy regulations (e.g.,HIPAA, GDPR) often restrict access to individual-level records. We introduceQuery, Don't Train (QDT): a structured-data foundation-model interface enablingtabular inference via LLM-generated SQL over EHRs. Instead of training on oraccessing individual-level examples, QDT uses a large language model (LLM) as aschema-aware query planner to generate privacy-compliant SQL queries from anatural language task description and a test-time input. The model thenextracts summary-level population statistics through these SQL queries and theLLM performs, chain-of-thought reasoning over the results to make predictions.This inference-time-only approach (1) eliminates the need for supervised modeltraining or direct data access, (2) ensures interpretability through symbolic,auditable queries, (3) naturally handles missing features without imputation orpreprocessing, and (4) effectively manages high-dimensional numerical data toenhance analytical capabilities. We validate QDT on the task of 30-day hospitalreadmission prediction for Type 2 diabetes patients using a MIMIC-style EHRcohort, achieving F1 = 0.70, which outperforms TabPFN (F1 = 0.68). To ourknowledge, this is the first demonstration of LLM-driven, privacy-preservingstructured prediction using only schema metadata and aggregate statistics -offering a scalable, interpretable, and regulation-compliant alternative toconventional foundation-model pipelines.</description>
      <author>example@mail.com (Josefa Lia Stoisser, Marc Boubnovski Martell, Kaspar Märtens, Lawrence Phillips, Stephen Michael Town, Rory Donovan-Maiye, Julien Fauqueur)</author>
      <guid isPermaLink="false">2505.21801v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Modeling the Path of Structural Strategic Deterrence: A Sand Table Simulation and Research Report on China's Military-Industrial Capability System against the United States Based on Rare Earth Supply Disconnection</title>
      <link>http://arxiv.org/abs/2505.21579v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper presents a novel AI-driven simulation framework  integrating GNN and LSTM to model non-kinetic deterrence through rare earth  export cut-offs, offering quantifiable insights into systemic impacts on U.S.  military capabilities&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种基于战略稀土供应切断的系统非动力学威慑路径建模框架，旨在评估中国对美国的出口控制政策在军事系统层面的战略影响。&lt;h4&gt;背景&lt;/h4&gt;研究背景涉及中国对美国的出口控制政策，特别是针对稀土资源的控制。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过模型评估中国出口控制政策对美军军事系统的影响，以及稀土供应中断对美国关键军事平台的影响。&lt;h4&gt;方法&lt;/h4&gt;模型采用“政策输入-资源节点-装备系统-能力输出”的四层结构，并集成了路径依赖建模、退化函数设计和能力滞后预测机制，形成战略仿真系统。此外，研究还结合了图神经网络和基于LSTM的时间序列方法，以动态评估稀土供应中断对美国F-35战斗机、核潜艇和人工智能作战系统等关键军事平台的影响。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，十年零容忍的稀土出口政策会导致第3至5年之间出现显著的技术脱节，以及第8至12年之间的系统性能力滞后，预计平均每年经济损失为350至400亿美元。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，稀土出口切断可以作为结构性的战略威慑手段，能够在不直接对抗的情况下扰乱部署节奏。提出的模型为战略决策提供了可量化和可视化的工具，并支持国家级安全模拟和政策优化研究。&lt;h4&gt;翻译&lt;/h4&gt;本研究提出了一种基于战略稀土供应切断的系统非动力学威慑路径建模框架，旨在评估中国对美国的出口控制政策在军事系统层面的战略影响。模型采用“政策输入-资源节点-装备系统-能力输出”的四层结构，并集成了路径依赖建模、退化函数设计和能力滞后预测机制，形成战略仿真系统。此外，研究还结合了图神经网络和基于LSTM的时间序列方法，以动态评估稀土供应中断对美国F-35战斗机、核潜艇和人工智能作战系统等关键军事平台的影响。研究发现，十年零容忍的稀土出口政策会导致第3至5年之间出现显著的技术脱节，以及第8至12年之间的系统性能力滞后，预计平均每年经济损失为350至400亿美元。研究结果表明，稀土出口切断可以作为结构性的战略威慑手段，能够在不直接对抗的情况下扰乱部署节奏。提出的模型为战略决策提供了可量化和可视化的工具，并支持国家级安全模拟和政策优化研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study proposes a systematic non-kinetic deterrence path modelingframework based on strategic rare earth supply cut-off, aiming to assess thestrategic effects of China's export control policy against the United States atthe military system level. The model adopts a four-layer structure of "policyinput -- resource node -- equipment system -- capability output" and integratespath dependency modeling, degradation function design, and capability lagprediction mechanisms to form a strategic simulation system. The studyincorporates graph neural networks and LSTM-based time series methods todynamically evaluate the impact of rare earth supply disruption on key U.S.military platforms such as the F-35 fighter, nuclear submarines, and AI combatsystems, identifying critical path nodes and strategic timing windows. Resultsindicate that a ten-year zero-tolerance policy on rare earth exports would leadto a significant technological disconnect between years 3 to 5 and a systemiccapability lag between years 8 to 12, with an estimated average annual economicimpact of 35 to 40 billion USD. These findings demonstrate that rare earthexport cut-offs can serve as a structural strategic deterrent capable ofdisrupting deployment tempos without direct confrontation. The proposed modelprovides quantifiable and visualized tools for strategic decision-making andsupports national-level security simulations and policy optimization research.</description>
      <author>example@mail.com (Wei Meng)</author>
      <guid isPermaLink="false">2505.21579v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Born a Transformer -- Always a Transformer?</title>
      <link>http://arxiv.org/abs/2505.21785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了Transformer在序列到序列任务中的理论限制，并探讨了这些限制在大型预训练语言模型（LLM）中的作用，以及LLM是否能通过模型规模和预训练数据的规模来克服这些限制。&lt;h4&gt;背景&lt;/h4&gt;Transformer在建模某些序列到序列任务时存在理论上的局限性，但这些局限性在大型预训练LLM中的作用尚不清楚。&lt;h4&gt;目的&lt;/h4&gt;通过研究受Liu等（2024）启发的检索和复制任务，探讨这些架构限制在预训练后的表现。&lt;h4&gt;方法&lt;/h4&gt;使用C-RASP框架研究长度泛化，并通过对预训练模型进行针对性的微调来分析模型在检索任务中的表现。&lt;h4&gt;主要发现&lt;/h4&gt;观察到预训练模型在检索查询标记右侧的标记（归纳）方面优于左侧（反归纳），但这种不对称性在理论保证长度泛化后消失。机制分析表明，这种不对称性与预训练Transformer中归纳和反归纳电路的强度差异有关。&lt;h4&gt;结论&lt;/h4&gt;预训练选择性地增强了Transformer的某些能力，但并未克服基本的长度泛化限制。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the theoretical limitations of Transformers in modeling certain sequence-to-sequence tasks, and explores the role of these limitations in large-scale pretrained language models (LLMs), as well as whether LLMs can effectively overcome these constraints in practice due to the scale of both the models themselves and their pretraining data. The paper explores how these architectural constraints manifest after pretraining by studying a family of retrieval and copying tasks inspired by Liu et al. [2024]. The recently proposed C-RASP framework for studying length generalization [Huang et al., 2025b] is used to provide guarantees for each of our settings. Empirically, an induction-versus-anti-induction asymmetry is observed, where pretrained models are better at retrieving tokens to the right (induction) rather than the left (anti-induction) of a query token. This asymmetry disappears upon targeted fine-tuning if length generalization is guaranteed by theory. Mechanistic analysis reveals that this asymmetry is connected to the differences in the strength of induction versus anti-induction circuits within pretrained Transformers. The findings are validated through practical experiments on real-world tasks demonstrating reliability risks. The results highlight that pretraining selectively enhances certain Transformer capabilities, but does not overcome fundamental length generalization limits.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformers have theoretical limitations in modeling certainsequence-to-sequence tasks, yet it remains largely unclear if these limitationsplay a role in large-scale pretrained LLMs, or whether LLMs might effectivelyovercome these constraints in practice due to the scale of both the modelsthemselves and their pretraining data. We explore how these architecturalconstraints manifest after pretraining, by studying a family of$\textit{retrieval}$ and $\textit{copying}$ tasks inspired by Liu et al.[2024]. We use the recently proposed C-RASP framework for studying lengthgeneralization [Huang et al., 2025b] to provide guarantees for each of oursettings. Empirically, we observe an $\textit{induction-versus-anti-induction}$asymmetry, where pretrained models are better at retrieving tokens to the right(induction) rather than the left (anti-induction) of a query token. Thisasymmetry disappears upon targeted fine-tuning if length-generalization isguaranteed by theory. Mechanistic analysis reveals that this asymmetry isconnected to the differences in the strength of induction versus anti-inductioncircuits within pretrained Transformers. We validate our findings throughpractical experiments on real-world tasks demonstrating reliability risks. Ourresults highlight that pretraining selectively enhances certain Transformercapabilities, but does not overcome fundamental length-generalization limits.</description>
      <author>example@mail.com (Yana Veitsman, Mayank Jobanputra, Yash Sarrof, Aleksandra Bakalova, Vera Demberg, Ellie Pavlick, Michael Hahn)</author>
      <guid isPermaLink="false">2505.21785v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>LaX: Boosting Low-Rank Training of Foundation Models via Latent Crossing</title>
      <link>http://arxiv.org/abs/2505.21732v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Latent Crossing(LaX)模块，用于增强低秩模型的能力，通过允许信息在不同低秩子空间之间流动，提升了低秩模型在预训练任务上的性能，同时参数使用量减少。&lt;h4&gt;背景&lt;/h4&gt;训练像ViTs和LLMs这样的基础模型需要巨大的计算成本，低秩矩阵或张量分解提供了一种参数高效的替代方案，但通常由于参数空间的限制而降低了性能。&lt;h4&gt;目的&lt;/h4&gt;提出LaX模块，旨在通过信息流动提升低秩模型的能力。&lt;h4&gt;方法&lt;/h4&gt;LaX是一个简单有效的模块，可以在低秩子空间之间实现信息流动，并在预训练任务上对ViT-Base/Large和类似LLaMA的模型进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;LaX可以提升低秩模型性能，使其达到或超过全秩基线，同时参数使用量减少了2-3倍。在LLaMA-7/13B模型上使用低秩适配器（LoRA）进行微调时，LaX在算术和常识推理任务上显著提升了性能，且成本可以忽略。&lt;h4&gt;结论&lt;/h4&gt;LaX是一种有效的方法，可以在减少参数使用的同时提升低秩模型的表现，对预训练和微调任务均有益处。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training foundation models such as ViTs and LLMs requires tremendouscomputing cost. Low-rank matrix or tensor factorization offers aparameter-efficient alternative, but often downgrades performance due to therestricted parameter space. In this work, we introduce {\textbf{Latent Crossing(LaX)}} -- a simple yet effective plug-and-play module that enhances thecapacity of low-rank models by enabling information flow across low-ranksubspaces. We extensively validate the benefits of LaX on pre-training taskswith ViT-Base/Large and LLaMA-like models ranging from 60M to 1B parameters.LaX boosts low-rank model performance to match or exceed the full-rankbaselines while using 2-3\(\times\) fewer parameters. When equipped withlow-rank adapters (i.e., LoRA) for fine-tuning LLaMA-7/13B, LaX consistentlyimproves performance on arithmetic and common sense reasoning tasks withnegligible cost.</description>
      <author>example@mail.com (Ruijie Zhang, Ziyue Liu, Zhengyang Wang, Zheng Zhang)</author>
      <guid isPermaLink="false">2505.21732v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>MedBridge: Bridging Foundation Vision-Language Models to Medical Image Diagnosis</title>
      <link>http://arxiv.org/abs/2505.21698v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MedBridge是一个轻量级的跨模态适应框架，用于提高医学图像诊断的准确性，同时减少资源消耗。&lt;h4&gt;背景&lt;/h4&gt;现有的视觉语言基础模型在自然图像分类方面表现优异，但在医学图像分类上效果不佳，因为存在显著的领域差异。同时，训练医学基础模型需要大量的资源。&lt;h4&gt;目的&lt;/h4&gt;开发一种轻量级的框架，以最小的开销将预训练的视觉语言模型（VLMs）用于准确的医学图像诊断。&lt;h4&gt;方法&lt;/h4&gt;MedBridge包含三个关键组件：1. 焦点采样模块，用于提取高分辨率局部区域，以捕捉细微的病理特征并补偿通用VLMs的有限输入分辨率；2. 查询编码器（QEncoder），通过一小组可学习的查询关注冻结的VLM特征图，以与医学语义对齐，而无需重新训练整个骨干网络；3. 专家混合机制，由可学习查询驱动，利用不同VLMs的互补优势，以最大化诊断性能。&lt;h4&gt;主要发现&lt;/h4&gt;MedBridge在五个医学成像基准上的三个关键适应任务中进行了评估，证明了其在跨领域和领域适应设置中的优越性能，即使在训练数据可用性较低的情况下。特别是在多标签胸部疾病诊断中，与最先进的VLM适应方法相比，MedBridge实现了6-15%的AUC提升。&lt;h4&gt;结论&lt;/h4&gt;MedBridge有效地利用了基础模型，在准确性和数据效率方面提高了医学诊断。&lt;h4&gt;翻译&lt;/h4&gt;最近，视觉语言基础模型在自然图像分类上取得了最先进的成果，但在医学图像上表现不佳，因为存在显著的领域差异。同时，训练医学基础模型需要大量的资源，包括大量的标注数据和强大的计算能力。为了以最小的开销弥合这一差距，我们引入了MedBridge，一个轻量级的跨模态适应框架，用于将预训练的VLMs重新用于准确的医学图像诊断。MedBridge包含三个关键组件。首先，一个焦点采样模块，用于提取高分辨率局部区域，以捕捉细微的病理特征并补偿通用VLMs的有限输入分辨率。其次，一个查询编码器（QEncoder），通过一小部分可学习的查询关注冻结的VLM特征图，以与医学语义对齐，而无需重新训练整个骨干网络。第三，一个由可学习查询驱动的专家混合机制，利用不同VLMs的互补优势，以最大化诊断性能。我们在五个医学成像基准上的三个关键适应任务中评估了MedBridge，证明了其在跨领域和领域适应设置中的优越性能，即使在训练数据可用性较低的情况下。值得注意的是，与最先进的VLM适应方法相比，在多标签胸部疾病诊断中，MedBridge实现了6-15%的AUC提升，这突出了它在利用基础模型进行准确和高效医学诊断方面的有效性。我们的代码可在https://github.com/ai-med/MedBridge上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent vision-language foundation models deliver state-of-the-art results onnatural image classification but falter on medical images due to pronounceddomain shifts. At the same time, training a medical foundation model requiressubstantial resources, including extensive annotated data and highcomputational capacity. To bridge this gap with minimal overhead, we introduceMedBridge, a lightweight multimodal adaptation framework that re-purposespretrained VLMs for accurate medical image diagnosis. MedBridge comprises threekey components. First, a Focal Sampling module that extracts high-resolutionlocal regions to capture subtle pathological features and compensate for thelimited input resolution of general-purpose VLMs. Second, a Query Encoder(QEncoder) injects a small set of learnable queries that attend to the frozenfeature maps of VLM, aligning them with medical semantics without retrainingthe entire backbone. Third, a Mixture of Experts mechanism, driven by learnablequeries, harnesses the complementary strength of diverse VLMs to maximizediagnostic performance. We evaluate MedBridge on five medical imagingbenchmarks across three key adaptation tasks, demonstrating its superiorperformance in both cross-domain and in-domain adaptation settings, even undervarying levels of training data availability. Notably, MedBridge achieved over6-15% improvement in AUC compared to state-of-the-art VLM adaptation methods inmulti-label thoracic disease diagnosis, underscoring its effectiveness inleveraging foundation models for accurate and data-efficient medical diagnosis.Our code is available at https://github.com/ai-med/MedBridge.</description>
      <author>example@mail.com (Yitong Li, Morteza Ghahremani, Christian Wachinger)</author>
      <guid isPermaLink="false">2505.21698v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Incentivizing Permissionless Distributed Learning of LLMs</title>
      <link>http://arxiv.org/abs/2505.21684v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种针对分布式深度学习基础模型的激励系统，即Gauntlet，该系统在bittensor区块链上部署，并用于训练一个1.2B的LLM，通过无权限的伪梯度贡献实现。Gauntlet适用于任何依赖聚合更新或伪梯度的同步分布式训练方案。&lt;h4&gt;背景&lt;/h4&gt;分布式深度学习需要高效的激励系统来奖励贡献者。&lt;h4&gt;目的&lt;/h4&gt;开发一个激励系统，以促进分布式深度学习中的贡献。&lt;h4&gt;方法&lt;/h4&gt;Gauntlet系统通过两阶段机制快速筛选节点在线时间、可靠性和同步性，核心组件估算伪梯度贡献前后的损失，并利用OpenSkill评分系统跟踪伪梯度分数的竞争力。此外，引入了一种新机制确保网络中的节点执行独特的计算。&lt;h4&gt;主要发现&lt;/h4&gt;Gauntlet系统在1.2B的模型运行中，根据参与者贡献的价值支付了真实价值的代币，并证明了激励系统的有效性。&lt;h4&gt;结论&lt;/h4&gt;Gauntlet系统在促进分布式深度学习中的贡献方面是有效的，能够产生具有竞争力的模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We describe an incentive system for distributed deep learning of foundationalmodels where peers are rewarded for contributions. The incentive system,\textit{Gauntlet}, has been deployed on the bittensor blockchain and used totrain a 1.2B LLM with completely permissionless contributions ofpseudo-gradients: no control over the users that can register or theirhardware. \textit{Gauntlet} can be applied to any synchronous distributedtraining scheme that relies on aggregating updates or pseudo-gradients. We relyon a two-stage mechanism for fast filtering of peer uptime, reliability, andsynchronization, combined with the core component that estimates the lossbefore and after individual pseudo-gradient contributions. We utilized anOpenSkill rating system to track competitiveness of pseudo-gradient scoresacross time. Finally, we introduce a novel mechanism to ensure peers on thenetwork perform unique computations. Our live 1.2B run, which has paid outreal-valued tokens to participants based on the value of their contributions,yielded a competitive (on a per-iteration basis) 1.2B model that demonstratesthe utility of our incentive system.</description>
      <author>example@mail.com (Joel Lidin, Amir Sarfi, Evangelos Pappas, Samuel Dare, Eugene Belilovsky, Jacob Steeves)</author>
      <guid isPermaLink="false">2505.21684v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Geometric Feature Prompting of Image Segmentation Models</title>
      <link>http://arxiv.org/abs/2505.21644v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了机器学习，特别是transformer架构和视觉transformer的引入，推动了计算机视觉基础模型的发展。SAM模型是一种用于自然图像分割的高性能基础模型，并已应用于医学和科学图像分割任务。本文提出了一种基于几何的提示生成器，用于生成与特定特征共定位的提示点，从而实现使用SAM在科学图像分析任务中的敏感和特定分割。&lt;h4&gt;背景&lt;/h4&gt;机器学习的发展，特别是transformer架构和视觉transformer的引入，促进了计算机视觉基础模型的发展。SAM模型是一种高性能的基础模型，用于自然图像分割，并已应用于医学和科学图像分割任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于几何的提示生成器，用于生成与特定特征共定位的提示点，以实现使用SAM在科学图像分析任务中的敏感和特定分割。&lt;h4&gt;方法&lt;/h4&gt;使用基于几何的提示生成器生成提示点，用于SAM模型在植物根分割等科学图像分析任务中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;基于几何的提示生成器可以自动生成敏感和特定的分割，显著提高了rhizotron图像处理的质量。&lt;h4&gt;结论&lt;/h4&gt;基于几何的提示生成器可以有效地提高SAM模型在科学图像分析任务中的性能，有助于自动化植物根分割等困难的图像分析任务。&lt;h4&gt;翻译&lt;/h4&gt;Advances in machine learning, especially the introduction of transformer architectures and vision transformers, have led to the development of highly capable computer vision foundation models. The segment anything model (known colloquially as SAM and more recently SAM 2), is a highly capable foundation model for segmentation of natural images and has been further applied to medical and scientific image segmentation tasks. SAM relies on prompts -- points or regions of interest in an image -- to generate associated segmentations. In this manuscript we propose the use of a geometrically motivated prompt generator to produce prompt points that are colocated with particular features of interest. Focused prompting enables the automatic generation of sensitive and specific segmentations in a scientific image analysis task using SAM with relatively few point prompts. The image analysis task examined is the segmentation of plant roots in rhizotron or minirhizotron images, which have historically been a difficult task to automate. Hand annotation of rhizotron images is laborious and often subjective; SAM, initialized with GeomPrompt local ridge prompts has the potential to dramatically improve rhizotron image processing. The authors have concurrently released an open source software suite called geomprompt https://pypi.org/project/geomprompt/ that can produce point prompts in a format that enables direct integration with the segment-anything package.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advances in machine learning, especially the introduction of transformerarchitectures and vision transformers, have led to the development of highlycapable computer vision foundation models. The segment anything model (knowncolloquially as SAM and more recently SAM 2), is a highly capable foundationmodel for segmentation of natural images and has been further applied tomedical and scientific image segmentation tasks. SAM relies on prompts --points or regions of interest in an image -- to generate associatedsegmentations.  In this manuscript we propose the use of a geometrically motivated promptgenerator to produce prompt points that are colocated with particular featuresof interest. Focused prompting enables the automatic generation of sensitiveand specific segmentations in a scientific image analysis task using SAM withrelatively few point prompts. The image analysis task examined is thesegmentation of plant roots in rhizotron or minirhizotron images, which hashistorically been a difficult task to automate. Hand annotation of rhizotronimages is laborious and often subjective; SAM, initialized with GeomPromptlocal ridge prompts has the potential to dramatically improve rhizotron imageprocessing.  The authors have concurrently released an open source software suite calledgeomprompt https://pypi.org/project/geomprompt/ that can produce point promptsin a format that enables direct integration with the segment-anything package.</description>
      <author>example@mail.com (Kenneth Ball, Erin Taylor, Nirav Patel, Andrew Bartels, Gary Koplik, James Polly, Jay Hineman)</author>
      <guid isPermaLink="false">2505.21644v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Caption This, Reason That: VLMs Caught in the Middle</title>
      <link>http://arxiv.org/abs/2505.21538v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文对视觉语言模型（VLMs）在视觉理解方面的进步进行了分析，指出了其与人类能力在特定视觉任务上的差距，并提出了改进的方法。&lt;h4&gt;背景&lt;/h4&gt;近年来，视觉语言模型在视觉理解方面取得了显著进展，但在计数或关系推理等特定视觉任务上仍落后于人类。&lt;h4&gt;目的&lt;/h4&gt;为了理解VLMs的潜在限制，论文采用了认知科学的方法，分析了VLMs在感知、注意力和记忆力等核心认知轴上的表现。&lt;h4&gt;方法&lt;/h4&gt;使用一系列针对这些能力的任务，评估了包括GPT-4o在内的最先进的VLMs，并通过视觉-文本解耦分析来研究失败的原因和改进方法。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，尽管高级模型在某些任务上接近天花板性能（例如类别识别），但在需要空间理解或选择性注意的任务上仍存在显著差距。当模型在自身生成的文本说明上进行推理时，表现较差的模型显示出显著的改进。&lt;h4&gt;结论&lt;/h4&gt;论文强调了改善VLMs的思维链（CoT）能力的重要性，即使在表现超过人类水平的模型中也是如此。此外，还证明了在复合视觉推理任务上进行针对性微调的潜力，并表明对较小的VLMs进行微调可以显著提高核心认知能力。&lt;h4&gt;翻译&lt;/h4&gt;Vision-Language Models (VLMs) have shown remarkable progress in visual understanding in recent years. Yet, they still lag behind human capabilities in specific visual tasks such as counting or relational reasoning. To understand the underlying limitations, we adopt methodologies from cognitive science, analyzing VLM performance along core cognitive axes: Perception, Attention, and Memory. Using a suite of tasks targeting these abilities, we evaluate state-of-the-art VLMs, including GPT-4o. Our analysis reveals distinct cognitive profiles: while advanced models approach ceiling performance on some tasks (e.g. category identification), a significant gap persists, particularly in tasks requiring spatial understanding or selective attention. Investigating the source of these failures and potential methods for improvement, we employ a vision-text decoupling analysis, finding that models struggling with direct visual reasoning show marked improvement when reasoning over their own generated text captions. These experiments reveal a strong need for improved VLM Chain-of-Thought (CoT) abilities, even in models that consistently exceed human performance. Furthermore, we demonstrate the potential of targeted fine-tuning on composite visual reasoning tasks and show that fine-tuning smaller VLMs substantially improves core cognitive abilities. While this improvement does not translate to large enhancements on challenging, out-of-distribution benchmarks, we show broadly that VLM performance on our datasets strongly correlates with performance on these other benchmarks. Our work provides a detailed analysis of VLM cognitive strengths and weaknesses and identifies key bottlenecks in simultaneous perception and reasoning while also providing an effective and simple solution.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Models (VLMs) have shown remarkable progress in visualunderstanding in recent years. Yet, they still lag behind human capabilities inspecific visual tasks such as counting or relational reasoning. To understandthe underlying limitations, we adopt methodologies from cognitive science,analyzing VLM performance along core cognitive axes: Perception, Attention, andMemory. Using a suite of tasks targeting these abilities, we evaluatestate-of-the-art VLMs, including GPT-4o. Our analysis reveals distinctcognitive profiles: while advanced models approach ceiling performance on sometasks (e.g. category identification), a significant gap persists, particularlyin tasks requiring spatial understanding or selective attention. Investigatingthe source of these failures and potential methods for improvement, we employ avision-text decoupling analysis, finding that models struggling with directvisual reasoning show marked improvement when reasoning over their owngenerated text captions. These experiments reveal a strong need for improvedVLM Chain-of-Thought (CoT) abilities, even in models that consistently exceedhuman performance. Furthermore, we demonstrate the potential of targetedfine-tuning on composite visual reasoning tasks and show that fine-tuningsmaller VLMs substantially improves core cognitive abilities. While thisimprovement does not translate to large enhancements on challenging,out-of-distribution benchmarks, we show broadly that VLM performance on ourdatasets strongly correlates with performance on these other benchmarks. Ourwork provides a detailed analysis of VLM cognitive strengths and weaknesses andidentifies key bottlenecks in simultaneous perception and reasoning while alsoproviding an effective and simple solution.</description>
      <author>example@mail.com (Zihan Weng, Lucas Gomez, Taylor Whittington Webb, Pouya Bashivan)</author>
      <guid isPermaLink="false">2505.21538v1</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>AgriFM: A Multi-source Temporal Remote Sensing Foundation Model for Crop Mapping</title>
      <link>http://arxiv.org/abs/2505.21357v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AgriFM的多源遥感基础模型，旨在提高作物地图绘制的准确性。&lt;h4&gt;背景&lt;/h4&gt;作物地图绘制依赖于多尺度时空模式建模，但目前基于Transformer的遥感基础模型在作物地图绘制方面仍存在不足。&lt;h4&gt;目的&lt;/h4&gt;提出AgriFM模型，以解决现有遥感基础模型在作物地图绘制中的不足。&lt;h4&gt;方法&lt;/h4&gt;AgriFM通过同时进行分层时空特征提取，并采用修改后的Video Swin Transformer架构，实现时空数据的统一处理。模型利用来自MODIS、Landsat-8/9和Sentinel-2三个卫星源的数据，并在包含超过2500万图像样本的全球代表性数据集上进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;AgriFM在所有下游任务中均表现出优于传统深度学习和最先进的通用遥感基础模型的性能。&lt;h4&gt;结论&lt;/h4&gt;AgriFM模型为作物地图绘制提供了一种高效且准确的方法。&lt;h4&gt;翻译&lt;/h4&gt;Accurate crop mapping fundamentally relies on modeling multi-scale spatiotemporal patterns, where spatial scales range from individual field textures to landscape-level context, and temporal scales capture both short-term phenological transitions and full growing-season dynamics. Transformer-based remote sensing foundation models (RSFMs) offer promising potential for crop mapping due to their innate ability for unified spatiotemporal processing. However, current RSFMs remain suboptimal for crop mapping: they either employ fixed spatiotemporal windows that ignore the multi-scale nature of crop systems or completely disregard temporal information by focusing solely on spatial patterns. To bridge these gaps, we present AgriFM, a multi-source remote sensing foundation model specifically designed for agricultural crop mapping. Our approach begins by establishing the necessity of simultaneous hierarchical spatiotemporal feature extraction, leading to the development of a modified Video Swin Transformer architecture where temporal down-sampling is synchronized with spatial scaling operations. This modified backbone enables efficient unified processing of long time-series satellite inputs. AgriFM leverages temporally rich data streams from three satellite sources including MODIS, Landsat-8/9 and Sentinel-2, and is pre-trained on a global representative dataset comprising over 25 million images samples supervised by land cover products. The resulting framework incorporates a versatile decoder architecture that dynamically fuses these learned spatiotemporal representations, supporting diverse downstream tasks. Comprehensive evaluations demonstrate AgriFM's superior performance over conventional deep learning approaches and state-of-the-art general-purpose RSFMs across all downstream tasks. Codes will be available at https://github.com/flyakon/AgriFM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate crop mapping fundamentally relies on modeling multi-scalespatiotemporal patterns, where spatial scales range from individual fieldtextures to landscape-level context, and temporal scales capture bothshort-term phenological transitions and full growing-season dynamics.Transformer-based remote sensing foundation models (RSFMs) offer promisingpotential for crop mapping due to their innate ability for unifiedspatiotemporal processing. However, current RSFMs remain suboptimal for cropmapping: they either employ fixed spatiotemporal windows that ignore themulti-scale nature of crop systems or completely disregard temporal informationby focusing solely on spatial patterns. To bridge these gaps, we presentAgriFM, a multi-source remote sensing foundation model specifically designedfor agricultural crop mapping. Our approach begins by establishing thenecessity of simultaneous hierarchical spatiotemporal feature extraction,leading to the development of a modified Video Swin Transformer architecturewhere temporal down-sampling is synchronized with spatial scaling operations.This modified backbone enables efficient unified processing of long time-seriessatellite inputs. AgriFM leverages temporally rich data streams from threesatellite sources including MODIS, Landsat-8/9 and Sentinel-2, and ispre-trained on a global representative dataset comprising over 25 million imagesamples supervised by land cover products. The resulting framework incorporatesa versatile decoder architecture that dynamically fuses these learnedspatiotemporal representations, supporting diverse downstream tasks.Comprehensive evaluations demonstrate AgriFM's superior performance overconventional deep learning approaches and state-of-the-art general-purposeRSFMs across all downstream tasks. Codes will be available athttps://github.com/flyakon/AgriFM.</description>
      <author>example@mail.com (Wenyuan Li, Shunlin Liang, Keyan Chen, Yongzhe Chen, Han Ma, Jianglei Xu, Yichuan Ma, Shikang Guan, Husheng Fang, Zhenwei Shi)</author>
      <guid isPermaLink="false">2505.21357v2</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Towards Robust Automated Perceptual Voice Quality Assessment with Speech Foundation Models</title>
      <link>http://arxiv.org/abs/2505.21356v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为VOQANet的深度学习框架，用于语音质量感知评估，以诊断和监测语音障碍。该框架结合了语音基础模型（SFM）和手工制作的声学特征，提高了评估的鲁棒性和可解释性。&lt;h4&gt;背景&lt;/h4&gt;传统的语音质量评估方法如CAPE-V和GRBAS是主观的，且存在评分者间差异，因此需要自动化的客观评估方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种自动化、客观的语音质量评估方法，以减少主观性和提高评估的一致性。&lt;h4&gt;方法&lt;/h4&gt;提出了VOQANet，它使用注意力机制从原始语音中提取高级声学和韵律信息。为了提高鲁棒性和可解释性，引入了VOQANet+，该框架将手工制作的声学特征与SFM嵌入结合。此外，评估了基于元音和句子级别的语音数据，以提高模型的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;基于句子的输入优于基于元音的输入，特别是在患者水平上，这突出了较长的语音表达在捕捉语音属性方面的优势。VOQANet在CAPE-V和GRBAS维度上优于基线方法，VOQANet+进一步提高了性能。在噪声条件下的额外测试表明，VOQANet+保持了高预测精度。&lt;h4&gt;结论&lt;/h4&gt;结合SFM嵌入和领域知识声学特征对于可解释和鲁棒的语音质量评估具有重要价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Perceptual voice quality assessment is essential for diagnosing andmonitoring voice disorders. Traditionally, expert raters use scales such as theCAPE-V and GRBAS. However, these are subjective and prone to inter-ratervariability, motivating the need for automated, objective assessment methods.This study proposes VOQANet, a deep learning framework with an attentionmechanism that leverages a Speech Foundation Model (SFM) to extract high-levelacoustic and prosodic information from raw speech. To improve robustness andinterpretability, we introduce VOQANet+, which integrates handcrafted acousticfeatures such as jitter, shimmer, and harmonics-to-noise ratio (HNR) with SFMembeddings into a hybrid representation. Unlike prior work focusing only onvowel-based phonation (PVQD-A subset) from the Perceptual Voice Quality Dataset(PVQD), we evaluate our models on both vowel-based and sentence-level speech(PVQD-S subset) for better generalizability. Results show that sentence-basedinput outperforms vowel-based input, particularly at the patient level,highlighting the benefit of longer utterances for capturing voice attributes.VOQANet consistently surpasses baseline methods in root mean squared error andPearson correlation across CAPE-V and GRBAS dimensions, with VOQANet+ achievingfurther improvements. Additional tests under noisy conditions show thatVOQANet+ maintains high prediction accuracy, supporting its use in real-worldand telehealth settings. These findings demonstrate the value of combining SFMembeddings with domain-informed acoustic features for interpretable and robustvoice quality assessment.</description>
      <author>example@mail.com (Whenty Ariyanti, Kuan-Yu Chen, Sabato Marco Siniscalchi, Hsin-Min Wang, Yu Tsao)</author>
      <guid isPermaLink="false">2505.21356v2</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Deep Video Discovery: Agentic Search with Tool Use for Long-form Video Understanding</title>
      <link>http://arxiv.org/abs/2505.18079v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  V2 draft. Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Deep Video Discovery (DVD)的代理，用于长视频理解，该代理利用代理搜索策略处理分割的视频片段，旨在克服长视频分析中的挑战。&lt;h4&gt;背景&lt;/h4&gt;长视频理解由于时空复杂性高和问答的困难而具有显著挑战。&lt;h4&gt;目的&lt;/h4&gt;提出DVD代理以克服处理信息密集型长视频时的限制。&lt;h4&gt;方法&lt;/h4&gt;DVD代理利用代理搜索策略，在多粒度视频数据库上提供一套以搜索为中心的工具，利用大型语言模型（LLM）的高级推理能力来规划当前观察状态，战略性地选择工具，并为动作制定适当的参数，并根据收集到的信息迭代地细化其内部推理。&lt;h4&gt;主要发现&lt;/h4&gt;DVD代理在多个长视频理解基准测试中表现出色，在LVBench数据集上显著超越了先前的工作，实现了SOTA性能。&lt;h4&gt;结论&lt;/h4&gt;通过综合消融研究和深入的工具分析，为长视频理解任务量身定制的智能代理的进一步发展提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a Deep Video Discovery (DVD) agent for long-form video understanding, which utilizes an agentic search strategy to process segmented video clips, aiming to overcome the challenges in long video analysis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-form video understanding presents significant challenges due toextensive temporal-spatial complexity and the difficulty of question answeringunder such extended contexts. While Large Language Models (LLMs) havedemonstrated considerable advancements in video analysis capabilities and longcontext handling, they continue to exhibit limitations when processinginformation-dense hour-long videos. To overcome such limitations, we proposethe Deep Video Discovery agent to leverage an agentic search strategy oversegmented video clips. Different from previous video agents manually designinga rigid workflow, our approach emphasizes the autonomous nature of agents. Byproviding a set of search-centric tools on multi-granular video database, ourDVD agent leverages the advanced reasoning capability of LLM to plan on itscurrent observation state, strategically selects tools, formulates appropriateparameters for actions, and iteratively refines its internal reasoning in lightof the gathered information. We perform comprehensive evaluation on multiplelong video understanding benchmarks that demonstrates the advantage of theentire system design. Our DVD agent achieves SOTA performance, significantlysurpassing prior works by a large margin on the challenging LVBench dataset.Comprehensive ablation studies and in-depth tool analyses are also provided,yielding insights to further advance intelligent agents tailored for long-formvideo understanding tasks. The code will be released later.</description>
      <author>example@mail.com (Xiaoyi Zhang, Zhaoyang Jia, Zongyu Guo, Jiahao Li, Bin Li, Houqiang Li, Yan Lu)</author>
      <guid isPermaLink="false">2505.18079v2</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Latent Mamba Operator for Partial Differential Equations</title>
      <link>http://arxiv.org/abs/2505.19105v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of the 42 nd International Conference on Machine  Learning, Vancouver, Canada. PMLR 267, 2025. Copyright 2025 by the author(s)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Latent Mamba Operator（LaMO）的新型神经网络算子，用于解决偏微分方程（PDEs），它在提高求解效率的同时，解决了现有神经网络算子在高维空间中的可扩展性、计算成本和捕捉PDE动态中的连续性和长程依赖性的问题。&lt;h4&gt;背景&lt;/h4&gt;神经网络算子作为一种数据驱动的框架，在解决PDEs方面表现出强大的能力，但现有方法在处理高维空间、计算成本以及捕捉PDE动态中的连续性和长程依赖性方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出LaMO算子，以解决现有神经网络算子的局限性，提高其在处理复杂PDE解模型时的效率。&lt;h4&gt;方法&lt;/h4&gt;LaMO算子结合了状态空间模型（SSMs）在潜在空间中的效率与神经网络算子中核积分公式的表达能力，并建立了状态空间模型（SSMs）与神经网络算子核积分之间的理论联系。&lt;h4&gt;主要发现&lt;/h4&gt;在多个PDE基准测试中，包括规则网格、结构网格和点云上的固体和流体物理数据集，LaMO算子实现了最先进的性能，在解算子近似方面比现有基线提高了32.3%，证明了其在建模复杂PDE解方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;LaMO算子为解决PDEs提供了一种高效且准确的新方法，有望在多个领域得到广泛应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：神经算子已成为解决偏微分方程（PDEs）的强大数据驱动框架，在数值方法上提供了显著的加速。然而，现有的神经算子在高维空间中难以扩展，计算成本高，且难以捕捉PDE动态中的连续性和长程依赖性。为了解决这些局限性，我们引入了潜在曼巴算子（LaMO），它将状态空间模型（SSMs）在潜在空间中的效率与神经算子中核积分公式的表达能力相结合。我们还建立了状态空间模型（SSMs）与神经算子核积分之间的理论联系。在规则网格、结构网格和点云上的固体和流体物理数据集的多个PDE基准测试中，LaMOs实现了最先进的性能，在解算子近似方面比现有基线提高了32.3%，突出了其在建模复杂PDE解方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural operators have emerged as powerful data-driven frameworks for solvingPartial Differential Equations (PDEs), offering significant speedups overnumerical methods. However, existing neural operators struggle with scalabilityin high-dimensional spaces, incur high computational costs, and face challengesin capturing continuous and long-range dependencies in PDE dynamics. To addressthese limitations, we introduce the Latent Mamba Operator (LaMO), whichintegrates the efficiency of state-space models (SSMs) in latent space with theexpressive power of kernel integral formulations in neural operators. We alsoestablish a theoretical connection between state-space models (SSMs) and thekernel integral of neural operators. Extensive experiments across diverse PDEbenchmarks on regular grids, structured meshes, and point clouds covering solidand fluid physics datasets, LaMOs achieve consistent state-of-the-art (SOTA)performance, with a 32.3% improvement over existing baselines in solutionoperator approximation, highlighting its efficacy in modeling complex PDEsolutions.</description>
      <author>example@mail.com (Karn Tiwari, Niladri Dutta, N M Anoop Krishnan, Prathosh A P)</author>
      <guid isPermaLink="false">2505.19105v2</guid>
      <pubDate>Thu, 29 May 2025 14:29:56 +0800</pubDate>
    </item>
    <item>
      <title>Improving Novel view synthesis of 360$^\circ$ Scenes in Extremely Sparse Views by Jointly Training Hemisphere Sampled Synthetic Images</title>
      <link>http://arxiv.org/abs/2505.19264v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于从极其稀疏的输入视图中进行新型视角合成，适用于虚拟现实和增强现实等应用。&lt;h4&gt;背景&lt;/h4&gt;在360度场景中，从极其稀疏的输入视图中进行新型视角合成对于虚拟现实和增强现实等应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;旨在解决典型结构从运动方法在极其稀疏视场情况下无法估计相机姿态的问题。&lt;h4&gt;方法&lt;/h4&gt;采用DUSt3R估计相机姿态并生成密集点云，利用估计的相机姿态从场景的上半球空间密集采样额外视图，并与点云一起渲染合成图像。通过在稀疏视图的参考图像和密集采样合成图像的组合上训练3D高斯散点模型，解决稀疏视场情况下输入有限导致的过拟合问题。在创建的数据集上重新训练基于扩散的图像增强模型，通过消除伪影进一步提高了点云渲染图像的质量。&lt;h4&gt;主要发现&lt;/h4&gt;与仅四个输入视图的基准方法相比，本文框架在极其稀疏视场条件下对360度场景的新型视角合成中显示出显著的改进。&lt;h4&gt;结论&lt;/h4&gt;该方法在稀疏视场条件下显著提高了360度场景的新型视角合成质量，为虚拟现实和增强现实应用提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在360度场景中，从极其稀疏的输入视图中进行新型视角合成对于虚拟现实和增强现实等应用至关重要。本文提出了一种新的框架，用于极其稀疏视场情况下的新型视角合成。由于典型结构从运动方法在极其稀疏视场情况下无法估计相机姿态，我们应用DUSt3R来估计相机姿态并生成密集点云。利用估计的相机姿态，我们从场景的上半球空间密集采样额外的视图，并与点云一起渲染合成图像。在稀疏视图的参考图像和密集采样合成图像的组合上训练3D高斯散点模型，允许在三维空间中实现更大的场景覆盖，解决了由于输入有限导致的过拟合问题。在创建的数据集上重新训练基于扩散的图像增强模型，通过消除伪影进一步提高了点云渲染图像的质量。与仅四个输入视图的基准方法相比，我们的框架在极其稀疏视场条件下对360度场景的新型视角合成中显示出显著的改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Novel view synthesis in 360$^\circ$ scenes from extremely sparse input viewsis essential for applications like virtual reality and augmented reality. Thispaper presents a novel framework for novel view synthesis in extremelysparse-view cases. As typical structure-from-motion methods are unable toestimate camera poses in extremely sparse-view cases, we apply DUSt3R toestimate camera poses and generate a dense point cloud. Using the poses ofestimated cameras, we densely sample additional views from the upper hemispherespace of the scenes, from which we render synthetic images together with thepoint cloud. Training 3D Gaussian Splatting model on a combination of referenceimages from sparse views and densely sampled synthetic images allows a largerscene coverage in 3D space, addressing the overfitting challenge due to thelimited input in sparse-view cases. Retraining a diffusion-based imageenhancement model on our created dataset, we further improve the quality of thepoint-cloud-rendered images by removing artifacts. We compare our frameworkwith benchmark methods in cases of only four input views, demonstratingsignificant improvement in novel view synthesis under extremely sparse-viewconditions for 360$^\circ$ scenes.</description>
      <author>example@mail.com (Guangan Chen, Anh Minh Truong, Hanhe Lin, Michiel Vlaminck, Wilfried Philips, Hiep Luong)</author>
      <guid isPermaLink="false">2505.19264v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
  <item>
      <title>Model Editing with Graph-Based External Memory</title>
      <link>http://arxiv.org/abs/2505.18343v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用双曲几何和图神经网络进行精确和稳定模型编辑的新框架，以解决大型语言模型在实际应用中存在的幻觉和过时参数知识问题。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在自然语言处理领域取得了革命性的进展，但它们的实际效用常常受到幻觉和过时参数知识的限制。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一种新的框架，旨在通过动态更新来提高模型的实用性和稳定性。&lt;h4&gt;方法&lt;/h4&gt;提出的框架名为HYPE，包括三个关键组件：(i)双曲图构建，使用Poincaré嵌入在双曲空间中表示知识三元组，通过确保对父概念的编辑不会意外影响子概念来保持层次关系和防止副作用；(ii)莫比乌斯变换更新，应用双曲加法来传播编辑，同时保持双曲流形内的结构一致性，不同于传统的欧几里得更新会扭曲关系距离；(iii)双重稳定化，结合梯度掩码和周期性GNN参数重置，通过关注关键参数并保持长期知识来防止灾难性遗忘。&lt;h4&gt;主要发现&lt;/h4&gt;在CounterFact、CounterFact+和MQuAKE数据集上，使用GPT-J和GPT2-XL进行的实验表明，HYPE显著提高了编辑稳定性、事实准确性和多跳推理能力。&lt;h4&gt;结论&lt;/h4&gt;HYPE框架能够有效提高大型语言模型在实际应用中的性能，为解决模型编辑中的幻觉和遗忘问题提供了一种新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have revolutionized natural language processing,yet their practical utility is often limited by persistent issues ofhallucinations and outdated parametric knowledge. Although post-training modelediting offers a pathway for dynamic updates, existing methods frequentlysuffer from overfitting and catastrophic forgetting. To tackle thesechallenges, we propose a novel framework that leverages hyperbolic geometry andgraph neural networks for precise and stable model edits. We introduce HYPE(HYperbolic Parameter Editing), which comprises three key components: (i)Hyperbolic Graph Construction, which uses Poincar\'e embeddings to representknowledge triples in hyperbolic space, preserving hierarchical relationshipsand preventing unintended side effects by ensuring that edits to parentconcepts do not inadvertently affect child concepts; (ii) M\"obius-TransformedUpdates, which apply hyperbolic addition to propagate edits while maintainingstructural consistency within the hyperbolic manifold, unlike conventionalEuclidean updates that distort relational distances; and (iii) DualStabilization, which combines gradient masking and periodic GNN parameterresetting to prevent catastrophic forgetting by focusing updates on criticalparameters and preserving long-term knowledge. Experiments on CounterFact,CounterFact+, and MQuAKE with GPT-J and GPT2-XL demonstrate that HYPEsignificantly enhances edit stability, factual accuracy, and multi-hopreasoning.</description>
      <author>example@mail.com (Yash Kumar Atri, Ahmed Alaa, Thomas Hartvigsen)</author>
      <guid isPermaLink="false">2505.18343v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Towards Better Instruction Following Retrieval Models</title>
      <link>http://arxiv.org/abs/2505.21439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Retrieval Models, Embedding, Retrieval with Instructions&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;InF-IR是一种用于增强检索模型在指令跟随信息检索（IR）中的能力的训练语料库，通过引入新颖的训练数据和方法来提升检索效果。&lt;h4&gt;背景&lt;/h4&gt;传统的信息检索模型在处理指令性查询时表现不佳，难以理解和执行用户的明确指令。&lt;h4&gt;目的&lt;/h4&gt;开发InF-IR语料库，以提升指令跟随信息检索模型的性能。&lt;h4&gt;方法&lt;/h4&gt;InF-IR通过扩展传统训练对到38,000个表达性的&lt;指令，查询，段落&gt;三元组作为正样本。对于每个正样本三元组，生成两个额外的负面样本，通过污染指令和查询来确保语义合理性同时保持指令错误。与现有语料库不同，InF-IR中的正负样本三元组有助于小型的编码器模型进行高效的学习。使用该语料库训练了InF-Embed模型，这是一个通过对比学习和指令查询注意力机制优化的指令感知嵌入模型。&lt;h4&gt;主要发现&lt;/h4&gt;InF-Embed在五个基于指令的检索基准测试中，相较于竞争基线在p-MRR上提升了8.1%，表明了其在指令跟随能力上的显著超越。&lt;h4&gt;结论&lt;/h4&gt;InF-IR和InF-Embed模型为指令跟随信息检索提供了有效的解决方案，显著提升了检索模型的性能。&lt;h4&gt;翻译&lt;/h4&gt;Modern information retrieval (IR) models, trained exclusively on standard &lt;query, passage&gt; pairs, struggle to effectively interpret and follow explicit user instructions. We introduce InF-IR, a large-scale, high-quality training corpus tailored for enhancing retrieval models in Instruction-Following IR. InF-IR expands traditional training pairs into over 38,000 expressive &lt;instruction, query, passage&gt; triplets as positive samples. In particular, for each positive triplet, we generate two additional hard negative examples by poisoning both instructions and queries, then rigorously validated by an advanced reasoning model (o3-mini) to ensure semantic plausibility while maintaining instructional incorrectness. Unlike existing corpora that primarily support computationally intensive reranking tasks for decoder-only language models, the highly contrastive positive-negative triplets in InF-IR further enable efficient representation learning for smaller encoder-only models, facilitating direct embedding-based retrieval. Using this corpus, we train InF-Embed, an instruction-aware Embedding model optimized through contrastive learning and instruction-query attention mechanisms to align retrieval outcomes precisely with user intents. Extensive experiments across five instruction-based retrieval benchmarks demonstrate that InF-Embed significantly surpasses competitive baselines by 8.1% in p-MRR, measuring the instruction-following capabilities.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern information retrieval (IR) models, trained exclusively on standard&lt;query, passage&gt; pairs, struggle to effectively interpret and follow explicituser instructions. We introduce InF-IR, a large-scale, high-quality trainingcorpus tailored for enhancing retrieval models in Instruction-Following IR.InF-IR expands traditional training pairs into over 38,000 expressive&lt;instruction, query, passage&gt; triplets as positive samples. In particular, foreach positive triplet, we generate two additional hard negative examples bypoisoning both instructions and queries, then rigorously validated by anadvanced reasoning model (o3-mini) to ensure semantic plausibility whilemaintaining instructional incorrectness. Unlike existing corpora that primarilysupport computationally intensive reranking tasks for decoder-only languagemodels, the highly contrastive positive-negative triplets in InF-IR furtherenable efficient representation learning for smaller encoder-only models,facilitating direct embedding-based retrieval. Using this corpus, we trainInF-Embed, an instruction-aware Embedding model optimized through contrastivelearning and instruction-query attention mechanisms to align retrieval outcomesprecisely with user intents. Extensive experiments across fiveinstruction-based retrieval benchmarks demonstrate that InF-Embed significantlysurpasses competitive baselines by 8.1% in p-MRR, measuring theinstruction-following capabilities.</description>
      <author>example@mail.com (Yuchen Zhuang, Aaron Trinh, Rushi Qiang, Haotian Sun, Chao Zhang, Hanjun Dai, Bo Dai)</author>
      <guid isPermaLink="false">2505.21439v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>MME-VideoOCR: Evaluating OCR-Based Capabilities of Multimodal LLMs in Video Scenarios</title>
      <link>http://arxiv.org/abs/2505.21333v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;多模态大型语言模型（MLLMs）在静态图像的OCR识别中取得了显著准确度，但在视频OCR中的效能因视频内容中的运动模糊、时间变化和视觉效果等因素而大幅降低。&lt;h4&gt;背景&lt;/h4&gt;MLLMs在视频OCR中的效能受限。&lt;h4&gt;目的&lt;/h4&gt;为了为MLLMs的训练提供更清晰的指导，研究者引入了MME-VideoOCR基准，该基准涵盖了广泛的视频OCR应用场景。&lt;h4&gt;方法&lt;/h4&gt;MME-VideoOCR包含10个任务类别，共25个独立任务，涵盖了44种不同的场景。基准包括1,464个不同分辨率、宽高比和长度的视频，以及2,000对精心制作的、人工标注的问答对。研究者评估了18种最先进的MLLMs在MME-VideoOCR上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;即使表现最好的模型（Gemini-2.5 Pro）的准确率也只有73.7%。细致分析表明，尽管现有的MLLMs在文本包含在单个或少数帧中的任务上表现出色，但在需要整体视频理解的复杂任务上，它们的处理能力有限。这些限制在需要时空推理、跨帧信息整合或抵抗语言先验偏见的场景中尤为明显。&lt;h4&gt;结论&lt;/h4&gt;研究结果强调了在动态视频场景中进行可靠OCR时，高分辨率视觉输入和充分的时间覆盖的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have achieved considerable accuracyin Optical Character Recognition (OCR) from static images. However, theirefficacy in video OCR is significantly diminished due to factors such as motionblur, temporal variations, and visual effects inherent in video content. Toprovide clearer guidance for training practical MLLMs, we introduce theMME-VideoOCR benchmark, which encompasses a comprehensive range of video OCRapplication scenarios. MME-VideoOCR features 10 task categories comprising 25individual tasks and spans 44 diverse scenarios. These tasks extend beyond textrecognition to incorporate deeper comprehension and reasoning of textualcontent within videos. The benchmark consists of 1,464 videos with varyingresolutions, aspect ratios, and durations, along with 2,000 meticulouslycurated, manually annotated question-answer pairs. We evaluate 18state-of-the-art MLLMs on MME-VideoOCR, revealing that even the best-performingmodel (Gemini-2.5 Pro) achieves an accuracy of only 73.7%. Fine-grainedanalysis indicates that while existing MLLMs demonstrate strong performance ontasks where relevant texts are contained within a single or few frames, theyexhibit limited capability in effectively handling tasks that demand holisticvideo comprehension. These limitations are especially evident in scenarios thatrequire spatio-temporal reasoning, cross-frame information integration, orresistance to language prior bias. Our findings also highlight the importanceof high-resolution visual input and sufficient temporal coverage for reliableOCR in dynamic video scenarios.</description>
      <author>example@mail.com (Yang Shi, Huanqian Wang, Wulin Xie, Huanyao Zhang, Lijie Zhao, Yi-Fan Zhang, Xinfeng Li, Chaoyou Fu, Zhuoer Wen, Wenting Liu, Zhuoran Zhang, Xinlong Chen, Bohan Zeng, Sihan Yang, Yuanxing Zhang, Pengfei Wan, Haotian Wang, Wenjing Yang)</author>
      <guid isPermaLink="false">2505.21333v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Learning Individual Behavior in Agent-Based Models with Graph Diffusion Networks</title>
      <link>http://arxiv.org/abs/2505.21426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，通过观察ABM生成数据来学习任何ABM的可微替代表达式。&lt;h4&gt;背景&lt;/h4&gt;Agent-Based Models (ABMs)是研究复杂系统涌现属性的有力工具，但其规则通常不可微分，限制了梯度方法的优化应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，能够学习ABM的可微替代表达式，以便与真实世界数据进行集成。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了扩散模型来捕捉行为随机性，以及图神经网络来建模代理之间的交互。与之前的替代表达方法不同，它直接模型化个体代理行为。&lt;h4&gt;主要发现&lt;/h4&gt;在两个ABM（Schelling的隔离模型和捕食者-食草者生态系统）上验证了该方法，显示其能够复制个体层面的模式并准确预测训练之外的涌现动态。&lt;h4&gt;结论&lt;/h4&gt;本文的结果展示了结合扩散模型和图学习进行数据驱动ABM模拟的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于代理模型（ABM）是研究复杂系统涌现属性的有力工具。在ABM中，代理行为由局部交互和随机规则控制。然而，这些规则通常不可微分，限制了梯度方法在优化中的应用，从而限制了与真实世界数据的集成。我们提出了一种新的框架，通过观察其生成数据来学习任何ABM的可微替代表达式。我们的方法结合了扩散模型来捕捉行为随机性，以及图神经网络来建模代理交互。与先前的替代表达方法不同，我们的方法引入了一个根本性的转变：它不是通过近似系统级输出，而是直接模型化个体代理行为，保留了定义ABM的去中心化、自下而上的动态。我们在两个ABM（Schelling的隔离模型和捕食者-食草者生态系统）上验证了我们的方法，显示它能够复制个体层面的模式并准确预测训练之外的涌现动态。我们的结果表明，结合扩散模型和图学习进行数据驱动ABM模拟具有潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Agent-Based Models (ABMs) are powerful tools for studying emergent propertiesin complex systems. In ABMs, agent behaviors are governed by local interactionsand stochastic rules. However, these rules are, in general, non-differentiable,limiting the use of gradient-based methods for optimization, and thusintegration with real-world data. We propose a novel framework to learn adifferentiable surrogate of any ABM by observing its generated data. Our methodcombines diffusion models to capture behavioral stochasticity and graph neuralnetworks to model agent interactions. Distinct from prior surrogate approaches,our method introduces a fundamental shift: rather than approximatingsystem-level outputs, it models individual agent behavior directly, preservingthe decentralized, bottom-up dynamics that define ABMs. We validate ourapproach on two ABMs (Schelling's segregation model and a Predator-Preyecosystem) showing that it replicates individual-level patterns and accuratelyforecasts emergent dynamics beyond training. Our results demonstrate thepotential of combining diffusion models and graph learning for data-driven ABMsimulation.</description>
      <author>example@mail.com (Francesco Cozzi, Marco Pangallo, Alan Perotti, André Panisson, Corrado Monti)</author>
      <guid isPermaLink="false">2505.21426v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding</title>
      <link>http://arxiv.org/abs/2505.21381v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ZigzagPointMamba的改进点云自监督学习方法，通过优化扫描路径和掩码策略，提升了点云模型的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的PointMamba方法在点云自监督学习中的计算效率较高，但依赖于复杂的标记排序和随机掩码，这会破坏空间连续性和局部语义相关性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的ZigzagPointMamba方法，以提高点云自监督学习的性能。&lt;h4&gt;方法&lt;/h4&gt;ZigzagPointMamba的核心是一个简单的之字形扫描路径，它全局性地序列化点云标记，通过保留相邻点标记的邻近性来增强空间连续性。同时，引入了语义Siamese掩码策略（SMS）来减少随机掩码对局部语义建模的影响。&lt;h4&gt;主要发现&lt;/h4&gt;ZigzagPointMamba在ShapeNetPart、ModelNet40以及ScanObjectNN的OBJ-BG、OBJ-ONLY和PB-T50-RS子集上的分类任务中分别取得了1.59%、0.4%、0.19%、1.22%和0.72%的准确率提升。&lt;h4&gt;结论&lt;/h4&gt;ZigzagPointMamba在点云自监督学习中表现出色，能够有效地进行特征提取，并通过改进的掩码策略实现鲁棒的全球语义建模。&lt;h4&gt;翻译&lt;/h4&gt;摘要：状态空间模型（SSMs）如PointMamba可以实现点云自监督学习的有效特征提取，具有线性复杂度，在计算效率上优于Transformer。然而，现有的基于PointMamba的方法依赖于复杂的标记排序和随机掩码，这会破坏空间连续性和局部语义相关性。我们提出了ZigzagPointMamba来应对这些挑战。我们方法的核心是一个简单的之字形扫描路径，它全局性地序列化点云标记，通过保留空间相邻点标记的邻近性来增强空间连续性。尽管如此，随机掩码会削弱自监督学习中的局部语义建模。为了解决这个问题，我们引入了一种语义Siamese掩码策略（SMS），该策略通过整合原始标记和相似标记的局部特征来掩码语义相似的标记，以促进重建。这克服了对孤立局部特征的依赖，并实现了鲁棒的全球语义建模。我们的预训练ZigzagPointMamba权重在下游任务中显著提高了性能，在ShapeNetPart的部件分割任务上实现了1.59%的mIoU提升，在ModelNet40的分类任务上提高了0.4%的准确率，在ScanObjectNN的OBJ-BG、OBJ-ONLY和PB-T50-RS子集上的分类任务分别提高了0.19%、1.22%和0.72%的准确率。代码可在以下链接找到：https://anonymous.4open.science/r/ZigzagPointMamba-1800/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State Space models (SSMs) such as PointMamba enable efficient featureextraction for point cloud self-supervised learning with linear complexity,outperforming Transformers in computational efficiency. However, existingPointMamba-based methods depend on complex token ordering and random masking,which disrupt spatial continuity and local semantic correlations. We proposeZigzagPointMamba to tackle these challenges. The core of our approach is asimple zigzag scan path that globally sequences point cloud tokens, enhancingspatial continuity by preserving the proximity of spatially adjacent pointtokens. Nevertheless, random masking undermines local semantic modeling inself-supervised learning. To address this, we introduce a Semantic-SiameseMasking Strategy (SMS), which masks semantically similar tokens to facilitatereconstruction by integrating local features of original and similar tokens.This overcomes the dependence on isolated local features and enables robustglobal semantic modeling. Our pre-trained ZigzagPointMamba weightssignificantly improve downstream tasks, achieving a 1.59% mIoU gain onShapeNetPart for part segmentation, a 0.4% higher accuracy on ModelNet40 forclassification, and 0.19%, 1.22%, and 0.72% higher accuracies respectively forthe classification tasks on the OBJ-BG, OBJ-ONLY, and PB-T50-RS subsets ofScanObjectNN. The code is available at:https://anonymous.4open.science/r/ZigzagPointMamba-1800/</description>
      <author>example@mail.com (Linshuang Diao, Dayong Ren, Sensen Song, Yurong Qian)</author>
      <guid isPermaLink="false">2505.21381v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Vision from EEG Brain Recordings: How much does EEG know?</title>
      <link>http://arxiv.org/abs/2505.21385v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从脑电图（EEG）数据中重建动态视觉刺激的框架，并深入研究了EEG信号中编码的信息。&lt;h4&gt;背景&lt;/h4&gt;由于脑电图信号的非平稳性、低信噪比以及EEG-视频刺激数据集的有限可用性，从脑电图记录中重建和理解动态视觉信息（视频）具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;研究如何从EEG信号中提取动态视觉信息，并为未来从EEG中提取视觉动态的研究提供价值。&lt;h4&gt;方法&lt;/h4&gt;首先在EEG-视频生成框架内使用基于三元组的对比学习策略训练一个特征提取网络。然后，使用修改后的StyleGAN-ADA进行视频合成，其中包含时间信息作为条件。此外，分析了不同脑区对处理动态视觉刺激的贡献。&lt;h4&gt;主要发现&lt;/h4&gt;通过多次实证研究，评估了该框架的有效性，并研究了从EEG信号中可以推断出的动态视觉信息量。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法对于从EEG中提取动态视觉信息具有重要意义，为相关领域的研究提供了新的思路和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing and understanding dynamic visual information (video) frombrain EEG recordings is challenging due to the non-stationary nature of EEGsignals, their low signal-to-noise ratio (SNR), and the limited availability ofEEG-Video stimulus datasets. Most recent studies have focused on reconstructingstatic images from EEG recordings. In this work, we propose a framework toreconstruct dynamic visual stimuli from EEG data and conduct an in-depth studyof the information encoded in EEG signals. Our approach first trains a featureextraction network using a triplet-based contrastive learning strategy withinan EEG-video generation framework. The extracted EEG features are then used forvideo synthesis with a modified StyleGAN-ADA, which incorporates temporalinformation as conditioning. Additionally, we analyze how different brainregions contribute to processing dynamic visual stimuli. Through severalempirical studies, we evaluate the effectiveness of our framework andinvestigate how much dynamic visual information can be inferred from EEGsignals. The inferences we derive through our extensive studies would be ofimmense value to future research on extracting visual dynamics from EEG.</description>
      <author>example@mail.com (Prajwal Singh, Anupam Sharma, Pankaj Pandey, Krishna Miyapuram, Shanmuganathan Raman)</author>
      <guid isPermaLink="false">2505.21385v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Hume: Introducing System-2 Thinking in Visual-Language-Action Model</title>
      <link>http://arxiv.org/abs/2505.21432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Hume模型，一种结合价值引导的二级系统视觉-语言-动作（VLA）模型，旨在探索人类类似思考能力的视觉-语言-动作模型在灵巧机器人控制中的应用。&lt;h4&gt;背景&lt;/h4&gt;人类在处理物理世界中的复杂任务时，会在实际行动前进行慢思考。这种思考模式在提升大型语言模型（LLMs）解决数字领域复杂任务方面取得了显著进展。然而，慢思考在机器人基础模型与物理世界交互中的潜力尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;探索人类类似思考能力的视觉-语言-动作模型在灵巧机器人控制中的应用。&lt;h4&gt;方法&lt;/h4&gt;Hume模型包括两个系统：系统2使用价值引导的思考，通过扩展视觉-语言-动作模型主干并添加一个新颖的价值查询头来估计预测动作的状态-动作价值，并通过重复采样多个动作候选并选择一个来执行价值引导的思考；系统1是一个轻量级的反应性视觉运动策略，它接收系统2选定的动作并执行级联动作去噪以进行灵巧的机器人控制。&lt;h4&gt;主要发现&lt;/h4&gt;Hume模型在多个模拟基准和真实机器人部署中优于现有的视觉-语言-动作模型。&lt;h4&gt;结论&lt;/h4&gt;Hume模型展示了慢思考在机器人控制中的应用潜力，并提供了优于现有方法的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在处理物理世界中的复杂任务时，人类在执行实际动作之前会进行慢思考。这种思考范式最近在提升大型语言模型（LLMs）解决数字领域复杂任务方面取得了显著的进展。然而，慢思考在机器人基础模型与物理世界交互中的潜力仍待探索。在本研究中，我们提出了Hume：一个具有价值引导的系统2思考和级联动作去噪的双系统视觉-语言-动作（VLA）模型，探索视觉-语言-动作模型的人类样思考能力，以实现灵巧机器人控制。Hume的系统2通过扩展视觉-语言-动作模型主干并添加一个新颖的价值查询头来实现价值引导的思考，用于估计预测动作的状态-动作价值。价值引导的思考通过重复采样多个动作候选并根据状态-动作价值进行选择来实现。Hume的系统1是一个轻量级的反应性视觉运动策略，它接收系统2选定的动作并进行级联动作去噪以实现灵巧的机器人控制。在部署时，系统2以低频进行价值引导的思考，而系统1异步接收系统2选定的动作候选并实时预测流畅的动作。我们发现，Hume在多个模拟基准和真实机器人部署中优于现有的视觉-语言-动作模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans practice slow thinking before performing actual actions when handlingcomplex tasks in the physical world. This thinking paradigm, recently, hasachieved remarkable advancement in boosting Large Language Models (LLMs) tosolve complex tasks in digital domains. However, the potential of slow thinkingremains largely unexplored for robotic foundation models interacting with thephysical world. In this work, we propose Hume: a dual-systemVision-Language-Action (VLA) model with value-guided System-2 thinking andcascaded action denoising, exploring human-like thinking capabilities ofVision-Language-Action models for dexterous robot control. System 2 of Humeimplements value-Guided thinking by extending a Vision-Language-Action Modelbackbone with a novel value-query head to estimate the state-action value ofpredicted actions. The value-guided thinking is conducted by repeat samplingmultiple action candidates and selecting one according to state-action value.System 1 of Hume is a lightweight reactive visuomotor policy that takes System2 selected action and performs cascaded action denoising for dexterous robotcontrol. At deployment time, System 2 performs value-guided thinking at a lowfrequency while System 1 asynchronously receives the System 2 selected actioncandidate and predicts fluid actions in real time. We show that Humeoutperforms the existing state-of-the-art Vision-Language-Action models acrossmultiple simulation benchmark and real-robot deployments.</description>
      <author>example@mail.com (Haoming Song, Delin Qu, Yuanqi Yao, Qizhi Chen, Qi Lv, Yiwen Tang, Modi Shi, Guanghui Ren, Maoqing Yao, Bin Zhao, Dong Wang, Xuelong Li)</author>
      <guid isPermaLink="false">2505.21432v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>EquAct: An SE(3)-Equivariant Multi-Task Transformer for Open-Loop Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2505.21351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的SE(3)-等变多任务Transformer，称为EquAct，能够从演示中学习语言条件下的多任务3D开环操作策略。&lt;h4&gt;背景&lt;/h4&gt;虽然机器人策略和语言指令内在地编码了丰富的3D几何结构，但标准的Transformer缺乏几何一致性的内置保证，往往在场景的SE(3)变换下产生不可预测的行为。&lt;h4&gt;目的&lt;/h4&gt;提出EquAct，旨在解决标准Transformer在处理场景变换时的不可预测行为问题。&lt;h4&gt;方法&lt;/h4&gt;EquAct利用SE(3)等变性作为策略和语言共享的关键结构特性，包括：(1)一个高效的SE(3)-等变基于点云的U-net，使用球形傅里叶特征进行策略推理；(2)SE(3)-不变特征线性调制(iFiLM)层进行语言条件化。&lt;h4&gt;主要发现&lt;/h4&gt;EquAct在具有SE(3)和SE(2)场景扰动的18个RLBenchmark模拟任务和4个物理任务上进行了基准测试，结果显示其在这些模拟和物理任务上均达到了最先进水平。&lt;h4&gt;结论&lt;/h4&gt;EquAct通过结合SE(3)等变性和语言条件化，显著提高了在3D操作任务中的空间泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer architectures can effectively learn language-conditioned,multi-task 3D open-loop manipulation policies from demonstrations by jointlyprocessing natural language instructions and 3D observations. However, althoughboth the robot policy and language instructions inherently encode rich 3Dgeometric structures, standard transformers lack built-in guarantees ofgeometric consistency, often resulting in unpredictable behavior under SE(3)transformations of the scene. In this paper, we leverage SE(3) equivariance asa key structural property shared by both policy and language, and proposeEquAct-a novel SE(3)-equivariant multi-task transformer. EquAct istheoretically guaranteed to be SE(3) equivariant and consists of two keycomponents: (1) an efficient SE(3)-equivariant point cloud-based U-net withspherical Fourier features for policy reasoning, and (2) SE(3)-invariantFeature-wise Linear Modulation (iFiLM) layers for language conditioning. Toevaluate its spatial generalization ability, we benchmark EquAct on 18 RLBenchsimulation tasks with both SE(3) and SE(2) scene perturbations, and on 4physical tasks. EquAct performs state-of-the-art across these simulation andphysical tasks.</description>
      <author>example@mail.com (Xupeng Zhu, Yu Qi, Yizhe Zhu, Robin Walters, Robert Platt)</author>
      <guid isPermaLink="false">2505.21351v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Assured Autonomy with Neuro-Symbolic Perception</title>
      <link>http://arxiv.org/abs/2505.21322v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于神经符号范式（NeuSPaPer）的感知模型，旨在提高AI在安全关键和竞争领域的可靠性。&lt;h4&gt;背景&lt;/h4&gt;目前许多应用于网络物理系统（CPS）的AI模型虽然准确度高，但只是简单的模式匹配器，缺乏安全性保证。&lt;h4&gt;目的&lt;/h4&gt;为了推进可保证的AI，本文倡导一种范式转变，将数据驱动感知模型与符号结构相结合，模仿人类对低级特征和高级上下文的推理能力。&lt;h4&gt;方法&lt;/h4&gt;本文设计了一个框架，利用结构化关系图，结合离线知识提取的基础模型和实时部署的专业场景图生成（SGG）算法，确保自主系统中的情境感知完整性。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用基于物理的模拟器和真实世界的数据集，本文展示了场景图生成（SGG）如何连接低级传感器感知和高级推理，为弹性、上下文感知的AI奠定了基础。&lt;h4&gt;结论&lt;/h4&gt;本文提出的NeuSPaPer框架有助于在CPS中推进可信自主性，实现安全关键领域的可靠AI。&lt;h4&gt;翻译&lt;/h4&gt;摘要：许多应用于网络物理系统（CPS）的先进AI模型，尽管准确度高，但仅仅是模式匹配器。由于安全性保证有限，人们在安全关键和竞争领域对其可靠性存在担忧。为了推进可保证的AI，我们倡导一种范式转变，将数据驱动感知模型赋予符号结构，这受到人类对低级特征和高级上下文进行推理能力的启发。我们提出了一个用于感知的神经符号范式（NeuSPaPer），并说明了联合对象检测和场景图生成（SGG）如何实现深度场景理解。通过离线知识提取的基础模型和实时部署的专业SGG算法，我们设计了一个利用结构化关系图的框架，确保自主系统中的情境感知完整性。使用基于物理的模拟器和真实世界的数据集，我们展示了SGG如何连接低级传感器感知和高级推理，为弹性、上下文感知的AI奠定了基础，并推进了CPS中的可信自主性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many state-of-the-art AI models deployed in cyber-physical systems (CPS),while highly accurate, are simply pattern-matchers.~With limited securityguarantees, there are concerns for their reliability in safety-critical andcontested domains. To advance assured AI, we advocate for a paradigm shift thatimbues data-driven perception models with symbolic structure, inspired by ahuman's ability to reason over low-level features and high-level context. Wepropose a neuro-symbolic paradigm for perception (NeuSPaPer) and illustrate howjoint object detection and scene graph generation (SGG) yields deep sceneunderstanding.~Powered by foundation models for offline knowledge extractionand specialized SGG algorithms for real-time deployment, we design a frameworkleveraging structured relational graphs that ensures the integrity ofsituational awareness in autonomy. Using physics-based simulators andreal-world datasets, we demonstrate how SGG bridges the gap between low-levelsensor perception and high-level reasoning, establishing a foundation forresilient, context-aware AI and advancing trusted autonomy in CPS.</description>
      <author>example@mail.com (R. Spencer Hallyburton, Miroslav Pajic)</author>
      <guid isPermaLink="false">2505.21322v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Collision Probability Estimation for Optimization-based Vehicular Motion Planning</title>
      <link>http://arxiv.org/abs/2505.21161v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于优化运动规划算法的碰撞概率（POC）估计方法，通过多圆形形状近似来估计两车之间的POC，并使用随机模型预测控制器（SMPC）进行路径跟踪。&lt;h4&gt;背景&lt;/h4&gt;许多自动驾驶的运动规划算法需要估计碰撞概率（POC）来处理测量和估计中的不确定性。常见的POC估计技术使用基于采样的方法，但计算效率低且结果非确定性。优化运动规划算法需要计算效率高的POC估计，以保持其可行性。&lt;h4&gt;目的&lt;/h4&gt;提出一种计算效率高、确定性强的POC估计方法，以支持优化运动规划算法。&lt;h4&gt;方法&lt;/h4&gt;通过多圆形形状近似来估计两车之间的POC，将预测车辆的位置和航向建模为随机变量，并针对位置和航向的Gaussian不确定性提出了一种计算效率高的算法。&lt;h4&gt;主要发现&lt;/h4&gt;该方法保证了提供的POC是一个过估计，这对于提供安全保证至关重要。在测试案例中，SMPC使用该方法生成了可复制的轨迹，同时控制器保持了其可行性，并展示了处理不同级别不确定性的能力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在自动驾驶运动规划中提供了计算效率高且安全的碰撞概率估计，并通过实验验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many motion planning algorithms for automated driving require estimating theprobability of collision (POC) to account for uncertainties in the measurementand estimation of the motion of road users. Common POC estimation techniquesoften utilize sampling-based methods that suffer from computationalinefficiency and a non-deterministic estimation, i.e., each estimation resultfor the same inputs is slightly different. In contrast, optimization-basedmotion planning algorithms require computationally efficient POC estimation,ideally using deterministic estimation, such that typical optimizationalgorithms for motion planning retain feasibility. Estimating the POCanalytically, however, is challenging because it depends on understanding thecollision conditions (e.g., vehicle's shape) and characterizing the uncertaintyin motion prediction. In this paper, we propose an approach in which weestimate the POC between two vehicles by over-approximating their shapes by amulti-circular shape approximation. The position and heading of the predictedvehicle are modelled as random variables, contrasting with the literature,where the heading angle is often neglected. We guarantee that the provided POCis an over-approximation, which is essential in providing safety guarantees,and present a computationally efficient algorithm for computing the POCestimate for Gaussian uncertainty in the position and heading. This algorithmis then used in a path-following stochastic model predictive controller (SMPC)for motion planning. With the proposed algorithm, the SMPC generatesreproducible trajectories while the controller retains its feasibility in thepresented test cases and demonstrates the ability to handle varying levels ofuncertainty.</description>
      <author>example@mail.com (Leon Tolksdorf, Arturo Tejada, Christian Birkner, Nathan van de Wouw)</author>
      <guid isPermaLink="false">2505.21161v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Data-Driven Cellular Mobility Management via Bayesian Optimization and Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2505.21249v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出两种基于数据驱动的移动管理方法，以解决蜂窝网络中由于网络密集化和异构用户移动特性带来的移动管理复杂性。&lt;h4&gt;背景&lt;/h4&gt;随着网络密集化和用户移动特性的多样化，传统的基于预设参数的手动切换（HO）机制在优化不同速度和部署条件下的移动性能方面往往失败。&lt;h4&gt;目的&lt;/h4&gt;针对上述挑战，提出利用高维贝叶斯优化（HD-BO）和深度强化学习（DRL）两种数据驱动的方法来优化移动管理。&lt;h4&gt;方法&lt;/h4&gt;HD-BO优化HO参数如A3偏移量和触发时间（TTT），在乒乓效应和无线链路失败（RLF）之间取得平衡。DRL提供了一种非参数化方法，允许代理根据实时网络条件选择服务小区。&lt;h4&gt;主要发现&lt;/h4&gt;使用真实世界蜂窝部署场景和Sionna射线追踪进行特定位置的信道传播建模，结果表明HD-BO和DRL都优于3GPP的基准。HD-BO通过迁移学习增强，能够在不同用户速度范围内泛化。将相同的迁移学习策略应用于DRL方法，可以将其训练时间减少2.5倍，同时保持最优的HO性能。仿真还显示，HD-BO在样本效率方面优于DRL，使其更适合训练数据有限的情况。&lt;h4&gt;结论&lt;/h4&gt;HD-BO和DRL都是有效的移动管理方法，能够提高蜂窝网络中的移动性能，并且通过迁移学习策略可以进一步提高其效率和适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobility management in cellular networks faces increasing complexity due tonetwork densification and heterogeneous user mobility characteristics.Traditional handover (HO) mechanisms, which rely on predefined parameters suchas A3-offset and time-to-trigger (TTT), often fail to optimize mobilityperformance across varying speeds and deployment conditions. Fixed A3-offsetand TTT configurations either delay HOs, increasing radio link failures (RLFs),or accelerate them, leading to excessive ping-pong effects. To address thesechallenges, we propose two data-driven mobility management approachesleveraging high-dimensional Bayesian optimization (HD-BO) and deepreinforcement learning (DRL). HD-BO optimizes HO parameters such as A3-offsetand TTT, striking a desired trade-off between ping-pongs vs. RLF. DRL providesa non-parameter-based approach, allowing an agent to select serving cells basedon real-time network conditions. We validate our approach using a real-worldcellular deployment scenario, and employing Sionna ray tracing forsite-specific channel propagation modeling. Results show that both HD-BO andDRL outperform 3GPP set-1 (TTT of 480 ms and A3-offset of 3 dB) and set-5 (TTTof 40 ms and A3-offset of -1 dB) benchmarks. We augment HD-BO with transferlearning so it can generalize across a range of user speeds. Applying the sametransfer-learning strategy to the DRL method reduces its training time by afactor of 2.5 while preserving optimal HO performance, showing that it adaptsefficiently to the mobility of aerial users such as UAVs. Simulations furtherreveal that HD-BO remains more sample-efficient than DRL, making it moresuitable for scenarios with limited training data.</description>
      <author>example@mail.com (Mohamed Benzaghta, Sahar Ammar, David López-Pérez, Basem Shihada, Giovanni Geraci)</author>
      <guid isPermaLink="false">2505.21249v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Occlusion Boundary and Depth: Mutual Enhancement via Multi-Task Learning</title>
      <link>http://arxiv.org/abs/2505.21231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 4 tables, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为MoDOT的新型网络，用于同时估计深度和遮挡边界，以改善场景理解和3D重建能力。&lt;h4&gt;背景&lt;/h4&gt;遮挡边界估计（OBE）和单目深度估计（MDE）是计算机视觉中的两个重要任务，OBE通过识别遮挡边界来提高场景理解和3D重建，而MDE通过单张图像推断深度。&lt;h4&gt;目的&lt;/h4&gt;提出一种同时估计深度和遮挡边界的网络，以改善场景理解和3D重建。&lt;h4&gt;方法&lt;/h4&gt;论文中提出的MoDOT网络首先联合估计深度和遮挡边界，引入了交叉注意力多尺度条带卷积模块（CASM）来增强深度预测，并引入了遮挡感知损失函数（OBDCL）以优化深度边界。&lt;h4&gt;主要发现&lt;/h4&gt;联合估计深度和遮挡边界对两个任务都有益，实验结果表明该方法在合成数据和真实数据集上均达到了最先进的性能，且在真实世界深度迁移任务中也表现良好。&lt;h4&gt;结论&lt;/h4&gt;MoDOT网络能够有效地估计深度和遮挡边界，为场景理解和3D重建提供了有力的支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要：遮挡边界估计（OBE）识别由物体间遮挡和单个物体内的自遮挡产生的边界，区分内在物体边缘和由遮挡引起的轮廓，以改善场景理解和3D重建能力。这与单目深度估计（MDE）密切相关，因为遮挡边界提供了解决深度模糊性的关键几何线索，而深度先验可以反过来在复杂场景中优化遮挡推理。在本文中，我们提出了一种新的网络，MoDOT，它首先联合估计深度和OB。我们提出了CASM，一个交叉注意力多尺度条带卷积模块，利用中级OB特征来显著增强深度预测。此外，我们引入了一个遮挡感知损失函数，OBDCL，它鼓励更锐利和更准确的深度边界。在真实和合成数据集上的大量实验证明了联合估计深度和OB的相互益处，并突出了我们模型设计的效果。我们的方法在我们的合成数据集和一个流行的真实数据集NYUD-v2上均达到了最先进的性能，显著优于多任务基线。此外，在没有领域自适应的情况下，真实世界深度迁移的结果与竞争对手相当，同时保持了锐利的遮挡边界以保持几何精度。我们将发布我们的代码、预训练模型和数据集，以支持未来在此方向上的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Occlusion Boundary Estimation (OBE) identifies boundaries arising from bothinter-object occlusions and self-occlusion within individual objects,distinguishing intrinsic object edges from occlusion-induced contours toimprove scene understanding and 3D reconstruction capacity. This is closelyrelated to Monocular Depth Estimation (MDE), which infers depth from a singleimage, as occlusion boundaries provide critical geometric cues for resolvingdepth ambiguities, while depth priors can conversely refine occlusion reasoningin complex scenes. In this paper, we propose a novel network, MoDOT, that firstjointly estimates depth and OBs. We propose CASM, a cross-attention multi-scalestrip convolution module, leverages mid-level OB features to significantlyenhance depth prediction. Additionally, we introduce an occlusion-aware lossfunction, OBDCL, which encourages sharper and more accurate depth boundaries.Extensive experiments on both real and synthetic datasets demonstrate themutual benefits of jointly estimating depth and OB, and highlight theeffectiveness of our model design. Our method achieves the state-of-the-art(SOTA) on both our proposed synthetic datasets and one popular real dataset,NYUD-v2, significantly outperforming multi-task baselines. Besides, withoutdomain adaptation, results on real-world depth transfer are comparable to thecompetitors, while preserving sharp occlusion boundaries for geometricfidelity. We will release our code, pre-trained models, and datasets to supportfuture research in this direction.</description>
      <author>example@mail.com (Lintao Xu, Yinghao Wang, Chaohui Wang)</author>
      <guid isPermaLink="false">2505.21231v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network Aided Detection for the Multi-User Multi-Dimensional Index Modulated Uplink</title>
      <link>http://arxiv.org/abs/2505.21343v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为CS-SFIM的压缩感知辅助空间-频率索引调制概念，用于下一代网络的大规模多用户多输入多输出上行链路。&lt;h4&gt;背景&lt;/h4&gt;在多用户多输入多输出上行链路系统中，服务大量用户会导致显著的互调干扰。&lt;h4&gt;目的&lt;/h4&gt;设计一种空间-频率域矩阵，利用近似消息传递和期望传播算法来检测多用户干扰。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于图神经网络（GNN）的检测器，包括GNN-AMP和GEPNet检测器，用于进一步降低检测复杂度并提高检测性能。&lt;h4&gt;主要发现&lt;/h4&gt;基于GNN的检测器在降低检测复杂度的同时，接近最大似然检测的性能。&lt;h4&gt;结论&lt;/h4&gt;GNN-AMP和GEPNet检测器在降低检测复杂度与提高检测性能之间取得了良好的平衡，适用于大规模多用户场景。&lt;h4&gt;翻译&lt;/h4&gt;The concept of Compressed Sensing-aided Space-Frequency Index Modulation (CS-SFIM) is proposed for the Large-Scale Multi-User Multiple-Input Multiple-Output Uplink (LS-MU-MIMO-UL) of Next-Generation (NG) networks. Specifically, in CS-SFIM, the information bits are mapped to both spatial- and frequency-domain indices, where the activation patterns of the transmit antennas and subcarriers are treated separately. Serving a large number of users in an MU-MIMO-UL system leads to substantial Multi-User Interference (MUI). Therefore, we design the Space-Frequency (SF) domain matrix as a joint factor graph, where Approximate Message Passing (AMP) and Expectation Propagation (EP) based MU detectors can be utilized. In the LS-MU-MIMO-UL scenario considered, the proposed system uses optimal Maximum Likelihood (ML) and Minimum Mean Square Error (MMSE) detectors as benchmarks for comparison with the proposed MP-based detectors. These MP-based detectors significantly reduce the detection complexity compared to ML detection, making it particularly suitable for LS-MU scenarios. To further reduce the detection complexity and improve the detection performance, we propose a pair of Graph Neural Network (GNN) based detectors, which rely on the orthogonal AMP (OAMP) and the EP algorithm, respectively referred to as the GNN-AMP and GEPNet detectors. The GEPNet detector maximizes the detection performance, while the GNN-AMP detector strikes a performance versus complexity trade-off. The GNN is trained for a single system configuration and yet it can be used for any number of users in the system. Simulation results show that the GNN-based detector approaches the ML performance in various configurations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The concept of Compressed Sensing-aided Space-Frequency Index Modulation(CS-SFIM) is conceived for the Large-Scale Multi-User Multiple-InputMultiple-Output Uplink (LS-MU-MIMO-UL) of Next-Generation (NG) networks.Explicitly, in CS-SFIM, the information bits are mapped to both spatial- andfrequency-domain indices, where we treat the activation patterns of thetransmit antennas and of the subcarriers separately. Serving a large number ofusers in an MU-MIMO-UL system leads to substantial Multi-User Interference(MUI). Hence, we design the Space-Frequency (SF) domain matrix as a jointfactor graph, where the Approximate Message Passing (AMP) and ExpectationPropagation (EP) based MU detectors can be utilized. In the LS-MU-MIMO-ULscenario considered, the proposed system uses optimal Maximum Likelihood (ML)and Minimum Mean Square Error (MMSE) detectors as benchmarks for comparisonwith the proposed MP-based detectors. These MP-based detectors significantlyreduce the detection complexity compared to ML detection, making the designeminently suitable for LS-MU scenarios. To further reduce the detectioncomplexity and improve the detection performance, we propose a pair of GraphNeural Network (GNN) based detectors, which rely on the orthogonal AMP (OAMP)and on the EP algorithm, which we refer to as the GNN-AMP and GEPNet detectors,respectively. The GEPNet detector maximizes the detection performance, whilethe GNN-AMP detector strikes a performance versus complexity trade-off. The GNNis trained for a single system configuration and yet it can be used for anynumber of users in the system. The simulation results show that the GNN-baseddetector approaches the ML performance in various configurations.</description>
      <author>example@mail.com (Xinyu Feng, Mohammed EL-Hajjar, Chao Xu, Lajos Hanzo)</author>
      <guid isPermaLink="false">2505.21343v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>RLJP: Legal Judgment Prediction via First-Order Logic Rule-enhanced with Large Language Models</title>
      <link>http://arxiv.org/abs/2505.21281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于一阶逻辑形式化和比较学习的规则增强法律判断预测框架，旨在通过自适应调整机制提升法律判断预测的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的语义增强法律判断预测模型忽视了法律推理逻辑这一关键组件，且其逻辑刚性限制了适应特定案件逻辑框架的能力。&lt;h4&gt;目的&lt;/h4&gt;开发一个自适应调整机制，以增强法律判断预测的性能。&lt;h4&gt;方法&lt;/h4&gt;采用三阶段方法：首先，使用一阶逻辑形式化初始化判断规则，以准确捕捉复杂的推理逻辑；其次，提出了一种混淆感知对比学习（CACL）来动态优化判断规则；最后，利用优化后的判断规则进行法律判断预测。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公共数据集上的实验结果表明，该框架在所有指标上均表现出优异的性能。&lt;h4&gt;结论&lt;/h4&gt;该规则增强的法律判断预测框架能够有效提升法律判断预测的性能。&lt;h4&gt;翻译&lt;/h4&gt;Legal Judgment Prediction (LJP) is a pivotal task in legal AI. Existing semantic-enhanced LJP models integrate judicial precedents and legal knowledge for high performance. But they neglect legal reasoning logic, a critical component of legal judgments requiring rigorous logical analysis. Although some approaches utilize legal reasoning logic for high-quality predictions, their logic rigidity hinders adaptation to case-specific logical frameworks, particularly in complex cases that are lengthy and detailed. This paper proposes a rule-enhanced legal judgment prediction framework based on first-order logic (FOL) formalism and comparative learning (CL) to develop an adaptive adjustment mechanism for legal judgment logic and further enhance performance in LJP. Inspired by the process of human exam preparation, our method follows a three-stage approach: first, we initialize judgment rules using the FOL formalism to capture complex reasoning logic accurately; next, we propose a Confusion-aware Contrastive Learning (CACL) to dynamically optimize the judgment rules through a quiz consisting of confusable cases; finally, we utilize the optimized judgment rules to predict legal judgments. Experimental results on two public datasets show superior performance across all metrics. The code is publicly available{https://anonymous.4open.science/r/RLJP-FDF1}.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Legal Judgment Prediction (LJP) is a pivotal task in legal AI. Existingsemantic-enhanced LJP models integrate judicial precedents and legal knowledgefor high performance. But they neglect legal reasoning logic, a criticalcomponent of legal judgments requiring rigorous logical analysis. Although someapproaches utilize legal reasoning logic for high-quality predictions, theirlogic rigidity hinders adaptation to case-specific logical frameworks,particularly in complex cases that are lengthy and detailed. This paperproposes a rule-enhanced legal judgment prediction framework based onfirst-order logic (FOL) formalism and comparative learning (CL) to develop anadaptive adjustment mechanism for legal judgment logic and further enhanceperformance in LJP. Inspired by the process of human exam preparation, ourmethod follows a three-stage approach: first, we initialize judgment rulesusing the FOL formalism to capture complex reasoning logic accurately; next, wepropose a Confusion-aware Contrastive Learning (CACL) to dynamically optimizethe judgment rules through a quiz consisting of confusable cases; finally, weutilize the optimized judgment rules to predict legal judgments. Experimentalresults on two public datasets show superior performance across all metrics.The code is publicly available{https://anonymous.4open.science/r/RLJP-FDF1}.</description>
      <author>example@mail.com (Yue Zhang, Zhiliang Tian, Shicheng Zhou, Haiyang Wang, Wenqing Hou, Yuying Liu, Xuechen Zhao, Minlie Huang, Ye Wang, Bin Zhou)</author>
      <guid isPermaLink="false">2505.21281v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>DeCAF: Decentralized Consensus-And-Factorization for Low-Rank Adaptation of Foundation Models</title>
      <link>http://arxiv.org/abs/2505.21382v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;LoRA是一种有效的微调方法，适用于视觉-语言模型和大型语言模型。本文提出了一种名为DeCAF的新算法，通过结合DLoRA和TSVD矩阵分解来解决去中心化LoRA中的收敛率问题。&lt;h4&gt;背景&lt;/h4&gt;LoRA通过冻结预训练模型权重并注入可训练的低秩矩阵，在边缘设备上高效学习基础模型。然而，在去中心化设置中，LoRA的理论基础仍需探索，特别是由于缺乏平滑性和模型一致性干扰。&lt;h4&gt;目的&lt;/h4&gt;提高去中心化LoRA（DLoRA）的收敛率，使其与去中心化SGD的速率相匹配，并引入DeCAF算法来解决一致性干扰问题。&lt;h4&gt;方法&lt;/h4&gt;确保梯度平滑性，并引入DeCAF算法，该算法将DLoRA与基于截断奇异值分解（TSVD）的矩阵分解相结合。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，TSVD的近似误差是有界的，随着秩的增加，DLoRA和DeCAF之间的共识差异消失，从而实现DeCAF的匹配收敛率。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，提出的算法在视觉/语言任务上优于局部训练，并在独立同分布和非独立同分布数据分布下优于联邦学习。&lt;h4&gt;翻译&lt;/h4&gt;Low-Rank Adaptation (LoRA) has emerged as one of the most effective, computationally tractable fine-tuning approaches for training Vision-Language Models (VLMs) and Large Language Models (LLMs). LoRA accomplishes this by freezing the pre-trained model weights and injecting trainable low-rank matrices, allowing for efficient learning of these foundation models even on edge devices. However, LoRA in decentralized settings still remains underexplored, particularly for the theoretical underpinnings due to the lack of smoothness guarantee and model consensus interference (defined formally below). This work improves the convergence rate of decentralized LoRA (DLoRA) to match the rate of decentralized SGD by ensuring gradient smoothness. We also introduce DeCAF, a novel algorithm integrating DLoRA with truncated singular value decomposition (TSVD)-based matrix factorization to resolve consensus interference. Theoretical analysis shows TSVD's approximation error is bounded and consensus differences between DLoRA and DeCAF vanish as rank increases, yielding DeCAF's matching convergence rate. Extensive experiments across vision/language tasks demonstrate our algorithms outperform local training and rivals federated learning under both IID and non-IID data distributions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-Rank Adaptation (LoRA) has emerged as one of the most effective,computationally tractable fine-tuning approaches for training Vision-LanguageModels (VLMs) and Large Language Models (LLMs). LoRA accomplishes this byfreezing the pre-trained model weights and injecting trainable low-rankmatrices, allowing for efficient learning of these foundation models even onedge devices. However, LoRA in decentralized settings still remains underexplored, particularly for the theoretical underpinnings due to the lack ofsmoothness guarantee and model consensus interference (defined formally below).This work improves the convergence rate of decentralized LoRA (DLoRA) to matchthe rate of decentralized SGD by ensuring gradient smoothness. We alsointroduce DeCAF, a novel algorithm integrating DLoRA with truncated singularvalue decomposition (TSVD)-based matrix factorization to resolve consensusinterference. Theoretical analysis shows TSVD's approximation error is boundedand consensus differences between DLoRA and DeCAF vanish as rank increases,yielding DeCAF's matching convergence rate. Extensive experiments acrossvision/language tasks demonstrate our algorithms outperform local training andrivals federated learning under both IID and non-IID data distributions.</description>
      <author>example@mail.com (Nastaran Saadati, Zhanhong Jiang, Joshua R. Waite, Shreyan Ganguly, Aditya Balu, Chinmay Hegde, Soumik Sarkar)</author>
      <guid isPermaLink="false">2505.21382v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>HuMoCon: Concept Discovery for Human Motion Understanding</title>
      <link>http://arxiv.org/abs/2505.20920v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HuMoCon的新颖的运动视频理解框架，用于高级人类行为分析。&lt;h4&gt;背景&lt;/h4&gt;运动概念发现对于理解和推理至关重要，但存在多模态特征对齐不明确和高频信息损失等问题。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够有效训练多模态编码器，提取语义上有意义且可推广的特征的运动概念发现框架。&lt;h4&gt;方法&lt;/h4&gt;该方法集成了特征对齐策略，利用视频进行上下文理解，以及运动进行细粒度交互建模，同时加入了速度重建机制以增强高频特征表达并减轻时间上的过度平滑。&lt;h4&gt;主要发现&lt;/h4&gt;在标准基准上的实验表明，HuMoCon能够实现有效的运动概念发现，并在训练大型模型进行人类运动理解方面显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;HuMoCon是一个有效的运动视频理解框架，并将开源相关代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present HuMoCon, a novel motion-video understanding framework designed foradvanced human behavior analysis. The core of our method is a human motionconcept discovery framework that efficiently trains multi-modal encoders toextract semantically meaningful and generalizable features. HuMoCon addresseskey challenges in motion concept discovery for understanding and reasoning,including the lack of explicit multi-modality feature alignment and the loss ofhigh-frequency information in masked autoencoding frameworks. Our approachintegrates a feature alignment strategy that leverages video for contextualunderstanding and motion for fine-grained interaction modeling, further with avelocity reconstruction mechanism to enhance high-frequency feature expressionand mitigate temporal over-smoothing. Comprehensive experiments on standardbenchmarks demonstrate that HuMoCon enables effective motion concept discoveryand significantly outperforms state-of-the-art methods in training large modelsfor human motion understanding. We will open-source the associated code withour paper.</description>
      <author>example@mail.com (Qihang Fang, Chengcheng Tang, Bugra Tekin, Shugao Ma, Yanchao Yang)</author>
      <guid isPermaLink="false">2505.20920v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Plenodium: UnderWater 3D Scene Reconstruction with Plenoptic Medium Representation</title>
      <link>http://arxiv.org/abs/2505.21258v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Plenodium的三维表示框架，该框架能够有效地对物体和参与介质进行联合建模，并通过球谐函数编码结合方向性和位置信息，实现高精度水下场景重建。&lt;h4&gt;背景&lt;/h4&gt;当前的水下场景重建方法主要依赖于基于视点的介质表示，而本文提出的方法则引入了新的表示方式。&lt;h4&gt;目的&lt;/h4&gt;提高水下场景重建的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;1. 使用球谐函数编码结合方向性和位置信息；2. 提出伪深度高斯互补方法，增强COLMAP生成的点云的深度先验；3. 开发深度排序正则化损失函数，优化场景几何结构和深度图的顺序一致性。&lt;h4&gt;主要发现&lt;/h4&gt;在真实世界的水下数据集上，该方法在三维重建方面取得了显著的改进。通过模拟数据集和可控散射介质，证明了该方法在水下场景中的恢复能力。&lt;h4&gt;结论&lt;/h4&gt;Plenodium方法在水下场景重建方面具有显著优势，能够有效提高重建精度。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为Plenodium（全息介质）的高效的三维表示框架，能够联合建模物体和参与介质。与现有的仅依赖于视点建模的介质表示方法不同，我们的新颖的全息介质表示方法通过球谐函数编码结合方向性和位置信息，实现了高度精确的水下场景重建。为了解决在退化水下环境中初始化的挑战，我们提出了伪深度高斯互补方法，以增强由COLMAP生成的点云的鲁棒深度先验。此外，我们还开发了一种深度排序正则化损失函数，以优化场景几何结构和提高深度图的顺序一致性。在真实世界水下数据集上的大量实验表明，我们的方法在三维重建方面取得了显著的改进。此外，我们通过具有真实标签和控制散射介质的模拟数据集，证明了我们的方法在水下场景中的恢复能力。我们的代码和数据集可在https://plenodium.github.io/获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Plenodium (plenoptic medium), an effective and efficient 3Drepresentation framework capable of jointly modeling both objects andparticipating media. In contrast to existing medium representations that relysolely on view-dependent modeling, our novel plenoptic medium representationincorporates both directional and positional information through sphericalharmonics encoding, enabling highly accurate underwater scene reconstruction.To address the initialization challenge in degraded underwater environments, wepropose the pseudo-depth Gaussian complementation to augment COLMAP-derivedpoint clouds with robust depth priors. In addition, a depth ranking regularizedloss is developed to optimize the geometry of the scene and improve the ordinalconsistency of the depth maps. Extensive experiments on real-world underwaterdatasets demonstrate that our method achieves significant improvements in 3Dreconstruction. Furthermore, we conduct a simulated dataset with ground truthand the controllable scattering medium to demonstrate the restorationcapability of our method in underwater scenarios. Our code and dataset areavailable at https://plenodium.github.io/.</description>
      <author>example@mail.com (Changguanng Wu, Jiangxin Dong, Chengjian Li, Jinhui Tang)</author>
      <guid isPermaLink="false">2505.21258v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>FCKT: Fine-Grained Cross-Task Knowledge Transfer with Semantic Contrastive Learning for Targeted Sentiment Analysis</title>
      <link>http://arxiv.org/abs/2505.21040v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对目标情感分析（TSA）任务进行研究，提出了一种名为FCKT的细粒度跨任务知识迁移框架，通过显式地结合方面级信息到情感预测中，实现了细粒度知识迁移，有效减轻了负迁移并提升了任务性能。&lt;h4&gt;背景&lt;/h4&gt;目标情感分析涉及从评论中识别特定方面并确定其对应情感的两个子任务。现有研究大多采用多任务学习范式在潜在空间中对齐特定任务的特征，但主要依赖于粗粒度知识迁移，缺乏对方面-情感关系的细粒度控制。&lt;h4&gt;目的&lt;/h4&gt;提出FCKT框架，以克服现有方法的局限性，实现细粒度知识迁移，有效减轻负迁移，并提升目标情感分析任务的表现。&lt;h4&gt;方法&lt;/h4&gt;FCKT框架通过显式地将方面级信息整合到情感预测中，实现细粒度知识迁移，从而提高任务性能。&lt;h4&gt;主要发现&lt;/h4&gt;在三个数据集上的实验表明，FCKT框架在目标情感分析任务中比各种基线和大型语言模型（LLMs）更有效。&lt;h4&gt;结论&lt;/h4&gt;FCKT框架能够有效提升目标情感分析任务的表现，减轻负迁移，并通过细粒度知识迁移实现更好的性能。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we address the task of targeted sentiment analysis (TSA), which involves two sub-tasks, i.e., identifying specific aspects from reviews and determining their corresponding sentiments. Aspect extraction forms the foundation for sentiment prediction, highlighting the critical dependency between these two tasks for effective cross-task knowledge transfer. While most existing studies adopt a multi-task learning paradigm to align task-specific features in the latent space, they predominantly rely on coarse-grained knowledge transfer. Such approaches lack fine-grained control over aspect-sentiment relationships, often assuming uniform sentiment polarity within related aspects. This oversimplification neglects contextual cues that differentiate sentiments, leading to negative transfer. To overcome these limitations, we propose FCKT, a fine-grained cross-task knowledge transfer framework tailored for TSA. By explicitly incorporating aspect-level information into sentiment prediction, FCKT achieves fine-grained knowledge transfer, effectively mitigating negative transfer and enhancing task performance. Experiments on three datasets, including comparisons with various baselines and large language models (LLMs), demonstrate the effectiveness of FCKT. The source code is available on https://github.com/cwei01/FCKT.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we address the task of targeted sentiment analysis (TSA),which involves two sub-tasks, i.e., identifying specific aspects from reviewsand determining their corresponding sentiments. Aspect extraction forms thefoundation for sentiment prediction, highlighting the critical dependencybetween these two tasks for effective cross-task knowledge transfer. While mostexisting studies adopt a multi-task learning paradigm to align task-specificfeatures in the latent space, they predominantly rely on coarse-grainedknowledge transfer. Such approaches lack fine-grained control overaspect-sentiment relationships, often assuming uniform sentiment polaritywithin related aspects. This oversimplification neglects contextual cues thatdifferentiate sentiments, leading to negative transfer. To overcome theselimitations, we propose FCKT, a fine-grained cross-task knowledge transferframework tailored for TSA. By explicitly incorporating aspect-levelinformation into sentiment prediction, FCKT achieves fine-grained knowledgetransfer, effectively mitigating negative transfer and enhancing taskperformance. Experiments on three datasets, including comparisons with variousbaselines and large language models (LLMs), demonstrate the effectiveness ofFCKT. The source code is available on https://github.com/cwei01/FCKT.</description>
      <author>example@mail.com (Wei Chen, Zhao Zhang, Meng Yuan, Kepeng Xu, Fuzhen Zhuang)</author>
      <guid isPermaLink="false">2505.21040v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>GSAT: Graph Structure Attention Networks</title>
      <link>http://arxiv.org/abs/2505.21288v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GSAT的图结构注意力网络，用于提高图分类基准测试的性能。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在处理图结构数据方面表现出强大的能力，但在图分类任务中，节点结构表示的局部拓扑信息通常被忽视，导致模型性能受限。&lt;h4&gt;目的&lt;/h4&gt;通过利用匿名随机游走（ARWs）建模的结构信息，引入GSAT网络，以整合节点属性和结构表示，使模型自动寻找关注不同边模式的模式，从而丰富图表示。&lt;h4&gt;方法&lt;/h4&gt;GSAT是对图注意力网络（GAT）的泛化，通过结合节点属性和结构信息，使模型能够自动关注节点邻域中的不同边。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，GSAT在部分图分类基准测试中略微提高了SOTA（最先进的技术）的性能。&lt;h4&gt;结论&lt;/h4&gt;GSAT网络通过整合结构信息，有效提高了图分类任务中的模型性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have emerged as a powerful tool for processing data represented in graph structures, achieving remarkable success across a wide range of applications. However, to further improve the performance on graph classification benchmarks, structural representation of each node that encodes rich local topological information in the neighbourhood of nodes is an important type of feature that is often overlooked in the modeling. The consequence of neglecting the structural information has resulted in a high number of layers to connect messages from distant nodes which by itself produces other problems such as oversmoothing. In the present paper, we leverage these structural information that are modeled by anonymous random walks (ARWs) and introduce graph structure attention network (GSAT) which is a generalization of graph attention network(GAT) to integrate the original attribute and the structural representation to enforce the model to automatically find patterns for attending to different edges in the node neighbourhood to enrich graph representation. Our experiments show GSAT slightly improves SOTA on some graph classification benchmarks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have emerged as a powerful tool for processingdata represented in graph structures, achieving remarkable success across awide range of applications. However, to further improve the performance ongraph classification benchmarks, structural representation of each node thatencodes rich local topological information in the neighbourhood of nodes is animportant type of feature that is often overlooked in the modeling. Theconsequence of neglecting the structural information has resulted high numberof layers to connect messages from distant nodes which by itself produces otherproblems such as oversmoothing. In the present paper, we leverage thesestructural information that are modeled by anonymous random walks (ARWs) andintroduce graph structure attention network (GSAT) which is a generalization ofgraph attention network(GAT) to integrate the original attribute and thestructural representation to enforce the model to automatically find patternsfor attending to different edges in the node neighbourhood to enrich graphrepresentation. Our experiments show GSAT slightly improves SOTA on some graphclassification benchmarks.</description>
      <author>example@mail.com (Farshad Noravesh, Reza Haffari, Layki Soon, Arghya Pal)</author>
      <guid isPermaLink="false">2505.21288v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Transfer learning for multifidelity simulation-based inference in cosmology</title>
      <link>http://arxiv.org/abs/2505.21215v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9+4 pages, 8+5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多保真度迁移学习的模拟推断方法，用于宇宙学参数估计，以克服高保真模拟数据集成本高昂的问题。&lt;h4&gt;背景&lt;/h4&gt;模拟推断（SBI）在无法获取封闭形式的似然函数或模型时进行宇宙学参数估计。然而，SBI依赖于机器学习进行神经网络压缩和密度估计，这需要大量的训练数据集，而高质量模拟数据的获取成本极高。&lt;h4&gt;目的&lt;/h4&gt;克服高保真模拟数据集成本高昂的限制。&lt;h4&gt;方法&lt;/h4&gt;通过多保真度迁移学习，将成本较低的、低保真度的模拟与少量高保真度模拟相结合。在CAMELS多场数据集的水动力学模拟中，利用仅暗物质N体模拟进行预训练，以减少所需的高保真度水动力学模拟数量。&lt;h4&gt;主要发现&lt;/h4&gt;预训练减少了所需的高保真度水动力学模拟数量，减少比例介于8到15之间，具体取决于模型复杂性、后验维度和性能指标。&lt;h4&gt;结论&lt;/h4&gt;通过利用低成本模拟，该方法在保持高性能和高准确性的同时，显著降低了计算成本。&lt;h4&gt;翻译&lt;/h4&gt;Simulation-based inference (SBI) enables cosmological parameter estimation when closed-form likelihoods or models are unavailable. However, SBI relies on machine learning for neural compression and density estimation. This requires large training datasets which are prohibitively expensive for high-quality simulations. We overcome this limitation with multifidelity transfer learning, combining less expensive, lower-fidelity simulations with a limited number of high-fidelity simulations. We demonstrate our methodology on dark matter density maps from two separate simulation suites in the hydrodynamical CAMELS Multifield Dataset. Pre-training on dark-matter-only $N$-body simulations reduces the required number of high-fidelity hydrodynamical simulations by a factor between $8$ and $15$, depending on the model complexity, posterior dimensionality, and performance metrics used. By leveraging cheaper simulations, our approach enables performant and accurate inference on high-fidelity models while substantially reducing computational costs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulation-based inference (SBI) enables cosmological parameter estimationwhen closed-form likelihoods or models are unavailable. However, SBI relies onmachine learning for neural compression and density estimation. This requireslarge training datasets which are prohibitively expensive for high-qualitysimulations. We overcome this limitation with multifidelity transfer learning,combining less expensive, lower-fidelity simulations with a limited number ofhigh-fidelity simulations. We demonstrate our methodology on dark matterdensity maps from two separate simulation suites in the hydrodynamical CAMELSMultifield Dataset. Pre-training on dark-matter-only $N$-body simulationsreduces the required number of high-fidelity hydrodynamical simulations by afactor between $8$ and $15$, depending on the model complexity, posteriordimensionality, and performance metrics used. By leveraging cheapersimulations, our approach enables performant and accurate inference onhigh-fidelity models while substantially reducing computational costs.</description>
      <author>example@mail.com (Alex A. Saoulis, Davide Piras, Niall Jeffrey, Alessio Spurio Mancini, Ana M. G. Ferreira, Benjamin Joachimi)</author>
      <guid isPermaLink="false">2505.21215v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Automatically Identify and Rectify: Robust Deep Contrastive Multi-view Clustering in Noisy Scenarios</title>
      <link>http://arxiv.org/abs/2505.21387v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为AIRMVC的新型多视角聚类框架，用于自动识别和纠正噪声数据，在噪声环境下展现出比现有算法更优的性能。&lt;h4&gt;背景&lt;/h4&gt;近年来，深度多视角聚类方法通过整合来自不同视角的多源信息展现出可靠的性能。然而，噪声在现实场景中普遍存在，导致性能下降。&lt;h4&gt;目的&lt;/h4&gt;针对噪声问题，提出一种自动识别和纠正噪声数据的多视角聚类框架。&lt;h4&gt;方法&lt;/h4&gt;使用GMM将噪声识别重新定义为异常识别问题，并设计了一种混合校正策略来减轻噪声数据的不利影响。同时，引入了一种噪声鲁棒的对比机制来生成可靠的表示，并通过理论证明这些表示可以丢弃噪声信息。&lt;h4&gt;主要发现&lt;/h4&gt;AIRMVC在六个基准数据集上的实验表明，其在噪声场景中的鲁棒性优于现有算法。&lt;h4&gt;结论&lt;/h4&gt;AIRMVC是一种有效应对噪声问题的多视角聚类方法，能够显著提高下游任务的表现。&lt;h4&gt;翻译&lt;/h4&gt;摘要：利用强大的表示学习能力，近年来深度多视角聚类方法通过有效整合来自不同视角的多源信息，表现出了可靠的性能。大多数现有方法依赖于干净的视角假设。然而，在现实场景中，噪声普遍存在，导致性能显著下降。为了解决这个问题，我们提出了一种名为AIRMVC的新型多视角聚类框架，用于自动识别和纠正噪声数据。具体来说，我们使用GMM将噪声识别重新定义为异常识别问题。然后，我们根据识别结果设计了一种混合校正策略，以减轻噪声数据的不利影响。此外，我们引入了一种噪声鲁棒的对比机制来生成可靠的表示。另外，我们还提供了一种理论证明，证明了这些表示可以丢弃噪声信息，从而提高下游任务的表现。在六个基准数据集上的大量实验表明，AIRMVC在噪声场景中的鲁棒性优于最先进的算法。AIRMVC的代码可在https://github.com/xihongyang1999/AIRMVC上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Leveraging the powerful representation learning capabilities, deep multi-viewclustering methods have demonstrated reliable performance by effectivelyintegrating multi-source information from diverse views in recent years. Mostexisting methods rely on the assumption of clean views. However, noise ispervasive in real-world scenarios, leading to a significant degradation inperformance. To tackle this problem, we propose a novel multi-view clusteringframework for the automatic identification and rectification of noisy data,termed AIRMVC. Specifically, we reformulate noisy identification as an anomalyidentification problem using GMM. We then design a hybrid rectificationstrategy to mitigate the adverse effects of noisy data based on theidentification results. Furthermore, we introduce a noise-robust contrastivemechanism to generate reliable representations. Additionally, we provide atheoretical proof demonstrating that these representations can discard noisyinformation, thereby improving the performance of downstream tasks. Extensiveexperiments on six benchmark datasets demonstrate that AIRMVC outperformsstate-of-the-art algorithms in terms of robustness in noisy scenarios. The codeof AIRMVC are available at https://github.com/xihongyang1999/AIRMVC on Github.</description>
      <author>example@mail.com (Xihong Yang, Siwei Wang, Fangdi Wang, Jiaqi Jin, Suyuan Liu, Yue Liu, En Zhu, Xinwang Liu, Yueming Jin)</author>
      <guid isPermaLink="false">2505.21387v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>SOLIDGEO: Measuring Multimodal Spatial Math Reasoning in Solid Geometry</title>
      <link>http://arxiv.org/abs/2505.21177v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SolidGeo，这是一个用于评估多模态大型语言模型在固体几何推理任务上表现的大规模基准。&lt;h4&gt;背景&lt;/h4&gt;几何学是数学的一个基本分支，在评估多模态大型语言模型（MLLMs）的推理能力中起着关键作用。然而，现有的多模态数学基准主要关注平面几何，而忽略了需要空间推理且比平面几何更具挑战性的固体几何。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一关键差距，本文引入了SolidGeo，它是第一个专门设计用于评估MLLMs在固体几何推理任务上表现的基准。&lt;h4&gt;方法&lt;/h4&gt;SolidGeo包含3,113个现实世界K-12和竞赛级别的题目，每个题目都配对视觉上下文，并标注了难度级别和细粒度的固体几何类别。该基准涵盖了投影、展开、空间测量和空间向量等多种3D推理主题。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验，观察到MLLMs在固体几何数学任务中遇到了重大挑战，与人类在SolidGeo上的表现存在相当大的性能差距。此外，本文分析了各种模型的性能、推理效率和错误模式，为MLLMs的固体几何数学推理能力提供了洞察。&lt;h4&gt;结论&lt;/h4&gt;SolidGeo有望成为推动MLLMs向更深入的几何推理和空间智能发展的催化剂。&lt;h4&gt;翻译&lt;/h4&gt;摘要：几何学是数学的一个基础分支，在评估多模态大型语言模型（MLLMs）的推理能力中起着至关重要的作用。然而，现有的多模态数学基准主要关注平面几何，而很大程度上忽略了需要空间推理且比平面几何更具挑战性的固体几何。为了解决这一关键缺口，我们引入了SolidGeo，这是第一个专门设计用来评估MLLMs在数学推理任务上固体几何性能的大规模基准。SolidGeo由3,113个真实世界的K-12和竞赛级别的题目组成，每个题目都与视觉上下文配对，并标注了难度级别和细粒度的固体几何类别。我们的基准涵盖了广泛的3D推理主题，如投影、展开、空间测量和空间向量，为评估固体几何提供了一个严格的测试平台。通过广泛的实验，我们发现MLLMs在固体几何数学任务中遇到了重大的挑战，与SolidGeo上人类能力相比存在相当大的性能差距。此外，我们还分析了各种模型的性能、推理效率和错误模式，为MLLMs的固体几何数学推理能力提供了见解。我们希望SolidGeo能够成为推动MLLMs向更深入的几何推理和空间智能发展的催化剂。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometry is a fundamental branch of mathematics and plays a crucial role inevaluating the reasoning capabilities of multimodal large language models(MLLMs). However, existing multimodal mathematics benchmarks mainly focus onplane geometry and largely ignore solid geometry, which requires spatialreasoning and is more challenging than plane geometry. To address this criticalgap, we introduce SolidGeo, the first large-scale benchmark specificallydesigned to evaluate the performance of MLLMs on mathematical reasoning tasksin solid geometry. SolidGeo consists of 3,113 real-world K-12 andcompetition-level problems, each paired with visual context and annotated withdifficulty levels and fine-grained solid geometry categories. Our benchmarkcovers a wide range of 3D reasoning subjects such as projection, unfolding,spatial measurement, and spatial vector, offering a rigorous testbed forassessing solid geometry. Through extensive experiments, we observe that MLLMsencounter substantial challenges in solid geometry math tasks, with aconsiderable performance gap relative to human capabilities on SolidGeo.Moreover, we analyze the performance, inference efficiency and error patternsof various models, offering insights into the solid geometric mathematicalreasoning capabilities of MLLMs. We hope SolidGeo serves as a catalyst foradvancing MLLMs toward deeper geometric reasoning and spatial intelligence.</description>
      <author>example@mail.com (Peijie Wang, Chao Yang, Zhong-Zhi Li, Fei Yin, Dekang Ran, Mi Tian, Zhilong Ji, Jinfeng Bai, Cheng-Lin Liu)</author>
      <guid isPermaLink="false">2505.21177v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Uni3D-MoE: Scalable Multimodal 3D Scene Understanding via Mixture of Experts</title>
      <link>http://arxiv.org/abs/2505.21079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Uni3D-MoE，一种基于稀疏混合专家（MoE）的3D多模态大语言模型，旨在实现自适应的3D多模态融合。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态大语言模型（MLLMs）在3D场景理解方面具有巨大潜力，但通常只利用一个或有限的3D模态，导致3D场景表示不完整，解释准确性降低。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出Uni3D-MoE，以实现更全面的3D场景理解和提高解释准确性。&lt;h4&gt;方法&lt;/h4&gt;Uni3D-MoE整合了包括多视角RGB和深度图像、鸟瞰图（BEV）地图、点云和体素表示在内的全面3D模态。其核心是使用可学习的路由机制，在标记级别动态选择合适的专家，每个专家根据学习到的模态偏好处理多模态标记，从而实现针对不同任务要求的灵活协作。&lt;h4&gt;主要发现&lt;/h4&gt;在标准3D场景理解基准和专用数据集上的广泛评估表明，Uni3D-MoE是有效的。&lt;h4&gt;结论&lt;/h4&gt;Uni3D-MoE能够有效地实现3D多模态融合，提高了3D场景理解的准确性和全面性。&lt;h4&gt;翻译&lt;/h4&gt;Recent advancements in multimodal large language models (MLLMs) have demonstrated considerable potential for comprehensive 3D scene understanding. However, existing approaches typically utilize only one or a limited subset of 3D modalities, resulting in incomplete representations of 3D scenes and reduced interpretive accuracy. Furthermore, different types of queries inherently depend on distinct modalities, indicating that uniform processing of all modality tokens may fail to effectively capture query-specific context. To address these challenges, we propose Uni3D-MoE, a sparse Mixture-of-Experts (MoE)-based 3D MLLM designed to enable adaptive 3D multimodal fusion. Specifically, Uni3D-MoE integrates a comprehensive set of 3D modalities, including multi-view RGB and depth images, bird's-eye-view (BEV) maps, point clouds, and voxel representations. At its core, our framework employs a learnable routing mechanism within the sparse MoE-based large language model, dynamically selecting appropriate experts at the token level. Each expert specializes in processing multimodal tokens based on learned modality preferences, thus facilitating flexible collaboration tailored to diverse task-specific requirements. Extensive evaluations on standard 3D scene understanding benchmarks and specialized datasets demonstrate the efficacy of Uni3D-MoE.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in multimodal large language models (MLLMs) havedemonstrated considerable potential for comprehensive 3D scene understanding.However, existing approaches typically utilize only one or a limited subset of3D modalities, resulting in incomplete representations of 3D scenes and reducedinterpretive accuracy. Furthermore, different types of queries inherentlydepend on distinct modalities, indicating that uniform processing of allmodality tokens may fail to effectively capture query-specific context. Toaddress these challenges, we propose Uni3D-MoE, a sparse Mixture-of-Experts(MoE)-based 3D MLLM designed to enable adaptive 3D multimodal fusion.Specifically, Uni3D-MoE integrates a comprehensive set of 3D modalities,including multi-view RGB and depth images, bird's-eye-view (BEV) maps, pointclouds, and voxel representations. At its core, our framework employs alearnable routing mechanism within the sparse MoE-based large language model,dynamically selecting appropriate experts at the token level. Each expertspecializes in processing multimodal tokens based on learned modalitypreferences, thus facilitating flexible collaboration tailored to diversetask-specific requirements. Extensive evaluations on standard 3D sceneunderstanding benchmarks and specialized datasets demonstrate the efficacy ofUni3D-MoE.</description>
      <author>example@mail.com (Yue Zhang, Yingzhao Jian, Hehe Fan, Yi Yang, Roger Zimmermann)</author>
      <guid isPermaLink="false">2505.21079v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>GeoLLaVA-8K: Scaling Remote-Sensing Multimodal Large Language Models to 8K Resolution</title>
      <link>http://arxiv.org/abs/2505.21375v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对超高分辨率遥感图像数据在地球观测中的价值及其对现有多模态基础模型的挑战，提出了新的视觉语言数据集和优化策略，构建了一个新的多模态大型语言模型。&lt;h4&gt;背景&lt;/h4&gt;超高分辨率遥感图像在地球观测中具有价值，但对现有多模态基础模型存在两个主要瓶颈：UHR训练数据有限和图像大小导致的token爆炸。&lt;h4&gt;目的&lt;/h4&gt;提出解决方案以应对UHR遥感图像数据的挑战，并提升多模态基础模型的处理能力。&lt;h4&gt;方法&lt;/h4&gt;引入了SuperRS-VQA和HighRS-VQA数据集，针对token爆炸问题提出了背景Token Pruning和Anchored Token Selection策略，并构建了GeoLLaVA-8K模型。&lt;h4&gt;主要发现&lt;/h4&gt;遥感图像中存在大量冗余信息，关键信息集中在少数与对象相关的token中，去除背景token可以提高性能。&lt;h4&gt;结论&lt;/h4&gt;GeoLLaVA-8K模型在处理高达8K×8K分辨率的遥感图像方面达到新水平，在XLRS-Bench基准测试中取得最佳成绩。&lt;h4&gt;翻译&lt;/h4&gt;Ultra-high-resolution (UHR) remote sensing (RS) imagery offers valuable data for Earth observation but pose challenges for existing multimodal foundation models due to two key bottlenecks: (1) limited availability of UHR training data, and (2) token explosion caused by the large image size. To address data scarcity, we introduce SuperRS-VQA (avg. 8,376×8,376) and HighRS-VQA (avg. 2,000×1,912), the highest-resolution vision-language datasets in RS to date, covering 22 real-world dialogue tasks. To mitigate token explosion, our pilot studies reveal significant redundancy in RS images: crucial information is concentrated in a small subset of object-centric tokens, while pruning background tokens (e.g., ocean or forest) can even improve performance. Motivated by these findings, we propose two strategies: Background Token Pruning and Anchored Token Selection, to reduce the memory footprint while preserving key semantics. Integrating these techniques, we introduce GeoLLaVA-8K, the first RS-focused multimodal large language model capable of handling inputs up to 8K×8K resolution, built on the LLaVA framework. Trained on SuperRS-VQA and HighRS-VQA, GeoLLaVA-8K sets a new state-of-the-art on the XLRS-Bench.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ultra-high-resolution (UHR) remote sensing (RS) imagery offers valuable datafor Earth observation but pose challenges for existing multimodal foundationmodels due to two key bottlenecks: (1) limited availability of UHR trainingdata, and (2) token explosion caused by the large image size. To address datascarcity, we introduce SuperRS-VQA (avg. 8,376$\times$8,376) and HighRS-VQA(avg. 2,000$\times$1,912), the highest-resolution vision-language datasets inRS to date, covering 22 real-world dialogue tasks. To mitigate token explosion,our pilot studies reveal significant redundancy in RS images: crucialinformation is concentrated in a small subset of object-centric tokens, whilepruning background tokens (e.g., ocean or forest) can even improve performance.Motivated by these findings, we propose two strategies: Background TokenPruning and Anchored Token Selection, to reduce the memory footprint whilepreserving key semantics.Integrating these techniques, we introduceGeoLLaVA-8K, the first RS-focused multimodal large language model capable ofhandling inputs up to 8K$\times$8K resolution, built on the LLaVA framework.Trained on SuperRS-VQA and HighRS-VQA, GeoLLaVA-8K sets a new state-of-the-arton the XLRS-Bench.</description>
      <author>example@mail.com (Fengxiang Wang, Mingshuo Chen, Yueying Li, Di Wang, Haotian Wang, Zonghao Guo, Zefan Wang, Boqi Shan, Long Lan, Yulin Wang, Hongzhen Wang, Wenjing Yang, Bo Du, Jing Zhang)</author>
      <guid isPermaLink="false">2505.21375v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>MUSEG: Reinforcing Video Temporal Understanding via Timestamp-Aware Multi-Segment Grounding</title>
      <link>http://arxiv.org/abs/2505.20715v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MUSEG的基于强化学习的新方法，旨在增强多模态大型语言模型对视频时间理解的准确性。&lt;h4&gt;背景&lt;/h4&gt;尽管视频理解技术取得了进展，但现有的多模态大型语言模型在细粒度时间推理方面仍然存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出MUSEG方法，以提升多模态大型语言模型对视频事件的时间推理能力。&lt;h4&gt;方法&lt;/h4&gt;MUSEG通过引入时间戳感知的多段定位来增强时间理解，并设计了带有阶段奖励的定制化强化学习训练方案，以逐步引导模型进行时间定位推理。&lt;h4&gt;主要发现&lt;/h4&gt;MUSEG在时间定位和时间敏感的视频问答任务上显著优于现有方法，并且在不同时间理解场景中具有良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;MUSEG是一种有效的方法，可以显著提高多模态大型语言模型在视频时间理解方面的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视频时间理解对于多模态大型语言模型（MLLMs）推理视频中的事件至关重要。尽管在一般视频理解方面取得了进展，但当前MLLMs在细粒度时间推理方面仍然存在困难。虽然最近探索了强化学习（RL）来解决这个问题，但现有的RL方法在有效性方面仍然有限。在这项工作中，我们提出了MUSEG，这是一种基于RL的新方法，通过引入时间戳感知的多段定位来增强时间理解。MUSEG使MLLMs能够与多个相关视频段进行对齐，从而促进更全面的时间推理。为了促进有效的学习，我们设计了一个带有阶段奖励的定制化RL训练方案，逐步引导模型进行时间定位推理。在时间定位和时间敏感的视频问答任务上的大量实验表明，MUSEG显著优于现有方法，并且在不同的时间理解场景中具有良好的泛化能力。查看我们的项目：https://github.com/THUNLP-MT/MUSEG。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video temporal understanding is crucial for multimodal large language models(MLLMs) to reason over events in videos. Despite recent advances in generalvideo understanding, current MLLMs still struggle with fine-grained temporalreasoning. While reinforcement learning (RL) has been explored to address thisissue recently, existing RL approaches remain limited in effectiveness. In thiswork, we propose MUSEG, a novel RL-based method that enhances temporalunderstanding by introducing timestamp-aware multi-segment grounding. MUSEGenables MLLMs to align queries with multiple relevant video segments, promotingmore comprehensive temporal reasoning. To facilitate effective learning, wedesign a customized RL training recipe with phased rewards that progressivelyguides the model toward temporally grounded reasoning. Extensive experiments ontemporal grounding and time-sensitive video QA tasks demonstrate that MUSEGsignificantly outperforms existing methods and generalizes well across diversetemporal understanding scenarios. View our project athttps://github.com/THUNLP-MT/MUSEG.</description>
      <author>example@mail.com (Fuwen Luo, Shengfeng Lou, Chi Chen, Ziyue Wang, Chenliang Li, Weizhou Shen, Jiyue Guo, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Yang Liu)</author>
      <guid isPermaLink="false">2505.20715v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Copresheaf Topological Neural Networks: A Generalized Deep Learning Framework</title>
      <link>http://arxiv.org/abs/2505.21251v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为共对射拓扑神经网络（CTNNs）的新框架，该框架能够统一多种深度学习架构，并用于处理结构化数据，如图像、点云、图、网格和拓扑流形。&lt;h4&gt;背景&lt;/h4&gt;尽管深度学习在各个领域产生了深远影响，但针对特定任务和数据类型的神经网络架构的设计仍然是该领域的一个挑战。&lt;h4&gt;目的&lt;/h4&gt;通过在代数拓扑的语言中奠定模型设计的基础，CTNNs旨在解决表示学习中的核心挑战，如长程依赖、过平滑、异质性和非欧几里得域。&lt;h4&gt;方法&lt;/h4&gt;CTNNs利用共对射的概念，这一概念从代数拓扑中提取，可以泛化和包含当前使用的多数实用深度学习模型。&lt;h4&gt;主要发现&lt;/h4&gt;在结构化数据基准测试中，CTNNs在需要层次化或局部敏感性的任务中，一致优于传统基准。&lt;h4&gt;结论&lt;/h4&gt;CTNNs作为深度学习下一代架构的原理性和多尺度基础。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了共对射拓扑神经网络（CTNNs），这是一种强大且统一的框架，它封装了广泛的深度学习架构，旨在处理结构化数据：包括图像、点云、图、网格和拓扑流形。虽然深度学习已经深刻影响了从数字助手到自主系统等各个领域，但针对特定任务和数据类型的神经网络架构的原理性设计仍然是该领域的一个持续存在的挑战。CTNNs通过在共对射的语言中奠定模型设计的基础来解决这个差距，共对射是代数拓扑中的一个概念，它可以泛化和包含今天使用的多数实用深度学习模型。这种抽象而建设性的公式产生了一个丰富的设计空间，从中可以得出理论上合理且实际有效的解决方案，以解决表示学习中的核心挑战：长程依赖、过平滑、异质性和非欧几里得域。我们关于结构化数据基准的实证结果表明，CTNNs在需要层次化或局部敏感性的任务中，一致优于传统基准。这些结果强调了CTNNs作为下一代深度学习架构的原理性和多尺度基础的特性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce copresheaf topological neural networks (CTNNs), a powerful andunifying framework that encapsulates a wide spectrum of deep learningarchitectures, designed to operate on structured data: including images, pointclouds, graphs, meshes, and topological manifolds. While deep learning hasprofoundly impacted domains ranging from digital assistants to autonomoussystems, the principled design of neural architectures tailored to specifictasks and data types remains one of the field's most persistent openchallenges. CTNNs address this gap by grounding model design in the language ofcopresheaves, a concept from algebraic topology that generalizes and subsumesmost practical deep learning models in use today. This abstract yetconstructive formulation yields a rich design space from which theoreticallysound and practically effective solutions can be derived to tackle corechallenges in representation learning: long-range dependencies, oversmoothing,heterophily, and non-Euclidean domains. Our empirical results on structureddata benchmarks demonstrate that CTNNs consistently outperform conventionalbaselines, particularly in tasks requiring hierarchical or localizedsensitivity. These results underscore CTNNs as a principled, multi-scalefoundation for the next generation of deep learning architectures.</description>
      <author>example@mail.com (Mustafa Hajij, Lennart Bastian, Sarah Osentoski, Hardik Kabaria, John L. Davenport, Sheik Dawood, Balaji Cherukuri, Joseph G. Kocheemoolayil, Nastaran Shahmansouri, Adrian Lew, Theodore Papamarkou, Tolga Birdal)</author>
      <guid isPermaLink="false">2505.21251v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning on LLM Back Generation Treebank for Cross-domain Constituency Parsing</title>
      <link>http://arxiv.org/abs/2505.20976v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACL 2025 main conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究利用大型语言模型（LLMs）自动生成跨领域依存句法树库的方法。&lt;h4&gt;背景&lt;/h4&gt;目前可用的多领域依存句法树库有限，跨领域依存句法解析在计算语言学中是一个未解决的问题。&lt;h4&gt;目的&lt;/h4&gt;提高LLMs在依存句法解析上的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为LLM back generation的新型树库生成方法，该方法类似于依存句法解析的反向过程。它使用仅包含领域关键词叶子节点的跨领域依存句法树作为输入，并填充缺失的词语来生成跨领域依存句法树库。此外，还引入了基于跨度对比学习的预训练策略，以充分利用LLM back generation树库进行跨领域依存句法解析。&lt;h4&gt;主要发现&lt;/h4&gt;通过在MCTB的五个目标领域上验证，LLM back generation树库结合对比学习预训练的方法，在平均结果上达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的方法在跨领域依存句法解析中取得了显著成效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-domain constituency parsing is still an unsolved challenge incomputational linguistics since the available multi-domain constituencytreebank is limited. We investigate automatic treebank generation by largelanguage models (LLMs) in this paper. The performance of LLMs on constituencyparsing is poor, therefore we propose a novel treebank generation method, LLMback generation, which is similar to the reverse process of constituencyparsing. LLM back generation takes the incomplete cross-domain constituencytree with only domain keyword leaf nodes as input and fills the missing wordsto generate the cross-domain constituency treebank. Besides, we also introducea span-level contrastive learning pre-training strategy to make full use of theLLM back generation treebank for cross-domain constituency parsing. We verifythe effectiveness of our LLM back generation treebank coupled with contrastivelearning pre-training on five target domains of MCTB. Experimental results showthat our approach achieves state-of-the-art performance on average resultscompared with various baselines.</description>
      <author>example@mail.com (Peiming Guo, Meishan Zhang, Jianling Li, Min Zhang, Yue Zhang)</author>
      <guid isPermaLink="false">2505.20976v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>AgriFM: A Multi-source Temporal Remote Sensing Foundation Model for Crop Mapping</title>
      <link>http://arxiv.org/abs/2505.21357v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AgriFM的多源遥感基础模型，该模型专门设计用于农业作物映射，通过改进的视频Swin Transformer架构和利用多源卫星数据，实现了高效的作物映射。&lt;h4&gt;背景&lt;/h4&gt;精确的作物映射依赖于对多尺度时空模式的建模，现有基于Transformer的遥感基础模型（RSFMs）在作物映射方面存在不足，如忽略作物系统的多尺度特性或忽视时间信息。&lt;h4&gt;目的&lt;/h4&gt;提出AgriFM模型，旨在解决现有RSFMs在作物映射中的不足，提高作物映射的准确性。&lt;h4&gt;方法&lt;/h4&gt;AgriFM通过建立同时进行分层时空特征提取的必要性，并开发了一种修改后的视频Swin Transformer架构，实现了时间下采样与空间缩放操作的同步。该模型利用来自MODIS、Landsat-8/9和Sentinel-2三个卫星源的时间丰富数据流，并在包含超过2500万张图像样本的全球代表性数据集上进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;AgriFM在所有下游任务中表现出优于传统深度学习和最先进的通用RSFMs的性能。&lt;h4&gt;结论&lt;/h4&gt;AgriFM是一种有效的作物映射工具，能够实现高效的多源遥感数据统一处理，为农业监测和管理提供支持。&lt;h4&gt;翻译&lt;/h4&gt;Accurate crop mapping fundamentally relies on modeling multi-scale spatiotemporal patterns, where spatial scales range from individual field textures to landscape-level context, and temporal scales capture both short-term phenological transitions and full growing-season dynamics. Transformer-based remote sensing foundation models (RSFMs) offer promising potential for crop mapping due to their innate ability for unified spatiotemporal processing. However, current RSFMs remain suboptimal for crop mapping: they either employ fixed spatiotemporal windows that ignore the multi-scale nature of crop systems or completely disregard temporal information by focusing solely on spatial patterns. To bridge these gaps, we present AgriFM, a multi-source remote sensing foundation model specifically designed for agricultural crop mapping. Our approach begins by establishing the necessity of simultaneous hierarchical spatiotemporal feature extraction, leading to the development of a modified Video Swin Transformer architecture where temporal down-sampling is synchronized with spatial scaling operations. This modified backbone enables efficient unified processing of long time-series satellite inputs. AgriFM leverages temporally rich data streams from three satellite sources including MODIS, Landsat-8/9 and Sentinel-2, and is pre-trained on a global representative dataset comprising over 25 million images samples supervised by land cover products. The resulting framework incorporates a versatile decoder architecture that dynamically fuses these learned spatiotemporal representations, supporting diverse downstream tasks. Comprehensive evaluations demonstrate AgriFM's superior performance over conventional deep learning approaches and state-of-the-art general-purpose RSFMs across all downstream tasks. Codes will be available at url https://github.com/flyakon/AgriFM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate crop mapping fundamentally relies on modeling multi-scalespatiotemporal patterns, where spatial scales range from individual fieldtextures to landscape-level context, and temporal scales capture bothshort-term phenological transitions and full growing-season dynamics.Transformer-based remote sensing foundation models (RSFMs) offer promisingpotential for crop mapping due to their innate ability for unifiedspatiotemporal processing. However, current RSFMs remain suboptimal for cropmapping: they either employ fixed spatiotemporal windows that ignore themulti-scale nature of crop systems or completely disregard temporal informationby focusing solely on spatial patterns. To bridge these gaps, we presentAgriFM, a multi-source remote sensing foundation model specifically designedfor agricultural crop mapping. Our approach begins by establishing thenecessity of simultaneous hierarchical spatiotemporal feature extraction,leading to the development of a modified Video Swin Transformer architecturewhere temporal down-sampling is synchronized with spatial scaling operations.This modified backbone enables efficient unified processing of long time-seriessatellite inputs. AgriFM leverages temporally rich data streams from threesatellite sources including MODIS, Landsat-8/9 and Sentinel-2, and ispre-trained on a global representative dataset comprising over 25 million imagesamples supervised by land cover products. The resulting framework incorporatesa versatile decoder architecture that dynamically fuses these learnedspatiotemporal representations, supporting diverse downstream tasks.Comprehensive evaluations demonstrate AgriFM's superior performance overconventional deep learning approaches and state-of-the-art general-purposeRSFMs across all downstream tasks. Codes will be available aturlhttps://github.com/flyakon/AgriFM.</description>
      <author>example@mail.com (Wenyuan Li, Shunlin Liang, Keyan Chen, Yongzhe Chen, Han Ma, Jianglei Xu, Yichuan Ma, Shikang Guan, Husheng Fang, Zhenwei Shi)</author>
      <guid isPermaLink="false">2505.21357v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Learnable Kernel Density Estimation for Graphs</title>
      <link>http://arxiv.org/abs/2505.21285v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为LGKDE的框架，用于图的核密度估计。&lt;h4&gt;背景&lt;/h4&gt;图密度估计的关键挑战在于有效地捕捉结构模式和语义变化，同时保持理论保证。&lt;h4&gt;目的&lt;/h4&gt;结合图核和核密度估计（KDE）来提高图密度估计的性能。&lt;h4&gt;方法&lt;/h4&gt;使用图神经网络将每个图表示为一个离散分布，并利用最大均值差异来学习图的度量，以进行多尺度KDE。通过最大化与精心设计的扰动图对的密度来学习所有参数。扰动节点特征和图光谱，有助于更好地描述正常密度区域的边界。&lt;h4&gt;主要发现&lt;/h4&gt;理论证明了LGKDE的一致性和收敛性保证，包括平均积分平方误差、鲁棒性和复杂性的界限。&lt;h4&gt;结论&lt;/h4&gt;通过在合成图分布中恢复底层密度以及在多个基准数据集上进行图异常检测的应用，验证了LGKDE的有效性。广泛的实证评估表明，LGKDE在大多数基准数据集上与最先进的基线相比表现出优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;本研究提出了一种名为LGKDE的框架，用于图的核密度估计。图密度估计的关键挑战在于有效地捕捉结构模式和语义变化，同时保持理论保证。结合图核和核密度估计（KDE）是提高图密度估计性能的标准方法，但由于核的手工制作和固定特征，其性能并不令人满意。我们的方法LGKDE利用图神经网络将每个图表示为一个离散分布，并利用最大均值差异来学习图的度量，以进行多尺度KDE，其中所有参数都是通过最大化与精心设计的扰动图对的密度来学习的。扰动是在节点特征和图光谱上进行的，这有助于更好地描述正常密度区域的边界。理论上，我们为LGKDE建立了一致性收敛保证，包括平均积分平方误差、鲁棒性和复杂性的界限。通过在合成图分布中恢复底层密度以及在多个基准数据集上进行图异常检测的应用，验证了LGKDE的有效性。广泛的实证评估表明，LGKDE在大多数基准数据集上与最先进的基线相比表现出优越的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work proposes a framework LGKDE that learns kernel density estimationfor graphs. The key challenge in graph density estimation lies in effectivelycapturing both structural patterns and semantic variations while maintainingtheoretical guarantees. Combining graph kernels and kernel density estimation(KDE) is a standard approach to graph density estimation, but hasunsatisfactory performance due to the handcrafted and fixed features ofkernels. Our method LGKDE leverages graph neural networks to represent eachgraph as a discrete distribution and utilizes maximum mean discrepancy to learnthe graph metric for multi-scale KDE, where all parameters are learned bymaximizing the density of graphs relative to the density of their well-designedperturbed counterparts. The perturbations are conducted on both node featuresand graph spectra, which helps better characterize the boundary of normaldensity regions. Theoretically, we establish consistency and convergenceguarantees for LGKDE, including bounds on the mean integrated squared error,robustness, and complexity. We validate LGKDE by demonstrating itseffectiveness in recovering the underlying density of synthetic graphdistributions and applying it to graph anomaly detection across diversebenchmark datasets. Extensive empirical evaluation shows that LGKDEdemonstrates superior performance compared to state-of-the-art baselines onmost benchmark datasets.</description>
      <author>example@mail.com (Xudong Wang, Ziheng Sun, Chris Ding, Jicong Fan)</author>
      <guid isPermaLink="false">2505.21285v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>BIPNN: Learning to Solve Binary Integer Programming via Hypergraph Neural Networks</title>
      <link>http://arxiv.org/abs/2505.20997v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BIPNN的框架，用于解决非线性二元整数规划问题。&lt;h4&gt;背景&lt;/h4&gt;传统的整数规划方法在处理非线性问题时存在可扩展性问题，而基于神经网络的求解器在非线性问题上的应用仍有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无监督学习框架BIPNN，通过超图神经网络来解决非线性二元整数规划问题。&lt;h4&gt;方法&lt;/h4&gt;BIPNN通过将非线性二元整数规划问题转化为无约束、可微分的多项式损失函数，利用超图神经网络进行无监督训练，并采用GPU加速和连续退火增强的训练流程。&lt;h4&gt;主要发现&lt;/h4&gt;BIPNN能够通过端到端的方式优化BIP问题，显著降低训练成本，并生成离散的高质量解。&lt;h4&gt;结论&lt;/h4&gt;在合成和真实世界数据集上的实验表明，BIPNN方法在解决非线性二元整数规划问题方面具有优越性。&lt;h4&gt;翻译&lt;/h4&gt;Binary (0-1) integer programming (BIP) is pivotal in scientific domains requiring discrete decision-making. As the advance of AI computing, recent works explore neural network-based solvers for integer linear programming (ILP) problems. Yet, they lack scalability for tackling nonlinear challenges. To handle nonlinearities, state-of-the-art Branch-and-Cut solvers employ linear relaxations, leading to exponential growth in auxiliary variables and severe computation limitations. To overcome these limitations, we propose BIPNN (Binary Integer Programming Neural Network), an unsupervised learning framework to solve nonlinear BIP problems via hypergraph neural networks (HyperGNN). Specifically, BIPNN reformulates BIPs-constrained, discrete, and nonlinear (sin, log, exp) optimization problems into unconstrained, differentiable, and polynomial loss functions. The reformulation stems from the observation of a precise one-to-one mapping between polynomial BIP objectives and hypergraph structures, enabling the unsupervised training of HyperGNN to optimize BIP problems in an end-to-end manner. On this basis, we propose a GPU-accelerated and continuous-annealing-enhanced training pipeline for BIPNN. The pipeline enables BIPNN to optimize large-scale nonlinear terms in BIPs fully in parallel via straightforward gradient descent, thus significantly reducing the training cost while ensuring the generation of discrete, high-quality solutions. Extensive experiments on synthetic and real-world datasets highlight the superiority of our approach.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Binary (0-1) integer programming (BIP) is pivotal in scientific domainsrequiring discrete decision-making. As the advance of AI computing, recentworks explore neural network-based solvers for integer linear programming (ILP)problems. Yet, they lack scalability for tackling nonlinear challenges. Tohandle nonlinearities, state-of-the-art Branch-and-Cut solvers employ linearrelaxations, leading to exponential growth in auxiliary variables and severecomputation limitations. To overcome these limitations, we propose BIPNN(Binary Integer Programming Neural Network), an unsupervised learning frameworkto solve nonlinear BIP problems via hypergraph neural networks (HyperGNN).Specifically, BIPNN reformulates BIPs-constrained, discrete, and nonlinear(sin, log, exp) optimization problems-into unconstrained, differentiable, andpolynomial loss functions. The reformulation stems from the observation of aprecise one-to-one mapping between polynomial BIP objectives and hypergraphstructures, enabling the unsupervised training of HyperGNN to optimize BIPproblems in an end-to-end manner. On this basis, we propose a GPU-acceleratedand continuous-annealing-enhanced training pipeline for BIPNN. The pipelineenables BIPNN to optimize large-scale nonlinear terms in BIPs fully in parallelvia straightforward gradient descent, thus significantly reducing the trainingcost while ensuring the generation of discrete, high-quality solutions.Extensive experiments on synthetic and real-world datasets highlight thesuperiority of our approach.</description>
      <author>example@mail.com (Sen Bai, Chunqi Yang, Xin Bai, Xin Zhang, Zhengang Jiang)</author>
      <guid isPermaLink="false">2505.20997v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Joint Learning in the Gaussian Single Index Model</title>
      <link>http://arxiv.org/abs/2505.21336v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 Pages, 3 Figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在多维高斯模型中联合学习一维投影和单变量函数的问题。&lt;h4&gt;背景&lt;/h4&gt;研究背景涉及表示学习和非线性回归的交汇点，这是一个基本的非凸问题。&lt;h4&gt;目的&lt;/h4&gt;目的是分析学习低维结构在多维设置中的理论和方法。&lt;h4&gt;方法&lt;/h4&gt;方法包括分析自然交替方案的梯度流动态，并证明其收敛性，收敛速度由信息指数控制，该指数反映了函数φ∗的高斯正则性。&lt;h4&gt;主要发现&lt;/h4&gt;主要发现是，即使初始方向与目标负相关，收敛仍然发生。&lt;h4&gt;结论&lt;/h4&gt;结论提供了理论洞察和实际方法，以在多维设置中学习低维结构。&lt;h4&gt;翻译&lt;/h4&gt;摘要：我们考虑了在多维高斯模型中联合学习一维投影和单变量函数的问题。具体来说，我们研究了形式为f(x)=φ∗(w∗,x)的预测器，其中方向w∗∈Sd-1（Rd的球面）和函数φ∗:R→R都是从高斯数据中学习的。这种设置捕捉了表示学习和非线性回归交叉处的根本非凸问题。我们分析了自然交替方案的梯度流动态，并证明了其收敛性，收敛速度由信息指数控制，该指数反映了函数φ∗的高斯正则性。引人注目的是，我们的分析表明，即使初始方向与目标负相关，收敛仍然发生。在实践方面，我们证明了可以使用适合问题结构的再生核希尔伯特空间（RKHS）有效地实现这种联合学习，从而实现单变量函数的高效和灵活估计。我们的结果为在多维设置中学习低维结构提供了理论和方法的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider the problem of jointly learning a one-dimensional projection anda univariate function in high-dimensional Gaussian models. Specifically, westudy predictors of the form $f(x)=\varphi^\star(\langle w^\star, x \rangle)$,where both the direction $w^\star \in \mathcal{S}_{d-1}$, the sphere of$\mathbb{R}^d$, and the function $\varphi^\star: \mathbb{R} \to \mathbb{R}$ arelearned from Gaussian data. This setting captures a fundamental non-convexproblem at the intersection of representation learning and nonlinearregression. We analyze the gradient flow dynamics of a natural alternatingscheme and prove convergence, with a rate controlled by the informationexponent reflecting the \textit{Gaussian regularity} of the function$\varphi^\star$. Strikingly, our analysis shows that convergence still occurseven when the initial direction is negatively correlated with the target. Onthe practical side, we demonstrate that such joint learning can be effectivelyimplemented using a Reproducing Kernel Hilbert Space (RKHS) adapted to thestructure of the problem, enabling efficient and flexible estimation of theunivariate function. Our results offer both theoretical insight and practicalmethodology for learning low-dimensional structure in high-dimensionalsettings.</description>
      <author>example@mail.com (Loucas Pillaud-Vivien, Adrien Schertzer)</author>
      <guid isPermaLink="false">2505.21336v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Towards Robust Automated Perceptual Voice Quality Assessment with Deep Learning</title>
      <link>http://arxiv.org/abs/2505.21356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的语音质量评估网络（VOQANet），旨在通过客观和可解释的方法解决传统语音质量评估的主观性和评分者间差异问题。&lt;h4&gt;背景&lt;/h4&gt;传统的语音质量评估依赖于专家评分者使用标准量表，如CAPE-V和GRBAS，但这些方法具有主观性和评分者间差异。&lt;h4&gt;目的&lt;/h4&gt;开发一种自动化和客观的语音质量评估方法，以辅助诊断和监测语音障碍。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为VOQANet的深度学习框架，该框架利用语音基础模型（SFM）从原始语音中捕获高级声学和韵律信息。为了提高鲁棒性和可解释性，还提出了VOQANet+，该模型将手工制作的声学特征（如抖动、颤音和信噪比）与SFM嵌入相结合。&lt;h4&gt;主要发现&lt;/h4&gt;基于句子的输入在患者级别上比基于元音的输入表现更好。VOQANet在RMSE和PCC方面始终优于基线方法，而VOQANet+在噪声条件下表现更好且保持鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;结合SFM嵌入和领域知识声学特征可以提高可解释性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：目标：感知语音质量评估在诊断和监测语音障碍中起着关键作用，它通过提供标准化声乐功能评估来提供标准化评估。传统上，这个过程依赖于专家评分者使用标准量表，如语音共识听觉感知评估（CAPE-V）和等级、粗糙度、呼吸、衰弱和紧张（GRBAS）。然而，这些指标本质上是主观的，容易受到评分者间差异的影响，这促使需要自动化和客观的评估方法。方法：我们提出了语音质量评估网络（VOQANet），这是一个具有注意力机制的深度学习框架，它利用语音基础模型（SFM）从原始语音中捕获高级声学和韵律信息。为了提高鲁棒性和可解释性，我们提出了VOQANet+，该模型将手工制作的声学特征（如抖动、颤音和谐波噪声比）与SFM嵌入相结合。结果：基于句子的输入在患者级别上比基于元音的输入表现更好。VOQANet在RMSE和PCC方面始终优于基线方法，而VOQANet+在噪声条件下表现更好且保持鲁棒性。结论：结合SFM嵌入和领域知识声学特征提高了可解释性和鲁棒性。意义：VOQANet+在现实世界和远程医疗环境中具有强大的应用潜力，通过一个可解释和噪声鲁棒的解决方案来解决主观感知评估的限制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Objective: Perceptual voice quality assessment plays a critical role indiagnosing and monitoring voice disorders by providing standardized evaluationof vocal function. Traditionally, this process relies on expert ratersutilizing standard scales, such as the Consensus Auditory-Perceptual Evaluationof Voice (CAPE-V) and Grade, Roughness, Breathiness, Asthenia, and Strain(GRBAS). However, these metrics are inherently subjective and susceptible tointer-rater variability, motivating the need for automated and objectiveassessment methods. Methods: We propose Voice Quality Assessment Network(VOQANet), a deep learning-based framework with an attention mechanism thatleverages a Speech Foundation Model (SFM) to capture high-level acoustic andprosodic information from raw speech. To enhance robustness andinterpretability, we present VOQANet+, which integrates handcrafted acousticfeatures such as jitter, shimmer, and harmonics-to-noise ratio (HNR) with SFMembeddings. Results: Sentence-based input yields stronger performance thanvowel-based input, especially at the patient level. VOQANet consistentlyoutperforms baseline methods in RMSE and PCC, while VOQANet+ performs evenbetter and maintains robustness under noisy conditions. Conclusion: CombiningSFM embeddings with domain-informed acoustic features improves interpretabilityand resilience. Significance: VOQANet+ shows strong potential for deployment inreal-world and telehealth settings, addressing the limitations of subjectiveperceptual assessments with an interpretable and noise-resilient solution.</description>
      <author>example@mail.com (Whenty Ariyanti, Kuan-Yu Chen, Sabato Marco Siniscalchi, Hsin-Min Wang, Yu Tsao)</author>
      <guid isPermaLink="false">2505.21356v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Something's Fishy In The Data Lake: A Critical Re-evaluation of Table Union Search Benchmarks</title>
      <link>http://arxiv.org/abs/2505.21329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted @ ACL 2025's Table Representation Learning Workshop (TRL)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了表格表示学习与数据发现方法在数据湖中的表格联合搜索（TUS）问题，并提出了未来基准测试的必要标准。&lt;h4&gt;背景&lt;/h4&gt;现有的TUS方法通常使用基准测试来评估语义理解能力，但这些基准测试存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出未来基准测试的必要标准，以实现更真实和可靠的语义表格联合搜索进展评估。&lt;h4&gt;方法&lt;/h4&gt;分析了现有的TUS基准测试，揭示了它们的局限性。&lt;h4&gt;主要发现&lt;/h4&gt;发现当前基准测试结果受到数据集特定特性的影响，未能有效隔离语义理解的增益。&lt;h4&gt;结论&lt;/h4&gt;当前基准测试未能有效评估语义理解能力，需要提出新的基准测试标准。&lt;h4&gt;翻译&lt;/h4&gt;Recent table representation learning and data discovery methods tackle tableunion search (TUS) within data lakes, which involves identifying tables thatcan be unioned with a given query table to enrich its content. These methodsare commonly evaluated using benchmarks that aim to assess semanticunderstanding in real-world TUS tasks. However, our analysis of prominent TUSbenchmarks reveals several limitations that allow simple baselines to performsurprisingly well, often outperforming more sophisticated approaches. Thissuggests that current benchmark scores are heavily influenced bydataset-specific characteristics and fail to effectively isolate the gains fromsemantic understanding. To address this, we propose essential criteria forfuture benchmarks to enable a more realistic and reliable evaluation ofprogress in semantic table union search.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent table representation learning and data discovery methods tackle tableunion search (TUS) within data lakes, which involves identifying tables thatcan be unioned with a given query table to enrich its content. These methodsare commonly evaluated using benchmarks that aim to assess semanticunderstanding in real-world TUS tasks. However, our analysis of prominent TUSbenchmarks reveals several limitations that allow simple baselines to performsurprisingly well, often outperforming more sophisticated approaches. Thissuggests that current benchmark scores are heavily influenced bydataset-specific characteristics and fail to effectively isolate the gains fromsemantic understanding. To address this, we propose essential criteria forfuture benchmarks to enable a more realistic and reliable evaluation ofprogress in semantic table union search.</description>
      <author>example@mail.com (Allaa Boutaleb, Bernd Amann, Hubert Naacke, Rafael Angarita)</author>
      <guid isPermaLink="false">2505.21329v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>IndustryEQA: Pushing the Frontiers of Embodied Question Answering in Industrial Scenarios</title>
      <link>http://arxiv.org/abs/2505.20640v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  v1.0&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为IndustryEQA的新基准，用于评估在安全关键型仓库场景中具身智能体的能力。&lt;h4&gt;背景&lt;/h4&gt;现有的具身问答（EQA）基准主要关注家庭环境，忽视了工业环境中的安全关键方面和推理过程。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，提出了IndustryEQA，旨在评估智能体在工业环境中的实际应用准备情况。&lt;h4&gt;方法&lt;/h4&gt;IndustryEQA基于NVIDIA Isaac Sim平台构建，提供了高保真度的连续记忆视频，包括多样化的工业资产、动态的人类代理和根据现实世界安全指南设计的危险情况。基准包括涵盖六个类别的丰富注释：设备安全、人类安全、物体识别、属性识别、时间理解和空间理解。此外，还提供了基于这些类别的额外推理评估。&lt;h4&gt;主要发现&lt;/h4&gt;IndustryEQA包括从小型仓库生成的971个问答对和从大型仓库生成的373个问答对，包含有人和无人的场景。&lt;h4&gt;结论&lt;/h4&gt;IndustryEQA旨在引导EQA研究，开发出更稳健、安全意识强、实际可应用的具身智能体，以适应复杂的工业环境。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Existing Embodied Question Answering (EQA) benchmarks primarily focus on household environments, often overlooking safety-critical aspects and reasoning processes pertinent to industrial settings. This drawback limits the evaluation of agent readiness for real-world industrial applications. To bridge this, we introduce IndustryEQA, the first benchmark dedicated to evaluating embodied agent capabilities within safety-critical warehouse scenarios. Built upon the NVIDIA Isaac Sim platform, IndustryEQA provides high-fidelity episodic memory videos featuring diverse industrial assets, dynamic human agents, and carefully designed hazardous situations inspired by real-world safety guidelines. The benchmark includes rich annotations covering six categories: equipment safety, human safety, object recognition, attribute recognition, temporal understanding, and spatial understanding. Besides, it also provides extrareasoning evaluation based on these categories. Specifically, it comprises 971 question-answer pairs generated from small warehouse and 373 pairs from large ones, incorporating scenarios with and without human. We further propose a comprehensive evaluation framework, including various baseline models, to assess their general perception and reasoning abilities in industrial environments. IndustryEQA aims to steer EQA research towards developing more robust, safety-aware, and practically applicable embodied agents for complex industrial environments. Benchmark and codes are available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing Embodied Question Answering (EQA) benchmarks primarily focus onhousehold environments, often overlooking safety-critical aspects and reasoningprocesses pertinent to industrial settings. This drawback limits the evaluationof agent readiness for real-world industrial applications. To bridge this, weintroduce IndustryEQA, the first benchmark dedicated to evaluating embodiedagent capabilities within safety-critical warehouse scenarios. Built upon theNVIDIA Isaac Sim platform, IndustryEQA provides high-fidelity episodic memoryvideos featuring diverse industrial assets, dynamic human agents, and carefullydesigned hazardous situations inspired by real-world safety guidelines. Thebenchmark includes rich annotations covering six categories: equipment safety,human safety, object recognition, attribute recognition, temporalunderstanding, and spatial understanding. Besides, it also provides extrareasoning evaluation based on these categories. Specifically, it comprises 971question-answer pairs generated from small warehouse and 373 pairs from largeones, incorporating scenarios with and without human. We further propose acomprehensive evaluation framework, including various baseline models, toassess their general perception and reasoning abilities in industrialenvironments. IndustryEQA aims to steer EQA research towards developing morerobust, safety-aware, and practically applicable embodied agents for complexindustrial environments. Benchmark and codes are available.</description>
      <author>example@mail.com (Yifan Li, Yuhang Chen, Anh Dao, Lichi Li, Zhongyi Cai, Zhen Tan, Tianlong Chen, Yu Kong)</author>
      <guid isPermaLink="false">2505.20640v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>HoPE: Hybrid of Position Embedding for Length Generalization in Vision-Language Models</title>
      <link>http://arxiv.org/abs/2505.20444v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视觉语言模型（VLMs）在多模态任务中的进展，特别是在长视频等长上下文场景中的性能问题。提出了一种名为HoPE的混合位置嵌入方法，以改善VLMs在长上下文中的能力。&lt;h4&gt;背景&lt;/h4&gt;尽管视觉语言模型在多模态任务中取得了显著进展，但在处理长视频等长上下文时，其性能通常会下降。现有的Rotary Position Embedding（RoPE）在长语言模型中广泛用于长度泛化，但将其扩展到视频中的空间时间依赖关系仍然是一个未解决的问题。&lt;h4&gt;目的&lt;/h4&gt;提出HoPE方法，旨在提高视觉语言模型在长上下文中的性能，尤其是在长视频理解与检索任务中。&lt;h4&gt;方法&lt;/h4&gt;研究不同分配策略对VLMs长上下文能力的影响，并提出了HoPE，包括混合频率分配策略和动态时间缩放机制。&lt;h4&gt;主要发现&lt;/h4&gt;当前的多模态RoPE无法可靠地捕获扩展上下文中的语义相似性。HoPE通过引入混合频率分配策略和动态时间缩放机制，解决了这一问题。&lt;h4&gt;结论&lt;/h4&gt;在四个视频基准测试中，HoPE在长视频理解和检索任务上优于现有方法，证实了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉语言模型（VLMs）在多模态任务中取得了显著进展。然而，在长上下文场景中，尤其是长视频中，它们的性能通常会下降。虽然旋转位置嵌入（RoPE）已被广泛应用于大型语言模型（LLMs）的长度泛化，但将vanilla RoPE扩展到捕捉视频中的复杂时空依赖关系仍然是一个未解决的问题。现有方法通常在RoPE中分配不同的频率来编码3D位置信息。然而，这些分配策略主要依赖于启发式方法，缺乏深入的理论分析。在本文中，我们首先研究了不同的分配策略如何影响VLMs的长上下文能力。我们的分析表明，当前的多模态RoPE无法可靠地捕获扩展上下文中的语义相似性。为了解决这个问题，我们提出了HoPE，一个旨在提高VLMs长上下文能力的混合位置嵌入。HoPE引入了一种混合频率分配策略，以在任意长上下文中进行可靠的语义建模，并引入了一种动态时间缩放机制，以促进在不同上下文长度上的鲁棒学习和灵活推理。在长视频理解和检索任务的四个视频基准测试中进行了广泛的实验，表明HoPE始终优于现有方法，证实了其有效性。代码可在https://github.com/hrlics/HoPE上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Models (VLMs) have made significant progress in multimodaltasks. However, their performance often deteriorates in long-context scenarios,particularly long videos. While Rotary Position Embedding (RoPE) has beenwidely adopted for length generalization in Large Language Models (LLMs),extending vanilla RoPE to capture the intricate spatial-temporal dependenciesin videos remains an unsolved challenge. Existing methods typically allocatedifferent frequencies within RoPE to encode 3D positional information. However,these allocation strategies mainly rely on heuristics, lacking in-depththeoretical analysis. In this paper, we first study how different allocationstrategies impact the long-context capabilities of VLMs. Our analysis revealsthat current multimodal RoPEs fail to reliably capture semantic similaritiesover extended contexts. To address this issue, we propose HoPE, a Hybrid ofPosition Embedding designed to improve the long-context capabilities of VLMs.HoPE introduces a hybrid frequency allocation strategy for reliable semanticmodeling over arbitrarily long context, and a dynamic temporal scalingmechanism to facilitate robust learning and flexible inference across diversecontext lengths. Extensive experiments across four video benchmarks on longvideo understanding and retrieval tasks demonstrate that HoPE consistentlyoutperforms existing methods, confirming its effectiveness. Code is availableat https://github.com/hrlics/HoPE.</description>
      <author>example@mail.com (Haoran Li, Yingjie Qin, Baoyuan Ou, Lai Xu, Ruiwen Xu)</author>
      <guid isPermaLink="false">2505.20444v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>A Cross Modal Knowledge Distillation &amp; Data Augmentation Recipe for Improving Transcriptomics Representations through Morphological Features</title>
      <link>http://arxiv.org/abs/2505.21317v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 Main Proceedings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过从显微镜图像中提取知识来增强转录组学的方法，以解决数据稀缺和可解释性问题。&lt;h4&gt;背景&lt;/h4&gt;理解细胞对刺激的反应对生物发现和药物开发至关重要。转录组学提供基因水平的可解释洞察，而显微镜成像提供丰富的预测特征，但难以解释。弱对齐数据集虽然可以支持多模态学习，但很稀缺，限制了其在训练和多模态推理中的效用。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，通过结合转录组学和显微镜图像信息，提高转录组学的预测能力和可解释性。&lt;h4&gt;方法&lt;/h4&gt;使用弱对齐数据，该方法对齐并绑定模态，通过形态信息丰富基因表达表示。为解决数据稀缺问题，引入了Semi-Clipped和PEA两种技术。&lt;h4&gt;主要发现&lt;/h4&gt;Semi-Clipped是CLIP的改进版本，用于跨模态蒸馏，并使用预训练的基础模型实现了最先进的成果。PEA是一种新的增强技术，可以增强转录组学数据，同时保留内在的生物信息。&lt;h4&gt;结论&lt;/h4&gt;这些策略提高了转录组学的预测能力并保留了其可解释性，为复杂的生物学任务提供了丰富的单模态表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding cellular responses to stimuli is crucial for biologicaldiscovery and drug development. Transcriptomics provides interpretable,gene-level insights, while microscopy imaging offers rich predictive featuresbut is harder to interpret. Weakly paired datasets, where samples sharebiological states, enable multimodal learning but are scarce, limiting theirutility for training and multimodal inference. We propose a framework toenhance transcriptomics by distilling knowledge from microscopy images. Usingweakly paired data, our method aligns and binds modalities, enriching geneexpression representations with morphological information. To address datascarcity, we introduce (1) Semi-Clipped, an adaptation of CLIP for cross-modaldistillation using pretrained foundation models, achieving state-of-the-artresults, and (2) PEA (Perturbation Embedding Augmentation), a novelaugmentation technique that enhances transcriptomics data while preservinginherent biological information. These strategies improve the predictive powerand retain the interpretability of transcriptomics, enabling rich unimodalrepresentations for complex biological tasks.</description>
      <author>example@mail.com (Ihab Bendidi, Yassir El Mesbahi, Alisandra K. Denton, Karush Suri, Kian Kenyon-Dean, Auguste Genovesio, Emmanuel Noutahi)</author>
      <guid isPermaLink="false">2505.21317v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Supervised Contrastive Learning for Ordinal Engagement Measurement</title>
      <link>http://arxiv.org/abs/2505.20676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 1 figure, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个基于视频的学生参与度测量方法，用于虚拟学习环境，并解决了参与度测量中的两个关键挑战：类别不平衡和将参与度视为有序类别而非仅分类。该方法利用监督对比学习进行有序分类，并提取视频样本中的情感和行为特征。&lt;h4&gt;背景&lt;/h4&gt;学生参与度在教育项目中至关重要，自动化的参与度测量有助于教师监控学生参与情况，识别参与度不足，并调整教学策略以提高学习成果。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来测量虚拟学习环境中的学生参与度，并解决参与度测量中的关键挑战。&lt;h4&gt;方法&lt;/h4&gt;该方法利用监督对比学习框架进行有序分类，使用序列分类器作为编码器，并应用时间序列数据增强技术来提高模型训练效果。&lt;h4&gt;主要发现&lt;/h4&gt;使用公开数据集DAiSEE评估了所提出方法的有效性，结果表明该方法在参与度水平分类方面具有鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该方法对理解并提高虚拟学习环境中的学生参与度具有显著贡献。&lt;h4&gt;翻译&lt;/h4&gt;Student engagement plays a crucial role in the successful delivery of educational programs. Automated engagement measurement helps instructors monitor student participation, identify disengagement, and adapt their teaching strategies to enhance learning outcomes effectively. This paper identifies two key challenges in this problem: class imbalance and incorporating order into engagement levels rather than treating it as mere categories. Then, a novel approach to video-based student engagement measurement in virtual learning environments is proposed that utilizes supervised contrastive learning for ordinal classification of engagement. Various affective and behavioral features are extracted from video samples and utilized to train ordinal classifiers within a supervised contrastive learning framework (with a sequential classifier as the encoder). A key step involves the application of divers time-series data augmentation techniques to these feature vectors, enhancing model training. The effectiveness of the proposed method was evaluated using a publicly available dataset for engagement measurement, DAiSEE, containing videos of students who participated in virtual learning programs. The results demonstrate the robust ability of the proposed method for the classification of the engagement level. This approach promises a significant contribution to understanding and enhancing student engagement in virtual learning environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Student engagement plays a crucial role in the successful delivery ofeducational programs. Automated engagement measurement helps instructorsmonitor student participation, identify disengagement, and adapt their teachingstrategies to enhance learning outcomes effectively. This paper identifies twokey challenges in this problem: class imbalance and incorporating order intoengagement levels rather than treating it as mere categories. Then, a novelapproach to video-based student engagement measurement in virtual learningenvironments is proposed that utilizes supervised contrastive learning forordinal classification of engagement. Various affective and behavioral featuresare extracted from video samples and utilized to train ordinal classifierswithin a supervised contrastive learning framework (with a sequentialclassifier as the encoder). A key step involves the application of diversetime-series data augmentation techniques to these feature vectors, enhancingmodel training. The effectiveness of the proposed method was evaluated using apublicly available dataset for engagement measurement, DAiSEE, containingvideos of students who participated in virtual learning programs. The resultsdemonstrate the robust ability of the proposed method for the classification ofthe engagement level. This approach promises a significant contribution tounderstanding and enhancing student engagement in virtual learningenvironments.</description>
      <author>example@mail.com (Sadaf Safa, Ali Abedi, Shehroz S. Khan)</author>
      <guid isPermaLink="false">2505.20676v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>OccLE: Label-Efficient 3D Semantic Occupancy Prediction</title>
      <link>http://arxiv.org/abs/2505.20617v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;OccLE是一种高效的3D语义占用预测方法，能够利用有限的体素注释实现高精度预测。&lt;h4&gt;背景&lt;/h4&gt;3D语义占用预测在自动驾驶感知中具有重要意义，但现有方法要么依赖全监督，要么依赖自监督，都存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出OccLE以解决现有方法的局限性，实现高效且精度高的3D语义占用预测。&lt;h4&gt;方法&lt;/h4&gt;OccLE通过解耦语义和几何学习任务，融合两者的特征网格进行预测。语义分支提取2D基础模型的伪标签，几何分支结合图像和激光雷达输入，利用半监督学习增强几何学习。通过Dual Mamba融合特征网格，并使用散点累积投影监督未标注预测。&lt;h4&gt;主要发现&lt;/h4&gt;OccLE在仅使用10%体素注释的情况下，在SemanticKITTI验证集上达到了16.59%的mIoU。&lt;h4&gt;结论&lt;/h4&gt;OccLE在有限的注释下实现了与现有方法相当的性能，为3D语义占用预测提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D semantic occupancy prediction offers an intuitive and efficient sceneunderstanding and has attracted significant interest in autonomous drivingperception. Existing approaches either rely on full supervision, which demandscostly voxel-level annotations, or on self-supervision, which provides limitedguidance and yields suboptimal performance. To address these challenges, wepropose OccLE, a Label-Efficient 3D Semantic Occupancy Prediction that takesimages and LiDAR as inputs and maintains high performance with limited voxelannotations. Our intuition is to decouple the semantic and geometric learningtasks and then fuse the learned feature grids from both tasks for the finalsemantic occupancy prediction. Therefore, the semantic branch distills 2Dfoundation model to provide aligned pseudo labels for 2D and 3D semanticlearning. The geometric branch integrates image and LiDAR inputs in cross-planesynergy based on their inherency, employing semi-supervision to enhancegeometry learning. We fuse semantic-geometric feature grids through Dual Mambaand incorporate a scatter-accumulated projection to supervise unannotatedprediction with aligned pseudo labels. Experiments show that OccLE achievescompetitive performance with only 10% of voxel annotations, reaching a mIoU of16.59% on the SemanticKITTI validation set.</description>
      <author>example@mail.com (Naiyu Fang, Zheyuan Zhou, Fayao Liu, Xulei Yang, Jiacheng Wei, Lemiao Qiu, Guosheng Lin)</author>
      <guid isPermaLink="false">2505.20617v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Deep k-grouping: An Unsupervised Learning Framework for Combinatorial Optimization on Graphs and Hypergraphs</title>
      <link>http://arxiv.org/abs/2505.20972v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的无监督组合优化框架Deep $k$-grouping，用于解决大规模图和超图上的$k$-分组问题，如着色和划分。&lt;h4&gt;背景&lt;/h4&gt;随着人工智能计算在科学发现中的应用，其在组合优化领域的潜力也逐渐显现。然而，现有的无监督神经网络求解器在解决大规模图和超图上的$k$-分组问题时，由于计算框架的限制而难以胜任。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无监督学习框架，以解决大规模图和超图上的$k$-分组问题。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种新的OH-PUBO（one-hot encoded polynomial unconstrained binary optimization）模型，用于在图和超图上建模$k$-分组问题；2. 开发了GPU加速算法，以解决大规模$k$-分组组合优化问题；3. 利用GPU加速算法统一训练流程，确保可扩展性；4. 提出了一种基于Gini系数的连续松弛退火策略，以强制解的离散性并防止收敛到局部最优。&lt;h4&gt;主要发现&lt;/h4&gt;Deep $k$-grouping在解决$k$-分组问题上优于现有的神经网络求解器和经典启发式算法，如SCIP和Tabu。&lt;h4&gt;结论&lt;/h4&gt;Deep $k$-grouping是一种有效的无监督学习框架，可以解决大规模图和超图上的$k$-分组问题，并具有优于现有方法的性能。&lt;h4&gt;翻译&lt;/h4&gt;With the application of AI computing in scientific discovery, its potential in the field of combinatorial optimization (CO) has also emerged in recent years. However, existing unsupervised neural network solvers struggle to solve $k$-grouping problems (e.g., coloring, partitioning) on large-scale graphs and hypergraphs due to limited computational frameworks. In this work, we propose Deep $k$-grouping, an unsupervised learning-based CO framework. Specifically, we contribute: Novel one-hot encoded polynomial unconstrained binary optimization (OH-PUBO), a formulation for modeling $k$-grouping problems on graphs and hypergraphs (e.g., graph/hypergraph coloring and partitioning); GPU-accelerated algorithms for large-scale $k$-grouping CO problems. Deep $k$-grouping employs the relaxation of large-scale OH-PUBO objectives as differentiable loss functions and trains to optimize them in an unsupervised manner. To ensure scalability, it leverages GPU-accelerated algorithms to unify the training pipeline; A Gini coefficient-based continuous relaxation annealing strategy to enforce discreteness of solutions while preventing convergence to local optima. Experimental results demonstrate that Deep $k$-grouping outperforms existing neural network solvers and classical heuristics such as SCIP and Tabu.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Along with AI computing shining in scientific discovery, its potential in thecombinatorial optimization (CO) domain has also emerged in recent years. Yet,existing unsupervised neural network solvers struggle to solve $k$-groupingproblems (e.g., coloring, partitioning) on large-scale graphs and hypergraphs,due to limited computational frameworks. In this work, we propose Deep$k$-grouping, an unsupervised learning-based CO framework. Specifically, wecontribute: Novel one-hot encoded polynomial unconstrained binary optimization(OH-PUBO), a formulation for modeling k-grouping problems on graphs andhypergraphs (e.g., graph/hypergraph coloring and partitioning); GPU-acceleratedalgorithms for large-scale k-grouping CO problems. Deep $k$-grouping employsthe relaxation of large-scale OH-PUBO objectives as differentiable lossfunctions and trains to optimize them in an unsupervised manner. To ensurescalability, it leverages GPU-accelerated algorithms to unify the trainingpipeline; A Gini coefficient-based continuous relaxation annealing strategy toenforce discreteness of solutions while preventing convergence to local optima.Experimental results demonstrate that Deep $k$-grouping outperforms existingneural network solvers and classical heuristics such as SCIP and Tabu.</description>
      <author>example@mail.com (Sen Bai, Chunqi Yang, Xin Bai, Xin Zhang, Zhengang Jiang)</author>
      <guid isPermaLink="false">2505.20972v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>HeteroBA: A Structure-Manipulating Backdoor Attack on Heterogeneous Graphs</title>
      <link>http://arxiv.org/abs/2505.21140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对异构图节点分类任务的新型异构后门攻击（HeteroBA）框架，旨在研究异构图神经网络（HGNNs）在推荐、金融和社会网络等领域的鲁棒性和安全性。&lt;h4&gt;背景&lt;/h4&gt;现有的研究主要关注提高HGNNs的预测性能，但对其鲁棒性和安全性，尤其是在后门攻击下的表现，研究不足。&lt;h4&gt;目的&lt;/h4&gt;研究HGNNs在多关系图场景下的潜在漏洞，并呼吁开发更鲁棒的防御措施来对抗后门威胁。&lt;h4&gt;方法&lt;/h4&gt;HeteroBA通过精心设计的触发节点和目标结构连接，利用基于注意力和基于聚类的策略选择有影响力的辅助节点，以实现有效的触发传播，从而使模型在保持对干净数据的准确性的同时，错误地将特定节点分类为目标标签。&lt;h4&gt;主要发现&lt;/h4&gt;在三个数据集和多种HGNN架构上的实验结果表明，HeteroBA实现了高攻击成功率，同时对干净数据的准确性影响最小。&lt;h4&gt;结论&lt;/h4&gt;该方法揭示了HGNNs的潜在漏洞，并呼吁在多关系图场景中采取更鲁棒的防御措施来对抗后门威胁。&lt;h4&gt;翻译&lt;/h4&gt;Heterogeneous graph neural networks (HGNNs) have recently drawn increasing attention for modeling complex multi-relational data in domains such as recommendation, finance, and social networks. While existing research has been largely focused on enhancing HGNNs' predictive performance, their robustness and security, especially under backdoor attacks, remain underexplored. In this paper, we propose a novel Heterogeneous Backdoor Attack (HeteroBA) framework for node classification tasks on heterogeneous graphs. HeteroBA inserts carefully crafted trigger nodes with realistic features and targeted structural connections, leveraging attention-based and clustering-based strategies to select influential auxiliary nodes for effective trigger propagation, thereby causing the model to misclassify specific nodes into a target label while maintaining accuracy on clean data. Experimental results on three datasets and various HGNN architectures demonstrate that HeteroBA achieves high attack success rates with minimal impact on the clean accuracy. Our method sheds light on potential vulnerabilities in HGNNs and calls for more robust defenses against backdoor threats in multi-relational graph scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterogeneous graph neural networks (HGNNs) have recently drawn increasingattention for modeling complex multi-relational data in domains such asrecommendation, finance, and social networks. While existing research has beenlargely focused on enhancing HGNNs' predictive performance, their robustnessand security, especially under backdoor attacks, remain underexplored. In thispaper, we propose a novel Heterogeneous Backdoor Attack (HeteroBA) frameworkfor node classification tasks on heterogeneous graphs. HeteroBA insertscarefully crafted trigger nodes with realistic features and targeted structuralconnections, leveraging attention-based and clustering-based strategies toselect influential auxiliary nodes for effective trigger propagation, therebycausing the model to misclassify specific nodes into a target label whilemaintaining accuracy on clean data. Experimental results on three datasets andvarious HGNN architectures demonstrate that HeteroBA achieves high attacksuccess rates with minimal impact on the clean accuracy. Our method sheds lighton potential vulnerabilities in HGNNs and calls for more robust defensesagainst backdoor threats in multi-relational graph scenarios.</description>
      <author>example@mail.com (Honglin Gao, Xiang Li, Lan Zhao, Gaoxi Xiao)</author>
      <guid isPermaLink="false">2505.21140v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Unfolding A Few Structures for The Many: Memory-Efficient Compression of Conformer and Speech Foundation Models</title>
      <link>http://arxiv.org/abs/2505.21237v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Interspeech2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型内存高效的模型压缩方法，用于Conformer ASR和语音基础系统。&lt;h4&gt;背景&lt;/h4&gt;传统的模型压缩方法通常牺牲性能以降低内存和存储需求。&lt;h4&gt;目的&lt;/h4&gt;开发一种既节省内存又保持高性能的模型压缩方法。&lt;h4&gt;方法&lt;/h4&gt;采用了一种独特的“从小到大”设计，通过训练一个包含少量Conformer或Transformer块的紧凑“种子”模型，并将其展开多次来模拟更大未压缩模型的不同逻辑深度。种子模型和多个展开路径在单个展开周期内联合训练。使用最大展开模型和最小种子模型之间的KL散度在自蒸馏过程中最小化它们的性能差异。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在多种深度配置下，可产生与单独构建的Conformer和wav2vec2/HuBERT语音基础模型相当的性能，同时仅需极小的内存和存储空间。Conformer和wav2vec2模型分别通过35%和30%的参数减少获得了无性能损失的模型。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地实现了模型压缩，在不牺牲性能的前提下显著降低了内存需求。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新型内存高效的模型压缩方法，用于Conformer ASR和语音基础系统。该方法通过独特的“从小到大”设计，通过训练一个包含少量Conformer或Transformer块的紧凑“种子”模型，并将其展开多次来模拟更大未压缩模型的不同逻辑深度。种子模型和多个展开路径在单个展开周期内联合训练。使用最大展开模型和最小种子模型之间的KL散度在自蒸馏过程中最小化它们的性能差异。实验结果表明，该方法在多种深度配置下，可产生与单独构建的Conformer和wav2vec2/HuBERT语音基础模型相当的性能，同时仅需极小的内存和存储空间。Conformer和wav2vec2模型分别通过35%和30%的参数减少获得了无性能损失的模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel memory-efficient model compression approach forConformer ASR and speech foundation systems. Our approach features a unique"small-to-large" design. A compact "seed" model containing a few Conformer orTransformer blocks is trained and unfolded many times to emulate theperformance of larger uncompressed models with different logical depths. Theseed model and many unfolded paths are jointly trained within a singleunfolding cycle. The KL-divergence between the largest unfolded and smallestseed models is used in a self-distillation process to minimize theirperformance disparity. Experimental results show that our foldable modelproduces ASR performance comparable to individually constructed Conformer andwav2vec2/HuBERT speech foundation models under various depth configurations,while requiring only minimal memory and storage. Conformer and wav2vec2 modelswith a reduction of 35% and 30% parameters are obtained without loss ofperformance, respectively.</description>
      <author>example@mail.com (Zhaoqing Li, Haoning Xu, Xurong Xie, Zengrui Jin, Tianzi Wang, Xunying Liu)</author>
      <guid isPermaLink="false">2505.21237v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>SeisCoDE: 3D Seismic Interpretation Foundation Model with Contrastive Self-Distillation Learning</title>
      <link>http://arxiv.org/abs/2505.20518v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了一种基于深度学习的3D地震解释预训练策略，通过引入一个基于视觉变换器的自监督学习框架，有效地捕捉了关键的地震特征，提高了地震解释的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;地震解释对于理解地下结构至关重要，但目前过程劳动密集、主观且计算量大。尽管深度学习具有潜力，但其成功依赖于大量高质量的地球物理数据集，而这些数据集通常很稀缺。&lt;h4&gt;目的&lt;/h4&gt;研究旨在开发一种用于3D地震解释的预训练策略，以实现知识迁移和泛化。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个基于视觉变换器的地震对比自蒸馏编码器（SeisCoDE），它利用地震信号处理和属性分析，在预训练过程中保持地震结构的完整性。SeisCoDE通过对比学习和自蒸馏学习，在没有标记数据的情况下学习有意义的潜在表示。&lt;h4&gt;主要发现&lt;/h4&gt;SeisCoDE能够有效地捕捉关键的地震特征和特性，生成稳健的潜在特征表示，从而驱动下游的地震解释。它在不同的地震解释任务中展现出增强的泛化能力，超越了传统的监督学习UNet方法。&lt;h4&gt;结论&lt;/h4&gt;这项研究强调了基于地震图像处理和属性分析原则的基金会模型（FMs）的潜力，为将FMs集成到地震解释中，从而可能革命性地改变地下特征表征和地球物理地震勘探铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;Seismic interpretation is vital for understanding subsurface structures but remains labor-intensive, subjective, and computationally demanding. While deep learning (DL) offers promise, its success hinges on large, high-quality datasets, often scarce in geophysics. Foundation Models (FMs), which have shown significant success in fields like natural language processing and computer vision, offer a transformative opportunity for seismic interpretation by enabling knowledge transfer and generalization across interpretation tasks. However, the application of FMs in this domain remains limited, especially at the 3D scale, due to the absence of a domain-specific pretraining workflow. Here, our study sought to develop a pretraining strategy for 3D seismic interpretation by introducing a vision transformer-based Seismic Contrastive Self-Distillation Encoder (SeisCoDE), a novel self-supervised learning (SSL) framework that leverages seismic signal processing and attribute analysis, preserving seismic structural integrity during pretraining. By leveraging contrastive learning and self-distillation, SeisCoDE learns meaningful latent representations without the need for labeled data (zero-shot approach). Results indicate that SeisCoDE effectively captures critical seismic features and characteristics, producing robust latent feature representations that drive downstream seismic interpretation. It demonstrates enhanced generalization abilities across different seismic interpretation tasks, outperforming the conventional supervised learning UNet method. Overall, this research emphasizes the potential of FMs informed by seismic image processing and attribute analysis principles, paving the way for continued innovation integrating FMs for seismic interpretation, with the potential to revolutionize subsurface characterization and geophysical seismic exploration.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Seismic interpretation is vital for understanding subsurface structures butremains labor-intensive, subjective, and computationally demanding. While deeplearning (DL) offers promise, its success hinges on large, high-qualitydatasets, often scarce in geophysics. Foundation Models (FMs), which have shownsignificant success in fields like natural language processing and computervision, offer a transformative opportunity for seismic interpretation byenabling knowledge transfer and generalization across interpretation tasks.However, the application of FMs in this domain remains limited, especially atthe 3D scale, due to the absence of a domain-specific pretraining workflow.Here, our study sought to develop a pretraining strategy for 3D seismicinterpretation by introducing a vision transformer-based Seismic ContrastiveSelf-Distillation Encoder (SeisCoDE), a novel self-supervised learning (SSL)framework that leverages seismic signal processing and attribute analysis,preserving seismic structural integrity during pretraining. By leveragingcontrastive learning and self-distillation, SeisCoDE learns meaningful latentrepresentations without the need for labeled data (zero-shot approach). Resultsindicate that SeisCoDE effectively captures critical seismic features andcharacteristics, producing robust latent feature representations that drivedownstream seismic interpretation. It demonstrates enhanced generalizationabilities across different seismic interpretation tasks, outperforming theconventional supervised learning UNet method. Overall, this research emphasizesthe potential of FMs informed by seismic image processing and attributeanalysis principles, paving the way for continued innovation integrating FMsfor seismic interpretation, with the potential to revolutionize subsurfacecharacterization and geophysical seismic exploration.</description>
      <author>example@mail.com (Goodluck Archibong, Ardiansyah Koeshidayatullah, Umair Waheed, Weichang Li, Dicky Harishidayat, Motaz Alfarraj)</author>
      <guid isPermaLink="false">2505.20518v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>CityGo: Lightweight Urban Modeling and Rendering with Proxy Buildings and Residual Gaussians</title>
      <link>http://arxiv.org/abs/2505.21041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CityGo是一个混合框架，用于高效和精确地模拟大规模城市场景，适用于AR导航、无人机检查和智能城市数字孪生等应用。&lt;h4&gt;背景&lt;/h4&gt;从空中图像重建城市规模环境具有挑战性，因为存在遮挡、不完整的几何形状和高内存需求。&lt;h4&gt;目的&lt;/h4&gt;提出CityGo框架，以实现轻量级、逼真的城市场景渲染。&lt;h4&gt;方法&lt;/h4&gt;CityGo结合了纹理代理几何和剩余以及周围的3D高斯，从空中视角渲染城市场景。首先从MVS点云中提取紧凑的建筑代理网格，然后使用零阶SH高斯通过图像渲染和反向投影生成无遮挡纹理。为了捕捉高频细节，引入基于代理-照片差异和深度先验的残差高斯。更广泛的 urban context通过周围的高斯表示，对非关键区域应用重要性感知的下采样以减少冗余。定制优化策略联合优化代理纹理和高斯参数，使得在移动GPU上实现复杂城市场景的实时渲染，同时显著降低训练和内存需求。&lt;h4&gt;主要发现&lt;/h4&gt;CityGo显著减少了训练时间，平均加速1.4倍，同时提供与纯3D高斯分层方法相当的视觉保真度。此外，CityGo能够在移动消费级GPU上实时渲染大规模城市场景，大幅减少内存使用和能耗。&lt;h4&gt;结论&lt;/h4&gt;CityGo框架通过结合多种技术，实现了高效和逼真的大规模城市场景渲染，为AR导航、无人机检查和智能城市数字孪生等应用提供了有力支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and efficient modeling of large-scale urban scenes is critical forapplications such as AR navigation, UAV based inspection, and smart citydigital twins. While aerial imagery offers broad coverage and complementslimitations of ground-based data, reconstructing city-scale environments fromsuch views remains challenging due to occlusions, incomplete geometry, and highmemory demands. Recent advances like 3D Gaussian Splatting (3DGS) improvescalability and visual quality but remain limited by dense primitive usage,long training times, and poor suit ability for edge devices. We propose CityGo,a hybrid framework that combines textured proxy geometry with residual andsurrounding 3D Gaussians for lightweight, photorealistic rendering of urbanscenes from aerial perspectives. Our approach first extracts compact buildingproxy meshes from MVS point clouds, then uses zero order SH Gaussians togenerate occlusion-free textures via image-based rendering and back-projection.To capture high-frequency details, we introduce residual Gaussians placed basedon proxy-photo discrepancies and guided by depth priors. Broader urban contextis represented by surrounding Gaussians, with importance-aware downsamplingapplied to non-critical regions to reduce redundancy. A tailored optimizationstrategy jointly refines proxy textures and Gaussian parameters, enablingreal-time rendering of complex urban scenes on mobile GPUs with significantlyreduced training and memory requirements. Extensive experiments on real-worldaerial datasets demonstrate that our hybrid representation significantlyreduces training time, achieving on average 1.4x speedup, while deliveringcomparable visual fidelity to pure 3D Gaussian Splatting approaches.Furthermore, CityGo enables real-time rendering of large-scale urban scenes onmobile consumer GPUs, with substantially reduced memory usage and energyconsumption.</description>
      <author>example@mail.com (Weihang Liu, Yuhui Zhong, Yuke Li, Xi Chen, Jiadi Cui, Honglong Zhang, Lan Xu, Xin Lou, Yujiao Shi, Jingyi Yu, Yingliang Zhang)</author>
      <guid isPermaLink="false">2505.21041v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Scaling and Prompting for Improved End-to-End Spoken Grammatical Error Correction</title>
      <link>http://arxiv.org/abs/2505.21137v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to Interspeech&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了语音语法错误纠正（SGEC）和反馈（SGECF）在第二语言学习者、教师和应试者中的重要性，并探讨了端到端（E2E）语音基础模型在SGEC和反馈生成中的有效性。&lt;h4&gt;背景&lt;/h4&gt;传统的SGEC系统依赖于由自动语音识别（ASR）、流畅度检测（DD）和移除以及语法错误纠正模块组成的级联流水线。&lt;h4&gt;目的&lt;/h4&gt;目的是评估端到端语音基础模型在SGEC和反馈生成中的效果，并解决有限标注数据的问题。&lt;h4&gt;方法&lt;/h4&gt;研究引入了伪标签过程来解决标注数据不足的挑战，将训练数据量从77小时扩展到约2500小时。此外，研究使用流畅的转录提示了一个基于E2E Whisper的SGEC模型，并评估了增加模型大小对性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;伪标签数据有助于提高SGEC性能，但在反馈生成中效果更显著。尽管伪标签数据对于更大的Whisper模型没有带来性能提升，但使用提示进行训练证明了其有益性。&lt;h4&gt;结论&lt;/h4&gt;端到端语音基础模型在SGEC和反馈生成中具有潜力，伪标签和数据量扩展有助于性能提升，而使用提示训练模型效果更佳。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spoken Grammatical Error Correction (SGEC) and Feedback (SGECF) are crucialfor second language learners, teachers and test takers. Traditional SGECsystems rely on a cascaded pipeline consisting of an ASR, a module fordisfluency detection (DD) and removal and one for GEC. With the rise ofend-to-end (E2E) speech foundation models, we investigate their effectivenessin SGEC and feedback generation. This work introduces a pseudo-labellingprocess to address the challenge of limited labelled data, expanding thetraining data size from 77 hours to approximately 2500 hours, leading toimproved performance. Additionally, we prompt an E2E Whisper-based SGEC modelwith fluent transcriptions, showing a slight improvement in SGEC performance,with more significant gains in feedback generation. Finally, we assess theimpact of increasing model size, revealing that while pseudo-labelled data doesnot yield performance gain for a larger Whisper model, training with promptsproves beneficial.</description>
      <author>example@mail.com (Mengjie Qian, Rao Ma, Stefano Bannò, Kate M. Knill, Mark J. F. Gales)</author>
      <guid isPermaLink="false">2505.21137v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter</title>
      <link>http://arxiv.org/abs/2505.20941v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Point Mamba Adapter (PMA)的新方法，用于提升点云理解能力，通过构建有序特征序列并融合互补语义信息，从而实现更全面的多层信息整合。&lt;h4&gt;背景&lt;/h4&gt;现有的点云理解方法主要依赖于预训练模型的最终输出，忽略了中间层丰富的互补信息，未能充分利用预训练模型的潜力。&lt;h4&gt;目的&lt;/h4&gt;提出一种解决方案，以克服现有方法的局限性，提升点云理解能力。&lt;h4&gt;方法&lt;/h4&gt;1. 提出PMA，从预训练模型的所有层构建有序特征序列。2. 利用Mamba融合所有互补语义。3. 设计几何约束门控提示生成器(G2PG)，应用于不同层，以共享几何约束并动态优化空间顺序。&lt;h4&gt;主要发现&lt;/h4&gt;PMA通过融合多样化的互补中间特征，显著提升了点云理解能力。&lt;h4&gt;结论&lt;/h4&gt;PMA方法在多个任务和挑战性的点云数据集上表现优异，为点云理解提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;Applying pre-trained models to assist point cloud understanding has recently become a mainstream paradigm in 3D perception. However, existing application strategies are straightforward, utilizing only the final output of the pre-trained model for various task heads. It neglects the rich complementary information in the intermediate layer, thereby failing to fully unlock the potential of pre-trained models. To overcome this limitation, we propose an orthogonal solution: Point Mamba Adapter (PMA), which constructs an ordered feature sequence from all layers of the pre-trained model and leverages Mamba to fuse all complementary semantics, thereby promoting comprehensive point cloud understanding. Constructing this ordered sequence is non-trivial due to the inherent isotropy of 3D space. Therefore, we further propose a geometry-constrained gate prompt generator (G2PG) shared across different layers, which applies shared geometric constraints to the output gates of the Mamba and dynamically optimizes the spatial order, thus enabling more effective integration of multi-layer information. Extensive experiments conducted on challenging point cloud datasets across various tasks demonstrate that our PMA elevates the capability for point cloud understanding to a new level by fusing diverse complementary intermediate features. Code is available at https://github.com/zyh16143998882/PMA.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Applying pre-trained models to assist point cloud understanding has recentlybecome a mainstream paradigm in 3D perception. However, existing applicationstrategies are straightforward, utilizing only the final output of thepre-trained model for various task heads. It neglects the rich complementaryinformation in the intermediate layer, thereby failing to fully unlock thepotential of pre-trained models. To overcome this limitation, we propose anorthogonal solution: Point Mamba Adapter (PMA), which constructs an orderedfeature sequence from all layers of the pre-trained model and leverages Mambato fuse all complementary semantics, thereby promoting comprehensive pointcloud understanding. Constructing this ordered sequence is non-trivial due tothe inherent isotropy of 3D space. Therefore, we further propose ageometry-constrained gate prompt generator (G2PG) shared across differentlayers, which applies shared geometric constraints to the output gates of theMamba and dynamically optimizes the spatial order, thus enabling more effectiveintegration of multi-layer information. Extensive experiments conducted onchallenging point cloud datasets across various tasks demonstrate that our PMAelevates the capability for point cloud understanding to a new level by fusingdiverse complementary intermediate features. Code is available athttps://github.com/zyh16143998882/PMA.</description>
      <author>example@mail.com (Yaohua Zha, Yanzi Wang, Hang Guo, Jinpeng Wang, Tao Dai, Bin Chen, Zhihao Ouyang, Xue Yuerong, Ke Chen, Shu-Tao Xia)</author>
      <guid isPermaLink="false">2505.20941v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>VLM-3R: Vision-Language Models Augmented with Instruction-Aligned 3D Reconstruction</title>
      <link>http://arxiv.org/abs/2505.20279v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为VLM-3R的统一框架，用于视觉-语言模型，通过3D重建指令微调来处理单目视频帧，实现了对3D场景的理解，并在时间和准确性上表现出色。&lt;h4&gt;背景&lt;/h4&gt;大模态模型（LMMs）在2D图像和视频上的快速进步，促使人们将这些模型扩展到理解3D场景，以期达到类似人类的视觉-空间智能。然而，实现与人类能力相当的空间理解在模型编码和数据获取方面带来了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在解决模型编码和数据获取的挑战，开发出能够有效理解3D场景的模型，并实现单目视频输入和时间敏感应用的扩展。&lt;h4&gt;方法&lt;/h4&gt;提出了VLM-3R框架，该框架通过几何编码器推导出隐式的3D令牌来表示空间理解，利用空间-视觉-视图融合和超过200K个精心挑选的3D重建指令问答对来对齐现实世界的空间环境与语言指令。&lt;h4&gt;主要发现&lt;/h4&gt;VLM-3R模型不仅促进了鲁棒的视觉-空间推理，还实现了对时间3D情境变化的理解，在准确性和可扩展性方面表现优异。&lt;h4&gt;结论&lt;/h4&gt;VLM-3R在视觉-空间推理和时间3D情境理解方面具有显著优势，为理解和模拟人类的视觉-空间智能提供了新的方法。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为VLM-3R的统一框架，用于视觉-语言模型，通过3D重建指令微调来处理单目视频帧，实现了对3D场景的理解，并在时间和准确性上表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of Large Multimodal Models (LMMs) for 2D images andvideos has motivated extending these models to understand 3D scenes, aiming forhuman-like visual-spatial intelligence. Nevertheless, achieving deep spatialunderstanding comparable to human capabilities poses significant challenges inmodel encoding and data acquisition. Existing methods frequently depend onexternal depth sensors for geometry capture or utilize off-the-shelf algorithmsfor pre-constructing 3D maps, thereby limiting their scalability, especiallywith prevalent monocular video inputs and for time-sensitive applications. Inthis work, we introduce VLM-3R, a unified framework for Vision-Language Models(VLMs) that incorporates 3D Reconstructive instruction tuning. VLM-3R processesmonocular video frames by employing a geometry encoder to derive implicit 3Dtokens that represent spatial understanding. Leveraging our Spatial-Visual-ViewFusion and over 200K curated 3D reconstructive instruction tuningquestion-answer (QA) pairs, VLM-3R effectively aligns real-world spatialcontext with language instructions. This enables monocular 3D spatialassistance and embodied reasoning. To facilitate the evaluation of temporalreasoning, we introduce the Vision-Spatial-Temporal Intelligence benchmark,featuring over 138.6K QA pairs across five distinct tasks focused on evolvingspatial relationships. Extensive experiments demonstrate that our model,VLM-3R, not only facilitates robust visual-spatial reasoning but also enablesthe understanding of temporal 3D context changes, excelling in both accuracyand scalability.</description>
      <author>example@mail.com (Zhiwen Fan, Jian Zhang, Renjie Li, Junge Zhang, Runjin Chen, Hezhen Hu, Kevin Wang, Huaizhi Qu, Dilin Wang, Zhicheng Yan, Hongyu Xu, Justin Theiss, Tianlong Chen, Jiachen Li, Zhengzhong Tu, Zhangyang Wang, Rakesh Ranjan)</author>
      <guid isPermaLink="false">2505.20279v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Advancing high-fidelity 3D and Texture Generation with 2.5D latents</title>
      <link>http://arxiv.org/abs/2505.21050v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于联合生成3D几何和纹理，以解决现有方法中几何和纹理生成不协调的问题。&lt;h4&gt;背景&lt;/h4&gt;尽管存在大规模3D数据集和3D生成模型的发展，但3D几何和纹理数据的复杂性和不均匀质量仍然阻碍了3D生成技术的性能。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一种新的框架，用于联合生成3D几何和纹理。&lt;h4&gt;方法&lt;/h4&gt;该方法首先将多视图RGB、法线和坐标图像整合到一个统一表示中，称为2.5D潜变量。然后，适应预训练的2D基础模型进行高保真2.5D生成，利用文本和图像条件。最后，引入了一个轻量级的2.5D到3D的refiner-decoder框架，从2.5D图像中高效地生成详细的3D表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该模型不仅能够从文本和图像输入中生成具有连贯结构和颜色的高质量3D对象，而且在几何条件纹理生成方面显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法在3D几何和纹理联合生成方面取得了显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the availability of large-scale 3D datasets and advancements in 3Dgenerative models, the complexity and uneven quality of 3D geometry and texturedata continue to hinder the performance of 3D generation techniques. In mostexisting approaches, 3D geometry and texture are generated in separate stagesusing different models and non-unified representations, frequently leading tounsatisfactory coherence between geometry and texture. To address thesechallenges, we propose a novel framework for joint generation of 3D geometryand texture. Specifically, we focus in generate a versatile 2.5Drepresentations that can be seamlessly transformed between 2D and 3D. Ourapproach begins by integrating multiview RGB, normal, and coordinate imagesinto a unified representation, termed as 2.5D latents. Next, we adaptpre-trained 2D foundation models for high-fidelity 2.5D generation, utilizingboth text and image conditions. Finally, we introduce a lightweight 2.5D-to-3Drefiner-decoder framework that efficiently generates detailed 3Drepresentations from 2.5D images. Extensive experiments demonstrate that ourmodel not only excels in generating high-quality 3D objects with coherentstructure and color from text and image inputs but also significantlyoutperforms existing methods in geometry-conditioned texture generation.</description>
      <author>example@mail.com (Xin Yang, Jiantao Lin, Yingjie Xu, Haodong Li, Yingcong Chen)</author>
      <guid isPermaLink="false">2505.21050v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Simple yet Effective Graph Distillation via Clustering</title>
      <link>http://arxiv.org/abs/2505.20807v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This is the technical report of the paper "Simple yet Effective Graph  Distillation via Clustering" accepted by KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ClustGDD的高效有效的图数据蒸馏方法，用于优化图神经网络（GNN）的训练。&lt;h4&gt;背景&lt;/h4&gt;尽管图表示学习在多个领域取得了成功，但训练大规模图上的GNN仍然具有巨大的计算开销。&lt;h4&gt;目的&lt;/h4&gt;通过将大型图蒸馏为紧凑且信息丰富的图，以实现高效的GNN训练。&lt;h4&gt;方法&lt;/h4&gt;ClustGDD通过快速且理论基础的聚类合成压缩图和节点属性，最小化簇内平方和，最大化原始图上的同质性。此外，通过类感知图采样和一致性损失对压缩图的节点属性进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;ClustGDD在五个基准数据集上的节点分类任务中，其性能与最先进的GDD方法相当甚至更优，同时速度提升了数个数量级。&lt;h4&gt;结论&lt;/h4&gt;ClustGDD是一种高效且有效的图数据蒸馏方法，可以显著提高GNN的训练效率。&lt;h4&gt;翻译&lt;/h4&gt;尽管在各个领域图表示学习取得了众多成功，但由于在实际中需要处理大规模图，图神经网络（GNN）的训练仍然面临着巨大的计算开销。最近，图数据蒸馏（GDD）作为一种将大型图蒸馏为紧凑且信息丰富的图的策略，已被证明是提高GNN训练效率的有前景的技术。然而，大多数现有的GDD工作依赖于启发式方法，这些方法在压缩图和原始图上对齐模型梯度或表示分布，导致结果质量下降、蒸馏大型图的训练成本高昂，或者两者兼而有之。受此启发，本文提出了一种高效有效的GDD方法，名为ClustGDD。在内部，ClustGDD通过快速且理论基础的聚类合成压缩图和节点属性，最小化簇内平方和，最大化原始图上的同质性。其基本思想受到我们通过弗雷歇起始距离（一种合成图像质量指标）揭示聚类与经验压缩质量之间联系的实证和理论发现启发。此外，为了减轻基于同质性的聚类带来的不利影响，ClustGDD通过类感知图采样和一致性损失对压缩图的节点属性进行微调。我们的广泛实验表明，在ClustGDD生成的压缩图上训练的GNN在五个基准数据集上的节点分类任务中，其性能与最先进的GDD方法相当甚至更优，同时速度提高了数个数量级。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite plentiful successes achieved by graph representation learning invarious domains, the training of graph neural networks (GNNs) still remainstenaciously challenging due to the tremendous computational overhead needed forsizable graphs in practice. Recently, graph data distillation (GDD), whichseeks to distill large graphs into compact and informative ones, has emerged asa promising technique to enable efficient GNN training. However, most existingGDD works rely on heuristics that align model gradients or representationdistributions on condensed and original graphs, leading to compromised resultquality, expensive training for distilling large graphs, or both. Motivated bythis, this paper presents an efficient and effective GDD approach, ClustGDD.Under the hood, ClustGDD resorts to synthesizing the condensed graph and nodeattributes through fast and theoretically-grounded clustering that minimizesthe within-cluster sum of squares and maximizes the homophily on the originalgraph. The fundamental idea is inspired by our empirical and theoreticalfindings unveiling the connection between clustering and empirical condensationquality using Fr\'echet Inception Distance, a well-known quality metric forsynthetic images. Furthermore, to mitigate the adverse effects caused by thehomophily-based clustering, ClustGDD refines the nodal attributes of thecondensed graph with a small augmentation learned via class-aware graphsampling and consistency loss. Our extensive experiments exhibit that GNNstrained over condensed graphs output by ClustGDD consistently achieve superioror comparable performance to state-of-the-art GDD methods in terms of nodeclassification on five benchmark datasets, while being orders of magnitudefaster.</description>
      <author>example@mail.com (Yurui Lai, Taiyan Zhang, Renchi Yang)</author>
      <guid isPermaLink="false">2505.20807v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>OmniIndoor3D: Comprehensive Indoor 3D Reconstruction</title>
      <link>http://arxiv.org/abs/2505.20610v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了名为OmniIndoor3D的新框架，用于使用高斯表示进行全面的室内3D重建。&lt;h4&gt;背景&lt;/h4&gt;传统的3DGS主要用于真实感渲染，缺乏高质量全景重建所需的精确几何信息。&lt;h4&gt;目的&lt;/h4&gt;实现室内场景的准确外观、几何和全景重建。&lt;h4&gt;方法&lt;/h4&gt;OmniIndoor3D首先结合多幅RGB-D图像创建粗略的3D重建，然后用此初始化3D高斯并引导3DGS训练。通过引入轻量级MLP调整3D高斯的几何属性，以解耦外观和几何之间的优化冲突。提出了一种受全景先验指导的稠密化策略，以改善高斯原语分布并鼓励平面表面的平滑性。&lt;h4&gt;主要发现&lt;/h4&gt;OmniIndoor3D通过联合优化外观、几何和全景重建，提供了全面的3D室内场景理解，促进了精确和鲁棒的机器人导航。在多个数据集上进行了彻底的评估，OmniIndoor3D在外观、几何和全景重建方面取得了最先进的结果。&lt;h4&gt;结论&lt;/h4&gt;该研究在室内3D重建方面填补了关键差距，相关代码将在https://ucwxb.github.io/OmniIndoor3D/发布。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为OmniIndoor3D的新框架，用于使用高斯表示进行全面的室内3D重建。该框架通过结合多幅RGB-D图像创建粗略的3D重建，然后用此初始化3D高斯并引导3DGS训练，实现了室内场景的准确外观、几何和全景重建。为了解耦外观和几何之间的优化冲突，我们引入了轻量级MLP来调整3D高斯的几何属性。此外，我们提出了一种受全景先验指导的稠密化策略，以改善高斯原语分布并鼓励平面表面的平滑性。通过联合优化外观、几何和全景重建，OmniIndoor3D提供了全面的3D室内场景理解，促进了精确和鲁棒的机器人导航。在多个数据集上进行了彻底的评估，OmniIndoor3D在外观、几何和全景重建方面取得了最先进的结果。我们相信我们的工作在室内3D重建方面填补了关键差距。相关代码可在https://ucwxb.github.io/OmniIndoor3D/找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel framework for comprehensive indoor 3D reconstruction usingGaussian representations, called OmniIndoor3D. This framework enables accurateappearance, geometry, and panoptic reconstruction of diverse indoor scenescaptured by a consumer-level RGB-D camera. Since 3DGS is primarily optimizedfor photorealistic rendering, it lacks the precise geometry critical forhigh-quality panoptic reconstruction. Therefore, OmniIndoor3D first combinesmultiple RGB-D images to create a coarse 3D reconstruction, which is then usedto initialize the 3D Gaussians and guide the 3DGS training. To decouple theoptimization conflict between appearance and geometry, we introduce alightweight MLP that adjusts the geometric properties of 3D Gaussians. Theintroduced lightweight MLP serves as a low-pass filter for geometryreconstruction and significantly reduces noise in indoor scenes. To improve thedistribution of Gaussian primitives, we propose a densification strategy guidedby panoptic priors to encourage smoothness on planar surfaces. Through thejoint optimization of appearance, geometry, and panoptic reconstruction,OmniIndoor3D provides comprehensive 3D indoor scene understanding, whichfacilitates accurate and robust robotic navigation. We perform thoroughevaluations across multiple datasets, and OmniIndoor3D achievesstate-of-the-art results in appearance, geometry, and panoptic reconstruction.We believe our work bridges a critical gap in indoor 3D reconstruction. Thecode will be released at: https://ucwxb.github.io/OmniIndoor3D/</description>
      <author>example@mail.com (Xiaobao Wei, Xiaoan Zhang, Hao Wang, Qingpo Wuwu, Ming Lu, Wenzhao Zheng, Shanghang Zhang)</author>
      <guid isPermaLink="false">2505.20610v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Dynamical Data for More Efficient and Generalizable Learning: A Case Study in Disordered Elastic Networks</title>
      <link>http://arxiv.org/abs/2505.21125v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过探索动态数据在机器学习模型中的应用，提出了一种基于图神经网络的模拟器，用于高效进行系统到属性的学习和预测，特别是在数据稀缺的条件下。&lt;h4&gt;背景&lt;/h4&gt;机器学习模型通常需要大量数据集，并且难以推广到训练分布之外，这在科学和工程领域提出了重大挑战，因为这些领域通常难以生成全面的数据集，且目标往往是发现训练域之外的新解决方案。&lt;h4&gt;目的&lt;/h4&gt;本文旨在探索如何利用动态数据通过图神经网络模拟器实现高效的系统到属性学习以及分布外预测。&lt;h4&gt;方法&lt;/h4&gt;研究人员使用基于图神经网络的模拟器，通过少量的训练示例学习基础的物理动力学，并准确复制未见过的网络的时空演变。&lt;h4&gt;主要发现&lt;/h4&gt;模拟器能够从少量训练示例中学习基础的物理动力学，并准确复制未见过的网络的时空演变。此外，模拟器能够准确预测诸如泊松比及其与应变的关系等涌现属性，即使它没有明确训练这一任务。它还能很好地推广到系统温度、应变幅度以及超出训练范围的泊松比的变化。&lt;h4&gt;结论&lt;/h4&gt;这些发现表明，使用动态数据来训练机器学习模型可以支持更高效和可推广的材料和分子设计方法，尤其是在数据稀缺的环境下。&lt;h4&gt;翻译&lt;/h4&gt;This paper explores the use of dynamic data in machine learning models by proposing a graph neural network-based simulator to enable efficient system-to-property learning and out-of-distribution prediction, especially in data-scarce settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning models often require large datasets and struggle togeneralize beyond their training distribution. These limitations posesignificant challenges in scientific and engineering contexts, where generatingexhaustive datasets is often impractical and the goal is frequently to discovernovel solutions outside the training domain. In this work, we explore the useof dynamical data through a graph neural network-based simulator to enableefficient system-to-property learning and out-of-distribution prediction in thecontext of uniaxial compression of two-dimensional disordered elastic networks.We find that the simulator can learn the underlying physical dynamics from asmall number of training examples and accurately reproduce the temporalevolution of unseen networks. Notably, the simulator is able to accuratelypredict emergent properties such as the Poisson's ratio and its dependence onstrain, even though it was not explicitly trained for this task. In addition,it generalizes well across variations in system temperature, strain amplitude,and most significantly, Poisson's ratios beyond the training range. Thesefindings suggest that using dynamical data to train machine learning models cansupport more data efficient and generalizable approaches for materials andmolecular design, especially in data-scarce settings.</description>
      <author>example@mail.com (Salman N. Salman, Sergey A. Shteingolts, Ron Levie, Dan Mendels)</author>
      <guid isPermaLink="false">2505.21125v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Intelligent Incident Hypertension Prediction in Obstructive Sleep Apnea</title>
      <link>http://arxiv.org/abs/2505.20615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at EUSIPCO 2025. Camera-ready due June 20, 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于深度学习的方法，通过整合DCT-based迁移学习来提高高血压预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;阻塞性睡眠呼吸暂停（OSA）是高血压的重要风险因素，主要是因为间歇性缺氧和睡眠碎片化。&lt;h4&gt;目的&lt;/h4&gt;预测患有OSA的个人在五年内是否会发展为高血压，这是一个复杂的挑战。&lt;h4&gt;方法&lt;/h4&gt;研究引入了一种新的深度学习方法，该方法结合了基于DCT的迁移学习来增强预测准确性。研究首次将所有多导睡眠图信号结合在一起用于高血压预测，利用其集体信息来提高模型性能。从这些信号中提取特征，并将其转换为二维表示，以利用预训练的二维神经网络，如MobileNet、EfficientNet和ResNet变体。为了进一步提高特征学习，引入了一个DCT层，该层将输入特征转换为基于频率的表示，保留关键频谱信息，解耦特征，并增强对噪声的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;通过在EfficientNet中策略性地放置DCT层，模型实现了最佳曲线下面积（AUC）为72.88%，证明了频率域特征提取和迁移学习在预测OSA患者五年内高血压风险方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了频率域特征提取和迁移学习在预测OSA患者高血压风险方面的有效性，尤其是在有限的医疗数据集上。&lt;h4&gt;翻译&lt;/h4&gt;摘要：阻塞性睡眠呼吸暂停（OSA）是高血压的一个重要风险因素，主要是由于间歇性缺氧和睡眠碎片化。预测患有OSA的个人在五年内是否会发展为高血压仍然是一个复杂的挑战。本研究引入了一种新的深度学习方法，该方法整合了基于DCT的迁移学习以增强预测准确性。我们是第一个将所有多导睡眠图信号结合在一起用于高血压预测的研究，利用它们的集体信息来提高模型性能。从这些信号中提取特征，并将其转换为二维表示，以利用预训练的二维神经网络，如MobileNet、EfficientNet和ResNet变体。为了进一步提高特征学习，我们引入了一个DCT层，该层将输入特征转换为基于频率的表示，保留关键频谱信息，解耦特征，并增强对噪声的鲁棒性。这种频率域方法与迁移学习相结合，特别有利于有限的医疗数据集，因为它利用了预训练网络的丰富表示来提高泛化能力。通过在EfficientNet中策略性地放置DCT层，我们的模型实现了最佳曲线下面积（AUC）为72.88%，证明了频率域特征提取和迁移学习在预测OSA患者五年内高血压风险方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Obstructive sleep apnea (OSA) is a significant risk factor for hypertension,primarily due to intermittent hypoxia and sleep fragmentation. Predictingwhether individuals with OSA will develop hypertension within five yearsremains a complex challenge. This study introduces a novel deep learningapproach that integrates Discrete Cosine Transform (DCT)-based transferlearning to enhance prediction accuracy. We are the first to incorporate allpolysomnography signals together for hypertension prediction, leveraging theircollective information to improve model performance. Features were extractedfrom these signals and transformed into a 2D representation to utilizepre-trained 2D neural networks such as MobileNet, EfficientNet, and ResNetvariants. To further improve feature learning, we introduced a DCT layer, whichtransforms input features into a frequency-based representation, preservingessential spectral information, decorrelating features, and enhancingrobustness to noise. This frequency-domain approach, coupled with transferlearning, is especially beneficial for limited medical datasets, as itleverages rich representations from pre-trained networks to improvegeneralization. By strategically placing the DCT layer at deeper truncationdepths within EfficientNet, our model achieved a best area under the curve(AUC) of 72.88%, demonstrating the effectiveness of frequency-domain featureextraction and transfer learning in predicting hypertension risk in OSApatients over a five-year period.</description>
      <author>example@mail.com (Omid Halimi Milani, Ahmet Enis Cetin, Bharati Prasad)</author>
      <guid isPermaLink="false">2505.20615v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Towards Conversational Development Environments: Using Theory-of-Mind and Multi-Agent Architectures for Requirements Refinement</title>
      <link>http://arxiv.org/abs/2505.20973v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种利用Foundation Models（FMs）的多智能体系统AlignMind的新方法，旨在解决FMs在软件开发中准确捕捉利益相关者需求的问题。&lt;h4&gt;背景&lt;/h4&gt;尽管FMs在自然语言任务中表现出色，但它们在准确捕捉利益相关者需求方面仍面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出的方法旨在通过增强FMs的“心灵理论”能力，考虑软件开发者的心理状态和视角，从而迭代地澄清利益相关者的信念、欲望和意图。&lt;h4&gt;方法&lt;/h4&gt;该方法在软件工程的初步需求收集阶段之后，通过细化需求，将利益相关者的需求转化为一系列精炼的需求和相应的自然语言工作流程。&lt;h4&gt;主要发现&lt;/h4&gt;通过涵盖150个不同用例的多方面评估，证明了该方法可以准确地捕捉利益相关者的意图和需求，并以规范和行动步骤的形式表达出来。&lt;h4&gt;结论&lt;/h4&gt;研究发现，在软件开发过程中有显著改进的潜力，这证明了这些投资的合理性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于Foundation Models（FMs）的AlignMind多智能体系统的新方法，旨在解决FMs在软件开发中准确捕捉利益相关者需求的问题。尽管FMs在自然语言任务中表现出色，但它们在准确捕捉利益相关者需求方面仍面临重大挑战。本文提出的方法旨在通过增强FMs的“心灵理论”能力，考虑软件开发者的心理状态和视角，从而迭代地澄清利益相关者的信念、欲望和意图。该方法在软件工程的初步需求收集阶段之后，通过细化需求，将利益相关者的需求转化为一系列精炼的需求和相应的自然语言工作流程。通过涵盖150个不同用例的多方面评估，证明了该方法可以准确地捕捉利益相关者的意图和需求，并以规范和行动步骤的形式表达出来。研究发现，在软件开发过程中有显著改进的潜力，这证明了这些投资的合理性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation Models (FMs) have shown remarkable capabilities in various naturallanguage tasks. However, their ability to accurately capture stakeholderrequirements remains a significant challenge for using FMs for softwaredevelopment. This paper introduces a novel approach that leverages anFM-powered multi-agent system called AlignMind to address this issue. By havinga cognitive architecture that enhances FMs with Theory-of-Mind capabilities,our approach considers the mental states and perspectives of software makers.This allows our solution to iteratively clarify the beliefs, desires, andintentions of stakeholders, translating these into a set of refinedrequirements and a corresponding actionable natural language workflow in theoften-overlooked requirements refinement phase of software engineering, whichis crucial after initial elicitation. Through a multifaceted evaluationcovering 150 diverse use cases, we demonstrate that our approach can accuratelycapture the intents and requirements of stakeholders, articulating them as bothspecifications and a step-by-step plan of action. Our findings suggest that thepotential for significant improvements in the software development processjustifies these investments. Our work lays the groundwork for future innovationin building intent-first development environments, where software makers canseamlessly collaborate with AIs to create software that truly meets theirneeds.</description>
      <author>example@mail.com (Keheliya Gallaba, Ali Arabat, Dayi Lin, Mohammed Sayagh, Ahmed E. Hassan)</author>
      <guid isPermaLink="false">2505.20973v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness</title>
      <link>http://arxiv.org/abs/2505.20426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了MMPerspective，这是一个用于评估多模态大型语言模型对透视理解的基准，通过一系列精心设计的任务来评估模型的透视感知、推理和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;理解透视是人类视觉感知的基础，但多模态大型语言模型（MLLMs）在内部化透视几何方面的程度尚不清楚。&lt;h4&gt;目的&lt;/h4&gt;MMPerspective旨在系统地评估MLLMs对透视的理解。&lt;h4&gt;方法&lt;/h4&gt;MMPerspective包含10个精心设计的任务，覆盖透视感知、推理和鲁棒性三个互补维度，共有2,711个真实和合成图像实例以及5,083个问题-答案对，用于测试关键能力，如消失点感知、计数、透视类型推理、三维空间中的线关系理解等。&lt;h4&gt;主要发现&lt;/h4&gt;通过对43个最先进的MLLMs进行综合评估，发现模型在表面层感知任务上表现出色，但在组合推理和保持空间一致性方面存在困难。&lt;h4&gt;结论&lt;/h4&gt;MMPerspective为诊断和推进视觉语言系统中的空间理解提供了一个有价值的测试平台。&lt;h4&gt;翻译&lt;/h4&gt;摘要：理解透视是人类视觉感知的基础，然而多模态大型语言模型（MLLMs）对透视几何的内部化程度尚不明确。我们介绍了MMPerspective，这是第一个专门设计来系统地评估MLLMs对透视理解的基准，它通过10个精心设计的任务，涵盖三个互补维度：透视感知、推理和鲁棒性。我们的基准包括2,711个真实和合成图像实例，以及5,083个问题-答案对，用于探测关键能力，如消失点感知和计数、透视类型推理、三维空间中的线关系理解等。通过综合评估43个最先进的MLLMs，我们发现了一些显著的局限性：虽然模型在表面层感知任务上表现出色，但它们在组合推理和扰动下的空间一致性维护方面存在困难。我们的分析进一步揭示了模型架构、规模和透视能力之间的有趣模式，突出了鲁棒性瓶颈和思维链提示的好处。MMPerspective为诊断和推进视觉语言系统中的空间理解提供了一个有价值的测试平台。资源可在https://yunlong10.github.io/MMPerspective/获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/yunlong10/MMPerspective&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding perspective is fundamental to human visual perception, yet theextent to which multimodal large language models (MLLMs) internalizeperspective geometry remains unclear. We introduce MMPerspective, the firstbenchmark specifically designed to systematically evaluate MLLMs' understandingof perspective through 10 carefully crafted tasks across three complementarydimensions: Perspective Perception, Reasoning, and Robustness. Our benchmarkcomprises 2,711 real-world and synthetic image instances with 5,083question-answer pairs that probe key capabilities, such as vanishing pointperception and counting, perspective type reasoning, line relationshipunderstanding in 3D space, invariance to perspective-preservingtransformations, etc. Through a comprehensive evaluation of 43 state-of-the-artMLLMs, we uncover significant limitations: while models demonstrate competenceon surface-level perceptual tasks, they struggle with compositional reasoningand maintaining spatial consistency under perturbations. Our analysis furtherreveals intriguing patterns between model architecture, scale, and perspectivecapabilities, highlighting both robustness bottlenecks and the benefits ofchain-of-thought prompting. MMPerspective establishes a valuable testbed fordiagnosing and advancing spatial understanding in vision-language systems.Resources available at: https://yunlong10.github.io/MMPerspective/</description>
      <author>example@mail.com (Yunlong Tang, Pinxin Liu, Mingqian Feng, Zhangyun Tan, Rui Mao, Chao Huang, Jing Bi, Yunzhong Xiao, Susan Liang, Hang Hua, Ali Vosoughi, Luchuan Song, Zeliang Zhang, Chenliang Xu)</author>
      <guid isPermaLink="false">2505.20426v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>ReassembleNet: Learnable Keypoints and Diffusion for 2D Fresco Reconstruction</title>
      <link>http://arxiv.org/abs/2505.21117v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ReassembleNet的重新组装方法，用于解决多个领域（如考古学、基因组学和分子对接）中的重组难题。该方法通过表示输入部件为轮廓关键点，并利用图神经网络池化技术来选择最具信息量的关键点，有效地降低了计算复杂度，同时能够集成多种模态的特征，包括几何和纹理数据。&lt;h4&gt;背景&lt;/h4&gt;重组任务在多个领域都是一项重大挑战，需要精确放置和定位元素来重建原始结构。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决现有深度学习方法的三个关键局限性：可扩展性、多模态性和现实世界的适用性。&lt;h4&gt;方法&lt;/h4&gt;ReassembleNet通过使用轮廓关键点表示输入部件，并应用图神经网络池化技术选择关键点。该方法在半合成数据集上进行预训练，并通过基于扩散的姿势估计来恢复原始结构。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，ReassembleNet在RMSE旋转和平移方面分别提高了55%和86%。&lt;h4&gt;结论&lt;/h4&gt;ReassembleNet是一种有效的重组方法，能够解决多个领域中的重组难题，并通过改进现有方法显著提高了性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：重组任务在多个领域（如考古学、基因组学和分子对接）中是一项重大挑战，需要精确放置和定位元素以重建原始结构。在本文中，我们针对最先进深度学习重组方法的三个关键局限性进行了处理，即：可扩展性、多模态性和现实世界的适用性：不仅限于方形或简单几何形状，还包括现实世界的复杂侵蚀或其他问题。我们提出了ReassembleNet，一种通过将每个输入部件表示为一组轮廓关键点，并通过图神经网络池化技术学习选择最具信息量的关键点来降低复杂度的方法。ReassembleNet在降低计算复杂度的同时，能够集成来自多个模态的特征，包括几何和纹理数据。通过在半合成数据集上进行预训练进一步增强了其性能。然后我们应用基于扩散的姿势估计来恢复原始结构。我们在RMSE旋转和平移方面分别将先前方法提高了55%和86%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The task of reassembly is a significant challenge across multiple domains,including archaeology, genomics, and molecular docking, requiring the preciseplacement and orientation of elements to reconstruct an original structure. Inthis work, we address key limitations in state-of-the-art Deep Learning methodsfor reassembly, namely i) scalability; ii) multimodality; and iii) real-worldapplicability: beyond square or simple geometric shapes, realistic and complexerosion, or other real-world problems. We propose ReassembleNet, a method thatreduces complexity by representing each input piece as a set of contourkeypoints and learning to select the most informative ones by Graph NeuralNetworks pooling inspired techniques. ReassembleNet effectively lowerscomputational complexity while enabling the integration of features frommultiple modalities, including both geometric and texture data. Furtherenhanced through pretraining on a semi-synthetic dataset. We then applydiffusion-based pose estimation to recover the original structure. We improveon prior methods by 55% and 86% for RMSE Rotation and Translation,respectively.</description>
      <author>example@mail.com (Adeela Islam, Stefano Fiorini, Stuart James, Pietro Morerio, Alessio Del Bue)</author>
      <guid isPermaLink="false">2505.21117v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>FM-Planner: Foundation Model Guided Path Planning for Autonomous Drone Navigation</title>
      <link>http://arxiv.org/abs/2505.20783v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于基础模型（特别是大型语言模型和视觉语言模型）的路径规划器（FM-Planner），并对其在无人机路径规划中的应用进行了全面评估和实际验证。&lt;h4&gt;背景&lt;/h4&gt;路径规划是自主无人机操作的关键组成部分，而基础模型在增强感知和智能决策方面提供了新的机会，但其在全球路径规划中的实际应用和效果尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的路径规划方法，并验证其在无人机路径规划中的实用性和有效性。&lt;h4&gt;方法&lt;/h4&gt;首先，使用标准化模拟场景对八种代表性的LLM和VLM方法进行了系统评估。然后，设计了一个集成的LLM-视觉规划器，结合语义推理和视觉感知以实现实时导航。最后，通过多种配置下的实际实验验证了所提出的路径规划器。&lt;h4&gt;主要发现&lt;/h4&gt;研究提供了有关在现实世界无人机应用中部署基础模型的优点、局限性和可行性的宝贵见解。&lt;h4&gt;结论&lt;/h4&gt;FM-Planner在无人机路径规划中展现出潜力，为自主飞行提供了实用的实现。&lt;h4&gt;翻译&lt;/h4&gt;摘要：路径规划是自主无人机操作的关键组成部分，它使得无人机能够在复杂环境中安全高效地导航。近年来，基础模型（尤其是大型语言模型和视觉语言模型）的进步为机器人领域的感知和智能决策提供了新的机遇。然而，这些模型在全球路径规划中的实际应用和效果还相对未充分探索。本文提出了一种基于基础模型的路径规划器（FM-Planner），并对其在无人机路径规划中的应用进行了全面基准测试和实际验证。具体来说，我们首先系统地评估了八种代表性的LLM和VLM方法，使用标准化的模拟场景。为了实现有效的实时导航，我们接着设计了一个集成的LLM-视觉规划器，该规划器结合了语义推理和视觉感知。此外，我们还通过多种配置下的实际实验部署并验证了所提出的路径规划器。我们的发现为在现实世界无人机应用中部署基础模型的优点、局限性和可行性提供了有价值的见解。项目网站：https://github.com/NTU-ICG/FM-Planner。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Path planning is a critical component in autonomous drone operations,enabling safe and efficient navigation through complex environments. Recentadvances in foundation models, particularly large language models (LLMs) andvision-language models (VLMs), have opened new opportunities for enhancedperception and intelligent decision-making in robotics. However, theirpractical applicability and effectiveness in global path planning remainrelatively unexplored. This paper proposes foundation model-guided pathplanners (FM-Planner) and presents a comprehensive benchmarking study andpractical validation for drone path planning. Specifically, we firstsystematically evaluate eight representative LLM and VLM approaches usingstandardized simulation scenarios. To enable effective real-time navigation, wethen design an integrated LLM-Vision planner that combines semantic reasoningwith visual perception. Furthermore, we deploy and validate the proposed pathplanner through real-world experiments under multiple configurations. Ourfindings provide valuable insights into the strengths, limitations, andfeasibility of deploying foundation models in real-world drone applications andproviding practical implementations in autonomous flight. Project site:https://github.com/NTU-ICG/FM-Planner.</description>
      <author>example@mail.com (Jiaping Xiao, Cheng Wen Tsao, Yuhang Zhang, Mir Feroskhan)</author>
      <guid isPermaLink="false">2505.20783v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Intern-GS: Vision Model Guided Sparse-View 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2505.20729v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Intern-GS的新方法，用于解决稀疏视图场景重建中的挑战，通过利用视觉基础模型中的丰富先验知识来增强稀疏视图高斯分层过程，从而实现高质量的场景重建。&lt;h4&gt;背景&lt;/h4&gt;稀疏视图场景重建因观测数据有限而面临重大挑战，导致信息不完整，使用现有方法进行重建效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出Intern-GS方法，以解决稀疏视图场景重建中的信息不完整问题，实现高质量的场景重建。&lt;h4&gt;方法&lt;/h4&gt;Intern-GS方法利用视觉基础模型指导3D高斯分层的初始化和优化过程。初始化阶段使用DUSt3R生成密集且非冗余的高斯点云；优化阶段，视觉基础模型预测未观测视图的深度和外观，细化3D高斯以补偿未见区域的信息缺失。&lt;h4&gt;主要发现&lt;/h4&gt;Intern-GS在LLFF、DTU、Tanks and Temples等不同数据集上实现了最先进的渲染质量，包括面向前方的场景和大规模场景。&lt;h4&gt;结论&lt;/h4&gt;Intern-GS方法有效提升了稀疏视图场景重建的质量，为该领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Sparse-view scene reconstruction often faces significant challenges due to the constraints imposed by limited observational data. These limitations result in incomplete information, leading to suboptimal reconstructions using existing methodologies. To address this, we present Intern-GS, a novel approach that effectively leverages rich prior knowledge from vision foundation models to enhance the process of sparse-view Gaussian Splatting, thereby enabling high-quality scene reconstruction. Specifically, Intern-GS utilizes vision foundation models to guide both the initialization and the optimization process of 3D Gaussian splatting, effectively addressing the limitations of sparse inputs. In the initialization process, our method employs DUSt3R to generate a dense and non-redundant gaussian point cloud. This approach significantly alleviates the limitations encountered by traditional structure-from-motion (SfM) methods, which often struggle under sparse-view constraints. During the optimization process, vision foundation models predict depth and appearance for unobserved views, refining the 3D Gaussians to compensate for missing information in unseen regions. Extensive experiments demonstrate that Intern-GS achieves state-of-the-art rendering quality across diverse datasets, including both forward-facing and large-scale scenes, such as LLFF, DTU, and Tanks and Temples.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sparse-view scene reconstruction often faces significant challenges due tothe constraints imposed by limited observational data. These limitations resultin incomplete information, leading to suboptimal reconstructions using existingmethodologies. To address this, we present Intern-GS, a novel approach thateffectively leverages rich prior knowledge from vision foundation models toenhance the process of sparse-view Gaussian Splatting, thereby enablinghigh-quality scene reconstruction. Specifically, Intern-GS utilizes visionfoundation models to guide both the initialization and the optimization processof 3D Gaussian splatting, effectively addressing the limitations of sparseinputs. In the initialization process, our method employs DUSt3R to generate adense and non-redundant gaussian point cloud. This approach significantlyalleviates the limitations encountered by traditional structure-from-motion(SfM) methods, which often struggle under sparse-view constraints. During theoptimization process, vision foundation models predict depth and appearance forunobserved views, refining the 3D Gaussians to compensate for missinginformation in unseen regions. Extensive experiments demonstrate that Intern-GSachieves state-of-the-art rendering quality across diverse datasets, includingboth forward-facing and large-scale scenes, such as LLFF, DTU, and Tanks andTemples.</description>
      <author>example@mail.com (Xiangyu Sun, Runnan Chen, Mingming Gong, Dong Xu, Tongliang Liu)</author>
      <guid isPermaLink="false">2505.20729v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>NeuralOM: Neural Ocean Model for Subseasonal-to-Seasonal Simulation</title>
      <link>http://arxiv.org/abs/2505.21020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多尺度交互图神经网络的神经网络海洋模型（NeuralOM），用于进行季节到季节的海洋模拟，以解决传统方法在模拟精度和计算效率方面的不足。&lt;h4&gt;背景&lt;/h4&gt;季节到季节的海洋模拟对于海洋研究至关重要，但由于海洋系统的巨大热惯性和长时间延迟，这一任务仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提高季节到季节海洋模拟的精度和计算效率，同时确保物理一致性和海洋系统的缓慢变化特性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种多阶段框架，以模拟海洋的缓慢变化特性，并引入了一个多尺度交互消息模块来捕捉海洋动力学中的复杂动态行为，如梯度变化和乘性耦合关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估表明，所提出的NeuralOM在季节到季节和极端事件模拟方面优于现有模型。&lt;h4&gt;结论&lt;/h4&gt;NeuralOM模型在季节到季节海洋模拟中具有显著优势，并可通过GitHub链接获取相关代码。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a neural ocean model (NeuralOM) based on a multi-scale interactive graph neural network for subseasonal-to-seasonal (S2S) ocean simulation, aiming to improve the accuracy and computational efficiency of traditional methods while ensuring physical consistency and the slow-changing properties of the ocean system. The proposed multi-stage framework is tailored to model the slowly changing nature of the ocean, and a multi-scale interactive messaging module is introduced to capture complex dynamical behaviors inherent in ocean dynamics. Extensive experimental evaluations confirm that the proposed NeuralOM outperforms state-of-the-art models in S2S and extreme event simulation. The codes are available at https://github.com/YuanGao-YG/NeuralOM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate Subseasonal-to-Seasonal (S2S) ocean simulation is criticallyimportant for marine research, yet remains challenging due to its substantialthermal inertia and extended time delay. Machine learning (ML)-based modelshave demonstrated significant advancements in simulation accuracy andcomputational efficiency compared to traditional numerical methods.Nevertheless, a significant limitation of current ML models for S2S oceansimulation is their inadequate incorporation of physical consistency and theslow-changing properties of the ocean system. In this work, we propose a neuralocean model (NeuralOM) for S2S ocean simulation with a multi-scale interactivegraph neural network to emulate diverse physical phenomena associated withocean systems effectively. Specifically, we propose a multi-stage frameworktailored to model the ocean's slowly changing nature. Additionally, weintroduce a multi-scale interactive messaging module to capture complexdynamical behaviors, such as gradient changes and multiplicative couplingrelationships inherent in ocean dynamics. Extensive experimental evaluationsconfirm that our proposed NeuralOM outperforms state-of-the-art models in S2Sand extreme event simulation. The codes are available athttps://github.com/YuanGao-YG/NeuralOM.</description>
      <author>example@mail.com (Yuan Gao, Ruiqi Shu, Hao Wu, Fan Xu, Yanfei Xiang, Ruijian Gou, Qingsong Wen, Xian Wu, Xiaomeng Huang)</author>
      <guid isPermaLink="false">2505.21020v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model Hidden Representations for Heart Rate Estimation from Auscultation</title>
      <link>http://arxiv.org/abs/2505.20745v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, Interspeech 2025 conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在自我监督声学表示基础模型（FMs）中，听诊信息，尤其是心音，如何被编码。通过使用公开的听诊图（PCG）数据集和心率（HR）估计模型，对六个声学表示FMs进行了层间调查，并展示了这些模型在心率估计方面的性能。&lt;h4&gt;背景&lt;/h4&gt;听诊是一种非侵入性的技术，可以提供基本的生命体征信息。最近，提出了基于声学的生命体征的自我监督声学表示基础模型（FMs）。然而，对这些预训练FM表示中听诊编码程度的研究还很少。&lt;h4&gt;目的&lt;/h4&gt;探究在自我监督声学表示基础模型中听诊信息，特别是心音，如何被编码。&lt;h4&gt;方法&lt;/h4&gt;使用公开的PCG数据集和HR估计模型，对六个声学表示FMs进行了层间调查，并实现了Nie等人在2024年的基线方法，该基线方法依赖于声学特征。&lt;h4&gt;主要发现&lt;/h4&gt;发现从预训练的基础模型（FMs）中得到的表示向量与基线方法具有可比的性能。特别是，使用内部CLAP模型的音频编码器进行的心率估计超过了基线结果，在多个训练/验证/测试分割中实现了更低的平均绝对误差（MAE），尽管存在领域不匹配。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，预训练的基础模型在心率估计方面具有潜力，并且内部CLAP模型的音频编码器在特定情况下表现优于基线方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：听诊，尤其是心音，是一种提供基本生命体征信息的非侵入性技术。最近，提出了基于声学的生命体征的自我监督声学表示基础模型（FMs）。然而，对这些预训练FM表示中听诊编码程度的研究还很少。在本研究中，使用公开的听诊图（PCG）数据集和心率（HR）估计模型，我们对六个声学表示FMs进行了层间调查：HuBERT、wav2vec2、wavLM、Whisper、对比语言音频预训练（CLAP）和内部CLAP模型。此外，我们实现了Nie等人在2024年的基线方法（依赖于声学特征），并表明总体而言，预训练基础模型的表示向量与基线方法具有可比的性能。值得注意的是，使用内部CLAP模型的音频编码器进行的心率估计优于基线结果，尽管存在领域不匹配，但在多个训练/验证/测试分割中实现了更低的平均绝对误差（MAE）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Auscultation, particularly heart sound, is a non-invasive technique thatprovides essential vital sign information. Recently, self-supervised acousticrepresentation foundation models (FMs) have been proposed to offer insightsinto acoustics-based vital signs. However, there has been little exploration ofthe extent to which auscultation is encoded in these pre-trained FMrepresentations. In this work, using a publicly available phonocardiogram (PCG)dataset and a heart rate (HR) estimation model, we conduct a layer-wiseinvestigation of six acoustic representation FMs: HuBERT, wav2vec2, wavLM,Whisper, Contrastive Language-Audio Pretraining (CLAP), and an in-house CLAPmodel. Additionally, we implement the baseline method from Nie et al., 2024(which relies on acoustic features) and show that overall, representationvectors from pre-trained foundation models (FMs) offer comparable performanceto the baseline. Notably, HR estimation using the representations from theaudio encoder of the in-house CLAP model outperforms the results obtained fromthe baseline, achieving a lower mean absolute error (MAE) across varioustrain/validation/test splits despite the domain mismatch.</description>
      <author>example@mail.com (Jingping Nie, Dung T. Tran, Karan Thakkar, Vasudha Kowtha, John Huang, Carlos Avendano, Erdrin Azemi, Vikramjit Mitra)</author>
      <guid isPermaLink="false">2505.20745v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Identity and Position Graph Embedding via Spectral-Based Random Feature Aggregation</title>
      <link>http://arxiv.org/abs/2505.20992v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACM SIGKDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于随机特征聚合（RFA）的方法，用于高效地实现节点身份和位置的嵌入，并在图神经网络（GNN）特征聚合方面进行了深入研究。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）通过特征聚合机制捕获图结构，表现出强大的能力支持各种任务。然而，大多数基于GNN的方法在效率和可扩展性方面存在问题，且不明确能捕获哪些拓扑属性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过随机特征聚合（RFA）来提高节点身份和位置嵌入的效率。&lt;h4&gt;方法&lt;/h4&gt;RFA方法采用基于谱的GNN作为其核心，仅使用随机噪声作为输入，并通过单次前向传播（FFP）推导出嵌入。此外，引入了基于度校正的谱聚类机制，对GNN核心进行度校正。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，RFA方法可以通过单次FFP分别推导出具有高、低通滤波器的两种变体，从而实现信息丰富的身份和位置嵌入，无需任何训练。&lt;h4&gt;结论&lt;/h4&gt;RFA方法在身份和位置嵌入方面实现了质量与效率之间的良好平衡，优于各种基线方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a new method, Random Feature Aggregation (RFA), for efficient node identity and position embedding, and conducts in-depth research on GNN feature aggregation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs), which capture graph structures via a featureaggregation mechanism following the graph embedding framework, havedemonstrated a powerful ability to support various tasks. According to thetopology properties (e.g., structural roles or community memberships of nodes)to be preserved, graph embedding can be categorized into identity and positionembedding. However, it is unclear for most GNN-based methods which propertythey can capture. Some of them may also suffer from low efficiency andscalability caused by several time- and space-consuming procedures (e.g.,feature extraction and training). From a perspective of graph signalprocessing, we find that high- and low-frequency information in the graphspectral domain may characterize node identities and positions, respectively.Based on this investigation, we propose random feature aggregation (RFA) forefficient identity and position embedding, serving as an extreme ablation studyregarding GNN feature aggregation. RFA (i) adopts a spectral-based GNN withoutlearnable parameters as its backbone, (ii) only uses random noises as inputs,and (iii) derives embeddings via just one feed-forward propagation (FFP).Inspired by degree-corrected spectral clustering, we further introduce a degreecorrection mechanism to the GNN backbone. Surprisingly, our experimentsdemonstrate that two variants of RFA with high- and low-pass filters canrespectively derive informative identity and position embeddings via just oneFFP (i.e., without any training). As a result, RFA can achieve a bettertrade-off between quality and efficiency for both identity and positionembedding over various baselines.</description>
      <author>example@mail.com (Meng Qin, Jiahong Liu, Irwin King)</author>
      <guid isPermaLink="false">2505.20992v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>REWIND: Speech Time Reversal for Enhancing Speaker Representations in Diffusion-based Voice Conversion</title>
      <link>http://arxiv.org/abs/2505.20756v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in INTERSPEECH 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用时间反转语音中学习到的说话人表示来增强说话人表示的方法，并评估了其在最新的基于扩散模型的语音转换（VC）模型中的有效性。&lt;h4&gt;背景&lt;/h4&gt;时间反转语音信号虽然无法理解，但保留了音调模式，可用于说话人识别。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，利用时间反转语音学习说话人表示，以增强说话人表示，并评估其在语音转换中的应用。&lt;h4&gt;方法&lt;/h4&gt;利用时间反转语音学习说话人表示，并将其作为增强策略应用于语音转换模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在提高说话人相似度相关评分的同时，保持了高语音质量。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效提高说话人相似度评分，且不影响语音质量。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语音时间反转是指整个语音信号在时间上的反转，使其播放时为倒放。这类信号由于音素和音节的根本结构被破坏，因此完全无法理解。然而，它们仍然保留了音调模式，尽管失去了语言内容，仍能进行感知说话人识别。在本文中，我们提出利用从时间反转语音中学习到的说话人表示作为一种增强策略来增强说话人表示。值得注意的是，在语音转换（VC）中，说话人和语言的解耦对于准确保留说话人的独特声音特征同时最小化语言内容干扰是至关重要的。该方法的有效性在最新的基于扩散的VC模型背景下进行了评估。实验结果表明，所提出的方法在显著提高说话人相似度相关评分的同时，保持了高语音质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech time reversal refers to the process of reversing the entire speechsignal in time, causing it to play backward. Such signals are completelyunintelligible since the fundamental structures of phonemes and syllables aredestroyed. However, they still retain tonal patterns that enable perceptualspeaker identification despite losing linguistic content. In this paper, wepropose leveraging speaker representations learned from time reversed speech asan augmentation strategy to enhance speaker representation. Notably, speakerand language disentanglement in voice conversion (VC) is essential toaccurately preserve a speaker's unique vocal traits while minimizinginterference from linguistic content. The effectiveness of the proposedapproach is evaluated in the context of state-of-the-art diffusion-based VCmodels. Experimental results indicate that the proposed approach significantlyimproves speaker similarity-related scores while maintaining high speechquality.</description>
      <author>example@mail.com (Ishan D. Biyani, Nirmesh J. Shah, Ashishkumar P. Gudmalwar, Pankaj Wasnik, Rajiv R. Shah)</author>
      <guid isPermaLink="false">2505.20756v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>MineAnyBuild: Benchmarking Spatial Planning for Open-world AI Agents</title>
      <link>http://arxiv.org/abs/2505.20148v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MineAnyBuild的综合基准，用于评估开放世界AI代理在Minecraft游戏中的空间规划能力。&lt;h4&gt;背景&lt;/h4&gt;空间规划在空间智能领域至关重要，需要理解和规划空间中的物体排列。具有空间规划能力的AI代理能更好地适应各种现实世界应用，如机器人操作、自动组装、城市规划等。&lt;h4&gt;目的&lt;/h4&gt;构建一个全面的基准，评估开放世界AI代理在Minecraft游戏中的空间规划能力。&lt;h4&gt;方法&lt;/h4&gt;MineAnyBuild要求代理根据给定的多模态人类指令生成可执行的架构建筑计划。它包含4,000个精心策划的空间规划任务，并利用丰富的玩家生成内容提供了一种无限可扩展的数据收集范式。&lt;h4&gt;主要发现&lt;/h4&gt;MineAnyBuild通过四个核心支持维度评估空间规划：空间理解、空间推理、创造力和空间常识。基于MineAnyBuild，对现有基于MLLM的代理进行了全面评估，揭示了它们在空间规划能力方面的严重限制和巨大潜力。&lt;h4&gt;结论&lt;/h4&gt;MineAnyBuild将为空间智能的评价开辟新的途径，并有助于推动能够进行空间规划的开世界AI代理的进一步发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial Planning is a crucial part in the field of spatial intelligence,which requires the understanding and planning about object arrangements inspace perspective. AI agents with the spatial planning ability can better adaptto various real-world applications, including robotic manipulation, automaticassembly, urban planning etc. Recent works have attempted to constructbenchmarks for evaluating the spatial intelligence of Multimodal Large LanguageModels (MLLMs). Nevertheless, these benchmarks primarily focus on spatialreasoning based on typical Visual Question-Answering (VQA) forms, which suffersfrom the gap between abstract spatial understanding and concrete taskexecution. In this work, we take a step further to build a comprehensivebenchmark called MineAnyBuild, aiming to evaluate the spatial planning abilityof open-world AI agents in the Minecraft game. Specifically, MineAnyBuildrequires an agent to generate executable architecture building plans based onthe given multi-modal human instructions. It involves 4,000 curated spatialplanning tasks and also provides a paradigm for infinitely expandable datacollection by utilizing rich player-generated content. MineAnyBuild evaluatesspatial planning through four core supporting dimensions: spatialunderstanding, spatial reasoning, creativity, and spatial commonsense. Based onMineAnyBuild, we perform a comprehensive evaluation for existing MLLM-basedagents, revealing the severe limitations but enormous potential in theirspatial planning abilities. We believe our MineAnyBuild will open new avenuesfor the evaluation of spatial intelligence and help promote further developmentfor open-world AI agents capable of spatial planning.</description>
      <author>example@mail.com (Ziming Wei, Bingqian Lin, Zijian Jiao, Yunshuang Nie, Liang Ma, Yuecheng Liu, Yuzheng Zhuang, Xiaodan Liang)</author>
      <guid isPermaLink="false">2505.20148v2</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Semi-supervised Clustering Through Representation Learning of Large-scale EHR Data</title>
      <link>http://arxiv.org/abs/2505.20731v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SCORE的半监督表示学习框架，用于从电子健康记录中捕获多领域疾病特征，并通过患者嵌入实现个性化医疗。&lt;h4&gt;背景&lt;/h4&gt;电子健康记录提供了丰富的现实世界数据，但它们的稀疏性、异质性和高维性使得建模困难，缺乏标准化的真实数据进一步增加了预测建模的复杂性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出SCORE框架，以实现更有效的疾病特征提取和患者嵌入。&lt;h4&gt;方法&lt;/h4&gt;SCORE使用预训练的代码嵌入和Poisson-Adapted Latent factor Mixture (PALM)模型来描述编码特征和提取有意义的患者表型，同时引入混合期望最大化(EM)和高斯变分近似(GVA)算法来处理大规模数据的计算挑战。&lt;h4&gt;主要发现&lt;/h4&gt;理论证明了混合方法的收敛性，量化了GVA误差，并推导了SCORE在发散嵌入维度下的误差率。实验表明，结合未标记数据可以提高准确性并降低对标签稀缺的敏感性。&lt;h4&gt;结论&lt;/h4&gt;SCORE在有限样本性能上优于现有方法，并在多发性硬化症（MS）患者残疾状态的预测中显示出比现有方法更具有信息性和预测性的患者嵌入。&lt;h4&gt;翻译&lt;/h4&gt;摘要：电子健康记录（EHR）为个性化医学提供了丰富的现实世界数据，提供了关于疾病进展、治疗反应和患者结果的认识。然而，它们的稀疏性、异质性和高维性使得它们难以建模，而缺乏标准化的真实数据进一步复杂化了预测建模。为了解决这些挑战，我们提出了一种名为SCORE的半监督表示学习框架，通过患者嵌入捕获多领域疾病特征。SCORE使用预训练的代码嵌入和泊松自适应潜在因子混合（PALM）模型来表征编码特征并提取有意义的患者表型和嵌入。为了处理大规模数据的计算挑战，它引入了一种混合期望最大化（EM）和高斯变分近似（GVA）算法，利用有限的标记数据来改进对大量未标记样本的估计。我们理论证明了这种混合方法的收敛性，量化了GVA误差，并推导了SCORE在发散嵌入维度下的误差率。我们的分析表明，结合未标记数据可以提高准确性并降低对标签稀缺的敏感性。广泛的模拟证实了SCORE在有限样本性能上优于现有方法。最后，我们使用部分标记的EHR数据将SCORE应用于预测多发性硬化症（MS）患者的残疾状态，证明了它比现有方法产生了更具有信息性和预测性的多发性硬化症相关条件的患者嵌入。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electronic Health Records (EHR) offer rich real-world data for personalizedmedicine, providing insights into disease progression, treatment responses, andpatient outcomes. However, their sparsity, heterogeneity, and highdimensionality make them difficult to model, while the lack of standardizedground truth further complicates predictive modeling. To address thesechallenges, we propose SCORE, a semi-supervised representation learningframework that captures multi-domain disease profiles through patientembeddings. SCORE employs a Poisson-Adapted Latent factor Mixture (PALM) Modelwith pre-trained code embeddings to characterize codified features and extractmeaningful patient phenotypes and embeddings. To handle the computationalchallenges of large-scale data, it introduces a hybrid Expectation-Maximization(EM) and Gaussian Variational Approximation (GVA) algorithm, leveraging limitedlabeled data to refine estimates on a vast pool of unlabeled samples. Wetheoretically establish the convergence of this hybrid approach, quantify GVAerrors, and derive SCORE's error rate under diverging embedding dimensions. Ouranalysis shows that incorporating unlabeled data enhances accuracy and reducessensitivity to label scarcity. Extensive simulations confirm SCORE's superiorfinite-sample performance over existing methods. Finally, we apply SCORE topredict disability status for patients with multiple sclerosis (MS) usingpartially labeled EHR data, demonstrating that it produces more informative andpredictive patient embeddings for multiple MS-related conditions compared toexisting approaches.</description>
      <author>example@mail.com (Linshanshan Wang, Mengyan Li, Zongqi Xia, Molei Liu, Tianxi Cai)</author>
      <guid isPermaLink="false">2505.20731v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Rotary Masked Autoencoders are Versatile Learners</title>
      <link>http://arxiv.org/abs/2505.20535v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RoMAE的旋转掩码自编码器，用于处理不规则的时序数据，同时避免了特定于时序的架构定制，提高了计算效率和方法的简洁性。&lt;h4&gt;背景&lt;/h4&gt;将Transformer应用于不规则时序数据通常需要对基本架构进行特殊化，这可能导致额外的计算开销和方法复杂度。&lt;h4&gt;目的&lt;/h4&gt;提出RoMAE，以实现多维度连续位置信息的表示学习，同时避免对时序特定架构进行特殊化。&lt;h4&gt;方法&lt;/h4&gt;RoMAE利用流行的旋转位置嵌入（RoPE）方法，扩展了掩码自编码器（MAE），使其能够处理包括不规则和多维时序、图像和音频在内的多种模态。&lt;h4&gt;主要发现&lt;/h4&gt;RoMAE在各种模态上表现出色，包括不规则和多维时序、图像和音频，在DESC ELAsTiCCChallenge等困难数据集上超越了特定的时序架构，同时在其他模态上保持了MAE的性能。此外，RoMAE能够重建嵌入的连续位置，表明在输入序列中包含学习到的嵌入会破坏RoPE的相对位置属性。&lt;h4&gt;结论&lt;/h4&gt;RoMAE是一种高效且通用的架构，适用于处理多种模态的数据，包括不规则时序数据，同时避免了时序特定架构的复杂性和计算成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Applying Transformers to irregular time-series typically requiresspecializations to their baseline architecture, which can result in additionalcomputational overhead and increased method complexity. We present the RotaryMasked Autoencoder (RoMAE), which utilizes the popular Rotary PositionalEmbedding (RoPE) method for continuous positions. RoMAE is an extension to theMasked Autoencoder (MAE) that enables representation learning withmultidimensional continuous positional information while avoiding anytime-series-specific architectural specializations. We showcase RoMAE'sperformance on a variety of modalities including irregular and multivariatetime-series, images, and audio, demonstrating that RoMAE surpasses specializedtime-series architectures on difficult datasets such as the DESC ELAsTiCCChallenge while maintaining MAE's usual performance across other modalities. Inaddition, we investigate RoMAE's ability to reconstruct the embedded continuouspositions, demonstrating that including learned embeddings in the inputsequence breaks RoPE's relative position property.</description>
      <author>example@mail.com (Uros Zivanovic, Serafina Di Gioia, Andre Scaffidi, Martín de los Rios, Gabriella Contardo, Roberto Trotta)</author>
      <guid isPermaLink="false">2505.20535v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Identifying Super Spreaders in Multilayer Networks</title>
      <link>http://arxiv.org/abs/2505.20980v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络识别多层网络中超级传播者的新方法。&lt;h4&gt;背景&lt;/h4&gt;多层网络可以捕捉不同类型的交互，提供对复杂关系结构的更准确表示。&lt;h4&gt;目的&lt;/h4&gt;旨在通过选择最有效的传播种子来识别网络中的超级传播者。&lt;h4&gt;方法&lt;/h4&gt;构建了一个模拟信息在不同网络中扩散的数据集，并将任务定义为基于四个维度的排名预测问题，这些维度量化了每个代理的传播潜力。模型TopSpreadersNetwork包含一个关系无关的编码器和自定义聚合层。&lt;h4&gt;主要发现&lt;/h4&gt;模型在识别高影响力节点方面表现出色，同时通过其结构化输出提供了更好的可解释性。&lt;h4&gt;结论&lt;/h4&gt;TopSpreadersNetwork在识别多层网络中的超级传播者方面优于传统的基于中心性的启发式方法和竞争性的深度学习方法。&lt;h4&gt;翻译&lt;/h4&gt;Identifying super-spreaders can be framed as a subtask of the influencemaximisation problem. It seeks to pinpoint agents within a network that, ifselected as single diffusion seeds, disseminate information most effectively.Multilayer networks, a specific class of heterogeneous graphs, can capturediverse types of interactions (e.g., physical-virtual or professional-social),and thus offer a more accurate representation of complex relational structures.In this work, we introduce a novel approach to identifying super-spreaders insuch networks by leveraging graph neural networks. To this end, we construct adataset by simulating information diffusion across hundreds of networks - tothe best of our knowledge, the first of its kind tailored specifically tomultilayer networks. We further formulate the task as a variation of theranking prediction problem based on a four-dimensional vector that quantifieseach agent's spreading potential: (i) the number of activations; (ii) theduration of the diffusion process; (iii) the peak number of activations; and(iv) the simulation step at which this peak occurs. Our model,TopSpreadersNetwork, comprises a relationship-agnostic encoder and a customaggregation layer. This design enables generalisation to previously unseen dataand adapts to varying graph sizes. In an extensive evaluation, we compare ourmodel against classic centrality-based heuristics and competitive deep learningmethods. The results, obtained across a broad spectrum of real-world andsynthetic multilayer networks, demonstrate that TopSpreadersNetwork achievessuperior performance in identifying high-impact nodes, while also offeringimproved interpretability through its structured output.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Identifying super-spreaders can be framed as a subtask of the influencemaximisation problem. It seeks to pinpoint agents within a network that, ifselected as single diffusion seeds, disseminate information most effectively.Multilayer networks, a specific class of heterogeneous graphs, can capturediverse types of interactions (e.g., physical-virtual or professional-social),and thus offer a more accurate representation of complex relational structures.In this work, we introduce a novel approach to identifying super-spreaders insuch networks by leveraging graph neural networks. To this end, we construct adataset by simulating information diffusion across hundreds of networks - tothe best of our knowledge, the first of its kind tailored specifically tomultilayer networks. We further formulate the task as a variation of theranking prediction problem based on a four-dimensional vector that quantifieseach agent's spreading potential: (i) the number of activations; (ii) theduration of the diffusion process; (iii) the peak number of activations; and(iv) the simulation step at which this peak occurs. Our model,TopSpreadersNetwork, comprises a relationship-agnostic encoder and a customaggregation layer. This design enables generalisation to previously unseen dataand adapts to varying graph sizes. In an extensive evaluation, we compare ourmodel against classic centrality-based heuristics and competitive deep learningmethods. The results, obtained across a broad spectrum of real-world andsynthetic multilayer networks, demonstrate that TopSpreadersNetwork achievessuperior performance in identifying high-impact nodes, while also offeringimproved interpretability through its structured output.</description>
      <author>example@mail.com (Michał Czuba, Mateusz Stolarski, Adam Piróg, Piotr Bielak, Piotr Bródka)</author>
      <guid isPermaLink="false">2505.20980v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>GIT-BO: High-Dimensional Bayesian Optimization with Tabular Foundation Models</title>
      <link>http://arxiv.org/abs/2505.20685v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GIT-BO的梯度信息辅助贝叶斯优化方法，用于解决高维空间中贝叶斯优化的问题。&lt;h4&gt;背景&lt;/h4&gt;贝叶斯优化在高维空间中面临维度的诅咒，现有方法通常通过低维嵌入或结构假设来缓解这一挑战，但往往导致计算成本高和刚性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来应对高维空间中贝叶斯优化的挑战。&lt;h4&gt;方法&lt;/h4&gt;利用预训练的表格基础模型（TFM）作为代理，并利用其梯度信息来自适应地识别用于优化的低维子空间。通过创建一个梯度信息诊断矩阵，揭示TFM预测的最敏感方向，实现不需要重复模型重训练的连续估计活动子空间优化。&lt;h4&gt;主要发现&lt;/h4&gt;在23个合成和真实世界基准测试中，GIT-BO在可扩展性和优化性能方面均优于四种基于高斯过程的现有高维贝叶斯优化方法，尤其是在维度增加到500维时表现尤为出色。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了通过梯度信息辅助的自适应子空间识别增强的基础模型是传统基于高斯过程方法的强大替代品，特别适用于高维贝叶斯优化任务。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a gradient-informed Bayesian Optimization method named GIT-BO, which is used to address the challenges of Bayesian optimization in high-dimensional spaces. The background is that Bayesian optimization faces the curse of dimensionality in high-dimensional spaces, and existing methods usually mitigate this challenge by leveraging low-dimensional embeddings or structural assumptions, but these approaches often result in high computational cost and rigidity. The purpose of this paper is to propose a new method to address the challenges of Bayesian optimization in high-dimensional spaces. The method utilizes a pre-trained tabular foundation model (TFM) as a surrogate and leverages its gradient information to adaptively identify low-dimensional subspaces for optimization. By creating a gradient-informed diagnostic matrix, it reveals the most sensitive directions of the TFM's predictions, enabling optimization in a continuously estimated active subspace without the need for repeated model retraining. Extensive empirical evaluation across 23 synthetic and real-world benchmarks demonstrates that GIT-BO consistently outperforms four state-of-the-art Gaussian process-based high-dimensional Bayesian Optimization methods, showing superior scalability and optimization performance, especially as dimensionality increases up to 500 dimensions. This work establishes that foundation models augmented with gradient-informed adaptive subspace identification are highly competitive alternatives to traditional Gaussian process-based approaches for high-dimensional Bayesian optimization tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bayesian optimization (BO) effectively optimizes expensive black-boxfunctions but faces significant challenges in high-dimensional spaces(dimensions exceeding 100) due to the curse of dimensionality. Existinghigh-dimensional BO methods typically leverage low-dimensional embeddings orstructural assumptions to mitigate this challenge, yet these approachesfrequently incur considerable computational overhead and rigidity due toiterative surrogate retraining and fixed assumptions. To address theselimitations, we propose Gradient-Informed Bayesian Optimization using TabularFoundation Models (GIT-BO), an approach that utilizes a pre-trained tabularfoundation model (TFM) as a surrogate, leveraging its gradient information toadaptively identify low-dimensional subspaces for optimization. We propose away to exploit internal gradient computations from the TFM's forward pass bycreating a gradient-informed diagnostic matrix that reveals the most sensitivedirections of the TFM's predictions, enabling optimization in a continuouslyre-estimated active subspace without the need for repeated model retraining.Extensive empirical evaluation across 23 synthetic and real-world benchmarksdemonstrates that GIT-BO consistently outperforms four state-of-the-artGaussian process-based high-dimensional BO methods, showing superiorscalability and optimization performances, especially as dimensionalityincreases up to 500 dimensions. This work establishes foundation models,augmented with gradient-informed adaptive subspace identification, as highlycompetitive alternatives to traditional Gaussian process-based approaches forhigh-dimensional Bayesian optimization tasks.</description>
      <author>example@mail.com (Rosen Ting-Ying Yu, Cyril Picard, Faez Ahmed)</author>
      <guid isPermaLink="false">2505.20685v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Equivariant Representation Learning for Symmetry-Aware Inference with Guarantees</title>
      <link>http://arxiv.org/abs/2505.19809v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种等变表示学习框架，用于解决回归、条件概率估计和不确定性量化问题，并提供了非渐近统计学习保证。&lt;h4&gt;背景&lt;/h4&gt;在回归、条件概率估计和不确定性量化等实际应用中，利用物理或几何中的对称性可以显著提高泛化能力和样本效率。虽然几何深度学习通过结合群论结构取得了显著的经验进步，但对其统计学习保证的研究较少。&lt;h4&gt;目的&lt;/h4&gt;设计一个同时解决回归、条件概率估计和不确定性量化的等变表示学习框架，并提供前所未有的非渐近统计学习保证。&lt;h4&gt;方法&lt;/h4&gt;框架基于算子群表示理论，通过近似条件期望算子的谱分解，构建既等变又解耦的表示。&lt;h4&gt;主要发现&lt;/h4&gt;在合成数据集和真实世界机器人应用中的实证评估表明，该方法在回归性能上与现有等变基线相当甚至更好，同时提供了良好的参数不确定性估计。&lt;h4&gt;结论&lt;/h4&gt;该框架在回归和不确定性量化方面具有潜力，为解决现实世界问题提供了有效工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In many real-world applications of regression, conditional probabilityestimation, and uncertainty quantification, exploiting symmetries rooted inphysics or geometry can dramatically improve generalization and sampleefficiency. While geometric deep learning has made significant empiricaladvances by incorporating group-theoretic structure, less attention has beengiven to statistical learning guarantees. In this paper, we introduce anequivariant representation learning framework that simultaneously addressesregression, conditional probability estimation, and uncertainty quantificationwhile providing first-of-its-kind non-asymptotic statistical learningguarantees. Grounded in operator and group representation theory, our frameworkapproximates the spectral decomposition of the conditional expectationoperator, building representations that are both equivariant and disentangledalong independent symmetry subgroups. Empirical evaluations on syntheticdatasets and real-world robotics applications confirm the potential of ourapproach, matching or outperforming existing equivariant baselines inregression while additionally providing well-calibrated parametric uncertaintyestimates.</description>
      <author>example@mail.com (Daniel Ordoñez-Apraez, Vladimir Kostić, Alek Fröhlich, Vivien Brandt, Karim Lounici, Massimiliano Pontil)</author>
      <guid isPermaLink="false">2505.19809v2</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Aggregation Buffer: Revisiting DropEdge with a New Parameter Block</title>
      <link>http://arxiv.org/abs/2505.20840v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文重新审视了DropEdge，一种用于GNN的数据增强技术，通过随机移除边来暴露多样化的图结构。尽管该方法在降低特定连接的过拟合方面有潜力，但在监督学习任务中的性能提升受到限制。&lt;h4&gt;背景&lt;/h4&gt;DropEdge是一种数据增强技术，用于Graph Neural Networks（GNNs）中，通过随机移除边来增加训练过程中图结构的多样性。&lt;h4&gt;目的&lt;/h4&gt;为了理解DropEdge性能受限的原因，并提高GNN的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;进行了理论分析，提出了一种名为Aggregation Buffer的参数块，专门设计来改善GNN的鲁棒性，并解决DropEdge的局限性。&lt;h4&gt;主要发现&lt;/h4&gt;DropEdge的性能提升受到许多GNN架构的基本限制。&lt;h4&gt;结论&lt;/h4&gt;Aggregation Buffer方法与任何GNN模型兼容，并在多个数据集上显示出一致的性能提升，同时有效解决了如度偏或结构差异等已知问题。&lt;h4&gt;翻译&lt;/h4&gt;我们重新审视了DropEdge，一种用于图神经网络（GNNs）的数据增强技术，它通过随机移除边来在训练过程中暴露多样化的图结构。虽然这是一种降低图中特定连接过拟合的有效方法，但我们观察到，其在监督学习任务中的性能提升潜力受到了显著限制。为了理解这一点，我们提供了一种理论分析，表明DropEdge性能有限的原因在于许多GNN架构存在的根本限制。基于这一分析，我们提出了一种名为聚合缓冲区（Aggregation Buffer）的参数块，专门设计用于通过解决DropEdge的局限性来提高GNN的鲁棒性。我们的方法与任何GNN模型兼容，并在多个数据集上显示出一致的性能提升。此外，我们的方法作为统一解决方案，有效解决了诸如度偏或结构差异等已知问题。代码和数据集可在https://github.com/dooho00/agg-buffer找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We revisit DropEdge, a data augmentation technique for GNNs which randomlyremoves edges to expose diverse graph structures during training. While being apromising approach to effectively reduce overfitting on specific connections inthe graph, we observe that its potential performance gain in supervisedlearning tasks is significantly limited. To understand why, we provide atheoretical analysis showing that the limited performance of DropEdge comesfrom the fundamental limitation that exists in many GNN architectures. Based onthis analysis, we propose Aggregation Buffer, a parameter block specificallydesigned to improve the robustness of GNNs by addressing the limitation ofDropEdge. Our method is compatible with any GNN model, and shows consistentperformance improvements on multiple datasets. Moreover, our method effectivelyaddresses well-known problems such as degree bias or structural disparity as aunifying solution. Code and datasets are available athttps://github.com/dooho00/agg-buffer.</description>
      <author>example@mail.com (Dooho Lee, Myeong Kong, Sagad Hamid, Cheonwoo Lee, Jaemin Yoo)</author>
      <guid isPermaLink="false">2505.20840v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Solving Euler equations with Multiple Discontinuities via Separation-Transfer Physics-Informed Neural Networks</title>
      <link>http://arxiv.org/abs/2505.20361v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为ST-PINNs的物理信息神经网络，用于解决涉及多个不连续性的流体动力学问题，通过递归解决不连续性并利用迁移学习，显著降低了问题复杂性和提高了解的准确性。&lt;h4&gt;背景&lt;/h4&gt;尽管物理信息神经网络（PINNs）在科学计算中取得了显著进展，但在解决涉及多个不连续性的流体动力学问题时仍然面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出ST-PINNs以解决涉及多个不连续性的流体动力学问题。&lt;h4&gt;方法&lt;/h4&gt;ST-PINNs通过依次解决从强到弱的不连续性，并在训练过程中利用迁移学习，从而显著降低问题复杂性和提高解的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;ST-PINNs首次将基于PINNs的方法应用于二维非定常平面激波折射问题，提供了对PINNs在复杂激波界面相互作用中应用的新的见解。数值实验表明，ST-PINNs能够更准确地捕捉到尖锐不连续性，并在涉及多个不连续性的流体动力学问题中显著减少解的错误。&lt;h4&gt;结论&lt;/h4&gt;ST-PINNs是一种有效的解决流体动力学问题的新方法，能够提高解的准确性并减少计算复杂度。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管物理信息神经网络（PINNs）在科学计算方面取得了显著的进步，但它们在解决涉及多个不连续性的流体动力学问题时仍然面临挑战。在这项工作中，我们提出了分离-迁移物理信息神经网络（ST-PINNs）来解决此类问题。通过按顺序从强到弱解决不连续性，并在训练过程中利用迁移学习，ST-PINNs显著降低了问题复杂性和提高了解的准确性。据我们所知，这是首次将基于PINNs的方法应用于二维非定常平面激波折射问题，为PINNs在复杂激波界面相互作用中的应用提供了新的见解。数值实验表明，ST-PINNs能够更准确地捕捉到尖锐不连续性，并在涉及多个不连续性的流体动力学问题中显著减少解的错误。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the remarkable progress of physics-informed neural networks (PINNs)in scientific computing, they continue to face challenges when solvinghydrodynamic problems with multiple discontinuities. In this work, we proposeSeparation-Transfer Physics Informed Neural Networks (ST-PINNs) to address suchproblems. By sequentially resolving discontinuities from strong to weak andleveraging transfer learning during training, ST-PINNs significantly reduce theproblem complexity and enhance solution accuracy. To the best of our knowledge,this is the first study to apply a PINNs-based approach to the two-dimensionalunsteady planar shock refraction problem, offering new insights into theapplication of PINNs to complex shock-interface interactions. Numericalexperiments demonstrate that ST-PINNs more accurately capture sharpdiscontinuities and substantially reduce solution errors in hydrodynamicproblems involving multiple discontinuities.</description>
      <author>example@mail.com (Chuanxing Wang, Hui Luo, Kai Wang, Guohuai Zhu, Mingxing Luo)</author>
      <guid isPermaLink="false">2505.20361v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Incorporating Flexible Image Conditioning into Text-to-Video Diffusion Models without Training</title>
      <link>http://arxiv.org/abs/2505.20629v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 11 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种灵活的Text-image-to-video (TI2V) 生成方法，通过创新的无监督训练方法FlexTI2V，能够将任意数量的图像在任意位置条件化到T2V基础模型中，提高了视频生成的可控性和效率。&lt;h4&gt;背景&lt;/h4&gt;现有的TI2V生成方法通常通过微调文本到视频（T2V）基础模型来实现，这种方式资源消耗大且仅限于有限的预定义条件设置。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法资源消耗大和条件设置有限的局限性。&lt;h4&gt;方法&lt;/h4&gt;FlexTI2V方法首先将条件图像在潜在空间中转换为噪声表示，然后在T2V模型的去噪过程中，使用新颖的随机补丁交换策略，通过局部图像补丁将视觉特征纳入视频表示。为了平衡创造性和保真度，采用动态控制机制调整视觉条件对每个视频帧的影响强度。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在无监督图像条件化方面优于先前的方法，并通过详细的消融研究和分析提供了更多关于方法的见解。&lt;h4&gt;结论&lt;/h4&gt;FlexTI2V方法为TI2V生成提供了一种资源高效且灵活的解决方案，通过创新的无监督训练和无损图像条件化，显著提升了视频生成的质量和可控性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-image-to-video (TI2V) generation is a critical problem for controllablevideo generation using both semantic and visual conditions. Most existingmethods typically add visual conditions to text-to-video (T2V) foundationmodels by finetuning, which is costly in resources and only limited to a fewpredefined conditioning settings. To tackle this issue, we introduce a unifiedformulation for TI2V generation with flexible visual conditioning. Furthermore,we propose an innovative training-free approach, dubbed FlexTI2V, that cancondition T2V foundation models on an arbitrary amount of images at arbitrarypositions. Specifically, we firstly invert the condition images to noisyrepresentation in a latent space. Then, in the denoising process of T2V models,our method uses a novel random patch swapping strategy to incorporate visualfeatures into video representations through local image patches. To balancecreativity and fidelity, we use a dynamic control mechanism to adjust thestrength of visual conditioning to each video frame. Extensive experimentsvalidate that our method surpasses previous training-free image conditioningmethods by a notable margin. We also show more insights of our method bydetailed ablation study and analysis.</description>
      <author>example@mail.com (Bolin Lai, Sangmin Lee, Xu Cao, Xiang Li, James M. Rehg)</author>
      <guid isPermaLink="false">2505.20629v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>UQLegalAI@COLIEE2025: Advancing Legal Case Retrieval with Large Language Models and Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2505.20743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文详细介绍了CaseLink方法，该方法由UQLegalAI团队在COLIEE 2025竞赛中应用，用于提高法律案例检索的准确性。&lt;h4&gt;背景&lt;/h4&gt;法律案例检索在法律领域扮演着关键角色，能够帮助法律专业人士和研究人员提出法律论点和做出明智决策。&lt;h4&gt;目的&lt;/h4&gt;为了提高检索准确性，通过举办COLIEE竞赛提供基准数据集进行评估。&lt;h4&gt;方法&lt;/h4&gt;CaseLink模型使用归纳图学习和全局案例图来捕捉案例之间的内在联系。它利用大型语言模型将法律文本转换为嵌入表示，并提出了一个新的对比目标函数，通过正则化案例节点的度来优化模型。&lt;h4&gt;主要发现&lt;/h4&gt;CaseLink模型通过将法律文本转换为嵌入表示，并利用案例参照关系的信息来优化模型，从而提高了法律案例检索的准确性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的CaseLink方法在COLIEE 2025竞赛中表现优异，为法律案例检索提供了一种有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：法律案例检索在法律领域起着至关重要的作用，它通过促进相关案例的高效识别，支持法律专业人士和研究人员提出法律论点和做出明智的决策。为了提高检索的准确性，每年都会举办法律信息提取和蕴涵竞赛（COLIEE），提供更新的基准数据集用于评估。本文详细介绍了CaseLink方法，这是UQLegalAI团队在COLIEE 2025竞赛Task 1中使用的第二高排名方法。CaseLink模型利用归纳图学习和全局案例图来捕捉案例之间的内在联系，以提高法律案例检索的准确性。具体来说，它使用专门用于文本嵌入的大语言模型将法律文本转换为嵌入表示，这些嵌入表示作为构建的案例图中节点的特征表示。此外，提出了一种新的对比目标函数，包括对案例节点度的正则化，以利用案例参照关系中的信息进行模型优化。我们方法中使用的主要代码库基于CaseLink的开源仓库：https://github.com/yanran-tang/CaseLink。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Legal case retrieval plays a pivotal role in the legal domain by facilitatingthe efficient identification of relevant cases, supporting legal professionalsand researchers to propose legal arguments and make informed decision-making.To improve retrieval accuracy, the Competition on Legal Information Extractionand Entailment (COLIEE) is held annually, offering updated benchmark datasetsfor evaluation. This paper presents a detailed description of CaseLink, themethod employed by UQLegalAI, the second highest team in Task 1 of COLIEE 2025.The CaseLink model utilises inductive graph learning and Global Case Graphs tocapture the intrinsic case connectivity to improve the accuracy of legal caseretrieval. Specifically, a large language model specialized in text embeddingis employed to transform legal texts into embeddings, which serve as thefeature representations of the nodes in the constructed case graph. A newcontrastive objective, incorporating a regularization on the degree of casenodes, is proposed to leverage the information within the case referencerelationship for model optimization. The main codebase used in our method isbased on an open-sourced repo of CaseLink:https://github.com/yanran-tang/CaseLink.</description>
      <author>example@mail.com (Yanran Tang, Ruihong Qiu, Zi Huang)</author>
      <guid isPermaLink="false">2505.20743v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Towards Pretraining Robust ASR Foundation Model with Acoustic-Aware Data Augmentation</title>
      <link>http://arxiv.org/abs/2505.20606v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  in submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了训练数据中的语言和声学多样性如何影响自动语音识别（ASR）模型的鲁棒性，并揭示了转录泛化主要受声学变化驱动，而非语言丰富性。研究发现，针对声学增强的方法可以显著提高ASR模型的泛化能力，在训练于960小时Librispeech数据集时，在未见数据集上可降低多达19.24%的词错误率。&lt;h4&gt;背景&lt;/h4&gt;Whisper的ASR表现通常归因于其庞大的680k小时训练集，这对于大多数研究者来说是不切实际的。&lt;h4&gt;目的&lt;/h4&gt;考察训练数据中的语言和声学多样性对ASR模型鲁棒性的影响。&lt;h4&gt;方法&lt;/h4&gt;使用针对声学的增强方法，在960小时Librispeech数据集上训练模型，并在未见数据集上评估词错误率。&lt;h4&gt;主要发现&lt;/h4&gt;转录泛化主要受声学变化驱动，声学增强方法可显著提高ASR模型的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;策略性的声学数据增强是构建鲁棒ASR模型的有前途的替代方案，可能成为未来缺乏大规模人类语音数据时的潜在解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Whisper在自动语音识别（ASR）中的鲁棒性能通常归因于其庞大的680k小时训练集，这对大多数研究者来说是不切实际的。在本文中，我们研究了训练数据中的语言和声学多样性如何影响ASR模型的鲁棒性，并揭示转录泛化主要是由声学变化驱动的，而不是语言丰富性。我们发现，针对声学的增强方法可以显著提高ASR模型的泛化能力，当在960小时的Librispeech数据集上训练时，在未见数据集上可降低多达19.24%的词错误率。这些发现突出了战略性的声学数据增强作为构建鲁棒ASR模型的有前途的替代方案，为未来缺乏大规模人类语音数据时的基础ASR模型提供了一种可能的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Whisper's robust performance in automatic speech recognition (ASR) is oftenattributed to its massive 680k-hour training set, an impractical scale for mostresearchers. In this work, we examine how linguistic and acoustic diversity intraining data affect the robustness of the ASR model and reveal thattranscription generalization is primarily driven by acoustic variation ratherthan linguistic richness. We find that targeted acoustic augmentation methodscould significantly improve the generalization ability of ASR models, reducingword-error rates by up to 19.24 percent on unseen datasets when training on the960-hour Librispeech dataset. These findings highlight strategic acousticallyfocused data augmentation as a promising alternative to massive datasets forbuilding robust ASR models, offering a potential solution to future foundationASR models when massive human speech data is lacking.</description>
      <author>example@mail.com (Dancheng Liu, Amir Nassereldine, Chenhui Xu, Jinjun Xiong)</author>
      <guid isPermaLink="false">2505.20606v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>'Hello, World!': Making GNNs Talk with LLMs</title>
      <link>http://arxiv.org/abs/2505.20742v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code and datasets are in https://github.com/kswoo97/GLN-Code&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Graph Lingual Network (GLN)的图神经网络，该网络基于大型语言模型，其隐藏表示以人类可读的文本形式呈现，旨在提高GNN的可解释性并提升其在节点分类和链接预测任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管图神经网络（GNNs）在多种图相关任务中表现出色，但它们的高维隐藏表示使其成为黑盒。&lt;h4&gt;目的&lt;/h4&gt;提出GLN，以增强GNN的可解释性并提高其在节点分类和链接预测任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;GLN通过精心设计的提示设计，结合了GNN的消息传递模块和高级技术，如图注意力和初始残差连接。&lt;h4&gt;主要发现&lt;/h4&gt;GLN的隐藏表示的可解释性使得可以直观地分析节点表示如何在（1）不同层之间以及（2）在高级GNN技术下发生变化，揭示了GNN的内部工作原理。此外，GLN在节点分类和链接预测上实现了强大的零样本性能，超越了现有的基于LLM的基线方法。&lt;h4&gt;结论&lt;/h4&gt;GLN通过其可解释的隐藏表示和强大的性能，为GNN的可解释性和实用性提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While graph neural networks (GNNs) have shown remarkable performance acrossdiverse graph-related tasks, their high-dimensional hidden representationsrender them black boxes. In this work, we propose Graph Lingual Network (GLN),a GNN built on large language models (LLMs), with hidden representations in theform of human-readable text. Through careful prompt design, GLN incorporatesnot only the message passing module of GNNs but also advanced GNN techniques,including graph attention and initial residual connection. Thecomprehensibility of GLN's hidden representations enables an intuitive analysisof how node representations change (1) across layers and (2) under advanced GNNtechniques, shedding light on the inner workings of GNNs. Furthermore, wedemonstrate that GLN achieves strong zero-shot performance on nodeclassification and link prediction, outperforming existing LLM-based baselinemethods.</description>
      <author>example@mail.com (Sunwoo Kim, Soo Yong Lee, Jaemin Yoo, Kijung Shin)</author>
      <guid isPermaLink="false">2505.20742v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>xChemAgents: Agentic AI for Explainable Quantum Chemistry</title>
      <link>http://arxiv.org/abs/2505.20574v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICML 2025 Workshop on MAS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了xChemAgents，一种基于合作代理框架的多模态图神经网络，用于增强化学物质电子和热力学性质的预测准确性。&lt;h4&gt;背景&lt;/h4&gt;多模态图神经网络在化学领域取得了进展，但简单地将大量异构描述符附加到原子几何结构上会降低对分子形状或对称性敏感的任务的性能，并损害可解释性。&lt;h4&gt;目的&lt;/h4&gt;xChemAgents旨在通过将物理感知推理注入多模态属性预测来提高预测的准确性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;xChemAgents由两个基于语言模型的代理组成：Selector代理自适应地识别与每个目标相关的稀疏加权描述符子集，并提供自然语言推理；Validator代理通过迭代对话强制实施物理约束，如单位一致性和比例定律。&lt;h4&gt;主要发现&lt;/h4&gt;在标准基准数据集上，xChemAgents比强基线实现了高达22%的平均绝对误差减少，同时产生了忠实、可由人类解释的解释。&lt;h4&gt;结论&lt;/h4&gt;实验结果突出了合作、自我验证代理在基于基础模型的材料科学中增强准确性和透明度的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了最近在多模态图神经网络领域的进展，指出通过将文本化学描述符与原子XYZ几何结构相结合可以增强对电子和热力学性质的预测准确性。然而，简单地将大量异构描述符附加到原子几何结构上往往降低了对于分子形状或对称性敏感的任务的性能，并损害了可解释性。xChemAgents提出了一种合作代理框架，将物理感知推理引入多模态属性预测。xChemAgents由两个基于语言模型的代理组成：Selector代理自适应地识别与每个目标相关的稀疏加权描述符子集，并提供自然语言推理；Validator代理通过迭代对话强制实施物理约束，如单位一致性和比例定律。在标准基准数据集上，xChemAgents实现了与强基线相比高达22%的平均绝对误差减少，同时产生了忠实、可由人类解释的解释。实验结果突出了合作、自我验证代理在基于基础模型的材料科学中增强准确性和透明度的潜力。实现和伴随的数据集可在https://github.com/KurbanIntelligenceLab/xChemAgents匿名获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent progress in multimodal graph neural networks has demonstrated thataugmenting atomic XYZ geometries with textual chemical descriptors can enhancepredictive accuracy across a range of electronic and thermodynamic properties.However, naively appending large sets of heterogeneous descriptors oftendegrades performance on tasks sensitive to molecular shape or symmetry, andundermines interpretability. xChemAgents proposes a cooperative agent frameworkthat injects physics-aware reasoning into multimodal property prediction.xChemAgents comprises two language-model-based agents: a Selector, whichadaptively identifies a sparse, weighted subset of descriptors relevant to eachtarget, and provides a natural language rationale; and a Validator, whichenforces physical constraints such as unit consistency and scaling laws throughiterative dialogue. On standard benchmark datasets, xChemAgents achieves up toa 22\% reduction in mean absolute error over strong baselines, while producingfaithful, human-interpretable explanations. Experiment results highlight thepotential of cooperative, self-verifying agents to enhance both accuracy andtransparency in foundation-model-driven materials science. The implementationand accompanying dataset are available anonymously athttps://github.com/KurbanIntelligenceLab/xChemAgents.</description>
      <author>example@mail.com (Can Polat, Mehmet Tuncel, Hasan Kurban, Erchin Serpedin, Mustafa Kurban)</author>
      <guid isPermaLink="false">2505.20574v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Modality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval</title>
      <link>http://arxiv.org/abs/2505.19650v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, project page: https://friedrichor.github.io/projects/UNITE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为UNITE的通用框架，用于解决多模态信息检索（MIR）中的挑战，通过数据管理和模态感知训练配置两个方面进行探索。&lt;h4&gt;背景&lt;/h4&gt;MIR由于数据源异质性和跨模态对齐的复杂性而面临固有挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种系统性的方法来解决MIR中的挑战，并提高多模态检索的性能。&lt;h4&gt;方法&lt;/h4&gt;提出UNITE框架，包含数据管理和模态感知训练配置；提出Modal-Aware Masked Contrastive Learning（MAMCL）来缓解不同模态实例之间的竞争关系。&lt;h4&gt;主要发现&lt;/h4&gt;UNITE在多个多模态检索基准测试中取得了最先进的成果，优于现有方法；数据管理和定制训练协议对稳健的跨模态表示学习至关重要。&lt;h4&gt;结论&lt;/h4&gt;该研究不仅提高了MIR的性能，还为多模态系统未来的研究提供了基础蓝图。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态信息检索（MIR）由于数据源异质性和跨模态对齐的复杂性而面临固有的挑战。虽然先前的研究已经识别了特征空间中的模态差距，但解决这些挑战的系统方法尚未得到探索。在这项工作中，我们引入了UNITE，这是一个通用的框架，通过两个关键但尚未充分探索的方面来解决这些挑战：数据管理和模态感知训练配置。我们的工作提供了第一个全面的分析，说明了模态特定的数据属性如何影响下游任务在不同场景中的性能。此外，我们提出了模态感知掩码对比学习（MAMCL）来缓解不同模态实例之间的竞争关系。我们的框架在多个多模态检索基准测试中实现了最先进的成果，以显著的优势超过了现有方法。通过广泛的实验，我们证明了战略性的模态管理和定制训练协议对于稳健的跨模态表示学习至关重要。这项工作不仅提高了MIR的性能，还为多模态系统未来的研究提供了基础蓝图。我们的项目可在https://friedrichor.github.io/projects/UNITE上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal information retrieval (MIR) faces inherent challenges due to theheterogeneity of data sources and the complexity of cross-modal alignment.While previous studies have identified modal gaps in feature spaces, asystematic approach to address these challenges remains unexplored. In thiswork, we introduce UNITE, a universal framework that tackles these challengesthrough two critical yet underexplored aspects: data curation andmodality-aware training configurations. Our work provides the firstcomprehensive analysis of how modality-specific data properties influencedownstream task performance across diverse scenarios. Moreover, we proposeModal-Aware Masked Contrastive Learning (MAMCL) to mitigate the competitiverelationships among the instances of different modalities. Our frameworkachieves state-of-the-art results on multiple multimodal retrieval benchmarks,outperforming existing methods by notable margins. Through extensiveexperiments, we demonstrate that strategic modality curation and tailoredtraining protocols are pivotal for robust cross-modal representation learning.This work not only advances MIR performance but also provides a foundationalblueprint for future research in multimodal systems. Our project is availableat https://friedrichor.github.io/projects/UNITE.</description>
      <author>example@mail.com (Fanheng Kong, Jingyuan Zhang, Yahui Liu, Hongzhi Zhang, Shi Feng, Xiaocui Yang, Daling Wang, Yu Tian, Victoria W., Fuzheng Zhang, Guorui Zhou)</author>
      <guid isPermaLink="false">2505.19650v2</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>PMOA-TTS: Introducing the PubMed Open Access Textual Times Series Corpus</title>
      <link>http://arxiv.org/abs/2505.20323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PMOA-TTS是一个包含124,699篇PubMed Open Access案例报告的公开数据集，每个案例报告都通过可扩展的LLM流程转换为结构化的（事件，时间）时间线，用于支持生物医学自然语言处理中的时间线提取、时间推理和纵向建模。&lt;h4&gt;背景&lt;/h4&gt;理解临床叙事中的时间动态对于建模患者轨迹至关重要，但大规模的时间标注资源仍然有限。&lt;h4&gt;目的&lt;/h4&gt;提供PMOA-TTS数据集，以支持生物医学自然语言处理中的时间线提取、时间推理和纵向建模。&lt;h4&gt;方法&lt;/h4&gt;结合启发式过滤和使用Llama 3.3来识别单个患者的案例报告，然后使用Llama 3.3和DeepSeek R1进行提示驱动的提取，以生成超过5.6百万个带时间戳的临床事件。通过三个指标评估时间线质量：事件级匹配、时间一致性以及时间戳对齐的AULTC。&lt;h4&gt;主要发现&lt;/h4&gt;数据集具有广泛的诊断和人口统计覆盖范围。在下游生存预测任务中，提取的时间线嵌入实现了时间依赖性的一致性指数高达0.82 ± 0.01，证明了时间结构化叙事的预测价值。&lt;h4&gt;结论&lt;/h4&gt;PMOA-TTS为生物医学自然语言处理中的时间线提取、时间推理和纵向建模提供了一个可扩展的基础。&lt;h4&gt;翻译&lt;/h4&gt;Understanding temporal dynamics in clinical narratives is essential for modeling patient trajectories, yet large-scale temporally annotated resources remain limited. We present PMOA-TTS, the first openly available dataset of 124,699 PubMed Open Access (PMOA) case reports, each converted into structured(event, time) timelines via a scalable LLM-based pipeline. Our approach combines heuristic filtering with Llama 3.3 to identify single-patient case reports, followed by prompt-driven extraction using Llama 3.3 and DeepSeek R1, resulting in over 5.6 million timestamped clinical events. To assess timeline quality, we evaluate against a clinician-curated reference set using three metrics: (i) event-level matching (80% match at a cosine similarity threshold of 0.1), (ii) temporal concordance (c-index &gt; 0.90), and (iii) Area Under the Log-Time CDF (AULTC) for timestamp alignment. Corpus-level analysis shows wide diagnostic and demographic coverage. In a downstream survival prediction task, embeddings from extracted timelines achieve time-dependent concordance indices up to 0.82 ± 0.01, demonstrating the predictive value of temporally structured narratives. PMOA-TTS provides a scalable foundation for timeline extraction, temporal reasoning, and longitudinal modeling in biomedical NLP. The dataset is available at: https://huggingface.co/datasets/snoroozi/pmoa-tts.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding temporal dynamics in clinical narratives is essential formodeling patient trajectories, yet large-scale temporally annotated resourcesremain limited. We present PMOA-TTS, the first openly available dataset of124,699 PubMed Open Access (PMOA) case reports, each converted into structured(event, time) timelines via a scalable LLM-based pipeline. Our approachcombines heuristic filtering with Llama 3.3 to identify single-patient casereports, followed by prompt-driven extraction using Llama 3.3 and DeepSeek R1,resulting in over 5.6 million timestamped clinical events. To assess timelinequality, we evaluate against a clinician-curated reference set using threemetrics: (i) event-level matching (80% match at a cosine similarity thresholdof 0.1), (ii) temporal concordance (c-index &gt; 0.90), and (iii) Area Under theLog-Time CDF (AULTC) for timestamp alignment. Corpus-level analysis shows widediagnostic and demographic coverage. In a downstream survival prediction task,embeddings from extracted timelines achieve time-dependent concordance indicesup to 0.82 $\pm$ 0.01, demonstrating the predictive value of temporallystructured narratives. PMOA-TTS provides a scalable foundation for timelineextraction, temporal reasoning, and longitudinal modeling in biomedical NLP.The dataset is available at: https://huggingface.co/datasets/snoroozi/pmoa-tts .</description>
      <author>example@mail.com (Shahriar Noroozizadeh, Sayantan Kumar, George H. Chen, Jeremy C. Weiss)</author>
      <guid isPermaLink="false">2505.20323v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>AmpleHate: Amplifying the Attention for Versatile Implicit Hate Detection</title>
      <link>http://arxiv.org/abs/2505.19528v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 4 figures, Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AmpleHate的新型隐式仇恨言论检测方法，该方法模仿人类推理过程，通过识别文本中的特定目标及其与周围语境的关系来检测隐式仇恨言论。&lt;h4&gt;背景&lt;/h4&gt;隐式仇恨言论检测由于其微妙性和对语境解释的依赖而具有挑战性，传统的对比学习方法在区分仇恨和非仇恨句子方面表现出色，但人类在检测隐式仇恨言论时首先识别文本中的特定目标，然后解释这些目标与周围语境的关系。&lt;h4&gt;目的&lt;/h4&gt;设计AmpleHate方法，以模仿人类推理过程，实现隐式仇恨言论的有效检测。&lt;h4&gt;方法&lt;/h4&gt;AmpleHate使用预训练的命名实体识别模型识别显式目标，并通过[CLS]标记捕获隐式目标信息。它计算显式目标、隐式目标和句子语境之间的注意力关系，并将这些关系向量直接注入最终的句子表示中。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AmpleHate在隐式仇恨言论检测方面取得了最先进的性能，平均比对比学习基线高出82.14%，并且收敛速度更快。定性分析进一步表明，AmpleHate产生的注意力模式与人类判断紧密一致，强调了其可解释性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;AmpleHate方法在隐式仇恨言论检测方面具有显著优势，其性能优于现有方法，且与人类判断相一致，具有较好的可解释性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Implicit hate speech detection is challenging due to its subtlety andreliance on contextual interpretation rather than explicit offensive words.Current approaches rely on contrastive learning, which are shown to beeffective on distinguishing hate and non-hate sentences. Humans, however,detect implicit hate speech by first identifying specific targets within thetext and subsequently interpreting how these target relate to their surroundingcontext. Motivated by this reasoning process, we propose AmpleHate, a novelapproach designed to mirror human inference for implicit hate detection.AmpleHate identifies explicit target using a pretrained Named EntityRecognition model and capture implicit target information via [CLS] tokens. Itcomputes attention-based relationships between explicit, implicit targets andsentence context and then, directly injects these relational vectors into thefinal sentence representation. This amplifies the critical signals oftarget-context relations for determining implicit hate. Experiments demonstratethat AmpleHate achieves state-of-the-art performance, outperforming contrastivelearning baselines by an average of 82.14% and achieve faster convergence.Qualitative analyses further reveal that attention patterns produced byAmpleHate closely align with human judgement, underscoring its interpretabilityand robustness.</description>
      <author>example@mail.com (Yejin Lee, Joonghyuk Hahn, Hyeseon Ahn, Yo-Sub Han)</author>
      <guid isPermaLink="false">2505.19528v2</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>CPathAgent: An Agent-based Foundation Model for Interpretable High-Resolution Pathology Image Analysis Mimicking Pathologists' Diagnostic Logic</title>
      <link>http://arxiv.org/abs/2505.20510v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  49 pages, 33 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为CPathAgent的新型计算机病理学模型，旨在模拟病理医生的诊断过程，通过自主执行缩放和导航操作，以观察到的视觉特征为基础，实现对病理图像的全面诊断。&lt;h4&gt;背景&lt;/h4&gt;当前计算机病理学模型无法完全复制病理医生的诊断过程，主要因为它们依赖于通用编码器进行分类或直接应用多模态模型生成报告。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够模拟病理医生诊断逻辑的计算机病理学模型，以实现更详细和可解释的诊断报告。&lt;h4&gt;方法&lt;/h4&gt;CPathAgent通过多阶段训练策略，将块级、区域级和全切片能力统一在一个模型中，以模拟病理医生的诊断过程。此外，还构建了一个专家验证的PathMMU-HR$^{2}$基准，用于大规模区域分析。&lt;h4&gt;主要发现&lt;/h4&gt;CPathAgent在三个尺度上的基准测试中，均优于现有方法，验证了基于代理的诊断方法的有效性，并为计算病理学的未来发展方向提供了新的思路。&lt;h4&gt;结论&lt;/h4&gt;CPathAgent模型在模拟病理医生的诊断逻辑方面具有显著优势，为计算病理学的发展提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in computational pathology have led to the emergence of numerous foundation models. However, these approaches fail to replicate the diagnostic process of pathologists, as they either simply rely on general-purpose encoders with multi-instance learning for classification or directly apply multimodal models to generate reports from images. A significant limitation is their inability to emulate the diagnostic logic employed by pathologists, who systematically examine slides at low magnification for overview before progressively zooming in on suspicious regions to formulate comprehensive diagnoses. To address this gap, we introduce CPathAgent, an innovative agent-based model that mimics pathologists' reasoning processes by autonomously executing zoom-in/out and navigation operations across pathology images based on observed visual features. To achieve this, we develop a multi-stage training strategy unifying patch-level, region-level, and whole-slide capabilities within a single model, which is essential for mimicking pathologists, who require understanding and reasoning capabilities across all three scales. This approach generates substantially more detailed and interpretable diagnostic reports compared to existing methods, particularly for huge region understanding. Additionally, we construct an expert-validated PathMMU-HR$^{2}$, the first benchmark for huge region analysis, a critical intermediate scale between patches and whole slides, as diagnosticianst typically examine several key regions rather than entire slides at once. Extensive experiments demonstrate that CPathAgent consistently outperforms existing approaches across three scales of benchmarks, validating the effectiveness of our agent-based diagnostic approach and highlighting a promising direction for the future development of computational pathology.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in computational pathology have led to the emergence ofnumerous foundation models. However, these approaches fail to replicate thediagnostic process of pathologists, as they either simply rely ongeneral-purpose encoders with multi-instance learning for classification ordirectly apply multimodal models to generate reports from images. A significantlimitation is their inability to emulate the diagnostic logic employed bypathologists, who systematically examine slides at low magnification foroverview before progressively zooming in on suspicious regions to formulatecomprehensive diagnoses. To address this gap, we introduce CPathAgent, aninnovative agent-based model that mimics pathologists' reasoning processes byautonomously executing zoom-in/out and navigation operations across pathologyimages based on observed visual features. To achieve this, we develop amulti-stage training strategy unifying patch-level, region-level, andwhole-slide capabilities within a single model, which is essential formimicking pathologists, who require understanding and reasoning capabilitiesacross all three scales. This approach generates substantially more detailedand interpretable diagnostic reports compared to existing methods, particularlyfor huge region understanding. Additionally, we construct an expert-validatedPathMMU-HR$^{2}$, the first benchmark for huge region analysis, a criticalintermediate scale between patches and whole slides, as diagnosticianstypically examine several key regions rather than entire slides at once.Extensive experiments demonstrate that CPathAgent consistently outperformsexisting approaches across three scales of benchmarks, validating theeffectiveness of our agent-based diagnostic approach and highlighting apromising direction for the future development of computational pathology.</description>
      <author>example@mail.com (Yuxuan Sun, Yixuan Si, Chenglu Zhu, Kai Zhang, Zhongyi Shui, Bowen Ding, Tao Lin, Lin Yang)</author>
      <guid isPermaLink="false">2505.20510v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Embodied AI with Foundation Models for Mobile Service Robots: A Systematic Review</title>
      <link>http://arxiv.org/abs/2505.20503v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基础模型在移动服务机器人中的应用，探讨了在动态环境中提升机器人理解和执行复杂任务的能力。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型（如大型语言模型、视觉-语言模型等）的快速发展，为移动服务机器人中的具身人工智能提供了新的方向。&lt;h4&gt;目的&lt;/h4&gt;对基础模型在移动服务机器人中的集成进行系统性的回顾，并识别具身人工智能中的关键开放挑战。&lt;h4&gt;方法&lt;/h4&gt;研究了如何通过结合基础模型和具身人工智能原理，实现实时传感器融合、语言条件控制以及自适应任务执行。&lt;h4&gt;主要发现&lt;/h4&gt;分析了基础模型在解决多模态传感器融合、不确定性下的实时决策、任务泛化以及有效人机交互等挑战中的作用。&lt;h4&gt;结论&lt;/h4&gt;探讨了基础模型在家庭助手、医疗保健和服务自动化等领域的实际应用，强调了预测性缩放定律、自主长期适应和跨具身泛化的重要性。&lt;h4&gt;翻译&lt;/h4&gt;This paper systematically reviews the integration of foundation models in mobile service robotics, exploring how these models can enhance the ability of robots to understand and execute complex tasks in dynamic real-world environments. The background is the rapid development of foundation models such as large language models and vision-language models, which have opened up new directions for embodied AI in mobile service robotics. The purpose is to identify key open challenges in embodied AI through a systematic review of the integration of foundation models in mobile service robotics. The method is to study how to combine foundation models with the principles of embodied AI to achieve real-time sensor fusion, language-conditioned control, and adaptive task execution. The main findings analyze the role of foundation models in addressing challenges such as multimodal sensor fusion, real-time decision-making under uncertainty, task generalization, and effective human-robot interaction. The conclusion discusses the practical applications of foundation models in the fields of domestic assistance, healthcare, and service automation, emphasizing the importance of predictive scaling laws, autonomous long-term adaptation, and cross-embodiment generalization for the scalable, efficient, and robust deployment of foundation models in human-centric robotic systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Rapid advancements in foundation models, including Large Language Models,Vision-Language Models, Multimodal Large Language Models, andVision-Language-Action Models have opened new avenues for embodied AI in mobileservice robotics. By combining foundation models with the principles ofembodied AI, where intelligent systems perceive, reason, and act throughphysical interactions, robots can improve understanding, adapt to, and executecomplex tasks in dynamic real-world environments. However, embodied AI inmobile service robots continues to face key challenges, including multimodalsensor fusion, real-time decision-making under uncertainty, taskgeneralization, and effective human-robot interactions (HRI). In this paper, wepresent the first systematic review of the integration of foundation models inmobile service robotics, identifying key open challenges in embodied AI andexamining how foundation models can address them. Namely, we explore the roleof such models in enabling real-time sensor fusion, language-conditionedcontrol, and adaptive task execution. Furthermore, we discuss real-worldapplications in the domestic assistance, healthcare, and service automationsectors, demonstrating the transformative impact of foundation models onservice robotics. We also include potential future research directions,emphasizing the need for predictive scaling laws, autonomous long-termadaptation, and cross-embodiment generalization to enable scalable, efficient,and robust deployment of foundation models in human-centric robotic systems.</description>
      <author>example@mail.com (Matthew Lisondra, Beno Benhabib, Goldie Nejat)</author>
      <guid isPermaLink="false">2505.20503v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>STRAP: Spatio-Temporal Pattern Retrieval for Out-of-Distribution Generalization</title>
      <link>http://arxiv.org/abs/2505.19547v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;STRAP是一个创新的时空检索增强模式学习框架，通过整合检索增强学习到STGNN持续学习流程中，增强了模型在时空异常分布场景下的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;时空图神经网络（STGNNs）在建模动态图结构数据方面表现出强大的能力，但在时空异常分布（STOOD）场景下，即时间和空间结构超出训练分布时，它们通常无法泛化。&lt;h4&gt;目的&lt;/h4&gt;提出STRAP框架的目的是为了解决STGNNs在STOOD场景下泛化能力不足的问题。&lt;h4&gt;方法&lt;/h4&gt;STRAP的核心是一个紧凑且表达丰富的模式库，它存储了具有历史、结构和语义信息的代表性时空模式，这些模式在训练阶段获得和优化。在推理阶段，STRAP根据当前输入与库中模式的相似度检索相关模式，并通过即插即用的提示机制将其注入模型中。此外，STRAP引入了知识平衡目标，以协调新信息与检索到的知识。&lt;h4&gt;主要发现&lt;/h4&gt;在多个真实世界流图数据集上的实验表明，STRAP在STOOD任务上始终优于最先进的STGNN基线，证明了其鲁棒性、适应性和强大的泛化能力，无需针对特定任务进行微调。&lt;h4&gt;结论&lt;/h4&gt;STRAP框架有效地提高了STGNNs在时空异常分布场景下的泛化能力，为动态图结构数据建模提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Spatio-Temporal Graph Neural Networks (STGNNs) have emerged as a powerful tool for modeling dynamic graph-structured data across diverse domains. However, they often fail to generalize in Spatio-Temporal Out-of-Distribution (STOOD) scenarios, where both temporal dynamics and spatial structures evolve beyond the training distribution. To address this problem, we propose an innovative Spatio-Temporal Retrieval-Augmented Pattern Learning framework, STRAP, which enhances model generalization by integrating retrieval-augmented learning into the STGNN continuous learning pipeline. The core of STRAP is a compact and expressive pattern library that stores representative spatio-temporal patterns enriched with historical, structural, and semantic information, which is obtained and optimized during the training phase. During inference, STRAP retrieves relevant patterns from this library based on similarity to the current input and injects them into the model via a plug-and-play prompting mechanism. This not only strengthens spatio-temporal representations but also mitigates catastrophic forgetting. Moreover, STRAP introduces a knowledge-balancing objective to harmonize new information with retrieved knowledge. Extensive experiments across multiple real-world streaming graph datasets show that STRAP consistently outperforms state-of-the-art STGNN baselines on STOOD tasks, demonstrating its robustness, adaptability, and strong generalization capability without task-specific fine-tuning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatio-Temporal Graph Neural Networks (STGNNs) have emerged as a powerfultool for modeling dynamic graph-structured data across diverse domains.However, they often fail to generalize in Spatio-Temporal Out-of-Distribution(STOOD) scenarios, where both temporal dynamics and spatial structures evolvebeyond the training distribution. To address this problem, we propose aninnovative Spatio-Temporal Retrieval-Augmented Pattern Learningframework,STRAP, which enhances model generalization by integratingretrieval-augmented learning into the STGNN continue learning pipeline. Thecore of STRAP is a compact and expressive pattern library that storesrepresentative spatio-temporal patterns enriched with historical, structural,and semantic information, which is obtained and optimized during the trainingphase. During inference, STRAP retrieves relevant patterns from this librarybased on similarity to the current input and injects them into the model via aplug-and-play prompting mechanism. This not only strengthens spatio-temporalrepresentations but also mitigates catastrophic forgetting. Moreover, STRAPintroduces a knowledge-balancing objective to harmonize new information withretrieved knowledge. Extensive experiments across multiple real-world streaminggraph datasets show that STRAP consistently outperforms state-of-the-art STGNNbaselines on STOOD tasks, demonstrating its robustness, adaptability, andstrong generalization capability without task-specific fine-tuning.</description>
      <author>example@mail.com (Haoyu Zhang, Wentao Zhang, Hao Miao, Xinke Jiang, Yuchen Fang, Yifan Zhang)</author>
      <guid isPermaLink="false">2505.19547v2</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Robust fine-tuning of speech recognition models via model merging: application to disordered speech</title>
      <link>http://arxiv.org/abs/2505.20477v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了使用模型合并技术来提升自动语音识别（ASR）在失语症语音上的表现，通过 Whisper 作为基础语音基础模型（SFM），实现了性能的显著提升。&lt;h4&gt;背景&lt;/h4&gt;尽管语音基础模型（SFM）在自动语音识别（ASR）领域取得了进步，但失语症语音的多样性和数据限制导致性能下降。&lt;h4&gt;目的&lt;/h4&gt;旨在通过模型合并技术来提高 ASR 的一般化能力。&lt;h4&gt;方法&lt;/h4&gt;研究了单轨迹合并和多运行合并两种方法，比较了微调和模型合并的效果。&lt;h4&gt;主要发现&lt;/h4&gt;多运行合并方法相较于传统微调，在失语症语音识别中实现了 12% 的错误率（WER）相对降低，在长音频上降低了 16.2% 的 WER。模型合并方法在低数据环境中仍然有效，并且对不同的模型架构具有普遍性。&lt;h4&gt;结论&lt;/h4&gt;模型合并是一种易于复制的改进方法，能够持续提升 ASR 性能，而无需额外的推理成本或超参数调整。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic Speech Recognition (ASR) has advanced with Speech Foundation Models(SFMs), yet performance degrades on dysarthric speech due to variability andlimited data. This study as part of the submission to the Speech Accessibilitychallenge, explored model merging to improve ASR generalization using Whisperas the base SFM. We compared fine-tuning with single-trajectory merging,combining models from one fine-tuning path, and multi-run merging, mergingindependently trained models. Our best multi-run merging approach achieved a12% relative decrease of WER over classic fine-tuning, and a 16.2% relativedecrease on long-form audios, a major loss contributor in dysarthric ASR.Merging more and more models led to continuous gains, remained effective inlow-data regimes, and generalized across model architectures. These resultshighlight model merging as an easily replicable adaptation method thatconsistently improves ASR without additional inference cost or hyperparametertuning.</description>
      <author>example@mail.com (Alexandre Ducorroy, Rachid Riad)</author>
      <guid isPermaLink="false">2505.20477v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>SEMMA: A Semantic Aware Knowledge Graph Foundation Model</title>
      <link>http://arxiv.org/abs/2505.20422v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SEMMA是一种双模块知识图谱基础模型，通过整合可转移的文本语义和结构信息，实现了对未见图的零样本推理。&lt;h4&gt;背景&lt;/h4&gt;现有的知识图谱基础模型主要依赖图结构，忽视了文本属性中编码的丰富语义信号。&lt;h4&gt;目的&lt;/h4&gt;提出SEMMA模型，以系统地整合可转移的文本语义和结构信息。&lt;h4&gt;方法&lt;/h4&gt;SEMMA利用大型语言模型（LLMs）丰富关系标识符，生成语义嵌入，形成文本关系图，并将其与结构组件融合。&lt;h4&gt;主要发现&lt;/h4&gt;在54个不同的知识图谱上，SEMMA在完全归纳式链接预测中优于仅基于结构的基线模型ULTRA。在更具挑战性的泛化设置中，当测试时的关系词汇完全未知时，结构方法失效，而SEMMA的效率提高了2倍。&lt;h4&gt;结论&lt;/h4&gt;文本语义对于结构无法独立发挥作用的泛化场景至关重要，强调了在知识推理中统一结构和语言信号的基础模型的需求。&lt;h4&gt;翻译&lt;/h4&gt;知识图谱基础模型（KGFMs）在通过学习可转移的模式实现未见图的零样本推理方面显示出希望。然而，大多数现有的KGFMs仅依赖于图结构，忽略了文本属性中编码的丰富语义信号。我们引入了SEMMA，这是一种双模块KGFM，它系统地整合了可转移的文本语义和结构。SEMMA利用大型语言模型（LLMs）来丰富关系标识符，生成语义嵌入，这些嵌入随后形成文本关系图，该图与结构组件融合。在54个不同的知识图谱上，SEMMA在完全归纳式链接预测中优于仅基于结构的基线模型ULTRA。关键的是，我们表明在更具挑战性的泛化设置中，即测试时关系词汇完全未知的情况下，结构方法崩溃，而SEMMA的效果提高了2倍。我们的发现表明，文本语义对于结构无法独立发挥作用的泛化场景至关重要，强调了在知识推理中统一结构和语言信号的基础模型的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge Graph Foundation Models (KGFMs) have shown promise in enablingzero-shot reasoning over unseen graphs by learning transferable patterns.However, most existing KGFMs rely solely on graph structure, overlooking therich semantic signals encoded in textual attributes. We introduce SEMMA, adual-module KGFM that systematically integrates transferable textual semanticsalongside structure. SEMMA leverages Large Language Models (LLMs) to enrichrelation identifiers, generating semantic embeddings that subsequently form atextual relation graph, which is fused with the structural component. Across 54diverse KGs, SEMMA outperforms purely structural baselines like ULTRA in fullyinductive link prediction. Crucially, we show that in more challenginggeneralization settings, where the test-time relation vocabulary is entirelyunseen, structural methods collapse while SEMMA is 2x more effective. Ourfindings demonstrate that textual semantics are critical for generalization insettings where structure alone fails, highlighting the need for foundationmodels that unify structural and linguistic signals in knowledge reasoning.</description>
      <author>example@mail.com (Arvindh Arun, Sumit Kumar, Mojtaba Nayyeri, Bo Xiong, Ponnurangam Kumaraguru, Antonio Vergari, Steffen Staab)</author>
      <guid isPermaLink="false">2505.20422v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Omni-R1: Reinforcement Learning for Omnimodal Reasoning via Two-System Collaboration</title>
      <link>http://arxiv.org/abs/2505.20256v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://aim-uofa.github.io/OmniR1&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Omni-R1的端到端强化学习框架，用于解决长时域视频-音频推理和细粒度像素理解在多模态模型中的矛盾需求。&lt;h4&gt;背景&lt;/h4&gt;在多模态模型中，长时域视频-音频推理需要密集的时间覆盖，这要求使用许多低分辨率帧；而精确的定位则需要高分辨率输入。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决上述矛盾，提高模型在视频-音频推理任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;提出了一种双系统架构，包括全局推理系统和细节理解系统。全局推理系统通过强化学习选择信息关键帧并重新定义任务，以降低空间成本；细节理解系统则在选定的分辨率较高的片段上执行像素级定位。&lt;h4&gt;主要发现&lt;/h4&gt;Omni-R1在RefAVS和REVOS两个具有挑战性的基准测试中，不仅超过了强监督基线，而且超过了专门的最新模型，同时显著提高了领域外泛化能力和减轻了多模态幻觉。&lt;h4&gt;结论&lt;/h4&gt;本文展示了强化学习在大型多模态推理中的首次成功应用，并突出了通往通用基础模型的可扩展路径。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes an end-to-end reinforcement learning framework called Omni-R1 to address the conflicting requirements of long-horizon video-audio reasoning and fine-grained pixel understanding in multimodal models. The paper introduces a two-system architecture, including a Global Reasoning System and a Detail Understanding System. Omni-R1 selects informative keyframes and reformulates the task at low spatial cost through reinforcement learning, while the Detail Understanding System performs pixel-level grounding on the selected high-resolution snippets. The framework has been demonstrated to outperform strong supervised baselines and specialized state-of-the-art models in challenging benchmarks, showing significant improvements in out-of-domain generalization and reduction of multimodal hallucination. The results highlight the first successful application of reinforcement learning to large-scale multimodal reasoning and indicate a scalable path towards universally foundational models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-horizon video-audio reasoning and fine-grained pixel understandingimpose conflicting requirements on omnimodal models: dense temporal coveragedemands many low-resolution frames, whereas precise grounding calls forhigh-resolution inputs. We tackle this trade-off with a two-systemarchitecture: a Global Reasoning System selects informative keyframes andrewrites the task at low spatial cost, while a Detail Understanding Systemperforms pixel-level grounding on the selected high-resolution snippets.Because ``optimal'' keyframe selection and reformulation are ambiguous and hardto supervise, we formulate them as a reinforcement learning (RL) problem andpresent Omni-R1, an end-to-end RL framework built on Group Relative PolicyOptimization. Omni-R1 trains the Global Reasoning System through hierarchicalrewards obtained via online collaboration with the Detail Understanding System,requiring only one epoch of RL on small task splits.  Experiments on two challenging benchmarks, namely Referring Audio-VisualSegmentation (RefAVS) and Reasoning Video Object Segmentation (REVOS), showthat Omni-R1 not only surpasses strong supervised baselines but alsooutperforms specialized state-of-the-art models, while substantially improvingout-of-domain generalization and mitigating multimodal hallucination. Ourresults demonstrate the first successful application of RL to large-scaleomnimodal reasoning and highlight a scalable path toward universally foundationmodels.</description>
      <author>example@mail.com (Hao Zhong, Muzhi Zhu, Zongze Du, Zheng Huang, Canyu Zhao, Mingyu Liu, Wen Wang, Hao Chen, Chunhua Shen)</author>
      <guid isPermaLink="false">2505.20256v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>PathBench: A comprehensive comparison benchmark for pathology foundation models towards precision oncology</title>
      <link>http://arxiv.org/abs/2505.20202v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  35 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;病理基础模型的出现彻底改变了计算病理学，实现了对全切片图像的高精度、泛化分析，从而提高了癌症的诊断和预后评估。然而，这些模型在临床转化中面临挑战，包括不同癌症类型间模型最优化的变异性、评估中的潜在数据泄露以及缺乏标准化的基准。没有严格的、无偏见的评估，即使是先进的病理基础模型也可能会局限于研究环境，延迟其救命应用。现有的基准测试工作受限于狭窄的癌症类型关注、潜在预训练数据重叠或不完整的任务覆盖。本文介绍了PathBench，这是第一个全面解决这些差距的基准，通过多中心室内数据集、涵盖从诊断到预后整个临床范围的评估以及自动排行榜系统进行持续模型评估。该框架结合了大规模数据，实现了对病理基础模型的客观比较，同时反映了现实世界的临床复杂性。所有评估数据均来自私人医疗机构，严格排除任何预训练使用，以避免数据泄露风险。收集了来自10家医院的8,549名患者的15,888张全切片图像，涵盖超过64个诊断和预后任务。目前，对19个病理基础模型的评估显示，Virchow2和H-Optimus-1是整体上最有效的模型。这项工作为研究人员提供了一个稳健的平台，为临床医生提供了关于不同临床场景中病理基础模型性能的可操作见解，最终加速了这些变革性技术的常规病理实践转化。&lt;h4&gt;背景&lt;/h4&gt;病理基础模型在计算病理学中的应用，以及对癌症诊断和预后评估的改进。&lt;h4&gt;目的&lt;/h4&gt;解决病理基础模型在临床转化中面临的挑战，并建立一个全面的基准来评估这些模型。&lt;h4&gt;方法&lt;/h4&gt;开发PathBench，一个综合性的基准，包括多中心室内数据集、全临床范围的评估和自动排行榜系统。&lt;h4&gt;主要发现&lt;/h4&gt;PathBench能够有效地评估病理基础模型，Virchow2和H-Optimus-1在19个模型中表现最佳。&lt;h4&gt;结论&lt;/h4&gt;PathBench为模型开发提供了一个稳健的平台，并加速了病理基础模型在临床实践中的应用。&lt;h4&gt;翻译&lt;/h4&gt;The emergence of pathology foundation models has revolutionized computational histopathology, enabling highly accurate, generalized whole-slide image analysis for improved cancer diagnosis and prognosis assessment. While these models show remarkable potential across cancer diagnostics and prognostics, their clinical translation faces critical challenges including variability in optimal model across cancer types, potential data leakage in evaluation, and lack of standardized benchmarks. Without rigorous, unbiased evaluation, even the most advanced PFMs risk remaining confined to research settings, delaying their life-saving applications. Existing benchmarking efforts remain limited by narrow cancer-type focus, potential pretraining data overlaps, or incomplete task coverage. We present PathBench, the first comprehensive benchmark addressing these gaps through: multi-center in-house datasets spanning common cancers with rigorous leakage prevention, evaluation across the full clinical spectrum from diagnosis to prognosis, and an automated leaderboard system for continuous model assessment. Our framework incorporates large-scale data, enabling objective comparison of PFMs while reflecting real-world clinical complexity. All evaluation data comes from private medical providers, with strict exclusion of any pretraining usage to avoid data leakage risks. We have collected 15,888 WSIs from 8,549 patients across 10 hospitals, encompassing over 64 diagnosis and prognosis tasks. Currently, our evaluation of 19 PFMs shows that Virchow2 and H-Optimus-1 are the most effective models overall. This work provides researchers with a robust platform for model development and offers clinicians actionable insights into PFM performance across diverse clinical scenarios, ultimately accelerating the translation of these transformative technologies into routine pathology practice.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of pathology foundation models has revolutionized computationalhistopathology, enabling highly accurate, generalized whole-slide imageanalysis for improved cancer diagnosis, and prognosis assessment. While thesemodels show remarkable potential across cancer diagnostics and prognostics,their clinical translation faces critical challenges including variability inoptimal model across cancer types, potential data leakage in evaluation, andlack of standardized benchmarks. Without rigorous, unbiased evaluation, eventhe most advanced PFMs risk remaining confined to research settings, delayingtheir life-saving applications. Existing benchmarking efforts remain limited bynarrow cancer-type focus, potential pretraining data overlaps, or incompletetask coverage. We present PathBench, the first comprehensive benchmarkaddressing these gaps through: multi-center in-hourse datasets spanning commoncancers with rigorous leakage prevention, evaluation across the full clinicalspectrum from diagnosis to prognosis, and an automated leaderboard system forcontinuous model assessment. Our framework incorporates large-scale data,enabling objective comparison of PFMs while reflecting real-world clinicalcomplexity. All evaluation data comes from private medical providers, withstrict exclusion of any pretraining usage to avoid data leakage risks. We havecollected 15,888 WSIs from 8,549 patients across 10 hospitals, encompassingover 64 diagnosis and prognosis tasks. Currently, our evaluation of 19 PFMsshows that Virchow2 and H-Optimus-1 are the most effective models overall. Thiswork provides researchers with a robust platform for model development andoffers clinicians actionable insights into PFM performance across diverseclinical scenarios, ultimately accelerating the translation of thesetransformative technologies into routine pathology practice.</description>
      <author>example@mail.com (Jiabo Ma, Yingxue Xu, Fengtao Zhou, Yihui Wang, Cheng Jin, Zhengrui Guo, Jianfeng Wu, On Ki Tang, Huajun Zhou, Xi Wang, Luyang Luo, Zhengyu Zhang, Du Cai, Zizhao Gao, Wei Wang, Yueping Liu, Jiankun He, Jing Cui, Zhenhui Li, Jing Zhang, Feng Gao, Xiuming Zhang, Li Liang, Ronald Cheong Kin Chan, Zhe Wang, Hao Chen)</author>
      <guid isPermaLink="false">2505.20202v1</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>Generalized and Personalized Federated Learning with Foundation Models via Orthogonal Transformations</title>
      <link>http://arxiv.org/abs/2505.19888v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Federated Learning旨在在不集中收集数据的情况下，在分散的客户端或设备上训练模型，以增强数据隐私和安全性。论文提出了一种名为FedOT的新方法，通过利用黑盒基础模型，实现了在异构环境中同时达到泛化和个性化的目标。&lt;h4&gt;背景&lt;/h4&gt;Federated Learning旨在解决数据隐私和安全性问题，但在异构环境中同时实现泛化和个性化仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出FedOT方法，以解决在异构环境中同时实现泛化和个性化的问题。&lt;h4&gt;方法&lt;/h4&gt;FedOT通过共享全局任务依赖的分类器，在客户端本地通过正交变换来适应特征。通过强制正交性，FedOT减轻了不同客户端之间的梯度冲突，保持了语义完整性，并在数据异质性较大的情况下实现了稳健的性能。&lt;h4&gt;主要发现&lt;/h4&gt;FedOT在多个基准测试中优于基线FL方法，联合优化全局分类器和局部正交变换可以实现更优的性能。&lt;h4&gt;结论&lt;/h4&gt;FedOT是一种有效的方法，可以同时实现泛化和个性化，具有更广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;Federated Learning (FL) aims to train models across decentralized clients or devices holding local data without the need for centralized data collection, thus enhancing data privacy and security. However, achieving both generalization and personalization in heterogeneous settings remains a significant challenge. To address this, we introduce FedOT, a novel approach that leverages black-box foundation models. FedOT shares only a global task-dependent classifier across clients while locally adapting features through orthogonal transformations. By enforcing orthogonality, FedOT mitigates gradient conflicts across diverse clients, preserves semantic integrity, and achieves robust performance even in the presence of substantial data heterogeneity. The strategy of combining global and local parameters enables a more balanced approach for both generalization and personalization, outperforming baseline FL methods across multiple benchmarks. Furthermore, our extensive analysis confirms that joint optimization of global classifiers and local orthogonal transformations yields superior performance and suggests broader applicability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Learning (FL) aims to train models across decentralized clients ordevices holding local data without the need for centralized data collection,thus enhancing data privacy and security. However, achieving bothgeneralization and personalization in heterogeneous settings remains asignificant challenge. To address this, we introduce FedOT, a novel approachthat leverages black-box foundation models. FedOT shares only a globaltask-dependent classifier across clients while locally adapting featuresthrough orthogonal transformations. By enforcing orthogonality, FedOT mitigatesgradient conflicts across diverse clients, preserves semantic integrity, andachieves robust performance even in the presence of substantial dataheterogeneity. The strategy of combining global and local parameters enables amore balanced approach for both generalization and personalization,outperforming baseline FL methods across multiple benchmarks. Furthermore, ourextensive analysis confirms that joint optimization of global classifiers andlocal orthogonal transformations yields superior performance and suggestsbroader applicability.</description>
      <author>example@mail.com (Eun Gyung Kong, Je Won Yeom, Yonghoon Jeon, Taesup Kim)</author>
      <guid isPermaLink="false">2505.19888v2</guid>
      <pubDate>Wed, 28 May 2025 14:29:15 +0800</pubDate>
    </item>
    <item>
      <title>How high is `high'? Rethinking the roles of dimensionality in topological data analysis and manifold learning</title>
      <link>http://arxiv.org/abs/2505.16879v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种广义的Hanson-Wright不等式，并利用它对数据点云的几何结构进行了新的统计分析。&lt;h4&gt;背景&lt;/h4&gt;论文以一般随机函数模型为数据设置，讨论了三个维度的概念：环境固有维度、相关秩和潜在固有维度。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过这些维度来揭示数据中的潜在同伦和流形结构。&lt;h4&gt;方法&lt;/h4&gt;分析表明，为了使持久性图揭示潜在同伦和流形结构出现，需要环境固有维度远大于样本大小的对数。&lt;h4&gt;主要发现&lt;/h4&gt;首次提供了证据表明，网格细胞活动中的环面结构实际上是等距于物理空间的，这意味着网格细胞活动传达了真实世界的几何忠实表示。&lt;h4&gt;结论&lt;/h4&gt;这些理论视角有助于解释Gardner等人在《自然》杂志上发表的关于网格细胞活动环面结构的神经科学发现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a generalised Hanson-Wright inequality and use it to establish newstatistical insights into the geometry of data point-clouds. In the setting ofa general random function model of data, we clarify the roles played by threenotions of dimensionality: ambient intrinsic dimension $p_{\mathrm{int}}$,which measures total variability across orthogonal feature directions;correlation rank, which measures functional complexity across samples; andlatent intrinsic dimension, which is the dimension of manifold structure hiddenin data. Our analysis shows that in order for persistence diagrams to reveallatent homology and for manifold structure to emerge it is sufficient that$p_{\mathrm{int}}\gg \log n$, where $n$ is the sample size. Informed by thesetheoretical perspectives, we revisit the ground-breaking neuroscience discoveryof toroidal structure in grid-cell activity made by Gardner et al. (Nature,2022): our findings reveal, for the first time, evidence that this structure isin fact isometric to physical space, meaning that grid cell activity conveys ageometrically faithful representation of the real world.</description>
      <author>example@mail.com (Hannah Sansford, Nick Whiteley, Patrick Rubin-Delanchy)</author>
      <guid isPermaLink="false">2505.16879v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
  <item>
      <title>Learning Genomic Structure from $k$-mers</title>
      <link>http://arxiv.org/abs/2505.16680v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于对比学习的基因组分析方法，用于分析基因组测序数据。该方法能够将来自同一基因组区域的序列聚集成簇，并保留了基因组区域的顺序性。&lt;h4&gt;背景&lt;/h4&gt;基因组测序会产生大量短核苷酸子序列，称为reads，这些reads需要被组装以重建完整的基因组。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法来分析基因组测序数据，以更好地理解基因组结构，并应用于下游任务。&lt;h4&gt;方法&lt;/h4&gt;使用对比学习训练编码器模型，生成能够将来自同一基因组区域的序列聚集成簇的嵌入（embeddings）。该方法能够保留基因组区域的顺序性，并提供k-mer序列的一般表示。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在模拟的古DNA（aDNA）read mapping和结构变异识别中表现出色，并且可以用于元基因组物种识别。通过引入特定的噪声模型和距离阈值参数Γ，可以增强嵌入的鲁棒性。该模型可以在没有全基因组组装的情况下，完全自监督地训练。&lt;h4&gt;结论&lt;/h4&gt;该方法在处理大规模基因组数据方面具有很好的扩展性，对于元基因组应用和与人类基因组大小相当的基因组映射具有很高的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于对比学习的基因组分析方法，用于分析基因组测序数据。该方法能够将来自同一基因组区域的序列聚集成簇，并保留了基因组区域的顺序性。背景是基因组测序会产生大量短核苷酸子序列，称为reads，这些reads需要被组装以重建完整的基因组。目的是开发一种方法来分析基因组测序数据，以更好地理解基因组结构，并应用于下游任务。方法是使用对比学习训练编码器模型，生成能够将来自同一基因组区域的序列聚集成簇的嵌入（embeddings）。该方法能够保留基因组区域的顺序性，并提供k-mer序列的一般表示。主要发现是该模型在模拟的古DNA（aDNA）read mapping和结构变异识别中表现出色，并且可以用于元基因组物种识别。通过引入特定的噪声模型和距离阈值参数Γ，可以增强嵌入的鲁棒性。该模型可以在没有全基因组组装的情况下，完全自监督地训练。结论是该方法在处理大规模基因组数据方面具有很好的扩展性，对于元基因组应用和与人类基因组大小相当的基因组映射具有很高的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequencing a genome to determine an individual's DNA produces an enormousnumber of short nucleotide subsequences known as reads, which must bereassembled to reconstruct the full genome. We present a method for analyzingthis type of data using contrastive learning, in which an encoder model istrained to produce embeddings that cluster together sequences from the samegenomic region. The sequential nature of genomic regions is preserved in theform of trajectories through this embedding space. Trained solely to reflectthe structure of the genome, the resulting model provides a generalrepresentation of $k$-mer sequences, suitable for a range of downstream tasksinvolving read data. We apply our framework to learn the structure of the $E.\coli$ genome, and demonstrate its use in simulated ancient DNA (aDNA) readmapping and identification of structural variations. Furthermore, we illustratethe potential of using this type of model for metagenomic speciesidentification. We show how incorporating a domain-specific noise model canenhance embedding robustness, and how a supervised contrastive learning settingcan be adopted when a linear reference genome is available, by introducing adistance thresholding parameter $\Gamma$. The model can also be trained fullyself-supervised on read data, enabling analysis without the need to construct afull genome assembly using specialized algorithms. Small prediction heads basedon a pre-trained embedding are shown to perform on par with BWA-aln, thecurrent gold standard approach for aDNA mapping, in terms of accuracy andruntime for short genomes. Given the method's favorable scaling properties withrespect to total genome size, inference using our approach is highly promisingfor metagenomic applications and for mapping to genomes comparable in size tothe human genome.</description>
      <author>example@mail.com (Filip Thor, Carl Nettelblad)</author>
      <guid isPermaLink="false">2505.16680v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Agentic 3D Scene Generation with Spatially Contextualized VLMs</title>
      <link>http://arxiv.org/abs/2505.20129v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的方法，使视觉语言模型（VLMs）能够通过注入不断演化的空间上下文来生成、理解和编辑复杂的3D环境。&lt;h4&gt;背景&lt;/h4&gt;尽管视觉语言模型在多模态内容生成方面取得了进展，但它们在处理和生成结构化3D场景方面的能力仍然未被充分探索，这限制了它们在空间基础任务中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的范式，使VLMs能够通过集成多模态推理能力和结构化3D理解来进行有效的空间推理。&lt;h4&gt;方法&lt;/h4&gt;该方法通过三个组件构建空间上下文：场景肖像提供高级语义蓝图，语义标记的点云捕捉对象级几何形状，场景超图编码丰富的空间关系，包括一元、二元和更高阶约束。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该框架可以处理多样化的输入，实现了先前工作中未见的一定程度的泛化。进一步的结果表明，注入空间上下文使VLMs能够执行交互式场景编辑和路径规划等下游任务。&lt;h4&gt;结论&lt;/h4&gt;这种方法为计算机图形学、3D视觉和具身应用中的空间智能系统提供了强大的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite recent advances in multimodal content generation enabled byvision-language models (VLMs), their ability to reason about and generatestructured 3D scenes remains largely underexplored. This limitation constrainstheir utility in spatially grounded tasks such as embodied AI, immersivesimulations, and interactive 3D applications. We introduce a new paradigm thatenables VLMs to generate, understand, and edit complex 3D environments byinjecting a continually evolving spatial context. Constructed from multimodalinput, this context consists of three components: a scene portrait thatprovides a high-level semantic blueprint, a semantically labeled point cloudcapturing object-level geometry, and a scene hypergraph that encodes richspatial relationships, including unary, binary, and higher-order constraints.Together, these components provide the VLM with a structured, geometry-awareworking memory that integrates its inherent multimodal reasoning capabilitieswith structured 3D understanding for effective spatial reasoning. Building onthis foundation, we develop an agentic 3D scene generation pipeline in whichthe VLM iteratively reads from and updates the spatial context. The pipelinefeatures high-quality asset generation with geometric restoration, environmentsetup with automatic verification, and ergonomic adjustment guided by the scenehypergraph. Experiments show that our framework can handle diverse andchallenging inputs, achieving a level of generalization not observed in priorwork. Further results demonstrate that injecting spatial context enables VLMsto perform downstream tasks such as interactive scene editing and pathplanning, suggesting strong potential for spatially intelligent systems incomputer graphics, 3D vision, and embodied applications.</description>
      <author>example@mail.com (Xinhang Liu, Yu-Wing Tai, Chi-Keung Tang)</author>
      <guid isPermaLink="false">2505.20129v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>An Out-Of-Distribution Membership Inference Attack Approach for Cross-Domain Graph Attacks</title>
      <link>http://arxiv.org/abs/2505.20074v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by the 34th International Joint Conference on Artificial  Intelligence (IJCAI-25)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对基于图神经网络的隐私泄露风险，提出了一种新的跨域图攻击方法，以应对现实世界中的分布多样性问题。&lt;h4&gt;背景&lt;/h4&gt;图神经网络方法由于引入了目标拓扑结构，存在隐私泄露风险，攻击者可以通过分析拓扑分布实现成员推理攻击（MIA）。随着隐私问题的加剧，MIA的假设（攻击者可以获得具有相同分布的辅助数据集）与实际情况逐渐脱节。&lt;h4&gt;目的&lt;/h4&gt;将现实世界MIA场景中的分布多样性问题归类为Out-Of-Distribution（OOD）问题，并提出一种名为GOOD-MIA的新方法，以实现跨域图攻击。&lt;h4&gt;方法&lt;/h4&gt;构建具有不同领域分布的影子子图，以模拟现实世界数据的多样性；探索在外部影响下保持不变的稳定节点表示；考虑消除混淆环境中的冗余信息，提取与任务相关的关键信息，以更清晰地区分训练数据和未见数据的特点；通过OOD设计实现跨域图攻击；在攻击推理过程中进行风险外推，优化攻击的领域适应性，以推广攻击到其他领域。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，GOOD-MIA在针对多领域设计的数据集上实现了优越的攻击性能。&lt;h4&gt;结论&lt;/h4&gt;GOOD-MIA是一种有效的跨域图攻击方法，能够应对现实世界中的分布多样性问题，提高图神经网络方法的隐私安全性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Network-based methods face privacy leakage risks due to theintroduction of topological structures about the targets, which allowsattackers to bypass the target's prior knowledge of the sensitive attributesand realize membership inference attacks (MIA) by observing and analyzing thetopology distribution. As privacy concerns grow, the assumption of MIA, whichpresumes that attackers can obtain an auxiliary dataset with the samedistribution, is increasingly deviating from reality. In this paper, wecategorize the distribution diversity issue in real-world MIA scenarios as anOut-Of-Distribution (OOD) problem, and propose a novel Graph OOD MembershipInference Attack (GOOD-MIA) to achieve cross-domain graph attacks.Specifically, we construct shadow subgraphs with distributions from differentdomains to model the diversity of real-world data. We then explore the stablenode representations that remain unchanged under external influences andconsider eliminating redundant information from confounding environments andextracting task-relevant key information to more clearly distinguish betweenthe characteristics of training data and unseen data. This OOD-based designmakes cross-domain graph attacks possible. Finally, we perform riskextrapolation to optimize the attack's domain adaptability during attackinference to generalize the attack to other domains. Experimental resultsdemonstrate that GOOD-MIA achieves superior attack performance in datasetsdesigned for multiple domains.</description>
      <author>example@mail.com (Jinyan Wang, Liu Yang, Yuecen Wei, Jiaxuan Si, Chenhao Guo, Qingyun Sun, Xianxian Li, Xingcheng Fu)</author>
      <guid isPermaLink="false">2505.20074v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Toward Patient-specific Partial Point Cloud to Surface Completion for Pre- to Intra-operative Registration in Image-guided Liver Interventions</title>
      <link>http://arxiv.org/abs/2505.19518v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于患者特定点云补全的方法，以辅助手术过程中的图像引导手术注册过程，解决术中点云部分可见性带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;在术中图像引导手术中，术中获取的数据缺乏对深层区域（如血管和肿瘤）的信息。图像到物理注册可以将术前信息与术中数据融合，但这一过程因术中点云的部分可见性而存在困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种患者特定的点云补全方法，以改善术中图像引导手术的注册过程。&lt;h4&gt;方法&lt;/h4&gt;利用VN-OccNet网络从部分术中点云生成完整的肝脏表面。网络通过术前模型的模拟变形进行训练。首先，深入分析了VN-OccNet的旋转等变性质及其在从部分术中表面恢复完整表面方面的有效性。然后，将补全的术中表面集成到Go-ICP注册算法中，以展示其在改善初始刚性注册结果方面的效用。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够有效地缓解术中点云部分可见性带来的挑战，VN-OccNet的旋转等变性和表面生成能力对于开发适用于术中点云变体的鲁棒注册框架具有很大潜力。&lt;h4&gt;结论&lt;/h4&gt;患者特定的点云补全方法在改善术中图像引导手术注册方面具有巨大潜力，VN-OccNet的性能为开发此类框架提供了强有力支持。&lt;h4&gt;翻译&lt;/h4&gt;Intra-operative data captured during image-guided surgery lacks sub-surface information, where key regions of interest, such as vessels and tumors, reside. Image-to-physical registration enables the fusion of pre-operative information and intra-operative data, typically represented as a point cloud. However, this registration process struggles due to partial visibility of the intra-operative point cloud. In this research, we propose a patient-specific point cloud completion approach to assist with the registration process. Specifically, we leverage VN-OccNet to generate a complete liver surface from a partial intra-operative point cloud. The network is trained in a patient-specific manner, where simulated deformations from the pre-operative model are used to train the model. First, we conduct an in-depth analysis of VN-OccNet's rotation-equivariant property and its effectiveness in recovering complete surfaces from partial intra-operative surfaces. Next, we integrate the completed intra-operative surface into the Go-ICP registration algorithm to demonstrate its utility in improving initial rigid registration outcomes. Our results highlight the promise of this patient-specific completion approach in mitigating the challenges posed by partial intra-operative visibility. The rotation equivariant and surface generation capabilities of VN-OccNet hold strong promise for developing robust registration frameworks for variations of the intra-operative point cloud.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Intra-operative data captured during image-guided surgery lacks sub-surfaceinformation, where key regions of interest, such as vessels and tumors, reside.Image-to-physical registration enables the fusion of pre-operative informationand intra-operative data, typically represented as a point cloud. However, thisregistration process struggles due to partial visibility of the intra-operativepoint cloud. In this research, we propose a patient-specific point cloudcompletion approach to assist with the registration process. Specifically, weleverage VN-OccNet to generate a complete liver surface from a partialintra-operative point cloud. The network is trained in a patient-specificmanner, where simulated deformations from the pre-operative model are used totrain the model. First, we conduct an in-depth analysis of VN-OccNet'srotation-equivariant property and its effectiveness in recovering completesurfaces from partial intra-operative surfaces. Next, we integrate thecompleted intra-operative surface into the Go-ICP registration algorithm todemonstrate its utility in improving initial rigid registration outcomes. Ourresults highlight the promise of this patient-specific completion approach inmitigating the challenges posed by partial intra-operative visibility. Therotation equivariant and surface generation capabilities of VN-OccNet holdstrong promise for developing robust registration frameworks for variations ofthe intra-operative point cloud.</description>
      <author>example@mail.com (Nakul Poudel, Zixin Yang, Kelly Merrell, Richard Simon, Cristian A. Linte)</author>
      <guid isPermaLink="false">2505.19518v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>TabPFN: One Model to Rule Them All?</title>
      <link>http://arxiv.org/abs/2505.20003v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Hollmann等人在《自然》杂志上介绍了TabPFN，这是一个基于Transformer的深度学习模型，用于表格数据的回归和分类。该模型在数据生成、密度估计、学习可重用嵌入和微调等方面具有潜力，可能超越现有的建模方法。&lt;h4&gt;背景&lt;/h4&gt;TabPFN是一种新的深度学习模型，用于处理表格数据，旨在解决现有方法的局限性。&lt;h4&gt;目的&lt;/h4&gt;解释TabPFN的工作原理，并证明其在各种统计任务上的优越性。&lt;h4&gt;方法&lt;/h4&gt;通过强调TabPFN作为近似贝叶斯推理的解释，并展示了其在半监督参数估计、协变量偏移下的预测和异质处理效应估计等方面的表现。&lt;h4&gt;主要发现&lt;/h4&gt;TabPFN在多个数据集上优于现有方法，包括在样本量高达10,000的数据集上。它在半监督参数估计、协变量偏移下的预测和异质处理效应估计方面优于专门的方法。在稀疏回归和分类中，TabPFN的性能优于LASSO，并能打破鲁棒性与效率之间的权衡。&lt;h4&gt;结论&lt;/h4&gt;TabPFN是一个强大的“基础模型”，在表格数据分析和统计任务中具有广泛应用前景。&lt;h4&gt;翻译&lt;/h4&gt;Hollmann等人最近在《自然》杂志上介绍了一种基于Transformer的深度学习模型TabPFN，用于表格数据的回归和分类。他们声称，在样本量高达10,000的数据集上，TabPFN以大幅度的优势优于所有以前的方法，并且使用的时间显著更少。他们还称TabPFN为表格数据的“基础模型”，因为它能够支持数据生成、密度估计、学习可重用嵌入和微调。如果这些声明得到充分的支持，TabPFN有可能在广泛的统计任务中超越现有的建模方法，类似于其他人工智能领域随着大型语言模型的兴起而开始的革命。在本文中，我们为统计学受众提供了一种对TabPFN工作原理的定制解释，强调将其解释为近似贝叶斯推理。我们还提供了更多关于TabPFN“基础模型”能力的证据：我们表明，TabPFN的即用型应用在半监督参数估计、协变量偏移下的预测和异质处理效应估计方面远远优于专门的最先进方法。我们进一步表明，TabPFN在稀疏回归中优于LASSO，并能在分类中打破鲁棒性与效率之间的权衡。所有实验都可以使用提供的代码在https://github.com/qinglong-tian/tabpfn_study进行重现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hollmann et al. (Nature 637 (2025) 319-326) recently introduced TabPFN, atransformer-based deep learning model for regression and classification ontabular data, which they claim "outperforms all previous methods on datasetswith up to 10,000 samples by a wide margin, using substantially less trainingtime." Furthermore, they have called TabPFN a "foundation model" for tabulardata, as it can support "data generation, density estimation, learning reusableembeddings and fine-tuning". If these statements are well-supported, TabPFN mayhave the potential to supersede existing modeling approaches on a wide range ofstatistical tasks, mirroring a similar revolution in other areas of artificialintelligence that began with the advent of large language models. In thispaper, we provide a tailored explanation of how TabPFN works for a statisticsaudience, by emphasizing its interpretation as approximate Bayesian inference.We also provide more evidence of TabPFN's "foundation model" capabilities: Weshow that an out-of-the-box application of TabPFN vastly outperformsspecialized state-of-the-art methods for semi-supervised parameter estimation,prediction under covariate shift, and heterogeneous treatment effectestimation. We further show that TabPFN can outperform LASSO at sparseregression and can break a robustness-efficiency trade-off in classification.All experiments can be reproduced using the code provided athttps://github.com/qinglong-tian/tabpfn_study(https://github.com/qinglong-tian/tabpfn_study).</description>
      <author>example@mail.com (Qiong Zhang, Yan Shuo Tan, Qinglong Tian, Pengfei Li)</author>
      <guid isPermaLink="false">2505.20003v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>LPCM: Learning-based Predictive Coding for LiDAR Point Cloud Compression</title>
      <link>http://arxiv.org/abs/2505.20059v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages long, 8 figures and over 50 references. Submitted with  IEEEtran journal mode. All figures are included in PDF format and the  bibliography is resolved manually&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于学习的预测编码方法（LPCM），用于高效压缩LiDAR点云数据，以降低存储和传输成本。&lt;h4&gt;背景&lt;/h4&gt;现有的基于学习的压缩方法未充分利用LiDAR的固有角分辨率，并且忽略了不同比特率下几何信息相关性的显著差异。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效预测和压缩LiDAR点云数据的方法，以降低存储和传输成本。&lt;h4&gt;方法&lt;/h4&gt;LPCM使用球坐标系将点云转换为预测树，并采用高比特率和低比特率编码模式。高比特率模式下使用LSTM-P模块预测和压缩高程角度，低比特率模式下使用变分半径压缩（VRC）模块直接压缩点径，并采用基于差分进化（DE）的量化参数选择方法。&lt;h4&gt;主要发现&lt;/h4&gt;LPCM在LiDAR基准数据集SemanticKITTI和MPEG指定的Ford数据集上的实验结果表明，其性能优于G-PCC和其他基于学习的压缩方法。&lt;h4&gt;结论&lt;/h4&gt;LPCM是一种有效的LiDAR点云压缩方法，能够显著降低存储和传输成本，并且具有优于现有方法的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于LiDAR点云数据量非常大，有效的压缩对于降低其存储和传输成本是必要的。然而，现有的基于学习的压缩方法没有利用LiDAR的固有角分辨率，并且忽略了不同比特率下几何信息相关性的显著差异。基于几何的点云压缩（G-PCC）标准中的预测几何编码方法使用固有角分辨率来预测方位角。然而，它仅模型化相邻点方位角之间简单线性关系。此外，它没有优化球坐标系中每个坐标轴上的残差量化参数。我们提出了一种具有高比特率和低比特率编码模式的基于学习的预测编码方法（LPCM）。LPCM使用球坐标系将点云转换为预测树。在高比特率编码模式下，我们使用基于轻量级长短期记忆（LSTM-P）模块来捕获不同坐标之间的长期几何相关性，以有效地预测和压缩高程角。在几何相关性下降的低比特率编码模式下，我们引入了变分半径压缩（VRC）模块来直接压缩点径。然后，我们分析了球坐标的量化与笛卡尔坐标的量化之间的差异，并提出了基于差分进化（DE）的量化参数选择方法，该方法在不增加编码时间的情况下提高了率失真性能。在LiDAR基准数据集SemanticKITTI和MPEG指定的Ford数据集上的实验结果表明，LPCM优于G-PCC和其他基于学习的压缩方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Since the data volume of LiDAR point clouds is very huge, efficientcompression is necessary to reduce their storage and transmission costs.However, existing learning-based compression methods do not exploit theinherent angular resolution of LiDAR and ignore the significant differences inthe correlation of geometry information at different bitrates. The predictivegeometry coding method in the geometry-based point cloud compression (G-PCC)standard uses the inherent angular resolution to predict the azimuth angles.However, it only models a simple linear relationship between the azimuth anglesof neighboring points. Moreover, it does not optimize the quantizationparameters for residuals on each coordinate axis in the spherical coordinatesystem. We propose a learning-based predictive coding method (LPCM) with bothhigh-bitrate and low-bitrate coding modes. LPCM converts point clouds intopredictive trees using the spherical coordinate system. In high-bitrate codingmode, we use a lightweight Long-Short-Term Memory-based predictive (LSTM-P)module that captures long-term geometry correlations between differentcoordinates to efficiently predict and compress the elevation angles. Inlow-bitrate coding mode, where geometry correlation degrades, we introduce avariational radius compression (VRC) module to directly compress the pointradii. Then, we analyze why the quantization of spherical coordinates differsfrom that of Cartesian coordinates and propose a differential evolution(DE)-based quantization parameter selection method, which improvesrate-distortion performance without increasing coding time. Experimentalresults on the LiDAR benchmark \textit{SemanticKITTI} and the MPEG-specified\textit{Ford} datasets show that LPCM outperforms G-PCC and otherlearning-based methods.</description>
      <author>example@mail.com (Chang Sun, Hui Yuan, Shiqi Jiang, Da Ai, Wei Zhang, Raouf Hamzaoui)</author>
      <guid isPermaLink="false">2505.20059v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>ViTaPEs: Visuotactile Position Encodings for Cross-Modal Alignment in Multimodal Transformers</title>
      <link>http://arxiv.org/abs/2505.20032v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ViTaPEs是一个基于transformer的框架，用于学习视觉触觉感知的任务无关表示，它有效地融合了视觉和触觉输入数据，并通过多尺度位置编码方案捕捉了跨模态的结构。&lt;h4&gt;背景&lt;/h4&gt;尽管在视觉触觉表示学习方面取得了进展，但融合这些模态以及在不同任务和环境之间泛化，而不依赖预训练的视觉语言模型，仍然存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出ViTaPEs框架，以学习视觉触觉感知的任务无关表示，并解决现有方法中未研究的位置编码问题。&lt;h4&gt;方法&lt;/h4&gt;ViTaPEs使用了一种新颖的多尺度位置编码方案来捕捉跨模态的结构，并提供了可证明的视觉触觉融合保证，同时通过实验验证了这些性质。&lt;h4&gt;主要发现&lt;/h4&gt;ViTaPEs在多个大规模真实世界数据集上的实验表明，它在各种识别任务中超越了最先进的基线，并展示了零样本泛化到未见过的域外场景的能力。&lt;h4&gt;结论&lt;/h4&gt;ViTaPEs在机器人抓取任务中表现出强大的迁移学习能力，在预测抓取成功方面优于最先进的基线。&lt;h4&gt;翻译&lt;/h4&gt;摘要：触觉感知提供了与视觉感知互补的局部重要信息，如纹理、顺应性和力。尽管在视觉触觉表示学习方面取得了进展，但在融合这些模态以及在不同任务和环境之间泛化，而不依赖预训练的视觉语言模型，仍然存在挑战。此外，现有方法没有研究位置编码，因此忽略了捕获细粒度视觉触觉相关性的多尺度空间推理需求。我们引入了ViTaPEs，这是一个基于transformer的框架，它能够稳健地整合视觉和触觉输入数据来学习视觉触觉感知的任务无关表示。我们的方法利用了一种新颖的多尺度位置编码方案来捕捉跨模态的结构，同时建模跨模态线索。与先前的工作不同，我们提供了视觉触觉融合的可证明保证，表明我们的编码是可注入的、刚体运动等变的，并且是信息保持的，这些性质通过实验得到了验证。在多个大规模真实世界数据集上的实验表明，ViTaPEs不仅在各种识别任务中超越了最先进的基线，而且还展示了零样本泛化到未见过的域外场景的能力。我们还在机器人抓取任务中进一步证明了ViTaPEs的迁移学习能力，在预测抓取成功方面优于最先进的基线。项目页面：https://sites.google.com/view/vitapes&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tactile sensing provides local essential information that is complementary tovisual perception, such as texture, compliance, and force. Despite recentadvances in visuotactile representation learning, challenges remain in fusingthese modalities and generalizing across tasks and environments without heavyreliance on pre-trained vision-language models. Moreover, existing methods donot study positional encodings, thereby overlooking the multi-scale spatialreasoning needed to capture fine-grained visuotactile correlations. Weintroduce ViTaPEs, a transformer-based framework that robustly integratesvisual and tactile input data to learn task-agnostic representations forvisuotactile perception. Our approach exploits a novel multi-scale positionalencoding scheme to capture intra-modal structures, while simultaneouslymodeling cross-modal cues. Unlike prior work, we provide provable guarantees invisuotactile fusion, showing that our encodings are injective,rigid-motion-equivariant, and information-preserving, validating theseproperties empirically. Experiments on multiple large-scale real-world datasetsshow that ViTaPEs not only surpasses state-of-the-art baselines across variousrecognition tasks but also demonstrates zero-shot generalization to unseen,out-of-domain scenarios. We further demonstrate the transfer-learning strengthof ViTaPEs in a robotic grasping task, where it outperforms state-of-the-artbaselines in predicting grasp success. Project page:https://sites.google.com/view/vitapes</description>
      <author>example@mail.com (Fotios Lygerakis, Ozan Özdenizci, Elmar Rückert)</author>
      <guid isPermaLink="false">2505.20032v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Hard Negative Contrastive Learning for Fine-Grained Geometric Understanding in Large Multimodal Models</title>
      <link>http://arxiv.org/abs/2505.20152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的硬负样本对比学习框架，用于视觉编码器，以增强几何理解能力，并在几何问题解决任务中取得了显著成果。&lt;h4&gt;背景&lt;/h4&gt;基于大规模自然场景图像的对比训练视觉编码器，大型多模态模型（LMMs）在视觉感知任务上取得了显著性能。然而，对比学习在总结描述上的固有局限性限制了模型在细致推理，尤其是在几何问题解决的关键场景中的能力。&lt;h4&gt;目的&lt;/h4&gt;为了提高几何理解能力，提出了一种新的硬负样本对比学习框架。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了基于图像的对比学习，通过扰动图生成代码创建基于生成的硬负样本，以及基于文本的对比学习，使用基于规则的负样本和基于检索的负样本。使用MMCLIP（多模态数学CLIP）训练CLIP，然后训练LMM进行几何问题解决。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，训练出的模型MMGeoLM在三个几何推理基准测试中显著优于其他开源模型，即使模型规模达到7B，也能与GPT-4o等强大的闭源模型相媲美。研究了不同负样本构建方法和负样本数量对LMM几何推理性能的影响，得出了有价值的结论。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提高了LMM在几何问题解决上的能力，为多模态模型在几何推理领域的应用提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;Benefiting from contrastively trained visual encoders on large-scale naturalscene images, Large Multimodal Models (LMMs) have achieved remarkableperformance across various visual perception tasks. However, the inherentlimitations of contrastive learning upon summarized descriptions fundamentallyrestrict the capabilities of models in meticulous reasoning, particularlyincrucial scenarios of geometric problem-solving. To enhance geometricunderstanding, we propose a novel hard negative contrastive learning frameworkfor the vision encoder, which combines image-based contrastive learning usinggeneration-based hard negatives created by perturbing diagram generation code,and text-based contrastive learning using rule-based negatives derived frommodified geometric descriptions and retrieval-based negatives selected based oncaption similarity. We train CLIP using our strong negative learning method,namely MMCLIP (Multimodal Math CLIP), and subsequently train an LMM forgeometric problem-solving. Experiments show that our trained model, MMGeoLM,significantly outperforms other open-source models on three geometric reasoningbenchmarks. Even with a size of 7B, it can rival powerful closed-source modelslike GPT-4o. We further study the impact of different negative sampleconstruction methods and the number of negative samples on the geometricreasoning performance of LMM, yielding fruitful conclusions. The code anddataset are available at https://github.com/THU-KEG/MMGeoLM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Benefiting from contrastively trained visual encoders on large-scale naturalscene images, Large Multimodal Models (LMMs) have achieved remarkableperformance across various visual perception tasks. However, the inherentlimitations of contrastive learning upon summarized descriptions fundamentallyrestrict the capabilities of models in meticulous reasoning, particularly incrucial scenarios of geometric problem-solving. To enhance geometricunderstanding, we propose a novel hard negative contrastive learning frameworkfor the vision encoder, which combines image-based contrastive learning usinggeneration-based hard negatives created by perturbing diagram generation code,and text-based contrastive learning using rule-based negatives derived frommodified geometric descriptions and retrieval-based negatives selected based oncaption similarity. We train CLIP using our strong negative learning method,namely MMCLIP (Multimodal Math CLIP), and subsequently train an LMM forgeometric problem-solving. Experiments show that our trained model, MMGeoLM,significantly outperforms other open-source models on three geometric reasoningbenchmarks. Even with a size of 7B, it can rival powerful closed-source modelslike GPT-4o. We further study the impact of different negative sampleconstruction methods and the number of negative samples on the geometricreasoning performance of LMM, yielding fruitful conclusions. The code anddataset are available at https://github.com/THU-KEG/MMGeoLM.</description>
      <author>example@mail.com (Kai Sun, Yushi Bai, Zhen Yang, Jiajie Zhang, Ji Qi, Lei Hou, Juanzi Li)</author>
      <guid isPermaLink="false">2505.20152v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Graph Wave Networks</title>
      <link>http://arxiv.org/abs/2505.20034v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 8 figures, published to WWW 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于波传播的图神经网络消息传递（MP）动力学模型，旨在提高图神经网络在处理图信号时的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的图神经网络方法将节点间的消息传递视为热扩散过程，并利用热方程来模拟节点在嵌入空间中的时间演化。然而，热方程难以描述图信号的处理中的波动特性，且其数值解稳定性低，导致模型训练效率低下。&lt;h4&gt;目的&lt;/h4&gt;为了更准确地描述图信号中的波动细节，本文将消息传递视为波传播过程，以捕捉波信号在空间中的时间演化。&lt;h4&gt;方法&lt;/h4&gt;基于物理中的波动方程，本文创新性地提出了一种图波动方程，以利用图上的波传播。具体来说，证明了图波动方程可以与传统光谱图神经网络相连接，便于基于不同拉普拉斯算子的图波动网络的设计，并提高光谱图神经网络的表现。此外，图波动方程是一个涉及时间二阶偏导数的偏微分方程（PDE），在图上的稳定性比涉及时间一阶偏导数的热方程更强。&lt;h4&gt;主要发现&lt;/h4&gt;理论证明了从图波动方程导出的数值解是稳定的，这可以显著提高模型效率同时确保其性能。大量实验表明，图波动网络在基准数据集上实现了最先进的（SOTA）和高效的性能，并在解决诸如过平滑和异质性等挑战性图问题上表现出色。&lt;h4&gt;结论&lt;/h4&gt;图波动网络通过模拟波传播过程，提高了图神经网络处理图信号的性能，特别是在解决过平滑和异质性等复杂图问题上具有显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.371467&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamics modeling has been introduced as a novel paradigm in message passing(MP) of graph neural networks (GNNs). Existing methods consider MP betweennodes as a heat diffusion process, and leverage heat equation to model thetemporal evolution of nodes in the embedding space. However, heat equation canhardly depict the wave nature of graph signals in graph signal processing.Besides, heat equation is essentially a partial differential equation (PDE)involving a first partial derivative of time, whose numerical solution usuallyhas low stability, and leads to inefficient model training. In this paper, wewould like to depict more wave details in MP, since graph signals areessentially wave signals that can be seen as a superposition of a series ofwaves in the form of eigenvector. This motivates us to consider MP as a wavepropagation process to capture the temporal evolution of wave signals in thespace. Based on wave equation in physics, we innovatively develop a graph waveequation to leverage the wave propagation on graphs. In details, we demonstratethat the graph wave equation can be connected to traditional spectral GNNs,facilitating the design of graph wave networks based on various Laplacians andenhancing the performance of the spectral GNNs. Besides, the graph waveequation is particularly a PDE involving a second partial derivative of time,which has stronger stability on graphs than the heat equation that involves afirst partial derivative of time. Additionally, we theoretically prove that thenumerical solution derived from the graph wave equation are constantly stable,enabling to significantly enhance model efficiency while ensuring itsperformance. Extensive experiments show that GWNs achieve SOTA and efficientperformance on benchmark datasets, and exhibit outstanding performance inaddressing challenging graph problems, such as over-smoothing and heterophily.</description>
      <author>example@mail.com (Juwei Yue, Haikuo Li, Jiawei Sheng, Yihan Guo, Xinghua Zhang, Chuan Zhou, Tingwen Liu, Li Guo)</author>
      <guid isPermaLink="false">2505.20034v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>TUNA: Comprehensive Fine-grained Temporal Understanding Evaluation on Dense Dynamic Videos</title>
      <link>http://arxiv.org/abs/2505.20124v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025 Main. Project page:  https://friedrichor.github.io/projects/TUNA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了TUNA，一个针对密集动态视频的细粒度理解的时间导向基准，包含视频描述和问答两个互补任务，旨在全面理解视频内容。&lt;h4&gt;背景&lt;/h4&gt;现有的视频理解基准通常将视频的时序元素（如摄像机、场景、动作和属性）分开处理，或仅关注特定方面，忽略了视频内容的整体性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出TUNA基准，以全面理解视频内容。&lt;h4&gt;方法&lt;/h4&gt;TUNA基准包含多样化的视频场景和动态，并辅以可解释和鲁棒的评估标准。在基准上评估了多个领先模型，提供了跨多个维度的细粒度性能评估。&lt;h4&gt;主要发现&lt;/h4&gt;评估揭示了视频时序理解中的关键挑战，如动作描述有限、对多主体理解不足和对摄像机运动的敏感性不足。&lt;h4&gt;结论&lt;/h4&gt;TUNA基准为改进视频理解模型提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视频的独特之处在于其时序元素的整合，包括摄像机、场景、动作和属性，以及随时间变化的动态关系。然而，现有的视频理解基准通常将这些属性分开处理，或者过于狭窄地关注特定方面，忽略了视频内容的整体性。为了解决这个问题，我们引入了TUNA，这是一个针对密集动态视频的细粒度理解的时间导向基准，包含两个互补任务：视频描述和问答。TUNA基准具有多样化的视频场景和动态，并辅以可解释和鲁棒的评估标准。我们在我们的基准上评估了几个领先模型，提供了跨多个维度的细粒度性能评估。这种评估揭示了视频时序理解中的关键挑战，如动作描述有限、对多主体理解不足和对摄像机运动的敏感性不足，为改进视频理解模型提供了有价值的见解。数据和代码可在https://friedrichor.github.io/projects/TUNA获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/friedrichor/TUNA&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Videos are unique in their integration of temporal elements, includingcamera, scene, action, and attribute, along with their dynamic relationshipsover time. However, existing benchmarks for video understanding often treatthese properties separately or narrowly focus on specific aspects, overlookingthe holistic nature of video content. To address this, we introduce TUNA, atemporal-oriented benchmark for fine-grained understanding on dense dynamicvideos, with two complementary tasks: captioning and QA. Our TUNA featuresdiverse video scenarios and dynamics, assisted by interpretable and robustevaluation criteria. We evaluate several leading models on our benchmark,providing fine-grained performance assessments across various dimensions. Thisevaluation reveals key challenges in video temporal understanding, such aslimited action description, inadequate multi-subject understanding, andinsensitivity to camera motion, offering valuable insights for improving videounderstanding models. The data and code are available athttps://friedrichor.github.io/projects/TUNA.</description>
      <author>example@mail.com (Fanheng Kong, Jingyuan Zhang, Hongzhi Zhang, Shi Feng, Daling Wang, Linhao Yu, Xingguang Ji, Yu Tian, Qi Wang, Fuzheng Zhang)</author>
      <guid isPermaLink="false">2505.20124v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>A Coarse to Fine 3D LiDAR Localization with Deep Local Features for Long Term Robot Navigation in Large Environments</title>
      <link>http://arxiv.org/abs/2505.18340v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种解决未知初始姿态的机器人全局定位问题的方法，该方法结合了蒙特卡洛定位（MCL）方法和深度学习模型，并在动态环境中进行了验证。&lt;h4&gt;背景&lt;/h4&gt;机器人在移动机器人领域中的位置定位是一个关键问题，特别是在初始姿态未知的情况下。&lt;h4&gt;目的&lt;/h4&gt;研究并提出一种有效的方法来解决机器人全局定位问题。&lt;h4&gt;方法&lt;/h4&gt;采用从粗到细的解决方案，粗定位基于MCL方法，利用MinkUNeXt神经网络生成3D激光雷达点云的鲁棒描述。细定位则通过全局点云配准实现，MinkUNeXt的中间层输出用于生成局部特征，以实现精确对齐。同时，还实施了一种经典ICP方法（MCL-ICP）用于比较。&lt;h4&gt;主要发现&lt;/h4&gt;MCL-DLF方法在动态环境中能够获得准确的机器人定位估计，即使在环境条件变化的情况下。&lt;h4&gt;结论&lt;/h4&gt;MCL-DLF方法在动态环境中具有优越的性能，并且代码已公开。&lt;h4&gt;翻译&lt;/h4&gt;The location of a robot is a key aspect in the field of mobile robotics. This problem is particularly complex when the initial pose of the robot is unknown. In order to find a solution, it is necessary to perform a global localization. This paper proposes a method that addresses this problem using a coarse-to-fine solution. The coarse localization relies on a probabilistic approach of the Monte Carlo Localization (MCL) method, with the contribution of a robust deep learning model, the MinkUNeXt neural network, to produce a robust description of point clouds of a 3D LiDAR within the observation model. For fine localization, global point cloud registration has been implemented. MinkUNeXt aids this by exploiting the outputs of its intermediate layers to produce deep local features for each point in a scan. These features facilitate precise alignment between the current sensor observation and one of the point clouds on the map. The proposed MCL method incorporating Deep Local Features for fine localization is termed MCL-DLF. Alternatively, a classical ICP method has been implemented for this precise localization aiming at comparison purposes. This method is termed MCL-ICP. In order to validate the performance of MCL-DLF method, it has been tested on publicly available datasets such as the NCLT dataset, which provides seasonal large-scale environments. Additionally, tests have been also performed with own data (UMH) that also includes seasonal variations on large indoor/outdoor scenarios. The results, which were compared with established state-of-the-art methodologies, demonstrate that the MCL-DLF method obtains an accurate estimate of the robot localization in dynamic environments despite changes in environmental conditions. For reproducibility purposes, the code is publicly available at https://github.com/miriammaximo/MCL-DLF.git&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The location of a robot is a key aspect in the field of mobile robotics. Thisproblem is particularly complex when the initial pose of the robot is unknown.In order to find a solution, it is necessary to perform a global localization.In this paper, we propose a method that addresses this problem using acoarse-to-fine solution. The coarse localization relies on a probabilisticapproach of the Monte Carlo Localization (MCL) method, with the contribution ofa robust deep learning model, the MinkUNeXt neural network, to produce a robustdescription of point clouds of a 3D LiDAR within the observation model. Forfine localization, global point cloud registration has been implemented.MinkUNeXt aids this by exploiting the outputs of its intermediate layers toproduce deep local features for each point in a scan. These features facilitateprecise alignment between the current sensor observation and one of the pointclouds on the map. The proposed MCL method incorporating Deep Local Featuresfor fine localization is termed MCL-DLF. Alternatively, a classical ICP methodhas been implemented for this precise localization aiming at comparisonpurposes. This method is termed MCL-ICP. In order to validate the performanceof MCL-DLF method, it has been tested on publicly available datasets such asthe NCLT dataset, which provides seasonal large-scale environments.Additionally, tests have been also performed with own data (UMH) that alsoincludes seasonal variations on large indoor/outdoor scenarios. The results,which were compared with established state-of-the-art methodologies,demonstrate that the MCL-DLF method obtains an accurate estimate of the robotlocalization in dynamic environments despite changes in environmentalconditions. For reproducibility purposes, the code is publicly available athttps://github.com/miriammaximo/MCL-DLF.git</description>
      <author>example@mail.com (Míriam Máximo, Antonio Santo, Arturo Gil, Mónica Ballesta, David Valiente)</author>
      <guid isPermaLink="false">2505.18340v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>GraphAU-Pain: Graph-based Action Unit Representation for Pain Intensity Estimation</title>
      <link>http://arxiv.org/abs/2505.19802v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GraphAU-Pain的方法，用于通过面部表情检测疼痛强度，旨在提高数字医疗中的疼痛监测、辅助诊断和治疗规划的有效性。&lt;h4&gt;背景&lt;/h4&gt;理解与疼痛相关的面部行为对于数字医疗至关重要，尤其是对于无法通过言语沟通的患者。现有的基于数据的方法在疼痛检测的解读性和严重程度量化方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出GraphAU-Pain方法，利用图神经网络框架来建模面部动作单元（AUs）及其相互关系，以实现疼痛强度的估计。&lt;h4&gt;方法&lt;/h4&gt;GraphAU-Pain方法将AUs表示为图节点，共现关系作为边，从而更直观地描述与疼痛相关的面部行为。通过使用关系图神经网络，该框架提供了更好的可解释性和显著的性能提升。&lt;h4&gt;主要发现&lt;/h4&gt;在公开可用的UNBC数据集上进行的实验表明，GraphAU-Pain方法在疼痛强度估计方面是有效的，实现了66.21%的F1分数和87.61%的准确率。&lt;h4&gt;结论&lt;/h4&gt;GraphAU-Pain方法为数字医疗中的疼痛监测和诊断提供了一种有效的解决方案，具有较好的可解释性和性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding pain-related facial behaviors is essential for digitalhealthcare in terms of effective monitoring, assisted diagnostics, andtreatment planning, particularly for patients unable to communicate verbally.Existing data-driven methods of detecting pain from facial expressions arelimited due to interpretability and severity quantification. To this end, wepropose GraphAU-Pain, leveraging a graph-based framework to model facial ActionUnits (AUs) and their interrelationships for pain intensity estimation. AUs arerepresented as graph nodes, with co-occurrence relationships as edges, enablinga more expressive depiction of pain-related facial behaviors. By utilizing arelational graph neural network, our framework offers improved interpretabilityand significant performance gains. Experiments conducted on the publiclyavailable UNBC dataset demonstrate the effectiveness of the GraphAU-Pain,achieving an F1-score of 66.21% and accuracy of 87.61% in pain intensityestimation.</description>
      <author>example@mail.com (Zhiyu Wang, Yang Liu, Hatice Gunes)</author>
      <guid isPermaLink="false">2505.19802v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Staircase Recognition and Location Based on Polarization Vision</title>
      <link>http://arxiv.org/abs/2505.19026v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了楼梯场景感知技术在机器人导航和下肢残疾人或视觉障碍者辅助行走中的应用，并提出了基于偏振和光强信息融合的对比增强算法，以及融合偏振双目和TOF深度信息的三维重建方法。&lt;h4&gt;背景&lt;/h4&gt;楼梯场景在人工环境中很常见，但机器人和人需要借助传感器和智能算法才能安全通过。&lt;h4&gt;目的&lt;/h4&gt;提高楼梯场景的识别准确率，减少传感器初始噪声，稳定输出信号，降低计算需求。&lt;h4&gt;方法&lt;/h4&gt;提出了一种融合偏振和光强信息的对比增强算法，并基于YOLOv11进行点云分割；同时，融合偏振双目和TOF深度信息实现楼梯的三维重建；此外，还提出了基于ICP注册和改进灰狼优化算法的单目相机和TOF相机联合标定算法。&lt;h4&gt;主要发现&lt;/h4&gt;偏振重建方法受环境光影响较小，不依赖于物体表面的纹理信息。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高楼梯场景的识别准确率，并实现高质量的三维重建。&lt;h4&gt;翻译&lt;/h4&gt;This paper discusses the application of staircase scene perception technology in robot navigation and assistance for people with lower limb disabilities or visual impairments. It proposes a contrast enhancement algorithm that integrates polarization and light intensity information, and a method of fusing polarized binocular and TOF depth information for three-dimensional reconstruction of the staircase. In addition, it also proposes a joint calibration algorithm for monocular camera and TOF camera based on ICP registration and improved gray wolf optimization algorithm.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Staircase is one of the most common structures in artificial scenes. However,it is difficult for humanoid robots and people with lower limb disabilities orvisual impairment to cross the scene without the help of sensors andintelligent algorithms. Staircase scene perception technology is a prerequisitefor recognition and localization. This technology is of great significance forthe mode switching of the robot and the calculation of the footprint positionto adapt to the discontinuous terrain. However, there are still many problemsthat constrain the application of this technology, such as low recognitionaccuracy, high initial noise from sensors, unstable output signals and highcomputational requirements. In terms of scene reconstruction, the binocular andtime of flight (TOF) reconstruction of the scene can be easily affected byenvironmental light and the surface material of the target object. In contrast,due to the special structure of the polarizer, the polarization can selectivelytransmit polarized light in a specific direction and this reconstruction methodrelies on the polarization information of the object surface. So the advantagesof polarization reconstruction are reflected, which are less affected byenvironmental light and not dependent on the texture information of the objectsurface. In this paper, in order to achieve the detection of staircase, thispaper proposes a contrast enhancement algorithm that integrates polarizationand light intensity information, and integrates point cloud segmentation basedon YOLOv11. To realize the high-quality reconstruction, we proposed a method offusing polarized binocular and TOF depth information to realize thethree-dimensional (3D) reconstruction of the staircase. Besides, it alsoproposes a joint calibration algorithm of monocular camera and TOF camera basedon ICP registration and improved gray wolf optimization algorithm.</description>
      <author>example@mail.com (Weifeng Kong, Zhiying Tan)</author>
      <guid isPermaLink="false">2505.19026v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Unifying Multimodal Large Language Model Capabilities and Modalities via Model Merging</title>
      <link>http://arxiv.org/abs/2505.19892v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种针对多模态大型语言模型（MLLM）的模型合并基准，并探讨了如何通过模型合并结合不同模态，实现通用语言模型。此外，提出了一种新的模型合并算法，并展示了模型合并在不需数据训练的情况下提升MLLM性能的潜力。&lt;h4&gt;背景&lt;/h4&gt;由于资源密集的训练需求，基础模型更新缓慢，而特定领域的模型在更新之间会进化。模型合并旨在将多个专家模型合并为一个更强大的模型，从而降低存储和服务成本，并支持去中心化的模型开发。&lt;h4&gt;目的&lt;/h4&gt;构建一个模型合并基准，用于MLLM的训练和评估，并探索如何结合不同模态，实现通用语言模型。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种模型合并基准，包括多个任务如VQA、几何、图表、OCR和Grounding，并提供了LoRA和全微调模型。同时，实现了10种模型合并算法，并提出了一种新的方法来去除任务向量中的噪声，并基于任务向量交互定义的损失进行优化。&lt;h4&gt;主要发现&lt;/h4&gt;模型合并为构建改进的MLLM提供了一种有希望的方法，无需数据训练。研究结果表明，多模态之间的互补性优于单个模态。&lt;h4&gt;结论&lt;/h4&gt;模型合并能够有效提升MLLM的性能，且不同模态的结合比单个模态更有优势。&lt;h4&gt;翻译&lt;/h4&gt;While foundation models update slowly due to resource-intensive training requirements, domain-specific models evolve between updates. Model merging aims to combine multiple expert models into a single, more capable model, thereby reducing storage and serving costs while supporting decentralized model development. Despite its potential, previous studies have primarily focused on merging visual classification models or Large Language Models (LLMs) for code and math tasks. Multimodal Large Language Models (MLLMs), which extend the capabilities of LLMs through large-scale multimodal training, have gained traction. However, there lacks a benchmark for model merging research that clearly divides the tasks for MLLM training and evaluation. In this paper, (i) we introduce the model merging benchmark for MLLMs, which includes multiple tasks such as VQA, Geometry, Chart, OCR, and Grounding, providing both LoRA and full fine-tuning models. Moreover, we explore how model merging can combine different modalities (e.g., vision-language, audio-language, and video-language models), moving toward the Omni-language model. (ii) We implement 10 model merging algorithms on the benchmark. Furthermore, we propose a novel method that removes noise from task vectors and robustly optimizes the merged vector based on a loss defined over task vector interactions, achieving an average performance gain of 2.48%. (iii) We find that model merging offers a promising way for building improved MLLMs without requiring data training. Our results also demonstrate that the complementarity among multiple modalities outperforms individual modalities.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While foundation models update slowly due to resource-intensive trainingrequirements, domain-specific models evolve between updates. Model merging aimsto combine multiple expert models into a single, more capable model, therebyreducing storage and serving costs while supporting decentralized modeldevelopment. Despite its potential, previous studies have primarily focused onmerging visual classification models or Large Language Models (LLMs) for codeand math tasks. Multimodal Large Language Models (MLLMs), which extend thecapabilities of LLMs through large-scale multimodal training, have gainedtraction. However, there lacks a benchmark for model merging research thatclearly divides the tasks for MLLM training and evaluation. In this paper, (i)we introduce the model merging benchmark for MLLMs, which includes multipletasks such as VQA, Geometry, Chart, OCR, and Grounding, providing both LoRA andfull fine-tuning models. Moreover, we explore how model merging can combinedifferent modalities (e.g., vision-language, audio-language, and video-languagemodels), moving toward the Omni-language model. (ii) We implement 10 modelmerging algorithms on the benchmark. Furthermore, we propose a novel methodthat removes noise from task vectors and robustly optimizes the merged vectorbased on a loss defined over task vector interactions, achieving an averageperformance gain of 2.48%. (iii) We find that model merging offers a promisingway for building improved MLLMs without requiring data training. Our resultsalso demonstrate that the complementarity among multiple modalities outperformsindividual modalities.</description>
      <author>example@mail.com (Yongxian Wei, Runxi Cheng, Weike Jin, Enneng Yang, Li Shen, Lu Hou, Sinan Du, Chun Yuan, Xiaochun Cao, Dacheng Tao)</author>
      <guid isPermaLink="false">2505.19892v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Reasoning Agent for Zero-Shot Composed Image Retrieval</title>
      <link>http://arxiv.org/abs/2505.19952v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个名为Zero-Shot Composed Image Retrieval (ZS-CIR)的框架，旨在通过使用多模态推理代理（MRA）来改进零样本复合图像检索的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的ZS-CIR方法依赖于大型语言模型生成中间文本作为查询和目标图像之间的锚点，这可能导致误差累积并降低检索性能。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的框架，通过直接使用未标记的图像数据构建三元组（参考图像，修改文本，目标图像），来减少对中间文本的依赖。&lt;h4&gt;方法&lt;/h4&gt;采用多模态推理代理（MRA）来直接构造三元组，并在这些合成三元组上训练模型，以学习复合查询与候选图像之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;在三个标准的CIR基准数据集上进行了实验，结果显示该方法在FashionIQ数据集上提高了7.5%的平均R@10，在CIRR上提高了9.6%的R@1，在CIRCO上提高了9.5%的mAP@5。&lt;h4&gt;结论&lt;/h4&gt;该方法在零样本复合图像检索中表现出色，能够有效提高检索性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Zero-Shot Composed Image Retrieval (ZS-CIR) aims to retrieve target imagesgiven a compositional query, consisting of a reference image and a modifyingtext-without relying on annotated training data. Existing approaches oftengenerate a synthetic target text using large language models (LLMs) to serve asan intermediate anchor between the compositional query and the target image.Models are then trained to align the compositional query with the generatedtext, and separately align images with their corresponding texts usingcontrastive learning. However, this reliance on intermediate text introduceserror propagation, as inaccuracies in query-to-text and text-to-image mappingsaccumulate, ultimately degrading retrieval performance. To address theseproblems, we propose a novel framework by employing a Multimodal ReasoningAgent (MRA) for ZS-CIR. MRA eliminates the dependence on textual intermediariesby directly constructing triplets, &lt;reference image, modification text, targetimage&gt;, using only unlabeled image data. By training on these synthetictriplets, our model learns to capture the relationships between compositionalqueries and candidate images directly. Extensive experiments on three standardCIR benchmarks demonstrate the effectiveness of our approach. On the FashionIQdataset, our method improves Average R@10 by at least 7.5\% over existingbaselines; on CIRR, it boosts R@1 by 9.6\%; and on CIRCO, it increases mAP@5 by9.5\%.</description>
      <author>example@mail.com (Rong-Cheng Tu, Wenhao Sun, Hanzhe You, Yingjie Wang, Jiaxing Huang, Li Shen, Dacheng Tao)</author>
      <guid isPermaLink="false">2505.19952v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>FruitNeRF++: A Generalized Multi-Fruit Counting Method Utilizing Contrastive Learning and Neural Radiance Fields</title>
      <link>http://arxiv.org/abs/2505.19863v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  for project website, see https://meyerls.github.io/fruit_nerfpp&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为FruitNeRF++的果实计数方法，该方法结合了对比学习和神经辐射场，从非结构化果园照片中计数果实。&lt;h4&gt;背景&lt;/h4&gt;FruitNeRF方法使用神经语义场和特定于果实的聚类方法，但需要针对每种果实类型进行适配，限制了方法的适用性和实用性。&lt;h4&gt;目的&lt;/h4&gt;设计一个形状无关的多果实计数框架，以解决FruitNeRF方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;使用视觉基础模型预测实例掩码，将每个果实的身份编码为实例嵌入到神经实例场中，通过体素采样神经场，提取带有实例特征的点云，以果实无关的方式对其进行聚类，从而获得果实计数。&lt;h4&gt;主要发现&lt;/h4&gt;使用包含苹果、李子、柠檬、梨、桃子和芒果的合成数据集以及真实的苹果数据集进行了评估，结果表明FruitNeRF++易于控制，与其他最先进的方法相比具有竞争力。&lt;h4&gt;结论&lt;/h4&gt;FruitNeRF++是一种有效的果实计数方法，易于使用，并且性能优于其他现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce FruitNeRF++, a novel fruit-counting approach that combinescontrastive learning with neural radiance fields to count fruits fromunstructured input photographs of orchards. Our work is based on FruitNeRF,which employs a neural semantic field combined with a fruit-specific clusteringapproach. The requirement for adaptation for each fruit type limits theapplicability of the method, and makes it difficult to use in practice. To liftthis limitation, we design a shape-agnostic multi-fruit counting framework,that complements the RGB and semantic data with instance masks predicted by avision foundation model. The masks are used to encode the identity of eachfruit as instance embeddings into a neural instance field. By volumetricallysampling the neural fields, we extract a point cloud embedded with the instancefeatures, which can be clustered in a fruit-agnostic manner to obtain the fruitcount. We evaluate our approach using a synthetic dataset containing apples,plums, lemons, pears, peaches, and mangoes, as well as a real-world benchmarkapple dataset. Our results demonstrate that FruitNeRF++ is easier to controland compares favorably to other state-of-the-art methods.</description>
      <author>example@mail.com (Lukas Meyer, Andrei-Timotei Ardelean, Tim Weyrich, Marc Stamminger)</author>
      <guid isPermaLink="false">2505.19863v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Equivariant Representation Learning for Symmetry-Aware Inference with Guarantees</title>
      <link>http://arxiv.org/abs/2505.19809v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种等变表示学习框架，用于回归、条件概率估计和不确定性量化，同时提供了非渐近性的统计学习保证。&lt;h4&gt;背景&lt;/h4&gt;在许多实际应用中，利用物理或几何中的对称性可以显著提高泛化能力和样本效率。尽管几何深度学习通过结合群论结构取得了显著的经验进展，但对其统计学习保证的关注较少。&lt;h4&gt;目的&lt;/h4&gt;同时解决回归、条件概率估计和不确定性量化问题，并提供前所未有的非渐近性统计学习保证。&lt;h4&gt;方法&lt;/h4&gt;该框架基于算子与群表示理论，近似条件期望算子的谱分解，构建既等变又解耦的表示。&lt;h4&gt;主要发现&lt;/h4&gt;在合成数据集和现实世界的机器人应用中的实证评估证实了该方法的潜力，在回归任务中与现有等变基线相当甚至优于它们，同时提供了良好校准的参数不确定性估计。&lt;h4&gt;结论&lt;/h4&gt;该方法在回归和不确定性量化方面具有显著优势，为等变表示学习提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In many real-world applications of regression, conditional probabilityestimation, and uncertainty quantification, exploiting symmetries rooted inphysics or geometry can dramatically improve generalization and sampleefficiency. While geometric deep learning has made significant empiricaladvances by incorporating group-theoretic structure, less attention has beengiven to statistical learning guarantees. In this paper, we introduce anequivariant representation learning framework that simultaneously addressesregression, conditional probability estimation, and uncertainty quantificationwhile providing first-of-its-kind non-asymptotic statistical learningguarantees. Grounded in operator and group representation theory, our frameworkapproximates the spectral decomposition of the conditional expectationoperator, building representations that are both equivariant and disentangledalong independent symmetry subgroups. Empirical evaluations on syntheticdatasets and real-world robotics applications confirm the potential of ourapproach, matching or outperforming existing equivariant baselines inregression while additionally providing well-calibrated parametric uncertaintyestimates.</description>
      <author>example@mail.com (Daniel Ordoñez-Apraez, Alek Fröhlich, Vladimir Kostić, Karim Lounici, Vivien Brandt, Massimiliano Pontil)</author>
      <guid isPermaLink="false">2505.19809v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Generalized and Personalized Federated Learning with Foundation Models via Orthogonal Transformations</title>
      <link>http://arxiv.org/abs/2505.19888v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FedOT是一种基于黑盒基础模型的联邦学习新方法，旨在解决异构环境中模型泛化与个性化的挑战。&lt;h4&gt;背景&lt;/h4&gt;联邦学习旨在在分布式客户端或设备上训练模型，无需集中式数据收集，以增强数据隐私和安全。&lt;h4&gt;目的&lt;/h4&gt;解决异构环境中模型泛化与个性化的问题。&lt;h4&gt;方法&lt;/h4&gt;FedOT通过在客户端之间共享全局任务依赖的分类器，并通过正交变换局部调整特征来实现。&lt;h4&gt;主要发现&lt;/h4&gt;通过强制正交性，FedOT减轻了不同客户端之间的梯度冲突，保留了语义完整性，并在存在大量数据异质性的情况下实现了稳健的性能。&lt;h4&gt;结论&lt;/h4&gt;FedOT的全球和局部参数结合策略为泛化与个性化提供了更平衡的方法，并在多个基准测试中优于基线联邦学习方法。&lt;h4&gt;翻译&lt;/h4&gt;联邦学习（FL）旨在在不进行集中式数据收集的情况下，在持有本地数据的去中心化客户端或设备上训练模型，从而增强数据隐私和安全。然而，在异构环境中实现泛化和个性化仍然是一个重大挑战。为了解决这个问题，我们引入了FedOT，这是一种利用黑盒基础模型的新方法。FedOT在客户端之间共享一个全局任务依赖的分类器，同时通过正交变换局部调整特征。通过强制正交性，FedOT减轻了不同客户端之间的梯度冲突，保留了语义完整性，即使在存在大量数据异质性的情况下也能实现稳健的性能。结合全球和局部参数的策略为泛化和个性化提供了更平衡的方法，在多个基准测试中优于基线联邦学习方法。此外，我们的广泛分析证实，全局分类器和局部正交变换的联合优化可以获得更好的性能，并表明其具有更广泛的应用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Learning (FL) aims to train models across decentralized clients ordevices holding local data without the need for centralized data collection,thus enhancing data privacy and security. However, achieving bothgeneralization and personalization in heterogeneous settings remains asignificant challenge. To address this, we introduce FedOT, a novel approachthat leverages black-box foundation models. FedOT shares only a globaltask-dependent classifier across clients while locally adapting featuresthrough orthogonal transformations. By enforcing orthogonality, FedOT mitigatesgradient conflicts across diverse clients, preserves semantic integrity, andachieves robust performance even in the presence of substantial dataheterogeneity. The strategy of combining global and local parameters enables amore balanced approach for both generalization and personalization,outperforming baseline FL methods across multiple benchmarks. Furthermore, ourextensive analysis confirms that joint optimization of global classifiers andlocal orthogonal transformations yields superior performance and suggestsbroader applicability.</description>
      <author>example@mail.com (Eun Gyung Kong, Je Won Yeom, Yonghoon Jeon, Taesup Kim)</author>
      <guid isPermaLink="false">2505.19888v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>MineAnyBuild: Benchmarking Spatial Planning for Open-world AI Agents</title>
      <link>http://arxiv.org/abs/2505.20148v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为MineAnyBuild的综合基准，用于评估在Minecraft游戏中开放世界AI代理的空间规划能力。&lt;h4&gt;背景&lt;/h4&gt;空间规划是空间智能领域的关键部分，需要理解和规划空间中物体的排列。具有空间规划能力的AI代理能够更好地适应各种现实世界应用，如机器人操作、自动装配和城市规划等。&lt;h4&gt;目的&lt;/h4&gt;构建一个综合基准，以评估开放世界AI代理在Minecraft游戏中的空间规划能力。&lt;h4&gt;方法&lt;/h4&gt;MineAnyBuild要求代理根据给定的多模态人类指令生成可执行的架构建筑计划。它包含4,000个精心策划的空间规划任务，并利用丰富的玩家生成内容提供了一个可无限扩展的数据收集范例。&lt;h4&gt;主要发现&lt;/h4&gt;MineAnyBuild通过四个核心支持维度评估空间规划：空间理解、空间推理、创造力和空间常识。基于MineAnyBuild的综合评估揭示了现有基于MLLM的代理在空间规划能力上的严重限制和巨大潜力。&lt;h4&gt;结论&lt;/h4&gt;MineAnyBuild将为空间智能的评估开辟新的途径，并有助于促进能够进行空间规划的开世界AI代理的进一步发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial Planning is a crucial part in the field of spatial intelligence,which requires the understanding and planning about object arrangements inspace perspective. AI agents with the spatial planning ability can better adaptto various real-world applications, including robotic manipulation, automaticassembly, urban planning etc. Recent works have attempted to constructbenchmarks for evaluating the spatial intelligence of Multimodal Large LanguageModels (MLLMs). Nevertheless, these benchmarks primarily focus on spatialreasoning based on typical Visual Question-Answering (VQA) forms, which suffersfrom the gap between abstract spatial understanding and concrete taskexecution. In this work, we take a step further to build a comprehensivebenchmark called MineAnyBuild, aiming to evaluate the spatial planning abilityof open-world AI agents in the Minecraft game. Specifically, MineAnyBuildrequires an agent to generate executable architecture building plans based onthe given multi-modal human instructions. It involves 4,000 curated spatialplanning tasks and also provides a paradigm for infinitely expandable datacollection by utilizing rich player-generated content. MineAnyBuild evaluatesspatial planning through four core supporting dimensions: spatialunderstanding, spatial reasoning, creativity, and spatial commonsense. Based onMineAnyBuild, we perform a comprehensive evaluation for existing MLLM-basedagents, revealing the severe limitations but enormous potential in theirspatial planning abilities. We believe our MineAnyBuild will open new avenuesfor the evaluation of spatial intelligence and help promote further developmentfor open-world AI agents capable of spatial planning.</description>
      <author>example@mail.com (Ziming Wei, Bingqian Lin, Zijian Jiao, Yunshuang Nie, Liang Ma, Yuecheng Liu, Yuzheng Zhuang, Xiaodan Liang)</author>
      <guid isPermaLink="false">2505.20148v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Advancements in Medical Image Classification through Fine-Tuning Natural Domain Foundation Models</title>
      <link>http://arxiv.org/abs/2505.19779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了最新基础模型在医学图像分类中的应用，分析了模型对医学领域的影响，并比较了不同模型在医学图像分类中的表现。&lt;h4&gt;背景&lt;/h4&gt;基础模型是大规模预训练模型，能够在多种任务中表现良好，并随着新方法的引入而持续改进。&lt;h4&gt;目的&lt;/h4&gt;探究DINOv2、MAE、VMamba、CoCa、SAM2和AIMv2等基础模型在医学图像分类中的应用效果，评估其配置，以了解这些先进技术在医学图像分类中的潜力。&lt;h4&gt;方法&lt;/h4&gt;通过微调这些模型并在CBIS-DDSM、ISIC2019、APTOS2019和CHEXPERT等数据集上评估其性能。&lt;h4&gt;主要发现&lt;/h4&gt;这些先进模型在医学图像分类中显著提升了分类结果，表现出良好的性能，即使是在有限标记数据的情况下。&lt;h4&gt;结论&lt;/h4&gt;基于研究结果，AIMv2、DINOv2和SAM2模型优于其他模型，显示出自然域训练进展对医学领域的积极影响和分类结果的提升。&lt;h4&gt;翻译&lt;/h4&gt;Using massive datasets, foundation models are large-scale, pre-trained models that perform a wide range of tasks. These models have shown consistently improved results with the introduction of new methods. It is crucial to analyze how these trends impact the medical field and determine whether these advancements can drive meaningful change. This study investigates the application of recent state-of-the-art foundation models, DINOv2, MAE, VMamba, CoCa, SAM2, and AIMv2, for medical image classification. We explore their effectiveness on datasets including CBIS-DDSM for mammography, ISIC2019 for skin lesions, APTOS2019 for diabetic retinopathy, and CHEXPERT for chest radiographs. By fine-tuning these models and evaluating their configurations, we aim to understand the potential of these advancements in medical image classification. The results indicate that these advanced models significantly enhance classification outcomes, demonstrating robust performance despite limited labeled data. Based on our results, AIMv2, DINOv2, and SAM2 models outperformed others, demonstrating that progress in natural domain training has positively impacted the medical domain and improved classification outcomes. Our code is publicly available at: https://github.com/sajjad-sh33/Medical-Transfer-Learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Using massive datasets, foundation models are large-scale, pre-trained modelsthat perform a wide range of tasks. These models have shown consistentlyimproved results with the introduction of new methods. It is crucial to analyzehow these trends impact the medical field and determine whether theseadvancements can drive meaningful change. This study investigates theapplication of recent state-of-the-art foundation models, DINOv2, MAE, VMamba,CoCa, SAM2, and AIMv2, for medical image classification. We explore theireffectiveness on datasets including CBIS-DDSM for mammography, ISIC2019 forskin lesions, APTOS2019 for diabetic retinopathy, and CHEXPERT for chestradiographs. By fine-tuning these models and evaluating their configurations,we aim to understand the potential of these advancements in medical imageclassification. The results indicate that these advanced models significantlyenhance classification outcomes, demonstrating robust performance despitelimited labeled data. Based on our results, AIMv2, DINOv2, and SAM2 modelsoutperformed others, demonstrating that progress in natural domain training haspositively impacted the medical domain and improved classification outcomes.Our code is publicly available at:https://github.com/sajjad-sh33/Medical-Transfer-Learning.</description>
      <author>example@mail.com (Mobina Mansoori, Sajjad Shahabodini, Farnoush Bayatmakou, Jamshid Abouei, Konstantinos N. Plataniotis, Arash Mohammadi)</author>
      <guid isPermaLink="false">2505.19779v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>AdaTP: Attention-Debiased Token Pruning for Video Large Language Models</title>
      <link>http://arxiv.org/abs/2505.20100v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AdaTP的Video LLMs新型token pruning方法，旨在解决视频理解任务中的计算开销问题，同时保持模型性能。&lt;h4&gt;背景&lt;/h4&gt;Video LLMs在视频理解任务中取得了显著成果，但它们由于生成大量视觉token而存在计算开销大的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来减少Video LLMs的计算开销，同时保持模型性能。&lt;h4&gt;方法&lt;/h4&gt;AdaTP方法集成了两个专门的去偏置模块，分别针对全局和局部注意力偏差。&lt;h4&gt;主要发现&lt;/h4&gt;AdaTP显著减少了Video LLMs的计算开销，同时保持了vanilla模型的表现。在LLaVA-OneVision-7B上，AdaTP的性能没有下降，而使用的FLOPs仅为vanilla模型的27.3%。&lt;h4&gt;结论&lt;/h4&gt;AdaTP在多种视频理解基准测试中实现了最先进的性能，是一个有效的Video LLMs token pruning方法。&lt;h4&gt;翻译&lt;/h4&gt;Video大型语言模型（Video LLMs）在视频理解任务中取得了显著的成果。然而，由于从多个视频帧中生成大量视觉token，它们通常存在计算开销大的问题。现有的视觉token压缩方法通常依赖于语言模型中的注意力分数作为指导。但是，这些分数具有固有的偏差：全局偏差反映了对视觉token序列两端的关注趋势，而局部偏差导致在不同帧中对相同空间位置过度集中。为了解决注意力偏差问题，我们提出了针对视频大型语言模型（Video LLMs）的注意力去偏置token剪枝（AdaTP），这是一种新颖的token剪枝流程。AdaTP将两个专门的去偏置模块集成到流程中，分别针对全局注意力偏差和局部注意力偏差。无需额外训练，我们的方法显著降低了Video LLMs的计算开销，同时保留了vanilla模型的表现。广泛的评估表明，AdaTP在各种常用的视频理解基准测试中实现了最先进的性能。特别是，在LLaVA-OneVision-7B上，AdaTP在仅使用vanilla模型27.3% FLOPs的情况下保持了性能，而没有性能下降。我们的代码将很快发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Large Language Models (Video LLMs) have achieved remarkable results invideo understanding tasks. However, they often suffer from heavy computationaloverhead due to the large number of visual tokens generated from multiple videoframes. Existing visual token compression methods often rely on attentionscores from language models as guidance. However, these scores exhibit inherentbiases: global bias reflects a tendency to focus on the two ends of the visualtoken sequence, while local bias leads to an over-concentration on the samespatial positions across different frames. To address the issue of attentionbias, we propose $\textbf{A}$ttention-$\textbf{D}$ebi$\textbf{a}$sed$\textbf{T}$oken $\textbf{P}$runing for Video Large Language Models($\textbf{AdaTP}$), a novel token pruning pipeline for Video LLMs. AdaTPintegrates two dedicated debiasing modules into the pipeline, targeting globalattention bias and local attention bias, respectively. Without the need foradditional training, our method significantly reduces the computationaloverhead of Video LLMs while retaining the performance of vanilla models.Extensive evaluation shows that AdaTP achieves state-of-the-art performance invarious commonly used video understanding benchmarks. In particular, onLLaVA-OneVision-7B, AdaTP maintains performance without degradation while usingonly up to $27.3\%$ FLOPs compared to the vanilla model. Our code will bereleased soon.</description>
      <author>example@mail.com (Fengyuan Sun, Leqi Shen, Hui Chen, Sicheng Zhao, Jungong Han, Guiguang Ding)</author>
      <guid isPermaLink="false">2505.20100v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Language Model-Enhanced Message Passing for Heterophilic Graph Learning</title>
      <link>http://arxiv.org/abs/2505.19762v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为LEMP4HG的新颖语言模型增强的消息传递方法，用于异质图学习，以解决传统图神经网络在异质图上的局限性。&lt;h4&gt;背景&lt;/h4&gt;传统的图神经网络在处理异质图时存在困难，因为异质图中连接的节点具有不同的特征和标签。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出了一种新的方法来增强异质图学习。&lt;h4&gt;方法&lt;/h4&gt;该方法利用语言模型生成节点连接分析，并通过门控机制将分析编码并与节点文本嵌入融合。此外，引入了一种基于启发式MVRD（调制可靠距离变化）的主动学习策略，以选择性地增强在消息传递中受影响最大的节点对。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在异质图上表现优异，在同质图上也能稳健地工作，同时使用图卷积网络（GCN）作为骨干网络和实际预算。&lt;h4&gt;结论&lt;/h4&gt;LEMP4HG方法能够有效提高异质图学习的效果，并在同质图上保持良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel language model-enhanced message passing approach (LEMP4HG) for heterophilic graph learning to address the limitations of traditional graph neural networks in handling heterophilic graphs. The method utilizes a language model to generate connection analysis for nodes and fuses it with node text embeddings through a gating mechanism. Additionally, an active learning strategy guided by the heuristic MVRD (Modulated Variation of Reliable Distance) is introduced to selectively enhance node pairs most affected by message passing. Extensive experiments demonstrate that LEMP4HG excels on heterophilic graphs and performs robustly on homophilic ones, using a graph convolutional network (GCN) backbone and a practical budget.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional graph neural networks (GNNs), which rely on homophily-drivenmessage passing, struggle with heterophilic graphs where connected nodesexhibit dissimilar features and different labels. While existing methodsaddress heterophily through graph structure refinement or adaptation ofneighbor aggregation functions, they often overlook the semantic potential ofnode text, rely on suboptimal message representation for propagation andcompromise performance on homophilic graphs. To address these limitations, wepropose a novel language model (LM)-enhanced message passing approach forheterophilic graph leaning (LEMP4HG). Specifically, in the context oftext-attributed graph, we provide paired node texts for LM to generate theirconnection analysis, which are encoded and then fused with paired node textualembeddings through a gating mechanism. The synthesized messages aresemantically enriched and adaptively balanced with both nodes' information,which mitigates contradictory signals when neighbor aggregation in heterophilicregions. Furthermore, we introduce an active learning strategy guided by ourheuristic MVRD (Modulated Variation of Reliable Distance), selectivelyenhancing node pairs suffer most from message passing, reducing the cost ofanalysis generation and side effects on homophilic regions. Extensiveexperiments validate that our approach excels on heterophilic graphs andperforms robustly on homophilic ones, with a graph convolutional network (GCN)backbone and a practical budget.</description>
      <author>example@mail.com (Wenjun Wang, Dawei Cheng)</author>
      <guid isPermaLink="false">2505.19762v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Reason without External Rewards</title>
      <link>http://arxiv.org/abs/2505.19590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Intuitor的基于内部反馈的强化学习方法，用于训练大型语言模型进行复杂推理，通过使用模型自身的置信度作为奖励信号，实现了无监督学习，并展示了其在数学基准测试和代码生成等任务上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型训练依赖于成本高昂且领域特定的监督，这限制了其推理能力的提升。&lt;h4&gt;目的&lt;/h4&gt;探索一种新的框架，使得大型语言模型能够在没有外部奖励或标记数据的情况下学习。&lt;h4&gt;方法&lt;/h4&gt;提出了Intuitor方法，它使用模型的自身置信度（称为自我确定性）作为唯一的奖励信号，并替换了Group Relative Policy Optimization（GRPO）中的外部奖励。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，Intuitor在数学基准测试上的性能与GRPO相当，同时在外部领域任务（如代码生成）上实现了更好的泛化能力，而无需黄金解决方案或测试案例。&lt;h4&gt;结论&lt;/h4&gt;内部模型信号可以驱动跨领域有效学习，为在验证性奖励不可用的自主人工智能系统中提供了一种可扩展的替代方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通过强化学习与可验证奖励（RLVR）训练复杂推理的大型语言模型（LLMs）是有效的，但受到对昂贵、特定领域的监督的依赖。我们探索了从内部反馈（RLIF）强化学习框架，该框架使LLMs能够在没有外部奖励或标记数据的情况下进行学习。我们提出了Intuitor，一种使用模型自身的置信度（称为自我确定性）作为其唯一奖励信号的RLIF方法。Intuitor用自我确定性分数替换了Group Relative Policy Optimization（GRPO）中的外部奖励，实现了完全无监督学习。实验表明，Intuitor在数学基准测试上的性能与GRPO相当，同时在代码生成等外部领域任务上实现了更好的泛化能力，而无需黄金解决方案或测试案例。我们的研究结果证明了内部模型信号可以驱动跨领域的有效学习，为在验证性奖励不可用的自主人工智能系统中提供了可扩展的替代方案。代码可在https://github.com/sunblaze-ucb/Intuitor上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training large language models (LLMs) for complex reasoning via ReinforcementLearning with Verifiable Rewards (RLVR) is effective but limited by reliance oncostly, domain-specific supervision. We explore Reinforcement Learning fromInternal Feedback (RLIF), a framework that enables LLMs to learn from intrinsicsignals without external rewards or labeled data. We propose Intuitor, an RLIFmethod that uses a model's own confidence, termed self-certainty, as its solereward signal. Intuitor replaces external rewards in Group Relative PolicyOptimization (GRPO) with self-certainty scores, enabling fully unsupervisedlearning. Experiments demonstrate that Intuitor matches GRPO's performance onmathematical benchmarks while achieving superior generalization toout-of-domain tasks like code generation, without requiring gold solutions ortest cases. Our findings show that intrinsic model signals can drive effectivelearning across domains, offering a scalable alternative to RLVR for autonomousAI systems where verifiable rewards are unavailable. Code is available athttps://github.com/sunblaze-ucb/Intuitor</description>
      <author>example@mail.com (Xuandong Zhao, Zhewei Kang, Aosong Feng, Sergey Levine, Dawn Song)</author>
      <guid isPermaLink="false">2505.19590v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Sparse2DGS: Sparse-View Surface Reconstruction using 2D Gaussian Splatting with Dense Point Cloud</title>
      <link>http://arxiv.org/abs/2505.19854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICIP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Gaussian Splatting (GS) 是一种快速有效的视图合成方法，被应用于3D重建，但需要大量多视角图像，限制了其准确度。&lt;h4&gt;背景&lt;/h4&gt;GS 在3D重建中应用广泛，但仅使用少量输入图像时，重建精度显著下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的3D重建方法 Sparse2DGS，以使用仅三张图像进行对象重建，并提高重建精度。&lt;h4&gt;方法&lt;/h4&gt;Sparse2DGS 使用 DUSt3R 和 COLMAP MVS 生成高精度和密集的3D点云，初始化2D高斯。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，Sparse2DGS 可以使用三张图像准确重建物体的3D形状。&lt;h4&gt;结论&lt;/h4&gt;Sparse2DGS 是一种有效的3D重建方法，即使在只有三张图像的情况下也能实现高精度重建。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gaussian Splatting (GS) has gained attention as a fast and effective methodfor novel view synthesis. It has also been applied to 3D reconstruction usingmulti-view images and can achieve fast and accurate 3D reconstruction. However,GS assumes that the input contains a large number of multi-view images, andtherefore, the reconstruction accuracy significantly decreases when only alimited number of input images are available. One of the main reasons is theinsufficient number of 3D points in the sparse point cloud obtained throughStructure from Motion (SfM), which results in a poor initialization foroptimizing the Gaussian primitives. We propose a new 3D reconstruction method,called Sparse2DGS, to enhance 2DGS in reconstructing objects using only threeimages. Sparse2DGS employs DUSt3R, a fundamental model for stereo images, alongwith COLMAP MVS to generate highly accurate and dense 3D point clouds, whichare then used to initialize 2D Gaussians. Through experiments on the DTUdataset, we show that Sparse2DGS can accurately reconstruct the 3D shapes ofobjects using just three images.</description>
      <author>example@mail.com (Natsuki Takama, Shintaro Ito, Koichi Ito, Hwann-Tzong Chen, Takafumi Aoki)</author>
      <guid isPermaLink="false">2505.19854v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>DuRep: Dual-Mode Speech Representation Learning via ASR-Aware Distillation</title>
      <link>http://arxiv.org/abs/2505.19774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了DuRep，一种双模式语音表示学习设置，它使单个语音编码器能够在离线和在线模式下高效运行，无需额外参数或模式特定调整，并在多种下游任务中实现最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;语音编码器与大型语言模型的结合在语音任务中引起了关注，但大多数研究集中在因果或全上下文语音编码器上，而对同时有效处理流式和非流式应用的研究有限。&lt;h4&gt;目的&lt;/h4&gt;提出DuRep，以实现一个语音编码器在离线和在线模式下都能高效运行，而无需额外的参数或模式特定调整，并在多种任务中达到最先进的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了DuRep，一个双模式语音表示学习设置，并开发了参数为200M的DuRep-200M编码器和参数为2B的DuRep-2B编码器，用于在多语言语音识别（ASR）任务中测试。&lt;h4&gt;主要发现&lt;/h4&gt;DuRep-200M在流式和非流式模式下分别比基线编码器提高了12%和11.6%的性能。将此方法扩展到2B参数，DuRep-2B在ASR和非ASR任务中设定了新的性能基准。分析揭示了编码器层之间声学和语义信息之间的有趣权衡。&lt;h4&gt;结论&lt;/h4&gt;DuRep通过提供一种灵活的双模式语音编码器，显著提高了语音任务中的性能，并为声学和语义信息之间的权衡提供了新的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in speech encoders have drawn attention due to theirintegration with Large Language Models for various speech tasks. While mostresearch has focused on either causal or full-context speech encoders, there'slimited exploration to effectively handle both streaming and non-streamingapplications, while achieving state-of-the-art performance. We introduce DuRep,a Dual-mode Speech Representation learning setup, which enables a single speechencoder to function efficiently in both offline and online modes withoutadditional parameters or mode-specific adjustments, across downstream tasks.DuRep-200M, our 200M parameter dual-mode encoder, achieves 12% and 11.6%improvements in streaming and non-streaming modes, over baseline encoders onMultilingual ASR. Scaling this approach to 2B parameters, DuRep-2B sets newperformance benchmarks across ASR and non-ASR tasks. Our analysis revealsinteresting trade-offs between acoustic and semantic information across encoderlayers.</description>
      <author>example@mail.com (Prabash Reddy Male, Swayambhu Nath Ray, Harish Arsikere, Akshat Jaiswal, Prakhar Swarup, Prantik Sen, Debmalya Chakrabarty, K V Vijay Girish, Nikhil Bhave, Frederick Weber, Sambuddha Bhattacharya, Sri Garimella)</author>
      <guid isPermaLink="false">2505.19774v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Can Visual Encoder Learn to See Arrows?</title>
      <link>http://arxiv.org/abs/2505.19944v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted for poster presentation at the Second  Workshop on Visual Concepts in CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了视觉语言模型（VLMs）在识别图像中的边缘时的不足，提出通过消除文本和位置偏差来提高边缘识别的准确性。&lt;h4&gt;背景&lt;/h4&gt;图像在工业和科学通信中被广泛用作关系的视觉表示，但VLMs在识别图像中的边缘时存在困难。&lt;h4&gt;目的&lt;/h4&gt;通过实验研究VLMs中的图像编码器是否可以通过在无文本和位置偏差的图数据集上训练来学习边缘表示。&lt;h4&gt;方法&lt;/h4&gt;使用人工生成的图-标题数据集进行对比学习来训练图像编码器，并在三个任务（探测、图像检索和标题生成）上评估其性能。&lt;h4&gt;主要发现&lt;/h4&gt;经过微调的模型在所有任务中都优于预训练的CLIP模型，在标题生成任务中超过了零样本GPT-4o和LLaVA-Mistral模型。&lt;h4&gt;结论&lt;/h4&gt;消除文本和位置偏差可以促进VLMs中边缘的准确识别，为提升图表理解提供了有前景的方法。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is a visual representation of a relationship illustrated with edges (lines or arrows), which is widely used in industrial and scientific communication. Although recognizing diagrams is essential for vision language models (VLMs) to comprehend domain-specific knowledge, recent studies reveal that many VLMs fail to identify edges in images. We hypothesize that these failures stem from an over-reliance on textual and positional biases, preventing VLMs from learning explicit edge features. Based on this idea, we empirically investigate whether the image encoder in VLMs can learn edge representation through training on a diagram dataset in which edges are biased neither by textual nor positional information. To this end, we conduct contrastive learning on an artificially generated diagram--caption dataset to train an image encoder and evaluate its diagram-related features on three tasks: probing, image retrieval, and captioning. Our results show that the fine-tuned model outperforms pretrained CLIP in all tasks and surpasses zero-shot GPT-4o and LLaVA-Mistral in the captioning task. These findings confirm that eliminating textual and positional biases fosters accurate edge recognition in VLMs, offering a promising path for advancing diagram understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The diagram is a visual representation of a relationship illustrated withedges (lines or arrows), which is widely used in industrial and scientificcommunication. Although recognizing diagrams is essential for vision languagemodels (VLMs) to comprehend domain-specific knowledge, recent studies revealthat many VLMs fail to identify edges in images. We hypothesize that thesefailures stem from an over-reliance on textual and positional biases,preventing VLMs from learning explicit edge features. Based on this idea, weempirically investigate whether the image encoder in VLMs can learn edgerepresentation through training on a diagram dataset in which edges are biasedneither by textual nor positional information. To this end, we conductcontrastive learning on an artificially generated diagram--caption dataset totrain an image encoder and evaluate its diagram-related features on threetasks: probing, image retrieval, and captioning. Our results show that thefinetuned model outperforms pretrained CLIP in all tasks and surpasseszero-shot GPT-4o and LLaVA-Mistral in the captioning task. These findingsconfirm that eliminating textual and positional biases fosters accurate edgerecognition in VLMs, offering a promising path for advancing diagramunderstanding.</description>
      <author>example@mail.com (Naoyuki Terashita, Yusuke Tozaki, Hideaki Omote, Congkha Nguyen, Ryosuke Nakamoto, Yuta Koreeda, Hiroaki Ozaki)</author>
      <guid isPermaLink="false">2505.19944v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>STRAP: Spatio-Temporal Pattern Retrieval for Out-of-Distribution Generalization</title>
      <link>http://arxiv.org/abs/2505.19547v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;STRAP是一种创新的时空检索增强模式学习方法，用于提高STGNN在时空分布外的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;Spatio-Temporal Graph Neural Networks (STGNNs)在动态图结构数据建模方面表现出色，但在时空分布外的场景中泛化能力不足。&lt;h4&gt;目的&lt;/h4&gt;提出STRAP框架，通过整合检索增强学习来提高STGNN的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;STRAP的核心是一个紧凑且具有表现力的模式库，存储了具有历史、结构和语义信息的代表性时空模式。在推理过程中，根据当前输入的相似性检索相关模式，并通过插件式提示机制注入模型中。&lt;h4&gt;主要发现&lt;/h4&gt;STRAP在多个真实世界流图数据集上的实验表明，它在时空分布外的任务上优于最先进的STGNN基线，证明了其鲁棒性、适应性和强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;STRAP通过知识平衡目标实现新信息与检索知识的和谐，有效缓解了灾难性遗忘，并显著提升了STGNN在时空分布外场景中的性能。&lt;h4&gt;翻译&lt;/h4&gt;Spatio-Temporal Graph Neural Networks (STGNNs) 已成为建模跨多个领域的动态图结构数据的有力工具。然而，它们在时空分布外 (STOOD) 场景中往往无法泛化，在这些场景中，时间和空间结构都超出了训练分布。为了解决这个问题，我们提出了一种创新的时空检索增强模式学习框架 STRAP，通过将检索增强学习整合到 STGNN 持续学习流程中来提高模型泛化能力。STRAP 的核心是一个紧凑且具有表现力的模式库，其中存储了具有历史、结构和语义信息的代表性时空模式，这些模式在训练过程中获得并优化。在推理过程中，STRAP 根据与当前输入的相似性从该库中检索相关模式，并通过插件式提示机制将其注入模型中。这不仅加强了时空表示，还减轻了灾难性遗忘。此外，STRAP 引入了一个知识平衡目标，以协调新信息与检索知识。在多个真实世界流图数据集上的大量实验表明，STRAP 在 STOOD 任务上始终优于最先进的 STGNN 基线，证明了其鲁棒性、适应性和强大的泛化能力，无需针对特定任务进行微调。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatio-Temporal Graph Neural Networks (STGNNs) have emerged as a powerfultool for modeling dynamic graph-structured data across diverse domains.However, they often fail to generalize in Spatio-Temporal Out-of-Distribution(STOOD) scenarios, where both temporal dynamics and spatial structures evolvebeyond the training distribution. To address this problem, we propose aninnovative Spatio-Temporal Retrieval-Augmented Pattern Learningframework,STRAP, which enhances model generalization by integratingretrieval-augmented learning into the STGNN continue learning pipeline. Thecore of STRAP is a compact and expressive pattern library that storesrepresentative spatio-temporal patterns enriched with historical, structural,and semantic information, which is obtained and optimized during the trainingphase. During inference, STRAP retrieves relevant patterns from this librarybased on similarity to the current input and injects them into the model via aplug-and-play prompting mechanism. This not only strengthens spatio-temporalrepresentations but also mitigates catastrophic forgetting. Moreover, STRAPintroduces a knowledge-balancing objective to harmonize new information withretrieved knowledge. Extensive experiments across multiple real-world streaminggraph datasets show that STRAP consistently outperforms state-of-the-art STGNNbaselines on STOOD tasks, demonstrating its robustness, adaptability, andstrong generalization capability without task-specific fine-tuning.</description>
      <author>example@mail.com (Haoyu Zhang, Wentao Zhang, Hao Miao, Xinke Jiang, Yuchen Fang, Yifan Zhang)</author>
      <guid isPermaLink="false">2505.19547v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Agentic Predictor: Performance Prediction for Agentic Workflows via Multi-View Encoding</title>
      <link>http://arxiv.org/abs/2505.19764v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code will be available at  https://github.com/DeepAuto-AI/agentic-predictor&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Agentic Predictor的轻量级预测器，用于高效评估基于大型语言模型的代理系统的工作流程，通过减少计算成本和优化搜索空间来提高优化代理系统的效率。&lt;h4&gt;背景&lt;/h4&gt;优化基于大型语言模型的代理系统面临挑战，因为存在大量搜索空间，包括代理配置、策略和通信模式。&lt;h4&gt;目的&lt;/h4&gt;设计一个轻量级的预测器，以高效评估代理系统的工作流程，减少训练预测器所需的流程评估数量。&lt;h4&gt;方法&lt;/h4&gt;Agentic Predictor采用多视角工作流程编码技术，结合代码架构、文本提示和交互图特征。此外，它还采用跨领域无监督预训练来提高预测精度。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与现有方法相比，Agentic Predictor在预测精度和工作流程效用方面都优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;性能预测器在简化基于大型语言模型的代理工作流程设计方面具有潜力。&lt;h4&gt;翻译&lt;/h4&gt;Large language models (LLMs) have demonstrated remarkable capabilities across diverse tasks, but optimizing LLM-based agentic systems remains challenging due to the vast search space of agent configurations, prompting strategies, and communication patterns. Existing approaches often rely on heuristic-based tuning or exhaustive evaluation, which can be computationally expensive and suboptimal. This paper proposes Agentic Predictor, a lightweight predictor for efficient agentic workflow evaluation. Agentic Predictor is equipped with a multi-view workflow encoding technique that leverages multi-view representation learning of agentic systems by incorporating code architecture, textual prompts, and interaction graph features. To achieve high predictive accuracy while significantly reducing the number of required workflow evaluations for training a predictor, Agentic Predictor employs cross-domain unsupervised pretraining. By learning to approximate task success rates, Agentic Predictor enables fast and accurate selection of optimal agentic workflow configurations for a given task, significantly reducing the need for expensive trial-and-errorevaluations. Experiments on a carefully curated benchmark spanning three domains show that our predictor outperforms state-of-the-art methods in both predictive accuracy and workflow utility, highlighting the potential of performance predictors in streamlining the design of LLM-based agentic workflows.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have demonstrated remarkable capabilities acrossdiverse tasks, but optimizing LLM-based agentic systems remains challenging dueto the vast search space of agent configurations, prompting strategies, andcommunication patterns. Existing approaches often rely on heuristic-basedtuning or exhaustive evaluation, which can be computationally expensive andsuboptimal. This paper proposes Agentic Predictor, a lightweight predictor forefficient agentic workflow evaluation. Agentic Predictor is equipped with amulti-view workflow encoding technique that leverages multi-view representationlearning of agentic systems by incorporating code architecture, textualprompts, and interaction graph features. To achieve high predictive accuracywhile significantly reducing the number of required workflow evaluations fortraining a predictor, Agentic Predictor employs cross-domain unsupervisedpretraining. By learning to approximate task success rates, Agentic Predictorenables fast and accurate selection of optimal agentic workflow configurationsfor a given task, significantly reducing the need for expensive trial-and-errorevaluations. Experiments on a carefully curated benchmark spanning threedomains show that our predictor outperforms state-of-the-art methods in bothpredictive accuracy and workflow utility, highlighting the potential ofperformance predictors in streamlining the design of LLM-based agenticworkflows.</description>
      <author>example@mail.com (Patara Trirat, Wonyong Jeong, Sung Ju Hwang)</author>
      <guid isPermaLink="false">2505.19764v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Learning for Dynamic Combinatorial Optimization without Training Data</title>
      <link>http://arxiv.org/abs/2505.19497v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了DyCO-GNN，这是一个用于动态组合优化的新颖的无监督学习框架，无需除问题实例之外的其他训练数据。DyCO-GNN通过利用随时间演变的图快照之间的结构相似性来加速优化，同时保持解决方案的质量。&lt;h4&gt;背景&lt;/h4&gt;目前动态组合优化需要大量的训练数据来训练模型。&lt;h4&gt;目的&lt;/h4&gt;提出一个不需要额外训练数据的无监督学习框架，以加速动态组合优化。&lt;h4&gt;方法&lt;/h4&gt;使用DyCO-GNN，通过分析时间演变的图快照之间的结构相似性来优化动态组合问题。&lt;h4&gt;主要发现&lt;/h4&gt;在动态最大割、最大独立集和旅行商问题等多个数据集上，DyCO-GNN在紧张的和中等的预算下表现出优异的性能，并且通常比基线方法快3-60倍，达到高质量解决方案。&lt;h4&gt;结论&lt;/h4&gt;DyCO-GNN在快速演变的资源受限环境中表现出实用的高效性。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新的无监督学习框架DyCO-GNN，用于动态组合优化，该框架无需除问题实例本身之外的其他训练数据。DyCO-GNN通过利用时间演变的图快照之间的结构相似性来加速优化，同时保持解决方案的质量。我们在动态最大割、最大独立集和旅行商问题等多个数据集上对DyCO-GNN进行了评估，证明了它在紧张和适中的时间预算下的优越性能。DyCO-GNN始终优于基线方法，实现高质量的解决方案速度可达3-60倍，突出了它在快速演变的资源受限环境中的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce DyCO-GNN, a novel unsupervised learning framework for DynamicCombinatorial Optimization that requires no training data beyond the probleminstance itself. DyCO-GNN leverages structural similarities acrosstime-evolving graph snapshots to accelerate optimization while maintainingsolution quality. We evaluate DyCO-GNN on dynamic maximum cut, maximumindependent set, and the traveling salesman problem across diverse datasets ofvarying sizes, demonstrating its superior performance under tight and moderatetime budgets. DyCO-GNN consistently outperforms the baseline methods, achievinghigh-quality solutions up to 3-60x faster, highlighting its practicaleffectiveness in rapidly evolving resource-constrained settings.</description>
      <author>example@mail.com (Yiqiao Liao, Farinaz Koushanfar, Parinaz Naghizadeh)</author>
      <guid isPermaLink="false">2505.19497v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Underwater Diffusion Attention Network with Contrastive Language-Image Joint Learning for Underwater Image Enhancement</title>
      <link>http://arxiv.org/abs/2505.19895v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为UDAN-CLIP的图像到图像扩散框架，用于水下图像增强，旨在解决水下图像增强中的挑战，包括光照吸收、散射、色彩偏差和伪影等问题。&lt;h4&gt;背景&lt;/h4&gt;水下图像增强对于水下环境中的物体检测、识别和场景理解至关重要。然而，现有的方法通常依赖于合成数据集，这可能导致偏差和泛化能力的限制。&lt;h4&gt;目的&lt;/h4&gt;提出UDAN-CLIP模型，旨在解决现有方法中的局限性，实现更有效的水下图像增强。&lt;h4&gt;方法&lt;/h4&gt;UDAN-CLIP模型在合成水下数据集上预训练，并通过基于视觉语言模型、空间注意力模块和新型CLIP-Diffusion损失的定制分类器进行增强。分类器保留自然大气先验，并通过语义引导扩散过程；空间注意力模块专注于纠正局部退化，如雾霾和低对比度；CLIP-Diffusion损失强化视觉文本对齐，并在增强过程中保持语义一致性。&lt;h4&gt;主要发现&lt;/h4&gt;UDAN-CLIP模型能够有效地纠正扭曲并恢复水下条件下的自然外观，通过定量指标和定性视觉比较验证了其性能。&lt;h4&gt;结论&lt;/h4&gt;UDAN-CLIP模型通过改进水下图像增强，实现了更真实、更细致的图像处理效果，为水下图像处理提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Underwater images are often affected by complex degradations such as light absorption, scattering, color casts, and artifacts, making enhancement critical for effective object detection, recognition, and scene understanding in aquatic environments. Existing methods, especially diffusion-based approaches, typically rely on synthetic paired datasets due to the scarcity of real underwater references, introducing bias and limiting generalization. Furthermore, fine-tuning these models can degrade learned priors, resulting in unrealistic enhancements due to domain shifts. To address these challenges, we propose UDAN-CLIP, an image-to-image diffusion framework pre-trained on synthetic underwater datasets and enhanced with a customized classifier based on vision-language model, a spatial attention module, and a novel CLIP-Diffusion loss. The classifier preserves natural in-air priors and semantically guides the diffusion process, while the spatial attention module focuses on correcting localized degradations such as haze and low contrast. The proposed CLIP-Diffusion loss further strengthens visual-textual alignment and helps maintain semantic consistency during enhancement. The proposed contributions empower our UDAN-CLIP model to perform more effective underwater image enhancement, producing results that are not only visually compelling but also more realistic and detail-preserving. These improvements are consistently validated through both quantitative metrics and qualitative visual comparisons, demonstrating the model's ability to correct distortions and restore natural appearance in challenging underwater conditions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Underwater images are often affected by complex degradations such as lightabsorption, scattering, color casts, and artifacts, making enhancement criticalfor effective object detection, recognition, and scene understanding in aquaticenvironments. Existing methods, especially diffusion-based approaches,typically rely on synthetic paired datasets due to the scarcity of realunderwater references, introducing bias and limiting generalization.Furthermore, fine-tuning these models can degrade learned priors, resulting inunrealistic enhancements due to domain shifts. To address these challenges, wepropose UDAN-CLIP, an image-to-image diffusion framework pre-trained onsynthetic underwater datasets and enhanced with a customized classifier basedon vision-language model, a spatial attention module, and a novelCLIP-Diffusion loss. The classifier preserves natural in-air priors andsemantically guides the diffusion process, while the spatial attention modulefocuses on correcting localized degradations such as haze and low contrast. Theproposed CLIP-Diffusion loss further strengthens visual-textual alignment andhelps maintain semantic consistency during enhancement. The proposedcontributions empower our UDAN-CLIP model to perform more effective underwaterimage enhancement, producing results that are not only visually compelling butalso more realistic and detail-preserving. These improvements are consistentlyvalidated through both quantitative metrics and qualitative visual comparisons,demonstrating the model's ability to correct distortions and restore naturalappearance in challenging underwater conditions.</description>
      <author>example@mail.com (Afrah Shaahid, Muzammil Behzad)</author>
      <guid isPermaLink="false">2505.19895v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>UltraVSR: Achieving Ultra-Realistic Video Super-Resolution with Efficient One-Step Diffusion Space</title>
      <link>http://arxiv.org/abs/2505.19958v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review, 10 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为UltraVSR的新框架，该框架通过高效的扩散空间实现超逼真和时序一致的视频超分辨率。&lt;h4&gt;背景&lt;/h4&gt;扩散模型在生成逼真图像细节方面具有巨大潜力，但在视频超分辨率方面，由于它们的固有随机性和缺乏时序建模，适应性仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够实现超逼真和时序一致的视频超分辨率的新框架。&lt;h4&gt;方法&lt;/h4&gt;UltraVSR的核心组件是退化感知恢复调度（DRS），它从低分辨率输入中估计退化因子，并将迭代去噪过程转化为从低分辨率到高分辨率视频的单步重建。此外，还包括一个轻量级的Recurrent Temporal Shift（RTS）模块，以及时空联合蒸馏（SJD）和时序异步推理（TAI）策略。&lt;h4&gt;主要发现&lt;/h4&gt;UltraVSR在单次采样步骤中实现了最先进的性能，无论是从定性还是定量方面。&lt;h4&gt;结论&lt;/h4&gt;UltraVSR通过其创新的方法在视频超分辨率领域取得了显著的进步。&lt;h4&gt;翻译&lt;/h4&gt;摘要：扩散模型在生成逼真图像细节方面显示出巨大潜力。然而，由于它们固有的随机性和缺乏时序建模，将这些模型应用于视频超分辨率（VSR）仍然具有挑战性。在本文中，我们提出了一种名为UltraVSR的新框架，通过高效的一步扩散空间实现超逼真和时序一致的视频超分辨率。UltraVSR的核心组件是退化感知恢复调度（DRS），它从低分辨率输入中估计退化因子，并将迭代去噪过程转化为从低分辨率到高分辨率视频的单步重建。这种设计消除了扩散噪声中的随机性，并显著提高了推理速度。为确保时序一致性，我们提出了一种轻量级且有效的Recurrent Temporal Shift（RTS）模块，该模块由RTS-卷积单元和RTS-注意力单元组成。通过沿时序维度部分移位特征组件，这两个单元协同促进有效特征在相邻帧之间的传播、融合和对齐，而不依赖于显式的时间层。RTS模块集成到预训练的文本到图像扩散模型中，并通过时空联合蒸馏（SJD）进一步增强，以在保持逼真细节的同时提高时序一致性。此外，我们引入了一种时序异步推理（TAI）策略，以在有限的内存约束下捕获长程时序依赖。大量实验表明，UltraVSR在单次采样步骤中实现了最先进的性能，无论是从定性还是定量方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion models have shown great potential in generating realistic imagedetail. However, adapting these models to video super-resolution (VSR) remainschallenging due to their inherent stochasticity and lack of temporal modeling.In this paper, we propose UltraVSR, a novel framework that enablesultra-realistic and temporal-coherent VSR through an efficient one-stepdiffusion space. A central component of UltraVSR is the Degradation-awareRestoration Schedule (DRS), which estimates a degradation factor from thelow-resolution input and transforms iterative denoising process into asingle-step reconstruction from from low-resolution to high-resolution videos.This design eliminates randomness from diffusion noise and significantly speedsup inference. To ensure temporal consistency, we propose a lightweight yeteffective Recurrent Temporal Shift (RTS) module, composed of an RTS-convolutionunit and an RTS-attention unit. By partially shifting feature components alongthe temporal dimension, these two units collaboratively facilitate effectivefeature propagation, fusion, and alignment across neighboring frames, withoutrelying on explicit temporal layers. The RTS module is integrated into apretrained text-to-image diffusion model and is further enhanced throughSpatio-temporal Joint Distillation (SJD), which improves temporal coherencewhile preserving realistic details. Additionally, we introduce a TemporallyAsynchronous Inference (TAI) strategy to capture long-range temporaldependencies under limited memory constraints. Extensive experiments show thatUltraVSR achieves state-of-the-art performance, both qualitatively andquantitatively, in a single sampling step.</description>
      <author>example@mail.com (Yong Liu, Jinshan Pan, Yinchuan Li, Qingji Dong, Chao Zhu, Yu Guo, Fei Wang)</author>
      <guid isPermaLink="false">2505.19958v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>SACM: SEEG-Audio Contrastive Matching for Chinese Speech Decoding</title>
      <link>http://arxiv.org/abs/2505.19652v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种用于普通话语音解码的脑机接口实验方案及相应的解码算法，通过收集癫痫患者的脑电和同步音频数据，实现了高精度的语音解码。&lt;h4&gt;背景&lt;/h4&gt;言语障碍如构音障碍和无语症会严重影响患者的沟通能力，脑机接口可以作为一种潜在的替代方案，直接将言语意图转换为语音。&lt;h4&gt;目的&lt;/h4&gt;研究普通话语音解码脑机接口，提高在线语音解码的准确性。&lt;h4&gt;方法&lt;/h4&gt;对八名耐药性癫痫患者进行词汇阅读任务，收集他们的立体脑电图和同步音频数据，采用基于对比学习的SEEG和音频对比匹配（SACM）算法进行语音解码。&lt;h4&gt;主要发现&lt;/h4&gt;SACM算法在语音检测和语音解码任务中均达到了显著高于随机水平的解码准确率，单电极的分析显示单个感觉运动皮层电极的性能与整个电极阵列相当。&lt;h4&gt;结论&lt;/h4&gt;这些发现为开发更精确的在线语音解码脑机接口提供了宝贵见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/WangHongbinary/SACM&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech disorders such as dysarthria and anarthria can severely impair thepatient's ability to communicate verbally. Speech decoding brain-computerinterfaces (BCIs) offer a potential alternative by directly translating speechintentions into spoken words, serving as speech neuroprostheses. This paperreports an experimental protocol for Mandarin Chinese speech decoding BCIs,along with the corresponding decoding algorithms. Stereo-electroencephalography(SEEG) and synchronized audio data were collected from eight drug-resistantepilepsy patients as they conducted a word-level reading task. The proposedSEEG and Audio Contrastive Matching (SACM), a contrastive learning-basedframework, achieved decoding accuracies significantly exceeding chance levelsin both speech detection and speech decoding tasks. Electrode-wise analysisrevealed that a single sensorimotor cortex electrode achieved performancecomparable to that of the full electrode array. These findings provide valuableinsights for developing more accurate online speech decoding BCIs.</description>
      <author>example@mail.com (Hongbin Wang, Zhihong Jia, Yuanzhong Shen, Ziwei Wang, Siyang Li, Kai Shu, Feng Hu, Dongrui Wu)</author>
      <guid isPermaLink="false">2505.19652v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>MetaGMT: Improving Actionable Interpretability of Graph Multilinear Networks via Meta-Learning Filtration</title>
      <link>http://arxiv.org/abs/2505.19445v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 Pages Main Content, 10 Pages including Appendix. 1 Figure, 7 Tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为MetaGMT的元学习框架，旨在提高图神经网络（GNN）在医疗和金融等高风险领域的决策过程解释的可靠性。&lt;h4&gt;背景&lt;/h4&gt;随着GNN在医疗和金融等领域的广泛应用，对GNN决策过程解释的可靠性提出了更高的要求。&lt;h4&gt;目的&lt;/h4&gt;提高GNN解释的准确性和鲁棒性，减少虚假相关性对解释的干扰。&lt;h4&gt;方法&lt;/h4&gt;采用了一种新颖的双层优化方法，通过元学习来增强解释的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;MetaGMT在BA-2Motifs、MUTAG和SP-Motif基准测试中，显著提高了解释质量和鲁棒性，同时保持了与基线方法相当的分类准确率。&lt;h4&gt;结论&lt;/h4&gt;MetaGMT的引入有助于提高GNN在敏感领域的应用安全性，通过更可靠的解释来辅助模型调试、支持针对性的再训练，并实现有意义的人工监督。&lt;h4&gt;翻译&lt;/h4&gt;The growing adoption of Graph Neural Networks (GNNs) in high-stakes domains like healthcare and finance demands reliable explanations of their decision-making processes. While inherently interpretable GNN architectures like Graph Multi-linear Networks (GMT) have emerged, they remain vulnerable to generating explanations based on spurious correlations, potentially undermining trust in critical applications. We present MetaGMT, a meta-learning framework that enhances explanation fidelity through a novel bi-level optimization approach. We demonstrate that MetaGMT significantly improves both explanation quality (AUC-ROC, Precision@K) and robustness to spurious patterns, across BA-2Motifs, MUTAG, and SP-Motif benchmarks. Our approach maintains competitive classification accuracy while producing more faithful explanations (with an increase up to 8% of Explanation ROC on SP-Motif 0.5) compared to baseline methods. These advancements in interpretability could enable safer deployment of GNNs in sensitive domains by (1) facilitating model debugging through more reliable explanations, (2) supporting targeted retraining when biases are identified, and (3) enabling meaningful human oversight. By addressing the critical challenge of explanation reliability, our work contributes to building more trustworthy and actionable GNN systems for real-world applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing adoption of Graph Neural Networks (GNNs) in high-stakes domainslike healthcare and finance demands reliable explanations of theirdecision-making processes. While inherently interpretable GNN architectureslike Graph Multi-linear Networks (GMT) have emerged, they remain vulnerable togenerating explanations based on spurious correlations, potentially underminingtrust in critical applications. We present MetaGMT, a meta-learning frameworkthat enhances explanation fidelity through a novel bi-level optimizationapproach. We demonstrate that MetaGMT significantly improves both explanationquality (AUC-ROC, Precision@K) and robustness to spurious patterns, acrossBA-2Motifs, MUTAG, and SP-Motif benchmarks. Our approach maintains competitiveclassification accuracy while producing more faithful explanations (with anincrease up to 8% of Explanation ROC on SP-Motif 0.5) compared to baselinemethods. These advancements in interpretability could enable safer deploymentof GNNs in sensitive domains by (1) facilitating model debugging through morereliable explanations, (2) supporting targeted retraining when biases areidentified, and (3) enabling meaningful human oversight. By addressing thecritical challenge of explanation reliability, our work contributes to buildingmore trustworthy and actionable GNN systems for real-world applications.</description>
      <author>example@mail.com (Rishabh Bhattacharya, Hari Shankar, Vaishnavi Shivkumar, Ponnurangam Kumaraguru)</author>
      <guid isPermaLink="false">2505.19445v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>CAD-Coder: Text-to-CAD Generation with Chain-of-Thought and Geometric Reward</title>
      <link>http://arxiv.org/abs/2505.19713v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了CAD-Coder，这是一个将文本转换为CAD的框架，它将文本转换为基于Python的参数化CAD语言CadQuery脚本的生成。&lt;h4&gt;背景&lt;/h4&gt;传统的文本到CAD转换方法存在几何验证困难、建模词汇有限以及与现有大型语言模型（LLMs）集成困难的问题。&lt;h4&gt;目的&lt;/h4&gt;提出CAD-Coder的目的是为了提高代码的有效性和几何精度，同时实现LLMs直接从自然语言生成多样化、有效和复杂的CAD模型。&lt;h4&gt;方法&lt;/h4&gt;方法包括：(1) 在配对文本-CadQuery数据上进行的监督微调；(2) 使用包含几何奖励（Chamfer Distance）和格式奖励的CAD特定奖励指导的强化学习，采用组奖励策略优化（GRPO）；(3) 引入思维链（CoT）规划过程来提高模型推理；(4) 通过自动化流程构建了一个包含110K个文本-CadQuery-3D模型三元组和1.5K个CoT样本的大型、高质量数据集。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CAD-Coder能够使LLMs直接从自然语言生成多样化、有效和复杂的CAD模型，从而推进了文本到CAD生成和几何推理的现有技术。&lt;h4&gt;结论&lt;/h4&gt;CAD-Coder显著提高了文本到CAD转换的准确性和效率，为LLMs在CAD建模领域的应用提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为CAD-Coder的新框架，该框架将文本到CAD转换为生成基于Python的参数化CAD语言CadQuery脚本的生成。为了提高代码的有效性和几何精度，我们提出了一种两阶段学习流程，包括监督微调和强化学习。我们还引入了思维链规划过程，并构建了一个大规模、高质量的数据集。实验结果表明，CAD-Coder能够使LLMs直接从自然语言生成多样化、有效和复杂的CAD模型，从而推进了文本到CAD生成和几何推理的现有技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we introduce CAD-Coder, a novel framework that reformulatestext-to-CAD as the generation of CadQuery scripts - a Python-based, parametricCAD language. This representation enables direct geometric validation, a richermodeling vocabulary, and seamless integration with existing LLMs. To furtherenhance code validity and geometric fidelity, we propose a two-stage learningpipeline: (1) supervised fine-tuning on paired text-CadQuery data, and (2)reinforcement learning with Group Reward Policy Optimization (GRPO), guided bya CAD-specific reward comprising both a geometric reward (Chamfer Distance) anda format reward. We also introduce a chain-of-thought (CoT) planning process toimprove model reasoning, and construct a large-scale, high-quality dataset of110K text-CadQuery-3D model triplets and 1.5K CoT samples via an automatedpipeline. Extensive experiments demonstrate that CAD-Coder enables LLMs togenerate diverse, valid, and complex CAD models directly from natural language,advancing the state of the art of text-to-CAD generation and geometricreasoning.</description>
      <author>example@mail.com (Yandong Guan, Xilin Wang, Xingxi Ming, Jing Zhang, Dong Xu, Qian Yu)</author>
      <guid isPermaLink="false">2505.19713v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>TCP: a Benchmark for Temporal Constraint-Based Planning</title>
      <link>http://arxiv.org/abs/2505.19927v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Temporal Constraint-based Planning (TCP)基准，用于评估大型语言模型（LLMs）的时间和规划能力，并通过实验发现现有模型在处理此类问题时存在局限性。&lt;h4&gt;背景&lt;/h4&gt;目前大多数基准评估LLMs的时间和规划能力时都是孤立的，并且限于复杂性的有限形式。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一差距，引入了TCP基准，旨在联合评估LLMs的时间和规划能力。&lt;h4&gt;方法&lt;/h4&gt;TCP基准中的每个实例都包含围绕合作项目的自然对话，其中包含明确或隐含的不同和相互依赖的时间约束。模型必须推断出一个满足所有约束的最佳时间表。通过LLM生成抽象问题原型，并与来自各个领域的现实场景配对，使用LLM丰富为对话。对样本子集进行人工质量检查，以确认基准的可靠性。&lt;h4&gt;主要发现&lt;/h4&gt;评估了最先进的LLMs，发现即使是最强大的模型在处理TCP时也面临困难，这突出了其难度并揭示了LLMs在基于时间约束的规划能力方面的局限性。&lt;h4&gt;结论&lt;/h4&gt;分析了潜在的失败案例，开源了基准，并希望研究结果能够启发未来的研究。&lt;h4&gt;翻译&lt;/h4&gt;Temporal reasoning and planning are essential capabilities for large language models (LLMs), yet most existing benchmarks evaluate them in isolation and under limited forms of complexity. To address this gap, we introduce the Temporal Constraint-based Planning (TCP) benchmark, that jointly assesses both capabilities. Each instance in TCP features a naturalistic dialogue around a collaborative project, where diverse and interdependent temporal constraints are explicitly or implicitly expressed, and models must infer an optimal schedule that satisfies all constraints. To construct TCP, we first generate abstract problem prototypes that are paired with realistic scenarios from various domains and enriched into dialogues using an LLM. A human quality check is performed on a sampled subset to confirm the reliability of our benchmark. We evaluate state-of-the-art LLMs and find that even the strongest models struggle with TCP, highlighting its difficulty and revealing limitations in LLMs' temporal constraint-based planning abilities. We analyze underlying failure cases, open source our benchmark, and hope our findings can inspire future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal reasoning and planning are essential capabilities for large languagemodels (LLMs), yet most existing benchmarks evaluate them in isolation andunder limited forms of complexity. To address this gap, we introduce theTemporal Constraint-based Planning (TCP) benchmark, that jointly assesses bothcapabilities. Each instance in TCP features a naturalistic dialogue around acollaborative project, where diverse and interdependent temporal constraintsare explicitly or implicitly expressed, and models must infer an optimalschedule that satisfies all constraints. To construct TCP, we first generateabstract problem prototypes that are paired with realistic scenarios fromvarious domains and enriched into dialogues using an LLM. A human quality checkis performed on a sampled subset to confirm the reliability of our benchmark.We evaluate state-of-the-art LLMs and find that even the strongest modelsstruggle with TCP, highlighting its difficulty and revealing limitations inLLMs' temporal constraint-based planning abilities. We analyze underlyingfailure cases, open source our benchmark, and hope our findings can inspirefuture research.</description>
      <author>example@mail.com (Zifeng Ding, Sikuan Yan, Zhangdie Yuan, Xianglong Hu, Fangru Lin, Andreas Vlachos)</author>
      <guid isPermaLink="false">2505.19927v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Modality Curation: Building Universal Embeddings for Advanced Multimodal Information Retrieval</title>
      <link>http://arxiv.org/abs/2505.19650v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, project page: https://friedrichor.github.io/projects/UNITE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为UNITE的通用框架，用于解决多模态信息检索中的挑战，通过数据管理和模态感知训练配置两个方面来解决问题。&lt;h4&gt;背景&lt;/h4&gt;多模态信息检索面临数据源异质性和跨模态对齐复杂性的挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种系统性的方法来应对这些挑战，并提高多模态检索的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了数据管理和模态感知训练配置，并提出了模态感知掩码对比学习（MAMCL）来减轻不同模态实例之间的竞争关系。&lt;h4&gt;主要发现&lt;/h4&gt;UNITE框架在多个多模态检索基准测试中取得了最先进的成果，超过了现有方法。实验表明，战略性的模态管理和定制化的训练协议对于稳健的跨模态表示学习至关重要。&lt;h4&gt;结论&lt;/h4&gt;这项工作不仅提高了多模态信息检索的性能，还为未来多模态系统的研究提供了基础蓝图。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal information retrieval (MIR) faces inherent challenges due to theheterogeneity of data sources and the complexity of cross-modal alignment.While previous studies have identified modal gaps in feature spaces, asystematic approach to address these challenges remains unexplored. In thiswork, we introduce UNITE, a universal framework that tackles these challengesthrough two critical yet underexplored aspects: data curation andmodality-aware training configurations. Our work provides the firstcomprehensive analysis of how modality-specific data properties influencedownstream task performance across diverse scenarios. Moreover, we proposeModal-Aware Masked Contrastive Learning (MAMCL) to mitigate the competitiverelationships among the instances of different modalities. Our frameworkachieves state-of-the-art results on multiple multimodal retrieval benchmarks,outperforming existing methods by notable margins. Through extensiveexperiments, we demonstrate that strategic modality curation and tailoredtraining protocols are pivotal for robust cross-modal representation learning.This work not only advances MIR performance but also provides a foundationalblueprint for future research in multimodal systems. Our project is availableat https://friedrichor.github.io/projects/UNITE.</description>
      <author>example@mail.com (Fanheng Kong, Jingyuan Zhang, Yahui Liu, Hongzhi Zhang, Shi Feng, Xiaocui Yang, Daling Wang, Yu Tian, Qi Wang, Fuzheng Zhang, Guorui Zhou)</author>
      <guid isPermaLink="false">2505.19650v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Chordless Structure: A Pathway to Simple and Expressive GNNs</title>
      <link>http://arxiv.org/abs/2505.19188v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于无和弦结构的图神经网络（CSGNN），通过省略和弦以降低图结构的复杂性，并提高信息表示的效率。&lt;h4&gt;背景&lt;/h4&gt;目前，研究人员提出了多种方法来增加图神经网络（GNNs）的有序信息，以增强其表达能力，但这些方法要么计算成本高，要么表达能力不足。&lt;h4&gt;目的&lt;/h4&gt;旨在设计一种更高效且具有强大表达能力的图神经网络。&lt;h4&gt;方法&lt;/h4&gt;提出了一个无和弦结构（CSGNN），并在其中省略了和弦以减少图结构的复杂性。&lt;h4&gt;主要发现&lt;/h4&gt;无和弦结构在表示图时比包含和弦的结构更高效和有效。CSGNN的表达能力比k-hop GNN（KPGNN）更强，且具有多项式复杂度。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，CSGNN在多种图任务中优于现有的GNNs，同时具有更低的计算成本和更好的性能。&lt;h4&gt;翻译&lt;/h4&gt;研究人员提出了多种方法来增加图神经网络（GNNs）的有序信息，以增强其表达能力。然而，这些方法要么计算成本高，要么表达能力不足。本文观察到，和弦增加了图结构的复杂性，但在许多情况下只贡献了很少的有用信息。相比之下，无和弦结构在表示图时更为高效和有效。因此，在利用循环信息时，我们选择省略和弦。据此，我们提出了一种基于无和弦结构的图神经网络（CSGNN），并证明了其表达能力严格优于具有多项式复杂度的k-hop GNN（KPGNN）。在现实世界数据集上的实验结果表明，CSGNN在各种图任务中优于现有的GNNs，同时具有更低的计算成本和更好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Researchers have proposed various methods of incorporating more structuredinformation into the design of Graph Neural Networks (GNNs) to enhance theirexpressiveness. However, these methods are either computationally expensive orlacking in provable expressiveness. In this paper, we observe that the chordsincrease the complexity of the graph structure while contributing little usefulinformation in many cases. In contrast, chordless structures are more efficientand effective for representing the graph. Therefore, when leveraging theinformation of cycles, we choose to omit the chords. Accordingly, we propose aChordless Structure-based Graph Neural Network (CSGNN) and prove that itsexpressiveness is strictly more powerful than the k-hop GNN (KPGNN) withpolynomial complexity. Experimental results on real-world datasets demonstratethat CSGNN outperforms existing GNNs across various graph tasks while incurringlower computational costs and achieving better performance than the GNNs of3-WL expressiveness.</description>
      <author>example@mail.com (Hongxu Pan, Shuxian Hu, Mo Zhou, Zhibin Wang, Rong Gu, Chen Tian, Kun Yang, Sheng Zhong)</author>
      <guid isPermaLink="false">2505.19188v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>InfoCons: Identifying Interpretable Critical Concepts in Point Clouds via Information Theory</title>
      <link>http://arxiv.org/abs/2505.19820v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML 2025 (Poster)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了点云模型的可解释性，重点关注将模型输出归因于可解释的关键概念，并提出了InfoCons解释框架，通过信息论原理将点云分解为三维概念，以检验其对模型预测的因果效应。&lt;h4&gt;背景&lt;/h4&gt;点云模型在自动驾驶等安全关键场景中的应用，对模型的可解释性提出了迫切需求。&lt;h4&gt;目的&lt;/h4&gt;为了实现人类可理解的模型故障诊断，提出了一种理想的临界子集，该子集应能够忠实保留对预测有因果影响的数据点，并且概念上是一致的，形成与人类感知相符合的语义结构。&lt;h4&gt;方法&lt;/h4&gt;InfoCons框架应用信息论原理，将点云分解为三维概念，并通过可学习的先验知识来检验这些概念对模型预测的因果效应。&lt;h4&gt;主要发现&lt;/h4&gt;InfoCons在合成数据集上进行了评估，并与四个基线进行了定性和定量的比较。此外，在两个真实世界数据集和两个应用中展示了其可扩展性和灵活性。&lt;h4&gt;结论&lt;/h4&gt;InfoCons框架能够有效地解释点云模型，并在实际应用中显示出良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;Given their deployment in safety-critical scenarios such as autonomous vehicles, the interpretability of point cloud (PC) models has become imperative. We focus on attributing PC model outputs to interpretable critical concepts, defined as meaningful subsets of the input point cloud. To enable human-understandable diagnostics of model failures, an ideal critical subset should be *faithful* (preserving points that causally influence predictions) and *conceptually coherent* (forming semantically meaningful structures that align with human perception). We propose InfoCons, an explanation framework that applies information-theoretic principles to decompose the point cloud into 3D concepts, enabling the examination of their causal effect on model predictions with learnable priors. We evaluate InfoCons on synthetic datasets for classification, comparing it qualitatively and quantitatively with four baselines. We further demonstrate its scalability and flexibility on two real-world datasets and in two applications that utilize critical scores of PC.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpretability of point cloud (PC) models becomes imperative given theirdeployment in safety-critical scenarios such as autonomous vehicles. We focuson attributing PC model outputs to interpretable critical concepts, defined asmeaningful subsets of the input point cloud. To enable human-understandablediagnostics of model failures, an ideal critical subset should be *faithful*(preserving points that causally influence predictions) and *conceptuallycoherent* (forming semantically meaningful structures that align with humanperception). We propose InfoCons, an explanation framework that appliesinformation-theoretic principles to decompose the point cloud into 3D concepts,enabling the examination of their causal effect on model predictions withlearnable priors. We evaluate InfoCons on synthetic datasets forclassification, comparing it qualitatively and quantitatively with fourbaselines. We further demonstrate its scalability and flexibility on tworeal-world datasets and in two applications that utilize critical scores of PC.</description>
      <author>example@mail.com (Feifei Li, Mi Zhang, Zhaoxiang Wang, Min Yang)</author>
      <guid isPermaLink="false">2505.19820v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>FHGS: Feature-Homogenized Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2505.19154v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于3D高斯散布（3DGS）的场景理解方法，并针对3DGS方法在处理异向性颜色表示和同向性语义特征之间的矛盾问题进行了改进。&lt;h4&gt;背景&lt;/h4&gt;尽管3DGS方法在渲染方面具有高效性，但它们未能解决高斯基元异向性颜色表示与语义特征同向性要求之间的固有矛盾，导致跨视图特征一致性不足。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一限制，本文提出了FHGS（特征同质化高斯散布），这是一种受物理模型启发的创新3D特征融合框架，能够在保持3DGS实时渲染效率的同时，实现从预训练模型到3D场景的高精度2D特征映射。&lt;h4&gt;方法&lt;/h4&gt;FHGS引入了以下创新：首先，提出了一种通用的特征融合架构，能够将大规模预训练模型的语义特征（如SAM、CLIP）嵌入到稀疏3D结构中；其次，引入了一种非可微分的特征融合机制，使语义特征表现出视点无关的同向分布；第三，提出了一种受电势场启发的双驱动优化策略，结合了来自语义特征场的外部监督和内部基元聚类指导。&lt;h4&gt;主要发现&lt;/h4&gt;FHGS通过这些创新，实现了全局语义对齐和局部结构一致性的协同优化，提高了跨视图特征的一致性。&lt;h4&gt;结论&lt;/h4&gt;FHGS能够有效地解决3DGS在场景理解中的局限性，并通过实验证明了其有效性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;Scene understanding based on 3D Gaussian Splatting (3DGS) has recently achieved notable advances. Although 3DGS related methods have efficient rendering capabilities, they fail to address the inherent contradiction between the anisotropic color representation of gaussian primitives and the isotropic requirements of semantic features, leading to insufficient cross-view feature consistency. To overcome the limitation, we propose FHGS (Feature-Homogenized Gaussian Splatting), a novel 3D feature fusion framework inspired by physical models, which can achieve high-precision mapping of arbitrary 2D features from pre-trained models to 3D scenes while preserving the real-time rendering efficiency of 3DGS. Specifically, our FHGS introduces the following innovations: Firstly, a universal feature fusion architecture is proposed, enabling robust embedding of large-scale pre-trained models' semantic features (e.g., SAM, CLIP) into sparse 3D structures. Secondly, a non-differentiable feature fusion mechanism is introduced, which enables semantic features to exhibit viewpoint independent isotropic distributions. This fundamentally balances the anisotropic rendering of gaussian primitives and the isotropic expression of features; Thirdly, a dual-driven optimization strategy inspired by electric potential fields is proposed, which combines external supervision from semantic feature fields with internal primitive clustering guidance. This mechanism enables synergistic optimization of global semantic alignment and local structural consistency. More interactive results can be accessed on: https://fhgs.cuastro.org/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scene understanding based on 3D Gaussian Splatting (3DGS) has recentlyachieved notable advances. Although 3DGS related methods have efficientrendering capabilities, they fail to address the inherent contradiction betweenthe anisotropic color representation of gaussian primitives and the isotropicrequirements of semantic features, leading to insufficient cross-view featureconsistency. To overcome the limitation, we proposes $\textit{FHGS}$(Feature-Homogenized Gaussian Splatting), a novel 3D feature fusion frameworkinspired by physical models, which can achieve high-precision mapping ofarbitrary 2D features from pre-trained models to 3D scenes while preserving thereal-time rendering efficiency of 3DGS. Specifically, our $\textit{FHGS}$introduces the following innovations: Firstly, a universal feature fusionarchitecture is proposed, enabling robust embedding of large-scale pre-trainedmodels' semantic features (e.g., SAM, CLIP) into sparse 3D structures.Secondly, a non-differentiable feature fusion mechanism is introduced, whichenables semantic features to exhibit viewpoint independent isotropicdistributions. This fundamentally balances the anisotropic rendering ofgaussian primitives and the isotropic expression of features; Thirdly, adual-driven optimization strategy inspired by electric potential fields isproposed, which combines external supervision from semantic feature fields withinternal primitive clustering guidance. This mechanism enables synergisticoptimization of global semantic alignment and local structural consistency.More interactive results can be accessed on: https://fhgs.cuastro.org/.</description>
      <author>example@mail.com (Q. G. Duan, Benyun Zhao, Mingqiao Han Yijun Huang, Ben M. Chen)</author>
      <guid isPermaLink="false">2505.19154v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Two Causally Related Needles in a Video Haystack</title>
      <link>http://arxiv.org/abs/2505.19853v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种长视频理解基准Causal2Needles，用于评估视频语言模型（VLMs）在视频理解方面的能力。&lt;h4&gt;背景&lt;/h4&gt;评估视频语言模型（VLMs）的视频理解能力是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出Causal2Needles基准，以评估VLMs从长视频中提取信息并理解它们的能力，以及建模人类行为因果关系的能力。&lt;h4&gt;方法&lt;/h4&gt;Causal2Needles引入了2-needle问题，这些问题要求从长视频中的人类行为事件及其相关叙述文本中提取信息。为了防止文本偏见，这些问题包含两种互补格式：一种要求识别包含答案的视频剪辑，另一种要求提供该视频剪辑中无关视觉细节的文本描述。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在现有基准中表现优异的模型在2-needle视觉接地方面存在困难，并且模型性能与两个针之间的距离呈负相关。&lt;h4&gt;结论&lt;/h4&gt;这些发现突出了当前VLMs的临界局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Evaluating the video understanding capabilities of Video-Language Models(VLMs) remains a significant challenge. We propose a long-context videounderstanding benchmark, Causal2Needles, that assesses two crucial abilitiesinsufficiently evaluated by existing benchmarks: (1) the ability to extractinformation from two separate locations in a long video and understand themjointly, and (2) the ability to model the world in terms of cause and effect inhuman behaviors. Specifically, Causal2Needles introduces 2-needle questions,which require extracting information from both the cause and effecthuman-behavior events in a long video and the associated narration text. Toprevent textual bias, these questions comprise two complementary formats: oneasking to identify the video clip containing the answer, and one asking for thetextual description of an unrelated visual detail from that video clip. Ourexperiments reveal that models excelling in pre-existing benchmarks strugglewith 2-needle visual grounding, and the model performance is negativelycorrelated with the distance between the two needles. These findings highlightcritical limitations in current VLMs.</description>
      <author>example@mail.com (Miaoyu Li, Qin Chao, Boyang Li)</author>
      <guid isPermaLink="false">2505.19853v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Omni-Perception: Omnidirectional Collision Avoidance for Legged Locomotion in Dynamic Environments</title>
      <link>http://arxiv.org/abs/2505.19214v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Omni-Perception的端到端移动策略，通过直接处理原始激光雷达点云数据实现3D空间意识和全方位碰撞避免，以在复杂三维环境中实现鲁棒的移动。&lt;h4&gt;背景&lt;/h4&gt;在复杂三维环境中，敏捷移动需要强大的空间意识来安全地避开各种障碍，如空中杂乱、不平坦的地形和动态的代理。基于深度的感知方法通常在传感器噪声、光照变化、中间表示（例如高程图）的计算开销以及非平面障碍处理上存在困难，限制了在非结构化环境中的性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以实现更鲁棒的空间感知和全方位碰撞避免，以提高在复杂环境中的移动性能。&lt;h4&gt;方法&lt;/h4&gt;论文中提出的Omni-Perception策略的核心是PD-RiskNet（近端-远端风险感知分层网络），这是一种新颖的感知模块，用于解释时空激光雷达数据以进行环境风险评估。为了促进高效的政策学习，开发了一个高保真激光雷达模拟工具包，具有现实的噪声建模和快速光线投射，与Isaac Gym、Genesis和MuJoCo等平台兼容，以实现可扩展的培训和有效的模拟到现实的迁移。&lt;h4&gt;主要发现&lt;/h4&gt;直接从原始激光雷达数据学习反应控制策略，使机器人能够比依赖中间地图或有限感知的方法更鲁棒地在具有静态和动态障碍的复杂环境中导航。通过真实世界实验和广泛模拟验证了Omni-Perception的有效性，证明了在高度动态环境中具有强大的全方位避免能力和卓越的移动性能。&lt;h4&gt;结论&lt;/h4&gt;Omni-Perception在提高复杂环境中移动机器人的鲁棒性方面具有显著潜力，并且其代码和模型将被开源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Agile locomotion in complex 3D environments requires robust spatial awarenessto safely avoid diverse obstacles such as aerial clutter, uneven terrain, anddynamic agents. Depth-based perception approaches often struggle with sensornoise, lighting variability, computational overhead from intermediaterepresentations (e.g., elevation maps), and difficulties with non-planarobstacles, limiting performance in unstructured environments. In contrast,direct integration of LiDAR sensing into end-to-end learning for leggedlocomotion remains underexplored. We propose Omni-Perception, an end-to-endlocomotion policy that achieves 3D spatial awareness and omnidirectionalcollision avoidance by directly processing raw LiDAR point clouds. At its coreis PD-RiskNet (Proximal-Distal Risk-Aware Hierarchical Network), a novelperception module that interprets spatio-temporal LiDAR data for environmentalrisk assessment. To facilitate efficient policy learning, we develop ahigh-fidelity LiDAR simulation toolkit with realistic noise modeling and fastraycasting, compatible with platforms such as Isaac Gym, Genesis, and MuJoCo,enabling scalable training and effective sim-to-real transfer. Learningreactive control policies directly from raw LiDAR data enables the robot tonavigate complex environments with static and dynamic obstacles more robustlythan approaches relying on intermediate maps or limited sensing. We validateOmni-Perception through real-world experiments and extensive simulation,demonstrating strong omnidirectional avoidance capabilities and superiorlocomotion performance in highly dynamic environments. We will open-source ourcode and models.</description>
      <author>example@mail.com (Zifan Wang, Teli Ma, Yufei Jia, Xun Yang, Jiaming Zhou, Wenlong Ouyang, Qiang Zhang, Junwei Liang)</author>
      <guid isPermaLink="false">2505.19214v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>HGCL: Hierarchical Graph Contrastive Learning for User-Item Recommendation</title>
      <link>http://arxiv.org/abs/2505.19020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Hierarchical Graph Contrastive Learning (HGCL)的新型图对比学习方法，用于用户-物品推荐。该方法通过整合层次化物品结构来提高推荐准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的GCL方法在用户-物品推荐中表现良好，但通常缺乏对层次化物品结构的明确建模，而这些结构反映了物品的内在组织特性，对于提高推荐精度至关重要。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入层次化物品结构来增强GCL方法在推荐任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;HGCL首先使用跨层对比学习预训练GCL模块以获得用户和物品表示；然后通过表示压缩和聚类方法构建用户-物品二分图；最后，在层次化图上微调用户和物品表示，并基于用户-物品交互分数提供推荐。&lt;h4&gt;主要发现&lt;/h4&gt;在三个广泛使用的基准数据集上的实验表明，HGCL相较于现有基线模型具有优越的性能，证明了层次化物品结构在增强GCL方法中的贡献。&lt;h4&gt;结论&lt;/h4&gt;HGCL作为一种结合层次化物品结构的GCL方法，能够显著提高推荐任务的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Graph Contrastive Learning (GCL), which combines graph neural networks with contrastive learning, has evolved as a pivotal tool in user-item recommendations. While promising, existing GCL methods often lack explicit modeling of hierarchical item structures, which represent item similarities across varying resolutions. Such hierarchical item structures are ubiquitous in various items (e.g., online products and local businesses), and reflect their inherent organizational properties that serve as critical signals for enhancing recommendation accuracy. In this paper, we propose Hierarchical Graph Contrastive Learning (HGCL), a novel GCL method that incorporates hierarchical item structures for user-item recommendations. First, HGCL pre-trains a GCL module using cross-layer contrastive learning to obtain user and item representations. Second, HGCL employs a representation compression and clustering method to construct a two-hierarchy user-item bipartite graph. Ultimately, HGCL fine-tunes user and item representations by learning on the hierarchical graph, and then provides recommendations based on user-item interaction scores. Experiments on three widely adopted benchmark datasets ranging from 70K to 382K nodes confirm the superior performance of HGCL over existing baseline models, highlighting the contribution of hierarchical item structures in enhancing GCL methods for recommendation tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Contrastive Learning (GCL), which fuses graph neural networks withcontrastive learning, has evolved as a pivotal tool in user-itemrecommendations. While promising, existing GCL methods often lack explicitmodeling of hierarchical item structures, which represent item similaritiesacross varying resolutions. Such hierarchical item structures are ubiquitous invarious items (e.g., online products and local businesses), and reflect theirinherent organizational properties that serve as critical signals for enhancingrecommendation accuracy. In this paper, we propose Hierarchical GraphContrastive Learning (HGCL), a novel GCL method that incorporates hierarchicalitem structures for user-item recommendations. First, HGCL pre-trains a GCLmodule using cross-layer contrastive learning to obtain user and itemrepresentations. Second, HGCL employs a representation compression andclustering method to construct a two-hierarchy user-item bipartite graph.Ultimately, HGCL fine-tunes user and item representations by learning on thehierarchical graph, and then provides recommendations based on user-iteminteraction scores. Experiments on three widely adopted benchmark datasetsranging from 70K to 382K nodes confirm the superior performance of HGCL overexisting baseline models, highlighting the contribution of hierarchical itemstructures in enhancing GCL methods for recommendation tasks.</description>
      <author>example@mail.com (Jiawei Xue, Zhen Yang, Haitao Lin, Ziji Zhang, Luzhu Wang, Yikun Gu, Yao Xu, Xin Li)</author>
      <guid isPermaLink="false">2505.19020v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Specialization: Benchmarking LLMs for Transliteration of Indian Languages</title>
      <link>http://arxiv.org/abs/2505.19851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了在多语言自然语言处理中，从一种文字到另一种文字的转写过程的重要性，特别是在像印度这样的语言多样性的环境中。研究评估了多个大型语言模型（LLMs）在转写任务上的表现，与IndicXlit这一最先进的转写模型进行了比较。&lt;h4&gt;背景&lt;/h4&gt;转写在多语言自然语言处理中扮演重要角色，特别是在语言多样化的环境中，如印度。&lt;h4&gt;目的&lt;/h4&gt;评估多个大型语言模型在转写任务上的表现，并与IndicXlit进行对比。&lt;h4&gt;方法&lt;/h4&gt;使用GPT-4o、GPT-4.5、GPT-4.1、Gemma-3-27B-it和Mistral-Large等LLMs，在十个主要印度语言上与IndicXlit进行了比较。实验使用了Dakshina和Aksharantardatasets等标准基准，通过Top-1 Accuracy和Character Error Rate来评估性能。&lt;h4&gt;主要发现&lt;/h4&gt;GPT系列模型在大多数情况下优于其他LLMs和IndicXlit。对GPT-4o进行微调能显著提高特定语言的表现。错误分析和噪声条件下的鲁棒性测试进一步阐明了LLMs相对于专业模型的优势。&lt;h4&gt;结论&lt;/h4&gt;基础模型在广泛的专用应用中具有高效性，并且与专业模型相比具有更低的成本。&lt;h4&gt;翻译&lt;/h4&gt;The process of transliteration, which maps text from one script to another, plays a crucial role in multilingual natural language processing, particularly within linguistically diverse contexts such as India. Despite significant advancements through specialized models like IndicXlit, recent developments in large language models suggest a potential for general-purpose models to excel at this task without explicit task-specific training. The current work systematically evaluates the performance of prominent LLMs, including GPT-4o, GPT-4.5, GPT-4.1, Gemma-3-27B-it, and Mistral-Large against IndicXlit, a state-of-the-art transliteration model, across ten major Indian languages. Experiments utilized standard benchmarks, including Dakshina and Aksharantardatasets, with performance assessed via Top-1 Accuracy and Character Error Rate. Our findings reveal that while GPT family models generally outperform other LLMs and IndicXlit for most instances. Additionally, fine-tuning GPT-4o improves performance on specific languages notably. An extensive error analysis and robustness testing under noisy conditions further elucidate strengths of LLMs compared to specialized models, highlighting the efficacy of foundational models for a wide spectrum of specialized applications with minimal overhead.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transliteration, the process of mapping text from one script to another,plays a crucial role in multilingual natural language processing, especiallywithin linguistically diverse contexts such as India. Despite significantadvancements through specialized models like IndicXlit, recent developments inlarge language models suggest a potential for general-purpose models to excelat this task without explicit task-specific training. The current worksystematically evaluates the performance of prominent LLMs, including GPT-4o,GPT-4.5, GPT-4.1, Gemma-3-27B-it, and Mistral-Large against IndicXlit, astate-of-the-art transliteration model, across ten major Indian languages.Experiments utilized standard benchmarks, including Dakshina and Aksharantardatasets, with performance assessed via Top-1 Accuracy and Character ErrorRate. Our findings reveal that while GPT family models generally outperformother LLMs and IndicXlit for most instances. Additionally, fine-tuning GPT-4oimproves performance on specific languages notably. An extensive error analysisand robustness testing under noisy conditions further elucidate strengths ofLLMs compared to specialized models, highlighting the efficacy of foundationalmodels for a wide spectrum of specialized applications with minimal overhead.</description>
      <author>example@mail.com (Gulfarogh Azam, Mohd Sadique, Saif Ali, Mohammad Nadeem, Erik Cambria, Shahab Saquib Sohail, Mohammad Sultan Alam)</author>
      <guid isPermaLink="false">2505.19851v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Discrete Markov Bridge</title>
      <link>http://arxiv.org/abs/2505.19752v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Discrete Markov Bridge的新型框架，用于离散表示学习，以解决现有方法在训练过程中使用固定速率转换矩阵的局限性。&lt;h4&gt;背景&lt;/h4&gt;离散扩散作为离散数据建模的一种新兴范式，但其现有方法通常在训练过程中依赖于固定的速率转换矩阵，这限制了潜在表示的表达能力，并约束了整体设计空间。&lt;h4&gt;目的&lt;/h4&gt;提出Discrete Markov Bridge框架，旨在解决现有方法的局限性，提高潜在表示的表达能力，并扩展设计空间。&lt;h4&gt;方法&lt;/h4&gt;该方法基于两个关键组件：矩阵学习和评分学习。进行了严格的理论分析，为矩阵学习建立了正式的性能保证，并证明了整体框架的收敛性。此外，分析了该方法的空间复杂度，解决了先前研究中识别出的实际约束。&lt;h4&gt;主要发现&lt;/h4&gt;在Text8数据集上，提出的Discrete Markov Bridge实现了1.38的ELBO，优于现有基线。此外，在CIFAR-10数据集上，该模型表现出与特定图像生成方法相当的性能。&lt;h4&gt;结论&lt;/h4&gt;Discrete Markov Bridge框架在离散表示学习方面表现出有效性，为离散数据建模提供了一种新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Discrete diffusion has recently emerged as a promising paradigm in discretedata modeling. However, existing methods typically rely on a fixed ratetransition matrix during training, which not only limits the expressiveness oflatent representations, a fundamental strength of variational methods, but alsoconstrains the overall design space. To address these limitations, we proposeDiscrete Markov Bridge, a novel framework specifically designed for discreterepresentation learning. Our approach is built upon two key components: MatrixLearning and Score Learning. We conduct a rigorous theoretical analysis,establishing formal performance guarantees for Matrix Learning and proving theconvergence of the overall framework. Furthermore, we analyze the spacecomplexity of our method, addressing practical constraints identified in priorstudies. Extensive empirical evaluations validate the effectiveness of theproposed Discrete Markov Bridge, which achieves an Evidence Lower Bound (ELBO)of 1.38 on the Text8 dataset, outperforming established baselines. Moreover,the proposed model demonstrates competitive performance on the CIFAR-10dataset, achieving results comparable to those obtained by image-specificgeneration approaches.</description>
      <author>example@mail.com (Hengli Li, Yuxuan Wang, Song-Chun Zhu, Ying Nian Wu, Zilong Zheng)</author>
      <guid isPermaLink="false">2505.19752v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>SPADE: Towards Scalable Path Planning Architecture on Actionable Multi-Domain 3D Scene Graphs</title>
      <link>http://arxiv.org/abs/2505.19098v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IROS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SPADE的路径规划框架，用于动态环境中的自主导航，该框架结合了分层路径规划和局部几何感知，以实现动态场景中的无碰撞移动。&lt;h4&gt;背景&lt;/h4&gt;现有的路径规划方法在场景图上遇到路径阻塞时，会进行整个场景图的重新规划，导致效率低下。&lt;h4&gt;目的&lt;/h4&gt;设计一个高效且能够在动态环境中进行自主导航的路径规划框架。&lt;h4&gt;方法&lt;/h4&gt;SPADE将规划问题分为两个部分：(a)解决稀疏的抽象全局层规划；(b)随着局部几何场景导航在更密集的局部低层中进行迭代路径细化。为了在密集的多任务域场景图中高效提取可行路径，该框架在路径规划之前强制进行有信息的采样。&lt;h4&gt;主要发现&lt;/h4&gt;SPADE优先考虑局部层规划和局部几何场景导航，在处理复杂和动态场景时，既能够导航动态场景，又能保持计算可行路径的效率。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的仿真实验和四足机器人的实际部署，验证了SPADE在处理复杂和动态场景中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we introduce SPADE, a path planning framework designed for autonomous navigation in dynamic environments using 3D scene graphs. SPADE combines hierarchical path planning with local geometric awareness to enable collision-free movement in dynamic scenes. The framework bifurcates the planning problem into two: (a) solving the sparse abstract global layer plan and (b) iterative path refinement across denser lower local layers in step with local geometric scene navigation. To ensure efficient extraction of a feasible route in a dense multi-task domain scene graphs, the framework enforces informed sampling of traversable edges prior to path-planning. This removes extraneous information not relevant to path-planning and reduces the overall planning complexity over a graph. Existing approaches address the problem of path planning over scene graphs by decoupling hierarchical and geometric path evaluation processes. Specifically, this results in an inefficient replanning over the entire scene graph when encountering path obstructions blocking the original route. In contrast, SPADE prioritizes local layer planning coupled with local geometric scene navigation, enabling navigation through dynamic scenes while maintaining efficiency in computing a traversable route. We validate SPADE through extensive simulation experiments and real-world deployment on a quadrupedal robot, demonstrating its efficacy in handling complex and dynamic scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we introduce SPADE, a path planning framework designed forautonomous navigation in dynamic environments using 3D scene graphs. SPADEcombines hierarchical path planning with local geometric awareness to enablecollision-free movement in dynamic scenes. The framework bifurcates theplanning problem into two: (a) solving the sparse abstract global layer planand (b) iterative path refinement across denser lower local layers in step withlocal geometric scene navigation. To ensure efficient extraction of a feasibleroute in a dense multi-task domain scene graphs, the framework enforcesinformed sampling of traversable edges prior to path-planning. This removesextraneous information not relevant to path-planning and reduces the overallplanning complexity over a graph. Existing approaches address the problem ofpath planning over scene graphs by decoupling hierarchical and geometric pathevaluation processes. Specifically, this results in an inefficient replanningover the entire scene graph when encountering path obstructions blocking theoriginal route. In contrast, SPADE prioritizes local layer planning coupledwith local geometric scene navigation, enabling navigation through dynamicscenes while maintaining efficiency in computing a traversable route. Wevalidate SPADE through extensive simulation experiments and real-worlddeployment on a quadrupedal robot, demonstrating its efficacy in handlingcomplex and dynamic scenarios.</description>
      <author>example@mail.com (Vignesh Kottayam Viswanathan, Akash Patel, Mario Alberto Valdes Saucedo, Sumeet Satpute, Christoforos Kanellakis, George Nikolakopoulos)</author>
      <guid isPermaLink="false">2505.19098v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>ExAnte: A Benchmark for Ex-Ante Inference in Large Language Models</title>
      <link>http://arxiv.org/abs/2505.19533v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了大型语言模型在时间推理方面的挑战，并提出了一种新的任务和基准来评估模型在遵循时间约束下的推理能力。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在时间推理上面临挑战，即使在设定时间截止点的情况下，模型也可能受到未来事件信息的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一个评估大型语言模型在遵循时间约束下推理能力的新任务和基准。&lt;h4&gt;方法&lt;/h4&gt;设计了一个包括股票预测、维基百科事件预测、科学出版物预测和问答等任务的基准，并使用泄漏率来量化模型对截止时间后信息的依赖。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，大型语言模型在遵循时间截止点方面存在困难，展示了在时间推理上的持续挑战。&lt;h4&gt;结论&lt;/h4&gt;该基准为评估和推进大型语言模型时间推理能力提供了潜在的评价框架，以促进其在时间敏感应用中的发展。&lt;h4&gt;翻译&lt;/h4&gt;Large language models (LLMs) face significant challenges in ex-antereasoning, where analysis, inference, or predictions must be made without access to information from future events. Even with explicit prompts enforcing temporal cutoffs, LLMs often generate outputs influenced by internalized knowledge of events beyond the specified cutoff. This paper introduces a novel task and benchmark designed to evaluate the ability of LLMs to reason while adhering to such temporal constraints. The benchmark includes a variety of tasks: stock prediction, Wikipedia event prediction, scientific publication prediction, and Question Answering (QA), designed to assess factual knowledge under temporal cutoff constraints. We use leakage rate to quantify models' reliance on future information beyond cutoff timestamps. Experimental results reveal that LLMs struggle to consistently adhere to temporal cutoffs across common prompting strategies and tasks, demonstrating persistent challenges in ex-ante reasoning. This benchmark provides a potential evaluation framework to advance the development of LLMs' temporal reasoning ability for time-sensitive applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) face significant challenges in ex-antereasoning, where analysis, inference, or predictions must be made withoutaccess to information from future events. Even with explicit prompts enforcingtemporal cutoffs, LLMs often generate outputs influenced by internalizedknowledge of events beyond the specified cutoff. This paper introduces a noveltask and benchmark designed to evaluate the ability of LLMs to reason whileadhering to such temporal constraints. The benchmark includes a variety oftasks: stock prediction, Wikipedia event prediction, scientific publicationprediction, and Question Answering (QA), designed to assess factual knowledgeunder temporal cutoff constraints. We use leakage rate to quantify models'reliance on future information beyond cutoff timestamps. Experimental resultsreveal that LLMs struggle to consistently adhere to temporal cutoffs acrosscommon prompting strategies and tasks, demonstrating persistent challenges inex-ante reasoning. This benchmark provides a potential evaluation framework toadvance the development of LLMs' temporal reasoning ability for time-sensitiveapplications.</description>
      <author>example@mail.com (Yachuan Liu, Xiaochun Wei, Lin Shi, Xinnuo Li, Bohan Zhang, Paramveer Dhillon, Qiaozhu Mei)</author>
      <guid isPermaLink="false">2505.19533v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Disentangled Human Body Representation Based on Unsupervised Semantic-Aware Learning</title>
      <link>http://arxiv.org/abs/2505.19049v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在无监督学习框架下具有可控细粒度语义和精确重建的人体表示方法。&lt;h4&gt;背景&lt;/h4&gt;近年来，3D人体表示学习受到越来越多的关注，但大量手工定义的人体约束复杂性和缺乏监督数据限制了现有工作在语义和表示能力方面对人体的可控和精确表示。&lt;h4&gt;目的&lt;/h4&gt;提出一种可以在无监督学习框架下学习人体几何语义测量与潜在码之间对应关系的人体表示方法，从而通过修改潜在编码参数来控制人体形状和姿态。&lt;h4&gt;方法&lt;/h4&gt;设计了一种全感知骨骼分组解耦策略来学习人体几何语义测量与潜在码之间的对应关系，并利用骨骼分组全感知编码器和无监督解耦损失学习表示模型。同时，引入了基于模板的残差学习方案以简化复杂身体形状和姿态空间中人体潜在参数的学习。此外，使用部分感知解码器来促进可控细粒度语义的学习。&lt;h4&gt;主要发现&lt;/h4&gt;该方法具有精确重建的能力，并且由于几何意义上的潜在码，它可以应用于从人体姿态转换到双线性潜在码插值的广泛范围。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，该方法在公共3D人体数据集上具有精确重建的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，3D人体表示的学习越来越受到关注。然而，大量手工定义的人体约束的复杂性和缺乏监督数据限制了现有工作在语义和表示能力方面对人体的可控和精确表示。在本文中，我们提出了一种在无监督学习框架下具有可控细粒度语义和高度精确重建的人体表示方法。特别地，我们设计了一种全感知的骨骼分组解耦策略来学习身体几何语义测量与潜在码之间的对应关系，从而通过修改潜在编码参数来控制人体形状和姿态。借助骨骼分组的全感知编码器和无监督解耦损失，我们的表示模型通过无监督的方式进行学习。此外，将基于模板的残差学习方案注入编码器以简化复杂身体形状和姿态空间中人体潜在参数的学习。由于潜在的几何意义代码，它可以用于广泛的范围，从人体姿态转换到双线性潜在代码插值。更进一步，利用部分感知解码器来促进可控细粒度语义的学习。在公共3D人体数据集上的实验结果表明，该方法具有精确重建的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, more and more attention has been paid to the learning of 3Dhuman representation. However, the complexity of lots of hand-defined humanbody constraints and the absence of supervision data limit that the existingworks controllably and accurately represent the human body in views ofsemantics and representation ability. In this paper, we propose a human bodyrepresentation with controllable fine-grained semantics and high precison ofreconstruction in an unsupervised learning framework. In particularly, wedesign a whole-aware skeleton-grouped disentangle strategy to learn acorrespondence between geometric semantical measurement of body and latentcodes, which facilitates the control of shape and posture of human body bymodifying latent coding paramerers. With the help of skeleton-groupedwhole-aware encoder and unsupervised disentanglement losses, our representationmodel is learned by an unsupervised manner. Besides, a based-template residuallearning scheme is injected into the encoder to ease of learning human bodylatent parameter in complicated body shape and pose spaces. Because of thegeometrically meaningful latent codes, it can be used in a wide range ofapplications, from human body pose transfer to bilinear latent codeinterpolation. Further more, a part-aware decoder is utlized to promote thelearning of controllable fine-grained semantics. The experimental results onpublic 3D human datasets show that the method has the ability of precisereconstruction.</description>
      <author>example@mail.com (Lu Wang, Xishuai Peng, S. Kevin Zhou)</author>
      <guid isPermaLink="false">2505.19049v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Lightweight Embeddings with Graph Rewiring for Collaborative Filtering</title>
      <link>http://arxiv.org/abs/2505.18999v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TOIS'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;LERG是一种基于图协同过滤的轻量级嵌入方法，旨在解决资源受限边缘设备上的嵌入存储成本高和图传播引起的运行时延迟问题。&lt;h4&gt;背景&lt;/h4&gt;随着推荐服务在资源受限的边缘设备上的快速扩展，基于图神经网络（GNN）的推荐系统面临高嵌入存储成本和图传播导致的运行时延迟等挑战。&lt;h4&gt;目的&lt;/h4&gt;提出LERG，以降低嵌入存储成本和优化图传播，从而在资源受限的边缘设备上实现高效的推荐系统。&lt;h4&gt;方法&lt;/h4&gt;LERG在保留LEGCF的代码簿结构的基础上，引入量化技术以减少存储成本，并通过预训练和细调阶段优化图传播。预训练阶段使用资源丰富的服务器上的完整交互图，细调阶段通过无梯度二进制整数规划方法识别和修剪低贡献实体，构建一个去除这些实体的重连图。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，LERG在三个公开基准数据集上实现了优于现有方法的推荐性能，同时显著降低了存储和计算成本。&lt;h4&gt;结论&lt;/h4&gt;LERG是一种有效的推荐系统，它能够在资源受限的边缘设备上提供高性能的推荐服务，同时降低存储和计算成本。&lt;h4&gt;翻译&lt;/h4&gt;As recommendation services scale rapidly and their deployment now commonly involves resource-constrained edge devices, GNN-based recommender systems face significant challenges, including high embedding storage costs and runtime latency from graph propagations. Our previous work, LEGCF, effectively reduced embedding storage costs but struggled to maintain recommendation performance under stricter storage limits. Additionally, LEGCF did not address the extensive runtime computation costs associated with graph propagation, which involves heavy multiplication and accumulation operations (MACs). These challenges consequently hinder effective training and inference on resource-constrained edge devices. To address these limitations, we propose Lightweight Embeddings with Rewired Graph for Graph Collaborative Filtering (LERG), an improved extension of LEGCF. LERG retains LEGCF's compositional codebook structure but introduces quantization techniques to reduce the storage cost, enabling the inclusion of more meta-embeddings within the same storage. To optimize graph propagation, we pretrain the quantized compositional embedding table using the full interaction graph on resource-rich servers, after which a fine-tuning stage is engaged to identify and prune low-contribution entities via a gradient-free binary integer programming approach, constructing a rewired graph that excludes these entities (i.e., user/item nodes) from propagating signals. The quantized compositional embedding table with selective embedding participation and sparse rewired graph are transferred to edge devices which significantly reduce computation memory and inference time. Experiments on three public benchmark datasets, including an industry-scale dataset, demonstrate that LERG achieves superior recommendation performance while dramatically reducing storage and computation costs for graph-based recommendation services.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As recommendation services scale rapidly and their deployment now commonlyinvolves resource-constrained edge devices, GNN-based recommender systems facesignificant challenges, including high embedding storage costs and runtimelatency from graph propagations. Our previous work, LEGCF, effectively reducedembedding storage costs but struggled to maintain recommendation performanceunder stricter storage limits. Additionally, LEGCF did not address theextensive runtime computation costs associated with graph propagation, whichinvolves heavy multiplication and accumulation operations (MACs). Thesechallenges consequently hinder effective training and inference onresource-constrained edge devices. To address these limitations, we proposeLightweight Embeddings with Rewired Graph for Graph Collaborative Filtering(LERG), an improved extension of LEGCF. LERG retains LEGCFs compositionalcodebook structure but introduces quantization techniques to reduce the storagecost, enabling the inclusion of more meta-embeddings within the same storage.To optimize graph propagation, we pretrain the quantized compositionalembedding table using the full interaction graph on resource-rich servers,after which a fine-tuning stage is engaged to identify and prunelow-contribution entities via a gradient-free binary integer programmingapproach, constructing a rewired graph that excludes these entities (i.e.,user/item nodes) from propagating signals. The quantized compositionalembedding table with selective embedding participation and sparse rewired graphare transferred to edge devices which significantly reduce computation memoryand inference time. Experiments on three public benchmark datasets, includingan industry-scale dataset, demonstrate that LERG achieves superiorrecommendation performance while dramatically reducing storage and computationcosts for graph-based recommendation services.</description>
      <author>example@mail.com (Xurong Liang, Tong Chen, Wei Yuan, Hongzhi Yin)</author>
      <guid isPermaLink="false">2505.18999v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Tabular Data within Systemic Contexts Need Grounding</title>
      <link>http://arxiv.org/abs/2505.19825v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的表格基础模型概念，即语义链接表（SLT），旨在解决现有模型在处理大规模、真实世界数据时忽略数据复杂性和操作环境的问题。&lt;h4&gt;背景&lt;/h4&gt;当前研究在处理表格数据时，往往将表格视为独立实体，并假设信息完整性，从而忽视了重要操作环境。&lt;h4&gt;目的&lt;/h4&gt;通过引入语义链接表（SLT）的概念，目的是将表格数据与其真正的操作环境相结合，以充分挖掘机器学习在处理复杂、互联表格数据方面的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为基础模型用于语义链接表（FMSLT）的新模型，该模型整合了声明性和程序性操作知识，以将表格数据置于其真实操作环境中。&lt;h4&gt;主要发现&lt;/h4&gt;实现FMSLT需要访问通常在公共数据集中不可用的操作知识，这突显了领域专家与研究人员之间紧密合作的需求。&lt;h4&gt;结论&lt;/h4&gt;本文揭示了当前表格基础模型的局限性，并提出了以FMSLT为中心的新方向，旨在推进结构化数据的鲁棒、情境感知模型的发展。&lt;h4&gt;翻译&lt;/h4&gt;当前对表格基础模型的研究往往忽略了大规模、真实世界数据的复杂性，将表格视为孤立实体，并假设信息完整性，从而忽视了关键的操作环境。为了解决这个问题，我们引入了语义链接表（SLT）的概念，认识到表格本质上与声明性和程序性操作知识相关联。我们提出了基础模型用于语义链接表（FMSLT），这些模型整合了这些组件，以将表格数据置于其真正的操作环境中。这种全面的表现形式解锁了机器学习在处理复杂、互联表格数据方面的全部潜力。实现FMSLT需要访问通常在公共数据集中不可用的操作知识，这突显了领域专家与研究人员之间紧密合作的需求。我们的工作揭示了当前表格基础模型的局限性，并提出了以FMSLT为中心的新方向，旨在推进结构化数据的鲁棒、情境感知模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current research on tabular foundation models often overlooks thecomplexities of large-scale, real-world data by treating tables as isolatedentities and assuming information completeness, thereby neglecting the vitaloperational context. To address this, we introduce the concept of SemanticallyLinked Tables (SLT), recognizing that tables are inherently connected to bothdeclarative and procedural operational knowledge. We propose Foundation Modelsfor Semantically Linked Tables (FMSLT), which integrate these components toground tabular data within its true operational context. This comprehensiverepresentation unlocks the full potential of machine learning for complex,interconnected tabular data across diverse domains. Realizing FMSLTs requiresaccess to operational knowledge that is often unavailable in public datasets,highlighting the need for close collaboration between domain experts andresearchers. Our work exposes the limitations of current tabular foundationmodels and proposes a new direction centered on FMSLTs, aiming to advancerobust, context-aware models for structured data.</description>
      <author>example@mail.com (Tassilo Klein, Johannes Hoffart)</author>
      <guid isPermaLink="false">2505.19825v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>LangDAug: Langevin Data Augmentation for Multi-Source Domain Generalization in Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2505.19659v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LangDAug的新型数据增强方法，用于解决医学图像分割模型在不同领域泛化困难的问题。&lt;h4&gt;背景&lt;/h4&gt;医学图像分割模型在跨领域泛化方面存在挑战，原因包括各种因素。现有的领域泛化方法包括表示学习和数据增强，但它们各有局限性。&lt;h4&gt;目的&lt;/h4&gt;提出LangDAug方法，旨在提高医学图像分割模型在不同领域泛化方面的性能。&lt;h4&gt;方法&lt;/h4&gt;LangDAug利用基于能量的模型（EBMs）通过对比散度训练来在不同领域之间穿梭，并通过Langevin动力学生成中间样本。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，LangDAug具有正则化效果，并且对于GLM，它通过数据流形的基本维度来上界Rademacher复杂性。实验结果表明，LangDAug优于现有的领域泛化方法，并有效补充了现有的领域随机化方法。&lt;h4&gt;结论&lt;/h4&gt;LangDAug是一种有效提高医学图像分割模型跨领域泛化能力的方法，且其代码库已在GitHub上开源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image segmentation models often struggle to generalize acrossdifferent domains due to various reasons. Domain Generalization (DG) methodsovercome this either through representation learning or data augmentation(DAug). While representation learning methods seek domain-invariant features,they often rely on ad-hoc techniques and lack formal guarantees. DAug methods,which enrich model representations through synthetic samples, have showncomparable or superior performance to representation learning approaches. Wepropose LangDAug, a novel $\textbf{Lang}$evin $\textbf{D}$ata$\textbf{Aug}$mentation for multi-source domain generalization in 2D medicalimage segmentation. LangDAug leverages Energy-Based Models (EBMs) trained viacontrastive divergence to traverse between source domains, generatingintermediate samples through Langevin dynamics. Theoretical analysis shows thatLangDAug induces a regularization effect, and for GLMs, it upper-bounds theRademacher complexity by the intrinsic dimensionality of the data manifold.Through extensive experiments on Fundus segmentation and 2D MRI prostatesegmentation benchmarks, we show that LangDAug outperforms state-of-the-artdomain generalization methods and effectively complements existingdomain-randomization approaches. The codebase for our method is available athttps://github.com/backpropagator/LangDAug.</description>
      <author>example@mail.com (Piyush Tiwary, Kinjawl Bhattacharyya, Prathosh A. P)</author>
      <guid isPermaLink="false">2505.19659v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Co-AttenDWG: Co-Attentive Dimension-Wise Gating and Expert Fusion for Multi-Modal Offensive Content Detection</title>
      <link>http://arxiv.org/abs/2505.19010v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的多模态Co-AttenDWG架构，用于改善文本和图像数据整合在分类、检索和场景理解等任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管预训练模型取得了进展，但当前方法受限于不足的跨模态交互和静态融合策略，无法充分利用不同模态的互补性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出了一种新的多模态Co-AttenDWG架构。&lt;h4&gt;方法&lt;/h4&gt;该架构通过投影文本和图像特征到公共嵌入空间，并使用专门的共注意力机制和维度门控网络来增强模态间的交互。同时，采用双路径编码器处理跨模态信息，并通过专家融合模块结合学习到的门控和自注意力产生统一表示。&lt;h4&gt;主要发现&lt;/h4&gt;在MIMIC和SemEvalMemotion 1.0数据集上的实验结果表明，该方法在跨模态对齐方面取得了显著提升，并达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该模型在多模态应用方面具有巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态学习已成为一个关键的研究领域，因为整合文本和图像数据可以显著提高分类、检索和场景理解等任务中的性能。然而，尽管预训练模型取得了进展，但当前方法受限于不足的跨模态交互和静态融合策略，无法充分利用不同模态的互补性。为了解决这些问题，我们提出了一种新型的多模态Co-AttenDWG架构，该架构利用双路径编码、维度门控的共注意力和高级专家融合。我们的方法首先将文本和图像特征投影到公共嵌入空间，其中专门的共注意力机制使模态之间能够进行同时、细粒度的交互。该机制通过维度门控网络进一步增强，该网络能够自适应地调节通道级别的特征贡献，确保只有最相关的信息被强调。同时，双路径编码器通过处理跨模态信息来细化表示，然后在额外的交叉注意力层进一步对齐模态。经过细化的特征通过专家融合模块进行聚合，该模块结合学习到的门控和自注意力产生鲁棒、统一的表示。我们在MIMIC和SemEvalMemotion 1.0数据集上验证了我们的方法，实验结果表明，在跨模态对齐方面取得了显著改进，并达到了最先进的性能，突出了我们模型在广泛的多模态应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal learning has become a critical research area because integratingtext and image data can significantly improve performance in tasks such asclassification, retrieval, and scene understanding. However, despite progresswith pre-trained models, current approaches are limited by inadequatecross-modal interactions and static fusion strategies that do not fully exploitthe complementary nature of different modalities. To address theseshortcomings, we introduce a novel multi-modal Co-AttenDWG architecture thatleverages dual-path encoding, co-attention with dimension-wise gating, andadvanced expert fusion. Our approach begins by projecting text and imagefeatures into a common embedding space, where a dedicated co-attentionmechanism enables simultaneous, fine-grained interactions between modalities.This mechanism is further enhanced by a dimension-wise gating network thatadaptively regulates the feature contributions at the channel level, ensuringthat only the most relevant information is emphasized. In parallel, dual-pathencoders refine the representations by processing cross-modal informationseparately before an additional cross-attention layer further alignsmodalities. The refined features are then aggregated via an expert fusionmodule that combines learned gating and self-attention to produce a robust,unified representation. We validate our approach on the MIMIC and SemEvalMemotion 1.0, where experimental results demonstrate significant improvementsin cross-modal alignment and state-of-the-art performance, underscoring thepotential of our model for a wide range of multi-modal applications.</description>
      <author>example@mail.com (Md. Mithun Hossain, Md. Shakil Hossain, Sudipto Chaki, M. F. Mridha)</author>
      <guid isPermaLink="false">2505.19010v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>CSTrack: Enhancing RGB-X Tracking via Compact Spatiotemporal Features</title>
      <link>http://arxiv.org/abs/2505.19434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML25!&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的RGB-X跟踪器CSTrack，通过建模紧凑时空特征来实现简单而有效的跟踪。&lt;h4&gt;背景&lt;/h4&gt;现有的RGB-X跟踪器方法通常采用两个并行分支分别处理RGB和X输入流，这导致模型需要同时处理两个分散的特征空间，增加了模型结构和计算过程的复杂性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出CSTrack，旨在通过紧凑时空特征建模实现高效跟踪。&lt;h4&gt;方法&lt;/h4&gt;CSTrack包括两个主要模块：空间紧凑模块和时序紧凑模块。空间紧凑模块将RGB-X双输入流集成到一个紧凑的空间特征中，实现跨模态的空间建模。时序紧凑模块通过构建精细的目标分布热图来紧凑地表示时序特征。&lt;h4&gt;主要发现&lt;/h4&gt;CSTrack在主流RGB-X基准测试上取得了新的SOTA（最先进技术）结果。&lt;h4&gt;结论&lt;/h4&gt;CSTrack通过紧凑时空建模方法有效提高了跟踪性能，并在实验中验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;有效地建模和利用RGB和其他模态（例如深度、热和事件数据，记为X）的时空特征是RGB-X跟踪器设计的核心。现有方法通常采用两个并行分支来分别处理RGB和X输入流，这要求模型同时处理两个分散的特征空间，从而增加了模型结构和计算过程的复杂性。更重要的是，在每个分散空间内的跨模态空间建模会带来大量的计算开销，限制了跨模态空间建模和时序建模的资源。为了解决这个问题，我们提出了一种新的跟踪器CSTrack，它专注于建模紧凑时空特征以实现简单而有效的跟踪。具体来说，我们首先引入了一个创新的空间紧凑模块，该模块将RGB-X双输入流集成到一个紧凑的空间特征中，从而实现跨模态的空间建模。此外，我们还设计了一个高效的时序紧凑模块，通过构建精细的目标分布热图来紧凑地表示时序特征。大量的实验验证了我们的紧凑时空建模方法的有效性，CSTrack在主流RGB-X基准测试上实现了新的SOTA结果。代码和模型将在以下网址发布：https://github.com/XiaokunFeng/CSTrack。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effectively modeling and utilizing spatiotemporal features from RGB and othermodalities (\eg, depth, thermal, and event data, denoted as X) is the core ofRGB-X tracker design. Existing methods often employ two parallel branches toseparately process the RGB and X input streams, requiring the model tosimultaneously handle two dispersed feature spaces, which complicates both themodel structure and computation process. More critically, intra-modalityspatial modeling within each dispersed space incurs substantial computationaloverhead, limiting resources for inter-modality spatial modeling and temporalmodeling. To address this, we propose a novel tracker, CSTrack, which focuseson modeling Compact Spatiotemporal features to achieve simple yet effectivetracking. Specifically, we first introduce an innovative Spatial Compact Modulethat integrates the RGB-X dual input streams into a compact spatial feature,enabling thorough intra- and inter-modality spatial modeling. Additionally, wedesign an efficient Temporal Compact Module that compactly represents temporalfeatures by constructing the refined target distribution heatmap. Extensiveexperiments validate the effectiveness of our compact spatiotemporal modelingmethod, with CSTrack achieving new SOTA results on mainstream RGB-X benchmarks.The code and models will be released at:https://github.com/XiaokunFeng/CSTrack.</description>
      <author>example@mail.com (X. Feng, D. Zhang, S. Hu, X. Li, M. Wu, J. Zhang, X. Chen, K. Huang)</author>
      <guid isPermaLink="false">2505.19434v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>A Smart Healthcare System for Monkeypox Skin Lesion Detection and Tracking</title>
      <link>http://arxiv.org/abs/2505.19023v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究开发了一个名为ITMAINN的智能AI医疗系统，用于从皮肤病变图像中检测猴痘，旨在支持公共卫生应对措施。&lt;h4&gt;背景&lt;/h4&gt;猴痘是一种以皮肤病变为特征的病毒性疾病，最近全球爆发凸显了对可扩展、易于获取和准确的诊断解决方案的迫切需求。&lt;h4&gt;目的&lt;/h4&gt;开发ITMAINN系统，以支持公共卫生管理，通过皮肤病变图像检测猴痘。&lt;h4&gt;方法&lt;/h4&gt;研究团队训练和评估了多个预训练模型，使用迁移学习在公开的皮肤病变数据集上识别最有效的模型。系统包括三个主要组件：预训练模型的选择、一个跨平台智能手机应用程序和一个实时监控仪表板。&lt;h4&gt;主要发现&lt;/h4&gt;在二分类任务中，Vision Transformer、MobileViT、Transformer-in-Transformer和VGG16模型达到了97.8%的准确率和F1分数。在多分类任务中，ResNetViT和ViT Hybrid模型达到了92%的准确率和92.24%及92.19%的F1分数。MobileViT模型因其性能最佳且轻量级而被部署在移动应用程序中。&lt;h4&gt;结论&lt;/h4&gt;ITMAINN系统对于在智能城市中发展响应性医疗基础设施至关重要，是公共卫生管理革命的一部分。&lt;h4&gt;翻译&lt;/h4&gt;Monkeypox is a viral disease characterized by distinctive skin lesions and has been reported in many countries. The recent global outbreak has emphasized the urgent need for scalable, accessible, and accurate diagnostic solutions to support public health responses. In this study, we developed ITMAINN, an intelligent, AI-driven healthcaresystem specifically designed to detect Monkeypox from skin lesion images using advanced deep learning techniques. Our system consists of three maincomponents. First, we trained and evaluated several pretrained models using transfer learning on publicly available skin lesion datasets to identify the most effective models. For binary classification (Monkeypox vs. non-Monkeypox), the Vision Transformer, MobileViT, Transformer-in-Transformer, and VGG16 achieved the highest performance, each with an accuracy and F1-score of 97.8%. For multiclass classification, which contains images of patients with Monkeypox and five other classes (chickenpox, measles, hand-foot-mouth disease, cowpox, and healthy), ResNetViT and ViT Hybrid models achieved 92% accuracy, with F1scores of 92.24% and 92.19%, respectively. The best-performing and most lightweight model, MobileViT, was deployed within the mobile application. The second component is a cross-platform smartphone application that enables users to detect Monkeypox through image analysis, track symptoms, and receive recommendations for nearby healthcare centers based on their location. The third component is a real-time monitoring dashboard designed for health authorities to support them in tracking cases, analyzing symptom trends, guiding public health interventions, and taking proactive measures. This system is fundamental in developing responsive healthcare infrastructure within smart cities. Our solution, ITMAINN, is part of revolutionizing public health management.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monkeypox is a viral disease characterized by distinctive skin lesions andhas been reported in many countries. The recent global outbreak has emphasizedthe urgent need for scalable, accessible, and accurate diagnostic solutions tosupport public health responses.  In this study, we developed ITMAINN, an intelligent, AI-driven healthcaresystem specifically designed to detect Monkeypox from skin lesion images usingadvanced deep learning techniques. Our system consists of three maincomponents. First, we trained and evaluated several pretrained models usingtransfer learning on publicly available skin lesion datasets to identify themost effective models. For binary classification (Monkeypox vs. non-Monkeypox),the Vision Transformer, MobileViT, Transformer-in-Transformer, and VGG16achieved the highest performance, each with an accuracy and F1-score of 97.8%.For multiclass classification, which contains images of patients with Monkeypoxand five other classes (chickenpox, measles, hand-foot-mouth disease, cowpox,and healthy), ResNetViT and ViT Hybrid models achieved 92% accuracy, with F1scores of 92.24% and 92.19%, respectively. The best-performing and mostlightweight model, MobileViT, was deployed within the mobile application. Thesecond component is a cross-platform smartphone application that enables usersto detect Monkeypox through image analysis, track symptoms, and receiverecommendations for nearby healthcare centers based on their location. Thethird component is a real-time monitoring dashboard designed for healthauthorities to support them in tracking cases, analyzing symptom trends,guiding public health interventions, and taking proactive measures.  This system is fundamental in developing responsive healthcare infrastructurewithin smart cities. Our solution, ITMAINN, is part of revolutionizing publichealth management.</description>
      <author>example@mail.com (Huda Alghoraibi, Nuha Alqurashi, Sarah Alotaibi, Renad Alkhudaydi, Bdoor Aldajani, Lubna Alqurashi, Jood Batweel, Maha A. Thafar)</author>
      <guid isPermaLink="false">2505.19023v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Chi-Square Wavelet Graph Neural Networks for Heterogeneous Graph Anomaly Detection</title>
      <link>http://arxiv.org/abs/2505.18934v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ChiGAD是一种基于新提出的Chi-Square滤波器的谱GNN框架，用于解决异构网络中的图异常检测问题。&lt;h4&gt;背景&lt;/h4&gt;异构网络中的图异常检测（GAD）由于节点和边的不均匀性而面临独特的挑战。现有的GNN方法主要关注同构图异常检测，未能解决三个关键问题：捕获不同元路径上的异常信号和丰富语义；在HIN维度对齐中保留高频内容；以及从类别不平衡的困难异常样本中有效学习。&lt;h4&gt;目的&lt;/h4&gt;提出ChiGAD以克服上述挑战，并实现更有效的异构网络异常检测。&lt;h4&gt;方法&lt;/h4&gt;ChiGAD包括：1）多图Chi-Square滤波器，通过为每个元路径图应用专门的Chi-Square滤波器来捕获异常信息；2）交互式元图卷积，在对齐特征的同时保留高频信息，并通过统一的Chi-Square滤波器整合异构信息；3）贡献信息交叉熵损失，优先处理困难异常以解决类别不平衡问题。&lt;h4&gt;主要发现&lt;/h4&gt;在公共和工业数据集上的大量实验表明，ChiGAD在多个指标上优于最先进的模型。此外，其同构图变体ChiGNN在七个GAD数据集上表现出色，验证了Chi-Square滤波器的有效性。&lt;h4&gt;结论&lt;/h4&gt;ChiGAD是一种有效的异构网络图异常检测方法，其性能优于现有模型，并通过实验验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Anomaly Detection (GAD) in heterogeneous networks presents uniquechallenges due to node and edge heterogeneity. Existing Graph Neural Network(GNN) methods primarily focus on homogeneous GAD and thus fail to address threekey issues: (C1) Capturing abnormal signal and rich semantics across diversemeta-paths; (C2) Retaining high-frequency content in HIN dimension alignment;and (C3) Learning effectively from difficult anomaly samples with classimbalance. To overcome these, we propose ChiGAD, a spectral GNN framework basedon a novel Chi-Square filter, inspired by the wavelet effectiveness in diversedomains. Specifically, ChiGAD consists of: (1) Multi-Graph Chi-Square Filter,which captures anomalous information via applying dedicated Chi-Square filtersto each meta-path graph; (2) Interactive Meta-Graph Convolution, which alignsfeatures while preserving high-frequency information and incorporatesheterogeneous messages by a unified Chi-Square Filter; and (3)Contribution-Informed Cross-Entropy Loss, which prioritizes difficult anomaliesto address class imbalance. Extensive experiments on public and industrialdatasets show that ChiGAD outperforms state-of-the-art models on multiplemetrics. Additionally, its homogeneous variant, ChiGNN, excels on seven GADdatasets, validating the effectiveness of Chi-Square filters. Our code isavailable at https://github.com/HsipingLi/ChiGAD.</description>
      <author>example@mail.com (Xiping Li, Xiangyu Dong, Xingyi Zhang, Kun Xie, Yuanhao Feng, Bo Wang, Guilin Li, Wuxiong Zeng, Xiujun Shu, Sibo Wang)</author>
      <guid isPermaLink="false">2505.18934v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>LogiCoL: Logically-Informed Contrastive Learning for Set-based Dense Retrieval</title>
      <link>http://arxiv.org/abs/2505.19588v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LogiCoL的逻辑信息对比学习目标，用于解决密集检索器在处理包含逻辑连接词的查询时的问题，通过在实体检索任务中提高了检索性能和逻辑一致性。&lt;h4&gt;背景&lt;/h4&gt;尽管双编码器和双编码器密集检索器取得了显著进展，但它们在处理包含逻辑连接词的查询时往往表现不佳，这在下游应用中是一个被忽视但重要的用例。&lt;h4&gt;目的&lt;/h4&gt;为了解决密集检索器在处理逻辑连接词查询时的挑战，提出LogiCoL，以改善检索结果在逻辑上的准确性。&lt;h4&gt;方法&lt;/h4&gt;LogiCoL基于批内监督对比学习，通过在目标函数中使用t-norm表达的两套软约束，来学习使检索器尊重查询结果之间的子集和互斥集关系。&lt;h4&gt;主要发现&lt;/h4&gt;使用LogiCoL训练的模型在实体检索任务中，无论是在检索性能还是结果逻辑一致性方面都取得了改进。&lt;h4&gt;结论&lt;/h4&gt;LogiCoL对于提高密集检索器处理逻辑连接词查询的能力是有效的，并对为何这类查询对密集检索器具有挑战性以及LogiCoL为何如此有效提供了详细分析和见解。&lt;h4&gt;翻译&lt;/h4&gt;尽管在双编码器和双编码器密集检索器方面取得了显著进展，但它们在处理包含逻辑连接词的查询时往往表现不佳，这在下游应用中是一个被忽视但重要的用例。当前密集检索器在处理此类查询时存在困难，以至于检索到的结果不尊重查询中隐含的逻辑约束。为了解决这一挑战，我们引入了LogiCoL，一种为密集检索器设计的逻辑信息对比学习目标。LogiCoL建立在批内监督对比学习的基础上，并通过在目标函数中使用t-norm表达的两套软约束，学习使检索器尊重查询结果之间的子集和互斥集关系。我们在实体检索任务上评估了LogiCoL的有效性，其中模型预期检索一组满足查询中隐含逻辑约束的维基百科实体。我们发现，使用LogiCoL训练的模型在检索性能和结果逻辑一致性方面都取得了改进。我们提供了详细的分析和见解，以揭示为什么包含逻辑连接词的查询对密集检索器具有挑战性，以及为什么LogiCoL最为有效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While significant progress has been made with dual- and bi-encoder denseretrievers, they often struggle on queries with logical connectives, a use casethat is often overlooked yet important in downstream applications. Currentdense retrievers struggle with such queries, such that the retrieved results donot respect the logical constraints implied in the queries. To address thischallenge, we introduce LogiCoL, a logically-informed contrastive learningobjective for dense retrievers. LogiCoL builds upon in-batch supervisedcontrastive learning, and learns dense retrievers to respect the subset andmutually-exclusive set relation between query results via two sets of softconstraints expressed via t-norm in the learning objective. We evaluate theeffectiveness of LogiCoL on the task of entity retrieval, where the model isexpected to retrieve a set of entities in Wikipedia that satisfy the implicitlogical constraints in the query. We show that models trained with LogiCoLyield improvement both in terms of retrieval performance and logicalconsistency in the results. We provide detailed analysis and insights touncover why queries with logical connectives are challenging for denseretrievers and why LogiCoL is most effective.</description>
      <author>example@mail.com (Yanzhen Shen, Sihao Chen, Xueqiang Xu, Yunyi Zhang, Chaitanya Malaviya, Dan Roth)</author>
      <guid isPermaLink="false">2505.19588v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>SETransformer: A Hybrid Attention-Based Architecture for Robust Human Activity Recognition</title>
      <link>http://arxiv.org/abs/2505.19369v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SETransformer的混合深度神经网络架构，用于通过可穿戴传感器数据进行人类活动识别（HAR），在移动计算、医疗保健和人与计算机交互领域具有重要作用。&lt;h4&gt;背景&lt;/h4&gt;尽管传统的深度学习模型如CNN和RNN在HAR任务中取得了成功，但它们通常难以捕捉多个传感器通道之间的长距离时间依赖性和上下文相关性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出了SETransformer，该模型结合了基于Transformer的时间建模、通道级别的squeeze-and-excitation（SE）注意力和可学习的时序注意力池化机制。&lt;h4&gt;方法&lt;/h4&gt;SETransformer以原始三轴加速度计数据为输入，利用全局自注意力机制捕捉在较长时间窗口内的活动特定的运动动态，并自适应地强调信息丰富的传感器通道和关键时间步骤。&lt;h4&gt;主要发现&lt;/h4&gt;在WISDM数据集上评估SETransformer，结果表明其显著优于包括LSTM、GRU、BiLSTM和CNN在内的传统模型。该模型达到了84.68%的验证准确率和84.64%的宏观F1分数，显著超越了所有基线架构。&lt;h4&gt;结论&lt;/h4&gt;SETransformer是一种具有竞争力的可解释解决方案，适用于现实世界的HAR任务，具有在移动和泛在感知应用中部署的强大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：使用可穿戴传感器数据进行的人类活动识别（HAR）已成为移动计算、医疗保健和人与计算机交互中的一个中心任务。尽管传统的深度学习模型如CNN和RNN取得了成功，但它们通常难以捕捉多个传感器通道之间的长距离时间依赖性和上下文相关性。为了解决这些局限性，我们提出了SETransformer，这是一种结合基于Transformer的时间建模、通道级别的squeeze-and-excitation（SE）注意力和可学习的时序注意力池化机制的混合深度神经网络架构。该模型以原始三轴加速度计数据为输入，利用全局自注意力机制捕捉在较长时间窗口内的活动特定的运动动态，并自适应地强调信息丰富的传感器通道和关键时间步骤。我们在WISDM数据集上评估了SETransformer，结果表明其显著优于包括LSTM、GRU、BiLSTM和CNN在内的传统模型。该模型达到了84.68%的验证准确率和84.64%的宏观F1分数，显著超越了所有基线架构。我们的结果表明，SETransformer是一种具有竞争力的可解释解决方案，适用于现实世界的HAR任务，具有在移动和泛在感知应用中部署的强大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human Activity Recognition (HAR) using wearable sensor data has become acentral task in mobile computing, healthcare, and human-computer interaction.Despite the success of traditional deep learning models such as CNNs and RNNs,they often struggle to capture long-range temporal dependencies and contextualrelevance across multiple sensor channels. To address these limitations, wepropose SETransformer, a hybrid deep neural architecture that combinesTransformer-based temporal modeling with channel-wise squeeze-and-excitation(SE) attention and a learnable temporal attention pooling mechanism. The modeltakes raw triaxial accelerometer data as input and leverages globalself-attention to capture activity-specific motion dynamics over extended timewindows, while adaptively emphasizing informative sensor channels and criticaltime steps.  We evaluate SETransformer on the WISDM dataset and demonstrate that itsignificantly outperforms conventional models including LSTM, GRU, BiLSTM, andCNN baselines. The proposed model achieves a validation accuracy of 84.68\% anda macro F1-score of 84.64\%, surpassing all baseline architectures by a notablemargin. Our results show that SETransformer is a competitive and interpretablesolution for real-world HAR tasks, with strong potential for deployment inmobile and ubiquitous sensing applications.</description>
      <author>example@mail.com (Yunbo Liu, Xukui Qin, Yifan Gao, Xiang Li, Chengwei Feng)</author>
      <guid isPermaLink="false">2505.19369v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised and Generalizable Tokenization for CLIP-Based 3D Understanding</title>
      <link>http://arxiv.org/abs/2505.18819v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, tokenizer&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通用的3D分词器，用于实现尺度不变的表达学习，并基于冻结的CLIP骨干网络。实验表明，结合基于superpoint的分组和坐标尺度归一化，在广泛的实验分析中，其性能优于传统方法。&lt;h4&gt;背景&lt;/h4&gt;现有的3D视觉语言模型如CLIP在扩展3D分词器后，为3D场景理解提供了有希望的基础。然而，标准方法如k-近邻或基于半径的分词在跨域泛化方面存在困难，因为它们对数据集特定的空间尺度敏感。&lt;h4&gt;目的&lt;/h4&gt;设计一个通用的3D分词器，实现尺度不变的表达学习，以提高3D场景理解的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的分词器S4Token，该分词器通过无标注训练，结合掩码点建模和基于聚类的目标，以及跨模态蒸馏，使3D分词与2D多视图图像特征对齐。此外，还提出了一种超点级别的特征传播模块，用于从稀疏分词中恢复点级别的细节。&lt;h4&gt;主要发现&lt;/h4&gt;结合superpoint分组与坐标尺度归一化的方法在性能上优于传统方法，并且S4Token能够产生不受场景尺度影响的语义信息分词。&lt;h4&gt;结论&lt;/h4&gt;提出的通用3D分词器S4Token在3D场景理解任务中表现出色，并有助于解决跨域泛化问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要：像CLIP这样的视觉语言模型在扩展3D分词器后，可以为3D场景理解提供有前景的基础，如果与3D分词器结合。然而，由于对数据集特定的空间尺度敏感，标准的如k近邻或基于半径的分词方法在跨领域泛化方面存在困难。我们提出了一种通用的3D分词器，旨在实现具有冻结CLIP骨干的尺度不变表示学习。我们表明，通过广泛的实验分析，结合基于superpoint的分组和坐标尺度归一化可以持续地优于传统方法。具体来说，我们引入了S4Token，这是一个分词管道，可以产生无论场景尺度如何的语义信息分词。我们的分词器在无注释的情况下使用掩码点建模和基于聚类的目标以及跨模态蒸馏进行训练，以使3D分词与2D多视图图像特征对齐。对于密集预测任务，我们提出了一个超点级特征传播模块，以从稀疏分词中恢复点级细节。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models like CLIP can offer a promising foundation for 3Dscene understanding when extended with 3D tokenizers. However, standardapproaches, such as k-nearest neighbor or radius-based tokenization, strugglewith cross-domain generalization due to sensitivity to dataset-specific spatialscales. We present a universal 3D tokenizer designed for scale-invariantrepresentation learning with a frozen CLIP backbone. We show that combiningsuperpoint-based grouping with coordinate scale normalization consistentlyoutperforms conventional methods through extensive experimental analysis.Specifically, we introduce S4Token, a tokenization pipeline that producessemantically-informed tokens regardless of scene scale. Our tokenizer istrained without annotations using masked point modeling and clustering-basedobjectives, along with cross-modal distillation to align 3D tokens with 2Dmulti-view image features. For dense prediction tasks, we propose asuperpoint-level feature propagation module to recover point-level detail fromsparse tokens.</description>
      <author>example@mail.com (Guofeng Mei, Bin Ren, Juan Liu, Luigi Riz, Xiaoshui Huang, Xu Zheng, Yongshun Gong, Ming-Hsuan Yang, Nicu Sebe, Fabio Poiesi)</author>
      <guid isPermaLink="false">2505.18819v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Pessimism Principle Can Be Effective: Towards a Framework for Zero-Shot Transfer Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2505.18447v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于悲观原则的新型框架，用于解决迁移强化学习中性能保证不足和负迁移风险的问题。&lt;h4&gt;背景&lt;/h4&gt;迁移强化学习旨在利用相关源域的大量数据，在目标环境中推导出近似最优策略，但面临着性能保证缺失和负迁移的风险。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的框架，以解决迁移强化学习中的性能保证不足和负迁移风险。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于悲观原则的框架，构建和优化目标域性能的保守估计，并通过构建两种类型的保守估计来严格表征其有效性，并开发具有收敛保证的高效分布式算法。&lt;h4&gt;主要发现&lt;/h4&gt;该框架提供了目标性能的优化下界，确保了安全和可靠的决策，并表现出源域质量的单调改进，从而避免了负迁移。&lt;h4&gt;结论&lt;/h4&gt;该框架为迁移强化学习中的迁移学习提供了理论上有根据且实践上稳健的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer reinforcement learning aims to derive a near-optimal policy for atarget environment with limited data by leveraging abundant data from relatedsource domains. However, it faces two key challenges: the lack of performanceguarantees for the transferred policy, which can lead to undesired actions, andthe risk of negative transfer when multiple source domains are involved. Wepropose a novel framework based on the pessimism principle, which constructsand optimizes a conservative estimation of the target domain's performance. Ourframework effectively addresses the two challenges by providing an optimizedlower bound on target performance, ensuring safe and reliable decisions, and byexhibiting monotonic improvement with respect to the quality of the sourcedomains, thereby avoiding negative transfer. We construct two types ofconservative estimations, rigorously characterize their effectiveness, anddevelop efficient distributed algorithms with convergence guarantees. Ourframework provides a theoretically sound and practically robust solution fortransfer learning in reinforcement learning.</description>
      <author>example@mail.com (Chi Zhang, Ziying Jia, George K. Atia, Sihong He, Yue Wang)</author>
      <guid isPermaLink="false">2505.18447v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>SMART-PC: Skeletal Model Adaptation for Robust Test-Time Training in Point Clouds</title>
      <link>http://arxiv.org/abs/2505.19546v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SMART-PC是一种基于骨骼的框架，用于解决3D点云分类中的分布偏移问题，通过利用3D点云的几何结构提高鲁棒性，并实现实时自适应，同时在基准数据集上取得了最先进的结果。&lt;h4&gt;背景&lt;/h4&gt;现有方法在适应过程中依赖计算昂贵的反向传播，限制了其在实际场景中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出SMART-PC框架，旨在提高3D点云分类对分布偏移的适应能力，并实现实时自适应。&lt;h4&gt;方法&lt;/h4&gt;SMART-PC通过预测骨骼表示，使模型能够提取对噪声敏感度低的稳健几何特征，并通过不使用反向传播和仅更新BatchNorm统计信息来实现实时适应。&lt;h4&gt;主要发现&lt;/h4&gt;SMART-PC在ModelNet40-C、ShapeNet-C和ScanObjectNN-C等基准数据集上实现了最先进的性能，在准确性和计算效率方面优于现有方法如MATE。&lt;h4&gt;结论&lt;/h4&gt;SMART-PC是一种高效且轻量级的框架，能够实现高帧率的同时保持优异的分类性能。&lt;h4&gt;翻译&lt;/h4&gt;Test-Time Training (TTT) has emerged as a promising solution to address distribution shifts in 3D point cloud classification. However, existing methods often rely on computationally expensive backpropagation during adaptation, limiting their applicability in real-world, time-sensitive scenarios. In this paper, we introduce SMART-PC, a skeleton-based framework that enhances resilience to corruptions by leveraging the geometric structure of 3D point clouds. During pre-training, our method predicts skeletal representations, enabling the model to extract robust and meaningful geometric features that are less sensitive to corruptions, thereby improving adaptability to test-time distribution shifts. Unlike prior approaches, SMART-PC achieves real-time adaptation by eliminating backpropagation and updating only BatchNorm statistics, resulting in a lightweight and efficient framework capable of achieving high frame-per-second rates while maintaining superior classification performance. Extensive experiments on benchmark datasets, including ModelNet40-C, ShapeNet-C, and ScanObjectNN-C, demonstrate that SMART-PC achieves state-of-the-art results, outperforming existing methods such as MATE in terms of both accuracy and computational efficiency. The implementation is available at: https://github.com/AliBahri94/SMART-PC.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Test-Time Training (TTT) has emerged as a promising solution to addressdistribution shifts in 3D point cloud classification. However, existing methodsoften rely on computationally expensive backpropagation during adaptation,limiting their applicability in real-world, time-sensitive scenarios. In thispaper, we introduce SMART-PC, a skeleton-based framework that enhancesresilience to corruptions by leveraging the geometric structure of 3D pointclouds. During pre-training, our method predicts skeletal representations,enabling the model to extract robust and meaningful geometric features that areless sensitive to corruptions, thereby improving adaptability to test-timedistribution shifts. Unlike prior approaches, SMART-PC achieves real-timeadaptation by eliminating backpropagation and updating only BatchNormstatistics, resulting in a lightweight and efficient framework capable ofachieving high frame-per-second rates while maintaining superior classificationperformance. Extensive experiments on benchmark datasets, includingModelNet40-C, ShapeNet-C, and ScanObjectNN-C, demonstrate that SMART-PCachieves state-of-the-art results, outperforming existing methods such as MATEin terms of both accuracy and computational efficiency. The implementation isavailable at: https://github.com/AliBahri94/SMART-PC.</description>
      <author>example@mail.com (Ali Bahri, Moslem Yazdanpanah, Sahar Dastani, Mehrdad Noori, Gustavo Adolfo Vargas Hakim, David Osowiechi, Farzad Beizaee, Ismail Ben Ayed, Christian Desrosiers)</author>
      <guid isPermaLink="false">2505.19546v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Graph-Based Operator Learning from Limited Data on Irregular Domains</title>
      <link>http://arxiv.org/abs/2505.18923v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图的注意力增强操作学习框架（GOLA），用于解决传统操作学习在复杂或不规则域中的适用性问题。&lt;h4&gt;背景&lt;/h4&gt;操作学习旨在近似从输入函数到输出解的映射，尤其是在偏微分方程（PDEs）的背景下。尽管DeepONet和Fourier Neural Operator（FNO）等最近的发展显示了强大的性能，但它们通常依赖于规则的网格离散化，限制了它们在复杂或不规则域中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出GOLA框架，通过构建从不规则采样空间点生成的图，并利用注意力增强的图神经网络（GNNs）来建模具有全局信息的空间依赖关系，以解决上述限制。&lt;h4&gt;方法&lt;/h4&gt;引入了一个基于傅里叶的编码器，使用可学习的复系数将输入函数投影到频域，即使在稀疏或非均匀样本的情况下也允许灵活嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;在包括达西流、对流、拟声子和非线性扩散等2D PDEs的多种情况下，该方法在变化的采样密度下进行了评估，并在数据稀缺的情况下，始终优于基线方法，显示了在不规则域上的强大泛化能力和效率。&lt;h4&gt;结论&lt;/h4&gt;GOLA框架在解决不规则域中的操作学习问题上表现出色，特别是在数据稀缺的环境中，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Operator learning seeks to approximate mappings from input functions tooutput solutions, particularly in the context of partial differential equations(PDEs). While recent advances such as DeepONet and Fourier Neural Operator(FNO) have demonstrated strong performance, they often rely on regular griddiscretizations, limiting their applicability to complex or irregular domains.In this work, we propose a Graph-based Operator Learning with Attention (GOLA)framework that addresses this limitation by constructing graphs fromirregularly sampled spatial points and leveraging attention-enhanced GraphNeural Netwoks (GNNs) to model spatial dependencies with global information. Toimprove the expressive capacity, we introduce a Fourier-based encoder thatprojects input functions into a frequency space using learnable complexcoefficients, allowing for flexible embeddings even with sparse or nonuniformsamples. We evaluated our approach across a range of 2D PDEs, including DarcyFlow, Advection, Eikonal, and Nonlinear Diffusion, under varying samplingdensities. Our method consistently outperforms baselines, particularly indata-scarce regimes, demonstrating strong generalization and efficiency onirregular domains.</description>
      <author>example@mail.com (Yile Li, Shandian Zhe)</author>
      <guid isPermaLink="false">2505.18923v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>AmpleHate: Amplifying the Attention for Versatile Implicit Hate Detection</title>
      <link>http://arxiv.org/abs/2505.19528v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 4 figures, Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AmpleHate的新方法，用于检测隐含仇恨言论，该方法通过模拟人类推理过程，在隐含仇恨检测方面取得了显著成果。&lt;h4&gt;背景&lt;/h4&gt;隐含仇恨言论检测由于其微妙性和对上下文解释的依赖性而具有挑战性，而现有方法主要依赖对比学习，这在区分仇恨和非仇恨句子方面已被证明是有效的。&lt;h4&gt;目的&lt;/h4&gt;提出AmpleHate方法，以模拟人类识别隐含仇恨言论的推理过程。&lt;h4&gt;方法&lt;/h4&gt;AmpleHate使用预训练的命名实体识别模型来识别显式目标，并通过[CLS]标记捕捉隐含目标信息。它计算显式目标、隐含目标和句子上下文之间的注意力关系，并将这些关系向量直接注入最终的句子表示中。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AmpleHate在隐含仇恨检测方面达到了最先进的性能，平均比对比学习基线提高了82.14%，并且收敛速度更快。定性分析进一步表明，AmpleHate产生的注意力模式与人类判断紧密一致，强调了其可解释性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;AmpleHate方法在隐含仇恨检测方面表现出色，为该领域的研究提供了新的思路和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Implicit hate speech detection is challenging due to its subtlety andreliance on contextual interpretation rather than explicit offensive words.Current approaches rely on contrastive learning, which are shown to beeffective on distinguishing hate and non-hate sentences. Humans, however,detect implicit hate speech by first identifying specific targets within thetext and subsequently interpreting how these target relate to their surroundingcontext. Motivated by this reasoning process, we propose AmpleHate, a novelapproach designed to mirror human inference for implicit hate detection.AmpleHate identifies explicit target using a pretrained Named EntityRecognition model and capture implicit target information via [CLS] tokens. Itcomputes attention-based relationships between explicit, implicit targets andsentence context and then, directly injects these relational vectors into thefinal sentence representation. This amplifies the critical signals oftarget-context relations for determining implicit hate. Experiments demonstratethat AmpleHate achieves state-of-the-art performance, outperforming contrastivelearning baselines by an average of 82.14% and achieve faster convergence.Qualitative analyses further reveal that attention patterns produced byAmpleHate closely align with human judgement, underscoring its interpretabilityand robustness.</description>
      <author>example@mail.com (Yejin Lee, Joonghyuk Hahn, Hyeseon Ahn, Yo-Sub Han)</author>
      <guid isPermaLink="false">2505.19528v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>MSD-LLM: Predicting Ship Detention in Port State Control Inspections with Large Language Model</title>
      <link>http://arxiv.org/abs/2505.19568v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于大型语言模型的船舶滞留预测方法，旨在提高船舶滞留预测的准确性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;海运是全球贸易的支柱，船舶检查对于确保海上安全和环境保护至关重要。港口国控制（PSC）通过实施安全法规来确保合规性，船舶滞留是最严重的后果，影响船舶安排和公司声誉。&lt;h4&gt;目的&lt;/h4&gt;针对传统机器学习方法在船舶滞留预测中的局限性以及基于自编码器的深度学习方法在处理不平衡数据时的挑战，提出了一种新的船舶滞留预测方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Maritime Ship Detention with Large Language Models (MSD-LLM)的方法，该方法集成了基于双稳健子空间恢复（DSR）层的自编码器和渐进式学习流程，以处理不平衡数据并提取有意义的PSC表示。然后，使用大型语言模型对特征进行分组和排序，以识别可能的滞留案例，并实现动态阈值，以实现灵活的滞留预测。&lt;h4&gt;主要发现&lt;/h4&gt;在亚太地区31,707条PSC检查记录上的广泛评估表明，MSD-LLM在新加坡港口的曲线下面积（AUC）上优于现有方法超过12%。此外，它对现实世界挑战具有鲁棒性，使其能够适应不同的海上风险评估场景。&lt;h4&gt;结论&lt;/h4&gt;MSD-LLM是一种有效的船舶滞留预测方法，可以提高预测的准确性和适应性，有助于提高海上安全和环境保护水平。&lt;h4&gt;翻译&lt;/h4&gt;摘要：海运是全球贸易的支柱，船舶检查对于确保海上安全和环境保护至关重要。港口国控制（PSC）通过实施安全法规来确保合规性，船舶滞留是最严重的后果，影响船舶安排和公司声誉。传统的船舶滞留预测机器学习方法受限于表示学习能力，因此准确性较低。同时，基于自编码器的深度学习方法由于学习历史PSC滞留记录数据严重不平衡而面临挑战。为了解决这些限制，我们提出了基于大型语言模型的船舶滞留（MSD-LLM），该方法集成了基于双稳健子空间恢复（DSR）层的自编码器和一个渐进式学习流程来处理不平衡数据并提取有意义的PSC表示。然后，使用大型语言模型对特征进行分组和排序，以识别可能的滞留案例，并实现动态阈值，以实现灵活的滞留预测。在亚太地区31,707条PSC检查记录上的广泛评估表明，MSD-LLM在新加坡港口的曲线下面积（AUC）上优于现有方法超过12%。此外，它对现实世界挑战具有鲁棒性，使其能够适应不同的海上风险评估场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Maritime transportation is the backbone of global trade, making shipinspection essential for ensuring maritime safety and environmental protection.Port State Control (PSC), conducted by national ports, enforces compliance withsafety regulations, with ship detention being the most severe consequence,impacting both ship schedules and company reputations. Traditional machinelearning methods for ship detention prediction are limited by the capacity ofrepresentation learning and thus suffer from low accuracy. Meanwhile,autoencoder-based deep learning approaches face challenges due to the severedata imbalance in learning historical PSC detention records. To address theselimitations, we propose Maritime Ship Detention with Large Language Models(MSD-LLM), integrating a dual robust subspace recovery (DSR) layer-basedautoencoder with a progressive learning pipeline to handle imbalanced data andextract meaningful PSC representations. Then, a large language model groups andranks features to identify likely detention cases, enabling dynamicthresholding for flexible detention predictions. Extensive evaluations on31,707 PSC inspection records from the Asia-Pacific region show that MSD-LLMoutperforms state-of-the-art methods more than 12\% on Area Under the Curve(AUC) for Singapore ports. Additionally, it demonstrates robustness toreal-world challenges, making it adaptable to diverse maritime risk assessmentscenarios.</description>
      <author>example@mail.com (Jiongchao Jin, Xiuju Fu, Xiaowei Gao, Tao Cheng, Ran Yan)</author>
      <guid isPermaLink="false">2505.19568v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Video Self-Supervised Learning via Image Foundation Models</title>
      <link>http://arxiv.org/abs/2505.19218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AdViSe的视频自监督学习方法，旨在显著降低使用预训练图像基础模型（IFMs）训练视频表示模型的开销。&lt;h4&gt;背景&lt;/h4&gt;过去十年，图像基础模型（IFMs）取得了前所未有的进展，但直接使用IFMs进行视频自监督表示学习的潜力被大量忽视。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种方法，以减少使用预训练IFMs进行视频自监督学习时的训练负担。&lt;h4&gt;方法&lt;/h4&gt;首先，将时间建模模块（ResNet3D）引入IFMs，构建视频表示模型。然后，采用视频自监督学习方法，即播放速率感知，来训练时间模块，同时冻结IFM组件。&lt;h4&gt;主要发现&lt;/h4&gt;在UCF101数据集上的实验表明，AdViSe的性能与最先进的方法相当，同时将训练时间减少了3.4倍，GPU内存使用量减少了8.2倍。&lt;h4&gt;结论&lt;/h4&gt;本研究为基于预训练IFM的低成本视频自监督学习提供了新的见解。&lt;h4&gt;翻译&lt;/h4&gt;在过去十年中，图像基础模型（IFMs）取得了前所未有的进步。然而，直接使用IFMs进行视频自监督表示学习的潜力在很大程度上被忽视了。在这项研究中，我们提出了一种名为AdViSe的先进视频自监督学习方法，旨在显著降低使用预训练IFMs训练视频表示模型的开销。具体来说，我们首先将时间建模模块（ResNet3D）引入IFMs，构建了一个视频表示模型。然后，我们采用了一种视频自监督学习方法，即播放速率感知，来训练时间模块，同时冻结IFM组件。在UCF101数据集上的实验表明，AdViSe的性能与最先进的方法相当，同时将训练时间减少了3.4倍，GPU内存使用量减少了8.2倍。这项研究为基于预训练IFM的低成本视频自监督学习提供了新的见解。代码可在https://github.com/JingwWu/advise-video-ssl上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.patrec.2025.03.015&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the past decade, image foundation models (IFMs) have achievedunprecedented progress. However, the potential of directly using IFMs for videoself-supervised representation learning has largely been overlooked. In thisstudy, we propose an advancing video self-supervised learning (AdViSe)approach, aimed at significantly reducing the training overhead of videorepresentation models using pre-trained IFMs. Specifically, we first introducetemporal modeling modules (ResNet3D) to IFMs, constructing a videorepresentation model. We then employ a video self-supervised learning approach,playback rate perception, to train temporal modules while freezing the IFMcomponents. Experiments on UCF101 demonstrate that AdViSe achieves performancecomparable to state-of-the-art methods while reducing training time by$3.4\times$ and GPU memory usage by $8.2\times$. This study offers freshinsights into low-cost video self-supervised learning based on pre-trainedIFMs. Code is available at https://github.com/JingwWu/advise-video-ssl.</description>
      <author>example@mail.com (Jingwei Wu, Zhewei Huang, Chang Liu)</author>
      <guid isPermaLink="false">2505.19218v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual Reasoning from Transit Maps</title>
      <link>http://arxiv.org/abs/2505.18675v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该摘要介绍了一种名为ReasonMap的基准，用于评估多模态大型语言模型（MLLMs）的精细视觉理解和空间推理能力。&lt;h4&gt;背景&lt;/h4&gt;MLLMs在视觉任务上取得了显著进展，但在涉及精细视觉理解的推理任务中能力不足。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一差距，研究人员开发了ReasonMap基准。&lt;h4&gt;方法&lt;/h4&gt;ReasonMap包含来自13个国家的30个城市的高分辨率交通图，以及涵盖两种问题类型和三个模板的1,008个问题-答案对。研究还设计了一个两级评估流程来正确评估答案的正确性和质量。&lt;h4&gt;主要发现&lt;/h4&gt;对15种流行的MLLMs的综合评估揭示了开放源代码模型中基础模型优于推理模型，而在闭源模型中观察到相反的趋势。此外，当视觉输入被遮蔽时，性能通常会下降，这表明MLLMs可以利用先验知识回答一些问题，但精细视觉推理任务仍然需要真正的视觉感知才能实现强性能。&lt;h4&gt;结论&lt;/h4&gt;ReasonMap基准为视觉推理提供了新的见解，有助于研究开源和闭源模型之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了多模态大型语言模型（MLLMs）在视觉任务上取得显著进展，但其在涉及精细视觉理解的推理任务中能力不足。为了填补这一差距，研究人员开发了ReasonMap基准，该基准包含来自13个国家的30个城市的高分辨率交通图和1,008个问题-答案对，涵盖两种问题类型和三个模板。评估发现，在开放源代码模型中，基础模型的表现优于推理模型，而在闭源模型中则相反。当视觉输入被遮蔽时，性能下降，表明MLLMs可以利用先验知识回答问题，但精细视觉推理任务仍需要真正的视觉感知。这项基准研究为视觉推理提供了新见解，有助于探究开源和闭源模型之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal large language models (MLLMs) have recently achieved significantprogress in visual tasks, including semantic scene understanding and text-imagealignment, with reasoning variants enhancing performance on complex tasksinvolving mathematics and logic. However, their capacity for reasoning tasksinvolving fine-grained visual understanding remains insufficiently evaluated.To address this gap, we introduce ReasonMap, a benchmark designed to assess thefine-grained visual understanding and spatial reasoning abilities of MLLMs.ReasonMap encompasses high-resolution transit maps from 30 cities across 13countries and includes 1,008 question-answer pairs spanning two question typesand three templates. Furthermore, we design a two-level evaluation pipelinethat properly assesses answer correctness and quality. Comprehensiveevaluations of 15 popular MLLMs, including both base and reasoning variants,reveal a counterintuitive pattern: among open-source models, base modelsoutperform reasoning ones, while the opposite trend is observed inclosed-source models. Additionally, performance generally degrades when visualinputs are masked, indicating that while MLLMs can leverage prior knowledge toanswer some questions, fine-grained visual reasoning tasks still requiregenuine visual perception for strong performance. Our benchmark study offersnew insights into visual reasoning and contributes to investigating the gapbetween open-source and closed-source models.</description>
      <author>example@mail.com (Sicheng Feng, Song Wang, Shuyi Ouyang, Lingdong Kong, Zikai Song, Jianke Zhu, Huan Wang, Xinchao Wang)</author>
      <guid isPermaLink="false">2505.18675v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>A Contrastive Learning Foundation Model Based on Perfectly Aligned Sample Pairs for Remote Sensing Images</title>
      <link>http://arxiv.org/abs/2505.19447v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PerA的自监督学习方法，用于预处理遥感图像，并通过在多个下游任务数据集上取得与现有最先进方法相当的性能来验证其优越性。&lt;h4&gt;背景&lt;/h4&gt;自监督学习（SSL）可以在没有昂贵标注数据的情况下预训练基础模型。对比学习（CL）方法在获得准确语义表示方面表现良好，但在遥感图像领域仍需特定适应。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自监督方法PerA，以生成通用的遥感特征，并通过语义完美对齐的样本对来提高特征质量。&lt;h4&gt;方法&lt;/h4&gt;PerA通过应用空间上不重叠的掩码到增强图像上，而不是随机裁剪，从采样的视图中获取特征。这种方法将来自不同视图的补丁分成语义对齐但外观不一致的不同部分。框架通过确保教师和学生之间的连续性以及预测可学习的掩码标记来提供高质量的特征。&lt;h4&gt;主要发现&lt;/h4&gt;与之前的对比方法相比，PerA方法具有更高的内存效率，并且由于其稀疏输入，可以训练更大的批次。此外，还收集了一个包含约500万张未标记遥感图像的预训练数据集。&lt;h4&gt;结论&lt;/h4&gt;PerA方法在多个下游任务数据集上取得了与现有最先进方法相当的性能，验证了其优越性，并有望为实际遥感解释工作做出贡献。&lt;h4&gt;翻译&lt;/h4&gt;Self-Supervised Learning (SSL) enables us to pre-train foundation models without costly labeled data. Among SSL methods, Contrastive Learning (CL) methods are better at obtaining accurate semantic representations in noise interference. However, due to the significant domain gap, while CL methods have achieved great success in many computer vision tasks, they still require specific adaptation for Remote Sensing (RS) images. To this end, we present a novel self-supervised method called PerA, which produces all-purpose RS features through semantically Perfectly Aligned sample pairs. Specifically, PerA obtains features from sampled views by applying spatially disjoint masks to augmented images rather than random cropping. With disjoint masks, we divide patches from different views into different parts that are semantically aligned but inconsistent in appearance. Our framework provides high-quality features by ensuring consistency between teacher and student and predicting learnable mask tokens. Compared to previous contrastive methods, our method demonstrates higher memory efficiency and can be trained with larger batches due to its sparse inputs. We also collect an unlabeled pre-training dataset, which contains about 5 million RS images. We conducted experiments on multiple downstream task datasets and achieved performance comparable to previous state-of-the-art methods with a limited model scale, which verified the superiority of our method. We hope this work will contribute to practical remote sensing interpretation works.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-Supervised Learning (SSL) enables us to pre-train foundation modelswithout costly labeled data. Among SSL methods, Contrastive Learning (CL)methods are better at obtaining accurate semantic representations in noiseinterference. However, due to the significant domain gap, while CL methods haveachieved great success in many computer vision tasks, they still requirespecific adaptation for Remote Sensing (RS) images. To this end, we present anovel self-supervised method called PerA, which produces all-purpose RSfeatures through semantically Perfectly Aligned sample pairs. Specifically,PerA obtains features from sampled views by applying spatially disjoint masksto augmented images rather than random cropping. With disjoint masks, we dividepatches from different views into different parts that are semantically alignedbut inconsistent in appearance. Our framework provides high-quality features byensuring consistency between teacher and student and predicting learnable masktokens. Compared to previous contrastive methods, our method demonstrateshigher memory efficiency and can be trained with larger batches due to itssparse inputs. We also collect an unlabeled pre-training dataset, whichcontains about 5 million RS images. We conducted experiments on multipledownstream task datasets and achieved performance comparable to previousstate-of-the-art methods with a limited model scale, which verified thesuperiority of our method. We hope this work will contribute to practicalremote sensing interpretation works.</description>
      <author>example@mail.com (Hengtong Shen, Haiyan Gu, Haitao Li, Yi Yang, Agen qiu)</author>
      <guid isPermaLink="false">2505.19447v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Improving Recommendation Fairness without Sensitive Attributes Using Multi-Persona LLMs</title>
      <link>http://arxiv.org/abs/2505.19473v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LLMFOSA的新框架，用于在不访问敏感属性的情况下提高推荐系统的公平性。&lt;h4&gt;背景&lt;/h4&gt;尽管推荐系统能够缓解信息过载，但公平性问题近年来引起了关注，可能导致某些用户群体受到不平等对待。&lt;h4&gt;目的&lt;/h4&gt;旨在提高推荐公平性，同时不依赖敏感属性。&lt;h4&gt;方法&lt;/h4&gt;LLMFOSA利用大型语言模型（LLMs）的推理能力，通过多个人格敏感信息推理模块和混淆感知敏感表示学习模块来推断和提炼敏感信息，并考虑了误标记混淆和代理之间的集体共识。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，LLMFOSA在提高公平性方面是有效的。&lt;h4&gt;结论&lt;/h4&gt;LLMFOSA为在不访问敏感属性的情况下提高推荐系统的公平性提供了一种新的有效方法。&lt;h4&gt;翻译&lt;/h4&gt;Despite the success of recommender systems in alleviating information overload, fairness issues have raised concerns in recent years, potentially leading to unequal treatment for certain user groups. While efforts have been made to improve recommendation fairness, they often assume that users'sensitive attributes are available during model training. However, collecting sensitive information can be difficult, especially on platforms that involve no personal information disclosure. Therefore, we aim to improve recommendation fairness without any access to sensitive attributes. However, this is a non-trivial task because uncovering latent sensitive patterns from complicated user behaviors without explicit sensitive attributes can be difficult. Consequently, suboptimal estimates of sensitive distributions can hinder the fairness training process. To address these challenges, leveraging the remarkable reasoning abilities of Large Language Models (LLMs), we propose a novel LLM-enhanced framework for Fair recommendation withOut SensitiveAttributes (LLMFOSA). A Multi-Persona Sensitive Information Inference module employs LLMs with distinct personas that mimic diverse human perceptions to infer and distill sensitive information. Furthermore, a Confusion-Aware Sensitive Representation Learning module incorporates inference results and rationales to develop robust sensitive representations, considering the mislabeling confusion and collective consensus among agents. The model is then optimized by a formulated mutual information objective. Extensive experiments on two public datasets validate the effectiveness of LLMFOSA in improving fairness.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the success of recommender systems in alleviating informationoverload, fairness issues have raised concerns in recent years, potentiallyleading to unequal treatment for certain user groups. While efforts have beenmade to improve recommendation fairness, they often assume that users'sensitive attributes are available during model training. However, collectingsensitive information can be difficult, especially on platforms that involve nopersonal information disclosure. Therefore, we aim to improve recommendationfairness without any access to sensitive attributes. However, this is anon-trivial task because uncovering latent sensitive patterns from complicateduser behaviors without explicit sensitive attributes can be difficult.Consequently, suboptimal estimates of sensitive distributions can hinder thefairness training process. To address these challenges, leveraging theremarkable reasoning abilities of Large Language Models (LLMs), we propose anovel LLM-enhanced framework for Fair recommendation withOut SensitiveAttributes (LLMFOSA). A Multi-Persona Sensitive Information Inference moduleemploys LLMs with distinct personas that mimic diverse human perceptions toinfer and distill sensitive information. Furthermore, a Confusion-AwareSensitive Representation Learning module incorporates inference results andrationales to develop robust sensitive representations, considering themislabeling confusion and collective consensus among agents. The model is thenoptimized by a formulated mutual information objective. Extensive experimentson two public datasets validate the effectiveness of LLMFOSA in improvingfairness.</description>
      <author>example@mail.com (Haoran Xin, Ying Sun, Chao Wang, Yanke Yu, Weijia Zhang, Hui Xiong)</author>
      <guid isPermaLink="false">2505.19473v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Sparse-to-Dense: A Free Lunch for Lossless Acceleration of Video Understanding in LLMs</title>
      <link>http://arxiv.org/abs/2505.19155v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Sparse-to-Dense（StD）的解码策略，旨在提高视频大型语言模型（Video-LLMs）的推理速度，同时保持模型性能。&lt;h4&gt;背景&lt;/h4&gt;由于Video-LLMs的自回归特性，随着输入序列长度的增加，推理延迟也会增加，这对于处理通常非常长的视频序列来说是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一种解码策略，以加快Video-LLMs的处理速度，同时不牺牲模型性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Sparse-to-Dense（StD）的解码策略，该策略包含两个模块：一个利用稀疏的top-K注意力，另一个使用密集的全注意力。这两个模块协同工作，以加速Video-LLM而不损失性能。&lt;h4&gt;主要发现&lt;/h4&gt;在解码过程中，Video-LLMs中大多数token的注意力得分是稀疏且集中的，只有某些token需要全面的全注意力。&lt;h4&gt;结论&lt;/h4&gt;StD是一种无需调整、即插即用的解决方案，在视频处理中实现了高达1.94倍的墙时速度提升。它通过最小的代码修改，实现了从标准Video-LLM到稀疏Video-LLM的无缝过渡，同时保持了模型性能。&lt;h4&gt;翻译&lt;/h4&gt;由于当前视频大型语言模型（Video-LLMs）具有自回归性质，随着输入序列长度的增加，推理延迟也随之增加，这对处理通常非常长的视频序列构成了挑战。我们观察到，在解码过程中，Video-LLMs中大多数token的注意力得分通常是稀疏且集中的，只有某些token需要全面的全注意力。基于这一观察，我们引入了一种名为稀疏到密集（StD）的新解码策略，该策略集成了两个不同的模块：一个利用稀疏的top-K注意力，另一个使用密集的全注意力。这些模块协同工作，在不损失性能的情况下加速Video-LLMs。快速（稀疏）模型推测性地解码多个token，而慢速（密集）模型并行验证它们。StD是一种无需调整、即插即用的解决方案，在视频处理中实现了高达1.94倍的墙时速度提升。它通过最小的代码修改，实现了从标准Video-LLM到稀疏Video-LLM的无缝过渡，同时保持了模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to the auto-regressive nature of current video large language models(Video-LLMs), the inference latency increases as the input sequence lengthgrows, posing challenges for the efficient processing of video sequences thatare usually very long. We observe that during decoding, the attention scores ofmost tokens in Video-LLMs tend to be sparse and concentrated, with only certaintokens requiring comprehensive full attention. Based on this insight, weintroduce Sparse-to-Dense (StD), a novel decoding strategy that integrates twodistinct modules: one leveraging sparse top-K attention and the other employingdense full attention. These modules collaborate to accelerate Video-LLMswithout loss. The fast (sparse) model speculatively decodes multiple tokens,while the slow (dense) model verifies them in parallel. StD is a tuning-free,plug-and-play solution that achieves up to a 1.94$\times$ walltime speedup invideo processing. It maintains model performance while enabling a seamlesstransition from a standard Video-LLM to a sparse Video-LLM with minimal codemodifications.</description>
      <author>example@mail.com (Xuan Zhang, Cunxiao Du, Sicheng Yu, Jiawei Wu, Fengzhuo Zhang, Wei Gao, Qian Liu)</author>
      <guid isPermaLink="false">2505.19155v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>From Single Images to Motion Policies via Video-Generation Environment Representations</title>
      <link>http://arxiv.org/abs/2505.19306v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为VGER的框架，用于从单张RGB图像构建环境表示，并生成无碰撞的运动策略模型。&lt;h4&gt;背景&lt;/h4&gt;自主机器人需要构建周围环境的表示并适应环境几何形状来运动。&lt;h4&gt;目的&lt;/h4&gt;解决从单张RGB图像构建策略模型以实现无碰撞运动生成的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为VGER的框架，该框架利用大规模视频生成模型生成基于输入图像的移动相机视频，并使用这些视频帧作为多视图数据集输入到预训练的3D基础模型中，以产生密集的点云。然后，引入了一种多尺度噪声方法来训练环境结构的隐式表示，并构建了一个符合表示几何形状的运动生成模型。&lt;h4&gt;主要发现&lt;/h4&gt;VGER在室内和室外环境中进行了广泛评估，展示了其生成考虑场景几何形状的平滑运动的能力。&lt;h4&gt;结论&lt;/h4&gt;VGER能够从单张RGB输入图像生成考虑场景几何形状的平滑运动。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为VGER的框架，用于从单张RGB图像构建环境表示，并生成无碰撞的运动策略模型。自主机器人需要构建周围环境的表示并适应环境几何形状来运动。本研究旨在解决从单张RGB图像构建策略模型以实现无碰撞运动生成的问题。提出了一种名为VGER的框架，该框架利用大规模视频生成模型生成基于输入图像的移动相机视频，并使用这些视频帧作为多视图数据集输入到预训练的3D基础模型中，以产生密集的点云。然后，引入了一种多尺度噪声方法来训练环境结构的隐式表示，并构建了一个符合表示几何形状的运动生成模型。VGER在室内和室外环境中进行了广泛评估，展示了其生成考虑场景几何形状的平滑运动的能力。VGER能够从单张RGB输入图像生成考虑场景几何形状的平滑运动。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous robots typically need to construct representations of theirsurroundings and adapt their motions to the geometry of their environment.Here, we tackle the problem of constructing a policy model for collision-freemotion generation, consistent with the environment, from a single input RGBimage. Extracting 3D structures from a single image often involves monoculardepth estimation. Developments in depth estimation have given rise to largepre-trained models such as DepthAnything. However, using outputs of thesemodels for downstream motion generation is challenging due to frustum-shapederrors that arise. Instead, we propose a framework known as Video-GenerationEnvironment Representation (VGER), which leverages the advances of large-scalevideo generation models to generate a moving camera video conditioned on theinput image. Frames of this video, which form a multiview dataset, are theninput into a pre-trained 3D foundation model to produce a dense point cloud. Wethen introduce a multi-scale noise approach to train an implicit representationof the environment structure and build a motion generation model that complieswith the geometry of the representation. We extensively evaluate VGER over adiverse set of indoor and outdoor environments. We demonstrate its ability toproduce smooth motions that account for the captured geometry of a scene, allfrom a single RGB input image.</description>
      <author>example@mail.com (Weiming Zhi, Ziyong Ma, Tianyi Zhang, Matthew Johnson-Roberson)</author>
      <guid isPermaLink="false">2505.19306v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Style2Code: A Style-Controllable Code Generation Framework with Dual-Modal Contrastive Representation Learning</title>
      <link>http://arxiv.org/abs/2505.19442v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures, submitted to EMNLP 2025 (Industry Track)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合对比学习和条件解码的代码生成框架，旨在实现可控的代码风格生成。&lt;h4&gt;背景&lt;/h4&gt;可控代码生成是合成遵循特定风格同时保持功能性的代码的挑战性任务。&lt;h4&gt;目的&lt;/h4&gt;实现灵活的风格控制，同时保证代码的正确性。&lt;h4&gt;方法&lt;/h4&gt;采用两阶段训练框架：第一阶段对代码风格表示与语义和结构特征进行对齐；第二阶段，基于学习到的风格向量微调语言模型（如Flan-T5）以指导生成。&lt;h4&gt;主要发现&lt;/h4&gt;该方法支持风格插值和用户个性化，相比之前的工作，在提供改进的风格控制的同时，不牺牲代码的正确性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法是首次将对比对齐与条件解码结合用于风格指导的代码生成的方法之一。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Controllable code generation, the ability to synthesize code that follows aspecified style while maintaining functionality, remains a challenging task. Wepropose a two-stage training framework combining contrastive learning andconditional decoding to enable flexible style control. The first stage alignscode style representations with semantic and structural features. In the secondstage, we fine-tune a language model (e.g., Flan-T5) conditioned on the learnedstyle vector to guide generation. Our method supports style interpolation anduser personalization via lightweight mixing. Compared to prior work, ourunified framework offers improved stylistic control without sacrificing codecorrectness. This is among the first approaches to combine contrastivealignment with conditional decoding for style-guided code generation.</description>
      <author>example@mail.com (Dutao Zhang, Sergey Kovalchuk, YuLong He)</author>
      <guid isPermaLink="false">2505.19442v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Search-Based Software Engineering in the Landscape of AI Foundation Models</title>
      <link>http://arxiv.org/abs/2505.19625v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于搜索的软件工程（SBSE）在人工智能（AI）和软件工程交叉领域的研究现状，以及与基础模型（FMs）结合的未来研究方向。&lt;h4&gt;背景&lt;/h4&gt;SBSE作为AI和软件工程的交叉领域，已有约25年的研究历史，并在整个软件工程生命周期中应用于解决各种问题，展示了其多领域的适应性。&lt;h4&gt;目的&lt;/h4&gt;提出一个研究路线图，阐述SBSE与FMs结合的现状，强调开放性挑战，并规划通过SBSE与FMs的相互作用来推进SBSE的研究方向。&lt;h4&gt;方法&lt;/h4&gt;通过分析SBSE与FMs结合的现状，识别开放性挑战，并提出潜在的研究方向。&lt;h4&gt;主要发现&lt;/h4&gt;SBSE与FMs的结合具有巨大潜力，但同时也面临一些开放性挑战。&lt;h4&gt;结论&lt;/h4&gt;本文提出的研究路线图旨在为SBSE在FMs时代的未来提供一个前瞻性和创新性的视角。&lt;h4&gt;翻译&lt;/h4&gt;Search-based software engineering (SBSE), at the intersection of artificial intelligence (AI) and software engineering, has been an active area of research for about 25 years. It has been applied to solve numerous problems across the entire software engineering lifecycle and has demonstrated its versatility in multiple domains. With the recent advancements in AI, particularly the emergence of foundation models (FMs), the evolution of SBSE alongside FMs remains undetermined. In this window of opportunity, we propose a research roadmap that articulates the current landscape of SBSE in relation to foundation models (FMs), highlights open challenges, and outlines potential research directions for advancing SBSE through its interplay with FMs. This roadmap aims to establish a forward-thinking and innovative perspective for the future of SBSE in the era of FMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Search-based software engineering (SBSE), at the intersection of artificialintelligence (AI) and software engineering, has been an active area of researchfor about 25 years. It has been applied to solve numerous problems across theentire software engineering lifecycle and has demonstrated its versatility inmultiple domains. With the recent advancements in AI, particularly theemergence of foundation models (FMs), the evolution of SBSE alongside FMsremains undetermined. In this window of opportunity, we propose a researchroadmap that articulates the current landscape of SBSE in relation tofoundation models (FMs), highlights open challenges, and outlines potentialresearch directions for advancing SBSE through its interplay with FMs. Thisroadmap aims to establish a forward-thinking and innovative perspective for thefuture of SBSE in the era of FMs.</description>
      <author>example@mail.com (Hassan Sartaj, Shaukat Ali)</author>
      <guid isPermaLink="false">2505.19625v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Medical Large Vision Language Models with Multi-Image Visual Ability</title>
      <link>http://arxiv.org/abs/2505.19031v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了医疗大型视觉语言模型（LVLMs）在多图像临床场景中的处理能力，并提出了一种新的数据集和模型以提升LVLMs的多图像理解能力。&lt;h4&gt;背景&lt;/h4&gt;LVLMs在单图像问答任务中表现良好，但在处理多图像医学任务时，如需要时间推理和跨模态分析，其能力有限。&lt;h4&gt;目的&lt;/h4&gt;填补LVLMs在多图像医学场景处理能力的空白，提升其视觉理解能力。&lt;h4&gt;方法&lt;/h4&gt;提出了Med-MIM数据集，包含83.2K个医疗多图像问答对，用于训练和评估LVLMs。同时，使用Med-MIM数据集微调Mantis和LLaVA-Med模型，得到两个针对多图像分析的医疗VLMs：MIM-LLaVA-Med和Med-Mantis。开发了Med-MIM基准来全面评估LVLMs的多图像理解能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MIM-LLaVA-Med和Med-Mantis在Med-MIM基准的保留集和未保留集上都取得了优异的性能，证明了Med-MIM数据集有效提升了LVLMs在医学领域的多图像理解能力。&lt;h4&gt;结论&lt;/h4&gt;Med-MIM数据集和相应的模型有效地提升了LVLMs在多图像医学场景中的处理能力。&lt;h4&gt;翻译&lt;/h4&gt;Medical large vision-language models (LVLMs) have demonstrated promising performance across various single-image question answering (QA) benchmarks, yet their capability in processing multi-image clinical scenarios remains underexplored. Unlike single image based tasks, medical tasks involving multiple images often demand sophisticated visual understanding capabilities, such as temporal reasoning and cross-modal analysis, which are poorly supported by current medical LVLMs. To bridge this critical gap, we present the Med-MIM instruction dataset, comprising 83.2K medical multi-image QA pairs that span four types of multi-image visual abilities (temporal understanding, reasoning, comparison, co-reference). Using this dataset, we fine-tune Mantis and LLaVA-Med, resulting in two specialized medical VLMs: MIM-LLaVA-Med and Med-Mantis, both optimized for multi-image analysis. Additionally, we develop the Med-MIM benchmark to comprehensively evaluate the medical multi-image understanding capabilities of LVLMs. We assess eight popular LVLMs, including our two models, on the Med-MIM benchmark. Experimental results show that both Med-Mantis and MIM-LLaVA-Med achieve superior performance on the held-in and held-out subsets of the Med-MIM benchmark, demonstrating that the Med-MIM instruction dataset effectively enhances LVLMs' multi-image understanding capabilities in the medical domain.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical large vision-language models (LVLMs) have demonstrated promisingperformance across various single-image question answering (QA) benchmarks, yettheir capability in processing multi-image clinical scenarios remainsunderexplored. Unlike single image based tasks, medical tasks involvingmultiple images often demand sophisticated visual understanding capabilities,such as temporal reasoning and cross-modal analysis, which are poorly supportedby current medical LVLMs. To bridge this critical gap, we present the Med-MIMinstruction dataset, comprising 83.2K medical multi-image QA pairs that spanfour types of multi-image visual abilities (temporal understanding, reasoning,comparison, co-reference). Using this dataset, we fine-tune Mantis andLLaVA-Med, resulting in two specialized medical VLMs: MIM-LLaVA-Med andMed-Mantis, both optimized for multi-image analysis. Additionally, we developthe Med-MIM benchmark to comprehensively evaluate the medical multi-imageunderstanding capabilities of LVLMs. We assess eight popular LVLMs, includingour two models, on the Med-MIM benchmark. Experimental results show that bothMed-Mantis and MIM-LLaVA-Med achieve superior performance on the held-in andheld-out subsets of the Med-MIM benchmark, demonstrating that the Med-MIMinstruction dataset effectively enhances LVLMs' multi-image understandingcapabilities in the medical domain.</description>
      <author>example@mail.com (Xikai Yang, Juzheng Miao, Yuchen Yuan, Jiaze Wang, Qi Dou, Jinpeng Li, Pheng-Ann Heng)</author>
      <guid isPermaLink="false">2505.19031v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>LocalKMeans: Convergence of Lloyd's Algorithm with Distributed Local Iterations</title>
      <link>http://arxiv.org/abs/2505.18420v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文分析了经典K-means交替最小化算法，即Lloyd算法，在包含局部迭代步骤的数据分布环境下的高斯混合情况。&lt;h4&gt;背景&lt;/h4&gt;在假设无标签数据分布在不同机器上的数据分布式设置中。&lt;h4&gt;目的&lt;/h4&gt;提出了一个名为LocalKMeans的算法，该算法通过在本地数据上运行迭代并在每$L$个这样的局部步骤中进行同步，以并行执行Lloyd算法。&lt;h4&gt;方法&lt;/h4&gt;对局部迭代的成本与非分布式设置进行了特征化，并显示了为局部步骤付出的代价是更高的信噪比要求。为了获得我们的结果，我们调整了一个虚拟迭代方法来与非凸、非光滑的目标函数一起工作，并与Lloyd步骤的紧密统计分析相结合。&lt;h4&gt;主要发现&lt;/h4&gt;局部迭代在过去被理论研究了梯度学习方法，但由于存在潜在变量（例如簇标识符），对无监督学习方法的解析比迭代梯度算法更为复杂。&lt;h4&gt;结论&lt;/h4&gt;LocalKMeans算法通过并行化和局部迭代，以更高的信噪比要求为代价，实现了K-means算法的分布式处理。&lt;h4&gt;翻译&lt;/h4&gt;在本文中，我们分析了经典K-means交替最小化算法，也称为Lloyd算法（Lloyd，1956），在包含局部迭代步骤的数据分布环境下的高斯混合情况。假设无标签数据分布在不同机器上，我们提出了一个名为LocalKMeans的算法，该算法通过在本地数据上运行迭代并在每L个这样的局部步骤中进行同步，以并行执行Lloyd算法。我们对这些局部迭代的成本与非分布式设置进行了特征化，并显示了为局部步骤付出的代价是更高的信噪比要求。虽然局部迭代在过去被理论研究了梯度学习方法，但由于存在潜在变量（例如簇标识符），对无监督学习方法的解析比迭代梯度算法更为复杂。为了获得我们的结果，我们调整了一个虚拟迭代方法来与非凸、非光滑的目标函数一起工作，并与Lloyd步骤的紧密统计分析相结合。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we analyze the classical $K$-means alternating-minimizationalgorithm, also known as Lloyd's algorithm (Lloyd, 1956), for a mixture ofGaussians in a data-distributed setting that incorporates local iterationsteps. Assuming unlabeled data distributed across multiple machines, we proposean algorithm, LocalKMeans, that performs Lloyd's algorithm in parallel in themachines by running its iterations on local data, synchronizing only every $L$of such local steps. We characterize the cost of these local iterations againstthe non-distributed setting, and show that the price paid for the local stepsis a higher required signal-to-noise ratio. While local iterations weretheoretically studied in the past for gradient-based learning methods, theanalysis of unsupervised learning methods is more involved owing to thepresence of latent variables, e.g. cluster identities, than that of aniterative gradient-based algorithm. To obtain our results, we adapt a virtualiterate method to work with a non-convex, non-smooth objective function, inconjunction with a tight statistical analysis of Lloyd steps.</description>
      <author>example@mail.com (Harsh Vardhan, Heng Zhu, Avishek Ghosh, Arya Mazumdar)</author>
      <guid isPermaLink="false">2505.18420v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>DocMMIR: A Framework for Document Multi-modal Information Retrieval</title>
      <link>http://arxiv.org/abs/2505.19312v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Comments: 13 pages, 7 figures. Code and data publicly available at  https://github.com/J1mL1/DocMMIR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的多模态文档检索框架DocMMIR，用于统一不同格式和领域的文档检索，并构建了一个大规模跨域多模态基准数据集。&lt;h4&gt;背景&lt;/h4&gt;无监督表示学习和大规模预训练视觉语言模型的发展显著提高了跨模态检索任务，但现有的多模态信息检索研究缺乏对文档级检索的全面探索，且缺乏该粒度的跨域数据集。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述限制，提出DocMMIR框架，旨在统一不同格式和领域的文档，并在一个综合检索场景中实现。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含450K样本的大规模跨域多模态基准数据集，系统性地整合了文本和视觉信息。对当前最先进的MLLMs进行了实验分析，并探索了训练策略，包括跨模态融合方法和损失函数，并开发了一种针对基准数据集训练CLIP的方法。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在当前最先进的MLLMs中，只有CLIP在零样本情况下表现出合理的性能。通过针对基准数据集训练CLIP，MRR@10相比零样本基线提高了31%。&lt;h4&gt;结论&lt;/h4&gt;DocMMIR框架能够有效提高文档级检索的性能，并提供了针对该领域的基准数据集和训练方法。&lt;h4&gt;翻译&lt;/h4&gt;The rapid advancement of unsupervised representation learning and large-scale pre-trained vision-language models has significantly improved cross-modal retrieval tasks. However, existing multi-modal information retrieval (MMIR) studies lack a comprehensive exploration of document-level retrieval and suffer from the absence of cross-domain datasets at this granularity. To address this limitation, we introduce DocMMIR, a novel multi-modal document retrieval framework designed explicitly to unify diverse document formats and domains, including Wikipedia articles, scientific papers (arXiv), and presentation slides, within a comprehensive retrieval scenario. We construct a large-scale cross-domain multimodal benchmark, comprising 450K samples, which systematically integrates textual and visual information. Our comprehensive experimental analysis reveals substantial limitations in current state-of-the-art MLLMs (CLIP, BLIP2, SigLIP-2, ALIGN) when applied to our tasks, with only CLIP demonstrating reasonable zero-shot performance. Furthermore, we conduct a systematic investigation of training strategies, including cross-modal fusion methods and loss functions, and develop a tailored approach to train CLIP on our benchmark. This results in a +31% improvement in MRR@10 compared to the zero-shot baseline. All our data and code are released in https://github.com/J1mL1/DocMMIR.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of unsupervised representation learning and large-scalepre-trained vision-language models has significantly improved cross-modalretrieval tasks. However, existing multi-modal information retrieval (MMIR)studies lack a comprehensive exploration of document-level retrieval and sufferfrom the absence of cross-domain datasets at this granularity. To address thislimitation, we introduce DocMMIR, a novel multi-modal document retrievalframework designed explicitly to unify diverse document formats and domains,including Wikipedia articles, scientific papers (arXiv), and presentationslides, within a comprehensive retrieval scenario. We construct a large-scalecross-domain multimodal benchmark, comprising 450K samples, whichsystematically integrates textual and visual information. Our comprehensiveexperimental analysis reveals substantial limitations in currentstate-of-the-art MLLMs (CLIP, BLIP2, SigLIP-2, ALIGN) when applied to ourtasks, with only CLIP demonstrating reasonable zero-shot performance.Furthermore, we conduct a systematic investigation of training strategies,including cross-modal fusion methods and loss functions, and develop a tailoredapproach to train CLIP on our benchmark. This results in a +31% improvement inMRR@10 compared to the zero-shot baseline. All our data and code are releasedin https://github.com/J1mL1/DocMMIR.</description>
      <author>example@mail.com (Zirui Li, Siwei Wu, Xingyu Wang, Yi Zhou, Yizhi Li, Chenghua Lin)</author>
      <guid isPermaLink="false">2505.19312v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Paying Alignment Tax with Contrastive Learning</title>
      <link>http://arxiv.org/abs/2505.19327v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的去偏方法，通过对比学习框架来平衡去偏和模型能力保留，避免了现有方法中模型能力下降的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的去偏方法往往导致模型能力下降，如事实准确性和知识保留。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的去偏方法，以减少模型能力下降的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种对比学习框架，通过精心构造的正负样本进行学习，引入对比计算和动态损失缩放来平衡去偏和模型能力保留。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在多个模型规模上实现了显著的改进，同时提高了毒性减少和忠实度保留，是第一个同时提高这两个指标的方法，避免了现有方法的模型能力下降特性。&lt;h4&gt;结论&lt;/h4&gt;通过对比学习显式建模正负样本，可能是减少语言模型去偏中‘对齐税’的有希望的方向。&lt;h4&gt;翻译&lt;/h4&gt;Current debiasing approaches often result in a degradation in model capabilities such as factual accuracy and knowledge retention. Through systematic evaluation across multiple benchmarks, we demonstrate that existing debiasing methods face fundamental trade-offs, particularly in smaller models, leading to reduced truthfulness, knowledge loss, or unintelligible outputs. To address these limitations, we propose a contrastive learning framework that learns through carefully constructed positive and negative examples. Our approach introduces contrast computation and dynamic loss scaling to balance bias mitigation with faithfulness preservation. Experimental results across multiple model scales demonstrate that our method achieves substantial improvements in both toxicity reduction and faithfulness preservation. Most importantly, we show that our framework is the first to consistently improve both metrics simultaneously, avoiding the capability degradation characteristic of existing approaches. These results suggest that explicit modeling of both positive and negative examples through contrastive learning could be a promising direction for reducing the alignment tax in language model debiasing.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current debiasing approaches often result a degradation in model capabilitiessuch as factual accuracy and knowledge retention. Through systematic evaluationacross multiple benchmarks, we demonstrate that existing debiasing methods facefundamental trade-offs, particularly in smaller models, leading to reducedtruthfulness, knowledge loss, or unintelligible outputs. To address theselimitations, we propose a contrastive learning framework that learns throughcarefully constructed positive and negative examples. Our approach introducescontrast computation and dynamic loss scaling to balance bias mitigation withfaithfulness preservation. Experimental results across multiple model scalesdemonstrate that our method achieves substantial improvements in both toxicityreduction and faithfulness preservation. Most importantly, we show that ourframework is the first to consistently improve both metrics simultaneously,avoiding the capability degradation characteristic of existing approaches.These results suggest that explicit modeling of both positive and negativeexamples through contrastive learning could be a promising direction forreducing the alignment tax in language model debiasing.</description>
      <author>example@mail.com (Buse Sibel Korkmaz, Rahul Nair, Elizabeth M. Daly, Antonio del Rio Chanona)</author>
      <guid isPermaLink="false">2505.19327v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Languages in Multilingual Speech Foundation Models Align Both Phonetically and Semantically</title>
      <link>http://arxiv.org/abs/2505.19606v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了跨语言对齐在预训练语言模型中的应用，并测试了其是否适用于语音模型，发现即使在缺乏语音线索的情况下，语音翻译检索的准确性也相对稳定。&lt;h4&gt;背景&lt;/h4&gt;跨语言对齐在文本型预训练语言模型和语音基础模型中都已被观察到，但其是否适用于语音模型仍是一个未解决的问题。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过实验验证跨语言对齐在语音模型中能否基于语义而非语音相似性发生。&lt;h4&gt;方法&lt;/h4&gt;通过发音控制的实验和跨语言同义词及近音词的词级数据集的受控实验，以及对编码器早期退出产生的转录的定性分析。&lt;h4&gt;主要发现&lt;/h4&gt;即使在没有语音线索的情况下，语音翻译检索的准确性仍然相对稳定，编码器中存在语音和语义知识，语音翻译会产生与源语言中对应词语的语音相似性的语义错误。&lt;h4&gt;结论&lt;/h4&gt;跨语言对齐在语音模型中是有效的，即使在缺乏语音线索的情况下，并且对低资源语言的语音识别也产生了改进。&lt;h4&gt;翻译&lt;/h4&gt;本研究探讨了跨语言对齐在预训练语言模型中的应用，并测试了其是否适用于语音模型。研究发现，即使在缺乏语音线索的情况下，语音翻译检索的准确性也相对稳定。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-lingual alignment in pretrained language models (LMs) has enabledefficient transfer in text-based LMs. Such an alignment has also been observedin speech foundation models. However, it remains an open question whetherfindings and methods from text-based cross-lingual alignment apply to speech.Building on prior work on spoken translation retrieval, we performpronunciation-controlled experiments to observe if cross-lingual alignment canindeed occur in such models on a semantic basis, instead of relying on phoneticsimilarities. Our findings indicate that even in the absence of phonetic cues,spoken translation retrieval accuracy remains relatively stable. We follow upwith a controlled experiment on a word-level dataset of cross-lingual synonymsand near-homophones, confirming the existence of both phonetic and semanticknowledge in the encoder. Finally, we qualitatively examine the transcriptionsproduced by early exiting the encoder, where we observe that speech translationproduces semantic errors that are characterized by phonetic similarities tocorresponding words in the source language. We apply this insight from earlyexiting to speech recognition in seven low-resource languages unsupported bythe Whisper model, and achieve improved accuracy in all languages examined,particularly for languages with transparent orthographies.</description>
      <author>example@mail.com (Ryan Soh-Eun Shim, Domenico De Cristofaro, Chengzhi Martin Hu, Alessandro Vietti, Barbara Plank)</author>
      <guid isPermaLink="false">2505.19606v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>On the Structure and Semantics of Identifier Names Containing Closed Syntactic Category Words</title>
      <link>http://arxiv.org/abs/2505.18444v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Current in submission to EMSE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过扩展语法模式的概念，研究了标识符名称的语结构，重点关注封闭的句法类别（如介词、连词、限定词）在软件工程中的应用，并提出了新的封闭类别标识符数据集（CCID），通过分析这些标识符的语法模式和程序行为之间的关系，揭示了开发者通过命名表达控制流、数据转换、时间推理和行为角色的常用结构。&lt;h4&gt;背景&lt;/h4&gt;标识符名称是代码的关键组成部分，对于开发者理解程序行为至关重要。尽管在自然语言中这些封闭的句法类别具有核心作用，但在软件工程中它们的研究却很少。&lt;h4&gt;目的&lt;/h4&gt;研究标识符名称的语结构，分析封闭类别语法模式和程序行为之间的关系，并探讨开发者如何通过命名编码行为。&lt;h4&gt;方法&lt;/h4&gt;提出新的封闭类别标识符数据集（CCID），使用扎根理论编码、统计分析和模式分析来分析数据。&lt;h4&gt;主要发现&lt;/h4&gt;揭示了开发者通过命名表达控制流、数据转换、时间推理和行为角色的常用结构。&lt;h4&gt;结论&lt;/h4&gt;为理解开发者如何通过命名编码行为提供了经验基础，并指出了命名支持、理解和教育领域未来研究的方向。&lt;h4&gt;翻译&lt;/h4&gt;Identifier names are crucial components of code, serving as primary clues for developers to understand program behavior. This paper investigates the linguistic structure of identifier names by extending the concept of grammar patterns; representations of the part-of-speech (PoS) sequences that underlie identifier phrases. The specific focus is on closed syntactic categories (e.g., prepositions, conjunctions, determiners), which are rarely studied in software engineering despite their central role in general natural language. The Closed Category Identifier Dataset (CCID) is presented, a new manually annotated dataset of 1,275 identifiers drawn from 30 open-source systems. The relationship between closed-category grammar patterns and program behavior is analyzed using grounded theory coding, statistical, and pattern analysis. The results reveal recurring structures that developers use to express control flow, data transformation, temporal reasoning, and behavioral roles through naming. This study contributes an empirical foundation for understanding how developers adapt linguistic resources to encode behavior in source code. By analyzing closed-category terms and their associated grammar patterns, the work highlights a previously underexplored dimension of identifier semantics and identifies promising directions for future research in naming support, comprehension, and education.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Identifier names are crucial components of code, serving as primary clues fordevelopers to understand program behavior. This paper investigates thelinguistic structure of identifier names by extending the concept of grammarpatterns; representations of the part-of-speech (PoS) sequences that underlieidentifier phrases. The specific focus is on closed syntactic categories (e.g.,prepositions, conjunctions, determiners), which are rarely studied in softwareengineering despite their central role in general natural language. The ClosedCategory Identifier Dataset (CCID) is presented, a new manually annotateddataset of 1,275 identifiers drawn from 30 open-source systems. Therelationship between closed-category grammar patterns and program behavior isanalyzed using grounded theory coding, statistical, and pattern analysis. Theresults reveal recurring structures that developers use to express controlflow, data transformation, temporal reasoning, and behavioral roles throughnaming. This study contributes an empirical foundation for understanding howdevelopers adapt linguistic resources to encode behavior in source code. Byanalyzing closed-category terms and their associated grammar patterns, the workhighlights a previously underexplored dimension of identifier semantics andidentifies promising directions for future research in naming support,comprehension, and education.</description>
      <author>example@mail.com (Christian D. Newman, Anthony Peruma, Eman Abdullah AlOmar, Mahie Crabbe, Syreen Banabilah, Reem S. AlSuhaibani, Michael J. Decker, Farhad Akhbardeh, Marcos Zampieri, Mohamed Wiem Mkaouer, Jonathan I. Maletic)</author>
      <guid isPermaLink="false">2505.18444v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Can LLMs Alleviate Catastrophic Forgetting in Graph Continual Learning? A Systematic Study</title>
      <link>http://arxiv.org/abs/2505.18697v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在图持续学习（GCL）中，大型语言模型（LLMs）是否能减轻灾难性遗忘问题。&lt;h4&gt;背景&lt;/h4&gt;现实世界的数据，包括图结构数据，通常以流式方式到达，这意味着学习系统需要在不断获取新知识的同时，不忘记之前学到的信息。&lt;h4&gt;目的&lt;/h4&gt;探讨LLMs在GCL中减轻灾难性遗忘的效果。&lt;h4&gt;方法&lt;/h4&gt;指出当前GCL实验设置的重大缺陷，并在更现实的场景下评估LLMs的性能。基于大量实验，提出了一种简单而有效的方法——简单图持续学习（SimGCL），并在无排练约束下，其性能超过了之前基于GNN的基线约20%。开发了易于使用的基准LLM4GCL以训练和评估现有的GCL方法。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs在GCL中的性能甚至微小修改都能带来显著结果。&lt;h4&gt;结论&lt;/h4&gt;LLMs可以减轻GCL中的灾难性遗忘问题，并提出了一种新的方法SimGCL，提高了GCL的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：如今，现实世界的数据，包括图结构数据，通常以流式方式到达，这意味着学习系统需要在不断获取新知识的同时，不忘记之前学到的信息。尽管大量现有工作试图解决图机器学习中的灾难性遗忘问题，但它们都是基于从头开始用流数据进行训练的。随着预训练模型的出现，越来越多的研究利用它们的强大泛化能力进行持续学习。因此，在这项工作中，我们试图回答大型语言模型（LLMs）是否可以减轻图持续学习（GCL）中的灾难性遗忘。我们首先指出，当前GCL的实验设置存在重大缺陷，因为评估阶段可能导致任务ID泄露。然后，我们在更现实的场景下评估了LLMs的性能，发现即使是微小的修改也能带来出色的结果。最后，基于大量实验，我们提出了一种简单而有效的方法，简单图持续学习（SimGCL），在无排练约束下，其性能比之前基于GNN的基线提高了约20%。为了促进可重复性，我们开发了一个易于使用的基准LLM4GCL，用于训练和评估现有的GCL方法。代码可在以下地址找到：https://github.com/ZhixunLEE/LLM4GCL。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nowadays, real-world data, including graph-structure data, often arrives in astreaming manner, which means that learning systems need to continuouslyacquire new knowledge without forgetting previously learned information.Although substantial existing works attempt to address catastrophic forgettingin graph machine learning, they are all based on training from scratch withstreaming data. With the rise of pretrained models, an increasing number ofstudies have leveraged their strong generalization ability for continuallearning. Therefore, in this work, we attempt to answer whether large languagemodels (LLMs) can mitigate catastrophic forgetting in Graph Continual Learning(GCL). We first point out that current experimental setups for GCL havesignificant flaws, as the evaluation stage may lead to task ID leakage. Then,we evaluate the performance of LLMs in more realistic scenarios and find thateven minor modifications can lead to outstanding results. Finally, based onextensive experiments, we propose a simple-yet-effective method, Simple GraphContinual Learning (SimGCL), that surpasses the previous state-of-the-artGNN-based baseline by around 20% under the rehearsal-free constraint. Tofacilitate reproducibility, we have developed an easy-to-use benchmark LLM4GCLfor training and evaluating existing GCL methods. The code is available at:https://github.com/ZhixunLEE/LLM4GCL.</description>
      <author>example@mail.com (Ziyang Cheng, Zhixun Li, Yuhan Li, Yixin Song, Kangyi Zhao, Dawei Cheng, Jia Li, Jeffrey Xu Yu)</author>
      <guid isPermaLink="false">2505.18697v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>DriveX: Omni Scene Modeling for Learning Generalizable World Knowledge in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2505.19239v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了DriveX，一个自监督的全局模型，它从大规模驾驶视频中学习通用的场景动力学和整体表示（几何、语义和运动）。DriveX通过引入Omni Scene Modeling (OSM)模块，统一了多模态监督，并提出了一个解耦的潜在世界建模策略，以提高运动建模的准确性，同时设计了Future Spatial Attention (FSA)以增强特定任务的推理能力。实验表明，DriveX在3D未来点云预测和多种任务中取得了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;数据驱动学习推动了自动驾驶的发展，但特定任务的模型由于优化目标狭窄和对昂贵标注数据的依赖，难以处理分布外的场景。&lt;h4&gt;目的&lt;/h4&gt;提出DriveX，以解决特定任务模型在处理分布外场景时的局限性。&lt;h4&gt;方法&lt;/h4&gt;DriveX采用Omni Scene Modeling (OSM)模块，通过多模态监督统一了3D点云预测、2D语义表示和图像生成，并提出了解耦的潜在世界建模策略，同时使用动态感知光线采样来增强运动建模。为了适应下游任务，设计了Future Spatial Attention (FSA)。&lt;h4&gt;主要发现&lt;/h4&gt;DriveX在3D未来点云预测上取得了显著改进，并在占用预测、流量估计和端到端驾驶等多种任务中达到了最先进的水平。&lt;h4&gt;结论&lt;/h4&gt;DriveX作为一个通用的世界模型，具有强大的性能，为构建鲁棒且统一的自动驾驶框架铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;Data-driven learning has advanced autonomous driving, yet task-specific models struggle with out-of-distribution scenarios due to their narrow optimization objectives and reliance on costly annotated data. We present DriveX, a self-supervised world model that learns generalizable scene dynamics and holistic representations (geometric, semantic, and motion) from large-scale driving videos. DriveX introduces Omni Scene Modeling (OSM), a module that unifies multimodal supervision-3D point cloud forecasting, 2D semantic representation, and image generation-to capture comprehensive scene evolution. To simplify learning complex dynamics, we propose a decoupled latent world modeling strategy that separates world representation learning from future state decoding, augmented by dynamic-aware ray sampling to enhance motion modeling. For downstream adaptation, we design Future Spatial Attention (FSA), a unified paradigm that dynamically aggregates spatiotemporal features from DriveX's predictions to enhance task-specific inference. Extensive experiments demonstrate DriveX's effectiveness: it achieves significant improvements in 3D future point cloud prediction over prior work, while attaining state-of-the-art results on diverse tasks including occupancy prediction, flow estimation, and end-to-end driving. These results validate DriveX's capability as a general-purpose world model, paving the way for robust and unified autonomous driving frameworks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data-driven learning has advanced autonomous driving, yet task-specificmodels struggle with out-of-distribution scenarios due to their narrowoptimization objectives and reliance on costly annotated data. We presentDriveX, a self-supervised world model that learns generalizable scene dynamicsand holistic representations (geometric, semantic, and motion) from large-scaledriving videos. DriveX introduces Omni Scene Modeling (OSM), a module thatunifies multimodal supervision-3D point cloud forecasting, 2D semanticrepresentation, and image generation-to capture comprehensive scene evolution.To simplify learning complex dynamics, we propose a decoupled latent worldmodeling strategy that separates world representation learning from futurestate decoding, augmented by dynamic-aware ray sampling to enhance motionmodeling. For downstream adaptation, we design Future Spatial Attention (FSA),a unified paradigm that dynamically aggregates spatiotemporal features fromDriveX's predictions to enhance task-specific inference. Extensive experimentsdemonstrate DriveX's effectiveness: it achieves significant improvements in 3Dfuture point cloud prediction over prior work, while attaining state-of-the-artresults on diverse tasks including occupancy prediction, flow estimation, andend-to-end driving. These results validate DriveX's capability as ageneral-purpose world model, paving the way for robust and unified autonomousdriving frameworks.</description>
      <author>example@mail.com (Chen Shi, Shaoshuai Shi, Kehua Sheng, Bo Zhang, Li Jiang)</author>
      <guid isPermaLink="false">2505.19239v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>X-MethaneWet: A Cross-scale Global Wetland Methane Emission Benchmark Dataset for Advancing Science Discovery with AI</title>
      <link>http://arxiv.org/abs/2505.18355v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 8 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了首个全球湿地甲烷基准数据集X-MethaneWet，通过结合物理模型模拟数据和实际观测数据，旨在提高全球湿地甲烷模型和科学发现，并探索了人工智能算法的应用。&lt;h4&gt;背景&lt;/h4&gt;甲烷是仅次于二氧化碳的第二大温室气体，其对气候变化有重要影响。准确模拟全球甲烷通量对于理解其时空变率和发展有效的减缓策略至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够改进全球湿地甲烷模型和促进科学发现的基准数据集，并通过人工智能算法提高甲烷通量预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;构建了X-MethaneWet数据集，评估了多种序列深度学习模型在数据集上的性能，并探索了四种不同的迁移学习技术以利用TEM-MDM模拟数据提高深度学习模型在FLUXNET-CH$_4$观测数据上的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明这些方法的有效性，突出了其在提高甲烷排放模型和开发更准确、可扩展的人工智能驱动气候模型方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;X-MethaneWet数据集和所采用的方法为改进全球湿地甲烷模型和推动气候变化研究提供了新的工具和策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Methane (CH$_4$) is the second most powerful greenhouse gas after carbondioxide and plays a crucial role in climate change due to its high globalwarming potential. Accurately modeling CH$_4$ fluxes across the globe and atfine temporal scales is essential for understanding its spatial and temporalvariability and developing effective mitigation strategies. In this work, weintroduce the first-of-its-kind cross-scale global wetland methane benchmarkdataset (X-MethaneWet), which synthesizes physics-based model simulation datafrom TEM-MDM and the real-world observation data from FLUXNET-CH$_4$. Thisdataset can offer opportunities for improving global wetland CH$_4$ modelingand science discovery with new AI algorithms. To set up AI model baselines formethane flux prediction, we evaluate the performance of various sequential deeplearning models on X-MethaneWet. Furthermore, we explore four differenttransfer learning techniques to leverage simulated data from TEM-MDM to improvethe generalization of deep learning models on real-world FLUXNET-CH$_4$observations. Our extensive experiments demonstrate the effectiveness of theseapproaches, highlighting their potential for advancing methane emissionmodeling and contributing to the development of more accurate and scalableAI-driven climate models.</description>
      <author>example@mail.com (Yiming Sun, Shuo Chen, Shengyu Chen, Chonghao Qiu, Licheng Liu, Youmi Oh, Sparkle L. Malone, Gavin McNicol, Qianlai Zhuang, Chris Smith, Yiqun Xie, Xiaowei Jia)</author>
      <guid isPermaLink="false">2505.18355v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Text-to-Image Diffusion Transformer via Split-Text Conditioning</title>
      <link>http://arxiv.org/abs/2505.19261v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DiT-ST的新型文本到图像扩散生成框架，用于解决当前文本到图像生成中完全文本条件导致的理解缺陷。&lt;h4&gt;背景&lt;/h4&gt;由于语法复杂，扩散变换器（DiTs）在处理完全文本描述时存在理解缺陷，可能导致语义混淆或忽略关键细节。&lt;h4&gt;目的&lt;/h4&gt;提出DiT-ST框架，以缓解DiTs的完全文本理解缺陷。&lt;h4&gt;方法&lt;/h4&gt;DiT-ST将完整文本描述转换为简化的分文本描述，并通过大型语言模型解析这些描述，提取并构建语义原语。分文本描述随后以分层和渐进的方式注入到DiT-ST的不同去噪阶段，并根据不同语义原语的敏感度进行分区处理。&lt;h4&gt;主要发现&lt;/h4&gt;DiT-ST通过分层和渐进的方式注入分文本描述，增强了特定语义原语在不同阶段的表示学习能力。&lt;h4&gt;结论&lt;/h4&gt;大量实验验证了DiT-ST在缓解完全文本理解缺陷方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;当前文本到图像的扩散生成通常采用完整的文本条件。由于语法复杂，扩散变换器（DiTs）固有地存在对完整文本描述的理解缺陷。一次性的完整文本输入要么忽略了关键的语义细节，要么通过同时模拟多种语义原语类型而导致语义混淆。为了缓解DiTs的这一缺陷，我们提出了一种名为DiT-ST的新型分文本条件框架。该框架将完整文本描述转换为分文本描述，即一系列简化的句子，以明确表达各种语义原语及其相互关系。然后，以分层和渐进的方式将分文本描述注入到DiT-ST的不同去噪阶段。具体来说，DiT-ST利用大型语言模型解析描述，提取各种原语，并按层次排序和构建这些原语，形成分文本输入。此外，我们根据扩散去噪过程对不同语义原语类型的微分敏感性进行分区，并确定适当的步长，通过交叉注意力将不同语义原语类型的标记增量注入到输入标记中。通过这种方式，DiT-ST增强了不同阶段特定语义原语类型的表示学习能力。大量实验验证了我们提出的DiT-ST在缓解完全文本理解缺陷方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current text-to-image diffusion generation typically employs complete-textconditioning. Due to the intricate syntax, diffusion transformers (DiTs)inherently suffer from a comprehension defect of complete-text captions.One-fly complete-text input either overlooks critical semantic details orcauses semantic confusion by simultaneously modeling diverse semantic primitivetypes. To mitigate this defect of DiTs, we propose a novel split-textconditioning framework named DiT-ST. This framework converts a complete-textcaption into a split-text caption, a collection of simplified sentences, toexplicitly express various semantic primitives and their interconnections. Thesplit-text caption is then injected into different denoising stages of DiT-STin a hierarchical and incremental manner. Specifically, DiT-ST leverages LargeLanguage Models to parse captions, extracting diverse primitives andhierarchically sorting out and constructing these primitives into a split-textinput. Moreover, we partition the diffusion denoising process according to itsdifferential sensitivities to diverse semantic primitive types and determinethe appropriate timesteps to incrementally inject tokens of diverse semanticprimitive types into input tokens via cross-attention. In this way, DiT-STenhances the representation learning of specific semantic primitive typesacross different stages. Extensive experiments validate the effectiveness ofour proposed DiT-ST in mitigating the complete-text comprehension defect.</description>
      <author>example@mail.com (Yu Zhang, Jialei Zhou, Xinchen Li, Qi Zhang, Zhongwei Wan, Tianyu Wang, Duoqian Miao, Changwei Wang, Longbing Cao)</author>
      <guid isPermaLink="false">2505.19261v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Conventional Contrastive Learning Often Falls Short: Improving Dense Retrieval with Cross-Encoder Listwise Distillation and Synthetic Data</title>
      <link>http://arxiv.org/abs/2505.19274v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  updated version of arxiv:2502.19712&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了通过语料库特定微调来提高嵌入模型检索有效性的方法。&lt;h4&gt;背景&lt;/h4&gt;以往研究表明，使用数据集的检索语料库生成的查询进行微调可以提高数据集的检索有效性。&lt;h4&gt;目的&lt;/h4&gt;旨在克服传统InfoNCE对比损失在微调过程中可能降低检索有效性的问题。&lt;h4&gt;方法&lt;/h4&gt;采用跨编码器列表蒸馏，并与仅使用对比学习的方法进行对比，发现列表蒸馏可以更一致地提高多个数据集的检索有效性。同时，通过合成更多使用不同查询类型（如断言、关键词和问题）的训练数据，提高了检索效果。&lt;h4&gt;主要发现&lt;/h4&gt;1. 使用列表蒸馏可以更一致地提高检索有效性；2. 使用多种查询类型合成训练数据比使用单一查询类型更有效；3. 合成查询在训练中提供了与人工编写查询相当的效用。&lt;h4&gt;结论&lt;/h4&gt;提出的方法在BERT嵌入模型中实现了最先进的检索有效性，并发布了模型和查询生成及训练代码，以促进进一步的研究。&lt;h4&gt;翻译&lt;/h4&gt;We investigate improving the retrieval effectiveness of embedding models through the lens of corpus-specific fine-tuning. Prior work has shown that fine-tuning with queries generated using a dataset's retrieval corpus can boost retrieval effectiveness for the dataset. However, we find that surprisingly, fine-tuning using the conventional InfoNCE contrastive loss often reduces effectiveness in state-of-the-art models. To overcome this, we revisit cross-encoder listwise distillation and demonstrate that, unlike using contrastive learning alone, listwise distillation can help more consistently improve retrieval effectiveness across multiple datasets. Additionally, we show that synthesizing more training data using diverse query types (such as claims, keywords, and questions) yields greater effectiveness than using any single query type alone, regardless of the query type used in evaluation. Our findings further indicate that synthetic queries offer comparable utility to human-written queries for training. We use our approach to train an embedding model that achieves state-of-the-art effectiveness among BERT embedding models. We release our model and both query generation and training code to facilitate further research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate improving the retrieval effectiveness of embedding modelsthrough the lens of corpus-specific fine-tuning. Prior work has shown thatfine-tuning with queries generated using a dataset's retrieval corpus can boostretrieval effectiveness for the dataset. However, we find that surprisingly,fine-tuning using the conventional InfoNCE contrastive loss often reduceseffectiveness in state-of-the-art models. To overcome this, we revisitcross-encoder listwise distillation and demonstrate that, unlike usingcontrastive learning alone, listwise distillation can help more consistentlyimprove retrieval effectiveness across multiple datasets. Additionally, we showthat synthesizing more training data using diverse query types (such as claims,keywords, and questions) yields greater effectiveness than using any singlequery type alone, regardless of the query type used in evaluation. Our findingsfurther indicate that synthetic queries offer comparable utility tohuman-written queries for training. We use our approach to train an embeddingmodel that achieves state-of-the-art effectiveness among BERT embedding models.We release our model and both query generation and training code to facilitatefurther research.</description>
      <author>example@mail.com (Manveer Singh Tamber, Suleman Kazi, Vivek Sourabh, Jimmy Lin)</author>
      <guid isPermaLink="false">2505.19274v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>CODE-DITING: A Reasoning-Based Metric for Functional Alignment in Code Evaluation</title>
      <link>http://arxiv.org/abs/2505.19502v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了信任度评估方法在神经代码生成中的重要性，并提出了CODE-DITING，一种平衡准确度、效率和可解释性的新代码评估方法。&lt;h4&gt;背景&lt;/h4&gt;传统的代码评估方法在灵活性和可扩展性上存在局限性。&lt;h4&gt;目的&lt;/h4&gt;系统地理解基于大型语言模型（LLM）的评估方法，并提出一种新的代码评估方法。&lt;h4&gt;方法&lt;/h4&gt;进行了一项综合实证研究，评估了基于不同基础模型的LLM评估方法，并提出了CODE-DITING方法。&lt;h4&gt;主要发现&lt;/h4&gt;基于通用基础模型的方法性能良好，但需要复杂的提示且缺乏可解释性；基于推理基础模型的方法具有更好的可解释性，但计算资源需求大。CODE-DITING方法通过数据蒸馏框架提高了可解释性并降低了计算成本。&lt;h4&gt;结论&lt;/h4&gt;CODE-DITING在准确度、效率和可解释性之间取得了平衡，是代码评估的一个有希望的替代方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在神经代码生成中，可信的代码片段评估方法起着至关重要的作用。传统方法要么依赖于参考解决方案，要么需要可执行测试用例，在灵活性和可扩展性上存在固有的局限性。最近提出的“LLM作为评判者”的方法通过直接评估问题描述与生成代码之间的功能一致性，提供了一个有希望的替代方案。为了系统地理解这些“LLM作为评判者”方法，我们跨三个不同的数据集进行了全面的实证研究。我们的研究揭示了两种LLM作为评判者方法的优缺点：基于通用基础模型的方法可以实现良好的性能，但需要复杂的提示且缺乏可解释性；基于推理基础模型的方法具有更好的可解释性，但因其大参数量而需要大量的计算资源。为了解决这些限制，我们提出了CODE-DITING，一种新的代码评估方法，它在准确度、效率和可解释性之间取得了平衡。我们开发了一个数据蒸馏框架，有效地将DeepSeek-R1671B的推理能力转移到我们的CODE-DITING 1.5B和7B模型中，显著提高了评估的可解释性并降低了计算成本。在推理过程中的多数投票策略下，CODE-DITING 1.5B优于所有参数量相同规模的模型，其性能相当于参数规模为5倍的模型。CODE-DITING 7B超过了GPT-4o和DeepSeek-V3 671B，尽管它只使用了这些大型模型1%的参数量。进一步的实验表明，CODE-DITING对偏好泄露具有鲁棒性，可以作为代码评估的有希望替代方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trustworthy evaluation methods for code snippets play a crucial role inneural code generation. Traditional methods, which either rely on referencesolutions or require executable test cases, have inherent limitation inflexibility and scalability. The recent LLM-as-Judge methodology offers apromising alternative by directly evaluating functional consistency between theproblem description and the generated code. To systematically understand thelandscape of these LLM-as-Judge methods, we conduct a comprehensive empiricalstudy across three diverse datasets. Our investigation reveals the pros andcons of two categories of LLM-as-Judge methods: the methods based on generalfoundation models can achieve good performance but require complex prompts andlack explainability, while the methods based on reasoning foundation modelsprovide better explainability with simpler prompts but demand substantialcomputational resources due to their large parameter sizes. To address theselimitations, we propose CODE-DITING, a novel code evaluation method thatbalances accuracy, efficiency and explainability. We develop a datadistillation framework that effectively transfers reasoning capabilities fromDeepSeek-R1671B to our CODE-DITING 1.5B and 7B models, significantly enhancingevaluation explainability and reducing the computational cost. With themajority vote strategy in the inference process, CODE-DITING 1.5B outperformsall models with the same magnitude of parameters and achieves performance whichwould normally exhibit in a model with 5 times of parameter scale. CODE-DITING7B surpasses GPT-4o and DeepSeek-V3 671B, even though it only uses 1% of theparameter volume of these large models. Further experiments show thatCODEDITING is robust to preference leakage and can serve as a promisingalternative for code evaluation.</description>
      <author>example@mail.com (Guang Yang, Yu Zhou, Xiang Chen, Wei Zheng, Xing Hu, Xin Zhou, David Lo, Taolue Chen)</author>
      <guid isPermaLink="false">2505.19502v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Mind The Gap: Deep Learning Doesn't Learn Deeply</title>
      <link>http://arxiv.org/abs/2505.18623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文旨在理解神经网络如何通过学习算法推理，并回答两个问题：当算法有效时，学习到的算法有多忠实，以及为什么神经网络在其他情况下无法学习有效的算法。&lt;h4&gt;背景&lt;/h4&gt;通常将学习算法推理表述为对合成数据进行归纳，其中参数化模型在输入、跟踪和输出上进行训练，这些输入、跟踪和输出由底层真实算法产生。&lt;h4&gt;目的&lt;/h4&gt;为了回答上述问题，本文使用了神经网络编译技术，该技术将源算法直接编码到神经网络参数中，使网络能够精确地计算算法，从而实现编译后的参数、中间向量和行为的比较。&lt;h4&gt;方法&lt;/h4&gt;本文重点分析了图神经网络（GNNs），因为它们与算法推理任务自然对齐，具体包括BFS、DFS和Bellman-Ford，这些算法涵盖了有效、忠实和无效的学习算法的范围。此外，本文引入了一种针对GNNs的神经网络编译方法，该方法通过解析设置网络参数，绕过训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;本文研究了神经网络学习算法推理中的可表达性-可训练性差距，这是一种学习算法推理的基本不足。作者假设归纳学习对于包含在计算类NC中的并行算法最有效。&lt;h4&gt;结论&lt;/h4&gt;本文通过神经网络编译方法，研究了神经网络学习算法推理的过程，并提出了关于可表达性-可训练性差距的假设，为开发能够从数据中稳健地学习复杂算法的神经网络提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;本文旨在理解神经网络如何通过学习算法推理，并回答两个问题：当算法有效时，学习到的算法有多忠实，以及为什么神经网络在其他情况下无法学习有效的算法。为了回答这些问题，我们使用了神经网络编译技术，这是一种直接将源算法编码到神经网络参数中的技术，使网络能够精确地计算算法。这允许比较编译后的参数、中间向量和行为。这项研究对于开发能够从数据中稳健地学习复杂算法的神经网络至关重要。我们的分析重点在于图神经网络（GNNs），它们与算法推理任务自然对齐，特别是我们选择的BFS、DFS和Bellman-Ford，它们涵盖了有效、忠实和无效的学习算法的范围。通常，学习算法推理被表述为对合成数据进行归纳，其中参数化模型在由底层真实算法产生的输入、跟踪和输出上进行训练。相比之下，我们为GNNs引入了一种神经网络编译方法，该方法通过解析设置网络参数，绕过训练。专注于GNNs利用了它们与算法推理的对齐、广泛的算法归纳文献以及神经网络编译在GNNs上的新颖应用。总的来说，本文旨在描述可表达性-可训练性差距——学习算法推理中的基本不足。我们假设归纳学习对于包含在计算类NC中的并行算法最有效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper aims to understand how neural networks learn algorithmic reasoningby addressing two questions: How faithful are learned algorithms when they areeffective, and why do neural networks fail to learn effective algorithmsotherwise? To answer these questions, we use neural compilation, a techniquethat directly encodes a source algorithm into neural network parameters,enabling the network to compute the algorithm exactly. This enables comparisonbetween compiled and conventionally learned parameters, intermediate vectors,and behaviors. This investigation is crucial for developing neural networksthat robustly learn complexalgorithms from data. Our analysis focuses on graphneural networks (GNNs), which are naturally aligned with algorithmic reasoningtasks, specifically our choices of BFS, DFS, and Bellman-Ford, which cover thespectrum of effective, faithful, and ineffective learned algorithms. Commonly,learning algorithmic reasoning is framed as induction over synthetic data,where a parameterized model is trained on inputs, traces, and outputs producedby an underlying ground truth algorithm. In contrast, we introduce a neuralcompilation method for GNNs, which sets network parameters analytically,bypassing training. Focusing on GNNs leverages their alignment with algorithmicreasoning, extensive algorithmic induction literature, and the novelapplication of neural compilation to GNNs. Overall, this paper aims tocharacterize expressability-trainability gaps - a fundamental shortcoming inlearning algorithmic reasoning. We hypothesize that inductive learning is mosteffective for parallel algorithms contained within the computational class\texttt{NC}.</description>
      <author>example@mail.com (Lucas Saldyt, Subbarao Kambhampati)</author>
      <guid isPermaLink="false">2505.18623v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>AI-predicted PT-symmetric magnets</title>
      <link>http://arxiv.org/abs/2505.18620v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了具有对称性量子输运和光学效应的奇偶性反铁磁（AFM1）材料，并使用人工智能、密度泛函理论（DFT）和对称性分析识别了23种候选AFM1材料。&lt;h4&gt;背景&lt;/h4&gt;AFM1材料因其奇偶性项在能带分散中的存在而具有不对称能带，这使其能够产生如磁压电效应、非互易导电性和光电流等响应。&lt;h4&gt;目的&lt;/h4&gt;探索AFM1材料的对称性量子输运和光学效应，并识别具有潜在应用价值的AFM1材料。&lt;h4&gt;方法&lt;/h4&gt;结合人工智能、DFT和对称性分析，使用图神经网络模型和AFM1特定的对称性约束筛选材料项目化合物，通过DFT计算确定材料的最低能量配置。&lt;h4&gt;主要发现&lt;/h4&gt;在23种候选材料中，AFM1具有最低能量，其中包括3种实验验证的AFM1材料、10种未知磁结构的合成化合物和10种尚未合成的材料。&lt;h4&gt;结论&lt;/h4&gt;AFM1材料在量子输运和光学效应方面具有潜力，并通过人工智能和DFT方法成功识别了多种候选材料。&lt;h4&gt;翻译&lt;/h4&gt;摘要：具有时间反演对称性和奇偶性反铁磁（AFM1）的材料因其对称性赋予的量子输运和光学效应而受到关注。这些材料在其能带分散中具有奇偶性项，导致非对称能带，并能够产生如磁压电效应、非互易导通性和光电流等响应。此外，它们可能在没有自旋轨道耦合的情况下支持非线性自旋霍尔效应，为自旋电流的产生提供了有效途径。我们通过结合人工智能、密度泛函理论（DFT）和对称性分析确定了23种候选AFM1材料。使用图神经网络模型并纳入AFM1特定的对称性约束，我们对材料项目化合物进行了筛选，以寻找高概率的AFM1候选材料。DFT计算表明，在23种候选材料中，AFM1具有测试的磁配置中的最低能量。这些材料包括3种实验验证的AFM1材料、10种具有未知磁结构的合成化合物和10种尚未合成的材料。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parity-time-reversal-symmetric odd-parity antiferromagnetic (AFM1) materialsare of interest for their symmetry-enabled quantum transport and opticaleffects. These materials host odd-parity terms in their band dispersion,leading to asymmetric energy bands and enabling responses such as themagnetopiezoelectric effect, nonreciprocal conductivity, and photocurrentgeneration. In addition, they may support a nonlinear spin Hall effect withoutspin-orbit coupling, offering an efficient route to spin current generation. Weidentify 23 candidate AFM1 materials by combining artificial intelligence,density functional theory (DFT), and symmetry analysis. Using a graph neuralnetwork model and incorporating AFM1-specific symmetry constraints, we screenMaterials Project compounds for high-probability AFM1 candidates. DFTcalculations show that AFM1 has the lowest energy among the tested magneticconfigurations in 23 candidate materials. These include 3 experimentallyverified AFM1 materials, 10 synthesized compounds with unknown magneticstructures, and 10 that are not yet synthesized.</description>
      <author>example@mail.com (Hao Wu, Daniel F. Agterberg)</author>
      <guid isPermaLink="false">2505.18620v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Are Time-Series Foundation Models Deployment-Ready? A Systematic Study of Adversarial Robustness Across Domains</title>
      <link>http://arxiv.org/abs/2505.19397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了时间序列基础模型（TSFMs）在对抗输入扰动下的鲁棒性，发现TSFMs对攻击较为脆弱，并提出了一些提高鲁棒性的潜在架构设计。&lt;h4&gt;背景&lt;/h4&gt;TSFMs在现实应用中越来越受欢迎，但它们对对抗输入扰动的鲁棒性尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;评估TSFMs在对抗输入扰动下的鲁棒性，并探索提高其鲁棒性的方法。&lt;h4&gt;方法&lt;/h4&gt;通过在代表性TSFMs和多个数据集上进行实验，研究TSFMs在对抗扰动下的预测行为变化。&lt;h4&gt;主要发现&lt;/h4&gt;TSFMs对对抗输入扰动非常敏感，即使是微小的扰动也可能导致显著的预测行为变化，如趋势反转、时间漂移和振幅变化，对基于TSFMs的服务构成严重风险。&lt;h4&gt;结论&lt;/h4&gt;论文提出了提高TSFMs鲁棒性的潜在架构设计，如结构稀疏性和多任务预训练，为设计更健壮的预测系统提供了实际指导。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the adversarial robustness of Time Series Foundation Models (TSFMs) and finds that they are highly sensitive to adversarial input perturbations. It proposes potential architectural designs, such as structural sparsity and multi-task pretraining, to improve robustness, providing actionable guidance for designing more resilient forecasting systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time Series Foundation Models (TSFMs), which are pretrained on large-scale,cross-domain data and capable of zero-shot forecasting in new scenarios withoutfurther training, are increasingly adopted in real-world applications. However,as the zero-shot forecasting paradigm gets popular, a critical yet overlookedquestion emerges: Are TSFMs robust to adversarial input perturbations? Suchperturbations could be exploited in man-in-the-middle attacks or datapoisoning. To address this gap, we conduct a systematic investigation into theadversarial robustness of TSFMs. Our results show that even minimalperturbations can induce significant and controllable changes in forecastbehaviors, including trend reversal, temporal drift, and amplitude shift,posing serious risks to TSFM-based services. Through experiments onrepresentative TSFMs and multiple datasets, we reveal their consistentvulnerabilities and identify potential architectural designs, such asstructural sparsity and multi-task pretraining, that may improve robustness.Our findings offer actionable guidance for designing more resilient forecastingsystems and provide a critical assessment of the adversarial robustness ofTSFMs.</description>
      <author>example@mail.com (Jiawen Zhang, Zhenwei Zhang, Shun Zheng, Xumeng Wen, Jia Li, Jiang Bian)</author>
      <guid isPermaLink="false">2505.19397v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Algorithms for Electing Successive Committees</title>
      <link>http://arxiv.org/abs/2505.18287v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages; 3 figures, accepted for publication in IJCAI-25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了成功选举委员会模型，旨在找到一系列最佳委员会，每个候选人只能连续加入有限数量的委员会。&lt;h4&gt;背景&lt;/h4&gt;现有模型对于寻求三个成员的委员会已被证明是NP-hard，缺乏有效的算法。&lt;h4&gt;目的&lt;/h4&gt;为了解锁该模型的全部潜力，设计了针对实际场景的参数化算法，以解决困难案例。&lt;h4&gt;方法&lt;/h4&gt;提出了参数化算法来解决困难案例，特别是在候选人数量适中或时间限制的情况下。&lt;h4&gt;主要发现&lt;/h4&gt;算法能够有效地解决在现实场景中存在的困难案例。&lt;h4&gt;结论&lt;/h4&gt;设计的算法提高了该选举模型在实际应用中的实用性。&lt;h4&gt;翻译&lt;/h4&gt;In a recently introduced model of successive committee elections (Brederecket al., AAAI-20) for a given set of ordinal or approval preferences one aims to find a sequence of a given length of "best" same-size committees such that each candidate is a member of a limited number of consecutive committees. However, the practical usability of this model remains limited, as the described task turns out to be NP-hard for most selection criteria already for seeking committees of size three. Non-trivial or somewhat efficient algorithms for these cases are lacking too. Motivated by a desire to unlock the full potential of the described temporal model of committee elections, we devise (parameterized) algorithms that effectively solve the mentioned hard cases in realistic scenarios of a moderate number of candidates or of a limited time horizon.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In a recently introduced model of successive committee elections (Brederecket al., AAAI-20) for a given set of ordinal or approval preferences one aims tofind a sequence of a given length of "best" same-size committees such that eachcandidate is a member of a limited number of consecutive committees. However,the practical usability of this model remains limited, as the described taskturns out to be NP-hard for most selection criteria already for seekingcommittees of size three. Non-trivial or somewhat efficient algorithms forthese cases are lacking too. Motivated by a desire to unlock the full potentialof the described temporal model of committee elections, we devise(parameterized) algorithms that effectively solve the mentioned hard cases inrealistic scenarios of a moderate number of candidates or of a limited timehorizon.</description>
      <author>example@mail.com (Pallavi Jain, Andrzej Kaczmarczyk)</author>
      <guid isPermaLink="false">2505.18287v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Domain and Task-Focused Example Selection for Data-Efficient Contrastive Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2505.19208v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个名为PolyCL的新型自监督对比学习框架，用于医学图像分割，通过利用不同图像之间的内在关系，以及结合Segment Anything Model（SAM）进行后处理和传播，实现了对有限标注数据的分割。&lt;h4&gt;背景&lt;/h4&gt;医学图像分割是医学影像流程中的关键任务，但需要大量手动标注的训练数据。手动标注过程昂贵、耗时且容易出错，限制了有效分割的实现。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够从有限标注数据中高效学习的自监督学习模型，以减少对大量手动标注数据的依赖。&lt;h4&gt;方法&lt;/h4&gt;提出了PolyCL框架，该框架不依赖于像素级标注或过度数据增强，从创新性替代物中学习并转移上下文感知判别特征。此外，将SAM作为后处理模块和传播机制集成到框架中。&lt;h4&gt;主要发现&lt;/h4&gt;在三个公开的CT数据集上的实验评估表明，PolyCL在低数据量和跨域场景中优于全监督和自监督基线。&lt;h4&gt;结论&lt;/h4&gt;PolyCL是一种有效的医学图像分割方法，能够从有限标注数据中学习，并在多种场景下优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：分割是医学影像流程中最重要任务之一，它影响着众多基于图像的决策。为了有效，完全监督的分割方法需要大量的手动标注训练数据。然而，像素级的标注过程既昂贵又耗时，且易出错，阻碍了进展并使其变得具有挑战性。因此，模型必须从有限的标注数据中高效地学习。自监督学习（SSL），尤其是通过在未标记数据上预训练并通过有限的标注进行微调的对比学习，可以促进这种有限的标注图像分割。为此，我们提出了一种新的自监督对比学习框架用于医学图像分割，利用不同图像的内在关系，称为PolyCL。不需要任何像素级标注或过度数据增强，我们的PolyCL以一种与任务相关的方式，从创新的替代品中学习和转移上下文感知判别特征。此外，我们将Segment Anything Model（SAM）以两种新颖的方式集成到我们的框架中：作为一个后处理精炼模块，使用来自粗略输出的边界框提示来提高预测掩码的准确性；以及作为一个通过SAM 2的传播机制，从单个标注的2D切片生成体部分割。在三个公开的计算机断层扫描（CT）数据集上的实验评估表明，PolyCL在低数据量和跨域场景中优于全监督和自监督基线。我们的代码可在https://github.com/tbwa233/PolyCL上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Segmentation is one of the most important tasks in the medical imagingpipeline as it influences a number of image-based decisions. To be effective,fully supervised segmentation approaches require large amounts of manuallyannotated training data. However, the pixel-level annotation process isexpensive, time-consuming, and error-prone, hindering progress and making itchallenging to perform effective segmentations. Therefore, models must learnefficiently from limited labeled data. Self-supervised learning (SSL),particularly contrastive learning via pre-training on unlabeled data andfine-tuning on limited annotations, can facilitate such limited labeled imagesegmentation. To this end, we propose a novel self-supervised contrastivelearning framework for medical image segmentation, leveraging inherentrelationships of different images, dubbed PolyCL. Without requiring anypixel-level annotations or unreasonable data augmentations, our PolyCL learnsand transfers context-aware discriminant features useful for segmentation froman innovative surrogate, in a task-related manner. Additionally, we integratethe Segment Anything Model (SAM) into our framework in two novel ways: as apost-processing refinement module that improves the accuracy of predicted masksusing bounding box prompts derived from coarse outputs, and as a propagationmechanism via SAM 2 that generates volumetric segmentations from a singleannotated 2D slice. Experimental evaluations on three public computedtomography (CT) datasets demonstrate that PolyCL outperforms fully-supervisedand self-supervised baselines in both low-data and cross-domain scenarios. Ourcode is available at https://github.com/tbwa233/PolyCL.</description>
      <author>example@mail.com (Tyler Ward, Aaron Moseley, Abdullah-Al-Zubaer Imran)</author>
      <guid isPermaLink="false">2505.19208v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model for Wireless Technology Recognition Using IQ Timeseries</title>
      <link>http://arxiv.org/abs/2505.19390v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer的基础模型，用于无线技术识别（WTR），该模型在大型无标签无线信号数据集上以无监督方式进行训练，能够有效识别不同采样率、捕获设备和频段的信号。&lt;h4&gt;背景&lt;/h4&gt;无线技术识别对于现代通信系统至关重要，它能够实现频谱的有效管理和多种技术的无缝共存。然而，传统的WTR方法在处理未见过的环境、不同的采样设备和信号类别时缺乏鲁棒性和适应性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够适应新无线技术和环境，且只需少量标记样本即可泛化的WTR模型。&lt;h4&gt;方法&lt;/h4&gt;该模型采用无监督预训练和轻量级微调的双阶段训练流程，利用输入补丁技术提高计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该模型在多种采样率和频段上实现了优越的准确性，同时保持了低计算复杂度。&lt;h4&gt;结论&lt;/h4&gt;该Transformer基础模型有望成为可重用的无线基础模型，能够适应新技术且最小化重新训练的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wireless Technology Recognition (WTR) is essential in modern communicationsystems, enabling efficient spectrum management and the seamless coexistence ofdiverse technologies. In real-world conditions, WTR solutions should be able tohandle signals from various resources with different sampling rates, capturingdevices, and frequency bands. However, traditional WTR methods, which rely onenergy detection, Convolutional Neural Network (CNN) models, or Deep Learning(DL), lack the robustness and adaptability required to generalize across unseenenvironments, different sampling devices, and previously unencountered signalclasses. In this work, we introduce a Transformer-based foundation model forWTR, trained in an unsupervised manner on large-scale, unlabeled wirelesssignal datasets. Foundation models are designed to learn general-purposerepresentations that transfer effectively across tasks and domains, allowinggeneralization towards new technologies and WTR sampling devices. Our approachleverages input patching for computational efficiency and incorporates atwo-stage training pipeline: unsupervised pre-training followed by lightweightfine-tuning. This enables the model to generalize to new wireless technologiesand environments using only a small number of labeled samples. Experimentalresults demonstrate that our model achieves superior accuracy across varyingsampling rates and frequency bands while maintaining low computationalcomplexity, supporting the vision of a reusable wireless foundation modeladaptable to new technologies with minimal retraining.</description>
      <author>example@mail.com (Mohammad Cheraghinia, Eli De Poorter, Jaron Fontaine, Merouane Debbah, Adnan Shahid)</author>
      <guid isPermaLink="false">2505.19390v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Convexified Message-Passing Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2505.18289v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Convexified Message Passing Graph Neural Networks (CGNNs)的新框架，它结合了消息传递GNNs的能力和凸优化的可处理性。CGNNs通过将非线性滤波器映射到再生核希尔伯特空间，将训练转化为凸优化问题，从而可以高效和优化地解决。实验结果表明，CGNNs在基准数据集上显著优于领先的GNN模型，准确率提高10%到40%，并具有强大的理论基础和广泛的适用性。&lt;h4&gt;背景&lt;/h4&gt;GNNs在图表示学习方面表现出色，但在处理凸优化问题时存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，将GNNs与凸优化相结合，以提高性能和可处理性。&lt;h4&gt;方法&lt;/h4&gt;引入CGNNs，通过映射非线性滤波器到再生核希尔伯特空间，将训练转化为凸优化问题，并使用投影梯度方法进行求解。&lt;h4&gt;主要发现&lt;/h4&gt;CGNNs在基准数据集上显著优于领先的GNN模型，准确率提高10%到40%，并具有强大的理论保证。CGNNs的凸性允许对统计性质进行准确和严格的分析。&lt;h4&gt;结论&lt;/h4&gt;CGNNs是一种强大的、原则性的方法，具有强大的理论基础和广泛的适用性。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs)已成为图表示学习的重要方法，在多种图预测任务上表现出强大的实证结果。在本文中，我们引入了Convexified Message Passing Graph Neural Networks (CGNNs)，这是一种新颖且通用的框架，它将消息传递GNNs的力量与凸优化的可处理性相结合。通过将它们的非线性滤波器映射到再生核希尔伯特空间，CGNNs将训练转化为凸优化问题，该问题可以通过投影梯度方法高效和优化地解决。这种凸性还进一步允许对CGNNs的统计性质进行准确和严格的分析。对于两层CGNNs，我们建立了严格的一般化保证，表明它们收敛到最优GNN的性能。为了扩展到更深的架构，我们采用了一种基于原则的层状训练策略。在基准数据集上的实验表明，CGNNs在大多数情况下显著优于领先的GNN模型，准确率提高了10%到40%，强调了它们作为具有强大理论基础和广泛适用性的强大且原则性方法的潜力。在很少的情况下，当改进不是定量实质性的，凸模型要么略微优于基线，要么与基线匹配，强调了它们的鲁棒性和广泛适用性。尽管在非凸模型中通常使用过参数化来增强性能，但我们表明我们的CGNNs框架产生了浅层凸模型，这些模型在准确率和资源效率方面都超过了这些模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have become prominent methods for graphrepresentation learning, demonstrating strong empirical results on diversegraph prediction tasks. In this paper, we introduce Convexified Message PassingGraph Neural Networks (CGNNs), a novel and general framework that combines thepower of message-passing GNNs with the tractability of convex optimization. Bymapping their nonlinear filters into a reproducing kernel Hilbert space, CGNNstransform training into a convex optimization problem, which can be solvedefficiently and optimally by projected gradient methods. This convexity furtherallows the statistical properties of CGNNs to be analyzed accurately andrigorously. For two-layer CGNNs, we establish rigorous generalizationguarantees, showing convergence to the performance of the optimal GNN. To scaleto deeper architectures, we adopt a principled layer-wise training strategy.Experiments on benchmark datasets show that CGNNs significantly exceed theperformance of leading GNN models, achieving 10 to 40 percent higher accuracyin most cases, underscoring their promise as a powerful and principled methodwith strong theoretical foundations. In rare cases where improvements are notquantitatively substantial, the convex models either slightly exceed or matchthe baselines, stressing their robustness and wide applicability. Thoughover-parameterization is often employed to enhance performance in nonconvexmodels, we show that our CGNNs framework yields shallow convex models that cansurpass these models in both accuracy and resource efficiency.</description>
      <author>example@mail.com (Saar Cohen, Noa Agmon, Uri Shaham)</author>
      <guid isPermaLink="false">2505.18289v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Latent Mamba Operator for Partial Differential Equations</title>
      <link>http://arxiv.org/abs/2505.19105v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of the 42 nd International Conference on Machine  Learning, Vancouver, Canada. PMLR 267, 2025. Copyright 2025 by the author(s)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Latent Mamba Operator (LaMO)的新方法，用于解决偏微分方程（PDEs），该方法在处理高维空间、降低计算成本以及捕捉PDE动态中的连续和长程依赖方面具有优势。&lt;h4&gt;背景&lt;/h4&gt;神经网络算子作为解决PDEs的数据驱动框架已显现其强大能力，但现有的神经网络算子在高维空间的可扩展性、计算成本以及捕捉PDE动态中的连续和长程依赖方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，论文旨在提出一种新的神经网络算子，以提高解决PDEs的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;LaMO结合了状态空间模型（SSMs）在潜在空间中的效率与神经网络算子核积分公式的表达能力，并在理论上建立了状态空间模型（SSMs）与神经网络算子核积分之间的联系。&lt;h4&gt;主要发现&lt;/h4&gt;在多个PDE基准测试中，LaMO在各种网格、结构化网格和点云数据集上实现了最先进的性能，相较于现有基线在解算子近似方面提高了32.3%，证明了其在模拟复杂PDE解方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;LaMO作为一种新型的神经网络算子，在解决PDEs方面展现出显著的优势，为处理高维空间和复杂PDE解提供了有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：神经网络算子已成为解决偏微分方程（PDEs）的强大数据驱动框架，在数值方法之上提供了显著的加速。然而，现有的神经网络算子在高维空间的可扩展性、计算成本以及捕捉PDE动态中的连续和长程依赖方面存在困难。为了解决这些限制，我们引入了潜在Mamba算子（LaMO），它将状态空间模型（SSMs）在潜在空间中的效率与神经网络算子核积分公式的表达能力相结合。我们还建立了状态空间模型（SSMs）与神经网络算子核积分之间的理论联系。在多种PDE基准测试中，包括规则网格、结构化网格和点云数据集的固体和流体物理数据集，LaMOs实现了最先进的性能，在解算子近似方面比现有基线提高了32.3%，突显了其在模拟复杂PDE解方面的功效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural operators have emerged as powerful data-driven frameworks for solvingPartial Differential Equations (PDEs), offering significant speedups overnumerical methods. However, existing neural operators struggle with scalabilityin high-dimensional spaces, incur high computational costs, and face challengesin capturing continuous and long-range dependencies in PDE dynamics. To addressthese limitations, we introduce the Latent Mamba Operator (LaMO), whichintegrates the efficiency of state-space models (SSMs) in latent space with theexpressive power of kernel integral formulations in neural operators. We alsoestablish a theoretical connection between state-space models (SSMs) and thekernel integral of neural operators. Extensive experiments across diverse PDEbenchmarks on regular grids, structured meshes, and point clouds covering solidand fluid physics datasets, LaMOs achieve consistent state-of-the-art (SOTA)performance, with a 32.3\% improvement over existing baselines in solutionoperator approximation, highlighting its efficacy in modeling complex PDEsolutions.</description>
      <author>example@mail.com (Karn Tiwari, Niladri Dutta, N M Anoop Krishnan, Prathosh A P)</author>
      <guid isPermaLink="false">2505.19105v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>BR-ASR: Efficient and Scalable Bias Retrieval Framework for Contextual Biasing ASR in Speech LLM</title>
      <link>http://arxiv.org/abs/2505.19179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by InterSpeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BR-ASR的偏置检索框架，用于大规模的上下文偏置，旨在解决大规模语音语言模型在自动语音识别（ASR）中对于命名实体和罕见词汇的上下文偏置问题。&lt;h4&gt;背景&lt;/h4&gt;尽管语音大语言模型（SpeechLLMs）在标准自动语音识别（ASR）方面取得了进步，但针对命名实体和罕见词汇的上下文偏置仍然是一个挑战，尤其是在大规模应用中。&lt;h4&gt;目的&lt;/h4&gt;旨在解决大规模上下文偏置的挑战，特别是对于命名实体和罕见词汇的识别问题。&lt;h4&gt;方法&lt;/h4&gt;提出了BR-ASR框架，包含两个创新：(1)语音和偏置对比学习以检索语义相关的候选词；(2)动态课程学习以减轻同音字混淆，这对最终性能有负面影响。该框架可以无缝集成到不同的ASR系统中，而无需微调。&lt;h4&gt;主要发现&lt;/h4&gt;在LibriSpeech测试集上，BR-ASR实现了2.8%/7.1%的偏置词错误率（B-WER），与2000个偏置词相比，相较于先前方法实现了45%的相对改进。同时，BR-ASR展示了高可扩展性：当将偏置列表扩展到200k时，相较于传统方法，它仅导致了0.3/2.9%的绝对词错误率（WER）/偏置词错误率（B-WER）下降，具有99.99%的剪枝率和每个查询20ms的延迟。&lt;h4&gt;结论&lt;/h4&gt;BR-ASR是一种有效的框架，能够提高大规模ASR系统的性能，特别是在处理命名实体和罕见词汇的上下文偏置方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While speech large language models (SpeechLLMs) have advanced standardautomatic speech recognition (ASR), contextual biasing for named entities andrare words remains challenging, especially at scale. To address this, wepropose BR-ASR: a Bias Retrieval framework for large-scale contextual biasing(up to 200k entries) via two innovations: (1) speech-and-bias contrastivelearning to retrieve semantically relevant candidates; (2) dynamic curriculumlearning that mitigates homophone confusion which negatively impacts the finalperformance. The is a general framework that allows seamless integration of theretrieved candidates into diverse ASR systems without fine-tuning. Experimentson LibriSpeech test-clean/-other achieve state-of-the-art (SOTA) biased worderror rates (B-WER) of 2.8%/7.1% with 2000 bias words, delivering 45% relativeimprovement over prior methods. BR-ASR also demonstrates high scalability: whenexpanding the bias list to 200k where traditional methods generally fail, itinduces only 0.3 / 2.9% absolute WER / B-WER degradation with a 99.99% pruningrate and only 20ms latency per query on test-other.</description>
      <author>example@mail.com (Xun Gong, Anqi Lv, Zhiming Wang, Huijia Zhu, Yanmin Qian)</author>
      <guid isPermaLink="false">2505.19179v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Less is More: Efficient Point Cloud Reconstruction via Multi-Head Decoders</title>
      <link>http://arxiv.org/abs/2505.19057v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文挑战了更深层的解码器架构总是能带来更好的点云重建性能的普遍假设，并提出了一个新型的多头解码器架构，通过多个独立头从点云的不同子集中重建完整形状，提高了重建的多样性和精确度。&lt;h4&gt;背景&lt;/h4&gt;普遍认为更深层的解码器架构在点云重建中总是能带来更好的性能。&lt;h4&gt;目的&lt;/h4&gt;研究解码器架构深度与点云重建性能之间的关系，并提出一种新的多头解码器架构。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新型的多头解码器架构，并通过在ModelNet40和ShapeNetPart上的实验来验证其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;发现超过一定深度后，增加解码器复杂性会导致过拟合和泛化能力下降；提出的多头解码器架构能够提高重建的多样性和精确度；在多个关键指标上（如Chamfer Distance、Hausdorff Distance、Earth Mover's Distance和F1-score）实现了性能提升，优于标准单头基线。&lt;h4&gt;结论&lt;/h4&gt;输出多样性和架构设计对于有效的点云重建可能比深度本身更为关键。&lt;h4&gt;翻译&lt;/h4&gt;本文挑战了更深层的解码器架构总是能带来更好的点云重建性能的普遍假设。我们的分析揭示，在超过一定深度后，增加解码器复杂性会导致过拟合和泛化能力下降。此外，我们提出了一种新颖的多头解码器架构，该架构通过从多个独立的头中重建完整形状来利用点云中的固有冗余，每个头操作一个不同的点子集。最终输出是通过连接所有头的预测得到的，增强了多样性和精确度。在ModelNet40和ShapeNetPart上的大量实验表明，我们的方法在关键指标上实现了持续改进，包括Chamfer距离（CD）、Hausdorff距离（HD）、地球迁移距离（EMD）和F1分数，优于标准的单头基线。我们的发现强调，输出多样性和架构设计对于有效和高效的点云重建可能比深度本身更为关键。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We challenge the common assumption that deeper decoder architectures alwaysyield better performance in point cloud reconstruction. Our analysis revealsthat, beyond a certain depth, increasing decoder complexity leads tooverfitting and degraded generalization. Additionally, we propose a novelmulti-head decoder architecture that exploits the inherent redundancy in pointclouds by reconstructing complete shapes from multiple independent heads, eachoperating on a distinct subset of points. The final output is obtained byconcatenating the predictions from all heads, enhancing both diversity andfidelity. Extensive experiments on ModelNet40 and ShapeNetPart demonstrate thatour approach achieves consistent improvements across key metrics--includingChamfer Distance (CD), Hausdorff Distance (HD), Earth Mover's Distance (EMD),and F1-score--outperforming standard single-head baselines. Our findingshighlight that output diversity and architectural design can be more criticalthan depth alone for effective and efficient point cloud reconstruction.</description>
      <author>example@mail.com (Pedro Alonso, Tianrui Li, Chongshou Li)</author>
      <guid isPermaLink="false">2505.19057v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Fast and Accurate Power Load Data Completion via Regularization-optimized Low-Rank Factorization</title>
      <link>http://arxiv.org/abs/2505.19133v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于低秩表示学习的电力负荷数据缺失值恢复方法，通过自适应调整正则化参数来优化低秩因子分解模型，提高了方法的适应性和计算效率。&lt;h4&gt;背景&lt;/h4&gt;低秩表示学习因其能够利用时空测量的内在低维结构，已成为恢复电力负荷数据缺失值的有力工具。低秩因子分解模型因其效率和可解释性而受到青睐，但其性能高度依赖于正则化参数的选择。&lt;h4&gt;目的&lt;/h4&gt;提出一种正则化优化的低秩因子分解方法，以改善现有方法的泛化能力和收敛速度。&lt;h4&gt;方法&lt;/h4&gt;引入比例-积分-微分控制器来自适应调整正则化系数，并对算法的复杂度进行了详细分析。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在保持随机梯度下降的计算效率的同时，提高了方法的适应性，实验结果表明，与现有基线相比，该方法在缺失值填充准确性和训练效率方面具有优势。&lt;h4&gt;结论&lt;/h4&gt;提出的正则化优化低秩因子分解方法在处理电力负荷数据缺失值恢复问题上表现出色，具有较高的实用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-rank representation learning has emerged as a powerful tool forrecovering missing values in power load data due to its ability to exploit theinherent low-dimensional structures of spatiotemporal measurements. Amongvarious techniques, low-rank factorization models are favoured for theirefficiency and interpretability. However, their performance is highly sensitiveto the choice of regularization parameters, which are typically fixed ormanually tuned, resulting in limited generalization capability or slowconvergence in practical scenarios. In this paper, we propose aRegularization-optimized Low-Rank Factorization, which introduces aProportional-Integral-Derivative controller to adaptively adjust theregularization coefficient. Furthermore, we provide a detailed algorithmiccomplexity analysis, showing that our method preserves the computationalefficiency of stochastic gradient descent while improving adaptivity.Experimental results on real-world power load datasets validate the superiorityof our method in both imputation accuracy and training efficiency compared toexisting baselines.</description>
      <author>example@mail.com (Yan Xia, Hao Feng, Hongwei Sun, Junjie Wang, Qicong Hu)</author>
      <guid isPermaLink="false">2505.19133v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>An Interpretable Representation Learning Approach for Diffusion Tensor Imaging</title>
      <link>http://arxiv.org/abs/2505.19110v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication at MIDL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的二维表示方法，用于Diffusion Tensor Imaging (DTI) 轨迹图，并使用深度学习模型进行处理，以提高大脑结构连接性的有效表示和解释。&lt;h4&gt;背景&lt;/h4&gt;DTI 轨迹图在研究大脑结构连接性方面提供了详细信息，但在深度学习模型中的有效表示和解释方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来处理 DTI 轨迹图，以便在深度学习模型中更有效地表示和解释大脑的结构连接性。&lt;h4&gt;方法&lt;/h4&gt;创建了一个将轨迹级别的FA值编码为9x9灰度图像的新二维表示，并通过Beta-Total Correlation Variational Autoencoder（带有空间广播解码器）来学习一个可分解和可解释的潜在嵌入。使用监督和未监督的表示学习策略，包括辅助分类、三元组损失和基于SimCLR的对比学习来评估嵌入的质量。&lt;h4&gt;主要发现&lt;/h4&gt;与1D Group深度神经网络（DNN）基线相比，该方法在下游性别分类任务中提高了15.74%的F1分数，并且比3D表示具有更好的可分解性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法在深度学习模型中提高了DTI轨迹图的处理效果，有助于更好地理解和分析大脑的结构连接性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于深度学习的Diffusion Tensor Imaging (DTI) 轨迹图的新型二维表示方法，通过将FA值编码为灰度图像，并利用变分自编码器学习潜在嵌入，显著提高了下游任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion Tensor Imaging (DTI) tractography offers detailed insights into thestructural connectivity of the brain, but presents challenges in effectiverepresentation and interpretation in deep learning models. In this work, wepropose a novel 2D representation of DTI tractography that encodes tract-levelfractional anisotropy (FA) values into a 9x9 grayscale image. Thisrepresentation is processed through a Beta-Total Correlation VariationalAutoencoder with a Spatial Broadcast Decoder to learn a disentangled andinterpretable latent embedding. We evaluate the quality of this embedding usingsupervised and unsupervised representation learning strategies, includingauxiliary classification, triplet loss, and SimCLR-based contrastive learning.Compared to the 1D Group deep neural network (DNN) baselines, our approachimproves the F1 score in a downstream sex classification task by 15.74% andshows a better disentanglement than the 3D representation.</description>
      <author>example@mail.com (Vishwa Mohan Singh, Alberto Gaston Villagran Asiares, Luisa Sophie Schuhmacher, Kate Rendall, Simon Weißbrod, David Rügamer, Inga Körte)</author>
      <guid isPermaLink="false">2505.19110v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>EnvSDD: Benchmarking Environmental Sound Deepfake Detection</title>
      <link>http://arxiv.org/abs/2505.19203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了音频生成系统在媒体制作中的应用及其潜在风险，提出了一种新的音频深度伪造检测系统。&lt;h4&gt;背景&lt;/h4&gt;现有的音频生成系统能够创建非常逼真的声音场景，但也可能存在深度伪造的风险。目前的研究主要集中在语音或歌唱声音的深度伪造检测，但对于环境声音的检测效果有限。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有环境声音深度伪造检测数据集规模和音频类型受限的问题，本文提出了一个名为EnvSDD的大规模数据集，并设计了一种基于预训练音频基础模型的深度伪造检测系统。&lt;h4&gt;方法&lt;/h4&gt;本文构建了包含45.25小时真实音频和316.74小时伪造音频的EnvSDD数据集，测试集包括多种条件以评估系统的泛化能力。同时，提出了一种基于预训练音频基础模型的深度伪造检测系统。&lt;h4&gt;主要发现&lt;/h4&gt;在EnvSDD数据集上的测试结果表明，本文提出的系统在性能上优于语音和歌唱领域的现有系统。&lt;h4&gt;结论&lt;/h4&gt;本文提出的EnvSDD数据集和基于预训练音频基础模型的深度伪造检测系统为环境声音的深度伪造检测提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Audio generation systems now create very realistic soundscapes that can enhance media production, but also pose potential risks. Several studies have examined deepfakes in speech or singing voice. However, environmental sounds have different characteristics, which may make methods for detecting speech and singing deepfakes less effective for real-world sounds. In addition, existing datasets for environmental sound deepfake detection are limited in scale and audio types. To address this gap, we introduce EnvSDD, the first large-scale curated dataset designed for this task, consisting of 45.25 hours of real and 316.74 hours of fake audio. The test set includes diverse conditions to evaluate the generalizability, such as unseen generation models and unseen datasets. We also propose an audio deepfake detection system, based on a pre-trained audio foundation model. Results on EnvSDD show that our proposed system outperforms the state-of-the-art systems from speech and singing domains.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio generation systems now create very realistic soundscapes that canenhance media production, but also pose potential risks. Several studies haveexamined deepfakes in speech or singing voice. However, environmental soundshave different characteristics, which may make methods for detecting speech andsinging deepfakes less effective for real-world sounds. In addition, existingdatasets for environmental sound deepfake detection are limited in scale andaudio types. To address this gap, we introduce EnvSDD, the first large-scalecurated dataset designed for this task, consisting of 45.25 hours of real and316.74 hours of fake audio. The test set includes diverse conditions toevaluate the generalizability, such as unseen generation models and unseendatasets. We also propose an audio deepfake detection system, based on apre-trained audio foundation model. Results on EnvSDD show that our proposedsystem outperforms the state-of-the-art systems from speech and singingdomains.</description>
      <author>example@mail.com (Han Yin, Yang Xiao, Rohan Kumar Das, Jisheng Bai, Haohe Liu, Wenwu Wang, Mark D Plumbley)</author>
      <guid isPermaLink="false">2505.19203v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Learn Beneficial Noise as Graph Augmentation</title>
      <link>http://arxiv.org/abs/2505.19024v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PiNGDA的图数据增强方法，旨在解决图对比学习（GCL）中图增强不稳定的问题。&lt;h4&gt;背景&lt;/h4&gt;尽管图对比学习（GCL）已被广泛研究，但生成有效且稳定的图增强仍然是一个挑战。现有的方法通常应用随机边删除等启发式增强，可能会破坏重要的图结构，导致GCL性能不稳定。&lt;h4&gt;目的&lt;/h4&gt;提出PiNGDA方法，通过科学分析噪声的有益效果，以及通过训练噪声生成器学习有益噪声，以增强图的拓扑结构和节点属性。&lt;h4&gt;方法&lt;/h4&gt;设计了一个高斯辅助变量来将损失函数转换为信息熵，通过学习有益噪声来生成图增强，而不是简单的估计。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，PiNGDA通过学习如何对图拓扑和节点属性产生有益扰动，从而更加可靠。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，PiNGDA在有效性和稳定性方面优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;尽管图对比学习（GCL）已经被广泛研究，但在生成有效且稳定的图增强方面仍然存在挑战。现有的方法通常采用诸如随机边删除之类的启发式增强，这可能会破坏重要的图结构，并导致GCL性能不稳定。在本文中，我们提出了一个名为PiNGDA的图数据增强方法，该方法通过科学分析信息理论下的噪声的有益效果，并通过可训练的噪声生成器学习有益噪声，在拓扑和属性上增强图。我们设计了一个高斯辅助变量来将损失函数转换为信息熵，并证明具有预定义增强的标准GCL等价于通过点估计估计有益噪声。在分析的基础上，PiNGDA通过训练噪声生成器从拓扑和属性两方面学习有益噪声，而不是简单的估计。由于生成器学习了如何对图拓扑和节点属性产生有益扰动，因此与现有方法相比，PiNGDA更加可靠。广泛的实验结果验证了PiNGDA的有效性和稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although graph contrastive learning (GCL) has been widely investigated, it isstill a challenge to generate effective and stable graph augmentations.Existing methods often apply heuristic augmentation like random edge dropping,which may disrupt important graph structures and result in unstable GCLperformance. In this paper, we propose Positive-incentive Noise driven GraphData Augmentation (PiNGDA), where positive-incentive noise (pi-noise)scientifically analyzes the beneficial effect of noise under the informationtheory. To bridge the standard GCL and pi-noise framework, we design a Gaussianauxiliary variable to convert the loss function to information entropy. Weprove that the standard GCL with pre-defined augmentations is equivalent toestimate the beneficial noise via the point estimation. Following our analysis,PiNGDA is derived from learning the beneficial noise on both topology andattributes through a trainable noise generator for graph augmentations, insteadof the simple estimation. Since the generator learns how to produce beneficialperturbations on graph topology and node attributes, PiNGDA is more reliablecompared with the existing methods. Extensive experimental results validate theeffectiveness and stability of PiNGDA.</description>
      <author>example@mail.com (Siqi Huang, Yanchen Xu, Hongyuan Zhang, Xuelong Li)</author>
      <guid isPermaLink="false">2505.19024v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>LLM-Guided Taxonomy and Hierarchical Uncertainty for 3D Point CLoud Active Learning</title>
      <link>http://arxiv.org/abs/2505.18924v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的主动学习框架，用于3D点云语义分割，首次将大型语言模型（LLMs）集成到构建层次化标签结构和引导基于不确定性的样本选择中。&lt;h4&gt;背景&lt;/h4&gt;传统的3D点云语义分割方法将标签视为平坦且独立的，而本文提出的方法利用LLMs提示自动生成多级语义分类，并引入了递归不确定性投影机制。&lt;h4&gt;目的&lt;/h4&gt;提高3D点云语义分割的准确率，尤其是在低标注预算情况下（如0.02%）。&lt;h4&gt;方法&lt;/h4&gt;采用LLMs构建层次化标签结构，并通过递归不确定性投影机制进行样本选择。&lt;h4&gt;主要发现&lt;/h4&gt;在S3DIS和ScanNet v2数据集上的实验表明，该方法在极低标注预算下（如0.02%）实现了高达4%的mIoU提升，显著优于现有基线。&lt;h4&gt;结论&lt;/h4&gt;LLMs在3D视觉中作为知识先验具有未被充分利用的潜力，并且层次化不确定性建模是一种有效的点云标注范式。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种用于3D点云语义分割的新主动学习框架，首次将大型语言模型（LLMs）集成到构建层次化标签结构和引导基于不确定性的样本选择中。与将标签视为平坦且独立的前期方法不同，我们的方法利用LLMs提示自动生成多级语义分类，并引入了递归不确定性投影机制，该机制在层次化级别间传播不确定性。这使得能够进行空间多样化的、标签感知的点选择，并尊重3D场景的固有语义结构。在S3DIS和ScanNet v2数据集上的实验表明，我们的方法在极低标注预算下（例如，0.02%）实现了高达4%的mIoU提升，显著优于现有基线。我们的结果突显了LLMs作为3D视觉中知识先验的未被充分利用的潜力，并确立了层次化不确定性建模作为有效点云标注范式的强大范式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel active learning framework for 3D point cloud semanticsegmentation that, for the first time, integrates large language models (LLMs)to construct hierarchical label structures and guide uncertainty-based sampleselection. Unlike prior methods that treat labels as flat and independent, ourapproach leverages LLM prompting to automatically generate multi-level semantictaxonomies and introduces a recursive uncertainty projection mechanism thatpropagates uncertainty across hierarchy levels. This enables spatially diverse,label-aware point selection that respects the inherent semantic structure of 3Dscenes. Experiments on S3DIS and ScanNet v2 show that our method achieves up to4% mIoU improvement under extremely low annotation budgets (e.g., 0.02%),substantially outperforming existing baselines. Our results highlight theuntapped potential of LLMs as knowledge priors in 3D vision and establishhierarchical uncertainty modeling as a powerful paradigm for efficient pointcloud annotation.</description>
      <author>example@mail.com (Chenxi Li, Nuo Chen, Fengyun Tan, Yantong Chen, Bochun Yuan, Tianrui Li, Chongshou Li)</author>
      <guid isPermaLink="false">2505.18924v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Machine Psychophysics: Cognitive Control in Vision-Language Models</title>
      <link>http://arxiv.org/abs/2505.18969v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文评估了108个视觉-语言模型在三种经典冲突任务及其更复杂的“平方”变体上的表现，发现模型性能与人类行为在资源受限情况下密切相关，并揭示了个体差异。&lt;h4&gt;背景&lt;/h4&gt;认知控制是指灵活协调思维和行动以追求内部目标的能力。&lt;h4&gt;目的&lt;/h4&gt;通过冲突任务评估认知控制，并检验视觉-语言模型在认知控制任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;在2200次试验中，对三种经典冲突任务及其“平方”变体进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;模型性能与人类行为在资源受限情况下密切相关，并揭示了个体差异。&lt;h4&gt;结论&lt;/h4&gt;当前的多模态基础模型中已经出现了类似于人类执行功能的形式。&lt;h4&gt;翻译&lt;/h4&gt;摘要：认知控制是指灵活协调思维和行动以追求内部目标的能力。评估认知控制的标准方法涉及对比一致和不一致试验的冲突任务，测量优先考虑相关信息并抑制干扰的能力。我们对108个视觉-语言模型在三种经典冲突任务及其更复杂的“平方”变体上的表现进行了评估，共有2200次试验。模型性能与人类行为在资源受限情况下密切相关，并揭示了个体差异。这些结果表明，当前的多模态基础模型中已经出现了类似于人类执行功能的形式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cognitive control refers to the ability to flexibly coordinate thought andaction in pursuit of internal goals. A standard method for assessing cognitivecontrol involves conflict tasks that contrast congruent and incongruent trials,measuring the ability to prioritize relevant information while suppressinginterference. We evaluate 108 vision-language models on three classic conflicttasks and their more demanding "squared" variants across 2,220 trials. Modelperformance corresponds closely to human behavior under resource constraintsand reveals individual differences. These results indicate that some form ofhuman-like executive function have emerged in current multi-modal foundationalmodels.</description>
      <author>example@mail.com (Dezhi Luo, Maijunxian Wang, Bingyang Wang, Tianwei Zhao, Yijiang Li, Hokin Deng)</author>
      <guid isPermaLink="false">2505.18969v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>YOPO-Rally: A Sim-to-Real Single-Stage Planner for Off-Road Terrain</title>
      <link>http://arxiv.org/abs/2505.18714v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种扩展的YOPO端到端导航框架，用于越野环境，特别是森林地形，并进行了仿真和真实世界的实验来验证其性能。&lt;h4&gt;背景&lt;/h4&gt;越野导航对自主机器人来说是一个挑战，因为崎岖的地形和密集的障碍物。&lt;h4&gt;目的&lt;/h4&gt;将YOPO导航框架扩展到越野环境，特别是森林地形。&lt;h4&gt;方法&lt;/h4&gt;构建了一个高性能的多传感器支持的越野模拟器YOPO-Sim，一个零样本仿真到现实规划器YOPO-Rally，以及一个MPC控制器。模拟器基于Unity引擎，可以生成随机的森林环境并导出深度图像和点云图。使用地形可通行性分析(TTA)处理成本图，生成专家轨迹，并将其与路径寻找集成到一个神经网络中，该网络输入深度图像、当前速度和目标向量，输出多个轨迹候选方案及其成本。规划器在模拟器中通过行为克隆进行训练，直接部署到现实世界而不需要微调。&lt;h4&gt;主要发现&lt;/h4&gt;YOPO-Sim模拟器可以提供与主流模拟器相竞争的性能，规划器能够生成具有成本的多条轨迹候选方案，且不需要在现实世界中进行微调。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架在模拟和真实世界的实验中验证了其性能。&lt;h4&gt;翻译&lt;/h4&gt;越野导航对自主机器人来说仍然是一个挑战，因为恶劣的地形和密集的障碍物。在这封信中，我们将YOPO（你只计划一次）端到端导航框架扩展到越野环境，明确关注森林地形，包括高性能的多传感器支持的越野模拟器YOPO-Sim、零样本仿真到现实规划器YOPO-Rally和MPC控制器。该模拟器基于Unity引擎，可以生成随机的森林环境并导出深度图像和点云图以供专家演示，与主流模拟器提供具有竞争力的性能。地形可通行性分析（TTA）处理成本图，生成以非均匀三次Hermite曲线表示的专家轨迹。规划器将TTA和路径寻找集成到一个单一的神经网络中，该网络输入深度图像、当前速度和目标向量，并输出具有成本的多个轨迹候选方案。规划器在模拟器中通过行为克隆进行训练，直接部署到现实世界而无需微调。最后，进行了一系列模拟和真实世界的实验，以验证所提出框架的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Off-road navigation remains challenging for autonomous robots due to theharsh terrain and clustered obstacles. In this letter, we extend the YOPO (YouOnly Plan Once) end-to-end navigation framework to off-road environments,explicitly focusing on forest terrains, consisting of a high-performance,multi-sensor supported off-road simulator YOPO-Sim, a zero-shot transfersim-to-real planner YOPO-Rally, and an MPC controller. Built on the Unityengine, the simulator can generate randomized forest environments and exportdepth images and point cloud maps for expert demonstrations, providingcompetitive performance with mainstream simulators. Terrain TraversabilityAnalysis (TTA) processes cost maps, generating expert trajectories representedas non-uniform cubic Hermite curves. The planner integrates TTA and thepathfinding into a single neural network that inputs the depth image, currentvelocity, and the goal vector, and outputs multiple trajectory candidates withcosts. The planner is trained by behavior cloning in the simulator and deployeddirectly into the real-world without fine-tuning. Finally, a series ofsimulated and real-world experiments is conducted to validate the performanceof the proposed framework.</description>
      <author>example@mail.com (Hongyu Cao, Junjie Lu, Xuewei Zhang, Yulin Hui, Zhiyu Li, Bailing Tian)</author>
      <guid isPermaLink="false">2505.18714v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>WeedNet: A Foundation Model-Based Global-to-Local AI Approach for Real-Time Weed Species Identification and Classification</title>
      <link>http://arxiv.org/abs/2505.18930v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了WeedNet，一个全球规模的杂草识别模型，能够识别多种杂草物种，包括有害和入侵植物。WeedNet利用自监督学习、微调和增强可信度策略，在多个杂草物种上实现了高准确率，并且具有可推广性和适应性。&lt;h4&gt;背景&lt;/h4&gt;早期杂草识别对于有效管理和控制杂草至关重要，同时使用计算机视觉技术和人工智能方法自动化这一过程越来越受到关注。&lt;h4&gt;目的&lt;/h4&gt;为了解决训练基于AI的杂草识别模型时遇到的挑战，如专家验证数据的有限性以及形态特征的复杂性和多样性，开发了一个新的杂草识别模型WeedNet。&lt;h4&gt;方法&lt;/h4&gt;WeedNet使用了自监督学习、微调和增强可信度策略，通过在1,593种杂草物种上进行测试，实现了91.02%的准确率。同时，使用微调和全局到局部的方法，对爱荷华州的杂草进行了特定地区的微调，实现了97.38%的整体准确率。&lt;h4&gt;主要发现&lt;/h4&gt;WeedNet在多个杂草物种上表现良好，特别是在爱荷华州的本地测试中取得了97.38%的准确率。此外，模型的多样性和适应性使其能够作为基础模型在不同地区进行微调。&lt;h4&gt;结论&lt;/h4&gt;WeedNet为杂草识别提供了一种高效且准确的方法，具有广泛的适用性和潜在的实用价值，可用于农业和生态保护咨询工具。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为WeedNet的全球规模杂草识别模型，能够识别多种杂草物种，包括有害和入侵植物。该模型通过自监督学习、微调和增强可信度策略，在多个杂草物种上实现了高准确率。WeedNet具有可推广性和适应性，可以在不同地区进行特定区域的微调。模型在爱荷华州的本地测试中取得了97.38%的准确率，显示出其作为基础模型在特定地区的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early identification of weeds is essential for effective management andcontrol, and there is growing interest in automating the process using computervision techniques coupled with AI methods. However, challenges associated withtraining AI-based weed identification models, such as limited expert-verifieddata and complexity and variability in morphological features, have hinderedprogress. To address these issues, we present WeedNet, the first global-scaleweed identification model capable of recognizing an extensive set of weedspecies, including noxious and invasive plant species. WeedNet is an end-to-endreal-time weed identification pipeline and uses self-supervised learning,fine-tuning, and enhanced trustworthiness strategies. WeedNet achieved 91.02%accuracy across 1,593 weed species, with 41% species achieving 100% accuracy.Using a fine-tuning strategy and a Global-to-Local approach, the local IowaWeedNet model achieved an overall accuracy of 97.38% for 85 Iowa weeds, mostclasses exceeded a 90% mean accuracy per class. Testing across intra-speciesdissimilarity (developmental stages) and inter-species similarity (look-alikespecies) suggests that diversity in the images collected, spanning all thegrowth stages and distinguishable plant characteristics, is crucial in drivingmodel performance. The generalizability and adaptability of the Global WeedNetmodel enable it to function as a foundational model, with the Global-to-Localstrategy allowing fine-tuning for region-specific weed communities. Additionalvalidation of drone- and ground-rover-based images highlights the potential ofWeedNet for integration into robotic platforms. Furthermore, integration withAI for conversational use provides intelligent agricultural and ecologicalconservation consulting tools for farmers, agronomists, researchers, landmanagers, and government agencies across diverse landscapes.</description>
      <author>example@mail.com (Yanben Shen, Timilehin T. Ayanlade, Venkata Naresh Boddepalli, Mojdeh Saadati, Ashlyn Rairdin, Zi K. Deng, Muhammad Arbab Arshad, Aditya Balu, Daren Mueller, Asheesh K Singh, Wesley Everman, Nirav Merchant, Baskar Ganapathysubramanian, Meaghan Anderson, Soumik Sarkar, Arti Singh)</author>
      <guid isPermaLink="false">2505.18930v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>AmorLIP: Efficient Language-Image Pretraining via Amortization</title>
      <link>http://arxiv.org/abs/2505.18983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;AmorLIP是一种高效的CLIP预训练框架，通过轻量级神经网络分摊对比学习中的昂贵计算，显著提高了训练效率和性能。&lt;h4&gt;背景&lt;/h4&gt;现有的CLIP方法通常使用来自每个minibatch的负样本来优化对比目标，这需要极大的批处理大小和数百甚至数千个GPU，导致计算需求增加。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些限制，提出AmorLIP，以实现鲁棒的表现学习，提高训练效率和性能。&lt;h4&gt;方法&lt;/h4&gt;AmorLIP通过轻量级神经网络分摊对比学习中的昂贵计算，并利用能量模型的频谱分解引入新的分摊目标，以及实用的技术来提高训练稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;在38个下游任务上的实验表明，AmorLIP在零样本分类和检索能力方面优于标准的CLIP基线，相对改进高达12.24%。&lt;h4&gt;结论&lt;/h4&gt;AmorLIP在零样本分类和检索任务中表现出色，是一种有效的CLIP预训练框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive Language-Image Pretraining (CLIP) has demonstrated strongzero-shot performance across diverse downstream text-image tasks. Existing CLIPmethods typically optimize a contrastive objective using negative samples drawnfrom each minibatch. To achieve robust representation learning, these methodsrequire extremely large batch sizes and escalate computational demands tohundreds or even thousands of GPUs. Prior approaches to mitigate this issueoften compromise downstream performance, prolong training duration, or facescalability challenges with very large datasets. To overcome these limitations,we propose AmorLIP, an efficient CLIP pretraining framework that amortizesexpensive computations involved in contrastive learning through lightweightneural networks, which substantially improves training efficiency andperformance. Leveraging insights from a spectral factorization of energy-basedmodels, we introduce novel amortization objectives along with practicaltechniques to improve training stability. Extensive experiments across 38downstream tasks demonstrate the superior zero-shot classification andretrieval capabilities of AmorLIP, consistently outperforming standard CLIPbaselines with substantial relative improvements of up to 12.24%.</description>
      <author>example@mail.com (Haotian Sun, Yitong Li, Yuchen Zhuang, Niao He, Hanjun Dai, Bo Dai)</author>
      <guid isPermaLink="false">2505.18983v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Canonical Policy: Learning Canonical 3D Representation for Equivariant Policy</title>
      <link>http://arxiv.org/abs/2505.18474v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了在机器人操作中，视觉模仿学习取得了显著进展，但将学习推广到未见过的物体、场景布局和摄像机视角仍然是一个关键挑战。&lt;h4&gt;背景&lt;/h4&gt;尽管使用了3D点云，它提供了几何感知和外观不变的表达，并通过将等变性纳入策略架构来利用空间对称性，但现有的等变性方法由于等变性组件的无结构集成，通常缺乏可解释性和严谨性。&lt;h4&gt;目的&lt;/h4&gt;提出了一种称为规范策略的原理性框架，用于3D等变性模仿学习，该框架统一了3D点云观察结果在规范表示下。&lt;h4&gt;方法&lt;/h4&gt;首先建立了一个3D规范表示的理论，通过将分布内和分布外的点云分组到规范表示，实现等变性观察到动作的映射。然后提出了一种灵活的策略学习流程，利用规范表示中的几何对称性和现代生成模型的表达能力。&lt;h4&gt;主要发现&lt;/h4&gt;在12个不同的模拟任务和4个现实世界的操作任务上验证了规范策略，涉及物体颜色、形状、摄像机视角和机器人平台的变体。与最先进的模仿学习策略相比，规范策略在模拟中平均提高了18.0%，在现实世界实验中提高了37.6%，显示出优越的泛化能力和样本效率。&lt;h4&gt;结论&lt;/h4&gt;规范策略在模仿学习中具有更好的泛化能力和样本效率，是解决视觉模仿学习挑战的有效方法。&lt;h4&gt;翻译&lt;/h4&gt;Visual Imitation learning has achieved remarkable progress in robotic manipulation, yet generalization to unseen objects, scene layouts, and camera viewpoints remains a key challenge. Recent advances address this by using 3D point clouds, which provide geometry-aware, appearance-invariant representations, and by incorporating equivariance into policy architectures to exploit spatial symmetries. However, existing equivariant approaches often lack interpretability and rigor due to unstructured integration of equivariant components. We introduce canonical policy, a principled framework for 3D equivariant imitation learning that unifies 3D point cloud observations under a canonical representation. We first establish a theory of 3D canonical representations, enabling equivariant observation-to-action mappings by grouping both in-distribution and out-of-distribution point clouds to a canonical representation. We then propose a flexible policy learning pipeline that leverages geometric symmetries from canonical representation and the expressiveness of modern generative models. We validate canonical policy on 12 diverse simulated tasks and 4 real-world manipulation tasks across 16 configurations, involving variations in object color, shape, camera viewpoint, and robot platform. Compared to state-of-the-art imitation learning policies, canonical policy achieves an average improvement of 18.0% in simulation and 37.6% in real-world experiments, demonstrating superior generalization capability and sample efficiency. For more details, please refer to the project website: https://zhangzhiyuanzhang.github.io/cp-website/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Imitation learning has achieved remarkable progress in roboticmanipulation, yet generalization to unseen objects, scene layouts, and cameraviewpoints remains a key challenge. Recent advances address this by using 3Dpoint clouds, which provide geometry-aware, appearance-invariantrepresentations, and by incorporating equivariance into policy architectures toexploit spatial symmetries. However, existing equivariant approaches often lackinterpretability and rigor due to unstructured integration of equivariantcomponents. We introduce canonical policy, a principled framework for 3Dequivariant imitation learning that unifies 3D point cloud observations under acanonical representation. We first establish a theory of 3D canonicalrepresentations, enabling equivariant observation-to-action mappings bygrouping both in-distribution and out-of-distribution point clouds to acanonical representation. We then propose a flexible policy learning pipelinethat leverages geometric symmetries from canonical representation and theexpressiveness of modern generative models. We validate canonical policy on 12diverse simulated tasks and 4 real-world manipulation tasks across 16configurations, involving variations in object color, shape, camera viewpoint,and robot platform. Compared to state-of-the-art imitation learning policies,canonical policy achieves an average improvement of 18.0% in simulation and37.6% in real-world experiments, demonstrating superior generalizationcapability and sample efficiency. For more details, please refer to the projectwebsite: https://zhangzhiyuanzhang.github.io/cp-website/.</description>
      <author>example@mail.com (Zhiyuan Zhang, Zhengtong Xu, Jai Nanda Lakamsani, Yu She)</author>
      <guid isPermaLink="false">2505.18474v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>SD-OVON: A Semantics-aware Dataset and Benchmark Generation Pipeline for Open-Vocabulary Object Navigation in Dynamic Scenes</title>
      <link>http://arxiv.org/abs/2505.18881v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. 21 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SD-OVON的语义感知数据集和基准生成流程，用于动态场景中的开放词汇物体导航。&lt;h4&gt;背景&lt;/h4&gt;当前的数据集往往局限于静态环境，而SD-OVON涵盖了动态场景和可操作物体。&lt;h4&gt;目的&lt;/h4&gt;提高导航任务的 realism，并促进开放词汇物体导航代理在复杂环境中的训练和评估。&lt;h4&gt;方法&lt;/h4&gt;使用预训练的多模态基础模型生成符合现实语义和日常常识的无限独特的照片级场景变体。提供与Habitat模拟器兼容的对象导航任务场景生成插件。并提供了两个预生成的对象导航任务数据集SD-OVON-3k和SD-OVON-10k。&lt;h4&gt;主要发现&lt;/h4&gt;SD-OVON包括约3k和10k个开放词汇物体导航任务场景，分别来源于包含2.5k个现实环境照片级扫描的SD-OVON-Scenes数据集和包含0.9k个手动检查和艺术家创建的可操作物体模型的数据集SD-OVON-Objects。&lt;h4&gt;结论&lt;/h4&gt;该方法增强了导航任务的 realism，并在SD-OVON-3k上评估了两个基线，证明了流程和数据集的有效性。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一个名为SD-OVON的用于动态场景中开放词汇物体导航的语义感知数据集和基准生成流程。它利用预训练的多模态基础模型生成无限独特的照片级场景变体，这些场景符合现实世界的语义和日常常识，用于导航代理的训练和评估。此外，我们还提供了一个用于生成与Habitat模拟器兼容的对象导航任务场景的插件。我们还提供了两个预生成的对象导航任务数据集，SD-OVON-3k和SD-OVON-10k，分别包含约3k和10k个开放词汇物体导航任务场景，这些场景来源于包含2.5k个现实环境照片级扫描的SD-OVON-Scenes数据集和包含0.9k个手动检查和艺术家创建的可操作物体模型的SD-OVON-Objects数据集。与仅限于静态环境的前期数据集不同，SD-OVON涵盖了动态场景和可操作物体，促进了从现实到模拟和从模拟到现实的机器人应用。这种方法增强了导航任务的 realism，并在SD-OVON-3k上评估了两个基线，证明了流程和数据集的有效性。数据集、基准和源代码是公开可用的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present the Semantics-aware Dataset and Benchmark Generation Pipeline forOpen-vocabulary Object Navigation in Dynamic Scenes (SD-OVON). It utilizespretraining multimodal foundation models to generate infinite uniquephoto-realistic scene variants that adhere to real-world semantics and dailycommonsense for the training and the evaluation of navigation agents,accompanied with a plugin for generating object navigation task episodescompatible to the Habitat simulator. In addition, we offer two pre-generatedobject navigation task datasets, SD-OVON-3k and SD-OVON-10k, comprisingrespectively about 3k and 10k episodes of the open-vocabulary object navigationtask, derived from the SD-OVON-Scenes dataset with 2.5k photo-realistic scansof real-world environments and the SD-OVON-Objects dataset with 0.9k manuallyinspected scanned and artist-created manipulatable object models. Unlike priordatasets limited to static environments, SD-OVON covers dynamic scenes andmanipulatable objects, facilitating both real-to-sim and sim-to-real roboticapplications. This approach enhances the realism of navigation tasks, thetraining and the evaluation of open-vocabulary object navigation agents incomplex settings. To demonstrate the effectiveness of our pipeline anddatasets, we propose two baselines and evaluate them along withstate-of-the-art baselines on SD-OVON-3k. The datasets, benchmark and sourcecode are publicly available.</description>
      <author>example@mail.com (Dicong Qiu, Jiadi You, Zeying Gong, Ronghe Qiu, Hui Xiong, Junwei Liang)</author>
      <guid isPermaLink="false">2505.18881v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Evidence-Grounded Multimodal Misinformation Detection with Attention-Based GNNs</title>
      <link>http://arxiv.org/abs/2505.18221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于图的方法来检测跨模态的情境外虚假信息，该方法通过构建证据图和断言图来评估图像和标题之间的一致性。&lt;h4&gt;背景&lt;/h4&gt;检测跨模态的情境外虚假信息具有挑战性，因为需要先解决断言的上下文，然后再检查是否存在虚假信息。现有的许多方法，包括大型语言模型（LLMs）和低资源语言模型（LVLMs），都没有执行这一上下文化步骤。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于图的方法，用于评估图像和标题之间的一致性，以检测虚假信息。&lt;h4&gt;方法&lt;/h4&gt;构建了两个图表示：一个是从在线文本证据中导出的证据图，另一个是从标题中的断言中得到的断言图。使用图神经网络（GNNs）对这些表示进行编码和比较，然后评估图像-标题对的真伪。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在评估集上的检测准确率为93.05%，并且比第二好的方法（一个LLM）高出2.82%，表明了更小、更特定于任务的模型的优势。&lt;h4&gt;结论&lt;/h4&gt;该方法在虚假信息检测任务中表现出色，证明了基于图的方法在检测跨模态情境外虚假信息方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal out-of-context (OOC) misinformation is misinformation thatrepurposes real images with unrelated or misleading captions. Detecting suchmisinformation is challenging because it requires resolving the context of theclaim before checking for misinformation. Many current methods, including LLMsand LVLMs, do not perform this contextualization step. LLMs hallucinate inabsence of context or parametric knowledge. In this work, we propose agraph-based method that evaluates the consistency between the image and thecaption by constructing two graph representations: an evidence graph, derivedfrom online textual evidence, and a claim graph, from the claim in the caption.Using graph neural networks (GNNs) to encode and compare these representations,our framework then evaluates the truthfulness of image-caption pairs. We createdatasets for our graph-based method, evaluate and compare our baseline modelagainst popular LLMs on the misinformation detection task. Our method scores$93.05\%$ detection accuracy on the evaluation set and outperforms thesecond-best performing method (an LLM) by $2.82\%$, making a case for smallerand task-specific methods.</description>
      <author>example@mail.com (Sharad Duwal, Mir Nafis Sharear Shopnil, Abhishek Tyagi, Adiba Mahbub Proma)</author>
      <guid isPermaLink="false">2505.18221v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>ImLPR: Image-based LiDAR Place Recognition using Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2505.18364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report, 22 Pages, 13 Figures and 12 Tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ImLPR的新颖的LiDAR Place Recognition (LPR)方法，该方法利用预训练的DINOv2 Vision Foundation Model (VFM)来生成丰富的描述符，以提升LPR的性能。&lt;h4&gt;背景&lt;/h4&gt;LiDAR Place Recognition是机器人定位的关键组成部分，而Visual Place Recognition（VPR）已经采用了Vision Foundation Models（VFMs）来增强描述符的鲁棒性。然而，LPR主要依赖特定任务的模型，且很少使用预训练的基础知识，这主要是因为缺乏3D基础模型和将VFM应用于LiDAR点云的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出ImLPR方法，以解决上述挑战，提升LPR的性能。&lt;h4&gt;方法&lt;/h4&gt;ImLPR将原始点云转换为Range Image Views（RIV），以便在LiDAR领域利用VFM。它使用MultiConv适配器和Patch-InfoNCE损失来实现有效的特征学习。&lt;h4&gt;主要发现&lt;/h4&gt;ImLPR在公开数据集上的验证表明，其在会话内和会话间LPR任务中优于现有方法，取得了最高的Recall@1和F1分数。此外，RIV作为LiDAR适应VFM的表示选择优于Bird's-Eye-View（BEV）。&lt;h4&gt;结论&lt;/h4&gt;ImLPR作为开源项目发布，为机器人社区提供了一种新的LPR方法。&lt;h4&gt;翻译&lt;/h4&gt;LiDAR Place Recognition (LPR) 是机器人定位的关键组件，它使得机器人能够将当前的扫描与先前环境地图对齐。尽管视觉位置识别（VPR）已经采用视觉基础模型（VFMs）来增强描述符的鲁棒性，但LPR依赖于特定任务的模型，并且很少使用预训练的基础知识。这是由于缺乏3D基础模型和将VFM用于LiDAR点云的挑战。为了解决这个问题，我们引入了ImLPR，这是一种新的流程，它使用预训练的DINOv2 VFM为LPR生成丰富的描述符。据我们所知，ImLPR是第一个利用VFM来支持LPR的方法。ImLPR将原始点云转换为范围图像视图（RIV），以便在LiDAR领域利用VFM。它采用MultiConv适配器和Patch-InfoNCE损失来实现有效的特征学习。我们使用公开数据集验证了ImLPR，它在会话内和会话间的LPR任务中优于最先进（SOTA）方法，在各个LiDAR上取得了最高的Recall@1和F1分数。我们还证明了RIV作为适应LiDAR的表示选择优于鸟瞰图（BEV）。我们将ImLPR作为开源项目发布，供机器人社区使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR Place Recognition (LPR) is a key component in robotic localization,enabling robots to align current scans with prior maps of their environment.While Visual Place Recognition (VPR) has embraced Vision Foundation Models(VFMs) to enhance descriptor robustness, LPR has relied on task-specific modelswith limited use of pre-trained foundation-level knowledge. This is due to thelack of 3D foundation models and the challenges of using VFM with LiDAR pointclouds. To tackle this, we introduce ImLPR, a novel pipeline that employs apre-trained DINOv2 VFM to generate rich descriptors for LPR. To our knowledge,ImLPR is the first method to leverage a VFM to support LPR. ImLPR converts rawpoint clouds into Range Image Views (RIV) to leverage VFM in the LiDAR domain.It employs MultiConv adapters and Patch-InfoNCE loss for effective featurelearning. We validate ImLPR using public datasets where it outperformsstate-of-the-art (SOTA) methods in intra-session and inter-session LPR with topRecall@1 and F1 scores across various LiDARs. We also demonstrate that RIVoutperforms Bird's-Eye-View (BEV) as a representation choice for adapting LiDARfor VFM. We release ImLPR as open source for the robotics community.</description>
      <author>example@mail.com (Minwoo Jung, Lanke Frank Tarimo Fu, Maurice Fallon, Ayoung Kim)</author>
      <guid isPermaLink="false">2505.18364v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Context-Driven Dynamic Pruning for Large Speech Foundation Models</title>
      <link>http://arxiv.org/abs/2505.18860v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为“上下文驱动动态剪枝”的技术，旨在优化语音基础模型的计算，减少计算资源需求，同时提高性能。&lt;h4&gt;背景&lt;/h4&gt;语音基础模型在语言和声学条件下具有强大的泛化能力，但推理时需要大量的计算资源。&lt;h4&gt;目的&lt;/h4&gt;通过动态优化模型结构，根据目标音频和外部上下文来减少模型计算资源。&lt;h4&gt;方法&lt;/h4&gt;使用Open Whisper-style Speech Model (OWSM)作为基准，并引入说话人嵌入、声学事件嵌入和语言信息作为额外的上下文。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过引入说话人嵌入，相比完全微调的OWSM模型，在减少56.7 GFLOPs的同时，BLEU分数提高了25.7%。&lt;h4&gt;结论&lt;/h4&gt;上下文驱动动态剪枝技术能够有效优化语音基础模型的计算，同时提升模型性能。&lt;h4&gt;翻译&lt;/h4&gt;The study proposes a technique called 'context-driven dynamic pruning' that aims to optimize the computation of speech foundation models, reducing the required computational resources while improving performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech foundation models achieve strong generalization across languages andacoustic conditions, but require significant computational resources forinference. In the context of speech foundation models, pruning techniques havebeen studied that dynamically optimize model structures based on the targetaudio leveraging external context. In this work, we extend this line ofresearch and propose context-driven dynamic pruning, a technique that optimizesthe model computation depending on the context between different input framesand additional context during inference. We employ the Open Whisper-styleSpeech Model (OWSM) and incorporate speaker embeddings, acoustic eventembeddings, and language information as additional context. By incorporatingthe speaker embedding, our method achieves a reduction of 56.7 GFLOPs whileimproving BLEU scores by a relative 25.7% compared to the fully fine-tuned OWSMmodel.</description>
      <author>example@mail.com (Masao Someki, Shikhar Bharadwaj, Atharva Anand Joshi, Chyi-Jiunn Lin, Jinchuan Tian, Jee-weon Jung, Markus Müller, Nathan Susanj, Jing Liu, Shinji Watanabe)</author>
      <guid isPermaLink="false">2505.18860v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Reward-Driven Interaction: Enhancing Proactive Dialogue Agents through User Satisfaction Prediction</title>
      <link>http://arxiv.org/abs/2505.18731v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的用户满意度估计方法，用于奖励驱动的主动对话代理，以确定最佳交互策略。&lt;h4&gt;背景&lt;/h4&gt;当前奖励驱动的主动对话代理需要精确的用户满意度估计作为内在奖励信号。&lt;h4&gt;目的&lt;/h4&gt;针对传统方法在真实场景中的局限性，提出两种辅助任务来提高用户话语和会话的表示学习，从而增强用户满意度预测。&lt;h4&gt;方法&lt;/h4&gt;提出了一种对比自监督学习任务和一种领域意图分类任务，分别帮助模型学习稀有用户话语的表示和识别ASR错误，以及从长尾领域学习用户会话的表示并提高模型在这些领域的性能。&lt;h4&gt;主要发现&lt;/h4&gt;在DuerOS上的评估表明，该方法在识别稀有用户话语和长尾领域的错误识别准确性方面有显著提高。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地解决了噪声奖励监督和长尾反馈稀疏性问题，提高了用户满意度预测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reward-driven proactive dialogue agents require precise estimation of usersatisfaction as an intrinsic reward signal to determine optimal interactionstrategies. Specifically, this framework triggers clarification questions whendetecting potential user dissatisfaction during interactions in the industrialdialogue system. Traditional works typically rely on training a neural networkmodel based on weak labels which are generated by a simple model trained onuser actions after current turn. However, existing methods suffer from twocritical limitations in real-world scenarios: (1) Noisy Reward Supervision,dependence on weak labels derived from post-hoc user actions introduces bias,particularly failing to capture satisfaction signals in ASR-error-inducedutterances; (2) Long-Tail Feedback Sparsity, the power-law distribution of userqueries causes reward prediction accuracy to drop in low-frequency domains. Thenoise in the weak labels and a power-law distribution of user utterancesresults in that the model is hard to learn good representation of userutterances and sessions. To address these limitations, we propose two auxiliarytasks to improve the representation learning of user utterances and sessionsthat enhance user satisfaction prediction. The first one is a contrastiveself-supervised learning task, which helps the model learn the representationof rare user utterances and identify ASR errors. The second one is adomain-intent classification task, which aids the model in learning therepresentation of user sessions from long-tailed domains and improving themodel's performance on such domains. The proposed method is evaluated onDuerOS, demonstrating significant improvements in the accuracy of errorrecognition on rare user utterances and long-tailed domains.</description>
      <author>example@mail.com (Wei Shen, Xiaonan He, Chuheng Zhang, Xuyun Zhang, Xiaolong Xu, Wanchun Dou)</author>
      <guid isPermaLink="false">2505.18731v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>FedSKC: Federated Learning with Non-IID Data via Structural Knowledge Collaboration</title>
      <link>http://arxiv.org/abs/2505.18981v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, International Conference on Web Services (ICWS) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了联邦学习中的数据异质性问题，并提出了基于结构知识协作的联邦学习方法（FedSKC），通过提取和转移客户端间的数据分布偏好，提供多样化的类相关知识和公平的收敛信号，从而提高模型性能。&lt;h4&gt;背景&lt;/h4&gt;随着边缘计算的进步，联邦学习作为一种保护隐私的协作学习范式显示出巨大潜力。然而，数据异质性问题，即多个客户端之间的标签偏好偏差，对模型收敛和性能产生负面影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的联邦学习方法，以解决数据异质性问题，并提高模型性能。&lt;h4&gt;方法&lt;/h4&gt;FedSKC方法包括三个组件：局部对比学习、全局差异聚合和全局周期性审查。局部对比学习用于防止局部训练导致的权重发散；全局差异聚合用于解决服务器和客户端之间的参数偏差；全局周期性审查用于纠正服务器随机选择设备引入的采样漂移。&lt;h4&gt;主要发现&lt;/h4&gt;FedSKC在非凸目标下进行了理论分析，并通过大量实验验证了其优越性。&lt;h4&gt;结论&lt;/h4&gt;FedSKC能够有效解决联邦学习中的数据异质性问题，并提高模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the advancement of edge computing, federated learning (FL) displays abright promise as a privacy-preserving collaborative learning paradigm.However, one major challenge for FL is the data heterogeneity issue, whichrefers to the biased labeling preferences among multiple clients, negativelyimpacting convergence and model performance. Most previous FL methods attemptto tackle the data heterogeneity issue locally or globally, neglectingunderlying class-wise structure information contained in each client. In thispaper, we first study how data heterogeneity affects the divergence of themodel and decompose it into local, global, and sampling drift sub-problems. Toexplore the potential of using intra-client class-wise structural knowledge inhandling these drifts, we thus propose Federated Learning with StructuralKnowledge Collaboration (FedSKC). The key idea of FedSKC is to extract andtransfer domain preferences from inter-client data distributions, offeringdiverse class-relevant knowledge and a fair convergent signal. FedSKC comprisesthree components: i) local contrastive learning, to prevent weight divergenceresulting from local training; ii) global discrepancy aggregation, whichaddresses the parameter deviation between the server and clients; iii) globalperiod review, correcting for the sampling drift introduced by the serverrandomly selecting devices. We have theoretically analyzed FedSKC undernon-convex objectives and empirically validated its superiority throughextensive experimental results.</description>
      <author>example@mail.com (Huan Wang, Haoran Li, Huaming Chen, Jun Yan, Lijuan Wang, Jiahua Shi, Shiping Chen, Jun Shen)</author>
      <guid isPermaLink="false">2505.18981v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Manifold-aware Representation Learning for Degradation-agnostic Image Restoration</title>
      <link>http://arxiv.org/abs/2505.18679v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ALl-in-One Image Restoration, low-level vision&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为MIRAGE的统一且轻量级的图像修复框架，用于解决多种退化问题，如噪声、模糊、雾霾、雨和低光照条件。MIRAGE通过模块化分解输入特征空间，并采用不同的处理模块来提高泛化和效率。&lt;h4&gt;背景&lt;/h4&gt;尽管图像修复技术有了一定的进步，但大多数现有方法将图像修复视为直接映射问题，没有考虑到不同退化类型的结构多样性。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够有效处理多种退化类型的图像修复框架。&lt;h4&gt;方法&lt;/h4&gt;MIRAGE将输入特征空间分解为三个语义对齐的并行分支，每个分支分别由专门的处理模块处理：全局上下文由注意力机制处理，局部纹理由卷积处理，通道统计由MLP处理。此外，引入了跨层对比学习方案，并在对称正定流形空间中进行对比学习，以更好地捕捉特征表示的底层几何结构。&lt;h4&gt;主要发现&lt;/h4&gt;MIRAGE在多种退化类型上实现了新的最先进性能，并为所有-in-one图像修复场景提供了一个可扩展的解决方案。&lt;h4&gt;结论&lt;/h4&gt;MIRAGE是一个高效且通用的图像修复框架，能够处理多种退化类型，并在公开的GitHub链接上提供代码和模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图像修复（IR）旨在从受噪声、模糊、雾霾、雨和低光照条件等退化影响的降质输入中恢复高质量图像。尽管最近取得了进展，但大多数现有方法将IR视为直接映射问题，没有对退化类型的结构多样性进行建模。在这项工作中，我们提出了MIRAGE，这是一个统一的、轻量级的所有-in-one图像修复框架，它明确地将输入特征空间分解为三个语义对齐的并行分支，每个分支由专门的模块处理：全局上下文由注意力机制处理，局部纹理由卷积处理，通道统计由MLP处理。这种模块化分解显著提高了跨多种退化的泛化和效率。此外，我们引入了一种跨层对比学习方案，该方案将浅层和潜在特征对齐，以增强共享表示的可区分性。为了更好地捕捉特征表示的底层几何结构，我们在对称正定（SPD）流形空间而不是传统的欧几里得空间中进行对比学习。大量的实验表明，MIRAGE不仅在各种退化类型上实现了新的最先进性能，而且为具有挑战性的所有-in-one图像修复场景提供了一个可扩展的解决方案。我们的代码和模型将公开提供在https://amazingren.github.io/MIRAGE/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image Restoration (IR) aims to recover high quality images from degradedinputs affected by various corruptions such as noise, blur, haze, rain, and lowlight conditions. Despite recent advances, most existing approaches treat IR asa direct mapping problem, relying on shared representations across degradationtypes without modeling their structural diversity. In this work, we presentMIRAGE, a unified and lightweight framework for all in one IR that explicitlydecomposes the input feature space into three semantically aligned parallelbranches, each processed by a specialized module attention for global context,convolution for local textures, and MLP for channel-wise statistics. Thismodular decomposition significantly improves generalization and efficiencyacross diverse degradations. Furthermore, we introduce a cross layercontrastive learning scheme that aligns shallow and latent features to enhancethe discriminability of shared representations. To better capture theunderlying geometry of feature representations, we perform contrastive learningin a Symmetric Positive Definite (SPD) manifold space rather than theconventional Euclidean space. Extensive experiments show that MIRAGE not onlyachieves new state of the art performance across a variety of degradation typesbut also offers a scalable solution for challenging all-in-one IR scenarios.Our code and models will be publicly available athttps://amazingren.github.io/MIRAGE/.</description>
      <author>example@mail.com (Bin Ren, Yawei Li, Xu Zheng, Yuqian Fu, Danda Pani Paudel, Ming-Hsuan Yang, Luc Van Gool, Nicu Sebe)</author>
      <guid isPermaLink="false">2505.18679v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>WeakMCN: Multi-task Collaborative Network for Weakly Supervised Referring Expression Comprehension and Segmentation</title>
      <link>http://arxiv.org/abs/2505.18686v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;WeakMCN是一种新的多任务协作网络，它结合了弱监督的指代表达理解（WREC）和分割（WRES）任务，在多任务框架中实现了有效的联合学习。&lt;h4&gt;背景&lt;/h4&gt;WREC和WRES旨在通过使用弱监督信号（如图像-文本对）从给定的表达中学习对象定位。这些任务传统上被单独建模。&lt;h4&gt;目的&lt;/h4&gt;提出WeakMCN，旨在通过联合学习提高WREC和WRES的性能，并验证其在半监督设置下的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;WeakMCN采用双分支架构，其中WREC分支采用基于锚点的对比学习，同时作为教师监督WRES分支。它还提出了动态视觉特征增强（DVFE）和协作一致性模块（CCM）来促进多任务协作。&lt;h4&gt;主要发现&lt;/h4&gt;WeakMCN在三个流行的REC和RES基准测试（RefCOCO、RefCOCO+和RefCOCOg）上取得了性能提升，WREC和WRES任务分别提高了3.91%和13.11%。此外，它在半监督REC和RES设置中表现出强的泛化能力，分别提高了8.94%和7.71%。&lt;h4&gt;结论&lt;/h4&gt;WeakMCN在WREC和WRES任务中实现了性能提升，并展示了在半监督设置中的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Weakly supervised referring expression comprehension and segmentation aim to learn object grounding based on a given expression using weak supervision signals like image-text pairs. While these tasks have traditionally been modeled separately, we argue that they can benefit from joint learning in a multi-task framework. To this end, we propose WeakMCN, a novel multi-task collaborative network that effectively combines WREC and WRES with a dual-branch architecture. Specifically, the WREC branch is formulated as anchor-based contrastive learning, which also acts as a teacher to supervise the WRES branch. In WeakMCN, we propose two innovative designs to facilitate multi-task collaboration, namely Dynamic Visual Feature Enhancement (DVFE) and Collaborative Consistency Module (CCM). DVFE dynamically combines various pre-trained visual knowledge to meet different task requirements, while CCM promotes cross-task consistency from the perspective of optimization. Extensive experimental results on three popular REC and RES benchmarks, i.e., RefCOCO, RefCOCO+, and RefCOCOg, consistently demonstrate performance gains of WeakMCN over state-of-the-art single-task alternatives, e.g., up to 3.91% and 13.11% on RefCOCO for WREC and WRES tasks, respectively. Furthermore, experiments also validate the strong generalization ability of WeakMCN in both semi-supervised REC and RES settings against existing methods, e.g., +8.94% for semi-REC and +7.71% for semi-RES on 1% RefCOCO. The code is publicly available at https://github.com/MRUIL/WeakMCN.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Weakly supervised referring expression comprehension(WREC) andsegmentation(WRES) aim to learn object grounding based on a given expressionusing weak supervision signals like image-text pairs. While these tasks havetraditionally been modeled separately, we argue that they can benefit fromjoint learning in a multi-task framework. To this end, we propose WeakMCN, anovel multi-task collaborative network that effectively combines WREC and WRESwith a dual-branch architecture. Specifically, the WREC branch is formulated asanchor-based contrastive learning, which also acts as a teacher to supervisethe WRES branch. In WeakMCN, we propose two innovative designs to facilitatemulti-task collaboration, namely Dynamic Visual Feature Enhancement(DVFE) andCollaborative Consistency Module(CCM). DVFE dynamically combines variouspre-trained visual knowledge to meet different task requirements, while CCMpromotes cross-task consistency from the perspective of optimization. Extensiveexperimental results on three popular REC and RES benchmarks, i.e., RefCOCO,RefCOCO+, and RefCOCOg, consistently demonstrate performance gains of WeakMCNover state-of-the-art single-task alternatives, e.g., up to 3.91% and 13.11% onRefCOCO for WREC and WRES tasks, respectively. Furthermore, experiments alsovalidate the strong generalization ability of WeakMCN in both semi-supervisedREC and RES settings against existing methods, e.g., +8.94% for semi-REC and+7.71% for semi-RES on 1% RefCOCO. The code is publicly available athttps://github.com/MRUIL/WeakMCN.</description>
      <author>example@mail.com (Yang Liu, Silin Cheng, Xinwei He, Sebastien Ourselin, Lei Tan, Gen Luo)</author>
      <guid isPermaLink="false">2505.18686v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Neural Parameter Search for Slimmer Fine-Tuned Models and Better Transfer</title>
      <link>http://arxiv.org/abs/2505.18713v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACL2025 Main&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NPS-Pruning的新方法，用于优化微调模型，通过结合预训练模型和剪枝微调模型，提高模型性能和压缩效率。&lt;h4&gt;背景&lt;/h4&gt;微调模型在特定领域表现良好，但在其他领域表现不佳，存在冗余问题。&lt;h4&gt;目的&lt;/h4&gt;开发有效的剪枝策略，提高微调模型的性能和压缩效率。&lt;h4&gt;方法&lt;/h4&gt;通过任务向量机制，计算微调模型与原模型之间的差异，并引入NPS-Pruning方法，在低秩子空间内搜索任务向量的神经参数，以优化模型。&lt;h4&gt;主要发现&lt;/h4&gt;NPS-Pruning方法在视觉、NLP和多模态基准测试中显示出有效性和鲁棒性，实现了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;NPS-Pruning方法能够通过模型插值增强知识迁移，通过模型合并实现有效的知识融合，同时部署压缩模型在保持近似原始性能的同时显著降低存储成本。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Foundation models and their checkpoints have significantly advanced deep learning, boosting performance across various applications. However, fine-tuned models often struggle outside their specific domains and exhibit considerable redundancy. Recent studies suggest that combining a pruned fine-tuned model with the original pre-trained model can mitigate forgetting, reduce interference when merging model parameters across tasks, and improve compression efficiency. In this context, developing an effective pruning strategy for fine-tuned models is crucial. Leveraging the advantages of the task vector mechanism, we preprocess fine-tuned models by calculating the differences between them and the original model. Recognizing that different task vector subspaces contribute variably to model performance, we introduce a novel method called Neural Parameter Search (NPS-Pruning) for slimming down fine-tuned models. This method enhances pruning efficiency by searching through neural parameters of task vectors within low-rank subspaces. Our method has three key applications: enhancing knowledge transfer through pairwise model interpolation, facilitating effective knowledge fusion via model merging, and enabling the deployment of compressed models that retain near-original performance while significantly reducing storage costs. Extensive experiments across vision, NLP, and multi-modal benchmarks demonstrate the effectiveness and robustness of our approach, resulting in substantial performance gains. The code is publicly available at: https://github.com/duguodong7/NPS-Pruning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models and their checkpoints have significantly advanced deeplearning, boosting performance across various applications. However, fine-tunedmodels often struggle outside their specific domains and exhibit considerableredundancy. Recent studies suggest that combining a pruned fine-tuned modelwith the original pre-trained model can mitigate forgetting, reduceinterference when merging model parameters across tasks, and improvecompression efficiency. In this context, developing an effective pruningstrategy for fine-tuned models is crucial. Leveraging the advantages of thetask vector mechanism, we preprocess fine-tuned models by calculating thedifferences between them and the original model. Recognizing that differenttask vector subspaces contribute variably to model performance, we introduce anovel method called Neural Parameter Search (NPS-Pruning) for slimming downfine-tuned models. This method enhances pruning efficiency by searching throughneural parameters of task vectors within low-rank subspaces. Our method hasthree key applications: enhancing knowledge transfer through pairwise modelinterpolation, facilitating effective knowledge fusion via model merging, andenabling the deployment of compressed models that retain near-originalperformance while significantly reducing storage costs. Extensive experimentsacross vision, NLP, and multi-modal benchmarks demonstrate the effectivenessand robustness of our approach, resulting in substantial performance gains. Thecode is publicly available at: https://github.com/duguodong7/NPS-Pruning.</description>
      <author>example@mail.com (Guodong Du, Zitao Fang, Jing Li, Junlin Li, Runhua Jiang, Shuyang Yu, Yifei Guo, Yangneng Chen, Sim Kuan Goh, Ho-Kin Tang, Daojing He, Honghai Liu, Min Zhang)</author>
      <guid isPermaLink="false">2505.18713v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Evolution Operator Learning for High-Dimensional Dynamical Systems</title>
      <link>http://arxiv.org/abs/2505.18671v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种仅使用编码器的方法来学习大规模非线性动力系统的演化算子，适用于分析展示复杂时空模式的系统，并为处理大规模气象数据集和模拟工具提供了有效工具。&lt;h4&gt;背景&lt;/h4&gt;演化算子非常适合分析展示复杂时空模式的系统，已成为科学社区的关键分析工具。随着可处理大量数据集和模拟工具的出现，需要一种数据驱动的方法来理解这些数据。&lt;h4&gt;目的&lt;/h4&gt;开发一种有效的方法来处理和分析大规模非线性动力系统的演化算子。&lt;h4&gt;方法&lt;/h4&gt;该方法的核心在于自监督表示学习方法与演化算子学习理论的关联。在多个科学领域测试了该方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在解释小蛋白质的折叠动力学、药物分子在宿主位点上的结合过程以及气候数据中的模式识别方面表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法为理解和分析复杂非线性动力系统提供了有效的数据驱动工具。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种仅使用编码器的方法来学习大规模非线性动力系统的演化算子，这些算子描述了复杂自然现象。演化算子特别适合分析展示复杂时空模式的系统，已经成为科学社区的关键分析工具。随着具有千兆级规模的气象数据集和每天能够运行数百万个分子动力学步骤的模拟工具成为商品，我们的方法提供了一个有效的工具，从数据驱动的角度来理解它们。其核心在于自监督表示学习方法与最近建立的演化算子学习理论之间的一种显著联系。为了展示所提出方法的有用性，我们在多个科学领域对其进行了测试：解释小蛋白质的折叠动力学、药物分子在宿主位点上的结合过程以及自主地在气候数据中找到模式。用于重现实验的代码和数据已开源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce an encoder-only approach to learn the evolution operators oflarge-scale non-linear dynamical systems, such as those describing complexnatural phenomena. Evolution operators are particularly well-suited foranalyzing systems that exhibit complex spatio-temporal patterns and have becomea key analytical tool across various scientific communities. As terabyte-scaleweather datasets and simulation tools capable of running millions of moleculardynamics steps per day are becoming commodities, our approach provides aneffective tool to make sense of them from a data-driven perspective. The coreof it lies in a remarkable connection between self-supervised representationlearning methods and the recently established learning theory of evolutionoperators. To show the usefulness of the proposed method, we test it acrossmultiple scientific domains: explaining the folding dynamics of small proteins,the binding process of drug-like molecules in host sites, and autonomouslyfinding patterns in climate data. Code and data to reproduce the experimentsare made available open source.</description>
      <author>example@mail.com (Giacomo Turri, Luigi Bonati, Kai Zhu, Massimiliano Pontil, Pietro Novelli)</author>
      <guid isPermaLink="false">2505.18671v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Date Fragments: A Hidden Bottleneck of Tokenization for Temporal Reasoning</title>
      <link>http://arxiv.org/abs/2505.16088v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种新的方法来评估BPE分词器在日期处理上的效果，并发现过多的分词会导致模型在处理不常见日期时的准确性下降。&lt;h4&gt;背景&lt;/h4&gt;现代的BPE分词器在处理日期时会将其分割成没有意义的片段，这会使得模型在时间推理上变得困难。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种评估日期分词器的方法，并提高时间推理的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了日期分片率作为衡量分词器保留日期成分完整性的指标，发布了DateAugBench数据集，通过层间探查和因果注意力分析揭示了日期抽象机制。&lt;h4&gt;主要发现&lt;/h4&gt;发现过多的分词会导致模型在处理不常见日期（如历史和未来日期）时准确性下降最多10分，较大的模型能够更快地完成日期片段的修复，并且模型的时间推理路径与人类理解有所不同。&lt;h4&gt;结论&lt;/h4&gt;通过提高日期分词的质量，可以显著提升时间推理的准确性，并且大型语言模型在日期抽象方面表现出独特的机制。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代的BPE分词器通常将日历日期分割成无意义的片段，例如20250312 $ightarrow$ 202, 503, 12，这会增加标记计数并掩盖所需的时间推理的固有结构。在这项工作中，我们（1）介绍了一种简单且可解释的度量指标，称为日期分片率，用于衡量分词器如何忠实地保留多数字日期成分；（2）发布了DateAugBench，一套包含6500个样本的测试集，涵盖了三个时间推理任务：基于上下文的日期解析、格式不变谜题和跨越历史、当代和未来时期的日期算术；（3）通过层间探查和因果注意力跳转分析，揭示了一种新兴的日期抽象机制，其中大型语言模型将月份、日期和年份成分的片段缝合起来进行时间推理。我们的实验表明，过多的分词会导致在罕见日期（如历史和未来日期）上准确性下降最多10分。此外，我们发现模型越大，修复日期片段的抽象机制就越快。最后，我们观察到LLM在组装日期片段时遵循的推理路径，通常与人类的解释（年$ightarrow$月$ightarrow$日）不同。我们的数据集和代码已公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern BPE tokenizers often split calendar dates into meaningless fragments,e.g., 20250312 $\rightarrow$ 202, 503, 12, inflating token counts and obscuringthe inherent structure needed for robust temporal reasoning. In this work, we(1) introduce a simple yet interpretable metric, termed date fragmentationratio, that measures how faithfully a tokenizer preserves multi-digit datecomponents; (2) release DateAugBench, a suite of 6500 examples spanning threetemporal reasoning tasks: context-based date resolution, format-invariancepuzzles, and date arithmetic across historical, contemporary, and future timeperiods; and (3) through layer-wise probing and causal attention-hop analyses,uncover an emergent date-abstraction mechanism whereby large language modelsstitch together the fragments of month, day, and year components for temporalreasoning. Our experiments show that excessive fragmentation correlates withaccuracy drops of up to 10 points on uncommon dates like historical andfuturistic dates. Further, we find that the larger the model, the faster theemergent date abstraction that heals date fragments is accomplished. Lastly, weobserve a reasoning path that LLMs follow to assemble date fragments, typicallydiffering from human interpretation (year $\rightarrow$ month $\rightarrow$day). Our datasets and code are made publicly available\href{https://github.com/gagan3012/date-fragments}{here}.</description>
      <author>example@mail.com (Gagan Bhatia, Maxime Peyrard, Wei Zhao)</author>
      <guid isPermaLink="false">2505.16088v2</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>TrajMoE: Spatially-Aware Mixture of Experts for Unified Human Mobility Modeling</title>
      <link>http://arxiv.org/abs/2505.18670v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TrajMoE的模型，用于跨城市人类移动性建模，以解决城市间空间表示异质性和移动模式多样性的挑战。&lt;h4&gt;背景&lt;/h4&gt;建模人类移动性对于城市规划、交通优化和个性化服务等应用至关重要，但由于城市间空间表示和移动模式的异质性，这一领域存在一般化难题。&lt;h4&gt;目的&lt;/h4&gt;提出一个统一且可扩展的模型，以解决城市间空间语义不一致和城市移动模式多样性的问题。&lt;h4&gt;方法&lt;/h4&gt;设计了一个空间语义编码器，它从基于POI的功能语义和访问模式中学习可迁移的位置表示。此外，设计了一个空间感知混合专家（SAMoE）Transformer，该Transformer将结构化先验注入到专门处理不同移动语义的专家中，并引入一个共享专家以捕获城市不变模式并实现自适应跨城市泛化。&lt;h4&gt;主要发现&lt;/h4&gt;TrajMoE在仅经过一次epoch的微调后，相对于竞争性移动基础模型实现了高达27%的相对改进，并且仅使用5%的目标城市数据就始终优于全数据基线。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，TrajMoE是实现真正可泛化、可迁移和可预训练的人类移动性基础模型的重要一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling human mobility across diverse cities is essential for applicationssuch as urban planning, transportation optimization, and personalized services.However, generalization remains challenging due to heterogeneous spatialrepresentations and mobility patterns across cities. Existing methods typicallyrely on numerical coordinates or require training city-specific models,limiting their scalability and transferability. We propose TrajMoE, a unifiedand scalable model for cross-city human mobility modeling. TrajMoE addressestwo key challenges: (1) inconsistent spatial semantics across cities, and (2)diverse urban mobility patterns. To tackle these, we begin by designing aspatial semantic encoder that learns transferable location representations fromPOI-based functional semantics and visit patterns. Furthermore, we design aSpatially-Aware Mixture-of-Experts (SAMoE) Transformer that injects structuredpriors into experts specialized in distinct mobility semantics, along with ashared expert to capture city-invariant patterns and enable adaptive cross-citygeneralization. Extensive experiments demonstrate that TrajMoE achieves up to27% relative improvement over competitive mobility foundation models after onlyone epoch of fine-tuning, and consistently outperforms full-data baselinesusing merely 5% of target city data. These results establish TrajMoE as asignificant step toward realizing a truly generalizable, transferable, andpretrainable foundation model for human mobility.</description>
      <author>example@mail.com (Chonghua Han, Yuan Yuan, Kaiyan Chen, Jingtao Ding, Yong Li)</author>
      <guid isPermaLink="false">2505.18670v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Distinctive Feature Codec: Adaptive Segmentation for Efficient Speech Representation</title>
      <link>http://arxiv.org/abs/2505.18516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于特征的方法，通过动态分配标记并根据语音内容的感知重要性来对连续的语音信号进行分词，与传统的基于帧的方法相比，这种方法在语音表示上更加高效。&lt;h4&gt;背景&lt;/h4&gt;语音分词在语音理解和生成的人工智能系统中是一个关键部分，由于语音信号中重要声学变化的不可预测时间，对连续语音信号进行分词比文本分词更加复杂。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过动态分配标记来提高语音表示的效率，并实现与传统基于帧的处理方法不同的分词方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一个基于特征的方法，该方法通过学习识别和优先处理语音信号中的特征区域，并使用分组标量量化方法来提高分词稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法显著提高了语音表示的效率，是首次将传统的基于信号处理的特征扩展到深度学习框架中。实验证明了该方法的有效性，并提供了如何将段边界与自然声学转换对齐以提高码本利用的理论见解。&lt;h4&gt;结论&lt;/h4&gt;该基于特征的方法为传统的基于帧的处理方法提供了一个有希望的替代方案，并推动了现代深度学习语音处理框架中的可解释性表示学习。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在神经语音编解码器模型中对语音进行分词是设计用于语音理解和生成的人工智能系统的关键部分。尽管基于文本的系统自然受益于离散符号之间的标记边界，但由于语音信号中重要声学变化的不可预测时间，对连续语音信号进行分词更为复杂。大多数当前的神经语音编解码器通常通过使用固定时间间隔的统一处理来解决这个问题，这忽略了语音中固有的信息密度变化。在本文中，我们介绍了一种基于特征的方法，该方法根据语音内容的感知重要性动态分配标记。通过学习识别和优先处理语音信号中的特征区域，我们的方法与传统的基于帧的方法相比，实现了显著的更高效的语音表示。这项工作标志着将传统的基于信号处理的特征首次扩展到深度学习框架中的成功。通过严格的实验，我们证明了我们方法的有效性，并提供了关于如何将段边界与自然声学转换对齐以提高码本利用的理论见解。此外，我们通过开发一种用于可变长度段分组标量量化方法来提高分词稳定性。我们的基于特征的方法为传统的基于帧的处理方法提供了一个有希望的替代方案，并推进了现代深度学习语音处理框架中的可解释性表示学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The tokenization of speech with neural speech codec models is a crucialaspect of AI systems designed for speech understanding and generation. Whiletext-based systems naturally benefit from token boundaries between discretesymbols, tokenizing continuous speech signals is more complex due to theunpredictable timing of important acoustic variations. Most current neuralspeech codecs typically address this by using uniform processing at fixed timeintervals, which overlooks the varying information density inherent in speech.In this paper, we introduce a distinctive feature-based approach thatdynamically allocates tokens based on the perceptual significance of speechcontent. By learning to identify and prioritize distinctive regions in speechsignals, our approach achieves a significantly more efficient speechrepresentation compared with conventional frame-based methods. This work marksthe first successful extension of traditional signal processing-baseddistinctive features into deep learning frameworks. Through rigorousexperimentation, we demonstrate the effectiveness of our approach and providetheoretical insights into how aligning segment boundaries with natural acoustictransitions improves codebook utilization. Additionally, we enhancetokenization stability by developing a Group-wise Scalar Quantization approachfor variable-length segments. Our distinctive feature-based approach offers apromising alternative to conventional frame-based processing and advancesinterpretable representation learning in the modern deep learning speechprocessing framework.</description>
      <author>example@mail.com (Xiangyu Zhang, Fuming Fang, Peng Gao, Bin Qin, Beena Ahmed, Julien Epps)</author>
      <guid isPermaLink="false">2505.18516v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Grounding Bodily Awareness in Visual Representations for Efficient Policy Learning</title>
      <link>http://arxiv.org/abs/2505.18487v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A preprint version&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究如何利用包含身体相关线索的视觉表示来提高机器人操作任务中的策略学习效率。&lt;h4&gt;背景&lt;/h4&gt;学习有效的视觉表示对机器人操作是一个基本挑战，因为动作执行中涉及复杂的身体动力学。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种方法，使得视觉表示能够有效地支持机器人操作任务的策略学习。&lt;h4&gt;方法&lt;/h4&gt;提出了Intertoken Contrast（ICon）方法，这是一种应用于视觉Transformer（ViTs）的token级表示的对比学习方法。ICon通过在特征空间中强制分离特定于代理和特定于环境的token，从而实现以代理为中心的视觉表示，这些表示嵌入身体特定的归纳偏差。该框架可以通过将对比损失作为辅助目标集成到端到端策略学习中。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，ICon不仅提高了各种操作任务中的策略性能，而且还促进了不同机器人之间的策略迁移。&lt;h4&gt;结论&lt;/h4&gt;ICon是一种有效的视觉表示学习方法，可以显著提高机器人操作任务中的策略学习效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：学习有效视觉表示以用于机器人操作是一个基本的挑战，因为动作执行中涉及到复杂的身体动力学。在本文中，我们研究了如何利用包含身体相关线索的视觉表示来支持下游机器人操作任务的策略学习。我们提出了一种名为Intertoken Contrast（ICon）的对比学习方法，应用于视觉Transformer（ViTs）的token级表示。ICon通过在特征空间中强制分离特定于代理和特定于环境的token，实现了以代理为中心的视觉表示，这些表示内嵌了身体特定的归纳偏差。该框架可以通过将对比损失作为辅助目标无缝集成到端到端策略学习中。我们的实验表明，ICon不仅提高了各种操作任务中的策略性能，而且也促进了不同机器人之间的策略迁移。项目网站：https://github.com/HenryWJL/icon&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning effective visual representations for robotic manipulation remains afundamental challenge due to the complex body dynamics involved in actionexecution. In this paper, we study how visual representations that carrybody-relevant cues can enable efficient policy learning for downstream roboticmanipulation tasks. We present $\textbf{I}$nter-token $\textbf{Con}$trast($\textbf{ICon}$), a contrastive learning method applied to the token-levelrepresentations of Vision Transformers (ViTs). ICon enforces a separation inthe feature space between agent-specific and environment-specific tokens,resulting in agent-centric visual representations that embed body-specificinductive biases. This framework can be seamlessly integrated into end-to-endpolicy learning by incorporating the contrastive loss as an auxiliaryobjective. Our experiments show that ICon not only improves policy performanceacross various manipulation tasks but also facilitates policy transfer acrossdifferent robots. The project website: https://github.com/HenryWJL/icon</description>
      <author>example@mail.com (Junlin Wang, Zhiyun Lin)</author>
      <guid isPermaLink="false">2505.18487v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Future-Oriented Navigation: Dynamic Obstacle Avoidance with One-Shot Energy-Based Multimodal Motion Prediction</title>
      <link>http://arxiv.org/abs/2505.00237v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE RA-L&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在动态和不确定环境中安全高效控制移动机器人的集成方法。&lt;h4&gt;背景&lt;/h4&gt;移动机器人在动态和不确定环境中面临的安全和效率问题。&lt;h4&gt;目的&lt;/h4&gt;实现移动机器人在动态环境中的有效导航。&lt;h4&gt;方法&lt;/h4&gt;该方法包括两个关键步骤：一次性多模态运动预测和模型预测控制。运动预测由基于能量的神经网络驱动，能够生成高分辨率的多步预测。预测结果被用于创建几何形状，这些形状作为数学约束。动态障碍物通过无监督方式按邻近性分组，以提高性能和效率。模型预测控制负责处理无碰撞导航，并特别设计用于主动避免动态障碍物。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在各种代表典型仓库设置的情景中进行了性能评估，结果表明该方法优于其他现有的动态障碍物避免方法。&lt;h4&gt;结论&lt;/h4&gt;该方法允许移动机器人在动态环境中有效导航，并优于现有的动态障碍物避免方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种在动态和不确定环境中安全高效控制移动机器人的集成方法。该方法包括两个关键步骤：一次性多模态运动预测和模型预测控制。运动预测由基于能量的神经网络驱动，能够生成高分辨率的多步预测。预测结果被用于创建几何形状，这些形状作为数学约束。动态障碍物通过无监督方式按邻近性分组，以提高性能和效率。模型预测控制负责处理无碰撞导航，并特别设计用于主动避免动态障碍物。该方法在各种代表典型仓库设置的情景中进行了性能评估，结果表明该方法优于其他现有的动态障碍物避免方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an integrated approach for the safe and efficient controlof mobile robots in dynamic and uncertain environments. The approach consistsof two key steps: one-shot multimodal motion prediction to anticipate motionsof dynamic obstacles and model predictive control to incorporate thesepredictions into the motion planning process. Motion prediction is driven by anenergy-based neural network that generates high-resolution, multi-steppredictions in a single operation. The prediction outcomes are further utilizedto create geometric shapes formulated as mathematical constraints. Instead oftreating each dynamic obstacle individually, predicted obstacles are grouped byproximity in an unsupervised way to improve performance and efficiency. Theoverall collision-free navigation is handled by model predictive control with aspecific design for proactive dynamic obstacle avoidance. The proposed approachallows mobile robots to navigate effectively in dynamic environments. Itsperformance is accessed across various scenarios that represent typicalwarehouse settings. The results demonstrate that the proposed approachoutperforms other existing dynamic obstacle avoidance methods.</description>
      <author>example@mail.com (Ze Zhang, Georg Hess, Junjie Hu, Emmanuel Dean, Lennart Svensson, Knut Åkesson)</author>
      <guid isPermaLink="false">2505.00237v2</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>ThanoRA: Task Heterogeneity-Aware Multi-Task Low-Rank Adaptation</title>
      <link>http://arxiv.org/abs/2505.18640v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ThanoRA是一个任务异构性感知的多任务低秩自适应框架，旨在提高多任务自适应的效率，同时保持LoRA的推理效率。&lt;h4&gt;背景&lt;/h4&gt;许多实际应用需要基础模型同时专精于多个任务，这促使了对高效多任务自适应方法的需求。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够在多任务自适应中保持推理效率的方法。&lt;h4&gt;方法&lt;/h4&gt;ThanoRA通过联合建模任务异构性，并在训练过程中缓解子空间干扰来实现多任务自适应。具体来说，它通过初始化时构建特定任务的LoRA子空间，并引入子空间保持正则化来防止任务干扰和子空间坍塌。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，ThanoRA在多模态和纯文本基准测试中，在各种多任务混合下，相对于基线方法，实现了稳健和优越的性能，而没有引入额外的推理开销。&lt;h4&gt;结论&lt;/h4&gt;ThanoRA能够实现高效且统一的多任务自适应，是一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;Low-Rank Adaptation (LoRA) 在下游微调基础模型时得到了广泛应用，因为它高效且没有额外的推理成本。许多实际应用需要基础模型能够同时专精于多个任务，这促使了对高效多任务自适应方法的需求。虽然最近的方法通过将LoRA与混合专家（MoE）集成来解决这个问题，但使用路由器防止了参数的可合并性，这增加了推理开销并阻碍了统一的多任务自适应，从而限制了部署的实际性。在这项工作中，我们提出了ThanoRA，一个任务异构性感知的多任务低秩自适应框架，它可以在保持LoRA推理效率的同时实现多任务自适应。ThanoRA在训练过程中联合建模任务异构性并缓解子空间干扰。具体来说，受任务之间复杂性和异构性固有差异的启发，ThanoRA在初始化时构建了特定任务的LoRA子空间，使得知识注入与任务异构性保持细粒度对齐。此外，为了防止多任务训练期间的干扰和子空间坍塌，ThanoRA引入了子空间保持正则化，以保持特定任务表示的独立性。通过这两个组件的协同作用，ThanoRA实现了高效和统一的多任务自适应。在多模态和纯文本基准测试上进行的广泛实验，在变化的多任务混合下表明，ThanoRA相对于基线方法，始终实现了稳健和优越的性能，而没有引入额外的推理开销。我们的代码在https://github.com/LiangJian24/ThanoRA上公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-Rank Adaptation (LoRA) is widely adopted for downstream fine-tuning offoundation models due to its efficiency and zero additional inference cost.Many real-world applications require foundation models to specialize inmultiple tasks simultaneously, motivating the need for efficient multi-taskadaptation. While recent approaches integrate LoRA with mixture-of-experts(MoE) to address this, the use of routers prevents parameter mergeability,which increases inference overhead and hinders unified multi-task adaptation,thereby limiting deployment practicality. In this work, we propose ThanoRA, aTask Heterogeneity-Aware Multi-Task Low-Rank Adaptation framework that enablesmulti-task adaptation while preserving the inference efficiency of LoRA.ThanoRA jointly models task heterogeneity and mitigates subspace interferencethroughout training. Specifically, motivated by inherent differences incomplexity and heterogeneity across tasks, ThanoRA constructs task-specificLoRA subspaces at initialization, enabling fine-grained knowledge injectionaligned with task heterogeneity. Furthermore, to prevent task interference andsubspace collapse during multi-task training, ThanoRA introduces asubspace-preserving regularization that maintains the independence oftask-specific representations. With the synergy of both components, ThanoRAenables efficient and unified multi-task adaptation. Extensive experimentsacross multimodal and text-only benchmarks under varying multi-task mixturesdemonstrate that ThanoRA consistently achieves robust and superior performanceover strong baselines without introducing additional inference overhead. Ourcode is publicly available at: https://github.com/LiangJian24/ThanoRA.</description>
      <author>example@mail.com (Jian Liang, Wenke Huang, Xianda Guo, Guancheng Wan, Bo Du, Mang Ye)</author>
      <guid isPermaLink="false">2505.18640v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Multilingual Question Answering in Low-Resource Settings: A Dzongkha-English Benchmark for Foundation Models</title>
      <link>http://arxiv.org/abs/2505.18638v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 20 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了DZEN数据集，该数据集包含并行藏语和英语测试题目，用于评估不丹中高学生的能力。&lt;h4&gt;背景&lt;/h4&gt;该研究针对大型语言模型（LLMs）在低资源语言，尤其是藏语中的性能进行了评估。&lt;h4&gt;目的&lt;/h4&gt;通过创建并行数据集测试LLMs，并分析不同提示策略，以提高LLMs在藏语中的性能。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含超过5000个问题的数据集，涉及多种科学主题，并使用此数据集测试LLMs，同时研究了不同的提示策略。&lt;h4&gt;主要发现&lt;/h4&gt;不同LLMs在藏语和英语测试中的性能存在显著差异；链式思维（CoT）提示对推理问题效果较好，对事实问题效果较差；增加英语翻译可以提升藏语问题回答的准确性。&lt;h4&gt;结论&lt;/h4&gt;研究指出，进一步研究以提高LLMs在藏语以及低资源语言中的性能具有广阔前景。&lt;h4&gt;翻译&lt;/h4&gt;本文提供DZEN数据集，包含并行藏语和英语测试题目，用于不丹中高学生能力评估。数据集涵盖5000多个问题，涵盖多种科学主题，并用于测试多种大型语言模型（LLMs）。研究发现，不同LLMs在藏语和英语测试中的性能存在显著差异；链式思维（CoT）提示对推理问题效果较好，对事实问题效果较差；增加英语翻译可以提高藏语问题回答的准确性。研究结果表明，进一步研究以提高LLMs在藏语及低资源语言中的性能具有广阔前景。数据集发布于https://github.com/kraritt/llm_dzongkha_evaluation。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we provide DZEN, a dataset of parallel Dzongkha and Englishtest questions for Bhutanese middle and high school students. The over 5Kquestions in our collection span a variety of scientific topics and includefactual, application, and reasoning-based questions. We use our paralleldataset to test a number of Large Language Models (LLMs) and find a significantperformance difference between the models in English and Dzongkha. We also lookat different prompting strategies and discover that Chain-of-Thought (CoT)prompting works well for reasoning questions but less well for factual ones. Wealso find that adding English translations enhances the precision of Dzongkhaquestion responses. Our results point to exciting avenues for further study toimprove LLM performance in Dzongkha and, more generally, in low-resourcelanguages. We release the dataset at:https://github.com/kraritt/llm_dzongkha_evaluation.</description>
      <author>example@mail.com (Md. Tanzib Hosain, Rajan Das Gupta, Md. Kishor Morol)</author>
      <guid isPermaLink="false">2505.18638v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>LiSTEN: Learning Soft Token Embeddings for Neural Audio LLMs</title>
      <link>http://arxiv.org/abs/2505.18517v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LiSTEN的框架，用于将大型语言模型（LLMs）应用于语音和音频任务，并有效适应不同任务。&lt;h4&gt;背景&lt;/h4&gt;基于大型语言模型（LLMs）的基础模型在处理各种任务和模态方面表现出色，但将其应用于通用音频语言任务因声学环境和任务差异而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;设计一个框架，使LLMs能够适应语音和音频任务，同时减少对大规模ASR或字幕数据集的依赖。&lt;h4&gt;方法&lt;/h4&gt;LiSTEN采用动态提示选择策略，并使用可学习的键值对，以平衡模型的一般和特定任务知识，同时避免多任务设置中的过拟合。&lt;h4&gt;主要发现&lt;/h4&gt;LiSTEN通过减少训练参数数量实现了与现有方法相当的性能，并简化了训练过程。此外，通过分析不同任务中选择的提示的多样性和重叠，增强了模型的可解释性。&lt;h4&gt;结论&lt;/h4&gt;LiSTEN是一种有效的框架，能够使LLMs适应语音和音频任务，并提高模型的可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models based on large language models (LLMs) have shown greatsuccess in handling various tasks and modalities. However, adapting thesemodels for general-purpose audio-language tasks is challenging due todifferences in acoustic environments and task variations. In this work, weintroduce LiSTEN Learning Soft Token Embeddings for Neural Audio LLMs), aframework for adapting LLMs to speech and audio tasks. LiSTEN uses a dynamicprompt selection strategy with learnable key-value pairs, allowing the model tobalance general and task-specific knowledge while avoiding overfitting in amultitask setting. Our approach reduces dependence on large-scale ASR orcaptioning datasets, achieves competitive performance with fewer trainableparameters, and simplifies training by using a single-stage process.Additionally, LiSTEN enhances interpretability by analyzing the diversity andoverlap of selected prompts across different tasks.</description>
      <author>example@mail.com (Pooneh Mousavi, Shubham Gupta, Cem Subakan, Mirco Ravanelli)</author>
      <guid isPermaLink="false">2505.18517v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>G1: Teaching LLMs to Reason on Graphs with Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2505.18499v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为G1的方法，通过在合成图论任务上进行强化学习（RL）训练，显著提升了大型语言模型（LLMs）在图相关任务上的推理能力。&lt;h4&gt;背景&lt;/h4&gt;虽然大型语言模型在许多任务上取得了显著进展，但它们在图相关任务上的表现仍然有限，这阻碍了通用模型的发展。以往尝试包括预训练图基础模型或使用监督微调，但往往面临大规模、通用图数据稀缺的问题。&lt;h4&gt;目的&lt;/h4&gt;旨在通过强化学习提升LLMs在图推理任务上的能力。&lt;h4&gt;方法&lt;/h4&gt;引入了Erdős，目前最大的图推理数据集，包含50个不同难度级别的图论任务，以及10万训练数据和5千测试数据。使用RL在Erdős上进行训练，以提升LLMs的图推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;G1在图推理任务上取得了显著改进，其微调后的3B模型甚至超过了Qwen2.5-72B-Instruct（规模是其24倍）。RL训练的模型也表现出强大的零样本泛化能力，能够应用于未见过的任务、领域和图编码方案，包括其他图论基准以及现实世界的节点分类和链接预测任务，同时没有牺牲一般推理能力。&lt;h4&gt;结论&lt;/h4&gt;通过在图论任务上使用强化学习微调LLMs，提供了一种高效、可扩展的构建强大图推理器的方法，结合了预训练LLMs的能力和大量自动生成的合成数据，表明LLMs具有被强化学习成功唤起的图理解能力。&lt;h4&gt;翻译&lt;/h4&gt;尽管大型语言模型（LLMs）在许多任务上取得了显著的进步，但它们在图相关任务上的能力仍然明显有限，这阻碍了真正通用模型的发展。以往尝试，包括预训练图基础模型或使用监督微调，通常面临诸如大规模、普遍代表性的图数据稀缺等挑战。我们引入了G1，这是一种简单但有效的方法，证明了在合成图论任务上进行强化学习（RL）可以显著扩展LLMs的图推理能力。为了使RL训练成为可能，我们精心制作了Erdős，迄今为止最大的图推理数据集，包含50个不同难度级别的图论任务，以及10万训练数据和5千测试数据，所有这些都是从现实世界的图中驱动的。在Erdős上使用RL，G1在图推理方面取得了实质性改进，我们的3B微调模型甚至优于Qwen2.5-72B-Instruct（规模是其24倍）。RL训练的模型也表现出对未见任务、领域和图编码方案的强大零样本泛化能力，包括其他图论基准以及现实世界的节点分类和链接预测任务，同时没有妥协一般推理能力。我们的发现提供了一种通过在图论任务上使用RL微调LLMs来构建强大图推理器的高效、可扩展路径，结合了预训练LLMs的能力和大量自动生成的合成数据，表明LLMs具有被强化学习成功唤起的图理解能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although Large Language Models (LLMs) have demonstrated remarkable progress,their proficiency in graph-related tasks remains notably limited, hindering thedevelopment of truly general-purpose models. Previous attempts, includingpretraining graph foundation models or employing supervised fine-tuning, oftenface challenges such as the scarcity of large-scale, universally representedgraph data. We introduce G1, a simple yet effective approach demonstrating thatReinforcement Learning (RL) on synthetic graph-theoretic tasks cansignificantly scale LLMs' graph reasoning abilities. To enable RL training, wecurate Erd\~os, the largest graph reasoning dataset to date comprising 50diverse graph-theoretic tasks of varying difficulty levels, 100k training dataand 5k test data, all drived from real-world graphs. With RL on Erd\~os, G1obtains substantial improvements in graph reasoning, where our finetuned 3Bmodel even outperforms Qwen2.5-72B-Instruct (24x size). RL-trained models alsoshow strong zero-shot generalization to unseen tasks, domains, and graphencoding schemes, including other graph-theoretic benchmarks as well asreal-world node classification and link prediction tasks, without compromisinggeneral reasoning abilities. Our findings offer an efficient, scalable path forbuilding strong graph reasoners by finetuning LLMs with RL on graph-theoretictasks, which combines the strengths of pretrained LLM capabilities withabundant, automatically generated synthetic data, suggesting that LLMs possessgraph understanding abilities that RL can elicit successfully.</description>
      <author>example@mail.com (Xiaojun Guo, Ang Li, Yifei Wang, Stefanie Jegelka, Yisen Wang)</author>
      <guid isPermaLink="false">2505.18499v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Token-Level Logits Matter: A Closer Look at Speech Foundation Models for Ambiguous Emotion Recognition</title>
      <link>http://arxiv.org/abs/2505.18484v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at INTERSPEECH 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了大型语音基础模型（SFMs）在模糊情感识别中的有效性。&lt;h4&gt;背景&lt;/h4&gt;情感智力在对话式人工智能中对于人机交互等领域至关重要。虽然已经开发了众多模型，但它们往往忽略了人类情感的复杂性和模糊性。&lt;h4&gt;目的&lt;/h4&gt;在大型语音基础模型时代，理解它们识别模糊情感的能力对于开发下一代情感感知模型至关重要。&lt;h4&gt;方法&lt;/h4&gt;本研究设计了用于模糊情感预测的提示，并引入了两种新颖的方法来推断模糊情感分布：一种分析生成的文本响应，另一种通过token级别的logits检查SFMs的内部处理。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，虽然SFMs可能不会始终如一地生成关于模糊情感的准确文本响应，但它们可以根据先验知识在token级别解释这种情感，显示出在不同提示下的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;SFMs在模糊情感识别方面具有一定的潜力，但需要进一步研究和改进。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在对话式人工智能中，情感智力对于人机交互等领域的应用至关重要。尽管已经开发了许多模型，但它们往往忽略了人类情感的复杂性和模糊性。在大型语音基础模型时代，理解它们在识别模糊情感方面的能力对于开发下一代情感感知模型至关重要。本研究检验了SFMs在模糊情感识别中的有效性。我们设计了用于模糊情感预测的提示，并引入了两种新颖的方法来推断模糊情感分布：一种分析生成的文本响应，另一种通过token级别的logits检查SFMs的内部处理。我们的发现表明，虽然SFMs可能不会始终如一地生成关于模糊情感的准确文本响应，但它们可以根据先验知识在token级别解释这种情感，显示出在不同提示下的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emotional intelligence in conversational AI is crucial across domains likehuman-computer interaction. While numerous models have been developed, theyoften overlook the complexity and ambiguity inherent in human emotions. In theera of large speech foundation models (SFMs), understanding their capability inrecognizing ambiguous emotions is essential for the development ofnext-generation emotion-aware models. This study examines the effectiveness ofSFMs in ambiguous emotion recognition. We designed prompts for ambiguousemotion prediction and introduced two novel approaches to infer ambiguousemotion distributions: one analysing generated text responses and the otherexamining the internal processing of SFMs through token-level logits. Ourfindings suggest that while SFMs may not consistently generate accurate textresponses for ambiguous emotions, they can interpret such emotions at the tokenlevel based on prior knowledge, demonstrating robustness across differentprompts.</description>
      <author>example@mail.com (Jule Valendo Halim, Siyi Wang, Hong Jia, Ting Dang)</author>
      <guid isPermaLink="false">2505.18484v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>BiomechGPT: Towards a Biomechanically Fluent Multimodal Foundation Model for Clinically Relevant Motion Tasks</title>
      <link>http://arxiv.org/abs/2505.18465v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了无标记运动捕捉技术在生物力学运动分析中的应用，提出了BiomechGPT，一个多模态生物力学-语言模型，用于回答与运动相关的临床问题。&lt;h4&gt;背景&lt;/h4&gt;无标记运动捕捉技术使生物力学运动分析在门诊、住院、治疗和家庭环境中成为可能，但随之而来的是下游分析任务的挑战。&lt;h4&gt;目的&lt;/h4&gt;探索多模态运动-语言模型是否能够回答与运动相关的详细且具有临床意义的临床问题。&lt;h4&gt;方法&lt;/h4&gt;收集了500名参与者的超过30小时生物力学数据，包括多种运动障碍的患者，并创建了运动相关的问题和答案的多模态数据集，在此基础上开发了BiomechGPT模型。&lt;h4&gt;主要发现&lt;/h4&gt;BiomechGPT在活动识别、运动障碍识别、诊断、临床结果评分和步行测量等多个任务上表现出高性能。&lt;h4&gt;结论&lt;/h4&gt;BiomechGPT为康复运动数据的基础模型提供了一个重要步骤。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Advances in markerless motion capture are expanding access to biomechanical movement analysis, making it feasible to obtain high-quality movement data from outpatient clinics, inpatient hospitals, therapy, and even home. Expanding access to movement data in these diverse contexts makes the challenge of performing downstream analytics all the more acute. Creating separate bespoke analysis code for all the tasks end users might want is both intractable and does not take advantage of the common features of human movement underlying them all. Recent studies have shown that fine-tuning language models to accept tokenized movement as an additional modality enables successful descriptive captioning of movement. Here, we explore whether such a multimodal motion-language model can answer detailed, clinically meaningful questions about movement. We collected over 30 hours of biomechanics from nearly 500 participants, many with movement impairments from a variety of etiologies, performing a range of movements used in clinical outcomes assessments. After tokenizing these movement trajectories, we created a multimodal dataset of motion-related questions and answers spanning a range of tasks. We developed BiomechGPT, a multimodal biomechanics-language model, on this dataset. Our results show that BiomechGPT demonstrates high performance across a range of tasks such as activity recognition, identifying movement impairments, diagnosis, scoring clinical outcomes, and measuring walking. BiomechGPT provides an important step towards a foundation model for rehabilitation movement data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advances in markerless motion capture are expanding access to biomechanicalmovement analysis, making it feasible to obtain high-quality movement data fromoutpatient clinics, inpatient hospitals, therapy, and even home. Expandingaccess to movement data in these diverse contexts makes the challenge ofperforming downstream analytics all the more acute. Creating separate bespokeanalysis code for all the tasks end users might want is both intractable anddoes not take advantage of the common features of human movement underlyingthem all. Recent studies have shown that fine-tuning language models to accepttokenized movement as an additional modality enables successful descriptivecaptioning of movement. Here, we explore whether such a multimodalmotion-language model can answer detailed, clinically meaningful questionsabout movement. We collected over 30 hours of biomechanics from nearly 500participants, many with movement impairments from a variety of etiologies,performing a range of movements used in clinical outcomes assessments. Aftertokenizing these movement trajectories, we created a multimodal dataset ofmotion-related questions and answers spanning a range of tasks. We developedBiomechGPT, a multimodal biomechanics-language model, on this dataset. Ourresults show that BiomechGPT demonstrates high performance across a range oftasks such as activity recognition, identifying movement impairments,diagnosis, scoring clinical outcomes, and measuring walking. BiomechGPTprovides an important step towards a foundation model for rehabilitationmovement data.</description>
      <author>example@mail.com (Ruize Yang, Ann Kennedy, R. James Cotton)</author>
      <guid isPermaLink="false">2505.18465v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>$μ$-MoE: Test-Time Pruning as Micro-Grained Mixture-of-Experts</title>
      <link>http://arxiv.org/abs/2505.18451v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;为了应对大型基础模型巨大的计算需求，引入了无需重新训练的激活感知压缩技术。然而，由于这些技术依赖于校准数据，对于未知的下游任务可能存在领域偏移。通过计算高效校准，可以实现针对每个提示的适应性激活感知剪枝，同时在推理阶段降低复杂性。将此方法表述为一种称为μ-MoE的微专家混合模型。实验表明，μ-MoE可以动态适应任务/提示相关的结构化稀疏性。&lt;h4&gt;背景&lt;/h4&gt;针对大型基础模型巨大的计算需求，激活感知压缩技术被引入以减少计算量。&lt;h4&gt;目的&lt;/h4&gt;解决由于激活感知压缩技术依赖于校准数据，可能导致的领域偏移问题，同时实现推理阶段的复杂性降低。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为μ-MoE的微专家混合模型，通过计算高效的校准，实现对每个提示的适应性激活感知剪枝。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明μ-MoE能够动态适应任务/提示相关的结构化稀疏性。&lt;h4&gt;结论&lt;/h4&gt;μ-MoE方法在减少计算复杂性的同时，能够适应不同任务和提示，有效解决领域偏移问题。&lt;h4&gt;翻译&lt;/h4&gt;为了应对大型基础模型巨大的计算需求，无需重新训练的激活感知压缩技术被引入。然而，由于这些技术依赖于校准数据，对于未知的下游任务可能存在领域偏移。通过计算高效的校准，可以实现针对每个提示的适应性激活感知剪枝，同时在推理阶段降低复杂性。我们将此方法表述为一种称为μ-MoE的微专家混合模型。几个实验表明μ-MoE可以动态适应任务/提示相关的结构化稀疏性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To tackle the huge computational demand of large foundation models,activation-aware compression techniques without retraining have beenintroduced. However, since these rely on calibration data, domain shift mayarise for unknown downstream tasks. With a computationally efficientcalibration, activation-aware pruning can be executed for every promptadaptively, yet achieving reduced complexity at inference. We formulate it as amixture of micro-experts, called $\mu$-MoE. Several experiments demonstratethat $\mu$-MoE can dynamically adapt to task/prompt-dependent structuredsparsity on the fly.</description>
      <author>example@mail.com (Toshiaki Koike-Akino, Jing Liu, Ye Wang)</author>
      <guid isPermaLink="false">2505.18451v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Reinforcement Twinning for Hybrid Control of Flapping-Wing Drones</title>
      <link>http://arxiv.org/abs/2505.18201v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于强化学习双胞胎算法的混合模型驱动/模型自由飞行控制方法，用于控制振翼飞行器的飞行。&lt;h4&gt;背景&lt;/h4&gt;控制振翼飞行器需要能够处理时间变化、非线性和欠驱动动力学，同时还要处理不完整和噪声的传感器数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的混合控制方法，以解决基于模型的方法在精确建模上的困难，以及无模型方法在高效导航高维非线性控制目标景观上的不足。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了基于模型的方法（MB）和无模型的方法（MF），其中MB方法使用自适应数字双胞胎进行伴随形式化，MF方法使用强化学习。两个代理通过迁移学习、模仿学习和经验共享在真实环境、数字双胞胎和裁判之间协作。裁判根据数字双胞胎内的性能和真实到虚拟环境的一致性比率选择与真实环境交互的最佳代理。&lt;h4&gt;主要发现&lt;/h4&gt;该算法在控制振翼飞行器的纵向动力学方面进行了评估，环境被模拟为受准稳态气动力影响的非线性、时变动力学系统。通过三种自适应模型初始化方法测试了混合控制学习方法：1）使用先前可用数据的离线识别，2）随机初始化并完全在线识别，3）使用估计偏差的离线预训练，然后在线适应。在所有三种情况下，所提出的混合学习方法都表现出比纯模型自由和无模型方法更优的性能。&lt;h4&gt;结论&lt;/h4&gt;混合控制学习方法在控制振翼飞行器方面表现出色，优于纯模型自由和无模型方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Controlling the flight of flapping-wing drones requires versatile controllersthat handle their time-varying, nonlinear, and underactuated dynamics fromincomplete and noisy sensor data. Model-based methods struggle with accuratemodeling, while model-free approaches falter in efficiently navigating veryhigh-dimensional and nonlinear control objective landscapes. This articlepresents a novel hybrid model-free/model-based approach to flight control basedon the recently proposed reinforcement twinning algorithm. The model-based (MB)approach relies on an adjoint formulation using an adaptive digital twin,continuously identified from live trajectories, while the model-free (MF)approach relies on reinforcement learning. The two agents collaborate throughtransfer learning, imitation learning, and experience sharing using the realenvironment, the digital twin and a referee. The latter selects the best agentto interact with the real environment based on performance within the digitaltwin and a real-to-virtual environment consistency ratio. The algorithm isevaluated for controlling the longitudinal dynamics of a flapping-wing drone,with the environment simulated as a nonlinear, time-varying dynamical systemunder the influence of quasi-steady aerodynamic forces. The hybrid controllearning approach is tested with three types of initialization of the adaptivemodel: (1) offline identification using previously available data, (2) randominitialization with full online identification, and (3) offline pre-trainingwith an estimation bias, followed by online adaptation. In all three scenarios,the proposed hybrid learning approach demonstrates superior performancecompared to purely model-free and model-based methods.</description>
      <author>example@mail.com (Romain Poletti, Lorenzo Schena, Lilla Koloszar, Joris Degroote, Miguel Alfonso Mendez)</author>
      <guid isPermaLink="false">2505.18201v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    <item>
      <title>Weather-Magician: Reconstruction and Rendering Framework for 4D Weather Synthesis In Real Time</title>
      <link>http://arxiv.org/abs/2505.19919v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project homepage: https://weathermagician.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于高斯散点插值的框架，用于重建和渲染具有合成4D天气效果的实时场景。&lt;h4&gt;背景&lt;/h4&gt;传统工业方法在制作城市数字孪生、VR/AR游戏场景设计或合成电影时，通常需要手动建模场景并使用各种渲染引擎，这种方法成本高、硬件需求大，且在复制复杂真实场景时质量较差。&lt;h4&gt;目的&lt;/h4&gt;提出一种更有效的方法，使用捕获的真实场景数据，通过重建和渲染算法快速重现逼真的场景，并解决现有算法无法有效重建和渲染真实世界天气效果的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于高斯散点插值的框架，该框架能够重建真实场景并在合成4D天气效果下进行渲染。通过应用高斯建模和渲染技术，可以模拟各种常见的天气效果，支持连续动态的天气变化，并易于控制效果的细节。&lt;h4&gt;主要发现&lt;/h4&gt;该框架具有低硬件要求，并实现了实时渲染性能。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法能够有效解决现有算法在重建和渲染真实世界天气效果方面的不足，为相关领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;For tasks such as urban digital twins, VR/AR/game scene design, or creating synthetic films, the traditional industrial approach often involves manually modeling scenes and using various rendering engines to complete the rendering process. This approach typically requires high labor costs and hardware demands, and can result in poor quality when replicating complex real-world scenes. A more efficient approach is to use data from captured real-world scenes, then apply reconstruction and rendering algorithms to quickly recreate the authentic scene. However, current algorithms are unable to effectively reconstruct and render real-world weather effects. To address this, we propose a framework based on gaussian splatting, that can reconstruct real scenes and render them under synthesized 4D weather effects. Our work can simulate various common weather effects by applying Gaussians modeling and rendering techniques. It supports continuous dynamic weather changes and can easily control the details of the effects. Additionally, our work has low hardware requirements and achieves real-time rendering performance. The result demos can be accessed on our project homepage: weathermagician.github.io&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For tasks such as urban digital twins, VR/AR/game scene design, or creatingsynthetic films, the traditional industrial approach often involves manuallymodeling scenes and using various rendering engines to complete the renderingprocess. This approach typically requires high labor costs and hardwaredemands, and can result in poor quality when replicating complex real-worldscenes. A more efficient approach is to use data from captured real-worldscenes, then apply reconstruction and rendering algorithms to quickly recreatethe authentic scene. However, current algorithms are unable to effectivelyreconstruct and render real-world weather effects. To address this, we proposea framework based on gaussian splatting, that can reconstruct real scenes andrender them under synthesized 4D weather effects. Our work can simulate variouscommon weather effects by applying Gaussians modeling and rendering techniques.It supports continuous dynamic weather changes and can easily control thedetails of the effects. Additionally, our work has low hardware requirementsand achieves real-time rendering performance. The result demos can be accessedon our project homepage: weathermagician.github.io</description>
      <author>example@mail.com (Chen Sang, Yeqiang Qian, Jiale Zhang, Chunxiang Wang, Ming Yang)</author>
      <guid isPermaLink="false">2505.19919v1</guid>
      <pubDate>Tue, 27 May 2025 14:42:15 +0800</pubDate>
    </item>
    </channel>
</rss>