<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 15 Apr 2025 14:28:49 +0800</lastBuildDate>
    <item>
      <title>GeoUni: A Unified Model for Generating Geometry Diagrams, Problems and Problem Solutions</title>
      <link>http://arxiv.org/abs/2504.10146v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GeoUni是一种统一的几何专家模型，能够在单个框架内生成问题解决方案和图表，创建独特和个性化的几何问题。&lt;h4&gt;背景&lt;/h4&gt;传统的机器学习处理几何问题的解决和图表生成是两个独立的任务，没有模型能够成功整合这两个功能以支持问题创建。&lt;h4&gt;目的&lt;/h4&gt;GeoUni旨在通过无缝集成解决几何问题的所有技能（从解决问题到可视化几何关系，再到定制问题）来掌握几何。&lt;h4&gt;方法&lt;/h4&gt;GeoUni使用了1.5B参数，在几何推理任务中达到了与DeepSeek-R1（671B参数）相当的性能，并且能够生成精确的几何图表，超越了文本到图像模型和统一模型，包括GPT-4o图像生成。&lt;h4&gt;主要发现&lt;/h4&gt;GeoUni是唯一能够基于特定知识点成功生成匹配图表的文本问题的模型，从而提供超越现有模型的更广泛的能力。&lt;h4&gt;结论&lt;/h4&gt;GeoUni通过整合几何问题的解决和图表生成，在几何推理和图表生成方面表现出色，并且具有创建个性化几何问题的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose GeoUni, the first unified geometry expert model capable ofgenerating problem solutions and diagrams within a single framework in a waythat enables the creation of unique and individualized geometry problems.Traditionally, solving geometry problems and generating diagrams have beentreated as separate tasks in machine learning, with no models successfullyintegrating both to support problem creation. However, we believe that masteryin geometry requires frictionless integration of all of these skills, fromsolving problems to visualizing geometric relationships, and finally, craftingtailored problems. Our extensive experiments demonstrate that GeoUni, with only1.5B parameters, achieves performance comparable to larger models such asDeepSeek-R1 with 671B parameters in geometric reasoning tasks. GeoUni alsoexcels in generating precise geometric diagrams, surpassing both text-to-imagemodels and unified models, including the GPT-4o image generation. Mostimportantly, GeoUni is the only model capable of successfully generatingtextual problems with matching diagrams based on specific knowledge points,thus offering a wider range of capabilities that extend beyond current models.</description>
      <author>example@mail.com (Jo-Ku Cheng, Zeren Zhang, Ran Chen, Jingyang Deng, Ziran Qin, Jinwen Ma)</author>
      <guid isPermaLink="false">2504.10146v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
  <item>
      <title>Foundation models for electronic health records: representation dynamics and transferability</title>
      <link>http://arxiv.org/abs/2504.10422v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于电子健康记录的基金会模型在临床预测任务中的性能，并评估了模型在不同医疗体系中的适应性和可移植性。&lt;h4&gt;背景&lt;/h4&gt;虽然基于电子健康记录的基金会模型在临床预测任务中表现出色，但将其适应到本地医疗体系中由于数据可用性和资源限制而存在挑战。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在调查这些模型学到了什么，评估在MIMIC-IV上训练的基金会模型转移到芝加哥大学医学中心机构电子健康记录数据集的可移植性。&lt;h4&gt;方法&lt;/h4&gt;研究了模型识别异常患者的能力，并考察了与未来临床结果相关的表示空间中患者轨迹。此外，还在源数据和目标数据集上评估了监督微调分类器的性能。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果提供了关于基金会模型在不同医疗体系间适应性的见解，强调了有效实施时的考虑因素，并对有助于其预测性能的潜在因素进行了实证分析。&lt;h4&gt;结论&lt;/h4&gt;本研究对基金会模型在不同医疗体系中的适应性进行了实证研究，为模型的有效实施提供了指导，并对模型预测性能背后的因素进行了深入分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) trained on electronic health records (EHRs) haveshown strong performance on a range of clinical prediction tasks. However,adapting these models to local health systems remains challenging due tolimited data availability and resource constraints. In this study, weinvestigated what these models learn and evaluated the transferability of an FMtrained on MIMIC-IV to an institutional EHR dataset at the University ofChicago Medical Center. We assessed their ability to identify outlier patientsand examined representation-space patient trajectories in relation to futureclinical outcomes. We also evaluated the performance of supervised fine-tunedclassifiers on both source and target datasets. Our findings offer insightsinto the adaptability of FMs across different healthcare systems, highlightconsiderations for their effective implementation, and provide an empiricalanalysis of the underlying factors that contribute to their predictiveperformance.</description>
      <author>example@mail.com (Michael C. Burkhart, Bashar Ramadan, Zewei Liao, Kaveri Chhikara, Juan C. Rojas, William F. Parker, Brett K. Beaulieu-Jones)</author>
      <guid isPermaLink="false">2504.10422v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Combining Forecasts using Meta-Learning: A Comparative Study for Complex Seasonality</title>
      <link>http://arxiv.org/abs/2504.08940v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE 10th International Conference on Data Science and Advanced  Analytics, DSAA'23, pp. 1-10, 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了通过元学习结合不同类型模型生成的预测，以提高预测准确性。&lt;h4&gt;背景&lt;/h4&gt;传统的预测结合方法通常涉及简单的平均，而机器学习技术通过元学习实现了更复杂的结合方法。&lt;h4&gt;目的&lt;/h4&gt;通过元学习提高预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;使用线性回归、k近邻、多层感知器、随机森林和长短期记忆作为元学习器。定义了针对具有复杂季节性的时间序列的全球和局部元学习变体，并在多个预测问题上对元学习器进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;元学习器在多个预测问题上的表现优于简单的平均方法。&lt;h4&gt;结论&lt;/h4&gt;元学习在结合不同类型模型生成的预测中具有优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we investigate meta-learning for combining forecasts generated by models of different types. While typical approaches for combining forecasts involve simple averaging, machine learning techniques enable more sophisticated methods of combining through meta-learning, leading to improved forecasting accuracy. We use linear regression, $k$-nearest neighbors, multilayer perceptron, random forest, and long short-term memory as meta-learners. We define global and local meta-learning variants for time series with complex seasonality and compare meta-learners on multiple forecasting problems, demonstrating their superior performance compared to simple averaging.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/DSAA60987.2023.10302585&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we investigate meta-learning for combining forecasts generatedby models of different types. While typical approaches for combining forecastsinvolve simple averaging, machine learning techniques enable more sophisticatedmethods of combining through meta-learning, leading to improved forecastingaccuracy. We use linear regression, $k$-nearest neighbors, multilayerperceptron, random forest, and long short-term memory as meta-learners. Wedefine global and local meta-learning variants for time series with complexseasonality and compare meta-learners on multiple forecasting problems,demonstrating their superior performance compared to simple averaging.</description>
      <author>example@mail.com (Grzegorz Dudek)</author>
      <guid isPermaLink="false">2504.08940v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Long Video Modeling Based on Temporal Dynamic Context</title>
      <link>http://arxiv.org/abs/2504.10443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Temporal Dynamic Context (TDC)的动态长视频编码方法，以解决现有长视频理解模型在处理长视频时信息丢失和模态融合问题。&lt;h4&gt;背景&lt;/h4&gt;虽然大型语言模型（LLMs）在视频理解方面取得了显著进展，但现有的模型仍然难以处理长视频，因为LLMs的上下文长度限制和视频中的大量信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效处理长视频的编码方法，减少信息丢失，并融合视频和音频等多模态信息。&lt;h4&gt;方法&lt;/h4&gt;1. 将视频分割成语义上一致的场景；2. 使用视觉-音频编码器将每帧编码成标记；3. 提出一种新颖的时间上下文压缩器，以减少每个段落的标记数量；4. 使用基于查询的Transformer聚合视频、音频和指令文本标记；5. 将静态帧标记和时间上下文标记输入LLM进行视频理解；6. 提出一种无训练的思考链策略，用于处理极长视频。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在通用视频理解和音视频理解基准测试中表现出色。&lt;h4&gt;结论&lt;/h4&gt;Temporal Dynamic Context (TDC)方法能够有效处理长视频，并在视频理解任务中取得良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;最近，大型语言模型（LLMs）在视频理解方面的进步导致了显著的突破。然而，由于LLMs的上下文长度限制和视频中的大量信息，现有的模型在处理长视频时仍然存在困难。尽管一些最近的方法是为长视频理解设计的，但它们在标记压缩过程中通常会丢失关键信息，并且难以处理音频等附加模态。在本工作中，我们提出了一种利用帧之间时间关系的动态长视频编码方法，称为Temporal Dynamic Context（TDC）。首先，我们根据帧间的相似性将视频分割成语义上一致的场景，然后使用视觉-音频编码器将每个帧编码成标记。其次，我们提出了一种新颖的时间上下文压缩器，以减少每个段落的标记数量。具体来说，我们采用基于查询的Transformer将视频、音频和指令文本标记聚合到一组有限的时间上下文标记中。最后，我们将静态帧标记和时间上下文标记输入LLM进行视频理解。此外，为了处理极长视频，我们提出了一种无需训练的思考链策略，该策略逐步从多个视频段中提取答案。这些中间答案作为推理过程的一部分，有助于最终答案。我们在通用视频理解和音视频理解基准测试上进行了广泛的实验，我们的方法在这些实验中表现出了强大的性能。代码和模型可在https://github.com/Hoar012/TDC-Video上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Large Language Models (LLMs) have led to significantbreakthroughs in video understanding. However, existing models still strugglewith long video processing due to the context length constraint of LLMs and thevast amount of information within the video. Although some recent methods aredesigned for long video understanding, they often lose crucial informationduring token compression and struggle with additional modality like audio. Inthis work, we propose a dynamic long video encoding method utilizing thetemporal relationship between frames, named Temporal Dynamic Context (TDC).Firstly, we segment the video into semantically consistent scenes based oninter-frame similarities, then encode each frame into tokens using visual-audioencoders. Secondly, we propose a novel temporal context compressor to reducethe number of tokens within each segment. Specifically, we employ a query-basedTransformer to aggregate video, audio, and instruction text tokens into alimited set of temporal context tokens. Finally, we feed the static frametokens and the temporal context tokens into the LLM for video understanding.Furthermore, to handle extremely long videos, we propose a training-freechain-of-thought strategy that progressively extracts answers from multiplevideo segments. These intermediate answers serve as part of the reasoningprocess and contribute to the final answer. We conduct extensive experiments ongeneral video understanding and audio-video understanding benchmarks, where ourmethod demonstrates strong performance. The code and models are available athttps://github.com/Hoar012/TDC-Video.</description>
      <author>example@mail.com (Haoran Hao, Jiaming Han, Yiyuan Zhang, Xiangyu Yue)</author>
      <guid isPermaLink="false">2504.10443v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>LMFormer: Lane based Motion Prediction Transformer</title>
      <link>http://arxiv.org/abs/2504.10275v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted: Autonomous Driving Workshop, CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LMFormer的路径预测网络，用于自动驾驶中的运动预测。&lt;h4&gt;背景&lt;/h4&gt;运动预测在自动驾驶中扮演着重要角色。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提供一种简单机制动态优先级排序车道，并引入网络学习行为的可解释性。&lt;h4&gt;方法&lt;/h4&gt;LMFormer使用车道连接信息学习车道结构中的长距离依赖，并提出了一种通过堆叠变换器层进行迭代精炼预测轨迹的有效方法。&lt;h4&gt;主要发现&lt;/h4&gt;LMFormer在多个指标上实现了SOTA性能，并展示了跨数据集网络性能以及LMFormer在多个数据集上训练并取得更好性能的统一能力。&lt;h4&gt;结论&lt;/h4&gt;LMFormer是一种有效的路径预测网络，在自动驾驶中具有广泛应用前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要：运动预测在自动驾驶中起着重要作用。本研究提出了LMFormer，一种用于轨迹预测任务的车道感知变换器网络。与先前的研究相比，我们的工作提供了一个简单的机制来动态优先级排序车道，并表明这种机制引入了网络学习行为的可解释性。此外，LMFormer使用交叉口、车道合并和车道分叉的车道连接信息，以学习车道结构中的长距离依赖。此外，我们还解决了预测轨迹的细化问题，并提出了一种通过堆叠变换器层进行迭代精炼的有效方法。为了基准测试，我们在nuScenes数据集上评估了LMFormer，并证明它在多个指标上实现了SOTA性能。此外，还使用了Deep Scenario数据集，不仅说明了跨数据集网络性能，还说明了LMFormer在多个数据集上训练并取得更好性能的统一能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motion prediction plays an important role in autonomous driving. This studypresents LMFormer, a lane-aware transformer network for trajectory predictiontasks. In contrast to previous studies, our work provides a simple mechanism todynamically prioritize the lanes and shows that such a mechanism introducesexplainability into the learning behavior of the network. Additionally,LMFormer uses the lane connection information at intersections, lane merges,and lane splits, in order to learn long-range dependency in lane structure.Moreover, we also address the issue of refining the predicted trajectories andpropose an efficient method for iterative refinement through stackedtransformer layers. For benchmarking, we evaluate LMFormer on the nuScenesdataset and demonstrate that it achieves SOTA performance across multiplemetrics. Furthermore, the Deep Scenario dataset is used to not only illustratecross-dataset network performance but also the unification capabilities ofLMFormer to train on multiple datasets and achieve better performance.</description>
      <author>example@mail.com (Harsh Yadav, Maximilian Schaefer, Kun Zhao, Tobias Meisen)</author>
      <guid isPermaLink="false">2504.10275v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis</title>
      <link>http://arxiv.org/abs/2504.10352v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ACM MM 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的伪自回归（PAR）编解码器语言建模方法，该方法统一了自回归（AR）和非自回归（NAR）建模。通过结合AR模型的显式时间建模和NAR模型的并行生成，PAR能够在固定时间步长生成动态长度的跨度。基于PAR，提出了PALLE，一个两阶段TTS系统，利用PAR进行初始生成，随后进行NAR细化。&lt;h4&gt;背景&lt;/h4&gt;现有的零样本文本到语音（TTS）系统面临共同困境：自回归模型在生成速度上较慢且缺乏时长控制能力，而非自回归模型缺乏时间建模且通常需要复杂的设计。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的TTS系统，解决现有零样本TTS系统中自回归模型和非自回归模型的问题。&lt;h4&gt;方法&lt;/h4&gt;采用PAR codec语言建模方法，结合AR模型的显式时间建模和NAR模型的并行生成。PALLE系统包括两个阶段：第一阶段使用PAR逐步生成语音标记，每步并行预测所有位置但只保留最左侧跨度；第二阶段迭代地并行细化低置信度标记，利用全局上下文信息。&lt;h4&gt;主要发现&lt;/h4&gt;在LibriTTS上训练的PALLE系统在LibriSpeech test-clean数据集上，在语音质量、说话人相似度和可懂度方面优于使用大规模数据训练的F5-TTS、E2-TTS和MaskGCT等最先进系统，同时推理速度可达十倍。&lt;h4&gt;结论&lt;/h4&gt;PALLE系统在保持高语音质量的同时，实现了快速推理，为TTS系统提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a novel pseudo-autoregressive (PAR) codec language modeling approach that unifies autoregressive (AR) and non-autoregressive (NAR) modeling. By combining explicit temporal modeling from AR with parallel generation from NAR, PAR generates dynamic-length spans at fixed time steps. Based on PAR, we propose PALLE, a two-stage TTS system that leverages PAR for initial generation followed by NAR refinement. In the first stage, PAR progressively generates speech tokens along the time dimension, with each step predicting all positions in parallel but only retaining the left-most span. In the second stage, low-confidence tokens are iteratively refined in parallel, leveraging the global contextual information. Experiments demonstrate that PALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on large-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech test-clean set in terms of speech quality, speaker similarity, and intelligibility, while achieving up to ten times faster inference speed. Audio samples are available at https://anonymous-palle.github.io.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent zero-shot text-to-speech (TTS) systems face a common dilemma:autoregressive (AR) models suffer from slow generation and lack durationcontrollability, while non-autoregressive (NAR) models lack temporal modelingand typically require complex designs. In this paper, we introduce a novelpseudo-autoregressive (PAR) codec language modeling approach that unifies ARand NAR modeling. Combining explicit temporal modeling from AR with parallelgeneration from NAR, PAR generates dynamic-length spans at fixed time steps.Building on PAR, we propose PALLE, a two-stage TTS system that leverages PARfor initial generation followed by NAR refinement. In the first stage, PARprogressively generates speech tokens along the time dimension, with each steppredicting all positions in parallel but only retaining the left-most span. Inthe second stage, low-confidence tokens are iteratively refined in parallel,leveraging the global contextual information. Experiments demonstrate thatPALLE, trained on LibriTTS, outperforms state-of-the-art systems trained onlarge-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeechtest-clean set in terms of speech quality, speaker similarity, andintelligibility, while achieving up to ten times faster inference speed. Audiosamples are available at https://anonymous-palle.github.io.</description>
      <author>example@mail.com (Yifan Yang, Shujie Liu, Jinyu Li, Yuxuan Hu, Haibin Wu, Hui Wang, Jianwei Yu, Lingwei Meng, Haiyang Sun, Yanqing Liu, Yan Lu, Kai Yu, Xie Chen)</author>
      <guid isPermaLink="false">2504.10352v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>MonoDiff9D: Monocular Category-Level 9D Object Pose Estimation via Diffusion Model</title>
      <link>http://arxiv.org/abs/2504.10433v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MonoDiff9D是一种基于扩散的9D单目对象姿态估计方法，无需形状先验或CAD模型即可实现高精度的对象姿态估计。&lt;h4&gt;背景&lt;/h4&gt;对象姿态估计对于机器人理解和交互环境至关重要，单目方法因其只需要单个RGB相机而受到青睐。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需形状先验、CAD模型或深度传感器的单目9D对象姿态估计方法。&lt;h4&gt;方法&lt;/h4&gt;首先使用DINOv2在零样本方式下估计粗略深度并将其转换为点云；然后融合点云的全局特征和输入图像；最后，使用融合的特征和时间步长来条件化MonoDiff9D，并通过基于transformer的降噪器从高斯噪声中恢复对象姿态。&lt;h4&gt;主要发现&lt;/h4&gt;在两个流行的基准数据集上，MonoDiff9D实现了在没有形状先验或CAD模型的情况下最先进的单目9D对象姿态估计精度。&lt;h4&gt;结论&lt;/h4&gt;MonoDiff9D代码将公开在https://github.com/CNJianLiu/MonoDiff9D上。&lt;h4&gt;翻译&lt;/h4&gt;对象姿态估计是机器人理解和交互环境的核心手段。对于这一任务，单目分类级方法因其仅需单个RGB相机而具有吸引力。然而，当前方法依赖于形状先验或已知对象内类的CAD模型。我们提出了一种基于扩散的单目分类级9D对象姿态生成方法，称为MonoDiff9D。我们的动机是利用扩散模型的概率性质来减轻对形状先验、CAD模型或深度传感器对内类未知对象姿态估计的需求。我们首先以零样本方式从单目图像中估计粗略深度，并将其转换为点云。然后，我们将点云的全局特征与输入图像融合，并使用融合的特征以及编码的时间步长来条件化MonoDiff9D。最后，我们设计了一种基于transformer的降噪器，以从高斯噪声中恢复对象姿态。在两个流行基准数据集上的大量实验表明，MonoDiff9D在不需要任何阶段的形状先验或CAD模型的情况下实现了最先进的单目分类级9D对象姿态估计精度。我们的代码将公开在https://github.com/CNJianLiu/MonoDiff9D上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object pose estimation is a core means for robots to understand and interactwith their environment. For this task, monocular category-level methods areattractive as they require only a single RGB camera. However, current methodsrely on shape priors or CAD models of the intra-class known objects. We proposea diffusion-based monocular category-level 9D object pose generation method,MonoDiff9D. Our motivation is to leverage the probabilistic nature of diffusionmodels to alleviate the need for shape priors, CAD models, or depth sensors forintra-class unknown object pose estimation. We first estimate coarse depth viaDINOv2 from the monocular image in a zero-shot manner and convert it into apoint cloud. We then fuse the global features of the point cloud with the inputimage and use the fused features along with the encoded time step to conditionMonoDiff9D. Finally, we design a transformer-based denoiser to recover theobject pose from Gaussian noise. Extensive experiments on two popular benchmarkdatasets show that MonoDiff9D achieves state-of-the-art monocularcategory-level 9D object pose estimation accuracy without the need for shapepriors or CAD models at any stage. Our code will be made public athttps://github.com/CNJianLiu/MonoDiff9D.</description>
      <author>example@mail.com (Jian Liu, Wei Sun, Hui Yang, Jin Zheng, Zichen Geng, Hossein Rahmani, Ajmal Mian)</author>
      <guid isPermaLink="false">2504.10433v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>SoccerNet-v3D: Leveraging Sports Broadcast Replays for 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2504.10106v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SoccerNet-v3D和ISSIA-3D两个用于足球转播分析中3D场景理解的数据集，并提出了单目3D球定位方法，以及用于评估标注质量的指标和优化技术。&lt;h4&gt;背景&lt;/h4&gt;体育视频分析是计算机视觉的关键领域，通过多视图对应关系实现详细的空间理解。&lt;h4&gt;目的&lt;/h4&gt;建立新的基准，增强体育分析中的空间和时间分析。&lt;h4&gt;方法&lt;/h4&gt;提出了基于三角测量的单目3D球定位任务，并引入了基于场线摄像校准和多视图同步的扩展数据集，以及用于评估标注质量的校准和重投影指标。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入场线摄像校准和多视图同步，实现了3D物体定位；提出了单目3D球定位方法作为基线；引入了边界框优化技术以细化2D标注。&lt;h4&gt;结论&lt;/h4&gt;提出的SoccerNet-v3D和ISSIA-3D数据集为3D足球场景理解提供了新的基准，提高了体育分析中的空间和时间分析能力。&lt;h4&gt;翻译&lt;/h4&gt;Sports video analysis is a key domain in computer vision, enabling detailed spatial understanding through multi-view correspondences. In this work, we introduce SoccerNet-v3D and ISSIA-3D, two enhanced and scalable datasets designed for 3D scene understanding in soccer broadcast analysis. These datasets extend SoccerNet-v3 and ISSIA by incorporating field-line-based camera calibration and multi-view synchronization, enabling 3D object localization through triangulation. We propose a monocular 3D ball localization task built upon the triangulation of ground-truth 2D ball annotations, along with several calibration and reprojection metrics to assess annotation quality on demand. Additionally, we present a single-image 3D ball localization method as a baseline, leveraging camera calibration and ball size priors to estimate the ball's position from a monocular viewpoint. To further refine 2D annotations, we introduce a bounding box optimization technique that ensures alignment with the 3D scene representation. Our proposed datasets establish new benchmarks for 3D soccer scene understanding, enhancing both spatial and temporal analysis in sports analytics. Finally, we provide code to facilitate access to our annotations and the generation pipelines for the datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sports video analysis is a key domain in computer vision, enabling detailedspatial understanding through multi-view correspondences. In this work, weintroduce SoccerNet-v3D and ISSIA-3D, two enhanced and scalable datasetsdesigned for 3D scene understanding in soccer broadcast analysis. Thesedatasets extend SoccerNet-v3 and ISSIA by incorporating field-line-based cameracalibration and multi-view synchronization, enabling 3D object localizationthrough triangulation. We propose a monocular 3D ball localization task builtupon the triangulation of ground-truth 2D ball annotations, along with severalcalibration and reprojection metrics to assess annotation quality on demand.Additionally, we present a single-image 3D ball localization method as abaseline, leveraging camera calibration and ball size priors to estimate theball's position from a monocular viewpoint. To further refine 2D annotations,we introduce a bounding box optimization technique that ensures alignment withthe 3D scene representation. Our proposed datasets establish new benchmarks for3D soccer scene understanding, enhancing both spatial and temporal analysis insports analytics. Finally, we provide code to facilitate access to ourannotations and the generation pipelines for the datasets.</description>
      <author>example@mail.com (Marc Gutiérrez-Pérez, Antonio Agudo)</author>
      <guid isPermaLink="false">2504.10106v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Satellite Federated Fine-Tuning for Foundation Models in Space Computing Power Networks</title>
      <link>http://arxiv.org/abs/2504.10403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种卫星-地面协同联邦微调框架，旨在解决大型基础模型在卫星上进行微调时的计算能力不足和通信挑战。&lt;h4&gt;背景&lt;/h4&gt;随着人工智能和低地球轨道卫星的发展，大型遥感基础模型在地面进行微调受到隐私和带宽限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种卫星-地面协同联邦微调框架，以解决卫星计算能力不足和通信挑战。&lt;h4&gt;方法&lt;/h4&gt;该框架通过合理分解和分配模型组件，减轻卫星计算能力不足的问题。在微调过程中，卫星与地面站或其他卫星交换中间结果，以应对空间传输网络中的通信挑战。此外，还引入了定制通信策略，包括并行轨道内通信策略、拓扑感知卫星-地面通信策略和最小化延迟的轨道间通信策略，以减少空间通信成本。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，采用该框架可以显著减少训练时间，提高约33%。&lt;h4&gt;结论&lt;/h4&gt;卫星-地面协同联邦微调框架能够有效解决大型基础模型在卫星上进行微调时的计算能力不足和通信挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advancements in artificial intelligence (AI) and low-earth orbit (LEO)satellites have promoted the application of large remote sensing foundationmodels for various downstream tasks. However, direct downloading of thesemodels for fine-tuning on the ground is impeded by privacy concerns and limitedbandwidth. Satellite federated learning (FL) offers a solution by enablingmodel fine-tuning directly on-board satellites and aggregating model updateswithout data downloading. Nevertheless, for large foundation models, thecomputational capacity of satellites is insufficient to support effectiveon-board fine-tuning in traditional satellite FL frameworks. To address thesechallenges, we propose a satellite-ground collaborative federated fine-tuningframework. The key of the framework lies in how to reasonably decompose andallocate model components to alleviate insufficient on-board computationcapabilities. During fine-tuning, satellites exchange intermediate results withground stations or other satellites for forward propagation and backpropagation, which brings communication challenges due to the specialcommunication topology of space transmission networks, such as intermittentsatellite-ground communication, short duration of satellite-groundcommunication windows, and unstable inter-orbit inter-satellite links (ISLs).To reduce transmission delays, we further introduce tailored communicationstrategies that integrate both communication and computing resources.Specifically, we propose a parallel intra-orbit communication strategy, atopology-aware satellite-ground communication strategy, and alatency-minimalization inter-orbit communication strategy to reduce spacecommunication costs. Simulation results demonstrate significant reductions intraining time with improvements of approximately 33%.</description>
      <author>example@mail.com (Yan zhu, Jingyang zhu, Ting Wang, Yuanming Shi, Chunxiao Jiang, Khaled Ben Letaief)</author>
      <guid isPermaLink="false">2504.10403v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Invariance Matters: Empowering Social Recommendation via Graph Invariant Learning</title>
      <link>http://arxiv.org/abs/2504.10432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Social Graph Invariant Learning（SGIL）方法，用于解决基于图的社会推荐系统中数据稀疏性和社交网络噪声问题，以增强推荐性能。&lt;h4&gt;背景&lt;/h4&gt;基于图的社会推荐系统利用图神经网络（GNNs）捕捉用户偏好，但现有方法往往忽略社交网络的噪声和冗余关系，影响用户偏好学习的准确性。&lt;h4&gt;目的&lt;/h4&gt;提出SGIL方法，旨在从输入社交图中揭示稳定的用户偏好，从而增强基于图的社会推荐系统的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;SGIL通过图生成器模拟多个噪声社交环境，并通过最小化这些环境中的不变风险来学习环境不变的用户偏好。同时，采用对抗性训练策略以生成更多潜在的社会噪声分布，促进生成社交环境的多样性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SGIL方法有效地提高了基于图的社会推荐系统的推荐性能。&lt;h4&gt;结论&lt;/h4&gt;SGIL方法为解决社交推荐系统中的噪声问题提供了一种新的思路，有助于提高推荐系统的准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;Graph-based social recommendation systems have shown significant promise in enhancing recommendation performance, particularly in addressing the issue of data sparsity in user behaviors. Typically, these systems leverage Graph Neural Networks (GNNs) to capture user preferences by incorporating high-order social influences from observed social networks. However, existing graph-based social recommendations often overlook the fact that social networks are inherently noisy, containing task-irrelevant relationships that can hinder accurate user preference learning. The removal of these redundant social relations is crucial, yet it remains challenging due to the lack of ground truth. In this paper, we approach the social denoising problem from the perspective of graph invariant learning and propose a novel method, Social Graph Invariant Learning (SGIL). Specifically, SGIL aims to uncover stable user preferences within the input social graph, thereby enhancing the robustness of graph-based social recommendation systems. To achieve this goal, SGIL first simulates multiple noisy social environments through graph generators. It then seeks to learn environment-invariant user preferences by minimizing invariant risk across these environments. To further promote diversity in the generated social environments, we employ an adversarial training strategy to simulate more potential social noisy distributions. Extensive experimental results demonstrate the effectiveness of the proposed SGIL. The code is available at https://github.com/yimutianyang/SIGIR2025-SGIL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-based social recommendation systems have shown significant promise inenhancing recommendation performance, particularly in addressing the issue ofdata sparsity in user behaviors. Typically, these systems leverage Graph NeuralNetworks (GNNs) to capture user preferences by incorporating high-order socialinfluences from observed social networks. However, existing graph-based socialrecommendations often overlook the fact that social networks are inherentlynoisy, containing task-irrelevant relationships that can hinder accurate userpreference learning. The removal of these redundant social relations iscrucial, yet it remains challenging due to the lack of ground truth. In thispaper, we approach the social denoising problem from the perspective of graphinvariant learning and propose a novel method, Social Graph InvariantLearning(SGIL). Specifically,SGIL aims to uncover stable user preferenceswithin the input social graph, thereby enhancing the robustness of graph-basedsocial recommendation systems. To achieve this goal, SGIL first simulatesmultiple noisy social environments through graph generators. It then seeks tolearn environment-invariant user preferences by minimizing invariant riskacross these environments. To further promote diversity in the generated socialenvironments, we employ an adversarial training strategy to simulate morepotential social noisy distributions. Extensive experimental resultsdemonstrate the effectiveness of the proposed SGIL. The code is available athttps://github.com/yimutianyang/SIGIR2025-SGIL.</description>
      <author>example@mail.com (Yonghui Yang, Le Wu, Yuxin Liao, Zhuangzhuang He, Pengyang Shao, Richang Hong, Meng Wang)</author>
      <guid isPermaLink="false">2504.10432v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Representation Learning Techniques for Comprehensive Facial State Analysis</title>
      <link>http://arxiv.org/abs/2504.10351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICME2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种全面的多模态面部状态分析方法。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型通过整合多模态信息显著提高了特征表示，适用于更广泛的应用。然而，对于理解感知的多模态面部表示研究有限。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够理解和分析面部状态（如动作单元（AU）和情感）的综合且稳健的框架，该框架能够桥接视觉和语言模态。&lt;h4&gt;方法&lt;/h4&gt;1. 编制一个新的多模态面部数据集（MFA），通过利用GPT-4生成详细的多层次语言描述，包括AU和情感描述。2. 引入一个针对AU和情感识别的新型多层次多模态面部基础模型（MF^2），该模型在面部图像的局部和全局层面上进行全面的视觉特征建模。3. 开发了一个解耦微调网络（DFN），能够高效地在不同任务和数据集上调整MF^2。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在AU和情感检测任务上表现出优异的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效提升多模态面部状态分析的准确性和适用性。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal foundation models have significantly improved feature representation by integrating information from multiple modalities, making them highly suitable for a broader set of applications. However, the exploration of multimodal facial representation for understanding perception has been limited. Understanding and analyzing facial states, such as Action Units (AUs) and emotions, require a comprehensive and robust framework that bridges visual and linguistic modalities. In this paper, we present a comprehensive pipeline for multimodal facial state analysis. First, we compile a new Multimodal FaceDataset (MFA) by generating detailed multilevel language descriptions of face, incorporating Action Unit (AU) and emotion descriptions, by leveraging GPT-4o. Second, we introduce a novel Multilevel Multimodal Face Foundation model (MF^2) tailored for Action Unit (AU) and emotion recognition. Our model incorporates comprehensive visual feature modeling at both local and global levels of face image, enhancing its ability to represent detailed facial appearances. This design aligns visual representations with structured AU and emotion descriptions, ensuring effective cross-modal integration. Third, we develop a Decoupled Fine-Tuning Network (DFN) that efficiently adapts MF^2 across various tasks and datasets. This approach not only reduces computational overhead but also broadens the applicability of the foundation model to diverse scenarios. Experimentation show superior performance for AU and emotion detection tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal foundation models have significantly improved featurerepresentation by integrating information from multiple modalities, making themhighly suitable for a broader set of applications. However, the exploration ofmultimodal facial representation for understanding perception has been limited.Understanding and analyzing facial states, such as Action Units (AUs) andemotions, require a comprehensive and robust framework that bridges visual andlinguistic modalities. In this paper, we present a comprehensive pipeline formultimodal facial state analysis. First, we compile a new Multimodal FaceDataset (MFA) by generating detailed multilevel language descriptions of face,incorporating Action Unit (AU) and emotion descriptions, by leveraging GPT-4o.Second, we introduce a novel Multilevel Multimodal Face Foundation model (MF^2)tailored for Action Unit (AU) and emotion recognition. Our model incorporatescomprehensive visual feature modeling at both local and global levels of faceimage, enhancing its ability to represent detailed facial appearances. Thisdesign aligns visual representations with structured AU and emotiondescriptions, ensuring effective cross-modal integration. Third, we develop aDecoupled Fine-Tuning Network (DFN) that efficiently adapts MF^2 across varioustasks and datasets. This approach not only reduces computational overhead butalso broadens the applicability of the foundation model to diverse scenarios.Experimentation show superior performance for AU and emotion detection tasks.</description>
      <author>example@mail.com (Kaiwen Zheng, Xuri Ge, Junchen Fu, Jun Peng, Joemon M. Jose)</author>
      <guid isPermaLink="false">2504.10351v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Pillar-Voxel Fusion Network for 3D Object Detection in Airborne Hyperspectral Point Clouds</title>
      <link>http://arxiv.org/abs/2504.09506v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PiV-AHPC的3D目标检测网络，用于空中高光谱点云（HPCs）数据，以解决融合技术和障碍物遮挡导致的几何-光谱失真问题。&lt;h4&gt;背景&lt;/h4&gt;高光谱点云可以同时描述地面物体的3D空间和光谱信息，但目前的方法在融合高光谱图像和LiDAR点云时，容易产生几何-光谱失真，影响下游任务的表现。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的3D目标检测网络PiV-AHPC。&lt;h4&gt;方法&lt;/h4&gt;PiV-AHPC采用柱状体-体素双分支编码器，分别从HPCs中提取光谱和垂直结构特征，以及从点云中提取准确的3D空间特征。同时，设计了一种多级特征融合机制，增强两个分支之间的信息交互，实现邻域特征对齐和通道自适应选择，从而有机地整合异构特征并减轻几何失真。&lt;h4&gt;主要发现&lt;/h4&gt;在两个空中HPCs数据集上的实验表明，PiV-AHPC具有最先进的检测性能和较高的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;PiV-AHPC是首次尝试针对HPCs任务的3D目标检测网络，能够有效解决现有方法中的几何-光谱失真问题，并在空中应用中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Hyperspectral point clouds (HPCs) can simultaneously characterize 3D spatial and spectral information of ground objects, offering excellent 3D perception and target recognition capabilities. Current approaches for generating HPCs often involve fusion techniques with hyperspectral images and LiDAR point clouds, which inevitably lead to geometric-spectral distortions due to fusion errors and obstacle occlusions. These adverse effects limit their performance in downstream fine-grained tasks across multiple scenarios, particularly in airborne applications. To address these issues, we propose PiV-AHPC, a 3D object detection network for airborne HPCs. To the best of our knowledge, this is the first attempt at this HPCs task. Specifically, we first develop a pillar-voxel dual-branch encoder, where the former captures spectral and vertical structural features from HPCs to overcome spectral distortion, while the latter emphasizes extracting accurate 3D spatial features from point clouds. A multi-level feature fusion mechanism is devised to enhance information interaction between the two branches, achieving neighborhood feature alignment and channel-adaptive selection, thereby organically integrating heterogeneous features and mitigating geometric distortion. Extensive experiments on two airborne HPCs datasets demonstrate that PiV-AHPC possesses state-of-the-art detection performance and high generalization capability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperspectral point clouds (HPCs) can simultaneously characterize 3D spatialand spectral information of ground objects, offering excellent 3D perceptionand target recognition capabilities. Current approaches for generating HPCsoften involve fusion techniques with hyperspectral images and LiDAR pointclouds, which inevitably lead to geometric-spectral distortions due to fusionerrors and obstacle occlusions. These adverse effects limit their performancein downstream fine-grained tasks across multiple scenarios, particularly inairborne applications. To address these issues, we propose PiV-AHPC, a 3Dobject detection network for airborne HPCs. To the best of our knowledge, thisis the first attempt at this HPCs task. Specifically, we first develop apillar-voxel dual-branch encoder, where the former captures spectral andvertical structural features from HPCs to overcome spectral distortion, whilethe latter emphasizes extracting accurate 3D spatial features from pointclouds. A multi-level feature fusion mechanism is devised to enhanceinformation interaction between the two branches, achieving neighborhoodfeature alignment and channel-adaptive selection, thereby organicallyintegrating heterogeneous features and mitigating geometric distortion.Extensive experiments on two airborne HPCs datasets demonstrate that PiV-AHPCpossesses state-of-the-art detection performance and high generalizationcapability.</description>
      <author>example@mail.com (Yanze Jiang, Yanfeng Gu, Xian Li)</author>
      <guid isPermaLink="false">2504.09506v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Negate or Embrace: On How Misalignment Shapes Multimodal Representation Learning</title>
      <link>http://arxiv.org/abs/2504.10143v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  38 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了多模态表示学习，特别是通过图像-文本对进行的多模态对比学习（MMCL），以及如何处理现实数据集中存在的模态间不匹配问题。&lt;h4&gt;背景&lt;/h4&gt;多模态表示学习旨在通过跨模态对齐线索来学习强大的表示。然而，现实数据集常常表现出模态间的不匹配。&lt;h4&gt;目的&lt;/h4&gt;旨在调和缓解和不利用不匹配的两种观点，并为从业者提供实用指南。&lt;h4&gt;方法&lt;/h4&gt;使用潜在变量模型，通过引入选择偏差和扰动偏差两种机制来形式化不匹配。选择偏差指某些语义变量缺失，扰动偏差指语义变量被扭曲，这两种偏差都影响跨模态共享的潜在变量。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，在温和的假设下，MMCL学习到的表示恰好捕捉了与不受选择和扰动偏差影响的语义变量子集相关的信息。&lt;h4&gt;结论&lt;/h4&gt;这为理解不匹配提供了一个统一的视角，并基于此提供了关于如何设计现实世界机器学习系统的可操作见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态表示学习，以多模态对比学习（MMCL）使用图像-文本对为例，旨在通过跨模态对齐线索来学习强大的表示。这种方法依赖于核心假设，即示例图像-文本对构成了一个相同概念的两种表示。然而，最近的研究表明，现实世界的数据集往往表现出不匹配。关于如何解决这个问题，有两种不同的观点：一种建议缓解不匹配，另一种则利用它。在这里，我们试图调和这些看似对立的观点，并为从业者提供实用指南。因此，我们使用潜在变量模型，通过引入两种特定的机制来形式化不匹配：选择偏差，其中一些语义变量缺失；以及扰动偏差，其中语义变量被扭曲——两者都影响跨模态共享的潜在变量。我们的理论分析表明，在温和的假设下，MMCL学习到的表示恰好捕捉了与不受选择和扰动偏差影响的语义变量子集相关的信息。这为理解不匹配提供了一个统一的视角。基于此，我们进一步提供了关于如何设计现实世界机器学习系统的可操作见解。我们通过在合成数据和真实图像-文本数据集上进行的广泛实证研究验证了我们的理论发现，揭示了不匹配对多模态表示学习的微妙影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal representation learning, exemplified by multimodal contrastivelearning (MMCL) using image-text pairs, aims to learn powerful representationsby aligning cues across modalities. This approach relies on the core assumptionthat the exemplar image-text pairs constitute two representations of anidentical concept. However, recent research has revealed that real-worlddatasets often exhibit misalignment. There are two distinct viewpoints on howto address this issue: one suggests mitigating the misalignment, and the otherleveraging it. We seek here to reconcile these seemingly opposing perspectives,and to provide a practical guide for practitioners. Using latent variablemodels we thus formalize misalignment by introducing two specific mechanisms:selection bias, where some semantic variables are missing, and perturbationbias, where semantic variables are distorted -- both affecting latent variablesshared across modalities. Our theoretical analysis demonstrates that, undermild assumptions, the representations learned by MMCL capture exactly theinformation related to the subset of the semantic variables invariant toselection and perturbation biases. This provides a unified perspective forunderstanding misalignment. Based on this, we further offer actionable insightsinto how misalignment should inform the design of real-world ML systems. Wevalidate our theoretical findings through extensive empirical studies on bothsynthetic data and real image-text datasets, shedding light on the nuancedimpact of misalignment on multimodal representation learning.</description>
      <author>example@mail.com (Yichao Cai, Yuhang Liu, Erdun Gao, Tianjiao Jiang, Zhen Zhang, Anton van den Hengel, Javen Qinfeng Shi)</author>
      <guid isPermaLink="false">2504.10143v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Relation-augmented Representation Generalization for Few-shot Action Recognition</title>
      <link>http://arxiv.org/abs/2504.10079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;HR2G-shot是一个用于Few-shot动作识别（FSAR）的框架，旨在通过统一三种关系建模（帧间、视频间和任务间）来学习特定任务的时序模式。&lt;h4&gt;背景&lt;/h4&gt;现有的FSAR方法通常通过设计各种帧间时序建模策略独立地为每个视频学习帧级表示，但忽略了视频与任务之间的显式关系建模，因此未能捕捉视频之间的共享时序模式并重用历史任务中的时序知识。&lt;h4&gt;目的&lt;/h4&gt;提出HR2G-shot框架，以解决现有FSAR方法中忽视视频与任务关系建模的问题，从而能够学习到跨视频的共享时序模式。&lt;h4&gt;方法&lt;/h4&gt;HR2G-shot框架包括以下两个组件：i) Inter-video Semantic Correlation（ISC）以细粒度方式执行跨视频帧级交互，捕获特定任务的查询特征并学习支持特征之间的类内和类间时序相关性；ii) Inter-task Knowledge Transfer（IKT）从存储历史任务中不同时序模式的数据库中检索和聚合相关时序知识。&lt;h4&gt;主要发现&lt;/h4&gt;在五个基准数据集上的大量实验表明，HR2G-shot优于当前的顶尖FSAR方法。&lt;h4&gt;结论&lt;/h4&gt;HR2G-shot框架能够有效地提高Few-shot动作识别的性能，为FSAR领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Few-shot动作识别（FSAR）旨在通过少量示例识别新的动作类别。现有方法通常通过设计各种帧间时序建模策略独立地为每个视频学习帧级表示。然而，它们忽略了视频与任务之间的显式关系建模，因此未能捕捉视频之间的共享时序模式并重用历史任务中的时序知识。鉴于这一点，我们提出了HR2G-shot，一个用于FSAR的分层关系增强表示泛化框架，它统一了三种类型的关系建模（帧间、视频间和任务间）来从整体角度学习特定任务的时序模式。除了执行帧间时序交互之外，我们还设计了两个组件来分别探索视频间和任务间关系：i) Inter-video Semantic Correlation（ISC）以细粒度方式执行跨视频帧级交互，从而捕获特定任务的查询特征并学习支持特征之间的类内和类间时序相关性；ii) Inter-task Knowledge Transfer（IKT）从存储历史任务中不同时序模式的数据库中检索和聚合相关时序知识。在五个基准数据集上的大量实验表明，HR2G-shot优于当前的顶尖FSAR方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot action recognition (FSAR) aims to recognize novel action categorieswith few exemplars. Existing methods typically learn frame-levelrepresentations independently for each video by designing various inter-frametemporal modeling strategies. However, they neglect explicit relation modelingbetween videos and tasks, thus failing to capture shared temporal patternsacross videos and reuse temporal knowledge from historical tasks. In light ofthis, we propose HR2G-shot, a Hierarchical Relation-augmented RepresentationGeneralization framework for FSAR, which unifies three types of relationmodeling (inter-frame, inter-video, and inter-task) to learn task-specifictemporal patterns from a holistic view. In addition to conducting inter-frametemporal interactions, we further devise two components to respectively exploreinter-video and inter-task relationships: i) Inter-video Semantic Correlation(ISC) performs cross-video frame-level interactions in a fine-grained manner,thereby capturing task-specific query features and learning intra- andinter-class temporal correlations among support features; ii) Inter-taskKnowledge Transfer (IKT) retrieves and aggregates relevant temporal knowledgefrom the bank, which stores diverse temporal patterns from historical tasks.Extensive experiments on five benchmarks show that HR2G-shot outperformscurrent top-leading FSAR methods.</description>
      <author>example@mail.com (Hongyu Qu, Ling Xing, Rui Yan, Yazhou Yao, Guo-Sen Xie, Xiangbo Shu)</author>
      <guid isPermaLink="false">2504.10079v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Inferring genotype-phenotype maps using attention models</title>
      <link>http://arxiv.org/abs/2504.10388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究从基因型预测表型的遗传学挑战，提出了基于注意力机制的机器学习方法作为传统线性回归方法的替代方案。&lt;h4&gt;背景&lt;/h4&gt;传统遗传学方法通常使用线性回归分析基因型与表型之间的关系，但这种方法在处理复杂基因-环境相互作用和上位性模式时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;探讨注意力机制在预测表型方面的潜力，并评估其在遗传学中的应用效果。&lt;h4&gt;方法&lt;/h4&gt;本研究应用注意力模型分析模拟数据和实验数据，比较了其在不同上位性复杂程度下的预测性能。&lt;h4&gt;主要发现&lt;/h4&gt;注意力模型在预测上位性环境下的表型方面表现出优于传统方法的预测能力。此外，多环境注意力模型能够通过有限的训练数据在新的环境条件下预测表型。&lt;h4&gt;结论&lt;/h4&gt;注意力机制在遗传学中预测表型具有潜力，特别是在处理复杂遗传和环境相互作用时，且能够实现跨环境的迁移学习。&lt;h4&gt;翻译&lt;/h4&gt;摘要：预测表型从基因型是遗传学的核心挑战。传统的数量遗传学方法通常使用基于线性回归的方法来分析这个问题。这些方法通常假设复杂性状的遗传结构可以用加性模型来参数化，其中位点的效应是独立的，加上（在某些情况下）位点之间的成对上位性相互作用。然而，这些模型在分析更复杂的上位性模式或微妙的基因-环境相互作用方面存在困难。最近机器学习领域的进展，尤其是基于注意力的模型，提供了一个有前景的替代方案。最初为自然语言处理开发的注意力模型在捕捉上下文相关的交互方面表现出色，并在预测蛋白质结构和功能方面表现出卓越的性能。在这里，我们将注意力模型应用于数量遗传学。我们使用模拟数据分析了基于注意力的方法在预测基因型从表型方面的性能，这些数据覆盖了具有增加上位性复杂性的各种模型，并使用芽殖酵母中最近的数量性状位点映射研究的实验数据。我们发现，与标准方法相比，我们的模型在上位性环境下表现出优越的样本外预测能力。我们还探索了一个更通用的多环境注意力模型，以联合分析跨多个环境的基因型-表型映射，并显示这种架构可以用于“迁移学习”——在新环境中用有限的训练数据预测表型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting phenotype from genotype is a central challenge in genetics.Traditional approaches in quantitative genetics typically analyze this problemusing methods based on linear regression. These methods generally assume thatthe genetic architecture of complex traits can be parameterized in terms of anadditive model, where the effects of loci are independent, plus (in some cases)pairwise epistatic interactions between loci. However, these models struggle toanalyze more complex patterns of epistasis or subtle gene-environmentinteractions. Recent advances in machine learning, particularly attention-basedmodels, offer a promising alternative. Initially developed for natural languageprocessing, attention-based models excel at capturing context-dependentinteractions and have shown exceptional performance in predicting proteinstructure and function. Here, we apply attention-based models to quantitativegenetics. We analyze the performance of this attention-based approach inpredicting phenotype from genotype using simulated data across a range ofmodels with increasing epistatic complexity, and using experimental data from arecent quantitative trait locus mapping study in budding yeast. We find thatour model demonstrates superior out-of-sample predictions in epistatic regimescompared to standard methods. We also explore a more general multi-environmentattention-based model to jointly analyze genotype-phenotype maps acrossmultiple environments and show that such architectures can be used for"transfer learning" - predicting phenotypes in novel environments with limitedtraining data.</description>
      <author>example@mail.com (Krishna Rijal, Caroline M. Holmes, Samantha Petti, Gautam Reddy, Michael M. Desai, Pankaj Mehta)</author>
      <guid isPermaLink="false">2504.10388v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian Splatting for Novel View Synthesis</title>
      <link>http://arxiv.org/abs/2504.10331v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LL-Gaussian的新框架，用于从低光sRGB图像中进行3D重建和增强，实现了伪自然光的新视角合成。&lt;h4&gt;背景&lt;/h4&gt;在低光场景中进行新颖视图合成（NVS）是一个重大挑战，因为输入质量下降，具有严重的噪声、低动态范围（LDR）和不稳定的初始化。&lt;h4&gt;目的&lt;/h4&gt;旨在解决低光场景下NVS的挑战，实现快速、高质量的3D重建和渲染。&lt;h4&gt;方法&lt;/h4&gt;LL-Gaussian引入了三个关键创新：1）一个端到端的低光高斯初始化模块（LLGIM），利用基于学习的MVS方法的密集先验来生成高质量的初始点云；2）一个双分支高斯分解模型，将场景的内在属性（反射率和照明）与瞬时的干扰分离，以实现稳定和可解释的优化；3）一个由物理约束和扩散先验引导的无监督优化策略，以联合引导分解和增强。&lt;h4&gt;主要发现&lt;/h4&gt;LL-Gaussian在速度和效果上优于现有的NeRF方法，实现了高达2000倍的速度提升，并将训练时间缩短到2%，同时提供更高质量的重建和渲染。&lt;h4&gt;结论&lt;/h4&gt;LL-Gaussian框架在低光环境下实现了有效的3D重建和渲染，为低光场景下的NVS提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Novel view synthesis (NVS) in low-light scenes remains a significantchallenge due to degraded inputs characterized by severe noise, low dynamicrange (LDR) and unreliable initialization. While recent NeRF-based approacheshave shown promising results, most suffer from high computational costs, andsome rely on carefully captured or pre-processed data--such as RAW sensorinputs or multi-exposure sequences--which severely limits their practicality.In contrast, 3D Gaussian Splatting (3DGS) enables real-time rendering withcompetitive visual fidelity; however, existing 3DGS-based methods struggle withlow-light sRGB inputs, resulting in unstable Gaussian initialization andineffective noise suppression. To address these challenges, we proposeLL-Gaussian, a novel framework for 3D reconstruction and enhancement fromlow-light sRGB images, enabling pseudo normal-light novel view synthesis. Ourmethod introduces three key innovations: 1) an end-to-end Low-Light GaussianInitialization Module (LLGIM) that leverages dense priors from learning-basedMVS approach to generate high-quality initial point clouds; 2) a dual-branchGaussian decomposition model that disentangles intrinsic scene properties(reflectance and illumination) from transient interference, enabling stable andinterpretable optimization; 3) an unsupervised optimization strategy guided byboth physical constrains and diffusion prior to jointly steer decomposition andenhancement. Additionally, we contribute a challenging dataset collected inextreme low-light environments and demonstrate the effectiveness ofLL-Gaussian. Compared to state-of-the-art NeRF-based methods, LL-Gaussianachieves up to 2,000 times faster inference and reduces training time to just2%, while delivering superior reconstruction and rendering quality.</description>
      <author>example@mail.com (Hao Sun, Fenggen Yu, Huiyao Xu, Tao Zhang, Changqing Zou)</author>
      <guid isPermaLink="false">2504.10331v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling Contrastive Learning's Capability of Neighborhood Aggregation for Collaborative Filtering</title>
      <link>http://arxiv.org/abs/2504.10113v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGIR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LightCCF的个性化推荐方法，基于图对比学习，通过理论推导和实验验证，发现CL目标函数的梯度下降过程等同于图卷积，支持在交互图上的邻域聚合，并提出改进的邻域聚合目标，提高了推荐系统的训练效率和推荐准确性。&lt;h4&gt;背景&lt;/h4&gt;个性化推荐在网页应用中广泛应用，图对比学习（GCL）成为推荐系统的主要方法之一，因为它能够从原始交互数据中提取自监督信号，有效缓解数据稀疏性问题。&lt;h4&gt;目的&lt;/h4&gt;揭示GCL方法性能提升的原因，并提出改进方法以提高推荐系统的训练效率和推荐准确性。&lt;h4&gt;方法&lt;/h4&gt;通过理论推导证明CL目标函数的梯度下降过程等同于图卷积，提出LightCCF方法，引入新的邻域聚合目标，实现高质量邻域聚合。&lt;h4&gt;主要发现&lt;/h4&gt;CL目标函数的梯度下降过程等同于图卷积，支持在交互图上的邻域聚合，现有方法在正样本选择上存在误区，限制了CL目标函数的潜力。&lt;h4&gt;结论&lt;/h4&gt;LightCCF方法在三个高度稀疏的公共数据集上，有效聚合邻域信息，防止图过度平滑，在训练效率和推荐准确性方面均优于现有GCL方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：个性化推荐在网页应用中得到广泛应用，图对比学习（GCL）逐渐成为推荐系统中的主流方法，主要归功于其从原始交互数据中提取自监督信号的能力，有效缓解了数据稀疏性问题。一个典型的基于GCL的方法通常在图卷积期间进行数据增强，以生成更多的对比视图，并对这些新视图进行对比以获得丰富的自监督信号。尽管这种范式是有效的，但其性能提升背后的原因仍然是个谜。在这篇论文中，我们首先通过理论推导揭示，CL目标的梯度下降过程形式上等同于图卷积，这意味着CL目标函数本质上支持在交互图上的邻域聚合。我们进一步通过实验验证这一能力，并确定了先前方法中选择正样本的常见误区，这些误区限制了CL目标函数的潜力。基于这一发现，我们提出了Light Contrastive Collaborative Filtering（LightCCF）方法，该方法引入了一个新的邻域聚合目标，在将用户推向所有互动项目的同时，将他们推向其他正对，从而以非常低的时间复杂度实现高质量的邻域聚合。在三个高度稀疏的公共数据集上，所提出的方法有效地聚合了邻域信息，同时防止了图过度平滑，在训练效率和推荐准确性方面均优于现有的基于GCL的方法。我们的实现是公开可访问的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Personalized recommendation is widely used in the web applications, and graphcontrastive learning (GCL) has gradually become a dominant approach inrecommender systems, primarily due to its ability to extract self-supervisedsignals from raw interaction data, effectively alleviating the problem of datasparsity. A classic GCL-based method typically uses data augmentation duringgraph convolution to generates more contrastive views, and performs contrast onthese new views to obtain rich self-supervised signals. Despite this paradigmis effective, the reasons behind the performance gains remain a mystery. Inthis paper, we first reveal via theoretical derivation that the gradientdescent process of the CL objective is formally equivalent to graphconvolution, which implies that CL objective inherently supports neighborhoodaggregation on interaction graphs. We further substantiate this capabilitythrough experimental validation and identify common misconceptions in theselection of positive samples in previous methods, which limit the potential ofCL objective. Based on this discovery, we propose the Light ContrastiveCollaborative Filtering (LightCCF) method, which introduces a novelneighborhood aggregation objective to bring users closer to all interacteditems while pushing them away from other positive pairs, thus achievinghigh-quality neighborhood aggregation with very low time complexity. On threehighly sparse public datasets, the proposed method effectively aggregateneighborhood information while preventing graph over-smoothing, demonstratingsignificant improvements over existing GCL-based counterparts in both trainingefficiency and recommendation accuracy. Our implementations are publiclyaccessible.</description>
      <author>example@mail.com (Yu Zhang, Yiwen Zhang, Yi Zhang, Lei Sang, Yun Yang)</author>
      <guid isPermaLink="false">2504.10113v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>EmbodiedOcc++: Boosting Embodied 3D Occupancy Prediction with Plane Regularization and Uncertainty Sampler</title>
      <link>http://arxiv.org/abs/2504.09540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EmbodiedOcc++的在线3D占用预测框架，通过引入几何引导优化模块（GRM）和语义感知不确定性采样器（SUS）两个关键创新，提升了原始框架的性能。&lt;h4&gt;背景&lt;/h4&gt;在线3D占用预测对于理解虚拟环境具有重要意义，然而现有的EmbodiedOcc框架未能充分利用室内环境的几何特性。&lt;h4&gt;目的&lt;/h4&gt;提高EmbodiedOcc框架在室内环境占用预测中的几何一致性。&lt;h4&gt;方法&lt;/h4&gt;1. 引入GRM模块，通过平面正则化约束高斯更新，使语义高斯与平面表面准确对齐。2. 引入SUS模块，在连续帧的重叠区域进行更有效的更新。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，EmbodiedOcc++在EmbodiedOcc-ScanNet基准测试中取得了最先进的性能，提高了边缘精度并保留了更多几何细节，同时保证了计算效率。&lt;h4&gt;结论&lt;/h4&gt;EmbodiedOcc++是一种有效的在线3D占用预测方法，对于在线实体感知具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;Online 3D occupancy prediction provides a comprehensive spatial understanding of embodied environments. While the innovative EmbodiedOcc framework utilizes 3D semantic Gaussians for progressive indoor occupancy prediction, it overlooks the geometric characteristics of indoor environments, which are primarily characterized by planar structures. This paper introduces EmbodiedOcc++, enhancing the original framework with two key innovations: a Geometry-guided Refinement Module (GRM) that constrains Gaussian updates through planar regularization, along with a Semantic-aware Uncertainty Sampler (SUS) that enables more effective updates in overlapping regions between consecutive frames. GRM regularizes the position update to align with surface normals. It determines the adaptive regularization weight using curvature-based and depth-based constraints, allowing semantic Gaussians to align accurately with planar surfaces while adapting in complex regions. To effectively improve geometric consistency from different views, SUS adaptively selects proper Gaussians to update. Comprehensive experiments on the EmbodiedOcc-ScanNet benchmark demonstrate that EmbodiedOcc++ achieves state-of-the-art performance across different settings. Our method demonstrates improved edge accuracy and retains more geometric details while ensuring computational efficiency, which is essential for online embodied perception. The code will be released at: https://github.com/PKUHaoWang/EmbodiedOcc2.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Online 3D occupancy prediction provides a comprehensive spatial understandingof embodied environments. While the innovative EmbodiedOcc framework utilizes3D semantic Gaussians for progressive indoor occupancy prediction, it overlooksthe geometric characteristics of indoor environments, which are primarilycharacterized by planar structures. This paper introduces EmbodiedOcc++,enhancing the original framework with two key innovations: a Geometry-guidedRefinement Module (GRM) that constrains Gaussian updates through planeregularization, along with a Semantic-aware Uncertainty Sampler (SUS) thatenables more effective updates in overlapping regions between consecutiveframes. GRM regularizes the position update to align with surface normals. Itdetermines the adaptive regularization weight using curvature-based anddepth-based constraints, allowing semantic Gaussians to align accurately withplanar surfaces while adapting in complex regions. To effectively improvegeometric consistency from different views, SUS adaptively selects properGaussians to update. Comprehensive experiments on the EmbodiedOcc-ScanNetbenchmark demonstrate that EmbodiedOcc++ achieves state-of-the-art performanceacross different settings. Our method demonstrates improved edge accuracy andretains more geometric details while ensuring computational efficiency, whichis essential for online embodied perception. The code will be released at:https://github.com/PKUHaoWang/EmbodiedOcc2.</description>
      <author>example@mail.com (Hao Wang, Xiaobao Wei, Xiaoan Zhang, Jianing Li, Chengyu Bai, Ying Li, Ming Lu, Wenzhao Zheng, Shanghang Zhang)</author>
      <guid isPermaLink="false">2504.09540v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>UP-Person: Unified Parameter-Efficient Transfer Learning for Text-based Person Retrieval</title>
      <link>http://arxiv.org/abs/2504.10084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 7 figures, first submited to IEEE TCSVT on 2024 May. Under  review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为UP-Person的新型统一参数高效迁移学习方法，用于基于文本的人物检索任务，该方法通过仅微调少量参数实现了良好的性能。&lt;h4&gt;背景&lt;/h4&gt;基于文本的人物检索（TPR）是一个多模态任务，它利用CLIP等预训练模型来提取人物图像和文本特征，并在这一领域取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种参数高效的方法，用于基于文本的人物检索，以解决全量微调大模型容易过拟合且泛化能力受限的问题。&lt;h4&gt;方法&lt;/h4&gt;UP-Person方法集成了三个轻量级PETL组件：Prefix、LoRA和Adapter。Prefix和LoRA用于挖掘局部信息，Adapter用于调整全局特征表示。同时优化了S-Prefix和L-Adapter两个子模块以适应统一的TPR架构。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，UP-Person在各种人物检索数据集上取得了最先进的结果，包括CUHK-PEDES、ICFG-PEDES和RSTPReid，而仅微调了4.7%的参数。&lt;h4&gt;结论&lt;/h4&gt;UP-Person方法通过微调少量参数实现了高效的人物检索，为基于文本的人物检索任务提供了一个新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Based on text, the paper proposes a novel unified parameter-efficient transfer learning method (UP-Person) for person retrieval, achieving advanced performance by merely fine-tuning a small number of parameters.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-based Person Retrieval (TPR) as a multi-modal task, which aims toretrieve the target person from a pool of candidate images given a textdescription, has recently garnered considerable attention due to the progressof contrastive visual-language pre-trained model. Prior works leveragepre-trained CLIP to extract person visual and textual features and fullyfine-tune the entire network, which have shown notable performance improvementscompared to uni-modal pre-training models. However, full-tuning a large modelis prone to overfitting and hinders the generalization ability. In this paper,we propose a novel Unified Parameter-Efficient Transfer Learning (PETL) methodfor Text-based Person Retrieval (UP-Person) to thoroughly transfer themulti-modal knowledge from CLIP. Specifically, UP-Person simultaneouslyintegrates three lightweight PETL components including Prefix, LoRA andAdapter, where Prefix and LoRA are devised together to mine local informationwith task-specific information prompts, and Adapter is designed to adjustglobal feature representations. Additionally, two vanilla submodules areoptimized to adapt to the unified architecture of TPR. For one thing, S-Prefixis proposed to boost attention of prefix and enhance the gradient propagationof prefix tokens, which improves the flexibility and performance of the vanillaprefix. For another thing, L-Adapter is designed in parallel with layernormalization to adjust the overall distribution, which can resolve conflictscaused by overlap and interaction among multiple submodules. Extensiveexperimental results demonstrate that our UP-Person achieves state-of-the-artresults across various person retrieval datasets, including CUHK-PEDES,ICFG-PEDES and RSTPReid while merely fine-tuning 4.7\% parameters. Code isavailable at https://github.com/Liu-Yating/UP-Person.</description>
      <author>example@mail.com (Yating Liu, Yaowei Li, Xiangyuan Lan, Wenming Yang, Zimo Liu, Qingmin Liao)</author>
      <guid isPermaLink="false">2504.10084v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Text To 3D Object Generation For Scalable Room Assembly</title>
      <link>http://arxiv.org/abs/2504.09328v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at the ICLR 2025 Workshop on Synthetic Data&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种端到端系统，用于生成高质量的3D室内场景合成数据，以解决数据稀缺的问题，并旨在通过合成数据增强机器学习模型的鲁棒性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现代场景理解机器学习模型，如深度估计和物体跟踪，依赖于大量、高质量的模拟真实部署场景的数据集。&lt;h4&gt;目的&lt;/h4&gt;为了解决数据稀缺的问题，该研究旨在提出一种可扩展、高质量、可定制的3D室内场景合成数据生成系统。&lt;h4&gt;方法&lt;/h4&gt;系统通过整合和适应文本到图像和多视图扩散模型，结合基于Neural Radiance Field的网格化技术，从文本提示中生成高保真3D物体资产，并使用渲染工具将它们整合到预定义的平面图中。同时，引入了新颖的损失函数和训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;系统支持按需场景生成，旨在缓解当前可用数据的稀缺性，这些数据通常由艺术家手工制作。&lt;h4&gt;结论&lt;/h4&gt;该系统推进了合成数据在解决机器学习训练限制中的作用，使得能够开发出更鲁棒和泛化的现实应用模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代场景理解机器学习模型，如深度估计和物体跟踪，依赖于大量、高质量的模拟真实部署场景的数据集。为了解决数据稀缺问题，我们提出了一种用于生成可扩展、高质量、可定制3D室内场景合成数据的端到端系统。通过整合和适应文本到图像和多视图扩散模型与基于Neural Radiance Field的网格化，该系统从文本提示中生成高保真3D物体资产，并使用渲染工具将它们整合到预定义的平面图中。通过引入新颖的损失函数和训练策略到现有方法中，该系统支持按需场景生成，旨在缓解当前可用数据的稀缺性，这些数据通常由艺术家手工制作。该系统推进了合成数据在解决机器学习训练限制中的作用，使得能够开发出更鲁棒和泛化的现实应用模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern machine learning models for scene understanding, such as depthestimation and object tracking, rely on large, high-quality datasets that mimicreal-world deployment scenarios. To address data scarcity, we propose anend-to-end system for synthetic data generation for scalable, high-quality, andcustomizable 3D indoor scenes. By integrating and adapting text-to-image andmulti-view diffusion models with Neural Radiance Field-based meshing, thissystem generates highfidelity 3D object assets from text prompts andincorporates them into pre-defined floor plans using a rendering tool. Byintroducing novel loss functions and training strategies into existing methods,the system supports on-demand scene generation, aiming to alleviate thescarcity of current available data, generally manually crafted by artists. Thissystem advances the role of synthetic data in addressing machine learningtraining limitations, enabling more robust and generalizable models forreal-world applications.</description>
      <author>example@mail.com (Sonia Laguna, Alberto Garcia-Garcia, Marie-Julie Rakotosaona, Stylianos Moschoglou, Leonhard Helminger, Sergio Orts-Escolano)</author>
      <guid isPermaLink="false">2504.09328v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>A Model Zoo of Vision Transformers</title>
      <link>http://arxiv.org/abs/2504.10231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the ICLR Workshop on Neural Network Weights as a New Data  Modality 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了第一个视觉变压器（ViT）模型动物园，旨在扩展现有模型动物园的功能和应用范围。&lt;h4&gt;背景&lt;/h4&gt;随着“模型动物园”的出现，神经网络模型分析、表示学习以及神经网络的参数生成等下游任务得到了发展。然而，现有的模型动物园在规模和架构上有限，且忽略了当前最成功的神经网络架构之一——Transformer。&lt;h4&gt;目的&lt;/h4&gt;填补现有模型动物园的不足，引入视觉变压器（ViT）模型动物园，并开发新的模型动物园生成蓝图。&lt;h4&gt;方法&lt;/h4&gt;开发了一种新的模型动物园生成蓝图，包括预训练和微调步骤，并发布250个独特的模型。这些模型通过大量生成因素生成，并通过权重空间和行为指标验证其多样性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的模型动物园允许研究人员将基于模型种群的方法从小型模型扩展到最先进架构。&lt;h4&gt;结论&lt;/h4&gt;该模型动物园可在github.com/ModelZoos/ViTModelZoo上获取，有助于推动神经网络模型种群方法的发展。&lt;h4&gt;翻译&lt;/h4&gt;The availability of large, structured populations of neural networks - called 'model zoos' - has led to the development of a multitude of downstream tasks ranging from model analysis, to representation learning on model weights or generative modeling of neural network parameters. However, existing model zoos are limited in size and architecture and neglect the transformer, which is among the currently most successful neural network architectures. We address this gap by introducing the first model zoo of vision transformers (ViT). To better represent recent training approaches, we develop a new blueprint for model zoo generation that encompasses both pre-training and fine-tuning steps, and publish 250 unique models. They are carefully generated with a large span of generating factors, and their diversity is validated using a thorough choice of weight-space and behavioral metrics. To further motivate the utility of our proposed dataset, we suggest multiple possible applications grounded in both extensive exploratory experiments and a number of examples from the existing literature. By extending previous lines of similar work, our model zoo allows researchers to push their model population-based methods from the small model regime to state-of-the-art architectures. We make our model zoo available at github.com/ModelZoos/ViTModelZoo.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The availability of large, structured populations of neural networks - called'model zoos' - has led to the development of a multitude of downstream tasksranging from model analysis, to representation learning on model weights orgenerative modeling of neural network parameters. However, existing model zoosare limited in size and architecture and neglect the transformer, which isamong the currently most successful neural network architectures. We addressthis gap by introducing the first model zoo of vision transformers (ViT). Tobetter represent recent training approaches, we develop a new blueprint formodel zoo generation that encompasses both pre-training and fine-tuning steps,and publish 250 unique models. They are carefully generated with a large spanof generating factors, and their diversity is validated using a thorough choiceof weight-space and behavioral metrics. To further motivate the utility of ourproposed dataset, we suggest multiple possible applications grounded in bothextensive exploratory experiments and a number of examples from the existingliterature. By extending previous lines of similar work, our model zoo allowsresearchers to push their model population-based methods from the small modelregime to state-of-the-art architectures. We make our model zoo available atgithub.com/ModelZoos/ViTModelZoo.</description>
      <author>example@mail.com (Damian Falk, Léo Meynent, Florence Pfammatter, Konstantin Schürholt, Damian Borth)</author>
      <guid isPermaLink="false">2504.10231v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>AI-Driven Code Refactoring: Using Graph Neural Networks to Enhance Software Maintainability</title>
      <link>http://arxiv.org/abs/2504.10412v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了图神经网络（GNNs）在代码重构中的应用，利用抽象语法树（AST）提高软件可维护性。&lt;h4&gt;背景&lt;/h4&gt;通过分析来自CodeSearchNet的200万个代码片段和75000个文件的GitHub Python语料库，研究对比了GNNs与基于规则的SonarQube和决策树。&lt;h4&gt;目的&lt;/h4&gt;利用GNNs提高代码重构的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;使用GNNs对代码进行重构，并与SonarQube和决策树进行对比，评估了复杂度、耦合度和重构精度等指标。&lt;h4&gt;主要发现&lt;/h4&gt;GNNs在重构代码时达到了92%的准确率，将复杂度降低了35%，耦合度降低了33%，超过了SonarQube（78%，16%）和决策树（85%，25%）。预处理固定了60%的语法错误。&lt;h4&gt;结论&lt;/h4&gt;GNNs提供了一个可扩展的人工智能驱动的路径，以实现更清洁的代码库，这对于软件工程至关重要。&lt;h4&gt;翻译&lt;/h4&gt;This study explores Graph Neural Networks (GNNs) as a transformative tool for code refactoring, using abstract syntax trees (ASTs) to boost software maintainability. It analyzes a dataset of 2 million snippets from CodeSearchNet and a custom 75000-file GitHub Python corpus, comparing GNNs against rule-based SonarQube and decision trees. Metrics include cyclomatic complexity (target below 10), coupling (target below 5), and refactoring precision. GNNs achieve 92% accuracy, reducing complexity by 35% and coupling by 33%, outperforming SonarQube (78%, 16%) and decision trees (85%, 25%). Preprocessing fixed 60% of syntax errors. Bar graphs, tables, and AST visuals clarify results. This offers a scalable AI-driven path to cleaner codebases, which is crucial for software engineering.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study explores Graph Neural Networks (GNNs) as a transformative tool forcode refactoring, using abstract syntax trees (ASTs) to boost softwaremaintainability. It analyzes a dataset of 2 million snippets from CodeSearchNetand a custom 75000-file GitHub Python corpus, comparing GNNs against rule-basedSonarQube and decision trees. Metrics include cyclomatic complexity (targetbelow 10), coupling (target below 5), and refactoring precision. GNNs achieve92% accuracy, reducing complexity by 35% and coupling by 33%, outperformingSonarQube (78%, 16%) and decision trees (85%, 25%). Preprocessing fixed 60% ofsyntax errors. Bar graphs, tables, and AST visuals clarify results. This offersa scalable AI-driven path to cleaner codebases, which is crucial for softwareengineering.</description>
      <author>example@mail.com (Gopichand Bandarupalli)</author>
      <guid isPermaLink="false">2504.10412v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>RICCARDO: Radar Hit Prediction and Convolution for Camera-Radar 3D Object Detection</title>
      <link>http://arxiv.org/abs/2504.09086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于雷达回波分布模型的雷达-相机融合方法，以提高雷达-相机检测性能。&lt;h4&gt;背景&lt;/h4&gt;雷达回波在物体边界和内部点反射，导致雷达回波分布复杂，依赖于物体类别、大小和方向等因素。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过雷达回波分布模型辅助融合，以提高雷达-相机检测性能。&lt;h4&gt;方法&lt;/h4&gt;1. 建立模型预测基于单目检测器获得的物体属性条件下的雷达回波分布。2. 使用预测分布作为核函数匹配单目检测附近的实际测量雷达点，生成附近位置的匹配分数。3. 融合阶段结合上下文和核检测器来细化匹配分数。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在nuScenes数据集上实现了最先进的雷达-相机检测性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过雷达回波分布模型辅助融合，有效提升了雷达-相机检测性能。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is summarized as follows: This paper proposes a radar-camera fusion method based on a radar hit distribution model to improve radar-camera detection performance. Radar hits reflect from points on both the boundary and internal to object outlines, resulting in a complex distribution of radar hits that depends on factors including object category, size, and orientation. The proposed method explicitly utilizes a radar hit distribution model to assist fusion. First, a model is built to predict radar hit distributions conditioned on object properties obtained from a monocular detector. Second, the predicted distribution is used as a kernel to match actual measured radar points in the neighborhood of the monocular detections, generating matching scores at nearby positions. Finally, a fusion stage combines context with the kernel detector to refine the matching scores. The method achieves the state-of-the-art radar-camera detection performance on nuScenes. The source code is available at https://github.com/longyunf/riccardo.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radar hits reflect from points on both the boundary and internal to objectoutlines. This results in a complex distribution of radar hits that depends onfactors including object category, size, and orientation. Current radar-camerafusion methods implicitly account for this with a black-box neural network. Inthis paper, we explicitly utilize a radar hit distribution model to assistfusion. First, we build a model to predict radar hit distributions conditionedon object properties obtained from a monocular detector. Second, we use thepredicted distribution as a kernel to match actual measured radar points in theneighborhood of the monocular detections, generating matching scores at nearbypositions. Finally, a fusion stage combines context with the kernel detector torefine the matching scores. Our method achieves the state-of-the-artradar-camera detection performance on nuScenes. Our source code is available athttps://github.com/longyunf/riccardo.</description>
      <author>example@mail.com (Yunfei Long, Abhinav Kumar, Xiaoming Liu, Daniel Morris)</author>
      <guid isPermaLink="false">2504.09086v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Mavors: Multi-granularity Video Representation for Multimodal Large Language Model</title>
      <link>http://arxiv.org/abs/2504.10068v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Mavors是一个针对多模态大型语言模型（MLLMs）长视频理解的新框架，旨在平衡计算效率与保留精细时空模式。&lt;h4&gt;背景&lt;/h4&gt;长视频理解在MLLMs中面临挑战，现有方法如稀疏采样、低分辨率密集采样和标记压缩在处理复杂运动或不同分辨率的视频时，会在时间动态、空间细节或微妙交互方面损失大量信息。&lt;h4&gt;目的&lt;/h4&gt;提出Mavors框架，旨在解决上述问题，实现整体长视频建模。&lt;h4&gt;方法&lt;/h4&gt;Mavors通过两个核心组件直接将原始视频内容编码成潜在表示：1) 内部块视觉编码器（IVE），通过3D卷积和视觉Transformer保留高分辨率空间特征；2) 交叉块特征聚合器（IFA），使用基于transformer的依赖建模和块级旋转位置编码建立块之间的时间一致性。此外，该框架通过将图像视为单帧视频，通过子图像分解统一图像和视频理解。&lt;h4&gt;主要发现&lt;/h4&gt;Mavors在保持空间保真度和时间连续性方面表现出优越性，在需要精细时空推理的任务中显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;Mavors框架在长视频理解中提供了一种有效的解决方案，能够平衡计算效率与时空信息保留。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在多模态大型语言模型（MLLMs）中进行长视频理解面临一个关键挑战：在保持精细时空模式的同时平衡计算效率。现有方法（例如稀疏采样、低分辨率密集采样和标记压缩）在处理复杂运动或不同分辨率的视频时，在时间动态、空间细节或微妙交互方面存在显著的信息损失。为了解决这个问题，我们提出了Mavors，这是一个用于整体长视频建模的新框架。具体来说，Mavors通过两个核心组件直接将原始视频内容编码成潜在表示：1) 内部块视觉编码器（IVE），通过3D卷积和视觉Transformer保留高分辨率空间特征；2) 交叉块特征聚合器（IFA），使用基于transformer的依赖建模和块级旋转位置编码建立块之间的时间一致性。此外，该框架通过将图像视为单帧视频，通过子图像分解统一图像和视频理解。在多个基准测试中的实验表明，Mavors在保持空间保真度和时间连续性方面具有优越性，在需要精细时空推理的任务中显著优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-context video understanding in multimodal large language models (MLLMs)faces a critical challenge: balancing computational efficiency with theretention of fine-grained spatio-temporal patterns. Existing approaches (e.g.,sparse sampling, dense sampling with low resolution, and token compression)suffer from significant information loss in temporal dynamics, spatial details,or subtle interactions, particularly in videos with complex motion or varyingresolutions. To address this, we propose $\mathbf{Mavors}$, a novel frameworkthat introduces $\mathbf{M}$ulti-gr$\mathbf{a}$nularity$\mathbf{v}$ide$\mathbf{o}$ $\mathbf{r}$epre$\mathbf{s}$entation for holisticlong-video modeling. Specifically, Mavors directly encodes raw video contentinto latent representations through two core components: 1) an Intra-chunkVision Encoder (IVE) that preserves high-resolution spatial features via 3Dconvolutions and Vision Transformers, and 2) an Inter-chunk Feature Aggregator(IFA) that establishes temporal coherence across chunks using transformer-baseddependency modeling with chunk-level rotary position encodings. Moreover, theframework unifies image and video understanding by treating images assingle-frame videos via sub-image decomposition. Experiments across diversebenchmarks demonstrate Mavors' superiority in maintaining both spatial fidelityand temporal continuity, significantly outperforming existing methods in tasksrequiring fine-grained spatio-temporal reasoning.</description>
      <author>example@mail.com (Yang Shi, Jiaheng Liu, Yushuo Guan, Zhenhua Wu, Yuanxing Zhang, Zihao Wang, Weihong Lin, Jingyun Hua, Zekun Wang, Xinlong Chen, Bohan Zeng, Wentao Zhang, Fuzheng Zhang, Wenjing Yang, Di Zhang)</author>
      <guid isPermaLink="false">2504.10068v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>The topology of synergy: linking topological and information-theoretic approaches to higher-order interactions in complex systems</title>
      <link>http://arxiv.org/abs/2504.10140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了不可约高阶相互作用在复杂系统中的研究，比较了拓扑数据分析和多变量信息理论在描述多变量数据中高阶相互作用的方法。&lt;h4&gt;背景&lt;/h4&gt;高阶相互作用成为复杂系统研究的核心，拓扑数据分析和多变量信息理论是识别高阶相互作用的主要框架。&lt;h4&gt;目的&lt;/h4&gt;评估两种框架在定义“高阶结构”方面的异同。&lt;h4&gt;方法&lt;/h4&gt;通过玩具示例和自然数据（如fMRI信号）进行对比研究，并使用PCA进行降维分析。&lt;h4&gt;主要发现&lt;/h4&gt;高阶协同信息与点云中的三维洞穴相关，fMRI数据中协同信息与三维洞穴的数量和大小有强相关性，PCA倾向于表示高阶冗余，但未能保留高阶信息和拓扑结构。&lt;h4&gt;结论&lt;/h4&gt;这些结果指向了发展一个涵盖拓扑和信息理论方法，同时强调更传统方法局限性的丰富的高阶相互作用理论的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：不可约高阶相互作用的研究已成为复杂系统研究的核心主题。拓扑数据分析和多变量信息理论是识别经验数据中高阶相互作用的最发达的两种框架。尽管这两者有相似的宗旨，但它们建立在明显不同的数学基础上，并且主要是平行发展的。在本研究中，我们展示了拓扑数据分析和信息理论方法在描述多变量数据中高阶相互作用方面的直接比较；目的是评估这些框架在定义“高阶结构”方面的相似性和差异性。我们从具有已知拓扑的玩具示例开始，然后转向自然数据：从人脑收集的fMRI信号。我们发现内在的高阶协同信息与点云中的三维洞穴相关：如球体这样的形状是协同主导的。在fMRI数据中，我们发现协同信息与三维洞穴的数量和大小之间存在强相关性。此外，我们发现降维技术如PCA优先表示高阶冗余，并且很大程度上未能保留高阶信息和拓扑结构，这表明基于流形的常见方法在系统地识别数据的重要特征方面存在系统性失败。这些结果指向了发展一个涵盖拓扑和信息理论方法，同时同时强调更传统方法局限性的丰富的高阶相互作用理论的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The study of irreducible higher-order interactions has become a core topic ofstudy in complex systems. Two of the most well-developed frameworks,topological data analysis and multivariate information theory, aim to provideformal tools for identifying higher-order interactions in empirical data.Despite similar aims, however, these two approaches are built on markedlydifferent mathematical foundations and have been developed largely in parallel.In this study, we present a head-to-head comparison of topological dataanalysis and information-theoretic approaches to describing higher-orderinteractions in multivariate data; with the aim of assessing the similaritiesand differences between how the frameworks define ``higher-order structures."We begin with toy examples with known topologies, before turning tonaturalistic data: fMRI signals collected from the human brain. We find thatintrinsic, higher-order synergistic information is associated withthree-dimensional cavities in a point cloud: shapes such as spheres aresynergy-dominated. In fMRI data, we find strong correlations betweensynergistic information and both the number and size of three-dimensionalcavities. Furthermore, we find that dimensionality reduction techniques such asPCA preferentially represent higher-order redundancies, and largely fail topreserve both higher-order information and topological structure, suggestingthat common manifold-based approaches to studying high-dimensional data aresystematically failing to identify important features of the data. Theseresults point towards the possibility of developing a rich theory ofhigher-order interactions that spans topological and information-theoreticapproaches while simultaneously highlighting the profound limitations of moreconventional methods.</description>
      <author>example@mail.com (Thomas F. Varley, Pedro A. M. Mediano, Alice Patania, Josh Bongard)</author>
      <guid isPermaLink="false">2504.10140v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Robust Unsupervised Domain Adaptation for 3D Point Cloud Segmentation Under Source Adversarial Attacks</title>
      <link>http://arxiv.org/abs/2504.01659v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种对抗鲁棒的领域自适应（UDA）框架，用于3D点云语义分割模型，通过 stealthy adversarial point cloud generation attack 和 Adversarial Adaptation Framework（AAF）来增强模型在对抗扰动下的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的无监督领域自适应（UDA）框架在干净数据上对3D点云语义分割模型具有良好的泛化能力，但忽略了当源域本身受到损害时的对抗鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;全面探索UDA框架的鲁棒性，并提出对抗鲁棒的解决方案。&lt;h4&gt;方法&lt;/h4&gt;设计了一种 stealthy adversarial point cloud generation attack，用于生成受污染的LiDAR点云数据集AdvSynLiDAR。基于此，提出了一种新的对抗自适应框架（AAF），通过扩展关键点敏感（KPS）损失到鲁棒长尾损失（RLT loss）并利用解码分支，使模型在预训练阶段关注长尾类别，并在适应阶段利用高置信度的解码点云信息来恢复点云结构。&lt;h4&gt;主要发现&lt;/h4&gt;在AdvSynLiDAR数据集上评估了AAF方法，结果表明AAF方法可以减轻3D点云分割应用中源对抗扰动下的性能下降。&lt;h4&gt;结论&lt;/h4&gt;本文提出的AAF方法能够有效提高3D点云语义分割模型在对抗扰动下的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;Unsupervised domain adaptation (UDA) frameworks have shown good generalization capabilities for 3D point cloud semantic segmentation models on clean data. However, existing works overlook adversarial robustness when the source domain itself is compromised. To comprehensively explore the robustness of the UDA frameworks, we first design a stealthy adversarial point cloud generation attack that can significantly contaminate datasets with only minor perturbations to the point cloud surface. Based on that, we propose a novel dataset, AdvSynLiDAR, comprising synthesized contaminated LiDAR point clouds. With the generated corrupted data, we further develop the Adversarial Adaptation Framework (AAF) as the countermeasure. Specifically, by extending the key point sensitive (KPS) loss towards the Robust Long-Tail loss (RLT loss) and utilizing a decoder branch, our approach enables the model to focus on long-tail classes during the pre-training phase and leverages high-confidence decoded point cloud information to restore point cloud structures during the adaptation phase. We evaluated our AAF method on the AdvSynLiDAR dataset, where the results demonstrate that our AAF method can mitigate performance degradation under source adversarial perturbations for UDA in the 3D point cloud segmentation application.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised domain adaptation (UDA) frameworks have shown goodgeneralization capabilities for 3D point cloud semantic segmentation models onclean data. However, existing works overlook adversarial robustness when thesource domain itself is compromised. To comprehensively explore the robustnessof the UDA frameworks, we first design a stealthy adversarial point cloudgeneration attack that can significantly contaminate datasets with only minorperturbations to the point cloud surface. Based on that, we propose a noveldataset, AdvSynLiDAR, comprising synthesized contaminated LiDAR point clouds.With the generated corrupted data, we further develop the AdversarialAdaptation Framework (AAF) as the countermeasure. Specifically, by extendingthe key point sensitive (KPS) loss towards the Robust Long-Tail loss (RLT loss)and utilizing a decoder branch, our approach enables the model to focus onlong-tail classes during the pre-training phase and leverages high-confidencedecoded point cloud information to restore point cloud structures during theadaptation phase. We evaluated our AAF method on the AdvSynLiDAR dataset, wherethe results demonstrate that our AAF method can mitigate performancedegradation under source adversarial perturbations for UDA in the 3D pointcloud segmentation application.</description>
      <author>example@mail.com (Haosheng Li, Junjie Chen, Yuecong Xu, Kemi Ding)</author>
      <guid isPermaLink="false">2504.01659v3</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>STaRFormer: Semi-Supervised Task-Informed Representation Learning via Dynamic Attention-Based Regional Masking for Sequential Data</title>
      <link>http://arxiv.org/abs/2504.10097v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer的模型STaRFormer，用于处理非平稳和 irregularly sampled的时空数据，以准确预测智能设备用户在车辆周围受限区域内的意图。&lt;h4&gt;背景&lt;/h4&gt;准确预测序列时空数据对于多种应用至关重要，但现实场景中的环境因素和传感器限制导致数据非平稳和不规则采样，带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;通过使用真实世界数据，学习智能设备用户在车辆周围受限区域内的意图。&lt;h4&gt;方法&lt;/h4&gt;开发了STaRFormer模型，它是一个通用的序列建模框架，采用了一种新颖的动态注意力区域掩码方案，并结合半监督对比学习来增强特定任务的潜在表示。&lt;h4&gt;主要发现&lt;/h4&gt;在15个不同类型（包括非平稳和不规则采样的）、领域、序列长度、训练样本和应用的实验数据集上，STaRFormer展示了其有效性和实用性，并取得了比现有方法显著的改进。&lt;h4&gt;结论&lt;/h4&gt;STaRFormer代码和数据将公开提供，以供进一步研究和应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：准确预测序列时空数据对于各种应用至关重要。利用真实世界数据，我们旨在学习智能设备用户在车辆周围受限区域内的意图。然而，在现实场景中，环境因素和传感器限制导致非平稳和不规则采样的数据，带来了重大挑战。为了解决这些问题，我们开发了一种基于Transformer的方法，即STaRFormer，它是一个用于序列建模的通用框架。STaRFormer采用了一种新颖的、基于动态注意力的区域掩码方案，并结合半监督对比学习来增强特定任务的潜在表示。在15个类型（包括非平稳和不规则采样的）、领域、序列长度、训练样本和应用不同的数据集上进行的综合实验，证明了STaRFormer的有效性和实用性。我们实现了对现有方法的显著改进。代码和数据将被公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate predictions using sequential spatiotemporal data are crucial forvarious applications. Utilizing real-world data, we aim to learn the intent ofa smart device user within confined areas of a vehicle's surroundings. However,in real-world scenarios, environmental factors and sensor limitations result innon-stationary and irregularly sampled data, posing significant challenges. Toaddress these issues, we developed a Transformer-based approach, STaRFormer,which serves as a universal framework for sequential modeling. STaRFormeremploys a novel, dynamic attention-based regional masking scheme combined withsemi-supervised contrastive learning to enhance task-specific latentrepresentations. Comprehensive experiments on 15 datasets varying in types(including non-stationary and irregularly sampled), domains, sequence lengths,training samples, and applications, demonstrate the efficacy and practicalityof STaRFormer. We achieve notable improvements over state-of-the-artapproaches. Code and data will be made available.</description>
      <author>example@mail.com (Maxmilian Forstenhäusler, Daniel Külzer, Christos Anagnostopoulos, Shameem Puthiya Parambath, Natascha Weber)</author>
      <guid isPermaLink="false">2504.10097v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Harmonize Cross-vendor X-ray Images by Non-linear Image Dynamics Correction</title>
      <link>http://arxiv.org/abs/2504.10080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了传统图像增强方法在医疗图像分析中如何提高模型鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;通过对不同供应商的图像应用常见的归一化方法，研究了这些方法对迁移学习中模型泛化的影响。&lt;h4&gt;目的&lt;/h4&gt;为了解决领域特定图像动态的非线性特性无法通过简单线性变换解决的问题。&lt;h4&gt;方法&lt;/h4&gt;将图像调和任务重新定义为曝光校正问题，并提出了一种名为全局深度曲线估计（GDCE）的方法来减少领域特定的曝光不匹配。&lt;h4&gt;主要发现&lt;/h4&gt;GDCE通过预定义的多项式函数进行增强，并利用“领域判别器”进行训练，旨在与现有的黑盒方法相比，提高下游任务中模型的透明度。&lt;h4&gt;结论&lt;/h4&gt;研究表明，通过这种方法，可以提高医疗图像分析中模型的鲁棒性和透明度。&lt;h4&gt;翻译&lt;/h4&gt;本研究探讨了如何在医疗图像分析中通过传统图像增强提高模型的鲁棒性。通过对来自不同供应商的图像应用常见的归一化方法，研究了这些方法对迁移学习中模型泛化的影响。为了解决领域特定图像动态的非线性特性无法通过简单线性变换解决的问题，将图像调和任务重新定义为曝光校正问题，并提出了一种名为全局深度曲线估计（GDCE）的方法来减少领域特定的曝光不匹配。GDCE通过预定义的多项式函数进行增强，并利用“领域判别器”进行训练，旨在与现有的黑盒方法相比，提高下游任务中模型的透明度。研究表明，通过这种方法，可以提高医疗图像分析中模型的鲁棒性和透明度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we explore how conventional image enhancement can improvemodel robustness in medical image analysis. By applying commonly usednormalization methods to images from various vendors and studying theirinfluence on model generalization in transfer learning, we show that thenonlinear characteristics of domain-specific image dynamics cannot be addressedby simple linear transforms. To tackle this issue, we reformulate the imageharmonization task as an exposure correction problem and propose a methodtermed Global Deep Curve Estimation (GDCE) to reduce domain-specific exposuremismatch. GDCE performs enhancement via a pre-defined polynomial function andis trained with the help of a ``domain discriminator'', aiming to improve modeltransparency in downstream tasks compared to existing black-box methods.</description>
      <author>example@mail.com (Yucheng Lu, Shunxin Wang, Dovile Juodelyte, Veronika Cheplygina)</author>
      <guid isPermaLink="false">2504.10080v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>CROSSAN: Towards Efficient and Effective Adaptation of Multiple Multimodal Foundation Models for Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2504.10307v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为CROSSAN的跨模态侧适配网络，用于解决多模态基础模型在序列推荐任务中的高效适配问题。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型在表示不同原始模态（如文本、图像、音频、视频等）方面表现出色，但其在序列推荐中的应用尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以高效且有效地适配多个多模态基础模型进行序列推荐任务。&lt;h4&gt;方法&lt;/h4&gt;CROSSAN利用完全解耦的侧适配器范式，并结合Mixture of Modality Expert Fusion (MOMEF)机制，实现跨模态学习并优化多模态融合的最终阶段。&lt;h4&gt;主要发现&lt;/h4&gt;CROSSAN在公开数据集上表现出色，能够适配四个基础模型并实现性能提升。随着适配的多模态基础模型增多，性能持续提升。&lt;h4&gt;结论&lt;/h4&gt;CROSSAN能够有效解决多模态基础模型在序列推荐任务中的适配问题，并有望促进相关领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a plug-and-play Cross-modal Side Adapter Network (CROSSAN) to address the issue of efficient adaptation of multimodal foundation models in the sequential recommendation task.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Foundation Models (MFMs) excel at representing diverse rawmodalities (e.g., text, images, audio, videos, etc.). As recommender systemsincreasingly incorporate these modalities, leveraging MFMs to generate betterrepresentations has great potential. However, their application in sequentialrecommendation remains largely unexplored. This is primarily because mainstreamadaptation methods, such as Fine-Tuning and even Parameter-EfficientFine-Tuning (PEFT) techniques (e.g., Adapter and LoRA), incur highcomputational costs, especially when integrating multiple modality encoders,thus hindering research progress. As a result, it remains unclear whether wecan efficiently and effectively adapt multiple (&gt;2) MFMs for the sequentialrecommendation task.  To address this, we propose a plug-and-play Cross-modal Side Adapter Network(CROSSAN). Leveraging the fully decoupled side adapter-based paradigm, CROSSANachieves high efficiency while enabling cross-modal learning across diversemodalities. To optimize the final stage of multimodal fusion across diversemodalities, we adopt the Mixture of Modality Expert Fusion (MOMEF) mechanism.CROSSAN achieves superior performance on the public datasets for adapting fourfoundation models with raw modalities. Performance consistently improves asmore MFMs are adapted. We will release our code and datasets to facilitatefuture research.</description>
      <author>example@mail.com (Junchen Fu, Yongxin Ni, Joemon M. Jose, Ioannis Arapakis, Kaiwen Zheng, Youhua Li, Xuri Ge)</author>
      <guid isPermaLink="false">2504.10307v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>ProtoGuard-guided PROPEL: Class-Aware Prototype Enhancement and Progressive Labeling for Incremental 3D Point Cloud Segmentation</title>
      <link>http://arxiv.org/abs/2504.01648v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对3D点云语义分割技术在现实场景中环境不断变化导致的灾难性遗忘问题，提出了ProtoGuard和PROPEL方法，显著提升了3D点云分割的mIoU值。&lt;h4&gt;背景&lt;/h4&gt;3D点云语义分割技术被广泛应用，但在实际环境中，由于环境不断变化，离线训练的分割模型可能会导致对先前类别的灾难性遗忘。&lt;h4&gt;目的&lt;/h4&gt;解决离线训练的分割模型在现实场景中可能出现的灾难性遗忘问题，并提出有效的CIL方法来提高3D点云分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了ProtoGuard和PROPEL方法。ProtoGuard在基础类别训练阶段维护每个类别的几何和语义原型，并通过注意力机制将其组合成原型特征。PROPEL在新型类别训练阶段继承基础特征提取器和分类器，基于密度分布和语义相似性指导伪标签的传播和更新。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在S3DIS和ScanNet数据集上取得了显著的效果，在S3DIS数据集的5步CIL场景下，3D点云分割的mIoU值提高了最多20.39%。&lt;h4&gt;结论&lt;/h4&gt;ProtoGuard和PROPEL方法能够有效解决3D点云语义分割中的灾难性遗忘问题，并显著提高分割性能。&lt;h4&gt;翻译&lt;/h4&gt;3D点云语义分割技术已被广泛应用。然而，在现实场景中，环境是不断演变的。因此，离线训练的分割模型可能会导致先前看到的类别的灾难性遗忘。类增量学习（CIL）旨在解决灾难性遗忘的问题。虽然点云很常见，但我们观察到不同类别之间存在高度相似性和不清晰的边界。同时，它们在类别分布上是不平衡的。这些问题导致了包括相似类别之间的误分类和长尾问题，这些问题在先前的CIL方法中尚未得到充分解决。因此，我们提出了ProtoGuard和PROPEL（伪标签的渐进式细化）。在基础类别训练阶段，ProtoGuard为每个类别维护几何和语义原型，这些原型通过注意力机制组合成原型特征。在新型类别训练阶段，PROPEL继承基础特征提取器和分类器，基于密度分布和语义相似性指导伪标签的传播和更新。大量的实验表明，我们的方法在S3DIS和ScanNet数据集上取得了显著的效果，在S3DIS数据集的5步CIL场景下，3D点云分割的mIoU值最多提高了20.39%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D point cloud semantic segmentation technology has been widely used.However, in real-world scenarios, the environment is evolving. Thus,offline-trained segmentation models may lead to catastrophic forgetting ofpreviously seen classes. Class-incremental learning (CIL) is designed toaddress the problem of catastrophic forgetting. While point clouds are common,we observe high similarity and unclear boundaries between different classes.Meanwhile, they are known to be imbalanced in class distribution. These lead toissues including misclassification between similar classes and the long-tailproblem, which have not been adequately addressed in previous CIL methods. Wethus propose ProtoGuard and PROPEL (Progressive Refinement Of PsEudo-Labels).In the base-class training phase, ProtoGuard maintains geometric and semanticprototypes for each class, which are combined into prototype features using anattention mechanism. In the novel-class training phase, PROPEL inherits thebase feature extractor and classifier, guiding pseudo-label propagation andupdates based on density distribution and semantic similarity. Extensiveexperiments show that our approach achieves remarkable results on both theS3DIS and ScanNet datasets, improving the mIoU of 3D point cloud segmentationby a maximum of 20.39% under the 5-step CIL scenario on S3DIS.</description>
      <author>example@mail.com (Haosheng Li, Yuecong Xu, Junjie Chen, Kemi Ding)</author>
      <guid isPermaLink="false">2504.01648v2</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>GNN-ACLP: Graph Neural Networks based Analog Circuit Link Prediction</title>
      <link>http://arxiv.org/abs/2504.10240v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Data will be made available on request&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的电路连接预测框架GNN-ACLP，旨在解决现有电路连接预测方法面临的三个主要挑战：拓扑模式利用不足、数据稀缺和适应不同网表格式有限。&lt;h4&gt;背景&lt;/h4&gt;电路连接预测在自动化模拟电路设计中至关重要，但现有方法存在三个主要问题：1) 在电路图中拓扑模式的利用不足；2) 由于标注复杂导致数据稀缺；3) 对不同网表格式的适应性有限。&lt;h4&gt;目的&lt;/h4&gt;提出GNN-ACLP框架，通过引入创新方法来解决上述挑战。&lt;h4&gt;方法&lt;/h4&gt;1) 引入SEAL框架，实现端口级别的电路连接预测精度；2) 提出Netlist Babel Fish工具，利用检索增强生成（RAG）和大型语言模型（LLM）增强网表格式的兼容性；3) 构建SpiceNetlist数据集，包含775个标注电路，涵盖10种不同类别的组件。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在SpiceNetlist数据集上，GNN-ACLP方法相较于现有方法提高了15.05%的准确率，在Image2Net数据集上提高了12.01%的准确率。&lt;h4&gt;结论&lt;/h4&gt;GNN-ACLP框架能够有效解决电路连接预测中的挑战，并显著提高预测精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Circuit link prediction identifying missing component connections fromincomplete netlists is crucial in automating analog circuit design. However,existing methods face three main challenges: 1) Insufficient use of topologicalpatterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due tothe complexity of annotations hinders model generalization; 3) Limitedadaptability to various netlist formats. We propose GNN-ACLP, a Graph NeuralNetworks (GNNs) based framework featuring three innovations to tackle thesechallenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributesfor Link Prediction) framework and achieve port-level accuracy in circuit linkprediction. Second, we propose Netlist Babel Fish, a netlist format conversiontool leveraging retrieval-augmented generation (RAG) with large language model(LLM) to enhance the compatibility of netlist formats. Finally, we constructSpiceNetlist, a comprehensive dataset that contains 775 annotated circuitsacross 10 different classes of components. The experimental results demonstratean improvement of 15.05% on the SpiceNetlist dataset and 12.01% on theImage2Net dataset over the existing approach.</description>
      <author>example@mail.com (Guanyuan Pan, Tiansheng Zhou, Bingtao Ma, Yaqi Wang, Jianxiang Zhao, Shuai Wang)</author>
      <guid isPermaLink="false">2504.10240v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Dual-Path Enhancements in Event-Based Eye Tracking: Augmented Robustness and Adaptive Temporal Modeling</title>
      <link>http://arxiv.org/abs/2504.09960v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Camera-ready version for CVPRW 2025. Accepted for presentation at the  IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops  (CVPRW 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;基于事件的眼睛跟踪技术在增强现实和人类-计算机交互中成为一个关键技术。为了解决现实世界中的挑战，如突发的眼睛运动和环境噪声，本研究提出了两个主要进展。&lt;h4&gt;背景&lt;/h4&gt;事件驱动的眼睛跟踪技术在增强现实和人类-计算机交互领域的重要性。&lt;h4&gt;目的&lt;/h4&gt;提高模型对现实世界挑战的鲁棒性，减少误差。&lt;h4&gt;方法&lt;/h4&gt;1. 引入一个鲁棒的数据增强流程，包括时间位移、空间翻转和事件删除。2. 提出KnightPupil混合架构，结合EfficientNet-B3骨干网络、双向GRU和线性时变状态空间模块。&lt;h4&gt;主要发现&lt;/h4&gt;1. 数据增强流程减少了12%的欧几里得距离误差。2. KnightPupil架构在CVPR 2025的3ET+基准测试中表现出色。&lt;h4&gt;结论&lt;/h4&gt;KnightPupil架构在AR/VR系统中的实际部署方面显示出其有效性，并为神经形态视觉的未来创新提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于事件的眼睛跟踪技术已成为增强现实和人类-计算机交互的关键技术。然而，现有方法难以应对现实世界的挑战，如突然的眼动和环境噪声。基于轻量级时空网络（一种针对边缘设备优化的因果架构）的效率，我们引入了两项关键进展。首先，一个鲁棒的数据增强流程，包括时间位移、空间翻转和事件删除，提高了模型的鲁棒性，在具有挑战性的样本上减少了12%的欧几里得距离误差（从1.70到1.61）。其次，我们提出了KnightPupil，一个结合EfficientNet-B3骨干网络用于空间特征提取、双向GRU用于上下文时序建模和线性时变状态空间模块以动态适应稀疏输入和噪声的混合架构。在CVPR 2025的3ET+基准测试中评估，我们的框架在事件驱动的眼睛跟踪挑战的私有测试集上实现了1.61的欧几里得距离，证明了其在AR/VR系统中的实际部署有效性，并为神经形态视觉的未来创新提供了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event-based eye tracking has become a pivotal technology for augmentedreality and human-computer interaction. Yet, existing methods struggle withreal-world challenges such as abrupt eye movements and environmental noise.Building on the efficiency of the Lightweight Spatiotemporal Network-a causalarchitecture optimized for edge devices-we introduce two key advancements.First, a robust data augmentation pipeline incorporating temporal shift,spatial flip, and event deletion improves model resilience, reducing Euclideandistance error by 12% (1.61 vs. 1.70 baseline) on challenging samples. Second,we propose KnightPupil, a hybrid architecture combining an EfficientNet-B3backbone for spatial feature extraction, a bidirectional GRU for contextualtemporal modeling, and a Linear Time-Varying State-Space Module to adapt tosparse inputs and noise dynamically. Evaluated on the 3ET+ benchmark, ourframework achieved 1.61 Euclidean distance on the private test set of theEvent-based Eye Tracking Challenge at CVPR 2025, demonstrating itseffectiveness for practical deployment in AR/VR systems while providing afoundation for future innovations in neuromorphic vision.</description>
      <author>example@mail.com (Hoang M. Truong, Vinh-Thuan Ly, Huy G. Tran, Thuan-Phat Nguyen, Tram T. Doan)</author>
      <guid isPermaLink="false">2504.09960v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Object Grounding via Hierarchical Contrastive Siamese Transformers</title>
      <link>http://arxiv.org/abs/2504.10048v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为H-COST的算法，用于在3D场景中根据自然语言输入定位多个对象，通过对比增强Siamese Transformer框架增强了模型对复杂点云数据的处理能力。&lt;h4&gt;背景&lt;/h4&gt;以往的多对象定位研究主要集中在单对象定位上，而现实场景中往往需要定位多个对象。&lt;h4&gt;目的&lt;/h4&gt;解决多对象定位的挑战，提高复杂语言指令的理解能力。&lt;h4&gt;方法&lt;/h4&gt;采用分层处理策略，逐步细化对象定位。引入对比增强Siamese Transformer框架，其中一个辅助网络处理来自真实标签的稳健对象关系，指导并增强第二个网络（参考网络），该网络处理分割的点云数据。&lt;h4&gt;主要发现&lt;/h4&gt;H-COST算法在多对象定位基准测试中比现有最先进的方法提升了9.5%。&lt;h4&gt;结论&lt;/h4&gt;H-COST算法在处理复杂点云数据和多对象定位方面表现出色，为解决现实世界中的多对象定位问题提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-object grounding in 3D scenes involves localizing multiple objectsbased on natural language input. While previous work has primarily focused onsingle-object grounding, real-world scenarios often demand the localization ofseveral objects. To tackle this challenge, we propose Hierarchical ContrastiveSiamese Transformers (H-COST), which employs a Hierarchical Processing strategyto progressively refine object localization, enhancing the understanding ofcomplex language instructions. Additionally, we introduce a Contrastive SiameseTransformer framework, where two networks with the identical structure areused: one auxiliary network processes robust object relations from ground-truthlabels to guide and enhance the second network, the reference network, whichoperates on segmented point-cloud data. This contrastive mechanism strengthensthe model' s semantic understanding and significantly enhances its ability toprocess complex point-cloud data. Our approach outperforms previousstate-of-the-art methods by 9.5% on challenging multi-object groundingbenchmarks.</description>
      <author>example@mail.com (Chengyi Du, Keyan Jin)</author>
      <guid isPermaLink="false">2504.10048v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>TinyLLaVA-Video-R1: Towards Smaller LMMs for Video Reasoning</title>
      <link>http://arxiv.org/abs/2504.09641v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TinyLLaVA-Video-R1，一个小型视频推理模型，它通过强化学习在通用视频问答数据集上提高了推理能力，并展示了“啊哈时刻”的涌现特性。&lt;h4&gt;背景&lt;/h4&gt;目前，通过强化学习提高大型多模态模型推理能力的研究取得了进展，但这些研究大多基于高度推理密集型数据集，并使用大规模模型作为基础。&lt;h4&gt;目的&lt;/h4&gt;提出探索小型模型推理能力的重要性，并使模型能够在通用问答数据集上解释其推理过程。&lt;h4&gt;方法&lt;/h4&gt;提出TinyLLaVA-Video-R1，这是一个基于TinyLLaVA-Video的视频理解模型，该模型经过可追踪的训练，参数不超过4B，并在通用视频问答数据集上应用强化学习。&lt;h4&gt;主要发现&lt;/h4&gt;TinyLLaVA-Video-R1在通用视频问答数据集上表现出显著的推理和思维能力提升，并展示了“啊哈时刻”的涌现特性。同时，分享了实验发现，为小型模型视频推理能力的研究提供实用见解。&lt;h4&gt;结论&lt;/h4&gt;TinyLLaVA-Video-R1证明了在小规模模型中探索推理能力的价值，并为未来研究提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;最近，通过强化学习提高大型多模态模型（LMMs）的推理能力取得了重大进展。然而，大多数现有工作都是基于高度推理密集型数据集，如数学和代码，研究人员通常选择大型模型作为基础。我们认为，对于计算资源有限的研究人员来说，探索小型模型的推理能力仍然具有价值。此外，使模型能够在通用问答数据集上解释其推理过程同样有意义。因此，我们提出了小型视频推理模型TinyLLaVA-Video-R1。基于TinyLLaVA-Video，这是一个参数不超过4B的可追踪训练视频理解模型，它不仅在使用强化学习后显著提高了在通用视频问答数据集上的推理和思维能力，还表现出“啊哈时刻”的涌现特性。此外，我们分享了一系列实验发现，旨在为未来探索小型模型视频推理（思考）能力提供实用见解。该模型可在https://github.com/ZhangXJ199/TinyLLaVA-Video-R1上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, improving the reasoning ability of large multimodal models (LMMs)through reinforcement learning has made great progress. However, most existingworks are based on highly reasoning-intensive datasets such as mathematics andcode, and researchers generally choose large-scale models as the foundation. Weargue that exploring small-scale models' reasoning capabilities remainsvaluable for researchers with limited computational resources. Moreover,enabling models to explain their reasoning processes on generalquestion-answering datasets is equally meaningful. Therefore, we present thesmall-scale video reasoning model TinyLLaVA-Video-R1. Based on TinyLLaVA-Video,a traceably trained video understanding model with no more than 4B parameters,it not only demonstrates significantly improved reasoning and thinkingcapabilities after using reinforcement learning on general Video-QA datasets,but also exhibits the emergent characteristic of "aha moments". Furthermore, weshare a series of experimental findings, aiming to provide practical insightsfor future exploration of video reasoning (thinking) abilities in small-scalemodels. It is available at https://github.com/ZhangXJ199/TinyLLaVA-Video-R1.</description>
      <author>example@mail.com (Xingjian Zhang, Siwei Wen, Wenjun Wu, Lei Huang)</author>
      <guid isPermaLink="false">2504.09641v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>AimTS: Augmented Series and Image Contrastive Learning for Time Series Classification</title>
      <link>http://arxiv.org/abs/2504.09993v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AimTS的预训练框架，用于时间序列分类任务，旨在解决现有方法在训练数据不足时准确率下降的问题。&lt;h4&gt;背景&lt;/h4&gt;现有时间序列分类方法主要在单一领域分别训练，当某些领域的训练样本不足时，准确性会下降。&lt;h4&gt;目的&lt;/h4&gt;提出AimTS框架，通过多源时间序列数据学习可泛化的表示，以提高时间序列分类的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;AimTS采用基于原型的高层对比学习方法，结合多种数据增强策略进行多源预训练。同时，引入图像模态补充结构信息，建立序列-图像对比学习，以增强泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AimTS在多源预训练后，在各种下游时间序列分类数据集上实现了良好的泛化性能，支持高效学习和少量样本学习。&lt;h4&gt;结论&lt;/h4&gt;AimTS是一种有效的时间序列分类预训练框架，能够提高模型在不同领域的泛化能力，适用于各种时间序列分类任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series classification (TSC) is an important task in time seriesanalysis. Existing TSC methods mainly train on each single domain separately,suffering from a degradation in accuracy when the samples for training areinsufficient in certain domains. The pre-training and fine-tuning paradigmprovides a promising direction for solving this problem. However, time seriesfrom different domains are substantially divergent, which challenges theeffective pre-training on multi-source data and the generalization ability ofpre-trained models. To handle this issue, we introduce Augmented Series andImage Contrastive Learning for Time Series Classification (AimTS), apre-training framework that learns generalizable representations frommulti-source time series data. We propose a two-level prototype-basedcontrastive learning method to effectively utilize various augmentations inmulti-source pre-training, which learns representations for TSC that can begeneralized to different domains. In addition, considering augmentations withinthe single time series modality are insufficient to fully addressclassification problems with distribution shift, we introduce the imagemodality to supplement structural information and establish a series-imagecontrastive learning to improve the generalization of the learnedrepresentations for TSC tasks. Extensive experiments show that aftermulti-source pre-training, AimTS achieves good generalization performance,enabling efficient learning and even few-shot learning on various downstreamTSC datasets.</description>
      <author>example@mail.com (Yuxuan Chen, Shanshan Huang, Yunyao Cheng, Peng Chen, Zhongwen Rao, Yang Shu, Bin Yang, Lujia Pan, Chenjuan Guo)</author>
      <guid isPermaLink="false">2504.09993v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Zero-shot Autonomous Microscopy for Scalable and Intelligent Characterization of 2D Materials</title>
      <link>http://arxiv.org/abs/2504.10281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为ATOMIC的自动实验系统，用于二维材料的自主表征，通过集成多种模型和算法，实现了无需额外训练的自动分析和图像识别。&lt;h4&gt;背景&lt;/h4&gt;原子尺度材料的表征通常需要经过长时间专业培训的专家，对于新发现的二维材料，即使是经过培训的专家也难以准确表征。&lt;h4&gt;目的&lt;/h4&gt;开发一个无需大量训练数据集即可理解研究目标的全自动实验系统，以实现二维材料的零样本自主表征。&lt;h4&gt;方法&lt;/h4&gt;ATOMIC系统集成了视觉基础模型（如Segment Anything Model）、大型语言模型（如ChatGPT）、无监督聚类和拓扑分析，通过提示工程自动化显微镜控制、样品扫描、图像分割和智能分析。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在分析典型MoS2样品时，实现了99.7%的单层识别准确率，并能检测到人眼难以识别的晶界裂缝。此外，系统在各种条件下仍保持稳健的准确性。&lt;h4&gt;结论&lt;/h4&gt;ATOMIC系统通过集成基础模型实现了自主分析，建立了一种可扩展且数据高效的表征范式，从根本上改变了纳米尺度材料研究的方法。&lt;h4&gt;翻译&lt;/h4&gt;Characterization of atomic-scale materials traditionally requires humanexperts with months to years of specialized training. Even for trained humanoperators, accurate and reliable characterization remains challenging when examining newly discovered materials such as two-dimensional (2D) structures. This bottleneck drives demand for fully autonomous experimentation systems capable of comprehending research objectives without requiring large training datasets. In this work, we present ATOMIC (Autonomous Technology for Optical Microscopy &amp; Intelligent Characterization), an end-to-end framework that integrates foundation models to enable fully autonomous, zero-shot characterization of 2D materials. Our system integrates the vision foundation model (i.e., Segment Anything Model), large language models (i.e., ChatGPT), unsupervised clustering, and topological analysis to automate microscope control, sample scanning, image segmentation, and intelligent analysis through prompt engineering, eliminating the need for additional training. When analyzing typical MoS2 samples, our approach achieves 99.7% segmentation accuracy for single layer identification, which is equivalent to that of humanexperts. In addition, the integrated model is able to detect grain boundary slits that are challenging to identify with human eyes. Furthermore, the system retains robust accuracy despite variable conditions including defocus, color temperature fluctuations, and exposure variations. It is applicable to a broadspectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardlessof whether they were fabricated via chemical vapor deposition or mechanical exfoliation. This work represents the implementation of foundation models to achieve autonomous analysis, establishing a scalable and data-efficient characterization paradigm that fundamentally transforms the approach to nanoscale materials research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Characterization of atomic-scale materials traditionally requires humanexperts with months to years of specialized training. Even for trained humanoperators, accurate and reliable characterization remains challenging whenexamining newly discovered materials such as two-dimensional (2D) structures.This bottleneck drives demand for fully autonomous experimentation systemscapable of comprehending research objectives without requiring large trainingdatasets. In this work, we present ATOMIC (Autonomous Technology for OpticalMicroscopy &amp; Intelligent Characterization), an end-to-end framework thatintegrates foundation models to enable fully autonomous, zero-shotcharacterization of 2D materials. Our system integrates the vision foundationmodel (i.e., Segment Anything Model), large language models (i.e., ChatGPT),unsupervised clustering, and topological analysis to automate microscopecontrol, sample scanning, image segmentation, and intelligent analysis throughprompt engineering, eliminating the need for additional training. Whenanalyzing typical MoS2 samples, our approach achieves 99.7% segmentationaccuracy for single layer identification, which is equivalent to that of humanexperts. In addition, the integrated model is able to detect grain boundaryslits that are challenging to identify with human eyes. Furthermore, the systemretains robust accuracy despite variable conditions including defocus, colortemperature fluctuations, and exposure variations. It is applicable to a broadspectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardlessof whether they were fabricated via chemical vapor deposition or mechanicalexfoliation. This work represents the implementation of foundation models toachieve autonomous analysis, establishing a scalable and data-efficientcharacterization paradigm that fundamentally transforms the approach tonanoscale materials research.</description>
      <author>example@mail.com (Jingyun Yang, Ruoyan Avery Yin, Chi Jiang, Yuepeng Hu, Xiaokai Zhu, Xingjian Hu, Sutharsika Kumar, Xiao Wang, Xiaohua Zhai, Keran Rong, Yunyue Zhu, Tianyi Zhang, Zongyou Yin, Jing Kong, Neil Zhenqiang Gong, Zhichu Ren, Haozhe Wang)</author>
      <guid isPermaLink="false">2504.10281v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Progressive Transfer Learning for Multi-Pass Fundus Image Restoration</title>
      <link>http://arxiv.org/abs/2504.10025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 12 figures including appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于渐进式迁移学习（PTL）的多次迭代图像质量恢复方法，用于改善糖尿病视网膜病变（DR）图像的质量，以支持更可靠的DR筛查。&lt;h4&gt;背景&lt;/h4&gt;糖尿病视网膜病变是导致视力障碍的主要原因之一，早期通过眼底成像进行诊断对于有效治疗规划至关重要。然而，由于照明不足、噪声、模糊和其他运动伪影等因素，眼底图像质量差给DR筛查带来了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过PTL方法迭代增强退化眼底图像的质量，确保更可靠的DR筛查。&lt;h4&gt;方法&lt;/h4&gt;研究首先训练一个Cycle GAN模型来恢复低质量图像，然后通过PTL方法在最新恢复的输出上进行多次迭代恢复，以提高每次迭代的整体质量。该方法能够在不需要任何配对数据的情况下学习盲恢复，并通过利用渐进学习和微调策略来最小化失真并保留关键视网膜特征。&lt;h4&gt;主要发现&lt;/h4&gt;在DeepDRiD大型眼底成像数据集上进行的实验表明，PTL在多次迭代图像质量恢复方面具有最先进的性能，表明PTL是一种优于迭代图像质量恢复的先进方法。&lt;h4&gt;结论&lt;/h4&gt;PTL方法在多遍修复方面表现出色，有望成为迭代图像质量恢复的优选方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diabetic retinopathy is a leading cause of vision impairment, making itsearly diagnosis through fundus imaging critical for effective treatmentplanning. However, the presence of poor quality fundus images caused by factorssuch as inadequate illumination, noise, blurring and other motion artifactsyields a significant challenge for accurate DR screening. In this study, wepropose progressive transfer learning for multi pass restoration to iterativelyenhance the quality of degraded fundus images, ensuring more reliable DRscreening. Unlike previous methods that often focus on a single passrestoration, multi pass restoration via PTL can achieve a superior blindrestoration performance that can even improve most of the good quality fundusimages in the dataset. Initially, a Cycle GAN model is trained to restore lowquality images, followed by PTL induced restoration passes over the latestrestored outputs to improve overall quality in each pass. The proposed methodcan learn blind restoration without requiring any paired data while surpassingits limitations by leveraging progressive learning and fine tuning strategiesto minimize distortions and preserve critical retinal features. To evaluatePTL's effectiveness on multi pass restoration, we conducted experiments onDeepDRiD, a large scale fundus imaging dataset specifically curated fordiabetic retinopathy detection. Our result demonstrates state of the artperformance, showcasing PTL's potential as a superior approach to iterativeimage quality restoration.</description>
      <author>example@mail.com (Uyen Phan, Ozer Can Devecioglu, Serkan Kiranyaz, Moncef Gabbouj)</author>
      <guid isPermaLink="false">2504.10025v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>RadarLLM: Empowering Large Language Models to Understand Human Motion from Millimeter-wave Point Cloud Sequence</title>
      <link>http://arxiv.org/abs/2504.09862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Radar-LLM的框架，利用大型语言模型（LLM）通过毫米波雷达进行人体运动理解，解决了毫米波雷达在语义理解上的挑战。&lt;h4&gt;背景&lt;/h4&gt;毫米波雷达在人体运动分析中提供隐私保护解决方案，但其稀疏点云对语义理解构成挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用毫米波雷达进行人体运动理解的方法，并实现隐私敏感应用中的运动理解。&lt;h4&gt;方法&lt;/h4&gt;1. 引入一个基于Aggregate VQ-VAE架构的运动引导雷达标记器，将时空点云编码为紧凑的语义标记；2. 建立雷达感知语言模型，在共享嵌入空间中实现雷达和文本之间的跨模态对齐；3. 提出一种基于物理感知的合成管道，从运动文本数据集中生成真实的雷达文本对。&lt;h4&gt;主要发现&lt;/h4&gt;Radar-LLM在合成和真实世界基准测试中实现了最先进的性能，能够将毫米波信号准确翻译成自然语言描述。&lt;h4&gt;结论&lt;/h4&gt;这一突破促进了在医疗保健和智能家居等隐私敏感应用中的全面运动理解。&lt;h4&gt;翻译&lt;/h4&gt;该框架能够将毫米波雷达信号转换为自然语言描述，为隐私敏感应用提供了有效的运动理解解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Millimeter-wave radar provides a privacy-preserving solution for human motionanalysis, yet its sparse point clouds pose significant challenges for semanticunderstanding. We present Radar-LLM, the first framework that leverages largelanguage models (LLMs) for human motion understanding using millimeter-waveradar as the sensing modality. Our approach introduces two key innovations: (1)a motion-guided radar tokenizer based on our Aggregate VQ-VAE architecture thatincorporates deformable body templates and masked trajectory modeling to encodespatiotemporal point clouds into compact semantic tokens, and (2) a radar-awarelanguage model that establishes cross-modal alignment between radar and text ina shared embedding space. To address data scarcity, we introduce aphysics-aware synthesis pipeline that generates realistic radar-text pairs frommotion-text datasets. Extensive experiments demonstrate that Radar-LLM achievesstate-of-the-art performance across both synthetic and real-world benchmarks,enabling accurate translation of millimeter-wave signals to natural languagedescriptions. This breakthrough facilitates comprehensive motion understandingin privacy-sensitive applications like healthcare and smart homes. We willrelease the full implementation to support further research onhttps://inowlzy.github.io/RadarLLM/.</description>
      <author>example@mail.com (Zengyuan Lai, Jiarui Yang, Songpengcheng Xia, Lizhou Lin, Lan Sun, Renwen Wang, Jianran Liu, Qi Wu, Ling Pei)</author>
      <guid isPermaLink="false">2504.09862v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Beamform for Cooperative Localization and Communication: A Link Heterogeneous GNN-Based Approach</title>
      <link>http://arxiv.org/abs/2504.10060v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于协同感知通信（CoISAC）系统联合波束成形的方法，旨在解决CoISAC波束成形设计中的挑战。&lt;h4&gt;背景&lt;/h4&gt;集成感知和通信（ISAC）是下一代无线网络的关键使能技术，支持高精度定位和环境重建等高级应用。协同ISAC（CoISAC）通过多个基站联合优化通信和感知性能来进一步增强这些能力。&lt;h4&gt;目的&lt;/h4&gt;针对CoISAC波束成形设计面临的系统异质性、大规模问题复杂性和对参数估计误差的敏感性等挑战，提出了一种新的解决方案。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种链路异构图神经网络（LHGNN）用于CoISAC系统的联合波束成形。LHGNN将通信和感知链路建模为异构节点，并将它们的交互建模为边，以捕捉CoISAC系统的异质性和复杂交互。此外，还引入了图注意力机制，以动态调整节点和链路的重要性，提高对信道和位置估计误差的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;数值结果表明，所提出的注意力增强的LHGNN在保持感知准确性的同时，在功率约束下实现了更高的通信速率，并且对通信信道和位置估计误差具有强鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法有效地解决了CoISAC波束成形设计中的挑战，为CoISAC系统的性能提升提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：集成感知与通信（ISAC）已成为下一代无线网络的关键推动力，支持高精度定位和环境重建等高级应用。协同ISAC（CoISAC）通过多个基站协同优化通信和感知性能进一步增强了这些能力。然而，CoISAC波束成形设计面临着系统异质性、大规模问题复杂性和对参数估计误差敏感性的重大挑战。传统的基于深度学习的技术未能充分利用CoISAC系统的独特结构特性，从而限制了其增强系统性能的能力。为了解决这些挑战，我们提出了一种用于CoISAC系统联合波束成形的方法——链路异构图神经网络（LHGNN）。与传统的方案不同，LHGNN将通信和感知链路建模为异构节点，并将它们的交互建模为边，从而能够捕捉CoISAC系统的异质性和复杂交互。此外，还引入了图注意力机制，以动态调整节点和链路的重要性，提高对信道和位置估计误差的鲁棒性。数值结果证明了所提出的注意力增强的LHGNN在保持感知准确性的同时，在功率约束下实现了更高的通信速率，并且对通信信道和位置估计误差具有强鲁棒性。所提出的方法也表现出对通信信道和位置估计误差的强鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrated sensing and communication (ISAC) has emerged as a key enabler fornext-generation wireless networks, supporting advanced applications such ashigh-precision localization and environment reconstruction. Cooperative ISAC(CoISAC) further enhances these capabilities by enabling multiple base stations(BSs) to jointly optimize communication and sensing performance throughcoordination. However, CoISAC beamforming design faces significant challengesdue to system heterogeneity, large-scale problem complexity, and sensitivity toparameter estimation errors. Traditional deep learning-based techniques fail toexploit the unique structural characteristics of CoISAC systems, therebylimiting their ability to enhance system performance. To address thesechallenges, we propose a Link-Heterogeneous Graph Neural Network (LHGNN) forjoint beamforming in CoISAC systems. Unlike conventional approaches, LHGNNmodels communication and sensing links as heterogeneous nodes and theirinteractions as edges, enabling the capture of the heterogeneous nature andintricate interactions of CoISAC systems. Furthermore, a graph attentionmechanism is incorporated to dynamically adjust node and link importance,improving robustness to channel and position estimation errors. Numericalresults demonstrate that the proposed attention-enhanced LHGNN achievessuperior communication rates while maintaining sensing accuracy under powerconstraints. The proposed method also exhibits strong robustness tocommunication channel and position estimation error.</description>
      <author>example@mail.com (Lixiang Lian, Chuanqi Bai, Yihan Xu, Huanyu Dong, Rui Cheng, Shunqing Zhang)</author>
      <guid isPermaLink="false">2504.10060v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Masked Autoencoder Self Pre-Training for Defect Detection in Microelectronics</title>
      <link>http://arxiv.org/abs/2504.10021v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了微电子缺陷检测中，由于数据和标签成本导致卷积神经网络（CNN）依然被广泛应用，而Transformer架构较少使用的问题。&lt;h4&gt;背景&lt;/h4&gt;传统上，计算机视觉领域Transformer架构成为标准，但在微电子缺陷检测领域，由于数据和标签生成成本高，导致CNN依然占据主导地位。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种基于掩码自编码器（MAE）的视觉Transformer（ViT）预训练框架，以解决微电子缺陷检测中的数据稀疏问题。&lt;h4&gt;方法&lt;/h4&gt;作者提出对目标数据集进行自预训练，使用少于10,000张扫描声学显微镜（SAM）图像，这些图像通过瞬态热分析（TTA）进行标记。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与监督ViT、在自然图像数据集上预训练的ViT以及文献中的最先进CNN缺陷检测模型相比，该方法带来了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;自预训练的模型通过聚焦于缺陷相关特征，如焊料材料中的裂纹，提供了故障特定的特征表示，表明该方法在实际微电子缺陷检测中具有可行性。&lt;h4&gt;翻译&lt;/h4&gt;While in general computer vision, transformer-based architectures have quickly become the gold standard, microelectronics defect detection still heavily relies on convolutional neural networks (CNNs). We hypothesize that this is due to the fact that a) transformers have an increased need for data and b) labelled image generation procedures for microelectronics are costly, and labelled data is therefore sparse. Whereas in other domains, pre-training on large natural image datasets can mitigate this problem, in microelectronics transfer learning is hindered due to the dissimilarity of domain data and natural images. Therefore, we evaluate self pre-training, where models are pre-trained on the target dataset, rather than another dataset. We propose a vision transformer (ViT) pre-training framework for defect detection in microelectronics based on masked autoencoders (MAE). In MAE, a large share of image patches is masked and reconstructed by the model during pre-training. We perform pre-training and defect detection using a dataset of less than 10,000 scanning acoustic microscopy (SAM) images labelled using transient thermal analysis (TTA). Our experimental results show that our approach leads to substantial performance gains compared to a) supervised ViT, b) ViT pre-trained on natural image datasets, and c) state-of-the-art CNN-based defect detection models used in the literature. Additionally, interpretability analysis reveals that our self pre-trained models, in comparison to ViT baselines, correctly focus on defect-relevant features such as cracks in the solder material. This demonstrates that our approach yields fault-specific feature representations, making our self pre-trained models viable for real-world defect detection in microelectronics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Whereas in general computer vision, transformer-based architectures havequickly become the gold standard, microelectronics defect detection stillheavily relies on convolutional neural networks (CNNs). We hypothesize thatthis is due to the fact that a) transformers have an increased need for dataand b) labelled image generation procedures for microelectronics are costly,and labelled data is therefore sparse. Whereas in other domains, pre-trainingon large natural image datasets can mitigate this problem, in microelectronicstransfer learning is hindered due to the dissimilarity of domain data andnatural images. Therefore, we evaluate self pre-training, where models arepre-trained on the target dataset, rather than another dataset. We propose avision transformer (ViT) pre-training framework for defect detection inmicroelectronics based on masked autoencoders (MAE). In MAE, a large share ofimage patches is masked and reconstructed by the model during pre-training. Weperform pre-training and defect detection using a dataset of less than 10.000scanning acoustic microscopy (SAM) images labelled using transient thermalanalysis (TTA). Our experimental results show that our approach leads tosubstantial performance gains compared to a) supervised ViT, b) ViT pre-trainedon natural image datasets, and c) state-of-the-art CNN-based defect detectionmodels used in the literature. Additionally, interpretability analysis revealsthat our self pre-trained models, in comparison to ViT baselines, correctlyfocus on defect-relevant features such as cracks in the solder material. Thisdemonstrates that our approach yields fault-specific feature representations,making our self pre-trained models viable for real-world defect detection inmicroelectronics.</description>
      <author>example@mail.com (Nikolai Röhrich, Alwin Hoffmann, Richard Nordsieck, Emilio Zarbali, Alireza Javanmardi)</author>
      <guid isPermaLink="false">2504.10021v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Transformer-Based Representation Learning for Robust Gene Expression Modeling and Cancer Prognosis</title>
      <link>http://arxiv.org/abs/2504.09704v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GexBERT是一种基于Transformer的自动编码器框架，用于基因表达数据的鲁棒性表示学习，在癌症研究中表现出色。&lt;h4&gt;背景&lt;/h4&gt;Transformer模型在自然语言和视觉任务中取得成功，但在基因表达分析中的应用受到数据稀疏性、高维度和缺失值的影响。&lt;h4&gt;目的&lt;/h4&gt;提出GexBERT，以解决基因表达数据分析中的挑战，并提高其在癌症研究中的应用。&lt;h4&gt;方法&lt;/h4&gt;GexBERT通过在大规模转录组图谱上进行预训练，学习上下文感知的基因嵌入，并使用掩码和恢复目标来捕捉数千个基因之间的共表达关系。&lt;h4&gt;主要发现&lt;/h4&gt;GexBERT在癌症研究中三个关键任务上表现出色：泛癌症分类、癌症特异性生存预测和缺失值填补。它提高了分类准确率，改善了生存预测，并在高缺失率下优于传统填补方法。此外，其基于注意力的可解释性揭示了具有生物学意义的基因模式。&lt;h4&gt;结论&lt;/h4&gt;GexBERT是一个可扩展且有效的基因表达建模工具，在基因覆盖有限或不完整的环境中具有转化潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer-based models have achieved remarkable success in natural languageand vision tasks, but their application to gene expression analysis remainslimited due to data sparsity, high dimensionality, and missing values. Wepresent GexBERT, a transformer-based autoencoder framework for robustrepresentation learning of gene expression data. GexBERT learns context-awaregene embeddings by pretraining on large-scale transcriptomic profiles with amasking and restoration objective that captures co-expression relationshipsamong thousands of genes. We evaluate GexBERT across three critical tasks incancer research: pan-cancer classification, cancer-specific survivalprediction, and missing value imputation. GexBERT achieves state-of-the-artclassification accuracy from limited gene subsets, improves survival predictionby restoring expression of prognostic anchor genes, and outperformsconventional imputation methods under high missingness. Furthermore, itsattention-based interpretability reveals biologically meaningful gene patternsacross cancer types. These findings demonstrate the utility of GexBERT as ascalable and effective tool for gene expression modeling, with translationalpotential in settings where gene coverage is limited or incomplete.</description>
      <author>example@mail.com (Shuai Jiang, Saeed Hassanpour)</author>
      <guid isPermaLink="false">2504.09704v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>EthCluster: An Unsupervised Static Analysis Method for Ethereum Smart Contract</title>
      <link>http://arxiv.org/abs/2504.09977v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了智能合约的设计问题，提出了一种利用无监督学习来识别以太坊智能合约Solidity源代码中的漏洞的方法。&lt;h4&gt;背景&lt;/h4&gt;设计不当的智能合约容易受到攻击，可能被攻击者利用漏洞窃取管理的虚拟货币。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法来检测智能合约中的特定漏洞。&lt;h4&gt;方法&lt;/h4&gt;使用无监督学习训练模型，从实际漏洞样本中获取数据，包括SmartBugs Curated和SolidiFI Benchmark数据集，用于开发一种健壮的无监督静态分析方法。该方法使用聚类算法来识别异常，随后将这些异常分类为有漏洞的智能合约。&lt;h4&gt;主要发现&lt;/h4&gt;检测到了五种特定漏洞：重入性、访问控制、时间戳依赖、tx.origin和未检查的低级别调用。&lt;h4&gt;结论&lt;/h4&gt;通过这种方法，可以有效地识别和分类有漏洞的智能合约。&lt;h4&gt;翻译&lt;/h4&gt;Poorly designed smart contracts are particularly vulnerable, as they may allow attackers to exploit weaknesses and steal the virtual currency they manage. In this study, we train a model using unsupervised learning to identify vulnerabilities in the Solidity source code of Ethereum smart contracts. To address the challenges associated with real-world smart contracts, our training data is derived from actual vulnerability samples obtained from datasets such as SmartBugs Curated and the SolidiFI Benchmark. These datasets enable us to develop a robust unsupervised static analysis method for detecting five specific vulnerabilities: Reentrancy, Access Control, Timestamp Dependency, tx.origin, and Unchecked Low-Level Calls. We employ clustering algorithms to identify outliers, which are subsequently classified as vulnerable smart contracts.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Poorly designed smart contracts are particularly vulnerable, as they mayallow attackers to exploit weaknesses and steal the virtual currency theymanage. In this study, we train a model using unsupervised learning to identifyvulnerabilities in the Solidity source code of Ethereum smart contracts. Toaddress the challenges associated with real-world smart contracts, our trainingdata is derived from actual vulnerability samples obtained from datasets suchas SmartBugs Curated and the SolidiFI Benchmark. These datasets enable us todevelop a robust unsupervised static analysis method for detecting fivespecific vulnerabilities: Reentrancy, Access Control, Timestamp Dependency,tx.origin, and Unchecked Low-Level Calls. We employ clustering algorithms toidentify outliers, which are subsequently classified as vulnerable smartcontracts.</description>
      <author>example@mail.com (Hong-Sheng Huang, Jen-Yi Ho, Hao-Wen Chen, Hung-Min Sun)</author>
      <guid isPermaLink="false">2504.09977v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>VideoAds for Fast-Paced Video Understanding: Where Opensource Foundation Models Beat GPT-4o &amp; Gemini-1.5 Pro</title>
      <link>http://arxiv.org/abs/2504.09282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了VideoAds，这是一个专门用于评估多模态大型语言模型（MLLMs）在广告视频上性能的数据集。该数据集包含经过精心挑选的广告视频和手动标注的多样化问题，涉及视觉发现、视频摘要和视觉推理三个核心任务。&lt;h4&gt;背景&lt;/h4&gt;广告视频由于其结构化的叙事和快速的场景转换，通常比同等长度的普通视频复杂得多，这对MLLMs提出了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;创建VideoAds数据集，以评估MLLMs在处理广告视频方面的性能。&lt;h4&gt;方法&lt;/h4&gt;VideoAds数据集包含复杂的广告视频和针对三个核心任务（视觉发现、视频摘要和视觉推理）的手动标注问题。还提出了一种定量方法来比较VideoAds与现有基准在视频复杂度方面的表现。&lt;h4&gt;主要发现&lt;/h4&gt;开源模型Qwen2.5-VL-72B在VideoAds上达到了73.35%的准确率，超过了GPT-4o（66.82%）和Gemini-1.5 Pro（69.66%）。在视频摘要和推理方面，两个专有模型落后于开源模型，但在视觉发现方面表现最佳。人类专家的准确率达到了94.27%。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，提高MLLMs的时间建模能力是必要的，并且VideoAds数据集可能成为未来研究理解需要高FPS采样的视频的关键基准。&lt;h4&gt;翻译&lt;/h4&gt;本文提出VideoAds数据集，旨在评估多模态大型语言模型在广告视频上的性能。数据集包含复杂广告视频和针对视觉发现、视频摘要和视觉推理的手动标注问题。实验发现，开源模型Qwen2.5-VL-72B在VideoAds上表现最佳，而人类专家的准确率高达94.27%。这强调了提升MLLMs时间建模能力的重要性，并指出VideoAds数据集作为理解高FPS采样视频的关键基准的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advertisement videos serve as a rich and valuable source of purpose-driveninformation, encompassing high-quality visual, textual, and contextual cuesdesigned to engage viewers. They are often more complex than general videos ofsimilar duration due to their structured narratives and rapid scenetransitions, posing significant challenges to multi-modal large language models(MLLMs). In this work, we introduce VideoAds, the first dataset tailored forbenchmarking the performance of MLLMs on advertisement videos. VideoAdscomprises well-curated advertisement videos with complex temporal structures,accompanied by \textbf{manually} annotated diverse questions across three coretasks: visual finding, video summary, and visual reasoning. We propose aquantitative measure to compare VideoAds against existing benchmarks in termsof video complexity. Through extensive experiments, we find thatQwen2.5-VL-72B, an opensource MLLM, achieves 73.35\% accuracy on VideoAds,outperforming GPT-4o (66.82\%) and Gemini-1.5 Pro (69.66\%); the twoproprietary models especially fall behind the opensource model in videosummarization and reasoning, but perform the best in visual finding. Notably,human experts easily achieve a remarkable accuracy of 94.27\%. These resultsunderscore the necessity of advancing MLLMs' temporal modeling capabilities andhighlight VideoAds as a potentially pivotal benchmark for future research inunderstanding video that requires high FPS sampling. The dataset and evaluationcode will be publicly available at https://videoadsbenchmark.netlify.app.</description>
      <author>example@mail.com (Zheyuan Zhang, Monica Dou, Linkai Peng, Hongyi Pan, Ulas Bagci, Boqing Gong)</author>
      <guid isPermaLink="false">2504.09282v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>IsoSEL: Isometric Structural Entropy Learning for Deep Graph Clustering in Hyperbolic Space</title>
      <link>http://arxiv.org/abs/2504.09970v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to IEEE TPAMI, 33 pages, including technical appendix of 16  pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于信息理论的深度图聚类方法，旨在解决传统方法在处理不平衡图和识别少数群体时的局限性。&lt;h4&gt;背景&lt;/h4&gt;图聚类是机器学习中的一个长期研究主题。尽管深度学习方法在近年来取得了令人鼓舞的结果，但它们通常需要预先定义的聚类数量K，并且在处理不平衡图时，特别是在识别少数群体方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;研究一个既具有挑战性又实用的深度图聚类问题，即在不考虑现实中的不平衡性的情况下，不使用K值进行图聚类。&lt;h4&gt;方法&lt;/h4&gt;从信息理论的新视角（即结构信息）来解决这个问题。首先，建立了一种新的可微结构信息，将离散形式主义推广到连续领域，以便通过梯度反向传播创建最佳的分区树，揭示聚类结构。随后，提出了一种名为IsoSEL的深度图聚类框架，设计了一种双曲神经网络来学习双曲空间洛伦兹模型中的分区树，并进一步进行了洛伦兹树对比学习，同时使用等距增强。&lt;h4&gt;主要发现&lt;/h4&gt;该方法理论上证明了其在不要求K值的情况下进行聚类的能力，并在不平衡图中识别少数群体，同时将时间复杂度降低到与节点数量O(N)相关。&lt;h4&gt;结论&lt;/h4&gt;在五个基准数据集上的大量实验表明，IsoSEL的平均NMI（归一化互信息）比14个最近的基线高出+1.3%，证明了该方法的优越性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图聚类是机器学习中的一个长期研究主题。近年来，深度学习方法取得了令人鼓舞的结果，但它们仍然需要预先定义的聚类数量K，并且通常在处理不平衡图时遇到困难，特别是在识别少数群体方面。这些局限性促使我们研究一个既具有挑战性又实用的难题：在不考虑现实中的不平衡性的情况下，不使用K值的深度图聚类。我们从信息理论（即结构信息）的新视角来解决这个问题。在文献中，结构信息在深度聚类中很少被触及，经典定义在离散形式主义中存在不足，忽略了节点属性，并表现出难以承受的复杂性。在本文中，我们首先建立了一种新的可微结构信息，将离散形式主义推广到连续领域，以便通过梯度反向传播创建最佳的分区树，揭示聚类结构。从理论上讲，我们证明了其在不要求K值的情况下进行聚类的能力，并在不平衡图中识别少数群体，同时将时间复杂度降低到与节点数量O(N)相关。随后，我们提出了一种名为IsoSEL的深度图聚类框架，其中我们设计了一种双曲神经网络来学习双曲空间洛伦兹模型中的分区树，并进一步进行了洛伦兹树对比学习，同时使用等距增强。结果，分区树通过互信息最大化结合了节点属性，而聚类分配则通过所提出的树对比学习得到细化。在五个基准数据集上的大量实验表明，IsoSEL的平均NMI比14个最近的基线高出+1.3%，证明了该方法的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph clustering is a longstanding topic in machine learning. In recentyears, deep learning methods have achieved encouraging results, but they stillrequire predefined cluster numbers K, and typically struggle with imbalancedgraphs, especially in identifying minority clusters. The limitations motivateus to study a challenging yet practical problem: deep graph clustering withoutK considering the imbalance in reality. We approach this problem from a freshperspective of information theory (i.e., structural information). In theliterature, structural information has rarely been touched in deep clustering,and the classic definition falls short in its discrete formulation, neglectingnode attributes and exhibiting prohibitive complexity. In this paper, we firstestablish a new Differentiable Structural Information, generalizing thediscrete formalism to continuous realm, so that the optimal partitioning tree,revealing the cluster structure, can be created by the gradientbackpropagation. Theoretically, we demonstrate its capability in clusteringwithout requiring K and identifying the minority clusters in imbalanced graphs,while reducing the time complexity to O(N) w.r.t. the number of nodes.Subsequently, we present a novel IsoSEL framework for deep graph clustering,where we design a hyperbolic neural network to learn the partitioning tree inthe Lorentz model of hyperbolic space, and further conduct Lorentz TreeContrastive Learning with isometric augmentation. As a result, the partitioningtree incorporates node attributes via mutual information maximization, whilethe cluster assignment is refined by the proposed tree contrastive learning.Extensive experiments on five benchmark datasets show the IsoSEL outperforms 14recent baselines by an average of +1.3% in NMI.</description>
      <author>example@mail.com (Li Sun, Zhenhao Huang, Yujie Wang, Hongbo Lv, Chunyang Liu, Hao Peng, Philip S. Yu)</author>
      <guid isPermaLink="false">2504.09970v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data</title>
      <link>http://arxiv.org/abs/2504.09967v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为IMAX的图像中心多标注X射线数据集，旨在通过数据构建层面增强医疗多模态大型语言模型的多任务学习能力。&lt;h4&gt;背景&lt;/h4&gt;医疗通用基础模型的出现改变了传统的特定任务模型开发范式，但近期进展过于强调简单数据扩展或架构组件增强，而忽视了从数据中心的视角重新审视多任务学习。&lt;h4&gt;目的&lt;/h4&gt;提出IMAX数据集，旨在提升医疗多模态大型语言模型的多任务学习能力。&lt;h4&gt;方法&lt;/h4&gt;IMAX具有高质量的数据整理，包含超过354K条适用于多种医疗任务的数据条目。每个X射线图像都与平均4.10个任务和7.46个训练条目相关联。与DMAX相比，IMAX在七个开源最先进的医疗MLLMs上展现出显著的性能提升。同时，研究了IMAX和DMAX训练过程中的统计模式差异，探讨了优化动态与多任务性能之间的潜在相关性，并提出了基于DMAX的优化训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;IMAX在七个开源最先进的医疗MLLMs上展现了3.20%到21.05%的显著多任务平均性能提升。IMAX和DMAX训练过程中表现出不同的统计模式，优化动态与多任务性能之间存在潜在相关性。&lt;h4&gt;结论&lt;/h4&gt;IMAX数据集能够有效提升医疗多模态大型语言模型的多任务学习能力，并通过优化训练策略解决获取高质量IMAX数据的实际困境。&lt;h4&gt;翻译&lt;/h4&gt;摘要：医疗通用基础模型的出现颠覆了传统的特定任务模型开发范式，旨在通过在大规模医疗数据集上进行联合训练更好地处理多个任务。然而，近期的进展过于强调简单数据扩展或架构组件增强，而忽视了从数据中心的视角重新审视多任务学习。关键的是，简单地汇总现有数据资源会导致图像任务对齐分散，无法培养全面图像理解或与多维图像解释的临床需求相一致。在本文中，我们介绍了图像中心的多标注X射线数据集（IMAX），这是第一次从数据构建层面尝试增强医疗多模态大型语言模型（MLLMs）的多任务学习能力。具体来说，IMAX具有以下特点：1）高质量的数据整理。包含适用于七种不同医疗任务的综合数据集，超过354K条条目。2）图像中心的密集标注。每个X射线图像与平均4.10个任务和7.46个训练条目相关联，确保每张图像的多任务表示丰富性。与通用的分散多标注X射线数据集（DMAX）相比，IMAX在七个开源最先进的医疗MLLMs上始终显示出3.20%到21.05%的显著多任务平均性能提升。此外，我们研究了IMAX和DMAX训练过程中表现出的统计模式差异，探讨了优化动态与多任务性能之间的潜在相关性。最后，利用IMAX数据构建的核心概念，我们提出了一种基于DMAX的优化训练策略，以缓解在实际场景中获取高质量IMAX数据的困境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of medical generalist foundation models has revolutionizedconventional task-specific model development paradigms, aiming to better handlemultiple tasks through joint training on large-scale medical datasets. However,recent advances prioritize simple data scaling or architectural componentenhancement, while neglecting to re-examine multi-task learning from adata-centric perspective. Critically, simply aggregating existing dataresources leads to decentralized image-task alignment, which fails to cultivatecomprehensive image understanding or align with clinical needs formulti-dimensional image interpretation. In this paper, we introduce theimage-centric multi-annotation X-ray dataset (IMAX), the first attempt toenhance the multi-task learning capabilities of medical multi-modal largelanguage models (MLLMs) from the data construction level. To be specific, IMAXis featured from the following attributes: 1) High-quality data curation. Acomprehensive collection of more than 354K entries applicable to sevendifferent medical tasks. 2) Image-centric dense annotation. Each X-ray image isassociated with an average of 4.10 tasks and 7.46 training entries, ensuringmulti-task representation richness per image. Compared to the generaldecentralized multi-annotation X-ray dataset (DMAX), IMAX consistentlydemonstrates significant multi-task average performance gains ranging from3.20% to 21.05% across seven open-source state-of-the-art medical MLLMs.Moreover, we investigate differences in statistical patterns exhibited by IMAXand DMAX training processes, exploring potential correlations betweenoptimization dynamics and multi-task performance. Finally, leveraging the coreconcept of IMAX data construction, we propose an optimized DMAX-based trainingstrategy to alleviate the dilemma of obtaining high-quality IMAX data inpractical scenarios.</description>
      <author>example@mail.com (Xun Zhu, Fanbin Mo, Zheng Zhang, Jiaxi Wang, Yiming Shi, Ming Wu, Chuang Zhang, Miao Li, Ji Wu)</author>
      <guid isPermaLink="false">2504.09967v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>3D CoCa: Contrastive Learners are 3D Captioners</title>
      <link>http://arxiv.org/abs/2504.09518v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为3D CoCa的3D场景描述方法，通过结合对比视觉-语言学习和3D字幕生成，有效描述3D场景内容。&lt;h4&gt;背景&lt;/h4&gt;由于点云的稀疏性和现有方法的跨模态对齐较弱，3D场景描述在自然语言中仍然是一个高度挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的统一框架，以解决3D场景描述中的挑战。&lt;h4&gt;方法&lt;/h4&gt;3D CoCa利用冻结的CLIP视觉-语言骨干网络提供丰富的语义先验，一个空间感知的3D场景编码器来捕获几何上下文，以及一个多模态解码器来生成描述性字幕。&lt;h4&gt;主要发现&lt;/h4&gt;与依赖于显式物体提议的前两阶段方法不同，3D CoCa在共享特征空间中联合优化对比和字幕生成目标，消除了对外部检测器或手工提议的需求。这种联合训练范式通过对齐3D和文本表示，实现了更强的空间推理和更丰富的语义基础。&lt;h4&gt;结论&lt;/h4&gt;在ScanRefer和Nr3D基准测试上，3D CoCa在CIDEr指标上分别比现有最佳方法提高了10.2%和5.76%，0.5IoU。&lt;h4&gt;翻译&lt;/h4&gt;3D字幕描述，旨在用自然语言描述3D场景的内容，由于点云固有的稀疏性和现有方法中存在的弱跨模态对齐，这仍然是一个高度具有挑战性的任务。为了解决这些挑战，我们提出了一种名为3D CoCa的新颖统一框架，该框架无缝地将对比视觉-语言学习与3D字幕生成结合到一个架构中。我们的方法利用一个冻结的CLIP视觉-语言骨干网络来提供丰富的语义先验，一个空间感知的3D场景编码器来捕获几何上下文，以及一个多模态解码器来生成描述性字幕。与依赖于显式物体提议的前两阶段方法不同，3D CoCa在共享特征空间中联合优化对比和字幕生成目标，消除了对外部检测器或手工提议的需求。这种联合训练范式通过对齐3D和文本表示，实现了更强的空间推理和更丰富的语义基础。在ScanRefer和Nr3D基准测试上，3D CoCa在CIDEr指标上分别比现有最佳方法提高了10.2%和5.76%，0.5IoU。代码可在https://github.com/AIGeeksGroup/3DCoCa上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D captioning, which aims to describe the content of 3D scenes in naturallanguage, remains highly challenging due to the inherent sparsity of pointclouds and weak cross-modal alignment in existing methods. To address thesechallenges, we propose 3D CoCa, a novel unified framework that seamlesslycombines contrastive vision-language learning with 3D caption generation in asingle architecture. Our approach leverages a frozen CLIP vision-languagebackbone to provide rich semantic priors, a spatially-aware 3D scene encoder tocapture geometric context, and a multi-modal decoder to generate descriptivecaptions. Unlike prior two-stage methods that rely on explicit objectproposals, 3D CoCa jointly optimizes contrastive and captioning objectives in ashared feature space, eliminating the need for external detectors orhandcrafted proposals. This joint training paradigm yields stronger spatialreasoning and richer semantic grounding by aligning 3D and textualrepresentations. Extensive experiments on the ScanRefer and Nr3D benchmarksdemonstrate that 3D CoCa significantly outperforms current state-of-the-arts by10.2% and 5.76% in CIDEr at 0.5IoU, respectively. Code will be available athttps://github.com/AIGeeksGroup/3DCoCa.</description>
      <author>example@mail.com (Ting Huang, Zeyu Zhang, Yemin Wang, Hao Tang)</author>
      <guid isPermaLink="false">2504.09518v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>OVERLORD: Ultimate Scaling of DataLoader for Multi-Source Large Foundation Model Training</title>
      <link>http://arxiv.org/abs/2504.09844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了现代大型基础模型（LFMs）训练框架中的数据并行范式和数据加载器，分析了其面临的挑战，并提出了一种名为OVERLORD的工业级分布式数据加载架构以解决这些问题。&lt;h4&gt;背景&lt;/h4&gt;现代框架使用数据加载器进行数据并行训练，这种设计简单但存在两个基本挑战：工作负载不平衡和资源消耗问题。&lt;h4&gt;目的&lt;/h4&gt;提高大型基础模型的训练效率和资源利用率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为OVERLORD的分布式数据加载架构，包含以下三个创新点：集中式和声明式的数据平面、分角色的源加载器和数据构造者、以及具有差异检查点的影子加载器。&lt;h4&gt;主要发现&lt;/h4&gt;OVERLORD在多千GPU的生产集群上实现了以下效果：4.5倍的端到端训练吞吐量提升，CPU内存使用量至少减少了3.6倍。&lt;h4&gt;结论&lt;/h4&gt;OVERLORD是一种有效的解决方案，能够显著提升大型基础模型的训练效率和资源利用率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern frameworks for training large foundation models (LFMs) employ dataloaders in a data parallel paradigm. While this design offers implementationsimplicity, it introduces two fundamental challenges. First, due to thequadratic computational complexity of the attention operator, the non-uniformsample distribution over data-parallel ranks leads to a significant workloadimbalance among loaders, which degrades the training efficiency. This paradigmalso impedes the implementation of data mixing algorithms (e.g., curriculumlearning) over different datasets. Second, to acquire a broad range ofcapability, LFMs training ingests data from diverse sources, each with distinctfile access states. Colocating massive datasets within loader instances caneasily exceed local pod memory capacity. Additionally, heavy sources withhigher transformation latency require larger worker pools, further exacerbatingmemory consumption.  We present OVERLORD, an industrial-grade distributed data loadingarchitecture with three innovations: (1) A centralized and declarative dataplane, which facilitates elastic data orchestration strategy, such aslong-short context, multimodal, and curriculum learning; (2) Disaggregatedmultisource preprocessing through role-specific actors, i.e., Source Loadersand Data Constructors, leveraging autoscaling for Source Loaders towardsheterogeneous and evolving source preprocessing cost; (3) Shadow Loaders withdifferential checkpointing for uninterrupted fault recovery. Deployed onproduction clusters scaling to multi-thousand GPU, OVERLORD achieves: (1) 4.5xend-to-end training throughput improvement, (2) a minimum 3.6x reduction in CPUmemory usage, with further improvements to be added in later experiments.</description>
      <author>example@mail.com (Juntao Zhao, Qi Lu, Wei Jia, Borui Wan, Lei Zuo, Junda Feng, Jianyu Jiang, Yangrui Chen, Shuaishuai Cao, Jialing He, Kaihua Jiang, Yuanzhe Hu, Yanghua Peng, Haibin Lin, Xin Liu, Chuan Wu)</author>
      <guid isPermaLink="false">2504.09844v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>COUNTER: Cluster GCN based Energy Efficient Resource Management for Sustainable Cloud Computing Environments</title>
      <link>http://arxiv.org/abs/2504.09995v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint version accepted at IEEE ICDCS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为COUNTER的模型，用于可持续的云资源管理，通过集成集群图神经网络在模拟云环境中评估，旨在减少能源消耗并保持服务质量参数。&lt;h4&gt;背景&lt;/h4&gt;云计算提供了灵活的IT应用开发环境，但大型数据中心因信息通信技术组件而消耗大量电力，随着大型人工智能模型的部署增加，这一问题更加严重，对全球环境产生重大影响。&lt;h4&gt;目的&lt;/h4&gt;提出COUNTER模型，旨在减少云计算中的能源消耗，同时保持服务质量。&lt;h4&gt;方法&lt;/h4&gt;COUNTER模型与集群图神经网络集成，并在模拟云环境中进行评估，与基于门控图神经网络的、旨在实现云计算碳中性的HUNTER模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与HUNTER模型相比，COUNTER模型在资源利用率、能源消耗和成本效益方面均有改进。&lt;h4&gt;结论&lt;/h4&gt;COUNTER模型为可持续的云资源管理提供了一种有效的方法，有助于减少能源消耗并提高云服务的效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：云计算，得益于信息技术的普及，为IT应用的开发提供了一个基础环境，为企业提供了几乎无限的、按使用付费的计算资源。然而，由于信息通信技术（ICT）组件，云计算服务托管的大型数据中心每年消耗大量的电力。这一问题因大型人工智能（AI）模型的增加部署而加剧，这些模型通常依赖于分布式数据中心，从而对全球环境产生重大影响。本研究提出了一种名为COUNTER的模型，旨在实现可持续的云资源管理。COUNTER与集群图神经网络集成，并在模拟云环境中进行评估，旨在在保持服务质量参数的同时减少能源消耗。实验结果表明，与基于门控图神经网络的、旨在实现云计算碳中性的HUNTER基线模型相比，COUNTER在资源利用率、能源消耗和成本效益方面均有改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cloud computing, thanks to the pervasiveness of information technologies,provides a foundational environment for developing IT applications, offeringorganizations virtually unlimited and flexible computing resources on apay-per-use basis. However, the large data centres where cloud computingservices are hosted consume significant amounts of electricity annually due toInformation and Communication Technology (ICT) components. This issue isexacerbated by the increasing deployment of large artificial intelligence (AI)models, which often rely on distributed data centres, thereby significantlyimpacting the global environment. This study proposes the COUNTER model,designed for sustainable cloud resource management. COUNTER is integrated withcluster graph neural networks and evaluated in a simulated cloud environment,aiming to reduce energy consumption while maintaining quality of serviceparameters. Experimental results demonstrate improvements in resourceutilisation, energy consumption, and cost effectiveness compared to thebaseline model, HUNTER, which employs a gated graph neural network aimed atachieving carbon neutrality in cloud computing for modern ICT systems.</description>
      <author>example@mail.com (Han Wang, Sukhpal Singh Gill, Steve Uhlig)</author>
      <guid isPermaLink="false">2504.09995v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Causal integration of chemical structures improves representations of microscopy images for morphological profiling</title>
      <link>http://arxiv.org/abs/2504.09544v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了MICON（分子-图像对比学习）框架，该框架通过将化学化合物作为诱导细胞表型反事实变换的治疗方法，在自我监督预训练中提高高通量显微镜屏幕中图像的学习表示。&lt;h4&gt;背景&lt;/h4&gt;尽管许多高通量显微镜屏幕本质上是多模态的，因为它们涉及化学或遗传扰动以及基于图像的读出，但大多数当前方法仅从图像中学习。&lt;h4&gt;目的&lt;/h4&gt;研究假设在自我监督预训练期间结合化学化合物结构可以提高高通量显微镜屏幕中图像的学习表示。&lt;h4&gt;方法&lt;/h4&gt;提出了MICON框架，该框架将化学化合物建模为诱导细胞表型反事实变换的治疗方法。&lt;h4&gt;主要发现&lt;/h4&gt;MICON在识别药物在独立重复和数据生成中心之间可重复效应的挑战性评估环境中，显著优于CellProfiler和现有的基于深度学习的表示学习方法。&lt;h4&gt;结论&lt;/h4&gt;将化学化合物信息纳入学习过程可以在评估环境中提供一致的改进，并且将化合物在因果框架中特别建模为治疗方法，优于直接在单一表示空间中对齐图像和化合物的方法。这表明了形态分析中表示学习的新方向，即方法应明确考虑显微镜筛选数据的模态性质。&lt;h4&gt;翻译&lt;/h4&gt;最近，自我监督深度学习在量化高通量显微镜屏幕中的细胞形态变化（称为形态分析）方面取得了进展。然而，大多数当前方法仅从图像中学习，尽管许多屏幕本质上是多模态的，因为它们涉及化学或遗传扰动以及基于图像的读出。我们假设在自我监督预训练期间结合化学化合物结构可以提高高通量显微镜屏幕中图像的学习表示。我们引入了一个表示学习框架，MICON（分子-图像对比学习），该框架将化学化合物建模为诱导细胞表型反事实变换的治疗方法。MICON在需要识别药物在独立重复和数据生成中心之间可重复效应的挑战性评估环境中，显著优于CellProfiler和现有的基于深度学习的表示学习方法。我们证明，将化学化合物信息纳入学习过程可以在评估环境中提供一致的改进，并且将化合物在因果框架中特别建模为治疗方法，优于直接在单一表示空间中对齐图像和化合物的方法。我们的发现指向了形态分析中表示学习的新方向，表明方法应明确考虑显微镜筛选数据的模态性质。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in self-supervised deep learning have improved our ability toquantify cellular morphological changes in high-throughput microscopy screens,a process known as morphological profiling. However, most current methods onlylearn from images, despite many screens being inherently multimodal, as theyinvolve both a chemical or genetic perturbation as well as an image-basedreadout. We hypothesized that incorporating chemical compound structure duringself-supervised pre-training could improve learned representations of images inhigh-throughput microscopy screens. We introduce a representation learningframework, MICON (Molecular-Image Contrastive Learning), that models chemicalcompounds as treatments that induce counterfactual transformations of cellphenotypes. MICON significantly outperforms classical hand-crafted featuressuch as CellProfiler and existing deep-learning-based representation learningmethods in challenging evaluation settings where models must identifyreproducible effects of drugs across independent replicates and data-generatingcenters. We demonstrate that incorporating chemical compound information intothe learning process provides consistent improvements in our evaluation settingand that modeling compounds specifically as treatments in a causal frameworkoutperforms approaches that directly align images and compounds in a singlerepresentation space. Our findings point to a new direction for representationlearning in morphological profiling, suggesting that methods should explicitlyaccount for the multimodal nature of microscopy screening data.</description>
      <author>example@mail.com (Yemin Yu, Neil Tenenholtz, Lester Mackey, Ying Wei, David Alvarez-Melis, Ava P. Amini, Alex X. Lu)</author>
      <guid isPermaLink="false">2504.09544v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Comorbidity-Informed Transfer Learning for Neuro-developmental Disorder Diagnosis</title>
      <link>http://arxiv.org/abs/2504.09463v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Comorbidity-Informed Transfer Learning（CITL）的框架，用于通过fMRI诊断神经发育障碍，以提高深度学习辅助诊断（CAD）的准确性。&lt;h4&gt;背景&lt;/h4&gt;神经发育障碍表现为认知、沟通、行为和适应性的功能障碍，而基于深度学习的CAD可以缓解神经影像学方面的医疗资源压力。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效诊断神经发育障碍的CAD方法，特别是在fMRI数据上。&lt;h4&gt;方法&lt;/h4&gt;CITL框架结合了迁移学习和伪标签技术，去除fMRI时间域中的干扰模式，并使用编码器-解码器架构生成新的表示。这些新表示在结构简单的分类网络中进行训练，以获得CAD模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CITL在检测自闭症谱系障碍和注意力缺陷多动障碍方面分别达到了76.32%和73.15%的准确性，优于现有的相关迁移学习工作。&lt;h4&gt;结论&lt;/h4&gt;CITL框架在神经发育障碍的诊断中具有竞争力，并提供了跨学科的新视角。&lt;h4&gt;翻译&lt;/h4&gt;Neuro-developmental disorders are manifested as dysfunctions in cognition, communication, behavior and adaptability, and deep learning-based computer-aided diagnosis (CAD) can alleviate the increasingly strained healthcare resources on neuroimaging. However, neuroimaging such as fMRI contains complex spatio-temporal features, which makes the corresponding representations susceptible to a variety of distractions, thus leading to less effective in CAD. For the first time, we present a Comorbidity-Informed Transfer Learning (CITL) framework for diagnosing neuro-developmental disorders using fMRI. In CITL, a new reinforced representation generation network is proposed, which first combines transfer learning with pseudo-labelling to remove interfering patterns from the temporal domain of fMRI and generates new representations using encoder-decoder architecture. The new representations are then trained in an architecturally simple classification network to obtain CAD model. In particular, the framework fully considers the comorbidity mechanisms of neuro-developmental disorders and effectively integrates them with semi-supervised learning and transfer learning, providing new perspectives on interdisciplinary. Experimental results demonstrate that CITL achieves competitive accuracies of 76.32% and 73.15% for detecting autism spectrum disorder and attention deficit hyperactivity disorder, respectively, which outperforms existing related transfer learning work for 7.2% and 0.5% respectively.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neuro-developmental disorders are manifested as dysfunctions in cognition,communication, behaviour and adaptability, and deep learning-basedcomputer-aided diagnosis (CAD) can alleviate the increasingly strainedhealthcare resources on neuroimaging. However, neuroimaging such as fMRIcontains complex spatio-temporal features, which makes the correspondingrepresentations susceptible to a variety of distractions, thus leading to lesseffective in CAD. For the first time, we present a Comorbidity-InformedTransfer Learning(CITL) framework for diagnosing neuro-developmental disordersusing fMRI. In CITL, a new reinforced representation generation network isproposed, which first combines transfer learning with pseudo-labelling toremove interfering patterns from the temporal domain of fMRI and generates newrepresentations using encoder-decoder architecture. The new representations arethen trained in an architecturally simple classification network to obtain CADmodel. In particular, the framework fully considers the comorbidity mechanismsof neuro-developmental disorders and effectively integrates them withsemi-supervised learning and transfer learning, providing new perspectives oninterdisciplinary. Experimental results demonstrate that CITL achievescompetitive accuracies of 76.32% and 73.15% for detecting autism spectrumdisorder and attention deficit hyperactivity disorder, respectively, whichoutperforms existing related transfer learning work for 7.2% and 0.5%respectively.</description>
      <author>example@mail.com (Xin Wen, Shijie Guo, Wenbo Ning, Rui Cao, Jie Xiang, Xiaobo Liu, Jintai Chen)</author>
      <guid isPermaLink="false">2504.09463v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>NetTAG: A Multimodal RTL-and-Layout-Aligned Netlist Foundation Model via Text-Attributed Graph</title>
      <link>http://arxiv.org/abs/2504.09260v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Design Automation Conference (DAC), 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;NetTAG是一种融合门语义与图结构的基础模型，用于网表表示学习，在电子设计自动化（EDA）领域有显著潜力。&lt;h4&gt;背景&lt;/h4&gt;电路表示学习在推进电子设计自动化（EDA）方面显示出前景，通过捕捉电路的结构和功能特性来处理各种任务。&lt;h4&gt;目的&lt;/h4&gt;为了提升网表表示学习，NetTAG旨在融合门语义与图结构，处理多样化的门类型，并支持多种功能和物理任务。&lt;h4&gt;方法&lt;/h4&gt;NetTAG将网表构造成文本属性图，门由符号逻辑表达式注解，物理特性作为文本属性。其多模态架构结合了基于LLM的文本编码器（用于门语义）和图变换器（用于全局结构）。通过门和图的自监督目标预训练，并与RTL和布局阶段对齐，NetTAG捕捉了电路的内在特性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，NetTAG在四个功能性和物理任务上持续优于每种特定任务的方法，并超越了最先进的AIG编码器，展示了其多功能性。&lt;h4&gt;结论&lt;/h4&gt;NetTAG在电子设计自动化领域展现出强大的应用潜力，特别是在网表表示学习方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Circuit representation learning has shown promise in advancing ElectronicDesign Automation (EDA) by capturing structural and functional circuitproperties for various tasks. Existing pre-trained solutions rely on graphlearning with complex functional supervision, such as truth table simulation.However, they only handle simple and-inverter graphs (AIGs), struggling tofully encode other complex gate functionalities. While large language models(LLMs) excel at functional understanding, they lack the structural awarenessfor flattened netlists. To advance netlist representation learning, we presentNetTAG, a netlist foundation model that fuses gate semantics with graphstructure, handling diverse gate types and supporting a variety of functionaland physical tasks. Moving beyond existing graph-only methods, NetTAGformulates netlists as text-attributed graphs, with gates annotated by symboliclogic expressions and physical characteristics as text attributes. Itsmultimodal architecture combines an LLM-based text encoder for gate semanticsand a graph transformer for global structure. Pre-trained with gate and graphself-supervised objectives and aligned with RTL and layout stages, NetTAGcaptures comprehensive circuit intrinsics. Experimental results show thatNetTAG consistently outperforms each task-specific method on four largelydifferent functional and physical tasks and surpasses state-of-the-art AIGencoders, demonstrating its versatility.</description>
      <author>example@mail.com (Wenji Fang, Wenkai Li, Shang Liu, Yao Lu, Hongce Zhang, Zhiyao Xie)</author>
      <guid isPermaLink="false">2504.09260v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Psychological Health Knowledge-Enhanced LLM-based Social Network Crisis Intervention Text Transfer Recognition Method</title>
      <link>http://arxiv.org/abs/2504.07983v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于大型语言模型（LLM）的文本传输识别方法，用于社交网络危机干预，该方法增强了特定领域的心理健康知识。&lt;h4&gt;背景&lt;/h4&gt;随着社交媒体平台上心理健康危机的普遍增加，识别和预防潜在伤害已成为一项紧迫的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种多层次的框架，该框架结合了使用BERT的迁移学习，并整合了心理健康知识、情感分析和行为预测技术，以提高危机检测的准确性和对细微情绪和语境变化的敏感性。&lt;h4&gt;方法&lt;/h4&gt;该方法包括一个基于真实世界事件社交媒体数据集训练的危机标注工具，使模型能够检测微妙的情感线索和识别心理危机。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在危机检测准确性方面优于传统模型，并且对细微的情感和语境变化表现出更高的敏感性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法对于识别和预防社交媒体平台上的心理健康危机具有潜在的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the prevalence of mental health crises increases on social mediaplatforms, identifying and preventing potential harm has become an urgentchallenge. This study introduces a large language model (LLM)-based texttransfer recognition method for social network crisis intervention, enhancedwith domain-specific mental health knowledge. We propose a multi-levelframework that incorporates transfer learning using BERT, and integrates mentalhealth knowledge, sentiment analysis, and behavior prediction techniques. Theframework includes a crisis annotation tool trained on social media datasetsfrom real-world events, enabling the model to detect nuanced emotional cues andidentify psychological crises. Experimental results show that the proposedmethod outperforms traditional models in crisis detection accuracy and exhibitsgreater sensitivity to subtle emotional and contextual variations.</description>
      <author>example@mail.com (Shurui Wu, Xinyi Huang, Dingxin Lu)</author>
      <guid isPermaLink="false">2504.07983v2</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>A Confounding Factors-Inhibition Adversarial Learning Framework for Multi-site fMRI Mental Disorder Identification</title>
      <link>http://arxiv.org/abs/2504.09179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MSalNET的新型多站点对抗学习网络，用于基于fMRI的脑部疾病检测。&lt;h4&gt;背景&lt;/h4&gt;fMRI数据集的异质性通常归因于扫描程序的不同、混杂效应的存在以及多个站点之间的群体多样性，这些因素影响了表示学习和分类过程的效率。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出了一种新的多站点对抗学习网络（MSalNET）来提高fMRI基于脑部疾病的检测效果。&lt;h4&gt;方法&lt;/h4&gt;首先，引入了一个具有节点信息组装（NIA）机制的表现学习模块，以更好地从功能连接（FC）中提取特征。其次，为了在不同站点之间泛化特征，提出了一种站点级特征提取模块，该模块可以从单个FC数据中学习，避免了额外的先验信息。最后，提出了一种对抗学习网络，通过引入一个新颖的损失函数来平衡个体分类和站点回归任务之间的权衡。&lt;h4&gt;主要发现&lt;/h4&gt;在ABIDE和ADHD-200数据集上评估了该方法，结果表明，与相关算法相比，该方法在ABIDE和ADHD-200数据集上分别达到了75.56和68.92的准确率。此外，站点回归的结果表明，该方法从数据驱动的角度减少了站点之间的变异性。NIA揭示的最具判别性的脑区与统计发现一致，在一定程度上揭示了深度学习的‘黑盒’。&lt;h4&gt;结论&lt;/h4&gt;MSalNET在提高fMRI基于脑部疾病的检测性能方面表现出色，同时减少了站点间的数据变异性，有助于揭示深度学习的内部机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In open data sets of functional magnetic resonance imaging (fMRI), theheterogeneity of the data is typically attributed to a combination of factors,including differences in scanning procedures, the presence of confoundingeffects, and population diversities between multiple sites. These factorscontribute to the diminished effectiveness of representation learning, which inturn affects the overall efficacy of subsequent classification procedures. Toaddress these limitations, we propose a novel multi-site adversarial learningnetwork (MSalNET) for fMRI-based mental disorder detection. Firstly, arepresentation learning module is introduced with a node information assembly(NIA) mechanism to better extract features from functional connectivity (FC).This mechanism aggregates edge information from both horizontal and verticaldirections, effectively assembling node information. Secondly, to generalizethe feature across sites, we proposed a site-level feature extraction modulethat can learn from individual FC data, which circumvents additional priorinformation. Lastly, an adversarial learning network is proposed as a means ofbalancing the trade-off between individual classification and site regressiontasks, with the introduction of a novel loss function. The proposed method wasevaluated on two multi-site fMRI datasets, i.e., Autism Brain Imaging DataExchange (ABIDE) and ADHD-200. The results indicate that the proposed methodachieves a better performance than other related algorithms with the accuracyof 75.56 and 68.92 in ABIDE and ADHD-200 datasets, respectively. Furthermore,the result of the site regression indicates that the proposed method reducessite variability from a data-driven perspective. The most discriminative brainregions revealed by NIA are consistent with statistical findings, uncoveringthe "black box" of deep learning to a certain extent.</description>
      <author>example@mail.com (Xin Wen, Shijie Guo, Wenbo Ning, Rui Cao, Yan Niu, Bin Wan, Peng Wei, Xiaobo Liu, Jie Xiang)</author>
      <guid isPermaLink="false">2504.09179v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>ToolTipNet: A Segmentation-Driven Deep Learning Baseline for Surgical Instrument Tip Detection</title>
      <link>http://arxiv.org/abs/2504.09700v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于深度学习的手术器械尖端检测方法，以解决机器人辅助腹腔镜根治性前列腺切除术中器械尖端定位不准确的问题。&lt;h4&gt;背景&lt;/h4&gt;在机器人辅助腹腔镜根治性前列腺切除术中，器械尖端的位置对于将超声框架与腹腔镜摄像机框架对准至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于视觉的方法，直接计算工具尖端在摄像机框架中的位置，以提高手术精确性。&lt;h4&gt;方法&lt;/h4&gt;利用深度学习技术，结合分割基础模型（Segment Anything），实现手术器械尖端的检测，并通过与手工图像处理方法进行比较实验。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在模拟和真实数据集上优于手工图像处理方法，能够有效检测小型且可动手术器械的尖端。&lt;h4&gt;结论&lt;/h4&gt;基于深度学习的手术器械尖端检测方法能够有效解决手术器械尖端定位问题，具有提高手术精度的潜力。&lt;h4&gt;翻译&lt;/h4&gt;在机器人辅助腹腔镜根治性前列腺切除术中，器械尖端位置对超声框架与腹腔镜摄像机框架的对准至关重要。现有方法中，由da Vinci API获取的器械尖端位置不准确，需要手动校正。因此，直接使用基于视觉的方法计算工具尖端在摄像机框架中的位置成为一个吸引人的解决方案。此外，手术器械尖端检测是其他任务（如手术技能评估和手术自动化）的关键组成部分。然而，由于工具尖端尺寸小且手术器械可动，这一任务具有挑战性。随着分割基础模型（Segment Anything）的出现，手术器械分割变得相对容易。基于这一进步，我们探索了基于深度学习的手术器械尖端检测方法，该方法以部分级器械分割掩码作为输入。与手工图像处理方法的比较实验表明，所提出的方法在模拟和真实数据集上均优于手工图像处理方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In robot-assisted laparoscopic radical prostatectomy (RALP), the location ofthe instrument tip is important to register the ultrasound frame with thelaparoscopic camera frame. A long-standing limitation is that the instrumenttip position obtained from the da Vinci API is inaccurate and requires hand-eyecalibration. Thus, directly computing the position of the tool tip in thecamera frame using the vision-based method becomes an attractive solution.Besides, surgical instrument tip detection is the key component of other tasks,like surgical skill assessment and surgery automation. However, this task ischallenging due to the small size of the tool tip and the articulation of thesurgical instrument. Surgical instrument segmentation becomes relatively easydue to the emergence of the Segmentation Foundation Model, i.e., SegmentAnything. Based on this advancement, we explore the deep learning-basedsurgical instrument tip detection approach that takes the part-level instrumentsegmentation mask as input. Comparison experiments with a hand-craftedimage-processing approach demonstrate the superiority of the proposed method onsimulated and real datasets.</description>
      <author>example@mail.com (Zijian Wu, Shuojue Yang, Yueming Jin, Septimiu E Salcudean)</author>
      <guid isPermaLink="false">2504.09700v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Towards Unbiased Federated Graph Learning: Label and Topology Perspectives</title>
      <link>http://arxiv.org/abs/2504.09963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FairFGL的新型框架，旨在通过细粒度图挖掘和协作学习来提高联邦图学习（FGL）中的公平性。&lt;h4&gt;背景&lt;/h4&gt;Federated Graph Learning（FGL）允许在不共享原始数据的情况下，对图神经网络进行隐私保护、分布式训练。subgraph-FL成为主流方法，但现有方法往往忽略了公平性，特别是在处理具有不利属性的节点时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了两个公平性目标：(1) 提高少数类节点的表示以实现类间公平性；(2) 减少异质连接带来的拓扑偏差以实现拓扑感知公平性。&lt;h4&gt;方法&lt;/h4&gt;FairFGL框架包括客户端和服务器端。客户端使用历史保持模块防止对主导局部类过度拟合，使用多数对齐模块细化异质多数类节点的表示，使用梯度修改模块将少数类知识从结构上优势的客户端传递以改善公平性。服务器端仅上传受影响最大的参数子集以减少通信成本，并更好地反映局部分布。基于集群的聚合策略协调冲突的更新并抑制全局多数主导。&lt;h4&gt;主要发现&lt;/h4&gt;在八个基准测试上的广泛评估表明，FairFGL显著提高了少数群体的性能，实现了高达22.62%的Macro-F1增益，同时增强了收敛性。&lt;h4&gt;结论&lt;/h4&gt;FairFGL框架通过提高少数类节点的表示和减少异质连接的拓扑偏差，有效地提升了联邦图学习中的公平性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Graph Learning (FGL) enables privacy-preserving, distributedtraining of graph neural networks without sharing raw data. Among itsapproaches, subgraph-FL has become the dominant paradigm, with most workfocused on improving overall node classification accuracy. However, thesemethods often overlook fairness due to the complexity of node features, labels,and graph structures. In particular, they perform poorly on nodes withdisadvantaged properties, such as being in the minority class within subgraphsor having heterophilous connections (neighbors with dissimilar labels ormisleading features). This reveals a critical issue: high accuracy can maskdegraded performance on structurally or semantically marginalized nodes. Toaddress this, we advocate for two fairness goals: (1) improving representationof minority class nodes for class-wise fairness and (2) mitigating topologicalbias from heterophilous connections for topology-aware fairness. We proposeFairFGL, a novel framework that enhances fairness through fine-grained graphmining and collaborative learning. On the client side, the History-PreservingModule prevents overfitting to dominant local classes, while the MajorityAlignment Module refines representations of heterophilous majority-class nodes.The Gradient Modification Module transfers minority-class knowledge fromstructurally favorable clients to improve fairness. On the server side, FairFGLuploads only the most influenced subset of parameters to reduce communicationcosts and better reflect local distributions. A cluster-based aggregationstrategy reconciles conflicting updates and curbs global majority dominance .Extensive evaluations on eight benchmarks show FairFGL significantly improvesminority-group performance , achieving up to a 22.62 percent Macro-F1 gainwhile enhancing convergence over state-of-the-art baselines.</description>
      <author>example@mail.com (Zhengyu Wu, Boyang Pang, Xunkai Li, Yinlin Zhu, Daohan Su, Bowen Fan, Rong-Hua Li, Guoren Wang, Chenghu Zhou)</author>
      <guid isPermaLink="false">2504.09963v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Mixture-of-Shape-Experts (MoSE): End-to-End Shape Dictionary Framework to Prompt SAM for Generalizable Medical Segmentation</title>
      <link>http://arxiv.org/abs/2504.09601v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025 workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的Mixture-of-Shape-Experts (MoSE)框架，用于提高医学图像分割中的单域泛化能力。&lt;h4&gt;背景&lt;/h4&gt;单域泛化（SDG）在医学图像分割中越来越受到关注，但现有的字典学习方法存在表示能力有限或过拟合的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效捕捉多样化和鲁棒形状先验的方法，以解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;MoSE框架将混合专家（MoE）训练的理念整合到字典学习中，将每个字典原子视为一个形状专家，并使用门控网络动态融合这些专家，以生成鲁棒的形状图。SAM编码用于指导稀疏激活，防止过拟合。形状图作为提示被用于SAM，实现双向集成。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个公共数据集上进行了广泛实验，证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;MoSE框架能够有效提高医学图像分割中的单域泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Single domain generalization (SDG) has recently attracted growing attention in medical image segmentation. One promising strategy for SDG is to leverage consistent semantic shape priors across different imaging protocols, scanner vendors, and clinical sites. However, existing dictionary learning methods that encode shape priors often suffer from limited representational power with a small set of offline computed shape elements, or overfitting when the dictionary size grows. Moreover, they are not readily compatible with large foundation models such as the Segment Anything Model (SAM). In this paper, we propose a novel Mixture-of-Shape-Experts (MoSE) framework that seamlessly integrates the idea of mixture-of-experts (MoE) training into dictionary learning to efficiently capture diverse and robust shape priors. Our method conceptualizes each dictionary atom as a shape expert, which specializes in encoding distinct semantic shape information. A gating network dynamically fuses these shape experts into a robust shape map, with sparse activation guided by SAM encoding to prevent overfitting. We further provide this shape map as a prompt to SAM, utilizing the powerful generalization capability of SAM through bidirectional integration. All modules, including the shape dictionary, are trained in an end-to-end manner. Extensive experiments on multiple public datasets demonstrate its effectiveness.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single domain generalization (SDG) has recently attracted growing attentionin medical image segmentation. One promising strategy for SDG is to leverageconsistent semantic shape priors across different imaging protocols, scannervendors, and clinical sites. However, existing dictionary learning methods thatencode shape priors often suffer from limited representational power with asmall set of offline computed shape elements, or overfitting when thedictionary size grows. Moreover, they are not readily compatible with largefoundation models such as the Segment Anything Model (SAM). In this paper, wepropose a novel Mixture-of-Shape-Experts (MoSE) framework that seamlesslyintegrates the idea of mixture-of-experts (MoE) training into dictionarylearning to efficiently capture diverse and robust shape priors. Our methodconceptualizes each dictionary atom as a shape expert, which specializes inencoding distinct semantic shape information. A gating network dynamicallyfuses these shape experts into a robust shape map, with sparse activationguided by SAM encoding to prevent overfitting. We further provide this shapemap as a prompt to SAM, utilizing the powerful generalization capability of SAMthrough bidirectional integration. All modules, including the shape dictionary,are trained in an end-to-end manner. Extensive experiments on multiple publicdatasets demonstrate its effectiveness.</description>
      <author>example@mail.com (Jia Wei, Xiaoqi Zhao, Jonghye Woo, Jinsong Ouyang, Georges El Fakhri, Qingyu Chen, Xiaofeng Liu)</author>
      <guid isPermaLink="false">2504.09601v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Glucose-Only Assessment: Advancing Nocturnal Hypoglycemia Prediction in Children with Type 1 Diabetes</title>
      <link>http://arxiv.org/abs/2504.09299v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ICLR 2025 Workshop on AI for Children&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究通过生理数据和机器学习技术，旨在改善1型糖尿病患者夜间低血糖的预测。&lt;h4&gt;背景&lt;/h4&gt;死在床上的综合症描述了年轻1型糖尿病患者突然无征兆的死亡，这种死亡被假设与夜间低血糖有关。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过利用生理数据和机器学习技术，提高1型糖尿病儿童夜间低血糖的预测能力。&lt;h4&gt;方法&lt;/h4&gt;研究分析了来自16名1型糖尿病儿童的内部数据集，整合了可穿戴传感器的生理指标。通过特征工程、模型选择、架构和过采样来探索预测性能。为了解决数据限制，应用了从公共成人数据集的迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;研究在内部数据集上实现了AUROC为0.75 +- 0.21的结果，通过迁移学习进一步提高了到0.78 +- 0.05。&lt;h4&gt;结论&lt;/h4&gt;研究超越了仅基于血糖的预测，通过结合生理参数，展示了机器学习在增强夜间低血糖检测和改善儿童糖尿病管理临床决策中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;The dead-in-bed syndrome describes the sudden and unexplained death of young individuals with Type 1 Diabetes (T1D) without prior long-term complications. One leading hypothesis attributes this phenomenon to nocturnal hypoglycemia (NH), a dangerous drop in blood glucose during sleep. This study aims to improve NH prediction in children with T1D by leveraging physiological data and machine learning (ML) techniques. We analyze an in-house dataset collected from 16 children with T1D, integrating physiological metrics from wearable sensors. We explore predictive performance through feature engineering, model selection, architectures, and oversampling. To address data limitations, we apply transfer learning from a publicly available adult dataset. Our results achieve an AUROC of 0.75 +- 0.21 on the in-house dataset, further improving to 0.78 +- 0.05 with transfer learning. This research moves beyond glucose-only predictions by incorporating physiological parameters, showcasing the potential of ML to enhance NH detection and improve clinical decision-making for pediatric diabetes management.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The dead-in-bed syndrome describes the sudden and unexplained death of youngindividuals with Type 1 Diabetes (T1D) without prior long-term complications.One leading hypothesis attributes this phenomenon to nocturnal hypoglycemia(NH), a dangerous drop in blood glucose during sleep. This study aims toimprove NH prediction in children with T1D by leveraging physiological data andmachine learning (ML) techniques. We analyze an in-house dataset collected from16 children with T1D, integrating physiological metrics from wearable sensors.We explore predictive performance through feature engineering, model selection,architectures, and oversampling. To address data limitations, we apply transferlearning from a publicly available adult dataset. Our results achieve an AUROCof 0.75 +- 0.21 on the in-house dataset, further improving to 0.78 +- 0.05 withtransfer learning. This research moves beyond glucose-only predictions byincorporating physiological parameters, showcasing the potential of ML toenhance NH detection and improve clinical decision-making for pediatricdiabetes management.</description>
      <author>example@mail.com (Marco Voegeli, Sonia Laguna, Heike Leutheuser, Marc Pfister, Marie-Anne Burckhardt, Julia E Vogt)</author>
      <guid isPermaLink="false">2504.09299v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Predicting ulcer in H&amp;E images of inflammatory bowel disease using domain-knowledge-driven graph neural network</title>
      <link>http://arxiv.org/abs/2504.09430v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Work accepted at ISBI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DomainGCN的弱监督模型，用于在炎症性肠病（IBD）中预测溃疡区域，以提高个性化治疗的选择。&lt;h4&gt;背景&lt;/h4&gt;炎症性肠病（IBD）是一种慢性炎症性疾病，其治疗常常受到副作用的影响。免疫细胞在IBD中起关键作用，而在全切片图像（WSIs）中准确识别溃疡区域对于表征这些细胞和探索潜在疗法至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够利用特定领域知识（如上皮、淋巴细胞和碎片的存在）的模型，以在IBD中预测WSI级别的溃疡区域。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为DomainGCN的模型，该模型结合了图卷积神经网络（GCN）和特定于溃疡特征的领域知识，用于WSI级别的溃疡预测。&lt;h4&gt;主要发现&lt;/h4&gt;DomainGCN在多个实例学习（MIL）方法中表现优于最先进的（SOTA）方法，并展示了领域知识带来的额外价值。&lt;h4&gt;结论&lt;/h4&gt;DomainGCN模型能够有效地利用领域知识提高IBD中溃疡区域的预测准确性，为个性化治疗提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;Inflammatory bowel disease (IBD) involves chronic inflammation of the digestive tract, with treatment options often burdened by adverse effects. Identifying biomarkers for personalized treatment is crucial. While immune cells play a key role in IBD, accurately identifying ulcer regions in whole slide images (WSIs) is essential for characterizing these cells and exploring potential therapeutics. Multiple instance learning (MIL) approaches have advanced WSI analysis but they lack spatial context awareness. In this work, we propose a weakly-supervised model called DomainGCN that employs a graph convolution neural network (GCN) and incorporates domain-specific knowledge of ulcer features, specifically, the presence of epithelium, lymphocytes, and debris for WSI-level ulcer prediction in IBD. We demonstrate that DomainGCN outperforms various state-of-the-art (SOTA) MIL methods and show the added value of domain knowledge.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inflammatory bowel disease (IBD) involves chronic inflammation of thedigestive tract, with treatment options often burdened by adverse effects.Identifying biomarkers for personalized treatment is crucial. While immunecells play a key role in IBD, accurately identifying ulcer regions in wholeslide images (WSIs) is essential for characterizing these cells and exploringpotential therapeutics. Multiple instance learning (MIL) approaches haveadvanced WSI analysis but they lack spatial context awareness. In this work, wepropose a weakly-supervised model called DomainGCN that employs a graphconvolution neural network (GCN) and incorporates domain-specific knowledge ofulcer features, specifically, the presence of epithelium, lymphocytes, anddebris for WSI-level ulcer prediction in IBD. We demonstrate that DomainGCNoutperforms various state-of-the-art (SOTA) MIL methods and show the addedvalue of domain knowledge.</description>
      <author>example@mail.com (Ruiwen Ding, Lin Li, Rajath Soans, Tosha Shah, Radha Krishnan, Marc Alexander Sze, Sasha Lukyanov, Yash Deshpande, Antong Chen)</author>
      <guid isPermaLink="false">2504.09430v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Query-based Knowledge Transfer for Heterogeneous Learning Environments</title>
      <link>http://arxiv.org/abs/2504.09205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICLR'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为QKT的新型框架，用于解决在数据异质性和隐私约束下的去中心化协作学习问题。&lt;h4&gt;背景&lt;/h4&gt;在数据异质性和隐私约束下，现有的联邦学习、集成学习和迁移学习方法无法充分满足客户独特的需求，尤其是在本地数据表示有限的情况下。&lt;h4&gt;目的&lt;/h4&gt;为了解决这个问题，提出了QKT框架，以实现针对特定客户需求的定制化知识获取，而不需要直接交换数据。&lt;h4&gt;方法&lt;/h4&gt;QKT采用数据无关的掩码策略，以实现高效的查询焦点知识迁移，同时优化任务特定参数，以减轻知识干扰和遗忘。&lt;h4&gt;主要发现&lt;/h4&gt;在标准基准和临床基准上的实验表明，QKT在单类别查询设置中平均优于现有协作学习方法20.91%，在多类别查询场景中平均优于14.32%。进一步的分析和消融研究显示，QKT有效地平衡了新知识和现有知识的学习，显示出其在去中心化学习中的应用潜力。&lt;h4&gt;结论&lt;/h4&gt;QKT框架能够有效地解决数据异质性和隐私约束下的去中心化协作学习问题，具有在去中心化学习领域的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decentralized collaborative learning under data heterogeneity and privacyconstraints has rapidly advanced. However, existing solutions like federatedlearning, ensembles, and transfer learning, often fail to adequately serve theunique needs of clients, especially when local data representation is limited.To address this issue, we propose a novel framework called Query-basedKnowledge Transfer (QKT) that enables tailored knowledge acquisition to fulfillspecific client needs without direct data exchange. QKT employs a data-freemasking strategy to facilitate communication-efficient query-focused knowledgetransfer while refining task-specific parameters to mitigate knowledgeinterference and forgetting. Our experiments, conducted on both standard andclinical benchmarks, show that QKT significantly outperforms existingcollaborative learning methods by an average of 20.91\% points in single-classquery settings and an average of 14.32\% points in multi-class query scenarios.Further analysis and ablation studies reveal that QKT effectively balances thelearning of new and existing knowledge, showing strong potential for itsapplication in decentralized learning.</description>
      <author>example@mail.com (Norah Alballa, Wenxuan Zhang, Ziquan Liu, Ahmed M. Abdelmoniem, Mohamed Elhoseiny, Marco Canini)</author>
      <guid isPermaLink="false">2504.09205v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>FSSUAVL: A Discriminative Framework using Vision Models for Federated Self-Supervised Audio and Image Understanding</title>
      <link>http://arxiv.org/abs/2504.09516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为FSSUAVL的单个深度模型，用于解决无配对数据情况下多模态音频和图像识别的问题。&lt;h4&gt;背景&lt;/h4&gt;现有研究表明，配对的多模态音频图像表示可以有效地通过视觉模型学习。然而，在联邦学习（FL）等场景中，数据往往是去中心化、异构的，且缺乏可靠的数据配对保证。&lt;h4&gt;目的&lt;/h4&gt;旨在通过FSSUAVL模型解决无配对模态深度学习表示的挑战。&lt;h4&gt;方法&lt;/h4&gt;FSSUAVL模型在FL中通过自监督对比学习（SSL）进行预训练，不通过模态对齐，而是通过对比SSL将音频和图像投影到共同的嵌入空间中。&lt;h4&gt;主要发现&lt;/h4&gt;与使用单独深度模型进行每个模态相比，FSSUAVL在CNN和ViT上的实验表明，它在各种基于图像和音频的下游任务中显著提高了性能。&lt;h4&gt;结论&lt;/h4&gt;FSSUAVL能够学习多模态特征表示，并允许集成辅助信息以提高识别精度。&lt;h4&gt;翻译&lt;/h4&gt;最近的研究表明，当配对时，视觉模型可以有效地学习多模态音频-图像表示。然而，使深度模型从无配对模态中学习表示的挑战仍未解决。这个问题在联邦学习（FL）等场景中尤为重要，在这些场景中，数据通常是去中心化的、异构的，并且缺乏可靠的数据配对保证。以前的努力通过在本地客户端使用辅助预训练编码器或生成模型来解决这个问题，这不可避免地随着模态数量的增加而增加计算成本。与这些方法不同，本文旨在通过使用在FL中预训练的自监督对比学习（SSL）的单个深度模型FSSUAVL来处理无配对音频和图像识别任务。FSSUAVL通过对比SSL将音频和图像联合区分，而不是对齐它们，将它们投影到共同的嵌入空间中。这扩展了FSSUAVL在配对和无配对音频和图像识别任务中的效用。我们在CNN和ViT上的实验表明，与为每个模态使用单独的深度模型相比，FSSUAVL在各种基于图像和音频的下游任务中显著提高了性能。此外，FSSUAVL学习多模态特征表示的能力允许集成辅助信息（如果可用）以提高识别精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies have demonstrated that vision models can effectively learnmultimodal audio-image representations when paired. However, the challenge ofenabling deep models to learn representations from unpaired modalities remainsunresolved. This issue is especially pertinent in scenarios like FederatedLearning (FL), where data is often decentralized, heterogeneous, and lacks areliable guarantee of paired data. Previous attempts tackled this issue throughthe use of auxiliary pretrained encoders or generative models on local clients,which invariably raise computational cost with increasing number modalities.Unlike these approaches, in this paper, we aim to address the task of unpairedaudio and image recognition using \texttt{FSSUAVL}, a single deep modelpretrained in FL with self-supervised contrastive learning (SSL). Instead ofaligning the audio and image modalities, \texttt{FSSUAVL} jointly discriminatesthem by projecting them into a common embedding space using contrastive SSL.This extends the utility of \texttt{FSSUAVL} to paired and unpaired audio andimage recognition tasks. Our experiments with CNN and ViT demonstrate that\texttt{FSSUAVL} significantly improves performance across various image- andaudio-based downstream tasks compared to using separate deep models for eachmodality. Additionally, \texttt{FSSUAVL}'s capacity to learn multimodal featurerepresentations allows for integrating auxiliary information, if available, toenhance recognition accuracy.</description>
      <author>example@mail.com (Yasar Abbas Ur Rehman, Kin Wai Lau, Yuyang Xie, Ma Lan, JiaJun Shen)</author>
      <guid isPermaLink="false">2504.09516v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Spatially Directional Dual-Attention GAT for Spatial Fluoride Health Risk Modeling</title>
      <link>http://arxiv.org/abs/2504.09416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为SDD-GAT的新型空间图神经网络，用于细粒度健康风险预测，并在贵州地区的氟化物监测样本和氟斑牙记录数据集上取得了显著效果。&lt;h4&gt;背景&lt;/h4&gt;氟化物环境暴露是公共卫生问题，特别是在氟化物浓度自然升高的地区。准确建模氟化物相关的健康风险，如牙氟斑病，需要能够捕捉地理和语义异质性的空间感知学习框架。&lt;h4&gt;目的&lt;/h4&gt;提出SDD-GAT，以实现氟化物相关健康风险的准确预测。&lt;h4&gt;方法&lt;/h4&gt;SDD-GAT引入了双图架构，将地理邻近性和属性相似性解耦，并采用方向性注意力机制将空间方向和距离显式编码到消息传递过程中。为了进一步提高空间一致性，引入了空间平滑度正则化项。&lt;h4&gt;主要发现&lt;/h4&gt;SDD-GAT在回归和分类任务中均显著优于传统模型和最先进的图神经网络，并且表现出改善的空间自相关性。&lt;h4&gt;结论&lt;/h4&gt;SDD-GAT为复杂环境设置下的空间健康风险建模和地理空间学习提供了一个可推广的基础。&lt;h4&gt;翻译&lt;/h4&gt;Environmental exposure to fluoride is a major public health concern, particularly in regions with naturally elevated fluoride concentrations. Accurate modeling of fluoride-related health risks, such as dental fluorosis, requires spatially aware learning frameworks capable of capturing both geographic and semantic heterogeneity. In this work, we propose Spatially Directional Dual-Attention Graph Attention Network (SDD-GAT), a novel spatial graph neural network designed for fine-grained health risk prediction. SDD-GAT introduces a dual-graph architecture that disentangles geographic proximity and attribute similarity, and incorporates a directional attention mechanism that explicitly encodes spatial orientation and distance into the message passing process. To further enhance spatial coherence, we introduce a spatial smoothness regularization term that enforces consistency in predictions across neighboring locations. We evaluate SDD-GAT on a large-scale dataset covering over 50,000 fluoride monitoring samples and fluorosis records across Guizhou Province, China. Results show that SDD-GAT significantly outperforms traditional models and state-of-the-art GNNs in both regression and classification tasks, while also exhibiting improved spatial autocorrelation as measured by Moran's I. Our framework provides a generalizable foundation for spatial health risk modeling and geospatial learning under complex environmental settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Environmental exposure to fluoride is a major public health concern,particularly in regions with naturally elevated fluoride concentrations.Accurate modeling of fluoride-related health risks, such as dental fluorosis,requires spatially aware learning frameworks capable of capturing bothgeographic and semantic heterogeneity. In this work, we propose SpatiallyDirectional Dual-Attention Graph Attention Network (SDD-GAT), a novel spatialgraph neural network designed for fine-grained health risk prediction. SDD-GATintroduces a dual-graph architecture that disentangles geographic proximity andattribute similarity, and incorporates a directional attention mechanism thatexplicitly encodes spatial orientation and distance into the message passingprocess. To further enhance spatial coherence, we introduce a spatialsmoothness regularization term that enforces consistency in predictions acrossneighboring locations. We evaluate SDD-GAT on a large-scale dataset coveringover 50,000 fluoride monitoring samples and fluorosis records across GuizhouProvince, China. Results show that SDD-GAT significantly outperformstraditional models and state-of-the-art GNNs in both regression andclassification tasks, while also exhibiting improved spatial autocorrelation asmeasured by Moran's I. Our framework provides a generalizable foundation forspatial health risk modeling and geospatial learning under complexenvironmental settings.</description>
      <author>example@mail.com (Da Yuan)</author>
      <guid isPermaLink="false">2504.09416v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>EasyREG: Easy Depth-Based Markerless Registration and Tracking using Augmented Reality Device for Surgical Guidance</title>
      <link>http://arxiv.org/abs/2504.09498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于增强现实（AR）设备的无标记框架，用于手术引导，通过深度传感器实现高精度和实时性能，避免了传统标记方法带来的不便。&lt;h4&gt;背景&lt;/h4&gt;传统的手术引导方法依赖外部标记物，虽然能实现高精度和实时性，但需要繁琐的校准过程，且在临床环境中部署困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种无标记的手术引导框架，以提高手术引导的准确性和实时性。&lt;h4&gt;方法&lt;/h4&gt;该框架包含两个模块：注册模块和跟踪模块。注册模块通过深度传感器误差校正、区域过滤技术和鲁棒的全球对齐来实现高精度、鲁棒的目标解剖定位。跟踪模块使用快速鲁棒的注册算法，利用注册模块的初始姿态估计实时目标姿态。&lt;h4&gt;主要发现&lt;/h4&gt;通过仿真和实际测量，该无标记系统在注册方面表现优于工业解决方案，在跟踪方面与工业解决方案相当。&lt;h4&gt;结论&lt;/h4&gt;该两模块设计使系统成为手术过程中目标解剖结构移动或静止时的全方位解决方案。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于增强现实（AR）设备的无标记框架，用于手术引导。该框架利用AR设备的深度传感器，避免了传统标记方法带来的不便。注册模块通过深度传感器误差校正、区域过滤技术和鲁棒的全球对齐来实现高精度、鲁棒的目标解剖定位。跟踪模块使用快速鲁棒的注册算法，利用注册模块的初始姿态估计实时目标姿态。通过仿真和实际测量，该无标记系统在注册方面表现优于工业解决方案，在跟踪方面与工业解决方案相当。该两模块设计使系统成为手术过程中目标解剖结构移动或静止时的全方位解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The use of Augmented Reality (AR) devices for surgical guidance has gainedincreasing traction in the medical field. Traditional registration methodsoften rely on external fiducial markers to achieve high accuracy and real-timeperformance. However, these markers introduce cumbersome calibration proceduresand can be challenging to deploy in clinical settings. While commercialsolutions have attempted real-time markerless tracking using the native RGBcameras of AR devices, their accuracy remains questionable for medicalguidance, primarily due to occlusions and significant outliers between the livesensor data and the preoperative target anatomy point cloud derived from MRI orCT scans. In this work, we present a markerless framework that relies only onthe depth sensor of AR devices and consists of two modules: a registrationmodule for high-precision, outlier-robust target anatomy localization, and atracking module for real-time pose estimation. The registration moduleintegrates depth sensor error correction, a human-in-the-loop region filteringtechnique, and a robust global alignment with curvature-aware feature sampling,followed by local ICP refinement, for markerless alignment of preoperativemodels with patient anatomy. The tracking module employs a fast and robustregistration algorithm that uses the initial pose from the registration moduleto estimate the target pose in real-time. We comprehensively evaluated theperformance of both modules through simulation and real-world measurements. Theresults indicate that our markerless system achieves superior performance forregistration and comparable performance for tracking to industrial solutions.The two-module design makes our system a one-stop solution for surgicalprocedures where the target anatomy moves or stays static during surgery.</description>
      <author>example@mail.com (Yue Yang, Christoph Leuze, Brian Hargreaves, Bruce Daniel, Fred Baik)</author>
      <guid isPermaLink="false">2504.09498v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Synthetic Aircraft Trajectory Generation Using Time-Based VQ-VAE</title>
      <link>http://arxiv.org/abs/2504.09101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper was presented at the 25th Integrated Communications,  Navigation and Surveillance Conference (ICNS 2025), April 8--10, 2025,  Brussels, Belgium&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于时间向量量化变分自编码器（TimeVQVAE）的飞行轨迹合成新方法，用于解决航空交通管理中的数据稀缺、信息保护以及大规模分析等问题。&lt;h4&gt;背景&lt;/h4&gt;现代航空交通管理中，生成合成飞行轨迹已成为解决数据稀缺、保护敏感信息和支持大规模分析的有前途的解决方案。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的轨迹合成方法，以适应TimeVQVAE，利用时间-频率域处理、向量量化和基于transformer的先验，捕捉飞行数据的全局和局部动态。&lt;h4&gt;方法&lt;/h4&gt;通过离散化潜在空间和整合transformer先验，模型学习长程时空依赖性，并保持整个飞行路径的连贯性。使用质量、统计和分布性指标以及开源航空交通模拟器中的可飞性评估来评估改进的TimeVQVAE。&lt;h4&gt;主要发现&lt;/h4&gt;TimeVQVAE在空间精度、时间一致性和统计特性方面优于时间卷积VAE基线，生成的合成轨迹与真实飞行数据相似。模拟器评估显示，大多数生成的轨迹保持操作可行性，但偶尔的异常值强调了需要额外的特定领域约束。&lt;h4&gt;结论&lt;/h4&gt;研究强调了多尺度表示学习在捕捉复杂飞行行为中的重要性，并证明了TimeVQVAE在生成具有代表性的合成轨迹方面的潜力，可用于下游任务如模型训练、空域设计和航空交通预测。&lt;h4&gt;翻译&lt;/h4&gt;In modern air traffic management, generating synthetic flight trajectories has emerged as a promising solution for addressing data scarcity, protecting sensitive information, and supporting large-scale analyses. In this paper, we propose a novel method for trajectory synthesis by adapting the Time-Based Vector Quantized Variational Autoencoder (TimeVQVAE). Our approach leverages time-frequency domain processing, vector quantization, and transformer-based priors to capture both global and local dynamics in flight data. By discretizing the latent space and integrating transformer priors, the model learns long-range spatiotemporal dependencies and preserves coherence across entire flight paths. We evaluate the adapted TimeVQVAE using an extensive suite of quality, statistical, and distributional metrics, as well as a flyability assessment conducted in an open-source air traffic simulator. Results indicate that TimeVQVAE outperforms a temporal convolutional VAE baseline, generating synthetic trajectories that mirror real flight data in terms of spatial accuracy, temporal consistency, and statistical properties. Furthermore, the simulator-based assessment shows that most generated trajectories maintain operational feasibility, although occasional outliers underscore the potential need for additional domain-specific constraints. Overall, our findings underscore the importance of multi-scale representation learning for capturing complex flight behaviors and demonstrate the promise of TimeVQVAE in producing representative synthetic trajectories for downstream tasks such as model training, airspace design, and air traffic forecasting.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In modern air traffic management, generating synthetic flight trajectorieshas emerged as a promising solution for addressing data scarcity, protectingsensitive information, and supporting large-scale analyses. In this paper, wepropose a novel method for trajectory synthesis by adapting the Time-BasedVector Quantized Variational Autoencoder (TimeVQVAE). Our approach leveragestime-frequency domain processing, vector quantization, and transformer-basedpriors to capture both global and local dynamics in flight data. Bydiscretizing the latent space and integrating transformer priors, the modellearns long-range spatiotemporal dependencies and preserves coherence acrossentire flight paths. We evaluate the adapted TimeVQVAE using an extensive suiteof quality, statistical, and distributional metrics, as well as a flyabilityassessment conducted in an open-source air traffic simulator. Results indicatethat TimeVQVAE outperforms a temporal convolutional VAE baseline, generatingsynthetic trajectories that mirror real flight data in terms of spatialaccuracy, temporal consistency, and statistical properties. Furthermore, thesimulator-based assessment shows that most generated trajectories maintainoperational feasibility, although occasional outliers underscore the potentialneed for additional domain-specific constraints. Overall, our findingsunderscore the importance of multi-scale representation learning for capturingcomplex flight behaviors and demonstrate the promise of TimeVQVAE in producingrepresentative synthetic trajectories for downstream tasks such as modeltraining, airspace design, and air traffic forecasting.</description>
      <author>example@mail.com (Abdulmajid Murad, Massimiliano Ruocco)</author>
      <guid isPermaLink="false">2504.09101v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised learning of non-Abelian multi-gap topological phases</title>
      <link>http://arxiv.org/abs/2504.09198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;最近实验成功实现了具有时间反演对称性的多带非阿贝尔拓扑绝缘体。它们的拓扑分类超越了传统的十倍分类，需要使用非阿贝尔群，表现出不能用整数拓扑不变量描述的新特性。&lt;h4&gt;背景&lt;/h4&gt;非阿贝尔群的唯一非交换乘积以及同伦分类（带或不带固定基点）的独特性，使得不同非阿贝尔拓扑相的识别比阿贝尔情况下更加复杂和具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;本工作提出了一种基于扩散映射的无监督学习方法，用于分类非阿贝尔多能隙拓扑相。&lt;h4&gt;方法&lt;/h4&gt;该方法通过自动绝热路径寻找过程，能够正确对属于同一相的样本进行排序，即使这些样本在样本集中没有通过绝热路径连接。更重要的是，该方法能够以数据驱动的方式推断非阿贝尔拓扑电荷的乘法表，而不需要先验知识。此外，该算法可以提供同伦（带或不带固定基点）样本的正确分类。&lt;h4&gt;主要发现&lt;/h4&gt;该方法可以正确识别非阿贝尔拓扑相，即使它们之间没有绝热路径连接，并且可以数据驱动地推断拓扑电荷的乘法表。&lt;h4&gt;结论&lt;/h4&gt;这些结果为使用机器学习方法研究非阿贝尔相的未来研究提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Recent experiments have successfully realized multi-band non-Abelian topological insulators with parity-time symmetry. Their topological classification transcends the conventional ten-fold classification, necessitating the use of non-Abelian groups, manifesting novel properties that cannot be described using integer topological invariants. The unique non-commutative multiplication of non-Abelian groups, along with the distinct topological classifications in the context of homotopy with or without a fixed base point, makes the identification of different non-Abelian topological phases more nuanced and challenging than in the Abelian case. In this work, we present an unsupervised learning method based on diffusion maps to classify non-Abelian multi-gap topological phases. The automatic adiabatic pathfinding process in our method can correctly sort the samples in the same phase even though they are not connected by adiabatic paths in the sample set. Most importantly, our method can deduce the multiplication table of the non-Abelian topological charges in a data-driven manner without requiring extit{a priori} knowledge. Additionally, our algorithm can provide the correct classifications for the samples within both the homotopy with and without a fixed base point. Our results provide insights for future studies on non-Abelian phase studies using machine learning approaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent experiments have successfully realized multi-band non-Abeliantopological insulators with parity-time symmetry. Their topologicalclassification transcends the conventional ten-fold classification,necessitating the use of non-Abelian groups, manifesting novel properties thatcannot be described using integer topological invariants. The uniquenon-commutative multiplication of non-Abelian groups, along with the distincttopological classifications in the context of homotopy with or without a fixedbase point, makes the identification of different non-Abelian topologicalphases more nuanced and challenging than in the Abelian case. In this work, wepresent an unsupervised learning method based on diffusion maps to classifynon-Abelian multi-gap topological phases. The automatic adiabatic pathfindingprocess in our method can correctly sort the samples in the same phase eventhough they are not connected by adiabatic paths in the sample set. Mostimportantly, our method can deduce the multiplication table of the non-Abeliantopological charges in a data-driven manner without requiring \textit{a priori}knowledge. Additionally, our algorithm can provide the correct classificationsfor the samples within both the homotopy with and without a fixed base point.Our results provide insights for future studies on non-Abelian phase studiesusing machine learning approaches.</description>
      <author>example@mail.com (Xiangxu He, Ruo-Yang Zhang, Xiaohan Cui, Lei Zhang, C. T. Chan)</author>
      <guid isPermaLink="false">2504.09198v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>FairACE: Achieving Degree Fairness in Graph Neural Networks via Contrastive and Adversarial Group-Balanced Training</title>
      <link>http://arxiv.org/abs/2504.09210v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FairACE的新型图神经网络框架，旨在解决图神经网络中存在的公平性问题，通过不对称对比学习和对抗训练来提高不同度数节点的预测公平性。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）中，度数偏差经常导致不同度数节点的预测性能不平等，现有模型主要关注预测精度，而忽略了不同度数组之间的公平性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出FairACE框架，旨在提高图神经网络中不同度数节点的预测公平性。&lt;h4&gt;方法&lt;/h4&gt;FairACE通过集成不对称对比学习和对抗训练来改进度数公平性，同时捕捉一跳局部邻域信息和两跳单边相似性，并采用度数公平性调节器来平衡高度和低度节点的性能。在模型训练过程中，提出了一个新的组平衡公平损失函数，以最小化不同度数组之间的分类差异。此外，还提出了一种新的公平性度量指标——准确度分布差距（ADG），可以定量评估并确保不同度数节点组的公平性能。&lt;h4&gt;主要发现&lt;/h4&gt;在合成和真实世界数据集上的实验结果表明，FairACE在提高度数公平性指标的同时，与最先进的GNN模型相比，保持了有竞争力的精度。&lt;h4&gt;结论&lt;/h4&gt;FairACE是一种有效的图神经网络框架，能够显著提高不同度数节点的预测公平性，同时保持高精度。&lt;h4&gt;翻译&lt;/h4&gt;摘要：公平性一直是图神经网络（GNNs）的一个重要挑战，因为度数偏差通常会导致不同度数节点的预测性能不平等。现有的GNN模型主要关注预测精度，常常忽略了不同度数组之间的公平性。为了解决这个问题，我们提出了一种名为Fairness-Aware Asymmetric Contrastive Ensemble（FairACE）的新颖GNN框架，该框架将不对称对比学习和对抗训练集成在一起，以提高度数公平性。FairACE捕捉了一跳局部邻域信息和两跳单边相似性，以创建更公平的节点表示，并采用度数公平性调节器来平衡高度和低度节点的性能。在模型训练期间，提出了一种新的组平衡公平损失，以最小化不同度数组之间的分类差异。此外，我们还提出了一种新的公平性度量指标，即准确度分布差距（ADG），它可以定量评估并确保不同度数节点组的公平性能。在合成和真实世界数据集上的实验结果表明，与最先进的GNN模型相比，FairACE在提高度数公平性指标的同时，保持了有竞争力的精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fairness has been a significant challenge in graph neural networks (GNNs)since degree biases often result in un-equal prediction performance among nodeswith varying degrees. Existing GNN models focus on prediction accuracy,frequently overlooking fairness across different degree groups. To addressthisissue, we propose a novel GNN framework, namely Fairness- Aware AsymmetricContrastive Ensemble (FairACE), which inte-grates asymmetric contrastivelearning with adversarial training to improve degree fairness. FairACE capturesone-hop local neighborhood information and two-hop monophily similarity tocreate fairer node representations and employs a degree fairness regulator tobalance performance between high-degree and low-degree nodes. During modeltraining, a novel group-balanced fairness loss is proposed to minimizeclassification disparities across degree groups. In addition, we also propose anovel fairness metric, the Accuracy Distribution Gap (ADG), which canquantitatively assess and ensure equitable performance across differentdegree-based node groups. Experimental results on both synthetic and real-worlddatasets demonstrate that FairACE significantly improves degree fairnessmetrics while maintaining competitive accuracy in comparison to thestate-of-the-art GNN models.</description>
      <author>example@mail.com (Jiaxin Liu, Xiaoqian Jiang, Cangqi Zhou, Jing Zhang)</author>
      <guid isPermaLink="false">2504.09210v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Graph Learning-Driven Multi-Vessel Association: Fusing Multimodal Data for Maritime Intelligence</title>
      <link>http://arxiv.org/abs/2504.09197v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图学习的多船关联（GMvA）方法，用于解决海事多模态数据融合中的挑战，如数据维度差异、目标计数不匹配、船舶规模变化、遮挡和来自AIS和CCTV等系统的异步数据流。&lt;h4&gt;背景&lt;/h4&gt;随着航道变得越来越拥挤和复杂，确保海事安全和优化交通管理需要有效的航道监控。当前方法在处理多模态数据时面临挑战，尤其是在交通密集的航道中。&lt;h4&gt;目的&lt;/h4&gt;提出GMvA方法以克服上述挑战，实现海事多模态数据的有效融合。&lt;h4&gt;方法&lt;/h4&gt;GMvA方法通过整合AIS和CCTV数据，利用时间序列学习和图神经网络来捕捉船舶轨迹的时空特征。该方法还引入了时间图注意力和时空注意力，以增强特征表示，并使用多层感知器计算鲁棒的相似度分数。此外，采用匈牙利算法确保全局一致和准确的目标匹配。&lt;h4&gt;主要发现&lt;/h4&gt;在真实世界的海事数据集上的实验表明，GMvA在多目标关联方面表现出优异的准确性和鲁棒性，即使在船舶密度高、AIS和CCTV数据不完整或不均匀分布的挑战场景中也优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;GMvA方法为海事多模态数据融合提供了一种有效的解决方案，能够提高航道监控的准确性和效率。&lt;h4&gt;翻译&lt;/h4&gt;Ensuring maritime safety and optimizing traffic management in increasingly crowded and complex waterways require effective waterway monitoring. However, current methods struggle with challenges arising from multimodal data, such as dimensional disparities, mismatched target counts, vessel scale variations, occlusions, and asynchronous data streams from systems like the automatic identification system (AIS) and closed-circuit television (CCTV). Traditional multi-target association methods often struggle with these complexities, particularly in densely trafficked waterways. To overcome these issues, we propose a graph learning-driven multi-vessel association (GMvA) method tailored for maritime multimodal data fusion. By integrating AIS and CCTV data, GMvA leverages time series learning and graph neural networks to capture the spatiotemporal features of vessel trajectories effectively. To enhance feature representation, the proposed method incorporates temporal graph attention and spatiotemporal attention, effectively capturing both local and global vessel interactions. Furthermore, a multi-layer perceptron-based uncertainty fusion module computes robust similarity scores, and the Hungarian algorithm is adopted to ensure globally consistent and accurate target matching. Extensive experiments on real-world maritime datasets confirm that GMvA delivers superior accuracy and robustness in multi-target association, outperforming existing methods even in challenging scenarios with high vessel density and incomplete or unevenly distributed AIS and CCTV data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring maritime safety and optimizing traffic management in increasinglycrowded and complex waterways require effective waterway monitoring. However,current methods struggle with challenges arising from multimodal data, such asdimensional disparities, mismatched target counts, vessel scale variations,occlusions, and asynchronous data streams from systems like the automaticidentification system (AIS) and closed-circuit television (CCTV). Traditionalmulti-target association methods often struggle with these complexities,particularly in densely trafficked waterways. To overcome these issues, wepropose a graph learning-driven multi-vessel association (GMvA) method tailoredfor maritime multimodal data fusion. By integrating AIS and CCTV data, GMvAleverages time series learning and graph neural networks to capture thespatiotemporal features of vessel trajectories effectively. To enhance featurerepresentation, the proposed method incorporates temporal graph attention andspatiotemporal attention, effectively capturing both local and global vesselinteractions. Furthermore, a multi-layer perceptron-based uncertainty fusionmodule computes robust similarity scores, and the Hungarian algorithm isadopted to ensure globally consistent and accurate target matching. Extensiveexperiments on real-world maritime datasets confirm that GMvA delivers superioraccuracy and robustness in multi-target association, outperforming existingmethods even in challenging scenarios with high vessel density and incompleteor unevenly distributed AIS and CCTV data.</description>
      <author>example@mail.com (Yuxu Lu, Kaisen Yang, Dong Yang, Haifeng Ding, Jinxian Weng, Ryan Wen Liu)</author>
      <guid isPermaLink="false">2504.09197v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Embodied Chain of Action Reasoning with Multi-Modal Foundation Model for Humanoid Loco-manipulation</title>
      <link>http://arxiv.org/abs/2504.09532v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于基础模型的新框架，用于使类人机器人能够从文本指令中自主规划行动，以执行复杂的非结构化环境中的行走和操作任务。&lt;h4&gt;背景&lt;/h4&gt;在复杂、非结构化环境中使类人机器人自主执行行走和操作任务具有重大挑战，这要求机器人具备在长时间范围内规划行动的能力，并利用多模态技术来弥合高级规划和实际任务执行之间的差距。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够从文本指令中自主规划行动的方法，以帮助类人机器人在非结构化环境中执行行走和操作任务。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了类人机器人特有的思维链方法，包括详细的可用性和身体运动分析，将任务分解为一系列行走和操作动作。此外，它还整合了基于观察和目标物体属性的空间推理，以有效地导航到可能看不见或被遮挡的目标位置。&lt;h4&gt;主要发现&lt;/h4&gt;通过严格的实验设置，在现实世界环境中对物体重新排列、操作和行走和操作任务进行了评估，证明了该方法在分离上半身和下半身控制方面的有效性，并展示了机器人行动推理策略在理解人类指令方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法在提高类人机器人在复杂环境中的自主操作能力方面具有潜力，尤其是在理解人类指令并执行相应的行动方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Enabling humanoid robots to autonomously perform loco-manipulation tasks incomplex, unstructured environments poses significant challenges. This entailsequipping robots with the capability to plan actions over extended horizonswhile leveraging multi-modality to bridge gaps between high-level planning andactual task execution. Recent advancements in multi-modal foundation modelshave showcased substantial potential in enhancing planning and reasoningabilities, particularly in the comprehension and processing of semanticinformation for robotic control tasks. In this paper, we introduce a novelframework based on foundation models that applies the embodied chain of actionreasoning methodology to autonomously plan actions from textual instructionsfor humanoid loco-manipulation. Our method integrates humanoid-specific chainof thought methodology, including detailed affordance and body movementanalysis, which provides a breakdown of the task into a sequence of locomotionand manipulation actions. Moreover, we incorporate spatial reasoning based onthe observation and target object properties to effectively navigate wheretarget position may be unseen or occluded. Through rigorous experimental setupson object rearrangement, manipulations and loco-manipulation tasks on areal-world environment, we evaluate our method's efficacy on the decoupledupper and lower body control and demonstrate the effectiveness of the chain ofrobotic action reasoning strategies in comprehending human instructions.</description>
      <author>example@mail.com (Yu Hao, Geeta Chandra Raju Bethala, Niraj Pudasaini, Hao Huang, Shuaihang Yuan, Congcong Wen, Baoru Huang, Anh Nguyen, Yi Fang)</author>
      <guid isPermaLink="false">2504.09532v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>HyperCore: The Core Framework for Building Hyperbolic Foundation Models with Comprehensive Modules</title>
      <link>http://arxiv.org/abs/2504.08912v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了HyperCore，一个用于构建跨多种模态的球面基础模型的全面开源框架。&lt;h4&gt;背景&lt;/h4&gt;球面神经网络成为建模跨多种模态层次数据的强大工具，研究表明球面空间比欧几里得空间更适合许多预训练和下游任务。&lt;h4&gt;目的&lt;/h4&gt;解决现有工具缺乏构建球面基础模型所需核心组件的问题，以利用最新的进展。&lt;h4&gt;方法&lt;/h4&gt;HyperCore提供核心模块，可轻松组合以开发新的球面基础模型，无需从头开始大量修改欧几里得模块。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，LViT优于其欧几里得对应版本，并且HyperCore在球面GNNs、CNNs、Transformers和视觉Transformer中具有优势。&lt;h4&gt;结论&lt;/h4&gt;HyperCore框架可以有效地促进球面神经网络的发展和应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：双曲神经网络已成为跨多种模态建模层次数据的强大工具。近期研究表明，基础模型中的词分布表现出无标度特性，这表明球面空间比欧几里得空间更适合许多预训练和下游任务。然而，现有的工具缺乏构建球面基础模型所需的核心组件，这使得利用最新的进展变得困难。我们引入了HyperCore，这是一个全面的开源框架，它为在多个模态上构建球面基础模型提供了核心模块。HyperCore的模块可以轻松组合以开发新的球面基础模型，无需从头开始大量修改欧几里得模块，从而避免了可能的研究冗余。为了展示其多功能性，我们构建并测试了第一个完全球面的视觉Transformer（LViT）以及一个微调管道，第一个完全球面的多模态CLIP模型（L-CLIP）和一个混合的Graph RAG，它具有球面图编码器。我们的实验表明，LViT优于其欧几里得对应版本。此外，我们还对球面GNNs、CNNs、Transformers和视觉Transformer的实验进行了基准测试和重现，以突出HyperCore的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperbolic neural networks have emerged as a powerful tool for modelinghierarchical data across diverse modalities. Recent studies show that tokendistributions in foundation models exhibit scale-free properties, suggestingthat hyperbolic space is a more suitable ambient space than Euclidean space formany pre-training and downstream tasks. However, existing tools lack essentialcomponents for building hyperbolic foundation models, making it difficult toleverage recent advancements. We introduce HyperCore, a comprehensiveopen-source framework that provides core modules for constructing hyperbolicfoundation models across multiple modalities. HyperCore's modules can beeffortlessly combined to develop novel hyperbolic foundation models,eliminating the need to extensively modify Euclidean modules from scratch andpossible redundant research efforts. To demonstrate its versatility, we buildand test the first fully hyperbolic vision transformers (LViT) with afine-tuning pipeline, the first fully hyperbolic multimodal CLIP model(L-CLIP), and a hybrid Graph RAG with a hyperbolic graph encoder. Ourexperiments demonstrate that LViT outperforms its Euclidean counterpart.Additionally, we benchmark and reproduce experiments across hyperbolic GNNs,CNNs, Transformers, and vision Transformers to highlight HyperCore'sadvantages.</description>
      <author>example@mail.com (Neil He, Menglin Yang, Rex Ying)</author>
      <guid isPermaLink="false">2504.08912v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs</title>
      <link>http://arxiv.org/abs/2504.09504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE International Conference on Multimedia &amp; Expo 2025  (ICME 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MADLLM的多变量异常检测方法，通过预训练的大型语言模型来解决异常检测任务中的多变量时间序列与语言模型文本模态不匹配的问题。&lt;h4&gt;背景&lt;/h4&gt;在将预训练的大型语言模型应用于异常检测任务时，多变量时间序列（MTS）模态与语言模型的文本模态不匹配，现有方法简单地将MTS数据转换为多个单变量时间序列序列，这可能导致许多问题。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的三重编码技术，以将MTS模态与LLMs的文本模态对齐，从而提高异常检测的准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了传统的补丁嵌入方法以及两种新的嵌入方法：跳过嵌入和特征嵌入。跳过嵌入通过改变传统方法中补丁处理的顺序，帮助LLMs保留先前特征的知识；特征嵌入利用对比学习，使模型更好地理解不同特征之间的相关性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在各种公共异常检测数据集上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;MADLLM方法在多变量异常检测任务中表现优异，为解决LLMs在处理MTS数据时的模态不匹配问题提供了一种有效途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When applying pre-trained large language models (LLMs) to address anomalydetection tasks, the multivariate time series (MTS) modality of anomalydetection does not align with the text modality of LLMs. Existing methodssimply transform the MTS data into multiple univariate time series sequences,which can cause many problems. This paper introduces MADLLM, a novelmultivariate anomaly detection method via pre-trained LLMs. We design a newtriple encoding technique to align the MTS modality with the text modality ofLLMs. Specifically, this technique integrates the traditional patch embeddingmethod with two novel embedding approaches: Skip Embedding, which alters theorder of patch processing in traditional methods to help LLMs retain knowledgeof previous features, and Feature Embedding, which leverages contrastivelearning to allow the model to better understand the correlations betweendifferent features. Experimental results demonstrate that our methodoutperforms state-of-the-art methods in various public anomaly detectiondatasets.</description>
      <author>example@mail.com (Wei Tao, Xiaoyang Qu, Kai Lu, Jiguang Wan, Guokuan Li, Jianzong Wang)</author>
      <guid isPermaLink="false">2504.09504v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>MASH: Masked Anchored SpHerical Distances for 3D Shape Representation and Generation</title>
      <link>http://arxiv.org/abs/2504.09149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 11 figures, SIGGRAPH 2025 Accept - Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MASH的新颖的多视角和参数化3D形状表示方法。&lt;h4&gt;背景&lt;/h4&gt;受多视图几何的启发，并鉴于感知形状理解对学习3D形状的重要性。&lt;h4&gt;目的&lt;/h4&gt;将3D形状表示为一系列可观察的局部表面补丁的集合。&lt;h4&gt;方法&lt;/h4&gt;使用球谐函数的紧凑性来编码MASH函数，并结合具有参数化基的广义视锥体，以局部化球面函数的空间范围。&lt;h4&gt;主要发现&lt;/h4&gt;开发了一种可微优化算法，可以将任何点云转换为MASH表示，该表示能够准确近似具有任意几何和拓扑的地面真实表面。&lt;h4&gt;结论&lt;/h4&gt;MASH在多个应用中表现出优越的性能，包括表面重建、形状生成、补全和混合，这得益于其独特的表示，涵盖了隐式和显式特征。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了一种名为MASH的新颖的多视角和参数化3D形状表示方法。受多视图几何的启发，并鉴于感知形状理解对学习3D形状的重要性，MASH将3D形状表示为一系列可观察的局部表面补丁的集合。我们进一步利用球谐函数的紧凑性来编码MASH函数，并结合具有参数化基的广义视锥体，以局部化球面函数的空间范围。我们开发了一种可微优化算法，可以将任何点云转换为MASH表示，该表示能够准确近似具有任意几何和拓扑的地面真实表面。大量实验表明，MASH在多个应用中表现出优越的性能，包括表面重建、形状生成、补全和混合，这得益于其独特的表示，涵盖了隐式和显式特征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Masked Anchored SpHerical Distances (MASH), a novel multi-viewand parametrized representation of 3D shapes. Inspired by multi-view geometryand motivated by the importance of perceptual shape understanding for learning3D shapes, MASH represents a 3D shape as a collection of observable localsurface patches, each defined by a spherical distance function emanating froman anchor point. We further leverage the compactness of spherical harmonics toencode the MASH functions, combined with a generalized view cone with aparameterized base that masks the spatial extent of the spherical function toattain locality. We develop a differentiable optimization algorithm capable ofconverting any point cloud into a MASH representation accurately approximatingground-truth surfaces with arbitrary geometry and topology. Extensiveexperiments demonstrate that MASH is versatile for multiple applicationsincluding surface reconstruction, shape generation, completion, and blending,achieving superior performance thanks to its unique representation encompassingboth implicit and explicit features.</description>
      <author>example@mail.com (Changhao Li, Yu Xin, Xiaowei Zhou, Ariel Shamir, Hao Zhang, Ligang Liu, Ruizhen Hu)</author>
      <guid isPermaLink="false">2504.09149v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Additive Parameter Updates of Vision Transformers for Few-Shot Continual Learning</title>
      <link>http://arxiv.org/abs/2504.08982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的FSCIL框架，通过冻结预训练的ViT参数并使用参数高效的增量更新机制，解决了增量学习中的灾难性遗忘问题。&lt;h4&gt;背景&lt;/h4&gt;在人工智能中，整合新类别信息而不丢失先前获得的知识是一个核心挑战，通常被称为灾难性遗忘。&lt;h4&gt;目的&lt;/h4&gt;解决增量学习中的灾难性遗忘问题，提出一种新的FSCIL框架。&lt;h4&gt;方法&lt;/h4&gt;冻结预训练的ViT参数，通过添加更新机制选择性地将可训练权重注入到自注意力模块中，仅更新一小部分参数以适应新类别。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在基准数据集上实现了与基线FSCIL方法相比的最优性能。&lt;h4&gt;结论&lt;/h4&gt;通过冻结ViT参数和参数高效的增量更新，该框架能够有效减少过拟合风险，同时避免覆盖先前学习到的知识。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在人工智能中，整合新类别信息而不丢失先前获得的知识仍然是一个核心挑战，通常被称为灾难性遗忘。少量样本类别增量学习（FSCIL）通过首先在基类稳健数据集上训练模型，然后在连续会话中仅使用少量每个新类别的标记示例来增量适应模型来解决此问题。然而，这种方法容易在有限的新数据上过拟合，这可能会损害整体性能并加剧遗忘。在这项工作中，我们提出了一种简单而有效的FSCIL新框架，该框架利用冻结的视觉Transformer（ViT）骨干网络，并辅以参数高效的增量更新。我们的方法冻结了预训练的ViT参数，并通过添加更新机制选择性地将可训练权重注入到自注意力模块中。这种设计仅更新一小部分参数以适应新类别，而不牺牲基会话期间学习到的表示。通过微调有限数量的参数，我们的方法在冻结的ViT中保留了可推广的特征，同时降低了过拟合的风险。此外，由于大多数参数保持不变，当引入小的新的数据批次时，模型避免了覆盖先前学习到的知识。在基准数据集上的大量实验表明，与基线FSCIL方法相比，我们的方法实现了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrating new class information without losing previously acquiredknowledge remains a central challenge in artificial intelligence, oftenreferred to as catastrophic forgetting. Few-shot class incremental learning(FSCIL) addresses this by first training a model on a robust dataset of baseclasses and then incrementally adapting it in successive sessions using only afew labeled examples per novel class. However, this approach is prone tooverfitting on the limited new data, which can compromise overall performanceand exacerbate forgetting. In this work, we propose a simple yet effectivenovel FSCIL framework that leverages a frozen Vision Transformer (ViT) backboneaugmented with parameter-efficient additive updates. Our approach freezes thepre-trained ViT parameters and selectively injects trainable weights into theself-attention modules via an additive update mechanism. This design updatesonly a small subset of parameters to accommodate new classes withoutsacrificing the representations learned during the base session. By fine-tuninga limited number of parameters, our method preserves the generalizable featuresin the frozen ViT while reducing the risk of overfitting. Furthermore, as mostparameters remain fixed, the model avoids overwriting previously learnedknowledge when small novel data batches are introduced. Extensive experimentson benchmark datasets demonstrate that our approach yields state-of-the-artperformance compared to baseline FSCIL methods.</description>
      <author>example@mail.com (Kyle Stein, Andrew Arash Mahyari, Guillermo Francia III, Eman El-Sheikh)</author>
      <guid isPermaLink="false">2504.08982v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Towards On-Device Learning and Reconfigurable Hardware Implementation for Encoded Single-Photon Signal Processing</title>
      <link>http://arxiv.org/abs/2504.09028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 8 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于OSOS-ELM的在线训练算法，用于提高深度神经网络从时间分辨光子到达信号中重构关键参数的准确性和效率，同时优化了硬件资源利用。&lt;h4&gt;背景&lt;/h4&gt;传统的基于反向传播的深度神经网络在重构关键参数时对光学设置和生物样本参数非常敏感，需要频繁重新训练，且数据存储和传输引入了延迟和存储开销。&lt;h4&gt;目的&lt;/h4&gt;提出一种在线训练算法，解决传统DNNs性能依赖参数和频繁重新训练的问题，并提高硬件效率。&lt;h4&gt;方法&lt;/h4&gt;采用基于One-Sided Jacobi旋转的在线序列极端学习机（OSOS-ELM）算法，利用FPGA的异构并行处理能力，并实现了一种整体的计算原型。&lt;h4&gt;主要发现&lt;/h4&gt;OSOS-ELM和OSELM在不同网络维度上达到可比的准确度，且OSOS-ELM更具有硬件效率。通过案例研究验证了算法的有效性，并在Xilinx ZCU104 FPGA上实现了整体计算原型。&lt;h4&gt;结论&lt;/h4&gt;OSOS-ELM算法能够有效提高深度神经网络重构关键参数的性能，并通过硬件优化进一步提升了计算效率。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes an online training algorithm based on OSOS-ELM to improve the accuracy and efficiency of reconstructing key parameters from time-resolved photon arrival signals using deep neural networks. The algorithm addresses the issues of performance dependence on optical setup and biological sample parameters in conventional DNNs, which require frequent retraining. By leveraging the parallel processing capabilities of heterogeneous FPGAs, the proposed algorithm optimizes hardware resource utilization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks (DNNs) enhance the accuracy and efficiency ofreconstructing key parameters from time-resolved photon arrival signalsrecorded by single-photon detectors. However, the performance of conventionalbackpropagation-based DNNs is highly dependent on various parameters of theoptical setup and biological samples under examination, necessitating frequentnetwork retraining, either through transfer learning or from scratch. Newlycollected data must also be stored and transferred to a high-performance GPUserver for retraining, introducing latency and storage overhead. To addressthese challenges, we propose an online training algorithm based on a One-SidedJacobi rotation-based Online Sequential Extreme Learning Machine (OSOS-ELM). Wefully exploit parallelism in executing OSOS-ELM on a heterogeneous FPGA withintegrated ARM cores. Extensive evaluations of OSOS-ELM and OSELM demonstratethat both achieve comparable accuracy across different network dimensions(i.e., input, hidden, and output layers), while OSOS-ELM proves to be morehardware-efficient. By leveraging the parallelism of OSOS-ELM, we implement aholistic computing prototype on a Xilinx ZCU104 FPGA, which integrates amulti-core CPU and programmable logic fabric. We validate our approach throughthree case studies involving single-photon signal analysis: sensing through fogusing commercial single-photon LiDAR, fluorescence lifetime estimation in FLIM,and blood flow index reconstruction in DCS, all utilizing one-dimensional dataencoded from photonic signals. From a hardware perspective, we optimize theOSOS-ELM workload by employing multi-tasked processing on ARM CPU cores andpipelined execution on the FPGA's logic fabric. We also implement our OSOS-ELMon the NVIDIA Jetson Xavier NX GPU to comprehensively investigate its computingperformance on another type of heterogeneous computing platform.</description>
      <author>example@mail.com (Zhenya Zang, Xingda Li, David Day Uei Li)</author>
      <guid isPermaLink="false">2504.09028v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>A Constrained Optimization Approach for Gaussian Splatting from Coarsely-posed Images and Noisy Lidar Point Clouds</title>
      <link>http://arxiv.org/abs/2504.09129v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于约束优化的3D Gaussian Splatting (3DGS)方法，用于同时估计相机姿态和进行3D重建，无需依赖SfM算法。&lt;h4&gt;背景&lt;/h4&gt;3DGS是一种强大的重建技术，但需要从精确的相机姿态和高保真点云中进行初始化。通常，初始化来自SfM算法，但SfM过程耗时且限制了3DGS在现实场景和大规模场景重建中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要SfM支持的3DGS初始化方法，以提高重建效率和适用性。&lt;h4&gt;方法&lt;/h4&gt;将相机姿态分解为相机到（设备）中心和（设备）中心到世界的优化序列。提出两个优化约束，根据每个参数组的敏感性来限制搜索空间。直接从噪声点云中学习场景几何，并引入几何约束以提高重建质量。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在收集的数据集和两个公开基准测试上，都显著优于现有的3DGS基线和补充COLMAP的方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效地进行3DGS的初始化，无需SfM支持，且重建质量优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) is a powerful reconstruction technique, but itneeds to be initialized from accurate camera poses and high-fidelity pointclouds. Typically, the initialization is taken from Structure-from-Motion (SfM)algorithms; however, SfM is time-consuming and restricts the application of3DGS in real-world scenarios and large-scale scene reconstruction. We introducea constrained optimization method for simultaneous camera pose estimation and3D reconstruction that does not require SfM support. Core to our approach isdecomposing a camera pose into a sequence of camera-to-(device-)center and(device-)center-to-world optimizations. To facilitate, we propose twooptimization constraints conditioned to the sensitivity of each parameter groupand restricts each parameter's search space. In addition, as we learn the scenegeometry directly from the noisy point clouds, we propose geometric constraintsto improve the reconstruction quality. Experiments demonstrate that theproposed method significantly outperforms the existing (multi-modal) 3DGSbaseline and methods supplemented by COLMAP on both our collected dataset andtwo public benchmarks.</description>
      <author>example@mail.com (Jizong Peng, Tze Ho Elden Tse, Kai Xu, Wenchao Gao, Angela Yao)</author>
      <guid isPermaLink="false">2504.09129v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>PCM-SAR: Physics-Driven Contrastive Mutual Learning for SAR Classification</title>
      <link>http://arxiv.org/abs/2504.09502v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于物理驱动的对比互学习SAR图像分类方法PCM-SAR，旨在解决现有方法在SAR数据样本生成和特征提取上的不足。&lt;h4&gt;背景&lt;/h4&gt;现有的基于对比学习的SAR图像分类方法常常依赖于为光学图像设计的样本生成策略，未能充分捕捉SAR数据的独特语义和物理特征。&lt;h4&gt;目的&lt;/h4&gt;提出PCM-SAR方法，通过结合领域特定的物理洞察力，改善样本生成和特征提取过程。&lt;h4&gt;方法&lt;/h4&gt;PCM-SAR利用灰度共生矩阵（GLCM）模拟真实的噪声模式，并应用语义检测进行无监督的局部采样，以确保生成的样本准确反映SAR成像特性。此外，采用基于互学习的多级特征融合机制，实现特征表示的协作优化。PCM-SAR通过细化SAR特征表示，显著提升了小型模型的性能。&lt;h4&gt;主要发现&lt;/h4&gt;PCM-SAR在多个数据集和SAR分类任务上，一致优于现有最先进（SOTA）的方法。&lt;h4&gt;结论&lt;/h4&gt;PCM-SAR方法有效提高了SAR图像分类的性能，尤其是在处理小型模型时，能够补偿其有限的容量。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a physics-driven contrastive mutual learning method, PCM-SAR, for SAR image classification. PCM-SAR addresses the limitations of existing methods by incorporating domain-specific physical insights to improve sample generation and feature extraction. Utilizing the gray-level co-occurrence matrix (GLCM) and semantic detection, PCM-SAR ensures that the generated samples accurately reflect SAR imaging properties. Furthermore, a multi-level feature fusion mechanism based on mutual learning refines feature representations collaboratively. Notably, PCM-SAR significantly enhances the performance of smaller models by refining SAR feature representations, compensating for their limited capacity. Experimental results demonstrate that PCM-SAR consistently outperforms state-of-the-art (SOTA) methods across diverse datasets and SAR classification tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing SAR image classification methods based on Contrastive Learning oftenrely on sample generation strategies designed for optical images, failing tocapture the distinct semantic and physical characteristics of SAR data. Toaddress this, we propose Physics-Driven Contrastive Mutual Learning for SARClassification (PCM-SAR), which incorporates domain-specific physical insightsto improve sample generation and feature extraction. PCM-SAR utilizes thegray-level co-occurrence matrix (GLCM) to simulate realistic noise patterns andapplies semantic detection for unsupervised local sampling, ensuring generatedsamples accurately reflect SAR imaging properties. Additionally, a multi-levelfeature fusion mechanism based on mutual learning enables collaborativerefinement of feature representations. Notably, PCM-SAR significantly enhancessmaller models by refining SAR feature representations, compensating for theirlimited capacity. Experimental results show that PCM-SAR consistentlyoutperforms SOTA methods across diverse datasets and SAR classification tasks.</description>
      <author>example@mail.com (Pengfei Wang, Hao Zheng, Zhigang Hu, Aikun Xu, Meiguang Zheng, Liu Yang)</author>
      <guid isPermaLink="false">2504.09502v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning</title>
      <link>http://arxiv.org/abs/2504.06958v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了使用强化学习中的RFT（Reinforcement Fine-Tuning）和GRPO（Group Relative Policy Optimization）方法，对视频多模态大语言模型（MLLMs）进行系统性的探索，旨在提升时空感知能力的同时保持通用能力。&lt;h4&gt;背景&lt;/h4&gt;近年来，强化学习在多模态大语言模型（MLLMs）的推理能力方面取得了显著进展。然而，GRPO和基于规则的奖励机制在文本和图像领域表现出潜力，但在视频理解领域的应用仍然有限。&lt;h4&gt;目的&lt;/h4&gt;通过RFT方法，提升视频MLLMs的时空感知能力，同时保持其通用能力。&lt;h4&gt;方法&lt;/h4&gt;论文通过在时空感知目标上进行多任务RFT，并在有限的样本下进行实验，开发出VideoChat-R1，这是一种强大的视频MLLM，在时空感知任务上达到了最先进的性能，同时不牺牲聊天能力，并展现出时空推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;VideoChat-R1在时空定位（+31.8）和对象跟踪（+31.2）等任务上，相比于Qwen2.5-VL-7B提升了数倍性能。此外，它在VideoMME（+0.9）、MVBench（+1.0）和感知测试（+0.9）等通用QAbenchmarks上也显著改进。&lt;h4&gt;结论&lt;/h4&gt;RFT对于视频MLLMs的特定任务增强具有潜力，研究结果为未来视频MLLMs的RL研究提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents a systematic exploration of Reinforcement Fine-Tuning (RFT) with Group Relative Policy Optimization (GRPO) for video multimodal large language models (MLLMs), aiming to enhance spatio-temporal perception while maintaining general capabilities. Our experiments reveal that RFT is highly data-efficient for task-specific improvements. Through multi-task RFT on spatio-temporal perception objectives with limited samples, we develop VideoChat-R1, a powerful video MLLM that achieves state-of-the-art performance on spatio-temporal perception tasks without sacrificing chat ability, while exhibiting emerging spatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1 boosts performance several-fold in tasks like temporal grounding (+31.8) and object tracking (+31.2). Additionally, it significantly improves on general QAbenchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9). Our findings underscore the potential of RFT for specialized task enhancement of Video MLLMs. We hope our work offers valuable insights for future RL research in video MLLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in reinforcement learning have significantly advanced thereasoning capabilities of multimodal large language models (MLLMs). Whileapproaches such as Group Relative Policy Optimization (GRPO) and rule-basedreward mechanisms demonstrate promise in text and image domains, theirapplication to video understanding remains limited. This paper presents asystematic exploration of Reinforcement Fine-Tuning (RFT) with GRPO for videoMLLMs, aiming to enhance spatio-temporal perception while maintaining generalcapabilities. Our experiments reveal that RFT is highly data-efficient fortask-specific improvements. Through multi-task RFT on spatio-temporalperception objectives with limited samples, we develop VideoChat-R1, a powerfulvideo MLLM that achieves state-of-the-art performance on spatio-temporalperception tasks without sacrificing chat ability, while exhibiting emergingspatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1boosts performance several-fold in tasks like temporal grounding (+31.8) andobject tracking (+31.2). Additionally, it significantly improves on general QAbenchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9).Our findings underscore the potential of RFT for specialized task enhancementof Video MLLMs. We hope our work offers valuable insights for future RLresearch in video MLLMs.</description>
      <author>example@mail.com (Xinhao Li, Ziang Yan, Desen Meng, Lu Dong, Xiangyu Zeng, Yinan He, Yali Wang, Yu Qiao, Yi Wang, Limin Wang)</author>
      <guid isPermaLink="false">2504.06958v3</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Federated Prototype Graph Learning</title>
      <link>http://arxiv.org/abs/2504.09493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Federated Graph Learning (FGL)在分布式训练和隐私保护方面具有显著优势，但多级FGL异构性带来了挑战。&lt;h4&gt;背景&lt;/h4&gt;FGL在图机器智能应用中具有分布式训练能力，可以缓解数据孤岛问题，但多级FGL异构性带来了模型、数据和通信层面的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出FedPG，一种通用的原型引导优化方法，以解决多级FGL异构性问题。&lt;h4&gt;方法&lt;/h4&gt;在客户端，集成多级拓扑感知原型来捕捉局部图语义；在服务器端，利用上传的原型，采用拓扑引导的对比学习和个性化技术来定制每个客户端的全局原型，并通过广播提高局部训练。&lt;h4&gt;主要发现&lt;/h4&gt;FedPG在准确率上优于现有基准，平均提高了3.57%，同时将通信成本降低了168倍。&lt;h4&gt;结论&lt;/h4&gt;FedPG是解决多级FGL异构性问题的一种有效方法，可以提高性能并降低通信成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, Federated Graph Learning (FGL) has gained significantattention for its distributed training capabilities in graph-based machineintelligence applications, mitigating data silos while offering a newperspective for privacy-preserve large-scale graph learning. However,multi-level FGL heterogeneity presents various client-server collaborationchallenges: (1) Model-level: The variation in clients for expected performanceand scalability necessitates the deployment of heterogeneous models.Unfortunately, most FGL methods rigidly demand identical client models due tothe direct model weight aggregation on the server. (2) Data-level: Theintricate nature of graphs, marked by the entanglement of node profiles andtopology, poses an optimization dilemma. This implies that models obtained byfederated training struggle to achieve superior performance. (3)Communication-level: Some FGL methods attempt to increase message sharing amongclients or between clients and the server to improve training, which inevitablyleads to high communication costs. In this paper, we propose FedPG as a generalprototype-guided optimization method for the above multi-level FGLheterogeneity. Specifically, on the client side, we integrate multi-leveltopology-aware prototypes to capture local graph semantics. Subsequently, onthe server side, leveraging the uploaded prototypes, we employ topology-guidedcontrastive learning and personalized technology to tailor global prototypesfor each client, broadcasting them to improve local training. Experimentsdemonstrate that FedPG outperforms SOTA baselines by an average of 3.57\% inaccuracy while reducing communication costs by 168x.</description>
      <author>example@mail.com (Zhengyu Wu, Xunkai Li, Yinlin Zhu, Rong-Hua Li, Guoren Wang, Chenghu Zhou)</author>
      <guid isPermaLink="false">2504.09493v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Distilling and exploiting quantitative insights from Large Language Models for enhanced Bayesian optimization of chemical reactions</title>
      <link>http://arxiv.org/abs/2504.08874v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了如何从大型语言模型（LLMs）中提取化学信息用于迁移学习，以加速化学反应的优化。&lt;h4&gt;背景&lt;/h4&gt;机器学习和贝叶斯优化算法可以显著加速化学反应的优化。迁移学习可以通过利用现有化学信息或与直接优化任务无关的数据来提高贝叶斯优化算法在低数据环境下的有效性。&lt;h4&gt;目的&lt;/h4&gt;考察LLM中的化学信息如何被提取并用于迁移学习，以加速通过最大化产量来优化反应条件。&lt;h4&gt;方法&lt;/h4&gt;使用调查式的提示方案和偏好学习来推断效用函数，该效用函数模型化LLM中嵌入在化学参数空间中的先前化学信息；利用效用函数来集中在参数空间的有希望的区域内，从而提高初始贝叶斯优化查询的产量并增强优化。&lt;h4&gt;主要发现&lt;/h4&gt;效用函数与实际实验测量（产量）在参数空间中显示出适度相关性，即使在零样本设置下也是如此；利用效用函数可以增强优化在6个数据集中4个数据集的优化效果。&lt;h4&gt;结论&lt;/h4&gt;这项工作将LLM中嵌入的化学知识与原理性贝叶斯优化方法加速反应优化的能力联系起来，被视为填补这一差距的一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning and Bayesian optimization (BO) algorithms can significantlyaccelerate the optimization of chemical reactions. Transfer learning canbolster the effectiveness of BO algorithms in low-data regimes by leveragingpre-existing chemical information or data outside the direct optimization task(i.e., source data). Large language models (LLMs) have demonstrated thatchemical information present in foundation training data can give them utilityfor processing chemical data. Furthermore, they can be augmented with and helpsynthesize potentially multiple modalities of source chemical data germane tothe optimization task. In this work, we examine how chemical information fromLLMs can be elicited and used for transfer learning to accelerate the BO ofreaction conditions to maximize yield. Specifically, we show that a survey-likeprompting scheme and preference learning can be used to infer a utilityfunction which models prior chemical information embedded in LLMs over achemical parameter space; we find that the utility function shows modestcorrelation to true experimental measurements (yield) over the parameter spacedespite operating in a zero-shot setting. Furthermore, we show that the utilityfunction can be leveraged to focus BO efforts in promising regions of theparameter space, improving the yield of the initial BO query and enhancingoptimization in 4 of the 6 datasets studied. Overall, we view this work as astep towards bridging the gap between the chemistry knowledge embedded in LLMsand the capabilities of principled BO methods to accelerate reactionoptimization.</description>
      <author>example@mail.com (Roshan Patel, Saeed Moayedpour, Louis De Lescure, Lorenzo Kogler-Anele, Alan Cherney, Sven Jager, Yasser Jangjou)</author>
      <guid isPermaLink="false">2504.08874v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Application of Contrastive Learning on ECG Data: Evaluating Performance in Japanese and Classification with Around 100 Labels</title>
      <link>http://arxiv.org/abs/2504.09302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 1 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了心电图（ECG）在心血管诊断中的应用，探讨了如何利用机器学习从ECG数据中提取信息，以及如何将多模态机器学习框架应用于非英语语言的临床研究。&lt;h4&gt;背景&lt;/h4&gt;ECG是心血管诊断的基本工具，具有强大且非侵入性的特点，常用于确定是否需要更详细的检查。由于用户专业水平各异，避免关键错误变得尤为重要。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过机器学习从ECG数据中提取有价值的信息，并实现多模态模型的分类，以帮助用户避免关键错误。&lt;h4&gt;方法&lt;/h4&gt;研究者使用了来自日本医院的常规患者ECG数据，并利用对比学习框架进行分类。他们使用了一个基于日本的、具有98个标签的语言模型。&lt;h4&gt;主要发现&lt;/h4&gt;即使在只有98个标签的情况下，基于日本的语言模型在分类准确率上与之前的研究相当，这表明了多模态机器学习框架在非英语语言临床研究中的适用性。&lt;h4&gt;结论&lt;/h4&gt;该研究扩展了多模态机器学习框架在更广泛的临床研究和非英语语言中的应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：心电图（ECG）由于其强大且非侵入性的特性，是心血管诊断的基本工具。其最关键的应用之一是确定是否需要更详细的检查，用户涵盖不同专业水平。鉴于这种专业水平的多样性，帮助用户避免关键错误至关重要。近年来，机器学习研究通过从ECG数据中提取有价值信息来解决这一挑战。利用语言模型，这些研究实现了旨在根据标记术语对ECG进行分类的多模态模型。然而，类别数量有所减少，并且这种方法是否适用于英语以外的语言还不确定。为了向实际应用迈进，我们使用了来自日本医院常规患者的ECG数据，并维护了大量从实际ECG读数中获得的日本标签。使用对比学习框架，我们发现即使有98个分类标签，我们的基于日本的语模型也实现了与先前研究相当的准确率。这项研究扩展了多模态机器学习框架在更广泛的临床研究和非英语语言中的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The electrocardiogram (ECG) is a fundamental tool in cardiovasculardiagnostics due to its powerful and non-invasive nature. One of the mostcritical usages is to determine whether more detailed examinations arenecessary, with users ranging across various levels of expertise. Given thisdiversity in expertise, it is essential to assist users to avoid criticalerrors. Recent studies in machine learning have addressed this challenge byextracting valuable information from ECG data. Utilizing language models, thesestudies have implemented multimodal models aimed at classifying ECGs accordingto labeled terms. However, the number of classes was reduced, and it remainsuncertain whether the technique is effective for languages other than English.To move towards practical application, we utilized ECG data from regularpatients visiting hospitals in Japan, maintaining a large number of Japaneselabels obtained from actual ECG readings. Using a contrastive learningframework, we found that even with 98 labels for classification, ourJapanese-based language model achieves accuracy comparable to previousresearch. This study extends the applicability of multimodal machine learningframeworks to broader clinical studies and non-English languages.</description>
      <author>example@mail.com (Junichiro Takahashi, JingChuan Guan, Masataka Sato, Kaito Baba, Kazuto Haruguchi, Daichi Nagashima, Satoshi Kodera, Norihiko Takeda)</author>
      <guid isPermaLink="false">2504.09302v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Artificial Intelligence Augmented Medical Imaging Reconstruction in Radiation Therapy</title>
      <link>http://arxiv.org/abs/2504.08844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD thesis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一系列基于人工智能的医学影像重建框架，旨在提升放射治疗的效果。&lt;h4&gt;背景&lt;/h4&gt;高效获取和精确重建的影像对于现代放射治疗至关重要，CT和MRI是常见的治疗规划和指导/监测手段。&lt;h4&gt;目的&lt;/h4&gt;设计AI驱动的医学影像重建框架，以提升CT图像重建的质量和速度，优化双能量CT（DECT）的多材料分解（MMD），并显著加速4D MRI的采集。&lt;h4&gt;方法&lt;/h4&gt;利用人工智能技术进行医学影像的重建。&lt;h4&gt;主要发现&lt;/h4&gt;提出的框架能够改善CT图像重建质量、提高速度、优化DECT的多材料分解以及加速4D MRI的采集。&lt;h4&gt;结论&lt;/h4&gt;AI驱动的医学影像重建框架对于增强放射治疗具有显著的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Efficiently acquired and precisely reconstructed imaging are crucial to the success of modern radiation therapy (RT). Computed tomography (CT) and magnetic resonance imaging (MRI) are two common modalities for providing RT treatment planning and delivery guidance/monitoring. In recent decades, artificial intelligence (AI) has emerged as a powerful and widely adopted technique across various fields, valued for its efficiency and convenience enabled by implicit function definition and data-driven feature representation learning. Here, we present a series of AI-driven medical imaging reconstruction frameworks for enhanced radiotherapy, designed to improve CT image reconstruction quality and speed, refine dual-energy CT (DECT) multi-material decomposition (MMD), and significantly accelerate 4D MRI acquisition.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficiently acquired and precisely reconstructed imaging are crucial to thesuccess of modern radiation therapy (RT). Computed tomography (CT) and magneticresonance imaging (MRI) are two common modalities for providing RT treatmentplanning and delivery guidance/monitoring. In recent decades, artificialintelligence (AI) has emerged as a powerful and widely adopted technique acrossvarious fields, valued for its efficiency and convenience enabled by implicitfunction definition and data-driven feature representation learning. Here, wepresent a series of AI-driven medical imaging reconstruction frameworks forenhanced radiotherapy, designed to improve CT image reconstruction quality andspeed, refine dual-energy CT (DECT) multi-material decomposition (MMD), andsignificantly accelerate 4D MRI acquisition.</description>
      <author>example@mail.com (Di Xu)</author>
      <guid isPermaLink="false">2504.08844v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Generation of Musical Timbres using a Text-Guided Diffusion Model</title>
      <link>http://arxiv.org/abs/2504.09219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，文本到音频系统在直接从文本描述生成完整音频片段方面取得了显著成功，但往往限制了人类创造性和有意表达。本研究提出了一种系统，允许作曲家、编曲家和表演者创建音乐创作的基本构建块：用于电子乐器和数字音频工作站的音乐音符音频。&lt;h4&gt;背景&lt;/h4&gt;文本到音频系统在音乐创作中的应用日益广泛，但现有系统往往缺乏人类创造性和有意表达。&lt;h4&gt;目的&lt;/h4&gt;开发一种系统，使作曲家、编曲家和表演者能够创建音乐创作的基本音频构建块。&lt;h4&gt;方法&lt;/h4&gt;该系统结合了潜在扩散模型和多模态对比学习，根据文本描述生成音乐音色。该方法通过联合生成频谱图的幅度和相位，消除了后续运行相位检索算法的需要。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种基于文本描述生成音乐音色的系统，该系统通过联合生成频谱图的幅度和相位，无需额外的相位检索算法。&lt;h4&gt;结论&lt;/h4&gt;该系统为音乐创作提供了新的工具，允许用户通过文本提示指定音频的音色特征。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, text-to-audio systems have achieved remarkable success, enabling the generation of complete audio segments directly from text descriptions. While these systems also facilitate music creation, the element of human creativity and deliberate expression is often limited. In contrast, the present work allows composers, arrangers, and performers to create the basic building blocks for music creation: audio of individual musical notes for use in electronic instruments and DAWs. Through text prompts, the user can specify the timbre characteristics of the audio. We introduce a system that combines a latent diffusion model and multi-modal contrastive learning to generate musical timbres conditioned on text descriptions. By jointly generating the magnitude and phase of the spectrogram, our method eliminates the need for subsequently running a phase retrieval algorithm, as related methods do. Audio examples, source code, and a web app are available at https://wxuanyuan.github.io/Musical-Note-Generation/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, text-to-audio systems have achieved remarkable success,enabling the generation of complete audio segments directly from textdescriptions. While these systems also facilitate music creation, the elementof human creativity and deliberate expression is often limited. In contrast,the present work allows composers, arrangers, and performers to create thebasic building blocks for music creation: audio of individual musical notes foruse in electronic instruments and DAWs. Through text prompts, the user canspecify the timbre characteristics of the audio. We introduce a system thatcombines a latent diffusion model and multi-modal contrastive learning togenerate musical timbres conditioned on text descriptions. By jointlygenerating the magnitude and phase of the spectrogram, our method eliminatesthe need for subsequently running a phase retrieval algorithm, as relatedmethods do.  Audio examples, source code, and a web app are available athttps://wxuanyuan.github.io/Musical-Note-Generation/</description>
      <author>example@mail.com (Weixuan Yuan, Qadeer Khan, Vladimir Golkov)</author>
      <guid isPermaLink="false">2504.09219v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Repetitive Contrastive Learning Enhances Mamba's Selectivity in Time Series Prediction</title>
      <link>http://arxiv.org/abs/2504.09185v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Repetitive Contrastive Learning (RCL)的框架，旨在增强Mamba模型在时间序列预测中的选择性能力，并通过实验证明了其在提升模型性能方面的有效性。&lt;h4&gt;背景&lt;/h4&gt;时间序列预测是长期序列预测的关键挑战，Mamba模型虽然表现出色，但存在选择性能力不足和噪声抑制不完整的问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决Mamba模型在选择性能力上的不足，提出了RCL框架，旨在增强其选择性能力，并提高时间序列预测的性能。&lt;h4&gt;方法&lt;/h4&gt;RCL通过序列增强和对比学习，使Mamba模块能够优先考虑信息丰富的时步，同时忽略噪声。具体方法包括：对Mamba块进行预训练，并将预训练参数转移到不同的骨干模型中，以及使用高斯噪声进行序列增强。&lt;h4&gt;主要发现&lt;/h4&gt;RCL显著提升了骨干模型的性能，超越了现有方法，并达到了最先进的水平。此外，还提出了两个指标来量化Mamba的选择性能力，为RCL带来的改进提供了理论、定性和定量证据。&lt;h4&gt;结论&lt;/h4&gt;RCL框架有效增强了Mamba模型的选择性能力，显著提升了时间序列预测的性能，为该领域的研究提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long sequence prediction is a key challenge in time series forecasting. WhileMamba-based models have shown strong performance due to their sequenceselection capabilities, they still struggle with insufficient focus on criticaltime steps and incomplete noise suppression, caused by limited selectiveabilities. To address this, we introduce Repetitive Contrastive Learning (RCL),a token-level contrastive pretraining framework aimed at enhancing Mamba'sselective capabilities. RCL pretrains a single Mamba block to strengthen itsselective abilities and then transfers these pretrained parameters toinitialize Mamba blocks in various backbone models, improving their temporalprediction performance. RCL uses sequence augmentation with Gaussian noise andapplies inter-sequence and intra-sequence contrastive learning to help theMamba module prioritize information-rich time steps while ignoring noisy ones.Extensive experiments show that RCL consistently boosts the performance ofbackbone models, surpassing existing methods and achieving state-of-the-artresults. Additionally, we propose two metrics to quantify Mamba's selectivecapabilities, providing theoretical, qualitative, and quantitative evidence forthe improvements brought by RCL.</description>
      <author>example@mail.com (Wenbo Yan, Hanzhong Cao, Ying Tan)</author>
      <guid isPermaLink="false">2504.09185v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Pushing the Accuracy Limit of Foundation Neural Network Models with Quantum Monte Carlo Forces and Path Integrals</title>
      <link>http://arxiv.org/abs/2504.07948v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种端到端集成策略，旨在生成高精度的量子化学合成数据集（能量和力），用于推导分子模拟的基础机器学习模型。&lt;h4&gt;背景&lt;/h4&gt;基于密度泛函理论（DFT）和大规模GPU加速软件的“雅各布楼梯”方法，在提高计算精度方面取得了进展。&lt;h4&gt;目的&lt;/h4&gt;通过Exascale计算，首次在完全基组极限下进行计算密集型量子蒙特卡罗力（QMC）的计算，以及将多态QMC能量和力与选定的配置相互作用波函数相结合。&lt;h4&gt;方法&lt;/h4&gt;利用迁移学习提高基于DFT的FeNNix-Bio1基础模型，并与路径积分自适应采样量子动力学相结合，以进行前所未有的纳米秒级反应模拟。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法展示了Exascale在深化我们对复杂生物系统内部机制理解方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;该方法有望在分子模拟领域产生重大影响，并为理解复杂生物系统提供新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose an end-to-end integrated strategy to produce highly accuratequantum chemistry (QC) synthetic datasets (energies and forces) aimed atderiving Foundation Machine Learning models for molecular simulation. Startingfrom Density Functional Theory (DFT), a "Jacob's Ladder" approach leveragescomputationally-optimized layers of massively GPU-accelerated software withincreasing accuracy. Thanks to Exascale, this is the first time that thecomputationally intensive calculation of Quantum Monte Carlo forces (QMC), andthe combination of multi-determinant QMC energies and forces withselected-Configuration Interaction wavefunctions, are computed at such scale atthe complete basis-set limit. To bridge the gap between accurate QC andcondensed-phase Molecular Dynamics, we leverage transfer learning to improvethe DFT-based FeNNix-Bio1 foundation model. The resulting approach is coupledto path integrals adaptive sampling quantum dynamics to perform nanosecondreactive simulations at unprecedented accuracy. These results demonstrate thepromise of Exascale to deepen our understanding of the inner machinery ofcomplex biosystems.</description>
      <author>example@mail.com (Anouar Benali, Thomas Plé, Olivier Adjoua, Valay Agarawal, Thomas Applencourt, Marharyta Blazhynska, Raymond Clay III, Kevin Gasperich, Khalid Hossain, Jeongnim Kim, Christopher Knight, Jaron T. Krogel, Yvon Maday, Maxime Maria, Matthieu Montes, Ye Luo, Evgeny Posenitskiy, Corentin Villot, Venkatram Vishwanath, Louis Lagardère, Jean-Philip Piquemal)</author>
      <guid isPermaLink="false">2504.07948v3</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>GenEDA: Unleashing Generative Reasoning on Netlist via Multimodal Encoder-Decoder Aligned Foundation Model</title>
      <link>http://arxiv.org/abs/2504.09485v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 9 figures, and 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GenEDA，这是一个将电路编码器与解码器在共享潜在空间中对齐的框架，旨在提高集成电路设计过程的效率。&lt;h4&gt;背景&lt;/h4&gt;现有预训练的电路模型通常仅限于作为预测任务的独立编码器或生成任务的解码器。这两种模型类型独立开发，运行在不同的电路模式上，并位于不同的潜在空间中，这限制了它们在更高级应用中相互补充的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架，将电路编码器与解码器在共享潜在空间中对齐，以便在电路设计过程中提供更强大的功能。&lt;h4&gt;方法&lt;/h4&gt;提出两种范式来支持开源可训练的大语言模型和商业冻结的大语言模型。基于对齐的架构，GenEDA能够执行三种前所未有的生成推理任务，从低级别的网表中以不同粒度逆向生成高级功能。&lt;h4&gt;主要发现&lt;/h4&gt;GenEDA将基于图的电路表示与基于文本的大语言模型（LLMs）连接起来，使得它们各自的潜在空间之间能够进行通信。实验表明，GenEDA显著提升了高级LLMs（如GPT-4o和DeepSeek-V3）在所有任务上的性能。&lt;h4&gt;结论&lt;/h4&gt;GenEDA通过共享潜在空间对齐电路编码器与解码器，为集成电路设计提供了一种新的、更有效的工具，并显著提升了LLMs的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The success of foundation AI has motivated the research of circuit foundationmodels, which are customized to assist the integrated circuit (IC) designprocess. However, existing pre-trained circuit models are typically limited tostandalone encoders for predictive tasks or decoders for generative tasks.These two model types are developed independently, operate on different circuitmodalities, and reside in separate latent spaces, which restricts their abilityto complement each other for more advanced applications. In this work, wepresent GenEDA, the first framework that aligns circuit encoders with decoderswithin a shared latent space. GenEDA bridges the gap between graph-basedcircuit representations and text-based large language models (LLMs), enablingcommunication between their respective latent spaces. To achieve the alignment,we propose two paradigms that support both open-source trainable LLMs andcommercial frozen LLMs. Built on this aligned architecture, GenEDA enablesthree unprecedented generative reasoning tasks over netlists, where the modelreversely generates the high-level functionality from low-level netlists indifferent granularities. These tasks extend traditional gate-type prediction todirect generation of full-circuit functionality. Experiments demonstrate thatGenEDA significantly boosts advanced LLMs' (e.g., GPT-4o and DeepSeek-V3)performance in all tasks.</description>
      <author>example@mail.com (Wenji Fang, Jing Wang, Yao Lu, Shang Liu, Zhiyao Xie)</author>
      <guid isPermaLink="false">2504.09485v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Vision-Language Model for Object Detection and Segmentation: A Review and Evaluation</title>
      <link>http://arxiv.org/abs/2504.09480v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A Review and Evaluation about Vision-Language Model for Object  Detection and Segmentation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基于视觉-语言模型（VLM）的检测和分割技术进行了系统回顾，评估了VLM在不同下游任务中的效果，并分析了模型架构、任务特性和训练方法之间的关系。&lt;h4&gt;背景&lt;/h4&gt;VLM在开放词汇（OV）物体检测和分割任务中得到了广泛应用，但在传统视觉任务中的有效性尚未得到评估。&lt;h4&gt;目的&lt;/h4&gt;评估VLM在不同检测和分割任务中的表现，并分析其相关因素。&lt;h4&gt;方法&lt;/h4&gt;1）对VLM在不同检测（如封闭集检测、领域自适应、拥挤物体等）和分割（如少样本、开放世界、小物体等）场景中的表现进行了评估；2）对检测任务中的VLM在不同微调粒度（零预测、视觉微调、文本提示）下的表现进行了评估；3）基于实证研究，分析了任务特征、模型架构和训练方法之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;1）揭示了不同VLM架构在不同任务中的性能优势和局限性；2）不同微调策略对性能的影响；3）任务特征、模型架构和训练方法之间存在关联。&lt;h4&gt;结论&lt;/h4&gt;该研究为计算机视觉、多模态学习和视觉基础模型领域的模式识别专家提供了有价值的信息，并指出了未来研究的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉-语言模型（VLM）在开放词汇（OV）物体检测和分割任务中得到了广泛应用。尽管它们在OV相关任务中显示出前景，但它们在传统视觉任务中的有效性至今尚未得到评估。在这项工作中，我们进行了基于VLM的检测和分割的系统性回顾，将VLM视为基础模型，并首次对多个下游任务进行了全面评估：1）评估涵盖了八个检测场景（封闭集检测、领域自适应、拥挤物体等）和八个分割场景（少样本、开放世界、小物体等），揭示了不同VLM架构在任务中的不同性能优势和局限性。2）对于检测任务，我们在三个微调粒度下评估了VLM：零预测、视觉微调和文本提示，并进一步分析了不同的微调策略在不同任务下的性能影响。3）基于实证发现，我们对任务特征、模型架构和训练方法之间的关系进行了深入分析，为未来的VLM设计提供了见解。4）我们认为这项工作将对计算机视觉、多模态学习和视觉基础模型领域的模式识别专家有价值，通过介绍他们了解问题，熟悉当前的研究进展，并为其未来的研究提供有希望的方向。与这次回顾和评估相关的项目已在https://github.com/better-chao/perceptual_abilities_evaluation创建。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Model (VLM) have gained widespread adoption inOpen-Vocabulary (OV) object detection and segmentation tasks. Despite they haveshown promise on OV-related tasks, their effectiveness in conventional visiontasks has thus far been unevaluated. In this work, we present the systematicreview of VLM-based detection and segmentation, view VLM as the foundationalmodel and conduct comprehensive evaluations across multiple downstream tasksfor the first time: 1) The evaluation spans eight detection scenarios(closed-set detection, domain adaptation, crowded objects, etc.) and eightsegmentation scenarios (few-shot, open-world, small object, etc.), revealingdistinct performance advantages and limitations of various VLM architecturesacross tasks. 2) As for detection tasks, we evaluate VLMs under threefinetuning granularities: \textit{zero prediction}, \textit{visualfine-tuning}, and \textit{text prompt}, and further analyze how differentfinetuning strategies impact performance under varied task. 3) Based onempirical findings, we provide in-depth analysis of the correlations betweentask characteristics, model architectures, and training methodologies, offeringinsights for future VLM design. 4) We believe that this work shall be valuableto the pattern recognition experts working in the fields of computer vision,multimodal learning, and vision foundation models by introducing them to theproblem, and familiarizing them with the current status of the progress whileproviding promising directions for future research. A project associated withthis review and evaluation has been created athttps://github.com/better-chao/perceptual_abilities_evaluation.</description>
      <author>example@mail.com (Yongchao Feng, Yajie Liu, Shuai Yang, Wenrui Cai, Jinqing Zhang, Qiqi Zhan, Ziyue Huang, Hongxi Yan, Qiao Wan, Chenguang Liu, Junzhe Wang, Jiahui Lv, Ziqi Liu, Tengyuan Shi, Qingjie Liu, Yunhong Wang)</author>
      <guid isPermaLink="false">2504.09480v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Effectiveness and Interpretability of Texts in LLM-based Time Series Models</title>
      <link>http://arxiv.org/abs/2504.08808v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了将文本数据融入大型语言模型（LLMs）进行时间序列预测的有效性和可解释性。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）被应用于时间序列预测任务，通过利用预训练的语言模型作为基础，并结合文本数据来增强LLMs的综合能力。&lt;h4&gt;目的&lt;/h4&gt;研究旨在调查文本数据融入LLMs进行时间序列预测的实际效果和可解释性。&lt;h4&gt;方法&lt;/h4&gt;通过一系列关于文本提示和文本原型的实证实验，研究者提出了新的指标——语义匹配指数（SMI），用于评估时间序列与文本之间的匹配度。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，两种模态之间存在不匹配，文本信息在许多情况下并没有显著提高时间序列预测的性能。可视化分析表明，现有框架学习到的文本表示在应用于时间序列数据时缺乏足够的可解释性。&lt;h4&gt;结论&lt;/h4&gt;研究揭示了当前时间序列LLMs中文本的不匹配和可解释性有限的问题，并希望这一研究能够提高对文本时间序列可解释性的认识。&lt;h4&gt;翻译&lt;/h4&gt;The study investigates the effectiveness and interpretability of incorporating textual data into large language models (LLMs) for time series forecasting. LLMs have been applied to time series forecasting tasks, leveraging pre-trained language models as the backbone and incorporating textual data to enhance the comprehensive capabilities of LLMs for time series. However, this study aims to investigate the actual efficacy and interpretability of such textual incorporations. Through a series of empirical experiments on textual prompts and textual prototypes, the study reveals the misalignment between two modalities and finds that textual information does not significantly improve time series forecasting performance in many cases. Visualization analysis indicates that the textual representations learned by existing frameworks lack sufficient interpretability when applied to time series data. A novel metric named Semantic Matching Index (SMI) is proposed to better evaluate the matching degree between time series and texts during the post hoc interpretability investigation. The study reveals the misalignment and limited interpretability of texts in current time-series LLMs and hopes to raise awareness of the interpretability of texts for time series. The code is available at https://github.com/zachysun/TS-Lang-Exp.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have been applied to time series forecastingtasks, leveraging pre-trained language models as the backbone and incorporatingtextual data to purportedly enhance the comprehensive capabilities of LLMs fortime series. However, are these texts really helpful for interpretation? Thisstudy seeks to investigate the actual efficacy and interpretability of suchtextual incorporations. Through a series of empirical experiments on textualprompts and textual prototypes, our findings reveal that the misalignmentbetween two modalities exists, and the textual information does notsignificantly improve time series forecasting performance in many cases.Furthermore, visualization analysis indicates that the textual representationslearned by existing frameworks lack sufficient interpretability when applied totime series data. We further propose a novel metric named Semantic MatchingIndex (SMI) to better evaluate the matching degree between time series andtexts during our post hoc interpretability investigation. Our analysis revealsthe misalignment and limited interpretability of texts in current time-seriesLLMs, and we hope this study can raise awareness of the interpretability oftexts for time series. The code is available athttps://github.com/zachysun/TS-Lang-Exp.</description>
      <author>example@mail.com (Zhengke Sun, Hangwei Qian, Ivor Tsang)</author>
      <guid isPermaLink="false">2504.08808v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>ReferGPT: Towards Zero-Shot Referring Multi-Object Tracking</title>
      <link>http://arxiv.org/abs/2504.09195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted CVPR 2025 Workshop on Distillation of Foundation Models for  Autonomous Driving&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ReferGPT的新型零样本多目标跟踪框架，该框架通过结合语言理解和目标关联实现基于文本查询的物体跟踪。&lt;h4&gt;背景&lt;/h4&gt;基于文本查询的多目标跟踪任务具有挑战性，因为它需要将语言理解与帧间的目标关联联系起来。现有的方法通常需要监督训练，且在处理开放式查询时可能存在泛化问题。&lt;h4&gt;目的&lt;/h4&gt;提出ReferGPT框架，以实现无需监督训练即可进行多目标跟踪。&lt;h4&gt;方法&lt;/h4&gt;ReferGPT使用一个多模态大型语言模型（MLLM）并赋予其空间知识，使其能够生成3D感知的描述性文本。此外，还提出了一种鲁棒的查询匹配策略，利用基于CLIP的语义编码和模糊匹配将MLLM生成的文本与用户查询关联起来。&lt;h4&gt;主要发现&lt;/h4&gt;在Refer-KITTI、Refer-KITTIv2和Refer-KITTI+数据集上的实验表明，ReferGPT在多目标跟踪任务中取得了与训练方法相当的性能，展示了其在自动驾驶场景中的鲁棒性和零样本能力。&lt;h4&gt;结论&lt;/h4&gt;ReferGPT是一种有效的零样本多目标跟踪框架，适用于无需监督训练的情境，并具有在自动驾驶等领域的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a novel zero-shot multi-object tracking framework called ReferGPT, which combines language understanding with object association to achieve object tracking based on textual queries.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tracking multiple objects based on textual queries is a challenging task thatrequires linking language understanding with object association across frames.Previous works typically train the whole process end-to-end or integrate anadditional referring text module into a multi-object tracker, but they bothrequire supervised training and potentially struggle with generalization toopen-set queries. In this work, we introduce ReferGPT, a novel zero-shotreferring multi-object tracking framework. We provide a multi-modal largelanguage model (MLLM) with spatial knowledge enabling it to generate 3D-awarecaptions. This enhances its descriptive capabilities and supports a moreflexible referring vocabulary without training. We also propose a robustquery-matching strategy, leveraging CLIP-based semantic encoding and fuzzymatching to associate MLLM generated captions with user queries. Extensiveexperiments on Refer-KITTI, Refer-KITTIv2 and Refer-KITTI+ demonstrate thatReferGPT achieves competitive performance against trained methods, showcasingits robustness and zero-shot capabilities in autonomous driving. The codes areavailable on https://github.com/Tzoulio/ReferGPT</description>
      <author>example@mail.com (Tzoulio Chamiti, Leandro Di Bella, Adrian Munteanu, Nikos Deligiannis)</author>
      <guid isPermaLink="false">2504.09195v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Large Self-Supervised Time-Series Models for Transferable Diagnosis in Cross-Aircraft Type Bleed Air System</title>
      <link>http://arxiv.org/abs/2504.09090v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个基于自监督学习的Bleed Air System (BAS)诊断模型，该模型可以将成熟机型（如A320、A330）的诊断知识迁移到新机型（如C919），以提高系统可靠性。&lt;h4&gt;背景&lt;/h4&gt;Bleed Air System对于维持飞行安全和运营效率至关重要，但其故障（如过压、低压和过热）会带来严重风险。当前诊断方法在应用于不同机型时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文旨在开发一种能够将诊断知识从成熟机型迁移到新机型的自监督学习模型。&lt;h4&gt;方法&lt;/h4&gt;本文提出的模型利用自监督预训练学习通用特征表示，无需标注数据，从而在数据稀缺的场景下有效。此外，还引入了跨模型数据集和适用于真实飞行数据的联合基准和异常检测损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够提高异常检测和基准信号预测的准确性，从而提高系统可靠性，并确保在新机型的早期运营阶段提供稳健的支持。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为大型飞行信号模型的研究奠定了基础，并提供了在模型容量和迁移性之间关系方面的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Bleed Air System（BAS）对于维持飞行安全与运营效率至关重要，支持诸如客舱增压、空调和发动机防冰等功能。然而，BAS的故障，包括过压、低压和过热，会带来诸如客舱失压、设备故障或发动机损坏等重大风险。当前的诊断方法在应用于不同飞机类型时面临显著限制，尤其是在缺乏足够运营数据的较新型号上。为了应对这些挑战，本文提出了一种基于自监督学习的基座模型，该模型使得将诊断知识从成熟机型（例如A320、A330）迁移到新机型（例如C919）成为可能。利用自监督预训练，该模型从飞行信号中学习通用的特征表示，而无需标注数据，这使得它在数据稀缺的场景下非常有效。该模型提高了异常检测和基准信号预测，从而增强了系统可靠性。本文引入了跨模型数据集，这是一个用于BAS诊断的自监督学习框架，以及一个针对真实飞行数据的创新性联合基准和异常检测损失函数。这些创新促进了诊断知识在飞机类型间的有效迁移，确保了对新机型早期运营阶段的稳健支持。此外，本文还探讨了模型容量与迁移性之间的关系，为未来关于大规模飞行信号模型的研究提供了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bleed Air System (BAS) is critical for maintaining flight safety andoperational efficiency, supporting functions such as cabin pressurization, airconditioning, and engine anti-icing. However, BAS malfunctions, includingoverpressure, low pressure, and overheating, pose significant risks such ascabin depressurization, equipment failure, or engine damage. Current diagnosticapproaches face notable limitations when applied across different aircrafttypes, particularly for newer models that lack sufficient operational data. Toaddress these challenges, this paper presents a self-supervised learning-basedfoundation model that enables the transfer of diagnostic knowledge from matureaircraft (e.g., A320, A330) to newer ones (e.g., C919). Leveragingself-supervised pretraining, the model learns universal feature representationsfrom flight signals without requiring labeled data, making it effective indata-scarce scenarios. This model enhances both anomaly detection and baselinesignal prediction, thereby improving system reliability. The paper introduces across-model dataset, a self-supervised learning framework for BAS diagnostics,and a novel Joint Baseline and Anomaly Detection Loss Function tailored toreal-world flight data. These innovations facilitate efficient transfer ofdiagnostic knowledge across aircraft types, ensuring robust support for earlyoperational stages of new models. Additionally, the paper explores therelationship between model capacity and transferability, providing a foundationfor future research on large-scale flight signal models.</description>
      <author>example@mail.com (Yilin Wang, Peixuan Lei, Xuyang Wang, Liangliang Jiang, Liming Xuan, Wei Cheng, Honghua Zhao, Yuanxiang Li)</author>
      <guid isPermaLink="false">2504.09090v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal 3D Genome Pre-training</title>
      <link>http://arxiv.org/abs/2504.09060v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MIX-HIC是第一个多模态3D基因组基础模型，它整合了3D基因组结构和表观基因组轨迹，并设计了跨模态交互和映射块，用于准确融合异质语义，显著提高了3D基因组知识聚合的准确性。&lt;h4&gt;背景&lt;/h4&gt;深度学习技术在计算生物学中的3D基因组分析任务中取得了显著进展，但对3D基因组知识的整体理解仍处于探索阶段。&lt;h4&gt;目的&lt;/h4&gt;提出MIX-HIC模型，以实现对3D基因组知识的统一和全面语义理解。&lt;h4&gt;方法&lt;/h4&gt;设计了跨模态交互和映射块，并引入了包含超过100万对Hi-C接触图和表观基因组轨迹样本的大规模数据集，用于高质量预训练。&lt;h4&gt;主要发现&lt;/h4&gt;MIX-HIC在多个下游任务中显著超越了现有最先进的方法，为3D基因组研究提供了宝贵资源。&lt;h4&gt;结论&lt;/h4&gt;MIX-HIC模型为3D基因组研究提供了新的方法和工具，有望推动该领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning techniques have driven significant progress in variousanalytical tasks within 3D genomics in computational biology. However, aholistic understanding of 3D genomics knowledge remains underexplored. Here, wepropose MIX-HIC, the first multimodal foundation model of 3D genome thatintegrates both 3D genome structure and epigenomic tracks, which obtainsunified and comprehensive semantics. For accurate heterogeneous semanticfusion, we design the cross-modal interaction and mapping blocks for robustunified representation, yielding the accurate aggregation of 3D genomeknowledge. Besides, we introduce the first large-scale dataset comprising over1 million pairwise samples of Hi-C contact maps and epigenomic tracks forhigh-quality pre-training, enabling the exploration of functional implicationsin 3D genomics. Extensive experiments show that MIX-HIC can significantlysurpass existing state-of-the-art methods in diverse downstream tasks. Thiswork provides a valuable resource for advancing 3D genomics research.</description>
      <author>example@mail.com (Minghao Yang, Pengteng Li, Yan Liang, Qianyi Cai, Zhihang Zheng, Shichen Zhang, Pengfei Zhang, Zhi-An Huang, Hui Xiong)</author>
      <guid isPermaLink="false">2504.09060v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Parameter-Free Fine-tuning via Redundancy Elimination for Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2504.08915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视觉基础模型（VFMs）中的冗余特征，并提出了一种参数免费的微调方法来解决这一问题。&lt;h4&gt;背景&lt;/h4&gt;VFMs是各种视觉任务的基础，但它们通常包含大量的特征冗余，这可能限制了它们对新任务的适应性。&lt;h4&gt;目的&lt;/h4&gt;旨在提高VFMs对新任务的适应性和微调效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于模型输出差异的通道选择算法，以识别冗余和有效的通道，并通过选择性替换冗余通道来增强预训练特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在域内和域外数据集上均表现出高效性和有效性，并且可以与现有的微调策略（如LoRA、Adapter）无缝集成，进一步提升了已微调模型的表现。&lt;h4&gt;结论&lt;/h4&gt;该方法显著降低了计算和GPU内存开销，为模型微调提供了一种新的视角。&lt;h4&gt;翻译&lt;/h4&gt;Vision foundation models (VFMs) are large pre-trained models that form the backbone of various vision tasks. Fine-tuning VFMs can further unlock their potential for downstream tasks or scenarios. However, VFMs often contain significant feature redundancy, which may limit their adaptability to new tasks. In this paper, we investigate the redundancies in the segment anything model (SAM) and then propose a parameter-free fine-tuning method to address this issue. Unlike traditional fine-tuning methods that adjust parameters, our method emphasizes selecting, reusing, and enhancing pre-trained features, offering a new perspective on model fine-tuning. Specifically, we introduce a channel selection algorithm based on the model's output difference to identify redundant and effective channels. By selectively replacing the redundant channels with more effective ones, we filter out less useful features and reuse the more relevant features to downstream tasks, thereby enhancing the task-specific feature representation. Experiments on both out-of-domain and in-domain datasets demonstrate the efficiency and effectiveness of our method. Notably, our approach can seamlessly integrate with existing fine-tuning strategies (e.g., LoRA, Adapter), further boosting the performance of already fine-tuned models. Moreover, since our channel selection involves only model inference, our method significantly reduces computational and GPU memory overhead.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision foundation models (VFMs) are large pre-trained models that form thebackbone of various vision tasks. Fine-tuning VFMs can further unlock theirpotential for downstream tasks or scenarios. However, VFMs often containsignificant feature redundancy, which may limit their adaptability to newtasks. In this paper, we investigate the redundancies in the segment anythingmodel (SAM) and then propose a parameter-free fine-tuning method to addressthis issue. Unlike traditional fine-tuning methods that adjust parameters, ourmethod emphasizes selecting, reusing, and enhancing pre-trained features,offering a new perspective on model fine-tuning. Specifically, we introduce achannel selection algorithm based on the model's output difference to identifyredundant and effective channels. By selectively replacing the redundantchannels with more effective ones, we filter out less useful features and reusethe more relevant features to downstream tasks, thereby enhancing thetask-specific feature representation. Experiments on both out-of-domain andin-domain datasets demonstrate the efficiency and effectiveness of our method.Notably, our approach can seamlessly integrate with existing fine-tuningstrategies (e.g., LoRA, Adapter), further boosting the performance of alreadyfine-tuned models. Moreover, since our channel selection involves only modelinference, our method significantly reduces computational and GPU memoryoverhead.</description>
      <author>example@mail.com (Jiahuan Long, Tingsong Jiang, Wen Yao, Yizhe Xiong, Zhengqin Xu, Shuai Jia, Chao Ma)</author>
      <guid isPermaLink="false">2504.08915v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>InfoGain Wavelets: Furthering the Design of Diffusion Wavelets for Graph-Structured Data</title>
      <link>http://arxiv.org/abs/2504.08802v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work was accepted to be presented at the Graph Signal Processing  Workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于信息理论的新方法来选择扩散尺度，以从不同分辨率提取图信号信息。&lt;h4&gt;背景&lt;/h4&gt;扩散小波通过使用不同幂次的图扩散算子（称为扩散尺度）从图信号中提取信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种无监督的方法来选择扩散尺度。&lt;h4&gt;方法&lt;/h4&gt;该方法基于信息理论，并展示了如何将其整合到基于小波的图神经网络中。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够通过图分类实验整合到波let-based GNNs中。&lt;h4&gt;结论&lt;/h4&gt;该研究为图信号处理提供了一种新的无监督选择扩散尺度的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：扩散小波通过利用不同幂次的图扩散算子（称为扩散尺度）从不同分辨率提取图信号信息。传统上，扩散尺度被选为二进制整数（2^j）。在这里，我们提出了一种基于信息理论的新颖无监督方法来选择扩散尺度。然后，我们展示了该方法可以通过图分类实验整合到基于小波的图神经网络中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion wavelets extract information from graph signals at different scalesof resolution by utilizing graph diffusion operators raised to various powers,known as diffusion scales. Traditionally, the diffusion scales are chosen to bedyadic integers, $\mathbf{2^j}$. Here, we propose a novel, unsupervised methodfor selecting the diffusion scales based on ideas from information theory. Wethen show that our method can be incorporated into wavelet-based GNNs via graphclassification experiments.</description>
      <author>example@mail.com (David R. Johnson, Smita Krishnaswamy, Michael Perlmutter)</author>
      <guid isPermaLink="false">2504.08802v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Robust SAM: On the Adversarial Robustness of Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2504.08906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by AAAI2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对Segment Anything Model (SAM)的对抗鲁棒性框架，旨在评估和增强SAM的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;SAM是一个广泛应用于图像分割、检测和跟踪等领域的视觉基础模型。然而，关于SAM鲁棒性的研究还处于早期阶段，现有攻击方法往往忽略了提示在评估SAM鲁棒性中的作用，且对防御方法的探索不足。&lt;h4&gt;目的&lt;/h4&gt;为了填补这些空白，本文提出了一个对抗鲁棒性框架，旨在评估和增强SAM的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;本文引入了一种跨提示攻击方法来提高攻击在不同提示类型之间的可迁移性。此外，还提出了一种参数适应策略来防御SAM的各种对抗攻击。为了平衡鲁棒性和准确性，使用奇异值分解（SVD）来约束可训练参数的空间，其中只有奇异值是可调整的。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的跨提示攻击方法在SAM和SAM 2上的攻击成功率优于先前的方法。通过仅调整512个参数，我们实现了至少15%的平均交并率（mIoU）的提升，对抗各种对抗攻击。与先前的方法相比，该方法在增强SAM鲁棒性的同时，最大限度地保持了其原始性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法有效地提高了SAM的鲁棒性，同时保持了其性能，为SAM在实际应用中的部署提供了保障。&lt;h4&gt;翻译&lt;/h4&gt;The Segment Anything Model (SAM) is a widely used vision foundation model with diverse applications, including image segmentation, detection, and tracking. Given SAM's wide applications, understanding its robustness against adversarial attacks is crucial for real-world deployment. However, research on SAM's robustness is still in its early stages. Existing attacks often overlook the role of prompts in evaluating SAM's robustness, and there has been insufficient exploration of defense methods to balance the robustness and accuracy. To address these gaps, this paper proposes an adversarial robustness framework designed to evaluate and enhance the robustness of SAM. Specifically, we introduce a cross-prompt attack method to enhance the attack transferability across different prompt types. Besides attacking, we propose a few-parameter adaptation strategy to defend SAM against various adversarial attacks. To balance robustness and accuracy, we use the singular value decomposition (SVD) to constrain the space of trainable parameters, where only singular values are adaptable. Experiments demonstrate that our cross-prompt attack method outperforms previous approaches in terms of attack success rate on both SAM and SAM 2. By adapting only 512 parameters, we achieve at least a 15% improvement in mean intersection over union (mIoU) against various adversarial attacks. Compared to previous defense methods, our approach enhances the robustness of SAM while maximally maintaining its original performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Segment Anything Model (SAM) is a widely used vision foundation modelwith diverse applications, including image segmentation, detection, andtracking. Given SAM's wide applications, understanding its robustness againstadversarial attacks is crucial for real-world deployment. However, research onSAM's robustness is still in its early stages. Existing attacks often overlookthe role of prompts in evaluating SAM's robustness, and there has beeninsufficient exploration of defense methods to balance the robustness andaccuracy. To address these gaps, this paper proposes an adversarial robustnessframework designed to evaluate and enhance the robustness of SAM. Specifically,we introduce a cross-prompt attack method to enhance the attack transferabilityacross different prompt types. Besides attacking, we propose a few-parameteradaptation strategy to defend SAM against various adversarial attacks. Tobalance robustness and accuracy, we use the singular value decomposition (SVD)to constrain the space of trainable parameters, where only singular values areadaptable. Experiments demonstrate that our cross-prompt attack methodoutperforms previous approaches in terms of attack success rate on both SAM andSAM 2. By adapting only 512 parameters, we achieve at least a 15\% improvementin mean intersection over union (mIoU) against various adversarial attacks.Compared to previous defense methods, our approach enhances the robustness ofSAM while maximally maintaining its original performance.</description>
      <author>example@mail.com (Jiahuan Long, Zhengqin Xu, Tingsong Jiang, Wen Yao, Shuai Jia, Chao Ma, Xiaoqian Chen)</author>
      <guid isPermaLink="false">2504.08906v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Position: Beyond Euclidean -- Foundation Models Should Embrace Non-Euclidean Geometries</title>
      <link>http://arxiv.org/abs/2504.08896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了在大型语言模型和基础模型时代，欧几里得空间在机器学习架构中的应用及其局限性，并提出了非欧几里得几何在模型中的必要性。&lt;h4&gt;背景&lt;/h4&gt;在当前机器学习领域，欧几里得空间是主流的几何设置。然而，现实世界数据往往具有非欧几里得结构，如多向关系、层次结构、对称性和非各向同性尺度。&lt;h4&gt;目的&lt;/h4&gt;提出超越欧几里得几何是必要的，以维持下一代基础模型的扩展规律。&lt;h4&gt;方法&lt;/h4&gt;通过理论研究和实证调查来支持这一观点，并概述了将非欧几里得几何整合到基础模型中的路线图，包括通过微调、从头训练和混合方法构建几何基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;欧几里得空间难以有效捕捉现实世界数据中的非欧几里得结构，而采用非欧几里得几何可以更有效地利用这些结构。&lt;h4&gt;结论&lt;/h4&gt;非欧几里得几何对于下一代基础模型的发展至关重要，任务感知适应性可以进一步提高效率和表达性。&lt;h4&gt;翻译&lt;/h4&gt;In the era of foundation models and Large Language Models (LLMs), Euclideanspace has been the de facto geometric setting for machine learningarchitectures. However, recent literature has demonstrated that this choicecomes with fundamental limitations. At a large scale, real-world data oftenexhibit inherently non-Euclidean structures, such as multi-way relationships,hierarchies, symmetries, and non-isotropic scaling, in a variety of domains,such as languages, vision, and the natural sciences. It is challenging toeffectively capture these structures within the constraints of Euclideanspaces. This position paper argues that moving beyond Euclidean geometry is notmerely an optional enhancement but a necessity to maintain the scaling law forthe next-generation of foundation models. By adopting these geometries,foundation models could more efficiently leverage the aforementionedstructures. Task-aware adaptability that dynamically reconfigures embeddings tomatch the geometry of downstream applications could further enhance efficiencyand expressivity. Our position is supported by a series of theoretical andempirical investigations of prevalent foundation models.Finally, we outline aroadmap for integrating non-Euclidean geometries into foundation models,including strategies for building geometric foundation models via fine-tuning,training from scratch, and hybrid approaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of foundation models and Large Language Models (LLMs), Euclideanspace has been the de facto geometric setting for machine learningarchitectures. However, recent literature has demonstrated that this choicecomes with fundamental limitations. At a large scale, real-world data oftenexhibit inherently non-Euclidean structures, such as multi-way relationships,hierarchies, symmetries, and non-isotropic scaling, in a variety of domains,such as languages, vision, and the natural sciences. It is challenging toeffectively capture these structures within the constraints of Euclideanspaces. This position paper argues that moving beyond Euclidean geometry is notmerely an optional enhancement but a necessity to maintain the scaling law forthe next-generation of foundation models. By adopting these geometries,foundation models could more efficiently leverage the aforementionedstructures. Task-aware adaptability that dynamically reconfigures embeddings tomatch the geometry of downstream applications could further enhance efficiencyand expressivity. Our position is supported by a series of theoretical andempirical investigations of prevalent foundation models.Finally, we outline aroadmap for integrating non-Euclidean geometries into foundation models,including strategies for building geometric foundation models via fine-tuning,training from scratch, and hybrid approaches.</description>
      <author>example@mail.com (Neil He, Jiahong Liu, Buze Zhang, Ngoc Bui, Ali Maatouk, Menglin Yang, Irwin King, Melanie Weber, Rex Ying)</author>
      <guid isPermaLink="false">2504.08896v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Neural Encoding and Decoding at Scale</title>
      <link>http://arxiv.org/abs/2504.08201v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为NEDS的多模态、多任务模型，旨在同时进行大规模的神经编码和解码，以更好地理解神经活动和行为之间的关系。&lt;h4&gt;背景&lt;/h4&gt;现有的大规模模型要么从行为预测神经活动（编码），要么从神经活动预测行为（解码），限制了它们捕捉神经活动和行为之间双向关系的能力。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一差距，研究引入了NEDS模型，以实现神经编码和解码的同步进行。&lt;h4&gt;方法&lt;/h4&gt;NEDS模型的核心是一个新颖的多任务掩码策略，该策略在神经、行为、同一模态和跨模态掩码之间交替。该方法在包含83只动物进行相同视觉决策任务的重复站点数据集上进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;与其它大规模模型相比，NEDS在预训练于多动物数据并在新动物上微调后，在编码和解码方面均达到了最先进的性能。此外，NEDS学习到的嵌入表现出涌现性质，即使没有明确的训练，它们也能高度预测每条记录中的大脑区域。&lt;h4&gt;结论&lt;/h4&gt;这一方法朝着构建一个能够无缝翻译神经活动和行为的脑部基础模型迈出了重要一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent work has demonstrated that large-scale, multi-animal models arepowerful tools for characterizing the relationship between neural activity andbehavior. Current large-scale approaches, however, focus exclusively on eitherpredicting neural activity from behavior (encoding) or predicting behavior fromneural activity (decoding), limiting their ability to capture the bidirectionalrelationship between neural activity and behavior. To bridge this gap, weintroduce a multimodal, multi-task model that enables simultaneous NeuralEncoding and Decoding at Scale (NEDS). Central to our approach is a novelmulti-task-masking strategy, which alternates between neural, behavioral,within-modality, and cross-modality masking. We pretrain our method on theInternational Brain Laboratory (IBL) repeated site dataset, which includesrecordings from 83 animals performing the same visual decision-making task. Incomparison to other large-scale models, we demonstrate that NEDS achievesstate-of-the-art performance for both encoding and decoding when pretrained onmulti-animal data and then fine-tuned on new animals. Surprisingly, NEDS'slearned embeddings exhibit emergent properties: even without explicit training,they are highly predictive of the brain regions in each recording. Altogether,our approach is a step towards a foundation model of the brain that enablesseamless translation between neural activity and behavior.</description>
      <author>example@mail.com (Yizi Zhang, Yanchen Wang, Mehdi Azabou, Alexandre Andre, Zixuan Wang, Hanrui Lyu, The International Brain Laboratory, Eva Dyer, Liam Paninski, Cole Hurwitz)</author>
      <guid isPermaLink="false">2504.08201v2</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Geometric Meta-Learning via Coupled Ricci Flow: Unifying Knowledge Representation and Quantum Entanglement</title>
      <link>http://arxiv.org/abs/2503.19867v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, submitted to IEEE PAMI&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过三项基本创新建立了将几何流与深度学习相结合的统一框架。&lt;h4&gt;背景&lt;/h4&gt;研究背景为几何流与深度学习的结合，旨在提升几何深度学习的能力。&lt;h4&gt;目的&lt;/h4&gt;目的是通过结合几何流与深度学习，提高学习效率和模型性能。&lt;h4&gt;方法&lt;/h4&gt;方法包括：1. 提出一种热力学耦合的Ricci流，动态适应参数空间几何与损失景观拓扑；2. 通过曲率爆破分析推导出显式相变阈值和临界学习率；3. 建立神经网络与共形场理论之间的AdS/CFT型全息对偶。&lt;h4&gt;主要发现&lt;/h4&gt;主要发现包括：1. 通过热力学耦合的Ricci流保留了等距知识嵌入；2. 通过曲率爆破分析实现了自动奇异点解析；3. 提供了纠缠熵界限，有助于正则化设计；4. 实验表明在保持复杂度的同时，加速了收敛速度并简化了拓扑结构。&lt;h4&gt;结论&lt;/h4&gt;理论上证明了通过结合Perelman熵与Wasserstein梯度流的新的Lyapunov函数，实现了指数稳定性，从根本上推进了几何深度学习。&lt;h4&gt;翻译&lt;/h4&gt;This paper establishes a unified framework integrating geometric flows with deep learning through three fundamental innovations. First, we propose a thermodynamically coupled Ricci flow that dynamically adapts parameter space geometry to loss landscape topology, formally proved to preserve isometric knowledge embedding (Theorem~\ref{thm:isometric}). Second, we derive explicit phase transition thresholds and critical learning rates (Theorem~\ref{thm:critical}) through curvature blowup analysis, enabling automated singularity resolution via geometric surgery (Lemma~\ref{lem:surgery}). Third, we establish an AdS/CFT-type holographic duality (Theorem~\ref{thm:ads}) between neural networks and conformal field theories, providing entanglement entropy bounds for regularization design. Experiments demonstrate 2.1\times convergence acceleration and 63% topological simplification while maintaining \(\mathcal{O}(N\log N)\) complexity, outperforming Riemannian baselines by 15.2% in few-shot accuracy. Theoretically, we prove exponential stability (Theorem~\ref{thm:converge}) through a new Lyapunov function combining Perelman entropy with Wasserstein gradient flows, fundamentally advancing geometric deep learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper establishes a unified framework integrating geometric flows withdeep learning through three fundamental innovations. First, we propose athermodynamically coupled Ricci flow that dynamically adapts parameter spacegeometry to loss landscape topology, formally proved to preserve isometricknowledge embedding (Theorem~\ref{thm:isometric}). Second, we derive explicitphase transition thresholds and critical learning rates(Theorem~\ref{thm:critical}) through curvature blowup analysis, enablingautomated singularity resolution via geometric surgery(Lemma~\ref{lem:surgery}). Third, we establish an AdS/CFT-type holographicduality (Theorem~\ref{thm:ads}) between neural networks and conformal fieldtheories, providing entanglement entropy bounds for regularization design.Experiments demonstrate 2.1$\times$ convergence acceleration and 63\%topological simplification while maintaining $\mathcal{O}(N\log N)$ complexity,outperforming Riemannian baselines by 15.2\% in few-shot accuracy.Theoretically, we prove exponential stability (Theorem~\ref{thm:converge})through a new Lyapunov function combining Perelman entropy with Wassersteingradient flows, fundamentally advancing geometric deep learning.</description>
      <author>example@mail.com (Ming Lei, Christophe Baehr)</author>
      <guid isPermaLink="false">2503.19867v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
  <item>
      <title>Variational Quantum Self-Organizing Map</title>
      <link>http://arxiv.org/abs/2504.03584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于核化Kohonen自组织图的量子神经网络架构，用于无监督学习经典和量子数据。&lt;h4&gt;背景&lt;/h4&gt;基于Kohonen自组织图，通过核化版本来处理量子数据。&lt;h4&gt;目的&lt;/h4&gt;开发一种算法，以无监督学习的方式从经典和量子数据中提取信息。&lt;h4&gt;方法&lt;/h4&gt;使用量子计算机计算量子状态之间的保真度，以识别自组织图输出神经元低维网格中的最佳匹配单元。通过调整输出神经元的变分参数来估计保真度。算法需要O(N)次电路评估，而不是量子核估计中的O(N^2)次。&lt;h4&gt;主要发现&lt;/h4&gt;算法能够从高维希尔伯特空间到低维网格点学习映射，同时保留希尔伯特空间的基本拓扑结构。在Fisher的Iris数据集上展示了算法的有效性，并在Schwinger模型上展示了量子数据的有效性。&lt;h4&gt;结论&lt;/h4&gt;该算法在无监督学习经典和量子数据方面表现出良好的效果，并且能够区分不同的数据类别。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新的量子神经网络架构，用于基于核化Kohonen自组织图的无监督学习经典和量子数据。该算法的核心思想是用量子态之间的保真度代替欧几里得距离度量，以识别自组织图输出神经元低维网格中的最佳匹配单元。通过计算量子计算机上的过渡概率来估计未知量子状态与包含变分参数的量子状态之间的保真度。这些估计的保真度随后用于调整输出神经元的变分参数。与量子核估计中需要的O(N^2)次电路评估相比，我们的算法对于N个数据样本只需要O(N)次电路评估。类似于自组织图的传统版本，我们的算法学习从高维希尔伯特空间到低维网格点的映射，同时保留希尔伯特空间的基本拓扑结构。我们通过构建一个二维可视化来展示算法的有效性，该可视化能够准确区分Fisher的Iris数据集中的三种不同的花卉种类。此外，我们还通过创建一个二维映射来展示我们在量子数据上的方法的有效性，该映射保留了Schwinger模型状态空间的拓扑结构，并在θ=π时区分模型的两个不同的相。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel quantum neural network architecture for unsupervisedlearning of classical and quantum data based on the kernelized version ofKohonen's self-organizing map. The central idea behind our algorithm is toreplace the Euclidean distance metric with the fidelity between quantum statesto identify the best matching unit from the low-dimensional grid of outputneurons in the self-organizing map. The fidelities between the unknown quantumstate and the quantum states containing the variational parameters areestimated by computing the transition probability on a quantum computer. Theestimated fidelities are in turn used to adjust the variational parameters ofthe output neurons. Unlike $\mathcal{O}(N^{2})$ circuit evaluations needed inquantum kernel estimation, our algorithm requires $\mathcal{O}(N)$ circuitevaluations for $N$ data samples. Analogous to the classical version of theself-organizing map, our algorithm learns a mapping from a high-dimensionalHilbert space to a low-dimensional grid of lattice points while preserving theunderlying topology of the Hilbert space. We showcase the effectiveness of ouralgorithm by constructing a two-dimensional visualization that accuratelydifferentiates between the three distinct species of flowers in Fisher's Irisdataset. In addition, we demonstrate the efficacy of our approach on quantumdata by creating a two-dimensional map that preserves the topology of the statespace in the Schwinger model and distinguishes between the two separate phasesof the model at $\theta = \pi$.</description>
      <author>example@mail.com (Amol Deshmukh)</author>
      <guid isPermaLink="false">2504.03584v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>ModernBERT or DeBERTaV3? Examining Architecture and Data Influence on Transformer Encoder Models Performance</title>
      <link>http://arxiv.org/abs/2504.08716v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文比较了DeBERTaV3和ModernBERT等预训练transformer-encoder模型，探讨了模型架构改进对性能的影响。&lt;h4&gt;背景&lt;/h4&gt;ModernBERT在多个基准测试中表现出比DeBERTaV3更好的性能，但其性能提升是否由于架构改进或训练数据差异尚不明确。&lt;h4&gt;目的&lt;/h4&gt;通过在相同数据集上预训练ModernBERT，与DeBERTaV3的French模型CamemBERTaV2进行比较，以隔离模型设计的影响。&lt;h4&gt;方法&lt;/h4&gt;进行了一个受控研究，使用相同的数据集预训练ModernBERT，并比较了模型在样本效率和基准性能方面的表现。&lt;h4&gt;主要发现&lt;/h4&gt;尽管ModernBERT在训练和推理速度上具有优势，但DeBERTaV3在样本效率和整体基准性能上仍然更优。高质量预训练数据加速了收敛，但并未显著提高最终性能，暗示了基准测试可能已经饱和。&lt;h4&gt;结论&lt;/h4&gt;在评估transformer模型时，将预训练数据与架构创新分离是很重要的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pretrained transformer-encoder models like DeBERTaV3 and ModernBERT introducearchitectural advancements aimed at improving efficiency and performance.Although the authors of ModernBERT report improved performance over DeBERTaV3on several benchmarks, the lack of disclosed training data and the absence ofcomparisons using a shared dataset make it difficult to determine whether thesegains are due to architectural improvements or differences in training data. Inthis work, we conduct a controlled study by pretraining ModernBERT on the samedataset as CamemBERTaV2, a DeBERTaV3 French model, isolating the effect ofmodel design. Our results show that the previous model generation remainssuperior in sample efficiency and overall benchmark performance, withModernBERT's primary advantage being faster training and inference speed.However, the new proposed model still provides meaningful architecturalimprovements compared to earlier models such as BERT and RoBERTa. Additionally,we observe that high-quality pre-training data accelerates convergence but doesnot significantly improve final performance, suggesting potential benchmarksaturation. These findings show the importance of disentangling pretrainingdata from architectural innovations when evaluating transformer models.</description>
      <author>example@mail.com (Wissam Antoun, Benoît Sagot, Djamé Seddah)</author>
      <guid isPermaLink="false">2504.08716v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Hypergraph Vision Transformers: Images are More than Nodes, More than Edges</title>
      <link>http://arxiv.org/abs/2504.08710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Hypergraph Vision Transformer (HgVT)的新方法，用于解决计算机视觉任务中的可扩展性、适应性和计算效率问题。&lt;h4&gt;背景&lt;/h4&gt;尽管Vision Transformers (ViTs)在计算机视觉任务中表现出良好的可扩展性，但在适应性和计算效率方面仍存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出HgVT以解决ViTs在处理高阶关系时的计算瓶颈，同时保持高效计算。&lt;h4&gt;方法&lt;/h4&gt;HgVT通过将层次双分图结构融入ViTs框架，利用人口和多样性正则化动态构建超图，无需聚类，并采用专家边缘池化来增强语义提取和图像检索。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，HgVT在图像分类和检索任务上表现出优异的性能，是一种高效的基于语义的视觉任务框架。&lt;h4&gt;结论&lt;/h4&gt;HgVT为基于语义的视觉任务提供了一种高效且有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in computer vision have highlighted the scalability ofVision Transformers (ViTs) across various tasks, yet challenges remain inbalancing adaptability, computational efficiency, and the ability to modelhigher-order relationships. Vision Graph Neural Networks (ViGs) offer analternative by leveraging graph-based methodologies but are hindered by thecomputational bottlenecks of clustering algorithms used for edge generation. Toaddress these issues, we propose the Hypergraph Vision Transformer (HgVT),which incorporates a hierarchical bipartite hypergraph structure into thevision transformer framework to capture higher-order semantic relationshipswhile maintaining computational efficiency. HgVT leverages population anddiversity regularization for dynamic hypergraph construction withoutclustering, and expert edge pooling to enhance semantic extraction andfacilitate graph-based image retrieval. Empirical results demonstrate that HgVTachieves strong performance on image classification and retrieval, positioningit as an efficient framework for semantic-based vision tasks.</description>
      <author>example@mail.com (Joshua Fixelle)</author>
      <guid isPermaLink="false">2504.08710v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>ProtoECGNet: Case-Based Interpretable Deep Learning for Multi-Label ECG Classification with Contrastive Learning</title>
      <link>http://arxiv.org/abs/2504.08713v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于原型学习的深度学习模型ProtoECGNet，用于可解释的多标签ECG分类。该模型通过结合不同的CNN架构和原型损失函数，提供了结构化的病例解释，并展现了其在临床决策支持中的应用潜力。&lt;h4&gt;背景&lt;/h4&gt;虽然深度学习在ECG分类中表现出色，但临床应用受到缺乏透明和忠实解释的阻碍。&lt;h4&gt;目的&lt;/h4&gt;开发一个原型基础的深度学习模型，以实现可解释的多标签ECG分类，并提供基于病例的解释。&lt;h4&gt;方法&lt;/h4&gt;ProtoECGNet采用结构化、多分支的架构，包括用于节律分类的1D CNN与全局原型、用于形态推理的2D CNN与时间局部原型、以及用于弥漫性异常的2D CNN与全局原型。每个分支使用原型损失函数进行训练，该损失函数结合了聚类、分离、多样性和对比损失。&lt;h4&gt;主要发现&lt;/h4&gt;ProtoECGNet在PTB-XL数据集上的所有71个诊断标签上展现了与现有黑盒模型相竞争的性能，同时提供了结构化的病例解释。通过结构化的医生评审，原型质量被评为具有代表性和清晰的。&lt;h4&gt;结论&lt;/h4&gt;原型学习可以有效地扩展到复杂的多标签时间序列分类，为临床决策支持提供了透明和值得信赖的深度学习模型的实用路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning-based electrocardiogram (ECG) classification has shownimpressive performance but clinical adoption has been slowed by the lack oftransparent and faithful explanations. Post hoc methods such as saliency mapsmay fail to reflect a model's true decision process. Prototype-based reasoningoffers a more transparent alternative by grounding decisions in similarity tolearned representations of real ECG segments, enabling faithful, case-basedexplanations. We introduce ProtoECGNet, a prototype-based deep learning modelfor interpretable, multi-label ECG classification. ProtoECGNet employs astructured, multi-branch architecture that reflects clinical interpretationworkflows: it integrates a 1D CNN with global prototypes for rhythmclassification, a 2D CNN with time-localized prototypes for morphology-basedreasoning, and a 2D CNN with global prototypes for diffuse abnormalities. Eachbranch is trained with a prototype loss designed for multi-label learning,combining clustering, separation, diversity, and a novel contrastive loss thatencourages appropriate separation between prototypes of unrelated classes whileallowing clustering for frequently co-occurring diagnoses. We evaluateProtoECGNet on all 71 diagnostic labels from the PTB-XL dataset, demonstratingcompetitive performance relative to state-of-the-art black-box models whileproviding structured, case-based explanations. To assess prototype quality, weconduct a structured clinician review of the final model's projectedprototypes, finding that they are rated as representative and clear.ProtoECGNet shows that prototype learning can be effectively scaled to complex,multi-label time-series classification, offering a practical path towardtransparent and trustworthy deep learning models for clinical decision support.</description>
      <author>example@mail.com (Sahil Sethi, David Chen, Thomas Statchen, Michael C. Burkhart, Nipun Bhandari, Bashar Ramadan, Brett Beaulieu-Jones)</author>
      <guid isPermaLink="false">2504.08713v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>FindAnything: Open-Vocabulary and Object-Centric Mapping for Robot Exploration in Any Environment</title>
      <link>http://arxiv.org/abs/2504.08603v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为FindAnything的开世界地图构建和探索框架，该框架将视觉-语言信息融入密集体素子图，以实现大规模未知环境的实时、开放词汇语义理解。&lt;h4&gt;背景&lt;/h4&gt;几何精确且语义丰富的地图表示对移动机器人的导航和任务规划至关重要，但实时、开放词汇语义理解仍是开放性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架，将视觉-语言信息结合到地图构建中，以实现更高级别的环境理解，并允许机器人探索任何环境。&lt;h4&gt;方法&lt;/h4&gt;使用视觉-语言特征，将环境表示为一系列体素占用子图，并通过eSAM生成的片段聚合像素级视觉-语言特征，最终将这些特征集成到以对象为中心的体素子图中。&lt;h4&gt;主要发现&lt;/h4&gt;FindAnything在Replica数据集上的闭集评估中达到了最先进的语义精度，并允许机器人根据自然语言查询选择的对象或感兴趣区域进行环境探索。&lt;h4&gt;结论&lt;/h4&gt;该系统是第一个在资源受限设备（如微型飞行器）上部署的系统，利用视觉-语言信息进行现实世界的机器人任务。&lt;h4&gt;翻译&lt;/h4&gt;摘要：几何精确且语义丰富的地图表示对于实现移动机器人的稳健和安全的导航与任务规划具有重要意义。然而，在大型未知环境中实现实时、开放词汇的语义理解仍然是一个未解决的问题。在本文中，我们提出了FindAnything，一个开放世界的地图构建和探索框架，该框架将视觉-语言信息融入密集的体素子图中。得益于视觉-语言特征的使用，FindAnything在高级别理解的同时，允许机器人无需任何外部真实姿态信息源的帮助即可探索任何环境。我们将环境表示为一系列体素占用子图，从而得到一种稳健且精确的地图表示，在SLAM系统修正其漂移时，基于姿态更新进行变形，使得子图之间具有局部一致性。从高效的SAM（eSAM）生成的片段中聚合像素级的视觉-语言特征，这些特征进而集成到以对象为中心的体素子图中，提供了一种将开放词汇查询映射到3D几何的方法，该方法在内存使用方面也是可扩展的。FindAnything的开放词汇地图表示在Replica数据集上的闭集评估中实现了最先进的语义精度。这种场景理解水平使得机器人能够根据通过自然语言查询选择的对象或感兴趣区域进行环境探索。我们的系统是第一个在其上部署的资源受限设备（如微型飞行器），利用视觉-语言信息进行现实世界的机器人任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometrically accurate and semantically expressive map representations haveproven invaluable to facilitate robust and safe mobile robot navigation andtask planning. Nevertheless, real-time, open-vocabulary semantic understandingof large-scale unknown environments is still an open problem. In this paper wepresent FindAnything, an open-world mapping and exploration framework thatincorporates vision-language information into dense volumetric submaps. Thanksto the use of vision-language features, FindAnything bridges the gap betweenpure geometric and open-vocabulary semantic information for a higher level ofunderstanding while allowing to explore any environment without the help of anyexternal source of ground-truth pose information. We represent the environmentas a series of volumetric occupancy submaps, resulting in a robust and accuratemap representation that deforms upon pose updates when the underlying SLAMsystem corrects its drift, allowing for a locally consistent representationbetween submaps. Pixel-wise vision-language features are aggregated fromefficient SAM (eSAM)-generated segments, which are in turn integrated intoobject-centric volumetric submaps, providing a mapping from open-vocabularyqueries to 3D geometry that is scalable also in terms of memory usage. Theopen-vocabulary map representation of FindAnything achieves state-of-the-artsemantic accuracy in closed-set evaluations on the Replica dataset. This levelof scene understanding allows a robot to explore environments based on objectsor areas of interest selected via natural language queries. Our system is thefirst of its kind to be deployed on resource-constrained devices, such as MAVs,leveraging vision-language information for real-world robotic tasks.</description>
      <author>example@mail.com (Sebastián Barbas Laina, Simon Boche, Sotiris Papatheodorou, Simon Schaefer, Jaehyung Jung, Stefan Leutenegger)</author>
      <guid isPermaLink="false">2504.08603v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>The Invisible EgoHand: 3D Hand Forecasting through EgoBody Pose Estimation</title>
      <link>http://arxiv.org/abs/2504.08654v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散的Transformer架构，用于从自视角视频中预测双手的3D轨迹和姿态，无论是否在视野内。&lt;h4&gt;背景&lt;/h4&gt;现有方法只关注预测手的位置，不考虑手的运动，并且仅在手在视野内时进行预测，忽略了即使手不在视野内，仍可以推断出手的大致位置。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，从自视角视频中预测双手的3D轨迹和姿态，无论手是否在视野内。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为EgoH4的基于扩散的Transformer架构，它接受观察序列和相机姿态作为输入，然后预测相机佩戴者的双手的未来3D运动和姿态。该方法利用全身姿态信息，并通过降噪和可见性预测器来提高预测的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;EgoH4在Ego-Exo4D数据集上进行了评估，该数据集结合了带有身体和手部注释的子集。在训练了156K个序列后，在34K个序列上进行了评估。EgoH4在预测手部轨迹和姿态方面分别将ADE和MPJPE的误差减少了3.4cm和5.1cm。&lt;h4&gt;结论&lt;/h4&gt;EgoH4通过提高预测准确性，为理解人类意图提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从自视角预测手部运动和姿态对于理解人类意图至关重要。然而，现有方法仅关注预测位置，不考虑手的运动，并且仅在视野内可见时进行预测。这种限制忽略了即使手不在视野内，仍可以推断出手的大致位置的事实。在本文中，我们提出了一种从自视角视频中预测双手的3D轨迹和姿态的方法，无论手是否在视野内。我们提出了一个用于自视角手部预测的基于扩散的Transformer架构，名为EgoH4，它接受观察序列和相机姿态作为输入，然后预测相机佩戴者的双手的未来3D运动和姿态。我们利用全身姿态信息，允许其他关节为手部运动提供约束。我们对手部和身体关节进行降噪，并使用手关节的可见性预测器和3D到2D重投影损失来最小化手部在视野内时的误差。我们在Ego-Exo4D数据集上评估了EgoH4，该数据集结合了带有身体和手部注释的子集。我们分别训练了156K个序列和评估了34K个序列。EgoH4在预测手部轨迹和姿态方面分别将ADE和MPJPE的误差减少了3.4cm和5.1cm。项目页面：https://masashi-hatano.github.io/EgoH4/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Forecasting hand motion and pose from an egocentric perspective is essentialfor understanding human intention. However, existing methods focus solely onpredicting positions without considering articulation, and only when the handsare visible in the field of view. This limitation overlooks the fact thatapproximate hand positions can still be inferred even when they are outside thecamera's view. In this paper, we propose a method to forecast the 3Dtrajectories and poses of both hands from an egocentric video, both in and outof the field of view. We propose a diffusion-based transformer architecture forEgocentric Hand Forecasting, EgoH4, which takes as input the observationsequence and camera poses, then predicts future 3D motion and poses for bothhands of the camera wearer. We leverage full-body pose information, allowingother joints to provide constraints on hand motion. We denoise the hand andbody joints along with a visibility predictor for hand joints and a 3D-to-2Dreprojection loss that minimizes the error when hands are in-view. We evaluateEgoH4 on the Ego-Exo4D dataset, combining subsets with body and handannotations. We train on 156K sequences and evaluate on 34K sequences,respectively. EgoH4 improves the performance by 3.4cm and 5.1cm over thebaseline in terms of ADE for hand trajectory forecasting and MPJPE for handpose forecasting. Project page: https://masashi-hatano.github.io/EgoH4/</description>
      <author>example@mail.com (Masashi Hatano, Zhifan Zhu, Hideo Saito, Dima Damen)</author>
      <guid isPermaLink="false">2504.08654v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Towards Efficient and Robust Moment Retrieval System: A Unified Framework for Multi-Granularity Models and Temporal Reranking</title>
      <link>http://arxiv.org/abs/2504.08384v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，旨在通过四个关键创新来提高交互式视频检索的效果，包括集成不同模型的搜索策略、存储优化技术、时间搜索机制和时间重排序方法。&lt;h4&gt;背景&lt;/h4&gt;长视频理解对交互检索系统来说是一个挑战，因为传统方法难以高效处理大量视频内容。&lt;h4&gt;目的&lt;/h4&gt;提升交互式视频检索的准确性、效率和使用者可理解性。&lt;h4&gt;方法&lt;/h4&gt;包括：(1) 集成粗粒度（CLIP）和细粒度（BEIT3）模型的集成搜索策略；(2) 通过TransNetV2选择代表性的关键帧并去除重复内容来优化存储；(3) 使用双重查询定位视频片段的起始和结束点；(4) 利用相邻帧的上下文稳定排名。&lt;h4&gt;主要发现&lt;/h4&gt;在已知项搜索和问答任务上的评估显示，该框架在检索精度、效率和用户可理解性方面都有显著提升。&lt;h4&gt;结论&lt;/h4&gt;该框架为现实世界的交互视频检索应用提供了一种稳健的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Long-form video understanding presents significant challenges for interactive retrieval systems, as conventional methods struggle to process extensive video content efficiently. Existing approaches often rely on single models, inefficient storage, unstable temporal search, and context-agnostic reranking, limiting their effectiveness. This paper presents a novel framework to enhance interactive video retrieval through four key innovations: (1) an ensemble search strategy that integrates coarse-grained (CLIP) and fine-grained (BEIT3) models to improve retrieval accuracy, (2) a storage optimization technique that reduces redundancy by selecting representative keyframes via TransNetV2 and deduplication, (3) a temporal search mechanism that localizes video segments using dual queries for start and end points, and (4) a temporal reranking approach that leverages neighboring frame context to stabilize rankings. Evaluated on known-item search and question-answering tasks, our framework demonstrates substantial improvements in retrieval precision, efficiency, and user interpretability, offering a robust solution for real-world interactive video retrieval applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-form video understanding presents significant challenges for interactiveretrieval systems, as conventional methods struggle to process extensive videocontent efficiently. Existing approaches often rely on single models,inefficient storage, unstable temporal search, and context-agnostic reranking,limiting their effectiveness. This paper presents a novel framework to enhanceinteractive video retrieval through four key innovations: (1) an ensemblesearch strategy that integrates coarse-grained (CLIP) and fine-grained (BEIT3)models to improve retrieval accuracy, (2) a storage optimization technique thatreduces redundancy by selecting representative keyframes via TransNetV2 anddeduplication, (3) a temporal search mechanism that localizes video segmentsusing dual queries for start and end points, and (4) a temporal rerankingapproach that leverages neighboring frame context to stabilize rankings.Evaluated on known-item search and question-answering tasks, our frameworkdemonstrates substantial improvements in retrieval precision, efficiency, anduser interpretability, offering a robust solution for real-world interactivevideo retrieval applications.</description>
      <author>example@mail.com (Huu-Loc Tran, Tinh-Anh Nguyen-Nhu, Huu-Phong Phan-Nguyen, Tien-Huy Nguyen, Nhat-Minh Nguyen-Dich, Anh Dao, Huy-Duc Do, Quan Nguyen, Hoang M. Le, Quang-Vinh Dinh)</author>
      <guid isPermaLink="false">2504.08384v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Enhanced Cooperative Perception Through Asynchronous Vehicle to Infrastructure Framework with Delay Mitigation for Connected and Automated Vehicles</title>
      <link>http://arxiv.org/abs/2504.08172v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 9 figures, This paper is under review of SAE Journal of  Connected and Automated Vehicles&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于单目交通摄像头的V2I框架，用于在道路交叉口检测3D对象，以提高自动驾驶车辆的感知范围和场景表示。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶车辆感知是关键组成部分，但传感器经常因为其他车辆、基础设施或周围物体造成盲区。虽然规划和控制算法的进步有助于自动驾驶车辆在低速和简单场景中应对盲区中的突发物体，但在高速和复杂交叉口仍存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提高自动驾驶车辆在复杂交叉口中的场景表示，为违规的敌对车辆提供足够的时间和距离进行反应。&lt;h4&gt;方法&lt;/h4&gt;提出了一种V2I框架，使用路边单元（RSU）的检测结果和车载系统进行异步晚期融合，以及一个时间延迟补偿模块来补偿RSU的处理和传输延迟。&lt;h4&gt;主要发现&lt;/h4&gt;该框架通过模拟和验证与Waymo行业报告中描述的场景相似的场景，结果表明该方法提高了场景表示和自动驾驶车辆的感知范围。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法改善了场景表示，为自动驾驶车辆提供了足够的时间和空间来应对违规的敌对车辆。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Perception is a key component of Automated vehicles (AVs). However, sensorsmounted to the AVs often encounter blind spots due to obstructions from othervehicles, infrastructure, or objects in the surrounding area. While recentadvancements in planning and control algorithms help AVs react to sudden objectappearances from blind spots at low speeds and less complex scenarios,challenges remain at high speeds and complex intersections. Vehicle toInfrastructure (V2I) technology promises to enhance scene representation forAVs in complex intersections, providing sufficient time and distance to reactto adversary vehicles violating traffic rules. Most existing methods forinfrastructure-based vehicle detection and tracking rely on LIDAR, RADAR orsensor fusion methods, such as LIDAR-Camera and RADAR-Camera. Although LIDARand RADAR provide accurate spatial information, the sparsity of point clouddata limits its ability to capture detailed object contours of objects faraway, resulting in inaccurate 3D object detection results. Furthermore, theabsence of LIDAR or RADAR at every intersection increases the cost ofimplementing V2I technology. To address these challenges, this paper proposes aV2I framework that utilizes monocular traffic cameras at road intersections todetect 3D objects. The results from the roadside unit (RSU) are then combinedwith the on-board system using an asynchronous late fusion method to enhancescene representation. Additionally, the proposed framework provides a timedelay compensation module to compensate for the processing and transmissiondelay from the RSU. Lastly, the V2I framework is tested by simulating andvalidating a scenario similar to the one described in an industry report byWaymo. The results show that the proposed method improves the scenerepresentation and the AV's perception range, giving enough time and space toreact to adversary vehicles.</description>
      <author>example@mail.com (Nithish Kumar Saravanan, Varun Jammula, Yezhou Yang, Jeffrey Wishart, Junfeng Zhao)</author>
      <guid isPermaLink="false">2504.08172v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>FMLGS: Fast Multilevel Language Embedded Gaussians for Part-level Interactive Agents</title>
      <link>http://arxiv.org/abs/2504.08581v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FMLGS的方法，用于在3D Gaussian Splatting中支持部分级别的开放词汇查询，旨在解决多粒度交互的挑战。&lt;h4&gt;背景&lt;/h4&gt;语义交互辐射场长期以来是3D现实世界应用（如具身AI实现场景理解和操作）的有希望的主干。然而，由于语言的模糊性和对物体组件查询时的质量退化，多粒度交互仍然是一个具有挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;提出FMLGS方法，以支持部分级别的开放词汇查询，并构建和查询一致的对象和部分级别语义。&lt;h4&gt;方法&lt;/h4&gt;设计了基于Segment Anything Model 2（SAM2）的高效流程来构建和查询一致的对象和部分级别语义。此外，还设计了语义偏差策略来解决物体部分之间语言模糊的问题，通过插值细粒度目标的语义特征来丰富信息。&lt;h4&gt;主要发现&lt;/h4&gt;FMLGS方法不仅能够更好地定位指定的部分级别目标，而且在速度和准确性方面都取得了第一名的成绩，比LERF快98倍，比LangSplat快4倍，比LEGaussians快2.5倍。同时，FMLGS被集成为一个虚拟代理，可以交互式地导航3D场景，定位目标，并通过聊天界面响应用户需求。&lt;h4&gt;结论&lt;/h4&gt;FMLGS方法在3D场景理解和操作方面具有巨大潜力，可以进一步扩展和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The semantically interactive radiance field has long been a promisingbackbone for 3D real-world applications, such as embodied AI to achieve sceneunderstanding and manipulation. However, multi-granularity interaction remainsa challenging task due to the ambiguity of language and degraded quality whenit comes to queries upon object components. In this work, we present FMLGS, anapproach that supports part-level open-vocabulary query within 3D GaussianSplatting (3DGS). We propose an efficient pipeline for building and queryingconsistent object- and part-level semantics based on Segment Anything Model 2(SAM2). We designed a semantic deviation strategy to solve the problem oflanguage ambiguity among object parts, which interpolates the semantic featuresof fine-grained targets for enriched information. Once trained, we can queryboth objects and their describable parts using natural language. Comparisonswith other state-of-the-art methods prove that our method can not only betterlocate specified part-level targets, but also achieve first-place performanceconcerning both speed and accuracy, where FMLGS is 98 x faster than LERF, 4 xfaster than LangSplat and 2.5 x faster than LEGaussians. Meanwhile, we furtherintegrate FMLGS as a virtual agent that can interactively navigate through 3Dscenes, locate targets, and respond to user demands through a chat interface,which demonstrates the potential of our work to be further expanded and appliedin the future.</description>
      <author>example@mail.com (Xin Tan, Yuzhou Ji, He Zhu, Yuan Xie)</author>
      <guid isPermaLink="false">2504.08581v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>LGRPool: Hierarchical Graph Pooling Via Local-Global Regularisation</title>
      <link>http://arxiv.org/abs/2504.08530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  f tables, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LGRPool的分层图池化（HGP）方法，旨在解决传统图神经网络（GNN）的扁平化和多尺度不足问题。&lt;h4&gt;背景&lt;/h4&gt;传统GNN在处理图数据时缺乏对全局拓扑结构的考虑，且多尺度分析不足。&lt;h4&gt;目的&lt;/h4&gt;提出LGRPool方法，以期望最大化机器学习框架为基础，通过正则化器使全局拓扑信息与不同尺度的局部消息传递保持一致。&lt;h4&gt;方法&lt;/h4&gt;LGRPool通过在不同层级的HGP表示中，利用正则化器来强制全局拓扑信息与局部消息传递相匹配。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，LGRPool在图分类基准测试中略优于一些基线方法。&lt;h4&gt;结论&lt;/h4&gt;LGRPool是一种有效的HGP方法，能够提升图分类的性能。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种分层图池化（HGP）方法，旨在解决传统图神经网络（GNN）的扁平化和多尺度不足问题。在机器学习的期望最大化框架下，通过正则化器使全局拓扑信息与不同尺度的局部消息传递相匹配。实验结果表明，该方法在图分类基准测试中略优于一些基线方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hierarchical graph pooling(HGP) are designed to consider the fact thatconventional graph neural networks(GNN) are inherently flat and are also notmultiscale. However, most HGP methods suffer not only from lack of consideringglobal topology of the graph and focusing on the feature learning aspect, butalso they do not align local and global features since graphs should inherentlybe analyzed in a multiscale way. LGRPool is proposed in the present paper as aHGP in the framework of expectation maximization in machine learning thataligns local and global aspects of message passing with each other using aregularizer to force the global topological information to be inline with thelocal message passing at different scales through the representations atdifferent layers of HGP. Experimental results on some graph classificationbenchmarks show that it slightly outperforms some baselines.</description>
      <author>example@mail.com (Farshad Noravesh, Reza Haffari, Layki Soon, Arghya Pal)</author>
      <guid isPermaLink="false">2504.08530v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Embodied Image Captioning: Self-supervised Learning Agents for Spatially Coherent Image Descriptions</title>
      <link>http://arxiv.org/abs/2504.08531v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 8 figures, 5 tables, code and test set annotations  available at https://hsp-iit.github.io/embodied-captioning/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种自监督方法，通过主动探索通用环境来提高智能体描述任意对象的能力。该方法通过共识机制提高了现有标题模型的准确性和一致性。&lt;h4&gt;背景&lt;/h4&gt;当前模型在获取连贯图像标题方面存在困难，因为不同的摄像头视角和杂乱的环境。&lt;h4&gt;目的&lt;/h4&gt;提高智能体在描述任意对象时的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一个三阶段框架，用于微调现有的标题模型：1）智能体探索环境，收集噪声图像-标题对；2）使用大型语言模型通过共识为每个对象实例提炼一致的伪标题；3）使用对比学习对这些伪标题进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;1）训练出的策略可以挖掘出与经典基线相比具有更高不一致性的样本；2）与现有方法相比，伪标题方法结合所有策略具有更高的语义相似性；3）微调显著提高了标题的准确性和一致性。&lt;h4&gt;结论&lt;/h4&gt;该方法是有效的，可以显著提高智能体描述任意对象的能力。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种自监督方法来提高智能体在描述任意对象时的能力，同时积极探索通用环境。这是一个具有挑战性的问题，因为当前模型由于不同的摄像头视角和杂乱的环境而难以获得连贯的图像标题。我们提出了一种三阶段框架来微调现有的标题模型，通过共识机制提高了跨视图的标题准确性和一致性。首先，智能体探索环境，收集噪声图像-标题对。然后，通过共识使用大型语言模型提炼每个对象实例的一致的伪标题。最后，使用对比学习对这些伪标题进行微调。我们分析了标题模型、探索策略、伪标签方法和微调策略的组合性能，在我们的手动标注测试集上。结果表明，可以训练出一种策略，与经典基线相比，可以挖掘出具有更高不一致性的样本。我们的伪标题方法与所有策略结合，与现有方法相比具有更高的语义相似性，微调显著提高了标题的准确性和一致性。代码和测试集注释可在https://hsp-iit.github.io/embodied-captioning/获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a self-supervised method to improve an agent's abilities indescribing arbitrary objects while actively exploring a generic environment.This is a challenging problem, as current models struggle to obtain coherentimage captions due to different camera viewpoints and clutter. We propose athree-phase framework to fine-tune existing captioning models that enhancescaption accuracy and consistency across views via a consensus mechanism. First,an agent explores the environment, collecting noisy image-caption pairs. Then,a consistent pseudo-caption for each object instance is distilled via consensususing a large language model. Finally, these pseudo-captions are used tofine-tune an off-the-shelf captioning model, with the addition of contrastivelearning. We analyse the performance of the combination of captioning models,exploration policies, pseudo-labeling methods, and fine-tuning strategies, onour manually labeled test set. Results show that a policy can be trained tomine samples with higher disagreement compared to classical baselines. Ourpseudo-captioning method, in combination with all policies, has a highersemantic similarity compared to other existing methods, and fine-tuningimproves caption accuracy and consistency by a significant margin. Code andtest set annotations available athttps://hsp-iit.github.io/embodied-captioning/</description>
      <author>example@mail.com (Tommaso Galliena, Tommaso Apicella, Stefano Rosa, Pietro Morerio, Alessio Del Bue, Lorenzo Natale)</author>
      <guid isPermaLink="false">2504.08531v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Seaweed-7B: Cost-Effective Training of Video Generation Foundation Model</title>
      <link>http://arxiv.org/abs/2504.08685v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种成本效益高的策略来训练视频生成基础模型。&lt;h4&gt;背景&lt;/h4&gt;本文提出了一种名为Seaweed-7B的中型研究模型，该模型拥有约70亿参数，通过665,000小时的H100 GPU时间从头开始训练。&lt;h4&gt;目的&lt;/h4&gt;在资源受限的环境中，设计选择对模型性能至关重要，本文强调了提高中型扩散模型性能的关键设计决策。&lt;h4&gt;方法&lt;/h4&gt;通过实证研究，分析了Seaweed-7B的性能，并与在更大GPU资源上训练的更大模型进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;Seaweed-7B在有限的计算资源下达到了与更大模型相当甚至超越的性能，并且模型具有较强的泛化能力，可以通过轻量级微调或继续训练有效地适应广泛的下游应用。&lt;h4&gt;结论&lt;/h4&gt;Seaweed-7B是一种在资源受限的情况下高效训练的视频生成模型，具有良好的性能和适应性。&lt;h4&gt;翻译&lt;/h4&gt;本技术报告提出了一种成本效益高的策略来训练视频生成基础模型。我们提出了一种名为Seaweed-7B的中型研究模型，该模型拥有约70亿参数，通过665,000小时的H100 GPU时间从头开始训练。尽管使用了有限的计算资源，Seaweed-7B在性能上与更大规模的当代视频生成模型具有高度竞争力。在资源受限的环境中，设计选择对模型性能至关重要。本文强调了提高中型扩散模型性能的关键设计决策。通过实证研究，我们发现Seaweed-7B在有限的计算资源下达到了与更大模型相当甚至超越的性能，并且模型具有较强的泛化能力，可以通过轻量级微调或继续训练有效地适应广泛的下游应用。更多信息请查看项目页面https://seaweed.video/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report presents a cost-efficient strategy for training a videogeneration foundation model. We present a mid-sized research model withapproximately 7 billion parameters (7B) called Seaweed-7B trained from scratchusing 665,000 H100 GPU hours. Despite being trained with moderate computationalresources, Seaweed-7B demonstrates highly competitive performance compared tocontemporary video generation models of much larger size. Design choices areespecially crucial in a resource-constrained setting. This technical reporthighlights the key design decisions that enhance the performance of themedium-sized diffusion model. Empirically, we make two observations: (1)Seaweed-7B achieves performance comparable to, or even surpasses, larger modelstrained on substantially greater GPU resources, and (2) our model, whichexhibits strong generalization ability, can be effectively adapted across awide range of downstream applications either by lightweight fine-tuning orcontinue training. See the project page at https://seaweed.video/</description>
      <author>example@mail.com (Team Seawead, Ceyuan Yang, Zhijie Lin, Yang Zhao, Shanchuan Lin, Zhibei Ma, Haoyuan Guo, Hao Chen, Lu Qi, Sen Wang, Feng Cheng, Feilong Zuo Xuejiao Zeng, Ziyan Yang, Fangyuan Kong, Zhiwu Qing, Fei Xiao, Meng Wei, Tuyen Hoang, Siyu Zhang, Peihao Zhu, Qi Zhao, Jiangqiao Yan, Liangke Gui, Sheng Bi, Jiashi Li, Yuxi Ren, Rui Wang, Huixia Li, Xuefeng Xiao, Shu Liu, Feng Ling, Heng Zhang, Houmin Wei, Huafeng Kuang, Jerry Duncan, Junda Zhang, Junru Zheng, Li Sun, Manlin Zhang, Renfei Sun, Xiaobin Zhuang, Xiaojie Li, Xin Xia, Xuyan Chi, Yanghua Peng, Yuping Wang, Yuxuan Wang, Zhongkai Zhao, Zhuo Chen, Zuquan Song, Zhenheng Yang, Jiashi Feng, Jianchao Yang, Lu Jiang)</author>
      <guid isPermaLink="false">2504.08685v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>PNE-SGAN: Probabilistic NDT-Enhanced Semantic Graph Attention Network for LiDAR Loop Closure Detection</title>
      <link>http://arxiv.org/abs/2504.08280v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PNE-SGAN是一种用于LiDAR闭环检测（LCD）的方法，旨在提高SLAM的鲁棒性和准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的LiDAR闭环检测方法在鲁棒性和准确性方面存在挑战，如语义图方法缺乏时间鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;提出PNE-SGAN，以克服现有方法的局限性，实现更准确和鲁棒的LiDAR闭环检测。&lt;h4&gt;方法&lt;/h4&gt;PNE-SGAN通过使用NDT协方差矩阵作为几何节点特征，并通过图注意力网络（GAT）进行处理来增强语义图。它将图相似度分数整合到概率时间滤波框架中，并使用HMM/Bayes滤波器模型，同时结合不确定的里程计进行运动建模，并利用前向-后向平滑处理模糊性。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI序列上的评估表明，PNE-SGAN实现了96.2%和95.1%的平均精度，显著优于现有方法，特别是在双向闭环场景中。&lt;h4&gt;结论&lt;/h4&gt;PNE-SGAN通过结合详细的NDT几何和概率时间推理原则，为LiDAR LCD提供了一个高度准确和鲁棒的解决方案，增强了在复杂、大规模环境中的SLAM可靠性。&lt;h4&gt;翻译&lt;/h4&gt;LiDAR闭环检测（LCD）对于一致的SLAM至关重要，但面临着鲁棒性和准确性的挑战。现有的方法，包括语义图方法，通常遭受粗略的几何表示，并且缺乏对噪声、动态和视角变化的时态鲁棒性。我们引入了PNE-SGAN，一种概率NDT增强语义图注意力网络，以克服这些限制。PNE-SGAN通过使用NDT协方差矩阵作为丰富、判别性的几何节点特征，并通过图注意力网络（GAT）进行处理来增强语义图。关键的是，它将图相似度分数整合到一个概率时间滤波框架中（建模为HMM/Bayes滤波器），结合不确定的里程计进行运动建模，并利用前向-后向平滑有效地处理模糊性。在具有挑战性的KITTI序列（00和08）上的评估表明，实现了96.2%和95.1%的平均精度，分别。PNE-SGAN显著优于现有方法，尤其是在其他方法失败的困难双向闭环场景中。通过将详细的NDT几何与原则性的概率时间推理相结合，PNE-SGAN为LiDAR LCD提供了一个高度准确和鲁棒的解决方案，增强了在复杂、大规模环境中的SLAM可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR loop closure detection (LCD) is crucial for consistent SimultaneousLocalization and Mapping (SLAM) but faces challenges in robustness andaccuracy. Existing methods, including semantic graph approaches, often sufferfrom coarse geometric representations and lack temporal robustness againstnoise, dynamics, and viewpoint changes. We introduce PNE-SGAN, a ProbabilisticNDT-Enhanced Semantic Graph Attention Network, to overcome these limitations.PNE-SGAN enhances semantic graphs by using Normal Distributions Transform (NDT)covariance matrices as rich, discriminative geometric node features, processedvia a Graph Attention Network (GAT). Crucially, it integrates graph similarityscores into a probabilistic temporal filtering framework (modeled as anHMM/Bayes filter), incorporating uncertain odometry for motion modeling andutilizing forward-backward smoothing to effectively handle ambiguities.Evaluations on challenging KITTI sequences (00 and 08) demonstratestate-of-the-art performance, achieving Average Precision of 96.2\% and 95.1\%,respectively. PNE-SGAN significantly outperforms existing methods, particularlyin difficult bidirectional loop scenarios where others falter. By synergizingdetailed NDT geometry with principled probabilistic temporal reasoning,PNE-SGAN offers a highly accurate and robust solution for LiDAR LCD, enhancingSLAM reliability in complex, large-scale environments.</description>
      <author>example@mail.com (Xiong Li, Shulei Liu, Xingning Chen, Yisong Wu, Dong Zhu)</author>
      <guid isPermaLink="false">2504.08280v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Latent Diffusion Autoencoders: Toward Efficient and Meaningful Unsupervised Representation Learning in Medical Imaging</title>
      <link>http://arxiv.org/abs/2504.08635v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 9 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为LDAE的潜在扩散自动编码器，这是一种用于医学图像中高效且有意义的不监督学习的创新框架，重点关注阿尔茨海默病（AD）。&lt;h4&gt;背景&lt;/h4&gt;该研究使用来自ADNI数据库的AD患者的脑部MRI作为案例研究。&lt;h4&gt;目的&lt;/h4&gt;验证LDAE方法的有效性，并证明其在捕获与AD和老龄化相关的3D脑部MRI的有意义语义表示方面的能力，以及其在生成和重建高质量图像同时保持计算效率的能力。&lt;h4&gt;方法&lt;/h4&gt;LDAE在压缩的潜在表示中应用扩散过程，与传统的在图像空间操作的扩散自动编码器不同。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果支持以下假设：(i) LDAE能够有效地捕获与AD和老龄化相关的3D脑部MRI的有意义语义表示；(ii) LDAE在生成和重建图像方面表现出高质量，并且计算效率高；(iii) 学习到的语义表示可以进行属性操作，产生解剖学上合理的修改；(iv) 与传统的扩散自动编码器相比，LDAE显著提高了推理吞吐量（20倍更快），同时也提高了重建质量。&lt;h4&gt;结论&lt;/h4&gt;LDAE被定位为可扩展医学图像应用的有希望的框架，有潜力成为医学图像分析的基础模型。&lt;h4&gt;翻译&lt;/h4&gt;This study presents Latent Diffusion Autoencoder (LDAE), a novel encoder-decoder diffusion-based framework for efficient and meaningful unsupervised learning in medical imaging, focusing on Alzheimer disease (AD) using brain MR from the ADNI database as a case study.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study presents Latent Diffusion Autoencoder (LDAE), a novelencoder-decoder diffusion-based framework for efficient and meaningfulunsupervised learning in medical imaging, focusing on Alzheimer disease (AD)using brain MR from the ADNI database as a case study. Unlike conventionaldiffusion autoencoders operating in image space, LDAE applies the diffusionprocess in a compressed latent representation, improving computationalefficiency and making 3D medical imaging representation learning tractable. Tovalidate the proposed approach, we explore two key hypotheses: (i) LDAEeffectively captures meaningful semantic representations on 3D brain MRassociated with AD and ageing, and (ii) LDAE achieves high-quality imagegeneration and reconstruction while being computationally efficient.Experimental results support both hypotheses: (i) linear-probe evaluationsdemonstrate promising diagnostic performance for AD (ROC-AUC: 90%, ACC: 84%)and age prediction (MAE: 4.1 years, RMSE: 5.2 years); (ii) the learned semanticrepresentations enable attribute manipulation, yielding anatomically plausiblemodifications; (iii) semantic interpolation experiments show strongreconstruction of missing scans, with SSIM of 0.969 (MSE: 0.0019) for a 6-monthgap. Even for longer gaps (24 months), the model maintains robust performance(SSIM &gt; 0.93, MSE &lt; 0.004), indicating an ability to capture temporalprogression trends; (iv) compared to conventional diffusion autoencoders, LDAEsignificantly increases inference throughput (20x faster) while also enhancingreconstruction quality. These findings position LDAE as a promising frameworkfor scalable medical imaging applications, with the potential to serve as afoundation model for medical image analysis. Code available athttps://github.com/GabrieleLozupone/LDAE</description>
      <author>example@mail.com (Gabriele Lozupone, Alessandro Bria, Francesco Fontanella, Frederick J. A. Meijer, Claudio De Stefano, Henkjan Huisman)</author>
      <guid isPermaLink="false">2504.08635v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>CMIP-CIL: A Cross-Modal Benchmark for Image-Point Class Incremental Learning</title>
      <link>http://arxiv.org/abs/2504.08422v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图像点类增量学习方法，用于帮助3D视觉机器人从2D图像中持续学习类别知识，提高其在动态环境中的感知能力。&lt;h4&gt;背景&lt;/h4&gt;一些增量学习方法在处理单模态遗忘时表现良好，但在跨模态情况下失败；而另一些方法虽然处理了训练/测试数据集中的模态差异，但假设它们之间没有模态差距。&lt;h4&gt;目的&lt;/h4&gt;探索跨模态任务，提出一个基准CMIP-CIL，并解决跨模态灾难性遗忘问题。&lt;h4&gt;方法&lt;/h4&gt;在预训练阶段，采用掩码点云和渲染的多视角图像，在对比学习框架内，通过图像-点对应关系的泛化来增强视觉模型。在增量学习阶段，通过冻结主干网络并促进对象表示接近其原型，模型能够有效保留和泛化先前看到的类别知识，同时继续学习新的类别。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上进行了全面实验，实验证明该方法达到了最先进的水平，大幅优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;该方法在增量学习方面取得了显著成果，为3D视觉机器人在动态环境中的感知能力提升提供了有效途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-point class incremental learning helps the 3D-points-vision robotscontinually learn category knowledge from 2D images, improving their perceptualcapability in dynamic environments. However, some incremental learning methodsaddress unimodal forgetting but fail in cross-modal cases, while others handlemodal differences within training/testing datasets but assume no modal gapsbetween them. We first explore this cross-modal task, proposing a benchmarkCMIP-CIL and relieving the cross-modal catastrophic forgetting problem. Itemploys masked point clouds and rendered multi-view images within a contrastivelearning framework in pre-training, empowering the vision model with thegeneralizations of image-point correspondence. In the incremental stage, byfreezing the backbone and promoting object representations close to theirrespective prototypes, the model effectively retains and generalizes knowledgeacross previously seen categories while continuing to learn new ones. Weconduct comprehensive experiments on the benchmark datasets. Experiments provethat our method achieves state-of-the-art results, outperforming the baselinemethods by a large margin.</description>
      <author>example@mail.com (Chao Qi, Jianqin Yin, Ren Zhang)</author>
      <guid isPermaLink="false">2504.08422v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>GigaTok: Scaling Visual Tokenizers to 3 Billion Parameters for Autoregressive Image Generation</title>
      <link>http://arxiv.org/abs/2504.08736v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  project page: https://silentview.github.io/GigaTok&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GigaTok是一种新的视觉自动回归图像生成方法，旨在在扩展视觉编码器时同时提高图像重建、生成和表示学习的能力。&lt;h4&gt;背景&lt;/h4&gt;在自动回归图像生成中，视觉编码器将图像压缩为紧凑的离散潜在标记，以实现高效的下游模型训练。然而，扩展视觉编码器通常会导致生成质量下降。&lt;h4&gt;目的&lt;/h4&gt;解决在扩展视觉编码器时图像重建和生成质量之间的矛盾。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为语义正则化的方法，该方法通过将编码器的语义一致特征与编码器特征对齐，以减轻潜在空间复杂性的增长。此外，还探索了三种扩展标记器的关键实践：(1) 使用一维标记器以获得更好的可扩展性；(2) 在扩展编码器和解码器时优先扩展解码器；(3) 使用熵损失来稳定训练。&lt;h4&gt;主要发现&lt;/h4&gt;通过扩展到30亿个参数，GigaTok在重建、下游AR生成和下游AR表示质量方面实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;GigaTok通过引入语义正则化和优化扩展策略，有效地解决了扩展视觉编码器时图像重建和生成质量之间的矛盾，实现了图像生成性能的提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In autoregressive (AR) image generation, visual tokenizers compress imagesinto compact discrete latent tokens, enabling efficient training of downstreamautoregressive models for visual generation via next-token prediction. Whilescaling visual tokenizers improves image reconstruction quality, it oftendegrades downstream generation quality -- a challenge not adequately addressedin existing literature. To address this, we introduce GigaTok, the firstapproach to simultaneously improve image reconstruction, generation, andrepresentation learning when scaling visual tokenizers. We identify the growingcomplexity of latent space as the key factor behind the reconstruction vs.generation dilemma. To mitigate this, we propose semantic regularization, whichaligns tokenizer features with semantically consistent features from apre-trained visual encoder. This constraint prevents excessive latent spacecomplexity during scaling, yielding consistent improvements in bothreconstruction and downstream autoregressive generation. Building on semanticregularization, we explore three key practices for scaling tokenizers:(1) using1D tokenizers for better scalability, (2) prioritizing decoder scaling whenexpanding both encoder and decoder, and (3) employing entropy loss to stabilizetraining for billion-scale tokenizers. By scaling to $\bf{3 \space billion}$parameters, GigaTok achieves state-of-the-art performance in reconstruction,downstream AR generation, and downstream AR representation quality.</description>
      <author>example@mail.com (Tianwei Xiong, Jun Hao Liew, Zilong Huang, Jiashi Feng, Xihui Liu)</author>
      <guid isPermaLink="false">2504.08736v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Boosting the Class-Incremental Learning in 3D Point Clouds via Zero-Collection-Cost Basic Shape Pre-Training</title>
      <link>http://arxiv.org/abs/2504.08412v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对3D点云增量学习的新方法，该方法不依赖于范例，且在预训练模型的基础上，通过引入3D几何知识，显著提升了模型的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的3D点云增量学习方法依赖于范例来防止模型发生灾难性遗忘，但在没有范例的情况下，性能会大幅下降。现有的预训练模型方法在2D领域取得了最先进的成果，但由于3D领域预训练数据集有限且对细粒度几何细节关注不足，这些方法无法迁移到3D领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种不依赖范例的3D点云增量学习方法，通过引入3D几何知识，提高模型在增量学习中的性能。&lt;h4&gt;方法&lt;/h4&gt;构建了一个零收集成本的基形状数据集，用于模型预训练，使模型能够获得广泛的3D几何知识。在此基础上，提出了一种嵌入3D几何知识的增量学习框架，该框架适用于无范例设置。在增量学习阶段，通过正则化相同类别的数据表示来计算类别原型，并在学习过程中持续调整，帮助模型记住不同类别的形状特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在各种基准数据集上，无论是在无范例还是基于范例的设置下，都显著优于其他基线方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过引入3D几何知识，有效解决了3D点云增量学习中范例依赖和性能下降的问题，为3D点云增量学习提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel incremental learning method for 3D point clouds that does not rely on exemplars, and improves the performance of the model by introducing 3D geometric knowledge.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing class-incremental learning methods in 3D point clouds rely onexemplars (samples of former classes) to resist the catastrophic forgetting ofmodels, and exemplar-free settings will greatly degrade the performance. Forexemplar-free incremental learning, the pre-trained model methods have achievedstate-of-the-art results in 2D domains. However, these methods cannot bemigrated to the 3D domains due to the limited pre-training datasets andinsufficient focus on fine-grained geometric details. This paper breaks throughthese limitations, proposing a basic shape dataset with zero collection costfor model pre-training. It helps a model obtain extensive knowledge of 3Dgeometries. Based on this, we propose a framework embedded with 3D geometryknowledge for incremental learning in point clouds, compatible withexemplar-free (-based) settings. In the incremental stage, the geometryknowledge is extended to represent objects in point clouds. The class prototypeis calculated by regularizing the data representation with the same categoryand is kept adjusting in the learning process. It helps the model remember theshape features of different categories. Experiments show that our methodoutperforms other baseline methods by a large margin on various benchmarkdatasets, considering both exemplar-free (-based) settings.</description>
      <author>example@mail.com (Chao Qi, Jianqin Yin, Meng Chen, Yingchun Niu, Yuan Sun)</author>
      <guid isPermaLink="false">2504.08412v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>DSM: Building A Diverse Semantic Map for 3D Visual Grounding</title>
      <link>http://arxiv.org/abs/2504.08307v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures, submitted to IROS, Project Page:  https://binicey.github.io/DSM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对机器人3D视觉定位任务的多样化语义图构建方法，利用VLMs捕捉场景中对象的潜在语义属性和关系，并通过几何滑动窗口图构建策略创建多样化语义图（DSM），以增强对定位信息的理解。&lt;h4&gt;背景&lt;/h4&gt;近年来，多模态大型语言模型（VLMs）在机器人领域的应用日益增多，但现有方法在3D视觉定位任务中往往侧重于通过几何和视觉信息获取场景信息，而忽略了从场景中提取多样化的语义信息以及理解丰富的隐含语义属性。&lt;h4&gt;目的&lt;/h4&gt;提出一种专门为机器人执行3D视觉定位任务设计的多样化语义图构建方法，以解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;该方法利用VLMs捕捉场景中对象的潜在语义属性和关系，通过几何滑动窗口图构建策略创建DSM，并基于DSM增强对定位信息的理解，引入了名为DSM-Grounding的新方法。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在语义分割和3D视觉定位等任务中优于现有方法，尤其是在与现有最佳方法相比的整体指标上表现出色。&lt;h4&gt;结论&lt;/h4&gt;该方法在导航和抓取任务上对机器人进行了部署，验证了其在导航和抓取任务中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, with the growing research and application of multimodallarge language models (VLMs) in robotics, there has been an increasing trend of utilizing VLMs for robotic scene understanding tasks. Existing approaches that use VLMs for 3D Visual Grounding tasks often focus on obtaining scene information through geometric and visual information, overlooking the extraction of diverse semantic information from the scene and the understanding of rich implicit semantic attributes, such as appearance, physics, and affordance. The 3D scene graph, which combines geometry and language, is an ideal representation method for environmental perception and is an effective carrier for language models in 3D Visual Grounding tasks. To address these issues, we propose a diverse semantic map construction method specifically designed for robotic agents performing 3D Visual Grounding tasks. This method leverages VLMs to capture the latent semantic attributes and relations of objects within the scene and creates a Diverse Semantic Map (DSM) through a geometry sliding-window map construction strategy. We enhance the understanding of grounding information based on DSM and introduce a novel approach named DSM-Grounding. Experimental results show that our method outperforms current approaches in tasks like semantic segmentation and 3D Visual Grounding, particularly excelling in overall metrics compared to the state-of-the-art. In addition, we have deployed this method on robots to validate its effectiveness in navigation and grasping tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, with the growing research and application of multimodallarge language models (VLMs) in robotics, there has been an increasing trend ofutilizing VLMs for robotic scene understanding tasks. Existing approaches thatuse VLMs for 3D Visual Grounding tasks often focus on obtaining sceneinformation through geometric and visual information, overlooking theextraction of diverse semantic information from the scene and the understandingof rich implicit semantic attributes, such as appearance, physics, andaffordance. The 3D scene graph, which combines geometry and language, is anideal representation method for environmental perception and is an effectivecarrier for language models in 3D Visual Grounding tasks. To address theseissues, we propose a diverse semantic map construction method specificallydesigned for robotic agents performing 3D Visual Grounding tasks. This methodleverages VLMs to capture the latent semantic attributes and relations ofobjects within the scene and creates a Diverse Semantic Map (DSM) through ageometry sliding-window map construction strategy. We enhance the understandingof grounding information based on DSM and introduce a novel approach namedDSM-Grounding. Experimental results show that our method outperforms currentapproaches in tasks like semantic segmentation and 3D Visual Grounding,particularly excelling in overall metrics compared to the state-of-the-art. Inaddition, we have deployed this method on robots to validate its effectivenessin navigation and grasping tasks.</description>
      <author>example@mail.com (Qinghongbing Xie, Zijian Liang, Long Zeng)</author>
      <guid isPermaLink="false">2504.08307v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Investigating Vision-Language Model for Point Cloud-based Vehicle Classification</title>
      <link>http://arxiv.org/abs/2504.08154v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages,3 figures, 1 table, CVPR DriveX workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型框架，通过整合路边LiDAR点云数据与视觉语言模型（VLMs）来提高重型卡车分类的效率和准确性，以支持协同和安全的驾驶环境。&lt;h4&gt;背景&lt;/h4&gt;重型卡车由于其大型尺寸和有限的机动性，对安全构成重大挑战。传统基于LiDAR的卡车分类方法依赖大量的人工标注，既费时又昂贵。&lt;h4&gt;目的&lt;/h4&gt;为了提高协同自动驾驶的安全视角，本研究旨在通过利用大型语言模型（LLMs）的少样本学习能力，实现高效的卡车分类。&lt;h4&gt;方法&lt;/h4&gt;本研究引入了三项关键创新：(1) 利用真实世界LiDAR数据集进行模型开发；(2) 设计预处理流程以适应VLM输入，包括点云注册以实现密集3D渲染和数学形态学技术以增强特征表示；(3) 利用上下文学习和少样本提示来实现最小标注训练数据的车辆分类。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法表现出令人鼓舞的性能，并具有减少标注工作量的潜力，同时提高分类准确性。&lt;h4&gt;结论&lt;/h4&gt;该方法在卡车分类方面具有潜力，能够减少标注工作量并提高分类准确性，对协同和安全的驾驶环境具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heavy-duty trucks pose significant safety challenges due to their large sizeand limited maneuverability compared to passenger vehicles. A deeperunderstanding of truck characteristics is essential for enhancing the safetyperspective of cooperative autonomous driving. Traditional LiDAR-based truckclassification methods rely on extensive manual annotations, which makes themlabor-intensive and costly. The rapid advancement of large language models(LLMs) trained on massive datasets presents an opportunity to leverage theirfew-shot learning capabilities for truck classification. However, existingvision-language models (VLMs) are primarily trained on image datasets, whichmakes it challenging to directly process point cloud data. This studyintroduces a novel framework that integrates roadside LiDAR point cloud datawith VLMs to facilitate efficient and accurate truck classification, whichsupports cooperative and safe driving environments. This study introduces threekey innovations: (1) leveraging real-world LiDAR datasets for modeldevelopment, (2) designing a preprocessing pipeline to adapt point cloud datafor VLM input, including point cloud registration for dense 3D rendering andmathematical morphological techniques to enhance feature representation, and(3) utilizing in-context learning with few-shot prompting to enable vehicleclassification with minimally labeled training data. Experimental resultsdemonstrate encouraging performance of this method and present its potential toreduce annotation efforts while improving classification accuracy.</description>
      <author>example@mail.com (Yiqiao Li, Jie Wei, Camille Kamga)</author>
      <guid isPermaLink="false">2504.08154v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>A Self-Supervised Framework for Space Object Behaviour Characterisation</title>
      <link>http://arxiv.org/abs/2504.06176v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对太空物体行为分析的空间安全与可持续性基础模型，利用光曲线（LCs）进行行为分析。&lt;h4&gt;背景&lt;/h4&gt;随着轨道物体数量的增加，自动化的太空物体行为分析方法对于空间安全至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够进行异常检测、运动预测和光曲线生成的太空物体行为分析模型。&lt;h4&gt;方法&lt;/h4&gt;采用Perceiver-Variational Autoencoder (VAE) 架构，在来自MMT-9观测站的227,000个光曲线上进行预训练，并通过两个独立的模拟器（CASSANDRA和GRIAL）进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;预训练模型在重建误差为0.01%的情况下识别出可能异常的光曲线。微调后，模型在异常检测和运动模式预测（如太阳对准、自旋等）中分别达到了88%和82%的准确率，ROC AUC分数分别为0.90和0.95。&lt;h4&gt;结论&lt;/h4&gt;该模型通过自监督学习实现了异常检测、运动预测和从预训练中学习到的丰富表示的合成数据生成，支持空间安全和可持续性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在大量未标记数据集上预训练，并在特定任务上进行微调的基础模型正越来越多地应用于专业领域。最近的例子包括用于气候的ClimaX和用于卫星地球观测的Clay，但尚未开发出用于太空物体行为分析的基础模型。随着轨道物体数量的增加，自动化的太空物体行为分析方法对于空间安全至关重要。我们提出了一种空间安全与可持续性基础模型，专注于使用光曲线（LCs）进行太空物体行为分析。我们实现了一个Perceiver-Variational Autoencoder (VAE) 架构，使用来自MMT-9观测站的227,000个光曲线进行预训练，并在自监督重建和掩码重建上进行预训练。VAE能够进行异常检测、运动预测和光曲线生成。我们使用两个独立的模拟器（CASSANDRA和GRIAL）对模型进行了微调，以进行异常检测和运动预测，使用了箱翼、Sentinel-3、SMOS和Starlink平台的CAD模型。我们的预训练模型达到了0.01%的重建误差，通过重建难度识别出可能异常的光曲线。在微调后，模型在异常检测和运动模式预测（如太阳对准、自旋等）中分别达到了88%和82%的准确率，ROC AUC分数分别为0.90和0.95。对高置信度异常预测的实时数据分析揭示了包括特征物体轮廓和卫星反光在内的明显模式。在这里，我们展示了如何通过自监督学习同时实现异常检测、运动预测和从预训练中学习到的丰富表示的合成数据生成。因此，我们的工作通过自动化监控和模拟能力支持空间安全和可持续性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation Models, pre-trained on large unlabelled datasets beforetask-specific fine-tuning, are increasingly being applied to specialiseddomains. Recent examples include ClimaX for climate and Clay for satelliteEarth observation, but a Foundation Model for Space Object Behavioural Analysishas not yet been developed. As orbital populations grow, automated methods forcharacterising space object behaviour are crucial for space safety. We presenta Space Safety and Sustainability Foundation Model focusing on space objectbehavioural analysis using light curves (LCs). We implemented aPerceiver-Variational Autoencoder (VAE) architecture, pre-trained withself-supervised reconstruction and masked reconstruction on 227,000 LCs fromthe MMT-9 observatory. The VAE enables anomaly detection, motion prediction,and LC generation. We fine-tuned the model for anomaly detection &amp; motionprediction using two independent LC simulators (CASSANDRA and GRIALrespectively), using CAD models of boxwing, Sentinel-3, SMOS, and Starlinkplatforms. Our pre-trained model achieved a reconstruction error of 0.01%,identifying potentially anomalous light curves through reconstructiondifficulty. After fine-tuning, the model scored 88% and 82% accuracy, with 0.90and 0.95 ROC AUC scores respectively in both anomaly detection and motion modeprediction (sun-pointing, spin, etc.). Analysis of high-confidence anomalypredictions on real data revealed distinct patterns including characteristicobject profiles and satellite glinting. Here, we demonstrate howself-supervised learning can simultaneously enable anomaly detection, motionprediction, and synthetic data generation from rich representations learned inpre-training. Our work therefore supports space safety and sustainabilitythrough automated monitoring and simulation capabilities.</description>
      <author>example@mail.com (Ian Groves, Andrew Campbell, James Fernandes, Diego Ramírez Rodríguez, Paul Murray, Massimiliano Vasile, Victoria Nockles)</author>
      <guid isPermaLink="false">2504.06176v2</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>STF-GCN: A Multi-Domain Graph Convolution Network Method for Automatic Modulation Recognition via Adaptive Correlation</title>
      <link>http://arxiv.org/abs/2504.08504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为STF-GCN的自动调制识别框架，用于解决低信噪比条件下深度学习方法的特征提取问题，并通过实验验证了其性能优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;现有的基于深度学习的自动调制识别方法在低信噪比条件下难以提取判别性和鲁棒性特征，且图神经网络方法在AMR任务中存在图结构构建和计算复杂性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效提取特征并降低计算复杂性的自动调制识别方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一个以时间域为锚点的时空频谱图卷积网络（STF-GCN）框架，融合了嵌入在图结构节点中的空间和频率域特征。同时，提出了一种基于自适应相关性的邻接矩阵构建方法，增强了图结构聚合局部信息的能力。此外，还引入了PoolGAT层来粗化和压缩全局关键特征，降低计算复杂度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，STF-GCN在RML2016.10a、RML2016.10b和RML22数据集上的识别准确率分别为64.35%、66.04%和70.95%，在低信噪比条件下的平均识别准确率分别比现有最佳模型高出1.20%、1.95%和1.83%。&lt;h4&gt;结论&lt;/h4&gt;STF-GCN框架在低信噪比条件下能够实现远超现有深度学习自动调制识别算法的性能，有效提高了识别准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic Modulation Recognition (AMR) is an essential part of IntelligentTransportation System (ITS) dynamic spectrum allocation. However, current deeplearning-based AMR (DL-AMR) methods are challenged to extract discriminativeand robust features at low signal-to-noise ratios (SNRs), where therepresentation of modulation symbols is highly interfered by noise.Furthermore, current research on GNN methods for AMR tasks generally suffersfrom issues related to graph structure construction and computationalcomplexity. In this paper, we propose a Spatial-Temporal-Frequency GraphConvolution Network (STF-GCN) framework, with the temporal domain as the anchorpoint, to fuse spatial and frequency domain features embedded in the graphstructure nodes. On this basis, an adaptive correlation-based adjacency matrixconstruction method is proposed, which significantly enhances the graphstructure's capacity to aggregate local information into individual nodes. Inaddition, a PoolGAT layer is proposed to coarsen and compress the global keyfeatures of the graph, significantly reducing the computational complexity. Theresults of the experiments confirm that STF-GCN is able to achieve recognitionperformance far beyond the state-of-the-art DL-AMR algorithms, with overallaccuracies of 64.35%, 66.04% and 70.95% on the RML2016.10a, RML2016.10b andRML22 datasets, respectively. Furthermore, the average recognition accuraciesunder low SNR conditions from -14dB to 0dB outperform the state-of-the-art(SOTA) models by 1.20%, 1.95% and 1.83%, respectively.</description>
      <author>example@mail.com (Mingyuan Shao, Zhengqiu Fu, Dingzhao Li, Fuqing Zhang, Yilin Cai, Shaohua Hong, Lin Cao, Yuan Peng, Jie Qi)</author>
      <guid isPermaLink="false">2504.08504v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>F$^3$Set: Towards Analyzing Fast, Frequent, and Fine-grained Events from Videos</title>
      <link>http://arxiv.org/abs/2504.08222v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The Thirteenth International Conference on Learning Representations  (ICLR 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视频分析和多模态语言模型中的F3事件分析问题，提出了一种新的基准数据集F3Set，并介绍了一种新的F3事件检测方法F3ED。&lt;h4&gt;背景&lt;/h4&gt;在视频分析和多模态语言模型中，分析快速、频繁和精细粒度的F3事件是一个重大挑战，因为运动模糊和细微的视觉差异导致现有方法难以精确识别。&lt;h4&gt;目的&lt;/h4&gt;为了推进视频理解研究，本文旨在提出一个包含精确F3事件检测的视频数据集，并评估现有方法，同时提出一种新的F3事件检测方法。&lt;h4&gt;方法&lt;/h4&gt;本文引入了F3Set基准，它包含用于精确F3事件检测的视频数据集。F3Set数据集规模庞大，细节全面，通常包含超过1000种事件类型，具有精确的时间戳和多层次粒度。本文在F3Set上评估了流行的时序动作理解方法，并提出了F3ED方法。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现在F3Set上，现有的时序动作理解方法面临着巨大的挑战，同时提出了的F3ED方法在F3事件检测上表现出色。&lt;h4&gt;结论&lt;/h4&gt;本文提出的F3Set数据集和F3ED方法为F3事件分析提供了新的基准和工具，有助于推动视频理解和多模态语言模型的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：分析快速、频繁、精细粒度（F3）事件在视频分析和多模态语言模型中提出了重大挑战。由于运动模糊和细微的视觉差异等挑战，现有方法难以高精度地识别满足所有F3标准的事件。为了推进视频理解研究，我们引入了F3Set，一个包含用于精确F3事件检测的视频数据集的基准。F3Set数据集以其广泛规模和全面细节为特点，通常包含超过1000种事件类型，具有精确的时间戳和多层次粒度。目前，F3Set包含几个体育数据集，该框架可以扩展到其他应用。我们在F3Set上评估了流行的时序动作理解方法，揭示了现有技术的重大挑战。此外，我们提出了一种新的F3事件检测方法，F3ED，实现了优越的性能。数据集、模型和基准代码可在https://github.com/F3Set/F3Set上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Analyzing Fast, Frequent, and Fine-grained (F$^3$) events presents asignificant challenge in video analytics and multi-modal LLMs. Current methodsstruggle to identify events that satisfy all the F$^3$ criteria with highaccuracy due to challenges such as motion blur and subtle visual discrepancies.To advance research in video understanding, we introduce F$^3$Set, a benchmarkthat consists of video datasets for precise F$^3$ event detection. Datasets inF$^3$Set are characterized by their extensive scale and comprehensive detail,usually encompassing over 1,000 event types with precise timestamps andsupporting multi-level granularity. Currently, F$^3$Set contains several sportsdatasets, and this framework may be extended to other applications as well. Weevaluated popular temporal action understanding methods on F$^3$Set, revealingsubstantial challenges for existing techniques. Additionally, we propose a newmethod, F$^3$ED, for F$^3$ event detections, achieving superior performance.The dataset, model, and benchmark code are available athttps://github.com/F3Set/F3Set.</description>
      <author>example@mail.com (Zhaoyu Liu, Kan Jiang, Murong Ma, Zhe Hou, Yun Lin, Jin Song Dong)</author>
      <guid isPermaLink="false">2504.08222v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Boosting multi-demographic federated learning for chest x-ray analysis using general-purpose self-supervised representations</title>
      <link>http://arxiv.org/abs/2504.08584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了联邦学习在医疗图像分析中的应用，分析了成人胸部X光片和儿科图像数据，发现联邦学习在处理非独立同分布数据时存在挑战，并提出使用自监督图像表示来提升性能。&lt;h4&gt;背景&lt;/h4&gt;可靠的AI模型需要大量多样化的标记数据集，联邦学习提供了一种去中心化和保护隐私的训练方法，但在非独立同分布的数据集中表现不佳。&lt;h4&gt;目的&lt;/h4&gt;为了解决联邦学习在处理非独立同分布数据时的局限性，研究分析了成人胸部X光片和儿科图像数据，以分类肺炎和无异常病例。&lt;h4&gt;方法&lt;/h4&gt;利用迁移学习，从通用自监督图像表示中学习，并使用最先进的视觉Transformer进行分类，对比分析了不同规模的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;联邦学习只在小规模成人数据集上提高了性能，在大规模数据集和儿科病例上则降低了性能。使用自监督权重显著提升了儿科病例和大多数成人数据集的性能。&lt;h4&gt;结论&lt;/h4&gt;通用自监督图像表示在解决临床联邦学习中的非独立同分布挑战方面具有潜力，有助于提高患者结果并推进儿科医疗保健。&lt;h4&gt;翻译&lt;/h4&gt;This study investigates the application of federated learning in medical image analysis, analyzes adult chest radiographs and pediatric images, and finds that federated learning has challenges in dealing with non-IID data, and proposes using self-supervised image representations to improve performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable artificial intelligence (AI) models for medical image analysis oftendepend on large and diverse labeled datasets. Federated learning (FL) offers adecentralized and privacy-preserving approach to training but struggles inhighly non-independent and identically distributed (non-IID) settings, whereinstitutions with more representative data may experience degraded performance.Moreover, existing large-scale FL studies have been limited to adult datasets,neglecting the unique challenges posed by pediatric data, which introducesadditional non-IID variability. To address these limitations, we analyzedn=398,523 adult chest radiographs from diverse institutions across multiplecountries and n=9,125 pediatric images, leveraging transfer learning fromgeneral-purpose self-supervised image representations to classify pneumonia andcases with no abnormality. Using state-of-the-art vision transformers, we foundthat FL improved performance only for smaller adult datasets (P&lt;0.001) butdegraded performance for larger datasets (P&lt;0.064) and pediatric cases(P=0.242). However, equipping FL with self-supervised weights significantlyenhanced outcomes across pediatric cases (P=0.031) and most adult datasets(P&lt;0.008), except the largest dataset (P=0.052). These findings underscore thepotential of easily deployable general-purpose self-supervised imagerepresentations to address non-IID challenges in clinical FL applications andhighlight their promise for enhancing patient outcomes and advancing pediatrichealthcare, where data scarcity and variability remain persistent obstacles.</description>
      <author>example@mail.com (Mahshad Lotfinia, Arash Tayebiarasteh, Samaneh Samiei, Mehdi Joodaki, Soroosh Tayebi Arasteh)</author>
      <guid isPermaLink="false">2504.08584v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Impact of Language Guidance: A Reproducibility Study</title>
      <link>http://arxiv.org/abs/2504.08140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了现代深度学习架构需要大量数据进行训练，以及使用自监督学习减少标注数据的需求，并提出了一种新的基于语言指导的对比学习方法，旨在提高自监督模型的性能。&lt;h4&gt;背景&lt;/h4&gt;现代深度学习架构需要大量数据来达到最佳效果，但标注这些数据既耗时又昂贵，且容易出错。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过自监督学习，特别是对比学习方法，减少对大量数据的标注需求。&lt;h4&gt;方法&lt;/h4&gt;Banani等人的研究提出了使用语言指导来采样视图对的方法，本文通过重现他们的实验来验证其观点，并发现他们的数据集RedCaps包含低质量字幕。作者使用BLIP-2图像字幕模型替换了字幕，并设计了新的评估指标来评估自监督模型的语义能力。&lt;h4&gt;主要发现&lt;/h4&gt;RedCaps数据集包含低质量字幕，通过使用BLIP-2替换字幕并设计新指标，提高了模型性能。&lt;h4&gt;结论&lt;/h4&gt;本文证明了语言指导在提高自监督学习模型的性能方面具有潜力，并指出了现有数据集可能存在的问题。&lt;h4&gt;翻译&lt;/h4&gt;本文讨论了现代深度学习架构需要大量数据进行训练，以及使用自监督学习减少标注数据的需求。最近的研究提出了使用语言指导来采样视图对的方法，本文通过重现他们的实验来验证其观点，并发现他们的数据集RedCaps包含低质量字幕。作者使用BLIP-2图像字幕模型替换了字幕，并设计了新的评估指标来评估自监督模型的语义能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern deep-learning architectures need large amounts of data to producestate-of-the-art results. Annotating such huge datasets is time-consuming,expensive, and prone to human error. Recent advances in self-supervisedlearning allow us to train huge models without explicit annotation. Contrastivelearning is a popular paradigm in self-supervised learning. Recent works likeSimCLR and CLIP rely on image augmentations or directly minimizing cross-modalloss between image and text. Banani et al. (2023) propose to use languageguidance to sample view pairs. They claim that language enables betterconceptual similarity, eliminating the effects of visual variability. Wereproduce their experiments to verify their claims and find that their dataset,RedCaps, contains low-quality captions. We use an off-the-shelf imagecaptioning model, BLIP-2, to replace the captions and improve performance, andwe also devise a new metric to evaluate the semantic capabilities ofself-supervised models based on interpretability methods.</description>
      <author>example@mail.com (Cherish Puniani, Advika Sinha, Shree Singhi, Aayan Yadav)</author>
      <guid isPermaLink="false">2504.08140v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Graph Reduction with Unsupervised Learning in Column Generation: A Routing Application</title>
      <link>http://arxiv.org/abs/2504.08401v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 4 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的列生成（CG）方法，用于提高大规模组合优化（CO）问题的计算效率。&lt;h4&gt;背景&lt;/h4&gt;列生成是一种针对大规模组合优化问题提高计算效率的方法，通过解决定价问题来减少决策变量的数量。&lt;h4&gt;目的&lt;/h4&gt;为了解决大型元素最短路径问题（ESPPRC）的求解难题，本文使用GNN来减小ESPPRC的规模，使其能够通过标准求解技术进行计算。&lt;h4&gt;方法&lt;/h4&gt;本文的GNN通过无监督学习进行训练，输出一个表示在缩减后的路径问题（PP）中应保留的弧的分布。通过局部搜索找到具有大缩减成本的列，从而加速收敛。&lt;h4&gt;主要发现&lt;/h4&gt;在一系列带时间窗的容量限制车辆路径问题（CVRP）上应用该方法，与文献中的简单缩减技术相比，收敛速度有显著提高。在固定的计算预算下，对于更大的实例，目标值提高了超过9%。&lt;h4&gt;结论&lt;/h4&gt;本文的CG算法性能得到了分析，并且方法在不同类别的实例上的泛化能力得到了测试。&lt;h4&gt;翻译&lt;/h4&gt;摘要：列生成（CG）是一种流行的针对大规模组合优化（CO）问题提高计算效率的方法。它通过解决定价问题来减少问题中的决策变量数量。对于许多组合优化问题，定价问题是一个带有资源约束的元素最短路径问题（ESPPRC）。大型ESPPRC实例难以求解到接近最优解。因此，我们使用图神经网络（GNN）来减小ESPPRC的规模，使其能够通过标准求解技术进行计算。我们的GNN通过无监督学习进行训练，并输出一个表示在缩减后的路径问题（PP）中应保留的弧的分布。通过局部搜索找到具有大缩减成本的列，从而加速收敛。我们在一系列带时间窗的容量限制车辆路径问题（CVRP）上应用了我们的方法，与文献中的简单缩减技术相比，收敛速度有显著提高。在固定的计算预算下，对于更大的实例，目标值提高了超过9%。我们还分析了我们的CG算法的性能，并测试了我们的方法在训练数据之外的不同类别的实例上的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Column Generation (CG) is a popular method dedicated to enhancingcomputational efficiency in large scale Combinatorial Optimization (CO)problems. It reduces the number of decision variables in a problem by solving apricing problem. For many CO problems, the pricing problem is an ElementaryShortest Path Problem with Resource Constraints (ESPPRC). Large ESPPRCinstances are difficult to solve to near-optimality. Consequently, we use aGraph neural Network (GNN) to reduces the size of the ESPPRC such that itbecomes computationally tractable with standard solving techniques. Our GNN istrained by Unsupervised Learning and outputs a distribution for the arcs to beretained in the reduced PP. The reduced PP is solved by a local search thatfinds columns with large reduced costs and speeds up convergence. We apply ourmethod on a set of Capacitated Vehicle Routing Problems with Time Windows andshow significant improvements in convergence compared to simple reductiontechniques from the literature. For a fixed computational budget, we improvethe objective values by over 9\% for larger instances. We also analyze theperformance of our CG algorithm and test the generalization of our method todifferent classes of instances than the training data.</description>
      <author>example@mail.com (Abdo Abouelrous, Laurens Bliea, Adriana F. Gabor, Yaoxin Wu, Yingqian Zhang)</author>
      <guid isPermaLink="false">2504.08401v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>ContrastiveGaussian: High-Fidelity 3D Generation with Contrastive Learning and Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2504.08100v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code will be available at  https://github.com/YaNLlan-ljb/ContrastiveGaussian&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ContrastiveGaussian的新方法，用于从单视图图像创建3D内容，该方法通过结合对比学习和感知损失来提高3D生成的质量和纹理保真度。&lt;h4&gt;背景&lt;/h4&gt;从单视图图像创建3D内容是一个具有挑战性的问题，近年来引起了广泛关注。现有方法通常利用预训练的2D扩散模型进行分数蒸馏采样（SDS）来生成多视图3D表示，但这些方法的性能通常受到扩散模型输出视觉不一致性的限制。&lt;h4&gt;目的&lt;/h4&gt;提出ContrastiveGaussian方法，旨在通过整合对比学习来改善3D生成质量，同时提高样本区分度和对比学习的性能。&lt;h4&gt;方法&lt;/h4&gt;ContrastiveGaussian方法通过使用感知损失来区分正负样本，利用视觉不一致性来提高3D生成质量。此外，为了进一步提高样本区分度和改善对比学习，该方法引入了超分辨率模型和数量感知三元组损失，以处理训练过程中的样本分布变化。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法实现了优异的纹理保真度和改进的几何一致性。&lt;h4&gt;结论&lt;/h4&gt;ContrastiveGaussian方法在从单视图图像创建3D内容方面取得了显著的进步，为该领域提供了一个有效且高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Creating 3D content from single-view images is a challenging problem that hasattracted considerable attention in recent years. Current approaches typicallyutilize score distillation sampling (SDS) from pre-trained 2D diffusion modelsto generate multi-view 3D representations. Although some methods have madenotable progress by balancing generation speed and model quality, theirperformance is often limited by the visual inconsistencies of the diffusionmodel outputs. In this work, we propose ContrastiveGaussian, which integratescontrastive learning into the generative process. By using a perceptual loss,we effectively differentiate between positive and negative samples, leveragingthe visual inconsistencies to improve 3D generation quality. To further enhancesample differentiation and improve contrastive learning, we incorporate asuper-resolution model and introduce another Quantity-Aware Triplet Loss toaddress varying sample distributions during training. Our experimentsdemonstrate that our approach achieves superior texture fidelity and improvedgeometric consistency.</description>
      <author>example@mail.com (Junbang Liu, Enpei Huang, Dongxing Mao, Hui Zhang, Xinyuan Song, Yongxin Ni)</author>
      <guid isPermaLink="false">2504.08100v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Local Distance-Preserving Node Embeddings and Their Performance on Random Graphs</title>
      <link>http://arxiv.org/abs/2504.08216v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在图机器学习中学习节点表示的基本问题，提出了一种基于地标节点的局部距离保持节点嵌入方法，并通过理论和实验证明了其在随机图上的有效性和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;现有嵌入方法在保留局部相似性方面效果良好，但往往无法捕捉全局函数如图距离。&lt;h4&gt;目的&lt;/h4&gt;研究局部距离保持节点嵌入的性能，特别是针对地标节点嵌入。&lt;h4&gt;方法&lt;/h4&gt;采用地标节点算法，通过计算从少量参考节点（即地标）到其他节点的最短路径来近似成对距离。&lt;h4&gt;主要发现&lt;/h4&gt;理论研究表明，与最坏情况图相比，随机图（如Erdős-Rényi随机图）在基于地标嵌入中需要的维度更低；实验上，基于图神经网络（GNN）的近似方法对于地标距离的泛化性能良好。&lt;h4&gt;结论&lt;/h4&gt;地标节点嵌入方法在图表示学习中具有有效性和可扩展性，为图表示学习提供了一种可行的替代方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning node representations is a fundamental problem in graph machinelearning. While existing embedding methods effectively preserve localsimilarity measures, they often fail to capture global functions like graphdistances. Inspired by Bourgain's seminal work on Hilbert space embeddings ofmetric spaces (1985), we study the performance of local distance-preservingnode embeddings. Known as landmark-based algorithms, these embeddingsapproximate pairwise distances by computing shortest paths from a small subsetof reference nodes (i.e., landmarks). Our main theoretical contribution showsthat random graphs, such as Erd\H{o}s-R\'enyi random graphs, require lowerdimensions in landmark-based embeddings compared to worst-case graphs.Empirically, we demonstrate that the GNN-based approximations for the distancesto landmarks generalize well to larger networks, offering a scalablealternative for graph representation learning.</description>
      <author>example@mail.com (My Le, Luana Ruiz, Souvik Dhara)</author>
      <guid isPermaLink="false">2504.08216v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>SN-LiDAR: Semantic Neural Fields for Novel Space-time View LiDAR Synthesis</title>
      <link>http://arxiv.org/abs/2504.08361v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SN-LiDAR的新方法，用于从未见过的视角生成真实的LiDAR扫描，并实现了语义分割、几何重建和LiDAR合成的联合处理。&lt;h4&gt;背景&lt;/h4&gt;现有的大多数LiDAR点云视图合成方法没有重建语义标签，这对于自动驾驶和机器人感知等下游应用至关重要。由于LiDAR点云缺乏大规模预训练模型，语义标注变得耗时且劳动密集。&lt;h4&gt;目的&lt;/h4&gt;提出SN-LiDAR方法，旨在解决LiDAR点云语义标注困难的问题，实现准确的语义分割、高质量的几何重建和逼真的LiDAR合成。&lt;h4&gt;方法&lt;/h4&gt;SN-LiDAR方法采用粗到细的平面网格特征表示来从多帧点云中提取全局特征，并利用基于CNN的编码器从当前帧点云中提取局部语义特征。&lt;h4&gt;主要发现&lt;/h4&gt;在SemanticKITTI和KITTI-360数据集上的实验表明，SN-LiDAR在语义和几何重建方面都表现出优越性，能够有效处理动态物体和大规模场景。&lt;h4&gt;结论&lt;/h4&gt;SN-LiDAR方法能够有效地从未见过的视角生成真实的LiDAR扫描，并在语义和几何重建方面取得了显著成果。&lt;h4&gt;翻译&lt;/h4&gt;Recent research has begun exploring novel view synthesis (NVS) for LiDAR point clouds, aiming to generate realistic LiDAR scans from unseen viewpoints. However, most existing approaches do not reconstruct semantic labels, which are crucial for many downstream applications such as autonomous driving and robotic perception. Unlike images, which benefit from powerful segmentation models, LiDAR point clouds lack such large-scale pre-trained models, making semantic annotation time-consuming and labor-intensive. To address this challenge, we propose SN-LiDAR, a method that jointly performs accurate semantic segmentation, high-quality geometric reconstruction, and realistic LiDAR synthesis. Specifically, we employ a coarse-to-fine planar-grid feature representation to extract global features from multi-frame point clouds and leverage a CNN-based encoder to extract local semantic features from the current frame point cloud. Extensive experiments on SemanticKITTI and KITTI-360 demonstrate the superiority of SN-LiDAR in both semantic and geometric reconstruction, effectively handling dynamic objects and large-scale scenes. Codes will be available on https://github.com/dtc111111/SN-Lidar.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research has begun exploring novel view synthesis (NVS) for LiDARpoint clouds, aiming to generate realistic LiDAR scans from unseen viewpoints.However, most existing approaches do not reconstruct semantic labels, which arecrucial for many downstream applications such as autonomous driving and roboticperception. Unlike images, which benefit from powerful segmentation models,LiDAR point clouds lack such large-scale pre-trained models, making semanticannotation time-consuming and labor-intensive. To address this challenge, wepropose SN-LiDAR, a method that jointly performs accurate semanticsegmentation, high-quality geometric reconstruction, and realistic LiDARsynthesis. Specifically, we employ a coarse-to-fine planar-grid featurerepresentation to extract global features from multi-frame point clouds andleverage a CNN-based encoder to extract local semantic features from thecurrent frame point cloud. Extensive experiments on SemanticKITTI and KITTI-360demonstrate the superiority of SN-LiDAR in both semantic and geometricreconstruction, effectively handling dynamic objects and large-scale scenes.Codes will be available on https://github.com/dtc111111/SN-Lidar.</description>
      <author>example@mail.com (Yi Chen, Tianchen Deng, Wentao Zhao, Xiaoning Wang, Wenqian Xi, Weidong Chen, Jingchuan Wang)</author>
      <guid isPermaLink="false">2504.08361v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models</title>
      <link>http://arxiv.org/abs/2504.08329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了电子健康记录(EHR)基础模型的局限性，并提出了一种名为MedRep的解决方案，以提高模型在处理未知医疗代码方面的表现。&lt;h4&gt;背景&lt;/h4&gt;尽管EHR基础模型在各种医疗任务中表现优异，但它们在处理不在词汇表中的未知医疗代码方面存在根本性的限制。&lt;h4&gt;目的&lt;/h4&gt;旨在通过提出MedRep来解决EHR基础模型在处理未知医疗代码方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;MedRep基于OMOP通用数据模型(CDM)，通过以下方式提高模型性能：1) 使用大型语言模型(LLM)提示丰富每个概念的信息；2) 利用OMOP词汇的图本体增强文本表示；3) 通过随机替换患者轨迹中的概念以进行数据增强。&lt;h4&gt;主要发现&lt;/h4&gt;使用MedRep训练的EHR基础模型在外部数据集中更好地保持了预测性能。&lt;h4&gt;结论&lt;/h4&gt;MedRep为EHR基础模型提供了一种有效的方法来处理未知医疗代码，并提高了模型在现实世界应用中的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：电子健康记录(EHR)基础模型已经在各种医疗任务中表现出了改进的性能，但存在一个基本限制：处理不在词汇表中的未知医疗代码。为了解决这个问题，我们基于观察性医疗结果伙伴关系(OMOP)通用数据模型(CDM)为EHR基础模型提出了MedRep，为患者轨迹提供集成医疗概念表示和基本数据增强策略。对于概念表示学习，我们通过大型语言模型(LLM)提示用最少的定义丰富每个概念的信息，并通过OMOP词汇的图本体增强文本表示。轨迹增强通过随机替换与具有密切相关表示的其他类似概念来随机替换选定的概念，使模型能够在词汇表外的概念上进行实践。最后，我们证明，使用MedRep训练的EHR基础模型在外部数据集中更好地保持了预测性能。我们的代码实现可在https://github.com/kicarussays/MedRep上公开访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electronic health record (EHR) foundation models have been an area ripe forexploration with their improved performance in various medical tasks. Despitethe rapid advances, there exists a fundamental limitation: Processing unseenmedical codes out of the vocabulary. This problem limits the generality of EHRfoundation models and the integration of models trained with differentvocabularies. To deal with this problem, we propose MedRep for EHR foundationmodels based on the observational medical outcome partnership (OMOP) commondata model (CDM), providing the integrated medical concept representations andthe basic data augmentation strategy for patient trajectories. For conceptrepresentation learning, we enrich the information of each concept with aminimal definition through large language model (LLM) prompts and enhance thetext-based representations through graph ontology of OMOP vocabulary.Trajectory augmentation randomly replaces selected concepts with other similarconcepts that have closely related representations to let the model practicewith the concepts out-of-vocabulary. Finally, we demonstrate that EHRfoundation models trained with MedRep better maintain the predictionperformance in external datasets. Our code implementation is publicly availableat https://github.com/kicarussays/MedRep.</description>
      <author>example@mail.com (Junmo Kim, Namkyeong Lee, Jiwon Kim, Kwangsoo Kim)</author>
      <guid isPermaLink="false">2504.08329v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Banana Ripeness Level Classification using a Simple CNN Model Trained with Real and Synthetic Datasets</title>
      <link>http://arxiv.org/abs/2504.08568v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 7 figures, conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了香蕉成熟度评估问题，提出了一种结合真实和合成数据训练的CNN模型，用于准确识别香蕉的成熟度。&lt;h4&gt;背景&lt;/h4&gt;香蕉成熟度对质量至关重要，目前工业上仍使用人工方法评估，而CNN模型有潜力解决这一问题，但数据量限制影响了模型的训练。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合真实和合成数据的方法，训练CNN模型以准确评估香蕉的成熟度。&lt;h4&gt;方法&lt;/h4&gt;创建了一个结合真实和合成数据的鲁棒数据集，设计了一个简单的CNN架构，并使用迁移学习技术进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;提出的CNN模型在多个架构和超参数配置下，实现了高达0.917的准确率和快速的执行时间。&lt;h4&gt;结论&lt;/h4&gt;所提出的CNN模型能够有效地识别香蕉的成熟度，具有较高的准确性和效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：香蕉的成熟度水平对于确定其质量至关重要。为了正确估计香蕉的成熟度，需要考虑国际营销标准。然而，在工业级别评估香蕉成熟度的过程中，仍然使用人工方法。使用CNN模型是一个吸引人的工具来解决这个问题，但关于训练这些模型所需的数据充分性的限制。另一方面，在当前技术中，现有的CNN模型和可用数据报告说，在识别香蕉成熟度方面的准确率是可以接受的。因此，这项工作提出了生成一个结合真实和合成数据以不同香蕉成熟度级别的鲁棒数据集。此外，它提出了一种简单的CNN架构，该架构使用合成数据进行训练，并使用迁移学习技术，通过改进模型以分类真实数据，来管理确定香蕉的成熟度水平。所提出的CNN模型使用多个架构进行评估，然后改变超参数配置，并使用优化器。结果显示，所提出的CNN模型达到了0.917的高准确率和快速的执行时间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.5220/0011654600003417&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The level of ripeness is essential in determining the quality of bananas. Tocorrectly estimate banana maturity, the metrics of international marketingstandards need to be considered. However, the process of assessing the maturityof bananas at an industrial level is still carried out using manual methods.The use of CNN models is an attractive tool to solve the problem, but there isa limitation regarding the availability of sufficient data to train thesemodels reliably. On the other hand, in the state-of-the-art, existing CNNmodels and the available data have reported that the accuracy results areacceptable in identifying banana maturity. For this reason, this work presentsthe generation of a robust dataset that combines real and synthetic data fordifferent levels of banana ripeness. In addition, it proposes a simple CNNarchitecture, which is trained with synthetic data and using the transferlearning technique, the model is improved to classify real data, managing todetermine the level of maturity of the banana. The proposed CNN model isevaluated with several architectures, then hyper-parameter configurations arevaried, and optimizers are used. The results show that the proposed CNN modelreaches a high accuracy of 0.917 and a fast execution time.</description>
      <author>example@mail.com (Luis Chuquimarca, Boris Vintimilla, Sergio Velastin)</author>
      <guid isPermaLink="false">2504.08568v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Academic Network Representation via Prediction-Sampling Incorporated Tensor Factorization</title>
      <link>http://arxiv.org/abs/2504.08323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于预测采样的张量潜在因子分解（PLFT）模型，用于解决学术网络高维和不完整（HDI）问题，以更准确地学习学术网络表示。&lt;h4&gt;背景&lt;/h4&gt;准确表示学术网络对于学术关系挖掘（如预测科学影响）具有重要意义。然而，由于学术网络的高维性和不完整性，传统的潜在因子分解（LFT）模型难以学习到准确的学术网络表示。&lt;h4&gt;目的&lt;/h4&gt;提出PLFT模型，旨在解决学术网络高维和不完整问题，提高模型对学术网络表示的学习能力。&lt;h4&gt;方法&lt;/h4&gt;PLFT模型包含两个主要思想：1）构建级联LFT架构，通过学习学术网络层次特征来增强模型表示学习能力；2）引入非线性激活结合的预测采样策略，通过逐层生成新的学术网络数据来更准确地学习网络表示。&lt;h4&gt;主要发现&lt;/h4&gt;在三个真实世界学术网络数据集上的实验结果表明，PLFT模型在预测网络实体间未探索的关系方面优于现有模型。&lt;h4&gt;结论&lt;/h4&gt;PLFT模型能够有效解决学术网络高维和不完整问题，提高学术网络表示的准确性，为学术关系挖掘提供了一种新的有效方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate representation to an academic network is of great significance toacademic relationship mining like predicting scientific impact. A LatentFactorization of Tensors (LFT) model is one of the most effective models forlearning the representation of a target network. However, an academic networkis often High-Dimensional and Incomplete (HDI) because the relationships amongnumerous network entities are impossible to be fully explored, making itdifficult for an LFT model to learn accurate representation of the academicnetwork. To address this issue, this paper proposes a Prediction-sampling-basedLatent Factorization of Tensors (PLFT) model with two ideas: 1) constructing acascade LFT architecture to enhance model representation learning ability vialearning academic network hierarchical features, and 2) introducing a nonlinearactivation-incorporated predicting-sampling strategy to more accurately learnthe network representation via generating new academic network data layer bylayer. Experimental results from the three real-world academic network datasetsshow that the PLFT model outperforms existing models when predicting theunexplored relationships among network entities.</description>
      <author>example@mail.com (Chunyang Zhang, Xin Liao, Hao Wu)</author>
      <guid isPermaLink="false">2504.08323v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Graph Based Deep Reinforcement Learning Aided by Transformers for Multi-Agent Cooperation</title>
      <link>http://arxiv.org/abs/2504.08195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 7 figures, Accepted to the 2025 IEEE International  Conference on Communications Workshops (ICC Workshops)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型框架，用于解决在部分可观测、有限通信范围和不确定环境下的分布式目标点服务应用中的自主无人机编队任务规划问题。&lt;h4&gt;背景&lt;/h4&gt;任务规划在灾难响应、环境监测和监控等应用中面临挑战，特别是在存在通信限制和不确定性时，传统的路径规划算法难以适用。&lt;h4&gt;目的&lt;/h4&gt;提出的方法旨在通过集成图神经网络（GNN）、深度强化学习（DRL）和基于transformer的消息传递机制，提高多智能体协调和集体任务执行能力。&lt;h4&gt;方法&lt;/h4&gt;该方法利用GNN通过自适应图构建来模拟智能体间和智能体与目标之间的交互，实现有限通信下的高效信息聚合和决策。transformer的消息传递机制结合边缘特征增强的注意力机制，捕捉复杂的交互模式。此外，采用具有优先级经验回放的Double Deep Q-Network（Double DQN）优化智能体策略，以适应部分可观测环境。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在服务提供（90%）和网格覆盖率（100%）方面优于基准方法，同时将平均每轮的步骤数从600减少到200。&lt;h4&gt;结论&lt;/h4&gt;该框架有效提高了多智能体导航的扩展性、适应性和任务执行效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：针对涉及服务分布式目标点的应用，如灾害响应、环境监测和监控，自主无人机编队任务规划在部分可观测、有限通信范围和不确定环境下具有挑战性，特别是在先验信息不可用的情况下。为了应对这些挑战，我们提出了一种新的框架，该框架集成了图神经网络（GNN）、深度强化学习（DRL）和基于transformer的机制，以增强多智能体协调和集体任务执行。我们的方法利用GNN通过自适应图构建来模拟智能体间和智能体与目标之间的交互，从而在受限通信下实现高效的信息聚合和决策。基于transformer的消息传递机制，通过边缘特征增强的注意力机制，捕捉复杂的交互模式，同时，具有优先级经验回放的Double Deep Q-Network（Double DQN）优化了部分可观测环境中的智能体策略。这种集成被精心设计，以解决多智能体导航的特定要求，如可扩展性、适应性和高效的任务执行。实验结果表明，该方法在服务提供和网格覆盖率方面优于基准方法，同时将平均每轮的步骤数从600减少到200。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mission planning for a fleet of cooperative autonomous drones in applicationsthat involve serving distributed target points, such as disaster response,environmental monitoring, and surveillance, is challenging, especially underpartial observability, limited communication range, and uncertain environments.Traditional path-planning algorithms struggle in these scenarios, particularlywhen prior information is not available. To address these challenges, wepropose a novel framework that integrates Graph Neural Networks (GNNs), DeepReinforcement Learning (DRL), and transformer-based mechanisms for enhancedmulti-agent coordination and collective task execution. Our approach leveragesGNNs to model agent-agent and agent-goal interactions through adaptive graphconstruction, enabling efficient information aggregation and decision-makingunder constrained communication. A transformer-based message-passing mechanism,augmented with edge-feature-enhanced attention, captures complex interactionpatterns, while a Double Deep Q-Network (Double DQN) with prioritizedexperience replay optimizes agent policies in partially observableenvironments. This integration is carefully designed to address specificrequirements of multi-agent navigation, such as scalability, adaptability, andefficient task execution. Experimental results demonstrate superiorperformance, with 90% service provisioning and 100% grid coverage (nodediscovery), while reducing the average steps per episode to 200, compared to600 for benchmark methods such as particle swarm optimization (PSO), greedyalgorithms and DQN.</description>
      <author>example@mail.com (Michael Elrod, Niloufar Mehrabi, Rahul Amin, Manveen Kaur, Long Cheng, Jim Martin, Abolfazl Razi)</author>
      <guid isPermaLink="false">2504.08195v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Enabling Automatic Differentiation with Mollified Graph Neural Operators</title>
      <link>http://arxiv.org/abs/2504.08277v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了 mollified graph neural operator (mGNO)，一种利用自动微分在任意几何上计算精确梯度的方法，用于学习偏微分方程（PDEs）的解算子。该方法在非规则网格和不同几何形状上的训练效率高，且能够提高物理损失的评估，从而提升泛化能力。&lt;h4&gt;背景&lt;/h4&gt;物理学信息神经网络算子结合数据和物理损失来学习PDEs的解算子。然而，计算物理损失中的导数存在挑战，传统的谱和有限差分方法由于有限分辨率而引入近似误差。&lt;h4&gt;目的&lt;/h4&gt;提出mGNO方法，以解决计算导数的挑战，并提高PDEs求解的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;mGNO结合自动微分技术，在任意几何上计算精确梯度，从而提高物理损失的评估，实现高效训练和更好的泛化。&lt;h4&gt;主要发现&lt;/h4&gt;与有限差分法相比，mGNO与autograd结合在规则网格上的PDEs求解中，将L2相对数据误差降低了20倍，尽管训练速度较慢。在非结构化点云上，mGNO求解PDEs，仅使用物理损失，在远低于有限差分法所需精度的分辨率下，误差比机器学习基线（Meta-PDE）低两个数量级，并且速度比数值求解器快一个到三个数量级。&lt;h4&gt;结论&lt;/h4&gt;mGNO可以高效地解决非规则网格和不同几何形状上的PDEs，并且对于逆设计和形状优化问题在复杂几何形状上也有应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：物理学信息神经网络算子提供了一种结合数据和物理损失的强大框架，用于学习偏微分方程（PDEs）的解算子。然而，这些物理损失依赖于导数。计算这些导数仍然具有挑战性，因为谱和有限差分方法由于有限分辨率而引入了近似误差。在这里，我们提出了mollified graph neural operator（mGNO），这是第一种利用自动微分在任意几何上计算精确梯度的方法。这种增强使得在非规则网格和变化几何形状上实现高效训练成为可能，同时允许在随机采样的点上无缝评估物理损失，以改善泛化能力。对于规则网格上的PDE示例，mGNO与autograd结合将L2相对数据误差降低了20倍，与有限差分法相比，尽管训练速度较慢。它还可以无缝地在非结构化点云上解决PDEs，仅使用物理损失，在远低于有限差分法达到足够精度的分辨率下。在这些非结构化点云上，mGNO导致比可比运行时间的机器学习基线（Meta-PDE）低两个数量级的误差，并且与数值求解器相比，在类似精度的情况下也提供了1到3个数量级的加速。mGNO还可以用于解决复杂几何形状上的逆设计和形状优化问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Physics-informed neural operators offer a powerful framework for learningsolution operators of partial differential equations (PDEs) by combining dataand physics losses. However, these physics losses rely on derivatives.Computing these derivatives remains challenging, with spectral and finitedifference methods introducing approximation errors due to finite resolution.Here, we propose the mollified graph neural operator (mGNO), the first methodto leverage automatic differentiation and compute \emph{exact} gradients onarbitrary geometries. This enhancement enables efficient training on irregulargrids and varying geometries while allowing seamless evaluation of physicslosses at randomly sampled points for improved generalization. For a PDEexample on regular grids, mGNO paired with autograd reduced the L2 relativedata error by 20x compared to finite differences, although training was slower.It can also solve PDEs on unstructured point clouds seamlessly, using physicslosses only, at resolutions vastly lower than those needed for finitedifferences to be accurate enough. On these unstructured point clouds, mGNOleads to errors that are consistently 2 orders of magnitude lower than machinelearning baselines (Meta-PDE) for comparable runtimes, and also deliversspeedups from 1 to 3 orders of magnitude compared to the numerical solver forsimilar accuracy. mGNOs can also be used to solve inverse design and shapeoptimization problems on complex geometries.</description>
      <author>example@mail.com (Ryan Y. Lin, Julius Berner, Valentin Duruisseaux, David Pitt, Daniel Leibovici, Jean Kossaifi, Kamyar Azizzadenesheli, Anima Anandkumar)</author>
      <guid isPermaLink="false">2504.08277v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Neural Encoding and Decoding at Scale</title>
      <link>http://arxiv.org/abs/2504.08201v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为NEDS的多模态、多任务模型，用于同时进行大规模的神经编码和解码，以桥接神经活动与行为之间的双向关系。&lt;h4&gt;背景&lt;/h4&gt;现有的大规模模型要么专注于从行为预测神经活动（编码），要么专注于从神经活动预测行为（解码），这限制了它们捕捉神经活动与行为之间双向关系的能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出NEDS模型，实现神经编码和解码的同步进行。&lt;h4&gt;方法&lt;/h4&gt;NEDS采用了一种新颖的多任务掩码策略，交替进行神经、行为、同模态和跨模态掩码。该模型在包含83只动物进行同一视觉决策任务的International Brain Laboratory (IBL)重复站点数据集上预训练。&lt;h4&gt;主要发现&lt;/h4&gt;与其它大规模模型相比，NEDS在基于多动物数据预训练并在新动物上微调时，在编码和解码方面均达到了最先进的性能。NEDS学习到的嵌入具有自涌现特性，即使没有明确的训练，也能高度预测每个记录的大脑区域。&lt;h4&gt;结论&lt;/h4&gt;NEDS模型是朝着构建一个能够无缝翻译神经活动和行为的脑部基础模型迈出的重要一步。&lt;h4&gt;翻译&lt;/h4&gt;最近的研究表明，大规模、多动物模型是表征神经活动与行为之间关系的有力工具。然而，当前的大规模方法要么专注于从行为预测神经活动（编码），要么专注于从神经活动预测行为（解码），这限制了它们捕捉神经活动与行为之间双向关系的能力。为了弥合这一差距，我们提出了一种多模态、多任务模型，称为NEDS，它能够实现大规模的神经编码和解码。我们方法的核心是一种新颖的多任务掩码策略，它交替进行神经、行为、同模态和跨模态掩码。我们在包含83只动物进行同一视觉决策任务的International Brain Laboratory (IBL)重复站点数据集上预训练了我们的方法。与其他大规模模型相比，我们证明了当在多动物数据上预训练并在新动物上微调时，NEDS在编码和解码方面均达到了最先进的性能。令人惊讶的是，NEDS学习到的嵌入具有自涌现特性：即使没有明确的训练，它们也能高度预测每个记录的大脑区域。总之，我们的方法朝着构建一个能够无缝翻译神经活动和行为的脑部基础模型迈出了重要一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent work has demonstrated that large-scale, multi-animal models arepowerful tools for characterizing the relationship between neural activity andbehavior. Current large-scale approaches, however, focus exclusively on eitherpredicting neural activity from behavior (encoding) or predicting behavior fromneural activity (decoding), limiting their ability to capture the bidirectionalrelationship between neural activity and behavior. To bridge this gap, weintroduce a multimodal, multi-task model that enables simultaneous NeuralEncoding and Decoding at Scale (NEDS). Central to our approach is a novelmulti-task-masking strategy, which alternates between neural, behavioral,within-modality, and cross-modality masking. We pretrain our method on theInternational Brain Laboratory (IBL) repeated site dataset, which includesrecordings from 83 animals performing the same visual decision-making task. Incomparison to other large-scale models, we demonstrate that NEDS achievesstate-of-the-art performance for both encoding and decoding when pretrained onmulti-animal data and then fine-tuned on new animals. Surprisingly, NEDS'slearned embeddings exhibit emergent properties: even without explicit training,they are highly predictive of the brain regions in each recording. Altogether,our approach is a step towards a foundation model of the brain that enablesseamless translation between neural activity and behavior.</description>
      <author>example@mail.com (Yizi Zhang, Yanchen Wang, Mehdi Azabou, Alexandre Andre, Zixuan Wang, Hanrui Lyu, The International Brain Laboratory, Eva Dyer, Liam Paninski, Cole Hurwitz)</author>
      <guid isPermaLink="false">2504.08201v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>DrivAer Transformer: A high-precision and fast prediction method for vehicle aerodynamic drag coefficient based on the DrivAerNet++ dataset</title>
      <link>http://arxiv.org/abs/2504.08217v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DrivAer Transformer (DAT)的点云学习框架，用于评估空气动力学性能，以加速汽车设计过程和提高开发效率。&lt;h4&gt;背景&lt;/h4&gt;深度学习方法在评估空气动力学性能方面表现出色，但处理复杂的三维车辆模型时，由于缺乏大规模数据集和训练资源，以及不同车辆模型几何形状的多样性和复杂性，预测精度和灵活性仍不足以满足当前生产需求。&lt;h4&gt;目的&lt;/h4&gt;提出DrivAer Transformer框架，旨在提高对复杂三维车辆模型空气动力学性能评估的准确性和灵活性。&lt;h4&gt;方法&lt;/h4&gt;DAT框架使用DrivAerNet++数据集，该数据集包含工业标准三维车辆形状的高保真CFD数据，直接从三维网格中估计空气阻力，从而避免了传统方法（如二维图像渲染或符号距离场）的限制。&lt;h4&gt;主要发现&lt;/h4&gt;DAT框架能够实现快速且准确的阻力预测，推动了空气动力学评估过程的演变，并为将数据驱动方法引入汽车设计奠定了关键基础。&lt;h4&gt;结论&lt;/h4&gt;DAT框架预计将加速车辆设计过程，提高开发效率。&lt;h4&gt;翻译&lt;/h4&gt;在当前阶段，基于深度学习的方法在评估空气动力学性能方面表现出卓越的能力，显著降低了传统计算流体动力学（CFD）模拟所需的时间和成本。然而，面对处理极其复杂的3D车辆模型的任务时，由于缺乏大规模数据集和训练资源，加上不同车辆模型几何形状的多样性和复杂性，这些网络的预测精度和灵活性仍然达不到当前生产所需的水平。鉴于Transformer模型在自然语言处理领域的显著成功及其在图像处理领域的强大潜力，本研究创新性地提出了一种名为DrivAer Transformer（DAT）的点云学习框架。DAT结构使用DrivAerNet++数据集，该数据集包含工业标准3D车辆形状的高保真CFD数据，能够直接从3D网格中准确估计空气阻力，从而避免了传统方法（如2D图像渲染或符号距离场）的限制。DAT能够实现快速且准确的阻力预测，推动空气动力学评估过程的演变，为将数据驱动方法引入汽车设计奠定关键基础。该框架预计将加速车辆设计过程，提高开发效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; At the current stage, deep learning-based methods have demonstrated excellentcapabilities in evaluating aerodynamic performance, significantly reducing thetime and cost required for traditional computational fluid dynamics (CFD)simulations. However, when faced with the task of processing extremely complexthree-dimensional (3D) vehicle models, the lack of large-scale datasets andtraining resources, coupled with the inherent diversity and complexity of thegeometry of different vehicle models, means that the prediction accuracy andversatility of these networks are still not up to the level required forcurrent production. In view of the remarkable success of Transformer models inthe field of natural language processing and their strong potential in thefield of image processing, this study innovatively proposes a point cloudlearning framework called DrivAer Transformer (DAT). The DAT structure uses theDrivAerNet++ dataset, which contains high-fidelity CFD data ofindustrial-standard 3D vehicle shapes. enabling accurate estimation of air dragdirectly from 3D meshes, thus avoiding the limitations of traditional methodssuch as 2D image rendering or signed distance fields (SDF). DAT enables fastand accurate drag prediction, driving the evolution of the aerodynamicevaluation process and laying the critical foundation for introducing adata-driven approach to automotive design. The framework is expected toaccelerate the vehicle design process and improve development efficiency.</description>
      <author>example@mail.com (Jiaqi He, Xiangwen Luo, Yiping Wang)</author>
      <guid isPermaLink="false">2504.08217v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>II-NVM: Enhancing Map Accuracy and Consistency with Normal Vector-Assisted Mapping</title>
      <link>http://arxiv.org/abs/2504.08204v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于SLAM技术的室内定位和地图构建方法，以解决室内环境中存在的“双面映射问题”，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;室内环境中，紧密排列的墙壁、门和其他表面容易被错误地识别为单一平面，这会严重影响地图的准确性和一致性。&lt;h4&gt;目的&lt;/h4&gt;提出一种SLAM方法，确保使用法向量一致性进行精确的地图构建。&lt;h4&gt;方法&lt;/h4&gt;1. 优化体素地图结构，存储点云数据和法向量信息；2. 引入自适应半径KD树搜索方法，根据局部点云密度动态调整搜索半径；3. 实施最少使用（LRU）缓存策略，提高体素地图的增量更新效率。&lt;h4&gt;主要发现&lt;/h4&gt;该方法有效地解决了“双面映射问题”，显著提高了地图构建的精度。&lt;h4&gt;结论&lt;/h4&gt;该方法在模拟环境和真实室内场景中均得到验证，并成功开源了针对“双面映射问题”的第一个模拟和真实世界数据集。&lt;h4&gt;翻译&lt;/h4&gt;SLAM技术在内向制图和定位中起着关键作用。室内环境中的一个常见问题是“双面映射问题”，其中紧密排列的墙壁、门和其他表面被错误地识别为单一平面，这会严重阻碍地图的准确性和一致性。为了解决这个问题，本文提出了一种SLAM方法，该方法确保了使用法向量一致性进行精确的制图。我们增强了体素地图结构，以便存储点云数据和法向量信息，使系统能够在最近邻搜索和地图更新期间评估一致性。此过程区分了表面的前后两侧，防止了错误的点到平面的约束。此外，我们实现了一种自适应半径KD树搜索方法，该方法根据局部点云密度动态调整搜索半径，从而提高了法向量计算的准确性。为了进一步提高实时性能和存储效率，我们引入了最少使用（LRU）缓存策略，该策略有助于体素地图的高效增量更新。代码已作为开源软件发布，并在模拟环境和真实室内场景中得到验证。实验结果表明，这种方法有效地解决了“双面映射问题”，并显著提高了制图精度。此外，我们还开发并开源了针对“双面映射问题”的第一个模拟和真实世界数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; SLAM technology plays a crucial role in indoor mapping and localization. Acommon challenge in indoor environments is the "double-sided mapping issue",where closely positioned walls, doors, and other surfaces are mistakenlyidentified as a single plane, significantly hindering map accuracy andconsistency. To address this issue this paper introduces a SLAM approach thatensures accurate mapping using normal vector consistency. We enhance the voxelmap structure to store both point cloud data and normal vector information,enabling the system to evaluate consistency during nearest neighbor searchesand map updates. This process distinguishes between the front and back sides ofsurfaces, preventing incorrect point-to-plane constraints. Moreover, weimplement an adaptive radius KD-tree search method that dynamically adjusts thesearch radius based on the local density of the point cloud, thereby enhancingthe accuracy of normal vector calculations. To further improve realtimeperformance and storage efficiency, we incorporate a Least Recently Used (LRU)cache strategy, which facilitates efficient incremental updates of the voxelmap. The code is released as open-source and validated in both simulatedenvironments and real indoor scenarios. Experimental results demonstrate thatthis approach effectively resolves the "double-sided mapping issue" andsignificantly improves mapping precision. Additionally, we have developed andopen-sourced the first simulation and real world dataset specifically tailoredfor the "double-sided mapping issue".</description>
      <author>example@mail.com (Chengwei Zhao, Yixuan Li, Yina Jian, Jie Xu, Linji Wang, Yongxin Ma, Xinglai Jin)</author>
      <guid isPermaLink="false">2504.08204v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Detecting Credit Card Fraud via Heterogeneous Graph Neural Networks with Graph Attention</title>
      <link>http://arxiv.org/abs/2504.08183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于异构图神经网络（HGNN）的信用卡欺诈检测方法，以解决复杂交易网络中的欺诈问题。&lt;h4&gt;背景&lt;/h4&gt;传统的机器学习方法依赖于交易记录的数值特征，而本研究提出了构建异构交易图的方法。&lt;h4&gt;目的&lt;/h4&gt;提高欺诈检测的准确性和对时间相关欺诈模式敏感度。&lt;h4&gt;方法&lt;/h4&gt;1. 构建包含用户、商家和交易等多节点类型的异构交易图；2. 利用图神经网络捕捉高阶交易关系；3. 采用图注意力机制动态分配不同交易关系的权重；4. 集成时间衰减机制增强对时间相关欺诈模式敏感度；5. 应用SMOTE过采样和代价敏感学习来解决欺诈交易样本稀缺的问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在IEEE-CIS欺诈检测数据集上优于现有的GNN模型，包括GCN、GAT和GraphSAGE，在准确率和OC-ROC方面均有显著提升。&lt;h4&gt;结论&lt;/h4&gt;未来研究可能探索动态图神经网络和强化学习的集成，以增强欺诈检测系统的实时适应性和为金融风险控制提供更智能的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This study proposes a credit card fraud detection method based on Heterogeneous Graph Neural Network (HGNN) to address fraud in complex transaction networks. Unlike traditional machine learning methods that rely solely on numerical features of transaction records, this approach constructs heterogeneous transaction graphs. These graphs incorporate multiple node types, including users, merchants, and transactions. By leveraging graph neural networks, the model captures higher-order transaction relationships. A GraphAttention Mechanism is employed to dynamically assign weights to different transaction relationships. Additionally, a Temporal Decay Mechanism is integrated to enhance the model's sensitivity to time-related fraud patterns. To address the scarcity of fraudulent transaction samples, this study applies SMOTE oversampling and Cost-sensitive Learning. These techniques strengthen the model's ability to identify fraudulent transactions. Experimental results demonstrate that the proposed method outperforms existing GNN models, including GCN, GAT, and GraphSAGE, on the IEEE-CIS Fraud Detection dataset. The model achieves notable improvements in both accuracy and OC-ROC. Future research may explore the integration of dynamic graph neural networks and reinforcement learning. Such advancements could enhance the real-time adaptability of fraud detection systems and provide more intelligent solutions for financial risk control.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study proposes a credit card fraud detection method based onHeterogeneous Graph Neural Network (HGNN) to address fraud in complextransaction networks. Unlike traditional machine learning methods that relysolely on numerical features of transaction records, this approach constructsheterogeneous transaction graphs. These graphs incorporate multiple node types,including users, merchants, and transactions. By leveraging graph neuralnetworks, the model captures higher-order transaction relationships. A GraphAttention Mechanism is employed to dynamically assign weights to differenttransaction relationships. Additionally, a Temporal Decay Mechanism isintegrated to enhance the model's sensitivity to time-related fraud patterns.To address the scarcity of fraudulent transaction samples, this study appliesSMOTE oversampling and Cost-sensitive Learning. These techniques strengthen themodel's ability to identify fraudulent transactions. Experimental resultsdemonstrate that the proposed method outperforms existing GNN models, includingGCN, GAT, and GraphSAGE, on the IEEE-CIS Fraud Detection dataset. The modelachieves notable improvements in both accuracy and OC-ROC. Future research mayexplore the integration of dynamic graph neural networks and reinforcementlearning. Such advancements could enhance the real-time adaptability of frauddetection systems and provide more intelligent solutions for financial riskcontrol.</description>
      <author>example@mail.com (Qiuwu Sha, Tengda Tang, Xinyu Du, Jie Liu, Yixian Wang, Yuan Sheng)</author>
      <guid isPermaLink="false">2504.08183v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Communication-Efficient Cooperative Localization: A Graph Neural Network Approach</title>
      <link>http://arxiv.org/abs/2504.08135v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通信高效的协同定位方法，用于解决无线网络中节点定位的问题。&lt;h4&gt;背景&lt;/h4&gt;在通信受限的环境中，传统的协同定位方法在无线网络中遇到困难，尤其是在存在环状拓扑结构的网络中。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，旨在同时降低定位误差和通信开销。&lt;h4&gt;方法&lt;/h4&gt;提出了一种向量量化消息传递神经网络（VQ-MPNN）用于协同定位，通过端到端神经网络训练，实现节点定位和消息压缩的协同设计。&lt;h4&gt;主要发现&lt;/h4&gt;VQ-MPNN通过将节点位置和距离测量作为节点和边特征，使用图神经网络进行编码，并通过构造向量量化码本来提高效率，从而实现低通信开销。&lt;h4&gt;结论&lt;/h4&gt;数值评估表明，所提出的VQ-MPNN方法在降低通信开销的同时，定位误差与现有方法相当。&lt;h4&gt;翻译&lt;/h4&gt;摘要：协作定位利用有噪声的节点间距离测量和交换的无线消息来估计无线网络中的节点位置。然而，在通信受限的环境中，传输大量信息变得有困难。在本文中，我们提出了一种针对通信高效的协作定位的方法，解决了两个主要挑战。首先，协作定位通常需要在具有环状图拓扑结构的无线网络上执行。其次，需要设计一个算法，在同时具有低定位误差的同时，要求通信开销大大降低。现有方法无法同时解决这两个挑战。为了实现这一点，我们提出了一种用于协作定位的向量量化消息传递神经网络（VQ-MPNN）。通过端到端神经网络训练，VQ-MPNN实现了节点定位和消息压缩的协同设计。具体来说，VQ-MPNN将先验节点位置和距离测量分别作为节点和边特征，使用图神经网络将它们编码为节点和边状态。为了找到一个高效的节点状态表示，我们为所有节点状态构建了一个向量量化码本，使得每个节点只需要传输一个码字索引。数值评估表明，我们提出的VQ-MPNN方法可以在降低通信开销的同时，提供与现有方法相当定位误差。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cooperative localization leverages noisy inter-node distance measurements andexchanged wireless messages to estimate node positions in a wireless network.In communication-constrained environments, however, transmitting large messagesbecomes problematic. In this paper, we propose an approach forcommunication-efficient cooperative localization that addresses two mainchallenges. First, cooperative localization often needs to be performed overwireless networks with loopy graph topologies. Second is the need for designingan algorithm that has low localization error while simultaneously requiring amuch lower communication overhead. Existing methods fall short of addressingthese two challenges concurrently. To achieve this, we propose a vectorquantized message passing neural network (VQ-MPNN) for cooperativelocalization. Through end-to-end neural network training, VQ-MPNN enables theco-design of node localization and message compression. Specifically, VQ-MPNNtreats prior node positions and distance measurements as node and edgefeatures, respectively, which are encoded as node and edge states using a graphneural network. To find an efficient representation for the node state, weconstruct a vector quantized codebook for all node states such that instead ofsending long messages, each node only needs to transmit a codeword index.Numerical evaluations demonstrates that our proposed VQ-MPNN approach candeliver localization errors that are similar to existing approaches whilereducing the overall communication overhead by an order of magnitude.</description>
      <author>example@mail.com (Yinan Zou, Christopher G. Brinton, Vishrant Tripathi)</author>
      <guid isPermaLink="false">2504.08135v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>SynthFM: Training Modality-agnostic Foundation Models for Medical Image Segmentation without Real Medical Data</title>
      <link>http://arxiv.org/abs/2504.08177v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SynthFM的合成数据生成框架，用于解决医学图像分割问题，并评估了其在多个数据集上的性能。&lt;h4&gt;背景&lt;/h4&gt;自然图像分割模型如Segment Anything Model (SAM) 在零样本分割方面表现优异，但在医学图像分割上由于纹理、对比度和噪声的差异而表现不佳。医学图像标注成本高且需要领域专业知识，限制了大规模标注数据的可用性。&lt;h4&gt;目的&lt;/h4&gt;提出SynthFM框架以解决医学图像分割问题，使基础模型能够在没有真实医学数据的情况下进行适应。&lt;h4&gt;方法&lt;/h4&gt;使用SAM的预训练编码器，并在SynthFM的数据集上从头开始训练解码器。在11个解剖结构上使用9个数据集（CT、MRI和超声）评估了该方法。&lt;h4&gt;主要发现&lt;/h4&gt;SynthFM在多个数据集上优于零样本基线模型SAM和MedSAM，在不同提示设置和分布外数据集上均取得了优越的结果。&lt;h4&gt;结论&lt;/h4&gt;SynthFM是一种有效的合成数据生成框架，可以显著提高医学图像分割的性能，为医学图像分割领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models like the Segment Anything Model (SAM) excel in zero-shotsegmentation for natural images but struggle with medical image segmentationdue to differences in texture, contrast, and noise. Annotating medical imagesis costly and requires domain expertise, limiting large-scale annotated dataavailability. To address this, we propose SynthFM, a synthetic data generationframework that mimics the complexities of medical images, enabling foundationmodels to adapt without real medical data. Using SAM's pretrained encoder andtraining the decoder from scratch on SynthFM's dataset, we evaluated our methodon 11 anatomical structures across 9 datasets (CT, MRI, and Ultrasound).SynthFM outperformed zero-shot baselines like SAM and MedSAM, achievingsuperior results under different prompt settings and on out-of-distributiondatasets.</description>
      <author>example@mail.com (Sourya Sengupta, Satrajit Chakrabarty, Keerthi Sravan Ravi, Gopal Avinash, Ravi Soni)</author>
      <guid isPermaLink="false">2504.08177v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Laws of Graph Neural Networks for Atomistic Materials Modeling</title>
      <link>http://arxiv.org/abs/2504.08112v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by DAC'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了图神经网络（GNNs）在原子材料建模中的应用，提出了一种具有数十亿参数的基础模型，并使用海量数据进行训练，旨在提升GNNs在原子材料建模中的性能。&lt;h4&gt;背景&lt;/h4&gt;原子材料建模在药物发现和材料科学等领域具有重要应用，而GNNs因其能够捕捉复杂的关联结构而成为建模的先进方法。&lt;h4&gt;目的&lt;/h4&gt;研究GNNs在原子材料建模中的扩展极限，开发一个具有数十亿参数的基础模型，并在海量数据集上训练。&lt;h4&gt;方法&lt;/h4&gt;通过结合大型语言模型（LLM）库的技术，有效管理大规模数据和模型，实现大规模GNN模型的有效训练和部署。&lt;h4&gt;主要发现&lt;/h4&gt;包括GNNs扩展定律的见解，强调模型大小、数据集体积和准确率之间的关系；一个优化用于原子材料建模的基础GNN模型；以及一个通过先进的LLM基于的训练技术增强的GNN代码库。&lt;h4&gt;结论&lt;/h4&gt;为具有数十亿参数和千兆级数据集的大规模GNNs奠定了基础，为原子材料建模的未来发展提供了一个可扩展的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Atomistic materials modeling is a critical task with wide-rangingapplications, from drug discovery to materials science, where accuratepredictions of the target material property can lead to significantadvancements in scientific discovery. Graph Neural Networks (GNNs) representthe state-of-the-art approach for modeling atomistic material data thanks totheir capacity to capture complex relational structures. While machine learningperformance has historically improved with larger models and datasets, GNNs foratomistic materials modeling remain relatively small compared to large languagemodels (LLMs), which leverage billions of parameters and terabyte-scaledatasets to achieve remarkable performance in their respective domains. Toaddress this gap, we explore the scaling limits of GNNs for atomistic materialsmodeling by developing a foundational model with billions of parameters,trained on extensive datasets in terabyte-scale. Our approach incorporatestechniques from LLM libraries to efficiently manage large-scale data andmodels, enabling both effective training and deployment of these large-scaleGNN models. This work addresses three fundamental questions in scaling GNNs:the potential for scaling GNN model architectures, the effect of dataset sizeon model accuracy, and the applicability of LLM-inspired techniques to GNNarchitectures. Specifically, the outcomes of this study include (1) insightsinto the scaling laws for GNNs, highlighting the relationship between modelsize, dataset volume, and accuracy, (2) a foundational GNN model optimized foratomistic materials modeling, and (3) a GNN codebase enhanced with advancedLLM-based training techniques. Our findings lay the groundwork for large-scaleGNNs with billions of parameters and terabyte-scale datasets, establishing ascalable pathway for future advancements in atomistic materials modeling.</description>
      <author>example@mail.com (Chaojian Li, Zhifan Ye, Massimiliano Lupo Pasini, Jong Youl Choi, Cheng Wan, Yingyan Celine Lin, Prasanna Balaprakash)</author>
      <guid isPermaLink="false">2504.08112v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Day-to-day Dynamic Tolling in Tradable Credit Schemes</title>
      <link>http://arxiv.org/abs/2504.08074v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了可交易信用方案（TCS）作为拥堵定价的替代方案，通过强化学习算法解决TCS下的日常动态收费问题，并评估了算法在不同参数和需求下的鲁棒性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;可交易信用方案（TCS）作为一种新兴的拥堵管理工具，因其收入中立性和通过初始信用分配解决公平性问题而受到关注。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过强化学习算法解决TCS下的日常动态收费问题，并评估算法在不同条件下的性能。&lt;h4&gt;方法&lt;/h4&gt;将TCS下的日常动态收费问题建模为离散时间马尔可夫决策过程，并使用强化学习算法进行求解。&lt;h4&gt;主要发现&lt;/h4&gt;强化学习算法在旅行时间和社会福利方面与贝叶斯优化基准相当，且在不同容量和需求水平上具有良好的泛化能力。通过调整超参数和采用正则化技术，算法表现出良好的鲁棒性，并生成了在不同需求供应变化下可转移的收费策略。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效解决TCS下的日常动态收费问题，并具有在实际网络中应用的潜力。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了可交易信用方案（TCS）作为一种替代拥堵定价的方法，考虑到其收入中立性和通过初始信用分配解决公平性问题。建模TCS以帮助未来的设计和实施涉及到用户和市场行为、供需动态和控制机制等挑战。在本文中，我们专注于后者，并解决了TCS下的日常动态收费问题，将其表述为离散时间马尔可夫决策过程，并使用强化学习（RL）算法来解决。我们的结果表明，RL算法在旅行时间和社会福利方面与贝叶斯优化基准相当，并在不同的容量和需求水平上具有泛化能力。我们进一步评估了RL在不同超参数下的鲁棒性，并应用了正则化技术来减轻动作振荡，从而生成在不同日常需求和供应变化下可转移的实际收费策略。最后，我们讨论了潜在的挑战，如扩展到大型网络，并展示了如何利用迁移学习来提高计算效率，从而促进基于RL的TCS解决方案的实用部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tradable credit schemes (TCS) are an increasingly studied alternative tocongestion pricing, given their revenue neutrality and ability to addressissues of equity through the initial credit allocation. Modeling TCS to aidfuture design and implementation is associated with challenges involving userand market behaviors, demand-supply dynamics, and control mechanisms. In thispaper, we focus on the latter and address the day-to-day dynamic tollingproblem under TCS, which is formulated as a discrete-time Markov DecisionProcess and solved using reinforcement learning (RL) algorithms. Our resultsindicate that RL algorithms achieve travel times and social welfare comparableto the Bayesian optimization benchmark, with generalization across varyingcapacities and demand levels. We further assess the robustness of RL underdifferent hyperparameters and apply regularization techniques to mitigateaction oscillation, which generates practical tolling strategies that aretransferable under day-to-day demand and supply variability. Finally, wediscuss potential challenges such as scaling to large networks, and show howtransfer learning can be leveraged to improve computational efficiency andfacilitate the practical deployment of RL-based TCS solutions.</description>
      <author>example@mail.com (Xiaoyi Wu, Ravi Seshadri, Filipe Rodrigues, Carlos Lima Azevedo)</author>
      <guid isPermaLink="false">2504.08074v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Vector Quantized-Elites: Unsupervised and Problem-Agnostic Quality-Diversity Optimization</title>
      <link>http://arxiv.org/abs/2504.08057v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 10 figures, 2 algorithms, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了VQ-Elites，一种新的质量多样性算法，该算法通过无监督学习自主构建结构化的行为空间网格，提高了传统质量多样性方法的灵活性。&lt;h4&gt;背景&lt;/h4&gt;传统的质量多样性方法如MAP-Elites依赖预定义的行为描述符和任务先验知识，限制了它们的灵活性和适用性。&lt;h4&gt;目的&lt;/h4&gt;提出VQ-Elites，旨在提高质量多样性算法的灵活性和鲁棒性，使其能够适应更广泛的任务。&lt;h4&gt;方法&lt;/h4&gt;VQ-Elites集成了矢量量化变分自动编码器，实现动态学习行为描述符并生成结构化的行为空间网格。此外，还引入了行为空间边界和协作机制以增强算法性能。&lt;h4&gt;主要发现&lt;/h4&gt;VQ-Elites能够有效地生成多样且高质量的结果，证明其在适应性、可扩展性、鲁棒性和扩展质量多样性优化到复杂领域方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;VQ-Elites是一种灵活、鲁棒且无需特定任务的优化框架，有助于解决复杂任务并扩展质量多样性优化应用范围。&lt;h4&gt;翻译&lt;/h4&gt;摘要：质量多样性算法通过优先发现多样化、高性能的解决方案而改变了优化方式。然而，传统的质量多样性方法，如MAP-Elites，严重依赖预定义的行为描述符和任务先验知识来定义行为空间网格，限制了它们的灵活性和适用性。在这项工作中，我们引入了向量量化精英（VQ-Elites），这是一种新型的质量多样性算法，它使用无监督学习自主构建结构化的行为空间网格，消除了对先验任务特定知识的需要。VQ-Elites的核心是矢量量化变分自动编码器的集成，这使得动态学习行为描述符和生成结构化的而非非结构化的行为空间网格成为可能，这是现有无监督质量多样性方法的重大进步。这种设计将VQ-Elites确立为一种灵活、鲁棒且无需特定任务的优化框架。为了进一步增强无监督质量多样性算法的性能，我们引入了两个关键组件：行为空间边界和协作机制，这些机制显著提高了收敛性和性能。我们在机器人臂姿态到达和移动机器人空间覆盖任务上验证了VQ-Elites。结果表明，它能够有效地生成多样、高质量的结果，强调了其适应性、可扩展性、对超参数的鲁棒性和将质量多样性优化扩展到复杂、以前无法访问的领域的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quality-Diversity algorithms have transformed optimization by prioritizingthe discovery of diverse, high-performing solutions over a single optimalresult. However, traditional Quality-Diversity methods, such as MAP-Elites,rely heavily on predefined behavioral descriptors and complete prior knowledgeof the task to define the behavioral space grid, limiting their flexibility andapplicability. In this work, we introduce Vector Quantized-Elites (VQ-Elites),a novel Quality-Diversity algorithm that autonomously constructs a structuredbehavioral space grid using unsupervised learning, eliminating the need forprior task-specific knowledge. At the core of VQ-Elites is the integration ofVector Quantized Variational Autoencoders, which enables the dynamic learningof behavioral descriptors and the generation of a structured, rather thanunstructured, behavioral space grid - a significant advancement over existingunsupervised Quality-Diversity approaches. This design establishes VQ-Elites asa flexible, robust, and task-agnostic optimization framework. To furtherenhance the performance of unsupervised Quality-Diversity algorithms, weintroduce two key components: behavioral space bounding and cooperationmechanisms, which significantly improve convergence and performance. Wevalidate VQ-Elites on robotic arm pose-reaching and mobile robot space-coveringtasks. The results demonstrate its ability to efficiently generate diverse,high-quality solutions, emphasizing its adaptability, scalability, robustnessto hyperparameters, and potential to extend Quality-Diversity optimization tocomplex, previously inaccessible domains.</description>
      <author>example@mail.com (Constantinos Tsakonas, Konstantinos Chatzilygeroudis)</author>
      <guid isPermaLink="false">2504.08057v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Psychological Health Knowledge-Enhanced LLM-based Social Network Crisis Intervention Text Transfer Recognition Method</title>
      <link>http://arxiv.org/abs/2504.07983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于大型语言模型（LLM）的文本转移识别方法，用于社交网络危机干预，并增强了特定领域的精神健康知识。&lt;h4&gt;背景&lt;/h4&gt;随着社交媒体平台上心理健康危机的普遍增加，识别和预防潜在危害已成为一项紧迫的挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够准确检测和识别社交网络中的心理健康危机的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种多层次框架，该框架结合了使用BERT的迁移学习，并整合了精神健康知识、情感分析和行为预测技术。框架包括一个在真实世界事件的社会媒体数据集上训练的危机标注工具，使模型能够检测细微的情绪线索和识别心理危机。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在危机检测准确率方面优于传统模型，并对微妙的情绪和语境变化表现出更高的敏感性。&lt;h4&gt;结论&lt;/h4&gt;该方法为社交网络中的心理健康危机干预提供了一种有效工具。&lt;h4&gt;翻译&lt;/h4&gt;As the prevalence of mental health crises increases on social media platforms, identifying and preventing potential harm has become an urgent challenge. This study introduces a large language model (LLM)-based text transfer recognition method for social network crisis intervention, enhanced with domain-specific mental health knowledge. We propose a multi-level framework that incorporates transfer learning using BERT, and integrates mental health knowledge, sentiment analysis, and behavior prediction techniques. The framework includes a crisis annotation tool trained on social media datasets from real-world events, enabling the model to detect nuanced emotional cues and identify psychological crises. Experimental results show that the proposed method outperforms traditional models in crisis detection accuracy and exhibits greater sensitivity to subtle emotional and contextual variations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the prevalence of mental health crises increases on social mediaplatforms, identifying and preventing potential harm has become an urgentchallenge. This study introduces a large language model (LLM)-based texttransfer recognition method for social network crisis intervention, enhancedwith domain-specific mental health knowledge. We propose a multi-levelframework that incorporates transfer learning using BERT, and integrates mentalhealth knowledge, sentiment analysis, and behavior prediction techniques. Theframework includes a crisis annotation tool trained on social media datasetsfrom real-world events, enabling the model to detect nuanced emotional cues andidentify psychological crises. Experimental results show that the proposedmethod outperforms traditional models in crisis detection accuracy and exhibitsgreater sensitivity to subtle emotional and contextual variations.</description>
      <author>example@mail.com (Shurui Wu, Xinyi Huang, Dingxin Lu)</author>
      <guid isPermaLink="false">2504.07983v1</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Pushing the Accuracy Limit of Foundation Neural Network Models with Quantum Monte Carlo Forces and Path Integrals</title>
      <link>http://arxiv.org/abs/2504.07948v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种端到端集成策略，用于生成高度精确的量子化学合成数据集（能量和力），旨在推导用于分子模拟的基础机器学习模型。&lt;h4&gt;背景&lt;/h4&gt;从密度泛函理论（DFT）出发，采用“雅各布楼梯”方法，利用大量并行GPU加速软件的计算优化层，提高精度。&lt;h4&gt;目的&lt;/h4&gt;生成高度精确的量子化学合成数据集，用于分子模拟的基础机器学习模型。&lt;h4&gt;方法&lt;/h4&gt;利用Exascale技术，首次在完全基组极限下计算了计算密集型计算扩散量子蒙特卡罗（QMC）力，以及多确定子QMC能量和力与选择-CI波函数的结合。通过迁移学习改进FeNNix-Bio1DFT基础模型，并与路径积分自适应采样量子动力学相结合，进行纳秒级反应模拟。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在前所未有的精度下进行了纳秒级反应模拟，展示了Exascale在深化对复杂生物系统内部机制理解方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;Exascale技术在量子化学合成数据集生成和分子模拟基础模型推导方面具有巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;We propose an end-to-end integrated strategy to produce highly accurate quantum chemistry (QC) synthetic datasets (energies and forces) aimed at deriving Foundation Machine Learning models for molecular simulation. Starting from Density Functional Theory (DFT), a "Jacob's Ladder" approach leverages computationally-optimized layers of massively parallel GPU-accelerated software with increasing accuracy. Thanks to Exascale, this is the first time that the computationally intensive calculation of Diffusion Quantum Monte Carlo (QMC) forces, and the combination of multi-determinant QMC energies and forces with selected-CI wavefunctions, are computed at such scale at the complete basis-set-limit. To bridge the gap between accurate QC and condensed-phasemolecular dynamics, we leverage transfer learning to improve the FeNNix-Bio1DFT-based foundation model. The resulting approach is coupled to path integrals adaptive sampling quantum dynamics to perform nanosecond reactive simulations at unprecedented accuracy. These results demonstrate the promise of Exascale to deepen our understanding of the inner machinery of complex biosystems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose an end-to-end integrated strategy to produce highly accuratequantum chemistry (QC) synthetic datasets (energies and forces) aimed atderiving Foundation Machine Learning models for molecular simulation. Startingfrom Density Functional Theory (DFT), a "Jacob's Ladder" approach leveragescomputationally-optimized layers of massively parallel GPU-accelerated softwarewith increasing accuracy. Thanks to Exascale, this is the first time that thecomputationally intensive calculation of Diffusion Quantum Monte Carlo (QMC)forces, and the combination of multi-determinant QMC energies and forces withselected-CI wavefunctions, are computed at such scale at the completebasis-set-limit. To bridge the gap between accurate QC and condensed-phasemolecular dynamics, we leverage transfer learning to improve the FeNNix-Bio1DFT-based foundation model. The resulting approach is coupled to path integralsadaptive sampling quantum dynamics to perform nanosecond reactive simulationsat unprecedented accuracy. These results demonstrate the promise of Exascale todeepen our understanding of the inner machinery of complex biosystems.</description>
      <author>example@mail.com (Anouar Benali, Thomas Plé, Olivier Adjoua, Valay Agarawal, Thomas Applencourt, Marharyta Blazhynska, Raymond Clay III, Kevin Gasperich, Khalid Hossain, Jeongnim Kim, Christopher Knight, Jaron T. Krogel, Yvon Maday, Maxime Maria, Matthieu Montes, Ye Luo, Evgeny Posenitskiy, Corentin Villot, Venkat Vishwanath, Louis Lagardère, Jean-Philip Piquemal)</author>
      <guid isPermaLink="false">2504.07948v2</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>ASHiTA: Automatic Scene-grounded HIerarchical Task Analysis</title>
      <link>http://arxiv.org/abs/2504.06553v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AShiTA的框架，用于将高级任务分解为与环境相关的子任务，以解决将抽象高级指令与3D场景关联的挑战。&lt;h4&gt;背景&lt;/h4&gt;尽管近年来在场景重建和理解方面取得了进展，但将抽象、高级指令与3D场景关联仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，能够将高级任务分解为与环境相关的子任务，并生成与3D场景图相关的任务层次结构。&lt;h4&gt;方法&lt;/h4&gt;AShiTA通过交替使用LLM辅助的层次任务分析和任务驱动的3D场景图构建来实现这一目标。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AShiTA在将高级任务分解为环境相关的子任务方面显著优于LLM基线，并且能够达到与最先进方法相当的性能。&lt;h4&gt;结论&lt;/h4&gt;AShiTA是一种有效的框架，可以解决将高级指令与3D场景关联的挑战，并具有与现有方法相媲美的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While recent work in scene reconstruction and understanding has made stridesin grounding natural language to physical 3D environments, it is stillchallenging to ground abstract, high-level instructions to a 3D scene.High-level instructions might not explicitly invoke semantic elements in thescene, and even the process of breaking a high-level task into a set of moreconcrete subtasks, a process called hierarchical task analysis, isenvironment-dependent. In this work, we propose ASHiTA, the first frameworkthat generates a task hierarchy grounded to a 3D scene graph by breaking downhigh-level tasks into grounded subtasks. ASHiTA alternates LLM-assistedhierarchical task analysis, to generate the task breakdown, with task-driven 3Dscene graph construction to generate a suitable representation of theenvironment. Our experiments show that ASHiTA performs significantly betterthan LLM baselines in breaking down high-level tasks into environment-dependentsubtasks and is additionally able to achieve grounding performance comparableto state-of-the-art methods.</description>
      <author>example@mail.com (Yun Chang, Leonor Fermoselle, Duy Ta, Bernadette Bucher, Luca Carlone, Jiuguang Wang)</author>
      <guid isPermaLink="false">2504.06553v3</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Are We Done with Object-Centric Learning?</title>
      <link>http://arxiv.org/abs/2504.07092v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于对象的学习（OCL）方法，旨在学习仅编码单个对象而不受场景中其他对象或背景线索影响的表示。研究提出了一种新的无监督探针方法，并通过实验验证了基于分割的对象编码在OOD泛化方面的优势。&lt;h4&gt;背景&lt;/h4&gt;OCL方法旨在通过分离对象来学习对象中心的表示，从而实现OOD泛化、样本高效合成和结构化环境的建模。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过OCL方法分离场景中的对象，并探讨其对OOD泛化等OCL目标的贡献。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Object-Centric Classification with Applied Masks (OCCAM)的新方法，该方法通过分割图像中的对象进行编码，并与基于槽位的OCL方法进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;基于分割的对象编码在OOD对象发现基准测试中表现出色，显著优于基于槽位的OCL方法。&lt;h4&gt;结论&lt;/h4&gt;尽管OCL方法在实现对象中心表示方面取得了重大进展，但其在现实世界应用中仍存在挑战。研究为OCL社区提供了可扩展的对象中心表示工具箱，并关注实际应用和基本问题，如理解人类认知中的物体感知。&lt;h4&gt;翻译&lt;/h4&gt;摘要：以对象为中心的学习（OCL）旨在学习仅编码对象，而将对象与其他对象或场景中的背景线索隔离的表示。这种方法支持各种目标，包括分布外（OOD）泛化、样本高效合成和结构化环境的建模。大多数研究都集中在开发将对象分离到表示空间中离散槽位的无监督机制上，使用无监督对象发现进行评估。然而，随着近期样本高效的分割模型的发展，我们可以在像素空间中分离对象并独立编码它们。这在对OOD对象发现基准的零样本性能上取得了显著成果，可以扩展到基础模型，并且可以无需额外配置处理可变数量的槽位。因此，OCL方法获得对象中心表示的目标已经基本实现。尽管取得了这些进展，但一个关键问题仍然存在：在场景中分离对象的能力如何有助于更广泛的OCL目标，例如OOD泛化？我们通过OCL的视角来探讨由虚假背景线索引起的OOD泛化挑战。我们提出了一种新的、无需训练的探针，称为Object-Centric Classification with Applied Masks（OCCAM），证明了基于分割的个体对象编码在性能上显著优于基于槽位的OCL方法。然而，在现实世界的应用中仍然存在挑战。我们为OCL社区提供了可扩展的对象中心表示工具箱，并专注于实际应用和基本问题，例如理解人类认知中的物体感知。我们的代码可在以下链接找到：https://github.com/AlexanderRubinstein/OCCAM。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object-centric learning (OCL) seeks to learn representations that only encodean object, isolated from other objects or background cues in a scene. Thisapproach underpins various aims, including out-of-distribution (OOD)generalization, sample-efficient composition, and modeling of structuredenvironments. Most research has focused on developing unsupervised mechanismsthat separate objects into discrete slots in the representation space,evaluated using unsupervised object discovery. However, with recentsample-efficient segmentation models, we can separate objects in the pixelspace and encode them independently. This achieves remarkable zero-shotperformance on OOD object discovery benchmarks, is scalable to foundationmodels, and can handle a variable number of slots out-of-the-box. Hence, thegoal of OCL methods to obtain object-centric representations has been largelyachieved. Despite this progress, a key question remains: How does the abilityto separate objects within a scene contribute to broader OCL objectives, suchas OOD generalization? We address this by investigating the OOD generalizationchallenge caused by spurious background cues through the lens of OCL. Wepropose a novel, training-free probe called Object-Centric Classification withApplied Masks (OCCAM), demonstrating that segmentation-based encoding ofindividual objects significantly outperforms slot-based OCL methods. However,challenges in real-world applications remain. We provide the toolbox for theOCL community to use scalable object-centric representations, and focus onpractical applications and fundamental questions, such as understanding objectperception in human cognition. Our code is available here:https://github.com/AlexanderRubinstein/OCCAM.</description>
      <author>example@mail.com (Alexander Rubinstein, Ameya Prabhu, Matthias Bethge, Seong Joon Oh)</author>
      <guid isPermaLink="false">2504.07092v2</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Orb-v3: atomistic simulation at scale</title>
      <link>http://arxiv.org/abs/2504.06231v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Orb-v3，这是Orb家族通用原子势的下一代。该模型在性能、速度和内存方面扩展了Pareto前沿，在各种评估中提供了接近最先进技术（SoTA）的性能，同时降低了10倍以上的延迟和8倍以上的内存。&lt;h4&gt;背景&lt;/h4&gt;Orb-v3是Orb家族的一部分，旨在提高原子模拟的准确性、速度和可扩展性。&lt;h4&gt;目的&lt;/h4&gt;开发一个在准确性、延迟和系统规模可扩展性方面都表现出色的原子模拟基础模型。&lt;h4&gt;方法&lt;/h4&gt;通过系统地遍历性能、速度和内存的Pareto前沿，研究了旋转等变、保守性和图稀疏性之间的权衡。&lt;h4&gt;主要发现&lt;/h4&gt;发现非等变、非保守架构可以准确地模拟物理性质，包括需要势能表面高阶导数的性质。&lt;h4&gt;结论&lt;/h4&gt;该模型发布遵循的原则是，最有价值的原子模拟基础模型应在所有方面都表现出色，这将推动一个由高通量和中等规模全原子模拟驱动的计算化学新时代。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了Orb-v3，这是Orb家族通用原子势的下一代。该家族的模型扩展了性能-速度-内存的Pareto前沿，在各种评估中提供了接近最先进技术（SoTA）的性能，同时降低了10倍以上的延迟和8倍以上的内存。我们的实验系统地遍历了这一前沿，描绘了由旋转等变、保守性和图稀疏性引起的权衡。与近期文献相反，我们发现非等变、非保守架构可以准确地模拟物理性质，包括那些需要势能表面高阶导数的性质。这一模型发布遵循的原则是，最有价值的原子模拟基础模型将在所有方面都表现出色，这将推动一个由高通量和中等规模全原子模拟驱动的计算化学新时代。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Orb-v3, the next generation of the Orb family of universalinteratomic potentials. Models in this family expand theperformance-speed-memory Pareto frontier, offering near SoTA performance acrossa range of evaluations with a &gt;10x reduction in latency and &gt; 8x reduction inmemory. Our experiments systematically traverse this frontier, charting thetrade-off induced by roto-equivariance, conservatism and graph sparsity.Contrary to recent literature, we find that non-equivariant, non-conservativearchitectures can accurately model physical properties, including those whichrequire higher-order derivatives of the potential energy surface.  This model release is guided by the principle that the most valuablefoundation models for atomic simulation will excel on all fronts: accuracy,latency and system size scalability. The reward for doing so is a new era ofcomputational chemistry driven by high-throughput and mesoscale all-atomsimulations.</description>
      <author>example@mail.com (Benjamin Rhodes, Sander Vandenhaute, Vaidotas Šimkus, James Gin, Jonathan Godwin, Tim Duignan, Mark Neumann)</author>
      <guid isPermaLink="false">2504.06231v2</guid>
      <pubDate>Mon, 14 Apr 2025 14:16:36 +0800</pubDate>
    </item>
    <item>
      <title>Solving the Correlation Cluster LP in Sublinear Time</title>
      <link>http://arxiv.org/abs/2503.20883v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法来解决相关聚类问题，该方法能够在多项式时间内找到近似解。&lt;h4&gt;背景&lt;/h4&gt;相关聚类是无监督学习和数据挖掘中的一个基础且广泛研究的问题，其目标是构造一个聚类，以最小化跨聚类边和缺失的内部聚类边的数量。&lt;h4&gt;目的&lt;/h4&gt;研究如何更简洁地表示相关聚类问题，并设计快速近似算法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的方法来找到集群线性规划（cluster LP）的可行解，并实现了解的近似。&lt;h4&gt;主要发现&lt;/h4&gt;在多项式时间内找到集群线性规划的可行解，目标值不超过最优解的(1+ε)倍，同时实现了快速(1.437+ε)近似算法。&lt;h4&gt;结论&lt;/h4&gt;该方法弥合了相关聚类近似算法的最新方法与快速算法之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;相关聚类是机器学习领域中的一个基本问题，其目的是通过将数据点分成不同的组来发现数据中的潜在结构。本文研究了如何用线性规划方法来解决这个问题，并提出了一种新的算法，该算法可以在多项式时间内找到近似解，从而加快了相关聚类的处理速度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3717823.3718181&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Correlation Clustering is a fundamental and widely-studied problem inunsupervised learning and data mining. The input is a graph and the goal is toconstruct a clustering minimizing the number of inter-cluster edges plus thenumber of missing intra-cluster edges.  CCL+24 introduced the cluster LP for Correlation Clustering, which theyargued captures the problem much more succinctly than previous linearprogramming formulations. However, the cluster LP has exponential size, with avariable for every possible set of vertices in the input graph. Nevertheless,CCL+24 showed how to find a feasible solution for the cluster LP in time$O(n^{\text{poly}(1/\eps)})$ with objective value at most $(1+\epsilon)$ timesthe value of an optimal solution for the respective Correlation Clusteringinstance. Furthermore, they showed how to round a solution to the cluster LP,yielding a $(1.437+\eps)$-approximation algorithm for the CorrelationClustering problem.  The main technical result of this paper is a new approach to find a feasiblesolution for the cluster LP with objective value at most $(1+\epsilon)$ of theoptimum in time $\widetilde O(2^{\text{poly}(1/\eps)} n)$, where $n$ is thenumber of vertices in the graph. We also show how to implement the roundingwithin the same time bounds, thus achieving a fast $(1.437+\eps)$-approximationalgorithm for the Correlation Clustering problem. This bridges the gap betweenstate-of-the-art methods for approximating Correlation Clustering and therecent focus on fast algorithms.</description>
      <author>example@mail.com (Nairen Cao, Vincent Cohen-Addad, Shi Li, Euiwoong Lee, David Rasmussen Lolck, Alantha Newman, Mikkel Thorup, Lukas Vogl, Shuyi Yan, Hanwen Zhang)</author>
      <guid isPermaLink="false">2503.20883v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
  <item>
      <title>Detect Anything 3D in the Wild</title>
      <link>http://arxiv.org/abs/2504.07958v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DetAny3D是一种可检测任意新对象的三维检测基础模型，它利用单目输入在任意相机配置下进行检测。&lt;h4&gt;背景&lt;/h4&gt;尽管深度学习在近集三维物体检测中取得了成功，但现有的方法在处理新对象和相机配置的零样本泛化方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出DetAny3D，以解决三维检测基础模型训练中标注三维数据有限的问题，并利用预训练的二维基础模型的知识。&lt;h4&gt;方法&lt;/h4&gt;DetAny3D包含两个核心模块：2D Aggregator用于对齐不同二维基础模型的特征；3D Interpreter with Zero-Embedding Mapping用于缓解从二维到三维知识迁移中的灾难性遗忘。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，DetAny3D在未见类别和新型相机配置上实现了最先进的性能，并在领域数据上超越了大多数竞争对手。&lt;h4&gt;结论&lt;/h4&gt;DetAny3D展示了三维基础模型在现实场景中多样化应用的潜力，如自动驾驶中的稀有物体检测，并预示着在开放世界环境中进一步探索以三维为中心的任务的前景。&lt;h4&gt;翻译&lt;/h4&gt;尽管深度学习在近集三维物体检测中取得了成功，但现有的方法在处理新对象和相机配置的零样本泛化方面存在困难。我们引入了DetAny3D，这是一种可提示的三维检测基础模型，它能够仅使用单目输入在任意相机配置下检测任何新对象。训练三维检测基础模型的基本限制是标注三维数据的有限可用性，这促使DetAny3D利用大量预训练的二维基础模型中嵌入的丰富先验知识来弥补这种稀缺性。为了有效地将二维知识迁移到三维，DetAny3D包含了两个核心模块：2D Aggregator，它对齐来自不同二维基础模型的特征；3D Interpreter with Zero-Embedding Mapping，它缓解了从二维到三维知识迁移中的灾难性遗忘。实验结果验证了我们的DetAny3D强大的泛化能力，它不仅在未见类别和新型相机配置上实现了最先进的性能，而且在领域数据上也超越了大多数竞争对手。DetAny3D揭示了三维基础模型在现实场景中多样化应用的潜力，例如自动驾驶中的稀有物体检测，并展示了在开放世界环境中进一步探索以三维为中心的任务的前景。更多信息可在DetAny3D项目页面上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the success of deep learning in close-set 3D object detection,existing approaches struggle with zero-shot generalization to novel objects andcamera configurations. We introduce DetAny3D, a promptable 3D detectionfoundation model capable of detecting any novel object under arbitrary cameraconfigurations using only monocular inputs. Training a foundation model for 3Ddetection is fundamentally constrained by the limited availability of annotated3D data, which motivates DetAny3D to leverage the rich prior knowledge embeddedin extensively pre-trained 2D foundation models to compensate for thisscarcity. To effectively transfer 2D knowledge to 3D, DetAny3D incorporates twocore modules: the 2D Aggregator, which aligns features from different 2Dfoundation models, and the 3D Interpreter with Zero-Embedding Mapping, whichmitigates catastrophic forgetting in 2D-to-3D knowledge transfer. Experimentalresults validate the strong generalization of our DetAny3D, which not onlyachieves state-of-the-art performance on unseen categories and novel cameraconfigurations, but also surpasses most competitors on in-domain data.DetAny3Dsheds light on the potential of the 3D foundation model for diverseapplications in real-world scenarios, e.g., rare object detection in autonomousdriving, and demonstrates promise for further exploration of 3D-centric tasksin open-world settings. More visualization results can be found at DetAny3Dproject page.</description>
      <author>example@mail.com (Hanxue Zhang, Haoran Jiang, Qingsong Yao, Yanan Sun, Renrui Zhang, Hao Zhao, Hongyang Li, Hongzi Zhu, Zetong Yang)</author>
      <guid isPermaLink="false">2504.07958v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Focal Cortical Dysplasia Type II Detection Using Cross Modality Transfer Learning and Grad-CAM in 3D-CNNs for MRI Analysis</title>
      <link>http://arxiv.org/abs/2504.07775v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了使用3D卷积神经网络（3D-CNNs）检测FCD（Focal cortical dysplasia，局灶性皮质发育不良）II型，并评估了跨模态迁移学习和可解释人工智能（XAI）技术，特别是Grad-CAM（梯度加权类激活映射）在提高诊断准确性和可解释性方面的益处。&lt;h4&gt;背景&lt;/h4&gt;FCD II型是难治性癫痫的主要原因，通常只能通过手术治愈。由于MRI检查中FCD的细微异常，其诊断非常困难，导致误诊。&lt;h4&gt;目的&lt;/h4&gt;研究使用3D-CNNs检测FCD，并评估跨模态迁移学习和XAI技术，特别是Grad-CAM在提高诊断准确性和可解释性方面的效果。&lt;h4&gt;方法&lt;/h4&gt;使用包含170个受试者（85名FCD患者和85名对照组）的数据集，其中包含T1加权和FLAIR MRI扫描，实施了ResNet架构（ResNet-18、-34和-50），并采用了使用预训练权重的迁移学习策略。&lt;h4&gt;主要发现&lt;/h4&gt;迁移学习显著提高了分类准确率（高达80.3%）和可解释性，通过一个名为Heat-Score的新度量标准来衡量，该标准评估模型对临床相关区域的关注。Heat-Score度量标准的改进强调了模型在癫痫区定位方面的能力，使AI预测和临床见解更接近。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，迁移学习，包括跨模态，以及XAI在推进基于AI的医学诊断方面的重要性，特别是对于像FCD这样的难以诊断的疾病。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Focal cortical dysplasia (FCD) type II is a major cause of drug-resistantepilepsy, often curable only by surgery. Despite its clinical importance, thediagnosis of FCD is very difficult in MRI because of subtle abnormalities,leading to misdiagnosis. This study investigates the use of 3D convolutionalneural networks (3D-CNNs) for FCD detection, using a dataset of 170 subjects(85 FCD patients and 85 controls) composed of T1-weighted and FLAIR MRI scans.In particular, it investigates the benefits obtained from cross-modalitytransfer learning and explainable artificial intelligence (XAI) techniques, inparticular Gradient-weighted Class Activation Mapping (Grad-CAM). ResNetarchitectures (ResNet-18, -34, and -50) were implemented, employing transferlearning strategies that used pre-trained weights from segmentation tasks.Results indicate that transfer learning significantly enhances classificationaccuracy (up to 80.3%) and interpretability, as measured by a novel Heat-Scoremetric, which evaluates the model's focus on clinically relevant regions.Improvements in the Heat-Score metric underscore the model's seizure zonelocalization capabilities, bringing AI predictions and clinical insights closertogether. These results highlight the importance of transfer learning,including cross-modality, and XAI in advancing AI-based medical diagnostics,especially for difficult-to-diagnose pathologies such as FCD.</description>
      <author>example@mail.com (Lorenzo Lasagni, Antonio Ciccarone, Renzo Guerrini, Matteo Lenge, Ludovico D'incerti)</author>
      <guid isPermaLink="false">2504.07775v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>GLUS: Global-Local Reasoning Unified into A Single Large Language Model for Video Segmentation</title>
      <link>http://arxiv.org/abs/2504.07962v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，利用多模态大型语言模型（MLLMs）进行参考视频对象分割（RefVOS），在MeViS和Ref-Youtube-VOS基准测试上实现了MLLMs的新突破。&lt;h4&gt;背景&lt;/h4&gt;以往基于MLLM的方法在“参考”和“视频对象分割”（VOS）之间存在困境，要么专注于理解几个关键帧（全局推理），要么在连续帧上跟踪对象（局部推理），并且依赖外部VOS或帧选择器来缓解另一方面的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，旨在解决MLLMs在RefVOS中的“参考”和“VOS”之间的矛盾，并提高分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出的框架GLUS将全局和局部一致性统一到单个视频分割MLLM中，使用稀疏的“上下文帧”提供全局信息，同时使用连续的“查询帧”进行局部对象跟踪。此外，通过与预训练的VOS记忆库联合训练，同时处理短程和长程时间信息。为了提高MLLMs在有限上下文窗口中的信息效率，引入了对象对比学习来区分硬性误报对象，并提出了自我精炼框架来识别关键帧并进行传播。&lt;h4&gt;主要发现&lt;/h4&gt;GLUS框架通过综合上述方法，提供了一种简单而有效的基准，在MeViS和Ref-Youtube-VOS基准测试上实现了MLLMs的新突破。&lt;h4&gt;结论&lt;/h4&gt;GLUS框架为MLLMs在RefVOS任务上提供了一个高效且准确的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的框架，利用多模态大型语言模型（MLLMs）进行参考视频对象分割（RefVOS）。以往基于MLLM的方法通常难以平衡“参考”和“视频对象分割”（VOS）之间的矛盾：它们要么专注于理解几个关键帧（全局推理），要么在连续帧上跟踪对象（局部推理），并且依赖外部VOS或帧选择器来缓解另一方面的挑战。然而，我们的框架GLUS表明，全局和局部一致性可以统一到一个视频分割MLLM中：一组稀疏的“上下文帧”提供全局信息，而连续的“查询帧”进行局部对象跟踪。这一点通过联合训练MLLM与预训练的VOS记忆库得到进一步支持，以同时处理短程和长程时间信息。为了提高MLLMs在有限上下文窗口中的信息效率，我们引入了对象对比学习来区分硬性误报对象，并提出了自我精炼框架来识别关键帧并进行传播。通过综合这些见解，我们的GLUS提供了一种简单而有效的基准，在MeViS和Ref-Youtube-VOS基准测试上实现了MLLMs的新突破。我们的项目页面在https://glus-video.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a novel framework utilizing multi-modal large languagemodels (MLLMs) for referring video object segmentation (RefVOS). PreviousMLLM-based methods commonly struggle with the dilemma between "Ref" and "VOS":they either specialize in understanding a few key frames (global reasoning) ortracking objects on continuous frames (local reasoning), and rely on externalVOS or frame selectors to mitigate the other end of the challenge. However, ourframework GLUS shows that global and local consistency can be unified into asingle video segmentation MLLM: a set of sparse "context frames" providesglobal information, while a stream of continuous "query frames" conducts localobject tracking. This is further supported by jointly training the MLLM with apre-trained VOS memory bank to simultaneously digest short-range and long-rangetemporal information. To improve the information efficiency within the limitedcontext window of MLLMs, we introduce object contrastive learning todistinguish hard false-positive objects and a self-refined framework toidentify crucial frames and perform propagation. By collectively integratingthese insights, our GLUS delivers a simple yet effective baseline, achievingnew state-of-the-art for MLLMs on the MeViS and Ref-Youtube-VOS benchmark. Ourproject page is at https://glus-video.github.io/.</description>
      <author>example@mail.com (Lang Lin, Xueyang Yu, Ziqi Pang, Yu-Xiong Wang)</author>
      <guid isPermaLink="false">2504.07962v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>WS-DETR: Robust Water Surface Object Detection through Vision-Radar Fusion with Detection Transformer</title>
      <link>http://arxiv.org/abs/2504.07441v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种鲁棒的视觉-雷达融合模型WS-DETR，用于解决无人水面舰艇在复杂水域中对象检测的挑战。&lt;h4&gt;背景&lt;/h4&gt;在复杂水域环境中，水面对象检测面临模糊边缘和多样化目标尺度的挑战。&lt;h4&gt;目的&lt;/h4&gt;为了提高模型在复杂环境中的鲁棒性，提出了一种新的视觉-雷达融合模型。&lt;h4&gt;方法&lt;/h4&gt;该方法包括：1. 引入多尺度边缘信息集成(MSEII)模块和分层特征聚合(HiFA)模块来增强边缘感知和提升多尺度目标检测能力；2. 使用自移动点表示和连续卷积及残差连接有效提取不规则点云数据下的不规则特征；3. 引入自适应特征交互融合(AFIF)模块通过几何对齐和语义融合来减少跨模态冲突。&lt;h4&gt;主要发现&lt;/h4&gt;在WaterScenes数据集上的大量实验表明，WS-DETR达到了最先进的性能，即使在恶劣的天气和光照条件下也保持着其优越性。&lt;h4&gt;结论&lt;/h4&gt;WS-DETR模型为无人水面舰艇在复杂水域中的鲁棒对象检测提供了一种有效解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust object detection for Unmanned Surface Vehicles (USVs) in complex waterenvironments is essential for reliable navigation and operation. Specifically,water surface object detection faces challenges from blurred edges and diverseobject scales. Although vision-radar fusion offers a feasible solution,existing approaches suffer from cross-modal feature conflicts, which negativelyaffect model robustness. To address this problem, we propose a robustvision-radar fusion model WS-DETR. In particular, we first introduce aMulti-Scale Edge Information Integration (MSEII) module to enhance edgeperception and a Hierarchical Feature Aggregator (HiFA) to boost multi-scaleobject detection in the encoder. Then, we adopt self-moving pointrepresentations for continuous convolution and residual connection toefficiently extract irregular features under the scenarios of irregular pointcloud data. To further mitigate cross-modal conflicts, an Adaptive FeatureInteractive Fusion (AFIF) module is introduced to integrate visual and radarfeatures through geometric alignment and semantic fusion. Extensive experimentson the WaterScenes dataset demonstrate that WS-DETR achieves state-of-the-art(SOTA) performance, maintaining its superiority even under adverse weather andlighting conditions.</description>
      <author>example@mail.com (Huilin Yin, Pengyu Wang, Senmao Li, Jun Yan, Daniel Watzenig)</author>
      <guid isPermaLink="false">2504.07441v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>A Pointcloud Registration Framework for Relocalization in Subterranean Environments</title>
      <link>http://arxiv.org/abs/2504.07231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种利用点云注册的鲁棒、计算友好的重定位框架，用于在地下环境中重建机器人位置，以提高导航和任务执行的准确性。&lt;h4&gt;背景&lt;/h4&gt;在地下环境中，由于外部定位信息有限、光线条件差、表面不规则以及尘埃等因素，重定位面临挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种适用于地下矿井和隧道中自主机器人的重定位方法。&lt;h4&gt;方法&lt;/h4&gt;该方法使用先验点云图，通过Intrinsic Shape Signatures (ISS)选择特征点，利用Fast Point Feature Histogram (FPFH)算法创建描述符，并通过匹配这些描述符来获取点云之间的对应关系。然后，使用匹配点估计3D变换，初始化Normal Distribution Transform (NDT)注册。最后，使用迭代最近点（ICP）注册算法进一步优化变换结果。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在尘土干扰和目标与源之间有显著初始变换的复杂条件下，提高了注册精度。&lt;h4&gt;结论&lt;/h4&gt;通过模拟和真实世界矿井数据集的实验验证了该框架在提高重定位方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Relocalization, the process of re-establishing a robot's position within an environment, is crucial for ensuring accurate navigation and task execution when external positioning information, such as GPS, is unavailable or has been lost. Subterranean environments present significant challenges for relocalization due to limited external positioning information, poor lighting that affects camera localization, irregular and often non-distinct surfaces, and dust, which can introduce noise and occlusion in sensor data. In this work, we propose a robust, computationally friendly framework for relocalization through point cloud registration utilizing a prior point cloud map. The framework employs Intrinsic Shape Signatures (ISS) to select feature points in both the target and prior point clouds. The Fast Point Feature Histogram (FPFH) algorithm is utilized to create descriptors for these feature points, and matching these descriptors yields correspondences between the point clouds. A 3D transformation is estimated using the matched points, which initializes a Normal Distribution Transform (NDT) registration. The transformation result from NDT is further refined using the Iterative Closest Point (ICP) registration algorithm. This framework enhances registration accuracy even in challenging conditions, such as dust interference and significant initial transformations between the target and source, making it suitable for autonomous robots operating in underground mines and tunnels. This framework was validated with experiments in simulated and real-world mine datasets, demonstrating its potential for improving relocalization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Relocalization, the process of re-establishing a robot's position within anenvironment, is crucial for ensuring accurate navigation and task executionwhen external positioning information, such as GPS, is unavailable or has beenlost. Subterranean environments present significant challenges forrelocalization due to limited external positioning information, poor lightingthat affects camera localization, irregular and often non-distinct surfaces,and dust, which can introduce noise and occlusion in sensor data. In this work,we propose a robust, computationally friendly framework for relocalizationthrough point cloud registration utilizing a prior point cloud map. Theframework employs Intrinsic Shape Signatures (ISS) to select feature points inboth the target and prior point clouds. The Fast Point Feature Histogram (FPFH)algorithm is utilized to create descriptors for these feature points, andmatching these descriptors yields correspondences between the point clouds. A3D transformation is estimated using the matched points, which initializes aNormal Distribution Transform (NDT) registration. The transformation resultfrom NDT is further refined using the Iterative Closest Point (ICP)registration algorithm. This framework enhances registration accuracy even inchallenging conditions, such as dust interference and significant initialtransformations between the target and source, making it suitable forautonomous robots operating in underground mines and tunnels. This frameworkwas validated with experiments in simulated and real-world mine datasets,demonstrating its potential for improving relocalization.</description>
      <author>example@mail.com (David Akhihiero, Jason N. Gross)</author>
      <guid isPermaLink="false">2504.07231v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal Reference Learning for Fine-grained Text-to-Image Retrieval</title>
      <link>http://arxiv.org/abs/2504.07718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  TMM25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多模态参考学习的细粒度文本到图像检索方法，旨在通过学习更鲁棒的特征表示来提高检索精度。&lt;h4&gt;背景&lt;/h4&gt;现有的文本到图像检索方法通常假设训练图像能够被其文本描述准确描绘，但文本描述可能存在歧义，无法充分描述图像中的判别性视觉细节，导致学习到的表示不准确。&lt;h4&gt;目的&lt;/h4&gt;为了缓解文本歧义的影响，提出了一种多模态参考学习方法，以学习更鲁棒的特征表示。&lt;h4&gt;方法&lt;/h4&gt;首先，提出了一种多模态参考构建模块，用于聚合同一对象的全部视觉和文本细节，形成一个全面的多模态参考。接着，提出了一种参考引导的表示学习模块，使用多模态参考来学习更准确的视觉和文本表示。此外，还引入了一种基于参考的细化方法，利用对象参考计算基于参考的相似度，以细化初始检索结果。&lt;h4&gt;主要发现&lt;/h4&gt;在五个细粒度文本到图像检索数据集上进行了广泛的实验，结果表明，该方法在检索性能上优于现有方法。例如，在RSTPReid文本到人物图像检索数据集上，该方法实现了56.2%的Rank1准确率，超过了最近提出的CFine方法5.6个百分点。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在细粒度文本到图像检索任务中表现出色，能够有效提高检索精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TMM.2025.3543066&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-grained text-to-image retrieval aims to retrieve a fine-grained targetimage with a given text query. Existing methods typically assume that eachtraining image is accurately depicted by its textual descriptions. However,textual descriptions can be ambiguous and fail to depict discriminative visualdetails in images, leading to inaccurate representation learning. To alleviatethe effects of text ambiguity, we propose a Multi-Modal Reference learningframework to learn robust representations. We first propose a multi-modalreference construction module to aggregate all visual and textual details ofthe same object into a comprehensive multi-modal reference. The multi-modalreference hence facilitates the subsequent representation learning andretrieval similarity computation. Specifically, a reference-guidedrepresentation learning module is proposed to use multi-modal references tolearn more accurate visual and textual representations. Additionally, weintroduce a reference-based refinement method that employs the objectreferences to compute a reference-based similarity that refines the initialretrieval results. Extensive experiments are conducted on five fine-grainedtext-to-image retrieval datasets for different text-to-image retrieval tasks.The proposed method has achieved superior performance over state-of-the-artmethods. For instance, on the text-to-person image retrieval dataset RSTPReid,our method achieves the Rank1 accuracy of 56.2\%, surpassing the recent CFineby 5.6\%.</description>
      <author>example@mail.com (Zehong Ma, Hao Chen, Wei Zeng, Limin Su, Shiliang Zhang)</author>
      <guid isPermaLink="false">2504.07718v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Trading Graph Neural Network</title>
      <link>http://arxiv.org/abs/2504.07923v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的算法——交易图神经网络（TGNN），该算法能够结构性地估计资产特征、交易商特征和关系特征对交易网络中资产价格的影响。&lt;h4&gt;背景&lt;/h4&gt;将传统的模拟方法与最近机器学习技术——图神经网络（GNN）相结合。&lt;h4&gt;目的&lt;/h4&gt;提高预测准确性，并在具有任何结构的网络中应用，允许交易者和资产之间的异质性。&lt;h4&gt;方法&lt;/h4&gt;TGNN算法结合了模拟方法（SMM）和图神经网络（GNN）的优点。&lt;h4&gt;主要发现&lt;/h4&gt;TGNN在预测准确性上优于现有的使用网络中心度测量的降阶方法。&lt;h4&gt;结论&lt;/h4&gt;TGNN算法在处理具有不同结构的网络时表现出色，能够处理交易者和资产之间的异质性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a new algorithm -- Trading Graph Neural Network (TGNN) that can structurally estimate the impact of asset features, dealer features and relationship features on asset prices in trading networks. It combines the strength of the traditional simulated method of moments (SMM) and recent machine learning techniques -- Graph Neural Network (GNN). It outperforms existing reduced-form methods with network centrality measures in prediction accuracy. The method can be used on networks with any structure, allowing for heterogeneity among both traders and assets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a new algorithm -- Trading Graph Neural Network (TGNN)that can structurally estimate the impact of asset features, dealer featuresand relationship features on asset prices in trading networks. It combines thestrength of the traditional simulated method of moments (SMM) and recentmachine learning techniques -- Graph Neural Network (GNN). It outperformsexisting reduced-form methods with network centrality measures in predictionaccuracy. The method can be used on networks with any structure, allowing forheterogeneity among both traders and assets.</description>
      <author>example@mail.com (Xian Wu)</author>
      <guid isPermaLink="false">2504.07923v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>We Are All Creators: Generative AI, Collective Knowledge, and the Path Towards Human-AI Synergy</title>
      <link>http://arxiv.org/abs/2504.07936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了生成式人工智能对传统人类独特性的挑战，特别是在创造力方面，并提出了人工智能作为一种新型智能和创造力的观点。&lt;h4&gt;背景&lt;/h4&gt;生成式人工智能通过神经网络基础模型展现出强大的内容生成能力，引发了关于作者权、版权和智能本身的激烈辩论。&lt;h4&gt;目的&lt;/h4&gt;文章旨在分析生成式人工智能的本质和影响，并探讨其与人类创造力的关系。&lt;h4&gt;方法&lt;/h4&gt;通过比较人工神经网络和生物神经网络的差异，分析了人工智能的学习过程，并从知识的角度探讨了人工智能创作的伦理问题。&lt;h4&gt;主要发现&lt;/h4&gt;生成式人工智能通过数学模式合成进行内容生成，而非生物理解或文字复制。人工智能的学习主要是从大量数据中提取统计模式。&lt;h4&gt;结论&lt;/h4&gt;文章建议人类与人工智能协同合作，利用人工智能作为辅助工具，以实现创新、民主化创造性表达和解决复杂挑战。同时，应关注人工智能工具的公平获取，以防止社会分化的加剧。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成式人工智能对传统的独特人类观念，特别是在创造力方面，提出了深刻的挑战。受基于神经网络的底层模型驱动，这些系统展示了惊人的内容生成能力，引发了关于作者权、版权和智能本身的激烈辩论。本文认为，生成式人工智能代表了一种新型的智能和创造力，它通过数学模式合成而不是生物理解或文字复制来运作。人工神经网络与生物神经网络之间的基本差异揭示了人工智能的学习主要是从大量数据中提取统计模式，这些模式是人类知识集体智慧的结晶。这种观点复杂化了版权盗窃的叙述，并突出了将人工智能输出归因于个人来源的实际挑战。我们主张追求人类与人工智能的协同合作，而不是追求可能徒劳的法律限制。通过将生成式人工智能视为人类直觉、情境和伦理判断的补充工具，社会可以解锁前所未有的创新，民主化创造性表达，并解决复杂挑战。这种基于对人工智能能力和局限性的现实理解的协作方法，提供了最有前景的前进道路。此外，将这些模型视为集体人类知识的产物，也提出了关于可访问性的伦理问题，确保这些工具的公平获取可以防止社会分歧的扩大，并充分利用它们的集体利益。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative AI presents a profound challenge to traditional notions of humanuniqueness, particularly in creativity. Fueled by neural network basedfoundation models, these systems demonstrate remarkable content generationcapabilities, sparking intense debates about authorship, copyright, andintelligence itself. This paper argues that generative AI represents analternative form of intelligence and creativity, operating through mathematicalpattern synthesis rather than biological understanding or verbatim replication.The fundamental differences between artificial and biological neural networksreveal AI learning as primarily statistical pattern extraction from vastdatasets crystallized forms of collective human knowledge scraped from theinternet. This perspective complicates copyright theft narratives andhighlights practical challenges in attributing AI outputs to individualsources. Rather than pursuing potentially futile legal restrictions, weadvocate for human AI synergy. By embracing generative AI as a complementarytool alongside human intuition, context, and ethical judgment, society canunlock unprecedented innovation, democratize creative expression, and addresscomplex challenges. This collaborative approach, grounded in realisticunderstanding of AIs capabilities and limitations, offers the most promisingpath forward. Additionally, recognizing these models as products of collectivehuman knowledge raises ethical questions about accessibility ensuring equitableaccess to these tools could prevent widening societal divides and leveragetheir full potential for collective benefit.</description>
      <author>example@mail.com (Jordi Linares-Pellicer, Juan Izquierdo-Domenech, Isabel Ferri-Molla, Carlos Aliaga-Torro)</author>
      <guid isPermaLink="false">2504.07936v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>DGOcc: Depth-aware Global Query-based Network for Monocular 3D Occupancy Prediction</title>
      <link>http://arxiv.org/abs/2504.07524v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DGOcc的深度感知全局查询网络，用于单目3D占用预测，以解决从2D图像中预测大规模室外场景的3D占用问题。&lt;h4&gt;背景&lt;/h4&gt;单目3D占用预测在3D场景理解中扮演着重要角色，但其从2D图像预测大场景3D占用的过程既不明确又资源密集。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的方法来预测单目图像中3D场景的占用和语义。&lt;h4&gt;方法&lt;/h4&gt;DGOcc网络首先利用先前的深度图提取深度上下文特征，以提供占用网络的明确几何信息。然后，提出一个全局查询模块（GQ）来充分利用深度上下文特征。此外，还设计了一种分层监督策略（HSS），以避免将高维3D体素特征上采样到全分辨率，从而降低GPU内存利用率和时间成本。&lt;h4&gt;主要发现&lt;/h4&gt;在SemanticKITTI和SSCBench-KITTI-360数据集上进行的实验表明，该方法在单目语义占用预测方面取得了最佳性能，同时减少了GPU和时间开销。&lt;h4&gt;结论&lt;/h4&gt;DGOcc网络为单目3D占用预测提供了一种高效且性能优越的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular 3D occupancy prediction, aiming to predict the occupancy andsemantics within interesting regions of 3D scenes from only 2D images, hasgarnered increasing attention recently for its vital role in 3D sceneunderstanding. Predicting the 3D occupancy of large-scale outdoor scenes from2D images is ill-posed and resource-intensive. In this paper, we present\textbf{DGOcc}, a \textbf{D}epth-aware \textbf{G}lobal query-based network formonocular 3D \textbf{Occ}upancy prediction. We first explore prior depth mapsto extract depth context features that provide explicit geometric informationfor the occupancy network. Then, in order to fully exploit the depth contextfeatures, we propose a Global Query-based (GQ) Module. The cooperation ofattention mechanisms and scale-aware operations facilitates the featureinteraction between images and 3D voxels. Moreover, a Hierarchical SupervisionStrategy (HSS) is designed to avoid upsampling the high-dimension 3D voxelfeatures to full resolution, which mitigates GPU memory utilization and timecost. Extensive experiments on SemanticKITTI and SSCBench-KITTI-360 datasetsdemonstrate that the proposed method achieves the best performance on monocularsemantic occupancy prediction while reducing GPU and time overhead.</description>
      <author>example@mail.com (Xu Zhao, Pengju Zhang, Bo Liu, Yihong Wu)</author>
      <guid isPermaLink="false">2504.07524v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>SF2T: Self-supervised Fragment Finetuning of Video-LLMs for Fine-Grained Understanding</title>
      <link>http://arxiv.org/abs/2504.07745v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Video-LLMs在视频理解方面的进展，并提出了Self-Supervised Fragment Fine-Tuning（SF$^2$T）和FineVidBench数据集，以提升Video-LLMs的细粒度视频理解能力。&lt;h4&gt;背景&lt;/h4&gt;Video-LLMs在视频整体描述方面表现出色，但在细粒度理解方面，如视觉动态和视频细节查询上存在困难。&lt;h4&gt;目的&lt;/h4&gt;针对Video-LLMs的不足，提出新的方法来提升其细粒度视频理解能力。&lt;h4&gt;方法&lt;/h4&gt;1. 提出Self-Supervised Fragment Fine-Tuning（SF$^2$T），该方法利用视频的内在特性进行训练，同时提高Video-LLMs的细粒度理解能力，并减少对人工标注的依赖。2. 构建了FineVidBench数据集，用于严格评估Video-LLMs在场景和片段层面的性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SF$^2$T方法能够提升Video-LLMs捕捉和解释时空细节的能力。&lt;h4&gt;结论&lt;/h4&gt;SF$^2$T和FineVidBench数据集为提升Video-LLMs的细粒度视频理解能力提供了有效的方法和工具。&lt;h4&gt;翻译&lt;/h4&gt;Video-based Large Language Models (Video-LLMs) have witnessed substantial advancements in recent years, propelled by the advancement in multi-modal LLMs. Although these models have demonstrated proficiency in providing the overall description of videos, they struggle with fine-grained understanding, particularly in aspects such as visual dynamics and video details inquiries. To tackle these shortcomings, we find that fine-tuning Video-LLMs on self-supervised fragment tasks, greatly improve their fine-grained video understanding abilities. Hence we propose two key contributions: (1) Self-Supervised Fragment Fine-Tuning (SF$^2$T), a novel effortless fine-tuning method, employs the rich inherent characteristics of videos for training, while unlocking more fine-grained understanding ability of Video-LLMs. Moreover, it relieves researchers from labor-intensive annotations and smartly circumvents the limitations of natural language, which often fails to capture the complex spatiotemporal variations in videos; (2) A novel benchmark dataset, namely FineVidBench, for rigorously assessing Video-LLMs' performance at both the scene and fragment levels, offering a comprehensive evaluation of their capabilities. We assessed multiple models and validated the effectiveness of SF$^2$T on them. Experimental results reveal that our approach improves their ability to capture and interpret spatiotemporal details.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video-based Large Language Models (Video-LLMs) have witnessed substantialadvancements in recent years, propelled by the advancement in multi-modal LLMs.Although these models have demonstrated proficiency in providing the overalldescription of videos, they struggle with fine-grained understanding,particularly in aspects such as visual dynamics and video details inquiries. Totackle these shortcomings, we find that fine-tuning Video-LLMs onself-supervised fragment tasks, greatly improve their fine-grained videounderstanding abilities. Hence we propose two key contributions:(1)Self-Supervised Fragment Fine-Tuning (SF$^2$T), a novel effortless fine-tuningmethod, employs the rich inherent characteristics of videos for training, whileunlocking more fine-grained understanding ability of Video-LLMs. Moreover, itrelieves researchers from labor-intensive annotations and smartly circumventsthe limitations of natural language, which often fails to capture the complexspatiotemporal variations in videos; (2) A novel benchmark dataset, namelyFineVidBench, for rigorously assessing Video-LLMs' performance at both thescene and fragment levels, offering a comprehensive evaluation of theircapabilities. We assessed multiple models and validated the effectiveness ofSF$^2$T on them. Experimental results reveal that our approach improves theirability to capture and interpret spatiotemporal details.</description>
      <author>example@mail.com (Yangliu Hu, Zikai Song, Na Feng, Yawei Luo, Junqing Yu, Yi-Ping Phoebe Chen, Wei Yang)</author>
      <guid isPermaLink="false">2504.07745v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Merging Embedded Topics with Optimal Transport for Online Topic Modeling on Data Streams</title>
      <link>http://arxiv.org/abs/2504.07711v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为StreamETM的在线主题建模新方法，用于处理文本数据流。&lt;h4&gt;背景&lt;/h4&gt;随着社交媒体的快速发展，每天产生的文本数据量巨大，需要在线主题建模方法来管理这些持续流入的数据流。&lt;h4&gt;目的&lt;/h4&gt;介绍StreamETM方法，该方法基于嵌入式主题模型（ETM）并通过不平衡最优传输合并连续的文档批次模型，同时采用在线变化点检测算法来识别主题随时间的变化。&lt;h4&gt;方法&lt;/h4&gt;StreamETM方法利用不平衡最优传输合并模型，并采用在线变化点检测算法来处理数据流。&lt;h4&gt;主要发现&lt;/h4&gt;StreamETM在模拟和真实世界数据上的数值实验中表现优于竞争对手。&lt;h4&gt;结论&lt;/h4&gt;StreamETM是一种有效的在线主题建模方法，能够处理数据流并识别文本流中的重大变化。&lt;h4&gt;翻译&lt;/h4&gt;摘要：主题建模是无监督学习的关键组成部分，用于在文本数据集中识别主题。社交媒体的快速增长每天产生大量文本数据，使得在线主题建模方法对于管理这些随时间持续到达的数据流至关重要。本文介绍了一种名为StreamETM的在线主题建模新方法。该方法基于嵌入式主题模型（ETM）通过不平衡最优传输合并连续的文档批次模型。此外，还采用了一种在线变化点检测算法来识别主题随时间的变化，从而能够识别文本流动态中的重大变化。在模拟和真实世界数据上的数值实验表明，StreamETM优于竞争对手。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Topic modeling is a key component in unsupervised learning, employed toidentify topics within a corpus of textual data. The rapid growth of socialmedia generates an ever-growing volume of textual data daily, making onlinetopic modeling methods essential for managing these data streams thatcontinuously arrive over time. This paper introduces a novel approach to onlinetopic modeling named StreamETM. This approach builds on the Embedded TopicModel (ETM) to handle data streams by merging models learned on consecutivepartial document batches using unbalanced optimal transport. Additionally, anonline change point detection algorithm is employed to identify shifts intopics over time, enabling the identification of significant changes in thedynamics of text streams. Numerical experiments on simulated and real-worlddata show StreamETM outperforming competitors.</description>
      <author>example@mail.com (Federica Granese, Benjamin Navet, Serena Villata, Charles Bouveyron)</author>
      <guid isPermaLink="false">2504.07711v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Novel Diffusion Models for Multimodal 3D Hand Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2504.07375v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MMTwin的新型扩散模型，用于多模态3D手部轨迹预测，旨在解决现有方法在处理多模态信息、手部运动与头部摄像机运动协同预测等方面的不足。&lt;h4&gt;背景&lt;/h4&gt;现有的手部轨迹预测方法主要针对2D自视角视频输入，缺乏对多模态环境信息的感知，且未考虑手部运动与头部摄像机运动的协同性。&lt;h4&gt;目的&lt;/h4&gt;提出MMTwin模型，旨在提高3D手部轨迹预测的性能，并使其能够处理多模态信息，同时预测手部轨迹和头部摄像机运动。&lt;h4&gt;方法&lt;/h4&gt;MMTwin模型能够整合2D RGB图像、3D点云、过去的手部轨迹点和文本提示等多模态信息作为输入。模型包含两个潜在的扩散模型，即头部摄像机运动扩散和手部轨迹预测扩散，用于同时预测头部摄像机运动和未来手部轨迹。此外，还提出了一种新的混合Mamba-Transformer模块作为手部轨迹预测扩散的降噪模型，以更好地融合多模态特征。&lt;h4&gt;主要发现&lt;/h4&gt;在三个公开数据集和自录数据上的实验结果表明，MMTwin模型相比现有基准方法，能够预测更合理的手部轨迹，并且具有良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;MMTwin模型在3D手部轨迹预测方面取得了显著成果，并为未来研究提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：预测手部运动对于理解人类意图和建立人类运动与机器人操作之间的动作空间至关重要。现有的手部轨迹预测（HTP）方法在3D空间中基于过去的自视角观察预测未来的手部路径点。然而，这些模型仅设计用于处理2D自视角视频输入。缺乏从2D和3D观察中感知多模态环境信息，阻碍了3D HTP性能的进一步改进。此外，这些模型忽略了手部运动与头部摄像机运动的协同性，要么单独预测手部轨迹，要么仅从过去帧中编码头部摄像机运动。为了解决这些限制，我们提出了用于多模态3D手部轨迹预测的新型扩散模型（MMTwin）。MMTwin被设计为吸收包括2D RGB图像、3D点云、过去的手部路径点和文本提示在内的多模态信息作为输入。此外，将两个潜在的扩散模型，即头部摄像机运动扩散和手部轨迹预测扩散作为双胞胎整合到MMTwin中，以同时预测头部摄像机运动和未来手部轨迹。我们提出了一种新的混合Mamba-Transformer模块作为手部轨迹预测扩散的降噪模型，以更好地融合多模态特征。在三个公开数据集和我们的自录数据上的实验结果表明，我们提出的MMTwin与最先进的基准相比，可以预测合理的手部轨迹，并且具有良好的泛化能力。代码和预训练模型将在https://github.com/IRMVLab/MMTwin发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting hand motion is critical for understanding human intentions andbridging the action space between human movements and robot manipulations.Existing hand trajectory prediction (HTP) methods forecast the future handwaypoints in 3D space conditioned on past egocentric observations. However,such models are only designed to accommodate 2D egocentric video inputs. Thereis a lack of awareness of multimodal environmental information from both 2D and3D observations, hindering the further improvement of 3D HTP performance. Inaddition, these models overlook the synergy between hand movements and headsetcamera egomotion, either predicting hand trajectories in isolation or encodingegomotion only from past frames. To address these limitations, we propose noveldiffusion models (MMTwin) for multimodal 3D hand trajectory prediction. MMTwinis designed to absorb multimodal information as input encompassing 2D RGBimages, 3D point clouds, past hand waypoints, and text prompt. Besides, twolatent diffusion models, the egomotion diffusion and the HTP diffusion astwins, are integrated into MMTwin to predict camera egomotion and future handtrajectories concurrently. We propose a novel hybrid Mamba-Transformer moduleas the denoising model of the HTP diffusion to better fuse multimodal features.The experimental results on three publicly available datasets and ourself-recorded data demonstrate that our proposed MMTwin can predict plausiblefuture 3D hand trajectories compared to the state-of-the-art baselines, andgeneralizes well to unseen environments. The code and pretrained models will bereleased at https://github.com/IRMVLab/MMTwin.</description>
      <author>example@mail.com (Junyi Ma, Wentao Bao, Jingyi Xu, Guanzhong Sun, Xieyuanli Chen, Hesheng Wang)</author>
      <guid isPermaLink="false">2504.07375v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Image Embeddings for E-Commerce: Evaluating Off-the Shelf Foundation Models, Fine-Tuning Strategies and Practical Trade-offs</title>
      <link>http://arxiv.org/abs/2504.07567v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted at Future Technologies Conference (FTC 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究对电子商务中用于分类和检索的基础模型图像嵌入进行了基准测试，评估其在现实世界应用中的适用性。&lt;h4&gt;背景&lt;/h4&gt;研究涵盖了通过监督学习、自监督学习和文本-图像对比学习训练的预训练卷积和转换模型嵌入。&lt;h4&gt;目的&lt;/h4&gt;评估全微调和迁移学习（top-tuning）在六个不同的电子商务数据集（时尚、消费品、汽车、食品和零售）上的表现。&lt;h4&gt;方法&lt;/h4&gt;评估了全微调、迁移学习（top-tuning）和跨调优在多个数据集上的效果，并分析了不同类型嵌入的表现。&lt;h4&gt;主要发现&lt;/h4&gt;全微调表现一致良好；文本-图像和自监督嵌入可以以较少的训练量匹配其性能；监督嵌入在架构上保持稳定，而SSL和对比嵌入则因top-tuning而显著改善；top-tuning成为全微调的高效替代方案，降低了计算成本；跨调优的影响取决于数据集特征。&lt;h4&gt;结论&lt;/h4&gt;研究结果为嵌入选择和微调策略提供了实用性指导，平衡了效率和性能。&lt;h4&gt;翻译&lt;/h4&gt;本研究对电子商务中用于分类和检索的基础模型图像嵌入进行了基准测试，评估其在现实世界应用中的适用性。研究涵盖了通过监督学习、自监督学习和文本-图像对比学习训练的预训练卷积和转换模型嵌入。评估了全微调和迁移学习（top-tuning）在六个不同的电子商务数据集（时尚、消费品、汽车、食品和零售）上的表现。评估了全微调、迁移学习（top-tuning）和跨调优在多个数据集上的效果，并分析了不同类型嵌入的表现。全微调表现一致良好；文本-图像和自监督嵌入可以以较少的训练量匹配其性能；监督嵌入在架构上保持稳定，而SSL和对比嵌入则因top-tuning而显著改善；top-tuning成为全微调的高效替代方案，降低了计算成本；跨调优的影响取决于数据集特征。研究结果为嵌入选择和微调策略提供了实用性指导，平衡了效率和性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We benchmark foundation models image embeddings for classification andretrieval in e-Commerce, evaluating their suitability for real-worldapplications. Our study spans embeddings from pre-trained convolutional andtransformer models trained via supervised, self-supervised, and text-imagecontrastive learning. We assess full fine-tuning and transfer learning(top-tuning) on six diverse e-Commerce datasets: fashion, consumer goods, cars,food, and retail. Results show full fine-tuning consistently performs well,while text-image and self-supervised embeddings can match its performance withless training. While supervised embeddings remain stable across architectures,SSL and contrastive embeddings vary significantly, often benefiting fromtop-tuning. Top-tuning emerges as an efficient alternative to full fine-tuning,reducing computational costs. We also explore cross-tuning, noting its impactdepends on dataset characteristics. Our findings offer practical guidelines forembedding selection and fine-tuning strategies, balancing efficiency andperformance.</description>
      <author>example@mail.com (Urszula Czerwinska, Cenk Bircanoglu, Jeremy Chamoux)</author>
      <guid isPermaLink="false">2504.07567v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Prediction of Usage Probabilities of Shopping-Mall Corridors Using Heterogeneous Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.07645v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, working manuscript with partial results&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的方法，用于预测购物中心走廊的使用概率。&lt;h4&gt;背景&lt;/h4&gt;通过分析购物中心楼层平面图，创建了走廊、商店和入口的向量层，从而构建了异构图网络。&lt;h4&gt;目的&lt;/h4&gt;该方法旨在通过商店特征和连接它们的图结构来预测使用概率。&lt;h4&gt;方法&lt;/h4&gt;使用商店的面积和类别等特征，以及通过走廊路径连接的商店、走廊交叉口和入口的图来预测使用概率。通过多层感知器（MLP）对每条边进行概率预测。&lt;h4&gt;主要发现&lt;/h4&gt;该方法适用于从实地调查或行人检测传感器获得的数据集进行训练，并通过概率模型生成合成学习数据集。&lt;h4&gt;结论&lt;/h4&gt;提出了考虑购物中心特定识别特征的图级特征，以提高模型性能。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种基于图神经网络（GNN）的方法，用于预测购物中心走廊的使用概率。通过分析购物中心楼层平面图，创建了走廊、商店和入口的向量层，从而构建了异构图网络。该方法旨在通过商店特征和连接它们的图结构来预测使用概率。使用商店的面积和类别等特征，以及通过走廊路径连接的商店、走廊交叉口和入口的图来预测使用概率。通过多层感知器（MLP）对每条边进行概率预测。该方法适用于从实地调查或行人检测传感器获得的数据集进行训练，并通过概率模型生成合成学习数据集。提出了考虑购物中心特定识别特征的图级特征，以提高模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a method based on graph neural network (GNN) for prediction ofprobabilities of usage of shopping-mall corridors. The heterogeneous graphnetwork of shops and corridor paths are obtained from floorplans of the mallsby creating vector layers for corridors, shops and entrances. These aresubsequently assimilated into nodes and edges of graphs. The prediction of theusage probability is based on the shop features, namely, the area and usagecategories they fall into, and on the graph connecting these shops, corridorjunctions and entrances by corridor paths. Though the presented method isapplicable for training on datasets obtained from a field survey or frompedestrian-detecting sensors, the target data of the supervised deep-learningwork flow in this work are obtained from a probability method. We also includea context-specific representation learning of latent features. Theusage-probability prediction is made on each edge, which is a connection by asection of corridor path between the adjacent nodes representing the shops orcorridor points. To create a feature for each edge, the hidden-layer featurevectors acquired in the message-passing GNN layers at the nodes of each edgeare averaged and concatenated with the vector obtained by their multiplication.These edge-features are then passed to multilayer perceptrons (MLP) to make thefinal prediction of usage probability on each edge. The samples of syntheticlearning dataset for each shopping mall are obtained by changing the shops'usage and area categories, and by subsequently feeding the graph into theprobability model.  When including different shopping malls in a single dataset, we also proposeto consider graph-level features to inform the model with specific identifyingfeatures of each mall.</description>
      <author>example@mail.com (Malik M Barakathullah, Immanuel Koh)</author>
      <guid isPermaLink="false">2504.07645v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Harnessing Equivariance: Modeling Turbulence with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.07741v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的湍流建模新方法，该方法将纳维-斯托克斯方程的离散旋转、反射和平移对称性嵌入到模型架构中，并推导出合适的不变输入和输出空间，使得GNN模型能够无缝嵌入到大涡模拟（LES）框架中，以获得保持对称性的模拟设置。&lt;h4&gt;背景&lt;/h4&gt;湍流建模在大型涡模拟（LES）中是一个挑战，需要考虑纳维-斯托克斯方程的对称性。&lt;h4&gt;目的&lt;/h4&gt;研究GNN在LES湍流建模中的应用，并验证其有效性和准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法基于图神经网络，并利用强化学习（RL）进行模型训练，确保模型与LES公式的离散化一致。&lt;h4&gt;主要发现&lt;/h4&gt;对于均匀各向同性湍流（HIT）和湍流通道流，GNN模型成功学习并恢复了湍流统计量和雷诺应力。在HIT案例中，基于GNN的LES方案在实际模拟中恢复了旋转和反射等变，同时稳定性和精度与未能遵守这些性质的对称性保护机器学习模型相当。GNN模型在湍流通道流中表现良好，学习到了近壁面和外部区域的区域建模策略。&lt;h4&gt;结论&lt;/h4&gt;该方法证明了GNN在湍流建模中的潜力，特别是在LES和RL的背景下。&lt;h4&gt;翻译&lt;/h4&gt;本研究提出了一种基于图神经网络（GNN）的湍流建模新方法，该方法将纳维-斯托克斯方程的离散旋转、反射和平移对称性嵌入到模型架构中。此外，推导出合适的不变输入和输出空间，使得GNN模型能够无缝嵌入到大涡模拟（LES）框架中，以获得保持对称性的模拟设置。该方法对两个典型测试案例——均匀各向同性湍流（HIT）和湍流通道流进行了研究。对于这两个案例，GNN模型都成功地通过强化学习（RL）在实际模拟中进行了训练，以确保模型与底层LES公式的离散化一致。对于HIT案例，基于GNN的LES方案在实际模拟中恢复了旋转和反射等变，精确到机器精度。同时，稳定性和精度与未能遵守这些性质的对称性保护的机器学习模型相当。相同的建模策略在湍流通道流中表现良好，GNN模型成功地学习到了更复杂的流动物理，并能够恢复湍流统计量和雷诺应力。这表明，该方法具有将区域建模策略应用于近壁面和外部区域的独特行为。因此，该方法证明了GNN在湍流建模中的潜力，特别是在大涡模拟（LES）和强化学习（RL）的背景下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work proposes a novel methodology for turbulence modeling in Large EddySimulation (LES) based on Graph Neural Networks (GNNs), which embeds thediscrete rotational, reflectional and translational symmetries of theNavier-Stokes equations into the model architecture. In addition, suitableinvariant input and output spaces are derived that allow the GNN models to beembedded seamlessly into the LES framework to obtain a symmetry-preservingsimulation setup. The suitability of the proposed approach is investigated fortwo canonical test cases: Homogeneous Isotropic Turbulence (HIT) and turbulentchannel flow. For both cases, GNN models are trained successfully in actualsimulations using Reinforcement Learning (RL) to ensure that the models areconsistent with the underlying LES formulation and discretization. It isdemonstrated for the HIT case that the resulting GNN-based LES scheme recoversrotational and reflectional equivariance up to machine precision in actualsimulations. At the same time, the stability and accuracy remain on par withnon-symmetry-preserving machine learning models that fail to obey theseproperties. The same modeling strategy translates well to turbulent channelflow, where the GNN model successfully learns the more complex flow physics andis able to recover the turbulent statistics and Reynolds stresses. It is shownthat the GNN model learns a zonal modeling strategy with distinct behaviors inthe near-wall and outer regions. The proposed approach thus demonstrates thepotential of GNNs for turbulence modeling, especially in the context of LES andRL.</description>
      <author>example@mail.com (Marius Kurz, Andrea Beck, Benjamin Sanderse)</author>
      <guid isPermaLink="false">2504.07741v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Fast Adaptation with Behavioral Foundation Models</title>
      <link>http://arxiv.org/abs/2504.07896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种快速适应策略，以提高无监督零样本强化学习（RL）在行为基础模型（BFM）中的零样本性能，通过在线与环境的交互，在不降低性能的情况下提升模型在下游任务上的表现。&lt;h4&gt;背景&lt;/h4&gt;无监督零样本RL作为一种强大的预训练BFM的方法，允许代理通过奖励函数在零样本方式下解决各种下游任务，但零样本策略由于训练过程中的错误而常常不是最优的。&lt;h4&gt;目的&lt;/h4&gt;设计快速适应策略，在不影响性能的情况下提高BFM的零样本性能。&lt;h4&gt;方法&lt;/h4&gt;提出演员-评论家（actor-critic）和演员-only（actor-only）快速适应策略，在预训练BFM的低维任务嵌入空间中搜索，快速提高其零样本策略在下游任务上的性能。&lt;h4&gt;主要发现&lt;/h4&gt;现有的BFM学习到一组包含比其推理过程确定的策略更优的策略，这使得它们非常适合快速适应。&lt;h4&gt;结论&lt;/h4&gt;在多个导航和运动领域上评估了快速适应策略，结果表明它们在数十个回合内实现了10-40%的性能提升，优于现有基线。&lt;h4&gt;翻译&lt;/h4&gt;Unsupervised zero-shot reinforcement learning (RL) has emerged as a powerful paradigm for pretraining behavioral foundation models (BFMs), enabling agents to solve a wide range of downstream tasks specified via reward functions in a zero-shot fashion, i.e., without additional test-time learning or planning. This is achieved by learning self-supervised task embeddings alongside corresponding near-optimal behaviors and incorporating an inference procedure to directly retrieve the latent task embedding and associated policy for any given reward function. Despite promising results, zero-shot policies are often suboptimal due to errors induced by the unsupervised training process, the embedding, and the inference procedure. In this paper, we focus on devising fast adaptation strategies to improve the zero-shot performance of BFMs in a few steps of online interaction with the environment while avoiding any performance drop during the adaptation process. Notably, we demonstrate that existing BFMs learn a set of skills containing more performant policies than those identified by their inference procedure, making them well-suited for fast adaptation. Motivated by this observation, we propose both actor-critic and actor-only fast adaptation strategies that search in the low-dimensional task-embedding space of the pre-trained BFM to rapidly improve the performance of its zero-shot policies on any downstream task. Notably, our approach mitigates the initial 'unlearning' phase commonly observed when fine-tuning pre-trained RL models. We evaluate our fast adaptation strategies on top of four state-of-the-art zero-shot RL methods in multiple navigation and locomotion domains. Our results show that they achieve 10-40% improvement over their zero-shot performance in a few tens of episodes, outperforming existing baselines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised zero-shot reinforcement learning (RL) has emerged as a powerfulparadigm for pretraining behavioral foundation models (BFMs), enabling agentsto solve a wide range of downstream tasks specified via reward functions in azero-shot fashion, i.e., without additional test-time learning or planning.This is achieved by learning self-supervised task embeddings alongsidecorresponding near-optimal behaviors and incorporating an inference procedureto directly retrieve the latent task embedding and associated policy for anygiven reward function. Despite promising results, zero-shot policies are oftensuboptimal due to errors induced by the unsupervised training process, theembedding, and the inference procedure. In this paper, we focus on devisingfast adaptation strategies to improve the zero-shot performance of BFMs in afew steps of online interaction with the environment while avoiding anyperformance drop during the adaptation process. Notably, we demonstrate thatexisting BFMs learn a set of skills containing more performant policies thanthose identified by their inference procedure, making them well-suited for fastadaptation. Motivated by this observation, we propose both actor-critic andactor-only fast adaptation strategies that search in the low-dimensionaltask-embedding space of the pre-trained BFM to rapidly improve the performanceof its zero-shot policies on any downstream task. Notably, our approachmitigates the initial "unlearning" phase commonly observed when fine-tuningpre-trained RL models. We evaluate our fast adaptation strategies on top offour state-of-the-art zero-shot RL methods in multiple navigation andlocomotion domains. Our results show that they achieve 10-40% improvement overtheir zero-shot performance in a few tens of episodes, outperforming existingbaselines.</description>
      <author>example@mail.com (Harshit Sikchi, Andrea Tirinzoni, Ahmed Touati, Yingchen Xu, Anssi Kanervisto, Scott Niekum, Amy Zhang, Alessandro Lazaric, Matteo Pirotta)</author>
      <guid isPermaLink="false">2504.07896v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>On the Temporal Question-Answering Capabilities of Large Language Models Over Anonymized Data</title>
      <link>http://arxiv.org/abs/2504.07646v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 tables, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了大型语言模型（LLMs）在处理训练数据中未出现的时间推理任务中的应用，重点关注结构化和半结构化匿名数据。&lt;h4&gt;背景&lt;/h4&gt;LLMs在时间推理任务中的应用仍是一个待探索的领域。&lt;h4&gt;目的&lt;/h4&gt;研究如何使用LLMs处理时间推理任务，并开发一种直接的方法，同时比较和深入分析不同的方法。&lt;h4&gt;方法&lt;/h4&gt;开发了直接LLMs流程，比较了各种方法，并创建了名为RATA的数据集，该数据集包含半结构化匿名数据，用于评估LLMs的性能。使用了如思维树、自我反思和代码执行等SoTA技术。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，要实现可扩展和可靠的解决方案，仅仅使用独立的LLMs是不够的，强调了集成方法的需求。&lt;h4&gt;结论&lt;/h4&gt;提出了集成方法对于实现时间推理任务的可扩展和可靠解决方案的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The applicability of Large Language Models (LLMs) in temporal reasoning tasksover data that is not present during training is still a field that remains tobe explored. In this paper we work on this topic, focusing on structured andsemi-structured anonymized data. We not only develop a direct LLM pipeline, butalso compare various methodologies and conduct an in-depth analysis. Weidentified and examined seventeen common temporal reasoning tasks in naturallanguage, focusing on their algorithmic components. To assess LLM performance,we created the \textit{Reasoning and Answering Temporal Ability} dataset(RATA), featuring semi-structured anonymized data to ensure reliance onreasoning rather than on prior knowledge. We compared several methodologies,involving SoTA techniques such as Tree-of-Thought, self-reflexion and codeexecution, tuned specifically for this scenario. Our results suggest thatachieving scalable and reliable solutions requires more than just standaloneLLMs, highlighting the need for integrated approaches.</description>
      <author>example@mail.com (Alfredo Garrachón Ruiz, Tomás de la Rosa, Daniel Borrajo)</author>
      <guid isPermaLink="false">2504.07646v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Radiology with Zero-Shot Multi-Task Capability</title>
      <link>http://arxiv.org/abs/2504.07416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了RadZero，一种用于放射学视觉-语言对齐的新颖相似性基础跨注意力框架，具有零样本多任务能力，以解决现有方法在利用复杂放射学报告、依赖低分辨率图像和注意力机制可解释性有限等方面的挑战。&lt;h4&gt;背景&lt;/h4&gt;多模态模型在放射学视觉-语言对齐方面取得了显著进展，但现有方法存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出RadZero，旨在解决现有方法在放射学视觉-语言对齐中的挑战。&lt;h4&gt;方法&lt;/h4&gt;RadZero利用大型语言模型从放射学报告中提取最小语义句子，采用多正对比学习策略有效捕捉图像与多个相关文本描述之间的关系，并使用预训练的视觉编码器与额外的可训练Transformer层进行高效的高分辨率图像处理。通过计算文本嵌入和局部图像块特征之间的相似性，实现零样本推理，并为分类提供相似性概率，以及为定位和分割提供像素级跨模态相似性图。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，RadZero在零样本分类、定位和分割方面优于现有方法，跨模态相似性图分析突出了其在提高视觉-语言对齐可解释性方面的潜力，定性评估也证明了其在开放词汇语义分割方面的能力。&lt;h4&gt;结论&lt;/h4&gt;RadZero在放射学视觉-语言对齐方面表现出色，有效提高了医学影像中的效率和可解释性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，多模态模型在放射学视觉-语言对齐方面取得了显著进展。然而，现有方法在有效利用复杂放射学报告进行学习、依赖低分辨率图像以及提供有限的注意力机制可解释性方面存在困难。为了解决这些挑战，我们引入了RadZero，这是一种新颖的基于相似性的跨注意力框架，用于放射学的视觉-语言对齐，具有零样本多任务能力。RadZero利用大型语言模型从放射学报告中提取最小语义句子，并采用多正对比学习策略有效捕捉图像与多个相关文本描述之间的关系。它还利用预训练的视觉编码器以及额外的可训练Transformer层，以实现高效的高分辨率图像处理。通过计算文本嵌入和局部图像块特征之间的相似性，RadZero实现了零样本推理，并为分类提供了相似性概率，以及为定位和分割提供了像素级跨模态相似性图。在公共胸部X光图基准测试上的实验结果表明，RadZero在零样本分类、定位和分割方面优于现有方法。此外，跨模态相似性图分析突出了其在提高视觉-语言对齐可解释性方面的潜力。此外，定性评估也证明了RadZero在开放词汇语义分割方面的能力，进一步验证了其在医学影像中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in multi-modal models have significantly improvedvision-language alignment in radiology. However, existing approaches struggleto effectively utilize complex radiology reports for learning, rely onlow-resolution images, and offer limited interpretability in attentionmechanisms. To address these challenges, we introduce RadZero, a novelsimilarity-based cross-attention framework for vision-language alignment inradiology with zero-shot multi-task capability. RadZero leverages largelanguage models to extract minimal semantic sentences from radiology reportsand employs a multi-positive contrastive learning strategy to effectivelycapture relationships between images and multiple relevant textualdescriptions. It also utilizes a pre-trained vision encoder with additionaltrainable Transformer layers, allowing efficient high-resolution imageprocessing. By computing similarity between text embeddings and local imagepatch features, RadZero enables zero-shot inference with similarity probabilityfor classification and pixel-level cross-modal similarity maps for groundingand segmentation. Experimental results on public chest radiograph benchmarksshow that RadZero outperforms state-of-the-art methods in zero-shotclassification, grounding, and segmentation. Furthermore, cross-modalsimilarity map analysis highlights its potential for improving explainabilityin vision-language alignment. Additionally, qualitative evaluation demonstratesRadZero's capability for open-vocabulary semantic segmentation, furthervalidating its effectiveness in medical imaging.</description>
      <author>example@mail.com (Jonggwon Park, Soobum Kim, Byungmu Yoon, Kyoyun Choi)</author>
      <guid isPermaLink="false">2504.07416v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>SAMJAM: Zero-Shot Video Scene Graph Generation for Egocentric Kitchen Videos</title>
      <link>http://arxiv.org/abs/2504.07867v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SAMJAM的零样本流水线，用于生成视频场景图，以解决当前VidSGG模型在动态厨房环境中的稳定性问题。&lt;h4&gt;背景&lt;/h4&gt;视频场景图生成（VidSGG）是理解动态厨房环境的一个重要话题，但现有的VidSGG模型需要大量训练才能生成场景图。&lt;h4&gt;目的&lt;/h4&gt;提出SAMJAM以解决VLMs在VidSGG中的动态性问题，并提高场景图生成的稳定性。&lt;h4&gt;方法&lt;/h4&gt;SAMJAM结合了SAM2的时间跟踪和Gemini的语义理解，首先由Gemini生成帧级场景图，然后使用匹配算法将场景图中的每个对象与SAM2生成的或传播的掩码对应，以在动态环境中生成时间上一致的场景图。&lt;h4&gt;主要发现&lt;/h4&gt;SAMJAM在EPIC-KITCHENS和EPIC-KITCHENS-100数据集上的平均召回率上比Gemini高出8.33%。&lt;h4&gt;结论&lt;/h4&gt;SAMJAM能够有效提高视频场景图生成的稳定性，在动态环境中优于现有的模型。&lt;h4&gt;翻译&lt;/h4&gt;Video Scene Graph Generation (VidSGG) is an important topic in understanding dynamic kitchen environments. Current models for VidSGG require extensive training to produce scene graphs. Recently, Vision Language Models (VLM) and Vision Foundation Models (VFM) have demonstrated impressive zero-shot capabilities in a variety of tasks. However, VLMs like Gemini struggle with the dynamics for VidSGG, failing to maintain stable object identities across frames. To overcome this limitation, we propose SAMJAM, a zero-shot pipeline that combines SAM2's temporal tracking with Gemini's semantic understanding. SAM2 also improves upon Gemini's object grounding by producing more accurate bounding boxes. In our method, we first prompt Gemini to generate a frame-level scene graph. Then, we employ a matching algorithm to map each object in the scene graph with a SAM2-generated or SAM2-propagated mask, producing a temporally-consistent scene graph in dynamic environments. Finally, we repeat this process again in each of the following frames. We empirically demonstrate that SAMJAM outperforms Gemini by 8.33% in mean recall on the EPIC-KITCHENS and EPIC-KITCHENS-100 datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Scene Graph Generation (VidSGG) is an important topic in understandingdynamic kitchen environments. Current models for VidSGG require extensivetraining to produce scene graphs. Recently, Vision Language Models (VLM) andVision Foundation Models (VFM) have demonstrated impressive zero-shotcapabilities in a variety of tasks. However, VLMs like Gemini struggle with thedynamics for VidSGG, failing to maintain stable object identities acrossframes. To overcome this limitation, we propose SAMJAM, a zero-shot pipelinethat combines SAM2's temporal tracking with Gemini's semantic understanding.SAM2 also improves upon Gemini's object grounding by producing more accuratebounding boxes. In our method, we first prompt Gemini to generate a frame-levelscene graph. Then, we employ a matching algorithm to map each object in thescene graph with a SAM2-generated or SAM2-propagated mask, producing atemporally-consistent scene graph in dynamic environments. Finally, we repeatthis process again in each of the following frames. We empirically demonstratethat SAMJAM outperforms Gemini by 8.33% in mean recall on the EPIC-KITCHENS andEPIC-KITCHENS-100 datasets.</description>
      <author>example@mail.com (Joshua Li, Fernando Jose Pena Cantu, Emily Yu, Alexander Wong, Yuchen Cui, Yuhao Chen)</author>
      <guid isPermaLink="false">2504.07867v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>DWFS-Obfuscation: Dynamic Weighted Feature Selection for Robust Malware Familial Classification under Obfuscation</title>
      <link>http://arxiv.org/abs/2504.07590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于动态加权特征选择的方法，用于提高Android恶意软件检测的鲁棒性和准确性。&lt;h4&gt;背景&lt;/h4&gt;Android操作系统的开源特性使其成为攻击者的主要目标，基于学习的方法在Android恶意软件检测领域取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;针对传统基于静态特征的检测方法难以识别混淆的恶意代码，以及依赖动态分析的方法效率低的问题，提出新的检测方法。&lt;h4&gt;方法&lt;/h4&gt;提出动态加权特征选择方法，分析特征的重要性和稳定性，计算分数以筛选最稳健的特征，并结合程序的结构信息。使用图神经网络进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;在8,664个恶意软件样本和44,940个变种上测试，该方法在未混淆数据集上达到95.56%的F1分数，在混淆数据集上达到92.28%的F1分数。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效检测混淆的恶意软件，提高了检测系统的鲁棒性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to its open-source nature, the Android operating system has consistentlybeen a primary target for attackers. Learning-based methods have madesignificant progress in the field of Android malware detection. However,traditional detection methods based on static features struggle to identifyobfuscated malicious code, while methods relying on dynamic analysis sufferfrom low efficiency. To address this, we propose a dynamic weighted featureselection method that analyzes the importance and stability of features,calculates scores to filter out the most robust features, and combines theseselected features with the program's structural information. We then utilizegraph neural networks for classification, thereby improving the robustness andaccuracy of the detection system. We analyzed 8,664 malware samples from eightmalware families and tested a total of 44,940 malware variants generated usingseven obfuscation strategies. Experiments demonstrate that our proposed methodachieves an F1-score of 95.56% on the unobfuscated dataset and 92.28% on theobfuscated dataset, indicating that the model can effectively detect obfuscatedmalware.</description>
      <author>example@mail.com (Xingyuan Wei, Zijun Cheng, Ning Li, Qiujian Lv, Ziyang Yu, Degang Sun)</author>
      <guid isPermaLink="false">2504.07590v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>VideoExpert: Augmented LLM for Temporal-Sensitive Video Understanding</title>
      <link>http://arxiv.org/abs/2504.07519v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为VideoExpert的通用多模态大语言模型，适用于多种时间敏感的视频任务，通过时空专家模块协同工作，提高了时间标记的准确性。&lt;h4&gt;背景&lt;/h4&gt;视频理解的核心挑战在于感知动态内容随时间的变化，而多模态大语言模型在处理时间敏感的视频任务时存在困难，需要生成时间戳来标记特定事件的发生。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效处理时间敏感视频任务的通用多模态大语言模型VideoExpert。&lt;h4&gt;方法&lt;/h4&gt;VideoExpert集成了两个并行模块：时间专家和空间专家。时间专家负责建模时间序列和进行时间定位，空间专家专注于内容细节分析和指令跟随。两个专家通过特殊标记协同工作，并保持独立的参数集。此外，引入了空间压缩模块来获取空间标记。&lt;h4&gt;主要发现&lt;/h4&gt;VideoExpert通过分离时间定位和内容生成，防止了文本模式偏差，提高了时间戳预测的准确性。空间压缩模块能够有效地过滤和压缩标记，为空间专家提供紧凑且信息丰富的输入。&lt;h4&gt;结论&lt;/h4&gt;实验表明，VideoExpert在有效性和多功能性方面表现出色，适用于多种时间敏感的视频任务。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视频理解的核心挑战在于感知随时间变化的动态内容。然而，多模态大语言模型在处理需要生成时间戳标记特定事件发生的时间敏感视频任务时存在困难。现有的策略要求MLLM直接生成绝对或相对时间戳。我们观察到，这些MLLM在生成时间戳时往往更多地依赖于语言模式而不是视觉线索，这影响了它们的性能。为了解决这个问题，我们提出了VideoExpert，这是一个通用目的的MLLM，适用于多种时间敏感的视频任务。受专家概念的启发，VideoExpert集成了两个并行模块：时间专家和空间专家。时间专家负责建模时间序列和执行时间定位。它处理高帧率且压缩的标记以捕捉视频中的动态变化，并包括一个轻量级预测头来进行精确的事件定位。空间专家专注于内容细节分析和指令跟随。它处理专门设计的空间标记和语言输入，旨在生成与内容相关的响应。这两个专家通过一个特殊标记无缝协作，确保协调的时间定位和内容生成。值得注意的是，时间和空间专家保持独立的参数集。通过将时间定位从内容生成中卸载，VideoExpert防止了时间戳预测中的文本模式偏差。此外，我们引入了空间压缩模块以获取空间标记。该模块在保留关键信息的同时过滤和压缩补丁标记，为空间专家提供紧凑但信息丰富的输入。广泛的实验证明了VideoExpert的有效性和多功能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The core challenge in video understanding lies in perceiving dynamic contentchanges over time. However, multimodal large language models struggle withtemporal-sensitive video tasks, which requires generating timestamps to markthe occurrence of specific events. Existing strategies require MLLMs togenerate absolute or relative timestamps directly. We have observed that thoseMLLMs tend to rely more on language patterns than visual cues when generatingtimestamps, affecting their performance. To address this problem, we proposeVideoExpert, a general-purpose MLLM suitable for several temporal-sensitivevideo tasks. Inspired by the expert concept, VideoExpert integrates twoparallel modules: the Temporal Expert and the Spatial Expert. The TemporalExpert is responsible for modeling time sequences and performing temporalgrounding. It processes high-frame-rate yet compressed tokens to capturedynamic variations in videos and includes a lightweight prediction head forprecise event localization. The Spatial Expert focuses on content detailanalysis and instruction following. It handles specially designed spatialtokens and language input, aiming to generate content-related responses. Thesetwo experts collaborate seamlessly via a special token, ensuring coordinatedtemporal grounding and content generation. Notably, the Temporal and SpatialExperts maintain independent parameter sets. By offloading temporal groundingfrom content generation, VideoExpert prevents text pattern biases in timestamppredictions. Moreover, we introduce a Spatial Compress module to obtain spatialtokens. This module filters and compresses patch tokens while preserving keyinformation, delivering compact yet detail-rich input for the Spatial Expert.Extensive experiments demonstrate the effectiveness and versatility of theVideoExpert.</description>
      <author>example@mail.com (Henghao Zhao, Ge-Peng Ji, Rui Yan, Huan Xiong, Zechao Li)</author>
      <guid isPermaLink="false">2504.07519v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Conditional Data Synthesis Augmentation</title>
      <link>http://arxiv.org/abs/2504.07426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CoDSA的框架，用于通过生成模型合成高质量数据，以提升多模态数据（包括表格、文本和图像数据）在监督学习任务中的模型性能。&lt;h4&gt;背景&lt;/h4&gt;现实世界的数据集通常规模有限，在关键子群体中存在代表性不足，导致预测偏差和性能下降。&lt;h4&gt;目的&lt;/h4&gt;解决数据集规模有限和代表性不足的问题，提高模型在监督学习任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;CoDSA利用生成模型（如扩散模型）合成高保真数据，重点关注欠采样或高兴趣区域。通过迁移学习，CoDSA微调预训练的生成模型，以增强合成数据的真实性和增加稀疏区域的样本密度。&lt;h4&gt;主要发现&lt;/h4&gt;CoDSA能够通过合成样本和目标区域分配来量化统计精度改进，提供其有效性的正式保证。实验表明，CoDSA在监督和未监督设置中均优于非自适应增强策略和最先进的基线。&lt;h4&gt;结论&lt;/h4&gt;CoDSA是一种有效的数据增强方法，能够显著提高模型在多模态数据上的性能，特别是在监督学习任务中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable machine learning and statistical analysis rely on diverse,well-distributed training data. However, real-world datasets are often limitedin size and exhibit underrepresentation across key subpopulations, leading tobiased predictions and reduced performance, particularly in supervised taskssuch as classification. To address these challenges, we propose ConditionalData Synthesis Augmentation (CoDSA), a novel framework that leveragesgenerative models, such as diffusion models, to synthesize high-fidelity datafor improving model performance across multimodal domains including tabular,textual, and image data. CoDSA generates synthetic samples that faithfullycapture the conditional distributions of the original data, with a focus onunder-sampled or high-interest regions. Through transfer learning, CoDSAfine-tunes pre-trained generative models to enhance the realism of syntheticdata and increase sample density in sparse areas. This process preservesinter-modal relationships, mitigates data imbalance, improves domainadaptation, and boosts generalization. We also introduce a theoreticalframework that quantifies the statistical accuracy improvements enabled byCoDSA as a function of synthetic sample volume and targeted region allocation,providing formal guarantees of its effectiveness. Extensive experimentsdemonstrate that CoDSA consistently outperforms non-adaptive augmentationstrategies and state-of-the-art baselines in both supervised and unsupervisedsettings.</description>
      <author>example@mail.com (Xinyu Tian, Xiaotong Shen)</author>
      <guid isPermaLink="false">2504.07426v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging LLMs for Multimodal Retrieval-Augmented Radiology Report Generation via Key Phrase Extraction</title>
      <link>http://arxiv.org/abs/2504.07415v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于检索增强的多模态放射学报告生成方法，旨在减轻放射科医生的工作负担，并通过利用多模态检索和大型语言模型（LLMs）来生成报告，同时减轻幻觉和降低计算需求。&lt;h4&gt;背景&lt;/h4&gt;放射学报告生成（RRG）有减轻放射科医生工作负担的潜力，但近年来大型语言模型（LLMs）在胸片（CXR）报告生成方面的应用，由于多模态语言模型（MLLMs）的资源密集特性，面临数据集庞大和计算成本高的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种检索增强的生成方法，以减轻放射学报告生成的计算需求，并提高报告的准确性。&lt;h4&gt;方法&lt;/h4&gt;方法利用LLMs提取关键短语，专注于关键诊断信息，并采用有效的训练策略，包括图像编码器结构搜索、向文本嵌入添加噪声和额外的训练目标。结合互补的预训练图像编码器，采用文本和语义图像嵌入之间的对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;在MIMIC-CXR数据集上评估，该方法在CheXbert指标上达到最先进的结果，在RadGraph F1指标上与MLLMs具有竞争力，且无需对LLM进行微调。该方法显示出在多视图RRG上的稳健泛化能力，适用于广泛的临床应用。&lt;h4&gt;结论&lt;/h4&gt;该方法为放射学报告生成提供了一种有效的解决方案，能够减少计算成本，同时提高报告的准确性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated radiology report generation (RRG) holds potential to reduceradiologists' workload, especially as recent advancements in large languagemodels (LLMs) enable the development of multimodal models for chest X-ray (CXR)report generation. However, multimodal LLMs (MLLMs) are resource-intensive,requiring vast datasets and substantial computational cost for training. Toaddress these challenges, we propose a retrieval-augmented generation approachthat leverages multimodal retrieval and LLMs to generate radiology reportswhile mitigating hallucinations and reducing computational demands. Our methoduses LLMs to extract key phrases from radiology reports, effectively focusingon essential diagnostic information. Through exploring effective trainingstrategies, including image encoder structure search, adding noise to textembeddings, and additional training objectives, we combine complementarypre-trained image encoders and adopt contrastive learning between text andsemantic image embeddings. We evaluate our approach on MIMIC-CXR dataset,achieving state-of-the-art results on CheXbert metrics and competitive RadGraphF1 metric alongside MLLMs, without requiring LLM fine-tuning. Our methoddemonstrates robust generalization for multi-view RRG, making it suitable forcomprehensive clinical applications.</description>
      <author>example@mail.com (Kyoyun Choi, Byungmu Yoon, Soobum Kim, Jonggwon Park)</author>
      <guid isPermaLink="false">2504.07415v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Exploring a Patch-Wise Approach for Privacy-Preserving Fake ID Detection</title>
      <link>http://arxiv.org/abs/2504.07761v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在数字化的世界中，验证身份证件真实性的挑战，特别是针对假身份证检测的局限性。提出了一种新型的隐私保护假身份证检测方法，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;随着数字化的普及，身份证件的真伪验证成为现实应用中的关键挑战，如数字银行、加密交易、租赁等。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来克服假身份证检测领域的隐私和性能之间的权衡问题。&lt;h4&gt;方法&lt;/h4&gt;研究提出了一种基于匿名化和不同补丁大小配置的隐私保护假身份证检测方法，同时考虑了如Vision Transformers和Foundation Models等先进方法。实验中使用了DLC-2021数据库，并发布了包含真实和假身份证片断的公共数据库。&lt;h4&gt;主要发现&lt;/h4&gt;在DLC-2021数据库上，该方法在补丁和身份证件层面上实现了13.91%和0%的等错误率，显示出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;研究提出的方法能够有效平衡隐私保护与性能，并为假身份证检测领域提供了新的思路和工具。&lt;h4&gt;翻译&lt;/h4&gt;In an increasingly digitalized world, verifying the authenticity of ID documents has become a critical challenge for real-life applications such as digital banking, crypto-exchanges, renting, etc. This study focuses on the topic of fake ID detection, covering several limitations in the field. In particular, no publicly available data from real ID documents exists, and most studies rely on proprietary in-house databases that are not available due to privacy reasons. In order to shed some light on this critical challenge that makes difficult to advance in the field, we explore a trade-off between privacy (i.e., amount of sensitive data available) and performance, proposing a novel patch-wise approach for privacy-preserving fake ID detection. Our proposed approach explores how privacy can be enhanced through: i) two levels of anonymization for an ID document (i.e., fully- and pseudo-anonymized), and ii) different patch size configurations, varying the amount of sensitive data visible in the patch image. Also, state-of-the-art methods such as Vision Transformers and Foundation Models are considered in the analysis. The experimental framework shows that, on an unseen database (DLC-2021), our proposal achieves 13.91% and 0% EERs at patch and ID document level, showing good generalization to other databases. In addition to this exploration, another key contribution of our study is the release of the first publicly available database that contains 48,400 patches from both real and fake ID documents, along with the experimental framework and models, which will be available in our GitHub.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In an increasingly digitalized world, verifying the authenticity of IDdocuments has become a critical challenge for real-life applications such asdigital banking, crypto-exchanges, renting, etc. This study focuses on thetopic of fake ID detection, covering several limitations in the field. Inparticular, no publicly available data from real ID documents exists, and moststudies rely on proprietary in-house databases that are not available due toprivacy reasons. In order to shed some light on this critical challenge thatmakes difficult to advance in the field, we explore a trade-off between privacy(i.e., amount of sensitive data available) and performance, proposing a novelpatch-wise approach for privacy-preserving fake ID detection. Our proposedapproach explores how privacy can be enhanced through: i) two levels ofanonymization for an ID document (i.e., fully- and pseudo-anonymized), and ii)different patch size configurations, varying the amount of sensitive datavisible in the patch image. Also, state-of-the-art methods such as VisionTransformers and Foundation Models are considered in the analysis. Theexperimental framework shows that, on an unseen database (DLC-2021), ourproposal achieves 13.91% and 0% EERs at patch and ID document level, showing agood generalization to other databases. In addition to this exploration,another key contribution of our study is the release of the first publiclyavailable database that contains 48,400 patches from both real and fake IDdocuments, along with the experimental framework and models, which will beavailable in our GitHub.</description>
      <author>example@mail.com (Javier Muñoz-Haro, Ruben Tolosana, Ruben Vera-Rodriguez, Aythami Morales, Julian Fierrez)</author>
      <guid isPermaLink="false">2504.07761v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>FLASH: Flexible Learning of Adaptive Sampling from History in Temporal Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.07337v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 4 figures, 12 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FLASH的动态图链接预测方法，通过学习可适应的邻居选择机制来提高时间图神经网络（TGNNs）的性能。&lt;h4&gt;背景&lt;/h4&gt;在动态图上的未来链接预测中，从历史交互中聚合时间信号是关键步骤，但包含长期历史数据资源密集。现有的时间图神经网络（TGNNs）通常依赖于静态的邻居采样启发式方法，如均匀采样或最近邻居选择，但这些方法无法适应底层图结构。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够适应图结构的动态链接预测方法，提高TGNNs的性能。&lt;h4&gt;方法&lt;/h4&gt;提出FLASH，一种可学习的图自适应邻居选择机制，它整合到TGNNs中，并使用自监督排序损失进行端到端训练。&lt;h4&gt;主要发现&lt;/h4&gt;理论证据表明，常用的启发式方法会阻碍TGNNs的性能，因此设计了FLASH来克服这一限制。&lt;h4&gt;结论&lt;/h4&gt;在多个基准测试中，使用FLASH的TGNNs实现了一致且显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从历史交互中聚合时间信号是动态图上未来链接预测的关键步骤。然而，包含长期历史数据是资源密集型的。因此，时间图神经网络（TGNNs）通常依赖于历史邻居采样启发式方法，如均匀采样或最近邻居选择。这些启发式方法是静态的，无法适应底层图结构。我们引入了FLASH，这是一种可学习的、图自适应的邻居选择机制，它概括了现有的启发式方法。FLASH可以无缝集成到TGNNs中，并使用自监督排序损失进行端到端训练。我们提供了理论证据，表明常用的启发式方法阻碍了TGNNs的性能，这激励了我们的设计。在多个基准测试上的大量实验表明，配备FLASH的TGNNs实现了一致且显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Aggregating temporal signals from historic interactions is a key step infuture link prediction on dynamic graphs. However, incorporating long historiesis resource-intensive. Hence, temporal graph neural networks (TGNNs) often relyon historical neighbors sampling heuristics such as uniform sampling or recentneighbors selection. These heuristics are static and fail to adapt to theunderlying graph structure. We introduce FLASH, a learnable and graph-adaptiveneighborhood selection mechanism that generalizes existing heuristics. FLASHintegrates seamlessly into TGNNs and is trained end-to-end using aself-supervised ranking loss. We provide theoretical evidence that commonlyused heuristics hinders TGNNs performance, motivating our design. Extensiveexperiments across multiple benchmarks demonstrate consistent and significantperformance improvements for TGNNs equipped with FLASH.</description>
      <author>example@mail.com (Or Feldman, Krishna Sri Ipsit Mantri, Carola-Bibiane Schönlieb, Chaim Baskin, Moshe Eliasof)</author>
      <guid isPermaLink="false">2504.07337v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Beating Transformers using Synthetic Cognition</title>
      <link>http://arxiv.org/abs/2504.07619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了通过生成情景反应行为来发展通用人工智能的道路，并探讨了使用合成认知来发展情景反应行为的方法。&lt;h4&gt;背景&lt;/h4&gt;目前，通用人工智能的发展需要生成情景反应行为，而Transformer架构在生成情景反应行为方面被认为是最佳方案。然而，现有的方法仍然无法实现推理功能。&lt;h4&gt;目的&lt;/h4&gt;研究使用合成认知来发展情景反应行为。&lt;h4&gt;方法&lt;/h4&gt;提出了一个处理序列的机制，并将其应用于DNA序列分类任务中，以DNA基础模型为基准进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在多个基准任务上的表现优于DNA基础模型，实现了在序列处理方面的扩展，并超越了Transformer架构在序列分类任务上的表现。&lt;h4&gt;结论&lt;/h4&gt;通过扩展合成认知以处理序列，并击败了Transformer架构在序列分类任务上的表现，实现了研究目标。&lt;h4&gt;翻译&lt;/h4&gt;The road to Artificial General Intelligence goes through the generation of episodic reactive behaviors, where the Transformer architecture has been proven to be the state-of-the-art. However, they still fail to develop reasoning. Recently, a novel approach for developing cognitive architectures, called Synthetic Cognition, has been proposed and implemented to develop instantaneous reactive behavior. In this study, we aim to explore the use of Synthetic Cognition to develop episodic reactive behaviors. We propose a mechanism to deal with sequences for the recent implementation of Synthetic Cognition, and test it against DNA foundation models in DNA sequence classification tasks. In our experiments, our proposal clearly outperforms the DNA foundation models, obtaining the best score on more benchmark tasks than the alternatives. Thus, we achieve two goals: expanding Synthetic Cognition to deal with sequences, and beating the Transformer architecture for sequence classification.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The road to Artificial General Intelligence goes through the generation ofepisodic reactive behaviors, where the Transformer architecture has been provento be the state-of-the-art. However, they still fail to develop reasoning.Recently, a novel approach for developing cognitive architectures, calledSynthetic Cognition, has been proposed and implemented to develop instantaneousreactive behavior. In this study, we aim to explore the use of SyntheticCognition to develop episodic reactive behaviors. We propose a mechanism todeal with sequences for the recent implementation of Synthetic Cognition, andtest it against DNA foundation models in DNA sequence classification tasks. Inour experiments, our proposal clearly outperforms the DNA foundation models,obtaining the best score on more benchmark tasks than the alternatives. Thus,we achieve two goals: expanding Synthetic Cognition to deal with sequences, andbeating the Transformer architecture for sequence classification.</description>
      <author>example@mail.com (Alfredo Ibias, Miguel Rodriguez-Galindo, Hector Antona, Guillem Ramirez-Miranda, Enric Guinovart)</author>
      <guid isPermaLink="false">2504.07619v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Identifying regions of interest in whole slide images of renal cell carcinoma</title>
      <link>http://arxiv.org/abs/2504.07313v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究开发了一个全自动系统，用于检测肾细胞癌全切片图像中的感兴趣区域（ROI），以减少分析时间和辅助病理学家做出更准确的决策。&lt;h4&gt;背景&lt;/h4&gt;病理学家的诊断工作因全切片图像中包含大量信息而变得耗时且繁琐。&lt;h4&gt;目的&lt;/h4&gt;减少分析时间并辅助病理学家在肾细胞癌诊断中做出更准确的决策。&lt;h4&gt;方法&lt;/h4&gt;使用高效纹理描述符——主旋转局部二值模式（DRLBP）和颜色转换来揭示和利用显微镜高放大倍数下的巨大纹理变化。对WSI片段的颜色通道分别进行特征提取，形成直方图。使用最频繁出现的模式作为特征选择步骤，丢弃非信息性特征。在1800个肾癌片段上比较和评估了不同分类器的性能。此外，通过深度学习和微调方法使用深度特征和迁移学习对图像片段进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;实现了高识别准确率，最佳精度结果为99.17%，使用SVM达到。迁移学习模型表现良好，使用ResNet-50的最高精度达到98.50%。该方法在图像分类和识别ROI方面表现出高效性。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法在图像分类和识别ROI方面表现出高效性，证明了其在肾细胞癌诊断中的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/s42600-021-00178-9&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The histopathological images contain a huge amount of information, which canmake diagnosis an extremely timeconsuming and tedious task. In this study, wedeveloped a completely automated system to detect regions of interest (ROIs) inwhole slide images (WSI) of renal cell carcinoma (RCC), to reduce time analysisand assist pathologists in making more accurate decisions. The proposedapproach is based on an efficient texture descriptor named dominant rotatedlocal binary pattern (DRLBP) and color transformation to reveal and exploit theimmense texture variability at the microscopic high magnifications level.Thereby, the DRLBPs retain the structural information and utilize the magnitudevalues in a local neighborhood for more discriminative power. For theclassification of the relevant ROIs, feature extraction of WSIs patches wasperformed on the color channels separately to form the histograms. Next, weused the most frequently occurring patterns as a feature selection step todiscard non-informative features. The performances of different classifiers ona set of 1800 kidney cancer patches originating from 12 whole slide images werecompared and evaluated. Furthermore, the small size of the image dataset allowsto investigate deep learning approach based on transfer learning for imagepatches classification by using deep features and fine-tuning methods. Highrecognition accuracy was obtained and the classifiers are efficient, the bestprecision result was 99.17% achieved with SVM. Moreover, transfer learningmodels perform well with comparable performance, and the highest precisionusing ResNet-50 reached 98.50%. The proposed approach results revealed a veryefficient image classification and demonstrated efficacy in identifying ROIs.This study presents an automatic system to detect regions of interest relevantto the diagnosis of kidney cancer in whole slide histopathology images.</description>
      <author>example@mail.com (Mohammed Lamine Benomar, Nesma Settouti, Eric Debreuve, Xavier Descombes, Damien Ambrosetti)</author>
      <guid isPermaLink="false">2504.07313v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Transformer-Based Temporal Information Extraction and Application: A Review</title>
      <link>http://arxiv.org/abs/2504.07470v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基于Transformer的时序信息提取（Temporal IE）进行了综述，分析了该领域的研究成果，并提出了未来研究方向。&lt;h4&gt;背景&lt;/h4&gt;时序信息提取旨在从非结构化文本中提取结构化时序信息，揭示文本中的隐含时间线。这一技术在医疗保健、新闻报道和情报分析等领域得到应用，帮助模型进行时序推理，并使人类用户理解文本的时间结构。&lt;h4&gt;目的&lt;/h4&gt;弥补目前对基于Transformer的时序信息提取研究缺乏全面综述的不足。&lt;h4&gt;方法&lt;/h4&gt;系统地总结和分析使用Transformer进行时序信息提取的研究成果。&lt;h4&gt;主要发现&lt;/h4&gt;基于Transformer的方法在时序信息提取方面取得了显著进展，但相关研究综述不足。&lt;h4&gt;结论&lt;/h4&gt;本文通过对现有研究的总结和分析，为时序信息提取领域的未来研究提供了方向。&lt;h4&gt;翻译&lt;/h4&gt;This paper aims to bridge the gap in the comprehensive reviews of temporal information extraction (IE) using Transformers, by systematically summarizing and analyzing the existing body of work in this field while highlighting potential future research directions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal information extraction (IE) aims to extract structured temporalinformation from unstructured text, thereby uncovering the implicit timelineswithin. This technique is applied across domains such as healthcare, newswire,and intelligence analysis, aiding models in these areas to perform temporalreasoning and enabling human users to grasp the temporal structure of text.Transformer-based pre-trained language models have produced revolutionaryadvancements in natural language processing, demonstrating exceptionalperformance across a multitude of tasks. Despite the achievements garnered byTransformer-based approaches in temporal IE, there is a lack of comprehensivereviews on these endeavors. In this paper, we aim to bridge this gap bysystematically summarizing and analyzing the body of work on temporal IE usingTransformers while highlighting potential future research directions.</description>
      <author>example@mail.com (Xin Su, Phillip Howard, Steven Bethard)</author>
      <guid isPermaLink="false">2504.07470v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>How Can Objects Help Video-Language Understanding?</title>
      <link>http://arxiv.org/abs/2504.07454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了多模态大型语言模型（MLLMs）如何感知视觉世界，并研究了对象表示和适应性问题，旨在提高视频语言理解能力。&lt;h4&gt;背景&lt;/h4&gt;目前对MLLMs如何感知视觉世界的理解有限，既有观点认为对象和关系建模可能通过归纳偏差隐式实现，也有观点指出简单的视觉字幕生成在视频理解中表现良好。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过对象帮助MLLMs进行视频语言理解。&lt;h4&gt;方法&lt;/h4&gt;从对象表示和适应性的角度，通过在五个视频问答数据集上的广泛评估，研究了表示表达性和集成难度之间的权衡。&lt;h4&gt;主要发现&lt;/h4&gt;明确整合以对象为中心的表示对于视频语言理解是必要的，而符号对象可以最容易被整合且在问答任务中表现良好。&lt;h4&gt;结论&lt;/h4&gt;希望研究结果能鼓励社区探索将感知模块显式集成到MLLM设计中的方法。代码和模型将公开发布。&lt;h4&gt;翻译&lt;/h4&gt;How multimodal large language models (MLLMs) perceive the visual worldremains a mystery. To one extreme, object and relation modeling may beimplicitly implemented with inductive biases, for example by treating objectsas tokens. To the other extreme, empirical results reveal the surprisingfinding that simply performing visual captioning, which tends to ignore spatialconfiguration of the objects, serves as a strong baseline for videounderstanding. We aim to answer the question: how can objects helpvideo-language understanding in MLLMs? We tackle the question from the objectrepresentation and adaptation perspectives. Specifically, we investigate thetrade-off between representation expressiveness (e.g., distributed versusymbolic) and integration difficulty (e.g., data-efficiency when learning theadapters). Through extensive evaluations on five video question answeringdatasets, we confirm that explicit integration of object-centric representationremains necessary, and the symbolic objects can be most easily integrated whilebeing performant for question answering. We hope our findings can encouragethe community to explore the explicit integration of perception modules intoMLLM design. Our code and models will be publicly released.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; How multimodal large language models (MLLMs) perceive the visual worldremains a mystery. To one extreme, object and relation modeling may beimplicitly implemented with inductive biases, for example by treating objectsas tokens. To the other extreme, empirical results reveal the surprisingfinding that simply performing visual captioning, which tends to ignore spatialconfiguration of the objects, serves as a strong baseline for videounderstanding. We aim to answer the question: how can objects helpvideo-language understanding in MLLMs? We tackle the question from the objectrepresentation and adaptation perspectives. Specifically, we investigate thetrade-off between representation expressiveness (e.g., distributed versussymbolic) and integration difficulty (e.g., data-efficiency when learning theadapters). Through extensive evaluations on five video question answeringdatasets, we confirm that explicit integration of object-centric representationremains necessary, and the symbolic objects can be most easily integrated whilebeing performant for question answering. We hope our findings can encourage thecommunity to explore the explicit integration of perception modules into MLLMdesign. Our code and models will be publicly released.</description>
      <author>example@mail.com (Zitian Tang, Shijie Wang, Junho Cho, Jaewook Yoo, Chen Sun)</author>
      <guid isPermaLink="false">2504.07454v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Data Fusion of Deep Learned Molecular Embeddings for Property Prediction</title>
      <link>http://arxiv.org/abs/2504.07297v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种改进的多任务学习模型，通过数据融合技术提高在稀疏数据集上的预测准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;深度学习方法在预测材料特性方面具有高精度和效率，但在数据稀疏的情况下，其准确性和适用性受到限制。&lt;h4&gt;目的&lt;/h4&gt;为了提高预测能力，研究提出了使用迁移学习和多任务学习等技术。&lt;h4&gt;方法&lt;/h4&gt;通过数据融合技术将多个单任务模型学习到的分子嵌入进行结合，并在这些结合的嵌入上训练多任务模型。该技术应用于量子化学数据集和实验数据集。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现标准的多任务模型在训练稀疏数据集且属性相关性较弱时表现不佳。&lt;h4&gt;结论&lt;/h4&gt;融合后的多任务模型在稀疏数据集上优于标准多任务模型，并且在数据受限的情况下，比单任务模型提供了更好的预测效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data-driven approaches such as deep learning can result in predictive modelsfor material properties with exceptional accuracy and efficiency. However, inmany problems data is sparse, severely limiting their accuracy andapplicability. To improve predictions, techniques such as transfer learning andmulti-task learning have been used. The performance of multi-task learningmodels depends on the strength of the underlying correlations between tasks andthe completeness of the dataset. We find that standard multi-task models tendto underperform when trained on sparse datasets with weakly correlatedproperties. To address this gap, we use data fusion techniques to combine thelearned molecular embeddings of various single-task models and trained amulti-task model on this combined embedding. We apply this technique to awidely used benchmark dataset of quantum chemistry data for small molecules aswell as a newly compiled sparse dataset of experimental data collected fromliterature and our own quantum chemistry and thermochemical calculations. Theresults show that the fused, multi-task models outperform standard multi-taskmodels for sparse datasets and can provide enhanced prediction on data-limitedproperties compared to single-task models.</description>
      <author>example@mail.com (Robert J Appleton, Brian C Barnes, Alejandro Strachan)</author>
      <guid isPermaLink="false">2504.07297v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Automating the Path: An R&amp;D Agenda for Human-Centered AI and Visualization</title>
      <link>http://arxiv.org/abs/2504.07529v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出一个系统框架来理解以人为本的人工智能（HCAI）如何改变可视化学科。&lt;h4&gt;背景&lt;/h4&gt;生成式AI、大型语言模型（LLMs）和基础模型的兴起正在深刻改变计算机科学，可视化也不例外。&lt;h4&gt;目的&lt;/h4&gt;设计一个框架，展示如何将HCAI的四个工具能力——放大、增强、赋权和提升——映射到可视化意义构建的四个阶段：观察、探索、建模和报告。&lt;h4&gt;方法&lt;/h4&gt;框架中，对于每个组合，本文回顾了现有工具，展望了未来的可能性，识别了挑战和陷阱，并考察了伦理考量。&lt;h4&gt;主要发现&lt;/h4&gt;该设计空间可以作为研发议程，帮助可视化研究人员和实践者将AI整合到工作中，并理解可视化如何支持HCAI研究。&lt;h4&gt;结论&lt;/h4&gt;该框架为可视化研究人员和实践者提供了一个整合AI的工具和方法的路线图，同时也强调了伦理和挑战的重要性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成式人工智能、大型语言模型（LLMs）和基础模型的兴起正在从根本上改变计算机科学，可视化也不例外。我们提出一个理解以人为本的人工智能（HCAI）如何改变可视化学科的系统性框架。我们的框架将四个关键HCAI工具能力——放大、增强、赋权和提升——映射到四个可视化意义构建的阶段：观察、探索、建模和报告。对于每个组合，我们回顾了现有工具，展望了未来的可能性，识别了挑战和陷阱，并考察了伦理考量。这个设计空间可以作为可视化研究人员和实践者的研发议程，以便将AI整合到他们的工作中，以及理解可视化如何支持HCAI研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of generative AI, large language models (LLMs), and foundationmodels is fundamentally reshaping computer science, and visualization andvisual analytics are no exception. We present a systematic framework forunderstanding how human-centered AI (HCAI) can transform the visualizationdiscipline. Our framework maps four key HCAI tool capabilities -- amplify,augment, empower, and enhance -- onto the four phases of visual sensemaking:view, explore, schematize, and report. For each combination, we review existingtools, envision future possibilities, identify challenges and pitfalls, andexamine ethical considerations. This design space can serve as an R\&amp;D agendafor both visualization researchers and practitioners to integrate AI into theirwork as well as understanding how visualization can support HCAI research.</description>
      <author>example@mail.com (Niklas Elmqvist, Clemens Nylandsted Klokmose)</author>
      <guid isPermaLink="false">2504.07529v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning</title>
      <link>http://arxiv.org/abs/2504.06958v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RFT的强化学习技术，结合GRPO用于视频多模态大语言模型，以增强时空感知能力同时保持通用能力。&lt;h4&gt;背景&lt;/h4&gt;强化学习在多模态大语言模型推理能力上取得了显著进展，但在视频理解领域应用有限。&lt;h4&gt;目的&lt;/h4&gt;旨在通过RFT与GRPO的结合，提升视频MLLM的时空感知能力。&lt;h4&gt;方法&lt;/h4&gt;通过在有限的样本上进行多任务RFT，开发出VideoChat-R1，这是一个强大的视频MLLM，在时空感知任务上实现了最先进的性能。&lt;h4&gt;主要发现&lt;/h4&gt;RFT在特定任务改进上非常高效，VideoChat-R1在时空感知任务上表现优异，同时在聊天能力上并未受损。与Qwen2.5-VL-7B相比，VideoChat-R1在时间定位和对象跟踪等任务上性能提升了数倍，并在多个通用QAbenchmark上也有显著提升。&lt;h4&gt;结论&lt;/h4&gt;RFT对于提升视频MLLM的特定任务能力具有潜力，为未来视频MLLM的RL研究提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a reinforcement learning technique called RFT, combined with GRPO for video multimodal large language models, aiming to enhance spatio-temporal perception while maintaining general capabilities.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in reinforcement learning have significantly advanced thereasoning capabilities of multimodal large language models (MLLMs). Whileapproaches such as Group Relative Policy Optimization (GRPO) and rule-basedreward mechanisms demonstrate promise in text and image domains, theirapplication to video understanding remains limited. This paper presents asystematic exploration of Reinforcement Fine-Tuning (RFT) with GRPO for videoMLLMs, aiming to enhance spatio-temporal perception while maintaining generalcapabilities. Our experiments reveal that RFT is highly data-efficient fortask-specific improvements. Through multi-task RFT on spatio-temporalperception objectives with limited samples, we develop VideoChat-R1, a powerfulvideo MLLM that achieves state-of-the-art performance on spatio-temporalperception tasks without sacrificing chat ability, while exhibiting emergingspatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1boosts performance several-fold in tasks like temporal grounding (+31.8) andobject tracking (+31.2). Additionally, it significantly improves on general QAbenchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9).Our findings underscore the potential of RFT for specialized task enhancementof Video MLLMs. We hope our work offers valuable insights for future RLresearch in video MLLMs.</description>
      <author>example@mail.com (Xinhao Li, Ziang Yan, Desen Meng, Lu Dong, Xiangyu Zeng, Yinan He, Yali Wang, Yu Qiao, Yi Wang, Limin Wang)</author>
      <guid isPermaLink="false">2504.06958v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>GPT Carry-On: Training Foundation Model for Customization Could Be Simple, Scalable and Affordable</title>
      <link>http://arxiv.org/abs/2504.07513v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种框架，用于充分利用现有的大型语言模型（LLM）和在线服务系统，为每个用户或任务定制LLM。&lt;h4&gt;背景&lt;/h4&gt;现代大型语言模型已经进入数百万用户的日常生活，但为每个用户或任务定制LLM在计算和存储资源上存在挑战。&lt;h4&gt;目的&lt;/h4&gt;研究是否能够为每个用户或任务定制LLM，并探讨如何高效地实现这一目标。&lt;h4&gt;方法&lt;/h4&gt;在预训练LLM的最终层嵌入上训练额外的transformer分支，然后将基础模型与一个轻量级的模块合并，以形成定制的LLM。通过混合不同领域的LLM，适应特定任务。在推理节点上外包大部分训练计算，在训练节点上仅训练轻量级模块。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在Qwen和DeepSeek开源模型上进行了测试，实现了更快的损失收敛。在解决数学问题时，该方法计算和模型尺寸极小，仅用1000个思维链数据样本和2层轻量级模块的1MB参数，结果令人鼓舞。&lt;h4&gt;结论&lt;/h4&gt;该框架能够有效地为每个用户或任务定制LLM，同时降低计算和存储资源的需求，具有实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代大型语言基础模型（LLM）现在已经进入了数百万用户的日常生活。我们提出了一个自然的问题，即是否可以为每个用户或每个任务定制LLM。从系统和工业经济角度考虑，通用的持续训练或微调仍然需要大量的训练GPU节点的计算和内存，而大多数部署中的推理节点，可能配备的是低端GPU，其配置是为了尽可能快地进行前向传播。我们提出了一种框架，以充分利用现有的LLM和在线服务系统。我们在预训练LLM的最终层嵌入上训练了一个额外的transformer分支，它是基础，然后一个延续模块将基础模型合并，以组成一个定制的LLM。我们可以混合多个层，或者混合多个不同领域如聊天、编码、数学等专业的LLM，以形成一个最适合新任务的新的LLM混合体。由于基础模型不需要更新参数，我们能够在推理节点上外包大部分的训练计算工作，仅在训练节点上训练一个轻量级的延续模块，我们在30B LLM上训练一个100M延续层时消耗的GPU内存少于1GB。我们测试了Qwen和DeepSeek开源模型进行持续预训练，并实现了更快的损失收敛。我们将其用于通过极小的计算和模型尺寸解决数学问题，使用了1000个思维链数据样本，以及2层延续模块的1MB参数，结果很有希望。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern large language foundation models (LLM) have now entered the dailylives of millions of users. We ask a natural question whether it is possible tocustomize LLM for every user or every task. From system and industrial economyconsideration, general continue-training or fine-tuning still requiresubstantial computation and memory of training GPU nodes, whereas mostinference nodes under deployment, possibly with lower-end GPUs, are configuredto make forward pass fastest possible. We propose a framework to take fulladvantages of existing LLMs and systems of online service. We train anadditional branch of transformer blocks on the final-layer embedding ofpretrained LLMs, which is the base, then a carry-on module merge the basemodels to compose a customized LLM. We can mix multiple layers, or multipleLLMs specialized in different domains such as chat, coding, math, to form a newmixture of LLM that best fit a new task. As the base model don't need to updateparameters, we are able to outsource most computation of the training job oninference nodes, and only train a lightweight carry-on on training nodes, wherewe consume less than 1GB GPU memory to train a 100M carry-on layer on 30B LLM.We tested Qwen and DeepSeek opensourced models for continue-pretraining and gotfaster loss convergence. We use it to improve solving math questions withextremely small computation and model size, with 1000 data samples ofchain-of-thoughts, and as small as 1 MB parameters of two layer layer carry-on,and the results are promising.</description>
      <author>example@mail.com (Jianqiao Wangni)</author>
      <guid isPermaLink="false">2504.07513v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>AMAD: AutoMasked Attention for Unsupervised Multivariate Time Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2504.06643v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  fix img issues&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AMAD的无监督多变量时间序列异常检测（UMTSAD）模型，该模型通过结合自动掩码机制和注意力混合模块，以及多尺度特征提取和自动相对关联建模，为UMTSAD问题提供了一种鲁棒且适应性强的解决方案。&lt;h4&gt;背景&lt;/h4&gt;UMTSAD在金融、网络和传感器系统等领域发挥着重要作用。近年来，基于Transformer和自注意力机制的深度学习模型在UMTSAD任务中取得了显著成果，但这些模型的序列异常关联假设通常局限于特定的预定义模式和场景，限制了其泛化能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有模型的局限性，提出AMAD模型，以实现更通用的异常关联表示和更好的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;AMAD模型通过以下方法实现：1. 引入基于AutoMask机制的自动掩码注意力结构；2. 结合注意力混合模块；3. 采用Max-Min训练策略和局部-全局对比学习方法；4. 结合多尺度特征提取和自动相对关联建模。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，AMAD模型在各种数据集上与现有SOTA基准相比，实现了具有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;AMAD模型为UMTSAD问题提供了一种有效的解决方案，具有鲁棒性和适应性，有望在多个领域得到应用。&lt;h4&gt;翻译&lt;/h4&gt;Unsupervised multivariate time series anomaly detection (UMTSAD) plays a critical role in various domains, including finance, networks, and sensor systems. In recent years, due to the outstanding performance of deep learning in general sequential tasks, many models have been specialized for deep UMTSAD tasks and have achieved impressive results, particularly those based on the Transformer and self-attention mechanisms. However, the sequence anomaly association assumptions underlying these models are often limited to specific predefined patterns and scenarios, such as concentrated or peak anomaly patterns. These limitations hinder their ability to generalize to diverse anomaly situations, especially where the lack of labels poses significant challenges. To address these issues, we propose AMAD, which integrates AutoMasked Attention for UMTSAD scenarios. AMAD introduces a novel structure based on the AutoMask mechanism and an attention mixup module, forming a simple yet generalized anomaly association representation framework. This framework is further enhanced by a Max-Min training strategy and a Local-Global contrastive learning approach. By combining multi-scale feature extraction with automatic relative association modeling, AMAD provides a robust and adaptable solution to UMTSAD challenges. Extensive experimental results demonstrate that the proposed model achieving competitive performance results compared to SOTA benchmarks across a variety of datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised multivariate time series anomaly detection (UMTSAD) plays acritical role in various domains, including finance, networks, and sensorsystems. In recent years, due to the outstanding performance of deep learningin general sequential tasks, many models have been specialized for deep UMTSADtasks and have achieved impressive results, particularly those based on theTransformer and self-attention mechanisms. However, the sequence anomalyassociation assumptions underlying these models are often limited to specificpredefined patterns and scenarios, such as concentrated or peak anomalypatterns. These limitations hinder their ability to generalize to diverseanomaly situations, especially where the lack of labels poses significantchallenges. To address these issues, we propose AMAD, which integrates\textbf{A}uto\textbf{M}asked Attention for UMTS\textbf{AD} scenarios. AMADintroduces a novel structure based on the AutoMask mechanism and an attentionmixup module, forming a simple yet generalized anomaly associationrepresentation framework. This framework is further enhanced by a Max-Mintraining strategy and a Local-Global contrastive learning approach. Bycombining multi-scale feature extraction with automatic relative associationmodeling, AMAD provides a robust and adaptable solution to UMTSAD challenges.Extensive experimental results demonstrate that the proposed model achievingcompetitive performance results compared to SOTA benchmarks across a variety ofdatasets.</description>
      <author>example@mail.com (Tiange Huang, Yongjun Li)</author>
      <guid isPermaLink="false">2504.06643v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Objaverse++: Curated 3D Object Dataset with Quality Annotations</title>
      <link>http://arxiv.org/abs/2504.07334v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 8 figures. Accepted to CVPR 2025 Workshop on Efficient Large  Vision Models (April 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Objaverse++的数据集，它是经过人工专家详细属性标注的Objaverse子集。该研究通过提升数据质量，优化了3D生成模型。&lt;h4&gt;背景&lt;/h4&gt;Objaverse是一个包含超过800,000个3D对象的的大型数据集，但其中低质量模型较多，限制了其效用。&lt;h4&gt;目的&lt;/h4&gt;通过人工标注提高Objaverse数据集的质量，并验证其对3D生成模型性能的提升。&lt;h4&gt;方法&lt;/h4&gt;人工标注了10,000个3D对象，包括美学质量分数、纹理颜色分类、多对象组合标志、透明度特征等属性，并训练了一个神经网络来标注剩余数据。&lt;h4&gt;主要发现&lt;/h4&gt;在图像到3D生成任务中，预先训练在高质量子集上的模型表现优于在Objaverse大型数据集上训练的模型。数据质量越高，训练损失收敛速度越快。&lt;h4&gt;结论&lt;/h4&gt;精心管理和丰富标注可以弥补原始数据集的大小限制，为开发3D生成模型提供更有效的途径。发布约500,000个精选3D模型的数据集，以促进3D计算机视觉下游任务的研究。&lt;h4&gt;翻译&lt;/h4&gt;本文提出Objaverse++，这是经过人类专家详细属性标注的Objaverse子集。随着3D内容生成领域的进步，Objaverse等大规模数据集推动了这一领域的发展，其中包含从互联网收集的超过800,000个3D对象。尽管Objaverse代表了可用的最大3D资产集合，但其效用受到低质量模型的普遍存在而限制。为了解决这一限制，我们手动标注了10,000个3D对象，包括美学质量评分、纹理颜色分类、多对象组合标志、透明度特征等详细属性。然后，我们训练了一个能够标注Objaverse数据集剩余标签的神经网络。通过实验和用户研究生成结果，我们证明了在质量专注的子集上预先训练的模型在图像到3D生成任务中表现优于在Objaverse更大数据集上训练的模型。此外，通过比较由我们的标签过滤的多个训练数据子集，我们的结果表明数据质量越高，训练损失收敛速度越快。这些发现表明，精心管理和丰富标注可以弥补原始数据集的大小限制，可能为开发3D生成模型提供更有效的途径。我们发布了约500,000个精选3D模型的数据集，以促进3D计算机视觉下游任务的研究。在不久的将来，我们旨在将我们的标注扩展到覆盖整个Objaverse数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents Objaverse++, a curated subset of Objaverse enhanced withdetailed attribute annotations by human experts. Recent advances in 3D contentgeneration have been driven by large-scale datasets such as Objaverse, whichcontains over 800,000 3D objects collected from the Internet. AlthoughObjaverse represents the largest available 3D asset collection, its utility islimited by the predominance of low-quality models. To address this limitation,we manually annotate 10,000 3D objects with detailed attributes, includingaesthetic quality scores, texture color classifications, multi-objectcomposition flags, transparency characteristics, etc. Then, we trained a neuralnetwork capable of annotating the tags for the rest of the Objaverse dataset.Through experiments and a user study on generation results, we demonstrate thatmodels pre-trained on our quality-focused subset achieve better performancethan those trained on the larger dataset of Objaverse in image-to-3D generationtasks. In addition, by comparing multiple subsets of training data filtered byour tags, our results show that the higher the data quality, the faster thetraining loss converges. These findings suggest that careful curation and richannotation can compensate for the raw dataset size, potentially offering a moreefficient path to develop 3D generative models. We release our enhanced datasetof approximately 500,000 curated 3D models to facilitate further research onvarious downstream tasks in 3D computer vision. In the near future, we aim toextend our annotations to cover the entire Objaverse dataset.</description>
      <author>example@mail.com (Chendi Lin, Heshan Liu, Qunshu Lin, Zachary Bright, Shitao Tang, Yihui He, Minghao Liu, Ling Zhu, Cindy Le)</author>
      <guid isPermaLink="false">2504.07334v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Defending LLM Watermarking Against Spoofing Attacks with Contrastive Representation Learning</title>
      <link>http://arxiv.org/abs/2504.06575v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种语义感知的水印算法，用于检测由大型语言模型（LLM）生成的文本，旨在提高水印文本的质量、可检测性和对去除攻击的鲁棒性，同时解决对抗仿冒攻击的挑战。&lt;h4&gt;背景&lt;/h4&gt;水印技术在检测LLM生成的文本方面显示出潜力，但目前的研究主要集中在水印文本的质量、可检测性和对去除攻击的鲁棒性上，而对仿冒攻击的防御研究较少。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效防御仿冒攻击的语义感知水印算法，同时保持水印文本的质量、可检测性和对去除攻击的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种语义感知水印算法，该算法通过后置嵌入水印，同时保留目标文本的原始意义。该方法引入了语义映射模型，指导生成绿色-红色标记列表，通过对比训练使其对语义扭曲变化敏感，对语义保留编辑不敏感。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法对去除攻击具有强大的鲁棒性，对仿冒攻击（如情感反转和有害内容插入）具有安全性，同时保持了高水印可检测性。&lt;h4&gt;结论&lt;/h4&gt;该算法为LLM提供了更安全、更语义感知的水印方法，是迈向更安全LLM水印的重要一步。&lt;h4&gt;翻译&lt;/h4&gt;摘要：水印技术已成为检测由LLM生成的文本的有前途的技术。当前研究主要集中在三个设计标准：水印文本的高质量、高可检测性和对去除攻击的鲁棒性。然而，对仿冒攻击的安全性研究相对较少。例如，一种挂靠攻击可以恶意改变水印文本的意义——将其变成仇恨言论——同时保留原始水印，从而损害LLM提供商的声誉。我们确定了两个使防御仿冒攻击变得困难的核心挑战：（1）水印需要对语义扭曲变化敏感，同时对语义保留编辑不敏感；（2）检测全局语义变化的需求与大多数水印方案局部、自回归性质之间的矛盾。为了解决这些挑战，我们提出了一种语义感知的水印算法，该算法在保持目标文本原始意义的同时后置嵌入水印。我们的方法引入了一个语义映射模型，该模型指导生成绿色-红色标记列表，通过对比训练使其对语义扭曲变化敏感，对语义保留变化不敏感。在两个标准基准上的实验表明，该方法对去除攻击具有强大的鲁棒性，对仿冒攻击（包括情感反转和有害内容插入）具有安全性，同时保持了高水印可检测性。我们的方法为LLM提供了更安全、更语义感知的水印方法，是迈向更安全LLM水印的重要一步。我们的代码可在https://github.com/UCSB-NLP-Chang/contrastive-watermark找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Watermarking has emerged as a promising technique for detecting textsgenerated by LLMs. Current research has primarily focused on three designcriteria: high quality of the watermarked text, high detectability, androbustness against removal attack. However, the security against spoofingattacks remains relatively understudied. For example, a piggyback attack canmaliciously alter the meaning of watermarked text-transforming it into hatespeech-while preserving the original watermark, thereby damaging the reputationof the LLM provider. We identify two core challenges that make defendingagainst spoofing difficult: (1) the need for watermarks to be both sensitive tosemantic-distorting changes and insensitive to semantic-preserving edits, and(2) the contradiction between the need to detect global semantic shifts and thelocal, auto-regressive nature of most watermarking schemes. To address thesechallenges, we propose a semantic-aware watermarking algorithm that post-hocembeds watermarks into a given target text while preserving its originalmeaning. Our method introduces a semantic mapping model, which guides thegeneration of a green-red token list, contrastively trained to be sensitive tosemantic-distorting changes and insensitive to semantic-preserving changes.Experiments on two standard benchmarks demonstrate strong robustness againstremoval attacks and security against spoofing attacks, including sentimentreversal and toxic content insertion, while maintaining high watermarkdetectability. Our approach offers a significant step toward more secure andsemantically aware watermarking for LLMs. Our code is available athttps://github.com/UCSB-NLP-Chang/contrastive-watermark.</description>
      <author>example@mail.com (Li An, Yujian Liu, Yepeng Liu, Yang Zhang, Yuheng Bu, Shiyu Chang)</author>
      <guid isPermaLink="false">2504.06575v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>ASHiTA: Automatic Scene-grounded HIerarchical Task Analysis</title>
      <link>http://arxiv.org/abs/2504.06553v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AShiTA的框架，用于将高级任务分解为与环境相关的子任务，以实现高级指令到3D场景的映射。&lt;h4&gt;背景&lt;/h4&gt;尽管近年来在场景重建和理解方面取得了进展，但将抽象的高级指令与3D场景联系起来仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;开发一个框架，能够将高级任务分解为与环境相关的子任务，并生成与3D场景图相关的任务层次结构。&lt;h4&gt;方法&lt;/h4&gt;AShiTA通过交替使用LLM辅助的层次任务分析和任务驱动的3D场景图构建来实现这一目标。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AShiTA在将高级任务分解为环境相关的子任务方面优于LLM基线，并且能够达到与最先进方法相当的地基性能。&lt;h4&gt;结论&lt;/h4&gt;AShiTA是一个有效的框架，可以用于将高级指令与3D场景相关联，并有望提高相关任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While recent work in scene reconstruction and understanding has made stridesin grounding natural language to physical 3D environments, it is stillchallenging to ground abstract, high-level instructions to a 3D scene.High-level instructions might not explicitly invoke semantic elements in thescene, and even the process of breaking a high-level task into a set of moreconcrete subtasks, a process called hierarchical task analysis, isenvironment-dependent. In this work, we propose ASHiTA, the first frameworkthat generates a task hierarchy grounded to a 3D scene graph by breaking downhigh-level tasks into grounded subtasks. ASHiTA alternates LLM-assistedhierarchical task analysis, to generate the task breakdown, with task-driven 3Dscene graph construction to generate a suitable representation of theenvironment. Our experiments show that ASHiTA performs significantly betterthan LLM baselines in breaking down high-level tasks into environment-dependentsubtasks and is additionally able to achieve grounding performance comparableto state-of-the-art methods.</description>
      <author>example@mail.com (Yun Chang, Leonor Fermoselle, Duy Ta, Bernadette Bucher, Luca Carlone, Jiuguang Wang)</author>
      <guid isPermaLink="false">2504.06553v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning through Bayesian Optimization</title>
      <link>http://arxiv.org/abs/2504.06265v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的架构，将LLM微调重新定义为通过深度核方法进行高斯过程边缘似然优化，以提高在不确定性下的优化效率。&lt;h4&gt;背景&lt;/h4&gt;虽然大型语言模型（LLMs）可以在其潜在空间中编码复杂关系，但利用它们进行不确定性下的优化仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;解决在不确定性下利用LLMs进行优化的挑战。&lt;h4&gt;方法&lt;/h4&gt;引入基于LLM的深度核，与GPs联合优化，以保留LLMs提供丰富灵活的输入空间和GPs建模此空间并具有预测不确定性的优点。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在Buchwald-Hartwig反应优化中几乎将高性能反应的发现率翻倍（从24%到43%），且无需特定特征即可比特定领域的表示提高14%。在19个基准测试中，该方法在各种任务、LLM架构、预训练领域和超参数设置上显示出鲁棒性、通用性和持续改进。&lt;h4&gt;结论&lt;/h4&gt;联合LLM-GP优化通过边缘似然隐式执行对比学习，对齐表示以产生更好的结构化嵌入空间、改进的不确定性校准和更有效的采样，无需任何外部损失。这项工作在样本高效优化方面提供了实际进展，并揭示了有效贝叶斯优化的关键因素。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大型语言模型（LLMs）可以在其潜在空间中编码复杂关系，然而利用它们在不确定性下的优化仍然具有挑战性。我们通过一种新的架构来解决这个问题，该架构将LLM微调重新定义为通过深度核方法进行高斯过程边缘似然优化。我们引入了基于LLM的深度核，与GPs联合优化，以保留LLMs提供丰富灵活的输入空间和GPs建模此空间并具有预测不确定性的优点。应用于Buchwald-Hartwig反应优化，我们的方法将高性能反应的发现率几乎翻倍（从24%到43%），且无需特定特征即可比特定领域的表示提高14%。在19个基准测试中，从一般化学到反应和分子性质优化的广泛实证评估证明了我们方法在任务、LLM架构（编码器、解码器、编码器-解码器）、预训练领域（与化学相关的或通用目的）和超参数设置（在单个数据集上一次调整）上的鲁棒性、通用性和持续改进。最后，我们解释了这些改进：通过边缘似然隐式执行的联合LLM-GP优化执行对比学习，对齐表示以产生更好的结构化嵌入空间、改进的不确定性校准和更有效的采样，无需任何外部损失。这项工作在样本高效优化方面提供了实际进展，并揭示了有效贝叶斯优化的关键因素。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) can encode complex relationships in their latentspaces, yet harnessing them for optimization under uncertainty remainschallenging. We address this gap with a novel architecture that reframes LLMfinetuning as Gaussian process (GP) marginal likelihood optimization via deepkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPsto preserve the benefits of both - LLMs to provide a rich and flexible inputspace for Bayesian optimization and - GPs to model this space with predictiveuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reactionoptimization, our method nearly doubles the discovery rate of high-performingreactions compared to static LLM embeddings (from 24% to 43% coverage of thetop 5% reactions in just 50 optimization iterations). We also observe a 14%improvement over domain-specific representations without requiring specializedfeatures. Extensive empirical evaluation across 19 benchmarks - ranging fromgeneral chemistry to reaction and molecular property optimization -demonstrates our method's robustness, generality, and consistent improvementsacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),(3) pretraining domains (chemistry-related or general-purpose) and (4)hyperparameter settings (tuned once on a single dataset). Finally, we explainthese improvements: joint LLM-GP optimization through marginal likelihoodimplicitly performs contrastive learning, aligning representations to produce(1) better-structured embedding spaces, (2) improved uncertainty calibration,and (3) more efficient sampling - without requiring any external loss. Thiswork provides both practical advances in sample-efficient optimization andinsights into what makes effective Bayesian optimization.</description>
      <author>example@mail.com (Bojana Ranković, Philippe Schwaller)</author>
      <guid isPermaLink="false">2504.06265v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Resource-efficient Inference with Foundation Model Programs</title>
      <link>http://arxiv.org/abs/2504.07247v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种利用基础模型程序来降低大型语言和视觉模型在生产部署中的推理时间资源成本的方法。&lt;h4&gt;背景&lt;/h4&gt;随着大型语言和视觉模型在生产部署中的应用，其推理时间的资源成本成为了一个日益严峻的挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种方法，以减少这些模型在运行时的资源消耗。&lt;h4&gt;方法&lt;/h4&gt;论文提出的方法将任务转化为程序，然后学习一个资源分配策略，该策略在每个输入上为每个程序模块选择不同资源成本和性能的基础模型‘后端’。对于简单的子任务使用较小的后端，而对于更复杂的子任务则利用更大、更强大的模型。&lt;h4&gt;主要发现&lt;/h4&gt;在两个新的“流式”视觉问答任务上评估了该方法，结果表明与单一的多模态模型相比，该实现实现了高达98%的资源节约，同时精度损失最小，展示了其可扩展和资源高效的多模态推理潜力。&lt;h4&gt;结论&lt;/h4&gt;该方法为解决大型语言和视觉模型在部署中的资源成本问题提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The inference-time resource costs of large language and vision models presenta growing challenge in production deployments. We propose the use of foundationmodel programs, i.e., programs that can invoke foundation models with varyingresource costs and performance, as an approach to this problem. Specifically,we present a method that translates a task into a program, then learns a policyfor resource allocation that, on each input, selects foundation model"backends" for each program module. The policy uses smaller, cheaper backendsto handle simpler subtasks, while allowing more complex subtasks to leveragelarger, more capable models. We evaluate the method on two new "streaming"visual question-answering tasks in which a system answers a question on asequence of inputs, receiving ground-truth feedback after each answer. Comparedto monolithic multi-modal models, our implementation achieves up to 98%resource savings with minimal accuracy loss, demonstrating its potential forscalable and resource-efficient multi-modal inference.</description>
      <author>example@mail.com (Lunyiu Nie, Zhimin Ding, Kevin Yu, Marco Cheung, Chris Jermaine, Swarat Chaudhuri)</author>
      <guid isPermaLink="false">2504.07247v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>A Multimedia Analytics Model for the Foundation Model Era</title>
      <link>http://arxiv.org/abs/2504.06138v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个针对基础模型时代的综合多媒体分析模型，旨在解决现有概念模型无法充分捕捉强大AI范式带来的复杂性。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型和代理人工智能的快速发展，多媒体分析领域正在经历变革，但现有的概念模型未能充分反映这一变化。&lt;h4&gt;目的&lt;/h4&gt;为了弥合这一差距，本文提出了一个专门为基础模型时代设计的多媒体分析模型。&lt;h4&gt;方法&lt;/h4&gt;该模型基于视觉分析、多媒体分析、知识生成、分析任务定义、混合倡议指导和人机协同强化学习等领域的现有框架，强调基于视觉分析代理的集成人机团队。&lt;h4&gt;主要发现&lt;/h4&gt;模型的核心在于专家用户与半自主分析过程之间无缝且明确可区分的交互渠道，确保用户意图与AI行为之间的持续对齐。此外，模型还解决了敏感领域如情报分析、调查性新闻等处理复杂、高风险数据的实际问题。&lt;h4&gt;结论&lt;/h4&gt;通过详细案例研究，本文展示了该模型如何促进对多媒体分析解决方案的深入理解和针对性改进。该概念框架明确捕捉了专家用户如何与AI驱动的多媒体分析系统进行最优交互和指导，为系统设计、比较和未来研究指明了方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：快速发展的基础模型和代理人工智能正在通过实现人类与分析系统之间更丰富、更复杂的交互来改变多媒体分析。然而，现有的视觉和多媒体分析概念模型并不能充分捕捉这些强大AI范式带来的复杂性。为了填补这一差距，我们提出了一种针对基础模型时代的综合多媒体分析模型。在视觉分析、多媒体分析、知识生成、分析任务定义、混合倡议指导和人机协同强化学习等现有框架的基础上，我们的模型强调基于视觉分析代理的集成人机团队。模型的核心在于专家用户与半自主分析过程之间无缝且明确可区分的交互渠道，确保用户意图与AI行为之间的持续对齐。模型解决了敏感领域如情报分析、调查性新闻等处理复杂、高风险数据的实际问题。通过详细案例研究，我们展示了我们的模型如何促进对多媒体分析解决方案的深入理解和针对性改进。通过明确捕捉专家用户如何与AI驱动的多媒体分析系统进行最优交互和指导，我们的概念框架为系统设计、比较和未来研究指明了方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advances in Foundation Models and agentic Artificial Intelligenceare transforming multimedia analytics by enabling richer, more sophisticatedinteractions between humans and analytical systems. Existing conceptual modelsfor visual and multimedia analytics, however, do not adequately capture thecomplexity introduced by these powerful AI paradigms. To bridge this gap, wepropose a comprehensive multimedia analytics model specifically designed forthe foundation model era. Building upon established frameworks from visualanalytics, multimedia analytics, knowledge generation, analytic taskdefinition, mixed-initiative guidance, and human-in-the-loop reinforcementlearning, our model emphasizes integrated human-AI teaming based on visualanalytics agents from both technical and conceptual perspectives. Central tothe model is a seamless, yet explicitly separable, interaction channel betweenexpert users and semi-autonomous analytical processes, ensuring continuousalignment between user intent and AI behavior. The model addresses practicalchallenges in sensitive domains such as intelligence analysis, investigativejournalism, and other fields handling complex, high-stakes data. We illustratethrough detailed case studies how our model facilitates deeper understandingand targeted improvement of multimedia analytics solutions. By explicitlycapturing how expert users can optimally interact with and guide AI-poweredmultimedia analytics systems, our conceptual framework sets a clear directionfor system design, comparison, and future research.</description>
      <author>example@mail.com (Marcel Worring, Jan Zahálka, Stef van den Elzen, Maximilian T. Fischer, Daniel A. Keim)</author>
      <guid isPermaLink="false">2504.06138v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>SINCon: Mitigate LLM-Generated Malicious Message Injection Attack for Rumor Detection</title>
      <link>http://arxiv.org/abs/2504.07135v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SINCon的防御机制，用于提高基于Message Propagation Trees的谣言检测系统对利用大型语言模型生成和注入恶意信息的攻击的抵抗力。&lt;h4&gt;背景&lt;/h4&gt;随着大型语言模型（LLMs）的快速发展，基于Message Propagation Trees（MPTs）的谣言检测系统正面临来自利用LLMs生成和注入恶意信息的对抗性攻击的威胁。&lt;h4&gt;目的&lt;/h4&gt;旨在提高模型对LLM驱动的信息注入攻击的抵抗力，同时保持对干净数据的分类准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为SINCon的防御机制，该机制通过对比学习鼓励模型学习到具有不同重要性的节点对预测具有更均匀影响的图表示。&lt;h4&gt;主要发现&lt;/h4&gt;在Twitter和Weibo数据集上的大量实验表明，SINCon不仅保持了在干净数据上的高分类准确性，而且显著增强了对抗LLM驱动的信息注入攻击的抵抗力。&lt;h4&gt;结论&lt;/h4&gt;SINCon是一种有效的防御机制，可以增强基于MPTs的谣言检测系统对LLM驱动的攻击的抵抗力，同时保持对干净数据的分类性能。&lt;h4&gt;翻译&lt;/h4&gt;在快速发展的LLMs时代，基于消息传播树（MPTs）的谣言检测系统，尤其是那些基于MPTs的系统，正面临来自利用LLMs生成和注入恶意信息的对抗性攻击的威胁。现有方法基于不同节点对预测具有不同影响程度的假设。它们将具有高预测影响度的节点定义为重要节点，并针对这些节点进行攻击。如果模型对节点预测影响度的处理更加均匀，攻击者将更难针对具有高预测影响度的节点。在本文中，我们提出了一个名为SINCon的防御机制，该机制鼓励模型学习具有不同重要性的节点对预测具有更均匀影响的图表示。在Twitter和Weibo数据集上的大量实验表明，SINCon不仅保持了在干净数据上的高分类准确性，而且显著增强了抵抗LLM驱动的信息注入攻击的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of rapidly evolving large language models (LLMs), state-of-the-artrumor detection systems, particularly those based on Message Propagation Trees(MPTs), which represent a conversation tree with the post as its root and thereplies as its descendants, are facing increasing threats from adversarialattacks that leverage LLMs to generate and inject malicious messages. Existingmethods are based on the assumption that different nodes exhibit varyingdegrees of influence on predictions. They define nodes with high predictiveinfluence as important nodes and target them for attacks. If the model treatsnodes' predictive influence more uniformly, attackers will find it harder totarget high predictive influence nodes. In this paper, we propose Similarizingthe predictive Influence of Nodes with Contrastive Learning (SINCon), a defensemechanism that encourages the model to learn graph representations where nodeswith varying importance have a more uniform influence on predictions. Extensiveexperiments on the Twitter and Weibo datasets demonstrate that SINCon not onlypreserves high classification accuracy on clean data but also significantlyenhances resistance against LLM-driven message injection attacks.</description>
      <author>example@mail.com (Mingqing Zhang, Qiang Liu, Xiang Tao, Shu Wu, Liang Wang)</author>
      <guid isPermaLink="false">2504.07135v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>LATTE: Lightweight Attention-based Traffic Accident Anticipation Engine</title>
      <link>http://arxiv.org/abs/2504.04103v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accept by Information Fusion (Elsevier)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为LATTE的轻量级注意力交通事故预测引擎，该引擎在资源受限的环境中能够准确预测实时交通事故，并具有高效的计算性能。&lt;h4&gt;背景&lt;/h4&gt;准确预测实时交通事故在自动驾驶中是一个关键挑战，尤其是在资源受限的环境中，现有的解决方案往往计算开销高或无法充分解决不断变化的交通场景的不确定性。&lt;h4&gt;目的&lt;/h4&gt;提出一种轻量级注意力交通事故预测引擎，以解决上述挑战。&lt;h4&gt;方法&lt;/h4&gt;LATTE采用高效多尺度空间聚合（EMSA）来捕捉不同尺度的空间特征，记忆注意力聚合（MAA）来增强时间建模，以及辅助自我注意力聚合（AAA）来提取扩展序列中的潜在依赖关系。此外，LATTE还集成了Flamingo警报辅助系统（FAA），利用视觉语言模型提供实时、认知可访问的口头危险警报，提高乘客对情境的认识。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集（DAD、CCD、A3D）上的评估表明，LATTE具有优越的预测能力和计算效率。在DAD基准上，LATTE达到了89.74%的平均精度（AP），比第二好的模型平均时间到事故（mTTA）高出5.4%，在80%的召回率（TTA@R80）下保持有竞争力的mTTA（4.04秒），并在不同的驾驶条件下展示了稳健的事故预测能力。其轻量级设计将浮点运算（FLOPs）减少了93.14%，参数数量减少了31.58%，在资源有限的硬件上实现实时运行而不影响性能。&lt;h4&gt;结论&lt;/h4&gt;LATTE的有效性得到了消融研究的证实，而可视化失败案例分析突出了其实际应用性和改进领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在自动驾驶中，准确预测实时交通事故是一个关键挑战，尤其是在资源受限的环境中。现有解决方案通常存在计算开销高或无法充分解决不断变化的交通场景的不确定性。本文提出了一种名为LATTE的轻量级注意力交通事故预测引擎，该引擎将计算效率与最先进的性能相结合。LATTE采用高效多尺度空间聚合（EMSA）来捕捉不同尺度的空间特征，记忆注意力聚合（MAA）来增强时间建模，以及辅助自我注意力聚合（AAA）来提取扩展序列中的潜在依赖关系。此外，LATTE还集成了Flamingo警报辅助系统（FAA），利用视觉语言模型提供实时、认知可访问的口头危险警报，提高乘客对情境的认识。在基准数据集（DAD、CCD、A3D）上的评估表明，LATTE具有优越的预测能力和计算效率。在DAD基准上，LATTE达到了89.74%的平均精度（AP），比第二好的模型平均时间到事故（mTTA）高出5.4%，在80%的召回率（TTA@R80）下保持有竞争力的mTTA（4.04秒），并在不同的驾驶条件下展示了稳健的事故预测能力。其轻量级设计将浮点运算（FLOPs）减少了93.14%，参数数量减少了31.58%，在资源有限的硬件上实现实时运行而不影响性能。消融研究证实了LATTE架构组件的有效性，而可视化失败案例分析突出了其实际应用性和改进领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately predicting traffic accidents in real-time is a critical challengein autonomous driving, particularly in resource-constrained environments.Existing solutions often suffer from high computational overhead or fail toadequately address the uncertainty of evolving traffic scenarios. This paperintroduces LATTE, a Lightweight Attention-based Traffic Accident AnticipationEngine, which integrates computational efficiency with state-of-the-artperformance. LATTE employs Efficient Multiscale Spatial Aggregation (EMSA) tocapture spatial features across scales, Memory Attention Aggregation (MAA) toenhance temporal modeling, and Auxiliary Self-Attention Aggregation (AAA) toextract latent dependencies over extended sequences. Additionally, LATTEincorporates the Flamingo Alert-Assisted System (FAA), leveraging avision-language model to provide real-time, cognitively accessible verbalhazard alerts, improving passenger situational awareness. Evaluations onbenchmark datasets (DAD, CCD, A3D) demonstrate LATTE's superior predictivecapabilities and computational efficiency. LATTE achieves state-of-the-art89.74% Average Precision (AP) on DAD benchmark, with 5.4% higher meanTime-To-Accident (mTTA) than the second-best model, and maintains competitivemTTA at a Recall of 80% (TTA@R80) (4.04s) while demonstrating robust accidentanticipation across diverse driving conditions. Its lightweight design deliversa 93.14% reduction in floating-point operations (FLOPs) and a 31.58% decreasein parameter count (Params), enabling real-time operation on resource-limitedhardware without compromising performance. Ablation studies confirm theeffectiveness of LATTE's architectural components, while visualizations andfailure case analyses highlight its practical applicability and areas forenhancement.</description>
      <author>example@mail.com (Jiaxun Zhang, Yanchen Guan, Chengyue Wang, Haicheng Liao, Guohui Zhang, Zhenning Li)</author>
      <guid isPermaLink="false">2504.04103v2</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Boundary representation learning via Transformer</title>
      <link>http://arxiv.org/abs/2504.07134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为边界表示变换器（BRT）的新方法，该方法将Transformer网络应用于边界表示（B-rep）模型的学习，以解决计算机辅助设计（CAD）领域的挑战。&lt;h4&gt;背景&lt;/h4&gt;近年来，由Transformer网络驱动的生成式人工智能在自然语言处理、计算机视觉和图形领域取得了显著成功。然而，Transformer在计算机辅助设计（CAD）领域的应用，尤其是处理边界表示（B-rep）模型，还相对较少。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文提出了Boundary Representation Transformer（BRT），这是一种新的方法，用于将Transformer适应于B-rep学习。&lt;h4&gt;方法&lt;/h4&gt;BRT提出了一个连续几何嵌入方法，将B-rep表面（修剪和未修剪的）编码为贝塞尔三角形，在不进行离散化的情况下保留其形状和连续性。此外，BRT还采用了一种拓扑感知的嵌入方法，将几何嵌入组织成一个序列的离散标记，适合于Transformer，以捕获B-rep模型中的几何和拓扑特征。这使得Transformer的关注机制能够有效地学习B-rep模型中边界元素的形状模式和上下文语义。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量的实验，证明了BRT在部分分类和特征识别任务中达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;BRT为B-rep模型学习提供了一种有效的解决方案，并展示了Transformer在CAD领域的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent rise of generative artificial intelligence (AI), powered byTransformer networks, has achieved remarkable success in natural languageprocessing, computer vision, and graphics. However, the application ofTransformers in computer-aided design (CAD), particularly for processingboundary representation (B-rep) models, remains largely unexplored. To bridgethis gap, this paper introduces Boundary Representation Transformer (BRT), anovel method adapting Transformer for B-rep learning. B-rep models pose uniquechallenges due to their irregular topology and continuous geometricdefinitions, which are fundamentally different from the structured and discretedata Transformers are designed for. To address this, BRT proposes a continuousgeometric embedding method that encodes B-rep surfaces (trimmed and untrimmed)into B\'ezier triangles, preserving their shape and continuity withoutdiscretization. Additionally, BRT employs a topology-aware embedding methodthat organizes these geometric embeddings into a sequence of discrete tokenssuitable for Transformers, capturing both geometric and topologicalcharacteristics within B-rep models. This enables the Transformer's attentionmechanism to effectively learn shape patterns and contextual semantics ofboundary elements in a B-rep model. Extensive experiments demonstrate that BRTachieves state-of-the-art performance in part classification and featurerecognition tasks.</description>
      <author>example@mail.com (Qiang Zou, Lizhen Zhu)</author>
      <guid isPermaLink="false">2504.07134v1</guid>
      <pubDate>Fri, 11 Apr 2025 14:16:31 +0800</pubDate>
    </item>
    <item>
      <title>Are We Done with Object-Centric Learning?</title>
      <link>http://arxiv.org/abs/2504.07092v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要讨论了以对象为中心的学习（OCL）方法，该方法旨在学习仅编码对象的表示，并从场景中的其他对象或背景线索中隔离出来。文章提出了OCL方法在无监督对象发现、样本高效组合和结构化环境建模等方面的应用，并介绍了一种新的无监督探测方法OCCAM，以解决现实应用中的挑战。&lt;h4&gt;背景&lt;/h4&gt;OCL方法旨在学习仅编码对象的表示，并从场景中的其他对象或背景线索中隔离出来，以支持各种目标，包括分布外（OOD）泛化、样本高效组合和结构化环境的建模。&lt;h4&gt;目的&lt;/h4&gt;OCL方法的目标是获得以对象为中心的表示，以支持OOD泛化、样本高效组合和结构化环境的建模。&lt;h4&gt;方法&lt;/h4&gt;文章提出了一种新的无监督探测方法OCCAM，该方法通过研究由虚假背景线索引起的OOD泛化挑战，证明了基于分割的对象编码在性能上优于基于槽的OCL方法。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，基于分割的对象编码在OOD对象发现基准测试中表现出色，且OCL方法可以扩展到基础模型，并能够处理可变数量的槽。&lt;h4&gt;结论&lt;/h4&gt;尽管OCL方法在实现对象为中心的表示方面取得了很大进展，但如何将场景中分离对象的能力与更广泛的OCL目标（如OOD泛化）联系起来仍是一个关键问题。文章提出了OCCAM方法，并提供了OCL社区的工具箱，以用于可扩展的对象为中心的表示，并关注实际应用和基本问题，如理解人类认知中的对象感知。&lt;h4&gt;翻译&lt;/h4&gt;摘要：以对象为中心的学习（OCL）旨在学习仅编码对象的表示，从场景中的其他对象或背景线索中隔离出来。这种方法支持各种目标，包括分布外（OOD）泛化、样本高效组合和结构化环境的建模。大多数研究集中在开发无监督机制，将对象分离到表示空间中的离散槽中，并通过无监督对象发现进行评估。然而，随着近期样本高效的分割模型的出现，我们可以在像素空间中分离对象并独立编码它们。这实现了在OOD对象发现基准测试上的显著零样本性能，可扩展到基础模型，并且可以开箱即用地处理可变数量的槽。因此，OCL方法获得对象为中心的表示的目标已经基本实现。尽管取得了这些进展，但一个关键问题仍然存在：在场景中分离对象的能力如何有助于更广泛的OCL目标，如OOD泛化？我们通过OCL的视角来研究由虚假背景线索引起的OOD泛化挑战。我们提出了一种新颖的无监督探测方法，称为OCCAM，证明了基于分割的个体对象编码在性能上显著优于基于槽的OCL方法。然而，现实应用中仍然存在挑战。我们为OCL社区提供了工具箱，以使用可扩展的对象为中心的表示，并专注于实际应用和基本问题，例如理解人类认知中的对象感知。我们的代码可在以下链接找到：https://github.com/AlexanderRubinstein/OCCAM&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object-centric learning (OCL) seeks to learn representations that only encodean object, isolated from other objects or background cues in a scene. Thisapproach underpins various aims, including out-of-distribution (OOD)generalization, sample-efficient composition, and modeling of structuredenvironments. Most research has focused on developing unsupervised mechanismsthat separate objects into discrete slots in the representation space,evaluated using unsupervised object discovery. However, with recentsample-efficient segmentation models, we can separate objects in the pixelspace and encode them independently. This achieves remarkable zero-shotperformance on OOD object discovery benchmarks, is scalable to foundationmodels, and can handle a variable number of slots out-of-the-box. Hence, thegoal of OCL methods to obtain object-centric representations has been largelyachieved. Despite this progress, a key question remains: How does the abilityto separate objects within a scene contribute to broader OCL objectives, suchas OOD generalization? We address this by investigating the OOD generalizationchallenge caused by spurious background cues through the lens of OCL. Wepropose a novel, training-free probe called $\textbf{Object-CentricClassification with Applied Masks (OCCAM)}$, demonstrating thatsegmentation-based encoding of individual objects significantly outperformsslot-based OCL methods. However, challenges in real-world applications remain.We provide the toolbox for the OCL community to use scalable object-centricrepresentations, and focus on practical applications and fundamental questions,such as understanding object perception in human cognition. Our code isavailable $\href{https://github.com/AlexanderRubinstein/OCCAM}{here}$.</description>
      <author>example@mail.com (Alexander Rubinstein, Ameya Prabhu, Matthias Bethge, Seong Joon Oh)</author>
      <guid isPermaLink="false">2504.07092v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
  <item>
      <title>Generalized Semantic Contrastive Learning via Embedding Side Information for Few-Shot Object Detection</title>
      <link>http://arxiv.org/abs/2504.07060v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by T-PAMI (IEEE Transactions on Pattern Analysis and Machine  Intelligence)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法来解决少量样本目标检测（FSOD）问题，通过引入侧信息来缓解特征空间和样本视角带来的负面影响，并提高模型在未知场景中的适应性。&lt;h4&gt;背景&lt;/h4&gt;FSOD旨在通过少量训练样本检测新类别对象，但面临基础类别空间中数据有限的问题。&lt;h4&gt;目的&lt;/h4&gt;提高FSOD在未知场景中的检测能力。&lt;h4&gt;方法&lt;/h4&gt;1. 利用嵌入侧信息构建知识矩阵，量化基础类别和新类别之间的语义关系。2. 开发基于侧信息的上下文语义监督对比学习，增强语义相似类别之间的区分度。3. 引入侧信息引导的区域感知掩码模块，通过反事实解释找到和放弃区分相似类别的偏置信息，进一步细化判别表示空间。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入侧信息和改进的特征表示学习，模型在多个基准数据集上优于现有方法，显著提高了FSOD在多数射击/分割情况下的能力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效解决FSOD中的特征空间和样本视角问题，提高了模型在未知场景中的检测性能。&lt;h4&gt;翻译&lt;/h4&gt;The objective of few-shot object detection (FSOD) is to detect novel objects with few training samples. The core challenge of this task is how to construct a generalized feature space for novel categories with limited data on the basis of the base category space, which could adapt the learned detection model to unknown scenarios. However, limited by insufficient samples for novel categories, two issues still exist: (1) the features of the novel category are easily implicitly represented by the features of the base category, leading to inseparable classifier boundaries, (2) novel categories with fewer data are not enough to fully represent the distribution, where the model fine-tuning is prone to overfitting. To address these issues, we introduce the side information to alleviate the negative influences derived from the feature space and sample viewpoints and formulate a novel generalized feature representation learning method for FSOD. Specifically, we first utilize embedding side information to construct a knowledge matrix to quantify the semantic relationship between the base and novel categories. Then, to strengthen the discrimination between semantically similar categories, we further develop contextual semantic supervised contrastive learning which embeds side information. Furthermore, to prevent overfitting problems caused by sparse samples, a side-information guided region-aware masked module is introduced to augment the diversity of samples, which finds and abandons biased information that discriminates between similar categories via counterfactual explanation, and refines the discriminative representation space further. Extensive experiments using ResNet and ViT backbones on PASCAL VOC, MS COCO, LVIS V1, FSOD-1K, and FSVOD-500 benchmarks demonstrate that our model outperforms the previous state-of-the-art methods, significantly improving the ability of FSOD in most shots/splits.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The objective of few-shot object detection (FSOD) is to detect novel objectswith few training samples. The core challenge of this task is how to constructa generalized feature space for novel categories with limited data on the basisof the base category space, which could adapt the learned detection model tounknown scenarios. However, limited by insufficient samples for novelcategories, two issues still exist: (1) the features of the novel category areeasily implicitly represented by the features of the base category, leading toinseparable classifier boundaries, (2) novel categories with fewer data are notenough to fully represent the distribution, where the model fine-tuning isprone to overfitting. To address these issues, we introduce the sideinformation to alleviate the negative influences derived from the feature spaceand sample viewpoints and formulate a novel generalized feature representationlearning method for FSOD. Specifically, we first utilize embedding sideinformation to construct a knowledge matrix to quantify the semanticrelationship between the base and novel categories. Then, to strengthen thediscrimination between semantically similar categories, we further developcontextual semantic supervised contrastive learning which embeds sideinformation. Furthermore, to prevent overfitting problems caused by sparsesamples, a side-information guided region-aware masked module is introduced toaugment the diversity of samples, which finds and abandons biased informationthat discriminates between similar categories via counterfactual explanation,and refines the discriminative representation space further. Extensiveexperiments using ResNet and ViT backbones on PASCAL VOC, MS COCO, LVIS V1,FSOD-1K, and FSVOD-500 benchmarks demonstrate that our model outperforms theprevious state-of-the-art methods, significantly improving the ability of FSODin most shots/splits.</description>
      <author>example@mail.com (Ruoyu Chen, Hua Zhang, Jingzhi Li, Li Liu, Zhen Huang, Xiaochun Cao)</author>
      <guid isPermaLink="false">2504.07060v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>EDIT: Enhancing Vision Transformers by Mitigating Attention Sink through an Encoder-Decoder Architecture</title>
      <link>http://arxiv.org/abs/2504.06738v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EDIT（编码器-解码器图像变换器）的新型架构，旨在减轻视觉变换器模型中观察到的注意力汇聚现象。&lt;h4&gt;背景&lt;/h4&gt;注意力汇聚现象是指过多的注意力集中在[CLS]标记上，从而扭曲模型有效处理图像块的能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决这个问题，研究者引入了一种层对齐的编码器-解码器架构，其中编码器使用自注意力来处理图像块，而解码器则使用交叉注意力来关注[CLS]标记。&lt;h4&gt;方法&lt;/h4&gt;与传统的编码器-解码器框架不同，EDIT允许解码器从低级特征开始提取信息，并逐层逐步细化表示。&lt;h4&gt;主要发现&lt;/h4&gt;通过序列注意力图证明了EDIT的可解释性，这些图说明了逐层对关键图像特征的精细关注。&lt;h4&gt;结论&lt;/h4&gt;在ImageNet-1k和ImageNet-21k上的实验以及迁移学习任务中，EDIT在性能上超过了DeiT3模型，这些结果表明EDIT的设计在解决注意力汇聚和改进视觉特征提取方面是有效的。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了一种新的架构EDIT（编码器-解码器图像变换器），旨在缓解在视觉变换器模型中观察到的注意力汇聚现象。当注意力过多地集中在[CLS]标记上时，会发生注意力汇聚现象，这会扭曲模型有效处理图像块的能力。为了解决这个问题，我们引入了一种层对齐的编码器-解码器架构，其中编码器使用自注意力来处理图像块，而解码器则使用交叉注意力来关注[CLS]标记。与传统的编码器-解码器框架不同，EDIT允许解码器从低级特征开始提取信息，并逐层逐步细化表示。通过序列注意力图证明了EDIT的可解释性，这些图说明了逐层对关键图像特征的精细关注。在ImageNet-1k和ImageNet-21k上的实验以及迁移学习任务中，EDIT在性能上超过了DeiT3模型，这些结果表明EDIT的设计在解决注意力汇聚和改进视觉特征提取方面是有效的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose EDIT (Encoder-Decoder Image Transformer), a novelarchitecture designed to mitigate the attention sink phenomenon observed inVision Transformer models. Attention sink occurs when an excessive amount ofattention is allocated to the [CLS] token, distorting the model's ability toeffectively process image patches. To address this, we introduce alayer-aligned encoder-decoder architecture, where the encoder utilizesself-attention to process image patches, while the decoder uses cross-attentionto focus on the [CLS] token. Unlike traditional encoder-decoder framework,where the decoder depends solely on high-level encoder representations, EDITallows the decoder to extract information starting from low-level features,progressively refining the representation layer by layer. EDIT is naturallyinterpretable demonstrated through sequential attention maps, illustrating therefined, layer-by-layer focus on key image features. Experiments on ImageNet-1kand ImageNet-21k, along with transfer learning tasks, show that EDIT achievesconsistent performance improvements over DeiT3 models. These results highlightthe effectiveness of EDIT's design in addressing attention sink and improvingvisual feature extraction.</description>
      <author>example@mail.com (Wenfeng Feng, Guoying Sun)</author>
      <guid isPermaLink="false">2504.06738v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>RayFronts: Open-Set Semantic Ray Frontiers for Online Scene Understanding and Exploration</title>
      <link>http://arxiv.org/abs/2504.06994v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Open-set语义映射对开放世界机器人至关重要，现有方法在深度范围或限制性环境中仅映射超出范围的实体，无法结合近场和远场观察，且在细粒度语义和效率之间进行权衡。本文介绍了RayFronts，一种统一的表示方法，它能够实现密集和超出范围的语义映射。&lt;h4&gt;背景&lt;/h4&gt;开放世界机器人的语义映射对机器人的导航和交互能力至关重要，但目前的方法存在深度范围限制、效率与细粒度语义之间的权衡等问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，实现既密集又高效的语义映射，以便机器人能够在近场和远场范围内做出明智的决策。&lt;h4&gt;方法&lt;/h4&gt;RayFronts通过编码任务无关的开集语义到近场体素和地图边界编码的远场射线，从而减少搜索体积，并在Orin AGX上以8.84 Hz的频率运行。此外，提出了一种规划无关的评估框架，以捕捉在线超出范围搜索和探索的效用。&lt;h4&gt;主要发现&lt;/h4&gt;在近场语义的基准测试中，RayFronts的细粒度图像编码提供了1.34倍的零样本3D语义分割性能，并通过16.5倍的吞吐量来提高效率。与最接近的在线基线相比，RayFronts将搜索体积减少了2.2倍。&lt;h4&gt;结论&lt;/h4&gt;RayFronts是一种有效的语义映射方法，能够在保证性能的同时提高效率，并通过新的评估框架改善了在线超出范围搜索和探索的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-set semantic mapping is crucial for open-world robots. Current mappingapproaches either are limited by the depth range or only map beyond-rangeentities in constrained settings, where overall they fail to combinewithin-range and beyond-range observations. Furthermore, these methods make atrade-off between fine-grained semantics and efficiency. We introduceRayFronts, a unified representation that enables both dense and beyond-rangeefficient semantic mapping. RayFronts encodes task-agnostic open-set semanticsto both in-range voxels and beyond-range rays encoded at map boundaries,empowering the robot to reduce search volumes significantly and make informeddecisions both within &amp; beyond sensory range, while running at 8.84 Hz on anOrin AGX. Benchmarking the within-range semantics shows that RayFronts'sfine-grained image encoding provides 1.34x zero-shot 3D semantic segmentationperformance while improving throughput by 16.5x. Traditionally, online mappingperformance is entangled with other system components, complicating evaluation.We propose a planner-agnostic evaluation framework that captures the utilityfor online beyond-range search and exploration, and show RayFronts reducessearch volume 2.2x more efficiently than the closest online baselines.</description>
      <author>example@mail.com (Omar Alama, Avigyan Bhattacharya, Haoyang He, Seungchan Kim, Yuheng Qiu, Wenshan Wang, Cherie Ho, Nikhil Keetha, Sebastian Scherer)</author>
      <guid isPermaLink="false">2504.06994v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>UAV Position Estimation using a LiDAR-based 3D Object Detection Method</title>
      <link>http://arxiv.org/abs/2504.07028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在无GPS环境中，通过深度学习方法进行3D物体检测，计算配备LiDAR传感器的无人机（UAV）与无人地面车（UGV）之间相对位置的方法。&lt;h4&gt;背景&lt;/h4&gt;在GPS信号不可用的环境中，精确定位无人机需要非GPS依赖的定位技术。&lt;h4&gt;目的&lt;/h4&gt;利用深度学习方法和3D检测算法确定无人机的相对位置。&lt;h4&gt;方法&lt;/h4&gt;通过评估LiDAR传感器数据，采用PointPillars算法结合列体素点云表示和2D卷积神经网络（CNN）生成独特的点云特征来识别无人机。定位方法利用点云分割、欧几里得聚类和预定义启发式算法获取无人机相对位置。然后，将两种方法的输出与参考真值解进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;PointPillars算法有效地用于识别无人机并计算其相对位置。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了深度学习方法和3D检测算法在无GPS环境中无人机定位的可行性和有效性。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了应用深度学习方法进行3D物体检测，从配备激光雷达传感器的无人机（UAV）在无GPS环境下计算无人机与无人地面车（UGV）之间相对位置的方法。通过评估激光雷达传感器数据，采用PointPillars算法（结合列体素点云表示和2D卷积神经网络CNN）生成表示待识别物体的独特点云特征，识别无人机。当前的定位方法利用点云分割、欧几里得聚类和预定义启发式算法来获得无人机的相对位置。然后，将两种方法的结果与参考真值解进行比较。研究结果表明，PointPillars算法有效地用于识别无人机并计算其相对位置，证明了在无GPS环境中无人机定位的深度学习方法和3D检测算法的可行性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/PLANS53410.2023.10139979&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the use of applying a deep learning approach for 3Dobject detection to compute the relative position of an Unmanned Aerial Vehicle(UAV) from an Unmanned Ground Vehicle (UGV) equipped with a LiDAR sensor in aGPS-denied environment. This was achieved by evaluating the LiDAR sensor's datathrough a 3D detection algorithm (PointPillars). The PointPillars algorithmincorporates a column voxel point-cloud representation and a 2D ConvolutionalNeural Network (CNN) to generate distinctive point-cloud features representingthe object to be identified, in this case, the UAV. The current localizationmethod utilizes point-cloud segmentation, Euclidean clustering, and predefinedheuristics to obtain the relative position of the UAV. Results from the twomethods were then compared to a reference truth solution.</description>
      <author>example@mail.com (Uthman Olawoye, Jason N. Gross)</author>
      <guid isPermaLink="false">2504.07028v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>FACT: Multinomial Misalignment Classification for Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2504.06627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at SCIA 2025 (the Scandinavian Conference on Image Analysis  2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FACT的方法，用于预测注册激光雷达点云对的配准质量（即注册误差）。该方法对于大型自动注册的3D模型的质量保证非常有用。&lt;h4&gt;背景&lt;/h4&gt;目前已有研究关注于注册错误的二元配准分类，本文将这一研究推广到多项式配准分类。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效预测注册点云对配准质量的方法，并提高现有方法的性能。&lt;h4&gt;方法&lt;/h4&gt;FACT从注册的点云对中提取局部特征，并使用基于点变换器的网络对这些特征进行处理，以预测不匹配类别。该方法引入了一种自定义的回归分类损失函数，结合了交叉熵和Wasserstein损失，并证明了其优于直接回归和先前的二元分类。&lt;h4&gt;主要发现&lt;/h4&gt;FACT能够成功分类使用经典ICP和GeoTransformer注册的点云对，而其他选择，如标准点云质量指标和注册残差，在预测不匹配方面表现不佳。在CorAl方法引入的合成扰动点云任务中，FACT的性能显著优于CorAl。此外，FACT还可以帮助专家纠正不匹配的点云图。&lt;h4&gt;结论&lt;/h4&gt;FACT是一种有效的点云配准质量预测方法，能够提高现有技术的性能，并有助于专家进行点云图的校正。&lt;h4&gt;翻译&lt;/h4&gt;We present FACT, a method for predicting alignment quality (i.e., registration error) of registered lidar point cloud pairs. This is useful e.g. for quality assurance of large, automatically registered 3D models. FACT extracts local features from a registered pair and processes them with a point transformer-based network to predict a misalignment class. We generalize prior work that study binary alignment classification of registration errors, by recasting it as multinomial misalignment classification. To achieve this, we introduce a custom regression-by-classification loss function that combines the cross-entropy and Wasserstein losses, and demonstrate that it outperforms both direct regression and prior binary classification. FACT successfully classifies point-cloud pairs registered with both the classical ICP and GeoTransformer, while other choices, such as standard point-cloud-quality metrics and registration residuals are shown to be poor choices for predicting misalignment. On a synthetically perturbed point-cloud task introduced by the CorAl method, we show that FACT achieves substantially better performance than CorAl. Finally, we demonstrate how FACT can assist experts in correcting misaligned point-cloud maps. Our code is available at https://github.com/LudvigDillen/FACT_for_PCMC.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present FACT, a method for predicting alignment quality (i.e.,registration error) of registered lidar point cloud pairs. This is useful e.g.for quality assurance of large, automatically registered 3D models. FACTextracts local features from a registered pair and processes them with a pointtransformer-based network to predict a misalignment class. We generalize priorwork that study binary alignment classification of registration errors, byrecasting it as multinomial misalignment classification. To achieve this, weintroduce a custom regression-by-classification loss function that combines thecross-entropy and Wasserstein losses, and demonstrate that it outperforms bothdirect regression and prior binary classification. FACT successfully classifiespoint-cloud pairs registered with both the classical ICP and GeoTransformer,while other choices, such as standard point-cloud-quality metrics andregistration residuals are shown to be poor choices for predictingmisalignment. On a synthetically perturbed point-cloud task introduced by theCorAl method, we show that FACT achieves substantially better performance thanCorAl. Finally, we demonstrate how FACT can assist experts in correctingmisaligned point-cloud maps. Our code is available athttps://github.com/LudvigDillen/FACT_for_PCMC.</description>
      <author>example@mail.com (Ludvig Dillén, Per-Erik Forssén, Johan Edstedt)</author>
      <guid isPermaLink="false">2504.06627v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning</title>
      <link>http://arxiv.org/abs/2504.06958v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了利用强化学习提升多模态大型语言模型在视频理解方面的推理能力，特别是通过RFT（强化微调）和GRPO（分组相对策略优化）技术。&lt;h4&gt;背景&lt;/h4&gt;虽然强化学习在文本和图像领域取得进展，但在视频理解方面的应用还有限。&lt;h4&gt;目的&lt;/h4&gt;旨在通过RFT和GRPO提高视频MLLM的时空感知能力，同时保持其一般能力。&lt;h4&gt;方法&lt;/h4&gt;通过在有限的样本上对时空感知目标进行多任务RFT，开发了VideoChat-R1，这是一种强大的视频MLLM。&lt;h4&gt;主要发现&lt;/h4&gt;VideoChat-R1在时空感知任务上达到了最先进的性能，同时在聊天能力上没有牺牲，并表现出时空推理能力。与Qwen2.5-VL-7B相比，它在时间基准和对象跟踪任务上的性能提高了几倍。此外，它在一般QAbenchmarks如VideoMME、MVBench和Perception Test上的表现也显著提升。&lt;h4&gt;结论&lt;/h4&gt;RFT对于视频MLLM的特定任务增强具有潜力，希望这项工作为视频MLLM中的RL研究提供有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces the use of reinforcement learning to enhance the reasoning capabilities of multimodal large language models (MLLMs) in video understanding, particularly through the techniques of RFT (Reinforcement Fine-Tuning) and GRPO (Group Relative Policy Optimization).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in reinforcement learning have significantly advanced thereasoning capabilities of multimodal large language models (MLLMs). Whileapproaches such as Group Relative Policy Optimization (GRPO) and rule-basedreward mechanisms demonstrate promise in text and image domains, theirapplication to video understanding remains limited. This paper presents asystematic exploration of Reinforcement Fine-Tuning (RFT) with GRPO for videoMLLMs, aiming to enhance spatio-temporal perception while maintaining generalcapabilities. Our experiments reveal that RFT is highly data-efficient fortask-specific improvements. Through multi-task RFT on spatio-temporalperception objectives with limited samples, we develop VideoChat-R1, a powerfulvideo MLLM that achieves state-of-the-art performance on spatio-temporalperception tasks without sacrificing chat ability, while exhibiting emergingspatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1boosts performance several-fold in tasks like temporal grounding (+31.8) andobject tracking (+31.2). Additionally, it significantly improves on general QAbenchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9).Our findings underscore the potential of RFT for specialized task enhancementof Video MLLMs. We hope our work offers valuable insights for future RLresearch in video MLLMs.</description>
      <author>example@mail.com (Xinhao Li, Ziang Yan, Desen Meng, Lu Dong, Xiangyu Zeng, Yinan He, Yali Wang, Yu Qiao, Yi Wang, Limin Wang)</author>
      <guid isPermaLink="false">2504.06958v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Machine Learning Approach towards Quantum Error Mitigation for Accurate Molecular Energetics</title>
      <link>http://arxiv.org/abs/2504.07077v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络和回归机器学习架构的方法，用于在量子计算机上实现分子哈密顿量的误差缓解（EM）技术，以减少噪声对计算的影响。&lt;h4&gt;背景&lt;/h4&gt;尽管在实现混合量子-经典算法方面付出了大量努力，但由于硬件噪声，这些算法主要局限于原理证明。容忍错误的实现是长期目标，但使用现有错误缓解技术通过当前的噪声中等规模量子（NISQ）设备超越小分子是一项挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法，使用统计学习方法来学习噪声及其随后的缓解，以实现分子哈密顿量的误差缓解，而无需指数级的计算开销。&lt;h4&gt;方法&lt;/h4&gt;设计了一个图神经网络和基于回归的机器学习架构，通过在精心选择的浅层子电路集合上训练，这些子电路遵循原始硬件架构。硬件连接性网络被映射到一个有向图，该图编码了原始门噪声配置文件的信息，以生成神经网络的特性。训练数据在构建基函数时即时生成，从而消除了计算开销。&lt;h4&gt;主要发现&lt;/h4&gt;在预测能量方面，对于几个强相关分子，该方法展示了数量级的改进。&lt;h4&gt;结论&lt;/h4&gt;该研究为在量子计算机上实现高效误差缓解技术提供了一种新的方法，为未来量子计算的应用奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;尽管已经付出了重大努力，但混合量子-经典算法的实现主要限于原理证明，这主要归因于硬件噪声。容忍错误的实现是长期目标。使用现有错误缓解技术通过当前的噪声中等规模量子（NISQ）设备超越小分子一直是一个挑战。然而，统计学习方法是有希望的噪声及其随后缓解的学习方法。我们设计了一个图神经网络和基于回归的机器学习架构，用于分子哈密顿量的实际误差缓解技术的实现，而无需指数级的开销。鉴于量子硬件的短暂相干时间，该机器学习模型使用理想或缓解的期望值在精心选择的浅层子电路集合上训练，这些子电路遵循原始硬件架构。硬件连接性网络被映射到一个有向图，该图编码了原始门噪声配置文件的信息，以生成神经网络的特性。训练数据在构建基函数时即时生成，从而消除了计算开销。我们证明了对于几个强相关分子，在预测能量方面有数量级的改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite significant efforts, the realization of the hybrid quantum-classicalalgorithms has predominantly been confined to proof-of-principles, mainly dueto the hardware noise. With fault-tolerant implementation being a long-termgoal, going beyond small molecules with existing error mitigation (EM)techniques with current noisy intermediate scale quantum (NISQ) devices hasbeen a challenge. That being said, statistical learning methods are promisingapproaches to learning the noise and its subsequent mitigation. We devise agraph neural network and regression-based machine learning (ML) architecturefor practical realization of EM techniques for molecular Hamiltonian withoutthe requirement of the exponential overhead. Given the short coherence time ofthe quantum hardware, the ML model is trained with either ideal or mitigatedexpectation values over a judiciously chosen ensemble of shallow sub-circuitsadhering to the native hardware architecture. The hardware connectivity networkis mapped to a directed graph which encodes the information of the native gatenoise profile to generate the features for the neural network. The trainingdata is generated on-the-fly during ansatz construction thus removing thecomputational overhead. We demonstrate orders of magnitude improvements inpredicted energy over a few strongly correlated molecules.</description>
      <author>example@mail.com (Srushti Patil, Dibyendu Mondal, Rahul Maitra)</author>
      <guid isPermaLink="false">2504.07077v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Convolutional Neural Network and Graph Neural Network based Surrogate Models on a Real-World Car External Aerodynamics Dataset</title>
      <link>http://arxiv.org/abs/2504.06699v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了两种代理模型方法在预测实际世界数据集上的阻力，并评估了它们在车辆开发过程中的应用。&lt;h4&gt;背景&lt;/h4&gt;空气动力学优化对于开发环保、空气动力学和时尚的汽车至关重要，但空气动力学模拟的耗时性阻碍了这一过程。&lt;h4&gt;目的&lt;/h4&gt;通过比较两种代理模型方法，评估它们在预测实际世界数据集上的阻力性能。&lt;h4&gt;方法&lt;/h4&gt;使用卷积神经网络（CNN）模型和基于图神经网络（GNN）的商业工具进行阻力预测，数据集由来自32个基线车辆几何形状的343个几何形状组成。&lt;h4&gt;主要发现&lt;/h4&gt;CNN方法平均绝对误差为2.3阻力计数，GNN方法为3.8。两种方法在预测阻力方向变化方面均达到约77%的准确性，但在捕捉基线组内部更细微的变化方面表现不一。&lt;h4&gt;结论&lt;/h4&gt;空气动力学专家可以使用这两种方法在两分钟内预测阻力，这比进行模拟快600倍以上，但在捕捉几何形状的更细微细节方面仍有改进空间。&lt;h4&gt;翻译&lt;/h4&gt;摘要：空气动力学优化对于开发环保型、空气动力学和时尚的汽车至关重要，这需要空气动力学专家和设计师之间的紧密合作，而空气动力学模拟的耗时性阻碍了这种合作。代理模型提供了一种可行的解决方案来减少这种开销，但在实际世界的空气动力学数据集中尚未得到检验。我们提出了一种对两种代理建模方法进行对比评估，以预测真实世界数据集上的阻力：一种使用有符号距离场作为输入的卷积神经网络（CNN）模型，以及一种直接处理表面网格的商业工具，基于图神经网络（GNN）。与基于参数化几何形状创建的数据集的研究相比，我们的数据集由来自五个不同汽车项目的32个基线车辆几何形状的343个几何形状组成，反映了典型车辆开发过程中遇到的多样化、自由形式的修改。我们的结果表明，基于CNN的方法实现了2.3阻力计数的平均绝对误差，而基于GNN的方法实现了3.8。两种方法在预测相对于基线几何形状的阻力方向变化方面均达到约77%的准确性。尽管两种方法有效地捕捉了基线组之间的更广泛趋势（来自单个基线几何形状的样本集），但它们在捕捉基线组内部的更细微变化方面表现不一。总之，我们的发现表明，空气动力学专家可以有效地使用这两种方法在两分钟内预测阻力，这比进行模拟快600倍以上。然而，在捕捉几何形状的更细微细节方面仍有改进空间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Aerodynamic optimization is crucial for developing eco-friendly, aerodynamic,and stylish cars, which requires close collaboration between aerodynamicistsand stylists, a collaboration impaired by the time-consuming nature ofaerodynamic simulations. Surrogate models offer a viable solution to reducethis overhead, but they are untested in real-world aerodynamic datasets. Wepresent a comparative evaluation of two surrogate modeling approaches forpredicting drag on a real-world dataset: a Convolutional Neural Network (CNN)model that uses a signed distance field as input and a commercial tool based onGraph Neural Networks (GNN) that directly processes a surface mesh. In contrastto previous studies based on datasets created from parameterized geometries,our dataset comprises 343 geometries derived from 32 baseline vehiclegeometries across five distinct car projects, reflecting the diverse, free-formmodifications encountered in the typical vehicle development process. Ourresults show that the CNN-based method achieves a mean absolute error of 2.3drag counts, while the GNN-based method achieves 3.8. Both methods achieveapproximately 77% accuracy in predicting the direction of drag change relativeto the baseline geometry. While both methods effectively capture the broadertrends between baseline groups (set of samples derived from a single baselinegeometry), they struggle to varying extents in capturing the finerintra-baseline group variations. In summary, our findings suggest thataerodynamicists can effectively use both methods to predict drag in under twominutes, which is at least 600 times faster than performing a simulation.However, there remains room for improvement in capturing the finer details ofthe geometry.</description>
      <author>example@mail.com (Sam Jacob Jacob, Markus Mrosek, Carsten Othmer, Harald Köstler)</author>
      <guid isPermaLink="false">2504.06699v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>TabKAN: Advancing Tabular Data Analysis using Kolmograv-Arnold Network</title>
      <link>http://arxiv.org/abs/2504.06559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 12 figures, 13 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为TabKAN的新框架，该框架利用Kolmogorov-Arnold Networks（KANs）对表格数据进行建模，通过引入可学习的激活函数在边上的优势，提高了可解释性和训练效率。&lt;h4&gt;背景&lt;/h4&gt;表格数据分析由于特征类型异质、缺失值和复杂交互而面临独特挑战。传统的机器学习方法通常优于深度学习方法，但近年来神经架构的进步为替代方案提供了希望。&lt;h4&gt;目的&lt;/h4&gt;提出TabKAN框架，以提升表格数据建模的性能，并提高模型的可解释性和训练效率。&lt;h4&gt;方法&lt;/h4&gt;包括：（1）引入适用于表格数据分析的模块化KAN架构；（2）开发KAN模型的迁移学习框架；（3）开发针对表格数据学习的模型特定可解释性；（4）对二元和多类分类任务中的原始监督学习进行综合评估。&lt;h4&gt;主要发现&lt;/h4&gt;TabKAN在多个公共数据集上的基准测试中表现出色，证明了其在监督学习中的优越性能，并在迁移学习场景中显著优于经典和基于Transformer的模型。&lt;h4&gt;结论&lt;/h4&gt;KAN基于的架构在跨领域高效转移知识方面具有优势，缩小了传统机器学习和深度学习在结构化数据之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;摘要：表格数据分析由于其异质特征类型、缺失值和复杂的交互而具有独特的挑战。虽然传统的机器学习方法，如梯度提升，通常优于深度学习方法，但近年来神经架构的进步提供了有希望的替代方案。本文介绍了一种名为TabKAN的新框架，该框架利用Kolmogorov-Arnold Networks（KANs）对表格数据进行建模。与传统的深度学习模型不同，KANs通过在边上使用可学习的激活函数，提高了可解释性和训练效率。我们的贡献包括：（1）引入了针对表格数据分析的模块化KAN架构；（2）开发了KAN模型的迁移学习框架，允许在不同领域之间有效转移知识；（3）开发了针对表格数据学习的模型特定可解释性，减少了对外部分析和模型无关分析的依赖；（4）对二元和多类分类任务中的原始监督学习进行了综合评估。通过在多个公共数据集上的广泛基准测试，TabKAN在监督学习中表现出优越的性能，在迁移学习场景中显著优于经典和基于Transformer的模型。我们的发现突出了KAN基于的架构在跨领域高效转移知识方面的优势，缩小了传统机器学习和深度学习在结构化数据之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tabular data analysis presents unique challenges due to its heterogeneousfeature types, missing values, and complex interactions. While traditionalmachine learning methods, such as gradient boosting, often outperform deeplearning approaches, recent advancements in neural architectures offerpromising alternatives. This paper introduces TabKAN, a novel framework thatadvances tabular data modeling using Kolmogorov-Arnold Networks (KANs). Unlikeconventional deep learning models, KANs leverage learnable activation functionson edges, enhancing both interpretability and training efficiency. Ourcontributions include: (1) the introduction of modular KAN-based architecturestailored for tabular data analysis, (2) the development of a transfer learningframework for KAN models, enabling effective knowledge transfer betweendomains, (3) the development of model-specific interpretability for tabulardata learning, reducing reliance on post hoc and model-agnostic analysis, and(4) comprehensive evaluation of vanilla supervised learning across binary andmulti-class classification tasks. Through extensive benchmarking on diversepublic datasets, TabKAN demonstrates superior performance in supervisedlearning while significantly outperforming classical and Transformer-basedmodels in transfer learning scenarios. Our findings highlight the advantage ofKAN-based architectures in efficiently transferring knowledge across domains,bridging the gap between traditional machine learning and deep learning forstructured data.</description>
      <author>example@mail.com (Ali Eslamian, Alireza Afzal Aghaei, Qiang Cheng)</author>
      <guid isPermaLink="false">2504.06559v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Teaching pathology foundation models to accurately predict gene expression with parameter efficient knowledge transfer</title>
      <link>http://arxiv.org/abs/2504.07061v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为PEKA的新型框架，用于从数字化病理图像中预测基因表达，并展示了其在基因表达预测方面的性能提升。&lt;h4&gt;背景&lt;/h4&gt;基因表达谱分析对于理解细胞异质性、生物过程和疾病机制至关重要。近年来，研究者对能够直接从数字化的组织病理学图像预测基因表达的计算机方法产生了浓厚兴趣。&lt;h4&gt;目的&lt;/h4&gt;提高基于图像模型的基因表达预测性能，同时降低模型的参数数量。&lt;h4&gt;方法&lt;/h4&gt;PEKA框架结合了块对齐适应、知识蒸馏和结构对齐损失来实现跨模态知识迁移。&lt;h4&gt;主要发现&lt;/h4&gt;PEKA在多个空间转录组数据集上实现了至少5%的性能提升，并优于其他参数高效的微调策略。&lt;h4&gt;结论&lt;/h4&gt;PEKA框架有助于提高基因表达预测的准确性，且参数效率高，有望在同行评审后推广使用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基因表达谱分析为理解细胞异质性、生物过程和疾病机制提供了关键见解。近年来，研究者对能够直接从数字化的组织病理学图像预测基因表达的计算机方法产生了浓厚兴趣。尽管基于图像的基础模型在多种病理下游分析中显示出希望，但它们在基因表达预测方面的表现仍然有限。明确结合转录组模型的信息可以帮助图像模型解决域偏移问题，但基础模型的微调和对齐可能成本高昂。在本文中，我们提出了一种名为Parameter Efficient Knowledge trAnsfer（PEKA）的新型框架，该框架利用块对齐适应，并集成了知识蒸馏和结构对齐损失以实现跨模态知识迁移。我们使用多个空间转录组数据集（包含206,123个图像瓷砖和匹配的基因表达谱）评估了PEKA在基因表达预测方面的表现，这些数据集涵盖了不同类型的组织。PEKA在基准基础模型上实现了至少5%的性能提升，同时也优于其他参数高效的微调策略。我们将在同行评审后发布代码、数据集和对齐模型，以促进更广泛的采用和进一步的开发。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gene expression profiling provides critical insights into cellularheterogeneity, biological processes and disease mechanisms. There has been anincreasing interest in computational approaches that can predict geneexpression directly from digitalized histopathology images. While imagefoundation models have shown promise in a variety of pathology downstreamanalysis, their performances on gene-expression prediction are still limited.Explicitly incorporating information from the transcriptomic models can helpimage models to address domain shift, yet the fine-tuning and alignment offoundation models can be expensive. In the work, we propose Parameter EfficientKnowledge trAnsfer (PEKA), a novel framework that leverages Block-AffineAdaptation and integrates knowledge distillation and structure alignment lossesfor cross-modal knowledge transfer. We evaluated PEKA for gene expressionprediction using multiple spatial transcriptomics datasets (comprising 206,123image tiles with matched gene expression profiles) that encompassed varioustypes of tissue. PEKA achieved at least 5\% performance improvement overbaseline foundation models while also outperforming alternativeparameter-efficient fine-tuning strategies. We will release the code, datasetsand aligned models after peer-review to facilitate broader adoption and furtherdevelopment for parameter efficient model alignment.</description>
      <author>example@mail.com (Shi Pan, Jianan Chen, Maria Secrier)</author>
      <guid isPermaLink="false">2504.07061v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Audio-visual Event Localization on Portrait Mode Short Videos</title>
      <link>http://arxiv.org/abs/2504.06884v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了用于竖屏短视频的音频-视觉事件定位（AVE-PM）数据集，并分析了现有AVEL方法在竖屏视频上的性能问题。&lt;h4&gt;背景&lt;/h4&gt;现有的AVEL数据集主要包含横向的长视频，而短视频已成为在线视频内容的主流格式，给AVEL带来了新的挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一个针对竖屏短视频的AVE-PM数据集，并研究如何改进现有方法以适应短视频的特点。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含25,335个剪辑的AVE-PM数据集，涵盖了86个细粒度类别，并进行了帧级标注。通过实证分析，研究了现有方法在竖屏视频上的性能下降问题，并提出了预处理和模型设计优化。&lt;h4&gt;主要发现&lt;/h4&gt;1) 竖屏视频的帧向空间偏差引入了不同的领域先验；2) 噪音音频组成影响了音频模态的可靠性。&lt;h4&gt;结论&lt;/h4&gt;通过优化预处理和模型设计，可以在竖屏视频上实现AVEL性能的提升，为移动视频内容时代的AVEL研究提供了基础基准和可操作的见解。&lt;h4&gt;翻译&lt;/h4&gt;Audio-visual event localization (AVEL) plays a critical role in multimodalscene understanding. While existing datasets for AVEL predominantly compriselandscape-oriented long videos with clean and simple audio context, shortvideos have become the primary format of online video content due to the theproliferation of smartphones. Short videos are characterized byportrait-oriented framing and layered audio compositions (e.g., overlappingsound effects, voiceovers, and music), which brings unique challengesunaddressed by conventional methods. To this end, we introduce AVE-PM, thefirst AVEL dataset specifically designed for portrait mode short videos,comprising 25,335 clips that span 86 fine-grained categories with frame-levelannotations. Beyond dataset creation, our empirical analysis shows thatstate-of-the-art AVEL methods suffer an average 18.66% performance drop duringcross-mode evaluation. Further analysis reveals two key challenges of differentvideo formats: 1) spatial bias from portrait-oriented framing introducesdistinct domain priors, and 2) noisy audio composition compromise thereliability of audio modality. To address these issues, we investigate optimalpreprocessing recipes and the impact of background music for AVEL on portraitmode videos. Experiments show that these methods can still benefit fromtailored preprocessing and specialized model design, thus achieving improvedperformance. This work provides both a foundational benchmark and actionableinsights for advancing AVEL research in the era of mobile-centric videocontent. Dataset and code will be released.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio-visual event localization (AVEL) plays a critical role in multimodalscene understanding. While existing datasets for AVEL predominantly compriselandscape-oriented long videos with clean and simple audio context, shortvideos have become the primary format of online video content due to the theproliferation of smartphones. Short videos are characterized byportrait-oriented framing and layered audio compositions (e.g., overlappingsound effects, voiceovers, and music), which brings unique challengesunaddressed by conventional methods. To this end, we introduce AVE-PM, thefirst AVEL dataset specifically designed for portrait mode short videos,comprising 25,335 clips that span 86 fine-grained categories with frame-levelannotations. Beyond dataset creation, our empirical analysis shows thatstate-of-the-art AVEL methods suffer an average 18.66% performance drop duringcross-mode evaluation. Further analysis reveals two key challenges of differentvideo formats: 1) spatial bias from portrait-oriented framing introducesdistinct domain priors, and 2) noisy audio composition compromise thereliability of audio modality. To address these issues, we investigate optimalpreprocessing recipes and the impact of background music for AVEL on portraitmode videos. Experiments show that these methods can still benefit fromtailored preprocessing and specialized model design, thus achieving improvedperformance. This work provides both a foundational benchmark and actionableinsights for advancing AVEL research in the era of mobile-centric videocontent. Dataset and code will be released.</description>
      <author>example@mail.com (Wuyang Liu, Yi Chai, Yongpeng Yan, Yanzhen Ren)</author>
      <guid isPermaLink="false">2504.06884v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Visualisation of a multidimensional point cloud as a 3D swarm of avatars</title>
      <link>http://arxiv.org/abs/2504.06751v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Chernoff面孔图标的多维数据可视化创新方法。&lt;h4&gt;背景&lt;/h4&gt;传统投影技术和数据维度分配相结合，利用人类大脑对面部表情的自然解释能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种数据可视化技术，以帮助分析复杂的数据结构。&lt;h4&gt;方法&lt;/h4&gt;该技术作为dpVision开源图像处理平台的插件实现，允许以“图腾”的形式交互式探索数据。&lt;h4&gt;主要发现&lt;/h4&gt;基于合成测试数据和葡萄牙葡萄酒vinhoverde15维数据库的样本可视化证明了该方法的实用性。&lt;h4&gt;结论&lt;/h4&gt;该方法对复杂数据结构分析具有实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;The article presents an innovative approach to the visualisation of multidimensional data, using icons inspired by Chernoff faces. The approach merges classical projection techniques with the assignment of particular data dimensions to mimic features, capitalizing on the natural ability of the human brain to interpret facial expressions. The technique is implemented as a plugin to the dpVision open-source image handling platform. The plugin allows the data to be interactively explored in the form of a swarm of 'totems' whose position in hyperspace as well as facial features represent various aspects of the data. Sample visualisations, based on synthetic test data as well as the vinhoverde15-dimensional database on Portuguese wines, confirm the usefulness of our approach to the analysis of complex data structures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The article presents an innovative approach to the visualisation ofmultidimensional data, using icons inspired by Chernoff faces. The approachmerges classical projection techniques with the assignment of particular datadimensions to mimic features, capitalizing on the natural ability of the humanbrain to interpret facial expressions. The technique is implemented as a pluginto the dpVision open-source image handling platform. The plugin allows the datato be interactively explored in the form of a swarm of "totems" whose positionin hyperspace as well as facial features represent various aspects of the data.Sample visualisations, based on synthetic test data as well as the vinhoverde15-dimensional database on Portuguese wines, confirm the usefulness of ourapproach to the analysis of complex data structures.</description>
      <author>example@mail.com (Leszek Luchowski, Dariusz Pojda)</author>
      <guid isPermaLink="false">2504.06751v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>CHIME: A Compressive Framework for Holistic Interest Modeling</title>
      <link>http://arxiv.org/abs/2504.06780v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为CHIME的压缩框架，用于整体兴趣建模，以改善推荐系统的性能。&lt;h4&gt;背景&lt;/h4&gt;整体用户兴趣建模对于改进推荐系统很重要，但面临着高计算成本和难以处理具有完整行为背景的多样化信息的问题。&lt;h4&gt;目的&lt;/h4&gt;旨在克服现有基于搜索的方法在行为选择中丢失关键信号的限制。&lt;h4&gt;方法&lt;/h4&gt;使用改进的大语言模型来编码带有异构输入的完整用户行为，引入多粒度对比学习目标以捕捉持久和短暂的兴趣模式，并应用残差矢量量化生成紧凑嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;CHIME在多个数据集上展示了优越的排名性能，为可扩展的整体兴趣建模提供了一种稳健的解决方案。&lt;h4&gt;结论&lt;/h4&gt;CHIME是一种有效的整体兴趣建模方法，有助于提高推荐系统的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：建模整体用户兴趣对于改善推荐系统至关重要，但受到高计算成本和处理具有完整行为背景的多样化信息的挑战。现有的基于搜索的方法可能在行为选择中丢失关键信号。为了克服这些限制，我们提出了CHIME：一种用于整体兴趣建模的压缩框架。它使用改进的大语言模型来编码带有异构输入的完整用户行为。我们引入了多粒度对比学习目标以捕捉持久和短暂的兴趣模式，并应用残差矢量量化生成紧凑嵌入。CHIME在各种数据集上展示了优越的排名性能，为推荐系统中的可扩展整体兴趣建模建立了一种稳健的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling holistic user interests is important for improving recommendationsystems but is challenged by high computational cost and difficulty in handlingdiverse information with full behavior context. Existing search-based methodsmight lose critical signals during behavior selection. To overcome theselimitations, we propose CHIME: A Compressive Framework for Holistic InterestModeling. It uses adapted large language models to encode complete userbehaviors with heterogeneous inputs. We introduce multi-granular contrastivelearning objectives to capture both persistent and transient interest patternsand apply residual vector quantization to generate compact embeddings. CHIMEdemonstrates superior ranking performance across diverse datasets, establishinga robust solution for scalable holistic interest modeling in recommendationsystems.</description>
      <author>example@mail.com (Yong Bai, Rui Xiang, Kaiyuan Li, Yongxiang Tang, Yanhua Cheng, Xialong Liu, Peng Jiang, Kun Gai)</author>
      <guid isPermaLink="false">2504.06780v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Self-Supervised Learning for Earth Observation via Dynamic Dataset Curation</title>
      <link>http://arxiv.org/abs/2504.06962v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPR Workshop : The First Workshop on Foundation and  Large Vision Models in Remote Sensing&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种动态数据集剪枝策略，旨在通过最大化数据集的多样性和平衡性来提高自监督学习（SSL）在地球观测（EO）领域的预训练效果。&lt;h4&gt;背景&lt;/h4&gt;尽管自监督学习在地球观测领域显示出强大的迁移性，但数据集的编制，特别是在平衡和多样化预训练数据集方面，仍然是一个未被充分探索的问题。在地球观测中，卫星图像中的冗余和重尾分布问题加剧了这一挑战，可能导致偏差的表示和低效的训练。&lt;h4&gt;目的&lt;/h4&gt;提出一种动态数据集剪枝策略，以提高SSL预训练的效率和模型的表现。&lt;h4&gt;方法&lt;/h4&gt;该方法通过迭代地优化训练集，而不需要预先存在的特征提取器，适用于数据集有限或不可用的领域。在Sentinel-1 WV合成孔径雷达（SAR）档案上进行了实验，该档案是一个以海洋观测为主的具有挑战性的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;在三个下游任务中，结果表明动态剪枝提高了计算效率和表示质量，从而增强了模型的迁移性。&lt;h4&gt;结论&lt;/h4&gt;动态剪枝策略能够提高SSL预训练的效果，并有助于提高模型在地球观测任务中的表现。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised learning (SSL) has enabled the development of vision foundation models for Earth Observation (EO), demonstrating strong transferability across diverse remote sensing tasks. While prior work has focused on network architectures and training strategies, the role of dataset curation, especially in balancing and diversifying pre-training datasets, remains underexplored. In EO, this challenge is amplified by the redundancy and heavy-tailed distributions common in satellite imagery, which can lead to biased representations and inefficient training. In this work, we propose a dynamic dataset pruning strategy designed to improve SSL pre-training by maximizing dataset diversity and balance. Our method iteratively refines the training set without requiring a pre-existing feature extractor, making it well-suited for domains where curated datasets are limited or unavailable. We demonstrate our approach on the Sentinel-1 Wave Mode (WV) Synthetic Aperture Radar (SAR) archive, a challenging dataset dominated by ocean observations. We train models from scratch on the entire Sentinel-1 WV archive spanning 10 years. Across three downstream tasks, our results show that dynamic pruning improves both computational efficiency and representation quality, leading to stronger transferability. We also release the weights of Nereus-SAR-1, the first model in the Nereus family, a series of foundation models for ocean observation and analysis using SAR imagery, at github.com/galeio-research/nereus-sar-models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) has enabled the development of visionfoundation models for Earth Observation (EO), demonstrating strongtransferability across diverse remote sensing tasks. While prior work hasfocused on network architectures and training strategies, the role of datasetcuration, especially in balancing and diversifying pre-training datasets,remains underexplored. In EO, this challenge is amplified by the redundancy andheavy-tailed distributions common in satellite imagery, which can lead tobiased representations and inefficient training.  In this work, we propose a dynamic dataset pruning strategy designed toimprove SSL pre-training by maximizing dataset diversity and balance. Ourmethod iteratively refines the training set without requiring a pre-existingfeature extractor, making it well-suited for domains where curated datasets arelimited or unavailable. We demonstrate our approach on the Sentinel-1 Wave Mode(WV) Synthetic Aperture Radar (SAR) archive, a challenging dataset dominated byocean observations. We train models from scratch on the entire Sentinel-1 WVarchive spanning 10 years. Across three downstream tasks, our results show thatdynamic pruning improves both computational efficiency and representationquality, leading to stronger transferability.  We also release the weights of Nereus-SAR-1, the first model in the Nereusfamily, a series of foundation models for ocean observation and analysis usingSAR imagery, at github.com/galeio-research/nereus-sar-models/.</description>
      <author>example@mail.com (Thomas Kerdreux, Alexandre Tuel, Quentin Febvre, Alexis Mouche, Bertrand Chapron)</author>
      <guid isPermaLink="false">2504.06962v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>LVC: A Lightweight Compression Framework for Enhancing VLMs in Long Video Understanding</title>
      <link>http://arxiv.org/abs/2504.06835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为轻量级视频压缩（LVC）的新方法，旨在提高视频语言模型（VLMs）对长视频的理解能力，同时降低数据和使用计算资源的需求。&lt;h4&gt;背景&lt;/h4&gt;长视频理解是一个复杂的任务，需要同时具备空间细节和时间感知能力。虽然VLMs可以通过多帧输入获得帧级理解能力，但它们由于稀疏采样策略而存在信息损失。相比之下，视频大型语言模型（Video-LLMs）在视觉特征中捕捉时间关系，但受限于高质量视频-文本数据集的稀缺。&lt;h4&gt;目的&lt;/h4&gt;目的是将长视频理解能力转移到VLMs上，同时最小化数据和使用计算资源。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为LVC的新方法，它具有查询注意力视频压缩机制，有效地解决了VLMs中的稀疏采样问题。通过仅训练10k个短视频-文本对的对齐层，LVC显著增强了VLMs的时间推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，LVC在各种模型上提供了持续的性能提升，包括InternVL2系列和Phi-3.5-Vision。特别是，InternVL2-40B-LVC在长视频理解基准MLVU和Video-MME上分别达到了68.2和65.9的分数，相对提高了14.6%和7.7%。&lt;h4&gt;结论&lt;/h4&gt;增强的模型和代码将很快公开。&lt;h4&gt;翻译&lt;/h4&gt;摘要：长视频理解是一个复杂的任务，需要空间细节和时间感知能力。虽然视觉语言模型（VLMs）通过多帧输入获得帧级理解能力，但它们由于稀疏采样策略而存在信息损失。相比之下，视频大型语言模型（Video-LLMs）在视觉特征中捕捉时间关系，但受限于高质量视频-文本数据集的稀缺。为了将长视频理解能力转移到VLMs上，同时最小化数据和使用计算资源，我们提出了轻量级视频压缩（LVC），这是一种具有查询注意力视频压缩机制的新方法，有效地解决了VLMs中的稀疏采样问题。通过仅训练10k个短视频-文本对的对齐层，LVC显著增强了VLMs的时间推理能力。广泛的实验表明，LVC在各种模型上提供了持续的性能提升，包括InternVL2系列和Phi-3.5-Vision。值得注意的是，InternVL2-40B-LVC在长视频理解基准MLVU和Video-MME上分别达到了68.2和65.9的分数，相对提高了14.6%和7.7%。增强的模型和代码将很快公开。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long video understanding is a complex task that requires both spatial detailand temporal awareness. While Vision-Language Models (VLMs) obtain frame-levelunderstanding capabilities through multi-frame input, they suffer frominformation loss due to the sparse sampling strategy. In contrast, Video LargeLanguage Models (Video-LLMs) capture temporal relationships within visualfeatures but are limited by the scarcity of high-quality video-text datasets.To transfer long video understanding capabilities to VLMs with minimal data andcomputational cost, we propose Lightweight Video Compression (LVC), a novelmethod featuring the Query-Attention Video Compression mechanism, whicheffectively tackles the sparse sampling problem in VLMs. By training only thealignment layer with 10k short video-text pairs, LVC significantly enhances thetemporal reasoning abilities of VLMs. Extensive experiments show that LVCprovides consistent performance improvements across various models, includingthe InternVL2 series and Phi-3.5-Vision. Notably, the InternVL2-40B-LVCachieves scores of 68.2 and 65.9 on the long video understanding benchmarksMLVU and Video-MME, respectively, with relative improvements of 14.6% and 7.7%.The enhanced models and code will be publicly available soon.</description>
      <author>example@mail.com (Ziyi Wang, Haoran Wu, Yiming Rong, Deyang Jiang, Yixin Zhang, Yunlong Zhao, Shuang Xu, Bo XU)</author>
      <guid isPermaLink="false">2504.06835v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Implementation of a Zed 2i Stereo Camera for High-Frequency Shoreline Change and Coastal Elevation Monitoring</title>
      <link>http://arxiv.org/abs/2504.06464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in IGARSS 2023 - 2023 IEEE International Geoscience and  Remote Sensing Symposium&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究通过使用低成本ZED 2i立体相机系统和近距离摄影测量法，以实现高时间分辨率和局部尺度的海岸高度和海岸线变化的监测。&lt;h4&gt;背景&lt;/h4&gt;随着沿海地区人口和财务利益的增加，对海岸高度和海岸线变化的监测需求日益增长。&lt;h4&gt;目的&lt;/h4&gt;解决现有资源缺乏所需时间分辨率的问题，以进行短期监测。&lt;h4&gt;方法&lt;/h4&gt;实施低成本ZED 2i立体相机系统，结合近距离摄影测量法，收集图像生成3D点云、海滩高度的数字表面模型（DSM）和地理校正影像。&lt;h4&gt;主要发现&lt;/h4&gt;研究的主要贡献包括：相机内在校准、获取图像和点云的地理校正和配准、海滩高度DSM的生成，以及与无人飞行器系统结构从运动摄影测量法得出的产品比较。&lt;h4&gt;结论&lt;/h4&gt;初步结果显示，尽管存在局限性，ZED 2i能够在局部和较高时间尺度上提供所需的测绘产品。系统实现了平均重投影误差0.20像素，点云配准27厘米，相对于地面实况的垂直误差37.56厘米，以及x和y方向的地理校正均方根误差分别为2.67厘米和2.81厘米。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着沿海地区人口和财政利益的增加，监测海岸高度和海岸线变化的需求也在增加。尽管有几种资源可以获取这些信息，但它们通常缺乏短期监测所需的时间分辨率（例如，每小时一次）。为了解决这个问题，本研究实施了一种低成本ZED 2i立体相机系统，并结合近距离摄影测量法收集图像以生成3D点云、海滩高度的数字表面模型（DSM）和局部尺度和高时间分辨率的地理校正影像。本研究的主要贡献包括：（i）相机内在校准，（ii）获取图像和点云的地理校正和配准，（iii）海滩高度DSM的生成，以及（iv）与无人飞行器系统结构从运动摄影测量法得出的产品进行比较。初步结果表明，尽管存在局限性，ZED 2i仍能在局部和较高时间尺度上提供所需的测绘产品。该系统实现了平均重投影误差0.20像素，点云配准27厘米，相对于地面实况的垂直误差37.56厘米，以及x和y方向的地理校正均方根误差分别为2.67厘米和2.81厘米。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/IGARSS52108.2023.10283203&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing population, thus financial interests, in coastal areas haveincreased the need to monitor coastal elevation and shoreline change. Thoughseveral resources exist to obtain this information, they often lack therequired temporal resolution for short-term monitoring (e.g., every hour). Toaddress this issue, this study implements a low-cost ZED 2i stereo camerasystem and close-range photogrammetry to collect images for generating 3D pointclouds, digital surface models (DSMs) of beach elevation, and georectifiedimagery at a localized scale and high temporal resolution. The maincontributions of this study are (i) intrinsic camera calibration, (ii)georectification and registration of acquired imagery and point cloud, (iii)generation of the DSM of the beach elevation, and (iv) a comparison of derivedproducts against those from uncrewed aircraft system structure-from-motionphotogrammetry. Preliminary results show that despite its limitations, the ZED2i can provide the desired mapping products at localized and high temporalscales. The system achieved a mean reprojection error of 0.20 px, a point cloudregistration of 27 cm, a vertical error of 37.56 cm relative to ground truth,and georectification root mean square errors of 2.67 cm and 2.81 cm for x andy.</description>
      <author>example@mail.com (José A. Pilartes-Congo, Matthew Kastl, Michael J. Starek, Marina Vicens-Miquel, Philippe Tissot)</author>
      <guid isPermaLink="false">2504.06464v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Unifying Search and Recommendation: A Generative Paradigm Inspired by Information Theory</title>
      <link>http://arxiv.org/abs/2504.06714v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GenSR的新颖的生成式范式，用于统一搜索和推荐任务，以提高用户建模和物品理解能力。&lt;h4&gt;背景&lt;/h4&gt;推荐系统和搜索引擎是在线平台的基础元素，前者主动提供信息，后者允许用户主动搜索信息。将这两个任务统一在一个共享模型中具有潜力，因为它可以增强用户建模和物品理解。&lt;h4&gt;目的&lt;/h4&gt;解决之前方法中梯度冲突和手动设计复杂性两个关键挑战。&lt;h4&gt;方法&lt;/h4&gt;GenSR通过使用特定任务的提示来划分模型的参数空间为子空间，从而增强互信息。具体来说，包括：(1) 双重表示学习，独立地建模协同和语义历史信息以导出有表达力的物品表示；(2) 搜索与推荐任务统一，利用对比学习和指令调整有效地生成特定任务的输出。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公开数据集上的大量实验表明，GenSR在搜索与推荐任务上优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;与之前基于判别的方法相比，GenSR引入了一种新的生成式范式，并从互信息的角度证明了其优越性。&lt;h4&gt;翻译&lt;/h4&gt;Recommender systems and search engines serve as foundational elements of online platforms, with the former delivering information proactively and the latter enabling users to seek information actively. Unifying both tasks in a shared model is promising since it can enhance user modeling and item understanding. Previous approaches mainly follow a discriminative paradigm, utilizing shared encoders to process input features and task-specific heads to perform each task. However, this paradigm encounters two key challenges: gradient conflict and manual design complexity. From the information theory perspective, these challenges potentially both stem from the same issue -- low mutual information between the input features and task-specific outputs during the optimization process. To tackle these issues, we propose GenSR, a novel generative paradigm for unifying search and recommendation (S&amp;R), which leverages task-specific prompts to partition the model's parameter space into subspaces, thereby enhancing mutual information. To construct effective subspaces for each task, GenSR first prepares informative representations for each subspace and then optimizes both subspaces in one unified model. Specifically, GenSR consists of two main modules: (1) Dual Representation Learning, which independently models collaborative and semantic historical information to derive expressive item representations; and (2) S&amp;R Task Unifying, which utilizes contrastive learning together with instruction tuning to generate task-specific outputs effectively. Extensive experiments on two public datasets show GenSR outperforms state-of-the-art methods across S&amp;R tasks. Our work introduces a new generative paradigm compared with previous discriminative methods and establishes its superiority from the mutual information perspective.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommender systems and search engines serve as foundational elements ofonline platforms, with the former delivering information proactively and thelatter enabling users to seek information actively. Unifying both tasks in ashared model is promising since it can enhance user modeling and itemunderstanding. Previous approaches mainly follow a discriminative paradigm,utilizing shared encoders to process input features and task-specific heads toperform each task. However, this paradigm encounters two key challenges:gradient conflict and manual design complexity. From the information theoryperspective, these challenges potentially both stem from the same issue -- lowmutual information between the input features and task-specific outputs duringthe optimization process.  To tackle these issues, we propose GenSR, a novel generative paradigm forunifying search and recommendation (S&amp;R), which leverages task-specific promptsto partition the model's parameter space into subspaces, thereby enhancingmutual information. To construct effective subspaces for each task, GenSR firstprepares informative representations for each subspace and then optimizes bothsubspaces in one unified model. Specifically, GenSR consists of two mainmodules: (1) Dual Representation Learning, which independently modelscollaborative and semantic historical information to derive expressive itemrepresentations; and (2) S&amp;R Task Unifying, which utilizes contrastive learningtogether with instruction tuning to generate task-specific outputs effectively.Extensive experiments on two public datasets show GenSR outperformsstate-of-the-art methods across S&amp;R tasks. Our work introduces a new generativeparadigm compared with previous discriminative methods and establishes itssuperiority from the mutual information perspective.</description>
      <author>example@mail.com (Jujia Zhao, Wenjie Wang, Chen Xu, Xiuying Wang, Zhaochun Ren, Suzan Verberne)</author>
      <guid isPermaLink="false">2504.06714v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>UKBOB: One Billion MRI Labeled Masks for Generalizable 3D Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2504.06908v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为UK Biobank Organs and Bones (UKBOB)的大规模标注数据集，用于医学影像研究，并提出了新的数据标注和模型训练方法。&lt;h4&gt;背景&lt;/h4&gt;医学影像领域面临收集大规模标注数据的挑战，包括隐私问题、物流和标注成本高。&lt;h4&gt;目的&lt;/h4&gt;开发UKBOB数据集，并利用自动标注和机器学习模型进行医学图像分割。&lt;h4&gt;方法&lt;/h4&gt;UKBOB包括51,761个3D MRI样本和超过137亿个2D器官分割掩码。使用自动标注和手动标注来验证数据质量，并提出了Entropy Test-time Adaptation (ETTA)方法来优化分割结果。基于Swin-UNetr架构训练了Swin-BOB基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;UKBOB在多个3D医学影像基准测试中取得了最先进的成果，包括BRATS脑部MRI肿瘤挑战和BTCV腹部CT扫描基准。&lt;h4&gt;结论&lt;/h4&gt;UKBOB是一个高质量的大规模医学影像数据集，其训练的模型在3D医学图像分割任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;在医学影像领域，由于隐私问题、物流和标注成本高，收集大规模标注数据是一个主要挑战。在这项工作中，我们介绍了UK Biobank器官和骨骼（UKBOB），这是最大的身体器官标注数据集，包含51,761个3D MRI样本（相当于1790万个2D图像）以及超过137亿个72个器官的2D分割掩码，所有这些数据都基于UK Biobank MRI数据集。我们利用自动标注，引入了具有器官特定过滤器的自动标签清理管道，并手动标注了300个MRI的11个腹部类别来验证质量（称为UKBOB-manual）。这种方法允许扩大数据集的收集规模，同时保持对标签的信心。我们进一步通过在过滤的UKBOB上展示训练模型的零样本泛化到其他类似领域的小型标注数据集（例如腹部MRI）来确认标签的有效性。为了进一步减轻噪声标签的影响，我们提出了一种名为Entropy Test-time Adaptation（ETTA）的新方法来优化分割输出。我们使用UKBOB来训练基于Swin-UNetr架构的3D医学图像分割基础模型Swin-BOB，在多个3D医学影像基准测试中取得了最先进的成果，包括BRATS脑部MRI肿瘤挑战（提高了0.4%）和BTCV腹部CT扫描基准（提高了1.3%）。预训练模型和代码可在https://emmanuelleb985.github.io/ukbob获取，过滤后的标签将与UK Biobank一起提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In medical imaging, the primary challenge is collecting large-scale labeleddata due to privacy concerns, logistics, and high labeling costs. In this work,we present the UK Biobank Organs and Bones (UKBOB), the largest labeled datasetof body organs, comprising 51,761 MRI 3D samples (equivalent to 17.9 million 2Dimages) and more than 1.37 billion 2D segmentation masks of 72 organs, allbased on the UK Biobank MRI dataset. We utilize automatic labeling, introducean automated label cleaning pipeline with organ-specific filters, and manuallyannotate a subset of 300 MRIs with 11 abdominal classes to validate the quality(referred to as UKBOB-manual). This approach allows for scaling up the datasetcollection while maintaining confidence in the labels. We further confirm thevalidity of the labels by demonstrating zero-shot generalization of trainedmodels on the filtered UKBOB to other small labeled datasets from similardomains (e.g., abdominal MRI). To further mitigate the effect of noisy labels,we propose a novel method called Entropy Test-time Adaptation (ETTA) to refinethe segmentation output. We use UKBOB to train a foundation model, Swin-BOB,for 3D medical image segmentation based on the Swin-UNetr architecture,achieving state-of-the-art results in several benchmarks in 3D medical imaging,including the BRATS brain MRI tumor challenge (with a 0.4% improvement) and theBTCV abdominal CT scan benchmark (with a 1.3% improvement). The pre-trainedmodels and the code are available at https://emmanuelleb985.github.io/ukbob ,and the filtered labels will be made available with the UK Biobank.</description>
      <author>example@mail.com (Emmanuelle Bourigault, Amir Jamaludin, Abdullah Hamdi)</author>
      <guid isPermaLink="false">2504.06908v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Robust and Noise-resilient Long-Term Prediction of Spatiotemporal Data Using Variational Mode Graph Neural Networks with 3D Attention</title>
      <link>http://arxiv.org/abs/2504.06660v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in IJCNN, 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于变分模态图卷积网络（VMGCN）和3D通道注意力机制来提高时空长期预测的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;在时空长期预测中，实时数据可能受到传感器噪声的干扰，改变其分布。&lt;h4&gt;目的&lt;/h4&gt;通过引入3D通道注意力机制来提高时空长期预测的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;使用历史数据输入，将噪声建模为独立同分布的高斯噪声，并将其融入大型ST交通流量数据集中。采用变分模态分解将受干扰的信号分解成模式，然后使用包含空间、时间和通道注意力的学习流程进行预测。实施可学习的软阈值方法来排除特征向量中的不重要模式，并应用基于信噪比（SNR）的特征缩减方法。&lt;h4&gt;主要发现&lt;/h4&gt;与基线模型相比，该方法在长期预测准确性、对噪声的鲁棒性以及模式截断方面的性能有所提高。&lt;h4&gt;结论&lt;/h4&gt;该方法实现了比基线模型更高的长期预测准确性、更强的噪声鲁棒性和改进的性能。&lt;h4&gt;翻译&lt;/h4&gt;本文重点研究了使用变分模态图卷积网络（VMGCN）通过引入3D通道注意力来提高时空长期预测的鲁棒性。该深度学习网络依赖于历史数据输入，然而，实时数据可能因传感器噪声而损坏，改变其分布。我们将这种噪声建模为独立同分布的高斯噪声，并将其纳入大型ST交通流量数据集中，产生了具有固有和加性噪声成分的数据。我们的方法包括使用变分模态分解将受干扰的信号分解成模式，然后将其输入到学习流程中进行预测。我们集成了一种包含空间、时间和通道注意力的3D注意力机制。空间和时间注意力模块学习它们各自的关联，而通道注意力机制用于抑制噪声并突出时空信号中的显著模式。此外，我们还实施了一种可学习的软阈值方法，用于从特征向量中排除不重要模式，并应用了一种基于信噪比（SNR）的特征缩减方法。我们比较了我们的方法与基线模型的性能，表明我们的方法在长期预测准确性、对噪声的鲁棒性以及与基线模型相比，在模式截断方面的性能得到了显著提高。本文的代码可在https://github.com/OsamaAhmad369/VMGCN上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper focuses on improving the robustness of spatiotemporal long-termprediction using a variational mode graph convolutional network (VMGCN) byintroducing 3D channel attention. The deep learning network for this taskrelies on historical data inputs, yet real-time data can be corrupted by sensornoise, altering its distribution. We model this noise as independent andidentically distributed (i.i.d.) Gaussian noise and incorporate it into theLargeST traffic volume dataset, resulting in data with both inherent andadditive noise components. Our approach involves decomposing the corruptedsignal into modes using variational mode decomposition, followed by feeding thedata into a learning pipeline for prediction. We integrate a 3D attentionmechanism encompassing spatial, temporal, and channel attention. The spatialand temporal attention modules learn their respective correlations, while thechannel attention mechanism is used to suppress noise and highlight thesignificant modes in the spatiotemporal signals. Additionally, a learnable softthresholding method is implemented to exclude unimportant modes from thefeature vector, and a feature reduction method based on the signal-to-noiseratio (SNR) is applied. We compare the performance of our approach againstbaseline models, demonstrating that our method achieves superior long-termprediction accuracy, robustness to noise, and improved performance with modetruncation compared to the baseline models. The code of the paper is availableat https://github.com/OsamaAhmad369/VMGCN.</description>
      <author>example@mail.com (Osama Ahmad, Zubair Khalid)</author>
      <guid isPermaLink="false">2504.06660v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Disentangle and Regularize: Sign Language Production with Articulator-Based Disentanglement and Channel-Aware Regularization</title>
      <link>http://arxiv.org/abs/2504.06610v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 4 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于transformer的无词汇手语生成框架，直接将口语文本映射到手势序列。&lt;h4&gt;背景&lt;/h4&gt;目前的手语生成方法往往依赖于词汇表或预训练模型。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需词汇表或预训练模型的手语生成方法。&lt;h4&gt;方法&lt;/h4&gt;首先训练一个姿态自动编码器，使用基于发音器官的解耦策略将手势姿态编码到紧凑的潜在空间中。然后训练一个非自回归的transformer解码器，从句子级别的文本嵌入中预测这些潜在表示。通过KL散度损失，应用通道感知正则化，使预测的潜在分布与从真实编码中提取的先验对齐。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在PHOENIX14T数据集上实现了最先进的成果，并且仅使用适度大小的训练集。&lt;h4&gt;结论&lt;/h4&gt;提出的方法不依赖词汇监督或预训练模型，在数据集上取得了优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们提出了一种简单无词汇、基于transformer的手语生成（SLP）框架，它直接将口语文本映射到手势序列。首先，我们训练了一个姿态自动编码器，使用基于发音器官的解耦策略将手势姿态编码到一个紧凑的潜在空间中，其中对应于面部、右手、左手和身体的特征被分别建模，以促进结构和可解释的学习。接下来，我们训练了一个非自回归的transformer解码器，以从句子级别的文本嵌入中预测这些潜在表示。为了指导这个过程，我们通过KL散度损失，应用通道感知正则化，将预测的潜在分布与从真实编码中提取的先验对齐。每个通道对损失的贡献根据其相关的发音器官区域进行加权，使模型在训练期间能够考虑到不同发音器官的相对重要性。我们的方法不依赖于词汇监督或预训练模型，并且仅使用适度大小的训练集在PHOENIX14T数据集上实现了最先进的成果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we propose a simple gloss-free, transformer-based sign languageproduction (SLP) framework that directly maps spoken-language text to sign posesequences. We first train a pose autoencoder that encodes sign poses into acompact latent space using an articulator-based disentanglement strategy, wherefeatures corresponding to the face, right hand, left hand, and body are modeledseparately to promote structured and interpretable representation learning.Next, a non-autoregressive transformer decoder is trained to predict theselatent representations from sentence-level text embeddings. To guide thisprocess, we apply channel-aware regularization by aligning predicted latentdistributions with priors extracted from the ground-truth encodings using aKL-divergence loss. The contribution of each channel to the loss is weightedaccording to its associated articulator region, enabling the model to accountfor the relative importance of different articulators during training. Ourapproach does not rely on gloss supervision or pretrained models, and achievesstate-of-the-art results on the PHOENIX14T dataset using only a modest trainingset.</description>
      <author>example@mail.com (Sumeyye Meryem Tasyurek, Tugce Kiziltepe, Hacer Yalim Keles)</author>
      <guid isPermaLink="false">2504.06610v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>IAAO: Interactive Affordance Learning for Articulated Objects in 3D Environments</title>
      <link>http://arxiv.org/abs/2504.06827v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该工作提出了一种名为IAAO的新型框架，该框架通过交互帮助智能代理理解其环境中的关节对象，并构建了一个显式的3D模型。&lt;h4&gt;背景&lt;/h4&gt;与依赖于特定任务网络和可动部分假设的先前方法不同，IAAO利用大型基础模型，在三个阶段估计交互性属性和部分关节。&lt;h4&gt;目的&lt;/h4&gt;旨在通过交互使智能代理能够理解和操纵环境中的关节对象。&lt;h4&gt;方法&lt;/h4&gt;IAAO使用3D高斯散点（3DGS）构建每个对象状态的分层特征和标签字段，通过蒸馏多视图图像中的掩码特征和视角一致的标签。然后对3D高斯原语进行对象和部分级别的查询，以识别静态和关节元素，并估计全局变换和局部关节参数以及属性。最后，基于估计的变换合并和细化不同状态的场景，实现基于属性的交互和对象的鲁棒操作。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在理解和操作关节对象方面是有效的。&lt;h4&gt;结论&lt;/h4&gt;IAAO框架为智能代理理解环境中的关节对象提供了一种有效的方法，通过交互和3D模型构建实现对象的可操纵性。&lt;h4&gt;翻译&lt;/h4&gt;这项工作提出了一种名为IAAO的新型框架，该框架通过交互帮助智能代理理解其环境中的关节对象，并构建了一个显式的3D模型。与依赖于特定任务网络和可动部分假设的先前方法不同，IAAO利用大型基础模型，在三个阶段估计交互性属性和部分关节。首先，使用3D高斯散点（3DGS）构建每个对象状态的分层特征和标签字段，通过蒸馏多视图图像中的掩码特征和视角一致的标签。然后对3D高斯原语进行对象和部分级别的查询，以识别静态和关节元素，并估计全局变换和局部关节参数以及属性。最后，基于估计的变换合并和细化不同状态的场景，实现基于属性的交互和对象的鲁棒操作。实验结果表明，该方法在理解和操作关节对象方面是有效的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents IAAO, a novel framework that builds an explicit 3D modelfor intelligent agents to gain understanding of articulated objects in theirenvironment through interaction. Unlike prior methods that rely ontask-specific networks and assumptions about movable parts, our IAAO leverageslarge foundation models to estimate interactive affordances and partarticulations in three stages. We first build hierarchical features and labelfields for each object state using 3D Gaussian Splatting (3DGS) by distillingmask features and view-consistent labels from multi-view images. We thenperform object- and part-level queries on the 3D Gaussian primitives toidentify static and articulated elements, estimating global transformations andlocal articulation parameters along with affordances. Finally, scenes fromdifferent states are merged and refined based on the estimated transformations,enabling robust affordance-based interaction and manipulation of objects.Experimental results demonstrate the effectiveness of our method.</description>
      <author>example@mail.com (Can Zhang, Gim Hee Lee)</author>
      <guid isPermaLink="false">2504.06827v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>MovSAM: A Single-image Moving Object Segmentation Framework Based on Deep Thinking</title>
      <link>http://arxiv.org/abs/2504.06863v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MovSAM的单图像移动目标分割框架，通过结合多模态大型语言模型和视觉特征，实现了基于逻辑推理的移动目标分割。&lt;h4&gt;背景&lt;/h4&gt;移动目标分割在理解动态视觉环境中至关重要，但现有方法依赖于多帧图像序列，而单图像移动目标分割对于运动意图预测和应对相机帧丢失等应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的单图像移动目标分割方法，以解决现有方法因缺乏时间线索而难以从单图像中分割移动目标的挑战。&lt;h4&gt;方法&lt;/h4&gt;MovSAM利用增强有思维链（CoT）提示的多模态大型语言模型（MLLM）来搜索移动目标并生成基于深度思考的文本提示，这些提示与Segment Anything Model（SAM）和Vision-Language Model（VLM）的视觉特征进行交叉融合，实现逻辑驱动的移动目标分割。分割结果经过深度思考的细化循环，使MovSAM能够通过逻辑推理迭代地提高对场景上下文和对象之间关系的理解。&lt;h4&gt;主要发现&lt;/h4&gt;MovSAM在现实世界的自动驾驶场景中得到了验证，尽管多帧方法在利用时间信息方面具有内在优势，但MovSAM在公共移动目标分割（MOS）基准测试中实现了最先进的性能，达到92.5%的准确率。&lt;h4&gt;结论&lt;/h4&gt;MovSAM是一种有效的单图像移动目标分割方法，在自动驾驶等场景中具有实际应用价值，并且性能优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：移动目标分割在理解动态视觉环境中起着至关重要的作用。虽然现有方法依赖于多帧图像序列来识别移动目标，但单图像移动目标分割对于运动意图预测和应对相机帧丢失等应用至关重要。然而，由于缺乏时间线索，从单图像中分割移动目标对现有方法来说仍然是一个挑战。为了解决这一差距，我们提出了MovSAM，这是第一个用于单图像移动目标分割的框架。MovSAM利用增强有思维链（CoT）提示的多模态大型语言模型（MLLM）来搜索移动目标并生成基于深度思考的文本提示，这些提示与Segment Anything Model（SAM）和Vision-Language Model（VLM）的视觉特征进行交叉融合，实现逻辑驱动的移动目标分割。分割结果经过深度思考的细化循环，使MovSAM能够通过逻辑推理迭代地提高对场景上下文和对象之间关系的理解。这种创新方法使MovSAM能够通过考虑场景理解来分割单图像中的移动目标。我们在现实世界中实现了MovSAM，以验证其实际应用价值和在自动驾驶场景中多帧方法失败时的有效性。此外，尽管多帧方法在利用时间信息方面具有内在优势，但MovSAM在公共移动目标分割（MOS）基准测试中实现了最先进的性能，达到92.5%的准确率。我们的实现将在https://github.com/IRMVLab/MovSAM上提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Moving object segmentation plays a vital role in understanding dynamic visualenvironments. While existing methods rely on multi-frame image sequences toidentify moving objects, single-image MOS is critical for applications likemotion intention prediction and handling camera frame drops. However,segmenting moving objects from a single image remains challenging for existingmethods due to the absence of temporal cues. To address this gap, we proposeMovSAM, the first framework for single-image moving object segmentation. MovSAMleverages a Multimodal Large Language Model (MLLM) enhanced withChain-of-Thought (CoT) prompting to search the moving object and generate textprompts based on deep thinking for segmentation. These prompts are cross-fusedwith visual features from the Segment Anything Model (SAM) and aVision-Language Model (VLM), enabling logic-driven moving object segmentation.The segmentation results then undergo a deep thinking refinement loop, allowingMovSAM to iteratively improve its understanding of the scene context andinter-object relationships with logical reasoning. This innovative approachenables MovSAM to segment moving objects in single images by considering sceneunderstanding. We implement MovSAM in the real world to validate its practicalapplication and effectiveness for autonomous driving scenarios where themulti-frame methods fail. Furthermore, despite the inherent advantage ofmulti-frame methods in utilizing temporal information, MovSAM achievesstate-of-the-art performance across public MOS benchmarks, reaching 92.5\% onJ\&amp;F. Our implementation will be available athttps://github.com/IRMVLab/MovSAM.</description>
      <author>example@mail.com (Chang Nie, Yiqing Xu, Guangming Wang, Zhe Liu, Yanzi Miao, Hesheng Wang)</author>
      <guid isPermaLink="false">2504.06863v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Societal Impacts Research Requires Benchmarks for Creative Composition Tasks</title>
      <link>http://arxiv.org/abs/2504.06549v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  v1: ICLR 2025 Workshop on Bidirectional Human-AI Alignment (BiAlign)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了能够自动化认知任务的基座模型的社会影响，强调开发基于实际用例的基准的重要性，以评估这些模型可能带来的风险和影响。&lt;h4&gt;背景&lt;/h4&gt;基座模型在自动化认知任务方面具有革命性，但它们的社会影响尚不明确，可能带来合成内容泛滥、同质化和误导性等问题。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过分析语言模型用户的行为，确定需要关注的创意性任务领域，并提出改进基准的方法。&lt;h4&gt;方法&lt;/h4&gt;通过主题分析2百万个语言模型用户提示，识别创意性任务是用户寻求帮助的常见用途，并分析现有基准与实际使用模式之间的差异。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现创意性任务在用户使用中很普遍，但现有基准与这些任务的实际使用模式之间存在不匹配。&lt;h4&gt;结论&lt;/h4&gt;文章主张关注创意性任务的基准，以更好地理解AI生成内容的社会影响，并呼吁提高透明度，以开发能够有效衡量模型进步和影响的基准。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译：Foundation models capable of automating cognitive tasks represent a pivotal technological shift, yet their societal implications remain unclear. These systems promise exciting advances, yet they also risk flooding our information ecosystem with formulaic, homogeneous, and potentially misleading synthetic content. Developing benchmarks grounded in real use cases where these risks are most significant is therefore critical. Through a thematic analysis using 2 million language model user prompts, we identify creative composition tasks as a prevalent usage category where users seek help with personal tasks that require everyday creativity. Our fine-grained analysis identifies mismatches between current benchmarks and usage patterns among these tasks. Crucially, we argue that the same use cases that currently lack thorough evaluations can lead to negative downstream impacts. This position paper argues that benchmarks focused on creative composition tasks is a necessary step towards understanding the societal harms of AI-generated content. We call for greater transparency in usage patterns to inform the development of new benchmarks that can effectively measure both the progress and the impacts of models with creative capabilities.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models that are capable of automating cognitive tasks represent apivotal technological shift, yet their societal implications remain unclear.These systems promise exciting advances, yet they also risk flooding ourinformation ecosystem with formulaic, homogeneous, and potentially misleadingsynthetic content. Developing benchmarks grounded in real use cases where theserisks are most significant is therefore critical. Through a thematic analysisusing 2 million language model user prompts, we identify creative compositiontasks as a prevalent usage category where users seek help with personal tasksthat require everyday creativity. Our fine-grained analysis identifiesmismatches between current benchmarks and usage patterns among these tasks.Crucially, we argue that the same use cases that currently lack thoroughevaluations can lead to negative downstream impacts. This position paper arguesthat benchmarks focused on creative composition tasks is a necessary steptowards understanding the societal harms of AI-generated content. We call forgreater transparency in usage patterns to inform the development of newbenchmarks that can effectively measure both the progress and the impacts ofmodels with creative capabilities.</description>
      <author>example@mail.com (Judy Hanwen Shen, Carlos Guestrin)</author>
      <guid isPermaLink="false">2504.06549v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>RAMBO: RL-augmented Model-based Optimal Control for Whole-body Loco-manipulation</title>
      <link>http://arxiv.org/abs/2504.06662v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了RAMBO，一个结合基于模型的反应力优化和强化学习反馈策略的混合框架，用于解决地面机器人在运动和与物体交互中的挑战。&lt;h4&gt;背景&lt;/h4&gt;地面机器人的loco-manipulation需要精确的力交互和抵抗未建模动态的鲁棒性。基于模型的控制器在规划优化方面有优势，但受限于模型的不准确性和计算成本。学习基于的方法具有鲁棒性，但在精确调节交互力方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出RAMBO框架，以实现精确的运动和交互，同时保证鲁棒和动态的运动。&lt;h4&gt;方法&lt;/h4&gt;RAMBO框架使用简化的动力学模型进行基于模型的反应力优化，并通过强化学习训练的反馈策略增强控制执行的鲁棒性。模型模块通过求解二次规划生成前馈扭矩，策略提供反馈残差以增强鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;在四足机器人的多种实际loco-manipulation任务中验证了框架的有效性，包括推动购物车、平衡盘子和握持软物体等。实验表明，RAMBO在精确操作的同时，实现了鲁棒和动态的运动，超越了使用端到端方案训练的策略。此外，该方法允许在末端执行器跟踪精度和合规性之间进行灵活权衡。&lt;h4&gt;结论&lt;/h4&gt;RAMBO框架是一个有效的解决方案，它结合了基于模型和控制学习的优点，提高了地面机器人在运动和交互中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Loco-manipulation -- coordinated locomotion and physical interaction withobjects -- remains a major challenge for legged robots due to the need for bothaccurate force interaction and robustness to unmodeled dynamics. Whilemodel-based controllers provide interpretable dynamics-level planning andoptimization, they are limited by model inaccuracies and computational cost. Incontrast, learning-based methods offer robustness while struggling with precisemodulation of interaction forces. We introduce RAMBO -- RL-AugmentedModel-Based Optimal Control -- a hybrid framework that integrates model-basedreaction force optimization using a simplified dynamics model and a feedbackpolicy trained with reinforcement learning. The model-based module generatesfeedforward torques by solving a quadratic program, while the policy providesfeedback residuals to enhance robustness in control execution. We validate ourframework on a quadruped robot across a diverse set of real-worldloco-manipulation tasks -- such as pushing a shopping cart, balancing a plate,and holding soft objects -- in both quadrupedal and bipedal walking. Ourexperiments demonstrate that RAMBO enables precise manipulation while achievingrobust and dynamic locomotion, surpassing the performance of policies trainedwith end-to-end scheme. In addition, our method enables flexible trade-offbetween end-effector tracking accuracy with compliance.</description>
      <author>example@mail.com (Jin Cheng, Dongho Kang, Gabriele Fadini, Guanya Shi, Stelian Coros)</author>
      <guid isPermaLink="false">2504.06662v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Masked Scene Modeling: Narrowing the Gap Between Supervised and Self-Supervised Learning in 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2504.06719v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于评估3D场景理解中自监督特征质量的方法，并引入了一种新的自监督模型，在仅使用现成特征的情况下，其性能与监督模型相似。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在2D计算机视觉领域取得了成功，但在3D场景理解中，自监督方法通常仅作为特定任务的微调初始化步骤，限制了其在通用特征提取方面的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够评估3D场景理解中自监督特征质量的方法，并开发一种新的自监督模型，以提高其在3D场景理解中的性能。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个稳健的评估协议，使用分层模型的多分辨率特征采样来创建丰富的点级表示，并引入了一种基于掩码场景建模目标的新自监督方法，该方法专门针对分层3D模型。&lt;h4&gt;主要发现&lt;/h4&gt;该方法不仅达到了与监督模型相媲美的性能，而且比现有的自监督方法有显著提升。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和模型能够有效地评估和提升3D场景理解中的自监督学习。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised learning has transformed 2D computer vision by enabling models trained on large, unannotated datasets to provide versatile off-the-shelf features that perform similarly to models trained with labels. However, in 3D scene understanding, self-supervised methods are typically only used as a weight initialization step for task-specific fine-tuning, limiting their utility for general-purpose feature extraction. This paper addresses this shortcoming by proposing a robust evaluation protocol specifically designed to assess the quality of self-supervised features for 3D scene understanding. Our protocol uses multi-resolution feature sampling of hierarchical models to create rich point-level representations that capture the semantic capabilities of the model and, hence, are suitable for evaluation with linear probing and nearest-neighbor methods. Furthermore, we introduce the first self-supervised model that performs similarly to supervised models when only off-the-shelf features are used in a linear probing setup. In particular, our model is trained natively in 3D with a novel self-supervised approach based on a Masked Scene Modeling objective, which reconstructs deep features of masked patches in a bottom-up manner and is specifically tailored to hierarchical 3D models. Our experiments not only demonstrate that our method achieves competitive performance to supervised models, but also surpasses existing self-supervised approaches by a large margin. The model and training code can be found at our Github repository (https://github.com/phermosilla/msm).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning has transformed 2D computer vision by enablingmodels trained on large, unannotated datasets to provide versatileoff-the-shelf features that perform similarly to models trained with labels.However, in 3D scene understanding, self-supervised methods are typically onlyused as a weight initialization step for task-specific fine-tuning, limitingtheir utility for general-purpose feature extraction. This paper addresses thisshortcoming by proposing a robust evaluation protocol specifically designed toassess the quality of self-supervised features for 3D scene understanding. Ourprotocol uses multi-resolution feature sampling of hierarchical models tocreate rich point-level representations that capture the semantic capabilitiesof the model and, hence, are suitable for evaluation with linear probing andnearest-neighbor methods. Furthermore, we introduce the first self-supervisedmodel that performs similarly to supervised models when only off-the-shelffeatures are used in a linear probing setup. In particular, our model istrained natively in 3D with a novel self-supervised approach based on a MaskedScene Modeling objective, which reconstructs deep features of masked patches ina bottom-up manner and is specifically tailored to hierarchical 3D models. Ourexperiments not only demonstrate that our method achieves competitiveperformance to supervised models, but also surpasses existing self-supervisedapproaches by a large margin. The model and training code can be found at ourGithub repository (https://github.com/phermosilla/msm).</description>
      <author>example@mail.com (Pedro Hermosilla, Christian Stippel, Leon Sick)</author>
      <guid isPermaLink="false">2504.06719v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>From Broadcast to Minimap: Achieving State-of-the-Art SoccerNet Game State Reconstruction</title>
      <link>http://arxiv.org/abs/2504.06357v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at the CVPR 2025 CVsports Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于单摄像头进行足球比赛状态重建（GSR）的鲁棒端到端流程，该流程在2024年SoccerNet比赛状态重建挑战赛中获得了第一名。&lt;h4&gt;背景&lt;/h4&gt;GSR在体育视频理解中至关重要，需要精确跟踪和定位场上的所有个体，包括球员、守门员、裁判等，以帮助教练和分析师优化训练策略和增强竞争优势。&lt;h4&gt;目的&lt;/h4&gt;解决使用单摄像头进行GSR的挑战，包括频繁的摄像头移动、遮挡和动态场景内容。&lt;h4&gt;方法&lt;/h4&gt;提出的方法集成了YOLOv5m对象检测、基于SegFormer的相机参数估计器和增强重识别、方向预测和球衣号码识别的DeepSORT跟踪框架。&lt;h4&gt;主要发现&lt;/h4&gt;该方法确保了空间准确性和时间一致性，实现了最先进的GSR，在2024年SoccerNet比赛状态重建挑战赛中排名第一，并且显著优于其他方法。&lt;h4&gt;结论&lt;/h4&gt;该方法为单摄像头设置下的GSR提供了有效解决方案，有助于提升体育视频分析的准确性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Game State Reconstruction (GSR), a critical task in Sports VideoUnderstanding, involves precise tracking and localization of all individuals onthe football field-players, goalkeepers, referees, and others - in real-worldcoordinates. This capability enables coaches and analysts to derive actionableinsights into player movements, team formations, and game dynamics, ultimatelyoptimizing training strategies and enhancing competitive advantage. Achievingaccurate GSR using a single-camera setup is highly challenging due to frequentcamera movements, occlusions, and dynamic scene content. In this work, wepresent a robust end-to-end pipeline for tracking players across an entirematch using a single-camera setup. Our solution integrates a fine-tuned YOLOv5mfor object detection, a SegFormer-based camera parameter estimator, and aDeepSORT-based tracking framework enhanced with re-identification, orientationprediction, and jersey number recognition. By ensuring both spatial accuracyand temporal consistency, our method delivers state-of-the-art game statereconstruction, securing first place in the SoccerNet Game State ReconstructionChallenge 2024 and significantly outperforming competing methods.</description>
      <author>example@mail.com (Vladimir Golovkin, Nikolay Nemtsev, Vasyl Shandyba, Oleg Udin, Nikita Kasatkin, Pavel Kononov, Anton Afanasiev, Sergey Ulasen, Andrei Boiarov)</author>
      <guid isPermaLink="false">2504.06357v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Domain-Conditioned Scene Graphs for State-Grounded Task Planning</title>
      <link>http://arxiv.org/abs/2504.06661v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种更结构化的状态 grounding 框架，用于解决基于大型多模态模型（LMMs）的机器人任务规划中的 grounding 问题。&lt;h4&gt;背景&lt;/h4&gt;现有的机器人任务规划框架已经集成了大型多模态模型，如 GPT-4V，但这类模型在 grounding 方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一个更结构化的状态 grounding 框架，以解决基于 LMM 的方法在细粒度、结构化和领域特定场景理解方面的弱点。&lt;h4&gt;方法&lt;/h4&gt;该框架以领域条件化的场景图作为场景表示，该图可以直接映射到经典规划语言（如 PDDL）中的符号状态。领域条件化的场景图生成通过轻量级的视觉-语言方法实现，该方法在领域相关的对象检测之上对领域特定的谓词进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;在三个领域中的应用评估表明，与之前的基于 LMM 的方法相比，该方法实现了显著更高的状态估计准确性和任务规划成功率。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了所提出的框架在解决基于 LMM 的机器人任务规划中的 grounding 问题上的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent robotic task planning frameworks have integrated large multimodalmodels (LMMs) such as GPT-4V. To address grounding issues of such models, ithas been suggested to split the pipeline into perceptional state grounding andsubsequent state-based planning. As we show in this work, the state groundingability of LMM-based approaches is still limited by weaknesses in granular,structured, domain-specific scene understanding. To address this shortcoming,we develop a more structured state grounding framework that features adomain-conditioned scene graph as its scene representation. We show that suchrepresentation is actionable in nature as it is directly mappable to a symbolicstate in classical planning languages such as PDDL. We provide an instantiationof our state grounding framework where the domain-conditioned scene graphgeneration is implemented with a lightweight vision-language approach thatclassifies domain-specific predicates on top of domain-relevant objectdetections. Evaluated across three domains, our approach achieves significantlyhigher state estimation accuracy and task planning success rates compared tothe previous LMM-based approaches.</description>
      <author>example@mail.com (Jonas Herzog, Jiangpin Liu, Yue Wang)</author>
      <guid isPermaLink="false">2504.06661v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Attributes-aware Visual Emotion Representation Learning</title>
      <link>http://arxiv.org/abs/2504.06578v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;视觉情感分析因图像在传达丰富语义和激发人类感知情感方面的兴趣增长而受到广泛关注。本文提出了一种名为A4Net的深度表示网络，旨在通过利用亮度、色彩、场景上下文和面部表情四个关键属性来弥合情感差距，提高情感分析的效果。&lt;h4&gt;背景&lt;/h4&gt;视觉情感分析相较于传统视觉任务存在挑战，主要是因为视觉特征与不同情感状态之间的复杂关系，即情感差距。&lt;h4&gt;目的&lt;/h4&gt;A4Net旨在通过融合和联合训练属性识别和视觉情感分析的各个方面，提供对图像中情感内容的更深入理解。&lt;h4&gt;方法&lt;/h4&gt;A4Net利用亮度、色彩、场景上下文和面部表情四个关键属性来弥合情感差距，并通过深度表示学习方法提取图像的通用特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，A4Net在多个视觉情感数据集上表现出与最先进方法相竞争的性能，并且其激活图的可视化揭示了其在不同视觉情感数据集上的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;A4Net为视觉情感分析提供了一种有效的方法，能够通过考虑多个情感属性来提高情感分析的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉情感分析或识别因人们对理解图像如何传达丰富语义和激发人类感知情感的日益关注而受到广泛关注。然而，与传统的视觉任务相比，视觉情感分析提出了独特的挑战，尤其是在一般视觉特征与其引发的不同的情感状态之间的复杂关系上，这被称为情感差距。研究人员已经使用深度表示学习方法来解决从整个图像中提取通用特征这一挑战。然而，大多数现有方法忽略了诸如亮度、色彩、场景理解和面部表情等特定情感属性的重要性。通过本文，我们引入了A4Net，这是一种深度表示网络，通过利用四个关键属性：亮度（属性1）、色彩（属性2）、场景上下文（属性3）和面部表情（属性4）来弥合情感差距。通过融合和联合训练属性识别和视觉情感分析的各个方面，A4Net旨在对图像中的情感内容提供更深入的洞察。实验结果表明了A4Net的有效性，展示了与最先进方法相比在多个视觉情感数据集上的竞争性能。此外，A4Net生成的激活图的可视化揭示了其在不同视觉情感数据集上的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual emotion analysis or recognition has gained considerable attention dueto the growing interest in understanding how images can convey rich semanticsand evoke emotions in human perception. However, visual emotion analysis posesdistinctive challenges compared to traditional vision tasks, especially due tothe intricate relationship between general visual features and the differentaffective states they evoke, known as the affective gap. Researchers have useddeep representation learning methods to address this challenge of extractinggeneralized features from entire images. However, most existing methodsoverlook the importance of specific emotional attributes such as brightness,colorfulness, scene understanding, and facial expressions. Through this paper,we introduce A4Net, a deep representation network to bridge the affective gapby leveraging four key attributes: brightness (Attribute 1), colorfulness(Attribute 2), scene context (Attribute 3), and facial expressions (Attribute4). By fusing and jointly training all aspects of attribute recognition andvisual emotion analysis, A4Net aims to provide a better insight into emotionalcontent in images. Experimental results show the effectiveness of A4Net,showcasing competitive performance compared to state-of-the-art methods acrossdiverse visual emotion datasets. Furthermore, visualizations of activation mapsgenerated by A4Net offer insights into its ability to generalize acrossdifferent visual emotion datasets.</description>
      <author>example@mail.com (Rahul Singh Maharjan, Marta Romeo, Angelo Cangelosi)</author>
      <guid isPermaLink="false">2504.06578v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>GRAIN: Multi-Granular and Implicit Information Aggregation Graph Neural Network for Heterophilous Graphs</title>
      <link>http://arxiv.org/abs/2504.06649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GRAIN的新型图神经网络模型，专门用于异质图任务，以解决传统GNN在异质图任务中的不足。&lt;h4&gt;背景&lt;/h4&gt;虽然图神经网络在图表示学习方面取得了显著成功，但近期研究表明，在异质图任务中，GNN往往无法超越简单的MLP，并且现有方法很少考虑信息粒度和隐含关系。&lt;h4&gt;目的&lt;/h4&gt;提出GRAIN模型，以克服上述局限性，提高在异质图任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;GRAIN通过聚合不同粒度级别的多视图信息，并整合来自远距离非邻居节点的隐含数据来增强节点嵌入。此外，还引入了一种自适应的图信息聚合器，有效地结合多粒度和隐含数据。&lt;h4&gt;主要发现&lt;/h4&gt;GRAIN在13个数据集上进行了实验，这些数据集覆盖了不同的同质性和异质性，结果显示GRAIN在多个方面均优于12个最先进的模型。&lt;h4&gt;结论&lt;/h4&gt;GRAIN在异质图任务中表现优异，无论是在同质性还是异质性图上，均显著优于现有模型。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNNs) have shown significant success in learning graph representations. However, recent studies reveal that GNNs often fail to outperform simple MLPs on heterophilous graph tasks, where connected nodes may differ in features or labels, challenging the homophily assumption. Existing methods addressing this issue often overlook the importance of information granularity and rarely consider implicit relationships between distant nodes. To overcome these limitations, we propose the Granular and Implicit Graph Network (GRAIN), a novel GNN model specifically designed for heterophilous graphs. GRAIN enhances node embeddings by aggregating multi-view information at various granularity levels and incorporating implicit data from distant, non-neighboring nodes. This approach effectively integrates local and global information, resulting in smoother, more accurate node representations. We also introduce an adaptive graph information aggregator that efficiently combines multi-granularity and implicit data, significantly improving node representation quality, as shown by experiments on 13 datasets covering varying homophily and heterophily. GRAIN consistently outperforms 12 state-of-the-art models, excelling on both homophilous and heterophilous graphs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have shown significant success in learning graphrepresentations. However, recent studies reveal that GNNs often fail tooutperform simple MLPs on heterophilous graph tasks, where connected nodes maydiffer in features or labels, challenging the homophily assumption. Existingmethods addressing this issue often overlook the importance of informationgranularity and rarely consider implicit relationships between distant nodes.To overcome these limitations, we propose the Granular and Implicit GraphNetwork (GRAIN), a novel GNN model specifically designed for heterophilousgraphs. GRAIN enhances node embeddings by aggregating multi-view information atvarious granularity levels and incorporating implicit data from distant,non-neighboring nodes. This approach effectively integrates local and globalinformation, resulting in smoother, more accurate node representations. We alsointroduce an adaptive graph information aggregator that efficiently combinesmulti-granularity and implicit data, significantly improving noderepresentation quality, as shown by experiments on 13 datasets covering varyinghomophily and heterophily. GRAIN consistently outperforms 12 state-of-the-artmodels, excelling on both homophilous and heterophilous graphs.</description>
      <author>example@mail.com (Songwei Zhao, Yuan Jiang, Zijing Zhang, Yang Yu, Hechang Chen)</author>
      <guid isPermaLink="false">2504.06649v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Earth-Adapter: Bridge the Geospatial Domain Gaps with Mixture of Frequency Adaptation</title>
      <link>http://arxiv.org/abs/2504.06220v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Earth-Adapter，这是一种专门为遥感（RS）场景设计的Parameter-Efficient Fine-Tuning（PEFT）方法，用于提高基础模型在遥感任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的PEFT方法在处理遥感图像特征时，由于难以处理伪影影响，效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出Earth-Adapter，以解决PEFT方法在遥感场景中的伪影处理问题，并提高基础模型在遥感任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;Earth-Adapter引入了一种新的混合频率适应过程，结合了混合适配器（MoA）和离散傅里叶变换（DFT）。通过DFT将特征分解为不同的频率成分，精确分离伪影和原始特征。MoA动态地为每个适配器专家分配权重，允许跨不同频率域组合特征。&lt;h4&gt;主要发现&lt;/h4&gt;与基线Rein相比，Earth-Adapter在域适应（DA）和域泛化（DG）语义分割基准测试中分别提高了9.0%和3.1%的mIoU。&lt;h4&gt;结论&lt;/h4&gt;Earth-Adapter能够更有效地克服伪影的干扰，显著提高基础模型在遥感场景上的性能。&lt;h4&gt;翻译&lt;/h4&gt;Parameter-Efficient Fine-Tuning (PEFT) 是一种技术，它允许我们将强大的基础模型 (FMs) 应用于各种下游任务，同时保留并发挥其固有的能力。然而，我们观察到现有的 PEFT 方法，这些方法通常是为自然图像设计的，在应用于遥感 (RS) 场景时存在困难。这主要是因为它们无法处理伪影影响，这是一个在遥感图像特征中尤其严重的问题。为了应对这一挑战，我们引入了 Earth-Adapter，这是第一个专门为 RS 伪影征服设计的 PEFT 方法。Earth-Adapter 引入了一种新的混合频率适应过程，它结合了混合适配器 (MoA) 和离散傅里叶变换 (DFT)。通过利用 DFT，Earth-Adapter 可以将特征分解为不同的频率成分，精确地分离伪影和原始特征。然后，MoA 动态地为每个适配器专家分配权重，允许跨不同频率域组合特征。这些简单而有效的方法使 Earth-Adapter 能够比以前的方法更有效地克服伪影造成的干扰，显著提高 FMs 在 RS 场景上的性能。在域适应 (DA) 和域泛化 (DG) 语义分割基准测试上的实验展示了 Earth-Adapter 的有效性。与基线 Rein 相比，Earth-Adapter 在 DA 和 DG 基准测试中分别提高了 9.0% mIoU 和 3.1% mIoU。我们的代码将在 https://github.com/VisionXLab/Earth-Adapter 上发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-Efficient Fine-Tuning (PEFT) is a technique that allows us to adaptpowerful Foundation Models (FMs) to diverse downstream tasks while preservingand unleashing their inherent capabilities. However, we have observed thatexisting PEFT methods, which are often designed with natural imagery in mind,struggle when applied to Remote Sensing (RS) scenarios. This is primarily dueto their inability to handle artifact influences, a problem particularly severein RS image features. To tackle this challenge, we introduce Earth-Adapter, thefirst PEFT method specifically designed for RS artifacts conquering.Earth-Adapter introduces a novel Mixture of Frequency Adaptation process thatcombines a Mixture of Adapter (MoA) with Discrete Fourier Transformation (DFT).By utilizing DFT, Earth-Adapter can decompose features into different frequencycomponents, precisely separating artifacts from original features. The MoA thendynamically assigns weights to each adapter expert, allowing for thecombination of features across various frequency domains. Thesesimple-yet-effective approaches enable Earth-Adapter to more efficientlyovercome the disturbances caused by artifacts than previous PEFT methods,significantly enhancing the FMs' performance on RS scenarios. Experiments onDomain Adaptation (DA), and Domain Generalization (DG) semantic segmentationbenchmarks showcase the Earth-Adapter's effectiveness. Compared with baselineRein, Earth-Adapter significantly improves 9.0% mIoU in DA and 3.1% mIoU in DGbenchmarks. Our code will be released athttps://github.com/VisionXLab/Earth-Adapter.</description>
      <author>example@mail.com (Xiaoxing Hu, Ziyang Gong, Yupei Wang, Yuru Jia, Gen Luo, Xue Yang)</author>
      <guid isPermaLink="false">2504.06220v2</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>AMAD: AutoMasked Attention for Unsupervised Multivariate Time Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2504.06643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages,7 figures, first upload&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AMAD的无监督多变量时间序列异常检测方法，旨在解决现有模型在处理多样化异常情况时的局限性。&lt;h4&gt;背景&lt;/h4&gt;无监督多变量时间序列异常检测（UMTSAD）在金融、网络和传感器系统等领域扮演着重要角色。近年来，基于Transformer和自注意力机制的深度学习模型在UMTSAD任务中取得了显著成果，但这些模型的序列异常关联假设通常局限于特定的预定义模式和场景。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有模型的局限性，本文提出AMAD方法，旨在提供一种更通用的异常关联表示框架，以应对多样化的异常情况。&lt;h4&gt;方法&lt;/h4&gt;AMAD方法集成了AutoMask机制和注意力mixup模块，形成了一种简单而通用的异常关联表示框架。该方法还采用了Max-Min训练策略和局部-全局对比学习方法，结合多尺度特征提取和自动相对关联建模。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有SOTA基准相比，AMAD在多个数据集上实现了具有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;AMAD提供了一种鲁棒且适应性强的方法，能够有效解决UMTSAD挑战，并在多个数据集上取得了优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;Unsupervised multivariate time series anomaly detection (UMTSAD) plays a critical role in various domains, including finance, networks, and sensor systems. In recent years, due to the outstanding performance of deep learning in general sequential tasks, many models have been specialized for deep UMTSAD tasks and have achieved impressive results, particularly those based on the Transformer and self-attention mechanisms. However, the sequence anomaly association assumptions underlying these models are often limited to specific predefined patterns and scenarios, such as concentrated or peak anomaly patterns. These limitations hinder their ability to generalize to diverse anomaly situations, especially where the lack of labels poses significant challenges. To address these issues, we propose AMAD, which integrates AutoMasked Attention for UMTSAD scenarios. AMAD introduces a novel structure based on the AutoMask mechanism and an attention mixup module, forming a simple yet generalized anomaly association representation framework. This framework is further enhanced by a Max-Min training strategy and a Local-Global contrastive learning approach. By combining multi-scale feature extraction with automatic relative association modeling, AMAD provides a robust and adaptable solution to UMTSAD challenges. Extensive experimental results demonstrate that the proposed model achieving competitive performance results compared to SOTA benchmarks across a variety of datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised multivariate time series anomaly detection (UMTSAD) plays acritical role in various domains, including finance, networks, and sensorsystems. In recent years, due to the outstanding performance of deep learningin general sequential tasks, many models have been specialized for deep UMTSADtasks and have achieved impressive results, particularly those based on theTransformer and self-attention mechanisms. However, the sequence anomalyassociation assumptions underlying these models are often limited to specificpredefined patterns and scenarios, such as concentrated or peak anomalypatterns. These limitations hinder their ability to generalize to diverseanomaly situations, especially where the lack of labels poses significantchallenges. To address these issues, we propose AMAD, which integrates\textbf{A}uto\textbf{M}asked Attention for UMTS\textbf{AD} scenarios. AMADintroduces a novel structure based on the AutoMask mechanism and an attentionmixup module, forming a simple yet generalized anomaly associationrepresentation framework. This framework is further enhanced by a Max-Mintraining strategy and a Local-Global contrastive learning approach. Bycombining multi-scale feature extraction with automatic relative associationmodeling, AMAD provides a robust and adaptable solution to UMTSAD challenges.Extensive experimental results demonstrate that the proposed model achievingcompetitive performance results compared to SOTA benchmarks across a variety ofdatasets.</description>
      <author>example@mail.com (Tiange Huang, Yongjun Li)</author>
      <guid isPermaLink="false">2504.06643v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Defending LLM Watermarking Against Spoofing Attacks with Contrastive Representation Learning</title>
      <link>http://arxiv.org/abs/2504.06575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种语义感知的水印算法，用于检测由LLMs生成的文本，旨在提高水印质量、可检测性和抗篡改能力，同时增强对仿冒攻击的安全性。&lt;h4&gt;背景&lt;/h4&gt;水印技术被用于检测LLMs生成的文本，但当前研究主要关注水印文本的质量、可检测性和抗移除攻击的鲁棒性，而对仿冒攻击的安全性关注较少。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效防御仿冒攻击的语义感知水印算法，同时保持水印文本的高质量、高可检测性和抗移除攻击的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;算法通过引入语义映射模型，生成绿色-红色标记列表，通过对比训练使其对语义扭曲变化敏感，对语义保留编辑不敏感，从而在嵌入水印的同时保持文本的原义。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在两个标准基准测试中表现出对移除攻击的强大鲁棒性和对仿冒攻击的安全性，包括情感反转和有害内容插入，同时保持高水印可检测性。&lt;h4&gt;结论&lt;/h4&gt;该方法为LLMs提供了一种更安全、更具语义感知的水印技术，有助于提高文本生成系统的安全性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：水印技术已成为检测由LLMs生成文本的有前途的技术。当前研究主要关注三个设计标准：水印文本的高质量、高可检测性和对移除攻击的鲁棒性。然而，对仿冒攻击的安全性研究相对较少。例如，通过附加攻击恶意改变水印文本的含义——将其转变为仇恨言论，同时保留原始水印，从而损害LLMs提供者的声誉。我们确定了两个使防御仿冒攻击变得困难的核心挑战：（1）水印需要同时对语义扭曲变化敏感，对语义保留编辑不敏感；（2）检测全局语义变化的需求与大多数水印方案局部、自回归性质之间的矛盾。为了解决这些挑战，我们提出了一种语义感知的水印算法，在事后将水印嵌入到给定的目标文本中，同时保持其原始含义。我们的方法引入了一个语义映射模型，该模型指导生成一个绿色-红色标记列表，通过对比训练使其对语义扭曲变化敏感，对语义保留变化不敏感。在两个标准基准测试上的实验表明，该方法对移除攻击具有强大的鲁棒性，对仿冒攻击（包括情感反转和有害内容插入）具有安全性，同时保持高水印可检测性。我们的方法为LLMs提供了更安全、更具语义感知的水印技术的重要一步。我们的代码可在https://github.com/UCSB-NLP-Chang/contrastive-watermark上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Watermarking has emerged as a promising technique for detecting textsgenerated by LLMs. Current research has primarily focused on three designcriteria: high quality of the watermarked text, high detectability, androbustness against removal attack. However, the security against spoofingattacks remains relatively understudied. For example, a piggyback attack canmaliciously alter the meaning of watermarked text-transforming it into hatespeech-while preserving the original watermark, thereby damaging the reputationof the LLM provider. We identify two core challenges that make defendingagainst spoofing difficult: (1) the need for watermarks to be both sensitive tosemantic-distorting changes and insensitive to semantic-preserving edits, and(2) the contradiction between the need to detect global semantic shifts and thelocal, auto-regressive nature of most watermarking schemes. To address thesechallenges, we propose a semantic-aware watermarking algorithm that post-hocembeds watermarks into a given target text while preserving its originalmeaning. Our method introduces a semantic mapping model, which guides thegeneration of a green-red token list, contrastively trained to be sensitive tosemantic-distorting changes and insensitive to semantic-preserving changes.Experiments on two standard benchmarks demonstrate strong robustness againstremoval attacks and security against spoofing attacks, including sentimentreversal and toxic content insertion, while maintaining high watermarkdetectability. Our approach offers a significant step toward more secure andsemantically aware watermarking for LLMs. Our code is available athttps://github.com/UCSB-NLP-Chang/contrastive-watermark.</description>
      <author>example@mail.com (Li An, Yujian Liu, Yepeng Liu, Yang Zhang, Yuheng Bu, Shiyu Chang)</author>
      <guid isPermaLink="false">2504.06575v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>cuTeSpMM: Accelerating Sparse-Dense Matrix Multiplication using GPU Tensor Cores</title>
      <link>http://arxiv.org/abs/2504.06443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用GPU的矩阵乘法引擎（即Tensor Core Units或TCUs）来加速稀疏-密集矩阵乘法（SpMM）的性能，并提出了一种新的方法cuTeSpMM，其性能显著高于现有方法。&lt;h4&gt;背景&lt;/h4&gt;现代GPU配备了矩阵乘法引擎，能够高效执行小尺寸矩阵乘法。这些引擎已用于加速密集矩阵乘法库，如Nvidia的cuBLAS，但最近的研究兴趣在于利用这些引擎进行SpMM。&lt;h4&gt;目的&lt;/h4&gt;研究能否有效地使用密集TCUs加速来自多个应用领域的稀疏矩阵的SpMM，例如SuiteSparse矩阵集合中的矩阵。&lt;h4&gt;方法&lt;/h4&gt;开发了一种基于TCU的GPU内核cuTeSpMM，并基于稀疏矩阵的非零结构和模型化操作强度，提出了TCU协同度的概念。&lt;h4&gt;主要发现&lt;/h4&gt;cuTeSpMM在具有高TCU协同度的稀疏矩阵上表现优于现有标量核心SpMM实现，而在TCU协同度低的矩阵上仅略逊色。&lt;h4&gt;结论&lt;/h4&gt;密集TCUs可以有效地用于加速来自多个应用领域的稀疏矩阵的SpMM，并且cuTeSpMM是一种高效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many recent GPUs feature matrix multiplication engines (aka Tensor Core Unitsor TCUs) that perform small fixed-size matrix-matrix products at very highthroughput. They have been used very effectively to speed up densematrix-matrix multiplication libraries like Nvidia's cuBLAS, enablingsignificantly higher performance over use of the traditional scalar GPU cores.There also been recent interest in using these dense TCUs for the importantsparse-dense matrix-matrix multiplication (SpMM) kernel via explicitzero-filling.  However, an examination of the attainable performance of TC-GNN, thestate-of-the-art TCU-enhanced SpMM implementation, indicates that for asubstantial majority of the sparse matrices in the SuiteSparse collection, theachieved performance falls significantly short of the state-of-the-art SpMMkernels that only utilize scalar cores.  In this paper, we therefore address the question: Can dense TCUs beeffectively used to accelerate SpMM for a range of sparse matrices arising frommultiple application domains, such as those found in the SuiteSparse matrixcollection? We answer this question in the affirmative by developing a veryefficient TCU-based GPU kernel - cuTeSpMM (cuda Tensor core SpMM) that achievessubstantially higher performance over TC-GNN. We also develop a notion of theTCU-Synergy of a sparse-matrix, based on its non-zero structure and a modeledOperational Intensity. For sparse matrices with high TCU-synergy, cuTeSpMMoutperforms state-of-the-art scalar-core SpMM implementations, while achievingonly slightly lower performance on matrices with low TCU-Synergy.</description>
      <author>example@mail.com (Lizhi Xiang, Omid Asudeh, Gerald Sabin, Aravind Sukumaran-Rajam, P. Sadayappan)</author>
      <guid isPermaLink="false">2504.06443v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Domain Generalization via Discrete Codebook Learning</title>
      <link>http://arxiv.org/abs/2504.06572v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICME 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的领域泛化学习方法，称为离散领域泛化（DDG），通过将特征图量化为离散码字来减少连续表示学习中的领域差距，从而提高模型的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;当前领域泛化（DG）方法主要关注连续特征的鲁棒表示学习，但这种方法在处理连续特征的大空间时可能难以减少分布差距，且容易受到像素细节的影响。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的领域泛化方法，以减少连续特征表示学习中的领域差距，并提高模型的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为离散领域泛化（DDG）的新学习范式，使用码本将特征图量化为离散码字，并在一个优先考虑语义信息的共享离散表示空间中进行学习。&lt;h4&gt;主要发现&lt;/h4&gt;理论证明了通过离散化过程可以减少连续表示学习中的领域差距，并通过实验证明了DDG相较于现有方法在多个DG基准测试中的优越性能。&lt;h4&gt;结论&lt;/h4&gt;DDG通过减少分布差距，优化表示空间的使用，提高了模型的泛化能力，具有潜在的实用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：领域泛化（DG）旨在解决不同环境中的分布偏移问题，以增强模型的可泛化性。当前DG方法局限于获取具有连续特征的鲁棒表示，特别是像素级别的训练。然而，这种DG范式可能难以缓解处理连续特征大空间时的分布差距，使其容易受到表现出伪相关或噪声的像素细节的影响。在本文中，我们首先从理论上证明，通过离散化过程可以减少连续表示学习中的领域差距。基于这一启发性的发现，我们引入了一种新的领域泛化学习范式，称为离散领域泛化（DDG）。DDG提出使用码本将特征图量化为离散码字，在优先考虑语义信息的共享离散表示空间中对齐语义等效信息。通过在语义级别进行学习，DDG减少了潜在特征的数量，优化了表示空间的使用，并缓解了与连续特征宽泛空间相关的风险。在DG中广泛使用的基准测试上的大量实验表明，DDG相较于最先进的方法具有优越的性能，突显了其减少分布差距并提高模型泛化能力的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain generalization (DG) strives to address distribution shifts acrossdiverse environments to enhance model's generalizability. Current DG approachesare confined to acquiring robust representations with continuous features,specifically training at the pixel level. However, this DG paradigm maystruggle to mitigate distribution gaps in dealing with a large space ofcontinuous features, rendering it susceptible to pixel details that exhibitspurious correlations or noise. In this paper, we first theoreticallydemonstrate that the domain gaps in continuous representation learning can bereduced by the discretization process. Based on this inspiring finding, weintroduce a novel learning paradigm for DG, termed Discrete DomainGeneralization (DDG). DDG proposes to use a codebook to quantize the featuremap into discrete codewords, aligning semantic-equivalent information in ashared discrete representation space that prioritizes semantic-levelinformation over pixel-level intricacies. By learning at the semantic level,DDG diminishes the number of latent features, optimizing the utilization of therepresentation space and alleviating the risks associated with the wide-rangingspace of continuous features. Extensive experiments across widely employedbenchmarks in DG demonstrate DDG's superior performance compared tostate-of-the-art approaches, underscoring its potential to reduce thedistribution gaps and enhance the model's generalizability.</description>
      <author>example@mail.com (Shaocong Long, Qianyu Zhou, Xikun Jiang, Chenhao Ying, Lizhuang Ma, Yuan Luo)</author>
      <guid isPermaLink="false">2504.06572v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>ASHiTA: Automatic Scene-grounded HIerarchical Task Analysis</title>
      <link>http://arxiv.org/abs/2504.06553v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ASHiTA的框架，用于将高级任务分解为与环境相关的子任务，并将其应用于场景重建和理解中。&lt;h4&gt;背景&lt;/h4&gt;尽管自然语言与物理3D环境之间的联系已经取得进展，但将抽象的高级指令与环境中的3D场景联系起来仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架，能够将高级任务分解为与环境相关的子任务，并生成一个适合环境的表示。&lt;h4&gt;方法&lt;/h4&gt;ASHiTA通过交替使用LLM辅助的层次任务分析和任务驱动的3D场景图构建来实现这一目标。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AShiTA在将高级任务分解为环境相关的子任务方面显著优于LLM基线，并且能够达到与最先进方法相当的性能。&lt;h4&gt;结论&lt;/h4&gt;AShiTA是一种有效的框架，可以用于将高级指令与环境中的3D场景联系起来，并在任务分解方面表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While recent work in scene reconstruction and understanding has made stridesin grounding natural language to physical 3D environments, it is stillchallenging to ground abstract, high-level instructions to a 3D scene.High-level instructions might not explicitly invoke semantic elements in thescene, and even the process of breaking a high-level task into a set of moreconcrete subtasks, a process called hierarchical task analysis, isenvironment-dependent. In this work, we propose ASHiTA, the first frameworkthat generates a task hierarchy grounded to a 3D scene graph by breaking downhigh-level tasks into grounded subtasks. ASHiTA alternates LLM-assistedhierarchical task analysis, to generate the task breakdown, with task-driven 3Dscene graph construction to generate a suitable representation of theenvironment. Our experiments show that ASHiTA performs significantly betterthan LLM baselines in breaking down high-level tasks into environment-dependentsubtasks and is additionally able to achieve grounding performance comparableto state-of-the-art methods.</description>
      <author>example@mail.com (Yun Chang, Leonor Fermoselle, Duy Ta, Bernadette Bucher, Luca Carlone, Jiuguang Wang)</author>
      <guid isPermaLink="false">2504.06553v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network-Based Distributed Optimal Control for Linear Networked Systems: An Online Distributed Training Approach</title>
      <link>http://arxiv.org/abs/2504.06439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了线性网络系统的分布式最优控制问题，提出了一种基于图循环神经网络（GRNN）的分布式最优控制方法，并实现了在线分布式训练。&lt;h4&gt;背景&lt;/h4&gt;目前大多数方法导致集中式最优控制器和离线训练过程，而网络容错性需求的增加要求控制器更加分布化和在线训练。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够在线分布式训练的分布式最优控制器，以应对网络容错性需求的增长。&lt;h4&gt;方法&lt;/h4&gt;首先，提出了一种基于GRNN的分布式最优控制方法，并将问题表述为自监督学习问题；然后，通过分布式梯度计算实现分布式在线训练，并设计了基于一致性的分布式在线训练优化器；此外，通过假设GRNN控制器的非线性激活函数具有局部扇形有界和斜率限制，提供了线性网络系统在所提GRNN控制器下的局部闭环稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过数值模拟验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的GRNN方法能够实现线性网络系统的分布式在线训练，具有良好的稳定性和适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we consider the distributed optimal control problem for linearnetworked systems. In particular, we are interested in learning distributedoptimal controllers using graph recurrent neural networks (GRNNs). Most of theexisting approaches result in centralized optimal controllers with offlinetraining processes. However, as the increasing demand of network resilience,the optimal controllers are further expected to be distributed, and aredesirable to be trained in an online distributed fashion, which are also themain contributions of our work. To solve this problem, we first propose aGRNN-based distributed optimal control method, and we cast the problem as aself-supervised learning problem. Then, the distributed online training isachieved via distributed gradient computation, and inspired by the(consensus-based) distributed optimization idea, a distributed online trainingoptimizer is designed. Furthermore, the local closed-loop stability of thelinear networked system under our proposed GRNN-based controller is provided byassuming that the nonlinear activation function of the GRNN-based controller isboth local sector-bounded and slope-restricted. The effectiveness of ourproposed method is illustrated by numerical simulations using a specificallydeveloped simulator.</description>
      <author>example@mail.com (Zihao Song, Panos J. Antsaklis, Hai Lin)</author>
      <guid isPermaLink="false">2504.06439v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>S'MoRE: Structural Mixture of Residual Experts for LLM Fine-tuning</title>
      <link>http://arxiv.org/abs/2504.06426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为S'MoRE的新型框架，该框架结合了LoRA的高效性和MoE的灵活性，以实现预训练大型语言模型的微调。&lt;h4&gt;背景&lt;/h4&gt;微调预训练的大型语言模型（LLMs）面临着参数效率和模型容量之间的平衡挑战。现有的LoRA方法虽然高效，但缺乏灵活性；而MoE架构在增加模型容量的同时，也带来了更多未充分利用的参数。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的框架S'MoRE，旨在提高LLMs微调的效率。&lt;h4&gt;方法&lt;/h4&gt;S'MoRE通过层次化的低秩分解专家权重，生成不同阶数的残差，这些残差以多层结构相互连接。通过将输入标记路由到残差子树中，S'MoRE通过实例化和组装少数低秩矩阵来模拟多个专家的能力。此外，S'MoRE的层间传播被设计为一种特殊的图神经网络（GNN）。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析和实验结果表明，与传统的MoE或Mixture-of-LoRA相比，S'MoRE在相似的参数预算下，通过指数级提高了“结构灵活性”。&lt;h4&gt;结论&lt;/h4&gt;S'MoRE实现了优异的微调性能，为高效的LLMs适应提供了一种变革性的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：微调预训练的大型语言模型（LLMs）面临着参数效率和模型容量平衡的双重挑战。现有的方法如低秩适应（LoRA）虽然高效但缺乏灵活性，而混合专家（MoE）架构在增加模型容量的同时，也带来了更多未充分利用的参数。为了解决这些限制，我们提出了结构化混合残差专家（S'MoRE）这一新颖的框架，它无缝地整合了LoRA的高效性和MoE的灵活性。具体来说，S'MoRE采用专家权重的层次化低秩分解，生成不同阶数的残差，这些残差以多层结构相互连接。通过将输入标记路由到残差子树中，S'MoRE通过实例化和组装少数低秩矩阵来模拟多个专家的能力。我们还将S'MoRE的残差层间传播设计为一种特殊的图神经网络（GNN），并证明在相似的参数预算下，S'MoRE通过指数级提高了传统MoE（或Mixture-of-LoRA）的“结构灵活性”。全面的理论分析和实证结果表明，S'MoRE实现了优越的微调性能，为高效的LLMs适应提供了一种变革性的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-tuning pre-trained large language models (LLMs) presents a dualchallenge of balancing parameter efficiency and model capacity. Existingmethods like low-rank adaptations (LoRA) are efficient but lack flexibility,while Mixture-of-Experts (MoE) architectures enhance model capacity at the costof more &amp; under-utilized parameters. To address these limitations, we proposeStructural Mixture of Residual Experts (S'MoRE), a novel framework thatseamlessly integrates the efficiency of LoRA with the flexibility of MoE.Specifically, S'MoRE employs hierarchical low-rank decomposition of expertweights, yielding residuals of varying orders interconnected in a multi-layerstructure. By routing input tokens through sub-trees of residuals, S'MoREemulates the capacity of many experts by instantiating and assembling just afew low-rank matrices. We craft the inter-layer propagation of S'MoRE'sresiduals as a special type of Graph Neural Network (GNN), and prove that undersimilar parameter budget, S'MoRE improves "structural flexibility" oftraditional MoE (or Mixture-of-LoRA) by exponential order. Comprehensivetheoretical analysis and empirical results demonstrate that S'MoRE achievessuperior fine-tuning performance, offering a transformative approach forefficient LLM adaptation.</description>
      <author>example@mail.com (Hanqing Zeng, Yinglong Xia, Zhuokai Zhao, Gilbert Jiang, Qiang Zhang, Jiayi Liu, Lizhu Zhang, Xiangjun Fan, Benyu Zhang)</author>
      <guid isPermaLink="false">2504.06426v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>DiffusionCom: Structure-Aware Multimodal Diffusion Model for Multimodal Knowledge Graph Completion</title>
      <link>http://arxiv.org/abs/2504.06543v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DiffusionCom的结构感知多模态扩散模型，用于多模态知识图谱补全。该模型通过生成模型的方法来建模实体和关系之间的关联，并利用结构信息来提高知识图谱补全的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态知识图谱补全方法大多基于判别模型，这些方法在捕捉现实世界知识图谱中的复杂连接时效率较低，限制了它们的整体性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高多模态知识图谱补全的性能，尤其是通过有效利用结构信息。&lt;h4&gt;方法&lt;/h4&gt;DiffusionCom从生成模型的角度出发，将实体和关系对的关联建模为它们的联合概率分布，并将多模态知识图谱补全任务视为从噪声中逐步生成联合概率分布的过程。此外，为了充分利用知识图谱中的结构信息，提出了Structure-MKGformer，这是一种自适应的结构感知多模态知识表示学习方法，作为DiffusionCom的编码器。Structure-MKGformer通过多模态图注意力网络（MGAT）捕获丰富的结构信息，并自适应地将其与实体表示融合，从而增强这些表示的结构感知能力。&lt;h4&gt;主要发现&lt;/h4&gt;DiffusionCom通过使用生成和判别损失来训练生成器，而特征提取器仅使用判别损失进行优化。这种双重方法使DiffusionCom能够利用生成和判别模型的优点。在FB15k-237-IMG和WN18-IMG数据集上的大量实验表明，DiffusionCom优于最先进的模型。&lt;h4&gt;结论&lt;/h4&gt;DiffusionCom是一种有效的多模态知识图谱补全方法，它通过结合生成和判别模型的优势，并充分利用结构信息，显著提高了知识图谱补全的性能。&lt;h4&gt;翻译&lt;/h4&gt;Most current MKGC approaches are predominantly based on discriminative models that maximize conditional likelihood. These approaches struggle to efficiently capture the complex connections in real-world knowledge graphs, thereby limiting their overall performance. To address this issue, we propose a structure-aware multimodal Diffusion model for multimodal knowledge graph Completion (DiffusionCom). DiffusionCom innovatively approaches the problem from the perspective of generative models, modeling the association between the (head, relation) pair and candidate tail entities as their joint probability distribution p((head, relation), (tail)), and framing the MKGC task as a process of gradually generating the joint probability distribution from noise. Furthermore, to fully leverage the structural information in MKGs, we propose Structure-MKGformer, an adaptive and structure-aware multimodal knowledge representation learning method, as the encoder for DiffusionCom. Structure-MKGformer captures rich structural information through a multimodal graph attention network (MGAT) and adaptively fuses it with entity representations, thereby enhancing the structural awareness of these representations. This design effectively addresses the limitations of existing MKGC methods, particularly those based on multimodal pre-trained models, in underutilizing structural information. DiffusionCom is trained using both generative and discriminative losses for the generator, while the feature extractor is optimized exclusively with discriminative loss. This dual approach allows DiffusionCom to harness the strengths of both generative and discriminative models. Extensive experiments on the FB15k-237-IMG and WN18-IMG datasets demonstrate that DiffusionCom outperforms state-of-the-art models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most current MKGC approaches are predominantly based on discriminative modelsthat maximize conditional likelihood. These approaches struggle to efficientlycapture the complex connections in real-world knowledge graphs, therebylimiting their overall performance. To address this issue, we propose astructure-aware multimodal Diffusion model for multimodal knowledge graphCompletion (DiffusionCom). DiffusionCom innovatively approaches the problemfrom the perspective of generative models, modeling the association between the$(head, relation)$ pair and candidate tail entities as their joint probabilitydistribution $p((head, relation), (tail))$, and framing the MKGC task as aprocess of gradually generating the joint probability distribution from noise.Furthermore, to fully leverage the structural information in MKGs, we proposeStructure-MKGformer, an adaptive and structure-aware multimodal knowledgerepresentation learning method, as the encoder for DiffusionCom.Structure-MKGformer captures rich structural information through a multimodalgraph attention network (MGAT) and adaptively fuses it with entityrepresentations, thereby enhancing the structural awareness of theserepresentations. This design effectively addresses the limitations of existingMKGC methods, particularly those based on multimodal pre-trained models, inutilizing structural information. DiffusionCom is trained using both generativeand discriminative losses for the generator, while the feature extractor isoptimized exclusively with discriminative loss. This dual approach allowsDiffusionCom to harness the strengths of both generative and discriminativemodels. Extensive experiments on the FB15k-237-IMG and WN18-IMG datasetsdemonstrate that DiffusionCom outperforms state-of-the-art models.</description>
      <author>example@mail.com (Wei Huang, Meiyu Liang, Peining Li, Xu Hou, Yawen Li, Junping Du, Zhe Xue, Zeli Guan)</author>
      <guid isPermaLink="false">2504.06543v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>SemiDAViL: Semi-supervised Domain Adaptation with Vision-Language Guidance for Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2504.06389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的语言引导的半监督领域自适应（SSDA）方法，用于语义分割，通过利用预训练语言模型中的语义关系来增强特征表示，从而提高分割性能。&lt;h4&gt;背景&lt;/h4&gt;领域自适应（DA）和半监督学习（SSL）在半监督领域自适应（SSDA）中结合，旨在使用有限的标记目标样本和大量的未标记目标数据将知识从源域迁移到目标域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的语言引导的SSDA设置，用于解决语义分割中由于监督不足和数据分布不平衡导致的性能问题。&lt;h4&gt;方法&lt;/h4&gt;利用视觉-语言模型（VLM）的语义泛化能力，在SSDA框架内建立协同框架，并引入类平衡分割损失公式来应对长尾分布中的类不平衡挑战。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多种领域自适应场景中，与现有最先进（SoTA）方法相比，显示出显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;提出的语言引导的SSDA方法有效地提高了语义分割的性能，为解决领域自适应和半监督学习中的挑战提供了一种新的思路。&lt;h4&gt;翻译&lt;/h4&gt;Domain Adaptation (DA) and Semi-supervised Learning (SSL) converge in Semi-supervised Domain Adaptation (SSDA), where the objective is to transfer knowledge from a source domain to a target domain using a combination of limited labeled target samples and abundant unlabeled target data. Although intuitive, a simple amalgamation of DA and SSL is suboptimal in semantic segmentation due to two major reasons: (1) previous methods, while able to learn good segmentation boundaries, are prone to confuse classes with similar visual appearance due to limited supervision; and (2) skewed and imbalanced training data distribution preferring source representation learning whereas impeding from exploring limited information about tailed classes. Language guidance can serve as a pivotal semantic bridge, facilitating robust class discrimination and mitigating visual ambiguities by leveraging the rich semantic relationships encoded in pre-trained language models to enhance feature representations across domains. Therefore, we propose the first language-guided SSDA setting for semantic segmentation in this work. Specifically, we harness the semantic generalization capabilities inherent in vision-language models (VLMs) to establish a synergistic framework within the SSDA paradigm. To address the inherent class-imbalance challenges in long-tailed distributions, we introduce class-balanced segmentation loss formulations that effectively regularize the learning process. Through extensive experimentation across diverse domain adaptation scenarios, our approach demonstrates substantial performance improvements over contemporarystate-of-the-art (SoTA) methodologies. Code is available: [GitHub](https://github.com/hritam-98/SemiDAViL).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain Adaptation (DA) and Semi-supervised Learning (SSL) converge inSemi-supervised Domain Adaptation (SSDA), where the objective is to transferknowledge from a source domain to a target domain using a combination oflimited labeled target samples and abundant unlabeled target data. Althoughintuitive, a simple amalgamation of DA and SSL is suboptimal in semanticsegmentation due to two major reasons: (1) previous methods, while able tolearn good segmentation boundaries, are prone to confuse classes with similarvisual appearance due to limited supervision; and (2) skewed and imbalancedtraining data distribution preferring source representation learning whereasimpeding from exploring limited information about tailed classes. Languageguidance can serve as a pivotal semantic bridge, facilitating robust classdiscrimination and mitigating visual ambiguities by leveraging the richsemantic relationships encoded in pre-trained language models to enhancefeature representations across domains. Therefore, we propose the firstlanguage-guided SSDA setting for semantic segmentation in this work.Specifically, we harness the semantic generalization capabilities inherent invision-language models (VLMs) to establish a synergistic framework within theSSDA paradigm. To address the inherent class-imbalance challenges inlong-tailed distributions, we introduce class-balanced segmentation lossformulations that effectively regularize the learning process. Throughextensive experimentation across diverse domain adaptation scenarios, ourapproach demonstrates substantial performance improvements over contemporarystate-of-the-art (SoTA) methodologies. Code is available:\href{https://github.com/hritam-98/SemiDAViL}{GitHub}.</description>
      <author>example@mail.com (Hritam Basak, Zhaozheng Yin)</author>
      <guid isPermaLink="false">2504.06389v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Deep spatio-temporal point processes: Advances and new directions</title>
      <link>http://arxiv.org/abs/2504.06364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了时空点过程（STPPs）在犯罪学、地震学、流行病学和社会网络等领域的重要应用。文章介绍了深度影响核方法的发展，该方法通过直接建模条件强度函数或学习灵活的数据驱动影响核来增强模型的表达能力，同时保持了统计可解释性。文章解释了开发深度核点过程的主要组成部分，包括使用函数基分解和图神经网络来编码复杂的空间或网络结构，以及使用基于似然和免似然的方法进行估计，并讨论了大规模数据的计算可扩展性。此外，还讨论了核可识别性的理论基础，并通过模拟和实际数据示例展示了其在犯罪分析、地震余震预测和脓毒症预测建模中的应用。最后，讨论了该领域的前景方向。&lt;h4&gt;背景&lt;/h4&gt;时空点过程（STPPs）用于模拟时间和空间中离散事件的分布，在犯罪学、地震学、流行病学和社会网络等领域有重要应用。&lt;h4&gt;目的&lt;/h4&gt;介绍深度影响核方法的发展及其在时空点过程中的应用。&lt;h4&gt;方法&lt;/h4&gt;开发深度核点过程，利用函数基分解和图神经网络编码复杂结构，使用基于似然和免似然的方法进行估计，并讨论计算可扩展性。&lt;h4&gt;主要发现&lt;/h4&gt;深度影响核方法增强了模型的表达能力，同时保持了统计可解释性。&lt;h4&gt;结论&lt;/h4&gt;深度影响核方法在时空点过程建模中有潜力，并在多个领域有应用。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Spatio-temporal point processes (STPPs) model discrete events distributed in time and space, with important applications in areas such as criminology, seismology, epidemiology, and social networks. Traditional models often rely on parametric kernels, limiting their ability to capture heterogeneous, nonstationary dynamics. Recent innovations integrate deep neural architectures-- either by modeling the conditional intensity function directly or by learning flexible, data-driven influence kernels, substantially broadening their expressive power. This article reviews the development of the deep influence kernel approach, which enjoys statistical explainability, since the influence kernel remains in the model to capture the spatiotemporal propagation of event influence and its impact on future events, while also possessing strong expressive power, thereby benefiting from both worlds. We explain the main components in developing deep kernel point processes, leveraging tools such as functional basis decomposition and graph neural networks to encode complex spatial or network structures, as well as estimation using both likelihood-based and likelihood-free methods, and address computational scalability for large-scale data. We also discuss the theoretical foundation of kernel identifiability. Simulated and real-data examples highlight applications to crime analysis, earthquake aftershock prediction, and sepsis prediction modeling, and we conclude by discussing promising directions for the field.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatio-temporal point processes (STPPs) model discrete events distributed intime and space, with important applications in areas such as criminology,seismology, epidemiology, and social networks. Traditional models often rely onparametric kernels, limiting their ability to capture heterogeneous,nonstationary dynamics. Recent innovations integrate deep neural architectures-- either by modeling the conditional intensity function directly or bylearning flexible, data-driven influence kernels, substantially broadeningtheir expressive power. This article reviews the development of the deepinfluence kernel approach, which enjoys statistical explainability, since theinfluence kernel remains in the model to capture the spatiotemporal propagationof event influence and its impact on future events, while also possessingstrong expressive power, thereby benefiting from both worlds. We explain themain components in developing deep kernel point processes, leveraging toolssuch as functional basis decomposition and graph neural networks to encodecomplex spatial or network structures, as well as estimation using bothlikelihood-based and likelihood-free methods, and address computationalscalability for large-scale data. We also discuss the theoretical foundation ofkernel identifiability. Simulated and real-data examples highlight applicationsto crime analysis, earthquake aftershock prediction, and sepsis predictionmodeling, and we conclude by discussing promising directions for the field.</description>
      <author>example@mail.com (Xiuyuan Cheng, Zheng Dong, Yao Xie)</author>
      <guid isPermaLink="false">2504.06364v1</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Robo-taxi Fleet Coordination at Scale via Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2504.06125v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 6 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种新型的决策框架，用于解决大规模的自动移动需求（AMoD）系统协调问题，通过结合数学建模和数据驱动技术，实现了系统性能、计算效率和泛化能力的提升。&lt;h4&gt;背景&lt;/h4&gt;AMoD系统，即自动移动需求系统，具有减少污染、能源消耗和城市拥堵的社会效益，但其规模化的协调是一个关键挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合数学建模和数据驱动技术的决策框架，以解决AMoD系统协调问题。&lt;h4&gt;方法&lt;/h4&gt;通过强化学习视角提出AMoD协调问题，并设计了一个基于图网络的框架，利用图表示学习、强化学习和经典运筹研究工具的优势。&lt;h4&gt;主要发现&lt;/h4&gt;在多种模拟真实性和场景中进行广泛评估，证明了该方法在系统性能、计算效率和泛化能力方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;论文提出了一个有效的AMoD系统协调框架，并公开了基准、数据集和模拟器，以及开源代码库，以促进该领域的研究民主化。&lt;h4&gt;翻译&lt;/h4&gt;The paper introduces a novel decision-making framework for addressing the coordination challenge of large-scale Autonomous Mobility-on-Demand (AMoD) systems by combining mathematical modeling with data-driven techniques. This approach, evaluated across various simulation fidelity and scenarios, demonstrates superior system performance, computational efficiency, and generalizability compared to existing methods. Motivated by the need to democratize research efforts in this area, the paper also releases publicly available benchmarks, datasets, and simulators for network-level coordination, along with an open-source codebase designed to provide accessible simulation platforms and establish a standardized validation process for comparing methodologies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fleets of robo-taxis offering on-demand transportation services, commonlyknown as Autonomous Mobility-on-Demand (AMoD) systems, hold significant promisefor societal benefits, such as reducing pollution, energy consumption, andurban congestion. However, orchestrating these systems at scale remains acritical challenge, with existing coordination algorithms often failing toexploit the systems' full potential. This work introduces a noveldecision-making framework that unites mathematical modeling with data-driventechniques. In particular, we present the AMoD coordination problem through thelens of reinforcement learning and propose a graph network-based framework thatexploits the main strengths of graph representation learning, reinforcementlearning, and classical operations research tools. Extensive evaluations acrossdiverse simulation fidelities and scenarios demonstrate the flexibility of ourapproach, achieving superior system performance, computational efficiency, andgeneralizability compared to prior methods. Finally, motivated by the need todemocratize research efforts in this area, we release publicly availablebenchmarks, datasets, and simulators for network-level coordination alongsidean open-source codebase designed to provide accessible simulation platforms andestablish a standardized validation process for comparing methodologies. Codeavailable at: https://github.com/StanfordASL/RL4AMOD</description>
      <author>example@mail.com (Luigi Tresca, Carolin Schmidt, James Harrison, Filipe Rodrigues, Gioele Zardini, Daniele Gammelli, Marco Pavone)</author>
      <guid isPermaLink="false">2504.06125v2</guid>
      <pubDate>Thu, 10 Apr 2025 14:14:52 +0800</pubDate>
    </item>
    <item>
      <title>Bridging the Gap Between Contextual and Standard Stochastic Bilevel Optimization</title>
      <link>http://arxiv.org/abs/2503.19991v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CSBO的上下文随机双层优化方法，通过结合上下文特定的下层问题，扩展了标准的随机双层优化方法。该方法由于上下文实化的无限约束，使得计算复杂性远高于SBO，并提出了一种新的简化框架，通过参数化将CSBO转化为等价的SBO问题，从而消除了条件采样的需求。在合理的上下文分布和下层正则性假设下，证明了CSBO的ε-稳定解可以通过近似最优的采样复杂度实现。&lt;h4&gt;背景&lt;/h4&gt;CSBO在元学习和超参数优化等应用中引入了上下文特定的下层问题，导致无限数量的约束，使得计算复杂性显著高于SBO。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决CSBO问题，提高计算效率和理论保证。&lt;h4&gt;方法&lt;/h4&gt;通过参数化将CSBO转化为等价的SBO问题，消除条件采样的需求。&lt;h4&gt;主要发现&lt;/h4&gt;在合理的上下文分布和下层正则性假设下，证明了CSBO的ε-稳定解可以通过近似最优的采样复杂度实现。&lt;h4&gt;结论&lt;/h4&gt;该方法提高了CSBO问题的实际解决能力，通过改进计算效率和理论保证。&lt;h4&gt;翻译&lt;/h4&gt;摘要：上下文随机双层优化（CSBO）通过结合上下文特定的下层问题扩展了标准的随机双层优化（SBO），这些下层问题出现在元学习和超参数优化等应用中。这种结构引入了无限数量的约束——每个上下文实现一个——使得CSBO的计算复杂性远高于SBO，因为不同上下文之间最小化器的模糊关系表明，对于每个上层迭代需要计算大量的下层解。现有的CSBO方法面临两个主要限制：与SBO相比存在显著的复杂性差距，并且依赖于不切实际的条件采样算子。我们提出了一种新的简化框架，通过参数化将下层解对上层决策和上下文的依赖解耦，从而将CSBO转化为等价的SBO问题，消除了条件采样的需求。在上下文分布和下层正则性的合理假设下，我们证明了CSBO的ε-稳定解可以通过近似最优的采样复杂度O(ε^-3)实现。我们的方法通过提高计算效率和理论保证，增强了解决CSBO问题的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contextual Stochastic Bilevel Optimization (CSBO) extends standard StochasticBilevel Optimization (SBO) by incorporating context-specific lower-levelproblems, which arise in applications such as meta-learning and hyperparameteroptimization. This structure imposes an infinite number of constraints - onefor each context realization - making CSBO significantly more challenging thanSBO as the unclear relationship between minimizers across different contextssuggests computing numerous lower-level solutions for each upper-leveliteration. Existing approaches to CSBO face two major limitations: substantialcomplexity gaps compared to SBO and reliance on impractical conditionalsampling oracles. We propose a novel reduction framework that decouples thedependence of the lower-level solution on the upper-level decision and contextthrough parametrization, thereby transforming CSBO into an equivalent SBOproblem and eliminating the need for conditional sampling. Under reasonableassumptions on the context distribution and the regularity of the lower-level,we show that an $\epsilon$-stationary solution to CSBO can be achieved with anear-optimal sampling complexity $\tilde{O}(\epsilon^{-3})$. Our approachenhances the practicality of solving CSBO problems by improving bothcomputational efficiency and theoretical guarantees.</description>
      <author>example@mail.com (Maxime Bouscary, Jiawei Zhang, Saurabh Amin)</author>
      <guid isPermaLink="false">2503.19991v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
  <item>
      <title>Towards an Optimal Bound for the Interleaving Distance on Mapper Graphs</title>
      <link>http://arxiv.org/abs/2504.03865v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究Mapper图在拓扑数据分析和可视化中的应用，提出了一种计算Mapper图交错距离的新方法，并优化了损失函数，用于估计距离。&lt;h4&gt;背景&lt;/h4&gt;Mapper图是拓扑数据分析和可视化中常用的工具，可以视为Reeb图的离散近似，用于分析复杂数据的形状和连通性。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种计算Mapper图交错距离的方法，并优化相关损失函数，以提高距离估计的准确性。&lt;h4&gt;方法&lt;/h4&gt;采用Mapper图的范畴论表述，开发了一种计算损失函数的框架，将最佳分配问题转化为整数线性规划问题进行优化。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法可以成功匹配已知交错距离的小规模Mapper图，并在MPEG-7数据集上对图像进行了分类。&lt;h4&gt;结论&lt;/h4&gt;该方法为Mapper图距离估计提供了一种有效且实用的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Mapper图是拓扑数据分析与可视化的常用工具，可以视为Reeb图的离散近似，为复杂数据的形状和连通性提供了洞察。对于给定的具有函数f：X→R的高维点云X，mapper图提供了由f诱导的X拓扑结构的摘要，其中每个节点代表一个局部邻域，边连接对应邻域重叠的节点。本文关注的是mapper图的交错距离，它是Reeb图版本的离散化，计算复杂度为NP-hard。这种距离通过衡量它们必须“拉伸”到何种程度才能变得可比较来量化两个mapper图之间的相似性。最近的工作介绍了一个损失函数，为mapper图的交错距离提供了上界，该函数评估了给定分配距离真实交错的程度。找到损失是计算上可行的，提供了一种估计距离的实用方法。在本文中，我们采用mapper图的范畴论表述，并开发了计算相关损失函数的第一种框架。由于边界质量取决于选择的分配，我们将损失函数的优化问题表述为寻找最佳分配的整数线性规划问题。为了评估我们优化的有效性，我们将它应用于交错距离已知的小规模mapper图，证明优化后的上界在这些情况下成功地匹配了交错距离。此外，我们在MPEG-7数据集上进行了实验，计算了由图像派生的mapper图集合的成对最优损失，并利用距离边界进行图像分类。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mapper graphs are a widely used tool in topological data analysis andvisualization. They can be viewed as discrete approximations of Reeb graphs,offering insight into the shape and connectivity of complex data. Given ahigh-dimensional point cloud $\mathbb{X}$ equipped with a function $f:\mathbb{X} \to \mathbb{R}$, a mapper graph provides a summary of thetopological structure of $\mathbb{X}$ induced by $f$, where each noderepresents a local neighborhood, and edges connect nodes whose correspondingneighborhoods overlap. Our focus is the interleaving distance for mappergraphs, arising from a discretization of the version for Reeb graphs, which isNP-hard to compute. This distance quantifies the similarity between two mappergraphs by measuring the extent to which they must be ``stretched" to becomecomparable. Recent work introduced a loss function that provides an upper boundon the interleaving distance for mapper graphs, which evaluates how far a givenassignment is from being a true interleaving. Finding the loss iscomputationally tractable, offering a practical way to estimate the distance.  In this paper, we employ a categorical formulation of mapper graphs anddevelop the first framework for computing the associated loss function. Sincethe quality of the bound depends on the chosen assignment, we optimize thisloss function by formulating the problem of finding the best assignment as aninteger linear programming problem. To evaluate the effectiveness of ouroptimization, we apply it to small mapper graphs where the interleavingdistance is known, demonstrating that the optimized upper bound successfullymatches the interleaving distance in these cases. Additionally, we conduct anexperiment on the MPEG-7 dataset, computing the pairwise optimal loss on acollection of mapper graphs derived from images and leveraging the distancebound for image classification.</description>
      <author>example@mail.com (Erin Wolf Chambers, Ishika Ghosh, Elizabeth Munch, Sarah Percival, Bei Wang)</author>
      <guid isPermaLink="false">2504.03865v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>Modular Soft Wearable Glove for Real-Time Gesture Recognition and Dynamic 3D Shape Reconstruction</title>
      <link>http://arxiv.org/abs/2504.05983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于线状电极和液态金属（EGaIn）的柔性传感器，用于提高可穿戴手套在虚拟现实、医疗康复和工业自动化等领域的应用。该手套具有高灵敏度、模块化和柔韧性，能够准确识别手势和动态重建手部形态。&lt;h4&gt;背景&lt;/h4&gt;随着人机交互（HCI）需求的增加，柔性可穿戴手套在虚拟现实、医疗康复和工业自动化等领域具有巨大潜力。然而，当前技术存在灵敏度不足和耐用性有限等问题，限制了其广泛应用。&lt;h4&gt;目的&lt;/h4&gt;开发一种高灵敏度、模块化和柔韧的可穿戴手套，以解决当前技术中的不足，提高其在各种应用中的性能。&lt;h4&gt;方法&lt;/h4&gt;设计了一种基于线状电极和液态金属的柔性电容传感器，并将其集成到一个适合人手解剖结构的传感器模块中。该系统能够独立捕获每个手指关节的弯曲信息，并记录相邻手指之间的微妙变化，从而实现准确的手势识别和动态手部形态重建。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，基于卷积神经网络（CNN）和多层感知器（MLP）的分类器在30种手势上实现了99.15%的准确率。同时，基于Transformer的深度神经网络（DNN）以平均距离（AD）2.076±3.231毫米的精度准确重建动态手部形状，关键点的重建准确率超过SOTA基准9.7%至64.9%。&lt;h4&gt;结论&lt;/h4&gt;该手套在手势识别和手部重建方面表现出色，具有高准确性、鲁棒性和可扩展性，是下一代人机交互系统的有前途解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着人机交互需求的增加，柔性可穿戴手套在虚拟现实、医疗康复和工业自动化等领域已成为一种有希望的解决方案。然而，现有技术仍然存在灵敏度不足和耐用性有限等问题，这阻碍了其广泛应用。本文提出了一种基于线状电极和液态金属（EGaIn）的具有高灵敏度、模块化和柔性的电容传感器，并将其集成到一个适合人手解剖结构的传感器模块中。该系统独立地捕获每个手指关节的弯曲信息，而相邻手指之间的额外测量则能够记录手指间距的微妙变化。这种设计实现了使用点云准确识别手势和动态重建复杂运动的动态手部形态。实验结果表明，我们的基于卷积神经网络（CNN）和多层感知器（MLP）的分类器在30种手势上实现了99.15%的准确率。同时，基于Transformer的深度神经网络（DNN）以平均距离（AD）2.076±3.231毫米的精度准确重建动态手部形状，关键点的重建准确率超过SOTA基准9.7%至64.9%。该手套在手势识别和手部重建方面表现出色，具有高准确性、鲁棒性和可扩展性，是下一代人机交互系统的有前途解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the increasing demand for human-computer interaction (HCI), flexiblewearable gloves have emerged as a promising solution in virtual reality,medical rehabilitation, and industrial automation. However, the currenttechnology still has problems like insufficient sensitivity and limiteddurability, which hinder its wide application. This paper presents a highlysensitive, modular, and flexible capacitive sensor based on line-shapedelectrodes and liquid metal (EGaIn), integrated into a sensor module tailoredto the human hand's anatomy. The proposed system independently captures bendinginformation from each finger joint, while additional measurements betweenadjacent fingers enable the recording of subtle variations in inter-fingerspacing. This design enables accurate gesture recognition and dynamic handmorphological reconstruction of complex movements using point clouds.Experimental results demonstrate that our classifier based on ConvolutionNeural Network (CNN) and Multilayer Perceptron (MLP) achieves an accuracy of99.15% across 30 gestures. Meanwhile, a transformer-based Deep Neural Network(DNN) accurately reconstructs dynamic hand shapes with an Average Distance (AD)of 2.076\pm3.231 mm, with the reconstruction accuracy at individual key pointssurpassing SOTA benchmarks by 9.7% to 64.9%. The proposed glove shows excellentaccuracy, robustness and scalability in gesture recognition and handreconstruction, making it a promising solution for next-generation HCI systems.</description>
      <author>example@mail.com (Huazhi Dong, Chunpeng Wang, Mingyuan Jiang, Francesco Giorgio-Serchi, Yunjie Yang)</author>
      <guid isPermaLink="false">2504.05983v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>Turin3D: Evaluating Adaptation Strategies under Label Scarcity in Urban LiDAR Segmentation with Semi-Supervised Techniques</title>
      <link>http://arxiv.org/abs/2504.05882v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPRW2025 - USM3D&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Turin3D，一个用于点云语义分割的新的空中激光雷达数据集，并在都灵市中心区域进行了数据收集和比较。&lt;h4&gt;背景&lt;/h4&gt;3D语义分割在都市建模中扮演着关键角色，它能够使我们对城市环境有更深入的理解和映射。&lt;h4&gt;目的&lt;/h4&gt;提出Turin3D数据集，并评估其性能，同时通过半监督学习方法提高点云语义分割模型的性能。&lt;h4&gt;方法&lt;/h4&gt;数据收集过程被描述，并与文献中提出的其他数据集进行了比较。数据集的验证和测试集进行了手动标注，以确保技术评估的可靠性。&lt;h4&gt;主要发现&lt;/h4&gt;对多个点云语义分割模型在Turin3D数据集上的性能进行了基准测试，并应用半监督学习技术提高了它们的性能。&lt;h4&gt;结论&lt;/h4&gt;该数据集将公开发布，以支持户外点云分割的研究，特别是对于无地面真实标注的监督学习和半监督学习方法具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D semantic segmentation plays a critical role in urban modelling, enablingdetailed understanding and mapping of city environments. In this paper, weintroduce Turin3D: a new aerial LiDAR dataset for point cloud semanticsegmentation covering an area of around 1.43 km2 in the city centre of Turinwith almost 70M points. We describe the data collection process and compareTurin3D with others previously proposed in the literature. We did not fullyannotate the dataset due to the complexity and time-consuming nature of theprocess; however, a manual annotation process was performed on the validationand test sets, to enable a reliable evaluation of the proposed techniques. Wefirst benchmark the performances of several point cloud semantic segmentationmodels, trained on the existing datasets, when tested on Turin3D, and thenimprove their performances by applying a semi-supervised learning techniqueleveraging the unlabelled training set. The dataset will be publicly availableto support research in outdoor point cloud segmentation, with particularrelevance for self-supervised and semi-supervised learning approaches given theabsence of ground truth annotations for the training set.</description>
      <author>example@mail.com (Luca Barco, Giacomo Blanco, Gaetano Chiriaco, Alessia Intini, Luigi La Riccia, Vittorio Scolamiero, Piero Boccardo, Paolo Garza, Fabrizio Dominici)</author>
      <guid isPermaLink="false">2504.05882v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models</title>
      <link>http://arxiv.org/abs/2504.06214v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种高效训练方法，用于构建超长上下文语言模型，并分析了相关设计选择的影响。&lt;h4&gt;背景&lt;/h4&gt;长上下文能力对于文档和视频理解、情境学习和推理时间扩展等应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;目的是通过构建超长上下文语言模型，扩展上下文长度，并保持模型的指令遵循和推理能力。&lt;h4&gt;方法&lt;/h4&gt;方法包括利用高效的持续预训练策略来扩展上下文窗口，并采用有效的指令调整来维持指令遵循和推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;UltraLong-8B模型在多个长上下文基准测试中实现了最先进的性能，同时在标准基准测试中也保持了竞争力。&lt;h4&gt;结论&lt;/h4&gt;研究建立了一个稳健的框架，能够高效地扩展上下文长度，同时保持模型的通用能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：长上下文能力对于包括文档和视频理解、情境学习和推理时间扩展在内的广泛应用至关重要，这些应用都需要模型处理和推理长序列的文本和多模态数据。在本研究中，我们介绍了一种高效训练方法，用于从对齐指令模型构建超长上下文LLMs，将上下文长度的边界从128K推至1M、2M和4M个标记。我们的方法利用高效的持续预训练策略来扩展上下文窗口，并采用有效的指令调整来维持指令遵循和推理能力。基于Llama3.1-Instruct并使用我们的方法构建的UltraLong-8B在多个长上下文基准测试中实现了最先进的性能。重要的是，使用我们的方法训练的模型在标准基准测试中也保持了竞争力，这表明对于长上下文和短上下文任务都有平衡的改进。我们进一步对关键设计选择进行了深入分析，强调了扩展策略和数据组成的影响。我们的发现建立了一个稳健的框架，能够在保持通用模型能力的同时高效地扩展上下文长度。我们发布了所有模型权重：https://ultralong.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-context capabilities are essential for a wide range of applications,including document and video understanding, in-context learning, andinference-time scaling, all of which require models to process and reason overlong sequences of text and multimodal data. In this work, we introduce aefficient training recipe for building ultra-long context LLMs from alignedinstruct model, pushing the boundaries of context lengths from 128K to 1M, 2M,and 4M tokens. Our approach leverages efficient continued pretrainingstrategies to extend the context window and employs effective instructiontuning to maintain the instruction-following and reasoning abilities. OurUltraLong-8B, built on Llama3.1-Instruct with our recipe, achievesstate-of-the-art performance across a diverse set of long-context benchmarks.Importantly, models trained with our approach maintain competitive performanceon standard benchmarks, demonstrating balanced improvements for both long andshort context tasks. We further provide an in-depth analysis of key designchoices, highlighting the impacts of scaling strategies and data composition.Our findings establish a robust framework for efficiently scaling contextlengths while preserving general model capabilities. We release all modelweights at: https://ultralong.github.io/.</description>
      <author>example@mail.com (Chejian Xu, Wei Ping, Peng Xu, Zihan Liu, Boxin Wang, Mohammad Shoeybi, Bo Li, Bryan Catanzaro)</author>
      <guid isPermaLink="false">2504.06214v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>A Self-Supervised Framework for Space Object Behaviour Characterisation</title>
      <link>http://arxiv.org/abs/2504.06176v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对太空物体行为分析的太空安全与可持续性基础模型，利用光曲线（LCs）进行行为分析，并通过自监督学习和迁移学习提高了异常检测和运动预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;随着轨道物体数量的增加，自动化方法对太空物体行为的特征分析对于太空安全至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够进行异常检测、运动预测和光曲线生成的太空物体行为分析模型。&lt;h4&gt;方法&lt;/h4&gt;使用光曲线（LCs）进行预训练，并采用Perceiver-Variational Autoencoder（VAE）架构，通过自监督和掩码重建进行预训练，然后使用独立的光曲线模拟器进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;预训练模型在重建误差为0.01%的情况下识别出可能异常的光曲线。微调后，模型在异常检测和运动模式预测（如太阳对准、自旋等）中分别达到了88%和82%的准确率，ROC AUC分数分别为0.90和0.95。对高置信度异常预测的分析揭示了包括特征物体轮廓和卫星反光在内的明显模式。&lt;h4&gt;结论&lt;/h4&gt;该研究通过自监督学习实现了异常检测、运动预测和合成数据生成，支持太空安全与可持续性，通过自动化监控和模拟能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在大量未标记数据集上预训练并在特定任务上进行微调的基础模型越来越多地应用于专业领域。最近的例子包括用于气候的ClimaX和用于卫星地球观测的Clay，但尚未开发用于太空物体行为分析的基础模型。随着轨道物体数量的增加，自动化方法对太空物体行为的特征分析对于太空安全至关重要。我们提出了一种专注于使用光曲线（LCs）进行太空物体行为分析的太空安全与可持续性基础模型。我们实现了一个Perceiver-Variational Autoencoder（VAE）架构，使用来自MMT-9天文台的227,000个LCs进行自监督重建和掩码重建进行预训练。VAE能够进行异常检测、运动预测和LC生成。我们使用两个独立的光曲线模拟器（CASSANDRA和GRIAL）对模型进行了微调，以进行异常检测和运动预测，使用了箱形机翼、Sentinel-3、SMOS和Starlink平台的CAD模型。我们的预训练模型在重建误差为0.01%的情况下识别出可能异常的光曲线。微调后，模型在异常检测和运动模式预测（如太阳对准、自旋等）中分别达到了88%和82%的准确率，ROC AUC分数分别为0.90和0.95。对真实数据中高置信度异常预测的分析揭示了包括特征物体轮廓和卫星反光在内的明显模式。在这里，我们展示了如何通过自监督学习同时实现从预训练中学习到的丰富表示的异常检测、运动预测和合成数据生成。因此，我们的工作通过自动化监控和模拟能力支持太空安全与可持续性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation Models, pre-trained on large unlabelled datasets beforetask-specific fine-tuning, are increasingly being applied to specialiseddomains. Recent examples include ClimaX for climate and Clay for satelliteEarth observation, but a Foundation Model for Space Object Behavioural Analysishas not yet been developed. As orbital populations grow, automated methods forcharacterising space object behaviour are crucial for space safety. We presenta Space Safety and Sustainability Foundation Model focusing on space objectbehavioural analysis using light curves (LCs). We implemented aPerceiver-Variational Autoencoder (VAE) architecture, pre-trained withself-supervised reconstruction and masked reconstruction on 227,000 LCs fromthe MMT-9 observatory. The VAE enables anomaly detection, motion prediction,and LC generation. We fine-tuned the model for anomaly detection &amp; motionprediction using two independent LC simulators (CASSANDRA and GRIALrespectively), using CAD models of boxwing, Sentinel-3, SMOS, and Starlinkplatforms. Our pre-trained model achieved a reconstruction error of 0.01%,identifying potentially anomalous light curves through reconstructiondifficulty. After fine-tuning, the model scored 88% and 82% accuracy, with 0.90and 0.95 ROC AUC scores respectively in both anomaly detection and motion modeprediction (sun-pointing, spin, etc.). Analysis of high-confidence anomalypredictions on real data revealed distinct patterns including characteristicobject profiles and satellite glinting. Here, we demonstrate howself-supervised learning can simultaneously enable anomaly detection, motionprediction, and synthetic data generation from rich representations learned inpre-training. Our work therefore supports space safety and sustainabilitythrough automated monitoring and simulation capabilities.</description>
      <author>example@mail.com (Ian Groves, Andrew Campbell, James Fernandes, Diego Rodriguez, Paul Murray, Massimiliano Vasile, Victoria Nockles)</author>
      <guid isPermaLink="false">2504.06176v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning through Bayesian Optimization</title>
      <link>http://arxiv.org/abs/2504.06265v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的架构，将LLM微调重构成通过深度核方法优化的高斯过程边缘似然。该方法结合了LLM和GPs的优点，应用于Buchwald-Hartwig反应优化，显著提高了反应发现率。实验结果表明，该方法在多个任务和不同参数设置下均表现出鲁棒性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;尽管大型语言模型（LLMs）可以编码复杂的潜在空间关系，但在不确定条件下的优化仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;填补这一空白，提出一种新的方法，将LLM微调作为高斯过程边缘似然优化的一种形式。&lt;h4&gt;方法&lt;/h4&gt;引入基于LLM的深度核，与GPs联合优化，以利用LLMs丰富的输入空间和GPs的预测不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在Buchwald-Hartwig反应优化中提高了反应发现率，同时在多个基准测试中表现出鲁棒性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该方法通过边缘似然优化实现LLM和GPs的联合优化，无需外部损失，提高了样本效率优化并揭示了有效贝叶斯优化的关键因素。&lt;h4&gt;翻译&lt;/h4&gt;Large Language Models (LLMs) can encode complex relationships in their latentspaces, yet harnessing them for optimization under uncertainty remainschallenging. We address this gap with a novel architecture that reframes LLMfinetuning as Gaussian process (GP) marginal likelihood optimization via deepkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPsto preserve the benefits of both - LLMs to provide a rich and flexible inputspace for Bayesian optimization and - GPs to model this space with predictiveuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reactionoptimization, our method nearly doubles the discovery rate of high-performingreactions compared to static LLM embeddings (from 24% to 43% coverage of thetop 5% reactions in just 50 optimization iterations). We also observe a 14%improvement over domain-specific representations without requiring specializedfeatures. Extensive empirical evaluation across 19 benchmarks - ranging fromgeneral chemistry to reaction and molecular property optimization -demonstrates our method's robustness, generality, and consistent improvementsacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),(3) pretraining domains (chemistry-related or general-purpose) and (4)hyperparameter settings (tuned once on a single dataset). Finally, we explainthese improvements: joint LLM-GP optimization through marginal likelihoodimplicitly performs contrastive learning, aligning representations to produce(1) better-structured embedding spaces, (2) improved uncertainty calibration,and (3) more efficient sampling - without requiring any external loss. Thiswork provides both practical advances in sample-efficient optimization andinsights into what makes effective Bayesian optimization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) can encode complex relationships in their latentspaces, yet harnessing them for optimization under uncertainty remainschallenging. We address this gap with a novel architecture that reframes LLMfinetuning as Gaussian process (GP) marginal likelihood optimization via deepkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPsto preserve the benefits of both - LLMs to provide a rich and flexible inputspace for Bayesian optimization and - GPs to model this space with predictiveuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reactionoptimization, our method nearly doubles the discovery rate of high-performingreactions compared to static LLM embeddings (from 24% to 43% coverage of thetop 5% reactions in just 50 optimization iterations). We also observe a 14%improvement over domain-specific representations without requiring specializedfeatures. Extensive empirical evaluation across 19 benchmarks - ranging fromgeneral chemistry to reaction and molecular property optimization -demonstrates our method's robustness, generality, and consistent improvementsacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),(3) pretraining domains (chemistry-related or general-purpose) and (4)hyperparameter settings (tuned once on a single dataset). Finally, we explainthese improvements: joint LLM-GP optimization through marginal likelihoodimplicitly performs contrastive learning, aligning representations to produce(1) better-structured embedding spaces, (2) improved uncertainty calibration,and (3) more efficient sampling - without requiring any external loss. Thiswork provides both practical advances in sample-efficient optimization andinsights into what makes effective Bayesian optimization.</description>
      <author>example@mail.com (Bojana Ranković, Philippe Schwaller)</author>
      <guid isPermaLink="false">2504.06265v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>PRIMEDrive-CoT: A Precognitive Chain-of-Thought Framework for Uncertainty-Aware Object Interaction in Driving Scene Scenario</title>
      <link>http://arxiv.org/abs/2504.05908v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at The IEEE/CVF Conference on Computer Vision and Pattern  Recognition 2025 - CVPRW&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PRIMEDrive-CoT的新型不确定性感知模型，用于解决驾驶场景中的物体交互和思维链（CoT）推理问题。&lt;h4&gt;背景&lt;/h4&gt;驾驶场景理解是一个涉及解释和关联驾驶环境中各种元素（如车辆、行人和交通信号）的关键现实问题。&lt;h4&gt;目的&lt;/h4&gt;针对现实世界中驾驶的不确定性和内在不确定性，提出一种能够处理不确定条件下的概率推理的方法。&lt;h4&gt;方法&lt;/h4&gt;结合基于LiDAR的3D物体检测和多视角RGB参考，使用贝叶斯图神经网络（BGNNs）对不确定条件下的物体交互和风险进行建模。通过CoT推理，利用物体动态和上下文线索，实现可解释的决策，并通过Grad-CAM可视化突出关注区域。&lt;h4&gt;主要发现&lt;/h4&gt;在DriveCoT数据集上的广泛评估表明，PRIMEDrive-CoT优于现有的CoT和风险感知模型。&lt;h4&gt;结论&lt;/h4&gt;PRIMEDrive-CoT模型在驾驶场景理解方面具有显著优势，能够提供可靠和可解释的驾驶场景理解。&lt;h4&gt;翻译&lt;/h4&gt;驾驶场景理解是涉及解释和关联驾驶环境中各种元素（如车辆、行人和交通信号）的关键现实问题。尽管自动驾驶技术取得了进展，但传统的管道仍然依赖于确定性的模型，这些模型无法捕捉现实世界中驾驶的概率性质和固有不确定性。为了解决这个问题，我们提出了PRIMEDrive-CoT，这是一种新的不确定性感知模型，用于驾驶场景中的物体交互和思维链（CoT）推理。特别是，我们的方法结合了基于LiDAR的3D物体检测和多视角RGB参考，以确保可解释和可靠的场景理解。使用贝叶斯图神经网络（BGNNs）对物体交互和风险进行建模，以在不确定条件下进行概率推理。通过CoT推理，利用物体动态和上下文线索，促进可解释的决策，同时Grad-CAM可视化突出了关注区域。在DriveCoT数据集上的广泛评估表明，PRIMEDrive-CoT优于现有的CoT和风险感知模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Driving scene understanding is a critical real-world problem that involvesinterpreting and associating various elements of a driving environment, such asvehicles, pedestrians, and traffic signals. Despite advancements in autonomousdriving, traditional pipelines rely on deterministic models that fail tocapture the probabilistic nature and inherent uncertainty of real-worlddriving. To address this, we propose PRIMEDrive-CoT, a novel uncertainty-awaremodel for object interaction and Chain-of-Thought (CoT) reasoning in drivingscenarios. In particular, our approach combines LiDAR-based 3D object detectionwith multi-view RGB references to ensure interpretable and reliable sceneunderstanding. Uncertainty and risk assessment, along with object interactions,are modelled using Bayesian Graph Neural Networks (BGNNs) for probabilisticreasoning under ambiguous conditions. Interpretable decisions are facilitatedthrough CoT reasoning, leveraging object dynamics and contextual cues, whileGrad-CAM visualizations highlight attention regions. Extensive evaluations onthe DriveCoT dataset demonstrate that PRIMEDrive-CoT outperformsstate-of-the-art CoT and risk-aware models.</description>
      <author>example@mail.com (Sriram Mandalika, Lalitha V, Athira Nambiar)</author>
      <guid isPermaLink="false">2504.05908v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>Orb-v3: atomistic simulation at scale</title>
      <link>http://arxiv.org/abs/2504.06231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Orb-v3，这是Orb系列通用原子势能的下一代模型。该模型在性能、速度和内存使用上取得了显著进步，在多种评估中接近当前最先进的技术水平，同时将延迟降低了10倍以上，内存降低了8倍以上。&lt;h4&gt;背景&lt;/h4&gt;Orb系列模型在性能、速度和内存使用之间寻求平衡，旨在提高原子模拟的效率。&lt;h4&gt;目的&lt;/h4&gt;开发Orb-v3模型，以在准确性、延迟和系统规模可扩展性上实现卓越性能，推动计算化学的新时代。&lt;h4&gt;方法&lt;/h4&gt;通过实验系统地跨越性能、速度和内存使用之间的平衡点，分析旋转等变、保守性和图稀疏性带来的权衡。&lt;h4&gt;主要发现&lt;/h4&gt;与现有文献相反，发现非等变和非保守架构可以准确地模拟物理性质，包括需要势能面高阶导数的性质。&lt;h4&gt;结论&lt;/h4&gt;Orb-v3模型将推动计算化学进入一个新时代，该时代由高通量和中等规模的原子模拟驱动。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了Orb-v3，这是Orb系列通用原子势能的下一代。这个系列的模型在性能-速度-内存的帕累托前沿上取得了进展，在各种评估中提供了接近最先进技术水平的性能，同时将延迟降低了10倍以上，内存降低了8倍以上。我们的实验系统地穿越了这个前沿，描绘了由旋转等变、保守性和图稀疏性引起的权衡。与近期文献相反，我们发现非等变和非保守架构可以准确地模拟物理性质，包括那些需要势能面高阶导数的性质。这次模型发布遵循的原则是最有价值的原子模拟基础模型将在所有方面（准确性、延迟和系统规模可扩展性）表现出色。这样做的好处是推动计算化学进入一个新时代，该时代由高通量和中等规模的原子模拟驱动。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Orb-v3, the next generation of the Orb family of universalinteratomic potentials. Models in this family expand theperformance-speed-memory Pareto frontier, offering near SoTA performance acrossa range of evaluations with a &gt;10x reduction in latency and &gt; 8x reduction inmemory. Our experiments systematically traverse this frontier, charting thetrade-off induced by roto-equivariance, conservatism and graph sparsity.Contrary to recent literature, we find that non-equivariant, non-conservativearchitectures can accurately model physical properties, including those whichrequire higher-order derivatives of the potential energy surface.  This model release is guided by the principle that the most valuablefoundation models for atomic simulation will excel on all fronts: accuracy,latency and system size scalability. The reward for doing so is a new era ofcomputational chemistry driven by high-throughput and mesoscale all-atomsimulations.</description>
      <author>example@mail.com (Benjamin Rhodes, Sander Vandenhaute, Vaidotas Šimkus, James Gin, Jonathan Godwin, Tim Duignan, Mark Neumann)</author>
      <guid isPermaLink="false">2504.06231v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>UVG-VPC: Voxelized Point Cloud Dataset for Visual Volumetric Video-based Coding</title>
      <link>http://arxiv.org/abs/2504.05888v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Point cloud compression;Geometry;Visualization;Three-dimensional  displays;Video sequences;Transform coding;Media;Open dataset;point  cloud;Visual Volumetric Video-based Coding (V3C);Video-based Point Cloud  Compression (V-PCC);Extended Reality (XR)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的开放数据集UVG-VPC，用于开发、评估和验证MPEG视觉体积视频编码（V3C）技术。&lt;h4&gt;背景&lt;/h4&gt;点云压缩在沉浸式视觉媒体处理和流媒体中变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;发布UVG-VPC数据集的主要目的是促进V3C技术的发展，从而塑造该领域的未来。&lt;h4&gt;方法&lt;/h4&gt;数据集包含12个具有不同运动、RGB纹理、3D几何和点表面遮挡特性的点云测试视频序列。每个序列长度为10秒，包含250帧，每秒25帧。序列以9到12位的几何精度体素化，体素颜色属性以8位RGB值表示。数据集还包括相关的法线，使其更适合评估点云压缩解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;UVG-VPC数据集包括不同特性的点云测试视频序列，适用于评估点云压缩解决方案。&lt;h4&gt;结论&lt;/h4&gt;UVG-VPC数据集的发布将促进V3C技术的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：点云压缩已成为沉浸式视觉媒体处理和流媒体的关键因素。本文提出一个新的开放数据集UVG-VPC，用于开发、评估和验证MPEG视觉体积视频编码（V3C）技术。该数据集在其自身的非商业许可下分发。它包含12个具有不同运动、RGB纹理、3D几何和点表面遮挡特性的点云测试视频序列。每个序列长度为10秒，包含250帧，每秒25帧。序列以9到12位的几何精度体素化，体素颜色属性以8位RGB值表示。数据集还包括相关的法线，使其更适合评估点云压缩解决方案。发布UVG-VPC数据集的主要目的是促进V3C技术的发展，从而塑造该领域的未来。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/QoMEX58391.2023.10178589&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud compression has become a crucial factor in immersive visual mediaprocessing and streaming. This paper presents a new open dataset called UVG-VPCfor the development, evaluation, and validation of MPEG Visual VolumetricVideo-based Coding (V3C) technology. The dataset is distributed under its ownnon-commercial license. It consists of 12 point cloud test video sequences ofdiverse characteristics with respect to the motion, RGB texture, 3D geometry,and surface occlusion of the points. Each sequence is 10 seconds long andcomprises 250 frames captured at 25 frames per second. The sequences arevoxelized with a geometry precision of 9 to 12 bits, and the voxel colorattributes are represented as 8-bit RGB values. The dataset also includesassociated normals that make it more suitable for evaluating point cloudcompression solutions. The main objective of releasing the UVG-VPC dataset isto foster the development of V3C technologies and thereby shape the future inthis field.</description>
      <author>example@mail.com (Guillaume Gautier, Alexandre Mercat, Louis Fréneau, Mikko Pitkänen, Jarno Vanne)</author>
      <guid isPermaLink="false">2504.05888v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>Heuristic Methods are Good Teachers to Distill MLPs for Graph Link Prediction</title>
      <link>http://arxiv.org/abs/2504.06193v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为EHDM（Ensemble Heuristic-Distilled MLPs）的链接预测方法，通过结合不同的教师模型和门控机制，实现了高效的链接预测。&lt;h4&gt;背景&lt;/h4&gt;链接预测是图学习中的一个关键任务，广泛应用于文献预测和产品推荐等领域。通过将图神经网络（GNN）教师模型蒸馏为多层感知器（MLP）学生模型，可以降低计算成本并提高性能。&lt;h4&gt;目的&lt;/h4&gt;研究不同教师模型对GNN到MLP蒸馏的影响，并提出一种有效的链接预测方法。&lt;h4&gt;方法&lt;/h4&gt;探索了不同教师模型（包括标准GNN、GNN4LP和启发式方法）在GNN到MLP蒸馏中的影响。提出了一种名为EHDM的方法，通过门控机制消除图依赖，并有效地整合互补信号。&lt;h4&gt;主要发现&lt;/h4&gt;发现更强的教师模型并不总是产生更强的学生模型；MLP从GNN4LP蒸馏出来的可能表现不如从更简单的GNN蒸馏出来的，而较弱的启发式方法可以教会MLP接近GNN的性能，同时显著降低训练成本。&lt;h4&gt;结论&lt;/h4&gt;EHDM方法在十个数据集上展示了平均7.93%的性能提升，并且训练时间比之前的GNN到MLP方法减少了1.95-3.32倍，证明了EHDM是一种高效且有效的链接预测方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：链接预测是图学习中的一个关键任务，其应用包括文献预测和产品推荐。将图神经网络（GNN）教师模型蒸馏为多层感知器（MLP）学生模型已证明是一种有效的方法，通过去除图依赖来降低计算成本并提高性能。然而，现有的蒸馏方法仅使用标准的GNN，忽略了其他教师模型，如用于链接预测的专用模型（GNN4LP）和启发式方法（例如共同邻居）。本文首先探讨了不同教师模型在GNN到MLP蒸馏中的影响。令人惊讶的是，我们发现更强的教师模型并不总是产生更强的学生模型：从GNN4LP蒸馏出来的MLP可能表现不如从更简单的GNN蒸馏出来的，而较弱的启发式方法可以教会MLP接近GNN的性能，同时显著降低训练成本。基于这些见解，我们提出了集成启发式蒸馏MLP（EHDM），它通过门控机制消除图依赖，并有效地整合互补信号。在十个数据集上的实验表明，与之前的GNN到MLP方法相比，EHDM的平均性能提升了7.93%，训练时间减少了1.95-3.32倍，表明EHDM是一种高效且有效的链接预测方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction is a crucial graph-learning task with applications includingcitation prediction and product recommendation. Distilling Graph NeuralNetworks (GNNs) teachers into Multi-Layer Perceptrons (MLPs) students hasemerged as an effective approach to achieve strong performance and reducingcomputational cost by removing graph dependency. However, existing distillationmethods only use standard GNNs and overlook alternative teachers such asspecialized model for link prediction (GNN4LP) and heuristic methods (e.g.,common neighbors). This paper first explores the impact of different teachersin GNN-to-MLP distillation. Surprisingly, we find that stronger teachers do notalways produce stronger students: MLPs distilled from GNN4LP can underperformthose distilled from simpler GNNs, while weaker heuristic methods can teachMLPs to near-GNN performance with drastically reduced training costs. Buildingon these insights, we propose Ensemble Heuristic-Distilled MLPs (EHDM), whicheliminates graph dependencies while effectively integrating complementarysignals via a gating mechanism. Experiments on ten datasets show an average7.93% improvement over previous GNN-to-MLP approaches with 1.95-3.32 times lesstraining time, indicating EHDM is an efficient and effective link predictionmethod.</description>
      <author>example@mail.com (Zongyue Qin, Shichang Zhang, Mingxuan Ju, Tong Zhao, Neil Shah, Yizhou Sun)</author>
      <guid isPermaLink="false">2504.06193v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:17 +0800</pubDate>
    </item>
    <item>
      <title>High-Resource Translation:Turning Abundance into Accessibility</title>
      <link>http://arxiv.org/abs/2504.05914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用迁移学习技术构建英泰卢语翻译模型的新方法，通过解决低资源语言的相关挑战，有效提升了模型翻译能力。&lt;h4&gt;背景&lt;/h4&gt;针对低资源语言翻译的挑战，本文研究了一种新的翻译模型构建方法。&lt;h4&gt;目的&lt;/h4&gt;旨在创建一个能够处理英语和泰卢语中多样化句子结构和语言细微差异的鲁棒翻译系统。&lt;h4&gt;方法&lt;/h4&gt;使用Bharat平行语料库（BPCC）作为主要数据集，通过迭代反向翻译生成合成平行数据，增强训练数据集，并优化训练参数以及有效使用预训练模型。&lt;h4&gt;主要发现&lt;/h4&gt;研究强调了创新数据处理技术的意义以及迁移学习在克服低资源语言数据稀疏性限制方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;该研究对机器翻译领域做出了贡献，并旨在改善英语和泰卢语使用者之间的实际沟通。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于迁移学习的英泰卢语翻译模型构建方法，通过使用BPCC数据集、迭代反向翻译以及优化训练参数等技术，提高了模型的翻译能力，并有助于改善英语和泰卢语使用者之间的沟通。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel approach to constructing an English-to-Telugutranslation model by leveraging transfer learning techniques and addressing thechallenges associated with low-resource languages. Utilizing the BharatParallel Corpus Collection (BPCC) as the primary dataset, the modelincorporates iterative backtranslation to generate synthetic parallel data,effectively augmenting the training dataset and enhancing the model'stranslation capabilities. The research focuses on a comprehensive strategy forimproving model performance through data augmentation, optimization of trainingparameters, and the effective use of pre-trained models. These methodologiesaim to create a robust translation system that can handle diverse sentencestructures and linguistic nuances in both English and Telugu. This workhighlights the significance of innovative data handling techniques and thepotential of transfer learning in overcoming limitations posed by sparsedatasets in low-resource languages. The study contributes to the field ofmachine translation and seeks to improve communication between English andTelugu speakers in practical contexts.</description>
      <author>example@mail.com (Abhiram Reddy Yanampally)</author>
      <guid isPermaLink="false">2504.05914v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Video Flow as Time Series: Discovering Temporal Consistency and Variability for VideoQA</title>
      <link>http://arxiv.org/abs/2504.05783v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Temporal Trio Transformer（T3T）的新型架构，用于视频问答任务，旨在通过建模时间一致性和时间变异性来提高视频问答的准确性和深度。&lt;h4&gt;背景&lt;/h4&gt;视频问答是一个复杂的视频语言任务，需要深入理解视觉内容和时间动态。传统的Transformer架构在整合多模态数据方面有效，但往往通过位置编码简化时间动态，未能捕捉视频序列中的非线性交互。&lt;h4&gt;目的&lt;/h4&gt;提出T3T架构，以改善视频问答的准确性和深度。&lt;h4&gt;方法&lt;/h4&gt;T3T包含三个关键组件：时间平滑（TS）、时间差异（TD）和时间融合（TF）。TS模块使用布朗桥捕捉平滑的连续时间过渡，TD模块识别和编码视频内容中的显著时间变化和突变，TF模块将时间特征与文本线索融合，以促进更深层次的理解和回答准确性。&lt;h4&gt;主要发现&lt;/h4&gt;T3T在多个视频问答基准数据集上的广泛测试中证明了其有效性，突出了对时间建模的细致方法对于提高视频问答准确性和深度的重要性。&lt;h4&gt;结论&lt;/h4&gt;T3T架构通过建模时间动态，为视频问答任务提供了更准确的答案，并强调了在视频问答中采用细致时间建模方法的重要性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视频问答（VideoQA）是一个复杂的视频语言任务，需要深入理解视觉内容和时间动态。传统的Transformer风格架构，虽然有效于整合多模态数据，但通常通过位置编码简化时间动态，未能捕捉视频序列中的非线性交互。在本文中，我们引入了时间三重奏Transformer（T3T），这是一种新型架构，用于建模时间一致性和时间变异性。T3T集成了三个关键组件：时间平滑（TS）、时间差异（TD）和时间融合（TF）。TS模块使用布朗桥捕捉平滑、连续的时间过渡，TD模块识别和编码视频内容中的显著时间变化和突变。随后，TF模块将这些时间特征与文本线索融合，促进更深层次的理解和回答准确性。通过在多个视频问答基准数据集上的广泛测试，T3T的有效性得到了证明。我们的结果强调了在提高视频问答的准确性和深度方面，对时间建模的细致方法的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Question Answering (VideoQA) is a complex video-language task thatdemands a sophisticated understanding of both visual content and temporaldynamics. Traditional Transformer-style architectures, while effective inintegrating multimodal data, often simplify temporal dynamics throughpositional encoding and fail to capture non-linear interactions within videosequences. In this paper, we introduce the Temporal Trio Transformer (T3T), anovel architecture that models time consistency and time variability. The T3Tintegrates three key components: Temporal Smoothing (TS), Temporal Difference(TD), and Temporal Fusion (TF). The TS module employs Brownian Bridge forcapturing smooth, continuous temporal transitions, while the TD moduleidentifies and encodes significant temporal variations and abrupt changeswithin the video content. Subsequently, the TF module synthesizes thesetemporal features with textual cues, facilitating a deeper contextualunderstanding and response accuracy. The efficacy of the T3T is demonstratedthrough extensive testing on multiple VideoQA benchmark datasets. Our resultsunderscore the importance of a nuanced approach to temporal modeling inimproving the accuracy and depth of video-based question answering.</description>
      <author>example@mail.com (Zijie Song, Zhenzhen Hu, Yixiao Ma, Jia Li, Richang Hong)</author>
      <guid isPermaLink="false">2504.05783v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>POD: Predictive Object Detection with Single-Frame FMCW LiDAR Point Cloud</title>
      <link>http://arxiv.org/abs/2504.05649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于FMCW LiDAR的3D物体检测在自动驾驶感知中的独特优势，提出了一种预测物体检测（POD）框架，以实现快速响应潜在危险。&lt;h4&gt;背景&lt;/h4&gt;LiDAR-based 3D object detection是自动驾驶领域的基本任务。&lt;h4&gt;目的&lt;/h4&gt;利用单帧FMCW点云数据，实现物体的短期未来位置和尺寸的预测。&lt;h4&gt;方法&lt;/h4&gt;将标准物体检测任务扩展为预测物体检测（POD），通过射线投射机制生成虚拟未来点，创建虚拟两帧点云，并使用稀疏4D编码器编码特征，最后将4D体素特征分离并重映射为两个鸟瞰图（BEV）特征。&lt;h4&gt;主要发现&lt;/h4&gt;FMCW LiDAR的核心优势在于与每个反射点相关的径向速度，避免使用多帧历史信息，实现更快的响应时间。&lt;h4&gt;结论&lt;/h4&gt;在内部数据集上的实验表明，所提出的POD框架在标准检测和预测检测方面均达到最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper explores the unique advantage of FrequencyModulated Continuous Wave (FMCW) LiDAR in autonomous perception. Given a singleframe FMCW point cloud with radial velocity measurements, we expect that our object detector can detect the short-term future locations of objects using only the current frame sensor data and demonstrate a fast ability to respond to intermediate danger. To achieve this, we extend the standard object detection task to a novel task named predictive object detection (POD), which aims to predict the short-term future location and dimensions of objects based solely on current observations. Typically, a motion prediction task requires historical sensor information to process the temporal contexts of each object, while our detector's avoidance of multi-frame historical information enables a much faster response time to potential dangers. The core advantage of FMCW LiDAR lies in the radial velocity associated with every reflected point. We propose a novel POD framework, the core idea of which is to generate a virtual future point using a ray casting mechanism, create virtual two-frame point clouds with the current and virtual future frames, and encode these two-frame voxel features with a sparse 4D encoder. Subsequently, the 4D voxel features are separated by temporal indices and remapped into two Bird's Eye View (BEV) features: one decoded for standard current frame object detection and the other for future predictive object detection. Extensive experiments on our in-house dataset demonstrate the state-of-the-art standard and predictive detection performance of the proposed POD framework.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR-based 3D object detection is a fundamental task in the field ofautonomous driving. This paper explores the unique advantage of FrequencyModulated Continuous Wave (FMCW) LiDAR in autonomous perception. Given a singleframe FMCW point cloud with radial velocity measurements, we expect that ourobject detector can detect the short-term future locations of objects usingonly the current frame sensor data and demonstrate a fast ability to respond tointermediate danger. To achieve this, we extend the standard object detectiontask to a novel task named predictive object detection (POD), which aims topredict the short-term future location and dimensions of objects based solelyon current observations. Typically, a motion prediction task requireshistorical sensor information to process the temporal contexts of each object,while our detector's avoidance of multi-frame historical information enables amuch faster response time to potential dangers. The core advantage of FMCWLiDAR lies in the radial velocity associated with every reflected point. Wepropose a novel POD framework, the core idea of which is to generate a virtualfuture point using a ray casting mechanism, create virtual two-frame pointclouds with the current and virtual future frames, and encode these two-framevoxel features with a sparse 4D encoder. Subsequently, the 4D voxel featuresare separated by temporal indices and remapped into two Bird's Eye View (BEV)features: one decoded for standard current frame object detection and the otherfor future predictive object detection. Extensive experiments on our in-housedataset demonstrate the state-of-the-art standard and predictive detectionperformance of the proposed POD framework.</description>
      <author>example@mail.com (Yining Shi, Kun Jiang, Xin Zhao, Kangan Qian, Chuchu Xie, Tuopu Wen, Mengmeng Yang, Diange Yang)</author>
      <guid isPermaLink="false">2504.05649v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>CamContextI2V: Context-aware Controllable Video Generation</title>
      <link>http://arxiv.org/abs/2504.06022v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CamContextI2V的图像到视频（I2V）模型，该模型结合了多种图像条件和3D约束以及相机控制，以丰富全局语义和精细视觉细节，从而实现更连贯和情境感知的视频生成。&lt;h4&gt;背景&lt;/h4&gt;现有的I2V扩散模型在场景理解和生成质量方面表现出色，但主要对静态图像进行动画处理，未扩展到提供的上下文之外。引入额外的约束（如相机轨迹）可以增加多样性，但往往降低视觉质量，限制了其在需要忠实场景表示的任务中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出CamContextI2V模型，旨在通过结合图像条件和3D约束以及相机控制，提高视频生成的视觉质量和场景连贯性。&lt;h4&gt;方法&lt;/h4&gt;CamContextI2V模型集成了多种图像条件、3D约束和相机控制，以增强全局语义和精细视觉细节，并通过RealEstate10K数据集进行了全面研究。&lt;h4&gt;主要发现&lt;/h4&gt;CamContextI2V模型在视觉质量和相机可控性方面有所提升，证明了时间感知对于有效情境表示的必要性。&lt;h4&gt;结论&lt;/h4&gt;CamContextI2V模型能够生成更高质量和情境感知的视频，对需要忠实场景表示的任务具有潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;最近，图像到视频（I2V）扩散模型在场景理解和生成质量方面表现出色，结合了图像条件以引导生成。然而，这些模型主要对静态图像进行动画处理，没有扩展到它们提供的上下文之外。引入额外的约束，如相机轨迹，可以增强多样性，但往往降低视觉质量，限制了它们在需要忠实场景表示的任务中的应用。我们提出了CamContextI2V，一种将多个图像条件与3D约束以及相机控制相结合的I2V模型，以丰富全局语义和精细视觉细节。这使视频生成更加连贯和情境感知。此外，我们强调了时间感知对于有效情境表示的必要性。我们在RealEstate10K数据集上的全面研究表明，在视觉质量和相机可控性方面有所改进。我们将在https://github.com/LDenninger/CamContextI2V上公开我们的代码和模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, image-to-video (I2V) diffusion models have demonstrated impressivescene understanding and generative quality, incorporating image conditions toguide generation. However, these models primarily animate static images withoutextending beyond their provided context. Introducing additional constraints,such as camera trajectories, can enhance diversity but often degrades visualquality, limiting their applicability for tasks requiring faithful scenerepresentation. We propose CamContextI2V, an I2V model that integrates multipleimage conditions with 3D constraints alongside camera control to enrich bothglobal semantics and fine-grained visual details. This enables more coherentand context-aware video generation. Moreover, we motivate the necessity oftemporal awareness for an effective context representation. Our comprehensivestudy on the RealEstate10K dataset demonstrates improvements in visual qualityand camera controllability. We make our code and models publicly available at:https://github.com/LDenninger/CamContextI2V.</description>
      <author>example@mail.com (Luis Denninger, Sina Mokhtarzadeh Azar, Juergen Gall)</author>
      <guid isPermaLink="false">2504.06022v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>ViTaMIn: Learning Contact-Rich Tasks Through Robot-Free Visuo-Tactile Manipulation Interface</title>
      <link>http://arxiv.org/abs/2504.06156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ViTaMIn的机器人操作界面，该界面将视觉和触觉传感无缝集成到手持式抓取器中，以实现无需远程操作的数据收集。&lt;h4&gt;背景&lt;/h4&gt;触觉信息对于人类和机器人与环境交互至关重要，尤其是在需要理解接触特性的任务中。目前，解决这类灵活操作任务通常依赖于从演示数据集进行模仿学习，而这通常需要通过远程操作系统收集，耗时费力。&lt;h4&gt;目的&lt;/h4&gt;提出ViTaMIn以解决上述挑战，提高数据收集效率和策略鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;ViTaMIn使用了一种具有触觉传感的柔顺鳍状抓取器，允许操作者在操作过程中感知力反馈。此外，还提出了一种多模态表示学习策略，以获得预训练的触觉表示。&lt;h4&gt;主要发现&lt;/h4&gt;在七个涉及接触的灵活操作任务上的实验表明，ViTaMIn显著优于基线方法，证明了其在复杂操作任务中的有效性。&lt;h4&gt;结论&lt;/h4&gt;ViTaMIn作为一种无需远程操作即可进行数据收集的机器人操作界面，对于提高数据效率和策略鲁棒性具有显著效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tactile information plays a crucial role for humans and robots to interacteffectively with their environment, particularly for tasks requiring theunderstanding of contact properties. Solving such dexterous manipulation tasksoften relies on imitation learning from demonstration datasets, which aretypically collected via teleoperation systems and often demand substantial timeand effort. To address these challenges, we present ViTaMIn, an embodiment-freemanipulation interface that seamlessly integrates visual and tactile sensinginto a hand-held gripper, enabling data collection without the need forteleoperation. Our design employs a compliant Fin Ray gripper with tactilesensing, allowing operators to perceive force feedback during manipulation formore intuitive operation. Additionally, we propose a multimodal representationlearning strategy to obtain pre-trained tactile representations, improving dataefficiency and policy robustness. Experiments on seven contact-richmanipulation tasks demonstrate that ViTaMIn significantly outperforms baselinemethods, demonstrating its effectiveness for complex manipulation tasks.</description>
      <author>example@mail.com (Fangchen Liu, Chuanyu Li, Yihua Qin, Ankit Shaw, Jing Xu, Pieter Abbeel, Rui Chen)</author>
      <guid isPermaLink="false">2504.06156v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Maternal and Fetal Health Status Assessment by Using Machine Learning on Optical 3D Body Scans</title>
      <link>http://arxiv.org/abs/2504.05627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了利用3D身体扫描数据预测不良妊娠结局和估计临床参数的潜力。&lt;h4&gt;背景&lt;/h4&gt;监测孕期母婴健康对于预防不良结局至关重要。虽然超声波扫描等测试具有高准确性，但它们可能成本高且不便。&lt;h4&gt;目的&lt;/h4&gt;开发一种新型算法，利用3D身体扫描数据预测不良妊娠结局（如早产、妊娠糖尿病、妊娠高血压）并估计胎儿体重。&lt;h4&gt;方法&lt;/h4&gt;研究开发了一种具有两个并行流的新算法，用于提取身体形状特征：一个用于监督学习提取连续腹部周长信息，另一个用于无监督学习提取全局形状描述符，同时还有一个分支用于收集人口统计数据。&lt;h4&gt;主要发现&lt;/h4&gt;3D身体形状有助于预测早产、妊娠糖尿病、妊娠高血压，并在估计胎儿体重方面表现良好。与其它机器学习模型相比，该算法实现了最佳性能，预测准确率超过88%，胎儿体重估计准确率为76.74%，误差范围为10%，比传统的人体测量方法高22.22%。&lt;h4&gt;结论&lt;/h4&gt;3D身体扫描数据在预测不良妊娠结局和估计胎儿体重方面具有潜力，且该算法的性能优于传统方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monitoring maternal and fetal health during pregnancy is crucial forpreventing adverse outcomes. While tests such as ultrasound scans offer highaccuracy, they can be costly and inconvenient. Telehealth and more accessiblebody shape information provide pregnant women with a convenient way to monitortheir health. This study explores the potential of 3D body scan data, capturedduring the 18-24 gestational weeks, to predict adverse pregnancy outcomes andestimate clinical parameters. We developed a novel algorithm with two parallelstreams which are used for extract body shape features: one for supervisedlearning to extract sequential abdominal circumference information, and anotherfor unsupervised learning to extract global shape descriptors, alongside abranch for demographic data.  Our results indicate that 3D body shape can assist in predicting pretermlabor, gestational diabetes mellitus (GDM), gestational hypertension (GH), andin estimating fetal weight. Compared to other machine learning models, ouralgorithm achieved the best performance, with prediction accuracies exceeding88% and fetal weight estimation accuracy of 76.74% within a 10% error margin,outperforming conventional anthropometric methods by 22.22%.</description>
      <author>example@mail.com (Ruting Cheng, Yijiang Zheng, Boyuan Feng, Chuhui Qiu, Zhuoxin Long, Joaquin A. Calderon, Xiaoke Zhang, Jaclyn M. Phillips, James K. Hahn)</author>
      <guid isPermaLink="false">2504.05627v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>On the Importance of Conditioning for Privacy-Preserving Data Augmentation</title>
      <link>http://arxiv.org/abs/2504.05849v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文探讨了使用潜在扩散模型进行数据增广，发现其不适合作为隐私保护方法，并指出其匿名化过程容易受到黑盒攻击。&lt;h4&gt;背景&lt;/h4&gt;潜在扩散模型被用作数据增广的方法，以增强训练数据集。有研究提出将此技术用于数据匿名化。&lt;h4&gt;目的&lt;/h4&gt;评估使用条件扩散模型进行数据匿名化的可行性，并分析其安全性。&lt;h4&gt;方法&lt;/h4&gt;使用对比学习方法训练模型，以识别人群中的人。通过条件扩散模型生成匿名化图像，并分析其易受黑盒攻击的情况。&lt;h4&gt;主要发现&lt;/h4&gt;条件扩散模型生成的匿名化图像在视觉上与原始图像差异很大，但仍然可能被识别。匿名化过程容易受到黑盒攻击。&lt;h4&gt;结论&lt;/h4&gt;潜在扩散模型条件化后的匿名化方法不适合作为隐私保护手段，且存在安全风险。&lt;h4&gt;翻译&lt;/h4&gt;摘要：潜在扩散模型可以作为一种强大的增广方法，用于人工扩展数据集以增强训练。对于人类视觉来说，这些增广图像与原始图像非常不同。先前的研究建议使用这种数据增广技术进行数据匿名化。然而，我们表明，条件于深度图或边缘等特征以引导扩散过程的潜在扩散模型不适合作为隐私保护方法。我们使用对比学习方法训练了一个模型，该模型可以正确地从候选人池中识别出人。此外，我们展示了使用条件扩散模型进行匿名化容易受到黑盒攻击。我们将所述方法的成功归因于匿名化过程中的潜在扩散模型的条件化。扩散模型被指示为匿名化图像生成相似的边缘。因此，模型可以学习识别这些模式进行识别。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Latent diffusion models can be used as a powerful augmentation method toartificially extend datasets for enhanced training. To the human eye, theseaugmented images look very different to the originals. Previous work hassuggested to use this data augmentation technique for data anonymization.However, we show that latent diffusion models that are conditioned on featureslike depth maps or edges to guide the diffusion process are not suitable as aprivacy preserving method. We use a contrastive learning approach to train amodel that can correctly identify people out of a pool of candidates. Moreover,we demonstrate that anonymization using conditioned diffusion models issusceptible to black box attacks. We attribute the success of the describedmethods to the conditioning of the latent diffusion model in the anonymizationprocess. The diffusion model is instructed to produce similar edges for theanonymized images. Hence, a model can learn to recognize these patterns foridentification.</description>
      <author>example@mail.com (Julian Lorenz, Katja Ludwig, Valentin Haug, Rainer Lienhart)</author>
      <guid isPermaLink="false">2504.05849v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Earth-Adapter: Bridge the Geospatial Domain Gaps with Mixture of Frequency Adaptation</title>
      <link>http://arxiv.org/abs/2504.06220v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Earth-Adapter，这是一种针对遥感图像特征中存在的伪影问题而设计的Parameter-Efficient Fine-Tuning (PEFT)方法，旨在提高基础模型在遥感场景下的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的PEFT方法通常针对自然图像设计，在遥感场景中应用时难以处理伪影影响。&lt;h4&gt;目的&lt;/h4&gt;解决现有PEFT方法在遥感场景中处理伪影的能力不足的问题。&lt;h4&gt;方法&lt;/h4&gt;Earth-Adapter引入了一种新的频率自适应过程，结合了混合适配器（MoA）和离散傅里叶变换（DFT）。通过DFT分解特征为不同频率成分，精确分离伪影和原始特征。MoA动态分配权重给每个适配器专家，允许跨不同频率域组合特征。&lt;h4&gt;主要发现&lt;/h4&gt;Earth-Adapter在领域自适应（DA）和领域泛化（DG）语义分割基准测试中展示了其有效性，与基线Rein相比，在DA基准上提高了9.0%的mIoU，在DG基准上提高了3.1%的mIoU。&lt;h4&gt;结论&lt;/h4&gt;Earth-Adapter能够更有效地克服伪影干扰，显著提升基础模型在遥感场景下的性能。&lt;h4&gt;翻译&lt;/h4&gt;Parameter-Efficient Fine-Tuning (PEFT)是一种技术，允许我们适应强大的基础模型（FMs）以执行多样化的下游任务，同时保留并发挥其固有能力。然而，我们观察到现有的PEFT方法，这些方法通常是为了自然图像而设计的，在应用于遥感（RS）场景时遇到了困难。这主要是因为它们无法处理伪影影响，在RS图像特征中这是一个特别严重的问题。为了应对这一挑战，我们引入了Earth-Adapter，这是第一个专门为RS伪影征服设计的PEFT方法。Earth-Adapter引入了一种新颖的频率自适应过程，结合了混合适配器（MoA）和离散傅里叶变换（DFT）。通过利用DFT，Earth-Adapter可以将特征分解为不同的频率成分，精确地分离伪影和原始特征。然后，MoA动态地为每个适配器专家分配权重，允许跨不同频率域组合特征。这些简单而有效的方法使Earth-Adapter比以前的PEFT方法更有效地克服了伪影造成的干扰，显著提高了FMs在RS场景中的性能。在领域自适应（DA）和领域泛化（DG）语义分割基准测试上的实验展示了Earth-Adapter的有效性。与基线Rein相比，Earth-Adapter在DA基准上显著提高了9.0%的mIoU，在DG基准上提高了3.1%的mIoU。我们的代码将在https://github.com/VisionXLab/Earth-Adapter上发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-Efficient Fine-Tuning (PEFT) is a technique that allows us to adaptpowerful Foundation Models (FMs) to diverse downstream tasks while preservingand unleashing their inherent capabilities. However, we have observed thatexisting PEFT methods, which are often designed with natural imagery in mind,struggle when applied to Remote Sensing (RS) scenarios. This is primarily dueto their inability to handle artifact influences, a problem particularly severein RS image features. To tackle this challenge, we introduce Earth-Adapter, thefirst PEFT method specifically designed for RS artifacts conquering.Earth-Adapter introduces a novel Mixture of Frequency Adaptation process thatcombines a Mixture of Adapter (MoA) with Discrete Fourier Transformation (DFT).By utilizing DFT, Earth-Adapter can decompose features into different frequencycomponents, precisely separating artifacts from original features. The MoA thendynamically assigns weights to each adapter expert, allowing for thecombination of features across various frequency domains. Thesesimple-yet-effective approaches enable Earth-Adapter to more efficientlyovercome the disturbances caused by artifacts than previous PEFT methods,significantly enhancing the FMs' performance on RS scenarios. Experiments onDomain Adaptation (DA), and Domain Generalization (DG) semantic segmentationbenchmarks showcase the Earth-Adapter's effectiveness. Compared with baselineRein, Earth-Adapter significantly improves 9.0% mIoU in DA and 3.1% mIoU in DGbenchmarks. Our code will be released athttps://github.com/VisionXLab/Earth-Adapter.</description>
      <author>example@mail.com (Xiaoxing Hu, Ziyang Gong, Yupei Wang, Yuru Jia, Gen Luo, Xue Yang)</author>
      <guid isPermaLink="false">2504.06220v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Comparative Analysis of Classical and Quantum-Inspired Solvers: A Preliminary Study on the Weighted Max-Cut Problem</title>
      <link>http://arxiv.org/abs/2504.05989v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 3 figures, 4 tables, paper Submitted to GECCO '25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究评估了八种算法在加权最大割图上的性能，包括遗传算法、图神经网络和密度矩阵重整化群，重点分析了解决方案的质量和计算效率。&lt;h4&gt;背景&lt;/h4&gt;组合优化在众多学科中至关重要，传统元启发式算法在探索复杂解空间方面表现出色，但往往在可扩展性上存在困难。深度学习成为快速生成高质量解决方案的可行替代方案，尤其是在元启发式算法表现不佳时。&lt;h4&gt;目的&lt;/h4&gt;评估不同算法在加权最大割图上的性能，并比较它们的解决方案质量和计算效率。&lt;h4&gt;方法&lt;/h4&gt;在10到250个节点的加权最大割图上评估了遗传算法、图神经网络和密度矩阵重整化群算法。分析集中在解决方案的质量和计算效率上。&lt;h4&gt;主要发现&lt;/h4&gt;遗传算法在小图上实现接近最优的结果，但随着问题规模的增加，其计算时间显著增长。图神经网络为中等规模实例提供了平衡的解决方案，具有低内存需求和快速推理，但在大图上表现出的变异性更大。同时，张量网络方法在大型图上持续产生高近似比和高效执行，尽管内存消耗有所增加。&lt;h4&gt;结论&lt;/h4&gt;不同的算法在处理加权最大割图问题时各有优缺点，应根据具体问题选择合适的算法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Combinatorial optimization is essential across numerous disciplines.Traditional metaheuristics excel at exploring complex solution spacesefficiently, yet they often struggle with scalability. Deep learning has becomea viable alternative for quickly generating high-quality solutions,particularly when metaheuristics underperform. In recent years,quantum-inspired approaches such as tensor networks have shown promise inaddressing these challenges. Despite these advancements, a thorough comparisonof the different paradigms is missing. This study evaluates eight algorithms onWeighted Max-Cut graphs ranging from 10 to 250 nodes. Specifically, we comparea Genetic Algorithm representing metaheuristics, a Graph Neural Network fordeep learning, and the Density Matrix Renormalization Group as a tensor networkapproach. Our analysis focuses on solution quality and computational efficiency(i.e., time and memory usage). Numerical results show that the GeneticAlgorithm achieves near-optimal results for small graphs, although itscomputation time grows significantly with problem size. The Graph NeuralNetwork offers a balanced solution for medium-sized instances with low memorydemands and rapid inference, yet it exhibits more significant variability onlarger graphs. Meanwhile, the Tensor Network approach consistently yields highapproximation ratios and efficient execution on larger graphs, albeit withincreased memory consumption.</description>
      <author>example@mail.com (Aitor Morais, Eneko Osaba, Iker Pastor, Izaskun Oregui)</author>
      <guid isPermaLink="false">2504.05989v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>REEF: Relevance-Aware and Efficient LLM Adapter for Video Understanding</title>
      <link>http://arxiv.org/abs/2504.05491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPRW'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种高效的大型语言模型适配器，用于处理未剪辑视频的视频级理解，该适配器优先考虑时空标记的上下文相关性。&lt;h4&gt;背景&lt;/h4&gt;将视觉模型集成到大型语言模型中，特别是视频理解领域，引起了极大的兴趣。现有方法通常使用基于相似性的贪婪方法压缩视觉记忆库，这可能忽略了单个标记的上下文重要性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的方法，旨在提高视频级理解中时空标记的上下文相关性。&lt;h4&gt;方法&lt;/h4&gt;该方法利用评分网络来选择性地压缩视觉记忆库，并根据相关性过滤空间标记，使用可微分的Top-K算子进行端到端训练。&lt;h4&gt;主要发现&lt;/h4&gt;在三个关键的视频级理解任务（未剪辑视频分类、视频问答和视频字幕）上，该方法在四个大规模数据集上实现了具有竞争力的或更好的结果，同时将计算开销减少了多达34%。&lt;h4&gt;结论&lt;/h4&gt;该方法将很快在GitHub上提供代码，表明其在视频理解领域具有潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrating vision models into large language models (LLMs) has sparkedsignificant interest in creating vision-language foundation models, especiallyfor video understanding. Recent methods often utilize memory banks to handleuntrimmed videos for video-level understanding. However, they typicallycompress visual memory using similarity-based greedy approaches, which canoverlook the contextual importance of individual tokens. To address this, weintroduce an efficient LLM adapter designed for video-level understanding ofuntrimmed videos that prioritizes the contextual relevance of spatio-temporaltokens. Our framework leverages scorer networks to selectively compress thevisual memory bank and filter spatial tokens based on relevance, using adifferentiable Top-K operator for end-to-end training. Across three keyvideo-level understanding tasks$\unicode{x2013}$ untrimmed videoclassification, video question answering, and videocaptioning$\unicode{x2013}$our method achieves competitive or superior resultson four large-scale datasets while reducing computational overhead by up to34%. The code will be available soon on GitHub.</description>
      <author>example@mail.com (Sakib Reza, Xiyun Song, Heather Yu, Zongfang Lin, Mohsen Moghaddam, Octavia Camps)</author>
      <guid isPermaLink="false">2504.05491v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Cross-functional transferability in universal machine learning interatomic potentials</title>
      <link>http://arxiv.org/abs/2504.05565v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文分析了在CHGNet框架下，从低保真数据集到高保真数据集迁移学习问题的挑战，并强调了元素能量参考和适当迁移学习在创建下一代高保真uMLIPs中的重要性。&lt;h4&gt;背景&lt;/h4&gt;uMLIPs的快速发展证明了通用势能表面可推广学习的可能性。&lt;h4&gt;目的&lt;/h4&gt;分析uMLIPs迁移学习问题的挑战，并探讨如何提高其准确性。&lt;h4&gt;方法&lt;/h4&gt;在0.24百万结构的MP-r$^2$SCAN数据集上，对不同的迁移学习方法进行基准测试，比较了有和没有在低保真数据集上预训练的扩展定律。&lt;h4&gt;主要发现&lt;/h4&gt;显著的能量尺度偏移和GGA与r$^2$SCAN之间的相关性差，给uMLIPs的跨功能数据迁移带来了挑战；通过迁移学习，即使目标数据集为亚百万结构，也能实现显著的数据效率。&lt;h4&gt;结论&lt;/h4&gt;适当的迁移学习和多保真学习对于在高保真数据上创建下一代uMLIPs至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid development of universal machine learning interatomic potentials(uMLIPs) has demonstrated the possibility for generalizable learning of theuniversal potential energy surface. In principle, the accuracy of uMLIPs can befurther improved by bridging the model from lower-fidelity datasets tohigh-fidelity ones. In this work, we analyze the challenge of this transferlearning problem within the CHGNet framework. We show that significant energyscale shifts and poor correlations between GGA and r$^2$SCAN pose challenges tocross-functional data transferability in uMLIPs. By benchmarking differenttransfer learning approaches on the MP-r$^2$SCAN dataset of 0.24 millionstructures, we demonstrate the importance of elemental energy referencing inthe transfer learning of uMLIPs. By comparing the scaling law with and withoutthe pre-training on a low-fidelity dataset, we show that significant dataefficiency can still be achieved through transfer learning, even with a targetdataset of sub-million structures. We highlight the importance of propertransfer learning and multi-fidelity learning in creating next-generationuMLIPs on high-fidelity data.</description>
      <author>example@mail.com (Xu Huang, Bowen Deng, Peichen Zhong, Aaron D. Kaplan, Kristin A. Persson, Gerbrand Ceder)</author>
      <guid isPermaLink="false">2504.05565v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>AEGIS: Human Attention-based Explainable Guidance for Intelligent Vehicle Systems</title>
      <link>http://arxiv.org/abs/2504.05950v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AEGIS的新框架，用于提高自主智能车辆（AIVs）的决策能力。&lt;h4&gt;背景&lt;/h4&gt;尽管近年来在自主智能车辆决策能力方面取得了进展，但训练机器捕捉对全面场景理解至关重要的区域，如人类感知和推理，仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过引入AEGIS框架，利用人类注意力来引导强化学习（RL）模型识别决策的关键区域。&lt;h4&gt;方法&lt;/h4&gt;AEGIS使用从眼动追踪转换而来的人类注意力来指导RL模型识别决策的关键区域。通过收集来自20名参与者的120万帧图像，AEGIS在六个场景下预训练了一个模型，以预测人类注意力模式。&lt;h4&gt;主要发现&lt;/h4&gt;AEGIS能够有效地利用人类注意力来引导RL模型识别决策关键区域。&lt;h4&gt;结论&lt;/h4&gt;AEGIS框架为提高自主智能车辆的决策能力提供了一种新的方法。&lt;h4&gt;翻译&lt;/h4&gt;Improving decision-making capabilities in Autonomous Intelligent Vehicles (AIVs) has been a heated topic in recent years. Despite advancements, training machines to capture regions of interest for comprehensive scene understanding, like human perception and reasoning, remains a significant challenge. This study introduces a novel framework, Human Attention-based Explainable Guidance for Intelligent Vehicle Systems (AEGIS). AEGIS utilizes human attention, converted from eye-tracking, to guide reinforcement learning (RL) models to identify critical regions of interest for decision-making. AEGIS uses a pre-trained human attention model to guide RL models to identify critical regions of interest for decision-making. By collecting 1.2 million frames from 20 participants across six scenarios, AEGIS pre-trains a model to predict human attention patterns.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Improving decision-making capabilities in Autonomous Intelligent Vehicles(AIVs) has been a heated topic in recent years. Despite advancements, trainingmachines to capture regions of interest for comprehensive scene understanding,like human perception and reasoning, remains a significant challenge. Thisstudy introduces a novel framework, Human Attention-based Explainable Guidancefor Intelligent Vehicle Systems (AEGIS). AEGIS utilizes human attention,converted from eye-tracking, to guide reinforcement learning (RL) models toidentify critical regions of interest for decision-making. AEGIS uses apre-trained human attention model to guide RL models to identify criticalregions of interest for decision-making. By collecting 1.2 million frames from20 participants across six scenarios, AEGIS pre-trains a model to predict humanattention patterns.</description>
      <author>example@mail.com (Zhuoli Zhuang, Cheng-You Lu, Yu-Cheng Fred Chang, Yu-Kai Wang, Thomas Do, Chin-Teng Lin)</author>
      <guid isPermaLink="false">2504.05950v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>A Large-Scale Analysis on Contextual Self-Supervised Video Representation Learning</title>
      <link>http://arxiv.org/abs/2504.06153v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR'25 Workshop: 6th Data-Efficient Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了无监督学习在视频领域的应用，提出了一个统一的基准，以促进不同方法之间的公平比较，并系统地分析了视频自监督学习的五个关键方面。&lt;h4&gt;背景&lt;/h4&gt;自监督学习作为无标签模型预训练的有力范式，在视频领域尤为重要，因为手动标注既昂贵又耗时。&lt;h4&gt;目的&lt;/h4&gt;建立统一的基准，以促进不同自监督学习方法的公平比较，并深入探究视频自监督学习的关键因素。&lt;h4&gt;方法&lt;/h4&gt;评估了六种自监督学习方法在六种网络架构上的表现，并在五个基准数据集上进行了广泛实验，同时评估了两个下游任务上的性能。&lt;h4&gt;主要发现&lt;/h4&gt;揭示了预训练策略、数据集特征、预训练任务和模型架构之间的相互作用，并将这些发现扩展到视频基础模型（ViFMs）。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的方法，显著降低了训练数据需求，同时超越了需要10%更多预训练数据的现有方法，为未来研究提供了指导。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning has emerged as a powerful paradigm for label-freemodel pretraining, particularly in the video domain, where manual annotation iscostly and time-intensive. However, existing self-supervised approaches employdiverse experimental setups, making direct comparisons challenging due to theabsence of a standardized benchmark. In this work, we establish a unifiedbenchmark that enables fair comparisons across different methods. Additionally,we systematically investigate five critical aspects of self-supervised learningin videos: (1) dataset size, (2) model complexity, (3) data distribution, (4)data noise, and (5) feature representations. To facilitate this study, weevaluate six self-supervised learning methods across six network architectures,conducting extensive experiments on five benchmark datasets and assessingperformance on two distinct downstream tasks. Our analysis reveals key insightsinto the interplay between pretraining strategies, dataset characteristics,pretext tasks, and model architectures. Furthermore, we extend these findingsto Video Foundation Models (ViFMs), demonstrating their relevance inlarge-scale video representation learning. Finally, leveraging these insights,we propose a novel approach that significantly reduces training datarequirements while surpassing state-of-the-art methods that rely on 10% morepretraining data. We believe this work will guide future research toward adeeper understanding of self-supervised video representation learning and itsbroader implications.</description>
      <author>example@mail.com (Akash Kumar, Ashlesha Kumar, Vibhav Vineet, Yogesh S Rawat)</author>
      <guid isPermaLink="false">2504.06153v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>DyTTP: Trajectory Prediction with Normalization-Free Transformers</title>
      <link>http://arxiv.org/abs/2504.05356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer架构的轨迹预测方法，通过集成DynamicTanh（DyT）和采用快照集成策略，提高了预测精度、推理速度和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;精确的轨迹预测对于自动驾驶系统的安全运行至关重要，而理解周围代理的动态行为是关键。Transformer架构在捕捉复杂时空依赖关系方面显示出巨大潜力，但其对归一化层的依赖可能导致计算开销和训练不稳定。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来解决Transformer架构在轨迹预测任务中的计算开销和训练不稳定问题。&lt;h4&gt;方法&lt;/h4&gt;1. 将DynamicTanh（DyT）集成到骨干网络中，以取代传统的层归一化，简化网络架构并提高推理稳定性。2. 采用快照集成策略，通过周期性学习率调度，在单个训练运行中捕获多个模型快照，并在推理时通过简单平均聚合这些快照，以从多样化的假设中受益而不会增加额外的计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;在Argoverse数据集上的大量实验表明，该方法显著提高了预测精度、推理速度和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文强调了无归一化Transformer设计结合轻量级集成技术在推进自动驾驶车辆轨迹预测方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;精确轨迹预测是自动驾驶系统安全运行的基础，理解周围代理的动态行为至关重要。基于Transformer的架构在捕捉复杂时空依赖关系方面展现出巨大潜力，但其对归一化层的依赖可能导致计算开销和训练不稳定。在本文中，我们提出了一种两阶段方法来应对这些挑战。首先，我们将最新方法DynamicTanh（DyT）集成到骨干网络中，取代传统的层归一化，简化了网络架构并提高了推理的稳定性。我们是最先使用DyT来解决轨迹预测任务的工作。作为补充，我们采用快照集成策略来进一步提高轨迹预测性能。通过周期性学习率调度，在单个训练运行中捕获多个模型快照。这些快照在推理时通过简单平均进行聚合，使得模型能够从多样化的假设中受益，而不会增加额外的计算成本。在Argoverse数据集上的大量实验表明，我们的结合方法显著提高了预测精度、推理速度和在不同驾驶场景中的鲁棒性。这项工作强调了无归一化Transformer设计结合轻量级集成技术在推进自动驾驶车辆轨迹预测方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate trajectory prediction is a cornerstone for the safe operation ofautonomous driving systems, where understanding the dynamic behavior ofsurrounding agents is crucial. Transformer-based architectures havedemonstrated significant promise in capturing complex spatio-temporalitydependencies. However, their reliance on normalization layers can lead tocomputation overhead and training instabilities. In this work, we present atwo-fold approach to address these challenges. First, we integrate DynamicTanh(DyT), which is the latest method to promote transformers, into the backbone,replacing traditional layer normalization. This modification simplifies thenetwork architecture and improves the stability of the inference. We are thefirst work to deploy the DyT to the trajectory prediction task. Complementingthis, we employ a snapshot ensemble strategy to further boost trajectoryprediction performance. Using cyclical learning rate scheduling, multiple modelsnapshots are captured during a single training run. These snapshots are thenaggregated via simple averaging at inference time, allowing the model tobenefit from diverse hypotheses without incurring substantial additionalcomputational cost. Extensive experiments on Argoverse datasets demonstratethat our combined approach significantly improves prediction accuracy,inference speed and robustness in diverse driving scenarios. This workunderscores the potential of normalization-free transformer designs augmentedwith lightweight ensemble techniques in advancing trajectory forecasting forautonomous vehicles.</description>
      <author>example@mail.com (Yunxiang Liu, Hongkuo Niu)</author>
      <guid isPermaLink="false">2504.05356v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Retrieval Augmented Generation with Collaborative Filtering for Personalized Text Generation</title>
      <link>http://arxiv.org/abs/2504.05731v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为CFRAG的方法，用于个性化文本生成，通过将协同过滤应用于RAG（检索增强生成）来利用用户间的协作信息。&lt;h4&gt;背景&lt;/h4&gt;个性化大型语言模型生成内容受到关注，现有的个性化RAG方法未考虑相似用户的历史可以帮助个性化当前用户的生成。&lt;h4&gt;目的&lt;/h4&gt;提出CFRAG方法，以利用用户间的协作信息，增强个性化文本生成。&lt;h4&gt;方法&lt;/h4&gt;CFRAG方法包括：1) 使用对比学习训练用户嵌入来检索相似用户并引入协作信息；2) 设计个性化检索和重新排序器来从用户历史中检索前$k$个文档；3) 考虑用户偏好进行检索和重新排序；4) 利用LLM的反馈来微调检索器和重新排序器。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明CFRAG方法有效，进一步分析确认了引入协作信息的重要性。&lt;h4&gt;结论&lt;/h4&gt;CFRAG方法通过利用用户间的协作信息，提高了个性化文本生成的效果。&lt;h4&gt;翻译&lt;/h4&gt;最近，对大型语言模型（LLM）进行个性化以生成符合个人用户偏好的内容受到了广泛关注。个性化检索增强生成（RAG），即从用户的历史中检索相关文档以反映他们的偏好并增强LLM的生成，是用于个性化的一种常用方法。然而，现有的个性化RAG方法没有考虑相似用户的历史也可以帮助对当前用户的个性化生成，这意味着用户间的协作信息也可以用于个性化生成。受推荐系统中协同过滤应用的启发，我们提出了一种名为CFRAG的方法，该方法将协同过滤应用于RAG以实现个性化文本生成。然而，这提出了两个挑战：（1）如何在不提供明确的用户相似性标签的情况下引入协作信息？（2）如何检索支持个性化LLM生成的文档？对于挑战1，我们使用对比学习来训练用户嵌入以检索相似用户并引入协作信息。对于挑战2，我们设计了一个个性化的检索器和重新排序器来从这些用户的 历史 中检索前$k$个文档。我们在检索和重新排序过程中考虑了用户的偏好。然后我们利用LLM的反馈来微调个性化的检索器和重新排序器，使它们能够检索满足LLM个性化生成需求的文档。在语言模型个性化（LaMP）基准测试上的实验结果验证了CFRAG的有效性。进一步的分析确认了引入协作信息的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, the personalization of Large Language Models (LLMs) to generatecontent that aligns with individual user preferences has garnered widespreadattention. Personalized Retrieval-Augmented Generation (RAG), which retrievesrelevant documents from the user's history to reflect their preferences andenhance LLM generation, is one commonly used approach for personalization.However, existing personalized RAG methods do not consider that the historiesof similar users can also assist in personalized generation for the currentuser, meaning that collaborative information between users can also benefitpersonalized generation. Inspired by the application of collaborative filteringin recommender systems, we propose a method called CFRAG, which adaptsCollaborative Filtering to RAG for personalized text generation. However, thispresents two challenges: (1)~how to incorporate collaborative informationwithout explicit user similarity labels? (2)~how to retrieve documents thatsupport personalized LLM generation? For Challenge 1, we use contrastivelearning to train user embeddings to retrieve similar users and introducecollaborative information. For Challenge 2, we design a personalized retrieverand reranker to retrieve the top-$k$ documents from these users' histories. Wetake into account the user's preference during retrieval and reranking. Then weleverage feedback from the LLM to fine-tune the personalized retriever andreranker, enabling them to retrieve documents that meet the personalizedgeneration needs of the LLM. Experimental results on the Language ModelPersonalization (LaMP) benchmark validate the effectiveness of CFRAG. Furtheranalysis confirms the importance of incorporating collaborative information.</description>
      <author>example@mail.com (Teng Shi, Jun Xu, Xiao Zhang, Xiaoxue Zang, Kai Zheng, Yang Song, Han Li)</author>
      <guid isPermaLink="false">2504.05731v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>How to Enable LLM with 3D Capacity? A Survey of Spatial Reasoning in LLM</title>
      <link>http://arxiv.org/abs/2504.05786v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了将大型语言模型（LLMs）与3D空间理解相结合的方法，分析了其分类、代表性方法、数据表示、架构修改和训练策略，并讨论了当前限制和未来研究方向。&lt;h4&gt;背景&lt;/h4&gt;3D空间理解在机器人、自动驾驶、虚拟现实和医学成像等现实世界应用中至关重要。大型语言模型在多个领域取得了显著成功，并显示出在3D理解任务中超越传统计算机视觉方法的潜力。&lt;h4&gt;目的&lt;/h4&gt;对将LLMs与3D空间理解相结合的方法进行全面综述，并提出一个分类法。&lt;h4&gt;方法&lt;/h4&gt;提出一个分类法，将现有方法分为图像基于方法、点云基于方法和混合模态方法三类。系统性地回顾了这些类别中的代表性方法，包括数据表示、架构修改和训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs在3D理解任务中显示出超越传统方法的潜力，但存在数据集稀缺和计算挑战等限制。&lt;h4&gt;结论&lt;/h4&gt;本文强调了在空间感知、多模态融合和现实世界应用中的有希望的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;3D空间理解在现实世界的应用，如机器人、自动驾驶、虚拟现实和医学成像等方面至关重要。近期，大型语言模型（LLMs）在多个领域取得了显著的成功，并被用于增强3D理解任务，显示出可能超越传统计算机视觉方法的潜力。在本综述中，我们全面回顾了将LLMs与3D空间理解相结合的方法。我们提出了一种分类法，将现有方法分为三类：基于图像的方法，从二维视觉数据中推导出3D理解；基于点云的方法，直接与3D表示工作；以及混合模态方法，结合多个数据流。我们系统地回顾了这些类别中的代表性方法，包括数据表示、架构修改和连接文本和3D模态的训练策略。最后，我们讨论了当前的局限性，包括数据集稀缺和计算挑战，同时强调了在空间感知、多模态融合和现实世界应用中的有希望的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D spatial understanding is essential in real-world applications such asrobotics, autonomous vehicles, virtual reality, and medical imaging. Recently,Large Language Models (LLMs), having demonstrated remarkable success acrossvarious domains, have been leveraged to enhance 3D understanding tasks, showingpotential to surpass traditional computer vision methods. In this survey, wepresent a comprehensive review of methods integrating LLMs with 3D spatialunderstanding. We propose a taxonomy that categorizes existing methods intothree branches: image-based methods deriving 3D understanding from 2D visualdata, point cloud-based methods working directly with 3D representations, andhybrid modality-based methods combining multiple data streams. Wesystematically review representative methods along these categories, coveringdata representations, architectural modifications, and training strategies thatbridge textual and 3D modalities. Finally, we discuss current limitations,including dataset scarcity and computational challenges, while highlightingpromising research directions in spatial perception, multi-modal fusion, andreal-world applications.</description>
      <author>example@mail.com (Jirong Zha, Yuxuan Fan, Xiao Yang, Chen Gao, Xinlei Chen)</author>
      <guid isPermaLink="false">2504.05786v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>REVEAL: Relation-based Video Representation Learning for Video-Question-Answering</title>
      <link>http://arxiv.org/abs/2504.05463v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为REVEAL的框架，用于视频问答任务，通过编码视觉关系信息来捕捉复杂的视觉关系变化。&lt;h4&gt;背景&lt;/h4&gt;视频问答（VideoQA）是一个挑战，即使是高级视频语言模型（VLM）也难以处理，因为需要将视觉内容表示成适合模型大小的输入。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了REVEAL框架，旨在通过编码结构化的分解表示来捕获视觉关系信息。&lt;h4&gt;方法&lt;/h4&gt;受时空场景图启发，将视频序列编码为一系列时间上的关系三元组（主语-谓语-宾语），并通过语言嵌入提取视频字幕中的显式关系。引入了多对多噪声对比估计（MM-NCE）和Q-Former架构来对齐视频导出的查询与基于文本的关系描述。在推理过程中，Q-Former生成一个高效的标记表示，可以作为VLM的输入。&lt;h4&gt;主要发现&lt;/h4&gt;在五个具有挑战性的基准测试（NeXT-QA、Intent-QA、STAR、VLEP和TVQA）上评估了提出的框架，结果显示基于查询的视频表示能够优于基于全局对齐的CLS或补丁标记表示，并在需要时间推理和关系理解的任务上与最先进模型具有竞争力。&lt;h4&gt;结论&lt;/h4&gt;提出的框架在视频问答任务中表现出色，并且代码和模型将公开发布。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视频问答（VideoQA）包括捕捉随时间变化的复杂视觉关系，即使对于高级视频语言模型（VLM）来说也是一个挑战，这主要是因为需要将这些模型的大小合理地表示为视觉内容。为了解决这个问题，我们提出了基于关系的视频表示学习（REVEAL）框架，该框架旨在通过将它们编码为结构化的分解表示来捕获视觉关系信息。具体来说，受时空场景图的启发，我们提出通过语言嵌入将视频序列编码为一系列时间上的关系三元组（主语-谓语-宾语）。为此，我们从视频字幕中提取显式关系，并引入了许多对多噪声对比估计（MM-NCE）以及Q-Former架构，以对齐由视频导出的查询与对应基于文本的关系描述。在推理过程中，生成的Q-Former产生了一个高效的标记表示，可以作为视频问答中VLM的输入。我们在五个具有挑战性的基准测试（NeXT-QA、Intent-QA、STAR、VLEP和TVQA）上评估了所提出的框架。结果显示，基于查询的视频表示能够优于基于全局对齐的CLS或补丁标记表示，并在需要时间推理和关系理解的任务上与最先进模型具有竞争力。代码和模型将公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video-Question-Answering (VideoQA) comprises the capturing of complex visualrelation changes over time, remaining a challenge even for advanced VideoLanguage Models (VLM), i.a., because of the need to represent the visualcontent to a reasonably sized input for those models. To address this problem,we propose  RElation-based Video rEpresentAtion Learning (REVEAL), a framework designedto capture visual relation information by encoding them into structured,decomposed representations. Specifically, inspired by spatiotemporal scenegraphs, we propose to encode video sequences as sets of relation triplets inthe form of (\textit{subject-predicate-object}) over time via their languageembeddings. To this end, we extract explicit relations from video captions andintroduce a Many-to-Many Noise Contrastive Estimation (MM-NCE) together with aQ-Former architecture to align an unordered set of video-derived queries withcorresponding text-based relation descriptions. At inference, the resultingQ-former produces an efficient token representation that can serve as input toa VLM for VideoQA.  We evaluate the proposed framework on five challenging benchmarks: NeXT-QA,Intent-QA, STAR, VLEP, and TVQA. It shows that the resulting query-based videorepresentation is able to outperform global alignment-based CLS or patch tokenrepresentations and achieves competitive results against state-of-the-artmodels, particularly on tasks requiring temporal reasoning and relationcomprehension. The code and models will be publicly released.</description>
      <author>example@mail.com (Sofian Chaybouti, Walid Bousselham, Moritz Wolter, Hilde Kuehne)</author>
      <guid isPermaLink="false">2504.05463v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>SEVERE++: Evaluating Benchmark Sensitivity in Generalization of Video Representation Learning</title>
      <link>http://arxiv.org/abs/2504.05706v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对现代视频自监督学习模型进行了全面评估，重点关注其在现实世界场景中的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在视频表示学习方面取得了显著进展，但视频自监督学习方法通常在狭窄的协议下进行评估，限制了对其泛化能力的理解。&lt;h4&gt;目的&lt;/h4&gt;评估现代视频自监督模型在四个关键下游因素（领域迁移、样本效率、动作粒度和任务多样性）上的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;本文分析了12种基于Transformer的方法（7种视频-only，5种视频-文本）和10种基于CNN的方法，在8个数据集和7个下游任务上进行了超过1100次实验。&lt;h4&gt;主要发现&lt;/h4&gt;尽管架构有所进步，但基于Transformer的模型对下游条件仍然敏感，没有一种方法能在所有因素上保持一致性的泛化，视频-only Transformer在领域迁移方面表现更好，CNN在细粒度任务上表现更佳，而视频-文本模型尽管进行了大规模预训练，但通常表现不佳。&lt;h4&gt;结论&lt;/h4&gt;本文的研究结果为当前视频自监督学习方法的优缺点提供了详细视角，并为评估视频表示学习中的泛化能力提供了一个统一的基准。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Continued advances in self-supervised learning have led to significant progress in video representation learning, offering a scalable alternative to supervised approaches by removing the need for manual annotations. Despite strong performance on standard action recognition benchmarks, video self-supervised learning methods are largely evaluated under narrow protocols, typically pretraining on Kinetics-400 and fine-tuning on similar datasets, limiting our understanding of their generalization in real world scenarios. In this work, we present a comprehensive evaluation of modern video self-supervised models, focusing on generalization across four key downstream factors: domain shift, sample efficiency, action granularity, and task diversity. Building on our prior work analyzing benchmark sensitivity in CNN-based contrastive learning, we extend the study to cover state-of-the-art transformer-based video-only and video-text models. Specifically, we benchmark 12 transformer-based methods (7 video-only, 5 video-text) and compare them to 10 CNN-based methods, totaling over 1100 experiments across 8 datasets and 7 downstream tasks. Our analysis shows that, despite architectural advances, transformer-based models remain sensitive to downstream conditions. No method generalizes consistently across all factors, video-only transformers perform better under domain shifts, CNNs outperform for fine-grained tasks, and video-text models often underperform despite large scale pretraining. We also find that recent transformer models do not consistently outperform earlier approaches. Our findings provide a detailed view of the strengths and limitations of current video SSL methods and offer a unified benchmark for evaluating generalization in video representation learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continued advances in self-supervised learning have led to significantprogress in video representation learning, offering a scalable alternative tosupervised approaches by removing the need for manual annotations. Despitestrong performance on standard action recognition benchmarks, videoself-supervised learning methods are largely evaluated under narrow protocols,typically pretraining on Kinetics-400 and fine-tuning on similar datasets,limiting our understanding of their generalization in real world scenarios. Inthis work, we present a comprehensive evaluation of modern videoself-supervised models, focusing on generalization across four key downstreamfactors: domain shift, sample efficiency, action granularity, and taskdiversity. Building on our prior work analyzing benchmark sensitivity inCNN-based contrastive learning, we extend the study to cover state-of-the-arttransformer-based video-only and video-text models. Specifically, we benchmark12 transformer-based methods (7 video-only, 5 video-text) and compare them to10 CNN-based methods, totaling over 1100 experiments across 8 datasets and 7downstream tasks. Our analysis shows that, despite architectural advances,transformer-based models remain sensitive to downstream conditions. No methodgeneralizes consistently across all factors, video-only transformers performbetter under domain shifts, CNNs outperform for fine-grained tasks, andvideo-text models often underperform despite large scale pretraining. We alsofind that recent transformer models do not consistently outperform earlierapproaches. Our findings provide a detailed view of the strengths andlimitations of current video SSL methods and offer a unified benchmark forevaluating generalization in video representation learning.</description>
      <author>example@mail.com (Fida Mohammad Thoker, Letian Jiang, Chen Zhao, Piyush Bagad, Hazel Doughty, Bernard Ghanem, Cees G. M. Snoek)</author>
      <guid isPermaLink="false">2504.05706v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Accelerated Reeds-Shepp and Under-Specified Reeds-Shepp Algorithms for Mobile Robot Path Planning</title>
      <link>http://arxiv.org/abs/2504.05921v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 27 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种简单直观的方法来加速最优Reeds-Shepp路径计算。&lt;h4&gt;背景&lt;/h4&gt;经典方法在Open Motion Planning Library中缺乏现代开源实现。&lt;h4&gt;目的&lt;/h4&gt;通过几何推理分析最优路径的行为，实现状态空间的新划分，并进一步减少可行的路径的最小集合。&lt;h4&gt;方法&lt;/h4&gt;重访和重新实现文献中的经典方法，作为评估新方法的基准。同时，解决了最终方向未指定的Reeds-Shepp规划问题。进行了全面实验以验证解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;与Open Motion Planning Library中原始Reeds-Shepp解决方案的现代C++实现相比，该方法实现了15倍的速度提升，而经典方法实现了5.79倍的速度提升。两种方法与原始解决方案相比，路径长度存在机器精度差异。&lt;h4&gt;结论&lt;/h4&gt;发布了对加速和未指定Reeds-Shepp问题的C++开源实现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TRO.2025.3554406&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we present a simple and intuitive method for acceleratingoptimal Reeds-Shepp path computation. Our approach uses geometrical reasoningto analyze the behavior of optimal paths, resulting in a new partitioning ofthe state space and a further reduction in the minimal set of viable paths. Werevisit and reimplement classic methodologies from the literature, which lackcontemporary open-source implementations, to serve as benchmarks for evaluatingour method. Additionally, we address the under-specified Reeds-Shepp planningproblem where the final orientation is unspecified. We perform exhaustiveexperiments to validate our solutions. Compared to the modern C++implementation of the original Reeds-Shepp solution in the Open Motion PlanningLibrary, our method demonstrates a 15x speedup, while classic methods achieve a5.79x speedup. Both approaches exhibit machine-precision differences in pathlengths compared to the original solution. We release our proposed C++implementations for both the accelerated and under-specified Reeds-Sheppproblems as open-source code.</description>
      <author>example@mail.com (Ibrahim Ibrahim, Wilm Decré, Jan Swevers)</author>
      <guid isPermaLink="false">2504.05921v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>A Multimedia Analytics Model for the Foundation Model Era</title>
      <link>http://arxiv.org/abs/2504.06138v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对基础模型时代的综合多媒体分析模型，旨在解决现有概念模型无法充分捕捉强大AI范式复杂性带来的问题。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型和代理人工智能的快速发展，多媒体分析正经历变革，但现有的视觉和多媒体分析概念模型不足以应对这种复杂性。&lt;h4&gt;目的&lt;/h4&gt;构建一个适用于基础模型时代的多媒体分析模型，以解决现有模型在处理复杂、高风险数据（如情报分析、调查性新闻等）中的实际问题。&lt;h4&gt;方法&lt;/h4&gt;基于视觉分析、多媒体分析、知识生成、分析任务定义、混合倡议指导和人机强化学习等框架，模型强调基于视觉分析代理的集成人机团队，并强调专家用户与半自主分析过程之间的无缝且明确可分离的交互通道。&lt;h4&gt;主要发现&lt;/h4&gt;模型通过详细案例研究展示了如何促进对多媒体分析解决方案的深入理解和针对性改进，并通过明确捕捉专家用户如何与AI驱动的多媒体分析系统进行最优交互和引导，为系统设计、比较和未来研究指明了方向。&lt;h4&gt;结论&lt;/h4&gt;该模型为系统设计、比较和未来研究提供了明确的方向，并有助于解决敏感领域中的实际问题，如情报分析和调查性新闻等。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advances in Foundation Models and agentic Artificial Intelligenceare transforming multimedia analytics by enabling richer, more sophisticatedinteractions between humans and analytical systems. Existing conceptual modelsfor visual and multimedia analytics, however, do not adequately capture thecomplexity introduced by these powerful AI paradigms. To bridge this gap, wepropose a comprehensive multimedia analytics model specifically designed forthe foundation model era. Building upon established frameworks from visualanalytics, multimedia analytics, knowledge generation, analytic taskdefinition, mixed-initiative guidance, and human-in-the-loop reinforcementlearning, our model emphasizes integrated human-AI teaming based on visualanalytics agents from both technical and conceptual perspectives. Central tothe model is a seamless, yet explicitly separable, interaction channel betweenexpert users and semi-autonomous analytical processes, ensuring continuousalignment between user intent and AI behavior. The model addresses practicalchallenges in sensitive domains such as intelligence analysis, investigativejournalism, and other fields handling complex, high-stakes data. We illustratethrough detailed case studies how our model facilitates deeper understandingand targeted improvement of multimedia analytics solutions. By explicitlycapturing how expert users can optimally interact with and guide AI-poweredmultimedia analytics systems, our conceptual framework sets a clear directionfor system design, comparison, and future research.</description>
      <author>example@mail.com (Marcel Worring, Jan Zahálka, Stef van den Elzen, Maximilian Fischer, Daniel Keim)</author>
      <guid isPermaLink="false">2504.06138v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>NativQA Framework: Enabling LLMs with Native, Local, and Everyday Knowledge</title>
      <link>http://arxiv.org/abs/2504.05995v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  LLMs, Native, Multilingual, Language Diversity, Contextual  Understanding, Minority Languages, Culturally Informed, Foundation Models,  Large Language Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NativQA的框架，旨在构建跨文化、跨地区的大规模问答数据集，用于评估和提升大型语言模型（LLMs）的能力。&lt;h4&gt;背景&lt;/h4&gt;随着大型语言模型（LLMs）的快速发展，其在文化偏见、公平性和不同语言及地区环境中的应用引起了担忧。&lt;h4&gt;目的&lt;/h4&gt;为了提升和评估LLMs的能力，需要开发关注多语言、本地和文化背景的大规模资源。&lt;h4&gt;方法&lt;/h4&gt;NativQA框架通过用户定义的种子查询，利用搜索引擎收集特定地点的日常信息，构建大规模的问答数据集。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在24个国家的39个地点，7种语言（从低资源到高资源语言）进行了评估，生成了超过30万个问答对。&lt;h4&gt;结论&lt;/h4&gt;开发出的资源可用于LLMs的基准测试和进一步微调，且该框架已向公众开放。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译：随着大型语言模型（LLMs）的快速发展，对其在文化偏见、公平性和在多样化语言及被代表不足的地区环境中的应用引发了担忧。为了提升和基准测试LLMs的能力，需要开发关注多语言、本地和文化背景的大规模资源。本研究提出了一种名为NativQA的框架，该框架能够无缝构建跨文化、跨地区的大规模、文化区域对齐的问答数据集。该框架利用用户定义的种子查询，并通过搜索引擎收集特定地点的日常信息。该框架已在24个国家的39个地点，涵盖7种语言（从极低资源到高资源语言）进行了评估，产生了超过30万个问答对。所开发资源可用于LLMs的基准测试和进一步微调。该框架已向公众开放（https://gitlab.com/nativqa/nativqa-framework）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of large language models (LLMs) has raised concernsabout cultural bias, fairness, and their applicability in diverse linguisticand underrepresented regional contexts. To enhance and benchmark thecapabilities of LLMs, there is a need to develop large-scale resources focusedon multilingual, local, and cultural contexts. In this study, we propose aframework, NativQA, that can seamlessly construct large-scale, culturally andregionally aligned QA datasets in native languages. The framework utilizesuser-defined seed queries and leverages search engines to collectlocation-specific, everyday information. It has been evaluated across 39locations in 24 countries and in 7 languages, ranging from extremelylow-resource to high-resource languages, which resulted over 300K QuestionAnswer (QA) pairs. The developed resources can be used for LLM benchmarking andfurther fine-tuning. The framework has been made publicly available for thecommunity (https://gitlab.com/nativqa/nativqa-framework).</description>
      <author>example@mail.com (Firoj Alam, Md Arid Hasan, Sahinur Rahman Laskar, Mucahid Kutlu, Shammur Absar Chowdhury)</author>
      <guid isPermaLink="false">2504.05995v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Robo-taxi Fleet Coordination at Scale via Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2504.06125v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 6 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种新的决策框架，用于解决大规模自主出行需求（AMoD）系统的协调问题，并通过公开可用的基准、数据集和模拟器以及开源代码库来促进该领域的研究民主化。&lt;h4&gt;背景&lt;/h4&gt;AMoD系统具有减少污染、能源消耗和城市拥堵的社会效益，但现有协调算法未能充分利用系统潜力。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合数学建模和数据驱动技术的决策框架，通过强化学习和图网络方法解决AMoD系统的协调问题。&lt;h4&gt;方法&lt;/h4&gt;使用图网络框架，结合图表示学习、强化学习和经典运筹学工具，并通过多种模拟场景和仿真忠实度进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在系统性能、计算效率和泛化能力方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;通过提供公开的基准、数据集、模拟器和开源代码库，论文旨在推动该领域的研究，并建立标准化的方法比较过程。&lt;h4&gt;翻译&lt;/h4&gt;Fleets of robo-taxis offering on-demand transportation services, commonly known as Autonomous Mobility-on-Demand (AMoD) systems, hold significant promise for societal benefits, such as reducing pollution, energy consumption, and urban congestion. However, orchestrating these systems at scale remains a critical challenge, with existing coordination algorithms often failing to exploit the systems' full potential. This work introduces a novel decision-making framework that unites mathematical modeling with data-driven techniques. In particular, we present the AMoD coordination problem through the lens of reinforcement learning and propose a graph network-based framework that exploits the main strengths of graph representation learning, reinforcement learning, and classical operations research tools. Extensive evaluations across diverse simulation fidelities and scenarios demonstrate the flexibility of our approach, achieving superior system performance, computational efficiency, and generalizability compared to prior methods. Finally, motivated by the need to democratize research efforts in this area, we release publicly available benchmarks, datasets, and simulators for network-level coordination alongside an open-source codebase designed to provide accessible simulation platforms and establish a standardized validation process for comparing methodologies. Code available at: https://github.com/StanfordASL/RL4AMOD&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fleets of robo-taxis offering on-demand transportation services, commonlyknown as Autonomous Mobility-on-Demand (AMoD) systems, hold significant promisefor societal benefits, such as reducing pollution, energy consumption, andurban congestion. However, orchestrating these systems at scale remains acritical challenge, with existing coordination algorithms often failing toexploit the systems' full potential. This work introduces a noveldecision-making framework that unites mathematical modeling with data-driventechniques. In particular, we present the AMoD coordination problem through thelens of reinforcement learning and propose a graph network-based framework thatexploits the main strengths of graph representation learning, reinforcementlearning, and classical operations research tools. Extensive evaluations acrossdiverse simulation fidelities and scenarios demonstrate the flexibility of ourapproach, achieving superior system performance, computational efficiency, andgeneralizability compared to prior methods. Finally, motivated by the need todemocratize research efforts in this area, we release publicly availablebenchmarks, datasets, and simulators for network-level coordination alongsidean open-source codebase designed to provide accessible simulation platforms andestablish a standardized validation process for comparing methodologies. Codeavailable at: https://github.com/StanfordASL/RL4AMOD</description>
      <author>example@mail.com (Luigi Tresca, Carolin Schmidt, James Harrison, Filipe Rodrigues, Gioele Zardini, Daniele Gammelli, Marco Pavone)</author>
      <guid isPermaLink="false">2504.06125v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>InvNeRF-Seg: Fine-Tuning a Pre-Trained NeRF for 3D Object Segmentation</title>
      <link>http://arxiv.org/abs/2504.05751v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Invariant NeRF for Segmentation (InvNeRFSeg)，这是一种两步零变化微调策略，用于3D场景的分割。&lt;h4&gt;背景&lt;/h4&gt;NeRF广泛用于从2D RGB图像中重建高质量的3D点云，但分割这些重建的3D场景对于下游任务（如物体计数、尺寸估计和场景理解）至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以实现从2D分割到高质量3D分割的有效转换。&lt;h4&gt;方法&lt;/h4&gt;首先在RGB图像上训练标准NeRF，然后使用2D分割掩码对其进行微调，而不改变模型架构或损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;该方法直接从精炼的辐射场产生更高质量、更干净的分割点云，且计算开销和复杂性最小。场密度分析显示，语义细化一致：物体区域的密度增加，背景密度被抑制，确保分割清晰且可解释。&lt;h4&gt;结论&lt;/h4&gt;InvNeRFSeg在合成水果和真实世界的大豆数据集上，在性能上优于SA3D和FruitNeRF，有效扩展了2D分割到高质量3D分割。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural Radiance Fields (NeRF) have been widely adopted for reconstructinghigh quality 3D point clouds from 2D RGB images. However, the segmentation ofthese reconstructed 3D scenes is more essential for downstream tasks such asobject counting, size estimation, and scene understanding. While segmentationon raw 3D point clouds using deep learning requires labor intensive andtime-consuming manual annotation, directly training NeRF on binary masks alsofails due to the absence of color and shading cues essential for geometrylearning. We propose Invariant NeRF for Segmentation (InvNeRFSeg), a two step,zero change fine tuning strategy for 3D segmentation. We first train a standardNeRF on RGB images and then fine tune it using 2D segmentation masks withoutaltering either the model architecture or loss function. This approach produceshigher quality, cleaner segmented point clouds directly from the refinedradiance field with minimal computational overhead or complexity. Field densityanalysis reveals consistent semantic refinement: densities of object regionsincrease while background densities are suppressed, ensuring clean andinterpretable segmentations. We demonstrate InvNeRFSegs superior performanceover both SA3D and FruitNeRF on both synthetic fruit and real world soybeandatasets. This approach effectively extends 2D segmentation to high quality 3Dsegmentation.</description>
      <author>example@mail.com (Jiangsan Zhao, Jakob Geipel, Krzysztof Kusnierek, Xuean Cui)</author>
      <guid isPermaLink="false">2504.05751v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Substructure-Aware Expert Model for Molecular Property Prediction</title>
      <link>http://arxiv.org/abs/2504.05844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ASE-Mol是一种基于图神经网络（GNN）的分子性质预测框架，通过混合专家（MoE）方法，结合BRICS分解和显著子结构意识，动态识别正负子结构，以解决数据不平衡和分子结构多样性带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;分子性质预测对于药物发现和毒性评估等应用至关重要。然而，传统的基于GNN的方法在数据不平衡和分子结构多样性面前存在泛化能力有限的问题。&lt;h4&gt;目的&lt;/h4&gt;提出ASE-Mol框架，旨在解决GNN在分子性质预测中的泛化能力问题，提高预测的准确性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;ASE-Mol采用MoE方法，结合BRICS分解和显著子结构意识，动态识别正负子结构，并整合MoE架构以减少负模式的影响，提高对正模式的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;在八个基准数据集上的实验结果表明，ASE-Mol在准确性和可解释性方面均取得了显著的提升，实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;ASE-Mol框架为分子性质预测提供了一种有效的方法，能够显著提高预测的准确性和可解释性，有望在药物发现和毒性评估等领域得到应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：分子性质预测对于药物发现和毒性评估等应用至关重要。虽然图神经网络（GNN）通过将分子建模为分子图表现出有希望的结果，但它们依赖于数据驱动学习，限制了它们的泛化能力，特别是在数据不平衡和不同的分子子结构存在的情况下。现有方法往往忽略了不同子结构对分子性质的贡献，对它们进行统一处理。为了解决这些挑战，我们提出了一种新的基于GNN的分子性质预测框架ASE-Mol，它利用混合专家（MoE）方法。ASE-Mol结合了BRICS分解和显著子结构意识，以动态识别正负子结构。通过整合MoE架构，它减少了负模式的不利影响，同时提高了对正模式的适应性。在八个基准数据集上的实验结果表明，ASE-Mol实现了最先进的性能，在准确性和可解释性方面都有显著提高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Molecular property prediction is essential for applications such as drugdiscovery and toxicity assessment. While Graph Neural Networks (GNNs) haveshown promising results by modeling molecules as molecular graphs, theirreliance on data-driven learning limits their ability to generalize,particularly in the presence of data imbalance and diverse molecularsubstructures. Existing methods often overlook the varying contributions ofdifferent substructures to molecular properties, treating them uniformly. Toaddress these challenges, we propose ASE-Mol, a novel GNN-based framework thatleverages a Mixture-of-Experts (MoE) approach for molecular propertyprediction. ASE-Mol incorporates BRICS decomposition and significantsubstructure awareness to dynamically identify positive and negativesubstructures. By integrating a MoE architecture, it reduces the adverse impactof negative motifs while improving adaptability to positive motifs.Experimental results on eight benchmark datasets demonstrate that ASE-Molachieves state-of-the-art performance, with significant improvements in bothaccuracy and interpretability.</description>
      <author>example@mail.com (Tianyi Jiang, Zeyu Wang, Shanqing Yu, Qi Xuan)</author>
      <guid isPermaLink="false">2504.05844v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>AVP-AP: Self-supervised Automatic View Positioning in 3D cardiac CT via Atlas Prompting</title>
      <link>http://arxiv.org/abs/2504.05966v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 8 figures, published to TMI&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AVP-AP的新型框架，用于在3D CT体中实现自动视角定位，以解决心脏CT检查中的疾病诊断和手术规划问题。&lt;h4&gt;背景&lt;/h4&gt;自动视角定位对于心脏CT检查至关重要，但由于个体差异和庞大的3D搜索空间，这一任务极具挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自动视角定位方法，以减少手动标注的工作量，并提高定位的准确性。&lt;h4&gt;方法&lt;/h4&gt;AVP-AP框架首先提出了一种图集提示方法，生成3D标准图集并训练网络通过自监督方式将切片映射到图集空间中的对应位置。然后，通过图集提示在参考CT中识别目标CT体中切片的大致位置，并最终通过最大化预测切片与查询图像在基础模型特征空间中的相似度来细化位置。&lt;h4&gt;主要发现&lt;/h4&gt;AVP-AP框架在任意视角定位中平均提高了19.8%的结构相似性（SSIM），在双心室视图定位中比四名放射科医生提高了9%的SSIM。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，AVP-AP框架在心脏CT检查中的自动视角定位方面具有灵活性和高效性，并且具有很好的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Automatic view positioning is crucial for cardiac computed tomography (CT) examinations, including disease diagnosis and surgical planning. However, it is highly challenging due to individual variability and large 3D search space. Existing work needs labor-intensive and time-consuming manual annotations to train view-specific models, which are limited to predicting only a fixed set of planes. However, in real clinical scenarios, the challenge of positioning semantic 2D slices with any orientation into varying coordinate space in arbitrary 3D volume remains unsolved. We thus introduce a novel framework, AVP-AP, the first to use Atlas Prompting for self-supervised Automatic View Positioning in the 3D CT volume. Specifically, this paper first proposes an atlas prompting method, which generates a 3D canonical atlas and trains a network to map slices into their corresponding positions in the atlas space via a self-supervised manner. Then, guided by atlas prompts corresponding to the given query images in a reference CT, we identify the coarse positions of slices in the target CT volume using rigid transformation between the 3D atlas and target CT volume, effectively reducing the search space. Finally, we refine the coarse positions by maximizing the similarity between the predicted slices and the query images in the feature space of a given foundation model. Our framework is flexible and efficient compared to other methods, outperforming other methods by 19.8% average structural similarity (SSIM) in arbitrary view positioning and achieving 9% SSIM in two-chamber view compared to four radiologists. Meanwhile, experiments on a public dataset validate our framework's generalizability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TMI.2025.3554785&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic view positioning is crucial for cardiac computed tomography (CT)examinations, including disease diagnosis and surgical planning. However, it ishighly challenging due to individual variability and large 3D search space.Existing work needs labor-intensive and time-consuming manual annotations totrain view-specific models, which are limited to predicting only a fixed set ofplanes. However, in real clinical scenarios, the challenge of positioningsemantic 2D slices with any orientation into varying coordinate space inarbitrary 3D volume remains unsolved. We thus introduce a novel framework,AVP-AP, the first to use Atlas Prompting for self-supervised Automatic ViewPositioning in the 3D CT volume. Specifically, this paper first proposes anatlas prompting method, which generates a 3D canonical atlas and trains anetwork to map slices into their corresponding positions in the atlas space viaa self-supervised manner. Then, guided by atlas prompts corresponding to thegiven query images in a reference CT, we identify the coarse positions ofslices in the target CT volume using rigid transformation between the 3D atlasand target CT volume, effectively reducing the search space. Finally, we refinethe coarse positions by maximizing the similarity between the predicted slicesand the query images in the feature space of a given foundation model. Ourframework is flexible and efficient compared to other methods, outperformingother methods by 19.8% average structural similarity (SSIM) in arbitrary viewpositioning and achieving 9% SSIM in two-chamber view compared to fourradiologists. Meanwhile, experiments on a public dataset validate ourframework's generalizability.</description>
      <author>example@mail.com (Xiaolin Fan, Yan Wang, Yingying Zhang, Mingkun Bao, Bosen Jia, Dong Lu, Yifan Gu, Jian Cheng, Haogang Zhu)</author>
      <guid isPermaLink="false">2504.05966v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Confidence Regularized Masked Language Modeling using Text Length</title>
      <link>http://arxiv.org/abs/2504.06037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的置信度正则化器，用于解决短文本输入时，掩码语言模型可能因过高置信单一答案而导致的准确性问题。&lt;h4&gt;背景&lt;/h4&gt;掩码语言模型是一种高效的文本表示学习方法，通过预测输入文本中随机掩码的词来学习语言表示。&lt;h4&gt;目的&lt;/h4&gt;旨在通过动态调整正则化强度来提高模型在短文本输入时的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种置信度正则化器，根据输入文本的长度动态控制正则化的强度。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在GLUE和SQuAD数据集上实现了更高的准确性和更低的期望校准误差。&lt;h4&gt;结论&lt;/h4&gt;该置信度正则化器能够有效提高短文本输入下的掩码语言模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Masked language modeling, which is a task to predict a randomly masked wordin the input text, is an efficient language representation learning method.Masked language modeling ignores various words which people can think of forfilling in the masked position and calculates the loss with a single word.Especially when the input text is short, the entropy of the word distributionthat can fill in the masked position can be high. This may cause the model tobe overconfident in the single answer. To address this issue, we propose anovel confidence regularizer that controls regularizing strength dynamically bythe input text length. Experiments with GLUE and SQuAD datasets showed that ourmethod achieves better accuracy and lower expected calibration error.</description>
      <author>example@mail.com (Seunghyun Ji, Soowon Lee)</author>
      <guid isPermaLink="false">2504.06037v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Models Enhanced Hyperbolic Space Recommender Systems</title>
      <link>http://arxiv.org/abs/2504.05694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HyperLLM的模型无关框架，用于推荐系统，通过在双曲空间中提取和整合文本和语义数据中的层次信息，显著提升了推荐性能。&lt;h4&gt;背景&lt;/h4&gt;现有方法在推荐系统中使用欧几里得空间，难以捕捉文本和语义数据中的丰富层次信息，而层次信息对于捕捉用户偏好至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种模型无关框架，HyperLLM，以有效提取和整合文本和语义数据中的层次信息。&lt;h4&gt;方法&lt;/h4&gt;HyperLLM从结构和语义两个角度提取和整合层次信息。结构上，使用LLM生成具有层次父子关系的多级分类标签；语义上，引入新的元优化策略，从语义嵌入中提取层次信息，并桥接语义和协同空间之间的差距。&lt;h4&gt;主要发现&lt;/h4&gt;HyperLLM在推荐性能上显著优于基于双曲空间和LLM的推荐系统，性能提升超过40%。此外，HyperLLM不仅提高了推荐性能，还增强了训练稳定性。&lt;h4&gt;结论&lt;/h4&gt;层次信息在推荐系统中起着关键作用，HyperLLM通过有效利用层次信息，显著提升了推荐系统的性能和训练稳定性。&lt;h4&gt;翻译&lt;/h4&gt;Large Language Models (LLMs) have attracted significant attention inrecommender systems for their excellent world knowledge capabilities. However,existing methods that rely on Euclidean space struggle to capture the richhierarchical information inherent in textual and semantic data, which isessential for capturing user preferences. The geometric properties ofhyperbolic space offer a promising solution to address this issue. Nevertheless,integrating LLMs-based methods with hyperbolic space to effectively extract andincorporate diverse hierarchical information is non-trivial. To this end, we propose amodel-agnostic framework, named HyperLLM, which extracts and integrateshierarchical information from both structural and semantic perspectives. Structurally,HyperLLM uses LLMs to generate multi-level classification tags with hierarchicalparent-child relationships for each item. Then, tag-item and user-item interactionsare jointly learned and aligned through contrastive learning, thereby providing themodel with clear hierarchical information. Semantically, HyperLLM introduces a novelmeta-optimized strategy to extract hierarchical information from semantic embeddingsand bridge the gap between the semantic and collaborative spaces for seamlessintegration. Extensive experiments show that HyperLLM significantly outperformsrecommender systems based on hyperbolic space and LLMs, achieving performanceimprovements of over 40%. Furthermore, HyperLLM not only improves recommenderperformance but also enhances training stability, highlighting the critical role ofhierarchical information in recommender systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have attracted significant attention inrecommender systems for their excellent world knowledge capabilities. However,existing methods that rely on Euclidean space struggle to capture the richhierarchical information inherent in textual and semantic data, which isessential for capturing user preferences. The geometric properties ofhyperbolic space offer a promising solution to address this issue.Nevertheless, integrating LLMs-based methods with hyperbolic space toeffectively extract and incorporate diverse hierarchical information isnon-trivial. To this end, we propose a model-agnostic framework, namedHyperLLM, which extracts and integrates hierarchical information from bothstructural and semantic perspectives. Structurally, HyperLLM uses LLMs togenerate multi-level classification tags with hierarchical parent-childrelationships for each item. Then, tag-item and user-item interactions arejointly learned and aligned through contrastive learning, thereby providing themodel with clear hierarchical information. Semantically, HyperLLM introduces anovel meta-optimized strategy to extract hierarchical information from semanticembeddings and bridge the gap between the semantic and collaborative spaces forseamless integration. Extensive experiments show that HyperLLM significantlyoutperforms recommender systems based on hyperbolic space and LLMs, achievingperformance improvements of over 40%. Furthermore, HyperLLM not only improvesrecommender performance but also enhances training stability, highlighting thecritical role of hierarchical information in recommender systems.</description>
      <author>example@mail.com (Wentao Cheng, Zhida Qin, Zexue Wu, Pengzhan Zhou, Tianyu Huang)</author>
      <guid isPermaLink="false">2504.05694v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Enhancing Ensemble Forecasts of Extreme Rainfall</title>
      <link>http://arxiv.org/abs/2504.05471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted paper at ICLR 2025 - Tackling Climate Change with Machine  Learning Workshop (https://www.climatechange.ai/events/iclr2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用图神经网络后处理集合预报的方法，以改善极端降水事件的预报准确性，从而提高预报的可靠性并减轻极端降水和洪水风险。&lt;h4&gt;背景&lt;/h4&gt;气候变化导致极端降水事件增多，威胁基础设施、农业和公共安全。集合预报系统提供概率预报，但存在偏差和难以捕捉极端天气的问题。&lt;h4&gt;目的&lt;/h4&gt;提高极端降水事件的预报准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新型框架，利用图神经网络后处理集合预报，特别建模了潜在分布的极端值，以捕捉空间依赖性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够捕捉空间依赖性，并提高极端事件的预报准确性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够提高预报的可靠性，减轻极端降水和洪水风险。&lt;h4&gt;翻译&lt;/h4&gt;Climate change is increasing the occurrence of extreme precipitation events, threatening infrastructure, agriculture, and public safety. Ensemble prediction systems provide probabilistic forecasts but exhibit biases and difficulties in capturing extreme weather. While post-processing techniques aim to enhance forecast accuracy, they rarely focus on precipitation, which exhibits complex spatial dependencies and tail behavior. Our novel framework leverages graph neural networks to post-process ensemble forecasts, specifically modeling the extremes of the underlying distribution. This allows to capture spatial dependencies and improves forecast accuracy for extreme events, thus leading to more reliable forecasts and mitigating risks of extreme precipitation and flooding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Climate change is increasing the occurrence of extreme precipitation events,threatening infrastructure, agriculture, and public safety. Ensemble predictionsystems provide probabilistic forecasts but exhibit biases and difficulties incapturing extreme weather. While post-processing techniques aim to enhanceforecast accuracy, they rarely focus on precipitation, which exhibits complexspatial dependencies and tail behavior. Our novel framework leverages graphneural networks to post-process ensemble forecasts, specifically modeling theextremes of the underlying distribution. This allows to capture spatialdependencies and improves forecast accuracy for extreme events, thus leading tomore reliable forecasts and mitigating risks of extreme precipitation andflooding.</description>
      <author>example@mail.com (Christopher Bülte, Sohir Maskey, Philipp Scholl, Jonas von Berg, Gitta Kutyniok)</author>
      <guid isPermaLink="false">2504.05471v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Decoupled Representation Learning and Regularization for Speech-Preserving Facial Expression Manipulation</title>
      <link>http://arxiv.org/abs/2504.05672v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Speech-preserving facial expression manipulation (SPFEM)的技术，旨在在不改变原始语音内容口型动画的情况下，使说话头表现出特定的参考情感。&lt;h4&gt;背景&lt;/h4&gt;在SPFEM中，参考和源输入中存在的情感和内容信息可以提供直接且准确的监督信号，但说话过程中这些元素的内在交织对作为监督信号的有效性构成了挑战。&lt;h4&gt;目的&lt;/h4&gt;该工作的目的是通过学习内容与情感先验，结合对比学习，来学习解耦的内容和情感表示，从而实现更精确的情感操控。&lt;h4&gt;方法&lt;/h4&gt;论文提出了ContrastiveDecoupled Representation Learning (CDRL)算法，包括ContrastiveContent Representation Learning (CCRL)模块和ContrastiveEmotion Representation Learning (CERL)模块，分别用于学习内容先验和情感先验，并引入情感感知和情感增强的对比学习来训练这些模块。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验和评估，该算法在多个基准测试中显示出了有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够确保学习到情感独立的内容表示和内容独立的情感表示，从而在SPFEM模型训练中实现更准确的情感操控和音频唇同步。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语音保留面部表情操纵（SPFEM）旨在修改一个说话头以显示特定的参考情感，同时保留源语音内容的口型动画。因此，参考和源输入中存在的情感和内容信息可以提供直接且准确的监督信号，用于SPFEM模型。然而，这些元素在说话过程中的内在交织对它们作为监督信号的有效性构成了挑战。在本工作中，我们提出通过对比学习来学习内容与情感先验，作为指导，通过创新的对比解耦表示学习（CDRL）算法来学习解耦的内容和情感表示。具体来说，设计了一个对比内容表示学习（CCRL）模块，用于学习包含主要内容信息的声音特征，作为内容先验，以指导从源输入中学习内容表示。同时，提出了一种对比情感表示学习（CERL）模块，利用预训练的视觉语言模型来学习情感先验，然后用于指导从参考输入中学习情感表示。我们进一步引入了情感感知和情感增强的对比学习来分别训练CCRL和CERL模块，确保学习到情感独立的内容表示和内容独立的情感表示。在SPFEM模型训练期间，使用解耦的内容和情感表示来监督生成过程，确保更准确的情感操控和音频唇同步。在多个基准测试上的广泛实验和评估显示了所提出算法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech-preserving facial expression manipulation (SPFEM) aims to modify atalking head to display a specific reference emotion while preserving the mouthanimation of source spoken contents. Thus, emotion and content informationexisting in reference and source inputs can provide direct and accuratesupervision signals for SPFEM models. However, the intrinsic intertwining ofthese elements during the talking process poses challenges to theireffectiveness as supervisory signals. In this work, we propose to learn contentand emotion priors as guidance augmented with contrastive learning to learndecoupled content and emotion representation via an innovative ContrastiveDecoupled Representation Learning (CDRL) algorithm. Specifically, a ContrastiveContent Representation Learning (CCRL) module is designed to learn audiofeature, which primarily contains content information, as content priors toguide learning content representation from the source input. Meanwhile, aContrastive Emotion Representation Learning (CERL) module is proposed to makeuse of a pre-trained visual-language model to learn emotion prior, which isthen used to guide learning emotion representation from the reference input. Wefurther introduce emotion-aware and emotion-augmented contrastive learning totrain CCRL and CERL modules, respectively, ensuring learningemotion-independent content representation and content-independent emotionrepresentation. During SPFEM model training, the decoupled content and emotionrepresentations are used to supervise the generation process, ensuring moreaccurate emotion manipulation together with audio-lip synchronization.Extensive experiments and evaluations on various benchmarks show theeffectiveness of the proposed algorithm.</description>
      <author>example@mail.com (Tianshui Chen, Jianman Lin, Zhijing Yang, Chumei Qing, Yukai Shi, Liang Lin)</author>
      <guid isPermaLink="false">2504.05672v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>SAP-CoPE: Social-Aware Planning using Cooperative Pose Estimation with Infrastructure Sensor Nodes</title>
      <link>http://arxiv.org/abs/2504.05727v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been submitted to the IEEE Transactions on Industrial  Electronics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SAP-CoPE的社会感知规划框架，旨在解决自动驾驶系统在人口密集室内环境中感知受限和遮挡敏感等问题，以提高系统的安全性、舒适性。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶系统在室内环境中面临感知局限和遮挡问题，这给准确识别人类意图和生成舒适的社会感知轨迹带来了困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种社会感知规划框架，以解决自动驾驶系统在室内环境中的安全问题。&lt;h4&gt;方法&lt;/h4&gt;SAP-CoPE框架集成了合作基础设施、新颖的3D人体姿态估计方法和基于模型预测控制的控制器。该框架考虑了相机投影矩阵中的不确定性传播，并确保了人类关节的一致性。该框架适用于单摄像头或多摄像头配置，并能整合稀疏的LiDAR点云数据。此外，通过将基于人体姿态的人类个人空间场集成到模型预测控制器中，增强了系统的安全性和舒适性。&lt;h4&gt;主要发现&lt;/h4&gt;SAP-CoPE框架能够生成社会感知轨迹，并在模拟和现实世界环境中进行了广泛的评估，证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;SAP-CoPE框架能够有效提高自动驾驶系统在室内环境中的安全性和舒适性。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Autonomous driving systems must operate safely in human-populated indoor environments, where challenges such as limited perception and occlusion sensitivity arise when relying solely on onboard sensors. These factors generate difficulties in the accurate recognition of human intentions and the generation of comfortable, socially aware trajectories. To address these issues, we propose SAP-CoPE, a social-aware planning framework that integrates cooperative infrastructure with a novel 3D human pose estimation method and a model predictive control-based controller. This real-time framework formulates an optimization problem that accounts for uncertainty propagation in the camera projection matrix while ensuring human joint coherence. The proposed method is adaptable to single- or multi-camera configurations and can incorporate sparse LiDAR point-cloud data. To enhance safety and comfort in human environments, we integrate a human personal space field based on human pose into a model predictive controller, enabling the system to navigate while avoiding discomfort zones. Extensive evaluations in both simulated and real-world settings demonstrate the effectiveness of our approach in generating socially aware trajectories for autonomous systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/HopeYless/SAP-CoPE-Project&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous driving systems must operate safely in human-populated indoorenvironments, where challenges such as limited perception and occlusionsensitivity arise when relying solely on onboard sensors. These factorsgenerate difficulties in the accurate recognition of human intentions and thegeneration of comfortable, socially aware trajectories. To address theseissues, we propose SAP-CoPE, a social-aware planning framework that integratescooperative infrastructure with a novel 3D human pose estimation method and amodel predictive control-based controller. This real-time framework formulatesan optimization problem that accounts for uncertainty propagation in the cameraprojection matrix while ensuring human joint coherence. The proposed method isadaptable to single- or multi-camera configurations and can incorporate sparseLiDAR point-cloud data. To enhance safety and comfort in human environments, weintegrate a human personal space field based on human pose into a modelpredictive controller, enabling the system to navigate while avoidingdiscomfort zones. Extensive evaluations in both simulated and real-worldsettings demonstrate the effectiveness of our approach in generating sociallyaware trajectories for autonomous systems.</description>
      <author>example@mail.com (Minghao Ning, Yufeng Yang, Shucheng Huang, Jiaming Zhong, Keqi Shu, Chen Sun, Ehsan Hashemi, Amir Khajepour)</author>
      <guid isPermaLink="false">2504.05727v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Dual Boost-Driven Graph-Level Clustering Network</title>
      <link>http://arxiv.org/abs/2504.05670v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图级聚类网络DBGCN，旨在解决图学习中的图级聚类问题。&lt;h4&gt;背景&lt;/h4&gt;图级聚类在图学习中是一个关键且具有挑战性的问题。虽然深度学习与表示学习的结合带来了一定程度的性能提升，但现有方法存在噪声和特征传播过程中的噪声聚合问题，导致聚类性能不理想。&lt;h4&gt;目的&lt;/h4&gt;提出DBGCN旨在通过交替促进图级聚类和过滤干扰信息来提高图级聚类性能。&lt;h4&gt;方法&lt;/h4&gt;DBGCN在池化步骤中评估全局特征的贡献，并使用可学习的转换矩阵优化特征，以获得高质量的图级表示。此外，通过评估图级表示之间的相似性，识别并抑制对聚类有害的信息，以提供更准确的视图融合指导。&lt;h4&gt;主要发现&lt;/h4&gt;DBGCN在六个基准数据集上优于现有的图级聚类方法。&lt;h4&gt;结论&lt;/h4&gt;DBGCN是一种有效的图级聚类方法，可以显著提高聚类性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-level clustering remains a pivotal yet formidable challenge in graphlearning. Recently, the integration of deep learning with representationlearning has demonstrated notable advancements, yielding performanceenhancements to a certain degree. However, existing methods suffer from atleast one of the following issues: 1. the original graph structure has noise,and 2. during feature propagation and pooling processes, noise is graduallyaggregated into the graph-level embeddings through information propagation.Consequently, these two limitations mask clustering-friendly information,leading to suboptimal graph-level clustering performance. To this end, wepropose a novel Dual Boost-Driven Graph-Level Clustering Network (DBGCN) toalternately promote graph-level clustering and filtering out interferenceinformation in a unified framework. Specifically, in the pooling step, weevaluate the contribution of features at the global and optimize them using alearnable transformation matrix to obtain high-quality graph-levelrepresentation, such that the model's reasoning capability can be improved.Moreover, to enable reliable graph-level clustering, we first identify andsuppress information detrimental to clustering by evaluating similaritiesbetween graph-level representations, providing more accurate guidance formulti-view fusion. Extensive experiments demonstrated that DBGCN outperformsthe state-of-the-art graph-level clustering methods on six benchmark datasets.</description>
      <author>example@mail.com (John Smith, Wenxuan Tu, Junlong Wu, Wenxin Zhang, Jingxin Liu, Haotian Wang, Jieren Cheng, Huajie Lei, Guangzhen Yao, Lingren Wang, Mengfei Li, Renda Han, Yu Li)</author>
      <guid isPermaLink="false">2504.05670v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>KAN-SAM: Kolmogorov-Arnold Network Guided Segment Anything Model for RGB-T Salient Object Detection</title>
      <link>http://arxiv.org/abs/2504.05878v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is accepted by ICME2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为KAN-SAM的新型基于提示学习的RGB-热显著目标检测方法，通过引入热特征和Kolmogorov-Arnold网络（KAN）适配器，有效地增强了RGB表示并提高了鲁棒性，同时通过随机掩码策略改善了泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的RGB-热显著目标检测方法在复杂场景中表现良好，但由于数据集多样性有限和多模态表示的效率问题，其泛化能力有限。&lt;h4&gt;目的&lt;/h4&gt;提高RGB-热显著目标检测方法的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;1. 使用Segment Anything Model 2（SAM2）进行RGB-T SOD，引入热特征作为指导提示；2. 通过KAN适配器高效准确地增强RGB表示；3. 引入互斥随机掩码策略以减少对RGB数据的依赖。&lt;h4&gt;主要发现&lt;/h4&gt;KAN-SAM方法在基准测试中表现出比现有方法更优越的性能。&lt;h4&gt;结论&lt;/h4&gt;KAN-SAM方法通过结合视觉基础模型和高效的特征增强策略，显著提高了RGB-热显著目标检测的泛化能力和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing RGB-thermal salient object detection (RGB-T SOD) methods aim toidentify visually significant objects by leveraging both RGB and thermalmodalities to enable robust performance in complex scenarios, but they oftensuffer from limited generalization due to the constrained diversity ofavailable datasets and the inefficiencies in constructing multi-modalrepresentations. In this paper, we propose a novel prompt learning-based RGB-TSOD method, named KAN-SAM, which reveals the potential of visual foundationalmodels for RGB-T SOD tasks. Specifically, we extend Segment Anything Model 2(SAM2) for RGB-T SOD by introducing thermal features as guiding prompts throughefficient and accurate Kolmogorov-Arnold Network (KAN) adapters, whicheffectively enhance RGB representations and improve robustness. Furthermore, weintroduce a mutually exclusive random masking strategy to reduce reliance onRGB data and improve generalization. Experimental results on benchmarksdemonstrate superior performance over the state-of-the-art methods.</description>
      <author>example@mail.com (Xingyuan Li, Ruichao Hou, Tongwei Ren, Gangshan Wu)</author>
      <guid isPermaLink="false">2504.05878v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Point-based Instance Completion with Scene Constraints</title>
      <link>http://arxiv.org/abs/2504.05698v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于点云的实例补全模型，能够鲁棒地在场景中补全任意尺度和大小的物体，并引入了场景约束以提升补全质量。&lt;h4&gt;背景&lt;/h4&gt;现有的点基于物体补全方法在场景补全方面存在局限性，如不考虑场景约束和期望输入在规范坐标系中。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法的局限性，提出一种新的点云基于实例补全模型，能够考虑场景约束并提高补全质量。&lt;h4&gt;方法&lt;/h4&gt;引入了表示场景约束的点云，并通过交叉注意力机制将其整合到补全模型中。构建了新的数据集ScanWCF，用于评估实例场景补全任务。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在部分扫描的保真度、补全质量和合理性方面优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的模型能够有效地补全场景中的物体，并提高了补全质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent point-based object completion methods have demonstrated the ability toaccurately recover the missing geometry of partially observed objects. However,these approaches are not well-suited for completing objects within a scene, asthey do not consider known scene constraints (e.g., other observed surfaces) intheir completions and further expect the partial input to be in a canonicalcoordinate system, which does not hold for objects within scenes. Whileinstance scene completion methods have been proposed for completing objectswithin a scene, they lag behind point-based object completion methods in termsof object completion quality and still do not consider known scene constraintsduring completion. To overcome these limitations, we propose a pointcloud-based instance completion model that can robustly complete objects atarbitrary scales and pose in the scene. To enable reasoning at the scene level,we introduce a sparse set of scene constraints represented as point clouds andintegrate them into our completion model via a cross-attention mechanism. Toevaluate the instance scene completion task on indoor scenes, we further builda new dataset called ScanWCF, which contains labeled partial scans as well asaligned ground truth scene completions that are watertight and collision-free.Through several experiments, we demonstrate that our method achieves improvedfidelity to partial scans, higher completion quality, and greater plausibilityover existing state-of-the-art methods.</description>
      <author>example@mail.com (Wesley Khademi, Li Fuxin)</author>
      <guid isPermaLink="false">2504.05698v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>GraphPINE: Graph Importance Propagation for Interpretable Drug Response Prediction</title>
      <link>http://arxiv.org/abs/2504.05454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GraphPINE的图神经网络架构，用于药物反应预测，该架构利用领域特定的先验知识来初始化节点重要性，并在训练过程中优化。&lt;h4&gt;背景&lt;/h4&gt;可解释性对于生物医学研究中的许多任务至关重要。现有的可解释性方法主要集中在注意力、梯度和Shapley值上，但这些方法无法处理具有强烈相关先验知识的数据，并且无法根据已知预测特征之间的关系来约束可解释性结果。&lt;h4&gt;目的&lt;/h4&gt;提出GraphPINE以克服现有方法的局限性，并提高药物反应预测的可解释性。&lt;h4&gt;方法&lt;/h4&gt;GraphPINE利用类似于LSTM的顺序格式，并引入了一个重要性传播层，该层统一了特征矩阵和节点重要性的更新，并使用基于GNN的图传播特征值。这种方法允许进行有信息的特征学习和改进的图表示。&lt;h4&gt;主要发现&lt;/h4&gt;GraphPINE在癌症药物反应预测中取得了PR-AUC为0.894和ROC-AUC为0.796的结果，涵盖了952种药物。&lt;h4&gt;结论&lt;/h4&gt;GraphPINE通过结合先验知识和图神经网络技术，为药物反应预测提供了更可解释的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：可解释性对于生物医学研究中的许多任务至关重要。最近的可解释性方法主要集中在注意力、梯度和Shapley值上。这些方法不处理具有强烈相关先验知识的数据，并且无法根据已知预测特征之间的关系来约束可解释性结果。我们提出了GraphPINE，一种利用领域特定先验知识初始化节点重要性并在训练过程中优化的图神经网络架构。通常，一个手动后预测步骤检查文献（即先验知识）以了解返回的预测特征。虽然可以在预测后获得梯度和注意力的节点重要性，但这些方法中的节点重要性缺乏补充先验知识；GraphPINE试图克服这一局限性。GraphPINE与其他GNN门控方法的不同之处在于利用了类似于LSTM的顺序格式。我们引入了一个重要性传播层，该层统一了1）特征矩阵和节点重要性的更新，2）使用基于GNN的图传播特征值。这种初始化和更新机制允许进行有信息的特征学习和改进的图表示。我们将GraphPINE应用于癌症药物反应预测，使用药物筛选和基因数据，这些数据来自包含超过5000个基因节点的基因-基因图，以及用于初始重要性的药物-靶点相互作用（DTI）图。基因-基因图和DTI来自经过精选的来源，并按讨论药物和基因之间关系的文章数量进行加权。GraphPINE在952种药物上实现了PR-AUC为0.894和ROC-AUC为0.796。代码可在https://anonymous.4open.science/r/GraphPINE-40DE上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Explainability is necessary for many tasks in biomedical research. Recentexplainability methods have focused on attention, gradient, and Shapley value.These do not handle data with strong associated prior knowledge and fail toconstrain explainability results based on known relationships betweenpredictive features.  We propose GraphPINE, a graph neural network (GNN) architecture leveragingdomain-specific prior knowledge to initialize node importance optimized duringtraining for drug response prediction. Typically, a manual post-prediction stepexamines literature (i.e., prior knowledge) to understand returned predictivefeatures. While node importance can be obtained for gradient and attentionafter prediction, node importance from these methods lacks complementary priorknowledge; GraphPINE seeks to overcome this limitation. GraphPINE differs fromother GNN gating methods by utilizing an LSTM-like sequential format. Weintroduce an importance propagation layer that unifies 1) updates for featurematrix and node importance and 2) uses GNN-based graph propagation of featurevalues. This initialization and updating mechanism allows for informed featurelearning and improved graph representation.  We apply GraphPINE to cancer drug response prediction using drug screeningand gene data collected for over 5,000 gene nodes included in a gene-gene graphwith a drug-target interaction (DTI) graph for initial importance. Thegene-gene graph and DTIs were obtained from curated sources and weighted byarticle count discussing relationships between drugs and genes. GraphPINEachieves a PR-AUC of 0.894 and ROC-AUC of 0.796 across 952 drugs. Code isavailable at https://anonymous.4open.science/r/GraphPINE-40DE.</description>
      <author>example@mail.com (Yoshitaka Inoue, Tianfan Fu, Augustin Luna)</author>
      <guid isPermaLink="false">2504.05454v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>DefMamba: Deformable Visual State Space Model</title>
      <link>http://arxiv.org/abs/2504.05794v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的视觉基础模型DefMamba，通过多尺度骨干结构和可变形Mamba（DM）块，动态调整扫描路径，以提高图像结构学习和对物体细节变化的检测能力。&lt;h4&gt;背景&lt;/h4&gt;状态空间模型（SSM）特别是Mamba因其平衡计算效率和性能的能力而受到关注。然而，现有的视觉Mamba方法大多使用预定义的扫描顺序将图像平面化为1D序列，导致模型无法充分利用图像的空间结构信息。&lt;h4&gt;目的&lt;/h4&gt;提出DefMamba模型以解决上述问题，增强模型对图像空间结构信息的利用。&lt;h4&gt;方法&lt;/h4&gt;DefMamba模型包含一个多尺度骨干结构和可变形Mamba（DM）块，以及可变形扫描（DS）策略，以动态调整扫描路径并优先处理重要信息。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，DefMamba在图像分类、目标检测、实例分割和语义分割等视觉任务中实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;DefMamba模型通过改进图像结构和细节变化的检测能力，在视觉任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Recently, state space models (SSM), particularly Mamba, have attracted significant attention from scholars due to their ability to effectively balance computational efficiency and performance. However, most existing visual Mamba methods flatten images into 1D sequences using predefined scan orders, which results in the model being less capable of utilizing the spatial structural information of the image during the feature extraction process. To address this issue, we proposed a novel visual foundation model called DefMamba. This model includes a multi-scale backbone structure and deformable mamba (DM) blocks, which dynamically adjust the scanning path to prioritize important information, thus enhancing the capture and processing of relevant input features. By combining a deformable scanning (DS) strategy, this model significantly improves its ability to learn image structures and detects changes in object details. Numerous experiments have shown that DefMamba achieves state-of-the-art performance in various visual tasks, including image classification, object detection, instance segmentation, and semantic segmentation. The code is open source on DefMamba.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, state space models (SSM), particularly Mamba, have attractedsignificant attention from scholars due to their ability to effectively balancecomputational efficiency and performance. However, most existing visual Mambamethods flatten images into 1D sequences using predefined scan orders, whichresults the model being less capable of utilizing the spatial structuralinformation of the image during the feature extraction process. To address thisissue, we proposed a novel visual foundation model called DefMamba. This modelincludes a multi-scale backbone structure and deformable mamba (DM) blocks,which dynamically adjust the scanning path to prioritize important information,thus enhancing the capture and processing of relevant input features. Bycombining a deformable scanning(DS) strategy, this model significantly improvesits ability to learn image structures and detects changes in object details.Numerous experiments have shown that DefMamba achieves state-of-the-artperformance in various visual tasks, including image classification, objectdetection, instance segmentation, and semantic segmentation. The code is opensource on DefMamba.</description>
      <author>example@mail.com (Leiye Liu, Miao Zhang, Jihao Yin, Tingwei Liu, Wei Ji, Yongri Piao, Huchuan Lu)</author>
      <guid isPermaLink="false">2504.05794v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>A Novel Approach to Linking Histology Images with DNA Methylation</title>
      <link>http://arxiv.org/abs/2504.05403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于图神经网络的弱监督学习框架，用于预测具有一致模式基因组的甲基化状态，并通过分析TCGA数据集，证明了该方法在预测甲基化状态方面的优越性。&lt;h4&gt;背景&lt;/h4&gt;DNA甲基化是一种表观遗传机制，通过向DNA添加甲基基团来调节基因表达。异常的甲基化模式与癌症发展有关。目前常用的DNA甲基化检测方法成本高、处理时间长，限制了其在临床实践中的应用。&lt;h4&gt;目的&lt;/h4&gt;探索全切片图像（WSIs）与DNA甲基化模式之间的关系，以降低检测成本和时间。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于端到端图神经网络的弱监督学习框架，并使用来自TCGA的三组数据（LGG、GBM和KIRC）进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在预测甲基化状态方面比现有方法提高了超过20%的AUROC分数，基因集富集分析显示大多数基因组在重要特征和通路中显著富集，并通过空间富集热图进一步研究了组织学模式与DNA甲基化状态之间的联系。&lt;h4&gt;结论&lt;/h4&gt;这是首次使用弱监督深度学习探索空间解析组织学模式与基因组甲基化状态之间关联的研究，为癌症的甲基化检测提供了新的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：DNA甲基化是一种表观遗传机制，通过向DNA添加甲基基团来调节基因表达。异常的甲基化模式与癌症发展有关。为了量化DNA甲基化，通常使用专门的检测方法。然而，这些方法通常成本高、处理时间长，限制了它们在常规临床实践中的广泛应用。相比之下，大多数癌症患者的全切片图像（WSIs）可以更容易地获得。因此，鉴于WSIs的易于获取，有必要探索WSIs与DNA甲基化模式之间的潜在关系。为了解决这个问题，我们提出了一种基于端到端图神经网络的弱监督学习框架，用于预测表现出样本间一致模式的基因组的甲基化状态。使用来自癌症基因组图谱（TCGA）的三个队列（TCGA-LGG（脑低级别胶质瘤）、TCGA-GBM（多形性胶质母细胞瘤）和TCGA-KIRC（肾肾细胞癌））的数据，我们证明了所提出的方法在预测甲基化状态方面比最先进（SOTA）方法提高了显著更高的AUROC分数，超过20%。我们对基因组进行了基因集富集分析，并显示大多数基因组在重要特征和通路中显著富集。我们还生成了空间富集热图，以进一步研究组织学模式与DNA甲基化状态之间的联系。据我们所知，这是首次使用弱监督深度学习探索空间解析组织学模式与基因组甲基化状态之间关联的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; DNA methylation is an epigenetic mechanism that regulates gene expression byadding methyl groups to DNA. Abnormal methylation patterns can disrupt geneexpression and have been linked to cancer development. To quantify DNAmethylation, specialized assays are typically used. However, these assays areoften costly and have lengthy processing times, which limits their widespreadavailability in routine clinical practice. In contrast, whole slide images(WSIs) for the majority of cancer patients can be more readily available. Assuch, given the ready availability of WSIs, there is a compelling need toexplore the potential relationship between WSIs and DNA methylation patterns.To address this, we propose an end-to-end graph neural network based weaklysupervised learning framework to predict the methylation state of gene groupsexhibiting coherent patterns across samples. Using data from three cohorts fromThe Cancer Genome Atlas (TCGA) - TCGA-LGG (Brain Lower Grade Glioma), TCGA-GBM(Glioblastoma Multiforme) ($n$=729) and TCGA-KIRC (Kidney Renal Clear CellCarcinoma) ($n$=511) - we demonstrate that the proposed approach achievessignificantly higher AUROC scores than the state-of-the-art (SOTA) methods, bymore than $20\%$. We conduct gene set enrichment analyses on the gene groupsand show that majority of the gene groups are significantly enriched inimportant hallmarks and pathways. We also generate spatially enriched heatmapsto further investigate links between histological patterns and DNA methylationstates. To the best of our knowledge, this is the first study that exploresassociation of spatially resolved histological patterns with gene groupmethylation states across multiple cancer types using weakly supervised deeplearning.</description>
      <author>example@mail.com (Manahil Raza, Muhammad Dawood, Talha Qaiser, Nasir M. Rajpoot)</author>
      <guid isPermaLink="false">2504.05403v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>ViralQC: A Tool for Assessing Completeness and Contamination of Predicted Viral Contigs</title>
      <link>http://arxiv.org/abs/2504.05790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ViralQC的工具，用于评估病毒contigs或bins的质量。&lt;h4&gt;背景&lt;/h4&gt;病毒是地球上最丰富的生物实体，在多种生态系统中扮演着重要角色。对病毒进行分类对于理解其特性和功能至关重要。宏基因组测序已成为病毒发现的最全面方法，但它区分病毒序列与细胞来源的序列仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，开发一个准确且高效的评估病毒contigs质量的方法。&lt;h4&gt;方法&lt;/h4&gt;ViralQC通过在病毒和细胞基因组上训练的基础模型识别潜在病毒序列中的污染区域，并通过蛋白质组织对齐来估计病毒完整性。&lt;h4&gt;主要发现&lt;/h4&gt;ViralQC在多个数据集上进行了评估，并与病毒质量评估的领先工具CheckV进行了比较。ViralQC正确识别了比CheckV多38%的污染，同时保持了中值绝对误差仅为3%。此外，ViralQC对中等至高质量（&gt;50%完整性）的contigs提供了更准确的结果，证明了其在完整性估计方面的优越性能。&lt;h4&gt;结论&lt;/h4&gt;ViralQC是一个准确且高效的工具，可以用于评估病毒contigs的质量，特别是在完整性估计方面表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivation: Viruses represent the most abundant biological entities on theplanet and play vital roles in diverse ecosystems. Cataloging viruses acrossvarious environments is essential for understanding their properties andfunctions. Metagenomic sequencing has emerged as the most comprehensive methodfor virus discovery, enabling the sequencing of all genetic materials,including viruses, from host or environmental samples. However, distinguishingviral sequences from the vast background of cellular organism-derived reads inmetagenomic data remains a significant challenge. While several learning-basedtools, such as VirSorter2 and geNomad, have shown promise in identifying viralcontigs, they often experience varying degrees of false positive rates due tonoise in sequencing and assembly, shared genes between viruses and their hosts,and the formation of proviruses within host genomes. This highlights the urgentneed for an accurate and efficient method to evaluate the quality of viralcontigs. Results: To address these challenges, we introduce ViralQC, a tooldesigned to assess the quality of reported viral contigs or bins. ViralQCidentifies contamination regions within putative viral sequences usingfoundation models trained on viral and cellular genomes and estimates viralcompleteness through protein organization alignment. We evaluate ViralQC onmultiple datasets and compare its performance against CheckV, thestate-of-the-art in virus quality assessment. Notably, ViralQC correctlyidentifies 38% more contamination than CheckV, while maintaining a medianabsolute error of only 3%. In addition, ViralQC delivers more accurate resultsfor medium- to high-quality (&gt;50% completeness) contigs, demonstrating itssuperior performance in completeness estimation.</description>
      <author>example@mail.com (Cheng Peng, Jiayu Shang, Jiaojiao Guan, Yanni Sun)</author>
      <guid isPermaLink="false">2504.05790v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>L3GS: Layered 3D Gaussian Splats for Efficient 3D Scene Delivery</title>
      <link>http://arxiv.org/abs/2504.05517v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种高效的三维内容交付框架，使用3D高斯块（3DGS）作为底层数据表示，以实现高质量的三维场景实时观看。&lt;h4&gt;背景&lt;/h4&gt;传统的3D内容表示如密集点云数据量大，网络带宽消耗高；新的表示如神经辐射场渲染效率低，帧率不佳。&lt;h4&gt;目的&lt;/h4&gt;创建一个高效的3D内容交付框架，允许用户以3DGS作为数据表示观看高质量的三维场景。&lt;h4&gt;方法&lt;/h4&gt;（1）创建新的分层3DGS场景以实现高效交付；（2）调度算法决定何时下载哪些块；（3）通过佩戴虚拟现实头盔的用户进行追踪实验，评估视觉效果和延迟。&lt;h4&gt;主要发现&lt;/h4&gt;系统L3GS实现了高视觉质量，平均SSIM值比基线高16.9%，并且可以与其他压缩的3DGS表示一起工作。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在保持高视觉质量的同时，实现了高效的3D内容交付。&lt;h4&gt;翻译&lt;/h4&gt;摘要：传统三维内容表示包括密集点云，消耗大量数据和网络带宽，而新的表示如神经辐射场由于非标准的体积渲染流程而帧率不佳。三维高斯块（3DGS）可以看作是点云的推广，兼具两者之长，具有高视觉质量和高效的渲染，实现实时帧率。然而，由于高网络数据消耗（例如，单个场景1.5GB），从托管服务器向客户端设备传输3DGS场景仍然具有挑战性。本文的目标是创建一个高效的三维内容交付框架，允许用户使用3DGS作为底层数据表示查看高质量的三维场景。本文的主要贡献包括：（1）创建新的分层3DGS场景以实现高效交付；（2）调度算法以决定何时下载哪些块；（3）通过佩戴虚拟现实头盔的用户进行的追踪实验来评估视觉效果和延迟。我们的分层3D高斯块交付系统L3GS展示了高视觉质量，平均SSIM值比基线高16.9%，并且可以与其他压缩的3DGS表示一起工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional 3D content representations include dense point clouds thatconsume large amounts of data and hence network bandwidth, while newerrepresentations such as neural radiance fields suffer from poor frame rates dueto their non-standard volumetric rendering pipeline. 3D Gaussian splats (3DGS)can be seen as a generalization of point clouds that meet the best of bothworlds, with high visual quality and efficient rendering for real-time framerates. However, delivering 3DGS scenes from a hosting server to client devicesis still challenging due to high network data consumption (e.g., 1.5 GB for asingle scene). The goal of this work is to create an efficient 3D contentdelivery framework that allows users to view high quality 3D scenes with 3DGSas the underlying data representation. The main contributions of the paper are:(1) Creating new layered 3DGS scenes for efficient delivery, (2) Schedulingalgorithms to choose what splats to download at what time, and (3) Trace-drivenexperiments from users wearing virtual reality headsets to evaluate the visualquality and latency. Our system for Layered 3D Gaussian Splats delivery L3GSdemonstrates high visual quality, achieving 16.9% higher average SSIM comparedto baselines, and also works with other compressed 3DGS representations.</description>
      <author>example@mail.com (Yi-Zhen Tsai, Xuechen Zhang, Zheng Li, Jiasi Chen)</author>
      <guid isPermaLink="false">2504.05517v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Measuring Déjà vu Memorization Efficiently</title>
      <link>http://arxiv.org/abs/2504.05651v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究表明，表示学习模型可能会记住其训练数据，本文提出了一种无需重新训练即可近似评估模型记忆能力的方法。&lt;h4&gt;背景&lt;/h4&gt;现有研究指出，表示学习模型可能错误地记住训练数据，例如，某些模型可以通过背景的表示正确预测前景标签。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单的方法来估计数据集级别的相关性，并用于评估预训练模型的记忆能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种无需重新训练的方法来近似评估模型的记忆能力，并通过预训练的图像和视觉语言模型进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;不同的记忆测量方法产生了非常相似的总结果，开源模型通常具有比在数据子集上训练的相似模型更低的记忆能力。&lt;h4&gt;结论&lt;/h4&gt;该方法首次允许测量预训练开源图像表示和视觉语言表示模型的记忆能力。&lt;h4&gt;翻译&lt;/h4&gt;最近的研究表明，表示学习模型可能会意外地记住它们的训练数据。例如， déjà vu 方法表明，对于某些表示学习模型和训练图像，有时仅通过背景的表示就可以正确预测前景标签，这比通过数据集级别的相关性更好。然而，他们的测量方法需要训练两个模型——一个用于估计数据集级别的相关性，另一个用于估计记忆。这种多模型设置对于大型开源模型来说变得不可行。在这项工作中，我们提出了替代的简单方法来估计数据集级别的相关性，并表明这些方法可以用来近似评估现成的模型的记忆能力，而无需任何重新训练。这使得我们首次能够测量预训练的开源图像表示和视觉语言表示模型的记忆能力。我们的结果表明，不同的记忆测量方法产生了非常相似的总结果。我们还发现，开源模型通常具有比在数据子集上训练的相似模型更低的记忆能力。代码对于视觉和视觉语言模型都是可用的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research has shown that representation learning models mayaccidentally memorize their training data. For example, the d\'ej\`a vu methodshows that for certain representation learning models and training images, itis sometimes possible to correctly predict the foreground label given only therepresentation of the background - better than through dataset-levelcorrelations. However, their measurement method requires training two models -one to estimate dataset-level correlations and the other to estimatememorization. This multiple model setup becomes infeasible for largeopen-source models. In this work, we propose alternative simple methods toestimate dataset-level correlations, and show that these can be used toapproximate an off-the-shelf model's memorization ability without anyretraining. This enables, for the first time, the measurement of memorizationin pre-trained open-source image representation and vision-languagerepresentation models. Our results show that different ways of measuringmemorization yield very similar aggregate results. We also find thatopen-source models typically have lower aggregate memorization than similarmodels trained on a subset of the data. The code is available both for visionand vision language models.</description>
      <author>example@mail.com (Narine Kokhlikyan, Bargav Jayaraman, Florian Bordes, Chuan Guo, Kamalika Chaudhuri)</author>
      <guid isPermaLink="false">2504.05651v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Nes2Net: A Lightweight Nested Architecture for Foundation Model Driven Speech Anti-spoofing</title>
      <link>http://arxiv.org/abs/2504.05657v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This manuscript has been submitted for peer review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Nested Res2Net (Nes2Net) 是一种轻量级后端架构，用于直接处理高维特征，旨在解决高维输出特征与下游任务模型输入不匹配的问题。&lt;h4&gt;背景&lt;/h4&gt;语音基础模型在语音相关任务中取得了显著进展，但它们的高维输出特征与需要低维输入的下游任务模型之间存在不匹配。&lt;h4&gt;目的&lt;/h4&gt;提出Nes2Net以解决使用维度缩减层导致参数开销增加、计算成本上升和信息丢失的问题。&lt;h4&gt;方法&lt;/h4&gt;Nes2Net采用嵌套结构，增强多尺度特征提取，改进特征交互，并保留高维信息，直接处理高维特征。&lt;h4&gt;主要发现&lt;/h4&gt;在CtRSVDD、ASVspoof 2021、ASVspoof 5、PartialSpoof和In-the-Wild等五个数据集上测试，Nes2Net实现了22%的性能提升和87%的后端计算成本降低。&lt;h4&gt;结论&lt;/h4&gt;Nes2Net在多个数据集上表现出优异的鲁棒性和泛化能力，且其代码包和预训练模型可在GitHub上获取。&lt;h4&gt;翻译&lt;/h4&gt;语音基础模型显著推进了各种语音相关任务，但其高维输出特征常常与下游任务模型所需的低维输入不匹配。一个常见的解决方案是应用一个维度缩减（DR）层，但这会增加参数开销、计算成本，并可能导致信息丢失。为了解决这些问题，我们提出了Nested Res2Net（Nes2Net），这是一种专为直接处理高维特征而设计的轻量级后端架构。嵌套结构增强了多尺度特征提取，改善了特征交互，并保留了高维信息。我们首先在CtRSVDD（一种唱歌声音深度伪造检测数据集）上验证了Nes2Net，与最先进的基线相比，实现了22%的性能提升和87%的后端计算成本降低。此外，在ASVspoof 2021、ASVspoof 5、PartialSpoof和In-the-Wild等四个不同的数据集上进行了广泛的测试，涵盖了完全伪造的语音、对抗攻击、部分伪造和现实场景，Nes2Net的一致表现突出了其优越的鲁棒性和泛化能力。代码包和预训练模型可在https://github.com/Liu-Tianchi/Nes2Net上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech foundation models have significantly advanced various speech-relatedtasks by providing exceptional representation capabilities. However, theirhigh-dimensional output features often create a mismatch with downstream taskmodels, which typically require lower-dimensional inputs. A common solution isto apply a dimensionality reduction (DR) layer, but this approach increasesparameter overhead, computational costs, and risks losing valuable information.To address these issues, we propose Nested Res2Net (Nes2Net), a lightweightback-end architecture designed to directly process high-dimensional featureswithout DR layers. The nested structure enhances multi-scale featureextraction, improves feature interaction, and preserves high-dimensionalinformation. We first validate Nes2Net on CtrSVDD, a singing voice deepfakedetection dataset, and report a 22% performance improvement and an 87% back-endcomputational cost reduction over the state-of-the-art baseline. Additionally,extensive testing across four diverse datasets: ASVspoof 2021, ASVspoof 5,PartialSpoof, and In-the-Wild, covering fully spoofed speech, adversarialattacks, partial spoofing, and real-world scenarios, consistently highlightsNes2Net's superior robustness and generalization capabilities. The code packageand pre-trained models are available at https://github.com/Liu-Tianchi/Nes2Net.</description>
      <author>example@mail.com (Tianchi Liu, Duc-Tuan Truong, Rohan Kumar Das, Kong Aik Lee, Haizhou Li)</author>
      <guid isPermaLink="false">2504.05657v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>iEBAKER: Improved Remote Sensing Image-Text Retrieval Framework via Eliminate Before Align and Keyword Explicit Reasoning</title>
      <link>http://arxiv.org/abs/2504.05644v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为iEBAKER的RSITR方法，用于遥感图像-文本检索，通过改进消除和排序策略来优化检索效果。&lt;h4&gt;背景&lt;/h4&gt;遥感图像-文本检索是一个基于查询搜索对应目标的研究领域，其中基于基础模型的方法如CLIP已取得一定成果，但现有方法存在忽略弱相关样本对和未能充分考虑遥感文本差异的问题。&lt;h4&gt;目的&lt;/h4&gt;提出iEBAKER方法，旨在解决现有遥感图像-文本检索方法中存在的不足，实现更精准的检索。&lt;h4&gt;方法&lt;/h4&gt;iEBAKER方法包括以下创新点：1. 提出了一种新的消除策略EBA来过滤弱相关样本对；2. 从局部相似性和全局相似性的相互作用角度，引入了排序策略SAR；3. 集成了关键词显式推理模块KER来提高关键概念的区分度；4. 直接将FM应用于RSITR任务，无需在遥感数据上进行额外预训练。&lt;h4&gt;主要发现&lt;/h4&gt;在三个流行的基准数据集上进行的实验表明，iEBAKER方法在检索精度上超越了现有模型，且所需的训练数据更少。&lt;h4&gt;结论&lt;/h4&gt;iEBAKER方法为遥感图像-文本检索提供了一种有效的解决方案，具有更好的性能和更少的训练数据需求。&lt;h4&gt;翻译&lt;/h4&gt;Recent studies focus on the Remote Sensing Image-Text Retrieval (RSITR),which aims at searching for the corresponding targets based on the given query.Among these efforts, the application of Foundation Models (FMs), such as CLIP,to the domain of remote sensing has yielded encouraging outcomes. However,existing FM based methodologies neglect the negative impact of weaklycorrelated sample pairs and fail to account for the key distinctions amongremote sensing texts, leading to biased and superficial exploration of samplepairs. To address these challenges, we propose an approach named iEBAKER (anImproved Eliminate Before Align strategy with Keyword Explicit Reasoningframework) for RSITR. Specifically, we propose an innovative Eliminate BeforeAlign (EBA) strategy to filter out the weakly correlated sample pairs, therebymitigating their deviations from optimal embedding space duringalignment.Further, two specific schemes are introduced from the perspective ofwhether local similarity and global similarity affect each other. On thisbasis, we introduce an alternative Sort After Reversed Retrieval (SAR)strategy, aims at optimizing the similarity matrix via reverse retrieval.Additionally, we incorporate a Keyword Explicit Reasoning (KER) module tofacilitate the beneficial impact of subtle key concept distinctions. Withoutbells and whistles, our approach enables a direct transition from FM to RSITRtask, eliminating the need for additional pretraining on remote sensing data.Extensive experiments conducted on three popular benchmark datasets demonstratethat our proposed iEBAKER method surpasses the state-of-the-art models whilerequiring less training data. Our source code will be released athttps://github.com/zhangy0822/iEBAKER.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies focus on the Remote Sensing Image-Text Retrieval (RSITR),which aims at searching for the corresponding targets based on the given query.Among these efforts, the application of Foundation Models (FMs), such as CLIP,to the domain of remote sensing has yielded encouraging outcomes. However,existing FM based methodologies neglect the negative impact of weaklycorrelated sample pairs and fail to account for the key distinctions amongremote sensing texts, leading to biased and superficial exploration of samplepairs. To address these challenges, we propose an approach named iEBAKER (anImproved Eliminate Before Align strategy with Keyword Explicit Reasoningframework) for RSITR. Specifically, we propose an innovative Eliminate BeforeAlign (EBA) strategy to filter out the weakly correlated sample pairs, therebymitigating their deviations from optimal embedding space duringalignment.Further, two specific schemes are introduced from the perspective ofwhether local similarity and global similarity affect each other. On thisbasis, we introduce an alternative Sort After Reversed Retrieval (SAR)strategy, aims at optimizing the similarity matrix via reverse retrieval.Additionally, we incorporate a Keyword Explicit Reasoning (KER) module tofacilitate the beneficial impact of subtle key concept distinctions. Withoutbells and whistles, our approach enables a direct transition from FM to RSITRtask, eliminating the need for additional pretraining on remote sensing data.Extensive experiments conducted on three popular benchmark datasets demonstratethat our proposed iEBAKER method surpasses the state-of-the-art models whilerequiring less training data. Our source code will be released athttps://github.com/zhangy0822/iEBAKER.</description>
      <author>example@mail.com (Yan Zhang, Zhong Ji, Changxu Meng, Yanwei Pang, Jungong Han)</author>
      <guid isPermaLink="false">2504.05644v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Falcon: Fractional Alternating Cut with Overcoming Minima in Unsupervised Segmentation</title>
      <link>http://arxiv.org/abs/2504.05613v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的无监督图像分割算法Falcon，通过改进算法结构和优化方法，在速度和准确度上显著提升，缩小了无监督和监督方法之间的差距。&lt;h4&gt;背景&lt;/h4&gt;现有的无监督图像分割算法往往分割效果不佳，基于图割的现代方法依赖高维注意力图和递归计算，在速度和准确性上落后于监督方法。&lt;h4&gt;目的&lt;/h4&gt;提出一种优化后的K-way Normalized Cut算法，在不依赖递归计算的情况下提高分割速度和准确性。&lt;h4&gt;方法&lt;/h4&gt;Falcon采用两阶段操作：(1) 通过扩展到分数二次变换实现快速K-way Normalized Cut，采用交替迭代过程和正则化以避免局部最优；(2) 使用互补的低级信息细化结果掩码，生成高质量的像素级分割。&lt;h4&gt;主要发现&lt;/h4&gt;Falcon在六个广泛认可的基准测试中平均提升了2.5%，在Cityscapes上最高提升了4.3%，并且与之前的图割方法相比，运行时间减少了约30%。&lt;h4&gt;结论&lt;/h4&gt;Falcon能够有效地利用基础模型注意力中的语义信息，通过高度并行的图割框架，为现实世界应用中的可扩展性和基于密集预测的视觉预训练铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;Falcon是一种基于优化的K-way Normalized Cut的无监督图像分割算法，通过改进算法结构和优化方法，在速度和准确度上显著提升，缩小了无监督和监督方法之间的差距。该算法分为两个阶段：第一阶段通过扩展到分数二次变换实现快速K-way Normalized Cut，采用交替迭代过程和正则化以避免局部最优；第二阶段使用互补的低级信息细化结果掩码，生成高质量的像素级分割。实验表明，Falcon在六个广泛认可的基准测试中平均提升了2.5%，在Cityscapes上最高提升了4.3%，并且与之前的图割方法相比，运行时间减少了约30%。这些发现表明，通过高度并行的图割框架，可以有效地利用基础模型注意力中的语义信息，为现实世界应用中的可扩展性和基于密集预测的视觉预训练铺平道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Today's unsupervised image segmentation algorithms often segmentsuboptimally. Modern graph-cut based approaches rely on high-dimensionalattention maps from Transformer-based foundation models, typically employing arelaxed Normalized Cut solved recursively via the Fiedler vector (theeigenvector of the second smallest eigenvalue). Consequently, they still lagbehind supervised methods in both mask generation speed and segmentationaccuracy. We present a regularized fractional alternating cut (Falcon), anoptimization-based K-way Normalized Cut without relying on recursiveeigenvector computations, achieving substantially improved speed and accuracy.Falcon operates in two stages: (1) a fast K-way Normalized Cut solved byextending into a fractional quadratic transformation, with an alternatingiterative procedure and regularization to avoid local minima; and (2)refinement of the resulting masks using complementary low-level information,producing high-quality pixel-level segmentations. Experiments show that Falconnot only surpasses existing state-of-the-art methods by an average of 2.5%across six widely recognized benchmarks (reaching up to 4.3\% improvement onCityscapes), but also reduces runtime by around 30% compared to priorgraph-based approaches. These findings demonstrate that the semanticinformation within foundation-model attention can be effectively harnessed by ahighly parallelizable graph cut framework. Consequently, Falcon can narrow thegap between unsupervised and supervised segmentation, enhancing scalability inreal-world applications and paving the way for dense prediction-based visionpre-training in various downstream tasks. The code is released inhttps://github.com/KordingLab/Falcon.</description>
      <author>example@mail.com (Xiao Zhang, Xiangyu Han, Xiwen Lai, Yao Sun, Pei Zhang, Konrad Kording)</author>
      <guid isPermaLink="false">2504.05613v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation</title>
      <link>http://arxiv.org/abs/2504.02438v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ViLaMP的视觉-语言模型，用于处理长视频，通过差分蒸馏技术，在保持计算效率的同时，保留了关键帧的完整信息，并简化了非关键帧的特征。&lt;h4&gt;背景&lt;/h4&gt;长视频处理对视觉-语言模型（VLMs）是一个挑战，因为处理长时间序列的计算成本很高。现有的剪枝和特征合并方法通常牺牲了关键的时间依赖性或稀释了语义信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，能够在处理长视频时，系统地保留任务相关的信息，同时减少冗余。&lt;h4&gt;方法&lt;/h4&gt;ViLaMP通过两个关键机制处理长视频：差分关键帧选择和差分特征合并。差分关键帧选择在帧级别保持时间上的独特性，同时最大化查询相关性；差分特征合并则在像素级别保留非关键帧中的显著特征。&lt;h4&gt;主要发现&lt;/h4&gt;ViLaMP在四个视频理解基准测试中表现出色，特别是在长视频内容上。它能够在单个NVIDIA A100 GPU上处理超长视频（高达10K帧），同时保持最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;ViLaMP通过创新的方法，在保持高计算效率的同时，实现了对长视频的高效处理，为视频理解领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-form video processing fundamentally challenges vision-language models(VLMs) due to the high computational costs of handling extended temporalsequences. Existing token pruning and feature merging methods often sacrificecritical temporal dependencies or dilute semantic information. We introducedifferential distillation, a principled approach that systematically preservestask-relevant information while suppressing redundancy. Based on thisprinciple, we develop ViLaMP, a hierarchical video-language model thatprocesses hour-long videos at ``mixed precision'' through two key mechanisms:(1) differential keyframe selection that maximizes query relevance whilemaintaining temporal distinctiveness at the frame level and (2) differentialfeature merging that preserves query-salient features in non-keyframes at thepatch level. Hence, ViLaMP retains full information in keyframes while reducingnon-keyframes to their most salient features, resembling mixed-precisiontraining. Extensive experiments demonstrate ViLaMP's superior performanceacross four video understanding benchmarks, particularly on long-form content.Notably, ViLaMP can process ultra-long videos (up to 10K frames) on a singleNVIDIA A100 GPU, achieving substantial computational efficiency whilemaintaining state-of-the-art performance.</description>
      <author>example@mail.com (Chuanqi Cheng, Jian Guan, Wei Wu, Rui Yan)</author>
      <guid isPermaLink="false">2504.02438v2</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>Divergent Paths: Separating Homophilic and Heterophilic Learning for Enhanced Graph-level Representations</title>
      <link>http://arxiv.org/abs/2504.05344v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究针对在图级别任务中GCN在异质图上表现不佳的问题，提出了一种名为DivGNN的新方法，该方法通过结合内部分类卷积（IntraNet）和外部分类高通过滤图卷积（InterNet）来提高分类性能。&lt;h4&gt;背景&lt;/h4&gt;传统的GCN在显示同质性的图上表现良好，但在异质图上效果不佳，因为它们通常不能有效区分同质性和异质性组件。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的学习策略，以解决在图级别任务中GCN在处理异质性图时的不足。&lt;h4&gt;方法&lt;/h4&gt;将节点分为同质性和异质性组件，分别学习它们的内部分类和外部分类部分。使用IntraNet处理内部分类，它依赖于复杂的图预处理步骤和一个基于类别的图读取函数。InterNet使用高通滤波器放大节点差异，以增强高频成分的细节识别。&lt;h4&gt;主要发现&lt;/h4&gt;GCN在提取分类信息方面表现良好，但往往从异质性组件中捕获噪声。通过分别学习内部分类和外部分类元素，可以显著提高分类性能。&lt;h4&gt;结论&lt;/h4&gt;DivGNN方法通过结合IntraNet和InterNet，在图级别任务中的分类性能上优于传统的GNN基线。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图卷积网络（GCN）主要针对同质性图，即相似节点连接的图，但在异质图上往往表现不佳。采用不同的方法来从同质性和异质性组件中学习的策略已经在理论和实验上被广泛讨论并证明是有效的。然而，在图级别任务中，对此主题的研究仍然非常稀少。为了解决这一差距，我们的研究对具有节点类别ID的图进行了分析，将内部分类和跨分类组件分别作为同质性和异质性的体现。我们发现，虽然GCN在提取分类信息方面表现良好，但它们经常从跨分类组件中捕获噪声。因此，对于内部分类和跨分类元素采用不同的学习策略至关重要。为了减轻这个问题，我们通过结合内部分类卷积（IntraNet）和外部分类高通过滤图卷积（InterNet）来分别学习内部分类和跨分类部分。我们的IntraNet依赖于复杂的图预处理步骤和一个新的基于类别的图读取函数。对于InterNet，我们使用高通滤波器放大节点差异，增强高频成分的细节识别。所提出的方法，DivGNN，结合了IntraNet和InterNet以及门控机制，在图级别任务中的分类性能上显著提高，超越了传统GNN基线的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Convolutional Networks (GCNs) are predominantly tailored for graphsdisplaying homophily, where similar nodes connect, but often fail onheterophilic graphs. The strategy of adopting distinct approaches to learn fromhomophilic and heterophilic components in node-level tasks has been widelydiscussed and proven effective both theoretically and experimentally. However,in graph-level tasks, research on this topic remains notably scarce. Addressingthis gap, our research conducts an analysis on graphs with nodes' category IDavailable, distinguishing intra-category and inter-category components asembodiment of homophily and heterophily, respectively. We find while GCNs excelat extracting information within categories, they frequently capture noise frominter-category components. Consequently, it is crucial to employ distinctlearning strategies for intra- and inter-category elements. To alleviate thisproblem, we separately learn the intra- and inter-category parts by acombination of an intra-category convolution (IntraNet) and an inter-categoryhigh-pass graph convolution (InterNet). Our IntraNet is supported bysophisticated graph preprocessing steps and a novel category-based graphreadout function. For the InterNet, we utilize a high-pass filter to amplifythe node disparities, enhancing the recognition of details in thehigh-frequency components. The proposed approach, DivGNN, combines the IntraNetand InterNet with a gated mechanism and substantially improves classificationperformance on graph-level tasks, surpassing traditional GNN baselines ineffectiveness.</description>
      <author>example@mail.com (Han Lei, Jiaxing Xu, Xia Dong, Yiping Ke)</author>
      <guid isPermaLink="false">2504.05344v1</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>QID: Efficient Query-Informed ViTs in Data-Scarce Regimes for OCR-free Visual Document Understanding</title>
      <link>http://arxiv.org/abs/2504.02971v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, accepted by CVPR 2025 MULA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为QID的新型方法，用于优化视觉编码器在文本丰富的文档图像中识别特定查询区域，特别适用于数据稀缺的微调场景。&lt;h4&gt;背景&lt;/h4&gt;在视觉文档理解任务中，使用新数据集微调预训练的视觉-语言模型时，通常难以优化视觉编码器以识别特定查询区域。&lt;h4&gt;目的&lt;/h4&gt;提出QID方法，以解决在数据稀缺情况下，直接将查询注入模型层并修改网络架构的方法难以适应新数据集的问题。&lt;h4&gt;方法&lt;/h4&gt;QID方法引入了一个双重模块框架：一个查询感知模块，用于生成独特的查询向量以精确引导模型焦点；以及一个查询无关模块，用于捕捉标记之间的位置关系，确保鲁棒的空间理解。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，使用QID方法在多个数据集上对OCR-free VLM进行了实验，特别是在处理数据稀缺环境中的文本丰富文档时，显著提高了性能。&lt;h4&gt;结论&lt;/h4&gt;QID方法通过独立于视觉注意力块的操作，促进了查询嵌入的有针对性学习，并增强了视觉语义识别，从而在视觉文档理解任务中取得了显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In Visual Document Understanding (VDU) tasks, fine-tuning a pre-trainedVision-Language Model (VLM) with new datasets often falls short in optimizingthe vision encoder to identify query-specific regions in text-rich documentimages. Existing methods that directly inject queries into model layers bymodifying the network architecture often struggle to adapt to new datasets withlimited annotations. To address this, we introduce QID, a novel, streamlined,architecture-preserving approach that integrates query embeddings into thevision encoder, leading to notable performance gains, particularly indata-scarce fine-tuning scenarios. Specifically, our approach introduces adual-module framework: a query-aware module that generates a unique queryvector to precisely guide the model's focus, as well as a query-agnostic modulethat captures the positional relationships among tokens, ensuring robustspatial understanding. Notably, both modules operate independently of thevision attention blocks, facilitating targeted learning of query embeddings andenhancing visual semantic identification. Experiments with OCR-free VLMs acrossmultiple datasets demonstrate significant performance improvements using ourmethod, especially in handling text-rich documents in data-scarce environments.</description>
      <author>example@mail.com (Binh M. Le, Shaoyuan Xu, Jinmiao Fu, Zhishen Huang, Moyan Li, Yanhui Guo, Hongdong Li, Sameera Ramasinghe, Bryan Wang)</author>
      <guid isPermaLink="false">2504.02971v2</guid>
      <pubDate>Wed, 09 Apr 2025 14:18:18 +0800</pubDate>
    </item>
    <item>
      <title>SSLFusion: Scale &amp; Space Aligned Latent Fusion Model for Multimodal 3D Object Detection</title>
      <link>http://arxiv.org/abs/2504.05170v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为SSLFusion的新型多模态3D物体检测模型，旨在解决现有方法中存在的特征尺度和对齐问题，以及计算复杂性问题。&lt;h4&gt;背景&lt;/h4&gt;多模态3D物体检测虽然取得了进展，但存在2D图像和3D点云特征之间的尺度与空间信息失配问题。&lt;h4&gt;目的&lt;/h4&gt;提高物体检测的准确性和效率，同时减少计算复杂度。&lt;h4&gt;方法&lt;/h4&gt;SSLFusion包含尺度对齐融合策略（SAF）、3D到2D空间对齐模块（SAM）和潜在跨模态融合模块（LFM）。SAF通过跨多级聚合图像和点云的特征来缓解模态间的尺度失配；SAM通过将3D坐标信息融入2D图像特征来减少模态间的差距；LFM在不使用基于QKV的注意力操作的情况下，在潜在空间中捕捉跨模态的非局部上下文。&lt;h4&gt;主要发现&lt;/h4&gt;SSLFusion在KITTI和DENSE数据集上表现优于现有方法，3D AP相比GraphAlign方法提高了2.15%。&lt;h4&gt;结论&lt;/h4&gt;SSLFusion模型有效地提高了多模态3D物体检测的准确性，同时减少了计算复杂度。&lt;h4&gt;翻译&lt;/h4&gt;Based on the provided Chinese summary, here is the JSON formatted key-value pairs extracted from the abstract:&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal 3D object detection based on deep neural networks has indeed madesignificant progress. However, it still faces challenges due to themisalignment of scale and spatial information between features extracted from2D images and those derived from 3D point clouds. Existing methods usuallyaggregate multimodal features at a single stage. However, leveragingmulti-stage cross-modal features is crucial for detecting objects of variousscales. Therefore, these methods often struggle to integrate features acrossdifferent scales and modalities effectively, thereby restricting the accuracyof detection. Additionally, the time-consuming Query-Key-Value-based(QKV-based) cross-attention operations often utilized in existing methods aidin reasoning the location and existence of objects by capturing non-localcontexts. However, this approach tends to increase computational complexity. Toaddress these challenges, we present SSLFusion, a novel Scale &amp; Space AlignedLatent Fusion Model, consisting of a scale-aligned fusion strategy (SAF), a3D-to-2D space alignment module (SAM), and a latent cross-modal fusion module(LFM). SAF mitigates scale misalignment between modalities by aggregatingfeatures from both images and point clouds across multiple levels. SAM isdesigned to reduce the inter-modal gap between features from images and pointclouds by incorporating 3D coordinate information into 2D image features.Additionally, LFM captures cross-modal non-local contexts in the latent spacewithout utilizing the QKV-based attention operations, thus mitigatingcomputational complexity. Experiments on the KITTI and DENSE datasetsdemonstrate that our SSLFusion outperforms state-of-the-art methods. Ourapproach obtains an absolute gain of 2.15% in 3D AP, compared with thestate-of-art method GraphAlign on the moderate level of the KITTI test set.</description>
      <author>example@mail.com (Bonan Ding, Jin Xie, Jing Nie, Jiale Cao)</author>
      <guid isPermaLink="false">2504.05170v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
  <item>
      <title>Cellular Network Design for UAV Corridors via Data-driven High-dimensional Bayesian Optimization</title>
      <link>http://arxiv.org/abs/2504.05176v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;通过一种新的数据驱动方法，研究无人机走廊的蜂窝网络设计，评估多种高维贝叶斯优化技术，以优化天线倾斜角度和半功率波束宽度，并通过案例研究验证方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;设计适用于无人机的蜂窝网络是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来设计适用于无人机的蜂窝网络。&lt;h4&gt;方法&lt;/h4&gt;采用数据驱动方法，评估高维贝叶斯优化技术，探索模型泛化能力，实现多目标优化。&lt;h4&gt;主要发现&lt;/h4&gt;某些方法在无人机走廊中实现了超过20dB的中值SINR增益，同时地面用户性能损失可忽略。通过迁移学习，高维贝叶斯优化可以在新场景中预测最优解。多目标优化可以平衡地面数据速率和无人机覆盖可靠性。优化无人机走廊覆盖可以提高地面用户的速率。&lt;h4&gt;结论&lt;/h4&gt;该方法通过案例研究证明了其在真实世界网络中的有效性，并识别了最佳的天线配置，在3D无人机走廊中实现超过两倍的数据速率，同时地面性能损失可忽略。&lt;h4&gt;翻译&lt;/h4&gt;我们通过一种新的数据驱动方法来解决为无人机走廊设计蜂窝网络的挑战。我们评估了多种最先进的高维贝叶斯优化（HD-BO）技术来联合优化蜂窝天线的倾斜角度和半功率波束宽度。我们发现，这些方法中的一些在无人机走廊中实现了超过20dB的中值SINR增益，同时对地面用户性能的影响可忽略不计。此外，我们探索了高维贝叶斯优化在迁移学习方面的能力，即利用先前观察到的场景源数据来预测新场景目标的最优解。我们提供了迁移学习成功的场景示例以及失败的场景示例。此外，我们证明高维贝叶斯优化可以实现多目标优化，识别了地面数据速率与无人机覆盖可靠性之间的最佳设计权衡。我们观察到，旨在在整个天空中提供无人机覆盖的目标可能会降低与专门针对无人机走廊优化的设置相比的地面用户速率。最后，我们通过一个真实世界蜂窝网络的案例研究验证了我们的方法，其中高维贝叶斯优化确定了最佳且非显而易见的天线配置，这些配置在3D无人机走廊中实现了超过两倍的数据速率，同时地面性能损失可忽略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We address the challenge of designing cellular networks for uncrewed aerialvehicles (UAVs) corridors through a novel data-driven approach. We assessmultiple state-of-the-art high-dimensional Bayesian optimization (HD-BO)techniques to jointly optimize the cell antenna tilts and half-power beamwidth(HPBW). We find that some of these approaches achieve over 20dB gains in medianSINR along UAV corridors, with negligible degradation to ground userperformance. Furthermore, we explore the HD-BO's capabilities in terms of modelgeneralization via transfer learning, where data from a previously observedscenario source is leveraged to predict the optimal solution for a new scenariotarget. We provide examples of scenarios where such transfer learning issuccessful and others where it fails. Moreover, we demonstrate that HD-BOenables multi-objective optimization, identifying optimal design trade-offsbetween data rates on the ground versus UAV coverage reliability. We observethat aiming to provide UAV coverage across the entire sky can lower the ratesfor ground users compared to setups specifically optimized for UAV corridors.Finally, we validate our approach through a case study in a real-world cellularnetwork, where HD-BO identifies optimal and non-obvious antenna configurationsthat result in more than double the rates along 3D UAV corridors withnegligible ground performance loss.</description>
      <author>example@mail.com (Mohamed Benzaghta, Giovanni Geraci, David López-Pérez, Alvaro Valcarce)</author>
      <guid isPermaLink="false">2504.05176v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models</title>
      <link>http://arxiv.org/abs/2504.05258v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TISER，一个增强大型语言模型（LLMs）时间推理能力的框架，通过结合时间线构建和迭代自我反思的多阶段过程，提高模型在时间推理任务上的表现。&lt;h4&gt;背景&lt;/h4&gt;LLMs在生成连贯文本、理解上下文和执行推理任务方面表现出色，但在处理时间相关信息，如事件序列、持续时间和时间关系方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出TISER框架，旨在提升LLMs在时间推理方面的能力。&lt;h4&gt;方法&lt;/h4&gt;TISER通过时间线构建与迭代自我反思相结合的多阶段过程来增强时间推理能力，并利用测试时间缩放扩展推理轨迹的长度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，TISER在多个基准测试中表现出最先进的性能，包括分布外测试集，并显示TISER使小型开源模型在具有挑战性的时间推理任务上超越了大型封闭权重模型。&lt;h4&gt;结论&lt;/h4&gt;TISER框架有效提升了LLMs的时间推理能力，为时间相关的应用提供了更准确和可追溯的推理过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have emerged as powerful tools for generatingcoherent text, understanding context, and performing reasoning tasks. However,they struggle with temporal reasoning, which requires processing time-relatedinformation such as event sequencing, durations, and inter-temporalrelationships. These capabilities are critical for applications includingquestion answering, scheduling, and historical analysis. In this paper, weintroduce TISER, a novel framework that enhances the temporal reasoningabilities of LLMs through a multi-stage process that combines timelineconstruction with iterative self-reflection. Our approach leverages test-timescaling to extend the length of reasoning traces, enabling models to capturecomplex temporal dependencies more effectively. This strategy not only boostsreasoning accuracy but also improves the traceability of the inference process.Experimental results demonstrate state-of-the-art performance across multiplebenchmarks, including out-of-distribution test sets, and reveal that TISERenables smaller open-source models to surpass larger closed-weight models onchallenging temporal reasoning tasks.</description>
      <author>example@mail.com (Adrián Bazaga, Rexhina Blloshmi, Bill Byrne, Adrià de Gispert)</author>
      <guid isPermaLink="false">2504.05258v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>PanoDreamer: Consistent Text to 360-Degree Scene Generation</title>
      <link>http://arxiv.org/abs/2504.05152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025 Workshop on Computer Vision for Metaverse&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为PanoDreamer的新框架，用于从文本描述或参考图像生成高质量、几何一致的3D场景。&lt;h4&gt;背景&lt;/h4&gt;当前方法在生成高质量纹理和一致的3D结构方面存在挑战，尤其是在超出参考图像视场范围的情况下。&lt;h4&gt;目的&lt;/h4&gt;解决当前方法在生成3D场景时存在的低质量纹理和结构不一致的问题。&lt;h4&gt;方法&lt;/h4&gt;PanoDreamer框架利用大型语言模型和变形优化流程，首先生成一组初始图像，然后将这些图像合成成360度全景图。接着，将全景图转换为3D点云，并使用多种方法生成与初始点云一致的额外图像，以扩展或细化点云。最后，利用3D高斯分层技术创建最终的3D场景。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，PanoDreamer在生成高质量、几何一致的3D场景方面是有效的。&lt;h4&gt;结论&lt;/h4&gt;PanoDreamer是一种有效的框架，能够生成高质量的3D场景，适用于虚拟现实和游戏等领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatically generating a complete 3D scene from a text description, areference image, or both has significant applications in fields like virtualreality and gaming. However, current methods often generate low-qualitytextures and inconsistent 3D structures. This is especially true whenextrapolating significantly beyond the field of view of the reference image. Toaddress these challenges, we propose PanoDreamer, a novel framework forconsistent, 3D scene generation with flexible text and image control. Ourapproach employs a large language model and a warp-refine pipeline, firstgenerating an initial set of images and then compositing them into a 360-degreepanorama. This panorama is then lifted into 3D to form an initial point cloud.We then use several approaches to generate additional images, from differentviewpoints, that are consistent with the initial point cloud and expand/refinethe initial point cloud. Given the resulting set of images, we utilize 3DGaussian Splatting to create the final 3D scene, which can then be renderedfrom different viewpoints. Experiments demonstrate the effectiveness ofPanoDreamer in generating high-quality, geometrically consistent 3D scenes.</description>
      <author>example@mail.com (Zhexiao Xiong, Zhang Chen, Zhong Li, Yi Xu, Nathan Jacobs)</author>
      <guid isPermaLink="false">2504.05152v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Unleashing the Power of LLMs in Dense Retrieval with Query Likelihood Modeling</title>
      <link>http://arxiv.org/abs/2504.05216v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于大型语言模型（LLM）的密集检索模型LLM-QL，通过查询似然（QL）最大化来提升检索性能。&lt;h4&gt;背景&lt;/h4&gt;密集检索是信息检索的关键任务，LLM在语义理解方面表现出色，但在建模全局信息上存在不足。&lt;h4&gt;目的&lt;/h4&gt;充分利用LLM的生成能力，通过QL最大化来提升密集检索性能。&lt;h4&gt;方法&lt;/h4&gt;LLM-QL模型包括两个主要组件：注意力停止（AS）和输入干扰（IC）。AS在建模QL时停止对前一个token的注意力，直到文档结束。IC在预测过程中对输入文档中的部分token进行掩码。&lt;h4&gt;主要发现&lt;/h4&gt;在MSMARCO数据集上的实验表明，LLM-QL的检索性能显著优于其他基于LLM的检索器，且使用LLM-QL估计的QL进行排名的性能远超基于词的QL。&lt;h4&gt;结论&lt;/h4&gt;LLM-QL模型能够有效提升密集检索的性能，为下游任务如重排序提供了更好的基础。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Dense retrieval is a crucial task in Information Retrieval (IR) and is the foundation for downstream tasks such as re-ranking. Recently, large language models (LLMs) have shown compelling semantic understanding capabilities and are appealing to researchers studying dense retrieval. LLMs, as decoder-style generative models, are competent at language generation while falling short on modeling global information due to the lack of attention to tokens afterward. Inspired by the classical word-based language modeling approach for IR, i.e., the query likelihood (QL) model, we seek to sufficiently utilize LLMs' generative ability by QL maximization. However, instead of ranking documents with QL estimation, we introduce an auxiliary task of QL maximization to yield a better backbone for contrastively learning a discriminative retriever. We name our model as LLM-QL. To condense global document semantics to a single vector during QL modeling, LLM-QL has two major components, Attention Stop (AS) and Input Corruption (IC). AS stops the attention of predictive tokens to previous tokens until the ending token of the document. IC masks a portion of tokens in the input documents during prediction. Experiments on MSMARCO show that LLM-QL can achieve significantly better performance than other LLM-based retrievers and using QL estimated by LLM-QL for ranking outperforms word-based QL by a large margin.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dense retrieval is a crucial task in Information Retrieval (IR) and is thefoundation for downstream tasks such as re-ranking. Recently, large languagemodels (LLMs) have shown compelling semantic understanding capabilities and areappealing to researchers studying dense retrieval. LLMs, as decoder-stylegenerative models, are competent at language generation while falling short onmodeling global information due to the lack of attention to tokens afterward.Inspired by the classical word-based language modeling approach for IR, i.e.,the query likelihood (QL) model, we seek to sufficiently utilize LLMs'generative ability by QL maximization. However, instead of ranking documentswith QL estimation, we introduce an auxiliary task of QL maximization to yielda better backbone for contrastively learning a discriminative retriever. Wename our model as LLM-QL. To condense global document semantics to a singlevector during QL modeling, LLM-QL has two major components, Attention Stop (AS)and Input Corruption (IC). AS stops the attention of predictive tokens toprevious tokens until the ending token of the document. IC masks a portion oftokens in the input documents during prediction. Experiments on MSMARCO showthat LLM-QL can achieve significantly better performance than other LLM-basedretrievers and using QL estimated by LLM-QL for ranking outperforms word-basedQL by a large margin.</description>
      <author>example@mail.com (Hengran Zhang, Keping Bi, Jiafeng Guo, Xiaojie Sun, Shihao Liu, Daiting Shi, Dawei Yin, Xueqi Cheng)</author>
      <guid isPermaLink="false">2504.05216v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Sparse Optimization for Transfer Learning: A L0-Regularized Framework for Multi-Source Domain Adaptation</title>
      <link>http://arxiv.org/abs/2504.04812v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了异构多源环境中的迁移学习，针对目标域和辅助域之间的分布差异，提出了一种基于L0正则化的稀疏优化迁移学习（SOTL）框架。&lt;h4&gt;背景&lt;/h4&gt;在异构多源环境中，目标域和辅助域之间存在分布差异，这给迁移学习带来了统计偏差和计算效率的挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决统计偏差和计算效率的问题，提出了SOTL框架。&lt;h4&gt;方法&lt;/h4&gt;SOTL框架通过以下两个关键创新扩展了联合估计迁移（JETS）范式：(1) 参数空间压缩和复杂性降低的L0约束精确稀疏性；(2) 优化重点的细化，强调目标参数而非冗余参数。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，SOTL在估计精度和计算速度方面都有显著提升，尤其是在对抗性辅助域条件下。在社区和犯罪基准上的实证验证表明，SOTL方法在跨域迁移中具有统计鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;SOTL方法在异构多源环境中的迁移学习方面具有显著优势，能够有效提高估计精度和计算效率，且在跨域迁移中表现出良好的统计鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了异构多源环境中的迁移学习，针对目标域与辅助域之间的分布差异问题，提出了一种基于L0正则化的稀疏优化迁移学习（SOTL）框架。为了解决统计偏差和计算效率的挑战，该方法通过两个关键创新扩展了联合估计迁移（JETS）范式：一是参数空间压缩和复杂性降低的L0约束精确稀疏性；二是优化重点的细化，强调目标参数而非冗余参数。仿真结果表明，SOTL在估计精度和计算速度方面都有显著提升，尤其是在对抗性辅助域条件下。在社区和犯罪基准上的实证验证表明，SOTL方法在跨域迁移中具有统计鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores transfer learning in heterogeneous multi-sourceenvironments with distributional divergence between target and auxiliarydomains. To address challenges in statistical bias and computationalefficiency, we propose a Sparse Optimization for Transfer Learning (SOTL)framework based on L0-regularization. The method extends the Joint EstimationTransferred from Strata (JETS) paradigm with two key innovations: (1)L0-constrained exact sparsity for parameter space compression and complexityreduction, and (2) refining optimization focus to emphasize target parametersover redundant ones. Simulations show that SOTL significantly improves bothestimation accuracy and computational speed, especially under adversarialauxiliary domain conditions. Empirical validation on the Community and Crimebenchmarks demonstrates the statistical robustness of the SOTL method incross-domain transfer.</description>
      <author>example@mail.com (Chenqi Gong, Hu Yang)</author>
      <guid isPermaLink="false">2504.04812v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>InstructionBench: An Instructional Video Understanding Benchmark</title>
      <link>http://arxiv.org/abs/2504.05040v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了InstructionBench，一个用于评估视频理解能力的基准，并评估了最新视频大语言模型（Video-LLMs）的表现。&lt;h4&gt;背景&lt;/h4&gt;尽管视频大语言模型（Video-LLMs）取得了进展，但对指导性视频理解的深入研究仍然不足。&lt;h4&gt;目的&lt;/h4&gt;提出InstructionBench基准，以挑战模型在具有严格步骤流程的指导性视频中的高级时间推理能力。&lt;h4&gt;方法&lt;/h4&gt;使用GPT-4生成开放式和多项选择题对的Q&amp;A对，评估粗粒度事件级和细粒度物体级推理。过滤策略排除了仅凭常识知识即可回答的问题，侧重于视觉感知和分析来评估Video-LLM模型。基准包含超过700个视频中的5k个问题。&lt;h4&gt;主要发现&lt;/h4&gt;在InstructionBench上评估的最新Video-LLMs中，闭源模型优于开源模型。然而，即使表现最好的模型GPT-4o，准确率也只有53.42%，表明在时间推理方面存在显著差距。&lt;h4&gt;结论&lt;/h4&gt;为了推进该领域的发展，还开发了一个包含超过19k个Q&amp;A对的综合指导性视频数据集，该数据集来自近2.5k个视频，并使用自动数据生成框架，从而丰富了社区的研究资源。&lt;h4&gt;翻译&lt;/h4&gt;尽管在视频大型语言模型（Video-LLMs）方面取得了进展，但对指导性视频理解的研究仍然不足。为了解决这个问题，我们引入了InstructionBench，一个用于指导性视频理解的基准，它挑战了模型在具有严格步骤流程的指导性视频中的高级时间推理能力。我们使用GPT-4来制定开放式和多项选择题对的问答对，以评估粗粒度事件级和细粒度物体级推理。我们的过滤策略排除了仅凭常识知识即可回答的问题，在评估视频大语言模型（Video-LLMs）时侧重于视觉感知和分析。该基准最终包含了700多个视频中的5k个问题。我们在InstructionBench上评估了最新的视频大语言模型（Video-LLMs），发现闭源模型优于开源模型。然而，即使是表现最好的模型GPT-4o，其准确率也只有53.42%，这表明在时间推理方面存在显著差距。为了推动该领域的发展，我们还开发了一个包含超过19k个问答对的综合指导性视频数据集，该数据集来自近2.5k个视频，并使用自动数据生成框架，从而丰富了社区的研究资源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite progress in video large language models (Video-LLMs), research oninstructional video understanding, crucial for enhancing access toinstructional content, remains insufficient. To address this, we introduceInstructionBench, an Instructional video understanding Benchmark, whichchallenges models' advanced temporal reasoning within instructional videoscharacterized by their strict step-by-step flow. Employing GPT-4, we formulateQ\&amp;A pairs in open-ended and multiple-choice formats to assess bothCoarse-Grained event-level and Fine-Grained object-level reasoning. Ourfiltering strategies exclude questions answerable purely by common-senseknowledge, focusing on visual perception and analysis when evaluating Video-LLMmodels. The benchmark finally contains 5k questions across over 700 videos. Weevaluate the latest Video-LLMs on our InstructionBench, finding thatclosed-source models outperform open-source ones. However, even the best model,GPT-4o, achieves only 53.42\% accuracy, indicating significant gaps in temporalreasoning. To advance the field, we also develop a comprehensive instructionalvideo dataset with over 19k Q\&amp;A pairs from nearly 2.5k videos, using anautomated data generation framework, thereby enriching the community's researchresources.</description>
      <author>example@mail.com (Haiwan Wei, Yitian Yuan, Xiaohan Lan, Wei Ke, Lin Ma)</author>
      <guid isPermaLink="false">2504.05040v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Unifying Physics- and Data-Driven Modeling via Novel Causal Spatiotemporal Graph Neural Network for Interpretable Epidemic Forecasting</title>
      <link>http://arxiv.org/abs/2504.05140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  32 pages, 12 figures. Submitted to Expert Systems with Applications  and currently under review. This version includes minor revisions. The work  proposes a physics-informed deep learning framework integrating a novel  epidemic model with causal spatiotemporal graph neural networks for  interpretable forecasting&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个名为CSTGNN的新颖的因果时空图神经网络，用于精确预测流行病，以支持有效的疾病控制和预防。&lt;h4&gt;背景&lt;/h4&gt;传统模型难以估计时空变化的流行病参数，而深度学习模型则通常忽略了疾病传播动态，且在流行病学背景下缺乏可解释性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些限制，提出了一种结合空间接触SIR模型和图神经网络（GNNs）的混合框架，以捕捉流行病的时空传播。&lt;h4&gt;方法&lt;/h4&gt;使用自适应静态连接图来表示人类流动的稳定成分，并利用时间动态模型来捕捉这些模式中的波动。通过结合自适应静态连接图和时间动态图，构建了一个动态图，包含人类流动网络的全面属性。此外，引入了一个时间分解模型来处理时间依赖性，并将其与动态图卷积网络结合用于流行病预测。&lt;h4&gt;主要发现&lt;/h4&gt;使用中国省级和德国州级的数据集进行验证，结果表明该方法有效模拟了传染病的时空动态，为预测和干预策略提供了有价值的工具。此外，对学习到的参数的分析提供了对疾病传播机制的见解，增强了模型的可解释性和实用性。&lt;h4&gt;结论&lt;/h4&gt;CSTGNN模型为流行病预测和干预策略提供了一个有效的工具，并有助于理解疾病的传播机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate epidemic forecasting is crucial for effective disease control andprevention. Traditional compartmental models often struggle to estimatetemporally and spatially varying epidemiological parameters, while deeplearning models typically overlook disease transmission dynamics and lackinterpretability in the epidemiological context. To address these limitations,we propose a novel Causal Spatiotemporal Graph Neural Network (CSTGNN), ahybrid framework that integrates a Spatio-Contact SIR model with Graph NeuralNetworks (GNNs) to capture the spatiotemporal propagation of epidemics.Inter-regional human mobility exhibits continuous and smooth spatiotemporalpatterns, leading to adjacent graph structures that share underlying mobilitydynamics. To model these dynamics, we employ an adaptive static connectivitygraph to represent the stable components of human mobility and utilize atemporal dynamics model to capture fluctuations within these patterns. Byintegrating the adaptive static connectivity graph with the temporal dynamicsgraph, we construct a dynamic graph that encapsulates the comprehensiveproperties of human mobility networks. Additionally, to capture temporal trendsand variations in infectious disease spread, we introduce a temporaldecomposition model to handle temporal dependence. This model is thenintegrated with a dynamic graph convolutional network for epidemic forecasting.We validate our model using real-world datasets at the provincial level inChina and the state level in Germany. Extensive studies demonstrate that ourmethod effectively models the spatiotemporal dynamics of infectious diseases,providing a valuable tool for forecasting and intervention strategies.Furthermore, analysis of the learned parameters offers insights into diseasetransmission mechanisms, enhancing the interpretability and practicalapplicability of our model.</description>
      <author>example@mail.com (Shuai Han, Lukas Stelz, Thomas R. Sokolowski, Kai Zhou, Horst Stöcker)</author>
      <guid isPermaLink="false">2504.05140v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>MSA-UNet3+: Multi-Scale Attention UNet3+ with New Supervised Prototypical Contrastive Loss for Coronary DSA Image Segmentation</title>
      <link>http://arxiv.org/abs/2504.05184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Work in progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MSA-UNet3+的冠状动脉DSA图像分割方法，以解决现有方法在低对比度、噪声、重叠结构、高类内方差和类别不平衡等问题。&lt;h4&gt;背景&lt;/h4&gt;精确分割冠状动脉DSA图像对于诊断和治疗冠状动脉疾病至关重要，但现有方法在处理这些挑战时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效分割冠状动脉DSA图像的深度学习模型，以支持临床诊断和治疗决策。&lt;h4&gt;方法&lt;/h4&gt;MSA-UNet3+结合了多尺度扩展瓶颈（MSD-Bottleneck）和上下文注意力融合模块（CAFM），同时引入了监督原型对比损失（SPCL）来减少类别不平衡和高类内方差。&lt;h4&gt;主要发现&lt;/h4&gt;在私有冠状动脉DSA数据集上的实验表明，MSA-UNet3+优于现有方法，实现了87.73%的Dice系数、87.78%的F1分数，以及显著降低的平均表面距离（ASD）和平均轮廓距离（ACD）。&lt;h4&gt;结论&lt;/h4&gt;MSA-UNet3+框架为临床医生提供了精确的血管分割，有助于准确识别冠状动脉狭窄，支持基于证据的诊断和治疗决策。&lt;h4&gt;翻译&lt;/h4&gt;摘要：冠状动脉数字减影血管造影（DSA）图像的精确分割对于诊断和治疗冠状动脉疾病至关重要。尽管基于深度学习的分割技术取得了进展，但低对比度、噪声、重叠结构、高类内方差和类别不平衡等挑战限制了精确的血管描绘。为了克服这些限制，我们提出了MSA-UNet3+：一种用于冠状动脉DSA图像分割的多尺度注意力增强UNet3+架构。该框架结合了多尺度扩展瓶颈（MSD-Bottleneck）和上下文注意力融合模块（CAFM），不仅增强了多尺度特征提取，还保留了细粒度细节，并提高了上下文理解。此外，我们提出了一种新的监督原型对比损失（SPCL），它结合了监督和原型对比学习，通过关注难以分类的背景样本来最小化类别不平衡和高类内方差。在私有冠状动脉DSA数据集上进行的实验表明，MSA-UNet3+优于现有方法，实现了87.73%的Dice系数、87.78%的F1分数，以及显著降低的平均表面距离（ASD）和平均轮廓距离（ACD）。该框架为临床医生提供了精确的血管分割，有助于准确识别冠状动脉狭窄，支持基于证据的诊断和治疗决策。代码将在以下GitHub链接发布：https://github.com/rayanmerghani/MSA-UNet3plus。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accurate segmentation of coronary Digital Subtraction Angiography (DSA)images is essential for diagnosing and treating coronary artery diseases.Despite advances in deep learning-based segmentation, challenges such as lowcontrast, noise, overlapping structures, high intra-class variance, and classimbalance limit precise vessel delineation. To overcome these limitations, wepropose the MSA-UNet3+: a Multi-Scale Attention enhanced UNet3+ architecturefor coronary DSA image segmentation. The framework combined Multi-Scale DilatedBottleneck (MSD-Bottleneck) with Contextual Attention Fusion Module (CAFM),which not only enhances multi-scale feature extraction but also preservefine-grained details, and improve contextual understanding. Furthermore, wepropose a new Supervised Prototypical Contrastive Loss (SPCL), which combinessupervised and prototypical contrastive learning to minimize class imbalanceand high intra-class variance by focusing on hard-to-classified backgroundsamples. Experiments carried out on a private coronary DSA dataset demonstratethat MSA-UNet3+ outperforms state-of-the-art methods, achieving a Dicecoefficient of 87.73%, an F1-score of 87.78%, and significantly reduced AverageSurface Distance (ASD) and Average Contour Distance (ACD). The developedframework provides clinicians with precise vessel segmentation, enablingaccurate identification of coronary stenosis and supporting informed diagnosticand therapeutic decisions. The code will be released at the following GitHubprofile link https://github.com/rayanmerghani/MSA-UNet3plus.</description>
      <author>example@mail.com (Rayan Merghani Ahmed, Adnan Iltaf, Bin Li, Shoujun Zhou)</author>
      <guid isPermaLink="false">2504.05184v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>PvNeXt: Rethinking Network Design and Temporal Motion for Point Cloud Video Recognition</title>
      <link>http://arxiv.org/abs/2504.05075v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为PvNeXt的框架，用于高效且有效地进行点云视频识别。&lt;h4&gt;背景&lt;/h4&gt;点云视频感知是3D视觉领域的关键任务，现有的4D表示学习技术通常涉及迭代处理和密集查询操作，导致计算冗余。&lt;h4&gt;目的&lt;/h4&gt;开发一个框架，通过个性化单次查询操作来实现点云视频的有效且高效识别。&lt;h4&gt;方法&lt;/h4&gt;PvNeXt包括两个关键模块：运动模仿器和单步运动编码器。运动模仿器用于捕获点云序列中的时间动态，生成与每帧对应的虚拟运动。单步运动编码器执行单步查询操作，将每帧的点云与其对应的虚拟运动帧关联，从而从点云序列中提取运动线索并捕捉整个序列的时间动态。&lt;h4&gt;主要发现&lt;/h4&gt;通过这两个模块的集成，PvNeXt实现了对每帧的个性化单次查询，有效消除了帧特定的循环和密集查询过程的需求。&lt;h4&gt;结论&lt;/h4&gt;在多个基准测试上的大量实验证明了该方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Point cloud video perception has become an essential task for the realm of 3Dvision. Current 4D representation learning techniques typically engage initerative processing coupled with dense query operations. Although effective incapturing temporal features, this approach leads to substantial computationalredundancy. In this work, we propose a framework, named as PvNeXt, foreffective yet efficient point cloud video recognition, via personalizedone-shot query operation. Specially, PvNeXt consists of two key modules, theMotion Imitator and the Single-Step Motion Encoder. The former module, theMotion Imitator, is designed to capture the temporal dynamics inherent insequences of point clouds, thus generating the virtual motion corresponding toeach frame. The Single-Step Motion Encoder performs a one-step query operation,associating point cloud of each frame with its corresponding virtual motionframe, thereby extracting motion cues from point cloud sequences and capturingtemporal dynamics across the entire sequence. Through the integration of thesetwo modules, {PvNeXt} enables personalized one-shot queries for each frame,effectively eliminating the need for frame-specific looping and intensive queryprocesses. Extensive experiments on multiple benchmarks demonstrate theeffectiveness of our method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud video perception has become an essential task for the realm of 3Dvision. Current 4D representation learning techniques typically engage initerative processing coupled with dense query operations. Although effective incapturing temporal features, this approach leads to substantial computationalredundancy. In this work, we propose a framework, named as PvNeXt, foreffective yet efficient point cloud video recognition, via personalizedone-shot query operation. Specially, PvNeXt consists of two key modules, theMotion Imitator and the Single-Step Motion Encoder. The former module, theMotion Imitator, is designed to capture the temporal dynamics inherent insequences of point clouds, thus generating the virtual motion corresponding toeach frame. The Single-Step Motion Encoder performs a one-step query operation,associating point cloud of each frame with its corresponding virtual motionframe, thereby extracting motion cues from point cloud sequences and capturingtemporal dynamics across the entire sequence. Through the integration of thesetwo modules, {PvNeXt} enables personalized one-shot queries for each frame,effectively eliminating the need for frame-specific looping and intensive queryprocesses. Extensive experiments on multiple benchmarks demonstrate theeffectiveness of our method.</description>
      <author>example@mail.com (Jie Wang, Tingfa Xu, Lihe Ding, Xinjie Zhang, Long Bai, Jianan Li)</author>
      <guid isPermaLink="false">2504.05075v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Inverse++: Vision-Centric 3D Semantic Occupancy Prediction Assisted with 3D Object Detection</title>
      <link>http://arxiv.org/abs/2504.04732v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多任务学习的3D语义占用预测方法，用于自动驾驶汽车通过车载全景摄像头预测周围环境的详细几何和语义信息。&lt;h4&gt;背景&lt;/h4&gt;现有的方法主要关注复杂内部结构模块设计以提升模型性能，例如高效的特征采样和聚合过程或中间特征表示格式。&lt;h4&gt;目的&lt;/h4&gt;通过引入额外的3D监督信号，结合额外的3D目标检测辅助分支，增强模型对场景中小型动态物体的捕捉能力，特别是对易受伤害的道路使用者（VRU）的检测，以确保自动驾驶汽车的安全性。&lt;h4&gt;方法&lt;/h4&gt;在nuScenes数据集上进行了广泛的实验，包括具有挑战性的雨天和夜间场景，展示了该方法达到最先进的性能，实现了31.73%的IoU分数和20.91%的mIoU分数，并在检测易受伤害的道路使用者方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;该方法通过引入额外的3D监督信号显著提升了模型性能，尤其在检测易受伤害的道路使用者方面表现出色。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is about a 3D semantic occupancy prediction method based on multitask learning, which aims to forecast detailed geometric and semantic information of the surrounding environment for autonomous vehicles (AVs) using onboard surround-view cameras. Existing methods mainly focus on complex internal structure module designs to improve model performance, such as efficient feature sampling and aggregation processes or intermediate feature representation formats. In this paper, we explore multitask learning by introducing an additional 3D supervision signal by incorporating an additional 3D object detection auxiliary branch. This extra 3D supervision signal enhances the model's overall performance by strengthening the capability of the intermediate features to capture small dynamic objects in the scene, and these small dynamic objects often include vulnerable road users, i.e. bicycles, motorcycles, and pedestrians, whose detection is crucial for ensuring driving safety in autonomous vehicles. Extensive experiments conducted on the nuScenes datasets, including challenging rainy and nighttime scenarios, showcase that our approach achieves state-of-the-art results, achieving an IoU score of 31.73% and a mIoU score of 20.91% and excels at detecting vulnerable road users (VRU). The code will be made available at: https://github.com/DanielMing123/Inverse++&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D semantic occupancy prediction aims to forecast detailed geometric andsemantic information of the surrounding environment for autonomous vehicles(AVs) using onboard surround-view cameras. Existing methods primarily focus onintricate inner structure module designs to improve model performance, such asefficient feature sampling and aggregation processes or intermediate featurerepresentation formats. In this paper, we explore multitask learning byintroducing an additional 3D supervision signal by incorporating an additional3D object detection auxiliary branch. This extra 3D supervision signal enhancesthe model's overall performance by strengthening the capability of theintermediate features to capture small dynamic objects in the scene, and thesesmall dynamic objects often include vulnerable road users, i.e. bicycles,motorcycles, and pedestrians, whose detection is crucial for ensuring drivingsafety in autonomous vehicles. Extensive experiments conducted on the nuScenesdatasets, including challenging rainy and nighttime scenarios, showcase thatour approach attains state-of-the-art results, achieving an IoU score of 31.73%and a mIoU score of 20.91% and excels at detecting vulnerable road users (VRU).The code will be made available at:https://github.com/DanielMing123/Inverse++</description>
      <author>example@mail.com (Zhenxing Ming, Julie Stephany Berrio, Mao Shan, Stewart Worrall)</author>
      <guid isPermaLink="false">2504.04732v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>TC-MGC: Text-Conditioned Multi-Grained Contrastive Learning for Text-Video Retrieval</title>
      <link>http://arxiv.org/abs/2504.04707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为TC-MGC的文本条件多粒度对比学习框架，用于文本-视频检索，并在多个基准测试中取得了有竞争力的结果。&lt;h4&gt;背景&lt;/h4&gt;多粒度对比学习方法在文本-视频检索中取得了成功，但视频的语义范围较广，可能导致文本无关的视频表示包含误导性信息。&lt;h4&gt;目的&lt;/h4&gt;提出TC-MGC框架，以解决文本-视频检索中模态语义对应关系捕捉不准确的问题。&lt;h4&gt;方法&lt;/h4&gt;TC-MGC模型采用语言-视频注意力块生成基于帧和文本注意力权重的聚合帧和视频表示。设计相似性重组模块以识别注意力相似性并重新组织跨模态相似性向量和矩阵。引入辅助相似性去相关正则化损失以最小化匹配文本-视频对的相似性方差，促进相似性方差最小化下的合作关系利用。最后，使用线性软最大化聚合模块来明确鼓励多个相似性之间的交互并促进多粒度信息的利用。&lt;h4&gt;主要发现&lt;/h4&gt;TC-MGC在多个文本-视频检索基准测试中取得了有竞争力的结果，在MSR-VTT、DiDeMo和VATEX上分别相对于X-CLIP模型在文本到视频检索R@1上实现了+2.8%（+1.3%）、+2.2%（+1.0%）和+1.5%（+0.9%）的相对（绝对）改进。&lt;h4&gt;结论&lt;/h4&gt;TC-MGC框架有效地解决了文本-视频检索中的模态语义对应关系捕捉问题，并在多个基准测试中取得了优异的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivated by the success of coarse-grained or fine-grained contrast intext-video retrieval, there emerge multi-grained contrastive learning methodswhich focus on the integration of contrasts with different granularity.However, due to the wider semantic range of videos, the text-agnostic videorepresentations might encode misleading information not described in texts,thus impeding the model from capturing precise cross-modal semanticcorrespondence. To this end, we propose a Text-Conditioned Multi-GrainedContrast framework, dubbed TC-MGC. Specifically, our model employs alanguage-video attention block to generate aggregated frame and videorepresentations conditioned on the word's and text's attention weights overframes. To filter unnecessary similarity interactions and decrease trainableparameters in the Interactive Similarity Aggregation (ISA) module, we design aSimilarity Reorganization (SR) module to identify attentive similarities andreorganize cross-modal similarity vectors and matrices. Next, we argue that theimbalance problem among multigrained similarities may result in over- andunder-representation issues. We thereby introduce an auxiliary SimilarityDecorrelation Regularization (SDR) loss to facilitate cooperative relationshiputilization by similarity variance minimization on matching text-video pairs.Finally, we present a Linear Softmax Aggregation (LSA) module to explicitlyencourage the interactions between multiple similarities and promote the usageof multi-grained information. Empirically, TC-MGC achieves competitive resultson multiple text-video retrieval benchmarks, outperforming X-CLIP model by+2.8% (+1.3%), +2.2% (+1.0%), +1.5% (+0.9%) relative (absolute) improvements intext-to-video retrieval R@1 on MSR-VTT, DiDeMo and VATEX, respectively. Ourcode is publicly available at https://github.com/JingXiaolun/TC-MGC.</description>
      <author>example@mail.com (Xiaolun Jing, Genke Yang, Jian Chu)</author>
      <guid isPermaLink="false">2504.04707v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>RS-RAG: Bridging Remote Sensing Imagery and Comprehensive Knowledge with a Multi-Modal Dataset and Retrieval-Augmented Generation Model</title>
      <link>http://arxiv.org/abs/2504.04988v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了在遥感视觉-语言任务中，如何利用视觉语言模型（VLMs）来增强语义推理能力，特别是在复杂或依赖特定领域知识的问题上。&lt;h4&gt;背景&lt;/h4&gt;VLMs在自然图像领域展现出强大的能力，遥感社区开始尝试将其应用于遥感视觉-语言任务，如场景理解、图像描述和视觉问答。&lt;h4&gt;目的&lt;/h4&gt;解决现有遥感VLMs缺乏外部知识集成和语义推理能力的问题。&lt;h4&gt;方法&lt;/h4&gt;引入了一个多模态遥感世界知识（RSWK）数据集，并提出了一个名为RS-RAG的新框架。该框架包括两个主要组件：多模态知识向量数据库构建模块和知识检索与响应生成模块。前者将遥感图像和相关文本知识编码到统一向量空间，后者根据图像和/或文本查询检索并重新排序相关知识，并将其纳入知识增强提示以指导VLM生成上下文相关的响应。&lt;h4&gt;主要发现&lt;/h4&gt;RS-RAG在图像描述、图像分类和视觉问答等三个代表性视觉-语言任务上，显著优于现有的最先进基线。&lt;h4&gt;结论&lt;/h4&gt;RS-RAG框架有效地提高了遥感视觉-语言任务中的语义推理能力。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Recent progress in VLMs has demonstrated impressive capabilities across a variety of tasks in the natural image domain. Motivated by these advancements, the remote sensing community has begun to adopt VLMs for remote sensing vision-language tasks, including scene understanding, image captioning, and visual question answering. However, existing remote sensing VLMs typically rely on closed-set scene understanding and focus on generic scene descriptions, yet lack the ability to incorporate external knowledge. This limitation hinders their capacity for semantic reasoning over complex or context-dependent queries that involve domain-specific or world knowledge. To address these challenges, we first introduced a multimodal Remote Sensing World Knowledge (RSWK) dataset, which comprises high-resolution satellite imagery and detailed textual descriptions for 14,141 well-known landmarks from 175 countries, integrating both remote sensing domain knowledge and broader world knowledge. Building upon this dataset, we proposed a novel Remote Sensing Retrieval-Augmented Generation (RS-RAG) framework, which consists of two key components. The Multi-Modal Knowledge Vector Database Construction module encodes remote sensing imagery and associated textual knowledge into a unified vector space. The Knowledge Retrieval and Response Generation module retrieves and re-ranks relevant knowledge based on image and/or text queries, and incorporates the retrieved content into a knowledge-augmented prompt to guide the VLM in producing contextually grounded responses. We validated the effectiveness of our approach on three representative vision-language tasks, including image captioning, image classification, and visual question answering, where RS-RAG significantly outperformed state-of-the-art baselines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent progress in VLMs has demonstrated impressive capabilities across avariety of tasks in the natural image domain. Motivated by these advancements,the remote sensing community has begun to adopt VLMs for remote sensingvision-language tasks, including scene understanding, image captioning, andvisual question answering. However, existing remote sensing VLMs typically relyon closed-set scene understanding and focus on generic scene descriptions, yetlack the ability to incorporate external knowledge. This limitation hinderstheir capacity for semantic reasoning over complex or context-dependent queriesthat involve domain-specific or world knowledge. To address these challenges,we first introduced a multimodal Remote Sensing World Knowledge (RSWK) dataset,which comprises high-resolution satellite imagery and detailed textualdescriptions for 14,141 well-known landmarks from 175 countries, integratingboth remote sensing domain knowledge and broader world knowledge. Building uponthis dataset, we proposed a novel Remote Sensing Retrieval-Augmented Generation(RS-RAG) framework, which consists of two key components. The Multi-ModalKnowledge Vector Database Construction module encodes remote sensing imageryand associated textual knowledge into a unified vector space. The KnowledgeRetrieval and Response Generation module retrieves and re-ranks relevantknowledge based on image and/or text queries, and incorporates the retrievedcontent into a knowledge-augmented prompt to guide the VLM in producingcontextually grounded responses. We validated the effectiveness of our approachon three representative vision-language tasks, including image captioning,image classification, and visual question answering, where RS-RAG significantlyoutperformed state-of-the-art baselines.</description>
      <author>example@mail.com (Congcong Wen, Yiting Lin, Xiaokang Qu, Nan Li, Yong Liao, Hui Lin, Xiang Li)</author>
      <guid isPermaLink="false">2504.04988v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>ADA-Net: Attention-Guided Domain Adaptation Network with Contrastive Learning for Standing Dead Tree Segmentation Using Aerial Imagery</title>
      <link>http://arxiv.org/abs/2504.04271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用空中多光谱正射影像分割立枯树木的新方法，并引入了基于域适应的领域迁移方法，以解决森林遥感中标注数据集获取困难的问题。&lt;h4&gt;背景&lt;/h4&gt;立枯树木的信息对理解森林生态系统功能和恢复力至关重要，但由于气候变化导致的大规模树木死亡事件，以及数据限制，这些问题在大型地理区域内一直缺乏研究。&lt;h4&gt;目的&lt;/h4&gt;研究目的是利用现有标注数据在目标域中预训练分割网络，然后将新的研究地点（源域X）的图像转换为目标域，通过域适应进行迁移学习。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为注意力引导的域适应网络（ADA-Net）的新方法，该方法结合了增强对比学习，旨在提供比现有方法更优的域适应性能。&lt;h4&gt;主要发现&lt;/h4&gt;使用来自芬兰和美国的两个数据集进行了评估，将美国图像转换为芬兰域，结果表明合成的USA2Finland数据集具有与芬兰域图像相似的特征。&lt;h4&gt;结论&lt;/h4&gt;ADA-Net方法提供了新的最先进的域适应性能，优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;本研究提出了一种利用空中多光谱正射影像分割立枯树木的新方法，并引入了基于域适应的领域迁移方法，旨在解决森林遥感中标注数据集获取困难的问题。通过引入注意力引导的域适应网络（ADA-Net）并使用增强对比学习，实现了优于现有方法的域适应性能。评估结果显示，将美国图像转换为芬兰域后，合成的USA2Finland数据集与芬兰域图像具有相似的特征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Information on standing dead trees is important for understanding forestecosystem functioning and resilience but has been lacking over large geographicregions. Climate change has caused large-scale tree mortality events that canremain undetected due to limited data. In this study, we propose a novel methodfor segmenting standing dead trees using aerial multispectral orthoimages.Because access to annotated datasets has been a significant problem in forestremote sensing due to the need for forest expertise, we introduce a method fordomain transfer by leveraging domain adaptation to learn a transformation froma source domain X to target domain Y. In this Image-to-Image translation task,we aim to utilize available annotations in the target domain by pre-training asegmentation network. When images from a new study site without annotations areintroduced (source domain X), these images are transformed into the targetdomain. Then, transfer learning is applied by inferring the pre-trained networkon domain-adapted images. In addition to investigating the feasibility ofcurrent domain adaptation approaches for this objective, we propose a novelapproach called the Attention-guided Domain Adaptation Network (ADA-Net) withenhanced contrastive learning. Accordingly, the ADA-Net approach provides newstate-of-the-art domain adaptation performance levels outperforming existingapproaches. We have evaluated the proposed approach using two datasets fromFinland and the US. The USA images are converted to the Finland domain, and weshow that the synthetic USA2Finland dataset exhibits similar characteristics tothe Finland domain images. The software implementation is shared athttps://github.com/meteahishali/ADA-Net. The data is publicly available athttps://www.kaggle.com/datasets/meteahishali/aerial-imagery-for-standing-dead-tree-segmentation.</description>
      <author>example@mail.com (Mete Ahishali, Anis Ur Rahman, Einari Heinaro, Samuli Junttila)</author>
      <guid isPermaLink="false">2504.04271v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Dual Consistent Constraint via Disentangled Consistency and Complementarity for Multi-view Clustering</title>
      <link>http://arxiv.org/abs/2504.04676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的多视角聚类框架，该框架通过解耦变分自动编码器将多视角信息分为共享信息和私有信息，从而学习到一致性和互补性信息。&lt;h4&gt;背景&lt;/h4&gt;多视角聚类可以探索多个视角的共同语义，近年来受到了越来越多的关注。然而，现有的方法主要集中在表示学习的一致性上，忽略了每个视角在表示学习中的互补性贡献。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来改善多视角表示学习，以同时利用一致性和互补性信息。&lt;h4&gt;方法&lt;/h4&gt;该方法通过对比学习最大化不同视角之间的互信息来学习信息丰富且一致性的表示。随后，利用一致性推理约束显式地利用互补信息，通过使用每个视角的私有和共享信息进行重构，以及使用所有视角的共享信息进行交叉重构。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法不仅有效地提高了数据表示的质量，而且易于扩展到其他场景，尤其是在复杂的多视角场景中。&lt;h4&gt;结论&lt;/h4&gt;本文的方法在多视角聚类中表现优于基线方法，并可能首次在统一的MVC理论框架中应用双重一致性约束。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel multi-view clustering framework that utilizes disentangled variational autoencoders to separate multi-view information into shared and private, thereby learning both consistency and complementarity information. The method first learns informative and consistent representations through contrastive learning, then employs consistency inference constraints to explicitly utilize complementary information by performing within-reconstruction using private and shared information of each view, and cross-reconstruction using shared information of all views. This approach effectively improves representation quality and is extendable to other scenarios. Extensive experiments demonstrate that the proposed method outperforms baseline methods, marking the first attempt to use dual consistency constraints within a unified MVC theoretical framework.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-view clustering can explore common semantics from multiple views andhas received increasing attention in recent years. However, current methodsfocus on learning consistency in representation, neglecting the contribution ofeach view's complementarity aspect in representation learning. This limit posesa significant challenge in multi-view representation learning. This paperproposes a novel multi-view clustering framework that introduces a disentangledvariational autoencoder that separates multi-view into shared and privateinformation, i.e., consistency and complementarity information. We first learninformative and consistent representations by maximizing mutual informationacross different views through contrastive learning. This process will ignorecomplementary information. Then, we employ consistency inference constraints toexplicitly utilize complementary information when attempting to seek theconsistency of shared information across all views. Specifically, we perform awithin-reconstruction using the private and shared information of each view anda cross-reconstruction using the shared information of all views. The dualconsistency constraints are not only effective in improving the representationquality of data but also easy to extend to other scenarios, especially incomplex multi-view scenes. This could be the first attempt to employ dualconsistent constraint in a unified MVC theoretical framework. During thetraining procedure, the consistency and complementarity features are jointlyoptimized. Extensive experiments show that our method outperforms baselinemethods.</description>
      <author>example@mail.com (Bo Li, Jing Yun)</author>
      <guid isPermaLink="false">2504.04676v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Egocentric Video Question Answering with Multimodal Large Language Models</title>
      <link>http://arxiv.org/abs/2504.04550v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文评估了多种多模态大型语言模型在以第一人称视角的Egocentric Video Question Answering任务上的表现，并引入了新的数据集QaEgo4Dv2以减少标注噪声，最终发现经过微调的Video-LLaVa-7B和Qwen2-VL-7B-Instruct模型在OpenQA和CloseQA任务上均取得了新的性能指标。&lt;h4&gt;背景&lt;/h4&gt;Egocentric Video Question Answering需要模型处理长时序推理、第一人称视角和频繁的摄像机运动等特殊挑战。&lt;h4&gt;目的&lt;/h4&gt;系统评估不同多模态大型语言模型在Egocentric Video Question Answering任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;使用零样本和微调方法评估了GPT-4o、Gemini-1.5-Pro、Video-LLaVa-7B和Qwen2-VL-7B-Instruct等四种模型，并引入了QaEgo4Dv2数据集以减少标注噪声。&lt;h4&gt;主要发现&lt;/h4&gt;经过微调的Video-LLaVa-7B和Qwen2-VL-7B-Instruct模型在OpenQA和CloseQA任务上均超越了之前的基准，其中OpenQA提升了+2.6%的ROUGE/METEOR指标，CloseQA提升了+13%的准确率。&lt;h4&gt;结论&lt;/h4&gt;模型在空间推理和细粒度物体识别方面存在困难，这些是未来改进的关键领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要：以自我为中心的视频问答（QA）要求模型处理长时序推理、第一人称视角和如频繁摄像机运动等特殊挑战。本文系统地评估了私有和开源的多模态大型语言模型（MLLMs）在QaEgo4Dv2上的表现——这是一个由QaEgo4D衍生的以自我为中心的视频的精炼数据集。使用零样本和微调方法对四种流行的MLLMs（GPT-4o、Gemini-1.5-Pro、Video-LLaVa-7B和Qwen2-VL-7B-Instruct）进行了评估，评估场景包括OpenQA和CloseQA。我们引入QaEgo4Dv2以减轻QaEgo4D中的标注噪声，从而实现更可靠的比较。我们的结果表明，经过微调的Video-LLaVa-7B和Qwen2-VL-7B-Instruct在OpenQA和CloseQA任务上实现了新的最先进性能，分别超过了之前的基准+2.6% ROUGE/METEOR（对于OpenQA）和+13%准确率（对于CloseQA）。我们还进行了一项详尽的错误分析，表明模型在空间推理和细粒度物体识别方面存在困难，这些是未来改进的关键领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Egocentric Video Question Answering (QA) requires models to handlelong-horizon temporal reasoning, first-person perspectives, and specializedchallenges like frequent camera movement. This paper systematically evaluatesboth proprietary and open-source Multimodal Large Language Models (MLLMs) onQaEgo4Dv2 - a refined dataset of egocentric videos derived from QaEgo4D. Fourpopular MLLMs (GPT-4o, Gemini-1.5-Pro, Video-LLaVa-7B and Qwen2-VL-7B-Instruct)are assessed using zero-shot and fine-tuned approaches for both OpenQA andCloseQA settings. We introduce QaEgo4Dv2 to mitigate annotation noise inQaEgo4D, enabling more reliable comparison. Our results show that fine-tunedVideo-LLaVa-7B and Qwen2-VL-7B-Instruct achieve new state-of-the-artperformance, surpassing previous benchmarks by up to +2.6% ROUGE/METEOR (forOpenQA) and +13% accuracy (for CloseQA). We also present a thorough erroranalysis, indicating the model's difficulty in spatial reasoning andfine-grained object recognition - key areas for future improvement.</description>
      <author>example@mail.com (Alkesh Patel, Vibhav Chitalia, Yinfei Yang)</author>
      <guid isPermaLink="false">2504.04550v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>TDFANet: Encoding Sequential 4D Radar Point Clouds Using Trajectory-Guided Deformable Feature Aggregation for Place Recognition</title>
      <link>http://arxiv.org/abs/2504.05103v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures. Accepted to ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究利用4D雷达进行地点识别，针对4D雷达数据稀疏、噪声大、分辨率低的特点，提出了一种基于多模态信息的方法，通过提取和聚合时空特征，实现地点识别。&lt;h4&gt;背景&lt;/h4&gt;地点识别对于自动驾驶车辆和移动机器人实现闭环或全局定位至关重要。虽然2D相机和3D激光雷达在地点识别方面取得了进展，但4D雷达作为对恶劣天气和光照条件具有鲁棒性的传感器，其在地点识别中的应用尚待探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用4D雷达进行地点识别的方法，以应对4D雷达数据的特点带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;方法包括：(1) 从速度属性中去除动态点和估计自我速度，(2) 在精炼的点云上进行鸟瞰图（BEV）特征编码，(3) 使用自我速度计算的BEV特征图运动轨迹进行特征对齐，(4) 提取和聚合对齐后的BEV特征图的多尺度时空特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在实际环境中是可行的，并展示了其在处理动态环境中的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法有效解决了4D雷达在地点识别中的挑战，为自动驾驶和移动机器人领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;地点识别对于实现自动驾驶车辆和移动机器人的闭环或全局定位至关重要。尽管在利用2D相机或3D激光雷达进行地点识别方面取得了进展，但如何使用4D雷达进行地点识别——这种传感器因其对恶劣天气和光照条件的鲁棒性而越来越受欢迎——仍需进一步研究。与激光雷达点云相比，雷达数据明显稀疏、噪声大、分辨率低，这阻碍了它们有效地表示场景，为基于4D雷达的地点识别带来了重大挑战。这项工作通过利用连续4D雷达扫描的多模态信息，有效地提取和聚合时空特征来解决这些挑战。我们的方法遵循一个原则性的流程，包括：(1) 从速度属性中去除动态点和估计自我速度，(2) 在精炼的点云上进行鸟瞰图（BEV）特征编码，(3) 使用自我速度计算的BEV特征图运动轨迹进行特征对齐，(4) 提取和聚合对齐后的BEV特征图的多尺度时空特征。实际实验结果验证了所提出方法的可行性，并展示了其在处理动态环境中的鲁棒性。源代码可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Place recognition is essential for achieving closed-loop or globalpositioning in autonomous vehicles and mobile robots. Despite recentadvancements in place recognition using 2D cameras or 3D LiDAR, it remains tobe seen how to use 4D radar for place recognition - an increasingly popularsensor for its robustness against adverse weather and lighting conditions.Compared to LiDAR point clouds, radar data are drastically sparser, noisier andin much lower resolution, which hampers their ability to effectively representscenes, posing significant challenges for 4D radar-based place recognition.This work addresses these challenges by leveraging multi-modal information fromsequential 4D radar scans and effectively extracting and aggregatingspatio-temporal features.Our approach follows a principled pipeline thatcomprises (1) dynamic points removal and ego-velocity estimation from velocityproperty, (2) bird's eye view (BEV) feature encoding on the refined pointcloud, (3) feature alignment using BEV feature map motion trajectory calculatedby ego-velocity, (4) multi-scale spatio-temporal features of the aligned BEVfeature maps are extracted and aggregated.Real-world experimental resultsvalidate the feasibility of the proposed method and demonstrate its robustnessin handling dynamic environments. Source codes are available.</description>
      <author>example@mail.com (Shouyi Lu, Guirong Zhuo, Haitao Wang, Quan Zhou, Huanyu Zhou, Renbo Huang, Minqing Huang, Lianqing Zheng, Qiang Shu)</author>
      <guid isPermaLink="false">2504.05103v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>AsyReC: A Multimodal Graph-based Framework for Spatio-Temporal Asymmetric Dyadic Relationship Classification</title>
      <link>http://arxiv.org/abs/2504.05030v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AsyReC的多模态图神经网络框架，用于解决计算模型在模拟双人对称关系时面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;双人对称关系通过重复互动形成，受到共享时空经验的影响。现有的计算方法在模拟这类关系时存在三个主要问题：未能模拟不对称关系、连续互动被离散框架采样中断、无法考虑周期性行为线索。&lt;h4&gt;目的&lt;/h4&gt;提出AsyReC框架以解决上述挑战，提高双人对称关系分类的准确性。&lt;h4&gt;方法&lt;/h4&gt;AsyReC框架包括三项创新：节点-边双重注意力机制的图神经网络、剪辑级关系学习架构、周期性时间编码器。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公开数据集上的实验表明，AsyReC框架在双人对称关系分类方面取得了最先进的性能。消融实验验证了不对称互动建模和周期性时间编码在提高现实场景中双人对称关系分类鲁棒性中的关键作用。&lt;h4&gt;结论&lt;/h4&gt;AsyReC框架为模拟双人对称关系提供了一种有效的方法，并在实际场景中显示出良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a multimodal graph neural network framework named AsyReC to address the challenges faced by existing computational methods in modeling dyadic relationships. AsyReC includes three core innovations: a triplet graph neural network with node-edge dual attention, a clip-level relationship learning architecture, and a periodic temporal encoder. Experiments on two public datasets demonstrate state-of-the-art performance, and ablation studies validate the critical role of asymmetric interaction modeling and periodic temporal encoding in improving the robustness of dyadic relationship classification in real-world scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dyadic social relationships, which refer to relationships between twoindividuals who know each other through repeated interactions (or not), areshaped by shared spatial and temporal experiences. Current computationalmethods for modeling these relationships face three major challenges: (1) thefailure to model asymmetric relationships, e.g., one individual may perceivethe other as a friend while the other perceives them as an acquaintance, (2)the disruption of continuous interactions by discrete frame sampling, whichsegments the temporal continuity of interaction in real-world scenarios, and(3) the limitation to consider periodic behavioral cues, such as rhythmicvocalizations or recurrent gestures, which are crucial for inferring theevolution of dyadic relationships. To address these challenges, we proposeAsyReC, a multimodal graph-based framework for asymmetric dyadic relationshipclassification, with three core innovations: (i) a triplet graph neural networkwith node-edge dual attention that dynamically weights multimodal cues tocapture interaction asymmetries (addressing challenge 1); (ii) a clip-levelrelationship learning architecture that preserves temporal continuity, enablingfine-grained modeling of real-world interaction dynamics (addressing challenge2); and (iii) a periodic temporal encoder that projects time indices ontosine/cosine waveforms to model recurrent behavioral patterns (addressingchallenge 3). Extensive experiments on two public datasets demonstratestate-of-the-art performance, while ablation studies validate the critical roleof asymmetric interaction modeling and periodic temporal encoding in improvingthe robustness of dyadic relationship classification in real-world scenarios.Our code is publicly available at: https://github.com/tw-repository/AsyReC.</description>
      <author>example@mail.com (Wang Tang, Fethiye Irmak Dogan, Linbo Qing, Hatice Gunes)</author>
      <guid isPermaLink="false">2504.05030v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>SAFT: Structure-aware Transformers for Textual Interaction Classification</title>
      <link>http://arxiv.org/abs/2504.04861v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的架构SAFT，用于有效融合文本和结构语义，以学习交互表示。&lt;h4&gt;背景&lt;/h4&gt;文本交互网络（TINs）被广泛应用于电商网站、社交网络等领域，用于建模用户与物品之间的交互，每个交互都与文本描述相关联。文本交互分类（TIC）在检测电商中的垃圾评论、金融中的欺诈交易等方面有广泛应用。&lt;h4&gt;目的&lt;/h4&gt;解决现有TIC解决方案未能捕捉丰富的文本语义和忽视TINs的二元结构和节点异质性，导致TIC性能下降的问题。&lt;h4&gt;方法&lt;/h4&gt;SAFT通过整合语言和图模块，利用行图注意力（LGA）/门控注意力单元（GAUs）和预训练语言模型（PLMs）来建模交互级别和标记级别的信号，并通过代理标记以迭代和上下文化的方式进行耦合。此外，开发了一种有效且理论基础的编码方法，将交互相关的局部和全局拓扑信息编码到结构嵌入中。&lt;h4&gt;主要发现&lt;/h4&gt;SAFT将TINs的结构特征注入到文本交互编码中，并促进了图采样策略的设计。&lt;h4&gt;结论&lt;/h4&gt;在多个真实TIN数据集上的广泛实证评估表明，SAFT在TIC准确率方面优于最先进的基线。&lt;h4&gt;翻译&lt;/h4&gt;摘要：文本交互网络（TINs）是一种无处不在的数据结构，用于模拟电子商务网站、社交网络等场景中用户与物品之间的互动，其中每个互动都与文本描述相关联。文本交互分类（TIC）在检测电子商务中的垃圾评论、金融中的欺诈交易等方面有广泛的应用。现有的TIC解决方案要么（i）由于使用上下文无关的文本嵌入而未能捕捉丰富的文本语义，要么（ii）忽视了TINs的二元结构和节点异质性，导致TIC性能下降。在本工作中，我们提出了一种新的架构SAFT，它集成了语言和图模块，用于有效地融合交互表示中的文本和结构语义。特别是，利用行图注意力（LGA）/门控注意力单元（GAUs）和预训练语言模型（PLMs）来建模交互级和标记级信号，并通过代理标记以迭代和上下文化的方式进行耦合。此外，开发了一种有效且理论基础的编码方法，将交互相关的局部和全局拓扑信息编码到结构嵌入中。得到的嵌入不仅将TINs的结构特征注入到文本交互编码中，还有助于设计图采样策略。在多个真实TIN数据集上的广泛实证评估表明，SAFT在TIC准确率方面优于最先进的基线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Textual interaction networks (TINs) are an omnipresent data structure used tomodel the interplay between users and items on e-commerce websites, socialnetworks, etc., where each interaction is associated with a text description.Classifying such textual interactions (TIC) finds extensive use in detectingspam reviews in e-commerce, fraudulent transactions in finance, and so on.Existing TIC solutions either (i) fail to capture the rich text semantics dueto the use of context-free text embeddings, and/or (ii) disregard the bipartitestructure and node heterogeneity of TINs, leading to compromised TICperformance. In this work, we propose SAFT, a new architecture that integrateslanguage- and graph-based modules for the effective fusion of textual andstructural semantics in the representation learning of interactions. Inparticular, line graph attention (LGA)/gated attention units (GAUs) andpretrained language models (PLMs) are capitalized on to model theinteraction-level and token-level signals, which are further coupled via theproxy token in an iterative and contextualized fashion. Additionally, anefficient and theoretically-grounded approach is developed to encode the localand global topology information pertaining to interactions into structuralembeddings. The resulting embeddings not only inject the structural featuresunderlying TINs into the textual interaction encoding but also facilitate thedesign of graph sampling strategies. Extensive empirical evaluations onmultiple real TIN datasets demonstrate the superiority of SAFT over thestate-of-the-art baselines in TIC accuracy.</description>
      <author>example@mail.com (Hongtao Wang, Renchi Yang, Hewen Wang, Haoran Zheng, Jianliang Xu)</author>
      <guid isPermaLink="false">2504.04861v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>GAMDTP: Dynamic Trajectory Prediction with Graph Attention Mamba Network</title>
      <link>http://arxiv.org/abs/2504.04862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GAMDTP的新型图注意力网络，用于动态轨迹预测，以提高自动驾驶系统的安全性和稳定性。&lt;h4&gt;背景&lt;/h4&gt;精确的交通参与者运动预测对于自动驾驶系统的安全性和稳定性至关重要。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的网络模型，以更高效和准确地提取特征，从而提高动态轨迹预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;GAMDTP通过GAT机制融合自注意力机制和mamba-ssm的结果，并在每个图卷积层中利用这两种方法的优点。此外，还设计了一种评分机制来评估预测质量。&lt;h4&gt;主要发现&lt;/h4&gt;GAMDTP在Argoverse数据集上实现了最先进的性能，在动态轨迹预测方面具有优越的准确性。&lt;h4&gt;结论&lt;/h4&gt;GAMDTP在动态轨迹预测方面表现出色，为自动驾驶系统的安全性和稳定性提供了有效的技术支持。&lt;h4&gt;翻译&lt;/h4&gt;Accurate motion prediction of traffic agents is crucial for the safety and stability of autonomous driving systems. In this paper, we introduce GAMDTP, a novel graph attention-based network tailored for dynamic trajectory prediction. Specifically, we fuse the result of self attention and mamba-ssm through a gat mechanism, leveraging the strengths of both to extract features more efficiently and accurately, in each graph convolution layer. GAMDTP encodes the high-definition map (HD map) data and the agents' historical trajectory coordinates and decodes the network's output to generate the final prediction results. Additionally, recent approaches predominantly focus on dynamically fusing historical forecast results and rely on two-stage frameworks including proposal and refinement. To further enhance the performance of the two-stage frameworks we also design a scoring mechanism to evaluate the prediction quality during the proposal and refinement processes. Experiments on the Argoverse dataset demonstrates that GAMDTP achieves state-of-the-art performance, achieving superior accuracy in dynamic trajectory prediction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate motion prediction of traffic agents is crucial for the safety andstability of autonomous driving systems. In this paper, we introduce GAMDTP, anovel graph attention-based network tailored for dynamic trajectory prediction.Specifically, we fuse the result of self attention and mamba-ssm through a gatemechanism, leveraging the strengths of both to extract features moreefficiently and accurately, in each graph convolution layer. GAMDTP encodes thehigh-definition map(HD map) data and the agents' historical trajectorycoordinates and decodes the network's output to generate the final predictionresults. Additionally, recent approaches predominantly focus on dynamicallyfusing historical forecast results and rely on two-stage frameworks includingproposal and refinement. To further enhance the performance of the two-stageframeworks we also design a scoring mechanism to evaluate the predictionquality during the proposal and refinement processes. Experiments on theArgoverse dataset demonstrates that GAMDTP achieves state-of-the-artperformance, achieving superior accuracy in dynamic trajectory prediction.</description>
      <author>example@mail.com (Yunxiang Liu, Hongkuo Niu, Jianlin Zhu)</author>
      <guid isPermaLink="false">2504.04862v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>ZFusion: An Effective Fuser of Camera and 4D Radar for 3D Object Perception in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2504.03438v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025 WDFM-AD&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于4D雷达和视觉融合的3D物体检测方法，名为ZFusion，以提高自动驾驶中的可靠3D物体感知。&lt;h4&gt;背景&lt;/h4&gt;尽管4D雷达在所有天气条件下具有传感能力，但其提供的点云数据比LiDAR稀疏。&lt;h4&gt;目的&lt;/h4&gt;提高自动驾驶中的3D物体检测准确性。&lt;h4&gt;方法&lt;/h4&gt;ZFusion方法融合了4D雷达和视觉模态，其核心FP-DDCA（特征金字塔-双可变形交叉注意力）融合器有效地补充了雷达信息和视觉信息。FP-DDCA融合器使用特征金字塔结构，包含Transformer块，以不同尺度交互式融合多模态特征。此外，利用了4D雷达的物理特性，采用Depth-Context-Split视图变换模块。&lt;h4&gt;主要发现&lt;/h4&gt;在VoD（Delft视角）数据集等典型交通场景中，ZFusion在感兴趣区域实现了最先进的mAP（平均精度均值），在整体区域与基线方法相比具有竞争力的mAP，表现出接近LiDAR的性能，并远超仅使用摄像头的检测方法。&lt;h4&gt;结论&lt;/h4&gt;ZFusion是一种具有竞争力的替代LiDAR的方法，特别是在成本方面具有优势。&lt;h4&gt;翻译&lt;/h4&gt;Reliable 3D object perception is essential in autonomous driving. Owing to its sensing capabilities in all weather conditions, 4D radar has recently received much attention. However, compared to LiDAR, 4D radar provides much sparser point cloud. In this paper, we propose a 3D object detection method, termed ZFusion, which fuses 4D radar and vision modality. As the core of ZFusion, our proposed FP-DDCA (Feature Pyramid-Double Deformable CrossAttention) fuser complements the (sparse) radar information and (dense) vision information, effectively. Specifically, with a feature-pyramid structure, the FP-DDCA fuser packs Transformer blocks to interactively fuse multi-modal features at different scales, thus enhancing perception accuracy. In addition, we utilize the Depth-Context-Split view transformation module due to the physical properties of 4D radar. Considering that 4D radar has a much lower cost than LiDAR, ZFusion is an attractive alternative to LiDAR-based methods. In typical traffic scenarios like the VoD (View-of-Delft) dataset, experiments show that with reasonable inference speed, ZFusion achieved the state-of-the-art mAP (mean average precision) in the region of interest, while having competitive mAP in the entire area compared to the baseline methods, which demonstrates performance close to LiDAR and greatly outperforms those camera-only methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable 3D object perception is essential in autonomous driving. Owing toits sensing capabilities in all weather conditions, 4D radar has recentlyreceived much attention. However, compared to LiDAR, 4D radar provides muchsparser point cloud. In this paper, we propose a 3D object detection method,termed ZFusion, which fuses 4D radar and vision modality. As the core ofZFusion, our proposed FP-DDCA (Feature Pyramid-Double Deformable CrossAttention) fuser complements the (sparse) radar information and (dense) visioninformation, effectively. Specifically, with a feature-pyramid structure, theFP-DDCA fuser packs Transformer blocks to interactively fuse multi-modalfeatures at different scales, thus enhancing perception accuracy. In addition,we utilize the Depth-Context-Split view transformation module due to thephysical properties of 4D radar. Considering that 4D radar has a much lowercost than LiDAR, ZFusion is an attractive alternative to LiDAR-based methods.In typical traffic scenarios like the VoD (View-of-Delft) dataset, experimentsshow that with reasonable inference speed, ZFusion achieved thestate-of-the-art mAP (mean average precision) in the region of interest, whilehaving competitive mAP in the entire area compared to the baseline methods,which demonstrates performance close to LiDAR and greatly outperforms thosecamera-only methods.</description>
      <author>example@mail.com (Sheng Yang, Tong Zhan, Shichen Qiao, Jicheng Gong, Qing Yang, Jian Wang, Yanfeng Lu)</author>
      <guid isPermaLink="false">2504.03438v2</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Feedback-Enhanced Hallucination-Resistant Vision-Language Model for Real-Time Scene Understanding</title>
      <link>http://arxiv.org/abs/2504.04772v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将自我意识嵌入人工智能的方法，以解决实时场景理解中的幻觉问题，提高人工智能在机器人、监控和辅助工具等领域的应用。&lt;h4&gt;背景&lt;/h4&gt;实时场景理解是人工智能的关键进步，但幻觉问题仍然是一个挑战，AI系统常常误解视觉输入，检测不存在的事物或描述从未发生的事件。&lt;h4&gt;目的&lt;/h4&gt;通过将自我意识嵌入AI，提高AI系统的可靠性，特别是在安全、自主导航等对准确性至关重要的领域。&lt;h4&gt;方法&lt;/h4&gt;该方法通过实时评估AI的初始输出，动态调整置信度阈值，并在确定度低于基准时抑制不可靠的声明。结合YOLOv5的对象检测能力和VILA1.5-3B的受控语言生成，将描述与已确认的视觉数据关联。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过动态阈值调整提高了准确性，基于证据的文本减少了幻觉，并实现了每秒18帧的实时性能。&lt;h4&gt;结论&lt;/h4&gt;与传统的相比，这种方法将幻觉减少了37%，具有快速、灵活和可靠的特点，在机器人导航、安全监控等领域表现出色，使AI感知与现实相符。&lt;h4&gt;翻译&lt;/h4&gt;摘要：实时场景理解是人工智能的关键进步，增强了机器人、监控和辅助工具。然而，幻觉仍然是一个挑战。AI系统经常误解视觉输入，检测不存在的事物或描述从未发生的事件。这些错误，远非微不足道，威胁到在安全、自主导航等对准确性至关重要的关键领域的可靠性。我们的方法通过将自我意识嵌入AI来解决这个问题。我们不是信任初始输出，而是我们的框架在实时中持续评估它们，动态调整置信度阈值。当确定性低于一个明确的基准时，它抑制不可靠的声明。结合YOLOv5的对象检测强度和VILA1.5-3B的受控语言生成，我们将描述与已确认的视觉数据关联。优点包括动态阈值调整以提高准确性，基于证据的文本以减少幻觉，以及每秒18帧的实时性能。这种反馈驱动的设计将幻觉减少了37%以上。快速、灵活、可靠，它在机器人导航、安全监控等应用中表现出色，使AI感知与现实相符。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-time scene comprehension is a key advance in artificial intelligence,enhancing robotics, surveillance, and assistive tools. However, hallucinationremains a challenge. AI systems often misinterpret visual inputs, detectingnonexistent objects or describing events that never happened. These errors, farfrom minor, threaten reliability in critical areas like security and autonomousnavigation where accuracy is essential.  Our approach tackles this by embedding self-awareness into the AI. Instead oftrusting initial outputs, our framework continuously assesses them in realtime, adjusting confidence thresholds dynamically. When certainty falls below asolid benchmark, it suppresses unreliable claims. Combining YOLOv5's objectdetection strength with VILA1.5-3B's controlled language generation, we tiedescriptions to confirmed visual data. Strengths include dynamic thresholdtuning for better accuracy, evidence-based text to reduce hallucination, andreal-time performance at 18 frames per second.  This feedback-driven design cuts hallucination by 37 percent over traditionalmethods. Fast, flexible, and reliable, it excels in applications from roboticnavigation to security monitoring, aligning AI perception with reality.</description>
      <author>example@mail.com (Zahir Alsulaimawi)</author>
      <guid isPermaLink="false">2504.04772v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Data Scaling Laws for End-to-End Autonomous Driving</title>
      <link>http://arxiv.org/abs/2504.04338v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 11 figures, 4 tables, CVPR 2025 Workshop on Autonomous  Driving&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了自动驾驶系统架构，对比了传统的分解方法和端到端可微分模型，并评估了不同数据集大小对系统性能的影响。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶系统通常采用分解方法，分别处理感知、预测和规划等模块，但这可能导致信息损失和计算开销。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文评估了一种简单的端到端驾驶架构在内部驾驶数据集上的性能，并研究了训练数据集大小与模型性能之间的关系。&lt;h4&gt;方法&lt;/h4&gt;在内部驾驶数据集上，通过开放循环指标和闭环模拟评估了简单端到端驾驶架构的性能，并分析了额外训练数据对性能提升的影响。&lt;h4&gt;主要发现&lt;/h4&gt;本文发现，通过增加训练数据集大小，可以实现目标性能提升，例如提高运动预测准确性的5%。&lt;h4&gt;结论&lt;/h4&gt;本文为自动驾驶开发中的数据驱动决策提供了见解，强调了数据工程在系统性能提升中的重要性。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the architecture of autonomous vehicle systems, compares the traditional decomposed approach with the end-to-end differentiable model, and evaluates the impact of different dataset sizes on system performance. The study evaluates the performance of a simple end-to-end driving architecture on internal driving datasets ranging in size from 16 to 8192 hours using open-loop metrics and closed-loop simulations, and analyzes the impact of additional training data on performance improvement. The findings show that by increasing the size of the training dataset, a targeted performance improvement, such as a 5% increase in motion prediction accuracy, can be achieved. This study provides insights for data-driven decision-making in the development of autonomous driving and emphasizes the importance of data engineering in enhancing system performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous vehicle (AV) stacks have traditionally relied on decomposedapproaches, with separate modules handling perception, prediction, andplanning. However, this design introduces information loss during inter-modulecommunication, increases computational overhead, and can lead to compoundingerrors. To address these challenges, recent works have proposed architecturesthat integrate all components into an end-to-end differentiable model, enablingholistic system optimization. This shift emphasizes data engineering oversoftware integration, offering the potential to enhance system performance bysimply scaling up training resources. In this work, we evaluate the performanceof a simple end-to-end driving architecture on internal driving datasetsranging in size from 16 to 8192 hours with both open-loop metrics andclosed-loop simulations. Specifically, we investigate how much additionaltraining data is needed to achieve a target performance gain, e.g., a 5%improvement in motion prediction accuracy. By understanding the relationshipbetween model performance and training dataset size, we aim to provide insightsfor data-driven decision-making in autonomous driving development.</description>
      <author>example@mail.com (Alexander Naumann, Xunjiang Gu, Tolga Dimlioglu, Mariusz Bojarski, Alperen Degirmenci, Alexander Popov, Devansh Bisla, Marco Pavone, Urs Müller, Boris Ivanovic)</author>
      <guid isPermaLink="false">2504.04338v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Sub-Clustering for Class Distance Recalculation in Long-Tailed Drug Classification</title>
      <link>http://arxiv.org/abs/2504.04647v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了长尾数据分布下的模型学习与分类问题，特别是在药物化学领域，提出了一种新的方法来改善长尾类别的分类性能。&lt;h4&gt;背景&lt;/h4&gt;在现实世界中，长尾数据分布普遍存在，使得模型难以有效学习并分类尾部类别。然而，在药物化学领域，某些尾部类别由于独特的分子结构特征，在训练过程中表现出更高的可识别性，这与传统理解相矛盾。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有不平衡学习方法过度依赖样本数量先验的问题，提出了一种新的方法，以改善尾部类别的分类性能，同时不损害主导类别的性能。&lt;h4&gt;方法&lt;/h4&gt;该方法打破传统的基于样本大小的静态评估范式，通过使用不同类别之间的特征距离建立动态的类间可分离性度量。具体来说，采用子聚类对比学习方法来全面学习每个类别的嵌入特征，并动态计算类别嵌入之间的距离，以捕捉不同类别样本在特征空间中的相对位置演化，从而重新平衡分类损失函数的权重。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，在药物化学领域，某些尾部类别由于独特的分子结构特征，在训练过程中表现出更高的可识别性。同时，提出的方法在不牺牲主导类别性能的情况下，显著提高了尾部类别的分类准确率。&lt;h4&gt;结论&lt;/h4&gt;该方法在多个现有的长尾药物数据集上进行了实验，并取得了有竞争力的结果，证明了其在改善尾部类别分类性能方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;In the real world, long-tailed data distributions are prevalent, making it challenging for models to effectively learn and classify tail classes. However, we discover that in the field of drug chemistry, certain tail classes exhibit higher identifiability during training due to their unique molecular structural features, a finding that significantly contrasts with the conventional understanding that tail classes are generally difficult to identify. Existing imbalance learning methods, such as resampling and cost-sensitive reweighting, overly rely on sample quantity priors, causing models to excessively focus on tail classes at the expense of head class performance. To address this issue, we propose a novel method that breaks away from the traditional static evaluation paradigm based on sample size. Instead, we establish a dynamic inter-class separability metric using feature distances between different classes. Specifically, we employ a sub-clustering contrastive learning approach to thoroughly learn the embedding features of each class, and we dynamically compute the distances between class embeddings to capture the relative positional evolution of samples from different classes in the feature space, thereby rebalancing the weights of the classification loss function. We conducted experiments on multiple existing long-tailed drug datasets and achieved competitive results by improving the accuracy of tail classes without compromising the performance of dominant classes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the real world, long-tailed data distributions are prevalent, making itchallenging for models to effectively learn and classify tail classes. However,we discover that in the field of drug chemistry, certain tail classes exhibithigher identifiability during training due to their unique molecular structuralfeatures, a finding that significantly contrasts with the conventionalunderstanding that tail classes are generally difficult to identify. Existingimbalance learning methods, such as resampling and cost-sensitive reweighting,overly rely on sample quantity priors, causing models to excessively focus ontail classes at the expense of head class performance. To address this issue,we propose a novel method that breaks away from the traditional staticevaluation paradigm based on sample size. Instead, we establish a dynamicalinter-class separability metric using feature distances between differentclasses. Specifically, we employ a sub-clustering contrastive learning approachto thoroughly learn the embedding features of each class, and we dynamicallycompute the distances between class embeddings to capture the relativepositional evolution of samples from different classes in the feature space,thereby rebalancing the weights of the classification loss function. Weconducted experiments on multiple existing long-tailed drug datasets andachieved competitive results by improving the accuracy of tail classes withoutcompromising the performance of dominant classes.</description>
      <author>example@mail.com (Yujia Su, Xinjie Li, Lionel Z. Wang)</author>
      <guid isPermaLink="false">2504.04647v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>VideoAgent2: Enhancing the LLM-Based Agent System for Long-Form Video Understanding by Uncertainty-Aware CoT</title>
      <link>http://arxiv.org/abs/2504.04471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种专门针对长视频分析的特殊思维链（CoT）过程，以应对现有方法在处理长视频时遇到的挑战。&lt;h4&gt;背景&lt;/h4&gt;长视频理解是计算机视觉中的一个越来越重要的挑战性任务，基于代理的方法因其能够处理长序列并整合各种工具来捕获细粒度信息而受到青睐。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法仅依赖大型语言模型（LLMs）的推理能力而缺乏针对长视频场景的增强推理机制，以及对外部工具错误或噪声的脆弱性问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种带有计划调整模式的CoT过程，该过程允许LLM逐步规划和调整其信息收集策略。此外，还纳入了LLM和外部工具的启发式不确定性估计，以指导CoT过程，使LLM能够评估新收集信息的可靠性，优化其收集策略，并在综合最终答案时做出更稳健的决策。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，这种不确定性感知的CoT有效地减轻了外部工具的噪声，导致更可靠的结果。&lt;h4&gt;结论&lt;/h4&gt;实现的方法在名为VideoAgent2的系统中，该系统还包括通用上下文获取和专用工具设计等额外模块。在三个专门的长视频基准测试（及其子集）上的评估表明，VideoAgent2的平均性能比以前的基于代理的方法VideoAgent高出13.1%，并且在所有零样本方法中取得了领先性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：长视频理解已成为计算机视觉中越来越重要且具有挑战性的任务。基于代理的方法因其能够处理长序列并整合各种工具来捕获细粒度信息而越来越受欢迎。然而，现有方法仍面临几个挑战：(1)它们通常仅依赖于大型语言模型（LLMs）的推理能力，而没有针对长视频场景的专门机制来增强推理；(2)它们仍然容易受到外部工具错误或噪声的影响。为了解决这些问题，我们提出了一种专门针对长视频分析的特殊思维链（CoT）过程。我们提出的带有计划调整模式的CoT过程允许LLM逐步规划和调整其信息收集策略。我们进一步纳入了LLM和外部工具的启发式不确定性估计，以指导CoT过程。这允许LLM评估新收集信息的可靠性，优化其收集策略，并在综合最终答案时做出更稳健的决策。实证实验表明，我们的不确定性感知CoT有效地减轻了外部工具的噪声，导致更可靠的结果。我们将我们的方法实现在一个名为VideoAgent2的系统中，该系统还包括通用上下文获取和专用工具设计等额外模块。在三个专门的长视频基准测试（及其子集）上的评估表明，VideoAgent2的平均性能比以前的基于代理的方法VideoAgent高出13.1%，并且在所有零样本方法中取得了领先性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long video understanding has emerged as an increasingly important yetchallenging task in computer vision. Agent-based approaches are gainingpopularity for processing long videos, as they can handle extended sequencesand integrate various tools to capture fine-grained information. However,existing methods still face several challenges: (1) they often rely solely onthe reasoning ability of large language models (LLMs) without dedicatedmechanisms to enhance reasoning in long video scenarios; and (2) they remainvulnerable to errors or noise from external tools. To address these issues, wepropose a specialized chain-of-thought (CoT) process tailored for long videoanalysis. Our proposed CoT with plan-adjust mode enables the LLM toincrementally plan and adapt its information-gathering strategy. We furtherincorporate heuristic uncertainty estimation of both the LLM and external toolsto guide the CoT process. This allows the LLM to assess the reliability ofnewly collected information, refine its collection strategy, and make morerobust decisions when synthesizing final answers. Empirical experiments showthat our uncertainty-aware CoT effectively mitigates noise from external tools,leading to more reliable outputs. We implement our approach in a system calledVideoAgent2, which also includes additional modules such as general contextacquisition and specialized tool design. Evaluation on three dedicated longvideo benchmarks (and their subsets) demonstrates that VideoAgent2 outperformsthe previous state-of-the-art agent-based method, VideoAgent, by an average of13.1% and achieves leading performance among all zero-shot approaches</description>
      <author>example@mail.com (Zhuo Zhi, Qiangqiang Wu, Minghe shen, Wenbo Li, Yinchuan Li, Kun Shao, Kaiwen Zhou)</author>
      <guid isPermaLink="false">2504.04471v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Quantum parallel information exchange (QPIE) hybrid network with transfer learning</title>
      <link>http://arxiv.org/abs/2504.04235v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了量子机器学习（QML）及其在复杂模式识别和时间序列数据预测中的应用，提出了一种新的量子并行信息交换（QPIE）混合网络架构，并通过动态梯度选择方法提高了学习效率和表示能力。&lt;h4&gt;背景&lt;/h4&gt;量子机器学习通过利用量子系统模拟和利用高维潜在空间的能力，在复杂模式识别和时间序列数据预测等领域展现出巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入新的混合网络架构和优化方法，提高量子神经网络（QNN）的学习效率和表示能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的量子并行信息交换（QPIE）混合网络，通过将经典神经网络的预训练参数输入到量子电路中，并利用非克莱因参数化量子门进行模式识别和时间序列数据预测。同时，开发了一种动态梯度选择方法，结合了量子处理单元（QPUs）上的参数偏移规则和GPU上的伴随微分。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，所提出的模型在特定基准测试中表现出更高的准确率，降低了约88%的额外随机性时间序列数据的收敛率，并在CPU/GPU和IonQ QPU模拟器上展示了更无偏的费舍尔信息矩阵特征值谱。&lt;h4&gt;结论&lt;/h4&gt;量子并行信息交换（QPIE）混合网络和动态梯度选择方法能够有效提高量子神经网络的学习效率和表示能力，为量子机器学习在复杂模式识别和时间序列数据预测中的应用提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;Quantum machine learning (QML) has emerged as an innovative framework with the potential to uncover complex patterns by leveraging quantum systems ability to simulate and exploit high-dimensional latent spaces, particularly in learning tasks. Quantum neural network (QNN) frameworks are inherently sensitive to the precision of gradient calculations and the computational limitations of current quantum hardware as unitary rotations introduce overhead from complex number computations, and the quantum gate operation speed remains a bottleneck for practical implementations. In this study, we introduce quantum parallel information exchange (QPIE) hybrid network, a new non-sequential hybrid classical quantum model architecture, leveraging quantum transfer learning by feeding pre-trained parameters from classical neural networks into quantum circuits, which enables efficient pattern recognition and temporal series data prediction by utilizing non-clifford parameterized quantum gates thereby enhancing both learning efficiency and representational capacity. Additionally, we develop a dynamic gradient selection method that applies the parameter shift rule on quantum processing units (QPUs) and adjoint differentiation on GPUs. Our results demonstrate model performance exhibiting higher accuracy in ad-hoc benchmarks, lowering approximately 88% convergence rate for extra stochasticity time-series data within 100-steps, and showcasing a more unbiased eigenvalue spectrum of the fisher information matrix on CPU/GPU and IonQ QPU simulators.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum machine learning (QML) has emerged as an innovative framework withthe potential to uncover complex patterns by leveraging quantum systems abilityto simulate and exploit high-dimensional latent spaces, particularly inlearning tasks. Quantum neural network (QNN) frameworks are inherentlysensitive to the precision of gradient calculations and the computationallimitations of current quantum hardware as unitary rotations introduce overheadfrom complex number computations, and the quantum gate operation speed remainsa bottleneck for practical implementations. In this study, we introduce quantumparallel information exchange (QPIE) hybrid network, a new non-sequentialhybrid classical quantum model architecture, leveraging quantum transferlearning by feeding pre-trained parameters from classical neural networks intoquantum circuits, which enables efficient pattern recognition and temporalseries data prediction by utilizing non-clifford parameterized quantum gatesthereby enhancing both learning efficiency and representational capacity.Additionally, we develop a dynamic gradient selection method that applies theparameter shift rule on quantum processing units (QPUs) and adjointdifferentiation on GPUs. Our results demonstrate model performance exhibitinghigher accuracy in ad-hoc benchmarks, lowering approximately 88% convergencerate for extra stochasticity time-series data within 100-steps, and showcasinga more unbaised eigenvalue spectrum of the fisher information matrix on CPU/GPUand IonQ QPU simulators.</description>
      <author>example@mail.com (Ziqing Guo, Alex Khan, Victor S. Sheng, Shabnam Jabeen, Ziwen Pan)</author>
      <guid isPermaLink="false">2504.04235v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>InteractVLM: 3D Interaction Reasoning from 2D Foundational Models</title>
      <link>http://arxiv.org/abs/2504.05303v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了InteractVLM方法，通过单张真实世界图像估计人体和物体上的3D接触点，实现了准确的3D人体-物体关节重建。&lt;h4&gt;背景&lt;/h4&gt;由于遮挡、深度模糊性和物体形状的广泛变化，从单张图像中估计3D接触点是一个挑战。现有的方法依赖于昂贵的动作捕捉系统收集的3D接触标注或繁琐的手动标注，限制了可扩展性和泛化能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，能够从单张真实世界图像中估计3D接触点，从而实现准确的3D人体-物体关节重建。&lt;h4&gt;方法&lt;/h4&gt;InteractVLM利用大型视觉语言模型（VLMs）的广泛视觉知识，并通过有限的3D接触数据进行微调。为了处理3D人体-物体接触的本质三维性，引入了新的模块，包括：(1) 通过多视图渲染将3D人体和物体表面嵌入2D空间，(2) 训练一个新的多视图定位模型（MV-Loc）来推断2D接触，(3) 将这些接触点提升到3D。此外，提出了一个新的任务，即语义人体接触估计，其中人体接触预测显式地依赖于物体语义，从而允许更丰富的交互建模。&lt;h4&gt;主要发现&lt;/h4&gt;InteractVLM在接触估计方面优于现有工作，并简化了从真实世界图像中进行3D重建的过程。&lt;h4&gt;结论&lt;/h4&gt;InteractVLM是一个有效的工具，可以用于从真实世界图像中估计3D接触点，并促进3D重建。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了InteractVLM，一种从单张真实图像估计人体和物体上的3D接触点的新方法，使得在3D空间中实现准确的人体-物体联合重建成为可能。这由于遮挡、深度模糊性和物体形状的极大差异而具有挑战性。现有方法依赖于通过昂贵的行为捕捉系统收集的3D接触标注或繁琐的手动标注，限制了可扩展性和泛化能力。为了克服这一点，InteractVLM利用了大型视觉语言模型（VLMs）的广泛视觉知识，并使用有限的3D接触数据进行微调。然而，直接应用这些模型是非平凡的，因为它们只能在2D空间中推理，而人体-物体接触本质上是在3D的。因此，我们引入了一个新的渲染-定位-提升模块，它：（1）通过多视图渲染将3D人体和物体表面嵌入2D空间，（2）训练一个新的多视图定位模型（MV-Loc）来推断接触点在2D中的位置，（3）将这些接触点提升到3D。（此外，我们还提出了一个新的任务，称为语义人体接触估计，其中人体接触预测明确地基于物体语义，这允许更丰富的交互建模。）InteractVLM在接触估计方面优于现有工作，并且有助于从真实图像中进行3D重建。代码和模型可在https://interactvlm.is.tue.mpg.de上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce InteractVLM, a novel method to estimate 3D contact points onhuman bodies and objects from single in-the-wild images, enabling accuratehuman-object joint reconstruction in 3D. This is challenging due to occlusions,depth ambiguities, and widely varying object shapes. Existing methods rely on3D contact annotations collected via expensive motion-capture systems ortedious manual labeling, limiting scalability and generalization. To overcomethis, InteractVLM harnesses the broad visual knowledge of large Vision-LanguageModels (VLMs), fine-tuned with limited 3D contact data. However, directlyapplying these models is non-trivial, as they reason only in 2D, whilehuman-object contact is inherently 3D. Thus we introduce a novelRender-Localize-Lift module that: (1) embeds 3D body and object surfaces in 2Dspace via multi-view rendering, (2) trains a novel multi-view localizationmodel (MV-Loc) to infer contacts in 2D, and (3) lifts these to 3D.Additionally, we propose a new task called Semantic Human Contact estimation,where human contact predictions are conditioned explicitly on object semantics,enabling richer interaction modeling. InteractVLM outperforms existing work oncontact estimation and also facilitates 3D reconstruction from an in-the wildimage. Code and models are available at https://interactvlm.is.tue.mpg.de.</description>
      <author>example@mail.com (Sai Kumar Dwivedi, Dimitrije Antić, Shashank Tripathi, Omid Taheri, Cordelia Schmid, Michael J. Black, Dimitrios Tzionas)</author>
      <guid isPermaLink="false">2504.05303v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>LATTE: Lightweight Attention-based Traffic Accident Anticipation Engine</title>
      <link>http://arxiv.org/abs/2504.04103v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accept by Information Fusion (Elsevier)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LATTE的轻量级注意力交通事故预测引擎，它在资源受限环境中准确预测实时交通事故。LATTE结合了计算效率和最先进的表现，通过高效的多尺度空间聚合、记忆注意力聚合和辅助自我注意力聚合等技术，实现了对交通事故的准确预测。&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶领域，准确预测实时交通事故是一个关键挑战，特别是在资源受限的环境中。现有的解决方案往往计算开销高或未能充分解决动态交通场景的不确定性。&lt;h4&gt;目的&lt;/h4&gt;开发一种轻量级的交通事故预测引擎，能够在资源受限的环境中提供准确的事故预测。&lt;h4&gt;方法&lt;/h4&gt;LATTE采用了高效的多尺度空间聚合（EMSA）来捕获不同尺度的空间特征，记忆注意力聚合（MAA）来增强时间建模，以及辅助自我注意力聚合（AAA）来提取长序列中的潜在依赖关系。此外，LATTE集成了Flamingo Alert-Assisted System（FAA），利用视觉语言模型提供实时、认知上可访问的口头危险警报。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集（DAD、CCD、A3D）上的评估表明，LATTE具有卓越的预测能力和计算效率。它在DAD基准上达到了89.74%的平均精度（AP），比第二好的模型平均时间到事故（mTTA）高出5.4%，在80%的召回率（TTA@R80）下保持了具有竞争力的mTTA（4.04秒），并在各种驾驶条件下展示了强大的事故预测能力。&lt;h4&gt;结论&lt;/h4&gt;LATTE通过其轻量级设计实现了93.14%的浮点运算（FLOPs）减少和31.58%的参数数量减少，能够在资源有限的硬件上实时运行而不影响性能。消融研究表明LATTE架构组件的有效性，而可视化失败案例分析突出了其实际应用性和改进领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要：准确预测自动驾驶环境中的实时交通事故是一个关键挑战，特别是在资源受限的环境中。现有解决方案通常计算开销高，或者未能充分解决动态交通场景的不确定性。本文提出了一种名为LATTE的轻量级注意力交通事故预测引擎，它结合了计算效率和最先进的性能。LATTE采用高效的多尺度空间聚合（EMSA）来捕捉跨尺度的空间特征，记忆注意力聚合（MAA）来增强时间建模，以及辅助自我注意力聚合（AAA）来提取长序列中的潜在依赖关系。此外，LATTE集成了Flamingo Alert-Assisted System（FAA），利用视觉语言模型提供实时、认知上可访问的口头危险警报，提高乘客对局势的认识。在基准数据集（DAD、CCD、A3D）上的评估表明，LATTE具有卓越的预测能力和计算效率。它在DAD基准上达到了89.74%的平均精度（AP），比第二好的模型平均时间到事故（mTTA）高出5.4%，在80%的召回率（TTA@R80）下保持了具有竞争力的mTTA（4.04秒），并在各种驾驶条件下展示了强大的事故预测能力。其轻量级设计实现了93.14%的浮点运算（FLOPs）减少和31.58%的参数数量减少，能够在资源有限的硬件上实时运行而不影响性能。消融研究表明LATTE架构组件的有效性，而可视化失败案例分析突出了其实际应用性和改进领域。我们的代码可在https://github.com/icypear/LATTE.git上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately predicting traffic accidents in real-time is a critical challengein autonomous driving, particularly in resource-constrained environments.Existing solutions often suffer from high computational overhead or fail toadequately address the uncertainty of evolving traffic scenarios. This paperintroduces LATTE, a Lightweight Attention-based Traffic Accident AnticipationEngine, which integrates computational efficiency with state-of-the-artperformance. LATTE employs Efficient Multiscale Spatial Aggregation (EMSA) tocapture spatial features across scales, Memory Attention Aggregation (MAA) toenhance temporal modeling, and Auxiliary Self-Attention Aggregation (AAA) toextract latent dependencies over extended sequences. Additionally, LATTEincorporates the Flamingo Alert-Assisted System (FAA), leveraging avision-language model to provide real-time, cognitively accessible verbalhazard alerts, improving passenger situational awareness. Evaluations onbenchmark datasets (DAD, CCD, A3D) demonstrate LATTE's superior predictivecapabilities and computational efficiency. LATTE achieves state-of-the-art89.74% Average Precision (AP) on DAD benchmark, with 5.4% higher meanTime-To-Accident (mTTA) than the second-best model, and maintains competitivemTTA at a Recall of 80% (TTA@R80) (4.04s) while demonstrating robust accidentanticipation across diverse driving conditions. Its lightweight design deliversa 93.14% reduction in floating-point operations (FLOPs) and a 31.58% decreasein parameter count (Params), enabling real-time operation on resource-limitedhardware without compromising performance. Ablation studies confirm theeffectiveness of LATTE's architectural components, while visualizations andfailure case analyses highlight its practical applicability and areas forenhancement. Our codes are available at https://github.com/icypear/LATTE.git.</description>
      <author>example@mail.com (Jiaxun Zhang, Yanchen Guan, Chengyue Wang, Haicheng Liao, Guohui Zhang, Zhenning Li)</author>
      <guid isPermaLink="false">2504.04103v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Uni4D: A Unified Self-Supervised Learning Framework for Point Cloud Videos</title>
      <link>http://arxiv.org/abs/2504.04837v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于自监督的稀疏策略的点云视频表示学习，提出了首个自解耦的MAE框架，用于在预训练阶段学习判别性4D表示。&lt;h4&gt;背景&lt;/h4&gt;点云视频表示学习基于自监督的稀疏策略，但进展缓慢，存在几个显著挑战。&lt;h4&gt;目的&lt;/h4&gt;提高4D任务的预训练和微调性能。&lt;h4&gt;方法&lt;/h4&gt;1. 在潜在空间中建模运动表示。2. 引入潜在标记和典型几何标记来解耦解码过程中的高级和低级特征。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在MSR-Action3D、NTU-RGBD、HOI4D、NvGesture和SHREC'17等数据集上进行了广泛的实验，验证了其有效性。预训练模型能够提高所有4D任务的微调性能，尤其在处理长视频方面表现突出。&lt;h4&gt;结论&lt;/h4&gt;自解耦学习框架可以显著提高4D任务的微调性能，预训练模型在处理长视频时表现尤为出色。&lt;h4&gt;翻译&lt;/h4&gt;Point cloud video representation learning is primarily built upon the masking strategy in a self-supervised manner. However, the progress is slow due to several significant challenges: (1) existing methods learn the motion particularly with hand-crafted designs, leading to unsatisfactory motion patterns during pre-training which are non-transferable on fine-tuning scenarios. (2) previous Masked AutoEncoder (MAE) frameworks are limited in resolving the huge representation gap inherent in 4D data. In this study, we introduce the first self-disentangled MAE for learning discriminative 4D representations in the pre-training stage. To address the first challenge, we propose to model the motion representation in a latent space. The second issue is resolved by introducing the latent tokens along with the typical geometry tokens to disentangle high-level and low-level features during decoding. Extensive experiments on MSR-Action3D, NTU-RGBD, HOI4D, NvGesture, and SHREC'17 verify this self-disentangled learning framework. We demonstrate that it can boost the fine-tuning performance on all 4D tasks, which we term Uni4D. Our pre-trained model presents discriminative and meaningful 4D representations, particularly benefits processing long videos, as Uni4D gets +3.8% segmentation accuracy on HOI4D, significantly outperforming either self-supervised or fully-supervised methods after end-to-end fine-tuning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud video representation learning is primarily built upon the maskingstrategy in a self-supervised manner. However, the progress is slow due toseveral significant challenges: (1) existing methods learn the motionparticularly with hand-crafted designs, leading to unsatisfactory motionpatterns during pre-training which are non-transferable on fine-tuningscenarios. (2) previous Masked AutoEncoder (MAE) frameworks are limited inresolving the huge representation gap inherent in 4D data. In this study, weintroduce the first self-disentangled MAE for learning discriminative 4Drepresentations in the pre-training stage. To address the first challenge, wepropose to model the motion representation in a latent space. The second issueis resolved by introducing the latent tokens along with the typical geometrytokens to disentangle high-level and low-level features during decoding.Extensive experiments on MSR-Action3D, NTU-RGBD, HOI4D, NvGesture, and SHREC'17verify this self-disentangled learning framework. We demonstrate that it canboost the fine-tuning performance on all 4D tasks, which we term Uni4D. Ourpre-trained model presents discriminative and meaningful 4D representations,particularly benefits processing long videos, as Uni4D gets $+3.8\%$segmentation accuracy on HOI4D, significantly outperforming eitherself-supervised or fully-supervised methods after end-to-end fine-tuning.</description>
      <author>example@mail.com (Zhi Zuo, Chenyi Zhuang, Zhiqiang Shen, Pan Gao, Jie Qin)</author>
      <guid isPermaLink="false">2504.04837v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Fine tuning generative adversarial networks with universal force fields: application to two-dimensional topological insulators</title>
      <link>http://arxiv.org/abs/2504.04940v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6+2 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要讨论了生成式人工智能在设计特定晶体材料方面的初步应用，提出了一种通过高级图神经网络和通用力场作为判别器来微调生成晶体结构的生成对抗网络的方法。&lt;h4&gt;背景&lt;/h4&gt;尽管生成式人工智能的应用场景迅速增长，但其在设计特定晶体材料方面的能力仍处于起步阶段。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过引入高级图神经网络和通用力场作为判别器，来微调生成晶体结构的生成对抗网络，以生成目标材料。&lt;h4&gt;方法&lt;/h4&gt;使用二维拓扑绝缘体作为目标空间示例，通过训练生成对抗网络来产生晶体结构，并通过后处理来约束输出。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，这种方法可以生成新的拓扑绝缘体，尽管大多数候选化合物中拓扑保护程度的带隙大小仍然是一个问题。&lt;h4&gt;结论&lt;/h4&gt;提出的方法可以有效地生成目标材料，为生成式人工智能在晶体材料设计中的应用提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管生成式人工智能的应用场景迅速增长，但其设计特定晶体材料的能力仍处于起步阶段。目前，逆向设计通常是通过限制训练数据集或从生成器网络产生大量样本，并通过后处理来约束输出来完成的。我们展示了通过引入高级图神经网络作为判别器，包括通用力场，来微调从潜在空间生成晶体结构的生成对抗网络的方法。这通过使用二维拓扑绝缘体作为目标空间示例来证明。尽管已经预测了许多二维拓扑绝缘体，但大多数候选化合物中拓扑保护程度的带隙大小仍然是一个问题。所得到的生成网络显示出可以产生新的拓扑绝缘体。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite rapid growth in use cases for generative artificial intelligence, itsability to design purpose built crystalline materials remains in a nascentphase. At the moment inverse design is generally accomplished by eitherconstraining the training data set or producing a vast number of samples from agenerator network and constraining the output via post-processing. We show thata general adversarial network trained to produce crystal structures from alatent space can be fine tuned through the introduction of advanced graphneural networks as discriminators, including a universal force field, tointrinsically bias the network towards generation of target materials. This isexemplified utilizing two-dimensional topological insulators as a sample targetspace. While a number of two-dimensional topological insulators have beenpredicted, the size of the band-gap, a measure of topological protection,remains a concern in most candidate compounds. The resulting generative networkis shown to yield novel topological insulators.</description>
      <author>example@mail.com (Alexander C. Tyner)</author>
      <guid isPermaLink="false">2504.04940v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Bidirectional Hierarchical Protein Multi-Modal Representation Learning</title>
      <link>http://arxiv.org/abs/2504.04770v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种多模态双向分层融合框架，用于有效融合蛋白质序列和结构信息，以改进蛋白质表示学习。&lt;h4&gt;背景&lt;/h4&gt;蛋白质表示学习对于多种生物学任务至关重要。现有的基于transformer的蛋白质语言模型和基于图神经网络的模型分别擅长处理序列和结构信息，但都存在局限性。&lt;h4&gt;目的&lt;/h4&gt;旨在通过融合序列和结构信息，提高蛋白质表示学习的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个多模态双向分层融合框架，使用注意力机制和门控机制来增强pLMs生成的序列表示和GNN提取的结构特征之间的交互。&lt;h4&gt;主要发现&lt;/h4&gt;在多个蛋白质相关任务上进行了广泛实验，方法在多个基准测试中显示出优于基线和现有融合技术的改进。&lt;h4&gt;结论&lt;/h4&gt;该方法在多模态蛋白质表示学习中达到了新的水平，强调了BIHIERARCHICAL FUSION在连接序列和结构模态方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：蛋白质表示学习对于众多生物学任务至关重要。最近，在大规模蛋白质序列上预训练的大型transformer基蛋白质语言模型（pLMs）在基于序列的任务中取得了显著的成果。然而，pLMs缺乏结构信息。相反，旨在利用3D结构信息的图神经网络（GNNs）在蛋白质相关预测任务中显示出有希望的泛化能力，但它们的有效性通常受到标记结构数据稀缺的限制。认识到序列和结构表示是同一蛋白质实体的互补视角，我们提出了一种多模态双向分层融合框架，以有效地融合这些模态。我们的框架采用注意力和门控机制，以实现pLMs生成的序列表示和GNN提取的结构特征之间的有效交互，从而提高神经网络各层之间的信息交换和增强。基于该框架，我们进一步引入了带有门控的局部双分层融合和带有多头自注意力的全局双分层融合方法。通过在一系列蛋白质相关任务上的大量实验，我们的方法在各种蛋白质表示学习基准测试中显示出对强大基线和现有融合技术的持续改进，包括反应（酶/EC分类）、模型质量评估（MQA）、蛋白质-配体结合亲和力预测（LBA）、蛋白质-蛋白质结合位点预测（PPBS）和B细胞表位预测（BCEs）。我们的方法为多模态蛋白质表示学习建立了新的基准，强调了BIHIERARCHICAL FUSION在连接序列和结构模态方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Protein representation learning is critical for numerous biological tasks.Recently, large transformer-based protein language models (pLMs) pretrained onlarge scale protein sequences have demonstrated significant success insequence-based tasks. However, pLMs lack structural information. Conversely,graph neural networks (GNNs) designed to leverage 3D structural informationhave shown promising generalization in protein-related prediction tasks, buttheir effectiveness is often constrained by the scarcity of labeled structuraldata. Recognizing that sequence and structural representations arecomplementary perspectives of the same protein entity, we propose a multimodalbidirectional hierarchical fusion framework to effectively merge thesemodalities. Our framework employs attention and gating mechanisms to enableeffective interaction between pLMs-generated sequential representations andGNN-extracted structural features, improving information exchange andenhancement across layers of the neural network. Based on the framework, wefurther introduce local Bi-Hierarchical Fusion with gating and globalBi-Hierarchical Fusion with multihead self-attention approaches. Throughextensive experiments on a diverse set of protein-related tasks, our methoddemonstrates consistent improvements over strong baselines and existing fusiontechniques in a variety of protein representation learning benchmarks,including react (enzyme/EC classification), model quality assessment (MQA),protein-ligand binding affinity prediction (LBA), protein-protein binding siteprediction (PPBS), and B cell epitopes prediction (BCEs). Our methodestablishes a new state-of-the-art for multimodal protein representationlearning, emphasizing the efficacy of BIHIERARCHICAL FUSION in bridgingsequence and structural modalities.</description>
      <author>example@mail.com (Xuefeng Liu, Songhao Jiang, Chih-chan Tien, Jinbo Xu, Rick Stevens)</author>
      <guid isPermaLink="false">2504.04770v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>DFormerv2: Geometry Self-Attention for RGBD Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2504.04701v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了DFormerv2，一种新的RGBD特征表示学习方法，该方法使用深度图作为几何先验，而不是像RGB图像那样显式地使用神经网络编码深度信息。&lt;h4&gt;背景&lt;/h4&gt;在复杂条件下（如低光和过曝），深度图对场景理解有很大的帮助，特别是提供3D几何信息。&lt;h4&gt;目的&lt;/h4&gt;研究如何从深度图中提取几何线索，并将其作为几何先验用于自注意力机制中。&lt;h4&gt;方法&lt;/h4&gt;DFormerv2通过深度图和RGB图像的特征融合，不显式地使用神经网络编码深度信息，而是将深度图作为几何先验来分配注意力权重。&lt;h4&gt;主要发现&lt;/h4&gt;DFormerv2在多种RGBD语义分割基准测试中表现出色。&lt;h4&gt;结论&lt;/h4&gt;深度图作为几何先验在场景理解中是有效的，DFormerv2是一种强大的RGBD编码器，能够提高语义分割的性能。&lt;h4&gt;翻译&lt;/h4&gt;近期在场景理解方面的进展在很大程度上得益于深度图提供的3D几何信息，特别是在复杂条件下（如低光和过曝）。现有的方法将深度图与RGB图像编码在一起，并执行特征融合以提高预测的鲁棒性。考虑到深度可以被视为RGB图像的几何补充，一个简单的问题出现了：我们真的需要像对RGB图像那样使用神经网络显式地编码深度信息吗？基于这一洞察，本文研究了学习RGBD特征表示的新方法，并提出了DFormerv2，一个强大的RGBD编码器，它明确地使用深度图作为几何先验，而不是使用神经网络来编码深度信息。我们的目标是提取深度图和所有图像块标记之间的空间距离中的几何线索，然后将这些线索用作几何先验来在自注意力中分配注意力权重。大量的实验表明，DFormerv2在各种RGBD语义分割基准测试中表现出卓越的性能。代码可在https://github.com/VCIP-RGBD/DFormer上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in scene understanding benefit a lot from depth maps becauseof the 3D geometry information, especially in complex conditions (e.g., lowlight and overexposed). Existing approaches encode depth maps along with RGBimages and perform feature fusion between them to enable more robustpredictions. Taking into account that depth can be regarded as a geometrysupplement for RGB images, a straightforward question arises: Do we really needto explicitly encode depth information with neural networks as done for RGBimages? Based on this insight, in this paper, we investigate a new way to learnRGBD feature representations and present DFormerv2, a strong RGBD encoder thatexplicitly uses depth maps as geometry priors rather than encoding depthinformation with neural networks. Our goal is to extract the geometry cluesfrom the depth and spatial distances among all the image patch tokens, whichwill then be used as geometry priors to allocate attention weights inself-attention. Extensive experiments demonstrate that DFormerv2 exhibitsexceptional performance in various RGBD semantic segmentation benchmarks. Codeis available at: https://github.com/VCIP-RGBD/DFormer.</description>
      <author>example@mail.com (Bo-Wen Yin, Jiao-Long Cao, Ming-Ming Cheng, Qibin Hou)</author>
      <guid isPermaLink="false">2504.04701v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>DyCON: Dynamic Uncertainty-aware Consistency and Contrastive Learning for Semi-supervised Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2504.04566v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DyCON的动态不确定性感知一致性和对比学习框架，用于解决医学图像分割中的半监督学习问题，以提高分割的准确性。&lt;h4&gt;背景&lt;/h4&gt;在医学图像分割中，半监督学习方法利用未标记数据减轻标注负担。然而，现有方法面临类别不平衡和病理变化带来的高不确定性，导致3D医学图像分割不准确。&lt;h4&gt;目的&lt;/h4&gt;提出DyCON框架，以解决类别不平衡和不确定性带来的挑战，从而提高医学图像分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;DyCON框架包含两个互补的损失函数：不确定性感知一致损失（UnCL）和焦点熵感知对比损失（FeCL）。UnCL通过动态加权每个体素对一致性损失的贡献，以保持高不确定性区域。FeCL通过引入双焦点机制和自适应置信度调整来增强不平衡区域中的局部特征区分能力。&lt;h4&gt;主要发现&lt;/h4&gt;DyCON在四个不同的医学图像分割数据集（ISLES'22、BraTS'19、LA、Pancreas）上的评估表明，与现有方法相比，DyCON具有优越的性能。&lt;h4&gt;结论&lt;/h4&gt;DyCON框架通过结合不确定性感知一致性和对比学习方法，有效地提高了医学图像分割的准确性，尤其是在类别不平衡和不确定性高的场景下。&lt;h4&gt;翻译&lt;/h4&gt;Semi-supervised learning in medical image segmentation leverages unlabeled data to reduce annotation burdens through consistency learning. However, current methods struggle with class imbalance and high uncertainty from pathology variations, leading to inaccurate segmentation in 3D medical images. To address these challenges, we present DyCON, a Dynamic Uncertainty-aware Consistency and Contrastive Learning framework that enhances the generalization of consistency methods with two complementary losses: Uncertainty-aware Consistency Loss (UnCL) and Focal Entropy-aware Contrastive Loss (FeCL). UnCL enforces global consistency by dynamically weighting the contribution of each voxel to the consistency loss based on its uncertainty, preserving high-uncertainty regions instead of filtering them out. Initially, UnCL prioritizes learning from uncertain voxels with lower penalties, encouraging the model to explore challenging regions. As training progress, the penalty shifts towards confident voxels to refine predictions and ensure global consistency. Meanwhile, FeCL enhances local feature discrimination in imbalanced regions by introducing dual focal mechanisms and adaptive confidence adjustments into the contrastive principle. These mechanisms jointly prioritize hard positives and negatives while focusing on uncertain sample pairs, effectively capturing subtle lesion variations under class imbalance. Extensive evaluations on four diverse medical image segmentation datasets (ISLES'22, BraTS'19, LA, Pancreas) show DyCON's superior performance against SOTA methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semi-supervised learning in medical image segmentation leverages unlabeleddata to reduce annotation burdens through consistency learning. However,current methods struggle with class imbalance and high uncertainty frompathology variations, leading to inaccurate segmentation in 3D medical images.To address these challenges, we present DyCON, a Dynamic Uncertainty-awareConsistency and Contrastive Learning framework that enhances the generalizationof consistency methods with two complementary losses: Uncertainty-awareConsistency Loss (UnCL) and Focal Entropy-aware Contrastive Loss (FeCL). UnCLenforces global consistency by dynamically weighting the contribution of eachvoxel to the consistency loss based on its uncertainty, preservinghigh-uncertainty regions instead of filtering them out. Initially, UnCLprioritizes learning from uncertain voxels with lower penalties, encouragingthe model to explore challenging regions. As training progress, the penaltyshift towards confident voxels to refine predictions and ensure globalconsistency. Meanwhile, FeCL enhances local feature discrimination inimbalanced regions by introducing dual focal mechanisms and adaptive confidenceadjustments into the contrastive principle. These mechanisms jointlyprioritizes hard positives and negatives while focusing on uncertain samplepairs, effectively capturing subtle lesion variations under class imbalance.Extensive evaluations on four diverse medical image segmentation datasets(ISLES'22, BraTS'19, LA, Pancreas) show DyCON's superior performance againstSOTA methods.</description>
      <author>example@mail.com (Maregu Assefa, Muzammal Naseer, Iyyakutti Iyappan Ganapathi, Syed Sadaf Ali, Mohamed L Seghier, Naoufel Werghi)</author>
      <guid isPermaLink="false">2504.04566v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Training state-of-the-art pathology foundation models with orders of magnitude less data</title>
      <link>http://arxiv.org/abs/2504.05186v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;计算病理学领域因现代视觉基础模型（FMs）的发展而迅速进步，通过增加训练数据集、模型大小和集成特定领域图像处理技术，可以显著提高模型在下游任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;计算病理学领域因现代视觉基础模型（FMs）的发展而迅速进步，这些模型通常在大量病理图像上训练。&lt;h4&gt;目的&lt;/h4&gt;优化病理FMs的训练，并在更高分辨率的图像上对模型进行微调，以进一步丰富嵌入中的信息。&lt;h4&gt;方法&lt;/h4&gt;对标准DINOv2框架进行修改，包括增加训练数据集和模型大小，集成特定领域图像处理技术，以及应用后训练过程进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;提出了三个新的病理FM，这些模型在训练数据量上比其他最先进的FM少一个到两个数量级，但在下游任务上表现出相当或更好的性能。即使是仅使用TCGA数据（12k WSIs）训练的模型也优于大多数现有FMs，平均而言与Virchow2相当，这是迄今为止发布的第二好的FM。&lt;h4&gt;结论&lt;/h4&gt;这表明，仍有很大潜力进一步改进用于训练病理FMs的模型和算法，以充分利用庞大的数据集。&lt;h4&gt;翻译&lt;/h4&gt;计算病理学领域因现代视觉基础模型（FMs）的发展而迅速进步，这些模型通常在大量病理图像上训练。最近的研究表明，增加训练数据集和模型大小以及集成特定领域的图像处理技术可以显著提高模型在下游任务上的性能。基于这些见解，我们的工作结合了文献中标准DINOv2框架的几个最近修改来优化病理FMs的训练。我们还应用了后训练过程，在更高分辨率的图像上对模型进行微调，以进一步丰富嵌入中的信息。我们提出了三个新的病理FM，这些模型在训练数据量上比用于训练其他最先进FM的WSI少一个到两个数量级，同时在下游任务上表现出相当或更好的性能。即使是仅使用TCGA数据（12k WSIs）训练的模型也优于大多数现有FMs，平均而言与Virchow2相当，这是迄今为止发布的第二好的FM。这表明，仍有很大潜力进一步改进用于训练病理FMs的模型和算法，以充分利用庞大的数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The field of computational pathology has recently seen rapid advances drivenby the development of modern vision foundation models (FMs), typically trainedon vast collections of pathology images. Recent studies demonstrate thatincreasing the training data set and model size and integrating domain-specificimage processing techniques can significantly enhance the model's performanceon downstream tasks. Building on these insights, our work incorporates severalrecent modifications to the standard DINOv2 framework from the literature tooptimize the training of pathology FMs. We also apply a post-training procedurefor fine-tuning models on higher-resolution images to further enrich theinformation encoded in the embeddings. We present three novel pathology FMstrained on up to two orders of magnitude fewer WSIs than those used to trainother state-of-the-art FMs while demonstrating a comparable or superiorperformance on downstream tasks. Even the model trained on TCGA alone (12kWSIs) outperforms most existing FMs and, on average, matches Virchow2, thesecond-best FM published to date. This suggests that there still remains asignificant potential for further improving the models and algorithms used totrain pathology FMs to take full advantage of the vast data collections.</description>
      <author>example@mail.com (Mikhail Karasikov, Joost van Doorn, Nicolas Känzig, Melis Erdal Cesur, Hugo Mark Horlings, Robert Berke, Fei Tang, Sebastian Otálora)</author>
      <guid isPermaLink="false">2504.05186v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Multi-resolution Score-Based Variational Graphical Diffusion for Causal Disaster System Modeling and Inference</title>
      <link>http://arxiv.org/abs/2504.04015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Temporal-SVGDM，一种基于评分的变分图扩散模型，用于处理多分辨率观测数据，旨在解决复杂系统中因果关系预测的挑战。&lt;h4&gt;背景&lt;/h4&gt;复杂系统中的因果关系复杂，难以准确预测。有效的建模需要精确的物理过程表示、整合相互依赖的因素以及结合多分辨率观测数据。&lt;h4&gt;目的&lt;/h4&gt;提高复杂系统因果关系的预测准确性，并增强对系统动态的理解。&lt;h4&gt;方法&lt;/h4&gt;Temporal-SVGDM通过构建每个变量在其原分辨率下的单个随机微分方程（SDE），并通过因果关系评分机制将这些SDE耦合起来。此外，在时间模型中，状态表示通过序列预测模型处理，以预测未来状态。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有方法相比，Temporal-SVGDM在真实世界数据集上提高了预测准确性和对因果关系的理解，并且在不同背景知识水平下表现出鲁棒的性能。&lt;h4&gt;结论&lt;/h4&gt;Temporal-SVGDM能够优雅地适应不同灾难类型，成功处理静态地震场景以及时间性的飓风和野火场景，即使在数据有限的情况下也能保持优异的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complex systems with intricate causal dependencies challenge accurateprediction. Effective modeling requires precise physical processrepresentation, integration of interdependent factors, and incorporation ofmulti-resolution observational data. These systems manifest in both staticscenarios with instantaneous causal chains and temporal scenarios with evolvingdynamics, complicating modeling efforts. Current methods struggle tosimultaneously handle varying resolutions, capture physical relationships,model causal dependencies, and incorporate temporal dynamics, especially withinconsistently sampled data from diverse sources. We introduce Temporal-SVGDM:Score-based Variational Graphical Diffusion Model for Multi-resolutionobservations. Our framework constructs individual SDEs for each variable at itsnative resolution, then couples these SDEs through a causal score mechanismwhere parent nodes inform child nodes' evolution. This enables unified modelingof both immediate causal effects in static scenarios and evolving dependenciesin temporal scenarios. In temporal models, state representations are processedthrough a sequence prediction model to predict future states based onhistorical patterns and causal relationships. Experiments on real-worlddatasets demonstrate improved prediction accuracy and causal understandingcompared to existing methods, with robust performance under varying levels ofbackground knowledge. Our model exhibits graceful degradation across differentdisaster types, successfully handling both static earthquake scenarios andtemporal hurricane and wildfire scenarios, while maintaining superiorperformance even with limited data.</description>
      <author>example@mail.com (Xuechun Li, Shan Gao, Susu Xu)</author>
      <guid isPermaLink="false">2504.04015v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Relational Deep Learning with Pretrained Tabular Models</title>
      <link>http://arxiv.org/abs/2504.04934v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LightRDL的新方法，旨在提高关系数据库中图神经网络（GNN）的效率，使其更适合实时预测。&lt;h4&gt;背景&lt;/h4&gt;关系数据库通过主键和外键关系组织数据，预测通常涉及将数据转换为平坦的表格格式，但设计能够完全捕捉复杂关系的特征具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;通过利用现有的特征工程努力，提高GNN在关系数据库中的效率，以实现实时预测。&lt;h4&gt;方法&lt;/h4&gt;使用GNN捕获关系数据库中的复杂关系，同时使用工程化特征编码时间信息，从而避免保留整个历史图，并允许使用更小、更高效的图。&lt;h4&gt;主要发现&lt;/h4&gt;LightRDL方法不仅提高了效率，而且在RelBench基准测试中，比GNN实现了高达33%的性能提升和526倍的推理速度。&lt;h4&gt;结论&lt;/h4&gt;LightRDL方法在关系数据库中进行实时预测方面具有显著优势，为实时推理提供了高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Relational databases, organized into tables connected by primary-foreign keyrelationships, are a common format for organizing data. Making predictions onrelational data often involves transforming them into a flat tabular formatthrough table joins and feature engineering, which serve as input to tabularmethods. However, designing features that fully capture complex relationalpatterns remains challenging. Graph Neural Networks (GNNs) offer a compellingalternative by inherently modeling these relationships, but their time overheadduring inference limits their applicability for real-time scenarios. In thiswork, we aim to bridge this gap by leveraging existing feature engineeringefforts to enhance the efficiency of GNNs in relational databases.Specifically, we use GNNs to capture complex relationships within relationaldatabases, patterns that are difficult to featurize, while employing engineeredfeatures to encode temporal information, thereby avoiding the need to retainthe entire historical graph and enabling the use of smaller, more efficientgraphs. Our \textsc{LightRDL} approach not only improves efficiency, but alsooutperforms existing models. Experimental results on the RelBench benchmarkdemonstrate that our framework achieves up to $33\%$ performance improvementand a $526\times$ inference speedup compared to GNNs, making it highly suitablefor real-time inference.</description>
      <author>example@mail.com (Veronica Lachi, Antonio Longa, Beatrice Bevilacqua, Bruno Lepri, Andrea Passerini, Bruno Ribeiro)</author>
      <guid isPermaLink="false">2504.04934v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>A Unified Pairwise Framework for RLHF: Bridging Generative Reward Modeling and Policy Optimization</title>
      <link>http://arxiv.org/abs/2504.04950v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11oages,2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Pairwise-RL的强化学习框架，用于提高大型语言模型与人类偏好的对齐。该框架通过结合生成性奖励建模和成对近端策略优化（PPO）算法来解决现有RLHF方法中的限制。&lt;h4&gt;背景&lt;/h4&gt;RLHF已成为在训练后使大型语言模型（LLMs）与人类偏好对齐的重要范式。该框架通常分为两个阶段：首先在人类偏好数据上训练奖励模型，然后使用强化学习算法优化语言模型。&lt;h4&gt;目的&lt;/h4&gt;解决现有RLHF方法的两个限制：一是现有框架依赖于布拉德利-特里模型进行成对比较以分配标量奖励，这对奖励模型提出了挑战；二是奖励模型通常从生成基础模型初始化，而奖励模型执行的是判别性任务，导致不匹配。&lt;h4&gt;方法&lt;/h4&gt;Pairwise-RL框架通过结合生成性奖励建模和成对近端策略优化（PPO）算法来应对上述挑战。该框架在奖励模型训练和应用过程中采用一致的成对范式，利用生成建模技术来提高奖励模型性能和分数校准。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估表明，Pairwise-RL在内部评估数据集和标准公共基准测试中均优于传统的RLHF框架，强调了其在提高对齐和模型行为方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;Pairwise-RL是一个有效的RLHF框架，能够提高大型语言模型与人类偏好的对齐，并改进模型行为。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement Learning from Human Feedback (RLHF) has emerged as a importantparadigm for aligning large language models (LLMs) with human preferencesduring post-training. This framework typically involves two stages: first,training a reward model on human preference data, followed by optimizing thelanguage model using reinforcement learning algorithms. However, current RLHFapproaches may constrained by two limitations. First, existing RLHF frameworksoften rely on Bradley-Terry models to assign scalar rewards based on pairwisecomparisons of individual responses. However, this approach imposes significantchallenges on reward model (RM), as the inherent variability in prompt-responsepairs across different contexts demands robust calibration capabilities fromthe RM. Second, reward models are typically initialized from generativefoundation models, such as pre-trained or supervised fine-tuned models, despitethe fact that reward models perform discriminative tasks, creating a mismatch.This paper introduces Pairwise-RL, a RLHF framework that addresses thesechallenges through a combination of generative reward modeling and a pairwiseproximal policy optimization (PPO) algorithm. Pairwise-RL unifies reward modeltraining and its application during reinforcement learning within a consistentpairwise paradigm, leveraging generative modeling techniques to enhance rewardmodel performance and score calibration. Experimental evaluations demonstratethat Pairwise-RL outperforms traditional RLHF frameworks across both internalevaluation datasets and standard public benchmarks, underscoring itseffectiveness in improving alignment and model behavior.</description>
      <author>example@mail.com (Wenyuan Xu, Xiaochen Zuo, Chao Xin, Yu Yue, Lin Yan, Yonghui Wu)</author>
      <guid isPermaLink="false">2504.04950v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>EquiCPI: SE(3)-Equivariant Geometric Deep Learning for Structure-Aware Prediction of Compound-Protein Interactions</title>
      <link>http://arxiv.org/abs/2504.04654v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EquiCPI的几何深度学习框架，用于预测化合物-蛋白质相互作用，该框架结合了第一性原理结构建模和SE(3)等变神经网络，在BindingDB和DUD-E数据集上取得了与现有深度学习竞争对手相当或更好的性能。&lt;h4&gt;背景&lt;/h4&gt;准确预测化合物-蛋白质相互作用是计算药物发现中的一个关键挑战，现有的基于序列的方法忽略了结合亲和力的三维结构决定因素。&lt;h4&gt;目的&lt;/h4&gt;提出EquiCPI框架，以解决现有方法在预测化合物-蛋白质相互作用时忽视三维结构决定因素的问题。&lt;h4&gt;方法&lt;/h4&gt;EquiCPI通过ESMFold将蛋白质序列转换为3D原子坐标，通过DiffDock-L对配体进行转换。然后，采用物理引导的构象重排序和等变特征学习。核心部分使用SE(3)等变消息传递，通过球谐函数的张量积层次化编码局部相互作用模式。&lt;h4&gt;主要发现&lt;/h4&gt;EquiCPI在BindingDB（亲和力预测）和DUD-E（虚拟筛选）数据集上实现了与现有深度学习竞争对手相当或更好的性能。&lt;h4&gt;结论&lt;/h4&gt;EquiCPI框架在预测化合物-蛋白质相互作用方面具有优越的性能，为计算药物发现提供了新的工具。&lt;h4&gt;翻译&lt;/h4&gt;Accurate prediction of compound-protein interactions (CPI) remains a cornerstone challenge in computational drug discovery. While existing sequence-based approaches leverage molecular fingerprints or graph representations, they critically overlook three-dimensional (3D) structural determinants of binding affinity. To bridge this gap, we present EquiCPI, an end-to-end geometric deep learning framework that synergizes first-principles structural modeling with SE(3)-equivariant neural networks. Our pipeline transforms raw sequences into 3D atomic coordinates via ESMFold for proteins and DiffDock-L for ligands, followed by physics-guided conformer re-ranking and equivariant feature learning. At its core, EquiCPI employs SE(3)-equivariant message passing over atomic point clouds, preserving symmetry under rotations, translations, and reflections, while hierarchically encoding local interaction patterns through tensor products of spherical harmonics. The proposed model is evaluated on BindingDB (affinity prediction) and DUD-E (virtual screening), EquiCPI achieves performance on par with or exceeding the state-of-the-art deep learning competitors.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction of compound-protein interactions (CPI) remains acornerstone challenge in computational drug discovery. While existingsequence-based approaches leverage molecular fingerprints or graphrepresentations, they critically overlook three-dimensional (3D) structuraldeterminants of binding affinity. To bridge this gap, we present EquiCPI, anend-to-end geometric deep learning framework that synergizes first-principlesstructural modeling with SE(3)-equivariant neural networks. Our pipelinetransforms raw sequences into 3D atomic coordinates via ESMFold for proteinsand DiffDock-L for ligands, followed by physics-guided conformer re-ranking andequivariant feature learning. At its core, EquiCPI employs SE(3)-equivariantmessage passing over atomic point clouds, preserving symmetry under rotations,translations, and reflections, while hierarchically encoding local interactionpatterns through tensor products of spherical harmonics. The proposed model isevaluated on BindingDB (affinity prediction) and DUD-E (virtual screening),EquiCPI achieves performance on par with or exceeding the state-of-the-art deeplearning competitors.</description>
      <author>example@mail.com (Ngoc-Quang Nguyen)</author>
      <guid isPermaLink="false">2504.04654v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Planning Safety Trajectories with Dual-Phase, Physics-Informed, and Transportation Knowledge-Driven Large Language Models</title>
      <link>http://arxiv.org/abs/2504.04562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为LetsPi的框架，用于安全、类似人类的轨迹规划，以克服现有基础模型在自动驾驶任务中的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有基础模型在场景理解、规划和控制等驾驶相关任务中表现出强大的推理和泛化能力，但面临幻觉、不确定性和长推理延迟的挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够安全、类似人类地进行轨迹规划的框架，以解决现有模型的局限性。&lt;h4&gt;方法&lt;/h4&gt; LetsPi框架集成了大语言模型（LLM）推理和基于物理的社会力动力学，并通过双阶段架构来平衡推理和计算效率。它包括记忆收集阶段和快速推理阶段，以及使用代理安全措施和基于物理的提示技术来增强LLM的知识。&lt;h4&gt;主要发现&lt;/h4&gt;在HighD数据集上的广泛实验表明，LetsPi在五个安全指标上优于基线模型。&lt;h4&gt;结论&lt;/h4&gt;LetsPi是一个有效的框架，可以用于安全的自动驾驶轨迹规划，并且优于现有的基线模型。&lt;h4&gt;翻译&lt;/h4&gt;该论文提出了一种名为LetsPi的框架，用于安全、类似人类的轨迹规划，以克服现有基础模型在自动驾驶任务中的局限性。现有基础模型在场景理解、规划和控制等驾驶相关任务中表现出强大的推理和泛化能力，但面临幻觉、不确定性和长推理延迟的挑战。为了解决这些局限性，我们引入了名为LetsPi的物理信息、双阶段、知识驱动框架，用于安全、类似人类的轨迹规划。为了防止幻觉和最小化不确定性，该混合框架集成了大语言模型（LLM）推理和基于物理的社会力动力学。LetsPi利用LLM来分析驾驶场景和历史信息，为社交力模型提供适当的参数和目标目的地（目标），然后生成未来轨迹。此外，双阶段架构通过其记忆收集阶段和快速推理阶段平衡推理和计算效率。记忆收集阶段利用基于物理的LLM通过推理、反思和记忆模块处理和优化规划结果，将安全的、高质量的驾驶经验存储在记忆库中。引入了代理安全措施和基于物理的提示技术，分别增强LLM对交通安全和物理力的知识。快速推理阶段提取类似驾驶经验的少样本示例用于新场景，同时简化输入输出要求，以实现快速轨迹规划而不牺牲安全性。在HighD数据集上的广泛实验表明，LetsPi在五个安全指标上优于基线模型。见PDF获取项目GitHub链接。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have demonstrated strong reasoning and generalizationcapabilities in driving-related tasks, including scene understanding, planning,and control. However, they still face challenges in hallucinations,uncertainty, and long inference latency. While existing foundation models havegeneral knowledge of avoiding collisions, they often lacktransportation-specific safety knowledge. To overcome these limitations, weintroduce LetsPi, a physics-informed, dual-phase, knowledge-driven frameworkfor safe, human-like trajectory planning. To prevent hallucinations andminimize uncertainty, this hybrid framework integrates Large Language Model(LLM) reasoning with physics-informed social force dynamics. LetsPi leveragesthe LLM to analyze driving scenes and historical information, providingappropriate parameters and target destinations (goals) for the social forcemodel, which then generates the future trajectory. Moreover, the dual-phasearchitecture balances reasoning and computational efficiency through its MemoryCollection phase and Fast Inference phase. The Memory Collection phaseleverages the physics-informed LLM to process and refine planning resultsthrough reasoning, reflection, and memory modules, storing safe, high-qualitydriving experiences in a memory bank. Surrogate safety measures andphysics-informed prompt techniques are introduced to enhance the LLM'sknowledge of transportation safety and physical force, respectively. The FastInference phase extracts similar driving experiences as few-shot examples fornew scenarios, while simplifying input-output requirements to enable rapidtrajectory planning without compromising safety. Extensive experiments usingthe HighD dataset demonstrate that LetsPi outperforms baseline models acrossfive safety metrics.See PDF for project Github link.</description>
      <author>example@mail.com (Rui Gan, Pei Li, Keke Long, Bocheng An, Junwei You, Keshu Wu, Bin Ran)</author>
      <guid isPermaLink="false">2504.04562v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>The Point, the Vision and the Text: Does Point Cloud Boost Spatial Reasoning of Large Language Models?</title>
      <link>http://arxiv.org/abs/2504.04540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了3D大型语言模型（LLMs）利用点云中的空间信息进行3D空间推理的能力，并提出了一个名为ScanReQA的3D问答基准来评估模型对二进制空间关系的理解。&lt;h4&gt;背景&lt;/h4&gt;3D LLMs利用点云进行3D空间推理受到了广泛关注，但点云在3D空间推理中的作用仍被低估。&lt;h4&gt;目的&lt;/h4&gt;评估和分析了这些模型，以回答是否点云真正提升了3D LLMs的空间推理能力。&lt;h4&gt;方法&lt;/h4&gt;通过替换点云为视觉和文本输入，评估了不同输入模态下LLMs的空间推理能力；提出了ScanReQA基准来评估模型对二进制空间关系的理解。&lt;h4&gt;主要发现&lt;/h4&gt;1) 没有点输入的LLMs即使在零样本情况下也能达到具有竞争力的表现；2) 现有的3D LLMs难以理解二进制空间关系；3) 3D LLMs在利用点云中的结构坐标进行细粒度空间推理方面存在局限性。&lt;h4&gt;结论&lt;/h4&gt;这些结论有助于3D LLMs的下一步发展，并为其他模态的基础模型提供见解。&lt;h4&gt;翻译&lt;/h4&gt;本研究利用3D大型语言模型（LLMs）中的空间信息进行3D空间推理，并提出了一个名为ScanReQA的3D问答基准来全面评估模型对二进制空间关系的理解。研究发现，没有点输入的LLMs即使在没有先验知识的情况下也能取得有竞争力的成绩；现有的3D LLMs在理解二进制空间关系方面存在困难；3D LLMs在利用点云中的结构坐标进行细粒度空间推理时存在限制。这些结论对3D LLMs的发展有重要意义，也为其他模态的基础模型提供了启示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Large Language Models (LLMs) leveraging spatial information in pointclouds for 3D spatial reasoning attract great attention. Despite some promisingresults, the role of point clouds in 3D spatial reasoning remainsunder-explored. In this work, we comprehensively evaluate and analyze thesemodels to answer the research question: \textit{Does point cloud truly boostthe spatial reasoning capacities of 3D LLMs?} We first evaluate the spatialreasoning capacity of LLMs with different input modalities by replacing thepoint cloud with the visual and text counterparts. We then propose a novel 3DQA (Question-answering) benchmark, ScanReQA, that comprehensively evaluatesmodels' understanding of binary spatial relationships. Our findings revealseveral critical insights: 1) LLMs without point input could even achievecompetitive performance even in a zero-shot manner; 2) existing 3D LLMsstruggle to comprehend the binary spatial relationships; 3) 3D LLMs exhibitlimitations in exploiting the structural coordinates in point clouds forfine-grained spatial reasoning. We think these conclusions can help the nextstep of 3D LLMs and also offer insights for foundation models in othermodalities. We release datasets and reproducible codes in the anonymous projectpage: https://3d-llm.xyz.</description>
      <author>example@mail.com (Weichen Zhang, Ruiying Peng, Chen Gao, Jianjie Fang, Xin Zeng, Kaiyuan Li, Ziyou Wang, Jinqiang Cui, Xin Wang, Xinlei Chen, Yong Li)</author>
      <guid isPermaLink="false">2504.04540v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Squeeze and Excitation: A Weighted Graph Contrastive Learning for Collaborative Filtering</title>
      <link>http://arxiv.org/abs/2504.04443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种加权图对比学习框架（WeightedGCL），旨在提高推荐系统的表现，特别是通过利用扰动视图的自我监督信号来减轻数据稀疏性的挑战。&lt;h4&gt;背景&lt;/h4&gt;对比学习（CL）作为一种强大的技术，在推荐系统中得到了应用，尤其是在处理数据稀疏性的问题上。&lt;h4&gt;目的&lt;/h4&gt;通过提出加权图对比学习框架，旨在解决现有GCL模型中特征注意力分配不合理的问题，从而提高模型的表现。&lt;h4&gt;方法&lt;/h4&gt;WeightedGCL采用了一种鲁棒的扰动策略，仅扰动最终GCN层的视图，并引入了squeeze and excitation网络（SENet）来动态加权扰动视图的特征。&lt;h4&gt;主要发现&lt;/h4&gt;WeightedGCL通过加强模型对关键特征的关注，减少了不相关信息的影响，实验结果表明，与基线模型相比，WeightedGCL实现了显著的准确率提升。&lt;h4&gt;结论&lt;/h4&gt;WeightedGCL框架在广泛使用的数据集上取得了显著的性能提升，证明了其有效性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive Learning (CL) has recently emerged as a powerful technique inrecommendation systems, particularly for its capability to harnessself-supervised signals from perturbed views to mitigate the persistentchallenge of data sparsity. The process of constructing perturbed views of theuser-item bipartite graph and performing contrastive learning between perturbedviews in a graph convolutional network (GCN) is called graph contrastivelearning (GCL), which aims to enhance the robustness of representationlearning. Although existing GCL-based models are effective, the weightassignment method for perturbed views has not been fully explored. A criticalproblem in existing GCL-based models is the irrational allocation of featureattention. This problem limits the model's ability to effectively leveragecrucial features, resulting in suboptimal performance. To address this, wepropose a Weighted Graph Contrastive Learning framework (WeightedGCL).Specifically, WeightedGCL applies a robust perturbation strategy, whichperturbs only the view of the final GCN layer. In addition, WeightedGCLincorporates a squeeze and excitation network (SENet) to dynamically weight thefeatures of the perturbed views. Our WeightedGCL strengthens the model's focuson crucial features and reduces the impact of less relevant information.Extensive experiments on widely used datasets demonstrate that our WeightedGCLachieves significant accuracy improvements compared to competitive baselines.</description>
      <author>example@mail.com (Zheyu Chen, Jinfeng Xu, Yutong Wei, Ziyue Peng)</author>
      <guid isPermaLink="false">2504.04443v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Attentional Graph Meta-Learning for Indoor Localization Using Extremely Sparse Fingerprints</title>
      <link>http://arxiv.org/abs/2504.04829v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于指纹的室内定位方法，旨在解决高精度定位和密集网格的需求带来的劳动密集型问题，通过结合注意力图神经网络和元学习框架，以及两种新的数据增强策略，实现了对稀疏指纹的有效利用。&lt;h4&gt;背景&lt;/h4&gt;现有的指纹定位方法劳动密集，且在高精度定位和稀疏指纹之间存在挑战，同时现有方法忽视了空间和环境特征的价值。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的定位方法，以减少劳动密集型工作，同时提高定位精度。&lt;h4&gt;方法&lt;/h4&gt;1) 使用注意力图神经网络（AGNN）模型学习空间邻接关系和信息聚合；2) 利用元学习框架和相似环境数据集增强模型训练；3) 引入两种数据增强策略：使用移动平台进行未标记指纹增强，以及通过环境数字孪生进行合成标记指纹增强。&lt;h4&gt;主要发现&lt;/h4&gt;AGML模型结合了AGNN模型和元学习框架的优点，能够有效地处理稀疏指纹带来的挑战，并通过实验证明了其在合成和真实世界数据集上的优越性。&lt;h4&gt;结论&lt;/h4&gt;AGML模型在稀疏指纹条件下，在多个评估指标上均优于现有的基准方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于指纹的室内定位由于需要密集网格和重复的时间和空间测量而往往劳动密集。在高稀疏指纹条件下保持高定位精度仍然是一个持续的挑战。现有的基准方法主要依赖于测量的指纹，而忽略了有价值的空间和环境特征。在本文中，我们提出了一种注意力图神经网络（AGNN）模型的系统整合，该模型能够学习空间邻接关系并聚合邻近指纹的信息，以及一个利用具有相似环境特征的数据集进行模型训练的元学习框架。为了最小化指纹收集的劳动，我们引入了两种新颖的数据增强策略：1）使用移动平台进行未标记指纹增强，这使半监督AGNN模型能够纳入未标记指纹的信息；2）通过环境数字孪生进行合成标记指纹增强，通过实际分布对齐增强了元学习框架，有效地最小化了合成和真实世界指纹之间的特征差异。通过整合这些新颖模块，我们提出了注意力图元学习（AGML）模型。这个新颖的模型结合了AGNN模型和元学习框架的优点，以解决由极端稀疏指纹带来的挑战。为了验证我们的方法，我们从消费级WiFi设备和专业设备收集了多个数据集，这些设备在多种环境中使用。在合成和真实世界数据集上进行的广泛实验表明，基于AGML模型的定位方法在所有评估指标上均一致优于使用稀疏指纹的所有基准方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fingerprint-based indoor localization is often labor-intensive due to theneed for dense grids and repeated measurements across time and space.Maintaining high localization accuracy with extremely sparse fingerprintsremains a persistent challenge. Existing benchmark methods primarily rely onthe measured fingerprints, while neglecting valuable spatial and environmentalcharacteristics. In this paper, we propose a systematic integration of anAttentional Graph Neural Network (AGNN) model, capable of learning spatialadjacency relationships and aggregating information from neighboringfingerprints, and a meta-learning framework that utilizes datasets with similarenvironmental characteristics to enhance model training. To minimize the laborrequired for fingerprint collection, we introduce two novel data augmentationstrategies: 1) unlabeled fingerprint augmentation using moving platforms, whichenables the semi-supervised AGNN model to incorporate information fromunlabeled fingerprints, and 2) synthetic labeled fingerprint augmentationthrough environmental digital twins, which enhances the meta-learning frameworkthrough a practical distribution alignment, which can minimize the featurediscrepancy between synthetic and real-world fingerprints effectively. Byintegrating these novel modules, we propose the Attentional Graph Meta-Learning(AGML) model. This novel model combines the strengths of the AGNN model and themeta-learning framework to address the challenges posed by extremely sparsefingerprints. To validate our approach, we collected multiple datasets fromboth consumer-grade WiFi devices and professional equipment across diverseenvironments. Extensive experiments conducted on both synthetic and real-worlddatasets demonstrate that the AGML model-based localization method consistentlyoutperforms all baseline methods using sparse fingerprints across all evaluatedmetrics.</description>
      <author>example@mail.com (Wenzhong Yan, Feng Yin, Jun Gao, Ao Wang, Yang Tian, Ruizhi Chen)</author>
      <guid isPermaLink="false">2504.04829v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models</title>
      <link>http://arxiv.org/abs/2504.04893v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to CVPR 2025 Workshop EVAL-FoMo-2&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SCAM，这是迄今为止最大、最多样化的真实世界印刷攻击图像数据集，对视觉-语言模型（VLMs）进行了广泛基准测试，揭示了印刷攻击对模型性能的影响，并提供了对构建鲁棒和可信的多模态AI系统的见解。&lt;h4&gt;背景&lt;/h4&gt;印刷攻击利用多模态基础模型中文本和视觉内容之间的相互作用，导致误导性文本嵌入图像时出现误分类。现有数据集在规模和多样性方面存在局限性，难以研究此类漏洞。&lt;h4&gt;目的&lt;/h4&gt;研究印刷攻击对视觉-语言模型的影响，并提供一个综合资源以促进对鲁棒和可信的多模态AI系统的研究。&lt;h4&gt;方法&lt;/h4&gt;引入了SCAM数据集，对VLMs进行了基准测试，并分析了训练数据和模型架构对攻击敏感性的影响。&lt;h4&gt;主要发现&lt;/h4&gt;印刷攻击显著降低了VLMs的性能，并发现训练数据和模型架构影响了攻击的敏感性。尽管大型语言模型（LLMs）的骨干结构有助于减轻其脆弱性，但最先进的视觉-语言模型（LVLMs）仍然容易受到攻击。合成攻击与真实世界（手写）攻击非常相似，验证了它们在研究中的使用。&lt;h4&gt;结论&lt;/h4&gt;印刷攻击是VLMs的一个重要安全漏洞，需要进一步研究以构建鲁棒的多模态AI系统。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了SCAM，这是迄今为止最大、最多样化的真实世界印刷攻击图像数据集。通过对视觉-语言模型（VLMs）进行广泛的基准测试，我们发现印刷攻击会显著降低模型性能，并确定了训练数据和模型架构对攻击敏感性的影响。我们的研究揭示了印刷攻击在LVLMs中持续存在的原因，尽管更大的LLMs骨干结构有助于减轻其脆弱性。此外，我们还证明了合成攻击与真实世界攻击非常相似，验证了它们在研究中的使用。我们的工作提供了一个综合资源，并为未来研究鲁棒和可信的多模态AI系统提供了实证见解。本文中介绍的数据集已公开发布，代码和评估工具也已在相关网站上提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Typographic attacks exploit the interplay between text and visual content inmultimodal foundation models, causing misclassifications when misleading textis embedded within images. However, existing datasets are limited in size anddiversity, making it difficult to study such vulnerabilities. In this paper, weintroduce SCAM, the largest and most diverse dataset of real-world typographicattack images to date, containing 1,162 images across hundreds of objectcategories and attack words. Through extensive benchmarking of Vision-LanguageModels (VLMs) on SCAM, we demonstrate that typographic attacks significantlydegrade performance, and identify that training data and model architectureinfluence the susceptibility to these attacks. Our findings reveal thattypographic attacks persist in state-of-the-art Large Vision-Language Models(LVLMs) due to the choice of their vision encoder, though larger Large LanguageModels (LLMs) backbones help mitigate their vulnerability. Additionally, wedemonstrate that synthetic attacks closely resemble real-world (handwritten)attacks, validating their use in research. Our work provides a comprehensiveresource and empirical insights to facilitate future research toward robust andtrustworthy multimodal AI systems. We publicly release the datasets introducedin this paper under https://huggingface.co/datasets/BLISS-e-V/SCAM, along withthe code for evaluations at https://github.com/Bliss-e-V/SCAM.</description>
      <author>example@mail.com (Justus Westerhoff, Erblina Purellku, Jakob Hackstein, Leo Pinetzki, Lorenz Hufe)</author>
      <guid isPermaLink="false">2504.04893v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>AVadCLIP: Audio-Visual Collaboration for Robust Video Anomaly Detection</title>
      <link>http://arxiv.org/abs/2504.04495v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 4 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的弱监督视频异常检测框架，该框架利用音频-视觉协作进行鲁棒的视频异常检测，显著提高了检测准确性。&lt;h4&gt;背景&lt;/h4&gt;传统的基于视觉的视频异常检测方法在复杂环境中存在信息不足和高误报率的问题。&lt;h4&gt;目的&lt;/h4&gt;解决传统方法在复杂环境中的局限性。&lt;h4&gt;方法&lt;/h4&gt;利用Contrastive Language-Image Pretraining (CLIP)的多模态表示学习能力，引入了两种主要创新：一种高效的音频-视觉融合，通过轻量级的参数调整实现自适应跨模态集成，同时保持冻结的CLIP骨干网络；以及一种新颖的音频-视觉提示，根据音频-视觉特征与文本标签之间的语义相关性，动态增强文本嵌入，显著提高CLIP在视频异常检测任务中的泛化能力。此外，为了提高推理过程中对模态缺失的鲁棒性，开发了一个基于不确定性的特征蒸馏模块，该模块从仅视觉输入中合成音频-视觉表示，并使用基于音频-视觉特征多样性的不确定性建模来动态强调蒸馏过程中的挑战性特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个基准测试中表现出色，音频集成显著提高了各种场景下的异常检测准确率。使用不确定性驱动的蒸馏增强的单模态数据，该方法在性能上始终优于当前的单一模态视频异常检测方法。&lt;h4&gt;结论&lt;/h4&gt;该方法通过音频-视觉协作和不确定性驱动的特征蒸馏，为视频异常检测提供了一种鲁棒的解决方案，显著提高了检测准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;With the increasing adoption of video anomaly detection in intelligentsurveillance domains, conventional visual-based detection approaches often struggle with information insufficiency and high false-positive rates in complex environments. To address these limitations, we present a novel weaklysupervised framework that leverages audio-visual collaboration for robust video anomaly detection. Capitalizing on the exceptional cross-modal representation learning capabilities of Contrastive Language-Image Pretraining (CLIP) across visual, audio, and textual domains, our framework introduces two major innovations: an efficient audio-visual fusion that enables adaptive cross-modal integration through lightweight parametric adaptation while maintaining the frozen CLIP backbone, and a novel audio-visual prompt that dynamically enhances text embeddings with key multimodal information based on the semantic correlation between audio-visual features and textual labels, significantly improving CLIP's generalization for the video anomaly detection task. Moreover, to enhance robustness against modality deficiency during inference, we further develop an uncertainty-driven feature distillation module that synthesizes audio-visual representations from visual-only inputs. This module employs uncertainty modeling based on the diversity of audio-visual features to dynamically emphasize challenging features during the distillation process. Our framework demonstrates superior performance across multiple benchmarks, with audio integration significantly boosting anomaly detection accuracy in various scenarios. Notably, with unimodal data enhanced by uncertainty-driven distillation, our approach consistently outperforms current unimodal VAD methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the increasing adoption of video anomaly detection in intelligentsurveillance domains, conventional visual-based detection approaches oftenstruggle with information insufficiency and high false-positive rates incomplex environments. To address these limitations, we present a novel weaklysupervised framework that leverages audio-visual collaboration for robust videoanomaly detection. Capitalizing on the exceptional cross-modal representationlearning capabilities of Contrastive Language-Image Pretraining (CLIP) acrossvisual, audio, and textual domains, our framework introduces two majorinnovations: an efficient audio-visual fusion that enables adaptive cross-modalintegration through lightweight parametric adaptation while maintaining thefrozen CLIP backbone, and a novel audio-visual prompt that dynamically enhancestext embeddings with key multimodal information based on the semanticcorrelation between audio-visual features and textual labels, significantlyimproving CLIP's generalization for the video anomaly detection task. Moreover,to enhance robustness against modality deficiency during inference, we furtherdevelop an uncertainty-driven feature distillation module that synthesizesaudio-visual representations from visual-only inputs. This module employsuncertainty modeling based on the diversity of audio-visual features todynamically emphasize challenging features during the distillation process. Ourframework demonstrates superior performance across multiple benchmarks, withaudio integration significantly boosting anomaly detection accuracy in variousscenarios. Notably, with unimodal data enhanced by uncertainty-drivendistillation, our approach consistently outperforms current unimodal VADmethods.</description>
      <author>example@mail.com (Peng Wu, Wanshun Su, Guansong Pang, Yujia Sun, Qingsen Yan, Peng Wang, Yanning Zhang)</author>
      <guid isPermaLink="false">2504.04495v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>3D Scene Understanding Through Local Random Access Sequence Modeling</title>
      <link>http://arxiv.org/abs/2504.03875v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project webpage: https://neuroailab.github.io/projects/lras_3d/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LRAS的自动回归生成模型，用于从单张图像中理解3D场景，旨在解决复杂场景下的对象和场景一致性维护问题。&lt;h4&gt;背景&lt;/h4&gt;3D场景理解是计算机视觉领域的关键问题，在图形、增强现实和机器人等领域有广泛的应用。尽管基于扩散的建模方法显示出潜力，但它们在保持对象和场景一致性方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出LRAS模型，旨在解决复杂场景下对象和场景一致性维护的局限性。&lt;h4&gt;方法&lt;/h4&gt;LRAS模型通过使用局部补丁量化和随机顺序序列生成，结合光流作为3D场景编辑的中间表示，实现了新颖的视角合成和3D对象操作能力。此外，通过修改序列设计，该框架还自然扩展到自监督深度估计。&lt;h4&gt;主要发现&lt;/h4&gt;LRAS在多个3D场景理解任务上表现出色，证明了其在构建下一代3D视觉模型方面的统一和有效性。&lt;h4&gt;结论&lt;/h4&gt;LRAS模型为3D场景理解提供了一种统一且有效的框架，有望推动相关技术的发展。&lt;h4&gt;翻译&lt;/h4&gt;3D场景理解从单张图像是计算机视觉中的一个关键问题，在图形、增强现实和机器人等领域有众多下游应用。虽然基于扩散的建模方法显示出前景，但它们通常难以保持对象和场景的一致性，特别是在复杂的真实场景中。为了解决这些局限性，我们提出了一种名为局部随机访问序列（LRAS）的自动回归生成方法，该方法使用局部补丁量化和随机顺序序列生成。通过利用光流作为3D场景编辑的中间表示，我们的实验表明LRAS实现了最先进的视角合成和3D对象操作能力。此外，我们展示了通过简单修改序列设计，我们的框架自然扩展到自监督深度估计。通过在多个3D场景理解任务上实现强大性能，LRAS为构建下一代3D视觉模型提供了一个统一且有效的框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D scene understanding from single images is a pivotal problem in computervision with numerous downstream applications in graphics, augmented reality,and robotics. While diffusion-based modeling approaches have shown promise,they often struggle to maintain object and scene consistency, especially incomplex real-world scenarios. To address these limitations, we propose anautoregressive generative approach called Local Random Access Sequence (LRAS)modeling, which uses local patch quantization and randomly ordered sequencegeneration. By utilizing optical flow as an intermediate representation for 3Dscene editing, our experiments demonstrate that LRAS achieves state-of-the-artnovel view synthesis and 3D object manipulation capabilities. Furthermore, weshow that our framework naturally extends to self-supervised depth estimationthrough a simple modification of the sequence design. By achieving strongperformance on multiple 3D scene understanding tasks, LRAS provides a unifiedand effective framework for building the next generation of 3D vision models.</description>
      <author>example@mail.com (Wanhee Lee, Klemen Kotar, Rahul Mysore Venkatesh, Jared Watrous, Honglin Chen, Khai Loong Aw, Daniel L. K. Yamins)</author>
      <guid isPermaLink="false">2504.03875v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Learning Conditionally Independent Transformations using Normal Subgroups in Group Theory</title>
      <link>http://arxiv.org/abs/2504.04490v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 10 figures, conference paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了利用正规子群进行条件独立变换分离的新方法，通过图像中的几何变换实验展示了该方法在无监督情况下成功对旋转和变换进行分类，揭示了通过正规子群进行群分解与表示学习中的变换分类之间的紧密联系。&lt;h4&gt;背景&lt;/h4&gt;人类通过认知能力识别物体及其变换，强调了无监督表示学习的重要性。无监督表示学习的一个基本挑战是在学习特征表示中分离不同的变换。&lt;h4&gt;目的&lt;/h4&gt;扩展当前表示学习框架，提出一种新的方法来分离条件独立变换，即使在没有交换性的情况下。&lt;h4&gt;方法&lt;/h4&gt;从伽罗瓦理论中汲取灵感，通过正规子群分解群以分析结构化变换。该方法利用正规子群来分离条件独立变换，即使在非交换情况下也能实现。&lt;h4&gt;主要发现&lt;/h4&gt;通过在图像的几何变换上的实验，证明了该方法能够无监督地对条件独立的变换进行分类。&lt;h4&gt;结论&lt;/h4&gt;该方法为表示学习中的变换分类提供了一个新的视角，表明通过正规子群进行群分解与变换分类之间存在紧密的联系。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类通过认知能力来识别物体及其变换，突出了无监督表示学习的重要性。无监督表示学习中的一个基本挑战是在学习特征表示中区分不同的变换。尽管已经探索了代数方法，但一个全面的理论框架仍然不发达。现有的方法基于代数独立性分解变换，但这些方法主要关注交换变换，并且不适用于变换条件独立但非交换的情况。为了扩展当前的表示学习框架，我们从伽罗瓦理论中汲取灵感，其中通过正规子群分解群为分析结构化变换提供了一个方法。在某种条件下，正规子群自然扩展了交换性，为变换的分类提供了基础，即使它们不交换。在本文中，我们提出了一种新颖的方法，该方法利用正规子群来实现条件独立变换的分离，即使在缺乏交换性的情况下也能实现。通过在图像几何变换上的实验，我们表明我们的方法成功地以无监督的方式对条件独立的变换进行了分类，如旋转和平移，这表明了通过正规子群进行群分解与表示学习中的变换分类之间的紧密联系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans develop certain cognitive abilities to recognize objects and theirtransformations without explicit supervision, highlighting the importance ofunsupervised representation learning. A fundamental challenge in unsupervisedrepresentation learning is to separate different transformations in learnedfeature representations. Although algebraic approaches have been explored, acomprehensive theoretical framework remains underdeveloped. Existing methodsdecompose transformations based on algebraic independence, but these methodsprimarily focus on commutative transformations and do not extend to cases wheretransformations are conditionally independent but noncommutative. To extendcurrent representation learning frameworks, we draw inspiration from Galoistheory, where the decomposition of groups through normal subgroups provides anapproach for the analysis of structured transformations. Normal subgroupsnaturally extend commutativity under certain conditions and offer a foundationfor the categorization of transformations, even when they do not commute. Inthis paper, we propose a novel approach that leverages normal subgroups toenable the separation of conditionally independent transformations, even in theabsence of commutativity. Through experiments on geometric transformations inimages, we show that our method successfully categorizes conditionallyindependent transformations, such as rotation and translation, in anunsupervised manner, suggesting a close link between group decomposition vianormal subgroups and transformation categorization in representation learning.</description>
      <author>example@mail.com (Kayato Nishitsunoi, Yoshiyuki Ohmura, Takayuki Komatsu, Yasuo Kuniyoshi)</author>
      <guid isPermaLink="false">2504.04490v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>MedGNN: Capturing the Links Between Urban Characteristics and Medical Prescriptions</title>
      <link>http://arxiv.org/abs/2504.04739v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages' main content. This is a preprint. Submitted to KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MedGNN的框架，用于研究城市社会人口和环境因素与健康之间的关系，旨在通过机器学习模型解决传统统计方法在非线性效应上的不足，以及机器学习模型在地理和拓扑效应上的不足。&lt;h4&gt;背景&lt;/h4&gt;理解城市社会人口和环境因素与健康之间的关系对于公共卫生和城市规划至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架MedGNN，以解决传统统计方法和机器学习模型在处理非线性、地理和拓扑效应时的局限性。&lt;h4&gt;方法&lt;/h4&gt;MedGNN通过构建一个2-hop空间图，将位置和定位节点嵌入与城市特征结合，以图神经网络的形式进行整合。该框架应用于包含超过150个环境和人口因素的MEDSAT数据集，覆盖伦敦4835个社区，并使用抑郁症处方作为案例研究。&lt;h4&gt;主要发现&lt;/h4&gt;MedGNN在预测准确性上比基线方法提高了25%以上。通过地理主成分分析分析了图嵌入，发现了一些与先前研究一致的结果，对当前辩论有贡献，并需要进一步研究。&lt;h4&gt;结论&lt;/h4&gt;MedGNN展示了机器学习在公共卫生研究中的潜力，尤其是在跨学科研究中的应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：理解城市社会人口和环境因素与健康之间的关系对于公共卫生和城市规划至关重要。然而，传统的统计方法难以处理非线性效应，而机器学习模型往往无法以可解释的方式捕捉地理（邻近区域更加相似）和拓扑（地点之间连接不等）效应。为了解决这个问题，我们提出了MedGNN，一个空间拓扑显式框架，它构建了一个2-hop空间图，将位置和定位节点嵌入与城市特征整合到图神经网络中。应用于覆盖超过150个环境和人口因素以及6种处方结果（抑郁症、焦虑症、糖尿病、高血压、哮喘和阿片类药物）的全面数据集MEDSAT，涵盖了伦敦4835个社区，与基线方法相比，MedGNN的平均预测准确性提高了25%以上。以抑郁症处方作为案例研究，我们通过地理主成分分析分析了图嵌入，发现了一些与先前研究一致的结果，对当前辩论有贡献，并需要进一步研究。这些结果表明，MedGNN具有潜力，更广泛地，精心应用的机器学习可以推动跨学科公共卫生研究的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding how urban socio-demographic and environmental factors relatewith health is essential for public health and urban planning. However,traditional statistical methods struggle with nonlinear effects, while machinelearning models often fail to capture geographical (nearby areas being moresimilar) and topological (unequal connectivity between places) effects in aninterpretable way. To address this, we propose MedGNN, a spatio-topologicallyexplicit framework that constructs a 2-hop spatial graph, integratingpositional and locational node embeddings with urban characteristics in a graphneural network. Applied to MEDSAT, a comprehensive dataset covering over 150environmental and socio-demographic factors and six prescription outcomes(depression, anxiety, diabetes, hypertension, asthma, and opioids) across 4,835Greater London neighborhoods, MedGNN improved predictions by over 25% onaverage compared to baseline methods. Using depression prescriptions as a casestudy, we analyzed graph embeddings via geographical principal componentanalysis, identifying findings that: align with prior research (e.g., higherantidepressant prescriptions among older and White populations), contribute toongoing debates (e.g., greenery linked to higher and NO2 to lowerprescriptions), and warrant further study (e.g., canopy evaporation correlatedwith fewer prescriptions). These results demonstrate MedGNN's potential, andmore broadly, of carefully applied machine learning, to advancetransdisciplinary public health research.</description>
      <author>example@mail.com (Minwei Zhao, Sanja Scepanovic, Stephen Law, Daniele Quercia, Ivica Obadic)</author>
      <guid isPermaLink="false">2504.04739v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable Single-View 3D Gaussian Splatting using Unsupervised Hierarchical Disentangled Representation Learning</title>
      <link>http://arxiv.org/abs/2504.04190v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Gaussian Splatting (GS) 在3D重建中取得了显著进展，但现有的3DGS方法在理解3D语义方面存在挑战，影响模型的可控性和可解释性。&lt;h4&gt;背景&lt;/h4&gt;Gaussian Splatting (GS) 在3D重建中提供了快速渲染和高品质的结果，但现有的方法难以理解3D语义。&lt;h4&gt;目的&lt;/h4&gt;提出一个可解释的单视图3DGS框架3DisGS，通过分层解耦表示学习（DRL）发现粗粒度和细粒度的3D语义。&lt;h4&gt;方法&lt;/h4&gt;模型采用双分支架构，包括点云初始化分支和三平面高斯生成分支，通过分离3D几何和视觉外观特征实现粗粒度解耦。通过DRL编码器适配器进一步发现每个模态中的细粒度语义表示。&lt;h4&gt;主要发现&lt;/h4&gt;这是第一个实现无监督可解释3DGS的工作，模型在保持高质量和快速重建的同时实现了3D解耦。&lt;h4&gt;结论&lt;/h4&gt;提出的3DisGS框架能够有效解决现有3DGS方法中语义理解的问题，提高了模型的可控性和可解释性。&lt;h4&gt;翻译&lt;/h4&gt;Gaussian Splatting (GS) 近期在3D重建领域取得了显著进展，实现了快速渲染和高质量的结果。然而，现有的3DGS方法在理解底层3D语义方面存在挑战，这阻碍了模型的可控性和可解释性。为了解决这个问题，我们提出了一种可解释的单视图3DGS框架，称为3DisGS，通过分层解耦表示学习（DRL）来发现粗粒度和细粒度的3D语义。具体来说，该模型采用双分支架构，包括点云初始化分支和三平面高斯生成分支，通过分离3D几何和视觉外观特征来实现粗粒度解耦。随后，通过基于DRL的编码器适配器进一步发现每个模态中的细粒度语义表示。据我们所知，这是第一个实现无监督可解释3DGS的工作。评估结果表明，我们的模型在保持高质量和快速重建的同时实现了3D解耦。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gaussian Splatting (GS) has recently marked a significant advancement in 3Dreconstruction, delivering both rapid rendering and high-quality results.However, existing 3DGS methods pose challenges in understanding underlying 3Dsemantics, which hinders model controllability and interpretability. To addressit, we propose an interpretable single-view 3DGS framework, termed 3DisGS, todiscover both coarse- and fine-grained 3D semantics via hierarchicaldisentangled representation learning (DRL). Specifically, the model employs adual-branch architecture, consisting of a point cloud initialization branch anda triplane-Gaussian generation branch, to achieve coarse-graineddisentanglement by separating 3D geometry and visual appearance features.Subsequently, fine-grained semantic representations within each modality arefurther discovered through DRL-based encoder-adapters. To our knowledge, thisis the first work to achieve unsupervised interpretable 3DGS. Evaluationsindicate that our model achieves 3D disentanglement while preservinghigh-quality and rapid reconstruction.</description>
      <author>example@mail.com (Yuyang Zhang, Baao Xie, Hu Zhu, Qi Wang, Huanting Guo, Xin Jin, Wenjun Zeng)</author>
      <guid isPermaLink="false">2504.04190v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>NCL-CIR: Noise-aware Contrastive Learning for Composed Image Retrieval</title>
      <link>http://arxiv.org/abs/2504.04339v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Has been accepted by ICASSP2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对Composed Image Retrieval (CIR)的噪声感知对比学习方法NCL-CIR，通过解决查询与目标图像不匹配的问题，提高了检索性能。&lt;h4&gt;背景&lt;/h4&gt;现有的CIR方法主要关注通过数据增强或模型设计探索查询对（图像和文本）之间的关系，但往往假设查询与目标图像完美对齐，这与实际情况不符。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来解决CIR中查询与目标图像不匹配导致的噪声问题，从而提高检索性能。&lt;h4&gt;方法&lt;/h4&gt;NCL-CIR包括两个关键组件：权重补偿块（WCB）和噪声对过滤块（NFB）。WCB通过不同的权重图确保多模态查询和目标图像的稳定token表示；NFB结合高斯混合模型（GMM）预测噪声对，并生成相应的软标签，设计基于软标签的噪声对比估计（NCE）损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;NCL-CIR能够有效减轻不匹配和部分匹配样本的影响，实验结果表明，NCL-CIR在基准数据集上取得了优异的性能。&lt;h4&gt;结论&lt;/h4&gt;NCL-CIR是一种有效的CIR方法，能够提高检索性能，特别是在处理不匹配和噪声数据时。&lt;h4&gt;翻译&lt;/h4&gt;Composed Image Retrieval (CIR) seeks to find a target image using a multi-modal query, which combines an image with modification text to pinpoint the target. While recent CIR methods have shown promise, they mainly focus on exploring relationships between the query pairs (image and text) through data augmentation or model design. These methods often assume perfect alignment between queries and target images, an idealized scenario rarely encountered in practice. In reality, pairs are often partially or completely mismatched due to issues like inaccurate modification texts, low-quality target images, and annotation errors. Ignoring these mismatches leads to numerous False Positive Pair (FFPs) denoted as noise pairs in the dataset, causing the model to overfit and ultimately reducing its performance. To address this problem, we propose the Noise-aware Contrastive Learning for CIR (NCL-CIR), comprising two key components: the Weight Compensation Block (WCB) and the Noise-pair Filter Block (NFB). The WCB coupled with diverse weight maps can ensure more stable token representations of multi-modal queries and target images. Meanwhile, the NFB, in conjunction with the Gaussian Mixture Model (GMM) predicts noise pairs by evaluating loss distributions, and generates soft labels correspondingly, allowing for the design of the soft-label based Noise Contrastive Estimation (NCE) loss function. Consequently, the overall architecture helps to mitigate the influence of mismatched and partially matched samples, with experimental results demonstrating that NCL-CIR achieves exceptional performance on the benchmark datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Composed Image Retrieval (CIR) seeks to find a target image using amulti-modal query, which combines an image with modification text to pinpointthe target. While recent CIR methods have shown promise, they mainly focus onexploring relationships between the query pairs (image and text) through dataaugmentation or model design. These methods often assume perfect alignmentbetween queries and target images, an idealized scenario rarely encountered inpractice. In reality, pairs are often partially or completely mismatched due toissues like inaccurate modification texts, low-quality target images, andannotation errors. Ignoring these mismatches leads to numerous False PositivePair (FFPs) denoted as noise pairs in the dataset, causing the model to overfitand ultimately reducing its performance. To address this problem, we proposethe Noise-aware Contrastive Learning for CIR (NCL-CIR), comprising two keycomponents: the Weight Compensation Block (WCB) and the Noise-pair Filter Block(NFB). The WCB coupled with diverse weight maps can ensure more stable tokenrepresentations of multi-modal queries and target images. Meanwhile, the NFB,in conjunction with the Gaussian Mixture Model (GMM) predicts noise pairs byevaluating loss distributions, and generates soft labels correspondingly,allowing for the design of the soft-label based Noise Contrastive Estimation(NCE) loss function. Consequently, the overall architecture helps to mitigatethe influence of mismatched and partially matched samples, with experimentalresults demonstrating that NCL-CIR achieves exceptional performance on thebenchmark datasets.</description>
      <author>example@mail.com (Peng Gao, Yujian Lee, Zailong Chen, Hui zhang, Xubo Liu, Yiyang Hu, Guquang Jing)</author>
      <guid isPermaLink="false">2504.04339v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>MME-Unify: A Comprehensive Benchmark for Unified Multimodal Understanding and Generation Models</title>
      <link>http://arxiv.org/abs/2504.03641v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://mme-unify.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出一个全面的评估框架，用于系统地评估统一多模态语言模型（U-MLLMs），并发现现有U-MLLMs在处理混合模态任务时存在性能差距。&lt;h4&gt;背景&lt;/h4&gt;现有的MLLM基准在评估U-MLLMs时面临挑战，包括缺乏标准化基准和混合模态生成基准的缺失。&lt;h4&gt;目的&lt;/h4&gt;设计一个综合的评估框架，以系统地评估U-MLLMs的性能。&lt;h4&gt;方法&lt;/h4&gt;提出的基准包括：1）标准化传统任务评估，从12个数据集中采样，涵盖10个任务和30个子任务；2）统一任务评估，引入五个测试多模态推理的新任务；3）全面模型基准测试，评估12个领先的U-MLLMs，包括Janus-Pro、EMU3、VILA-U和Gemini2-flash等。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现现有U-MLLMs在处理混合模态任务时存在显著的性能差距，突显了需要更强大的模型。&lt;h4&gt;结论&lt;/h4&gt;需要开发更强大的模型来有效处理混合模态任务。&lt;h4&gt;翻译&lt;/h4&gt;Existing MLLM benchmarks face significant challenges in evaluating UnifiedMLLMs (U-MLLMs) due to: 1) lack of standardized benchmarks for traditionaltasks, leading to inconsistent comparisons; 2) absence of benchmarks formixed-modality generation, which fails to assess multimodal reasoningcapabilities. We present a comprehensive evaluation framework designed tosystematically assess U-MLLMs. Our benchmark includes: Standardized TraditionalTask Evaluation. We sample from 12 datasets, covering 10 tasks with 30subtasks, ensuring consistent and fair comparisons across studies. 2. UnifiedTask Assessment. We introduce five novel tasks testing multimodal reasoning,including image editing, commonsense QA with image generation, and geometricreasoning. 3. Comprehensive Model Benchmarking. We evaluate 12 leading U-MLLMs,such as Janus-Pro, EMU3, VILA-U, and Gemini2-flash, alongside specializedunderstanding (e.g., Claude-3.5-Sonnet) and generation models (e.g., DALL-E-3).Our findings reveal substantial performance gaps in existing U-MLLMs,highlighting the need for more robust models capable of handling mixed-modalitytasks effectively. The code and evaluation data can be found inhttps://mme-unify.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing MLLM benchmarks face significant challenges in evaluating UnifiedMLLMs (U-MLLMs) due to: 1) lack of standardized benchmarks for traditionaltasks, leading to inconsistent comparisons; 2) absence of benchmarks formixed-modality generation, which fails to assess multimodal reasoningcapabilities. We present a comprehensive evaluation framework designed tosystematically assess U-MLLMs. Our benchmark includes: Standardized TraditionalTask Evaluation. We sample from 12 datasets, covering 10 tasks with 30subtasks, ensuring consistent and fair comparisons across studies." 2. UnifiedTask Assessment. We introduce five novel tasks testing multimodal reasoning,including image editing, commonsense QA with image generation, and geometricreasoning. 3. Comprehensive Model Benchmarking. We evaluate 12 leading U-MLLMs,such as Janus-Pro, EMU3, VILA-U, and Gemini2-flash, alongside specializedunderstanding (e.g., Claude-3.5-Sonnet) and generation models (e.g., DALL-E-3).Our findings reveal substantial performance gaps in existing U-MLLMs,highlighting the need for more robust models capable of handling mixed-modalitytasks effectively. The code and evaluation data can be found inhttps://mme-unify.github.io/.</description>
      <author>example@mail.com (Wulin Xie, Yi-Fan Zhang, Chaoyou Fu, Yang Shi, Bingyan Nie, Hongkai Chen, Zhang Zhang, Liang Wang, Tieniu Tan)</author>
      <guid isPermaLink="false">2504.03641v2</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Sparsity-Aware Communication for Distributed Graph Neural Network Training</title>
      <link>http://arxiv.org/abs/2504.04673v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的Graph Neural Networks (GNNs)训练方法，通过开发稀疏感知算法和通信避免方法，显著提高了GNN训练的效率。&lt;h4&gt;背景&lt;/h4&gt;GNNs在图数据上学习嵌入和分类非常高效，但其训练过程中通信成本成为扩展的瓶颈。&lt;h4&gt;目的&lt;/h4&gt;旨在解决GNN训练中的通信瓶颈问题。&lt;h4&gt;方法&lt;/h4&gt;1. 开发稀疏感知算法，仅传输必要的矩阵元素；2. 利用图划分模型重新排序矩阵，大幅减少传输元素的数量；3. 使用定制分区模型解决通信负载不平衡问题；4. 与通信避免方法（1.5D并行SpMM）相结合，通过复制子矩阵减少通信。&lt;h4&gt;主要发现&lt;/h4&gt;通过这些方法，实现了高达14倍的性能提升，在某些实例中甚至将通信量减少到几乎为零，实现了相对于基于通信忽略SpMM的GNN框架的通信免费并行训练。&lt;h4&gt;结论&lt;/h4&gt;提出的稀疏感知算法和通信避免方法能够有效提升GNN训练的效率，特别是在大规模并行计算环境中。&lt;h4&gt;翻译&lt;/h4&gt;Graph神经网络（GNNs）是一种在图数据上学习嵌入和分类的计算高效方法。然而，GNN的训练具有低计算强度，使得通信成本成为扩展的瓶颈。稀疏矩阵与稠密矩阵乘法（SpMM）是GNN全图训练中的核心计算操作。先前的工作在并行化此操作时，主要关注无疏密感知算法，其中矩阵元素无论稀疏模式如何都会进行通信。这导致了一种可预测的通信模式，可以与计算重叠，并允许使用集体通信操作，但代价是浪费大量的带宽，通过传输不必要的数据。我们开发了稀疏感知算法，通过三种新颖的方法解决了GNN训练中的通信瓶颈。首先，我们只传输必要的矩阵元素。其次，我们利用图划分模型重新排序矩阵，大幅减少传输元素的数量。最后，我们使用定制的分区模型解决通信负载不平衡问题，最小化了总通信量和最大发送量。我们进一步将这些稀疏利用方法与通信避免方法（1.5D并行SpMM）相结合，其中子矩阵被复制以减少通信。我们探讨了这些组合优化的权衡，并在256个GPU上实现了高达14倍的性能提升，在某些实例中甚至将通信量减少到几乎为零，相对于基于通信忽略SpMM的流行GNN框架，实现了通信免费的并行训练。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are a computationally efficient method to learnembeddings and classifications on graph data. However, GNN training has lowcomputational intensity, making communication costs the bottleneck forscalability. Sparse-matrix dense-matrix multiplication (SpMM) is the corecomputational operation in full-graph training of GNNs. Previous workparallelizing this operation focused on sparsity-oblivious algorithms, wherematrix elements are communicated regardless of the sparsity pattern. This leadsto a predictable communication pattern that can be overlapped with computationand enables the use of collective communication operations at the expense ofwasting significant bandwidth by communicating unnecessary data. We developsparsity-aware algorithms that tackle the communication bottlenecks in GNNtraining with three novel approaches. First, we communicate only the necessarymatrix elements. Second, we utilize a graph partitioning model to reorder thematrix and drastically reduce the amount of communicated elements. Finally, weaddress the high load imbalance in communication with a tailored partitioningmodel, which minimizes both the total communication volume and the maximumsending volume. We further couple these sparsity-exploiting approaches with acommunication-avoiding approach (1.5D parallel SpMM) in which submatrices arereplicated to reduce communication. We explore the tradeoffs of these combinedoptimizations and show up to 14X improvement on 256 GPUs and on some instancesreducing communication to almost zero resulting in a communication-freeparallel training relative to a popular GNN framework based oncommunication-oblivious SpMM.</description>
      <author>example@mail.com (Ujjaini Mukhodopadhyay, Alok Tripathy, Oguz Selvitopi, Katherine Yelick, Aydin Buluc)</author>
      <guid isPermaLink="false">2504.04673v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Software Engineering of Cyber-Physical Systems: the Road Ahead</title>
      <link>http://arxiv.org/abs/2504.04630v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  1 figure, 11 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了将基础模型，特别是大型语言模型，应用于支持各种软件工程活动，包括编码和测试。特别关注了在支持网络物理系统（CPS）的软件工程中的应用，并指出当前研究的局限性。作者提出了一个研究路线图，用于将基础模型整合到CPS软件工程的各个阶段，并强调了软件工程界面临的关键研究机会和挑战。&lt;h4&gt;背景&lt;/h4&gt;基础模型，尤其是大型语言模型，在支持软件工程活动中的应用越来越广泛。在CPS软件工程中，这些模型的应用也在增长，但相关研究仍然有限。&lt;h4&gt;目的&lt;/h4&gt;提出将基础模型，尤其是利用不同数据模态（如图像、音频）和融合多种模态的模型，整合到CPS软件工程各个阶段的研究路线图。&lt;h4&gt;方法&lt;/h4&gt;无具体的研究方法描述。&lt;h4&gt;主要发现&lt;/h4&gt;除了大型语言模型外，其他基础模型，如视觉语言模型，在支持CPS软件工程方面具有巨大潜力。&lt;h4&gt;结论&lt;/h4&gt;软件工程界需要探索将不同类型的基础模型整合到CPS软件工程的各个阶段，并应对其中的研究机会和挑战。&lt;h4&gt;翻译&lt;/h4&gt;本文探讨了基础模型，尤其是大型语言模型，在支持各种软件工程活动中的应用，包括编码和测试。这些模型在支持网络物理系统（CPS）的软件工程中的应用也在增长。然而，这方面的研究还相对有限。作者认为，除了大型语言模型外，其他利用不同数据模态（如图像、音频）和多模态模型（融合多种模态）的基础模型，在处理多样化的数据类型时，对于支持CPS软件工程具有很大的潜力。为了解决这个问题，作者提出了一项研究路线图，用于将基础模型整合到CPS软件工程的各个阶段，并强调了软件工程界面临的关键研究机会和挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation Models (FMs), particularly Large Language Models (LLMs), areincreasingly used to support various software engineering activities (e.g.,coding and testing). Their applications in the software engineering ofCyber-Physical Systems (CPSs) are also growing. However, research in this arearemains limited. Moreover, existing studies have primarily focused on LLMs-onlyone type of FM-leaving ample opportunities to explore others, such asvision-language models. We argue that, in addition to LLMs, other FMs utilizingdifferent data modalities (e.g., images, audio) and multimodal models (whichintegrate multiple modalities) hold great potential for supporting CPS softwareengineering, given that these systems process diverse data types. To addressthis, we present a research roadmap for integrating FMs into various phases ofCPS software engineering, highlighting key research opportunities andchallenges for the software engineering community.</description>
      <author>example@mail.com (Chengjie Lu, Pablo Valle, Jiahui Wu, Erblin Isaku, Hassan Sartaj, Aitor Arrieta, Shaukat Ali)</author>
      <guid isPermaLink="false">2504.04630v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Graph Neural Networks for Particle Track Reconstruction</title>
      <link>http://arxiv.org/abs/2504.04670v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了针对高能物理中粒子轨迹重建问题的Exa.TrkX项目，该项目通过将粒子轨迹重建转化为图上的边缘分类问题，并使用图神经网络（GNN）来生成粒子轨迹，从而减轻计算负担。然而，基于GNN的方法存在内存限制，本研究通过改进Exa.TrkX流程，提高了重建的精度和召回率，并引入了性能优化，使得实现速度提高了2倍。&lt;h4&gt;背景&lt;/h4&gt;粒子轨迹重建是高能物理中的重要问题，对于研究亚原子粒子的性质至关重要。传统的轨迹重建算法在粒子数量增加时计算效率低下。&lt;h4&gt;目的&lt;/h4&gt;提高粒子轨迹重建的计算效率，并优化GNN训练过程。&lt;h4&gt;方法&lt;/h4&gt;1. 将粒子轨迹重建转化为图上的边缘分类问题，并使用GNN生成粒子轨迹。2. 对Exa.TrkX流程进行改进，使其能够在输入粒子图的样本上训练，并提高重建的精度和召回率。3. 引入GNN训练的性能优化，以适应改进后的Exa.TrkX流程。&lt;h4&gt;主要发现&lt;/h4&gt;改进后的Exa.TrkX流程能够处理更多的粒子，提高了重建的精度和召回率，并且通过性能优化实现了2倍的速度提升。&lt;h4&gt;结论&lt;/h4&gt;通过改进Exa.TrkX流程和引入性能优化，显著提高了粒子轨迹重建的计算效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：粒子轨迹重建是高能物理（HEP）中的一个重要问题，对于研究亚原子粒子的性质是必要的。传统的轨迹重建算法在加速器内粒子数量的增加时计算效率不高。为了减轻这种计算负担，Exa.TrkX项目引入了一个将粒子轨迹重建简化为图上的边缘分类的流程，并使用图神经网络（GNN）来生成粒子轨迹。然而，这种基于GNN的方法内存限制，跳过了超过GPU内存的图。我们引入了对Exa.TrkX流程的改进，以在输入粒子图的样本上进行训练，并表明这些改进可以推广到更高的精度和召回率。此外，我们将为GNN训练引入的性能优化应用于我们增强的Exa.TrkX流程。这些优化提供了相对于我们基于PyTorch Geometric的基线实现2倍的速度提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Particle track reconstruction is an important problem in high-energy physics(HEP), necessary to study properties of subatomic particles. Traditional trackreconstruction algorithms scale poorly with the number of particles within theaccelerator. The Exa.TrkX project, to alleviate this computational burden,introduces a pipeline that reduces particle track reconstruction to edgeclassification on a graph, and uses graph neural networks (GNNs) to produceparticle tracks. However, this GNN-based approach is memory-prohibitive andskips graphs that would exceed GPU memory. We introduce improvements to theExa.TrkX pipeline to train on samples of input particle graphs, and show thatthese improvements generalize to higher precision and recall. In addition, weadapt performance optimizations, introduced for GNN training, to fit ouraugmented Exa.TrkX pipeline. These optimizations provide a $2\times$ speedupover our baseline implementation in PyTorch Geometric.</description>
      <author>example@mail.com (Alok Tripathy, Alina Lazar, Xiangyang Ju, Paolo Calafiura, Katherine Yelick, Aydin Buluc)</author>
      <guid isPermaLink="false">2504.04670v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>PIORF: Physics-Informed Ollivier-Ricci Flow for Long-Range Interactions in Mesh Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.04052v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025. Youn-Yeol Yu and Jeongwhan Choi contributed  equally to this work&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的物理信息Ollivier-Ricci流（PIORF）方法，用于解决无结构网格上流体流动的长期依赖性问题，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;数据驱动的模拟器在无结构网格上模拟物理系统时受到长期依赖性的挑战，特别是在细化网格区域，这被称为'过度挤压'问题，阻碍了信息传播。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的重连方法，结合物理相关性和图拓扑结构，以解决流体流动中的长期依赖性问题。&lt;h4&gt;方法&lt;/h4&gt;PIORF方法利用Ollivier-Ricci曲率（ORC）识别瓶颈区域，并连接这些区域与高速度梯度节点，以实现长距离相互作用并减轻过度挤压。&lt;h4&gt;主要发现&lt;/h4&gt;PIORF在重连边方面计算效率高，可以扩展到更大规模的模拟，并且在三个流体动力学基准数据集上的实验结果显示，PIORF在性能上优于基线模型和现有的重连方法，最高提高了26.2%。&lt;h4&gt;结论&lt;/h4&gt;PIORF方法在处理流体流动中的长期依赖性方面是一种有效且高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, data-driven simulators based on graph neural networks have gainedattention in modeling physical systems on unstructured meshes. However, theystruggle with long-range dependencies in fluid flows, particularly in refinedmesh regions. This challenge, known as the 'over-squashing' problem, hindersinformation propagation. While existing graph rewiring methods address thisissue to some extent, they only consider graph topology, overlooking theunderlying physical phenomena. We propose Physics-Informed Ollivier-Ricci Flow(PIORF), a novel rewiring method that combines physical correlations with graphtopology. PIORF uses Ollivier-Ricci curvature (ORC) to identify bottleneckregions and connects these areas with nodes in high-velocity gradient nodes,enabling long-range interactions and mitigating over-squashing. Our approach iscomputationally efficient in rewiring edges and can scale to largersimulations. Experimental results on 3 fluid dynamics benchmark datasets showthat PIORF consistently outperforms baseline models and existing rewiringmethods, achieving up to 26.2 improvement.</description>
      <author>example@mail.com (Youn-Yeol Yu, Jeongwhan Choi, Jaehyeon Park, Kookjin Lee, Noseong Park)</author>
      <guid isPermaLink="false">2504.04052v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>COHESION: Composite Graph Convolutional Network with Dual-Stage Fusion for Multimodal Recommendation</title>
      <link>http://arxiv.org/abs/2504.04452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CIKM 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为COHESION的多模态推荐方法，该方法通过改进模态融合和表示学习过程来提升推荐准确度。&lt;h4&gt;背景&lt;/h4&gt;多模态推荐利用多种模态信息来应对数据稀疏性和提高推荐准确度，其中模态融合和表示学习是关键过程。&lt;h4&gt;目的&lt;/h4&gt;揭示模态融合和表示学习之间的互补性，并提高推荐系统的性能。&lt;h4&gt;方法&lt;/h4&gt;COHESION采用双阶段融合策略，在早期使用ID嵌入精炼所有模态，在晚期融合它们的表示。此外，还引入了复合图卷积网络来提取用户和物品之间的异构和同构潜在关系，并提出了一种新颖的自适应优化方法以确保跨模态的平衡和合理表示。&lt;h4&gt;主要发现&lt;/h4&gt;COHESION在处理无关信息、改善表示质量以及增强模态融合等方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;在三个广泛使用的数据集上的实验表明，COHESION在多种基线方法中具有显著的优越性。&lt;h4&gt;翻译&lt;/h4&gt;最近在多模态推荐领域的研究，利用多样化的模态信息来处理数据稀疏性并提升推荐准确性，引起了广泛关注。多模态推荐中的两个关键过程是模态融合和表示学习。以往在模态融合方面的方法通常在早期或晚期采用简单的注意力或预定义策略，未能有效处理模态间的无关信息。在表示学习方面，先前研究已经构建了包含用户-物品、用户-用户和物品-物品关系的异构和同构图结构，以更好地捕捉用户兴趣和物品特征。在以前的工作中，模态融合和表示学习被视为两个独立的过程。在本文中，我们揭示了这两个过程是互补的，并且可以相互支持。具体来说，强大的表示学习增强了模态融合，而有效的融合改善了表示质量。基于这两个过程，我们引入了一种名为COHESION的多模态推荐方法，该方法引入了双阶段融合策略以减少无关信息的影响，在早期使用ID嵌入精炼所有模态，在晚期融合它们的表示。此外，它还提出了一种复合图卷积网络，利用用户-物品、用户-用户和物品-物品图来提取用户和物品内的异构和同构潜在关系。此外，它还引入了一种新颖的自适应优化方法，以确保跨模态的平衡和合理表示。在三个广泛使用的数据集上的大量实验表明，COHESION在各种基线方法中表现出显著的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent works in multimodal recommendations, which leverage diverse modalinformation to address data sparsity and enhance recommendation accuracy, havegarnered considerable interest. Two key processes in multimodal recommendationsare modality fusion and representation learning. Previous approaches inmodality fusion often employ simplistic attentive or pre-defined strategies atearly or late stages, failing to effectively handle irrelevant informationamong modalities. In representation learning, prior research has constructedheterogeneous and homogeneous graph structures encapsulating user-item,user-user, and item-item relationships to better capture user interests anditem profiles. Modality fusion and representation learning were considered astwo independent processes in previous work. In this paper, we reveal that thesetwo processes are complementary and can support each other. Specifically,powerful representation learning enhances modality fusion, while effectivefusion improves representation quality. Stemming from these two processes, weintroduce a COmposite grapH convolutional nEtwork with dual-stage fuSION forthe multimodal recommendation, named COHESION. Specifically, it introduces adual-stage fusion strategy to reduce the impact of irrelevant information,refining all modalities using ID embedding in the early stage and fusing theirrepresentations at the late stage. It also proposes a composite graphconvolutional network that utilizes user-item, user-user, and item-item graphsto extract heterogeneous and homogeneous latent relationships within users anditems. Besides, it introduces a novel adaptive optimization to ensure balancedand reasonable representations across modalities. Extensive experiments onthree widely used datasets demonstrate the significant superiority of COHESIONover various competitive baselines.</description>
      <author>example@mail.com (Jinfeng Xu, Zheyu Chen, Wei Wang, Xiping Hu, Sang-Wook Kim, Edith C. H. Ngai)</author>
      <guid isPermaLink="false">2504.04452v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>TGraphX: Tensor-Aware Graph Neural Network for Multi-Dimensional Feature Learning</title>
      <link>http://arxiv.org/abs/2504.03953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to arXiv. Code repository:  https://github.com/arashsajjadi/TGraphX |||  https://git.cs.usask.ca/arash/tgraphx&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TGraphX通过统一卷积神经网络（CNNs）和图神经网络（GNNs）来增强视觉推理任务，实现了对空间特征提取和关系推理的桥梁。&lt;h4&gt;背景&lt;/h4&gt;传统的CNN擅长提取图像的丰富空间特征，但缺乏建模物体间关系的内在能力；而传统的GNN通常依赖于平展的节点特征，从而丢弃了重要的空间细节。&lt;h4&gt;目的&lt;/h4&gt;提出TGraphX，以克服上述限制，并提升视觉推理任务的表现。&lt;h4&gt;方法&lt;/h4&gt;TGraphX使用CNN生成多维节点特征（如(3*128*128)张量），保留局部空间语义；这些空间感知的节点参与图计算，使用1*1卷积进行消息传递，融合相邻特征的同时保持其结构；此外，使用具有残差连接的深度CNN聚合器来稳健地细化融合的消息。&lt;h4&gt;主要发现&lt;/h4&gt;TGraphX不仅连接了空间特征提取和关系推理的差距，还在物体检测细化集合推理方面表现出显著改进。&lt;h4&gt;结论&lt;/h4&gt;TGraphX为视觉推理任务提供了一种新的方法，显著提高了相关任务的表现。&lt;h4&gt;翻译&lt;/h4&gt;TGraphX提出了一种新的深度学习范式，通过统一卷积神经网络（CNNs）和图神经网络（GNNs）来增强视觉推理任务。传统的CNN在提取图像的丰富空间特征方面表现出色，但缺乏建模物体间关系的内在能力。相反，传统的GNN通常依赖于平展的节点特征，从而丢弃了重要的空间细节。TGraphX通过使用CNN生成多维节点特征（例如（3*128*128）张量）来克服这些限制，这些节点特征保留了局部空间语义。这些空间感知的节点参与一个图，在该图中使用1*1卷积进行消息传递，融合相邻特征的同时保持其结构。此外，使用具有残差连接的深度CNN聚合器来稳健地细化融合的消息，确保稳定的梯度流和端到端的可训练性。我们的方法不仅弥合了空间特征提取和关系推理之间的差距，还在物体检测细化集合推理方面展示了显著的改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; TGraphX presents a novel paradigm in deep learning by unifying convolutionalneural networks (CNNs) with graph neural networks (GNNs) to enhance visualreasoning tasks. Traditional CNNs excel at extracting rich spatial featuresfrom images but lack the inherent capability to model inter-objectrelationships. Conversely, conventional GNNs typically rely on flattened nodefeatures, thereby discarding vital spatial details. TGraphX overcomes theselimitations by employing CNNs to generate multi-dimensional node features(e.g., (3*128*128) tensors) that preserve local spatial semantics. Thesespatially aware nodes participate in a graph where message passing is performedusing 1*1 convolutions, which fuse adjacent features while maintaining theirstructure. Furthermore, a deep CNN aggregator with residual connections is usedto robustly refine the fused messages, ensuring stable gradient flow andend-to-end trainability. Our approach not only bridges the gap between spatialfeature extraction and relational reasoning but also demonstrates significantimprovements in object detection refinement and ensemble reasoning.</description>
      <author>example@mail.com (Arash Sajjadi, Mark Eramian)</author>
      <guid isPermaLink="false">2504.03953v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>MInCo: Mitigating Information Conflicts in Distracted Visual Model-based Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2504.04164v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MInCo的新算法，用于解决视觉MBRL中的信息冲突问题，通过使用负样本免费的对比学习，帮助学习不变表示和鲁棒策略，即使在存在任务无关的视觉干扰时也能保持性能。&lt;h4&gt;背景&lt;/h4&gt;现有的基于视觉模型的强化学习（MBRL）算法在观察重建方面往往存在信息冲突，这导致难以学习紧凑的表示，从而降低了策略的鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;揭示当前视觉MBRL算法中信息冲突的根源，并提出一种新的算法来缓解信息冲突。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的算法MInCo，通过负样本免费的对比学习来缓解信息冲突，并引入时间变化的重新加权来引导学习偏向动态建模。&lt;h4&gt;主要发现&lt;/h4&gt;信息冲突源于视觉表示学习和潜在动态建模，通过信息论视角分析得出。&lt;h4&gt;结论&lt;/h4&gt;MInCo在机器人控制任务中表现出色，能够学习对抗背景噪声的不变表示，并且优于现有的视觉MBRL方法。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Existing visual model-based reinforcement learning (MBRL) algorithms with observation reconstruction often suffer from information conflicts, making it difficult to learn compact representations and hence result in less robust policies, especially in the presence of task-irrelevant visual distractions. In this paper, we first reveal that the information conflicts in current visual MBRL algorithms stem from visual representation learning and latent dynamics modeling with an information-theoretic perspective. Based on this finding, we present a new algorithm to resolve information conflicts for visual MBRL, named MInCo, which mitigates information conflicts by leveraging negative-free contrastive learning, aiding in learning invariant representation and robust policies despite noisy observations. To prevent the dominance of visual representation learning, we introduce time-varying reweighting to bias the learning towards dynamics modeling as training proceeds. We evaluate our method on several robotic control tasks with dynamic background distractions. Our experiments demonstrate that MInCo learns invariant representations against background noise and consistently outperforms current state-of-the-art visual MBRL methods. Code is available at https://github.com/ShiguangSun/minco.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing visual model-based reinforcement learning (MBRL) algorithms withobservation reconstruction often suffer from information conflicts, making itdifficult to learn compact representations and hence result in less robustpolicies, especially in the presence of task-irrelevant visual distractions. Inthis paper, we first reveal that the information conflicts in current visualMBRL algorithms stem from visual representation learning and latent dynamicsmodeling with an information-theoretic perspective. Based on this finding, wepresent a new algorithm to resolve information conflicts for visual MBRL, namedMInCo, which mitigates information conflicts by leveraging negative-freecontrastive learning, aiding in learning invariant representation and robustpolicies despite noisy observations. To prevent the dominance of visualrepresentation learning, we introduce time-varying reweighting to bias thelearning towards dynamics modeling as training proceeds. We evaluate our methodon several robotic control tasks with dynamic background distractions. Ourexperiments demonstrate that MInCo learns invariant representations againstbackground noise and consistently outperforms current state-of-the-art visualMBRL methods. Code is available at https://github.com/ShiguangSun/minco.</description>
      <author>example@mail.com (Shiguang Sun, Hanbo Zhang, Zeyang Liu, Xinrui Yang, Lipeng Wan, Bing Yan, Xingyu Chen, Xuguang Lan)</author>
      <guid isPermaLink="false">2504.04164v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>NuScenes-SpatialQA: A Spatial Understanding and Reasoning Benchmark for Vision-Language Models in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2504.03164v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Vision-Language Models (VLMs) 在自动驾驶任务中有很大的潜力，但其在空间理解和推理方面的能力仍存在显著局限性。&lt;h4&gt;背景&lt;/h4&gt;目前没有系统性地评估VLMs在驾驶场景中空间推理能力的基准。&lt;h4&gt;目的&lt;/h4&gt;提出NuScenes-SpatialQA基准，专门用于评估VLMs在自动驾驶中的空间理解和推理能力。&lt;h4&gt;方法&lt;/h4&gt;在NuScenes数据集的基础上，通过自动化的3D场景图生成流程和QA生成流程构建基准。&lt;h4&gt;主要发现&lt;/h4&gt;空间增强型VLM在定性QA中表现优于其他模型，但在定量QA中不具备竞争力。&lt;h4&gt;结论&lt;/h4&gt;VLMs在空间理解和推理方面仍然面临重大挑战。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Recent advancements in Vision-Language Models (VLMs) have demonstrated strong potential for autonomous driving tasks. However, their spatial understanding and reasoning-key capabilities for autonomous driving-still exhibit significant limitations. Notably, none of the existing benchmarks systematically evaluate VLMs' spatial reasoning capabilities in driving scenarios. To fill this gap, we propose NuScenes-SpatialQA, the first large-scale ground-truth-based Question-Answer (QA) benchmark specifically designed to evaluate the spatial understanding and reasoning capabilities of VLMs in autonomous driving. Built upon the NuScenes dataset, the benchmark is constructed through an automated 3D scene graph generation pipeline and a QA generation pipeline. The benchmark systematically evaluates VLMs' performance in both spatial understanding and reasoning across multiple dimensions. Using this benchmark, we conduct extensive experiments on diverse VLMs, including both general and spatial-enhanced models, providing the first comprehensive evaluation of their spatial capabilities in autonomous driving. Surprisingly, the experimental results show that the spatial-enhanced VLM outperforms in qualitative QA but does not demonstrate competitiveness in quantitative QA. In general, VLMs still face considerable challenges in spatial understanding and reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Vision-Language Models (VLMs) have demonstrated strongpotential for autonomous driving tasks. However, their spatial understandingand reasoning-key capabilities for autonomous driving-still exhibit significantlimitations. Notably, none of the existing benchmarks systematically evaluateVLMs' spatial reasoning capabilities in driving scenarios. To fill this gap, wepropose NuScenes-SpatialQA, the first large-scale ground-truth-basedQuestion-Answer (QA) benchmark specifically designed to evaluate the spatialunderstanding and reasoning capabilities of VLMs in autonomous driving. Builtupon the NuScenes dataset, the benchmark is constructed through an automated 3Dscene graph generation pipeline and a QA generation pipeline. The benchmarksystematically evaluates VLMs' performance in both spatial understanding andreasoning across multiple dimensions. Using this benchmark, we conductextensive experiments on diverse VLMs, including both general andspatial-enhanced models, providing the first comprehensive evaluation of theirspatial capabilities in autonomous driving. Surprisingly, the experimentalresults show that the spatial-enhanced VLM outperforms in qualitative QA butdoes not demonstrate competitiveness in quantitative QA. In general, VLMs stillface considerable challenges in spatial understanding and reasoning.</description>
      <author>example@mail.com (Kexin Tian, Jingrui Mao, Yunlong Zhang, Jiwan Jiang, Yang Zhou, Zhengzhong Tu)</author>
      <guid isPermaLink="false">2504.03164v2</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Variational Self-Supervised Learning</title>
      <link>http://arxiv.org/abs/2504.04318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to NeurIPS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为VSSL（变分自监督学习）的新框架，该框架结合了变分推理和自监督学习，以实现高效的、无需解码器的表示学习。&lt;h4&gt;背景&lt;/h4&gt;传统的变分自编码器（VAEs）依赖于解码器进行输入重建，而本文提出的方法VSSL则采用不同的策略。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的学习方法，能够高效地学习数据表示，同时避免使用解码器。&lt;h4&gt;方法&lt;/h4&gt;VSSL通过耦合两个具有高斯输出的编码器，并使用动量更新的教师网络来定义一个动态的、数据依赖的前验分布。学生编码器从增强的视角生成近似的后验分布。在ELBO中的重建项被替换为跨视图去噪目标，以保持高斯KL散度的解析可处理性。此外，还引入了基于余弦的KL和似然项的公式，以增强高维潜在空间中的语义对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在CIFAR-10、CIFAR-100和ImageNet-100上的实验表明，VSSL在性能上与BYOL和MoCo V3等领先的自监督方法相当或更优。&lt;h4&gt;结论&lt;/h4&gt;VSSL提供了一种可扩展的、基于概率的方法来学习可迁移的表示，而不需要生成重建，从而弥合了变分建模和现代自监督技术之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为VSSL（变分自监督学习）的新框架，该框架结合了变分推理与自监督学习，以实现高效的、无需解码器的表示学习。与依赖于解码器进行输入重建的传统变分自编码器（VAEs）不同，VSSL对称地耦合了两个具有高斯输出的编码器。一个动量更新的教师网络定义了一个动态的、数据依赖的前验，而学生编码器从增强的视角生成近似的后验。ELBO中的重建项被替换为跨视图去噪目标，以保持高斯KL散度的解析可处理性。我们进一步引入了基于余弦的KL和似然项的公式，以增强高维潜在空间中的语义对齐。在CIFAR-10、CIFAR-100和ImageNet-100上的实验表明，VSSL在性能上与BYOL和MoCo V3等领先的自监督方法相当或更优。VSSL提供了一种可扩展的、基于概率的方法来学习可迁移的表示，而不需要生成重建，从而弥合了变分建模和现代自监督技术之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Variational Self-Supervised Learning (VSSL), a novel frameworkthat combines variational inference with self-supervised learning to enableefficient, decoder-free representation learning. Unlike traditional VAEs thatrely on input reconstruction via a decoder, VSSL symmetrically couples twoencoders with Gaussian outputs. A momentum-updated teacher network defines adynamic, data-dependent prior, while the student encoder produces anapproximate posterior from augmented views. The reconstruction term in the ELBOis replaced with a cross-view denoising objective, preserving the analyticaltractability of Gaussian KL divergence. We further introduce cosine-basedformulations of KL and log-likelihood terms to enhance semantic alignment inhigh-dimensional latent spaces. Experiments on CIFAR-10, CIFAR-100, andImageNet-100 show that VSSL achieves competitive or superior performance toleading self-supervised methods, including BYOL and MoCo V3. VSSL offers ascalable, probabilistically grounded approach to learning transferablerepresentations without generative reconstruction, bridging the gap betweenvariational modeling and modern self-supervised techniques.</description>
      <author>example@mail.com (Mehmet Can Yavuz, Berrin Yanikoglu)</author>
      <guid isPermaLink="false">2504.04318v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Directional Sign Loss: A Topology-Preserving Loss Function that Approximates the Sign of Finite Differences</title>
      <link>http://arxiv.org/abs/2504.04202v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为方向符号损失（DSL）的新损失函数，用于在表示学习中保持拓扑特征，特别是在拓扑敏感数据中。&lt;h4&gt;背景&lt;/h4&gt;保持学习到的潜在空间中的关键拓扑特征是表示学习中的一个基本挑战，尤其是对于拓扑敏感数据。&lt;h4&gt;目的&lt;/h4&gt;DSL旨在通过惩罚输入和重建数据之间关键点的差异，鼓励自动编码器和其他可学习的压缩器保留原始数据的拓扑特征。&lt;h4&gt;方法&lt;/h4&gt;本文介绍了DSL的数学公式、复杂度分析和实际实现，并将其行为与不可微的对应物和其他拓扑度量进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;在单维、二维和三维数据上的实验表明，将DSL与传统损失函数相结合比单独使用传统损失函数更有效地保持拓扑特征。此外，DSL作为常见拓扑度量的可微、高效代理，使其能够在基于梯度的优化框架中使用。&lt;h4&gt;结论&lt;/h4&gt;DSL是一种有效的工具，可以帮助在表示学习中保持拓扑特征，尤其是在处理拓扑敏感数据时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Preserving critical topological features in learned latent spaces is afundamental challenge in representation learning, particularly fortopology-sensitive data. This paper introduces directional sign loss (DSL), anovel loss function that approximates the number of mismatches in the signs offinite differences between corresponding elements of two arrays. By penalizingdiscrepancies in critical points between input and reconstructed data, DSLencourages autoencoders and other learnable compressors to retain thetopological features of the original data. We present the mathematicalformulation, complexity analysis, and practical implementation of DSL,comparing its behavior to its non-differentiable counterpart and to othertopological measures. Experiments on one-, two-, and three-dimensional datashow that combining DSL with traditional loss functions preserves topologicalfeatures more effectively than traditional losses alone. Moreover, DSL servesas a differentiable, efficient proxy for common topology-based metrics,enabling its use in gradient-based optimization frameworks.</description>
      <author>example@mail.com (Harvey Dam, Tripti Agarwal, Ganesh Gopalakrishnan)</author>
      <guid isPermaLink="false">2504.04202v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Enhance Then Search: An Augmentation-Search Strategy with Foundation Models for Cross-Domain Few-Shot Object Detection</title>
      <link>http://arxiv.org/abs/2504.04517v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究展示了在大量数据集上预训练的基础模型，如GroundingDINO和LAE-DINO，在跨域小样本目标检测（CD-FSOD）任务上的出色表现，并介绍了通过图像数据增强技术和基于网格的子域搜索策略增强模型性能的方法。&lt;h4&gt;背景&lt;/h4&gt;大量数据集预训练的基础模型在跨域小样本目标检测任务中表现良好。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过数据增强和子域搜索策略提升基础模型在CD-FSOD任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;通过严格的小样本训练，采用图像数据增强方法和网格化的子域搜索策略，有效地在广阔的域空间中寻找最优子域。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法促进了小样本目标检测的效率，并提供了从基础模型中高效搜索最优参数配置的解决CD-FSOD问题的方法。&lt;h4&gt;结论&lt;/h4&gt;研究显著推动了视觉-语言模型在数据稀缺环境中的实际部署，为优化其跨域泛化能力提供了关键见解，而无需劳动密集型重新训练。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Foundation models pretrained on extensive datasets, such as GroundingDINO and LAE-DINO, have performed remarkably in the cross-domain few-shot object detection (CD-FSOD) task. Through rigorous few-shot training, we found that the integration of image-based data augmentation techniques and grid-based sub-domain search strategy significantly enhances the performance of these foundation models. Building upon GroundingDINO, we employed several widely used image augmentation methods and established optimization objectives to effectively navigate the expansive domain space in search of optimal sub-domains. This approach facilitates efficient few-shot object detection and introduces an approach to solving the CD-FSOD problem by efficiently searching for the optimal parameter configuration from the foundation model. Our findings substantially advance the practical deployment of vision-language models in data-scarce environments, offering critical insights into optimizing their cross-domain generalization capabilities without labor-intensive retraining. Code is available at https://github.com/jaychempan/ETS.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/jaychempan/ETS&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models pretrained on extensive datasets, such as GroundingDINO andLAE-DINO, have performed remarkably in the cross-domain few-shot objectdetection (CD-FSOD) task. Through rigorous few-shot training, we found that theintegration of image-based data augmentation techniques and grid-basedsub-domain search strategy significantly enhances the performance of thesefoundation models. Building upon GroundingDINO, we employed several widely usedimage augmentation methods and established optimization objectives toeffectively navigate the expansive domain space in search of optimalsub-domains. This approach facilitates efficient few-shot object detection andintroduces an approach to solving the CD-FSOD problem by efficiently searchingfor the optimal parameter configuration from the foundation model. Our findingssubstantially advance the practical deployment of vision-language models indata-scarce environments, offering critical insights into optimizing theircross-domain generalization capabilities without labor-intensive retraining.Code is available at https://github.com/jaychempan/ETS.</description>
      <author>example@mail.com (Jiancheng Pan, Yanxing Liu, Xiao He, Long Peng, Jiahao Li, Yuze Sun, Xiaomeng Huang)</author>
      <guid isPermaLink="false">2504.04517v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>QE-RAG: A Robust Retrieval-Augmented Generation Benchmark for Query Entry Errors</title>
      <link>http://arxiv.org/abs/2504.04062v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为QE-RAG的鲁棒RAG基准，旨在评估RAG方法在应对查询输入错误时的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管RAG方法在提高大型语言模型（LLM）的事实准确性方面得到了广泛应用，但现有基准假设用于检索的用户查询是正确的，而现实中的查询输入错误很常见。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在探索查询输入错误对RAG方法的影响，并提出改进方法。&lt;h4&gt;方法&lt;/h4&gt;作者通过在六个常用数据集中注入三种常见的查询输入错误，以20%和40%的比率模拟现实场景，分析错误对LLM输出的影响，并提出基于对比学习的鲁棒检索器训练方法和检索增强的查询纠正方法。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，现有的RAG方法对查询输入错误具有较差的鲁棒性，而提出的方法显著提高了RAG处理查询输入错误的鲁棒性，并且与现有RAG方法兼容，进一步提高了其鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和基准对于评估和改进RAG方法在现实世界中的表现具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;摘要：检索增强的生成（RAG）已成为提高大型语言模型（LLMs）事实准确性的广泛采用的方法。尽管当前基准从各种角度评估RAG方法的表现，但它们共享一个共同的假设，即用于检索的用户查询是无误的。然而，在用户与LLMs之间的现实交互中，查询输入错误，如键盘邻近错误、视觉相似性错误和拼写错误，很常见。这些错误对当前RAG方法的影响尚未得到充分探索。为了填补这一空白，我们提出了QE-RAG，这是第一个针对查询输入错误设计的鲁棒RAG基准。我们通过在随机选择的用户查询中注入三种常见的查询输入错误，以20%和40%的比率增强六个广泛使用的数据集，模拟典型用户行为。我们分析了这些错误对LLM输出的影响，发现损坏的查询会降低模型性能，这可以通过查询纠正和训练鲁棒的检索器来缓解。基于这些见解，我们提出了一种基于对比学习的鲁棒检索器训练方法和一个检索增强的查询纠正方法。广泛的领域内和跨领域实验表明：（1）最先进的RAG方法包括顺序、分支和迭代方法，对查询输入错误具有较差的鲁棒性；（2）我们的方法在处理查询输入错误时显著提高了RAG的鲁棒性，并且与现有RAG方法兼容，进一步提高了它们的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retriever-augmented generation (RAG) has become a widely adopted approach forenhancing the factual accuracy of large language models (LLMs). While currentbenchmarks evaluate the performance of RAG methods from various perspectives,they share a common assumption that user queries used for retrieval areerror-free. However, in real-world interactions between users and LLMs, queryentry errors such as keyboard proximity errors, visual similarity errors, andspelling errors are frequent. The impact of these errors on current RAG methodsagainst such errors remains largely unexplored. To bridge this gap, we proposeQE-RAG, the first robust RAG benchmark designed specifically to evaluateperformance against query entry errors. We augment six widely used datasets byinjecting three common types of query entry errors into randomly selected userqueries at rates of 20\% and 40\%, simulating typical user behavior inreal-world scenarios. We analyze the impact of these errors on LLM outputs andfind that corrupted queries degrade model performance, which can be mitigatedthrough query correction and training a robust retriever for retrievingrelevant documents. Based on these insights, we propose a contrastivelearning-based robust retriever training method and a retrieval-augmented querycorrection method. Extensive in-domain and cross-domain experiments revealthat: (1) state-of-the-art RAG methods including sequential, branching, anditerative methods, exhibit poor robustness to query entry errors; (2) ourmethod significantly enhances the robustness of RAG when handling query entryerrors and it's compatible with existing RAG methods, further improving theirrobustness.</description>
      <author>example@mail.com (Kepu Zhang, Zhongxiang Sun, Weijie Yu, Xiaoxue Zang, Kai Zheng, Yang Song, Han Li, Jun Xu)</author>
      <guid isPermaLink="false">2504.04062v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>MedM-VL: What Makes a Good Medical LVLM?</title>
      <link>http://arxiv.org/abs/2504.04323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于LLaVA框架的医学LVLMs的多种架构设计，构建了针对2D和3D模态的模型，旨在支持通用和特定领域的医学任务，并开发了MedM-VL代码库，发布了两个LVLM变体。&lt;h4&gt;背景&lt;/h4&gt;随着深度学习的发展，医学图像分析从单一任务扩展到更复杂的多模态任务，如医学视觉问答和报告生成。传统的浅层和特定任务模型在处理临床实践中的复杂性和可扩展性方面越来越有限。&lt;h4&gt;目的&lt;/h4&gt;研究医学LVLMs的架构设计，构建模型以支持通用和特定领域的医学任务，并开发可复现和可扩展的代码库。&lt;h4&gt;方法&lt;/h4&gt;基于LLaVA框架，构建了针对2D和3D模态的模型，并开发了MedM-VL代码库，提供了两个LVLM变体：MedM-VL-2D和MedM-VL-CT-Chest。&lt;h4&gt;主要发现&lt;/h4&gt;提出了基于LLaVA框架的医学LVLMs的多种架构设计，并构建了支持2D和3D模态的模型，这些模型可以作为有效的基础模型。&lt;h4&gt;结论&lt;/h4&gt;医学LVLMs为处理复杂的视觉语言任务提供了统一的解决方案，MedM-VL代码库和模型为医学图像分析提供了可复现和可扩展的工具。&lt;h4&gt;翻译&lt;/h4&gt;Medical image analysis is a fundamental component. As deep learning progresses, the focus has shifted from single-task applications, such as classification and segmentation, to more complex multimodal tasks, including medical visual question answering and report generation. Traditional shallow and task-specific models are increasingly limited in addressing the complexity and scalability required in clinical practice. The emergence of large language models (LLMs) has driven the development of medical Large Vision-Language Models (LVLMs), offering a unified solution for diverse vision-language tasks. In this study, we investigate various architectural designs for medical LVLMs based on the widely adopted LLaVA framework, which follows an encoder-connector-LLM paradigm. We construct two distinct models targeting 2D and 3D modalities, respectively. These models are designed to support both general-purpose medical tasks and domain-specific fine-tuning, thereby serving as effective foundation models. To facilitate reproducibility and further research, we develop a modular and extensible codebase, MedM-VL, and release two LVLM variants: MedM-VL-2D for 2D medical image analysis and MedM-VL-CT-Chest for 3D CT-based applications. The code and models are available at: https://github.com/MSIIP/MedM-VL&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image analysis is a fundamental component. As deep learningprogresses, the focus has shifted from single-task applications, such asclassification and segmentation, to more complex multimodal tasks, includingmedical visual question answering and report generation. Traditional shallowand task-specific models are increasingly limited in addressing the complexityand scalability required in clinical practice. The emergence of large languagemodels (LLMs) has driven the development of medical Large Vision-LanguageModels (LVLMs), offering a unified solution for diverse vision-language tasks.In this study, we investigate various architectural designs for medical LVLMsbased on the widely adopted LLaVA framework, which follows anencoder-connector-LLM paradigm. We construct two distinct models targeting 2Dand 3D modalities, respectively. These models are designed to support bothgeneral-purpose medical tasks and domain-specific fine-tuning, thereby servingas effective foundation models. To facilitate reproducibility and furtherresearch, we develop a modular and extensible codebase, MedM-VL, and releasetwo LVLM variants: MedM-VL-2D for 2D medical image analysis andMedM-VL-CT-Chest for 3D CT-based applications. The code and models areavailable at: https://github.com/MSIIP/MedM-VL</description>
      <author>example@mail.com (Yiming Shi, Shaoshuai Yang, Xun Zhu, Haoyu Wang, Miao Li, Ji Wu)</author>
      <guid isPermaLink="false">2504.04323v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive and Variational Approaches in Self-Supervised Learning for Complex Data Mining</title>
      <link>http://arxiv.org/abs/2504.04032v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于自监督学习的算法，通过实验验证了其在复杂数据挖掘任务中的有效性。&lt;h4&gt;背景&lt;/h4&gt;复杂数据挖掘在许多领域具有广泛的应用价值，特别是在无标签数据的特征提取和分类任务中。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种算法，并通过实验验证其在复杂数据挖掘任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;论文提出了基于自监督学习的算法，并通过实验验证了其效果。实验中使用了AdamW优化器和0.002的学习率，并通过消融实验分析了各个模块的贡献。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，AdamW优化器和0.002学习率的组合在所有评估指标中表现最佳，自适应优化方法可以提高模型在复杂数据挖掘任务中的性能。对比学习、变分模块和数据增强策略在模型的泛化能力和鲁棒性方面发挥了关键作用。&lt;h4&gt;结论&lt;/h4&gt;该方法在训练过程中能够稳定收敛，有效避免严重过拟合，对不同数据集具有较强的适应性，能够有效地从无标签数据中提取高质量特征，并提高分类准确率。在复杂数据环境中，该方法仍能保持高检测精度，证明了其在复杂数据挖掘中的适用性。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is summarized as follows: This paper proposes an algorithm based on self-supervised learning and verifies its effectiveness through experiments. The study found that the combination of AdamW optimizer and 0.002 learning rate performs best in all evaluation indicators, indicating that the adaptive optimization method can improve the performance of the model in complex data mining tasks. In addition, the ablation experiment further analyzed the contribution of each module. The results show that contrastive learning, variational modules, and data augmentation strategies play a key role in the generalization ability and robustness of the model. Through the convergence curve analysis of the loss function, the experiment verifies that the method can converge stably during the training process and effectively avoid serious overfitting. Further experimental results show that the model has strong adaptability on different data sets, can effectively extract high-quality features from unlabeled data, and improves classification accuracy. At the same time, under different data distribution conditions, the method can still maintain high detection accuracy, proving its applicability in complex data environments. This study analyzed the role of self-supervised learning methods in complex data mining through systematic experiments and verified its advantages in improving feature extraction quality, optimizing classification performance, and enhancing model stability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complex data mining has wide application value in many fields, especially inthe feature extraction and classification tasks of unlabeled data. This paperproposes an algorithm based on self-supervised learning and verifies itseffectiveness through experiments. The study found that in terms of theselection of optimizer and learning rate, the combination of AdamW optimizerand 0.002 learning rate performed best in all evaluation indicators, indicatingthat the adaptive optimization method can improve the performance of the modelin complex data mining tasks. In addition, the ablation experiment furtheranalyzed the contribution of each module. The results show that contrastivelearning, variational modules, and data augmentation strategies play a key rolein the generalization ability and robustness of the model. Through theconvergence curve analysis of the loss function, the experiment verifies thatthe method can converge stably during the training process and effectivelyavoid serious overfitting. Further experimental results show that the model hasstrong adaptability on different data sets, can effectively extracthigh-quality features from unlabeled data, and improves classificationaccuracy. At the same time, under different data distribution conditions, themethod can still maintain high detection accuracy, proving its applicability incomplex data environments. This study analyzed the role of self-supervisedlearning methods in complex data mining through systematic experiments andverified its advantages in improving feature extraction quality, optimizingclassification performance, and enhancing model stability</description>
      <author>example@mail.com (Yingbin Liang, Lu Dai, Shuo Shi, Minghao Dai, Junliang Du, Haige Wang)</author>
      <guid isPermaLink="false">2504.04032v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Environmental Science: A Survey of Emerging Frontiers</title>
      <link>http://arxiv.org/abs/2504.04280v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基础模型在环境科学中的应用，强调了其在预测、数据生成、数据同化、降尺度、逆建模、模型集成和跨领域决策等环境用例中的进展。&lt;h4&gt;背景&lt;/h4&gt;建模环境生态系统对于资源管理、可持续发展和理解复杂的生态过程至关重要。然而，传统的数据驱动方法在捕捉复杂和相互关联的过程方面面临挑战，并且在许多环境应用中受到有限观测数据的限制。&lt;h4&gt;目的&lt;/h4&gt;通过讨论这些新兴方法及其未来机会，旨在促进跨学科合作，加速机器学习在解决关键环境挑战中的科学发现。&lt;h4&gt;方法&lt;/h4&gt;本文详细介绍了这些模型的发展过程，包括数据收集、架构设计、训练、调整和评估。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型利用大规模预训练和复杂异构数据的通用表示，为捕捉环境过程中的时空动态和依赖关系提供了变革性的机会。&lt;h4&gt;结论&lt;/h4&gt;本文提供了对基础模型在环境科学中应用的全面概述，强调了其在不同环境用例中的进展和未来潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling environmental ecosystems is essential for effective resourcemanagement, sustainable development, and understanding complex ecologicalprocesses. However, traditional data-driven methods face challenges incapturing inherently complex and interconnected processes and are furtherconstrained by limited observational data in many environmental applications.Foundation models, which leverages large-scale pre-training and universalrepresentations of complex and heterogeneous data, offer transformativeopportunities for capturing spatiotemporal dynamics and dependencies inenvironmental processes, and facilitate adaptation to a broad range ofapplications. This survey presents a comprehensive overview of foundation modelapplications in environmental science, highlighting advancements in commonenvironmental use cases including forward prediction, data generation, dataassimilation, downscaling, inverse modeling, model ensembling, anddecision-making across domains. We also detail the process of developing thesemodels, covering data collection, architecture design, training, tuning, andevaluation. Through discussions on these emerging methods as well as theirfuture opportunities, we aim to promote interdisciplinary collaboration thataccelerates advancements in machine learning for driving scientific discoveryin addressing critical environmental challenges.</description>
      <author>example@mail.com (Runlong Yu, Shengyu Chen, Yiqun Xie, Huaxiu Yao, Jared Willard, Xiaowei Jia)</author>
      <guid isPermaLink="false">2504.04280v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Multilingual Continual Pretraining: Data Mixing for Adapting LLMs Across Languages and Resources</title>
      <link>http://arxiv.org/abs/2504.04152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文系统地评估了36种连续预训练（CPT）配置，旨在解决大型语言模型（LLMs）在不同语言间性能差异的问题。&lt;h4&gt;背景&lt;/h4&gt;LLMs在不同语言间的性能存在显著差异，高资源语言受益较多，而低资源语言则被边缘化。&lt;h4&gt;目的&lt;/h4&gt;评估不同CPT配置对多语言分类性能的影响，并分析不同数据策略的有效性。&lt;h4&gt;方法&lt;/h4&gt;研究涉及三种多语言基础模型，涵盖30多种语言，这些语言被分为自利、自私和停滞三种类型，并考虑了不同的资源水平。&lt;h4&gt;主要发现&lt;/h4&gt;1. 双语CPT提升了多语言分类性能，但生成过程中常出现语言混合问题；2. 在CPT过程中包含编程代码数据，能持续提升多语言分类准确率，尤其是对低资源语言，但会略微降低生成质量；3. 与先前研究不同，发现语言分类与跨语言迁移影响之间存在较大差异。&lt;h4&gt;结论&lt;/h4&gt;这些发现强调了多语言表示学习的复杂性，并突出了系统研究可推广语言分类的重要性，以指导未来的多语言CPT策略。&lt;h4&gt;翻译&lt;/h4&gt;This paper systematically evaluates 36 Continual Pretraining (CPT) configurations to address the performance disparities among different languages in Large Language Models (LLMs). The background is that LLMs exhibit significant disparities in performance across languages, with high-resource languages benefiting more while underrepresented ones are marginalized. The purpose is to assess the impact of different CPT configurations on multilingual classification performance and analyze the effectiveness of different data strategies. The study involves three multilingual base models and covers 30+ languages categorized as altruistic, selfish, and stagnant, considering various resource levels. The major findings are: 1. Bilingual CPT improves multilingual classification but often causes language mixing issues during generation; 2. Including programming code data during CPT consistently enhances multilingual classification accuracy, particularly benefiting low-resource languages, but introduces a trade-off by slightly degrading generation quality; 3. Contrary to prior work, substantial deviations from language classifications according to their impact on cross-lingual transfer are observed. These findings emphasize the complexity of multilingual representation learning and underscore the importance of systematic studies on generalizable language classification to inform future multilingual CPT strategies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) exhibit significant disparities in performanceacross languages, primarily benefiting high-resource languages whilemarginalizing underrepresented ones. Continual Pretraining (CPT) has emerged asa promising approach to address this imbalance, although the relativeeffectiveness of monolingual, bilingual, and code-augmented data strategiesremains unclear. This study systematically evaluates 36 CPT configurationsinvolving three multilingual base models, across 30+ languages categorized asaltruistic, selfish, and stagnant, spanning various resource levels. Ourfindings reveal three major insights: (1) Bilingual CPT improves multilingualclassification but often causes language mixing issues during generation. (2)Including programming code data during CPT consistently enhances multilingualclassification accuracy, particularly benefiting low-resource languages, butintroduces a trade-off by slightly degrading generation quality. (3) Contraryto prior work, we observe substantial deviations from language classificationsaccording to their impact on cross-lingual transfer: Languages classified asaltruistic often negatively affect related languages, selfish languages showconditional and configuration-dependent behavior, and stagnant languagesdemonstrate surprising adaptability under certain CPT conditions. These nuancedinteractions emphasize the complexity of multilingual representation learning,underscoring the importance of systematic studies on generalizable languageclassification to inform future multilingual CPT strategies.</description>
      <author>example@mail.com (Zihao Li, Shaoxiong Ji, Hengyu Luo, Jörg Tiedemann)</author>
      <guid isPermaLink="false">2504.04152v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Pathology Foundation Model: Progress and Future Directions</title>
      <link>http://arxiv.org/abs/2504.04045v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了病理学计算领域中，基于大规模病理学数据预训练的病理学基础模型（PFMs）在自动癌症诊断中的应用。这些模型在特征提取和聚合方面性能显著提升，但缺乏系统分析框架。&lt;h4&gt;背景&lt;/h4&gt;计算病理学利用全切片图像进行自动化癌症诊断，其性能依赖于特征提取器和聚合器。PFMs在特征提取和聚合方面有显著提升，但缺乏系统分析框架。&lt;h4&gt;目的&lt;/h4&gt;提出一个通过自顶向下哲学组织PFMs的分层分类法，用于分析任何领域的FMs，并对PFM评估任务进行系统分类。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种组织PFMs的分类法，并系统地将PFM评估任务分为切片级、区域级、多模态和生物学任务，提供了全面的基准评估标准。&lt;h4&gt;主要发现&lt;/h4&gt;分析确定了PFM开发（病理学特定方法、端到端预训练、数据-模型可扩展性）和利用（有效适应、模型维护）中的关键挑战。&lt;h4&gt;结论&lt;/h4&gt;本文为未来PFM领域的发展指明了方向，并提供了相关的资源链接。&lt;h4&gt;翻译&lt;/h4&gt;This survey reviews the application of Pathology Foundation Models (PFMs) in the field of computational pathology for automated cancer diagnosis, which rely on large-scale histopathology data for pretraining and have significantly enhanced the capabilities of extractors and aggregators, but lack systematic analysis frameworks. This paper proposes a hierarchical taxonomy to organize PFMs through a top-down philosophy, which can be used to analyze FMs in any domain, and systematically categorizes PFM evaluation tasks into slide-level, patch-level, multimodal, and biological tasks, providing comprehensive benchmarking criteria. The analysis identifies critical challenges in both PFM development (pathology-specific methodology, end-to-end pretraining, data-model scalability) and utilization (effective adaptation, model maintenance), paving the way for future directions in this promising field. The resources referenced in this survey are available at https://github.com/BearCleverProud/AwesomeWSI.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computational pathology, analyzing whole slide images for automated cancerdiagnosis, relies on the multiple instance learning framework where performanceheavily depends on the feature extractor and aggregator. Recent PathologyFoundation Models (PFMs), pretrained on large-scale histopathology data, havesignificantly enhanced capabilities of extractors and aggregators but lacksystematic analysis frameworks. This survey presents a hierarchical taxonomyorganizing PFMs through a top-down philosophy that can be utilized to analyzeFMs in any domain: model scope, model pretraining, and model design.Additionally, we systematically categorize PFM evaluation tasks intoslide-level, patch-level, multimodal, and biological tasks, providingcomprehensive benchmarking criteria. Our analysis identifies criticalchallenges in both PFM development (pathology-specific methodology, end-to-endpretraining, data-model scalability) and utilization (effective adaptation,model maintenance), paving the way for future directions in this promisingfield. Resources referenced in this survey are available athttps://github.com/BearCleverProud/AwesomeWSI.</description>
      <author>example@mail.com (Conghao Xiong, Hao Chen, Joseph J. Y. Sung)</author>
      <guid isPermaLink="false">2504.04045v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Transformer representation learning is necessary for dynamic multi-modal physiological data on small-cohort patients</title>
      <link>http://arxiv.org/abs/2504.04120v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer表示模型和传统机器学习算法的术后谵妄（POD）预测框架，利用多模态生理数据，包括aEEG、生命体征、心电图监测数据和血流动力学参数，以提高POD的早期和准确诊断。&lt;h4&gt;背景&lt;/h4&gt;术后谵妄是高风险手术患者中常见的一种严重神经精神并发症，其诊断在重症监护室（ICUs）中因主观监测方法而存在显著误诊。&lt;h4&gt;目的&lt;/h4&gt;旨在通过提出一种POD预测框架，实现POD的早期和准确诊断。&lt;h4&gt;方法&lt;/h4&gt;该方法包括使用Transformer表示模型和传统机器学习算法，并利用多模态生理数据进行预测。研究还构建了首个包含两种患者类型的POD多模态数据集，并评估了不同的Transformer架构。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，使用Transformer表示，特别是Pathformer的融合自适应方法，在患者TYPE I中提高了敏感性和Youden指数。研究强调了从术后第1天到第3天进行有效谵妄诊断的潜力，以及通过多模态Transformer架构进行表示学习的必要性。&lt;h4&gt;结论&lt;/h4&gt;多模态生理数据和通过多模态Transformer架构进行表示学习在临床诊断中具有潜在价值，有助于提高术后谵妄的早期诊断准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Postoperative delirium (POD), a severe neuropsychiatric complicationaffecting nearly 50% of high-risk surgical patients, is defined as an acutedisorder of attention and cognition, It remains significantly underdiagnosed inthe intensive care units (ICUs) due to subjective monitoring methods. Early andaccurate diagnosis of POD is critical and achievable. Here, we propose a PODprediction framework comprising a Transformer representation model followed bytraditional machine learning algorithms. Our approaches utilizes multi-modalphysiological data, including amplitude-integrated electroencephalography(aEEG), vital signs, electrocardiographic monitor data as well as hemodynamicparameters. We curated the first multi-modal POD dataset encompassing twopatient types and evaluated the various Transformer architectures forrepresentation learning. Empirical results indicate a consistent improvementsof sensitivity and Youden index in patient TYPE I using Transformerrepresentations, particularly our fusion adaptation of Pathformer. By enablingeffective delirium diagnosis from postoperative day 1 to 3, our extensiveexperimental findings emphasize the potential of multi-modal physiological dataand highlight the necessity of representation learning via multi-modalTransformer architecture in clinical diagnosis.</description>
      <author>example@mail.com (Bingxu Wang, Kunzhi Cai, Yuqi Zhang, Yachong Guo)</author>
      <guid isPermaLink="false">2504.04120v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>UniRVQA: A Unified Framework for Retrieval-Augmented Vision Question Answering via Self-Reflective Joint Training</title>
      <link>http://arxiv.org/abs/2504.04065v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一的检索增强视觉问答（UniRVQA）框架，用于解决复杂视觉问答问题，并在回答准确性方面取得显著提升。&lt;h4&gt;背景&lt;/h4&gt;现有的知识图谱视觉问答（KB-VQA）系统通常使用独立的检索器和生成器，这限制了参数知识共享，且在多模态信息集成方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出UniRVQA框架，以适应精细粒度的知识密集型任务，并在统一的框架内实现跨任务的参数知识共享。&lt;h4&gt;方法&lt;/h4&gt;UniRVQA使用通用多模态预训练模型，并引入反思回答机制以评估和优化知识边界，同时整合延迟交互到检索增强生成联合训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;UniRVQA在回答准确性方面实现了与现有最先进模型的竞争力，比基线模型提升了4.7%，并将基础的多语言语言模型（MLLMs）的VQA性能平均提升了7.5%。&lt;h4&gt;结论&lt;/h4&gt;UniRVQA框架通过有效集成多模态信息和参数知识共享，显著提高了知识密集型视觉问答系统的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge-based Vision Question Answering (KB-VQA) systems address complexvisual-grounded questions requiring external knowledge, such as web-sourcedencyclopedia articles. Existing methods often use sequential and separateframeworks for the retriever and the generator with limited parametricknowledge sharing. However, since both retrieval and generation tasks requireaccurate understanding of contextual and external information, such separationcan potentially lead to suboptimal system performance. Another key challenge isthe integration of multimodal information. General-purpose multimodalpre-trained models, while adept at multimodal representation learning, strugglewith fine-grained retrieval required for knowledge-intensive visual questions.Recent specialized pre-trained models mitigate the issue, but arecomputationally expensive. To bridge the gap, we propose a UnifiedRetrieval-Augmented VQA framework (UniRVQA). UniRVQA adapts general multimodalpre-trained models for fine-grained knowledge-intensive tasks within a unifiedframework, enabling cross-task parametric knowledge sharing and the extensionof existing multimodal representation learning capability. We further introducea reflective-answering mechanism that allows the model to explicitly evaluateand refine its knowledge boundary. Additionally, we integrate late interactioninto the retrieval-augmented generation joint training process to enhancefine-grained understanding of queries and documents. Our approach achievescompetitive performance against state-of-the-art models, delivering asignificant 4.7% improvement in answering accuracy, and brings an average 7.5%boost in base MLLMs' VQA performance.</description>
      <author>example@mail.com (Jiaqi Deng, Kaize Shi, Zonghan Wu, Huan Huo, Dingxian Wang, Guandong Xu)</author>
      <guid isPermaLink="false">2504.04065v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Re-thinking Temporal Search for Long-Form Video Understanding</title>
      <link>http://arxiv.org/abs/2504.02259v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025; A real-world long video needle-in-haystack  benchmark; long-video QA with human ref frames&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了长视频理解中的时间搜索范式，并针对当前最先进的长期上下文视觉语言模型（VLMs）存在的根本问题提出了解决方案。&lt;h4&gt;背景&lt;/h4&gt;长视频理解在计算机视觉中是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提高时间搜索的质量和效率。&lt;h4&gt;方法&lt;/h4&gt;将时间搜索问题定义为长视频海棉问题，并引入了LV-Haystack数据集；提出了一种轻量级的时间搜索框架T*，该框架借鉴了图像视觉搜索技术，并引入了自适应缩放机制。&lt;h4&gt;主要发现&lt;/h4&gt;在LV-Haystack数据集上，当前最先进的方法在时间搜索能力上存在显著差距，仅达到2.1%的时间F1分数；T*框架与现有方法的结合显著提高了长视频理解能力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高长视频理解的效果，并提供了代码、基准和模型。&lt;h4&gt;翻译&lt;/h4&gt;Efficiently understanding long-form videos remains a significant challenge in computer vision. In this work, we revisit temporal search paradigms for long-form video understanding and address a fundamental issue pertaining to all state-of-the-art (SOTA) long-context vision-language models (VLMs). Our contributions are twofold: First, we frame temporal search as a Long Video Haystack problem: finding a minimal set of relevant frames (e.g., one to five) from tens of thousands based on specific queries. Upon this formulation, we introduce LV-Haystack, the first dataset with 480 hours of videos, 15,092 human-annotated instances for both training and evaluation aiming to improve temporal search quality and efficiency. Results on LV-Haystack highlight a significant research gap in temporal search capabilities, with current SOTA search methods only achieving 2.1% temporal F1 score on the Longvideo bench subset. Next, inspired by visual search in images, we propose a lightweight temporal search framework, T* that reframes costly temporal search as spatial search. T* leverages powerful visual localization techniques commonly used in images and introduces an adaptive zooming-in mechanism that operates across both temporal and spatial dimensions. Extensive experiments show that integrating T* with existing methods significantly improves SOTA long-form video understanding. Under an inference budget of 32 frames, T* improves GPT-4o's performance from 50.5% to 53.1% and LLaVA-OneVision-OV-72B's performance from 56.5% to 62.4% on the Longvideo bench XL subset. Our code, benchmark, and models are provided in the Supplementary material.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficiently understanding long-form videos remains a significant challenge incomputer vision. In this work, we revisit temporal search paradigms forlong-form video understanding and address a fundamental issue pertaining to allstate-of-the-art (SOTA) long-context vision-language models (VLMs). Ourcontributions are twofold: First, we frame temporal search as a Long VideoHaystack problem: finding a minimal set of relevant frames (e.g., one to five)from tens of thousands based on specific queries. Upon this formulation, weintroduce LV-Haystack, the first dataset with 480 hours of videos, 15,092human-annotated instances for both training and evaluation aiming to improvetemporal search quality and efficiency. Results on LV-Haystack highlight asignificant research gap in temporal search capabilities, with current SOTAsearch methods only achieving 2.1% temporal F1 score on the Longvideobenchsubset. Next, inspired by visual search in images, we propose a lightweighttemporal search framework, T* that reframes costly temporal search as spatialsearch. T* leverages powerful visual localization techniques commonly used inimages and introduces an adaptive zooming-in mechanism that operates acrossboth temporal and spatial dimensions. Extensive experiments show thatintegrating T* with existing methods significantly improves SOTA long-formvideo understanding. Under an inference budget of 32 frames, T* improvesGPT-4o's performance from 50.5% to 53.1% and LLaVA-OneVision-OV-72B'sperformance from 56.5% to 62.4% on the Longvideobench XL subset. Our code,benchmark, and models are provided in the Supplementary material.</description>
      <author>example@mail.com (Jinhui Ye, Zihan Wang, Haosen Sun, Keshigeyan Chandrasegaran, Zane Durante, Cristobal Eyzaguirre, Yonatan Bisk, Juan Carlos Niebles, Ehsan Adeli, Li Fei-Fei, Jiajun Wu, Manling Li)</author>
      <guid isPermaLink="false">2504.02259v2</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Time Series: A Survey</title>
      <link>http://arxiv.org/abs/2504.04011v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基于Transformer的基础模型在时间序列分析中的应用，并提出了一个新的分类法来对这些模型进行分类。&lt;h4&gt;背景&lt;/h4&gt;Transformer模型在时间序列分析领域已成为主流范式，其在预测、异常检测、分类、趋势分析等任务中表现出前所未有的能力。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供一个全面概述当前最先进的时间序列分析预训练基础模型，并引入一个新颖的分类法来对这些模型进行分类。&lt;h4&gt;方法&lt;/h4&gt;通过分析模型的架构设计、预测类型、时间序列类型、模型规模和复杂度以及训练阶段使用的目标函数等多个维度对模型进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;分类法区分了基于补丁表示和直接操作原始序列的模型，以及提供概率或确定性预测的模型，以及能够处理单变量或多变量时间序列的模型。此外，还突出了轻量级架构和大规模基础模型之间的差异。&lt;h4&gt;结论&lt;/h4&gt;本文为研究人员和实践者提供了一个资源，提供了对当前趋势的见解，并确定了基于Transformer的时间序列建模未来研究的有希望的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer-based foundation models have emerged as a dominant paradigm intime series analysis, offering unprecedented capabilities in tasks such asforecasting, anomaly detection, classification, trend analysis and many moretime series analytical tasks. This survey provides a comprehensive overview ofthe current state of the art pre-trained foundation models, introducing a noveltaxonomy to categorize them across several dimensions. Specifically, weclassify models by their architecture design, distinguishing between thoseleveraging patch-based representations and those operating directly on rawsequences. The taxonomy further includes whether the models provideprobabilistic or deterministic predictions, and whether they are designed towork with univariate time series or can handle multivariate time series out ofthe box. Additionally, the taxonomy encompasses model scale and complexity,highlighting differences between lightweight architectures and large-scalefoundation models. A unique aspect of this survey is its categorization by thetype of objective function employed during training phase. By synthesizingthese perspectives, this survey serves as a resource for researchers andpractitioners, providing insights into current trends and identifying promisingdirections for future research in transformer-based time series modeling.</description>
      <author>example@mail.com (Siva Rama Krishna Kottapalli, Karthik Hubli, Sandeep Chandrashekhara, Garima Jain, Sunayana Hubli, Gayathri Botla, Ramesh Doddaiah)</author>
      <guid isPermaLink="false">2504.04011v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>VideoComp: Advancing Fine-Grained Compositional and Temporal Alignment in Video-Text Models</title>
      <link>http://arxiv.org/abs/2504.03970v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025, project page at  https://github.com/google-deepmind/video_comp&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出VideoComp，一个用于提升视频-文本组成性理解的基准和学习框架，旨在改善视觉语言模型（VLMs）在精细时间对齐方面的性能。&lt;h4&gt;背景&lt;/h4&gt;现有基准主要关注静态图像-文本组成性或独立单事件视频，而VideoComp旨在解决连续多事件视频中的对齐问题。&lt;h4&gt;目的&lt;/h4&gt;通过构建两个组成性基准ActivityNet-Comp和YouCook2-Comp，测试模型在扩展且连贯的视频-文本序列中的组成性敏感性。&lt;h4&gt;方法&lt;/h4&gt;利用具有时间定位事件字幕的视频-文本数据集，构建基准，并创建具有微妙时间干扰的负样本，如重新排序、动作词替换、部分字幕和组合干扰。提出层次化成对偏好损失，强化与时间准确对的对齐，并逐渐惩罚越来越被破坏的对齐，以鼓励精细的组成性学习。为了缓解密集标注视频数据的有限可用性，引入预训练策略，通过连接短视频-字幕对来模拟多事件序列。&lt;h4&gt;主要发现&lt;/h4&gt;在基准上评估视频-文本基础模型和大型多模态模型（LMMs），识别了组成性方面的优势和改进领域。&lt;h4&gt;结论&lt;/h4&gt;VideoComp提供了一个全面的框架，用于评估和增强模型在实现精细、时间一致的视频-文本对齐方面的能力。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了VideoComp，这是一个旨在提升视频-文本组成性理解的基准和学习框架，目标是改善视觉语言模型（VLMs）在精细时间对齐方面的性能。与现有基准不同，这些基准主要关注静态图像-文本组成性或独立单事件视频，我们的基准针对连续多事件视频中的对齐。利用具有时间定位事件字幕的视频-文本数据集（例如ActivityNet-Captions，YouCook2），我们构建了两个组成性基准，ActivityNet-Comp和YouCook2-Comp。我们创建了具有微妙时间干扰的负样本，如重新排序、动作词替换、部分字幕和组合干扰。这些基准全面测试了模型在扩展、连贯的视频-文本序列中的组成性敏感性。为了提高模型性能，我们提出了一个层次化成对偏好损失，它强化了与时间准确对的对齐，并逐渐惩罚越来越被破坏的对齐，鼓励精细的组成性学习。为了缓解密集标注视频数据的有限可用性，我们引入了一种预训练策略，通过连接短视频-字幕对来模拟多事件序列。我们在我们的基准上评估了视频-文本基础模型和大型多模态模型（LMMs），确定了组成性方面的优势和改进领域。总的来说，我们的工作提供了一个全面的框架，用于评估和增强模型在实现精细、时间一致的视频-文本对齐方面的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce VideoComp, a benchmark and learning framework for advancingvideo-text compositionality understanding, aimed at improving vision-languagemodels (VLMs) in fine-grained temporal alignment. Unlike existing benchmarksfocused on static image-text compositionality or isolated single-event videos,our benchmark targets alignment in continuous multi-event videos. Leveragingvideo-text datasets with temporally localized event captions (e.g.ActivityNet-Captions, YouCook2), we construct two compositional benchmarks,ActivityNet-Comp and YouCook2-Comp. We create challenging negative samples withsubtle temporal disruptions such as reordering, action word replacement,partial captioning, and combined disruptions. These benchmarks comprehensivelytest models' compositional sensitivity across extended, cohesive video-textsequences. To improve model performance, we propose a hierarchical pairwisepreference loss that strengthens alignment with temporally accurate pairs andgradually penalizes increasingly disrupted ones, encouraging fine-grainedcompositional learning. To mitigate the limited availability of denselyannotated video data, we introduce a pretraining strategy that concatenatesshort video-caption pairs to simulate multi-event sequences. We evaluatevideo-text foundational models and large multimodal models (LMMs) on ourbenchmark, identifying both strengths and areas for improvement incompositionality. Overall, our work provides a comprehensive framework forevaluating and enhancing model capabilities in achieving fine-grained,temporally coherent video-text alignment.</description>
      <author>example@mail.com (Dahun Kim, AJ Piergiovanni, Ganesh Mallya, Anelia Angelova)</author>
      <guid isPermaLink="false">2504.03970v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Is Temporal Prompting All We Need For Limited Labeled Action Recognition?</title>
      <link>http://arxiv.org/abs/2504.01890v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in CVPR-W 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，视频理解取得了显著进步，这主要得益于大规模标注数据集的可用性。本文提出了一种名为TP-CLIP的CLIP模型改编，它利用时间视觉提示进行时间适应，而无需修改CLIP的核心架构，从而保持了其泛化能力。&lt;h4&gt;背景&lt;/h4&gt;视频理解的发展依赖于大规模标注数据集，而视觉-语言模型在基于对比预训练的基础上在零样本任务中表现出良好的泛化能力，有助于克服对标注数据集的依赖。&lt;h4&gt;目的&lt;/h4&gt;提出TP-CLIP模型，旨在为视频数据提供一种高效且参数较少的时间适应方法，同时保持CLIP模型的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;TP-CLIP通过修改视觉-语言模型的架构以适应视频数据，同时利用时间视觉提示进行时间适应，而不改变CLIP的核心架构。&lt;h4&gt;主要发现&lt;/h4&gt;TP-CLIP在零样本和少样本学习任务中表现出高效性，参数和计算效率优于现有方法。与最新的最先进方法相比，TP-CLIP只需要1/3的GFLOPs和1/28的可调参数数量，但在性能上可以超过15.8%。&lt;h4&gt;结论&lt;/h4&gt;TP-CLIP是一种高效且参数较少的视频理解方法，在保持CLIP模型泛化能力的同时，显著提高了零样本和少样本学习任务中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video understanding has shown remarkable improvements in recent years,largely dependent on the availability of large scaled labeled datasets. Recentadvancements in visual-language models, especially based on contrastivepretraining, have shown remarkable generalization in zero-shot tasks, helpingto overcome this dependence on labeled datasets. Adaptations of such models forvideos, typically involve modifying the architecture of vision-language modelsto cater to video data. However, this is not trivial, since such adaptationsare mostly computationally intensive and struggle with temporal modeling. Wepresent TP-CLIP, an adaptation of CLIP that leverages temporal visual promptingfor temporal adaptation without modifying the core CLIP architecture. Thispreserves its generalization abilities. TP-CLIP efficiently integrates into theCLIP architecture, leveraging its pre-trained capabilities for video data.Extensive experiments across various datasets demonstrate its efficacy inzero-shot and few-shot learning, outperforming existing approaches with fewerparameters and computational efficiency. In particular, we use just 1/3 theGFLOPs and 1/28 the number of tuneable parameters in comparison to recentstate-of-the-art and still outperform it by up to 15.8% depending on the taskand dataset.</description>
      <author>example@mail.com (Shreyank N Gowda, Boyan Gao, Xiao Gu, Xiaobo Jin)</author>
      <guid isPermaLink="false">2504.01890v2</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Can ChatGPT Learn My Life From a Week of First-Person Video?</title>
      <link>http://arxiv.org/abs/2504.03857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过穿戴相机设备收集个人生活数据，研究预训练模型对个人生活信息的学习能力。&lt;h4&gt;背景&lt;/h4&gt;随着生成式AI和可穿戴相机设备（如智能眼镜和AI增强别针）的进步，研究模型从第一人称相机数据中学习个人生活信息的能力成为可能。&lt;h4&gt;目的&lt;/h4&gt;探究预训练模型通过第一人称相机数据了解穿戴者个人生活的能力。&lt;h4&gt;方法&lt;/h4&gt;作者穿戴相机头显54小时，生成不同长度的摘要（如分钟级、小时级和日级摘要），并在生成的摘要层次结构上微调GPT-4o和GPT-4o-mini模型。通过查询微调后的模型，了解模型学到了什么。&lt;h4&gt;主要发现&lt;/h4&gt;两个模型都学会了关于作者的基本信息（如大致年龄、性别）。GPT-4o正确推断出作者住在匹兹堡，是CMU的博士生，是右撇子，并且有宠物猫。然而，两个模型都存在幻觉，并为视频中出现的个体编造名字。&lt;h4&gt;结论&lt;/h4&gt;预训练模型可以从个人生活数据中学习基本信息，但存在幻觉问题。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the ability of pre-trained models to learn about individuals' personal lives through first-person camera data, using wearable camera devices and generating summaries of various lengths. The results show that the models can learn basic information but suffer from hallucinations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivated by recent improvements in generative AI and wearable camera devices(e.g. smart glasses and AI-enabled pins), I investigate the ability offoundation models to learn about the wearer's personal life throughfirst-person camera data. To test this, I wore a camera headset for 54 hoursover the course of a week, generated summaries of various lengths (e.g.minute-long, hour-long, and day-long summaries), and fine-tuned both GPT-4o andGPT-4o-mini on the resulting summary hierarchy. By querying the fine-tunedmodels, we are able to learn what the models learned about me. The results aremixed: Both models learned basic information about me (e.g. approximate age,gender). Moreover, GPT-4o correctly deduced that I live in Pittsburgh, am a PhDstudent at CMU, am right-handed, and have a pet cat. However, both models alsosuffered from hallucination and would make up names for the individuals presentin the video footage of my life.</description>
      <author>example@mail.com (Keegan Harris)</author>
      <guid isPermaLink="false">2504.03857v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Biologically Inspired Hierarchical Temporal Memory with Hardware-Accelerated Reflex Memory</title>
      <link>http://arxiv.org/abs/2504.03746v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种加速层次时间记忆（AHTM）系统，通过引入反射记忆（RM）块来提高第一阶推理的速度，从而在处理重复信息时比原始的层次时间记忆（HTM）系统更高效，同时仍支持多阶推理。&lt;h4&gt;背景&lt;/h4&gt;随着物联网的快速扩张，产生了大量数据，需要高效的无监督学习系统来处理这些数据。&lt;h4&gt;目的&lt;/h4&gt;提高层次时间记忆（HTM）算法处理第一阶推理的速度，并保持多阶推理的能力。&lt;h4&gt;方法&lt;/h4&gt;设计了一个反射记忆（RM）块，该块受到脊髓工作机制的启发，以加速第一阶推理。将RM块与HTM结合形成AHTM系统，并在内容可寻址内存（CAM）块中实现硬件加速版本（H-AHTM）。&lt;h4&gt;主要发现&lt;/h4&gt;AHTM模块预测事件的时间缩短至0.125秒，而H-AHTM模块仅需0.094秒，与原始算法相比，AHTM加速了推理速度至7.55倍，而H-AHTM进一步提高了性能，速度提升了10.10倍。&lt;h4&gt;结论&lt;/h4&gt;AHTM和H-AHTM系统通过优化HTM算法，显著提高了数据处理和预测的速度，为物联网等应用提供了更高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid expansion of the Internet of Things (IoT) generates zettabytes ofdata that demand efficient unsupervised learning systems. Hierarchical TemporalMemory (HTM), a third-generation unsupervised AI algorithm, models theneocortex of the human brain by simulating columns of neurons to process andpredict sequences. These neuron columns can memorize and infer sequences acrossmultiple orders. While multiorder inferences offer robust predictivecapabilities, they often come with significant computational overhead. TheSequence Memory (SM) component of HTM, which manages these inferences,encounters bottlenecks primarily due to its extensive programmableinterconnects. In many cases, it has been observed that first-order temporalrelationships have proven to be sufficient without any significant loss inefficiency. This paper introduces a Reflex Memory (RM) block, inspired by theSpinal Cord's working mechanisms, designed to accelerate the processing offirst-order inferences. The RM block performs these inferences significantlyfaster than the SM. The integration of RM with HTM forms a system called theAccelerated Hierarchical Temporal Memory (AHTM), which processes repetitiveinformation more efficiently than the original HTM while still supportingmultiorder inferences. The experimental results demonstrate that the HTMpredicts an event in 0.945 s, whereas the AHTM module does so in 0.125 s.Additionally, the hardware implementation of RM in a content-addressable memory(CAM) block, known as Hardware-Accelerated Hierarchical Temporal Memory(H-AHTM), predicts an event in just 0.094 s, significantly improving inferencespeed. Compared to the original algorithm \cite{bautista2020matlabhtm}, AHTMaccelerates inference by up to 7.55x, while H-AHTM further enhances performancewith a 10.10x speedup.</description>
      <author>example@mail.com (Pavia Bera, Sabrina Hassan Moon, Jennifer Adorno, Dayane Alfenas Reis, Sanjukta Bhanja)</author>
      <guid isPermaLink="false">2504.03746v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Semantic-guided Representation Learning for Multi-Label Recognition</title>
      <link>http://arxiv.org/abs/2504.03801v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in ICME2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SigRL的语义引导表示学习方法，用于解决多标签识别（MLR）中的挑战，并在多个MLR基准测试中显示出优于现有方法的性能。&lt;h4&gt;背景&lt;/h4&gt;多标签识别在复杂场景中优于单标签分类，但面临着标注所有相关类别的不确定性问题，且现有的基于视觉和语言预训练的方法在处理零样本MLR任务时，存在语义信息不足的问题。&lt;h4&gt;目的&lt;/h4&gt;通过引入SigRL方法，旨在提高模型学习有效视觉和文本表示的能力，从而改善视觉图像和类别之间的下游对齐。&lt;h4&gt;方法&lt;/h4&gt;SigRL方法包括三个模块：基于图的多标签相关性模块（GMC），用于丰富多标签文本的语义表示；语义视觉特征重建模块（SVFR），通过集成学习到的文本表示来增强视觉表示中的语义信息；以及利用局部和全局特征优化VLP模型的图像-文本匹配能力。&lt;h4&gt;主要发现&lt;/h4&gt;SigRL在零样本MLR（包含未见过的标签）和单正多标签学习（包含有限标签）的多个MLR基准测试中，比现有方法表现出更优的性能。&lt;h4&gt;结论&lt;/h4&gt;SigRL方法通过引入新的模块和优化策略，有效提高了多标签识别的性能，为MLR任务提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为SigRL的语义引导表示学习方法，用于解决多标签识别（MLR）中的挑战，并在多个MLR基准测试中显示出优于现有方法的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-label Recognition (MLR) involves assigning multiple labels to each datainstance in an image, offering advantages over single-label classification incomplex scenarios. However, it faces the challenge of annotating all relevantcategories, often leading to uncertain annotations, such as unseen orincomplete labels. Recent Vision and Language Pre-training (VLP) based methodshave made significant progress in tackling zero-shot MLR tasks by leveragingrich vision-language correlations. However, the correlation between multi-labelsemantics has not been fully explored, and the learned visual features oftenlack essential semantic information. To overcome these limitations, weintroduce a Semantic-guided Representation Learning approach (SigRL) thatenables the model to learn effective visual and textual representations,thereby improving the downstream alignment of visual images and categories.Specifically, we first introduce a graph-based multi-label correlation module(GMC) to facilitate information exchange between labels, enriching the semanticrepresentation across the multi-label texts. Next, we propose a Semantic VisualFeature Reconstruction module (SVFR) to enhance the semantic information in thevisual representation by integrating the learned textual representation duringreconstruction. Finally, we optimize the image-text matching capability of theVLP model using both local and global features to achieve zero-shot MLR.Comprehensive experiments are conducted on several MLR benchmarks, encompassingboth zero-shot MLR (with unseen labels) and single positive multi-labellearning (with limited labels), demonstrating the superior performance of ourapproach compared to state-of-the-art methods. The code is available athttps://github.com/MVL-Lab/SigRL.</description>
      <author>example@mail.com (Ruhui Zhang, Hezhe Qiao, Pengcheng Xu, Mingsheng Shang, Lin Chen)</author>
      <guid isPermaLink="false">2504.03801v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>A High-Speed Time-Optimal Trajectory Generation Strategy via a Two-layer Planning Model</title>
      <link>http://arxiv.org/abs/2503.11072v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对优化基于实时运动规划在无人机、机械臂和火箭等领域的应用，提出了一个针对智能地面车辆的分层轨迹生成算法。&lt;h4&gt;背景&lt;/h4&gt;优化基于实时运动规划在处理非凸性和非线性规划算法限制时变得具有挑战性，特别是非线性动态、避障约束和非凸输入等因素的加剧。&lt;h4&gt;目的&lt;/h4&gt;为了提高鲁棒性和减少计算负担，提出了一种使用凸优化方法的分层轨迹生成算法，旨在为轨迹优化提供实时保证并提高运动预测的计算速度。&lt;h4&gt;方法&lt;/h4&gt;该方法将原始问题分解为基于小时间窗的规划周期，每个周期在一系列由定制搜索算法增量构建的受限凸集合中求解。&lt;h4&gt;主要发现&lt;/h4&gt;通过数学分析和实验验证，证明了该方法的鲁棒性，特别是在与通用顺序凸规划算法的比较实验中，该方法在动态地图中的计算效率和最终时间的减少方面表现出优越性能。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效解决实时运动规划中的挑战，并为智能地面车辆的轨迹优化提供了一种高效和鲁棒的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Motion planning and trajectory generation are crucial technologies in variousdomains including the control of Unmanned Aerial Vehicles, manipulators, androckets. However, optimization-based real-time motion planning becomesincreasingly challenging due to the problem's probable non-convexity and theinherent limitations of non-linear programming algorithms. Highly nonlineardynamics, obstacle avoidance constraints, and non-convex inputs can exacerbatethese difficulties. In order to enhance the robustness and reduce thecomputational burden, this paper proposes a two-layer trajectory generatingalgorithm for intelligent ground vehicles with convex optimization methods,aiming to provide real-time guarantees for trajectory optimization and toimprove the calculate speed of motion prediction. Our approach involvesbreaking down the original problem into small horizon-based planning cycleswith fixed final times, referred to as planning cycles. Each planning cycle isthen solved within a series of restricted convex sets constructed by somecustomized search algorithms incrementally. We rigorously establish theseadvantages through mathematical analysis under moderate assumptions andcomprehensive experimental validations. For linear vehicle models, comparativeexperiments with general sequential convex programming algorithms demonstratethe superior performance of our proposed method, particularly in terms of thecomputational efficiency in dynamic maps and the reduced final time.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motion planning and trajectory generation are crucial technologies in variousdomains including the control of Unmanned Aerial Vehicles, manipulators, androckets. However, optimization-based real-time motion planning becomesincreasingly challenging due to the problem's probable non-convexity and theinherent limitations of non-linear programming algorithms. Highly nonlineardynamics, obstacle avoidance constraints, and non-convex inputs can exacerbatethese difficulties. In order to enhance the robustness and reduce thecomputational burden, this paper proposes a two-layer trajectory generatingalgorithm for intelligent ground vehicles with convex optimization methods,aiming to provide real-time guarantees for trajectory optimization and toimprove the calculate speed of motion prediction. Our approach involvesbreaking down the original problem into small horizon-based planning cycleswith fixed final times, referred to as planning cycles. Each planning cycle isthen solved within a series of restricted convex sets constructed by somecustomized search algorithms incrementally. We rigorously establish theseadvantages through mathematical analysis under moderate assumptions andcomprehensive experimental validations. For linear vehicle models, comparativeexperiments with general sequential convex programming algorithms demonstratethe superior performance of our proposed method, particularly in terms of thecomputational efficiency in dynamic maps and the reduced final time.</description>
      <author>example@mail.com (Haotian Tan, Yuan-Hua Ni)</author>
      <guid isPermaLink="false">2503.11072v2</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Semi-Self Representation Learning for Crowdsourced WiFi Trajectories</title>
      <link>http://arxiv.org/abs/2504.03756v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by VTC2025-Spring&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于WiFi指纹的定位，提出了一种半自代表学习解决方案，通过新颖的‘切分和翻转’增强方案和两阶段学习过程，实现了对大量未标记WiFi轨迹数据的自动标注，从而减轻了基于轨迹定位中人工标注的负担。&lt;h4&gt;背景&lt;/h4&gt;WiFi指纹定位技术已得到深入研究。点定位方法依赖于WiFi指纹的位置标注，而轨迹定位方法则需要WiFi轨迹的终点标注，WiFi轨迹是一系列信号特征的多元时间序列。由于在特定区域内潜在轨迹数量的指数增长，轨迹数据集通常比点数据集大得多。&lt;h4&gt;目的&lt;/h4&gt;提出一种半自代表学习解决方案，能够自动标注大量未标记的WiFi轨迹数据集，从而减轻基于轨迹定位的人工标注负担。&lt;h4&gt;方法&lt;/h4&gt;通过一个基于‘切分和翻转’增强方案的新颖‘中间相遇’范式，使用一个较小的标记轨迹数据集$ilde C$自动标注一个较大的未标记WiFi轨迹数据集$C$。两阶段学习过程包括轨迹嵌入和终点嵌入，然后使用标记数据集$ilde C$对学习到的表示进行标注，并将其连接到一个基于神经网络的定位网络。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了对未标记轨迹数据集的自动标注，同时显著降低了人工标注的负担，且在准确性方面表现出良好的潜力。&lt;h4&gt;结论&lt;/h4&gt;提出的半自代表学习解决方案能够有效减少基于轨迹定位的人工标注工作量，同时保持较高的定位精度。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies WiFi fingerprint-based localization and proposes a semi-self-representation learning solution. Through a novel 'cut-and-flip' augmentation scheme based on the meet-in-the-middle paradigm, a large dataset C of crowdsourced unlabeled WiFi trajectories can be automatically labeled by a much smaller dataset $ilde C$ of labeled WiFi trajectories. The size of $ilde C$ only needs to be proportional to the size of the physical field, while the unlabeled C could be much larger. This is made possible through a novel 'cut-and-flip' augmentation scheme based on the meet-in-the-middle paradigm. A two-stage learning process consisting of trajectory embedding followed by endpoint embedding is proposed for the unlabeled C. Then the learned representations are labeled by $ilde C$ and connected to a neural-based localization network. The result, while delivering promising accuracy, significantly relieves the burden of human annotations for trajectory-based localization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; WiFi fingerprint-based localization has been studied intensively. Point-basedsolutions rely on position annotations of WiFi fingerprints. Trajectory-basedsolutions, however, require end-position annotations of WiFi trajectories,where a WiFi trajectory is a multivariate time series of signal features. Atrajectory dataset is much larger than a pointwise dataset as the number ofpotential trajectories in a field may grow exponentially with respect to thesize of the field. This work presents a semi-self representation learningsolution, where a large dataset $C$ of crowdsourced unlabeled WiFi trajectoriescan be automatically labeled by a much smaller dataset $\tilde C$ of labeledWiFi trajectories. The size of $\tilde C$ only needs to be proportional to thesize of the physical field, while the unlabeled $C$ could be much larger. Thisis made possible through a novel ``cut-and-flip'' augmentation scheme based onthe meet-in-the-middle paradigm. A two-stage learning consisting of trajectoryembedding followed by endpoint embedding is proposed for the unlabeled $C$.Then the learned representations are labeled by $\tilde C$ and connected to aneural-based localization network. The result, while delivering promisingaccuracy, significantly relieves the burden of human annotations fortrajectory-based localization.</description>
      <author>example@mail.com (Yu-Lin Kuo, Yu-Chee Tseng, Ting-Hui Chiang, Yan-Ann Chen)</author>
      <guid isPermaLink="false">2504.03756v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Experimental Study on Time Series Analysis of Lower Limb Rehabilitation Exercise Data Driven by Novel Model Architecture and Large Models</title>
      <link>http://arxiv.org/abs/2504.03799v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了新型模型架构和大规模基础模型在下肢康复运动数据时间序列分析中的应用，旨在利用机器学习和人工智能的进步，为中风后患者肢体运动功能恢复提供主动康复指导策略。&lt;h4&gt;背景&lt;/h4&gt;研究使用了深圳先进技术研究院提出的SIAT-LLMD下肢运动数据集。&lt;h4&gt;目的&lt;/h4&gt;研究目的是系统地阐明创新性xLSTM架构和基础模型Lag-Llama在涉及关节运动学和动力学参数的短期时间预测任务中的实施和分析结果。&lt;h4&gt;方法&lt;/h4&gt;研究使用了SIAT-LLMD数据集，并采用了xLSTM架构和Lag-Llama模型进行时间序列分析。&lt;h4&gt;主要发现&lt;/h4&gt;研究提供了AI辅助医疗康复应用的见解，证明了尖端模型架构和大规模模型在康复医学时间预测中的潜力。&lt;h4&gt;结论&lt;/h4&gt;研究结果为个性化康复方案的将来应用建立了理论基础，对临床实践中定制化治疗干预措施的发展具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;This study investigates the application of novel model architectures and large-scale foundational models in temporal series analysis of lower limb rehabilitation motion data, aiming to leverage advancements in machine learning and artificial intelligence to empower active rehabilitation guidance strategies for post-stroke patients in limb motor function recovery. Utilizing the SIAT-LLMD dataset of lower limb movement data proposed by the Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, we systematically elucidate the implementation and analytical outcomes of the innovative xLSTM architecture and the foundational model Lag-Llama in short-term temporal prediction tasks involving joint kinematics and dynamics parameters. The research provides novel insights for AI-enabled medical rehabilitation applications, demonstrating the potential of cutting-edge model architectures and large-scale models in rehabilitation medicine temporal prediction. These findings establish theoretical foundations for future applications of personalized rehabilitation regimens, offering significant implications for the development of customized therapeutic interventions in clinical practice.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study investigates the application of novel model architectures andlarge-scale foundational models in temporal series analysis of lower limbrehabilitation motion data, aiming to leverage advancements in machine learningand artificial intelligence to empower active rehabilitation guidancestrategies for post-stroke patients in limb motor function recovery. Utilizingthe SIAT-LLMD dataset of lower limb movement data proposed by the ShenzhenInstitute of Advanced Technology, Chinese Academy of Sciences, wesystematically elucidate the implementation and analytical outcomes of theinnovative xLSTM architecture and the foundational model Lag-Llama inshort-term temporal prediction tasks involving joint kinematics and dynamicsparameters. The research provides novel insights for AI-enabled medicalrehabilitation applications, demonstrating the potential of cutting-edge modelarchitectures and large-scale models in rehabilitation medicine temporalprediction. These findings establish theoretical foundations for futureapplications of personalized rehabilitation regimens, offering significantimplications for the development of customized therapeutic interventions inclinical practice.</description>
      <author>example@mail.com (Hengyu Lin)</author>
      <guid isPermaLink="false">2504.03799v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>TransNet: Transfer Knowledge for Few-shot Knowledge Graph Completion</title>
      <link>http://arxiv.org/abs/2504.03720v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于迁移学习的少样本知识图谱补全方法（TransNet），旨在提高知识图谱在下游任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;现实中的知识图谱往往不完整，且关系分布呈现长尾分布，导致多数关系只有少量训练三元组，影响性能。&lt;h4&gt;目的&lt;/h4&gt;通过引入少样本学习，在只有少量训练三元组的情况下，对包含新关系的三元组进行准确预测。&lt;h4&gt;方法&lt;/h4&gt;TransNet通过学习不同任务之间的关系，有效地将相似任务的知识迁移到当前任务，并采用元学习来对新、未见过的关系进行有效泛化。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上的实验表明，TransNet在性能上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;TransNet能够有效提高知识图谱在下游任务中的性能，并能够泛化到新、未见过的关系。&lt;h4&gt;翻译&lt;/h4&gt;Knowledge graphs (KGs) are ubiquitous and widely used in various applications. However, most real-world knowledge graphs are incomplete, which significantly degrades their performance on downstream tasks. Additionally, the relationships in real-world knowledge graphs often follow a long-tail distribution, meaning that most relations are represented by only a few training triplets. To address these challenges, few-shot learning has been introduced. Few-shot KG completion aims to make accurate predictions for triplets involving novel relations when only a limited number of training triplets are available. Although many methods have been proposed, they typically learn each relation individually, overlooking the correlations between different tasks and the relevant information in previously trained tasks. In this paper, we propose a transfer learning-based few-shot KG completion method (TransNet). By learning the relationships between different tasks, TransNet effectively transfers knowledge from similar tasks to improve the current task's performance. Furthermore, by employing meta-learning, TransNet can generalize effectively to new, unseen relations. Extensive experiments on benchmark datasets demonstrate the superiority of TransNet over state-of-the-art methods. Code can be found at https://github.com/lihuiliullh/TransNet/tree/main&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge graphs (KGs) are ubiquitous and widely used in variousapplications. However, most real-world knowledge graphs are incomplete, whichsignificantly degrades their performance on downstream tasks. Additionally, therelationships in real-world knowledge graphs often follow a long-taildistribution, meaning that most relations are represented by only a fewtraining triplets. To address these challenges, few-shot learning has beenintroduced. Few-shot KG completion aims to make accurate predictions fortriplets involving novel relations when only a limited number of trainingtriplets are available. Although many methods have been proposed, theytypically learn each relation individually, overlooking the correlationsbetween different tasks and the relevant information in previously trainedtasks. In this paper, we propose a transfer learning-based few-shot KGcompletion method (TransNet). By learning the relationships between differenttasks, TransNet effectively transfers knowledge from similar tasks to improvethe current task's performance. Furthermore, by employing meta-learning,TransNet can generalize effectively to new, unseen relations. Extensiveexperiments on benchmark datasets demonstrate the superiority of TransNet overstate-of-the-art methods. Code can be found athttps://github.com/lihuiliullh/TransNet/tree/main</description>
      <author>example@mail.com (Lihui Liu, Zihao Wang, Dawei Zhou, Ruijie Wang, Yuchen Yan, Bo Xiong, Sihong He, Kai Shu, Hanghang Tong)</author>
      <guid isPermaLink="false">2504.03720v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>ProtoGCD: Unified and Unbiased Prototype Learning for Generalized Category Discovery</title>
      <link>http://arxiv.org/abs/2504.03755v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IEEE TPAMI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ProtoGCD的统一且无偏的原型学习框架，用于解决广义类别发现（GCD）问题，该问题需要模型自动聚类和发现新的类别，同时利用旧类别的标注样本。该框架在解决旧类和新类不平衡、对比学习忽视潜在正样本以及与聚类目标解耦等问题上取得了显著成效。&lt;h4&gt;背景&lt;/h4&gt;广义类别发现（GCD）是一个实用但未充分探索的问题，需要模型利用旧类别的标注样本自动聚类和发现新的类别。然而，未标注的数据中既包含旧类别也包含新类别，这给模型带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种统一的、无偏的原型学习框架ProtoGCD，以解决GCD问题中旧类和新类不平衡、对比学习忽视潜在正样本以及与聚类目标解耦等问题。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种双级自适应伪标签机制以减轻确认偏差；2. 引入两个正则化项以帮助学习更适合GCD的表示；3. 设计了一种准则来估计新类别的数量；4. 将ProtoGCD扩展到检测未见过的异常值，实现任务级统一。&lt;h4&gt;主要发现&lt;/h4&gt;ProtoGCD在通用和细粒度数据集上都达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;ProtoGCD是一种有效解决GCD问题的方法，其在旧类和新类之间实现了统一的建模，并取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：广义类别发现（GCD）是一个实用但未充分探索的问题，它要求模型通过利用旧类别的标注样本来自动聚类和发现新的类别。挑战在于未标注数据中既包含旧类别也包含新类别。早期的工作利用参数化分类器的伪标签处理旧类和新类，导致它们之间不平衡的准确率。最近的方法采用对比学习，却忽视了潜在的正样本，并且与聚类目标解耦，导致偏差表示和次优结果。为了解决这些问题，我们引入了一个统一且无偏的原型学习框架，即ProtoGCD，其中旧类和新类通过联合原型和统一的学习目标进行建模，从而实现了旧类和新类之间的统一建模。具体来说，我们提出了一种双级自适应伪标签机制来减轻确认偏差，以及两个正则化项来共同帮助学习更适合GCD的表示。此外，为了实际考虑，我们制定了一种准则来估计新类别的数量。此外，我们将ProtoGCD扩展到检测未见过的异常值，实现了任务级的统一。综合实验表明，ProtoGCD在通用和细粒度数据集上都达到了最先进的性能。代码可在https://github.com/mashijie1028/ProtoGCD上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TPAMI.2025.3557502&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalized category discovery (GCD) is a pragmatic but underexploredproblem, which requires models to automatically cluster and discover novelcategories by leveraging the labeled samples from old classes. The challenge isthat unlabeled data contain both old and new classes. Early works leveragingpseudo-labeling with parametric classifiers handle old and new classesseparately, which brings about imbalanced accuracy between them. Recent methodsemploying contrastive learning neglect potential positives and are decoupledfrom the clustering objective, leading to biased representations andsub-optimal results. To address these issues, we introduce a unified andunbiased prototype learning framework, namely ProtoGCD, wherein old and newclasses are modeled with joint prototypes and unified learning objectives,{enabling unified modeling between old and new classes}. Specifically, wepropose a dual-level adaptive pseudo-labeling mechanism to mitigateconfirmation bias, together with two regularization terms to collectively helplearn more suitable representations for GCD. Moreover, for practicalconsiderations, we devise a criterion to estimate the number of new classes.Furthermore, we extend ProtoGCD to detect unseen outliers, achieving task-levelunification. Comprehensive experiments show that ProtoGCD achievesstate-of-the-art performance on both generic and fine-grained datasets. Thecode is available at https://github.com/mashijie1028/ProtoGCD.</description>
      <author>example@mail.com (Shijie Ma, Fei Zhu, Xu-Yao Zhang, Cheng-Lin Liu)</author>
      <guid isPermaLink="false">2504.03755v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Brain Network Classification Based on Graph Contrastive Learning and Graph Transformer</title>
      <link>http://arxiv.org/abs/2504.03740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures, uses tikz.sty&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PHGCL-DDGformer的新型模型，该模型结合了图对比学习和图变换器，有效提升了脑网络分类任务中的表征学习能力。&lt;h4&gt;背景&lt;/h4&gt;脑网络功能网络的动态特征描述对于阐明人类大脑功能机制具有重要意义。尽管图神经网络在功能网络分析方面取得了显著进展，但数据稀缺和监督不足等问题仍然存在。&lt;h4&gt;目的&lt;/h4&gt;为了解决训练数据有限和监督不足的局限性，本文提出了一种名为PHGCL-DDGformer的新型模型。&lt;h4&gt;方法&lt;/h4&gt;该模型通过整合图对比学习和图变换器，并实施自适应图增强策略，包括属性掩码和边扰动，以增强数据。此外，构建了双重域图变换器(DDGformer)模块，以整合局部和全局信息，并通过图对比学习框架最大化正负样本对之间的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，PHGCL-DDGformer模型在脑网络分类任务中优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;PHGCL-DDGformer模型通过有效提升表征学习能力，在脑网络分类任务中表现出色，为解决脑网络分析中的数据稀缺和监督不足问题提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;The dynamic characterization of functional brain networks is of great significance for elucidating the mechanisms of human brain function. Although graph neural networks have achieved remarkable progress in functional network analysis, challenges such as data scarcity and insufficient supervision persist. To address the limitations of limited training data and inadequate supervision, this paper proposes a novel model named PHGCL-DDGformer that integrates graph contrastive learning with graph transformers, effectively enhancing the representation learning capability for brain network classification tasks. To overcome the constraints of existing graph contrastive learning methods in brain network feature extraction, an adaptive graph augmentation strategy combining attribute masking and edge perturbation is implemented for data enhancement. Subsequently, a dual-domain graph transformer (DDGformer) module is constructed to integrate local and global information, where graph convolutional networks aggregate neighborhood features to capture local patterns while attention mechanisms extract global dependencies. Finally, a graph contrastive learning framework is established to maximize the consistency between positive and negative pairs, thereby obtaining high-quality graph representations. Experimental results on real-world datasets demonstrate that the PHGCL-DDGformer model outperforms existing state-of-the-art approaches in brain network classification tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The dynamic characterization of functional brain networks is of greatsignificance for elucidating the mechanisms of human brain function. Althoughgraph neural networks have achieved remarkable progress in functional networkanalysis, challenges such as data scarcity and insufficient supervisionpersist. To address the limitations of limited training data and inadequatesupervision, this paper proposes a novel model named PHGCL-DDGformer thatintegrates graph contrastive learning with graph transformers, effectivelyenhancing the representation learning capability for brain networkclassification tasks. To overcome the constraints of existing graph contrastivelearning methods in brain network feature extraction, an adaptive graphaugmentation strategy combining attribute masking and edge perturbation isimplemented for data enhancement. Subsequently, a dual-domain graph transformer(DDGformer) module is constructed to integrate local and global information,where graph convolutional networks aggregate neighborhood features to capturelocal patterns while attention mechanisms extract global dependencies. Finally,a graph contrastive learning framework is established to maximize theconsistency between positive and negative pairs, thereby obtaining high-qualitygraph representations. Experimental results on real-world datasets demonstratethat the PHGCL-DDGformer model outperforms existing state-of-the-art approachesin brain network classification tasks.</description>
      <author>example@mail.com (ZhiTeng Zhu, Lan Yao)</author>
      <guid isPermaLink="false">2504.03740v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Meshing of High-Dimensional Toroidal Manifolds from Quasi-Periodic Three-Body Problem Dynamics using Parameterization via Discrete One-Forms</title>
      <link>http://arxiv.org/abs/2504.03791v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种高维视觉计算机模型，该模型通过使用一种参数化技术，能够对任意高维嵌入空间中的环面流形进行拓扑精确建模和直观可视化，从而革新空间任务设计过程。&lt;h4&gt;背景&lt;/h4&gt;高维视觉计算机模型在空间任务设计中具有革命性的潜力，而环形限制三体问题（CR3BP）产生的高维环面流形对任务设计者具有重要意义。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的网格化技术，能够对CR3BP中的高维点云进行精确建模和可视化。&lt;h4&gt;方法&lt;/h4&gt;该方法将基于离散一形式的方法扩展到CR3BP中的准周期轨道轨迹上的高维点云，并应用一种与嵌入无关的三角形侧向性分配算法来增强网格。&lt;h4&gt;主要发现&lt;/h4&gt;该技术提供了高维拓扑结构的新型表面表示，这些结构以前仅以点或曲线的形式展示。这种方法展示了微分几何方法在表征具有复杂高维嵌入空间的流形方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;这些模型为动态系统的解决方案空间提供了新的模型和可视化方法，有望提高空间任务轨迹视觉检查和设计的实用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：高维视觉计算机模型有望革新空间任务设计过程。环形限制三体问题（CR3BP）产生了对任务设计者极具吸引力的高维环面流形。我们提出了一种网格化技术，利用一种与嵌入无关的参数化方法，在任意高维嵌入空间中对环面流形进行拓扑精确建模和直观可视化。这项工作描述了将基于离散一形式的方法扩展到CR3BP中准周期轨道轨迹上的高维点云的网格化方法。通过应用一种与嵌入无关的三角形侧向性分配算法，增强了生成的网格。这显著提高了将网格下投影到3D空间进行可视化后的可解释性。这些模型提供了高维拓扑结构的新型表面表示，这些结构以前仅以点或曲线的形式展示。这一成功证明了微分几何方法在表征具有复杂、高维嵌入空间的流形方面的有效性，为动态系统的解决方案空间的新模型和可视化奠定了基础。这种表示有望通过使计算表面可视化与分析方法应用于基础解流形，提高三体问题在空间任务轨迹视觉检查和设计中的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-dimensional visual computer models are poised to revolutionize the spacemission design process. The circular restricted three-body problem (CR3BP)gives rise to high-dimensional toroidal manifolds that are of immense interestto mission designers. We present a meshing technique which leverages anembedding-agnostic parameterization to enable topologically accurate modellingand intuitive visualization of toroidal manifolds in arbitrarilyhigh-dimensional embedding spaces. This work describes the extension of adiscrete one-form-based toroidal point cloud meshing method to high-dimensionalpoint clouds sampled along quasi-periodic orbital trajectories in the CR3BP.The resulting meshes are enhanced through the application of anembedding-agnostic triangle-sidedness assignment algorithm. This significantlyincreases the intuitiveness of interpreting the meshes after they aredownprojected to 3D for visualization. These models provide novel surface-basedrepresentations of high-dimensional topologies which have so far only beenshown as points or curves. This success demonstrates the effectiveness ofdifferential geometric methods for characterizing manifolds with complex,high-dimensional embedding spaces, laying the foundation for new models andvisualizations of high-dimensional solution spaces for dynamical systems. Suchrepresentations promise to enhance the utility of the three-body problem forthe visual inspection and design of space mission trajectories by enabling theapplication of proven computational surface visualization and analysis methodsto underlying solution manifolds.</description>
      <author>example@mail.com (Dante Basile, Xavier Tricoche, Martin Lo)</author>
      <guid isPermaLink="false">2504.03791v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>FAST: Federated Active Learning with Foundation Models for Communication-efficient Sampling and Training</title>
      <link>http://arxiv.org/abs/2504.03783v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FAST的联邦主动学习框架，旨在降低在人工参与学习过程中通信成本，同时减少标注工作。&lt;h4&gt;背景&lt;/h4&gt;Federated Active Learning（FAL）是一种在保持数据隐私的前提下，利用分布式客户端大量未标记数据的框架。然而，实际部署受限于高昂的标注成本和通信密集型采样过程。&lt;h4&gt;目的&lt;/h4&gt;探讨在人工参与学习过程中，如何以最小的标注工作减少通信成本。&lt;h4&gt;方法&lt;/h4&gt;提出了一种两阶段FAL框架，第一阶段利用基础模型进行弱标注，第二阶段专注于最不确定的样本进行细化。&lt;h4&gt;主要发现&lt;/h4&gt;通过利用基础模型的表征知识并将细化步骤整合到简化的工作流程中，FAST大幅降低了迭代主动采样产生的开销。&lt;h4&gt;结论&lt;/h4&gt;在医学和自然图像基准数据集上的实验表明，与现有FAL方法相比，FAST平均提高了4.36%的性能，并在有限的5%标注预算下将通信轮次减少了八倍。&lt;h4&gt;翻译&lt;/h4&gt;摘要：联邦主动学习（Federated Active Learning，简称FAL）作为一种能够在保护数据隐私的前提下，利用分布式客户端的大量未标记数据的框架，已经逐渐成为一个有前景的框架。然而，在实际部署中，它受到高标注成本和通信密集型采样过程的限制，尤其是在跨数据孤岛设置中，客户端拥有大量本地数据集时。本文针对一个关键问题进行了探讨：在人工参与学习过程中，如何以最少的标注工作来降低通信成本？现有的FAL方法通常依赖于将主动采样与联邦更新分开的迭代标注过程，导致多次昂贵的通信和标注。为此，我们引入了FAST，一个两阶段的FAL框架，它在初步阶段利用基础模型进行弱标注，随后在专注于最不确定样本的细化阶段。通过利用基础模型的表征知识并将细化步骤整合到一个简化的工作流程中，FAST大幅减少了迭代主动采样产生的开销。在多样化的医学和自然图像基准数据集上的大量实验表明，与现有FAL方法相比，FAST平均提高了4.36%的性能，并在有限的5%标注预算下将通信轮次减少了八倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Active Learning (FAL) has emerged as a promising framework toleverage large quantities of unlabeled data across distributed clients whilepreserving data privacy. However, real-world deployments remain limited by highannotation costs and communication-intensive sampling processes, particularlyin a cross-silo setting, when clients possess substantial local datasets. Thispaper addresses the crucial question: What is the best practice to reducecommunication costs in human-in-the-loop learning with minimal annotatoreffort? Existing FAL methods typically rely on iterative annotation processesthat separate active sampling from federated updates, leading to multiplerounds of expensive communication and annotation. In response, we introduceFAST, a two-pass FAL framework that harnesses foundation models for weaklabeling in a preliminary pass, followed by a refinement pass focusedexclusively on the most uncertain samples. By leveraging representationknowledge from foundation models and integrating refinement steps into astreamlined workflow, FAST substantially reduces the overhead incurred byiterative active sampling. Extensive experiments on diverse medical and naturalimage benchmarks demonstrate that FAST outperforms existing FAL methods by anaverage of 4.36% while reducing communication rounds eightfold under a limited5% labeling budget.</description>
      <author>example@mail.com (Haoyuan Li, Jindong Wang, Mathias Funk, Aaqib Saeed)</author>
      <guid isPermaLink="false">2504.03783v1</guid>
      <pubDate>Tue, 08 Apr 2025 14:27:10 +0800</pubDate>
    </item>
    <item>
      <title>Crash Time Matters: HybridMamba for Fine-Grained Temporal Localization in Traffic Surveillance Footage</title>
      <link>http://arxiv.org/abs/2504.03235v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HybridMamba的新型架构，用于在长视频监控中检测交通事故，该架构结合了视觉Transformer和状态空间时序建模，以实现精确的事故时间定位。&lt;h4&gt;背景&lt;/h4&gt;交通事故检测对于紧急响应和基础设施规划至关重要，但由于事故事件短暂且罕见，这一任务仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够准确定位交通事故发生时间的算法。&lt;h4&gt;方法&lt;/h4&gt;HybridMamba使用多级令牌压缩和分层时序处理，以保持计算效率，同时不牺牲时间分辨率。&lt;h4&gt;主要发现&lt;/h4&gt;在爱荷华州交通部的大规模数据集上评估，HybridMamba的平均绝对误差为1.50秒，其中65.2%的预测与真实值相差在一秒以内。它在参数数量显著少于TimeChat和VideoLLaMA2等最近视频语言模型的情况下，性能提升了最多2.8秒。结果表明，HybridMamba在2到40分钟的视频上具有强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;HybridMamba为交通监控中的细粒度时间定位提供了一种稳健且高效的解决方案。代码将在论文发表后发布。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在长视频监控中检测交通事故对于紧急响应和基础设施规划至关重要，但由于事故事件短暂且罕见，这一任务仍然具有挑战性。我们引入了HybridMamba，这是一种结合视觉Transformer和状态空间时序建模的新架构，以实现精确的事故时间定位。我们的方法使用多级令牌压缩和分层时序处理，以保持计算效率，同时不牺牲时间分辨率。在爱荷华州交通部的大规模数据集上评估，HybridMamba的平均绝对误差为1.50秒，其中65.2%的预测与真实值相差在一秒以内。它在参数数量显著少于TimeChat和VideoLLaMA2等最近视频语言模型的情况下，性能提升了最多2.8秒。结果表明，HybridMamba在2到40分钟的视频上具有强大的泛化能力。HybridMamba为交通监控中的细粒度时间定位提供了一种稳健且高效的解决方案。代码将在论文发表后发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic crash detection in long-form surveillance videos is critical foremergency response and infrastructure planning but remains difficult due to thebrief and rare nature of crash events. We introduce HybridMamba, a novelarchitecture that combines visual transformers with state-space temporalmodeling to achieve accurate crash time localization. Our method usesmulti-level token compression and hierarchical temporal processing to remaincomputationally efficient without sacrificing temporal resolution. Evaluated ona large-scale dataset from the Iowa Department of Transportation, HybridMambaachieves a mean absolute error of 1.50 seconds, with 65.2 percent ofpredictions within one second of the ground truth. It outperforms recentvideo-language models such as TimeChat and VideoLLaMA2 by up to 2.8 seconds,while using significantly fewer parameters. Our results demonstrate stronggeneralization across videos ranging from 2 to 40 minutes in diverseconditions. HybridMamba offers a robust and efficient solution for fine-grainedtemporal localization in traffic surveillance. The code will be released uponpublication.</description>
      <author>example@mail.com (Ibne Farabi Shihab, Anuj Sharma)</author>
      <guid isPermaLink="false">2504.03235v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
  <item>
      <title>Autonomous and Self-Adapting System for Synthetic Media Detection and Attribution</title>
      <link>http://arxiv.org/abs/2504.03615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了自主自适应合成媒体识别系统的概念，该系统能够检测合成图像并归因于已知来源，同时无需人工干预就能自主识别和纳入新型生成器。通过采用开放集识别策略和可演化的嵌入空间，系统能够区分已知和未知来源，并使用无监督聚类方法将未知样本聚集成高置信度簇，持续优化决策边界，从而保持对生成模型演变过程中的稳健检测和归因性能。&lt;h4&gt;背景&lt;/h4&gt;随着生成式人工智能的快速发展，合成图像的生成技术越来越高级，虽然有益于许多领域，但也带来了虚假信息、欺诈等风险。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够自主识别和适应新型生成器的合成媒体识别系统。&lt;h4&gt;方法&lt;/h4&gt;采用开放集识别策略、可演化的嵌入空间，以及无监督聚类方法。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在性能上显著优于现有方法，是迈向通用、适应性强的人工智能时代法医系统的重要一步。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效应对生成模型快速发展的挑战，为合成媒体识别提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Rapid advances in generative AI have enabled the creation of highly realisticsynthetic images, which, while beneficial in many domains, also pose seriousrisks in terms of disinformation, fraud, and other malicious applications.Current synthetic image identification systems are typically static, relying onfeature representations learned from known generators; as new generative modelsemerge, these systems suffer from severe performance degradation. In thispaper, we introduce the concept of an autonomous self-adaptive synthetic mediaidentification system -- one that not only detects synthetic images andattributes them to known sources but also autonomously identifies andincorporates novel generators without human intervention. Our approachleverages an open-set identification strategy with an evolvable embedding spacethat distinguishes between known and unknown sources. By employing anunsupervised clustering method to aggregate unknown samples intohigh-confidence clusters and continuously refining its decision boundaries, oursystem maintains robust detection and attribution performance even as thegenerative landscape evolves. Extensive experiments demonstrate that our methodsignificantly outperforms existing approaches, marking a crucial step towarduniversal, adaptable forensic systems in the era of rapidly advancinggenerative models.</description>
      <author>example@mail.com (Aref Azizpour, Tai D. Nguyen, Matthew C. Stamm)</author>
      <guid isPermaLink="false">2504.03615v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>BabyLM's First Words: Word Segmentation as a Phonological Probing Task</title>
      <link>http://arxiv.org/abs/2504.03338v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 10 figures, submitted to CoNLL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用大型语言模型（LLMs）进行语音分析的问题，并提出了一种基于词汇分割的语音探查任务，以研究基于儿童语音训练的跨31种语言的音素语言模型所学习的表示。&lt;h4&gt;背景&lt;/h4&gt;语音分析使用LLMs困难，因为缺乏除英语外的语音基准，且LLMs中使用的标准输入表示（图形字的子词）不适用于分析音素的表示。&lt;h4&gt;目的&lt;/h4&gt;通过词汇分割作为语音探查任务，研究基于音素的、在儿童语音上训练的语言模型所学习的表示。&lt;h4&gt;方法&lt;/h4&gt;使用无监督方法从训练模型中提取词汇边界，并利用预测误差在词汇开始处达到峰值的现象。同时，使用线性探针识别模型隐式跟踪词汇边界，即使这些边界没有出现在训练中。&lt;h4&gt;主要发现&lt;/h4&gt;该跨语言工作证实了语言习得统计学习理论，并实证地激励了训练子词标记器的新方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为语音分析提供了新的视角，并有助于提高基于音素的语言模型的性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the difficulty of phonological analysis using large language models (LLMs) and proposes a phonological probing task based on word segmentation to study the representations learned by phoneme-based language models trained on child-directed speech across 31 languages. Using unsupervised methods to extract word boundaries from a trained model based on the observation that prediction-error peaks at the start of words, and also using linear probes to identify that these models implicitly track word boundaries even when they do not appear in training. This cross-lingual work corroborates statistical learning theories of acquisition and empirically motivates new methods for training subword tokenizers.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Language models provide a key framework for studying linguistic theoriesbased on prediction, but phonological analysis using large language models(LLMs) is difficult; there are few phonological benchmarks beyond English andthe standard input representation used in LLMs (subwords of graphemes) is notsuitable for analyzing the representation of phonemes. In this work, wedemonstrate how word segmentation can be used as a phonological probing task,allowing us to study the representations learned by phoneme-based languagemodels trained on child-directed speech across 31 languages. Followingcomputational models of word segmentation, we present unsupervised methods forextracting word boundaries from a trained model using the observation thatprediction-error peaks at the start of words. We also use linear probes toidentify that these models implicitly track word boundaries, even when they donot appear in training. This cross-lingual work corroborates statisticallearning theories of acquisition and empirically motivates new methods fortraining subword tokenizers.</description>
      <author>example@mail.com (Zébulon Goriely)</author>
      <guid isPermaLink="false">2504.03338v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>RingMoE: Mixture-of-Modality-Experts Multi-Modal Foundation Models for Universal Remote Sensing Image Interpretation</title>
      <link>http://arxiv.org/abs/2504.03166v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;RingMoE是一种统一的多模态遥感基础模型，能够有效处理遥感数据的多模态特性，提高了遥感分析的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;现有的遥感模型主要处理单一或有限的模态，忽略了遥感观察的内在多模态性质。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一基本差距，提出RingMoE模型，旨在提高遥感分析的性能。&lt;h4&gt;方法&lt;/h4&gt;RingMoE模型包含三个关键创新：(1) 分层混合专家（MoE）架构，能够建模模态内知识并捕捉跨模态依赖；(2) 物理信息自监督学习，将传感器特定的辐射特性嵌入到预训练目标中；(3) 动态专家剪枝，实现自适应模型压缩。&lt;h4&gt;主要发现&lt;/h4&gt;RingMoE在23个基准测试中优于现有的基础模型，并在多个领域得到应用和验证。&lt;h4&gt;结论&lt;/h4&gt;RingMoE模型在提高遥感分析性能方面取得了显著进展，并已在多个领域得到应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着基础模型的快速发展，以自监督的方式革新了视觉表示学习。然而，它们在遥感（RS）中的应用仍然受到一个基本差距的限制：现有的模型主要处理单一或有限的模态，忽略了遥感观察的内在多模态性质。光学、合成孔径雷达（SAR）和多光谱数据提供了互补的见解，显著减少了单源分析中的固有模糊性和不确定性。为了弥合这一差距，我们引入了RingMoE，一个具有147亿参数的统一多模态RS基础模型，在来自九颗卫星的4000万多模态RS图像上进行了预训练。RingMoE包含三个关键创新：(1) 由模态专用、协作和共享专家组成的分层混合专家（MoE）架构，有效地建模模态内知识，同时捕捉跨模态依赖以减轻模态表示之间的冲突；(2) 物理信息自监督学习，将传感器特定的辐射特性明确嵌入到预训练目标中；(3) 动态专家剪枝，在保持性能的同时，将模型压缩从147亿参数降至10亿参数，便于在地球观测应用中的高效部署。在涵盖六个关键RS任务（即分类、检测、分割、跟踪、变化检测和深度估计）的23个基准测试中评估，RingMoE优于现有的基础模型，并设定了新的SOTA，证明了从单模态到多模态场景的显著适应性。除了理论进步之外，它已在多个部门得到部署和试用，包括应急响应、土地管理、海洋科学和城市规划。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of foundation models has revolutionized visualrepresentation learning in a self-supervised manner. However, their applicationin remote sensing (RS) remains constrained by a fundamental gap: existingmodels predominantly handle single or limited modalities, overlooking theinherently multi-modal nature of RS observations. Optical, synthetic apertureradar (SAR), and multi-spectral data offer complementary insights thatsignificantly reduce the inherent ambiguity and uncertainty in single-sourceanalysis. To bridge this gap, we introduce RingMoE, a unified multi-modal RSfoundation model with 14.7 billion parameters, pre-trained on 400 millionmulti-modal RS images from nine satellites. RingMoE incorporates three keyinnovations: (1) A hierarchical Mixture-of-Experts (MoE) architecturecomprising modal-specialized, collaborative, and shared experts, effectivelymodeling intra-modal knowledge while capturing cross-modal dependencies tomitigate conflicts between modal representations; (2) Physics-informedself-supervised learning, explicitly embedding sensor-specific radiometriccharacteristics into the pre-training objectives; (3) Dynamic expert pruning,enabling adaptive model compression from 14.7B to 1B parameters whilemaintaining performance, facilitating efficient deployment in Earth observationapplications. Evaluated across 23 benchmarks spanning six key RS tasks (i.e.,classification, detection, segmentation, tracking, change detection, and depthestimation), RingMoE outperforms existing foundation models and sets new SOTAs,demonstrating remarkable adaptability from single-modal to multi-modalscenarios. Beyond theoretical progress, it has been deployed and trialed inmultiple sectors, including emergency response, land management, marinesciences, and urban planning.</description>
      <author>example@mail.com (Hanbo Bi, Yingchao Feng, Boyuan Tong, Mengyu Wang, Haichen Yu, Yongqiang Mao, Hao Chang, Wenhui Diao, Peijin Wang, Yue Yu, Hanyang Peng, Yehong Zhang, Kun Fu, Xian Sun)</author>
      <guid isPermaLink="false">2504.03166v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>MedSAM2: Segment Anything in 3D Medical Images and Videos</title>
      <link>http://arxiv.org/abs/2504.03600v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  https://medsam2.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了MedSAM2，这是一个用于3D图像和视频分割的promptable分割基础模型，通过大量医学数据集进行微调，实现了高效、可扩展和高质量的分割。&lt;h4&gt;背景&lt;/h4&gt;医学图像和视频分割对精准医学至关重要，目前2D图像分割模型发展迅速，但针对3D图像和视频的通用模型研究有限。&lt;h4&gt;目的&lt;/h4&gt;开发一个适用于3D图像和视频分割的通用模型MedSAM2，并通过大规模用户研究验证其性能。&lt;h4&gt;方法&lt;/h4&gt;在包含455,000个3D图像-掩码对和76,000帧的大规模医学数据集上微调Segment Anything Model 2，并实施人机交互流程以创建大规模数据集。&lt;h4&gt;主要发现&lt;/h4&gt;MedSAM2在广泛的器官、病变和成像模态上优于现有模型，通过标注5,000个CT病变、3,984个肝脏MRI病变和251,550个超声心动图视频帧，证明了MedSAM2可以减少超过85%的人工成本。&lt;h4&gt;结论&lt;/h4&gt;MedSAM2是一种实用工具，支持研究环境和医疗保健环境中高效、可扩展和高质量的分割。&lt;h4&gt;翻译&lt;/h4&gt;Medical image and video segmentation is a critical task for precision medicine, which has witnessed considerable progress in developing task or modality-specific and generalist models for 2D images. However, there have been limited studies on building general-purpose models for 3D images and videos with comprehensive user studies. Here, we present MedSAM2, a promptable segmentation foundation model for 3D image and video segmentation. The model is developed by fine-tuning the Segment Anything Model 2 on a large medical dataset with over 455,000 3D image-mask pairs and 76,000 frames, outperforming previous models across a wide range of organs, lesions, and imaging modalities. Furthermore, we implement a human-in-the-loop pipeline to facilitate the creation of large-scale datasets resulting in, to the best of our knowledge, the most extensive user study to date, involving the annotation of 5,000 CT lesions, 3,984 liver MRI lesions, and 251,550 echocardiogram video frames, demonstrating that MedSAM2 can reduce manual costs by more than 85%. MedSAM2 is also integrated into widely used platforms with user-friendly interfaces for local and cloud deployment, making it a practical tool for supporting efficient, scalable, and high-quality segmentation in both research and healthcare environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image and video segmentation is a critical task for precisionmedicine, which has witnessed considerable progress in developing task ormodality-specific and generalist models for 2D images. However, there have beenlimited studies on building general-purpose models for 3D images and videoswith comprehensive user studies. Here, we present MedSAM2, a promptablesegmentation foundation model for 3D image and video segmentation. The model isdeveloped by fine-tuning the Segment Anything Model 2 on a large medicaldataset with over 455,000 3D image-mask pairs and 76,000 frames, outperformingprevious models across a wide range of organs, lesions, and imaging modalities.Furthermore, we implement a human-in-the-loop pipeline to facilitate thecreation of large-scale datasets resulting in, to the best of our knowledge,the most extensive user study to date, involving the annotation of 5,000 CTlesions, 3,984 liver MRI lesions, and 251,550 echocardiogram video frames,demonstrating that MedSAM2 can reduce manual costs by more than 85%. MedSAM2 isalso integrated into widely used platforms with user-friendly interfaces forlocal and cloud deployment, making it a practical tool for supportingefficient, scalable, and high-quality segmentation in both research andhealthcare environments.</description>
      <author>example@mail.com (Jun Ma, Zongxin Yang, Sumin Kim, Bihui Chen, Mohammed Baharoon, Adibvafa Fallahpour, Reza Asakereh, Hongwei Lyu, Bo Wang)</author>
      <guid isPermaLink="false">2504.03600v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Optimization of a Triangular Delaunay Mesh Generator using Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2504.03610v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于强化学习的三角形Delaunay网格生成器，用于优化网格质量。&lt;h4&gt;背景&lt;/h4&gt;研究Delaunay网格生成，并引入了图神经网络和标准Delaunay算法。&lt;h4&gt;目的&lt;/h4&gt;提高网格质量，实现网格生成、改进和生成不同分辨率的网格。&lt;h4&gt;方法&lt;/h4&gt;使用图神经网络分布和修改顶点，结合标准Delaunay算法进行三角剖分。&lt;h4&gt;主要发现&lt;/h4&gt;所学的网格生成器输出的网格与Triangle和DistMesh等流行的Delaunay网格生成器相当。&lt;h4&gt;结论&lt;/h4&gt;提出的网格生成器在多种任务中表现出色，包括网格生成、网格改进和生成可变分辨率网格。&lt;h4&gt;翻译&lt;/h4&gt;In this work we introduce a triangular Delaunay mesh generator that can be trained using reinforcement learning to maximize a given mesh quality metric. Our mesh generator consists of a graph neural network that distributes and modifies vertices, and a standard Delaunay algorithm to triangulate the vertices. We explore various design choices and evaluate our mesh generator on various tasks including mesh generation, mesh improvement, and producing variable resolution meshes. The learned mesh generator outputs meshes that are comparable to those produced by Triangle and DistMesh, two popular Delaunay-based mesh generators.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work we introduce a triangular Delaunay mesh generator that can betrained using reinforcement learning to maximize a given mesh quality metric.Our mesh generator consists of a graph neural network that distributes andmodifies vertices, and a standard Delaunay algorithm to triangulate thevertices. We explore various design choices and evaluate our mesh generator onvarious tasks including mesh generation, mesh improvement, and producingvariable resolution meshes. The learned mesh generator outputs meshes that arecomparable to those produced by Triangle and DistMesh, two popularDelaunay-based mesh generators.</description>
      <author>example@mail.com (Will Thacher, Per-Olof Persson, Yulong Pan)</author>
      <guid isPermaLink="false">2504.03610v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>PF3Det: A Prompted Foundation Feature Assisted Visual LiDAR 3D Detector</title>
      <link>http://arxiv.org/abs/2504.03563v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is accepted to the CVPR 2025 Workshop on Distillation of  Foundation Models for Autonomous Driving (WDFM-AD)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Prompted Foundational 3D Detector (PF3Det)的3D目标检测方法，该方法结合了基础模型编码器和软提示技术，以增强LiDAR和摄像头特征的融合，实现了在有限训练数据下的高效3D检测。&lt;h4&gt;背景&lt;/h4&gt;3D目标检测对于自动驾驶至关重要，它需要利用LiDAR点云提供的精确深度信息和摄像头图像提供的丰富语义信息。然而，由于领域差距，有效地融合LiDAR点和图像仍然具有挑战性，并且许多模型由于高质量标注数据的有限性和高昂的成本而性能受限。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的多模态3D目标检测方法，以解决当前3D目标检测中的挑战。&lt;h4&gt;方法&lt;/h4&gt;PF3Det方法结合了基础模型的预训练和提示工程技术，通过整合基础模型编码器和软提示来增强LiDAR和摄像头特征的融合。&lt;h4&gt;主要发现&lt;/h4&gt;PF3Det在nuScenes数据集上实现了最先进的结果，在有限的训练数据下提高了NDS（一个度量指标）1.19%和mAP（平均精度）2.42%。&lt;h4&gt;结论&lt;/h4&gt;PF3Det展示了在3D检测中的效率，特别是在有限标注数据的情况下。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D物体检测对于自动驾驶至关重要，它利用LiDAR点云精确的深度信息和摄像头图像丰富的语义信息。因此，结合这两种模态的多模态方法提供了更稳健的检测结果。然而，由于领域差距，有效地融合LiDAR点和图像仍然具有挑战性。此外，许多模型的性能受限于高质量标注数据量，这很难创建。近年来，基于大规模预训练的不同模态的基础模型的发展，使得多模态融合更加完善。结合提示工程技术以实现高效训练，我们提出了Prompted Foundational 3D Detector (PF3Det)，该技术整合了基础模型编码器和软提示来增强LiDAR-摄像头特征融合。PF3Det在有限的训练数据下实现了最先进的成果，在nuScenes数据集上提高了NDS 1.19%和mAP 2.42%，证明了其在3D检测中的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D object detection is crucial for autonomous driving, leveraging both LiDARpoint clouds for precise depth information and camera images for rich semanticinformation. Therefore, the multi-modal methods that combine both modalitiesoffer more robust detection results. However, efficiently fusing LiDAR pointsand images remains challenging due to the domain gaps. In addition, theperformance of many models is limited by the amount of high quality labeleddata, which is expensive to create. The recent advances in foundation models,which use large-scale pre-training on different modalities, enable bettermulti-modal fusion. Combining the prompt engineering techniques for efficienttraining, we propose the Prompted Foundational 3D Detector (PF3Det), whichintegrates foundation model encoders and soft prompts to enhance LiDAR-camerafeature fusion. PF3Det achieves the state-of-the-art results under limitedtraining data, improving NDS by 1.19% and mAP by 2.42% on the nuScenes dataset,demonstrating its efficiency in 3D detection.</description>
      <author>example@mail.com (Kaidong Li, Tianxiao Zhang, Kuan-Chuan Peng, Guanghui Wang)</author>
      <guid isPermaLink="false">2504.03563v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Robust Human Registration with Body Part Segmentation on Noisy Point Clouds</title>
      <link>http://arxiv.org/abs/2504.03602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种混合方法，用于将人体网格注册到3D点云中，以改善人体姿态估计和分割的准确性。&lt;h4&gt;背景&lt;/h4&gt;由于真实世界数据中的噪声和背景杂波，将人体网格注册到3D点云中对于增强现实和人类-机器人交互等应用至关重要，但通常会产生不精确的结果。&lt;h4&gt;目的&lt;/h4&gt;提高人体姿态估计和分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;方法首先为单个点分配身体部分标签，然后引导两步SMPL-X拟合：使用身体部分质心来估计初始姿态和方向，接着全局优化点云对齐。此外，还证明拟合的人体网格可以细化身体部分标签，从而提高分割效果。&lt;h4&gt;主要发现&lt;/h4&gt;在杂乱和噪声的真实世界数据集InterCap、EgoBody和BEHAVE上，该方法在姿态估计和分割精度方面显著优于先前的方法。&lt;h4&gt;结论&lt;/h4&gt;该方法显著提高了人体网格到3D点云注册的精度，对于增强现实和人类-机器人交互等领域具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;摘要：将人体网格注册到3D点云中对于增强现实和人类-机器人交互等应用至关重要，但由于真实世界数据中的噪声和背景杂波，常常会产生不精确的结果。我们提出了一种混合方法，该方法将身体部分分割结合到网格拟合过程中，从而提高了人体姿态估计和分割的准确性。该方法首先为单个点分配身体部分标签，然后引导两步SMPL-X拟合：使用身体部分质心来估计初始姿态和方向，接着全局优化点云对齐。此外，我们还证明拟合的人体网格可以细化身体部分标签，从而提高分割效果。在杂乱和噪声的真实世界数据集InterCap、EgoBody和BEHAVE上进行的评估表明，我们的方法在姿态估计和分割精度方面显著优于先前的方法。代码和结果可在我们的项目网站上找到：https://segfit.github.io&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Registering human meshes to 3D point clouds is essential for applicationssuch as augmented reality and human-robot interaction but often yieldsimprecise results due to noise and background clutter in real-world data. Weintroduce a hybrid approach that incorporates body-part segmentation into themesh fitting process, enhancing both human pose estimation and segmentationaccuracy. Our method first assigns body part labels to individual points, whichthen guide a two-step SMPL-X fitting: initial pose and orientation estimationusing body part centroids, followed by global refinement of the point cloudalignment. Additionally, we demonstrate that the fitted human mesh can refinebody part labels, leading to improved segmentation. Evaluations on thecluttered and noisy real-world datasets InterCap, EgoBody, and BEHAVE show thatour approach significantly outperforms prior methods in both pose estimationand segmentation accuracy. Code and results are available on our projectwebsite: https://segfit.github.io</description>
      <author>example@mail.com (Kai Lascheit, Daniel Barath, Marc Pollefeys, Leonidas Guibas, Francis Engelmann)</author>
      <guid isPermaLink="false">2504.03602v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating the Impact of Electrode Shift on Classification Performance in Electromyography-Based Motion Prediction Using Sliding-Window Normalization</title>
      <link>http://arxiv.org/abs/2504.03196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在运动估计中，尤其是EMG信号的应用中，如何减少电极位移带来的分类性能下降。&lt;h4&gt;背景&lt;/h4&gt;EMG信号在假肢、辅助服装和康复等领域有广泛应用。尽管运动估计技术取得了进展，但在跨个体泛化、电极位移和日常变化方面仍存在挑战。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过技术手段减少电极位移对EMG信号分类性能的影响。&lt;h4&gt;方法&lt;/h4&gt;提出了一种滑动窗口归一化（SWN）技术，结合z-score归一化和滑动窗口方法来减少电极位移导致的分类性能下降。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SWN技术可以将分类误差降低到-1.0%，相较于未归一化的情况（-7.6%）提高了6.6%的分类准确率。当SWN与使用多个电极位置混合的策略结合时，分类准确率比基准情况提高了2.4%。&lt;h4&gt;结论&lt;/h4&gt;SWN技术能够有效减少电极位移导致的性能下降，从而增强基于EMG的运动估计系统的实用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：电肌电图（EMG）信号在许多应用中都有使用，包括假手、辅助服装和康复。最近在运动估计方面的进展提高了性能，但跨个体泛化、电极位移和日常变化仍然存在挑战。当发生电极位移时，迁移学习和对抗性域适应通过减少性能差距至-1%（八类场景）来提高分类性能。然而，对于迁移学习中的再训练或对抗性域适应中的训练，还需要更多的数据。为了解决这个问题，我们研究了一种滑动窗口归一化（SWN）技术，在实时预测场景中。这种方法结合了z-score归一化和滑动窗口方法来减少电极位移导致的分类性能下降。我们使用涉及右臂的目标轨迹跟踪任务的实验数据验证了SWN的有效性。对于从EMG信号中获得的三个动作分类（休息、屈曲和伸展肘部），我们的离线分析表明，SWN将分类差异准确率降低到-1.0%，相较于未归一化的情况（-7.6%）提高了6.6%。此外，当SWN与使用多个电极位置混合的策略结合时，分类准确率比基准情况提高了2.4%。这些结果表明，SWN可以有效地减少由电极位移引起的性能下降，从而增强基于EMG的运动估计系统的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electromyography (EMG) signals are used in many applications, includingprosthetic hands, assistive suits, and rehabilitation. Recent advances inmotion estimation have improved performance, yet challenges remain incross-subject generalization, electrode shift, and daily variations. Whenelectrode shift occurs, both transfer learning and adversarial domainadaptation improve classification performance by reducing the performance gapto -1\% (eight-class scenario). However, additional data are needed forre-training in transfer learning or for training in adversarial domainadaptation. To address this issue, we investigated a sliding-windownormalization (SWN) technique in a real-time prediction scenario. This methodcombines z-score normalization with a sliding-window approach to reduce thedecline in classification performance caused by electrode shift. We validatedthe effectiveness of SWN using experimental data from a target trajectorytracking task involving the right arm. For three motions classification (rest,flexion, and extension of the elbow) obtained from EMG signals, our offlineanalysis showed that SWN reduced the differential classification accuracy to-1.0\%, representing a 6.6\% improvement compared to the case withoutnormalization (-7.6\%). Furthermore, when SWN was combined with a strategy thatuses a mixture of multiple electrode positions, classification accuracyimproved by an additional 2.4\% over the baseline. These results suggest thatSWN can effectively reduce the performance degradation caused by electrodeshift, thereby enhancing the practicality of EMG-based motion estimationsystems.</description>
      <author>example@mail.com (Taichi Tanaka, Isao Nambu, Yasuhiro Wada)</author>
      <guid isPermaLink="false">2504.03196v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>MME-Unify: A Comprehensive Benchmark for Unified Multimodal Understanding and Generation Models</title>
      <link>http://arxiv.org/abs/2504.03641v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://mme-unify.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个全面的评估框架，用于评估统一的多模态语言模型（U-MLLMs），并发现现有U-MLLMs在处理混合模态任务方面存在性能差距。&lt;h4&gt;背景&lt;/h4&gt;现有的MLLM基准在评估U-MLLMs时面临挑战，包括缺乏标准化基准和混合模态生成基准。&lt;h4&gt;目的&lt;/h4&gt;设计一个评估框架，以系统地评估U-MLLMs。&lt;h4&gt;方法&lt;/h4&gt;该框架包括标准化传统任务评估、统一任务评估和综合模型基准测试。标准化传统任务评估从12个数据集中采样，涵盖10个任务和30个子任务。统一任务评估引入了5个新的测试多模态推理的任务。综合模型基准测试评估了12个领先的U-MLLMs，包括Janus-Pro、EMU3、VILA-U和Gemini2-flash，以及专门的理解和生成模型。&lt;h4&gt;主要发现&lt;/h4&gt;发现现有U-MLLMs在处理混合模态任务方面存在显著的性能差距。&lt;h4&gt;结论&lt;/h4&gt;需要更强大的模型来有效处理混合模态任务。&lt;h4&gt;翻译&lt;/h4&gt;Existing MLLM benchmarks face significant challenges in evaluating UnifiedMLLMs (U-MLLMs) due to: 1) lack of standardized benchmarks for traditional tasks, leading to inconsistent comparisons; 2) absence of benchmarks for mixed-modality generation, which fails to assess multimodal reasoning capabilities. We present a comprehensive evaluation framework designed to systematically assess U-MLLMs. Our benchmark includes: Standardized TraditionalTask Evaluation. We sample from 12 datasets, covering 10 tasks with 30 subtasks, ensuring consistent and fair comparisons across studies. 2. UnifiedTask Assessment. We introduce five novel tasks testing multimodal reasoning, including image editing, commonsense QA with image generation, and geometric reasoning. 3. Comprehensive Model Benchmarking. We evaluate 12 leading U-MLLMs, such as Janus-Pro, EMU3, VILA-U, and Gemini2-flash, alongside specialized understanding (e.g., Claude-3.5-Sonnet) and generation models (e.g., DALL-E-3). Our findings reveal substantial performance gaps in existing U-MLLMs, highlighting the need for more robust models capable of handling mixed-modality tasks effectively. The code and evaluation data can be found in https://mme-unify.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing MLLM benchmarks face significant challenges in evaluating UnifiedMLLMs (U-MLLMs) due to: 1) lack of standardized benchmarks for traditionaltasks, leading to inconsistent comparisons; 2) absence of benchmarks formixed-modality generation, which fails to assess multimodal reasoningcapabilities. We present a comprehensive evaluation framework designed tosystematically assess U-MLLMs. Our benchmark includes: Standardized TraditionalTask Evaluation. We sample from 12 datasets, covering 10 tasks with 30subtasks, ensuring consistent and fair comparisons across studies." 2. UnifiedTask Assessment. We introduce five novel tasks testing multimodal reasoning,including image editing, commonsense QA with image generation, and geometricreasoning. 3. Comprehensive Model Benchmarking. We evaluate 12 leading U-MLLMs,such as Janus-Pro, EMU3, VILA-U, and Gemini2-flash, alongside specializedunderstanding (e.g., Claude-3.5-Sonnet) and generation models (e.g., DALL-E-3).Our findings reveal substantial performance gaps in existing U-MLLMs,highlighting the need for more robust models capable of handling mixed-modalitytasks effectively. The code and evaluation data can be found inhttps://mme-unify.github.io/.</description>
      <author>example@mail.com (Wulin Xie, Yi-Fan Zhang, Chaoyou Fu, Yang Shi, Bingyan Nie, Hongkai Chen, Zhang Zhang, Liang Wang, Tieniu Tan)</author>
      <guid isPermaLink="false">2504.03641v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>AutoSSVH: Exploring Automated Frame Sampling for Efficient Self-Supervised Video Hashing</title>
      <link>http://arxiv.org/abs/2504.03587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR'25. 11 pages, 5 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AutoSSVH的Self-Supervised Video Hashing方法，通过对抗性帧采样和基于哈希的对比学习，提高了视频哈希编码的效率和检索性能。&lt;h4&gt;背景&lt;/h4&gt;现有的Self-Supervised Video Hashing方法依赖于随机帧采样，忽略了帧间的信息密度和重建难度，导致哈希码质量不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架AutoSSVH，旨在通过改进帧采样和引入新的哈希对比学习策略，提高视频哈希编码的性能。&lt;h4&gt;方法&lt;/h4&gt;AutoSSVH采用对抗性帧采样自动选择信息丰富的挑战性帧，增强编码能力。同时，引入哈希组件投票策略和基于点到集的哈希对比目标，以捕捉视频间的复杂语义关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AutoSSVH在检索效率和性能方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;AutoSSVH是一种有效的视频哈希编码方法，能够提高视频检索的效率和准确性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a new framework called AutoSSVH for Self-Supervised Video Hashing, which improves the efficiency and retrieval performance of video hashing through adversarial frame sampling and hash-based contrastive learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-Supervised Video Hashing (SSVH) compresses videos into hash codes forefficient indexing and retrieval using unlabeled training videos. Existingapproaches rely on random frame sampling to learn video features and treat allframes equally. This results in suboptimal hash codes, as it ignoresframe-specific information density and reconstruction difficulty. To addressthis limitation, we propose a new framework, termed AutoSSVH, that employsadversarial frame sampling with hash-based contrastive learning. Ouradversarial sampling strategy automatically identifies and selects challengingframes with richer information for reconstruction, enhancing encodingcapability. Additionally, we introduce a hash component voting strategy and apoint-to-set (P2Set) hash-based contrastive objective, which help capturecomplex inter-video semantic relationships in the Hamming space and improve thediscriminability of learned hash codes. Extensive experiments demonstrate thatAutoSSVH achieves superior retrieval efficacy and efficiency compared tostate-of-the-art approaches. Code is available athttps://github.com/EliSpectre/CVPR25-AutoSSVH.</description>
      <author>example@mail.com (Niu Lian, Jun Li, Jinpeng Wang, Ruisheng Luo, Yaowei Wang, Shu-Tao Xia, Bin Chen)</author>
      <guid isPermaLink="false">2504.03587v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Training Enhances Machine Learning Potentials for Long-Lasting Molecular Dynamics</title>
      <link>http://arxiv.org/abs/2504.03521v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为动态训练（DT）的方法，旨在提高分子动力学（MD）模拟的模型性能，并在氢分子与锚定在石墨烯空位处的钯团簇的复杂系统中取得了比传统方法更优越的预测精度。&lt;h4&gt;背景&lt;/h4&gt;分子动力学模拟在计算物理学和化学中至关重要，但与从头计算方法相比，机器学习方法在长期模拟中的准确性仍然有限。&lt;h4&gt;目的&lt;/h4&gt;提出动态训练（DT）方法，以增强模型在长期分子动力学模拟中的性能。&lt;h4&gt;方法&lt;/h4&gt;将动态训练（DT）应用于等变图神经网络（EGNN），用于模拟氢分子与钯团簇的相互作用。&lt;h4&gt;主要发现&lt;/h4&gt;动态训练（DT）在模拟中显示出比传统方法更高的预测精度，并且其架构独立的设计确保了其在各种机器学习势能中的应用。&lt;h4&gt;结论&lt;/h4&gt;动态训练（DT）是一种实用的工具，可以推进分子动力学模拟的进展，尤其是在长期模拟中提高模型性能方面具有潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Molecular Dynamics (MD) simulations are vital for exploring complex systemsin computational physics and chemistry. While machine learning methodsdramatically reduce computational costs relative to ab initio methods, theiraccuracy in long-lasting simulations remains limited. Here we propose dynamictraining (DT), a method designed to enhance model performance over extended MDsimulations. Applying DT to an equivariant graph neural network (EGNN) on thechallenging system of a hydrogen molecule interacting with a palladium clusteranchored to a graphene vacancy demonstrates a superior prediction accuracycompared to conventional approaches. Crucially, the DT architecture-independentdesign ensures its applicability across diverse machine learning potentials,making it a practical tool for advancing MD simulations.</description>
      <author>example@mail.com (Ivan Žugec, Tin Hadži Veljković, Maite Alducin, J. Iñaki Juaristi)</author>
      <guid isPermaLink="false">2504.03521v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>RANa: Retrieval-Augmented Navigation</title>
      <link>http://arxiv.org/abs/2504.03524v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的基于大规模学习的导航方法，该方法能够利用先前操作收集的信息，通过引入检索增强的智能体和独特的智能体架构，在ObjectNav、ImageNav和Instance-ImageNav任务上显著提高性能。&lt;h4&gt;背景&lt;/h4&gt;现有的基于大规模学习的导航方法通常将每个场景视为新的问题，智能体在未知环境中以干净的记忆开始。然而，在实际环境中，智能体应该能够利用先前操作收集的信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，使智能体能够利用先前操作收集的信息，从而在未知环境中进行更有效的导航。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新的基于强化学习的检索增强智能体，该智能体能够查询从先前场景收集的数据库，并学习如何整合额外的上下文信息。该方法采用了一种独特的智能体架构，并使用视觉基础模型（FM）进行语义和几何理解。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在ObjectNav、ImageNav和Instance-ImageNav任务上进行了评估，结果表明检索技术允许零样本迁移，并在多个任务和环境之间显著提高了性能。&lt;h4&gt;结论&lt;/h4&gt;通过引入检索增强的智能体，可以显著提高基于大规模学习的导航方法的性能，使其在未知环境中更加有效。&lt;h4&gt;翻译&lt;/h4&gt;Methods for navigation based on large-scale learning typically treat each episode as a new problem, where the agent is spawned with a clean memory in an unknown environment. While these generalization capabilities to an unknown environment are extremely important, we claim that, in a realistic setting, an agent should have the capacity of exploiting information collected during earlier robot operations. We address this by introducing a new retrieval-augmented agent, trained with RL, capable of querying a database collected from previous episodes in the same environment and learning how to integrate this additional context information. We introduce a unique agent architecture for the general navigation task, evaluated on ObjectNav, ImageNav and Instance-ImageNav. Our retrieval and context encoding methods are data-driven and heavily employ vision foundation models (FM) for both semantic and geometric understanding. We propose new benchmarks for these settings and we show that retrieval allows zero-shot transfer across tasks and environments while significantly improving performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Methods for navigation based on large-scale learning typically treat eachepisode as a new problem, where the agent is spawned with a clean memory in anunknown environment. While these generalization capabilities to an unknownenvironment are extremely important, we claim that, in a realistic setting, anagent should have the capacity of exploiting information collected duringearlier robot operations. We address this by introducing a newretrieval-augmented agent, trained with RL, capable of querying a databasecollected from previous episodes in the same environment and learning how tointegrate this additional context information. We introduce a unique agentarchitecture for the general navigation task, evaluated on ObjectNav, ImageNavand Instance-ImageNav. Our retrieval and context encoding methods aredata-driven and heavily employ vision foundation models (FM) for both semanticand geometric understanding. We propose new benchmarks for these settings andwe show that retrieval allows zero-shot transfer across tasks and environmentswhile significantly improving performance.</description>
      <author>example@mail.com (Gianluca Monaci, Rafael S. Rezende, Romain Deffayet, Gabriela Csurka, Guillaume Bono, Hervé Déjean, Stéphane Clinchant, Christian Wolf)</author>
      <guid isPermaLink="false">2504.03524v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>ZFusion: An Effective Fuser of Camera and 4D Radar for 3D Object Perception in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2504.03438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025 WDFM-AD&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ZFusion的3D物体检测方法，该方法融合了4D雷达和视觉信息，以实现可靠的自动驾驶3D物体感知。&lt;h4&gt;背景&lt;/h4&gt;4D雷达因其全天候的感知能力而受到关注，但其提供的点云数据比LiDAR稀疏。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以提高3D物体检测的准确性，同时降低成本。&lt;h4&gt;方法&lt;/h4&gt;ZFusion方法的核心是FP-DDCA（特征金字塔-双可变形交叉注意力）融合器，它通过特征金字塔结构和Transformer块在不同尺度上交互式融合多模态特征。此外，还使用了Depth-Context-Split视图转换模块来利用4D雷达的物理特性。&lt;h4&gt;主要发现&lt;/h4&gt;在VoD（Delft视图）数据集等典型交通场景中，ZFusion在感兴趣区域实现了最先进的mAP（平均平均精度），并且在整个区域与基线方法相比具有竞争力的mAP，表明其性能接近LiDAR，并显著优于仅使用摄像头的方案。&lt;h4&gt;结论&lt;/h4&gt;ZFusion是一种有吸引力的替代方案，可以降低自动驾驶中3D物体检测的成本，同时保持高性能。&lt;h4&gt;翻译&lt;/h4&gt;Reliable 3D object perception is essential in autonomous driving. Owing to its sensing capabilities in all weather conditions, 4D radar has recently received much attention. However, compared to LiDAR, 4D radar provides much sparser point cloud. In this paper, we propose a 3D object detection method, termed ZFusion, which fuses 4D radar and vision modality. As the core of ZFusion, our proposed FP-DDCA (Feature Pyramid-Double Deformable CrossAttention) fuser complements the (sparse) radar information and (dense) vision information, effectively. Specifically, with a feature-pyramid structure, the FP-DDCA fuser packs Transformer blocks to interactively fuse multi-modal features at different scales, thus enhancing perception accuracy. In addition, we utilize the Depth-Context-Split view transformation module due to the physical properties of 4D radar. Considering that 4D radar has a much lower cost than LiDAR, ZFusion is an attractive alternative to LiDAR-based methods. In typical traffic scenarios like the VoD (View-of-Delft) dataset, experiments show that with reasonable inference speed, ZFusion achieved the state-of-the-art mAP (mean average precision) in the region of interest, while having competitive mAP in the entire area compared to the baseline methods, which demonstrates performance close to LiDAR and greatly outperforms those camera-only methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable 3D object perception is essential in autonomous driving. Owing toits sensing capabilities in all weather conditions, 4D radar has recentlyreceived much attention. However, compared to LiDAR, 4D radar provides muchsparser point cloud. In this paper, we propose a 3D object detection method,termed ZFusion, which fuses 4D radar and vision modality. As the core ofZFusion, our proposed FP-DDCA (Feature Pyramid-Double Deformable CrossAttention) fuser complements the (sparse) radar information and (dense) visioninformation, effectively. Specifically, with a feature-pyramid structure, theFP-DDCA fuser packs Transformer blocks to interactively fuse multi-modalfeatures at different scales, thus enhancing perception accuracy. In addition,we utilize the Depth-Context-Split view transformation module due to thephysical properties of 4D radar. Considering that 4D radar has a much lowercost than LiDAR, ZFusion is an attractive alternative to LiDAR-based methods.In typical traffic scenarios like the VoD (View-of-Delft) dataset, experimentsshow that with reasonable inference speed, ZFusion achieved thestate-of-the-art mAP (mean average precision) in the region of interest, whilehaving competitive mAP in the entire area compared to the baseline methods,which demonstrates performance close to LiDAR and greatly outperforms thosecamera-only methods.</description>
      <author>example@mail.com (Sheng Yang, Tong Zhan, Shichen Qiao, Jicheng Gong, Qing Yang, Yanfeng Lu, Jian Wang)</author>
      <guid isPermaLink="false">2504.03438v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Optimizing Specific and Shared Parameters for Efficient Parameter Tuning</title>
      <link>http://arxiv.org/abs/2504.03450v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SaS的新型Parameter-Efficient Transfer Learning (PETL)方法，旨在高效地适应下游任务，同时减少计算开销。&lt;h4&gt;背景&lt;/h4&gt;尽管基础模型在众多应用中取得了最先进的性能，但将它们有效地适应下游任务是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;解决将基础模型适应下游任务时计算开销的问题。&lt;h4&gt;方法&lt;/h4&gt;SaS方法通过调整一小部分参数来微调模型，同时保留预训练知识。它包含一个共享模块和一个特定层模块：(1) 共享模块使用低秩投影捕获跨层共有的统计特征；(2) 特定层模块使用超网络为每一层生成定制参数。&lt;h4&gt;主要发现&lt;/h4&gt;SaS在多样化的下游任务、少样本设置和领域泛化实验中显著提高了性能，同时保持了优于现有方法的参数效率。SaS的参数量增加了不到0.05%，比现有方法更为紧凑。&lt;h4&gt;结论&lt;/h4&gt;SaS强调了在迁移学习中捕捉共享和层特定信息的重要性。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Foundation models, with a vast number of parameters and pretraining on massive datasets, achieve state-of-the-art performance across various applications. However, efficiently adapting them to downstream tasks with minimal computational overhead remains a challenge. Parameter-Efficient Transfer Learning (PETL) addresses this by fine-tuning only a small subset of parameters while preserving pre-trained knowledge. In this paper, we propose SaS, a novel PETL method that effectively mitigates distributional shifts during fine-tuning. SaS integrates (1) a shared module that captures common statistical characteristics across layers using low-rank projections and (2) a layer-specific module that employs hypernetworks to generate tailored parameters for each layer. This dual design ensures an optimal balance between performance and parameter efficiency while introducing less than 0.05% additional parameters, making it significantly more compact than existing methods. Extensive experiments on diverse downstream tasks, few-shot settings and domain generalization demonstrate that SaS significantly enhances performance while maintaining superior parameter efficiency compared to existing methods, highlighting the importance of capturing both shared and layer-specific information in transfer learning. Code and data are available at https://anonymous.4open.science/r/SaS-PETL-3565.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models, with a vast number of parameters and pretraining onmassive datasets, achieve state-of-the-art performance across variousapplications. However, efficiently adapting them to downstream tasks withminimal computational overhead remains a challenge. Parameter-EfficientTransfer Learning (PETL) addresses this by fine-tuning only a small subset ofparameters while preserving pre-trained knowledge. In this paper, we proposeSaS, a novel PETL method that effectively mitigates distributional shiftsduring fine-tuning. SaS integrates (1) a shared module that captures commonstatistical characteristics across layers using low-rank projections and (2) alayer-specific module that employs hypernetworks to generate tailoredparameters for each layer. This dual design ensures an optimal balance betweenperformance and parameter efficiency while introducing less than 0.05%additional parameters, making it significantly more compact than existingmethods. Extensive experiments on diverse downstream tasks, few-shot settingsand domain generalization demonstrate that SaS significantly enhancesperformance while maintaining superior parameter efficiency compared toexisting methods, highlighting the importance of capturing both shared andlayer-specific information in transfer learning. Code and data are available athttps://anonymous.4open.science/r/SaS-PETL-3565.</description>
      <author>example@mail.com (Van-Anh Nguyen, Thanh-Toan Do, Mehrtash Harandi, Dinh Phung, Trung Le)</author>
      <guid isPermaLink="false">2504.03450v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>ATM-Net: Anatomy-Aware Text-Guided Multi-Modal Fusion for Fine-Grained Lumbar Spine Segmentation</title>
      <link>http://arxiv.org/abs/2504.03476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ATM-Net是一个创新的框架，用于腰椎结构的精细分割，显著优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;精确的腰椎脊柱分割对诊断脊柱疾病至关重要，现有方法缺乏精细细节，并且依赖于视觉模型导致分类错误。&lt;h4&gt;目的&lt;/h4&gt;提出ATM-Net框架，解决现有方法的局限性，实现腰椎结构的精细分割。&lt;h4&gt;方法&lt;/h4&gt;ATM-Net采用解剖感知、文本引导的多模态融合机制，结合ATPG将图像标注转换为解剖感知提示，并使用HASF模块整合这些提示与图像特征，通过CCAE模块进行多模态对比学习以增强分类和细化分割。&lt;h4&gt;主要发现&lt;/h4&gt;在MRSpineSeg和SPIDER数据集上的实验表明，ATM-Net在分类判别和分割细节方面均显著优于现有方法，例如在SPIDER数据集上达到Dice指数79.39%和HD95值9.91像素，优于SpineParseNet的8.31%和4.14像素。&lt;h4&gt;结论&lt;/h4&gt;ATM-Net是一个有效的腰椎脊柱分割方法，能够提供更精确的诊断结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate lumbar spine segmentation is crucial for diagnosing spinaldisorders. Existing methods typically use coarse-grained segmentationstrategies that lack the fine detail needed for precise diagnosis.Additionally, their reliance on visual-only models hinders the capture ofanatomical semantics, leading to misclassified categories and poor segmentationdetails. To address these limitations, we present ATM-Net, an innovativeframework that employs an anatomy-aware, text-guided, multi-modal fusionmechanism for fine-grained segmentation of lumbar substructures, i.e.,vertebrae (VBs), intervertebral discs (IDs), and spinal canal (SC). ATM-Netadopts the Anatomy-aware Text Prompt Generator (ATPG) to adaptively convertimage annotations into anatomy-aware prompts in different views. These insightsare further integrated with image features via the Holistic Anatomy-awareSemantic Fusion (HASF) module, building a comprehensive anatomical context. TheChannel-wise Contrastive Anatomy-Aware Enhancement (CCAE) module furtherenhances class discrimination and refines segmentation through class-wisechannel-level multi-modal contrastive learning. Extensive experiments on theMRSpineSeg and SPIDER datasets demonstrate that ATM-Net significantlyoutperforms state-of-the-art methods, with consistent improvements regardingclass discrimination and segmentation details. For example, ATM-Net achievesDice of 79.39% and HD95 of 9.91 pixels on SPIDER, outperforming the competitiveSpineParseNet by 8.31% and 4.14 pixels, respectively.</description>
      <author>example@mail.com (Sheng Lian, Dengfeng Pan, Jianlong Cai, Guang-Yong Chen, Zhun Zhong, Zhiming Luo, Shen Zhao, Shuo Li)</author>
      <guid isPermaLink="false">2504.03476v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Locations of Characters in Narratives: Andersen and Persuasion Datasets</title>
      <link>http://arxiv.org/abs/2504.03434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 3 figures, 10 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了机器在叙述语境中理解空间关系的能力，并引入了两个新的数据集：Andersen和Persuasion，用于测试AI理解人物与地点之间关系的能力。&lt;h4&gt;背景&lt;/h4&gt;机器在叙述语境中理解空间关系的能力是阅读理解中的一个有趣方面，这一领域的研究仍在进行中。&lt;h4&gt;目的&lt;/h4&gt;为了测试AI在理解叙述中人物与其相应地点关系方面的能力。&lt;h4&gt;方法&lt;/h4&gt;研究者从汉斯·克里斯蒂安·安徒生的《安徒生童话》中选择了十五个儿童故事，并对每个故事中的人物及其位置进行了手动标注，形成了Andersen数据集。同样，研究者对简·奥斯汀的小说《劝导》中的人物及其位置也进行了手动标注，形成了Persuasion数据集。然后，研究者使用这些数据集来提示大型语言模型（LLMs），通过从故事或小说中提取摘录并结合询问该摘录中提到的人物位置的问题来创建提示。&lt;h4&gt;主要发现&lt;/h4&gt;在测试的五种LLMs中，Andersen数据集表现最好的LLM准确识别出61.85%的例子中的位置，而在Persuasion数据集中，表现最好的LLM在56.06%的案例中做到了这一点。&lt;h4&gt;结论&lt;/h4&gt;这些发现表明，LLMs在理解叙述中的空间关系方面具有一定的能力，但仍存在改进空间。&lt;h4&gt;翻译&lt;/h4&gt;The study explores the ability of machines to grasp spatial understanding within narrative contexts, and introduces two new datasets: Andersen and Persuasion, to test the AI's competence in understanding the relationship between characters and their respective locations in narratives.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability of machines to grasp spatial understanding within narrativecontexts is an intriguing aspect of reading comprehension that continues to bestudied. Motivated by the goal to test the AI's competence in understanding therelationship between characters and their respective locations in narratives,we introduce two new datasets: Andersen and Persuasion. For the Andersendataset, we selected fifteen children's stories from "Andersen's Fairy Tales"by Hans Christian Andersen and manually annotated the characters and theirrespective locations throughout each story. Similarly, for the Persuasiondataset, characters and their locations in the novel "Persuasion" by JaneAusten were also manually annotated. We used these datasets to prompt LargeLanguage Models (LLMs). The prompts are created by extracting excerpts from thestories or the novel and combining them with a question asking the location ofa character mentioned in that excerpt. Out of the five LLMs we tested, thebest-performing one for the Andersen dataset accurately identified the locationin 61.85% of the examples, while for the Persuasion dataset, thebest-performing one did so in 56.06% of the cases.</description>
      <author>example@mail.com (Batuhan Ozyurt, Roya Arkhmammadova, Deniz Yuret)</author>
      <guid isPermaLink="false">2504.03434v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Optimizing Quantum Circuits via ZX Diagrams using Reinforcement Learning and Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.03429v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于ZX计算、图神经网络和强化学习的量子电路优化框架，旨在减少噪声对量子计算的影响。&lt;h4&gt;背景&lt;/h4&gt;量子计算受噪声影响较大，尤其是双量子比特门的引入，因此减少双量子比特门数量至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了提高量子计算的可靠性，研究提出了一种新的量子电路优化方法。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了强化学习和树搜索，通过ZX图直接操作，寻找减少CNOT门数量的电路优化规则。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够在所有可能的电路变换空间中搜索，发现任意优化规则，并在大量不同随机电路上展现出与现有电路优化器相媲美的竞争力。&lt;h4&gt;结论&lt;/h4&gt;该研究为量子电路优化提供了一种新的思路，有助于提高量子计算的可靠性。&lt;h4&gt;翻译&lt;/h4&gt;Quantum computing is currently strongly limited by the impact of noise, inparticular introduced by the application of two-qubit gates. For this reason, reducing the number of two-qubit gates is of paramount importance on noisy intermediate-scale quantum hardware. To advance towards more reliable quantum computing, we introduce a framework based on ZX calculus, graph-neural networks and reinforcement learning for quantum circuit optimization. By combining reinforcement learning and tree search, our method addresses the challenge of selecting optimal sequences of ZX calculus rewrite rules. Instead of relying on existing heuristic rules for minimizing circuits, our method trains a novel reinforcement learning policy that directly operates on ZX-graphs, therefore allowing us to search through the space of all possible circuit transformations to find a circuit significantly minimizing the number of CNOT gates. This way we can scale beyond hard-coded rules towards discovering arbitrary optimization rules. We demonstrate our method's competetiveness with state-of-the-art circuit optimizers and generalization capabilities on large sets of diverserandom circuits.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum computing is currently strongly limited by the impact of noise, inparticular introduced by the application of two-qubit gates. For this reason,reducing the number of two-qubit gates is of paramount importance on noisyintermediate-scale quantum hardware. To advance towards more reliable quantumcomputing, we introduce a framework based on ZX calculus, graph-neural networksand reinforcement learning for quantum circuit optimization. By combiningreinforcement learning and tree search, our method addresses the challenge ofselecting optimal sequences of ZX calculus rewrite rules. Instead of relying onexisting heuristic rules for minimizing circuits, our method trains a novelreinforcement learning policy that directly operates on ZX-graphs, thereforeallowing us to search through the space of all possible circuit transformationsto find a circuit significantly minimizing the number of CNOT gates. This waywe can scale beyond hard-coded rules towards discovering arbitrary optimizationrules. We demonstrate our method's competetiveness with state-of-the-artcircuit optimizers and generalization capabilities on large sets of diverserandom circuits.</description>
      <author>example@mail.com (Alexander Mattick, Maniraman Periyasamy, Christian Ufrecht, Abhishek Y. Dubey, Christopher Mutschler, Axel Plinge, Daniel D. Scherer)</author>
      <guid isPermaLink="false">2504.03429v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Early detection of diabetes through transfer learning-based eye (vision) screening and improvement of machine learning model performance and advanced parameter setting algorithms</title>
      <link>http://arxiv.org/abs/2504.03439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages,12 Figures, 1 Table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用迁移学习（TL）技术提高糖尿病视网膜病变（DR）检测的机器学习模型性能，通过降维、优化学习率调整和高级参数调优算法，提高了检测效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;糖尿病视网膜病变是糖尿病的严重并发症，由长期高血糖水平导致的视网膜小血管损伤引起。未治疗的DR可能导致视网膜静脉阻塞和异常血管生长，显著增加失明的风险。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过迁移学习技术提高糖尿病视网膜病变检测的机器学习模型性能，以实现早期诊断，及时干预，防止视力丧失并改善患者预后。&lt;h4&gt;方法&lt;/h4&gt;研究采用了迁移学习技术，包括降维、优化学习率调整和高级参数调优算法，以提高模型的效率和诊断准确性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的模型在测试数据集上实现了84%的整体准确率，超过了先前的研究。最高类别特定准确率达到89%，最大敏感性为97%，F1分数为92%，表明在识别DR病例方面具有强大性能。&lt;h4&gt;结论&lt;/h4&gt;基于迁移学习的DR筛查是早期诊断的有前景的方法，能够实现及时干预，防止视力丧失并改善患者预后。&lt;h4&gt;翻译&lt;/h4&gt;Diabetic Retinopathy (DR) is a serious and common complication of diabetes, caused by prolonged high blood sugar levels that damage the small retinal blood vessels. If left untreated, DR can progress to retinal vein occlusion and stimulate abnormal blood vessel growth, significantly increasing the risk of blindness. Traditional diabetes diagnosis methods often utilize convolutional neural networks (CNNs) to extract visual features from retinal images, followed by classification algorithms such as decision trees and k-nearest neighbors (KNN) for disease detection. However, these approaches face several challenges, including low accuracy and sensitivity, lengthy machine learning (ML) model training due to high data complexity and volume, and the use of limited datasets for testing and evaluation. This study investigates the application of transfer learning (TL) to enhance ML model performance in DR detection. Key improvements include dimensionality reduction, optimized learning rate adjustments, and advanced parameter tuning algorithms, aimed at increasing efficiency and diagnostic accuracy. The proposed model achieved an overall accuracy of 84% on the testing dataset, outperforming prior studies. The highest class-specific accuracy reached 89%, with a maximum sensitivity of 97% and an F1-score of 92%, demonstrating strong performance in identifying DR cases. These findings suggest that TL-based DR screening is a promising approach for early diagnosis, enabling timely interventions to prevent vision loss and improve patient outcomes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diabetic Retinopathy (DR) is a serious and common complication of diabetes,caused by prolonged high blood sugar levels that damage the small retinal bloodvessels. If left untreated, DR can progress to retinal vein occlusion andstimulate abnormal blood vessel growth, significantly increasing the risk ofblindness. Traditional diabetes diagnosis methods often utilize convolutionalneural networks (CNNs) to extract visual features from retinal images, followedby classification algorithms such as decision trees and k-nearest neighbors(KNN) for disease detection. However, these approaches face several challenges,including low accuracy and sensitivity, lengthy machine learning (ML) modeltraining due to high data complexity and volume, and the use of limiteddatasets for testing and evaluation. This study investigates the application oftransfer learning (TL) to enhance ML model performance in DR detection. Keyimprovements include dimensionality reduction, optimized learning rateadjustments, and advanced parameter tuning algorithms, aimed at increasingefficiency and diagnostic accuracy. The proposed model achieved an overallaccuracy of 84% on the testing dataset, outperforming prior studies. Thehighest class-specific accuracy reached 89%, with a maximum sensitivity of 97%and an F1-score of 92%, demonstrating strong performance in identifying DRcases. These findings suggest that TL-based DR screening is a promisingapproach for early diagnosis, enabling timely interventions to prevent visionloss and improve patient outcomes.</description>
      <author>example@mail.com (Mohammad Reza Yousefi, Ali Bakrani, Amin Dehghani)</author>
      <guid isPermaLink="false">2504.03439v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Decentralized Collective World Model for Emergent Communication and Coordination</title>
      <link>http://arxiv.org/abs/2504.03353v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种完全去中心化的多智能体世界模型，该模型通过时间扩展的集体预测编码实现符号的涌现和协调行为。该模型同时实现了通信和协调，并通过对比学习进行信息交流，从而预测环境动态，估计状态，并共享关键信息。&lt;h4&gt;背景&lt;/h4&gt;以往的研究要么关注通信，要么关注协调，而本文提出的方法同时实现了这两者。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够同时实现通信和协调的多智能体世界模型。&lt;h4&gt;方法&lt;/h4&gt;该方法将世界模型与通信渠道集成，通过双向消息交换和对比学习进行信息对齐，使智能体能够预测环境动态，从部分观察中估计状态，并共享关键信息。&lt;h4&gt;主要发现&lt;/h4&gt;在两个智能体的轨迹绘制任务中，基于通信的方法在智能体具有不同的感知能力时优于非通信模型，实现了仅次于集中式模型的第二好的协调效果。去中心化的方法通过限制直接访问其他智能体的内部状态，促进了更有意义的符号系统的涌现，这些符号系统能够准确反映环境状态。&lt;h4&gt;结论&lt;/h4&gt;去中心化的通信对于支持协调并发展对环境的共享表示是有效的。&lt;h4&gt;翻译&lt;/h4&gt;We propose a fully decentralized multi-agent world model that enables both symbol emergence for communication and coordinated behavior through temporal extension of collective predictive coding. Unlike previous research that focuses on either communication or coordination separately, our approach achieves both simultaneously. Our method integrates world models with communication channels, enabling agents to predict environmental dynamics, estimate states from partial observations, and share critical information through bidirectional message exchange with contrastive learning for message alignment. Using a two-agent trajectory drawing task, we demonstrate that our communication-based approach outperforms non-communicative models when agents have divergent perceptual capabilities, achieving the second-best coordination after centralized models. Importantly, our distributed approach with constraints preventing direct access to other agents' internal states facilitates the emergence of more meaningful symbol systems that accurately reflect environmental states. These findings demonstrate the effectiveness of decentralized communication for supporting coordination while developing shared representations of the environment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a fully decentralized multi-agent world model that enables bothsymbol emergence for communication and coordinated behavior through temporalextension of collective predictive coding. Unlike previous research thatfocuses on either communication or coordination separately, our approachachieves both simultaneously. Our method integrates world models withcommunication channels, enabling agents to predict environmental dynamics,estimate states from partial observations, and share critical informationthrough bidirectional message exchange with contrastive learning for messagealignment. Using a two-agent trajectory drawing task, we demonstrate that ourcommunication-based approach outperforms non-communicative models when agentshave divergent perceptual capabilities, achieving the second-best coordinationafter centralized models. Importantly, our distributed approach withconstraints preventing direct access to other agents' internal statesfacilitates the emergence of more meaningful symbol systems that accuratelyreflect environmental states. These findings demonstrate the effectiveness ofdecentralized communication for supporting coordination while developing sharedrepresentations of the environment.</description>
      <author>example@mail.com (Kentaro Nomura, Tatsuya Aoki, Tadahiro Taniguchi, Takato Horii)</author>
      <guid isPermaLink="false">2504.03353v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>NuScenes-SpatialQA: A Spatial Understanding and Reasoning Benchmark for Vision-Language Models in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2504.03164v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了视觉语言模型（VLMs）在自动驾驶任务中的应用，指出其在空间理解和推理方面存在局限性，并提出了一种新的基准测试方法NuScenes-SpatialQA来评估VLMs的空间理解能力。&lt;h4&gt;背景&lt;/h4&gt;近年来，VLMs在自动驾驶任务中展现出巨大潜力，但其空间理解和推理能力仍有待提高。&lt;h4&gt;目的&lt;/h4&gt;提出NuScenes-SpatialQA基准，系统地评估VLMs在自动驾驶中的空间理解和推理能力。&lt;h4&gt;方法&lt;/h4&gt;基于NuScenes数据集，通过自动化的3D场景图生成和问答生成流程构建基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，空间增强型VLM在定性问答中表现优于其他模型，但在定量问答中并未展现出竞争力。&lt;h4&gt;结论&lt;/h4&gt;VLMs在空间理解和推理方面仍面临重大挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，视觉-语言模型（VLMs）在自动驾驶任务中显示出强大的潜力。然而，它们的空间理解和推理能力——自动驾驶的关键能力——仍然存在显著限制。值得注意的是，现有的基准测试没有一个系统地评估VLMs在驾驶场景中的空间推理能力。为了填补这一空白，我们提出了NuScenes-SpatialQA，这是第一个大规模基于真实数据的问答（QA）基准，专门设计用于评估VLMs在自动驾驶中的空间理解和推理能力。该基准建立在NuScenes数据集之上，通过自动化的3D场景图生成流程和问答生成流程构建。该基准系统地评估了VLMs在空间理解和推理方面的表现。使用这个基准，我们对多种VLMs进行了广泛的实验，包括通用模型和空间增强型模型，提供了对它们在自动驾驶中空间能力的第一项全面评估。令人惊讶的是，实验结果表明，空间增强型VLM在定性问答方面表现优于其他模型，但在定量问答方面并未显示出竞争力。总的来说，VLMs在空间理解和推理方面仍然面临相当大的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Vision-Language Models (VLMs) have demonstrated strongpotential for autonomous driving tasks. However, their spatial understandingand reasoning-key capabilities for autonomous driving-still exhibit significantlimitations. Notably, none of the existing benchmarks systematically evaluateVLMs' spatial reasoning capabilities in driving scenarios. To fill this gap, wepropose NuScenes-SpatialQA, the first large-scale ground-truth-basedQuestion-Answer (QA) benchmark specifically designed to evaluate the spatialunderstanding and reasoning capabilities of VLMs in autonomous driving. Builtupon the NuScenes dataset, the benchmark is constructed through an automated 3Dscene graph generation pipeline and a QA generation pipeline. The benchmarksystematically evaluates VLMs' performance in both spatial understanding andreasoning across multiple dimensions. Using this benchmark, we conductextensive experiments on diverse VLMs, including both general andspatial-enhanced models, providing the first comprehensive evaluation of theirspatial capabilities in autonomous driving. Surprisingly, the experimentalresults show that the spatial-enhanced VLM outperforms in qualitative QA butdoes not demonstrate competitiveness in quantitative QA. In general, VLMs stillface considerable challenges in spatial understanding and reasoning.</description>
      <author>example@mail.com (Kexin Tian, Jingrui Mao, Yunlong Zhang, Jiwan Jiang, Yang Zhou, Zhengzhong Tu)</author>
      <guid isPermaLink="false">2504.03164v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>MultiClear: Multimodal Soft Exoskeleton Glove for Transparent Object Grasping Assistance</title>
      <link>http://arxiv.org/abs/2504.03379v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为MultiClear的多模态框架，旨在通过融合RGB数据、深度数据和听觉信号来增强可穿戴软外骨骼手套在抓取透明物体时的辅助功能。&lt;h4&gt;背景&lt;/h4&gt;抓取是与环境互动的基本技能，但对于某些人来说（例如由于残疾）这项能力可能很难。可穿戴机器人解决方案可以增强或恢复手的功能，而最近的研究利用计算机视觉来提高抓取能力。然而，由于透明物体视觉对比度差和深度线索模糊，抓取透明物体仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种多模态框架，以增强可穿戴软外骨骼手套在抓取透明物体时的辅助功能。&lt;h4&gt;方法&lt;/h4&gt;该手套集成了腱驱动执行器、RGB-D相机和内置麦克风。为了实现精确和自适应控制，提出了一种分层控制架构。该架构包括提供上下文感知的高层控制层、处理多模态感官输入的中层控制层以及执行PID电机控制的低层控制层。透明物体分割的挑战通过引入用于零样本分割的视觉基础模型来管理。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在透明物体操作中实现了70.37%的抓取能力评分，证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;MultiClear框架能够有效提高抓取透明物体的能力，为可穿戴机器人手套提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：抓取是与环境互动的基本技能。然而，这项能力对于一些人来说可能很难（例如由于残疾）。可穿戴机器人解决方案可以增强或恢复手的功能，而最近的研究利用计算机视觉来提高抓取能力。然而，由于透明物体视觉对比度差和深度线索模糊，抓取透明物体仍然具有挑战性。此外，虽然已经探索了结合触觉和听觉反馈的多模态控制策略来抓取透明物体，但视觉与这些模态的集成仍然处于发展阶段。本文介绍了一种名为MultiClear的多模态框架，旨在通过融合RGB数据、深度数据和听觉信号来增强可穿戴软外骨骼手套在抓取透明物体时的辅助功能。该外骨骼手套集成了腱驱动执行器、RGB-D相机和内置麦克风。为了实现精确和自适应控制，提出了一种分层控制架构。对于所提出的分层控制架构，高层控制层提供上下文感知，中层控制层处理多模态感官输入，低层控制层执行PID电机控制以进行精细的抓取调整。通过引入用于零样本分割的视觉基础模型来管理透明物体分割的挑战。所提出的系统实现了70.37%的抓取能力评分，证明了其在透明物体操作中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grasping is a fundamental skill for interacting with the environment.However, this ability can be difficult for some (e.g. due to disability).Wearable robotic solutions can enhance or restore hand function, and recentadvances have leveraged computer vision to improve grasping capabilities.However, grasping transparent objects remains challenging due to their poorvisual contrast and ambiguous depth cues. Furthermore, while multimodal controlstrategies incorporating tactile and auditory feedback have been explored tograsp transparent objects, the integration of vision with these modalitiesremains underdeveloped. This paper introduces MultiClear, a multimodalframework designed to enhance grasping assistance in a wearable softexoskeleton glove for transparent objects by fusing RGB data, depth data, andauditory signals. The exoskeleton glove integrates a tendon-driven actuatorwith an RGB-D camera and a built-in microphone. To achieve precise and adaptivecontrol, a hierarchical control architecture is proposed. For the proposedhierarchical control architecture, a high-level control layer providescontextual awareness, a mid-level control layer processes multimodal sensoryinputs, and a low-level control executes PID motor control for fine-tunedgrasping adjustments. The challenge of transparent object segmentation wasmanaged by introducing a vision foundation model for zero-shot segmentation.The proposed system achieves a Grasping Ability Score of 70.37%, demonstratingits effectiveness in transparent object manipulation.</description>
      <author>example@mail.com (Chen Hu, Timothy Neate, Shan Luo, Letizia Gionfrida)</author>
      <guid isPermaLink="false">2504.03379v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>QID: Efficient Query-Informed ViTs in Data-Scarce Regimes for OCR-free Visual Document Understanding</title>
      <link>http://arxiv.org/abs/2504.02971v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, accepted by CVPR 2025 MULA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为QID的新方法，用于优化视觉语言模型在视觉文档理解任务中的性能，特别是在数据稀缺的微调场景中。&lt;h4&gt;背景&lt;/h4&gt;在视觉文档理解任务中，使用新的数据集微调预训练的视觉语言模型时，往往难以优化视觉编码器以识别文本丰富的文档图像中的查询特定区域。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在提出一种新的、简化的、架构保持的方法，该方法将查询嵌入集成到视觉编码器中，以实现显著的性能提升。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法引入了一个双模块框架：一个查询感知模块，用于生成独特的查询向量以精确引导模型焦点；以及一个查询无关模块，用于捕获标记之间的位置关系，确保鲁棒的空间理解。两个模块都独立于视觉注意力块运行，便于有针对性地学习查询嵌入并增强视觉语义识别。&lt;h4&gt;主要发现&lt;/h4&gt;在多个数据集上进行的实验表明，使用该方法在处理文本丰富的文档以及数据稀缺环境中的性能有显著提升。&lt;h4&gt;结论&lt;/h4&gt;QID方法在视觉文档理解任务中，特别是在数据稀缺的微调场景中，能够显著提高视觉语言模型的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In Visual Document Understanding (VDU) tasks, fine-tuning a pre-trainedVision-Language Model (VLM) with new datasets often falls short in optimizingthe vision encoder to identify query-specific regions in text-rich documentimages. Existing methods that directly inject queries into model layers bymodifying the network architecture often struggle to adapt to new datasets withlimited annotations. To address this, we introduce QID, a novel, streamlined,architecture-preserving approach that integrates query embeddings into thevision encoder, leading to notable performance gains, particularly indata-scarce fine-tuning scenarios. Specifically, our approach introduces adual-module framework: a query-aware module that generates a unique queryvector to precisely guide the model's focus, as well as a query-agnostic modulethat captures the positional relationships among tokens, ensuring robustspatial understanding. Notably, both modules operate independently of thevision attention blocks, facilitating targeted learning of query embeddings andenhancing visual semantic identification. Experiments with OCR-free VLMs acrossmultiple datasets demonstrate significant performance improvements using ourmethod, especially in handling text-rich documents in data-scarce environments.</description>
      <author>example@mail.com (Binh M. Le, Shaoyuan Xu, Jinmiao Fu, Zhishen Huang, Moyan Li, Yanhui Guo, Hongdong Li, Sameera Ramasinghe, Bryan Wang)</author>
      <guid isPermaLink="false">2504.02971v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Seeing is Believing: Belief-Space Planning with Foundation Models as Uncertainty Estimators</title>
      <link>http://arxiv.org/abs/2504.03245v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，利用视觉语言模型（VLM）作为感知模块来估计不确定性和促进符号 grounding，以解决开放世界环境中可泛化的机器人移动操作挑战。&lt;h4&gt;背景&lt;/h4&gt;在开放世界环境中，由于长期目标、复杂目标和部分可观测性，可泛化的机器人移动操作面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来应对这些挑战，并提高机器人对部分可观测性和属性不确定性的推理能力。&lt;h4&gt;方法&lt;/h4&gt;该方法构建了一个符号信念表示，并使用信念空间规划器生成考虑不确定性并包含战略信息收集的计划。&lt;h4&gt;主要发现&lt;/h4&gt;模拟评估表明，该方法在规划战略信息收集方面优于基于 VLM 的端到端规划或基于 VLM 的状态估计基线。&lt;h4&gt;结论&lt;/h4&gt;这项工作突出了 VLM 在构建信念空间符号场景表示方面的潜力，从而能够实现下游任务，如不确定性感知规划。&lt;h4&gt;翻译&lt;/h4&gt;在开放世界环境中，通用的机器人移动操作由于长期目标、复杂目标和部分可观测性而面临重大挑战。解决这些挑战的一种有前景的方法是使用参数化技能库进行规划，其中任务规划器将这些技能按顺序排列以实现用结构化语言（如基于符号事实的逻辑表达式）指定的目标。虽然视觉语言模型（VLM）可以用于使这些表达式具体化，但它们通常假设完全可观测性，当代理缺乏足够的信息来以确定性评估事实时，会导致次优行为。本文介绍了一种新颖的框架，该框架利用 VLM 作为感知模块来估计不确定性和促进符号 grounding。我们的方法构建了一个符号信念表示，并使用信念空间规划器生成考虑不确定性并包含战略信息收集的计划。这使得代理能够有效地对部分可观测性和属性不确定性进行推理。我们在需要部分可观测环境推理的多种具有挑战性的真实世界任务上展示了我们的系统。模拟评估表明，我们的方法在规划战略信息收集方面优于基于 VLM 的端到端规划或基于 VLM 的状态估计基线。这项工作突出了 VLM 构建信念空间符号场景表示的潜力，从而能够实现下游任务，如不确定性感知规划。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalizable robotic mobile manipulation in open-world environments posessignificant challenges due to long horizons, complex goals, and partialobservability. A promising approach to address these challenges involvesplanning with a library of parameterized skills, where a task planner sequencesthese skills to achieve goals specified in structured languages, such aslogical expressions over symbolic facts. While vision-language models (VLMs)can be used to ground these expressions, they often assume full observability,leading to suboptimal behavior when the agent lacks sufficient information toevaluate facts with certainty. This paper introduces a novel framework thatleverages VLMs as a perception module to estimate uncertainty and facilitatesymbolic grounding. Our approach constructs a symbolic belief representationand uses a belief-space planner to generate uncertainty-aware plans thatincorporate strategic information gathering. This enables the agent toeffectively reason about partial observability and property uncertainty. Wedemonstrate our system on a range of challenging real-world tasks that requirereasoning in partially observable environments. Simulated evaluations show thatour approach outperforms both vanilla VLM-based end-to-end planning orVLM-based state estimation baselines by planning for and executing strategicinformation gathering. This work highlights the potential of VLMs to constructbelief-space symbolic scene representations, enabling downstream tasks such asuncertainty-aware planning.</description>
      <author>example@mail.com (Linfeng Zhao, Willie McClinton, Aidan Curtis, Nishanth Kumar, Tom Silver, Leslie Pack Kaelbling, Lawson L. S. Wong)</author>
      <guid isPermaLink="false">2504.03245v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Graph Attention for Heterogeneous Graphs with Positional Encoding</title>
      <link>http://arxiv.org/abs/2504.02938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了图神经网络（GNNs）在异构图上的应用，特别是节点分类和链接预测任务，并通过实验比较了不同的GNN架构，发现图注意力网络在这些任务上表现优异。&lt;h4&gt;背景&lt;/h4&gt;图神经网络已经成为建模图数据的黄金标准，但在处理异构图时，其性能往往不如同构图，存在一定的挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在找到最有效的GNN方法来处理异构图上的节点分类和链接预测任务。&lt;h4&gt;方法&lt;/h4&gt;本文对多种GNN架构进行了基准测试，并提出了通过整合位置编码来增强注意力网络的方法，使用全拉普拉斯谱来准确捕捉图中每个节点的相对和绝对位置。&lt;h4&gt;主要发现&lt;/h4&gt;图注意力网络在节点分类和链接预测任务上表现最佳，且通过整合位置编码的方法进一步提升了性能。&lt;h4&gt;结论&lt;/h4&gt;通过使用全拉普拉斯谱和位置编码，可以显著提高GNN在异构图上的节点分类和链接预测任务中的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have emerged as the de facto standard for modeling graph data, with attention mechanisms and transformers significantly enhancing their performance on graph-based tasks. Despite these advancements, the performance of GNNs on heterogeneous graphs often remains complex, with networks generally underperforming compared to their homogeneous counterparts. This work benchmarks various GNN architectures to identify the most effective methods for heterogeneous graphs, with a particular focus on node classification and link prediction. Our findings reveal that graph attention networks excel in these tasks. As a main contribution, we explore enhancements to these attention networks by integrating positional encodings for node embeddings. This involves utilizing the full Laplacian spectrum to accurately capture both the relative and absolute positions of each node within the graph, further enhancing performance on downstream tasks such as node classification and link prediction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have emerged as the de facto standard formodeling graph data, with attention mechanisms and transformers significantlyenhancing their performance on graph-based tasks. Despite these advancements,the performance of GNNs on heterogeneous graphs often remains complex, withnetworks generally underperforming compared to their homogeneous counterparts.This work benchmarks various GNN architectures to identify the most effectivemethods for heterogeneous graphs, with a particular focus on nodeclassification and link prediction. Our findings reveal that graph attentionnetworks excel in these tasks. As a main contribution, we explore enhancementsto these attention networks by integrating positional encodings for nodeembeddings. This involves utilizing the full Laplacian spectrum to accuratelycapture both the relative and absolute positions of each node within the graph,further enhancing performance on downstream tasks such as node classificationand link prediction.</description>
      <author>example@mail.com (Nikhil Shivakumar Nayak)</author>
      <guid isPermaLink="false">2504.02938v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Objective Quality: Benchmarking Features and Quality Evaluation</title>
      <link>http://arxiv.org/abs/2504.03381v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究分析了全参考点云客观度量指标的不同特征，通过比较不同客观质量度量指标之间的差异，选择了点云质量度量、点云结构相似度、点云质量指标和多尺度图相似度等指标。研究使用了递归特征消除和回归算法，在压缩场景数据库上对模型进行训练和验证，最终发现结合点云质量度量、多尺度图相似度和PSNR MSE D2，使用岭回归得到的模型性能最佳。&lt;h4&gt;背景&lt;/h4&gt;当前全参考点云客观度量指标能提供非常准确的可感知质量表示，这些指标通常由一组特征组合而成，最终得出一个质量值。&lt;h4&gt;目的&lt;/h4&gt;分析最佳性能度量指标的不同特征，并基于这些特征选择和组合出最佳模型。&lt;h4&gt;方法&lt;/h4&gt;比较不同客观质量度量指标，使用递归特征消除和回归算法（支持向量回归和岭回归）进行特征选择，在压缩场景数据库上进行模型训练和验证，并在五个公开的主观质量评估数据集上评估最佳组合模型。&lt;h4&gt;主要发现&lt;/h4&gt;通过递归特征消除选出的几个特征，结合所使用的回归方法，发现点云质量度量、多尺度图相似度和PSNR MSE D2的组合，结合岭回归算法，取得了最佳性能。&lt;h4&gt;结论&lt;/h4&gt;定义了特征选择模型，该模型结合了特定特征，通过岭回归算法实现了对点云质量的最佳估计。&lt;h4&gt;翻译&lt;/h4&gt;摘要：目前，全参考点云客观度量指标正在提供非常准确的可感知质量表示。这些指标通常由一组特征组合而成，从而得到一个最终的质量值。在本研究中，分析了最佳性能度量指标的不同特征。为此，比较了它们之间的不同客观质量度量指标，并研究了它们在质量表示上的差异。这提供了一组在本研究中使用的度量指标，即点到平面、点到属性、点云结构相似度、点云质量指标和多尺度图相似度。根据这些指标定义的特征，基于它们对客观估计的贡献进行了考察。为了使用递归特征选择算法，采用了支持向量回归和岭回归算法。对于这项研究，使用了静态点云压缩场景数据库进行模型的训练和验证。根据递归特征消除，选择了几个特征，并使用用于选择这些特征的回归方法进行了组合。然后，在五个不同的公开主观质量评估数据集上评估了最佳组合模型，针对不同的点云特征和失真。结论是，从点云质量度量、多尺度图相似度和PSNR MSE D2中选出的特征组合，结合岭回归，实现了最佳性能。该模型导致了特征选择模型的定义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Full-reference point cloud objective metrics are currently providing veryaccurate representations of perceptual quality. These metrics are usuallycomposed of a set of features that are somehow combined, resulting in a finalquality value. In this study, the different features of the best-performingmetrics are analyzed. For that, different objective quality metrics arecompared between them, and the differences in their quality representation arestudied. This provided a selection of the set of metrics used in this study,namely the point-to-plane, point-to-attribute, Point Cloud StructuralSimilarity, Point Cloud Quality Metric and Multiscale Graph Similarity. Thefeatures defined in those metrics are examined based on their contribution tothe objective estimation using recursive feature elimination. To employ therecursive feature selection algorithm, both the support vector regression andthe ridge regression algorithms were employed. For this study, the BroadQuality Assessment of Static Point Clouds in Compression Scenario database wasused for both training and validation of the models. According to the recursivefeature elimination, several features were selected and then combined using theregression method used to select those features. The best combination modelswere then evaluated across five different publicly available subjective qualityassessment datasets, targeting different point cloud characteristics anddistortions. It was concluded that a combination of features selected from thePoint Cloud Quality Metric, Multiscale Graph Similarity and PSNR MSE D2,combined with Ridge Regression, results in the best performance. This modelleads to the definition of the Feature Selection Model.</description>
      <author>example@mail.com (Joao Prazeres, Rafael Rodrigues, Manuela Pereira, Antonio M. G. Pinheiro)</author>
      <guid isPermaLink="false">2504.03381v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Comparative Analysis of Unsupervised and Supervised Autoencoders for Nuclei Classification in Clear Cell Renal Cell Carcinoma Images</title>
      <link>http://arxiv.org/abs/2504.03146v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted 4-page paper at IEEE ISBI 2025. 3 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了监督和自编码器在清晰细胞肾细胞癌（ccRCC）图像核分类中的应用，评估了不同的自编码器架构，并通过整合监督分类分支和优化分类性能来提高ccRCC病理分级自动化。&lt;h4&gt;背景&lt;/h4&gt;ccRCC图像的核分类通常依赖于病理学家的主观视觉评级，本研究旨在自动化这一过程。&lt;h4&gt;目的&lt;/h4&gt;自动化ccRCC图像的核分类，提高诊断准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;研究了标准自编码器、压缩自编码器（CAEs）、判别自编码器（DAEs）和基于分类器的判别自编码器（CDAE），并使用Optuna工具进行超参数调整。通过Bhattacharyya距离评估潜在空间中的类别可分性，并将F1分数纳入调整过程以优化分类性能。&lt;h4&gt;主要发现&lt;/h4&gt;CDAE在潜在空间分离和分类精度方面表现出优异的性能，通过潜在聚类和细粒度分类识别了具有挑战性的ccRCC等级，并且模型在所有评估指标上优于当前最先进的CHR-Network。&lt;h4&gt;结论&lt;/h4&gt;在ccRCC病理中，通过整合分类分支、神经网络架构搜索和对比学习，可以增强分级自动化，特别是在检测侵略性肿瘤等级方面，可能提高诊断准确性。&lt;h4&gt;翻译&lt;/h4&gt;本研究探讨了监督和自编码器在清晰细胞肾细胞癌（ccRCC）图像核分类中的应用。我们评估了各种自编码器架构，包括标准自编码器、收缩自编码器（CAEs）、判别自编码器（DAEs）以及基于分类器的判别自编码器（CDAE），并使用超参数调整工具Optuna进行优化。从多个指标中选择了Bhattacharyya距离来评估潜在空间中的类别可分性，揭示了在无监督模型中区分相邻等级的挑战。整合了监督分类分支的CDAE在潜在空间分离和分类精度方面表现出优越的性能。鉴于CDAE-CNN在分类指标上实现了显著改进，证实了监督学习对特征提取的价值，F1分数被纳入调整过程以优化分类性能。结果显示，通过利用自编码器的分类能力进行潜在聚类后的细粒度分类，可以显著提高识别侵略性ccRCC等级。我们的模型在所有评估指标上优于当前最先进的CHR-Network。这些发现表明，在自编码器中整合分类分支、结合神经网络架构搜索和对比学习，可以增强ccRCC病理中的分级自动化，特别是在检测侵略性肿瘤等级方面，并可能提高诊断准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study explores the application of supervised and unsupervisedautoencoders (AEs) to automate nuclei classification in clear cell renal cellcarcinoma (ccRCC) images, a diagnostic task traditionally reliant on subjectivevisual grading by pathologists. We evaluate various AE architectures, includingstandard AEs, contractive AEs (CAEs), and discriminative AEs (DAEs), as well asa classifier-based discriminative AE (CDAE), optimized using the hyperparametertuning tool Optuna. Bhattacharyya distance is selected from several metrics toassess class separability in the latent space, revealing challenges indistinguishing adjacent grades using unsupervised models. CDAE, integrating asupervised classifier branch, demonstrated superior performance in both latentspace separation and classification accuracy. Given that CDAE-CNN achievednotable improvements in classification metrics, affirming the value ofsupervised learning for class-specific feature extraction, F1 score wasincorporated into the tuning process to optimize classification performance.Results show significant improvements in identifying aggressive ccRCC grades byleveraging the classification capability of AE through latent clusteringfollowed by fine-grained classification. Our model outperforms the currentstate of the art, CHR-Network, across all evaluated metrics. These findingssuggest that integrating a classifier branch in AEs, combined with neuralarchitecture search and contrastive learning, enhances grading automation inccRCC pathology, particularly in detecting aggressive tumor grades, and mayimprove diagnostic accuracy.</description>
      <author>example@mail.com (Fatemeh Javadian, Zahra Aminparast, Johannes Stegmaier, Abin Jose)</author>
      <guid isPermaLink="false">2504.03146v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Block Toeplitz Sparse Precision Matrix Estimation for Large-Scale Interval-Valued Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2504.03322v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对大规模区间值时间序列（ITS）的特征提取方法，包括自动分段、聚类和特征迁移学习，用于预测。&lt;h4&gt;背景&lt;/h4&gt;由于ITS在各个领域中的广泛应用，建模和预测ITS受到了广泛关注。目前尚未有针对大规模ITS的建模尝试。&lt;h4&gt;目的&lt;/h4&gt;提出一种适用于大规模ITS的特征提取方法，并用于预测。&lt;h4&gt;方法&lt;/h4&gt;该方法包括自动分段和聚类，以及特征迁移学习。通过将ITS的自动分段和聚类转化为Toeplitz稀疏精度矩阵和分配集的估计，使用极大极小算法将高度非凸优化问题转化为两个子问题。通过动态规划和交替方向法交替解决这两个子问题，并建立其收敛性质。使用联合自回归图（JRP）对子序列进行图像化，并对每个聚类分配一个类别标签，构建图像数据集。然后，选择适当的神经网络在图像数据集上进行训练，并用于提取预测步骤中的特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够有效地获得原始数据的不变表示，并提高预测性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在预测ITS方面具有有效性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;Modeling and forecasting interval-valued time series (ITS) have attracted considerable attention due to their growing presence in various contexts. To the best of our knowledge, there have been no efforts to model large-scale ITS. In this paper, we propose a feature extraction procedure for large-scale ITS, which involves key steps such as auto-segmentation and clustering, and feature transfer learning. This procedure can be seamlessly integrated with any suitable prediction models for forecasting purposes. Specifically, we transform the automatic segmentation and clustering of ITS into the estimation of Toeplitz sparse precision matrices and assignment set. The majorization-minimization algorithm is employed to convert this highly non-convex optimization problem into two subproblems. We derive efficient dynamic programming and alternating direction method to solve these two subproblems alternately and establish their convergence properties. By employing the Joint Recurrence Plot (JRP) to image subsequence and assigning a class label to each cluster, an image dataset is constructed. Then, an appropriate neural network is chosen to train on this image dataset and used to extract features for the next step of forecasting. Real data applications demonstrate that the proposed method can effectively obtain invariant representations of the raw data and enhance forecasting performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling and forecasting interval-valued time series (ITS) have attractedconsiderable attention due to their growing presence in various contexts. Tothe best of our knowledge, there have been no efforts to model large-scale ITS.In this paper, we propose a feature extraction procedure for large-scale ITS,which involves key steps such as auto-segmentation and clustering, and featuretransfer learning. This procedure can be seamlessly integrated with anysuitable prediction models for forecasting purposes. Specifically, we transformthe automatic segmentation and clustering of ITS into the estimation ofToeplitz sparse precision matrices and assignment set. Themajorization-minimization algorithm is employed to convert this highlynon-convex optimization problem into two subproblems. We derive efficientdynamic programming and alternating direction method to solve these twosubproblems alternately and establish their convergence properties. Byemploying the Joint Recurrence Plot (JRP) to image subsequence and assigning aclass label to each cluster, an image dataset is constructed. Then, anappropriate neural network is chosen to train on this image dataset and used toextract features for the next step of forecasting. Real data applicationsdemonstrate that the proposed method can effectively obtain invariantrepresentations of the raw data and enhance forecasting performance.</description>
      <author>example@mail.com (Wan Tian, Zhongfeng Qin)</author>
      <guid isPermaLink="false">2504.03322v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>FontGuard: A Robust Font Watermarking Approach Leveraging Deep Font Knowledge</title>
      <link>http://arxiv.org/abs/2504.03128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了FontGuard，一种新型的字体水印模型，用于解决AI生成内容在法医和安全性问题上的挑战，如来源追踪和版权保护。&lt;h4&gt;背景&lt;/h4&gt;随着AI生成内容的增多，出现了源追踪、版权保护等法医和安全问题，强调了有效水印技术的必要性。&lt;h4&gt;目的&lt;/h4&gt;提高字体水印的质量和嵌入容量，并增强对现实世界扭曲的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;FontGuard利用字体模型和语言引导的对比学习，通过改变隐藏风格特征来修改字体，生成大量接近原始字体的字体变体，并使用图像-文本对比学习重构嵌入的位。&lt;h4&gt;主要发现&lt;/h4&gt;FontGuard在解码准确性和视觉质量方面优于现有方法，在合成、跨媒体和在线社交网络扭曲下分别提高了+5.4%、+7.4%和+5.8%的解码准确率，并在LPIPS方面提高了52.7%的视觉质量。&lt;h4&gt;结论&lt;/h4&gt;FontGuard是一种有效的字体水印模型，能够解决AI生成内容带来的法医和安全问题。&lt;h4&gt;翻译&lt;/h4&gt;The proliferation of AI-generated content brings significant concerns on the forensic and security issues such as source tracing, copyright protection, etc, highlighting the need for effective watermarking technologies. Font-based text watermarking has emerged as an effective solution to embed information, which could ensure copyright, traceability, and compliance of the generated text content. Existing font watermarking methods usually neglect essential font knowledge, which leads to watermarked fonts of low quality and limited embedding capacity. These methods are also vulnerable to real-world distortions, low-resolution fonts, and inaccurate character segmentation. In this paper, we introduce FontGuard, a novel font watermarking model that harnesses the capabilities of font models and language-guided contrastive learning. Unlike previous methods that focus solely on the pixel-level alteration, FontGuard modifies fonts by altering hidden style features, resulting in better font quality upon watermark embedding. We also leverage the font manifold to increase the embedding capacity of our proposed method by generating substantial font variants closely resembling the original font. Furthermore, in the decoder, we employ an image-text contrastive learning to reconstruct the embedded bits, which can achieve desirable robustness against various real-world transmission distortions. FontGuard outperforms state-of-the-art methods by +5.4%, +7.4%, and +5.8% in decoding accuracy under synthetic, cross-media, and online social network distortions, respectively, while improving the visual quality by 52.7% in terms of LPIPS. Moreover, FontGuard uniquely allows the generation of watermarked fonts for unseen fonts without re-training the network. The code and dataset are available at https://github.com/KAHIMWONG/FontGuard.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The proliferation of AI-generated content brings significant concerns on theforensic and security issues such as source tracing, copyright protection, etc,highlighting the need for effective watermarking technologies. Font-based textwatermarking has emerged as an effective solution to embed information, whichcould ensure copyright, traceability, and compliance of the generated textcontent. Existing font watermarking methods usually neglect essential fontknowledge, which leads to watermarked fonts of low quality and limitedembedding capacity. These methods are also vulnerable to real-worlddistortions, low-resolution fonts, and inaccurate character segmentation. Inthis paper, we introduce FontGuard, a novel font watermarking model thatharnesses the capabilities of font models and language-guided contrastivelearning. Unlike previous methods that focus solely on the pixel-levelalteration, FontGuard modifies fonts by altering hidden style features,resulting in better font quality upon watermark embedding. We also leverage thefont manifold to increase the embedding capacity of our proposed method bygenerating substantial font variants closely resembling the original font.Furthermore, in the decoder, we employ an image-text contrastive learning toreconstruct the embedded bits, which can achieve desirable robustness againstvarious real-world transmission distortions. FontGuard outperformsstate-of-the-art methods by +5.4%, +7.4%, and +5.8% in decoding accuracy undersynthetic, cross-media, and online social network distortions, respectively,while improving the visual quality by 52.7% in terms of LPIPS. Moreover,FontGuard uniquely allows the generation of watermarked fonts for unseen fontswithout re-training the network. The code and dataset are available athttps://github.com/KAHIMWONG/FontGuard.</description>
      <author>example@mail.com (Kahim Wong, Jicheng Zhou, Kemou Li, Yain-Whar Si, Xiaowei Wu, Jiantao Zhou)</author>
      <guid isPermaLink="false">2504.03128v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud-based Grasping for Soft Hand Exoskeleton</title>
      <link>http://arxiv.org/abs/2504.03369v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于视觉预测控制框架的软手外骨骼控制系统，用于辅助抓取，并通过深度感知实现环境上下文感知，提高抓取能力。&lt;h4&gt;背景&lt;/h4&gt;抓取是与环境中的物体互动和操作的基本技能，但对于手部有障碍的人来说，这项能力可能具有挑战性。软手外骨骼可以增强或恢复手的基本功能，但控制这些外骨骼以支持用户仍然困难。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过视觉预测控制框架，利用深度感知的环境上下文意识来预测抓取目标和确定激活的控制状态。&lt;h4&gt;方法&lt;/h4&gt;该方法基于几何建模，与需要大量标记数据集且泛化能力有限的数据驱动方法不同，能够在不同的抓取场景中实现稳健的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;使用抓取能力评分（GAS）评估性能，系统在15个物体和健康参与者中实现了91%的GAS，证明了其在不同物体类型上的有效性。&lt;h4&gt;结论&lt;/h4&gt;与基于学习模型相比，该方法在未见过的物体上保持了重建成功率，强调了其增强的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Grasping is a fundamental skill for interacting with and manipulating objects in the environment. However, this ability can be challenging for individuals with hand impairments. Soft hand exoskeletons designed to assist grasping can enhance or restore essential hand functions, yet controlling these soft exoskeletons to support users effectively remains difficult due to the complexity of understanding the environment. This study presents a vision-based predictive control framework that leverages contextual awareness from depth perception to predict the grasping target and determine the next control state for activation. Unlike data-driven approaches that require extensive labeled datasets and struggle with generalizability, our method is grounded in geometric modelling, enabling robust adaptation across diverse grasping scenarios. The Grasping Ability Score (GAS) was used to evaluate performance, with our system achieving a state-of-the-art GAS of 91% across 15 objects and healthy participants, demonstrating its effectiveness across different object types. The proposed approach maintained reconstruction success for unseen objects, underscoring its enhanced generalizability compared to learning-based models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grasping is a fundamental skill for interacting with and manipulating objectsin the environment. However, this ability can be challenging for individualswith hand impairments. Soft hand exoskeletons designed to assist grasping canenhance or restore essential hand functions, yet controlling these softexoskeletons to support users effectively remains difficult due to thecomplexity of understanding the environment. This study presents a vision-basedpredictive control framework that leverages contextual awareness from depthperception to predict the grasping target and determine the next control statefor activation. Unlike data-driven approaches that require extensive labelleddatasets and struggle with generalizability, our method is grounded ingeometric modelling, enabling robust adaptation across diverse graspingscenarios. The Grasping Ability Score (GAS) was used to evaluate performance,with our system achieving a state-of-the-art GAS of 91% across 15 objects andhealthy participants, demonstrating its effectiveness across different objecttypes. The proposed approach maintained reconstruction success for unseenobjects, underscoring its enhanced generalizability compared to learning-basedmodels.</description>
      <author>example@mail.com (Chen Hu, Enrica Tricomi, Eojin Rho, Daekyum Kim, Lorenzo Masia, Shan Luo, Letizia Gionfrida)</author>
      <guid isPermaLink="false">2504.03369v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Endo3R: Unified Online Reconstruction from Dynamic Monocular Endoscopic Video</title>
      <link>http://arxiv.org/abs/2504.03198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Endo3R的3D场景重建方法，用于从单目手术视频中实现在线尺度一致重建，旨在提高外科医生对手术场景的感知，并增强计算机辅助手术任务的效果。&lt;h4&gt;背景&lt;/h4&gt;由于内窥镜视频固有的问题，如动态变形和无纹理表面，从单目手术视频中重建3D场景是一个挑战。现有的方法要么依赖于校准或工具先验来估计尺度，要么采用SfM类似的多阶段管道，导致误差累积并需要离线优化。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需先验或额外优化的在线尺度一致重建方法，以增强外科医生对手术场景的感知。&lt;h4&gt;方法&lt;/h4&gt;Endo3R模型通过预测全局对齐的点云图、尺度一致的视频深度和相机参数来实现这一目标。该方法通过不确定性感知的双记忆机制扩展了最近的双边重建模型的能力，以实现长期增量动态重建。此外，为了解决缺乏具有真实深度和相机位姿的端孔镜数据集的问题，该方法还设计了一种具有新颖动态感知流损失的自我监督机制。&lt;h4&gt;主要发现&lt;/h4&gt;Endo3R在SCARED和Hamlyn数据集上进行了大量实验，证明了其在零样本手术视频深度预测和相机姿态估计方面的优越性能，以及在线效率。&lt;h4&gt;结论&lt;/h4&gt;Endo3R为单目手术视频的在线尺度一致重建提供了一种有效的方法，有助于提高外科医生对手术场景的感知和计算机辅助手术任务的执行。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从单目手术视频中重建3D场景可以增强外科医生的感知，因此在各种计算机辅助手术任务中发挥着至关重要的作用。然而，由于内窥镜视频固有的问题，如动态变形和无纹理表面，实现尺度一致的重建仍然是一个挑战。尽管近年来取得了进展，但当前的方法要么依赖于校准或工具先验来估计尺度，要么采用SfM类似的多阶段管道，导致误差累积并需要离线优化。在本文中，我们提出了Endo3R，一个用于从单目手术视频进行在线尺度一致重建的统一3D基础模型，无需任何先验或额外优化。我们的模型通过预测全局对齐的点云图、尺度一致的视频深度和相机参数来统一任务，无需任何离线优化。我们方法的核心贡献是通过不确定性感知的双记忆机制，将最近的双边重建模型的能力扩展到长期增量动态重建。该机制维护短期动态和长期空间一致性的历史标记。值得注意的是，为了应对手术场景的高度动态性，我们通过Sampson距离测量标记的不确定性，并过滤掉具有高不确定性的标记。关于端孔镜数据集缺乏具有真实深度和相机位姿的问题，我们进一步设计了一种具有新颖动态感知流损失的自我监督机制。在SCARED和Hamlyn数据集上进行的丰富实验表明，我们在零样本手术视频深度预测和相机姿态估计方面具有优越的性能，并且具有在线效率。项目页面：https://wrld.github.io/Endo3R/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing 3D scenes from monocular surgical videos can enhance surgeon'sperception and therefore plays a vital role in various computer-assistedsurgery tasks. However, achieving scale-consistent reconstruction remains anopen challenge due to inherent issues in endoscopic videos, such as dynamicdeformations and textureless surfaces. Despite recent advances, current methodseither rely on calibration or instrument priors to estimate scale, or employSfM-like multi-stage pipelines, leading to error accumulation and requiringoffline optimization. In this paper, we present Endo3R, a unified 3D foundationmodel for online scale-consistent reconstruction from monocular surgical video,without any priors or extra optimization. Our model unifies the tasks bypredicting globally aligned pointmaps, scale-consistent video depths, andcamera parameters without any offline optimization. The core contribution ofour method is expanding the capability of the recent pairwise reconstructionmodel to long-term incremental dynamic reconstruction by an uncertainty-awaredual memory mechanism. The mechanism maintains history tokens of bothshort-term dynamics and long-term spatial consistency. Notably, to tackle thehighly dynamic nature of surgical scenes, we measure the uncertainty of tokensvia Sampson distance and filter out tokens with high uncertainty. Regarding thescarcity of endoscopic datasets with ground-truth depth and camera poses, wefurther devise a self-supervised mechanism with a novel dynamics-aware flowloss. Abundant experiments on SCARED and Hamlyn datasets demonstrate oursuperior performance in zero-shot surgical video depth prediction and camerapose estimation with online efficiency. Project page:https://wrld.github.io/Endo3R/.</description>
      <author>example@mail.com (Jiaxin Guo, Wenzhen Dong, Tianyu Huang, Hao Ding, Ziyi Wang, Haomin Kuang, Qi Dou, Yun-Hui Liu)</author>
      <guid isPermaLink="false">2504.03198v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>A model-free feature extraction procedure for interval-valued time series prediction</title>
      <link>http://arxiv.org/abs/2504.03310v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合迁移学习和图像处理方法的新颖特征提取流程，用于预测区间值时间序列。&lt;h4&gt;背景&lt;/h4&gt;区间值时间序列的预测是一个复杂的问题，本文提出的方法旨在通过改进特征提取来提升预测性能。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效预测区间值时间序列的方法，并通过实验证明其有效性。&lt;h4&gt;方法&lt;/h4&gt;1. 将区间值时间序列转换为双变量点值时间序列作为代表形式。2. 使用多种图像处理方法（如重游图、Gramian角和场、马尔可夫转换场）将时间序列转换为图像。3. 构建图像数据集，将每种图像处理方法的输出视为一个单独的类别。4. 在此数据集上训练多个特征提取网络（FEN）候选模型，特别是具有不同层数的ResNet。5. 从FEN的倒数第二层提取最相关的特征。6. 将提取的特征整合到传统的预测模型中，形成预测模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有方法相比，该方法在预测性能上有了显著提升。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高区间值时间序列的预测性能，为相关领域的研究提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we propose a novel feature extraction procedure to predict interval-valued time series by combining transfer learning and imaging approaches. Initially, we represent interval-valued time series using a bivariate point-valued time series, which serves as a representative form. We first transform each time series into images by employing various imaging approaches such as recurrence plot, gramian angular summation/difference field, and Markov transition field, and construct an image dataset by treating each imaging method's output as a separate class. Based on this dataset, we train several candidates for a feature extraction network (FEN), specifically ResNet with varying layers. Then we choose the penultimate layer of the FEN to extract the most relevant features from the transformed images. We integrate the extracted features into conventional predictive models to formulate the corresponding prediction models. To formulate prediction, we integrate the extracted features into a regular prediction model. The proposed methods are evaluated based on the S&amp;P 500 index and three data-generating processes (DGPs), and the experimental results demonstrate a notable improvement in prediction performance compared to existing methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present a novel feature extraction procedure to predictinterval-valued time series by combing transfer learning and imagingapproaches. Initially, we represent interval-valued time series using abivariate point-valued time series, which serves as a representative form. Wefirst transform each time series into images by employing various imagingapproaches such as recurrence plot, gramian angular summation/difference field,and Markov transition field, and construct an image dataset by treating eachimaging method's output as a separate class. Based on this dataset, we trainseveral candidates for a feature extraction network (FEN), specifically ResNetwith varying layers. Then we choose the penultimate layer of the FEN to extractthe most relevant features from the transformed images. We integrate theextracted features into conventional predictive models to formulate thecorresponding prediction models. To formulate prediction, we integrate theextracted features into a regular prediction model. The proposed methods areevaluated based on the S\&amp;P 500 index and three data-generating processes(DGPs), and the experimental results demonstrate a notable improvement inprediction performance compared to existing methods.</description>
      <author>example@mail.com (Wan Tian, Zhongfeng Qin, Tao Hu)</author>
      <guid isPermaLink="false">2504.03310v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>SLACK: Attacking LiDAR-based SLAM with Adversarial Point Injections</title>
      <link>http://arxiv.org/abs/2504.03089v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了SLACK，一个用于攻击LiDAR扫描的端到端深度生成对抗模型，能够在不降低LiDAR质量的情况下进行多次点注入攻击，以应对基于学习的LiDAR方法的对抗攻击。&lt;h4&gt;背景&lt;/h4&gt;基于学习的LiDAR方法在自动驾驶车辆中广泛应用，但容易受到对抗攻击，即通过点注入（PiJ）方式对LiDAR数据进行攻击，这给导航和地图生成带来了严重的安全挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效攻击LiDAR扫描的方法，同时不降低LiDAR数据质量。&lt;h4&gt;方法&lt;/h4&gt;设计了SLACK，一个端到端的深度生成对抗模型，并设计了一种新的自编码器，通过结合对比学习和基于分割的注意力机制来增强对比学习，以实现精确的重建。&lt;h4&gt;主要发现&lt;/h4&gt;SLACK在KITTI和CARLA-64数据集上的点注入任务中，性能优于现有最佳基线，同时保持了扫描的准确性。通过使用LiDAR数据的一小部分，SLACK能够严重降低导航和地图质量，但不会降低LiDAR扫描质量。&lt;h4&gt;结论&lt;/h4&gt;SLACK能够有效地对LiDAR扫描进行攻击，为基于学习的LiDAR方法的安全性研究提供了新的视角和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The widespread adoption of learning-based methods for the LiDAR makesautonomous vehicles vulnerable to adversarial attacks through adversarial\textit{point injections (PiJ)}. It poses serious security challenges fornavigation and map generation. Despite its critical nature, no major workexists that studies learning-based attacks on LiDAR-based SLAM. Our workproposes SLACK, an end-to-end deep generative adversarial model to attack LiDARscans with several point injections without deteriorating LiDAR quality. Tofacilitate SLACK, we design a novel yet simple autoencoder that augmentscontrastive learning with segmentation-based attention for precisereconstructions. SLACK demonstrates superior performance on the task of\textit{point injections (PiJ)} compared to the best baselines on KITTI andCARLA-64 dataset while maintaining accurate scan quality. We qualitatively andquantitatively demonstrate PiJ attacks using a fraction of LiDAR points. Itseverely degrades navigation and map quality without deteriorating the LiDARscan quality.</description>
      <author>example@mail.com (Prashant Kumar, Dheeraj Vattikonda, Kshitij Madhav Bhat, Kunal Dargan, Prem Kalra)</author>
      <guid isPermaLink="false">2504.03089v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Mamba as a Bridge: Where Vision Foundation Models Meet Vision Language Models for Domain-Generalized Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2504.03193v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为MFuser的融合框架，旨在解决在领域泛化语义分割中，视觉基础模型（VFMs）和视觉-语言模型（VLMs）结合时的问题。&lt;h4&gt;背景&lt;/h4&gt;VFMs和VLMs在领域泛化语义分割（DGSS）中表现出色，但现有方法往往只依赖其中一种，忽略了它们的互补优势。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的融合框架，以有效结合VFMs和VLMs的优点，同时保持序列长度的线性可扩展性。&lt;h4&gt;方法&lt;/h4&gt;MFuser框架包括MVFuser和MTEnhancer两个主要组件：MVFuser作为共适配器，通过捕捉序列和空间动态来联合微调两个模型；MTEnhancer是一个混合注意力-Mamba模块，通过结合图像先验来细化文本嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，MFuser在合成到真实和真实到真实基准测试中显著优于最先进的DGSS方法，分别达到了68.20 mIoU和71.87 mIoU。&lt;h4&gt;结论&lt;/h4&gt;MFuser在保持线性可扩展性的同时，实现了精确的特征局部性和强大的文本对齐，为领域泛化语义分割提供了有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;Vision Foundation Models (VFMs) 和 Vision-Language Models (VLMs) 在 Domain Generalized Semantic Segmentation (DGSS) 中由于它们的强大泛化能力而受到关注。然而，现有的 DGSS 方法通常完全依赖于 VFMs 或 VLMs，忽视了它们的互补优势。VFMs（例如，DINOv2）擅长捕获细粒度特征，而 VLMs（例如，CLIP）提供稳健的文本对齐，但难以处理粗粒度。尽管它们具有互补的优势，但由于增加了补丁标记而使长序列建模复杂化，因此有效地将 VFMs 和 VLMs 与注意力机制集成是具有挑战性的。为了解决这个问题，我们提出了 MFuser，这是一种基于 Mamba 的新型融合框架，它有效地结合了 VFMs 和 VLMs 的优势，同时保持了序列长度的线性可扩展性。MFuser 由两个关键组件组成：MVFuser，它作为共适配器，通过捕捉序列和空间动态来联合微调两个模型；MTEnhancer，这是一个混合注意力-Mamba 模块，通过结合图像先验来细化文本嵌入。我们的方法在不增加显著计算开销的情况下，实现了精确的特征局部性和强大的文本对齐。大量的实验表明，MFuser 在合成到真实和真实到真实基准测试中显著优于最先进的 DGSS 方法，分别达到了 68.20 mIoU 和 71.87 mIoU。代码可在 https://github.com/devinxzhang/MFuser 上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision Foundation Models (VFMs) and Vision-Language Models (VLMs) have gainedtraction in Domain Generalized Semantic Segmentation (DGSS) due to their stronggeneralization capabilities. However, existing DGSS methods often relyexclusively on either VFMs or VLMs, overlooking their complementary strengths.VFMs (e.g., DINOv2) excel at capturing fine-grained features, while VLMs (e.g.,CLIP) provide robust text alignment but struggle with coarse granularity.Despite their complementary strengths, effectively integrating VFMs and VLMswith attention mechanisms is challenging, as the increased patch tokenscomplicate long-sequence modeling. To address this, we propose MFuser, a novelMamba-based fusion framework that efficiently combines the strengths of VFMsand VLMs while maintaining linear scalability in sequence length. MFuserconsists of two key components: MVFuser, which acts as a co-adapter to jointlyfine-tune the two models by capturing both sequential and spatial dynamics; andMTEnhancer, a hybrid attention-Mamba module that refines text embeddings byincorporating image priors. Our approach achieves precise feature locality andstrong text alignment without incurring significant computational overhead.Extensive experiments demonstrate that MFuser significantly outperformsstate-of-the-art DGSS methods, achieving 68.20 mIoU on synthetic-to-real and71.87 mIoU on real-to-real benchmarks. The code is available athttps://github.com/devinxzhang/MFuser.</description>
      <author>example@mail.com (Xin Zhang, Robby T. Tan)</author>
      <guid isPermaLink="false">2504.03193v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>LiDAR-based Object Detection with Real-time Voice Specifications</title>
      <link>http://arxiv.org/abs/2504.02920v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures, submitted as part of MSc research&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于LiDAR的对象检测系统，该系统具备实时语音指定功能，通过多模态PointNet框架整合KITTI的3D点云和RGB图像，验证集准确率达到87.0%，超过67.5%的200样本基线。系统通过结合空间和视觉数据、使用加权损失解决类别不平衡问题，并通过自适应技术优化训练。Tkinter原型提供使用Edge TTS（en-IN-PrabhatNeural）的自然印度男性语音输出，同时提供3D可视化和实时反馈，增强自动驾驶导航、辅助技术等领域的可访问性和安全性。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶导航、辅助技术等领域需要高准确度的对象检测系统，并且需要结合空间和视觉数据以及语音交互功能。&lt;h4&gt;目的&lt;/h4&gt;开发一个高准确度、具备实时语音指定功能的多模态对象检测系统，以增强自动驾驶导航、辅助技术等领域的应用。&lt;h4&gt;方法&lt;/h4&gt;使用KITTI的3D点云和RGB图像，通过多模态PointNet框架进行整合；结合空间和视觉数据，使用加权损失解决类别不平衡问题；通过自适应技术优化训练；使用Tkinter和Edge TTS实现自然语音输出。&lt;h4&gt;主要发现&lt;/h4&gt;系统在3000样本子集上的验证准确率达到87.0%，超过基线；通过结合数据和优化训练技术提高了准确率。&lt;h4&gt;结论&lt;/h4&gt;该系统是一个可扩展的进步，在人类-计算机交互和环境感知方面具有广泛应用前景，符合当前研究趋势。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents a LiDAR-based object detection system with real-time voice specifications, integrating KITTI's 3D point clouds and RGB images through a multi-modal PointNet framework. It achieves 87.0% validation accuracy on a 3000-sample subset, surpassing a 200-sample baseline of 67.5% by combining spatial and visual data, addressing class imbalance with weighted loss, and refining training via adaptive techniques. A Tkinter prototype provides natural Indian male voice output using Edge TTS (en-IN-PrabhatNeural), alongside 3D visualizations and real-time feedback, enhancing accessibility and safety in autonomous navigation, assistive technology, and beyond. The study offers a detailed methodology, comprehensive experimental analysis, and a broad review of applications and challenges, establishing this work as a scalable advancement in human-computer interaction and environmental perception, aligned with current research trends.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a LiDAR-based object detection system with real-timevoice specifications, integrating KITTI's 3D point clouds and RGB imagesthrough a multi-modal PointNet framework. It achieves 87.0% validation accuracyon a 3000-sample subset, surpassing a 200-sample baseline of 67.5% by combiningspatial and visual data, addressing class imbalance with weighted loss, andrefining training via adaptive techniques. A Tkinter prototype provides naturalIndian male voice output using Edge TTS (en-IN-PrabhatNeural), alongside 3Dvisualizations and real-time feedback, enhancing accessibility and safety inautonomous navigation, assistive technology, and beyond. The study offers adetailed methodology, comprehensive experimental analysis, and a broad reviewof applications and challenges, establishing this work as a scalableadvancement in human-computer interaction and environmental perception, alignedwith current research trends.</description>
      <author>example@mail.com (Anurag Kulkarni)</author>
      <guid isPermaLink="false">2504.02920v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Improving log-based anomaly detection through learned adaptive filter</title>
      <link>http://arxiv.org/abs/2504.02994v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度强化学习（DRL）的日志异常检测方法，通过构建学习自适应过滤器，针对不同日志序列应用不同的正常/异常过滤阈值，以提升日志异常检测的性能。&lt;h4&gt;背景&lt;/h4&gt;日志记录了系统运行时的重要信息，对于检测异常行为和管理现代软件系统非常有用。现有的无监督方法在预测下一个日志事件时使用固定配置，导致检测性能不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种自适应的日志异常检测方法，以应对不同日志序列的动态性和变化性。&lt;h4&gt;方法&lt;/h4&gt;使用深度强化学习（DRL）构建学习自适应过滤器，并定义马尔可夫决策过程（MDP）来解决这个问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在两个数据集HDFS和BGL上优于固定配置，显著提升了日志异常检测的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过自适应过滤器在日志异常检测中取得了更好的性能。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Log messages record important system runtime information and are useful for detecting anomalous behaviors and managing modern software systems. Many supervised and unsupervised learning methods have been proposed recently for log-based anomaly detection. State-of-the-art unsupervised methods predict the next log event given a log sequence and apply fixed configurations that use the same filter condition (i.e., k, the top k predicted log events will be regarded as normal next events), which leads to inferior performance in the detection stage because it sets one fixed k for all log sequences, which ignores the dynamic nature and variance in different log sequences. Recently, deep reinforcement learning (DRL) are widely applied to make intelligent decisions in a dynamic environment. In this work, we contend that it is necessary to apply adaptive filters for different log sequences. To achieve this, we propose a novel approach based on DRL to construct a learned adaptive filter and apply different normal/abnormal filter thresholds for different log sequences. We define the Markov Decision Process (MDP) and formulate the learned adaptive filter as a problem that can be solved by DRL. We evaluate the learned adaptive filter on two state-of-the-art log-based anomaly detection unsupervised approaches DeepLog and LogAnomaly in two datasets HDFS and BGL. Extensive experiments show that our approach outperforms the fixed configurations and achieves significantly better performance in log-based anomaly detection.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Log messages record important system runtime information and are useful fordetecting anomalous behaviors and managing modern software systems. Manysupervised and unsupervised learning methods have been proposed recently forlog-based anomaly detection. State-of-the-art unsupervised methods predict thenext log event given a log sequence and apply fixed configurations that use thesame filter condition (i.e. k, the top k predicted log events will be regardedas normal next events) which leads to inferior performance in the detectionstage because it sets one fixed k for all log sequences, which ignores thedynamic nature and variance in different log sequences. Recently, deepreinforcement learning (DRL) are widely applied to make intelligent decisionsin a dynamic environment. In this work, we contend that it is necessary toapply adaptive filters for different log sequences. To achieve this, we proposea novel approach based on DRL to construct a learned adaptive filter and applydifferent normal/abnormal filter thresholds for different log sequences. Wedefine the Markov Decision Process (MDP) and formulate the learned adaptivefilter as a problem that can be solved by DRL. We evaluate the learned adaptivefilter on two state-of-the-art log-based anomaly detection unsupervisedapproaches DeepLog and LogAnomaly in two datasets HDFS and BGL. Extensiveexperiments show that our approach outperforms the fixed configurations andachieves significantly better performance in log-based anomaly detection.</description>
      <author>example@mail.com (Yiyuan Xiong, Shaofeng Cai)</author>
      <guid isPermaLink="false">2504.02994v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Overcoming Deceptiveness in Fitness Optimization with Unsupervised Quality-Diversity</title>
      <link>http://arxiv.org/abs/2504.01915v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种无监督的QD算法AURORA-XCon，该算法通过学习感官数据中的特征，能够高效地解决欺骗性优化问题，且无需领域专业知识。&lt;h4&gt;背景&lt;/h4&gt;政策优化是工程和研究的根本领域，在机器人等领域有应用。传统优化方法如强化学习和进化算法在欺骗性适应度景观中难以找到最优解。&lt;h4&gt;目的&lt;/h4&gt;研究无监督QD算法在解决欺骗性优化问题中的应用，并提高其性能。&lt;h4&gt;方法&lt;/h4&gt;提出AURORA框架，通过对比学习和周期性灭绝事件增强AURORA，形成AURORA-XCon算法。&lt;h4&gt;主要发现&lt;/h4&gt;AURORA-XCon算法在欺骗性优化问题中表现优于传统优化基线，在某些情况下甚至比具有领域特定手工特征的QD基线提高了34%。&lt;h4&gt;结论&lt;/h4&gt;AURORA-XCon算法为无监督QD算法在传统优化领域的应用开辟了新的途径，并扩大了其在特征空间定义困难的领域的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;Policy optimization seeks the best solution to a control problem according to an objective or fitness function, serving as a fundamental field of engineering and research with applications in robotics. Traditional optimization methods like reinforcement learning and evolutionary algorithms struggle with deceptive fitness landscapes, where following immediate improvements leads to suboptimal solutions. Quality-diversity (QD) algorithms offer a promising approach by maintaining diverse intermediate solutions as stepping stones for escaping local optima. However, QD algorithms require domain expertise to define hand-crafted features, limiting their applicability where characterizing solution diversity remains unclear. In this paper, we show that unsupervised QD algorithms - specifically the AURORA framework, which learns features from sensory data - efficiently solve deceptive optimization problems without domain expertise. By enhancing AURORA with contrastive learning and periodic extinction events, we propose AURORA-XCon, which outperforms all traditional optimization baselines and matches, in some cases even improving by up to 34%, the best QD baseline with domain-specific hand-crafted features. This work establishes a novel application of unsupervised QD algorithms, shifting their focus from discovering novel solutions toward traditional optimization and expanding their potential to domains where defining feature spaces poses challenges.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3712256.3726314&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/lisacoiffard/aurora-xcon&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Policy optimization seeks the best solution to a control problem according toan objective or fitness function, serving as a fundamental field of engineeringand research with applications in robotics. Traditional optimization methodslike reinforcement learning and evolutionary algorithms struggle with deceptivefitness landscapes, where following immediate improvements leads to suboptimalsolutions. Quality-diversity (QD) algorithms offer a promising approach bymaintaining diverse intermediate solutions as stepping stones for escapinglocal optima. However, QD algorithms require domain expertise to definehand-crafted features, limiting their applicability where characterizingsolution diversity remains unclear. In this paper, we show that unsupervised QDalgorithms - specifically the AURORA framework, which learns features fromsensory data - efficiently solve deceptive optimization problems without domainexpertise. By enhancing AURORA with contrastive learning and periodicextinction events, we propose AURORA-XCon, which outperforms all traditionaloptimization baselines and matches, in some cases even improving by up to 34%,the best QD baseline with domain-specific hand-crafted features. This workestablishes a novel application of unsupervised QD algorithms, shifting theirfocus from discovering novel solutions toward traditional optimization andexpanding their potential to domains where defining feature spaces poseschallenges.</description>
      <author>example@mail.com (Lisa Coiffard, Paul Templier, Antoine Cully)</author>
      <guid isPermaLink="false">2504.01915v2</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Morpheus: Benchmarking Physical Reasoning of Video Generative Models with Real Physical Experiments</title>
      <link>http://arxiv.org/abs/2504.02918v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了图像和视频生成模型在物理世界建模方面的潜力，并提出了一个名为Morpheus的基准测试来评估这些模型的物理推理能力。&lt;h4&gt;背景&lt;/h4&gt;近期在图像和视频生成方面取得了显著进展，这些模型有望具备世界建模能力，即生成真实、物理上合理的视频，这可能会革新机器人、自动驾驶和科学模拟等领域。&lt;h4&gt;目的&lt;/h4&gt;在将这些模型视为世界模型之前，研究者们提出需要检验它们是否遵循物理守恒定律。&lt;h4&gt;方法&lt;/h4&gt;研究者们介绍了Morpheus，一个用于评估视频生成模型在物理推理方面的基准测试。它包含了80个反映物理现象的真实世界视频，这些视频受守恒定律指导。由于人工生成的视频缺乏真实世界数据，研究者们利用物理学信息和视觉语言基础模型，通过物理学告知的指标来评估物理合理性。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，即使在高级提示和视频条件化下，当前的模型在编码物理原理方面仍存在困难，尽管它们生成的视频在美学上令人满意。&lt;h4&gt;结论&lt;/h4&gt;所有数据、排行榜和代码都在项目的页面上开源。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Recent advances in image and video generation raise hopes that these models possess world modeling capabilities, the ability to generate realistic, physically plausible videos. This could revolutionize applications in robotics, autonomous driving, and scientific simulation. However, before treating these models as world models, we must ask: Do they adhere to physical conservation laws? To answer this, we introduce Morpheus, a benchmark for evaluating video generation models on physical reasoning. It features 80 real-world videos capturing physical phenomena, guided by conservation laws. Since artificial generations lack ground truth, we assess physical plausibility using physics-informed metrics evaluated with respect to infallible conservation laws known per physical setting, leveraging advances in physics-informed neural networks and vision-language foundation models. Our findings reveal that even with advanced prompting and video conditioning, current models struggle to encode physical principles despite generating aesthetically pleasing videos. All data, leaderboard, and code are open-sourced at our project page.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in image and video generation raise hopes that these modelspossess world modeling capabilities, the ability to generate realistic,physically plausible videos. This could revolutionize applications in robotics,autonomous driving, and scientific simulation. However, before treating thesemodels as world models, we must ask: Do they adhere to physical conservationlaws? To answer this, we introduce Morpheus, a benchmark for evaluating videogeneration models on physical reasoning. It features 80 real-world videoscapturing physical phenomena, guided by conservation laws. Since artificialgenerations lack ground truth, we assess physical plausibility usingphysics-informed metrics evaluated with respect to infallible conservation lawsknown per physical setting, leveraging advances in physics-informed neuralnetworks and vision-language foundation models. Our findings reveal that evenwith advanced prompting and video conditioning, current models struggle toencode physical principles despite generating aesthetically pleasing videos.All data, leaderboard, and code are open-sourced at our project page.</description>
      <author>example@mail.com (Chenyu Zhang, Daniil Cherniavskii, Andrii Zadaianchuk, Antonios Tragoudaras, Antonios Vozikis, Thijmen Nijdam, Derck W. E. Prinzhorn, Mark Bodracska, Nicu Sebe, Efstratios Gavves)</author>
      <guid isPermaLink="false">2504.02918v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>SPF-Portrait: Towards Pure Portrait Customization with Semantic Pollution-Free Fine-tuning</title>
      <link>http://arxiv.org/abs/2504.00396v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SPF-Portrait的文本驱动肖像定制方法，旨在解决在微调预训练的文本到图像（T2I）模型时出现的语义污染问题，以实现更好的性能和增量学习。&lt;h4&gt;背景&lt;/h4&gt;现有的T2I模型微调方法在定制肖像属性时，由于语义污染难以保持原始模型的行为和实现增量学习。&lt;h4&gt;目的&lt;/h4&gt;提出SPF-Portrait，旨在理解定制语义的同时消除文本驱动肖像定制中的语义污染。&lt;h4&gt;方法&lt;/h4&gt;SPF-Portrait采用了一种双路径流程，将原始模型作为参考，通过对比学习确保对目标属性的适应，并有意将其他无关属性与原始肖像对齐。此外，引入了一种新的语义感知精细控制图，以空间引导对比路径之间的对齐过程。还提出了一种新的响应增强机制，以增强目标属性的性能，同时减轻跨模态监督中固有的表示差异。&lt;h4&gt;主要发现&lt;/h4&gt;SPF-Portrait不仅有效地保留了原始模型的表现，还避免了过度对齐，并通过实验证明了其达到最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;SPF-Portrait是一种有效的文本驱动肖像定制方法，能够显著提高性能并避免语义污染。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a method named SPF-Portrait for text-driven portrait customization, aiming to solve the problem of semantic pollution during the fine-tuning of pre-trained Text-to-Image (T2I) models, in order to achieve better performance and incremental learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-tuning a pre-trained Text-to-Image (T2I) model on a tailored portraitdataset is the mainstream method for text-driven customization of portraitattributes. Due to Semantic Pollution during fine-tuning, existing methodsstruggle to maintain the original model's behavior and achieve incrementallearning while customizing target attributes. To address this issue, we proposeSPF-Portrait, a pioneering work to purely understand customized semantics whileeliminating semantic pollution in text-driven portrait customization. In ourSPF-Portrait, we propose a dual-path pipeline that introduces the originalmodel as a reference for the conventional fine-tuning path. Through contrastivelearning, we ensure adaptation to target attributes and purposefully alignother unrelated attributes with the original portrait. We introduce a novelSemantic-Aware Fine Control Map, which represents the precise response regionsof the target semantics, to spatially guide the alignment process between thecontrastive paths. This alignment process not only effectively preserves theperformance of the original model but also avoids over-alignment. Furthermore,we propose a novel response enhancement mechanism to reinforce the performanceof target attributes, while mitigating representation discrepancy inherent indirect cross-modal supervision. Extensive experiments demonstrate thatSPF-Portrait achieves state-of-the-art performance. Project webpage:https://spf-portrait.github.io/SPF-Portrait/</description>
      <author>example@mail.com (Xiaole Xian, Zhichao Liao, Qingyu Li, Wenyu Qin, Pengfei Wan, Weicheng Xie, Long Zeng, Linlin Shen, Pingfa Feng)</author>
      <guid isPermaLink="false">2504.00396v2</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Can DeepSeek Reason Like a Surgeon? An Empirical Evaluation for Vision-Language Understanding in Robotic-Assisted Surgery</title>
      <link>http://arxiv.org/abs/2503.23130v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DeepSeek模型在场景理解、问答和文本生成任务中表现出色，本研究调查了其在机器人手术场景中的对话能力，包括单短语问答、视觉问答和详细描述等任务。&lt;h4&gt;背景&lt;/h4&gt;DeepSeek模型因其高效的训练范式和强大的推理能力在通用场景理解、问答和文本生成任务中表现出色。&lt;h4&gt;目的&lt;/h4&gt;研究DeepSeek模型在机器人手术场景中的对话能力，特别是单短语问答、视觉问答和详细描述等任务。&lt;h4&gt;方法&lt;/h4&gt;使用公开数据集EndoVis18和CholecT50及其对应的对话数据进行广泛评估。&lt;h4&gt;主要发现&lt;/h4&gt;DeepSeek-VL2在手术场景的复杂理解任务上优于现有的通用多模态大型语言模型；DeepSeek-V3在直接输入图像标记时在单句问答任务上表现出更好性能；但DeepSeek模型在满足临床要求理解手术场景方面仍有不足。&lt;h4&gt;结论&lt;/h4&gt;DeepSeek模型在未经手术特定数据集微调的情况下，不适合用于手术场景中的视觉语言任务。&lt;h4&gt;翻译&lt;/h4&gt;The DeepSeek models have shown exceptional performance in general sceneunderstanding, question-answering (QA), and text generation tasks, owingto their efficient training paradigm and strong reasoning capabilities. Inthis study, we investigate the dialogue capabilities of the DeepSeek modelin robotic surgery scenarios, focusing on tasks such as Single Phrase QA,Visual QA, and Detailed Description. The Single Phrase QA tasks furtherincludesub-tasks such as surgical instrument recognition, action understanding, andspatial position analysis. We conduct extensive evaluations using publiclyavailable datasets, including EndoVis18 and CholecT50, along with theircorresponding dialogue data. Our empirical study shows that, compared toexisting general-purpose multimodal large language models, DeepSeek-VL2performs better on complex understanding tasks in surgical scenes. Additionally,although DeepSeek-V3 is purely a language model, we find that when imagetokens are directly inputted, the model demonstrates better performance onsentence QA tasks. However, overall, the DeepSeek models still fall short ofmeeting the clinical requirements for understanding surgical scenes. Undergeneral prompts, DeepSeek models lack the ability to effectively analyze global surgical concepts and fail to provide detailed insights into surgical scenarios. Based on our observations, we argue that the DeepSeek models are not ready for vision-language tasks in surgical contextswithout fine-tuning on surgery-specific datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The DeepSeek models have shown exceptional performance in general sceneunderstanding, question-answering (QA), and text generation tasks, owing totheir efficient training paradigm and strong reasoning capabilities. In thisstudy, we investigate the dialogue capabilities of the DeepSeek model inrobotic surgery scenarios, focusing on tasks such as Single Phrase QA, VisualQA, and Detailed Description. The Single Phrase QA tasks further includesub-tasks such as surgical instrument recognition, action understanding, andspatial position analysis. We conduct extensive evaluations using publiclyavailable datasets, including EndoVis18 and CholecT50, along with theircorresponding dialogue data. Our empirical study shows that, compared toexisting general-purpose multimodal large language models, DeepSeek-VL2performs better on complex understanding tasks in surgical scenes.Additionally, although DeepSeek-V3 is purely a language model, we find thatwhen image tokens are directly inputted, the model demonstrates betterperformance on single-sentence QA tasks. However, overall, the DeepSeek modelsstill fall short of meeting the clinical requirements for understandingsurgical scenes. Under general prompts, DeepSeek models lack the ability toeffectively analyze global surgical concepts and fail to provide detailedinsights into surgical scenarios. Based on our observations, we argue that theDeepSeek models are not ready for vision-language tasks in surgical contextswithout fine-tuning on surgery-specific datasets.</description>
      <author>example@mail.com (Boyi Ma, Yanguang Zhao, Jie Wang, Guankun Wang, Kun Yuan, Tong Chen, Long Bai, Hongliang Ren)</author>
      <guid isPermaLink="false">2503.23130v3</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Capabilities of LLMs for IMU-based Fine-grained Human Activity Understanding</title>
      <link>http://arxiv.org/abs/2504.02878v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to The 2nd International Workshop on Foundation Models for  Cyber-Physical Systems &amp; Internet of Things (FMSys 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用惯性测量单元（IMUs）进行人类活动识别（HAR），并探讨了利用大型语言模型（LLMs）在细粒度HAR任务上的应用。&lt;h4&gt;背景&lt;/h4&gt;现有方法主要关注粗粒度活动，如行走或跑步，而预训练的LLMs在细粒度HAR任务上，如空中书写字母识别，表现不佳。&lt;h4&gt;目的&lt;/h4&gt;旨在提高LLMs在细粒度HAR任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;通过使用自收集的数据集和少量样本学习对LLMs进行微调，并设计了一个基于编码器的流程，将3D数据映射到2D等价数据，以保持时空信息，从而实现稳健的字母预测。&lt;h4&gt;主要发现&lt;/h4&gt;在平坦表面书写场景中，通过微调和少量样本学习，在2D数据上实现了129倍的改进。在空中书写场景中，端到端流程在识别包含最多5个字母的单词时达到了78%的准确率。&lt;h4&gt;结论&lt;/h4&gt;LLMs可以作为细粒度HAR的有用工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：使用惯性测量单元（IMUs）进行的人类活动识别（HAR）越来越多地利用大型语言模型（LLMs），然而，现有方法主要关注粗粒度活动，如行走或跑步。我们的初步研究表明，预训练的LLMs在细粒度HAR任务上，如空中书写字母识别，表现极差，几乎只能达到随机猜测的准确率。在这项工作中，我们首先填补了这一差距，针对平坦表面书写场景：通过使用自收集的数据集和少量样本学习对LLMs进行微调，我们在2D数据上实现了129倍的改进。为了扩展到3D场景，我们设计了一个基于编码器的流程，将3D数据映射到2D等价数据，以保留时空信息，从而实现稳健的字母预测。我们的端到端流程在中空书写场景中识别最多5个字母的单词时达到了78%的准确率，确立了LLMs作为细粒度HAR的有用工具的地位。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human activity recognition (HAR) using inertial measurement units (IMUs)increasingly leverages large language models (LLMs), yet existing approachesfocus on coarse activities like walking or running. Our preliminary studyindicates that pretrained LLMs fail catastrophically on fine-grained HAR taskssuch as air-written letter recognition, achieving only near-random guessingaccuracy. In this work, we first bridge this gap for flat-surface writingscenarios: by fine-tuning LLMs with a self-collected dataset and few-shotlearning, we achieved up to a 129x improvement on 2D data. To extend this to 3Dscenarios, we designed an encoder-based pipeline that maps 3D data into 2Dequivalents, preserving the spatiotemporal information for robust letterprediction. Our end-to-end pipeline achieves 78% accuracy on word recognitionwith up to 5 letters in mid-air writing scenarios, establishing LLMs as viabletools for fine-grained HAR.</description>
      <author>example@mail.com (Lilin Xu, Kaiyuan Hou, Xiaofan Jiang)</author>
      <guid isPermaLink="false">2504.02878v1</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>LogiCity: Advancing Neuro-Symbolic AI with Abstract Urban Simulation</title>
      <link>http://arxiv.org/abs/2411.00773v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 8 figures, In Advances in Neural Information Processing  Systems (NeurIPS) 37 D&amp;B Track (2024): 69840-69864&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;LogiCity是一个基于可定制一阶逻辑的城市环境模拟器，旨在解决现有NeSy AI基准测试的不足，为多智能体交互提供长周期推理任务。&lt;h4&gt;背景&lt;/h4&gt;近年来，NeSy AI系统迅速发展，但现有的NeSy AI基准测试未能提供具有复杂多智能体交互的长周期推理任务，且通常受限于固定的简单逻辑规则。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，LogiCity被引入作为第一个基于可定制一阶逻辑的模拟器，用于模拟具有多个动态智能体的城市环境。&lt;h4&gt;方法&lt;/h4&gt;LogiCity使用语义和空间概念（如IsAmbulance(X)和IsClose(X, Y)）来定义一阶逻辑规则，这些规则控制不同智能体的行为。用户可以配置抽象级别，以适应不同场景的复杂度。&lt;h4&gt;主要发现&lt;/h4&gt;LogiCity在抽象推理方面显示了NeSy框架的优势，并突出了在长周期多智能体场景或高维、不平衡数据下处理更复杂抽象的挑战。&lt;h4&gt;结论&lt;/h4&gt;LogiCity被认为是NeSy AI发展中的一个重要步骤，其灵活的设计和特点为下一代NeSy AI的进步奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;最近几年，神经符号（NeSy）人工智能系统得到了快速发展，这些系统将符号推理集成到深度神经网络中。然而，大多数现有的NeSy AI基准测试未能提供具有复杂多智能体交互的长周期推理任务。此外，它们通常受限于固定和简化的逻辑规则，这些规则适用于有限的实体，使得它们远远不能反映现实世界的复杂性。为了解决这些关键差距，我们引入了LogiCity，这是第一个基于可定制一阶逻辑的城市环境模拟器，用于具有多个动态智能体的环境。LogiCity使用语义和空间概念（如IsAmbulance(X)和IsClose(X, Y)）来建模各种城市元素。这些概念用于定义控制各种智能体行为的FOL规则。由于概念和规则是抽象的，它们可以普遍适用于任何智能体组成的城市，从而便于实现各种场景的实例化。此外，LogiCity的一个关键特性是其支持用户可配置的抽象，这使得逻辑推理的复杂度可以定制。为了探索NeSy AI的各个方面，LogiCity引入了两个任务，一个具有长周期顺序决策的特点，另一个专注于一步视觉推理，难度和智能体行为各异。我们的广泛评估揭示了NeSy框架在抽象推理方面的优势。此外，我们强调了在长周期多智能体场景或高维、不平衡数据下处理更复杂抽象的挑战。凭借其灵活的设计、各种功能和提出的新挑战，我们认为LogiCity是NeSy AI进步中的一个关键步骤。所有代码和数据都在我们的网站上开源：https://jaraxxus-me.github.io/LogiCity/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Jaraxxus-Me/LogiCity&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent years have witnessed the rapid development of Neuro-Symbolic (NeSy) AIsystems, which integrate symbolic reasoning into deep neural networks. However,most of the existing benchmarks for NeSy AI fail to provide long-horizonreasoning tasks with complex multi-agent interactions. Furthermore, they areusually constrained by fixed and simplistic logical rules over limitedentities, making them far from real-world complexities. To address thesecrucial gaps, we introduce LogiCity, the first simulator based on customizablefirst-order logic (FOL) for an urban-like environment with multiple dynamicagents. LogiCity models diverse urban elements using semantic and spatialconcepts, such as IsAmbulance(X) and IsClose(X, Y). These concepts are used todefine FOL rules that govern the behavior of various agents. Since the conceptsand rules are abstractions, they can be universally applied to cities with anyagent compositions, facilitating the instantiation of diverse scenarios.Besides, a key feature of LogiCity is its support for user-configurableabstractions, enabling customizable simulation complexities for logicalreasoning. To explore various aspects of NeSy AI, LogiCity introduces twotasks, one features long-horizon sequential decision-making, and the otherfocuses on one-step visual reasoning, varying in difficulty and agentbehaviors. Our extensive evaluation reveals the advantage of NeSy frameworks inabstract reasoning. Moreover, we highlight the significant challenges ofhandling more complex abstractions in long-horizon multi-agent scenarios orunder high-dimensional, imbalanced data. With its flexible design, variousfeatures, and newly raised challenges, we believe LogiCity represents a pivotalstep forward in advancing the next generation of NeSy AI. All the code and dataare open-sourced at our website: https://jaraxxus-me.github.io/LogiCity/</description>
      <author>example@mail.com (Bowen Li, Zhaoyu Li, Qiwei Du, Jinqi Luo, Wenshan Wang, Yaqi Xie, Simon Stepputtis, Chen Wang, Katia P. Sycara, Pradeep Kumar Ravikumar, Alexander G. Gray, Xujie Si, Sebastian Scherer)</author>
      <guid isPermaLink="false">2411.00773v2</guid>
      <pubDate>Mon, 07 Apr 2025 14:18:46 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Language-Free Visual Representation Learning</title>
      <link>http://arxiv.org/abs/2504.01017v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page at https://davidfan.io/webssl/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了视觉自监督学习（Visual Self-Supervised Learning, SSL）在多模态设置，如视觉问答（Visual Question Answering, VQA）中表现不如对比语言-图像预训练（Contrastive Language-Image Pretraining, CLIP）的原因，并提出了纯视觉SSL方法在规模上可以与语言监督视觉预训练相媲美的观点。&lt;h4&gt;背景&lt;/h4&gt;视觉自监督学习在多模态设置中表现不如CLIP，通常认为这是由于语言监督引入的语义差异，尽管视觉SSL和CLIP模型通常在训练数据上有所不同。&lt;h4&gt;目的&lt;/h4&gt;研究视觉自监督方法是否由于缺乏语言监督或训练数据差异而落后于CLIP。&lt;h4&gt;方法&lt;/h4&gt;在MetaCLIP数据上训练视觉SSL和CLIP模型，并利用VQA作为视觉编码器的多样化测试平台。在受控环境中，研究了视觉SSL模型在数据和模型容量方面的表现，以及视觉SSL性能在参数扩展到70亿后是否饱和。&lt;h4&gt;主要发现&lt;/h4&gt;在受控设置中，视觉SSL模型在数据和模型容量方面优于CLIP模型，且在参数扩展到70亿后，视觉SSL的性能并未饱和。视觉SSL方法在广泛的VQA和经典视觉基准测试中达到了CLIP级别的性能。&lt;h4&gt;结论&lt;/h4&gt;这些发现表明，纯视觉自监督学习在规模上可以与语言监督的视觉预训练相媲美，为视觉中心表征学习开辟了新的机会。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Visual Self-Supervised Learning (SSL) currently underperforms Contrastive Language-Image Pretraining (CLIP) in multimodal settings such as Visual Question Answering (VQA). This multimodal gap is often attributed to the semantics introduced by language supervision, even though visual SSL and CLIP models are often trained on different data. In this work, we ask the question: 'Do visual self-supervised approaches lag behind CLIP due to the lack of language supervision, or differences in the training data?' We study this question by training both visual SSL and CLIP models on the same MetaCLIP data, and leveraging VQA as a diverse testbed for vision encoders. In this controlled setup, visual SSL models scale better than CLIP models in terms of data and model capacity, and visual SSL performance does not saturate even after scaling up to 7B parameters. Consequently, we observe visual SSL methods achieve CLIP-level performance on a wide range of VQA and classic vision benchmarks. These findings demonstrate that pure visual SSL can match language-supervised visual pretraining at scale, opening new opportunities for vision-centric representation learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Self-Supervised Learning (SSL) currently underperforms ContrastiveLanguage-Image Pretraining (CLIP) in multimodal settings such as VisualQuestion Answering (VQA). This multimodal gap is often attributed to thesemantics introduced by language supervision, even though visual SSL and CLIPmodels are often trained on different data. In this work, we ask the question:"Do visual self-supervised approaches lag behind CLIP due to the lack oflanguage supervision, or differences in the training data?" We study thisquestion by training both visual SSL and CLIP models on the same MetaCLIP data,and leveraging VQA as a diverse testbed for vision encoders. In this controlledsetup, visual SSL models scale better than CLIP models in terms of data andmodel capacity, and visual SSL performance does not saturate even after scalingup to 7B parameters. Consequently, we observe visual SSL methods achieveCLIP-level performance on a wide range of VQA and classic vision benchmarks.These findings demonstrate that pure visual SSL can match language-supervisedvisual pretraining at scale, opening new opportunities for vision-centricrepresentation learning.</description>
      <author>example@mail.com (David Fan, Shengbang Tong, Jiachen Zhu, Koustuv Sinha, Zhuang Liu, Xinlei Chen, Michael Rabbat, Nicolas Ballas, Yann LeCun, Amir Bar, Saining Xie)</author>
      <guid isPermaLink="false">2504.01017v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
  <item>
      <title>Multi-Head Adaptive Graph Convolution Network for Sparse Point Cloud-Based Human Activity Recognition</title>
      <link>http://arxiv.org/abs/2504.02778v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了使用毫米波雷达进行人类活动识别的研究，旨在提高老年人及需要帮助者的独立生活支持。&lt;h4&gt;背景&lt;/h4&gt;人类活动识别对于支持老年人独立生活和需要帮助的人来说至关重要。虽然基于图像的方法在过去十年中取得了显著进展，但它们的应用受到隐私保护和光线条件限制的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于毫米波雷达和自适应图卷积框架的人类活动识别方法，以克服现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为多头自适应核（MAK）的模块，该模块在图卷积框架内生成多个动态核，以适应不同局部特征空间的不同方面。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在基准数据集上取得了最先进的性能，证明了其在人类活动识别中的有效性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够适应不同的局部特征，并在人类活动识别任务中实现最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;Human activity recognition is increasingly vital for supporting independent living, particularly for the elderly and those in need of assistance. Domesticservice robots with monitoring capabilities can enhance safety and provide essential support. Although image-based methods have advanced considerably in the past decade, their adoption remains limited by concerns over privacy and sensitivity to low-light or dark conditions. As an alternative, millimetre-wave (mmWave) radar can produce point cloud data which is privacy-preserving. However, processing the sparse and noisy point clouds remains a long-standing challenge. While graph-based methods and attention mechanisms show promise, they predominantly rely on 'fixed' kernels; kernels that are applied uniformly across all neighbourhoods, highlighting the need for adaptive approaches that can dynamically adjust their kernels to the specific geometry of each local neighbourhood in point cloud data. To overcome this limitation, we introduce an adaptive approach within the graph convolutional framework. Instead of a single shared weight function, our Multi-Head Adaptive Kernel (MAK) module generates multiple dynamic kernels, each capturing different aspects of the local featurespace. By progressively refining local features while maintaining global spatial context, our method enables convolution kernels to adapt to varying local features. Experimental results on benchmark datasets confirm the effectiveness of our approach, achieving state-of-the-art performance in human activity recognition. Our source code is made publicly available at: https://github.com/Gbouna/MAK-GCN&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human activity recognition is increasingly vital for supporting independentliving, particularly for the elderly and those in need of assistance. Domesticservice robots with monitoring capabilities can enhance safety and provideessential support. Although image-based methods have advanced considerably inthe past decade, their adoption remains limited by concerns over privacy andsensitivity to low-light or dark conditions. As an alternative, millimetre-wave(mmWave) radar can produce point cloud data which is privacy-preserving.However, processing the sparse and noisy point clouds remains a long-standingchallenge. While graph-based methods and attention mechanisms show promise,they predominantly rely on "fixed" kernels; kernels that are applied uniformlyacross all neighbourhoods, highlighting the need for adaptive approaches thatcan dynamically adjust their kernels to the specific geometry of each localneighbourhood in point cloud data. To overcome this limitation, we introduce anadaptive approach within the graph convolutional framework. Instead of a singleshared weight function, our Multi-Head Adaptive Kernel (MAK) module generatesmultiple dynamic kernels, each capturing different aspects of the local featurespace. By progressively refining local features while maintaining globalspatial context, our method enables convolution kernels to adapt to varyinglocal features. Experimental results on benchmark datasets confirm theeffectiveness of our approach, achieving state-of-the-art performance in humanactivity recognition. Our source code is made publicly available at:https://github.com/Gbouna/MAK-GCN</description>
      <author>example@mail.com (Vincent Gbouna Zakka, Luis J. Manso, Zhuangzhuang Dai)</author>
      <guid isPermaLink="false">2504.02778v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Robust Unsupervised Domain Adaptation for 3D Point Cloud Segmentation Under Source Adversarial Attacks</title>
      <link>http://arxiv.org/abs/2504.01659v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种对抗鲁棒的领域自适应（UDA）框架，用于3D点云语义分割模型，并在合成污染数据集AdvSynLiDAR上进行了评估。&lt;h4&gt;背景&lt;/h4&gt;现有的无监督领域自适应（UDA）框架在干净数据上对3D点云语义分割模型具有良好的泛化能力，但忽视了当源域本身受损时的对抗鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;全面探索UDA框架的鲁棒性，并提出对抗鲁棒的解决方案。&lt;h4&gt;方法&lt;/h4&gt;设计了一种隐蔽的对抗点云生成攻击，可以仅通过轻微扰动点云表面来显著污染数据集。基于此，创建了包含合成污染LiDAR点云的新数据集AdvSynLiDAR。进一步开发对抗自适应框架（AAF）作为对策，通过扩展关键点敏感（KPS）损失到鲁棒长尾损失（RLT损失）并使用解码器分支，使模型在预训练阶段关注长尾类别，并在适应阶段利用高置信度解码的点云信息来恢复点云结构。&lt;h4&gt;主要发现&lt;/h4&gt;在AdvSynLiDAR数据集上评估的AAF方法可以减轻源域对抗扰动下的性能下降，适用于3D点云分割应用。&lt;h4&gt;结论&lt;/h4&gt;本文提出的对抗自适应框架（AAF）能够提高3D点云语义分割模型在源域受损情况下的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：无监督领域自适应（UDA）框架在干净数据上对3D点云语义分割模型展示了良好的泛化能力。然而，现有工作在源域本身受损时忽略了对抗鲁棒性。为了全面探索UDA框架的鲁棒性，我们首先设计了一种隐蔽的对抗点云生成攻击，该攻击可以通过对点云表面的微小扰动来显著污染数据集。基于此，我们提出了一个新的数据集AdvSynLiDAR，它包含合成的污染LiDAR点云。利用生成的污染数据，我们进一步开发了对抗自适应框架（AAF）作为对策。具体来说，通过将关键点敏感（KPS）损失扩展到鲁棒长尾损失（RLT损失）并利用解码器分支，我们的方法使模型能够在预训练阶段关注长尾类别，并在适应阶段利用高置信度解码的点云信息来恢复点云结构。我们在AdvSynLiDAR数据集上评估了我们的AAF方法，结果表明，我们的AAF方法可以减轻源域对抗扰动下的性能下降，适用于3D点云分割应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised domain adaptation (UDA) frameworks have shown goodgeneralization capabilities for 3D point cloud semantic segmentation models onclean data. However, existing works overlook adversarial robustness when thesource domain itself is compromised. To comprehensively explore the robustnessof the UDA frameworks, we first design a stealthy adversarial point cloudgeneration attack that can significantly contaminate datasets with only minorperturbations to the point cloud surface. Based on that, we propose a noveldataset, AdvSynLiDAR, comprising synthesized contaminated LiDAR point clouds.With the generated corrupted data, we further develop the AdversarialAdaptation Framework (AAF) as the countermeasure. Specifically, by extendingthe key point sensitive (KPS) loss towards the Robust Long-Tail loss (RLT loss)and utilizing a decoder branch, our approach enables the model to focus onlong-tail classes during the pre-training phase and leverages high-confidencedecoded point cloud information to restore point cloud structures during theadaptation phase. We evaluated our AAF method on the AdvSynLiDAR dataset, wherethe results demonstrate that our AAF method can mitigate performancedegradation under source adversarial perturbations for UDA in the 3D pointcloud segmentation application.</description>
      <author>example@mail.com (Haosheng Li, Junjie Chen, Yuecong Xu, Kemi Ding)</author>
      <guid isPermaLink="false">2504.01659v2</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>A Hybrid Similarity-Aware Graph Neural Network with Transformer for Node Classification</title>
      <link>http://arxiv.org/abs/2504.02615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为SIGNNet的新型节点分类框架，旨在解决图深度学习中节点分类的挑战，包括过压缩问题和可扩展性问题。&lt;h4&gt;背景&lt;/h4&gt;节点分类在图深度学习中非常重要，应用于推荐系统、药物发现和引文网络等领域。图卷积网络和图变换器在节点分类任务中表现出色，但存在过压缩和可扩展性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，以解决图卷积网络和图变换器的局限性，并提高节点分类的准确性。&lt;h4&gt;方法&lt;/h4&gt;SIGNNet结合了图卷积网络和基于分数的机制来捕获局部和全局节点交互，并采用基于Personalized PageRank的节点采样方法来解决可扩展性问题。它还引入了结构感知多头注意力机制（SA-MHA），以根据拓扑重要性优先考虑节点。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与现有最先进的方法相比，SIGNNet在多个数据集上实现了显著的性能提升，平均准确率提高了6.03%至19.61%。&lt;h4&gt;结论&lt;/h4&gt;SIGNNet是一种有效的节点分类方法，通过结合图卷积网络和图变换器的优点，同时解决它们的局限性，实现了更高的准确率和更好的可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.eswa.2025.127292&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Node classification has gained significant importance in graph deep learningwith real-world applications such as recommendation systems, drug discovery,and citation networks. Graph Convolutional Networks and Graph Transformers haveachieved superior performance in node classification tasks. However, the keyconcern with Graph Convolutional Networks is over-squashing, which limits theirability to capture long-range dependencies in the network. Additionally, GraphTransformers face scalability challenges, making it difficult to process largegraphs efficiently. To address this, we propose a novel framework, A HybridSImilarity-Aware Graph Neural Network with Transformer for Node Classification(SIGNNet), which capitalizes on local and global structural information,enhances the model's capability to effectively capture fine-grainedrelationships and broader contextual patterns within the graph structure. Theproposed method leverages Graph Convolutional Networks alongside a score-basedmechanism to effectively capture local and global node interactions whileaddressing the limitations of over-squashing. Our proposed method employs anovel Personalized PageRank-based node sampling method to address scalabilityissues by generating subgraphs of nodes. Additionally, SIGNNet incorporates anovel attention mechanism, Structure-Aware Multi-Head Attention (SA-MHA), whichintegrates node structural information for informed attention weighting,enabling the model to prioritize nodes based on topological significance.Extensive experiments demonstrate the significant improvements achieved by theproposed method over existing state-of-the-art methods, with average accuracygains of 6.03%, 5.47%, 4.78%, 19.10%, 19.61%, 7.22%, 19.54%, and 14.94% onCora, Citeseer, CS, Wisconsin, Texas, Actor, Cornell and Chameleon datasets,respectively.</description>
      <author>example@mail.com (Aman Singh, Shahid Shafi Dar, Ranveer Singh, Nagendra Kumar)</author>
      <guid isPermaLink="false">2504.02615v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>F-ViTA: Foundation Model Guided Visible to Thermal Translation</title>
      <link>http://arxiv.org/abs/2504.02801v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为F-ViTA的新方法，用于可见光到热成像的图像翻译，旨在解决收集大规模热数据集的成本和劳动密集性问题。&lt;h4&gt;背景&lt;/h4&gt;热成像在低光和夜间条件下对场景理解至关重要，但收集大规模热数据集需要昂贵的专业红外成像设备。&lt;h4&gt;目的&lt;/h4&gt;通过探索可见光到热图像的翻译，减少收集大规模热数据集的成本和劳动密集性。&lt;h4&gt;方法&lt;/h4&gt;F-ViTA利用基础模型中嵌入的通用世界知识来指导扩散过程，通过条件化InstructPix2Pix扩散模型，使用来自SAM和Grounded DINO等基础模型的零样本掩码和标签，使模型能够学习场景对象与其热特征之间的有意义相关性。&lt;h4&gt;主要发现&lt;/h4&gt;在五个公开数据集上的大量实验表明，F-ViTA优于最先进的方法，并且模型能够很好地泛化到分布外的场景，并能从同一可见图像生成长波红外(LWIR)、中波红外(MWIR)和近红外(NIR)翻译。&lt;h4&gt;结论&lt;/h4&gt;F-ViTA是一种有效的可见光到热图像翻译方法，能够显著降低数据收集成本并提高翻译质量。&lt;h4&gt;翻译&lt;/h4&gt;F-ViTA是一种新的可见光到热图像翻译方法，它利用基础模型中的通用知识来指导扩散过程，从而实现高效的图像翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Thermal imaging is crucial for scene understanding, particularly in low-lightand nighttime conditions. However, collecting large thermal datasets is costlyand labor-intensive due to the specialized equipment required for infraredimage capture. To address this challenge, researchers have exploredvisible-to-thermal image translation. Most existing methods rely on GenerativeAdversarial Networks (GANs) or Diffusion Models (DMs), treating the task as astyle transfer problem. As a result, these approaches attempt to learn both themodality distribution shift and underlying physical principles from limitedtraining data. In this paper, we propose F-ViTA, a novel approach thatleverages the general world knowledge embedded in foundation models to guidethe diffusion process for improved translation. Specifically, we condition anInstructPix2Pix Diffusion Model with zero-shot masks and labels from foundationmodels such as SAM and Grounded DINO. This allows the model to learn meaningfulcorrelations between scene objects and their thermal signatures in infraredimagery. Extensive experiments on five public datasets demonstrate that F-ViTAoutperforms state-of-the-art (SOTA) methods. Furthermore, our model generalizeswell to out-of-distribution (OOD) scenarios and can generate Long-Wave Infrared(LWIR), Mid-Wave Infrared (MWIR), and Near-Infrared (NIR) translations from thesame visible image. Code: https://github.com/JayParanjape/F-ViTA/tree/master.</description>
      <author>example@mail.com (Jay N. Paranjape, Celso de Melo, Vishal M. Patel)</author>
      <guid isPermaLink="false">2504.02801v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>CanonNet: Canonical Ordering and Curvature Learning for Point Cloud Analysis</title>
      <link>http://arxiv.org/abs/2504.02763v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CanonNet的轻量级神经网络，用于点云处理，旨在解决点云处理中的两个基本挑战：建立一致的点顺序和有效地学习细粒度的几何特征。&lt;h4&gt;背景&lt;/h4&gt;点云处理面临两个主要挑战：一是建立一致的点顺序，二是有效地学习细粒度的几何特征。现有的架构依赖于复杂的操作，这限制了其表达性，同时难以捕捉详细的表面几何形状。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的神经网络架构，以解决点云处理中的挑战，并提高几何特征的提取效率。&lt;h4&gt;方法&lt;/h4&gt;CanonNet由两个互补的组件组成：(1) 一个预处理管道，用于创建规范化的点顺序和方向；(2) 一个几何学习框架，网络从具有精确曲率值的合成表面中学习。这种模块化方法消除了对复杂不变架构的需求，同时有效地捕捉局部几何属性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CanonNet在曲率估计方面取得了最先进的性能，在几何描述符任务中与现有方法相比具有竞争力，同时参数数量显著减少（100倍）。CanonNet的效率使其特别适合计算资源有限的现实世界应用，证明了数学预处理可以有效地补充神经网络架构，用于点云分析。&lt;h4&gt;结论&lt;/h4&gt;CanonNet是一种有效的点云处理方法，能够以更少的参数实现更好的性能，特别适用于资源受限的应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：点云处理面临两个基本挑战：建立一致的点顺序和有效地学习细粒度的几何特征。当前架构依赖于复杂的操作，限制了其表达性，同时难以捕捉详细的表面几何形状。我们提出了CanonNet，一个由两个互补组件组成的轻量级神经网络：(1) 一个预处理管道，用于创建规范化的点顺序和方向；(2) 一个几何学习框架，网络从具有精确曲率值的合成表面中学习。这种模块化方法消除了对复杂不变架构的需求，同时有效地捕捉局部几何属性。我们的实验表明，在曲率估计方面取得了最先进的性能，在几何描述符任务中与现有方法相比具有竞争力，同时参数数量显著减少（100倍）。CanonNet的效率使其特别适合计算资源有限的现实世界应用，证明了数学预处理可以有效地补充神经网络架构，用于点云分析。该项目的代码是公开可用的[https://benjyfri.github.io/CanonNet/](https://benjyfri.github.io/CanonNet/)。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud processing poses two fundamental challenges: establishingconsistent point ordering and effectively learning fine-grained geometricfeatures. Current architectures rely on complex operations that limitexpressivity while struggling to capture detailed surface geometry. We presentCanonNet, a lightweight neural network composed of two complementarycomponents: (1) a preprocessing pipeline that creates a canonical pointordering and orientation, and (2) a geometric learning framework where networkslearn from synthetic surfaces with precise curvature values. This modularapproach eliminates the need for complex transformation-invariant architectureswhile effectively capturing local geometric properties. Our experimentsdemonstrate state-of-the-art performance in curvature estimation andcompetitive results in geometric descriptor tasks with significantly fewerparameters (\textbf{100X}) than comparable methods. CanonNet's efficiency makesit particularly suitable for real-world applications where computationalresources are limited, demonstrating that mathematical preprocessing caneffectively complement neural architectures for point cloud analysis. The codefor the project is publicly available\hyperlink{https://benjyfri.github.io/CanonNet/}{https://benjyfri.github.io/CanonNet/}.</description>
      <author>example@mail.com (Benjy Friedmann, Michael Werman)</author>
      <guid isPermaLink="false">2504.02763v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>L-LBVC: Long-Term Motion Estimation and Prediction for Learned Bi-Directional Video Compression</title>
      <link>http://arxiv.org/abs/2504.02560v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to 2025 Data Compression Conference (DCC)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的双向视频压缩框架L-LBVC，在低延迟配置下显著优于现有的学习方法。&lt;h4&gt;背景&lt;/h4&gt;尽管学习视频压缩（LVC）在低延迟配置下表现出色，但学习双向视频压缩（LBVC）的性能仍落后于传统双向编码。&lt;h4&gt;目的&lt;/h4&gt;解决长期运动估计和预测不准确的问题，尤其是在大运动场景中。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种自适应运动估计模块，可以处理短期和长期运动。2. 提出了一种自适应运动预测模块，可以大幅减少运动编码的比特成本。&lt;h4&gt;主要发现&lt;/h4&gt;L-LBVC在实验中显著优于之前的LVC方法，在某些测试数据集上甚至超过了VVC（VTM）。&lt;h4&gt;结论&lt;/h4&gt;L-LBVC框架在低延迟配置下实现了良好的性能，对于视频压缩领域具有潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;最近，学习视频压缩（LVC）在低延迟配置下表现出卓越的性能。然而，学习双向视频压缩（LBVC）的性能仍然落后于传统的双向编码。性能差距主要源于对远距离帧的长期运动估计和预测不准确，尤其是在大运动场景中。为了解决这两个关键问题，本文提出了一种新颖的LBVC框架，即L-LBVC。首先，我们提出了一种自适应运动估计模块，可以处理短期和长期运动。具体来说，我们直接估计相邻帧和非相邻帧的光流，对于具有小运动的非相邻帧。对于具有大运动的非相邻帧，我们通过递归累积相邻帧之间的局部流来估计长期流。其次，我们提出了一种自适应运动预测模块，可以大幅减少运动编码的比特成本。为了提高长期运动预测的准确性，我们在测试期间自适应地下采样参考帧，以匹配训练期间观察到的运动范围。实验表明，我们的L-LBVC在性能上显著优于之前的LVC方法，在某些测试数据集上甚至在随机访问配置下超过了VVC（VTM）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, learned video compression (LVC) has shown superior performanceunder low-delay configuration. However, the performance of learnedbi-directional video compression (LBVC) still lags behind traditionalbi-directional coding. The performance gap mainly arises from inaccuratelong-term motion estimation and prediction of distant frames, especially inlarge motion scenes. To solve these two critical problems, this paper proposesa novel LBVC framework, namely L-LBVC. Firstly, we propose an adaptive motionestimation module that can handle both short-term and long-term motions.Specifically, we directly estimate the optical flows for adjacent frames andnon-adjacent frames with small motions. For non-adjacent frames with largemotions, we recursively accumulate local flows between adjacent frames toestimate long-term flows. Secondly, we propose an adaptive motion predictionmodule that can largely reduce the bit cost for motion coding. To improve theaccuracy of long-term motion prediction, we adaptively downsample referenceframes during testing to match the motion ranges observed during training.Experiments show that our L-LBVC significantly outperforms previousstate-of-the-art LVC methods and even surpasses VVC (VTM) on some test datasetsunder random access configuration.</description>
      <author>example@mail.com (Yongqi Zhai, Luyang Tang, Wei Jiang, Jiayu Yang, Ronggang Wang)</author>
      <guid isPermaLink="false">2504.02560v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Systematic Evaluation of Large Vision-Language Models for Surgical Artificial Intelligence</title>
      <link>http://arxiv.org/abs/2504.02799v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了大型视觉语言模型在手术人工智能领域的应用，分析了11种最先进的VLM在17个关键视觉理解任务上的表现，并探讨了VLM在实际应用中的潜力和挑战。&lt;h4&gt;背景&lt;/h4&gt;VLM在图像理解领域具有新范式，能在未进行特定任务训练的情况下执行任务，这在医学领域尤其有前景，因为专家标注的数据稀缺。&lt;h4&gt;目的&lt;/h4&gt;分析VLM在手术AI中的实际应用，评估其泛化能力和适应性。&lt;h4&gt;方法&lt;/h4&gt;使用13个数据集，涵盖了腹腔镜、机器人手术和开放式手术，对11种VLM在17个关键视觉理解任务上的表现进行了全面分析。&lt;h4&gt;主要发现&lt;/h4&gt;VLM显示出良好的泛化能力，有时在测试时优于监督模型，并且通过上下文学习（在测试中结合例子）性能提高了三倍，显示出适应性的关键优势。但需要空间或时间推理的任务仍然具有挑战性。&lt;h4&gt;结论&lt;/h4&gt;VLM在手术以外的领域，如处理临床和更广泛的真实世界中的复杂和动态场景，具有潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Vision-Language Models offer a new paradigm for AI-driven imageunderstanding, enabling models to perform tasks without task-specific training.This flexibility holds particular promise across medicine, whereexpert-annotated data is scarce. Yet, VLMs' practical utility inintervention-focused domains--especially surgery, where decision-making issubjective and clinical scenarios are variable--remains uncertain. Here, wepresent a comprehensive analysis of 11 state-of-the-art VLMs across 17 keyvisual understanding tasks in surgical AI--from anatomy recognition to skillassessment--using 13 datasets spanning laparoscopic, robotic, and openprocedures. In our experiments, VLMs demonstrate promising generalizability, attimes outperforming supervised models when deployed outside their trainingsetting. In-context learning, incorporating examples during testing, boostedperformance up to three-fold, suggesting adaptability as a key strength. Still,tasks requiring spatial or temporal reasoning remained difficult. Beyondsurgery, our findings offer insights into VLMs' potential for tackling complexand dynamic scenarios in clinical and broader real-world applications.</description>
      <author>example@mail.com (Anita Rau, Mark Endo, Josiah Aklilu, Jaewoo Heo, Khaled Saab, Alberto Paderno, Jeffrey Jopling, F. Christopher Holsinger, Serena Yeung-Levy)</author>
      <guid isPermaLink="false">2504.02799v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>SCMPPI: Supervised Contrastive Multimodal Framework for Predicting Protein-Protein Interactions</title>
      <link>http://arxiv.org/abs/2504.02698v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages,11 figures,conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个名为SCMPPI的新监督对比多模态框架，用于蛋白质-蛋白质相互作用（PPI）预测，该框架在准确性、AUC等关键指标上优于现有方法，并在跨物种预测中表现出强大的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;蛋白质-蛋白质相互作用（PPI）预测对于揭示细胞功能网络和疾病机制至关重要，但传统的实验方法耗时且成本高，现有的计算模型在跨模态特征融合、鲁棒性和假阴性抑制方面面临挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的监督对比多模态框架，以增强PPI预测的性能。&lt;h4&gt;方法&lt;/h4&gt;SCMPPI通过整合蛋白质序列特征（如AAC、DPC、CKSAAP-ESMC）和PPI网络拓扑信息（如Node2Vec图嵌入），并结合改进的监督对比学习策略。此外，SCMPPI引入了负样本过滤机制并修改了对比损失函数，以优化多模态特征。&lt;h4&gt;主要发现&lt;/h4&gt;在八个基准数据集（包括酵母、人类和H.pylori）上的实验表明，SCMPPI在准确性和AUC等关键指标上优于现有方法，如DF-PPI和TAGPPI，并在跨物种预测中表现出强泛化能力。&lt;h4&gt;结论&lt;/h4&gt;SCMPPI成功应用于CD9网络、Wnt途径和癌症特异性网络，为疾病靶点发现提供了一种可靠的工具。此外，该框架为多模态生物信息融合和对比学习中的协作优化提供了新的范例。&lt;h4&gt;翻译&lt;/h4&gt;摘要：蛋白质-蛋白质相互作用（PPI）预测是揭示细胞功能网络和疾病机制的关键任务。然而，传统的实验方法耗时且成本高昂，现有的计算模型在跨模态特征融合、鲁棒性和假阴性抑制方面面临挑战。在本文中，我们提出了一种新的监督对比多模态框架，称为SCMPPI，用于PPI预测。通过整合蛋白质序列特征（如AAC、DPC、CKSAAP-ESMC）与PPI网络拓扑信息（如Node2Vec图嵌入），并结合改进的监督对比学习策略，SCMPPI显著提高了PPI预测性能。对于PPI任务，SCMPPI引入了负样本过滤机制并修改了对比损失函数，有效地优化了多模态特征。在包括酵母、人类和H.pylori在内的八个基准数据集上的实验表明，SCMPPI在准确性和AUC等关键指标上优于现有方法（如DF-PPI和TAGPPI），并在跨物种预测中显示出强大的泛化能力（在多物种数据集上AUC&gt;99%）。此外，SCMPPI已成功应用于CD9网络、Wnt途径和癌症特异性网络，为疾病靶点发现提供了一种可靠的工具。该框架还为多模态生物信息融合和对比学习中的协作优化提供了一种新的范例。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Protein-Protein Interaction (PPI) prediction is a key task in uncoveringcellular functional networks and disease mechanisms. However, traditionalexperimental methods are time-consuming and costly, and existing computationalmodels face challenges in cross-modal feature fusion, robustness, andfalse-negative suppression. In this paper, we propose a novel supervisedcontrastive multimodal framework, SCMPPI, for PPI prediction. By integratingprotein sequence features (AAC, DPC, CKSAAP-ESMC) with PPI network topologyinformation (Node2Vec graph embedding), and combining an improved supervisedcontrastive learning strategy, SCMPPI significantly enhances PPI predictionperformance. For the PPI task, SCMPPI introduces a negative sample filteringmechanism and modifies the contrastive loss function, effectively optimizingmultimodal features. Experiments on eight benchmark datasets, including yeast,human, and H.pylori, show that SCMPPI outperforms existing state-of-the-artmethods (such as DF-PPI and TAGPPI) in key metrics such as accuracy ( 98.01%)and AUC (99.62%), and demonstrates strong generalization in cross-speciesprediction (AUC &gt; 99% on multi-species datasets). Furthermore, SCMPPI has beensuccessfully applied to CD9 networks, the Wnt pathway, and cancer-specificnetworks, providing a reliable tool for disease target discovery. Thisframework also offers a new paradigm for multimodal biological informationfusion and contrastive learning in collaborative optimization for variouscombined predictions.</description>
      <author>example@mail.com (Shengrui XU, Tianchi Lu, Zikun Wang, Jixiu Zhai, Jingwan Wang)</author>
      <guid isPermaLink="false">2504.02698v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Learning Audio-guided Video Representation with Gated Attention for Video-Text Retrieval</title>
      <link>http://arxiv.org/abs/2504.02397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AVIGATE的新型视频-文本检索框架，该框架通过门控注意力机制有效地利用音频线索，并通过自适应边缘对比损失处理视频与文本之间的正负关系，从而在公共基准测试中实现最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;视频-文本检索对于视频理解和多模态信息检索至关重要，现有方法主要依赖视觉和文本特征，常忽略音频信息，且传统模型在利用音频时往往不考虑其有用性，导致视频表示不优。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的视频-文本检索框架，以解决现有方法中音频信息利用不足和视频表示不优的问题。&lt;h4&gt;方法&lt;/h4&gt;AVIGATE框架通过门控注意力机制选择性地过滤掉无信息的音频信号，并提出自适应边缘对比损失来处理视频与文本之间的正负关系。&lt;h4&gt;主要发现&lt;/h4&gt;AVIGATE在所有公共基准测试中实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;AVIGATE框架通过有效利用音频线索和自适应对比损失，显著提升了视频-文本检索的性能。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is summarized as follows: 'This paper proposes a novel video-text retrieval framework named AVIGATE, which effectively utilizes audio cues through a gated attention mechanism and proposes an adaptive margin-based contrastive loss to handle the inherently unclear positive-negative relationship between video and text, achieving state-of-the-art performance on all public benchmarks.'&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video-text retrieval, the task of retrieving videos based on a textual queryor vice versa, is of paramount importance for video understanding andmultimodal information retrieval. Recent methods in this area rely primarily onvisual and textual features and often ignore audio, although it helps enhanceoverall comprehension of video content. Moreover, traditional models thatincorporate audio blindly utilize the audio input regardless of whether it isuseful or not, resulting in suboptimal video representation. To address theselimitations, we propose a novel video-text retrieval framework, Audio-guidedVIdeo representation learning with GATEd attention (AVIGATE), that effectivelyleverages audio cues through a gated attention mechanism that selectivelyfilters out uninformative audio signals. In addition, we propose an adaptivemargin-based contrastive loss to deal with the inherently unclearpositive-negative relationship between video and text, which facilitateslearning better video-text alignment. Our extensive experiments demonstratethat AVIGATE achieves state-of-the-art performance on all the publicbenchmarks.</description>
      <author>example@mail.com (Boseung Jeong, Jicheol Park, Sungyeon Kim, Suha Kwak)</author>
      <guid isPermaLink="false">2504.02397v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision</title>
      <link>http://arxiv.org/abs/2504.02477v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 11 figures, survey paper submitted to Information Fusion&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文系统地回顾了多模态融合技术在机器人视觉关键任务中的应用，包括语义场景理解、同时定位与建图（SLAM）、3D物体检测、导航与定位以及机器人操作。比较了基于大型语言模型（LLMs）的视觉语言模型（VLMs）与传统多模态融合方法，分析了它们的优缺点和协同作用。此外，对常用数据集进行了深入分析，评估了其在现实世界机器人场景中的适用性和挑战。还确定了关键研究挑战，如跨模态对齐、高效融合策略、实时部署和领域适应性，并提出了未来的研究方向。&lt;h4&gt;背景&lt;/h4&gt;机器人视觉从多模态融合技术和视觉语言模型（VLMs）的进步中受益匪浅。&lt;h4&gt;目的&lt;/h4&gt;提供多模态感知和交互在机器人视觉中进步的有价值参考。&lt;h4&gt;方法&lt;/h4&gt;进行了系统回顾、比较分析和前瞻性讨论。&lt;h4&gt;主要发现&lt;/h4&gt;分析了多模态融合在机器人视觉任务中的应用，比较了VLMs与传统的多模态融合方法，并深入分析了常用数据集。&lt;h4&gt;结论&lt;/h4&gt;确定了关键研究挑战，并提出了未来的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;本文系统地回顾了多模态融合技术在机器人视觉关键任务中的应用，包括语义场景理解、同时定位与建图（SLAM）、3D物体检测、导航与定位以及机器人操作。我们比较了基于大型语言模型（LLMs）的视觉语言模型（VLMs）与传统多模态融合方法，分析了它们的优点、局限性和协同作用。此外，我们对常用数据集进行了深入分析，评估了它们在现实世界机器人场景中的适用性和挑战。进一步地，我们确定了关键研究挑战，如跨模态对齐、高效融合策略、实时部署和领域适应性，并提出了未来的研究方向，包括用于鲁棒多模态表示的自监督学习、基于transformer的融合架构和可扩展的多模态框架。通过全面的回顾、比较分析和前瞻性讨论，我们为推进机器人视觉中的多模态感知和交互提供了有价值的参考。本调查中涉及的研究的完整列表可在https://github.com/Xiaofeng-Han-Res/MF-RV找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robot vision has greatly benefited from advancements in multimodal fusiontechniques and vision-language models (VLMs). We systematically review theapplications of multimodal fusion in key robotic vision tasks, includingsemantic scene understanding, simultaneous localization and mapping (SLAM), 3Dobject detection, navigation and localization, and robot manipulation. Wecompare VLMs based on large language models (LLMs) with traditional multimodalfusion methods, analyzing their advantages, limitations, and synergies.Additionally, we conduct an in-depth analysis of commonly used datasets,evaluating their applicability and challenges in real-world robotic scenarios.Furthermore, we identify critical research challenges such as cross-modalalignment, efficient fusion strategies, real-time deployment, and domainadaptation, and propose future research directions, including self-supervisedlearning for robust multimodal representations, transformer-based fusionarchitectures, and scalable multimodal frameworks. Through a comprehensivereview, comparative analysis, and forward-looking discussion, we provide avaluable reference for advancing multimodal perception and interaction inrobotic vision. A comprehensive list of studies in this survey is available athttps://github.com/Xiaofeng-Han-Res/MF-RV.</description>
      <author>example@mail.com (Xiaofeng Han, Shunpeng Chen, Zenghuang Fu, Zhe Feng, Lue Fan, Dong An, Changwei Wang, Li Guo, Weiliang Meng, Xiaopeng Zhang, Rongtao Xu, Shibiao Xu)</author>
      <guid isPermaLink="false">2504.02477v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Graph Attention-Driven Bayesian Deep Unrolling for Dual-Peak Single-Photon Lidar Imaging</title>
      <link>http://arxiv.org/abs/2504.02480v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于双峰单光子Lidar成像的深度展开算法，以应对噪声环境和每个像素中多个目标的问题。&lt;h4&gt;背景&lt;/h4&gt;单光子Lidar成像在3D成像方面具有高分辨率和长距离的能力，但在噪声环境和每个像素有多个目标的情况下应用困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够处理复杂场景的深度展开算法，以改善单光子Lidar成像在噪声环境中的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了分层贝叶斯模型来处理多个目标，并使用神经网络展开底层统计方法。采用双重深度图表示，并利用几何深度学习从点云中提取特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法结合了统计方法和基于学习的方法，在准确性和不确定性量化方面具有优势，实验结果表明其性能优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;该算法在合成和真实数据上的实验结果证明了其在准确性方面的竞争力，并提供了不确定性信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single-photon Lidar imaging offers a significant advantage in 3D imaging dueto its high resolution and long-range capabilities, however it is challengingto apply in noisy environments with multiple targets per pixel. To tackle thesechallenges, several methods have been proposed. Statistical methods demonstrateinterpretability on the inferred parameters, but they are often limited intheir ability to handle complex scenes. Deep learning-based methods have shownsuperior performance in terms of accuracy and robustness, but they lackinterpretability or they are limited to a single-peak per pixel. In this paper,we propose a deep unrolling algorithm for dual-peak single-photon Lidarimaging. We introduce a hierarchical Bayesian model for multiple targets andpropose a neural network that unrolls the underlying statistical method. Tosupport multiple targets, we adopt a dual depth maps representation and exploitgeometric deep learning to extract features from the point cloud. The proposedmethod takes advantages of statistical methods and learning-based methods interms of accuracy and quantifying uncertainty. The experimental results onsynthetic and real data demonstrate the competitive performance when comparedto existing methods, while also providing uncertainty information.</description>
      <author>example@mail.com (Kyungmin Choi, JaKeoung Koo, Stephen McLaughlin, Abderrahim Halimi)</author>
      <guid isPermaLink="false">2504.02480v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Toward General and Robust LLM-enhanced Text-attributed Graph Learning</title>
      <link>http://arxiv.org/abs/2504.02343v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为UltraTAG的统一框架，用于LLM增强的TAG学习，旨在解决现有方法缺乏统一框架和应对现实世界TAG数据稀疏性问题。&lt;h4&gt;背景&lt;/h4&gt;LLMs和TAGs的广泛应用推动了LLM增强的TAG学习成为关键研究领域，但现有方法面临统一框架缺失和数据稀疏性挑战。&lt;h4&gt;目的&lt;/h4&gt;提出UltraTAG和UltraTAG-S以解决LLM与GNN复杂交互中的优化视角多样性和现实世界TAG数据稀疏性问题。&lt;h4&gt;方法&lt;/h4&gt;UltraTAG提供了一种统一、全面和领域自适应的框架，UltraTAG-S则通过LLM文本传播和文本增强来减轻文本稀疏性，并利用LLM增强的节点选择技术和边缘重构策略来处理边缘稀疏性。&lt;h4&gt;主要发现&lt;/h4&gt;UltraTAG-S在理想和稀疏设置中分别提高了2.12%和17.47%，且随着数据稀疏比率的增加，性能提升也相应增加。&lt;h4&gt;结论&lt;/h4&gt;UltraTAG-S在LLM增强的TAG学习中表现优异，有效应对了数据稀疏性问题，为该领域的研究提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Recent advancements in Large Language Models (LLMs) and the proliferation of Text-Attributed Graphs (TAGs) across various domains have positioned LLM-enhanced TAG learning as a critical research area. By utilizing rich graph descriptions, this paradigm leverages LLMs to generate high-quality embeddings, thereby enhancing the representational capacity of Graph Neural Networks (GNNs). However, the field faces significant challenges: (1) the absence of a unified framework to systematize the diverse optimization perspectives arising from the complex interactions between LLMs and GNNs, and (2) the lack of a robust method capable of handling real-world TAGs, which often suffer from texts and edge sparsity, leading to suboptimal performance. To address these challenges, we propose UltraTAG, a unified pipeline for LLM-enhanced TAG learning. UltraTAG provides a unified comprehensive and domain-adaptive framework that not only organizes existing methodologies but also paves the way for future advancements in the field. Building on this framework, we propose UltraTAG-S, a robust instantiation of UltraTAG designed to tackle the inherent sparsity issues in real-world TAGs. UltraTAG-S employs LLM-based text propagation and text augmentation to mitigate text sparsity, while leveraging LLM-augmented node selection techniques based on PageRank and edge reconfiguration strategies to address edge sparsity. Our extensive experiments demonstrate that UltraTAG-S significantly outperforms existing baselines, achieving improvements of 2.12% and 17.47% in ideal and sparse settings, respectively. Moreover, as the data sparsity ratio increases, the performance improvement of UltraTAG-S also rises, which underscores the effectiveness and robustness of UltraTAG-S.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Large Language Models (LLMs) and the proliferation ofText-Attributed Graphs (TAGs) across various domains have positionedLLM-enhanced TAG learning as a critical research area. By utilizing rich graphdescriptions, this paradigm leverages LLMs to generate high-quality embeddings,thereby enhancing the representational capacity of Graph Neural Networks(GNNs). However, the field faces significant challenges: (1) the absence of aunified framework to systematize the diverse optimization perspectives arisingfrom the complex interactions between LLMs and GNNs, and (2) the lack of arobust method capable of handling real-world TAGs, which often suffer fromtexts and edge sparsity, leading to suboptimal performance.  To address these challenges, we propose UltraTAG, a unified pipeline forLLM-enhanced TAG learning. UltraTAG provides a unified comprehensive anddomain-adaptive framework that not only organizes existing methodologies butalso paves the way for future advancements in the field. Building on thisframework, we propose UltraTAG-S, a robust instantiation of UltraTAG designedto tackle the inherent sparsity issues in real-world TAGs. UltraTAG-S employsLLM-based text propagation and text augmentation to mitigate text sparsity,while leveraging LLM-augmented node selection techniques based on PageRank andedge reconfiguration strategies to address edge sparsity. Our extensiveexperiments demonstrate that UltraTAG-S significantly outperforms existingbaselines, achieving improvements of 2.12\% and 17.47\% in ideal and sparsesettings, respectively. Moreover, as the data sparsity ratio increases, theperformance improvement of UltraTAG-S also rises, which underscores theeffectiveness and robustness of UltraTAG-S.</description>
      <author>example@mail.com (Zihao Zhang, Xunkai Li, Rong-Hua Li, Bing Zhou, Zhenjun Li, Guoren Wang)</author>
      <guid isPermaLink="false">2504.02343v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Learning dynamics on the picosecond timescale in a superconducting synapse structure</title>
      <link>http://arxiv.org/abs/2504.02754v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了一种基于超导电子学的学习突触实现，通过实验测量其突触动力学，展示了超导电感可以动态地保持突触权重，并实现快速且节能的学习。&lt;h4&gt;背景&lt;/h4&gt;传统人工智能系统在训练时间和能耗方面存在限制，而基于人类大脑原理的脉冲神经网络通过无监督学习提供了一种更快、更节能的替代方案。&lt;h4&gt;目的&lt;/h4&gt;研究超导电子学实现的学习突触，并通过实验测量其突触动力学。&lt;h4&gt;方法&lt;/h4&gt;通过使用超导神经元脉冲系统，实验测量了超导电感在学习和遗忘过程中的动态变化，并进行了电路模拟验证。&lt;h4&gt;主要发现&lt;/h4&gt;超导电感可以动态地保持突触权重，学习可以通过减缓突触后脉冲的到达时间来停止，学习时间约为16.1 +/- 1 ps，学习部分的功耗小于每学习事件一个attojoule。&lt;h4&gt;结论&lt;/h4&gt;这种超导电子学实现的学习突触有望实现极快和节能的学习处理器。&lt;h4&gt;翻译&lt;/h4&gt;Conventional Artificial Intelligence (AI) systems are running intolimitations in terms of training time and energy. Following the principles ofthe human brain, spiking neural networks trained with unsupervised learningoffer a faster, more energy-efficient alternative. However, the dynamics ofspiking, learning, and forgetting become more complicated in such schemes. Herewe study a superconducting electronics implementation of a learning synapse andexperimentally measure its spiking dynamics. By pulsing the system with asuperconducting neuron, we show that a superconducting inductor can dynamicallyhold the synaptic weight with updates due to learning and forgetting. Learningcan be stopped by slowing down the arrival time of the post-synaptic pulse, inaccordance with the Spike-Timing Dependent Plasticity paradigm. We findexcellent agreement with circuit simulations, and by fitting the turn-on of thepulsing frequency, we confirm a learning time of 16.1 +/- 1 ps. The powerdissipation in the learning part of the synapse is less than one attojoule perlearning event. This leads to the possibility of an extremely fast andenergy-efficient learning processor.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conventional Artificial Intelligence (AI) systems are running intolimitations in terms of training time and energy. Following the principles ofthe human brain, spiking neural networks trained with unsupervised learningoffer a faster, more energy-efficient alternative. However, the dynamics ofspiking, learning, and forgetting become more complicated in such schemes. Herewe study a superconducting electronics implementation of a learning synapse andexperimentally measure its spiking dynamics. By pulsing the system with asuperconducting neuron, we show that a superconducting inductor can dynamicallyhold the synaptic weight with updates due to learning and forgetting. Learningcan be stopped by slowing down the arrival time of the post-synaptic pulse, inaccordance with the Spike-Timing Dependent Plasticity paradigm. We findexcellent agreement with circuit simulations, and by fitting the turn-on of thepulsing frequency, we confirm a learning time of 16.1 +/- 1 ps. The powerdissipation in the learning part of the synapse is less than one attojoule perlearning event. This leads to the possibility of an extremely fast andenergy-efficient learning processor.</description>
      <author>example@mail.com (Ken Segall, Leon Nichols, Will Friend, Steven B. Kaplan)</author>
      <guid isPermaLink="false">2504.02754v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>A Framework for Situating Innovations, Opportunities, and Challenges in Advancing Vertical Systems with Large AI Models</title>
      <link>http://arxiv.org/abs/2504.02793v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  pre-print; 7 pages of main content, 1 figure, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文讨论了大型人工智能模型在标准化基准测试中表现出色，但在实际应用中如医疗、教育和法律等领域存在显著局限性，如数据变化敏感、决策缺乏上下文信息、降低用户信任等。为解决这些问题，论文提出了一种框架，通过分层抽象创新来满足用户对大型模型的需求。&lt;h4&gt;背景&lt;/h4&gt;大型人工智能模型在标准化基准测试中表现出色，但在实际应用中存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架，通过分层抽象创新来满足用户对大型模型的需求。&lt;h4&gt;方法&lt;/h4&gt;通过多个案例研究，展示如何将框架应用于不同领域，并强调框架不同层的动态性。&lt;h4&gt;主要发现&lt;/h4&gt;模型在处理实际应用时存在数据变化敏感、决策缺乏上下文信息、降低用户信任等问题。&lt;h4&gt;结论&lt;/h4&gt;框架可以帮助研究人员和实践者优化创新位置、发现被忽视的机会、促进跨学科沟通。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大型人工智能（AI）模型因其对标准化基准的显著性能而受到广泛关注，这些性能常常被认为是“超人类”的。然而，当这些模型在医疗、教育和法律等高风险领域应用时，它们往往显示出明显的局限性。例如，它们对输入数据的微小变化表现出脆弱性，在关键环境中做出缺乏上下文信息的决策，并通过自信地产生或复制不准确的信息来破坏用户信任。应用大型模型所面临的这些挑战需要跨学科的创新，以使模型的能力与实际应用的需求相一致。我们介绍了一个框架，通过分层抽象创新来弥合这一差距，旨在满足用户对大型模型的需求。通过多个案例研究，我们说明了来自不同领域的学者和实践者如何实施这一框架。除了模块化将大型模型转化为有用的“垂直系统”的流程之外，我们还强调了框架不同层之间的动态性。最后，我们讨论了我们的框架如何指导研究人员和实践者：（一）优化他们的创新位置（例如，当垂直特定洞察力可以推动广泛影响的垂直无关创新时）；（二）发现被忽视的机会（例如，发现跨领域的重复性问题以开发实用的基础模型，而不是追逐基准）；（三）促进关键挑战的跨学科沟通（例如，为AI开发者、领域专家和人与计算机交互学者提供一个共享的词汇表）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large artificial intelligence (AI) models have garnered significant attentionfor their remarkable, often "superhuman", performance on standardizedbenchmarks. However, when these models are deployed in high-stakes verticalssuch as healthcare, education, and law, they often reveal notable limitations.For instance, they exhibit brittleness to minor variations in input data,present contextually uninformed decisions in critical settings, and undermineuser trust by confidently producing or reproducing inaccuracies. Thesechallenges in applying large models necessitate cross-disciplinary innovationsto align the models' capabilities with the needs of real-world applications. Weintroduce a framework that addresses this gap through a layer-wise abstractionof innovations aimed at meeting users' requirements with large models. Throughmultiple case studies, we illustrate how researchers and practitioners acrossvarious fields can operationalize this framework. Beyond modularizing thepipeline of transforming large models into useful "vertical systems", we alsohighlight the dynamism that exists within different layers of the framework.Finally, we discuss how our framework can guide researchers and practitionersto (i) optimally situate their innovations (e.g., when vertical-specificinsights can empower broadly impactful vertical-agnostic innovations), (ii)uncover overlooked opportunities (e.g., spotting recurring problems acrossverticals to develop practically useful foundation models instead of chasingbenchmarks), and (iii) facilitate cross-disciplinary communication of criticalchallenges (e.g., enabling a shared vocabulary for AI developers, domainexperts, and human-computer interaction scholars).</description>
      <author>example@mail.com (Gaurav Verma, Jiawei Zhou, Mohit Chandra, Srijan Kumar, Munmun De Choudhury)</author>
      <guid isPermaLink="false">2504.02793v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation</title>
      <link>http://arxiv.org/abs/2504.02438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ViLaMP，一个能够处理时长为一小时的视频的层级视频语言模型，通过差分蒸馏和混合精度机制，在保持计算效率的同时，实现高性能的视频理解。&lt;h4&gt;背景&lt;/h4&gt;长视频处理对视觉语言模型（VLMs）提出了挑战，因为处理长时间序列的计算成本很高，现有的剪枝和特征合并方法往往牺牲了关键的时序依赖或稀释了语义信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种原则性的方法，系统地保留任务相关的信息同时抑制冗余，以开发一个高效的视频语言模型。&lt;h4&gt;方法&lt;/h4&gt;ViLaMP采用差分蒸馏原理，通过两个关键机制处理视频：(1) 差分关键帧选择，在帧级别上保持时间上的独特性同时最大化查询相关性；(2) 差分特征合并，在补丁级别上保留非关键帧中的显著特征。&lt;h4&gt;主要发现&lt;/h4&gt;ViLaMP在四个视频理解基准测试中展现了优越的性能，特别是对长视频内容。ViLaMP能够在单个NVIDIA A100 GPU上处理超长视频（高达10K帧），在保持最先进性能的同时实现显著的计算效率。&lt;h4&gt;结论&lt;/h4&gt;ViLaMP通过差分蒸馏和混合精度机制，有效解决了长视频处理中的计算成本问题，并在保持高性能的同时，实现了高效的视频理解处理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-form video processing fundamentally challenges vision-language models(VLMs) due to the high computational costs of handling extended temporalsequences. Existing token pruning and feature merging methods often sacrificecritical temporal dependencies or dilute semantic information. We introducedifferential distillation, a principled approach that systematically preservestask-relevant information while suppressing redundancy. Based on thisprinciple, we develop ViLaMP, a hierarchical video-language model thatprocesses hour-long videos at ``mixed precision'' through two key mechanisms:(1) differential keyframe selection that maximizes query relevance whilemaintaining temporal distinctiveness at the frame level and (2) differentialfeature merging that preserves query-salient features in non-keyframes at thepatch level. Hence, ViLaMP retains full information in keyframes while reducingnon-keyframes to their most salient features, resembling mixed-precisiontraining. Extensive experiments demonstrate ViLaMP's superior performanceacross four video understanding benchmarks, particularly on long-form content.Notably, ViLaMP can process ultra-long videos (up to 10K frames) on a singleNVIDIA A100 GPU, achieving substantial computational efficiency whilemaintaining state-of-the-art performance.</description>
      <author>example@mail.com (Chuanqi Cheng, Jian Guan, Wei Wu, Rui Yan)</author>
      <guid isPermaLink="false">2504.02438v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets</title>
      <link>http://arxiv.org/abs/2504.02792v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为统一世界模型（UWM）的框架，用于利用视频和动作数据来学习策略，并通过模拟和真实世界的实验证明了其在多任务机器人数据集上的有效性和优越性。&lt;h4&gt;背景&lt;/h4&gt;模仿学习是一种很有前景的方法，但将其应用于大型机器人基础模型面临挑战，因为其依赖于高质量的专家演示。同时，大量的视频数据描述了广泛的环境和多样的行为，但这些数据缺乏动作标注，难以直接用于模仿学习。&lt;h4&gt;目的&lt;/h4&gt;提出UWM框架，以利用视频和动作数据，克服现有方法中动作标注的难题，实现更通用的机器人学习。&lt;h4&gt;方法&lt;/h4&gt;UWM框架通过统一变换器架构整合动作扩散过程和视频扩散过程，独立控制每个模态的扩散时间步，从而灵活地表示策略、前向动力学、逆动力学和视频生成器。&lt;h4&gt;主要发现&lt;/h4&gt;1. UWM在具有动力学和动作预测的大规模多任务机器人数据集上进行有效预训练，比模仿学习产生更通用和鲁棒的政策；2. UWM通过独立控制模态特定的扩散时间步，自然地促进了从无动作视频数据的学习，进一步提高了微调策略的性能。&lt;h4&gt;结论&lt;/h4&gt;UWM为利用大型、异构数据集进行可扩展的机器人学习提供了有希望的步骤，并为模仿学习和世界建模等不同范式之间提供了一个简单的统一。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为统一世界模型（UWM）的框架，用于利用视频和动作数据来学习策略，并通过模拟和真实世界的实验证明了其在多任务机器人数据集上的有效性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Imitation learning has emerged as a promising approach towards buildinggeneralist robots. However, scaling imitation learning for large robotfoundation models remains challenging due to its reliance on high-qualityexpert demonstrations. Meanwhile, large amounts of video data depicting a widerange of environments and diverse behaviors are readily available. This dataprovides a rich source of information about real-world dynamics andagent-environment interactions. Leveraging this data directly for imitationlearning, however, has proven difficult due to the lack of action annotationrequired for most contemporary methods. In this work, we present Unified WorldModels (UWM), a framework that allows for leveraging both video and action datafor policy learning. Specifically, a UWM integrates an action diffusion processand a video diffusion process within a unified transformer architecture, whereindependent diffusion timesteps govern each modality. We show that by simplycontrolling each diffusion timestep, UWM can flexibly represent a policy, aforward dynamics, an inverse dynamics, and a video generator. Through simulatedand real-world experiments, we show that: (1) UWM enables effective pretrainingon large-scale multitask robot datasets with both dynamics and actionpredictions, resulting in more generalizable and robust policies than imitationlearning, (2) UWM naturally facilitates learning from action-free video datathrough independent control of modality-specific diffusion timesteps, furtherimproving the performance of finetuned policies. Our results suggest that UWMoffers a promising step toward harnessing large, heterogeneous datasets forscalable robot learning, and provides a simple unification between the oftendisparate paradigms of imitation learning and world modeling. Videos and codeare available at https://weirdlabuw.github.io/uwm/.</description>
      <author>example@mail.com (Chuning Zhu, Raymond Yu, Siyuan Feng, Benjamin Burchfiel, Paarth Shah, Abhishek Gupta)</author>
      <guid isPermaLink="false">2504.02792v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>EvMic: Event-based Non-contact sound recovery from effective spatial-temporal modeling</title>
      <link>http://arxiv.org/abs/2504.02402v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Our project page: https://yyzq1.github.io/EvMic/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的非接触式声音恢复方法，通过利用事件流中的时空信息来提高信号质量。&lt;h4&gt;背景&lt;/h4&gt;早期研究在采样率、带宽、视场和光学路径的简单性等方面遇到了权衡。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效恢复声音的方法，同时提高信号质量。&lt;h4&gt;方法&lt;/h4&gt;使用新型模拟流程生成大量训练集，设计网络利用事件稀疏性捕获空间信息，使用Mamba模型长期时间信息，并训练空间聚合块以聚合不同位置的信息。此外，还设计了一个使用激光矩阵的成像系统来增强梯度并收集多个数据序列进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在合成和真实世界数据上均有效。&lt;h4&gt;结论&lt;/h4&gt;该方法在视觉声音恢复方面具有潜力，并且能够提高声音恢复的质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When sound waves hit an object, they induce vibrations that producehigh-frequency and subtle visual changes, which can be used for recovering thesound. Early studies always encounter trade-offs related to sampling rate,bandwidth, field of view, and the simplicity of the optical path. Recentadvances in event camera hardware show good potential for its application invisual sound recovery, because of its superior ability in capturinghigh-frequency signals. However, existing event-based vibration recoverymethods are still sub-optimal for sound recovery. In this work, we propose anovel pipeline for non-contact sound recovery, fully utilizing spatial-temporalinformation from the event stream. We first generate a large training set usinga novel simulation pipeline. Then we designed a network that leverages thesparsity of events to capture spatial information and uses Mamba to modellong-term temporal information. Lastly, we train a spatial aggregation block toaggregate information from different locations to further improve signalquality. To capture event signals caused by sound waves, we also designed animaging system using a laser matrix to enhance the gradient and collectedmultiple data sequences for testing. Experimental results on synthetic andreal-world data demonstrate the effectiveness of our method.</description>
      <author>example@mail.com (Hao Yin, Shi Guo, Xu Jia, Xudong XU, Lu Zhang, Si Liu, Dong Wang, Huchuan Lu, Tianfan Xue)</author>
      <guid isPermaLink="false">2504.02402v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Group-based Distinctive Image Captioning with Memory Difference Encoding and Attention</title>
      <link>http://arxiv.org/abs/2504.02496v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages. arXiv admin note: substantial text overlap with  arXiv:2108.09151&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为“基于组的差异化显著图像描述方法”的全新方法，旨在增强图像描述的显著性和准确性。&lt;h4&gt;背景&lt;/h4&gt;近年来，图像描述的研究主要集中在通过增加数据集和模型大小来提高准确性。然而，现有模型在区分目标图像与其他相似图像方面的能力尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;旨在通过视觉比较同一组相似图像中的每张图像，并突出每张图像的独特性，来生成具有显著性的图像描述。&lt;h4&gt;方法&lt;/h4&gt;引入了基于组的差异化记忆注意力（GDMA）模块，该模块旨在识别和强调图像中独特可区分的对象特征，并在描述生成过程中优先考虑这些特征。此外，还从真实描述中选择了显著词汇来引导语言解码器和GDMA模块，并提出了新的评价指标“显著词率”（DisWordRate）。&lt;h4&gt;主要发现&lt;/h4&gt;该方法显著提高了基准模型的描述显著性，并在不牺牲过多准确性的情况下实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究为图像描述的显著性和准确性提供了新的解决方案，并提出了新的评价指标和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in image captioning have focused on enhancing accuracy bysubstantially increasing the dataset and model size. While conventionalcaptioning models exhibit high performance on established metrics such as BLEU,CIDEr, and SPICE, the capability of captions to distinguish the target imagefrom other similar images is under-explored. To generate distinctive captions,a few pioneers employed contrastive learning or re-weighted the ground-truthcaptions. However, these approaches often overlook the relationships amongobjects in a similar image group (e.g., items or properties within the samealbum or fine-grained events). In this paper, we introduce a novel approach toenhance the distinctiveness of image captions, namely Group-based DifferentialDistinctive Captioning Method, which visually compares each image with otherimages in one similar group and highlights the uniqueness of each image. Inparticular, we introduce a Group-based Differential Memory Attention (GDMA)module, designed to identify and emphasize object features in an image that areuniquely distinguishable within its image group, i.e., those exhibiting lowsimilarity with objects in other images. This mechanism ensures that suchunique object features are prioritized during caption generation for the image,thereby enhancing the distinctiveness of the resulting captions. To furtherrefine this process, we select distinctive words from the ground-truth captionsto guide both the language decoder and the GDMA module. Additionally, wepropose a new evaluation metric, the Distinctive Word Rate (DisWordRate), toquantitatively assess caption distinctiveness. Quantitative results indicatethat the proposed method significantly improves the distinctiveness of severalbaseline models, and achieves state-of-the-art performance on distinctivenesswhile not excessively sacrificing accuracy...</description>
      <author>example@mail.com (Jiuniu Wang, Wenjia Xu, Qingzhong Wang, Antoni B. Chan)</author>
      <guid isPermaLink="false">2504.02496v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>An Introductory Survey to Autoencoder-based Deep Clustering -- Sandboxes for Combining Clustering with Deep Learning</title>
      <link>http://arxiv.org/abs/2504.02087v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基于自编码器的深度聚类算法，这些算法在无需标签的情况下从数据中学习低维、非线性表示，并介绍了其在研究和开发新型聚类算法中的应用。&lt;h4&gt;背景&lt;/h4&gt;自编码器提供了一种从数据中学习低维、非线性表示的通用方法，它不依赖于数据类型或领域知识。&lt;h4&gt;目的&lt;/h4&gt;自编码器的通用性和领域无关性以及其简单性使其成为研究和发展新型（深度）聚类算法的理想平台。&lt;h4&gt;方法&lt;/h4&gt;通过结合深度学习与聚类，形成深度聚类，以学习适合特定聚类任务的表示，从而提高聚类结果的质量。&lt;h4&gt;主要发现&lt;/h4&gt;自编码器可以缓解维度灾难，并通过深度聚类算法学习到高质量的聚类表示。&lt;h4&gt;结论&lt;/h4&gt;本文为基于自编码器的深度聚类算法提供了基础，这些算法是许多现代方法的基石。&lt;h4&gt;翻译&lt;/h4&gt;摘要：自编码器提供了一种从数据中学习低维、非线性表示的通用方法，无需对数据类型或其他领域知识做出任何特定假设。其通用性和领域无关性相结合，加上其简单性，使自编码器成为研究和发展新型（深度）聚类算法的理想沙盒。聚类方法基于相似性对数据进行分组，这项任务可以从自编码器学习到的低维表示中受益，从而减轻维度灾难。特别是，深度学习与聚类的结合，称为深度聚类，能够学习到适合特定聚类任务的表示，从而获得高质量的结果。本综述为作为许多现代方法基石的基于自编码器的深度聚类算法提供了介绍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autoencoders offer a general way of learning low-dimensional, non-linearrepresentations from data without labels. This is achieved without making anyparticular assumptions about the data type or other domain knowledge. Thegenerality and domain agnosticism in combination with their simplicity makeautoencoders a perfect sandbox for researching and developing novel (deep)clustering algorithms. Clustering methods group data based on similarity, atask that benefits from the lower-dimensional representation learned by anautoencoder, mitigating the curse of dimensionality. Specifically, thecombination of deep learning with clustering, called Deep Clustering, enablesto learn a representation tailored to specific clustering tasks, leading tohigh-quality results. This survey provides an introduction to fundamentalautoencoder-based deep clustering algorithms that serve as building blocks formany modern approaches.</description>
      <author>example@mail.com (Collin Leiber, Lukas Miklautz, Claudia Plant, Christian Böhm)</author>
      <guid isPermaLink="false">2504.02087v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Data-Driven Design of 3GPP Handover Parameters with Bayesian Optimization and Transfer Learning</title>
      <link>http://arxiv.org/abs/2504.02633v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于高维贝叶斯优化和迁移学习的动态切换优化框架，用于解决密集蜂窝网络中由于用户速度和部署条件变化而导致的移动管理挑战。&lt;h4&gt;背景&lt;/h4&gt;在密集蜂窝网络中，由于用户速度和部署条件的变化，移动管理变得具有挑战性。传统的3GPP切换方案难以平衡无线链路故障（RLFs）和ping-pong现象。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的切换优化框架，以减少RLFs和ping-pong现象，并通过提高泛化能力来适应不同的用户速度。&lt;h4&gt;方法&lt;/h4&gt;该方法基于高维贝叶斯优化（HD-BO）和迁移学习，以减少训练时间并提高泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;在真实部署的评估中，HD-BO在性能上优于3GPP的set-1和set-5基准，而迁移学习使得快速适应成为可能而不损失性能。&lt;h4&gt;结论&lt;/h4&gt;数据驱动的、针对特定地点的移动管理在大规模网络中有巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：密集蜂窝网络中的移动管理由于用户速度和部署条件的变化而具有挑战性。依赖于固定A3偏移量和触发时间（TTT）参数的传统3GPP切换（HO）方案，难以平衡无线链路故障（RLFs）和ping-pong现象。我们提出了一种基于高维贝叶斯优化（HD-BO）和增强迁移学习的数据驱动切换优化框架，以减少训练时间并提高跨不同用户速度的泛化能力。在真实部署上的评估表明，HD-BO在性能上优于3GPP的set-1和set-5基准，而迁移学习使得快速适应成为可能而不损失性能。这突出了数据驱动、针对特定地点的大规模网络移动管理的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobility management in dense cellular networks is challenging due to varyinguser speeds and deployment conditions. Traditional 3GPP handover (HO) schemes,relying on fixed A3-offset and time-to-trigger (TTT) parameters, struggle tobalance radio link failures (RLFs) and ping-pongs. We propose a data-driven HOoptimization framework based on high-dimensional Bayesian optimization (HD-BO)and enhanced with transfer learning to reduce training time and improvegeneralization across different user speeds. Evaluations on a real-worlddeployment show that HD-BO outperforms 3GPP set-1 and set-5 benchmarks, whiletransfer learning enables rapid adaptation without loss in performance. Thishighlights the potential of data-driven, site-specific mobility management inlarge-scale networks.</description>
      <author>example@mail.com (Mohamed Benzaghta, Sahar Ammar, David López-Pérez, Basem Shihada, Giovanni Geraci)</author>
      <guid isPermaLink="false">2504.02633v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>CornerPoint3D: Look at the Nearest Corner Instead of the Center</title>
      <link>http://arxiv.org/abs/2504.02464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2407.04061&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对3D物体检测问题，提出了一种新的方法，旨在提高跨域场景下的检测精度。&lt;h4&gt;背景&lt;/h4&gt;传统的基于中心的3D物体检测方法在跨域任务中由于点云分布的变化，容易导致定位精度下降。同时，现有的评估指标由于数据集大小差异，存在过拟合问题。&lt;h4&gt;目的&lt;/h4&gt;研究如何提高模型在跨域场景下的检测性能，特别是预测物体尺寸的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出两种新的评估指标，引入EdgeHead来指导模型学习，并提出了CornerPoint3D检测器，该检测器基于CenterPoint，使用热图监督学习。&lt;h4&gt;主要发现&lt;/h4&gt;EdgeHead和CornerPoint3D方法显著提高了跨域场景下的检测性能，实现了检测质量和定位精度之间的平衡。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在多个跨域任务中优于传统的基于中心的检测器，为跨域3D物体检测提供了一种更合理和鲁棒的方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a new method for 3D object detection, aiming to improve detection performance in cross-domain scenarios. Traditional center-based 3D object detection methods are prone to poor localization accuracy in cross-domain tasks due to varying point cloud distributions. At the same time, existing evaluation metrics suffer from overfitting due to dataset-specific size variations. The main focus of this study is to improve the accuracy of predicting object sizes in cross-domain scenarios. Two new evaluation metrics are proposed, EdgeHead is introduced to guide model learning, and a new 3D object detector, CornerPoint3D, is proposed, which is based on CenterPoint and uses heatmaps to supervise the learning and detection of the nearest corner of each object. The proposed methods significantly improve the detection performance in cross-domain scenarios, achieve a balanced trade-off between detection quality and localization accuracy, and outperform the traditional center-based detector CenterPoint in multiple cross-domain tasks, providing a more reasonable and robust cross-domain 3D object detection solution.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D object detection aims to predict object centers, dimensions, and rotationsfrom LiDAR point clouds. Despite its simplicity, LiDAR captures only the nearside of objects, making center-based detectors prone to poor localizationaccuracy in cross-domain tasks with varying point distributions. Meanwhile,existing evaluation metrics designed for single-domain assessment also sufferfrom overfitting due to dataset-specific size variations. A key questionarises: Do we really need models to maintain excellent performance in theentire 3D bounding boxes after being applied across domains? Actually, one ofour main focuses is on preventing collisions between vehicles and otherobstacles, especially in cross-domain scenarios where correctly predicting thesizes is much more difficult. To address these issues, we rethink cross-domain3D object detection from a practical perspective. We propose two new metricsthat evaluate a model's ability to detect objects' closer-surfaces to the LiDARsensor. Additionally, we introduce EdgeHead, a refinement head that guidesmodels to focus more on learnable closer surfaces, significantly improvingcross-domain performance under both our new and traditional BEV/3D metrics.Furthermore, we argue that predicting the nearest corner rather than the objectcenter enhances robustness. We propose a novel 3D object detector, coined asCornerPoint3D, which is built upon CenterPoint and uses heatmaps to supervisethe learning and detection of the nearest corner of each object. Our proposedmethods realize a balanced trade-off between the detection quality of entirebounding boxes and the locating accuracy of closer surfaces to the LiDARsensor, outperforming the traditional center-based detector CenterPoint inmultiple cross-domain tasks and providing a more practically reasonable androbust cross-domain 3D object detection solution.</description>
      <author>example@mail.com (Ruixiao Zhang, Runwei Guan, Xiangyu Chen, Adam Prugel-Bennett, Xiaohao Cai)</author>
      <guid isPermaLink="false">2504.02464v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Customer Contact Efficiency with Graph Neural Networks in Credit Card Fraud Detection Workflow</title>
      <link>http://arxiv.org/abs/2504.02275v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合关系图卷积网络（RGCN）的欺诈检测框架，旨在提高识别欺诈交易准确性和效率，以解决信用卡欺诈问题。&lt;h4&gt;背景&lt;/h4&gt;信用卡欺诈自上个世纪以来一直是一个持续存在的问题，给行业造成了巨大的经济损失。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有欺诈检测系统误报合法交易的问题，提高检测准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种结合关系图卷积网络（RGCN）的欺诈检测框架，利用交易数据的关系结构减少对直接客户确认的需求。&lt;h4&gt;主要发现&lt;/h4&gt;实验使用IBM信用卡交易数据集评估了该框架的有效性。&lt;h4&gt;结论&lt;/h4&gt;该框架能够提高欺诈检测的准确性和效率，减少对客户直接确认的需求，同时保持高检测性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Credit card fraud has been a persistent issue since the last century, causingsignificant financial losses to the industry. The most effective way to preventfraud is by contacting customers to verify suspicious transactions. However,while these systems are designed to detect fraudulent activity, they oftenmistakenly flag legitimate transactions, leading to unnecessary declines thatdisrupt the user experience and erode customer trust. Frequent false positivescan frustrate customers, resulting in dissatisfaction, increased complaints,and a diminished sense of security. To address these limitations, we propose afraud detection framework incorporating Relational Graph Convolutional Networks(RGCN) to enhance the accuracy and efficiency of identifying fraudulenttransactions. By leveraging the relational structure of transaction data, ourmodel reduces the need for direct customer confirmation while maintaining highdetection performance. Our experiments are conducted using the IBM credit cardtransaction dataset to evaluate the effectiveness of this approach.</description>
      <author>example@mail.com (Menghao Huo, Kuan Lu, Qiang Zhu, Zhenrui Chen)</author>
      <guid isPermaLink="false">2504.02275v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Taylor Series-Inspired Local Structure Fitting Network for Few-shot Point Cloud Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2504.02454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TaylorSeg的无预训练局部结构拟合网络，用于Few-shot点云语义分割，旨在提高未见过的新类别在点云场景中的分割准确率。&lt;h4&gt;背景&lt;/h4&gt;现有的基于预训练的方法在点云语义分割中引入了过多的时间开销，并且忽略了不规则点云中的局部结构表示。&lt;h4&gt;目的&lt;/h4&gt;解决预训练方法带来的时间开销和局部结构表示问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为TaylorConv的新型局部结构拟合卷积，它通过显式编码局部几何结构来学习点云的低阶基本信息和高阶细化信息。基于TaylorConv，构建了两种TaylorSeg变体：非参数的TaylorSeg-NN和参数化的TaylorSeg-PN。TaylorSeg-PN还配备了自适应推拉（APP）模块以减轻查询集和支持集之间的特征分布差异。&lt;h4&gt;主要发现&lt;/h4&gt;TaylorSeg在2-way 1-shot设置下，在S3DIS和ScanNet数据集上分别比现有最先进方法提高了+2.28%和+4.37%的mIoU。&lt;h4&gt;结论&lt;/h4&gt;TaylorSeg通过无预训练和局部结构拟合，有效地提高了Few-shot点云语义分割的性能。&lt;h4&gt;翻译&lt;/h4&gt;Few-shot point cloud semantic segmentation aims to accurately segment 'unseen' new categories in point cloud scenes using limited labeled data. However, pretraining-based methods not only introduce excessive time overhead but also overlook the local structure representation among irregular point clouds. To address these issues, we propose a pretraining-free local structure fitting network for few-shot point cloud semantic segmentation, named TaylorSeg. Specifically, inspired by Taylor series, we treat the local structure representation of irregular point clouds as a polynomial fitting problem and propose a novel local structure fitting convolution, called TaylorConv. This convolution learns the low-order basic information and high-order refined information of point clouds from explicit encoding of local geometric structures. Then, using TaylorConv as the basic component, we construct two variants of TaylorSeg: a non-parametric TaylorSeg-NN and a parametric TaylorSeg-PN. The former can achieve performance comparable to existing parametric models without pretraining. For the latter, we equip it with an Adaptive Push-Pull (APP) module to mitigate the feature distribution differences between the query set and the support set. Extensive experiments validate the effectiveness of the proposed method. Notably, under the 2-way 1-shot setting, TaylorSeg-PN achieves improvements of +2.28% and +4.37% mIoU on the S3DIS and ScanNet datasets respectively, compared to the previous state-of-the-art methods. Our code is available at https://github.com/changshuowang/TaylorSeg.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot point cloud semantic segmentation aims to accurately segment"unseen" new categories in point cloud scenes using limited labeled data.However, pretraining-based methods not only introduce excessive time overheadbut also overlook the local structure representation among irregular pointclouds. To address these issues, we propose a pretraining-free local structurefitting network for few-shot point cloud semantic segmentation, namedTaylorSeg. Specifically, inspired by Taylor series, we treat the localstructure representation of irregular point clouds as a polynomial fittingproblem and propose a novel local structure fitting convolution, calledTaylorConv. This convolution learns the low-order basic information andhigh-order refined information of point clouds from explicit encoding of localgeometric structures. Then, using TaylorConv as the basic component, weconstruct two variants of TaylorSeg: a non-parametric TaylorSeg-NN and aparametric TaylorSeg-PN. The former can achieve performance comparable toexisting parametric models without pretraining. For the latter, we equip itwith an Adaptive Push-Pull (APP) module to mitigate the feature distributiondifferences between the query set and the support set. Extensive experimentsvalidate the effectiveness of the proposed method. Notably, under the 2-way1-shot setting, TaylorSeg-PN achieves improvements of +2.28% and +4.37% mIoU onthe S3DIS and ScanNet datasets respectively, compared to the previousstate-of-the-art methods. Our code is available athttps://github.com/changshuowang/TaylorSeg.</description>
      <author>example@mail.com (Changshuo Wang, Shuting He, Xiang Fang, Meiqing Wu, Siew-Kei Lam, Prayag Tiwari)</author>
      <guid isPermaLink="false">2504.02454v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Towards Computation- and Communication-efficient Computational Pathology</title>
      <link>http://arxiv.org/abs/2504.02628v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MAGA-GLTrans的计算和通信高效的框架，用于解决计算病理学模型在依赖高倍全切片图像分析时的诊断效率问题。&lt;h4&gt;背景&lt;/h4&gt;当前的计算病理学模型在多种应用中表现出色，但由于依赖高倍全切片图像分析，其诊断效率存在显著挑战，尤其是在时间敏感的诊断场景和需要高效数据传输的情况下。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出了MAGA-GLTrans框架，旨在通过使用低倍输入而不是高倍输入来有效地减少计算时间、文件传输需求和存储开销。&lt;h4&gt;方法&lt;/h4&gt;该框架的关键创新在于提出的放大比例对齐（MAGA）机制，它通过自我监督学习有效地对齐低倍和高倍特征表示，以弥合信息差距。&lt;h4&gt;主要发现&lt;/h4&gt;MAGA-GLTrans在各种基本的CPath任务中进行了广泛的评估，展示了最先进的分类性能，同时实现了显著的效率提升：计算时间减少了高达10.7倍，文件传输和存储需求减少了20倍以上。&lt;h4&gt;结论&lt;/h4&gt;MAGA-GLTrans框架的灵活性和高效性使其成为时间敏感应用的有希望解决方案，特别是在手术冷冻切片诊断的背景下，准确性和效率至关重要。&lt;h4&gt;翻译&lt;/h4&gt;尽管在广泛的领域中表现出色，但当前的计算机病理学模型由于依赖高倍全切片图像分析，在诊断效率方面面临重大挑战。这种限制严重影响了它们的临床实用性，尤其是在时间敏感的诊断场景和需要高效数据传输的情况下。为了解决这些问题，我们提出了一种名为放大比例对齐全局-局部变换器（MAGA-GLTrans）的新型计算和通信高效框架。我们的方法通过使用低倍输入而不是高倍输入，有效地减少了计算时间、文件传输需求和存储开销。我们的关键创新在于我们提出的放大比例对齐（MAGA）机制，该机制通过自我监督学习通过有效地对齐低倍和高倍特征表示来弥合信息差距。通过在各个基本的CPath任务中进行广泛的评估，MAGA-GLTrans展示了最先进的分类性能，同时实现了显著的效率提升：计算时间减少了高达10.7倍，文件传输和存储需求减少了20倍以上。此外，我们通过两个重要的扩展突出了我们的MAGA框架的通用性：（1）将其作为特征提取器用于提高任何CPath架构的效率，（2）与现有基础模型和病理学特定编码器兼容，使它们能够以最小信息损失处理低倍输入。这些进步使MAGA-GLTrans成为时间敏感应用的有希望解决方案，特别是在手术冷冻切片诊断的背景下，准确性和效率至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the impressive performance across a wide range of applications,current computational pathology models face significant diagnostic efficiencychallenges due to their reliance on high-magnification whole-slide imageanalysis. This limitation severely compromises their clinical utility,especially in time-sensitive diagnostic scenarios and situations requiringefficient data transfer. To address these issues, we present a novelcomputation- and communication-efficient framework called Magnification-AlignedGlobal-Local Transformer (MAGA-GLTrans). Our approach significantly reducescomputational time, file transfer requirements, and storage overhead byenabling effective analysis using low-magnification inputs rather thanhigh-magnification ones. The key innovation lies in our proposed magnificationalignment (MAGA) mechanism, which employs self-supervised learning to bridgethe information gap between low and high magnification levels by effectivelyaligning their feature representations. Through extensive evaluation acrossvarious fundamental CPath tasks, MAGA-GLTrans demonstrates state-of-the-artclassification performance while achieving remarkable efficiency gains: up to10.7 times reduction in computational time and over 20 times reduction in filetransfer and storage requirements. Furthermore, we highlight the versatility ofour MAGA framework through two significant extensions: (1) its applicability asa feature extractor to enhance the efficiency of any CPath architecture, and(2) its compatibility with existing foundation models andhistopathology-specific encoders, enabling them to process low-magnificationinputs with minimal information loss. These advancements position MAGA-GLTransas a particularly promising solution for time-sensitive applications,especially in the context of intraoperative frozen section diagnosis where bothaccuracy and efficiency are paramount.</description>
      <author>example@mail.com (Chu Han, Bingchao Zhao, Jiatai Lin, Shanshan Lyu, Longfei Wang, Tianpeng Deng, Cheng Lu, Changhong Liang, Hannah Y. Wen, Xiaojing Guo, Zhenwei Shi, Zaiyi Liu)</author>
      <guid isPermaLink="false">2504.02628v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Refining CLIP's Spatial Awareness: A Visual-Centric Perspective</title>
      <link>http://arxiv.org/abs/2504.02328v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为空间相关性蒸馏（SCD）的框架，旨在解决Contrastive Language-Image Pre-training (CLIP)在密集多模态任务中空间感知能力不足的问题，并通过该框架实现了在多种开放词汇密集预测基准测试中的最先进结果。&lt;h4&gt;背景&lt;/h4&gt;CLIP在全局语言对齐方面表现出色，但在空间信息敏感度上有限，导致其在零样本分类任务中表现良好，但在需要精确空间理解的任务中表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提高CLIP在密集多模态任务中的空间感知能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为空间相关性蒸馏（SCD）的框架，以保留CLIP的内在空间结构并减轻上述退化。此外，还引入了一个轻量级的Refiner，它直接从CLIP中提取精细的相关性，基于CLIP自然捕捉高质量密集特征的有趣发现。&lt;h4&gt;主要发现&lt;/h4&gt;CLIP ViTs经过区域语言对齐（RLA）微调后，在空间意识方面存在显著损失，这是密集预测任务中至关重要的。&lt;h4&gt;结论&lt;/h4&gt;SCD框架和轻量级Refiner的使用使得CLIP ViTs能够整合视觉-语言和视觉中心的改进，在多种开放词汇密集预测基准测试中达到了最先进的结果。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive Language-Image Pre-training (CLIP)在全局语言对齐方面表现出色，但在空间信息敏感度上有限，导致其在零样本分类任务中表现良好，但在需要精确空间理解的任务中表现不佳。近期的研究引入了区域语言对齐（RLA）来增强CLIP在密集多模态任务中的性能，通过将区域视觉表示与相应的文本输入对齐。然而，我们发现经过RLA微调的CLIP ViTs在空间意识方面存在明显的损失，这对于密集预测任务至关重要。为了解决这个问题，我们提出了空间相关性蒸馏（SCD）框架，该框架保留了CLIP固有的空间结构并减轻了上述退化。为了进一步增强空间相关性，我们引入了一个轻量级的Refiner，它基于CLIP自然捕捉高质量密集特征的有趣发现，直接从CLIP中提取精细的相关性。这些组件共同构成了一个鲁棒的蒸馏框架，使得CLIP ViTs能够整合视觉-语言和视觉中心的改进，在各种开放词汇密集预测基准测试中实现了最先进的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive Language-Image Pre-training (CLIP) excels in global alignmentwith language but exhibits limited sensitivity to spatial information, leadingto strong performance in zero-shot classification tasks but underperformance intasks requiring precise spatial understanding. Recent approaches haveintroduced Region-Language Alignment (RLA) to enhance CLIP's performance indense multimodal tasks by aligning regional visual representations withcorresponding text inputs. However, we find that CLIP ViTs fine-tuned with RLAsuffer from notable loss in spatial awareness, which is crucial for denseprediction tasks. To address this, we propose the Spatial CorrelationDistillation (SCD) framework, which preserves CLIP's inherent spatial structureand mitigates the above degradation. To further enhance spatial correlations,we introduce a lightweight Refiner that extracts refined correlations directlyfrom CLIP before feeding them into SCD, based on an intriguing finding thatCLIP naturally captures high-quality dense features. Together, these componentsform a robust distillation framework that enables CLIP ViTs to integrate bothvisual-language and visual-centric improvements, achieving state-of-the-artresults across various open-vocabulary dense prediction benchmarks.</description>
      <author>example@mail.com (Congpei Qiu, Yanhao Wu, Wei Ke, Xiuxiu Bai, Tong Zhang)</author>
      <guid isPermaLink="false">2504.02328v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>All-day Depth Completion via Thermal-LiDAR Fusion</title>
      <link>http://arxiv.org/abs/2504.02356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了在恶劣环境（如雨天和低光条件）下使用热像仪进行深度补全的可行性，并提出了一个基于对比学习和伪监督（COPS）的框架来提高补全精度。&lt;h4&gt;背景&lt;/h4&gt;现有深度补全方法在明亮条件下表现良好，但在恶劣环境下，如雨天和低光条件下，由于RGB传感器的限制，往往难以实现可靠性能。&lt;h4&gt;目的&lt;/h4&gt;评估热像仪在多种环境条件下的深度补全的可行性和鲁棒性，并提出解决方案以克服深度边界不清和监督不足的问题。&lt;h4&gt;方法&lt;/h4&gt;在MS$^2$和ViViD数据集上进行了广泛的基准测试，提出了一种结合对比学习和伪监督的框架（COPS），利用深度基础模型来提高深度边界清晰度和补全精度。&lt;h4&gt;主要发现&lt;/h4&gt;热像仪在恶劣环境下提供清晰的可见性，但热图像的特点（如模糊、低对比度和噪声）带来了深度边界不清的问题。&lt;h4&gt;结论&lt;/h4&gt;论文提出的COPS框架能够有效提高深度补全的准确性和鲁棒性，为在恶劣环境下进行深度补全提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;Depth completion, which estimates dense depth from sparse LiDAR and RGBimages, has demonstrated outstanding performance in well-lit conditions.However, due to the limitations of RGB sensors, existing methods often struggleto achieve reliable performance in harsh environments, such as heavy rain andlow-light conditions. Furthermore, we observe that ground truth depth mapsoften suffer from large missing measurements in adverse weather conditions suchas heavy rain, leading to insufficient supervision. In contrast, thermalcameras are known for providing clear and reliable visibility in suchconditions, yet research on thermal-LiDAR depth completion remainsunderexplored. Moreover, the characteristics of thermal images, such asblurriness, low contrast, and noise, bring unclear depth boundary problems. Toaddress these challenges, we first evaluate the feasibility and robustness ofthermal-LiDAR depth completion across diverse lighting (eg., well-lit,low-light), weather (eg., clear-sky, rainy), and environment (eg., indoor,outdoor) conditions, by conducting extensive benchmarks on the MS$^2$ and ViViDdatasets. In addition, we propose a framework that utilizes COntrastivelearning and Pseudo-Supervision (COPS) to enhance depth boundary clarity andimprove completion accuracy by leveraging a depth foundation model in two keyways. First, COPS enforces a depth-aware contrastive loss between differentdepth points by mining positive and negative samples using a monocular depthfoundation model to sharpen depth boundaries. Second, it mitigates the issue ofincomplete supervision from ground truth depth maps by leveraging foundationmodel predictions as dense depth priors. We also provide in-depth analyses ofthe key challenges in thermal-LiDAR depth completion to aid in understandingthe task and encourage future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Depth completion, which estimates dense depth from sparse LiDAR and RGBimages, has demonstrated outstanding performance in well-lit conditions.However, due to the limitations of RGB sensors, existing methods often struggleto achieve reliable performance in harsh environments, such as heavy rain andlow-light conditions. Furthermore, we observe that ground truth depth mapsoften suffer from large missing measurements in adverse weather conditions suchas heavy rain, leading to insufficient supervision. In contrast, thermalcameras are known for providing clear and reliable visibility in suchconditions, yet research on thermal-LiDAR depth completion remainsunderexplored. Moreover, the characteristics of thermal images, such asblurriness, low contrast, and noise, bring unclear depth boundary problems. Toaddress these challenges, we first evaluate the feasibility and robustness ofthermal-LiDAR depth completion across diverse lighting (eg., well-lit,low-light), weather (eg., clear-sky, rainy), and environment (eg., indoor,outdoor) conditions, by conducting extensive benchmarks on the MS$^2$ and ViViDdatasets. In addition, we propose a framework that utilizes COntrastivelearning and Pseudo-Supervision (COPS) to enhance depth boundary clarity andimprove completion accuracy by leveraging a depth foundation model in two keyways. First, COPS enforces a depth-aware contrastive loss between differentdepth points by mining positive and negative samples using a monocular depthfoundation model to sharpen depth boundaries. Second, it mitigates the issue ofincomplete supervision from ground truth depth maps by leveraging foundationmodel predictions as dense depth priors. We also provide in-depth analyses ofthe key challenges in thermal-LiDAR depth completion to aid in understandingthe task and encourage future research.</description>
      <author>example@mail.com (Janghyun Kim, Minseong Kweon, Jinsun Park, Ukcheol Shin)</author>
      <guid isPermaLink="false">2504.02356v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Model Editing with Task-Localized Sparse Fine-tuning</title>
      <link>http://arxiv.org/abs/2504.02620v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted ICLR 2025 - https://github.com/iurada/talos-task-arithmetic&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法TaLoS，用于编辑模型，通过构建稀疏的任务向量来表示特定任务的知识，提高了训练和推理效率，并在任务添加和否定方面优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;任务算术是一种编辑模型的有前景方法，它将特定任务的知识表示为可组合的任务向量。然而，现有方法依赖于网络线性化来推导任务向量，导致训练和推理过程中的计算瓶颈，并且线性化本身不能确保权重解耦，这是任务向量无冲突组合的关键属性。&lt;h4&gt;目的&lt;/h4&gt;提出TaLoS以解决现有方法的计算瓶颈和权重解耦问题，允许在没有显式线性化和跨任务共享信息的情况下构建稀疏任务向量。&lt;h4&gt;方法&lt;/h4&gt;TaLoS方法通过识别预训练模型中具有一致低梯度敏感性的参数子集，并只对这些参数进行稀疏更新，从而促进权重解耦。&lt;h4&gt;主要发现&lt;/h4&gt;发现预训练模型中存在一组参数，这些参数在所有任务中都具有一致的低梯度敏感性，稀疏更新这些参数可以促进权重解耦。&lt;h4&gt;结论&lt;/h4&gt;TaLoS提高了训练和推理效率，并在任务添加和否定方面优于现有方法。该方法通过模块化参数编辑，促进了可适应基础模型在实际应用中的部署。&lt;h4&gt;翻译&lt;/h4&gt;摘要：任务算术作为一种通过将特定任务知识表示为可组合的任务向量来编辑模型的方法，已经显示出其潜力。然而，现有方法依赖于网络线性化来推导任务向量，这导致了训练和推理过程中的计算瓶颈。此外，线性化本身并不能确保权重解耦，这是实现任务向量无冲突组合的关键属性。为了解决这些问题，我们提出了TaLoS，它允许在不要求显式线性化和跨任务共享信息的情况下构建稀疏任务向量。我们发现预训练模型包含一组参数，这些参数在所有任务中都表现出一致的低梯度敏感性，并且只对这些参数进行稀疏更新可以促进权重解耦。我们的实验表明，TaLoS提高了训练和推理效率，在任务添加和否定方面优于现有方法。通过实现模块化参数编辑，我们的方法促进了可适应基础模型在现实世界应用中的实际部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Task arithmetic has emerged as a promising approach for editing models byrepresenting task-specific knowledge as composable task vectors. However,existing methods rely on network linearization to derive task vectors, leadingto computational bottlenecks during training and inference. Moreover,linearization alone does not ensure weight disentanglement, the key propertythat enables conflict-free composition of task vectors. To address this, wepropose TaLoS which allows to build sparse task vectors with minimalinterference without requiring explicit linearization and sharing informationacross tasks. We find that pre-trained models contain a subset of parameterswith consistently low gradient sensitivity across tasks, and that sparselyupdating only these parameters allows for promoting weight disentanglementduring fine-tuning. Our experiments prove that TaLoS improves training andinference efficiency while outperforming current methods in task addition andnegation. By enabling modular parameter editing, our approach fosters practicaldeployment of adaptable foundation models in real-world applications.</description>
      <author>example@mail.com (Leonardo Iurada, Marco Ciccone, Tatiana Tommasi)</author>
      <guid isPermaLink="false">2504.02620v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Moment Quantization for Video Temporal Grounding</title>
      <link>http://arxiv.org/abs/2504.02286v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于时刻量化的视频时间定位方法（MQVTG），用于提高相关和无关时刻的区分度。&lt;h4&gt;背景&lt;/h4&gt;视频时间定位是视频理解中的关键任务，其目的是定位与语言描述相关的时刻。这一任务的挑战在于区分相关和无关的时刻。&lt;h4&gt;目的&lt;/h4&gt;提高相关和无关时刻的区分度。&lt;h4&gt;方法&lt;/h4&gt;MQVTG通过将输入视频量化为不同的离散向量来增强相关和无关时刻的区分度。具体来说，MQVTG维护一个可学习的时刻码本，其中每个视频时刻与一个码字匹配。为了考虑视觉多样性，MQVTG将时刻-码字匹配视为一个聚类过程，而不使用离散向量，以避免直接硬量化中信息的丢失。此外，还采用了有效的先验初始化和联合投影策略来增强维护的时刻码本。&lt;h4&gt;主要发现&lt;/h4&gt;MQVTG在六个流行的基准测试中表现出了有效性和泛化能力，显著优于现有方法。进一步的质量分析表明，该方法有效地将相关特征分组，并分离无关特征，与提高区分度的目标一致。&lt;h4&gt;结论&lt;/h4&gt;MQVTG是一种简单易实现的视频时间定位方法，可以集成到现有的时间定位模型中，作为即插即用的组件。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video temporal grounding is a critical video understanding task, which aimsto localize moments relevant to a language description. The challenge of thistask lies in distinguishing relevant and irrelevant moments. Previous methodsfocused on learning continuous features exhibit weak differentiation betweenforeground and background features. In this paper, we propose a novelMoment-Quantization based Video Temporal Grounding method (MQVTG), whichquantizes the input video into various discrete vectors to enhance thediscrimination between relevant and irrelevant moments. Specifically, MQVTGmaintains a learnable moment codebook, where each video moment matches acodeword. Considering the visual diversity, i.e., various visual expressionsfor the same moment, MQVTG treats moment-codeword matching as a clusteringprocess without using discrete vectors, avoiding the loss of useful informationfrom direct hard quantization. Additionally, we employ effectiveprior-initialization and joint-projection strategies to enhance the maintainedmoment codebook. With its simple implementation, the proposed method can beintegrated into existing temporal grounding models as a plug-and-playcomponent. Extensive experiments on six popular benchmarks demonstrate theeffectiveness and generalizability of MQVTG, significantly outperformingstate-of-the-art methods. Further qualitative analysis shows that our methodeffectively groups relevant features and separates irrelevant ones, aligningwith our goal of enhancing discrimination.</description>
      <author>example@mail.com (Xiaolong Sun, Le Wang, Sanping Zhou, Liushuai Shi, Kun Xia, Mengnan Liu, Yabing Wang, Gang Hua)</author>
      <guid isPermaLink="false">2504.02286v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>RoboAct-CLIP: Video-Driven Pre-training of Atomic Action Understanding for Robotics</title>
      <link>http://arxiv.org/abs/2504.02069v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IROS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了RoboAct-CLIP，一个用于机器人系统的视觉语言模型（VLM），它通过多模态感知和语义推理实现跨任务泛化、动态环境交互和长期规划。该模型解决了现有VLM在机器人应用中的局限性，并展示了在模拟环境中的优越性能。&lt;h4&gt;背景&lt;/h4&gt;现有的开放源代码VLM主要用于通用视觉-语言对齐任务，无法有效建模机器人操作中至关重要的时间相关动作语义。&lt;h4&gt;目的&lt;/h4&gt;提出RoboAct-CLIP以克服现有VLM的局限性，包括对时间演变模式的不考虑和视觉特征之间的纠缠。&lt;h4&gt;方法&lt;/h4&gt;1) 提出了一种数据集重建框架，对开源机器人视频进行语义约束的动作单元分割和重新标注，构建包含单一原子动作（如“抓取”）的纯净训练集。2) 基于CLIP架构，采用时间解耦微调策略，将视频帧中的时间动作特征从以对象为中心的特征中分离出来，以实现机器人原子动作的分层表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，RoboAct-CLIP预训练模型在模拟环境中比基线VLM成功率高12%，并在多对象操作任务中表现出更优的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;RoboAct-CLIP通过解决现有VLM的局限性，显著提高了机器人系统的性能。&lt;h4&gt;翻译&lt;/h4&gt;Visual Language Models (VLMs) have emerged as pivotal tools for robot systems, enabling cross-task generalization, dynamic environmental interaction, and long-horizon planning through multimodal perception and semantic reasoning. However, existing open-source VLMs predominantly trained for generic vision-language alignment tasks fail to model temporally correlated action semantics that are crucial for robotic manipulation effectively. While current image-based fine-tuning methods partially adapt VLMs to robotic applications, they fundamentally disregard temporal evolution patterns in video sequences and suffer from visual feature entanglement between robotic agents, manipulated objects, and environmental contexts, thereby limiting semantic decoupling capability for atomic actions and compromising model generalizability. To overcome these challenges, this work presents RoboAct-CLIP with dual technical contributions: 1) A dataset reconstruction framework that performs semantic-constrained action unit segmentation and re-annotation on open-source robotic videos, constructing purified training sets containing singular atomic actions (e.g., "grasp"); 2) A temporal-decoupling fine-tuning strategy based on Contrastive Language-Image Pretraining (CLIP) architecture, which disentangles temporal action features across video frames from object-centric characteristics to achieve hierarchical representation learning of robotic atomic actions. Experimental results in simulated environments demonstrate that the RoboAct-CLIP pretrained model achieves a 12% higher success rate than baseline VLMs, along with superior generalization in multi-object manipulation tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Language Models (VLMs) have emerged as pivotal tools for roboticsystems, enabling cross-task generalization, dynamic environmental interaction,and long-horizon planning through multimodal perception and semantic reasoning.However, existing open-source VLMs predominantly trained for genericvision-language alignment tasks fail to model temporally correlated actionsemantics that are crucial for robotic manipulation effectively. While currentimage-based fine-tuning methods partially adapt VLMs to robotic applications,they fundamentally disregard temporal evolution patterns in video sequences andsuffer from visual feature entanglement between robotic agents, manipulatedobjects, and environmental contexts, thereby limiting semantic decouplingcapability for atomic actions and compromising model generalizability.Toovercome these challenges, this work presents RoboAct-CLIP with dual technicalcontributions: 1) A dataset reconstruction framework that performssemantic-constrained action unit segmentation and re-annotation on open-sourcerobotic videos, constructing purified training sets containing singular atomicactions (e.g., "grasp"); 2) A temporal-decoupling fine-tuning strategy based onContrastive Language-Image Pretraining (CLIP) architecture, which disentanglestemporal action features across video frames from object-centriccharacteristics to achieve hierarchical representation learning of roboticatomic actions.Experimental results in simulated environments demonstrate thatthe RoboAct-CLIP pretrained model achieves a 12% higher success rate thanbaseline VLMs, along with superior generalization in multi-object manipulationtasks.</description>
      <author>example@mail.com (Zhiyuan Zhang, Yuxin He, Yong Sun, Junyu Shi, Lijiang Liu, Qiang Nie)</author>
      <guid isPermaLink="false">2504.02069v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>LLM-Augmented Graph Neural Recommenders: Integrating User Reviews</title>
      <link>http://arxiv.org/abs/2504.02195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合用户评论和购买行为的推荐系统框架，通过GNN和LLM生成审查感知表示，在保留评论语义的同时减少文本噪声。&lt;h4&gt;背景&lt;/h4&gt;推荐系统越来越倾向于结合用户评论和购买行为的信息，但将LLM生成的文本表示与基于图的用户行为嵌入合并仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，使用GNN模型和LLM生成审查感知表示，同时平衡用户-物品交互和文本特征。&lt;h4&gt;方法&lt;/h4&gt;使用混合目标函数平衡用户-物品交互和文本衍生特征，确保有效捕捉用户的语言和行为信号。&lt;h4&gt;主要发现&lt;/h4&gt;在多个数据集上评估了该方法，与基线GNN推荐模型相比，取得了显著改进。特别地，当审查数据稀疏或分布不均时，推荐准确度有显著提升。&lt;h4&gt;结论&lt;/h4&gt;将LLM驱动的文本反馈与GNN得出的用户行为模式相结合，对于开发鲁棒、情境感知的推荐系统具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommender systems increasingly aim to combine signals from both userreviews and purchase (or other interaction) behaviors. While user-writtencomments provide explicit insights about preferences, merging these textualrepresentations from large language models (LLMs) with graph-based embeddingsof user actions remains a challenging task. In this work, we propose aframework that employs both a Graph Neural Network (GNN)-based model and an LLMto produce review-aware representations, preserving review semantics whilemitigating textual noise. Our approach utilizes a hybrid objective thatbalances user-item interactions against text-derived features, ensuring thatuser's both behavioral and linguistic signals are effectively captured. Weevaluate this method on multiple datasets from diverse application domains,demonstrating consistent improvements over a baseline GNN-based recommendermodel. Notably, our model achieves significant gains in recommendation accuracywhen review data is sparse or unevenly distributed. These findings highlightthe importance of integrating LLM-driven textual feedback with GNN-derived userbehavioral patterns to develop robust, context-aware recommender systems.</description>
      <author>example@mail.com (Hiroki Kanezashi, Toyotaro Suzumura, Cade Reid, Md Mostafizur Rahman, Yu Hirate)</author>
      <guid isPermaLink="false">2504.02195v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Re-thinking Temporal Search for Long-Form Video Understanding</title>
      <link>http://arxiv.org/abs/2504.02259v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025; A real-world long video needle-in-haystack  benchmark; long-video QA with human ref frames&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了长视频理解中的时间搜索范式，提出了新的时间搜索方法，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;长视频理解在计算机视觉中是一个重大挑战，现有的长上下文视觉语言模型（VLMs）存在时间搜索能力不足的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的时间搜索方法，提高长视频理解的效果。&lt;h4&gt;方法&lt;/h4&gt;将时间搜索问题定义为长视频海量信息中查找最小相关帧的问题，并创建了包含3,874个标注实例的LV-Haystack基准数据集。同时，提出了一种名为T*的轻量级关键帧搜索框架，将时间搜索转化为空间搜索问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，T*框架在LV-Haystack基准数据集上显著提高了SOTA长视频理解性能，且在特定条件下，T*能显著提升GPT-4o和LLaVA-OneVision-72B模型的性能。&lt;h4&gt;结论&lt;/h4&gt;T*框架能够有效提高长视频理解的效果，为长视频理解领域提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;Efficient understanding of long-form videos remains a significant challenge in computer vision. In this work, we revisit temporal search paradigms for long-form video understanding, studying a fundamental issue pertaining to all state-of-the-art (SOTA) long-context vision-language models (VLMs). In particular, our contributions are two-fold: First, we formulate temporal search as a Long Video Haystack problem, i.e., finding a minimal set of relevant frames (typically one to five) among tens of thousands of frames from real-world long videos given specific queries. To validate our formulation, we create LV-Haystack, the first benchmark containing 3,874 human-annotated instances with fine-grained evaluation metrics for assessing keyframe search quality and computational efficiency. Experimental results on LV-Haystack highlight a significant research gap in temporal search capabilities, with SOTA keyframe selection methods achieving only 2.1% temporal F1 score on the LV-Bench subset. Next, inspired by visual search in images, we re-think temporal searching and propose a lightweight keyframe searching framework, T*, which casts the expensive temporal search as a spatial search problem. T* leverages superior visual localization capabilities typically used in images and introduces an adaptive zooming-in mechanism that operates across both temporal and spatial dimensions. Our extensive experiments show that when integrated with existing methods, T* significantly improves SOTA long-form video understanding performance. Specifically, under an inference budget of 32 frames, T* improves GPT-4o's performance from 50.5% to 53.1% and LLaVA-OneVision-72B's performance from 56.5% to 62.4% on LongVideoBench XL subset. Our PyTorch code, benchmark dataset and models are included in the Supplementary material.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient understanding of long-form videos remains a significant challengein computer vision. In this work, we revisit temporal search paradigms forlong-form video understanding, studying a fundamental issue pertaining to allstate-of-the-art (SOTA) long-context vision-language models (VLMs). Inparticular, our contributions are two-fold: First, we formulate temporal searchas a Long Video Haystack problem, i.e., finding a minimal set of relevantframes (typically one to five) among tens of thousands of frames fromreal-world long videos given specific queries. To validate our formulation, wecreate LV-Haystack, the first benchmark containing 3,874 human-annotatedinstances with fine-grained evaluation metrics for assessing keyframe searchquality and computational efficiency. Experimental results on LV-Haystackhighlight a significant research gap in temporal search capabilities, with SOTAkeyframe selection methods achieving only 2.1% temporal F1 score on the LVBenchsubset.  Next, inspired by visual search in images, we re-think temporal searching andpropose a lightweight keyframe searching framework, T*, which casts theexpensive temporal search as a spatial search problem. T* leverages superiorvisual localization capabilities typically used in images and introduces anadaptive zooming-in mechanism that operates across both temporal and spatialdimensions. Our extensive experiments show that when integrated with existingmethods, T* significantly improves SOTA long-form video understandingperformance. Specifically, under an inference budget of 32 frames, T* improvesGPT-4o's performance from 50.5% to 53.1% and LLaVA-OneVision-72B's performancefrom 56.5% to 62.4% on LongVideoBench XL subset. Our PyTorch code, benchmarkdataset and models are included in the Supplementary material.</description>
      <author>example@mail.com (Jinhui Ye, Zihan Wang, Haosen Sun, Keshigeyan Chandrasegaran, Zane Durante, Cristobal Eyzaguirre, Yonatan Bisk, Juan Carlos Niebles, Ehsan Adeli, Li Fei-Fei, Jiajun Wu, Manling Li)</author>
      <guid isPermaLink="false">2504.02259v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Estimating Scene Flow in Robot Surroundings with Distributed Miniaturized Time-of-Flight Sensors</title>
      <link>http://arxiv.org/abs/2504.02439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 5 figures, 2 tables, 1 algorithm&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从低密度和噪声点云中估计场景流的方法，以改善机器人的安全运动和反应。&lt;h4&gt;背景&lt;/h4&gt;跟踪机器人周围的人或物体运动对于提高机器人的安全运动和反应至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究提出了一种从机器人身体上分布的微型飞行时间（ToF）传感器获取的低密度和噪声点云中进行场景流估计的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法通过聚类连续帧中的点并应用迭代最近点（ICP）来估计密集的运动流。此外，还引入了额外的步骤以减轻传感器噪声和低密度数据点的影响。具体来说，使用基于适应度的分类来区分静止点和运动点，以及一个内点去除策略来细化几何对应关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法能够以与传感器噪声相匹配的误差，一致地近似运动的方向和大小。&lt;h4&gt;结论&lt;/h4&gt;该方法在估计机器人周围物体运动方面是有效的。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents an approach for scene flow estimation from low-density and noisy point clouds acquired from miniaturized Time of Flight (ToF) sensors distributed on the robot body. The proposed method clusters points from consecutive frames and applies Iterative Closest Point (ICP) to estimate a dense motion flow, with additional steps introduced to mitigate the impact of sensor noise and low-density data points. Specifically, a fitness-based classification is employed to distinguish between stationary and moving points, and an inlier removal strategy is used to refine geometric correspondences. Experimental results show that the method consistently approximates the direction of the motion and its magnitude with an error which is in line with sensor noise.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tracking motions of humans or objects in the surroundings of the robot isessential to improve safe robot motions and reactions. In this work, we presentan approach for scene flow estimation from low-density and noisy point cloudsacquired from miniaturized Time of Flight (ToF) sensors distributed on therobot body. The proposed method clusters points from consecutive frames andapplies Iterative Closest Point (ICP) to estimate a dense motion flow, withadditional steps introduced to mitigate the impact of sensor noise andlow-density data points. Specifically, we employ a fitness-based classificationto distinguish between stationary and moving points and an inlier removalstrategy to refine geometric correspondences. The proposed approach isvalidated in an experimental setup where 24 ToF are used to estimate thevelocity of an object moving at different controlled speeds. Experimentalresults show that the method consistently approximates the direction of themotion and its magnitude with an error which is in line with sensor noise.</description>
      <author>example@mail.com (Jack Sander, Giammarco Caroleo, Alessandro Albini, Perla Maiolino)</author>
      <guid isPermaLink="false">2504.02439v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>OmniCellTOSG: The First Cell Text-Omic Signaling Graphs Dataset for Joint LLM and GNN Modeling</title>
      <link>http://arxiv.org/abs/2504.02148v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为OmniCellTOSG的细胞文本-组学信号图（TOSG）数据集，用于研究细胞信号网络。&lt;h4&gt;背景&lt;/h4&gt;细胞信号系统受到多种因素的影响，如年龄、性别、饮食、环境暴露和疾病，这使得解码这些系统具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;OmniCellTOSG旨在通过整合可读性注释和定量数据，为理解细胞信号网络提供一个新的数据集。&lt;h4&gt;方法&lt;/h4&gt;OmniCellTOSG包含约1.2亿个细胞的单细胞RNA测序数据，并引入了一种结合大型语言模型和图神经网络的新图模型。&lt;h4&gt;主要发现&lt;/h4&gt;OmniCellTOSG数据集有助于解码细胞信号，并促进创新细胞信号模型的发展。&lt;h4&gt;结论&lt;/h4&gt;OmniCellTOSG数据集为生命科学、医疗保健和精准医学研究提供了新的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：复杂的细胞信号系统，受蛋白质丰度和相互作用的影响，在器官中产生不同的细胞类型。这些系统在年龄、性别、饮食、环境暴露和疾病等影响下演变，由于涉及数万个基因和蛋白质，解码它们具有挑战性。最近，数十亿个单细胞组学数据为理解各种细胞亚群和条件下的信号网络提供了坚实的基础。受到在大规模数据集上预训练的大型基础模型（例如大型语言模型和大型视觉模型）成功的影响，我们引入了OmniCellTOSG，这是第一个细胞文本-组学信号图（TOSG）数据集。每个TOSG代表单个或元细胞的信号网络，并标注了如器官、疾病、性别、年龄和细胞亚型等信息。OmniCellTOSG提供了两个关键贡献。首先，它引入了一种新的图模型，该模型将可读性注释（如生物功能、细胞位置、信号通路、相关疾病和药物）与定量基因和蛋白质丰度数据相结合，使图推理能够解码细胞信号。这种方法需要结合大型语言模型和图神经网络的新联合模型。其次，该数据集由来自不同组织（健康和疾病）和条件的大约1.2亿个细胞的单细胞RNA测序数据构建，并且完全兼容PyTorch。这促进了创新细胞信号模型的发展，这些模型可以改变生命科学、医疗保健和精准医学研究。OmniCellTOSG数据集将持续扩展并定期更新。数据集和代码可在https://github.com/FuhaiLiAiLab/OmniCellTOSG获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complex cell signaling systems -- governed by varying protein abundances andinteractions -- generate diverse cell types across organs. These systems evolveunder influences such as age, sex, diet, environmental exposures, and diseases,making them challenging to decode given the involvement of tens of thousands ofgenes and proteins. Recently, hundreds of millions of single-cell omics datahave provided a robust foundation for understanding these signaling networkswithin various cell subpopulations and conditions. Inspired by the success oflarge foundation models (for example, large language models and large visionmodels) pre-trained on massive datasets, we introduce OmniCellTOSG, the firstdataset of cell text-omic signaling graphs (TOSGs). Each TOSG represents thesignaling network of an individual or meta-cell and is labeled with informationsuch as organ, disease, sex, age, and cell subtype. OmniCellTOSG offers two keycontributions. First, it introduces a novel graph model that integrateshuman-readable annotations -- such as biological functions, cellular locations,signaling pathways, related diseases, and drugs -- with quantitative gene andprotein abundance data, enabling graph reasoning to decode cell signaling. Thisapproach calls for new joint models combining large language models and graphneural networks. Second, the dataset is built from single-cell RNA sequencingdata of approximately 120 million cells from diverse tissues and conditions(healthy and diseased) and is fully compatible with PyTorch. This facilitatesthe development of innovative cell signaling models that could transformresearch in life sciences, healthcare, and precision medicine. The OmniCellTOSGdataset is continuously expanding and will be updated regularly. The datasetand code are available at https://github.com/FuhaiLiAiLab/OmniCellTOSG.</description>
      <author>example@mail.com (Heming Zhang, Tim Xu, Dekang Cao, Shunning Liang, Lars Schimmelpfennig, Levi Kaster, Di Huang, Carlos Cruchaga, Guangfu Li, Michael Province, Yixin Chen, Philip Payne, Fuhai Li)</author>
      <guid isPermaLink="false">2504.02148v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>LL4G: Self-Supervised Dynamic Optimization for Graph-Based Personality Detection</title>
      <link>http://arxiv.org/abs/2504.02146v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为LL4G的基于图的个性检测方法，该方法通过利用大型语言模型（LLMs）优化图神经网络（GNNs）来自动适应性地处理文本数据，尤其是在社交媒体帖子中提取的图结构。该方法通过整合语义和结构信息，生成鲁棒的个性轮廓。&lt;h4&gt;背景&lt;/h4&gt;现有方法在处理稀疏或噪声数据时存在困难，且通常依赖于静态图，这限制了它们捕捉节点间关系动态变化的能力。&lt;h4&gt;目的&lt;/h4&gt;提出LL4G框架，以提高基于图的个性检测的准确性和适应性。&lt;h4&gt;方法&lt;/h4&gt;LL4G利用LLMs提取语义特征以生成节点表示和推断关系。图结构根据输入数据自适应地添加节点和边，并持续优化。GNN使用这些优化的表示进行节点重构、边预测和对比学习任务的联合训练。&lt;h4&gt;主要发现&lt;/h4&gt;在Kaggle和Pandora数据集上的实验结果表明，LL4G在性能上优于现有模型。&lt;h4&gt;结论&lt;/h4&gt;LL4G通过结合语义和结构信息，为基于图的个性检测提供了一种有效的方法，并在实际数据集上表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Graph-based personality detection constructs graph structures from textual data, particularly social media posts. Current methods often struggle with sparse or noisy data and rely on static graphs, limiting their ability to capture dynamic changes between nodes and relationships. This paper introduces LL4G, a self-supervised framework leveraging large language models (LLMs) to optimize graph neural networks (GNNs). LLMs extract rich semantic features to generate node representations and to infer explicit and implicit relationships. The graph structure adaptively adds nodes and edges based on input data, continuously optimizing itself. The GNN then uses these optimized representations for joint training on node reconstruction, edge prediction, and contrastive learning tasks. This integration of semantic and structural information generates robust personality profiles. Experimental results on Kaggle and Pandora datasets show LL4G outperforms state-of-the-art models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-based personality detection constructs graph structures from textualdata, particularly social media posts. Current methods often struggle withsparse or noisy data and rely on static graphs, limiting their ability tocapture dynamic changes between nodes and relationships. This paper introducesLL4G, a self-supervised framework leveraging large language models (LLMs) tooptimize graph neural networks (GNNs). LLMs extract rich semantic features togenerate node representations and to infer explicit and implicit relationships.The graph structure adaptively adds nodes and edges based on input data,continuously optimizing itself. The GNN then uses these optimizedrepresentations for joint training on node reconstruction, edge prediction, andcontrastive learning tasks. This integration of semantic and structuralinformation generates robust personality profiles. Experimental results onKaggle and Pandora datasets show LL4G outperforms state-of-the-art models.</description>
      <author>example@mail.com (Lingzhi Shen, Yunfei Long, Xiaohao Cai, Guanming Chen, Yuhan Wang, Imran Razzak, Shoaib Jameel)</author>
      <guid isPermaLink="false">2504.02146v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Instruction-Guided Autoregressive Neural Network Parameter Generation</title>
      <link>http://arxiv.org/abs/2504.02012v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了IGPG（指令引导的参数生成）框架，旨在通过统一参数合成，提高神经网络模型的可适应性和迁移学习能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基于扩散模型的方法在处理大型架构时存在可扩展性限制，处理不同网络深度时缺乏灵活性，且参数生成不连贯，影响了层间连贯性。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过IGPG框架，实现参数的统一生成，以提升模型在多种任务和架构下的适应性。&lt;h4&gt;方法&lt;/h4&gt;IGPG利用VQ-VAE和自回归模型，根据任务指令、数据集和架构细节生成神经网络参数，并通过自回归方式生成权重token，确保层间连贯性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，IGPG能够将多种预训练模型整合到一个灵活的生成框架中，生成的参数在性能上与现有方法相当甚至更优，尤其在大型架构的应用中表现出良好的可扩展性和效率。&lt;h4&gt;结论&lt;/h4&gt;IGPG作为一个强大的工具，在预训练权重检索、模型选择和快速特定任务微调方面具有巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：学习在任务描述和架构规范下生成神经网络参数对于推进模型适应性和迁移学习至关重要。现有方法，尤其是基于扩散模型的方法，在处理大型架构时存在可扩展性限制，处理不同网络深度时缺乏灵活性，并且参数生成不连贯，破坏了层间连贯性。在这项工作中，我们提出了IGPG（指令引导的参数生成），一个统一不同任务和架构参数合成的自回归框架。IGPG利用VQ-VAE和自回归模型，根据任务指令、数据集和架构细节生成神经网络参数。通过自回归地生成神经网络权重的token，IGPG确保了层间连贯性，并实现了模型和数据集之间的有效适应。在操作token级别，IGPG有效地捕捉了从广泛的预训练模型中聚合的复杂参数分布。在多个视觉数据集上的大量实验表明，IGPG将多种预训练模型整合到一个单一的灵活生成框架中。合成的参数在性能上与最先进的方法相当甚至更优，尤其是在应用于大型架构时的可扩展性和效率方面。这些结果强调了IGPG在预训练权重检索、模型选择和快速特定任务微调方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning to generate neural network parameters conditioned on taskdescriptions and architecture specifications is pivotal for advancing modeladaptability and transfer learning. Existing methods especially those based ondiffusion models suffer from limited scalability to large architectures,rigidity in handling varying network depths, and disjointed parametergeneration that undermines inter-layer coherence. In this work, we propose IGPG(Instruction Guided Parameter Generation), an autoregressive framework thatunifies parameter synthesis across diverse tasks and architectures. IGPGleverages a VQ-VAE and an autoregressive model to generate neural networkparameters, conditioned on task instructions, dataset, and architecturedetails. By autoregressively generating neural network weights' tokens, IGPGensures inter-layer coherence and enables efficient adaptation across modelsand datasets. Operating at the token level, IGPG effectively captures complexparameter distributions aggregated from a broad spectrum of pretrained models.Extensive experiments on multiple vision datasets demonstrate that IGPGconsolidates diverse pretrained models into a single, flexible generativeframework. The synthesized parameters achieve competitive or superiorperformance relative to state-of-the-art methods, especially in terms ofscalability and efficiency when applied to large architectures. These resultsunderscore ICPG potential as a powerful tool for pretrained weight retrieval,model selection, and rapid task-specific fine-tuning.</description>
      <author>example@mail.com (Soro Bedionita, Bruno Andreis, Song Chong, Sung Ju Hwang)</author>
      <guid isPermaLink="false">2504.02012v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Aligned Better, Listen Better for Audio-Visual Large Language Models</title>
      <link>http://arxiv.org/abs/2504.02061v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了音频在多模态视频理解中的重要性，提出了一个细粒度的视听语言模型Dolphin，并通过新的数据集AVU改善了音频信息的利用，提高了视频理解的准确性和减少了幻觉。&lt;h4&gt;背景&lt;/h4&gt;音频对于多模态视频理解至关重要，视频本身包含音频信息，而视频大语言模型（Video-LLMs）在许多以音频为中心的场景中面临挑战。&lt;h4&gt;目的&lt;/h4&gt;解决现有Video-LLMs和视听大语言模型（AV-LLMs）在利用音频信息方面的不足，提高视频理解的准确性和减少幻觉。&lt;h4&gt;方法&lt;/h4&gt;（1）从模型架构角度，提出了一个细粒度的AV-LLM，即Dolphin，通过同时考虑音频和视觉模态在时间和空间维度上的对齐。（2）从数据集角度，制作了一个视听字幕和指令微调数据集AVU，包含5.2百万个多样化的开放式数据元组（视频、音频、问题、答案），并引入了一种新的数据分区策略。&lt;h4&gt;主要发现&lt;/h4&gt;模型在视听理解方面取得了显著性能，同时减轻了潜在的幻觉。&lt;h4&gt;结论&lt;/h4&gt;通过改进模型架构和数据集，音频信息得到了更有效的利用，从而提高了视频理解的准确性和减少了幻觉。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio is essential for multimodal video understanding. On the one hand, videoinherently contains audio, which supplies complementary information to vision.Besides, video large language models (Video-LLMs) can encounter manyaudio-centric settings. However, existing Video-LLMs and Audio-Visual LargeLanguage Models (AV-LLMs) exhibit deficiencies in exploiting audio information,leading to weak understanding and hallucinations. To solve the issues, we delveinto the model architecture and dataset. (1) From the architecturalperspective, we propose a fine-grained AV-LLM, namely Dolphin. The concurrentalignment of audio and visual modalities in both temporal and spatialdimensions ensures a comprehensive and accurate understanding of videos.Specifically, we devise an audio-visual multi-scale adapter for multi-scaleinformation aggregation, which achieves spatial alignment. For temporalalignment, we propose audio-visual interleaved merging. (2) From the datasetperspective, we curate an audio-visual caption and instruction-tuning dataset,called AVU. It comprises 5.2 million diverse, open-ended data tuples (video,audio, question, answer) and introduces a novel data partitioning strategy.Extensive experiments show our model not only achieves remarkable performancein audio-visual understanding, but also mitigates potential hallucinations.</description>
      <author>example@mail.com (Yuxin Guo, Shuailei Ma, Shijie Ma, Xiaoyi Bao, Chen-Wei Xie, Kecheng Zheng, Tingyu Weng, Siyang Sun, Yun Zheng, Wei Zou)</author>
      <guid isPermaLink="false">2504.02061v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>MonoGS++: Fast and Accurate Monocular RGB Gaussian SLAM</title>
      <link>http://arxiv.org/abs/2504.02437v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MonoGS++的快速且精确的SLAM方法，该方法利用3D高斯表示，仅基于RGB输入。&lt;h4&gt;背景&lt;/h4&gt;之前的基于3D高斯散布（GS）的方法大多依赖于深度传感器。&lt;h4&gt;目的&lt;/h4&gt;减少硬件依赖，降低对RGB输入的依赖，并实现实时稀疏点云生成。&lt;h4&gt;方法&lt;/h4&gt;1. 引入动态3D高斯插入，避免在先前已良好重建的区域添加冗余高斯；2. 引入增强清晰度的高斯密集化模块和平面正则化，以更好地处理无纹理区域和平面。&lt;h4&gt;主要发现&lt;/h4&gt;在合成Replica和真实世界的TUM-RGBD数据集上实现了精确的相机跟踪结果，与最先进的方法相当。&lt;h4&gt;结论&lt;/h4&gt;与之前的最先进方法相比，MonoGS++实现了每秒帧数（fps）的显著提高，达到了5.57倍。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为MonoGS++的快速且精确的SLAM方法，该方法利用3D高斯表示，仅基于RGB输入。虽然之前基于3D高斯散布（GS）的方法在很大程度上依赖于深度传感器，但我们的方法减少了硬件依赖，并且只需RGB输入，利用在线视觉里程计（VO）在实时中生成稀疏点云。为了减少冗余并提高3D场景重建的质量，我们在3D高斯映射中实施了一系列方法学增强。首先，我们引入了动态3D高斯插入，以避免在先前已良好重建的区域添加冗余高斯。其次，我们引入了增强清晰度的高斯密集化模块和平面正则化，以更好地处理无纹理区域和平面。我们在合成Replica和真实世界的TUM-RGBD数据集上实现了精确的相机跟踪结果，与最先进的方法相当。此外，我们的方法实现了每秒帧数（fps）的显著提高，达到了5.57倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present MonoGS++, a novel fast and accurate Simultaneous Localization andMapping (SLAM) method that leverages 3D Gaussian representations and operatessolely on RGB inputs. While previous 3D Gaussian Splatting (GS)-based methodslargely depended on depth sensors, our approach reduces the hardware dependencyand only requires RGB input, leveraging online visual odometry (VO) to generatesparse point clouds in real-time. To reduce redundancy and enhance the qualityof 3D scene reconstruction, we implemented a series of methodologicalenhancements in 3D Gaussian mapping. Firstly, we introduced dynamic 3D Gaussianinsertion to avoid adding redundant Gaussians in previously well-reconstructedareas. Secondly, we introduced clarity-enhancing Gaussian densification moduleand planar regularization to handle texture-less areas and flat surfacesbetter. We achieved precise camera tracking results both on the syntheticReplica and real-world TUM-RGBD datasets, comparable to those of thestate-of-the-art. Additionally, our method realized a significant 5.57ximprovement in frames per second (fps) over the previous state-of-the-art,MonoGS.</description>
      <author>example@mail.com (Renwu Li, Wenjing Ke, Dong Li, Lu Tian, Emad Barsoum)</author>
      <guid isPermaLink="false">2504.02437v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>MageSQL: Enhancing In-context Learning for Text-to-SQL Applications with Large Language Models</title>
      <link>http://arxiv.org/abs/2504.02055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于上下文学习的文本到SQL的转换方法MageSQL，旨在提高LLMs在文本到SQL任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;文本到SQL问题旨在将自然语言问题转换为SQL语句，以简化数据库系统与最终用户之间的交互。近年来，大型语言模型（LLMs）在各种任务中表现出色，包括文本到SQL。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在构建提示时缺乏高质量上下文信息和缺乏鲁棒的反馈机制来纠正翻译错误的问题。&lt;h4&gt;方法&lt;/h4&gt;MageSQL通过探索一系列技术，利用SQL查询的语法和语义来识别相关的少量示例作为提示LLMs的上下文。特别地，引入了一种基于图对比学习的方法，该方法结合了SQL特定的数据增强策略。此外，还提出了一种错误纠正模块来检测和修复生成的SQL查询中的潜在不准确之处。&lt;h4&gt;主要发现&lt;/h4&gt;在多个基准数据集上进行了全面评估，结果表明，提出的方法在性能上明显优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;MageSQL在文本到SQL任务中取得了显著的性能提升，为LLMs在数据库交互中的应用提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;本文旨在将自然语言问题转化为SQL语句，以简化数据库系统与最终用户之间的交互。近期，大型语言模型在众多任务中表现出色，包括文本到SQL。然而，现有方法在构建提示时缺乏高质量上下文信息，且缺乏鲁棒的反馈机制来纠正翻译错误。为解决这些问题，本文提出了一种基于上下文学习的文本到SQL方法MageSQL。MageSQL利用SQL查询的语法和语义来识别相关的少量示例作为上下文，以提示LLMs。特别地，引入了基于图对比学习的方法，并结合了SQL特定的数据增强策略。此外，还提出了一个错误纠正模块来检测和修复生成的SQL查询中的潜在不准确之处。在多个基准数据集上进行的全面评估表明，本文提出的方法在性能上明显优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The text-to-SQL problem aims to translate natural language questions into SQLstatements to ease the interaction between database systems and end users.Recently, Large Language Models (LLMs) have exhibited impressive capabilitiesin a variety of tasks, including text-to-SQL. While prior works have exploredvarious strategies for prompting LLMs to generate SQL statements, they stillfall short of fully harnessing the power of LLM due to the lack of (1)high-quality contextual information when constructing the prompts and (2)robust feedback mechanisms to correct translation errors. To address thesechallenges, we propose MageSQL, a text-to-SQL approach based on in-contextlearning over LLMs. MageSQL explores a suite of techniques that leverage thesyntax and semantics of SQL queries to identify relevant few-shotdemonstrations as context for prompting LLMs. In particular, we introduce agraph-based demonstration selection method -- the first of its kind in thetext-to-SQL problem -- that leverages graph contrastive learning adapted withSQL-specific data augmentation strategies. Furthermore, an error correctionmodule is proposed to detect and fix potential inaccuracies in the generatedSQL query. We conduct comprehensive evaluations on several benchmarkingdatasets. The results show that our proposed methods outperformstate-of-the-art methods by an obvious margin.</description>
      <author>example@mail.com (Chen Shen, Jin Wang, Sajjadur Rahman, Eser Kandogan)</author>
      <guid isPermaLink="false">2504.02055v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Agglomerating Large Vision Encoders via Distillation for VFSS Segmentation</title>
      <link>http://arxiv.org/abs/2504.02351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种通过知识蒸馏从多个大型医学基础模型中提高低复杂度模型性能的新框架，旨在弥合医学图像分割任务的性能差距。&lt;h4&gt;背景&lt;/h4&gt;医学图像的基于基础模型的部署取得了显著成功，但它们的训练开销和推理复杂性仍然很高。&lt;h4&gt;目的&lt;/h4&gt;实现复杂性和性能之间的更好的权衡，提高低复杂度模型在医学图像分割任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;提出的新框架通过从多个大型医学基础模型中学习知识来改进低复杂度模型，这些基础模型在不同的视觉任务上各有专长。&lt;h4&gt;主要发现&lt;/h4&gt;聚类的模型在12个分割任务中表现出优异的泛化能力，而专用模型则需要为每个任务进行显式训练。该方法在Dice系数方面实现了平均2%的性能提升。&lt;h4&gt;结论&lt;/h4&gt;新框架能够有效提高医学图像分割任务的模型性能，并降低了模型的复杂性和推理开销。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The deployment of foundation models for medical imaging has demonstratedconsiderable success. However, their training overheads associated withdownstream tasks remain substantial due to the size of the image encodersemployed, and the inference complexity is also significantly high. Althoughlightweight variants have been obtained for these foundation models, theirperformance is constrained by their limited model capacity and suboptimaltraining strategies. In order to achieve an improved tradeoff betweencomplexity and performance, we propose a new framework to improve theperformance of low complexity models via knowledge distillation from multiplelarge medical foundation models (e.g., MedSAM, RAD-DINO, MedCLIP), eachspecializing in different vision tasks, with the goal to effectively bridge theperformance gap for medical image segmentation tasks. The agglomerated modeldemonstrates superior generalization across 12 segmentation tasks, whereasspecialized models require explicit training for each task. Our approachachieved an average performance gain of 2\% in Dice coefficient compared tosimple distillation.</description>
      <author>example@mail.com (Chengxi Zeng, Yuxuan Jiang, Fan Zhang, Alberto Gambaruto, Tilo Burghardt)</author>
      <guid isPermaLink="false">2504.02351v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>From Text to Graph: Leveraging Graph Neural Networks for Enhanced Explainability in NLP</title>
      <link>http://arxiv.org/abs/2504.02064v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的自然语言处理任务的可解释性方法，通过将句子自动转换为图，并利用节点和关系来维持语义，从而实现模型的可解释性。&lt;h4&gt;背景&lt;/h4&gt;自然语言处理任务通常使用Transformer型模型，尤其是生成模型，这些模型在执行生成和分类任务时表现出高 versatility。随着模型规模的增加，它们取得了出色的结果。然而，由于模型规模大，可解释性技术变得计算成本高昂，并且Transformer通过将输入信息分解为缺乏固有语义意义的序列来解释输入信息，这从一开始就增加了模型解释的复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过自动将句子转换为图，并利用节点和关系来维持语义，以实现自然语言处理任务的可解释性。&lt;h4&gt;方法&lt;/h4&gt;该方法通过自动将句子转换为图，并利用节点和关系来维持语义，使得模型的可解释性得以实现，并允许在后续任务中利用这些知识，从而理解模型如何将文本中的不同元素与解释的任务关联起来。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在确定给定分类的文本结构中最重要的组件方面具有前景。&lt;h4&gt;结论&lt;/h4&gt;该方法为自然语言处理任务的可解释性提供了一种新的思路，有助于理解模型的工作原理，并可能提高模型在实际应用中的可信度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Researchers have relegated natural language processing tasks toTransformer-type models, particularly generative models, because these modelsexhibit high versatility when performing generation and classification tasks.As the size of these models increases, they achieve outstanding results. Giventheir widespread use, many explainability techniques are developed based onthese models. However, this process becomes computationally expensive due tothe large size of the models. Additionally, transformers interpret inputinformation through tokens that fragment input words into sequences lackinginherent semantic meaning, complicating the explanation of the model from thevery beginning. This study proposes a novel methodology to achieveexplainability in natural language processing tasks by automatically convertingsentences into graphs and maintaining semantics through nodes and relationsthat express fundamental linguistic concepts. It also allows the subsequentexploitation of this knowledge in subsequent tasks, making it possible toobtain trends and understand how the model associates the different elementsinside the text with the explained task. The experiments delivered promisingresults in determining the most critical components within the text structurefor a given classification.</description>
      <author>example@mail.com (Fabio Yáñez-Romero, Andrés Montoyo, Armando Suárez, Yoan Gutiérrez, Ruslan Mitkov)</author>
      <guid isPermaLink="false">2504.02064v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>MinkOcc: Towards real-time label-efficient semantic occupancy prediction</title>
      <link>http://arxiv.org/abs/2504.02270v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MinkOcc的多模态3D语义占用预测框架，用于摄像头和激光雷达，通过半监督训练过程减少对密集3D标注的依赖。&lt;h4&gt;背景&lt;/h4&gt;开发3D语义占用预测模型通常依赖于密集的3D标注进行监督学习，这是一个既费时又费力的过程，强调了需要标签效率高甚至无标签的方法。&lt;h4&gt;目的&lt;/h4&gt;提出一种减少对人工标注依赖的3D语义占用预测方法，同时保持或提高预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;MinkOcc采用两步半监督训练程序：首先使用小数据集的明确3D标注启动训练过程，然后通过更容易标注的累积激光雷达扫描和图像（通过视觉基础模型进行语义标注）继续监督。&lt;h4&gt;主要发现&lt;/h4&gt;MinkOcc有效地利用了这些丰富的传感器监督线索，在保持竞争性准确性的同时，减少了90%的依赖性，并通过早期融合结合激光雷达和摄像头数据，利用稀疏卷积网络进行实时预测。&lt;h4&gt;结论&lt;/h4&gt;MinkOcc在监督和计算效率方面表现出色，旨在将MinkOcc扩展到精选数据集之外，以实现更广泛的自动驾驶中3D语义占用预测的实际应用。&lt;h4&gt;翻译&lt;/h4&gt;Developing 3D semantic occupancy prediction models often relies on dense 3D annotations for supervised learning, a process that is both labor and resource-intensive, underscoring the need for label-efficient or even label-free approaches. To address this, we introduce MinkOcc, a multi-modal 3D semantic occupancy prediction framework for cameras and LiDARs that proposes a two-step semi-supervised training procedure. Here, a small dataset of explicitly 3D annotations warm-starts the training process; then, the supervision is continued by simpler-to-annotate accumulated LiDAR sweeps and images -- semantically labelled through vision foundational models. MinkOcc effectively utilizes these sensor-rich supervisory cues and reduces reliance on manual labeling by 90% while maintaining competitive accuracy. In addition, the proposed model incorporates information from LiDAR and camera data through early fusion and leverages sparse convolution networks for real-time prediction. With its efficiency in both supervision and computation, we aim to extend MinkOcc beyond curated datasets, enabling broader real-world deployment of 3D semantic occupancy prediction in autonomous driving.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing 3D semantic occupancy prediction models often relies on dense 3Dannotations for supervised learning, a process that is both labor andresource-intensive, underscoring the need for label-efficient or evenlabel-free approaches. To address this, we introduce MinkOcc, a multi-modal 3Dsemantic occupancy prediction framework for cameras and LiDARs that proposes atwo-step semi-supervised training procedure. Here, a small dataset ofexplicitly 3D annotations warm-starts the training process; then, thesupervision is continued by simpler-to-annotate accumulated LiDAR sweeps andimages -- semantically labelled through vision foundational models. MinkOcceffectively utilizes these sensor-rich supervisory cues and reduces reliance onmanual labeling by 90\% while maintaining competitive accuracy. In addition,the proposed model incorporates information from LiDAR and camera data throughearly fusion and leverages sparse convolution networks for real-timeprediction. With its efficiency in both supervision and computation, we aim toextend MinkOcc beyond curated datasets, enabling broader real-world deploymentof 3D semantic occupancy prediction in autonomous driving.</description>
      <author>example@mail.com (Samuel Sze, Daniele De Martini, Lars Kunze)</author>
      <guid isPermaLink="false">2504.02270v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Geometric Reasoning in the Embedding Space</title>
      <link>http://arxiv.org/abs/2504.02018v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文展示了图神经网络和Transformer能够学习推理几何约束，能够从一组唯一描述包含这些点的隐藏图形的约束中预测点的空间位置。&lt;h4&gt;背景&lt;/h4&gt;研究背景是几何约束推理在图形神经网络和Transformer中的应用。&lt;h4&gt;目的&lt;/h4&gt;研究目的是探究图神经网络和Transformer在处理几何约束和预测点空间位置的能力。&lt;h4&gt;方法&lt;/h4&gt;通过训练模型从一组约束中预测点的空间位置，并观察模型在嵌入空间中形成的隐藏图形。&lt;h4&gt;主要发现&lt;/h4&gt;两种模型都能够预测点的位置，并在推理过程中在嵌入空间中形成由输入约束描述的隐藏图形。分析显示，两种模型在训练过程中恢复网格结构，使得网格内点的嵌入在二维子空间中组织，并反映了网格的邻域结构。设计的图神经网络在任务上表现优于Transformer，且更容易扩展。&lt;h4&gt;结论&lt;/h4&gt;图神经网络在处理几何约束和预测点空间位置方面表现优于Transformer，并且具有更好的可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this contribution, we demonstrate that Graph Neural Networks andTransformers can learn to reason about geometric constraints. We train them topredict spatial position of points in a discrete 2D grid from a set ofconstraints that uniquely describe hidden figures containing these points. Bothmodels are able to predict the position of points and interestingly, they formthe hidden figures described by the input constraints in the embedding spaceduring the reasoning process. Our analysis shows that both models recover thegrid structure during training so that the embeddings corresponding to thepoints within the grid organize themselves in a 2D subspace and reflect theneighborhood structure of the grid. We also show that the Graph Neural Networkwe design for the task performs significantly better than the Transformer andis also easier to scale.</description>
      <author>example@mail.com (Jan Hůla, David Mojžíšek, Jiří Janeček, David Herel, Mikoláš Janota)</author>
      <guid isPermaLink="false">2504.02018v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Digital-twin imaging based on descattering Gaussian splatting</title>
      <link>http://arxiv.org/abs/2504.02278v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于高斯分裂的数字孪生成像方法，用于观察散射介质背后的三维物体。&lt;h4&gt;背景&lt;/h4&gt;三维成像通过散射介质在医学和天文学中非常重要。&lt;h4&gt;目的&lt;/h4&gt;通过数字孪生模型，模拟散射介质背后的物体和环境变化，实现三维物体的再现。&lt;h4&gt;方法&lt;/h4&gt;构建数字孪生模型，使用由高斯点云组成的数据，通过卷积点扩散函数来模拟散射过程。&lt;h4&gt;主要发现&lt;/h4&gt;成功从退化图像中构建了一个高对比度的数字孪生三维物体，假设数据是由散射介质干扰的波前采集。&lt;h4&gt;结论&lt;/h4&gt;通过结合数据处理和图像测量，该技术可以再现物体。&lt;h4&gt;翻译&lt;/h4&gt;摘要：三维成像通过散射介质在医学和天文学中非常重要。我们提出了一种基于高斯分裂的数字孪生成像方法来观察散射介质背后的物体。通过数据同化构建的数字孪生模型，在虚拟空间中模拟物体和环境变化的行为。通过使用由高斯点云组成的点云构建数字孪生，并通过卷积点扩散函数模拟散射过程，可以再现散射介质背后的三维物体。在本研究中，成功从退化图像中构建了一个高对比度的数字孪生三维物体，假设数据是由散射介质干扰的波前采集。这种技术通过结合数据处理和图像测量来再现物体。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Three-dimensional imaging through scattering media is important in medicalscience and astronomy. We propose a digital-twin imaging method based onGaussian splatting to observe an object behind a scattering medium. A digitaltwin model built through data assimilation, emulates the behavior of objectsand environmental changes in a virtual space. By constructing a digital twinusing point clouds composed of Gaussians and simulating the scattering processthrough the convolution of a point spread function, three-dimensional objectsbehind a scattering medium can be reproduced as a digital twin. In this study,a high-contrast digital twin reproducing a three-dimensional object wassuccessfully constructed from degraded images, assuming that data were acquiredfrom wavefronts disturbed by a scattering medium. This technique reproducesobjects by integrating data processing with image measurements.</description>
      <author>example@mail.com (Suguru Shimomura, Kazuki Yamanouchi, Jun Tanida)</author>
      <guid isPermaLink="false">2504.02278v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Direction-Aware Hybrid Representation Learning for 3D Hand Pose and Shape Estimation</title>
      <link>http://arxiv.org/abs/2504.01298v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025 workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于模型的三维手姿态和形状估计方法，通过学习方向感知混合特征（DaHyF）来提高估计的准确性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的基于模型的三维手姿态和形状估计方法直接从图像中回归参数模型参数，但这种方法涉及到复杂的优化问题，存在许多局部最小值，使得训练困难。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的方法，旨在提高三维手姿态和形状估计的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出的方法包括学习方向感知混合特征（DaHyF），融合隐式图像特征和显式二维关节坐标特征，并利用相机坐标系中的像素方向信息来估计姿态、形状和相机视角。此外，方法还直接预测3D手姿态，并使用基于对比学习的预测置信度来减少运动捕捉过程中的抖动。&lt;h4&gt;主要发现&lt;/h4&gt;在FreiHAND数据集上评估了该方法，结果表明其准确率比现有最先进的方法高出33%以上。在HO3Dv2和HO3Dv3排行榜上，DaHyF在平均关节误差（经过缩放和平移对齐）的度量上取得了顶尖排名，与第二好的结果相比，最大的改进是10%。此外，该方法在具有手部位置变化、遮挡和运动模糊的真实时间运动捕捉场景中表现出了有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在三维手姿态和形状估计方面取得了显著的改进，提高了准确性和鲁棒性，并且在实际应用场景中表现良好。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most model-based 3D hand pose and shape estimation methods directly regressthe parametric model parameters from an image to obtain 3D joints under weaksupervision. However, these methods involve solving a complex optimizationproblem with many local minima, making training difficult. To address thischallenge, we propose learning direction-aware hybrid features (DaHyF) thatfuse implicit image features and explicit 2D joint coordinate features. Thisfusion is enhanced by the pixel direction information in the camera coordinatesystem to estimate pose, shape, and camera viewpoint. Our method directlypredicts 3D hand poses with DaHyF representation and reduces jittering duringmotion capture using prediction confidence based on contrastive learning. Weevaluate our method on the FreiHAND dataset and show that it outperformsexisting state-of-the-art methods by more than 33% in accuracy. DaHyF alsoachieves the top ranking on both the HO3Dv2 and HO3Dv3 leaderboards for themetric of Mean Joint Error (after scale and translation alignment). Compared tothe second-best results, the largest improvement observed is 10%. We alsodemonstrate its effectiveness in real-time motion capture scenarios with handposition variability, occlusion, and motion blur.</description>
      <author>example@mail.com (Shiyong Liu, Zhihao Li, Xiao Tang, Jianzhuang Liu)</author>
      <guid isPermaLink="false">2504.01298v2</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Modality Tags for Enhanced Cross-Modal Video Retrieval</title>
      <link>http://arxiv.org/abs/2504.01591v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MAC-VR的新型视频检索方法，通过利用从基础模型自动提取的模态特定标签来增强视频检索。&lt;h4&gt;背景&lt;/h4&gt;视频检索需要将视觉内容与相应的自然语言描述进行对齐。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够提升视频检索效果的新方法。&lt;h4&gt;方法&lt;/h4&gt;在潜在空间中对齐模态，同时学习并对齐从视频及其对应字幕特征中提取的辅助潜在概念，以改善视觉和文本潜在概念的对齐，从而区分不同的概念。&lt;h4&gt;主要发现&lt;/h4&gt;在MSR-VTT、DiDeMo、TGIF、Charades和YouCook2五个数据集上进行了广泛的实验，结果表明模态特定标签提高了跨模态对齐，在三个数据集上优于现有最先进的方法，在其他两个数据集上表现相当或更好。&lt;h4&gt;结论&lt;/h4&gt;MAC-VR方法通过模态特定标签有效提升了视频检索的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video retrieval requires aligning visual content with corresponding naturallanguage descriptions. In this paper, we introduce Modality Auxiliary Conceptsfor Video Retrieval (MAC-VR), a novel approach that leverages modality-specifictags -- automatically extracted from foundation models -- to enhance videoretrieval. We propose to align modalities in a latent space, along withlearning and aligning auxiliary latent concepts, derived from the features of avideo and its corresponding caption. We introduce these auxiliary concepts toimprove the alignment of visual and textual latent concepts, and so are able todistinguish concepts from one other. We conduct extensive experiments on fivediverse datasets: MSR-VTT, DiDeMo, TGIF, Charades and YouCook2. Theexperimental results consistently demonstrate that modality-specific tagsimprove cross-modal alignment, outperforming current state-of-the-art methodsacross three datasets and performing comparably or better across the other two.</description>
      <author>example@mail.com (Adriano Fragomeni, Dima Damen, Michael Wray)</author>
      <guid isPermaLink="false">2504.01591v2</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>HCAF-DTA: drug-target binding affinity prediction with cross-attention fused hypergraph neural networks</title>
      <link>http://arxiv.org/abs/2504.02014v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为HCAF-DTA的药物-靶标关联预测模型，基于交叉注意力融合超图神经网络，用于提高药物与靶标蛋白结合亲和力的预测准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的深度学习方法往往忽略了药物分子的内部子结构特征和药物-靶标相互作用的信息，导致预测性能有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的药物-靶标关联预测模型，以提高药物与靶标蛋白结合亲和力的预测准确性。&lt;h4&gt;方法&lt;/h4&gt;模型创新性地在特征提取阶段引入超图表示：基于树分解算法构建药物分子超图，通过融合超图神经网络和图神经网络通过跳跃连接提取子结构和全局特征；对于蛋白质特征提取，基于ESM模型预测的接触图构建加权图，并使用多层图神经网络捕捉空间依赖性；在预测阶段，设计了双向多头交叉注意力机制，从原子和氨基酸的双重观点建模分子间相互作用，并通过注意力融合具有相关信息的跨模态特征。&lt;h4&gt;主要发现&lt;/h4&gt;在Davis和KIBA等基准数据集上的实验表明，HCAF-DTA在所有三个性能评估指标上都优于现有技术，MSE指标分别达到0.198和0.122，与最优基线相比提高了4%。&lt;h4&gt;结论&lt;/h4&gt;HCAF-DTA模型在药物与靶标蛋白结合亲和力预测方面具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;Accurate prediction of the binding affinity between drugs and target proteins is a core task in computer-aided drug design. Existing deep learning methods tend to ignore the information of internal sub-structural features of drug molecules and drug-target interactions, resulting in limited prediction performance. In this paper, we propose a drug-target association prediction model HCAF-DTA based on cross-attention fusion hypergraph neural network. The model innovatively introduces hypergraph representation in the feature extraction stage: drug molecule hypergraphs are constructed based on the tree decomposition algorithm, and the sub-structural and global features extracted by fusing the hypergraph neural network with the graphical neural network through hopping connections, in which the hyper edges can efficiently characterise the functional functional groups and other key chemical features; for the protein feature extraction, a weighted graph is constructed based on the residues predicted by the ESM model contact maps to construct weighted graphs, and multilayer graph neural networks were used to capture spatial dependencies. In the prediction stage, a bidirectional multi-head cross-attention mechanism is designed to model intermolecular interactions from the dual viewpoints of atoms and amino acids, and cross-modal features with correlated information are fused by attention. Experiments on benchmark datasets such as Davis and KIBA show that HCAF-DTA outperforms state of the arts in all three performance evaluation metrics, with the MSE metrics reaching 0.198 and 0.122, respectively, with an improvement of up to 4% from the optimal baseline.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction of the binding affinity between drugs and target proteinsis a core task in computer-aided drug design. Existing deep learning methodstend to ignore the information of internal sub-structural features of drugmolecules and drug-target interactions, resulting in limited predictionperformance. In this paper, we propose a drug-target association predictionmodel HCAF-DTA based on cross-attention fusion hypergraph neural network. Themodel innovatively introduces hypergraph representation in the featureextraction stage: drug molecule hypergraphs are constructed based on the treedecomposition algorithm, and the sub-structural and global features extractedby fusing the hypergraph neural network with the graphical neural networkthrough hopping connections, in which the hyper edges can efficientlycharacterise the functional functional groups and other key chemical features;for the protein feature extraction, a weighted graph is constructed based onthe residues predicted by the ESM model contact maps to construct weightedgraphs, and multilayer graph neural networks were used to capture spatialdependencies. In the prediction stage, a bidirectional multi-headcross-attention mechanism is designed to model intermolecular interactions fromthe dual viewpoints of atoms and amino acids, and cross-modal features withcorrelated information are fused by attention. Experiments on benchmarkdatasets such as Davis and KIBA show that HCAF-DTA outperforms state of thearts in all three performance evaluation metrics, with the MSE metrics reaching0.198 and 0.122, respectively, with an improvement of up to 4% from the optimalbaseline.</description>
      <author>example@mail.com (Jiannuo Li, Lan Yao)</author>
      <guid isPermaLink="false">2504.02014v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Test-time Adaptation for Foundation Medical Segmentation Model without Parametric Updates</title>
      <link>http://arxiv.org/abs/2504.02008v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对MedSAM模型在特定复杂结构病变和边界框提示扰动下性能下降的问题的解决方案。&lt;h4&gt;背景&lt;/h4&gt;基础医学分割模型，如MedSAM，在器官和病变分割上表现出色，但在处理复杂结构和边界框提示扰动时性能不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高MedSAM在处理复杂病变时的性能，同时减少计算复杂度。&lt;h4&gt;方法&lt;/h4&gt;通过理论分析表明，直接优化图像嵌入可以像参数更新一样达到同样的目标，从而在不导致灾难性遗忘的情况下实现高效计算和分割性能。具体方法包括使用分布近似潜在条件随机场损失结合熵最小化损失来最大化后验预测概率。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在三个数据集上实现了约3%的Dice分数提升，同时计算复杂度降低了7倍以上。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高MedSAM在复杂病变分割上的性能，同时显著降低计算成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation medical segmentation models, with MedSAM being the most popular,have achieved promising performance across organs and lesions. However, MedSAMstill suffers from compromised performance on specific lesions with intricatestructures and appearance, as well as bounding box prompt-inducedperturbations. Although current test-time adaptation (TTA) methods for medicalimage segmentation may tackle this issue, partial (e.g., batch normalization)or whole parametric updates restrict their effectiveness due to limited updatesignals or catastrophic forgetting in large models. Meanwhile, these approachesignore the computational complexity during adaptation, which is particularlysignificant for modern foundation models. To this end, our theoretical analysesreveal that directly refining image embeddings is feasible to approach the samegoal as parametric updates under the MedSAM architecture, which enables us torealize high computational efficiency and segmentation performance without therisk of catastrophic forgetting. Under this framework, we propose to encouragemaximizing factorized conditional probabilities of the posterior predictionprobability using a proposed distribution-approximated latent conditionalrandom field loss combined with an entropy minimization loss. Experiments showthat we achieve about 3\% Dice score improvements across three datasets whilereducing computational complexity by over 7 times.</description>
      <author>example@mail.com (Kecheng Chen, Xinyu Luo, Tiexin Qin, Jie Liu, Hui Liu, Victor Ho Fun Lee, Hong Yan, Haoliang Li)</author>
      <guid isPermaLink="false">2504.02008v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Output Prediction of Quantum Circuits based on Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.00464v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNNs）的框架，用于预测量子电路在噪声和无噪声条件下的输出期望值，并比较不同参数化量子电路（PQCs）的性能。&lt;h4&gt;背景&lt;/h4&gt;量子电路的输出预测是开发量子设备的关键挑战。&lt;h4&gt;目的&lt;/h4&gt;通过自然图表示量子电路，提出一种基于GNNs的框架来预测量子电路的输出期望值，并比较不同PQCs的性能。&lt;h4&gt;方法&lt;/h4&gt;使用非参数化量子门集构建噪声和无噪声条件下的数据集，为GNNs设计节点特征向量以包含噪声信息。比较GNNs和卷积神经网络（CNNs）在相同数据集上的预测性能，并使用参数化量子门集构建噪声PQCs，利用变分量子本征求解器（VQE）计算氢分子的基态能量。提出了间接比较方案和直接比较方案来预测电路性能。&lt;h4&gt;主要发现&lt;/h4&gt;GNNs在各种条件下表现出优越的预测精度。直接比较方案比间接比较方案在相同数据集上平均提高了36.2%，为使用GNNs预测PQCs的整体性质提供了新的有效视角。&lt;h4&gt;结论&lt;/h4&gt;GNNs在预测量子电路输出期望值和比较PQCs性能方面具有显著优势，为量子计算领域提供了新的研究思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：量子电路的输出预测是开发量子设备的一项极具挑战性的任务。受量子电路自然图表示的启发，本文提出了一种基于图神经网络（GNNs）的框架，用于预测量子电路在噪声和无噪声条件下的输出期望值，并比较不同参数化量子电路（PQCs）的性能。我们使用非参数化量子门集在噪声和无噪声条件下构建数据集，以预测电路期望值。为GNNs设计的节点特征向量特别包含噪声信息。在我们的模拟中，我们比较了GNNs在噪声和无噪声条件下对同一数据集的预测性能与卷积神经网络（CNNs）及其量子比特可扩展性。GNNs在各种条件下表现出优越的预测精度。随后，我们利用参数化量子门集构建噪声PQCs，并使用变分量子本征求解器（VQE）计算氢分子的基态能量。我们提出了两种方案：间接比较方案，直接预测基态能量然后比较电路性能，以及直接比较方案，直接预测两个电路的相对性能。模拟结果表明，直接比较方案在相同数据集上平均比间接比较方案提高了36.2%，为使用GNNs预测PQCs的整体性质提供了新的有效视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The output prediction of quantum circuits is a formidably challenging taskimperative in developing quantum devices. Motivated by the natural graphrepresentation of quantum circuits, this paper proposes a Graph Neural Networks(GNNs)-based framework to predict the output expectation values of quantumcircuits under noisy and noiseless conditions and compare the performance ofdifferent parameterized quantum circuits (PQCs). We construct datasets undernoisy and noiseless conditions using a non-parameterized quantum gate set topredict circuit expectation values. The node feature vectors for GNNs arespecifically designed to include noise information. In our simulations, wecompare the prediction performance of GNNs in both noisy and noiselessconditions against Convolutional Neural Networks (CNNs) on the same dataset andtheir qubit scalability. GNNs demonstrate superior prediction accuracy acrossdiverse conditions. Subsequently, we utilize the parameterized quantum gate setto construct noisy PQCs and compute the ground state energy of hydrogenmolecules using the Variational Quantum Eigensolver (VQE). We propose twoschemes: the Indirect Comparison scheme, which involves directly predicting theground state energy and subsequently comparing circuit performances, and theDirect Comparison scheme, which directly predicts the relative performance ofthe two circuits. Simulation results indicate that the Direct Comparison schemesignificantly outperforms the Indirect Comparison scheme by an average of 36.2%on the same dataset, providing a new and effective perspective for using GNNsto predict the overall properties of PQCs, specifically by focusing on theirperformance differences.</description>
      <author>example@mail.com (Yuxiang Liu, Fanxu Meng, Lu Wang, Yi Hu, Zaichen Zhang, Xutao Yu)</author>
      <guid isPermaLink="false">2504.00464v2</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Reducing Smoothness with Expressive Memory Enhanced Hierarchical Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.00349v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HiGFlow的层次图流网络，用于时间序列数据的图形预测模型，通过动态大小的记忆缓冲变量存储不同分辨率变量间之前的信息，提高预测效果。&lt;h4&gt;背景&lt;/h4&gt;图形预测模型通过在图上投影时间序列数据来学习其结构，近年来，通过边权重捕捉变量间空间-时间关联的技术得到了发展。&lt;h4&gt;目的&lt;/h4&gt;HiGFlow旨在解决层次模型中信息丢失的问题，提高时间序列数据预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;HiGFlow引入了动态大小的记忆缓冲变量，用于存储跨变量分辨率的先前信息，并通过提高Weisfeiler-Lehman (WL) 表达性来增强消息传递的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;理论研究表明，HiGFlow在映射到层次结构中的新特征空间时减少了平滑度，并且通过改进WL表达性非严格地增强了消息传递的效用。&lt;h4&gt;结论&lt;/h4&gt;实证结果表明，HiGFlow在平均绝对误差（MAE）和均方根误差（RMSE）方面至少优于最先进的基线模型，包括transformer模型，平均分别提高了6.1%和6.2%。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Graphical forecasting models learn the structure of time series data via projecting onto a graph, with recent techniques capturing spatial-temporal associations between variables via edge weights. Hierarchical variants offer a distinct advantage by analysing the time series across multiple resolutions, making them particularly effective in tasks like global weather forecasting, where low-resolution variable interactions are significant. A critical challenge in hierarchical models is information loss during forward or backward passes through the hierarchy. We propose the Hierarchical Graph Flow (HiGFlow) network, which introduces a memory buffer variable of dynamic size to store previously seen information across variable resolutions. We theoretically show two key results: HiGFlow reduces smoothness when mapping onto new feature spaces in the hierarchy and non-strictly enhances the utility of message-passing by improving Weisfeiler-Lehman (WL) expressivity. Empirical results demonstrate that HiGFlow outperforms state-of-the-art baselines, including transformer models, by at least an average of 6.1% in MAE and 6.2% in RMSE. Code is available at https://github.com/TB862/HiGFlow.git.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphical forecasting models learn the structure of time series data viaprojecting onto a graph, with recent techniques capturing spatial-temporalassociations between variables via edge weights. Hierarchical variants offer adistinct advantage by analysing the time series across multiple resolutions,making them particularly effective in tasks like global weather forecasting,where low-resolution variable interactions are significant. A criticalchallenge in hierarchical models is information loss during forward or backwardpasses through the hierarchy. We propose the Hierarchical Graph Flow (HiGFlow)network, which introduces a memory buffer variable of dynamic size to storepreviously seen information across variable resolutions. We theoretically showtwo key results: HiGFlow reduces smoothness when mapping onto new featurespaces in the hierarchy and non-strictly enhances the utility ofmessage-passing by improving Weisfeiler-Lehman (WL) expressivity. Empiricalresults demonstrate that HiGFlow outperforms state-of-the-art baselines,including transformer models, by at least an average of 6.1% in MAE and 6.2% inRMSE. Code is available at https://github.com/TB862/ HiGFlow.git.</description>
      <author>example@mail.com (Thomas Bailie, Yun Sing Koh, S. Karthik Mukkavilli, Varvara Vetrova)</author>
      <guid isPermaLink="false">2504.00349v2</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>From Flatland to Space: Teaching Vision-Language Models to Perceive and Reason in 3D</title>
      <link>http://arxiv.org/abs/2503.22976v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://fudan-zvg.github.io/spar&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种通过利用空间相关图像数据来提升视觉语言模型（VLM）在空间感知方面的能力的方法，以解决VLM在处理复杂3D场景时存在的限制。&lt;h4&gt;背景&lt;/h4&gt;现有的VLM在处理空间感知方面仍有困难，限制了它们对复杂3D场景进行推理的能力。&lt;h4&gt;目的&lt;/h4&gt;旨在通过利用空间相关图像数据来提升VLM的空间感知能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一个基于场景数据和3D真实情况的2D空间数据生成和注释流程，并构建了大规模数据集SPAR-7M。同时，设计了SPAR-Bench基准，用于更全面地评估空间能力。&lt;h4&gt;主要发现&lt;/h4&gt;通过在SPAR-7M和大规模2D数据集上训练，模型在2D空间基准测试中达到了最先进的性能。在特定3D任务数据集上的进一步微调也取得了有竞争力的结果。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地提高了VLM的空间推理能力，为VLM在空间感知方面的应用提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in LVLMs have improved vision-language understanding, butthey still struggle with spatial perception, limiting their ability to reasonabout complex 3D scenes. Unlike previous approaches that incorporate 3Drepresentations into models to improve spatial understanding, we aim to unlockthe potential of VLMs by leveraging spatially relevant image data. To this end,we introduce a novel 2D spatial data generation and annotation pipeline builtupon scene data with 3D ground-truth. This pipeline enables the creation of adiverse set of spatial tasks, ranging from basic perception tasks to morecomplex reasoning tasks. Leveraging this pipeline, we construct SPAR-7M, alarge-scale dataset generated from thousands of scenes across multiple publicdatasets. In addition, we introduce SPAR-Bench, a benchmark designed to offer amore comprehensive evaluation of spatial capabilities compared to existingspatial benchmarks, supporting both single-view and multi-view inputs. Trainingon both SPAR-7M and large-scale 2D datasets enables our models to achievestate-of-the-art performance on 2D spatial benchmarks. Further fine-tuning on3D task-specific datasets yields competitive results, underscoring theeffectiveness of our dataset in enhancing spatial reasoning.</description>
      <author>example@mail.com (Jiahui Zhang, Yurui Chen, Yanpeng Zhou, Yueming Xu, Ze Huang, Jilin Mei, Junhui Chen, Yu-Jie Yuan, Xinyue Cai, Guowei Huang, Xingyue Quan, Hang Xu, Li Zhang)</author>
      <guid isPermaLink="false">2503.22976v2</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Real-Time Navigation for Autonomous Aerial Vehicles Using Video</title>
      <link>http://arxiv.org/abs/2504.01996v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Journal of Real-Time Image Processing&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于语义信息引导空间导航的方法，以简化自主导航系统中的几何3D点云构建和处理过程，并通过引入一种新的马尔可夫决策过程（MDP）框架来减轻计算机视觉（CV）算法的工作负担。&lt;h4&gt;背景&lt;/h4&gt;大多数使用车载相机的自主导航应用依赖于几何3D点云的构建和处理，这是一个成本较高的过程。同时，检测和利用语义信息（如交通标志）需要计算机视觉算法，这些算法对资源有限的无人机等设备来说是具有挑战性的。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来快速使空间可导航，并减少对资源有限设备的计算机视觉算法的需求。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新的MDP框架，并将其应用于基于特征和基于神经网络的物体检测任务，通过开环和闭环模拟以及硬件在环仿真进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法在能耗和速度方面具有显著优势，与基于静态特征和神经网络的模型相比，只牺牲了有限的准确性。&lt;h4&gt;结论&lt;/h4&gt;该研究证明，使用语义信息指导的自主导航系统可以通过减轻CV算法的负担来提高导航效率。&lt;h4&gt;翻译&lt;/h4&gt;Most applications in autonomous navigation using mounted cameras rely on the construction and processing of geometric 3D point clouds, which is an expensive process. However, there is another simpler way to make a space navigable quickly: to use semantic information (e.g., traffic signs) to guide the agent. However, detecting and acting on semantic information involves Computer Vision~(CV) algorithms such as object detection, which themselves are demanding for agents such as aerial drones with limited onboard resources. To solve this problem, we introduce a novel Markov Decision Process~(MDP) framework to reduce the workload of these CV approaches. We apply our proposed framework to both feature-based and neural-network-based object-detection tasks, using open-loop and closed-loop simulations as well as hardware-in-the-loop emulations. These holistic tests show significant benefits in energy consumption and speed with only a limited loss in accuracy compared to models based on static features and neural networks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most applications in autonomous navigation using mounted cameras rely on theconstruction and processing of geometric 3D point clouds, which is an expensiveprocess. However, there is another simpler way to make a space navigablequickly: to use semantic information (e.g., traffic signs) to guide the agent.However, detecting and acting on semantic information involves ComputerVision~(CV) algorithms such as object detection, which themselves are demandingfor agents such as aerial drones with limited onboard resources. To solve thisproblem, we introduce a novel Markov Decision Process~(MDP) framework to reducethe workload of these CV approaches. We apply our proposed framework to bothfeature-based and neural-network-based object-detection tasks, using open-loopand closed-loop simulations as well as hardware-in-the-loop emulations. Theseholistic tests show significant benefits in energy consumption and speed withonly a limited loss in accuracy compared to models based on static features andneural networks.</description>
      <author>example@mail.com (Khizar Anjum, Parul Pandey, Vidyasagar Sadhu, Roberto Tron, Dario Pompili)</author>
      <guid isPermaLink="false">2504.01996v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>A Concise Survey on Lane Topology Reasoning for HD Mapping</title>
      <link>http://arxiv.org/abs/2504.01989v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE IV'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文系统地回顾了车道拓扑推理技术的发展历程和当前状态，并对相关方法进行了分类。&lt;h4&gt;背景&lt;/h4&gt;车道拓扑推理技术在高清地图和自动驾驶应用中扮演着关键角色。&lt;h4&gt;目的&lt;/h4&gt;对车道拓扑推理方法进行综述，分析其发展过程，并探讨未来研究方向。&lt;h4&gt;方法&lt;/h4&gt;将方法分为三类：基于程序建模的方法、基于航空影像的方法和基于车载传感器的方法，并分析了从早期基于规则的方案到现代基于学习（如使用Transformer、图神经网络等深度学习架构）的解决方案的进步。&lt;h4&gt;主要发现&lt;/h4&gt;本文考察了标准化的评估指标，包括道路级别的指标（APLS和TLTS得分）和车道级别的指标（DET和TOP得分），并比较了在OpenLane-V2等基准数据集上的性能。&lt;h4&gt;结论&lt;/h4&gt;本文识别了关键技术挑战，如数据集可用性和模型效率，并概述了未来研究的潜在方向。为研究人员和从业者提供了关于高清地图应用中车道拓扑推理的理论框架、实际实施和新兴趋势的见解。&lt;h4&gt;翻译&lt;/h4&gt;Lane topology reasoning techniques play a crucial role in high-definition (HD) mapping and autonomous driving applications. While recent years have witnessed significant advances in this field, there has been limited effort to consolidate these works into a comprehensive overview. This survey systematically reviews the evolution and current state of lane topology reasoning methods, categorizing them into three major paradigms: procedural modeling-based methods, aerial imagery-based methods, and onboard sensors-based methods. We analyze the progression from early rule-based approaches to modern learning-based solutions utilizing transformers, graph neural networks (GNNs), and other deep learning architectures. The paper examines standardized evaluation metrics, including road-level measures (APLS and TLTS score), and lane-level metrics (DET and TOP score), along with performance comparisons on benchmark datasets such as OpenLane-V2. We identify key technical challenges, including dataset availability and model efficiency, and outline promising directions for future research. This comprehensive review provides researchers and practitioners with insights into the theoretical frameworks, practical implementations, and emerging trends in lane topology reasoning for HD mapping applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lane topology reasoning techniques play a crucial role in high-definition(HD) mapping and autonomous driving applications. While recent years havewitnessed significant advances in this field, there has been limited effort toconsolidate these works into a comprehensive overview. This surveysystematically reviews the evolution and current state of lane topologyreasoning methods, categorizing them into three major paradigms: proceduralmodeling-based methods, aerial imagery-based methods, and onboard sensors-basedmethods. We analyze the progression from early rule-based approaches to modernlearning-based solutions utilizing transformers, graph neural networks (GNNs),and other deep learning architectures. The paper examines standardizedevaluation metrics, including road-level measures (APLS and TLTS score), andlane-level metrics (DET and TOP score), along with performance comparisons onbenchmark datasets such as OpenLane-V2. We identify key technical challenges,including dataset availability and model efficiency, and outline promisingdirections for future research. This comprehensive review provides researchersand practitioners with insights into the theoretical frameworks, practicalimplementations, and emerging trends in lane topology reasoning for HD mappingapplications.</description>
      <author>example@mail.com (Yi Yao, Miao Fan, Shengtong Xu, Haoyi Xiong, Xiangzeng Liu, Wenbo Hu, Wenbing Huang)</author>
      <guid isPermaLink="false">2504.01989v1</guid>
      <pubDate>Fri, 04 Apr 2025 14:16:33 +0800</pubDate>
    </item>
    <item>
      <title>Spatiotemporal Attention Learning Framework for Event-Driven Object Recognition</title>
      <link>http://arxiv.org/abs/2504.00370v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2025 IEEE NSENS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于事件视觉传感器的新型时空学习框架，用于事件驱动的目标识别。&lt;h4&gt;背景&lt;/h4&gt;事件视觉传感器受到生物神经系统的启发，以异步方式捕获局部像素级别的强度变化，包含位置、极性和时间戳信息，具有动态范围、延迟和功耗等方面的优势。&lt;h4&gt;目的&lt;/h4&gt;设计一种高效的时空学习框架，用于基于事件视觉传感器的目标识别。&lt;h4&gt;方法&lt;/h4&gt;使用增强的VGG网络，结合卷积块注意力模块（CBAM），在减少参数数量的同时，达到与ResNet-based方法相当的性能。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在CIFAR10-DVS和N-Caltech101数据集上实现了76.4%和72.4%的最高Top-1准确率，无需预训练权重，降低了数据增强的依赖。&lt;h4&gt;结论&lt;/h4&gt;该框架在真实世界应用中展现出高效和有效的特性。&lt;h4&gt;翻译&lt;/h4&gt;Event-based vision sensors, inspired by biological neural systems, asynchronously capture local pixel-level intensity changes as a sparse eventstream containing position, polarity, and timestamp information. These neuromorphic sensors offer significant advantages in dynamic range, latency, and power efficiency. Their working principle inherently addresses traditional camera limitations such as motion blur and redundant background information, making them particularly suitable for dynamic vision tasks. While recent works have proposed increasingly complex event-based architectures, the computational overhead and parameter complexity of these approaches limit their practical deployment. This paper presents a novel spatiotemporal learning framework for event-based object recognition, utilizing a VGG network enhanced with Convolutional Block Attention Module (CBAM). Our approach achieves comparable performance to state-of-the-art ResNet-based methods while reducing parameter count by 2.3% compared to the original VGG model. Specifically, it outperforms ResNet-based methods like MVF-Net, achieving the highest Top-1 accuracy of 76.4% (pretrained) and 71.3% (not pretrained) on CIFAR10-DVS, and 72.4% (not pretrained) on N-Caltech101. These results highlight the robustness of our method when pretrained weights are not used, making it suitable for scenarios where transfer learning is unavailable. Moreover, our approach reduces reliance on data augmentation. Experimental results on standard event-based datasets demonstrate the framework's efficiency and effectiveness for real-world applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event-based vision sensors, inspired by biological neural systems,asynchronously capture local pixel-level intensity changes as a sparse eventstream containing position, polarity, and timestamp information. Theseneuromorphic sensors offer significant advantages in dynamic range, latency,and power efficiency. Their working principle inherently addresses traditionalcamera limitations such as motion blur and redundant background information,making them particularly suitable for dynamic vision tasks. While recent workshave proposed increasingly complex event-based architectures, the computationaloverhead and parameter complexity of these approaches limit their practicaldeployment. This paper presents a novel spatiotemporal learning framework forevent-based object recognition, utilizing a VGG network enhanced withConvolutional Block Attention Module (CBAM). Our approach achieves comparableperformance to state-of-the-art ResNet-based methods while reducing parametercount by 2.3% compared to the original VGG model. Specifically, it outperformsResNet-based methods like MVF-Net, achieving the highest Top-1 accuracy of76.4% (pretrained) and 71.3% (not pretrained) on CIFAR10-DVS, and 72.4% (notpretrained) on N-Caltech101. These results highlight the robustness of ourmethod when pretrained weights are not used, making it suitable for scenarioswhere transfer learning is unavailable. Moreover, our approach reduces relianceon data augmentation. Experimental results on standard event-based datasetsdemonstrate the framework's efficiency and effectiveness for real-worldapplications.</description>
      <author>example@mail.com (Tiantian Xie, Pengpai Wang, Rosa H. M. Chan)</author>
      <guid isPermaLink="false">2504.00370v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
  <item>
      <title>Learning from Streaming Video with Orthogonal Gradients</title>
      <link>http://arxiv.org/abs/2504.01961v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对从连续视频流中进行表示学习的挑战，提出了一种自监督学习方法，并展示了该方法在三个任务上的效果。&lt;h4&gt;背景&lt;/h4&gt;传统的视频学习方法在训练时会对视频进行剪辑和随机排列，以创建满足独立同分布（IID）样本假设的非冗余批次。然而，当视频仅以连续流的形式可用时，这种假设被打破，导致性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以解决从连续视频流中进行表示学习时性能下降的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种几何修改标准优化器的方法，通过在训练过程中利用正交梯度来解耦批次。该方法可以应用于任何优化器，并通过Stochastic Gradient Descent (SGD)和AdamW进行了演示。&lt;h4&gt;主要发现&lt;/h4&gt;在三个任务（DoRA、VideoMAE、未来视频预测）上，与随机排列学习相比，顺序学习导致了性能下降。提出的正交优化器能够减轻这种下降，并在所有三个场景中优于AdamW。&lt;h4&gt;结论&lt;/h4&gt;所提出的正交优化器能够提高从连续视频流中学习表示的性能，为后续任务提供了更好的模型。&lt;h4&gt;翻译&lt;/h4&gt;本文针对从连续视频流中进行表示学习的挑战，以自监督方式提出了一种解决方案。与传统的通过剪辑和随机排列视频进行训练的方法不同，本文提出的方法在训练过程中通过利用正交梯度来解耦批次，从而解决了连续视频流中IID假设被打破的问题。在DoRA、VideoMAE和未来视频预测三个任务上，本文提出的方法均优于标准AdamW优化器，表明了正交优化器在提高表示学习性能方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We address the challenge of representation learning from a continuous streamof video as input, in a self-supervised manner. This differs from the standardapproaches to video learning where videos are chopped and shuffled duringtraining in order to create a non-redundant batch that satisfies theindependently and identically distributed (IID) sample assumption expected byconventional training paradigms. When videos are only available as a continuousstream of input, the IID assumption is evidently broken, leading to poorperformance. We demonstrate the drop in performance when moving from shuffledto sequential learning on three tasks: the one-video representation learningmethod DoRA, standard VideoMAE on multi-video datasets, and the task of futurevideo prediction. To address this drop, we propose a geometric modification tostandard optimizers, to decorrelate batches by utilising orthogonal gradientsduring training. The proposed modification can be applied to any optimizer --we demonstrate it with Stochastic Gradient Descent (SGD) and AdamW. Ourproposed orthogonal optimizer allows models trained from streaming videos toalleviate the drop in representation learning performance, as evaluated ondownstream tasks. On three scenarios (DoRA, VideoMAE, future prediction), weshow our orthogonal optimizer outperforms the strong AdamW in all threescenarios.</description>
      <author>example@mail.com (Tengda Han, Dilara Gokay, Joseph Heyward, Chuhan Zhang, Daniel Zoran, Viorica Pătrăucean, João Carreira, Dima Damen, Andrew Zisserman)</author>
      <guid isPermaLink="false">2504.01961v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Deep Representation Learning for Unsupervised Clustering of Myocardial Fiber Trajectories in Cardiac Diffusion Tensor Imaging</title>
      <link>http://arxiv.org/abs/2504.01953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures. Submitted to MICCAI 2025 (under review)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新的深度学习框架，用于无监督聚类心肌纤维，通过识别不同的纤维束提供了一种数据驱动的方法。&lt;h4&gt;背景&lt;/h4&gt;理解复杂的心肌结构对于诊断和治疗心脏病至关重要，但现有方法在从DTI数据中准确捕捉这种复杂结构方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法来准确捕捉心肌纤维的复杂结构。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了双向长短期记忆网络来捕获纤维沿线的局部顺序信息，以及Transformer自动编码器来学习全局形状特征，同时结合了重要的解剖学背景。&lt;h4&gt;主要发现&lt;/h4&gt;使用基于密度的算法对这些表示进行聚类，可以识别出33到62个稳健的簇，成功捕捉到纤维轨迹的细微区别。&lt;h4&gt;结论&lt;/h4&gt;该框架提供了一种新的、灵活的、量化的方法来分析心肌结构，达到了前所未有的水平，并可能应用于改进手术规划、描述疾病相关的重塑以及最终推进个性化心脏病护理。&lt;h4&gt;翻译&lt;/h4&gt;Understanding the complex myocardial architecture is critical for diagnosing and treating heart disease. However, existing methods often struggle to accurately capture this intricate structure from Diffusion Tensor Imaging (DTI) data, particularly due to the lack of ground truth labels and the ambiguous, intertwined nature of fiber trajectories. We present a novel deep learning framework for unsupervised clustering of myocardial fibers, providing a data-driven approach to identifying distinct fiber bundles. We uniquely combine a Bidirectional Long Short-Term Memory network to capture local sequential information along fibers, with a Transformer autoencoder to learn global shape features, with pointwise incorporation of essential anatomical context. Clustering these representations using a density-based algorithm identifies 33 to 62 robust clusters, successfully capturing the subtle distinctions in fiber trajectories with varying levels of granularity. Our framework offers a new, flexible, and quantitative way to analyze myocardial structure, achieving a level of delineation that, to our knowledge, has not been previously achieved, with potential applications in improving surgical planning, characterizing disease-related remodeling, and ultimately, advancing personalized cardiac care.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the complex myocardial architecture is critical for diagnosingand treating heart disease. However, existing methods often struggle toaccurately capture this intricate structure from Diffusion Tensor Imaging (DTI)data, particularly due to the lack of ground truth labels and the ambiguous,intertwined nature of fiber trajectories. We present a novel deep learningframework for unsupervised clustering of myocardial fibers, providing adata-driven approach to identifying distinct fiber bundles. We uniquely combinea Bidirectional Long Short-Term Memory network to capture local sequentialinformation along fibers, with a Transformer autoencoder to learn global shapefeatures, with pointwise incorporation of essential anatomical context.Clustering these representations using a density-based algorithm identifies 33to 62 robust clusters, successfully capturing the subtle distinctions in fibertrajectories with varying levels of granularity. Our framework offers a new,flexible, and quantitative way to analyze myocardial structure, achieving alevel of delineation that, to our knowledge, has not been previously achieved,with potential applications in improving surgical planning, characterizingdisease-related remodeling, and ultimately, advancing personalized cardiaccare.</description>
      <author>example@mail.com (Mohini Anand, Xavier Tricoche)</author>
      <guid isPermaLink="false">2504.01953v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Robust Unsupervised Domain Adaptation for 3D Point Cloud Segmentation Under Source Adversarial Attacks</title>
      <link>http://arxiv.org/abs/2504.01659v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了无监督领域自适应（UDA）框架在3D点云语义分割模型上的鲁棒性，并提出了一种对抗适应框架（AAF）来应对对抗性攻击。&lt;h4&gt;背景&lt;/h4&gt;现有的UDA框架在处理干净数据时表现出良好的泛化能力，但在源域本身受到损害时，往往忽视了对抗鲁棒性问题。&lt;h4&gt;目的&lt;/h4&gt;全面探索UDA框架的鲁棒性，并提出一种有效的对抗适应框架。&lt;h4&gt;方法&lt;/h4&gt;1. 设计了一种隐蔽的对抗点云生成攻击，能通过轻微扰动点云表面显著污染数据集。2. 构建了新的数据集AdvSynLiDAR，包含合成的受污染的LiDAR点云。3. 开发了对抗适应框架（AAF），通过扩展关键点敏感（KPS）损失到鲁棒长尾损失（RLT损失），并利用解码器分支，使模型在预训练阶段关注长尾类别，在适应阶段利用高置信度解码点云信息来恢复点云结构。&lt;h4&gt;主要发现&lt;/h4&gt;在AdvSynLiDAR数据集上评估结果表明，AAF方法可以减轻源域对抗扰动对3D点云分割应用中UDA性能的下降。&lt;h4&gt;结论&lt;/h4&gt;提出的对抗适应框架（AAF）能够有效提升3D点云语义分割模型在对抗环境下的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;Unsupervised domain adaptation (UDA) frameworks have shown good generalization capabilities for 3D point cloud semantic segmentation models on clean data. However, existing works overlook adversarial robustness when the source domain itself is compromised. To comprehensively explore the robustness of the UDA frameworks, we first design a stealthy adversarial point cloud generation attack that can significantly contaminate datasets with only minor perturbations to the point cloud surface. Based on that, we propose a novel dataset, AdvSynLiDAR, comprising synthesized contaminated LiDAR point clouds. With the generated corrupted data, we further develop the Adversarial Adaptation Framework (AAF) as the countermeasure. Specifically, by extending the key point sensitive (KPS) loss towards the Robust Long-Tail loss (RLT loss) and utilizing a decoder branch, our approach enables the model to focus on long-tail classes during the pre-training phase and leverages high-confidence decoded point cloud information to restore point cloud structures during the adaptation phase. We evaluated our AAF method on the AdvSynLiDAR dataset, where the results demonstrate that our AAF method can mitigate performance degradation under source adversarial perturbations for UDA in the 3D point cloud segmentation application.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised domain adaptation (UDA) frameworks have shown goodgeneralization capabilities for 3D point cloud semantic segmentation models onclean data. However, existing works overlook adversarial robustness when thesource domain itself is compromised. To comprehensively explore the robustnessof the UDA frameworks, we first design a stealthy adversarial point cloudgeneration attack that can significantly contaminate datasets with only minorperturbations to the point cloud surface. Based on that, we propose a noveldataset, AdvSynLiDAR, comprising synthesized contaminated LiDAR point clouds.With the generated corrupted data, we further develop the AdversarialAdaptation Framework (AAF) as the countermeasure. Specifically, by extendingthe key point sensitive (KPS) loss towards the Robust Long-Tail loss (RLT loss)and utilizing a decoder branch, our approach enables the model to focus onlong-tail classes during the pre-training phase and leverages high-confidencedecoded point cloud information to restore point cloud structures during theadaptation phase. We evaluated our AAF method on the AdvSynLiDAR dataset, wherethe results demonstrate that our AAF method can mitigate performancedegradation under source adversarial perturbations for UDA in the 3D pointcloud segmentation application.</description>
      <author>example@mail.com (Haosheng Li, Yuecong Xu, Junjie Chen, Kemi Ding)</author>
      <guid isPermaLink="false">2504.01659v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Focal Mechanism Uncertainty Quantification In Ground Motion Simulations Of Le Teil Earthquake</title>
      <link>http://arxiv.org/abs/2504.01868v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究核电站（NPPs）地震安全，特别是依靠基础隔震来减少地震影响的基础设施。通过分析地震源参数的不确定性如何影响地面运动预测，探讨了地面运动预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;确保核电站的地震安全至关重要，特别是对于依赖基础隔震来减少地震影响的设施。地震响应的理解需要准确的模型来预测地面运动，这些地面运动通常对地震源参数（如震源机制，即走向、倾角和滑动角）等众多因素敏感。&lt;h4&gt;目的&lt;/h4&gt;研究地震源参数的不确定性如何影响地面运动预测。&lt;h4&gt;方法&lt;/h4&gt;基于SMATCH基准，使用谱元法进行了27次3D高保真数值模拟，每次模拟都包含了不同的震源机制变化。通过将模拟的地面运动与记录数据比较，使用了两种成熟的拟合优度标准：一种评估时频域特征，另一种关注地面运动信号的强度度量。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现震源机制的变异性对地面运动预测有显著影响，尤其是滑动角，它与波和强度度量显示出最强的相关性。&lt;h4&gt;结论&lt;/h4&gt;研究强调了震源机制变异性对地面运动预测的重要性，特别是在滑动角方面。&lt;h4&gt;翻译&lt;/h4&gt;本研究考察了这些参数的不确定性如何影响地面运动预测。分析基于SMATCH基准，该基准为评估法国Cruas-Meysse核电站2019年Mw 4.9 Le-Teil地震期间的地震响应提供了一种标准化的方法。通过谱元法进行了27次3D高保真数值模拟，每次模拟都包含了不同的震源机制变化。这些模拟为研究这次事件中观察到的异常地面运动背后的因素提供了一种有效的方法。为了量化不确定性，使用两种成熟的拟合优度标准将模拟的地面运动与记录数据进行了比较：一种评估时频域特征，另一种关注通过强度度量来表征地面运动信号。结果表明，震源机制变异性对地面运动预测有显著影响，尤其是滑动角，它与波和强度度量显示出最强的相关性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the seismic safety of nuclear power plants (NPPs) is essential,especially for facilities that rely on base isolation to reduce earthquakeimpacts. For understanding the seismic response, accurate models are key topredict the ground motions, which are generally sensitive to various factors,including earthquake source parameters like the focal mechanism, i.e., strike,dip, and rake angles. This study examines how uncertainties in these parametersaffect ground motion predictions. The analysis is based on the SMATCHbenchmark, which provides a standardized approach for evaluating the seismicresponse of the Cruas-Meysse NPP in France during the Mw 4.9 Le-Teil earthquakeof 2019. A set of 27 3D high-fidelity numerical simulations was performed usinga spectral-element method, each incorporating different focal mechanismvariations. These simulations provide an effective approach for investigatingthe factors behind the exceptional ground motion observed during this event. Toquantify uncertainty, the simulated ground motions were compared to recordeddata using two well-established goodness-of-fit criteria: one assessingtime-frequency domain characteristics and another focusing on thecharacterization of the ground motion signals by intensity measures. Resultshighlight the significant influence of focal mechanism variability on groundmotion predictions, especially on the rake angle, which showed the strongestcorrelation with wave and intensity measures.</description>
      <author>example@mail.com (Valeria Soto, Fernando Lopez-Caballero)</author>
      <guid isPermaLink="false">2504.01868v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Dual-stream Transformer-GCN Model with Contextualized Representations Learning for Monocular 3D Human Pose Estimation</title>
      <link>http://arxiv.org/abs/2504.01764v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于Transformer-GCN双流模型的上下文表示学习新方法，用于单目3D人体姿态估计。&lt;h4&gt;背景&lt;/h4&gt;单目3D人体姿态估计面临深度模糊、3D标注训练数据有限、模型建模不平衡和模型泛化能力受限等挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于上下文表示学习的创新运动预训练方法，以解决上述挑战。&lt;h4&gt;方法&lt;/h4&gt;方法包括掩码2D姿态特征，并使用Transformer-GCN双流模型通过自蒸馏设置学习高维表示。GCN流有效学习相邻关键点和帧之间的局部关系，而Transformer流捕获全局空间和时间特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在两个基准数据集上实现了最先进的性能，在Human3.6M上MPJPE为38.0mm，P-MPJPE为31.9mm；在MPI-INF-3DHP上MPJPE为15.9mm。&lt;h4&gt;结论&lt;/h4&gt;该方法在公共数据集和真实场景视频中表现出了鲁棒性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种基于Transformer-GCN双流模型的上下文表示学习新方法，用于单目3D人体姿态估计。单目3D人体姿态估计面临深度模糊、3D标注训练数据有限、模型建模不平衡和模型泛化能力受限等挑战。为了解决这些挑战，本文提出了一种基于上下文表示学习的创新运动预训练方法。具体方法包括掩码2D姿态特征，并使用Transformer-GCN双流模型通过自蒸馏设置学习高维表示。GCN流有效学习相邻关键点和帧之间的局部关系，而Transformer流捕获全局空间和时间特征。该方法在两个基准数据集上实现了最先进的性能，在Human3.6M上MPJPE为38.0mm，P-MPJPE为31.9mm；在MPI-INF-3DHP上MPJPE为15.9mm。此外，在公共数据集和真实场景视频中的可视化实验表明了该方法具有鲁棒性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a novel approach to monocular 3D human pose estimationusing contextualized representation learning with the Transformer-GCNdual-stream model. Monocular 3D human pose estimation is challenged by depthambiguity, limited 3D-labeled training data, imbalanced modeling, andrestricted model generalization. To address these limitations, our workintroduces a groundbreaking motion pre-training method based on contextualizedrepresentation learning. Specifically, our method involves masking 2D posefeatures and utilizing a Transformer-GCN dual-stream model to learnhigh-dimensional representations through a self-distillation setup. By focusingon contextualized representation learning and spatial-temporal modeling, ourapproach enhances the model's ability to understand spatial-temporalrelationships between postures, resulting in superior generalization.Furthermore, leveraging the Transformer-GCN dual-stream model, our approacheffectively balances global and local interactions in video pose estimation.The model adaptively integrates information from both the Transformer and GCNstreams, where the GCN stream effectively learns local relationships betweenadjacent key points and frames, while the Transformer stream capturescomprehensive global spatial and temporal features. Our model achievesstate-of-the-art performance on two benchmark datasets, with an MPJPE of 38.0mmand P-MPJPE of 31.9mm on Human3.6M, and an MPJPE of 15.9mm on MPI-INF-3DHP.Furthermore, visual experiments on public datasets and in-the-wild videosdemonstrate the robustness and generalization capabilities of our approach.</description>
      <author>example@mail.com (Mingrui Ye, Lianping Yang, Hegui Zhu, Zenghao Zheng, Xin Wang, Yantao Lo)</author>
      <guid isPermaLink="false">2504.01764v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Bridge 2D-3D: Uncertainty-aware Hierarchical Registration Network with Domain Alignment</title>
      <link>http://arxiv.org/abs/2504.01641v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AAAI2025accept&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对图像到点云配准的方法，通过创新设计，提高了配准的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;传统的图像到点云配准方法通常采用粗到细的流程确定刚体变换，但这种方法可能导致在匹配过程中关注错误的噪声区域，而忽略关键区域。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的配准方法，旨在提高图像和点云之间的匹配精度。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为UHMM的不确定性感知分层匹配模块和一种名为AMAM的对抗性模态对齐模块。UHMM通过建模图像补丁中关键信息的不确定性，促进图像和点云特征的多级融合交互；AMAM通过对抗性方法缩小图像和点云之间的域差距。&lt;h4&gt;主要发现&lt;/h4&gt;在RGB-D Scene V2和7-Scenes基准数据集上的广泛实验和消融研究表明，该方法在图像到点云配准任务中具有优越性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法是图像到点云配准任务中的最先进方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种图像到点云配准的方法，通常通过粗到细的流程确定刚体变换。然而，直接且均匀地匹配图像补丁和点云补丁可能会导致在匹配过程中关注错误的噪声补丁，而忽略关键补丁。此外，由于图像和点云模态之间的显著差异，没有特定设计改进可能难以弥合域差距。为了解决上述问题，我们创新性地提出了不确定性感知分层匹配模块（UHMM）和对抗性模态对齐模块（AMAM）。在UHMM中，我们模拟了图像补丁中关键信息的不确定性，并促进了图像和点云特征的多级融合交互。在AMAM中，我们设计了一种对抗性方法来缩小图像和点云之间的域差距。在RGB-D Scene V2和7-Scenes基准数据集上的广泛实验和消融研究表明，我们的方法具有优越性，使其成为图像到点云配准任务中的最先进方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The method for image-to-point cloud registration typically determines therigid transformation using a coarse-to-fine pipeline. However, directly anduniformly matching image patches with point cloud patches may lead to focusingon incorrect noise patches during matching while ignoring key ones. Moreover,due to the significant differences between image and point cloud modalities, itmay be challenging to bridge the domain gap without specific improvements indesign. To address the above issues, we innovatively propose theUncertainty-aware Hierarchical Matching Module (UHMM) and the Adversarial ModalAlignment Module (AMAM). Within the UHMM, we model the uncertainty of criticalinformation in image patches and facilitate multi-level fusion interactionsbetween image and point cloud features. In the AMAM, we design an adversarialapproach to reduce the domain gap between image and point cloud. Extensiveexperiments and ablation studies on RGB-D Scene V2 and 7-Scenes benchmarksdemonstrate the superiority of our method, making it a state-of-the-artapproach for image-to-point cloud registration tasks.</description>
      <author>example@mail.com (Zhixin Cheng, Jiacheng Deng, Xinjun Li, Baoqun Yin, Tianzhu Zhang)</author>
      <guid isPermaLink="false">2504.01641v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Slot-Level Robotic Placement via Visual Imitation from Single Human Video</title>
      <link>http://arxiv.org/abs/2504.01959v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的机器人学习方法，用于通过人类演示视频教授机器人重复性任务（如包装），并通过实验证明了该方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;当前大多数现代机器人学习方法集中在学习一组预定义的任务上，这些方法在处理新任务时普遍缺乏泛化能力。&lt;h4&gt;目的&lt;/h4&gt;通过人类演示视频，扩展机器人的技能集，使其能够学习新的重复性任务。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为SLeRP的模块化系统，该系统利用多个先进的视觉基础模型和一个新的槽级放置检测器Slot-Net，从而消除了昂贵视频演示的需求。&lt;h4&gt;主要发现&lt;/h4&gt;SLeRP在真实世界的视频数据集上进行了评估，结果表明其性能优于多个基线，并且可以在真实机器人上部署。&lt;h4&gt;结论&lt;/h4&gt;SLeRP能够有效地利用人类演示视频教授机器人新的重复性任务，为机器人学习提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;The majority of modern robot learning methods focus on learning a set of pre-defined tasks with limited or no generalization to new tasks. Extending the robot skillset to novel tasks involves gathering an extensive amount of training data for additional tasks. In this paper, we address the problem of teaching new tasks to robots using human demonstration videos for repetitive tasks (e.g., packing). This task requires understanding the human video to identify which object is being manipulated (the pick object) and where it is being placed (the placement slot). In addition, it needs to re-identify the pick object and the placement slots during inference along with the relative poses to enable robot execution of the task. To tackle this, we propose SLeRP, a modular system that leverages several advanced visual foundation models and an novel slot-level placement detector Slot-Net, eliminating the need for expensive video demonstrations for training. We evaluate our system using a new benchmark of real-world videos. The evaluation results show that SLeRP outperforms several baselines and can be deployed on a real robot.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The majority of modern robot learning methods focus on learning a set ofpre-defined tasks with limited or no generalization to new tasks. Extending therobot skillset to novel tasks involves gathering an extensive amount oftraining data for additional tasks. In this paper, we address the problem ofteaching new tasks to robots using human demonstration videos for repetitivetasks (e.g., packing). This task requires understanding the human video toidentify which object is being manipulated (the pick object) and where it isbeing placed (the placement slot). In addition, it needs to re-identify thepick object and the placement slots during inference along with the relativeposes to enable robot execution of the task. To tackle this, we propose SLeRP,a modular system that leverages several advanced visual foundation models and anovel slot-level placement detector Slot-Net, eliminating the need forexpensive video demonstrations for training. We evaluate our system using a newbenchmark of real-world videos. The evaluation results show that SLeRPoutperforms several baselines and can be deployed on a real robot.</description>
      <author>example@mail.com (Dandan Shan, Kaichun Mo, Wei Yang, Yu-Wei Chao, David Fouhey, Dieter Fox, Arsalan Mousavian)</author>
      <guid isPermaLink="false">2504.01959v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>ProtoGuard-guided PROPEL: Class-Aware Prototype Enhancement and Progressive Labeling for Incremental 3D Point Cloud Segmentation</title>
      <link>http://arxiv.org/abs/2504.01648v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ProtoGuard和PROPEL的3D点云语义分割技术，用于解决在线训练模型中灾难性遗忘的问题，并有效处理类间相似度高、边界不清以及类别分布不平衡的问题。&lt;h4&gt;背景&lt;/h4&gt;3D点云语义分割技术在现实场景中应用广泛，但环境不断变化可能导致离线训练的模型出现灾难性遗忘，而现有的类增量学习（CIL）方法未能有效解决这些问题。&lt;h4&gt;目的&lt;/h4&gt;提出ProtoGuard和PROPEL算法，以解决CIL方法中未解决的相似类误分类和长尾问题。&lt;h4&gt;方法&lt;/h4&gt;在基础类训练阶段，ProtoGuard通过注意力机制维护每个类的几何和语义原型，并形成原型特征。在新型类训练阶段，PROPEL继承基础特征提取器和分类器，基于密度分布和语义相似性引导伪标签的传播和更新。&lt;h4&gt;主要发现&lt;/h4&gt;在S3DIS和ScanNet数据集上进行的实验表明，该方法在5步CIL场景下将3D点云分割的mIoU提高了最多20.39%。&lt;h4&gt;结论&lt;/h4&gt;ProtoGuard和PROPEL算法能够有效提高3D点云语义分割的性能，特别是在处理类间相似度高、边界不清以及类别分布不平衡的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D point cloud semantic segmentation technology has been widely used.However, in real-world scenarios, the environment is evolving. Thus,offline-trained segmentation models may lead to catastrophic forgetting ofpreviously seen classes. Class-incremental learning (CIL) is designed toaddress the problem of catastrophic forgetting. While point clouds are common,we observe high similarity and unclear boundaries between different classes.Meanwhile, they are known to be imbalanced in class distribution. These lead toissues including misclassification between similar classes and the long-tailproblem, which have not been adequately addressed in previous CIL methods. Wethus propose ProtoGuard and PROPEL (Progressive Refinement Of PsEudo-Labels).In the base-class training phase, ProtoGuard maintains geometric and semanticprototypes for each class, which are combined into prototype features using anattention mechanism. In the novel-class training phase, PROPEL inherits thebase feature extractor and classifier, guiding pseudo-label propagation andupdates based on density distribution and semantic similarity. Extensiveexperiments show that our approach achieves remarkable results on both theS3DIS and ScanNet datasets, improving the mIoU of 3D point cloud segmentationby a maximum of 20.39% under the 5-step CIL scenario on S3DIS.</description>
      <author>example@mail.com (Haosheng Li, Yuecong Xu, Junjie Chen, Kemi Ding)</author>
      <guid isPermaLink="false">2504.01648v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>UniViTAR: Unified Vision Transformer with Native Resolution</title>
      <link>http://arxiv.org/abs/2504.01792v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的视觉基础模型UniViTAR，用于解决传统视觉Transformer在标准化输入分辨率时忽视自然视觉数据变异性及空间上下文准确性的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的视觉Transformer通过标准化输入分辨率简化视觉建模，但这种方法忽略了自然视觉数据的变异性，并可能牺牲空间上下文的准确性。&lt;h4&gt;目的&lt;/h4&gt;提出UniViTAR，以解决现有方法在视觉表示方面的系统性分析不足的问题。&lt;h4&gt;方法&lt;/h4&gt;UniViTAR通过以下方式实现：1）对原始范式进行架构升级，整合多个高级组件；2）引入渐进式训练范式，结合分辨率课程学习和视觉模式适应机制；3）采用混合训练框架，结合sigmoid对比损失和从冻结教师模型的特征蒸馏。&lt;h4&gt;主要发现&lt;/h4&gt;UniViTAR通过上述方法，实现了从固定分辨率预训练到原生分辨率调整的过渡，并提高了计算效率和时序推理能力。&lt;h4&gt;结论&lt;/h4&gt;在公共数据集上进行的广泛实验表明，UniViTAR在多个模型规模（从0.3B到1B）上均显示出其有效性。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Conventional Vision Transformer simplifies visual modeling by standardizing input resolutions, often disregarding the variability of natural visual data and compromising spatial-contextual fidelity. While preliminary explorations have superficially investigated native resolution modeling, existing approaches still lack systematic analysis from a visual representation perspective. To bridge this gap, we introduce UniViTAR, a family of homogeneous vision foundation models tailored for unified visual modality and native resolution scenario in the era of multimodal. Our framework first conducts architectural upgrades to the vanilla paradigm by integrating multiple advanced components. Building upon these improvements, a progressive training paradigm is introduced, which strategically combines two core mechanisms: (1) resolution curriculum learning, transitioning from fixed-resolution pretraining to native resolution tuning, thereby leveraging ViT's inherent adaptability to variable-length sequences, and (2) visual modality adaptation via inter-batch image-video switching, which balances computational efficiency with enhanced temporal reasoning. In parallel, a hybrid training framework further synergizes sigmoid-based contrastive loss with feature distillation from a frozen teacher model, thereby accelerating early-stage convergence. Finally, trained exclusively on public datasets, extensive experiments across multiple model scales from 0.3B to 1B demonstrate its effectiveness.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conventional Vision Transformer simplifies visual modeling by standardizinginput resolutions, often disregarding the variability of natural visual dataand compromising spatial-contextual fidelity. While preliminary explorationshave superficially investigated native resolution modeling, existing approachesstill lack systematic analysis from a visual representation perspective. Tobridge this gap, we introduce UniViTAR, a family of homogeneous visionfoundation models tailored for unified visual modality and native resolutionscenario in the era of multimodal. Our framework first conducts architecturalupgrades to the vanilla paradigm by integrating multiple advanced components.Building upon these improvements, a progressive training paradigm isintroduced, which strategically combines two core mechanisms: (1) resolutioncurriculum learning, transitioning from fixed-resolution pretraining to nativeresolution tuning, thereby leveraging ViT's inherent adaptability tovariable-length sequences, and (2) visual modality adaptation via inter-batchimage-video switching, which balances computational efficiency with enhancedtemporal reasoning. In parallel, a hybrid training framework further synergizessigmoid-based contrastive loss with feature distillation from a frozen teachermodel, thereby accelerating early-stage convergence. Finally, trainedexclusively on public datasets, externsive experiments across multiple modelscales from 0.3B to 1B demonstrate its effectiveness.</description>
      <author>example@mail.com (Limeng Qiao, Yiyang Gan, Bairui Wang, Jie Qin, Shuang Xu, Siqi Yang, Lin Ma)</author>
      <guid isPermaLink="false">2504.01792v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>A Retina-Inspired Pathway to Real-Time Motion Prediction inside Image Sensors for Extreme-Edge Intelligence</title>
      <link>http://arxiv.org/abs/2504.01275v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种受视网膜启发的神经形态框架，能够在相机像素级别直接执行实时、节能的运动预测。&lt;h4&gt;背景&lt;/h4&gt;动物在生存过程中，如攻击和逃避反应等关键行为，需要实时预测运动。同样，利用计算机视觉的自主系统也能从实时运动预测能力中受益。&lt;h4&gt;目的&lt;/h4&gt;为了在计算机视觉应用中实现实时运动预测，本研究旨在提出一种直接在相机像素级别进行运动预测的方法。&lt;h4&gt;方法&lt;/h4&gt;本研究采用GlobalFoundries 22nm FDSOI技术实现硬件算法框架，集成了视网膜运动预测的关键计算模块，包括双相滤波器、脉冲累加器、非线性电路和用于多方向运动预测的二维阵列。此外，通过3D Cu-Cu混合键合方法将传感器和运动预测计算芯片集成，以最小化面积使用并简化布线复杂性。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在真实世界物体刺激下验证有效，为依赖于预测视觉计算的决策场景提供了高效、低延迟的运动预测，同时硬件实现中每次运动预测的功耗仅为18.56 pJ。&lt;h4&gt;结论&lt;/h4&gt;该视网膜启发的神经形态框架为计算机视觉中的实时运动预测提供了一种高效、节能的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to predict motion in real time is fundamental to many maneuveringactivities in animals, particularly those critical for survival, such as attackand escape responses. Given its significance, it is no surprise that motionprediction in animals begins in the retina. Similarly, autonomous systemsutilizing computer vision could greatly benefit from the capability to predictmotion in real time. Therefore, for computer vision applications, motionprediction should be integrated directly at the camera pixel level. Towardsthat end, we present a retina-inspired neuromorphic framework capable ofperforming real-time, energy-efficient MP directly within camera pixels. Ourhardware-algorithm framework, implemented using GlobalFoundries 22nm FDSOItechnology, integrates key retinal MP compute blocks, including a biphasicfilter, spike adder, nonlinear circuit, and a 2D array for multi-directionalmotion prediction. Additionally, integrating the sensor and MP compute dieusing a 3D Cu-Cu hybrid bonding approach improves design compactness byminimizing area usage and simplifying routing complexity. Validated onreal-world object stimuli, the model delivers efficient, low-latency MP fordecision-making scenarios reliant on predictive visual computation, whileconsuming only 18.56 pJ/MP in our mixed-signal hardware implementation.</description>
      <author>example@mail.com (Subhradip Chakraborty, Shay Snyder, Md Abdullah-Al Kaiser, Maryam Parsa, Gregory Schwartz, Akhilesh R. Jaiswal)</author>
      <guid isPermaLink="false">2504.01275v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Direction-Aware Hybrid Representation Learning for 3D Hand Pose and Shape Estimation</title>
      <link>http://arxiv.org/abs/2504.01298v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025 workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为DaHyF的3D手部姿态和形状估计方法，通过融合隐式图像特征和显式2D关节坐标特征，并结合像素方向信息，有效地解决了传统方法中的优化难题，并在多个数据集上取得了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;传统的基于模型的手部姿态和形状估计方法直接从图像中回归参数模型参数，但这种方法涉及到解决具有许多局部极小值的复杂优化问题，使得训练变得困难。&lt;h4&gt;目的&lt;/h4&gt;为了解决传统方法的训练难题，提出了一种新的手部姿态和形状估计方法。&lt;h4&gt;方法&lt;/h4&gt;提出的方法名为DaHyF，它融合了隐式图像特征和显式2D关节坐标特征，并通过像素方向信息来估计姿态、形状和相机视角。该方法还利用对比学习来提高预测的置信度，从而减少运动捕捉过程中的抖动。&lt;h4&gt;主要发现&lt;/h4&gt;在FreiHAND数据集上，该方法在准确率上比现有最先进的方法提高了33%以上。在HO3Dv2和HO3Dv3排行榜上，DaHyF在平均关节误差（经过缩放和转换对齐）这一指标上取得了第一的成绩，与第二名的最大提升为10%。此外，该方法在实时运动捕捉场景中也表现出良好的效果，能够处理手部位置变化、遮挡和运动模糊等问题。&lt;h4&gt;结论&lt;/h4&gt;DaHyF是一种高效的手部姿态和形状估计方法，在多个数据集和场景中均表现出优异的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most model-based 3D hand pose and shape estimation methods directly regressthe parametric model parameters from an image to obtain 3D joints under weaksupervision. However, these methods involve solving a complex optimizationproblem with many local minima, making training difficult. To address thischallenge, we propose learning direction-aware hybrid features (DaHyF) thatfuse implicit image features and explicit 2D joint coordinate features. Thisfusion is enhanced by the pixel direction information in the camera coordinatesystem to estimate pose, shape, and camera viewpoint. Our method directlypredicts 3D hand poses with DaHyF representation and reduces jittering duringmotion capture using prediction confidence based on contrastive learning. Weevaluate our method on the FreiHAND dataset and show that it outperformsexisting state-of-the-art methods by more than 33% in accuracy. DaHyF alsoachieves the top ranking on both the HO3Dv2 and HO3Dv3 leaderboards for themetric of Mean Joint Error (after scale and translation alignment). Compared tothe second-best results, the largest improvement observed is 10%. We alsodemonstrate its effectiveness in real-time motion capture scenarios with handposition variability, occlusion, and motion blur.</description>
      <author>example@mail.com (Shiyong Liu, Zhihao Li, Xiao Tang, Jianzhuang Liu)</author>
      <guid isPermaLink="false">2504.01298v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>BlenderGym: Benchmarking Foundational Model Systems for Graphics Editing</title>
      <link>http://arxiv.org/abs/2504.01786v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025 Accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BlenderGym的综合视觉语言模型（VLM）系统基准，用于评估3D图形编辑中的VLM系统性能。&lt;h4&gt;背景&lt;/h4&gt;3D图形编辑在电影制作和游戏设计等领域至关重要，但这一过程耗时且需要高度专业的领域知识。自动化这一过程具有挑战性，因为图形编辑需要执行各种任务，每项任务都需要不同的技能集。&lt;h4&gt;目的&lt;/h4&gt;为了解决VLM系统开发与评估的瓶颈问题，该研究旨在提供一个全面的基准来评估VLM系统在3D图形编辑中的表现。&lt;h4&gt;方法&lt;/h4&gt;BlenderGym通过基于代码的3D重建任务来评估VLM系统。研究人员评估了封闭源和开源的VLM系统，并观察到即使是当前最先进的VLM系统在执行对人类Blender用户来说相对简单的任务时也遇到了困难。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，用于指导生成过程缩放的验证器本身可以通过推理缩放得到改进，这与关于LLM在编码和数学任务中推理缩放的最新见解相呼应。此外，推理计算的有效性并不均匀，可以通过在生成和验证之间战略性地分配来优化。&lt;h4&gt;结论&lt;/h4&gt;BlenderGym为研究推理缩放技术对VLM在图形编辑任务中性能的影响提供了平台，并揭示了推理计算优化的重要性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D图形编辑在电影制作和游戏设计等应用中至关重要，但这是一个耗时且需要高度专业领域知识的过程。自动化这一过程具有挑战性，因为图形编辑需要执行各种任务，每项任务都需要不同的技能集。最近，视觉语言模型（VLMs）已成为自动化编辑过程的有力框架，但其开发与评估受到缺乏全面基准的制约，该基准需要人类水平的感觉并呈现现实世界的编辑复杂性。在这项工作中，我们提出了BlenderGym，这是第一个用于3D图形编辑的综合VLM系统基准。BlenderGym通过基于代码的3D重建任务来评估VLM系统。我们评估了封闭源和开源的VLM系统，并观察到即使是当前最先进的VLM系统在执行对人类Blender用户来说相对简单的任务时也遇到了困难。通过BlenderGym，我们研究了推理缩放技术如何影响VLM在图形编辑任务中的性能。值得注意的是，我们的发现揭示了用于指导生成过程缩放的验证器本身可以通过推理缩放得到改进，这与关于LLM在编码和数学任务中推理缩放的最新见解相呼应。我们进一步表明，推理计算的有效性并不均匀，可以通过在生成和验证之间战略性地分配来优化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D graphics editing is crucial in applications like movie production and gamedesign, yet it remains a time-consuming process that demands highly specializeddomain expertise. Automating this process is challenging because graphicalediting requires performing a variety of tasks, each requiring distinct skillsets. Recently, vision-language models (VLMs) have emerged as a powerfulframework for automating the editing process, but their development andevaluation are bottlenecked by the lack of a comprehensive benchmark thatrequires human-level perception and presents real-world editing complexity. Inthis work, we present BlenderGym, the first comprehensive VLM system benchmarkfor 3D graphics editing. BlenderGym evaluates VLM systems through code-based 3Dreconstruction tasks. We evaluate closed- and open-source VLM systems andobserve that even the state-of-the-art VLM system struggles with tasksrelatively easy for human Blender users. Enabled by BlenderGym, we study howinference scaling techniques impact VLM's performance on graphics editingtasks. Notably, our findings reveal that the verifier used to guide the scalingof generation can itself be improved through inference scaling, complementingrecent insights on inference scaling of LLM generation in coding and mathtasks. We further show that inference compute is not uniformly effective andcan be optimized by strategically distributing it between generation andverification.</description>
      <author>example@mail.com (Yunqi Gu, Ian Huang, Jihyeon Je, Guandao Yang, Leonidas Guibas)</author>
      <guid isPermaLink="false">2504.01786v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Context-Aware Human Behavior Prediction Using Multimodal Large Language Models: Challenges and Insights</title>
      <link>http://arxiv.org/abs/2504.00839v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于预训练的多模态语言模型（MLLMs）的框架，用于在共享环境中预测人类行为，以提高人机交互的安全性和效率。&lt;h4&gt;背景&lt;/h4&gt;预测共享环境中的人类行为对于安全高效的人机交互至关重要。传统的基于数据驱动的方法在特定领域的数据集、活动类型和预测范围内进行预训练。&lt;h4&gt;目的&lt;/h4&gt;利用大型语言模型（LLMs）的突破，实现跨领域的开放式泛化，以描述各种人类活动并在任何环境中进行预测。&lt;h4&gt;方法&lt;/h4&gt;本文介绍了一个模块化的多模态人类活动预测框架，该框架允许我们基准测试各种MLLMs、输入变化、情境学习（ICL）和自回归技术。&lt;h4&gt;主要发现&lt;/h4&gt;评估结果表明，最佳框架配置在预测目标帧中的人类行为时，可以达到92.8%的语义相似度和66.1%的精确标签准确率。&lt;h4&gt;结论&lt;/h4&gt;预训练的MLLMs可以有效地用于情境感知的人类行为预测，为提高人机交互提供了新的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting human behavior in shared environments is crucial for safe andefficient human-robot interaction. Traditional data-driven methods to that endare pre-trained on domain-specific datasets, activity types, and predictionhorizons. In contrast, the recent breakthroughs in Large Language Models (LLMs)promise open-ended cross-domain generalization to describe various humanactivities and make predictions in any context. In particular, Multimodal LLMs(MLLMs) are able to integrate information from various sources, achieving morecontextual awareness and improved scene understanding. The difficulty inapplying general-purpose MLLMs directly for prediction stems from their limitedcapacity for processing large input sequences, sensitivity to prompt design,and expensive fine-tuning. In this paper, we present a systematic analysis ofapplying pre-trained MLLMs for context-aware human behavior prediction. To thisend, we introduce a modular multimodal human activity prediction framework thatallows us to benchmark various MLLMs, input variations, In-Context Learning(ICL), and autoregressive techniques. Our evaluation indicates that thebest-performing framework configuration is able to reach 92.8% semanticsimilarity and 66.1% exact label accuracy in predicting human behaviors in thetarget frame.</description>
      <author>example@mail.com (Yuchen Liu, Lino Lerch, Luigi Palmieri, Andrey Rudenko, Sebastian Koch, Timo Ropinski, Marco Aiello)</author>
      <guid isPermaLink="false">2504.00839v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>MergeVQ: A Unified Framework for Visual Generation and Representation with Disentangled Token Merging and Quantization</title>
      <link>http://arxiv.org/abs/2504.00999v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR2025 (in process for more analysis and extension)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MergeVQ是一种结合了向量量化（VQ）和标记合并技术的图像建模方法，它在自监督预训练和图像生成方面取得了成功。&lt;h4&gt;背景&lt;/h4&gt;现有的VQ方法在共享潜在空间中难以平衡生成质量、表示学习和效率之间的权衡。&lt;h4&gt;目的&lt;/h4&gt;提出MergeVQ，以提升VQ生成模型在图像生成和视觉表示学习方面的性能。&lt;h4&gt;方法&lt;/h4&gt;MergeVQ通过在编码器中的自注意力块之后使用标记合并模块来解耦top-k语义与潜在空间，通过解码器中的交叉注意力恢复细节。第二阶段生成引入了MergeAR，用于高效的栅格顺序预测。&lt;h4&gt;主要发现&lt;/h4&gt;在ImageNet上的实验表明，MergeVQ作为一个自动重放（AR）生成模型，在视觉表示学习和图像生成任务上实现了有竞争力的性能，同时保持了有利的标记效率和推理速度。&lt;h4&gt;结论&lt;/h4&gt;MergeVQ是一个高效且性能优越的图像生成和视觉表示学习方法，相关代码和模型将公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Masked Image Modeling (MIM) with Vector Quantization (VQ) has achieved greatsuccess in both self-supervised pre-training and image generation. However,most existing methods struggle to address the trade-off in shared latent spacefor generation quality vs. representation learning and efficiency. To push thelimits of this paradigm, we propose MergeVQ, which incorporates token mergingtechniques into VQ-based generative models to bridge the gap between imagegeneration and visual representation learning in a unified architecture. Duringpre-training, MergeVQ decouples top-k semantics from latent space with thetoken merge module after self-attention blocks in the encoder for subsequentLook-up Free Quantization (LFQ) and global alignment and recovers theirfine-grained details through cross-attention in the decoder for reconstruction.As for the second-stage generation, we introduce MergeAR, which performs KVCache compression for efficient raster-order prediction. Extensive experimentson ImageNet verify that MergeVQ as an AR generative model achieves competitiveperformance in both visual representation learning and image generation taskswhile maintaining favorable token efficiency and inference speed. The code andmodel will be available at https://apexgen-x.github.io/MergeVQ.</description>
      <author>example@mail.com (Siyuan Li, Luyuan Zhang, Zedong Wang, Juanxi Tian, Cheng Tan, Zicheng Liu, Chang Yu, Qingsong Xie, Haonan Lu, Haoqian Wang, Zhen Lei)</author>
      <guid isPermaLink="false">2504.00999v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>DecoFuse: Decomposing and Fusing the "What", "Where", and "How" for Brain-Inspired fMRI-to-Video Decoding</title>
      <link>http://arxiv.org/abs/2504.00432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DecoFuse是一种新型的基于脑启发框架，用于从fMRI信号中解码视频，它通过分解视频成分并分别解码，最后融合以重建视频。&lt;h4&gt;背景&lt;/h4&gt;现有的fMRI到视频的方法往往侧重于语义内容，而忽视了空间和运动信息，而这些方面对于视觉体验至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出DecoFuse，以解决从fMRI信号中解码视频的挑战，并提高解码的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;DecoFuse首先将视频分解为三个组件——语义、空间和运动，然后分别解码每个组件，最后将它们融合以重建视频。&lt;h4&gt;主要发现&lt;/h4&gt;DecoFuse在语义分类、空间一致性、运动预测和视频生成方面均优于现有方法，实现了82.4%的语义分类准确率，70.6%的空间一致性准确率，0.212的余弦相似度运动预测，以及21.9%的50种分类准确率。&lt;h4&gt;结论&lt;/h4&gt;DecoFuse提供了一个强大且生物学上合理的fMRI到视频解码框架。&lt;h4&gt;翻译&lt;/h4&gt;Decoding visual experiences from brain activity is a significant challenge. Existing fMRI-to-video methods often focus on semantic content while overlooking spatial and motion information. However, these aspects are all essential and are processed through distinct pathways in the brain. Motivated by this, we propose DecoFuse, a novel brain-inspired framework for decoding videos from fMRI signals. It first decomposes the video into three components - semantic, spatial, and motion - then decodes each component separately before fusing them to reconstruct the video. This approach not only simplifies the complex task of video decoding by decomposing it into manageable sub-tasks, but also establishes a clearer connection between learned representations and their biological counterpart, as supported by ablation studies. Further, our experiments show significant improvements over previous state-of-the-art methods, achieving 82.4% accuracy for semantic classification, 70.6% accuracy in spatial consistency, a 0.212 cosine similarity for motion prediction, and 21.9% 50-way accuracy for video generation. Additionally, neural encoding analyses for semantic and spatial information align with the two-streams hypothesis, further validating the distinct roles of the ventral and dorsal pathways. Overall, DecoFuse provides a strong and biologically plausible framework for fMRI-to-video decoding. Project page: https://chongjg.github.io/DecoFuse/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decoding visual experiences from brain activity is a significant challenge.Existing fMRI-to-video methods often focus on semantic content whileoverlooking spatial and motion information. However, these aspects are allessential and are processed through distinct pathways in the brain. Motivatedby this, we propose DecoFuse, a novel brain-inspired framework for decodingvideos from fMRI signals. It first decomposes the video into three components -semantic, spatial, and motion - then decodes each component separately beforefusing them to reconstruct the video. This approach not only simplifies thecomplex task of video decoding by decomposing it into manageable sub-tasks, butalso establishes a clearer connection between learned representations and theirbiological counterpart, as supported by ablation studies. Further, ourexperiments show significant improvements over previous state-of-the-artmethods, achieving 82.4% accuracy for semantic classification, 70.6% accuracyin spatial consistency, a 0.212 cosine similarity for motion prediction, and21.9% 50-way accuracy for video generation. Additionally, neural encodinganalyses for semantic and spatial information align with the two-streamshypothesis, further validating the distinct roles of the ventral and dorsalpathways. Overall, DecoFuse provides a strong and biologically plausibleframework for fMRI-to-video decoding. Project page:https://chongjg.github.io/DecoFuse/.</description>
      <author>example@mail.com (Chong Li, Jingyang Huo, Weikang Gong, Yanwei Fu, Xiangyang Xue, Jianfeng Feng)</author>
      <guid isPermaLink="false">2504.00432v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Q-Adapt: Adapting LMM for Visual Quality Assessment with Progressive Instruction Tuning</title>
      <link>http://arxiv.org/abs/2504.01655v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Q-Adapt的新范式，用于感知导向的指令调整，旨在解决现有方法在联合指令调整中忽视感知解释冲突的问题，从而提高图像质量评估的可解释性。&lt;h4&gt;背景&lt;/h4&gt;随着大型多模态基础模型（LMM）的快速发展，图像质量评估（IQA）的可解释性得到了新的可能性，包括整体质量解释和属性感知回答。&lt;h4&gt;目的&lt;/h4&gt;消除这两种类型感知解释之间的冲突，实现LMM在EIQA任务中的协同，以增强IQA的多方面解释。&lt;h4&gt;方法&lt;/h4&gt;Q-Adapt采用渐进式指令调整策略，将LMM的EIQA适应过程分为两个阶段：第一阶段通过使用LoRA（低秩自适应）等高效迁移学习策略，为两个任务赋予通用的感知知识；第二阶段引入指令自适应视觉提示调整，动态适应不同任务的视觉特征。&lt;h4&gt;主要发现&lt;/h4&gt;Q-Adapt实现了轻量级的视觉质量评估器，在感知相关基准和常用IQA数据库上展现出可比的性能，甚至在某些情况下优于其他方法。&lt;h4&gt;结论&lt;/h4&gt;Q-Adapt能够有效解决感知解释冲突，提高图像质量评估的可解释性，并在多个方面展现出优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大型多模态基础模型（LMM）的快速发展为指令调整下的可解释图像质量评估（EIQA）开辟了道路，从整体质量解释和属性感知回答两个角度进行。然而，现有工作通常忽视了这两种类型感知解释在联合指令调整中的冲突，导致感知理解不足。为了解决这个问题，我们提出了一种新的以感知为导向的指令调整范式，即Q-Adapt，旨在消除这两种EIQA任务之间的冲突，实现LMM适应时的协同，从而增强IQA的多方面解释。特别是，我们提出了一种渐进式指令调整策略，将LMM的EIQA适应过程分为两个阶段，第一阶段通过使用LoRA（低秩自适应）等高效迁移学习策略，为两个任务赋予通用的感知知识；第二阶段引入指令自适应视觉提示调整，动态适应不同任务的视觉特征。这样，我们提出的Q-Adapt可以实现轻量级的视觉质量评估器，在感知相关基准和常用IQA数据库上展现出可比的性能，甚至在某些情况下优于其他方法。源代码在https://github.com/yeppp27/Q-Adapt上公开。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of Large Multi-modal Foundation Models (LMM) has pavedthe way for the possible Explainable Image Quality Assessment (EIQA) withinstruction tuning from two perspectives: overall quality explanation, andattribute-wise perception answering. However, existing works usually overlookedthe conflicts between these two types of perception explanations during jointinstruction tuning, leading to insufficient perception understanding. Tomitigate this, we propose a new paradigm for perception-oriented instructiontuning, i.e., Q-Adapt, which aims to eliminate the conflicts and achieve thesynergy between these two EIQA tasks when adapting LMM, resulting in enhancedmulti-faceted explanations of IQA. Particularly, we propose a progressiveinstruction tuning strategy by dividing the adaption process of LMM for EIQAinto two stages, where the first stage empowers the LMM with universalperception knowledge tailored for two tasks using an efficient transferlearning strategy, i.e., LoRA, and the second stage introduces theinstruction-adaptive visual prompt tuning to dynamically adapt visual featuresfor the different instructions from two tasks. In this way, our proposedQ-Adapt can achieve a lightweight visual quality evaluator, demonstratingcomparable performance and, in some instances, superior results acrossperceptual-related benchmarks and commonly-used IQA databases. The source codeis publicly available at https://github.com/yeppp27/Q-Adapt.</description>
      <author>example@mail.com (Yiting Lu, Xin Li, Haoning Wu, Bingchen Li, Weisi Lin, Zhibo Chen)</author>
      <guid isPermaLink="false">2504.01655v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Global Intervention and Distillation for Federated Out-of-Distribution Generalization</title>
      <link>http://arxiv.org/abs/2504.00850v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对联邦学习中存在的属性偏差问题，提出了FedGID方法，旨在提升模型在未见数据上的表现。&lt;h4&gt;背景&lt;/h4&gt;属性偏差导致局部模型学习非因果关联，导致性能下降和收敛不稳定。&lt;h4&gt;目的&lt;/h4&gt;提出全局干预和蒸馏方法，以解决数据质量和领域信息不足的问题。&lt;h4&gt;方法&lt;/h4&gt;FedGID利用多样属性特征进行后门调整，包括两个主要模块：全局干预模块和全局蒸馏模块。全局干预模块自适应地分离图像中的对象和背景，注入背景信息以干预样本分布，防止模型将背景与标签关联视为因果关系。全局蒸馏模块利用统一的知识库指导客户端模型的表示学习，防止局部模型对客户端特定属性过拟合。&lt;h4&gt;主要发现&lt;/h4&gt;FedGID增强了模型在未见数据上关注主要主题的能力，并在协作建模中优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;FedGID方法有效提升了联邦学习模型的性能和稳定性。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we propose a global intervention and distillation method, FedGID, to address the attribute skew problem in federated learning, aiming to enhance the performance of models on unseen data. The method includes two main modules: a global intervention module and a global distillation module. The global intervention module adaptively decouples objects and backgrounds in images, injects background information into random samples to intervene in the sample distribution, and prevents the model from treating background-label associations as causal. The global distillation module leverages a unified knowledge base to guide the representation learning of client models, preventing local models from overfitting to client-specific attributes. Experimental results on three datasets demonstrate that FedGID enhances the model's ability to focus on the main subjects in unseen data and outperforms existing methods in collaborative modeling.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Attribute skew in federated learning leads local models to focus on learningnon-causal associations, guiding them towards inconsistent optimizationdirections, which inevitably results in performance degradation and unstableconvergence. Existing methods typically leverage data augmentation to enhancesample diversity or employ knowledge distillation to learn invariantrepresentations. However, the instability in the quality of generated data andthe lack of domain information limit their performance on unseen samples. Toaddress these issues, this paper presents a global intervention anddistillation method, termed FedGID, which utilizes diverse attribute featuresfor backdoor adjustment to break the spurious association between backgroundand label. It includes two main modules, where the global intervention moduleadaptively decouples objects and backgrounds in images, injects backgroundinformation into random samples to intervene in the sample distribution, whichlinks backgrounds to all categories to prevent the model from treatingbackground-label associations as causal. The global distillation moduleleverages a unified knowledge base to guide the representation learning ofclient models, preventing local models from overfitting to client-specificattributes. Experimental results on three datasets demonstrate that FedGIDenhances the model's ability to focus on the main subjects in unseen data andoutperforms existing methods in collaborative modeling.</description>
      <author>example@mail.com (Zhuang Qi, Runhui Zhang, Lei Meng, Wei Wu, Yachong Zhang, Xiangxu Meng)</author>
      <guid isPermaLink="false">2504.00850v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Modality Tags for Enhanced Cross-Modal Video Retrieval</title>
      <link>http://arxiv.org/abs/2504.01591v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为MAC-VR（Modality Auxiliary Concepts for Video Retrieval）的新型视频检索方法，通过利用从基础模型自动提取的模态特定标签来增强视频检索效果。&lt;h4&gt;背景&lt;/h4&gt;视频检索需要将视觉内容与相应的自然语言描述进行对齐。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的方法，即使用模态特定标签来提高视频检索的准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法在潜在空间中对齐模态，并学习与对齐辅助潜在概念，这些概念是从视频及其对应字幕的特征中提取的。引入这些辅助概念以改善视觉和文本潜在概念的对齐，并区分不同概念。&lt;h4&gt;主要发现&lt;/h4&gt;在五个不同的数据集（MSR-VTT、DiDeMo、TGIF、Charades和YouCook2）上进行的广泛实验表明，模态特定标签提高了跨模态对齐，在三个数据集上优于现有最先进的方法，在其他两个数据集上表现相当或更好。&lt;h4&gt;结论&lt;/h4&gt;MAC-VR方法能够有效地提高视频检索的准确性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为MAC-VR（模态辅助概念视频检索）的新方法，该方法利用从基础模型自动提取的模态特定标签来增强视频检索。我们建议在潜在空间中对齐模态，并学习与对齐辅助潜在概念，这些概念是从视频及其对应字幕的特征中提取的。我们将这些辅助概念引入以改善视觉和文本潜在概念的对齐，并能够区分不同的概念。我们在五个不同的数据集（MSR-VTT、DiDeMo、TGIF、Charades和YouCook2）上进行了广泛的实验。实验结果表明，模态特定标签提高了跨模态对齐，在三个数据集上优于现有最先进的方法，在其他两个数据集上表现相当或更好。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video retrieval requires aligning visual content with corresponding naturallanguage descriptions. In this paper, we introduce Modality Auxiliary Conceptsfor Video Retrieval (MAC-VR), a novel approach that leverages modality-specifictags -- automatically extracted from foundation models -- to enhance videoretrieval. We propose to align modalities in a latent space, along withlearning and aligning auxiliary latent concepts, derived from the features of avideo and its corresponding caption. We introduce these auxiliary concepts toimprove the alignment of visual and textual latent concepts, and so are able todistinguish concepts from one other. We conduct extensive experiments on fivediverse datasets: MSR-VTT, DiDeMo, TGIF, Charades and YouCook2. Theexperimental results consistently demonstrate that modality-specific tagsimprove cross-modal alignment, outperforming current state-of-the-art methodsacross three datasets and performing comparably or better across the other two.</description>
      <author>example@mail.com (Adriano Fragomeni, Dima Damen, Michael Wray)</author>
      <guid isPermaLink="false">2504.01591v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>UniFault: A Fault Diagnosis Foundation Model from Bearing Data</title>
      <link>http://arxiv.org/abs/2504.01373v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为UniFault的基础模型，用于机器故障诊断，旨在解决现有故障诊断模型在数据多样性和通用性方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;故障诊断对于预测性维护至关重要，但现有的故障诊断模型在处理不同数据集时的泛化能力有限。&lt;h4&gt;目的&lt;/h4&gt;提出UniFault模型，以解决故障诊断数据集小、异构性强的问题，并提高模型的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;UniFault模型包含一个全面的数据调和管道，包括两个关键创新：一是统一方案，将多元输入转换为标准化的单变量序列，同时保留局部通道间关系；二是跨域时间融合策略，减轻分布偏移，丰富样本多样性和数量。&lt;h4&gt;主要发现&lt;/h4&gt;UniFault在超过90亿个数据点的预训练上表现出色，在少量数据的情况下也能实现良好的性能。&lt;h4&gt;结论&lt;/h4&gt;UniFault在真实世界的故障诊断数据集上实现了最先进的性能，为故障诊断模型设定了新的基准，并为更可扩展和鲁棒的预测性维护解决方案铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：机器故障诊断（FD）对于预测性维护至关重要，它能够实现早期故障检测并预防意外故障。尽管如此，现有的FD模型在处理不同数据集时的泛化能力有限。基础模型（FM）在视觉和语言领域都展示了巨大的潜力，即使数据量很少，通过少样本或零样本学习也能实现令人印象深刻的泛化能力。然而，将这些进步应用于FD面临着独特的挑战。与图像和文本中可用的庞大、一致的数据集不同，FD数据集通常较小且异构性更强，不同系统和应用之间的采样频率和通道数量存在显著差异。这种异构性使得设计一个能够有效处理此类多样化数据并保持鲁棒特征提取和学习能力的通用架构变得复杂。在本文中，我们引入了UniFault，这是一种用于故障诊断的基础模型，系统地解决了这些问题。具体来说，该模型包含一个全面的数据调和管道，具有两个关键创新。首先，一个统一方案将多元输入转换为标准化的单变量序列，同时保留局部通道间关系。其次，一种新颖的跨域时间融合策略减轻了分布偏移，丰富了样本多样性和数量，提高了模型在变化条件下的泛化能力。UniFault在超过90亿个数据点的预训练上表现出色，使得少量数据的性能更优越。在真实世界的FD数据集上的大量实验表明，UniFault实现了最先进的性能，为故障诊断模型设定了新的基准，并为更可扩展和鲁棒的预测性维护解决方案铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine fault diagnosis (FD) is a critical task for predictive maintenance,enabling early fault detection and preventing unexpected failures. Despite itsimportance, existing FD models are operation-specific with limitedgeneralization across diverse datasets. Foundation models (FM) havedemonstrated remarkable potential in both visual and language domains,achieving impressive generalization capabilities even with minimal data throughfew-shot or zero-shot learning. However, translating these advances to FDpresents unique hurdles. Unlike the large-scale, cohesive datasets availablefor images and text, FD datasets are typically smaller and more heterogeneous,with significant variations in sampling frequencies and the number of channelsacross different systems and applications. This heterogeneity complicates thedesign of a universal architecture capable of effectively processing suchdiverse data while maintaining robust feature extraction and learningcapabilities. In this paper, we introduce UniFault, a foundation model forfault diagnosis that systematically addresses these issues. Specifically, themodel incorporates a comprehensive data harmonization pipeline featuring twokey innovations. First, a unification scheme transforms multivariate inputsinto standardized univariate sequences while retaining local inter-channelrelationships. Second, a novel cross-domain temporal fusion strategy mitigatesdistribution shifts and enriches sample diversity and count, improving themodel generalization across varying conditions. UniFault is pretrained on over9 billion data points spanning diverse FD datasets, enabling superior few-shotperformance. Extensive experiments on real-world FD datasets demonstrate thatUniFault achieves SoTA performance, setting a new benchmark for fault diagnosismodels and paving the way for more scalable and robust predictive maintenancesolutions.</description>
      <author>example@mail.com (Emadeldeen Eldele, Mohamed Ragab, Xu Qing, Edward, Zhenghua Chen, Min Wu, Xiaoli Li, Jay Lee)</author>
      <guid isPermaLink="false">2504.01373v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>MSSFC-Net:Enhancing Building Interpretation with Multi-Scale Spatial-Spectral Feature Collaboration</title>
      <link>http://arxiv.org/abs/2504.00759v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MSSFC-Net的多尺度空间-光谱特征协同双重任务网络，用于遥感图像中的建筑提取和变化检测。&lt;h4&gt;背景&lt;/h4&gt;现有的遥感图像分析方法通常独立处理建筑提取和变化检测任务，忽略了它们之间的内在关联，未能利用共享的特征表示进行相互增强。&lt;h4&gt;目的&lt;/h4&gt;提出MSSFC-Net旨在解决上述问题，通过联合建模空间-光谱多尺度特征，有效地平衡精确度和召回率，提高检测准确性和变化定位的完整性。&lt;h4&gt;方法&lt;/h4&gt;MSSFC-Net框架整合了双重任务，具体包括：设计一个具有空间-光谱特征协作的Dual-branchMulti-scale Feature Extraction模块（DMFE）以增强多尺度表示学习；引入一个Multi-scale Differential Fusion Module（MDFM）进行时间特征聚合，显式地建模差分和双重时间特征之间的交互。&lt;h4&gt;主要发现&lt;/h4&gt;在三个基准数据集上进行的广泛实验表明，MSSFC-Net在建筑提取和变化检测任务中均取得了优异的性能，有效地提高了检测准确性并保持了完整性。&lt;h4&gt;结论&lt;/h4&gt;MSSFC-Net通过其独特的架构和模块设计，为遥感图像中的建筑提取和变化检测提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Building interpretation from remote sensing imagery primarily involves twofundamental tasks: building extraction and change detection. However, mostexisting methods address these tasks independently, overlooking their inherentcorrelation and failing to exploit shared feature representations for mutualenhancement. Furthermore, the diverse spectral,spatial, and scalecharacteristics of buildings pose additional challenges in jointly modelingspatial-spectral multi-scale features and effectively balancing precision andrecall. The limited synergy between spatial and spectral representations oftenresults in reduced detection accuracy and incomplete change localization.Toaddress these challenges, we propose a Multi-Scale Spatial-Spectral FeatureCooperative Dual-Task Network (MSSFC-Net) for joint building extraction andchange detection in remote sensing images. The framework integrates both taskswithin a unified architecture, leveraging their complementary nature tosimultaneously extract building and change features. Specifically,a Dual-branchMulti-scale Feature Extraction module (DMFE) with Spatial-Spectral FeatureCollaboration (SSFC) is designed to enhance multi-scale representationlearning, effectively capturing shallow texture details and deep semanticinformation, thus improving building extraction performance. For temporalfeature aggregation, we introduce a Multi-scale Differential Fusion Module(MDFM) that explicitly models the interaction between differential anddual-temporal features. This module refines the network's capability to detectlarge-area changes and subtle structural variations in buildings. Extensiveexperiments conducted on three benchmark datasets demonstrate that MSSFC-Netachieves superior performance in both building extraction and change detectiontasks, effectively improving detection accuracy while maintaining completeness.</description>
      <author>example@mail.com (Dehua Huo, Weida Zhan, Jinxin Guo, Depeng Zhu, Yu Chen, YiChun Jiang, Yueyi Han, Deng Han, Jin Li)</author>
      <guid isPermaLink="false">2504.00759v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Normalize on the SPD Manifold under Bures-Wasserstein Geometry</title>
      <link>http://arxiv.org/abs/2504.00660v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于广义Bures-Wasserstein几何的Riemannian批归一化算法，用于更有效地处理协方差矩阵的学习。&lt;h4&gt;背景&lt;/h4&gt;协方差矩阵在多个科学领域中被证明非常有效，但它们位于对称正定流形上，这是一个具有内在非欧几里得几何的黎曼空间，因此学习表示时需要尊重其几何结构。&lt;h4&gt;目的&lt;/h4&gt;提高Riemannian批归一化（RBN）算法在处理协方差矩阵时的性能，特别是对于病态协方差矩阵（ICSM）。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于广义Bures-Wasserstein几何（GBWM）的RBN算法，并引入了可学习的度量参数和矩阵幂变形来增强表示能力。&lt;h4&gt;主要发现&lt;/h4&gt;Bures-Wasserstein度量（BWM）在处理病态协方差矩阵方面优于现有的RBN方法，而GBWM能够更细腻地表示SPD流形的几何结构。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，所提出的方法在不同数据集上验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：协方差矩阵在许多科学领域中被证明非常有效。由于这些矩阵位于对称正定流形上——一个具有内在非欧几里得几何的黎曼空间，因此在表示学习中的主要挑战是尊重这种潜在的几何结构。从欧几里得深度学习的成功中汲取灵感，研究人员已经开发了在SPD流形上的神经网络，以进行更真实的协方差嵌入学习。这一领域的一个显著进展是实现黎曼批归一化（RBN），这已被证明可以提高SPD网络模型的表现。然而，现有RBN下的黎曼度量可能无法有效地处理病态协方差矩阵（ICSM），从而损害了RBN的有效性。相比之下，Bures-Wasserstein度量（BWM）在处理病态方面表现出优越的性能。此外，最近引入的广义BWM（GBWM）通过SPD矩阵参数化标准BWM，允许对SPD流形的丰富几何结构进行更细致的表示。因此，我们提出了一种基于GBWM几何的RBN算法，并引入了一个可学习的度量参数。此外，还引入了通过矩阵幂变形GBWM的方法，以进一步增强基于GBWM的RBN的表示能力。在不同数据集上的实验结果验证了我们提出方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Covariance matrices have proven highly effective across many scientificfields. Since these matrices lie within the Symmetric Positive Definite (SPD)manifold - a Riemannian space with intrinsic non-Euclidean geometry, theprimary challenge in representation learning is to respect this underlyinggeometric structure. Drawing inspiration from the success of Euclidean deeplearning, researchers have developed neural networks on the SPD manifolds formore faithful covariance embedding learning. A notable advancement in this areais the implementation of Riemannian batch normalization (RBN), which has beenshown to improve the performance of SPD network models. Nonetheless, theRiemannian metric beneath the existing RBN might fail to effectively deal withthe ill-conditioned SPD matrices (ICSM), undermining the effectiveness of RBN.In contrast, the Bures-Wasserstein metric (BWM) demonstrates superiorperformance for ill-conditioning. In addition, the recently introducedGeneralized BWM (GBWM) parameterizes the vanilla BWM via an SPD matrix,allowing for a more nuanced representation of vibrant geometries of the SPDmanifold. Therefore, we propose a novel RBN algorithm based on the GBWgeometry, incorporating a learnable metric parameter. Moreover, the deformationof GBWM by matrix power is also introduced to further enhance therepresentational capacity of GBWM-based RBN. Experimental results on differentdatasets validate the effectiveness of our proposed method.</description>
      <author>example@mail.com (Rui Wang, Shaocheng Jin, Ziheng Chen, Xiaoqing Luo, Xiao-Jun Wu)</author>
      <guid isPermaLink="false">2504.00660v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Autonomous Driving System: An Initial Roadmap</title>
      <link>http://arxiv.org/abs/2504.00911v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了将基础模型（如大型语言模型）集成到自动驾驶系统中的进展及其带来的挑战，并提出了一个结构化的路线图，包括基础模型的基础设施、在自动驾驶系统中的应用以及当前实践中的应用。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶系统（ADS）是高度复杂的网络物理系统，需要严格的软件工程实践来确保可靠性和安全性。将基础模型（FMs）集成到ADS中带来了新的系统设计和评估挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，本文提出了一个结构化的路线图，用于将FMs集成到自动驾驶中，并建立清晰的研究路线。&lt;h4&gt;方法&lt;/h4&gt;路线图覆盖了三个关键方面：FMs的基础设施、在自动驾驶系统中的应用和它们在实践中的应用。对于每个方面，本文回顾了当前的研究进展，确定了现有的挑战，并指出了需要由社区解决的研究差距。&lt;h4&gt;主要发现&lt;/h4&gt;集成FMs到ADS中提高了感知、推理和决策能力，但同时也引入了新的设计评估挑战。&lt;h4&gt;结论&lt;/h4&gt;需要系统地评估FMs在自动驾驶中的应用，并解决相关的系统设计问题。&lt;h4&gt;翻译&lt;/h4&gt;近年来，基础模型（如大型语言模型）在自动驾驶系统（ADS）中的集成取得了显著进展，提高了在动态和不确定环境中的感知、推理和决策能力。然而，ADS是高度复杂的网络物理系统，需要严格的软件工程实践来确保可靠性和安全性。将基础模型（FMs）集成到ADS中引入了新的系统设计和评估挑战，需要系统地回顾以建立清晰的研究路线。为了解决这些挑战，我们提出了一个结构化的路线图，用于将FMs集成到自动驾驶中，涵盖了三个关键方面：FMs的基础设施、在自动驾驶系统中的应用以及它们在实践中的应用。对于每个方面，我们回顾了当前的研究进展，确定了现有的挑战，并强调了需要由社区解决的研究差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Foundation Models (FMs), such as Large Language Models(LLMs), have significantly enhanced Autonomous Driving Systems (ADSs) byimproving perception, reasoning, and decision-making in dynamic and uncertainenvironments. However, ADSs are highly complex cyber-physical systems thatdemand rigorous software engineering practices to ensure reliability andsafety. Integrating FMs into ADSs introduces new challenges in system designand evaluation, requiring a systematic review to establish a clear researchroadmap. To unlock these challenges, we present a structured roadmap forintegrating FMs into autonomous driving, covering three key aspects: theinfrastructure of FMs, their application in autonomous driving systems, andtheir current applications in practice. For each aspect, we review the currentresearch progress, identify existing challenges, and highlight research gapsthat need to be addressed by the community.</description>
      <author>example@mail.com (Xiongfei Wu, Mingfei Cheng, Qiang Hu, Jianlang Chen, Yuheng Huang, Manabu Okada, Michio Hayashi, Tomoyuki Tsuchiya, Xiaofei Xie, Lei Ma)</author>
      <guid isPermaLink="false">2504.00911v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Gaze-Guided 3D Hand Motion Prediction for Detecting Intent in Egocentric Grasping Tasks</title>
      <link>http://arxiv.org/abs/2504.01024v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过预测手部姿态和关节位置来检测人类意图的新方法，旨在推动神经康复应用中上肢辅助机器人技术的发展。&lt;h4&gt;背景&lt;/h4&gt;传统的依赖生理信号测量的人类意图检测方法存在限制，且通常缺乏环境上下文。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需事先了解抓取目标即可动态适应患者辅助需求的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法整合了注视信息、历史手部运动序列和环境物体数据，使用向量量化变分自动编码器进行鲁棒的手部姿态编码，以及自回归生成变压器进行有效的手部运动序列预测。&lt;h4&gt;主要发现&lt;/h4&gt;在健康受试者中进行的小型研究表明，这些新技术具有可用性。通过广泛实验，证明了该方法可以成功预测连续的手部运动，特别是注视信息在预测能力方面显示出显著增强，尤其是在输入帧较少的情况下，突出了该方法在实际应用中的潜力。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法对于神经康复应用中上肢辅助机器人技术的发展具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human intention detection with hand motion prediction is critical to drivethe upper-extremity assistive robots in neurorehabilitation applications.However, the traditional methods relying on physiological signal measurementare restrictive and often lack environmental context. We propose a novelapproach that predicts future sequences of both hand poses and joint positions.This method integrates gaze information, historical hand motion sequences, andenvironmental object data, adapting dynamically to the assistive needs of thepatient without prior knowledge of the intended object for grasping.Specifically, we use a vector-quantized variational autoencoder for robust handpose encoding with an autoregressive generative transformer for effective handmotion sequence prediction. We demonstrate the usability of these noveltechniques in a pilot study with healthy subjects. To train and evaluate theproposed method, we collect a dataset consisting of various types of graspactions on different objects from multiple subjects. Through extensiveexperiments, we demonstrate that the proposed method can successfully predictsequential hand movement. Especially, the gaze information shows significantenhancements in prediction capabilities, particularly with fewer input frames,highlighting the potential of the proposed method for real-world applications.</description>
      <author>example@mail.com (Yufei He, Xucong Zhang, Arno H. A. Stienen)</author>
      <guid isPermaLink="false">2504.01024v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>FIORD: A Fisheye Indoor-Outdoor Dataset with LIDAR Ground Truth for 3D Scene Reconstruction and Benchmarking</title>
      <link>http://arxiv.org/abs/2504.01732v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SCIA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种针对场景重建任务定制的鱼眼图像数据集，用于解决大规模3D场景重建和新型视图合成方法中依赖的视角图像数据集存在的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有的3D场景重建和视图合成方法主要依赖于包含窄视场视角图像的数据集，虽然对小规模场景有效，但需要大量图像和广泛的运动结构（SfM）处理，限制了可扩展性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了一种新的鱼眼图像数据集，以支持更高效和可扩展的场景重建。&lt;h4&gt;方法&lt;/h4&gt;该数据集使用双200度鱼眼镜头，提供了5个室内和5个室外场景的完整360度覆盖。每个场景都有稀疏的SfM点云和精确的LIDAR生成的密集点云，可以作为几何地面实况，以在遮挡和反射等挑战性条件下进行稳健的基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;该数据集支持多种场景重建、新型视图合成和基于图像的渲染方法，包括Gaussian Splatting和基于NeRF的Nerfacto方法。&lt;h4&gt;结论&lt;/h4&gt;通过提供全面的360度覆盖和精确的点云数据，该数据集为场景重建和视图合成提供了更强大的工具，并支持多样化的方法研究。&lt;h4&gt;翻译&lt;/h4&gt;The development of large-scale 3D scene reconstruction and novel view synthesis methods mostly rely on datasets comprising perspective images with narrow fields of view (FoV). While effective for small-scale scenes, these datasets require large image sets and extensive structure-from-motion (SfM) processing, limiting scalability. To address this, we introduce a fisheye image dataset tailored for scene reconstruction tasks. Using dual 200-degree fisheye lenses, our dataset provides full 360-degree coverage of 5 indoor and 5 outdoor scenes. Each scene has sparse SfM point clouds and precise LIDAR-derived dense point clouds that can be used as geometric ground-truth, enabling robust benchmarking under challenging conditions such as occlusions and reflections. While the baseline experiments focus on vanilla Gaussian Splatting and NeRF-based Nerfacto methods, the dataset supports diverse approaches for scene reconstruction, novel view synthesis, and image-based rendering.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of large-scale 3D scene reconstruction and novel viewsynthesis methods mostly rely on datasets comprising perspective images withnarrow fields of view (FoV). While effective for small-scale scenes, thesedatasets require large image sets and extensive structure-from-motion (SfM)processing, limiting scalability. To address this, we introduce a fisheye imagedataset tailored for scene reconstruction tasks. Using dual 200-degree fisheyelenses, our dataset provides full 360-degree coverage of 5 indoor and 5 outdoorscenes. Each scene has sparse SfM point clouds and precise LIDAR-derived densepoint clouds that can be used as geometric ground-truth, enabling robustbenchmarking under challenging conditions such as occlusions and reflections.While the baseline experiments focus on vanilla Gaussian Splatting and NeRFbased Nerfacto methods, the dataset supports diverse approaches for scenereconstruction, novel view synthesis, and image-based rendering.</description>
      <author>example@mail.com (Ulas Gunes, Matias Turkulainen, Xuqian Ren, Arno Solin, Juho Kannala, Esa Rahtu)</author>
      <guid isPermaLink="false">2504.01732v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Overcoming Deceptiveness in Fitness Optimization with Unsupervised Quality-Diversity</title>
      <link>http://arxiv.org/abs/2504.01915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AURORA-XCon的优化框架，该框架通过无监督QD算法解决欺骗性优化问题，无需领域专业知识，并显著优于传统优化方法。&lt;h4&gt;背景&lt;/h4&gt;政策优化是工程和研究的核心领域，在机器人等领域有广泛应用。传统优化方法如强化学习和进化算法在欺骗性适应度景观中表现不佳，而QD算法需要领域专业知识来定义特征，限制了其应用。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需领域专业知识即可有效解决欺骗性优化问题的无监督QD算法。&lt;h4&gt;方法&lt;/h4&gt;提出AURORA框架，该框架从感官数据中学习特征，并通过对比学习和周期性灭绝事件增强AURORA，形成AURORA-XCon。&lt;h4&gt;主要发现&lt;/h4&gt;AURORA-XCon在欺骗性优化问题上的表现优于所有传统优化基线，在某些情况下甚至比具有领域特定手工特征的QD基线提高了34%。&lt;h4&gt;结论&lt;/h4&gt;AURORA-XCon建立了无监督QD算法的新应用，将重点从发现新解决方案转向传统优化，并扩展了其在特征空间定义具有挑战性的领域的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：政策优化寻求根据目标或适应度函数找到控制问题的最佳解决方案，作为工程和研究的根本领域，在机器人等领域有应用。传统的优化方法，如强化学习和进化算法，在欺骗性适应度景观中表现不佳，遵循即时改进会导致次优解。质量-多样性（QD）算法通过保持多样化的中间解决方案作为逃离局部最优的垫脚石，提供了一种有希望的方法。然而，QD算法需要领域专业知识来定义手工特征，限制了它们在难以表征解决方案多样性的领域的适用性。在本文中，我们表明无监督QD算法——特别是从感官数据中学习特征的AURORA框架——可以有效地解决欺骗性优化问题，而无需领域专业知识。通过增强AURORA的对比学习和周期性灭绝事件，我们提出了AURORA-XCon，它优于所有传统的优化基线，在某些情况下甚至比具有领域特定手工特征的QD基线提高了34%。这项工作建立了一种无监督QD算法的新应用，将它们的重点从发现新解决方案转向传统优化，并扩展了它们在定义特征空间具有挑战性的领域的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3712256.3726314&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Policy optimization seeks the best solution to a control problem according toan objective or fitness function, serving as a fundamental field of engineeringand research with applications in robotics. Traditional optimization methodslike reinforcement learning and evolutionary algorithms struggle with deceptivefitness landscapes, where following immediate improvements leads to suboptimalsolutions. Quality-diversity (QD) algorithms offer a promising approach bymaintaining diverse intermediate solutions as stepping stones for escapinglocal optima. However, QD algorithms require domain expertise to definehand-crafted features, limiting their applicability where characterizingsolution diversity remains unclear. In this paper, we show that unsupervised QDalgorithms - specifically the AURORA framework, which learns features fromsensory data - efficiently solve deceptive optimization problems without domainexpertise. By enhancing AURORA with contrastive learning and periodicextinction events, we propose AURORA-XCon, which outperforms all traditionaloptimization baselines and matches, in some cases even improving by up to 34%,the best QD baseline with domain-specific hand-crafted features. This workestablishes a novel application of unsupervised QD algorithms, shifting theirfocus from discovering novel solutions toward traditional optimization andexpanding their potential to domains where defining feature spaces poseschallenges.</description>
      <author>example@mail.com (Lisa Coiffard, Paul Templier, Antoine Cully)</author>
      <guid isPermaLink="false">2504.01915v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Graphically Speaking: Unmasking Abuse in Social Media with Conversation Insights</title>
      <link>http://arxiv.org/abs/2504.01902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用图神经网络（GNNs）来检测社交媒体中滥用语言的新方法，该方法在检测滥用语言时考虑了对话上下文，并取得了显著的效果。&lt;h4&gt;背景&lt;/h4&gt;在社交媒体中检测滥用语言是一个挑战，因为滥用语言的识别往往依赖于对话上下文，包括内容和评论之间的拓扑结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于图神经网络的方法来改进滥用语言检测（ALD）模型的性能。&lt;h4&gt;方法&lt;/h4&gt;利用图神经网络（GNNs）将社交媒体对话建模为图，其中节点代表评论，边代表回复结构。系统性地研究了各种图表示和上下文窗口，以确定最佳的ALD配置。&lt;h4&gt;主要发现&lt;/h4&gt;GNN模型在F1分数上优于无上下文基线和线性上下文感知方法，证明了结构化对话上下文的重要性，并将GNNs确立为推进上下文感知滥用语言检测的稳健框架。&lt;h4&gt;结论&lt;/h4&gt;结构化对话上下文对于滥用语言检测至关重要，GNNs是这一领域的一个有效工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting abusive language in social media conversations poses significantchallenges, as identifying abusiveness often depends on the conversationalcontext, characterized by the content and topology of preceding comments.Traditional Abusive Language Detection (ALD) models often overlook thiscontext, which can lead to unreliable performance metrics. Recent NaturalLanguage Processing (NLP) methods that integrate conversational context oftendepend on limited and simplified representations, and report inconsistentresults. In this paper, we propose a novel approach that utilize graph neuralnetworks (GNNs) to model social media conversations as graphs, where nodesrepresent comments, and edges capture reply structures. We systematicallyinvestigate various graph representations and context windows to identify theoptimal configuration for ALD. Our GNN model outperform both context-agnosticbaselines and linear context-aware methods, achieving significant improvementsin F1 scores. These findings demonstrate the critical role of structuredconversational context and establish GNNs as a robust framework for advancingcontext-aware abusive language detection.</description>
      <author>example@mail.com (Célia Nouri, Jean-Philippe Cointet, Chloé Clavel)</author>
      <guid isPermaLink="false">2504.01902v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Intrinsic-feature-guided 3D Object Detection</title>
      <link>http://arxiv.org/abs/2504.00382v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于模板辅助特征增强模块的内在特征引导3D目标检测方法，旨在提高自动驾驶系统中LiDAR点云数据在3D目标检测方面的性能。&lt;h4&gt;背景&lt;/h4&gt;LiDAR点云数据在3D目标检测中存在稀疏性、分布不均和不完整结构等问题，限制了检测性能。&lt;h4&gt;目的&lt;/h4&gt;提高自动驾驶系统中基于LiDAR的3D目标检测性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于模板辅助特征增强模块的3D目标检测方法，该方法从相对通用的模板中提取内在特征，并为前景物体提供丰富的结构信息。此外，还设计了一种提案级别的对比学习机制，以增强前景与背景物体之间的特征差异。&lt;h4&gt;主要发现&lt;/h4&gt;该方法可以作为即插即用组件，提高多种现有方法的性能，并通过大量实验证明了其具有高度竞争力的检测结果。&lt;h4&gt;结论&lt;/h4&gt;该方法在3D目标检测方面取得了显著成效，并将在GitHub上提供代码。&lt;h4&gt;翻译&lt;/h4&gt;LiDAR-based 3D object detection is essential for autonomous driving systems. However, LiDAR point clouds may appear to have sparsity, uneven distribution, and incomplete structures, significantly limiting the detection performance. In road driving environments, target objects referring to vehicles, pedestrians, and cyclists are well-suited for enhancing representation through the complete template guidance, considering their grid and topological structures. Therefore, this paper presents an intrinsic-feature-guided 3D object detection method based on a template-assisted feature enhancement module, which extracts intrinsic features from relatively generalized templates and provides rich structural information for foreground objects. Furthermore, a proposal-level contrastive learning mechanism is designed to enhance the feature differences between foreground and background objects. The proposed modules can act as plug-and-play components and improve the performance of multiple existing methods. Extensive experiments illustrate that the proposed method achieves the highly competitive detection results. Code will be available at https://github.com/zhangwanjingjj/IfgNet.git.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR-based 3D object detection is essential for autonomous driving systems.However, LiDAR point clouds may appear to have sparsity, uneven distribution,and incomplete structures, significantly limiting the detection performance. Inroad driving environments, target objects referring to vehicles, pedestriansand cyclists are well-suited for enhancing representation through the completetemplate guidance, considering their grid and topological structures.Therefore, this paper presents an intrinsic-feature-guided 3D object detectionmethod based on a template-assisted feature enhancement module, which extractsintrinsic features from relatively generalized templates and provides richstructural information for foreground objects. Furthermore, a proposal-levelcontrastive learning mechanism is designed to enhance the feature differencesbetween foreground and background objects. The proposed modules can act asplug-and-play components and improve the performance of multiple existingmethods. Extensive experiments illustrate that the proposed method achieves thehighly competitive detection results. Code will be available athttps://github.com/zhangwanjingjj/IfgNet.git.</description>
      <author>example@mail.com (Wanjing Zhang, Chenxing Wang)</author>
      <guid isPermaLink="false">2504.00382v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Identifying Obfuscated Code through Graph-Based Semantic Analysis of Binary Code</title>
      <link>http://arxiv.org/abs/2504.01481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The 13th International Conference on Complex Networks and their  Applications, Dec 2024, Istabul, Turkey&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用基于图的方法进行函数级混淆检测的问题，比较了从基础方法到GNN（图神经网络）等有潜力的技术，在不同的特征选择上进行了算法对比。&lt;h4&gt;背景&lt;/h4&gt;保护敏感程序内容是多种情境下的关键问题，包括合法使用和不良使用。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过图神经网络等方法检测函数级混淆，以保护敏感程序内容。&lt;h4&gt;方法&lt;/h4&gt;本文考虑了各种混淆类型和混淆器，形成了两个复杂的数据集，并通过比较不同的算法和特征选择来检测混淆。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，GNN需要捕捉函数语义方面的有意义特征才能超越基础方法。在11类分类任务和实际恶意软件分析示例中，该方法表现出令人满意的结果。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在函数级混淆检测方面取得了满意的效果，尤其是在具有挑战性的分类任务和实际应用中。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the problem of function-level obfuscation detection using graph-based approaches, comparing algorithms from elementary baselines to promising techniques like GNN (Graph Neural Networks), on different feature choices. We consider various obfuscation types and obfuscators, resulting in two complex datasets. Our findings demonstrate that GNNs need meaningful features that capture aspects of function semantics to outperform baselines. Our approach shows satisfactory results, especially in a challenging 11-class classification task and in a practical malware analysis example.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Protecting sensitive program content is a critical issue in varioussituations, ranging from legitimate use cases to unethical contexts.Obfuscation is one of the most used techniques to ensure such protection.Consequently, attackers must first detect and characterize obfuscation beforelaunching any attack against it. This paper investigates the problem offunction-level obfuscation detection using graph-based approaches, comparingalgorithms, from elementary baselines to promising techniques like GNN (GraphNeural Networks), on different feature choices. We consider various obfuscationtypes and obfuscators, resulting in two complex datasets. Our findingsdemonstrate that GNNs need meaningful features that capture aspects of functionsemantics to outperform baselines. Our approach shows satisfactory results,especially in a challenging 11-class classification task and in a practicalmalware analysis example.</description>
      <author>example@mail.com (Roxane Cohen, Robin David, Florian Yger, Fabrice Rossi)</author>
      <guid isPermaLink="false">2504.01481v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Is Temporal Prompting All We Need For Limited Labeled Action Recognition?</title>
      <link>http://arxiv.org/abs/2504.01890v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in CVPR-W 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，视频理解取得了显著进展，主要依赖于大规模标记数据集的可用性。基于对比预训练的视觉语言模型在零样本任务中表现出出色的泛化能力，有助于克服对标记数据集的依赖。本文提出了一种名为TP-CLIP的视频理解模型，它通过时间视觉提示进行时间适应，而不修改CLIP的核心架构，从而保持了其泛化能力。实验表明，TP-CLIP在零样本和少样本学习中表现出高效性，参数和计算效率优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;视频理解在过去几年中取得了显著进步，主要依赖于大规模标记数据集。然而，基于对比预训练的视觉语言模型在视频数据上的应用存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为TP-CLIP的视频理解模型，通过时间视觉提示进行时间适应，同时保持CLIP模型的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;TP-CLIP是对CLIP模型的改进，通过修改架构以适应视频数据，同时利用预训练能力进行时间适应。&lt;h4&gt;主要发现&lt;/h4&gt;TP-CLIP在零样本和少样本学习中表现出高效性，参数和计算效率优于现有方法，且在特定任务和数据集上性能优于最先进的模型。&lt;h4&gt;结论&lt;/h4&gt;TP-CLIP是一种高效的视频理解模型，它通过时间视觉提示进行时间适应，同时保持了CLIP模型的泛化能力，且在参数和计算效率上优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Video understanding has shown remarkable improvements in recent years, largely dependent on the availability of large scaled labeled datasets. Recent advancements in visual-language models, especially based on contrastive pretraining, have shown remarkable generalization in zero-shot tasks, helping to overcome this dependence on labeled datasets. Adaptations of such models for videos, typically involve modifying the architecture of vision-language models to cater to video data. However, this is not trivial, since such adaptations are mostly computationally intensive and struggle with temporal modeling. We present TP-CLIP, an adaptation of CLIP that leverages temporal visual prompting for temporal adaptation without modifying the core CLIP architecture. This preserves its generalization abilities. TP-CLIP efficiently integrates into the CLIP architecture, leveraging its pre-trained capabilities for video data. Extensive experiments across various datasets demonstrate its efficacy in zero-shot and few-shot learning, outperforming existing approaches with fewer parameters and computational efficiency. In particular, we use just 1/3 the GFLOPs and 1/28 the number of tunable parameters in comparison to recent state-of-the-art and still outperform it by up to 15.8% depending on the task and dataset.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video understanding has shown remarkable improvements in recent years,largely dependent on the availability of large scaled labeled datasets. Recentadvancements in visual-language models, especially based on contrastivepretraining, have shown remarkable generalization in zero-shot tasks, helpingto overcome this dependence on labeled datasets. Adaptations of such models forvideos, typically involve modifying the architecture of vision-language modelsto cater to video data. However, this is not trivial, since such adaptationsare mostly computationally intensive and struggle with temporal modeling. Wepresent TP-CLIP, an adaptation of CLIP that leverages temporal visual promptingfor temporal adaptation without modifying the core CLIP architecture. Thispreserves its generalization abilities. TP-CLIP efficiently integrates into theCLIP architecture, leveraging its pre-trained capabilities for video data.Extensive experiments across various datasets demonstrate its efficacy inzero-shot and few-shot learning, outperforming existing approaches with fewerparameters and computational efficiency. In particular, we use just 1/3 theGFLOPs and 1/28 the number of tuneable parameters in comparison to recentstate-of-the-art and still outperform it by up to 15.8% depending on the taskand dataset.</description>
      <author>example@mail.com (Shreyank N Gowda, Boyan Gao, Xiao Gu, Xiaobo Jin)</author>
      <guid isPermaLink="false">2504.01890v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>SMILE: Infusing Spatial and Motion Semantics in Masked Video Learning</title>
      <link>http://arxiv.org/abs/2504.00527v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SMILE是一种新的视频自监督学习方法，通过融合空间和运动语义来增强视频表示学习。&lt;h4&gt;背景&lt;/h4&gt;现有的视频自监督学习方法如VideoMAE主要基于重建自然视频中的像素级细节，这限制了它们在语义表示和运动动态编码方面的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的SSL方法，以解决现有方法在语义表示和运动动态编码方面的限制。&lt;h4&gt;方法&lt;/h4&gt;SMILE利用图像语言预训练模型（如CLIP）的高层空间语义来指导学习过程，并通过引入合成运动模式来增强运动表示。此外，SMILE能够在不使用自然视频数据的情况下学习强大的视频表示。&lt;h4&gt;主要发现&lt;/h4&gt;SMILE在7个数据集上进行了广泛的实验，其表现优于当前的SSL方法，展示了其在学习更具区分性和可推广的视频表示方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;SMILE是一种有效的视频自监督学习方法，能够学习到更具有区分性和可推广的视频表示，其代码已开源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Masked video modeling, such as VideoMAE, is an effective paradigm for videoself-supervised learning (SSL). However, they are primarily based onreconstructing pixel-level details on natural videos which have substantialtemporal redundancy, limiting their capability for semantic representation andsufficient encoding of motion dynamics. To address these issues, this paperintroduces a novel SSL approach for video representation learning, dubbed asSMILE, by infusing both spatial and motion semantics. In SMILE, we leverageimage-language pretrained models, such as CLIP, to guide the learning processwith their high-level spatial semantics. We enhance the representation ofmotion by introducing synthetic motion patterns in the training data, allowingthe model to capture more complex and dynamic content. Furthermore, usingSMILE, we establish a new self-supervised video learning paradigm capable oflearning strong video representations without requiring any natural video data.We have carried out extensive experiments on 7 datasets with various downstreamscenarios. SMILE surpasses current state-of-the-art SSL methods, showcasing itseffectiveness in learning more discriminative and generalizable videorepresentations. Code is available: https://github.com/fmthoker/SMILE</description>
      <author>example@mail.com (Fida Mohammad Thoker, Letian Jiang, Chen Zhao, Bernard Ghanem)</author>
      <guid isPermaLink="false">2504.00527v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Generalized Tensor-based Parameter-Efficient Fine-Tuning via Lie Group Transformations</title>
      <link>http://arxiv.org/abs/2504.00851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将基于矩阵的参数高效微调（PEFT）方法扩展到高维参数空间的方法，以解决现有方法在处理高维参数空间时的不足。&lt;h4&gt;背景&lt;/h4&gt;在人工智能中，对预训练基础模型进行适配是核心实践，但广泛的任务和计算成本使得全量微调不切实际。LoRA等PEFT方法虽然成功，但主要针对线性层，忽略了高维参数空间如卷积核。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，将基于矩阵的PEFT方法推广到高维参数空间，同时保持其结构特性。&lt;h4&gt;方法&lt;/h4&gt;将参数视为李群元素，将更新建模为对应李代数中的扰动，并通过指数映射将这些扰动映射回李群，确保平滑、一致的更新，从而保持参数空间的固有结构。&lt;h4&gt;主要发现&lt;/h4&gt;在计算机视觉和自然语言处理上的大量实验验证了该方法的有效性和通用性，显示出比现有方法明显的改进。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效地扩展PEFT方法到高维参数空间，同时保持结构特性，为人工智能领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Adapting pre-trained foundation models for diverse downstream tasks is a core practice in artificial intelligence. However, the wide range of tasks and high computational costs make full fine-tuning impractical. To overcome this, parameter-efficient fine-tuning (PEFT) methods like LoRA have emerged and are becoming a growing research focus. Despite the success of these methods, they are primarily designed for linear layers, focusing on two-dimensional matrices while largely ignoring higher-dimensional parameter spaces like convolutional kernels. Moreover, directly applying these methods to higher-dimensional parameter spaces often disrupts their structural relationships. Given the rapid advancements in matrix-based PEFT methods, rather than designing a specialized strategy, we propose a generalization that extends matrix-based PEFT methods to higher-dimensional parameter spaces without compromising their structural properties. Specifically, we treat parameters as elements of a Lie group, with updates modeled as perturbations in the corresponding Lie algebra. These perturbations are mapped back to the Lie group through the exponential map, ensuring smooth, consistent updates that preserve the inherent structure of the parameter space. Extensive experiments on computer vision and natural language processing validate the effectiveness and versatility of our approach, demonstrating clear improvements over existing methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adapting pre-trained foundation models for diverse downstream tasks is a corepractice in artificial intelligence. However, the wide range of tasks and highcomputational costs make full fine-tuning impractical. To overcome this,parameter-efficient fine-tuning (PEFT) methods like LoRA have emerged and arebecoming a growing research focus. Despite the success of these methods, theyare primarily designed for linear layers, focusing on two-dimensional matriceswhile largely ignoring higher-dimensional parameter spaces like convolutionalkernels. Moreover, directly applying these methods to higher-dimensionalparameter spaces often disrupts their structural relationships. Given the rapidadvancements in matrix-based PEFT methods, rather than designing a specializedstrategy, we propose a generalization that extends matrix-based PEFT methods tohigher-dimensional parameter spaces without compromising their structuralproperties. Specifically, we treat parameters as elements of a Lie group, withupdates modeled as perturbations in the corresponding Lie algebra. Theseperturbations are mapped back to the Lie group through the exponential map,ensuring smooth, consistent updates that preserve the inherent structure of theparameter space. Extensive experiments on computer vision and natural languageprocessing validate the effectiveness and versatility of our approach,demonstrating clear improvements over existing methods.</description>
      <author>example@mail.com (Chongjie Si, Zhiyi Shi, Xuehui Wang, Yichen Xiao, Xiaokang Yang, Wei Shen)</author>
      <guid isPermaLink="false">2504.00851v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>CBIL: Collective Behavior Imitation Learning for Fish from Real Videos</title>
      <link>http://arxiv.org/abs/2504.00234v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CBIL的可扩展方法，用于从视频中直接学习鱼群行为，不依赖于捕获的运动轨迹。&lt;h4&gt;背景&lt;/h4&gt;传统的基于规则的集体行为方法依赖于手工制定的原则，限制了生成集体行为的运动多样性和逼真性。近期的方法虽然通过数据学习，但往往需要真实的运动轨迹，特别是在高密度和动作不规则的群体中，难以保证真实性。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需真实运动轨迹即可从视频中学习集体行为的方法，以实现更真实的集体行为模拟。&lt;h4&gt;方法&lt;/h4&gt;CBIL方法首先利用视频表示学习，其中掩码视频自编码器（MVAE）以自监督的方式从视频输入中提取隐含状态。然后，提出了一种新的对抗性模仿学习方法，以有效地捕捉鱼群复杂的运动，并允许在潜在空间中高效地模仿运动模式的分布。此外，该方法结合了生物启发的奖励和先验来规范和稳定训练。&lt;h4&gt;主要发现&lt;/h4&gt;CBIL方法可以用于各种动画任务，并通过学习到的集体运动先验来提高动画的真实性。该方法在处理不同物种的集体行为时也表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;CBIL方法为模拟真实的集体行为提供了一种有效的方法，并在检测野外视频中异常鱼行为的应用中展示了其潜力。&lt;h4&gt;翻译&lt;/h4&gt;复现真实的集体行为是一个引人入胜但具有挑战性的任务。传统的基于规则的方法依赖于手工制定的原则，限制了生成集体行为的运动多样性和逼真性。最近的方法虽然从数据中学习，但通常需要真实的运动轨迹，尤其是在高密度且动作不规则的群体中，难以保证真实性。在本文中，我们提出了一种可扩展的方法，称为集体行为模仿学习（CBIL），用于直接从视频中学习鱼群行为，而不依赖于捕获的运动轨迹。我们的方法首先利用视频表示学习，其中掩码视频自编码器（MVAE）以自监督的方式从视频输入中提取隐含状态。MVAE有效地将二维观测映射到紧凑且表达性强，适用于模仿学习阶段的隐含状态。然后，我们提出了一种新的对抗性模仿学习方法，以有效地捕捉鱼群的复杂运动，允许在潜在空间中高效地模仿运动模式的分布。该方法还结合了生物启发的奖励和先验，以规范和稳定训练。一旦训练完成，CBIL可以用于各种动画任务，并使用学习到的集体运动先验。我们还展示了它在处理不同物种的集体行为时的有效性。最后，我们展示了该系统在检测野外视频中的异常鱼行为中的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3687904&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reproducing realistic collective behaviors presents a captivating yetformidable challenge. Traditional rule-based methods rely on hand-craftedprinciples, limiting motion diversity and realism in generated collectivebehaviors. Recent imitation learning methods learn from data but often requireground truth motion trajectories and struggle with authenticity, especially inhigh-density groups with erratic movements. In this paper, we present ascalable approach, Collective Behavior Imitation Learning (CBIL), for learningfish schooling behavior directly from videos, without relying on capturedmotion trajectories. Our method first leverages Video Representation Learning,where a Masked Video AutoEncoder (MVAE) extracts implicit states from videoinputs in a self-supervised manner. The MVAE effectively maps 2D observationsto implicit states that are compact and expressive for following the imitationlearning stage. Then, we propose a novel adversarial imitation learning methodto effectively capture complex movements of the schools of fish, allowing forefficient imitation of the distribution for motion patterns measured in thelatent space. It also incorporates bio-inspired rewards alongside priors toregularize and stabilize training. Once trained, CBIL can be used for variousanimation tasks with the learned collective motion priors. We further show itseffectiveness across different species. Finally, we demonstrate the applicationof our system in detecting abnormal fish behavior from in-the-wild videos.</description>
      <author>example@mail.com (Yifan Wu, Zhiyang Dou, Yuko Ishiwaka, Shun Ogawa, Yuke Lou, Wenping Wang, Lingjie Liu, Taku Komura)</author>
      <guid isPermaLink="false">2504.00234v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Overlap-Aware Feature Learning for Robust Unsupervised Domain Adaptation for 3D Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2504.01668v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages,6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对3D点云语义分割（PCSS）中的无监督领域自适应（UDA）方法，提出了一种新的框架，以提高对现实世界扰动和对抗性扰动的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;3D点云语义分割在机器人系统和自动驾驶中至关重要，无监督领域自适应方法可以缓解标签稀缺问题，但现有方法忽视了对抗性攻击和现实世界扰动的影响。&lt;h4&gt;目的&lt;/h4&gt;解决现有PCSS-UDA方法在对抗攻击和现实世界扰动下的鲁棒性问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一个三部分框架，包括：1）一个鲁棒性评估模型，通过鲁棒性指标量化对抗攻击/腐败类型的抵抗力；2）一个可逆注意力对齐模块（IAAM），通过注意力引导的重叠抑制，实现双向领域映射并保持判别结构；3）一个具有质量感知对比学习的对比记忆库，通过特征质量逐步优化伪标签，以获得更具判别性的表示。&lt;h4&gt;主要发现&lt;/h4&gt;在SynLiDAR-to-SemanticPOSS适应实验中，该方法在对抗攻击下实现了最大14.3%的mIoU提升。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高3D点云语义分割在对抗攻击和现实世界扰动下的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D point cloud semantic segmentation (PCSS) is a cornerstone forenvironmental perception in robotic systems and autonomous driving, enablingprecise scene understanding through point-wise classification. Whileunsupervised domain adaptation (UDA) mitigates label scarcity in PCSS, existingmethods critically overlook the inherent vulnerability to real-worldperturbations (e.g., snow, fog, rain) and adversarial distortions. This workfirst identifies two intrinsic limitations that undermine current PCSS-UDArobustness: (a) unsupervised features overlap from unaligned boundaries inshared-class regions and (b) feature structure erosion caused bydomain-invariant learning that suppresses target-specific patterns. To addressthe proposed problems, we propose a tripartite framework consisting of: 1) arobustness evaluation model quantifying resilience against adversarialattack/corruption types through robustness metrics; 2) an invertible attentionalignment module (IAAM) enabling bidirectional domain mapping while preservingdiscriminative structure via attention-guided overlap suppression; and 3) acontrastive memory bank with quality-aware contrastive learning thatprogressively refines pseudo-labels with feature quality for morediscriminative representations. Extensive experiments onSynLiDAR-to-SemanticPOSS adaptation demonstrate a maximum mIoU improvement of14.3\% under adversarial attack.</description>
      <author>example@mail.com (Junjie Chen, Yuecong Xu, Haosheng Li, Kemi Ding)</author>
      <guid isPermaLink="false">2504.01668v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Lorentzian Graph Isomorphic Network</title>
      <link>http://arxiv.org/abs/2504.00142v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Lorentzian Graph Isomorphic Network（LGIN）的新型图神经网络，该网络在双曲空间中运行，利用Lorentzian模型来增强图表示学习。&lt;h4&gt;背景&lt;/h4&gt;现有的图神经网络主要在欧几里得空间中运行，这可能会限制它们捕捉复杂图固有的层次结构和多关系结构的能力。&lt;h4&gt;目的&lt;/h4&gt;LGIN通过结合曲率感知聚合函数，保留了Lorentzian度量张量，确保嵌入保持在双曲空间内，提出了一种新的更新规则，有效地捕捉局部邻域交互作用和全局结构特性，从而区分非同构图。&lt;h4&gt;方法&lt;/h4&gt;LGIN通过在九个基准数据集上进行了广泛的评估，包括分子和蛋白质结构，包括曲率感知聚合函数和新的更新规则。&lt;h4&gt;主要发现&lt;/h4&gt;LGIN在九个基准数据集上，包括分子和蛋白质结构上，一致地优于或与最先进的GNN相当，证明了其在建模复杂图结构方面的鲁棒性和有效性。&lt;h4&gt;结论&lt;/h4&gt;LGIN是第一个将强大的图神经网络概念扩展到黎曼流形的研究，为双曲图学习领域的未来进步铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了Lorentzian图同构网络（LGIN），这是一种新型图神经网络（GNN），设计用于在双曲空间中运行，利用Lorentzian模型来增强图表示学习。现有的GNN主要在欧几里得空间中运行，这可能会限制它们捕捉复杂图固有的层次结构和多关系结构的能力。LGIN通过结合曲率感知聚合函数，保留了Lorentzian度量张量，确保嵌入保持在双曲空间内，通过提出一种新的更新规则，有效地捕捉局部邻域交互作用和全局结构特性，使LGIN能够区分非同构图，其表达能力至少与Weisfeiler-Lehman测试相当。通过在九个基准数据集上进行了广泛的评估，包括分子和蛋白质结构，LGIN在九个基准数据集上，包括分子和蛋白质结构上，一致地优于或与最先进的GNN相当，证明了其在建模复杂图结构方面的鲁棒性和有效性。据我们所知，这是第一个将强大的图神经网络概念扩展到黎曼流形的研究，为双曲图学习领域的未来进步铺平了道路。我们论文的代码可以在https://github.com/Deceptrax123/LGIN上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Deceptrax123/LGIN&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce the Lorentzian Graph Isomorphic Network (LGIN), a novel graphneural network (GNN) designed to operate in hyperbolic spaces, leveraging theLorentzian model to enhance graph representation learning. Existing GNNsprimarily operate in Euclidean spaces, which can limit their ability to capturehierarchical and multi-relational structures inherent to complex graphs. LGINaddresses this by incorporating curvature-aware aggregation functions thatpreserve the Lorentzian metric tensor, ensuring embeddings remain constrainedwithin the hyperbolic space by proposing a new update rule that effectivelycaptures both local neighborhood interactions and global structural properties,enabling LGIN to distinguish non-isomorphic graphs with expressiveness at leastas powerful as the Weisfeiler-Lehman test. Through extensive evaluation acrossnine benchmark datasets, including molecular and protein structures, LGINconsistently outperforms or matches state-of-the-art GNNs, demonstrating itsrobustness and efficacy in modeling complex graph structures. To the best ofour knowledge, this is the first study to extend the concept of a powerfulgraph neural network to Riemannian manifolds, paving the way for futureadvancements in hyperbolic graph learning. The code for our paper can be foundat https://github.com/Deceptrax123/LGIN.</description>
      <author>example@mail.com (Srinitish Srinivasan, Omkumar CU)</author>
      <guid isPermaLink="false">2504.00142v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Deep Graph Reinforcement Learning for UAV-Enabled Multi-User Secure Communications</title>
      <link>http://arxiv.org/abs/2504.01446v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IEEE TMC&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度图强化学习的框架，用于实现无人机（UAV）驱动的多用户安全通信，以提高无线通信中的物理层安全。&lt;h4&gt;背景&lt;/h4&gt;无人机具有灵活的移动性，有望增强无线通信的物理层安全，但适应这种高网络动态性的高效安全设计颇具挑战。&lt;h4&gt;目的&lt;/h4&gt;通过提出一种深度图强化学习框架，解决无人机驱动的多用户安全通信问题。&lt;h4&gt;方法&lt;/h4&gt;将安全波束成形重新解释为图神经网络（GNN）学习任务，通过消息传递机制管理用户之间的相互干扰。利用基于GNN的安全波束成形来指导无人机部署策略的更新。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，该方法实现了接近最优的安全性能，并显著提高了策略确定的效率。深度图强化学习框架提供了一种可扩展的解决方案，适用于各种网络场景和配置。&lt;h4&gt;结论&lt;/h4&gt;该框架为无人机通信中的信息安全提供了坚实的基础，并能够适应不同的网络环境和配置。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While unmanned aerial vehicles (UAVs) with flexible mobility are envisionedto enhance physical layer security in wireless communications, the efficientsecurity design that adapts to such high network dynamics is ratherchallenging. The conventional approaches extended from optimizationperspectives are usually quite involved, especially when jointly consideringfactors in different scales such as deployment and transmission in UAV-relatedscenarios. In this paper, we address the UAV-enabled multi-user securecommunications by proposing a deep graph reinforcement learning framework.Specifically, we reinterpret the security beamforming as a graph neural network(GNN) learning task, where mutual interference among users is managed throughthe message-passing mechanism. Then, the UAV deployment is obtained throughsoft actor-critic reinforcement learning, where the GNN-based securitybeamforming is exploited to guide the deployment strategy update. Simulationresults demonstrate that the proposed approach achieves near-optimal securityperformance and significantly enhances the efficiency of strategydetermination. Moreover, the deep graph reinforcement learning framework offersa scalable solution, adaptable to various network scenarios and configurations,establishing a robust basis for information security in UAV-enabledcommunications.</description>
      <author>example@mail.com (Xiao Tang, Kexin Zhao, Chao Shen, Qinghe Du, Yichen Wang, Dusit Niyato, Zhu Han)</author>
      <guid isPermaLink="false">2504.01446v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>TransientTables: Evaluating LLMs' Reasoning on Temporally Evolving Semi-structured Tables</title>
      <link>http://arxiv.org/abs/2504.01879v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 Pages. 21 Tables, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了人类在科学和社会进步中理解事件时间序列的能力，并提出了一个名为TRANSIENTTABLES的数据集，用于评估大型语言模型（LLMs）的时间推理能力。&lt;h4&gt;背景&lt;/h4&gt;人类不断发现新事物，理解导致这些突破的事件时间序列对于科学和社会的进步至关重要。然而，LLMs通常在静态数据集上训练，限制了它们进行有效时间推理的能力。&lt;h4&gt;目的&lt;/h4&gt;评估LLMs的时间推理能力，并介绍一种基于模板的问答生成流程，利用LLMs优化模板和问题。&lt;h4&gt;方法&lt;/h4&gt;构建了包含3,971个问题的TRANSIENTTABLES数据集，涵盖14,000多个表格和1,238个实体，跨越多个时间段。使用最先进的LLMs建立基准，并引入了以任务分解为中心的新型建模策略。&lt;h4&gt;主要发现&lt;/h4&gt;TRANSIENTTABLES数据集和基于模板的问答生成流程有助于提升LLMs的时间推理能力。&lt;h4&gt;结论&lt;/h4&gt;通过TRANSIENTTABLES数据集和新型建模策略，可以增强LLMs的时间推理能力，为科学和社会进步提供支持。&lt;h4&gt;翻译&lt;/h4&gt;Humans continuously make new discoveries, and understanding temporal sequence of events leading to these breakthroughs is essential for advancing science and society. This ability to reason over time allows us to identify future steps and understand the effects of financial and political decisions on our lives. However, large language models (LLMs) are typically trained on static datasets, limiting their ability to perform effective temporal reasoning. To assess the temporal reasoning capabilities of LLMs, we present the TRANSIENTTABLES dataset, which comprises 3,971 questions derived from over 14,000 tables, spanning 1,238 entities across multiple time periods. We introduce a template-based question-generation pipeline that harnesses LLMs to refine both templates and questions. Additionally, we establish baseline results using state-of-the-art LLMs to create a benchmark. We also introduce novel modeling strategies centered around task decomposition, enhancing LLM performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans continuously make new discoveries, and understanding temporal sequenceof events leading to these breakthroughs is essential for advancing science andsociety. This ability to reason over time allows us to identify future stepsand understand the effects of financial and political decisions on our lives.However, large language models (LLMs) are typically trained on static datasets,limiting their ability to perform effective temporal reasoning. To assess thetemporal reasoning capabilities of LLMs, we present the TRANSIENTTABLESdataset, which comprises 3,971 questions derived from over 14,000 tables,spanning 1,238 entities across multiple time periods. We introduce atemplate-based question-generation pipeline that harnesses LLMs to refine bothtemplates and questions. Additionally, we establish baseline results usingstate-of-the-art LLMs to create a benchmark. We also introduce novel modelingstrategies centered around task decomposition, enhancing LLM performance.</description>
      <author>example@mail.com (Abhilash Shankarampeta, Harsh Mahajan, Tushar Kataria, Dan Roth, Vivek Gupta)</author>
      <guid isPermaLink="false">2504.01879v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Refining Interactions: Enhancing Anisotropy in Graph Neural Networks with Language Semantics</title>
      <link>http://arxiv.org/abs/2504.01429v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICME 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LanSAGNN的框架，通过整合大型语言模型（LLMs）和图神经网络（GNNs）来增强文本属性图（TAGs）的能力，通过改进模型结构提升了LLMs在图相关任务中的效果。&lt;h4&gt;背景&lt;/h4&gt;现有的方法将图结构的文本描述或相邻节点的文本直接输入到LLMs中，但这种方法往往导致LLMs将结构信息简单地视为一般上下文文本，限制了其在图相关任务中的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出LanSAGNN框架，将各向异性GNNs的概念扩展到自然语言层面，利用LLMs提取节点对之间的定制语义信息，有效捕捉节点关系中的独特交互。&lt;h4&gt;方法&lt;/h4&gt;引入了LanSAGNN框架，并提出了一个高效的二层LLMs微调架构，以更好地将LLMs的输出与图任务对齐。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，LanSAGNN在不增加复杂性的同时显著提升了基于LLM的方法，并显示出对干扰的强大鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;LanSAGNN框架能够有效增强LLM在图相关任务中的表现，为文本属性图的处理提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of Large Language Models (LLMs) with Graph Neural Networks(GNNs) has recently been explored to enhance the capabilities of Text AttributeGraphs (TAGs). Most existing methods feed textual descriptions of the graphstructure or neighbouring nodes' text directly into LLMs. However, theseapproaches often cause LLMs to treat structural information simply as generalcontextual text, thus limiting their effectiveness in graph-related tasks. Inthis paper, we introduce LanSAGNN (Language Semantic Anisotropic Graph NeuralNetwork), a framework that extends the concept of anisotropic GNNs to thenatural language level. This model leverages LLMs to extract tailor-madesemantic information for node pairs, effectively capturing the uniqueinteractions within node relationships. In addition, we propose an efficientdual-layer LLMs finetuning architecture to better align LLMs' outputs withgraph tasks. Experimental results demonstrate that LanSAGNN significantlyenhances existing LLM-based methods without increasing complexity while alsoexhibiting strong robustness against interference.</description>
      <author>example@mail.com (Zhaoxing Li, Xiaoming Zhang, Haifeng Zhang, Chengxiang Liu)</author>
      <guid isPermaLink="false">2504.01429v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Scene-Centric Unsupervised Panoptic Segmentation</title>
      <link>http://arxiv.org/abs/2504.01955v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear at CVPR 2025. Christoph Reich and Oliver Hahn - both  authors contributed equally. Code: https://github.com/visinf/cups Project  page: https://visinf.github.io/cups/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种无监督的全景分割方法，无需人工标注数据，直接在场景中心图像上进行训练，通过结合视觉表示、深度和运动线索来获得高分辨率的全景伪标签，显著提高了全景分割质量。&lt;h4&gt;背景&lt;/h4&gt;无监督全景分割旨在不依赖人工标注数据，对图像进行语义区域和对象实例的分割。&lt;h4&gt;目的&lt;/h4&gt;消除对象中心训练数据的需要，实现复杂场景的无监督理解。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的无监督全景方法，该方法直接在场景中心图像上进行训练，并利用伪标签训练和全景自训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在复杂场景的全景分割上取得了显著的性能提升，例如在Cityscapes数据集上，PQ指标比最近的最新无监督全景分割方法提高了9.4个百分点。&lt;h4&gt;结论&lt;/h4&gt;该方法无需人工标注，能够准确预测复杂场景的全景分割，为无监督全景分割提供了一种新的有效途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised panoptic segmentation aims to partition an image intosemantically meaningful regions and distinct object instances without trainingon manually annotated data. In contrast to prior work on unsupervised panopticscene understanding, we eliminate the need for object-centric training data,enabling the unsupervised understanding of complex scenes. To that end, wepresent the first unsupervised panoptic method that directly trains onscene-centric imagery. In particular, we propose an approach to obtainhigh-resolution panoptic pseudo labels on complex scene-centric data, combiningvisual representations, depth, and motion cues. Utilizing both pseudo-labeltraining and a panoptic self-training strategy yields a novel approach thataccurately predicts panoptic segmentation of complex scenes without requiringany human annotations. Our approach significantly improves panoptic quality,e.g., surpassing the recent state of the art in unsupervised panopticsegmentation on Cityscapes by 9.4% points in PQ.</description>
      <author>example@mail.com (Oliver Hahn, Christoph Reich, Nikita Araslanov, Daniel Cremers, Christian Rupprecht, Stefan Roth)</author>
      <guid isPermaLink="false">2504.01955v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Zero-Shot 4D Lidar Panoptic Segmentation</title>
      <link>http://arxiv.org/abs/2504.00848v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SAL-4D的新方法，用于在Lidar中进行零样本4D分割和识别任意物体，以促进具身导航的发展。&lt;h4&gt;背景&lt;/h4&gt;零样本4D分割和识别在Lidar中对于具身导航至关重要，其应用范围包括流式感知、语义映射和定位。&lt;h4&gt;目的&lt;/h4&gt;克服由于数据集缺乏多样性和标注规模导致的挑战，提出一种适用于时空场景理解的方法。&lt;h4&gt;方法&lt;/h4&gt;SAL-4D方法利用多模态机器人传感器设置，结合视频对象分割（VOS）的最新进展和现成的视觉-语言基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用VOS模型对短视频序列中的tracklets进行伪标签，并用序列级CLIP tokens进行标注，然后利用校准的多模态感官设置将它们提升到4D Lidar空间，SAL-4D在3D零样本Lidar全景分割（LPS）上优于之前的成果，并解锁了零样本4D-LPS。&lt;h4&gt;结论&lt;/h4&gt;SAL-4D方法在3D零样本Lidar全景分割上取得了显著成果，为Lidar中的零样本4D分割和识别提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Zero-shot 4D segmentation and recognition of arbitrary objects in Lidar iscrucial for embodied navigation, with applications ranging from streamingperception to semantic mapping and localization. However, the primary challengein advancing research and developing generalized, versatile methods forspatio-temporal scene understanding in Lidar lies in the scarcity of datasetsthat provide the necessary diversity and scale of annotations.To overcome thesechallenges, we propose SAL-4D (Segment Anything in Lidar--4D), a method thatutilizes multi-modal robotic sensor setups as a bridge to distill recentdevelopments in Video Object Segmentation (VOS) in conjunction withoff-the-shelf Vision-Language foundation models to Lidar. We utilize VOS modelsto pseudo-label tracklets in short video sequences, annotate these trackletswith sequence-level CLIP tokens, and lift them to the 4D Lidar space usingcalibrated multi-modal sensory setups to distill them to our SAL-4D model. Dueto temporal consistent predictions, we outperform prior art in 3D Zero-ShotLidar Panoptic Segmentation (LPS) over $5$ PQ, and unlock Zero-Shot 4D-LPS.</description>
      <author>example@mail.com (Yushan Zhang, Aljoša Ošep, Laura Leal-Taixé, Tim Meinhardt)</author>
      <guid isPermaLink="false">2504.00848v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Flexible and Explainable Graph Analysis for EEG-based Alzheimer's Disease Classification</title>
      <link>http://arxiv.org/abs/2504.01329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了阿尔茨海默病，这是一种导致记忆力、推理能力和行为能力下降的神经退行性疾病。通过使用脑电图（EEG）数据，研究者提出了一个灵活且可解释的门控图卷积网络（GGCN）结合多目标树结构帕累托估计器（MOTPE）超参数调优方法，以有效识别阿尔茨海默病患者。&lt;h4&gt;背景&lt;/h4&gt;阿尔茨海默病是一种常见的痴呆症，其病因尚在探索中，目前没有一种能够解释每个患者病理的全能理论。早期干预已被证明对管理症状和减缓疾病进展有效。&lt;h4&gt;目的&lt;/h4&gt;通过提出一种新的算法，旨在提高阿尔茨海默病患者的识别准确性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;研究者使用了脑电图（EEG）数据，结合深度学习和图神经网络方法，并提出了一个灵活的GGCN模型，配合MOTPE超参数调优。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在区分健康人和阿尔茨海默病患者方面表现出高效率，其接收者操作特征（ROC）得分超过0.9，并在不同频率带的脑电图信号功率谱密度（PSD）上区分了中度至重度痴呆患者与健康个体。&lt;h4&gt;结论&lt;/h4&gt;该研究不仅提高了识别准确率，还增强了嵌入邻接矩阵的可解释性，揭示了阿尔茨海默病患者与健康个体在大脑额叶和顶叶区域之间的连接差异。&lt;h4&gt;翻译&lt;/h4&gt;Alzheimer's Disease is a progressive neurological disorder that is one of the most common forms of dementia. It leads to a decline in memory, reasoning ability, and behavior, especially in older people. The cause of Alzheimer's Disease is still under exploration and there is no all-inclusive theory that can explain the pathologies in each individual patient. Nevertheless, early intervention has been found to be effective in managing symptoms and slowing down the disease's progression. Recent research has utilized electroencephalography (EEG) data to identify biomarkers that distinguish Alzheimer's Disease patients from healthy individuals. Prior studies have used various machine learning methods, including deep learning and graph neural networks, to examine electroencephalography-based signals for identifying Alzheimer's Disease patients. In our research, we proposed a Flexible and Explainable Gated Graph Convolutional Network (GGCN) with Multi-Objective Tree-Structured Parzen Estimator (MOTPE) hyperparameter tuning. This provides a flexible solution that efficiently identifies the optimal number of GGCN blocks to achieve the optimized precision, specificity, and recall outcomes, as well as the optimized area under the Receiver Operating Characteristic (AUC). Our findings demonstrated a high efficacy with an over 0.9 Receiver Operating Characteristic score, alongside precision, specificity, and recall scores in distinguishing health control with Alzheimer's Disease patients in Moderate to Severe Dementia using the power spectrum density (PSD) of electroencephalography signals across various frequency bands. Moreover, our research enhanced the interpretability of the embedded adjacency matrices, revealing connectivity differences in frontal and parietal brain regions between Alzheimer's patients and healthy individuals.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Alzheimer's Disease is a progressive neurological disorder that is one of themost common forms of dementia. It leads to a decline in memory, reasoningability, and behavior, especially in older people. The cause of Alzheimer'sDisease is still under exploration and there is no all-inclusive theory thatcan explain the pathologies in each individual patient. Nevertheless, earlyintervention has been found to be effective in managing symptoms and slowingdown the disease's progression. Recent research has utilizedelectroencephalography (EEG) data to identify biomarkers that distinguishAlzheimer's Disease patients from healthy individuals. Prior studies have usedvarious machine learning methods, including deep learning and graph neuralnetworks, to examine electroencephalography-based signals for identifyingAlzheimer's Disease patients. In our research, we proposed a Flexible andExplainable Gated Graph Convolutional Network (GGCN) with Multi-ObjectiveTree-Structured Parzen Estimator (MOTPE) hyperparameter tuning. This provides aflexible solution that efficiently identifies the optimal number of GGCN blocksto achieve the optimized precision, specificity, and recall outcomes, as wellas the optimized area under the Receiver Operating Characteristic (AUC). Ourfindings demonstrated a high efficacy with an over 0.9 Receiver OperatingCharacteristic score, alongside precision, specificity, and recall scores indistinguishing health control with Alzheimer's Disease patients in Moderate toSevere Dementia using the power spectrum density (PSD) ofelectroencephalography signals across various frequency bands. Moreover, ourresearch enhanced the interpretability of the embedded adjacency matrices,revealing connectivity differences in frontal and parietal brain regionsbetween Alzheimer's patients and healthy individuals.</description>
      <author>example@mail.com (Jing Wang, Jun-En Ding, Feng Liu, Elisa Kallioniemi, Shuqiang Wang, Wen-Xiang Tsai, Albert C. Yang)</author>
      <guid isPermaLink="false">2504.01329v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>All Patches Matter, More Patches Better: Enhance AI-Generated Image Detection via Panoptic Patch Learning</title>
      <link>http://arxiv.org/abs/2504.01396v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于AI生成图像检测的方法，通过分析确定了两个关键原则：所有图像块都重要，更多的图像块能提高检测的鲁棒性；并针对训练中存在的少数图像块偏差问题，提出了全景图像块学习（PPL）框架。&lt;h4&gt;背景&lt;/h4&gt;AI生成图像（AIGI）数量的指数增长，对鲁棒和通用的检测方法提出了迫切需求。&lt;h4&gt;目的&lt;/h4&gt;提出有效的AI生成图像检测方法。&lt;h4&gt;方法&lt;/h4&gt;提出两个关键原则：所有图像块都重要，更多的图像块能提高检测的鲁棒性；针对训练中存在的偏差问题，提出了全景图像块学习（PPL）框架，包括随机替换图像块和图像块对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;发现训练的检测器往往存在少数图像块偏差，即偏好学习有限区域中的明显特征，而忽略了更广泛的特征分布。&lt;h4&gt;结论&lt;/h4&gt;通过实验验证了PPL框架的有效性，能够提高AI生成图像检测的鲁棒性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;The exponential growth of AI-generated images (AIGIs) underscores the urgent need for robust and generalizable detection methods. In this paper, we establish two key principles for AIGI detection through systematic analysis: (1) All Patches Matter: Unlike conventional image classification where discriminative features concentrate on object-centric regions, each patch in AIGIs inherently contains synthetic artifacts due to the uniform generation process, suggesting that every patch serves as an important artifact source for detection. (2) More Patches Better: Leveraging distributed artifacts across more patches improves detection robustness by capturing complementary forensic evidence and reducing over-reliance on specific patches, thereby enhancing robustness and generalization. However, our counterfactual analysis reveals an undesirable phenomenon: naively trained detectors often exhibit a Few-Patch Bias, discriminating between real and synthetic images based on minority patches. We identify Lazy Learner as the root cause: detectors preferentially learn conspicuous artifacts in limited patches while neglecting broader artifact distributions. To address this bias, we propose the Panoptic Patch Learning (PPL) framework, involving: (1) Random Patch Replacement that randomly substitutes synthetic patches with real counterparts to compel models to identify artifacts in underutilized regions, encouraging the broader use of more patches; (2) Patch-wise Contrastive Learning that enforces consistent discriminative capability across all patches, ensuring uniform utilization of all patches. Extensive experiments across two different settings on several benchmarks verify the effectiveness of our approach.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The exponential growth of AI-generated images (AIGIs) underscores the urgentneed for robust and generalizable detection methods. In this paper, weestablish two key principles for AIGI detection through systematic analysis:\textbf{(1) All Patches Matter:} Unlike conventional image classification wherediscriminative features concentrate on object-centric regions, each patch inAIGIs inherently contains synthetic artifacts due to the uniform generationprocess, suggesting that every patch serves as an important artifact source fordetection. \textbf{(2) More Patches Better}: Leveraging distributed artifactsacross more patches improves detection robustness by capturing complementaryforensic evidence and reducing over-reliance on specific patches, therebyenhancing robustness and generalization. However, our counterfactual analysisreveals an undesirable phenomenon: naively trained detectors often exhibit a\textbf{Few-Patch Bias}, discriminating between real and synthetic images basedon minority patches. We identify \textbf{Lazy Learner} as the root cause:detectors preferentially learn conspicuous artifacts in limited patches whileneglecting broader artifact distributions. To address this bias, we propose the\textbf{P}anoptic \textbf{P}atch \textbf{L}earning (PPL) framework, involving:(1) Random Patch Replacement that randomly substitutes synthetic patches withreal counterparts to compel models to identify artifacts in underutilizedregions, encouraging the broader use of more patches; (2) Patch-wiseContrastive Learning that enforces consistent discriminative capability acrossall patches, ensuring uniform utilization of all patches. Extensive experimentsacross two different settings on several benchmarks verify the effectiveness ofour approach.</description>
      <author>example@mail.com (Zheng Yang, Ruoxin Chen, Zhiyuan Yan, Ke-Yue Zhang, Xinghe Fu, Shuang Wu, Xiujun Shu, Taiping Yao, Junchi Yan, Shouhong Ding, Xi Li)</author>
      <guid isPermaLink="false">2504.01396v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Privacy-Preserving Transfer Learning for Community Detection using Locally Distributed Multiple Networks</title>
      <link>http://arxiv.org/abs/2504.00890v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于光谱聚类的新的迁移学习方法TransNet，用于网络数据的社区检测。&lt;h4&gt;背景&lt;/h4&gt;目标网络的聚类性能可以通过使用辅助源网络来提高，这些源网络异构、隐私保护且分散存储在各个来源。&lt;h4&gt;目的&lt;/h4&gt;改善目标网络的聚类性能。&lt;h4&gt;方法&lt;/h4&gt;使用随机响应机制对本地存储网络的边进行扰动以实现差分隐私。允许源网络具有不同的隐私保护和异构水平。提出了一种自适应加权方法来聚合源网络的特征空间，并引入自适应权重以结合隐私和异构的影响。提出了一种正则化方法，结合源网络的加权平均特征空间和目标网络的特征空间，以实现它们之间的最佳平衡。&lt;h4&gt;主要发现&lt;/h4&gt;自适应加权方法具有误差界限或然属性，即估计特征空间的误差界限仅取决于信息丰富的源网络。TransNet的表现优于仅使用目标网络的估计器和仅使用加权源网络的估计器。&lt;h4&gt;结论&lt;/h4&gt;TransNet在社区检测方面表现出色，并优于传统的估计方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为TransNet的新方法，基于光谱聚类进行迁移学习，用于网络数据的社区检测。该方法旨在通过使用辅助源网络（这些网络异构、隐私保护且分散存储）来提高目标网络的聚类性能。为了实现差分隐私，对本地存储网络的边进行了扰动。提出了一种自适应加权方法来聚合源网络的特征空间，并引入自适应权重以结合隐私和异构的影响。此外，还提出了一种正则化方法，结合源网络的加权平均特征空间和目标网络的特征空间。理论分析表明，自适应加权方法具有误差界限或然属性，并且TransNet在性能上优于仅使用目标网络或仅使用加权源网络的估计器。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper develops a new spectral clustering-based method called TransNetfor transfer learning in community detection of network data. Our goal is toimprove the clustering performance of the target network using auxiliary sourcenetworks, which are heterogeneous, privacy-preserved, and locally stored acrossvarious sources. The edges of each locally stored network are perturbed usingthe randomized response mechanism to achieve differential privacy. Notably, weallow the source networks to have distinct privacy-preserving and heterogeneitylevels as often desired in practice. To better utilize the information from thesource networks, we propose a novel adaptive weighting method to aggregate theeigenspaces of the source networks multiplied by adaptive weights chosen toincorporate the effects of privacy and heterogeneity. We propose aregularization method that combines the weighted average eigenspace of thesource networks with the eigenspace of the target network to achieve an optimalbalance between them. Theoretically, we show that the adaptive weighting methodenjoys the error-bound-oracle property in the sense that the error bound of theestimated eigenspace only depends on informative source networks. We alsodemonstrate that TransNet performs better than the estimator using only thetarget network and the estimator using only the weighted source networks.</description>
      <author>example@mail.com (Xiao Guo, Xuming He, Xiangyu Chang, Shujie Ma)</author>
      <guid isPermaLink="false">2504.00890v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Spatial-R1: Enhancing MLLMs in Video Spatial Reasoning</title>
      <link>http://arxiv.org/abs/2504.01805v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为Spatial-R1的方法，旨在提升多模态大型语言模型（MLLMs）在视频理解中的空间推理能力，通过定制化数据集和特定任务优化策略，显著提升了模型在视频空间推理任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;增强MLLMs在视频理解中的空间推理能力对于视频分析至关重要，但目前这一任务仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出Spatial-R1方法，以改善MLLMs在视频理解中的空间推理能力。&lt;h4&gt;方法&lt;/h4&gt;1. 创建了SR数据集，这是一个从ScanNet中收集的新视频空间推理数据集，包含了自动生成的跨七种任务类型的问答对。2. 应用了特定任务的组相对策略优化（GRPO）进行微调。3. 使用GRPO在SR数据集上训练Qwen2.5-VL-7B-Instruct模型。&lt;h4&gt;主要发现&lt;/h4&gt;Spatial-R1在VSI-Bench基准测试中显著提升了性能，比基线模型提高了7.4%，并且优于当代的强大模型。&lt;h4&gt;结论&lt;/h4&gt;这项工作验证了特定数据定制和优化技术对于提高视频MLLMs中复杂空间推理的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Enhancing the spatial reasoning capabilities of Multi-modal Large Language Models (MLLMs) for video understanding is crucial yet challenging. We present Spatial-R1, a targeted approach involving two key contributions: the curation of SR, a new video spatial reasoning dataset from ScanNet with automatically generated QA pairs across seven task types, and the application of Task-Specific Group Relative Policy Optimization (GRPO) for fine-tuning. By training the Qwen2.5-VL-7B-Instruct model on SR using GRPO, Spatial-R1 significantly advances performance on the VSI-Bench benchmark, achieving a 7.4% gain over the baseline and outperforming strong contemporary models. This work validates the effectiveness of specialized data curation and optimization techniques for improving complex spatial reasoning in video MLLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Enhancing the spatial reasoning capabilities of Multi-modal Large LanguageModels (MLLMs) for video understanding is crucial yet challenging. We presentSpatial-R1, a targeted approach involving two key contributions: the curationof SR, a new video spatial reasoning dataset from ScanNet with automaticallygenerated QA pairs across seven task types, and the application ofTask-Specific Group Relative Policy Optimization (GRPO) for fine-tuning. Bytraining the Qwen2.5-VL-7B-Instruct model on SR using GRPO, Spatial-R1significantly advances performance on the VSI-Bench benchmark, achieving a7.4\% gain over the baseline and outperforming strong contemporary models. Thiswork validates the effectiveness of specialized data curation and optimizationtechniques for improving complex spatial reasoning in video MLLMs.</description>
      <author>example@mail.com (Kun Ouyang)</author>
      <guid isPermaLink="false">2504.01805v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Data-driven Optimization and Transfer Learning for Cellular Network Antenna Configurations</title>
      <link>http://arxiv.org/abs/2504.00825v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于数据的大规模蜂窝网络优化方法，以伦敦的生产蜂窝网络为案例研究，并使用Sionna射线追踪进行特定地点的信道传播建模。&lt;h4&gt;背景&lt;/h4&gt;论文针对大规模蜂窝网络优化问题，提出了一种基于数据的方法。&lt;h4&gt;目的&lt;/h4&gt;提高网络性能，优化基站天线倾斜和半功率波束宽度。&lt;h4&gt;方法&lt;/h4&gt;使用Sionna射线追踪技术进行信道传播建模，并通过转移学习实现模型泛化。&lt;h4&gt;主要发现&lt;/h4&gt;优化后的网络性能显著提升，10%-最差用户速率比3GPP基线提高了超过一倍。对于空中用户，发现配置可以使其中值速率提高五倍，同时不损害地面用户的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提高了网络性能，并通过转移学习实现了模型泛化。&lt;h4&gt;翻译&lt;/h4&gt;We propose a data-driven approach for large-scale cellular network optimization, using a production cellular network in London as a case study and employing Sionna ray tracing for site-specific channel propagation modeling. We optimize base station antenna tilts and half-power beamwidths, resulting in more than double the 10%-worst user rates compared to a 3GPP baseline. In scenarios involving aerial users, we identify configurations that increase their median rates fivefold without compromising ground user performance. We further demonstrate the efficacy of model generalization through transfer learning, leveraging available data from a scenario source to predict the optimal solution for a scenario target within a similar number of iterations, without requiring a new initial dataset, and with a negligible performance loss.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a data-driven approach for large-scale cellular networkoptimization, using a production cellular network in London as a case study andemploying Sionna ray tracing for site-specific channel propagation modeling. Weoptimize base station antenna tilts and half-power beamwidths, resulting inmore than double the 10\%-worst user rates compared to a 3GPP baseline. Inscenarios involving aerial users, we identify configurations that increasetheir median rates fivefold without compromising ground user performance. Wefurther demonstrate the efficacy of model generalization through transferlearning, leveraging available data from a scenario source to predict theoptimal solution for a scenario target within a similar number of iterations,without requiring a new initial dataset, and with a negligible performanceloss.</description>
      <author>example@mail.com (Mohamed Benzaghta, Giovanni Geraci, David López-Pérez, Alvaro Valcarce)</author>
      <guid isPermaLink="false">2504.00825v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>3DBonsai: Structure-Aware Bonsai Modeling Using Conditioned 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2504.01619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICME 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了3DBonsai，一种新的文本到3D bonsai生成框架，通过结合3D先验和2D扩散技术生成具有复杂结构的3D bonsai。&lt;h4&gt;背景&lt;/h4&gt;现有方法利用的3D先验缺乏详细的复杂结构信息，限制了它们生成复杂结构，如盆景。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够生成具有复杂结构的3D bonsai的新框架。&lt;h4&gt;方法&lt;/h4&gt;设计了一个可训练的3D空间占用算法生成盆景结构，并通过随机采样和点云增强作为3D高斯先验进行增强。引入了两种盆景生成管道：精细结构条件生成和粗略结构条件生成。同时，编译了一个统一的2D和3D中式盆景数据集。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，3DBonsai在结构感知3D bonsai生成方面显著优于现有方法，提供了一个新的基准。&lt;h4&gt;结论&lt;/h4&gt;3DBonsai是一个高效的结构感知3D bonsai生成框架，有望为3D bonsai的生成提供新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in text-to-3D generation have shown remarkable results byleveraging 3D priors in combination with 2D diffusion. However, previousmethods utilize 3D priors that lack detailed and complex structuralinformation, limiting them to generating simple objects and presentingchallenges for creating intricate structures such as bonsai. In this paper, wepropose 3DBonsai, a novel text-to-3D framework for generating 3D bonsai withcomplex structures. Technically, we first design a trainable 3D spacecolonization algorithm to produce bonsai structures, which are then enhancedthrough random sampling and point cloud augmentation to serve as the 3DGaussian priors. We introduce two bonsai generation pipelines with distinctstructural levels: fine structure conditioned generation, which initializes 3DGaussians using a 3D structure prior to produce detailed and complex bonsai,and coarse structure conditioned generation, which employs a multi-viewstructure consistency module to align 2D and 3D structures. Moreover, we havecompiled a unified 2D and 3D Chinese-style bonsai dataset. Our experimentalresults demonstrate that 3DBonsai significantly outperforms existing methods,providing a new benchmark for structure-aware 3D bonsai generation.</description>
      <author>example@mail.com (Hao Wu, Hao Wang, Ruochong Li, Xuran Ma, Hui Xiong)</author>
      <guid isPermaLink="false">2504.01619v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning in Financial Time Series with Gramian Angular Field</title>
      <link>http://arxiv.org/abs/2504.00378v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在金融分析中，时间序列建模因数据稀缺而受到的限制，并提出了使用迁移学习来缓解这一问题。通过引入Gramian Angular Field (GAF) 变换来优化时间序列相似性函数，提高了迁移学习中的源域选择，并通过深度神经网络（DNN）和长短期记忆（LSTM）网络进行了广泛实验，结果表明GAF相似性函数显著降低了预测误差。&lt;h4&gt;背景&lt;/h4&gt;在金融分析中，时间序列建模常因数据稀缺而受限，而迁移学习通过利用相似领域的数据进行缓解，但选择合适的源域至关重要。&lt;h4&gt;目的&lt;/h4&gt;通过引入GAF变换来优化源域选择，提高迁移学习在时间序列建模中的效果。&lt;h4&gt;方法&lt;/h4&gt;评估了多种基线相似性函数，包括基本和最先进的（SOTA）函数，并使用DNN和LSTM网络进行了大量实验。&lt;h4&gt;主要发现&lt;/h4&gt;基于GAF的相似性函数显著减少了预测误差，特别是Coral（GAF）对DNN和CMD（GAF）对LSTM的性能表现突出。&lt;h4&gt;结论&lt;/h4&gt;GAF相似性函数在复杂金融环境中有效，能够显著提高迁移学习的时间序列建模性能。&lt;h4&gt;翻译&lt;/h4&gt;在金融分析中，时间序列建模常常受到数据稀缺的限制，这限制了神经网络模型泛化的能力。迁移学习通过利用相似领域的数据进行缓解，但选择适当的源域是至关重要的。本研究通过引入Gramian Angular Field（GAF）变换来改进时间序列相似性函数，从而增强了迁移学习中的源域选择。我们评估了包括基本和最先进的（SOTA）函数在内的广泛基线相似性函数，并使用深度神经网络（DNN）和长短期记忆（LSTM）网络进行了大量实验。结果表明，基于GAF的相似性函数显著降低了预测误差。值得注意的是，Coral（GAF）对DNN和CMD（GAF）对LSTM始终表现出优异的性能，突出了它们在复杂金融环境中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In financial analysis, time series modeling is often hampered by datascarcity, limiting neural network models' ability to generalize. Transferlearning mitigates this by leveraging data from similar domains, but selectingappropriate source domains is crucial to avoid negative transfer. This studyenhances source domain selection in transfer learning by introducing GramianAngular Field (GAF) transformations to improve time series similarityfunctions. We evaluate a comprehensive range of baseline similarity functions,including both basic and state-of-the-art (SOTA) functions, and performextensive experiments with Deep Neural Networks (DNN) and Long Short-TermMemory (LSTM) networks. The results demonstrate that GAF-based similarityfunctions significantly reduce prediction errors. Notably, Coral (GAF) for DNNand CMD (GAF) for LSTM consistently deliver superior performance, highlightingtheir effectiveness in complex financial environments.</description>
      <author>example@mail.com (Hou-Wan Long, On-In Ho, Qi-Qiao He, Yain-Whar Si)</author>
      <guid isPermaLink="false">2504.00378v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Ross3D: Reconstructive Visual Instruction Tuning with 3D-Awareness</title>
      <link>http://arxiv.org/abs/2504.01901v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Ross3D的新方法，旨在通过引入3D意识来改进2D大模态模型在3D场景理解上的应用。&lt;h4&gt;背景&lt;/h4&gt;随着2D图像和视频的大模态模型（LMMs）的快速发展，研究者们开始尝试将这些模型应用于3D场景的解析，但缺乏大规模的3D视觉-语言数据集成为了主要障碍。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了一种新的视角，通过在训练过程中加入3D意识的视觉监督来改进2D LMMs。&lt;h4&gt;方法&lt;/h4&gt;Ross3D方法包括跨视图和全局视图重建。跨视图重建需要通过聚合来自其他视图的重叠信息来重建被遮挡的视图；全局视图重建则是通过聚合所有可用视图的信息来恢复鸟瞰图，从而提供整个场景的全面概述。&lt;h4&gt;主要发现&lt;/h4&gt;实证研究表明，Ross3D在多个3D场景理解基准测试中实现了最先进的性能。此外，半监督实验表明，该方法在利用大量未标记的3D视觉数据方面具有显著潜力。&lt;h4&gt;结论&lt;/h4&gt;Ross3D通过引入3D意识，显著提升了2D LMMs在3D场景理解上的表现，并为利用大规模未标记数据提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid development of Large Multimodal Models (LMMs) for 2D images andvideos has spurred efforts to adapt these models for interpreting 3D scenes.However, the absence of large-scale 3D vision-language datasets has posed asignificant obstacle. To address this issue, typical approaches focus oninjecting 3D awareness into 2D LMMs by designing 3D input-level scenerepresentations. This work provides a new perspective. We introducereconstructive visual instruction tuning with 3D-awareness (Ross3D), whichintegrates 3D-aware visual supervision into the training procedure.Specifically, it incorporates cross-view and global-view reconstruction. Theformer requires reconstructing masked views by aggregating overlappinginformation from other views. The latter aims to aggregate information from allavailable views to recover Bird's-Eye-View images, contributing to acomprehensive overview of the entire scene. Empirically, Ross3D achievesstate-of-the-art performance across various 3D scene understanding benchmarks.More importantly, our semi-supervised experiments demonstrate significantpotential in leveraging large amounts of unlabeled 3D vision-only data.</description>
      <author>example@mail.com (Haochen Wang, Yucheng Zhao, Tiancai Wang, Haoqiang Fan, Xiangyu Zhang, Zhaoxiang Zhang)</author>
      <guid isPermaLink="false">2504.01901v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>PRISM-0: A Predicate-Rich Scene Graph Generation Framework for Zero-Shot Open-Vocabulary Tasks</title>
      <link>http://arxiv.org/abs/2504.00844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PRISM-0是一种零样本开放词汇场景图生成框架，用于从视觉输入中提取结构化表示，以促进基于图像的理解和推理。&lt;h4&gt;背景&lt;/h4&gt;场景图生成（SGG）是从视觉输入中提取结构化表示的过程，尽管完全监督的SGG方法性能持续提升，但存在训练偏差问题。&lt;h4&gt;目的&lt;/h4&gt;克服训练偏差问题，提出PRISM-0框架，以实现零样本开放词汇的场景图生成。&lt;h4&gt;方法&lt;/h4&gt;PRISM-0采用自下而上的方法，通过基础模型来捕捉多样化的开放词汇谓词预测的全谱系。对象对被过滤后传递给视觉语言模型（VLM）生成描述性字幕，这些字幕用于提示大型语言模型（LLM）生成细粒度和粗粒度的谓词。谓词通过VQA模型进行验证，以提供最终的SGG。&lt;h4&gt;主要发现&lt;/h4&gt;PRISM-0可以丰富现有的SG数据集，如Visual Genome（VG），并通过实验证明其生成的场景图语义上有意义，能提高下游任务如图像标题和句子到图检索的性能。&lt;h4&gt;结论&lt;/h4&gt;PRISM-0的性能与最佳完全监督方法相当，是一种有效的场景图生成方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In Scene Graphs Generation (SGG) one extracts structured representation fromvisual inputs in the form of objects nodes and predicates connecting them. Thisfacilitates image-based understanding and reasoning for various downstreamtasks. Although fully supervised SGG approaches showed steady performanceimprovements, they suffer from a severe training bias. This is caused by theavailability of only small subsets of curated data and exhibits long-tailpredicate distribution issues with a lack of predicate diversity adverselyaffecting downstream tasks. To overcome this, we introduce PRISM-0, a frameworkfor zero-shot open-vocabulary SGG that bootstraps foundation models in abottom-up approach to capture the whole spectrum of diverse, open-vocabularypredicate prediction. Detected object pairs are filtered and passed to a VisionLanguage Model (VLM) that generates descriptive captions. These are used toprompt an LLM to generate fine-andcoarse-grained predicates for the pair. Thepredicates are then validated using a VQA model to provide a final SGG. Withthe modular and dataset-independent PRISM-0, we can enrich existing SG datasetssuch as Visual Genome (VG). Experiments illustrate that PRIMS-0 generatessemantically meaningful graphs that improve downstream tasks such as ImageCaptioning and Sentence-to-Graph Retrieval with a performance on par to thebest fully supervised methods.</description>
      <author>example@mail.com (Abdelrahman Elskhawy, Mengze Li, Nassir Navab, Benjamin Busam)</author>
      <guid isPermaLink="false">2504.00844v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Enhanced Cross-modal 3D Retrieval via Tri-modal Reconstruction</title>
      <link>http://arxiv.org/abs/2504.01476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICME 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多视图图像和点云的跨模态3D检索方法，通过联合表示3D形状，实现图像、点云和文本的三模态对齐，提高跨模态3D检索的性能。&lt;h4&gt;背景&lt;/h4&gt;跨模态3D检索是一个关键且具有挑战性的任务，目前的方法主要依赖于特定的3D表示（如点云），很少有方法利用2D-3D的一致性和互补关系，这限制了它们的性能。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在通过引入多视图图像和点云来共同表示3D形状，从而实现图像、点云和文本的三模态对齐，以增强跨模态3D检索。&lt;h4&gt;方法&lt;/h4&gt;本文提出了三模态重建来提高编码器的一般化能力。在点特征下，本文在文本特征的指导下重建图像特征，反之亦然。通过精细的2D-3D融合，将点云和多视图图像特征聚合为多模态嵌入，以增强几何和语义理解。同时，为了应对数据集中存在的噪声，本文采用硬负对比训练，强调具有更大重要性的更难负样本，从而得到鲁棒的判别嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;在Text2Shape数据集上的大量实验表明，本文的方法在形状到文本和文本到形状检索任务中显著优于之前的最佳方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过联合表示3D形状，有效地提高了跨模态3D检索的性能，为该领域的研究提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;Cross-modal 3D retrieval is a critical yet challenging task, aiming to achieve bi-directional retrieval between 3D and text modalities. Current methods predominantly rely on a certain 3D representation (e.g., point cloud), with few exploiting the 2D-3D consistency and complementary relationships, which constrains their performance. To bridge this gap, we propose to adopt multi-view images and point clouds to jointly represent 3D shapes, facilitating tri-modal alignment (i.e., image, point, text) for enhanced cross-modal 3D retrieval. Notably, we introduce tri-modal reconstruction to improve the generalization ability of encoders. Given point features, we reconstruct image features under the guidance of text features, and vice versa. With well-aligned point cloud and multi-view image features, we aggregate them as multi-modal embeddings through fine-grained 2D-3D fusion to enhance geometric and semantic understanding. Recognizing the significant noise in current datasets where many 3D shapes and texts share similar semantics, we employ hard negative contrastive training to emphasize harder negatives with greater significance, leading to robust discriminative embeddings. Extensive experiments on the Text2Shape dataset demonstrate that our method significantly outperforms previous state-of-the-art methods in both shape-to-text and text-to-shape retrieval tasks by a substantial margin.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-modal 3D retrieval is a critical yet challenging task, aiming toachieve bi-directional retrieval between 3D and text modalities. Currentmethods predominantly rely on a certain 3D representation (e.g., point cloud),with few exploiting the 2D-3D consistency and complementary relationships,which constrains their performance. To bridge this gap, we propose to adoptmulti-view images and point clouds to jointly represent 3D shapes, facilitatingtri-modal alignment (i.e., image, point, text) for enhanced cross-modal 3Dretrieval. Notably, we introduce tri-modal reconstruction to improve thegeneralization ability of encoders. Given point features, we reconstruct imagefeatures under the guidance of text features, and vice versa. With well-alignedpoint cloud and multi-view image features, we aggregate them as multimodalembeddings through fine-grained 2D-3D fusion to enhance geometric and semanticunderstanding. Recognizing the significant noise in current datasets where many3D shapes and texts share similar semantics, we employ hard negativecontrastive training to emphasize harder negatives with greater significance,leading to robust discriminative embeddings. Extensive experiments on theText2Shape dataset demonstrate that our method significantly outperformsprevious state-of-the-art methods in both shape-to-text and text-to-shaperetrieval tasks by a substantial margin.</description>
      <author>example@mail.com (Junlong Ren, Hao Wang)</author>
      <guid isPermaLink="false">2504.01476v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Neural Approaches to SAT Solving: Design Choices and Interpretability</title>
      <link>http://arxiv.org/abs/2504.01173v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对图神经网络在布尔可满足性问题上的应用进行了全面评估，并解释了模型如何泛化到不同实例的机制。&lt;h4&gt;背景&lt;/h4&gt;图神经网络被应用于解决布尔可满足性问题，并提出了新的训练改进方法。&lt;h4&gt;目的&lt;/h4&gt;评估图神经网络在布尔可满足性问题上的性能，并提出提高其性能的方法。&lt;h4&gt;方法&lt;/h4&gt;引入了新的最邻近赋值监督方法，以及将图神经网络扩展为扩散模型，并分析了嵌入空间模式和优化轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;变量子句图表示与循环神经网络更新相结合，在SAT赋值预测上取得了良好的精度，同时降低了计算需求。&lt;h4&gt;结论&lt;/h4&gt;这些网络在推理时间上能够有效地扩展到训练分布之外，这是通过测试时间缩放实验所证明的。&lt;h4&gt;翻译&lt;/h4&gt;在这项贡献中，我们提供了一个关于图神经网络应用于布尔可满足性问题的全面评估，并伴随对模型泛化到不同实例的机制的直观解释。我们引入了几个训练改进，特别是引入了一种新的最邻近赋值监督方法，该方法能够根据模型当前状态动态适应，显著提高了在具有较大解空间的问题上的性能。我们的实验证明了变量子句图表示与循环神经网络更新的适用性，这些方法在SAT赋值预测上取得了良好的精度，同时减少了计算需求。我们将基础图神经网络扩展为扩散模型，该模型促进了增量采样，并且可以有效地与单元传播等经典技术相结合。通过分析嵌入空间模式和优化轨迹，我们展示了这些网络隐式地执行了一个类似于MaxSAT的连续松弛的过程，提供了它们推理过程的可解释视图。这种理解指导了我们的设计选择，并解释了循环架构在推理时间上如何有效地扩展到训练分布之外，这是通过测试时间缩放实验所证明的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this contribution, we provide a comprehensive evaluation of graph neuralnetworks applied to Boolean satisfiability problems, accompanied by anintuitive explanation of the mechanisms enabling the model to generalize todifferent instances. We introduce several training improvements, particularly anovel closest assignment supervision method that dynamically adapts to themodel's current state, significantly enhancing performance on problems withlarger solution spaces. Our experiments demonstrate the suitability ofvariable-clause graph representations with recurrent neural network updates,which achieve good accuracy on SAT assignment prediction while reducingcomputational demands. We extend the base graph neural network into a diffusionmodel that facilitates incremental sampling and can be effectively combinedwith classical techniques like unit propagation. Through analysis of embeddingspace patterns and optimization trajectories, we show how these networksimplicitly perform a process very similar to continuous relaxations of MaxSAT,offering an interpretable view of their reasoning process. This understandingguides our design choices and explains the ability of recurrent architecturesto scale effectively at inference time beyond their training distribution,which we demonstrate with test-time scaling experiments.</description>
      <author>example@mail.com (David Mojžíšek, Jan Hůla, Ziwei Li, Ziyu Zhou, Mikoláš Janota)</author>
      <guid isPermaLink="false">2504.01173v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Prompt Instructed Zero Shot Composed Image Retrieval with Image-Only Data</title>
      <link>http://arxiv.org/abs/2504.00812v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图像检索方法，称为组合图像检索（CIR），它通过文本描述来检索与参考图像相匹配的图像。文章强调了利用大型语言模型（LLMs）代替人工标注以生成CIR训练数据的重要性，并介绍了一个名为InstructCIR的模型，该模型在零样本组合图像检索任务中表现优异。&lt;h4&gt;背景&lt;/h4&gt;传统的CIR模型依赖人工制作的包含参考图像、重构文本和目标图像的三元组数据。然而，人工制作三元组数据成本高昂，限制了CIR模型的扩展性。&lt;h4&gt;目的&lt;/h4&gt;旨在通过利用大型语言模型减少对人工标注的依赖，从而提高CIR模型训练的效率和可扩展性。&lt;h4&gt;方法&lt;/h4&gt;文章提出了一种使用大型语言模型（LLMs）生成CIR训练数据的方法，并引入了一个结合图像和文本模态的嵌入重构架构。&lt;h4&gt;主要发现&lt;/h4&gt;InstructCIR模型在CIRR和FashionIQ数据集上的零样本组合图像检索任务中优于现有方法，并且通过增加生成数据量，其性能接近监督基线。&lt;h4&gt;结论&lt;/h4&gt;利用大型语言模型可以有效地生成CIR训练数据，并显著提高CIR模型在零样本场景下的性能。&lt;h4&gt;翻译&lt;/h4&gt;组合图像检索（CIR）是检索与参考图像匹配的图像的任务，其中文本描述了参考图像的变化。传统的CIR模型依赖于包含参考图像、重构文本和目标图像的三元组数据。然而，制作这样的三元组数据通常需要人工干预，导致成本高昂。这一挑战阻碍了CIR模型训练的可扩展性，即使在大量未标记数据可用的情况下。随着基础模型的最近进展，我们倡导CIR训练范式的一个转变，其中人类标注可以被大型语言模型（LLMs）有效地替代。具体来说，我们证明了大型标题和语言模型在仅依赖于未标记图像集合生成CIR数据方面的能力。此外，我们引入了一个嵌入重构架构，该架构有效地结合了图像和文本模态。我们的模型，名为InstructCIR，在CIRR和FashionIQ数据集上的零样本组合图像检索任务中优于现有方法。此外，我们还证明了通过增加生成数据量，我们的零样本模型接近监督基线的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Composed Image Retrieval (CIR) is the task of retrieving images matching areference image augmented with a text, where the text describes changes to thereference image in natural language. Traditionally, models designed for CIRhave relied on triplet data containing a reference image, reformulation text,and a target image. However, curating such triplet data often necessitateshuman intervention, leading to prohibitive costs. This challenge has hinderedthe scalability of CIR model training even with the availability of abundantunlabeled data. With the recent advances in foundational models, we advocate ashift in the CIR training paradigm where human annotations can be efficientlyreplaced by large language models (LLMs). Specifically, we demonstrate thecapability of large captioning and language models in efficiently generatingdata for CIR only relying on unannotated image collections. Additionally, weintroduce an embedding reformulation architecture that effectively combinesimage and text modalities. Our model, named InstructCIR, outperformsstate-of-the-art methods in zero-shot composed image retrieval on CIRR andFashionIQ datasets. Furthermore, we demonstrate that by increasing the amountof generated data, our zero-shot model gets closer to the performance ofsupervised baselines.</description>
      <author>example@mail.com (Yiqun Duan, Sameera Ramasinghe, Stephen Gould, Ajanthan Thalaiyasingam)</author>
      <guid isPermaLink="false">2504.00812v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Efficient n-body simulations using physics informed graph neural networks</title>
      <link>http://arxiv.org/abs/2504.01169v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures, 3 tables, accepted in conference MAEB 2025 (more  info at  https://www.uik.eus/es/curso/xvi-congreso-espanol-metaheuristicas-algoritmos-evolutivos-bioinspirados)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过整合物理信息图神经网络（GNN）和传统数值方法来加速n体模拟的新方法。&lt;h4&gt;背景&lt;/h4&gt;传统的n体模拟方法在处理大规模系统时效率较低。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够提高计算效率且保持高精度预测的n体模拟方法。&lt;h4&gt;方法&lt;/h4&gt;该方法采用基于蛙跳法的模拟引擎生成数据集，然后将数据集转换为图表示。训练一个自定义的GNN来预测粒子的加速度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的模型在预测精度和长期稳定性方面表现出色，累积误差在位置、速度和加速度上保持微小。此外，该方法在传统的模拟技术上实现了约17%的加速。&lt;h4&gt;结论&lt;/h4&gt;将深度学习与传统物理模拟方法相结合为显著提高计算效率提供了有希望的途径，同时不会牺牲精度。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种加速n体模拟的新方法，该方法将物理信息图神经网络与传统的数值方法相结合。通过蛙跳模拟引擎生成数据集，并将其转换为图表示。训练一个定制的GNN来预测粒子的加速度。实验表明，所提出的模型在预测精度和长期稳定性方面表现出色，累积误差在位置、速度和加速度上保持微小。此外，该方法在传统的模拟技术上实现了约17%的加速。这些结果表明，将深度学习与传统物理模拟方法相结合为显著提高计算效率提供了有希望的途径，同时不会牺牲精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel approach for accelerating n-body simulations byintegrating a physics-informed graph neural networks (GNN) with traditionalnumerical methods. Our method implements a leapfrog-based simulation engine togenerate datasets from diverse astrophysical scenarios which are thentransformed into graph representations. A custom-designed GNN is trained topredict particle accelerations with high precision. Experiments, conducted on60 training and 6 testing simulations spanning from 3 to 500 bodies over 1000time steps, demonstrate that the proposed model achieves extremely lowprediction errors-loss values while maintaining robust long-term stability,with accumulated errors in position, velocity, and acceleration remaininginsignificant. Furthermore, our method yields a modest speedup of approximately17% over conventional simulation techniques. These results indicate that theintegration of deep learning with traditional physical simulation methodsoffers a promising pathway to significantly enhance computational efficiencywithout compromising accuracy.</description>
      <author>example@mail.com (Víctor Ramos-Osuna, Alberto Díaz-Álvarez, Raúl Lara-Cabrera)</author>
      <guid isPermaLink="false">2504.01169v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>CopyQNN: Quantum Neural Network Extraction Attack under Varying Quantum Noise</title>
      <link>http://arxiv.org/abs/2504.00366v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CopyQNN的框架，用于防御量子神经网络（QNN）模型提取攻击，通过数据清洗和量子领域内的对比学习和迁移学习技术，显著提高了攻击防御效果。&lt;h4&gt;背景&lt;/h4&gt;量子神经网络在多个领域显示出巨大的价值，而训练良好的QNN通常作为知识产权通过云平台QNN-as-a-Service（QNNaaS）提供。现有的攻击方法忽略了量子噪声的影响，限制了其在现实世界中的应用。&lt;h4&gt;目的&lt;/h4&gt;为了解决量子噪声对现有攻击方法的影响，提出CopyQNN框架，以提高QNN模型提取攻击的防御能力。&lt;h4&gt;方法&lt;/h4&gt;CopyQNN框架采用三步数据清洗方法来消除噪声数据，并整合了量子领域的对比学习和迁移学习，以使用有限的清洗数据高效训练替代QNN。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CopyQNN在NISQ计算机上的实际应用显著优于现有的QNN提取攻击，平均性能提高了8.73%，同时查询次数减少了90倍，硬件开销增加不大。&lt;h4&gt;结论&lt;/h4&gt;CopyQNN框架通过数据清洗和量子学习技术，有效地防御了QNN模型提取攻击，为QNN在现实世界中的应用提供了安全保障。&lt;h4&gt;翻译&lt;/h4&gt;摘要：量子神经网络（QNN）在多个领域显示出显著的价值，经过良好训练的QNN通常作为知识产权通过基于云的QNN-as-a-Service（QNNaaS）平台提供。最近的工作研究了使用经典和新兴量子策略的QNN模型提取攻击。这些攻击涉及对手查询QNNaaS平台以获取用于训练本地替代QNN的标记数据，这些QNN能够复制基于云模型的功能。然而，现有的方法在很大程度上忽略了噪声中间规模量子（NISQ）计算机中固有的量子噪声的影响，限制了它们在现实世界设置中的有效性。为了解决这一限制，我们提出了CopyQNN框架，该框架采用基于其噪声敏感性的三步数据清洗方法来消除噪声数据。随后，在量子领域内整合了对比学习和迁移学习，使得使用有限的清洗查询数据能够高效地训练替代QNN。在NISQ计算机上的实验结果表明，CopyQNN的实际实现显著优于最先进的QNN提取攻击，在所有任务上平均性能提高了8.73%，同时查询次数减少了90倍，硬件开销仅有适度增加。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum Neural Networks (QNNs) have shown significant value across domains,with well-trained QNNs representing critical intellectual property oftendeployed via cloud-based QNN-as-a-Service (QNNaaS) platforms. Recent work hasexamined QNN model extraction attacks using classical and emerging quantumstrategies. These attacks involve adversaries querying QNNaaS platforms toobtain labeled data for training local substitute QNNs that replicate thefunctionality of cloud-based models. However, existing approaches have largelyoverlooked the impact of varying quantum noise inherent in noisyintermediate-scale quantum (NISQ) computers, limiting their effectiveness inreal-world settings. To address this limitation, we propose the CopyQNNframework, which employs a three-step data cleaning method to eliminate noisydata based on its noise sensitivity. This is followed by the integration ofcontrastive and transfer learning within the quantum domain, enabling efficienttraining of substitute QNNs using a limited but cleaned set of queried data.Experimental results on NISQ computers demonstrate that a practicalimplementation of CopyQNN significantly outperforms state-of-the-art QNNextraction attacks, achieving an average performance improvement of 8.73%across all tasks while reducing the number of required queries by 90x, withonly a modest increase in hardware overhead.</description>
      <author>example@mail.com (Zhenxiao Fu, Leyi Zhao, Xuhong Zhang, Yilun Xu, Gang Huang, Fan Chen)</author>
      <guid isPermaLink="false">2504.00366v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>CellVTA: Enhancing Vision Foundation Models for Accurate Cell Segmentation and Classification</title>
      <link>http://arxiv.org/abs/2504.00784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CellVTA是一种新的细胞实例分割方法，通过结合CNN适配器模块，显著提高了基于Vision Transformers的视觉基础模型在细胞实例分割上的性能。&lt;h4&gt;背景&lt;/h4&gt;细胞实例分割在数字病理学中具有广泛的应用，而基于Vision Transformers的视觉基础模型在病理图像分析中取得了显著的成功，但其对细胞实例分割的改进有限。&lt;h4&gt;目的&lt;/h4&gt;提出CellVTA方法，以提高视觉基础模型在细胞实例分割任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;CellVTA通过引入CNN适配器模块，从输入图像中提取高分辨率的空间信息，并通过交叉注意力机制将其注入ViT中，同时保留ViT的核心架构，以便与预训练的基础模型无缝集成。&lt;h4&gt;主要发现&lt;/h4&gt;CellVTA在CoNIC数据集上达到0.538 mPQ，在PanNuke数据集上达到0.506 mPQ，显著优于现有的细胞分割方法。消融实验证实了该方法优于其他微调策略，包括仅解码器微调和全微调。&lt;h4&gt;结论&lt;/h4&gt;CellVTA方法在细胞实例分割任务上取得了显著的性能提升，为基于Vision Transformers的细胞实例分割提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;Cell instance segmentation is a fundamental task in digital pathology with broad clinical applications. Recently, vision foundation models, which are predominantly based on Vision Transformers (ViTs), have achieved remarkable success in pathology image analysis. However, their improvements in cell instance segmentation remain limited. A key challenge arises from the tokenization process in ViTs, which substantially reduces the spatial resolution of input images, leading to suboptimal segmentation quality, especially for small and densely packed cells. To address this problem, we propose CellVTA (Cell Vision Transformer with Adapter), a novel method that improves the performance of vision foundation models for cell instance segmentation by incorporating a CNN-based adapter module. This adapter extracts high-resolution spatial information from input images and injects it into the ViT through a cross-attention mechanism. Our method preserves the core architecture of ViT, ensuring seamless integration with pretrained foundation models. Extensive experiments show that CellVTA achieves 0.538 mPQ on the CoNIC dataset and 0.506 mPQ on the PanNuke dataset, which significantly outperforms the state-of-the-art cell segmentation methods. Ablation studies confirm the superiority of our approach over other fine-tuning strategies, including decoder-only fine-tuning and full fine-tuning. Our code and models are publicly available at https://github.com/JieZheng-ShanghaiTech/CellVTA.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/JieZheng-ShanghaiTech/CellVTA&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cell instance segmentation is a fundamental task in digital pathology withbroad clinical applications. Recently, vision foundation models, which arepredominantly based on Vision Transformers (ViTs), have achieved remarkablesuccess in pathology image analysis. However, their improvements in cellinstance segmentation remain limited. A key challenge arises from thetokenization process in ViTs, which substantially reduces the spatialresolution of input images, leading to suboptimal segmentation quality,especially for small and densely packed cells. To address this problem, wepropose CellVTA (Cell Vision Transformer with Adapter), a novel method thatimproves the performance of vision foundation models for cell instancesegmentation by incorporating a CNN-based adapter module. This adapter extractshigh-resolution spatial information from input images and injects it into theViT through a cross-attention mechanism. Our method preserves the corearchitecture of ViT, ensuring seamless integration with pretrained foundationmodels. Extensive experiments show that CellVTA achieves 0.538 mPQ on the CoNICdataset and 0.506 mPQ on the PanNuke dataset, which significantly outperformsthe state-of-the-art cell segmentation methods. Ablation studies confirm thesuperiority of our approach over other fine-tuning strategies, includingdecoder-only fine-tuning and full fine-tuning. Our code and models are publiclyavailable at https://github.com/JieZheng-ShanghaiTech/CellVTA.</description>
      <author>example@mail.com (Yang Yang, Xijie Xu, Yixun Zhou, Jie Zheng)</author>
      <guid isPermaLink="false">2504.00784v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Suite-IN++: A FlexiWear BodyNet Integrating Global and Local Motion Features from Apple Suite for Robust Inertial Navigation</title>
      <link>http://arxiv.org/abs/2504.00438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages,10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Suite-IN++的深度学习框架，用于基于可穿戴设备的行人定位。&lt;h4&gt;背景&lt;/h4&gt;可穿戴技术的普及建立了由智能手机、智能手表和耳机组成的多元化设备生态系统，这对于普遍的行人定位至关重要。然而，传统的行人死地定位（PDR）在处理多种运动模式时存在困难，而数据驱动的方法虽然提高了准确性，但由于依赖于单一设备设置，往往缺乏鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在通过充分利用现有的可穿戴设备，形成一个灵活的可穿戴体网，以实现鲁棒和准确的行人定位。&lt;h4&gt;方法&lt;/h4&gt;Suite-IN++框架整合了不同身体部位可穿戴设备的运动数据，使用对比学习来分离全局和局部运动特征。它根据每个设备的数据可靠性融合全局特征，以捕捉整体运动趋势，并使用注意力机制来揭示局部特征中的跨设备相关性，从而提取有助于准确定位的运动细节。&lt;h4&gt;主要发现&lt;/h4&gt;为了评估该方法，我们构建了一个真实的可穿戴体网数据集，包含了iPhone、Apple Watch和AirPods等设备，覆盖了不同的行走模式和设备配置。实验结果表明，Suite-IN++在真实生活中的行人跟踪场景中实现了卓越的定位精度和鲁棒性，显著优于现有的最先进模型。&lt;h4&gt;结论&lt;/h4&gt;Suite-IN++在真实世界的行人跟踪场景中，实现了比现有最先进模型更高的定位精度和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着可穿戴技术的普及，智能手机、智能手表和耳机等组成的多元化设备生态系统已成为实现普遍行人定位的关键推动力。然而，传统的行人死地定位（PDR）在处理多种运动模式时存在困难，而数据驱动的方法尽管提高了准确性，但由于依赖于单一设备设置，往往缺乏鲁棒性。因此，充分利用现有可穿戴设备，形成一个灵活的可穿戴体网，以实现鲁棒和准确的行人定位是一个有前景的解决方案。本文提出了一种名为Suite-IN++的深度学习框架，用于基于可穿戴设备的行人定位。Suite-IN++整合了不同身体部位可穿戴设备的运动数据，使用对比学习来分离全局和局部运动特征。它根据每个设备的数据可靠性融合全局特征，以捕捉整体运动趋势，并使用注意力机制来揭示局部特征中的跨设备相关性，从而提取有助于准确定位的运动细节。为了评估该方法，我们构建了一个真实的可穿戴体网数据集，包含了iPhone、Apple Watch和AirPods等设备，覆盖了不同的行走模式和设备配置。实验结果表明，Suite-IN++在真实生活中的行人跟踪场景中实现了卓越的定位精度和鲁棒性，显著优于现有的最先进模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The proliferation of wearable technology has established multi-deviceecosystems comprising smartphones, smartwatches, and headphones as criticalenablers for ubiquitous pedestrian localization. However, traditionalpedestrian dead reckoning (PDR) struggles with diverse motion modes, whiledata-driven methods, despite improving accuracy, often lack robustness due totheir reliance on a single-device setup. Therefore, a promising solution is tofully leverage existing wearable devices to form a flexiwear bodynet for robustand accurate pedestrian localization. This paper presents Suite-IN++, a deeplearning framework for flexiwear bodynet-based pedestrian localization.Suite-IN++ integrates motion data from wearable devices on different bodyparts, using contrastive learning to separate global and local motion features.It fuses global features based on the data reliability of each device tocapture overall motion trends and employs an attention mechanism to uncovercross-device correlations in local features, extracting motion details helpfulfor accurate localization. To evaluate our method, we construct a real-lifeflexiwear bodynet dataset, incorporating Apple Suite (iPhone, Apple Watch, andAirPods) across diverse walking modes and device configurations. Experimentalresults demonstrate that Suite-IN++ achieves superior localization accuracy androbustness, significantly outperforming state-of-the-art models in real-lifepedestrian tracking scenarios.</description>
      <author>example@mail.com (Lan Sun, Songpengcheng Xia, Jiarui Yang, Ling Pei)</author>
      <guid isPermaLink="false">2504.00438v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>GKAN: Explainable Diagnosis of Alzheimer's Disease Using Graph Neural Network with Kolmogorov-Arnold Networks</title>
      <link>http://arxiv.org/abs/2504.00946v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 4 figures, under review of The Southwest Data Science  Conference (SDSC 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GCN-KAN的神经网络框架，用于阿尔茨海默病（AD）的诊断，该框架通过结合Kolmogorov-Arnold Networks（KAN）与图卷积网络（GCN）来提高诊断准确性和可解释性。&lt;h4&gt;背景&lt;/h4&gt;阿尔茨海默病是一种复杂的神经退行性疾病，其诊断面临挑战。现有的图卷积网络在建模脑连接方面显示出潜力，但其对线性变换的依赖限制了其捕捉神经影像数据中复杂非线性模式的能力。&lt;h4&gt;目的&lt;/h4&gt;提出GCN-KAN框架的目的是为了提高阿尔茨海默病诊断的准确性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;GCN-KAN框架利用结构MRI数据，采用可学习的样条变换来更好地表示脑区之间的相互作用，并将KAN集成到GCN中。&lt;h4&gt;主要发现&lt;/h4&gt;在阿尔茨海默病神经影像学倡议（ADNI）数据集上评估发现，GCN-KAN在分类准确率上比传统的GCN高出4-8%，同时提供了关于与AD相关的关键脑区的可解释见解。&lt;h4&gt;结论&lt;/h4&gt;GCN-KAN是一种稳健且可解释的工具，可用于早期阿尔茨海默病诊断。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Alzheimer's Disease (AD) is a progressive neurodegenerative disorder thatposes significant diagnostic challenges due to its complex etiology. GraphConvolutional Networks (GCNs) have shown promise in modeling brain connectivityfor AD diagnosis, yet their reliance on linear transformations limits theirability to capture intricate nonlinear patterns in neuroimaging data. Toaddress this, we propose GCN-KAN, a novel single-modal framework thatintegrates Kolmogorov-Arnold Networks (KAN) into GCNs to enhance bothdiagnostic accuracy and interpretability. Leveraging structural MRI data, ourmodel employs learnable spline-based transformations to better represent brainregion interactions. Evaluated on the Alzheimer's Disease NeuroimagingInitiative (ADNI) dataset, GCN-KAN outperforms traditional GCNs by 4-8% inclassification accuracy while providing interpretable insights into key brainregions associated with AD. This approach offers a robust and explainable toolfor early AD diagnosis.</description>
      <author>example@mail.com (Tianqi Ding, Dawei Xiang, Keith E Schubert, Liang Dong)</author>
      <guid isPermaLink="false">2504.00946v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Detecting Glioma, Meningioma, and Pituitary Tumors, and Normal Brain Tissues based on Yolov11 and Yolov8 Deep Learning Models</title>
      <link>http://arxiv.org/abs/2504.00189v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 7 figures, 8 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习模型YoloV11和YoloV8的先进技术，用于快速准确诊断脑组织中的胶质瘤、脑膜瘤和垂体瘤，以提高治疗效果。&lt;h4&gt;背景&lt;/h4&gt;准确快速地诊断正常脑组织中的胶质瘤、脑膜瘤和垂体瘤对于最佳治疗计划和改善医疗结果至关重要。MRI作为非侵入性诊断工具在检测脑部异常，包括肿瘤方面被广泛应用。&lt;h4&gt;目的&lt;/h4&gt;开发一种先进的人工智能技术，利用深度学习模型来检测脑肿瘤，以减少手动解读MRI扫描的时间消耗和人为错误。&lt;h4&gt;方法&lt;/h4&gt;采用基于迁移学习的微调方法，将前沿的深度学习技术与医学影像相结合，将脑肿瘤分类为无肿瘤、胶质瘤、脑膜瘤和垂体瘤四个类别。&lt;h4&gt;主要发现&lt;/h4&gt;研究利用了公开可用的CE-MRI Figshare数据集，对预训练模型YoloV8和YoloV11进行微调，分别达到99.49%和99.56%的准确率，以及定制CNN的96.98%准确率。结果表明，卷积神经网络（CNN）在脑肿瘤检测和分类中具有实现高精度的潜力。&lt;h4&gt;结论&lt;/h4&gt;该研究验证了CNN在脑肿瘤检测和分类中的高精度潜力，突显了其在医学影像和诊断中的变革性作用。&lt;h4&gt;翻译&lt;/h4&gt;Accurate and quick diagnosis of normal brain tissue Glioma, Meningioma, and Pituitary Tumors is crucial for optimal treatment planning and improved medical results. Magnetic Resonance Imaging (MRI) is widely used as a non-invasive diagnostic tool for detecting brain abnormalities, including tumors. However, manual interpretation of MRI scans is often time-consuming, prone to human error, and dependent on highly specialized expertise. This paper proposes an advanced AI-driven technique to detecting glioma, meningioma, and pituitary brain tumors using YoloV11 and YoloV8 deep learning models. Methods: Using a transfer learning-based fine-tuning approach, we integrate cutting-edge deep learning techniques with medical imaging to classify brain tumors into four categories: No-Tumor, Glioma, Meningioma, and Pituitary Tumors. Results: The study utilizes the publicly accessible CE-MRI Figshare dataset and involves fine-tuning pre-trained models YoloV8 and YoloV11 of 99.49% and 99.56% accuracies; and customized CNN accuracy of 96.98%. The results validate the potential of CNNs in achieving high precision in brain tumor detection and classification, highlighting their transformative role in medical imaging and diagnostics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and quick diagnosis of normal brain tissue Glioma, Meningioma, andPituitary Tumors is crucial for optimal treatment planning and improved medicalresults. Magnetic Resonance Imaging (MRI) is widely used as a non-invasivediagnostic tool for detecting brain abnormalities, including tumors. However,manual interpretation of MRI scans is often time-consuming, prone to humanerror, and dependent on highly specialized expertise. This paper proposes anadvanced AI-driven technique to detecting glioma, meningioma, and pituitarybrain tumors using YoloV11 and YoloV8 deep learning models.  Methods: Using a transfer learning-based fine-tuning approach, we integratecutting-edge deep learning techniques with medical imaging to classify braintumors into four categories: No-Tumor, Glioma, Meningioma, and PituitaryTumors.  Results: The study utilizes the publicly accessible CE-MRI Figshare datasetand involves fine-tuning pre-trained models YoloV8 and YoloV11 of 99.49% and99.56% accuracies; and customized CNN accuracy of 96.98%. The results validatethe potential of CNNs in achieving high precision in brain tumor detection andclassification, highlighting their transformative role in medical imaging anddiagnostics.</description>
      <author>example@mail.com (Ahmed M. Taha, Salah A. Aly, Mohamed F. Darwish)</author>
      <guid isPermaLink="false">2504.00189v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>GraphMaster: Automated Graph Synthesis via LLM Agents in Data-Limited Environments</title>
      <link>http://arxiv.org/abs/2504.00711v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GraphMaster是一个专门为数据有限环境中的图数据合成设计的多智能体框架，通过优化合成过程，确保语义一致性和结构完整性。&lt;h4&gt;背景&lt;/h4&gt;GFMs在AI研究中取得革命性进展，但受限于大规模图语料库的稀缺。传统图数据合成技术缺乏生成语义丰富节点的能力，而大语言模型在图合成中的应用受到限制。&lt;h4&gt;目的&lt;/h4&gt;开发GraphMaster以解决数据有限环境中的图数据合成问题。&lt;h4&gt;方法&lt;/h4&gt;GraphMaster由四个专门的LLM智能体（Manager、Perception、Enhancement和Evaluation）组成，通过迭代优化协同工作，同时确保语义一致性和结构完整性。创建新的数据有限“Sub”变体图基准测试，并开发了一种结合人类评估和Grassmannian流形分析的可解释性评估框架。&lt;h4&gt;主要发现&lt;/h4&gt;GraphMaster在多个数据集上显著优于传统合成方法，为在数据稀缺环境中推进GFMs奠定了坚实基础。&lt;h4&gt;结论&lt;/h4&gt;GraphMaster是一个有效的框架，可以显著提高数据有限环境中的图数据合成能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The era of foundation models has revolutionized AI research, yet GraphFoundation Models (GFMs) remain constrained by the scarcity of large-scalegraph corpora. Traditional graph data synthesis techniques primarily focus onsimplistic structural operations, lacking the capacity to generate semanticallyrich nodes with meaningful textual attributes: a critical limitation forreal-world applications. While large language models (LLMs) demonstrateexceptional text generation capabilities, their direct application to graphsynthesis is impeded by context window limitations, hallucination phenomena,and structural consistency challenges. To address these issues, we introduceGraphMaster, the first multi-agent framework specifically designed for graphdata synthesis in data-limited environments. GraphMaster orchestrates fourspecialized LLM agents (Manager, Perception, Enhancement, and Evaluation) thatcollaboratively optimize the synthesis process through iterative refinement,ensuring both semantic coherence and structural integrity. To rigorouslyevaluate our approach, we create new data-limited "Sub" variants of sixstandard graph benchmarks, specifically designed to test synthesis capabilitiesunder realistic constraints. Additionally, we develop a novel interpretabilityassessment framework that combines human evaluation with a principledGrassmannian manifold-based analysis, providing both qualitative andquantitative measures of semantic coherence. Experimental results demonstratethat GraphMaster significantly outperforms traditional synthesis methods acrossmultiple datasets, establishing a strong foundation for advancing GFMs indata-scarce environments.</description>
      <author>example@mail.com (Enjun Du, Xunkai Li, Tian Jin, Zhihan Zhang, Rong-Hua Li, Guoren Wang)</author>
      <guid isPermaLink="false">2504.00711v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Fair Sufficient Representation Learning</title>
      <link>http://arxiv.org/abs/2504.01030v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  35 pages, 11 figures, and 6 tables (1 in the main text, 5 in the  appendix)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为公平充分表示学习（FSRL）的方法，旨在平衡充分性和公平性，以减少或消除统计建模和机器学习中的偏见。&lt;h4&gt;背景&lt;/h4&gt;在统计建模和机器学习中，存在因数据或模型本身产生的偏见，这些偏见可能不公平地影响敏感属性，如种族、性别、年龄等。&lt;h4&gt;目的&lt;/h4&gt;目标是确保预测和决策不受敏感属性的不公正影响。&lt;h4&gt;方法&lt;/h4&gt;FSRL方法基于学习充分表示和确保公平性的目标函数的凸组合。该方法在表示层面管理公平性和充分性，使用距离协方差实现，该协方差有效于描述随机变量之间的独立性。&lt;h4&gt;主要发现&lt;/h4&gt;通过在健康案例和具有不同结构的文本数据集上的实验，FSRL在公平性和准确性之间实现了比现有方法更优的权衡。&lt;h4&gt;结论&lt;/h4&gt;FSRL为公平表示学习提供了一个新颖的视角，并在实验中证明了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The main objective of fair statistical modeling and machine learning is tominimize or eliminate biases that may arise from the data or the model itself,ensuring that predictions and decisions are not unjustly influenced bysensitive attributes such as race, gender, age, or other protectedcharacteristics. In this paper, we introduce a Fair Sufficient RepresentationLearning (FSRL) method that balances sufficiency and fairness. Sufficiencyensures that the representation should capture all necessary information aboutthe target variables, while fairness requires that the learned representationremains independent of sensitive attributes. FSRL is based on a convexcombination of an objective function for learning a sufficient representationand an objective function that ensures fairness. Our approach manages fairnessand sufficiency at the representation level, offering a novel perspective onfair representation learning. We implement this method using distancecovariance, which is effective for characterizing independence between randomvariables. We establish the convergence properties of the learnedrepresentations. Experiments conducted on healthcase and text datasets withdiverse structures demonstrate that FSRL achieves a superior trade-off betweenfairness and accuracy compared to existing approaches.</description>
      <author>example@mail.com (Xueyu Zhou, Chun Yin IP, Jian Huang)</author>
      <guid isPermaLink="false">2504.01030v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>CoMatcher: Multi-View Collaborative Feature Matching</title>
      <link>http://arxiv.org/abs/2504.01872v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 7 figures, to be published in CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多视角协作匹配策略，用于复杂场景中的可靠轨迹构建。&lt;h4&gt;背景&lt;/h4&gt;图像集匹配中使用的成对匹配范式在所选独立对存在显著遮挡或极端视角变化时往往导致模糊估计。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，提出了CoMatcher，一个深度多视角匹配器，用于（i）利用不同视角的互补上下文线索形成一个全面的3D场景理解；（ii）利用跨视角投影一致性来推断可靠的全球解决方案。&lt;h4&gt;方法&lt;/h4&gt;基于CoMatcher，开发了一个分组框架，充分利用跨视角关系进行大规模匹配任务。&lt;h4&gt;主要发现&lt;/h4&gt;在多种复杂场景上的大量实验表明，与主流的双视角匹配范式相比，该方法具有优越性。&lt;h4&gt;结论&lt;/h4&gt;该方法在复杂场景中的可靠轨迹构建方面优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a multi-view collaborative matching strategy for reliable track construction in complex scenarios. We observe that the pairwise matching paradigms applied to image set matching often result in ambiguous estimation when the selected independent pairs exhibit significant occlusions or extreme viewpoint changes. This challenge primarily stems from the inherent uncertainty in interpreting intricate 3D structures based on limited two-view observations, as the 3D-to-2D projection leads to significant information loss. To address this, we introduce CoMatcher, a deep multi-view matcher to (i) leverage complementary context cues from different views to form a holistic 3D scene understanding and (ii) utilize cross-view projection consistency to infer a reliable global solution. Building on CoMatcher, we develop a group-wise framework that fully exploits cross-view relationships for large-scale matching tasks. Extensive experiments on various complex scenarios demonstrate the superiority of our method over the mainstream two-view matching paradigm.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a multi-view collaborative matching strategy for reliabletrack construction in complex scenarios. We observe that the pairwise matchingparadigms applied to image set matching often result in ambiguous estimationwhen the selected independent pairs exhibit significant occlusions or extremeviewpoint changes. This challenge primarily stems from the inherent uncertaintyin interpreting intricate 3D structures based on limited two-view observations,as the 3D-to-2D projection leads to significant information loss. To addressthis, we introduce CoMatcher, a deep multi-view matcher to (i) leveragecomplementary context cues from different views to form a holistic 3D sceneunderstanding and (ii) utilize cross-view projection consistency to infer areliable global solution. Building on CoMatcher, we develop a groupwiseframework that fully exploits cross-view relationships for large-scale matchingtasks. Extensive experiments on various complex scenarios demonstrate thesuperiority of our method over the mainstream two-view matching paradigm.</description>
      <author>example@mail.com (Jintao Zhang, Zimin Xia, Mingyue Dong, Shuhan Shen, Linwei Yue, Xianwei Zheng)</author>
      <guid isPermaLink="false">2504.01872v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Initialization for LiDAR-inertial SLAM</title>
      <link>http://arxiv.org/abs/2504.01451v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE/ASME Transactions on Mechatronics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对LiDAR-inertial SLAM系统的动态初始化方法，以解决在机器人运动过程中快速且鲁棒地初始化系统的问题。&lt;h4&gt;背景&lt;/h4&gt;初始状态（包括初始速度、重力方向和IMU偏差）的准确性对于LiDAR-inertial SLAM系统的初始化至关重要。不准确的初始值会降低初始化速度或导致失败。&lt;h4&gt;目的&lt;/h4&gt;在机器人运动时，如自然灾害后的快速救援环境评估、炸弹处理和救援任务中的LiDAR-inertial SLAM重启等紧急任务中，需要鲁棒且快速的初始化方法。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法（D-LI-Init）通过迭代对齐基于LiDAR的里程计与IMU测量值来实现系统初始化。该方法将LiDAR和陀螺仪紧密集成在ESIKF框架中，以增强LiDAR里程计模块的可靠性。&lt;h4&gt;主要发现&lt;/h4&gt;D-LI-Init算法能够有效服务于各种平台，包括车辆、手持设备和无人机。无论机器人是运动还是静止，该方法都能完成动态初始化，且不受特定运动模式的影响。&lt;h4&gt;结论&lt;/h4&gt;为了惠及研究社区，作者已在GitHub上开源了代码和测试数据集。&lt;h4&gt;翻译&lt;/h4&gt;The accuracy of the initial state, including initial velocity, gravity direction, and IMU biases, is critical for the initialization of LiDAR-inertial SLAM systems. Inaccurate initial values can reduce initialization speed or lead to failure. When the system faces urgent tasks, robust and fast initialization is required while the robot is moving, such as during the swift assessment of rescue environments after natural disasters, bomb disposal, and restarting LiDAR-inertial SLAM in rescue missions. However, existing initialization methods usually require the platform to remain stationary, which is ineffective when the robot is in motion. To address this issue, this paper introduces a robust and fast dynamic initialization method for LiDAR-inertial systems (D-LI-Init). This method iteratively aligns LiDAR-based odometry with IMU measurements to achieve system initialization. To enhance the reliability of the LiDAR odometry module, the LiDAR and gyroscope are tightly integrated within the ESIKF framework. The gyroscope compensates for rotational distortion in the point cloud. Translational distortion compensation occurs during the iterative update phase, resulting in the output of LiDAR-gyroscope odometry. The proposed method can initialize the system no matter the robot is moving or stationary. Experiments on public datasets and real-world environments demonstrate that the D-LI-Init algorithm can effectively serve various platforms, including vehicles, handheld devices, and UAVs. D-LI-Init completes dynamic initialization regardless of specific motion patterns. To benefit the research community, we have open-sourced our code and test datasets on GitHub.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TMECH.2025.3554878&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accuracy of the initial state, including initial velocity, gravitydirection, and IMU biases, is critical for the initialization of LiDAR-inertialSLAM systems. Inaccurate initial values can reduce initialization speed or leadto failure. When the system faces urgent tasks, robust and fast initializationis required while the robot is moving, such as during the swift assessment ofrescue environments after natural disasters, bomb disposal, and restartingLiDAR-inertial SLAM in rescue missions. However, existing initializationmethods usually require the platform to remain stationary, which is ineffectivewhen the robot is in motion. To address this issue, this paper introduces arobust and fast dynamic initialization method for LiDAR-inertial systems(D-LI-Init). This method iteratively aligns LiDAR-based odometry with IMUmeasurements to achieve system initialization. To enhance the reliability ofthe LiDAR odometry module, the LiDAR and gyroscope are tightly integratedwithin the ESIKF framework. The gyroscope compensates for rotational distortionin the point cloud. Translational distortion compensation occurs during theiterative update phase, resulting in the output of LiDAR-gyroscope odometry.The proposed method can initialize the system no matter the robot is moving orstationary. Experiments on public datasets and real-world environmentsdemonstrate that the D-LI-Init algorithm can effectively serve variousplatforms, including vehicles, handheld devices, and UAVs. D-LI-Init completesdynamic initialization regardless of specific motion patterns. To benefit theresearch community, we have open-sourced our code and test datasets on GitHub.</description>
      <author>example@mail.com (Jie Xu, Yongxin Ma, Yixuan Li, Xuanxuan Zhang, Jun Zhou, Shenghai Yuan, Lihua Xie)</author>
      <guid isPermaLink="false">2504.01451v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Training Frozen Feature Pyramid DINOv2 for Eyelid Measurements with Infinite Encoding and Orthogonal Regularization</title>
      <link>http://arxiv.org/abs/2504.00515v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究评估了深度学习模型在自动化眼睑参数测量中的应用，并探讨了其在实际临床应用中的潜力。&lt;h4&gt;背景&lt;/h4&gt;准确测量眼睑参数对于眼整形诊断至关重要，但当前方法主要依赖手工操作，存在不一致性。&lt;h4&gt;目的&lt;/h4&gt;评估SE-ResNet、EfficientNet和基于视觉变换器的DINOv2模型，利用智能手机获取的图像自动化眼睑参数测量。&lt;h4&gt;方法&lt;/h4&gt;使用均方误差（MSE）、平均绝对误差（MAE）和R²指标评估模型在冻结和微调设置下的性能。针对类别不平衡和泛化问题，采用了焦点损失、正则化和二进制编码策略。&lt;h4&gt;主要发现&lt;/h4&gt;DINOv2模型在冻结条件下表现出优异的可扩展性和鲁棒性，轻量级回归器如MLP和Deep Ensemble提供了高精度和低计算开销。结合改进策略，DINOv2模型在所有任务上均能提供一致、准确的预测。&lt;h4&gt;结论&lt;/h4&gt;DINOv2模型结合改进策略是移动友好型临床应用的有力候选，研究突出了基础模型在推进人工智能眼科护理方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Accurate measurement of eyelid parameters such as Margin Reflex Distances (MRD1, MRD2) and Levator Function (LF) is critical in oculoplastic diagnostics but remains limited by manual, inconsistent methods. This study evaluates deep learning models: SE-ResNet, EfficientNet, and the vision transformer-based DINOv2 for automating these measurements using smartphone-acquired images. We assess performance across frozen and fine-tuned settings, using MSE, MAE, and R² metrics. DINOv2, pretrained through self-supervised learning, demonstrates superior scalability and robustness, especially under frozen conditions ideal for mobile deployment. Lightweight regressors such as MLP and Deep Ensemble offer high precision with minimal computational overhead. To address class imbalance and improve generalization, we integrate focal loss, orthogonal regularization, and binary encoding strategies. Our results show that DINOv2 combined with these enhancements delivers consistent, accurate predictions across all tasks, making it a strong candidate for real-world, mobile-friendly clinical applications. This work highlights the potential of foundation models in advancing AI-powered ophthalmic care.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/jimchen1551/EyelidMeasure&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate measurement of eyelid parameters such as Margin Reflex Distances(MRD1, MRD2) and Levator Function (LF) is critical in oculoplastic diagnosticsbut remains limited by manual, inconsistent methods. This study evaluates deeplearning models: SE-ResNet, EfficientNet, and the vision transformer-basedDINOv2 for automating these measurements using smartphone-acquired images. Weassess performance across frozen and fine-tuned settings, using MSE, MAE, andR2 metrics. DINOv2, pretrained through self-supervised learning, demonstratessuperior scalability and robustness, especially under frozen conditions idealfor mobile deployment. Lightweight regressors such as MLP and Deep Ensembleoffer high precision with minimal computational overhead. To address classimbalance and improve generalization, we integrate focal loss, orthogonalregularization, and binary encoding strategies. Our results show that DINOv2combined with these enhancements delivers consistent, accurate predictionsacross all tasks, making it a strong candidate for real-world, mobile-friendlyclinical applications. This work highlights the potential of foundation modelsin advancing AI-powered ophthalmic care.</description>
      <author>example@mail.com (Chun-Hung Chen)</author>
      <guid isPermaLink="false">2504.00515v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>TimeSearch: Hierarchical Video Search with Spotlight and Reflection for Human-like Long Video Understanding</title>
      <link>http://arxiv.org/abs/2504.01407v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为TimeSearch的新框架，用于帮助大型视频语言模型（LVLMs）理解长视频，并显著提高了长视频处理任务的准确性。&lt;h4&gt;背景&lt;/h4&gt;LVLMs在视频语言任务中表现出色，但在处理长视频时由于涉及大量视频帧而面临挑战，降采样可能导致视觉幻觉，难以准确解释长视频。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够使LVLMs以人类类似方式理解长视频的新框架。&lt;h4&gt;方法&lt;/h4&gt;TimeSearch框架整合了两个类似人类的原语：1）Spotlight通过时间增强帧表示（TAFR）高效识别相关的时间事件，将视觉特征与时间戳绑定；2）Reflection利用LVLMs的内在时间自反能力评估识别事件的正确性。TimeSearch逐步探索关键事件，并根据反射置信度优先考虑时间搜索。&lt;h4&gt;主要发现&lt;/h4&gt;在具有挑战性的长视频基准测试中，TimeSearch显著优于现有技术，将LVBench上的准确性从41.8%提高到51.5%。此外，在时间定位实验中，适当的TAFR足以以更简单但更灵活的方式激发LVLMs的惊人时间定位能力，使Charades-STA上的mIoU提高了11.8%。&lt;h4&gt;结论&lt;/h4&gt;TimeSearch框架为LVLMs处理长视频提供了有效的方法，显著提高了视频语言任务的性能。&lt;h4&gt;翻译&lt;/h4&gt;Large video-language models (LVLMs) have shown remarkable performance across various video-language tasks. However, they encounter significant challenges when processing long videos because of the large number of video frames involved. Downsampling long videos in either space or time can lead to visual hallucinations, making it difficult to accurately interpret long videos. Motivated by human hierarchical temporal search strategies, we propose TimeSearch, a novel framework enabling LVLMs to understand long videos in a human-like manner. TimeSearch integrates two human-like primitives into a unified autoregressive LVLM: 1) Spotlight efficiently identifies relevant temporal events through a Temporal-Augmented Frame Representation (TAFR), explicitly binding visual features with timestamps; 2) Reflection evaluates the correctness of the identified events, leveraging the inherent temporal self-reflection capabilities of LVLMs. TimeSearch progressively explores key events and prioritizes temporal search based on reflection confidence. Extensive experiments on challenging long-video benchmarks confirm that TimeSearch substantially surpasses previous state-of-the-art, improving the accuracy from 41.8% to 51.5% on the LVBench. Additionally, experiments on temporal grounding demonstrate that appropriate TAFR is adequate to effectively stimulate the surprising temporal grounding ability of LVLMs in a simpler yet versatile manner, which improves mIoU on Charades-STA by 11.8%. The code will be released.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large video-language models (LVLMs) have shown remarkable performance acrossvarious video-language tasks. However, they encounter significant challengeswhen processing long videos because of the large number of video framesinvolved. Downsampling long videos in either space or time can lead to visualhallucinations, making it difficult to accurately interpret long videos.Motivated by human hierarchical temporal search strategies, we propose\textbf{TimeSearch}, a novel framework enabling LVLMs to understand long videosin a human-like manner. TimeSearch integrates two human-like primitives into aunified autoregressive LVLM: 1) \textbf{Spotlight} efficiently identifiesrelevant temporal events through a Temporal-Augmented Frame Representation(TAFR), explicitly binding visual features with timestamps; 2)\textbf{Reflection} evaluates the correctness of the identified events,leveraging the inherent temporal self-reflection capabilities of LVLMs.TimeSearch progressively explores key events and prioritizes temporal searchbased on reflection confidence. Extensive experiments on challenging long-videobenchmarks confirm that TimeSearch substantially surpasses previousstate-of-the-art, improving the accuracy from 41.8\% to 51.5\% on the LVBench.Additionally, experiments on temporal grounding demonstrate that appropriateTAFR is adequate to effectively stimulate the surprising temporal groundingability of LVLMs in a simpler yet versatile manner, which improves mIoU onCharades-STA by 11.8\%. The code will be released.</description>
      <author>example@mail.com (Junwen Pan, Rui Zhang, Xin Wan, Yuan Zhang, Ming Lu, Qi She)</author>
      <guid isPermaLink="false">2504.01407v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>TransforMerger: Transformer-based Voice-Gesture Fusion for Robust Human-Robot Communication</title>
      <link>http://arxiv.org/abs/2504.01708v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TransforMerger的基于Transformer的推理模型，用于处理机器人操作中的自然和灵活的通信方法，通过融合语音和手势输入来生成结构化的动作命令。&lt;h4&gt;背景&lt;/h4&gt;随着人机协作的发展，对机器人控制的自然和灵活的通信方法变得至关重要。传统的依赖单一模态或刚性规则的方法在处理噪声或数据错位以及不符合预设对象名称的对象描述时存在困难。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够有效处理自然和灵活通信的机器人控制方法。&lt;h4&gt;方法&lt;/h4&gt;TransforMerger模型将多模态数据合并成一个统一的句子，并通过语言模型进行处理。该方法使用概率嵌入来处理不确定性，并集成上下文场景理解来解决模糊引用。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟和真实世界的实验中，TransforMerger对噪声、数据错位和缺失信息的鲁棒性得到了验证。结果显示，TransforMerger在需要更多上下文知识的场景中优于确定性基线，从而实现了更稳健和灵活的人机通信。&lt;h4&gt;结论&lt;/h4&gt;TransforMerger模型能够提高人机通信的鲁棒性和灵活性，为机器人控制提供了有效的通信手段。&lt;h4&gt;翻译&lt;/h4&gt;As human-robot collaboration advances, natural and flexible communication methods are essential for effective robot control. Traditional methods relying on a single modality or rigid rules struggle with noisy or misaligned data as well as with object descriptions that do not perfectly fit the predefined object names (e.g., 'Pick that red object'). We introduce TransforMerger, a transformer-based reasoning model that infers a structured action command for robotic manipulation based on fused voice and gesture inputs. Our approach merges multimodal data into a single unified sentence, which is then processed by the language model. We employ probabilistic embeddings to handle uncertainty and we integrate contextual scene understanding to resolve ambiguous references (e.g., gestures pointing to multiple objects or vague verbal cues like 'this'). We evaluate TransforMerger in simulated and real-world experiments, demonstrating its robustness to noise, misalignment, and missing information. Our results show that TransforMerger outperforms deterministic baselines, especially in scenarios requiring more contextual knowledge, enabling more robust and flexible human-robot communication. Code and datasets are available at: http://imitrob.ciirc.cvut.cz/publications/transformerger.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As human-robot collaboration advances, natural and flexible communicationmethods are essential for effective robot control. Traditional methods relyingon a single modality or rigid rules struggle with noisy or misaligned data aswell as with object descriptions that do not perfectly fit the predefinedobject names (e.g. 'Pick that red object'). We introduce TransforMerger, atransformer-based reasoning model that infers a structured action command forrobotic manipulation based on fused voice and gesture inputs. Our approachmerges multimodal data into a single unified sentence, which is then processedby the language model. We employ probabilistic embeddings to handle uncertaintyand we integrate contextual scene understanding to resolve ambiguous references(e.g., gestures pointing to multiple objects or vague verbal cues like "this").We evaluate TransforMerger in simulated and real-world experiments,demonstrating its robustness to noise, misalignment, and missing information.Our results show that TransforMerger outperforms deterministic baselines,especially in scenarios requiring more contextual knowledge, enabling morerobust and flexible human-robot communication. Code and datasets are availableat: http://imitrob.ciirc.cvut.cz/publications/transformerger.</description>
      <author>example@mail.com (Petr Vanc, Karla Stepanova)</author>
      <guid isPermaLink="false">2504.01708v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Point Cloud Semantic Segmentation With Virtual Point Enhancement</title>
      <link>http://arxiv.org/abs/2504.01449v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于虚拟点增强（VPE）的多模态点云语义分割方法，用于解决LiDAR点云识别中稀疏性和密度变化带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;LiDAR点云在物体识别中的应用证明其有益，但稀疏性和不均匀的密度对捕捉物体细节构成挑战，特别是对于中程和小型目标。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于VPE的多模态点云语义分割方法，通过集成从图像生成的虚拟点来解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;方法中引入了空间差异驱动的自适应滤波模块，用于从虚拟点中选择性地提取有价值的伪点，从而提高中程目标的密度。此外，还提出了一个噪声鲁棒的稀疏特征编码器，该编码器结合了噪声鲁棒的特征提取和细粒度特征增强。噪声鲁棒的特征提取利用2D图像空间来减少噪声点的影响，而细粒度特征增强通过内体素邻域点聚合和下采样体素聚合来提升稀疏几何特征。&lt;h4&gt;主要发现&lt;/h4&gt;在SemanticKITTI和nuScenes两个大规模基准数据集上的结果表明，引入7.7%的虚拟点后，mIoU提高了2.89%，验证了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法通过虚拟点增强和噪声鲁棒的特征提取，有效地提高了点云语义分割的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于LiDAR的3D点云识别在各种应用中已被证明是有益的。然而，稀疏性和密度变化给捕捉物体的复杂细节带来了重大挑战，特别是在中程和小型目标上。因此，我们提出了一种基于虚拟点增强（VPE）的多模态点云语义分割方法，该方法将生成的虚拟点与图像相结合以解决这些问题。这些虚拟点密集但噪声大，直接引入它们会增加计算负担并降低性能。因此，我们引入了一个空间差异驱动的自适应滤波模块，该模块根据密度和距离从这些虚拟点中选择性地提取有价值伪点，提高了中程目标的密度。随后，我们提出了一种噪声鲁棒的稀疏特征编码器，该编码器结合了噪声鲁棒的特征提取和细粒度特征增强。噪声鲁棒的特征提取利用2D图像空间以减少噪声点的影响，而细粒度特征增强通过内体素邻域点聚合和下采样体素聚合来提升稀疏几何特征。在SemanticKITTI和nuScenes两个大型基准数据集上的结果表明，通过在nuScenes上引入7.7%的虚拟点，mIoU提高了2.89%，验证了该方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR-based 3D point cloud recognition has been proven beneficial in variousapplications. However, the sparsity and varying density pose a significantchallenge in capturing intricate details of objects, particularly formedium-range and small targets. Therefore, we propose a multi-modal point cloudsemantic segmentation method based on Virtual Point Enhancement (VPE), whichintegrates virtual points generated from images to address these issues. Thesevirtual points are dense but noisy, and directly incorporating them canincrease computational burden and degrade performance. Therefore, we introducea spatial difference-driven adaptive filtering module that selectively extractsvaluable pseudo points from these virtual points based on density and distance,enhancing the density of medium-range targets. Subsequently, we propose anoise-robust sparse feature encoder that incorporates noise-robust featureextraction and fine-grained feature enhancement. Noise-robust featureextraction exploits the 2D image space to reduce the impact of noisy points,while fine-grained feature enhancement boosts sparse geometric features throughinner-voxel neighborhood point aggregation and downsampled voxel aggregation.The results on the SemanticKITTI and nuScenes, two large-scale benchmark datasets, have validated effectiveness, significantly improving 2.89\% mIoU withthe introduction of 7.7\% virtual points on nuScenes.</description>
      <author>example@mail.com (Zaipeng Duan, Xuzhong Hu, Pei An, Jie Ma)</author>
      <guid isPermaLink="false">2504.01449v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Slow-Fast Architecture for Video Multi-Modal Large Language Models</title>
      <link>http://arxiv.org/abs/2504.01328v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的慢-快架构来解决在有限的计算预算下平衡视频多模态大型语言模型（MLLMs）的时间分辨率和空间细节的关键挑战。&lt;h4&gt;背景&lt;/h4&gt;在有限的计算预算下，视频多模态MLLMs面临平衡时间分辨率和空间细节的挑战，现有方法通常在输入模型前使用预定义规则压缩视频表示，导致不可逆的信息损失并忽略输入指令。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的慢-快架构来解决这个问题，使模型能够使用更多输入帧同时保留空间细节。&lt;h4&gt;方法&lt;/h4&gt;慢-快设计采用双令牌策略：快速视觉令牌和慢速视觉令牌。快速视觉令牌是一组紧凑的压缩视频特征，与文本嵌入一起输入模型以提供快速概述；慢速视觉令牌是不压缩的视频特征，通过特别设计的混合解码层与文本嵌入交叉注意，以线性复杂度实现指令感知的相关视觉细节提取。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该模型显著优于仅使用自注意力机制的基线，将输入容量从16帧扩展到128帧，计算量仅增加3%，并在五个视频理解基准测试中实现了16%的平均性能提升。7B模型在同类模型中实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;慢-快架构是一种即插即用的设计，可以集成到其他视频MLLMs中，以提高效率和可扩展性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel slow-fast architecture to address the key challenge of balancing temporal resolution and spatial detail for video-based multi-modal large language models (MLLMs) under limited compute budget. Existing methods typically compress video representations using predefined rules before feeding them into the LLM, resulting in irreversible information loss and often ignoring input instructions. To address this, we propose a novel slow-fast architecture that naturally circumvents this trade-off, enabling the use of more input frames while preserving spatial details. Inspired by how humans first skim a video before focusing on relevant parts, our slow-fast design employs a dual-token strategy: 1) 'fast' visual tokens -- a compact set of compressed video features -- are fed into the LLM alongside text embeddings to provide a quick overview; 2) 'slow' visual tokens -- uncompressed video features -- are cross-attended by text embeddings through specially designed hybrid decoder layers, enabling instruction-aware extraction of relevant visual details with linear complexity. We conduct systematic exploration to optimize both the overall architecture and key components. Experiments show that our model significantly outperforms self-attention-only baselines, extending the input capacity from 16 to 128 frames with just a 3% increase in computation, and achieving a 16% average performance improvement across five video understanding benchmarks. Our 7B model achieves state-of-the-art performance among models of similar size. Furthermore, our slow-fast architecture is a plug-and-play design that can be integrated into other video MLLMs to improve efficiency and scalability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Balancing temporal resolution and spatial detail under limited compute budgetremains a key challenge for video-based multi-modal large language models(MLLMs). Existing methods typically compress video representations usingpredefined rules before feeding them into the LLM, resulting in irreversibleinformation loss and often ignoring input instructions. To address this, wepropose a novel slow-fast architecture that naturally circumvents thistrade-off, enabling the use of more input frames while preserving spatialdetails. Inspired by how humans first skim a video before focusing on relevantparts, our slow-fast design employs a dual-token strategy: 1) "fast" visualtokens -- a compact set of compressed video features -- are fed into the LLMalongside text embeddings to provide a quick overview; 2) "slow" visual tokens-- uncompressed video features -- are cross-attended by text embeddings throughspecially designed hybrid decoder layers, enabling instruction-aware extractionof relevant visual details with linear complexity. We conduct systematicexploration to optimize both the overall architecture and key components.Experiments show that our model significantly outperforms self-attention-onlybaselines, extending the input capacity from 16 to 128 frames with just a 3%increase in computation, and achieving a 16% average performance improvementacross five video understanding benchmarks. Our 7B model achievesstate-of-the-art performance among models of similar size. Furthermore, ourslow-fast architecture is a plug-and-play design that can be integrated intoother video MLLMs to improve efficiency and scalability.</description>
      <author>example@mail.com (Min Shi, Shihao Wang, Chieh-Yun Chen, Jitesh Jain, Kai Wang, Junjun Xiong, Guilin Liu, Zhiding Yu, Humphrey Shi)</author>
      <guid isPermaLink="false">2504.01328v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Semantic Mastery: Enhancing LLMs with Advanced Natural Language Understanding</title>
      <link>http://arxiv.org/abs/2504.00409v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了提升大型语言模型在自然语言处理任务中能力的最新方法，分析了结构化知识图谱、检索增强生成和微调策略等高级自然语言理解技术，以及如何通过结合Transformer架构、对比学习和混合符号-神经网络方法解决复杂NLP任务中的幻觉、歧义和不一致性等问题。&lt;h4&gt;背景&lt;/h4&gt;尽管大型语言模型在自然语言处理任务中的能力有了显著提升，但深入语义理解、语境连贯性和微妙推理仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过更高级的自然语言理解技术提升大型语言模型的能力，以实现与人类水平相当的语义理解。&lt;h4&gt;方法&lt;/h4&gt;本文讨论了使用语义解析、知识集成和上下文强化学习等技术的方法，并分析了结构化知识图谱、检索增强生成（RAG）和微调策略，以及结合Transformer架构、对比学习和混合符号-神经网络方法。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现语义精度对于提升AI驱动的语言系统至关重要，并提出了将统计语言模型与真正的自然语言理解之间差距缩小的未来研究方向。&lt;h4&gt;结论&lt;/h4&gt;通过结合多种高级技术，大型语言模型在自然语言处理任务中的表现可以得到显著提升，未来研究应着重于提升语义精度和解决复杂任务中的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have greatly improved their capability inperforming NLP tasks. However, deeper semantic understanding, contextualcoherence, and more subtle reasoning are still difficult to obtain. The paperdiscusses state-of-the-art methodologies that advance LLMs with more advancedNLU techniques, such as semantic parsing, knowledge integration, and contextualreinforcement learning. We analyze the use of structured knowledge graphs,retrieval-augmented generation (RAG), and fine-tuning strategies that matchmodels with human-level understanding. Furthermore, we address theincorporation of transformer-based architectures, contrastive learning, andhybrid symbolic-neural methods that address problems like hallucinations,ambiguity, and inconsistency in the factual perspectives involved in performingcomplex NLP tasks, such as question-answering text summarization and dialoguegeneration. Our findings show the importance of semantic precision forenhancing AI-driven language systems and suggest future research directions tobridge the gap between statistical language models and true natural languageunderstanding.</description>
      <author>example@mail.com (Mohanakrishnan Hariharan)</author>
      <guid isPermaLink="false">2504.00409v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>SuperDec: 3D Scene Decomposition with Superquadric Primitives</title>
      <link>http://arxiv.org/abs/2504.00992v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了SuperDec方法，通过将3D场景分解为超二次元基元来创建紧凑的3D场景表示。&lt;h4&gt;背景&lt;/h4&gt;目前的研究大多利用几何基元来获得逼真的3D场景表示，而本文提出利用这些基元来获得紧凑且富有表现力的表示。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，在局部对单个对象进行处理，并利用实例分割方法将解决方案扩展到整个3D场景。&lt;h4&gt;方法&lt;/h4&gt;设计了新的架构，能够有效地将任意对象的点云分解为紧凑的超二次元集。&lt;h4&gt;主要发现&lt;/h4&gt;在ShapeNet上训练了该架构，并在ScanNet++数据集提取的对象实例以及全复制品场景上证明了其泛化能力。&lt;h4&gt;结论&lt;/h4&gt;基于超二次元的紧凑表示对于各种下游应用非常有用，包括机器人任务和可控制的可视内容生成与编辑。&lt;h4&gt;翻译&lt;/h4&gt;我们提出SuperDec方法，通过将3D场景分解为超二次元基元来创建紧凑的3D场景表示。尽管最近的研究大多利用几何基元来获得逼真的3D场景表示，但我们提出利用这些基元来获得紧凑且富有表现力的表示。我们提出在局部对单个对象进行处理，并利用实例分割方法将解决方案扩展到整个3D场景。为此，我们设计了一种新的架构，能够有效地将任意对象的点云分解为紧凑的超二次元集。我们在ShapeNet上训练了该架构，并在ScanNet++数据集提取的对象实例以及全复制品场景上证明了其泛化能力。最后，我们展示了基于超二次元的紧凑表示在机器人任务和可控制的可视内容生成与编辑等多种下游应用中的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present SuperDec, an approach for creating compact 3D scenerepresentations via decomposition into superquadric primitives. While mostrecent works leverage geometric primitives to obtain photorealistic 3D scenerepresentations, we propose to leverage them to obtain a compact yet expressiverepresentation. We propose to solve the problem locally on individual objectsand leverage the capabilities of instance segmentation methods to scale oursolution to full 3D scenes. In doing that, we design a new architecture whichefficiently decompose point clouds of arbitrary objects in a compact set ofsuperquadrics. We train our architecture on ShapeNet and we prove itsgeneralization capabilities on object instances extracted from the ScanNet++dataset as well as on full Replica scenes. Finally, we show how a compactrepresentation based on superquadrics can be useful for a diverse range ofdownstream applications, including robotic tasks and controllable visualcontent generation and editing.</description>
      <author>example@mail.com (Elisabetta Fedele, Boyang Sun, Leonidas Guibas, Marc Pollefeys, Francis Engelmann)</author>
      <guid isPermaLink="false">2504.00992v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Adversarial Curriculum Graph-Free Knowledge Distillation for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.00540v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种快速且高质量的无数据知识蒸馏方法ACGKD，用于图神经网络的知识蒸馏，解决了视觉领域方法在图数据上的无效性问题。&lt;h4&gt;背景&lt;/h4&gt;传统的知识蒸馏方法在处理图数据时效果不佳，因为图数据的拓扑结构和非网格性质使得视觉领域的方法不适用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，能够在不牺牲蒸馏质量的前提下，显著降低伪图的时空复杂度，并提高图神经网络知识蒸馏的效率。&lt;h4&gt;方法&lt;/h4&gt;ACGKD方法利用二进制具体分布来建模图结构，并引入空间复杂度调整参数，以实现高效的梯度计算。此外，通过增加学生的维度并复用教师的分类器来消除学生和教师模型之间的维度歧义，并采用基于CL的策略确保学生逐步学习图结构。&lt;h4&gt;主要发现&lt;/h4&gt;ACGKD在从GNNs进行知识蒸馏而不需要训练数据的情况下，达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;ACGKD是一种有效的无数据知识蒸馏方法，特别适用于图神经网络，能够显著提高知识蒸馏的效率和质量。&lt;h4&gt;翻译&lt;/h4&gt;Data-free Knowledge Distillation (DFKD)是一种使用生成器构建伪样本而不需要真实数据的方法，通过强制学生克服维度差异并学习在伪样本上模仿教师模型的输出，将知识从教师模型转移到学生模型。近年来，在视觉领域，关于此领域的研究取得了显著的进展。然而，图数据的可变拓扑结构和非网格性质使得视觉领域的方法无效。在先前关于图神经网络可微分方法的研究基础上，本文提出了一种快速且高质量的无数据知识蒸馏方法。在不影响蒸馏质量的前提下，所提出的无图KD方法（ACGKD）通过利用二进制具体分布来建模图结构并引入空间复杂度调整参数，显著降低了伪图的时空复杂度。这种方法使得图结构的梯度计算变得高效，从而加速了整体蒸馏过程。此外，ACGKD通过增加学生的维度并复用教师的分类器来消除学生和教师模型之间的维度歧义，并为图知识蒸馏提供了一种基于CL的策略，以确保学生逐步学习图结构。广泛的实验表明，ACGKD在从GNNs进行知识蒸馏而不需要训练数据的情况下，达到了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data-free Knowledge Distillation (DFKD) is a method that constructspseudo-samples using a generator without real data, and transfers knowledgefrom a teacher model to a student by enforcing the student to overcomedimensional differences and learn to mimic the teacher's outputs on thesepseudo-samples. In recent years, various studies in the vision domain have madenotable advancements in this area. However, the varying topological structuresand non-grid nature of graph data render the methods from the vision domainineffective. Building upon prior research into differentiable methods for graphneural networks, we propose a fast and high-quality data-free knowledgedistillation approach in this paper. Without compromising distillation quality,the proposed graph-free KD method (ACGKD) significantly reduces the spatialcomplexity of pseudo-graphs by leveraging the Binary Concrete distribution tomodel the graph structure and introducing a spatial complexity tuningparameter. This approach enables efficient gradient computation for the graphstructure, thereby accelerating the overall distillation process. Additionally,ACGKD eliminates the dimensional ambiguity between the student and teachermodels by increasing the student's dimensions and reusing the teacher'sclassifier. Moreover, it equips graph knowledge distillation with a CL-basedstrategy to ensure the student learns graph structures progressively. Extensiveexperiments demonstrate that ACGKD achieves state-of-the-art performance indistilling knowledge from GNNs without training data.</description>
      <author>example@mail.com (Yuang Jia, Xiaojuan Shan, Jun Xia, Guancheng Wan, Yuchen Zhang, Wenke Huang, Mang Ye, Stan Z. Li)</author>
      <guid isPermaLink="false">2504.00540v2</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Shot-by-Shot: Film-Grammar-Aware Training-Free Audio Description Generation</title>
      <link>http://arxiv.org/abs/2504.01020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://www.robots.ox.ac.uk/vgg/research/shot-by-shot/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种自动生成视频材料音频描述的方法，使用了一个两阶段框架，以'镜头'作为视频理解的基本单位，并通过扩展时间上下文、整合电影语法工具来指导音频描述生成。&lt;h4&gt;背景&lt;/h4&gt;研究旨在自动生成视频材料的音频描述，如电影和电视剧。&lt;h4&gt;目的&lt;/h4&gt;目标是开发一种自动生成音频描述的系统，以提高视频内容的可访问性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个两阶段框架，利用镜头作为视频理解的基本单位，并扩展了时间上下文和电影语法工具。该方法兼容开源和专有视觉语言模型（VLMs），并通过附加模块集成专家知识，无需重新训练VLMs。&lt;h4&gt;主要发现&lt;/h4&gt;实现了在所有先前无训练方法中的最先进性能，甚至在某些基准测试中超过了微调方法。引入了新的评估指标——动作得分，用于评估预测的音频描述质量。还提出了一种新的评估协议，将自动框架作为音频描述生成助手，并要求它们生成多个候选音频描述以供选择。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在音频描述生成方面具有显著的性能提升，并且通过引入新的评估方法和协议，进一步提高了描述质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Our objective is the automatic generation of Audio Descriptions (ADs) foredited video material, such as movies and TV series. To achieve this, wepropose a two-stage framework that leverages "shots" as the fundamental unitsof video understanding. This includes extending temporal context toneighbouring shots and incorporating film grammar devices, such as shot scalesand thread structures, to guide AD generation. Our method is compatible withboth open-source and proprietary Visual-Language Models (VLMs), integratingexpert knowledge from add-on modules without requiring additional training ofthe VLMs. We achieve state-of-the-art performance among all prior training-freeapproaches and even surpass fine-tuned methods on several benchmarks. Toevaluate the quality of predicted ADs, we introduce a new evaluation measure --an action score -- specifically targeted to assessing this important aspect ofAD. Additionally, we propose a novel evaluation protocol that treats automaticframeworks as AD generation assistants and asks them to generate multiplecandidate ADs for selection.</description>
      <author>example@mail.com (Junyu Xie, Tengda Han, Max Bain, Arsha Nagrani, Eshika Khandelwal, Gül Varol, Weidi Xie, Andrew Zisserman)</author>
      <guid isPermaLink="false">2504.01020v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>WikiVideo: Article Generation from Multiple Videos</title>
      <link>http://arxiv.org/abs/2504.00939v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Repo can be found here: https://github.com/alexmartin1722/wikivideo&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种自动创建高级维基百科风格文章的挑战性任务，该文章从多个不同视频关于现实世界事件（如自然灾害或政治选举）中聚合信息。&lt;h4&gt;背景&lt;/h4&gt;视频是检索增强生成（RAG）的直观来源，但大多数当代RAG工作流程主要关注文本，而基于视频的现有摘要方法主要关注低级场景理解而不是高级事件语义。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一差距，本文介绍了WikiVideo，一个由专家编写的文章和密集注释的视频组成的基准，这些视频为文章的论点提供了证据，促进了视频在RAG管道中的集成，并能够创建基于多模态来源的深入内容。&lt;h4&gt;方法&lt;/h4&gt;进一步提出了协作文章生成（CAG），这是一种从多个视频中创建文章的新颖交互式方法。CAG通过r1风格的推理模型和VideoLLM之间的迭代交互，从比VideoLLM单独使用时更高的层次推断出关于目标事件的结论，而VideoLLM专注于低级视觉特征。&lt;h4&gt;主要发现&lt;/h4&gt;在占卜检索和RAG设置中，我们对最先进的VideoLLMs和CAG进行了基准测试，发现CAG在一致性上优于替代方法，同时为未来的研究提出了引人入胜的途径。&lt;h4&gt;结论&lt;/h4&gt;CAG在整合视频和创建基于多模态来源的深入内容方面表现出色，为未来的研究和应用提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种自动创建高级维基百科风格文章的挑战性任务，该文章从多个不同视频关于现实世界事件（如自然灾害或政治选举）中聚合信息。视频是检索增强生成（RAG）的直观来源，但大多数当代RAG工作流程主要关注文本，而基于视频的现有摘要方法主要关注低级场景理解而不是高级事件语义。为了填补这一差距，我们引入了WikiVideo，一个由专家编写的文章和密集注释的视频组成的基准，这些视频为文章的论点提供了证据，促进了视频在RAG管道中的集成，并能够创建基于多模态来源的深入内容。进一步，我们提出了协作文章生成（CAG），这是一种从多个视频中创建文章的新颖交互式方法。CAG通过r1风格的推理模型和VideoLLM之间的迭代交互，从比VideoLLM单独使用时更高的层次推断出关于目标事件的结论，而VideoLLM专注于低级视觉特征。我们在占卜检索和RAG设置中对最先进的VideoLLMs和CAG进行了基准测试，发现CAG在一致性上优于替代方法，同时为未来的研究提出了引人入胜的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present the challenging task of automatically creating a high-levelWikipedia-style article that aggregates information from multiple diversevideos about real-world events, such as natural disasters or politicalelections. Videos are intuitive sources for retrieval-augmented generation(RAG), but most contemporary RAG workflows focus heavily on text and existingmethods for video-based summarization focus on low-level scene understandingrather than high-level event semantics. To close this gap, we introduceWikiVideo, a benchmark consisting of expert-written articles and denselyannotated videos that provide evidence for articles' claims, facilitating theintegration of video into RAG pipelines and enabling the creation of in-depthcontent that is grounded in multimodal sources. We further proposeCollaborative Article Generation (CAG), a novel interactive method for articlecreation from multiple videos. CAG leverages an iterative interaction betweenan r1-style reasoning model and a VideoLLM to draw higher level inferencesabout the target event than is possible with VideoLLMs alone, which fixate onlow-level visual features. We benchmark state-of-the-art VideoLLMs and CAG inboth oracle retrieval and RAG settings and find that CAG consistentlyoutperforms alternative methods, while suggesting intriguing avenues for futurework.</description>
      <author>example@mail.com (Alexander Martin, Reno Kriz, William Gantt Walden, Kate Sanders, Hannah Recknor, Eugene Yang, Francis Ferraro, Benjamin Van Durme)</author>
      <guid isPermaLink="false">2504.00939v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>SPF-Portrait: Towards Pure Portrait Customization with Semantic Pollution-Free Fine-tuning</title>
      <link>http://arxiv.org/abs/2504.00396v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SPF-Portrait的文本驱动肖像定制方法，旨在消除语义污染，提高定制语义的理解能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基于预训练的文本到图像（T2I）模型在肖像数据集上进行微调时，虽然可以实现属性定制，但存在语义污染问题，这影响了原始模型的行为并阻碍了增量学习。&lt;h4&gt;目的&lt;/h4&gt;提出SPF-Portrait方法，以纯粹理解定制语义并消除文本驱动肖像定制中的语义污染。&lt;h4&gt;方法&lt;/h4&gt;SPF-Portrait采用双路径流水线，将原始模型作为传统微调路径的参考，通过对比学习确保对目标属性的适应，并有意将其他无关属性与原始肖像对齐。引入了一种新的语义感知精细控制图，以空间引导对比路径之间的对齐过程。此外，还提出了一种新的响应增强机制，以强化目标属性的性能，同时减轻直接跨模态监督中固有的表示差异。&lt;h4&gt;主要发现&lt;/h4&gt;SPF-Portrait不仅有效保留了原始模型的表现，还避免了过度对齐，并通过实验证明了其达到最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;SPF-Portrait在文本驱动肖像定制方面取得了显著的成果，为解决语义污染和提高定制效果提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;While fine-tuning pre-trained Text-to-Image (T2I) models on portrait datasets enables attribute customization, existing methods suffer from SemanticPollution that compromises the original model's behavior and prevents incremental learning. To address this, we propose SPF-Portrait, a pioneering work to purely understand customized semantics while eliminating semantic pollution in text-driven portrait customization. In our SPF-Portrait, we propose a dual-path pipeline that introduces the original model as a reference for the conventional fine-tuning path. Through contrastive learning, we ensure adaptation to target attributes and purposefully align other unrelated attributes with the original portrait. We introduce a novel Semantic-Aware FineControl Map, which represents the precise response regions of the target semantics, to spatially guide the alignment process between the contrastive paths. This alignment process not only effectively preserves the performance of the original model but also avoids over-alignment. Furthermore, we propose a novel response enhancement mechanism to reinforce the performance of target attributes, while mitigating representation discrepancy inherent in direct cross-modal supervision. Extensive experiments demonstrate that SPF-Portrait achieves state-of-the-art performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While fine-tuning pre-trained Text-to-Image (T2I) models on portrait datasetsenables attribute customization, existing methods suffer from SemanticPollution that compromises the original model's behavior and preventsincremental learning. To address this, we propose SPF-Portrait, a pioneeringwork to purely understand customized semantics while eliminating semanticpollution in text-driven portrait customization. In our SPF-Portrait, wepropose a dual-path pipeline that introduces the original model as a referencefor the conventional fine-tuning path. Through contrastive learning, we ensureadaptation to target attributes and purposefully align other unrelatedattributes with the original portrait. We introduce a novel Semantic-Aware FineControl Map, which represents the precise response regions of the targetsemantics, to spatially guide the alignment process between the contrastivepaths. This alignment process not only effectively preserves the performance ofthe original model but also avoids over-alignment. Furthermore, we propose anovel response enhancement mechanism to reinforce the performance of targetattributes, while mitigating representation discrepancy inherent in directcross-modal supervision. Extensive experiments demonstrate that SPF-Portraitachieves state-of-the-art performance.</description>
      <author>example@mail.com (Xiaole Xian, Zhichao Liao, Qingyu Li, Wenyu Qin, Pengfei Wan, Weicheng Xie, Long Zeng, Linlin Shen, Pingfa Feng)</author>
      <guid isPermaLink="false">2504.00396v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>NeuRadar: Neural Radiance Fields for Automotive Radar Point Clouds</title>
      <link>http://arxiv.org/abs/2504.00859v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于神经辐射场的雷达点云模型NeuRadar，该模型能够同时生成雷达点云、相机图像和激光雷达点云，并探讨了集合式目标检测方法，提高了模型的可推广性。&lt;h4&gt;背景&lt;/h4&gt;雷达在自动驾驶系统中至关重要，因为它对恶劣天气和不同光照条件具有鲁棒性。最近，神经辐射场（NeRFs）在自动驾驶领域受到关注，但尚未应用于雷达点云。&lt;h4&gt;目的&lt;/h4&gt;开发一个基于NeRF的雷达点云模型，实现雷达点云、相机图像和激光雷达点云的高效生成，并探索目标检测方法以提升模型性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于NeRF的模型NeuRadar，并采用了集合式目标检测方法，如DETR，以及基于NeRF几何的编码器解决方案。同时，提出了确定性和概率性点云表示方法来精确模拟雷达行为。&lt;h4&gt;主要发现&lt;/h4&gt;NeuRadar在两个汽车数据集上实现了逼真的重建结果，为基于NeRF的雷达点云模拟模型建立了基准。同时，发布了ZOD的序列和驾驶数据集的雷达数据，以及NeuRadar的源代码以促进进一步研究。&lt;h4&gt;结论&lt;/h4&gt;NeuRadar模型在雷达点云模拟方面取得了显著成果，为自动驾驶领域提供了新的研究工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：雷达是自动驾驶（AD）系统的重要传感器，由于其耐恶劣天气和不同光照条件的能力而重要。最近，由于其在自动驾驶中实现高效测试和验证的潜力，基于神经辐射场（NeRFs）的新颖视图合成已受到广泛关注，但雷达点云的研究尚处于未探索状态。在本文中，我们提出了NeuRadar，这是一个基于NeRF的模型，可以联合生成雷达点云、相机图像和激光雷达点云。我们探讨了基于集合的目标检测方法，如DETR，并提出了基于NeRF几何的编码器解决方案，以提高通用性。我们提出了确定性和概率性点云表示，以准确模拟雷达行为，后者能够捕捉雷达的随机行为。我们在两个汽车数据集上实现了逼真的重建结果，为基于NeRF的雷达点云模拟模型建立了基准。此外，我们发布了ZOD的序列和驾驶的雷达数据，以促进该领域的进一步研究。为了鼓励雷达NeRF的进一步发展，我们发布了NeuRadar的源代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radar is an important sensor for autonomous driving (AD) systems due to itsrobustness to adverse weather and different lighting conditions. Novel viewsynthesis using neural radiance fields (NeRFs) has recently receivedconsiderable attention in AD due to its potential to enable efficient testingand validation but remains unexplored for radar point clouds. In this paper, wepresent NeuRadar, a NeRF-based model that jointly generates radar point clouds,camera images, and lidar point clouds. We explore set-based object detectionmethods such as DETR, and propose an encoder-based solution grounded in theNeRF geometry for improved generalizability. We propose both a deterministicand a probabilistic point cloud representation to accurately model the radarbehavior, with the latter being able to capture radar's stochastic behavior. Weachieve realistic reconstruction results for two automotive datasets,establishing a baseline for NeRF-based radar point cloud simulation models. Inaddition, we release radar data for ZOD's Sequences and Drives to enablefurther research in this field. To encourage further development of radarNeRFs, we release the source code for NeuRadar.</description>
      <author>example@mail.com (Mahan Rafidashti, Ji Lan, Maryam Fatemi, Junsheng Fu, Lars Hammarstrand, Lennart Svensson)</author>
      <guid isPermaLink="false">2504.00859v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Output Prediction of Quantum Circuits based on Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.00464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNNs）的框架，用于预测量子电路在噪声和无噪声条件下的输出期望值，并比较不同参数化量子电路（PQCs）的性能。&lt;h4&gt;背景&lt;/h4&gt;量子电路的输出预测对于开发量子设备至关重要，但这是一个极具挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法来预测量子电路的输出期望值，并比较不同参数化量子电路的性能。&lt;h4&gt;方法&lt;/h4&gt;构建了无噪声和噪声条件下的数据集，使用非参数化量子门集来预测电路期望值。设计节点特征向量以包含噪声信息，并在有噪声和无噪声条件下比较GNNs和卷积神经网络（CNNs）的预测性能。使用参数化量子门集构建有噪声的PQCs，并使用变分量子本征求解器（VQE）计算氢分子的基态能量。提出了两种方案：间接比较方案和直接比较方案。&lt;h4&gt;主要发现&lt;/h4&gt;GNNs在多种条件下表现出优越的预测准确性。直接比较方案在相同数据集上平均比间接比较方案表现好36.2%，为使用GNNs预测PQCs的整体特性提供了新的有效视角。&lt;h4&gt;结论&lt;/h4&gt;GNNs是一种有效的工具，可以用于预测量子电路的输出期望值和比较不同PQCs的性能，特别是在关注它们的性能差异方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The output prediction of quantum circuits is a formidably challenging taskimperative in developing quantum devices. Motivated by the natural graphrepresentation of quantum circuits, this paper proposes a Graph Neural Networks(GNNs)-based framework to predict the output expectation values of quantumcircuits under noisy and noiseless conditions and compare the performance ofdifferent parameterized quantum circuits (PQCs). We construct datasets undernoisy and noiseless conditions using a non-parameterized quantum gate set topredict circuit expectation values. The node feature vectors for GNNs arespecifically designed to include noise information. In our simulations, wecompare the prediction performance of GNNs in both noisy and noiselessconditions against Convolutional Neural Networks (CNNs) on the same dataset andtheir qubit scalability. GNNs demonstrate superior prediction accuracy acrossdiverse conditions. Subsequently, we utilize the parameterized quantum gate setto construct noisy PQCs and compute the ground state energy of hydrogenmolecules using the Variational Quantum Eigensolver (VQE). We propose twoschemes: the Indirect Comparison scheme, which involves directly predicting theground state energy and subsequently comparing circuit performances, and theDirect Comparison scheme, which directly predicts the relative performance ofthe two circuits. Simulation results indicate that the Direct Comparison schemesignificantly outperforms the Indirect Comparison scheme by an average of 36.2%on the same dataset, providing a new and effective perspective for using GNNsto predict the overall properties of PQCs, specifically by focusing on theirperformance differences.</description>
      <author>example@mail.com (Yuxiang Liu, Fanxu Meng, Lu Wang, Yi Hu, Zaichen Zhang, Xutao Yu)</author>
      <guid isPermaLink="false">2504.00464v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>AttentiveGRU: Recurrent Spatio-Temporal Modeling for Advanced Radar-Based BEV Object Detection</title>
      <link>http://arxiv.org/abs/2504.00559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对雷达数据特性的注意力循环神经网络AttentiveGRU，用于Bird's-eye view (BEV)物体检测，显著提高了检测性能。&lt;h4&gt;背景&lt;/h4&gt;BEV物体检测在高级汽车3D雷达感知系统中至关重要，但雷达数据的稀疏性和非确定性限制了传统单帧BEV方法的效率。&lt;h4&gt;目的&lt;/h4&gt;解决雷达数据限制，提高BEV物体检测的性能。&lt;h4&gt;方法&lt;/h4&gt;提出AttentiveGRU，通过动态识别和融合时序相关结构来提取个性化的时空上下文信息，并利用物体潜在表示的一致性来丰富特征表示。&lt;h4&gt;主要发现&lt;/h4&gt;在nuScenes数据集上的实验结果显示，与最佳雷达检测提交相比，汽车类别的mAP提高了21%。在另一个数据集上的进一步评估也显示出显著的物体检测能力提升。&lt;h4&gt;结论&lt;/h4&gt;AttentiveGRU方法在物体检测能力上取得了显著进步，证明了其在实际应用中的有效性和适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bird's-eye view (BEV) object detection has become important for advancedautomotive 3D radar-based perception systems. However, the inherently sparseand non-deterministic nature of radar data limits the effectiveness oftraditional single-frame BEV paradigms. In this paper, we addresses thislimitation by introducing AttentiveGRU, a novel attention-based recurrentapproach tailored for radar constraints, which extracts individualizedspatio-temporal context for objects by dynamically identifying and fusingtemporally correlated structures across present and memory states. Byleveraging the consistency of object's latent representation over time, ourapproach exploits temporal relations to enrich feature representations for bothstationary and moving objects, thereby enhancing detection performance andeliminating the need for externally providing or estimating any informationabout ego vehicle motion. Our experimental results on the public nuScenesdataset show a significant increase in mAP for the car category by 21% over thebest radar-only submission. Further evaluations on an additional datasetdemonstrate notable improvements in object detection capabilities, underscoringthe applicability and effectiveness of our method.</description>
      <author>example@mail.com (Loveneet Saini, Mirko Meuter, Hasan Tercan, Tobias Meisen)</author>
      <guid isPermaLink="false">2504.00559v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Less is More: Efficient Black-box Attribution via Minimal Interpretable Subset Selection</title>
      <link>http://arxiv.org/abs/2504.00470v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LiMA的新型高效黑盒归因机制，用于识别对模型决策影响最大的输入区域。&lt;h4&gt;背景&lt;/h4&gt;现有的归因方法主要任务是高效准确地识别输入预测交互关系，特别是当输入数据为离散型，如图像时，分析输入和输出之间的关系面临巨大挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个可信的AI系统，识别对模型决策影响最大的输入区域。&lt;h4&gt;方法&lt;/h4&gt;LiMA将重要区域的归因重新定义为子模块子集选择的优化问题。首先，设计了一个子模块函数来量化子集的重要性并有效捕捉其对决策结果的影响。然后，通过一种新颖的双向贪婪搜索算法高效地排名输入子区域的重要性。&lt;h4&gt;主要发现&lt;/h4&gt;LiMA可以识别出最和最不重要的样本，同时确保最优的归因边界以最小化误差。实验表明，该方法提供了忠实于事实的解释，所需区域更少，表现出强大的泛化能力，在插入和删除方面平均提高了36.3%和39.6%，并且在归因效率上优于简单的贪婪搜索，速度快1.6倍。此外，在解释模型预测错误的原因时，LiMA的平均最高置信度比最先进的归因算法高出86.1%。&lt;h4&gt;结论&lt;/h4&gt;LiMA在归因方面具有高效性和准确性，为理解和改进AI模型提供了新的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：为了开发一个可信的AI系统，旨在识别对模型决策影响最大的输入区域。现有归因方法的主要任务是高效准确地识别输入预测交互关系。特别是在输入数据为离散型，如图像的情况下，由于组合爆炸，分析输入和输出之间的关系面临重大挑战。在本文中，我们提出了一种新颖且高效的黑盒归因机制LiMA（Less input is More faithful for Attribution），将重要区域的归因重新定义为子模块子集选择的优化问题。首先，为了准确评估交互关系，我们设计了一个子模块函数来量化子集的重要性并有效地捕捉其对决策结果的影响。然后，通过一种新颖的双向贪婪搜索算法，高效地按重要性排名输入子区域，从而提高优化效率。LiMA既识别出最和最不重要的样本，又确保了最优的归因边界以最小化误差。在八个基础模型上的大量实验表明，我们的方法提供了忠实于事实的解释，所需区域更少，表现出强大的泛化能力，在插入和删除方面平均提高了36.3%和39.6%，在归因效率上优于简单的贪婪搜索，速度快1.6倍。此外，在解释模型预测错误的原因时，我们的方法平均最高的置信度比最先进的归因算法高出86.1%。代码可在https://github.com/RuoyuChen10/LIMA获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To develop a trustworthy AI system, which aim to identify the input regionsthat most influence the models decisions. The primary task of existingattribution methods lies in efficiently and accurately identifying therelationships among input-prediction interactions. Particularly when the inputdata is discrete, such as images, analyzing the relationship between inputs andoutputs poses a significant challenge due to the combinatorial explosion. Inthis paper, we propose a novel and efficient black-box attribution mechanism,LiMA (Less input is More faithful for Attribution), which reformulates theattribution of important regions as an optimization problem for submodularsubset selection. First, to accurately assess interactions, we design asubmodular function that quantifies subset importance and effectively capturestheir impact on decision outcomes. Then, efficiently ranking input sub-regionsby their importance for attribution, we improve optimization efficiency througha novel bidirectional greedy search algorithm. LiMA identifies both the mostand least important samples while ensuring an optimal attribution boundary thatminimizes errors. Extensive experiments on eight foundation models demonstratethat our method provides faithful interpretations with fewer regions andexhibits strong generalization, shows an average improvement of 36.3% inInsertion and 39.6% in Deletion. Our method also outperforms the naive greedysearch in attribution efficiency, being 1.6 times faster. Furthermore, whenexplaining the reasons behind model prediction errors, the average highestconfidence achieved by our method is, on average, 86.1% higher than that ofstate-of-the-art attribution algorithms. The code is available athttps://github.com/RuoyuChen10/LIMA.</description>
      <author>example@mail.com (Ruoyu Chen, Siyuan Liang, Jingzhi Li, Shiming Liu, Li Liu, Hua Zhang, Xiaochun Cao)</author>
      <guid isPermaLink="false">2504.00470v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Reducing Smoothness with Expressive Memory Enhanced Hierarchical Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.00349v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HiGFlow的分层图流网络，用于时间序列数据的图形预测模型，通过在多个分辨率上分析时间序列数据，提高了全球天气预报等任务中的预测效果。&lt;h4&gt;背景&lt;/h4&gt;图形预测模型通过将时间序列数据投影到图上来学习其结构，最近的技术通过边权重捕捉变量之间的时空关联。&lt;h4&gt;目的&lt;/h4&gt;提出HiGFlow网络以解决分层模型中信息损失的问题，并提高预测效果。&lt;h4&gt;方法&lt;/h4&gt;HiGFlow网络引入了一个动态大小的内存缓冲变量，用于存储不同变量分辨率下之前看到的信息。该网络通过减少映射到新特征空间时的平滑度，并提高Weisfeiler-Lehman (WL) 表达性来增强消息传递的效用。&lt;h4&gt;主要发现&lt;/h4&gt;HiGFlow在降低平滑度和提高消息传递的效用方面取得了理论上的关键成果。实证结果表明，HiGFlow在MAE和RMSE指标上优于包括transformer模型在内的最先进基线，平均提高了6.1%和6.2%。&lt;h4&gt;结论&lt;/h4&gt;HiGFlow网络在时间序列预测任务中表现出色，特别是在需要处理低分辨率变量交互的全球天气预报等任务中。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a Hierarchical Graph Flow (HiGFlow) network for graphical forecasting models on time series data, which improves the prediction effect by analyzing time series data across multiple resolutions, especially in tasks like global weather forecasting that require handling low-resolution variable interactions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphical forecasting models learn the structure of time series data viaprojecting onto a graph, with recent techniques capturing spatial-temporalassociations between variables via edge weights. Hierarchical variants offer adistinct advantage by analysing the time series across multiple resolutions,making them particularly effective in tasks like global weather forecasting,where low-resolution variable interactions are significant. A criticalchallenge in hierarchical models is information loss during forward or backwardpasses through the hierarchy. We propose the Hierarchical Graph Flow (HiGFlow)network, which introduces a memory buffer variable of dynamic size to storepreviously seen information across variable resolutions. We theoretically showtwo key results: HiGFlow reduces smoothness when mapping onto new featurespaces in the hierarchy and non-strictly enhances the utility ofmessage-passing by improving Weisfeiler-Lehman (WL) expressivity. Empiricalresults demonstrate that HiGFlow outperforms state-of-the-art baselines,including transformer models, by at least an average of 6.1% in MAE and 6.2% inRMSE. Code is available at https://github.com/TB862/ HiGFlow.git.</description>
      <author>example@mail.com (Thomas Bailie, Yun Sing Koh, S. Karthik Mukkavilli, Varvara Vetrova)</author>
      <guid isPermaLink="false">2504.00349v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Near-surface coherent structures in an intense tropical cyclone: conditional eddies and vertical momentum fluxes</title>
      <link>http://arxiv.org/abs/2504.00293v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究热带气旋边界层中湍流结构的间歇性及其对眼壁动量动力学的影响。&lt;h4&gt;背景&lt;/h4&gt;湍流结构的间歇性使得其难以完全表征，尤其是对眼壁动量动力学的影响。&lt;h4&gt;目的&lt;/h4&gt;使用大涡模拟输出，研究极端雷诺应力事件相关的条件平均涡旋的三维结构。&lt;h4&gt;方法&lt;/h4&gt;使用31米水平网格和15米垂直网格间距的大涡模拟，进行二维和三维分析。&lt;h4&gt;主要发现&lt;/h4&gt;对于喷射事件，条件涡旋结构大致倾斜于流入边界层中的平均流动方向，在眼壁的外部和内部区域。对于扫掠事件，涡旋核心的连贯性较低。研究发现的涡旋性质表明，简单壁面湍流中的连贯结构与复杂环境流中的结构相似。&lt;h4&gt;结论&lt;/h4&gt;研究结果揭示了热带气旋边界层中湍流结构的复杂性及其与简单壁面湍流结构的相似性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The intermittency of coherent turbulent structures in the tropical cycloneboundary layer makes them challenging to fully characterize, especiallyregarding their impact on momentum dynamics in the eyewall. Furthermore, thefine spatial and temporal model resolution needed to resolve these structureshas long impeded their understanding. Using the output of a large eddysimulation (with 31-m horizontal and 15-m vertical grid spacing), weinvestigate the three-dimensional structure of conditionally averaged eddiesassociated with extreme Reynolds stress events in the near-surface region of acategory 5 tropical cyclone. For ejection events, we find (using two- andthree-dimensional analysis) that the structure of the conditional eddy is avortex core roughly inclined toward the direction of the mean flow in theinflowing boundary layer, outer and inner eyewall region. For sweep events,this vortex core is less coherent. The nature of the educed eddies found inthis study suggests a similarity between the coherent structures in simplerwall-bounded turbulent flows and those in complex environmental flows.</description>
      <author>example@mail.com (Chibueze N. Oguejiofor, David H. Richter)</author>
      <guid isPermaLink="false">2504.00293v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Simple yet Effective Node Property Prediction on Edge Streams under Distribution Shifts</title>
      <link>http://arxiv.org/abs/2504.00328v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 14 figures, To Appear in ICDE 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为SPLASH的方法，用于在边缘流中预测节点属性，特别适用于分布偏移的情况。&lt;h4&gt;背景&lt;/h4&gt;节点属性预测在图上的应用广泛，但现实世界数据集的图随时间演变，给节点属性预测带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出SPLASH方法，以提高在分布偏移的情况下预测节点属性的有效性。&lt;h4&gt;方法&lt;/h4&gt;SPLASH包括特征增强方法、自动特征选择方法、轻量级的MLP-TGNN架构。&lt;h4&gt;主要发现&lt;/h4&gt;大多数基于TGNN的方法在没有适当节点特征的情况下效果较差，并且由于复杂的模型架构，容易受到分布偏移的影响。&lt;h4&gt;结论&lt;/h4&gt;SPLASH在动态节点分类、动态异常检测和节点亲和力预测任务上表现优异。&lt;h4&gt;翻译&lt;/h4&gt;摘要：节点属性（例如，节点类别）预测在图上的问题因其在广泛领域的应用而受到广泛关注。来自现实世界数据集的图通常随时间演变，新出现的边缘和动态变化的节点属性给此问题带来了重大挑战。为了应对这一问题，已经开发了时序图神经网络（TGNNs）来从新兴边缘的流中预测动态节点属性。然而，我们的分析显示，大多数基于TGNN的方法（a）在没有适当节点特征的情况下效果较差，（b）由于它们复杂的模型架构，容易受到分布偏移的影响。在本文中，我们提出了SPLASH，这是一种简单而强大的方法，用于在分布偏移的情况下在边缘流上预测节点属性。我们的主要贡献如下：（1）我们提出了边缘流的特征增强方法和自动特征选择方法，提高了TGNNs的有效性；（2）我们提出了一种轻量级的基于MLP的TGNN架构，它在分布偏移下高度高效和鲁棒；（3）我们在七个真实世界数据集上进行了广泛的实验，以评估所提出的方法及其竞争对手在动态节点分类、动态异常检测和节点亲和力预测任务中的准确性、效率、泛化能力和定性性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The problem of predicting node properties (e.g., node classes) in graphs hasreceived significant attention due to its broad range of applications. Graphsfrom real-world datasets often evolve over time, with newly emerging edges anddynamically changing node properties, posing a significant challenge for thisproblem. In response, temporal graph neural networks (TGNNs) have beendeveloped to predict dynamic node properties from a stream of emerging edges.However, our analysis reveals that most TGNN-based methods are (a) far lesseffective without proper node features and, due to their complex modelarchitectures, (b) vulnerable to distribution shifts. In this paper, we proposeSPLASH, a simple yet powerful method for predicting node properties on edgestreams under distribution shifts. Our key contributions are as follows: (1) wepropose feature augmentation methods and an automatic feature selection methodfor edge streams, which improve the effectiveness of TGNNs, (2) we propose alightweight MLP-based TGNN architecture that is highly efficient and robustunder distribution shifts, and (3) we conduct extensive experiments to evaluatethe accuracy, efficiency, generalization, and qualitative performance of theproposed method and its competitors on dynamic node classification, dynamicanomaly detection, and node affinity prediction tasks across seven real-worlddatasets.</description>
      <author>example@mail.com (Jongha Lee, Taehyung Kwon, Heechan Moon, Kijung Shin)</author>
      <guid isPermaLink="false">2504.00328v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>A Novel Deep Learning Method for Detecting Nucleon-Nucleon Correlations</title>
      <link>http://arxiv.org/abs/2504.00790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究使用SMASH模型探究核子-核子相关性对重离子碰撞的影响，开发了一种结合单核子分布和核子-核子相关性的蒙特卡洛采样方法，通过深度学习技术提高了分类准确率。&lt;h4&gt;背景&lt;/h4&gt;使用SMASH模型研究重离子碰撞中的核子-核子相关性。&lt;h4&gt;目的&lt;/h4&gt;通过比较不同初始核配置，揭示核子-核子相关性对重离子碰撞的影响，并开发新的分类方法。&lt;h4&gt;方法&lt;/h4&gt;采用SMASH模型，结合单核子分布和核子-核子相关性，使用深度学习技术进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;在传统可观测量中，除了超中心碰撞外，不同初始核配置之间的差异最小。传统的分类方法在区分无相关性和核子-核子相关性配置时失败，而新开发的深度学习方法提高了分类准确率。&lt;h4&gt;结论&lt;/h4&gt;新方法能够通过高维潜在空间中的统计分析提取细微的核结构信号，为研究重离子碰撞中的初始态核性质和夸克-胶子等离子体特性提供了新的途径，克服了传统单事件分析的局限性。&lt;h4&gt;翻译&lt;/h4&gt;本研究利用SMASH模型，通过蒙特卡洛采样方法结合单核子分布和核子-核子相关性，研究了核子-核子相关性对重离子碰撞的影响。我们开发了一种创新的方法，通过比较标准Woods-Saxon分布（无相关性）、硬球排斥（步骤相关性）和从头计算的核子-核子相关性（nn相关性）三种初始核配置，发现除了超中心碰撞外，传统可观测量之间差异最小。在区分无相关性和nn相关性配置时，传统的基于注意力的点云网络和多事件混合分类器失败（准确率约为50%）。为了解决这个问题，我们开发了一种新的深度学习架构，结合多事件统计和高维潜在空间特征相关性，实现了60%的整体分类准确率，对于中心碰撞，准确率提高到70%。这种方法通过高维潜在空间中的统计分析提取细微的核结构信号，为研究重离子碰撞中的初始态核性质和夸克-胶子等离子体特性提供了新的范式，克服了传统单事件分析在检测细微初始态差异方面的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study investigates the impact of nucleon-nucleon correlations onheavy-ion collisions using the hadronic transport model SMASH in $\sqrt{s_{\rmNN}}=3$ GeV $^{197}{\rm Au}$+$^{197}{\rm Au}$ collisions. We developed aninnovative Monte Carlo sampling method that incorporates both single-nucleondistributions and nucleon-nucleon correlations. By comparing three initialnuclear configurations - a standard Woods-Saxon distribution (un-corr),hard-sphere repulsion (step corr), and ab initio nucleon-nucleon correlations(nn-corr)- we revealed minimal differences in traditional observables exceptfor ultra-central collisions. When distinguishing between un-corr and nn-corrconfigurations, conventional attention-based point cloud networks andmulti-event mixing classifiers failed (accuracy ~50%). To resolve this, wedeveloped a novel deep learning architecture integrating multi-event statisticsand high-dimensional latent space feature correlations, achieving 60\% overallclassification accuracy, which improved to 70\% for central collisions. Thismethod enables the extraction of subtle nuclear structure signals throughstatistical analysis in high-dimensional latent space, offering a new paradigmfor studying initial-state nuclear properties and quark-gluon plasmacharacteristics in heavy-ion collisions. It overcomes the limitations oftraditional single-event analysis in detecting subtle initial-statedifferences.</description>
      <author>example@mail.com (Yu-Jing Huang, Zhu Meng, Long-Gang Pang, Xin-Nian Wang)</author>
      <guid isPermaLink="false">2504.00790v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>How does Watermarking Affect Visual Language Models in Document Understanding?</title>
      <link>http://arxiv.org/abs/2504.01048v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了水印对视觉语言模型（VLMs）在文档理解任务中的性能影响，并提出了相应的评估框架。&lt;h4&gt;背景&lt;/h4&gt;VLMs在处理跨领域如金融、法律和学术的复杂多模态文档中被广泛应用，但文档中常含有如水印等噪声信息。&lt;h4&gt;目的&lt;/h4&gt;探究水印对VLMs性能的影响，并提出评估水印影响的框架。&lt;h4&gt;方法&lt;/h4&gt;考虑了不同类型的文档数据、水印在文档中的位置和内容变化等因素，通过实验分析了水印对VLMs性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;水印会显著降低VLMs的性能，性能下降率可达36%。分散的水印比集中的水印造成更强的干扰，水印中的语义内容比简单的视觉遮挡造成更大的破坏。&lt;h4&gt;结论&lt;/h4&gt;水印通过强制广泛的注意力重分配和改变嵌入空间中的语义表示来降低性能。研究强调了在文档理解任务中部署VLMs的挑战，并为开发对水印文档鲁棒的推理机制提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉语言模型（VLMs）已成为文档理解任务的基础模型，广泛应用于处理金融、法律和学术等领域的复杂多模态文档。然而，文档常常包含如水印等噪声信息，这不可避免地引出了以下问题：水印是否会影响VLMs在文档理解中的性能？为了解决这个问题，我们提出了一种新的评估框架来研究可见水印对VLMs性能的影响。我们考虑了各种因素，包括不同类型的文档数据、水印在文档中的位置和内容变化。我们的实验结果表明，水印可以显著降低VLMs的性能，性能下降率高达36%。我们发现分散的水印比集中的水印造成更强的干扰，水印中的语义内容比简单的视觉遮挡造成更大的破坏。通过注意力机制分析和嵌入相似性检查，我们发现性能下降主要是由于水印1）强制广泛的注意力重分配，2）改变嵌入空间中的语义表示。我们的研究不仅突出了在文档理解任务中部署VLMs的挑战，还为开发对水印文档鲁棒的推理机制提供了见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Language Models (VLMs) have become foundational models for documentunderstanding tasks, widely used in the processing of complex multimodaldocuments across domains such as finance, law, and academia. However, documentsoften contain noise-like information, such as watermarks, which inevitablyleads us to inquire: \emph{Do watermarks degrade the performance of VLMs indocument understanding?} To address this, we propose a novel evaluationframework to investigate the effect of visible watermarks on VLMs performance.We takes into account various factors, including different types of documentdata, the positions of watermarks within documents and variations in watermarkcontent. Our experimental results reveal that VLMs performance can besignificantly compromised by watermarks, with performance drop rates reachingup to 36\%. We discover that \emph{scattered} watermarks cause strongerinterference than centralized ones, and that \emph{semantic contents} inwatermarks creates greater disruption than simple visual occlusion. Throughattention mechanism analysis and embedding similarity examination, we find thatthe performance drops are mainly attributed to that watermarks 1) forcewidespread attention redistribution, and 2) alter semantic representation inthe embedding space. Our research not only highlights significant challenges indeploying VLMs for document understanding, but also provides insights towardsdeveloping robust inference mechanisms on watermarked documents.</description>
      <author>example@mail.com (Chunxue Xu, Yiwei Wang, Bryan Hooi, Yujun Cai, Songze Li)</author>
      <guid isPermaLink="false">2504.01048v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>CamoSAM2: Motion-Appearance Induced Auto-Refining Prompts for Video Camouflaged Object Detection</title>
      <link>http://arxiv.org/abs/2504.00375v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures,&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SAM2在视频对象分割中表现出色，但在面对伪装物体时存在挑战，本文提出了CamoSAM2模型，通过运动-外观提示诱导（MAPI）和细化框架来生成和优化提示，提高分割质量。&lt;h4&gt;背景&lt;/h4&gt;SAM2在视频对象分割中表现出色，但伪装物体难以识别，给自动分割带来挑战。&lt;h4&gt;目的&lt;/h4&gt;提出CamoSAM2模型，解决SAM2在伪装物体分割中的问题，实现高质量自动检测和分割。&lt;h4&gt;方法&lt;/h4&gt;1. 提出运动-外观提示诱导器（MAPI）来检测伪装物体；2. 提出视频自适应多提示细化（AMPR）策略；3. 通过伪装物体确定、关键帧选择和多提示形成三步生成可靠提示。&lt;h4&gt;主要发现&lt;/h4&gt;CamoSAM2在两个基准数据集上的实验表明，比现有方法在mIoU指标上提高了8.0%和10.1%，且推理速度最快。&lt;h4&gt;结论&lt;/h4&gt;CamoSAM2在视频对象分割任务中显著优于现有方法，提高了分割精度和速度。&lt;h4&gt;翻译&lt;/h4&gt;The Segment Anything Model 2 (SAM2), a prompt-guided video foundation model, has remarkably performed in video object segmentation, drawing significant attention in the community. Due to the high similarity between camouflaged objects and their surroundings, which makes them difficult to distinguish even by the human eye, the application of SAM2 for automated segmentation in real-world scenarios faces challenges in camouflage perception and reliable prompts generation. To address these issues, we propose CamoSAM2, a motion-appearance prompt inducer (MAPI) and refinement framework to automatically generate and refine prompts for SAM2, enabling high-quality automatic detection and segmentation in VCOD task. Initially, we introduce a prompt inducer that simultaneously integrates motion and appearance cues to detect camouflaged objects, delivering more accurate initial predictions than existing methods. Subsequently, we propose a video-based adaptive multi-prompts refinement (AMPR) strategy tailored for SAM2, aimed at mitigating prompt error in initial coarse masks and further producing good prompts. Specifically, we introduce a novel three-step process to generate reliable prompts by camouflaged object determination, pivotal prompting frame selection, and multi-prompts formation. Extensive experiments conducted on two benchmark datasets demonstrate that our proposed model, CamoSAM2, significantly outperforms existing state-of-the-art methods, achieving increases of 8.0% and 10.1% in mIoU metric. Additionally, our method achieves the fastest inferencespeed compared to current VCOD models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Segment Anything Model 2 (SAM2), a prompt-guided video foundation model,has remarkably performed in video object segmentation, drawing significantattention in the community. Due to the high similarity between camouflagedobjects and their surroundings, which makes them difficult to distinguish evenby the human eye, the application of SAM2 for automated segmentation inreal-world scenarios faces challenges in camouflage perception and reliableprompts generation. To address these issues, we propose CamoSAM2, amotion-appearance prompt inducer (MAPI) and refinement framework toautomatically generate and refine prompts for SAM2, enabling high-qualityautomatic detection and segmentation in VCOD task. Initially, we introduce aprompt inducer that simultaneously integrates motion and appearance cues todetect camouflaged objects, delivering more accurate initial predictions thanexisting methods. Subsequently, we propose a video-based adaptive multi-promptsrefinement (AMPR) strategy tailored for SAM2, aimed at mitigating prompt errorin initial coarse masks and further producing good prompts. Specifically, weintroduce a novel three-step process to generate reliable prompts bycamouflaged object determination, pivotal prompting frame selection, andmulti-prompts formation. Extensive experiments conducted on two benchmarkdatasets demonstrate that our proposed model, CamoSAM2, significantlyoutperforms existing state-of-the-art methods, achieving increases of 8.0% and10.1% in mIoU metric. Additionally, our method achieves the fastest inferencespeed compared to current VCOD models.</description>
      <author>example@mail.com (Xin Zhang, Keren Fu, Qijun Zhao)</author>
      <guid isPermaLink="false">2504.00375v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Agentic Multimodal AI for Hyperpersonalized B2B and B2C Advertising in Competitive Markets: An AI-Driven Competitive Advertising Framework</title>
      <link>http://arxiv.org/abs/2504.00338v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多语言、多模态的人工智能框架，用于B2B和B2C市场的自主、超个性化广告。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型（FMs）在现实世界应用中的日益增长，对动态市场需要适应性、可靠性和高效的战略。&lt;h4&gt;目的&lt;/h4&gt;在化工行业中，通过AI发现的材料推动创新，但商业成功依赖于市场接受度，需要基础模型驱动的广告框架在现实环境中运行。&lt;h4&gt;方法&lt;/h4&gt;系统通过整合检索增强生成（RAG）、多模态推理和基于自适应角色的定位，生成与文化相关的、市场意识强的广告，以适应不断变化的消费者行为和竞争。验证结合了现实世界的产品实验和模拟人类殖民地代理，以建模消费者角色，大规模优化策略并确保隐私合规。合成实验反映了现实世界场景，使广告策略的成本效益测试成为可能，无需风险性A/B测试。结合结构化检索增强推理和上下文学习（ICL），框架提高了参与度，防止市场蚕食，并最大化回报率。&lt;h4&gt;主要发现&lt;/h4&gt;该框架将AI驱动的创新与市场接受度相结合，推动了多模态FMs在商业营销中的部署。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地提高广告的参与度和回报率，为商业营销中的高风险决策提供了支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing use of foundation models (FMs) in real-world applications demandsadaptive, reliable, and efficient strategies for dynamic markets. In thechemical industry, AI-discovered materials drive innovation, but commercialsuccess hinges on market adoption, requiring FM-driven advertising frameworksthat operate in-the-wild. We present a multilingual, multimodal AI frameworkfor autonomous, hyper-personalized advertising in B2B and B2C markets. Byintegrating retrieval-augmented generation (RAG), multimodal reasoning, andadaptive persona-based targeting, our system generates culturally relevant,market-aware ads tailored to shifting consumer behaviors and competition.Validation combines real-world product experiments with a Simulated HumanisticColony of Agents to model consumer personas, optimize strategies at scale, andensure privacy compliance. Synthetic experiments mirror real-world scenarios,enabling cost-effective testing of ad strategies without risky A/B tests.Combining structured retrieval-augmented reasoning with in-context learning(ICL), the framework boosts engagement, prevents market cannibalization, andmaximizes ROAS. This work bridges AI-driven innovation and market adoption,advancing multimodal FM deployment for high-stakes decision-making incommercial marketing.</description>
      <author>example@mail.com (Sakhinana Sagar Srinivas, Akash Das, Shivam Gupta, Venkataramana Runkana)</author>
      <guid isPermaLink="false">2504.00338v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>UnIRe: Unsupervised Instance Decomposition for Dynamic Urban Scene Reconstruction</title>
      <link>http://arxiv.org/abs/2504.00763v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于3D高斯分层（3DGS）的UnIRe方法，用于动态城市场景的重建和解构，以支持自动驾驶、城市规划和场景编辑。&lt;h4&gt;背景&lt;/h4&gt;现有的动态场景解构方法无法在不进行人工标注的情况下实现实例感知分解，这对于实例级场景编辑至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，能够利用RGB图像和LiDAR点云，在不需手动标注的情况下对场景进行实例感知分解。&lt;h4&gt;方法&lt;/h4&gt;引入了4D超级点，这是一种新颖的表示方法，能够在4D空间中对多帧LiDAR点进行聚类，从而基于时空相关性实现无监督的实例分离。这些4D超级点作为分解4D初始化的基础，为任意动态类提供空间和时间初始化，以训练动态3DGS，无需边界框或对象模板。此外，还引入了2D和3D空间中的平滑度正则化策略，进一步提高了时间稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在动态场景解构方面优于现有方法，同时实现了准确和灵活的实例级编辑，对于实际应用具有实用性。&lt;h4&gt;结论&lt;/h4&gt;UnIRe方法为动态城市场景的重建和解构提供了一种有效途径，对自动驾驶、城市规划和场景编辑等领域具有重要的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing and decomposing dynamic urban scenes is crucial for autonomousdriving, urban planning, and scene editing. However, existing methods fail toperform instance-aware decomposition without manual annotations, which iscrucial for instance-level scene editing.We propose UnIRe, a 3D GaussianSplatting (3DGS) based approach that decomposes a scene into a staticbackground and individual dynamic instances using only RGB images and LiDARpoint clouds. At its core, we introduce 4D superpoints, a novel representationthat clusters multi-frame LiDAR points in 4D space, enabling unsupervisedinstance separation based on spatiotemporal correlations. These 4D superpointsserve as the foundation for our decomposed 4D initialization, i.e., providingspatial and temporal initialization to train a dynamic 3DGS for arbitrarydynamic classes without requiring bounding boxes or objecttemplates.Furthermore, we introduce a smoothness regularization strategy inboth 2D and 3D space, further improving the temporal stability.Experiments onbenchmark datasets show that our method outperforms existing methods indecomposed dynamic scene reconstruction while enabling accurate and flexibleinstance-level editing, making it a practical solution for real-worldapplications.</description>
      <author>example@mail.com (Yunxuan Mao, Rong Xiong, Yue Wang, Yiyi Liao)</author>
      <guid isPermaLink="false">2504.00763v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>MPDrive: Improving Spatial Understanding with Marker-Based Prompt Learning for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2504.00379v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于标记的提示学习框架（MPDrive），用于解决自动驾驶视觉问答（AD-VQA）中的空间理解问题，通过使用视觉标记来表示空间坐标，提高了视觉感知和空间表达准确性。&lt;h4&gt;背景&lt;/h4&gt;AD-VQA依赖于模型的空间理解能力，但传统方法通过文本表示坐标，导致视觉坐标和文本描述之间存在语义差距，影响了空间信息的准确传递。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来改善AD-VQA中的空间信息表达，提高视觉感知和空间表达的准确性。&lt;h4&gt;方法&lt;/h4&gt;使用检测专家在物体区域上叠加数字标签来创建标记图像，将复杂的文本坐标生成转换为直观的基于文本的视觉标记预测。将原始图像和标记图像融合为场景级特征，并与检测先验结合以推导实例级特征，构建双粒度视觉提示来刺激LLM的空间感知能力。&lt;h4&gt;主要发现&lt;/h4&gt;在DriveLM和CODA-LM数据集上的实验表明，MPDrive实现了最先进的性能，特别是在需要复杂空间理解的情况下。&lt;h4&gt;结论&lt;/h4&gt;MPDrive通过使用视觉标记提高了AD-VQA中空间信息的表达，显著提升了视觉感知和空间表达的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous driving visual question answering (AD-VQA) aims to answerquestions related to perception, prediction, and planning based on givendriving scene images, heavily relying on the model's spatial understandingcapabilities. Prior works typically express spatial information through textualrepresentations of coordinates, resulting in semantic gaps between visualcoordinate representations and textual descriptions. This oversight hinders theaccurate transmission of spatial information and increases the expressiveburden. To address this, we propose a novel Marker-based Prompt learningframework (MPDrive), which represents spatial coordinates by concise visualmarkers, ensuring linguistic expressive consistency and enhancing the accuracyof both visual perception and spatial expression in AD-VQA. Specifically, wecreate marker images by employing a detection expert to overlay object regionswith numerical labels, converting complex textual coordinate generation intostraightforward text-based visual marker predictions. Moreover, we fuseoriginal and marker images as scene-level features and integrate them withdetection priors to derive instance-level features. By combining thesefeatures, we construct dual-granularity visual prompts that stimulate the LLM'sspatial perception capabilities. Extensive experiments on the DriveLM andCODA-LM datasets show that MPDrive achieves state-of-the-art performance,particularly in cases requiring sophisticated spatial understanding.</description>
      <author>example@mail.com (Zhiyuan Zhang, Xiaofan Li, Zhihao Xu, Wenjie Peng, Zijian Zhou, Miaojing Shi, Shuangping Huang)</author>
      <guid isPermaLink="false">2504.00379v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Monocular and Generalizable Gaussian Talking Head Animation</title>
      <link>http://arxiv.org/abs/2504.00665v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了MGGTalk，这是一种基于单目数据集的通用高斯头部动画方法，它能够推广到未见过的身份而无需个性化重训练。&lt;h4&gt;背景&lt;/h4&gt;之前的3D高斯分层（3DGS）方法需要难以获取的多视图数据集，以及繁琐的个性化学习和推理。&lt;h4&gt;目的&lt;/h4&gt;MGGTalk旨在实现更实际和更广泛的应用。&lt;h4&gt;方法&lt;/h4&gt;MGGTalk探索深度信息来增强几何和面部对称特性，补充几何和外观特征。首先，基于从深度估计获得的像素级几何信息，采用对称操作和点云过滤技术确保3DGS的完整和精确的位置参数。随后，采用带有对称先验的两阶段策略预测剩余的3DGS参数，首先预测可见面部区域的Gaussian参数，然后利用这些参数来改进对不可见区域的预测。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，MGGTalk在各种指标上超越了之前的最先进方法，实现了优越的性能。&lt;h4&gt;结论&lt;/h4&gt;MGGTalk在单目数据集上实现了一种通用的头部动画方法，能够在不进行个性化训练的情况下推广到未见过的身份，并在性能上优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we introduce Monocular and Generalizable Gaussian Talking HeadAnimation (MGGTalk), which requires monocular datasets and generalizes tounseen identities without personalized re-training. Compared with previous 3DGaussian Splatting (3DGS) methods that requires elusive multi-view datasets ortedious personalized learning/inference, MGGtalk enables more practical andbroader applications. However, in the absence of multi-view and personalizedtraining data, the incompleteness of geometric and appearance information posesa significant challenge. To address these challenges, MGGTalk explores depthinformation to enhance geometric and facial symmetry characteristics tosupplement both geometric and appearance features. Initially, based on thepixel-wise geometric information obtained from depth estimation, we incorporatesymmetry operations and point cloud filtering techniques to ensure a completeand precise position parameter for 3DGS. Subsequently, we adopt a two-stagestrategy with symmetric priors for predicting the remaining 3DGS parameters. Webegin by predicting Gaussian parameters for the visible facial regions of thesource image. These parameters are subsequently utilized to improve theprediction of Gaussian parameters for the non-visible regions. Extensiveexperiments demonstrate that MGGTalk surpasses previous state-of-the-artmethods, achieving superior performance across various metrics.</description>
      <author>example@mail.com (Shengjie Gong, Haojie Li, Jiapeng Tang, Dongming Hu, Shuangping Huang, Hao Chen, Tianshui Chen, Zhuoman Liu)</author>
      <guid isPermaLink="false">2504.00665v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>SciReplicate-Bench: Benchmarking LLMs in Agent-driven Algorithmic Reproduction from Research Papers</title>
      <link>http://arxiv.org/abs/2504.00255v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究评估了大型语言模型（LLMs）从近期自然语言处理（NLP）论文中算法描述生成代码的能力。&lt;h4&gt;背景&lt;/h4&gt;该任务需要两个关键能力：算法理解能力，即从论文和学术文献中综合信息来理解实现逻辑；以及编码专业知识，即识别依赖关系并正确实现必要的API。&lt;h4&gt;目的&lt;/h4&gt;为了便于严格评估，研究者们引入了SciReplicate-Bench，这是一个包含100个任务的标准，这些任务来自2024年发表的36篇NLP论文，具有详细的注释和全面的测试案例。&lt;h4&gt;方法&lt;/h4&gt;基于SciReplicate-Bench，研究者们提出了Sci-Reproducer，一个多智能体框架，包括一个文献智能体，它解释文献中的算法概念，和一个代码智能体，它从代码库中检索依赖关系并实现解决方案。为了评估算法理解，研究者们引入了推理图准确率，这量化了生成的推理图与从代码注释和结构中得到的参考推理图之间的相似性。为了评估实现质量，研究者们使用了执行准确率、CodeBLEU和代码库依赖/API召回率指标。&lt;h4&gt;主要发现&lt;/h4&gt;在实验中，研究者们评估了各种强大的非推理LLMs和推理LLMs作为基础模型。使用Sci-Reproducer表现最好的LLM仅达到39%的执行准确率，突显了该基准的难度。分析发现，缺失或不一致的算法描述是成功再现的关键障碍。&lt;h4&gt;结论&lt;/h4&gt;研究者们将开源其基准，并将在https://github.com/xyzCS/SciReplicate-Bench上提供代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study evaluates large language models (LLMs) in generating code fromalgorithm descriptions from recent NLP papers. The task requires two keycompetencies: (1) algorithm comprehension: synthesizing information from papersand academic literature to understand implementation logic, and (2) codingexpertise: identifying dependencies and correctly implementing necessary APIs.To facilitate rigorous evaluation, we introduce SciReplicate-Bench, a benchmarkof 100 tasks from 36 NLP papers published in 2024, featuring detailedannotations and comprehensive test cases. Building on SciReplicate-Bench, wepropose Sci-Reproducer, a multi-agent framework consisting of a Paper Agentthat interprets algorithmic concepts from literature and a Code Agent thatretrieves dependencies from repositories and implement solutions. To assessalgorithm understanding, we introduce reasoning graph accuracy, whichquantifies similarity between generated and reference reasoning graphs derivedfrom code comments and structure. For evaluating implementation quality, weemploy execution accuracy, CodeBLEU, and repository dependency/API recallmetrics. In our experiments, we evaluate various powerful Non-Reasoning LLMsand Reasoning LLMs as foundational models. The best-performing LLM usingSci-Reproducer achieves only 39% execution accuracy, highlighting thebenchmark's difficulty.Our analysis identifies missing or inconsistentalgorithm descriptions as key barriers to successful reproduction. We willopen-source our benchmark, and code athttps://github.com/xyzCS/SciReplicate-Bench.</description>
      <author>example@mail.com (Yanzheng Xiang, Hanqi Yan, Shuyin Ouyang, Lin Gui, Yulan He)</author>
      <guid isPermaLink="false">2504.00255v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Cal or No Cal? -- Real-Time Miscalibration Detection of LiDAR and Camera Sensors</title>
      <link>http://arxiv.org/abs/2504.01040v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于检测传感器校准状态的框架，通过对比学习对传感器数据进行校准状态分类，以实现更准确的环境表示和传感器融合应用。&lt;h4&gt;背景&lt;/h4&gt;传感器校准对于自动驾驶的安全性至关重要，目前存在从基于目标的离线校准向无目标的在线校准的趋势，但现有方法在实时性和资源需求上存在限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种校准检测框架，将重点从直接回归校准参数转移到校准状态的二分类（校准或未校准），以确保车辆在任何时候的安全。&lt;h4&gt;方法&lt;/h4&gt;采用对比学习方法，在潜在空间中比较不同传感器模态的嵌入特征，以分类校准状态，并分析了特征嵌入和校准错误，以突出方法性能。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在检测性能、推理时间和资源需求方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;该框架能够有效检测传感器校准状态，提高自动驾驶的安全性。&lt;h4&gt;翻译&lt;/h4&gt;The goal of extrinsic calibration is the alignment of sensor data to ensure an accurate representation of the surroundings and enable sensor fusion applications. From a safety perspective, sensor calibration is a key enabler of autonomous driving. In the current state of the art, a trend from target-based offline calibration towards targetless online calibration can be observed. However, online calibration is subject to strict real-time and resource constraints which are not met by state-of-the-art methods. This is mainly due to the high number of parameters to estimate, the reliance on geometric features, or the dependence on specific vehicle maneuvers. To meet these requirements and ensure the vehicle's safety at any time, we propose a miscalibration detection framework that shifts the focus from the direct regression of calibration parameters to a binary classification of the calibration state, i.e., calibrated or miscalibrated. Therefore, we propose a contrastive learning approach that compares embedded features in a latent space to classify the calibration state of two different sensor modalities. Moreover, we provide a comprehensive analysis of the feature embeddings and challenging calibration errors that highlight the performance of our approach. As a result, our method outperforms the current state-of-the-art in terms of detection performance, inference time, and resource demand. The code is open source and available on https://github.com/TUMFTM/MiscalibrationDetection.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The goal of extrinsic calibration is the alignment of sensor data to ensurean accurate representation of the surroundings and enable sensor fusionapplications. From a safety perspective, sensor calibration is a key enabler ofautonomous driving. In the current state of the art, a trend from target-basedoffline calibration towards targetless online calibration can be observed.However, online calibration is subject to strict real-time and resourceconstraints which are not met by state-of-the-art methods. This is mainly dueto the high number of parameters to estimate, the reliance on geometricfeatures, or the dependence on specific vehicle maneuvers. To meet theserequirements and ensure the vehicle's safety at any time, we propose amiscalibration detection framework that shifts the focus from the directregression of calibration parameters to a binary classification of thecalibration state, i.e., calibrated or miscalibrated. Therefore, we propose acontrastive learning approach that compares embedded features in a latent spaceto classify the calibration state of two different sensor modalities. Moreover,we provide a comprehensive analysis of the feature embeddings and challengingcalibration errors that highlight the performance of our approach. As a result,our method outperforms the current state-of-the-art in terms of detectionperformance, inference time, and resource demand. The code is open source andavailable on https://github.com/TUMFTM/MiscalibrationDetection.</description>
      <author>example@mail.com (Ilir Tahiraj, Jeremialie Swadiryus, Felix Fent, Markus Lienkamp)</author>
      <guid isPermaLink="false">2504.01040v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Diffusion Model and Image Foundation Model for Improved Correspondence Matching in Coronary Angiography</title>
      <link>http://arxiv.org/abs/2504.00191v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新的方法，用于在冠状动脉造影图像中进行准确的对应匹配，以重建3D冠状动脉结构，这对于冠状动脉疾病的精确诊断和治疗规划至关重要。&lt;h4&gt;背景&lt;/h4&gt;传统的匹配方法在自然图像中通常无法推广到X射线图像，因为X射线图像具有纹理缺失、对比度低和结构重叠等固有差异，这些问题因训练数据不足而加剧。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，本研究提出了一种新的流程，该流程使用条件扩散模型生成逼真的配对冠状动脉造影图像，为训练提供高质量的合成数据。&lt;h4&gt;方法&lt;/h4&gt;本研究采用了大规模图像基础模型来引导特征聚合，通过关注语义相关的区域和关键点，从而提高对应匹配的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在合成数据集上表现出优异的匹配性能，并且能够有效地推广到真实世界的数据集，为这项任务提供了一个实用的解决方案。&lt;h4&gt;结论&lt;/h4&gt;本研究还探讨了不同基础模型在对应匹配中的有效性，为利用高级图像基础模型进行医学影像应用提供了新的见解。&lt;h4&gt;翻译&lt;/h4&gt;Accurate correspondence matching in coronary angiography images is crucial for reconstructing 3D coronary artery structures, which is essential for precise diagnosis and treatment planning of coronary artery disease (CAD). Traditional matching methods for natural images often fail to generalize to X-ray images due to inherent differences such as lack of texture, lower contrast, and overlapping structures, compounded by insufficient training data. To address these challenges, we propose a novel pipeline that generates realistic paired coronary angiography images using a diffusion model conditioned on 2D projections of 3D reconstructed meshes from Coronary Computed Tomography Angiography (CCTA), providing high-quality synthetic data for training. Additionally, we employ large-scale image foundation models to guide feature aggregation, enhancing correspondence matching accuracy by focusing on semantically relevant regions and keypoints. Our approach demonstrates superior matching performance on synthetic datasets and effectively generalizes to real-world datasets, offering a practical solution for this task. Furthermore, our work investigates the efficacy of different foundation models in correspondence matching, providing novel insights into leveraging advanced image foundation models for medical imaging applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate correspondence matching in coronary angiography images is crucialfor reconstructing 3D coronary artery structures, which is essential forprecise diagnosis and treatment planning of coronary artery disease (CAD).Traditional matching methods for natural images often fail to generalize toX-ray images due to inherent differences such as lack of texture, lowercontrast, and overlapping structures, compounded by insufficient training data.To address these challenges, we propose a novel pipeline that generatesrealistic paired coronary angiography images using a diffusion modelconditioned on 2D projections of 3D reconstructed meshes from Coronary ComputedTomography Angiography (CCTA), providing high-quality synthetic data fortraining. Additionally, we employ large-scale image foundation models to guidefeature aggregation, enhancing correspondence matching accuracy by focusing onsemantically relevant regions and keypoints. Our approach demonstrates superiormatching performance on synthetic datasets and effectively generalizes toreal-world datasets, offering a practical solution for this task. Furthermore,our work investigates the efficacy of different foundation models incorrespondence matching, providing novel insights into leveraging advancedimage foundation models for medical imaging applications.</description>
      <author>example@mail.com (Lin Zhao, Xin Yu, Yikang Liu, Xiao Chen, Eric Z. Chen, Terrence Chen, Shanhui Sun)</author>
      <guid isPermaLink="false">2504.00191v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Robust LiDAR-Camera Calibration with 2D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2504.00525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in IEEE Robotics and Automation Letters. Code available at:  https://github.com/ShuyiZhou495/RobustCalibration&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于几何约束的LiDAR-camera系统校准方法，利用2D Gaussian Splatting技术，通过优化外参数和结合重投影与三角测量损失，提高了校准的鲁棒性和精度。&lt;h4&gt;背景&lt;/h4&gt;LiDAR-camera系统在机器人领域日益流行，校准是整合LiDAR和相机数据的关键步骤。传统的校准方法依赖辅助目标物体，操作复杂，而无需辅助目标的方法尚未达到实际效果。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需辅助目标物体的校准方法，利用2D Gaussian Splatting技术估计LiDAR-camera的外参数，并提高校准的鲁棒性和精度。&lt;h4&gt;方法&lt;/h4&gt;方法首先使用LiDAR点云重建无色的2D Gaussian Splatting，然后通过最小化光度损失更新高斯斑点的颜色，并在过程中优化外参数。此外，通过结合重投影和三角测量损失来克服光度损失的局限性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够有效估计LiDAR-camera的外参数，并通过结合多种损失函数提高了校准的鲁棒性和精度。&lt;h4&gt;结论&lt;/h4&gt;所提出的校准方法能够有效提高LiDAR-camera系统的校准性能，为机器人领域提供了一种新的校准解决方案。&lt;h4&gt;翻译&lt;/h4&gt;LiDAR-camera systems have become increasingly popular in robotics recently. A critical and initial step in integrating the LiDAR and camera data is the calibration of the LiDAR-camera system. Most existing calibration methods rely on auxiliary target objects, which often involve complex manual operations, whereas targetless methods have yet to achieve practical effectiveness. Recognizing that 2D Gaussian Splatting (2DGS) can reconstruct geometric information from camera image sequences, we propose a calibration method that estimates LiDAR-camera extrinsic parameters using geometric constraints. The proposed method begins by reconstructing colorless 2DGS using LiDAR point clouds. Subsequently, we update the colors of the Gaussian splats by minimizing the photometric loss. The extrinsic parameters are optimized during this process. Additionally, we address the limitations of the photometric loss by incorporating the reprojection and triangulation losses, thereby enhancing the calibration robustness and accuracy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2025.3552955&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR-camera systems have become increasingly popular in robotics recently. Acritical and initial step in integrating the LiDAR and camera data is thecalibration of the LiDAR-camera system. Most existing calibration methods relyon auxiliary target objects, which often involve complex manual operations,whereas targetless methods have yet to achieve practical effectiveness.Recognizing that 2D Gaussian Splatting (2DGS) can reconstruct geometricinformation from camera image sequences, we propose a calibration method thatestimates LiDAR-camera extrinsic parameters using geometric constraints. Theproposed method begins by reconstructing colorless 2DGS using LiDAR pointclouds. Subsequently, we update the colors of the Gaussian splats by minimizingthe photometric loss. The extrinsic parameters are optimized during thisprocess. Additionally, we address the limitations of the photometric loss byincorporating the reprojection and triangulation losses, thereby enhancing thecalibration robustness and accuracy.</description>
      <author>example@mail.com (Shuyi Zhou, Shuxiang Xie, Ryoichi Ishikawa, Takeshi Oishi)</author>
      <guid isPermaLink="false">2504.00525v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>SAVeD: Learning to Denoise Low-SNR Video for Improved Downstream Performance</title>
      <link>http://arxiv.org/abs/2504.00161v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://suzanne-stathatos.github.io/SAVeD Code page:  https://github.com/suzanne-stathatos/SAVeD&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SAVeD是一种自监督方法，用于降噪低信噪比视频，特别适用于水下声纳、超声和显微镜等场景，在分类、检测、跟踪和计数任务上优于现有视频降噪方法。&lt;h4&gt;背景&lt;/h4&gt;传统的视觉任务模型在自然图像中表现良好，但在低信噪比视频（如水下声纳、超声和显微镜视频）中表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为SAVeD的自监督方法，用于改善低信噪比视频的降噪效果。&lt;h4&gt;方法&lt;/h4&gt;SAVeD通过利用前景和背景运动差异，使用具有时间瓶颈的编码器-解码器来增强物体可见性，并仅使用原始噪声数据训练。&lt;h4&gt;主要发现&lt;/h4&gt;SAVeD在分类、检测、跟踪和计数任务上取得了显著改进，且资源需求低于现有视频降噪方法。&lt;h4&gt;结论&lt;/h4&gt;SAVeD是一种有效的低信噪比视频降噪方法，在多个视觉任务上表现出色。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型在自然图像的视觉任务上表现出色，但在低信噪比视频（如水下声纳、超声和显微镜视频）中表现不佳。我们引入了用于下游任务的时空增强和视频去噪（SAVeD），这是一种自监督方法，用于降噪低信噪比传感器视频，并且仅使用原始噪声数据进行训练。通过利用前景和背景运动差异，SAVeD使用具有时间瓶颈的编码器-解码器来增强物体可见性。我们的方法在分类、检测、跟踪和计数任务上取得了改进，并且在使用资源方面优于最先进的视频降噪方法。项目页面：https://suzanne-stathatos.github.io/SAVeD 代码页面：https://github.com/suzanne-stathatos/SAVeD&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models excel at vision tasks in natural images but fail in lowsignal-to-noise ratio (SNR) videos, such as underwater sonar, ultrasound, andmicroscopy. We introduce Spatiotemporal Augmentations and denoising in Videofor Downstream Tasks (SAVeD), a self-supervised method that denoises low-SNRsensor videos and is trained using only the raw noisy data. By leveragingdifferences in foreground and background motion, SAVeD enhances objectvisibility using an encoder-decoder with a temporal bottleneck. Our approachimproves classification, detection, tracking, and counting, outperformingstate-of-the-art video denoising methods with lower resource requirements.Project page: https://suzanne-stathatos.github.io/SAVeD Code page:https://github.com/suzanne-stathatos/SAVeD</description>
      <author>example@mail.com (Suzanne Stathatos, Michael Hobley, Markus Marks, Pietro Perona)</author>
      <guid isPermaLink="false">2504.00161v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Attention Networks for Lossless Point Cloud Attribute Compression</title>
      <link>http://arxiv.org/abs/2504.00481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by DCC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于点云无损属性压缩的深度层次注意力上下文模型，该模型利用多分辨率空间结构和残差学习，引入了一种简单有效的细节级别（LoD）结构以实现从粗到细的表示，并通过并行编码同一细化级别的点来提高效率。&lt;h4&gt;背景&lt;/h4&gt;点云数据在处理和存储过程中存在挑战，因此需要有效的压缩方法。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的点云无损属性压缩方法，以实现高效的数据压缩。&lt;h4&gt;方法&lt;/h4&gt;使用深度层次注意力上下文模型，结合多分辨率空间结构和残差学习，引入LoD结构，实现并行编码，并采用归一化处理和分割点云以优化时间复杂度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在颜色和反射属性方面提供了比最新G-PCC更好的编码性能，同时保持了更高效的编码和解码运行时间。&lt;h4&gt;结论&lt;/h4&gt;该模型能够有效地压缩点云数据，同时保持高压缩性能和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a deep hierarchical attention context model forlossless attribute compression of point clouds, leveraging a multi-resolutionspatial structure and residual learning. A simple and effective Level of Detail(LoD) structure is introduced to yield a coarse-to-fine representation. Toenhance efficiency, points within the same refinement level are encoded inparallel, sharing a common context point group. By hierarchically aggregatinginformation from neighboring points, our attention model learns contextualdependencies across varying scales and densities, enabling comprehensivefeature extraction. We also adopt normalization for position coordinates andattributes to achieve scale-invariant compression. Additionally, we segment thepoint cloud into multiple slices to facilitate parallel processing, furtheroptimizing time complexity. Experimental results demonstrate that the proposedmethod offers better coding performance than the latest G-PCC for color andreflectance attributes while maintaining more efficient encoding and decodingruntimes.</description>
      <author>example@mail.com (Yueru Chen, Wei Zhang, Dingquan Li, Jing Wang, Ge Li)</author>
      <guid isPermaLink="false">2504.00481v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>NeRF-Based defect detection</title>
      <link>http://arxiv.org/abs/2504.00270v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 11 figures, 2025 2nd International Conference on Remote  Sensing, Mapping and Image Processing (RSMIP 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于NeRF和数字孪生概念的自动化缺陷检测框架，通过无人机捕获图像并重建机械设备的3D模型，利用ICP算法对模型进行对齐，从而实现精确的点云分析以检测潜在缺陷。&lt;h4&gt;背景&lt;/h4&gt;工业自动化快速发展，对大规模机械的精确和高效缺陷检测提出了需求。传统的检查方法劳动密集、主观且存在危险性。&lt;h4&gt;目的&lt;/h4&gt;克服传统检查方法的挑战，提高检测精度，增强操作安全性，并提供一种可扩展的缺陷检测解决方案。&lt;h4&gt;方法&lt;/h4&gt;使用无人机捕获图像，重建机械的3D模型，并生成标准参考模型和当前状态模型进行比较。通过ICP算法对模型进行对齐，进行精确的点云分析。&lt;h4&gt;主要发现&lt;/h4&gt;该方法消除了人工检查，提高了准确性，增强了操作安全性，并为缺陷检测提供了一种可扩展的解决方案。&lt;h4&gt;结论&lt;/h4&gt;该方法在可靠和高效的工业应用中展现出巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着工业自动化的快速发展，对大规模机械的精确高效缺陷检测的需求日益凸显。传统的检查技术，包括手动攀爬高大结构进行视觉评估等，劳动密集、主观且往往存在危险。为了克服这些挑战，本文提出了一种基于神经辐射场（NeRF）和数字孪生概念的自动化缺陷检测框架。该系统利用无人机捕获图像并重建机械的3D模型，同时生成标准参考模型和当前状态模型以进行比较。通过迭代最近点（ICP）算法实现模型对齐，从而进行精确的点云分析以检测潜在的缺陷。通过消除人工检查，这种方法提高了准确性，增强了操作安全性，并为缺陷检测提供了一种可扩展的解决方案。所提出的方法在可靠和高效的工业应用中展现了巨大的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of industrial automation has highlighted the need forprecise and efficient defect detection in large-scale machinery. Traditionalinspection techniques, involving manual procedures such as scaling tallstructures for visual evaluation, are labor-intensive, subjective, and oftenhazardous. To overcome these challenges, this paper introduces an automateddefect detection framework built on Neural Radiance Fields (NeRF) and theconcept of digital twins. The system utilizes UAVs to capture images andreconstruct 3D models of machinery, producing both a standard reference modeland a current-state model for comparison. Alignment of the models is achievedthrough the Iterative Closest Point (ICP) algorithm, enabling precise pointcloud analysis to detect deviations that signify potential defects. Byeliminating manual inspection, this method improves accuracy, enhancesoperational safety, and offers a scalable solution for defect detection. Theproposed approach demonstrates great promise for reliable and efficientindustrial applications.</description>
      <author>example@mail.com (Tianqi, Ding, Dawei Xiang, Yijiashun Qi, Ze Yang, Zunduo Zhao, Tianyao Sun, Pengbin Feng, Haoyu Wang)</author>
      <guid isPermaLink="false">2504.00270v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Can DeepSeek Reason Like a Surgeon? An Empirical Evaluation for Vision-Language Understanding in Robotic-Assisted Surgery</title>
      <link>http://arxiv.org/abs/2503.23130v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DeepSeek系列模型在场景理解、问答和文本生成任务中表现出色，本研究探讨了其在机器人手术场景中的对话能力。&lt;h4&gt;背景&lt;/h4&gt;DeepSeek系列模型因其高效的训练范式和强大的推理能力在多个任务中表现出色。&lt;h4&gt;目的&lt;/h4&gt;研究DeepSeek模型在机器人手术场景中的对话能力，重点关注单短语问答、视觉问答和详细描述等任务。&lt;h4&gt;方法&lt;/h4&gt;使用EndoVis18和CholecT50等公开数据集及其对应的对话数据，对DeepSeek-V3模型进行广泛评估。&lt;h4&gt;主要发现&lt;/h4&gt;DeepSeek-V3在手术器械和软组织识别任务中表现良好，但在空间位置分析和手术动作理解方面存在显著局限性。在一般提示下，模型无法有效分析全局手术概念，且无法提供详细的手术场景洞察。&lt;h4&gt;结论&lt;/h4&gt;DeepSeek-V3未经针对手术特定数据集的微调，尚不适用于手术场景中的视觉语言任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; DeepSeek series have demonstrated outstanding performance in general sceneunderstanding, question-answering (QA), and text generation tasks, owing to itsefficient training paradigm and strong reasoning capabilities. In this study,we investigate the dialogue capabilities of the DeepSeek model in roboticsurgery scenarios, focusing on tasks such as Single Phrase QA, Visual QA, andDetailed Description. The Single Phrase QA tasks further include sub-tasks suchas surgical instrument recognition, action understanding, and spatial positionanalysis. We conduct extensive evaluations using publicly available datasets,including EndoVis18 and CholecT50, along with their corresponding dialoguedata. Our comprehensive evaluation results indicate that, when provided withspecific prompts, DeepSeek-V3 performs well in surgical instrument and tissuerecognition tasks However, DeepSeek-V3 exhibits significant limitations inspatial position analysis and struggles to understand surgical actionsaccurately. Additionally, our findings reveal that, under general prompts,DeepSeek-V3 lacks the ability to effectively analyze global surgical conceptsand fails to provide detailed insights into surgical scenarios. Based on ourobservations, we argue that the DeepSeek-V3 is not ready for vision-languagetasks in surgical contexts without fine-tuning on surgery-specific datasets.</description>
      <author>example@mail.com (Boyi Ma, Yanguang Zhao, Jie Wang, Guankun Wang, Kun Yuan, Tong Chen, Long Bai, Hongliang Ren)</author>
      <guid isPermaLink="false">2503.23130v2</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Skeletonization Quality Evaluation: Geometric Metrics for Point Cloud Analysis in Robotics</title>
      <link>http://arxiv.org/abs/2504.00032v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 12 figures, under-review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了骨架化技术在形状分析中的应用，重点关注定义和量化几何属性，以系统评估点云形状的骨架化结果。&lt;h4&gt;背景&lt;/h4&gt;骨架化是形状分析的有力工具，广泛应用于机器人等领域。尽管近年来骨架化算法得到了研究，但它们的性能很少通过详细的数值评估来量化。&lt;h4&gt;目的&lt;/h4&gt;定义和量化几何属性，系统评估点云形状骨架化结果，包括拓扑相似性、有界性、中心性和平滑性。&lt;h4&gt;方法&lt;/h4&gt;引入了代表性的度量定义和数值评分框架，用于分析不同场景下点云数据的骨架化结果，并提供一个开源工具以供研究社区评估和优化骨架模型。&lt;h4&gt;主要发现&lt;/h4&gt;提出了几何评估方法，并评估了其在不同机器人应用中的性能和敏感性。&lt;h4&gt;结论&lt;/h4&gt;本文为骨架化技术在点云形状分析中的应用提供了系统的方法和工具，有助于提高骨架模型的性能和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Skeletonization is a powerful tool for shape analysis, rooted in the inherentinstinct to understand an object's morphology. It has found applications acrossvarious domains, including robotics. Although skeletonization algorithms havebeen studied in recent years, their performance is rarely quantified withdetailed numerical evaluations. This work focuses on defining and quantifyinggeometric properties to systematically score the skeletonization results ofpoint cloud shapes across multiple aspects, including topological similarity,boundedness, centeredness, and smoothness. We introduce these representativemetric definitions along with a numerical scoring framework to analyzeskeletonization outcomes concerning point cloud data for different scenarios,from object manipulation to mobile robot navigation. Additionally, we providean open-source tool to enable the research community to evaluate and refinetheir skeleton models. Finally, we assess the performance and sensitivity ofthe proposed geometric evaluation methods from various robotic applications.</description>
      <author>example@mail.com (Qingmeng Wen, Yu-Kun Lai, Ze Ji, Seyed Amir Tafrishi)</author>
      <guid isPermaLink="false">2504.00032v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>A point cloud reconstruction method based on uncertainty feature enhancement for aerodynamic shape optimization</title>
      <link>http://arxiv.org/abs/2503.23082v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  There are some problems with the data that can lead to wrong  conclusions&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的点云自动编码器架构AE-BUFE，用于高效和精确地表示3D飞机形状，并通过不确定性分析优化设计空间，提高气动优化的成本效益。&lt;h4&gt;背景&lt;/h4&gt;形状表示的精度和设计空间的维度显著影响气动优化的成本和结果。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的点云自动编码器架构，以实现高效和精确的3D飞机形状表示，并通过不确定性分析优化设计空间。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为AE-BUFE的点云自动编码器架构，包括基于不确定性指数的特征增强模块和点云自动编码器模块。该方法通过学习点云几何表示的形状特征来建立低维潜在空间。&lt;h4&gt;主要发现&lt;/h4&gt;与现有的点云自动编码器架构和POD线性降维方法相比，新架构显著提高了低维潜在空间的提取效果。&lt;h4&gt;结论&lt;/h4&gt;基于AE-BUFE参数化方法开发的SBO优化框架在多目标气动优化设计中表现出高效性和工程实用性，同时确保了起飞和着陆性能，并在跨音速和超声速条件下提高了气动性能。&lt;h4&gt;翻译&lt;/h4&gt;The precision of shape representation and the dimensionality of the designspace significantly influence the cost and outcomes of aerodynamic optimization. The design space can be represented more compactly by maintaining geometric precision while reducing dimensions, hence enhancing the cost-effectiveness of the optimization process. This research presents a new point cloud autoencoder architecture, called AE-BUFE, designed to attain efficient and precise generalized representations of 3D aircraft through uncertainty analysis of the deformation relationships among surface gridpoints. The deep learning architecture consists of two components: the uncertainty index-based feature enhancement module and the point cloud autoencoder module. It learns the shape features of the point cloud geometric representation to establish a low-dimensional latent space. To assess and evaluate the efficiency of the method, a comparison was conducted with the prevailing point cloud autoencoder architecture and the proper orthogonal decomposition (POD) linear dimensionality reduction method under conditions of complex shape deformation. The results showed that the new architecture significantly improved the extraction effect of the low-dimensional latent space. Then, we developed the SBO optimization framework based on the AE-BUFE parameterization method and completed a multi-objective aerodynamic optimization design for a wide-speed-range vehicle considering volume and moment constraints. While ensuring the take-off and landing performance, the aerodynamic performance is improved at transonic and hypersonic conditions, which verifies the efficiency and engineering practicality of this method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The precision of shape representation and the dimensionality of the designspace significantly influence the cost and outcomes of aerodynamicoptimization. The design space can be represented more compactly by maintaininggeometric precision while reducing dimensions, hence enhancing thecost-effectiveness of the optimization process. This research presents a newpoint cloud autoencoder architecture, called AE-BUFE, designed to attainefficient and precise generalized representations of 3D aircraft throughuncertainty analysis of the deformation relationships among surface gridpoints. The deep learning architecture consists of two components: theuncertainty index-based feature enhancement module and the point cloudautoencoder module. It learns the shape features of the point cloud geometricrepresentation to establish a low-dimensional latent space. To assess andevaluate the efficiency of the method, a comparison was conducted with theprevailing point cloud autoencoder architecture and the proper orthogonaldecomposition (POD) linear dimensionality reduction method under conditions ofcomplex shape deformation. The results showed that the new architecturesignificantly improved the extraction effect of the low-dimensional latentspace. Then, we developed the SBO optimization framework based on the AE-BUFEparameterization method and completed a multi-objective aerodynamicoptimization design for a wide-speed-range vehicle considering volume andmoment constraints. While ensuring the take-off and landing performance, theaerodynamic performance is improved at transonic and hypersonic conditions,which verifies the efficiency and engineering practicability of this method.</description>
      <author>example@mail.com (Junlin Li, Yang Zhang, Bo Pang, Junqiang Bai, Jiakuan Xu)</author>
      <guid isPermaLink="false">2503.23082v3</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Mesh Compression with Quantized Neural Displacement Fields</title>
      <link>http://arxiv.org/abs/2504.01027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种简单而有效的方法，扩展了隐式神经网络表示（INRs）在压缩3D三角形网格中的应用。&lt;h4&gt;背景&lt;/h4&gt;隐式神经网络表示（INRs）已成功用于压缩多种3D表面表示，如符号距离函数（SDFs）、体素网格等，但在处理无结构数据如3D网格和点云方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，使隐式神经网络表示（INRs）能够压缩3D三角形网格。&lt;h4&gt;方法&lt;/h4&gt;该方法通过一个小型神经网络编码位移场，以细化要压缩的3D网格表面的粗略版本。&lt;h4&gt;主要发现&lt;/h4&gt;训练后的神经网络权重比位移场或原始表面占用更低的内存，且该方法能够保留复杂的几何纹理，在4x到380x的压缩比范围内表现出最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法为3D三角形网格的压缩提供了一种高效且有效的解决方案，扩展了隐式神经网络表示（INRs）的应用范围。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Implicit neural representations (INRs) have been successfully used tocompress a variety of 3D surface representations such as Signed DistanceFunctions (SDFs), voxel grids, and also other forms of structured data such asimages, videos, and audio. However, these methods have been limited in theirapplication to unstructured data such as 3D meshes and point clouds. This workpresents a simple yet effective method that extends the usage of INRs tocompress 3D triangle meshes. Our method encodes a displacement field thatrefines the coarse version of the 3D mesh surface to be compressed using asmall neural network. Once trained, the neural network weights occupy muchlower memory than the displacement field or the original surface. We show thatour method is capable of preserving intricate geometric textures anddemonstrates state-of-the-art performance for compression ratios ranging from4x to 380x.</description>
      <author>example@mail.com (Sai Karthikey Pentapati, Gregoire Phillips, Alan C. Bovik)</author>
      <guid isPermaLink="false">2504.01027v1</guid>
      <pubDate>Thu, 03 Apr 2025 14:30:40 +0800</pubDate>
    </item>
    <item>
      <title>Unbiasing through Textual Descriptions: Mitigating Representation Bias in Video Benchmarks</title>
      <link>http://arxiv.org/abs/2503.18637v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published at CVPR 2025, project webpage  https://utd-project.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新的“通过文本描述（UTD）”视频基准，该基准基于现有视频分类和检索数据集的无偏子集，以实现对视频理解能力更稳健的评估。&lt;h4&gt;背景&lt;/h4&gt;当前视频基准可能存在不同的表示偏差，例如物体偏差或单帧偏差，其中仅识别物体或仅使用单帧就足以进行正确预测。&lt;h4&gt;目的&lt;/h4&gt;解决当前视频基准可能存在的表示偏差问题，并通过无偏的子集进行视频理解的评估。&lt;h4&gt;方法&lt;/h4&gt;利用视觉语言模型（VLMs）和大型语言模型（LLMs）来分析和去除基准中的表示偏差。具体来说，生成视频的逐帧文本描述，过滤特定信息（例如仅对象）并利用这些描述来从三个维度考察表示偏差：1）概念偏差——确定特定概念（例如物体）是否足以进行预测；2）时间偏差——评估时间信息是否对预测有贡献；3）常识与数据集偏差——评估零样本推理或数据集相关性是否对预测有贡献。&lt;h4&gt;主要发现&lt;/h4&gt;对12个流行的视频分类和检索数据集进行了系统性分析，并为这些数据集创建了新的物体偏差测试分割。此外，在原始和去偏分割上对30个最先进的视频模型进行了基准测试，并分析了模型中的偏差。&lt;h4&gt;结论&lt;/h4&gt;为了促进更稳健的视频理解基准和模型的发展，发布了“UTD-descriptions”，包含每个数据集的丰富结构化描述的数据集，以及“UTD-splits”，包含物体偏差测试分割的数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a new "Unbiased through Textual Description (UTD)" video benchmarkbased on unbiased subsets of existing video classification and retrievaldatasets to enable a more robust assessment of video understandingcapabilities. Namely, we tackle the problem that current video benchmarks maysuffer from different representation biases, e.g., object bias or single-framebias, where mere recognition of objects or utilization of only a single frameis sufficient for correct prediction. We leverage VLMs and LLMs to analyze anddebias benchmarks from such representation biases. Specifically, we generateframe-wise textual descriptions of videos, filter them for specific information(e.g. only objects) and leverage them to examine representation biases acrossthree dimensions: 1) concept bias - determining if a specific concept (e.g.,objects) alone suffice for prediction; 2) temporal bias - assessing if temporalinformation contributes to prediction; and 3) common sense vs. dataset bias -evaluating whether zero-shot reasoning or dataset correlations contribute toprediction. We conduct a systematic analysis of 12 popular video classificationand retrieval datasets and create new object-debiased test splits for thesedatasets. Moreover, we benchmark 30 state-of-the-art video models on originaland debiased splits and analyze biases in the models. To facilitate the futuredevelopment of more robust video understanding benchmarks and models, werelease: "UTD-descriptions", a dataset with our rich structured descriptionsfor each dataset, and "UTD-splits", a dataset of object-debiased test splits.</description>
      <author>example@mail.com (Nina Shvetsova, Arsha Nagrani, Bernt Schiele, Hilde Kuehne, Christian Rupprecht)</author>
      <guid isPermaLink="false">2503.18637v1</guid>
      <pubDate>Wed, 02 Apr 2025 14:05:05 +0800</pubDate>
    </item>
  <item>
      <title>Evaluating machine learning models for predicting pesticides toxicity to honey bees</title>
      <link>http://arxiv.org/abs/2503.24305v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究小分子在生物医学、环境和农业化学领域的应用，并探讨了针对蜜蜂（Apis mellifera）的化学毒性数据集ApisTox的性能。&lt;h4&gt;背景&lt;/h4&gt;小分子在生物医学、环境和农业化学领域具有重要作用，但不同领域对物质的物理化学要求和成功标准不同。目前，生物医学领域有大量数据集和标准，而农业化学领域数据稀缺，特别是针对特定物种的毒性数据。&lt;h4&gt;目的&lt;/h4&gt;评估ApisTox数据集，并探讨其在农业化学领域的应用。&lt;h4&gt;方法&lt;/h4&gt;使用多种机器学习方法评估ApisTox，包括分子指纹、图核和图神经网络，以及预训练模型。同时，将ApisTox与MoleculeNet基准中的药物数据集进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;ApisTox代表了一个独特的化学空间，当前基于生物医学数据训练的最先进算法在非药物数据集上的性能下降，表明其泛化能力有限。&lt;h4&gt;结论&lt;/h4&gt;需要更多多样化的数据集和针对农业化学领域的特定模型开发。&lt;h4&gt;翻译&lt;/h4&gt;摘要：小分子在生物医学、环境和农业化学领域发挥着关键作用，每个领域都有其独特的物理化学要求和成功标准。尽管生物医学研究受益于大量数据集和既定的基准，但农业化学数据仍然稀缺，特别是在特定物种的毒性方面。本研究专注于ApisTox，这是迄今为止最全面的蜜蜂（Apis mellifera）实验验证化学毒性的数据集，蜜蜂是一种生态上至关重要的授粉者。我们使用一系列机器学习方法评估ApisTox，包括分子指纹、图核和图神经网络，以及预训练模型。与MoleculeNet基准中的药物数据集的比较分析表明，ApisTox代表了一个独特的化学空间。在非药物数据集（如ApisTox）上的性能下降表明，当前仅基于生物医学数据训练的最先进算法泛化能力有限。我们的研究强调了需要更多多样化的数据集和针对农业化学领域的针对性模型开发。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/j-adamczyk/apistox_bee_toxicity_ml_prediction&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Small molecules play a critical role in the biomedical, environmental, andagrochemical domains, each with distinct physicochemical requirements andsuccess criteria. Although biomedical research benefits from extensive datasetsand established benchmarks, agrochemical data remain scarce, particularly withrespect to species-specific toxicity. This work focuses on ApisTox, the mostcomprehensive dataset of experimentally validated chemical toxicity to thehoney bee (Apis mellifera), an ecologically vital pollinator. We evaluateApisTox using a diverse suite of machine learning approaches, includingmolecular fingerprints, graph kernels, and graph neural networks, as well aspretrained models. Comparative analysis with medicinal datasets from theMoleculeNet benchmark reveals that ApisTox represents a distinct chemicalspace. Performance degradation on non-medicinal datasets, such as ApisTox,demonstrates their limited generalizability of current state-of-the-artalgorithms trained solely on biomedical data. Our study highlights the need formore diverse datasets and for targeted model development geared toward theagrochemical domain.</description>
      <author>example@mail.com (Jakub Adamczyk, Jakub Poziemski, Pawel Siedlecki)</author>
      <guid isPermaLink="false">2503.24305v2</guid>
      <pubDate>Wed, 02 Apr 2025 14:05:05 +0800</pubDate>
    </item>
    <item>
      <title>Introducing the Short-Time Fourier Kolmogorov Arnold Network: A Dynamic Graph CNN Approach for Tree Species Classification in 3D Point Clouds</title>
      <link>http://arxiv.org/abs/2503.23647v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为STFT-KAN的新型Kolmogorov-Arnold网络，用于基于TLS和ALS数据进行树木种类分类，以促进生物多样性保护。&lt;h4&gt;背景&lt;/h4&gt;准确分类树木种类对于生物多样性保护至关重要，而现有的深度学习模型在3D点云分类领域表现出色，但通常复杂度高，难以开发高效、低计算架构。&lt;h4&gt;目的&lt;/h4&gt;开发一种轻量级的深度学习模型，用于高效、低计算地分类树木种类。&lt;h4&gt;方法&lt;/h4&gt;提出STFT-KAN，一种结合了短时傅里叶变换（STFT）的Kolmogorov-Arnold网络，并将其应用于轻量级DGCNN版本（liteDGCNN）中，用于TLS数据分类。此外，还评估了一种混合架构，结合了MLP在边缘卷积和STFT-KAN在其他层中的使用。&lt;h4&gt;主要发现&lt;/h4&gt;STFT-KAN在平衡模型复杂性和性能方面表现优异，参数数量减少，与基于MLP的模型相比，取得了有竞争力的结果。混合架构在参数数量减少50%和75%的同时，实现了与MLP模型相当的性能。与PointMLP lite等最先进的3D点云学习方法相比，STFT-KAN在参数数量减少了87%的情况下，仍能提供有竞争力的结果。&lt;h4&gt;结论&lt;/h4&gt;STFT-KAN是一种高效、低计算且性能优异的树木种类分类模型，为生物多样性保护提供了新的技术手段。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/said-ohamouddou/stft-kan-litedgcnn&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate classification of tree species based on Terrestrial Laser Scanning(TLS) and Airborne Laser Scanning (ALS) is essential for biodiversityconservation. While advanced deep learning models for 3D point cloudclassification have demonstrated strong performance in this domain, their highcomplexity often hinders the development of efficient, low-computationarchitectures. In this paper, we introduce STFT-KAN, a novel Kolmogorov-Arnoldnetwork that integrates the Short-Time Fourier Transform (STFT), which canreplace the standard linear layer with activation. We implemented STFT-KANwithin a lightweight version of DGCNN, called liteDGCNN, to classify treespecies using the TLS data. Our experiments show that STFT-KAN outperformsexisting KAN variants by effectively balancing model complexity and performancewith parameter count reduction, achieving competitive results compared toMLP-based models. Additionally, we evaluated a hybrid architecture thatcombines MLP in edge convolution with STFT-KAN in other layers, achievingcomparable performance to MLP models while reducing the parameter count by 50%and 75% compared to other KAN-based variants. Furthermore, we compared ourmodel to leading 3D point cloud learning approaches, demonstrating thatSTFT-KAN delivers competitive results compared to the state-of-the-art methodPointMLP lite with an 87% reduction in parameter count.</description>
      <author>example@mail.com (Said Ohamouddou, Mohamed Ohamouddou, Hanaa El Afia, Abdellatif El Afia, Rafik Lasri, Raddouane Chiheb)</author>
      <guid isPermaLink="false">2503.23647v2</guid>
      <pubDate>Wed, 02 Apr 2025 14:05:05 +0800</pubDate>
    </item>
    <item>
      <title>Nonhuman Primate Brain Tissue Segmentation Using a Transfer Learning Approach</title>
      <link>http://arxiv.org/abs/2503.22829v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于STU-Net和迁移学习的新方法，用于非人类灵长类动物（NHPs）的脑组织分割，以解决NHP脑MRI数据集标注稀缺、脑体积小、成像数据分辨率有限以及人脑与NHP脑解剖差异等问题。&lt;h4&gt;背景&lt;/h4&gt;非人类灵长类动物在理解人类大脑功能和神经疾病方面扮演着重要角色。准确分割NHP脑组织对于理解神经疾病至关重要，但由于上述原因，这一过程具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，利用从人类脑MRI数据迁移的知识，提高NHP脑MRI分割的准确性，特别是在训练数据有限的情况下。&lt;h4&gt;方法&lt;/h4&gt;采用STU-Net网络和迁移学习技术，有效界定复杂组织边界并捕捉NHP脑特有的精细解剖细节。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在分割小脑皮质结构（如豆状核和丘脑）方面表现出色，这些结构在有限的空间分辨率和组织对比度下难以分辨。该方法在分割小脑皮质结构时取得了DSC超过0.88、IoU超过0.8和HD95小于7的成果。&lt;h4&gt;结论&lt;/h4&gt;本研究介绍了一种稳健的多类脑组织分割方法，有望加速进化神经科学研究和与人类健康相关的神经疾病临床前研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于与人类的近亲进化关系，非人类灵长类动物（NHPs）是人类大脑功能和神经疾病研究的关键模型。准确分割NHP脑组织对于理解神经疾病至关重要，但由于标注的NHP脑MRI数据集稀缺、NHP脑体积小、现有成像数据分辨率有限以及人脑与NHP脑的解剖差异，这一过程具有挑战性。为了解决这些挑战，我们提出了一种基于STU-Net的迁移学习方法，以利用从人类脑MRI数据迁移的知识来提高NHP脑MRI分割的准确性，特别是在训练数据有限的情况下。STU-Net和迁移学习的结合有效地界定了复杂组织边界并捕捉了NHP脑特有的精细解剖细节。值得注意的是，我们的方法在分割小脑皮质结构（如豆状核和丘脑）方面表现出色，这些结构在有限的空间分辨率和组织对比度下难以分辨，并实现了DSC超过0.88、IoU超过0.8和HD95小于7的成果。本研究介绍了一种稳健的多类脑组织分割方法，有望加速进化神经科学研究和与人类健康相关的神经疾病临床前研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Non-human primates (NHPs) serve as critical models for understanding humanbrain function and neurological disorders due to their close evolutionaryrelationship with humans. Accurate brain tissue segmentation in NHPs iscritical for understanding neurological disorders, but challenging due to thescarcity of annotated NHP brain MRI datasets, the small size of the NHP brain,the limited resolution of available imaging data and the anatomical differencesbetween human and NHP brains. To address these challenges, we propose a novelapproach utilizing STU-Net with transfer learning to leverage knowledgetransferred from human brain MRI data to enhance segmentation accuracy in theNHP brain MRI, particularly when training data is limited. The combination ofSTU-Net and transfer learning effectively delineates complex tissue boundariesand captures fine anatomical details specific to NHP brains. Notably, ourmethod demonstrated improvement in segmenting small subcortical structures suchas putamen and thalamus that are challenging to resolve with limited spatialresolution and tissue contrast, and achieved DSC of over 0.88, IoU over 0.8 andHD95 under 7. This study introduces a robust method for multi-class braintissue segmentation in NHPs, potentially accelerating research in evolutionaryneuroscience and preclinical studies of neurological disorders relevant tohuman health.</description>
      <author>example@mail.com (Zhen Lin, Hongyu Yuan, Richard Barcus, Qing Lyu, Sucheta Chakravarty, Megan E. Lipford, Carol A. Shively, Suzanne Craft, Mohammad Kawas, Jeongchul Kim, Christopher T. Whitlow)</author>
      <guid isPermaLink="false">2503.22829v2</guid>
      <pubDate>Wed, 02 Apr 2025 14:05:05 +0800</pubDate>
    </item>
    <item>
      <title>A point cloud reconstruction method based on uncertainty feature enhancement for aerodynamic shape optimization</title>
      <link>http://arxiv.org/abs/2503.23082v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The data has some error which can lead to wrong understanding&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了形状表示的精度和设计空间的维度对气动优化成本和结果的影响，提出了一种新的点云自动编码器架构AE-BUFE，通过分析表面网格点之间的变形关系的不确定性来获得3D飞机的高效和精确的泛化表示。&lt;h4&gt;背景&lt;/h4&gt;形状表示的精度和设计空间的维度对气动优化的成本和结果有显著影响。&lt;h4&gt;目的&lt;/h4&gt;提高优化过程的成本效益，通过紧凑地表示设计空间，同时保持几何精度。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的点云自动编码器架构AE-BUFE，包括基于不确定指数的特征增强模块和点云自动编码器模块，通过学习点云的几何表示的形状特征来建立低维潜在空间。&lt;h4&gt;主要发现&lt;/h4&gt;新架构显著提高了低维潜在空间的提取效果，并与现有的点云自动编码器架构和POD线性降维方法进行了比较。&lt;h4&gt;结论&lt;/h4&gt;该方法在跨音速和超声速条件下提高了气动性能，同时确保了起飞和着陆性能，验证了该方法的效率和应用工程实用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：形状表示的精度和设计空间的维度显著影响了气动优化的成本和结果。通过保持几何精度同时减少维度，可以更紧凑地表示设计空间，从而提高优化过程的成本效益。本研究提出了一种新的点云自动编码器架构，称为AE-BUFE，旨在通过分析表面网格点之间变形关系的不确定性，实现对3D飞机的效率和精确的泛化表示。该深度学习架构包括两个组件：基于不确定指数的特征增强模块和点云自动编码器模块。它通过学习点云几何表示的形状特征来建立低维潜在空间。为了评估和评估该方法的有效性，在复杂形状变形的条件下，与现有的点云自动编码器架构和适当的正交分解（POD）线性降维方法进行了比较。结果表明，新架构显著提高了低维潜在空间的提取效果。然后，基于AE-BUFE参数化方法开发了SBO优化框架，并针对考虑体积和力矩约束的宽速域车辆完成了多目标气动优化设计。在确保起飞和着陆性能的同时，在跨音速和超声速条件下提高了气动性能，验证了该方法的效率和工程实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The precision of shape representation and the dimensionality of the designspace significantly influence the cost and outcomes of aerodynamicoptimization. The design space can be represented more compactly by maintaininggeometric precision while reducing dimensions, hence enhancing thecost-effectiveness of the optimization process. This research presents a newpoint cloud autoencoder architecture, called AE-BUFE, designed to attainefficient and precise generalized representations of 3D aircraft throughuncertainty analysis of the deformation relationships among surface gridpoints. The deep learning architecture consists of two components: theuncertainty index-based feature enhancement module and the point cloudautoencoder module. It learns the shape features of the point cloud geometricrepresentation to establish a low-dimensional latent space. To assess andevaluate the efficiency of the method, a comparison was conducted with theprevailing point cloud autoencoder architecture and the proper orthogonaldecomposition (POD) linear dimensionality reduction method under conditions ofcomplex shape deformation. The results showed that the new architecturesignificantly improved the extraction effect of the low-dimensional latentspace. Then, we developed the SBO optimization framework based on the AE-BUFEparameterization method and completed a multi-objective aerodynamicoptimization design for a wide-speed-range vehicle considering volume andmoment constraints. While ensuring the take-off and landing performance, theaerodynamic performance is improved at transonic and hypersonic conditions,which verifies the efficiency and engineering practicability of this method.</description>
      <author>example@mail.com (Junlin Li, Yang Zhang, Bo Pang, Junqiang Bai, Jiakuan Xu)</author>
      <guid isPermaLink="false">2503.23082v2</guid>
      <pubDate>Wed, 02 Apr 2025 14:05:05 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Clustering Algorithms on Poisson and Cox Point Processes</title>
      <link>http://arxiv.org/abs/2503.18555v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  37 pages, 17 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了三种新的分层聚类模型，包括Clustroid分层最近邻（CHN^2）、单链接分层最近邻（SHN^2）和Hausdorff（完全链接）分层最近邻（H^2N^2），这些模型适用于具有可数无限个点的数据集。&lt;h4&gt;背景&lt;/h4&gt;聚类是无监督学习中广泛使用的技术，用于根据数据集中元素之间的相似性识别数据集中的组。&lt;h4&gt;目的&lt;/h4&gt;提出的新模型旨在对具有可数无限个点的数据集进行更有效的聚类。&lt;h4&gt;方法&lt;/h4&gt;这些算法通过多个层次的聚类，通过连接最近邻点或簇来构建簇，但它们使用的距离度量不同（分别为clustroid、单链接和Hausdorff）。每个方法首先应用于欧几里得空间上的齐次泊松点过程，并定义了系统发育森林。&lt;h4&gt;主要发现&lt;/h4&gt;对于CHN^2算法，确定了簇的几乎确定有限性和每个算法层次的平均簇大小的界限。典型的簇的平均大小被证明是无限的。此外，当层次数趋于无穷大时，所有三个算法的极限结构被检查，并推导出了极限连通部分的性质，例如一端性。对于SHN^2在泊松点过程的具体情况，极限图被证明是最小生成树子图。CHN^2算法还扩展到泊松设置之外的某些平稳Cox点过程，在这些情况下也显示出类似的有限簇性质。还表明，可以通过这种聚类算法有效地检测到Cox触发的聚集。&lt;h4&gt;结论&lt;/h4&gt;提出的新分层聚类模型在处理具有可数无限个点的数据集时显示出有效性和新的聚类性质。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Clustering is a widely used technique in unsupervised learning to identifygroups within a dataset based on the similarities between its elements. Thispaper introduces three new hierarchical clustering models, ClustroidHierarchical Nearest Neighbor ($\mathrm{CHN}^2$), Single Linkage HierarchicalNearest Neighbor ($\mathrm{SHN}^2$), and Hausdorff (Complete Linkage)Hierarchical Nearest Neighbor ($\mathrm{H}^2\mathrm{N}^2$), all designed fordatasets with a countably infinite number of points. These algorithms proceedthrough multiple levels of clustering and construct clusters by connectingnearest-neighbor points or clusters, but differ in the distance metrics theyemploy (clustroid, single linkage, or Hausdorff, respectively). Each method isfirst applied to the homogeneous Poisson point process on the Euclidean space,where it defines a phylogenetic forest, which is a factor of the point processand therefore unimodular. The results established for the $\mathrm{CHN}^2$algorithm include the almost-sure finiteness of the clusters and bounds on themean cluster size at each level of the algorithm. The mean size of the typicalcluster is shown to be infinite. Moreover, the limiting structure of all threealgorithms is examined as the number of levels tends to infinity, andproperties such as the one-endedness of the limiting connected components arederived. In the specific case of $\mathrm{SHN}^2$ on the Poisson point process,the limiting graph is shown to be a subgraph of the Minimal Spanning Forest.The $\mathrm{CHN}^2$ algorithm is also extended beyond the Poisson setting, tocertain stationary Cox point processes. Similar finite-cluster properties areshown to hold in these cases. It is also shown that efficient detection ofCox-triggered aggregation can be achieved through this clustering algorithm.</description>
      <author>example@mail.com (Sayeh Khaniha, François Baccelli)</author>
      <guid isPermaLink="false">2503.18555v2</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
  <item>
      <title>Easi3R: Estimating Disentangled Motion from DUSt3R Without Training</title>
      <link>http://arxiv.org/abs/2503.24391v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Page: https://easi3r.github.io/ Code:  https://github.com/Inception3D/Easi3R&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Easi3R，一种简单高效的4D重建无监督训练方法，该方法在真实世界动态视频上表现优于现有基于大规模动态数据集训练的方法。&lt;h4&gt;背景&lt;/h4&gt;DUSt3R在静态场景的密集点云和相机参数估计方面取得了进展，但4D数据集的规模和多样性有限，限制了4D模型的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出Easi3R，一种无需训练即可进行4D重建的方法，以克服4D数据集的局限性。&lt;h4&gt;方法&lt;/h4&gt;Easi3R在推理过程中应用注意力自适应，利用DUSt3R的注意力层来编码相机和物体运动信息，并通过细致地分离这些注意力图来实现动态区域分割、相机姿态估计和4D密集点云图重建。&lt;h4&gt;主要发现&lt;/h4&gt;Easi3R在真实世界动态视频上的实验表明，该方法在轻量级的注意力自适应方面显著优于基于大规模动态数据集训练或微调的现有方法。&lt;h4&gt;结论&lt;/h4&gt;Easi3R是一种简单有效的4D重建方法，无需预训练或网络微调，能够有效地利用已有知识进行4D重建。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in DUSt3R have enabled robust estimation of dense pointclouds and camera parameters of static scenes, leveraging Transformer networkarchitectures and direct supervision on large-scale 3D datasets. In contrast, the limited scale and diversity of available 4D datasets present a major bottleneck for training a highly generalizable 4D model. This constraint has driven conventional 4D methods to fine-tune 3D models on scalable dynamic videodata with additional geometric priors such as optical flow and depths. In this work, we take an opposite path and introduce Easi3R, a simple yet efficient training-free method for 4D reconstruction. Our approach applies attention adaptation during inference, eliminating the need for from-scratch pre-training or network fine-tuning. We find that the attention layers in DUSt3R inherently encode rich information about camera and object motion. By carefully disentangling these attention maps, we achieve accurate dynamic region segmentation, camera pose estimation, and 4D dense point map reconstruction. Extensive experiments on real-world dynamic videos demonstrate that our lightweight attention adaptation significantly outperforms previous state-of-the-art methods that are trained or finetuned on extensive dynamic datasets. Our code is publicly available for research purpose at https://easi3r.github.io/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/inception3d/easi3r&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in DUSt3R have enabled robust estimation of dense pointclouds and camera parameters of static scenes, leveraging Transformer networkarchitectures and direct supervision on large-scale 3D datasets. In contrast,the limited scale and diversity of available 4D datasets present a majorbottleneck for training a highly generalizable 4D model. This constraint hasdriven conventional 4D methods to fine-tune 3D models on scalable dynamic videodata with additional geometric priors such as optical flow and depths. In thiswork, we take an opposite path and introduce Easi3R, a simple yet efficienttraining-free method for 4D reconstruction. Our approach applies attentionadaptation during inference, eliminating the need for from-scratch pre-trainingor network fine-tuning. We find that the attention layers in DUSt3R inherentlyencode rich information about camera and object motion. By carefullydisentangling these attention maps, we achieve accurate dynamic regionsegmentation, camera pose estimation, and 4D dense point map reconstruction.Extensive experiments on real-world dynamic videos demonstrate that ourlightweight attention adaptation significantly outperforms previousstate-of-the-art methods that are trained or finetuned on extensive dynamicdatasets. Our code is publicly available for research purpose athttps://easi3r.github.io/</description>
      <author>example@mail.com (Xingyu Chen, Yue Chen, Yuliang Xiu, Andreas Geiger, Anpei Chen)</author>
      <guid isPermaLink="false">2503.24391v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Spatiotemporal Learning of Brain Dynamics from fMRI Using Frequency-Specific Multi-Band Attention for Cognitive and Psychiatric Applications</title>
      <link>http://arxiv.org/abs/2503.23394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Multi-Band Brain Net (MBBN)的基于Transformer的框架，用于模拟fMRI数据中的特定频率的时空脑动力学，通过整合无标度网络原理和频率解析的多波段自注意力机制，揭示了在精神疾病（如ADHD、ASD、抑郁症）中的连接中断。&lt;h4&gt;背景&lt;/h4&gt;理解大脑复杂非线性动力学如何产生适应性认知和行为是神经科学的一个主要挑战。这些动力学表现出无标度和多分形特性，影响着神经网络的重配置。&lt;h4&gt;目的&lt;/h4&gt;提出MBBN框架的目的是为了更好地捕捉大脑的非线性动力学，并提高对精神疾病中神经网络连接中断的理解。&lt;h4&gt;方法&lt;/h4&gt;MBBN框架通过结合无标度网络原理和频率解析的多波段自注意力机制，从fMRI数据中建模特定频率的时空脑动力学。&lt;h4&gt;主要发现&lt;/h4&gt;MBBN在三个大规模神经影像队列（UK Biobank、ABCD、ABIDE）上进行了训练，总共有45,951个个体。它揭示了以前无法检测到的频率依赖性网络相互作用，并揭示了精神疾病中的连接中断。&lt;h4&gt;结论&lt;/h4&gt;MBBN在预测准确性方面达到了30.59%的显著提升，证明了基于频率的时空建模在捕捉潜在神经计算方面的优势。MBBN的可解释性揭示了神经发育障碍的新频率特异性生物标志物，为大脑功能分层组织提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：理解大脑的复杂非线性动力学如何产生适应性认知和行为是神经科学的一个核心挑战。这些动力学表现出无标度和多分形特性，影响着神经网络的重配置。然而，传统的神经影像模型受到线性和平稳假设的限制，限制了它们捕捉这些过程的能力。以捕获长程依赖性而闻名的Transformer架构与大脑的层次和时间组织相吻合。我们引入了多波段脑网络（MBBN），这是一个基于Transformer的框架，通过整合无标度网络原理与频率解析的多波段自注意力，从fMRI中模拟特定频率的时空脑动力学。在三个大规模神经影像队列（UK Biobank、ABCD、ABIDE）上训练，总人数为45,951人，MBBN揭示了以前无法检测到的频率依赖性网络相互作用，揭示了精神疾病（ADHD、ASD、抑郁症）中的连接中断。这种验证显示了强大的泛化能力，并突出了在人群之间保守的核心神经原理。MBBN在预测准确性方面比最先进的方法高出30.59%，证明了基于频率的时空建模在捕捉潜在神经计算方面的优势。MBBN的可解释性揭示了神经发育障碍的新频率特异性生物标志物，为大脑功能分层组织提供了见解。通过提供一个可解释的时空学习框架，MBBN提供了关于神经计算如何支撑认知功能和精神疾病易感性的见解，对大脑解码、认知神经科学和精准精神病学具有影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding how the brain's complex nonlinear dynamics give rise toadaptive cognition and behavior is a central challenge in neuroscience. Thesedynamics exhibit scale-free and multifractal properties, influencing thereconfiguration of neural networks. However, conventional neuroimaging modelsare constrained by linear and stationary assumptions, limiting their ability tocapture these processes. Transformer-based architectures, known for capturinglong-range dependencies, align well with the brain's hierarchical and temporalorganization. We introduce Multi-Band Brain Net (MBBN), a transformer-basedframework that models frequency-specific spatiotemporal brain dynamics fromfMRI by integrating scale-free network principles with frequency-resolvedmulti-band self-attention. Trained on three large-scale neuroimaging cohorts(UK Biobank, ABCD, ABIDE) totaling 45,951 individuals, MBBN reveals previouslyundetectable frequency-dependent network interactions, shedding light onconnectivity disruptions in psychiatric conditions (ADHD, ASD, depression).This validation shows robust generalizability and highlights core neuralprinciples conserved across populations. MBBN achieves up to 30.59% higherpredictive accuracy than state-of-the-art methods, demonstrating the advantageof frequency-informed spatiotemporal modeling in capturing latent neuralcomputations. MBBN's interpretability uncovers novel frequency-specificbiomarkers for neurodevelopmental disorders, providing insights into thehierarchical organization of brain function. By offering an interpretableframework for spatiotemporal learning, MBBN provides insights into how neuralcomputations underpin cognitive function and psychiatric vulnerability, withimplications for brain decoding, cognitive neuroscience, and precisionpsychiatry.</description>
      <author>example@mail.com (Sangyoon Bae, Junbeom Kwon, Shinjae Yoo, Jiook Cha)</author>
      <guid isPermaLink="false">2503.23394v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Human Motion Prediction via Multi-range Decoupling Decoding with Gating-adjusting Aggregation</title>
      <link>http://arxiv.org/abs/2503.23381v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为多范围解耦解码与门控调整聚合（MD2GA）的新方法，用于改进人体运动预测（HMP）中的运动表示学习，并通过实验证明该方法能够提升预测性能。&lt;h4&gt;背景&lt;/h4&gt;尽管基于深度学习的运动表示学习方法在运动表示学习方面显示出潜力，但它们往往忽略了历史信息与未来时刻之间变化的关联性和依赖性，这限制了运动表示的学习并阻碍了预测性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来改进人体运动预测中的运动表示学习，以提升预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法采用两阶段策略：第一阶段，通过多范围解耦解码调整特征学习，将共享特征解码为不同的未来长度，不同的解码器提供对运动模式的不同见解；第二阶段，通过门控调整聚合动态地结合由输入运动数据引导的不同见解。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的方法可以轻松集成到其他运动预测方法中，并增强其预测性能。&lt;h4&gt;结论&lt;/h4&gt;MD2GA方法能够有效地利用时间相关性来改进运动表示学习，从而提升人体运动预测的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Expressive representation of pose sequences is crucial for accurate motion modeling in human motion prediction (HMP). While recent deep learning-based methods have shown promise in learning motion representations, these methods tend to overlook the varying relevance and dependencies between historical information and future moments, with a stronger correlation for short-term predictions and weaker for distant future predictions. This limits the learning of motion representation and then hampers prediction performance. In this paper, we propose a novel approach called multi-range decoupling decoding with gating-adjusting aggregation ($MD2GA$), which leverages the temporal correlations to refine motion representation learning. This approach employs a two-stage strategy for HMP. In the first stage, a multi-range decoupling decoding adeptly adjusts feature learning by decoding the shared features into distinct future lengths, where different decoders offer diverse insights into motion patterns. In the second stage, a gating-adjusting aggregation dynamically combines the diverse insights guided by input motion data. Extensive experiments demonstrate that the proposed method can be easily integrated into other motion prediction methods and enhance their prediction performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Expressive representation of pose sequences is crucial for accurate motionmodeling in human motion prediction (HMP). While recent deep learning-basedmethods have shown promise in learning motion representations, these methodstend to overlook the varying relevance and dependencies between historicalinformation and future moments, with a stronger correlation for short-termpredictions and weaker for distant future predictions. This limits the learningof motion representation and then hampers prediction performance. In thispaper, we propose a novel approach called multi-range decoupling decoding withgating-adjusting aggregation ($MD2GA$), which leverages the temporalcorrelations to refine motion representation learning. This approach employs atwo-stage strategy for HMP. In the first stage, a multi-range decouplingdecoding adeptly adjusts feature learning by decoding the shared features intodistinct future lengths, where different decoders offer diverse insights intomotion patterns. In the second stage, a gating-adjusting aggregationdynamically combines the diverse insights guided by input motion data.Extensive experiments demonstrate that the proposed method can be easilyintegrated into other motion prediction methods and enhance their predictionperformance.</description>
      <author>example@mail.com (Jiexin Wang, Wenwen Qiang, Zhao Yang, Bing Su)</author>
      <guid isPermaLink="false">2503.23381v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating machine learning models for predicting pesticides toxicity to honey bees</title>
      <link>http://arxiv.org/abs/2503.24305v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究小分子在生物医学、环境和农业化学领域的应用，通过机器学习方法评估了针对蜜蜂（Apis mellifera）的化学毒性数据库ApisTox，并探讨了数据集多样性和模型针对性的重要性。&lt;h4&gt;背景&lt;/h4&gt;小分子在多个领域扮演重要角色，但不同领域的物理化学要求和成功标准不同。生物医学领域数据丰富，而农业化学领域数据稀缺，尤其是针对特定物种的毒性数据。&lt;h4&gt;目的&lt;/h4&gt;评估ApisTox数据库，并比较其在不同数据集上的表现，特别是与生物医学数据集的对比。&lt;h4&gt;方法&lt;/h4&gt;使用分子指纹、图核、图神经网络和预训练模型等多种机器学习方法对ApisTox进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;ApisTox展示了独特的化学空间，且在非生物医学数据集上的表现不佳，表明当前最先进的算法在仅基于生物医学数据训练的情况下泛化能力有限。&lt;h4&gt;结论&lt;/h4&gt;研究强调了需要更多样化的数据集和针对农业化学领域的模型开发。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/j-adamczyk/apistox_bee_toxicity_ml_prediction&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Small molecules play a critical role in the biomedical, environmental, andagrochemical domains, each with distinct physicochemical requirements andsuccess criteria. Although biomedical research benefits from extensive datasetsand established benchmarks, agrochemical data remain scarce, particularly withrespect to species-specific toxicity. This work focuses on ApisTox, the mostcomprehensive dataset of experimentally validated chemical toxicity to thehoney bee (\textit{Apis mellifera}), an ecologically vital pollinator. Weevaluate ApisTox using a diverse suite of machine learning approaches,including molecular fingerprints, graph kernels, and graph neural networks, aswell as pretrained models. Comparative analysis with medicinal datasets fromthe MoleculeNet benchmark reveals that ApisTox represents a distinct chemicalspace. Performance degradation on non-medicinal datasets, such as ApisTox,demonstrates their limited generalizability of current state-of-the-artalgorithms trained solely on biomedical data. Our study highlights the need formore diverse datasets and for targeted model development geared toward theagrochemical domain.</description>
      <author>example@mail.com (Jakub Adamczyk, Jakub Poziemski, Pawel Siedlecki)</author>
      <guid isPermaLink="false">2503.24305v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Advances in Continual Graph Learning for Anti-Money Laundering Systems: A Comprehensive Review</title>
      <link>http://arxiv.org/abs/2503.24259v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对用于反洗钱（AML）的持续图学习技术进行了批判性评估。&lt;h4&gt;背景&lt;/h4&gt;金融机构需要根据规定报告可疑的洗钱交易，因此需要不断监控大量交易。洗钱者不断调整策略以逃避检测，使得检测方法需要不断调整。&lt;h4&gt;目的&lt;/h4&gt;通过允许模型在保留先前知识的同时吸收新信息，持续学习方法可能解决传统机器学习模型在动态环境中因新数据调整而导致的灾难性遗忘问题，从而增强AML实践。&lt;h4&gt;方法&lt;/h4&gt;本文将现有持续图学习方法分为基于重放、基于正则化和基于架构的策略，并在合成和真实世界AML数据集上进行了深入实验评估。&lt;h4&gt;主要发现&lt;/h4&gt;分析表明，持续学习可以改善模型在面对极端类别不平衡和演变的欺诈模式时的适应性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文概述了关键挑战，并提出了未来研究的方向。&lt;h4&gt;翻译&lt;/h4&gt;本文对用于反洗钱（AML）的持续图学习技术进行了批判性评估。金融机构需要根据规定报告可疑的洗钱交易，因此需要不断监控大量交易。洗钱者不断调整策略以逃避检测，使得检测方法需要不断调整。通过允许模型在保留先前知识的同时吸收新信息，持续学习方法可能解决传统机器学习模型在动态环境中因新数据调整而导致的灾难性遗忘问题，从而增强AML实践。本文将现有持续图学习方法分为基于重放、基于正则化和基于架构的策略，并在合成和真实世界AML数据集上进行了深入实验评估。分析表明，持续学习可以改善模型在面对极端类别不平衡和演变的欺诈模式时的适应性和鲁棒性。本文概述了关键挑战，并提出了未来研究的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Financial institutions are required by regulation to report suspiciousfinancial transactions related to money laundering. Therefore, they need toconstantly monitor vast amounts of incoming and outgoing transactions. Aparticular challenge in detecting money laundering is that money laundererscontinuously adapt their tactics to evade detection. Hence, detection methodsneed constant fine-tuning. Traditional machine learning models suffer fromcatastrophic forgetting when fine-tuning the model on new data, therebylimiting their effectiveness in dynamic environments. Continual learningmethods may address this issue and enhance current anti-money laundering (AML)practices, by allowing models to incorporate new information while retainingprior knowledge. Research on continual graph learning for AML, however, isstill scarce. In this review, we critically evaluate state-of-the-art continualgraph learning approaches for AML applications. We categorise methods intoreplay-based, regularization-based, and architecture-based strategies withinthe graph neural network (GNN) framework, and we provide in-depth experimentalevaluations on both synthetic and real-world AML data sets that showcase theeffect of the different hyperparameters. Our analysis demonstrates thatcontinual learning improves model adaptability and robustness in the face ofextreme class imbalances and evolving fraud patterns. Finally, we outline keychallenges and propose directions for future research.</description>
      <author>example@mail.com (Bruno Deprez, Wei Wei, Wouter Verbeke, Bart Baesens, Kevin Mets, Tim Verdonck)</author>
      <guid isPermaLink="false">2503.24259v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Adapting Vision Foundation Models for Real-time Ultrasound Image Segmentation</title>
      <link>http://arxiv.org/abs/2503.24368v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的实时超声图像分割方法，该方法利用层次视觉基础模型Hiera提取多尺度特征，并通过DINOv2表示增强视觉表达，实现了精确和鲁棒的分割。&lt;h4&gt;背景&lt;/h4&gt;现有的超声分割方法在适应新任务时存在困难，依赖昂贵的手动标注，而实时方法通常无法达到最先进的性能。&lt;h4&gt;目的&lt;/h4&gt;克服上述局限性，提出一个自适应框架，利用视觉基础模型提取多尺度特征，并提高分割的精确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;使用Hiera模型提取多尺度特征，结合DINOv2表示增强视觉表达，然后将这些增强特征解码以产生精确和鲁棒的分割。&lt;h4&gt;主要发现&lt;/h4&gt;在六个公开数据集和一个内部数据集上进行了广泛的评估，涵盖了心脏和甲状腺超声分割。实验表明，该方法在多个数据集上优于最先进的方法，在1%和10%数据设置中，平均超越nnUNet超过20%。&lt;h4&gt;结论&lt;/h4&gt;该方法在单个GPU上使用TensorRT实现了约77 FPS的推理速度，使得实时临床应用成为可能。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新的实时超声图像分割方法，该方法利用层次视觉基础模型Hiera提取多尺度特征，并通过DINOv2表示增强视觉表达。这些增强特征随后被解码以产生精确和鲁棒的分割。我们在六个公开数据集和一个内部数据集上进行了广泛的评估，涵盖了心脏和甲状腺超声分割。实验表明，我们的方法在多个数据集上优于最先进的方法，在1%和10%数据设置中，平均超越nnUNet超过20%。我们的方法在单个GPU上使用TensorRT实现了约77 FPS的推理速度，使得实时临床应用成为可能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel approach that adapts hierarchical vision foundation modelsfor real-time ultrasound image segmentation. Existing ultrasound segmentationmethods often struggle with adaptability to new tasks, relying on costly manualannotations, while real-time approaches generally fail to matchstate-of-the-art performance. To overcome these limitations, we introduce anadaptive framework that leverages the vision foundation model Hiera to extractmulti-scale features, interleaved with DINOv2 representations to enhance visualexpressiveness. These enriched features are then decoded to produce precise androbust segmentation. We conduct extensive evaluations on six public datasetsand one in-house dataset, covering both cardiac and thyroid ultrasoundsegmentation. Experiments show that our approach outperforms state-of-the-artmethods across multiple datasets and excels with limited supervision,surpassing nnUNet by over 20\% on average in the 1\% and 10\% data settings.Our method achieves $\sim$77 FPS inference speed with TensorRT on a single GPU,enabling real-time clinical applications.</description>
      <author>example@mail.com (Xiaoran Zhang, Eric Z. Chen, Lin Zhao, Xiao Chen, Yikang Liu, Boris Maihe, James S. Duncan, Terrence Chen, Shanhui Sun)</author>
      <guid isPermaLink="false">2503.24368v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Traffic Engineering in Large-scale Networks with Generalizable Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2503.24203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TELGEN的新型交通工程（TE）算法，用于在大规模网络中高效解决TE问题，同时提高了算法在不同网络条件下的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;随着全球规模云广域网络或骨干低地球轨道卫星星座的快速增长，大规模计算机网络中的交通工程（TE）问题变得至关重要且具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决传统TE算法的可扩展性问题，本文旨在提出一种新的TE算法，以提高效率并增强其在不同网络条件下的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;TELGEN通过将“预测最优TE解决方案”的问题转化为“预测最优TE算法”的问题，从而学习并高效地近似经典最优TE算法的端到端求解过程。&lt;h4&gt;主要发现&lt;/h4&gt;TELGEN在随机和真实世界网络上进行了训练和评估，节点数可达5000，链路数可达10^6。TELGEN在所有情况下都保证了可行性，并实现了小于3%的优化差距。与经典最优求解器相比，TELGEN节省了高达84%的求解时间，并且在大型网络上的训练时间和求解时间比最新的学习算法减少了2-4个数量级。&lt;h4&gt;结论&lt;/h4&gt;TELGEN算法在解决大规模网络中的TE问题方面表现出色，同时提高了算法的泛化能力和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic engineering (TE) in large-scale computer networks has become afundamental yet challenging problem, owing to the swift growth of global-scalecloud wide-area networks or backbone low-Earth-orbit satellite constellations.To address the scalability issue of traditional TE algorithms, learning-basedapproaches have been proposed, showing potential of significant efficiencyimprovement over state-of-the-art methods. Nevertheless, the intrinsiclimitations of existing learning-based methods hinder their practicalapplication: they are not generalizable across diverse topologies and networkconditions, incur excessive training overhead, and do not respect linkcapacities by default.  This paper proposes TELGEN, a novel TE algorithm that learns to solve TEproblems efficiently in large-scale networks, while achieving superiorgeneralizability across diverse network conditions. TELGEN is based on thenovel idea of transforming the problem of "predicting the optimal TE solution"into "predicting the optimal TE algorithm", which enables TELGEN to learn andefficiently approximate the end-to-end solving process of classical optimal TEalgorithms. The learned algorithm is agnostic to the exact network topology ortraffic patterns, and can efficiently solve TE problems given arbitrary inputsand generalize well to unseen topologies and demands.  We trained and evaluated TELGEN on random and real-world networks with up to5000 nodes and 106 links. TELGEN achieved less than 3% optimality gap whileensuring feasibility in all cases, even when the test network had up to 20xmore nodes than the largest in training. It also saved up to 84% solving timethan classical optimal solver, and could reduce training time per epoch andsolving time by 2-4 orders of magnitude than latest learning algorithms on thelargest networks.</description>
      <author>example@mail.com (Fangtong Zhou, Xiaorui Liu, Ruozhou Yu, Guoliang Xue)</author>
      <guid isPermaLink="false">2503.24203v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network-Based Predictive Modeling for Robotic Plaster Printing</title>
      <link>http://arxiv.org/abs/2503.24130v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的建模方法来预测基于颗粒的制造工艺产生的表面。&lt;h4&gt;背景&lt;/h4&gt;该制造工艺包括在墙壁上喷涂水泥砂浆，并使用机械臂辅助进行。&lt;h4&gt;目的&lt;/h4&gt;模型旨在模拟打印过程，并最终用于生成机械臂轨迹和优化打印参数，以实现自主抹灰工艺。&lt;h4&gt;方法&lt;/h4&gt;使用机械臂轨迹特征（如位置、速度和方向）以及打印过程参数来计算预测。GNN模型由编码器-处理器-解码器架构组成，并使用实验室测试数据训练。超参数通过贝叶斯方案优化。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在预测未见过的真实数据方面表现出良好的泛化能力，并在性能和预测步骤中的误差缩放方面优于现有基准模型。&lt;h4&gt;结论&lt;/h4&gt;该模型在预测误差方面有显著改进，显示出其在不同场景中的通用性和与现有基准模型的优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work proposes a Graph Neural Network (GNN) modeling approach to predictthe resulting surface from a particle based fabrication process. The latterconsists of spray-based printing of cementitious plaster on a wall and isfacilitated with the use of a robotic arm. The predictions are computed usingthe robotic arm trajectory features, such as position, velocity and direction,as well as the printing process parameters. The proposed approach, based on aparticle representation of the wall domain and the end effector, allows for theadoption of a graph-based solution. The GNN model consists of anencoder-processor-decoder architecture and is trained using data fromlaboratory tests, while the hyperparameters are optimized by means of aBayesian scheme. The aim of this model is to act as a simulator of the printingprocess, and ultimately used for the generation of the robotic arm trajectoryand the optimization of the printing parameters, towards the materialization ofan autonomous plastering process. The performance of the proposed model isassessed in terms of the prediction error against unseen ground truth data,which shows its generality in varied scenarios, as well as in comparison withthe performance of an existing benchmark model. The results demonstrate asignificant improvement over the benchmark model, with notably betterperformance and enhanced error scaling across prediction steps.</description>
      <author>example@mail.com (Diego Machain Rivera, Selen Ercan Jenny, Ping Hsun Tsai, Ena Lloret-Fritschi, Luis Salamanca, Fernando Perez-Cruz, Konstantinos E. Tatsis)</author>
      <guid isPermaLink="false">2503.24130v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>ORAL: Prompting Your Large-Scale LoRAs via Conditional Recurrent Diffusion</title>
      <link>http://arxiv.org/abs/2503.24354v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ORAL，一个用于生成高质量模型权重的条件循环扩散框架，旨在解决低秩适应（LoRA）在大型语言模型（LLMs）中的应用问题。&lt;h4&gt;背景&lt;/h4&gt;参数生成作为一种新型神经网络开发范式，为传统神经网络训练提供了替代方案。LoRA在LLMs中的应用承诺了高效的适应，但现有方法在同时实现可扩展性和可控性方面存在局限。&lt;h4&gt;目的&lt;/h4&gt;提出ORAL框架，以解决LoRA在LLMs中应用的局限性，实现高效适应。&lt;h4&gt;方法&lt;/h4&gt;ORAL结合了新的条件机制，整合模型架构和文本任务规范，生成特定于任务的LoRA参数，这些参数能够在不断演变的基座模型之间无缝迁移。&lt;h4&gt;主要发现&lt;/h4&gt;ORAL方法可扩展到数十亿参数的LLMs，并保持可控性。通过在七个语言任务、四个视觉任务和三个多模态任务上使用五个预训练LLMs进行的广泛实验，证明了ORAL生成的LoRA参数在性能上与传统的训练模型相当或更优。&lt;h4&gt;结论&lt;/h4&gt;ORAL框架为LoRA在LLMs中的应用提供了一种有效的解决方案，有望提高LLMs的适应性和性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：参数生成已成为神经网络开发的创新范式，它通过直接合成高质量模型权重，为传统的神经网络训练提供了一种替代方案。在低秩适应（LoRA）应用于不断更新的大型语言模型（LLMs）的背景下，这种方法承诺在无需昂贵重新训练的情况下实现高效适应。然而，现有方法在同时实现可扩展性和可控性方面面临关键限制。在本文中，我们引入了ORAL，一个针对这些挑战的新型条件循环扩散框架。ORAL结合了一种新的条件机制，该机制整合了模型架构和文本任务规范，使得能够生成特定于任务的LoRA参数，这些参数可以在不断演变的基座模型之间无缝迁移。我们的方法成功扩展到数十亿参数的LLMs，并保持了可控性。通过在七个语言任务、四个视觉任务和三个多模态任务上使用五个预训练LLMs进行的广泛实验，我们证明了ORAL生成的LoRA参数在性能上与未经训练的普通训练模型相当或更优。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter generation has emerged as a novel paradigm for neural networkdevelopment, offering an alternative to traditional neural network training bysynthesizing high-quality model weights directly. In the context of Low-RankAdaptation (LoRA) for evolving ($\textit{i.e.}$, constantly updated) largelanguage models (LLMs), this approach promises efficient adaptation withoutcostly retraining. However, existing methods face critical limitations insimultaneously achieving scalability and controllability. In this paper, weintroduce $\texttt{ORAL}$, a novel $\textbf{conditional recurrent diffusion}$framework that addresses these challenges. $\texttt{ORAL}$ incorporates a novelconditioning mechanism that integrates model architecture and textual taskspecifications, enabling the generation of task-specific LoRA parameters thatcan seamlessly transfer across evolving foundation models. Our approachsuccessfully scales to billions-of-parameter LLMs and maintainscontrollability. Through extensive experiments across seven language tasks,four vision tasks, and three multimodal tasks using five pre-trained LLMs, wedemonstrate that $\texttt{ORAL}$ generates high-quality LoRA parameters thatachieve comparable or superior performance to vanilla trained counterparts.</description>
      <author>example@mail.com (Rana Muhammad Shahroz Khan, Dongwen Tang, Pingzhi Li, Kai Wang, Tianlong Chen)</author>
      <guid isPermaLink="false">2503.24354v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Inductive Graph Representation Learning with Quantum Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2503.24111v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合量子计算和图结构数据处理的新方法——量子图神经网络（QGNNs），并介绍了其在分子数据集上的应用和性能。&lt;h4&gt;背景&lt;/h4&gt;现有的QGNNs因缺乏灵活性而限制了其在图结构问题中的应用，而经典的图神经网络（GNNs）虽然具有可扩展性和鲁棒性，但无法直接应用于量子计算。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有QGNNs的局限性，本文提出了一种基于经典GraphSAGE方法的通用QGNN框架，利用量子模型作为聚合器。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了图上的归纳表示学习技术与参数化的量子卷积和池化层，以实现经典与量子范式之间的有效桥梁。通过灵活的卷积层设计，可以针对特定问题进行定制。&lt;h4&gt;主要发现&lt;/h4&gt;在QM9数据集上的节点回归任务中，该框架成功地对非平凡的分子数据集进行了建模，其性能与经典GNNs相当。此外，该方法在不需要电路修改的情况下，对具有不同原子数量的分子表现出稳健的泛化能力，并略优于经典GNNs。此外，通过数值研究，证明了随着量子比特数量的增加，该框架没有出现贫瘠的平台，表明所提出的量子模型可以有效地扩展到处理更大和更复杂的图结构问题。&lt;h4&gt;结论&lt;/h4&gt;本文提出的QGNN框架在结合量子计算和图结构数据处理方面展现出潜力，为解决更广泛的图结构问题提供了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum Graph Neural Networks (QGNNs) present a promising approach forcombining quantum computing with graph-structured data processing. Whileclassical Graph Neural Networks (GNNs) are renowned for their scalability androbustness, existing QGNNs often lack flexibility due to graph-specific quantumcircuit designs, limiting their applicability to a narrower range ofgraph-structured problems, falling short of real-world scenarios. To addressthese limitations, we propose a versatile QGNN framework inspired by theclassical GraphSAGE approach, utilizing quantum models as aggregators. In thiswork, we integrate established techniques for inductive representation learningon graphs with parametrized quantum convolutional and pooling layers,effectively bridging classical and quantum paradigms. The convolutional layeris flexible, enabling tailored designs for specific problems. Benchmarked on anode regression task with the QM9 dataset, we demonstrate that our frameworksuccessfully models a non-trivial molecular dataset, achieving performancecomparable to classical GNNs. In particular, we show that our quantum approachexhibits robust generalization across molecules with varying numbers of atomswithout requiring circuit modifications, slightly outperforming classical GNNs.Furthermore, we numerically investigate the scalability of the QGNN framework.Specifically, we demonstrate the absence of barren plateaus in our architectureas the number of qubits increases, suggesting that the proposed quantum modelcan be extended to handle larger and more complex graph-based problemseffectively.</description>
      <author>example@mail.com (Arthur M. Faria, Ignacio F. Graña, Savvas Varsamopoulos)</author>
      <guid isPermaLink="false">2503.24111v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1</title>
      <link>http://arxiv.org/abs/2503.24376v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report (In Progress); Code released at:  https://github.com/TencentARC/SEED-Bench-R1&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的基准SEED-Bench-R1，用于评估多模态大型语言模型在视频理解任务中的后训练方法，并通过实验证明了强化学习在数据效率和性能上的优势。&lt;h4&gt;背景&lt;/h4&gt;近期，基于思维链（COT）的生成技术显著提升了大型语言模型（LLMs）的推理能力，强化学习（RL）成为有效的后训练方法。多模态大型语言模型（MLLMs）继承了这种推理潜力，但在需要感知和逻辑推理的任务中仍被低估。&lt;h4&gt;目的&lt;/h4&gt;设计SEED-Bench-R1基准，以系统评估MLLMs在视频理解任务中的后训练方法。&lt;h4&gt;方法&lt;/h4&gt;SEED-Bench-R1包含复杂的现实视频和日常规划任务，以多项选择题的形式呈现，要求高级感知和推理。通过一个三层的层次结构来评估泛化能力：分布内、跨环境和跨环境任务场景。使用Qwen2-VL-Instruct-7B作为基模型，比较了强化学习（RL）与监督微调（SFT）。&lt;h4&gt;主要发现&lt;/h4&gt;RL在分布内和分布外任务上均表现出数据效率和性能上的优势，甚至在一些视频理解基准测试中优于SFT。分析表明，RL增强了视觉感知，但往往产生不太逻辑连贯的推理链。&lt;h4&gt;结论&lt;/h4&gt;识别出关键限制，如推理不一致和忽视视觉线索，并建议在基模型推理、奖励建模和强化学习对噪声信号的鲁棒性方面进行未来改进。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近期在思维链（COT）生成方面的进步显著提高了大型语言模型（LLMs）的推理能力，强化学习（RL）已成为一种有效的后训练方法。多模态大型语言模型（MLLMs）继承了这种推理潜力，但在需要感知和逻辑推理的任务中仍被低估。为了解决这个问题，我们引入了SEED-Bench-R1基准，这是一个用于系统评估MLLMs在视频理解任务中后训练方法的基准。它包括复杂的现实视频和日常规划任务，以多项选择题的形式呈现，需要高级感知和推理。SEED-Bench-R1通过一个三层层次结构来评估泛化能力：分布内、跨环境和跨环境任务场景，配备了一个包含易于验证的地面实况答案的大型训练数据集。使用Qwen2-VL-Instruct-7B作为基模型，我们比较了RL与监督微调（SFT），证明了RL的数据效率和在分布内和分布外任务上的优越性能，甚至在像LongVideoBench这样的通用视频理解基准测试中优于SFT。我们的详细分析表明，RL增强了视觉感知，但往往产生不太逻辑连贯的推理链。我们确定了关键限制，如不一致的推理和忽视的视觉线索，并建议在基模型推理、奖励建模和强化学习对噪声信号的鲁棒性方面进行未来改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/tencentarc/seed-bench-r1&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Chain of Thought (COT) generation have significantlyimproved the reasoning capabilities of Large Language Models (LLMs), withreinforcement learning (RL) emerging as an effective post-training approach.Multimodal Large Language Models (MLLMs) inherit this reasoning potential butremain underexplored in tasks requiring both perception and logical reasoning.To address this, we introduce SEED-Bench-R1, a benchmark designed tosystematically evaluate post-training methods for MLLMs in video understanding.It includes intricate real-world videos and complex everyday planning tasks inthe format of multiple-choice questions, requiring sophisticated perception andreasoning. SEED-Bench-R1 assesses generalization through a three-levelhierarchy: in-distribution, cross-environment, and cross-environment-taskscenarios, equipped with a large-scale training dataset with easily verifiableground-truth answers. Using Qwen2-VL-Instruct-7B as a base model, we compare RLwith supervised fine-tuning (SFT), demonstrating RL's data efficiency andsuperior performance on both in-distribution and out-of-distribution tasks,even outperforming SFT on general video understanding benchmarks likeLongVideoBench. Our detailed analysis reveals that RL enhances visualperception but often produces less logically coherent reasoning chains. Weidentify key limitations such as inconsistent reasoning and overlooked visualcues, and suggest future improvements in base model reasoning, reward modeling,and RL robustness against noisy signals.</description>
      <author>example@mail.com (Yi Chen, Yuying Ge, Rui Wang, Yixiao Ge, Lu Qiu, Ying Shan, Xihui Liu)</author>
      <guid isPermaLink="false">2503.24376v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating High-Efficiency Organic Photovoltaic Discovery via Pretrained Graph Neural Networks and Generative Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2503.23766v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AI for Accelerated Materials Design - ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种框架，通过结合大规模预训练的图神经网络（GNN）和基于GPT-2的强化学习（RL）策略，旨在设计具有高功率转换效率（PCE）的有机光伏（OPV）分子。&lt;h4&gt;背景&lt;/h4&gt;有机光伏材料是成本效益高的太阳能利用的潜在途径，但优化供体-受体（D-A）组合以达到高PCE仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;设计具有高PCE的OPV分子。&lt;h4&gt;方法&lt;/h4&gt;提出了一种框架，该框架结合了大规模预训练的图神经网络（GNN）和基于GPT-2的强化学习（RL）策略。&lt;h4&gt;主要发现&lt;/h4&gt;该方法产生的候选分子预计效率接近21%，同时进行了初步的片段级分析，以识别RL模型识别的结构基序，这些基序可能有助于提高PCE，从而为更广泛的研究社区提供设计指南。&lt;h4&gt;结论&lt;/h4&gt;正在构建迄今为止最大的开源OPV数据集，预计将包括近3000对供体-受体。讨论了与实验团队合作合成和表征AI设计分子的计划，这将提供新数据以完善和改进预测和生成模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：有机光伏（OPV）材料为低成本太阳能利用提供了有希望的途径。然而，优化供体-受体（D-A）组合以达到高功率转换效率（PCE）仍然是一个重大挑战。在本工作中，我们提出了一种框架，该框架将大规模预训练的图神经网络（GNN）与基于GPT-2的强化学习（RL）策略相结合，以设计具有潜在高PCE的OPV分子。这种方法产生了预计效率接近21%的候选分子，尽管需要进一步的实验验证。此外，我们进行了初步的片段级分析，以识别由RL模型识别的结构基序，这些基序可能有助于提高PCE，从而为更广泛的研究社区提供设计指南。为了促进持续发现，我们正在构建迄今为止最大的开源OPV数据集，预计将包括近3000对供体-受体。最后，我们讨论了与实验团队合作合成和表征AI设计分子的计划，这将提供新数据以完善和改进我们的预测和生成模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Organic photovoltaic (OPV) materials offer a promising avenue towardcost-effective solar energy utilization. However, optimizing donor-acceptor(D-A) combinations to achieve high power conversion efficiency (PCE) remains asignificant challenge. In this work, we propose a framework that integrateslarge-scale pretraining of graph neural networks (GNNs) with a GPT-2(Generative Pretrained Transformer 2)-based reinforcement learning (RL)strategy to design OPV molecules with potentially high PCE. This approachproduces candidate molecules with predicted efficiencies approaching 21\%,although further experimental validation is required. Moreover, we conducted apreliminary fragment-level analysis to identify structural motifs recognized bythe RL model that may contribute to enhanced PCE, thus providing designguidelines for the broader research community. To facilitate continueddiscovery, we are building the largest open-source OPV dataset to date,expected to include nearly 3,000 donor-acceptor pairs. Finally, we discussplans to collaborate with experimental teams on synthesizing and characterizingAI-designed molecules, which will provide new data to refine and improve ourpredictive and generative models.</description>
      <author>example@mail.com (Jiangjie Qiu, Hou Hei Lam, Xiuyuan Hu, Wentao Li, Siwei Fu, Fankun Zeng, Hao Zhang, Xiaonan Wang)</author>
      <guid isPermaLink="false">2503.23766v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating and Designing Sparse Autoencoders by Approximating Quasi-Orthogonality</title>
      <link>http://arxiv.org/abs/2503.24277v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了稀疏自编码器（SAEs）在可解释性方面的应用，并提出了一种新的SAE架构和评估方法。&lt;h4&gt;背景&lt;/h4&gt;稀疏自编码器是现代机制可解释性的重要工具，但现有的基于top-$k$激活函数的SAE方法缺乏对超参数$k$的理论支持。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种新的方法来评估SAE的特征激活程度，并设计一个无需调整稀疏度超参数的SAE架构。&lt;h4&gt;方法&lt;/h4&gt;基于线性表示假设（LRH）和叠加假设（SH），本文提出了一种近似特征激活（AFA）方法，并引入了ZF图来可视化LLM隐藏嵌入和SAE特征向量之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;AFA可以近似真实稀疏特征向量的幅度，并提出了一种新的评估指标来衡量输入和激活之间的对齐程度。基于AFA，本文设计了一种新的SAE架构——top-AFA SAE，该架构无需调整稀疏度超参数，且在重构损失方面与最先进的top-k SAE相当。&lt;h4&gt;结论&lt;/h4&gt;top-AFA SAE在理论上更合理，且在无需调整超参数$k$的情况下，实现了与最先进的top-k SAE相当的性能。&lt;h4&gt;翻译&lt;/h4&gt;Sparse autoencoders (SAEs) have emerged as a workhorse of modern mechanistic interpretability, but leading SAE approaches with top-$k$ style activation functions lack theoretical grounding for selecting the hyperparameter $k$. SAEs are based on the linear representation hypothesis (LRH), which assumes that the representations of large language models (LLMs) are linearly encoded, and the superposition hypothesis (SH), which states that there can be more features in the model than its dimensionality. We show that, based on the formal definitions of the LRH and SH, the magnitude of sparse feature vectors (the latent representations learned by SAEs of the dense embeddings of LLMs) can be approximated using their corresponding dense vector with a closed-form error bound. To visualize this, we propose the ZF plot, which reveals a previously unknown relationship between LLM hidden embeddings and SAE feature vectors, allowing us to make the first empirical measurement of the extent to which feature vectors of pre-trained SAEs are over- or under-activated for a given input. Correspondingly, we introduce Approximate Feature Activation (AFA), which approximates the magnitude of the ground-truth sparse feature vector, and propose a new evaluation metric derived from AFA to assess the alignment between inputs and activations. We also leverage AFA to introduce a novel SAE architecture, the top-AFA SAE, leading to SAEs that: (a) are more in line with theoretical justifications; and (b) obviate the need to tune SAE sparsity hyperparameters. Finally, we empirically demonstrate that top-AFA SAEs achieve reconstruction loss comparable to that of state-of-the-art top-k SAEs, without requiring the hyperparameter $k$ to be tuned. Our code is available at: https://github.com/SewoongLee/top-afa-sae.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/sewoonglee/top-afa-sae&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sparse autoencoders (SAEs) have emerged as a workhorse of modern mechanisticinterpretability, but leading SAE approaches with top-$k$ style activationfunctions lack theoretical grounding for selecting the hyperparameter $k$. SAEsare based on the linear representation hypothesis (LRH), which assumes that therepresentations of large language models (LLMs) are linearly encoded, and thesuperposition hypothesis (SH), which states that there can be more features inthe model than its dimensionality. We show that, based on the formaldefinitions of the LRH and SH, the magnitude of sparse feature vectors (thelatent representations learned by SAEs of the dense embeddings of LLMs) can beapproximated using their corresponding dense vector with a closed-form errorbound. To visualize this, we propose the ZF plot, which reveals a previouslyunknown relationship between LLM hidden embeddings and SAE feature vectors,allowing us to make the first empirical measurement of the extent to whichfeature vectors of pre-trained SAEs are over- or under-activated for a giveninput. Correspondingly, we introduce Approximate Feature Activation (AFA),which approximates the magnitude of the ground-truth sparse feature vector, andpropose a new evaluation metric derived from AFA to assess the alignmentbetween inputs and activations. We also leverage AFA to introduce a novel SAEarchitecture, the top-AFA SAE, leading to SAEs that: (a) are more in line withtheoretical justifications; and (b) obviate the need to tune SAE sparsityhyperparameters. Finally, we empirically demonstrate that top-AFA SAEs achievereconstruction loss comparable to that of state-of-the-art top-k SAEs, withoutrequiring the hyperparameter $k$ to be tuned. Our code is available at:https://github.com/SewoongLee/top-afa-sae.</description>
      <author>example@mail.com (Sewoong Lee, Adam Davies, Marc E. Canby, Julia Hockenmaier)</author>
      <guid isPermaLink="false">2503.24277v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>GNN-Based Candidate Node Predictor for Influence Maximization in Temporal Graphs</title>
      <link>http://arxiv.org/abs/2503.23713v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 5 figures, Accepted in AAAI25 to AI4TS Workshop@AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合图神经网络（GNN）和双向长短期记忆（BiLSTM）模型的新颖学习方法，用于在动态网络中识别有影响力的节点，以解决传统影响力最大化策略在关系和结构快速演变时的不足。&lt;h4&gt;背景&lt;/h4&gt;在信息快速传播的社会媒体时代，有效地识别动态网络中的有影响力节点至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了解决传统方法在关系和结构快速演变时的不足，提高种子集选择预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个融合GNN和BiLSTM的混合框架，该框架能够捕捉结构和时间动态，并通过双向BiLSTM分析网络过去和未来的状态模式，确保模型对时间变化的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在动态适应图进化的每个时间快照时提高了种子集计算的效率，在预测潜在种子节点时实现了90%的平均准确率，显著减少了计算开销。&lt;h4&gt;结论&lt;/h4&gt;该方法在病毒营销和社交网络分析等领域特别有效，这些领域理解时间动态至关重要。&lt;h4&gt;翻译&lt;/h4&gt;在信息快速传播的社会媒体时代，有效地识别动态网络中的有影响力节点至关重要。传统的最大化影响力策略往往无法跟上快速演变的关系和结构，导致错失机会和低效。为了解决这个问题，我们提出了一种新的基于学习的方法，将图神经网络（GNN）与双向长短期记忆（BiLSTM）模型相结合。这个混合框架能够同时捕捉结构和时间动态，从而实现候选节点预测的准确性。BiLSTM的双向特性使我们的模型能够分析网络过去和未来状态的模式，确保模型对时间变化的适应性。通过在每次时间快照中动态适应图进化，该方法提高了种子集计算的效率，在预测潜在种子节点时实现了90%的平均准确率，显著减少了计算开销。该方法在病毒营销和社交网络分析等领域特别有效，这些领域理解时间动态至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In an age where information spreads rapidly across social media, effectivelyidentifying influential nodes in dynamic networks is critical. Traditionalinfluence maximization strategies often fail to keep up with rapidly evolvingrelationships and structures, leading to missed opportunities andinefficiencies. To address this, we propose a novel learning-based approachintegrating Graph Neural Networks (GNNs) with Bidirectional Long Short-TermMemory (BiLSTM) models. This hybrid framework captures both structural andtemporal dynamics, enabling accurate prediction of candidate nodes for seed setselection. The bidirectional nature of BiLSTM allows our model to analyzepatterns from both past and future network states, ensuring adaptability tochanges over time. By dynamically adapting to graph evolution at each timesnapshot, our approach improves seed set calculation efficiency, achieving anaverage of 90% accuracy in predicting potential seed nodes across diversenetworks. This significantly reduces computational overhead by optimizing thenumber of nodes evaluated for seed selection. Our method is particularlyeffective in fields like viral marketing and social network analysis, whereunderstanding temporal dynamics is crucial.</description>
      <author>example@mail.com (Priyanka Gautam, Balasubramaniam Natarajan, Sai Munikoti, S M Ferdous, Mahantesh Halappanavar)</author>
      <guid isPermaLink="false">2503.23713v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>PathOrchestra: A Comprehensive Foundation Model for Computational Pathology with Over 100 Diverse Clinical-Grade Tasks</title>
      <link>http://arxiv.org/abs/2503.24345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PathOrchestra是一个基于自监督学习训练的病理学基础模型，它在多个临床任务上表现出色，具有较高的准确率，并具有临床应用潜力。&lt;h4&gt;背景&lt;/h4&gt;高分辨率病理图像的复杂性和可变性给计算病理学带来了挑战，而基于AI的病理学基础模型的发展需要大规模数据集、大量存储空间和计算资源。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够处理多种临床任务的病理学基础模型，并验证其在不同临床任务上的有效性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;PathOrchestra在包含300K张病理切片的数据集上通过自监督学习进行训练，该数据集来自20种不同组织和器官类型。模型在112个临床任务上进行了严格评估，使用了61个私有和51个公共数据集。&lt;h4&gt;主要发现&lt;/h4&gt;PathOrchestra在27,755张全切片图像（WSIs）和9,415,729个区域（ROIs）上表现出色，在47个任务中实现了超过95%的准确率，包括跨器官的泛癌分类、淋巴瘤亚型诊断和膀胱癌筛查。它是第一个为高发病率结直肠癌和诊断复杂的淋巴瘤生成结构化报告的模型。&lt;h4&gt;结论&lt;/h4&gt;PathOrchestra证明了大规模自监督病理学基础模型的可行性和有效性，其在广泛临床等级任务上的验证表明，它具有临床整合的潜力，为更高效、高质量的医疗服务提供了途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：高分辨率病理图像的复杂性和可变性给计算病理学带来了重大挑战。虽然利用AI的病理学基础模型已经催化了变革性的进步，但它们的发展需要大规模数据集、大量存储空间和计算资源。此外，确保它们的临床适用性和泛化能力需要在广泛的临床任务上进行严格的验证。在这里，我们介绍了PathOrchestra，这是一个通过在包含来自多个中心的20种组织和器官类型的300K张病理切片的数据集上进行自监督学习训练的多功能病理学基础模型。该模型使用61个私有和51个公共数据集的组合在112个临床任务上进行了严格评估。这些任务包括数字切片预处理、泛癌分类、病变识别、多癌亚型分类、生物标志物评估、基因表达预测和结构化报告的生成。PathOrchestra在27,755个全切片图像（WSIs）和9,415,729个区域（ROIs）上表现出色，在47个任务中实现了超过95%的准确率，包括跨器官的泛癌分类、淋巴瘤亚型诊断和膀胱癌筛查。值得注意的是，它是第一个为高发病率结直肠癌和诊断复杂的淋巴瘤生成结构化报告的模型。总的来说，PathOrchestra展示了大规模自监督病理学基础模型的可行性和有效性，它在广泛临床等级任务上的验证表明，它具有临床整合的潜力，为更高效、高质量的医疗服务提供了途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The complexity and variability inherent in high-resolution pathologicalimages present significant challenges in computational pathology. Whilepathology foundation models leveraging AI have catalyzed transformativeadvancements, their development demands large-scale datasets, considerablestorage capacity, and substantial computational resources. Furthermore,ensuring their clinical applicability and generalizability requires rigorousvalidation across a broad spectrum of clinical tasks. Here, we presentPathOrchestra, a versatile pathology foundation model trained viaself-supervised learning on a dataset comprising 300K pathological slides from20 tissue and organ types across multiple centers. The model was rigorouslyevaluated on 112 clinical tasks using a combination of 61 private and 51 publicdatasets. These tasks encompass digital slide preprocessing, pan-cancerclassification, lesion identification, multi-cancer subtype classification,biomarker assessment, gene expression prediction, and the generation ofstructured reports. PathOrchestra demonstrated exceptional performance across27,755 WSIs and 9,415,729 ROIs, achieving over 0.950 accuracy in 47 tasks,including pan-cancer classification across various organs, lymphoma subtypediagnosis, and bladder cancer screening. Notably, it is the first model togenerate structured reports for high-incidence colorectal cancer anddiagnostically complex lymphoma-areas that are infrequently addressed byfoundational models but hold immense clinical potential. Overall, PathOrchestraexemplifies the feasibility and efficacy of a large-scale, self-supervisedpathology foundation model, validated across a broad range of clinical-gradetasks. Its high accuracy and reduced reliance on extensive data annotationunderline its potential for clinical integration, offering a pathway towardmore efficient and high-quality medical services.</description>
      <author>example@mail.com (Fang Yan, Jianfeng Wu, Jiawen Li, Wei Wang, Jiaxuan Lu, Wen Chen, Zizhao Gao, Jianan Li, Hong Yan, Jiabo Ma, Minda Chen, Yang Lu, Qing Chen, Yizhi Wang, Xitong Ling, Xuenian Wang, Zihan Wang, Qiang Huang, Shengyi Hua, Mianxin Liu, Lei Ma, Tian Shen, Xiaofan Zhang, Yonghong He, Hao Chen, Shaoting Zhang, Zhe Wang)</author>
      <guid isPermaLink="false">2503.24345v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>CIBR: Cross-modal Information Bottleneck Regularization for Robust CLIP Generalization</title>
      <link>http://arxiv.org/abs/2503.24182v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Cross-modal Information Bottleneck (CIB)框架，用于解释Contrastive Language-Image Pretraining (CLIP)的对比学习目标，并通过Cross-modal Information Bottleneck Regularization (CIBR)方法在训练中强制执行这些原则，从而提高了跨模态表示学习的效果。&lt;h4&gt;背景&lt;/h4&gt;CLIP在跨模态任务中取得了显著成功，但其强大的泛化能力的理论基础尚不明确。&lt;h4&gt;目的&lt;/h4&gt;填补CLIP泛化能力理论基础上的空白，并提高跨模态表示学习的效果。&lt;h4&gt;方法&lt;/h4&gt;提出CIB框架，将CLIP的对比学习目标解释为隐式信息瓶颈优化，并引入CIBR方法，在训练中强制执行信息瓶颈原则，通过引入惩罚项来减少模态特定的冗余。&lt;h4&gt;主要发现&lt;/h4&gt;CIBR在多个视觉-语言基准测试中表现出色，包括零样本分类和文本-图像检索，其性能优于标准CLIP，为CLIP的泛化提供了第一个理论理解。&lt;h4&gt;结论&lt;/h4&gt;CIBR方法为未来跨模态表示学习提供了指导，并证明了信息瓶颈理论在解释CLIP泛化能力方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive Language-Image Pretraining (CLIP)在跨模态任务，如零样本图像分类和文本图像检索中取得了显著的成功，通过有效地对齐视觉和文本表示。然而，CLIP强大泛化能力的理论基础仍然不明确。在这项工作中，我们通过提出跨模态信息瓶颈（CIB）框架来填补这一空白。CIB为CLIP的对比学习目标提供了一个原则性的解释，将其视为隐式信息瓶颈优化。在这种观点下，模型最大化共享的跨模态信息，同时丢弃模态特定的冗余，从而在模态之间保持基本的语义对齐。基于这一洞察，我们引入了一种跨模态信息瓶颈正则化（CIBR）方法，在训练中明确强制执行这些IB原则。CIB引入了一个惩罚项，以减少模态特定的冗余，从而增强图像和文本特征之间的语义对齐。我们在广泛的视觉-语言基准测试中验证了CIBR，包括跨越七个不同图像数据集的零样本分类和MSCOCO和Flickr30K上的文本图像检索。结果表明，CIBR在标准CLIP之上取得了一致的性能提升。这些发现为CLIP通过IB视角的泛化提供了第一个理论理解。它们还证明了实际改进，为未来的跨模态表示学习提供了指导。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive Language-Image Pretraining (CLIP) has achieved remarkable successin cross-modal tasks such as zero-shot image classification and text-imageretrieval by effectively aligning visual and textual representations. However,the theoretical foundations underlying CLIP's strong generalization remainunclear. In this work, we address this gap by proposing the Cross-modalInformation Bottleneck (CIB) framework. CIB offers a principled interpretationof CLIP's contrastive learning objective as an implicit Information Bottleneckoptimization. Under this view, the model maximizes shared cross-modalinformation while discarding modality-specific redundancies, thereby preservingessential semantic alignment across modalities. Building on this insight, weintroduce a Cross-modal Information Bottleneck Regularization (CIBR) methodthat explicitly enforces these IB principles during training. CIBR introduces apenalty term to discourage modality-specific redundancy, thereby enhancingsemantic alignment between image and text features. We validate CIBR onextensive vision-language benchmarks, including zero-shot classification acrossseven diverse image datasets and text-image retrieval on MSCOCO and Flickr30K.The results show consistent performance gains over standard CLIP. Thesefindings provide the first theoretical understanding of CLIP's generalizationthrough the IB lens. They also demonstrate practical improvements, offeringguidance for future cross-modal representation learning.</description>
      <author>example@mail.com (Yingrui Ji, Xi Xiao, Gaofei Chen, Hao Xu, Chenrui Ma, Lijing Zhu, Aokun Liang, Jiansheng Chen)</author>
      <guid isPermaLink="false">2503.24182v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Predicting the von Neumann Entanglement Entropy Using a Graph Neural Network</title>
      <link>http://arxiv.org/abs/2503.23635v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用图神经网络从实验数据中预测冯·诺伊曼纠缠熵的方法，并测试了其在Rydberg梯级系统上的应用。&lt;h4&gt;背景&lt;/h4&gt;计算实验数据中的冯·诺伊曼纠缠熵具有挑战性，因为其依赖于完整的波函数，迫使依赖于像经典互信息这样的近似。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法来预测实验数据中的冯·诺伊曼熵。&lt;h4&gt;方法&lt;/h4&gt;使用图神经网络对实验可访问的比特串进行预测。&lt;h4&gt;主要发现&lt;/h4&gt;在训练范围内，该方法在熵值从0到1.9的数据集上实现了平均绝对误差为$3.7imes 10^{-3}$，并且当熵值大于最大熵的0.01时，平均绝对百分比误差为1.72%，优于基于互信息的界限。当测试范围超出时，模型仍能提供合理的结果。此外，使用小数据集微调模型可以显著提高其在原始训练范围之外的数据上的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在预测冯·诺伊曼熵方面表现出色，并且通过微调可以进一步提高其性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Calculating the von Neumann entanglement entropy from experimental data ischallenging due to its dependence on the complete wavefunction, forcingreliance on approximations like classical mutual information (MI). We propose amachine learning approach using a graph neural network for predicting the vonNeumann entropy from experimentally accessible bitstrings. We tested thisapproach on a Rydberg ladder system and achieved a mean absolute error of $3.7\times 10^{-3}$ when testing it inside of its training range on a dataset withentropy ranging from 0 to 1.9, we also evaluated the mean absolute percentageerror on the data that have its entropy larger than 0.01 of the maximumentropy(so we can avoid the areas of our phase space with near zero entropy)and got a relative error of 1.72%, outperforming MI-based bounds. When testedbeyond this range, the model still delivers reasonable results. Furthermore, wedemonstrate that fine tuning the model with a small dataset significantlyimproves its performance on data outside its original training range.</description>
      <author>example@mail.com (Anas Saleh)</author>
      <guid isPermaLink="false">2503.23635v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Consistent Subject Generation via Contrastive Instantiated Concepts</title>
      <link>http://arxiv.org/abs/2503.24387v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://contrastive-concept-instantiation.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为Contrastive Concept Instantiation (CoCoIns)的生成模型，用于在多个独立创作中合成一致的主体内容。&lt;h4&gt;背景&lt;/h4&gt;现有的文本到图像生成模型虽然能合成多样化且忠实的内容，但由于多个创作之间的主体变化，限制了其在长内容生成中的应用。&lt;h4&gt;目的&lt;/h4&gt;目的是有效地合成多个独立创作中的一致主体。&lt;h4&gt;方法&lt;/h4&gt;CoCoIns框架由一个生成模型和一个映射网络组成，映射网络将输入的潜在代码转换为与特定概念实例相关的伪词。用户可以使用相同的潜在代码生成一致的主体。论文提出了一个对比学习方法，训练网络区分提示和潜在代码的组合。&lt;h4&gt;主要发现&lt;/h4&gt;通过单一主体的广泛评估，CoCoIns的表现与现有方法相当，同时保持了更高的灵活性。此外，论文还展示了将CoCoIns扩展到多个主体和其他对象类别的潜力。&lt;h4&gt;结论&lt;/h4&gt;CoCoIns是一个有效的方法，能够在多个独立创作中合成一致的主体，并且有潜力扩展到更广泛的领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While text-to-image generative models can synthesize diverse and faithfulcontents, subject variation across multiple creations limits the application inlong content generation. Existing approaches require time-consuming tuning,references for all subjects, or access to other creations. We introduceContrastive Concept Instantiation (CoCoIns) to effectively synthesizeconsistent subjects across multiple independent creations. The frameworkconsists of a generative model and a mapping network, which transforms inputlatent codes into pseudo-words associated with certain instances of concepts.Users can generate consistent subjects with the same latent codes. To constructsuch associations, we propose a contrastive learning approach that trains thenetwork to differentiate the combination of prompts and latent codes. Extensiveevaluations of human faces with a single subject show that CoCoIns performscomparably to existing methods while maintaining higher flexibility. We alsodemonstrate the potential of extending CoCoIns to multiple subjects and otherobject categories.</description>
      <author>example@mail.com (Lee Hsin-Ying, Kelvin C. K. Chan, Ming-Hsuan Yang)</author>
      <guid isPermaLink="false">2503.24387v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Simple Feedfoward Neural Networks are Almost All You Need for Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2503.23621v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了时间序列数据在不同领域的应用，并探讨了简单前馈神经网络（SFNN）在时间序列预测中的性能。&lt;h4&gt;背景&lt;/h4&gt;时间序列数据广泛应用于金融、医疗保健等领域，每个领域都有其独特的复杂性和结构。尽管Transformer和图神经网络（GNNs）等高级模型在时间序列预测中取得了成功，但它们的复杂性并非总是必要的。&lt;h4&gt;目的&lt;/h4&gt;研究SFNN在时间序列预测中的性能，并比较其与高级模型如Transformer和GNNs的表现。&lt;h4&gt;方法&lt;/h4&gt;通过实验和分析，评估SFNN在时间序列预测中的性能，并与高级模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;SFNN可以取得与高级模型相当甚至更好的性能，同时更加简单、小巧、快速和稳健。多变量SFNN即使在存在强系列间关系的情况下也能提供有竞争力的结果。&lt;h4&gt;结论&lt;/h4&gt;SFNN可以作为时间序列预测方法的一个强大基准，是未来方法进行比较的参考。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了时间序列数据在不同领域的应用，并探讨了简单前馈神经网络（SFNN）在时间序列预测中的性能。尽管Transformer和图神经网络（GNNs）等高级模型在时间序列预测中取得了成功，但它们的复杂性并非总是必要的。本文通过实验和分析，发现SFNN可以取得与高级模型相当甚至更好的性能，同时更加简单、小巧、快速和稳健。多变量SFNN即使在存在强系列间关系的情况下也能提供有竞争力的结果。SFNN可以作为时间序列预测方法的一个强大基准，是未来方法进行比较的参考。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series data are everywhere -- from finance to healthcare -- and eachdomain brings its own unique complexities and structures. While advanced modelslike Transformers and graph neural networks (GNNs) have gained popularity intime series forecasting, largely due to their success in tasks like languagemodeling, their added complexity is not always necessary. In our work, we showthat simple feedforward neural networks (SFNNs) can achieve performance on parwith, or even exceeding, these state-of-the-art models, while being simpler,smaller, faster, and more robust. Our analysis indicates that, in many cases,univariate SFNNs are sufficient, implying that modeling interactions betweenmultiple series may offer only marginal benefits. Even when inter-seriesrelationships are strong, a basic multivariate SFNN still delivers competitiveresults. We also examine some key design choices and offer guidelines on makinginformed decisions. Additionally, we critique existing benchmarking practicesand propose an improved evaluation protocol. Although SFNNs may not be optimalfor every situation (hence the ``almost'' in our title) they serve as a strongbaseline that future time series forecasting methods should always be comparedagainst.</description>
      <author>example@mail.com (Fan-Keng Sun, Yu-Cheng Wu, Duane S. Boning)</author>
      <guid isPermaLink="false">2503.23621v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Order Matters: On Parameter-Efficient Image-to-Video Probing for Recognizing Nearly Symmetric Actions</title>
      <link>http://arxiv.org/abs/2503.24298v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究了一种参数高效的图像到视频探测方法，用于识别近似对称动作，并提出了Self-attentive Temporal Embedding Probing（STEP）方法，在参数高效的视频传输中增强了时间敏感性。&lt;h4&gt;背景&lt;/h4&gt;现有的图像预训练模型探测机制，如DinoV2和CLIP，依赖于注意力机制进行时间建模，但本质上是排列不变的，导致无论帧序如何，预测都相同。&lt;h4&gt;目的&lt;/h4&gt;解决识别近似对称动作的问题，即视觉上相似的动作在相反的时间顺序中展开（例如，打开和关闭瓶子）。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Self-attentive Temporal Embedding Probing（STEP）的方法，包括三个关键改进：(1) 可学习的帧级位置编码，显式编码时间顺序；(2) 单个全局CLS标记，用于序列连贯性；(3) 简化的注意力机制以提高参数效率。&lt;h4&gt;主要发现&lt;/h4&gt;STEP在四个活动识别基准测试中优于现有的图像到视频探测机制，参数减少了1/3。在两个数据集上，它超过了所有已发布的方法，包括完全微调的模型。在识别近似对称动作方面，STEP具有明显优势，比其他探测机制高9-19%，比参数更重的PEFT迁移方法高5-15%。&lt;h4&gt;结论&lt;/h4&gt;STEP方法在参数高效的视频传输中提高了时间敏感性，并显著提高了识别近似对称动作的性能。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了参数高效的图像到视频探测，以解决识别近似对称动作这一未解决的问题——视觉上相似的动作在相反的时间顺序中展开（例如，打开和关闭瓶子）。现有的图像预训练模型探测机制，如DinoV2和CLIP，依赖于注意力机制进行时间建模，但本质上是对称不变的，导致无论帧序如何，预测都相同。为了解决这个问题，我们引入了Self-attentive Temporal Embedding Probing（STEP），这是一种简单而有效的方法，旨在在参数高效的图像到视频传输中强制执行时间敏感性。STEP通过以下三个关键改进增强了自注意力探测：(1) 可学习的帧级位置编码，显式编码时间顺序；(2) 单个全局CLS标记，用于序列连贯性；(3) 简化的注意力机制以提高参数效率。在四个活动识别基准测试中，STEP优于现有的图像到视频探测机制，参数减少了1/3。在两个数据集上，它超过了所有已发布的方法，包括完全微调的模型。在识别近似对称动作方面，STEP具有明显优势，比其他探测机制高9-19%，比参数更重的PEFT迁移方法高5-15%。代码和模型将公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study parameter-efficient image-to-video probing for the unaddressedchallenge of recognizing nearly symmetric actions - visually similar actionsthat unfold in opposite temporal order (e.g., opening vs. closing a bottle).Existing probing mechanisms for image-pretrained models, such as DinoV2 andCLIP, rely on attention mechanism for temporal modeling but are inherentlypermutation-invariant, leading to identical predictions regardless of frameorder. To address this, we introduce Self-attentive Temporal Embedding Probing(STEP), a simple yet effective approach designed to enforce temporalsensitivity in parameter-efficient image-to-video transfer. STEP enhancesself-attentive probing with three key modifications: (1) a learnable frame-wisepositional encoding, explicitly encoding temporal order; (2) a single globalCLS token, for sequence coherence; and (3) a simplified attention mechanism toimprove parameter efficiency. STEP outperforms existing image-to-video probingmechanisms by 3-15% across four activity recognition benchmarks with only 1/3of the learnable parameters. On two datasets, it surpasses all publishedmethods, including fully fine-tuned models. STEP shows a distinct advantage inrecognizing nearly symmetric actions, surpassing other probing mechanisms by9-19%. and parameter-heavier PEFT-based transfer methods by 5-15%. Code andmodels will be made publicly available.</description>
      <author>example@mail.com (Thinesh Thiyakesan Ponbagavathi, Alina Roitberg)</author>
      <guid isPermaLink="false">2503.24298v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>From Colors to Classes: Emergence of Concepts in Vision Transformers</title>
      <link>http://arxiv.org/abs/2503.24071v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Accepted at The 3rd World Conference on eXplainable  Artificial Intelligence&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对Vision Transformers（ViTs）在计算机视觉任务中的应用进行了研究，通过层级的分析揭示了ViTs如何通过神经元标记编码概念，并探讨了不同预训练策略对编码概念的影响。&lt;h4&gt;背景&lt;/h4&gt;Vision Transformers（ViTs）在计算机视觉任务中越来越受欢迎，但其信息处理过程尚未得到充分研究。与卷积神经网络（CNNs）不同，ViTs缺乏CNNs的归纳偏见，但可能通过注意力机制从第一层学习全局依赖关系。&lt;h4&gt;目的&lt;/h4&gt;提高对ViTs层级的理解，分析其编码概念的方式，并探讨预训练策略对编码概念的影响。&lt;h4&gt;方法&lt;/h4&gt;采用神经元标记对最先进的ViTs进行层级分析，比较不同预训练策略下编码概念的差异。&lt;h4&gt;主要发现&lt;/h4&gt;ViTs在网络的各层中编码概念，随着复杂性的增加，每层编码的概念数量也增加，反映了更多样化和具体的功能集合。早期层主要编码基本特征如颜色和纹理，而后期层则代表更具体的类别，包括物体和动物。&lt;h4&gt;结论&lt;/h4&gt;ViTs能够通过层级的概念编码处理信息，不同预训练策略会影响编码概念的数量和类别，对特定下游任务的微调通常会减少编码概念的数量，并将概念转向更相关的类别。&lt;h4&gt;翻译&lt;/h4&gt;Vision Transformers (ViTs) are increasingly utilized in various computer vision tasks due to their powerful representation capabilities. However, it remains understudied how ViTs process information layer by layer. Numerous studies have shown that convolutional neural networks (CNNs) extract features of increasing complexity throughout their layers, which is crucial for tasks like domain adaptation and transfer learning. ViTs, lacking the same inductive biases as CNNs, can potentially learn global dependencies from the first layers due to their attention mechanisms. Given the increasing importance of ViTs in computer vision, there is a need to improve the layer-wise understanding of ViTs. In this work, we present a novel, layer-wise analysis of concepts encoded in state-of-the-art ViTs using neuron labeling. Our findings reveal that ViTs encode concepts with increasing complexity throughout the network. Early layers primarily encode basic features such as colors and textures, while later layers represent more specific classes, including objects and animals. As the complexity of encoded concepts increases, the number of concepts represented in each layer also rises, reflecting a more diverse and specific set of features. Additionally, different pretraining strategies influence the quantity and category of encoded concepts, with finetuning to specific downstream tasks generally reducing the number of encoded concepts and shifting the concepts to more relevant categories.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/teresa-sc/concepts_in_vits&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision Transformers (ViTs) are increasingly utilized in various computervision tasks due to their powerful representation capabilities. However, itremains understudied how ViTs process information layer by layer. Numerousstudies have shown that convolutional neural networks (CNNs) extract featuresof increasing complexity throughout their layers, which is crucial for taskslike domain adaptation and transfer learning. ViTs, lacking the same inductivebiases as CNNs, can potentially learn global dependencies from the first layersdue to their attention mechanisms. Given the increasing importance of ViTs incomputer vision, there is a need to improve the layer-wise understanding ofViTs. In this work, we present a novel, layer-wise analysis of concepts encodedin state-of-the-art ViTs using neuron labeling. Our findings reveal that ViTsencode concepts with increasing complexity throughout the network. Early layersprimarily encode basic features such as colors and textures, while later layersrepresent more specific classes, including objects and animals. As thecomplexity of encoded concepts increases, the number of concepts represented ineach layer also rises, reflecting a more diverse and specific set of features.Additionally, different pretraining strategies influence the quantity andcategory of encoded concepts, with finetuning to specific downstream tasksgenerally reducing the number of encoded concepts and shifting the concepts tomore relevant categories.</description>
      <author>example@mail.com (Teresa Dorszewski, Lenka Tětková, Robert Jenssen, Lars Kai Hansen, Kristoffer Knutsen Wickstrøm)</author>
      <guid isPermaLink="false">2503.24071v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Can Test-Time Scaling Improve World Foundation Model?</title>
      <link>http://arxiv.org/abs/2503.24320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SWIFT，一个针对世界基础模型（WFM）的测试时间缩放框架，用于提高WFM推理的性能。&lt;h4&gt;背景&lt;/h4&gt;世界基础模型通过预测未来状态从当前观测和输入中模拟物理世界，在物理智能应用（如自动驾驶和机器人技术）中发挥着核心作用。然而，这些模型在预训练和后训练过程中对计算资源需求量大，并且受到可用数据的限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种测试时间缩放方法，作为传统模型增大或重新训练的替代方案，以提高WFM推理的效率和效果。&lt;h4&gt;方法&lt;/h4&gt;SWIFT结合了可扩展的WFM评估工具包和进程级推理策略，包括快速分词、基于概率的Top-K剪枝和高效的束搜索。&lt;h4&gt;主要发现&lt;/h4&gt;测试时间缩放对于WFMs是可行的，SWIFT提供了在不重新训练或增加模型大小的情况下提高WFM推理的可扩展和有效途径。&lt;h4&gt;结论&lt;/h4&gt;SWIFT是一种有效的测试时间缩放框架，可以提升WFM的性能，且代码已公开。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了世界基础模型在物理智能领域的应用及其面临的挑战，提出了SWIFT测试时间缩放框架，并展示了其在COSMOS模型上的效果，得出SWIFT可以有效提高WFM推理性能的结论。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; World foundation models, which simulate the physical world by predictingfuture states from current observations and inputs, have become central to manyapplications in physical intelligence, including autonomous driving androbotics. However, these models require substantial computational resources forpretraining and are further constrained by available data during post-training.As such, scaling computation at test time emerges as both a critical andpractical alternative to traditional model enlargement or re-training. In thiswork, we introduce SWIFT, a test-time scaling framework tailored for WFMs.SWIFT integrates our extensible WFM evaluation toolkit with process-levelinference strategies, including fast tokenization, probability-based Top-Kpruning, and efficient beam search. Empirical results on the COSMOS modeldemonstrate that test-time scaling exists even in a compute-optimal way. Ourfindings reveal that test-time scaling laws hold for WFMs and that SWIFTprovides a scalable and effective pathway for improving WFM inference withoutretraining or increasing model size. The code is available athttps://github.com/Mia-Cong/SWIFT.git.</description>
      <author>example@mail.com (Wenyan Cong, Hanqing Zhu, Peihao Wang, Bangya Liu, Dejia Xu, Kevin Wang, David Z. Pan, Yan Wang, Zhiwen Fan, Zhangyang Wang)</author>
      <guid isPermaLink="false">2503.24320v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Style Quantization for Data-Efficient GAN Training</title>
      <link>http://arxiv.org/abs/2503.24282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SQ-GAN的新方法，通过引入风格空间量化方案来增强一致性正则化（CR）的性能，从而解决GAN在有限数据设置下难以有效利用输入潜在空间的问题。&lt;h4&gt;背景&lt;/h4&gt;在有限数据设置下，GAN在导航和有效利用输入潜在空间方面存在困难，导致从稀疏输入潜在空间中相邻变量生成的图像在现实感上存在显著差异，进而影响CR的效果。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提高CR性能。&lt;h4&gt;方法&lt;/h4&gt;SQ-GAN通过将稀疏的连续输入潜在空间转化为紧凑的结构化离散代理空间，使每个元素对应特定的真实数据点。它首先将输入潜在变量映射到一个较少纠缠的“风格”空间，并使用可学习的代码簿进行量化，使每个量化代码控制不同的变化因素。此外，它通过优化最优传输距离，将代码簿代码与由基础模型从训练数据中提取的特征对齐，将外部知识嵌入代码簿，并建立一个语义丰富的词汇表，以正确描述训练数据集。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，与我们的方法相比，判别器鲁棒性和生成质量都有显著提高。&lt;h4&gt;结论&lt;/h4&gt;SQ-GAN通过引入风格空间量化方案，有效地提高了GAN在有限数据设置下的CR性能，从而改善了图像生成的质量和判别器的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Under limited data setting, GANs often struggle to navigate and effectivelyexploit the input latent space. Consequently, images generated from adjacentvariables in a sparse input latent space may exhibit significant discrepanciesin realism, leading to suboptimal consistency regularization (CR) outcomes. Toaddress this, we propose \textit{SQ-GAN}, a novel approach that enhances CR byintroducing a style space quantization scheme. This method transforms thesparse, continuous input latent space into a compact, structured discrete proxyspace, allowing each element to correspond to a specific real data point,thereby improving CR performance. Instead of direct quantization, we first mapthe input latent variables into a less entangled ``style'' space and applyquantization using a learnable codebook. This enables each quantized code tocontrol distinct factors of variation. Additionally, we optimize the optimaltransport distance to align the codebook codes with features extracted from thetraining data by a foundation model, embedding external knowledge into thecodebook and establishing a semantically rich vocabulary that properlydescribes the training dataset. Extensive experiments demonstrate significantimprovements in both discriminator robustness and generation quality with ourmethod.</description>
      <author>example@mail.com (Jian Wang, Xin Lan, Jizhe Zhou, Yuxin Tian, Jiancheng Lv)</author>
      <guid isPermaLink="false">2503.24282v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Graph-Eq: Discovering Mathematical Equations using Graph Generative Models</title>
      <link>http://arxiv.org/abs/2503.23617v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Graph-EQ的深度图生成模型，用于高效地发现数学方程，并展示了其在发现适合数据集的方程方面的能力。&lt;h4&gt;背景&lt;/h4&gt;现有的方程发现方法大多依赖遗传编程，但这种方法通常速度慢且容易过拟合。&lt;h4&gt;目的&lt;/h4&gt;提出Graph-EQ模型，旨在高效地发现描述数据集的数学方程，并生成新的方程。&lt;h4&gt;方法&lt;/h4&gt;Graph-EQ使用条件变分自编码器（CVAE）来学习方程空间中的丰富潜在表示，并通过贝叶斯优化在无监督学习的大规模方程语料库上进行训练。它还使用贝叶斯优化来高效地探索学习到的潜在空间。&lt;h4&gt;主要发现&lt;/h4&gt;Graph-EQ的编码器-解码器架构能够准确重构输入方程，并且可以从学习到的潜在表示中采样并解码成有效的方程，包括训练数据中的新方程和未见过的方程。在20个具有已知真实方程的数据集上进行的实验表明，Graph-EQ在大多数数据集中成功发现了真实方程。&lt;h4&gt;结论&lt;/h4&gt;Graph-EQ模型在方程发现方面表现出色，能够有效地从数据集中发现最佳拟合的方程。&lt;h4&gt;翻译&lt;/h4&gt;摘要：发现描述数据集的有意义、准确且简洁的数学方程在各个领域都有价值。方程提供了变量之间的明确关系，使人们能够更深入地了解潜在数据模式。大多数现有的方程发现方法依赖于遗传编程，这种迭代搜索方程空间的方法通常速度慢且容易过拟合。通过将方程表示为有向无环图，我们利用图神经网络来学习方程的潜在语义，并生成新的、之前未见过的方程。尽管图生成模型已在许多领域中显示出在发现新类型图方面的成功，但其应用于发现方程的领域仍大部分未探索。在这项工作中，我们提出了Graph-EQ，这是一种专为高效方程发现设计的深度图生成模型。Graph-EQ使用条件变分自编码器（CVAE）通过在大规模方程语料库上以无监督方式训练，来学习方程空间的丰富潜在表示。我们不是直接搜索方程空间，而是采用贝叶斯优化来高效地探索这个学习到的潜在空间。我们表明，Graph-Eq的编码器-解码器架构能够准确重构输入方程。此外，我们还表明，可以从学习到的潜在表示中进行采样并解码成有效的方程，包括训练数据中的新方程和未见过的方程。最后，我们通过使用贝叶斯优化探索潜在空间来评估Graph-Eq发现最佳拟合数据集方程的能力。在20个具有已知真实方程的数据集上进行的潜在空间探索表明，Graph-Eq在大多数数据集中成功地发现了真实方程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to discover meaningful, accurate, and concise mathematicalequations that describe datasets is valuable across various domains. Equationsoffer explicit relationships between variables, enabling deeper insights intounderlying data patterns. Most existing equation discovery methods rely ongenetic programming, which iteratively searches the equation space but is oftenslow and prone to overfitting. By representing equations as directed acyclicgraphs, we leverage the use of graph neural networks to learn the underlyingsemantics of equations, and generate new, previously unseen equations. Althoughgraph generative models have been shown to be successful in discovering newtypes of graphs in many fields, there application in discovering equationsremains largely unexplored. In this work, we propose Graph-EQ, a deep graphgenerative model designed for efficient equation discovery. Graph-EQ uses aconditional variational autoencoder (CVAE) to learn a rich latentrepresentation of the equation space by training it on a large corpus ofequations in an unsupervised manner. Instead of directly searching the equationspace, we employ Bayesian optimization to efficiently explore this learnedlatent space. We show that the encoder-decoder architecture of Graph-Eq is ableto accurately reconstruct input equations. Moreover, we show that the learnedlatent representation can be sampled and decoded into valid equations,including new and previously unseen equations in the training data. Finally, weassess Graph-Eq's ability to discover equations that best fit a dataset byexploring the latent space using Bayesian optimization. Latent spaceexploration is done on 20 dataset with known ground-truth equations, andGraph-Eq is shown to successfully discover the grountruth equation in themajority of datasets.</description>
      <author>example@mail.com (Nisal Ranasinghe, Damith Senanayake, Saman Halgamuge)</author>
      <guid isPermaLink="false">2503.23617v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Node Embeddings via Neighbor Embeddings</title>
      <link>http://arxiv.org/abs/2503.23822v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于邻居嵌入方法的统一框架，用于处理图布局和节点嵌入两种非参数图表示学习范式。&lt;h4&gt;背景&lt;/h4&gt;图布局和节点嵌入是两种不同的图表示学习方法，前者将节点嵌入2D空间进行可视化，后者将节点嵌入高维向量空间进行下游处理。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用单一框架同时处理图布局和节点嵌入问题。&lt;h4&gt;方法&lt;/h4&gt;引入了图t-SNE和图CNE两种方法，分别用于二维图布局和高维节点表示，并基于InfoNCE目标函数进行优化。&lt;h4&gt;主要发现&lt;/h4&gt;图t-SNE和图CNE在局部结构保持方面优于现有算法，且概念上更为简单。&lt;h4&gt;结论&lt;/h4&gt;本文提出的统一框架能够有效处理图布局和节点嵌入问题，为非参数图表示学习提供了一种新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph layouts and node embeddings are two distinct paradigms fornon-parametric graph representation learning. In the former, nodes are embeddedinto 2D space for visualization purposes. In the latter, nodes are embeddedinto a high-dimensional vector space for downstream processing.State-of-the-art algorithms for these two paradigms, force-directed layouts andrandom-walk-based contrastive learning (such as DeepWalk and node2vec), havelittle in common. In this work, we show that both paradigms can be approachedwith a single coherent framework based on established neighbor embeddingmethods. Specifically, we introduce graph t-SNE, a neighbor embedding methodfor two-dimensional graph layouts, and graph CNE, a contrastive neighborembedding method that produces high-dimensional node representations byoptimizing the InfoNCE objective. We show that both graph t-SNE and graph CNEstrongly outperform state-of-the-art algorithms in terms of local structurepreservation, while being conceptually simpler.</description>
      <author>example@mail.com (Jan Niklas Böhm, Marius Keute, Alica Guzmán, Sebastian Damrich, Andrew Draganov, Dmitry Kobak)</author>
      <guid isPermaLink="false">2503.23822v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Point Tracking in Surgery--The 2024 Surgical Tattoos in Infrared (STIR) Challenge</title>
      <link>http://arxiv.org/abs/2503.24306v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了STIR挑战2024，旨在推动手术空间理解领域向更精确和高效的算法发展。&lt;h4&gt;背景&lt;/h4&gt;理解手术中的组织运动对于下游任务（如分割、3D重建、虚拟组织标记、自主探头扫描和子任务自主性）至关重要。&lt;h4&gt;目的&lt;/h4&gt;通过引入一个点跟踪挑战，量化算法并推动其发展。&lt;h4&gt;方法&lt;/h4&gt;参与者提交算法，使用名为STIR（红外手术标记）的数据集进行评估，挑战包括准确性和效率两个量化组件。&lt;h4&gt;主要发现&lt;/h4&gt;共有8支队伍参加挑战，其中4支在挑战日之前提交，4支在挑战日之后提交。&lt;h4&gt;结论&lt;/h4&gt;STIR挑战2024有助于推动手术空间理解领域向更精确和高效的算法发展。&lt;h4&gt;翻译&lt;/h4&gt;Understanding tissue motion in surgery is crucial to enable applications in downstream tasks such as segmentation, 3D reconstruction, virtual tissue landmarking, autonomous probe-based scanning, and subtask autonomy. Labelled data are essential to enabling algorithms in these downstream tasks since they allow us to quantify and train algorithms. This paper introduces a point tracking challenge to address this, wherein participants can submit their algorithms for quantification. The submitted algorithms are evaluated using a dataset named surgical tattoos in infrared (STIR), with the challenge aptly named the STIR Challenge 2024. The STIR Challenge 2024 comprises two quantitative components: accuracy and efficiency. The accuracy component tests the accuracy of algorithms on in vivo and ex vivo sequences. The efficiency component tests the latency of algorithm inference. The challenge was conducted as a part of MICCAI EndoVis 2024. In this challenge, we had 8 total teams, with 4 teams submitting before and 4 submitting after challenge day. This paper details the STIR Challenge 2024, which serves to move the field towards more accurate and efficient algorithms for spatial understanding in surgery. In this paper we summarize the design, submissions, and results from the challenge. The challenge dataset is available here: https://zenodo.org/records/14803158, and the code for baseline models and metric calculation is available here: https://github.com/athaddius/STIRMetrics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/athaddius/stirmetrics&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding tissue motion in surgery is crucial to enable applications indownstream tasks such as segmentation, 3D reconstruction, virtual tissuelandmarking, autonomous probe-based scanning, and subtask autonomy. Labeleddata are essential to enabling algorithms in these downstream tasks since theyallow us to quantify and train algorithms. This paper introduces a pointtracking challenge to address this, wherein participants can submit theiralgorithms for quantification. The submitted algorithms are evaluated using adataset named surgical tattoos in infrared (STIR), with the challenge aptlynamed the STIR Challenge 2024. The STIR Challenge 2024 comprises twoquantitative components: accuracy and efficiency. The accuracy component teststhe accuracy of algorithms on in vivo and ex vivo sequences. The efficiencycomponent tests the latency of algorithm inference. The challenge was conductedas a part of MICCAI EndoVis 2024. In this challenge, we had 8 total teams, with4 teams submitting before and 4 submitting after challenge day. This paperdetails the STIR Challenge 2024, which serves to move the field towards moreaccurate and efficient algorithms for spatial understanding in surgery. In thispaper we summarize the design, submissions, and results from the challenge. Thechallenge dataset is available here: https://zenodo.org/records/14803158 , andthe code for baseline models and metric calculation is available here:https://github.com/athaddius/STIRMetrics</description>
      <author>example@mail.com (Adam Schmidt, Mert Asim Karaoglu, Soham Sinha, Mingang Jang, Ho-Gun Ha, Kyungmin Jung, Kyeongmo Gu, Ihsan Ullah, Hyunki Lee, Jonáš Šerých, Michal Neoral, Jiří Matas, Rulin Zhou, Wenlong He, An Wang, Hongliang Ren, Bruno Silva, Sandro Queirós, Estêvão Lima, João L. Vilaça, Shunsuke Kikuchi, Atsushi Kouno, Hiroki Matsuzaki, Tongtong Li, Yulu Chen, Ling Li, Xiang Ma, Xiaojian Li, Mona Sheikh Zeinoddin, Xu Wang, Zafer Tandogdu, Greg Shaw, Evangelos Mazomenos, Danail Stoyanov, Yuxin Chen, Zijian Wu, Alexander Ladikos, Simon DiMaio, Septimiu E. Salcudean, Omid Mohareri)</author>
      <guid isPermaLink="false">2503.24306v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>DANTE-AD: Dual-Vision Attention Network for Long-Term Audio Description</title>
      <link>http://arxiv.org/abs/2503.24096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了DANTE-AD，一种基于双视觉Transformer架构的视频描述模型，用于提高视觉障碍观众对视频关键视觉元素的理解。&lt;h4&gt;背景&lt;/h4&gt;虽然短视频理解技术发展迅速，但保持连贯的长期视觉叙事的解决方案仍然没有解决。现有方法主要依赖于帧级嵌入，有效描述基于对象的内容，但缺乏场景间的上下文信息。&lt;h4&gt;目的&lt;/h4&gt;提出DANTE-AD模型，通过融合帧和场景级嵌入，提高长期上下文理解，并生成细粒度的音频描述。&lt;h4&gt;方法&lt;/h4&gt;DANTE-AD采用双视觉Transformer架构，通过序列交叉注意力机制实现上下文定位，并融合帧和场景级嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;DANTE-AD在多个关键场景的评估中优于现有方法，无论是在传统的自然语言处理指标还是在基于大型语言模型（LLM）的评估中。&lt;h4&gt;结论&lt;/h4&gt;DANTE-AD为视觉障碍观众提供了更有效的视频描述，是视频描述领域的一项重要进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio Description is a narrated commentary designed to aid vision-impairedaudiences in perceiving key visual elements in a video. While short-form videounderstanding has advanced rapidly, a solution for maintaining coherentlong-term visual storytelling remains unresolved. Existing methods rely solelyon frame-level embeddings, effectively describing object-based content butlacking contextual information across scenes. We introduce DANTE-AD, anenhanced video description model leveraging a dual-vision Transformer-basedarchitecture to address this gap. DANTE-AD sequentially fuses both frame andscene level embeddings to improve long-term contextual understanding. Wepropose a novel, state-of-the-art method for sequential cross-attention toachieve contextual grounding for fine-grained audio description generation.Evaluated on a broad range of key scenes from well-known movie clips, DANTE-ADoutperforms existing methods across traditional NLP metrics and LLM-basedevaluations.</description>
      <author>example@mail.com (Adrienne Deganutti, Simon Hadfield, Andrew Gilbert)</author>
      <guid isPermaLink="false">2503.24096v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Evaluation of (Un-)Supervised Machine Learning Methods for GNSS Interference Classification with Real-World Data Discrepancies</title>
      <link>http://arxiv.org/abs/2503.23775v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  34 pages, 25 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了在道路上实现车辆精确定位的重要性，并分析了基于机器学习的干扰监测方法在实际应用中的可行性和挑战。&lt;h4&gt;背景&lt;/h4&gt;车辆定位对于自动驾驶汽车、收费系统和数字测速仪等应用至关重要。全球导航卫星系统（GNSS）接收器通常用于验证车辆的绝对位置，但GNSS定位可能受到干扰信号的影响。&lt;h4&gt;目的&lt;/h4&gt;评估基于机器学习的干扰监测方法在现实世界环境中的性能，并提出解决实际应用中数据集创建困难的方法。&lt;h4&gt;方法&lt;/h4&gt;在德国的两条高速公路和奥地利Seetal阿尔卑斯山以及大型室内环境中进行了大规模的测量活动。评估了最新的基于监督学习的机器学习方法，并探讨了伪标签在无监督学习中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;发现由于数据集差异，数据集的合并存在挑战，并评估了异常检测、领域适应和数据增强技术，以展示模型适应数据集变化的能力。&lt;h4&gt;结论&lt;/h4&gt;尽管基于机器学习的干扰监测方法在监控干扰方面表现出色，但在实际应用中仍存在挑战，需要进一步研究和改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.33012/2024.19887&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accuracy and reliability of vehicle localization on roads are crucial forapplications such as self-driving cars, toll systems, and digital tachographs.To achieve accurate positioning, vehicles typically use global navigationsatellite system (GNSS) receivers to validate their absolute positions.However, GNSS-based positioning can be compromised by interference signals,necessitating the identification, classification, determination of purpose, andlocalization of such interference to mitigate or eliminate it. Recentapproaches based on machine learning (ML) have shown superior performance inmonitoring interference. However, their feasibility in real-world applicationsand environments has yet to be assessed. Effective implementation of MLtechniques requires training datasets that incorporate realistic interferencesignals, including real-world noise and potential multipath effects that mayoccur between transmitter, receiver, and satellite in the operational area.Additionally, these datasets require reference labels. Creating such datasetsis often challenging due to legal restrictions, as causing interference to GNSSsources is strictly prohibited. Consequently, the performance of ML-basedmethods in practical applications remains unclear. To address this gap, wedescribe a series of large-scale measurement campaigns conducted in real-worldsettings at two highway locations in Germany and the Seetal Alps in Austria,and in large-scale controlled indoor environments. We evaluate the latestsupervised ML-based methods to report on their performance in real-worldsettings and present the applicability of pseudo-labeling for unsupervisedlearning. We demonstrate the challenges of combining datasets due to datadiscrepancies and evaluate outlier detection, domain adaptation, and dataaugmentation techniques to present the models' capabilities to adapt to changesin the datasets.</description>
      <author>example@mail.com (Lucas Heublein, Nisha L. Raichur, Tobias Feigl, Tobias Brieger, Fin Heuer, Lennart Asbach, Alexander Rügamer, Felix Ott)</author>
      <guid isPermaLink="false">2503.23775v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Buffer is All You Need: Defending Federated Learning against Backdoor Attacks under Non-iids via Buffering</title>
      <link>http://arxiv.org/abs/2503.23511v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FLBuff是一种针对非独立同分布情况下的联邦学习后门攻击的防御方法。&lt;h4&gt;背景&lt;/h4&gt;联邦学习容易受到后门攻击，现有的防御措施大多基于独立同分布假设，忽略了联邦学习的非独立同分布特性。&lt;h4&gt;目的&lt;/h4&gt;提出FLBuff以应对非独立同分布情况下的后门攻击。&lt;h4&gt;方法&lt;/h4&gt;FLBuff通过监督对比学习模型提取最后一层表示，创建一个中间缓冲层来区分良性和恶意更新。&lt;h4&gt;主要发现&lt;/h4&gt;FLBuff在非独立同分布环境下表现出色，优于现有的防御方法。&lt;h4&gt;结论&lt;/h4&gt;FLBuff是一种有效的防御非独立同分布环境下后门攻击的方法。&lt;h4&gt;翻译&lt;/h4&gt;Federated Learning (FL) is a popular paradigm enabling clients to jointlytrain a global model without sharing raw data. However, FL is known to bevulnerable towards backdoor attacks due to its distributed nature. Asparticipants, attackers can upload model updates that effectively compromiseFL. What's worse, existing defenses are mostly designed underindependent-and-identically-distributed (iid) settings, hence neglecting thefundamental non-iid characteristic of FL. Here we propose FLBuff for tacklingbackdoor attacks even under non-iids. The main challenge for such defenses isthat non-iids bring benign and malicious updates closer, hence harder toseparate. FLBuff is inspired by our insight that non-iids can be modeled asomni-directional expansion in representation space while backdoor attacks asuni-directional. This leads to the key design of FLBuff, i.e., asupervised-contrastive-learning model extracting penultimate-layerrepresentations to create a large in-between buffer layer. Comprehensiveevaluations demonstrate that FLBuff consistently outperforms state-of-the-artdefenses.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Learning (FL) is a popular paradigm enabling clients to jointlytrain a global model without sharing raw data. However, FL is known to bevulnerable towards backdoor attacks due to its distributed nature. Asparticipants, attackers can upload model updates that effectively compromiseFL. What's worse, existing defenses are mostly designed underindependent-and-identically-distributed (iid) settings, hence neglecting thefundamental non-iid characteristic of FL. Here we propose FLBuff for tacklingbackdoor attacks even under non-iids. The main challenge for such defenses isthat non-iids bring benign and malicious updates closer, hence harder toseparate. FLBuff is inspired by our insight that non-iids can be modeled asomni-directional expansion in representation space while backdoor attacks asuni-directional. This leads to the key design of FLBuff, i.e., asupervised-contrastive-learning model extracting penultimate-layerrepresentations to create a large in-between buffer layer. Comprehensiveevaluations demonstrate that FLBuff consistently outperforms state-of-the-artdefenses.</description>
      <author>example@mail.com (Xingyu Lyu, Ning Wang, Yang Xiao, Shixiong Li, Tao Li, Danjue Chen, Yimin Chen)</author>
      <guid isPermaLink="false">2503.23511v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Frequency-Aware Attention-LSTM for PM$_{2.5}$ Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2503.24043v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FALNet的频率感知LSTM网络，旨在提高PM2.5浓度预测的准确性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;PM2.5浓度预测的准确性和鲁棒性是环境监测和风险评估的重要问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的模型FALNet，以增强PM2.5浓度预测的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;FALNet结合了频率域分解、时间建模和基于注意力的细化。首先使用STL和FFT提取趋势、季节性和去噪残差成分，然后使用堆叠LSTM捕捉长期依赖关系，并使用多头注意力机制动态关注关键时间步。&lt;h4&gt;主要发现&lt;/h4&gt;在真实世界城市空气质量数据集上的实验表明，FALNet在标准指标如MAE、RMSE和R²上始终优于传统模型。模型在捕捉污染高峰和非平稳条件下的急剧波动方面表现出强大的适应性。&lt;h4&gt;结论&lt;/h4&gt;FALNet在实时空气污染预测、环境风险评估和决策支持方面具有有效性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To enhance the accuracy and robustness of PM$_{2.5}$ concentrationforecasting, this paper introduces FALNet, a Frequency-Aware LSTM Network thatintegrates frequency-domain decomposition, temporal modeling, andattention-based refinement. The model first applies STL and FFT to extracttrend, seasonal, and denoised residual components, effectively filtering outhigh-frequency noise. The filtered residuals are then fed into a stacked LSTMto capture long-term dependencies, followed by a multi-head attention mechanismthat dynamically focuses on key time steps. Experiments conducted on real-worldurban air quality datasets demonstrate that FALNet consistently outperformsconventional models across standard metrics such as MAE, RMSE, and $R^2$. Themodel shows strong adaptability in capturing sharp fluctuations duringpollution peaks and non-stationary conditions. These results validate theeffectiveness and generalizability of FALNet for real-time air pollutionprediction, environmental risk assessment, and decision-making support.</description>
      <author>example@mail.com (Jiahui LU, Shuang Wu, Zhenkai Qin, Dongze Wu, Guifang Yang)</author>
      <guid isPermaLink="false">2503.24043v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Contrastive Learning: Synthetic Data Enables List-wise Training with Multiple Levels of Relevance</title>
      <link>http://arxiv.org/abs/2503.23239v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code: https://github.com/BatsResearch/sycl&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用大型语言模型生成合成文档，以解决传统信息检索训练方法中存在的不足。&lt;h4&gt;背景&lt;/h4&gt;尽管大型语言模型在信息检索领域得到了应用，但主要的训练范式仍然是基于二进制相关标签的对比学习，存在忽视文档细微差异和易受标注噪声影响的问题。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些局限性，本文旨在通过使用大型语言模型直接生成合成文档来改进信息检索系统的训练。&lt;h4&gt;方法&lt;/h4&gt;本文使用开源的大型语言模型生成不同相关性的合成文档，并结合Wasserstein距离作为损失函数，训练密集检索器。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与传统的InfoNCE训练方法相比，本文提出的方法在多个信息检索数据集上取得了显著的优势。该方法在不需要真实文档的情况下，其性能优于通过自监督训练的检索器，并且在评估零样本性能时优于使用真实标注文档训练的检索器。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在信息检索领域具有显著的优势，能够有效提高检索系统的性能和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，大型语言模型（LLMs）的进步使得信息检索（IR）管道可以通过各种方式与合成数据进行增强。然而，主要的训练范式仍然是使用二进制相关标签和InfoNCE损失的对比学习，其中一篇正文档与一篇或多篇负文档进行比较。这种目标将所有未明确标注为相关的文档视为同等程度的负文档，无论它们的实际相关性程度如何，因此（a）错过了对排名有用的细微差别，（b）容易受到标注噪声的影响。为了克服这一局限性，在本文中，我们完全放弃了真实的训练文档和标注，并使用开源LLMs直接生成合成文档，这些文档根据几个不同的相关性级别回答真实用户查询。这种具有递增相关性的完全合成排名上下文，以及适当的列表损失（Wasserstein距离），使我们能够以更好地捕捉排名任务的方式训练密集检索器。在多个IR数据集上的实验表明，我们提出的方法在性能上显著优于使用InfoNCE的传统训练方法。在不使用任何真实文档进行训练的情况下，我们的密集检索器在性能上显著优于通过自监督训练的相同检索器。更重要的是，它匹配了在同一数据集的真实、标注的训练文档上训练的相同检索器的性能，同时具有更高的鲁棒性，并且在零样本评估BEIR数据集集合时明显优于它。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/batsresearch/sycl&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in large language models (LLMs) have allowed theaugmentation of information retrieval (IR) pipelines with synthetic data invarious ways. Yet, the main training paradigm remains: contrastive learningwith binary relevance labels and the InfoNCE loss, where one positive documentis compared against one or more negatives. This objective treats all documentsthat are not explicitly annotated as relevant on an equally negative footing,regardless of their actual degree of relevance, thus (a) missing subtle nuancesthat are useful for ranking and (b) being susceptible to annotation noise. Toovercome this limitation, in this work we forgo real training documents andannotations altogether and use open-source LLMs to directly generate syntheticdocuments that answer real user queries according to several different levelsof relevance. This fully synthetic ranking context of graduated relevance,together with an appropriate list-wise loss (Wasserstein distance), enables usto train dense retrievers in a way that better captures the ranking task.Experiments on various IR datasets show that our proposed approach outperformsconventional training with InfoNCE by a large margin. Without using any realdocuments for training, our dense retriever significantly outperforms the sameretriever trained through self-supervision. More importantly, it matches theperformance of the same retriever trained on real, labeled training documentsof the same dataset, while being more robust to distribution shift and clearlyoutperforming it when evaluated zero-shot on the BEIR dataset collection.</description>
      <author>example@mail.com (Reza Esfandiarpoor, George Zerveas, Ruochen Zhang, Macton Mgonzo, Carsten Eickhoff, Stephen H. Bach)</author>
      <guid isPermaLink="false">2503.23239v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Resilient Sensor Fusion under Adverse Sensor Failures via Multi-Modal Expert Fusion</title>
      <link>http://arxiv.org/abs/2503.19776v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了MoME，一个高效的LiDAR相机3D目标检测器，通过混合专家方法实现鲁棒性能，有效解决了多模态传感器融合框架中的依赖问题。&lt;h4&gt;背景&lt;/h4&gt;现代自动驾驶感知系统使用互补的多模态传感器，如LiDAR和相机。尽管传感器融合架构在恶劣环境中提高了性能，但在严重传感器故障下，如LiDAR光束减少、LiDAR丢失、有限视野、相机丢失和遮挡，性能仍会大幅下降。&lt;h4&gt;目的&lt;/h4&gt;提出MoME，旨在通过混合专家方法，实现鲁棒的3D目标检测，即使在多模态传感器融合框架中存在模态依赖。&lt;h4&gt;方法&lt;/h4&gt;MoME通过三个并行专家解码器完全解耦模态依赖，分别使用相机特征、LiDAR特征或两者的组合来解码目标查询。采用多专家解码（MED）框架，每个查询根据相机和LiDAR特征的质量选择性地使用其中一个专家解码器。MoME利用自适应查询路由器（AQR）选择最合适的专家解码器。&lt;h4&gt;主要发现&lt;/h4&gt;MoME在nuScenes-R基准测试中实现了最先进的性能，在极端天气和传感器故障条件下，显著优于现有模型。&lt;h4&gt;结论&lt;/h4&gt;MoME在处理不同传感器故障场景时表现出鲁棒性，是自动驾驶感知系统中的有效解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代自动驾驶感知系统使用互补的多模态传感器，如激光雷达和摄像头。尽管传感器融合架构在恶劣环境中提高了性能，但在严重传感器故障下，如激光雷达光束减少、激光雷达丢失、有限视野、摄像头丢失和遮挡，性能仍然会显著下降。这种限制源于当前传感器融合框架中的模态依赖。在本研究中，我们引入了一种高效且鲁棒的激光雷达-摄像头3D目标检测器，称为MoME，通过混合专家方法实现鲁棒性能。我们的MoME使用三个并行专家解码器完全解耦模态依赖，分别使用摄像头特征、激光雷达特征或两者的组合来解码目标查询。我们提出了多专家解码（MED）框架，其中每个查询选择性地使用三个专家解码器之一进行解码。MoME利用自适应查询路由器（AQR）根据摄像头和激光雷达特征的质量为每个查询选择最合适的专家解码器。这确保了每个查询都由最适合的专家处理，从而在多样化的传感器故障场景中实现鲁棒性能。我们在nuScenes-R基准测试中评估了MoME的性能。我们的MoME在极端天气和传感器故障条件下实现了最先进的性能，在各种传感器故障场景中显著优于现有模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern autonomous driving perception systems utilize complementarymulti-modal sensors, such as LiDAR and cameras. Although sensor fusionarchitectures enhance performance in challenging environments, they stillsuffer significant performance drops under severe sensor failures, such asLiDAR beam reduction, LiDAR drop, limited field of view, camera drop, andocclusion. This limitation stems from inter-modality dependencies in currentsensor fusion frameworks. In this study, we introduce an efficient and robustLiDAR-camera 3D object detector, referred to as MoME, which can achieve robustperformance through a mixture of experts approach. Our MoME fully decouplesmodality dependencies using three parallel expert decoders, which use camerafeatures, LiDAR features, or a combination of both to decode object queries,respectively. We propose Multi-Expert Decoding (MED) framework, where eachquery is decoded selectively using one of three expert decoders. MoME utilizesan Adaptive Query Router (AQR) to select the most appropriate expert decoderfor each query based on the quality of camera and LiDAR features. This ensuresthat each query is processed by the best-suited expert, resulting in robustperformance across diverse sensor failure scenarios. We evaluated theperformance of MoME on the nuScenes-R benchmark. Our MoME achievedstate-of-the-art performance in extreme weather and sensor failure conditions,significantly outperforming the existing models across various sensor failurescenarios.</description>
      <author>example@mail.com (Konyul Park, Yecheol Kim, Daehun Kim, Jun Won Choi)</author>
      <guid isPermaLink="false">2503.19776v2</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models For Seismic Data Processing: An Extensive Review</title>
      <link>http://arxiv.org/abs/2503.24166v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在地震处理中应用基础模型的方法，并评估了不同模型特征对性能和效率的影响。&lt;h4&gt;背景&lt;/h4&gt;地震处理在将原始数据转换为高质量的地下图像方面起着关键作用，但传统方法面临数据噪声、损坏和依赖手动工作流程等挑战。&lt;h4&gt;目的&lt;/h4&gt;研究基础模型在地震处理中的应用，特别是在去多次覆盖、插值和去噪任务上。&lt;h4&gt;方法&lt;/h4&gt;本文评估了不同模型特征，如预训练技术和神经网络架构，并批判性地分析了各种自然图像基础模型，建议了一些有潜力的候选模型。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型在地震处理中显示出潜力，特别是在自然成像方面取得了成功。&lt;h4&gt;结论&lt;/h4&gt;本文建议进一步探索基础模型在地震处理中的应用，以克服传统方法的局限性。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Seismic processing plays a crucial role in transforming raw data into high-quality subsurface images, pivotal for various geoscience applications. Despite its importance, traditional seismic processing techniques face challenges such as noisy and damaged data and the reliance on manual, time-consuming workflows. The emergence of deep learning approaches has introduced effective and user-friendly alternatives, yet many of these deep learning approaches rely on synthetic datasets and specialized neural networks. Recently, foundation models have gained traction in the seismic domain, due to their success in natural imaging. This paper investigates the application of foundation models in seismic processing on the tasks: demultiple, interpolation, and denoising. It evaluates the impact of different model characteristics, such as pre-training technique and neural network architecture, on performance and efficiency. Rather than proposing a single seismic foundation model, this paper critically examines various natural image foundation models and suggests some promising candidates for future exploration.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Seismic processing plays a crucial role in transforming raw data intohigh-quality subsurface images, pivotal for various geoscience applications.Despite its importance, traditional seismic processing techniques facechallenges such as noisy and damaged data and the reliance on manual,time-consuming workflows. The emergence of deep learning approaches hasintroduced effective and user-friendly alternatives, yet many of these deeplearning approaches rely on synthetic datasets and specialized neural networks.Recently, foundation models have gained traction in the seismic domain, due totheir success in natural imaging. This paper investigates the application offoundation models in seismic processing on the tasks: demultiple,interpolation, and denoising. It evaluates the impact of different modelcharacteristics, such as pre-training technique and neural networkarchitecture, on performance and efficiency. Rather than proposing a singleseismic foundation model, this paper critically examines various natural imagefoundation models and suggest some promising candidates for future exploration.</description>
      <author>example@mail.com (Fabian Fuchs, Mario Ruben Fernandez, Norman Ettrich, Janis Keuper)</author>
      <guid isPermaLink="false">2503.24166v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Question-Aware Knowledge Graph Prompting for Enhancing Large Language Models</title>
      <link>http://arxiv.org/abs/2503.23523v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为QAP的方法，用于解决大型语言模型在需要外部知识任务上的困难，特别是在知识密集型的多项选择题（MCQA）中。该方法通过整合知识图谱（KG）和图神经网络（GNN）来增强推理能力，并通过实验证明其有效性。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在需要外部知识（如MCQA）的任务上存在困难，现有的方法通常需要昂贵的微调或检索到噪声知识图谱信息。&lt;h4&gt;目的&lt;/h4&gt;提出QAP方法，以解决MCQA任务中相关知识图谱知识缺失的问题，并提高LLMs在知识密集型任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;QAP方法将问题嵌入到GNN聚合中，以动态评估知识图谱的相关性，并使用全局注意力机制来捕捉选项之间的相互关系，从而丰富软提示。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，QAP在多个数据集上优于现有方法，证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;QAP方法能够有效提高LLMs在MCQA等知识密集型任务上的表现，为解决相关难题提供了一种新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) often struggle with tasks requiring externalknowledge, such as knowledge-intensive Multiple Choice Question Answering(MCQA). Integrating Knowledge Graphs (KGs) can enhance reasoning; however,existing methods typically demand costly fine-tuning or retrieve noisy KGinformation. Recent approaches leverage Graph Neural Networks (GNNs) togenerate KG-based input embedding prefixes as soft prompts for LLMs but fail toaccount for question relevance, resulting in noisy prompts. Moreover, in MCQAtasks, the absence of relevant KG knowledge for certain answer options remainsa significant challenge. To address these issues, we propose Question-AwareKnowledge Graph Prompting (QAP), which incorporates question embeddings intoGNN aggregation to dynamically assess KG relevance. QAP employs globalattention to capture inter-option relationships, enriching soft prompts withinferred knowledge. Experimental results demonstrate that QAP outperformsstate-of-the-art methods across multiple datasets, highlighting itseffectiveness.</description>
      <author>example@mail.com (Haochen Liu, Song Wang, Chen Chen, Jundong Li)</author>
      <guid isPermaLink="false">2503.23523v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Embedding Shift Dissection on CLIP: Effects of Augmentations on VLM's Representation Learning</title>
      <link>http://arxiv.org/abs/2503.23495v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted at MIV at CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了不同增强技术对视觉语言模型CLIP嵌入表示的影响，为机制可解释性和VLM的鲁棒性研究提供了基础。&lt;h4&gt;背景&lt;/h4&gt;通过理解视觉语言模型在不同增强技术下的表示变化，可以获得关于机制可解释性的宝贵见解。&lt;h4&gt;目的&lt;/h4&gt;展示CLIP在不同增强技术下的嵌入表示变化，并分析其对模型可解释性的影响。&lt;h4&gt;方法&lt;/h4&gt;对CLIP的嵌入表示在9种常见增强技术下的变化进行了分析，包括噪声、模糊、颜色抖动、缩放和旋转、翻转、弹性变换和透视变换、随机亮度和对比度调整以及像素块粗略dropout等。&lt;h4&gt;主要发现&lt;/h4&gt;发现噪声、透视变换和缩放变换等增强技术对嵌入表示有较大影响。&lt;h4&gt;结论&lt;/h4&gt;本研究为未来关于VLM鲁棒性和对抗数据防御的机制可解释性研究提供了具体基础。&lt;h4&gt;翻译&lt;/h4&gt;This study investigates the representation shift on Vision Language Models like CLIP under different augmentations, providing a solid foundation for future research on the robustness of VLMs for mechanistic interpretability and adversarial data defense.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the representation shift on Vision Language Models like CLIPunder different augmentations provides valuable insights on MechanisticInterpretability. In this study, we show the shift on CLIP's embeddings on 9common augmentation techniques: noise, blur, color jitter, scale and rotate,flip, elastic and perspective transforms, random brightness and contrast, andcoarse dropout of pixel blocks. We scrutinize the embedding shifts undersimilarity on attention map, patch, edge, detail preservation, cosinesimilarity, L2 distance, pairwise distance and dendrogram clusters and providequalitative analysis on sample images. Our findings suggest certainaugmentations like noise, perspective transform and shift scaling have higherdegree of drastic impact on embedding shift. This study provides a concretefoundation for future work on VLM's robustness for mechanical interpretationand adversarial data defense.</description>
      <author>example@mail.com (Ashim Dahal, Saydul Akbar Murad, Nick Rahimi)</author>
      <guid isPermaLink="false">2503.23495v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>AI-Assisted Colonoscopy: Polyp Detection and Segmentation using Foundation Models</title>
      <link>http://arxiv.org/abs/2503.24138v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE TMI for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究评估了基础模型在结肠镜检查中息肉分割的表现，发现这些模型在医学影像领域具有潜力，尤其是在标注数据稀缺的情况下。&lt;h4&gt;背景&lt;/h4&gt;在结肠镜检查中，有80%的息肉可能通过深度学习模型检测到。为了解决这一挑战，基础模型被提出作为有希望的候选者。&lt;h4&gt;目的&lt;/h4&gt;研究旨在评估基础模型在息肉分割任务中的性能，特别是检测和界定能力。&lt;h4&gt;方法&lt;/h4&gt;使用了三个不同的结肠镜检查数据集，比较了五种基础模型（DINOv2, YOLO-World, GroundingDINO, SAM和MedSAM）与两种基准网络（YOLOv8和Mask R-CNN）的表现。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型在息肉特征化方面表现良好，但成功高度依赖于领域专门化。在医学应用中，特定领域的模型是必要的，而通用模型需要微调以达到有效结果。&lt;h4&gt;结论&lt;/h4&gt;通过专门化，基础模型在检测和分割任务中优于最先进的模型，某些模型在零样本评估中甚至超越了经过微调的模型。&lt;h4&gt;翻译&lt;/h4&gt;In colonoscopy, 80% of the missed polyps could be detected with the help of Deep Learning models. In the search for algorithms capable of addressing this challenge, foundation models emerge as promising candidates. Their zero-shot or few-shot learning capabilities, facilitate generalization to new data or tasks without extensive fine-tuning. A concept that is particularly advantageous in the medical imaging domain, where large annotated datasets for traditional training are scarce. In this context, a comprehensive evaluation of foundation models for polyp segmentation was conducted, assessing both detection and delimitation. For the study, three different colonoscopy datasets have been employed to compare the performance of five different foundation models, DINOv2, YOLO-World, GroundingDINO, SAM and MedSAM, against two benchmark networks, YOLOv8 and Mask R-CNN. Results show that the success of foundation models in polyp characterization is highly dependent on domain specialization. For optimal performance in medical applications, domain-specific models are essential, and generic models require fine-tuning to achieve effective results. Through this specialization, foundation models demonstrated superior performance compared to state-of-the-art detection and segmentation models, with some models even excelling in zero-shot evaluation; outperforming fine-tuned models on unseen data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/udelaqui/foundation_models_for_polyp_detection_segmentation&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In colonoscopy, 80% of the missed polyps could be detected with the help ofDeep Learning models. In the search for algorithms capable of addressing thischallenge, foundation models emerge as promising candidates. Their zero-shot orfew-shot learning capabilities, facilitate generalization to new data or taskswithout extensive fine-tuning. A concept that is particularly advantageous inthe medical imaging domain, where large annotated datasets for traditionaltraining are scarce. In this context, a comprehensive evaluation of foundationmodels for polyp segmentation was conducted, assessing both detection anddelimitation. For the study, three different colonoscopy datasets have beenemployed to compare the performance of five different foundation models,DINOv2, YOLO-World, GroundingDINO, SAM and MedSAM, against two benchmarknetworks, YOLOv8 and Mask R-CNN. Results show that the success of foundationmodels in polyp characterization is highly dependent on domain specialization.For optimal performance in medical applications, domain-specific models areessential, and generic models require fine-tuning to achieve effective results.Through this specialization, foundation models demonstrated superiorperformance compared to state-of-the-art detection and segmentation models,with some models even excelling in zero-shot evaluation; outperformingfine-tuned models on unseen data.</description>
      <author>example@mail.com (Uxue Delaquintana-Aramendi, Leire Benito-del-Valle, Aitor Alvarez-Gila, Javier Pascau, Luisa F Sánchez-Peralta, Artzai Picón, J Blas Pagador, Cristina L Saratxaga)</author>
      <guid isPermaLink="false">2503.24138v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Pre-training with 3D Synthetic Data: Learning 3D Point Cloud Instance Segmentation from 3D Synthetic Scenes</title>
      <link>http://arxiv.org/abs/2503.24229v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于生成模型的3D点云实例分割模型预训练方法，通过使用3D合成数据来训练模型，以降低大规模3D空间中点云数据集创建的成本。&lt;h4&gt;背景&lt;/h4&gt;近年来，3D点云数据在机器人控制、车辆或其他现实世界系统中的应用越来越广泛，但创建3D点云数据集的成本远高于2D图像数据集。&lt;h4&gt;目的&lt;/h4&gt;提高3D点云实例分割的准确性和效率，降低数据集创建成本。&lt;h4&gt;方法&lt;/h4&gt;提出了一种使用3D合成数据进行预训练的方法，利用Point-E生成3D点云数据，并将其插入到3D场景中。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法与基线方法相比，在3D点云实例分割任务上提高了性能。&lt;h4&gt;结论&lt;/h4&gt;3D生成模型对于3D点云实例分割是有效的，并且使用Point-E作为早期3D生成模型可以有效地支持3D合成数据的预训练。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, the research community has witnessed growing use of 3D point cloud data for the high applicability in various real-world applications. By means of 3D point cloud, this modality enables to consider the actual size and spatial understanding. The applied fields include mechanical control of robots, vehicles, or other real-world systems. Along this line, we would like to improve 3D point cloud instance segmentation which has emerged as a particularly promising approach for these applications. However, the creation of 3D point cloud datasets entails enormous costs compared to 2D image datasets. To train a model of 3D point cloud instance segmentation, it is necessary not only to assign categories but also to provide detailed annotations for each point in the large-scale 3D space. Meanwhile, the increase of recent proposals for generative models in 3D domain has spurred proposals for using a generative model to create 3D point cloud data. In this work, we propose a pre-training with 3D synthetic data to train a 3D point cloud instance segmentation model based on generative model for 3D scenes represented by point cloud data. We directly generate 3D point cloud data with Point-E for inserting a generated data into a 3D scene. More recently in 2025, although there are other accurate 3D generation models, even using the Point-E as an early 3D generative model can effectively support the pre-training with 3D synthetic data. In the experimental section, we compare our pre-training method with baseline methods indicated improved performance, demonstrating the efficacy of 3D generative models for 3D point cloud instance segmentation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the recent years, the research community has witnessed growing use of 3Dpoint cloud data for the high applicability in various real-world applications.By means of 3D point cloud, this modality enables to consider the actual sizeand spatial understanding. The applied fields include mechanical control ofrobots, vehicles, or other real-world systems. Along this line, we would liketo improve 3D point cloud instance segmentation which has emerged as aparticularly promising approach for these applications. However, the creationof 3D point cloud datasets entails enormous costs compared to 2D imagedatasets. To train a model of 3D point cloud instance segmentation, it isnecessary not only to assign categories but also to provide detailedannotations for each point in the large-scale 3D space. Meanwhile, the increaseof recent proposals for generative models in 3D domain has spurred proposalsfor using a generative model to create 3D point cloud data. In this work, wepropose a pre-training with 3D synthetic data to train a 3D point cloudinstance segmentation model based on generative model for 3D scenes representedby point cloud data. We directly generate 3D point cloud data with Point-E forinserting a generated data into a 3D scene. More recently in 2025, althoughthere are other accurate 3D generation models, even using the Point-E as anearly 3D generative model can effectively support the pre-training with 3Dsynthetic data. In the experimental section, we compare our pre-training methodwith baseline methods indicated improved performance, demonstrating theefficacy of 3D generative models for 3D point cloud instance segmentation.</description>
      <author>example@mail.com (Daichi Otsuka, Shinichi Mae, Ryosuke Yamada, Hirokatsu Kataoka)</author>
      <guid isPermaLink="false">2503.24229v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Learning: Comparative Analysis of Clustering Techniques on High-Dimensional Data</title>
      <link>http://arxiv.org/abs/2503.23215v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对K-means、DBSCAN和Spectral Clustering等聚类算法在处理高维数据集上的表现进行了全面比较分析。&lt;h4&gt;背景&lt;/h4&gt;高维数据集的聚类分析是数据挖掘和机器学习中的关键问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的评估框架，用于通过多种降维技术（PCA、t-SNE和UMAP）和多种量化指标来评估聚类性能。&lt;h4&gt;方法&lt;/h4&gt;在MNIST、Fashion-MNIST和UCI HAR数据集上进行了实验，比较了不同聚类算法在处理不同数据集时的表现。&lt;h4&gt;主要发现&lt;/h4&gt;预处理数据使用UMAP可以一致地提高所有算法的聚类质量，Spectral Clustering在处理复杂流形结构时表现出优异的性能。K-means在计算效率上表现优异，DBSCAN在处理不规则聚类方面表现出色，而Spectral Clustering在捕捉复杂关系方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;算法的选择应根据数据特性进行指导，并提出了一个用于评估和选择高维数据应用中聚类技术的系统方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a comprehensive comparative analysis of prominentclustering algorithms K-means, DBSCAN, and Spectral Clustering onhigh-dimensional datasets. We introduce a novel evaluation framework thatassesses clustering performance across multiple dimensionality reductiontechniques (PCA, t-SNE, and UMAP) using diverse quantitative metrics.Experiments conducted on MNIST, Fashion-MNIST, and UCI HAR datasets reveal thatpreprocessing with UMAP consistently improves clustering quality across allalgorithms, with Spectral Clustering demonstrating superior performance oncomplex manifold structures. Our findings show that algorithm selection shouldbe guided by data characteristics, with Kmeans excelling in computationalefficiency, DBSCAN in handling irregular clusters, and Spectral Clustering incapturing complex relationships. This research contributes a systematicapproach for evaluating and selecting clustering techniques for highdimensional data applications.</description>
      <author>example@mail.com (Vishnu Vardhan Baligodugula, Fathi Amsaad)</author>
      <guid isPermaLink="false">2503.23215v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic Video Understanding</title>
      <link>http://arxiv.org/abs/2503.24008v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个名为H2VU的层级和全面视频理解基准，用于评估一般视频和在线流媒体视频理解能力。&lt;h4&gt;背景&lt;/h4&gt;随着多模态模型的发展，评估视频理解能力的需求增加，但现有的评估基准存在覆盖范围、任务多样性和场景适应性方面的局限性。&lt;h4&gt;目的&lt;/h4&gt;解决现有基准的局限性，提出H2VU基准，以更准确地评估模型的综合视频理解能力。&lt;h4&gt;方法&lt;/h4&gt;H2VU基准包括三个关键特性：扩展视频时长、综合评估任务和丰富视频数据。扩展视频时长包括从3秒剪辑到1.5小时记录的不同时长视频；综合评估任务包括感知推理、反常识理解和轨迹状态跟踪等；丰富视频数据包括扩展第一人称流媒体视频数据集。&lt;h4&gt;主要发现&lt;/h4&gt;H2VU的结果显示，现有的多模态大型语言模型（MLLMs）在新提出的评估任务中具有很大的改进潜力。&lt;h4&gt;结论&lt;/h4&gt;H2VU能够通过提供对MLLMs的全面深入分析，促进视频理解研究的发展。&lt;h4&gt;翻译&lt;/h4&gt;With the rapid development of multimodal models, the demand for assessing video understanding capabilities has been steadily increasing. However, existing benchmarks for evaluating video understanding exhibit significant limitations in coverage, task diversity, and scene adaptability. These shortcomings hinder the accurate assessment of models' comprehensive video understanding capabilities. To tackle this challenge, we propose a hierarchical and holistic video understanding (H2VU) benchmark designed to evaluate both general video and online streaming video comprehension. This benchmark contributes three key features: Extended video duration: Spanning videos from brief 3-second clips to comprehensive 1.5-hour recordings, thereby bridging the temporal gaps found in current benchmarks. Comprehensive assessment tasks: Beyond traditional perceptual and reasoning tasks, we have introduced modules for countercommonsense comprehension and trajectory state tracking. These additions test the models' deep understanding capabilities beyond mere prior knowledge. Enriched video data: To keep pace with the rapid evolution of current AI agents, we have expanded first-person streaming video datasets. This expansion allows for the exploration of multimodal models' performance in understanding streaming videos from a first-person perspective. Extensive results from H2VU reveal that existing multimodal large language models (MLLMs) possess substantial potential for improvement in our newly proposed evaluation tasks. We expect that H2VU will facilitate advancements in video understanding research by offering a comprehensive and in-depth analysis of MLLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of multimodal models, the demand for assessingvideo understanding capabilities has been steadily increasing. However,existing benchmarks for evaluating video understanding exhibit significantlimitations in coverage, task diversity, and scene adaptability. Theseshortcomings hinder the accurate assessment of models' comprehensive videounderstanding capabilities. To tackle this challenge, we propose a hierarchicaland holistic video understanding (H2VU) benchmark designed to evaluate bothgeneral video and online streaming video comprehension. This benchmarkcontributes three key features:  Extended video duration: Spanning videos from brief 3-second clips tocomprehensive 1.5-hour recordings, thereby bridging the temporal gaps found incurrent benchmarks. Comprehensive assessment tasks: Beyond traditionalperceptual and reasoning tasks, we have introduced modules forcountercommonsense comprehension and trajectory state tracking. These additionstest the models' deep understanding capabilities beyond mere prior knowledge.Enriched video data: To keep pace with the rapid evolution of current AIagents, we have expanded first-person streaming video datasets. This expansionallows for the exploration of multimodal models' performance in understandingstreaming videos from a first-person perspective. Extensive results from H2VUreveal that existing multimodal large language models (MLLMs) possesssubstantial potential for improvement in our newly proposed evaluation tasks.We expect that H2VU will facilitate advancements in video understandingresearch by offering a comprehensive and in-depth analysis of MLLMs.</description>
      <author>example@mail.com (Qi Wu, Quanlong Zheng, Yanhao Zhang, Junlin Xie, Jinguo Luo, Kuo Wang, Peng Liu, Qingsong Xie, Ru Zhen, Haonan Lu, Zhenyu Yang)</author>
      <guid isPermaLink="false">2503.24008v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>PhysPose: Refining 6D Object Poses with Physical Constraints</title>
      <link>http://arxiv.org/abs/2503.23587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://data.ciirc.cvut.cz/public/projects/2025PhysPose&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PhysPose的新方法，用于从图像中准确估计6D物体姿态，该方法通过后处理优化物理推理，确保姿态估计的物理一致性，并在多个数据集上取得了最先进的精度。&lt;h4&gt;背景&lt;/h4&gt;物体中心场景理解中，从图像中准确估计6D物体姿态是一个关键问题，这对于机器人、增强现实和场景重建等应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以解决现有方法在现实场景中部署时产生的物理不一致性姿态估计问题。&lt;h4&gt;方法&lt;/h4&gt;PhysPose方法通过后处理优化将物理推理整合到姿态估计中，通过强制执行非穿透和重力约束来确保物理可行性。&lt;h4&gt;主要发现&lt;/h4&gt;在YCB-Video数据集上，PhysPose达到了最先进的精度，并在HOPE-Video数据集上优于最先进的方法。此外，通过在具有挑战性的抓取和放置任务中显著提高成功率，展示了其在机器人应用中的影响。&lt;h4&gt;结论&lt;/h4&gt;物理一致性对于现实世界应用至关重要，PhysPose方法通过提高物理一致性，在机器人应用中取得了显著的成果。&lt;h4&gt;翻译&lt;/h4&gt;Accurate 6D object pose estimation from images is a key problem in object-centric scene understanding, enabling applications in robotics, augmented reality, and scene reconstruction. Despite recent advances, existing methods often produce physically inconsistent pose estimates, hindering their deployment in real-world scenarios. We introduce PhysPose, a novel approach that integrates physical reasoning into pose estimation through a post-processing optimization enforcing non-penetration and gravitational constraints. By leveraging scene geometry, PhysPose refines pose estimates to ensure physical plausibility. Our approach achieves state-of-the-art accuracy on the YCB-Video dataset from the BOP benchmark and improves over the state-of-the-art pose estimation methods on the HOPE-Video dataset. Furthermore, we demonstrate its impact in robotics by significantly improving success rates in a challenging pick-and-place task, highlighting the importance of physical consistency in real-world applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate 6D object pose estimation from images is a key problem inobject-centric scene understanding, enabling applications in robotics,augmented reality, and scene reconstruction. Despite recent advances, existingmethods often produce physically inconsistent pose estimates, hindering theirdeployment in real-world scenarios. We introduce PhysPose, a novel approachthat integrates physical reasoning into pose estimation through apostprocessing optimization enforcing non-penetration and gravitationalconstraints. By leveraging scene geometry, PhysPose refines pose estimates toensure physical plausibility. Our approach achieves state-of-the-art accuracyon the YCB-Video dataset from the BOP benchmark and improves over thestate-of-the-art pose estimation methods on the HOPE-Video dataset.Furthermore, we demonstrate its impact in robotics by significantly improvingsuccess rates in a challenging pick-and-place task, highlighting the importanceof physical consistency in real-world applications.</description>
      <author>example@mail.com (Martin Malenický, Martin Cífka, Médéric Fourmy, Louis Montaut, Justin Carpentier, Josef Sivic, Vladimir Petrik)</author>
      <guid isPermaLink="false">2503.23587v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>CrossMuSim: A Cross-Modal Framework for Music Similarity Retrieval with LLM-Powered Text Description Sourcing and Mining</title>
      <link>http://arxiv.org/abs/2503.23128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICME2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的跨模态对比学习框架，用于音乐相似性检索，通过利用文本描述的开放性来指导音乐相似性建模，克服了传统单模态方法在捕捉复杂音乐关系方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;音乐相似性检索对于流媒体平台中管理和探索大量相关内容至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来改进音乐相似性建模，以更好地捕捉复杂的音乐关系。&lt;h4&gt;方法&lt;/h4&gt;引入了一种双源数据获取方法，结合在线抓取和基于LLM的提示，利用精心设计的提示和LLM的全面音乐知识生成丰富的描述。&lt;h4&gt;主要发现&lt;/h4&gt;通过客观指标、主观评价和华为音乐流媒体平台的真实世界A/B测试，证明了所提出的框架在性能上显著优于现有基准。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架在音乐相似性检索方面取得了显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Music similarity retrieval is fundamental for managing and exploring relevantcontent from large collections in streaming platforms. This paper presents anovel cross-modal contrastive learning framework that leverages the open-endednature of text descriptions to guide music similarity modeling, addressing thelimitations of traditional uni-modal approaches in capturing complex musicalrelationships. To overcome the scarcity of high-quality text-music paired data,this paper introduces a dual-source data acquisition approach combining onlinescraping and LLM-based prompting, where carefully designed prompts leverageLLMs' comprehensive music knowledge to generate contextually rich descriptions.Exten1sive experiments demonstrate that the proposed framework achievessignificant performance improvements over existing benchmarks through objectivemetrics, subjective evaluations, and real-world A/B testing on the Huawei Musicstreaming platform.</description>
      <author>example@mail.com (Tristan Tsoi, Jiajun Deng, Yaolong Ju, Benno Weck, Holger Kirchhoff, Simon Lui)</author>
      <guid isPermaLink="false">2503.23128v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>A SAT-centered XAI method for Deep Learning based Video Understanding</title>
      <link>http://arxiv.org/abs/2503.23870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于SAT（ satisfiability）的新的形式化解释模型，用于视频理解中的深度学习。该模型结合了SAT求解技术和形式化可解释人工智能的原则，以解决现有XAI技术在视频理解领域中的局限性。&lt;h4&gt;背景&lt;/h4&gt;视频理解领域的深度学习模型存在可解释性差的问题，现有可解释人工智能（XAI）技术在处理这一问题时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过将深度学习模型和视频数据编码到逻辑框架中，并将解释查询作为可满足性问题来制定，旨在生成具有形式保证的逻辑解释。&lt;h4&gt;方法&lt;/h4&gt;该方法详细描述了概念框架、编码深度学习模型和视频数据的过程、以及如何构建“为什么”和“为什么不”的问题，并提出了一个将SAT求解器与深度学习视频理解模型集成的创新架构。&lt;h4&gt;主要发现&lt;/h4&gt;尽管命题逻辑的计算复杂性和表示能力仍存在挑战，但提出的方法为提高深度学习在视频理解这一复杂且关键领域的可解释性提供了一个有希望的方向。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一种新的方法来提高视频理解中深度学习模型的可解释性，为这一领域的研究提供了新的思路和可能的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a novel formal SAT-based explanation model for deeplearning in video understanding. The proposed method integrates SAT solvingtechniques with the principles of formal explainable AI to address thelimitations of existing XAI techniques in this domain. By encoding deeplearning models and video data into a logical framework and formulatingexplanation queries as satisfiability problems, the method aims to generatelogic-based explanations with formal guarantees. The paper details theconceptual framework, the process of encoding deep learning models and videodata, the formulation of "Why?" and "Why not?" questions, and a novelarchitecture integrating a SAT solver with a deep learning video understandingmodel. While challenges related to computational complexity and therepresentational power of propositional logic remain, the proposed approachoffers a promising direction for enhancing the explainability of deep learningin the complex and critical domain of video understanding.</description>
      <author>example@mail.com (Hojer Key)</author>
      <guid isPermaLink="false">2503.23870v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Omnidirectional Stereo Matching with a Pre-trained Depth Foundation Model</title>
      <link>http://arxiv.org/abs/2503.23502v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://vita-epfl.github.io/DFI-OmniStereo-website/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DFI-OmniStereo的新型全向立体匹配方法，用于解决移动机器人场景理解中的全360度深度感知问题。&lt;h4&gt;背景&lt;/h4&gt;全向深度感知对于需要场景理解的全360度视野的移动机器人应用至关重要。基于摄像头的设置通过使用立体深度估计来生成密集、高分辨率的深度图，是一种经济实惠的解决方案。&lt;h4&gt;目的&lt;/h4&gt;为了提高现有全向立体匹配方法在多样化环境、深度范围和光照条件下的深度准确性。&lt;h4&gt;方法&lt;/h4&gt;DFI-OmniStereo利用大规模预训练的基础模型进行相对单目深度估计，并结合迭代优化立体匹配架构。此外，引入了专用的两阶段训练策略，用于在缩放不变微调之前利用相对单目深度特征进行全向立体匹配。&lt;h4&gt;主要发现&lt;/h4&gt;DFI-OmniStereo在现实世界的Helvepad数据集上实现了最先进的性能，相比之前最佳的全向立体匹配方法，将视差均方误差（MAE）降低了大约16%。&lt;h4&gt;结论&lt;/h4&gt;DFI-OmniStereo为移动机器人中的全向深度感知提供了一种有效且准确的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Omnidirectional depth perception is essential for mobile roboticsapplications that require scene understanding across a full 360{\deg} field ofview. Camera-based setups offer a cost-effective option by using stereo depthestimation to generate dense, high-resolution depth maps without relying onexpensive active sensing. However, existing omnidirectional stereo matchingapproaches achieve only limited depth accuracy across diverse environments,depth ranges, and lighting conditions, due to the scarcity of real-world data.We present DFI-OmniStereo, a novel omnidirectional stereo matching method thatleverages a large-scale pre-trained foundation model for relative monoculardepth estimation within an iterative optimization-based stereo matchingarchitecture. We introduce a dedicated two-stage training strategy to utilizethe relative monocular depth features for our omnidirectional stereo matchingbefore scale-invariant fine-tuning. DFI-OmniStereo achieves state-of-the-artresults on the real-world Helvipad dataset, reducing disparity MAE byapproximately 16% compared to the previous best omnidirectional stereo method.</description>
      <author>example@mail.com (Jannik Endres, Oliver Hahn, Charles Corbière, Simone Schaub-Meyer, Stefan Roth, Alexandre Alahi)</author>
      <guid isPermaLink="false">2503.23502v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>SALT: A Flexible Semi-Automatic Labeling Tool for General LiDAR Point Clouds with Cross-Scene Adaptability and 4D Consistency</title>
      <link>http://arxiv.org/abs/2503.23980v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种灵活的半自动标记工具SALT，用于处理通用LiDAR点云数据，具有跨场景适应性和4D一致性。&lt;h4&gt;背景&lt;/h4&gt;现有方法依赖相机蒸馏，而SALT直接在原始LiDAR数据上操作，自动生成预分割结果。&lt;h4&gt;目的&lt;/h4&gt;提高LiDAR数据的标注效率，并推动LiDAR数据集和LiDAR基础模型的发展。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的零样本学习范式，称为数据对齐，通过将LiDAR数据与视觉基础模型的训练分布对齐，将其转换为伪图像。此外，设计了4D一致的提示策略和4D非极大值抑制模块来增强SAM2，确保高质量、时间一致性的预分割。&lt;h4&gt;主要发现&lt;/h4&gt;SALT在SemanticKITTI数据集上超过了最新的零样本方法，提高了18.4%的PQ评分，在新的低分辨率LiDAR数据集和三种LiDAR类型的数据组合上，达到了接近40-50%的人类标注者性能。&lt;h4&gt;结论&lt;/h4&gt;SALT的开源将促进LiDAR数据集的显著扩展，并为LiDAR基础模型的发展奠定基础。&lt;h4&gt;翻译&lt;/h4&gt;We propose a flexible Semi-Automatic Labeling Tool (SALT) for general LiDAR point clouds with cross-scene adaptability and 4D consistency. Unlike recent approaches that rely on camera distillation, SALT operates directly on raw LiDAR data, automatically generating pre-segmentation results. To achieve this, we propose a novel zero-shot learning paradigm, termed data alignment, which transforms LiDAR data into pseudo-images by aligning with the training distribution of vision foundation models. Additionally, we design a 4D-consistent prompting strategy and 4D non-maximum suppression module to enhance SAM2, ensuring high-quality, temporally consistent presegmentation. SALT surpasses the latest zero-shot methods by 18.4% PQ on SemanticKITTI and achieves nearly 40-50% of human annotator performance on our newly collected low-resolution LiDAR data and on combined data from three LiDAR types, significantly boosting annotation efficiency. We anticipate that SALT's open-sourcing will catalyze substantial expansion of current LiDAR datasets and lay the groundwork for the future development of LiDAR foundation models. Code is available at https://github.com/Cavendish518/SALT.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Cavendish518/SALT&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a flexible Semi-Automatic Labeling Tool (SALT) for general LiDARpoint clouds with cross-scene adaptability and 4D consistency. Unlike recentapproaches that rely on camera distillation, SALT operates directly on rawLiDAR data, automatically generating pre-segmentation results. To achieve this,we propose a novel zero-shot learning paradigm, termed data alignment, whichtransforms LiDAR data into pseudo-images by aligning with the trainingdistribution of vision foundation models. Additionally, we design a4D-consistent prompting strategy and 4D non-maximum suppression module toenhance SAM2, ensuring high-quality, temporally consistent presegmentation.SALT surpasses the latest zero-shot methods by 18.4% PQ on SemanticKITTI andachieves nearly 40-50% of human annotator performance on our newly collectedlow-resolution LiDAR data and on combined data from three LiDAR types,significantly boosting annotation efficiency. We anticipate that SALT'sopen-sourcing will catalyze substantial expansion of current LiDAR datasets andlay the groundwork for the future development of LiDAR foundation models. Codeis available at https://github.com/Cavendish518/SALT.</description>
      <author>example@mail.com (Yanbo Wang, Yongtao Chen, Chuan Cao, Tianchen Deng, Wentao Zhao, Jingchuan Wang, Weidong Chen)</author>
      <guid isPermaLink="false">2503.23980v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>POINT$^{2}$: A Polymer Informatics Training and Testing Database</title>
      <link>http://arxiv.org/abs/2503.23491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了POINT$^{2}$数据库和协议，旨在解决聚合物信息学领域中的标准化工作流程问题，包括预测准确性、不确定性量化、机器学习可解释性和聚合物合成可行性。&lt;h4&gt;背景&lt;/h4&gt;聚合物信息学领域的发展得益于机器学习技术的集成，使得聚合物性质的快速预测和高性能聚合物材料的发现成为可能。&lt;h4&gt;目的&lt;/h4&gt;开发一个综合的基准数据库和协议，以解决聚合物信息学领域中的标准化工作流程问题。&lt;h4&gt;方法&lt;/h4&gt;利用现有标记数据集和未标记的PI1M数据集，通过训练于现实聚合物上的神经网络生成约一百万个虚拟聚合物。开发了包括分位数随机森林、具有dropout的多层感知器、图神经网络和预训练的大型语言模型在内的机器学习模型。这些模型与多种聚合物表示方法相结合，以实现包括气体渗透率、热导率、玻璃转变温度、熔点、分数自由体积和密度在内的多种性质的预测、不确定性估计、模型可解释性和基于模板的聚合物聚合合成可行性。&lt;h4&gt;主要发现&lt;/h4&gt;POINT$^{2}$数据库可以作为一个宝贵的资源，用于聚合物发现和优化。&lt;h4&gt;结论&lt;/h4&gt;POINT$^{2}$数据库和协议的引入为聚合物信息学领域提供了一个解决标准化工作流程问题的方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：聚合物信息学的进步得益于机器学习技术的集成，使得聚合物性质的快速预测和高性能聚合物材料的发现成为可能。然而，该领域缺乏一个涵盖预测准确性、不确定性量化、机器学习可解释性和聚合物合成可行性的标准化工作流程。在本研究中，我们引入了POINT$^{2}$（POlymer INformatics Training and Testing），一个旨在解决这些关键挑战的综合基准数据库和协议。利用现有的标记数据集和未标记的PI1M数据集，通过训练于现实聚合物上的神经网络生成约一百万个虚拟聚合物，我们开发了一个包括分位数随机森林、具有dropout的多层感知器、图神经网络和预训练的大型语言模型在内的机器学习模型集合。这些模型与多种聚合物表示方法相结合，如Morgan、MACCS、RDKit、拓扑、原子对指纹和基于图的描述符，以实现包括气体渗透率、热导率、玻璃转变温度、熔点、分数自由体积和密度在内的多种性质的预测、不确定性估计、模型可解释性和基于模板的聚合物聚合合成可行性。POINT$^{2}$数据库可以作为聚合物信息学社区进行聚合物发现和优化的宝贵资源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advancement of polymer informatics has been significantly propelled bythe integration of machine learning (ML) techniques, enabling the rapidprediction of polymer properties and expediting the discovery ofhigh-performance polymeric materials. However, the field lacks a standardizedworkflow that encompasses prediction accuracy, uncertainty quantification, MLinterpretability, and polymer synthesizability. In this study, we introducePOINT$^{2}$ (POlymer INformatics Training and Testing), a comprehensivebenchmark database and protocol designed to address these critical challenges.Leveraging the existing labeled datasets and the unlabeled PI1M dataset, acollection of approximately one million virtual polymers generated via arecurrent neural network trained on the realistic polymers, we develop anensemble of ML models, including Quantile Random Forests, MultilayerPerceptrons with dropout, Graph Neural Networks, and pretrained large languagemodels. These models are coupled with diverse polymer representations such asMorgan, MACCS, RDKit, Topological, Atom Pair fingerprints, and graph-baseddescriptors to achieve property predictions, uncertainty estimations, modelinterpretability, and template-based polymerization synthesizability across aspectrum of properties, including gas permeability, thermal conductivity, glasstransition temperature, melting temperature, fractional free volume, anddensity. The POINT$^{2}$ database can serve as a valuable resource for thepolymer informatics community for polymer discovery and optimization.</description>
      <author>example@mail.com (Jiaxin Xu, Gang Liu, Ruilan Guo, Meng Jiang, Tengfei Luo)</author>
      <guid isPermaLink="false">2503.23491v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Systematic Relational Reasoning with Large Language and Reasoning Models</title>
      <link>http://arxiv.org/abs/2503.23487v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ACL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;大语言模型（LLMs）在系统性推理方面存在困难，尽管在特定任务上表现良好，但往往依赖于捷径而非真正的推理能力，导致它们在分布外样本上表现不佳。强化学习和思维链提示的培训策略被视为改进，但关于LRMs的潜力仍知之甚少。本文关注需要系统推理关系的任务，特别是关于定性空间和时间推理的任务，并发现LLMs和LRMs的整体表现不佳。&lt;h4&gt;背景&lt;/h4&gt;LLMs在系统性推理上存在挑战，它们的性能依赖于捷径而非真正的推理能力。&lt;h4&gt;目的&lt;/h4&gt;研究LLMs在系统推理关系上的表现，特别是关于定性空间和时间推理的任务。&lt;h4&gt;方法&lt;/h4&gt;通过控制问题实例的难度，精确测量模型的可泛化程度。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs和LRMs在上述任务上的整体表现不佳，尽管比随机机会要好。&lt;h4&gt;结论&lt;/h4&gt;LLMs和LRMs在需要系统性推理的任务上表现不佳。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have been found to struggle with systematicreasoning. Even on tasks where they appear to perform well, their performanceoften depends on shortcuts, rather than on genuine reasoning abilities, leadingthem to collapse on out-of-distribution examples. Post-training strategiesbased on reinforcement learning and chain-of-thought prompting have recentlybeen hailed as a step change. However, little is still known about thepotential of the resulting ``Large Reasoning Models'' (LRMs) beyond problemsolving in mathematics and programming, where finding genuineout-of-distribution problems can be difficult. In this paper, we focus on tasksthat require systematic reasoning about relational compositions, especially forqualitative spatial and temporal reasoning. These tasks allow us to control thedifficulty of problem instances, and measure in a precise way to what extentmodels can generalise. We find that that the considered LLMs and LRMs overallperform poorly overall, albeit better than random chance.</description>
      <author>example@mail.com (Irtaza Khalid, Amir Masoud Nourollah, Steven Schockaert)</author>
      <guid isPermaLink="false">2503.23487v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Can DeepSeek-V3 Reason Like a Surgeon? An Empirical Evaluation for Vision-Language Understanding in Robotic-Assisted Surgery</title>
      <link>http://arxiv.org/abs/2503.23130v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DeepSeek-V3在通用场景理解、问答和文本生成任务中表现出色，本研究探讨了其在机器人手术场景中的对话能力。&lt;h4&gt;背景&lt;/h4&gt;DeepSeek-V3是一种新兴的大型语言模型，具有高效训练范式和强大的推理能力。&lt;h4&gt;目的&lt;/h4&gt;研究DeepSeek-V3在机器人手术场景中的对话能力，重点关注单句问答、视觉问答和详细描述等任务。&lt;h4&gt;方法&lt;/h4&gt;使用EndoVis18和CholecT50等公开数据集及其对应的对话数据进行广泛评估。&lt;h4&gt;主要发现&lt;/h4&gt;DeepSeek-V3在提供特定提示时在手术器械和组织识别任务中表现良好，但在空间位置分析和手术动作理解方面存在显著局限性。在一般提示下，DeepSeek-V3无法有效分析全局手术概念，并无法提供对手术场景的详细洞察。&lt;h4&gt;结论&lt;/h4&gt;DeepSeek-V3在手术上下文中进行视觉语言任务前，需要针对手术特定数据集进行微调才能准备好使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; DeepSeek-V3, a recently emerging Large Language Model (LLM), demonstratesoutstanding performance in general scene understanding, question-answering(QA), and text generation tasks, owing to its efficient training paradigm andstrong reasoning capabilities. In this study, we investigate the dialoguecapabilities of DeepSeek-V3 in robotic surgery scenarios, focusing on taskssuch as Single Phrase QA, Visual QA, and Detailed Description. The SinglePhrase QA tasks further include sub-tasks such as surgical instrumentrecognition, action understanding, and spatial position analysis. We conductextensive evaluations using publicly available datasets, including EndoVis18and CholecT50, along with their corresponding dialogue data. Our comprehensiveevaluation results indicate that, when provided with specific prompts,DeepSeek-V3 performs well in surgical instrument and tissue recognition tasksHowever, DeepSeek-V3 exhibits significant limitations in spatial positionanalysis and struggles to understand surgical actions accurately. Additionally,our findings reveal that, under general prompts, DeepSeek-V3 lacks the abilityto effectively analyze global surgical concepts and fails to provide detailedinsights into surgical scenarios. Based on our observations, we argue that theDeepSeek-V3 is not ready for vision-language tasks in surgical contexts withoutfine-tuning on surgery-specific datasets.</description>
      <author>example@mail.com (Boyi Ma, Yanguang Zhao, Jie Wang, Guankun Wang, Kun Yuan, Tong Chen, Long Bai, Hongliang Ren)</author>
      <guid isPermaLink="false">2503.23130v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data</title>
      <link>http://arxiv.org/abs/2503.24129v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025, Project page:  https://dominik-schnaus.github.io/itsamatch/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了随着模型和数据集规模增加，视觉和语言嵌入变得越来越相似的现象，并探讨了无监督匹配的可能性。&lt;h4&gt;背景&lt;/h4&gt;基于柏拉图表示假设，视觉和语言嵌入随着模型和数据集规模增加而变得更加同质化，模态内的成对距离也变得更加相似。&lt;h4&gt;目的&lt;/h4&gt;研究无监督匹配在视觉和语言基础模型中的应用，以实现无监督的视觉和语言嵌入匹配。&lt;h4&gt;方法&lt;/h4&gt;将无监督匹配问题转化为二次分配问题，并引入了一种新的启发式算法。此外，还开发了一种技术来找到最优匹配问题，使得非平凡匹配的可能性很高。&lt;h4&gt;主要发现&lt;/h4&gt;通过在四个数据集上部署多种视觉和语言模型，研究发现，对于许多问题实例，视觉和语言表示可以在无监督的情况下进行匹配。&lt;h4&gt;结论&lt;/h4&gt;这一发现为将语义知识嵌入到其他模态中提供了可能性，且无需进行虚拟的标注。通过无监督分类器展示了非平凡的分类准确率，证明了这一概念的有效性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于柏拉图表示假设的新方法，通过将无监督匹配问题转化为二次分配问题，研究了视觉和语言基础模型的无监督匹配。研究发现，视觉和语言表示可以在无监督的情况下进行匹配，为将语义知识嵌入到其他模态中提供了可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The platonic representation hypothesis suggests that vision and languageembeddings become more homogeneous as model and dataset sizes increase. Inparticular, pairwise distances within each modality become more similar. Thissuggests that as foundation models mature, it may become possible to matchvision and language embeddings in a fully unsupervised fashion, i.e. withoutparallel data. We present the first feasibility study, and investigateconformity of existing vision and language foundation models in the context ofunsupervised, or "blind", matching. First, we formulate unsupervised matchingas a quadratic assignment problem and introduce a novel heuristic thatoutperforms previous solvers. We also develop a technique to find optimalmatching problems, for which a non-trivial match is very likely. Second, weconduct an extensive study deploying a range of vision and language models onfour datasets. Our analysis reveals that for many problem instances, vision andlanguage representations can be indeed matched without supervision. Thisfinding opens up the exciting possibility of embedding semantic knowledge intoother modalities virtually annotation-free. As a proof of concept, we showcasean unsupervised classifier, which achieves non-trivial classification accuracywithout any image-text annotation.</description>
      <author>example@mail.com (Dominik Schnaus, Nikita Araslanov, Daniel Cremers)</author>
      <guid isPermaLink="false">2503.24129v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>A QUBO Framework for Team Formation</title>
      <link>http://arxiv.org/abs/2503.23209v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了团队组建问题，旨在通过优化专家技能覆盖率和成本来形成团队。&lt;h4&gt;背景&lt;/h4&gt;团队组建问题涉及到一组专家和一项任务，每个专家有一组技能，任务需要某些技能。&lt;h4&gt;目的&lt;/h4&gt;目标是找到一个专家组合，在最大化技能覆盖率的同时，最小化与专家相关的成本。&lt;h4&gt;方法&lt;/h4&gt;提出了统一的团队组建公式，包括三种不同的成本函数和二次无约束二进制优化（QUBO）方法，并评估了两种通用的解决方案。使用图神经网络进行迁移学习，通过学习专家和技能的表示来实现。&lt;h4&gt;主要发现&lt;/h4&gt;基于QUBO公式的团队组建问题解决方案至少与现有的基线方法一样好。QUBO方法结合图神经网络能够有效地学习专家和技能的表示，实现跨实例的迁移学习。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在团队组建问题上具有良好的性能，并通过迁移学习提高了解决方案的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The team formation problem assumes a set of experts and a task, where eachexpert has a set of skills and the task requires some skills. The objective isto find a set of experts that maximizes coverage of the required skills whilesimultaneously minimizing the costs associated with the experts. Differentdefinitions of cost have traditionally led to distinct problem formulations andalgorithmic solutions. We introduce the unified TeamFormation formulation thatcaptures all cost definitions for team formation problems that balance taskcoverage and expert cost. Specifically, we formulate three TeamFormationvariants with different cost functions using quadratic unconstrained binaryoptimization (QUBO), and we evaluate two distinct general-purpose solutionmethods. We show that solutions based on the QUBO formulations of TeamFormationproblems are at least as good as those produced by established baselines.Furthermore, we show that QUBO-based solutions leveraging graph neural networkscan effectively learn representations of experts and skills to enable transferlearning, allowing node embeddings from one problem instance to be efficientlyapplied to another.</description>
      <author>example@mail.com (Karan Vombatkere, Evimaria Terzi, Theodoros Lappas)</author>
      <guid isPermaLink="false">2503.23209v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Learning Bijective Surface Parameterization for Inferring Signed Distance Functions from Sparse Point Clouds with Grid Deformation</title>
      <link>http://arxiv.org/abs/2503.23670v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Conference on Computer Vision and Pattern Recognition  (CVPR) 2025. Project page:https://takeshie.github.io/Bijective-SDF&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从稀疏点云中推断有符号距离函数（SDFs）的新方法，用于表面重建。&lt;h4&gt;背景&lt;/h4&gt;稀疏点云缺乏详细的几何信息，这对于学习连续场是必要的。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，本文提出了一种端到端学习动态变形网络来预测SDFs的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种双射表面参数化（BSP）方法，从局部块学习全局形状。具体来说，构建了从参数域到3D局部块的稀疏点双射映射，并将块集成到全局表面上。同时，引入了网格变形优化（GDO）来优化网格点的变形，进一步细化参数化表面。&lt;h4&gt;主要发现&lt;/h4&gt;在合成和真实扫描数据集上的实验结果表明，该方法显著优于当前最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;该方法在表面重建方面具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从稀疏点云中推断有符号距离函数（SDFs）仍然是表面重建中的一个挑战。关键在于稀疏点云中缺乏详细的几何信息，这对于学习连续场是必要的。为了解决这个问题，我们提出了一种新的方法，通过端到端学习动态变形网络来预测SDFs。为了从稀疏点参数化连续表面，我们提出了一种双射表面参数化（BSP），它从局部块学习全局形状。具体来说，我们为稀疏点从参数域到3D局部块构建了一个双射映射，并将块集成到全局表面上。同时，我们将网格变形优化（GDO）引入到表面逼近中，以优化网格点的变形并进一步细化参数化表面。在合成和真实扫描数据集上的实验结果表明，我们的方法在性能上显著优于当前最先进的方法。项目页面：https://takeshie.github.io/Bijective-SDF&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inferring signed distance functions (SDFs) from sparse point clouds remains achallenge in surface reconstruction. The key lies in the lack of detailedgeometric information in sparse point clouds, which is essential for learning acontinuous field. To resolve this issue, we present a novel approach thatlearns a dynamic deformation network to predict SDFs in an end-to-end manner.To parameterize a continuous surface from sparse points, we propose a bijectivesurface parameterization (BSP) that learns the global shape from local patches.Specifically, we construct a bijective mapping for sparse points from theparametric domain to 3D local patches, integrating patches into the globalsurface. Meanwhile, we introduce grid deformation optimization (GDO) into thesurface approximation to optimize the deformation of grid points and furtherrefine the parametric surfaces. Experimental results on synthetic and realscanned datasets demonstrate that our method significantly outperforms thecurrent state-of-the-art methods. Project page:https://takeshie.github.io/Bijective-SDF</description>
      <author>example@mail.com (Takeshi Noda, Chao Chen, Junsheng Zhou, Weiqi Zhang, Yu-Shen Liu, Zhizhong Han)</author>
      <guid isPermaLink="false">2503.23670v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>A Systematic Decade Review of Trip Route Planning with Travel Time Estimation based on User Preferences and Behavior</title>
      <link>http://arxiv.org/abs/2503.23486v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文系统地探讨了通过人工智能（AI）在自适应行程路线规划和旅行时间估计（TTE）方面的进展。&lt;h4&gt;背景&lt;/h4&gt;随着城市交通系统的日益复杂化，传统的导航方法往往难以适应动态用户偏好、实时交通状况和可扩展性要求。&lt;h4&gt;目的&lt;/h4&gt;研究旨在探索现有人工智能技术（如机器学习、强化学习和图神经网络）以及新兴方法（如元学习、可解释人工智能、生成人工智能和联邦学习）的贡献。&lt;h4&gt;方法&lt;/h4&gt;除了强调这些创新外，论文还确定了关键挑战，如伦理问题、计算可扩展性和有效数据集成，这些挑战必须解决以推进该领域。&lt;h4&gt;结论&lt;/h4&gt;论文最后提出了利用人工智能构建高效、透明和可持续导航系统的建议。&lt;h4&gt;翻译&lt;/h4&gt;本文系统地探讨了通过人工智能（AI）在自适应行程路线规划和旅行时间估计（TTE）方面的进展。随着城市交通系统的日益复杂化，传统的导航方法往往难以适应动态用户偏好、实时交通状况和可扩展性要求。研究旨在探索现有人工智能技术（如机器学习、强化学习和图神经网络）以及新兴方法（如元学习、可解释人工智能、生成人工智能和联邦学习）的贡献。除了强调这些创新外，论文还确定了关键挑战，如伦理问题、计算可扩展性和有效数据集成，这些挑战必须解决以推进该领域。论文最后提出了利用人工智能构建高效、透明和可持续导航系统的建议。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper systematically explores the advancements in adaptive trip routeplanning and travel time estimation (TTE) through Artificial Intelligence (AI).With the increasing complexity of urban transportation systems, traditionalnavigation methods often struggle to accommodate dynamic user preferences,real-time traffic conditions, and scalability requirements. This study exploresthe contributions of established AI techniques, including Machine Learning(ML), Reinforcement Learning (RL), and Graph Neural Networks (GNNs), alongsideemerging methodologies like Meta-Learning, Explainable AI (XAI), Generative AI,and Federated Learning. In addition to highlighting these innovations, thepaper identifies critical challenges such as ethical concerns, computationalscalability, and effective data integration, which must be addressed to advancethe field. The paper concludes with recommendations for leveraging AI to buildefficient, transparent, and sustainable navigation systems.</description>
      <author>example@mail.com (Nikil Jayasuriya, Deshan Sumanathilaka)</author>
      <guid isPermaLink="false">2503.23486v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>MSNGO: multi-species protein function annotation based on 3D protein structure and network propagation</title>
      <link>http://arxiv.org/abs/2503.23014v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MSNGO的多物种蛋白质功能预测模型，通过整合结构特征和网络传播方法，显著提高了预测准确率。&lt;h4&gt;背景&lt;/h4&gt;近年来，蛋白质功能预测利用AlphaFold2预测的高精度蛋白质结构，突破了序列特征的瓶颈，提高了预测准确率。然而，多物种蛋白质功能预测方法仍然处于使用PPI网络和序列特征的阶段。&lt;h4&gt;目的&lt;/h4&gt;为了解决多物种蛋白质功能预测中提供有效跨物种标签传播的问题，特别是对于蛋白质注释稀疏的物种。&lt;h4&gt;方法&lt;/h4&gt;我们采用图表示学习方法从蛋白质结构接触图中提取氨基酸表示，并使用图卷积池化模块训练结构模型以推导蛋白质级别的结构特征。在结合ESM-2的序列特征后，我们应用网络传播算法来聚合信息并更新异构图中的节点表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MSNGO在多物种蛋白质功能预测方面优于依赖序列特征和PPI网络的先前方法。&lt;h4&gt;结论&lt;/h4&gt;结构特征可以显著提高多物种蛋白质功能预测的准确率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：动机：近年来，蛋白质功能预测突破了序列特征的瓶颈，利用AlphaFold2预测的高精度蛋白质结构显著提高了预测准确性。尽管单物种蛋白质功能预测方法已经取得了显著的成就，但多物种蛋白质功能预测方法仍然处于使用PPI网络和序列特征的阶段。为解决此问题，我们提出了MSNGO模型，该模型整合了结构特征和网络传播方法。结果表明，使用结构特征可以显著提高多物种蛋白质功能预测的准确性。结果：我们采用图表示学习方法从蛋白质结构接触图中提取氨基酸表示，并使用图卷积池化模块训练结构模型以推导蛋白质级别的结构特征。结合ESM-2的序列特征后，我们应用网络传播算法来聚合信息并更新异构图中的节点表示。结果表明，MSNGO在多物种蛋白质功能预测方面优于依赖序列特征和PPI网络的先前方法。可用性：https://github.com/blingbell/MSNGO。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/blingbell/msngo&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivation: In recent years, protein function prediction has broken throughthe bottleneck of sequence features, significantly improving predictionaccuracy using high-precision protein structures predicted by AlphaFold2. Whilesingle-species protein function prediction methods have achieved remarkablesuccess, multi-species protein function prediction methods are still in thestage of using PPI networks and sequence features. Providing effectivecross-species label propagation for species with sparse protein annotationsremains a challenging issue. To address this problem, we propose the MSNGOmodel, which integrates structural features and network propagation methods.Our validation shows that using structural features can significantly improvethe accuracy of multi-species protein function prediction. Results: We employgraph representation learning techniques to extract amino acid representationsfrom protein structure contact maps and train a structural model using a graphconvolution pooling module to derive protein-level structural features. Afterincorporating the sequence features from ESM-2, we apply a network propagationalgorithm to aggregate information and update node representations within aheterogeneous network. The results demonstrate that MSNGO outperforms previousmulti-species protein function prediction methods that rely on sequencefeatures and PPI networks. Availability: https://github.com/blingbell/MSNGO.</description>
      <author>example@mail.com (Beibei Wang, Boyue Cui, Shiqu Chen, Xuan Wang, Yadong Wang, Junyi Li)</author>
      <guid isPermaLink="false">2503.23014v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Compositional Scene Understanding in Multimodal Generative Models</title>
      <link>http://arxiv.org/abs/2503.23125v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文评估了当前文本到图像模型和多模态视觉语言模型在处理视觉场景组合性方面的能力，并与人类参与者进行了比较。&lt;h4&gt;背景&lt;/h4&gt;视觉世界本质上是组合性的，由物体及其关系组成。计算机视觉系统需要反映和利用这种组合性来实现稳健和通用的场景理解。&lt;h4&gt;目的&lt;/h4&gt;评估当前文本到图像（如DALL-E 3）和多模态视觉语言模型（如GPT-4V、GPT-4o、Claude Sonnet 3.5、QWEN2-VL-72B和InternVL2.5-38B）的组合视觉处理能力，并与人类参与者进行比较。&lt;h4&gt;方法&lt;/h4&gt;通过比较这些模型在解决组合性和关系任务中的表现，并与人类参与者进行对比。&lt;h4&gt;主要发现&lt;/h4&gt;这些系统在解决组合性和关系任务方面显示出一些能力，比上一代多模态模型有显著改进，但性能仍然远低于人类参与者，特别是在涉及多个（&gt;5）物体和多种关系的复杂场景中。&lt;h4&gt;结论&lt;/h4&gt;这些结果强调了在视觉场景的组合理解方面取得进一步进步的必要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/andrewjlee0/evaluating_compositionality_vlms&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The visual world is fundamentally compositional. Visual scenes are defined bythe composition of objects and their relations. Hence, it is essential forcomputer vision systems to reflect and exploit this compositionality to achieverobust and generalizable scene understanding. While major strides have beenmade toward the development of general-purpose, multimodal generative models,including both text-to-image models and multimodal vision-language models, itremains unclear whether these systems are capable of accurately generating andinterpreting scenes involving the composition of multiple objects andrelations. In this work, we present an evaluation of the compositional visualprocessing capabilities in the current generation of text-to-image (DALL-E 3)and multimodal vision-language models (GPT-4V, GPT-4o, Claude Sonnet 3.5,QWEN2-VL-72B, and InternVL2.5-38B), and compare the performance of thesesystems to human participants. The results suggest that these systems displaysome ability to solve compositional and relational tasks, showing notableimprovements over the previous generation of multimodal models, but withperformance nevertheless well below the level of human participants,particularly for more complex scenes involving many ($&gt;5$) objects and multiplerelations. These results highlight the need for further progress towardcompositional understanding of visual scenes.</description>
      <author>example@mail.com (Shuhao Fu, Andrew Jun Lee, Anna Wang, Ida Momennejad, Trevor Bihl, Hongjing Lu, Taylor W. Webb)</author>
      <guid isPermaLink="false">2503.23125v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Multi-label classification for multi-temporal, multi-spatial coral reef condition monitoring using vision foundation model with adapter learning</title>
      <link>http://arxiv.org/abs/2503.23012v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了一种将DINOv2视觉基础模型与LoRA微调方法相结合的方法，用于珊瑚礁生态系统状况的多标签分类。&lt;h4&gt;背景&lt;/h4&gt;珊瑚礁生态系统面临气候变化和人类活动带来的严重威胁，而传统的深度学习模型在处理复杂的海底生态图像时难以达到高精度。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的珊瑚礁状况多标签分类方法，以促进珊瑚礁生态系统的监测、保护和管理工作。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了DINOv2视觉基础模型和LoRA微调方法，并利用了在泰国考陶15个潜水点收集的多时相水下调查图像，所有图像都按照公民科学保护计划中使用的通用标准进行了标注。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，DINOv2-LoRA模型实现了优越的准确性，匹配率为64.77%，高于最佳传统模型的60.34%。同时，使用LoRA将可训练参数从1.1亿减少到5.91百万。在不同时间和空间设置下的迁移学习实验突出了DINOv2-LoRA在不同季节和地点的卓越泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究首次探索了在多时相和多空间设置下对基础模型进行有效适应的方法，为珊瑚礁状况的分类提供了工具，并推动了珊瑚礁生态系统的研究和管理。&lt;h4&gt;翻译&lt;/h4&gt;Coral reef ecosystems provide essential ecosystem services, but face significant threats from climate change and human activities. Although advances in deep learning have enabled automatic classification of coral reef conditions, conventional deep models struggle to achieve high performance when processing complex underwater ecological images. Vision foundation models, known for their high accuracy and cross-domain generalizability, offer promising solutions. However, fine-tuning these models requires substantial computational resources and results in high carbon emissions. To address these challenges, adapter learning methods such as Low-Rank Adaptation (LoRA) have emerged as a solution. This study introduces an approach integrating the DINOv2 vision foundation model with the LoRA fine-tuning method. The approach leverages multi-temporal field images collected through underwater surveys at 15 dive sites at Koh Tao, Thailand, with all images labeled according to universal standards used in citizen science-based conservation programs. The experimental results demonstrate that the DINOv2-LoRA model achieved superior accuracy, with a match ratio of 64.77%, compared to 60.34% achieved by the best conventional model. Furthermore, incorporating LoRA reduced the trainable parameters from 1,100M to 5.91M. Transfer learning experiments conducted under different temporal and spatial settings highlight the exceptional generalizability of DINOv2-LoRA across different seasons and sites. This study is the first to explore the efficient adaptation of foundation models for multi-label classification of coral reef conditions under multi-temporal and multi-spatial settings. The proposed method advances the classification of coral reef conditions and provides a tool for monitoring, conserving, and managing coral reef ecosystems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Coral reef ecosystems provide essential ecosystem services, but facesignificant threats from climate change and human activities. Although advancesin deep learning have enabled automatic classification of coral reefconditions, conventional deep models struggle to achieve high performance whenprocessing complex underwater ecological images. Vision foundation models,known for their high accuracy and cross-domain generalizability, offerpromising solutions. However, fine-tuning these models requires substantialcomputational resources and results in high carbon emissions. To address thesechallenges, adapter learning methods such as Low-Rank Adaptation (LoRA) haveemerged as a solution. This study introduces an approach integrating the DINOv2vision foundation model with the LoRA fine-tuning method. The approachleverages multi-temporal field images collected through underwater surveys at15 dive sites at Koh Tao, Thailand, with all images labeled according touniversal standards used in citizen science-based conservation programs. Theexperimental results demonstrate that the DINOv2-LoRA model achieved superioraccuracy, with a match ratio of 64.77%, compared to 60.34% achieved by the bestconventional model. Furthermore, incorporating LoRA reduced the trainableparameters from 1,100M to 5.91M. Transfer learning experiments conducted underdifferent temporal and spatial settings highlight the exceptionalgeneralizability of DINOv2-LoRA across different seasons and sites. This studyis the first to explore the efficient adaptation of foundation models formulti-label classification of coral reef conditions under multi-temporal andmulti-spatial settings. The proposed method advances the classification ofcoral reef conditions and provides a tool for monitoring, conserving, andmanaging coral reef ecosystems.</description>
      <author>example@mail.com (Xinlei Shao, Hongruixuan Chen, Fan Zhao, Kirsty Magson, Jundong Chen, Peiran Li, Jiaqi Wang, Jun Sasaki)</author>
      <guid isPermaLink="false">2503.23012v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>LiM-Loc: Visual Localization with Dense and Accurate 3D Reference Maps Directly Corresponding 2D Keypoints to 3D LiDAR Point Clouds</title>
      <link>http://arxiv.org/abs/2503.23664v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于3D LiDAR和精确校准相机生成密集和准确3D参考地图的方法，以实现视觉定位的精确相机位姿估计。&lt;h4&gt;背景&lt;/h4&gt;现有的视觉定位方法通常依赖于大量的图像和精确的特征匹配，但由于特征匹配的不完美，3D参考地图往往稀疏且不准确。&lt;h4&gt;目的&lt;/h4&gt;提高视觉定位的准确性，通过减少3D重建中的误差。&lt;h4&gt;方法&lt;/h4&gt;结合图像和3D传感器，直接将3D LiDAR点云分配给关键点，生成密集和准确的3D参考地图，避免特征匹配，并使用宽域LiDAR点云进行2D-3D匹配误差的减少。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够避免特征匹配错误，对几乎所有关键点实现精确的3D重建，并使用室内和室外数据集证实了其提高了相机位姿估计的准确性。&lt;h4&gt;结论&lt;/h4&gt;结合3D LiDAR和精确相机的方法能够生成高质量的3D参考地图，从而提高视觉定位的精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual localization is to estimate the 6-DOF camera pose of a query image ina 3D reference map. We extract keypoints from the reference image and generatea 3D reference map with 3D reconstruction of the keypoints in advance. Weemphasize that the more keypoints in the 3D reference map and the smaller theerror of the 3D positions of the keypoints, the higher the accuracy of thecamera pose estimation. However, previous image-only methods require a hugenumber of images, and it is difficult to 3D-reconstruct keypoints without errordue to inevitable mismatches and failures in feature matching. As a result, the3D reference map is sparse and inaccurate. In contrast, accurate 3D referencemaps can be generated by combining images and 3D sensors. Recently, 3D-LiDARhas been widely used around the world. LiDAR, which measures a large space withhigh density, has become inexpensive. In addition, accurately calibratedcameras are also widely used, so images that record the external parameters ofthe camera without errors can be easily obtained. In this paper, we propose amethod to directly assign 3D LiDAR point clouds to keypoints to generate denseand accurate 3D reference maps. The proposed method avoids feature matching andachieves accurate 3D reconstruction for almost all keypoints. To estimatecamera pose over a wide area, we use the wide-area LiDAR point cloud to removepoints that are not visible to the camera and reduce 2D-3D correspondenceerrors. Using indoor and outdoor datasets, we apply the proposed method toseveral state-of-the-art local features and confirm that it improves theaccuracy of camera pose estimation.</description>
      <author>example@mail.com (Masahiko Tsuji, Hitoshi Niigaki, Ryuichi Tanida)</author>
      <guid isPermaLink="false">2503.23664v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Open-Vocabulary Semantic Segmentation with Uncertainty Alignment for Robotic Scene Understanding in Indoor Building Environments</title>
      <link>http://arxiv.org/abs/2503.23105v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  32 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉语言模型和大型语言模型的开放词汇场景语义分割和检测管道，用于辅助机器人在复杂建筑环境中进行自适应和直观的导航。&lt;h4&gt;背景&lt;/h4&gt;全球残疾人数量增加，对先进辅助技术提出了更高的需求，以改善他们的移动性和独立性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效导航复杂建筑环境的自主辅助机器人，如智能轮椅。&lt;h4&gt;方法&lt;/h4&gt;提出了一种'分割检测选择'框架，用于开放词汇场景分类，并利用视觉语言模型和大型语言模型来处理空间分割和语义识别。&lt;h4&gt;主要发现&lt;/h4&gt;现有的深度学习方法在处理开放词汇检测时存在困难，且大多数方法忽略了场景识别问题的不确定性，导致在模糊和复杂环境中的成功率较低。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法能够解决现有方法的不足，为辅助机器人在复杂环境中提供更准确的定位和导航能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The global rise in the number of people with physical disabilities, in partdue to improvements in post-trauma survivorship and longevity, has amplifiedthe demand for advanced assistive technologies to improve mobility andindependence. Autonomous assistive robots, such as smart wheelchairs, requirerobust capabilities in spatial segmentation and semantic recognition tonavigate complex built environments effectively. Place segmentation involvesdelineating spatial regions like rooms or functional areas, while semanticrecognition assigns semantic labels to these regions, enabling accuratelocalization to user-specific needs. Existing approaches often utilize deeplearning; however, these close-vocabulary detection systems struggle tointerpret intuitive and casual human instructions. Additionally, most existingmethods ignore the uncertainty of the scene recognition problem, leading to lowsuccess rates, particularly in ambiguous and complex environments. To addressthese challenges, we propose an open-vocabulary scene semantic segmentation anddetection pipeline leveraging Vision Language Models (VLMs) and Large LanguageModels (LLMs). Our approach follows a 'Segment Detect Select' framework foropen-vocabulary scene classification, enabling adaptive and intuitivenavigation for assistive robots in built environments.</description>
      <author>example@mail.com (Yifan Xu, Vineet Kamat, Carol Menassa)</author>
      <guid isPermaLink="false">2503.23105v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>The Marine Debris Forward-Looking Sonar Datasets</title>
      <link>http://arxiv.org/abs/2503.22880v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 12 figures, Oceans Brest 2025 camera readyu&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了海洋垃圾前视声纳数据集，包括三个不同设置和多个计算机视觉任务，旨在提供丰富多样的数据集，以促进水下机器人领域的研究。&lt;h4&gt;背景&lt;/h4&gt;声纳感知对于水下机器人至关重要，但目前受到AI系统能力限制，需要大量的训练数据集，而公开的声纳数据较少。&lt;h4&gt;目的&lt;/h4&gt;构建一个海洋垃圾前视声纳数据集，以支持水下机器人在不同环境下的视觉任务研究。&lt;h4&gt;方法&lt;/h4&gt;数据集包括水槽、转盘和淹没采石场三种不同设置，以及对象分类、对象检测、语义分割、块匹配和无监督学习等多种计算机视觉任务。&lt;h4&gt;主要发现&lt;/h4&gt;提供了数据集的详细描述、基本分析和一些任务的初步结果。&lt;h4&gt;结论&lt;/h4&gt;期望这个公开可用的数据集能为研究社区带来益处，并促进水下机器人领域的研究进展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：声纳传感对于水下机器人来说是基本的，但受限于AI系统的能力，这些系统需要大量的训练数据集。公开的声纳数据非常缺乏。本文提出了海洋垃圾前视声纳数据集，包含三种不同的设置（水槽、转盘、淹没采石场），增加了数据集的多样性，并涉及多个计算机视觉任务：对象分类、对象检测、语义分割、块匹配和无监督学习。我们提供了完整的数据集描述、基本分析和一些任务的初始结果。我们期待这个公开可用的数据集能为研究界带来益处，可访问https://doi.org/10.5281/zenodo.15101686。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sonar sensing is fundamental for underwater robotics, but limited bycapabilities of AI systems, which need large training datasets. Public data insonar modalities is lacking. This paper presents the Marine DebrisForward-Looking Sonar datasets, with three different settings (watertank,turntable, flooded quarry) increasing dataset diversity and multiple computervision tasks: object classification, object detection, semantic segmentation,patch matching, and unsupervised learning. We provide full dataset description,basic analysis and initial results for some tasks. We expect the researchcommunity will benefit from this dataset, which is publicly available athttps://doi.org/10.5281/zenodo.15101686</description>
      <author>example@mail.com (Matias Valdenegro-Toro, Deepan Chakravarthi Padmanabhan, Deepak Singh, Bilal Wehbe, Yvan Petillot)</author>
      <guid isPermaLink="false">2503.22880v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Introducing the Short-Time Fourier Kolmogorov Arnold Network: A Dynamic Graph CNN Approach for Tree Species Classification in 3D Point Clouds</title>
      <link>http://arxiv.org/abs/2503.23647v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为STFT-KAN的新型Kolmogorov-Arnold网络，通过整合短时傅里叶变换（STFT）来降低模型复杂度，并应用于树木物种分类。&lt;h4&gt;背景&lt;/h4&gt;准确分类树木物种对于生物多样性保护至关重要，而深度学习模型在3D点云分类领域表现出色，但其高复杂性限制了高效、低计算架构的发展。&lt;h4&gt;目的&lt;/h4&gt;降低模型复杂度，同时保持高性能，以实现高效、低计算架构的树木物种分类。&lt;h4&gt;方法&lt;/h4&gt;在轻量级DGCNN（liteDGCNN）架构中实现STFT-KAN，使用TLS数据对树木物种进行分类。同时，评估了结合MLP的混合架构。&lt;h4&gt;主要发现&lt;/h4&gt;STFT-KAN在降低参数数量的同时，与现有的KAN变体相比，在模型复杂度和性能之间取得了平衡。混合架构在参数数量减少50%和75%的情况下，性能与MLP模型相当。与PointMLP lite等最先进的3D点云学习方法相比，STFT-KAN在参数数量减少了87%的情况下，仍然取得了具有竞争力的结果。&lt;h4&gt;结论&lt;/h4&gt;STFT-KAN是一种有效降低模型复杂度的方法，能够实现高效、低计算架构的树木物种分类，并在参数数量减少的情况下保持竞争力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/said-ohamouddou/stft-kan-litedgcnn&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate classification of tree species based on Terrestrial Laser Scanning(TLS) and Airborne Laser Scanning (ALS) is essential for biodiversityconservation. While advanced deep learning models for 3D point cloudclassification have demonstrated strong performance in this domain, their highcomplexity often hinders the development of efficient, low-computationarchitectures. In this paper, we introduce STFT-KAN, a novel Kolmogorov-Arnoldnetwork that integrates the Short-Time Fourier Transform (STFT), which canreplace the standard linear layer with activation. We implemented STFT-KANwithin a lightweight version of DGCNN, called liteDGCNN, to classify treespecies using the TLS data. Our experiments show that STFT-KAN outperformsexisting KAN variants by effectively balancing model complexity and performancewith parameter count reduction, achieving competitive results compared toMLP-based models. Additionally, we evaluated a hybrid architecture thatcombines MLP in edge convolution with STFT-KAN in other layers, achievingcomparable performance to MLP models while reducing the parameter count by 50%and 75% compared to other KAN-based variants. Furthermore, we compared ourmodel to leading 3D point cloud learning approaches, demonstrating thatSTFT-KAN delivers competitive results compared to the state-of-the-art methodPointMLP lite with an 87% reduction in parameter count.</description>
      <author>example@mail.com (Said Ohamouddoua, Mohamed Ohamouddoub, Rafik Lasrib, Hanaa El Afiaa, Raddouane Chiheba, Abdellatif El Afiaa)</author>
      <guid isPermaLink="false">2503.23647v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Graph ODEs and Beyond: A Comprehensive Survey on Integrating Differential Equations with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2503.23167v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了图神经网络（GNN）和微分方程（DE）在近年来表现出的显著协同效应，这两个研究领域近年来发展迅速。&lt;h4&gt;背景&lt;/h4&gt;GNNs在处理图结构数据方面表现出强大的能力，而DEs则为建模时间和空间上的连续动态提供了一个原理性的框架。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供一个关于GNNs和DEs交叉研究领域的全面概述。&lt;h4&gt;方法&lt;/h4&gt;文章将分类现有方法，讨论其背后的原理，并强调它们在分子建模、交通预测和流行病传播等领域的应用。&lt;h4&gt;主要发现&lt;/h4&gt;文章识别了开放性挑战，并概述了未来研究的方向，以推进这一跨学科领域的发展。&lt;h4&gt;结论&lt;/h4&gt;本文为寻求理解和贡献GNNs与DEs融合的研究人员和从业者提供了一个资源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/emory-melody/awesome-graph-ndes&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) and differential equations (DEs) are two rapidlyadvancing areas of research that have shown remarkable synergy in recent years.GNNs have emerged as powerful tools for learning on graph-structured data,while differential equations provide a principled framework for modelingcontinuous dynamics across time and space. The intersection of these fields hasled to innovative approaches that leverage the strengths of both, enablingapplications in physics-informed learning, spatiotemporal modeling, andscientific computing. This survey aims to provide a comprehensive overview ofthe burgeoning research at the intersection of GNNs and DEs. We will categorizeexisting methods, discuss their underlying principles, and highlight theirapplications across domains such as molecular modeling, traffic prediction, andepidemic spreading. Furthermore, we identify open challenges and outline futureresearch directions to advance this interdisciplinary field. A comprehensivepaper list is provided at https://github.com/Emory-Melody/Awesome-Graph-NDEs.This survey serves as a resource for researchers and practitioners seeking tounderstand and contribute to the fusion of GNNs and DEs</description>
      <author>example@mail.com (Zewen Liu, Xiaoda Wang, Bohan Wang, Zijie Huang, Carl Yang, Wei Jin)</author>
      <guid isPermaLink="false">2503.23167v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Empowering Large Language Models with 3D Situation Awareness</title>
      <link>http://arxiv.org/abs/2503.23024v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法，旨在通过利用扫描轨迹和视觉语言模型自动生成情境感知数据集，以提高大型语言模型在3D场景理解中的应用。&lt;h4&gt;背景&lt;/h4&gt;由于大型语言模型在2D图像领域的成功，它们在3D场景理解中的应用成为了一个新的趋势。&lt;h4&gt;目的&lt;/h4&gt;解决当前基于大型语言模型的方法忽视自我中心视角，仅使用全局视角数据集的问题。&lt;h4&gt;方法&lt;/h4&gt;提出的方法包括：利用数据收集过程中的扫描轨迹、使用视觉语言模型生成高质量的文字描述和问答对，以及引入情境定位模块以预测观察者的位置和视角。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个基准测试中表现良好，有效提高了大型语言模型在3D场景中的情境意识，同时显著扩展了现有数据集并减少了人工努力。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地增强了大型语言模型在3D场景理解中的情境感知能力，为大型语言模型在3D场景理解中的应用提供了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Driven by the great success of Large Language Models (LLMs) in the 2D imagedomain, their applications in 3D scene understanding has emerged as a newtrend. A key difference between 3D and 2D is that the situation of anegocentric observer in 3D scenes can change, resulting in differentdescriptions (e.g., ''left" or ''right"). However, current LLM-based methodsoverlook the egocentric perspective and simply use datasets from a globalviewpoint. To address this issue, we propose a novel approach to automaticallygenerate a situation-aware dataset by leveraging the scanning trajectory duringdata collection and utilizing Vision-Language Models (VLMs) to producehigh-quality captions and question-answer pairs. Furthermore, we introduce asituation grounding module to explicitly predict the position and orientationof observer's viewpoint, thereby enabling LLMs to ground situation descriptionin 3D scenes. We evaluate our approach on several benchmarks, demonstratingthat our method effectively enhances the 3D situational awareness of LLMs whilesignificantly expanding existing datasets and reducing manual effort.</description>
      <author>example@mail.com (Zhihao Yuan, Yibo Peng, Jinke Ren, Yinghong Liao, Yatong Han, Chun-Mei Feng, Hengshuang Zhao, Guanbin Li, Shuguang Cui, Zhen Li)</author>
      <guid isPermaLink="false">2503.23024v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Nonhuman Primate Brain Tissue Segmentation Using a Transfer Learning Approach</title>
      <link>http://arxiv.org/abs/2503.22829v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用STU-Net和迁移学习的新方法，以提高非人类灵长类动物（NHPs）脑组织分割的准确性，尤其是在训练数据有限的情况下。&lt;h4&gt;背景&lt;/h4&gt;非人类灵长类动物由于与人类有密切的进化关系，是人类大脑功能和神经系统疾病研究的重要模型。然而，由于标注数据集稀缺、脑组织体积小、成像数据分辨率有限以及人脑和NHP脑部的解剖差异，准确分割NHP脑组织是一项挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法来解决上述挑战，提高NHP脑组织分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;使用STU-Net和迁移学习，利用人类脑MRI数据的知识来提高NHP脑MRI分割的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法有效地勾勒出复杂的组织边界，并捕捉到NHP脑部特有的精细解剖细节。该方法在分割小脑室结构（如豆状核和丘脑）方面表现出色，这些结构在有限的空间分辨率和组织对比度下难以分辨。分割结果达到了DSC超过0.88，IoU超过0.8，HD95低于7。&lt;h4&gt;结论&lt;/h4&gt;该方法为NHP多类别脑组织分割提供了一种稳健的方法，有望加速进化神经科学和与人类健康相关的神经系统疾病临床前研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：非人类灵长类动物（NHPs）由于其与人类的密切进化关系，是理解人类大脑功能和神经系统疾病的关键模型。由于标注的NHP脑MRI数据集稀缺、NHP脑体积小、可用成像数据的分辨率有限以及人脑与NHP脑部的解剖差异，准确分割NHP脑组织对于理解神经系统疾病至关重要，但也是一个挑战。为了解决这些挑战，我们提出了一种利用STU-Net和迁移学习的新方法，以利用从人类脑MRI数据中迁移的知识来提高NHP脑MRI的分割准确性，尤其是在训练数据有限的情况下。STU-Net和迁移学习的组合有效地勾勒出了复杂的组织边界，并捕捉到了NHP脑部特有的精细解剖细节。值得注意的是，我们的方法在分割小脑室结构（如豆状核和丘脑）方面表现出色，这些结构在有限的空间分辨率和组织对比度下难以分辨，并实现了DSC超过0.88，IoU超过0.8，HD95低于7。本研究介绍了一种用于NHP多类别脑组织分割的稳健方法，可能加速进化神经科学和与人类健康相关的神经系统疾病临床前研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Non-human primates (NHPs) serve as critical models for understanding humanbrain function and neurological disorders due to their close evolutionaryrelationship with humans. Accurate brain tissue segmentation in NHPs iscritical for understanding neurological disorders, but challenging due to thescarcity of annotated NHP brain MRI datasets, the small size of the NHP brain,the limited resolution of available imaging data and the anatomical differencesbetween human and NHP brains. To address these challenges, we propose a novelapproach utilizing STU-Net with transfer learning to leverage knowledgetransferred from human brain MRI data to enhance segmen-tation accuracy in theNHP brain MRI, particularly when training data is limited.The combination ofSTU-Net and transfer learning effectively delineates complex tissue boundariesand captures fine anatomical details specific to NHP brains. Notably, ourmethod demonstrated improvement in segmenting small subcortical structures suchas putamen and thalamus that are challenging to resolve with limited spatialresolution and tissue contrast, and achieved DSC of over 0.88, IoU over 0.8 andHD95 under 7. This study introduces a robust method for multi-class braintissue segmentation in NHPs, potentially accelerating research in evolutionaryneuroscience and preclinical studies of neurological disorders relevant tohuman health.</description>
      <author>example@mail.com (Zhen Lin, Hongyu Yuan, Richard Barcus, Qing Lyu, Sucheta Chakravarty, Megan E. Lipford, Carol A. Shively, Suzanne Craft, Mohammad Kawas, Jeongchul Kim, Christopher T. Whitlow)</author>
      <guid isPermaLink="false">2503.22829v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Prediction of 30-day hospital readmission with clinical notes and EHR information</title>
      <link>http://arxiv.org/abs/2503.23050v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了利用临床笔记和电子健康记录（EHR）结合预测患者30天内是否会再次入院的方法，并通过图神经网络（GNN）模型实现了较高的预测准确率。&lt;h4&gt;背景&lt;/h4&gt;高医院再入院率与患者成本和健康风险密切相关，因此开发能够支持临床医生预测患者短期内（如30天内）是否再次入院的有效预测模型至关重要。&lt;h4&gt;目的&lt;/h4&gt;旨在通过结合临床笔记和EHR数据，开发一个能够预测患者30天内是否再次入院的有效模型。&lt;h4&gt;方法&lt;/h4&gt;本文采用图神经网络（GNN）技术，将临床笔记和EHR数据作为图神经网络的节点，并解决EHR数据中不同类型信息的表示问题，同时探索了大型语言模型（LLM）来描述临床笔记。&lt;h4&gt;主要发现&lt;/h4&gt;模型实现了0.72的AUROC和66.7%的平衡准确率，表明结合多模态信息的重要性。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，结合临床笔记和EHR数据可以有效地预测患者再入院风险，这对于降低医疗成本和改善患者健康具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;摘要：高医院再入院率与患者显著的成本和健康风险相关。因此，开发能够支持临床医生在相对较短的时间内（例如，30天内）确定患者是否会再次入院的有效预测模型至关重要。如今，收集有关患者医院事件的既定信息（如电子健康记录-EHR）和非结构化信息（临床笔记）是可能的，所有这些信息都可能包含对预测模型相关的信息。然而，它们的集成具有挑战性。在这项工作中，我们探索了临床笔记和EHR的结合来预测30天内的医院再入院。我们解决了EHR数据中各种类型信息的表示问题，同时探索了LLM来描述临床笔记。我们将这两个信息来源作为图神经网络（GNN）的节点。我们的模型实现了0.72的AUROC和66.7%的平衡准确率，突出了结合多模态信息的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High hospital readmission rates are associated with significant costs andhealth risks for patients. Therefore, it is critical to develop predictivemodels that can support clinicians to determine whether or not a patient willreturn to the hospital in a relatively short period of time (e.g, 30-days).Nowadays, it is possible to collect both structured (electronic health records- EHR) and unstructured information (clinical notes) about a patient hospitalevent, all potentially containing relevant information for a predictive model.However, their integration is challenging. In this work we explore thecombination of clinical notes and EHRs to predict 30-day hospital readmissions.We address the representation of the various types of information available inthe EHR data, as well as exploring LLMs to characterize the clinical notes. Wecollect both information sources as the nodes of a graph neural network (GNN).Our model achieves an AUROC of 0.72 and a balanced accuracy of 66.7\%,highlighting the importance of combining the multimodal information.</description>
      <author>example@mail.com (Tiago Almeida, Plinio Moreno, Catarina Barata)</author>
      <guid isPermaLink="false">2503.23050v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>CA^2ST: Cross-Attention in Audio, Space, and Time for Holistic Video Recognition</title>
      <link>http://arxiv.org/abs/2503.23447v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages including appendix, TPAMI under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CA^2ST是一种基于Transformer的全面视频识别方法，通过结合空间、时间和音频专家，通过交叉注意力实现平衡的全面视频理解。&lt;h4&gt;背景&lt;/h4&gt;现有视频识别模型大多数缺乏对视频的平衡时空理解。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的两流架构CAST，并扩展为CAVA，以实现平衡的视频理解。&lt;h4&gt;方法&lt;/h4&gt;CAST使用RGB输入，通过Bottleneck Cross-Attention (B-CA)使空间和时专家交换信息并协同预测。CAVA通过集成音频专家进一步扩展CAST。&lt;h4&gt;主要发现&lt;/h4&gt;CAST在EPIC-KITCHENS-100、Something-Something-V2和Kinetics-400等基准数据集上表现出平衡的性能，CAVA在音频-视觉动作识别基准上也有良好表现。&lt;h4&gt;结论&lt;/h4&gt;CA^2ST通过交叉注意力结合空间、时间和音频专家，实现了平衡和全面的视频理解，并在多个数据集上验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose Cross-Attention in Audio, Space, and Time (CA^2ST), atransformer-based method for holistic video recognition. Recognizing actions invideos requires both spatial and temporal understanding, yet most existingmodels lack a balanced spatio-temporal understanding of videos. To addressthis, we propose a novel two-stream architecture, called Cross-Attention inSpace and Time (CAST), using only RGB input. In each layer of CAST, BottleneckCross-Attention (B-CA) enables spatial and temporal experts to exchangeinformation and make synergistic predictions. For holistic video understanding,we extend CAST by integrating an audio expert, forming Cross-Attention inVisual and Audio (CAVA). We validate the CAST on benchmarks with differentcharacteristics, EPIC-KITCHENS-100, Something-Something-V2, and Kinetics-400,consistently showing balanced performance. We also validate the CAVA onaudio-visual action recognition benchmarks, including UCF-101, VGG-Sound,KineticsSound, and EPIC-SOUNDS. With a favorable performance of CAVA acrossthese datasets, we demonstrate the effective information exchange amongmultiple experts within the B-CA module. In summary, CA^2ST combines CAST andCAVA by employing spatial, temporal, and audio experts through cross-attention,achieving balanced and holistic video understanding.</description>
      <author>example@mail.com (Jongseo Lee, Joohyun Chang, Dongho Lee, Jinwoo Choi)</author>
      <guid isPermaLink="false">2503.23447v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>PolypSegTrack: Unified Foundation Model for Colonoscopy Video Analysis</title>
      <link>http://arxiv.org/abs/2503.24108v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PolypSegTrack的新型基础模型，该模型能够联合处理结肠镜视频中的息肉检测、分割、分类和无监督跟踪。&lt;h4&gt;背景&lt;/h4&gt;早期检测、准确分割、分类和跟踪结肠镜下的息肉对于预防结直肠癌至关重要。现有的基于深度学习的结肠镜视频分析方法要么需要特定任务的微调，要么缺乏跟踪能力，或者依赖于特定领域的预训练。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需特定任务微调、具有跟踪能力且不依赖特定领域预训练的模型，以用于结肠镜视频分析。&lt;h4&gt;方法&lt;/h4&gt;PolypSegTrack模型利用了一种新的条件掩码损失，使得可以在具有像素级分割掩码或边界框注释的数据集上灵活训练。模型的无监督跟踪模块通过对象查询可靠地将息肉实例关联到帧之间，而不依赖于任何启发式方法。此外，模型使用在自然图像上无监督预训练的鲁棒视觉基础模型作为骨干网络。&lt;h4&gt;主要发现&lt;/h4&gt;在多个息肉基准数据集上的实验表明，PolypSegTrack在检测、分割、分类和跟踪方面显著优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;PolypSegTrack是一种有效的结肠镜视频分析工具，能够提高息肉检测和跟踪的准确性，为结直肠癌的早期诊断提供支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early detection, accurate segmentation, classification and tracking of polypsduring colonoscopy are critical for preventing colorectal cancer. Many existingdeep-learning-based methods for analyzing colonoscopic videos either requiretask-specific fine-tuning, lack tracking capabilities, or rely ondomain-specific pre-training. In this paper, we introduce\textit{PolypSegTrack}, a novel foundation model that jointly addresses polypdetection, segmentation, classification and unsupervised tracking incolonoscopic videos. Our approach leverages a novel conditional mask loss,enabling flexible training across datasets with either pixel-level segmentationmasks or bounding box annotations, allowing us to bypass task-specificfine-tuning. Our unsupervised tracking module reliably associates polypinstances across frames using object queries, without relying on anyheuristics. We leverage a robust vision foundation model backbone that ispre-trained unsupervisedly on natural images, thereby removing the need fordomain-specific pre-training. Extensive experiments on multiple polypbenchmarks demonstrate that our method significantly outperforms existingstate-of-the-art approaches in detection, segmentation, classification, andtracking.</description>
      <author>example@mail.com (Anwesa Choudhuri, Zhongpai Gao, Meng Zheng, Benjamin Planche, Terrence Chen, Ziyan Wu)</author>
      <guid isPermaLink="false">2503.24108v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>From Flatland to Space: Teaching Vision-Language Models to Perceive and Reason in 3D</title>
      <link>http://arxiv.org/abs/2503.22976v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://fudan-zvg.github.io/spar&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用空间相关图像数据提升视觉语言模型（VLM）空间感知能力的新方法。&lt;h4&gt;背景&lt;/h4&gt;现有VLM在处理复杂3D场景时存在空间感知问题，限制了它们推理复杂三维场景的能力。&lt;h4&gt;目的&lt;/h4&gt;通过利用空间相关图像数据，旨在提升VLM的空间感知能力。&lt;h4&gt;方法&lt;/h4&gt;1. 引入一种基于场景数据和3D地面真相的二维空间数据生成和注释流程；2. 构建了大规模数据集SPAR-7M，包含来自多个公共数据集的数千个场景；3. 设计了SPAR-Bench基准，用于更全面地评估空间能力；4. 在SPAR-7M和大规模二维数据集上训练模型。&lt;h4&gt;主要发现&lt;/h4&gt;训练模型在二维空间基准测试上取得了最先进的性能，在3D特定任务数据集上的微调也取得了有竞争力的结果。&lt;h4&gt;结论&lt;/h4&gt;提出的方法和数据集有效地提高了VLM的空间推理能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in LVLMs have improved vision-language understanding, butthey still struggle with spatial perception, limiting their ability to reasonabout complex 3D scenes. Unlike previous approaches that incorporate 3Drepresentations into models to improve spatial understanding, we aim to unlockthe potential of VLMs by leveraging spatially relevant image data. To this end,we introduce a novel 2D spatial data generation and annotation pipeline builtupon scene data with 3D ground-truth. This pipeline enables the creation of adiverse set of spatial tasks, ranging from basic perception tasks to morecomplex reasoning tasks. Leveraging this pipeline, we construct SPAR-7M, alarge-scale dataset generated from thousands of scenes across multiple publicdatasets. In addition, we introduce SPAR-Bench, a benchmark designed to offer amore comprehensive evaluation of spatial capabilities compared to existingspatial benchmarks, supporting both single-view and multi-view inputs. Trainingon both SPAR-7M and large-scale 2D datasets enables our models to achievestate-of-the-art performance on 2D spatial benchmarks. Further fine-tuning on3D task-specific datasets yields competitive results, underscoring theeffectiveness of our dataset in enhancing spatial reasoning.</description>
      <author>example@mail.com (Jiahui Zhang, Yurui Chen, Yanpeng Zhou, Yueming Xu, Ze Huang, Jilin Mei, Junhui Chen, Yu-Jie Yuan, Xinyue Cai, Guowei Huang, Xingyue Quan, Hang Xu, Li Zhang)</author>
      <guid isPermaLink="false">2503.22976v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>MIL vs. Aggregation: Evaluating Patient-Level Survival Prediction Strategies Using Graph-Based Learning</title>
      <link>http://arxiv.org/abs/2503.23042v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要讨论了肿瘤学家在使用全切片图像（WSI）预测癌症患者预后时遇到的挑战，并介绍了基于多个WSI数据集预测生存率的策略比较，包括独立处理WSI和使用多实例学习（MIL）选择最具有代表性的WSI。&lt;h4&gt;背景&lt;/h4&gt;肿瘤学家在治疗决策中依赖于多种数据，包括WSI，但由于肿瘤异质性和患者内部变异性，以及WSI分析复杂性，预测癌症患者预后是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在比较不同策略对WSI和患者级别的生存率预测的影响，以确定是否应使用所有WSI或只使用最具有代表性的WSI。&lt;h4&gt;方法&lt;/h4&gt;研究采用了MIL方法自动识别最相关的WSI，并评估了不同图神经网络（GNN）架构在这些策略下的表现。实验使用了MMIST-ccRCC数据集，该数据集包括透明细胞肾细胞癌（ccRCC）患者。&lt;h4&gt;主要发现&lt;/h4&gt;基于MIL的选择提高了准确性，表明选择最具有代表性的WSI有利于生存预测。&lt;h4&gt;结论&lt;/h4&gt;使用最具有代表性的WSI比使用所有WSI进行生存预测更准确。&lt;h4&gt;翻译&lt;/h4&gt;摘要讨论了肿瘤学家在治疗决策中依赖于多种数据，包括全切片图像（WSI），但预测癌症患者的预后由于肿瘤异质性和患者内部变异性以及WSI分析的复杂性而是一个挑战。该研究旨在通过比较不同的WSI和患者级别的生存率预测策略来回答是否应该使用所有WSI或识别出最具代表性的幻灯片。研究使用多实例学习（MIL）自动识别最相关的WSI，并评估了在这些策略下不同的图神经网络（GNN）架构。实验使用了包含透明细胞肾细胞癌（ccRCC）患者的MMIST-ccRCC数据集。结果显示，基于MIL的选择提高了准确性，表明选择最具代表性的幻灯片有助于生存预测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Oncologists often rely on a multitude of data, including whole-slide images(WSIs), to guide therapeutic decisions, aiming for the best patient outcome.However, predicting the prognosis of cancer patients can be a challenging taskdue to tumor heterogeneity and intra-patient variability, and the complexity ofanalyzing WSIs. These images are extremely large, containing billions ofpixels, making direct processing computationally expensive and requiringspecialized methods to extract relevant information. Additionally, multipleWSIs from the same patient may capture different tumor regions, some being moreinformative than others. This raises a fundamental question: Should we use allWSIs to characterize the patient, or should we identify the most representativeslide for prognosis? Our work seeks to answer this question by performing acomparison of various strategies for predicting survival at the WSI and patientlevel. The former treats each WSI as an independent sample, mimicking thestrategy adopted in other works, while the latter comprises methods to eitheraggregate the predictions of the several WSIs or automatically identify themost relevant slide using multiple-instance learning (MIL). Additionally, weevaluate different Graph Neural Networks architectures under these strategies.We conduct our experiments using the MMIST-ccRCC dataset, which comprisespatients with clear cell renal cell carcinoma (ccRCC). Our results show thatMIL-based selection improves accuracy, suggesting that choosing the mostrepresentative slide benefits survival prediction.</description>
      <author>example@mail.com (M Rita Verdelho, Alexandre Bernardino, Catarina Barata)</author>
      <guid isPermaLink="false">2503.23042v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>OmniMMI: A Comprehensive Multi-modal Interaction Benchmark in Streaming Video Contexts</title>
      <link>http://arxiv.org/abs/2503.22952v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear at CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了OmniMMI，一个针对Omni语言模型在流媒体视频环境中进行多模态交互的全面基准。&lt;h4&gt;背景&lt;/h4&gt;多模态语言模型（如GPT-4o）的快速发展推动了全语言模型的发展，这些模型旨在处理和积极响应连续的多模态数据流。&lt;h4&gt;目的&lt;/h4&gt;评估Omni语言模型在流媒体视频环境中的实际交互能力是一个挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了OmniMMI，包含超过1,121个视频和2,290个问题，解决现有视频基准中两个关键且未充分探索的挑战：流媒体视频理解和主动推理，涵盖六个不同的子任务。此外，还提出了一个新型框架，多模态复用建模（M4），以实现一个高效推理的流媒体模型。&lt;h4&gt;主要发现&lt;/h4&gt;OmniMMI涵盖了广泛的视频和问题，针对流媒体视频理解和主动推理进行了评估。&lt;h4&gt;结论&lt;/h4&gt;OmniMMI为Omni语言模型在流媒体视频环境中的多模态交互提供了一个有价值的基准。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着多模态语言模型（如GPT-4o）的快速进步，全语言模型的发展得到了推动，这些模型旨在处理和积极响应连续的多模态数据流。尽管它们具有潜力，但在流媒体视频环境中评估它们的实际交互能力仍然是一个巨大的挑战。在这项工作中，我们介绍了OmniMMI，这是一个针对Omni语言模型在流媒体视频环境中进行多模态交互的全面基准。OmniMMI包含超过1,121个视频和2,290个问题，解决了现有视频基准中两个关键且未充分探索的挑战：流媒体视频理解和主动推理，涉及六个不同的子任务。此外，我们还提出了一种新型框架，多模态复用建模（M4），旨在实现一个高效推理的流媒体模型，该模型能够同时观察、聆听并生成。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of multi-modal language models (MLLMs) like GPT-4o haspropelled the development of Omni language models, designed to process andproactively respond to continuous streams of multi-modal data. Despite theirpotential, evaluating their real-world interactive capabilities in streamingvideo contexts remains a formidable challenge. In this work, we introduceOmniMMI, a comprehensive multi-modal interaction benchmark tailored forOmniLLMs in streaming video contexts. OmniMMI encompasses over 1,121 videos and2,290 questions, addressing two critical yet underexplored challenges inexisting video benchmarks: streaming video understanding and proactivereasoning, across six distinct subtasks. Moreover, we propose a novelframework, Multi-modal Multiplexing Modeling (M4), designed to enable aninference-efficient streaming model that can see, listen while generating.</description>
      <author>example@mail.com (Yuxuan Wang, Yueqian Wang, Bo Chen, Tong Wu, Dongyan Zhao, Zilong Zheng)</author>
      <guid isPermaLink="false">2503.22952v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>AuditVotes: A Framework Towards More Deployable Certified Robustness for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2503.22998v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了AuditVotes框架，旨在解决图神经网络（GNN）在自适应攻击下的鲁棒性问题，同时提高数据质量和预测一致性。&lt;h4&gt;背景&lt;/h4&gt;尽管图神经网络（GNN）取得了进展，但自适应攻击对其鲁棒性仍构成挑战。基于随机平滑的认证鲁棒性提供了模型预测在特定范围内对抗扰动下的稳定性保证，但现有方法在精度和鲁棒性之间存在权衡。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架，在GNN中同时实现高清洁精度和认证鲁棒精度。&lt;h4&gt;方法&lt;/h4&gt;AuditVotes框架结合了随机平滑、增强和条件平滑。增强作为预处理步骤，去噪随机图，提高数据质量和清洁精度。条件平滑作为后处理步骤，使用滤波函数选择性计数投票，过滤低质量预测，提高投票一致性。&lt;h4&gt;主要发现&lt;/h4&gt;AuditVotes显著提高了清洁精度、认证鲁棒性和经验鲁棒性，同时保持高计算效率。与基准随机平滑相比，AuditVotes在Cora-ML数据集上攻击者可以任意插入20条边的情况下，将清洁精度提高了437.1%，认证精度提高了409.3%。&lt;h4&gt;结论&lt;/h4&gt;AuditVotes为在现实世界中部署认证鲁棒的GNN迈出了重要一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite advancements in Graph Neural Networks (GNNs), adaptive attackscontinue to challenge their robustness. Certified robustness based onrandomized smoothing has emerged as a promising solution, offering provableguarantees that a model's predictions remain stable under adversarialperturbations within a specified range. However, existing methods face acritical trade-off between accuracy and robustness, as achieving strongerrobustness requires introducing greater noise into the input graph. Thisexcessive randomization degrades data quality and disrupts predictionconsistency, limiting the practical deployment of certifiably robust GNNs inreal-world scenarios where both accuracy and robustness are essential. Toaddress this challenge, we propose \textbf{AuditVotes}, the first framework toachieve both high clean accuracy and certifiably robust accuracy for GNNs. Itintegrates randomized smoothing with two key components,\underline{au}gmentation and con\underline{dit}ional smoothing, aiming toimprove data quality and prediction consistency. The augmentation, acting as apre-processing step, de-noises the randomized graph, significantly improvingdata quality and clean accuracy. The conditional smoothing, serving as apost-processing step, employs a filtering function to selectively count votes,thereby filtering low-quality predictions and improving voting consistency.Extensive experimental results demonstrate that AuditVotes significantlyenhances clean accuracy, certified robustness, and empirical robustness whilemaintaining high computational efficiency. Notably, compared to baselinerandomized smoothing, AuditVotes improves clean accuracy by $437.1\%$ andcertified accuracy by $409.3\%$ when the attacker can arbitrarily insert $20$edges on the Cora-ML datasets, representing a substantial step toward deployingcertifiably robust GNNs in real-world applications.</description>
      <author>example@mail.com (Yuni Lai, Yulin Zhu, Yixuan Sun, Yulun Wu, Bin Xiao, Gaolei Li, Jianhua Li, Kai Zhou)</author>
      <guid isPermaLink="false">2503.22998v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>A point cloud reconstruction method based on uncertainty feature enhancement for aerodynamic shape optimization</title>
      <link>http://arxiv.org/abs/2503.23082v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的点云自动编码器架构AE-BUFE，用于通过分析表面网格点之间的变形关系的不确定性来获得3D飞机的精确和高效的一般表示，以提高气动优化的成本效益。&lt;h4&gt;背景&lt;/h4&gt;形状表示的精度和设计空间的维度显著影响气动优化的成本和结果。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的点云自动编码器架构，以实现高效和精确的3D飞机形状特征表示，并评估其优化过程的成本效益。&lt;h4&gt;方法&lt;/h4&gt;提出了基于不确定指数的特征增强模块和点云自动编码器模块的深度学习架构，并通过与现有点云自动编码器架构和POD线性降维方法进行比较来评估其效率。&lt;h4&gt;主要发现&lt;/h4&gt;新的架构显著提高了低维潜在空间的提取效果，并通过基于AE-BUFE参数化方法的SBO优化框架完成了考虑体积和力矩约束的多目标气动优化设计。&lt;h4&gt;结论&lt;/h4&gt;该方法在跨音速和超声速条件下提高了气动性能，同时确保了起飞和着陆性能，验证了其效率和工程实用性。&lt;h4&gt;翻译&lt;/h4&gt;The precision of shape representation and the dimensionality of the designspace significantly influence the cost and outcomes of aerodynamic optimization. The design space can be represented more compactly by maintaining geometric precision while reducing dimensions, hence enhancing the cost-effectiveness of the optimization process. This research presents a new point cloud autoencoder architecture, called AE-BUFE, designed to attain efficient and precise generalized representations of 3D aircraft through uncertainty analysis of the deformation relationships among surface gridpoints. The deep learning architecture consists of two components: the uncertainty index-based feature enhancement module and the point cloud autoencoder module. It learns the shape features of the point cloud geometric representation to establish a low-dimensional latent space. To assess and evaluate the efficiency of the method, a comparison was conducted with the prevailing point cloud autoencoder architecture and the proper orthogonal decomposition (POD) linear dimensionality reduction method under conditions of complex shape deformation. The results showed that the new architecture significantly improved the extraction effect of the low-dimensional latent space. Then, we developed the SBO optimization framework based on the AE-BUFE parameterization method and completed a multi-objective aerodynamic optimization design for a wide-speed-range vehicle considering volume and moment constraints. While ensuring the take-off and landing performance, the aerodynamic performance is improved at transonic and hypersonic conditions, which verifies the efficiency and engineering practicability of this method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The precision of shape representation and the dimensionality of the designspace significantly influence the cost and outcomes of aerodynamicoptimization. The design space can be represented more compactly by maintaininggeometric precision while reducing dimensions, hence enhancing thecost-effectiveness of the optimization process. This research presents a newpoint cloud autoencoder architecture, called AE-BUFE, designed to attainefficient and precise generalized representations of 3D aircraft throughuncertainty analysis of the deformation relationships among surface gridpoints. The deep learning architecture consists of two components: theuncertainty index-based feature enhancement module and the point cloudautoencoder module. It learns the shape features of the point cloud geometricrepresentation to establish a low-dimensional latent space. To assess andevaluate the efficiency of the method, a comparison was conducted with theprevailing point cloud autoencoder architecture and the proper orthogonaldecomposition (POD) linear dimensionality reduction method under conditions ofcomplex shape deformation. The results showed that the new architecturesignificantly improved the extraction effect of the low-dimensional latentspace. Then, we developed the SBO optimization framework based on the AE-BUFEparameterization method and completed a multi-objective aerodynamicoptimization design for a wide-speed-range vehicle considering volume andmoment constraints. While ensuring the take-off and landing performance, theaerodynamic performance is improved at transonic and hypersonic conditions,which verifies the efficiency and engineering practicability of this method.</description>
      <author>example@mail.com (Junlin Li, Yang Zhang, Bo Pang, Junqiang Bai, Jiakuan Xu)</author>
      <guid isPermaLink="false">2503.23082v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>SuperEIO: Self-Supervised Event Feature Learning for Event Inertial Odometry</title>
      <link>http://arxiv.org/abs/2503.22963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SuperEIO的新型框架，用于实现基于事件和IMU测量的里程计。该框架利用基于学习的单事件检测和图神经网络进行事件描述符匹配，以应对高速度运动和挑战性的光照条件。&lt;h4&gt;背景&lt;/h4&gt;事件相机异步输出低延迟事件流，适用于高速运动和复杂光照条件下的状态估计。然而，与基于帧的相机相比，事件相机在运动依赖性方面对鲁棒的事件特征检测和匹配提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个鲁棒的基于事件和IMU测量的里程计系统，用于在资源受限平台上实现低延迟和实时操作。&lt;h4&gt;方法&lt;/h4&gt;SuperEIO框架采用卷积神经网络进行事件特征检测，并利用图神经网络实现事件描述符匹配。此外，使用TensorRT加速深度网络推理，以确保低延迟处理。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，SuperEIO在多个公共数据集上表现出更高的精度和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;SuperEIO框架为事件相机辅助的状态估计提供了一种有效的解决方案，并开源了相关代码以促进该领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;Event cameras asynchronously output low-latency event streams, promising for state estimation in high-speed motion and challenging lighting conditions. As opposed to frame-based cameras, the motion-dependent nature of event cameras presents persistent challenges in achieving robust event feature detection and matching. In recent years, learning-based approaches have demonstrated superior robustness over traditional handcrafted methods in feature detection and matching, particularly under aggressive motion and HDR scenarios. In this paper, we propose SuperEIO, a novel framework that leverages the learning-based event-only detection and IMU measurements to achieve event-inertial odometry. Our event-only feature detection employs a convolutional neural network under continuous event streams. Moreover, our system adopts the graph neural network to achieve event descriptor matching for loop closure. The proposed system utilizes TensorRT to accelerate the inference speed of deep networks, which ensures low-latency processing and robust real-time operation on resource-limited platforms. Besides, we evaluate our method extensively on multiple public datasets, demonstrating its superior accuracy and robustness compared to other state-of-the-art event-based methods. We have also open-sourced our pipeline to facilitate research in the field: https://github.com/arclab-hku/SuperEIO.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/arclab-hku/supereio&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event cameras asynchronously output low-latency event streams, promising forstate estimation in high-speed motion and challenging lighting conditions. Asopposed to frame-based cameras, the motion-dependent nature of event cameraspresents persistent challenges in achieving robust event feature detection andmatching. In recent years, learning-based approaches have demonstrated superiorrobustness over traditional handcrafted methods in feature detection andmatching, particularly under aggressive motion and HDR scenarios. In thispaper, we propose SuperEIO, a novel framework that leverages the learning-basedevent-only detection and IMU measurements to achieve event-inertial odometry.Our event-only feature detection employs a convolutional neural network undercontinuous event streams. Moreover, our system adopts the graph neural networkto achieve event descriptor matching for loop closure. The proposed systemutilizes TensorRT to accelerate the inference speed of deep networks, whichensures low-latency processing and robust real-time operation onresource-limited platforms. Besides, we evaluate our method extensively onmultiple public datasets, demonstrating its superior accuracy and robustnesscompared to other state-of-the-art event-based methods. We have alsoopen-sourced our pipeline to facilitate research in the field:https://github.com/arclab-hku/SuperEIO.</description>
      <author>example@mail.com (Peiyu Chen, Fuling Lin, Weipeng Guan, Peng Lu)</author>
      <guid isPermaLink="false">2503.22963v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Graph Kolmogorov-Arnold Networks for Multi-Cancer Classification and Biomarker Identification, An Interpretable Multi-Omics Approach</title>
      <link>http://arxiv.org/abs/2503.22939v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MOGKAN的深度学习模型，用于整合多组学数据，以实现对31种癌症类型的准确分类和生物解释。&lt;h4&gt;背景&lt;/h4&gt;多组学数据整合在精准医学中是一个重大挑战，需要先进的计算方法来准确进行疾病分类和生物解释。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够准确和可解释地跨31种癌症类型进行癌症分类的深度学习模型。&lt;h4&gt;方法&lt;/h4&gt;MOGKAN结合了差异表达分析、DESeq2、LIMMA和LASSO回归，以减少多组学数据的维度，同时保留相关的生物特征。模型架构基于Kolmogorov-Arnold定理原理，使用可训练的单变量函数来增强可解释性和特征分析。&lt;h4&gt;主要发现&lt;/h4&gt;MOGKAN实现了96.28%的分类准确率，并且与卷积神经网络（CNNs）和图神经网络（GNNs）相比，实验变异性降低，标准差减少了1.58至7.30个百分点。通过基因本体（GO）和京都基因与基因组百科全书（KEGG）富集分析验证了MOGKAN识别的生物标志物是癌症相关标志物。&lt;h4&gt;结论&lt;/h4&gt;MOGKAN能够通过检测磷脂酰肌醇结合物质和调节鞘脂细胞过程来揭示分子肿瘤发生机制，将多组学数据与基于图的深度学习相结合，展示了优越的预测性能和可解释性，有潜力将复杂的多组学数据转化为可临床操作的癌症诊断。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为MOGKAN的深度学习模型，该模型整合了信使RNA、微RNA序列和DNA甲基化数据，以及蛋白质-蛋白质相互作用（PPI）网络，用于31种癌症类型的准确和可解释的癌症分类。MOGKAN采用了一种混合方法，结合差异表达分析、DESeq2、线性模型微阵列（LIMMA）和最小绝对收缩和选择算子（LASSO）回归，以减少多组学数据的维度，同时保留相关的生物特征。该模型架构基于Kolmogorov-Arnold定理原理，使用可训练的单变量函数来增强可解释性和特征分析。MOGKAN实现了96.28%的分类准确率，并证明了低实验变异性，与卷积神经网络（CNNs）和图神经网络（GNNs）相比，标准差降低了1.58至7.30个百分点。通过基因本体（GO）和京都基因与基因组百科全书（KEGG）富集分析验证了MOGKAN识别的生物标志物是癌症相关标志物。所提出的模型能够通过检测磷脂酰肌醇结合物质和调节鞘脂细胞过程来揭示分子肿瘤发生机制。通过整合多组学数据与基于图的深度学习，我们提出的方法展示了优越的预测性能和可解释性，有潜力将复杂的多组学数据转化为可临床操作的癌症诊断。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of multi-omics data presents a major challenge in precisionmedicine, requiring advanced computational methods for accurate diseaseclassification and biological interpretation. This study introduces theMulti-Omics Graph Kolmogorov-Arnold Network (MOGKAN), a deep learning modelthat integrates messenger RNA, micro RNA sequences, and DNA methylation datawith Protein-Protein Interaction (PPI) networks for accurate and interpretablecancer classification across 31 cancer types. MOGKAN employs a hybrid approachcombining differential expression with DESeq2, Linear Models for Microarray(LIMMA), and Least Absolute Shrinkage and Selection Operator (LASSO) regressionto reduce multi-omics data dimensionality while preserving relevant biologicalfeatures. The model architecture is based on the Kolmogorov-Arnold theoremprinciple, using trainable univariate functions to enhance interpretability andfeature analysis. MOGKAN achieves classification accuracy of 96.28 percent anddemonstrates low experimental variability with a standard deviation that isreduced by 1.58 to 7.30 percents compared to Convolutional Neural Networks(CNNs) and Graph Neural Networks (GNNs). The biomarkers identified by MOGKANhave been validated as cancer-related markers through Gene Ontology (GO) andKyoto Encyclopedia of Genes and Genomes (KEGG) enrichment analysis. Theproposed model presents an ability to uncover molecular oncogenesis mechanismsby detecting phosphoinositide-binding substances and regulating sphingolipidcellular processes. By integrating multi-omics data with graph-based deeplearning, our proposed approach demonstrates superior predictive performanceand interpretability that has the potential to enhance the translation ofcomplex multi-omics data into clinically actionable cancer diagnostics.</description>
      <author>example@mail.com (Fadi Alharbi, Nishant Budhiraja, Aleksandar Vakanski, Boyu Zhang, Murtada K. Elbashir, Mohanad Mohammed)</author>
      <guid isPermaLink="false">2503.22939v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>HumanAesExpert: Advancing a Multi-Modality Foundation Model for Human Image Aesthetic Assessment</title>
      <link>http://arxiv.org/abs/2503.23907v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对人类图像美学评估（HIAA）的全面实现框架，并介绍了相关数据集、模型和实验结果。&lt;h4&gt;背景&lt;/h4&gt;图像美学评估是一个长期且具有挑战性的研究领域，而其子集人类图像美学评估（HIAA）在社交媒体、人工智能工作流程和相关领域中广泛应用，但研究相对较少。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一研究空白，本文旨在开发一个适用于HIAA的全面实现框架。&lt;h4&gt;方法&lt;/h4&gt;首先，构建了一个名为HumanBeauty的数据集，包含108k张高质量的人像图像和人工标注。其中，50K张图像通过严格的整理过程人工收集并标注，使用创新的12维美学标准，其余58K张图像从公共数据集中系统筛选。基于此数据集，提出了HumanAesExpert视觉语言模型，该模型通过结合语言建模（LM）和回归头，并引入专家头以整合美学子维度的知识。此外，还引入了MetaVoter，以聚合所有三个头的评分，从而提高评估精度。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，HumanAesExpert模型在HIAA方面的表现优于其他最先进模型。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和模型为HIAA领域的发展做出了贡献，并公开了数据集、模型和代码以促进该领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图像美学评估（IAA）是一项长期且具有挑战性的研究任务。然而，其子集人类图像美学评估（HIAA）却鲜有研究，尽管HIAA在社交媒体、人工智能工作流程和相关领域中得到了广泛应用。为了填补这一研究空白，我们的工作开创了一个针对HIAA的整体实现框架。具体来说，我们引入了HumanBeauty，这是第一个专门为HIAA构建的数据集，包含108k张高质量的人像图像和人工标注。为了实现全面和细粒度HIAA，通过严格的整理过程人工收集了50K张人像图像，并利用我们开创性的12维美学标准进行标注，其余58K张具有整体美学标签的图像从公共数据集中系统筛选。基于HumanBeauty数据库，我们提出了HumanAesExpert，这是一种用于人类图像美学评估的强大视觉语言模型。我们创新性地设计了一个专家头，以结合人类对美学子维度的知识，并联合利用语言建模（LM）和回归头。这种方法使我们的模型在整体和细粒度HIAA方面都表现出色。此外，我们还引入了MetaVoter，它聚合了所有三个头的评分，以有效地平衡每个头的功能，从而实现提高评估精度。广泛的实验表明，我们的HumanAesExpert模型在HIAA方面的表现比其他最先进模型要好得多。我们的数据集、模型和代码已公开发布，以促进HIAA社区的发展。项目网页：https://humanaesexpert.github.io/HumanAesExpert/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image Aesthetic Assessment (IAA) is a long-standing and challenging researchtask. However, its subset, Human Image Aesthetic Assessment (HIAA), has beenscarcely explored, even though HIAA is widely used in social media, AIworkflows, and related domains. To bridge this research gap, our work pioneersa holistic implementation framework tailored for HIAA. Specifically, weintroduce HumanBeauty, the first dataset purpose-built for HIAA, whichcomprises 108k high-quality human images with manual annotations. To achievecomprehensive and fine-grained HIAA, 50K human images are manually collectedthrough a rigorous curation process and annotated leveraging our trailblazing12-dimensional aesthetic standard, while the remaining 58K with overallaesthetic labels are systematically filtered from public datasets. Based on theHumanBeauty database, we propose HumanAesExpert, a powerful Vision LanguageModel for aesthetic evaluation of human images. We innovatively design anExpert head to incorporate human knowledge of aesthetic sub-dimensions whilejointly utilizing the Language Modeling (LM) and Regression head. This approachempowers our model to achieve superior proficiency in both overall andfine-grained HIAA. Furthermore, we introduce a MetaVoter, which aggregatesscores from all three heads, to effectively balance the capabilities of eachhead, thereby realizing improved assessment precision. Extensive experimentsdemonstrate that our HumanAesExpert models deliver significantly betterperformance in HIAA than other state-of-the-art models. Our datasets, models,and codes are publicly released to advance the HIAA community. Project webpage:https://humanaesexpert.github.io/HumanAesExpert/</description>
      <author>example@mail.com (Zhichao Liao, Xiaokun Liu, Wenyu Qin, Qingyu Li, Qiulin Wang, Pengfei Wan, Di Zhang, Long Zeng, Pingfa Feng)</author>
      <guid isPermaLink="false">2503.23907v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Communication-Efficient and Personalized Federated Foundation Model Fine-Tuning via Tri-Matrix Adaptation</title>
      <link>http://arxiv.org/abs/2503.23869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CE-LoRA的通信高效联邦学习自适应方法，用于解决预训练基础模型微调中的通信成本高和数据异构导致的模型性能不佳问题。&lt;h4&gt;背景&lt;/h4&gt;在联邦学习中，客户端间的数据异构性导致高通信成本和模型性能不佳。&lt;h4&gt;目的&lt;/h4&gt;降低通信成本，提高模型性能，并保护数据隐私。&lt;h4&gt;方法&lt;/h4&gt;采用三因子分解低秩自适应方法，结合个性化模型参数聚合。引入小尺寸稠密矩阵进行LoRA参数分解，考虑客户端在训练数据集和模型参数空间中的相似性，学习个性化的模型聚合权重。&lt;h4&gt;主要发现&lt;/h4&gt;CE-LoRA显著降低了通信开销，在非独立同分布数据条件下提高了性能，并有效提升了数据隐私保护，减轻了基于梯度的数据重建攻击。&lt;h4&gt;结论&lt;/h4&gt;CE-LoRA是一种有效的联邦学习自适应方法，能够提高模型性能并保护数据隐私。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In federated learning, fine-tuning pre-trained foundation models posessignificant challenges, particularly regarding high communication cost andsuboptimal model performance due to data heterogeneity between the clients. Toaddress these issues, this paper introduces communication-efficient federatedLoRA adaption (CE-LoRA), a method that employs a tri-factorization low-rankadaptation approach with personalized model parameter aggregation. We firstpresents a novel LoRA parameter factorization by introducing a small-size densematrix, which can significantly reduce the communication cost and achievecomparable empirical performance than transferring the low-rank parametermatrix used by existing methods. Without violating data privacy, the serverconsiders the client similarity in both training dataset and model parameterspace, and learns personalized weights for model aggregation. Our experimentson various LLM and VLM fine-tuning tasks demonstrate that CE-LoRA not onlysignificantly reduces communication overhead but also improves performanceunder not independently and identically distributed data conditions. Inaddition, CE-LoRA improves data privacy protection, effectively mitigatinggradient-based data reconstruction attacks.</description>
      <author>example@mail.com (Yongle Li, Bo Liu, Sheng Huang, ZHeng ZHang, Xiaotong Yuan, Richang Hong)</author>
      <guid isPermaLink="false">2503.23869v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>FlexiMo: A Flexible Remote Sensing Foundation Model</title>
      <link>http://arxiv.org/abs/2503.23844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FlexiMo是一个灵活的遥感基础模型，能够适应任意空间分辨率，并通过空间分辨率感知模块和轻量级通道自适应模块，提高了模型在不同数据集上的泛化能力和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;多源卫星影像的快速扩展推动了遥感技术的发展，但许多现有模型受限于固定的空间分辨率和块大小，限制了其充分利用卫星影像中固有的异构空间特征的能力。&lt;h4&gt;目的&lt;/h4&gt;提出FlexiMo模型，以解决现有遥感模型在空间分辨率和块大小上的限制，提高模型的灵活性和有效性。&lt;h4&gt;方法&lt;/h4&gt;FlexiMo模型包含一个空间分辨率感知模块，该模块使用无参数对齐嵌入机制动态调整块嵌入，同时包含一个轻量级通道自适应模块，利用传感器的先验光谱信息处理不同通道数量的图像。&lt;h4&gt;主要发现&lt;/h4&gt;FlexiMo在多种多模态、多分辨率和多尺度数据集上的实验表明，该模型显著提高了模型泛化能力和鲁棒性，并在下游任务如场景分类、土地覆盖分类、城市建筑分割和云检测中表现出色。&lt;h4&gt;结论&lt;/h4&gt;FlexiMo通过参数高效和物理一致的自适应，为现实世界的遥感应用中的更适应性和有效的遥感基础模型铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid expansion of multi-source satellite imagery drives innovation inEarth observation, opening unprecedented opportunities for Remote SensingFoundation Models to harness diverse data. However, many existing models remainconstrained by fixed spatial resolutions and patch sizes, limiting theirability to fully exploit the heterogeneous spatial characteristics inherent insatellite imagery. To address these challenges, we propose FlexiMo, a flexibleremote sensing foundation model that endows the pre-trained model with theflexibility to adapt to arbitrary spatial resolutions. Central to FlexiMo is aspatial resolution-aware module that employs a parameter-free alignmentembedding mechanism to dynamically recalibrate patch embeddings based on theinput image's resolution and dimensions. This design not only preservescritical token characteristics and ensures multi-scale feature fidelity butalso enables efficient feature extraction without requiring modifications tothe underlying network architecture. In addition, FlexiMo incorporates alightweight channel adaptation module that leverages prior spectral informationfrom sensors. This mechanism allows the model to process images with varyingnumbers of channels while maintaining the data's intrinsic physical properties.Extensive experiments on diverse multimodal, multi-resolution, and multi-scaledatasets demonstrate that FlexiMo significantly enhances model generalizationand robustness. In particular, our method achieves outstanding performanceacross a range of downstream tasks, including scene classification, land coverclassification, urban building segmentation, and cloud detection. By enablingparameter-efficient and physically consistent adaptation, FlexiMo paves the wayfor more adaptable and effective foundation models in real-world remote sensingapplications.</description>
      <author>example@mail.com (Xuyang Li, Chenyu Li, Pedram Ghamisi, Danfeng Hong)</author>
      <guid isPermaLink="false">2503.23844v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Invariant Control Strategies for Active Flow Control using Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2503.22775v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用强化学习进行主动流动控制，特别是通过图神经网络（GNN）来提高控制策略的泛化能力，以解决现有方法的计算挑战和泛化能力不足的问题。&lt;h4&gt;背景&lt;/h4&gt;强化学习在主动流动控制领域应用广泛，尤其在降低二维圆柱体阻力方面已有应用。然而，由于样本效率低和模拟成本高，这些应用仍然面临计算挑战，且训练得到的策略泛化能力有限。&lt;h4&gt;目的&lt;/h4&gt;提出使用图神经网络来提升强化学习在流动控制中的应用，提高泛化能力，减少计算成本。&lt;h4&gt;方法&lt;/h4&gt;采用图神经网络处理无结构的三维流动数据，保持空间关系，并引入旋转、反射和排列不变性，以改善控制策略的泛化能力。在二维圆柱体主动流动控制问题中应用该方法，并使用Relexi和FLEXI框架进行训练和模拟。&lt;h4&gt;主要发现&lt;/h4&gt;基于GNN的控制策略在性能上与现有方法相当，同时具有更好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;图神经网络是一种有前景的架构，适用于基于强化学习的流动控制，Relexi和FLEXI框架适用于大规模的强化学习应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：强化学习在主动流动控制任务中得到了应用，最初的应用探索了通过流动场增强来降低二维圆柱体的阻力。自那时起，强化学习已被扩展到更复杂的湍流流动，并在学习复杂控制策略方面显示出巨大潜力。然而，由于样本效率低和相关的模拟成本高，这些应用在计算上具有挑战性。这一事实由于这些训练策略网络的泛化能力不足而加剧，通常隐式地与其训练条件的输入配置相关联。在这项工作中，我们提出使用图神经网络来解决这个问题特定的限制，有效地增加了适用范围，并从预先的强化学习训练成本中获得更多价值。GNN可以自然地处理无结构的、三维的流动数据，保持空间关系，而不受笛卡尔网格的约束。此外，它们将旋转、反射和排列不变性纳入所学习的控制策略中，从而提高了泛化能力，从而消除了常用CNN或MLP架构的缺点。为了证明这种方法的有效性，我们回顾了二维圆柱体主动流动控制中已建立的基准问题。使用Relexi，一个高性能的强化学习框架，实现了RL训练，并使用FLEXI，一个高阶不连续伽辽金框架，并行进行流动模拟。我们的结果表明，基于GNN的控制策略在性能上与现有方法相当，同时受益于改进的泛化能力。这项工作将GNN确立为基于强化学习的流动控制的有希望架构，并突出了Relexi和FLEXI在流体动力学大规模强化学习应用中的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.13140/RG.2.2.35286.77125&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement learning has gained traction for active flow control tasks,with initial applications exploring drag mitigation via flow field augmentationaround a two-dimensional cylinder. RL has since been extended to more complexturbulent flows and has shown significant potential in learning complex controlstrategies. However, such applications remain computationally challenging dueto its sample inefficiency and associated simulation costs. This fact isworsened by the lack of generalization capabilities of these trained policynetworks, often being implicitly tied to the input configurations of theirtraining conditions. In this work, we propose the use of graph neural networksto address this particular limitation, effectively increasing the range ofapplicability and getting more value out of the upfront RL training cost. GNNscan naturally process unstructured, threedimensional flow data, preservingspatial relationships without the constraints of a Cartesian grid.Additionally, they incorporate rotational, reflectional, and permutationinvariance into the learned control policies, thus improving generalization andthereby removing the shortcomings of commonly used CNN or MLP architectures. Todemonstrate the effectiveness of this approach, we revisit the well-establishedtwo-dimensional cylinder benchmark problem for active flow control. The RLtraining is implemented using Relexi, a high-performance RL framework, withflow simulations conducted in parallel using the high-order discontinuousGalerkin framework FLEXI. Our results show that GNN-based control policiesachieve comparable performance to existing methods while benefiting fromimproved generalization properties. This work establishes GNNs as a promisingarchitecture for RL-based flow control and highlights the capabilities ofRelexi and FLEXI for large-scale RL applications in fluid dynamics.</description>
      <author>example@mail.com (Marius Kurz, Rohan Kaushik, Marcel Blind, Patrick Kopper, Anna Schwarz, Felix Rodach, Andrea Beck)</author>
      <guid isPermaLink="false">2503.22775v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Conformal uncertainty quantification to evaluate predictive fairness of foundation AI model for skin lesion classes across patient demographics</title>
      <link>http://arxiv.org/abs/2503.23819v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于深度学习的医学图像诊断AI系统在医疗保健等高风险应用中的透明度和可解释性问题，并提出了一种使用符合性分析来量化预测不确定性的方法。&lt;h4&gt;背景&lt;/h4&gt;深度学习AI系统在医学图像诊断方面开始达到与人类专家相似的性能，但这些系统是数据密集型的黑盒，难以被用于高风险应用。&lt;h4&gt;目的&lt;/h4&gt;为了解决AI系统在临床应用中的不透明度和不可解释性问题，研究旨在量化基于视觉Transformer（ViT）的基础模型的预测不确定性。&lt;h4&gt;方法&lt;/h4&gt;研究使用了符合性分析来量化基于ViT的基础模型在皮肤病变分类任务中的预测不确定性，并使用了多个公开基准数据集。在模型训练过程中，采用了模型无关的动态F1分数采样来稳定类别不平衡，并研究了这种偏差缓解步骤对不确定性量化（UQ）的影响。&lt;h4&gt;主要发现&lt;/h4&gt;符合性分析提供了一种方法无关的覆盖保证，并为每个个体提供了不确定性分数。动态F1分数采样有助于稳定类别不平衡，并影响不确定性量化。&lt;h4&gt;结论&lt;/h4&gt;通过使用符合性分析和动态F1分数采样，可以评估基础模型特征嵌入的鲁棒性，从而提高临床AI的可靠性和公平性。&lt;h4&gt;翻译&lt;/h4&gt;Deep learning based diagnostic AI systems based on medical images are starting to provide similar performance as human experts. However these datahungry complex systems are inherently black boxes and therefore slow to be adopted for high risk applications like healthcare. This problem of lack of transparency is exacerbated in the case of recent large foundation models, which are trained in a self supervised manner on millions of data points to provide robust generalisation across a range of downstream tasks, but the embeddings generated from them happen through a process that is not interpretable, and hence not easily trustable for clinical applications. To address this timely issue, we deploy conformal analysis to quantify the predictive uncertainty of a vision transformer (ViT) based foundation model across patient demographics with respect to sex, age and ethnicity for the tasks of skin lesion classification using several public benchmark datasets. The significant advantage of this method is that conformal analysis is method independent and it not only provides a coverage guarantee at population level but also provides an uncertainty score for each individual. We used a model-agnostic dynamic F1-score-based sampling during model training, which helped to stabilize the class imbalance and we investigate the effects on uncertainty quantification (UQ) with or without this bias mitigation step. Thus we show how this can be used as a fairness metric to evaluate the robustness of the feature embeddings of the foundation model (Google DermFoundation) and thus advance the trustworthiness and fairness of clinical AI.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning based diagnostic AI systems based on medical images arestarting to provide similar performance as human experts. However these datahungry complex systems are inherently black boxes and therefore slow to beadopted for high risk applications like healthcare. This problem of lack oftransparency is exacerbated in the case of recent large foundation models,which are trained in a self supervised manner on millions of data points toprovide robust generalisation across a range of downstream tasks, but theembeddings generated from them happen through a process that is notinterpretable, and hence not easily trustable for clinical applications. Toaddress this timely issue, we deploy conformal analysis to quantify thepredictive uncertainty of a vision transformer (ViT) based foundation modelacross patient demographics with respect to sex, age and ethnicity for thetasks of skin lesion classification using several public benchmark datasets.The significant advantage of this method is that conformal analysis is methodindependent and it not only provides a coverage guarantee at population levelbut also provides an uncertainty score for each individual. We used amodel-agnostic dynamic F1-score-based sampling during model training, whichhelped to stabilize the class imbalance and we investigate the effects onuncertainty quantification (UQ) with or without this bias mitigation step. Thuswe show how this can be used as a fairness metric to evaluate the robustness ofthe feature embeddings of the foundation model (Google DermFoundation) and thusadvance the trustworthiness and fairness of clinical AI.</description>
      <author>example@mail.com (Swarnava Bhattacharyya, Umapada Pal, Tapabrata Chakraborti)</author>
      <guid isPermaLink="false">2503.23819v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Spatiotemporal Prediction using Artificial Intelligence: Extending the Framework of Geographically and Temporally Weighted Neural Network (GTWNN) for Differing Geographical and Temporal Contexts</title>
      <link>http://arxiv.org/abs/2503.22751v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文旨在通过扩展人工神经网络（ANNs）的数学框架来改进预测犯罪模型，并适当地应用它们。&lt;h4&gt;背景&lt;/h4&gt;地理空间和时间建模领域的最新进展集中在将地理加权纳入其深度学习模型中，以考虑空间数据中常见的非空间平稳性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的半解析方法来解决地理和时间加权回归（GTWR），并将其应用于伦敦犯罪数据。&lt;h4&gt;方法&lt;/h4&gt;对地理和时间加权神经网络（GTWNN）框架进行数学扩展，并生成三个数学扩展，结合这些扩展生成五种新的ANN，应用于伦敦和底特律数据集。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明，其中一个扩展是冗余的，通常被另一个称为历史依赖模块的扩展所超越。剩余的扩展形成了三种新的ANN设计，可能对GTWNN有改进。&lt;h4&gt;结论&lt;/h4&gt;在伦敦和底特律犯罪数据集中评估了各种模型的有效性，强调了在选择建模策略以改进模型适用性时考虑特定地理和时间特征的重要性。总的来说，提出的方法为时空建模中更具有情境感知、准确和鲁棒的ANN方法提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;本文旨在通过扩展人工神经网络（ANNs）的数学框架来改进预测犯罪模型，并适当地应用它们。地理空间和时间建模领域的最新进展集中在将地理加权纳入其深度学习模型中，以考虑空间数据中常见的非空间平稳性。本文提出一种新的半解析方法来解决地理和时间加权回归（GTWR），并将其应用于伦敦犯罪数据。对地理和时间加权神经网络（GTWNN）框架进行数学扩展，并生成三个数学扩展，结合这些扩展生成五种新的ANN，应用于伦敦和底特律数据集。结果表明，其中一个扩展是冗余的，通常被另一个称为历史依赖模块的扩展所超越。剩余的扩展形成了三种新的ANN设计，可能对GTWNN有改进。在伦敦和底特律犯罪数据集中评估了各种模型的有效性，强调了在选择建模策略以改进模型适用性时考虑特定地理和时间特征的重要性。总的来说，提出的方法为时空建模中更具有情境感知、准确和鲁棒的ANN方法提供了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper aims at improving predictive crime models by extending themathematical framework of Artificial Neural Networks (ANNs) tailored to generalspatiotemporal problems and appropriately applying them. Recent advancements inthe geospatial-temporal modelling field have focused on the inclusion ofgeographical weighting in their deep learning models to account for nonspatialstationarity, which is often apparent in spatial data. We formulate a novelsemi-analytical approach to solving Geographically and Temporally WeightedRegression (GTWR), and applying it to London crime data. The results producehigh-accuracy predictive evaluation scores that affirm the validity of theassumptions and approximations in the approach. This paper presentsmathematical advances to the Geographically and Temporally Weighted NeuralNetwork (GTWNN) framework, which offers a novel contribution to the field.Insights from past literature are harmoniously employed with the assumptionsand approximations to generate three mathematical extensions to GTWNN'sframework. Combinations of these extensions produce five novel ANNs, applied tothe London and Detroit datasets. The results suggest that one of the extensionsis redundant and is generally surpassed by another extension, which we term thehistory-dependent module. The remaining extensions form three novel ANN designsthat pose potential GTWNN improvements. We evaluated the efficacy of variousmodels in both the London and Detroit crime datasets, highlighting theimportance of accounting for specific geographic and temporal characteristicswhen selecting modelling strategies to improve model suitability. In general,the proposed methods provide the foundations for a more context-aware,accurate, and robust ANN approach in spatio-temporal modelling.</description>
      <author>example@mail.com (Nicholas Robert Fisk, Matthew Ng Kok Ming, Zahratu Shabrina)</author>
      <guid isPermaLink="false">2503.22751v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>MGD-SAM2: Multi-view Guided Detail-enhanced Segment Anything Model 2 for High-Resolution Class-agnostic Segmentation</title>
      <link>http://arxiv.org/abs/2503.23786v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的Segment Anything Model（MGD-SAM2），用于解决高分辨率独立类别分割（HRCS）中的细粒度细节分割问题。&lt;h4&gt;背景&lt;/h4&gt;尽管SAMs在图像分析任务中表现出色，但在处理高分辨率输入和低分辨率掩码预测时存在局限性，同时依赖于准确的手动提示。&lt;h4&gt;目的&lt;/h4&gt;提出MGD-SAM2以解决SAMs在HRCS中的细粒度细节分割挑战。&lt;h4&gt;方法&lt;/h4&gt;MGD-SAM2集成了SAM2和多种模块，包括Multi-view Perception Adapter (MPAdapter)、Multi-view Complementary Enhancement Module (MCEM)、Hierarchical Multi-view Interaction Module (HMIM)和Detail Refinement Module (DRM)。这些模块旨在增强局部细节和全局语义的提取，聚合多视角特征，并生成高分辨率的掩码预测。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MGD-SAM2在多个高分辨率和正常分辨率数据集上表现出优异的性能和强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;MGD-SAM2是一个有效的解决方案，可以提高HRCS中的细粒度细节分割性能。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Segment Anything Models (SAMs), as vision foundation models, have demonstrated remarkable performance across various image analysis tasks. Despite their strong generalization capabilities, SAMs encounter challenges in fine-grained detail segmentation for high-resolution class-independent segmentation (HRCS), due to the limitations in the direct processing of high-resolution inputs and low-resolution mask predictions, and the reliance on accurate manual prompts. To address these limitations, we propose MGD-SAM2 which integrates SAM2 with multi-view feature interaction between a global image and local patches to achieve precise segmentation. MGD-SAM2 incorporates the pre-trained SAM2 with four novel modules: the Multi-view Perception Adapter (MPAdapter), the Multi-view Complementary Enhancement Module (MCEM), the Hierarchical Multi-view Interaction Module (HMIM), and the Detail Refinement Module (DRM). Specifically, we first introduce MPAdapter to adapt the SAM2 encoder for enhanced extraction of local details and global semantics in HRCS images. Then, MCEM and HMIM are proposed to further exploit local texture and global context by aggregating multi-view features within and across multi-scales. Finally, DRM is designed to generate gradually restored high-resolution mask predictions, compensating for the loss of fine-grained details resulting from directly upsampling the low-resolution prediction maps. Experimental results demonstrate the superior performance and strong generalization of our model on multiple high-resolution and normal-resolution datasets. Code will be available at https://github.com/sevenshr/MGD-SAM2.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/sevenshr/mgd-sam2&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Segment Anything Models (SAMs), as vision foundation models, havedemonstrated remarkable performance across various image analysis tasks.Despite their strong generalization capabilities, SAMs encounter challenges infine-grained detail segmentation for high-resolution class-independentsegmentation (HRCS), due to the limitations in the direct processing ofhigh-resolution inputs and low-resolution mask predictions, and the reliance onaccurate manual prompts. To address these limitations, we propose MGD-SAM2which integrates SAM2 with multi-view feature interaction between a globalimage and local patches to achieve precise segmentation. MGD-SAM2 incorporatesthe pre-trained SAM2 with four novel modules: the Multi-view Perception Adapter(MPAdapter), the Multi-view Complementary Enhancement Module (MCEM), theHierarchical Multi-view Interaction Module (HMIM), and the Detail RefinementModule (DRM). Specifically, we first introduce MPAdapter to adapt the SAM2encoder for enhanced extraction of local details and global semantics in HRCSimages. Then, MCEM and HMIM are proposed to further exploit local texture andglobal context by aggregating multi-view features within and acrossmulti-scales. Finally, DRM is designed to generate gradually restoredhigh-resolution mask predictions, compensating for the loss of fine-graineddetails resulting from directly upsampling the low-resolution prediction maps.Experimental results demonstrate the superior performance and stronggeneralization of our model on multiple high-resolution and normal-resolutiondatasets. Code will be available at https://github.com/sevenshr/MGD-SAM2.</description>
      <author>example@mail.com (Haoran Shen, Peixian Zhuang, Jiahao Kou, Yuxin Zeng, Haoying Xu, Jiangyun Li)</author>
      <guid isPermaLink="false">2503.23786v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Language-Guided Trajectory Traversal in Disentangled Stable Diffusion Latent Space for Factorized Medical Image Generation</title>
      <link>http://arxiv.org/abs/2503.23623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了预训练的视觉-语言基础模型在医学图像数据集上进行微调后，在医学图像生成和插值中实现潜在因素解耦的能力。&lt;h4&gt;背景&lt;/h4&gt;文本到图像的扩散模型能够从自然语言提示中生成逼真的图像，这在疾病解释或探索因果关系方面至关重要。&lt;h4&gt;目的&lt;/h4&gt;探索预训练视觉-语言基础模型在医学图像领域解耦潜在因素的能力。&lt;h4&gt;方法&lt;/h4&gt;通过在胸部X光和皮肤数据集上进行大量实验，研究微调后的语言引导的Stable Diffusion模型如何学习将关键属性（如患者的解剖结构或疾病诊断特征）进行解耦。&lt;h4&gt;主要发现&lt;/h4&gt;微调后的语言引导的Stable Diffusion模型能够学习到关键属性，并通过生成模型的潜在空间轨迹遍历来识别、隔离和操作这些属性。&lt;h4&gt;结论&lt;/h4&gt;提出了一种框架，通过生成模型的潜在空间轨迹遍历来精确控制医学图像的生成。&lt;h4&gt;翻译&lt;/h4&gt;本研究首先探讨了预训练的视觉-语言基础模型在医学图像数据集上进行微调后，在医学图像生成和插值中实现潜在因素解耦的能力。通过在胸部X光和皮肤数据集上的大量实验，我们发现微调后的语言引导的Stable Diffusion模型能够自动学习到关键属性，如患者的解剖结构或疾病诊断特征。我们设计了一个框架，通过生成模型的潜在空间轨迹遍历来识别、隔离和操作这些关键属性，从而实现医学图像生成的精确控制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-to-image diffusion models have demonstrated a remarkable ability togenerate photorealistic images from natural language prompts. Thesehigh-resolution, language-guided synthesized images are essential for theexplainability of disease or exploring causal relationships. However, theirpotential for disentangling and controlling latent factors of variation inspecialized domains like medical imaging remains under-explored. In this work,we present the first investigation of the power of pre-trained vision-languagefoundation models, once fine-tuned on medical image datasets, to perform latentdisentanglement for factorized medical image generation and interpolation.Through extensive experiments on chest X-ray and skin datasets, we illustratethat fine-tuned, language-guided Stable Diffusion inherently learns tofactorize key attributes for image generation, such as the patient's anatomicalstructures or disease diagnostic features. We devise a framework to identify,isolate, and manipulate key attributes through latent space trajectorytraversal of generative models, facilitating precise control over medical imagesynthesis.</description>
      <author>example@mail.com (Zahra TehraniNasab, Amar Kumar, Tal Arbel)</author>
      <guid isPermaLink="false">2503.23623v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Vision-Language Foundation Models to Reveal Hidden Image-Attribute Relationships in Medical Imaging</title>
      <link>http://arxiv.org/abs/2503.23618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视觉语言基础模型（VLMs）在引导图像生成和医学影像应用中的性能，探讨了微调后的基础模型在识别关键数据属性方面的作用。&lt;h4&gt;背景&lt;/h4&gt;VLMs在通过文本引导图像生成方面表现出色，并在医学影像中应用。&lt;h4&gt;目的&lt;/h4&gt;研究微调后的基础模型是否可以帮助识别关键和可能未知的数据属性。&lt;h4&gt;方法&lt;/h4&gt;在胸部X光数据集上评估提出的方法，与依赖于结构因果模型（SCMs）的方法进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;微调后的VLMs可以生成高分辨率、精确编辑的图像，并揭示由于可用元数据粒度和模型容量限制而之前被掩盖的隐藏数据关系。&lt;h4&gt;结论&lt;/h4&gt;实验表明，这些模型有潜力揭示数据集的潜在属性，但也暴露了微调后的VLMs在准确图像编辑和易受偏差和虚假相关性影响方面的局限性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉语言基础模型（VLMs）在通过文本引导图像生成方面表现出色，在医学影像中有新兴应用。在这项工作中，我们首次研究了以下问题：‘微调后的基础模型是否可以帮助识别关键和可能未知的数据属性？’通过在我们的胸部X光数据集上评估我们的方法，我们表明，与依赖于结构因果模型（SCMs）的方法相比，这些模型可以根据多个指标生成高分辨率、精确编辑的图像。我们首次证明，微调后的VLMs可以揭示由于可用元数据粒度和模型容量限制而之前被掩盖的隐藏数据关系。我们的实验既展示了这些模型揭示数据集潜在属性的可能性，也暴露了微调后的VLMs在准确图像编辑和易受偏差和虚假相关性影响方面的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language foundation models (VLMs) have shown impressive performance inguiding image generation through text, with emerging applications in medicalimaging. In this work, we are the first to investigate the question: 'Canfine-tuned foundation models help identify critical, and possibly unknown, dataproperties?' By evaluating our proposed method on a chest x-ray dataset, weshow that these models can generate high-resolution, precisely edited imagescompared to methods that rely on Structural Causal Models (SCMs) according tonumerous metrics. For the first time, we demonstrate that fine-tuned VLMs canreveal hidden data relationships that were previously obscured due to availablemetadata granularity and model capacity limitations. Our experimentsdemonstrate both the potential of these models to reveal underlying datasetproperties while also exposing the limitations of fine-tuned VLMs for accurateimage editing and susceptibility to biases and spurious correlations.</description>
      <author>example@mail.com (Amar Kumar, Anita Kriz, Barak Pertzov, Tal Arbel)</author>
      <guid isPermaLink="false">2503.23618v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Bootstrap Your Own Views: Masked Ego-Exo Modeling for Fine-grained View-invariant Video Representations</title>
      <link>http://arxiv.org/abs/2503.19706v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025 Camera-ready, 18 pages, 7 figures, 9 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为BYOV的新型掩码ego-exo建模方法，用于从未配对的ego-exo视频中学习精细粒度的视不变视频表示，该方法同时促进了因果时序动态和跨视图对齐。&lt;h4&gt;背景&lt;/h4&gt;由于ego和exo视图之间在视角、运动模式和上下文上的显著差异，从ego和exo视频中学习视不变表示一直是视频理解系统跨多个视图泛化中的一个未充分探索的领域。&lt;h4&gt;目的&lt;/h4&gt;提出BYOV模型，旨在从未配对的ego-exo视频中学习视不变视频表示，以促进视频理解系统在不同视角之间的泛化。&lt;h4&gt;方法&lt;/h4&gt;BYOV方法通过自我视图掩码和跨视图掩码预测来学习视不变和强大的表示，同时捕获人类动作的组合特性，以实现鲁棒的跨视图理解。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，BYOV在四个下游ego-exo视频任务的所有指标上显著优于现有方法，并实现了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;BYOV是一种有效的视不变视频表示学习方法，能够提高视频理解系统在不同视角下的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从自视角（第一人称，ego）和外视角（第三人称，exo）视频中学习视不变的表示是跨多个视图泛化视频理解系统的一种有希望的途径。然而，由于ego和外视图在视角、运动模式和上下文之间存在显著差异，这个领域尚未得到充分探索。在本文中，我们提出了一种新的掩码ego-exo建模方法，称为Bootstrap Your Own Views（BYOV），该方法同时促进了因果时序动态和跨视图对齐，用于从未配对的ego-exo视频中学习精细粒度的视不变视频表示。我们强调了捕捉人类动作组合特性作为实现鲁棒跨视图理解的基础的重要性。具体来说，自我视图掩码和跨视图掩码预测被设计用来同时学习视不变和强大的表示。实验结果表明，我们的BYOV在四个下游ego-exo视频任务的所有指标上都显著优于现有方法，并在所有指标上取得了显著的性能提升。代码可在https://github.com/park-jungin/byov上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/park-jungin/byov&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; View-invariant representation learning from egocentric (first-person, ego)and exocentric (third-person, exo) videos is a promising approach towardgeneralizing video understanding systems across multiple viewpoints. However,this area has been underexplored due to the substantial differences inperspective, motion patterns, and context between ego and exo views. In thispaper, we propose a novel masked ego-exo modeling that promotes both causaltemporal dynamics and cross-view alignment, called Bootstrap Your Own Views(BYOV), for fine-grained view-invariant video representation learning fromunpaired ego-exo videos. We highlight the importance of capturing thecompositional nature of human actions as a basis for robust cross-viewunderstanding. Specifically, self-view masking and cross-view maskingpredictions are designed to learn view-invariant and powerful representationsconcurrently. Experimental results demonstrate that our BYOV significantlysurpasses existing approaches with notable gains across all metrics in fourdownstream ego-exo video tasks. The code is available athttps://github.com/park-jungin/byov.</description>
      <author>example@mail.com (Jungin Park, Jiyoung Lee, Kwanghoon Sohn)</author>
      <guid isPermaLink="false">2503.19706v2</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>SparseLoc: Sparse Open-Set Landmark-based Global Localization for Autonomous Navigation</title>
      <link>http://arxiv.org/abs/2503.23465v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SparseLoc是一种新的全局定位框架，利用视觉语言基础模型生成稀疏的语义拓扑地图，以实现更高效和鲁棒的全局定位。&lt;h4&gt;背景&lt;/h4&gt;全局定位在自主导航中至关重要，但依赖于密集的激光雷达地图需要大量存储和计算资源。&lt;h4&gt;目的&lt;/h4&gt;提出一种更高效和鲁棒的全局定位方法，克服现有技术的局限性。&lt;h4&gt;方法&lt;/h4&gt;SparseLoc结合了稀疏地图表示和蒙特卡洛定位方案，并采用了一种新颖的后期优化策略来改进姿态估计。&lt;h4&gt;主要发现&lt;/h4&gt;SparseLoc实现了超过5倍的位置定位精度提升，相对于现有稀疏映射技术，在KITTI数据集上达到了平均全局定位误差低于5米和2度的性能。&lt;h4&gt;结论&lt;/h4&gt;SparseLoc通过紧凑且高度区分性的地图构建和精心设计的优化调度，为全局定位提供了更有效和鲁棒的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Global localization is a critical problem in autonomous navigation, enablingprecise positioning without reliance on GPS. Modern global localizationtechniques often depend on dense LiDAR maps, which, while precise, requireextensive storage and computational resources. Recent approaches have exploredalternative methods, such as sparse maps and learned features, but they sufferfrom poor robustness and generalization. We propose SparseLoc, a globallocalization framework that leverages vision-language foundation models togenerate sparse, semantic-topometric maps in a zero-shot manner. It combinesthis map representation with a Monte Carlo localization scheme enhanced by anovel late optimization strategy, ensuring improved pose estimation. Byconstructing compact yet highly discriminative maps and refining localizationthrough a carefully designed optimization schedule, SparseLoc overcomes thelimitations of existing techniques, offering a more efficient and robustsolution for global localization. Our system achieves over a 5X improvement inlocalization accuracy compared to existing sparse mapping techniques. Despiteutilizing only 1/500th of the points of dense mapping methods, it achievescomparable performance, maintaining an average global localization error below5m and 2 degrees on KITTI sequences.</description>
      <author>example@mail.com (Pranjal Paul, Vineeth Bhat, Tejas Salian, Mohammad Omama, Krishna Murthy Jatavallabhula, Naveen Arulselvan, K. Madhava Krishna)</author>
      <guid isPermaLink="false">2503.23465v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Towards Trustworthy GUI Agents: A Survey</title>
      <link>http://arxiv.org/abs/2503.23434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, work in process&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于大型基础模型的GUI代理的可靠性和安全性问题，分析了其在安全性、可靠性、透明度、伦理和评估方法五个关键维度的可信度。&lt;h4&gt;背景&lt;/h4&gt;随着GUI代理的自主性提高，其在网络安全、隐私保护和安全性方面引发了重大担忧。&lt;h4&gt;目的&lt;/h4&gt;本文旨在评估GUI代理在五个关键维度的可信度，并识别相关挑战。&lt;h4&gt;方法&lt;/h4&gt;通过调查和识别主要挑战，如对抗性攻击的易受性、序列决策中的级联故障模式以及缺乏现实评估基准。&lt;h4&gt;主要发现&lt;/h4&gt;GUI代理的部署受到安全漏洞、动态环境中的可靠性问题、透明度和可解释性、伦理考量以及评价方法等方面的阻碍。&lt;h4&gt;结论&lt;/h4&gt;随着GUI代理的普及，建立稳健的安全标准和负责任的发展实践是至关重要的，本文为通过系统理解和未来研究提高GUI代理的可信度提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;This abstract discusses the reliability and security issues of GUI agents powered by large foundation models, analyzing their trustworthiness in five critical dimensions: security, reliability in dynamic environments, transparency and explainability, ethical considerations, and evaluation methodologies. The background of the paper is that the increasing autonomy of GUI agents has raised major concerns about their network security, privacy protection, and safety. The purpose of this paper is to assess the trustworthiness of GUI agents in five critical dimensions and identify related challenges. The method used is to investigate and identify major challenges such as vulnerability to adversarial attacks, cascading failure modes in sequential decision-making, and the lack of realistic evaluation benchmarks. The main findings show that the deployment of GUI agents is hindered by security vulnerabilities, reliability issues in dynamic environments, transparency and explainability, ethical considerations, and evaluation methods. The conclusion is that as GUI agents become more widespread, it is essential to establish robust safety standards and responsible development practices, and this paper provides a foundation for advancing trustworthy GUI agents through systematic understanding and future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; GUI agents, powered by large foundation models, can interact with digitalinterfaces, enabling various applications in web automation, mobile navigation,and software testing. However, their increasing autonomy has raised criticalconcerns about their security, privacy, and safety. This survey examines thetrustworthiness of GUI agents in five critical dimensions: securityvulnerabilities, reliability in dynamic environments, transparency andexplainability, ethical considerations, and evaluation methodologies. We alsoidentify major challenges such as vulnerability to adversarial attacks,cascading failure modes in sequential decision-making, and a lack of realisticevaluation benchmarks. These issues not only hinder real-world deployment butalso call for comprehensive mitigation strategies beyond task success. As GUIagents become more widespread, establishing robust safety standards andresponsible development practices is essential. This survey provides afoundation for advancing trustworthy GUI agents through systematicunderstanding and future research.</description>
      <author>example@mail.com (Yucheng Shi, Wenhao Yu, Wenlin Yao, Wenhu Chen, Ninghao Liu)</author>
      <guid isPermaLink="false">2503.23434v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of WebAgents: Towards Next-Generation AI Agents for Web Automation with Large Foundation Models</title>
      <link>http://arxiv.org/abs/2503.23350v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基于人工智能技术的AI Agent在处理网络任务中的应用，特别是大型基础模型（LFMs）在WebAgent中的应用潜力。&lt;h4&gt;背景&lt;/h4&gt;随着网络技术的发展，人们的生活在很多方面得到了革命性的改变，但网络上的许多任务重复且耗时，影响了生活质量。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用AI技术，特别是LFMs，开发能够自动处理网络任务的AI Agent，以提升用户的生活便利性和效率。&lt;h4&gt;方法&lt;/h4&gt;对WebAgent的研究进行了全面回顾，涵盖了架构、训练和可信度三个关键方面。&lt;h4&gt;主要发现&lt;/h4&gt;大型基础模型在语言理解和推理方面表现出人类水平的能力，为开发强大的AI Agent提供了可能性。&lt;h4&gt;结论&lt;/h4&gt;本文探讨了WebAgent的未来研究方向，以进一步挖掘LFMs的潜力。&lt;h4&gt;翻译&lt;/h4&gt;With the advancement of web techniques, they have significantly revolutionized various aspects of people's lives. Despite the importance of the web, many tasks performed on it are repetitive and time-consuming, negatively impacting overall quality of life. To efficiently handle these tedious daily tasks, one of the most promising approaches is to advance autonomous agents based on Artificial Intelligence (AI) techniques, referred to as AI Agents, as they can operate continuously without fatigue or performance degradation. In the context of the web, leveraging AI Agents -- termed WebAgents -- to automatically assist people in handling tedious daily tasks can dramatically enhance productivity and efficiency. Recently, Large Foundation Models (LFMs) containing billions of parameters have exhibited human-like language understanding and reasoning capabilities, showing proficiency in performing various complex tasks. This naturally raises the question: `Can LFMs be utilized to develop powerful AI Agents that automatically handle web tasks, providing significant convenience to users?' To fully explore the potential of LFMs, extensive research has emerged on WebAgents designed to complete daily web tasks according to user instructions, significantly enhancing the convenience of daily human life. In this survey, we comprehensively review existing research studies on WebAgents across three key aspects: architectures, training, and trustworthiness. Additionally, several promising directions for future research are explored to provide deeper insights.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the advancement of web techniques, they have significantlyrevolutionized various aspects of people's lives. Despite the importance of theweb, many tasks performed on it are repetitive and time-consuming, negativelyimpacting overall quality of life. To efficiently handle these tedious dailytasks, one of the most promising approaches is to advance autonomous agentsbased on Artificial Intelligence (AI) techniques, referred to as AI Agents, asthey can operate continuously without fatigue or performance degradation. Inthe context of the web, leveraging AI Agents -- termed WebAgents -- toautomatically assist people in handling tedious daily tasks can dramaticallyenhance productivity and efficiency. Recently, Large Foundation Models (LFMs)containing billions of parameters have exhibited human-like languageunderstanding and reasoning capabilities, showing proficiency in performingvarious complex tasks. This naturally raises the question: `Can LFMs beutilized to develop powerful AI Agents that automatically handle web tasks,providing significant convenience to users?' To fully explore the potential ofLFMs, extensive research has emerged on WebAgents designed to complete dailyweb tasks according to user instructions, significantly enhancing theconvenience of daily human life. In this survey, we comprehensively reviewexisting research studies on WebAgents across three key aspects: architectures,training, and trustworthiness. Additionally, several promising directions forfuture research are explored to provide deeper insights.</description>
      <author>example@mail.com (Liangbo Ning, Ziran Liang, Zhuohang Jiang, Haohao Qu, Yujuan Ding, Wenqi Fan, Xiao-yong Wei, Shanru Lin, Hui Liu, Philip S. Yu, Qing Li)</author>
      <guid isPermaLink="false">2503.23350v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Large Self-Supervised Models Bridge the Gap in Domain Adaptive Object Detection</title>
      <link>http://arxiv.org/abs/2503.23220v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages (8 main), 5 figures, accepted at CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的领域自适应目标检测（DAOD）方法，名为DINO Teacher，该方法通过使用大型预训练模型DINOv2来生成更准确的目标域标签，并通过特征对齐提高模型性能。&lt;h4&gt;背景&lt;/h4&gt;当前DAOD方法多采用Mean Teacher自标注，但该方法存在脆弱性和过度约束的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的DAOD方法，以解决现有方法的局限性，并提高目标域标签的准确性。&lt;h4&gt;方法&lt;/h4&gt;DINO Teacher包含两个组件：一是仅使用源数据训练一个新的标注器；二是通过特征对齐，使学生的源和目标图像块特征与DINO编码器的特征更接近。&lt;h4&gt;主要发现&lt;/h4&gt;DINO Teacher在多个DAOD数据集上取得了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;DINO Teacher通过利用大型预训练模型DINOv2，提高了DAOD的目标域标签准确性和模型性能。&lt;h4&gt;翻译&lt;/h4&gt;The current state-of-the-art methods in domain adaptive object detection (DAOD) use Mean Teacher self-labelling, where a teacher model, directly derived as an exponential moving average of the student model, is used to generate labels on the target domain which are then used to improve both models in a positive loop. This couples learning and generating labels on the target domain, and other recent works also leverage the generated labels to add additional domain alignment losses. We believe this coupling is brittle and excessively constrained: there is no guarantee that a student trained only on source data can generate accurate target domain labels and initiate the positive feedback loop, and much better target domain labels can likely be generated by using a large pretrained network that has been exposed to much more data. Vision foundational models are exactly such models, and they have shown impressive task generalization capabilities even when frozen. We want to leverage these models for DAOD and introduce DINO Teacher, which consists of two components. First, we train a new labeller on source data only using a large frozen DINOv2 backbone and show it generates more accurate labels than Mean Teacher. Next, we align the student's source and target image patch features with those from a DINO encoder, driving source and target representations closer to the generalizable DINO representation. We obtain state-of-the-art performance on multiple DAOD datasets. Code available at https://github.com/TRAILab/DINO_Teacher&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The current state-of-the-art methods in domain adaptive object detection(DAOD) use Mean Teacher self-labelling, where a teacher model, directly derivedas an exponential moving average of the student model, is used to generatelabels on the target domain which are then used to improve both models in apositive loop. This couples learning and generating labels on the targetdomain, and other recent works also leverage the generated labels to addadditional domain alignment losses. We believe this coupling is brittle andexcessively constrained: there is no guarantee that a student trained only onsource data can generate accurate target domain labels and initiate thepositive feedback loop, and much better target domain labels can likely begenerated by using a large pretrained network that has been exposed to muchmore data. Vision foundational models are exactly such models, and they haveshown impressive task generalization capabilities even when frozen. We want toleverage these models for DAOD and introduce DINO Teacher, which consists oftwo components. First, we train a new labeller on source data only using alarge frozen DINOv2 backbone and show it generates more accurate labels thanMean Teacher. Next, we align the student's source and target image patchfeatures with those from a DINO encoder, driving source and targetrepresentations closer to the generalizable DINO representation. We obtainstate-of-the-art performance on multiple DAOD datasets. Code available athttps://github.com/TRAILab/DINO_Teacher</description>
      <author>example@mail.com (Marc-Antoine Lavoie, Anas Mahmoud, Steven L. Waslander)</author>
      <guid isPermaLink="false">2503.23220v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Adaptation For Remote Sensing Visual Grounding</title>
      <link>http://arxiv.org/abs/2503.23083v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于PEFT技术的参数高效微调方法在遥感领域视觉定位任务中的应用，通过评估LoRA在不同模块的放置和结合BitFit及适配器对通用视觉定位数据集预训练的OFA基础模型进行微调，实现了性能与现有SOTA模型相当甚至更优，同时显著降低了计算成本。&lt;h4&gt;背景&lt;/h4&gt;基础模型在多模态领域表现出色，但在遥感视觉定位任务中由于领域特定挑战，直接应用效果不佳。&lt;h4&gt;目的&lt;/h4&gt;为了解决遥感视觉定位任务中的性能问题，研究如何利用PEFT技术来提升模型性能。&lt;h4&gt;方法&lt;/h4&gt;采用PEFT技术，对预训练的OFA基础模型进行微调，评估LoRA在不同模块的放置，并使用BitFit和适配器进行细调。&lt;h4&gt;主要发现&lt;/h4&gt;通过PEFT技术，实现了与现有SOTA模型相当或更优的性能，同时显著降低了计算成本。&lt;h4&gt;结论&lt;/h4&gt;PEFT技术在遥感视觉定位任务中具有潜力，为多模态分析提供了高效且经济的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型已经彻底改变了人工智能（AI），在多模态领域提供了非凡的能力。它们能够在复杂的地空和卫星图像中精确地定位物体，使用丰富的上下文信息和详细的物体描述，这对于遥感（RS）至关重要。这些模型可以通过视觉定位（VG）任务将文本描述与物体位置关联起来，但由于领域特定的挑战，它们直接应用于RS会产生次优结果。为了解决这个问题，我们应用了参数高效微调（PEFT）技术来适应这些模型用于RS特定的VG任务。具体来说，我们评估了LoRA在Grounding DINO的不同模块中的放置，并使用BitFit和适配器对在通用视觉定位数据集上预训练的OFA基础模型进行了微调。这种方法实现了与当前最先进（SOTA）模型相当或超过的性能，同时显著降低了计算成本。这项研究突出了PEFT技术在推进遥感多模态分析中的潜力，为全模型训练提供了一个实用且经济的替代方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have revolutionized artificial intelligence (AI), offeringremarkable capabilities across multi-modal domains. Their ability to preciselylocate objects in complex aerial and satellite images, using rich contextualinformation and detailed object descriptions, is essential for remote sensing(RS). These models can associate textual descriptions with object positionsthrough the Visual Grounding (VG) task, but due to domain-specific challenges,their direct application to RS produces sub-optimal results. To address this,we applied Parameter Efficient Fine Tuning (PEFT) techniques to adapt thesemodels for RS-specific VG tasks. Specifically, we evaluated LoRA placementacross different modules in Grounding DINO and used BitFit and adapters tofine-tune the OFA foundation model pre-trained on general-purpose VG datasets.This approach achieved performance comparable to or surpassing current State OfThe Art (SOTA) models while significantly reducing computational costs. Thisstudy highlights the potential of PEFT techniques to advance efficient andprecise multi-modal analysis in RS, offering a practical and cost-effectivealternative to full model training.</description>
      <author>example@mail.com (Hasan Moughnieh, Mohamad Chalhoub, Hasan Nasrallah, Cristiano Nattero, Paolo Campanella, Ali J. Ghandour)</author>
      <guid isPermaLink="false">2503.23083v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>InkFM: A Foundational Model for Full-Page Online Handwritten Note Understanding</title>
      <link>http://arxiv.org/abs/2503.23081v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了名为InkFM的基础模型，用于分析手写内容的整页，并展示了其在文本识别、数学表达式识别和页面分割方面的能力。&lt;h4&gt;背景&lt;/h4&gt;平板电脑和触控笔在笔记记录中越来越受欢迎，因此需要开发方法来准确理解和解释手写数字笔记的内容。&lt;h4&gt;目的&lt;/h4&gt;优化笔记体验，确保流畅高效的工作流程。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为InkFM的基础模型，该模型在多种任务上进行了训练，能够识别28种不同的文字脚本、数学表达式，并将页面分割成不同的元素，如文本和绘图。&lt;h4&gt;主要发现&lt;/h4&gt;InkFM在文本行分割任务上实现了超越公共基线的SoTA质量，通过在公共数据集上进行微调或LoRA调整，进一步提高了页面分割质量，实现了在DeepWriting、CASIA、SCUT和Mathwriting数据集上的最佳文本识别效果，以及在QuickDraw数据集上的草图分类。&lt;h4&gt;结论&lt;/h4&gt;InkFM的适应性为开发具有手写输入的应用程序提供了强大的起点。&lt;h4&gt;翻译&lt;/h4&gt;摘要：平板电脑和触控笔越来越被用于笔记记录。为了优化这一体验并确保流畅高效的工作流程，开发准确理解和解释手写数字笔记内容的方法至关重要。我们介绍了一种名为InkFM的基础模型，用于分析整页手写内容。该模型在多种任务上进行了训练，提供了一种独特的功能组合：识别28种不同的文字脚本、数学表达式识别，以及将页面分割成不同的元素，如文本和绘图。我们的结果表明，这些任务可以有效地在单个模型中统一，实现了超越公共基线（如docTR）的SoTA文本行分割质量。在公共数据集上对基础模型进行微调或LoRA调整，进一步提高了页面分割质量，实现了在DeepWriting、CASIA、SCUT和Mathwriting数据集上的最佳文本识别效果，以及在QuickDraw数据集上的草图分类。InkFM的这种适应性为开发具有手写输入的应用程序提供了强大的起点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tablets and styluses are increasingly popular for taking notes. To optimizethis experience and ensure a smooth and efficient workflow, it's important todevelop methods for accurately interpreting and understanding the content ofhandwritten digital notes. We introduce a foundational model called InkFM foranalyzing full pages of handwritten content. Trained on a diverse mixture oftasks, this model offers a unique combination of capabilities: recognizing textin 28 different scripts, mathematical expressions recognition, and segmentingpages into distinct elements like text and drawings. Our results demonstratethat these tasks can be effectively unified within a single model, achievingSoTA text line segmentation out-of-the-box quality surpassing public baselineslike docTR. Fine- or LoRA-tuning our base model on public datasets furtherimproves the quality of page segmentation, achieves state-of the art textrecognition (DeepWriting, CASIA, SCUT, and Mathwriting datasets) and sketchclassification (QuickDraw). This adaptability of InkFM provides a powerfulstarting point for developing applications with handwritten input.</description>
      <author>example@mail.com (Anastasiia Fadeeva, Vincent Coriou, Diego Antognini, Claudiu Musat, Andrii Maksai)</author>
      <guid isPermaLink="false">2503.23081v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Identifying Multi-modal Knowledge Neurons in Pretrained Transformers via Two-stage Filtering</title>
      <link>http://arxiv.org/abs/2503.22941v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种使用MiniGPT-4识别与特定知识相关的神经元的方法，以解决多模态语言模型（MLLMs）中知识定位的问题。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型（LLMs）在自然语言处理（NLP）和计算机视觉领域取得了进展，但MLLMs存在内部处理不透明、产生幻觉和错误信息等挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决MLLMs中知识定位的问题。&lt;h4&gt;方法&lt;/h4&gt;研究通过两个阶段提取知识神经元：使用 inpainting 和 GradCAM 进行激活差异过滤，以及基于梯度的过滤。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在MS COCO 2017数据集上的图像标题生成任务中，比现有方法能更准确地定位知识。&lt;h4&gt;结论&lt;/h4&gt;该方法有助于MLLMs中知识的可视化和可解释性，并为未来的知识编辑和控制展示了潜力。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in large language models (LLMs) have led to the development of multimodal LLMs (MLLMs) in the fields of natural language processing (NLP) and computer vision. Although these models allow for integrated visual and language understanding, they present challenges such as opaque internal processing and the generation of hallucinations and misinformation. Therefore, there is a need for a method to clarify the location of knowledge in MLLMs. In this study, we propose a method to identify neurons associated with specific knowledge using MiniGPT-4, a Transformer-based MLLM. Specifically, we extract knowledge neurons through two stages: activation differences filtering using inpainting and gradient-based filtering using GradCAM. Experiments on the image caption generation task using the MS COCO 2017 dataset, BLEU, ROUGE, and BERTScore quantitative evaluation, and qualitative evaluation using an activation heatmap showed that our method is able to locate knowledge with higher accuracy than existing methods. This study contributes to the visualization and explainability of knowledge in MLLMs and shows the potential for future knowledge editing and control.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in large language models (LLMs) have led to the developmentof multimodal LLMs (MLLMs) in the fields of natural language processing (NLP)and computer vision. Although these models allow for integrated visual andlanguage understanding, they present challenges such as opaque internalprocessing and the generation of hallucinations and misinformation. Therefore,there is a need for a method to clarify the location of knowledge in MLLMs.  In this study, we propose a method to identify neurons associated withspecific knowledge using MiniGPT-4, a Transformer-based MLLM. Specifically, weextract knowledge neurons through two stages: activation differences filteringusing inpainting and gradient-based filtering using GradCAM. Experiments on theimage caption generation task using the MS COCO 2017 dataset, BLEU, ROUGE, andBERTScore quantitative evaluation, and qualitative evaluation using anactivation heatmap showed that our method is able to locate knowledge withhigher accuracy than existing methods.  This study contributes to the visualization and explainability of knowledgein MLLMs and shows the potential for future knowledge editing and control.</description>
      <author>example@mail.com (Yugen Sato, Tomohiro Takagi)</author>
      <guid isPermaLink="false">2503.22941v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Task Tokens: A Flexible Approach to Adapting Behavior Foundation Models</title>
      <link>http://arxiv.org/abs/2503.22886v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为“任务标记”的方法，旨在使基于Transformer的行为基础模型（BFM）能够更好地适应特定任务，同时保持其灵活性。&lt;h4&gt;背景&lt;/h4&gt;虽然基于Transformer的BFM在生成鲁棒行为方面表现出色，但它们通常需要精细的提示工程才能完成特定任务，这可能导致结果不理想。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，使BFM能够有效地适应特定任务，同时保持其灵活性。&lt;h4&gt;方法&lt;/h4&gt;通过利用BFM的Transformer架构，本文提出了一种通过强化学习学习新任务特定编码器的方法，同时保持原始BFM不变。这种方法允许结合用户定义的先验知识，平衡奖励设计和提示工程。通过训练任务编码器将观察映射到标记，作为BFM的额外输入，从而引导性能提升，同时保持模型的多样化控制特性。&lt;h4&gt;主要发现&lt;/h4&gt;本文展示了“任务标记”在多种任务中的有效性，包括分布外场景，并显示了其与其他提示模态的兼容性。&lt;h4&gt;结论&lt;/h4&gt;结果表明，“任务标记”是一种有前景的方法，可以使BFM适应特定控制任务，同时保留其泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：最近在模仿学习方面的进展导致基于Transformer的行为基础模型（BFM）的出现，这些模型能够为类人形代理提供多模态、类似人类的控制。虽然BFM在零样本生成鲁棒行为方面表现出色，但它们通常需要精细的提示工程来完成特定任务，这可能导致结果不理想。我们引入了“任务标记”方法，这是一种有效地调整BFM以适应特定任务同时保持其灵活性的方法。我们的方法利用BFM的Transformer架构，通过强化学习学习一个新的任务特定编码器，同时保持原始BFM冻结。这允许结合用户定义的先验知识，平衡奖励设计和提示工程。通过训练一个任务编码器将观察映射到标记，用作BFM的额外输入，我们引导性能改进，同时保持模型的多样化控制特性。我们在各种任务中展示了Task Tokens的有效性，包括分布外场景，并显示了它们与其他提示模态的兼容性。我们的结果表明，Task Tokens为将BFM适应特定控制任务同时保留其泛化能力提供了一种有前景的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in imitation learning have led to transformer-basedbehavior foundation models (BFMs) that enable multi-modal, human-like controlfor humanoid agents. While excelling at zero-shot generation of robustbehaviors, BFMs often require meticulous prompt engineering for specific tasks,potentially yielding suboptimal results. We introduce "Task Tokens", a methodto effectively tailor BFMs to specific tasks while preserving theirflexibility. Our approach leverages the transformer architecture of BFMs tolearn a new task-specific encoder through reinforcement learning, keeping theoriginal BFM frozen. This allows incorporation of user-defined priors,balancing reward design and prompt engineering. By training a task encoder tomap observations to tokens, used as additional BFM inputs, we guide performanceimprovement while maintaining the model's diverse control characteristics. Wedemonstrate Task Tokens' efficacy across various tasks, includingout-of-distribution scenarios, and show their compatibility with otherprompting modalities. Our results suggest that Task Tokens offer a promisingapproach for adapting BFMs to specific control tasks while retaining theirgeneralization capabilities.</description>
      <author>example@mail.com (Ron Vainshtein, Zohar Rimon, Shie Mannor, Chen Tessler)</author>
      <guid isPermaLink="false">2503.22886v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>Zero-shot Domain Generalization of Foundational Models for 3D Medical Image Segmentation: An Experimental Study</title>
      <link>http://arxiv.org/abs/2503.22862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了域偏移对医学图像分割模型泛化能力的影响，探讨了基础模型在跨模态医学数据中的应用，并通过实验验证了可提示基础模型在通过智能提示技术弥合域差距方面的潜力。&lt;h4&gt;背景&lt;/h4&gt;医学图像分割中的域偏移限制了模型的泛化能力，而基础模型在大规模数据上的训练显示出零样本泛化的潜力，但在体积医学数据中的应用尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;通过实验研究检验基础模型在域泛化（DG）方面的能力，并探究零样本DG的可行性。&lt;h4&gt;方法&lt;/h4&gt;对6个医学分割基础模型和涵盖多种模态和解剖结构的12个公共数据集进行了全面实验研究。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现可提示基础模型通过智能提示技术在弥合域差距方面具有潜力，并对零样本DG的多个方面进行了探究，提供了有关基础模型在DG方面的可行性的有价值见解。&lt;h4&gt;结论&lt;/h4&gt;论文提出了基础模型在DG领域的应用潜力，并为未来研究指明了有希望的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain shift, caused by variations in imaging modalities and acquisitionprotocols, limits model generalization in medical image segmentation. Whilefoundation models (FMs) trained on diverse large-scale data hold promise forzero-shot generalization, their application to volumetric medical data remainsunderexplored. In this study, we examine their ability towards domaingeneralization (DG), by conducting a comprehensive experimental studyencompassing 6 medical segmentation FMs and 12 public datasets spanningmultiple modalities and anatomies. Our findings reveal the potential ofpromptable FMs in bridging the domain gap via smart prompting techniques.Additionally, by probing into multiple facets of zero-shot DG, we offervaluable insights into the viability of FMs for DG and identify promisingavenues for future research.</description>
      <author>example@mail.com (Soumitri Chattopadhyay, Basar Demir, Marc Niethammer)</author>
      <guid isPermaLink="false">2503.22862v1</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    <item>
      <title>MonoInstance: Enhancing Monocular Priors via Multi-view Instance Alignment for Neural Rendering and Reconstruction</title>
      <link>http://arxiv.org/abs/2503.18363v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025. Project page:  https://wen-yuan-zhang.github.io/MonoInstance/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MonoInstance是一种利用单目深度先验来增强神经渲染和重建的方法，通过在多个视图中共享3D空间中实例深度，从而将单目深度的不确定性转化为噪声点云中的密度度量。&lt;h4&gt;背景&lt;/h4&gt;单目深度先验在多视图任务如3D重建和新视图合成中被广泛采用，但由于每个视图的预测不一致，如何在多视图环境中更有效地利用单目线索仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出MonoInstance方法，以解决单目先验中固有的不准确性和跨视图不一致性问题，为神经渲染和重建提供增强的几何先验。&lt;h4&gt;方法&lt;/h4&gt;MonoInstance通过在多个视图中共享3D空间中对齐分割实例的深度，将单目深度的不确定性转化为噪声点云中的密度度量，并在深度先验不可靠的高不确定性区域引入约束项，以鼓励投影实例与附近视图的对应实例掩码对齐。&lt;h4&gt;主要发现&lt;/h4&gt;MonoInstance是一种通用的策略，可以无缝集成到各种多视图神经渲染框架中，实验结果表明，MonoInstance在重建和新视图合成任务上显著提高了性能。&lt;h4&gt;结论&lt;/h4&gt;MonoInstance方法能够有效地利用单目深度先验，提高神经渲染和重建的性能，为多视图任务提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular depth priors have been widely adopted by neural rendering inmulti-view based tasks such as 3D reconstruction and novel view synthesis.However, due to the inconsistent prediction on each view, how to moreeffectively leverage monocular cues in a multi-view context remains achallenge. Current methods treat the entire estimated depth mapindiscriminately, and use it as ground truth supervision, while ignoring theinherent inaccuracy and cross-view inconsistency in monocular priors. Toresolve these issues, we propose MonoInstance, a general approach that exploresthe uncertainty of monocular depths to provide enhanced geometric priors forneural rendering and reconstruction. Our key insight lies in aligning eachsegmented instance depths from multiple views within a common 3D space, therebycasting the uncertainty estimation of monocular depths into a density measurewithin noisy point clouds. For high-uncertainty areas where depth priors areunreliable, we further introduce a constraint term that encourages theprojected instances to align with corresponding instance masks on nearby views.MonoInstance is a versatile strategy which can be seamlessly integrated intovarious multi-view neural rendering frameworks. Our experimental resultsdemonstrate that MonoInstance significantly improves the performance in bothreconstruction and novel view synthesis under various benchmarks.</description>
      <author>example@mail.com (Wenyuan Zhang, Yixiao Yang, Han Huang, Liang Han, Kanle Shi, Yu-Shen Liu, Zhizhong Han)</author>
      <guid isPermaLink="false">2503.18363v2</guid>
      <pubDate>Tue, 01 Apr 2025 14:29:58 +0800</pubDate>
    </item>
    </channel>
</rss>